From 7cc857e9138d8675894667fd728975105fcfd745 Mon Sep 17 00:00:00 2001
From: Kosta Zertsekel <konszert@marvell.com>
Date: Sun, 6 Jan 2013 10:18:39 +0200
Subject: [PATCH 0007/1825] AXP initial support: add mach-armadaxp and plat

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit 1773d2c9879ef14bc441241c332394e843fea9e5

Change-Id: Ie9a20cb6aec5accc44937949ba6622380c2ed5af

Signed-off-by: Kosta Zertsekel <konszert@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 arch/arm/kernel/Makefile                           |    2 +
 arch/arm/kernel/perf_event_pj4b.c                  |  606 +++
 arch/arm/kernel/smp.c                              |    9 +
 arch/arm/mach-armadaxp/Kconfig                     |   97 +
 arch/arm/mach-armadaxp/Makefile                    |  156 +
 arch/arm/mach-armadaxp/Makefile.boot               |    4 +
 arch/arm/mach-armadaxp/clcd.c                      |  555 +++
 arch/arm/mach-armadaxp/clock.c                     |   50 +
 arch/arm/mach-armadaxp/clock.h                     |    5 +
 arch/arm/mach-armadaxp/config/mvRules.mk           |  178 +
 arch/arm/mach-armadaxp/config/mvSysCesaConfig.h    |   45 +
 arch/arm/mach-armadaxp/config/mvSysCntmrConfig.h   |   36 +
 arch/arm/mach-armadaxp/config/mvSysDdrConfig.h     |   45 +
 arch/arm/mach-armadaxp/config/mvSysEthConfig.h     |  151 +
 arch/arm/mach-armadaxp/config/mvSysEthPhyConfig.h  |   32 +
 arch/arm/mach-armadaxp/config/mvSysGppConfig.h     |   37 +
 arch/arm/mach-armadaxp/config/mvSysHwConfig.h      |  267 ++
 arch/arm/mach-armadaxp/config/mvSysNfcConfig.h     |   36 +
 arch/arm/mach-armadaxp/config/mvSysPciConfig.h     |   26 +
 arch/arm/mach-armadaxp/config/mvSysPexConfig.h     |   50 +
 arch/arm/mach-armadaxp/config/mvSysPonConfig.h     |   38 +
 arch/arm/mach-armadaxp/config/mvSysRtcConfig.h     |   36 +
 arch/arm/mach-armadaxp/config/mvSysSataConfig.h    |   36 +
 arch/arm/mach-armadaxp/config/mvSysSdmmcConfig.h   |   37 +
 arch/arm/mach-armadaxp/config/mvSysSpiConfig.h     |   36 +
 arch/arm/mach-armadaxp/config/mvSysTdmConfig.h     |   68 +
 arch/arm/mach-armadaxp/config/mvSysTsConfig.h      |   39 +
 arch/arm/mach-armadaxp/config/mvSysTwsiConfig.h    |   41 +
 arch/arm/mach-armadaxp/config/mvSysUsbConfig.h     |   36 +
 arch/arm/mach-armadaxp/config/mvSysXorConfig.h     |   36 +
 arch/arm/mach-armadaxp/core.c                      | 1528 ++++++
 arch/arm/mach-armadaxp/dbg-trace.c                 |  112 +
 arch/arm/mach-armadaxp/dbg-trace.h                 |   24 +
 arch/arm/mach-armadaxp/dump_cp15_regs.c            |  219 +
 arch/arm/mach-armadaxp/export.c                    |  205 +
 arch/arm/mach-armadaxp/flashmap.c                  |  250 +
 arch/arm/mach-armadaxp/headsmp.S                   |   83 +
 arch/arm/mach-armadaxp/hwmon.c                     |  353 ++
 arch/arm/mach-armadaxp/include/mach/armadaxp.h     |  216 +
 arch/arm/mach-armadaxp/include/mach/clkdev.h       |    7 +
 arch/arm/mach-armadaxp/include/mach/debug-macro.S  |   20 +
 arch/arm/mach-armadaxp/include/mach/dma.h          |   16 +
 arch/arm/mach-armadaxp/include/mach/dove_bl.h      |   35 +
 arch/arm/mach-armadaxp/include/mach/entry-macro.S  |  171 +
 arch/arm/mach-armadaxp/include/mach/gpio.h         |   55 +
 arch/arm/mach-armadaxp/include/mach/hardware.h     |   21 +
 arch/arm/mach-armadaxp/include/mach/ide.h          |   15 +
 arch/arm/mach-armadaxp/include/mach/io.h           |   32 +
 arch/arm/mach-armadaxp/include/mach/irqs.h         |  170 +
 arch/arm/mach-armadaxp/include/mach/kw_macro.h     |   39 +
 arch/arm/mach-armadaxp/include/mach/memory.h       |   34 +
 arch/arm/mach-armadaxp/include/mach/param.h        |   15 +
 arch/arm/mach-armadaxp/include/mach/serial.h       |   41 +
 arch/arm/mach-armadaxp/include/mach/smp.h          |   29 +
 arch/arm/mach-armadaxp/include/mach/system.h       |   31 +
 arch/arm/mach-armadaxp/include/mach/timex.h        |    9 +
 arch/arm/mach-armadaxp/include/mach/uncompress.h   |  133 +
 arch/arm/mach-armadaxp/include/mach/vmalloc.h      |   11 +
 arch/arm/mach-armadaxp/irq.c                       |  329 ++
 arch/arm/mach-armadaxp/leds.c                      |   49 +
 arch/arm/mach-armadaxp/mpp.h                       |   34 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysCesa.c       |  117 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysCesaApi.h    |   71 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysDdr.c        |  134 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysEth.c        |  132 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysEthApi.h     |   71 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysEthPhy.c     |  104 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysEthPhyApi.h  |   71 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysNeta.c       |  137 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysNetaApi.h    |   71 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysPci.c        | 1382 ++++++
 arch/arm/mach-armadaxp/mv_hal_if/mvSysPci.h        |  256 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysPex.c        |  106 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysPexApi.h     |   71 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysSFlash.c     |  226 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysSata.c       |   82 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysSataApi.h    |   71 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysSpi.c        |  126 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysSpiApi.h     |   70 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysTdm.c        |  236 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysTdmApi.h     |   78 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysTs.c         |   87 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysTsApi.h      |   73 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysUsb.c        |  103 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysUsbApi.h     |   70 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysXor.c        |   87 +
 arch/arm/mach-armadaxp/mv_hal_if/mvSysXorApi.h     |   70 +
 arch/arm/mach-armadaxp/pci.c                       |  243 +
 arch/arm/mach-armadaxp/pex.c                       |  405 ++
 arch/arm/mach-armadaxp/platsmp.c                   |  275 ++
 arch/arm/mach-armadaxp/pm.c                        |  112 +
 arch/arm/mach-armadaxp/proc_aurora_dbg.c           |   88 +
 arch/arm/mach-armadaxp/sysmap.c                    |  235 +
 arch/arm/mach-armadaxp/time.c                      |  344 ++
 arch/arm/mach-armadaxp/usb.c                       |  161 +
 arch/arm/mm/Kconfig                                |  192 +-
 arch/arm/mm/cache-aurora-l2.c                      |  689 +++
 arch/arm/mm/mmu.c                                  |    6 +
 arch/arm/mm/proc-sheeva_pj4bv6.S                   |  326 ++
 arch/arm/mm/proc-sheeva_pj4bv7.S                   |  546 +++
 arch/arm/mm/sheeva_pj4b-macros.S                   |   32 +
 arch/arm/plat-armada/Kconfig                       |  459 ++
 arch/arm/plat-armada/Makefile                      |   15 +
 arch/arm/plat-armada/armadaxp_suspend.S            |  189 +
 arch/arm/plat-armada/cpuidle.c                     |  333 ++
 arch/arm/plat-armada/hotplug.c                     |  125 +
 .../arm/plat-armada/include/plat/cache-aurora-l2.h |  164 +
 arch/arm/plat-armada/include/plat/gpio.h           |   26 +
 arch/arm/plat-armada/include/plat/i2s-orion.h      |   23 +
 arch/arm/plat-armada/include/plat/msi.h            |   11 +
 arch/arm/plat-armada/include/plat/mv_xor.h         |   30 +
 arch/arm/plat-armada/include/plat/mvsdio.h         |   21 +
 arch/arm/plat-armada/include/plat/orion_wdt.h      |   18 +
 arch/arm/plat-armada/include/plat/xor.h            |   26 +
 arch/arm/plat-armada/linux_oss/mvOs.c              |  245 +
 arch/arm/plat-armada/linux_oss/mvOs.h              |  573 +++
 arch/arm/plat-armada/linux_oss/mvOsSata.h          |  157 +
 arch/arm/plat-armada/msi.c                         |  154 +
 .../plat-armada/mv_drivers_lsp/mv_audio/Makefile   |   15 +
 .../mv_drivers_lsp/mv_audio/cs42l51-hal.c          |  178 +
 .../mv_drivers_lsp/mv_audio/mv88fx-hal.c           |  342 ++
 .../mv_drivers_lsp/mv_audio/mv88fx-pcm.c           | 1678 +++++++
 .../mv_drivers_lsp/mv_audio/mv88fx-pcm.h           |  124 +
 .../mv_drivers_lsp/mv_audio_soc/Makefile           |   22 +
 .../mv_drivers_lsp/mv_audio_soc/mv88fx-i2s.c       |  827 ++++
 .../mv_drivers_lsp/mv_audio_soc/mv88fx-i2s.h       |   20 +
 .../mv_drivers_lsp/mv_audio_soc/mv88fx-pcm.c       |  617 +++
 .../mv_drivers_lsp/mv_audio_soc/mv88fx-pcm.h       |  126 +
 .../mv_drivers_lsp/mv_audio_soc/mv88fx-rt5623.c    |  359 ++
 .../mv_drivers_lsp/mv_audio_soc/mv88fx.c           |  648 +++
 .../plat-armada/mv_drivers_lsp/mv_btns/Makefile    |   12 +
 .../mv_drivers_lsp/mv_btns/btns_driver.c           |  360 ++
 .../mv_drivers_lsp/mv_btns/btns_driver.h           |   60 +
 .../arm/plat-armada/mv_drivers_lsp/mv_cesa/Kconfig |   51 +
 .../plat-armada/mv_drivers_lsp/mv_cesa/Makefile    |   18 +
 .../plat-armada/mv_drivers_lsp/mv_cesa/cesa_dev.c  |  276 ++
 .../plat-armada/mv_drivers_lsp/mv_cesa/cesa_dev.h  |   63 +
 .../plat-armada/mv_drivers_lsp/mv_cesa/cesa_if.c   |  392 ++
 .../plat-armada/mv_drivers_lsp/mv_cesa/cesa_if.h   |  102 +
 .../mv_drivers_lsp/mv_cesa/cesa_ocf_drv.c          | 1248 +++++
 .../plat-armada/mv_drivers_lsp/mv_cesa/cesa_test.c | 3038 ++++++++++++
 arch/arm/plat-armada/mv_drivers_lsp/mv_dma/Kconfig |   55 +
 .../arm/plat-armada/mv_drivers_lsp/mv_dma/Makefile |   14 +
 .../arm/plat-armada/mv_drivers_lsp/mv_dma/mv_dma.c |  798 ++++
 .../plat-armada/mv_drivers_lsp/mv_gpio/Makefile    |   12 +
 .../plat-armada/mv_drivers_lsp/mv_gpio/mv_gpio.c   |  160 +
 .../arm/plat-armada/mv_drivers_lsp/mv_mtd/Makefile |   13 +
 .../arm/plat-armada/mv_drivers_lsp/mv_mtd/mflash.c |  361 ++
 .../plat-armada/mv_drivers_lsp/mv_mtd/nand_lnc.c   |  702 +++
 .../plat-armada/mv_drivers_lsp/mv_mtd/nand_lnc.h   |   85 +
 .../plat-armada/mv_drivers_lsp/mv_mtd/nand_nfc.c   | 1760 +++++++
 .../plat-armada/mv_drivers_lsp/mv_mtd/nand_nfc.h   |   36 +
 .../arm/plat-armada/mv_drivers_lsp/mv_mtd/sflash.c |  419 ++
 .../arm/plat-armada/mv_drivers_lsp/mv_neta/Kconfig |  819 ++++
 .../mv_drivers_lsp/mv_neta/bm/bm_sysfs.c           |  145 +
 .../mv_drivers_lsp/mv_neta/hwf/hwf_bm.c            |  254 +
 .../mv_drivers_lsp/mv_neta/hwf/hwf_sysfs.c         |  162 +
 .../mv_drivers_lsp/mv_neta/l2fw/l2fw_sysfs.c       |  200 +
 .../mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.c      | 1878 ++++++++
 .../mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.h      |   40 +
 .../mv_drivers_lsp/mv_neta/net_dev/Makefile        |   17 +
 .../mv_drivers_lsp/mv_neta/net_dev/mv_eth_proc.c   |  520 ++
 .../mv_drivers_lsp/mv_neta/net_dev/mv_eth_proc.h   |  126 +
 .../mv_drivers_lsp/mv_neta/net_dev/mv_eth_switch.c |  767 +++
 .../mv_drivers_lsp/mv_neta/net_dev/mv_eth_sysfs.c  |  478 ++
 .../mv_drivers_lsp/mv_neta/net_dev/mv_eth_tool.c   |  839 ++++
 .../mv_drivers_lsp/mv_neta/net_dev/mv_eth_tool.h   |    7 +
 .../mv_drivers_lsp/mv_neta/net_dev/mv_ethernet.c   |  411 ++
 .../mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c     | 4994 ++++++++++++++++++++
 .../mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h     |  536 +++
 .../mv_drivers_lsp/mv_neta/net_dev/mv_pon_sysfs.c  |  181 +
 .../mv_drivers_lsp/mv_neta/pmt/pmt_sysfs.c         |  180 +
 .../mv_drivers_lsp/mv_neta/pnc/pnc_sysfs.c         |  363 ++
 .../mv_drivers_lsp/mv_neta/pnc/wol_sysfs.c         |  201 +
 .../plat-armada/mv_drivers_lsp/mv_network/Kconfig  |  320 ++
 .../mv_drivers_lsp/mv_network/mv_ethernet/Makefile |   17 +
 .../mv_network/mv_ethernet/mv_eth_proc.c           |  571 +++
 .../mv_network/mv_ethernet/mv_eth_proc.h           |  138 +
 .../mv_network/mv_ethernet/mv_eth_tool.c           | 1061 +++++
 .../mv_network/mv_ethernet/mv_eth_tool.h           |   85 +
 .../mv_network/mv_ethernet/mv_ethernet.c           |  410 ++
 .../mv_network/mv_ethernet/mv_gateway.c            | 1443 ++++++
 .../mv_network/mv_ethernet/mv_gtw_igmp.c           |  541 +++
 .../mv_network/mv_ethernet/mv_netdev.c             | 3637 ++++++++++++++
 .../mv_network/mv_ethernet/mv_netdev.h             |  531 +++
 .../mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_mgr.c | 2087 ++++++++
 .../mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_mgr.h |  224 +
 .../mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_sec.c |  716 +++
 .../plat-armada/mv_drivers_lsp/mv_phone/Kconfig    |   93 +
 .../plat-armada/mv_drivers_lsp/mv_phone/Makefile   |  111 +
 arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tal.c |  157 +
 arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tal.h |   70 +
 .../plat-armada/mv_drivers_lsp/mv_phone/tdm_if.c   |  451 ++
 .../plat-armada/mv_drivers_lsp/mv_phone/tdm_if.h   |  116 +
 .../mv_drivers_lsp/mv_phone/test/Makefile          |   12 +
 .../mv_drivers_lsp/mv_phone/test/tdm_dev.c         |  367 ++
 .../mv_drivers_lsp/mv_phone/test/tdm_dev.h         |   87 +
 .../mv_drivers_lsp/mv_phone/vpapi_dev.c            | 1027 ++++
 .../mv_drivers_lsp/mv_phone/vpapi_dev.h            |  266 ++
 arch/arm/plat-armada/mv_drivers_lsp/mv_proc/proc.c |  533 +++
 .../arm/plat-armada/mv_drivers_lsp/mv_sata/Kconfig |   34 +
 .../plat-armada/mv_drivers_lsp/mv_sata/Makefile    |   19 +
 .../mv_drivers_lsp/mv_sata/mvIALCommon.c           | 2621 ++++++++++
 .../mv_drivers_lsp/mv_sata/mvIALCommon.h           |  195 +
 .../mv_drivers_lsp/mv_sata/mvIALCommonUtils.c      | 1274 +++++
 .../mv_drivers_lsp/mv_sata/mvIALCommonUtils.h      |  140 +
 .../mv_drivers_lsp/mv_sata/mvLinuxIalHt.c          | 2158 +++++++++
 .../mv_drivers_lsp/mv_sata/mvLinuxIalHt.h          |  264 ++
 .../mv_drivers_lsp/mv_sata/mvLinuxIalLib.c         | 1414 ++++++
 .../mv_drivers_lsp/mv_sata/mvLinuxIalLib.h         |  109 +
 .../mv_drivers_lsp/mv_sata/mvLinuxIalOs.c          |   55 +
 .../mv_drivers_lsp/mv_sata/mvLinuxIalSmart.c       |  428 ++
 .../mv_drivers_lsp/mv_sata/mvLinuxIalSmart.h       |  109 +
 .../mv_drivers_lsp/mv_sata/mvScsiAtaLayer.c        | 3553 ++++++++++++++
 .../mv_drivers_lsp/mv_sata/mvScsiAtaLayer.h        |  402 ++
 .../arm/plat-armada/mv_drivers_lsp/mv_sdio/Kconfig |   14 +
 .../plat-armada/mv_drivers_lsp/mv_sdio/Makefile    |   12 +
 .../plat-armada/mv_drivers_lsp/mv_sdio/mvsdmmc.c   | 1615 +++++++
 .../plat-armada/mv_drivers_lsp/mv_sdio/mvsdmmc.h   |  199 +
 .../plat-armada/mv_drivers_lsp/mv_switch/Makefile  |   12 +
 .../mv_drivers_lsp/mv_switch/mv_switch.c           | 1374 ++++++
 .../mv_drivers_lsp/mv_switch/mv_switch.h           |   68 +
 .../mv_drivers_lsp/mv_switch/mv_switch_sysfs.c     |  205 +
 arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/Kconfig |   63 +
 .../arm/plat-armada/mv_drivers_lsp/mv_tsu/Makefile |   10 +
 .../arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu.c | 1552 ++++++
 .../arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu.h |   49 +
 .../mv_drivers_lsp/mv_tsu/mv_tsu_ioctl.h           |   79 +
 .../arm/plat-armada/mv_drivers_lsp/mv_udc/Makefile |   25 +
 arch/arm/plat-armada/mv_drivers_lsp/mv_udc/README  |   86 +
 .../mv_drivers_lsp/mv_udc/mv_udc_main.c            | 2025 ++++++++
 arch/arm/plat-armada/mv_drivers_lsp/mv_xor/Kconfig |   87 +
 .../arm/plat-armada/mv_drivers_lsp/mv_xor/Makefile |   12 +
 .../plat-armada/mv_drivers_lsp/mv_xor/mv_netdma.c  | 1619 +++++++
 arch/arm/plat-armada/pmu.c                         |   32 +
 arch/arm/plat-armada/power.c                       |  286 ++
 arch/arm/plat-armada/power.h                       |   22 +
 237 files changed, 82795 insertions(+), 7 deletions(-)
 create mode 100644 arch/arm/kernel/perf_event_pj4b.c
 create mode 100644 arch/arm/mach-armadaxp/Kconfig
 create mode 100644 arch/arm/mach-armadaxp/Makefile
 create mode 100644 arch/arm/mach-armadaxp/Makefile.boot
 create mode 100644 arch/arm/mach-armadaxp/clcd.c
 create mode 100644 arch/arm/mach-armadaxp/clock.c
 create mode 100644 arch/arm/mach-armadaxp/clock.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvRules.mk
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysCesaConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysCntmrConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysDdrConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysEthConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysEthPhyConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysGppConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysHwConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysNfcConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysPciConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysPexConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysPonConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysRtcConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysSataConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysSdmmcConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysSpiConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysTdmConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysTsConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysTwsiConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysUsbConfig.h
 create mode 100644 arch/arm/mach-armadaxp/config/mvSysXorConfig.h
 create mode 100644 arch/arm/mach-armadaxp/core.c
 create mode 100644 arch/arm/mach-armadaxp/dbg-trace.c
 create mode 100644 arch/arm/mach-armadaxp/dbg-trace.h
 create mode 100644 arch/arm/mach-armadaxp/dump_cp15_regs.c
 create mode 100644 arch/arm/mach-armadaxp/export.c
 create mode 100644 arch/arm/mach-armadaxp/flashmap.c
 create mode 100644 arch/arm/mach-armadaxp/headsmp.S
 create mode 100644 arch/arm/mach-armadaxp/hwmon.c
 create mode 100644 arch/arm/mach-armadaxp/include/mach/armadaxp.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/clkdev.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/debug-macro.S
 create mode 100644 arch/arm/mach-armadaxp/include/mach/dma.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/dove_bl.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/entry-macro.S
 create mode 100644 arch/arm/mach-armadaxp/include/mach/gpio.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/hardware.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/ide.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/io.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/irqs.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/kw_macro.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/memory.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/param.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/serial.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/smp.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/system.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/timex.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/uncompress.h
 create mode 100644 arch/arm/mach-armadaxp/include/mach/vmalloc.h
 create mode 100644 arch/arm/mach-armadaxp/irq.c
 create mode 100644 arch/arm/mach-armadaxp/leds.c
 create mode 100644 arch/arm/mach-armadaxp/mpp.h
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysCesa.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysCesaApi.h
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysDdr.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysEth.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysEthApi.h
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysEthPhy.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysEthPhyApi.h
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysNeta.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysNetaApi.h
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysPci.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysPci.h
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysPex.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysPexApi.h
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysSFlash.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysSata.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysSataApi.h
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysSpi.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysSpiApi.h
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysTdm.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysTdmApi.h
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysTs.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysTsApi.h
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysUsb.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysUsbApi.h
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysXor.c
 create mode 100644 arch/arm/mach-armadaxp/mv_hal_if/mvSysXorApi.h
 create mode 100644 arch/arm/mach-armadaxp/pci.c
 create mode 100644 arch/arm/mach-armadaxp/pex.c
 create mode 100644 arch/arm/mach-armadaxp/platsmp.c
 create mode 100644 arch/arm/mach-armadaxp/pm.c
 create mode 100644 arch/arm/mach-armadaxp/proc_aurora_dbg.c
 create mode 100644 arch/arm/mach-armadaxp/sysmap.c
 create mode 100644 arch/arm/mach-armadaxp/time.c
 create mode 100644 arch/arm/mach-armadaxp/usb.c
 create mode 100644 arch/arm/mm/cache-aurora-l2.c
 create mode 100644 arch/arm/mm/proc-sheeva_pj4bv6.S
 create mode 100644 arch/arm/mm/proc-sheeva_pj4bv7.S
 create mode 100644 arch/arm/mm/sheeva_pj4b-macros.S
 create mode 100644 arch/arm/plat-armada/Kconfig
 create mode 100644 arch/arm/plat-armada/Makefile
 create mode 100644 arch/arm/plat-armada/armadaxp_suspend.S
 create mode 100644 arch/arm/plat-armada/cpuidle.c
 create mode 100644 arch/arm/plat-armada/hotplug.c
 create mode 100644 arch/arm/plat-armada/include/plat/cache-aurora-l2.h
 create mode 100644 arch/arm/plat-armada/include/plat/gpio.h
 create mode 100644 arch/arm/plat-armada/include/plat/i2s-orion.h
 create mode 100644 arch/arm/plat-armada/include/plat/msi.h
 create mode 100644 arch/arm/plat-armada/include/plat/mv_xor.h
 create mode 100644 arch/arm/plat-armada/include/plat/mvsdio.h
 create mode 100644 arch/arm/plat-armada/include/plat/orion_wdt.h
 create mode 100644 arch/arm/plat-armada/include/plat/xor.h
 create mode 100644 arch/arm/plat-armada/linux_oss/mvOs.c
 create mode 100644 arch/arm/plat-armada/linux_oss/mvOs.h
 create mode 100644 arch/arm/plat-armada/linux_oss/mvOsSata.h
 create mode 100644 arch/arm/plat-armada/msi.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_audio/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_audio/cs42l51-hal.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_audio/mv88fx-hal.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_audio/mv88fx-pcm.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_audio/mv88fx-pcm.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-i2s.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-i2s.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-pcm.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-pcm.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-rt5623.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_btns/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_btns/btns_driver.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_btns/btns_driver.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Kconfig
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_dev.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_dev.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_if.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_if.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_ocf_drv.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_test.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_dma/Kconfig
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_dma/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_dma/mv_dma.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_gpio/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_gpio/mv_gpio.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/mflash.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_lnc.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_lnc.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_nfc.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_nfc.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/sflash.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/Kconfig
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/bm/bm_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/hwf/hwf_bm.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/hwf/hwf_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/l2fw_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_proc.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_proc.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_switch.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_tool.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_tool.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_ethernet.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_pon_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/pmt/pmt_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/pnc/pnc_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/pnc/wol_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/Kconfig
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_proc.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_proc.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_tool.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_tool.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_ethernet.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_gateway.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_gtw_igmp.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_mgr.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_mgr.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_sec.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_phone/Kconfig
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_phone/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tal.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tal.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tdm_if.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tdm_if.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_phone/test/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_phone/test/tdm_dev.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_phone/test/tdm_dev.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_phone/vpapi_dev.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_phone/vpapi_dev.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_proc/proc.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/Kconfig
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommon.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommon.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommonUtils.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommonUtils.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalHt.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalHt.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalLib.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalLib.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalOs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalSmart.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalSmart.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvScsiAtaLayer.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvScsiAtaLayer.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/Kconfig
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/mvsdmmc.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/mvsdmmc.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_switch/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_switch/mv_switch.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_switch/mv_switch.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_switch/mv_switch_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/Kconfig
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu_ioctl.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_udc/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_udc/README
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_udc/mv_udc_main.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_xor/Kconfig
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_xor/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_xor/mv_netdma.c
 create mode 100644 arch/arm/plat-armada/pmu.c
 create mode 100644 arch/arm/plat-armada/power.c
 create mode 100644 arch/arm/plat-armada/power.h

diff --git a/arch/arm/kernel/Makefile b/arch/arm/kernel/Makefile
index 22b0f1e..f87808c 100644
--- a/arch/arm/kernel/Makefile
+++ b/arch/arm/kernel/Makefile
@@ -15,6 +15,8 @@ CFLAGS_REMOVE_return_address.o = -pg
 
 # Object file lists.
 
+include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+
 obj-y		:= elf.o entry-armv.o entry-common.o irq.o opcodes.o \
 		   process.o ptrace.o return_address.o sched_clock.o \
 		   setup.o signal.o stacktrace.o sys_arm.o time.o traps.o
diff --git a/arch/arm/kernel/perf_event_pj4b.c b/arch/arm/kernel/perf_event_pj4b.c
new file mode 100644
index 0000000..8f92487
--- /dev/null
+++ b/arch/arm/kernel/perf_event_pj4b.c
@@ -0,0 +1,606 @@
+/*
+ * Marvell Sheeva PJ4B CPU support
+ */
+
+#ifdef CONFIG_ARCH_ARMADA_XP 
+
+#define	MRVL_PJ4B_PMU_ENABLE	0x001	/* Enable counters */
+#define MRVL_PJ4B_PMN_RESET	0x002	/* Reset event counters */
+#define	MRVL_PJ4B_CCNT_RESET	0x004	/* Reset cycles counter */
+#define	MRVL_PJ4B_PMU_RESET	(MRVL_PJ4B_CCNT_RESET | MRVL_PJ4B_PMN_RESET)
+#define MRVL_PJ4B_PMU_CNT64	0x008	/* Make CCNT count every 64th cycle */
+
+
+
+
+#define PJ4BV7_PMNC_P		(1 << 1) /* Reset all counters */
+#define PJ4BV7_PMNC_C		(1 << 2) /* Cycle counter reset */
+
+/*
+* Different types of events that can be counted by the Marvell PJ4 Performance Monitor
+* 
+*/
+enum mrvl_pj4b_perf_types  {
+	MRVL_PJ4B_SOFTWARE_INCR = 0x00,	/* software increment */
+	MRVL_PJ4B_IFU_IFETCH_REFILL = 0x01,	/* instruction fetch that cause a refill at the lowest level of instruction or unified cache */
+	MRVL_PJ4B_IF_TLB_REFILL = 0x02,	/* instruction fetch that cause a TLB refill at the lowest level of TLB */
+	MRVL_PJ4B_DATA_RW_CACHE_REFILL = 0x03,	/* data read or write operation that causes a refill of at the lowest level of data or unified cache */
+	MRVL_PJ4B_DATA_RW_CACHE_ACCESS = 0x04,	/* data read or write operation that causes a cache access at the lowest level of data or unified cache */
+	MRVL_PJ4B_DATA_RW_TLB_REFILL = 0x05,	/* data read or write operation that causes a TLB refill at the lowest level of TLB */
+	MRVL_PJ4B_DATA_READ_INST_EXEC = 0x06,	/* data read architecturally executed */
+	MRVL_PJ4B_DATA_WRIT_INST_EXEC = 0x07,	/* data write architecturally executed */
+	MRVL_PJ4B_INSN_EXECUTED = 0x08,	/* instruction architecturally executed */
+	MRVL_PJ4B_EXCEPTION_TAKEN = 0x09,	/* exception taken */
+	MRVL_PJ4B_EXCEPTION_RETURN = 0x0a,	/* exception return architecturally executed */
+	MRVL_PJ4B_INSN_WR_CONTEXTIDR = 0x0b,	/* instruction that writes to the Context ID Register architecturally executed */
+	MRVL_PJ4B_SW_CHANGE_PC = 0x0c,	/* software change of PC, except by an exception, architecturally executed */
+	MRVL_PJ4B_BR_EXECUTED = 0x0d,	/* immediate branch architecturally executed, taken or not taken */
+	MRVL_PJ4B_PROCEDURE_RETURN = 0x0e,	/* procedure return architecturally executed */
+	MRVL_PJ4B_UNALIGNED_ACCESS = 0x0f,	/* unaligned access architecturally executed */
+	MRVL_PJ4B_BR_INST_MISS_PRED = 0x10,	/* branch mispredicted or not predicted */
+	MRVL_PJ4B_CYCLE_COUNT = 0x11,	/* cycle count */
+	MRVL_PJ4B_BR_PRED_TAKEN = 0x12,	/* branches or other change in the program flow that could have been predicted by the branch prediction resources of the processor */
+	MRVL_PJ4B_DCACHE_READ_HIT = 0x40,	/* counts the number of Data Cache read hits */
+	MRVL_PJ4B_DCACHE_READ_MISS = 0x41,	/* connts the number of Data Cache read misses */
+	MRVL_PJ4B_DCACHE_WRITE_HIT = 0x42,	/* counts the number of Data Cache write hits */
+	MRVL_PJ4B_DCACHE_WRITE_MISS = 0x43,	/* counts the number of Data Cache write misses */
+	MRVL_PJ4B_MMU_BUS_REQUEST = 0x44,	/* counts the number of cycles of request to the MMU Bus */
+	MRVL_PJ4B_ICACHE_BUS_REQUEST = 0x45,	/* counts the number of cycles the Instruction Cache requests the bus until the data return */
+	MRVL_PJ4B_WB_WRITE_LATENCY = 0x46,	/* counts the number of cycles the Write Buffer requests the bus */
+	MRVL_PJ4B_HOLD_LDM_STM = 0x47,	/* counts the number of cycles the pipeline is held because of a load/store multiple instruction */
+	MRVL_PJ4B_NO_DUAL_CFLAG = 0x48,	/* counts the number of cycles the processor cannot dual issue because of a Carry flag dependency */
+	MRVL_PJ4B_NO_DUAL_REGISTER_PLUS = 0x49,	/* counts the number of cycles the processor cannot dual issue because the register file does not have enough read ports and at least one other reason */
+	MRVL_PJ4B_LDST_ROB0_ON_HOLD = 0x4a,	/* counts the number of cycles a load or store instruction waits to retire from ROB0 */
+	MRVL_PJ4B_LDST_ROB1_ON_HOLD = 0x4b,	/* counts the number of cycles a load or store instruction waits to retire from ROB0=1 */
+	MRVL_PJ4B_DATA_WRITE_ACCESS_COUNT = 0x4c, 	/* counts the number of any Data write access */
+	MRVL_PJ4B_DATA_READ_ACCESS_COUNT = 0x4d, 	/* counts the number of any Data read access */
+	MRVL_PJ4B_A2_STALL = 0x4e, 	/* counts the number of cycles ALU A2 is stalled */
+	/*TODO: implement with fabric counters*/
+	MRVL_PJ4B_L2C_WRITE_HIT = 0x4f, 	/* counts the number of write accesses to addresses already in the L2C */
+	MRVL_PJ4B_L2C_WRITE_MISS = 0x50,	/* counts the number of write accesses to addresses not in the L2C */
+	MRVL_PJ4B_L2C_READ_COUNT = 0x51,	/* counts the number of L2C cache-to-bus external read request */
+	/*TODO: end*/
+	MRVL_PJ4B_ICACHE_READ_MISS = 0x60, 	/* counts the number of Instruction Cache read misses */
+	MRVL_PJ4B_ITLB_MISS = 0x61, 	/* counts the number of instruction TLB miss */
+	MRVL_PJ4B_SINGLE_ISSUE = 0x62, 	/* counts the number of cycles the processor single issues */
+	MRVL_PJ4B_BR_RETIRED = 0x63, 	/* counts the number of times one branch retires */
+	MRVL_PJ4B_ROB_FULL = 0x64, 	/* counts the number of cycles the Re-order Buffer (ROB) is full */
+	MRVL_PJ4B_MMU_READ_BEAT = 0x65, 	/* counts the number of times the bus returns RDY to the MMU */
+	MRVL_PJ4B_WB_WRITE_BEAT = 0x66, 	/* counts the number times the bus returns ready to the Write Buffer */
+	MRVL_PJ4B_DUAL_ISSUE = 0x67, 	/* counts the number of cycles the processor dual issues */
+	MRVL_PJ4B_NO_DUAL_RAW = 0x68, 	/* counts the number of cycles the processor cannot dual issue because of a Read after Write hazard */
+	MRVL_PJ4B_HOLD_IS = 0x69, 	/* counts the number of cycles the issue is held */
+	/*TODO: implement with fabric counters*/
+	MRVL_PJ4B_L2C_LATENCY = 0x6a, 	/* counts the latency for the most recent L2C read from the external bus Counts cycles */
+	/*TODO: end*/
+	MRVL_PJ4B_DCACHE_ACCESS = 0x70, 	/* counts the number of times the Data cache is accessed */
+	MRVL_PJ4B_DTLB_MISS = 0x71, 	/* counts the number of data TLB misses */
+	MRVL_PJ4B_BR_PRED_MISS = 0x72, 	/* counts the number of mispredicted branches */
+	MRVL_PJ4B_A1_STALL = 0x74, 	/* counts the number of cycles ALU A1 is stalled */
+	MRVL_PJ4B_DCACHE_READ_LATENCY = 0x75, 	/* counts the number of cycles the Data cache requests the bus for a read */
+	MRVL_PJ4B_DCACHE_WRITE_LATENCY = 0x76, 	/* counts the number of cycles the Data cache requests the bus for a write */
+	MRVL_PJ4B_NO_DUAL_REGISTER_FILE = 0x77, 	/* counts the number of cycles the processor cannot dual issue because the register file doesn't have enough read ports */
+	MRVL_PJ4B_BIU_SIMULTANEOUS_ACCESS = 0x78, 	/* BIU Simultaneous Access */
+	MRVL_PJ4B_L2C_READ_HIT = 0x79, 	/* counts the number of L2C cache-to-bus external read requests */
+	MRVL_PJ4B_L2C_READ_MISS = 0x7a, 	/* counts the number of L2C read accesses that resulted in an external read request */
+	MRVL_PJ4B_L2C_EVICTION = 0x7b, 	/* counts the number of evictions (CastOUT) of a line from the L2 cache */
+	MRVL_PJ4B_TLB_MISS = 0x80, 	/* counts the number of instruction and data TLB misses */
+	MRVL_PJ4B_BR_TAKEN = 0x81, 	/* counts the number of taken branches */
+	MRVL_PJ4B_WB_FULL = 0x82, 	/* counts the number of cycles WB is full */
+	MRVL_PJ4B_DCACHE_READ_BEAT = 0x83, 	/* counts the number of times the bus returns Data to the Data cache during read request */
+	MRVL_PJ4B_DCACHE_WRITE_BEAT = 0x84, 	/* counts the number of times the bus returns ready to the Data cache during write request */
+	MRVL_PJ4B_NO_DUAL_HW = 0x85, 	/* counts the number of cycles the processor cannot dual issue because of hardware conflict */
+	MRVL_PJ4B_NO_DUAL_MULTIPLE = 0x86, 	/* counts the number of cycles the processor cannot dual issue because of multiple reasons */
+	MRVL_PJ4B_BIU_ANY_ACCESS = 0x87, 	/* counts the number of cycles the BIU is accessed by any unit */
+	MRVL_PJ4B_MAIN_TLB_REFILL_BY_ICACHE = 0x88, 	/* counts the number of instruction fetch operations that causes a Main TLB walk */
+	MRVL_PJ4B_MAIN_TLB_REFILL_BY_DCACHE = 0x89, 	/* counts the number of Data read or write operations that causes a Main TLB walk */
+	MRVL_PJ4B_ICACHE_READ_BEAT = 0x8a, 	/* counts the number of times the bus returns RDY to the instruction cache */
+	MRVL_PJ4B_PMUEXT_IN0 = 0x90, 	/* counts any event from external input source PMUEXTIN[0] */
+	MRVL_PJ4B_PMUEXT_IN1 = 0x91, 	/* counts any event from external input source PMUEXTIN[1] */
+	MRVL_PJ4B_PMUEXT_IN0_IN1 = 0x92, 	/* counts any event from both external input sources PMUEXTIN[0] and PMUEXTIN[1] */
+	MRVL_PJ4B_WMMX2_STORE_FIFO_FULL = 0xc0, 	/* counts the number of cycles when the WMMX2 store FIFO is full */
+	MRVL_PJ4B_WMMX2_FINISH_FIFO_FULL = 0xc1, 	/* counts the number of cycles when the WMMX2 finish FIFO is full */
+	MRVL_PJ4B_WMMX2_INST_FIFO_FULL = 0xc2, 	/* counts the number of cycles when the WMMX2 instruction FIFO is full */
+	MRVL_PJ4B_WMMX2_INST_RETIRED = 0xc3, 	/* counts the number of retired WMMX2 instructions */
+	MRVL_PJ4B_WMMX2_BUSY = 0xc4, 	/* counts the number of cycles when the WMMX2 is busy */
+	MRVL_PJ4B_WMMX2_HOLD_MI = 0xc5, 	/* counts the number of cycles when WMMX2 holds the issue stage */
+	MRVL_PJ4B_WMMX2_HOLD_MW = 0xc6, 	/* counts the number of cycles when WMMX2 holds the write back stage */
+	/* EVT_CCNT is not hardware defined */
+	MRVL_PJ4B_EVT_CCNT = 0xFE,		/* CPU_CYCLE */
+	MRVL_PJ4B_EVT_UNUSED = 0xFF, 
+};
+
+enum  pj4b_pmu_counters {MRVL_PJ4B_CCNT=0, 
+						MRVL_PJ4B_PMN0, 
+						MRVL_PJ4B_PMN1, 
+						MRVL_PJ4B_PMN2, 
+						MRVL_PJ4B_PMN3, 
+						MRVL_PJ4B_PMN4, 
+						MRVL_PJ4B_PMN5, 
+						MRVL_PJ4B_MAX_COUNTERS};
+
+#define MRVL_PJ4B_CCNT_BIT_OFFSET 	31
+#define MRVL_PJ4B_PMN_BIT_OFFSET 	0
+
+#define MRVL_PJ4B_ALL_CNTRS			(0x8000003F)
+
+/*
+ * The hardware events that we support. We do support cache operations but
+ * we have harvard caches and no way to combine instruction and data
+ * accesses/misses in hardware.
+ */
+static const unsigned mrvl_pj4b_perf_map[PERF_COUNT_HW_MAX] = {
+	[PERF_COUNT_HW_CPU_CYCLES]	    = MRVL_PJ4B_EVT_CCNT,
+	[PERF_COUNT_HW_INSTRUCTIONS]	    = MRVL_PJ4B_INSN_EXECUTED,
+	[PERF_COUNT_HW_CACHE_REFERENCES]    = HW_OP_UNSUPPORTED,
+	[PERF_COUNT_HW_CACHE_MISSES]	    = HW_OP_UNSUPPORTED,
+	[PERF_COUNT_HW_BRANCH_INSTRUCTIONS] = MRVL_PJ4B_BR_RETIRED,
+	[PERF_COUNT_HW_BRANCH_MISSES]	    = MRVL_PJ4B_BR_PRED_MISS,
+	[PERF_COUNT_HW_BUS_CYCLES]	    = HW_OP_UNSUPPORTED,
+};
+
+static const unsigned mrvl_pj4b_perf_cache_map[PERF_COUNT_HW_CACHE_MAX]
+					[PERF_COUNT_HW_CACHE_OP_MAX]
+					[PERF_COUNT_HW_CACHE_RESULT_MAX] = {
+	[C(L1D)] = {
+		[C(OP_READ)] = {
+			[C(RESULT_ACCESS)]  = MRVL_PJ4B_DCACHE_ACCESS,
+			[C(RESULT_MISS)]    = MRVL_PJ4B_DCACHE_READ_MISS,
+		},
+		[C(OP_WRITE)] = {
+			[C(RESULT_ACCESS)]  = MRVL_PJ4B_DCACHE_ACCESS,
+			[C(RESULT_MISS)]    = MRVL_PJ4B_DCACHE_WRITE_MISS,
+		},
+		[C(OP_PREFETCH)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = CACHE_OP_UNSUPPORTED,
+		},
+	},
+	[C(L1I)] = {
+		[C(OP_READ)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = MRVL_PJ4B_ICACHE_READ_MISS,
+		},
+		[C(OP_WRITE)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = CACHE_OP_UNSUPPORTED,
+		},
+		[C(OP_PREFETCH)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = CACHE_OP_UNSUPPORTED,
+		},
+	},
+	/*TODO add L2 counters*/
+	[C(LL)] = {
+		[C(OP_READ)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = CACHE_OP_UNSUPPORTED,
+		},
+		[C(OP_WRITE)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = CACHE_OP_UNSUPPORTED,
+		},
+		[C(OP_PREFETCH)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = CACHE_OP_UNSUPPORTED,
+		},
+	},
+	[C(DTLB)] = {
+		/*
+		 * The ARM performance counters can count micro DTLB misses,
+		 * micro ITLB misses and main TLB misses. There isn't an event
+		 * for TLB misses, so use the micro misses here and if users
+		 * want the main TLB misses they can use a raw counter.
+		 */
+		[C(OP_READ)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = MRVL_PJ4B_DTLB_MISS,
+		},
+		[C(OP_WRITE)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = MRVL_PJ4B_DTLB_MISS,
+		},
+		[C(OP_PREFETCH)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = CACHE_OP_UNSUPPORTED,
+		},
+	},
+	[C(ITLB)] = {
+		[C(OP_READ)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = MRVL_PJ4B_ITLB_MISS,
+		},
+		[C(OP_WRITE)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = MRVL_PJ4B_ITLB_MISS,
+		},
+		[C(OP_PREFETCH)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = CACHE_OP_UNSUPPORTED,
+		},
+	},
+	[C(BPU)] = {
+		[C(OP_READ)] = {
+			[C(RESULT_ACCESS)]  = MRVL_PJ4B_BR_RETIRED,
+			[C(RESULT_MISS)]    = MRVL_PJ4B_BR_PRED_MISS,
+		},
+		[C(OP_WRITE)] = {
+			[C(RESULT_ACCESS)]  = MRVL_PJ4B_BR_RETIRED,
+			[C(RESULT_MISS)]    = MRVL_PJ4B_BR_PRED_MISS,
+		},
+		[C(OP_PREFETCH)] = {
+			[C(RESULT_ACCESS)]  = CACHE_OP_UNSUPPORTED,
+			[C(RESULT_MISS)]    = CACHE_OP_UNSUPPORTED,
+		},
+	},
+};
+
+/*Helper functions*/
+static inline void mrvl_pj4b_pmu_cntr_disable(u32 val)
+{
+	asm volatile("mcr p15, 0, %0, c9, c14, 2" : : "r"(val));
+	asm volatile("mcr p15, 0, %0, c9, c12, 2" : : "r"(val));	
+}
+
+static inline void mrvl_pj4b_pmu_cntr_enable(u32 val)
+{
+	asm volatile("mcr p15, 0, %0, c9, c12, 1" : : "r"(val));	
+	asm volatile("mcr p15, 0, %0, c9, c14, 1" : : "r"(val));
+}
+
+static inline void mrvl_pj4b_pmu_select_event(u32 cntr, u32 evt)
+{
+	asm volatile("mcr p15, 0, %0, c9, c12, 5" : : "r"(cntr));
+	asm volatile("mcr p15, 0, %0, c9, c13, 1" : : "r"(evt));
+}
+
+static inline void mrvl_pj4b_pmu_clear_events(u32 val)
+{
+	asm volatile("mcr p15, 0, %0, c9, c12, 2" : : "r"(val));	
+}
+
+static inline void mrvl_pj4b_pmu_enable_events(u32 val)
+{
+	asm volatile("mcr p15, 0, %0, c9, c12, 1": : "r"(val));
+}
+
+static inline u32 mrvl_pj4b_pmu_read_events(void)
+{
+	u32 val;
+	asm volatile("mcr p15, 0, %0, c9, c12, 1": "=r"(val));
+	return val;
+}
+
+
+static inline void mrvl_pj4b_write_pmnc(u32 val)
+{
+	asm volatile("mcr p15, 0, %0, c9, c12, 0": : "r"(val));
+} 
+
+static inline u32 mrvl_pj4b_read_pmnc(void)
+{
+	u32 val;
+
+	asm volatile("mrc p15, 0, %0, c9, c12, 0" : "=r"(val));
+
+	return val;
+}
+
+static inline void mrvl_pj4b_pmu_clear_overflow(u32 val)
+{
+	/* writeback clears overflow bits */
+	asm volatile("mcr p15, 0, %0, c9, c12, 3": : "r"(val));
+}
+
+static inline int mrvl_pj4b_pmu_counter_has_overflowed(unsigned long val,
+				  enum pj4b_pmu_counters counter)
+{
+	int ret = 0;
+	
+	if (counter == MRVL_PJ4B_CCNT)
+		ret = (val & (1 << MRVL_PJ4B_CCNT_BIT_OFFSET));
+	else if (counter < MRVL_PJ4B_MAX_COUNTERS)
+		ret = (val & (1 << (counter-MRVL_PJ4B_PMN0)));
+	else
+		WARN_ONCE(1, "invalid counter number (%d)\n", counter);
+
+	return ret;
+
+}
+
+static inline u32 mrvl_pj4b_pmu_read_overflow(void)
+{
+	u32 val;
+	/* check counter */
+	asm volatile("mrc p15, 0, %0, c9, c12, 3" : "=r"(val));
+	return val;
+}
+
+
+/*API functions*/
+static u32 mrvl_pj4b_pmu_read_counter(int counter)
+{
+	u32 val = 0;
+	
+	switch (counter) {
+	case MRVL_PJ4B_CCNT:
+		asm volatile("mrc p15, 0, %0, c9, c13, 0" : "=r" (val));		
+		break;
+	case MRVL_PJ4B_PMN0:
+	case MRVL_PJ4B_PMN1:
+	case MRVL_PJ4B_PMN2:
+	case MRVL_PJ4B_PMN3:
+	case MRVL_PJ4B_PMN4:
+	case MRVL_PJ4B_PMN5:
+		asm volatile("mcr p15, 0, %0, c9, c12, 5": : "r"(counter - MRVL_PJ4B_PMN0));
+		asm volatile("mrc p15, 0, %0, c9, c13, 2" : "=r"(val));
+		break;
+ 	}	
+	return val;
+} 
+
+static void mrvl_pj4b_pmu_write_counter(int counter, u32 val)
+{
+	switch (counter) {
+	case MRVL_PJ4B_CCNT:
+		asm volatile("mcr p15, 0, %0, c9, c13, 0" : : "r" (val));
+		break;
+	case MRVL_PJ4B_PMN0:
+	case MRVL_PJ4B_PMN1:
+	case MRVL_PJ4B_PMN2:
+	case MRVL_PJ4B_PMN3:
+	case MRVL_PJ4B_PMN4:
+	case MRVL_PJ4B_PMN5:
+		asm volatile("mcr p15, 0, %0, c9, c12, 5": : "r"(counter - MRVL_PJ4B_PMN0));
+		asm volatile("mcr p15, 0, %0, c9, c13, 2": : "r"(val));
+		break;
+	}
+}
+
+
+static u64 mrvl_pj4b_pmu_raw_event(u64 config)
+{
+	return config & 0xff;
+}
+
+static inline int mrvl_pj4b_pmu_event_map(int config)
+{
+	int mapping = mrvl_pj4b_perf_map[config];
+	if (HW_OP_UNSUPPORTED == mapping)
+		mapping = -EOPNOTSUPP;
+	return mapping;
+}
+
+static int mrvl_pj4b_pmu_get_event_idx(struct cpu_hw_events *cpuc,
+				  struct hw_perf_event *event)
+{
+	int idx;
+	/* Always place a cycle counter into the cycle counter. */
+	if (event->config_base == MRVL_PJ4B_EVT_CCNT) {		
+		if (test_and_set_bit(MRVL_PJ4B_CCNT, cpuc->used_mask)) {		
+			return -EAGAIN;
+		}
+		return MRVL_PJ4B_CCNT;
+	} else {
+		/*
+		 * For anything other than a cycle counter, try and use
+		 * the events counters
+		 */
+		for (idx = MRVL_PJ4B_PMN0; idx < armpmu->num_events; ++idx) {
+			if (!test_and_set_bit(idx, cpuc->used_mask)) {			
+				return idx;
+			}
+		}
+		/* The counters are all in use. */
+		return -EAGAIN;
+	}	
+}
+
+void mrvl_pj4b_pmu_enable_event(struct hw_perf_event *hwc, int idx)
+{
+	u32 enable;
+	unsigned long flags;
+	raw_spin_lock_irqsave(&pmu_lock, flags);
+	if (idx == MRVL_PJ4B_CCNT) {	
+		enable = (1 << MRVL_PJ4B_CCNT_BIT_OFFSET);
+	} 
+	else if (idx < MRVL_PJ4B_MAX_COUNTERS) {
+		enable   = (1 << (idx - MRVL_PJ4B_PMN0));
+	} 
+	else {
+		WARN_ONCE(1, "invalid counter number (%d)\n", idx);
+		return;
+	}
+	mrvl_pj4b_pmu_cntr_disable(enable);
+	/*select event*/
+	if (idx != MRVL_PJ4B_CCNT) {		
+		/*select event*/
+		u32 evt = (hwc->config_base & 0xFF);		
+		mrvl_pj4b_pmu_select_event((idx-MRVL_PJ4B_PMN0), evt);
+	}	
+	mrvl_pj4b_pmu_cntr_enable(enable);
+	raw_spin_unlock_irqrestore(&pmu_lock, flags);	
+}
+
+
+void mrvl_pj4b_pmu_disable_event(struct hw_perf_event *hwc, int idx)
+{
+	u32 enable;
+	unsigned long flags;
+	raw_spin_lock_irqsave(&pmu_lock, flags);
+	if (idx == MRVL_PJ4B_CCNT) {	
+		enable = (1 << MRVL_PJ4B_CCNT_BIT_OFFSET);
+	} 
+	else if (idx < MRVL_PJ4B_MAX_COUNTERS) {
+		enable   = (1 << (idx - MRVL_PJ4B_PMN0));
+	} 
+	else {
+		WARN_ONCE(1, "invalid counter number (%d)\n", idx);
+		return;
+	}	
+	mrvl_pj4b_pmu_cntr_disable(enable);
+	raw_spin_unlock_irqrestore(&pmu_lock, flags);
+}
+
+
+static irqreturn_t mrvl_pj4b_pmu_handle_irq(int irq, void *arg)
+{
+	int i = 0;
+	u32 flag;
+	struct pt_regs *regs;
+	struct perf_sample_data data;	
+	struct cpu_hw_events *cpuc;	
+	u32 pmnc;
+	pmnc = mrvl_pj4b_read_pmnc();	
+	pmnc &= ~MRVL_PJ4B_PMU_ENABLE;
+	mrvl_pj4b_write_pmnc(pmnc);	
+
+	flag = mrvl_pj4b_pmu_read_overflow();	
+	mrvl_pj4b_pmu_clear_overflow(flag);
+
+	/*
+	 * Did an overflow occur?
+	 */
+	if (!flag) {		
+		pmnc |= MRVL_PJ4B_PMU_ENABLE;
+		mrvl_pj4b_write_pmnc(pmnc);
+		return IRQ_NONE;
+	}	
+	/*
+	 * Handle the counter(s) overflow(s)
+	 */
+	regs = get_irq_regs();
+	perf_sample_data_init(&data, 0);
+
+	cpuc = &__get_cpu_var(cpu_hw_events);
+
+	for (i = MRVL_PJ4B_CCNT; i < armpmu->num_events; i++) {
+
+		struct perf_event *event = cpuc->events[i];
+		struct hw_perf_event *hwc;
+
+		if (!test_bit(i, cpuc->active_mask)) {
+			continue;
+		}
+		if (!mrvl_pj4b_pmu_counter_has_overflowed(flag, i)) {		
+			continue;
+		}
+
+		hwc = &event->hw;
+		armpmu_event_update(event, hwc, i,1);
+		data.period = event->hw.last_period;
+
+		if (!armpmu_event_set_period(event, hwc, i)) {		
+			continue;
+		}
+
+		if (perf_event_overflow(event, 0, &data, regs))
+			armpmu->disable(hwc, i);
+ 	}	
+	pmnc |= MRVL_PJ4B_PMU_ENABLE;
+	mrvl_pj4b_write_pmnc(pmnc);	
+	
+	/*
+	 * Handle the pending perf events.
+	 *
+	 * Note: this call *must* be run with interrupts enabled. For
+	 * platforms that can have the PMU interrupts raised as a PMI, this
+	 * will not work.
+	 */
+	//perf_event_do_pending();
+		irq_work_run();
+	
+	return IRQ_HANDLED;
+} 
+
+
+/*
+asmlinkage void __exception do_mrvl_pj4b_pmu_event(struct pt_regs *regs)
+{	
+	struct pt_regs *old_regs = set_irq_regs(regs);
+	int cpu = smp_processor_id();
+	irq_enter();
+	irq_stat[cpu].local_pmu_irqs++;
+	armpmu->handle_irq(IRQ_AURORA_MP, NULL);    
+	irq_exit();	 	
+	set_irq_regs(old_regs);
+}
+*/
+
+static void mrvl_pj4b_pmu_stop(void)
+{
+	u32 pmnc;
+	unsigned long flags;
+	raw_spin_lock_irqsave(&pmu_lock, flags);
+	pmnc = mrvl_pj4b_read_pmnc();
+	pmnc &= ~MRVL_PJ4B_PMU_ENABLE;
+	mrvl_pj4b_write_pmnc(pmnc);	
+	raw_spin_unlock_irqrestore(&pmu_lock, flags);
+} 
+
+
+static void mrvl_pj4b_pmu_start(void)
+{
+	u32 pmnc;
+	unsigned long flags;
+
+	raw_spin_lock_irqsave(&pmu_lock, flags);		
+	pmnc = mrvl_pj4b_read_pmnc();
+	pmnc |= (MRVL_PJ4B_PMU_ENABLE);
+	mrvl_pj4b_write_pmnc(pmnc);
+	raw_spin_unlock_irqrestore(&pmu_lock, flags);
+} 
+
+static u32 __init mrvl_pj4b_read_reset_pmnc(void)
+{
+	u32 pmnc = mrvl_pj4b_read_pmnc();
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_PMU_RESET
+	mrvl_pj4b_write_pmnc(pmnc); /* WA - need to write 0 to bit 2 before
+					write*/
+#endif
+	pmnc |= (MRVL_PJ4B_PMU_RESET);
+	mrvl_pj4b_write_pmnc(pmnc);
+	return ((pmnc >> 11) & 0x1F)+1;
+}
+
+static void mrvl_pj4b_pmu_reset(void *info)
+{
+	u32 idx, nb_cnt = armpmu->num_events;
+
+	/* The counter and interrupt enable registers are unknown at reset. */
+	for (idx = 1; idx < nb_cnt; ++idx)
+		mrvl_pj4b_pmu_disable_event(NULL, idx);
+
+	/* Initialize & Reset PMNC: C and P bits */
+	mrvl_pj4b_write_pmnc(PJ4BV7_PMNC_P | PJ4BV7_PMNC_C);
+	
+}
+
+
+static const struct arm_pmu mrvl_pj4b_pmu = {
+	
+	.id				= MRVL_PERF_PMU_ID_PJ4B,
+	.name			= "Armada PJ4",
+	.stop			= mrvl_pj4b_pmu_stop, /*v*/
+	.start			= mrvl_pj4b_pmu_start, /*v*/
+	.enable			= mrvl_pj4b_pmu_enable_event, /*v*/
+	.disable		= mrvl_pj4b_pmu_disable_event, /*v*/
+	.read_counter	= mrvl_pj4b_pmu_read_counter, /*v*/
+	.write_counter	= mrvl_pj4b_pmu_write_counter, /*v*/
+	.get_event_idx	= mrvl_pj4b_pmu_get_event_idx,/*v*/
+	.cache_map		= mrvl_pj4b_perf_cache_map,
+	.event_map		= mrvl_pj4b_pmu_event_map, /*v*/
+	.handle_irq		= mrvl_pj4b_pmu_handle_irq, /*v*/
+	.reset 			= mrvl_pj4b_pmu_reset,
+	/*.raw_event		= mrvl_pj4b_pmu_raw_event,*/
+	.raw_event_mask	= 0xFF,
+	.num_events		= MRVL_PJ4B_MAX_COUNTERS,
+	.max_period		= (1LLU << 32) - 1,
+};
+
+static const struct arm_pmu *__init mrvl_pj4b_pmu_init(void)
+{
+	return &mrvl_pj4b_pmu;
+}
+
+#endif /*#ifdef CONFIG_ARCH_ARMADA_XP*/
diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 66e638f..626c187 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -335,6 +335,15 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	current->active_mm = mm;
 	cpumask_set_cpu(cpu, mm_cpumask(mm));
 
+#ifdef CONFIG_MACH_ARMADA_XP_FPGA
+	unsigned int cpurev;
+	__asm__ __volatile__("mrc p15, 1, %0, c0, c0, 7   @ read CPU ID reg\n"
+		: "=r" (cpurev) :: "memory");
+	printk("CPU%u: FPGA Booted secondary processor (ID 0x%04x)\n", cpu, (cpurev & 0xFFFF));
+#else
+	printk("CPU%u: Booted secondary processor\n", cpu);
+#endif
+
 	printk("CPU%u: Booted secondary processor\n", cpu);
 
 	cpu_init();
diff --git a/arch/arm/mach-armadaxp/Kconfig b/arch/arm/mach-armadaxp/Kconfig
new file mode 100644
index 0000000..43bd7d3
--- /dev/null
+++ b/arch/arm/mach-armadaxp/Kconfig
@@ -0,0 +1,97 @@
+if ARCH_ARMADA_XP
+
+config  MV_HAL_RULES_PATH
+        string "path of the mvRules.mk file for HAL drivers"
+        default "arch/arm/mach-armadaxp/mv_hal_support/mvRules.mk"
+        ---help---
+	
+#source "arch/arm/plat-orion/mv_hal_drivers/Kconfig"
+
+menu "Marvell Armada Options"
+
+config ARMADA_XP
+	bool "Armada XP SoC Family"
+	default y
+
+choice
+	prompt "Armada XP Chip revision"
+	depends on ARMADA_XP
+	default ARMADA_XP_REV_Z1
+
+config  ARMADA_XP_REV_Z1
+	bool "MV88F78x30 and MV88F78x60 Z1 SoC devices"
+	select ARMADA_XP_ERRATA_SMI_1
+	select ARMADA_XP_DEEP_IDLE_L2_WA if CACHE_AURORA_L2
+	select ARMADA_XP_DEEP_IDLE_UNMASK_INTS_WA
+	select SHEEVA_ERRATA_ARM_CPU_4742
+	select SHEEVA_ERRATA_ARM_CPU_4786 if (ARM_THUMB && VFP)
+#	select SHEEVA_ERRATA_ARM_CPU_5315
+	select SHEEVA_ERRATA_ARM_CPU_4413
+	select SHEEVA_ERRATA_ARM_CPU_4659
+	select SHEEVA_ERRATA_ARM_CPU_5114 if (CPU_SHEEVA_PJ4B_V6 && AURORA_IO_CACHE_COHERENCY)
+	select SHEEVA_ERRATA_ARM_CPU_4611
+#	select SHEEVA_ERRATA_ARM_CPU_4948
+	select SHEEVA_ERRATA_ARM_CPU_PMU_RESET
+	select SHEEVA_ERRATA_ARM_CPU_BTS61 if (SMP || AURORA_IO_CACHE_COHERENCY)
+	---help---
+	Choosing this option will generate a linux kernel for the
+	  MV78x30 and MV78x60 devices with revision Z1
+
+config  KW40_REV_A0
+	bool "MV88F6710 A0 SoC devices"
+	select SHEEVA_ERRATA_ARM_CPU_5114 if (CPU_V6)
+	---help---
+	Choosing this option will generate a linux kernel for the
+	  MV88F6710 (KW40) devices with revision A0
+
+config  ARMADA_XP_REV_A0
+	bool "MV88F78x30 and MV88F78x60 A0 SoC devices"
+	---help---
+	Choosing this option will generate a linux kernel for the
+	  MV78x30 and MV78x60 devices with revision A0
+
+endchoice
+
+config MACH_ARMADA_XP_DB
+	bool "Marvell Armada XP Development Board"	
+	default y
+	help
+
+config MACH_ARMADA_XP_RDSRV
+	bool "Marvell Armada XP Server Board"
+	default y
+	help
+
+config MACH_ARMADA_XP_FPGA
+	bool "Marvell Armada XP FPGA Board"	
+	depends on !MACH_ARMADA_XP_DB && !MACH_ARMADA_XP_RDSRV
+	default y
+	help
+
+config CFU_DRAM_BYPASS
+        bool "Bypass CFU to DRAM via Punit"
+	default n
+	help
+
+config ARMADAXP_USE_IRQ_INDIRECT_MODE
+       bool "Use indirect mode for handling interrupt controller"
+       default n
+       help
+         This mode enables using indirect mode for handling interrupts, in this
+	 mode, the Interrupt Set Enable/Clear Enable registers are used for
+	 unmasking/masking shared interrupts, and Interrupt Set Mask/Clear Mask
+	 used for masking/unmasking per-cpu interrupts. Without this mode, the
+	 Interrupt Source register is used directly. and this requires the
+	 following:
+	 - Locking mechanism to protect the access to the Interrupt Source Register
+	 - Reads operation of those registers.
+	 - Using the affinity variable for restoring the mask values
+
+config ARMADAXP_USE_IRQ_INTERRUPT_ACK
+       bool "Use Interrupt Ack register to detect pending interrupts"
+       default n
+       help
+	 
+endmenu
+
+endif
diff --git a/arch/arm/mach-armadaxp/Makefile b/arch/arm/mach-armadaxp/Makefile
new file mode 100644
index 0000000..b40d163
--- /dev/null
+++ b/arch/arm/mach-armadaxp/Makefile
@@ -0,0 +1,156 @@
+#*******************************************************************************
+# Marvell GPL License Option
+#
+# If you received this File from Marvell, you may opt to use, redistribute and/or 
+# modify this File in accordance with the terms and conditions of the General 
+# Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+# available along with the File in the license.txt file or by writing to the Free 
+# Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+# on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+#
+# THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+# WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+# DISCLAIMED.  The GPL License provides additional details about this warranty 
+# disclaimer.
+#*******************************************************************************/
+include 	  $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+
+# Objects list
+COMMON_OBJS	= $(COMMON_DIR)/mvDebug.o $(COMMON_DIR)/mvCommon.o $(COMMON_DIR)/mvStack.o $(COMMON_DIR)/mvList.o
+
+OSSERVICES_OBJS	= $(OSSERV_DIR)/mvOs.o
+
+HAL_OBJS	= $(HAL_RTC_DIR)/mvRtc.o					\
+                  $(HAL_CNTMR_DIR)/mvCntmr.o					\
+		  $(HAL_TWSI_DIR)/mvTwsi.o					\
+                  $(HAL_UART_DIR)/mvUart.o $(HAL_GPP_DIR)/mvGpp.o               \
+                  $(HAL_DRAM_DIR)/mvDramIf.o					\
+		  $(HAL_IF_DIR)/mvSysDdr.o
+#		  $(HAL_DRAM_SPD_DIR)/mvSpd.o
+
+KW_FAM_OBJS	= $(BOARD_ENV_DIR)/mvBoardEnvSpec.o $(SOC_ENV_DIR)/mvCtrlEnvLib.o	\
+		  $(BOARD_ENV_DIR)/mvBoardEnvLib.o $(SOC_ENV_DIR)/mvCtrlEnvAddrDec.o 	\
+		  $(SOC_SYS_DIR)/mvAhbToMbus.o $(SOC_SYS_DIR)/mvCpuIf.o 		\
+		  $(SOC_CPU_DIR)/mvCpu.o $(SOC_DEVICE_DIR)/mvDevice.o
+                  
+QD_OBJS		= $(HAL_QD_DIR)/src/driver/gtDrvConfig.o $(HAL_QD_DIR)/src/driver/gtDrvEvents.o \
+                  $(HAL_QD_DIR)/src/driver/gtHwCntl.o $(HAL_QD_DIR)/src/platform/gtMiiSmiIf.o	\
+                  $(HAL_QD_DIR)/src/platform/platformDeps.o $(HAL_QD_DIR)/src/platform/gtSem.o	\
+                  $(HAL_QD_DIR)/src/platform/gtDebug.o $(HAL_QD_DIR)/src/msapi/gtBrgFdb.o 	\
+                  $(HAL_QD_DIR)/src/msapi/gtBrgStp.o $(HAL_QD_DIR)/src/msapi/gtBrgVlan.o 	\
+                  $(HAL_QD_DIR)/src/msapi/gtEvents.o $(HAL_QD_DIR)/src/msapi/gtPortCtrl.o 	\
+                  $(HAL_QD_DIR)/src/msapi/gtPortStat.o $(HAL_QD_DIR)/src/msapi/gtPortStatus.o 	\
+                  $(HAL_QD_DIR)/src/msapi/gtQosMap.o $(HAL_QD_DIR)/src/msapi/gtPIRL.o  		\
+                  $(HAL_QD_DIR)/src/msapi/gtPhyCtrl.o $(HAL_QD_DIR)/src/msapi/gtPhyInt.o 	\
+                  $(HAL_QD_DIR)/src/msapi/gtSysConfig.o $(HAL_QD_DIR)/src/msapi/gtSysCtrl.o	\
+                  $(HAL_QD_DIR)/src/msapi/gtVersion.o $(HAL_QD_DIR)/src/msapi/gtUtils.o 	\
+                  $(HAL_QD_DIR)/src/msapi/gtBrgVtu.o $(HAL_QD_DIR)/src/msapi/gtPortRmon.o 	\
+                  $(HAL_QD_DIR)/src/msapi/gtSysStatus.o $(HAL_QD_DIR)/src/msapi/gtPortRateCtrl.o\
+                  $(HAL_QD_DIR)/src/msapi/gtPortPav.o $(HAL_QD_DIR)/src/msapi/gtVct.o		\
+		  $(HAL_QD_DIR)/src/msapi/gtPIRL2.o $(HAL_QD_DIR)/src/msapi/gtCCPVT.o		\
+		  $(HAL_QD_DIR)/src/msapi/gtPCSCtrl.o
+
+LSP_OBJS        = core.o irq.o time.o leds.o sysmap.o export.o clock.o
+
+obj-y   				:=  armadaxp.o
+armadaxp-objs  				:=$(LSP_OBJS) $(COMMON_OBJS) $(OSSERVICES_OBJS) $(HAL_OBJS) 	\
+					  $(KW_FAM_OBJS)
+
+armadaxp-$(CONFIG_MV_INCLUDE_SDIO) 	+= $(HAL_SDMMC_DIR)/mvSdmmcAddrDec.o
+armadaxp-$(CONFIG_MV_INCLUDE_XOR) 	+= $(HAL_XOR_DIR)/mvXor.o $(HAL_XOR_DIR)/mvXorAddrDec.o		\
+					   $(HAL_IF_DIR)/mvSysXor.o
+armadaxp-$(CONFIG_MV_INCLUDE_PEX) 	+= $(HAL_PEX_DIR)/mvPex.o					\
+					   $(HAL_IF_DIR)/mvSysPex.o $(HAL_PEX_DIR)/mvPexAddrDec.o
+armadaxp-$(CONFIG_MV_INCLUDE_PCI) 	+= $(HAL_PCI_DIR)/mvPci.o $(HAL_IF_DIR)/mvSysPci.o
+armadaxp-$(CONFIG_MV_INCLUDE_USB) 	+= $(HAL_USB_DIR)/mvUsb.o $(HAL_USB_DIR)/mvUsbAddrDec.o		\
+					   $(HAL_IF_DIR)/mvSysUsb.o
+armadaxp-y				+= $(HAL_ETHPHY_DIR)/mvEthPhy.o $(HAL_IF_DIR)/mvSysEthPhy.o
+
+# Legacy Giga driver
+ifeq ($(CONFIG_MV_ETH_LEGACY),y) 
+armadaxp-$(CONFIG_MV_ETH_LEGACY)	+= $(HAL_ETH_GBE_DIR)/mvEth.o $(HAL_ETH_GBE_DIR)/mvEthDebug.o \
+					   $(HAL_ETH_GBE_DIR)/mvEthAddrDec.o $(HAL_IF_DIR)/mvSysEth.o
+armadaxp-$(CONFIG_MV_ETH_NFP)           += $(HAL_ETH_NFP_DIR)/mvNfp.o 
+armadaxp-$(CONFIG_MV_ETH_NFP_NAT) 	+= $(HAL_ETH_NFP_DIR)/mvNfpNat.o
+armadaxp-$(CONFIG_MV_ETH_NFP_FDB) 	+= $(HAL_ETH_NFP_DIR)/mvNfpFdb.o  
+armadaxp-$(CONFIG_MV_ETH_NFP_PPP) 	+= $(HAL_ETH_NFP_DIR)/mvNfpPpp.o  
+armadaxp-$(CONFIG_MV_ETH_NFP_SEC)	+= $(HAL_ETH_NFP_DIR)/mvNfpSec.o
+
+endif
+
+# NETA Giga driver
+ifeq ($(CONFIG_MV_ETH_NETA),y)
+armadaxp-$(CONFIG_MV_ETH_NETA)	        += $(HAL_ETH_GBE_DIR)/mvNeta.o $(HAL_ETH_GBE_DIR)/mvNetaDebug.o \
+					   $(HAL_ETH_GBE_DIR)/mvNetaAddrDec.o $(HAL_IF_DIR)/mvSysNeta.o
+armadaxp-$(CONFIG_MV_ETH_PNC)    	+= $(HAL_ETH_PNC_DIR)/mvTcam.o
+armadaxp-$(CONFIG_MV_ETH_PNC_PARSER)	+= $(HAL_ETH_PNC_DIR)/mvPnc.o 
+armadaxp-$(CONFIG_MV_ETH_PNC_WOL)       += $(HAL_ETH_PNC_DIR)/mvPncWol.o
+armadaxp-$(CONFIG_MV_ETH_BM) 	        += $(HAL_ETH_BM_DIR)/mvBm.o
+armadaxp-$(CONFIG_MV_ETH_PMT)	        += $(HAL_ETH_PMT_DIR)/mvPmt.o 
+armadaxp-$(CONFIG_MV_ETH_HWF)           += $(HAL_ETH_GBE_DIR)/mvHwf.o
+armadaxp-$(CONFIG_MV_ETH_NFP)		+= $(HAL_ETH_NFP_DIR)/mvNfp.o
+armadaxp-$(CONFIG_MV_ETH_NFP_NAT) 	+= $(HAL_ETH_NFP_DIR)/mvNfpNat.o
+armadaxp-$(CONFIG_MV_ETH_NFP_SWF) 	+= $(HAL_ETH_NFP_DIR)/mvNfpSwf.o
+armadaxp-$(CONFIG_MV_ETH_NFP_FIB) 	+= $(HAL_ETH_NFP_DIR)/mvNfpFib.o
+armadaxp-$(CONFIG_MV_ETH_NFP_PNC) 	+= $(HAL_ETH_NFP_DIR)/mvNfpPnc.o    
+endif
+
+armadaxp-$(CONFIG_MV_INCLUDE_CESA) 	+= $(HAL_CESA_DIR)/mvCesa.o $(HAL_CESA_DIR)/mvCesaDebug.o 	\
+					   $(HAL_CESA_DIR)/mvCesaAddrDec.o				\
+                        		   $(HAL_CESA_DIR)/mvMD5.o $(HAL_CESA_DIR)/mvSHA1.o 		\
+					   $(HAL_CESA_DIR)/mvSHA256.o					\
+					   $(HAL_CESA_AES_DIR)/mvAesAlg.o $(HAL_CESA_AES_DIR)/mvAesApi.o\
+					   $(HAL_IF_DIR)/mvSysCesa.o
+armadaxp-$(CONFIG_MV_INCLUDE_INTEG_SATA)+= $(HAL_IF_DIR)/mvSysSata.o $(HAL_SATA_DIR)/mvSataSoc.o	\
+					   $(HAL_SATA_DIR)/mvSataAddrDec.o
+armadaxp-$(CONFIG_MV_INCLUDE_SPI) 	+= $(HAL_SPI_DIR)/mvSpi.o $(HAL_SPI_DIR)/mvSpiCmnd.o 		\
+                         		   $(HAL_SFLASH_DIR)/mvSFlash.o $(HAL_IF_DIR)/mvSysSFlash.o	\
+					   $(HAL_IF_DIR)/mvSysSpi.o
+armadaxp-$(CONFIG_MV_INCLUDE_NFC)	+= $(HAL_NFC_DIR)/mvNfc.o
+armadaxp-$(CONFIG_MV_INCLUDE_AUDIO) 	+= $(HAL_AUDIO_DIR)/mvAudio.o $(HAL_IF_DIR)/mvSysAudio.o	\
+					   $(HAL_AUDIO_DIR)/mvAudioAddrDec.o
+armadaxp-$(CONFIG_MV_INCLUDE_TS) 	+= $(HAL_TS_DIR)/mvTsu.o $(HAL_IF_DIR)/mvSysTs.o		\
+					   $(HAL_TS_DIR)/mvTsuAddrDec.o
+armadaxp-$(CONFIG_MV_CPU_PERF_CNTRS)    += $(HAL_CPU_DIR)/mvCpuCntrs.o $(HAL_CPU_DIR)/pj4/mvPJ4Cntrs.o
+armadaxp-$(CONFIG_PCIE_VIRTUAL_BRIDGE_SUPPORT) += $(HAL_PEX_DIR)/mvVrtBrgPex.o
+armadaxp-$(CONFIG_MV_CPU_L2_PERF_CNTRS) += $(HAL_CPU_DIR)/mvCpuL2Cntrs.o
+
+obj-$(CONFIG_MV_INCLUDE_SWITCH) 	+= $(QD_OBJS)
+
+# drivers part
+# Legacy Giga driver
+ifeq ($(CONFIG_MV_ETH_LEGACY),y)
+obj-$(CONFIG_MV_ETH_NFP) 	        += $(LSP_NFP_MGR_DIR)/mv_nfp_mgr.o
+obj-$(CONFIG_MV_ETH_NFP_SEC)            += $(LSP_NFP_MGR_DIR)/mv_nfp_sec.o
+endif
+
+ifeq ($(CONFIG_MV_ETH_NETA),y)
+obj-$(CONFIG_MV_ETH_NFP)	        += $(LSP_NFP_MGR_DIR)/mv_nfp_mgr.o $(LSP_NFP_MGR_DIR)/nfp_sysfs.o
+obj-$(CONFIG_MV_ETH_PNC)                += $(LSP_PNC_DIR)/pnc_sysfs.o
+obj-$(CONFIG_MV_ETH_BM)                 += $(LSP_BM_DIR)/bm_sysfs.o
+obj-$(CONFIG_MV_ETH_PNC_WOL)            += $(LSP_PNC_DIR)/wol_sysfs.o
+obj-$(CONFIG_MV_ETH_PMT)		+= $(LSP_PMT_DIR)/pmt_sysfs.o
+obj-$(CONFIG_MV_ETH_HWF)        	+= $(LSP_HWF_DIR)/hwf_sysfs.o $(LSP_HWF_DIR)/hwf_bm.o
+obj-$(CONFIG_MV_ETH_L2FW)               += $(LSP_L2FW_DIR)/l2fw_sysfs.o $(LSP_L2FW_DIR)/mv_eth_l2fw.o
+endif
+
+obj-$(CONFIG_MV_USE_XOR_ENGINE) 	+= $(PLAT_DRIVERS)/mv_xor/
+obj-$(CONFIG_MV_CESA) 			+= $(PLAT_DRIVERS)/mv_cesa/
+#obj-y					+= $(PLAT_DRIVERS)/mv_btns/
+obj-y					+= $(PLAT_DRIVERS)/mv_gpio/
+obj-$(CONFIG_MV_INCLUDE_SWITCH)         += $(LSP_SWITCH_DIR)/
+obj-$(CONFIG_SENSORS_ARMADA_XP)	+= hwmon.o
+# The rest of the drivers are compiled through the driver dir directly.
+
+
+# LSP part
+armadaxp-$(CONFIG_MV_INCLUDE_USB)    	+= usb.o
+armadaxp-$(CONFIG_MV_INCLUDE_PCI)	+= pci.o
+armadaxp-$(CONFIG_MV_INCLUDE_PEX)	+= pex.o
+armadaxp-$(CONFIG_FEROCEON_PROC) 	+= $(PLAT_DRIVERS)/mv_proc/proc.o
+armadaxp-$(CONFIG_MV_DBG_TRACE) 	+= dbg-trace.o
+armadaxp-$(CONFIG_SMP)			+= platsmp.o headsmp.o
+armadaxp-$(CONFIG_PROC_FS)		+= dump_cp15_regs.o
+obj-$(CONFIG_FB_DOVE_CLCD)		+= clcd.o
+obj-$(CONFIG_PM)			+= pm.o
+
diff --git a/arch/arm/mach-armadaxp/Makefile.boot b/arch/arm/mach-armadaxp/Makefile.boot
new file mode 100644
index 0000000..c7e75ac
--- /dev/null
+++ b/arch/arm/mach-armadaxp/Makefile.boot
@@ -0,0 +1,4 @@
+   zreladdr-y	:= 0x00008000
+params_phys-y	:= 0x00000100
+initrd_phys-y	:= 0x00800000
+
diff --git a/arch/arm/mach-armadaxp/clcd.c b/arch/arm/mach-armadaxp/clcd.c
new file mode 100644
index 0000000..dd0277c
--- /dev/null
+++ b/arch/arm/mach-armadaxp/clcd.c
@@ -0,0 +1,555 @@
+/*
+ *  linux/arch/arm/mach-dove/clcd.c
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/sysdev.h>
+#include <linux/amba/bus.h>
+#include <linux/amba/kmi.h>
+#include <linux/mm.h>
+#include <linux/io.h>
+#include <asm/irq.h>
+#include <asm/setup.h>
+#include <linux/param.h>		/* HZ */
+#include <asm/mach-types.h>
+
+#include <asm/mach/arch.h>
+#include <asm/mach/flash.h>
+#include <asm/mach/irq.h>
+#include <asm/mach/map.h>
+#include <asm/mach/time.h>
+#include <video/dovefb.h>
+#include <video/dovefbreg.h>
+#ifdef CONFIG_FB_DOVE_DCON
+#include <video/dovedcon.h>
+#include <mach/dove_bl.h>
+#endif
+#include "gpp/mvGppRegs.h"
+#include <ctrlEnv/mvCtrlEnvRegs.h>
+
+int lcd_panel;
+module_param(lcd_panel, uint, 0);
+MODULE_PARM_DESC(lcd_panel, "set to 1 to enable LCD panel.");
+
+unsigned int lcd0_enable;
+module_param(lcd0_enable, uint, 0);
+MODULE_PARM_DESC(lcd0_enable, "set to 1 to enable LCD0 output.");
+
+#if defined(CONFIG_FB_DOVE_CLCD_FLAREON_GV) || \
+    defined(CONFIG_FB_DOVE_CLCD_FLAREON_GV_MODULE)
+	#ifndef CONFIG_ARCH_DOVENB_ON_TAHOE_AXI
+	#define	LCD_BASE_PHY_ADDR		0x80400000
+	#define	LCD1_BASE_PHY_ADDR		0x80410000
+	#define	DCON_BASE_PHY_ADDR		0x80420000
+	#else
+	#define	LCD_BASE_PHY_ADDR		0xB0020000
+	#define	LCD1_BASE_PHY_ADDR		0xB0010000
+	#define	DCON_BASE_PHY_ADDR		0xB0030000
+	#endif
+#elif defined(CONFIG_ARCH_DOVE)
+	#define	LCD_BASE_PHY_ADDR		(DOVE_LCD1_PHYS_BASE)
+	#define	LCD1_BASE_PHY_ADDR		(DOVE_LCD2_PHYS_BASE)
+	#define	DCON_BASE_PHY_ADDR		(DOVE_LCD_DCON_PHYS_BASE)
+#elif defined(CONFIG_ARCH_FEROCEON_KW)
+	#define	LCD_BASE_PHY_ADDR		(INTER_REGS_BASE | 0xC0000)
+#else
+	#ifdef CONFIG_ARCH_TAHOE_AXI
+	#define LCD_BASE_PHY_ADDR		0x1C010000
+	#define LCD1_BASE_PHY_ADDR		0x1C020000
+	#else
+	#define	LCD_BASE_PHY_ADDR		0x70000000
+	#define	LCD1_BASE_PHY_ADDR		0x70010000
+	#define	DCON_BASE_PHY_ADDR		0x70020000
+	#define	IRE_BASE_PHY_ADDR		0x70021000
+
+	#endif /* CONFIG_ARCH_TAHOE */
+#endif
+
+/*
+ * Default mode database.
+ */
+static struct fb_videomode video_modes[] = {
+	[0] = {			/* 640x480@60 */
+	.pixclock	= 0,
+	.refresh	= 60,
+	.xres		= 640,
+	.yres		= 480,
+
+	.right_margin	= 16,
+	.hsync_len	= 96,
+	.left_margin	= 48,
+
+	.lower_margin	= 11,
+	.vsync_len	= 2,
+	.upper_margin	= 31,
+	.sync		= 0,
+	},
+	[1] = {			/* 640x480@72 */
+	.pixclock	= 0,
+	.refresh	= 72,
+	.xres		= 640,
+	.yres		= 480,
+
+	.right_margin	= 24,
+	.hsync_len	= 40,
+	.left_margin	= 128,
+
+	.lower_margin	= 9,
+	.vsync_len	= 3,
+	.upper_margin	= 28,
+	.sync		= 0,
+	},
+	[2] = {			/* 640x480@75 */
+	.pixclock	= 0,
+	.refresh	= 75,
+	.xres		= 640,
+	.yres		= 480,
+
+	.right_margin	= 16,
+	.hsync_len	= 96,
+	.left_margin	= 48,
+
+	.lower_margin	= 11,
+	.vsync_len	= 2,
+	.upper_margin	= 32,
+	.sync		= 0,
+	},
+	[3] = {			/* 640x480@85 */
+	.pixclock	= 0,
+	.refresh	= 85,
+	.xres		= 640,
+	.yres		= 480,
+
+	.right_margin	= 32,
+	.hsync_len	= 48,
+	.left_margin	= 112,
+
+	.lower_margin	= 1,
+	.vsync_len	= 3,
+	.upper_margin	= 25,
+	.sync		= 0,
+	},
+	[4] = {			/* 800x600@56 */
+	.pixclock	= 0,
+	.refresh	= 56,
+	.xres		= 800,
+	.yres		= 600,
+
+	.right_margin	= 32,
+	.hsync_len	= 128,
+	.left_margin	= 128,
+
+	.lower_margin	= 1,
+	.vsync_len	= 4,
+	.upper_margin	= 14,
+	.sync		= 0,
+	},
+	[5] = {			/* 800x600@60 */
+	.pixclock	= 0,
+	.refresh	= 60,
+	.xres		= 800,
+	.yres		= 600,
+
+	.right_margin	= 40,
+	.hsync_len	= 128,
+	.left_margin	= 88,
+
+	.lower_margin	= 1,
+	.vsync_len	= 4,
+	.upper_margin	= 23,
+	.sync		= 0,
+	},
+	[6] = {			/* 800x600@72 */
+	.pixclock	= 0,
+	.refresh	= 72,
+	.xres		= 800,
+	.yres		= 600,
+
+	.right_margin	= 56,
+	.hsync_len	= 120,
+	.left_margin	= 64,
+
+	.lower_margin	= 37,
+	.vsync_len	= 6,
+	.upper_margin	= 23,
+	.sync		= 0,
+	},
+	[7] = {			/* 800x600@75 */
+	.pixclock	= 0,
+	.refresh	= 75,
+	.xres		= 800,
+	.yres		= 600,
+
+	.right_margin	= 16,
+	.hsync_len	= 80,
+	.left_margin	= 160,
+
+	.lower_margin	= 1,
+	.vsync_len	= 2,
+	.upper_margin	= 21,
+	.sync		= 0,
+	},
+	[8] = {			/* 800x600@85 */
+	.pixclock	= 0,
+	.refresh	= 85,
+	.xres		= 800,
+	.yres		= 600,
+
+	.right_margin	= 32,
+	.hsync_len	= 64,
+	.left_margin	= 152,
+
+	.lower_margin	= 1,
+	.vsync_len	= 3,
+	.upper_margin	= 27,
+	.sync		= 0,
+	},
+	[9] = {			/* 1024x600@60 */
+	.pixclock	= 0,
+	.refresh	= 60,
+	.xres		= 1024,
+	.yres		= 600,
+
+	.right_margin	= 38,
+	.hsync_len	= 100,
+	.left_margin	= 38,
+	.right_margin	= 38,
+
+	.lower_margin	= 8,
+	.vsync_len	= 4,
+	.upper_margin	= 8,
+	.sync		= 0,
+	},
+	[10] = {			/* 1024x768@60 */
+	.pixclock	= 0,
+	.refresh	= 60,
+	.xres		= 1024,
+	.yres		= 768,
+
+	.right_margin	= 24,
+	.hsync_len	= 136,
+	.left_margin	= 160,
+
+	.lower_margin	= 3,
+	.vsync_len	= 6,
+	.upper_margin	= 29,
+	.sync		= 0,
+	},
+	[11] = {			/* 1024x768@70 */
+	.pixclock	= 0,
+	.refresh	= 70,
+	.xres		= 1024,
+	.yres		= 768,
+
+	.right_margin	= 24,
+	.hsync_len	= 136,
+	.left_margin	= 144,
+
+	.lower_margin	= 3,
+	.vsync_len	= 6,
+	.upper_margin	= 29,
+	.sync		= 0,
+	},
+	[12] = {			/* 1024x768@75 */
+	.pixclock	= 0,
+	.refresh	= 75,
+	.xres		= 1024,
+	.yres		= 768,
+
+	.right_margin	= 16,
+	.hsync_len	= 96,
+	.left_margin	= 176,
+
+	.lower_margin	= 1,
+	.vsync_len	= 3,
+	.upper_margin	= 28,
+	.sync		= 0,
+	},
+	[12] = {			/* 1024x768@85 */
+	.pixclock	= 0,
+	.refresh	= 85,
+	.xres		= 1024,
+	.yres		= 768,
+
+	.right_margin	= 48,
+	.hsync_len	= 96,
+	.left_margin	= 208,
+
+	.lower_margin	= 1,
+	.vsync_len	= 3,
+	.upper_margin	= 36,
+	.sync		= 0,
+	},
+	[13] = {			/* 1280x720@60 */
+	.pixclock	= 0,
+	.refresh	= 60,
+	.xres		= 1280, /* 1328 */
+	.yres		= 720,  /* 816 */
+
+	.hsync_len	= 40,
+	.left_margin	= 220,
+	.right_margin	= 110,
+
+	.vsync_len	= 5,
+	.upper_margin	= 20,
+	.lower_margin	= 5,
+	.sync		= 0,
+	},
+	[14] = {			/* 1280x1024@60 */
+	.pixclock	= 0,
+	.refresh	= 60,
+	.xres		= 1280,
+	.yres		= 1024,
+
+	.right_margin	= 48,
+	.hsync_len	= 112,
+	.left_margin	= 248,
+
+	.lower_margin	= 1,
+	.vsync_len	= 3,
+	.upper_margin	= 38,
+	.sync		= 0,
+	},
+	[15] = {			/* 1366x768@60 */
+	.pixclock	= 0,
+	.refresh	= 60,
+	.xres		= 1366,
+	.yres		= 768,
+
+	.right_margin	= 72,
+	.hsync_len	= 144,
+	.left_margin	= 216,
+
+	.lower_margin	= 1,
+	.vsync_len	= 3,
+	.upper_margin	= 23,
+	.sync		= 0,
+	},
+#if 1
+	[16] = {			/* 1650x1050@60 */
+	.pixclock	= 0,
+	.refresh	= 60,
+	.xres		= 1650,
+	.yres		= 1050,
+
+	.right_margin	= 104,
+	.hsync_len	= 184,
+	.left_margin	= 288,
+
+	.lower_margin	= 1,
+	.vsync_len	= 3,
+	.upper_margin	= 33,
+	.sync		= 0,
+	},
+	[17] = {			/* 1920x1080@60 */
+	.pixclock	= 0,
+	.refresh	= 60,
+	.xres		= 1920,
+	.yres		= 1080,
+
+	.right_margin	= 88,
+	.hsync_len	= 44,
+	.left_margin	= 148,
+
+	.lower_margin	= 4,
+	.vsync_len	= 5,
+	.upper_margin	= 36,
+	.sync		= 0,
+	},
+	[18] = {			/* 1920x1200@60 */
+	.pixclock	= 0,
+	.refresh	= 60,
+	.xres		= 1920,
+	.yres		= 1200,
+
+	.right_margin	= 128,
+	.hsync_len	= 208,
+	.left_margin	= 336,
+
+	.lower_margin	= 1,
+	.vsync_len	= 3,
+	.upper_margin	= 38,
+	.sync		= 0,
+	},
+#endif
+	[19] = {			/* 480x272@60 */
+	.pixclock	= 0,
+	.refresh	= 60,
+	.xres		= 480,
+	.yres		= 272,
+
+	.right_margin	= 2,
+	.hsync_len	= 41,
+	.left_margin	= 2,
+
+	.lower_margin	= 2,
+	.vsync_len	= 10,
+	.upper_margin	= 2,
+	.sync		= 0,
+	},
+
+
+};
+
+
+#if defined(CONFIG_FB_DOVE_CLCD)
+
+static struct resource lcd0_vid_res[] = {
+	[0] = {
+		.start	= LCD_PHYS_BASE,
+		.end	= LCD_PHYS_BASE+0x10000,
+		.flags	= IORESOURCE_MEM,
+	},
+	[1] = {
+		.start	= IRQ_AURORA_LCD,
+		.end	= IRQ_AURORA_LCD,
+		.flags	= IORESOURCE_IRQ,
+	},
+};
+
+
+static struct resource lcd0_res[] = {
+	[0] = {
+		.start	= LCD_PHYS_BASE,
+		.end	= LCD_PHYS_BASE+0x10000,
+		.flags	= IORESOURCE_MEM,
+	},
+	[1] = {
+		.start	= IRQ_AURORA_LCD,
+		.end	= IRQ_AURORA_LCD,
+		.flags	= IORESOURCE_IRQ,
+	},
+};
+
+
+static struct platform_device lcd0_platform_device = {
+	.name = "dovefb",
+	.id = 0,			/* lcd0 */
+	.dev = {
+		.coherent_dma_mask = ~0,
+		/*.platform_data = &lcd0_dmi,*/
+	},
+	.num_resources	= ARRAY_SIZE(lcd0_res),
+	.resource	= lcd0_res,
+};
+
+static struct platform_device lcd0_vid_platform_device = {
+	.name = "dovefb_ovly",
+	.id = 0,			/* lcd0 */
+	.dev = {
+		.coherent_dma_mask = ~0,
+		/*.platform_data = &lcd0_vid_dmi,*/
+	},
+	.num_resources	= ARRAY_SIZE(lcd0_vid_res),
+	.resource	= lcd0_vid_res,
+};
+#endif /* CONFIG_FB_DOVE_CLCD */
+
+#ifdef CONFIG_BACKLIGHT_DOVE
+static struct resource backlight_res[] = {
+	[0] = {
+		.start	= LCD_PHYS_BASE,
+		.end	= LCD_PHYS_BASE+0x1C8,
+		.flags	= IORESOURCE_MEM,
+	},
+};
+
+static struct platform_device backlight_platform_device = {
+	.name = "dove-bl",
+	.id = 0,
+	.num_resources	= ARRAY_SIZE(backlight_res),
+	.resource	= backlight_res,
+};
+
+#endif /* CONFIG_FB_DOVE_DCON */
+
+/*****************************************************************************
+ * I2C buses - adc, hdmi
+ ****************************************************************************/
+static struct i2c_board_info __initdata i2c_adi9889[] = {
+	{
+		I2C_BOARD_INFO("adi9889_i2c", 0x3D),
+	},
+	{
+		I2C_BOARD_INFO("adi9889_edid_i2c", 0x3F),
+	},
+};
+
+static struct i2c_board_info __initdata i2c_ths8200[] = {
+	{
+		I2C_BOARD_INFO("ths8200_i2c", 0x21),
+	},
+};
+
+
+
+int clcd_platform_init(struct dovefb_mach_info *lcd0_dmi_data,
+		       struct dovefb_mach_info *lcd0_vid_dmi_data,
+		       struct dovebl_platform_data *backlight_data)
+{
+	u32 total_x, total_y, i;
+	u64 div_result;
+
+	for (i = 0; i < ARRAY_SIZE(video_modes); i++) {
+		total_x = video_modes[i].xres + video_modes[i].hsync_len +
+			video_modes[i].left_margin +
+			video_modes[i].right_margin;
+		total_y = video_modes[i].yres + video_modes[i].vsync_len +
+			video_modes[i].upper_margin +
+			video_modes[i].lower_margin;
+		div_result = 1000000000000ll;
+		do_div(div_result,
+			(total_x * total_y * video_modes[i].refresh));
+		video_modes[i].pixclock	= div_result;
+	}
+
+	/*
+	 * Because DCON depends on lcd0 & lcd1 clk. Here we
+	 * try to reorder the load sequence. Fix me when h/w
+	 * changes.
+	 */
+#ifdef CONFIG_FB_DOVE_CLCD
+	/* lcd0 */
+	if (lcd0_enable && lcd0_dmi_data && lcd0_vid_dmi_data) {
+
+		lcd0_vid_dmi_data->modes = video_modes;
+		lcd0_vid_dmi_data->num_modes = ARRAY_SIZE(video_modes);
+		lcd0_vid_platform_device.dev.platform_data = lcd0_vid_dmi_data;
+
+		lcd0_dmi_data->modes = video_modes;
+		lcd0_dmi_data->num_modes = ARRAY_SIZE(video_modes);
+		lcd0_platform_device.dev.platform_data = lcd0_dmi_data;
+		platform_device_register(&lcd0_vid_platform_device);
+		platform_device_register(&lcd0_platform_device);
+	} else {
+		printk(KERN_INFO "LCD 0 disabled (%d).\n", lcd0_enable);
+	}
+#endif
+
+#ifdef CONFIG_BACKLIGHT_DOVE
+	if (lcd0_enable && lcd_panel) {
+		backlight_platform_device.dev.platform_data = backlight_data;
+		platform_device_register(&backlight_platform_device);
+	}
+#endif
+
+	if (lcd0_enable && !lcd_panel) {
+		i2c_register_board_info(1, i2c_adi9889,
+				ARRAY_SIZE(i2c_adi9889));
+		i2c_register_board_info(1, i2c_ths8200,
+				ARRAY_SIZE(i2c_ths8200));
+	}
+
+	return 0;
+}
+
diff --git a/arch/arm/mach-armadaxp/clock.c b/arch/arm/mach-armadaxp/clock.c
new file mode 100644
index 0000000..15b04ae
--- /dev/null
+++ b/arch/arm/mach-armadaxp/clock.c
@@ -0,0 +1,50 @@
+/*
+ *  linux/arch/arm/mach-dove/clock.c
+ */
+
+/* TODO: Implement the functions below...	*/
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/list.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/string.h>
+#include <linux/clk.h>
+#include <linux/spinlock.h>
+#include <linux/platform_device.h>
+#include <linux/delay.h>
+
+#include <mach/hardware.h>
+
+#include "clock.h"
+
+int clk_enable(struct clk *clk)
+{
+	return 0;
+}
+EXPORT_SYMBOL(clk_enable);
+
+void clk_disable(struct clk *clk)
+{
+}
+EXPORT_SYMBOL(clk_disable);
+
+unsigned long clk_get_rate(struct clk *clk)
+{
+	return 0;
+}
+EXPORT_SYMBOL(clk_get_rate);
+
+
+void clks_register(struct clk *clks, size_t num)
+{
+}
+
+static int __init clk_init(void)
+{
+	/* TODO: Call clks_register with appropriate params. */
+	clks_register(NULL, 0);
+	return 0;
+}
+arch_initcall(clk_init);
diff --git a/arch/arm/mach-armadaxp/clock.h b/arch/arm/mach-armadaxp/clock.h
new file mode 100644
index 0000000..3fd3a3b
--- /dev/null
+++ b/arch/arm/mach-armadaxp/clock.h
@@ -0,0 +1,5 @@
+struct clk {
+	unsigned int dummy;
+};
+
+void clks_register(struct clk *clks, size_t num);
diff --git a/arch/arm/mach-armadaxp/config/mvRules.mk b/arch/arm/mach-armadaxp/config/mvRules.mk
new file mode 100644
index 0000000..c4f4de9
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvRules.mk
@@ -0,0 +1,178 @@
+# This flags will be used only by the Marvell arch files compilation.
+
+###################################################################################################
+# General definitions
+###################################################################################################
+CPU_ARCH    = ARM
+CHIP        = 88F78xx0
+VENDOR      = Marvell
+ifeq ($(CONFIG_CPU_BIG_ENDIAN),y)
+ENDIAN      = BE
+else
+ENDIAN      = LE
+endif
+
+###################################################################################################
+# directory structure
+###################################################################################################
+# Main directory structure
+PLAT_PATH	  = ../plat-armada
+PLAT_DRIVERS	  = $(PLAT_PATH)/mv_drivers_lsp
+HAL_DIR           = $(PLAT_PATH)/mv_hal
+COMMON_DIR        = $(PLAT_PATH)/common
+OSSERV_DIR        = $(PLAT_PATH)/linux_oss
+CONFIG_DIR        = config
+HAL_IF		  = mv_hal_if
+
+# HALs
+HAL_ETHPHY_DIR    = $(HAL_DIR)/eth-phy
+HAL_FLASH_DIR     = $(HAL_DIR)/flash
+HAL_RTC_DIR       = $(HAL_DIR)/rtc/integ_rtc
+HAL_VOICEBAND     = $(HAL_DIR)/voiceband
+HAL_SLIC_DIR      = $(HAL_VOICEBAND)/slic
+HAL_DAA_DIR       = $(HAL_VOICEBAND)/daa
+HAL_SATA_DIR      = $(HAL_DIR)/sata/CoreDriver/
+HAL_QD_DIR        = $(HAL_DIR)/qd-dsdt
+HAL_SFLASH_DIR    = $(HAL_DIR)/sflash
+HAL_CNTMR_DIR     = $(HAL_DIR)/cntmr
+HAL_DRAM_DIR      = $(HAL_DIR)/ddr2_3/
+#HAL_DRAM_SPD_DIR  = $(HAL_DIR)/ddr2_3/spd
+HAL_GPP_DIR       = $(HAL_DIR)/gpp
+HAL_TWSI_DIR      = $(HAL_DIR)/twsi
+HAL_TWSI_ARCH_DIR = $(SOC_TWSI_DIR)/Arch$(CPU_ARCH)
+HAL_UART_DIR      = $(HAL_DIR)/uart
+
+ifeq ($(CONFIG_MV_ETH_NETA),y)
+HAL_ETH_DIR       = $(HAL_DIR)/neta 
+HAL_ETH_GBE_DIR   = $(HAL_DIR)/neta/gbe
+HAL_ETH_NFP_DIR   = $(HAL_DIR)/neta/nfp
+HAL_ETH_PNC_DIR   = $(HAL_DIR)/neta/pnc
+HAL_ETH_BM_DIR    = $(HAL_DIR)/neta/bm
+LSP_NETWORK_DIR   = $(PLAT_DRIVERS)/mv_neta
+LSP_NET_DEV_DIR   = $(LSP_NETWORK_DIR)/net_dev
+LSP_NFP_MGR_DIR   = $(LSP_NETWORK_DIR)/nfp_mgr
+LSP_PNC_DIR       = $(LSP_NETWORK_DIR)/pnc
+LSP_BM_DIR        = $(LSP_NETWORK_DIR)/bm
+LSP_PMT_DIR       = $(LSP_NETWORK_DIR)/pmt
+LSP_HWF_DIR       = $(LSP_NETWORK_DIR)/hwf
+LSP_L2FW_DIR      = $(LSP_NETWORK_DIR)/l2fw
+LSP_SWITCH_DIR    = $(PLAT_DRIVERS)/mv_switch
+endif
+
+ifeq ($(CONFIG_MV_ETH_LEGACY),y)
+HAL_ETH_DIR       = $(HAL_DIR)/eth
+HAL_ETH_GBE_DIR   = $(HAL_DIR)/eth/gbe
+HAL_ETH_NFP_DIR	  = $(HAL_DIR)/eth/nfp
+LSP_NETWORK_DIR   = $(PLAT_DRIVERS)/mv_network
+LSP_NET_DEV_DIR   = $(LSP_NETWORK_DIR)/mv_etherent
+LSP_NFP_MGR_DIR   = $(LSP_NETWORK_DIR)/nfp_mgr
+endif
+
+HAL_CPU_DIR       = $(HAL_DIR)/cpu
+HAL_SDMMC_DIR	  = $(HAL_DIR)/sdmmc
+ifeq ($(CONFIG_MV_INCLUDE_PEX),y)
+HAL_PCI_DIR	  = $(HAL_DIR)/pci
+HAL_PEX_DIR       = $(HAL_DIR)/pex
+endif
+ifeq ($(CONFIG_MV_INCLUDE_TDM),y)
+HAL_TDM_DIR       = $(HAL_DIR)/voiceband/tdm
+endif
+ifeq ($(CONFIG_MV_INCLUDE_USB),y)
+HAL_USB_DIR       = $(HAL_DIR)/usb
+endif
+ifeq ($(CONFIG_MV_INCLUDE_CESA),y)
+HAL_CESA_DIR	  = $(HAL_DIR)/cesa
+HAL_CESA_AES_DIR  = $(HAL_DIR)/cesa/AES
+endif
+ifeq ($(CONFIG_MV_INCLUDE_XOR),y)
+HAL_XOR_DIR       = $(HAL_DIR)/xor
+endif
+ifeq ($(CONFIG_MV_INCLUDE_SPI),y)
+HAL_SPI_DIR       = $(HAL_DIR)/spi
+endif
+ifeq ($(CONFIG_MV_INCLUDE_AUDIO),y)
+HAL_AUDIO_DIR     = $(HAL_DIR)/audio
+endif
+ifeq ($(CONFIG_MV_INCLUDE_NFC),y)
+HAL_NFC_DIR     = $(HAL_DIR)/nfc
+endif
+
+# Environment components
+AXP_FAM_DIR	= armada_xp_family
+SOC_DEVICE_DIR	= $(AXP_FAM_DIR)/device
+SOC_CPU_DIR	= $(AXP_FAM_DIR)/cpu
+BOARD_ENV_DIR	= $(AXP_FAM_DIR)/boardEnv
+SOC_ENV_DIR	= $(AXP_FAM_DIR)/ctrlEnv
+SOC_SYS_DIR	= $(AXP_FAM_DIR)/ctrlEnv/sys
+HAL_IF_DIR	= mv_hal_if
+
+#####################################################################################################
+# Include path
+###################################################################################################
+
+LSP_PATH_I      = $(srctree)/arch/arm/mach-armadaxp
+PLAT_PATH_I	= $(srctree)/arch/arm/plat-armada
+
+HAL_PATH        = -I$(PLAT_PATH_I)/$(HAL_DIR) -I$(PLAT_PATH_I)/$(HAL_SATA_DIR) -I$(PLAT_PATH_I)/$(HAL_ETH_DIR)
+AXP_FAM_PATH	= -I$(LSP_PATH_I)/$(AXP_FAM_DIR)
+QD_PATH         = -I$(PLAT_PATH_I)/$(HAL_QD_DIR)/Include  -I$(PLAT_PATH_I)/$(HAL_QD_DIR)/Include/h/msApi 	\
+                  -I$(PLAT_PATH_I)/$(HAL_QD_DIR)/Include/h/driver -I$(PLAT_PATH_I)/$(HAL_QD_DIR)/Include/h/platform
+                     
+COMMON_PATH   	= -I$(PLAT_PATH_I)/$(COMMON_DIR) -I$(srctree)
+ 
+OSSERV_PATH     = -I$(PLAT_PATH_I)/$(OSSERV_DIR)
+LSP_PATH        = -I$(LSP_PATH_I)
+CONFIG_PATH     = -I$(LSP_PATH_I)/$(CONFIG_DIR)
+HAL_IF_PATH	= -I$(LSP_PATH_I)/$(HAL_IF)
+DRIVERS_LSP_PATH = -I$(PLAT_PATH_I)/$(PLAT_DRIVERS) -I$(PLAT_PATH_I)/$(LSP_NETWORK_DIR) -I$(PLAT_PATH_I)/$(LSP_SWITCH_DIR)
+
+EXTRA_INCLUDE  	= $(OSSERV_PATH) $(COMMON_PATH) $(HAL_PATH)  $(AXP_FAM_PATH) \
+                  $(LSP_PATH) $(CONFIG_PATH) $(DRIVERS_LSP_PATH) $(HAL_IF_PATH)
+
+###################################################################################################
+# defines
+###################################################################################################
+MV_DEFINE = -DMV_LINUX -DMV_CPU_$(ENDIAN) -DMV_$(CPU_ARCH) 
+
+
+ifeq ($(CONFIG_MV_GATEWAY),y)
+EXTRA_INCLUDE	+= $(QD_PATH)
+EXTRA_CFLAGS    += -DLINUX  
+endif
+
+ifeq ($(CONFIG_MV_INCLUDE_SWITCH),y)
+EXTRA_INCLUDE   += $(QD_PATH)
+EXTRA_CFLAGS    += -DLINUX
+endif
+
+ifeq ($(CONFIG_MV_CESA_TEST),y)
+EXTRA_CFLAGS 	+= -DCONFIG_MV_CESA_TEST
+endif
+
+ifeq ($(CONFIG_SATA_DEBUG_ON_ERROR),y)
+EXTRA_CFLAGS    += -DMV_LOG_ERROR
+endif
+
+ifeq ($(CONFIG_SATA_FULL_DEBUG),y)
+EXTRA_CFLAGS    += -DMV_LOG_DEBUG
+endif
+
+ifeq ($(CONFIG_MV_SATA_SUPPORT_ATAPI),y)
+EXTRA_CFLAGS    += -DMV_SUPPORT_ATAPI
+endif
+
+ifeq ($(CONFIG_MV_SATA_ENABLE_1MB_IOS),y)
+EXTRA_CFLAGS    += -DMV_SUPPORT_1MBYTE_IOS
+endif
+
+ifeq ($(CONFIG_PCIE_VIRTUAL_BRIDGE_SUPPORT),y)
+EXTRA_CFLAGS    +=-DPCIE_VIRTUAL_BRIDGE_SUPPORT
+endif
+
+ifeq ($(CONFIG_MV_CESA_CHAIN_MODE_SUPPORT),y)
+EXTRA_CFLAGS    += -DMV_CESA_CHAIN_MODE_SUPPORT
+endif
+
+EXTRA_CFLAGS 	+= $(EXTRA_INCLUDE) $(MV_DEFINE)
+
+EXTRA_AFLAGS 	+= $(EXTRA_CFLAGS)
diff --git a/arch/arm/mach-armadaxp/config/mvSysCesaConfig.h b/arch/arm/mach-armadaxp/config/mvSysCesaConfig.h
new file mode 100644
index 0000000..141e9a4
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysCesaConfig.h
@@ -0,0 +1,45 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysCesaConfig.h - Marvell Cesa unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+//#include "mvSysHwConfig.h"
+#include  "ctrlEnv/mvCtrlEnvSpec.h"
+
+/*
+** Base address for cesa registers.
+*/
+#define MV_CESA_REGS_BASE(chan) 	(MV_CESA_REGS_OFFSET(chan))
+
+#define MV_CESA_TDMA_REGS_BASE(chan)	(MV_CESA_TDMA_REGS_OFFSET(chan))
+
+#define MV_CESA_CHANNELS		(CONFIG_MV_CESA_CHANNELS)
+
+#ifdef CONFIG_MV_CESA_CHAIN_MODE
+	#define MV_CESA_CHAIN_MODE
+#endif
diff --git a/arch/arm/mach-armadaxp/config/mvSysCntmrConfig.h b/arch/arm/mach-armadaxp/config/mvSysCntmrConfig.h
new file mode 100644
index 0000000..de55150
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysCntmrConfig.h
@@ -0,0 +1,36 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysCntmrConfig.h - Marvell Counter Manager unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for counter manager registers.
+*/
+#define MV_CNTMR_REGS_BASE		(MV_CNTMR_REGS_OFFSET)
diff --git a/arch/arm/mach-armadaxp/config/mvSysDdrConfig.h b/arch/arm/mach-armadaxp/config/mvSysDdrConfig.h
new file mode 100644
index 0000000..8332ebd
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysDdrConfig.h
@@ -0,0 +1,45 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysDdrConfig.h - Marvell DRAM controller unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for DDR registers.
+*/
+#define MV_DDR_WIN_REGS_BASE		(MV_MBUS_REGS_OFFSET)
+#define MV_DDR_CTRL_REGS_BASE		(MV_DRAM_REGS_OFFSET)
+
+/* used for ddr2 "bak" files */
+#define MV_DDR_REGS_BASE		(MV_DRAM_REGS_OFFSET)
+
+#ifndef MV_BOOTROM
+#define MV_STATIC_DRAM_ON_BOARD
+#endif
+
diff --git a/arch/arm/mach-armadaxp/config/mvSysEthConfig.h b/arch/arm/mach-armadaxp/config/mvSysEthConfig.h
new file mode 100644
index 0000000..c6757da
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysEthConfig.h
@@ -0,0 +1,151 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysEthConfig.h - Marvell Ethernet unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#ifndef __mvSysEthConfig_h__
+#define __mvSysEthConfig_h__
+
+#include "mvSysHwConfig.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+
+/*
+** Base address for ethernet registers.
+*/
+#ifdef CONFIG_MV_PON
+#define MV_PON_PORT(p)		((p) == MV_PON_PORT_ID)
+#define MV_PON_REG_BASE         MV_PON_REGS_OFFSET
+#define MV_ETH_REGS_BASE(p)	(MV_PON_PORT(p) ? MV_PON_REGS_OFFSET : MV_ETH_REGS_OFFSET(p))
+#else
+#define MV_PON_PORT(p)		MV_FALSE
+#define MV_ETH_REGS_BASE(p)	MV_ETH_REGS_OFFSET(p)
+#endif /* CONFIG_MV_PON */ 
+
+#define MV_BM_REG_BASE		MV_BM_REGS_OFFSET
+#define MV_PNC_REG_BASE         MV_PNC_REGS_OFFSET
+#define MV_ETH_COMPLEX_BASE	(MV_ETH_COMPLEX_OFFSET)
+
+#if defined(CONFIG_MV_INCLUDE_GIG_ETH)
+
+/* put descriptors in uncached memory */
+/* #define ETH_DESCR_UNCACHED */
+
+/* port's default queueus */
+#define ETH_DEF_RXQ         0  
+
+#ifdef CONFIG_MV_ETH_LEGACY 
+
+#ifdef CONFIG_MV_NFP_STATS
+#define MV_FP_STATISTICS
+#else
+#undef MV_FP_STATISTICS
+#endif
+
+/* Default configuration for TX_EN workaround: 0 - Disabled, 1 - Enabled */
+#define MV_ETH_TX_EN_DEFAULT        0
+
+/* un-comment if you want to perform tx_done from within the poll function */
+/* #define ETH_TX_DONE_ISR */
+
+/* Descriptors location: DRAM/internal-SRAM */
+#define ETH_DESCR_IN_SDRAM
+#undef  ETH_DESCR_IN_SRAM    /* No integrated SRAM in 88Fxx81 devices */
+
+#if defined(ETH_DESCR_IN_SRAM)
+#if defined(ETH_DESCR_UNCACHED)
+ #define ETH_DESCR_CONFIG_STR    "Uncached descriptors in integrated SRAM"
+#else
+ #define ETH_DESCR_CONFIG_STR    "Cached descriptors in integrated SRAM"
+#endif
+#elif defined(ETH_DESCR_IN_SDRAM)
+#if defined(ETH_DESCR_UNCACHED)
+ #define ETH_DESCR_CONFIG_STR    "Uncached descriptors in DRAM"
+#else
+ #define ETH_DESCR_CONFIG_STR    "Cached descriptors in DRAM"
+#endif
+#else 
+ #error "Ethernet descriptors location undefined"
+#endif /* ETH_DESCR_IN_SRAM or ETH_DESCR_IN_SDRAM*/
+
+/* SW Sync-Barrier: not relevant for 88fxx81*/
+/* Reasnable to define this macro when descriptors in SRAM and buffers in DRAM */
+/* In RX the CPU theoretically might see himself as the descriptor owner,      */
+/* although the buffer hadn't been written to DRAM yet. Performance cost.      */
+/* #define INCLUDE_SYNC_BARR */
+
+/* Buffers cache coherency method (buffers in DRAM) */
+#ifndef MV_CACHE_COHER_SW
+/* Taken from mvCommon.h */
+/* Memory uncached, HW or SW cache coherency is not needed */
+#define MV_UNCACHED             0   
+/* Memory cached, HW cache coherency supported in WriteThrough mode */
+#define MV_CACHE_COHER_HW_WT    1
+/* Memory cached, HW cache coherency supported in WriteBack mode */
+#define MV_CACHE_COHER_HW_WB    2
+/* Memory cached, No HW cache coherency, Cache coherency must be in SW */
+#define MV_CACHE_COHER_SW       3
+
+#endif
+
+#define ETHER_DRAM_COHER    MV_CACHE_COHER_SW   /* No HW coherency in 88Fxx81 devices */
+
+#if (ETHER_DRAM_COHER == MV_CACHE_COHER_HW_WB)
+ #define ETH_SDRAM_CONFIG_STR    "DRAM HW cache coherency (write-back)"
+#elif (ETHER_DRAM_COHER == MV_CACHE_COHER_HW_WT)
+ #define ETH_SDRAM_CONFIG_STR    "DRAM HW cache coherency (write-through)"
+#elif (ETHER_DRAM_COHER == MV_CACHE_COHER_SW)
+ #define ETH_SDRAM_CONFIG_STR    "DRAM SW cache-coherency"
+#elif (ETHER_DRAM_COHER == MV_UNCACHED)
+#   define ETH_SDRAM_CONFIG_STR  "DRAM uncached"
+#else
+ #error "Ethernet-DRAM undefined"
+#endif /* ETHER_DRAM_COHER */
+
+
+/****************************************************************/
+/************* Ethernet driver configuration ********************/
+/****************************************************************/
+
+/* port's default queueus */
+#define ETH_DEF_TXQ         0
+
+#define MV_ETH_RX_Q_NUM     CONFIG_MV_ETH_RXQ
+#define MV_ETH_TX_Q_NUM     CONFIG_MV_ETH_TXQ
+
+/* interrupt coalescing setting */
+#define ETH_TX_COAL    		    200
+#define ETH_RX_COAL    		    200
+
+/* Checksum offloading */
+#define TX_CSUM_OFFLOAD
+#define RX_CSUM_OFFLOAD
+#endif /* CONFIG_MV_ETH_LEGACY */
+
+#endif /* CONFIG_MV_INCLUDE_GIG_ETH */
+
+#endif /* __mvSysEthConfig_h__ */
diff --git a/arch/arm/mach-armadaxp/config/mvSysEthPhyConfig.h b/arch/arm/mach-armadaxp/config/mvSysEthPhyConfig.h
new file mode 100644
index 0000000..74cc239
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysEthPhyConfig.h
@@ -0,0 +1,32 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysEthPhyConfig.h - Marvell Ethernet-PHY specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
diff --git a/arch/arm/mach-armadaxp/config/mvSysGppConfig.h b/arch/arm/mach-armadaxp/config/mvSysGppConfig.h
new file mode 100644
index 0000000..630d523
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysGppConfig.h
@@ -0,0 +1,37 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysGppConfig.h - Marvell GPP unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for GPP registers.
+*/
+#define MV_GPP_REGS_BASE(unit)		(MV_GPP_REGS_OFFSET(unit))
+#define MV_GPP_REGS_BASE_0		(MV_GPP_REGS_OFFSET(0))
diff --git a/arch/arm/mach-armadaxp/config/mvSysHwConfig.h b/arch/arm/mach-armadaxp/config/mvSysHwConfig.h
new file mode 100644
index 0000000..c6d6f6d
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysHwConfig.h
@@ -0,0 +1,267 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysHwCfg.h - Marvell system HW configuration file
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#ifndef __INCmvSysHwConfigh
+#define __INCmvSysHwConfigh
+
+#define CONFIG_MARVELL	1
+
+/* includes */
+#define _1K         0x00000400
+#define _4K         0x00001000
+#define _8K         0x00002000
+#define _16K        0x00004000
+#define _32K        0x00008000
+#define _64K        0x00010000
+#define _128K       0x00020000
+#define _256K       0x00040000
+#define _512K       0x00080000
+
+#define _1M         0x00100000
+#define _2M         0x00200000
+#define _4M         0x00400000
+#define _8M         0x00800000
+#define _16M        0x01000000
+#define _32M        0x02000000
+#define _64M        0x04000000
+#define _128M       0x08000000
+#define _256M       0x10000000
+#define _512M       0x20000000
+
+#define _1G         0x40000000
+#define _2G         0x80000000
+
+/****************************************/
+/* Soc supporeted Units definitions	*/
+/****************************************/
+
+#ifdef CONFIG_MV_INCLUDE_PEX
+#define MV_INCLUDE_PEX
+
+#ifdef CONFIG_MV_PEX_0_4X1
+#define MV_PEX_0_4X1		1
+#define MV_PEX_0_1X4		0
+#endif
+#ifdef CONFIG_MV_PEX_0_1X4
+#define MV_PEX_0_4X1		0
+#define MV_PEX_0_1X4		1
+#endif
+
+#ifdef CONFIG_MV_PEX_1_4X1
+#define MV_PEX_1_4X1		1
+#define MV_PEX_1_1X4		0
+#endif
+#ifdef CONFIG_MV_PEX_1_1X4
+#define MV_PEX_1_4X1		0
+#define MV_PEX_1_1X4		1
+#endif
+
+#ifdef CONFIG_MV_PEX_2_4X1
+#define MV_PEX_2_4X1		1
+#endif
+
+#ifdef CONFIG_MV_PEX_3_4X1
+#define MV_PEX_3_4X1		1
+#endif
+
+#endif /* CONFIG_MV_INCLUDE_PEX */
+
+#ifdef CONFIG_MV_INCLUDE_PCI
+#define MV_INCLUDE_PCI
+#endif
+
+#ifdef CONFIG_MV_INCLUDE_TWSI
+#define MV_INCLUDE_TWSI
+#endif
+#ifdef CONFIG_MV_INCLUDE_CESA
+#define MV_INCLUDE_CESA
+#endif
+#ifdef CONFIG_MV_INCLUDE_GIG_ETH
+#define MV_INCLUDE_GIG_ETH
+#endif
+#ifdef CONFIG_MV_INCLUDE_INTEG_SATA
+#define MV_INCLUDE_INTEG_SATA
+#define MV_INCLUDE_SATA
+#endif
+#ifdef CONFIG_MV_INCLUDE_USB
+#define MV_INCLUDE_USB
+//#define MV_USB_VOLTAGE_FIX
+#endif
+#ifdef CONFIG_MV_INCLUDE_LEGACY_NAND
+#define MV_INCLUDE_LEGACY_NAND
+#endif
+#ifdef CONFIG_MV_INCLUDE_TDM
+#define MV_INCLUDE_TDM
+#endif
+#ifdef CONFIG_MV_INCLUDE_XOR
+#define MV_INCLUDE_XOR
+#endif
+#ifdef CONFIG_MV_INCLUDE_TWSI
+#define MV_INCLUDE_TWSI
+#endif
+#ifdef CONFIG_MV_INCLUDE_UART
+#define MV_INCLUDE_UART
+#endif
+#ifdef CONFIG_MV_INCLUDE_SPI
+#define MV_INCLUDE_SPI
+#endif
+#ifdef CONFIG_MV_INCLUDE_NOR
+#define MV_INCLUDE_NOR
+#endif
+#ifdef CONFIG_MV_INCLUDE_SFLASH_MTD
+#define MV_INCLUDE_SFLASH_MTD
+#endif
+#ifdef CONFIG_MV_INCLUDE_AUDIO
+#define MV_INCLUDE_AUDIO
+#endif
+#ifdef CONFIG_MV_INCLUDE_TS
+#define MV_INCLUDE_TS
+#endif
+#ifdef CONFIG_MV_INCLUDE_SDIO
+#define MV_INCLUDE_SDIO
+#endif
+#ifdef CONFIG_MTD_NAND_LNC_BOOT
+#define MTD_NAND_LNC_BOOT
+#endif
+#ifdef CONFIG_MTD_NAND_LNC
+#define MTD_NAND_LNC
+#endif
+#ifdef CONFIG_MTD_NAND_NFC
+#define MTD_NAND_NFC
+#endif
+#ifdef CONFIG_MV_INCLUDE_PDMA
+#define MV_INCLUDE_PDMA
+#endif
+#ifdef CONFIG_MV_SPI_BOOT
+#define MV_SPI_BOOT
+#endif
+#ifdef CONFIG_AURORA_IO_CACHE_COHERENCY
+#define AURORA_IO_CACHE_COHERENCY
+#endif
+
+/* convert Definitions for Errata used in the HAL */
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_4413
+#define SHEEVA_ERRATA_ARM_CPU_4413
+#endif
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_BTS61
+#define SHEEVA_ERRATA_ARM_CPU_BTS61
+#endif
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_4611
+#define SHEEVA_ERRATA_ARM_CPU_4611
+#endif
+
+/****************************************************************/
+/************* General    configuration ********************/
+/****************************************************************/
+
+/* Enable Clock Power Control */
+#define MV_INCLUDE_CLK_PWR_CNTRL
+
+/* Disable the DEVICE BAR in the PEX */
+#define MV_DISABLE_PEX_DEVICE_BAR
+
+/* Allow the usage of early printings during initialization */
+#define MV_INCLUDE_EARLY_PRINTK
+
+/****************************************************************/
+/************* NFP configuration ********************************/
+/****************************************************************/
+#define MV_NFP_SEC_Q_SIZE		64
+#define MV_NFP_SEC_REQ_Q_SIZE		1000
+
+
+
+/****************************************************************/
+/************* CESA configuration ********************/
+/****************************************************************/
+
+#ifdef MV_INCLUDE_CESA
+
+#define MV_CESA_MAX_CHAN               4
+
+/* Use 2K of SRAM */
+#define MV_CESA_MAX_BUF_SIZE           1600
+
+#endif /* MV_INCLUDE_CESA */
+
+/* DRAM cache coherency configuration */
+#define MV_CACHE_COHERENCY  MV_CACHE_COHER_SW
+
+
+
+/****************************************************************/
+/*************** Telephony configuration ************************/
+/****************************************************************/
+#if defined(CONFIG_MV_TDM_LINEAR_MODE)
+ #define MV_TDM_LINEAR_MODE
+#elif defined(CONFIG_MV_TDM_ULAW_MODE)
+ #define MV_TDM_ULAW_MODE
+#endif
+
+#if defined(CONFIG_MV_TDM_5CHANNELS)
+ #define MV_TDM_5CHANNELS 
+#endif
+
+#if defined(CONFIG_MV_TDM_USE_EXTERNAL_PCLK_SOURCE)
+ #define MV_TDM_USE_EXTERNAL_PCLK_SOURCE
+#endif
+
+/* We use the following registers to store DRAM interface pre configuration   */
+/* auto-detection results													  */
+/* IMPORTANT: We are using mask register for that purpose. Before writing     */
+/* to units mask register, make sure main maks register is set to disable     */
+/* all interrupts.                                                            */
+#define DRAM_BUF_REG0   0x30810 /* sdram bank 0 size            */  
+#define DRAM_BUF_REG1   0x30820 /* sdram config                 */
+#define DRAM_BUF_REG2   0x30830 /* sdram mode                   */
+#define DRAM_BUF_REG3   0x308c4 /* dunit control low            */          
+#define DRAM_BUF_REG4   0x60a90 /* sdram address control        */
+#define DRAM_BUF_REG5   0x60a94 /* sdram timing control low     */
+#define DRAM_BUF_REG6   0x60a98 /* sdram timing control high    */
+#define DRAM_BUF_REG7   0x60a9c /* sdram ODT control low        */
+#define DRAM_BUF_REG8   0x60b90 /* sdram ODT control high       */
+#define DRAM_BUF_REG9   0x60b94 /* sdram Dunit ODT control      */
+#define DRAM_BUF_REG10  0x60b98 /* sdram Extended Mode          */
+#define DRAM_BUF_REG11  0x60b9c /* sdram Ddr2 Time Low Reg      */
+#define DRAM_BUF_REG12  0x60a00 /* sdram Ddr2 Time High Reg     */
+#define DRAM_BUF_REG13  0x60a04 /* dunit Ctrl High              */
+#define DRAM_BUF_REG14  0x60b00 /* sdram second DIMM exist      */
+
+/* Following the pre-configuration registers default values restored after    */
+/* auto-detection is done                                                     */
+#define DRAM_BUF_REG_DV 0
+
+/* DRAM detection stuff */
+#define MV_DRAM_AUTO_SIZE
+
+/* Default FPGA Clock */
+#define MV_FPGA_CLK	25000000
+#endif /* __INCmvSysHwConfigh */
+
diff --git a/arch/arm/mach-armadaxp/config/mvSysNfcConfig.h b/arch/arm/mach-armadaxp/config/mvSysNfcConfig.h
new file mode 100644
index 0000000..858497a
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysNfcConfig.h
@@ -0,0 +1,36 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysSpiConfig.h - Marvell SPI unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for SPI registers.
+*/
+#define MV_NFC_REGS_BASE		(MV_NFC_REGS_OFFSET)
diff --git a/arch/arm/mach-armadaxp/config/mvSysPciConfig.h b/arch/arm/mach-armadaxp/config/mvSysPciConfig.h
new file mode 100644
index 0000000..2783d1a
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysPciConfig.h
@@ -0,0 +1,26 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for Pex registers.
+*/
+#define MV_PCI_IF_REGS_BASE(pciIf) 		(MV_PEX_IF_REGS_OFFSET(pciIf))
+
diff --git a/arch/arm/mach-armadaxp/config/mvSysPexConfig.h b/arch/arm/mach-armadaxp/config/mvSysPexConfig.h
new file mode 100644
index 0000000..14a5292
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysPexConfig.h
@@ -0,0 +1,50 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysPciIfConfig.h - Marvell PCI / Pex units specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for Pex registers.
+*/
+#define MV_PEX_IF_REGS_BASE(unit) 		(MV_PEX_IF_REGS_OFFSET(unit))
+
+/* PEX Work arround */
+/* the target we will use for the workarround */
+#define PEX_CONFIG_RW_WA_TARGET PEX0_MEM
+/*a flag that indicates if we are going to use the 
+size and base of the target we using for the workarround
+window */
+#define PEX_CONFIG_RW_WA_USE_ORIGINAL_WIN_VALUES 1
+/* if the above flag is 0 then the following values
+will be used for the workarround window base and size,
+otherwise the following defines will be ignored */
+#define PEX_CONFIG_RW_WA_BASE 0xF3000000
+#define PEX_CONFIG_RW_WA_SIZE _16M
+
diff --git a/arch/arm/mach-armadaxp/config/mvSysPonConfig.h b/arch/arm/mach-armadaxp/config/mvSysPonConfig.h
new file mode 100644
index 0000000..7701866
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysPonConfig.h
@@ -0,0 +1,38 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysDdrConfig.h - Marvell DRAM controller unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for PON registers.
+*/
+#define MV_EPON_MAC_REGS_BASE		(MV_GPON_MAC_REGS_OFFSET)
+#define MV_GPON_MAC_REGS_BASE		(MV_GPON_MAC_REGS_OFFSET)
+
diff --git a/arch/arm/mach-armadaxp/config/mvSysRtcConfig.h b/arch/arm/mach-armadaxp/config/mvSysRtcConfig.h
new file mode 100644
index 0000000..38a3b54
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysRtcConfig.h
@@ -0,0 +1,36 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysRtcConfig.h - Marvell Real-Time clock unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for RTC registers.
+*/
+#define MV_RTC_REGS_BASE		(MV_RTC_REGS_OFFSET)
diff --git a/arch/arm/mach-armadaxp/config/mvSysSataConfig.h b/arch/arm/mach-armadaxp/config/mvSysSataConfig.h
new file mode 100644
index 0000000..057b5a7
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysSataConfig.h
@@ -0,0 +1,36 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysSataConfig.h - Marvell Sata unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for SPI registers.
+*/
+#define MV_SATA_REGS_BASE		(MV_SATA_REGS_OFFSET)
diff --git a/arch/arm/mach-armadaxp/config/mvSysSdmmcConfig.h b/arch/arm/mach-armadaxp/config/mvSysSdmmcConfig.h
new file mode 100644
index 0000000..e5a4d3b
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysSdmmcConfig.h
@@ -0,0 +1,37 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysSdmmcConfig.h - Marvell SDMMC unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for audio registers.
+*/
+#define MV_SDMMC_REGS_BASE		(MV_SDMMC_REGS_OFFSET)
+
diff --git a/arch/arm/mach-armadaxp/config/mvSysSpiConfig.h b/arch/arm/mach-armadaxp/config/mvSysSpiConfig.h
new file mode 100644
index 0000000..a13c1a4
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysSpiConfig.h
@@ -0,0 +1,36 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysSpiConfig.h - Marvell SPI unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for SPI registers.
+*/
+#define MV_SPI_REGS_BASE(unit)		(MV_SPI_REGS_OFFSET(unit))
diff --git a/arch/arm/mach-armadaxp/config/mvSysTdmConfig.h b/arch/arm/mach-armadaxp/config/mvSysTdmConfig.h
new file mode 100644
index 0000000..7946fdf
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysTdmConfig.h
@@ -0,0 +1,68 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysTdmConfig.h - Marvell TDM unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+#include "mvOs.h"
+
+/****************************************************************/
+/*************** Telephony configuration ************************/
+/****************************************************************/
+#if defined(CONFIG_MV_TDM_SUPPORT)
+	#define MV_TDM_SUPPORT
+	#define MV_TDM_REGS_BASE	MV_TDM_REGS_OFFSET
+#elif defined(CONFIG_MV_COMM_UNIT_SUPPORT)
+	#define MV_COMM_UNIT_SUPPORT
+	#define MV_COMM_UNIT_REGS_BASE	MV_COMM_UNIT_REGS_OFFSET
+#endif
+
+/* SLIC vendor */
+#if defined(CONFIG_SILABS_SLIC_SUPPORT)
+	#define SILABS_SLIC_SUPPORT
+	#if defined(CONFIG_SILABS_SLIC_3215)
+		#define SILABS_SLIC_3215
+	#elif defined(CONFIG_SILABS_SLIC_3217)
+		#define SILABS_SLIC_3217
+	#endif
+#elif defined(CONFIG_ZARLINK_SLIC_SUPPORT)
+	#define ZARLINK_SLIC_SUPPORT
+	#if defined(CONFIG_ZARLINK_SLIC_VE880)
+		#define ZARLINK_SLIC_VE880
+		#define SLIC_TIMER_EVENT_SUPPORT
+	#elif defined(CONFIG_ZARLINK_SLIC_VE792)
+		#define ZARLINK_SLIC_VE792
+	#endif
+#else
+	#define SILABS_SLIC_3215_OLD_SUPPORT
+#endif
+
+#if defined(CONFIG_MV_TDM_USE_EXTERNAL_PCLK_SOURCE)
+ #define MV_TDM_USE_EXTERNAL_PCLK_SOURCE
+#endif
diff --git a/arch/arm/mach-armadaxp/config/mvSysTsConfig.h b/arch/arm/mach-armadaxp/config/mvSysTsConfig.h
new file mode 100644
index 0000000..be94e0a
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysTsConfig.h
@@ -0,0 +1,39 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysTsConfig.h - Marvell TS unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for TS registers.
+*/
+#define MV_TSU_GLOBAL_REGS_BASE		(MV_TSU_GLOBAL_REGS_OFFSET)
+#define MV_TSU_REGS_BASE(port)		(MV_TSU_REGS_OFFSET(port))
+
+
diff --git a/arch/arm/mach-armadaxp/config/mvSysTwsiConfig.h b/arch/arm/mach-armadaxp/config/mvSysTwsiConfig.h
new file mode 100644
index 0000000..6c9772d
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysTwsiConfig.h
@@ -0,0 +1,41 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysTwsiConfig.h - Marvell TWSI unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+/*
+** Base address for TWSI registers.
+*/
+#define MV_TWSI_SLAVE_REGS_BASE(unit) 	(MV_TWSI_SLAVE_REGS_OFFSET(unit))
+
+/*
+** Specific definition for Main CPU interrupt cause register.
+** Needed for TWSI operation completion monitoring.
+*/
+#define MV_TWSI_CPU_MAIN_INT_CAUSE(chNum, cpu)	TWSI_CPU_MAIN_INT_CAUSE_REG(cpu)
diff --git a/arch/arm/mach-armadaxp/config/mvSysUsbConfig.h b/arch/arm/mach-armadaxp/config/mvSysUsbConfig.h
new file mode 100644
index 0000000..7c82f5c
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysUsbConfig.h
@@ -0,0 +1,36 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysUsbConfig.h - Marvell USB unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for USB registers.
+*/
+#define MV_USB_REGS_BASE(unit) 		(MV_USB_REGS_OFFSET(unit))
diff --git a/arch/arm/mach-armadaxp/config/mvSysXorConfig.h b/arch/arm/mach-armadaxp/config/mvSysXorConfig.h
new file mode 100644
index 0000000..4681653
--- /dev/null
+++ b/arch/arm/mach-armadaxp/config/mvSysXorConfig.h
@@ -0,0 +1,36 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+
+*******************************************************************************/
+/*******************************************************************************
+* mvSysXorConfig.h - Marvell XOR unit specific configurations
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#include "mvSysHwConfig.h"
+
+/*
+** Base address for XOR registers.
+*/
+#define MV_XOR_REGS_BASE(unit)		(MV_XOR_REGS_OFFSET(unit))
diff --git a/arch/arm/mach-armadaxp/core.c b/arch/arm/mach-armadaxp/core.c
new file mode 100644
index 0000000..4b3df6c
--- /dev/null
+++ b/arch/arm/mach-armadaxp/core.c
@@ -0,0 +1,1528 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <linux/device.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/sysdev.h>
+#include <linux/mbus.h>
+#include <asm/mach/time.h>
+#include <linux/clocksource.h>
+#include <mach/hardware.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/setup.h>
+#include <asm/mach-types.h>
+
+#include <asm/mach/arch.h>
+#include <asm/mach/flash.h>
+#include <asm/mach/irq.h>
+#include <asm/mach/map.h>
+#include <mach/system.h>
+
+#include <linux/tty.h>
+#include <linux/platform_device.h>
+#include <linux/serial_core.h>
+#include <linux/serial.h>
+#include <linux/serial_8250.h>
+#include <linux/serial_reg.h>
+#include <linux/ata_platform.h>
+#include <asm/serial.h>
+#include <plat/cache-aurora-l2.h>
+
+#include <mach/serial.h>
+
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "ctrlEnv/sys/mvCpuIf.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "mvDebug.h"
+#include "mvSysHwConfig.h"
+#include "pex/mvPexRegs.h"
+#include "cntmr/mvCntmr.h"
+#include "gpp/mvGpp.h"
+#include "plat/gpio.h"
+#include "cpu/mvCpu.h"
+
+#if defined(CONFIG_MV_INCLUDE_SDIO)
+#include "sdmmc/mvSdmmc.h"
+#include <plat/mvsdio.h>
+#endif
+#if defined(CONFIG_MV_INCLUDE_CESA)
+#include "cesa/mvCesa.h"
+#endif
+
+#include <plat/mv_xor.h>
+
+/* I2C */
+#include <linux/i2c.h>	
+#include <linux/mv643xx_i2c.h>
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+#include "ctrlEnv/mvCtrlEnvRegs.h"
+
+/* SPI */
+#include "mvSysSpiApi.h"
+
+/* Eth Phy */
+#include "mvSysEthPhyApi.h"
+
+/* LCD */
+#include <video/dovefb.h>
+#include <video/dovefbreg.h>
+#include <mach/dove_bl.h>
+
+/* NAND */
+#ifdef CONFIG_MTD_NAND_NFC
+#include "mv_mtd/nand_nfc.h"
+#endif
+
+#define MV_COHERENCY_FABRIC_CTRL_REG		(MV_COHERENCY_FABRIC_OFFSET + 0x0)
+#define MV_COHERENCY_FABRIC_CFG_REG		(MV_COHERENCY_FABRIC_OFFSET + 0x4)
+
+#ifdef CONFIG_FB_DOVE
+extern unsigned int lcd0_enable;
+extern int lcd_panel;
+#endif
+extern unsigned int irq_int_type[];
+extern void __init axp_map_io(void);
+extern void __init mv_init_irq(void);
+extern struct sys_timer axp_timer;
+extern MV_CPU_DEC_WIN* mv_sys_map(void);
+#if defined(CONFIG_MV_INCLUDE_CESA)
+extern u32 mv_crypto_virt_base_get(u8 chan);
+#endif
+extern void axp_init_irq(void);
+
+/* for debug putstr */
+static char arr[256];
+MV_U32 mvTclk = 166666667;
+MV_U32 mvSysclk = 200000000;
+
+#ifdef CONFIG_MV_INCLUDE_GIG_ETH
+MV_U8 mvMacAddr[CONFIG_MV_ETH_PORTS_NUM][6];
+MV_U16 mvMtu[CONFIG_MV_ETH_PORTS_NUM] = {0};
+#endif
+
+/*
+ * Helpers to get DDR bank info
+ */
+#define DDR_BASE_CS_OFF(n)	(0x0180 + ((n) << 3))
+#define DDR_SIZE_CS_OFF(n)	(0x0184 + ((n) << 3))
+#define TARGET_DDR		0
+#define COHERENCY_STATUS_SHARED_NO_L2_ALLOC	0x1
+
+struct mbus_dram_target_info armadaxp_mbus_dram_info;
+
+/* XOR0 is disabled in Z1 Silicone */
+#undef XOR0_ENABLE
+
+
+/*********************************************************************************/
+/**************                 Early Printk Support                **************/
+/*********************************************************************************/
+#ifdef MV_INCLUDE_EARLY_PRINTK
+#define MV_UART0_LSR 	(*(volatile unsigned char *)(INTER_REGS_BASE + 0x12000 + 0x14))
+#define MV_UART0_THR	(*(volatile unsigned char *)(INTER_REGS_BASE + 0x12000 + 0x0 ))	 
+#define MV_UART1_LSR    (*(volatile unsigned char *)(INTER_REGS_BASE + 0x12100 + 0x14))
+#define MV_UART1_THR    (*(volatile unsigned char *)(INTER_REGS_BASE + 0x12100 + 0x0 ))
+#define MV_SERIAL_BASE 	((unsigned char *)(INTER_REGS_BASE + 0x12000 + 0x0 ))
+#define DEV_REG		(*(volatile unsigned int *)(INTER_REGS_BASE + 0x40000))
+#define CLK_REG         (*(volatile unsigned int *)(INTER_REGS_BASE + 0x2011c))
+/*
+ * This does not append a newline
+ */
+static void putstr(const char *s)
+{
+	unsigned int model;
+	
+	/* Get dev ID, make sure pex clk is on */
+	if((CLK_REG & 0x4) == 0)
+	{
+		CLK_REG = CLK_REG | 0x4;
+		model = (DEV_REG >> 16) & 0xffff;
+		CLK_REG = CLK_REG & ~0x4;
+	}
+	else
+		model = (DEV_REG >> 16) & 0xffff;
+
+        while (*s) {
+		while ((MV_UART0_LSR & UART_LSR_THRE) == 0);
+		MV_UART0_THR = *s;
+		
+                if (*s == '\n') {
+                        while ((MV_UART0_LSR & UART_LSR_THRE) == 0); 
+                        MV_UART0_THR = '\r';
+                }
+                s++;
+        }
+}
+extern void putstr(const char *ptr);
+void mv_early_printk(char *fmt,...)
+{
+	va_list args;
+	va_start(args, fmt);
+	vsprintf(arr,fmt,args);
+	va_end(args);
+	putstr(arr);
+}
+#endif
+
+/*********************************************************************************/
+/**************               UBoot Tagging Parameters              **************/
+/*********************************************************************************/
+#ifdef CONFIG_BE8_ON_LE
+#define read_tag(a)    le32_to_cpu(a)
+#define read_mtu(a)    le16_to_cpu(a)
+#else
+#define read_tag(a)    a
+#define read_mtu(a)    a
+#endif
+
+extern MV_U32 gBoardId; 
+extern unsigned int elf_hwcap;
+extern u32 mvIsUsbHost;
+
+static int __init parse_tag_mv_uboot(const struct tag *tag)
+{
+    	unsigned int mvUbootVer = 0;
+	int i = 0;
+
+	printk("Using UBoot passing parameters structure\n");
+	mvUbootVer = read_tag(tag->u.mv_uboot.uboot_version);
+	mvIsUsbHost = read_tag(tag->u.mv_uboot.isUsbHost);
+	gBoardId =  (mvUbootVer & 0xff);
+
+#ifdef CONFIG_MV_INCLUDE_GIG_ETH
+	for (i = 0; i < CONFIG_MV_ETH_PORTS_NUM; i++) {
+#if defined (CONFIG_OVERRIDE_ETH_CMDLINE)
+		memset(mvMacAddr[i], 0, 6);
+		mvMtu[i] = 0;
+#else
+printk(">>>>>>>Tag MAC %02x:%02x:%02x:%02x:%02x:%02x\n", tag->u.mv_uboot.macAddr[i][5], tag->u.mv_uboot.macAddr[i][4],
+	tag->u.mv_uboot.macAddr[i][3], tag->u.mv_uboot.macAddr[i][2], tag->u.mv_uboot.macAddr[i][1], tag->u.mv_uboot.macAddr[i][0]);
+		memcpy(mvMacAddr[i], tag->u.mv_uboot.macAddr[i], 6);
+		mvMtu[i] = read_mtu(tag->u.mv_uboot.mtu[i]);
+#endif
+	}
+#endif
+
+#ifdef CONFIG_MV_NAND
+               /* get NAND ECC type(1-bit or 4-bit) */
+	if ((mvUbootVer >> 8) >= 0x3040c)
+		mv_nand_ecc = read_tag(tag->u.mv_uboot.nand_ecc);
+	else
+		mv_nand_ecc = 1; /* fallback to 1-bit ECC */
+#endif
+	return 0;
+}
+
+__tagtable(ATAG_MV_UBOOT, parse_tag_mv_uboot);
+
+/*********************************************************************************/
+/**************                Command Line Parameters              **************/
+/*********************************************************************************/
+#ifdef CONFIG_MV_INCLUDE_USB
+#include "mvSysUsbApi.h"
+/* Required to get the configuration string from the Kernel Command Line */
+static char *usb0Mode = "host";
+static char *usb1Mode = "host";
+static char *usb2Mode = "device";
+int mv_usb0_cmdline_config(char *s);
+int mv_usb1_cmdline_config(char *s);
+int mv_usb2_cmdline_config(char *s);
+__setup("usb0Mode=", mv_usb0_cmdline_config);
+__setup("usb1Mode=", mv_usb1_cmdline_config);
+__setup("usb2Mode=", mv_usb2_cmdline_config);
+
+int mv_usb0_cmdline_config(char *s)
+{
+    usb0Mode = s;
+    return 1;
+}
+
+int mv_usb1_cmdline_config(char *s)
+{
+    usb1Mode = s;
+    return 1;
+}
+
+int mv_usb2_cmdline_config(char *s)
+{
+    usb2Mode = s;
+    return 1;
+}
+#endif
+
+#ifdef CONFIG_CACHE_AURORA_L2
+static int noL2 = 0;
+static int __init noL2_setup(char *__unused)
+{
+     noL2 = 1;
+     return 1;
+}
+
+__setup("noL2", noL2_setup);
+#endif
+
+#ifndef CONFIG_SHEEVA_ERRATA_ARM_CPU_4948
+unsigned int l0_disable_flag = 0;		/* L0 Enabled by Default */
+static int __init l0_disable_setup(char *__unused)
+{
+     l0_disable_flag = 1;
+     return 1;
+}
+
+__setup("l0_disable", l0_disable_setup);
+#endif
+
+#ifndef CONFIG_SHEEVA_ERRATA_ARM_CPU_5315
+unsigned int sp_enable_flag = 0;		/* SP Disabled by Default */
+static int __init spec_prefesth_setup(char *__unused)
+{
+     sp_enable_flag = 1;
+     return 1;
+}
+
+__setup("sp_enable", spec_prefesth_setup);
+#endif
+
+#ifdef CONFIG_JTAG_DEBUG
+	MV_U32 support_wait_for_interrupt = 0x0;
+#else
+	MV_U32 support_wait_for_interrupt = 0x1;
+#endif
+static int __init noWFI_setup(char *__unused)
+{
+     support_wait_for_interrupt = 0;
+     return 1;
+}
+
+__setup("noWFI", noWFI_setup);
+
+MV_U32 support_Z1A_serdes_cfg = 0x0;
+static int __init serdesZ1A_setup(char *__unused)
+{
+     printk("Supporting Z1A Serdes Configurations.\n");
+     support_Z1A_serdes_cfg = 1;
+     return 1;
+}
+
+__setup("Z1A", serdesZ1A_setup);
+
+char *nfcConfig = NULL;
+static int __init nfcConfig_setup(char *s)
+{
+	nfcConfig = s;
+	return 1;
+}
+__setup("nfcConfig=", nfcConfig_setup);
+
+void __init armadaxp_setup_cpu_mbus(void)
+{
+	void __iomem *addr;
+	int i;
+	int cs;
+	u8	coherency_status = 0;
+#if defined(CONFIG_AURORA_IO_CACHE_COHERENCY)
+	coherency_status = COHERENCY_STATUS_SHARED_NO_L2_ALLOC;
+#endif
+
+	/*
+	 * Setup MBUS dram target info.
+	 */
+	armadaxp_mbus_dram_info.mbus_dram_target_id = TARGET_DDR;
+	addr = (void __iomem *)AXP_BRIDGE_VIRT_BASE;
+
+	for (i = 0, cs = 0; i < 4; i++) {
+		u32 base = readl(addr + DDR_BASE_CS_OFF(i));
+		u32 size = readl(addr + DDR_SIZE_CS_OFF(i));
+
+		/*
+		 * Chip select enabled?
+		 */
+		if (size & 1) {
+			struct mbus_dram_window *w;
+
+			w = &armadaxp_mbus_dram_info.cs[cs++];
+			w->cs_index = i;
+			w->mbus_attr = 0xf & ~(1 << i);
+			w->mbus_attr |= coherency_status << 4;
+			w->base = base & 0xff000000;
+			w->size = (size | 0x00ffffff) + 1;
+		}
+	}
+	armadaxp_mbus_dram_info.num_cs = cs;
+}
+
+/*********************************************************************************/
+/**************               I/O Devices Platform Info             **************/
+/*********************************************************************************/
+/*************
+ * I2C(TWSI) *
+ *************/
+static struct mv64xxx_i2c_pdata axp_i2c_pdata = {
+       .freq_m         = 8, /* assumes 166 MHz TCLK */
+       .freq_n         = 3,
+       .timeout        = 1000, /* Default timeout of 1 second */
+};
+
+static struct resource axp_i2c_0_resources[] = {
+	{
+		.name   = "i2c base",
+		.start  = INTER_REGS_PHYS_BASE + MV_TWSI_SLAVE_REGS_OFFSET(0),
+		.end    = INTER_REGS_PHYS_BASE + MV_TWSI_SLAVE_REGS_OFFSET(0) + 0x20 - 1,
+		.flags  = IORESOURCE_MEM,
+	},
+	{
+		.name   = "i2c irq",
+		.start  = IRQ_AURORA_I2C0,
+		.end    = IRQ_AURORA_I2C0,
+		.flags  = IORESOURCE_IRQ,
+	},
+};
+
+
+static struct resource axp_i2c_1_resources[] = {
+	{
+		.name   = "i2c base",
+		.start  = INTER_REGS_PHYS_BASE + MV_TWSI_SLAVE_REGS_OFFSET(1),
+		.end    = INTER_REGS_PHYS_BASE + MV_TWSI_SLAVE_REGS_OFFSET(1) + 0x20 - 1,
+		.flags  = IORESOURCE_MEM,
+	},
+	{
+		.name   = "i2c irq",
+		.start  = IRQ_AURORA_I2C1,
+		.end    = IRQ_AURORA_I2C1,
+		.flags  = IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device axp_i2c0 = {
+	.name           = MV64XXX_I2C_CTLR_NAME,
+	.id             = 0,
+	.num_resources  = ARRAY_SIZE(axp_i2c_0_resources),
+	.resource       = axp_i2c_0_resources,
+	.dev            = {
+		.platform_data = &axp_i2c_pdata,
+	},
+};
+
+static struct platform_device axp_i2c1 = {
+	.name           = MV64XXX_I2C_CTLR_NAME,
+	.id             = 1,
+	.num_resources  = ARRAY_SIZE(axp_i2c_1_resources),
+	.resource       = axp_i2c_1_resources,
+	.dev            = {
+		.platform_data = &axp_i2c_pdata,
+	},
+};
+/**********
+ * UART-0 *
+ **********/
+static struct plat_serial8250_port aurora_uart0_data[] = {
+	{
+		.mapbase	= (INTER_REGS_PHYS_BASE | MV_UART_REGS_OFFSET(0)),
+		.membase	= (char *)(INTER_REGS_BASE | MV_UART_REGS_OFFSET(0)),
+		.irq		= IRQ_AURORA_UART0,
+#if 0
+		.flags		= UPF_SKIP_TEST | UPF_BOOT_AUTOCONF,
+		.iotype		= UPIO_MEM,
+#else
+		.flags		= UPF_FIXED_TYPE | UPF_SKIP_TEST | UPF_BOOT_AUTOCONF,
+		.iotype		= UPIO_DWAPB,
+		.private_data	= (void *) (INTER_REGS_BASE | MV_UART_REGS_OFFSET(0) | 0x7C),
+		.type		= PORT_16550A,
+#endif
+		.regshift	= 2,
+		.uartclk	= 0,
+	}, {
+	},
+};
+
+static struct resource aurora_uart0_resources[] = {
+	{
+		.start		= (INTER_REGS_PHYS_BASE | MV_UART_REGS_OFFSET(0)),
+		.end		= (INTER_REGS_PHYS_BASE | MV_UART_REGS_OFFSET(0)) + SZ_256 - 1,
+		.flags		= IORESOURCE_MEM,
+	}, {
+		.start		= IRQ_AURORA_UART0,
+		.end		= IRQ_AURORA_UART0,
+		.flags		= IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device aurora_uart0 = {
+	.name			= "serial8250",
+	.id			= 0,
+	.dev			= {
+		.platform_data	= aurora_uart0_data,
+	},
+	.resource		= aurora_uart0_resources,
+	.num_resources		= ARRAY_SIZE(aurora_uart0_resources),
+};
+
+
+void __init serial_initialize(void)
+{
+	aurora_uart0_data[0].uartclk = mvBoardTclkGet();
+	platform_device_register(&aurora_uart0);
+}
+
+/********
+ * SDIO *
+ ********/
+#if defined(CONFIG_MV_INCLUDE_SDIO)
+static struct resource mvsdio_resources[] = {
+	[0] = {
+		.start	= INTER_REGS_PHYS_BASE + MV_SDMMC_REGS_OFFSET,
+		.end	= INTER_REGS_PHYS_BASE + MV_SDMMC_REGS_OFFSET + SZ_1K -1,
+		.flags	= IORESOURCE_MEM,
+	},
+	[1] = {
+		.start	= IRQ_AURORA_SDIO,
+		.end	= IRQ_AURORA_SDIO,
+		.flags	= IORESOURCE_IRQ,
+	},
+
+};
+
+static u64 mvsdio_dmamask = 0xffffffffUL;
+
+static struct mvsdio_platform_data mvsdio_data = {
+	.gpio_write_protect	= 0,
+	.gpio_card_detect	= 0,
+	.dram			= NULL,
+};
+
+static struct platform_device mv_sdio_plat = {
+	.name		= "mvsdio",
+	.id		= -1,
+	.dev		= {
+		.dma_mask = &mvsdio_dmamask,
+		.coherent_dma_mask = 0xffffffff,
+		.platform_data	= &mvsdio_data,
+	},
+	.num_resources	= ARRAY_SIZE(mvsdio_resources),
+	.resource	= mvsdio_resources,
+};
+#endif /* #if defined(CONFIG_MV_INCLUDE_SDIO) */
+
+/*******
+ * GBE *
+ *******/
+#ifdef CONFIG_MV_ETHERNET
+#if defined(CONFIG_MV_ETH_LEGACY)
+static struct platform_device mv88fx_eth = {
+	.name		= "mv88fx_eth",
+	.id		= 0,
+	.num_resources	= 0,
+};
+#elif defined(CONFIG_MV_ETH_NETA)
+static struct platform_device mv88fx_neta = {
+	.name		= "mv88fx_neta",
+	.id		= 0,
+	.num_resources	= 0,
+};
+#else
+#error "Ethernet Mode is not defined (should be Legacy or NETA)"
+#endif /* Ethernet mode: legacy or NETA */
+
+static void __init eth_init(void)
+{
+#if defined(CONFIG_MV_ETH_LEGACY)
+	platform_device_register(&mv88fx_eth);
+#elif defined(CONFIG_MV_ETH_NETA)
+	platform_device_register(&mv88fx_neta);
+#endif /* Ethernet mode: legacy or NETA */
+}
+
+#endif /* CONFIG_MV_ETHERNET */
+
+/*******
+ * RTC *
+ *******/
+static struct resource axp_rtc_resource[] = {
+	{
+		.start	= INTER_REGS_PHYS_BASE + MV_RTC_REGS_OFFSET,
+		.end	= INTER_REGS_PHYS_BASE + MV_RTC_REGS_OFFSET + 32 - 1,
+		.flags	= IORESOURCE_MEM,
+	}, {
+		.start	= IRQ_AURORA_RTC,
+		.flags	= IORESOURCE_IRQ,
+	}
+};
+
+static void __init rtc_init(void)
+{
+	platform_device_register_simple("rtc-mv", -1, axp_rtc_resource, 2);
+}
+
+/********
+ * SATA *
+ ********/
+#ifdef CONFIG_SATA_MV
+#define SATA_PHYS_BASE (INTER_REGS_PHYS_BASE | 0xA0000)
+#define IRQ_DSMP_SATA IRQ_AURORA_SATA0
+
+static struct mv_sata_platform_data dbdsmp_sata_data = {
+	.n_ports	= 2,
+};
+
+static struct resource armadaxp_sata_resources[] = {
+	{
+		.name	= "sata base",
+		.start	= SATA_PHYS_BASE,
+		.end	= SATA_PHYS_BASE + 0x5000 - 1,
+		.flags	= IORESOURCE_MEM,
+	}, {
+		.name	= "sata irq",
+		.start	= IRQ_DSMP_SATA,
+		.end	= IRQ_DSMP_SATA,
+		.flags	= IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device armadaxp_sata = {
+	.name		= "sata_mv",
+	.id		= 0,
+	.dev		= {
+		.coherent_dma_mask	= 0xffffffff,
+	},
+	.num_resources	= ARRAY_SIZE(armadaxp_sata_resources),
+	.resource	= armadaxp_sata_resources,
+};
+
+void __init armadaxp_sata_init(struct mv_sata_platform_data *sata_data)
+{
+
+	armadaxp_sata.dev.platform_data = sata_data;
+	sata_data->dram = &armadaxp_mbus_dram_info;
+	platform_device_register(&armadaxp_sata);
+}
+#endif
+/*****************************************************************************
+ * SoC hwmon Thermal Sensor
+ ****************************************************************************/
+void __init armadaxp_hwmon_init(void)
+{
+	platform_device_register_simple("axp-temp", 0, NULL, 0);
+}
+
+/*************
+ * 7-Segment *
+ *************/
+static struct timer_list axp_db_timer;
+static void axp_db_7seg_event(unsigned long data)
+{
+	static int count = 0;
+
+	/* Update the 7 segment */
+	mvBoardDebugLed(count);
+
+	/* Incremnt count and arm the timer*/
+	count = (count + 1) & 7;
+	mod_timer(&axp_db_timer, jiffies + 1 * HZ);
+}
+
+static int __init axp_db_7seg_init(void)
+{
+	/* Create the 7segment timer */
+	setup_timer(&axp_db_timer, axp_db_7seg_event, 0);
+
+	/* Arm it expire in 1 second */
+	mod_timer(&axp_db_timer, jiffies + 1 * HZ);
+
+	return 0;
+}
+__initcall(axp_db_7seg_init);
+
+#ifdef CONFIG_FB_DOVE
+/*****************************************************************************
+ * LCD
+ ****************************************************************************/
+
+/*
+ * LCD HW output Red[0] to LDD[0] when set bit [19:16] of reg 0x190
+ * to 0x0. Which means HW outputs BGR format default. All platforms
+ * uses this controller should enable .panel_rbswap. Unless layout
+ * design connects Blue[0] to LDD[0] instead.
+ */
+static struct dovefb_mach_info kw_lcd0_dmi = {
+	.id_gfx			= "GFX Layer 0",
+	.id_ovly		= "Video Layer 0",
+	.pix_fmt		= PIX_FMT_RGB888PACK,
+	.lcd_ref_clk		= 25000000,
+#if defined(CONFIG_FB_DOVE_CLCD_DCONB_BYPASS0)
+	.io_pin_allocation	= IOPAD_DUMB24,
+	.panel_rgb_type		= DUMB24_RGB888_0,
+#else
+	.io_pin_allocation      = IOPAD_DUMB24,
+	.panel_rgb_type         = DUMB24_RGB888_0,
+#endif
+	.panel_rgb_reverse_lanes = 0,
+	.gpio_output_data	= 3,
+	.gpio_output_mask	= 3,
+	.ddc_polling_disable	= 1,
+	.ddc_i2c_address	= 0x50,
+	.ddc_i2c_adapter	= 0,
+	.invert_composite_blank	= 0,
+	.invert_pix_val_ena	= 0,
+	.invert_pixclock	= 0,
+	.invert_vsync		= 0,
+	.invert_hsync		= 0,
+	.panel_rbswap		= 1,
+	.active			= 1,
+	.lvds_info = {
+		.lvds_24b_option = 1,
+		.lvds_tick_drv = 2
+	}
+};
+
+static struct dovefb_mach_info kw_lcd0_vid_dmi = {
+	.id_ovly		= "Video Layer 0",
+	.pix_fmt		= PIX_FMT_RGB888PACK,
+	.io_pin_allocation	= IOPAD_DUMB24,
+	.panel_rgb_type		= DUMB24_RGB888_0,
+	.panel_rgb_reverse_lanes = 0,
+	.gpio_output_data	= 3,
+	.gpio_output_mask	= 3,
+	.ddc_i2c_adapter	= -1,
+	.invert_composite_blank	= 0,
+	.invert_pix_val_ena	= 0,
+	.invert_pixclock	= 0,
+	.invert_vsync		= 0,
+	.invert_hsync		= 0,
+	.panel_rbswap		= 0,
+	.active			= 1,
+	.enable_lcd0		= 0,
+};
+
+/*****************************************************************************
+ * BACKLIGHT
+ ****************************************************************************/
+static struct dovebl_platform_data dsmp_backlight_data = {
+	.default_intensity = 0xa,
+	.gpio_pm_control = 1,
+
+	.lcd_start = LCD_PHYS_BASE,	/* lcd power control reg base. */
+	.lcd_end = LCD_PHYS_BASE+0x1C8,	/* end of reg map. */
+	.lcd_offset = LCD_SPU_DUMB_CTRL,/* register offset */
+	.lcd_mapped = 0,		/* va = 0, pa = 1 */
+	.lcd_mask = 0x0,		/* mask, bit[21] */
+	.lcd_on = 0x0,			/* value to enable lcd power */
+	.lcd_off = 0x0,			/* value to disable lcd power */
+
+	.blpwr_start = LCD_PHYS_BASE, /* bl pwr ctrl reg base. */
+	.blpwr_end = LCD_PHYS_BASE+0x1C8,/* end of reg map. */
+	.blpwr_offset = LCD_SPU_DUMB_CTRL,/* register offset */
+	.blpwr_mapped = 0,		/* pa = 0, va = 1 */
+	.blpwr_mask = 0x0,		/* mask */
+	.blpwr_on = 0x0,		/* value to enable bl power */
+	.blpwr_off = 0x0,		/* value to disable bl power */
+
+	.btn_start = LCD_PHYS_BASE, /* brightness control reg base. */
+	.btn_end = LCD_PHYS_BASE+0x1C8,	/* end of reg map. */
+	.btn_offset = LCD_CFG_GRA_PITCH,	/* register offset */
+	.btn_mapped = 0,		/* pa = 0, va = 1 */
+	.btn_mask = 0xF0000000,	/* mask */
+	.btn_level = 15,	/* how many level can be configured. */
+	.btn_min = 0x1,	/* min value */
+	.btn_max = 0xF,	/* max value */
+	.btn_inc = 0x1,	/* increment */
+};
+
+#endif /* CONFIG_FB_DOVE */
+
+#ifdef CONFIG_MTD_NAND_NFC
+/*****************************************************************************
+ * NAND controller
+ ****************************************************************************/
+static struct resource axp_nfc_resources[] = {
+	{
+		.start  = INTER_REGS_BASE + MV_NFC_REGS_OFFSET,
+		.end    = INTER_REGS_BASE + MV_NFC_REGS_OFFSET + 0x400 -1,
+		.flags  = IORESOURCE_MEM,
+	}
+};
+
+
+static struct mtd_partition nand_parts_info[] = {
+	{
+		.name		= "UBoot",
+		.offset		= 0,
+		.size		= 1 * SZ_1M
+	},
+	{
+		.name		= "UImage",
+		.offset	= MTDPART_OFS_APPEND,
+		.size		= 4 * SZ_1M },
+	{
+		.name		= "Root",
+		.offset	= MTDPART_OFS_APPEND,
+		.size         = MTDPART_SIZ_FULL
+	},
+};
+
+
+static struct nfc_platform_data axp_nfc_data = {
+	.nfc_width	= 8,
+	.num_devs	= 1,
+	.num_cs		= 1,
+	.use_dma	= 0,
+	.ecc_type	= MV_NFC_ECC_BCH_2K,
+	.parts		= nand_parts_info,
+	.nr_parts	= ARRAY_SIZE(nand_parts_info),
+};
+
+static struct platform_device axp_nfc = {
+	.name           = "armada-nand",
+	.id             = 0,
+	.dev            = {
+							.platform_data = &axp_nfc_data,
+						},
+	.num_resources  = ARRAY_SIZE(axp_nfc_resources),
+	.resource       = axp_nfc_resources,
+
+};
+
+static void __init axp_db_nfc_init(void)
+{
+	/* Check for ganaged mode */
+	if (nfcConfig) {
+		if (strncmp(nfcConfig, "ganged", 6) == 0) {
+			axp_nfc_data.nfc_width = 16;
+			axp_nfc_data.num_devs = 2;
+			nfcConfig += 7;
+		}
+
+		/* Check for ECC type directive */
+		if (strcmp(nfcConfig, "8bitecc") == 0) {
+			axp_nfc_data.ecc_type = MV_NFC_ECC_BCH_1K;
+		} else if (strcmp(nfcConfig, "12bitecc") == 0) {
+			axp_nfc_data.ecc_type = MV_NFC_ECC_BCH_704B;
+		} else if (strcmp(nfcConfig, "16bitecc") == 0) {
+			axp_nfc_data.ecc_type = MV_NFC_ECC_BCH_512B;
+		}
+	}
+
+	axp_nfc_data.tclk = mvBoardTclkGet();
+
+	platform_device_register(&axp_nfc);
+}
+#endif
+/*********************************************************************************/
+/**************                      Helper Routines                **************/
+/*********************************************************************************/
+#ifdef CONFIG_MV_INCLUDE_CESA
+unsigned char*  mv_sram_usage_get(int* sram_size_ptr)
+{
+	int used_size = 0;
+
+#if defined(CONFIG_MV_CESA)
+	used_size = sizeof(MV_CESA_SRAM_MAP);
+#endif
+
+	if(sram_size_ptr != NULL)
+		*sram_size_ptr = _8K - used_size;
+
+	return (char *)(mv_crypto_virt_base_get(0) + used_size);
+}
+#endif
+
+void print_board_info(void)
+{
+	char name_buff[50];
+	printk("\n");
+	printk("  Marvell Armada-XP");
+
+	mvBoardNameGet(name_buff);
+	printk(" %s Board - ",name_buff);
+
+	mvCtrlModelRevNameGet(name_buff);
+	printk(" Soc: %s",  name_buff);
+#if defined(MV_CPU_LE)
+	printk(" LE\n");
+#else
+	printk(" BE\n");
+#endif
+	printk("  Detected Tclk %d, SysClk %d, FabricClk %d, PClk %d\n",mvTclk, mvSysclk, mvCpuL2ClkGet(), mvCpuPclkGet());
+	printk("  LSP version: %s\n", LSP_VERSION);
+	printk("\n");
+}
+
+#ifdef	CONFIG_AURORA_IO_CACHE_COHERENCY
+static void io_coherency_init(void)
+{
+	MV_U32 reg;
+
+	/* set CIB read snoop command to ReadUnique */
+	reg = MV_REG_READ(MV_CIB_CTRL_CFG_REG);
+	reg &= ~(7 << 16);
+	reg |= (7 << 16);
+	MV_REG_WRITE(MV_CIB_CTRL_CFG_REG, reg);
+
+#ifndef CONFIG_SMP 
+        /* enable CPUs in SMP group on Fabric coherency */
+	reg = MV_REG_READ(MV_COHERENCY_FABRIC_CTRL_REG);
+	reg &= ~(0x3<<24);
+	reg |= 1<<24;
+	MV_REG_WRITE(MV_COHERENCY_FABRIC_CTRL_REG, reg);
+
+	reg = MV_REG_READ(MV_COHERENCY_FABRIC_CFG_REG);
+	reg &= ~(0x3<<24);
+	reg |= 1<<24;
+	MV_REG_WRITE(MV_COHERENCY_FABRIC_CFG_REG, reg);
+#endif
+}
+#endif
+
+#ifdef CONFIG_DEBUG_LL
+extern void printascii(const char *);
+static void check_cpu_mode(void)
+{
+                u32 cpu_id_code_ext;
+                int cpu_mode = 0;
+                asm volatile("mrc p15, 1, %0, c15, c12, 0": "=r"(cpu_id_code_ext));
+
+                if (((cpu_id_code_ext >> 16) & 0xF) == 0x2)
+                        cpu_mode = 6;
+                else if (((cpu_id_code_ext >> 16) & 0xF) == 0x3)
+                        cpu_mode = 7;
+                else 
+                        pr_err("unknow cpu mode!!!\n");
+#ifdef CONFIG_DEBUGGER_MODE_V6
+		if (cpu_mode != 6) {
+			printascii("cpu mode (ARMv7) doesn't mach kernel configuration\n");
+			panic("cpu mode mismatch");
+		}
+#else
+#ifdef CONFIG_CPU_V7
+                if (cpu_mode != 7) {
+                        printascii("cpu mode (ARMv6) doesn't mach kernel configuration\n");
+                        panic("cpu mode mismatch");
+                }
+#endif
+#endif
+	printk("Aurora: Working in ARMv%d mode\n",cpu_mode);
+}
+#endif
+
+/*****************************************************************************
+ * XOR
+ ****************************************************************************/
+static struct mv_xor_platform_shared_data armadaxp_xor_shared_data = {
+	.dram		= &armadaxp_mbus_dram_info,
+};
+
+static u64 armadaxp_xor_dmamask = DMA_BIT_MASK(32);
+
+/*****************************************************************************
+ * XOR0
+ ****************************************************************************/
+#ifdef XOR0_ENABLE
+static struct resource armadaxp_xor0_shared_resources[] = {
+	{
+		.name	= "xor 0 low",
+		.start	= XOR0_PHYS_BASE,
+		.end	= XOR0_PHYS_BASE + 0xff,
+		.flags	= IORESOURCE_MEM,
+	}, {
+		.name	= "xor 0 high",
+		.start	= XOR0_HIGH_PHYS_BASE,
+		.end	= XOR0_HIGH_PHYS_BASE + 0xff,
+		.flags	= IORESOURCE_MEM,
+	},
+};
+
+static struct platform_device armadaxp_xor0_shared = {
+	.name		= MV_XOR_SHARED_NAME,
+	.id		= 0,
+	.dev		= {
+		.platform_data = &armadaxp_xor_shared_data,
+	},
+	.num_resources	= ARRAY_SIZE(armadaxp_xor0_shared_resources),
+	.resource	= armadaxp_xor0_shared_resources,
+};
+
+static struct resource armadaxp_xor00_resources[] = {
+	[0] = {
+		.start	= IRQ_AURORA_XOR0,
+		.end	= IRQ_AURORA_XOR0,
+		.flags	= IORESOURCE_IRQ,
+	},
+};
+
+static struct mv_xor_platform_data armadaxp_xor00_data = {
+	.shared		= &armadaxp_xor0_shared,
+	.hw_id		= 0,
+	.pool_size	= PAGE_SIZE,
+};
+
+static struct platform_device armadaxp_xor00_channel = {
+	.name		= MV_XOR_NAME,
+	.id		= 0,
+	.num_resources	= ARRAY_SIZE(armadaxp_xor00_resources),
+	.resource	= armadaxp_xor00_resources,
+	.dev		= {
+		.dma_mask		= &armadaxp_xor_dmamask,
+		.coherent_dma_mask	= DMA_BIT_MASK(64),
+		.platform_data		= &armadaxp_xor00_data,
+	},
+};
+
+static struct resource armadaxp_xor01_resources[] = {
+	[0] = {
+		.start	= IRQ_AURORA_XOR1,
+		.end	= IRQ_AURORA_XOR1,
+		.flags	= IORESOURCE_IRQ,
+	},
+};
+
+static struct mv_xor_platform_data armadaxp_xor01_data = {
+	.shared		= &armadaxp_xor0_shared,
+	.hw_id		= 1,
+	.pool_size	= PAGE_SIZE,
+};
+
+static struct platform_device armadaxp_xor01_channel = {
+	.name		= MV_XOR_NAME,
+	.id		= 1,
+	.num_resources	= ARRAY_SIZE(armadaxp_xor01_resources),
+	.resource	= armadaxp_xor01_resources,
+	.dev		= {
+		.dma_mask		= &armadaxp_xor_dmamask,
+		.coherent_dma_mask	= DMA_BIT_MASK(64),
+		.platform_data		= &armadaxp_xor01_data,
+	},
+};
+
+static void __init armadaxp_xor0_init(void)
+{
+	platform_device_register(&armadaxp_xor0_shared);
+
+	/*
+	 * two engines can't do memset simultaneously, this limitation
+	 * satisfied by removing memset support from one of the engines.
+	 */
+	dma_cap_set(DMA_MEMCPY, armadaxp_xor00_data.cap_mask);
+	dma_cap_set(DMA_XOR, armadaxp_xor00_data.cap_mask);
+	platform_device_register(&armadaxp_xor00_channel);
+
+	dma_cap_set(DMA_MEMCPY, armadaxp_xor01_data.cap_mask);
+	dma_cap_set(DMA_MEMSET, armadaxp_xor01_data.cap_mask);
+	dma_cap_set(DMA_XOR, armadaxp_xor01_data.cap_mask);
+	platform_device_register(&armadaxp_xor01_channel);
+}
+#endif
+
+/*****************************************************************************
+ * XOR1
+ ****************************************************************************/
+static struct resource armadaxp_xor1_shared_resources[] = {
+	{
+		.name	= "xor 1 low",
+		.start	= XOR1_PHYS_BASE,
+		.end	= XOR1_PHYS_BASE + 0xff,
+		.flags	= IORESOURCE_MEM,
+	}, {
+		.name	= "xor 1 high",
+		.start	= XOR1_HIGH_PHYS_BASE,
+		.end	= XOR1_HIGH_PHYS_BASE + 0xff,
+		.flags	= IORESOURCE_MEM,
+	},
+};
+
+static struct platform_device armadaxp_xor1_shared = {
+	.name		= MV_XOR_SHARED_NAME,
+	.id		= 1,
+	.dev		= {
+		.platform_data = &armadaxp_xor_shared_data,
+	},
+	.num_resources	= ARRAY_SIZE(armadaxp_xor1_shared_resources),
+	.resource	= armadaxp_xor1_shared_resources,
+};
+
+static struct resource armadaxp_xor10_resources[] = {
+	[0] = {
+		.start	= IRQ_AURORA_XOR0,
+		.end	= IRQ_AURORA_XOR0,
+		.flags	= IORESOURCE_IRQ,
+	},
+};
+
+static struct mv_xor_platform_data armadaxp_xor10_data = {
+	.shared		= &armadaxp_xor1_shared,
+	.hw_id		= 0,
+	.pool_size	= PAGE_SIZE,
+};
+
+static struct platform_device armadaxp_xor10_channel = {
+	.name		= MV_XOR_NAME,
+	.id		= 2,
+	.num_resources	= ARRAY_SIZE(armadaxp_xor10_resources),
+	.resource	= armadaxp_xor10_resources,
+	.dev		= {
+		.dma_mask		= &armadaxp_xor_dmamask,
+		.coherent_dma_mask	= DMA_BIT_MASK(64),
+		.platform_data		= &armadaxp_xor10_data,
+	},
+};
+
+static struct resource armadaxp_xor11_resources[] = {
+	[0] = {
+		.start	= IRQ_AURORA_XOR1,
+		.end	= IRQ_AURORA_XOR1,
+		.flags	= IORESOURCE_IRQ,
+	},
+};
+
+static struct mv_xor_platform_data armadaxp_xor11_data = {
+	.shared		= &armadaxp_xor1_shared,
+	.hw_id		= 1,
+	.pool_size	= PAGE_SIZE,
+};
+
+static struct platform_device armadaxp_xor11_channel = {
+	.name		= MV_XOR_NAME,
+	.id		= 3,
+	.num_resources	= ARRAY_SIZE(armadaxp_xor11_resources),
+	.resource	= armadaxp_xor11_resources,
+	.dev		= {
+		.dma_mask		= &armadaxp_xor_dmamask,
+		.coherent_dma_mask	= DMA_BIT_MASK(64),
+		.platform_data		= &armadaxp_xor11_data,
+	},
+};
+
+static void __init armadaxp_xor1_init(void)
+{
+	platform_device_register(&armadaxp_xor1_shared);
+
+	/*
+	 * two engines can't do memset simultaneously, this limitation
+	 * satisfied by removing memset support from one of the engines.
+	 */
+	dma_cap_set(DMA_MEMCPY, armadaxp_xor10_data.cap_mask);
+	dma_cap_set(DMA_XOR, armadaxp_xor10_data.cap_mask);
+	platform_device_register(&armadaxp_xor10_channel);
+
+	dma_cap_set(DMA_MEMCPY, armadaxp_xor11_data.cap_mask);
+	dma_cap_set(DMA_MEMSET, armadaxp_xor11_data.cap_mask);
+	dma_cap_set(DMA_XOR, armadaxp_xor11_data.cap_mask);
+	platform_device_register(&armadaxp_xor11_channel);
+}
+
+static void cpu_fabric_common_init(void)
+{
+	MV_U32	reg;
+
+#ifdef CONFIG_DEBUG_LL
+        check_cpu_mode();
+#endif
+
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_4948
+	printk("L0 cache Disabled (by Errata #4948)\n");
+#else
+	__asm volatile ("mrc p15, 1, %0, c15, c1, 0" : "=r" (reg));
+	if (l0_disable_flag) {
+		printk("L0 cache Disabled\n");	
+		reg |= (1 << 0);
+	} else {
+		printk("L0 cache Enabled\n");
+		reg &= ~(1 << 0);
+	}
+	__asm volatile ("mcr p15, 1, %0, c15, c1, 0" : : "r" (reg));
+#endif
+
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_5315
+	printk("Speculative Prefetch Disabled (by Errata #5315)\n");
+#else
+	__asm volatile ("mrc p15, 1, %0, c15, c2, 0" : "=r" (reg));
+	if (sp_enable_flag) {
+		printk("Speculative Prefetch Enabled\n");
+		reg &= ~(1 << 7);
+	} else {
+		printk("Speculative Prefetch Disabled\n");
+		reg |= (1 << 7);
+	}
+	__asm volatile ("mcr p15, 1, %0, c15, c2, 0" : : "r" (reg));
+#endif
+
+#ifdef CONFIG_CACHE_AURORA_L2
+	if (!noL2)
+		aurora_l2_init((void __iomem *)(INTER_REGS_BASE + MV_AURORA_L2_REGS_OFFSET));
+#endif
+
+#ifdef	CONFIG_AURORA_IO_CACHE_COHERENCY
+	printk("Support IO coherency.\n");
+	io_coherency_init();
+#endif
+}
+
+/*****************************************************************************
+ * DB BOARD: Main Initialization
+ ****************************************************************************/
+static void __init axp_db_init(void)
+{
+	/* Call Aurora/cpu special configurations */
+	cpu_fabric_common_init();
+
+	/* Select appropriate Board ID for Machine */
+	gBoardId = DB_88F78XX0_BP_ID;
+
+	/* Before initializing the HAL, select Z1A serdes cfg if needed */
+	if (support_Z1A_serdes_cfg)
+		mvBoardSerdesZ1ASupport();
+
+	/* init the Board environment */
+	mvBoardEnvInit();
+
+	/* init the controller environment */
+	if( mvCtrlEnvInit() ) {
+		printk( "Controller env initialization failed.\n" );
+		return;
+	}
+
+	armadaxp_setup_cpu_mbus();
+
+	/* Init the CPU windows setting and the access protection windows. */
+	if( mvCpuIfInit(mv_sys_map())) {
+		printk( "Cpu Interface initialization failed.\n" );
+		return;
+	}
+
+	/* Init Tclk & SysClk */
+	mvTclk = mvBoardTclkGet();
+	mvSysclk = mvBoardSysClkGet();
+
+	elf_hwcap &= ~HWCAP_JAVA;
+
+	serial_initialize();
+
+	/* At this point, the CPU windows are configured according to default definitions in mvSysHwConfig.h */
+	/* and cpuAddrWinMap table in mvCpuIf.c. Now it's time to change defaults for each platform.         */
+	/*mvCpuIfAddDecShow();*/
+
+	print_board_info();
+
+	mv_gpio_init();
+
+	/* RTC */
+	rtc_init();
+
+	/* SPI */
+	mvSysSpiInit(0, _16M);
+
+	/* ETH-PHY */
+	mvSysEthPhyInit();
+
+	/* Sata */
+#ifdef CONFIG_SATA_MV
+	armadaxp_sata_init(&dbdsmp_sata_data);
+#endif
+#ifdef CONFIG_MTD_NAND_NFC
+	/* NAND */
+	axp_db_nfc_init();
+#endif
+	/* HWMON */
+	armadaxp_hwmon_init();
+
+	/* XOR */
+#ifdef XOR0_ENABLE
+	armadaxp_xor0_init();
+#endif
+	armadaxp_xor1_init();
+
+	/* I2C */
+	platform_device_register(&axp_i2c0);
+
+
+#ifdef CONFIG_FB_DOVE
+      if ((lcd0_enable == 1) && (lcd_panel == 0 ))
+        platform_device_register(&axp_i2c1);
+#endif
+
+
+	
+
+#if defined(CONFIG_MV_INCLUDE_SDIO)
+	if (MV_TRUE == mvCtrlPwrClckGet(SDIO_UNIT_ID, 0)) {
+		int irq_detect = mvBoardSDIOGpioPinGet(BOARD_GPP_SDIO_DETECT);
+		MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+
+		if (irq_detect != MV_ERROR) {
+			mvsdio_data.gpio_card_detect = mvBoardSDIOGpioPinGet(BOARD_GPP_SDIO_DETECT);
+			irq_int_type[mvBoardSDIOGpioPinGet(BOARD_GPP_SDIO_DETECT)+IRQ_AURORA_GPIO_START] = GPP_IRQ_TYPE_CHANGE_LEVEL;
+		}
+
+		if(mvBoardSDIOGpioPinGet(BOARD_GPP_SDIO_WP) != MV_ERROR)
+			mvsdio_data.gpio_write_protect = mvBoardSDIOGpioPinGet(BOARD_GPP_SDIO_WP);
+
+		if(MV_OK == mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1))
+			if (MV_OK == mvSdmmcWinInit(addrWinMap))
+				mvsdio_data.clock = mvBoardTclkGet();
+		platform_device_register(&mv_sdio_plat);
+       }
+#endif
+
+#ifdef CONFIG_MV_ETHERNET
+	/* Ethernet */
+	eth_init();
+#endif
+
+#ifdef CONFIG_FB_DOVE
+	kw_lcd0_dmi.dram = &armadaxp_mbus_dram_info;
+	if (lcd_panel) {
+		kw_lcd0_dmi.lvds_info.enabled = 1;
+		kw_lcd0_dmi.fixed_full_div = 1;
+		kw_lcd0_dmi.full_div_val = 7;	
+		printk(KERN_INFO "LCD Panel enabled.\n");
+	}
+	clcd_platform_init(&kw_lcd0_dmi, &kw_lcd0_vid_dmi, &dsmp_backlight_data);
+#endif
+
+	return;
+}
+
+#ifdef CONFIG_FB_DOVE
+/*
+ * This fixup function is used to reserve memory for the LCD engine
+ * as these drivers require large chunks of consecutive memory.
+ */
+void __init axp_tag_fixup_mem32(struct machine_desc *mdesc, struct tag *t,
+		char **from, struct meminfo *meminfo)
+{
+	struct tag *last_tag = NULL;
+	int total_size = PAGE_ALIGN(DEFAULT_FB_SIZE*4) * 2;
+	uint32_t memory_start;
+
+	for (; t->hdr.size; t = tag_next(t))
+		if ((t->hdr.tag == ATAG_MEM) && (t->u.mem.size >= total_size)) {
+			if ((last_tag == NULL) ||
+			    (t->u.mem.start > last_tag->u.mem.start))
+				last_tag = t;
+		}
+
+	if (last_tag == NULL) {
+		early_printk(KERN_WARNING "No suitable memory tag was found, "
+				"required memory %d MB.\n", total_size);
+		return;
+	}
+
+	/* Resereve memory from last tag for LCD usage.	*/
+	last_tag->u.mem.size -= total_size;
+	memory_start = last_tag->u.mem.start + last_tag->u.mem.size;
+
+	kw_lcd0_dmi.fb_mem[0] = (void*)memory_start;
+	kw_lcd0_dmi.fb_mem_size[0] = total_size / 2;
+	kw_lcd0_dmi.fb_mem[1] = (void*)(memory_start + kw_lcd0_dmi.fb_mem_size[0]);
+	kw_lcd0_dmi.fb_mem_size[1] = total_size / 2;
+
+}
+#endif /* CONFIG_FB_DOVE */
+
+
+MACHINE_START(ARMADA_XP_DB, "Marvell Armada XP Development Board")
+	/* MAINTAINER("MARVELL") */
+	//.phys_io	= INTER_REGS_PHYS_BASE,
+	//.io_pg_offst	= ((INTER_REGS_BASE) >> 18) & 0xfffc,
+	.boot_params	= 0x00000100,
+	.map_io		= axp_map_io,
+	.init_irq	= axp_init_irq,
+	.timer		= &axp_timer,
+	.init_machine	= axp_db_init,
+#ifdef CONFIG_FB_DOVE
+	/* reserve memory for LCD */
+	.fixup		= axp_tag_fixup_mem32,
+#endif /* CONFIG_FB_DOVE */
+MACHINE_END
+
+
+/*****************************************************************************
+* RDSRV BOARD: Main Initialization
+ ****************************************************************************/
+static void __init axp_rdsrv_init(void)
+{
+	/* Call Aurora/cpu special configurations */
+	cpu_fabric_common_init();
+
+	/* Select appropriate Board ID for Machine */
+	gBoardId = RD_78460_SERVER_ID;
+
+	/* init the Board environment */
+	mvBoardEnvInit();
+
+	/* init the controller environment */
+	if( mvCtrlEnvInit() ) {
+		printk( "Controller env initialization failed.\n" );
+		return;
+	}
+
+	armadaxp_setup_cpu_mbus();
+
+	/* Init the CPU windows setting and the access protection windows. */
+	if( mvCpuIfInit(mv_sys_map())) {
+		printk( "Cpu Interface initialization failed.\n" );
+		return;
+	}
+
+	/* Init Tclk & SysClk */
+	mvTclk = mvBoardTclkGet();
+	mvSysclk = mvBoardSysClkGet();
+
+	elf_hwcap &= ~HWCAP_JAVA;
+
+	serial_initialize();
+
+	/* At this point, the CPU windows are configured according to default definitions in mvSysHwConfig.h */
+	/* and cpuAddrWinMap table in mvCpuIf.c. Now it's time to change defaults for each platform.         */
+	/*mvCpuIfAddDecShow();*/
+
+	print_board_info();
+
+	mv_gpio_init();
+
+	/* RTC */
+	rtc_init();
+
+	/* SPI */
+	mvSysSpiInit(0, _16M);
+
+	/* ETH-PHY */
+	mvSysEthPhyInit();
+
+	/* Sata */
+#ifdef CONFIG_SATA_MV
+	armadaxp_sata_init(&dbdsmp_sata_data);
+#endif
+
+	/* HWMON */
+	armadaxp_hwmon_init();
+
+	/* I2C */
+	platform_device_register(&axp_i2c0);
+
+#if defined(CONFIG_MV_INCLUDE_SDIO)
+	if (MV_TRUE == mvCtrlPwrClckGet(SDIO_UNIT_ID, 0)) {
+		int irq_detect = mvBoardSDIOGpioPinGet(BOARD_GPP_SDIO_DETECT);
+		MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+
+		if (irq_detect != MV_ERROR) {
+			mvsdio_data.gpio_card_detect = mvBoardSDIOGpioPinGet(BOARD_GPP_SDIO_DETECT);
+			irq_int_type[mvBoardSDIOGpioPinGet(BOARD_GPP_SDIO_DETECT)+IRQ_AURORA_GPIO_START] = GPP_IRQ_TYPE_CHANGE_LEVEL;
+		}
+
+		if(mvBoardSDIOGpioPinGet(BOARD_GPP_SDIO_WP) != MV_ERROR)
+			mvsdio_data.gpio_write_protect = mvBoardSDIOGpioPinGet(BOARD_GPP_SDIO_WP);
+
+		if(MV_OK == mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1))
+			if (MV_OK == mvSdmmcWinInit(addrWinMap))
+				mvsdio_data.clock = mvBoardTclkGet();
+		platform_device_register(&mv_sdio_plat);
+	}
+#endif
+
+#ifdef CONFIG_MV_ETHERNET
+	/* Ethernet */
+	eth_init();
+#endif
+
+	return;
+}
+
+/*MACHINE_START(ARMADA_XP_RDSRV, "Marvell Armada XP Server Board")
+		/ MAINTAINER("MARVELL") 
+		.phys_io	= INTER_REGS_PHYS_BASE,
+  .io_pg_offst	= ((INTER_REGS_BASE) >> 18) & 0xfffc,
+					.boot_params	= 0x00000100,
+	 .map_io		= axp_map_io,
+  .init_irq	= axp_init_irq,
+  .timer		= &axp_timer,
+  .init_machine	= axp_rdsrv_init,
+  MACHINE_END */
+
+/*****************************************************************************
+ * FPGA BOARD: Main Initialization
+ ****************************************************************************/
+extern MV_TARGET_ATTRIB mvTargetDefaultsArray[];
+static void __init axp_fpga_init(void)
+{
+	/* Call Aurora/cpu special configurations */
+	cpu_fabric_common_init();
+
+	/* Select appropriate Board ID for Machine */
+	gBoardId = FPGA_88F78XX0_ID;
+
+        /* init the Board environment */
+       	mvBoardEnvInit();
+
+        /* init the controller environment */
+        if( mvCtrlEnvInit() ) {
+            printk( "Controller env initialization failed.\n" );
+            return;
+        }
+	
+	/* Replace PCI-0 Attribute for FPGA 0xE => 0xD */
+	mvTargetDefaultsArray[PEX0_MEM].attrib = 0xD8;
+
+	/* Init the CPU windows setting and the access protection windows. */
+	/*if( mvCpuIfInit(mv_sys_map())) {
+		printk( "Cpu Interface initialization failed.\n" );
+		return;
+	}*/
+
+	armadaxp_setup_cpu_mbus();
+
+	/* Init the CPU windows setting and the access protection windows. */
+	if( mvCpuIfInit(mv_sys_map())) {
+		printk( "Cpu Interface initialization failed.\n" );
+		return;
+	}
+
+    	/* Init Tclk & SysClk */
+    	mvTclk = mvBoardTclkGet();
+   	mvSysclk = mvBoardSysClkGet();
+
+	elf_hwcap &= ~HWCAP_JAVA;
+
+	serial_initialize();
+
+	/* At this point, the CPU windows are configured according to default definitions in mvSysHwConfig.h */
+	/* and cpuAddrWinMap table in mvCpuIf.c. Now it's time to change defaults for each platform.         */
+	/*mvCpuIfAddDecShow();*/
+
+	print_board_info();
+
+	mv_gpio_init();
+
+	/* RTC */
+	rtc_init();
+
+	return;
+}
+
+/*MACHINE_START(ARMADA_XP_FPGA, "Marvell Armada XP FPGA Board")
+	 MAINTAINER("MARVELL") 
+	.phys_io	= INTER_REGS_PHYS_BASE,
+	.io_pg_offst	= ((INTER_REGS_BASE) >> 18) & 0xfffc,
+	.boot_params	= 0x00000100,
+	.map_io		= axp_map_io,
+	.init_irq	= axp_init_irq,
+	.timer		= &axp_timer,
+	.init_machine	= axp_fpga_init,
+MACHINE_END */
diff --git a/arch/arm/mach-armadaxp/dbg-trace.c b/arch/arm/mach-armadaxp/dbg-trace.c
new file mode 100644
index 0000000..43cabbd
--- /dev/null
+++ b/arch/arm/mach-armadaxp/dbg-trace.c
@@ -0,0 +1,112 @@
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/time.h>
+#include "dbg-trace.h"
+
+#define TRACE_ARR_LEN   800
+#define STR_LEN         128
+struct trace {
+	struct timeval tv;
+	char str[STR_LEN];
+	unsigned int callback_val1;
+	unsigned int callback_val2;
+	char valid;
+};
+
+static unsigned int (*trc_callback1) (unsigned char) = NULL;
+static unsigned int (*trc_callback2) (unsigned char) = NULL;
+static unsigned char trc_param1 = 0;
+static unsigned char trc_param2 = 0;
+struct trace *trc_arr;
+static int trc_index;
+static int trc_active = 0;
+
+void TRC_START()
+{
+	trc_active = 1;
+}
+
+void TRC_STOP()
+{
+	trc_active = 0;
+}
+
+void TRC_INIT(void *callback1, void *callback2, unsigned char callback1_param, unsigned char callback2_param)
+{
+	printk("Marvell debug tracing is on\n");
+	trc_arr = (struct trace *)kmalloc(TRACE_ARR_LEN*sizeof(struct trace),GFP_KERNEL);
+	if(trc_arr == NULL)
+	{
+		printk("Can't allocate Debug Trace buffer\n");
+		return;
+	}
+	memset(trc_arr,0,TRACE_ARR_LEN*sizeof(struct trace));
+	trc_index = 0;
+	trc_callback1 = callback1;
+	trc_callback2 = callback2;
+	trc_param1 = callback1_param;
+	trc_param2 = callback2_param;
+}
+
+void TRC_REC(char *fmt,...)
+{
+	va_list args;
+	struct trace *trc = &trc_arr[trc_index];
+
+	if(trc_active == 0)
+		return;
+
+	do_gettimeofday(&trc->tv);
+	if(trc_callback1)
+		trc->callback_val1 = trc_callback1(trc_param1);
+	if(trc_callback2)
+		trc->callback_val2 = trc_callback2(trc_param2);
+	va_start(args, fmt);
+	vsprintf(trc->str,fmt,args);
+	va_end(args);
+	trc->valid = 1;
+	if((++trc_index) == TRACE_ARR_LEN)
+		trc_index = 0;
+}
+
+void TRC_OUTPUT(void)
+{
+	int i,j;
+	struct trace *p;
+	printk("\n\nTrace %d items\n",TRACE_ARR_LEN);
+	for(i=0,j=trc_index; i<TRACE_ARR_LEN; i++,j++) {
+		if(j == TRACE_ARR_LEN)
+			j = 0;
+		p = &trc_arr[j];
+		if(p->valid) {
+			unsigned long uoffs;
+			struct trace *plast;
+			if(p == &trc_arr[0])
+				plast = &trc_arr[TRACE_ARR_LEN-1];
+			else
+				plast = p-1;
+			if(p->tv.tv_sec == ((plast)->tv.tv_sec))
+				uoffs = (p->tv.tv_usec - ((plast)->tv.tv_usec));
+			else
+				uoffs = (1000000 - ((plast)->tv.tv_usec)) +
+					((p->tv.tv_sec - ((plast)->tv.tv_sec) - 1) * 1000000) + 
+					p->tv.tv_usec;
+			printk("%03d: [+%ld usec]", j, (unsigned long)uoffs);
+			if(trc_callback1)
+				printk("[%u]",p->callback_val1);
+			if(trc_callback2)
+				printk("[%u]",p->callback_val2);
+			printk(": %s",p->str);
+		}
+		p->valid = 0;
+	}
+	memset(trc_arr,0,TRACE_ARR_LEN*sizeof(struct trace));
+	trc_index = 0;
+}
+
+void TRC_RELEASE(void)
+{
+	kfree(trc_arr);
+	trc_index = 0;
+}
+
diff --git a/arch/arm/mach-armadaxp/dbg-trace.h b/arch/arm/mach-armadaxp/dbg-trace.h
new file mode 100644
index 0000000..c1ad60b
--- /dev/null
+++ b/arch/arm/mach-armadaxp/dbg-trace.h
@@ -0,0 +1,24 @@
+
+#ifndef _MV_DBG_TRCE_H_
+#define _MV_DBG_TRCE_H_
+
+#ifdef CONFIG_MV_DBG_TRACE
+void TRC_INIT(void *callback1, void *callback2,
+		unsigned char callback1_param, unsigned char callback2_param);
+void TRC_REC(char *fmt,...);
+void TRC_OUTPUT(void);
+void TRC_RELEASE(void);
+void TRC_START(void);
+void TRC_STOP(void);
+
+#else
+#define TRC_INIT(x1,x2,x3,x4)
+#define TRC_REC(X...)
+#define TRC_OUTPUT()
+#define TRC_RELEASE()
+#define TRC_START()
+#define TRC_STOP()
+#endif
+
+
+#endif
diff --git a/arch/arm/mach-armadaxp/dump_cp15_regs.c b/arch/arm/mach-armadaxp/dump_cp15_regs.c
new file mode 100644
index 0000000..bc4901e
--- /dev/null
+++ b/arch/arm/mach-armadaxp/dump_cp15_regs.c
@@ -0,0 +1,219 @@
+/*
+ * arch/arm/mach-dove/dump_cp15_regs.c
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <linux/proc_fs.h>
+
+static int
+proc_dump_cp15_read(char *page, char **start, off_t off, int count, int *eof,
+			void *data)
+{
+	char *p = page;
+	int len;
+	unsigned int value;
+	
+	asm volatile("mrc p15, 0, %0, c0, c0, 0": "=r"(value));
+	p += sprintf(p, "Main ID: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c0, c0, 1": "=r"(value));
+	p += sprintf(p, "Cache Type: 0x%08x\n", value);
+	
+#ifdef CONFIG_CPU_V7
+	asm volatile("mrc p15, 0, %0, c0, c0, 2": "=r"(value));
+	p += sprintf(p, "TCM Type: 0x%08x\n", value);
+#endif	
+
+	asm volatile("mrc p15, 0, %0, c0, c0, 3": "=r"(value));
+	p += sprintf(p, "TLB Type: 0x%08x\n", value);
+
+#ifdef CONFIG_CPU_V7
+	asm volatile("mrc p15, 0, %0, c0, c0, 5": "=r"(value));
+	p += sprintf(p, "Microprocessor ID: 0x%08x\n", value);
+#endif	
+
+	asm volatile("mrc p15, 0, %0, c0, c1, 0": "=r"(value));
+	p += sprintf(p, "Processor Feature 0: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c0, c1, 1": "=r"(value));
+	p += sprintf(p, "Processor Feature 1: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c0, c1, 2": "=r"(value));
+	p += sprintf(p, "Debug Feature 0: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c0, c1, 3": "=r"(value));
+	p += sprintf(p, "Auxiliary Feature 0: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c0, c1, 4": "=r"(value));
+	p += sprintf(p, "Memory Model Feature 0: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c0, c1, 5": "=r"(value));
+	p += sprintf(p, "Memory Model Feature 1: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c0, c1, 6": "=r"(value));
+	p += sprintf(p, "Memory Model Feature 2: 0x%08x\n", value);
+
+	asm volatile("mrc p15, 0, %0, c0, c1, 7": "=r"(value));
+	p += sprintf(p, "Memory Model Feature 3: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c0, c2, 0": "=r"(value));
+	p += sprintf(p, "Set Attribute 0: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c0, c2, 1": "=r"(value));
+	p += sprintf(p, "Set Attribute 1: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c0, c2, 2": "=r"(value));
+	p += sprintf(p, "Set Attribute 2: 0x%08x\n", value);
+
+	asm volatile("mrc p15, 0, %0, c0, c2, 3": "=r"(value));
+	p += sprintf(p, "Set Attribute 3: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c0, c2, 4": "=r"(value));
+	p += sprintf(p, "Set Attribute 4: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c0, c2, 5": "=r"(value));
+	p += sprintf(p, "Set Attribute 5: 0x%08x\n", value);
+#ifdef CONFIG_CPU_V7
+	asm volatile("mrc p15, 1, %0, c0, c0, 0": "=r"(value));
+	p += sprintf(p, "Current Cache Size ID: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 1, %0, c0, c0, 1": "=r"(value));
+	p += sprintf(p, "Current Cache Level ID: 0x%08x\n", value);
+
+	asm volatile("mrc p15, 1, %0, c0, c0, 7": "=r"(value));
+	p += sprintf(p, "Silicon ID: 0x%08x\n", value);
+
+	asm volatile("mrc p15, 2, %0, c0, c0, 0": "=r"(value));
+	p += sprintf(p, "Cache Size Selection: 0x%08x\n", value);
+
+#endif
+	asm volatile("mrc p15, 0, %0, c1, c0, 0": "=r"(value));
+	p += sprintf(p, "Control : 0x%08x\n", value);
+
+	asm volatile("mrc p15, 0, %0, c1, c0, 1": "=r"(value));
+	p += sprintf(p, "Auxiliary Control : 0x%08x\n", value);
+
+	asm volatile("mrc p15, 0, %0, c1, c0, 2": "=r"(value));
+	p += sprintf(p, "Coprocessor Access Control : 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c1, c1, 0": "=r"(value));
+	p += sprintf(p, "Secure Configuration : 0x%08x\n", value);
+
+	asm volatile("mrc p15, 0, %0, c2, c0, 0": "=r"(value));
+	p += sprintf(p, "Translation Table Base 0 : 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c2, c0, 1": "=r"(value));
+	p += sprintf(p, "Translation Table Base 1 : 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c2, c0, 2": "=r"(value));
+	p += sprintf(p, "Translation Table Control : 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c3, c0, 0": "=r"(value));
+	p += sprintf(p, "Domain Access Control : 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c5, c0, 0": "=r"(value));
+	p += sprintf(p, "Data Fault Status : 0x%08x\n", value);
+
+	asm volatile("mrc p15, 0, %0, c5, c0, 1": "=r"(value));
+	p += sprintf(p, "Instruction Fault Status : 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c6, c0, 0": "=r"(value));
+	p += sprintf(p, "Data Fault Address : 0x%08x\n", value);
+
+	asm volatile("mrc p15, 0, %0, c6, c0, 1": "=r"(value));
+	p += sprintf(p, "Watchpoint Fault Address : 0x%08x\n", value);
+
+	asm volatile("mrc p15, 0, %0, c6, c0, 2": "=r"(value));
+	p += sprintf(p, "Instruction Fault Address : 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c7, c10, 6": "=r"(value));
+	p += sprintf(p, "Cache Dirty Status: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 1, %0, c15, c1, 0": "=r"(value));
+	p += sprintf(p, "Auxiliary Debug Modes Control 0: 0x%08x\n", value);
+
+	asm volatile("mrc p15, 1, %0, c15, c1, 1": "=r"(value));
+	p += sprintf(p, "Auxiliary Debug Modes Control 1: 0x%08x\n", value);
+
+#if 1
+	asm volatile("mrc p15, 1, %0, c15, c1, 0": "=r"(value));
+	p += sprintf(p, "Control Configuration: 0x%08x\n", value);
+	p += sprintf(p, "    Write Buffer Coalescing\t: %s\n", (value & (1 << 8)) ?
+		     "Enabled" : "Disabled");
+	if (value & (1 << 8))
+		p += sprintf(p, "    WB WAIT CYC\t: 0x%x\n", (value >> 9) & 0x7);
+
+	p += sprintf(p, "    Coprocessor dual issue \t: %s\n", (value & (1 << 15)) ?
+		     "Disabled" : "Enabled");
+
+	p += sprintf(p, "    L2 write allocate\t: %s\n", (value & (1 << 28)) ?
+		     "Enabled" : "Disabled");
+
+	p += sprintf(p, "    Streaming\t: %s\n", (value & (1 << 29)) ?
+		     "Enabled" : "Disabled");
+#endif	
+	asm volatile("mrc p15, 1, %0, c15, c12, 0": "=r"(value));
+	p += sprintf(p, "CPU ID Code Extension: 0x%08x\n", value);
+	
+	asm volatile("mrc p15, 0, %0, c9, c14, 0": "=r"(value));
+	p += sprintf(p, "User mode access for PMC registers: %s\n", (value & 1) ?
+		     "Enabled" : "Disabled");
+	asm volatile("mrc p15, 0, %0, c10, c2, 0": "=r"(value));
+	p += sprintf(p, "Memory Attribute PRRR: 0x%08x\n", value);
+
+	asm volatile("mrc p15, 0, %0, c10, c2, 1": "=r"(value));
+	p += sprintf(p, "Memory Attribute NMRR: 0x%08x\n", value);
+
+	asm volatile("mrc p15, 1, %0, c15, c1, 2": "=r"(value));
+	p += sprintf(p, "Auxiliary Debug Modes Control 2: 0x%08x\n", value);
+
+	asm volatile("mrc p15, 1, %0, c15, c2, 0": "=r"(value));
+	p += sprintf(p, "Auxiliary Functional Modes Control 0: 0x%08x\n", value);
+
+	asm volatile("mrc p15, 1, %0, c15, c2, 1": "=r"(value));
+	p += sprintf(p, "Auxiliary Functional Modes Control 1: 0x%08x\n", value);
+
+	len = (p - page) - off;
+	if (len < 0)
+		len = 0;
+	
+	*eof = (len <= count) ? 1 : 0;
+	*start = page + off;
+
+	return len;
+}
+int dump_init_module(void)
+{
+#ifdef CONFIG_PROC_FS
+	struct proc_dir_entry *res;
+	res = create_proc_entry("mv_dump_cp15", S_IRUSR, NULL);
+	if (!res)
+		return -ENOMEM;
+
+	res->read_proc = proc_dump_cp15_read;
+#endif
+
+	return 0;
+}
+
+void dump_cleanup_module(void)
+{
+	remove_proc_entry("mv_dump_cp15", NULL);
+}
+
+module_init(dump_init_module);
+module_exit(dump_cleanup_module);
+
+MODULE_AUTHOR("Saeed Bishara");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/mach-armadaxp/export.c b/arch/arm/mach-armadaxp/export.c
new file mode 100644
index 0000000..7706b1c
--- /dev/null
+++ b/arch/arm/mach-armadaxp/export.c
@@ -0,0 +1,205 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#include <linux/types.h>
+#include <linux/kernel.h>
+
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "ctrlEnv/sys/mvCpuIf.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "mvDebug.h"
+#include "mvSysHwConfig.h"
+#include "pex/mvPexRegs.h"
+#include "cntmr/mvCntmr.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "mvOs.h"
+
+
+/*************************************************************************************************************
+ * Environment 
+ *************************************************************************************************************/
+extern u32 mvTclk;
+extern u32 mvSysclk;
+
+EXPORT_SYMBOL(mv_early_printk);
+EXPORT_SYMBOL(mvCtrlPwrClckGet);
+EXPORT_SYMBOL(mvCtrlModelRevGet);
+EXPORT_SYMBOL(mvTclk);
+EXPORT_SYMBOL(mvSysclk);
+EXPORT_SYMBOL(mvCtrlModelGet);
+EXPORT_SYMBOL(mvOsIoUncachedMalloc);
+EXPORT_SYMBOL(mvOsIoUncachedFree);
+EXPORT_SYMBOL(mvOsIoCachedMalloc);
+EXPORT_SYMBOL(mvOsIoCachedFree);
+EXPORT_SYMBOL(mvDebugMemDump);
+EXPORT_SYMBOL(mvHexToBin);
+EXPORT_SYMBOL(mvBinToHex);
+EXPORT_SYMBOL(mvSizePrint);
+EXPORT_SYMBOL(mvDebugPrintMacAddr);
+EXPORT_SYMBOL(mvCtrlEthMaxPortGet);
+EXPORT_SYMBOL(mvCtrlTargetNameGet);
+EXPORT_SYMBOL(mvBoardIdGet);
+EXPORT_SYMBOL(mvBoardPhyAddrGet);
+EXPORT_SYMBOL(mvCpuIfTargetWinGet);
+EXPORT_SYMBOL(mvMacStrToHex);
+EXPORT_SYMBOL(mvBoardTclkGet);
+EXPORT_SYMBOL(mvBoardMacSpeedGet);
+EXPORT_SYMBOL(mvWinOverlapTest);
+EXPORT_SYMBOL(mvCtrlAddrWinMapBuild);
+EXPORT_SYMBOL(mvBoardTdmSpiModeGet);
+EXPORT_SYMBOL(mvBoardTdmSpiCsGet);
+EXPORT_SYMBOL(mvBoardTdmDevicesCountGet);
+
+#include "spi/mvSpiCmnd.h"
+EXPORT_SYMBOL(mvSpiWriteThenWrite);
+EXPORT_SYMBOL(mvSpiWriteThenRead);
+#include "spi/mvSpi.h"
+EXPORT_SYMBOL(mvSpiParamsSet);
+#include "gpp/mvGpp.h"
+EXPORT_SYMBOL(mvGppValueSet);
+
+/*************************************************************************************************************
+ * TDM
+ *************************************************************************************************************/
+#if defined(MV_INCLUDE_TDM)
+EXPORT_SYMBOL(mvCtrlTdmUnitIrqGet);
+EXPORT_SYMBOL(mvCtrlTdmUnitTypeGet);
+#endif
+
+/*************************************************************************************************************
+ * Audio
+ *************************************************************************************************************/
+#ifdef CONFIG_MV_INCLUDE_AUDIO
+#include "audio/mvAudio.h"
+#include "mvSysAudioApi.h"
+EXPORT_SYMBOL(mvSPDIFRecordTclockSet);
+EXPORT_SYMBOL(mvSPDIFPlaybackCtrlSet);
+EXPORT_SYMBOL(mvI2SPlaybackCtrlSet);
+EXPORT_SYMBOL(mvAudioPlaybackControlSet);
+EXPORT_SYMBOL(mvAudioDCOCtrlSet);
+EXPORT_SYMBOL(mvI2SRecordCntrlSet);
+EXPORT_SYMBOL(mvAudioRecordControlSet);
+EXPORT_SYMBOL(mvSysAudioInit);
+EXPORT_SYMBOL(mvBoardA2DTwsiAddrGet);
+EXPORT_SYMBOL(mvBoardA2DTwsiAddrTypeGet);
+#endif
+
+/*************************************************************************************************************
+ * USB
+ *************************************************************************************************************/
+#ifdef CONFIG_MV_INCLUDE_USB
+extern u32 mvIsUsbHost;
+
+#include "usb/mvUsb.h"
+EXPORT_SYMBOL(mvIsUsbHost);
+EXPORT_SYMBOL(mvCtrlUsbMaxGet);
+EXPORT_SYMBOL(mvUsbGetCapRegAddr);
+#ifdef MV_USB_VOLTAGE_FIX
+EXPORT_SYMBOL(mvUsbGppInit);
+EXPORT_SYMBOL(mvUsbBackVoltageUpdate);
+#endif
+#endif /* CONFIG_MV_INCLUDE_USB */
+
+/*************************************************************************************************************
+ * CESA
+ *************************************************************************************************************/
+#ifdef CONFIG_MV_INCLUDE_CESA
+#include "mvSysCesaApi.h"
+#include "cesa/mvCesa.h"
+#include "cesa/mvMD5.h"
+#include "cesa/mvSHA1.h"
+extern unsigned char*  mv_sram_usage_get(int* sram_size_ptr);
+
+EXPORT_SYMBOL(mvSysCesaInit);
+EXPORT_SYMBOL(mvCesaSessionOpen);
+EXPORT_SYMBOL(mvCesaSessionClose);
+EXPORT_SYMBOL(mvCesaAction);
+EXPORT_SYMBOL(mvCesaReadyGet);
+EXPORT_SYMBOL(mvCesaCopyFromMbuf);
+EXPORT_SYMBOL(mvCesaCopyToMbuf);
+EXPORT_SYMBOL(mvCesaMbufCopy);
+EXPORT_SYMBOL(mvCesaCryptoIvSet);
+EXPORT_SYMBOL(mvMD5);
+EXPORT_SYMBOL(mvSHA1);
+
+EXPORT_SYMBOL(mvCesaDebugQueue);
+EXPORT_SYMBOL(mvCesaDebugSram);
+EXPORT_SYMBOL(mvCesaDebugSAD);
+EXPORT_SYMBOL(mvCesaDebugStatus);
+EXPORT_SYMBOL(mvCesaDebugMbuf);
+EXPORT_SYMBOL(mvCesaDebugSA);
+EXPORT_SYMBOL(mv_sram_usage_get);
+
+extern u32 mv_crypto_virt_base_get(void);
+extern u32 mv_crypto_phys_base_get(void);
+EXPORT_SYMBOL(mv_crypto_virt_base_get);
+EXPORT_SYMBOL(mv_crypto_phys_base_get);
+EXPORT_SYMBOL(cesaReqResources);
+EXPORT_SYMBOL(mvCesaFinish);
+
+#endif
+
+/*************************************************************************************************************
+ * Flashes
+ *************************************************************************************************************/
+#if defined (CONFIG_MV_INCLUDE_SPI)
+#include <sflash/mvSFlash.h>
+#include <sflash/mvSFlashSpec.h>
+EXPORT_SYMBOL(mvSFlashInit);
+EXPORT_SYMBOL(mvSFlashSectorErase);
+EXPORT_SYMBOL(mvSFlashChipErase);
+EXPORT_SYMBOL(mvSFlashBlockRd);
+EXPORT_SYMBOL(mvSFlashBlockWr);
+EXPORT_SYMBOL(mvSFlashIdGet);
+EXPORT_SYMBOL(mvSFlashWpRegionSet);
+EXPORT_SYMBOL(mvSFlashWpRegionGet);
+EXPORT_SYMBOL(mvSFlashStatRegLock);
+EXPORT_SYMBOL(mvSFlashSizeGet);
+EXPORT_SYMBOL(mvSFlashPowerSaveEnter);
+EXPORT_SYMBOL(mvSFlashPowerSaveExit);
+EXPORT_SYMBOL(mvSFlashModelGet);
+#endif
+
+
+/*************************************************************************************************************
+ * SATA
+ *************************************************************************************************************/
+#ifdef CONFIG_MV_INCLUDE_INTEG_SATA
+#include <sata/CoreDriver/mvSata.h>
+EXPORT_SYMBOL(mvSataWinInit);
+#endif
+
+/*************************************************************************************************************
+ * DMA/XOR
+ *************************************************************************************************************/
+#if defined (CONFIG_MV_XOR_MEMCOPY) || defined (CONFIG_MV_IDMA_MEMCOPY)
+EXPORT_SYMBOL(asm_memcpy);
+#endif
+
+#ifdef CONFIG_MV_SP_I_FTCH_DB_INV 
+EXPORT_SYMBOL(mv_l2_inv_range);
+#endif
+
+/*************************************************************************************************************
+ * Marvell TRACE
+ *************************************************************************************************************/
+#ifdef CONFIG_MV_DBG_TRACE
+#include "dbg-trace.h"
+EXPORT_SYMBOL(TRC_INIT);
+EXPORT_SYMBOL(TRC_REC);
+EXPORT_SYMBOL(TRC_OUTPUT);
+EXPORT_SYMBOL(TRC_START);
+EXPORT_SYMBOL(TRC_RELEASE);
+#endif
diff --git a/arch/arm/mach-armadaxp/flashmap.c b/arch/arm/mach-armadaxp/flashmap.c
new file mode 100644
index 0000000..3d48279
--- /dev/null
+++ b/arch/arm/mach-armadaxp/flashmap.c
@@ -0,0 +1,250 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+********************************************************************************/
+
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/map.h>
+#include <linux/mtd/partitions.h>
+#include <linux/version.h>
+#include "mvSysHwConfig.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "ctrlEnv/sys/mvCpuIf.h"
+
+#define MTD_FLASH_MAP_DEBUG
+
+#ifdef MTD_FLASH_MAP_DEBUG
+#define DB(x)	x
+#else
+#define DB(x)
+#endif
+
+#define MTD_MAX_FLASH_NUMBER	4
+#define MTD_DUMMY_BANK_WIDTH	2
+
+struct maps_init_info
+{
+	struct map_info mapInfo;
+	char ** mtdDrv;
+	struct mtd_info * mtdInfo;
+	char name[32];
+};
+
+static struct maps_init_info maps[MTD_MAX_FLASH_NUMBER];
+static unsigned int mapsNum = 0;
+
+#if defined (CONFIG_MTD_CFI) || defined (CONFIG_MTD_JEDECPROBE)
+static char * cfiDev = "cfi_flash";
+static char * cfiMtdList[] = { "cfi_probe", NULL };
+#endif
+
+#ifdef CONFIG_MV_INCLUDE_SFLASH_MTD
+static char * sflashDev = "spi_flash";
+static char * sflashMtdList[] = {"sflash", NULL};
+#endif
+
+#ifdef CONFIG_MTD_PARTITIONS
+static struct mtd_partition *mtd_parts;
+static int                   mtd_parts_nb;
+static const char *part_probes[] __initdata = {"cmdlinepart", NULL};
+#endif /* CONFIG_MTD_PARTITIONS */
+
+static int flashInfoFill(void)
+{
+	int expectedDevs = 0;
+	int devs, i;
+
+	/* clear the whole array */
+	memset((void*)maps, 0x0, sizeof(maps));
+
+#if defined (CONFIG_MTD_CFI) || defined (CONFIG_MTD_JEDECPROBE)
+	/* gather the CFI and JEDEC NOR flash devices information */
+	devs = mvBoardGetDevicesNumber(BOARD_DEV_NOR_FLASH);
+
+	for(i=0; i<devs; i++) {
+		if (expectedDevs >= MTD_MAX_FLASH_NUMBER) {
+			printk(KERN_NOTICE "\nERROR: %s - Exceeded MAX MTD flash devices number", __FUNCTION__);
+			break;
+		}
+		maps[expectedDevs].mtdDrv = cfiMtdList;	
+		sprintf(maps[expectedDevs].name, "%s_%d", cfiDev, i);
+		maps[expectedDevs].mapInfo.name = maps[expectedDevs].name;
+		maps[expectedDevs].mapInfo.phys = mvBoardGetDeviceBaseAddr(i, BOARD_DEV_NOR_FLASH);
+		maps[expectedDevs].mapInfo.size = mvBoardGetDeviceWinSize(i, BOARD_DEV_NOR_FLASH);
+		maps[expectedDevs].mapInfo.bankwidth = (mvBoardGetDeviceBusWidth(i, BOARD_DEV_NOR_FLASH) / 8);
+		
+		if ((maps[expectedDevs].mapInfo.phys != 0xFFFFFFFF) && 
+		    (maps[expectedDevs].mapInfo.size != 0xFFFFFFFF)) {
+			DB(printk("\nINFO: Found %s %d - base 0x%08x, size 0x%x, bus %d", maps[expectedDevs].mapInfo.name, i,
+			   (unsigned int)maps[expectedDevs].mapInfo.phys, (unsigned int)maps[expectedDevs].mapInfo.size, maps[expectedDevs].mapInfo.bankwidth));
+			++expectedDevs;
+		} else {
+			printk(KERN_NOTICE "\nERROR: %s - Failed to get Device Base address and Size (%s %d)", __FUNCTION__, maps[expectedDevs].mapInfo.name, i);
+		}
+	}
+#endif
+	
+#ifdef CONFIG_MV_INCLUDE_SFLASH_MTD
+	/* gather the SPI flash devices information */
+	devs = mvBoardGetDevicesNumber(BOARD_DEV_SPI_FLASH);
+
+	for(i=0; i<devs; i++) {
+		if (expectedDevs >= MTD_MAX_FLASH_NUMBER) {
+			printk(KERN_NOTICE "\nERROR: %s - Exceeded MAX MTD flash devices number", __FUNCTION__);
+			break;
+		}
+		maps[expectedDevs].mtdDrv = sflashMtdList;
+		maps[expectedDevs].mapInfo.name = sflashDev;
+		maps[expectedDevs].mapInfo.phys = mvBoardGetDeviceBaseAddr(i, BOARD_DEV_SPI_FLASH);
+		maps[expectedDevs].mapInfo.size = mvBoardGetDeviceWinSize(i, BOARD_DEV_SPI_FLASH);
+		maps[expectedDevs].mapInfo.bankwidth = MTD_DUMMY_BANK_WIDTH;
+
+		if ((maps[expectedDevs].mapInfo.phys != 0xFFFFFFFF) && 
+		    (maps[expectedDevs].mapInfo.size != 0xFFFFFFFF)) {
+			DB(printk("\nINFO: Found %s %d - base 0x%08x, size 0x%x", maps[expectedDevs].mapInfo.name, i,
+						(unsigned int)maps[expectedDevs].mapInfo.phys,
+						(unsigned int)maps[expectedDevs].mapInfo.size));
+			++expectedDevs;
+		} else {
+			printk(KERN_NOTICE "\nERROR: %s - Failed to get Device Base address and Size (%s %d)",
+					__FUNCTION__, maps[expectedDevs].mapInfo.name, i);
+		}
+	}
+#endif
+
+	DB(printk("\nINFO: %s - Found %d Flash Devices", __FUNCTION__, expectedDevs));
+	return expectedDevs;
+}
+
+static int __init flashProbe(char ** mtdDrv, struct map_info * map, struct mtd_info ** mtd)
+{
+	if ((mtdDrv == NULL) || (map == NULL) || (mtd == NULL)) {
+		printk(KERN_NOTICE "\nERROR: NULL pointer parameter at %s entry", __FUNCTION__);
+		return -EINVAL;
+	}
+
+	/* remap the physical address to a virtual address */
+	map->virt = ioremap(map->phys, map->size);
+	if (!map->virt) {
+		printk(KERN_NOTICE "\nERROR: Failed to ioremap Flash device at physical base 0x%x.", (unsigned int)map->phys);
+		return -EIO;
+	}
+	
+	DB(printk("\nINFO: Io remapped successfully - phy addr = 0x%08x, virt addr = 0x%08x",
+				(unsigned int)map->phys, (unsigned int)map->virt));
+
+	simple_map_init(map);
+
+	*mtd = NULL;
+	for(; (!(*mtd) && *mtdDrv); mtdDrv++) {
+		DB(printk("\nINFO: Using %s to probe %s at address 0x%08x, size 0x%x, width %dm",
+					*mtdDrv, map->name, (unsigned int)map->phys,
+					(unsigned int)map->size, map->bankwidth));
+		if ((*mtd = do_map_probe(*mtdDrv, map))) {
+			DB(printk(" - detected OK"));
+			/*map->size = (*mtd)->size;*/
+			(*mtd)->owner = THIS_MODULE;
+
+#ifdef CONFIG_MTD_PARTITIONS
+			mtd_parts_nb = parse_mtd_partitions(*mtd, part_probes, &mtd_parts, 0);
+
+			if (mtd_parts_nb > 0) {
+				add_mtd_partitions (*mtd, mtd_parts, mtd_parts_nb);
+				return 0;
+			}
+#endif
+
+			if (/*add_mtd_device(*mtd) != 0*/mtd_device_register(*mtd, NULL,0)){
+				printk(KERN_NOTICE "\nERROR: %s - Failed to add the mtd device", __FUNCTION__);
+				iounmap((void *)map->virt);
+				map->virt = 0;
+				return -ENXIO;
+			}
+
+			return 0;
+		} else {
+			DB(printk(" - Not detected"));
+		}
+	}
+ 
+	iounmap((void *)map->virt);
+	map->virt = 0;
+	return -ENXIO;
+}
+	
+static int __init flash_map_init(void)
+{	
+	int i;
+
+	mapsNum = flashInfoFill();
+	DB(printk("\nINFO: flash_map_init - detected %d devices\n",  mapsNum));
+
+	for (i=0; i<mapsNum; i++) {
+		DB(printk("MTD: Initialize the %s device at address 0x%08x\n", maps[i].mapInfo.name, (unsigned int)maps[i].mapInfo.phys));
+		if (flashProbe(maps[i].mtdDrv, &maps[i].mapInfo, &maps[i].mtdInfo) == 0) {
+			DB(printk(" - OK.\n"));
+		} else {
+			maps[i].mtdInfo = NULL;
+			DB(printk(" - FAILED!\n"));
+		}
+	}
+
+	return 0;
+}
+
+static void __exit flash_map_exit(void)
+{
+	int i;
+
+	for (i=0; i<mapsNum; i++) {
+		if (maps[i].mtdInfo) {
+			//del_mtd_device(maps[i].mtdInfo);
+			  mtd_device_unregister(maps[i].mtdInfo);
+			map_destroy(maps[i].mtdInfo);
+		}
+
+		if (maps[i].mapInfo.virt) {
+			iounmap((void *)maps[i].mapInfo.virt);
+			maps[i].mapInfo.virt = 0;
+		}
+	}
+}
+
+module_init(flash_map_init);
+module_exit(flash_map_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("MTD map driver for Marvell platforms");
diff --git a/arch/arm/mach-armadaxp/headsmp.S b/arch/arm/mach-armadaxp/headsmp.S
new file mode 100644
index 0000000..139281a
--- /dev/null
+++ b/arch/arm/mach-armadaxp/headsmp.S
@@ -0,0 +1,83 @@
+/*
+ *  linux/arch/arm/mach-armadaxp/headsmp.S
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#include <linux/linkage.h>
+#include <linux/init.h>
+#include <asm/memory.h>
+
+	__INIT
+
+/*
+ * specific entry point for secondary CPUs.  This provides
+ * a "holding pen" into which all secondary cores are held until we're
+ * ready for them to initialise.
+ */
+ENTRY(axp_secondary_startup)
+#ifdef CONFIG_CPU_ENDIAN_BE32
+        /* convert CPU to big endian */
+        .word 0x100f11ee /* mrc p15, 0, r0, c1, c0 */
+        .word 0x800080e3 /* orr r0, r0, #0x80 */
+        .word 0x100f01ee /* mcr p15, 0, r0, c1, c0 */
+#endif
+	mrc	p15, 0, r0, c0, c0, 5
+	and	r0, r0, #15
+	adr	r4, 1f
+	ldmia	r4, {r5, r6}
+	sub	r4, r4, r5
+	add	r6, r6, r4
+#ifndef CONFIG_SHEEVA_ERRATA_ARM_CPU_4948
+	/*
+	 * Disable L0 on secondary CPU if flag set
+	 */
+	adr	r7, l0_disable_flag_addr
+	ldr	r7, [r7]
+	sub	r7, r7, #(PAGE_OFFSET - PHYS_OFFSET)
+	ldr	r7, [r7]
+	cmp	r7, #0
+	beq	l0_dis_skip
+	mrc	p15, 1, r7, c15, c1, 0
+	orr	r7, r7, #0x1
+	mcr	p15, 1, r7, c15, c1, 0
+l0_dis_skip:
+#endif
+#ifndef CONFIG_SHEEVA_ERRATA_ARM_CPU_5315
+	/*
+	 * Speculative prefetch on secondary CPU if flag set
+	 * Auxiliary Functional Modes Control 0 Register
+	 * Bit[7]: 0-Enable, 1-Disable (reset default)
+	 */
+	adr	r7, sp_enable_flag_addr
+	ldr	r7, [r7]
+	sub	r7, r7, #(PAGE_OFFSET - PHYS_OFFSET)
+	ldr	r7, [r7]
+	cmp	r7, #0
+	beq	sp_ena_skip
+	mrc	p15, 1, r7, c15, c2, 0
+	bic	r7, r7, #(1 << 7)
+	mcr	p15, 1, r7, c15, c2, 0	
+sp_ena_skip:
+#endif
+pen:	ldr	r7, [r6]
+	cmp	r7, r0
+	bne	pen
+
+	/*
+	 * we've been released from the holding pen: secondary_stack
+	 * should now contain the SVC stack for this core
+	 */
+	b	secondary_startup
+
+1:	.long	.
+	.long	pen_release
+#ifndef CONFIG_SHEEVA_ERRATA_ARM_CPU_4948
+l0_disable_flag_addr:
+	.word	l0_disable_flag
+#endif
+#ifndef CONFIG_SHEEVA_ERRATA_ARM_CPU_5315
+sp_enable_flag_addr:
+	.word	sp_enable_flag
+#endif
diff --git a/arch/arm/mach-armadaxp/hwmon.c b/arch/arm/mach-armadaxp/hwmon.c
new file mode 100644
index 0000000..354d68c
--- /dev/null
+++ b/arch/arm/mach-armadaxp/hwmon.c
@@ -0,0 +1,353 @@
+/*
+ * hwmon-axp.c - temperature monitoring driver for Dove SoC
+ *
+ * Inspired from other hwmon drivers
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA.
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/jiffies.h>
+#include <linux/hwmon.h>
+#include <linux/sysfs.h>
+#include <linux/hwmon-sysfs.h>
+#include <linux/err.h>
+#include <linux/list.h>
+#include <linux/platform_device.h>
+#include <linux/cpu.h>
+#include <asm/io.h>
+//#include <linux/delay.h>
+#include <linux/slab.h>
+//#include "pmu/mvPmuRegs.h"
+
+/* Termal Sensor Registers */
+#define TSEN_STATUS_REG				0x182B0
+#define	TSEN_STATUS_TEMP_OUT_OFFSET		19
+#define	TSEN_STATUS_TEMP_OUT_MASK		(0x1FF << TSEN_STATUS_TEMP_OUT_OFFSET)
+
+#define TSEN_CONF_REG				0x184D0
+#define	TSEN_CONF_OTF_CALIB_MASK		(0x1 << 30)
+#define	TSEN_CONF_START_CALIB_MASK		(0x1 << 25)
+#define	TSEN_CONF_REF_CAL_MASK			(0x1FF << 11)
+#define	TSEN_CONF_SOFT_RESET_MASK		(0x1 << 1)
+
+#define ARMADAXP_OVERHEAT_TEMP	105000		/* milidegree Celsius */
+#define ARMADAXP_OVERHEAT_DELAY	0x700
+#define ARMADAXP_OVERCOOL_TEMP	10000		/* milidegree Celsius */
+#define	ARMADAXP_OVERCOOL_DELAY	0x700
+#define ARMADAXP_OVERHEAT_MIN	0
+#define ARMADAXP_OVERHEAT_MAX	110000
+#define ARMADAXP_OVERCOOL_MIN	0
+#define ARMADAXP_OVERCOOL_MAX	110000
+
+/* Junction Temperature */
+#define ARMADAXP_TSEN_TEMP2RAW(x) ((3153000 - (13825 * x)) / 10000)
+#define ARMADAXP_TSEN_RAW2TEMP(x) ((3153000 - (10000 * x)) * 1000 / 13825)
+#if 0
+/* Dove */
+((2281638 - (10 * x)) / 7298)    /* in millCelsius */
+ ((2281638 - (7298 * x)) / 10)
+#endif
+
+#define LABEL "T-junction"
+static struct device *hwmon_dev;
+unsigned int temp_min = ARMADAXP_OVERCOOL_TEMP;
+unsigned int temp_max = ARMADAXP_OVERHEAT_TEMP;
+
+typedef enum {
+	SHOW_TEMP,
+	TEMP_MAX,
+	TEMP_MIN,
+	SHOW_NAME,
+	SHOW_TYPE,
+	SHOW_LABEL } SHOW;
+
+static void axptemp_set_thresholds(unsigned int max, unsigned int min)
+{
+#if 0
+	u32 temp, reg;
+
+	/* Set the overheat threashold & delay */
+	temp = ARMADAXP_TSEN_TEMP2RAW(max);
+	reg = readl(INTER_REGS_BASE | PMU_THERMAL_MNGR_REG);
+	reg &= ~PMU_TM_OVRHEAT_THRSH_MASK;
+	reg |= (temp << PMU_TM_OVRHEAT_THRSH_OFFS);
+	writel(reg, (INTER_REGS_BASE | PMU_THERMAL_MNGR_REG));
+
+	/* Set the overcool threshole & delay */
+	temp = ARMADAXP_TSEN_TEMP2RAW(min);
+	reg = readl(INTER_REGS_BASE | PMU_THERMAL_MNGR_REG);
+	reg &= ~PMU_TM_COOL_THRSH_MASK;
+	reg |= (temp << PMU_TM_COOL_THRSH_OFFS);
+	writel(reg, (INTER_REGS_BASE | PMU_THERMAL_MNGR_REG));
+#endif
+}
+
+static int axptemp_init_sensor(void)
+{
+	u32 reg;
+
+	/* init the TSEN sensor once */
+	/* Enable On-The-Fly Calibration mode */
+	reg = readl(INTER_REGS_BASE | TSEN_CONF_REG);
+	reg |= TSEN_CONF_OTF_CALIB_MASK;
+	writel(reg, (INTER_REGS_BASE | TSEN_CONF_REG));
+
+	/* Set the Reference Count value */
+	reg = readl(INTER_REGS_BASE | TSEN_CONF_REG);
+	reg &= ~(TSEN_CONF_REF_CAL_MASK);
+	reg |= (0xf1 << 11);
+	writel(reg, (INTER_REGS_BASE | TSEN_CONF_REG));
+
+	/* Do not start calibration sequence */
+	reg = readl(INTER_REGS_BASE | TSEN_CONF_REG);
+	reg &= ~(TSEN_CONF_START_CALIB_MASK);
+	writel(reg, (INTER_REGS_BASE | TSEN_CONF_REG));
+
+	/* Initiate Soft Reset
+	reg = readl(INTER_REGS_BASE | TSEN_CONF_REG);
+	reg |= TSEN_CONF_SOFT_RESET_MASK;
+	writel(reg, (INTER_REGS_BASE | TSEN_CONF_REG));
+	*/
+	//udelay(1000);
+
+	/* Exit from Soft Reset
+	reg = readl(INTER_REGS_BASE | TSEN_CONF_REG);
+	reg &= ~(TSEN_CONF_SOFT_RESET_MASK);
+	writel(reg, (INTER_REGS_BASE | TSEN_CONF_REG));
+	*/
+	//udelay(10000);
+
+#if 0
+	/* Set thresholds */
+	axptemp_set_thresholds(temp_max, temp_min);
+
+	/* Set delays */
+	writel(ARMADAXP_OVERHEAT_DELAY, (INTER_REGS_BASE | PMU_TM_OVRHEAT_DLY_REG));
+	writel(ARMADAXP_OVERCOOL_DELAY, (INTER_REGS_BASE | PMU_TM_COOLING_DLY_REG));
+#endif
+
+	return 0;
+}
+
+static int axptemp_read_temp(void)
+{
+	u32 reg;
+
+	reg = readl(INTER_REGS_BASE | TSEN_STATUS_REG);
+	reg = (reg & TSEN_STATUS_TEMP_OUT_MASK) >> TSEN_STATUS_TEMP_OUT_OFFSET;
+//	value = ((3153000 - (10000 * reg)) / 13825);
+
+	return ARMADAXP_TSEN_RAW2TEMP(reg);
+}
+
+
+/*
+ * Sysfs stuff
+ */
+
+static ssize_t show_name(struct device *dev, struct device_attribute
+			  *devattr, char *buf) {
+	return sprintf(buf, "%s\n", "axp-hwmon");
+}
+
+static ssize_t show_alarm(struct device *dev, struct device_attribute
+			  *devattr, char *buf)
+{
+#if 0
+	int alarm = 0;
+	u32 reg;
+
+	reg = readl(INTER_REGS_BASE | PMU_INT_CAUSE_REG);
+	if (reg & PMU_INT_OVRHEAT_MASK)
+	{
+		alarm = 1;
+		writel ((reg & ~PMU_INT_OVRHEAT_MASK), (INTER_REGS_BASE | PMU_INT_CAUSE_REG));
+	}
+	else if (reg & PMU_INT_COOLING_MASK)
+	{
+		alarm = 2;
+		writel ((reg & ~PMU_INT_COOLING_MASK), (INTER_REGS_BASE | PMU_INT_CAUSE_REG));
+	}
+#endif
+	return sprintf(buf, "%d\n", 0);
+}
+
+static ssize_t show_info(struct device *dev,
+			 struct device_attribute *devattr, char *buf) {
+	int ret;
+	struct sensor_device_attribute *attr = to_sensor_dev_attr(devattr);
+
+	if (attr->index == SHOW_TYPE)
+		ret = sprintf(buf, "%d\n", 3);
+	else if (attr->index == SHOW_LABEL)
+		ret = sprintf(buf, "%s\n", LABEL);
+	else
+		ret = sprintf(buf, "%d\n", -1);
+	return ret;
+}
+
+static ssize_t show_temp(struct device *dev,
+			 struct device_attribute *devattr, char *buf) {
+	int ret;
+	struct sensor_device_attribute *attr = to_sensor_dev_attr(devattr);
+
+	if (attr->index == SHOW_TEMP)
+		ret = sprintf(buf, "%d\n", axptemp_read_temp());
+	else if (attr->index == TEMP_MAX)
+		ret = sprintf(buf, "%d\n", temp_max);
+	else if (attr->index == TEMP_MIN)
+		ret = sprintf(buf, "%d\n", temp_min);
+	else
+		ret = sprintf(buf, "%d\n", -1);
+
+	return ret;
+}
+
+static ssize_t set_temp(struct device *dev, struct device_attribute *devattr,
+			 const char *buf, size_t count) {
+
+	struct sensor_device_attribute *attr = to_sensor_dev_attr(devattr);
+	unsigned int temp;
+
+	if (sscanf(buf, "%d", &temp) != 1)
+		printk(KERN_WARNING "Invalid input string for temperature!");
+
+	if (attr->index == TEMP_MAX) {
+		if((temp < ARMADAXP_OVERHEAT_MIN) || (temp > ARMADAXP_OVERHEAT_MAX))
+			printk(KERN_WARNING "Invalid max temperature input (out of range: %d-%d)!",
+				ARMADAXP_OVERHEAT_MIN, ARMADAXP_OVERHEAT_MAX);
+		else {
+			temp_max = temp;
+			axptemp_set_thresholds(temp_max, temp_min);
+		}
+	}
+	else if (attr->index == TEMP_MIN) {
+		if((temp < ARMADAXP_OVERCOOL_MIN) || (temp > ARMADAXP_OVERCOOL_MAX))
+			printk(KERN_WARNING "Invalid min temperature input (out of range: %d-%d)!",
+				ARMADAXP_OVERCOOL_MIN, ARMADAXP_OVERCOOL_MAX);
+		else {
+			temp_min = temp;
+			axptemp_set_thresholds(temp_max, temp_min);
+		}
+	}
+	else
+		printk(KERN_ERR "axp-temp: Invalid sensor attribute!");
+
+	printk(KERN_INFO "set_temp got string: %d\n", temp);
+
+	return count;
+}
+
+/* TODO - Add read/write support in order to support setting max/min */
+static SENSOR_DEVICE_ATTR(temp1_type, S_IRUGO, show_info, NULL,
+			  SHOW_TYPE);
+static SENSOR_DEVICE_ATTR(temp1_label, S_IRUGO, show_info, NULL,
+			  SHOW_LABEL);
+static SENSOR_DEVICE_ATTR(temp1_input, S_IRUGO, show_temp, NULL,
+			  SHOW_TEMP);
+static SENSOR_DEVICE_ATTR(temp1_max, S_IRWXUGO, show_temp, set_temp,
+			  TEMP_MAX);
+static SENSOR_DEVICE_ATTR(temp1_min, S_IRWXUGO, show_temp, set_temp,
+			  TEMP_MIN);
+static DEVICE_ATTR(temp1_crit_alarm, S_IRUGO, show_alarm, NULL);
+static SENSOR_DEVICE_ATTR(name, S_IRUGO, show_name, NULL, SHOW_NAME);
+
+static struct attribute *axptemp_attributes[] = {
+	&sensor_dev_attr_name.dev_attr.attr,
+	&dev_attr_temp1_crit_alarm.attr,
+	&sensor_dev_attr_temp1_input.dev_attr.attr,
+	&sensor_dev_attr_temp1_max.dev_attr.attr,
+	&sensor_dev_attr_temp1_min.dev_attr.attr,
+	&sensor_dev_attr_temp1_type.dev_attr.attr,
+	&sensor_dev_attr_temp1_label.dev_attr.attr,
+	NULL
+};
+
+static const struct attribute_group axptemp_group = {
+	.attrs = axptemp_attributes,
+};
+
+static int __devinit axptemp_probe(struct platform_device *pdev)
+{
+	int err;
+
+	err = axptemp_init_sensor();
+	if (err)
+		goto exit;
+
+	err = sysfs_create_group(&pdev->dev.kobj, &axptemp_group);
+	if (err)
+		goto exit;
+
+	hwmon_dev = hwmon_device_register(&pdev->dev);
+	if (IS_ERR(hwmon_dev)) {
+		dev_err(&pdev->dev, "Class registration failed (%d)\n",
+			err);
+		goto exit;
+	}
+
+	printk(KERN_INFO "Armada XP hwmon thermal sensor initialized.\n");
+
+	return 0;
+
+exit:
+	sysfs_remove_group(&pdev->dev.kobj, &axptemp_group);
+	return err;
+}
+
+static int __devexit axptemp_remove(struct platform_device *pdev)
+{
+	struct axptemp_data *data = platform_get_drvdata(pdev);
+
+	hwmon_device_unregister(hwmon_dev);
+	sysfs_remove_group(&pdev->dev.kobj, &axptemp_group);
+	platform_set_drvdata(pdev, NULL);
+	kfree(data);
+	return 0;
+}
+
+static int axptemp_resume(struct platform_device *dev)
+{
+	return axptemp_init_sensor();
+}
+
+static struct platform_driver axptemp_driver = {
+	.driver = {
+		.owner = THIS_MODULE,
+		.name = "axp-temp",
+	},
+	.probe = axptemp_probe,
+	.remove = __devexit_p(axptemp_remove),
+	.resume = axptemp_resume,
+};
+
+static int __init axptemp_init(void)
+{
+	return platform_driver_register(&axptemp_driver);
+}
+
+static void __exit axptemp_exit(void)
+{
+	platform_driver_unregister(&axptemp_driver);
+}
+
+MODULE_AUTHOR("Marvell Semiconductors");
+MODULE_DESCRIPTION("Marvell Armada XP SoC hwmon driver");
+MODULE_LICENSE("GPL");
+
+module_init(axptemp_init)
+module_exit(axptemp_exit)
diff --git a/arch/arm/mach-armadaxp/include/mach/armadaxp.h b/arch/arm/mach-armadaxp/include/mach/armadaxp.h
new file mode 100644
index 0000000..a3d8844
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/armadaxp.h
@@ -0,0 +1,216 @@
+/*
+ * include/asm-arm/arch-aurora/dove.h
+ *
+ * Generic definitions for Marvell Dove MV88F6781 SoC
+ *
+ * Author: Tzachi Perelstein <tzachi@marvell.com>
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#ifndef __ASM_ARCH_AURORA_H
+#define __ASM_ARCH_AURORA_H
+
+#include <mach/vmalloc.h>
+
+/****************************************************************/
+/******************* System Address Mapping *********************/
+/****************************************************************/
+
+/*
+ * Armada-XP address maps.
+ *
+ * phys		virt		size
+ * e0000000	@runtime	128M	PCIe-0 Memory space
+ * e8000000	@runtime	128M	PCIe-1 Memory space
+ * f0000000	fab00000	16M	SPI-CS0 (Flash)
+ * f1000000	fbb00000	1M	Internal Registers
+ * f1100000	fbc00000	1M	PCIe-0 I/O space
+ * f1200000	fbd00000	1M	PCIe-1 I/O space
+ * f1300000	fbe00000	1M	PCIe-2 I/O space
+ * f1400000	fbf00000	1M	PCIe-3 I/O space
+ * f1500000	fc000000	1M	PCIe-4 I/O space
+ * f1600000	fc100000	1M	PCIe-5 I/O space
+ * f1700000	fc200000	1M	PCIe-6 I/O space
+ * f1800000	fc300000	1M	PCIe-7 I/O space
+ * f1900000	fc400000	1M	PCIe-8 I/O space
+ * f1a00000	fc500000	1M	PCIe-9 I/O space
+ * f1b00000	fc600000	1M	DMA based UART
+ * f4000000	fe700000	1M	Device-CS0
+ * f2000000	fc700000	32M	Boot-Device CS (NOR Flash)
+ * f4100000	fe800000	1M	Device-CS1 (NOR Flash)
+ * f4200000	fe900000	1M	Device-CS2 (NOR Flash)
+ * f4300000	fea00000	1M	Device-CS3 (NOR Flash)
+ * f4400000	feb00000	1M	CESA SRAM (2 units)
+ * f4500000	fec00000	1M	NETA-BM (PNC)
+ * fff00000	fed00000	1M	BootROM
+ * f4700000	fee00800	1M	PMU Scratch pad
+ * f4800000	fef00000	1M	Legacy Nand Flash
+ */
+
+/*
+ * SDRAM Address decoding
+ * These values are dummy. Uboot configures these values.
+ */
+#define SDRAM_CS0_BASE  		0x00000000
+#define SDRAM_CS0_SIZE  		_256M
+#define SDRAM_CS1_BASE  		0x10000000
+#define SDRAM_CS1_SIZE  		_256M
+#define SDRAM_CS2_BASE  		0x20000000
+#define SDRAM_CS2_SIZE  		_256M
+#define SDRAM_CS3_BASE  		0x30000000
+#define SDRAM_CS3_SIZE  		_256M
+
+/*
+ * PEX Address Decoding
+ * Virtual address not specified - remapped @runtime
+ */
+#define PEX0_MEM_PHYS_BASE		0xE0000000
+#define PEX0_MEM_SIZE			_32M
+#define PEX1_MEM_PHYS_BASE		0xE2000000
+#define PEX1_MEM_SIZE			_32M
+#define PEX2_MEM_PHYS_BASE		0xE4000000
+#define PEX2_MEM_SIZE			_32M
+#define PEX3_MEM_PHYS_BASE		0xE6000000
+#define PEX3_MEM_SIZE			_32M
+#define PEX4_MEM_PHYS_BASE		0xE8000000
+#define PEX4_MEM_SIZE			_32M
+#define PEX5_MEM_PHYS_BASE		0x0	/*TBD*/
+#define PEX5_MEM_SIZE			_32M
+#define PEX6_MEM_PHYS_BASE		0xEA000000		
+#define PEX6_MEM_SIZE			_32M
+#define PEX7_MEM_PHYS_BASE		0x0	/*TBD*/
+#define PEX7_MEM_SIZE			_32M
+#define PEX8_MEM_PHYS_BASE		0xEC000000		
+#define PEX8_MEM_SIZE			_32M
+#define PEX9_MEM_PHYS_BASE		0xEE000000
+#define PEX9_MEM_SIZE			_32M
+
+#define SPI_CS0_PHYS_BASE		0xF0000000
+#define SPI_CS0_VIRT_BASE		0xFAB00000
+#define SPI_CS0_SIZE			_16M
+
+#ifdef CONFIG_MACH_ARMADA_XP_FPGA
+ #define INTER_REGS_PHYS_BASE		0xF1000000
+ /* Make sure that no other machines are compiled in */
+ #if defined (CONFIG_MACH_ARMADA_XP_DB) || defined (CONFIG_MACH_ARMADA_XP_RDSRV)
+ #error	"Conflicting Board Configuration!!"
+ #endif
+#else
+ #define INTER_REGS_PHYS_BASE		0xD0000000
+#endif
+#define INTER_REGS_BASE			0xFBB00000
+
+#define PEX0_IO_PHYS_BASE		0xF1100000
+#define PEX0_IO_VIRT_BASE		0xFBC00000
+#define PEX0_IO_SIZE			_1M
+#define PEX1_IO_PHYS_BASE		0xF1200000
+#define PEX1_IO_VIRT_BASE		0xFBD00000
+#define PEX1_IO_SIZE			_1M
+#define PEX2_IO_PHYS_BASE		0xF1300000
+#define PEX2_IO_VIRT_BASE		0xFBE00000
+#define PEX2_IO_SIZE			_1M
+#define PEX3_IO_PHYS_BASE		0xF1400000
+#define PEX3_IO_VIRT_BASE		0xFBF00000
+#define PEX3_IO_SIZE			_1M
+#define PEX4_IO_PHYS_BASE		0xF1500000
+#define PEX4_IO_VIRT_BASE		0xFC000000
+#define PEX4_IO_SIZE			_1M
+#define PEX5_IO_PHYS_BASE		0xF1600000
+#define PEX5_IO_VIRT_BASE		0xFC100000
+#define PEX5_IO_SIZE			_1M
+#define PEX6_IO_PHYS_BASE		0xF1700000
+#define PEX6_IO_VIRT_BASE		0xFC200000
+#define PEX6_IO_SIZE			_1M
+#define PEX7_IO_PHYS_BASE		0xF1800000
+#define PEX7_IO_VIRT_BASE		0xFC300000
+#define PEX7_IO_SIZE			_1M
+#define PEX8_IO_PHYS_BASE		0xF1900000
+#define PEX8_IO_VIRT_BASE		0xFC400000
+#define PEX8_IO_SIZE			_1M
+#define PEX9_IO_PHYS_BASE		0xF1A00000
+#define PEX9_IO_VIRT_BASE		0xFC500000
+#define PEX9_IO_SIZE			_1M
+
+#define UART_REGS_BASE			0xF1B00000
+#define UART_VIRT_BASE			0xFC600000
+#define UART_SIZE			_1M
+
+#define DEVICE_BOOTCS_PHYS_BASE		0xF2000000
+#define DEVICE_BOOTCS_VIRT_BASE		0xFC700000
+#define DEVICE_BOOTCS_SIZE		_32M
+#define DEVICE_CS0_PHYS_BASE		0xF4000000
+#define DEVICE_CS0_VIRT_BASE		0xFE700000
+#define DEVICE_CS0_SIZE			_1M
+#define DEVICE_CS1_PHYS_BASE		0xF4100000
+#define DEVICE_CS1_VIRT_BASE		0xFE800000
+#define DEVICE_CS1_SIZE			_1M
+#define DEVICE_CS2_PHYS_BASE		0xF4200000
+#define DEVICE_CS2_VIRT_BASE		0xFE900000
+#define DEVICE_CS2_SIZE			_1M
+#define DEVICE_CS3_PHYS_BASE		0xF4300000
+#define DEVICE_CS3_VIRT_BASE		0xFEA00000
+#define DEVICE_CS3_SIZE			_1M
+
+#define CRYPT_ENG_PHYS_BASE(chan)	((chan == 0) ? 0xC8010000 : 0xF4480000)
+#define CRYPT_ENG_VIRT_BASE(chan)	((chan == 0) ? 0xFEB00000 : 0xFEB10000)
+#define CRYPT_ENG_SIZE			_64K
+
+#define XOR0_PHYS_BASE			(INTER_REGS_PHYS_BASE | 0x60800)
+#define XOR1_PHYS_BASE			(INTER_REGS_PHYS_BASE | 0x60900)
+#define XOR0_HIGH_PHYS_BASE		(INTER_REGS_PHYS_BASE | 0x60B00)
+#define XOR1_HIGH_PHYS_BASE		(INTER_REGS_PHYS_BASE | 0xF0B00)
+
+#define PNC_BM_PHYS_BASE		0xF4500000
+#define PNC_BM_VIRT_BASE		0xFEC00000
+#define PNC_BM_SIZE			_1M
+
+#define BOOTROM_PHYS_BASE		0xFFF00000
+#define BOOTROM_VIRT_BASE		0xFED00000
+#define BOOTROM_SIZE			_1M
+
+#define PMU_SCRATCH_PHYS_BASE		0xF4700000
+#define PMU_SCRATCH_VIRT_BASE		0xFEE00000
+#define PMU_SCRATCH_SIZE		_1M
+
+#define LEGACY_NAND_PHYS_BASE		0xF4800000
+#define LEGACY_NAND_VIRT_BASE		0xFEF00000
+#define LEGACY_NAND_SIZE		_1M
+
+#define	LCD_PHYS_BASE			(INTER_REGS_PHYS_BASE | 0xE0000)
+
+#define AXP_NFC_PHYS_BASE	(INTER_REGS_PHYS_BASE | 0xD0000)
+
+/*
+ * Linux native definitiotns
+ */
+#define SDRAM_OPERATION_REG		(INTER_REGS_BASE | 0x1418)
+#define AXP_UART0_PHYS_BASE		(INTER_REGS_PHYS_BASE | 0x12000)
+#define DDR_VIRT_BASE			(INTER_REGS_BASE | 0x00000)
+#define AXP_BRIDGE_VIRT_BASE		(INTER_REGS_BASE | 0x20000)
+#define AXP_BRIDGE_PHYS_BASE		(INTER_REGS_PHYS_BASE | 0x20000)
+#define DDR_WINDOW_CPU_BASE		(DDR_VIRT_BASE | 0x1500)
+#define AXP_SW_TRIG_IRQ			(AXP_BRIDGE_VIRT_BASE | 0x0A04)
+#define AXP_SW_TRIG_IRQ_PHYS		(AXP_BRIDGE_PHYS_BASE | 0x0A04)
+#define AXP_SW_TRIG_IRQ_CPU_TARGET_OFFS	8
+#define AXP_SW_TRIG_IRQ_INITID_MASK	0x1F
+#define AXP_PER_CPU_BASE		(AXP_BRIDGE_VIRT_BASE | 0x1000)
+#define AXP_IRQ_VIRT_BASE		(AXP_PER_CPU_BASE)
+#define AXP_CPU_INTACK			0xB4
+#define AXP_IRQ_SEL_CAUSE_OFF		0xA0
+#define AXP_IN_DOORBELL_CAUSE		0x78
+#define AXP_IN_DRBEL_CAUSE			(AXP_PER_CPU_BASE | 0x78)
+#define AXP_IN_DRBEL_MSK			(AXP_PER_CPU_BASE | 0x7c)
+
+#ifdef CONFIG_MACH_ARMADA_XP_FPGA
+#define AXP_CPU_RESUME_ADDR_REG(cpu)	(AXP_BRIDGE_VIRT_BASE | 0x984)
+#else
+#define AXP_CPU_RESUME_ADDR_REG(cpu)	(AXP_BRIDGE_VIRT_BASE | (0x2124+(cpu)*0x100))
+#endif
+#define AXP_CPU_RESUME_CTRL_REG		(AXP_BRIDGE_VIRT_BASE | 0x988)
+#define AXP_CPU_RESET_REG(cpu)		(AXP_BRIDGE_VIRT_BASE | (0x800+(cpu)*8))
+#define AXP_L2_CLEAN_WAY_REG		(INTER_REGS_BASE | 0x87BC) 
+#define AXP_L2_MNTNC_STAT_REG		(INTER_REGS_BASE | 0x8704)
+#endif
diff --git a/arch/arm/mach-armadaxp/include/mach/clkdev.h b/arch/arm/mach-armadaxp/include/mach/clkdev.h
new file mode 100644
index 0000000..04b37a8
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/clkdev.h
@@ -0,0 +1,7 @@
+#ifndef __ASM_MACH_CLKDEV_H
+#define __ASM_MACH_CLKDEV_H
+
+#define __clk_get(clk) ({ 1; })
+#define __clk_put(clk) do { } while (0)
+
+#endif
diff --git a/arch/arm/mach-armadaxp/include/mach/debug-macro.S b/arch/arm/mach-armadaxp/include/mach/debug-macro.S
new file mode 100644
index 0000000..ee535f2
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/debug-macro.S
@@ -0,0 +1,20 @@
+/*
+ * debug-macro.S
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+*/
+
+#include <mach/armadaxp.h>
+
+	
+	.macro  addruart, rp, rv
+	ldr     \rp, =INTER_REGS_PHYS_BASE
+	ldr	\rv, =INTER_REGS_BASE
+	orr     \rp, \rp, #0x00012000
+        orr     \rv, \rv, #0x00012000	
+	.endm
+
+#define UART_SHIFT	2
+#include <asm/hardware/debug-8250.S>
diff --git a/arch/arm/mach-armadaxp/include/mach/dma.h b/arch/arm/mach-armadaxp/include/mach/dma.h
new file mode 100644
index 0000000..8e2f2d0
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/dma.h
@@ -0,0 +1,16 @@
+/*
+ * DaVinci DMA definitions
+ *
+ * Author: Kevin Hilman, MontaVista Software, Inc. <source@mvista.com>
+ *
+ * 2007 (c) MontaVista Software, Inc. This file is licensed under
+ * the terms of the GNU General Public License version 2. This program
+ * is licensed "as is" without any warranty of any kind, whether express
+ * or implied.
+ */
+#ifndef __ASM_ARCH_DMA_H
+#define __ASM_ARCH_DMA_H
+
+#define MAX_DMA_ADDRESS			0xffffffff
+
+#endif /* __ASM_ARCH_DMA_H */
diff --git a/arch/arm/mach-armadaxp/include/mach/dove_bl.h b/arch/arm/mach-armadaxp/include/mach/dove_bl.h
new file mode 100644
index 0000000..8a447f2
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/dove_bl.h
@@ -0,0 +1,35 @@
+#ifndef __ASM_ARCH_DOVE_BL_H
+#define __ASM_ARCH_DOVE_BL_H
+#include <linux/ioport.h>
+
+struct dovebl_platform_data {
+	int	default_intensity;
+	int	gpio_pm_control; /* enable LCD/panel power management via gpio*/
+
+	resource_size_t lcd_start;	/* lcd power control reg base. */
+	resource_size_t lcd_end;	/* end of reg map. */
+	unsigned long lcd_offset;	/* register offset */
+	unsigned long lcd_mapped;	/* pa = 0, va = 1 */
+	unsigned long lcd_mask;		/* mask */
+	unsigned long lcd_on;		/* value to enable lcd power */
+	unsigned long lcd_off;		/* value to disable lcd power */
+
+	resource_size_t blpwr_start;	/* backlight pwr ctrl reg base. */
+	resource_size_t blpwr_end;	/* end of reg map. */
+	unsigned long blpwr_offset;	/* register offset */
+	unsigned long blpwr_mapped;	/* pa = 0, va = 1 */
+	unsigned long blpwr_mask;	/* mask */
+	unsigned long blpwr_on;		/* value to enable bl power */
+	unsigned long blpwr_off;	/* value to disable bl power */
+
+	resource_size_t btn_start;	/* brightness control reg base. */
+	resource_size_t btn_end;	/* end of reg map. */
+	unsigned long btn_offset;	/* register offset */
+	unsigned long btn_mapped;	/* pa = 0, va = 1 */
+	unsigned long btn_mask;	/* mask */
+	unsigned long btn_level;	/* how many level can be configured. */
+	unsigned long btn_min;	/* min value */
+	unsigned long btn_max;	/* max value */
+	unsigned long btn_inc;	/* increment */
+};
+#endif /* __ASM_ARCH_DOVE_BL_H */
diff --git a/arch/arm/mach-armadaxp/include/mach/entry-macro.S b/arch/arm/mach-armadaxp/include/mach/entry-macro.S
new file mode 100644
index 0000000..98f5b90
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/entry-macro.S
@@ -0,0 +1,171 @@
+/*
+ * include/asm-arm/arch-mv78xx0/entry-macro.S
+ *
+ * Low-level IRQ helper macros for Marvell MV78xx0 platforms
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#include <mach/armadaxp.h>
+
+	.macro	disable_fiq
+	.endm
+
+	.macro  get_irqnr_preamble, base, tmp
+	ldr	\base, =AXP_IRQ_VIRT_BASE
+	.endm
+
+	.macro  arch_ret_to_user, tmp1, tmp2
+	.endm
+#ifndef CONFIG_ARMADAXP_USE_IRQ_INTERRUPT_ACK
+
+#if defined(CONFIG_CPU_BIG_ENDIAN)
+        	.macro	HTOLL sr, tt		@ sr   = A  ,B  ,C  ,D    
+        	eor \tt, \sr, \sr, ror #16 ;    @ temp = A^C,B^	  
+        	bic \tt, \tt, #0xff0000 ;       @ temp = A^C,0  ,C^A,D^B
+        	mov \sr, \sr, ror #8 ;          @ sr   = D  ,A  ,B  ,C
+        	eor \sr, \sr, \tt, lsr #8       @ sr   = D  ,C  ,B  ,A
+        	.endm
+#else		
+        	.macro	HTOLL sr, tt	
+        	.endm
+#endif
+	/* TBD - need to be optimized 29*(sel-1) + cls 						*/
+	/* r1 - we shouldnt use it here 							*/
+	/* in case of SMP we only handle bit 0,1 (doorbell) and 5,6 (timer) from cause Vec 0 	*/
+	/* return value is: irqnr and the flag state!!!!!!!!!!!!				*/
+	.macro  get_irqnr_and_base, irqnr, irqstat, base, tmp
+	@ check low interrupts
+	ldr	\irqstat, [\base, #AXP_IRQ_SEL_CAUSE_OFF]			
+	HTOLL	\irqstat, \tmp
+	ands 	\tmp, \irqstat, #0x80000000		@ did we get irq
+	beq	1001f	
+	mov 	\tmp, \irqstat
+
+	mov 	\tmp, \tmp, lsr #29 			@ determine the irq group,  
+	bics	\tmp, \tmp, #4 	 			@ clear irq_stat bit
+
+#ifdef CONFIG_SMP
+	@ if vec sel is 0 and bits 0-7 are set then it is IPI/PMU/Local timer handled seperatly.	
+	bne	1000f
+	ands	\tmp, \irqstat, #0xfd
+	beq 	1000f
+
+	@restore tmp - should be optimized!!!!
+        mov     \tmp, \irqstat
+
+        mov     \tmp, \tmp, lsr #29                     @ determine the irq group,
+        bics    \tmp, \tmp, #4                          @ clear irq_stat bit
+	beq	1001f
+
+#endif
+1000:
+	bic	\irqstat, \irqstat, #(0xE0000000) 	@ leave irq bits, clear the rest				
+	mov    	\irqnr, #0x1F
+	orrs    \irqnr, \irqnr, \tmp, lsl #5    	@ irqnr = 0x1F, 0x3F, 0x5F, 0x7f, make sure Z is off	
+	clz	\irqstat, \irqstat	              	@ find first active interrupt source
+	sub	\irqnr, \irqnr, \irqstat
+	mov 	r1, #3	
+	mul	\tmp, r1, \tmp
+	sub 	\irqnr, \irqnr, \tmp
+1001:	
+	.endm
+
+
+        /* We assume that irqstat (the raw value of the IRQ acknowledge
+         * register) is preserved from the macro above.
+         */
+
+	.macro test_for_ipi, irqnr, irqstat, base, tmp
+	ands 	\tmp, \irqstat, #0x80000000		@ did we get irq
+	beq	1002f
+	ands 	\tmp, \irqstat, #0x00000001		@ was it doorbell
+	beq	1002f
+	mov 	\tmp, #0
+	strh   	\tmp, [\base, #AXP_IN_DOORBELL_CAUSE]	@ clean irq
+1002:
+	.endm
+
+
+	/* As above, this assumes that irqstat and base are preserved.. */
+
+	.macro test_for_ltirq, irqnr, irqstat, base, tmp
+	ands 	\tmp, \irqstat, #0x80000000		@ did we get irq
+	beq	1003f
+	ands 	\tmp, \irqstat, #0x00000060		@ was it timer
+1003:
+	.endm
+
+
+	.macro test_for_pmuirq, irqnr, irqstat, base, tmp
+	ands 	\tmp, \irqstat, #0x80000000		@ did we get irq
+	beq	1005f
+	ands 	\tmp, \irqstat, #0x00000008		@ was it mp
+1005:
+	.endm
+	
+#else
+		/*
+		 * The interrupt numbering scheme is defined in the
+		 * interrupt controller spec.
+		 *
+		 * Interrupts 0-2 are IPI
+		 * 0-31 are local.
+		 * 32-1022 are global
+		 * 1023 is "spurious" (no interrupt)
+		 */
+
+		.macro  get_irqnr_and_base, irqnr, irqstat, base, tmp
+
+		ldr     \irqstat, [\base, #AXP_CPU_INTACK]
+		ldr	\tmp, =1023
+		and     \irqnr, \irqstat, \tmp
+#ifdef CONFIG_SMP
+		cmp     \irqnr, #7	
+		cmpcc	\irqnr, \irqnr
+		cmpne	\irqnr, \tmp
+		cmpcs	\irqnr, \irqnr
+#else
+		cmp     \irqnr, \tmp
+#endif
+		.endm
+
+		/* We assume that irqstat (the raw value of the IRQ acknowledge
+		 * register) is preserved from the macro above.
+		 * If there is an IPI, we immediately signal end of interrupt on the
+		 * controller, since this requires the original irqstat value which
+		 * we won't easily be able to recreate later.
+		 */
+
+		.macro test_for_ipi, irqnr, irqstat, base, tmp
+		ldr	\tmp, =1023
+		and     \irqnr, \irqstat, \tmp
+		cmp	\irqnr, #3
+		movcc	\tmp, #0
+		strcc	\tmp, [\base, #AXP_IN_DOORBELL_CAUSE]   @ clean ipi irq
+		cmpcs	\irqnr, \irqnr
+
+		.endm
+
+		/* As above, this assumes that irqstat and base are preserved.. */
+
+		.macro test_for_ltirq, irqnr, irqstat, base, tmp
+		ldr	\tmp, =1023
+		and     \irqnr, \irqstat, \tmp
+		mov	\tmp, #0
+		cmp	\irqnr, #5
+		moveq   \tmp, #1
+		cmp     \tmp, #0
+		.endm
+
+		.macro test_for_pmuirq, irqnr, irqstat, base, tmp
+		ldr	\tmp, =1023
+		and     \irqnr, \irqstat, \tmp
+		mov	\tmp, #0
+		cmp	\irqnr, #3
+		moveq	\tmp, #1
+		cmp	\tmp, #0
+		.endm
+#endif
diff --git a/arch/arm/mach-armadaxp/include/mach/gpio.h b/arch/arm/mach-armadaxp/include/mach/gpio.h
new file mode 100644
index 0000000..7ca789d
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/gpio.h
@@ -0,0 +1,55 @@
+/*
+ * include/asm-arm/arch-dove/gpio.h
+ *
+ * Author: Tzachi Perelstein <tzachi@marvell.com>
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#ifndef __ASM_ARCH_GPIO_H
+#define __ASM_ARCH_GPIO_H
+
+#include <asm/errno.h>
+#include <mach/irqs.h>
+#include <plat/gpio.h>
+#include <asm-generic/gpio.h>		/* cansleep wrappers */
+
+#define gpio_get_value	__gpio_get_value
+#define gpio_set_value	__gpio_set_value
+#define gpio_cansleep	__gpio_cansleep
+
+#define GPIO_MAX	64
+
+#define GPIO_BASE_LO		(AURORA_GPIO_VIRT_BASE + 0x00)
+#define GPIO_BASE_HI		(AURORA_GPIO_VIRT_BASE + 0x20)
+
+#define GPIO_BASE(pin)		((pin < 32) ? GPIO_BASE_LO : GPIO_BASE_HI)
+
+#define GPIO_OUT(pin)		(GPIO_BASE(pin) + 0x00)
+#define GPIO_IO_CONF(pin)	(GPIO_BASE(pin) + 0x04)
+#define GPIO_BLINK_EN(pin)	(GPIO_BASE(pin) + 0x08)
+#define GPIO_IN_POL(pin)	(GPIO_BASE(pin) + 0x0c)
+#define GPIO_DATA_IN(pin)	(GPIO_BASE(pin) + 0x10)
+#define GPIO_EDGE_CAUSE(pin)	(GPIO_BASE(pin) + 0x14)
+#define GPIO_EDGE_MASK(pin)	(GPIO_BASE(pin) + 0x18)
+#define GPIO_LEVEL_MASK(pin)	(GPIO_BASE(pin) + 0x1c)
+
+static inline int gpio_to_irq(int pin)
+{
+	if (pin < NR_GPIO_IRQS)
+		return pin + IRQ_AURORA_GPIO_START;
+
+	return -EINVAL;
+}
+
+static inline int irq_to_gpio(int irq)
+{
+	if (IRQ_AURORA_GPIO_START < irq && irq < NR_IRQS)
+		return irq - IRQ_AURORA_GPIO_START;
+
+	return -EINVAL;
+}
+
+#endif
diff --git a/arch/arm/mach-armadaxp/include/mach/hardware.h b/arch/arm/mach-armadaxp/include/mach/hardware.h
new file mode 100644
index 0000000..e937269
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/hardware.h
@@ -0,0 +1,21 @@
+/*
+ * include/mach/hardware.h
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#ifndef __ASM_ARCH_HARDWARE_H
+#define __ASM_ARCH_HARDWARE_H
+
+#include "armadaxp.h"
+
+#define pcibios_assign_all_busses()	1
+
+#define PCIBIOS_MIN_IO			0x1000
+#define PCIBIOS_MIN_MEM			0x01000000
+#define PCIMEM_BASE			PEX0_MEM_PHYS_BASE /* mem base for VGA */
+
+
+#endif
diff --git a/arch/arm/mach-armadaxp/include/mach/ide.h b/arch/arm/mach-armadaxp/include/mach/ide.h
new file mode 100644
index 0000000..04e0bca
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/ide.h
@@ -0,0 +1,15 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
diff --git a/arch/arm/mach-armadaxp/include/mach/io.h b/arch/arm/mach-armadaxp/include/mach/io.h
new file mode 100644
index 0000000..0d8a34a
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/io.h
@@ -0,0 +1,32 @@
+/*
+ * include/asm-arm/arch-dove/io.h
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#ifndef __ASM_ARCH_IO_H
+#define __ASM_ARCH_IO_H
+
+#include "armadaxp.h"
+
+#define IO_SPACE_LIMIT		0xffffffff
+#define IO_SPACE_REMAP 		PEX0_IO_PHYS_BASE
+
+#define __io(a)			((a) + PEX0_IO_VIRT_BASE)
+#define __mem_pci(a)		((unsigned long)(a))
+#define __mem_isa(a)		(a)
+
+/*#define aurora_setbits(r, mask)	writel(readl(r) | (mask), (r))
+#define aurora_clrbits(r, mask)	writel(readl(r) & ~(mask), (r))*/
+
+#ifdef CONFIG_AURORA_IO_CACHE_COHERENCY
+#define dma_io_sync()	do {				\
+	writel(0x1, INTER_REGS_BASE + 0x21810);		\
+	while (readl(INTER_REGS_BASE + 0x21810) & 0x1);	\
+} while (0)
+#else
+#define dma_io_sync()	do { } while (0)
+#endif
+#endif
diff --git a/arch/arm/mach-armadaxp/include/mach/irqs.h b/arch/arm/mach-armadaxp/include/mach/irqs.h
new file mode 100644
index 0000000..6d281c5
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/irqs.h
@@ -0,0 +1,170 @@
+/*
+ * include/asm-arm/arch-aurora/irqs.h
+ *
+ * IRQ definitions for Marvell Dove MV88F6781 SoC
+ *
+ * Author: Tzachi Perelstein <tzachi@marvell.com>
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#ifndef __ASM_ARCH_IRQS_H
+#define __ASM_ARCH_IRQS_H
+
+/*
+ * Aurora Low Interrupt Controller
+ */
+
+#define IRQ_AURORA_IN_DRBL_LOW	0
+#define IRQ_AURORA_IN_DRBL_HIGH	1
+#define IRQ_AURORA_OUT_DRBL 	2
+#define IRQ_AURORA_MP		3
+#define IRQ_AURORA_SOC_ERROR	4
+#define IRQ_AURORA_TIMER0	5
+#define IRQ_LOCALTIMER 		IRQ_AURORA_TIMER0
+#define IRQ_AURORA_TIMER1	6
+#define IRQ_AURORA_WD		7
+
+#define IRQ_AURORA_GBE0_FIC	8
+#define IRQ_AURORA_GBE0_SIC	9
+#define IRQ_AURORA_GBE1_FIC	10
+#define IRQ_AURORA_GBE1_SIC	11
+#define IRQ_AURORA_GBE2_FIC     12
+#define IRQ_AURORA_GBE2_SIC	13
+#define IRQ_AURORA_GBE3_FIC	14
+#define IRQ_AURORA_GBE3_SIC	15
+
+#define IRQ_AURORA_LCD		29
+#define IRQ_AURORA_SPI          30
+#define IRQ_AURORA_I2C0		31
+#define IRQ_AURORA_I2C1		32
+
+#define IRQ_AURORA_DMA0		33
+#define IRQ_AURORA_DMA1		34
+#define IRQ_AURORA_DMA2		35
+#define IRQ_AURORA_DMA3		36
+
+#define IRQ_AURORA_GLOB_TIMER0	37
+#define IRQ_AURORA_GLOB_TIMER1	38
+#define IRQ_AURORA_GLOB_TIMER2	39
+#define IRQ_AURORA_GLOB_TIMER3	40
+
+#define IRQ_AURORA_UART0	41
+#define IRQ_AURORA_UART1	42
+#define IRQ_AURORA_UART2	43
+#define IRQ_AURORA_UART3	44
+
+#define IRQ_AURORA_USB0		45
+#define IRQ_AURORA_USB1		46
+#define IRQ_AURORA_USB2		47
+
+#define IRQ_AURORA_CRYPTO(chan)	((chan == 0) ? 48 : 49)
+
+#define IRQ_AURORA_RTC		50
+
+#define IRQ_AURORA_XOR0		51
+#define IRQ_AURORA_XOR1		52
+
+#define IRQ_AURORA_BM		53
+#define IRQ_AURORA_SDIO		54
+#define IRQ_AURORA_SATA0	55
+#define IRQ_AURORA_TDM		56
+#define IRQ_AURORA_SATA1	57
+	
+#define IRQ_AURORA_PCIE0	58
+#define IRQ_AURORA_PCIE1	59
+#define IRQ_AURORA_PCIE2	60
+#define IRQ_AURORA_PCIE3	61
+#define IRQ_AURORA_PCIE4	62
+#define IRQ_AURORA_PCIE5	63
+#define IRQ_AURORA_PCI0		63	/* FPGA only */
+#define IRQ_AURORA_PCIE6	64
+#define IRQ_AURORA_PCIE7	65
+
+#define IRQ_AURORA_GBE0		66
+#define IRQ_AURORA_GBE0_RX	67
+#define IRQ_AURORA_GBE0_TX	68
+#define IRQ_AURORA_GBE0_MISC	69
+#define IRQ_AURORA_GBE1		70
+#define IRQ_AURORA_GBE1_RX	71
+#define IRQ_AURORA_GBE1_TX	72
+#define IRQ_AURORA_GBE1_MISC	73
+#define IRQ_AURORA_GBE2		74
+#define IRQ_AURORA_GBE2_RX	75
+#define IRQ_AURORA_GBE2_TX	76
+#define IRQ_AURORA_GBE2_MISC	77
+#define IRQ_AURORA_GBE3		78
+#define IRQ_AURORA_GBE3_RX	79
+#define IRQ_AURORA_GBE3_TX	80
+#define IRQ_AURORA_GBE3_MISC	81
+
+#define IRQ_AURORA_GPIO_0_7	82
+#define IRQ_AURORA_GPIO_8_15	83
+#define IRQ_AURORA_GPIO_16_23	84
+#define IRQ_AURORA_GPIO_24_31	85
+#define IRQ_AURORA_GPIO_32_39	87
+#define IRQ_AURORA_GPIO_40_47	88
+#define IRQ_AURORA_GPIO_48_55	89
+#define IRQ_AURORA_GPIO_56_63	90
+#define IRQ_AURORA_GPIO_64_66	91
+
+#define IRQ_AURORA_XOR2		94
+#define IRQ_AURORA_XOR3		95
+
+#define IRQ_AURORA_SHARE_INB_DB0	96
+#define IRQ_AURORA_SHARE_INB_DB1	97
+#define IRQ_AURORA_SHARE_INB_DB2	98
+
+#define IRQ_AURORA_PCIE8	99
+#define IRQ_AURORA_PCIE9	103
+
+#define IRQ_AURORA_OVRHT	107
+
+#define IRQ_AURORA_DRAM		108
+
+#define IRQ_AURORA_NET_WKUP0	109
+#define IRQ_AURORA_NET_WKUP1	110
+#define IRQ_AURORA_NET_WKUP2	111
+#define IRQ_AURORA_NET_WKUP3	112
+
+#define IRQ_AURORA_NFC		113
+
+#define IRQ_AURORA_MTL_FIX	114
+
+#define IRQ_AURORA_OVRCL	115
+
+#define IRQ_MAIN_INTS_NUM	116
+
+/*
+ * AURORA General Purpose Pins
+ */
+#define IRQ_AURORA_GPIO_START		128
+#define NR_GPIO_IRQS			67
+
+/*
+ * AURORA MSI interrupts
+ */
+#define NR_PRIVATE_MSI_GROUP		16
+#define NR_PRIVATE_MSI_IRQS		NR_PRIVATE_MSI_GROUP
+#define NR_MSI_IRQS			NR_PRIVATE_MSI_IRQS
+#define IRQ_AURORA_MSI_START		(IRQ_AURORA_GPIO_START + NR_GPIO_IRQS)
+#define NR_IRQS				(IRQ_AURORA_GPIO_START + NR_GPIO_IRQS + NR_MSI_IRQS)
+#define GPP_IRQ_TYPE_LEVEL		0
+#define GPP_IRQ_TYPE_CHANGE_LEVEL	1
+
+/*
+ * Aurora Error interrupts
+ */
+
+#define INT_ERR_CESA0         		0
+#define INT_ERR_DEVBUS         		1
+
+/*
+ * IRQ HAL remapping
+ */
+#define NET_TH_RXTX_IRQ_NUM(x)		(IRQ_AURORA_GBE0_FIC + ((x) * 2))
+#define SATA_IRQ_NUM			(IRQ_AURORA_SATA0)
+#define CESA_IRQ(chan)			IRQ_AURORA_CRYPTO(chan)
+#endif
diff --git a/arch/arm/mach-armadaxp/include/mach/kw_macro.h b/arch/arm/mach-armadaxp/include/mach/kw_macro.h
new file mode 100644
index 0000000..9e0525a
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/kw_macro.h
@@ -0,0 +1,39 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ *
+ * Assembler-only file 
+ */
+
+
+support_wait_for_interrupt_address:
+        .word   support_wait_for_interrupt
+
+/* rd, rs, rt, re - are temp registers that will b used (non are input/output) */
+.macro mv_flush_all, rd, rs, rt, re
+	mov     \re, #0
+
+        mov     \rd, #(4 - 1) << 30      @ 4 way cache
+        mov     \rs, #(256 * CACHE_DLINESIZE)
+
+1:      orr     \rt, \re, \rd
+2:      mcr     p15, 0, \rt, c7, c14, 2          @ clean & invalidate D index
+        subs    \rt, \rt, #1 << 30
+        bcs     2b                              @ entries 3 to 0
+        add     \re, \re, #32
+        cmp     \re, \rs
+        bne     1b
+
+/* exit */	
+	.endm
diff --git a/arch/arm/mach-armadaxp/include/mach/memory.h b/arch/arm/mach-armadaxp/include/mach/memory.h
new file mode 100644
index 0000000..4fb5666
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/memory.h
@@ -0,0 +1,34 @@
+/*
+ * include/asm-arm/arch-mv78xx0/memory.h
+ */
+
+#ifndef __ASM_ARCH_MEMORY_H
+#define __ASM_ARCH_MEMORY_H
+
+#define PHYS_OFFSET		UL(0x00000000)
+
+/* #define __virt_to_bus(x)	__virt_to_phys(x) */
+/* #define __bus_to_virt(x)	__phys_to_virt(x) */
+
+
+/* Override the ARM default */
+#if 0
+#ifdef CONFIG_FB_DOVE_CONSISTENT_DMA_SIZE
+
+#if (CONFIG_FB_DOVE_CONSISTENT_DMA_SIZE == 0)
+#undef CONFIG_FB_DOVE_CONSISTENT_DMA_SIZE
+#define CONFIG_FB_DOVE_CONSISTENT_DMA_SIZE 2
+#endif
+
+#define CONSISTENT_DMA_SIZE \
+	(((CONFIG_FB_DOVE_CONSISTENT_DMA_SIZE + 1) & ~1) * 1024 * 1024)
+
+#endif
+#endif
+
+#ifdef CONFIG_AURORA_IO_CACHE_COHERENCY
+#define arch_is_coherent()  1  
+#endif
+
+
+#endif
diff --git a/arch/arm/mach-armadaxp/include/mach/param.h b/arch/arm/mach-armadaxp/include/mach/param.h
new file mode 100644
index 0000000..04e0bca
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/param.h
@@ -0,0 +1,15 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
diff --git a/arch/arm/mach-armadaxp/include/mach/serial.h b/arch/arm/mach-armadaxp/include/mach/serial.h
new file mode 100644
index 0000000..7f57c8c
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/serial.h
@@ -0,0 +1,41 @@
+/*
+ *  linux/include/asm-arm/arch-integrator/serial.h
+ *
+ *  Copyright (C) 1999 ARM Limited
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#ifndef __ASM_ARCH_SERIAL_H
+#define __ASM_ARCH_SERIAL_H
+
+#include <asm/irq.h>
+//#include <linux/autoconf.h>
+
+#include "../arch/arm/mach-armadaxp/config/mvSysHwConfig.h"
+
+extern unsigned int mvTclk;
+
+#undef  BASE_BAUD
+#define BASE_BAUD (mvTclk / 16)
+
+#define PORT0_BASE	(INTER_REGS_BASE + 0x12000) /* port 0 base */
+#define PORT1_BASE 	(INTER_REGS_BASE + 0x12100) /* port 1 base */
+
+#define STD_COM_FLAGS (ASYNC_BOOT_AUTOCONF | ASYNC_SKIP_TEST /* | ASYNC_SPD_VHI  115200 */ )
+
+#define STD_SERIAL_PORT_DEFNS
+#define EXTRA_SERIAL_PORT_DEFNS
+
+#endif
diff --git a/arch/arm/mach-armadaxp/include/mach/smp.h b/arch/arm/mach-armadaxp/include/mach/smp.h
new file mode 100644
index 0000000..7f4563e
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/smp.h
@@ -0,0 +1,29 @@
+#ifndef ASMARM_ARCH_SMP_H
+#define ASMARM_ARCH_SMP_H
+
+#include <asm/io.h>
+#include <mach/armadaxp.h>
+
+#define hard_smp_processor_id()			\
+	({						\
+		unsigned int cpunum;			\
+		__asm__("mrc p15, 0, %0, c0, c0, 5"	\
+			: "=r" (cpunum));		\
+		cpunum &= 0x0F;				\
+	})
+
+/*
+ * We use IRQ1 as the IPI
+ */
+static inline void smp_cross_call(const struct cpumask *mask)
+{
+	unsigned long map = *cpus_addr(*mask);
+	void __iomem *addr = (void __iomem *)(AXP_SW_TRIG_IRQ);
+	
+	//printk("smp_cross_call %x \n",(unsigned int)( ((map & 0x3) << 8) | 0x0) );
+	writel( ( ((map & 0xf) << 8) | 0x0), addr);
+
+	return;
+}
+
+#endif
diff --git a/arch/arm/mach-armadaxp/include/mach/system.h b/arch/arm/mach-armadaxp/include/mach/system.h
new file mode 100644
index 0000000..3f83783
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/system.h
@@ -0,0 +1,31 @@
+/*
+ * include/mach/system.h
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2. This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#ifndef __MACH_SYSTEM_H
+#define __MACH_SYSTEM_H
+
+#include <asm/proc-fns.h>
+#include <mach/hardware.h>
+
+#include "boardEnv/mvBoardEnvLib.h"
+
+#define LSP_VERSION	"AXP_1.3.0"
+
+static inline void arch_idle(void)
+{
+	cpu_do_idle();
+}
+
+static inline void arch_reset(char mode, const char *cmd)
+{
+	printk("Reseting...\n");
+	mvBoardReset();
+	while (1);/* This should never be reached */
+}
+
+#endif
diff --git a/arch/arm/mach-armadaxp/include/mach/timex.h b/arch/arm/mach-armadaxp/include/mach/timex.h
new file mode 100644
index 0000000..c8cf294
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/timex.h
@@ -0,0 +1,9 @@
+/*
+ * include/asm-arm/arch-dove/timex.h
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#define CLOCK_TICK_RATE		(100 * HZ)
diff --git a/arch/arm/mach-armadaxp/include/mach/uncompress.h b/arch/arm/mach-armadaxp/include/mach/uncompress.h
new file mode 100644
index 0000000..78b9d08
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/uncompress.h
@@ -0,0 +1,133 @@
+/*
+ * include/asm-arm/arch-aurora/uncompress.h
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#include <mach/armadaxp.h>
+
+#define UART_THR ((volatile unsigned char *)(AXP_UART0_PHYS_BASE + 0x0))
+#define UART_LSR ((volatile unsigned char *)(AXP_UART0_PHYS_BASE + 0x14))
+
+#define LSR_THRE	0x20
+
+static void putc(const char c)
+{
+	int i;
+
+	for (i = 0; i < 0x1000; i++) {
+		/* Transmit fifo not full? */
+		if (*UART_LSR & LSR_THRE)
+			break;
+	}
+
+	*UART_THR = c;
+}
+
+static void flush(void)
+{
+}
+
+/*
+ * nothing to do
+ */
+#define arch_decomp_setup()
+#define arch_decomp_wdog()
+
+#if 0
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+//#include <linux/autoconf.h>
+#include "../arch/arm/mach-armadaxp/config/mvSysHwConfig.h"
+#include <linux/serial_reg.h>
+#define MV_UART0_LSR 	(*(volatile unsigned char *)(INTER_REGS_BASE + 0x12000 + 0x14))
+#define MV_UART0_THR	(*(volatile unsigned char *)(INTER_REGS_BASE + 0x12000 + 0x0 ))	 
+
+#define MV_UART1_LSR    (*(volatile unsigned char *)(INTER_REGS_BASE + 0x12100 + 0x14))
+#define MV_UART1_THR    (*(volatile unsigned char *)(INTER_REGS_BASE + 0x12100 + 0x0 ))
+#define MV_SERIAL_BASE ((unsigned char *)(INTER_REGS_BASE + 0x12000 + 0x0 ))
+
+#define DEV_REG		(*(volatile unsigned int *)(INTER_REGS_BASE + 0x40000))
+#define CLK_REG         (*(volatile unsigned int *)(INTER_REGS_BASE + 0x2011c))
+/*
+ * This does not append a newline
+ */
+static void putstr(const char *s)
+{
+	unsigned int model;
+	
+	/* Get dev ID, make sure pex clk is on */
+	if((CLK_REG & 0x4) == 0)
+	{
+		CLK_REG = CLK_REG | 0x4;
+		model = (DEV_REG >> 16) & 0xffff;
+		CLK_REG = CLK_REG & ~0x4;
+	}
+	else
+		model = (DEV_REG >> 16) & 0xffff;
+
+        while (*s) {
+		while ((MV_UART0_LSR & UART_LSR_THRE) == 0);
+		MV_UART0_THR = *s;
+		
+                if (*s == '\n') {
+                        while ((MV_UART0_LSR & UART_LSR_THRE) == 0); 
+                        MV_UART0_THR = '\r';
+                }
+                s++;
+        }
+}
+
+#if 0
+static void putc(const char c)
+{
+	unsigned char *base = MV_SERIAL_BASE;
+	int i;
+
+	for (i = 0; i < 0x1000; i++) {
+		if (base[UART_LSR << 2] & UART_LSR_THRE)
+			break;
+		barrier();
+	}
+
+	base[UART_TX << 2] = c;
+}
+#endif
+#if 0
+static void flush(void)
+{
+	unsigned char *base = MV_SERIAL_BASE;
+	unsigned char mask;
+	int i;
+
+	mask = UART_LSR_TEMT | UART_LSR_THRE;
+
+	for (i = 0; i < 0x1000; i++) {
+		if ((base[UART_LSR << 2] & mask) == mask)
+			break;
+		barrier();
+	}
+}
+#endif
+/*
+ * nothing to do
+ */
+#define arch_decomp_setup()
+#define arch_decomp_wdog()
+#endif
diff --git a/arch/arm/mach-armadaxp/include/mach/vmalloc.h b/arch/arm/mach-armadaxp/include/mach/vmalloc.h
new file mode 100644
index 0000000..1630fe6
--- /dev/null
+++ b/arch/arm/mach-armadaxp/include/mach/vmalloc.h
@@ -0,0 +1,11 @@
+/*
+ * include/asm-arm/arch-aurora/vmalloc.h
+ */
+
+/* Dove LCD driver performs big allocations for FrameBuffer memory, we need to
+ * move CONSISTENT_BASE by 32MB
+ */
+/* Was 0x2000000 */
+
+#define VMALLOC_END	(0xfa800000)
+
diff --git a/arch/arm/mach-armadaxp/irq.c b/arch/arm/mach-armadaxp/irq.c
new file mode 100644
index 0000000..432b6f6
--- /dev/null
+++ b/arch/arm/mach-armadaxp/irq.c
@@ -0,0 +1,329 @@
+/*
+ * arch/arm/mach/irq.c
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/irq.h>
+#include <asm/mach/arch.h>
+#include <asm/gpio.h>
+#include <asm/io.h>
+#include <linux/irq.h>
+#include <linux/interrupt.h>
+#include <plat/msi.h>
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "gpp/mvGpp.h"
+#include "gpp/mvGppRegs.h"
+#include "mvOs.h"
+
+unsigned int  irq_int_type[NR_IRQS];
+static DEFINE_SPINLOCK(irq_controller_lock);
+
+int max_per_cpu_irq = 28; // not enabled, default.
+static int __init per_cpu_irq_setup(char *__unused)
+{
+	max_per_cpu_irq=7;
+	return 1;
+}
+
+__setup("per_cpu_irq_enable", per_cpu_irq_setup);
+
+static void axp_unmask_fabric_interrupt(int cpu)
+{
+	u32 val;
+	val = MV_REG_READ(CPU_CF_LOCAL_MASK_REG(cpu));
+	val |=  (1 << cpu);
+	MV_REG_WRITE(CPU_CF_LOCAL_MASK_REG(cpu), val);
+
+#ifdef CONFIG_SMP
+	if (cpu > 0) { /*enabled for both cpu */
+		val = MV_REG_READ(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_MP));
+		/* FIXME: assuming all 4 cpus */
+		val |= 0xf;
+		MV_REG_WRITE(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_MP), val);
+	}
+#endif
+}
+
+static void axp_mask_fabric_interrupt(int cpu)
+{
+	u32 val;
+	val = MV_REG_READ(CPU_CF_LOCAL_MASK_REG(cpu));
+	val &=  ~(1 << cpu);
+	MV_REG_WRITE(CPU_CF_LOCAL_MASK_REG(cpu), val);
+
+#ifdef CONFIG_SMP
+	if (cpu > 0) { /*disabled for both cpu */
+		val = MV_REG_READ(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_MP));
+		val &= ~0xf;
+		MV_REG_WRITE(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_MP), val);
+	}
+#endif	
+}
+
+#ifdef CONFIG_ARMADAXP_USE_IRQ_INDIRECT_MODE
+void axp_irq_mask(struct irq_data *d)
+{	
+	u32 irq=d->irq;
+	if (irq < 8) // per CPU; treat giga as shared interrupt
+		MV_REG_WRITE(CPU_INT_SET_MASK_LOCAL_REG, irq);
+	else
+		MV_REG_WRITE(CPU_INT_CLEAR_ENABLE_REG, irq);
+}
+
+void axp_irq_unmask(struct irq_data *d)
+{	
+
+	u32 irq=d->irq;
+	if (irq < 8) // per CPU
+		MV_REG_WRITE(CPU_INT_CLEAR_MASK_LOCAL_REG, irq);
+	else
+		MV_REG_WRITE(CPU_INT_SET_ENABLE_REG, irq);
+}
+
+void axp_irq_disable(struct irq_data *d)
+{	
+	u32 irq=d->irq;
+	MV_REG_WRITE(CPU_INT_CLEAR_ENABLE_REG, irq);
+}
+
+void axp_irq_enable(struct irq_data *d)
+{	
+	u32 irq=d->irq;
+	MV_REG_WRITE(CPU_INT_SET_ENABLE_REG, irq);
+}
+
+#ifdef CONFIG_SMP
+int axp_set_affinity(unsigned int irq, const struct cpumask *mask_val)
+{
+	MV_U32 addr, temp;
+
+	addr = (CPU_INT_SOURCE_CONTROL_REG(irq));
+
+	spin_lock(&irq_controller_lock);
+	cpumask_copy(irq_desc[irq].affinity, mask_val);
+	irq_desc[irq].node = cpumask_first(mask_val);
+	temp = MV_REG_READ(addr);
+	temp &= ~0xf;
+	temp |= *cpus_addr(*mask_val);
+	MV_REG_WRITE(addr, temp);
+	spin_unlock(&irq_controller_lock);
+
+	return 0;
+}
+#endif
+#else
+
+void axp_irq_mask(struct irq_data *d)
+{	
+	u32 irq = d->irq;
+	MV_U32 addr, temp, gpio_indx;
+	if ((irq >= IRQ_AURORA_GPIO_START) && (irq < IRQ_AURORA_MSI_START)) {
+		/* GPIO Interrupts */
+		/* calculate index in main interrupt */
+		gpio_indx = IRQ_AURORA_GPIO_0_7 + ((irq - IRQ_AURORA_GPIO_START) >> 3);
+		/* add 1 because there is a gap between IRQ_AURORA_GPIO_24_31
+		   and IRQ_AURORA_GPIO_32_39 */
+		if (gpio_indx > IRQ_AURORA_GPIO_24_31)
+			gpio_indx++;
+		addr = (CPU_INT_SOURCE_CONTROL_REG(gpio_indx));
+	} else if (irq >= IRQ_AURORA_MSI_START) {
+		/* Per CPU MSI Interrupts */
+		if ((irq - IRQ_AURORA_MSI_START) < NR_PRIVATE_MSI_GROUP)
+			addr = CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_IN_DRBL_LOW);
+		else
+			addr = CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_IN_DRBL_HIGH);
+	} else 
+		addr = CPU_INT_SOURCE_CONTROL_REG(irq);
+
+	spin_lock(&irq_controller_lock);
+	temp = MV_REG_READ(addr);
+
+	if ((irq >= IRQ_AURORA_GPIO_START) && (irq < IRQ_AURORA_MSI_START)) {
+		MV_U32 bitmask = 1 << (irq & (32-1));
+		MV_U32 reg = (irq - IRQ_AURORA_GPIO_START) >> 5;
+		MV_REG_BIT_RESET(GPP_INT_LVL_REG(reg), bitmask);
+	}
+
+	if (irq <= max_per_cpu_irq) // per CPU
+		temp &= ~(1 << smp_processor_id());
+	/* for GPIO IRQs , don't disable INTS , they will be disabled in the units mask */
+	else if (irq < IRQ_MAIN_INTS_NUM)
+		temp &= ~0xf;
+	
+	MV_REG_WRITE(addr, temp);
+	spin_unlock(&irq_controller_lock);
+}
+
+void axp_irq_unmask(struct irq_data *d)
+{	
+	u32 irq=d->irq;
+	MV_U32 addr, temp, gpio_indx;
+	unsigned int map = 0x1;
+	if ((irq >= IRQ_AURORA_GPIO_START) && (irq < IRQ_AURORA_MSI_START)) {
+		/* GPIO Interrupts */
+		/* calculate index in main interrupt */
+		gpio_indx = IRQ_AURORA_GPIO_0_7 + ((irq - IRQ_AURORA_GPIO_START) >> 3);
+		/* add 1 because there is a gap between IRQ_AURORA_GPIO_24_31
+		   and IRQ_AURORA_GPIO_32_39 */
+		if (gpio_indx > IRQ_AURORA_GPIO_24_31)
+			gpio_indx++;
+		addr = (CPU_INT_SOURCE_CONTROL_REG(gpio_indx));
+	} else if (irq >= IRQ_AURORA_MSI_START) {
+		/* Per CPU MSI Interrupts */
+		if ((irq - IRQ_AURORA_MSI_START) < NR_PRIVATE_MSI_GROUP)
+			addr = CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_IN_DRBL_LOW);
+		else
+			addr = CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_IN_DRBL_HIGH);
+	} else 
+		addr = CPU_INT_SOURCE_CONTROL_REG(irq);
+
+	spin_lock(&irq_controller_lock);
+	temp = MV_REG_READ(addr);
+
+	if (irq >= IRQ_AURORA_GPIO_START) {
+		MV_U32 bitmask = 1 << (irq & (32-1));
+		MV_U32 reg = (irq - IRQ_AURORA_GPIO_START) >> 5;
+		MV_REG_BIT_SET(GPP_INT_LVL_REG(reg), bitmask);
+	}
+#ifdef CONFIG_SMP
+	else
+		map = *cpus_addr(*irq_desc[irq].affinity);
+#endif
+	temp &= ~0xf;
+	temp |= map;
+	temp |= (0x1 << 28); /* Set IntEn for this source */
+	MV_REG_WRITE(addr, temp);
+	spin_unlock(&irq_controller_lock);
+}
+
+
+#ifdef CONFIG_SMP
+int axp_set_affinity(unsigned int irq, const struct cpumask *mask_val)
+{
+	cpumask_copy(irq_desc[irq].affinity, mask_val);
+	spin_lock(&irq_controller_lock);
+	irq_desc[irq].node = cpumask_first(mask_val);
+	spin_unlock(&irq_controller_lock);
+	axp_irq_unmask(irq);
+	return 0;
+}
+#endif
+#endif /* CONFIG_ARMADAXP_USE_IRQ_INDIRECT_MODE */
+
+#ifdef CONFIG_SMP
+void second_cpu_init(void)
+{
+
+	struct irq_data *d = irq_get_irq_data(IRQ_AURORA_IN_DRBL_LOW);
+	unsigned long temp;
+ 	/* open IPI mask */
+	temp = MV_REG_READ(AXP_IN_DRBEL_MSK) | 0x1;
+	MV_REG_WRITE(AXP_IN_DRBEL_MSK, temp);
+
+	axp_irq_unmask(d);
+}
+#endif
+
+static struct irq_chip axp_irq_chip = {
+	.name		= "axp_irq",
+	.irq_mask		= axp_irq_mask,
+	.irq_mask_ack	= axp_irq_mask,
+	.irq_unmask		= axp_irq_unmask,
+#ifdef CONFIG_ARMADAXP_USE_IRQ_INDIRECT_MODE
+	.irq_disable	= axp_irq_disable,
+	.irq_enable		= axp_irq_enable,
+#else
+	.irq_disable	= axp_irq_mask,
+	.irq_enable		= axp_irq_unmask,
+#endif
+#ifdef CONFIG_SMP
+	.set_affinity   = axp_set_affinity,
+#endif
+};
+
+
+void __init axp_init_irq(void)
+{
+	u32 irq;
+	struct irq_chip_generic *gc;
+	struct irq_chip_type *ct;
+
+	/* MASK all interrupts */
+	/* Enable IRQ in control register */
+	for (irq = 0; irq < IRQ_MAIN_INTS_NUM; irq++) {
+		axp_irq_mask(irq_get_irq_data(irq));
+#ifndef CONFIG_SMP
+#ifdef CONFIG_ARMADAXP_USE_IRQ_INDIRECT_MODE
+		MV_REG_WRITE(CPU_INT_CLEAR_MASK_LOCAL_REG, irq);
+#endif
+#endif
+
+	}
+	
+	/*
+	gc = irq_alloc_generic_chip("axp_irq", 1, 0, 0xFBB20B00,
+				    handle_level_irq);
+	ct = gc->chip_types;
+	ct->chip.irq_mask = irq_gc_mask_clr_bit;
+	ct->chip.irq_unmask = irq_gc_mask_set_bit;
+	irq_setup_generic_chip(gc, IRQ_MSK(32), IRQ_GC_INIT_MASK_CACHE,
+			       IRQ_NOREQUEST, IRQ_LEVEL | IRQ_NOPROBE);
+	
+	*/
+	
+	/*
+	 * Register IRQ sources
+	 */
+	for (irq = 0; irq < IRQ_AURORA_MSI_START ; irq++) {
+		irq_set_chip(irq, &axp_irq_chip);
+		irq_set_chip_data(irq, 0); 
+		irq_set_handler(irq, handle_level_irq);
+		//irq_desc[irq].status |= IRQ_LEVEL;
+		irq_set_status_flags(irq,IRQ_LEVEL);
+		set_irq_flags(irq, IRQF_VALID);
+	}
+
+#ifdef CONFIG_SMP
+	{
+		u32/*void __iomem **/addr;
+        	/* Set the default affinity to the boot cpu. */
+        	cpumask_clear(irq_default_affinity);
+        	cpumask_set_cpu(smp_processor_id(), irq_default_affinity);
+		/* open IPI mask */
+		axp_irq_unmask(IRQ_AURORA_IN_DRBL_LOW);
+		addr = /*(void __iomem *)*/(AXP_IN_DRBEL_MSK);
+		MV_REG_WRITE(addr, 0x1); // only IPI 0
+	}
+#endif
+
+	armada_msi_init();
+
+}
+
+int pmu_request_irq(int irq, irq_handler_t handler)
+{
+	int i;
+	int ret = request_irq(irq, handler, IRQF_DISABLED | IRQF_NOBALANCING, "armpmu", NULL);
+	if (!ret) {
+		for_each_online_cpu(i) {
+			axp_unmask_fabric_interrupt(i);
+		}
+	}
+	return ret;
+}
+
+void pmu_free_irq(int irq)
+{
+	int i;
+	for_each_online_cpu(i) {
+		axp_mask_fabric_interrupt(i);
+	}
+	free_irq(irq, NULL);
+}
+
diff --git a/arch/arm/mach-armadaxp/leds.c b/arch/arm/mach-armadaxp/leds.c
new file mode 100644
index 0000000..66639b2
--- /dev/null
+++ b/arch/arm/mach-armadaxp/leds.c
@@ -0,0 +1,49 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#include <linux/module.h>
+#include <linux/spinlock.h>
+#include <linux/init.h>
+
+#include <mach/hardware.h>
+#include <asm/leds.h>
+#include <asm/system.h>
+#include <asm/mach-types.h>
+#include "boardEnv/mvBoardEnvLib.h"
+
+static	u32		last_jiffies = 0;
+static	u32		led_val = 0;
+
+
+void mv_leds_hearbeat(void)
+{
+	u32 sec = jiffies_to_msecs(jiffies - last_jiffies) / 1000;
+	
+	if (!sec)
+		return;
+
+	led_val = (led_val % (1 << mvBoardDebugLedNumGet(mvBoardIdGet())));
+	mvBoardDebugLed(led_val);
+	led_val++;
+	last_jiffies = jiffies;
+}
+
+static int __init leds_init(void)
+{
+	return 0;
+}
+
+__initcall(leds_init);
diff --git a/arch/arm/mach-armadaxp/mpp.h b/arch/arm/mach-armadaxp/mpp.h
new file mode 100644
index 0000000..1065468
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mpp.h
@@ -0,0 +1,34 @@
+#ifndef __ARCH_DOVE_MPP_H
+#define __ARCH_DOVE_MPP_H
+
+enum aurora_mpp_type {
+	/*
+	 * This MPP is unused.
+	 */
+	MPP_UNUSED,
+
+	/*
+	 * This MPP pin is used as a generic GPIO pin.
+	 */
+	MPP_GPIO,
+
+        /*
+         * This MPP is used as a SATA activity LED.
+         */
+        MPP_SATA_LED,
+        /*
+         * This MPP is used as a functional pad.
+         */
+        MPP_FUNCTIONAL,
+
+};
+
+struct aurora_mpp_mode {
+	int			mpp;
+	enum aurora_mpp_type	type;
+};
+
+void aurora_mpp_conf(struct aurora_mpp_mode *mode);
+
+
+#endif
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysCesa.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysCesa.c
new file mode 100644
index 0000000..49f6154
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysCesa.c
@@ -0,0 +1,117 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "mv_cesa/cesa_if.h"
+
+extern u32 mv_crypto_phys_base_get(u8 chan);
+extern u32 mv_crypto_virt_base_get(u8 chan);
+
+/*******************************************************************************
+* mvSysCesaInit - Initialize the Cesa subsystem
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None
+* OUTPUT:
+*		None
+* RETURN:
+*       None
+*
+*******************************************************************************/
+MV_STATUS mvSysCesaInit(int numOfSession, int queueDepth, void *osHandle)
+{
+	MV_CESA_HAL_DATA halData;
+	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+	MV_STATUS status;
+	MV_U8 chan;
+
+	status = mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1);
+
+	if(status == MV_OK) {
+		for(chan = 0; chan < MV_CESA_CHANNELS; chan++) {
+			status = mvCesaIfTdmaWinInit(chan, addrWinMap);
+			
+			if(status != MV_OK) {
+				mvOsPrintf("Error, unable to initialize CESA windows for channel(%d)\n", chan);
+				break;
+			}
+			halData.sramPhysBase[chan] = (MV_ULONG)mv_crypto_phys_base_get(chan);
+			halData.sramVirtBase[chan] = (MV_U8*)mv_crypto_virt_base_get(chan);
+			halData.sramOffset[chan] = 0;
+		}
+
+		if(status == MV_OK) {
+			halData.ctrlModel = mvCtrlModelGet();
+			halData.ctrlRev = mvCtrlRevGet();
+			status = mvCesaIfInit (numOfSession, queueDepth, osHandle, &halData);
+		}
+	}
+
+	return status;
+}
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysCesaApi.h b/arch/arm/mach-armadaxp/mv_hal_if/mvSysCesaApi.h
new file mode 100644
index 0000000..ce8aa9b
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysCesaApi.h
@@ -0,0 +1,71 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef __MV_SYS_CESA_API_H__
+#define __MV_SYS_CESA_API_H__
+
+
+MV_STATUS mvSysCesaInit (int numOfSession, int queueDepth, void *osHandle);
+
+#endif
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysDdr.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysDdr.c
new file mode 100644
index 0000000..38dc444
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysDdr.c
@@ -0,0 +1,134 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+#include "boardEnv/mvBoardEnvSpec.h"
+#include "twsi/mvTwsi.h"
+
+
+/*******************************************************************************
+* mvSysDdrSpdRead
+*
+* DESCRIPTION:
+*	System interface for reading DDR SPD contents.
+*
+* INPUT:
+*       data:	Buffer to read data into.
+*       size:	Number of bytes to read.
+*
+* OUTPUT:
+*       data:	SPD data.
+*
+* RETURN:
+*	MV_OK on success,
+*	MV_ERROR otherwise.
+*
+*******************************************************************************/
+MV_STATUS mvSysDdrSpdRead(MV_U8 *data, MV_U32 size)
+{
+	MV_TWSI_SLAVE slave;
+
+	slave.slaveAddr.address = MV_BOARD_DIMM0_I2C_ADDR;
+	slave.slaveAddr.type = ADDR7_BIT;
+	slave.validOffset = MV_TRUE;
+	slave.offset = 0;
+	slave.moreThen256 = MV_FALSE;
+
+	return mvTwsiRead(MV_BOARD_DIMM_I2C_CHANNEL, &slave, data, size);
+}
+
+
+/*******************************************************************************
+* mvSysDdrSpdWrite
+*
+* DESCRIPTION:
+*	System interface for writing DDR SPD contents.
+*
+* INPUT:
+*       data:	Buffer holding the data to be written.
+*       size:	Number of bytes to write.
+*
+* OUTPUT:
+*	None.
+*
+* RETURN:
+*	MV_OK on success,
+*	MV_ERROR otherwise.
+*
+*******************************************************************************/
+MV_STATUS mvSysDdrSpdWrite(MV_U8 *data, MV_U32 size)
+{
+	MV_TWSI_SLAVE slave;
+
+	slave.slaveAddr.address = MV_BOARD_DIMM0_I2C_ADDR;
+	slave.slaveAddr.type = ADDR7_BIT;
+	slave.validOffset = MV_TRUE;
+	slave.offset = 0;
+	slave.moreThen256 = MV_FALSE;
+
+	return	mvTwsiWrite(MV_BOARD_DIMM_I2C_CHANNEL, &slave, data, size);
+}
+
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysEth.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysEth.c
new file mode 100644
index 0000000..f8b64b6
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysEth.c
@@ -0,0 +1,132 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "cpu/mvCpu.h"
+#include "eth/mvEth.h"
+
+
+/*******************************************************************************
+* mvSysEthInit - Initialize the Eth subsystem
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None
+* OUTPUT:
+*		None
+* RETURN:
+*       None
+*
+*******************************************************************************/
+MV_VOID mvSysEthInit(MV_VOID)
+{
+	MV_ETH_HAL_DATA halData;
+	MV_U32 port;
+	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+	MV_STATUS status;
+
+	status = mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1);
+	if(status != MV_OK)
+		return;
+
+	{
+		int i;
+		for(i = 0; i < MAX_TARGETS; i++) {
+			if(addrWinMap[i].enable == MV_FALSE)
+				continue;
+			printk("%d - Base 0x%08x , Size = 0x%08x.\n", i,
+					addrWinMap[i].addrWin.baseLow,
+					addrWinMap[i].addrWin.size);
+		}
+	}
+	halData.maxPortNum = mvCtrlEthMaxPortGet();
+	halData.cpuPclk = mvCpuPclkGet();
+	halData.tclk = mvBoardTclkGet();
+#ifdef ETH_DESCR_IN_SRAM
+	halData.sramSize = mvCtrlSramSizeGet();
+#endif
+
+	for (port=0;port < halData.maxPortNum;port++) {
+		if(mvCtrlPwrClckGet(ETH_GIG_UNIT_ID, port) == MV_FALSE) {
+			halData.portData[port].powerOn = MV_FALSE;
+			continue;
+		}
+		status = mvEthWinInit(port, addrWinMap);
+		if(status == MV_OK) {
+			halData.portData[port].powerOn = MV_TRUE;
+			halData.portData[port].phyAddr = mvBoardPhyAddrGet(port);
+			halData.portData[port].isSgmii = mvBoardIsPortInSgmii(port);
+			halData.portData[port].macSpeed = mvBoardMacSpeedGet(port);
+		}
+	}
+
+	mvEthHalInit(&halData);
+
+	return;
+}
+
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysEthApi.h b/arch/arm/mach-armadaxp/mv_hal_if/mvSysEthApi.h
new file mode 100644
index 0000000..e1016e4
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysEthApi.h
@@ -0,0 +1,71 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef __MV_SYS_ETH_API_H__
+#define __MV_SYS_ETH_API_H__
+
+
+MV_VOID mvSysEthInit(void);
+
+#endif
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysEthPhy.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysEthPhy.c
new file mode 100644
index 0000000..0c9cdf5
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysEthPhy.c
@@ -0,0 +1,104 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "eth-phy/mvEthPhy.h"
+#if defined(MV_ETH_LEGACY)
+#include "eth/gbe/mvEthRegs.h"
+#else
+#include "neta/gbe/mvEthRegs.h"
+#endif
+
+
+/*******************************************************************************
+* mvSysEthPhyInit - Initialize the EthPhy subsystem
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None
+* OUTPUT:
+*		None
+* RETURN:
+*       None
+*
+*******************************************************************************/
+MV_STATUS mvSysEthPhyInit(void)
+{
+	MV_ETHPHY_HAL_DATA halData;
+	MV_U32 port;
+
+	for (port=0; port < mvCtrlEthMaxPortGet(); port++) {
+		halData.phyAddr[port] = mvBoardPhyAddrGet(port);
+		halData.boardSpecInit = MV_FALSE;
+	}
+
+	halData.ethPhySmiReg = ETH_SMI_REG(MV_ETH_SMI_PORT); 
+
+	return mvEthPhyHalInit(&halData);
+}
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysEthPhyApi.h b/arch/arm/mach-armadaxp/mv_hal_if/mvSysEthPhyApi.h
new file mode 100644
index 0000000..eab268a
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysEthPhyApi.h
@@ -0,0 +1,71 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef __MV_SYS_ETHPHY_API_H__
+#define __MV_SYS_ETHPHY_API_H__
+
+
+MV_STATUS mvSysEthPhyInit(void);
+
+#endif
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysNeta.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysNeta.c
new file mode 100644
index 0000000..4d053bc
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysNeta.c
@@ -0,0 +1,137 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "cpu/mvCpu.h"
+#include "neta/gbe/mvNeta.h"
+
+
+/*******************************************************************************
+* mvSysNetaInit - Initialize the Eth subsystem
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None
+* OUTPUT:
+*		None
+* RETURN:
+*       None
+*
+*******************************************************************************/
+void 	mvSysNetaInit(void)
+{
+	MV_NETA_HAL_DATA halData;
+	MV_U32 port;
+	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+	MV_STATUS status;
+	int i;
+
+	memset(&halData, 0, sizeof(halData));
+	status = mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1);
+	if(status != MV_OK)
+		return;
+
+	for(i = 0; i < MAX_TARGETS; i++) {
+		if(addrWinMap[i].enable == MV_FALSE)
+			continue;
+
+		printk("%d - Base 0x%08x , Size = 0x%08x.\n", i,
+				addrWinMap[i].addrWin.baseLow,
+				addrWinMap[i].addrWin.size);
+	}
+	halData.maxPort = mvCtrlEthMaxPortGet();
+	halData.pClk = mvCpuPclkGet();
+	halData.tClk = mvBoardTclkGet();
+	halData.maxCPUs = mvCtrlEthMaxCPUsGet();
+	halData.iocc = arch_is_coherent();
+
+#ifdef CONFIG_MV_ETH_BM
+	halData.bmPhysBase = PNC_BM_PHYS_BASE;
+	halData.bmVirtBase = (MV_U8*)ioremap(PNC_BM_PHYS_BASE, PNC_BM_SIZE);
+#endif /* CONFIG_MV_ETH_BM */
+
+#ifdef CONFIG_MV_ETH_PNC
+        halData.pncPhysBase = PNC_BM_PHYS_BASE;
+        halData.pncVirtBase = (MV_U8*)ioremap(PNC_BM_PHYS_BASE, PNC_BM_SIZE);
+#endif /* CONFIG_MV_ETH_PNC */
+
+	for (port=0; port<halData.maxPort; port++) {
+		if(mvCtrlPwrClckGet(ETH_GIG_UNIT_ID, port) == MV_FALSE) {
+			continue;
+		}
+        	mvNetaPortPowerUp(port, mvBoardIsPortInSgmii(port), mvBoardIsPortInGmii(port));
+		status = mvNetaWinInit(port, addrWinMap);
+		if(status != MV_OK) {
+			continue;
+		}
+	}
+	mvNetaHalInit(&halData);
+
+	return;
+}
+
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysNetaApi.h b/arch/arm/mach-armadaxp/mv_hal_if/mvSysNetaApi.h
new file mode 100644
index 0000000..d7b56f8
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysNetaApi.h
@@ -0,0 +1,71 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef __MV_SYS_NETA_API_H__
+#define __MV_SYS_NETA_API_H__
+
+
+void mvSysNetaInit(void);
+
+#endif /* __MV_SYS_NETA_API_H__ */
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysPci.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysPci.c
new file mode 100644
index 0000000..a537357
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysPci.c
@@ -0,0 +1,1382 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File under the following licensing terms. 
+Redistribution and use in source and binary forms, with or without modification, 
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer. 
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution. 
+
+    *   Neither the name of Marvell nor the names of its contributors may be 
+        used to endorse or promote products derived from this software without 
+        specific prior written permission. 
+    
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND 
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE 
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR 
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES 
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; 
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON 
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT 
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS 
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvSysPci.h"
+#include "ddr2_3/mvDramIf.h"
+
+/* PCI BARs registers offsets are inconsecutive. This struct describes BAR	*/
+/* register offsets	and its function where its is located.			*/
+/* Also, PCI address remap registers offsets are inconsecutive. This struct	*/
+/* describes address remap register offsets					*/
+typedef struct _pciBarRegInfo
+{
+	MV_U32 funcNum;
+	MV_U32 baseLowRegOffs;
+	MV_U32 baseHighRegOffs;
+	MV_U32 sizeRegOffs;
+	MV_U32 remapLowRegOffs;
+	MV_U32 remapHighRegOffs;
+}PCI_BAR_REG_INFO;
+
+typedef struct _pciBarStatus
+{
+	MV_PCI_BAR	bar;
+	int		enable;
+}PCI_BAR_STATUS;
+
+PCI_BAR_STATUS pciBarStatusMap[] = 
+{
+#if defined(MV_INCLUDE_SDRAM_CS0)
+	{CS0_BAR, EN},      
+#endif
+#if defined(MV_INCLUDE_SDRAM_CS1)
+        {CS1_BAR, EN}, 	
+#endif	      		
+#if defined(MV_INCLUDE_SDRAM_CS2)
+        {CS2_BAR, EN}, 	
+#endif
+#if defined(MV_INCLUDE_SDRAM_CS3)
+        {CS3_BAR, EN},   		
+#endif
+#if defined(MV_INCLUDE_DEVICE_CS0)          		
+	{DEVCS0_BAR, EN},    	
+#endif
+#if defined(MV_INCLUDE_DEVICE_CS1)          		
+	{DEVCS1_BAR, EN},    	
+#endif
+#if defined(MV_INCLUDE_DEVICE_CS2)          		
+	{DEVCS2_BAR, EN},    	
+#endif
+	{BOOTCS_BAR, EN},     	
+	{MEM_INTER_REGS_BAR, EN},
+	{IO_INTER_REGS_BAR, EN}, 
+	{P2P_MEM0, DIS},     		
+	{P2P_IO, DIS},
+	{TBL_TERM, TBL_TERM}       	
+};
+
+/* PCI BAR table. Note that table entry number must match its target 		*/
+/* enumerator. For example, table entry '4' must describe Deivce CS0 		*/
+/* target which is represent by DEVICE_CS0 enumerator (4).                  */
+#if 0
+MV_PCI_BAR_WIN pciBarMap[] = 
+{
+/*     base low      base high      size        enable/disable				*/
+	{{SDRAM_CS0_BASE , 0, SDRAM_CS0_SIZE      	 },   EN},          
+	{{SDRAM_CS1_BASE , 0, SDRAM_CS1_SIZE      	 },   EN},          
+	{{SDRAM_CS2_BASE , 0, SDRAM_CS2_SIZE      	 },   EN},          
+	{{SDRAM_CS3_BASE , 0, SDRAM_CS3_SIZE      	 },   EN},          
+	{{DEVICE_CS0_BASE, 0, DEVICE_CS0_SIZE     	 },   EN},          
+	{{DEVICE_CS1_BASE, 0, DEVICE_CS1_SIZE     	 },   EN},          
+	{{DEVICE_CS2_BASE, 0, DEVICE_CS2_SIZE     	 },   EN},          
+	{{BOOTDEV_CS_BASE, 0, BOOTDEV_CS_SIZE     	 },   EN},          
+	{{INTER_REGS_BASE, 0, INTER_REGS_SIZE 	 	 },   EN},
+	{{INTER_REGS_BASE, 0, INTER_REGS_SIZE 	 	 },   EN},
+	{{  0xFFFFFFFF   , 0,    0xFFFFFFFF          },  DIS}, 	/* Ignore P2P 	*/ 
+	{{  0xFFFFFFFF   , 0,    0xFFFFFFFF          },  DIS},	/* Ignore P2P 	*/ 
+    /* Table terminator */
+    {{TBL_TERM, TBL_TERM, TBL_TERM}, TBL_TERM} 
+};
+#endif
+
+/* Locals */
+static MV_U32 pciBurstBytes2Reg(MV_U32 size);
+static MV_U32 pciBurstReg2Bytes(MV_U32 size);
+
+static MV_STATUS pciWinOverlapDetect(MV_U32 pciIf, MV_PCI_BAR bar,
+									 MV_ADDR_WIN *pAddrWin);
+
+static MV_STATUS pciBarRegInfoGet(MV_U32 pciIf, MV_PCI_BAR bar, 
+								  PCI_BAR_REG_INFO *pBarRegInfo);
+
+static MV_STATUS pciWinIsValid(MV_U32 baseLow, MV_U32 size);
+
+/* Forward declarations */
+const MV_8* pciBarNameGet(MV_PCI_BAR bar);
+
+/*******************************************************************************
+* mvPciInit - Initialize PCI interfaces
+*
+* DESCRIPTION:
+*       This function initiate the PCI interface:
+*       1) Set local bus number. In case of convential PCI it gets the bus
+*          number using mvPciLocalBusNumGet(). In case of PCI-X this 
+*          information is read only.
+*       2) Interface device number. In case of conventional PCI it gets the
+*          device number using mvPciLocalDevNumGet(). In case of PCI-X this 
+*          information is read only.
+*       3) PCI Arbiter if needed.
+*       4) Enable Master and Slave on PCI interfaces.
+*	5) Open PCI BARs according to default setting. 
+*	   Note that PCI bridge (P2P) is NOT initialized.
+*	6) Enable CPU to PCI ordering.
+*
+* INPUT:
+*
+*       pciIf   - PCI interface number.
+*		localBus - Local Bus of the PCI interface to be set
+*		localDev - Local Dev of the PCI interface to be set
+*		bFirstCall - Indicates wether this is the first call of this
+*					 function .
+*
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       MV_OK if function success otherwise MV_ERROR or MV_BAD_PARAM
+*
+*******************************************************************************/
+MV_STATUS mvPciInit(MV_U32 pciIf, MV_PCI_MOD pciIfmod)
+{
+	MV_PCI_BAR     bar, barix=0;
+	MV_PCI_MODE    pciMode;
+	MV_PCI_PROT_WIN pciProtWin;
+   	MV_PCI_BAR_WIN pciBarMap[PCI_MAX_BARS];  
+	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+	MV_TARGET target;
+	MV_UNIT_WIN_INFO *addrDecWin;
+
+	/* Parameter checking  */
+	if (pciIf >= mvCtrlPciMaxIfGet()) {
+		mvOsPrintf("mvPciInit: ERR. Invalid PCI interface %d\n", pciIf);
+		return MV_BAD_PARAM;
+	}
+
+	/* device and bus numbers */
+	if (MV_OK != mvPciModeGet(pciIf, &pciMode)) {
+		mvOsPrintf("mvPciInit: ERR. mvPciModeGet failed\n");
+		return MV_ERROR;
+	}
+
+	/* First disable all PCI target windows  */
+	for (bar = 0; bar < PCI_MAX_BARS; bar++)
+		mvPciTargetWinEnable(pciIf, bar, MV_FALSE);
+
+	/* WA CQ 4382*/
+	MV_REG_BIT_SET(PCI_BASE_ADDR_ENABLE_REG(pciIf) ,BIT15);
+
+	/* Loop over all BARs and copy enabled SDRAM windows only */
+	if (MV_OK != mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1)){
+		mvOsPrintf("mvPciInit: ERR. mvCtrlAddrWinMapBuild failed\n");
+		return MV_ERROR;
+	}
+
+	for (target = SDRAM_CS0; target <= SDRAM_CS3; target++) {
+		addrDecWin = &addrWinMap[target];
+		if (addrDecWin->enable == MV_TRUE) {
+			pciBarMap[barix].addrWin.baseLow = addrDecWin->addrWin.baseLow;
+			pciBarMap[barix].addrWin.baseHigh = addrDecWin->addrWin.baseHigh;
+			pciBarMap[barix].addrWin.size = addrDecWin->addrWin.size;
+			pciBarMap[barix].enable = EN;
+			barix++;
+		}
+	}
+
+	/* Initialize all non used BARs */
+	for (bar = barix; bar < PCI_MAX_BARS; bar++) {
+		pciBarMap[bar].addrWin.baseLow = 0xFFFFFFFF;
+		pciBarMap[bar].addrWin.baseHigh = 0;
+		pciBarMap[bar].addrWin.size = 0xFFFFFFFF;
+		pciBarMap[bar].enable = DIS;
+	}
+
+	/* finally fill table with TBL_TERM entry */
+	bar = PCI_MAX_BARS - 1;
+	pciBarMap[bar].addrWin.baseLow = TBL_TERM;
+	pciBarMap[bar].addrWin.baseHigh = TBL_TERM;
+	pciBarMap[bar].addrWin.size = TBL_TERM;
+	pciBarMap[bar].enable =  TBL_TERM;
+
+
+    	/* Memory Mapped Internal Registers BAR can not be disabled.            */
+    	/* Relocate its BAR first to avoid colisions with other BARs (e.g DRAM) */
+    	if (MV_OK != mvPciTargetWinSet(pciIf, MEM_INTER_REGS_BAR, &pciBarMap[MEM_INTER_REGS_BAR])) {
+        	mvOsPrintf("mvPciInit: ERR. mvPciTargetWinSet failed\n");
+        	return MV_ERROR;
+    	}        
+
+	/* Now, go through all targets in default table until table terminator	*/
+	for (bar = 0; pciBarMap[bar].enable != TBL_TERM; bar++)
+    	{
+		/* Skip the P2P BARs. They should be configured seperately			*/
+		if (0xFFFFFFFF == pciBarMap[bar].addrWin.baseLow)
+            		continue;
+
+		/* check if the size passed is zero ! */
+		if (0 == pciBarMap[bar].addrWin.size) {
+			/* disable the bar */
+			mvPciTargetWinEnable(pciIf,bar,MV_FALSE);
+			continue;
+		}
+
+		if (MV_OK != mvPciTargetWinSet(pciIf, bar, &pciBarMap[bar])) {
+			mvOsPrintf("mvPciInit: ERR. mvPciTargetWinSet %d failed\n", bar);
+			return MV_ERROR;
+		}        
+    	}
+	
+	MV_REG_BIT_SET(PCI_ADDR_DECODE_CONTROL_REG(pciIf), PADCR_REMAP_REG_WR_DIS);
+
+	/* configure access control unit 0 to DDR to enhance performance */
+	pciProtWin.addrWin.baseLow = 0;
+	pciProtWin.addrWin.baseHigh = 0;
+	pciProtWin.addrWin.size = mvDramIfSizeGet();
+#ifdef AURORA_IO_CACHE_COHERENCY
+	pciProtWin.attributes.snoop = WT_CACHE_COHER;
+#else
+	pciProtWin.attributes.snoop = NO_CACHE_COHER;
+#endif
+	pciProtWin.attributes.access = ALLOWED;
+	pciProtWin.attributes.write = ALLOWED;
+	pciProtWin.attributes.swapType = MV_BYTE_SWAP;
+	pciProtWin.attributes.readMaxBurst = 128; 
+	pciProtWin.attributes.readBurst = 256;
+	pciProtWin.attributes.writeMaxBurst = 128;
+	pciProtWin.attributes.pciOrder = MV_FALSE;
+	pciProtWin.enable = MV_TRUE;
+	if( mvPciProtWinSet(pciIf, 0, &pciProtWin) != MV_OK ) {
+		mvOsPrintf("mvPciInit: ERR. mvPciProtWinSet failed\n");
+		return MV_ERROR;
+	}
+
+	mvPciHalInit(pciIf, pciIfmod);
+
+	return MV_OK;
+}
+
+
+
+/*******************************************************************************
+* mvPciTargetWinSet - Set PCI to peripheral target address window BAR
+*
+* DESCRIPTION:
+*       This function sets an address window from PCI to a peripheral 
+*       target (e.g. SDRAM bank0, PCI_MEM0), also known as BARs. 
+*       A new PCI BAR window is set for specified target address window.
+*       If address decode window parameter structure enables the window, 
+*       the routine will also enable the target window, allowing PCI to access
+*       the target window.
+*
+* INPUT:
+*       pciIf       - PCI interface number.
+*       bar         - BAR to be accessed by slave.
+*       pAddrBarWin - PCI target window information data structure.
+*
+* OUTPUT:
+*       N/A
+*
+* RETURN:
+*       MV_OK if PCI BAR target window was set correctly, MV_BAD_PARAM on bad params 
+*       MV_ERROR otherwise 
+*       (e.g. address window overlapps with other active PCI target window).
+*
+*******************************************************************************/
+MV_STATUS mvPciTargetWinSet(MV_U32 pciIf,
+							MV_PCI_BAR bar, 
+                            MV_PCI_BAR_WIN *pAddrBarWin)
+{
+	MV_U32 pciData;
+	MV_U32 sizeToReg;
+	MV_U32 size;
+	MV_U32 baseLow;
+	MV_U32 baseHigh;
+	MV_U32 localBus;
+	MV_U32 localDev;
+	PCI_BAR_REG_INFO barRegInfo;
+
+	size     = pAddrBarWin->addrWin.size;
+	baseLow  = pAddrBarWin->addrWin.baseLow;
+	baseHigh = pAddrBarWin->addrWin.baseHigh;
+
+	/* Parameter checking   */
+	if(pciIf >= mvCtrlPciMaxIfGet())
+	{
+		mvOsPrintf("mvPciTargetWinSet: ERR. Invalid PCI interface %d\n", pciIf);
+		return MV_BAD_PARAM;
+	}
+
+	if(bar >= PCI_MAX_BARS )
+	{
+		mvOsPrintf("mvPciTargetWinSet: ERR. Illigal PCI BAR %d\n", bar);
+		return MV_BAD_PARAM;
+	}
+
+
+	/* if the address windows is disabled , we only disable the appropriare
+	pci bar and ignore other settings */
+
+	if (MV_FALSE == pAddrBarWin->enable)
+	{
+        MV_REG_BIT_SET(PCI_BASE_ADDR_ENABLE_REG(pciIf), BARER_ENABLE(bar));
+		return MV_OK;
+	}
+
+	if (0 == pAddrBarWin->addrWin.size)
+	{
+        mvOsPrintf("mvPciTargetWinSet: ERR. Target %d can't be zero!\n",bar);
+        return MV_BAD_PARAM;
+	}
+
+	/* Check if the window complies with PCI spec							*/
+	if (MV_TRUE != pciWinIsValid(baseLow, size))
+	{
+        mvOsPrintf("mvPciTargetWinSet: ERR. Target %d window invalid\n", bar);
+		return MV_BAD_PARAM;
+	}
+
+    /* 2) Check if the requested window overlaps with current windows		*/
+	if(MV_TRUE == pciWinOverlapDetect(pciIf, bar, &pAddrBarWin->addrWin))
+	{
+		mvOsPrintf("mvPciTargetWinSet: ERR. Overlap detected for target %d\n",
+																		bar);
+		return MV_BAD_PARAM;
+	}
+
+	/* Get size register value according to window size						*/
+	sizeToReg = ctrlSizeToReg(size, PBBLR_BASE_ALIGNMET);
+
+	/* Size parameter validity check.                                   */
+	if (-1 == sizeToReg)
+	{
+		mvOsPrintf("mvPciTargetWinSet: ERR. Target BAR %d size invalid.\n",bar);
+		return MV_BAD_PARAM;
+	}
+
+	localBus = mvPciLocalBusNumGet(pciIf);
+	localDev = mvPciLocalDevNumGet(pciIf);
+	
+	/* Get BAR register information */
+	pciBarRegInfoGet(pciIf, bar, &barRegInfo);
+	
+	/* Internal register space size have no size register. Do not perform	*/
+	/* size register assigment for this slave target					 	*/
+	if (0 != barRegInfo.sizeRegOffs)
+	{    
+		/* Update size register */
+		MV_REG_WRITE(barRegInfo.sizeRegOffs, (sizeToReg << BAR_SIZE_OFFS));
+	}
+	
+	/* Read current address */
+	pciData = mvPciConfigRead(pciIf, localBus, localDev, barRegInfo.funcNum, 
+													barRegInfo.baseLowRegOffs);
+
+	/* Clear current address */
+	pciData &= ~PBBLR_BASE_MASK;
+	pciData |= (baseLow & PBBLR_BASE_MASK);
+		
+	/* Write new address */
+	mvPciConfigWrite(pciIf, localBus, localDev, barRegInfo.funcNum,
+											barRegInfo.baseLowRegOffs, pciData);
+
+	/* Skip base high settings if the BAR has only base low (32-bit)		*/
+	if (0 != barRegInfo.baseHighRegOffs)
+	{
+		mvPciConfigWrite(pciIf, localBus, localDev, barRegInfo.funcNum, 
+										barRegInfo.baseHighRegOffs, baseHigh);	
+	}
+
+	/* Enable/disable the BAR */
+    if (MV_TRUE == pAddrBarWin->enable)
+    {
+        MV_REG_BIT_RESET(PCI_BASE_ADDR_ENABLE_REG(pciIf), BARER_ENABLE(bar));
+    }
+	else
+	{
+        MV_REG_BIT_SET(PCI_BASE_ADDR_ENABLE_REG(pciIf), BARER_ENABLE(bar));
+	}
+
+	return MV_OK;
+}
+
+/*******************************************************************************
+* mvPciTargetWinGet - Get PCI to peripheral target address window
+*
+* DESCRIPTION:
+*		Get the PCI to peripheral target address window BAR.
+*
+* INPUT:
+*       pciIf - PCI interface number.
+*       bar   - BAR to be accessed by slave.
+*
+* OUTPUT:
+*       pAddrBarWin - PCI target window information data structure.
+*
+* RETURN:
+*       MV_BAD_PARAM for bad parameters ,MV_ERROR on error ! otherwise MV_OK
+*
+*******************************************************************************/
+MV_STATUS mvPciTargetWinGet(MV_U32 pciIf, MV_PCI_BAR bar, 
+                            MV_PCI_BAR_WIN *pAddrBarWin)
+{
+	MV_U32 size;
+	MV_U32 baseLow;
+	MV_U32 baseHigh;
+	MV_U32 localBus;
+	MV_U32 localDev;
+	MV_U32 barEnable;
+	PCI_BAR_REG_INFO barRegInfo;
+
+	/* Parameter checking   */
+	if (pciIf >= mvCtrlPciMaxIfGet())
+	{
+		mvOsPrintf("mvPciTargetWinGet: ERR. Invalid PCI interface %d\n", pciIf);
+		return MV_BAD_PARAM;
+	}
+
+	if (bar >= PCI_MAX_BARS )
+	{
+		mvOsPrintf("mvPciTargetWinGet: ERR. Illigal PCI BAR %d.\n", bar);
+		return MV_BAD_PARAM;
+	}
+
+	localBus = mvPciLocalBusNumGet(pciIf);
+	localDev = mvPciLocalDevNumGet(pciIf);
+
+	/* Get BAR register information */
+	pciBarRegInfoGet(pciIf, bar, &barRegInfo);
+
+	/* Reading Base Low bar */
+	baseLow = mvPciConfigRead(pciIf, localBus, localDev, barRegInfo.funcNum, 
+												barRegInfo.baseLowRegOffs);
+
+	baseLow &= PBBLR_BASE_MASK;
+
+	/* Skip base high if the BAR has only base low (32-bit)		*/
+	if (0 != barRegInfo.baseHighRegOffs)
+	{
+		/* Reading Base High */
+		baseHigh = mvPciConfigRead(pciIf, localBus, localDev, barRegInfo.funcNum, 
+												barRegInfo.baseHighRegOffs);
+	}
+	else
+	{
+		baseHigh = 0;
+	}
+
+    /* Internal register space size have no size register. Do not perform	*/
+	/* size register assigment for this slave target					 	*/
+	if (0 != barRegInfo.sizeRegOffs)
+	{    
+		/* Reading bar size*/
+		size = ctrlRegToSize(
+					(MV_REG_READ(barRegInfo.sizeRegOffs) >> PBSR_SIZE_OFFS), 
+														PBBLR_BASE_ALIGNMET);
+	}
+	else
+	{
+		size = INTER_REGS_SIZE;
+	}
+
+	/* Assign value to user struct */
+	pAddrBarWin->addrWin.baseLow  = baseLow;
+	pAddrBarWin->addrWin.baseHigh = baseHigh;
+	pAddrBarWin->addrWin.size     = size;
+
+	/* Check if window is enabled   */
+	barEnable = MV_REG_READ(PCI_BASE_ADDR_ENABLE_REG(pciIf));
+	
+	if (~barEnable & (BARER_ENABLE(bar)))
+    {
+        pAddrBarWin->enable = MV_TRUE;
+    }
+    else
+    {
+        pAddrBarWin->enable = MV_FALSE;
+    }
+
+	return MV_OK;
+}
+
+
+/*******************************************************************************
+* mvPciTargetWinEnable - Enable/disable a PCI BAR window
+*
+* DESCRIPTION:
+*       This function enable/disable a PCI BAR window.
+*       if parameter 'enable' == MV_TRUE the routine will enable the 
+*       window, thus enabling PCI accesses for that BAR (before enabling the 
+*       window it is tested for overlapping). Otherwise, the window will 
+*       be disabled.
+*
+* INPUT:
+*       pciIf  - PCI interface number.
+*       bar    - BAR to be accessed by slave.
+*       enable - Enable/disable parameter.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       MV_BAD_PARAM for bad parameters ,MV_ERROR on error ! otherwise MV_OK
+*
+*******************************************************************************/
+MV_STATUS mvPciTargetWinEnable(MV_U32 pciIf, MV_PCI_BAR bar, MV_BOOL enable)
+{
+	MV_PCI_BAR_WIN barWin;
+
+	/* Parameter checking   */
+	if (pciIf >= mvCtrlPciMaxIfGet())
+	{
+		mvOsPrintf("mvPciTargetWinEnable: ERR. Invalid PCI interface %d\n",
+                                                                        pciIf);
+		return MV_BAD_PARAM;
+	}
+
+	if (bar >= PCI_MAX_BARS )
+	{
+		mvOsPrintf("mvPciTargetWinEnable: ERR. Illigal PCI BAR %d\n", bar);
+		return MV_BAD_PARAM;
+	}
+	
+	if (MV_TRUE == enable)
+	{   /* First check for overlap with other enabled windows				*/
+        /* Get current window */
+		if (MV_OK != mvPciTargetWinGet(pciIf, bar, &barWin))
+		{
+			mvOsPrintf("mvPciTargetWinEnable: ERR. targetWinGet fail\n");
+			return MV_ERROR;
+		}
+
+		/* Check for overlapping */
+		if (MV_TRUE == pciWinOverlapDetect(pciIf, bar, &barWin.addrWin))
+		
+		{   /* Overlap detected	*/
+			mvOsPrintf("mvPciTargetWinEnable: ERR. Overlap detected\n");
+			return MV_ERROR;
+		}
+		else
+		{
+			/* No Overlap. Enable address decode target window              */
+			MV_REG_BIT_RESET(PCI_BASE_ADDR_ENABLE_REG(pciIf),BARER_ENABLE(bar));
+		}
+	}
+	else
+	{
+		/* Disable address decode target window                             */
+		MV_REG_BIT_SET(PCI_BASE_ADDR_ENABLE_REG(pciIf), BARER_ENABLE(bar));
+	}
+
+	return MV_OK;
+}
+
+
+/*******************************************************************************
+* mvPciProtWinSet - Set PCI protection access window
+*
+* DESCRIPTION:
+*       This function sets a specified address window with access protection 
+*       attributes. If protection structure enables the window the routine will
+*       also enable the protection window.
+*
+* INPUT:
+*       pciIf    - PCI interface number.
+*       winNum   - Protecion window number.
+*       pProtWin - Protection window structure.
+*
+* OUTPUT:
+*       N/A
+*
+* RETURN:
+*       MV_BAD_PARAM for bad parameters ,MV_ERROR on error ! otherwise MV_OK
+*
+*******************************************************************************/
+MV_STATUS mvPciProtWinSet(MV_U32 pciIf, 
+						  MV_U32 winNum, 
+                          MV_PCI_PROT_WIN *pProtWin)
+{
+	MV_U32 protBaseLow;
+	MV_U32 protBaseHigh;
+	MV_U32 protSize;
+
+	/* Parameter checking   */
+	if (pciIf >= mvCtrlPciMaxIfGet())
+	{
+		mvOsPrintf("mvPciProtWinSet: ERR. Invalid PCI interface %d\n", pciIf);
+		return MV_BAD_PARAM;
+	}
+	if (winNum >= PCI_MAX_PROT_WIN)
+	{
+		mvOsPrintf("mvPciProtWinSet: ERR. Invalid window num %d\n", winNum);
+		return MV_BAD_PARAM;
+	}
+
+	/* Check if the window complies with PCI spec							*/
+	if (MV_TRUE != pciWinIsValid(pProtWin->addrWin.baseLow, 
+                                 pProtWin->addrWin.size))
+	{
+        mvOsPrintf("mvPciProtWinSet: ERR. Win base 0x%x unaligned to size 0x%x\n",
+                   pProtWin->addrWin.baseLow, pProtWin->addrWin.size);
+
+		return MV_BAD_PARAM;
+	}
+
+	if (pProtWin->attributes.swapType >= SWAP_TYPE_MAX)
+	{
+		mvOsPrintf("mvPciProtWinSet: ERR. Swap parameter invalid %d\n",
+					                            pProtWin->attributes.swapType);
+		return MV_BAD_PARAM;
+
+	}
+
+	/* 1) Calculate protection window base low register value	*/
+	protBaseLow  =  pProtWin->addrWin.baseLow;
+
+	/* Setting the appropriate bits according to the passed values */
+	if (MV_TRUE == pProtWin->enable) 
+	{
+		protBaseLow |= PACBLR_EN;
+	}
+	else
+	{
+		protBaseLow &= ~PACBLR_EN;
+	}
+
+	/* I/O Cache Coherency */
+	protBaseLow |= ((MV_U32)pProtWin->attributes.snoop << PACBLR_SNOOP_OFFS);
+
+	/* Access protect */
+	if (ALLOWED == pProtWin->attributes.access)
+	{
+		protBaseLow &= ~PACBLR_ACCPROT;
+	}
+	else
+	{
+		protBaseLow |= PACBLR_ACCPROT;
+	}
+
+	/* Write Protect */
+	if (ALLOWED == pProtWin->attributes.write)
+	{
+		protBaseLow &= ~PACBLR_WRPROT;
+	}
+	else
+	{
+		protBaseLow |= PACBLR_WRPROT;
+	}
+	
+	/* PCI slave Data Swap Control */
+	protBaseLow |= (pProtWin->attributes.swapType << PACBLR_PCISWAP_OFFS);
+
+
+	/* Read Max Burst */
+	if (( pciBurstBytes2Reg(pProtWin->attributes.readMaxBurst) << PACBLR_RDMBURST_OFFS) > PACBLR_RDMBURST_128BYTE)
+	{
+		mvOsPrintf("mvPciProtWinSet: ERR illigal read max burst\n");
+		return MV_ERROR;
+	}
+	protBaseLow |= (pciBurstBytes2Reg(pProtWin->attributes.readMaxBurst) << PACBLR_RDMBURST_OFFS);
+
+
+	/* Typical PCI read transaction Size. Only valid for PCI conventional */
+	if ((pciBurstBytes2Reg(pProtWin->attributes.readBurst) << PACBLR_RDSIZE_OFFS) > PACBLR_RDSIZE_256BYTE )
+	{
+		mvOsPrintf("mvPciProtWinSet: ERR. illigal read size\n");
+		return MV_ERROR;
+	}
+	protBaseLow |= (pciBurstBytes2Reg(pProtWin->attributes.readBurst) << PACBLR_RDSIZE_OFFS);
+
+
+	/* 2) Calculate protection window base high register value	*/
+	protBaseHigh =  pProtWin->addrWin.baseHigh;
+
+	/* 3) Calculate protection window size register value	*/
+	protSize     =  ctrlSizeToReg(pProtWin->addrWin.size, PACSR_SIZE_ALIGNMENT) << PACSR_SIZE_OFFS;
+    
+
+	/* Write Max Burst */
+	if ((pciBurstBytes2Reg(pProtWin->attributes.writeMaxBurst) << PACSR_WRMBURST_OFFS) > PACSR_WRMBURST_128BYTE )
+	{
+		mvOsPrintf("mvPciProtWinSet: ERR illigal write max burst\n");
+		return MV_ERROR;
+	}
+	protSize |= (pciBurstBytes2Reg(pProtWin->attributes.writeMaxBurst) << PACSR_WRMBURST_OFFS);
+
+	/* Pci Order */
+    if (MV_TRUE == pProtWin->attributes.pciOrder)
+	{
+		protSize |= PACSR_PCI_ORDERING;
+	}
+	else
+	{
+		protSize &= ~PACSR_PCI_ORDERING;
+	}
+		    
+	/* Writing protection window walues into registers */
+	MV_REG_WRITE(PCI_ACCESS_CTRL_BASEL_REG(pciIf,winNum), protBaseLow);
+	MV_REG_WRITE(PCI_ACCESS_CTRL_BASEH_REG(pciIf,winNum), protBaseHigh);
+	MV_REG_WRITE(PCI_ACCESS_CTRL_SIZE_REG(pciIf,winNum),  protSize);
+
+	return MV_OK;
+}
+/*******************************************************************************
+* mvPciProtWinGet - Get PCI protection access window
+*
+* DESCRIPTION:
+*       This function gets a specified address window and access protection 
+*       attributes for a specific protection window .
+*
+* INPUT:
+*       pciIf    - PCI interface number.
+*       winNum   - Protecion window number.
+*       pProtWin - pointer to a Protection window structure.
+*
+* OUTPUT:
+*       pProtWin - Protection window structure.
+*
+* RETURN:
+*       MV_BAD_PARAM for bad parameters ,MV_ERROR on error ! otherwise MV_OK
+*
+*******************************************************************************/
+MV_STATUS mvPciProtWinGet(MV_U32 pciIf, 
+						  MV_U32 winNum, 
+                          MV_PCI_PROT_WIN *pProtWin)
+{
+	MV_U32 protBaseLow;
+	MV_U32 protBaseHigh;
+	MV_U32 protSize;
+
+	/* Parameter checking   */
+	if (pciIf >= mvCtrlPciMaxIfGet())
+	{
+		mvOsPrintf("mvPciProtWinGet: ERR. Invalid PCI interface %d\n", pciIf);
+		return MV_BAD_PARAM;
+	}
+	if (winNum >= PCI_MAX_PROT_WIN)
+	{
+		mvOsPrintf("mvPciProtWinGet: ERR. Invalid window num %d\n", winNum);
+		return MV_BAD_PARAM;
+	}
+
+	/* Writing protection window walues into registers */
+	protBaseLow = MV_REG_READ(PCI_ACCESS_CTRL_BASEL_REG(pciIf,winNum));
+	protBaseHigh = MV_REG_READ(PCI_ACCESS_CTRL_BASEH_REG(pciIf,winNum));
+	protSize = MV_REG_READ(PCI_ACCESS_CTRL_SIZE_REG(pciIf,winNum));
+
+
+	/* 1) Get Protection Windows base low 	*/
+	pProtWin->addrWin.baseLow = protBaseLow & PACBLR_BASE_L_MASK;
+
+	/* Get the appropriate protection attributes according to register bits*/
+
+	/* Is Windows enabled ? */
+	if (protBaseLow & PACBLR_EN)
+	{
+		pProtWin->enable = MV_TRUE;
+	}
+	else
+	{
+		pProtWin->enable = MV_FALSE;
+	}
+
+
+	/* What is access protect ? */
+	if (protBaseLow & PACBLR_ACCPROT)
+	{
+		pProtWin->attributes.access = FORBIDDEN;
+	}
+	else
+	{
+		pProtWin->attributes.access = ALLOWED;
+	}
+
+	/* Is write protect ? */
+	if (protBaseLow & PACBLR_WRPROT)
+	{
+		pProtWin->attributes.write = FORBIDDEN;
+	}
+	else
+	{
+		pProtWin->attributes.write = ALLOWED;
+	}
+
+
+    	/* PCI slave Data Swap Control */
+	pProtWin->attributes.swapType = (protBaseLow & PACBLR_PCISWAP_MASK) >> PACBLR_PCISWAP_OFFS;
+
+
+	/* Read Max Burst */
+	pProtWin->attributes.readMaxBurst = pciBurstReg2Bytes((protBaseLow & PACBLR_RDMBURST_MASK) >> PACBLR_RDMBURST_OFFS);
+
+	/* Typical PCI read transaction Size. */
+	pProtWin->attributes.readBurst = pciBurstReg2Bytes((protBaseLow & PACBLR_RDSIZE_MASK) >> PACBLR_RDSIZE_OFFS);
+
+
+	/* window base high register value	*/
+	pProtWin->addrWin.baseHigh = protBaseHigh;
+
+	/*Calculate protection window size register value	*/
+	pProtWin->addrWin.size = ctrlRegToSize(((protSize & PACSR_SIZE_MASK) >> PACSR_SIZE_OFFS),PACSR_SIZE_ALIGNMENT);
+
+
+	/* Write Max Burst */
+	pProtWin->attributes.writeMaxBurst = pciBurstReg2Bytes((protSize & PACSR_WRMBURST_MASK) >> PACSR_WRMBURST_OFFS);
+
+	/* Pci Order */
+	if (protSize & PACSR_PCI_ORDERING)
+	{
+		pProtWin->attributes.pciOrder = MV_TRUE;
+	}
+	else
+	{
+		pProtWin->attributes.pciOrder = MV_FALSE;
+	}
+
+
+	return MV_OK;
+}
+
+
+/*******************************************************************************
+* mvPciProtWinEnable - Enable/disable a PCI protection access window
+*
+* DESCRIPTION:
+*       This function enable/disable a PCI protection access window.
+*       if parameter 'enable' == MV_TRUE the routine will enable the 
+*       protection window, otherwise, the protection window will be disabled.
+*
+* INPUT:
+*       pciIf  - PCI interface number.
+*       winNum - Protecion window number.
+*       enable - Enable/disable parameter.
+*
+* OUTPUT:
+*       N/A
+*
+* RETURN:
+*       MV_BAD_PARAM for bad parameters ,MV_ERROR on error ! otherwise MV_OK
+*
+*******************************************************************************/
+MV_STATUS mvPciProtWinEnable(MV_U32 pciIf, MV_U32 winNum, MV_BOOL enable)
+{
+	/* Parameter checking   */
+	if (pciIf >= mvCtrlPciMaxIfGet())
+	{
+		mvOsPrintf("mvPciProtWinEnable: ERR. Invalid PCI interface %d\n", 
+																		pciIf);
+		return MV_BAD_PARAM;
+	}
+
+	if (winNum >= PCI_MAX_PROT_WIN)
+	{
+		mvOsPrintf("mvPciProtWinEnable: ERR. Invalid window num %d\n", winNum);
+		return MV_BAD_PARAM;
+	}
+
+    if (MV_TRUE == enable)
+    {
+        MV_REG_BIT_SET(PCI_ACCESS_CTRL_BASEL_REG(pciIf,winNum), PACBLR_EN);
+    }
+	else
+	{
+        MV_REG_BIT_RESET(PCI_ACCESS_CTRL_BASEL_REG(pciIf,winNum), PACBLR_EN);
+	}
+
+	return MV_OK;
+}
+
+
+/*******************************************************************************
+* mvPciTargetRemap - Set PCI to target address window remap.
+*
+* DESCRIPTION:
+*       The PCI interface supports remap of the BAR original address window.
+*       For each BAR it is possible to define a remap address. For example
+*       an address 0x12345678 that hits BAR 0x10 (SDRAM CS[0]) will be modified
+*       according to remap register but will also be targeted to the 
+*       SDRAM CS[0].
+*
+* INPUT:
+*       pciIf    - PCI interface number.
+*       bar      - Peripheral target enumerator accessed by slave.
+*       pAddrWin - Address window to be checked.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       MV_BAD_PARAM for bad parameters ,MV_ERROR on error ! otherwise MV_OK
+*
+*******************************************************************************/
+MV_STATUS mvPciTargetRemap(MV_U32 pciIf,
+						   MV_PCI_BAR bar,
+                           MV_ADDR_WIN *pAddrWin)
+{
+	PCI_BAR_REG_INFO barRegInfo;
+	
+	/* Parameter checking   */
+	if (pciIf >= mvCtrlPciMaxIfGet())
+	{
+		mvOsPrintf("mvPciTargetRemap: ERR. Invalid PCI interface num %d\n", 
+																		pciIf);
+		return MV_BAD_PARAM;
+	}
+
+	if (MV_IS_NOT_ALIGN(pAddrWin->baseLow, PBARR_REMAP_ALIGNMENT))
+	{
+		mvOsPrintf("mvPciTargetRemap: Error remapping PCI interface %d bar %s."\
+				   "\nAddress 0x%08x is unaligned to size 0x%x.\n",
+				   pciIf,
+				   pciBarNameGet(bar),
+                   pAddrWin->baseLow,
+				   pAddrWin->size);
+		return MV_ERROR;
+	}
+
+	pciBarRegInfoGet(pciIf, bar, &barRegInfo);
+
+	/* Set remap low register value */
+	MV_REG_WRITE(barRegInfo.remapLowRegOffs, pAddrWin->baseLow);
+	
+	/* Skip base high settings if the BAR has only base low (32-bit)		*/
+	if (0 != barRegInfo.remapHighRegOffs)
+	{
+		MV_REG_WRITE(barRegInfo.remapHighRegOffs, pAddrWin->baseHigh);
+	}
+
+	return MV_OK;
+}
+
+/*******************************************************************************
+* pciWinOverlapDetect - Detect address windows overlapping
+*
+* DESCRIPTION:
+*       This function detects address window overlapping of a given address 
+*       window in PCI BARs.
+*
+* INPUT:
+*       pAddrWin - Address window to be checked.
+*       bar      - BAR to be accessed by slave.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       MV_TRUE if the given address window overlap current address
+*       decode map, MV_FALSE otherwise.
+*
+*******************************************************************************/
+static MV_BOOL pciWinOverlapDetect(MV_U32 pciIf, MV_PCI_BAR bar, MV_ADDR_WIN *pAddrWin)
+{
+	MV_U32		barEnableReg;
+	MV_U32		targetBar;
+	MV_PCI_BAR_WIN	barAddrWin;
+
+	/* Read base address enable register. Do not check disabled windows		*/
+	barEnableReg = MV_REG_READ(PCI_BASE_ADDR_ENABLE_REG(pciIf));
+	
+	for(targetBar = 0; targetBar < PCI_MAX_BARS; targetBar++) {
+	        /* don't check our target or illegal targets */
+        	if (targetBar == bar)
+            		continue;
+        
+		/* Do not check disabled windows	*/
+		if (barEnableReg & (BARER_ENABLE(targetBar)))
+			continue;
+
+		/* Get window parameters 	*/
+		if (MV_OK != mvPciTargetWinGet(pciIf, targetBar, &barAddrWin)) {
+			mvOsPrintf("pciWinOverlapDetect: ERR. TargetWinGet failed\n");
+			return MV_ERROR;
+		}
+        
+		/* skip overlapp detect between MEM_INTER_REGS_BAR and IO_INTER_REGS_BAR*/
+		if (((bar == MEM_INTER_REGS_BAR)&&(targetBar == IO_INTER_REGS_BAR)) ||
+			((bar == IO_INTER_REGS_BAR)&&(targetBar == MEM_INTER_REGS_BAR))) {
+			return MV_FALSE;
+		} else if(MV_TRUE == mvWinOverlapTest(pAddrWin, &barAddrWin.addrWin)) {                    
+			mvOsPrintf("pciWinOverlapDetect: BAR %d overlap current %d\n", bar, targetBar);
+			return MV_TRUE;           
+		}
+	}
+
+	return MV_FALSE;
+}
+
+/*******************************************************************************
+* cpuWinIsValid - Check if the given address window is valid
+*
+* DESCRIPTION:
+*		PCI spec restrict BAR base to be aligned to BAR size.
+*		This function checks if the given address window is valid.
+*
+* INPUT:
+*       baseLow - 32bit low base address.
+*       size    - Window size.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       MV_TRUE if the address window is valid, MV_FALSE otherwise.
+*
+*******************************************************************************/
+static MV_STATUS pciWinIsValid(MV_U32 baseLow, MV_U32 size)
+{
+
+	/* PCI spec restrict BAR base to be aligned to BAR size					*/
+	if(MV_IS_NOT_ALIGN(baseLow, size))
+	{
+		return MV_ERROR;
+	}
+	else
+	{
+		return MV_TRUE;
+	}
+}
+
+/*******************************************************************************
+* pciBarRegInfoGet - Get BAR register information
+*
+* DESCRIPTION:
+* 		PCI BARs registers offsets are inconsecutive. 
+*		This function gets a PCI BAR register information like register offsets
+*		and function location of the BAR.
+*
+* INPUT:
+*       pciIf - PCI interface number.
+*		bar	  - The PCI BAR in question.	
+*
+* OUTPUT:
+*       pBarRegInfo - BAR register info struct.
+*
+* RETURN:
+*		MV_BAD_PARAM when bad parameters ,MV_ERROR on error ,othewise MV_OK
+*
+*******************************************************************************/
+static MV_STATUS pciBarRegInfoGet(MV_U32 pciIf, 
+								  MV_PCI_BAR bar,
+								  PCI_BAR_REG_INFO *pBarRegInfo)
+{
+	switch (bar)
+	{
+		/* Function 0 Bars */
+		#if defined(MV_INCLUDE_SDRAM_CS0)
+		case CS0_BAR:      		/* SDRAM chip select 0 bar*/
+			pBarRegInfo->funcNum          = 0;
+			pBarRegInfo->baseLowRegOffs   = PCI_SCS0_BASE_ADDR_LOW;
+			pBarRegInfo->baseHighRegOffs  = PCI_SCS0_BASE_ADDR_HIGH;
+			pBarRegInfo->sizeRegOffs      = PCI_CS0_BAR_SIZE_REG(pciIf);
+			pBarRegInfo->remapLowRegOffs  = PCI_CS0_ADDR_REMAP_REG(pciIf);
+			pBarRegInfo->remapHighRegOffs = 0;
+			break;
+		#endif
+		#if defined(MV_INCLUDE_SDRAM_CS1)
+		case CS1_BAR:      		/* SDRAM chip select 1 bar*/
+			pBarRegInfo->funcNum          = 0;
+			pBarRegInfo->baseLowRegOffs   = PCI_SCS1_BASE_ADDR_LOW;
+			pBarRegInfo->baseHighRegOffs  = PCI_SCS1_BASE_ADDR_HIGH;
+			pBarRegInfo->sizeRegOffs      = PCI_CS1_BAR_SIZE_REG(pciIf);
+			pBarRegInfo->remapLowRegOffs  = PCI_CS1_ADDR_REMAP_REG(pciIf);
+			pBarRegInfo->remapHighRegOffs = 0;
+			break;
+		#endif
+		case MEM_INTER_REGS_BAR: /* Memory Mapped Internal bar */
+			pBarRegInfo->funcNum          = 0;
+			pBarRegInfo->baseLowRegOffs   = PCI_INTER_REG_MEM_MAPPED_BASE_ADDR_L;
+			pBarRegInfo->baseHighRegOffs  = PCI_INTER_REG_MEM_MAPPED_BASE_ADDR_H;
+			pBarRegInfo->sizeRegOffs      = 0;
+			pBarRegInfo->remapLowRegOffs  = 0;
+			pBarRegInfo->remapHighRegOffs = 0;
+			break;
+	
+		/* Function 1 Bars */
+		#if defined(MV_INCLUDE_SDRAM_CS2)
+		case CS2_BAR:      		/* SDRAM chip select 2 bar*/
+			pBarRegInfo->funcNum          = 1;
+			pBarRegInfo->baseLowRegOffs   = PCI_SCS2_BASE_ADDR_LOW;
+			pBarRegInfo->baseHighRegOffs  = PCI_SCS2_BASE_ADDR_HIGH;
+			pBarRegInfo->sizeRegOffs      = PCI_CS2_BAR_SIZE_REG(pciIf);
+			pBarRegInfo->remapLowRegOffs  = PCI_CS2_ADDR_REMAP_REG(pciIf);
+			pBarRegInfo->remapHighRegOffs = 0;
+			break;
+		#endif
+		#if defined(MV_INCLUDE_SDRAM_CS3)
+		case CS3_BAR:      		/* SDRAM chip select 3 bar*/
+			pBarRegInfo->funcNum		  = 1;
+			pBarRegInfo->baseLowRegOffs	  = PCI_SCS3_BASE_ADDR_LOW;
+			pBarRegInfo->baseHighRegOffs  = PCI_SCS3_BASE_ADDR_HIGH;
+			pBarRegInfo->sizeRegOffs	  = PCI_CS3_BAR_SIZE_REG(pciIf);
+			pBarRegInfo->remapLowRegOffs  = PCI_CS3_ADDR_REMAP_REG(pciIf);
+			pBarRegInfo->remapHighRegOffs = 0;
+			break;
+		#endif
+		#if defined(MV_INCLUDE_DEVICE_CS0) 
+		/* Function 2 Bars */
+		case DEVCS0_BAR:     	/* Device chip select 0 bar*/
+			pBarRegInfo->funcNum		  = 2;
+			pBarRegInfo->baseLowRegOffs	  = PCI_DEVCS0_BASE_ADDR_LOW;
+			pBarRegInfo->baseHighRegOffs  = PCI_DEVCS0_BASE_ADDR_HIGH;
+			pBarRegInfo->sizeRegOffs	  = PCI_DEVCS0_BAR_SIZE_REG(pciIf);
+			pBarRegInfo->remapLowRegOffs  = PCI_DEVCS0_ADDR_REMAP_REG(pciIf);
+			pBarRegInfo->remapHighRegOffs = 0;
+			break;
+		#endif
+		#if defined(MV_INCLUDE_DEVICE_CS1) 
+		case DEVCS1_BAR:     	/* Device chip select 0 bar*/
+			pBarRegInfo->funcNum		  = 2;
+			pBarRegInfo->baseLowRegOffs	  = PCI_DEVCS1_BASE_ADDR_LOW;
+			pBarRegInfo->baseHighRegOffs  = PCI_DEVCS1_BASE_ADDR_HIGH;
+			pBarRegInfo->sizeRegOffs	  = PCI_DEVCS1_BAR_SIZE_REG(pciIf);
+			pBarRegInfo->remapLowRegOffs  = PCI_DEVCS1_ADDR_REMAP_REG(pciIf);
+			pBarRegInfo->remapHighRegOffs = 0;
+			break;
+		#endif
+		#if defined(MV_INCLUDE_DEVICE_CS2) 
+		case DEVCS2_BAR:     	/* Device chip select 0 bar*/
+			pBarRegInfo->funcNum		  = 2;
+			pBarRegInfo->baseLowRegOffs	  = PCI_DEVCS2_BASE_ADDR_LOW;
+			pBarRegInfo->baseHighRegOffs  = PCI_DEVCS2_BASE_ADDR_HIGH;
+			pBarRegInfo->sizeRegOffs	  = PCI_DEVCS2_BAR_SIZE_REG(pciIf);
+			pBarRegInfo->remapLowRegOffs  = PCI_DEVCS2_ADDR_REMAP_REG(pciIf);
+			pBarRegInfo->remapHighRegOffs = 0;
+			break;
+		#endif
+		case BOOTCS_BAR:      	/* Boot device chip select bar*/
+			pBarRegInfo->funcNum		  = 3;
+			pBarRegInfo->baseLowRegOffs	  = PCI_BOOTCS_BASE_ADDR_LOW;
+			pBarRegInfo->baseHighRegOffs  = PCI_BOOTCS_BASE_ADDR_HIGH;
+			pBarRegInfo->sizeRegOffs	  = PCI_BOOTCS_BAR_SIZE_REG(pciIf);
+			pBarRegInfo->remapLowRegOffs  = PCI_BOOTCS_ADDR_REMAP_REG(pciIf);
+			pBarRegInfo->remapHighRegOffs = 0;
+			break;
+	
+		/* Function 4 Bars */
+		case P2P_MEM0:      		/* P2P memory 0 */
+			pBarRegInfo->funcNum		  = 4;
+			pBarRegInfo->baseLowRegOffs	  = PCI_P2P_MEM0_BASE_ADDR_LOW;
+			pBarRegInfo->baseHighRegOffs  = PCI_P2P_MEM0_BASE_ADDR_HIGH;
+			pBarRegInfo->sizeRegOffs	  = PCI_P2P_MEM0_BAR_SIZE_REG(pciIf);
+			pBarRegInfo->remapLowRegOffs  = PCI_P2P_MEM0_ADDR_REMAP_LOW_REG(pciIf);
+			pBarRegInfo->remapHighRegOffs = PCI_P2P_MEM0_ADDR_REMAP_HIGH_REG(pciIf);
+			break;
+		case P2P_IO:        		/* P2P IO */
+			pBarRegInfo->funcNum		  = 4;
+			pBarRegInfo->baseLowRegOffs   = PCI_P2P_IO_BASE_ADDR;
+			pBarRegInfo->baseHighRegOffs  = 0;
+			pBarRegInfo->sizeRegOffs	  = PCI_P2P_IO_BAR_SIZE_REG(pciIf);
+			pBarRegInfo->remapLowRegOffs  = PCI_P2P_IO_ADDR_REMAP_REG(pciIf);
+			pBarRegInfo->remapHighRegOffs = 0;
+			break;
+		case IO_INTER_REGS_BAR: /* IO Mapped Internal bar */
+			pBarRegInfo->funcNum		  = 4;
+			pBarRegInfo->baseLowRegOffs	  = PCI_INTER_REGS_IO_MAPPED_BASE_ADDR;
+			pBarRegInfo->baseHighRegOffs  = 0;
+			pBarRegInfo->sizeRegOffs	  = 0;
+			pBarRegInfo->remapLowRegOffs  = 0;
+			pBarRegInfo->remapHighRegOffs = 0;
+			break;
+	
+	
+		default: 
+			mvOsPrintf("mvPciTargetWinGet: ERR.non existing target\n");
+			return MV_ERROR;
+
+	}
+
+	return MV_OK;
+}
+
+/*******************************************************************************
+* pciBarNameGet - Get the string name of PCI BAR.
+*
+* DESCRIPTION:
+*		This function get the string name of PCI BAR.
+*
+* INPUT:
+*       bar - PCI bar number.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       pointer to the string name of PCI BAR.
+*
+*******************************************************************************/
+const MV_8* pciBarNameGet( MV_PCI_BAR bar )
+{
+	switch( bar ) 
+	{
+	#if defined(MV_INCLUDE_SDRAM_CS0)
+		case CS0_BAR: 
+			return "CS0_BAR..............";
+	#endif
+	#if defined(MV_INCLUDE_SDRAM_CS1)
+		case CS1_BAR: 
+			return "CS1_BAR..............";
+	#endif
+	#if defined(MV_INCLUDE_SDRAM_CS2)
+		case CS2_BAR: 
+			return "CS2_BAR..............";
+	#endif
+	#if defined(MV_INCLUDE_SDRAM_CS3)
+		case CS3_BAR: 
+			return "CS3_BAR..............";
+	#endif
+	#if defined(MV_INCLUDE_DEVICE_CS0)
+		case DEVCS0_BAR: 
+			return "DEVCS0_BAR...........";
+	#endif
+	#if defined(MV_INCLUDE_DEVICE_CS1)
+		case DEVCS1_BAR: 
+			return "DEVCS1_BAR...........";
+	#endif
+	#if defined(MV_INCLUDE_DEVICE_CS2)
+		case DEVCS2_BAR: 
+			return "DEVCS2_BAR...........";
+	#endif
+		case BOOTCS_BAR: 
+			return "BOOTCS_BAR...........";
+		case MEM_INTER_REGS_BAR: 
+			return "MEM_INTER_REGS_BAR...";
+		case IO_INTER_REGS_BAR: 
+			return "IO_INTER_REGS_BAR....";
+		case P2P_MEM0: 
+			return "P2P_MEM0.............";
+		case P2P_IO: 
+			return "P2P_IO...............";
+		default:
+			 return "target unknown";
+	}
+}
+
+/*******************************************************************************
+* mvPciAddrDecShow - Print the PCI address decode map (BARs).
+*
+* DESCRIPTION:
+*		This function print the PCI address decode map (BARs).
+*
+* INPUT:
+*       None.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       None.
+*
+*******************************************************************************/
+MV_VOID mvPciAddrDecShow(MV_VOID)
+{
+	MV_PCI_BAR_WIN win;
+	MV_PCI_BAR bar;
+	MV_U32 pciIf;
+
+	for( pciIf = 0; pciIf < mvCtrlPciMaxIfGet(); pciIf++ )
+	{ 
+		mvOsOutput( "\n" );
+		mvOsOutput( "PCI%d:\n", pciIf );
+		mvOsOutput( "-----\n" );
+
+		for( bar = 0; bar < PCI_MAX_BARS; bar++ ) 
+		{
+			memset( &win, 0, sizeof(MV_PCI_BAR_WIN) );
+
+			mvOsOutput( "%s ", pciBarNameGet(bar) );
+
+			if( mvPciTargetWinGet( pciIf, bar, &win ) == MV_OK )
+			{
+				if( win.enable )
+				{
+                    mvOsOutput( "base %08x, ", win.addrWin.baseLow );
+                    mvSizePrint( win.addrWin.size );
+                    mvOsOutput( "\n" );
+				}
+				else
+					mvOsOutput( "disable\n" );
+			}
+		}
+	}	
+}
+
+/* convert burst bytes to register value*/
+static MV_U32 pciBurstBytes2Reg(MV_U32 size)
+{
+        MV_U32 ret;
+        switch(size)
+        {
+                case 32: ret = 0; break;
+                case 64: ret = 1; break;
+                case 128: ret = 2; break;
+                case 256: ret = 3; break;
+                default: ret = 0xF; /* error */
+        }
+        return ret;
+}
+
+/* convert register value to burst bytes*/
+static MV_U32 pciBurstReg2Bytes(MV_U32 size)
+{
+        MV_U32 ret;
+        switch(size)
+        {
+                case 0: ret = 32; break;
+                case 1: ret = 64; break;
+                case 2: ret = 128; break;
+                case 3: ret = 256; break;
+                default: ret = 0x0; /* error */
+        }
+        return ret;
+}
+
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysPci.h b/arch/arm/mach-armadaxp/mv_hal_if/mvSysPci.h
new file mode 100644
index 0000000..9f58f04
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysPci.h
@@ -0,0 +1,256 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File under the following licensing terms. 
+Redistribution and use in source and binary forms, with or without modification, 
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer. 
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution. 
+
+    *   Neither the name of Marvell nor the names of its contributors may be 
+        used to endorse or promote products derived from this software without 
+        specific prior written permission. 
+    
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND 
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE 
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR 
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES 
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; 
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON 
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT 
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS 
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+
+#ifndef __INCSysPCIH
+#define __INCSysPCIH
+
+#include "ctrlEnv/sys/mvCpuIf.h"
+#include "pci/mvPci.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "ctrlEnv/mvCtrlEnvAddrDec.h"
+#include "mvSysPciConfig.h"
+
+#define PCI_MAX_PROT_WIN			6
+
+/* 4KB granularity */
+#define MINIMUM_WINDOW_SIZE     		0x1000
+#define MINIMUM_BAR_SIZE        		0x1000
+#define MINIMUM_BAR_SIZE_MASK			0xFFFFF000
+#define BAR_SIZE_OFFS				12
+#define BAR_SIZE_MASK				(0xFFFFF << BAR_SIZE_OFFS)
+
+#define PCI_IO_WIN_NUM          		1   /* Number of PCI_IO windows  */
+#define PCI_MEM_WIN_NUM         		4   /* Number of PCI_MEM windows */
+
+#ifndef MV_ASMLANGUAGE
+#include "ctrlEnv/mvCtrlEnvLib.h"
+typedef enum _mvPCIBars
+{
+	PCI_BAR_TBL_TERM = -1, /* none valid bar, used as bars list terminator */
+#if defined(MV_INCLUDE_SDRAM_CS0)
+	CS0_BAR,
+#endif	
+#if defined(MV_INCLUDE_SDRAM_CS1)
+	CS1_BAR,
+#endif	      		
+#if defined(MV_INCLUDE_SDRAM_CS2)
+	CS2_BAR,
+#endif
+#if defined(MV_INCLUDE_SDRAM_CS3)
+	CS3_BAR,
+#endif
+#if defined(MV_INCLUDE_DEVICE_CS0)          		
+	DEVCS0_BAR,
+#endif
+#if defined(MV_INCLUDE_DEVICE_CS1)          		
+	DEVCS1_BAR,
+#endif
+#if defined(MV_INCLUDE_DEVICE_CS2)          		
+	DEVCS2_BAR,
+#endif
+	BOOTCS_BAR,      	/* Boot device chip select bar*/
+	MEM_INTER_REGS_BAR, 	/* Memory Mapped Internal bar */
+	IO_INTER_REGS_BAR,	/* IO Mapped Internal bar */
+	P2P_MEM0,      		/* P2P memory 0 */
+	P2P_IO,        		/* P2P IO */
+	PCI_MAX_BARS
+}MV_PCI_BAR;
+#endif /* MV_ASMLANGUAGE */
+
+#if defined(MV_INCLUDE_SDRAM_CS3)
+#define MV_PCI_BAR_IS_DRAM_BAR(bar) 		((bar >= CS0_BAR) && (bar <= CS3_BAR))
+#elif defined(MV_INCLUDE_SDRAM_CS2)
+#define MV_PCI_BAR_IS_DRAM_BAR(bar)		((bar >= CS0_BAR) && (bar <= CS2_BAR))
+#elif defined(MV_INCLUDE_SDRAM_CS1)
+#define MV_PCI_BAR_IS_DRAM_BAR(bar)		((bar >= CS0_BAR) && (bar <= CS1_BAR))
+#elif defined(MV_INCLUDE_SDRAM_CS0)
+#define MV_PCI_BAR_IS_DRAM_BAR(bar)		((bar == CS0_BAR))
+#endif
+
+
+/****************************************/
+/* PCI Slave Address Decoding registers */
+/****************************************/
+#define PCI_CS0_BAR_SIZE_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0c08 + ((pciIf) * 0x80))
+#define PCI_CS1_BAR_SIZE_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d08 + ((pciIf) * 0x80))
+#define PCI_CS2_BAR_SIZE_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0c0c + ((pciIf) * 0x80))
+#define PCI_CS3_BAR_SIZE_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d0c + ((pciIf) * 0x80))
+#define PCI_DEVCS0_BAR_SIZE_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0c10 + ((pciIf) * 0x80))
+#define PCI_DEVCS1_BAR_SIZE_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d10 + ((pciIf) * 0x80))
+#define PCI_DEVCS2_BAR_SIZE_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d18 + ((pciIf) * 0x80))
+#define PCI_BOOTCS_BAR_SIZE_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d14 + ((pciIf) * 0x80))
+#define PCI_P2P_MEM0_BAR_SIZE_REG(pciIf)	(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d1c + ((pciIf) * 0x80))
+#define PCI_P2P_IO_BAR_SIZE_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d24 + ((pciIf) * 0x80))
+#define PCI_EXPAN_ROM_BAR_SIZE_REG(pciIf)	(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d2c + ((pciIf) * 0x80)) 
+#define PCI_BASE_ADDR_ENABLE_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0c3c + ((pciIf) * 0x80)) 
+#define PCI_CS0_ADDR_REMAP_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0c48 + ((pciIf) * 0x80)) 
+#define PCI_CS1_ADDR_REMAP_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d48 + ((pciIf) * 0x80)) 
+#define PCI_CS2_ADDR_REMAP_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0c4c + ((pciIf) * 0x80)) 
+#define PCI_CS3_ADDR_REMAP_REG(pciIf)		(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d4c + ((pciIf) * 0x80)) 
+#define PCI_DEVCS0_ADDR_REMAP_REG(pciIf)	(MV_PCI_IF_REGS_BASE(pciIf) + 0x0c50 + ((pciIf) * 0x80)) 
+#define PCI_DEVCS1_ADDR_REMAP_REG(pciIf)	(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d50 + ((pciIf) * 0x80)) 
+#define PCI_DEVCS2_ADDR_REMAP_REG(pciIf)	(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d58 + ((pciIf) * 0x80)) 
+#define PCI_BOOTCS_ADDR_REMAP_REG(pciIf)	(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d54 + ((pciIf) * 0x80)) 
+#define PCI_P2P_MEM0_ADDR_REMAP_LOW_REG(pciIf)	(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d5c + ((pciIf) * 0x80)) 
+#define PCI_P2P_MEM0_ADDR_REMAP_HIGH_REG(pciIf)	(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d60 + ((pciIf) * 0x80)) 
+#define PCI_P2P_IO_ADDR_REMAP_REG(pciIf)	(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d6c + ((pciIf) * 0x80)) 
+#define PCI_EXPAN_ROM_ADDR_REMAP_REG(pciIf)	(MV_PCI_IF_REGS_BASE(pciIf) + 0x0f38 + ((pciIf) * 0x80))
+#define PCI_DRAM_BAR_BANK_SELECT_REG(pciIf)	(MV_PCI_IF_REGS_BASE(pciIf) + 0x0c1c + ((pciIf) * 0x80))
+#define PCI_ADDR_DECODE_CONTROL_REG(pciIf)	(MV_PCI_IF_REGS_BASE(pciIf) + 0x0d3c + ((pciIf) * 0x80))
+
+/* PCI Bars Size Registers (PBSR) */
+#define PBSR_SIZE_OFFS				12
+#define PBSR_SIZE_MASK				(0xfffff << PBSR_SIZE_OFFS)
+
+/* Base Address Registers Enable Register (BARER) */
+#define BARER_ENABLE(target)			(1 << (target))
+
+/* PCI Base Address Remap Registers (PBARR) */
+#define PBARR_REMAP_OFFS			12
+#define PBARR_REMAP_MASK			(0xfffff << PBARR_REMAP_OFFS)
+#define PBARR_REMAP_ALIGNMENT			(1 << PBARR_REMAP_OFFS)
+
+/* PCI DRAM Bar Bank Select Register (PDBBSR) */
+#define PDBBSR_DRAM_BANK_OFFS(bank)		((bank) * 2)
+#define PDBBSR_DRAM_BANK_MASK(bank)		(0x3 << PDBBSR_DRAM_BANK_OFFS(bank))
+
+/* PCI Address Decode Control Register (PADCR)*/
+#define PADCR_REMAP_REG_WR_DIS			BIT0
+#define PADCR_MSG_REG_ACC			BIT3
+
+#define PADCR_VPD_HIGH_ADDR_OFFS		8 /* Bits [31:15] of the VPD address */
+#define PADCR_VPD_HIGH_ADDR_MASK		(0x1ffff << PADCR_VPD_HIGH_ADDR_OFFS)
+
+/* PCI Headers Retarget Control Register (PHRCR) */
+#define PHRCR_ENABLE				BIT0
+#define PHRCR_BUFF_SIZE_OFFS			1 
+#define PHRCR_BUFF_SIZE_MASK			(0x7 << PHRCR_BUFF_SIZE_OFFS)
+#define PHRCR_BUFF_SIZE_258BYTE			(0x0 << PHRCR_BUFF_SIZE_OFFS)
+#define PHRCR_BUFF_SIZE_512BYTE			(0x1 << PHRCR_BUFF_SIZE_OFFS)
+#define PHRCR_BUFF_SIZE_1KB			(0x2 << PHRCR_BUFF_SIZE_OFFS)
+#define PHRCR_BUFF_SIZE_2KB			(0x3 << PHRCR_BUFF_SIZE_OFFS)
+#define PHRCR_BUFF_SIZE_4KB			(0x4 << PHRCR_BUFF_SIZE_OFFS)
+#define PHRCR_BUFF_SIZE_8KB			(0x5 << PHRCR_BUFF_SIZE_OFFS)
+#define PHRCR_MASK1_OFFS			16
+#define PHRCR_MASK1_MASK			(0xffff << PHRCR_MASK1_OFFS)
+
+/* PCI Headers Retarget Base Register (PHRBR) */
+#define PHRBR_BASE_OFFS				16
+#define PHRBR_BASE_MASK				(0xffff << PHRBR_BASE_OFFS)
+
+/* PCI Headers Retarget Base High Register (PHRBHR) */
+#define PHRBHR_BASE_OFFS			0
+#define PHRBHR_BASE_MASK			(0xffffffff << PHRBHR_BASE_OFFS)
+
+/* This structure describes a PCI BAR. It is also refered as PCI target     */
+/* window to keep consistency with other address decode units in the system */
+typedef struct _mvPciBarWin 
+{
+    MV_ADDR_WIN		addrWin;	/* Address window       */
+    MV_BOOL     	enable;		/* BAR enable/disable   */
+}MV_PCI_BAR_WIN;
+
+typedef enum
+{
+    NO_CACHE_COHER = 0,
+    WT_CACHE_COHER,
+    WB_CACHE_COHER
+}MV_PCI_SNOOP;
+
+/* This structure describes PCI region attributes                           */
+typedef struct _mvPciRegionAttr
+{
+    MV_PCI_SNOOP	snoop;		/* Cache Coherenc			*/
+    MV_PROT_RIGHT	access;         /* Access protection                    */
+    MV_PROT_RIGHT	write;          /* Write protection                     */
+    MV_SWAP_TYPE	swapType;       /* Data swap mode for that region       */
+    MV_U32		readMaxBurst;   /* Read max burst                       */
+    MV_U32		readBurst;      /* Read burst. Conventional PCI only    */
+    MV_U32		writeMaxBurst;  /* Write max burst                      */
+    MV_BOOL		pciOrder;       /* Hardware support for PCI ordering    */
+}MV_PCI_REGION_ATTR;
+
+/* The PCI slave interface supports configurable access control.            */
+/* It is possible to define up to six address ranges to different           */
+/* configurations. This structure describes the PCI access region           */
+typedef struct _mvPciProtWin
+{
+    MV_ADDR_WIN         addrWin;	/* An address window                    */
+    MV_PCI_REGION_ATTR  attributes;	/* Window attributes                    */
+    MV_BOOL             enable;		/* Window enabled/disabled              */
+}MV_PCI_PROT_WIN;
+
+/* Global Functions prototypes */
+MV_STATUS mvPciInit(MV_U32 pciIf, MV_PCI_MOD pciIfmod);
+MV_STATUS mvPciTargetWinSet(MV_U32 pciIf, MV_PCI_BAR slaveTarget, MV_PCI_BAR_WIN *pAddrBarWin);
+MV_STATUS mvPciTargetWinGet(MV_U32 pciIf, MV_PCI_BAR slaveTarget, MV_PCI_BAR_WIN *pAddrBarWin);
+MV_STATUS mvPciTargetWinEnable(MV_U32 pciIf,MV_PCI_BAR slaveTarget, MV_BOOL enable);
+MV_STATUS mvPciProtWinSet(MV_U32 pciIf, MV_U32 winNum, MV_PCI_PROT_WIN *pProtWin);
+MV_STATUS mvPciProtWinGet(MV_U32 pciIf, MV_U32 winNum, MV_PCI_PROT_WIN *pProtWin);
+MV_STATUS mvPciProtWinEnable(MV_U32 pciIf, MV_U32 winNum, MV_BOOL enable);
+MV_STATUS mvPciTargetRemap(MV_U32 pciIf, MV_PCI_BAR slaveTarget, MV_ADDR_WIN *pAddrWin);
+MV_VOID   mvPciAddrDecShow(MV_VOID);
+
+#endif
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysPex.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysPex.c
new file mode 100644
index 0000000..e04ed71
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysPex.c
@@ -0,0 +1,106 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "pex/mvPex.h"
+#include "pex/mvPexRegs.h"
+
+MV_STATUS mvPexTargetWinGet(MV_U32 pexIf, MV_U32 winNum, MV_PEX_DEC_WIN *pAddrDecWin);
+
+
+/*******************************************************************************
+* mvSysPexInit - Initialize the Pex subsystem
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None
+* OUTPUT:
+*		None
+* RETURN:
+*       None
+*
+*******************************************************************************/
+MV_STATUS mvSysPexInit(MV_U32 pexIf, MV_PEX_TYPE pexType)
+{
+	MV_PEX_HAL_DATA halData;
+	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+	MV_STATUS status;
+
+	status = mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1);
+	if(status == MV_OK)
+		status = mvPexWinInit(pexIf, pexType, addrWinMap);
+
+	if(status == MV_OK) {
+		halData.ctrlModel = mvCtrlModelGet();
+		halData.maxPexIf = mvCtrlPexMaxIfGet();
+		status = mvPexInit(pexIf, pexType, &halData);
+	}
+
+	return status;
+}
+
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysPexApi.h b/arch/arm/mach-armadaxp/mv_hal_if/mvSysPexApi.h
new file mode 100644
index 0000000..1b6a6bf
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysPexApi.h
@@ -0,0 +1,71 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef __MV_SYS_PEX_API_H__
+#define __MV_SYS_PEX_API_H__
+
+
+MV_STATUS mvSysPexInit(MV_U32 pexIf, MV_PEX_TYPE pexType);
+
+#endif
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysSFlash.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysSFlash.c
new file mode 100644
index 0000000..2b84d9c
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysSFlash.c
@@ -0,0 +1,226 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+#include "spi/mvSpi.h"
+#include "spi/mvSpiCmnd.h"
+#include "sflash/mvSysSFlash.h"
+
+#define MV_SYS_SFLASH_MAX_CMD_LEN 4
+
+static struct {
+	MV_U8 buf[MV_SYS_SFLASH_MAX_CMD_LEN];
+	MV_U32 bufLen;
+	MV_U8  transType;
+} mvSysSflashCmd;
+
+/*******************************************************************************
+* mvSysSflashCommandSet
+*
+* DESCRIPTION:
+*	System interface for sending a command to the SPI flash.
+*
+* INPUT:
+*       flashHandle: Handle passed by OS glue by which an SPI flash is
+*		     identified.
+*      	cmdBuff:     Command data to be written.
+*	cmdLen:	     Command length in bytes.
+*	transType:   Bitmask describing the transaction type, see 
+*		     SYS_SFLASH_TRANS_XX for details.
+*
+* OUTPUT:
+*	None.
+*
+* RETURN:
+*	MV_OK on success,
+*	MV_ERROR otherwise.
+*
+*******************************************************************************/
+MV_STATUS mvSysSflashCommandSet(MV_VOID *flashHandle, MV_U8* cmdBuff, MV_U32 cmdLen,
+		MV_U8 transType)
+{
+	if (cmdLen > MV_SYS_SFLASH_MAX_CMD_LEN)
+		return MV_ERROR;
+
+	if (!(transType & SYS_SFLASH_TRANS_START) || (mvSysSflashCmd.transType != 0))
+		return MV_ERROR;	
+
+	mvSpiParamsSet(0, 0, SPI_TYPE_FLASH);
+
+	memcpy(mvSysSflashCmd.buf,cmdBuff,cmdLen);	
+	mvSysSflashCmd.bufLen = cmdLen;
+	mvSysSflashCmd.transType = transType;
+
+	if (transType & SYS_SFLASH_TRANS_END)
+		return mvSysSflashDataWrite(flashHandle, NULL, 0, transType);
+
+	return MV_OK;
+}
+
+
+/*******************************************************************************
+* mvSysSflashDataRead
+*
+* DESCRIPTION:
+*	System interface for reading SPI flash data.
+*
+* INPUT:
+*       flashHandle: Handle passed by OS glue by which an SPI flash is
+*		     identified.
+*	dataBuff:    Buffer to read the data into.
+*	dataLen:     Number of bytes to read.
+*	dummyBytes:  Number of dummy bytes to read before reading the real
+*		     data.
+*	transType:   Bitmask describing the transaction type, see 
+*		     SYS_SFLASH_TRANS_XX for details.
+*
+* OUTPUT:
+*	dataBuff: The data as read from flash.
+*
+* RETURN:
+*	MV_OK on success,
+*	MV_ERROR otherwise.
+*
+*******************************************************************************/
+MV_STATUS mvSysSflashDataRead(MV_VOID *flashHandle, MV_U8* dataBuff, MV_U32 dataLen,
+		MV_U32 dummyBytes, MV_U8 transType)
+{
+	MV_STATUS  ret;	
+
+	if (!(mvSysSflashCmd.transType & SYS_SFLASH_TRANS_START))
+		return MV_ERROR;
+
+
+	ret = mvSpiWriteThenRead (0, mvSysSflashCmd.buf, mvSysSflashCmd.bufLen,
+			dataBuff, dataLen, dummyBytes);
+	if (transType & SYS_SFLASH_TRANS_END)
+		memset(&mvSysSflashCmd,0,sizeof(mvSysSflashCmd));
+	return ret;
+}
+
+
+/*******************************************************************************
+* mvSysSflashDataWrite
+*
+* DESCRIPTION:
+*	System interface for writing SPI flash data.
+*
+* INPUT:
+*       flashHandle: Handle passed by OS glue by which an SPI flash is
+*		     identified.
+*	dataBuff:    Buffer holding the data to be written.
+*	dataLen:     Number of bytes to write.
+*	transType:   Bitmask describing the transaction type, see 
+*		     SYS_SFLASH_TRANS_XX for details.
+*
+* OUTPUT:
+*	None.
+*
+* RETURN:
+*	MV_OK on success,
+*	MV_ERROR otherwise.
+*
+*******************************************************************************/
+MV_STATUS mvSysSflashDataWrite(MV_VOID *flashHandle, MV_U8* dataBuff, MV_U32 dataLen,
+		MV_U8 transType)
+{
+	MV_STATUS ret;
+
+	if (!(mvSysSflashCmd.transType & SYS_SFLASH_TRANS_START))
+		return MV_ERROR;
+
+	ret = mvSpiWriteThenWrite (0, mvSysSflashCmd.buf, mvSysSflashCmd.bufLen, dataBuff, dataLen);
+	if (transType & SYS_SFLASH_TRANS_END)
+		memset(&mvSysSflashCmd,0,sizeof(mvSysSflashCmd));
+	return ret;
+}
+
+
+/*******************************************************************************
+* mvSysSflashFreqSet
+*
+* DESCRIPTION:
+*	System interface for controlling the SPI interface frequency.
+*
+* INPUT:
+*       flashHandle: Handle passed by OS glue by which an SPI flash is
+*		     identified.
+*	freq:	     The new frequency to be configured for the SPI IF.
+*
+* OUTPUT:
+*	None.
+*
+* RETURN:
+*	MV_OK on success,
+*	MV_ERROR otherwise.
+*
+*******************************************************************************/
+MV_STATUS mvSysSflashFreqSet(MV_VOID *flashHandle, MV_U32 freq)
+{
+
+	return mvSpiBaudRateSet(0, freq);
+}
+
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysSata.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysSata.c
new file mode 100644
index 0000000..a0317c9
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysSata.c
@@ -0,0 +1,82 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+#include "sata/CoreDriver/mvSata.h"
+#include "ctrlEnv/mvCtrlEnvAddrDec.h"
+
+MV_STATUS mvSysSataWinInit(MV_VOID)
+{
+	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+	MV_STATUS status;
+
+	status = mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1);
+	if(status == MV_OK)
+		status = mvSataWinInit(addrWinMap);
+
+	return status;
+}
+
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysSataApi.h b/arch/arm/mach-armadaxp/mv_hal_if/mvSysSataApi.h
new file mode 100644
index 0000000..575a8d6
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysSataApi.h
@@ -0,0 +1,71 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef __MV_SYS_SATA_API_H__
+#define __MV_SYS_SATA_API_H__
+
+MV_STATUS mvSysSataWinInit(MV_VOID);
+
+#endif 
+
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysSpi.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysSpi.c
new file mode 100644
index 0000000..b407634
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysSpi.c
@@ -0,0 +1,126 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "spi/mvSpi.h"
+#include "spi/mvSysSpi.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+
+
+/*******************************************************************************
+* mvSysSpiInit - Initialize the SPI subsystem
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None
+* OUTPUT:
+*		None
+* RETURN:
+*       None
+*
+*******************************************************************************/
+MV_STATUS   mvSysSpiInit(MV_U8 spiId, MV_U32 serialBaudRate)
+{
+	MV_SPI_HAL_DATA halData;
+
+	halData.ctrlModel = mvCtrlModelGet();
+	halData.tclk = mvBoardTclkGet();
+
+	return mvSpiInit(spiId, serialBaudRate, &halData);
+}
+
+
+/*******************************************************************************
+* mvSysSpiMppConfig
+*
+* DESCRIPTION:
+*	System interface for configuring the MPP's configuration to enable /
+*	disable SPI mode.
+*
+* INPUT:
+*      	mode:	The mode to be set into MPP unit.
+*
+* OUTPUT:
+*	None.
+*
+* RETURN:
+*	MV_OK on success,
+*	MV_ERROR otherwise.
+*
+*******************************************************************************/
+MV_STATUS mvSysSpiMppConfig(MV_U8 mode)
+{
+#if 0
+	if(mode == SYS_SPI_MPP_ENABLE)
+		mvMPPConfigToSPI();
+	else
+		mvMPPConfigToDefault();
+#endif
+	return MV_OK;
+}
+
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysSpiApi.h b/arch/arm/mach-armadaxp/mv_hal_if/mvSysSpiApi.h
new file mode 100644
index 0000000..80888c0
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysSpiApi.h
@@ -0,0 +1,70 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef __MV_SYS_SPI_API_H__
+#define __MV_SYS_SPI_API_H__
+
+MV_STATUS   mvSysSpiInit(MV_U8 spi_id, MV_U32 serialBaudRate);
+
+#endif
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysTdm.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysTdm.c
new file mode 100644
index 0000000..83c9d59
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysTdm.c
@@ -0,0 +1,236 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#ifdef CONFIG_MV_TDM_SUPPORT
+#include "voiceband/tdm/mvTdm.h"
+#else
+ #include "voiceband/commUnit/mvCommUnit.h"
+ #include "gpp/mvGpp.h"
+#endif
+#include "voiceband/mvSysTdmSpi.h"
+#include "spi/mvSpiCmnd.h"
+#include "spi/mvSpi.h"
+
+#define MAX_DATA_LENGTH		255
+
+/*******************************************************************************
+* mvSysTdmInit - Initialize the TDM subsystem
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None
+* OUTPUT:
+*		None
+* RETURN:
+*       None
+*
+*******************************************************************************/
+MV_STATUS mvSysTdmInit(MV_TDM_PARAMS* tdmParams)
+{
+	MV_TDM_HAL_DATA halData;
+	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+	MV_STATUS status;
+
+	status = mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1);
+	if(status == MV_OK)
+#ifdef MV_TDM_SUPPORT
+		status = mvTdmWinInit(addrWinMap);
+#else
+		status = mvCommUnitWinInit(addrWinMap);
+#endif
+
+	if(status == MV_OK) {
+		halData.spiMode = mvBoardTdmSpiModeGet();
+		halData.model = mvCtrlModelGet();
+#ifdef MV_TDM_SUPPORT
+		status = mvTdmHalInit (tdmParams, &halData);
+#else
+		halData.maxCs = mvBoardTdmDevicesCountGet();
+		status = mvCommUnitHalInit (tdmParams, &halData);
+		
+		/* Issue SLIC reset */
+		mvGppValueSet(0, BIT24, 0);
+		mvOsDelay(1);
+		mvGppValueSet(0, BIT24, BIT24);
+#endif
+	}
+
+	return status;
+}
+
+MV_VOID mvSysTdmSpiRead(MV_U16 lineId, MV_U8* cmdBuff, MV_U8 cmdSize, MV_U8* dataBuff, MV_U8 dataSize)
+{
+#if defined(MV_TDM_SUPPORT) && !defined(ZARLINK_SLIC_SUPPORT)
+
+	if((cmdSize > 4) || (dataSize > MAX_DATA_LENGTH))
+	{
+		mvOsPrintf("Error, exceeded max size of command(%d) or data(%d)\n", cmdSize, dataSize);
+		return;
+	}
+
+	mvTdmSpiRead(cmdBuff, cmdSize, dataBuff, dataSize, lineId);
+
+#else /* MV_COMM_UNIT_SUPPORT || ZARLINK_SLIC_SUPPORT */
+
+	/* Set SPI parameters(lineId = devId) */
+	mvSpiParamsSet(0, mvBoardTdmSpiCsGet(lineId), SPI_TYPE_SLIC);
+	
+	if(MV_OK != mvSpiWriteThenRead (0, cmdBuff, cmdSize, dataBuff, dataSize, 0))
+		printk("SPI read failed !!!\n");
+
+#endif /* MV_TDM_SUPPORT */
+}
+
+/*******************************************************************************
+* mvSysTdmSpiWrite - telephony register write via SPI interface
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None
+* OUTPUT:
+*		None
+* RETURN:
+*       None
+*
+*******************************************************************************/
+MV_VOID mvSysTdmSpiWrite(MV_U16 lineId, MV_U8* cmdBuff, MV_U8 cmdSize, MV_U8* dataBuff, MV_U8 dataSize)
+{
+#if defined(MV_TDM_SUPPORT) && !defined(ZARLINK_SLIC_SUPPORT)
+
+	if((cmdSize > 3) || (dataSize > MAX_DATA_LENGTH))
+	{
+		mvOsPrintf("Error, exceeded max size of command(%d) or data(%d)\n", cmdSize, dataSize);
+		return;
+	}
+
+	mvTdmSpiWrite(cmdBuff, cmdSize, dataBuff, dataSize, lineId);
+
+#else /* MV_COMM_UNIT_SUPPORT || ZARLINK_SLIC_SUPPORT */
+	
+	/* Set SPI parameters(lineId = devId) */
+	mvSpiParamsSet(0, mvBoardTdmSpiCsGet(lineId), SPI_TYPE_SLIC);
+
+	if(MV_OK != mvSpiWriteThenWrite (0, cmdBuff, cmdSize, dataBuff, dataSize))
+		printk("SPI write failed !!!\n");
+
+#endif /* MV_TDM_SUPPORT */
+}
+
+/*******************************************************************************
+* mvSysTdmIntEnable - Enable CSLAC device interrupts. 
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       Device ID
+* OUTPUT:
+*		None
+* RETURN:
+*       None
+*
+*******************************************************************************/
+MV_VOID mvSysTdmIntEnable(MV_U8 deviceId)
+{
+#if defined(MV_TDM_SUPPORT)
+
+	mvTdmIntEnable();
+
+#else /* MV_COMM_UNIT_SUPPORT */
+
+	mvCommUnitIntEnable(deviceId);
+
+#endif
+}
+
+/*******************************************************************************
+* mvSysTdmIntDisable - Disable CSLAC device interrupts. 
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       Device ID
+* OUTPUT:
+*		None
+* RETURN:
+*       None
+*
+*******************************************************************************/
+MV_VOID mvSysTdmIntDisable(MV_U8 deviceId)
+{
+#if defined(MV_TDM_SUPPORT)
+
+	mvTdmIntDisable();
+
+#else /* MV_COMM_UNIT_SUPPORT */
+
+	mvCommUnitIntDisable(deviceId);
+
+#endif
+}
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysTdmApi.h b/arch/arm/mach-armadaxp/mv_hal_if/mvSysTdmApi.h
new file mode 100644
index 0000000..74ca023
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysTdmApi.h
@@ -0,0 +1,78 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef __MV_SYS_TDM_API_H__
+#define __MV_SYS_TDM_API_H__
+
+#include "mvSysTdmConfig.h"
+
+#ifdef MV_TDM_SUPPORT
+#include "voiceband/tdm/mvTdm.h"
+#else
+  #include "voiceband/commUnit/mvCommUnit.h"
+#endif
+
+MV_STATUS mvSysTdmInit (MV_TDM_PARAMS* tdmParams);
+
+#endif
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysTs.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysTs.c
new file mode 100644
index 0000000..79ea4e8
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysTs.c
@@ -0,0 +1,87 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+#include "ts/mvTsu.h"
+#include "ctrlEnv/mvCtrlEnvAddrDec.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "ts/mvTsuRegs.h"
+
+MV_STATUS mvSysTsuInit(MV_TSU_CORE_CLOCK coreClock, MV_TSU_PORTS_MODE mode,
+		void *osHandle)
+{
+	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+	MV_STATUS status;
+
+	status = mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1);
+	if(status == MV_OK)
+		status = mvTsuWinInit(addrWinMap);
+
+	if(status == MV_OK)
+		status = mvTsuHalInit(coreClock, mode, osHandle);
+	return status;
+}
+
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysTsApi.h b/arch/arm/mach-armadaxp/mv_hal_if/mvSysTsApi.h
new file mode 100644
index 0000000..837782d
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysTsApi.h
@@ -0,0 +1,73 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef __MV_SYS_TS_API_H__
+#define __MV_SYS_TS_API_H__
+
+#include "ts/mvTsu.h"
+
+MV_STATUS mvSysTsuInit(MV_TSU_CORE_CLOCK coreClock, MV_TSU_PORTS_MODE mode,
+		void *osHandle);
+
+#endif
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysUsb.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysUsb.c
new file mode 100644
index 0000000..f84e065
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysUsb.c
@@ -0,0 +1,103 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "usb/mvUsb.h"
+#include "ctrlEnv/mvCtrlEnvAddrDec.h"
+#include "usb/mvUsbRegs.h"
+
+/*******************************************************************************
+* mvSysUsbHalInit - Initialize the USB subsystem
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None
+* OUTPUT:
+*		None
+* RETURN:
+*       None
+*
+*******************************************************************************/
+MV_STATUS   mvSysUsbInit(MV_U32 dev, MV_BOOL isHost)
+{
+	MV_USB_HAL_DATA halData;
+	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+	MV_STATUS status;
+
+	status = mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1);
+	if(status == MV_OK)
+		status = mvUsbWinInit(dev, addrWinMap);
+
+	if(status == MV_OK) {
+		halData.ctrlModel = mvCtrlModelGet();
+		halData.ctrlRev = mvCtrlRevGet();
+		status = mvUsbHalInit(dev, isHost, &halData);
+	}
+
+	return status;
+}
+
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysUsbApi.h b/arch/arm/mach-armadaxp/mv_hal_if/mvSysUsbApi.h
new file mode 100644
index 0000000..675b608
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysUsbApi.h
@@ -0,0 +1,70 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef __MV_SYS_USB_API_H__
+#define __MV_SYS_USB_API_H__
+
+MV_STATUS   mvSysUsbInit(MV_U32 dev, MV_BOOL isHost);
+
+#endif
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysXor.c b/arch/arm/mach-armadaxp/mv_hal_if/mvSysXor.c
new file mode 100644
index 0000000..20acd3e
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysXor.c
@@ -0,0 +1,87 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+#include "xor/mvXor.h"
+#include "ctrlEnv/mvCtrlEnvAddrDec.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "xor/mvXorRegs.h"
+
+MV_VOID mvSysXorInit (void)
+{
+	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+	MV_STATUS status;
+
+	status = mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1);
+	if(status == MV_OK)
+		status = mvXorWinInit(addrWinMap);
+
+	if(status == MV_OK)
+		mvXorHalInit(MV_XOR_MAX_CHAN);
+	return;
+}
+
+
diff --git a/arch/arm/mach-armadaxp/mv_hal_if/mvSysXorApi.h b/arch/arm/mach-armadaxp/mv_hal_if/mvSysXorApi.h
new file mode 100644
index 0000000..fb2b06d
--- /dev/null
+++ b/arch/arm/mach-armadaxp/mv_hal_if/mvSysXorApi.h
@@ -0,0 +1,70 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef __MV_SYS_XOR_API_H__
+#define __MV_SYS_XOR_API_H__
+
+MV_VOID mvSysXorInit (void);
+
+#endif
diff --git a/arch/arm/mach-armadaxp/pci.c b/arch/arm/mach-armadaxp/pci.c
new file mode 100644
index 0000000..6951093
--- /dev/null
+++ b/arch/arm/mach-armadaxp/pci.c
@@ -0,0 +1,243 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#include <linux/kernel.h>
+#include <linux/pci.h>
+#include <linux/ptrace.h>
+#include <linux/slab.h>
+#include <linux/ioport.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/init.h>
+                                                                                                                             
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/system.h>
+#include <asm/mach/pci.h>
+
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "ctrlEnv/sys/mvCpuIf.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+#include "mvSysPci.h"
+#include "pci/mvPci.h"
+
+#undef DEBUG
+#ifdef DEBUG
+#	define DB(x) x
+#else
+#	define DB(x) 
+#endif
+
+static int __init mv_map_irq(struct pci_dev *dev, u8 slot, u8 pin);
+
+extern u32 mv_pci_mem_size_get(int ifNum);
+extern u32 mv_pci_io_base_get(int ifNum);
+extern u32 mv_pci_io_size_get(int ifNum);
+extern u32 mv_pci_mem_base_get(int ifNum);
+
+void __init mv_pci_preinit(void)
+{
+	MV_ADDR_WIN win;
+	
+	if (mvCtrlPciMaxIfGet() > 1)
+		panic("Single PCI is supported ONLY!");
+
+       	mvPciInit(0, MV_PCI_MOD_HOST);
+
+	/* I/O remmap */
+	win.baseLow = 0x0;
+	win.baseHigh = 0x0;
+	mvCpuIfPciRemap(PCI_IF0_IO, &win);
+}
+
+
+/* Currentlly the PCI config read/write are implemented as read modify write
+   to 32 bit.
+   TBD: adjust it to realy use 1/2/4 byte(partial) read/write, after the pex
+	read config WA will be removed.
+*/
+static int mv_pci0_read_config(struct pci_bus *bus, unsigned int devfn, int where,
+                          int size, u32 *val)
+{
+
+        MV_U32 bus_num,func,regOff,dev_no,temp;
+	MV_U32 localBus;
+ 
+	*val = 0xffffffff;
+
+        bus_num = bus->number;
+        dev_no = PCI_SLOT(devfn);
+ 
+	/* don't return for our device */
+	localBus = mvPciLocalBusNumGet(0);
+	if((dev_no == 0) && ( bus_num == localBus)) {
+		DB(printk("PCI 0 read from our own dev return 0xffffffff \n"));
+		return 0xffffffff;
+	}
+
+        func = PCI_FUNC(devfn); 
+        regOff = (MV_U32)where & PCAR_REG_NUM_MASK;
+
+	if ((func == 0)&&(dev_no < 2))
+		DB(printk("PCI 0 read: bus = %x dev = %x func = %x regOff = %x ",bus_num,dev_no,func,regOff));
+	
+
+        temp = (u32) mvPciConfigRead(0, bus_num, dev_no, func, regOff);
+
+        switch (size) {
+        case 1:
+                temp = (temp >>  (8*(where & 0x3))) & 0xff;
+                break;
+ 
+        case 2:
+                temp = (temp >>  (8*(where & 0x2))) & 0xffff;
+                break;
+ 
+        default:
+                break;
+        }
+	
+	*val = temp;
+
+	if ((func == 0)&&(dev_no < 2)) {
+		DB(printk(" got %x \n",temp));
+	}
+	
+        return 0;
+}
+
+static int mv_pci0_write_config(struct pci_bus *bus, unsigned int devfn, int where,
+                           int size, u32 val)
+{
+        MV_U32 bus_num,func,regOff,dev_no,temp, mask , shift;
+ 
+	bus_num = bus->number;
+	dev_no = PCI_SLOT(devfn); 
+	func = PCI_FUNC(devfn); 
+	regOff = (MV_U32)where & PCAR_REG_NUM_MASK;
+
+	DB(printk("PCI 0: writing data %x size %x to bus %x dev %x func %x offs %x \n",val,size,bus_num,dev_no,func,regOff));
+	if( size != 4)
+        	temp = (u32) mvPciConfigRead(0, bus_num, dev_no, func, regOff);
+	else
+		temp = val;
+
+        switch (size) {
+        case 1:
+		shift = (8*(where & 0x3));
+		mask = 0xff;
+                break;
+ 
+        case 2:
+		shift = (8*(where & 0x2));
+                mask = 0xffff; 
+                break;
+ 
+        default:
+		shift = 0;
+		mask = 0xffffffff;
+                break;
+        }
+	
+	temp = (temp & (~(mask<<shift))) | ((val & mask) << shift);
+	mvPciConfigWrite(0, bus_num, dev_no, func, regOff, temp);
+
+        return 0;
+}
+
+static struct pci_ops mv_pci_ops = {
+        .read   = mv_pci0_read_config,
+        .write  = mv_pci0_write_config,
+};
+
+int __init mv_pci_setup(int nr, struct pci_sys_data *sys)
+{
+        struct resource *res;
+
+	if (nr)
+		panic("Single PCI is supported ONLY!");
+
+        sys->map_irq = mv_map_irq;
+
+	res = kmalloc(sizeof(struct resource) * 2, GFP_KERNEL);
+        if (!res)
+                panic("PCI: unable to alloc resources");
+                                                                                                                             
+        memset(res, 0, sizeof(struct resource) * 2);
+                                                                                                                             
+	res[0].start = mv_pci_io_base_get(0) - IO_SPACE_REMAP;
+	res[0].end   =  mv_pci_io_base_get(0) - IO_SPACE_REMAP +  mv_pci_io_size_get(0) - 1;
+	res[0].name  = "PCI0 IO Primary";
+	res[0].flags = IORESOURCE_IO;
+                                                                                                                             
+	res[1].start =  mv_pci_mem_base_get(0);
+	res[1].end   =  mv_pci_mem_base_get(0) +  mv_pci_mem_size_get(0) - 1;
+	res[1].name  = "PCI0 Memory Primary";
+	res[1].flags = IORESOURCE_MEM;
+ 
+        if (request_resource(&ioport_resource, &res[0]))
+		printk ("IO Request resource failed - Pci If %x\n",nr);
+
+	if (request_resource(&iomem_resource, &res[1]))
+		printk ("Memory Request resource failed - Pci If %x\n",nr);
+ 
+        sys->resource[0] = &res[0];
+        sys->resource[1] = &res[1];
+        sys->resource[2] = NULL;
+        sys->io_offset   = 0x0;
+ 
+        return 1;
+
+}
+
+struct pci_bus *mv_pci_scan_bus(int nr, struct pci_sys_data *sys)
+{
+	struct pci_ops *ops;
+	struct pci_bus *bus;
+
+        if (nr)
+		panic("Single PCI is supported ONLY!");
+
+	ops = &mv_pci_ops;
+	bus = pci_scan_bus(sys->busnr, ops, sys);
+	return bus;
+}
+
+static int __init mv_map_irq(struct pci_dev *dev, u8 slot, u8 pin)
+{
+	return IRQ_AURORA_PCI0;
+}
+
+static struct hw_pci mv_pci __initdata = {
+	.swizzle        	= pci_std_swizzle,
+        .map_irq                = mv_map_irq,
+        .setup                  = mv_pci_setup,
+        .scan                   = mv_pci_scan_bus,
+        .preinit                = mv_pci_preinit,
+};
+ 
+static int __init mv_pci_init(void)
+{
+	MV_U32 ifnum = mvCtrlPciMaxIfGet();
+	if (ifnum) {
+		mv_pci.nr_controllers = ifnum; 
+		pci_common_init(&mv_pci);
+	}
+
+    return 0;
+}
+
+subsys_initcall(mv_pci_init);
+
diff --git a/arch/arm/mach-armadaxp/pex.c b/arch/arm/mach-armadaxp/pex.c
new file mode 100644
index 0000000..f7158c4
--- /dev/null
+++ b/arch/arm/mach-armadaxp/pex.c
@@ -0,0 +1,405 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#include <linux/kernel.h>
+#include <linux/pci.h>
+#include <linux/ptrace.h>
+#include <linux/slab.h>
+#include <linux/ioport.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/init.h>
+                                                                                                                             
+#include <mach/hardware.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/system.h>
+#include <asm/mach/pci.h>
+#include <mach/irqs.h>
+
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "ctrlEnv/sys/mvCpuIf.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+#include "pex/mvPexRegs.h"
+#include "mvSysPexApi.h"
+
+#ifdef MV_DEBUG
+#	define DB(x) x
+#else
+#	define DB(x) 
+#endif
+
+#define MV_PEX_MASK_ABCD              (BIT24 | BIT25 | BIT26 | BIT27)
+
+static int __init mv_map_irq_0(struct pci_dev *dev, u8 slot, u8 pin);
+static int __init mv_map_irq_1(struct pci_dev *dev, u8 slot, u8 pin);
+static int __init mv_map_irq_2(struct pci_dev *dev, u8 slot, u8 pin);
+static int __init mv_map_irq_3(struct pci_dev *dev, u8 slot, u8 pin);
+static int __init mv_map_irq_4(struct pci_dev *dev, u8 slot, u8 pin);
+static int __init mv_map_irq_5(struct pci_dev *dev, u8 slot, u8 pin);
+static int __init mv_map_irq_6(struct pci_dev *dev, u8 slot, u8 pin);
+static int __init mv_map_irq_7(struct pci_dev *dev, u8 slot, u8 pin);
+static int __init mv_map_irq_8(struct pci_dev *dev, u8 slot, u8 pin);
+static int __init mv_map_irq_9(struct pci_dev *dev, u8 slot, u8 pin);
+
+extern u32 mv_pci_mem_size_get(int ifNum);
+extern u32 mv_pci_io_base_get(int ifNum);
+extern u32 mv_pci_io_size_get(int ifNum);
+extern u32 mv_pci_mem_base_get(int ifNum);
+extern int mv_is_pci_io_mapped(int ifNum);
+extern MV_TARGET mv_pci_io_target_get(int ifNum);
+
+static void* mv_get_irqmap_func[] __initdata =
+{
+	mv_map_irq_0,
+	mv_map_irq_1,
+	mv_map_irq_2,
+	mv_map_irq_3,
+	mv_map_irq_4,
+	mv_map_irq_5,
+	mv_map_irq_6,
+	mv_map_irq_7,
+	mv_map_irq_8,
+	mv_map_irq_9
+};
+
+void __init mv_pex_preinit(void)
+{
+	static MV_U32 pex0flg = 0;
+	unsigned int pciIf, temp;
+	MV_ADDR_WIN pciIoRemap;
+	MV_BOARD_PEX_INFO* boardPexInfo = mvBoardPexInfoGet();
+	MV_U32 pexHWInf = 0;
+
+	for (pciIf = 0; pciIf < boardPexInfo->boardPexIfNum; pciIf++) 
+	{
+		/* Translate logical interface number to physical */
+		pexHWInf = boardPexInfo->pexMapping[pciIf];
+
+		printk("PCI-E: Cheking physical bus #%d (controller #%d): ", pciIf, pexHWInf);
+		if (MV_FALSE == mvCtrlPwrClckGet(PEX_UNIT_ID, pexHWInf))	
+		{
+			printk("Disabled\n");
+			continue;
+		}
+
+		/* init the PCI interface */
+		temp = mvSysPexInit(pexHWInf, MV_PEX_ROOT_COMPLEX);
+
+		if (MV_NO_SUCH == temp)
+		{
+			printk("Enabled - No Link\n");
+			/* No Link - shutdown interface */
+			mvCtrlPwrClckSet(PEX_UNIT_ID, pexHWInf, MV_FALSE);;
+			continue;
+		}
+		else if ((MV_OK != temp) && (MV_NO_SUCH != temp)){
+			printk("Init FAILED!!!\n");
+			printk("PCI-E %d: Init Failed.\n", pexHWInf);
+		}
+
+		printk("Enabled - Link UP\n");
+		/* Assign bus number 0 to first active/available bus */
+		if (pex0flg == 0) {
+	       		mvPexLocalBusNumSet(pexHWInf, 0x0);
+	       		pex0flg = 1;
+		}
+
+		MV_REG_BIT_SET(PEX_MASK_REG(pexHWInf), MV_PEX_MASK_ABCD);
+		if (mv_is_pci_io_mapped(pexHWInf))
+		{
+			pciIoRemap.baseLow = mv_pci_io_base_get(pexHWInf) - IO_SPACE_REMAP;
+			pciIoRemap.baseHigh = 0; 		
+			pciIoRemap.size = mv_pci_io_size_get(pexHWInf);
+			mvCpuIfPexRemap(mv_pci_io_target_get(pexHWInf), &pciIoRemap);
+		}
+	}
+}
+
+/* Currentlly the PCI config read/write are implemented as read modify write
+   to 32 bit.
+   TBD: adjust it to realy use 1/2/4 byte(partial) read/write, after the pex
+	read config WA will be removed.
+*/
+static int mv_pci_read_config(struct pci_bus *bus, 
+				  unsigned int devfn, int where,
+				  int size, u32 *val)
+{
+	u32 bus_num,func,regOff,dev_no,temp, localBus;		
+	struct pci_sys_data *sysdata = (struct pci_sys_data *)bus->sysdata;	
+	u32 pciIf = sysdata->mv_controller_num;
+
+	*val = 0xffffffff;
+
+	if (MV_FALSE == mvCtrlPwrClckGet(PEX_UNIT_ID, pciIf))
+		return 0;
+	bus_num = bus->number;
+	dev_no = PCI_SLOT(devfn);
+
+	/* don't return for our device */
+	localBus = mvPexLocalBusNumGet(pciIf);
+	if ((dev_no == 0) && ( bus_num == localBus))
+	{
+		DB(printk("PCI %d read from our own dev return 0xffffffff \n", pciIf));
+		return 0xffffffff;
+	}
+
+	func = PCI_FUNC(devfn); 
+	regOff = (MV_U32)where & PXCAR_REG_NUM_MASK;
+
+	DB(printk("PCI %d read: bus = %x dev = %x func = %x regOff = %x ",pciIf, bus_num,dev_no,func,regOff));
+	
+	temp = (u32) mvPexConfigRead(pciIf, bus_num, dev_no, func, regOff);
+	switch (size) {
+		case 1:
+			temp = (temp >>  (8*(where & 0x3))) & 0xff;
+			break;
+
+		case 2:
+			temp = (temp >>  (8*(where & 0x2))) & 0xffff;
+			break;
+
+		default:
+			break;
+	}
+		
+	*val = temp;
+
+	DB(printk(" got %x \n",temp));
+	
+    return 0;
+}
+
+static int mv_pci_write_config(struct pci_bus *bus, unsigned int devfn, int where,
+                           int size, u32 val)
+{
+	u32 bus_num,func,regOff,dev_no,temp, mask , shift;
+	struct pci_sys_data *sysdata = (struct pci_sys_data *)bus->sysdata;	
+	u32 pciIf = sysdata->mv_controller_num;		
+
+	if (MV_FALSE == mvCtrlPwrClckGet(PEX_UNIT_ID, pciIf))
+		return 0xFFFFFFFF;
+	bus_num = bus->number;
+	dev_no = PCI_SLOT(devfn);
+	func = PCI_FUNC(devfn);
+	regOff = (MV_U32)where & PXCAR_REG_NUM_MASK;
+
+	DB(printk("PCI %d: writing data %x size %x to bus %x dev %x func %x offs %x \n",
+			  pciIf, val,size,bus_num,dev_no,func,regOff));
+	if (size != 4)
+	{
+		temp = (u32) mvPexConfigRead(pciIf, bus_num, dev_no, func, regOff);
+	}
+	else
+	{
+		temp = val;
+	}
+
+	switch (size) {
+		case 1:
+			shift = (8*(where & 0x3));
+			mask = 0xff;
+			break;
+		case 2:
+			shift = (8*(where & 0x2));
+			mask = 0xffff;
+			break;
+
+		default:
+			shift = 0;
+			mask = 0xffffffff;
+			break;
+	}
+
+	temp = (temp & (~(mask<<shift))) | ((val & mask) << shift);
+	mvPexConfigWrite(pciIf, bus_num, dev_no, func, regOff, temp);
+	return 0;
+}
+
+
+static struct pci_ops mv_pci_ops = {
+        .read   = mv_pci_read_config,
+        .write  = mv_pci_write_config,
+};
+
+
+int __init mv_pex_setup(int nr, struct pci_sys_data *sys)
+{
+	struct resource *res;
+	u32 membase, iobase, index = 0;	
+	MV_BOARD_PEX_INFO* boardPexInfo = mvBoardPexInfoGet();
+	MV_U32 pexHWInf = 0;
+
+	/* Translate logical interface number to physical */
+	pexHWInf = boardPexInfo->pexMapping[nr];
+
+	/* Check if this interface is used or not */
+	if (MV_FALSE == mvCtrlPwrClckGet(PEX_UNIT_ID, pexHWInf))
+		return 0;
+
+	/* Allocate resources memory */	
+	res = kmalloc(sizeof(struct resource) * 2, GFP_KERNEL);
+	if (!res)
+	{
+		panic("PCI: unable to alloc resources");
+		return 0;
+	}
+                                                                                                                             
+	memset(res, 0, sizeof(struct resource) * 2);
+
+	/* Save the H/W if number for this PEX bus */
+	sys->mv_controller_num = pexHWInf;
+	sys->map_irq = mv_get_irqmap_func[sys->mv_controller_num];
+	
+	membase = mv_pci_mem_base_get(sys->mv_controller_num);
+	if (mv_is_pci_io_mapped(sys->mv_controller_num))
+	{
+	
+		iobase = mv_pci_io_base_get(sys->mv_controller_num);
+		res[index].start = iobase - IO_SPACE_REMAP;
+		res[index].end   = iobase - IO_SPACE_REMAP + mv_pci_io_size_get(sys->mv_controller_num)-1;
+		res[index].name  = "PCIx IO Primary";
+		res[index].flags = IORESOURCE_IO;		
+		if (request_resource(&ioport_resource, &res[index]))
+		{	
+			printk ("IO Request resource failed - Pci If %x\n",nr);
+		}
+		else
+			index++;
+	}
+	res[index].start = membase;
+	res[index].end   = membase + mv_pci_mem_size_get(sys->mv_controller_num)-1;
+	res[index].name  = "PCIx Memory Primary";
+	res[index].flags = IORESOURCE_MEM;
+
+	if (request_resource(&iomem_resource, &res[index]))
+	{	
+		printk ("Memory Request resource failed - Pci If %x\n",nr);
+	}
+ 
+	sys->resource[0] = &res[0];
+	if (index > 0) 
+	{
+		sys->resource[1] = &res[1];
+		sys->resource[2] = NULL;
+	}
+	else
+		sys->resource[1] = NULL;
+	sys->io_offset   = 0x0;
+
+	return 1;
+}
+
+
+struct pci_bus *mv_pex_scan_bus(int nr, struct pci_sys_data *sys)
+{
+	struct pci_ops *ops = &mv_pci_ops;	
+	struct pci_bus *bus;
+	MV_BOARD_PEX_INFO* boardPexInfo = mvBoardPexInfoGet();
+	MV_U32 pexNextHWInf, ifnum;
+
+	bus = pci_scan_bus(sys->busnr, ops, sys);
+
+	/* Set the bus number in the following controller */
+	for (ifnum = (nr+1); ifnum < boardPexInfo->boardPexIfNum; ifnum++) {
+		pexNextHWInf = boardPexInfo->pexMapping[ifnum];
+		if (MV_TRUE == mvCtrlPwrClckGet(PEX_UNIT_ID, pexNextHWInf)) {
+			mvPexLocalBusNumSet(pexNextHWInf, (bus->subordinate + 1));
+			break;
+		}
+	}
+
+	return bus;
+}
+
+
+static int __init mv_map_irq_0(struct pci_dev *dev, u8 slot, u8 pin)
+{	
+	return IRQ_AURORA_PCIE0;
+}
+
+static int __init mv_map_irq_1(struct pci_dev *dev, u8 slot, u8 pin)
+{
+	return IRQ_AURORA_PCIE1;
+}
+
+static int __init mv_map_irq_2(struct pci_dev *dev, u8 slot, u8 pin)
+{
+	return IRQ_AURORA_PCIE2;
+}
+
+static int __init mv_map_irq_3(struct pci_dev *dev, u8 slot, u8 pin)
+{
+	return IRQ_AURORA_PCIE3;
+}
+
+static int __init mv_map_irq_4(struct pci_dev *dev, u8 slot, u8 pin)
+{
+	return IRQ_AURORA_PCIE4;
+}
+
+static int __init mv_map_irq_5(struct pci_dev *dev, u8 slot, u8 pin)
+{
+	return IRQ_AURORA_PCIE5;
+}
+
+static int __init mv_map_irq_6(struct pci_dev *dev, u8 slot, u8 pin)
+{
+	return IRQ_AURORA_PCIE6;
+}
+
+static int __init mv_map_irq_7(struct pci_dev *dev, u8 slot, u8 pin)
+{
+	return IRQ_AURORA_PCIE7;
+}
+
+static int __init mv_map_irq_8(struct pci_dev *dev, u8 slot, u8 pin)
+{
+	return IRQ_AURORA_PCIE8;
+}
+
+static int __init mv_map_irq_9(struct pci_dev *dev, u8 slot, u8 pin)
+{
+	return IRQ_AURORA_PCIE9;
+}
+
+static struct hw_pci mv_pci __initdata = {
+	.swizzle        	= pci_std_swizzle,
+        .setup                  = mv_pex_setup,
+        .scan                   = mv_pex_scan_bus,
+        .preinit                = mv_pex_preinit,
+};
+
+
+static int __init mv_pci_init(void)
+{
+    /* WA - Disable PEX on RD-SERVER board */
+    if (mvBoardIdGet() == RD_78460_SERVER_ID)
+	return 0;
+
+    mv_pci.nr_controllers = (mvBoardPexInfoGet())->boardPexIfNum;
+    mv_pci.swizzle        = pci_std_swizzle;
+    mv_pci.map_irq         = mv_map_irq_0;
+    mv_pci.setup           = mv_pex_setup;
+    mv_pci.scan            = mv_pex_scan_bus;
+    mv_pci.preinit         = mv_pex_preinit;
+    pci_common_init(&mv_pci);
+    return 0;
+}
+
+
+subsys_initcall(mv_pci_init);
+
diff --git a/arch/arm/mach-armadaxp/platsmp.c b/arch/arm/mach-armadaxp/platsmp.c
new file mode 100644
index 0000000..bed0c40
--- /dev/null
+++ b/arch/arm/mach-armadaxp/platsmp.c
@@ -0,0 +1,275 @@
+/*
+ *  linux/arch/arm/mach-armadaxp/platsmp.c
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/delay.h>
+#include <linux/device.h>
+#include <linux/smp.h>
+#include <linux/io.h>
+#include <linux/dma-mapping.h>
+
+#include <asm/cacheflush.h>
+#include <mach/hardware.h>
+#include <asm/mach-types.h>
+#include <asm/unified.h>
+
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "ctrlEnv/sys/mvCpuIf.h"
+
+extern void axp_secondary_startup(void);
+extern void second_cpu_init(void);
+extern void second_cpu_msi_init(void);
+extern MV_CPU_DEC_WIN* mv_sys_map(void);
+
+/*
+ * control for which core is the next to come out of the secondary
+ * boot "holding pen"
+ */
+volatile int __cpuinitdata pen_release = -1;
+
+static unsigned int __init get_core_count(void)
+{
+#ifdef CONFIG_MACH_ARMADA_XP_FPGA
+	return 2;
+#else
+	/* Read the number of availabe CPUs in the SoC */
+	return ((MV_REG_READ(SOC_COHERENCY_FABRIC_CFG_REG) & 0xF) + 1);
+#endif
+}
+
+static DEFINE_SPINLOCK(boot_lock);
+
+void __cpuinit platform_secondary_init(unsigned int cpu)
+{
+	trace_hardirqs_off();
+
+	/*
+	 * if any interrupts are already enabled for the primary
+	 * core (e.g. timer irq), then they will not have been enabled
+	 * for us: do so
+	 */
+	second_cpu_init();
+#ifdef CONFIG_PCI_MSI
+	/* Support for MSI interrupts */
+	second_cpu_msi_init();
+#endif
+	/*
+	 * let the primary processor know we're out of the
+	 * pen, then head off into the C entry point
+	 */
+	pen_release = -1;
+	smp_wmb();
+
+	/*
+	 * Synchronise with the boot thread.
+	 */
+	spin_lock(&boot_lock);
+	spin_unlock(&boot_lock);
+}
+
+int __cpuinit boot_secondary(unsigned int cpu, struct task_struct *idle)
+{
+	unsigned long timeout;
+
+	/*
+	 * set synchronisation state between this boot processor
+	 * and the secondary one
+	 */
+	spin_lock(&boot_lock);
+
+	/*
+	 * The secondary processor is waiting to be released from
+	 * the holding pen - release it, then wait for it to flag
+	 * that it has been released by resetting pen_release.
+	 *
+	 * Note that "pen_release" is the hardware CPU ID, whereas
+	 * "cpu" is Linux's internal ID.
+	 */
+	flush_cache_all();
+	pen_release = cpu;
+	flush_cache_all();
+	/* send ipi to wake cpu in case it in offline state */ 
+        smp_cross_call(cpumask_of(cpu));
+
+	timeout = jiffies + (10 * HZ);
+	while (time_before(jiffies, timeout)) {
+		smp_rmb();
+		if (pen_release == -1)
+			break;
+
+		dmac_map_area((const void *)&pen_release, 32, DMA_BIDIRECTIONAL);
+		udelay(10);
+	}
+
+	/*
+	 * now the secondary core is starting up let it run its
+	 * calibrations, then wait for it to finish
+	 */
+	spin_unlock(&boot_lock);
+
+	//printk("pen_release %d \n",pen_release);
+	return pen_release != -1 ? -ENOSYS : 0;
+}
+
+#define AXP_CPU_DIVCLK_CTRL0			0x18700
+#define AXP_CPU_DIVCLK_CTRL2_RATIO_FULL0	0x18708
+#define AXP_CPU_DIVCLK_CTRL2_RATIO_FULL1	0x1870C
+
+static void __init wakeup_cpus(void)
+{
+	MV_U32 val = 0;
+	MV_U32 ncores = get_core_count();
+#ifndef CONFIG_MACH_ARMADA_XP_FPGA
+	/* Scale up CPU#1 clock to max */
+	if (ncores > 1) {
+		val = MV_REG_READ(AXP_CPU_DIVCLK_CTRL2_RATIO_FULL0);
+		val &= ~(0xFF000000); 	/* cpu1 clkdiv ratio; cpu0 based on SAR */
+		val |= 0x1 << 24;
+		MV_REG_WRITE(AXP_CPU_DIVCLK_CTRL2_RATIO_FULL0, val);
+	}
+
+	/* Scale up CPU#2 clock to max */
+	if (ncores > 2) {
+		val = MV_REG_READ(AXP_CPU_DIVCLK_CTRL2_RATIO_FULL1);
+		val &= ~0x00FF0000;	/* cpus 2 clkdiv ratios */
+		val |= 0x1 << 16;
+		MV_REG_WRITE(AXP_CPU_DIVCLK_CTRL2_RATIO_FULL1, val);
+	}
+
+	/* Scale up CPU#3 clock to max */
+	if (ncores > 3) {
+		val = MV_REG_READ(AXP_CPU_DIVCLK_CTRL2_RATIO_FULL1);
+		val &= ~0xFF000000;	/* cpus 3 clkdiv ratios */
+		val |= 0x1 << 24;
+		MV_REG_WRITE(AXP_CPU_DIVCLK_CTRL2_RATIO_FULL1, val);
+	}
+
+	/* Set clock devider reload smooth bit mask */
+	val = MV_REG_READ(AXP_CPU_DIVCLK_CTRL0);
+	val |= ((0x1 << (ncores-1)) - 1) << 21;
+	MV_REG_WRITE(AXP_CPU_DIVCLK_CTRL0, val);
+
+	/* Request clock devider reload */
+	val = MV_REG_READ(AXP_CPU_DIVCLK_CTRL0);
+	val |= 1 << 24;
+	MV_REG_WRITE(AXP_CPU_DIVCLK_CTRL0, val);
+
+	/* Wait for clocks to settle down then release reload request */
+	udelay(100);
+	val &= ~(0xf << 21);
+	MV_REG_WRITE(AXP_CPU_DIVCLK_CTRL0, val);
+	udelay(100);
+#endif
+	/* Set resume control and address */
+	MV_REG_WRITE(AXP_CPU_RESUME_CTRL_REG, 0x0);
+	if (ncores > 1) MV_REG_WRITE(AXP_CPU_RESUME_ADDR_REG(1), virt_to_phys(axp_secondary_startup));
+	if (ncores > 2) MV_REG_WRITE(AXP_CPU_RESUME_ADDR_REG(2), virt_to_phys(axp_secondary_startup));
+	if (ncores > 3) MV_REG_WRITE(AXP_CPU_RESUME_ADDR_REG(3), virt_to_phys(axp_secondary_startup));
+
+	/* nobody is to be released from the pen yet */
+	pen_release = -1;
+
+	/* Kick secondary CPUs */
+	if (ncores > 1) MV_REG_WRITE(AXP_CPU_RESET_REG(1), 0x0);
+	if (ncores > 2)	MV_REG_WRITE(AXP_CPU_RESET_REG(2), 0x0);
+	if (ncores > 3) MV_REG_WRITE(AXP_CPU_RESET_REG(3), 0x0);
+
+	mb();
+	udelay(10);
+}
+
+static void __init initialize_bridge(void)
+{
+	MV_U32 reg;
+	MV_U32 ncores = get_core_count();
+
+	/* Associate all available CPUs to SMP group 0 */
+	reg = MV_REG_READ(SOC_COHERENCY_FABRIC_CFG_REG);
+	reg |= (((0x1 << ncores) - 1) << 24);
+	MV_REG_WRITE(SOC_COHERENCY_FABRIC_CFG_REG, reg);
+
+	/* enable CPUs in SMP group on Fabric coherency */
+	reg = MV_REG_READ(SOC_COHERENCY_FABRIC_CTRL_REG);
+	reg |= (((0x1 << ncores) - 1) << 24);
+	MV_REG_WRITE(SOC_COHERENCY_FABRIC_CTRL_REG, reg);
+}
+
+/*
+ * Initialise the CPU possible map early - this describes the CPUs
+ * which may be present or become present in the system.
+ */
+void __init smp_init_cpus(void)
+{
+	MV_U32 i;
+	MV_U32 ncores = get_core_count();
+
+	printk("SMP: init cpus\n");
+	/* Set CPU address decoding */
+	if( mvCpuIfInit(mv_sys_map())) {
+		printk( "Cpu Interface initialization failed.\n" );
+		return;
+	}
+	mvCpuIfAddDecShow();
+
+	for (i = 0; i < ncores; i++)
+		set_cpu_possible(i, true);
+}
+
+void __init smp_prepare_cpus(unsigned int max_cpus)
+{
+	unsigned int ncores = get_core_count();
+	unsigned int cpu = smp_processor_id();
+	int i;
+
+	printk("SMP: prepare CPUs (%d cores)\n", ncores);
+	/* sanity check */
+	if (ncores == 0) {
+		printk(KERN_ERR
+		       "strange CM count of 0? Default to 1\n");
+
+		ncores = 1;
+	}
+
+	if (ncores > NR_CPUS) {
+		printk(KERN_WARNING
+		       "no. of cores (%d) greater than configured "
+		       "maximum of %d - clipping\n",
+		       ncores, NR_CPUS);
+		ncores = NR_CPUS;
+	}
+
+	smp_store_cpu_info(cpu);
+
+	/*
+	 * are we trying to boot more cores than exist?
+	 */
+	if (max_cpus > ncores)
+		max_cpus = ncores;
+
+#ifdef CONFIG_LOCAL_TIMERS
+	/*
+	 * Enable the local timer for primary CPU. If the device is
+	 * dummy (!CONFIG_LOCAL_TIMERS), it was already registers in
+	 * aurora_time_init
+	 */
+//	local_timer_setup();
+#endif
+
+	/*
+	 * Initialise the present map, which describes the set of CPUs
+	 * actually populated at the present time.
+	 */
+	for (i = 0; i < max_cpus; i++)
+		set_cpu_present(i, true);
+
+	if (max_cpus > 1) {	
+		flush_cache_all();
+		wakeup_cpus();		
+	}
+	initialize_bridge();
+}
diff --git a/arch/arm/mach-armadaxp/pm.c b/arch/arm/mach-armadaxp/pm.c
new file mode 100644
index 0000000..8d3f63e
--- /dev/null
+++ b/arch/arm/mach-armadaxp/pm.c
@@ -0,0 +1,112 @@
+/*
+ * pm.c
+ *
+ * Power Management functions for Marvell Dove System On Chip
+ *
+ * Maintainer: Tawfik Bayouk <tawfik@marvell.com>
+ *
+ * This file is licensed under  the terms of the GNU General Public
+ * License version 2. This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+#include <linux/module.h>
+#include <linux/sysfs.h>
+#include <linux/proc_fs.h>
+#include <linux/interrupt.h>
+#include <linux/suspend.h>
+#include <linux/interrupt.h>
+
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+
+#ifdef CONFIG_SHEEVA_DEEP_IDLE
+extern void armadaxp_deepidle(void);
+/*
+ * Logical check for Dove valid PM states
+ */
+static int dove_pm_valid(suspend_state_t state)
+{
+	return (state == PM_SUSPEND_STANDBY);
+}
+
+/*
+ * Enter the requested PM state
+ */
+static int dove_pm_enter(suspend_state_t state)
+{
+	MV_U32	reg;
+
+	switch (state)	{
+	case PM_SUSPEND_STANDBY:
+		printk(KERN_INFO "Entering Wol Mode (Neta IRQs 8,10,12,14 are enabled now)...\n");
+
+		/* Reenable the NETA IRQ in order to wake from it */
+		reg = MV_REG_READ(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE0_FIC));
+		reg |= 0x1;
+		MV_REG_WRITE(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE0_FIC), reg);
+
+		reg = MV_REG_READ(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE1_FIC));
+		reg |= 0x1;
+		MV_REG_WRITE(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE1_FIC), reg);
+
+		reg = MV_REG_READ(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE2_FIC));
+		reg |= 0x1;
+		MV_REG_WRITE(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE2_FIC), reg);
+
+		reg = MV_REG_READ(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE3_FIC));
+		reg |= 0x1;
+		MV_REG_WRITE(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE3_FIC), reg);
+
+		armadaxp_deepidle();
+
+		/* Disable it since it will be re-enabled by the stack */
+		reg = MV_REG_READ(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE0_FIC));
+		reg &= ~0x1;
+		MV_REG_WRITE(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE0_FIC), reg);
+
+		reg = MV_REG_READ(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE1_FIC));
+		reg &= ~0x1;
+		MV_REG_WRITE(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE1_FIC), reg);
+
+		reg = MV_REG_READ(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE2_FIC));
+		reg &= ~0x1;
+		MV_REG_WRITE(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE2_FIC), reg);
+
+		reg = MV_REG_READ(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE3_FIC));
+		reg &= ~0x1;
+		MV_REG_WRITE(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_GBE3_FIC), reg);
+
+		printk(KERN_INFO "Exiting Wol Mode (Neta IRQs 8,10,12,14 are disabled now)...\n");
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static struct platform_suspend_ops dove_pm_ops = {
+	.valid		= dove_pm_valid,
+	.enter		= dove_pm_enter,
+};
+
+static int __init dove_pm_init(void)
+{
+	printk(KERN_INFO "ArmadaXP Power Managament Suspend Operations Initialized\n");
+	suspend_set_ops(&dove_pm_ops);
+	return 0;
+}
+
+__initcall(dove_pm_init);
+
+#else
+
+static int __init dove_pm_init(void)
+{
+	printk(KERN_INFO "ArmadaXP Power Managament NOT Initialized (Missing Deep-Idle Support)\n");
+	return 0;
+}
+
+__initcall(dove_pm_init);
+
+#endif /* CONFIG_SHEEVA_DEEP_IDLE */
diff --git a/arch/arm/mach-armadaxp/proc_aurora_dbg.c b/arch/arm/mach-armadaxp/proc_aurora_dbg.c
new file mode 100644
index 0000000..ed59c0a
--- /dev/null
+++ b/arch/arm/mach-armadaxp/proc_aurora_dbg.c
@@ -0,0 +1,88 @@
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <linux/device.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/sysdev.h>
+#include <linux/proc_fs.h>
+#include <linux/version.h> 
+ 
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/setup.h>
+#include <asm/mach-types.h>
+
+static struct proc_dir_entry *aurora_dbg;
+
+unsigned int aurora_core_index(void)
+{
+        unsigned int value;
+
+        __asm__ __volatile__("mrc p15, 0, %0, c0, c0, 5   @ read CPU ID reg\n"
+                : "=r" (value) :: "memory");
+        return (value & 0xF);
+}
+
+/********************************************************************/
+int aurora_dbg_read (char *buffer, char **buffer_location, off_t offset,
+                            int buffer_length, int *zero, void *ptr) {
+
+	char *p = buffer;
+  	unsigned int val, len;
+
+#ifdef CONFIG_SMP
+	p += sprintf(p,"CPU %d:\n", aurora_core_index());
+#endif
+	__asm volatile ("mrc  p15, 1, %0, c15, c1, 1" : "=r" (val));
+	p += sprintf(p, "c1, 1 %x \n", val);
+	__asm volatile ("mrc  p15, 1, %0, c15, c1, 2" : "=r" (val));
+	p += sprintf(p, "c1, 2 %x \n", val);
+	__asm volatile ("mrc  p15, 1, %0, c15, c2, 0" : "=r" (val));
+	p += sprintf(p, "c2, 0 %x \n", val);
+	__asm volatile ("mrc  p15, 1, %0, c15, c2, 1" : "=r" (val));
+	p += sprintf(p, "c2, 1 %x \n", val);
+	__asm volatile ("mrc  p15, 1, %0, c15, c1, 0" : "=r" (val));
+	p += sprintf(p, "c1, 0 %x \n", val);
+
+#ifdef CONFIG_PERF_EVENTS
+	__asm volatile ("mrc  p15, 0, %0, c9, c12, 0" : "=r" (val));
+	p += sprintf(p, "pmon ctrl %x \n", val);
+	__asm volatile ("mrc  p15, 0, %0, c9, c12, 1" : "=r" (val));
+	p += sprintf(p, "pmon cntrs en %x \n", val);
+	__asm volatile ("mrc  p15, 0, %0, c9, c12, 3" : "=r" (val));
+	p += sprintf(p, "pmon cntrs oflow %x \n", val);
+	__asm volatile ("mrc  p15, 0, %0, c9, c12, 5" : "=r" (val));
+	p += sprintf(p, "pmon cntr sel %x \n", val);
+	__asm volatile ("mrc  p15, 0, %0, c9, c13, 0" : "=r" (val));
+	p += sprintf(p, "pmon cycle cnt %x \n", val);
+	__asm volatile ("mrc  p15, 0, %0, c9, c13, 1" : "=r" (val));
+	p += sprintf(p, "pmon evt sel %x \n", val);
+	__asm volatile ("mrc  p15, 0, %0, c9, c13, 2" : "=r" (val));
+	p += sprintf(p, "pmon cntr val %x \n", val);
+	__asm volatile ("mrc  p15, 0, %0, c9, c14, 1" : "=r" (val));
+	p += sprintf(p, "pmon int en %x \n", val);
+#endif
+
+	len = (p - buffer);
+  	return len;
+}
+
+/********************************************************************/
+int __init start_aurora_dbg(void)
+{
+        aurora_dbg = create_proc_entry ("aurora_dbg" , 0666 , NULL);
+  	aurora_dbg->read_proc = aurora_dbg_read;
+  	aurora_dbg->write_proc = NULL;
+  	aurora_dbg->nlink = 1;
+	return 0;
+}
+void __exit stop_aurora_dbg(void)
+{
+        remove_proc_entry("aurora_dbg",  NULL);
+        return;
+}
+module_init(start_aurora_dbg);
+module_exit(stop_aurora_dbg);
+
diff --git a/arch/arm/mach-armadaxp/sysmap.c b/arch/arm/mach-armadaxp/sysmap.c
new file mode 100644
index 0000000..d4c0cfd
--- /dev/null
+++ b/arch/arm/mach-armadaxp/sysmap.c
@@ -0,0 +1,235 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+
+#include "mvSysHwConfig.h"
+#include "ctrlEnv/sys/mvCpuIf.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include <asm/mach/map.h>
+
+/* for putstr */
+/* #include <asm/arch/uncompress.h> */
+
+MV_CPU_DEC_WIN* mv_sys_map(void);
+
+#if defined(CONFIG_MV_INCLUDE_CESA)
+u32 mv_crypto_phys_base_get(u8 chan);
+u32 mv_crypto_virt_base_get(u8 chan);
+#endif
+
+struct map_desc  MEM_TABLE[] =	{
+	/* no use for pex mem remap */	
+	{ INTER_REGS_BASE,		__phys_to_pfn(INTER_REGS_PHYS_BASE),	SZ_1M,  	     	MT_DEVICE},
+	{ PEX0_IO_VIRT_BASE,   		__phys_to_pfn(PEX0_IO_PHYS_BASE),	PEX0_IO_SIZE,  		MT_DEVICE},
+	{ PEX1_IO_VIRT_BASE,   		__phys_to_pfn(PEX1_IO_PHYS_BASE),	PEX1_IO_SIZE,  		MT_DEVICE},
+	{ PEX2_IO_VIRT_BASE,   		__phys_to_pfn(PEX2_IO_PHYS_BASE),	PEX2_IO_SIZE,  		MT_DEVICE},
+	{ PEX3_IO_VIRT_BASE,   		__phys_to_pfn(PEX3_IO_PHYS_BASE),	PEX3_IO_SIZE,  		MT_DEVICE},
+	{ PEX4_IO_VIRT_BASE,   		__phys_to_pfn(PEX4_IO_PHYS_BASE),	PEX4_IO_SIZE,  		MT_DEVICE},
+	{ PEX5_IO_VIRT_BASE,   		__phys_to_pfn(PEX5_IO_PHYS_BASE),	PEX5_IO_SIZE,  		MT_DEVICE},
+	{ PEX6_IO_VIRT_BASE,   		__phys_to_pfn(PEX6_IO_PHYS_BASE),	PEX6_IO_SIZE,  		MT_DEVICE},
+	{ PEX7_IO_VIRT_BASE,   		__phys_to_pfn(PEX7_IO_PHYS_BASE),	PEX7_IO_SIZE,  		MT_DEVICE},
+	{ PEX8_IO_VIRT_BASE,   		__phys_to_pfn(PEX8_IO_PHYS_BASE),	PEX8_IO_SIZE,  		MT_DEVICE},
+	{ PEX9_IO_VIRT_BASE,   		__phys_to_pfn(PEX9_IO_PHYS_BASE),	PEX9_IO_SIZE,  		MT_DEVICE},
+#ifdef MV_INCLUDE_LEGACY_NAND
+	{ LEGACY_NAND_VIRT_BASE,	__phys_to_pfn(LEGACY_NAND_PHYS_BASE),	LEGACY_NAND_SIZE, 	MT_DEVICE},
+#endif
+	{ SPI_CS0_VIRT_BASE,		__phys_to_pfn(SPI_CS0_PHYS_BASE),	SPI_CS0_SIZE,		MT_DEVICE},
+	{ CRYPT_ENG_VIRT_BASE(0),	__phys_to_pfn(CRYPT_ENG_PHYS_BASE(0)),	CRYPT_ENG_SIZE,		MT_DEVICE},
+#if (CONFIG_MV_CESA_CHANNELS > 1)
+	{ CRYPT_ENG_VIRT_BASE(1),	__phys_to_pfn(CRYPT_ENG_PHYS_BASE(1)),	CRYPT_ENG_SIZE,		MT_DEVICE},
+#endif
+#ifdef CONFIG_MV_ETH_BM
+	{ PNC_BM_VIRT_BASE,		__phys_to_pfn(PNC_BM_PHYS_BASE),	PNC_BM_SIZE,		MT_DEVICE}
+#endif
+};
+
+MV_CPU_DEC_WIN SYSMAP_ARMADA_XP[] = {
+	/* base low       	     base high        size       		WinNum     	enable */
+	{{SDRAM_CS0_BASE,			0,	SDRAM_CS0_SIZE		},	0xFFFFFFFF,	DIS},	/* SDRAM_CS0 */
+	{{SDRAM_CS1_BASE,			0,	SDRAM_CS1_SIZE		},	0xFFFFFFFF,	DIS},	/* SDRAM_CS1 */
+	{{SDRAM_CS2_BASE,			0,	SDRAM_CS2_SIZE		},	0xFFFFFFFF,	DIS},	/* SDRAM_CS2 */
+	{{SDRAM_CS3_BASE,			0,	SDRAM_CS3_SIZE		},	0xFFFFFFFF,	DIS},	/* SDRAM_CS3 */
+	{{DEVICE_CS0_PHYS_BASE,		0,	DEVICE_CS0_SIZE,	},	0x8,		EN},	/* DEVICE_CS0 */
+	{{DEVICE_CS1_PHYS_BASE,		0,	DEVICE_CS1_SIZE,	},	TBL_UNUSED,	DIS},	/* DEVICE_CS1 */
+	{{DEVICE_CS2_PHYS_BASE,		0,	DEVICE_CS2_SIZE,	},	TBL_UNUSED,	DIS},	/* DEVICE_CS2 */
+	{{DEVICE_CS3_PHYS_BASE,		0,	DEVICE_CS3_SIZE,	},	TBL_UNUSED,	DIS},	/* DEVICE_CS3 */
+	{{PEX0_MEM_PHYS_BASE,		0,	PEX0_MEM_SIZE		},	0x0,		EN},	/* PEX0_MEM */
+	{{PEX0_IO_PHYS_BASE,		0,	PEX0_IO_SIZE		},	TBL_UNUSED,	DIS},	/* PEX0_IO */
+	{{PEX1_MEM_PHYS_BASE,		0,	PEX1_MEM_SIZE		},	0x1,		EN},	/* PEX1_MEM */
+	{{PEX1_IO_PHYS_BASE,		0,	PEX1_IO_SIZE		},	TBL_UNUSED,	DIS},	/* PEX1_IO */
+	{{PEX2_MEM_PHYS_BASE,		0,	PEX2_MEM_SIZE		},	0x2,		EN},	/* PEX2_MEM */
+	{{PEX2_IO_PHYS_BASE,		0,	PEX2_IO_SIZE		},	TBL_UNUSED,	DIS},	/* PEX2_IO */
+	{{PEX3_MEM_PHYS_BASE,		0,	PEX3_MEM_SIZE		},	0x3,		EN},	/* PEX3_MEM */
+	{{PEX3_IO_PHYS_BASE,		0,	PEX3_IO_SIZE		},	TBL_UNUSED,	DIS},	/* PEX3_IO */
+	{{PEX4_MEM_PHYS_BASE,		0,	PEX4_MEM_SIZE		},	0x4,		EN},	/* PEX4_MEM */
+	{{PEX4_IO_PHYS_BASE,		0,	PEX4_IO_SIZE		},	TBL_UNUSED,	DIS},	/* PEX4_IO */
+	{{PEX5_MEM_PHYS_BASE,		0,	PEX5_MEM_SIZE		},	TBL_UNUSED,	DIS},	/* PEX5_MEM */
+	{{PEX5_IO_PHYS_BASE,		0,	PEX5_IO_SIZE		},	TBL_UNUSED,	DIS},	/* PEX5_IO */
+	{{PEX6_MEM_PHYS_BASE,		0,	PEX6_MEM_SIZE		},	0x5,		EN},	/* PEX6_MEM */
+	{{PEX6_IO_PHYS_BASE,		0,	PEX6_IO_SIZE		},	TBL_UNUSED,	DIS},	/* PEX6_IO */
+	{{PEX7_MEM_PHYS_BASE,		0,	PEX7_MEM_SIZE		},	TBL_UNUSED,	DIS},	/* PEX7_MEM */
+	{{PEX7_IO_PHYS_BASE,		0,	PEX7_IO_SIZE		},	TBL_UNUSED,	DIS},	/* PEX7_IO */
+	{{PEX8_MEM_PHYS_BASE,		0,	PEX8_MEM_SIZE		},	0x6,		EN},	/* PEX8_MEM */
+	{{PEX8_IO_PHYS_BASE,		0,	PEX8_IO_SIZE		},	TBL_UNUSED,	DIS},	/* PEX8_IO */
+	{{PEX9_MEM_PHYS_BASE,		0,	PEX9_MEM_SIZE		},	0x7,		EN},	/* PEX9_MEM */
+	{{PEX9_IO_PHYS_BASE,		0,	PEX9_IO_SIZE		},	TBL_UNUSED,	DIS},	/* PEX9_IO */
+	{{INTER_REGS_PHYS_BASE,		0,	INTER_REGS_SIZE		},	0x14,		EN},	/* INTER_REGS */
+	{{UART_REGS_BASE,			0,	UART_SIZE			},	TBL_UNUSED,	DIS},	/* DMA_UART */
+	{{SPI_CS0_PHYS_BASE,		0,	SPI_CS0_SIZE		},	0xe,		EN},	/* SPI_CS0 */
+	{{TBL_UNUSED,				0,	TBL_UNUSED,			},	TBL_UNUSED,	DIS},	/* SPI_CS1 */
+	{{TBL_UNUSED,				0,	TBL_UNUSED,			},	TBL_UNUSED,	DIS},	/* SPI_CS2 */
+	{{TBL_UNUSED,				0,	TBL_UNUSED,			},	TBL_UNUSED,	DIS},	/* SPI_CS3 */
+	{{TBL_UNUSED,				0,	TBL_UNUSED,			},	TBL_UNUSED,	DIS},	/* SPI_CS4 */
+	{{TBL_UNUSED,				0,	TBL_UNUSED,			},	TBL_UNUSED,	DIS},	/* SPI_CS5 */
+	{{TBL_UNUSED,				0,	TBL_UNUSED,			},	TBL_UNUSED,	DIS},	/* SPI_CS6 */
+	{{TBL_UNUSED,				0,	TBL_UNUSED,			},	TBL_UNUSED,	DIS},	/* SPI_CS7 */
+	{{BOOTROM_PHYS_BASE,		0,	BOOTROM_SIZE		},	0x9,		EN},	/* BOOTROM */
+	{{DEVICE_BOOTCS_PHYS_BASE,	0,	DEVICE_BOOTCS_SIZE	},	0xa,		EN},	/* DEV_BOOCS */
+	{{PMU_SCRATCH_PHYS_BASE,	0,	PMU_SCRATCH_SIZE	},	TBL_UNUSED,	DIS},	/* PMU SCRATCHPAD */
+	{{CRYPT_ENG_PHYS_BASE(0),	0,	CRYPT_ENG_SIZE		},	0xb,		EN},	/* CRYPT0_ENG */
+	{{CRYPT_ENG_PHYS_BASE(1),	0,	CRYPT_ENG_SIZE		},	0xc,		EN},	/* CRYPT1_ENG */
+	{{PNC_BM_PHYS_BASE,			0,	PNC_BM_SIZE			},	0xd,		EN},	/* PNC_BM */
+	{{TBL_TERM,					TBL_TERM, TBL_TERM		},	TBL_TERM,	TBL_TERM}
+};
+
+
+MV_CPU_DEC_WIN* mv_sys_map(void)
+{
+	return SYSMAP_ARMADA_XP;
+}
+
+
+#if defined(CONFIG_MV_INCLUDE_CESA)
+u32 mv_crypto_phys_base_get(u8 chan)
+{
+	return CRYPT_ENG_PHYS_BASE(chan);
+}
+u32 mv_crypto_virt_base_get(u8 chan)
+{
+	return CRYPT_ENG_VIRT_BASE(chan);
+}
+#endif
+
+void __init axp_map_io(void)
+{
+        iotable_init(MEM_TABLE, ARRAY_SIZE(MEM_TABLE));
+}
+
+static u32 mv_pci_mem_base[] = 
+{
+	PEX0_MEM_PHYS_BASE,
+	PEX1_MEM_PHYS_BASE,
+	PEX2_MEM_PHYS_BASE,
+	PEX3_MEM_PHYS_BASE,
+	PEX4_MEM_PHYS_BASE,
+	PEX5_MEM_PHYS_BASE,
+	PEX6_MEM_PHYS_BASE,
+	PEX7_MEM_PHYS_BASE,
+	PEX8_MEM_PHYS_BASE,
+	PEX9_MEM_PHYS_BASE,
+};
+
+static u32 mv_pci_mem_size[] = 
+{
+	PEX0_MEM_SIZE,
+	PEX1_MEM_SIZE,
+	PEX2_MEM_SIZE,
+	PEX3_MEM_SIZE,
+	PEX4_MEM_SIZE,
+	PEX5_MEM_SIZE,
+	PEX6_MEM_SIZE,
+	PEX7_MEM_SIZE,
+	PEX8_MEM_SIZE,
+	PEX9_MEM_SIZE,
+};
+
+static u32 mv_pci_io_base[] = 
+{
+	PEX0_IO_PHYS_BASE,
+	PEX1_IO_PHYS_BASE,
+	PEX2_IO_PHYS_BASE,
+	PEX3_IO_PHYS_BASE,
+	PEX4_IO_PHYS_BASE,
+	PEX5_IO_PHYS_BASE,
+	PEX6_IO_PHYS_BASE,
+	PEX7_IO_PHYS_BASE,
+	PEX8_IO_PHYS_BASE,
+	PEX9_IO_PHYS_BASE
+};
+
+static u32 mv_pci_io_size[] = 
+{
+	PEX0_IO_SIZE,
+	PEX1_IO_SIZE,
+	PEX2_IO_SIZE,
+	PEX3_IO_SIZE,
+	PEX4_IO_SIZE,
+	PEX5_IO_SIZE,
+	PEX6_IO_SIZE,
+	PEX7_IO_SIZE,
+	PEX8_IO_SIZE,
+	PEX9_IO_SIZE,
+};
+
+static MV_TARGET mv_pci_io_target[] = 
+{
+	PEX0_IO,
+	PEX1_IO,
+	PEX2_IO,
+	PEX3_IO,
+	PEX4_IO,
+	PEX5_IO,
+	PEX6_IO,
+	PEX7_IO,
+	PEX8_IO,
+	PEX9_IO,
+};
+
+u32 mv_pci_mem_base_get(int ifNum)
+{
+	return mv_pci_mem_base[ifNum];
+}
+
+u32 mv_pci_mem_size_get(int ifNum)
+{
+	return mv_pci_mem_size[ifNum];
+}
+
+u32 mv_pci_io_base_get(int ifNum)
+{
+	return mv_pci_io_base[ifNum];
+}
+
+u32 mv_pci_io_size_get(int ifNum)
+{
+	return mv_pci_io_size[ifNum];
+}
+
+MV_TARGET mv_pci_io_target_get(int ifNum)
+{
+	return mv_pci_io_target[ifNum];
+}
+
+int mv_is_pci_io_mapped(int ifNum)
+{
+	/* FIXME: First 8 address decode windows are statically assigned
+	   for 8 PCIE mem BARs.
+	   This is disabled as long that no more windows are available for
+	   I/O BARs
+	*/
+	    
+	return 0;
+}
diff --git a/arch/arm/mach-armadaxp/time.c b/arch/arm/mach-armadaxp/time.c
new file mode 100644
index 0000000..53c1f7d
--- /dev/null
+++ b/arch/arm/mach-armadaxp/time.c
@@ -0,0 +1,344 @@
+/*
+ * arch/arm/mach-armadaxp/time.c
+ *
+ * Marvell Aurora SoC timer handling.
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ *
+ * Timer 0 is used as free-running clocksource, while timer 1 is
+ * used as clock_event_device.
+ */
+
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/timer.h>
+#include <linux/clockchips.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <asm/mach/time.h>
+#include <mach/hardware.h>
+#include <asm/localtimer.h>
+#include <asm/sched_clock.h>
+
+#include "boardEnv/mvBoardEnvLib.h"
+#include "cpu/mvCpu.h"
+
+#ifdef CONFIG_SMP
+static DEFINE_PER_CPU(struct clock_event_device, local_clockevent);
+#endif
+
+extern void axp_irq_mask(struct irq_data *d);
+extern void axp_irq_unmask(struct irq_data *d);
+
+#define   TIMER_CTRL		(MV_CNTMR_REGS_OFFSET + 0x0000)
+#define    TIMER0_EN		0x0001
+#define    TIMER0_RELOAD_EN	0x0002
+#define    TIMER1_EN		0x0004
+#define    TIMER1_RELOAD_EN	0x0008
+#define  TIMER0_RELOAD		(MV_CNTMR_REGS_OFFSET + 0x0010)
+#define  TIMER0_VAL		(MV_CNTMR_REGS_OFFSET + 0x0014)
+#define  TIMER1_RELOAD		(MV_CNTMR_REGS_OFFSET + 0x0018)
+#define  TIMER1_VAL		(MV_CNTMR_REGS_OFFSET + 0x001c)
+#define  TIMER_WD_RELOAD	(MV_CNTMR_REGS_OFFSET + 0x0020)
+#define  TIMER_WD_VAL		(MV_CNTMR_REGS_OFFSET + 0x0024)
+#define  TIMER_CAUSE		(MV_CNTMR_REGS_OFFSET + 0x0028)
+#define   INT_TIMER0_CLR 	~(1 << 0)
+#define   INT_TIMER1_CLR 	~(1 << 8)
+
+#define  LCL_TIMER_BASE		(0x21000 | 0x40)
+#define  LCL_TIMER_CTRL		(LCL_TIMER_BASE + 0x0000)
+#define    LCL_TIMER0_EN		0x0001
+#define    LCL_TIMER0_RELOAD_EN		0x0002
+#define    LCL_TIMER1_EN		0x0004
+#define    LCL_TIMER1_RELOAD_EN		0x0008
+#define  LCL_TIMER0_RELOAD	(LCL_TIMER_BASE + 0x0010)
+#define  LCL_TIMER0_VAL		(LCL_TIMER_BASE + 0x0014)
+#define  LCL_TIMER1_RELOAD	(LCL_TIMER_BASE + 0x0018)
+#define  LCL_TIMER1_VAL		(LCL_TIMER_BASE + 0x001c)
+#define  LCL_TIMER_WD_RELOAD	(LCL_TIMER_BASE + 0x0020)
+#define  LCL_TIMER_WD_VAL	(LCL_TIMER_BASE + 0x0024)
+#define  LCL_TIMER_CAUSE	(LCL_TIMER_BASE + 0x0028)
+#define   LCL_INT_TIMER0_CLR 	~(1 << 0)
+#define   LCL_INT_TIMER1_CLR	~(1 << 8)
+
+#define BRIDGE_CAUSE		(MV_MBUS_REGS_OFFSET | 0x0260)
+#define BRIDGE_INT_TIMER0	(1 << 24)
+#define BRIDGE_INT_TIMER1	(1 << 25)
+#define BRIDGE_MASK		(MV_MBUS_REGS_OFFSET | 0x10c4)
+
+/*
+ * Number of timer ticks per jiffy.
+ */
+static u32 ticks_per_jiffy;
+
+
+static DEFINE_CLOCK_DATA(cd);
+
+
+
+unsigned long long notrace sched_clock(void)
+{
+	u32 cyc = ~MV_REG_READ(TIMER0_VAL);
+	return cyc_to_sched_clock(&cd, cyc, (u32)~0);
+}
+
+static void notrace axp_update_sched_clock(void)
+{
+	u32 cyc = ~MV_REG_READ(TIMER0_VAL);
+	update_sched_clock(&cd, cyc, (u32)~0);
+}
+
+static void __init setup_sched_clock(unsigned long tclk)
+{
+	init_sched_clock(&cd, axp_update_sched_clock, 32, tclk);
+}
+
+
+
+/*
+ * Clocksource handling.
+ */
+static cycle_t axp_clksrc_read(struct clocksource *cs)
+{
+	return (0xffffffff - MV_REG_READ(TIMER0_VAL));
+}
+
+static struct clocksource axp_clksrc = {
+	.name		= "axp_clocksource",
+	.shift		= 20,
+	.rating		= 300,
+	.read		= axp_clksrc_read,
+	.mask		= CLOCKSOURCE_MASK(32),
+	.flags		= CLOCK_SOURCE_IS_CONTINUOUS,
+};
+
+
+/*
+ * Clockevent handling.
+ */
+int axp_clkevt_next_event(unsigned long delta, struct clock_event_device *dev)
+{
+	unsigned long flags;
+	u32 u;
+
+	if (delta == 0)
+		return -ETIME;	
+
+	local_irq_save(flags);
+
+	/* Clear and enable clockevent timer interrupt */
+	MV_REG_WRITE(LCL_TIMER_CAUSE, LCL_INT_TIMER0_CLR);
+	/*axp_irq_unmask(IRQ_LOCALTIMER);*/
+	axp_irq_unmask(irq_get_irq_data(IRQ_LOCALTIMER));
+
+	/* Setup new clockevent timer value */
+	MV_REG_WRITE(LCL_TIMER0_VAL, delta);
+
+
+	/* Enable the timer */
+	u = MV_REG_READ(LCL_TIMER_CTRL);
+	u = (u & ~LCL_TIMER0_RELOAD_EN) | LCL_TIMER0_EN;
+	MV_REG_WRITE(LCL_TIMER_CTRL, u);
+
+	local_irq_restore(flags);
+
+	return 0;
+}
+
+static void axp_clkevt_mode(enum clock_event_mode mode, struct clock_event_device *dev)
+{
+	unsigned long flags;
+	u32 u;
+
+	local_irq_save(flags);
+
+	if (mode == CLOCK_EVT_MODE_PERIODIC) {
+		/* Setup timer to fire at 1/HZ intervals */
+		MV_REG_WRITE(LCL_TIMER0_RELOAD, (ticks_per_jiffy - 1));
+		MV_REG_WRITE(LCL_TIMER0_VAL, (ticks_per_jiffy - 1));
+
+
+		/* Enable timer interrupt */
+		/*axp_irq_unmask(IRQ_LOCALTIMER);*/
+		axp_irq_unmask(irq_get_irq_data(IRQ_LOCALTIMER));
+
+
+		/* Enable timer */
+		u = MV_REG_READ(LCL_TIMER_CTRL);
+		u |= (LCL_TIMER0_EN | LCL_TIMER0_RELOAD_EN);
+		MV_REG_WRITE(LCL_TIMER_CTRL, u);
+	} else {
+		/* Disable timer */
+		u = MV_REG_READ(LCL_TIMER_CTRL);
+		u &= ~LCL_TIMER0_EN;
+		MV_REG_WRITE(LCL_TIMER_CTRL, u);
+
+		/* Disable timer interrupt */
+		//axp_irq_mask(IRQ_LOCALTIMER);
+		axp_irq_mask(irq_get_irq_data(IRQ_LOCALTIMER));
+
+
+		/* ACK pending timer interrupt */
+		MV_REG_WRITE(LCL_TIMER_CAUSE, LCL_INT_TIMER0_CLR);
+	}
+
+
+	local_irq_restore(flags);
+}
+
+static struct clock_event_device axp_clkevt;
+static irqreturn_t axp_timer_interrupt(int irq, void *dev_id)
+{
+	/* ACK timer interrupt and call event handler */
+	MV_REG_WRITE(LCL_TIMER_CAUSE, LCL_INT_TIMER0_CLR);
+	axp_clkevt.event_handler(&axp_clkevt);
+
+	return IRQ_HANDLED;
+}
+
+static struct irqaction axp_timer_irq = {
+	.name		= "axp_tick",
+	.flags		= IRQF_DISABLED | IRQF_TIMER,
+	.handler	= axp_timer_interrupt
+};
+
+
+/*
+ * Setup the local clock events for a CPU.
+ */
+void __cpuinit mv_timer_setup(struct clock_event_device *clk, unsigned int fabric_clk)
+{
+	unsigned int cpu = smp_processor_id();
+
+	clk->features		= (CLOCK_EVT_FEAT_ONESHOT | CLOCK_EVT_FEAT_PERIODIC),
+	clk->shift		= 32,
+	clk->rating		= 300,
+	clk->set_next_event	= axp_clkevt_next_event,
+	clk->set_mode		= axp_clkevt_mode,
+	clk->cpumask		= cpumask_of(cpu);
+	clk->mult		= div_sc(fabric_clk, NSEC_PER_SEC, clk->shift);
+	clk->max_delta_ns	= clockevent_delta2ns(0xffffffff, clk);
+	clk->min_delta_ns	= clockevent_delta2ns(0x1, clk);
+}
+
+void __init axp_time_init(unsigned int fabric_clk)
+{
+	u32 u;
+
+	printk("Initializing ArmadaXP Timer\n");
+
+	ticks_per_jiffy = (fabric_clk + HZ/2) / HZ;
+	
+	setup_sched_clock(fabric_clk);
+
+	/* Setup free-running clocksource timer (interrupts disabled) */
+	MV_REG_WRITE(TIMER0_VAL, 0xffffffff);
+	MV_REG_WRITE(TIMER0_RELOAD, 0xffffffff);
+	u = MV_REG_READ(BRIDGE_MASK);
+	u &= ~BRIDGE_INT_TIMER0;
+	MV_REG_WRITE(BRIDGE_MASK, u);
+	u = MV_REG_READ(TIMER_CTRL);
+	u |= (TIMER0_EN | TIMER0_RELOAD_EN);
+	MV_REG_WRITE(TIMER_CTRL, u);
+	axp_clksrc.mult = clocksource_hz2mult(fabric_clk, axp_clksrc.shift);
+	clocksource_register(&axp_clksrc);
+
+#ifdef CONFIG_SMP
+	{
+		percpu_timer_setup();
+	        return;
+	}
+#endif
+	/* Setup clockevent timer (interrupt-driven) */
+	axp_clkevt.name = "axp_tick";
+	axp_clkevt.irq = IRQ_LOCALTIMER;
+	mv_timer_setup(&axp_clkevt, fabric_clk);
+	setup_irq(IRQ_LOCALTIMER, &axp_timer_irq);
+	clockevents_register_device(&axp_clkevt);
+}
+
+static void axp_timer_init(void)
+{
+#ifdef CONFIG_MACH_ARMADA_XP_FPGA
+	axp_time_init(25000000);
+#else
+	axp_time_init(mvCpuL2ClkGet());
+#endif
+}
+
+struct sys_timer axp_timer = {
+	.init = axp_timer_init,
+};
+
+
+#if defined (CONFIG_SMP) && defined (CONFIG_LOCAL_TIMERS)
+/*
+ * Used on SMP for either the local timer or IPI_TIMER
+ */
+void local_timer_interrupt(void)
+{
+	struct clock_event_device *clk = &__get_cpu_var(local_clockevent);
+
+	printk("local_timer_interrupt\n");
+	clk->event_handler(clk);
+}
+
+/*
+ * local_timer_ack: checks for a local timer interrupt.
+ *
+ * If a local timer interrupt has occurred, acknowledge and return 1.
+ * Otherwise, return 0.
+ */
+int local_timer_ack(void)
+{
+	if(MV_REG_READ(LCL_TIMER_CAUSE) & ~LCL_INT_TIMER0_CLR) {
+		MV_REG_WRITE(LCL_TIMER_CAUSE, LCL_INT_TIMER0_CLR);
+		return 1;
+	}
+	return 0;
+}
+
+/*
+ * Setup the local clock events for a CPU.
+ */
+void __cpuinit local_timer_setup(struct clock_event_device *clk)
+{
+#ifdef CONFIG_MACH_ARMADA_XP_FPGA
+	unsigned int fabric_clk = 25000000;
+#else
+	unsigned int fabric_clk = mvCpuL2ClkGet();
+#endif
+
+	ticks_per_jiffy = (fabric_clk + HZ/2) / HZ;
+	clk->name = "local_timer";
+	clk->irq = IRQ_LOCALTIMER;
+	mv_timer_setup(clk, fabric_clk);
+	clockevents_register_device(clk);
+}
+
+#ifdef CONFIG_HOTPLUG_CPU
+/*
+ * take a local timer down
+ */
+void __cpuexit local_timer_stop(void)
+{
+	unsigned long flags;
+	u32 u;
+
+	local_irq_save(flags);
+
+	/* Disable timer */
+	u = MV_REG_READ(LCL_TIMER_CTRL);
+	u &= ~LCL_TIMER0_EN;
+	MV_REG_WRITE(LCL_TIMER_CTRL, u);
+	MV_REG_WRITE(LCL_TIMER_CAUSE, LCL_INT_TIMER0_CLR);
+	/* Disable timer interrupt */
+	/*axp_irq_mask(IRQ_LOCALTIMER);*/
+	axp_irq_mask(irq_get_irq_data(IRQ_LOCALTIMER));
+
+	local_irq_restore(flags);
+}
+#endif
+#endif	/* CONFIG_LOCAL_TIMERS && CONFIG_SMP */
diff --git a/arch/arm/mach-armadaxp/usb.c b/arch/arm/mach-armadaxp/usb.c
new file mode 100644
index 0000000..55a4eea
--- /dev/null
+++ b/arch/arm/mach-armadaxp/usb.c
@@ -0,0 +1,161 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+//#include <linux/autoconf.h>
+#include <linux/kernel.h>
+#include <linux/pci.h>
+#include <linux/ptrace.h>
+#include <linux/slab.h>
+#include <linux/ioport.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/init.h>
+#include <linux/platform_device.h>
+                                                                                                                             
+#include <asm/io.h>
+#include <asm/irq.h>
+
+#include "mvCommon.h"
+#include "mvDebug.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "mvSysUsbApi.h"
+#include "usb/mvUsbRegs.h"
+#include "usb/mvUsb.h"
+
+u32 mvIsUsbHost = 0x03;
+
+#define MV_USB_DMA_MASK		0xffffffff
+#define MAX_USB_PORTS		3
+
+static char usb_dev_name[]  = "mv_udc";
+static char usb_host_name[] = "ehci_marvell";
+static char usb_bus_name[]  = "platform";
+
+
+static void mv_usb_release(struct device *dev)
+{
+    struct platform_device  *pdev = to_platform_device(dev); 
+
+    /* normally not freed */
+    printk("mv_usb_release\n");
+
+    kfree(pdev->resource);
+    kfree(pdev->dev.dma_mask);
+    kfree(pdev);
+} 
+
+
+static int __init   mv_usb_init(void)
+{
+	int                     status, dev, num, isHost;
+	char*                   name_ptr;
+	struct platform_device* mv_usb_dev_ptr;
+	int 			irq_num[3] = {	IRQ_AURORA_USB0,
+						IRQ_AURORA_USB1,
+						IRQ_AURORA_USB2};
+
+	num = mvCtrlUsbMaxGet(); 
+	if (num > MAX_USB_PORTS) {
+		printk("WARNING: Limited USB ports number to %d\n", MAX_USB_PORTS);
+		num = MAX_USB_PORTS;
+	}
+
+	for(dev=0; dev<num; dev++)
+	{
+		if (MV_FALSE == mvCtrlPwrClckGet(USB_UNIT_ID, dev))
+		{
+			printk("\nWarning Integrated USB %d is Powered Off\n",dev);
+			continue;	    
+		}
+
+		isHost = mvIsUsbHost & (1 << dev);
+
+		if(isHost)
+			name_ptr = usb_host_name;
+		else
+			name_ptr = usb_dev_name;
+
+		printk("registered dev#%d asa %s\n",dev,name_ptr);
+		status = mvSysUsbInit(dev, isHost);
+
+		mv_usb_dev_ptr = kmalloc(sizeof(struct platform_device), GFP_KERNEL);
+		if(mv_usb_dev_ptr == NULL)
+		{
+			printk("Can't allocate platform_device structure - %d bytes\n",
+					sizeof(struct platform_device) );
+			return 1;
+		}
+		memset(mv_usb_dev_ptr, 0, sizeof(struct platform_device) );
+
+		mv_usb_dev_ptr->name               = name_ptr;
+		mv_usb_dev_ptr->id                 = dev;
+
+		mv_usb_dev_ptr->num_resources  = 2;
+
+		mv_usb_dev_ptr->resource = (struct resource*)kmalloc(2*sizeof(struct resource), GFP_KERNEL);
+		if(mv_usb_dev_ptr->resource == NULL)
+		{
+			printk("Can't allocate 2 resource structure - %d bytes\n",
+					2*sizeof(struct resource) );
+			kfree(mv_usb_dev_ptr);
+			return 1;
+		}
+		memset(mv_usb_dev_ptr->resource, 0, 2*sizeof(struct resource));
+
+		mv_usb_dev_ptr->resource[0].start =
+			( INTER_REGS_BASE | MV_USB_CORE_CAP_LENGTH_REG(dev));
+		mv_usb_dev_ptr->resource[0].end   =
+			((INTER_REGS_BASE | MV_USB_CORE_CAP_LENGTH_REG(dev)) + 4096);
+		mv_usb_dev_ptr->resource[0].flags = IORESOURCE_DMA;
+
+		mv_usb_dev_ptr->resource[1].start = irq_num[dev];
+		mv_usb_dev_ptr->resource[1].flags = IORESOURCE_IRQ;
+
+		mv_usb_dev_ptr->dev.dma_mask           = kmalloc(sizeof(u64), GFP_KERNEL);
+		*mv_usb_dev_ptr->dev.dma_mask          = MV_USB_DMA_MASK;
+
+		mv_usb_dev_ptr->dev.coherent_dma_mask  = ~0;
+		mv_usb_dev_ptr->dev.release            = mv_usb_release;
+		dev_set_name(&mv_usb_dev_ptr->dev, "%s", usb_bus_name);
+
+		printk("Marvell USB %s controller #%d: %p\n",
+				isHost ? "EHCI Host" : "Gadget", dev, mv_usb_dev_ptr);
+
+		status = platform_device_register(mv_usb_dev_ptr);
+		if (status)
+		{
+			printk("Can't register Marvell USB EHCI controller #%d, status=%d\n", 
+					dev, status);
+			return status;
+		}
+	}
+	return 0;
+}
+
+subsys_initcall(mv_usb_init);
+
diff --git a/arch/arm/mm/Kconfig b/arch/arm/mm/Kconfig
index afede57..fd25eef 100644
--- a/arch/arm/mm/Kconfig
+++ b/arch/arm/mm/Kconfig
@@ -153,13 +153,13 @@ config CPU_ARM925T
 	select CPU_CP15_MMU
 	select CPU_COPY_V4WB if MMU
 	select CPU_TLB_V4WBI if MMU
- 	help
- 	  The ARM925T is a mix between the ARM920T and ARM926T, but with
+	help
+	  The ARM925T is a mix between the ARM920T and ARM926T, but with
 	  different instruction and data caches. It is used in TI's OMAP
- 	  device family.
+	  device family.
 
- 	  Say Y if you want support for the ARM925T processor.
- 	  Otherwise, say N.
+	  Say Y if you want support for the ARM925T processor.
+	  Otherwise, say N.
 
 # ARM926T
 config CPU_ARM926T
@@ -397,7 +397,7 @@ config CPU_SHEEVA_PJ4B_V7
 	select CPU_V7
 
 endchoice
-	  
+
 # Marvell PJ4
 config CPU_PJ4
 	bool
@@ -740,7 +740,7 @@ config BE8_ON_LE
 	select CPU_BIG_ENDIAN
 	help
 	  Run BE8 kernel on a little endian machine.
-	  
+
 config CPU_HIGH_VECTOR
 	depends on !MMU && CPU_CP15 && !CPU_ARM740T
 	bool "Select the High exception vector"
@@ -865,6 +865,184 @@ config CACHE_FEROCEON_L2_WRITETHROUGH
 	  Say Y here to use the Feroceon L2 cache in writethrough mode.
 	  Unless you specifically require this, say N for writeback mode.
 
+config SHEEVA_ERRATA_ARM_CPU_4742
+	bool "Sheeva Errata 4742: Enable sync barriers after WFI idle"
+	depends on CPU_SHEEVA_PJ4B_V6 || CPU_SHEEVA_PJ4B_V7
+	help
+	  When coming out of WFI IDLE state, a specific timing sensitivity exists
+	  between the retiring WFI instruction and the newly issued subsequent
+	  instructions. This sensitivity can result in a CPU hang scenario.
+	  WA: The software must insert either a Data Synchronization Barrier (DSB)
+	  or Data Memory Barrier (DMB) command immediately after the WFI instruction.
+
+config SHEEVA_ERRATA_ARM_CPU_4786
+	bool "Sheeva Errata 4786: Disable coprocessor dual issue mode"
+	depends on (CPU_SHEEVA_PJ4B_V6 || CPU_SHEEVA_PJ4B_V7) && ARM_THUMB && VFP
+	help
+	  If the last instruction inside a Thumb IT block is a branch, and the
+	  following instruction is a VFP instruction, the logic may incorrectly
+	  dual-issue the VFP instruction along with the branch instruction. This
+	  causes the VFP instruction to be executed, even though the branch
+	  instruction may be taken.
+	  WA: Set the CP15 coprocessor dual-issue disable bit in the Auxiliary
+	  Debug Modes Control 0 register (bit[15]). This setting disables the
+	  dual-issuing of VFP instructions before entering an IT block.
+
+config SHEEVA_ERRATA_ARM_CPU_5315
+	bool "Sheeva Errata 5315: Disable Data Speculative prefetch from MBU/LSU"
+	depends on CPU_SHEEVA_PJ4B_V6 || CPU_SHEEVA_PJ4B_V7
+	default n
+	help
+	  When a PLD instruction is used as a memory hint, using a fast load
+	  bypass (load data is used as the address for a subsequent memory access)
+	  can result in data corruption.
+	  WA: Do not operate in Speculative mode
+
+config SHEEVA_ERRATA_ARM_CPU_4413
+	bool "Sheeva Errata 4413: Add SB before L1 Invalidate by MVA"
+	depends on CPU_SHEEVA_PJ4B_V6 || CPU_SHEEVA_PJ4B_V7
+	help
+	  Potentially, invalidates by a Modified Virtual Address (MVA) entry can
+	  cause lines to fill into the L1 cache in an "intermediate" state without
+	  the lines being subsequently updated to a valid state. As a result, a
+	  subsequent "multi-hit" scenario and potential data corruption can occur
+	  when a future operation allocates the same address to a separate line.
+	  WA: The Invalidate by MVA operation (or sequence of MVA operations) must
+	  be preceded by a barrier to ensure that the preceding pre-condition for
+	  the cache miss is completed.
+
+config SHEEVA_ERRATA_ARM_CPU_4659
+	bool "Sheeva Errata 4659: Add ISB following L1 I$ Invalidate by MVA"
+	depends on CPU_SHEEVA_PJ4B_V6 || CPU_SHEEVA_PJ4B_V7
+	help
+	  I-Cache maintenance by using an MVA command can cause other instructions
+	  in I-Fetch to be executed twice.
+	  WA: Follow I-Cache maintenance by an MVA command with an Instruction
+	  Synchronization Barrier (ISB) instruction. This instruction flushes the
+	  pipeline after the maintenance operation, deleting any double-instructions.
+
+config SHEEVA_ERRATA_ARM_CPU_5114
+	bool "Sheeva Errata 5114: Force all MMU pages to be Shared"
+	depends on CPU_SHEEVA_PJ4B_V6 && AURORA_IO_CACHE_COHERENCY
+	help
+	  When a non-shared line fill request causes a shared cacheable eviction
+	  in close proximity to an incoming snoop to the victim line, the incoming
+	  snoop can incorrectly miss and result in data corruption.
+	  WA: When using cacheable shared memory, set all memory pages/descriptors
+	  to be shared in the Translation Table Base Register 0
+
+config SHEEVA_ERRATA_ARM_CPU_4611
+	bool "Sheeva Errata 4611: Preceed every L1 Clean operation with DSB"
+	depends on CPU_SHEEVA_PJ4B_V6 || CPU_SHEEVA_PJ4B_V7
+	help
+	  A CP15 clean operation can result in a dead lock state if it is hit by
+	  an incoming snoop evento.
+	  WA: Before any CP15 clean type operation in Cache Coherency mode, issue
+	  a Data Memory Barrier (DMB) or a Data Synchronization Barrier (DSB)
+	  instruction.
+
+config SHEEVA_ERRATA_ARM_CPU_BTS61
+	bool "Sheeva Errata BTS61: Disable WFI and WFE instructions in SMP or Coherent systems"
+	depends on (CPU_SHEEVA_PJ4B_V6 || CPU_SHEEVA_PJ4B_V7) && (SMP || AURORA_IO_CACHE_COHERENCY)
+	help
+	  When the CPU is set to WFI mode in the system with a Snoop command, a
+	  snoop response may not occur and that will cause a system hang.
+	  WA: Do not use the WFI mode in SMP/coherent systems.
+
+config SHEEVA_ERRATA_ARM_CPU_4948
+	bool "Sheeva Errata 4948: Disable L0 cache"
+	depends on CPU_SHEEVA_PJ4B_V6 || CPU_SHEEVA_PJ4B_V7
+	default n
+	help
+	  In a very rare case, the core can fail to observe the correct data
+	  as follows:
+	    1. After a first load, a second load operation to the same address
+	       occurs, and an invalidate snoop to the same line is arbitrated
+	       between both reads.
+	    2. The core may observe the old data for the second read, while the
+	       first load got the new data laying in this address.
+	    3. A third load to the same address will see the new data.
+	  WA: This event can occur when the first load access crosses a cache
+	  line boundary (i.e., unaligned access). If it does occur, L0 data
+	  cache can be disabled
+
+config SHEEVA_ERRATA_ARM_CPU_PMU_RESET
+	bool "Sheeva Errata CPU Performance counters reset"
+	depends on CPU_SHEEVA_PJ4B_V6 || CPU_SHEEVA_PJ4B_V7
+	help
+	  CPU Performance counters are not reset by writing '1' to Performance
+	  Monitor Control register bit 2 as expected.
+	  WA: Write 0 and then 1 to bit 2 in Performance Monitor Control register.
+
+config SHEEVA_ERRATA_ARM_CPU_ADD_DELAY_FOR_STOP_MACHINE
+	bool "stop_machine function can livelock"
+	depends on CPU_V6 && SMP
+	default y
+	help
+	  add delay when polling the stop_machine state.
+
+config SHEEVA_ERRATA_ARM_CPU_ADD_DELAY_FOR_STREX
+	bool "Spinlocks using LDREX and STREX instructions can livelock"
+	depends on CPU_V6 && SMP
+	default n
+	help
+	  add delay after strex.
+
+config SHEEVA_DEEP_IDLE
+	bool "Enable CPU/L2 Deep Idle Power Management"
+	depends on ARCH_ARMADA_XP && CPU_IDLE
+
+config ARMADA_XP_DEEP_IDLE_L2_WA
+	bool "Manage Aurora L2 on deepIdle"
+	depends on SHEEVA_DEEP_IDLE && CACHE_AURORA_L2
+
+config ARMADA_XP_DEEP_IDLE_UNMASK_INTS_WA
+	bool "Enable deepIdle workaround for regret mode"
+	depends on SHEEVA_DEEP_IDLE
+
+config CACHE_AURORA_L2
+	bool "Enable Marvell Aurora L2 cache controller"
+	depends on ARCH_ARMADA_XP
+	default y
+	help
+	  This option enables the Marvell Aurora L2 cache controller.
+
+config AURORA_L2_PT_WALK
+	bool "Enable Marvell page table walk in L2 to improve performance"
+	depends on CACHE_AURORA_L2
+	default y
+	help
+	  This option enables PTE caching in L2 to improve performance.
+
+config AURORA_L2_OUTER
+	bool
+	depends on CACHE_AURORA_L2 && (CPU_SHEEVA_PJ4B_V6 || ARMADA_XP_REV_Z1)
+	default y
+	select OUTER_CACHE
+	help
+	  This option enables all outer cache operations in V6 mode.
+
+config ENABLE_UNALINGED_ACCESS_FAULT
+	bool "Enable S/W handling for Unaligned Access"
+	default n
+	help
+	  This flag enables S/W handling of unaligned access
+
+config AURORA_IO_CACHE_COHERENCY
+	bool "Enable Marvell Aurora I/O cache coherency"
+	depends on ARCH_ARMADA_XP
+	default y
+	help
+	  This option enables the hardware mechanism for I/O cache coherency.
+
+config CPU_SHEEVA_PJ4B_PMC_ACCESS_IN_USERMODE
+	bool "Enabled User mode access for PMC"
+	depends on CPU_SHEEVA_PJ4B_V6 || CPU_SHEEVA_PJ4B_V7
+	default n
+	help
+	  Say Y if you allow user mode application to access Performance
+	  Monitor Counter of PJ4 in user mode
+
 config MIGHT_HAVE_CACHE_L2X0
 	bool
 	help
diff --git a/arch/arm/mm/cache-aurora-l2.c b/arch/arm/mm/cache-aurora-l2.c
new file mode 100644
index 0000000..e969a00
--- /dev/null
+++ b/arch/arm/mm/cache-aurora-l2.c
@@ -0,0 +1,689 @@
+/*
+ * arch/arm/mm/cache-aurora-l2.c - AURORA shared L2 cache controller support
+ *
+ * Copyright (C) 2008 Marvell Semiconductor
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ *
+ * References:
+ * - Unified Shared Layer 2 Cache for Armada CP SoC devices,
+ *   Document ID MV-S104858-00, Rev. A, October 23 2007.
+ */
+
+#include <linux/init.h>
+#include <asm/cacheflush.h>
+#include <linux/proc_fs.h>
+
+#include <plat/cache-aurora-l2.h>
+#include <asm/io.h>
+
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+
+/*
+ * L2 registers offsets
+ */
+#define L2_CONTROL		0x100
+#define L2_AUX_CONTROL		0x104
+#define L2_SYNC			0x700
+#define L2_RANGE_BASE		0x710
+#define L2_INVALIDATE_PA	0x770
+#define L2_INVALIDATE_RANGE	0x774
+#define L2_CLEAN_PA		0x7B0
+#define L2_CLEAN_RANGE		0x7B4
+#define L2_FLUSH_PA		0x7F0
+#define L2_FLUSH_RANGE		0x7F4
+#define L2_LOCKDOWN_DATA	0x900
+#define L2_LOCKDOWN_INSTR	0x904
+#define L2_LOCKDOWN_FPU		0x980
+#define L2_LOCKDOWN_IO_BRG	0x984
+
+static unsigned int l2rep = L2ACR_REPLACEMENT_TYPE_SEMIPLRU;
+static int __init l2rep_setup(char *str)
+{
+	if (!strcmp(str, "WayRR"))
+		l2rep = L2ACR_REPLACEMENT_TYPE_WAYRR;
+	else if (!strcmp(str, "LFSR"))
+		l2rep = L2ACR_REPLACEMENT_TYPE_LFSR;
+	else if (!strcmp(str, "pLRU"))
+		l2rep = L2ACR_REPLACEMENT_TYPE_SEMIPLRU;
+	else
+		return 0;
+	return 1;
+}
+__setup("l2rep=", l2rep_setup);
+
+void __iomem *auroraL2_base = NULL;
+bool auroraL2_enable = 0;
+#ifdef CONFIG_PROC_FS
+static unsigned char *replacement[] = {"WayRR",
+				       "LFSR",
+				       "semi pLRU",
+				       "reserved",
+};
+static unsigned char *associativity[] ={"reserved",
+					"reserved", 
+					"reserved", 
+					"4-way", 
+					"reserved", 
+					"reserved", 
+					"reserved", 
+					"8-way",
+					"reserved", 
+					"reserved", 
+					"reserved", 
+					"12-way", 
+					"reserved", 
+					"reserved", 
+					"reserved", 
+					"16-way", 
+					};
+static unsigned char *wsize[]={   "reserved(16KB)", 
+                                  "16KB",
+                                  "32KB",
+                                  "64KB",
+                                  "128KB",
+                                  "256KB",
+                                  "512KB",
+                                  "reserved(512KB)"
+                              };
+static unsigned char *wa_mode[] = {"Requester Attribute", 
+                                  "force no write allocate",
+                                  "force write allocate",
+                                  "reserved"
+                              	};
+static unsigned char *wbwt_mode[] = {"PageAttribute", 
+                                  "force WB",
+                                  "force WT",
+                                  "reserved"
+                              	};
+
+
+
+static int proc_auroraL2_info_read(char *page, char **start, off_t off, int count, int *eof,
+		    void *data)
+{
+	char *p = page;
+	int len;
+    	__u32 aux;
+
+	p += sprintf(p, "AuroraL2 Information:\n");
+			 
+	aux = readl(auroraL2_base + L2_AUX_CTRL_REG);		 
+	p += sprintf(p, "Replacement   : %s\n", replacement[(aux >> L2ACR_REPLACEMENT_OFFSET) & 0x3]);
+	p += sprintf(p, "Associativity : %s\n", associativity[(aux >> 13) & 0xf]);
+	p += sprintf(p, "Way size      : %s\n", wsize[(aux >> 17) & 0xF]);
+	p += sprintf(p, "Data ECC      : %s\n", ((aux >> 20) & 0x1) ? "Enabled" : "Disabled");
+	p += sprintf(p, "TAG parity    : %s\n", ((aux >> 21) & 0x1) ? "Enabled" : "Disabled");
+ 	p += sprintf(p, "Write mode forcing     : %s\n", wbwt_mode[(aux >> 0) & 0x3]);
+	p += sprintf(p, "Write allocate forcing : %s\n", wa_mode[(aux >> 23) & 0x3]);
+   
+	len = (p - page) - off;
+	if (len < 0)
+		len = 0;
+
+	*eof = (len <= count) ? 1 : 0;
+	*start = page + off;
+
+	return len;
+}
+
+#ifdef CONFIG_CACHE_AURORAL2_EVENT_MONITOR_ENABLE
+static unsigned int last_counter[2][2] = {{0,0},{0,0}};
+
+static unsigned char *event_name[]= {    
+                                        "Counter Disabled", 
+                                        "CastOut",
+                                        "DataRdHit",
+                                        "DataRdReq",
+                                        "DataWrHit",
+                                        "DataWrReq",
+                                        "DataWTReq",
+                                        "InstRdHit",
+                                        "InstRdReq",
+                                        "MmuRdHit",
+                                        "MmuRdReq",
+                                        "WriteWAMiss",
+                                        "WriteWACLReq",
+                                        "WriteWANoCLReq",
+                                        "SRAMWr",
+                                        "SRAMrRd",
+                                        "RMWWrite"
+                                        "SpeculativeInstReq"
+                                        "SpeculativeInstHit"
+                                        "RGFStall"
+                                        "EBStall"
+                                        "LRBStall"
+                                        "Idle"
+                                        "Active"
+                                    };
+static int proc_auroraL2_counter_read(char *page, char **start, off_t off, int count, int *eof,
+		    void *data)
+{
+	char *p = page;
+	int len, i, cfg;
+    	unsigned int counter[2][2], delta_counter[2][2];
+
+	p += sprintf(p, "AuroraL2 Event Counter Information:\n\n");			 
+	p += sprintf(p, "L2_CNTR_CTRL_REG    : %#08x\n", readl(auroraL2_base + L2_CNTR_CTRL_REG));
+
+	for (i = 0; i < L2_MAX_COUNTERS; i++){
+		cfg = readl(auroraL2_base + L2_CNTR_CONFIG_REG(i));
+		p += sprintf(p, "L2_CNTR%d_CONFIG_REG : %#08x[%s]\n", cfg, event_name[(cfg >> 2) & 0x3F]);
+	     	counter[i][0] = readl(auroraL2_base + L2_CNTR_VAL_LOW_REG(i));
+    		counter[i][1] = readl(auroraL2_base + L2_CNTR_VAL_HIGH_REG(i));
+        	delta_counter[i][0] = counter[i][0] - last_counter[i][0];
+        	delta_counter[i][1] = counter[i][1] - last_counter[i][1];
+	}
+    
+    	p += sprintf(p, "\n=========================================================================\n");
+    	p += sprintf(p, "currnet counter 0 1: %12u%12u     %12u%12u     %12u%12u\n",  counter[0][1]  counter[0][0],  counter[1][1], counter[1][0]);
+    	p += sprintf(p, "delta   counter 0 1: %12u%12u     %12u%12u     %12u%12u\n",  delta_counter[0][1],  delta_counter[0][0],  delta_counter[1][1], delta_counter[1][0]);
+
+	len = (p - page) - off;
+	if (len < 0)
+		len = 0;
+
+	*eof = (len <= count) ? 1 : 0;
+	*start = page + off;
+
+    	memcpy((unsigned char *)last_counter, (unsigned char *)counter, sizeof(last_counter));
+    
+	return len;
+}
+
+
+static int proc_auroraL2_counter_write(struct file *file, const char __user *buffer,
+				unsigned long count, void *data)
+{
+    u8 param[3][32];
+    u32 configs[3] = {0};
+    u8 *buffer_tmp = kmalloc(count+16, GFP_KERNEL);
+    int i, cfg;
+
+    memset(buffer_tmp, 0x0, sizeof(buffer_tmp));
+
+    if(copy_from_user(buffer_tmp, buffer, count))
+    {
+        if (buffer_tmp)        
+            kfree(buffer_tmp);
+        return -EFAULT;    
+    }
+
+    sscanf(buffer_tmp, "%s %s %s %s\n",  param[0], param[1], param[2]);
+
+    if (strcmp(param[0], "reset") == 0)
+    {
+	for (i = 0; i < L2_MAX_COUNTERS; i++){
+		/* Stop counters */
+		cfg = readl(auroraL2_base + L2_CNTR_CONFIG_REG(i));
+		cfg &= ~(0x3F << 2)
+        	writel(cfg, auroraL2_base + L2_CNTR_CONFIG_REG(i)); 
+	}
+        writel(0x101, auroraL2_base + L2_CNTR_CTRL_REG); /* reset counter values */
+
+        memset((unsigned char *)last_counter, 0, sizeof(last_counter));         
+        
+        goto out;
+    }
+
+    for (i = 0; i < 3; i++)
+        configs[i] = simple_strtoul(param[i], NULL, 0);             
+
+    writel(configs[0], auroraL2_base + L2_CNTR_CTRL_REG); 
+    writel(configs[1], auroraL2_base + L2_CNTR_CONFIG_REG(0)); 
+    writel(configs[2], auroraL2_base + L2_CNTR_CONFIG_REG(1)); 	 
+
+out:
+   
+    if (buffer_tmp)        
+        kfree(buffer_tmp);
+    
+	return count;
+}
+#endif /* CONFIG_CACHE_TAUROS3_EVENT_MONITOR_ENABLE */
+#endif /* CONFIG_PROC_FS */
+
+#define CACHE_LINE_SIZE		32
+#define MAX_RANGE_SIZE		1024
+#define RANGE_OP
+
+static int l2_wt_override = 0;
+static DEFINE_SPINLOCK(smp_l2cache_lock);
+
+/*
+ * Low-level cache maintenance operations.
+ *
+ *
+ * Cache range operations are initiated by writing the start and
+ * end addresses to successive cp15 registers, and process every
+ * cache line whose first byte address lies in the inclusive range
+ * [start:end-1] (the end address is inclusive).
+ *
+ * The cache range operations stall the CPU pipeline until completion.
+ *
+ * The range operations require two successive cp15 writes, in
+ * between which we don't want to be preempted.
+ */
+
+static inline void cache_sync(void)
+{    
+    writel(0, auroraL2_base+L2_SYNC);  /* flush L2 write buffer (barrier) */ 
+}
+
+#ifdef CONFIG_AURORA_L2_OUTER
+inline void l2_clean_pa(unsigned int addr)
+{
+    	if (!auroraL2_enable)
+        	return;        
+
+	writel(addr & ~0x1f, auroraL2_base+L2_CLEAN_PA);
+	cache_sync();
+}
+
+static inline void l2_inv_pa(unsigned long addr)
+{
+	if (!auroraL2_enable)
+        	return;        
+
+	writel(addr & ~0x1f, auroraL2_base+L2_INVALIDATE_PA);
+}
+
+static inline void l2_clean_inv_pa(unsigned long addr)
+{
+	if (!auroraL2_enable)
+        	return;        
+
+	writel(addr & ~0x1f, auroraL2_base+L2_FLUSH_PA);
+	cache_sync();
+}
+
+void l2_clean_va(unsigned int addr)
+{
+	l2_clean_pa(__pa(addr));
+}
+
+static inline void l2_clean_pa_range(unsigned long start, unsigned long end)
+{
+	unsigned long flags;
+
+	/*
+	 * Make sure 'start' and 'end' reference the same page, as
+	 * L2 is PIPT and range operations only do a TLB lookup on
+	 * the start address.
+	 */
+	BUG_ON((start ^ end) & ~(PAGE_SIZE - 1));
+#ifdef RANGE_OP
+	spin_lock_irqsave(&smp_l2cache_lock, flags);
+#ifdef CONFIG_SMP
+	writel(start, auroraL2_base+L2_RANGE_BASE + (4 * hard_smp_processor_id()));
+#else	
+	writel(start, auroraL2_base+L2_RANGE_BASE);
+#endif
+	writel(end, auroraL2_base+L2_CLEAN_RANGE);
+	spin_unlock_irqrestore(&smp_l2cache_lock, flags);
+#else
+	for(; start <= end; start += CACHE_LINE_SIZE)
+		writel(start, auroraL2_base+L2_CLEAN_PA);
+#endif
+	cache_sync();
+}
+
+static inline void l2_flush_pa_range(unsigned long start, unsigned long end)
+{
+	unsigned long flags;
+
+	/*
+	 * Make sure 'start' and 'end' reference the same page, as
+	 * L2 is PIPT and range operations only do a TLB lookup on
+	 * the start address.
+	 */
+	BUG_ON((start ^ end) & ~(PAGE_SIZE - 1));
+#ifdef RANGE_OP
+	spin_lock_irqsave(&smp_l2cache_lock, flags);
+#ifdef CONFIG_SMP
+	writel(start, auroraL2_base+L2_RANGE_BASE + (4 * hard_smp_processor_id()));
+#else
+	writel(start, auroraL2_base+L2_RANGE_BASE);
+#endif
+	writel(end, auroraL2_base+L2_FLUSH_RANGE);
+	spin_unlock_irqrestore(&smp_l2cache_lock, flags);
+#else
+	for ( ; start <= end; start += CACHE_LINE_SIZE)
+		writel(start, auroraL2_base+L2_FLUSH_PA);
+#endif
+	cache_sync();
+}
+
+static inline void l2_inv_pa_range(unsigned long start, unsigned long end)
+{
+	unsigned long flags;
+
+	/*
+	 * Make sure 'start' and 'end' reference the same page, as
+	 * L2 is PIPT and range operations only do a TLB lookup on
+	 * the start address.
+	 */
+	BUG_ON((start ^ end) & ~(PAGE_SIZE - 1));
+#ifdef RANGE_OP
+	spin_lock_irqsave(&smp_l2cache_lock, flags);
+#ifdef CONFIG_SMP
+	writel(start, auroraL2_base+L2_RANGE_BASE + (4 * hard_smp_processor_id()));
+#else	
+	writel(start, auroraL2_base+L2_RANGE_BASE);
+#endif
+	writel(end, auroraL2_base+L2_INVALIDATE_RANGE);
+	spin_unlock_irqrestore(&smp_l2cache_lock, flags);
+#else
+	for(; start <= end; start += CACHE_LINE_SIZE)
+		writel(start, auroraL2_base+L2_INVALIDATE_PA);
+#endif
+
+	cache_sync();
+}
+
+
+/*
+ * Linux primitives.
+ *
+ * Note that the end addresses passed to Linux primitives are
+ * noninclusive, while the hardware cache range operations use
+ * inclusive start and end addresses.
+ */
+
+static inline unsigned long calc_range_end(unsigned long start, unsigned long end)
+{
+	unsigned long range_end;
+
+	BUG_ON(start & (CACHE_LINE_SIZE - 1));
+	BUG_ON(end & (CACHE_LINE_SIZE - 1));
+
+	/*
+	 * Try to process all cache lines between 'start' and 'end'.
+	 */
+	range_end = end;
+
+	/*
+	 * Limit the number of cache lines processed at once,
+	 * since cache range operations stall the CPU pipeline
+	 * until completion.
+	 */
+	if (range_end > start + MAX_RANGE_SIZE)
+		range_end = start + MAX_RANGE_SIZE;
+
+	/*
+	 * Cache range operations can't straddle a page boundary.
+	 */
+	if (range_end > (start | (PAGE_SIZE - 1)) + 1)
+		range_end = (start | (PAGE_SIZE - 1)) + 1;
+
+	return range_end;
+}
+
+static void aurora_l2_inv_range(unsigned long start, unsigned long end)
+{
+    	if (!auroraL2_enable)
+        	return;        
+	/*
+	 * Clean and invalidate partial first cache line.
+	 */
+	if (start & (CACHE_LINE_SIZE - 1)) {
+		l2_clean_inv_pa(start & ~(CACHE_LINE_SIZE - 1));
+		start = (start | (CACHE_LINE_SIZE - 1)) + 1;
+	}
+
+	/*
+	 * Clean and invalidate partial last cache line.
+	 */
+	if (start < end && end & (CACHE_LINE_SIZE - 1)) {
+		l2_clean_inv_pa(end & ~(CACHE_LINE_SIZE - 1));
+		end &= ~(CACHE_LINE_SIZE - 1);
+	}
+
+	/*
+	 * Invalidate all full cache lines between 'start' and 'end'.
+	 */
+	while (start < end) {
+		unsigned long range_end = calc_range_end(start, end);
+		l2_inv_pa_range(start, range_end - CACHE_LINE_SIZE);
+		start = range_end;
+	}
+
+	dsb();
+}
+
+void aurora_l2_clean_range(unsigned long start, unsigned long end)
+{
+    	if (!auroraL2_enable)
+        	return;        
+	/*
+	 * If L2 is forced to WT, the L2 will always be clean and we
+	 * don't need to do anything here.
+	 */
+	if (!l2_wt_override) {
+		start &= ~(CACHE_LINE_SIZE - 1);
+		end = (end + CACHE_LINE_SIZE - 1) & ~(CACHE_LINE_SIZE - 1);
+		while (start != end) {
+			unsigned long range_end = calc_range_end(start, end);
+			l2_clean_pa_range(start, range_end - CACHE_LINE_SIZE);
+			start = range_end;
+		}
+	}
+
+	dsb();
+}
+
+void aurora_l2_flush_range(unsigned long start, unsigned long end)
+{
+    	if (!auroraL2_enable)
+        	return;        
+
+	start &= ~(CACHE_LINE_SIZE - 1);
+	end = (end + CACHE_LINE_SIZE - 1) & ~(CACHE_LINE_SIZE - 1);
+	while (start != end) {
+		unsigned long range_end = calc_range_end(start, end);
+		if (!l2_wt_override)
+			l2_flush_pa_range(start, range_end - CACHE_LINE_SIZE);
+		start = range_end;
+	}
+
+	dsb();
+}
+#endif /* #ifdef CONFIG_AURORA_L2_OUTER */
+
+/*
+ * Routines to disable and re-enable the D-cache and I-cache at run
+ * time.  
+ */
+static u32 __init invalidate_and_disable_cache(void)
+{
+	int dummy;
+	volatile u32 cr;
+
+	cr = get_cr();
+	if (cr & CR_C) {
+		unsigned long flags;
+
+		raw_local_irq_save(flags);
+		flush_cache_all();
+		set_cr(cr & ~CR_C);
+		raw_local_irq_restore(flags);
+	}
+	if (cr & CR_I) {
+		set_cr(cr & ~CR_I);
+		__asm__ __volatile__("mcr p15, 0, %0, c7, c5, 0\n" : "=r" (dummy));
+	}
+	
+	return ((cr & CR_C) | (cr & CR_I));
+}
+
+static void __init enable_cache(u32 mask)
+{
+	volatile u32 cr1;
+
+	cr1 = get_cr();
+	set_cr(cr1 | mask);
+}
+
+
+static void __init enable_l2(void)
+{
+	u32 u, mask;
+#if 0
+	/* Enable SMP (SMPnAMP) in Aux Control Reg */
+	__asm__ __volatile__("mrc p15, 0, %0, c1, c0, 1" : "=r" (u));
+	u |= 0x40; /* Set SMPnAMP bit */
+	__asm__ __volatile__("mcr p15, 0, %0, c1, c0, 1\n" : : "r" (u));
+#endif
+	/* Enable Broadcasring (FW) in Extra Features Reg */	
+	__asm__ __volatile__("mrc p15, 1, %0, c15, c2, 0" : "=r" (u));
+	u |= 0x100; /* Set the FW bit */
+	__asm__ __volatile__("mcr p15, 1, %0, c15, c2, 0\n" : : "r" (u));
+
+	u = readl(auroraL2_base+L2_CONTROL);
+	if (!(u & 1)) {
+		printk(KERN_INFO "Aurora L2 Cache Enabled\n");
+		u |= 1;
+		mask = invalidate_and_disable_cache();
+		writel(u, auroraL2_base+L2_CONTROL);
+		enable_cache(mask);
+	}
+}
+
+/* lock_mask is a bit map. '1' means way is locked. '0' means way is unlocked */
+void __init aurora_l2_lockdown(u32 cpuId, u32 lock_mask)
+{
+	lock_mask &= 0xFF;
+	writel(lock_mask, auroraL2_base+L2_LOCKDOWN_DATA+(cpuId*8));
+	writel(lock_mask, auroraL2_base+L2_LOCKDOWN_INSTR+(cpuId*8));
+	writel(lock_mask, auroraL2_base+L2_LOCKDOWN_FPU);
+	writel(lock_mask, auroraL2_base+L2_LOCKDOWN_IO_BRG);
+}
+
+
+void auroraL2_inv_all(void)
+{
+	u32 u   = 0xffff; // all ways
+	writel(u, auroraL2_base+L2_INVAL_WAY_REG);
+}
+
+void auroraL2_flush_all(void)
+{
+	u32 u   = 0xffff; // all ways
+
+    	if (!auroraL2_enable)
+		return;
+
+	writel(u, auroraL2_base + L2_FLUSH_WAY_REG);
+	cache_sync();
+}
+
+
+struct regs_entry {
+	u32             reg_address;
+	u32             reg_value;
+};
+
+static struct regs_entry aurora_l2_regs[] = {
+	{L2_AUX_CONTROL,0},
+	{L2_CONTROL, 0}
+};
+
+/* L2 Power management function */
+int aurora_l2_pm_enter(void)
+{
+	int i;
+
+    	if (!auroraL2_enable)
+		return 0;
+	for ( i = 0; i < ARRAY_SIZE(aurora_l2_regs); i++)
+		aurora_l2_regs[i].reg_value = readl(auroraL2_base+ aurora_l2_regs[i].reg_address);
+
+	return 0;
+}
+int aurora_l2_pm_exit(void)
+{
+	int i;
+	u32	u;
+    	if (!auroraL2_enable)
+		return 0;
+
+	u = readl(auroraL2_base+L2_CONTROL);
+        if (!(u & 1)) {
+		pr_debug("Aurora: Enabling L2\n");
+
+		for ( i = 0; i < ARRAY_SIZE(aurora_l2_regs); i++)
+			writel(aurora_l2_regs[i].reg_value, auroraL2_base+ aurora_l2_regs[i].reg_address);
+	}
+	return 0;
+}
+
+int __init aurora_l2_init(void __iomem *base)
+{	
+	__u32 aux;
+	u32 u;
+
+#ifdef CONFIG_PROC_FS
+	struct proc_dir_entry *res;
+	struct proc_dir_entry *res_file;
+
+	res = proc_mkdir("AuroraL2", NULL);
+	if (!res)
+		return -ENOMEM;
+
+    	/* Create information proc file */
+	res_file = create_proc_entry("info", S_IWUSR | S_IRUGO, res);
+	if (!res)
+		return -ENOMEM;
+
+	res_file->read_proc = proc_auroraL2_info_read;
+	res_file->write_proc = NULL;
+
+#ifdef CONFIG_CACHE_AURORAL2_EVENT_MONITOR_ENABLE
+	/* Create counter proc file */
+	res_file = create_proc_entry("counter", S_IWUSR | S_IRUGO, res);
+	if (!res)
+		return -ENOMEM;
+
+	res_file->read_proc = proc_auroraL2_counter_read;    
+	res_file->write_proc = proc_auroraL2_counter_write;
+#endif /* CONFIG_CACHE_AURORAL2_EVENT_MONITOR_ENABLE */
+#endif
+
+#ifdef CONFIG_AURORA_L2_OUTER
+	outer_cache.inv_range = aurora_l2_inv_range;
+	outer_cache.clean_range = aurora_l2_clean_range;
+	outer_cache.flush_range = aurora_l2_flush_range;
+#endif
+	
+	auroraL2_base = base;
+        					 		
+	/* 1. Write to AuroraL2 Auxiliary Control Register, 0x104
+	 *    Setting up Associativity, Way Size, and Latencies
+	 */	
+	aux = readl(auroraL2_base + L2_AUX_CTRL_REG);
+	aux &= ~L2ACR_REPLACEMENT_MASK;
+	aux |= l2rep;
+	writel(aux, auroraL2_base + L2_AUX_CTRL_REG); 	    	
+
+	l2_wt_override = ((aux & (0x3)) == 0x2 ? 1:0);
+	/* 3. Secure write to AuroraL2 Invalidate by Way, 0x77c
+	 */ 
+	auroraL2_inv_all();
+
+	/* 4. Write to the Lockdown D and Lockdown I Register 9 if required
+	 */  
+    
+	/* 5. Write to interrupt clear register, 0x220, to clear any residual 
+	 *    raw interrupt set.
+	 */
+	writel(0x1FF, auroraL2_base + L2_INT_CAUSE_REG); 	    
+	
+	/* 6. Enable L2 cache
+	 */
+	enable_l2();
+    	auroraL2_enable = 1;
+
+	return 0;
+}
diff --git a/arch/arm/mm/mmu.c b/arch/arm/mm/mmu.c
index 983ad96..64559f3 100644
--- a/arch/arm/mm/mmu.c
+++ b/arch/arm/mm/mmu.c
@@ -869,8 +869,13 @@ static void __init fill_pmd_gaps(void)
 #define fill_pmd_gaps() do { } while (0)
 #endif
 
+#ifdef CONFIG_FB_DOVE
+static void*  __initdata vmalloc_min =
+	(void *)(VMALLOC_END - SZ_128M - SZ_32M);
+#else
 static void * __initdata vmalloc_min =
 	(void *)(VMALLOC_END - (240 << 20) - VMALLOC_OFFSET);
+#endif
 
 /*
  * vmalloc=size forces the vmalloc area to be exactly 'size'
@@ -993,6 +998,7 @@ void __init sanity_check_meminfo(void)
 		}
 	}
 #endif
+#endif
 	meminfo.nr_banks = j;
 	high_memory = __va(arm_lowmem_limit - 1) + 1;
 	memblock_set_current_limit(arm_lowmem_limit);
diff --git a/arch/arm/mm/proc-sheeva_pj4bv6.S b/arch/arm/mm/proc-sheeva_pj4bv6.S
new file mode 100644
index 0000000..1bf4a41
--- /dev/null
+++ b/arch/arm/mm/proc-sheeva_pj4bv6.S
@@ -0,0 +1,326 @@
+/*
+ *  linux/arch/arm/mm/proc-sheeva_pj4bv6.S
+ *
+ *  Copyright (C) 2001 Deep Blue Solutions Ltd.
+ *  Modified by Catalin Marinas for noMMU support
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ *  This is the "shell" of the ARMv6 processor support.
+ */
+#include <linux/init.h>
+#include <linux/linkage.h>
+#include <asm/assembler.h>
+#include <asm/asm-offsets.h>
+#include <asm/hwcap.h>
+#include <asm/pgtable-hwdef.h>
+#include <asm/pgtable.h>
+#include <mach/armadaxp.h>
+
+#include "proc-macros.S"
+#include "sheeva_pj4b-macros.S"
+
+#define D_CACHE_LINE_SIZE	32
+
+#define TTB_C		(1 << 0)
+#define TTB_S		(1 << 1)
+#define TTB_IMP		(1 << 2)
+#define TTB_RGN_NC	(0 << 3)
+#define TTB_RGN_WBWA	(1 << 3)
+#define TTB_RGN_WT	(2 << 3)
+#define TTB_RGN_WB	(3 << 3)
+
+#ifdef CONFIG_AURORA_L2_PT_WALK
+#define TTB_FLAGS_OUTER	TTB_RGN_WB
+#else
+#define TTB_FLAGS_OUTER	0
+#endif
+
+#ifndef CONFIG_SMP
+#define TTB_FLAGS	TTB_FLAGS_OUTER
+#define PMD_FLAGS	PMD_SECT_WB
+#else
+#define TTB_FLAGS	TTB_FLAGS_OUTER|TTB_S
+#define PMD_FLAGS	PMD_SECT_WBWA|PMD_SECT_S
+#endif
+
+ENTRY(cpu_sheeva_pj4b_v6_proc_init)
+	mov	pc, lr
+
+ENTRY(cpu_sheeva_pj4b_v6_proc_fin)
+	stmfd	sp!, {lr}
+	cpsid	if				@ disable interrupts
+	bl	v6_flush_kern_cache_all
+#ifdef CONFIG_CACHE_AURORA_L2
+	mcr	p15, 0, r0, c7, c10, 4		@ Data Synchronization Barrier
+	ldr	r0, =0xffff			@ L2C clean all 16 ways
+	ldr	r1, =AXP_L2_CLEAN_WAY_REG
+	str	r0, [r1]
+	mrc	p15, 0, r0, c0, c0, 5		@ Read CPU core number
+	and	r0, r0, #0xF
+	mov	r1, #0x1
+	lsl	r0, r1, r0
+1:	ldr	r1, =AXP_L2_MNTNC_STAT_REG	@ Read maintanence status to check done per CPU
+	ldr	r1, [r1]
+	tst	r0, r1
+	bne	1b
+	mcr	p15, 0, r0, c7, c10, 4		@ Data Synchronization Barrier
+#endif
+	mrc	p15, 0, r0, c1, c0, 0		@ ctrl register
+	bic	r0, r0, #0x1000			@ ...i............
+	bic	r0, r0, #0x0006			@ .............ca.
+	mcr	p15, 0, r0, c1, c0, 0		@ disable caches
+	ldmfd	sp!, {pc}
+
+/*
+ *	cpu_sheeva_pj4b_v6_reset(loc)
+ *
+ *	Perform a soft reset of the system.  Put the CPU into the
+ *	same state as it would be if it had been reset, and branch
+ *	to what would be the reset vector.
+ *
+ *	- loc   - location to jump to for soft reset
+ */
+	.align	5
+ENTRY(cpu_sheeva_pj4b_v6_reset)
+	mov	pc, r0
+
+/*
+ *	cpu_sheeva_pj4b_v6_do_idle()
+ *
+ *	Idle the processor (eg, wait for interrupt).
+ *
+ *	IRQs are already disabled.
+ */
+ENTRY(cpu_sheeva_pj4b_v6_do_idle)
+	mov	r1, #0
+	mcr	p15, 0, r1, c7, c10, 4		@ DWB - WFI may enter a low-power mode
+#ifndef CONFIG_SHEEVA_ERRATA_ARM_CPU_BTS61
+	mcr	p15, 0, r1, c7, c0, 4		@ wait for interrupt
+#endif
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_4742
+	mcr	p15, 0, r0, c7, c10, 4		@barrier
+#endif
+	mov	pc, lr
+
+ENTRY(cpu_sheeva_pj4b_v6_dcache_clean_area)
+#ifndef TLB_CAN_READ_FROM_L1_CACHE
+#if !defined(CONFIG_HAVE_GENERIC_DMA_COHERENT) || defined(CONFIG_SHEEVA_ERRATA_ARM_CPU_4611)
+	mrs     r2, cpsr
+        orr     r3, r2, #PSR_F_BIT | PSR_I_BIT
+        msr     cpsr_c, r3                      @ Disable interrupts
+	mcr     p15, 0, r0, c7, c10, 4          @ Data Synchronization Barrier
+#endif
+1:	mcr	p15, 0, r0, c7, c10, 1		@ clean D entry
+#ifndef CONFIG_AURORA_L2_PT_WALK
+	mcr     p15, 1, r0, c7, c11, 1		@ clean L2C D entry
+#endif
+	mcr     p15, 0, r0, c7, c10, 4          @ Data Synchronization Barrier
+	add	r0, r0, #D_CACHE_LINE_SIZE
+	subs	r1, r1, #D_CACHE_LINE_SIZE
+	bhi	1b
+#if !defined(CONFIG_HAVE_GENERIC_DMA_COHERENT) || defined(CONFIG_SHEEVA_ERRATA_ARM_CPU_4611)
+        msr     cpsr_c, r2                      @ Restore interrupts
+	mcr	p15, 0, r0, c7, c10, 4		@ Data Synchronization Barrier
+#endif
+#endif
+	mov	pc, lr
+
+/*
+ *	cpu_arm926_switch_mm(pgd_phys, tsk)
+ *
+ *	Set the translation table base pointer to be pgd_phys
+ *
+ *	- pgd_phys - physical address of new TTB
+ *
+ *	It is assumed that:
+ *	- we are not using split page tables
+ */
+ENTRY(cpu_sheeva_pj4b_v6_switch_mm)
+#ifdef CONFIG_MMU
+	mov	r2, #0
+	ldr	r1, [r1, #MM_CONTEXT_ID]	@ get mm->context.id
+	orr	r0, r0, #TTB_FLAGS
+	mcr	p15, 0, r2, c7, c5, 6		@ flush BTAC/BTB
+	mcr	p15, 0, r2, c7, c10, 4		@ drain write buffer
+	mcr	p15, 0, r0, c2, c0, 0		@ set TTB 0
+	mcr	p15, 0, r0, c7, c10, 4		@ Data Synchronization Barrier
+	mcr	p15, 0, r1, c13, c0, 1		@ set context ID
+#endif
+	mov	pc, lr
+
+/*
+ *	cpu_sheeva_pj4b_v6_set_pte_ext(ptep, pte, ext)
+ *
+ *	Set a level 2 translation table entry.
+ *
+ *	- ptep  - pointer to level 2 translation table entry
+ *		  (hardware version is stored at -1024 bytes)
+ *	- pte   - PTE value to store
+ *	- ext	- value for extended PTE bits
+ */
+	armv6_mt_table cpu_v6
+
+ENTRY(cpu_sheeva_pj4b_v6_set_pte_ext)
+#ifdef CONFIG_MMU
+	armv6_set_pte_ext cpu_v6
+#endif
+	mov	pc, lr
+
+
+
+	.type	cpu_sheeva_pj4b_v6_name, #object
+cpu_sheeva_pj4b_v6_name:
+	.asciz	"Marvell PJ4Bv6 processor"
+	.size	cpu_sheeva_pj4b_v6_name, . - cpu_sheeva_pj4b_v6_name
+
+	.type	cpu_pj4_name, #object
+cpu_pj4_name:
+	.asciz	"Marvell PJ4 processor"
+	.size	cpu_pj4_name, . - cpu_pj4_name
+
+	.align
+
+	__INIT
+
+/*
+ *	__pj4bv6_setup
+ *
+ *	Initialise TLB, Caches, and MMU state ready to switch the MMU
+ *	on.  Return in r0 the new CP15 C1 control register setting.
+ *
+ *	We automatically detect if we have a Harvard cache, and use the
+ *	Harvard cache control instructions insead of the unified cache
+ *	control instructions.
+ *
+ *	This should be able to cover all ARMv6 cores.
+ *
+ *	It is assumed that:
+ *	- cache type register is implemented
+ */
+__pj4bv6_setup:
+	sheeva_pj4b_config
+
+#if defined(CONFIG_SMP) || defined (CONFIG_AURORA_IO_CACHE_COHERENCY)
+	mrc	p15, 0, r0, c1, c0, 1		@ Enable SMP/nAMP mode
+	orr	r0, r0, #0x20
+	mcr	p15, 0, r0, c1, c0, 1
+	mrc 	p15, 1, r0, c15, c2, 0
+	orr	r0, r0, #0x2			@ SMP enable 
+	mcr 	p15, 1, r0, c15, c2, 0
+#endif
+#ifdef CONFIG_CPU_SHEEVA_PJ4B_PMC_ACCESS_IN_USERMODE
+	@ Enable performance counters user access
+	mrc     p15, 0, r0, c9, c14, 0
+	orr     r0, r0, #0x1
+	mcr     p15, 0, r0, c9, c14, 0
+#endif /* CONFIG_CPU_SHEEVA_PJ4B_PMC_ACCESS_IN_USERMODE */
+	mov	r0, #0
+	mcr	p15, 0, r0, c7, c10, 4		@ Data Synchronization Barrier
+	mcr	p15, 0, r0, c7, c14, 0		@ clean+invalidate D cache
+	mcr	p15, 0, r0, c7, c5, 0		@ invalidate I cache
+	mcr	p15, 0, r0, c7, c15, 0		@ clean+invalidate cache
+	mcr	p15, 0, r0, c7, c10, 4		@ drain write buffer
+#ifdef CONFIG_MMU
+	mcr	p15, 0, r0, c8, c7, 0		@ invalidate I + D TLBs
+	mcr	p15, 0, r0, c2, c0, 2		@ TTB control register
+	orr	r4, r4, #TTB_FLAGS
+	mcr	p15, 0, r4, c2, c0, 1		@ load TTB1
+	mcr	p15, 0, r0, c7, c10, 4		@ Data Synchronization Barrier
+#endif /* CONFIG_MMU */
+	adr	r5, v6_crval
+	ldmia	r5, {r5, r6}
+#ifdef CONFIG_CPU_ENDIAN_BE8
+	orr	r6, r6, #1 << 25		@ big-endian page tables
+#endif
+	mrc	p15, 0, r0, c1, c0, 0		@ read control register
+	bic	r0, r0, r5			@ clear bits them
+	orr	r0, r0, r6			@ set them
+	mov	pc, lr				@ return to head.S:__ret
+
+	/*
+	 *         V X F   I D LR
+	 * .... ...E PUI. .T.T 4RVI ZFRS BLDP WCAM
+	 * rrrr rrrx xxx0 0101 xxxx xxxx x111 xxxx < forced
+	 *         0 110       0011 1.00 .111 1101 < we want
+	 */
+	.type	v6_crval, #object
+v6_crval:
+	crval	clear=0x01e0fb7f, mmuset=0x00c0387d, ucset=0x00c0187c
+
+	.type	v6_processor_functions, #object
+ENTRY(v6_processor_functions)
+	.word	v6_early_abort
+	.word	v6_pabort
+	.word	cpu_sheeva_pj4b_v6_proc_init
+	.word	cpu_sheeva_pj4b_v6_proc_fin
+	.word	cpu_sheeva_pj4b_v6_reset
+	.word	cpu_sheeva_pj4b_v6_do_idle
+	.word	cpu_sheeva_pj4b_v6_dcache_clean_area
+	.word	cpu_sheeva_pj4b_v6_switch_mm
+	.word	cpu_sheeva_pj4b_v6_set_pte_ext
+	.size	v6_processor_functions, . - v6_processor_functions
+
+	.type	cpu_arch_name, #object
+cpu_arch_name:
+	.asciz	"armv6"
+	.size	cpu_arch_name, . - cpu_arch_name
+
+	.type	cpu_elf_name, #object
+cpu_elf_name:
+	.asciz	"v6"
+	.size	cpu_elf_name, . - cpu_elf_name
+	.align
+
+	.section ".proc.info.init", #alloc, #execinstr
+
+	/*
+	 * Match any ARMv6 processor core.
+	 */
+	.type	__pj4bv6_proc_info, #object
+__pj4bv6_proc_info:
+	.long	0x000f0000
+	.long	0x000f0000
+	.long   PMD_TYPE_SECT | \
+		PMD_SECT_AP_WRITE | \
+		PMD_SECT_AP_READ | \
+		PMD_FLAGS
+	.long   PMD_TYPE_SECT | \
+		PMD_SECT_XN | \
+		PMD_SECT_AP_WRITE | \
+		PMD_SECT_AP_READ
+	b	__pj4bv6_setup
+	.long	cpu_arch_name
+	.long	cpu_elf_name
+	.long	HWCAP_SWP|HWCAP_HALF|HWCAP_THUMB|HWCAP_FAST_MULT|HWCAP_EDSP|HWCAP_JAVA
+	.long	cpu_sheeva_pj4b_v6_name
+	.long	v6_processor_functions
+	.long	v6wbi_tlb_fns
+	.long	v6_user_fns
+	.long	v6_cache_fns
+	.size	__pj4bv6_proc_info, . - __pj4bv6_proc_info
+
+	.type	__pj4_v6_proc_info, #object
+__pj4_v6_proc_info:
+	.long	0x560f5810
+	.long	0xff0ffff0
+	.long   PMD_TYPE_SECT | \
+		PMD_SECT_AP_WRITE | \
+		PMD_SECT_AP_READ | \
+		PMD_FLAGS
+	.long   PMD_TYPE_SECT | \
+		PMD_SECT_XN | \
+		PMD_SECT_AP_WRITE | \
+		PMD_SECT_AP_READ
+	b	__pj4bv6_setup
+	.long	cpu_arch_name
+	.long	cpu_elf_name
+	.long	HWCAP_SWP|HWCAP_HALF|HWCAP_THUMB|HWCAP_FAST_MULT|HWCAP_EDSP
+	.long	cpu_pj4_name
+	.long	v6_processor_functions
+	.long	v6wbi_tlb_fns
+	.long	v6_user_fns
+	.long	v6_cache_fns
+	.size	__pj4_v6_proc_info, . - __pj4_v6_proc_info
diff --git a/arch/arm/mm/proc-sheeva_pj4bv7.S b/arch/arm/mm/proc-sheeva_pj4bv7.S
new file mode 100644
index 0000000..0b1aac2
--- /dev/null
+++ b/arch/arm/mm/proc-sheeva_pj4bv7.S
@@ -0,0 +1,546 @@
+/*
+ *  linux/arch/arm/mm/proc-sheeva_pj4bv7.S
+ *
+ *  Copyright (C) 2001 Deep Blue Solutions Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ *  This is the "shell" of the ARMv7 processor support.
+ */
+#include <linux/init.h>
+#include <linux/linkage.h>
+#include <asm/assembler.h>
+#include <asm/asm-offsets.h>
+#include <asm/hwcap.h>
+#include <asm/pgtable-hwdef.h>
+#include <asm/pgtable.h>
+#include <mach/armadaxp.h>
+
+#include "proc-macros.S"
+#include "sheeva_pj4b-macros.S"
+
+#define TTB_S		(1 << 1)
+#define TTB_RGN_NC	(0 << 3)
+#define TTB_RGN_OC_WBWA	(1 << 3)
+#define TTB_RGN_OC_WT	(2 << 3)
+#define TTB_RGN_OC_WB	(3 << 3)
+#define TTB_NOS		(1 << 5)
+#define TTB_IRGN_NC	((0 << 0) | (0 << 6))
+#define TTB_IRGN_WBWA	((0 << 0) | (1 << 6))
+#define TTB_IRGN_WT	((1 << 0) | (0 << 6))
+#define TTB_IRGN_WB	((1 << 0) | (1 << 6))
+
+/* PTWs cacheable, inner WB not shareable, outer WB not shareable */
+#define TTB_FLAGS_UP	TTB_IRGN_WB|TTB_RGN_OC_WB
+#define PMD_FLAGS_UP	PMD_SECT_WB
+
+
+/* PTWs cacheable, inner WBWA shareable, outer WBWA not shareable */
+#define TTB_FLAGS_SMP	TTB_IRGN_WBWA|TTB_S|TTB_NOS|TTB_RGN_OC_WBWA
+#define PMD_FLAGS_SMP	PMD_SECT_WBWA|PMD_SECT_S
+
+ENTRY(cpu_pj4bv7_proc_init)
+	mov	pc, lr
+ENDPROC(cpu_pj4bv7_proc_init)
+
+ENTRY(cpu_pj4bv7_proc_fin)
+	
+	
+	
+	
+	
+#ifdef CONFIG_CACHE_AURORA_L2
+	mcr	p15, 0, r0, c7, c10, 4		@ Data Synchronization Barrier
+	ldr	r0, =0xffff			@ L2C clean all 16 ways
+	ldr	r1, =AXP_L2_CLEAN_WAY_REG
+	str	r0, [r1]
+	mrc	p15, 0, r0, c0, c0, 5		@ Read CPU core number
+	and	r0, r0, #0xF
+	mov	r1, #0x1
+	lsl	r0, r1, r0
+1:	ldr	r1, =AXP_L2_MNTNC_STAT_REG	@ Read maintanence status to check done per CPU
+	ldr	r1, [r1]
+	tst	r0, r1
+	bne	1b
+	mcr	p15, 0, r0, c7, c10, 4		@ Data Synchronization Barrier
+#endif
+	mrc	p15, 0, r0, c1, c0, 0		@ ctrl register
+	bic	r0, r0, #0x1000			@ ...i............
+	bic	r0, r0, #0x0006			@ .............ca.
+	mcr	p15, 0, r0, c1, c0, 0		@ disable caches
+	mov	pc, lr
+	
+ENDPROC(cpu_pj4bv7_proc_fin)
+
+/*
+++*	cpu_pj4bv7_reset(loc)
+ *
+ *	Perform a soft reset of the system.  Put the CPU into the
+ *	same state as it would be if it had been reset, and branch
+ *	to what would be the reset vector.
+ *
+ *	- loc   - location to jump to for soft reset
+ */
+	.align	5
+ENTRY(cpu_pj4bv7_reset)
+	mov	pc, r0
+ENDPROC(cpu_pj4bv7_reset)
+
+/*
+++ *	cpu_pj4bv7_do_idle()
+ *
+ *	Idle the processor (eg, wait for interrupt).
+ *
+ *	IRQs are already disabled.
+ */
+ENTRY(cpu_pj4bv7_do_idle)
+#ifndef CONFIG_SHEEVA_ERRATA_ARM_CPU_BTS61
+	dsb					@ WFI may enter a low-power mode
+	wfi
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_4742
+	mcr	p15, 0, r0, c7, c10, 4		@barrier
+#endif
+#endif	
+	mov	pc, lr
+ENDPROC(cpu_pj4bv7_do_idle)
+
+ENTRY(cpu_pj4bv7_dcache_clean_area)
+#ifndef TLB_CAN_READ_FROM_L1_CACHE
+	dcache_line_size r2, r3
+1:	mcr	p15, 0, r0, c7, c10, 1		@ clean D entry
+	add	r0, r0, r2
+	subs	r1, r1, r2
+	bhi	1b
+	dsb
+#endif
+	mov	pc, lr
+ENDPROC(cpu_pj4bv7_dcache_clean_area)
+
+/*
+ *	cpu_pj4bv7_switch_mm(pgd_phys, tsk)
+ *
+ *	Set the translation table base pointer to be pgd_phys
+ *
+ *	- pgd_phys - physical address of new TTB
+ *
+ *	It is assumed that:
+ *	- we are not using split page tables
+ */
+ENTRY(cpu_pj4bv7_switch_mm)
+#ifdef CONFIG_MMU
+	mov	r2, #0
+	ldr	r1, [r1, #MM_CONTEXT_ID]	@ get mm->context.id
+#ifdef CONFIG_AURORA_L2_PT_WALK 
+	ALT_SMP(orr	r0, r0, #TTB_FLAGS_SMP)
+	ALT_UP(orr	r0, r0, #TTB_FLAGS_UP)
+#else
+	bic     r0, r0, #0x18                   @ DONOT Cache the page table in L2
+#endif
+#ifdef CONFIG_ARM_ERRATA_430973
+	mcr	p15, 0, r2, c7, c5, 6		@ flush BTAC/BTB
+#endif
+#ifdef CONFIG_ARM_ERRATA_754322
+	dsb
+#endif
+	mcr	p15, 0, r2, c13, c0, 1		@ set reserved context ID
+	isb
+1:	mcr	p15, 0, r0, c2, c0, 0		@ set TTB 0
+	isb
+#ifdef CONFIG_ARM_ERRATA_754322
+	dsb
+#endif
+	mcr	p15, 0, r1, c13, c0, 1		@ set context ID
+	isb
+#endif
+	mov	pc, lr
+ENDPROC(cpu_pj4bv7_switch_mm)
+
+/*
+ *	cpu_pj4bv7_set_pte_ext(ptep, pte)
+ *
+ *	Set a level 2 translation table entry.
+ *
+ *	- ptep  - pointer to level 2 translation table entry
+ *		  (hardware version is stored at -1024 bytes)
+ *	- pte   - PTE value to store
+ *	- ext	- value for extended PTE bits
+ */
+ENTRY(cpu_pj4bv7_set_pte_ext)
+#ifdef CONFIG_MMU
+ 
+str	r1, [r0]			@ linux version
+ 
+
+	bic	r3, r1, #0x000003f0
+	bic	r3, r3, #PTE_TYPE_MASK
+	orr	r3, r3, r2
+	orr	r3, r3, #PTE_EXT_AP0 | 2
+
+	tst	r1, #1 << 4
+	orrne	r3, r3, #PTE_EXT_TEX(1)
+
+	eor	r1, r1, #L_PTE_DIRTY
+	tst	r1, #L_PTE_RDONLY | L_PTE_DIRTY
+	orrne	r3, r3, #PTE_EXT_APX
+
+	tst	r1, #L_PTE_USER
+	orrne	r3, r3, #PTE_EXT_AP1
+#ifdef CONFIG_CPU_USE_DOMAINS
+	@ allow kernel read/write access to read-only user pages
+	tstne	r3, #PTE_EXT_APX
+	bicne	r3, r3, #PTE_EXT_APX | PTE_EXT_AP0
+#endif
+
+	tst	r1, #L_PTE_XN
+	orrne	r3, r3, #PTE_EXT_XN
+
+	tst	r1, #L_PTE_YOUNG
+	tstne	r1, #L_PTE_PRESENT
+	moveq	r3, #0
+
+ ARM(	str	r3, [r0, #2048]! )
+ THUMB(	add	r0, r0, #2048 )
+ THUMB(	str	r3, [r0] )
+	mcr	p15, 0, r0, c7, c10, 1		@ flush_pte
+#endif
+	mov	pc, lr
+ENDPROC(cpu_pj4bv7_set_pte_ext)
+
+cpu_pj4bv7_name:
+	.ascii	"Marvell PJ4Bv7 Processor"
+	.align
+
+/*
+	 * Memory region attributes with SCTLR.TRE=1
+	 *
+	 *   n = TEX[0],C,B
+	 *   TR = PRRR[2n+1:2n]		- memory type
+	 *   IR = NMRR[2n+1:2n]		- inner cacheable property
+	 *   OR = NMRR[2n+17:2n+16]	- outer cacheable property
+	 *
+	 *			n	TR	IR	OR
+	 *   UNCACHED		000	00
+	 *   BUFFERABLE		001	10	00	00
+	 *   WRITETHROUGH	010	10	10	10
+	 *   WRITEBACK		011	10	11	11
+	 *   reserved		110
+	 *   WRITEALLOC		111	10	01	01
+	 *   DEV_SHARED		100	01
+	 *   DEV_NONSHARED	100	01
+	 *   DEV_WC		001	10
+	 *   DEV_CACHED		011	10
+	 *
+	 * Other attributes:
+	 *
+	 *   DS0 = PRRR[16] = 0		- device shareable property
+	 *   DS1 = PRRR[17] = 1		- device shareable property
+	 *   NS0 = PRRR[18] = 0		- normal shareable property
+	 *   NS1 = PRRR[19] = 1		- normal shareable property
+	 *   NOS = PRRR[24+n] = 1	- not outer shareable
+	 */
+.equ	PRRR,	0xff0a81a8
+.equ	NMRR,	0x40e040e0
+
+/* Suspend/resume support: derived from arch/arm/mach-s5pv210/sleep.S */
+.globl	cpu_v7_suspend_size
+.equ	cpu_v7_suspend_size, 4 * 9
+#ifdef CONFIG_PM_SLEEP
+ENTRY(cpu_v7_do_suspend)
+	stmfd	sp!, {r4 - r11, lr}
+	mrc	p15, 0, r4, c13, c0, 0	@ FCSE/PID
+	mrc	p15, 0, r5, c13, c0, 1	@ Context ID
+	mrc	p15, 0, r6, c13, c0, 3	@ User r/o thread ID
+	stmia	r0!, {r4 - r6}
+	mrc	p15, 0, r6, c3, c0, 0	@ Domain ID
+	mrc	p15, 0, r7, c2, c0, 0	@ TTB 0
+	mrc	p15, 0, r8, c2, c0, 1	@ TTB 1
+	mrc	p15, 0, r9, c1, c0, 0	@ Control register
+	mrc	p15, 0, r10, c1, c0, 1	@ Auxiliary control register
+	mrc	p15, 0, r11, c1, c0, 2	@ Co-processor access control
+	stmia	r0, {r6 - r11}
+	ldmfd	sp!, {r4 - r11, pc}
+ENDPROC(cpu_v7_do_suspend)
+
+ENTRY(cpu_v7_do_resume)
+	mov	ip, #0
+	mcr	p15, 0, ip, c8, c7, 0	@ invalidate TLBs
+	mcr	p15, 0, ip, c7, c5, 0	@ invalidate I cache
+	ldmia	r0!, {r4 - r6}
+	mcr	p15, 0, r4, c13, c0, 0	@ FCSE/PID
+	mcr	p15, 0, r5, c13, c0, 1	@ Context ID
+	mcr	p15, 0, r6, c13, c0, 3	@ User r/o thread ID
+	ldmia	r0, {r6 - r11}
+	mcr	p15, 0, r6, c3, c0, 0	@ Domain ID
+	mcr	p15, 0, r7, c2, c0, 0	@ TTB 0
+	mcr	p15, 0, r8, c2, c0, 1	@ TTB 1
+	mcr	p15, 0, ip, c2, c0, 2	@ TTB control register
+	mcr	p15, 0, r10, c1, c0, 1	@ Auxiliary control register
+	mcr	p15, 0, r11, c1, c0, 2	@ Co-processor access control
+	ldr	r4, =PRRR		@ PRRR
+	ldr	r5, =NMRR		@ NMRR
+	mcr	p15, 0, r4, c10, c2, 0	@ write PRRR
+	mcr	p15, 0, r5, c10, c2, 1	@ write NMRR
+	isb
+	mov	r0, r9			@ control register
+	mov	r2, r7, lsr #14		@ get TTB0 base
+	mov	r2, r2, lsl #14
+	ldr	r3, cpu_resume_l1_flags
+	b	cpu_resume_mmu
+ENDPROC(cpu_v7_do_resume)
+cpu_resume_l1_flags:
+	ALT_SMP(.long PMD_TYPE_SECT | PMD_SECT_AP_WRITE | PMD_FLAGS_SMP)
+	ALT_UP(.long  PMD_TYPE_SECT | PMD_SECT_AP_WRITE | PMD_FLAGS_UP)
+#else
+#define cpu_v7_do_suspend	0
+#define cpu_v7_do_resume	0
+#endif
+
+	__CPUINIT
+
+	
+/*
+++ *	__pj4bv7_setup
+ *
+ *	Initialise TLB, Caches, and MMU state ready to switch the MMU
+ *	on.  Return in r0 the new CP15 C1 control register setting.
+ *
+ *	We automatically detect if we have a Harvard cache, and use the
+ *	Harvard cache control instructions insead of the unified cache
+ *	control instructions.
+ *
+ *	This should be able to cover all ARMv7 cores.
+ *
+ *	It is assumed that:
+ *	- cache type register is implemented
+ */
+__pj4bv7_setup:
+	sheeva_pj4b_config
+
+#if 0
+@ CURRENTLY NOT SUPPORTED 
+defined(CONFIG_SMP)
+	mrc	p15, 0, r0, c1, c0, 1		@ Enable SMP/nAMP mode
+	orr	r0, r0, #0x20
+	mcr	p15, 0, r0, c1, c0, 1
+#if 1
+	mrc 	p15, 1, r0, c15, c2, 0
+	orr	r0, r0, #0x2			@ SMP enable 
+	mcr 	p15, 1, r0, c15, c2, 0
+#endif
+#endif
+
+#ifdef CONFIG_SMP
+	ALT_SMP(mrc	p15, 0, r0, c1, c0, 1)
+	ALT_UP(mov	r0, #(1 << 6))		@ fake it for UP
+	tst	r0, #(1 << 6)			@ SMP/nAMP mode enabled?
+	orreq	r0, r0, #(1 << 6) | (1 << 0)	@ Enable SMP/nAMP mode and
+	mcreq	p15, 0, r0, c1, c0, 1		@ TLB ops broadcasting
+#endif
+#ifdef CONFIG_CPU_SHEEVA_PJ4B_PMC_ACCESS_IN_USERMODE
+	@ Enable performance counters user access
+	mrc     p15, 0, r0, c9, c14, 0
+	orr     r0, r0, #0x1
+	mcr     p15, 0, r0, c9, c14, 0
+#endif /* CONFIG_CPU_SHEEVA_PJ4B_PMC_ACCESS_IN_USERMODE */
+adr	r12, __pj4bv7_setup_stack		@ the local stack
+	stmia	r12, {r0-r5, r7, r9, r11, lr}
+	bl	v7_flush_dcache_all
+	ldmia	r12, {r0-r5, r7, r9, r11, lr}
+
+	mrc	p15, 0, r0, c0, c0, 0		@ read main ID register
+	and	r10, r0, #0xff000000		@ ARM?
+	teq	r10, #0x41000000
+	bne	3f
+	and	r5, r0, #0x00f00000		@ variant
+	and	r6, r0, #0x0000000f		@ revision
+	orr	r6, r6, r5, lsr #20-4		@ combine variant and revision
+	ubfx	r0, r0, #4, #12			@ primary part number
+
+	/* Cortex-A8 Errata */
+	ldr	r10, =0x00000c08		@ Cortex-A8 primary part number
+	teq	r0, r10
+	bne	2f
+
+
+#ifdef CONFIG_ARM_ERRATA_430973
+	teq	r5, #0x00100000			@ only present in r1p*
+	mrceq	p15, 0, r10, c1, c0, 1		@ read aux control register
+	orreq	r10, r10, #(1 << 6)		@ set IBE to 1
+	mcreq	p15, 0, r10, c1, c0, 1		@ write aux control register
+#endif
+#ifdef CONFIG_ARM_ERRATA_458693
+	teq	r6, #0x20			@ only present in r2p0
+	mrceq	p15, 0, r10, c1, c0, 1		@ read aux control register
+	orreq	r10, r10, #(1 << 5)		@ set L1NEON to 1
+	orreq	r10, r10, #(1 << 9)		@ set PLDNOP to 1
+	mcreq	p15, 0, r10, c1, c0, 1		@ write aux control register
+#endif
+#ifdef CONFIG_ARM_ERRATA_460075
+	teq	r6, #0x20			@ only present in r2p0
+	mrceq	p15, 1, r10, c9, c0, 2		@ read L2 cache aux ctrl register
+	tsteq	r10, #1 << 22
+	orreq	r10, r10, #(1 << 22)		@ set the Write Allocate disable bit
+	mcreq	p15, 1, r10, c9, c0, 2		@ write the L2 cache aux ctrl register
+#endif
+	b	3f
+	/* Cortex-A9 Errata */
+2:	ldr	r10, =0x00000c09		@ Cortex-A9 primary part number
+	teq	r0, r10
+	bne	3f
+#ifdef CONFIG_ARM_ERRATA_742230
+	cmp	r6, #0x22			@ only present up to r2p2
+	mrcle	p15, 0, r10, c15, c0, 1		@ read diagnostic register
+	orrle	r10, r10, #1 << 4		@ set bit #4
+	mcrle	p15, 0, r10, c15, c0, 1		@ write diagnostic register
+#endif
+#ifdef CONFIG_ARM_ERRATA_742231
+	teq	r6, #0x20			@ present in r2p0
+	teqne	r6, #0x21			@ present in r2p1
+	teqne	r6, #0x22			@ present in r2p2
+	mrceq	p15, 0, r10, c15, c0, 1		@ read diagnostic register
+	orreq	r10, r10, #1 << 12		@ set bit #12
+	orreq	r10, r10, #1 << 22		@ set bit #22
+	mcreq	p15, 0, r10, c15, c0, 1		@ write diagnostic register
+#endif
+#ifdef CONFIG_ARM_ERRATA_743622
+	teq	r6, #0x20			@ present in r2p0
+	teqne	r6, #0x21			@ present in r2p1
+	teqne	r6, #0x22			@ present in r2p2
+	mrceq	p15, 0, r10, c15, c0, 1		@ read diagnostic register
+	orreq	r10, r10, #1 << 6		@ set bit #6
+	mcreq	p15, 0, r10, c15, c0, 1		@ write diagnostic register
+#endif
+#ifdef CONFIG_ARM_ERRATA_751472
+	cmp	r6, #0x30			@ present prior to r3p0
+	mrclt	p15, 0, r10, c15, c0, 1		@ read diagnostic register
+	orrlt	r10, r10, #1 << 11		@ set bit #11
+	mcrlt	p15, 0, r10, c15, c0, 1		@ write diagnostic register
+#endif
+
+3:	mov	r10, #0
+#ifdef HARVARD_CACHE
+	mcr	p15, 0, r10, c7, c5, 0		@ I+BTB cache invalidate
+#endif
+	dsb
+#ifdef CONFIG_MMU
+	mcr	p15, 0, r10, c8, c7, 0		@ invalidate I + D TLBs
+	mcr	p15, 0, r10, c2, c0, 2		@ TTB control register
+			
+#ifdef CONFIG_AURORA_L2_PT_WALK
+	ALT_SMP(orr	r4, r4, #TTB_FLAGS_SMP)
+	ALT_UP(orr	r4, r4, #TTB_FLAGS_UP)
+	ALT_SMP(orr	r8, r8, #TTB_FLAGS_SMP)
+	ALT_UP(orr	r8, r8, #TTB_FLAGS_UP)
+#else
+						@ OC bits in TTB1 register
+	bic	r4, r4, #0x18                   @ DONOT Cache the page table in L2
+#endif
+	mcr	p15, 0, r8, c2, c0, 1		@ load TTB1
+	
+	ldr	r5, =PRRR			@ PRRR
+	ldr	r6, =NMRR			@ NMRR
+	mcr	p15, 0, r5, c10, c2, 0		@ write PRRR
+	mcr	p15, 0, r6, c10, c2, 1		@ write NMRR
+#endif
+	adr	r5, v7_crval
+	ldmia	r5, {r5, r6}
+#ifdef CONFIG_CPU_ENDIAN_BE8
+	orr	r6, r6, #1 << 25		@ big-endian page tables
+#endif
+#ifdef CONFIG_SWP_EMULATE
+	orr     r5, r5, #(1 << 10)              @ set SW bit in "clear"
+	bic     r6, r6, #(1 << 10)              @ clear it in "mmuset"
+#endif
+   	mrc	p15, 0, r0, c1, c0, 0		@ read control register
+	bic	r0, r0, r5			@ clear bits them
+	orr	r0, r0, r6			@ set them
+ THUMB(	orr	r0, r0, #1 << 30	)	@ Thumb exceptions
+	mov	pc, lr				@ return to head.S:__ret
+ENDPROC(__pj4bv7_setup)
+
+	/*   AT
+	 *  TFR   EV X F   I D LR    S
+	 * .EEE ..EE PUI. .T.T 4RVI ZWRS BLDP WCAM
+	 * rxxx rrxx xxx0 0101 xxxx xxxx x111 xxxx < forced
+	 *    1    0 110       0011 1100 .111 1101 < we want
+	 */
+	.type	v7_crval, #object
+v7_crval:
+	crval	clear=0x0120c302, mmuset=0x10c03c7d, ucset=0x00c01c7c
+
+__pj4bv7_setup_stack:
+	.space	4 * 11				@ 11 registers
+__INITDATA
+	.type	v7_processor_functions, #object
+ENTRY(v7_processor_functions)
+	.word	v7_early_abort
+	.word	v7_pabort
+	.word	cpu_pj4bv7_proc_init
+	.word	cpu_pj4bv7_proc_fin
+	.word	cpu_pj4bv7_reset
+	.word	cpu_pj4bv7_do_idle
+	.word	cpu_pj4bv7_dcache_clean_area
+	.word	cpu_pj4bv7_switch_mm
+	.word	cpu_pj4bv7_set_pte_ext
+	.word	cpu_v7_suspend_size
+	.word	cpu_v7_do_suspend
+	.word	cpu_v7_do_resume
+	
+	/*
+	this whole 
+		.word	cpu_v7_suspend_size
+	.word	cpu_v7_do_suspend
+	.word	cpu_v7_do_resume
+	section above is a copy paste from proc-v7.s and need to be revisted
+	*/
+	
+	.size	v7_processor_functions, . - v7_processor_functions
+
+	.section ".rodata"
+	.type	cpu_arch_name, #object
+cpu_arch_name:
+	.asciz	"armv7"
+	.size	cpu_arch_name, . - cpu_arch_name
+
+	.type	cpu_elf_name, #object
+cpu_elf_name:
+	.asciz	"v7"
+	.size	cpu_elf_name, . - cpu_elf_name
+	.align
+
+	.section ".proc.info.init", #alloc, #execinstr
+
+	/*
+	 * Match any ARMv7 processor core.
+	 */
+	.type	__v7_proc_info, #object
+__v7_proc_info:
+	.long	0x000f0000		@ Required ID value
+	.long	0x000f0000		@ Mask for ID
+	
+	ALT_SMP(.long \
+		PMD_TYPE_SECT | \
+		PMD_SECT_AP_WRITE | \
+		PMD_SECT_AP_READ | \
+		PMD_FLAGS_SMP)
+	ALT_UP(.long \
+		PMD_TYPE_SECT | \
+		PMD_SECT_AP_WRITE | \
+		PMD_SECT_AP_READ | \
+		PMD_FLAGS_UP)
+	.long   PMD_TYPE_SECT | \
+		PMD_SECT_XN | \
+		PMD_SECT_AP_WRITE | \
+		PMD_SECT_AP_READ
+	W(b)	__pj4bv7_setup
+	.long	cpu_arch_name
+	.long	cpu_elf_name
+	.long	HWCAP_SWP|HWCAP_HALF|HWCAP_THUMB|HWCAP_FAST_MULT|HWCAP_EDSP|HWCAP_TLS
+	.long	cpu_pj4bv7_name
+	.long	v7_processor_functions
+	.long	v7wbi_tlb_fns
+	.long	v6_user_fns
+	.long	v7_cache_fns
+	.size	__v7_proc_info, . - __v7_proc_info
diff --git a/arch/arm/mm/sheeva_pj4b-macros.S b/arch/arm/mm/sheeva_pj4b-macros.S
new file mode 100644
index 0000000..c467d3b
--- /dev/null
+++ b/arch/arm/mm/sheeva_pj4b-macros.S
@@ -0,0 +1,32 @@
+	.macro	sheeva_pj4b_config
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_4948
+	mrc 	p15, 1, r0, c15, c1, 0
+	orr     r0, r0, #1			@ Disable L0 cache.
+	mcr 	p15, 1, r0, c15, c1, 0
+#endif
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_4786
+	mrc 	p15, 1, r0, c15, c1, 0
+	orr     r0, r0, #(1 << 15)		@ Disable Dual issue for coprocessor instructions
+	mcr 	p15, 1, r0, c15, c1, 0
+#endif
+	mrc 	p15, 1, r0, c15, c1, 1
+	orr     r0, r0, #(1 << 16)		@ Disable data transfer for clean line.
+	mcr 	p15, 1, r0, c15, c1, 1
+
+	mrc 	p15, 1, r0, c15, c1, 2 
+	bic     r0, r0, #(1 << 23)		@ Enable fast LDR.
+	orr     r0, r0, #(1 << 25)		@ Disable interleave between normal write and snoop data intervene.
+	orr     r0, r0, #(1 << 27)		@ Disable Critical Word First feature.
+	orr     r0, r0, #(1 << 29)		@ Disable SO/device/EX non cacheable request to get out outstanding.
+	orr     r0, r0, #(1 << 30) 		@ MBU change the way when it get second linefill
+	mcr 	p15, 1, r0, c15, c1, 2
+
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_5315
+	mrc     p15, 1, r0, c15, c2, 0
+	orr     r0, r0, #(1 << 7)              @ Disable spec read from the MBu/LSU
+        mcr     p15, 1, r0, c15, c2, 0
+#else
+	/* Speculative Prefetch is not enabled here - managed at runtime */
+#endif
+	.endm
+
diff --git a/arch/arm/plat-armada/Kconfig b/arch/arm/plat-armada/Kconfig
new file mode 100644
index 0000000..ea46c73
--- /dev/null
+++ b/arch/arm/plat-armada/Kconfig
@@ -0,0 +1,459 @@
+if PLAT_ARMADA
+
+menu "Armada SoC options"
+	depends on PLAT_ARMADA
+
+#since the Kconfig parser dispatch all source commands, we call the machines Kconfigs from here and
+#not vice versa because otherwise the plat-feroceon Kconfig will be dispatched twice.     
+#if ARCH_FEROCEON_ORION
+#source "arch/arm/mach-feroceon-orion/Kconfig"
+#endif
+
+#if ARCH_FEROCEON_KW
+#source "arch/arm/mach-feroceon-kw/Kconfig"
+#endif
+
+#if ARCH_FEROCEON_KW2
+#source "arch/arm/mach-feroceon-kw2/Kconfig"
+#endif
+
+#if ARCH_FEROCEON_MV78XX0
+#source "arch/arm/mach-feroceon-mv78xx0/Kconfig"
+#endif
+
+
+config JTAG_DEBUG
+        bool "Enable JTAG by disable \"wait for interrupt\"."
+	depends on MV88F6500 || MV88F6281 || MV78XX0
+        default n
+        ---help---
+           Enable the JTAG debugger taking over the CPU by disabling "wait for interrupt" idle loop."
+
+
+menu "Armada SoC Included Features"
+
+config MV_INCLUDE_PEX
+	bool "PCI Express Support"
+	depends on PCI && (MV88F6500 || MV88F6281 || MV78XX0 || ARMADA_XP)
+	default y
+	select MV_PEX_2_1X4
+	select MV_PEX_3_1X4
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+choice
+	prompt "PEX-0 Mode"
+	depends on MV_INCLUDE_PEX
+	default MV_PEX_0_4X1
+
+config MV_PEX_0_4X1
+	bool "Quad X1 interfaces"
+
+config MV_PEX_0_1X4
+	bool "Single X4 interface"
+endchoice
+
+choice
+	prompt "PEX-1 Mode"
+	depends on MV_INCLUDE_PEX
+	default MV_PEX_1_4X1
+
+config MV_PEX_1_4X1
+	bool "Quad X1 interfaces"
+
+config MV_PEX_1_1X4
+	bool "Single X4 interface"
+endchoice
+
+config MV_PEX_2_1X4
+	bool "PEX-2 in 1x4 Mode"
+	depends on MV_INCLUDE_PEX
+
+config MV_PEX_3_1X4
+	bool "PEX-3 in 1x4 Mode"
+	depends on MV_INCLUDE_PEX
+
+config MV_INCLUDE_PCI
+	bool "PCI Support"
+	depends on PCI && (MV88F6500 || MV88F6281 || MV78XX0 || ARMADA_XP)
+	default n
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+config MV_INCLUDE_USB
+	bool "USB Support"
+	depends on MV88F6500 || MV88F6281 || MV78XX0 || ARMADA_XP
+	default y
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+config MV_INCLUDE_XOR
+	bool "XOR Support"
+	depends on MV88F6500 || MV88F6281 || MV78XX0 || ARMADA_XP
+	default y
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+config MV_INCLUDE_CESA
+	bool "CESA Support"
+	depends on MV88F6500 || MV88F6082 || MV88F6183 || MV88F6281 || MV78XX0 || ARMADA_XP
+	default y
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+config MV_INCLUDE_NFC
+	bool "Nand Flash Controller Support"
+	depends on MV88F6500 || ARMADA_XP
+	default y
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+config MV_INCLUDE_LEGACY_NAND
+	bool "Legacy NAND Support"
+	depends on MV88F6500 || MV88F6281 || MV78XX0 || ARMADA_XP
+	default y
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+config MV_INCLUDE_INTEG_SATA
+	bool "Integrated SATA Support"
+	depends on MV88F6500 || MV88F6281 || MV78XX0 || ARMADA_XP
+	default y
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+config MV_INCLUDE_TDM
+	bool "Integrated TDM Support"
+	depends on MV88F6500 || MV88F6281 || MV78XX0 || ARMADA_XP
+	default y
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+config MV_INCLUDE_GIG_ETH
+	bool "Giga Ethernet Support"
+	depends on MV88F6500 || MV88F6281 || MV78XX0 || ARMADA_XP
+	default y
+
+config MV_INCLUDE_SPI
+	bool "SPI Support"
+	depends on MV88F6500 || MV88F6281 || (MV78XX0 && !MV78XX0_Z0) || ARMADA_XP
+	default y
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+config MV_INCLUDE_NOR
+	bool "NOR Support"
+	depends on MV88F6500 || MV88F6281 || (MV78XX0 && !MV78XX0_Z0) || ARMADA_XP
+	default y
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+
+config MV_INCLUDE_SDIO
+	bool "SDIO Support"
+	depends on MV88F6500 || MV88F6281 || ARMADA_XP
+	default y
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+config MV_INCLUDE_TS
+	bool "TSU Support"
+	depends on MV88F6500 || MV88F6281
+	default n
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+config MV_INCLUDE_PON
+	bool "PON Support"
+	depends on MV88F6500
+	default y
+        ---help---
+        Please don't change this configs unless you know what you are doing.
+
+config MV_INCLUDE_SWITCH
+        bool "Ethernet Switch Support"
+        depends on MV88F6500 || MV88F6281 || MV78XX0 || ARMADA_XP
+        default y
+
+endmenu
+
+config MV_GPP_MAX_PINS
+	int
+	default 32 if MV78XX0
+	default 64 if MV88F6281
+	default 70 if MV88F6500
+	default 67 if ARMADA_XP
+
+	
+config MV_DCACHE_SIZE
+	hex
+	default 0x8000 if MV78XX0 || ARMADA_XP
+	default 0x4000 if MV88F6500 || MV88F6281
+
+config MV_ICACHE_SIZE
+	hex
+	default 0x8000 if MV78XX0 || ARMDAD_XP
+	default 0x4000 if MV88F6500 || MV88F6281
+	          
+menu "Armada SoC MTD support"
+
+config MV_FLASH_CTRL
+	bool
+	default n
+
+config MV_INCLUDE_SFLASH_MTD
+    bool "Marvell support for MTD SPI flash device"
+    select MV_FLASH_CTRL
+    depends on MTD && MV_INCLUDE_SPI
+   	default y
+
+config MV_SPI_BOOT
+	bool "Marvell boot support from MTD SPI device"
+	depends on MV_INCLUDE_SFLASH_MTD
+	default n
+	---help---
+	Choose this option if SPI MTD is the system boot device.
+	This option controls the various flash types support in the board
+	device chip-select information structure under mvBoardEnvSpec.c
+                    
+config MV_INCLUDE_MFLASH_MTD
+    bool "Marvell support for MTD Marvell flash device"
+    select MV_FLASH_CTRL
+    depends on MTD && MV_INCLUDE_INTEG_MFLASH && !ARMADA_XP
+   	default y
+
+config MTD_NAND_LNC
+	bool "MTD driver for the Legacy NAND controller"
+	depends on MTD && MV_INCLUDE_LEGACY_NAND
+	default y
+
+config MTD_NAND_LNC_BOOT
+	bool "Marvell boot support from MTD NAND device"
+	depends on MTD_NAND_LNC
+	default n
+	---help---
+	Choose this option if NAND MTD is the system boot device.	            
+	This option controls the various flash types support in the board
+	device chip-select information structure under mvBoardEnvSpec.c
+
+config MTD_NAND_LNC_RS_ECC
+	bool "Support Reed-Solomon 4-bit ECC algorithm for Legacy Nand Controller"
+	depends on MTD_NAND_LNC
+	default y
+	---help---
+	Choose this option to support Reed-Solomon 4-bit ECC algorithm.
+	Note this option also requires support by low-level boot loader.
+
+config MTD_NAND_LNC_8BYTE_READ
+	bool "Support 8B burst Read for Legacy Nand Controller"
+	depends on MTD_NAND_LNC
+	default n
+	---help---
+	Choose this option to support NAND 8 Byte Read burst algorithm.
+
+config MTD_NAND_NFC
+        tristate "MTD driver for the Armada Nand Flash Controller"
+        depends on MTD_NAND && MV_INCLUDE_NFC
+	default y
+        help
+          This enables the driver for the NAND flash controller found in
+          the Marvell Armada SoC devices.
+
+config MTD_NAND_NFC_GANG_SUPPORT
+        bool "NAND Ganged mode support for the NFC"
+        depends on MTD_NAND_NFC
+	default y
+        help
+          This option enables the support for 2x8bit ganged mode in
+          Marvell's NFC HAL driver and the MTD stack.
+
+config MTD_NAND_NFC_MLC_SUPPORT
+        bool "NAND MLC devices support for the NFC"
+        depends on MTD_NAND_NFC
+	default y
+	help
+          This option allows support for Nand devices with non-standard
+          page/oob layout. These devices are detected incorrectly with
+          standard autodetection mechanism based on the READ_ID command.
+
+config MTD_NAND_NFC_INIT_RESET
+        bool "NAND Enable Reset on Initialization"
+        depends on MTD_NAND_NFC
+	default n
+	help
+          This option forces NAND reset command on initialization. This
+	  is required by certain NAND vendors (Micron).
+
+endmenu
+
+choice
+	prompt "SoC USB Mode"
+	depends on MV_INCLUDE_USB
+	default MV_USB_HOST
+
+config MV_USB_HOST
+	bool "Support for USB Host"
+	---help---
+	Choosing this option will configure on chip USB Controller to work in Host mode
+
+config MV_USB_DEVICE
+	bool "Support for USB Device"
+	---help---
+	Choosing this option will configure on chip USB Controller to work in Device mode
+endchoice
+
+
+config ARCH_SUPPORTS_BIG_ENDIAN
+	bool
+	default y
+
+config USE_DSP
+	bool "Use pld/ldrd/strd arm DSP instructions"
+	depends on !ARMADA_XP
+	default n
+
+choice
+	prompt "Protect from speculative instruction prefetch"
+	depends on CACHE_FEROCEON_L2
+	default MV_SP_I_FTCH_DB_INV
+
+config MV_SP_I_FTCH_DB_INV
+	bool "Double invalidate for DMA buffers"
+	---help---
+	Choosing this option will add L2 invalidate for DMA recieved buffers before processing it,
+	This is done through the pci_unmap_sg/page/single APIs.
+
+config MV_SP_I_FTCH_LCK_L2_ICACHE
+	bool "Lock L2 I-cache"
+	---help---
+	Choosing this option will lock L2 Icache.
+
+config MV_SP_I_FTCH_NONE
+	bool "Ignore"
+
+endchoice
+
+config  FEROCEON_PROC
+	bool "Support for MV-shell proc file system"
+	depends on PROC_FS
+	---help---	
+	  Choosing this option will enable you to use the MV-shell through the Proc
+	  File system.
+	  The MV-shell is a debug utility which can be run from the shell.
+
+config  MV_PMU_PROC
+        bool "Support procfs control on Power-Management features"
+        depends on PROC_FS
+        ---help---
+          Choose this option to enable control over the power-management features through
+          the proc file-system.
+
+config  MV_DBG_TRACE
+	bool "Enable tracing utility"
+	default n
+	---help---
+	  Choosing this debug option will cause some kernel modules to log operations into
+	  a cyclic buffer and dump them on failures. Enabling this feature decreases performance.
+
+config  MV_CPU_PERF_CNTRS
+        bool "CPU Performance counters support"
+        default n
+        ---help---
+        Choosing this option will enable you to use CPU Performance counters
+
+config  MV_CPU_L2_PERF_CNTRS
+        bool "CPU L2 Performance counters support"
+        default n
+        ---help---
+        Choosing this option will enable you to use CPU L2 Performance counters
+
+menu "Soc DMA accelerations"
+
+source arch/arm/plat-armada/mv_drivers_lsp/mv_xor/Kconfig
+
+source arch/arm/plat-armada/mv_drivers_lsp/mv_dma/Kconfig
+
+endmenu
+
+
+menu "SoC Networking support"
+depends on MV_INCLUDE_GIG_ETH
+
+config MV_ETHERNET
+        bool "Networking support"
+	depends on MV_INCLUDE_GIG_ETH
+	default y
+        ---help---
+        Choose this option to support Marvell Gigabit Ethernet Controller 
+
+if MV_ETHERNET
+
+choice 
+        prompt "GbE Mode"
+        depends on MV_INCLUDE_GIG_ETH 
+        default MV_ETH_LEGACY
+
+config MV_ETH_LEGACY
+        bool "Legacy mode "
+        ---help---
+
+config MV_ETH_NETA
+        bool "Acceleration mode "
+	depends on ARCH_FEROCEON_KW2 || ARCH_ARMADA_XP
+        ---help---
+
+endchoice
+
+
+if MV_ETH_LEGACY
+source arch/arm/plat-armada/mv_drivers_lsp/mv_network/Kconfig
+endif
+
+if MV_ETH_NETA
+source arch/arm/plat-armada/mv_drivers_lsp/mv_neta/Kconfig
+endif
+
+endif # MV_ETHERNET
+endmenu # "SoC Networking support"
+
+source arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Kconfig
+
+source arch/arm/plat-armada/mv_drivers_lsp/mv_phone/Kconfig
+
+
+#source arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/Kconfig
+
+source arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/Kconfig
+
+source arch/arm/plat-armada/mv_drivers_lsp/mv_pon/Kconfig
+
+
+config  SCSI_MVSATA
+	tristate "Support for Marvell Sata Adapters"
+	depends on ( MV_INCLUDE_INTEG_SATA && SCSI ) || ( PCI && SCSI )
+	---help---
+	  Choosing this option will enable you to use the Marvell Sata
+	  adapters support with emulation as SCSI adapters.
+	  Note that the kernel scsi subsystem must be chosen too.
+
+source arch/arm/plat-armada/mv_drivers_lsp/mv_sata/Kconfig
+
+config PCIE_VIRTUAL_BRIDGE_SUPPORT
+        bool "Enable virtual bridge on PCIe"
+        depends on PCI
+        ---help---
+        Enable virtual bridge module to support PCIe switches
+
+config MV_UART_POLLING_MODE
+        bool "Enable Polling mode for UART driver"
+        depends on ARCH_FEROCEON_KW2
+	default y
+        ---help---
+        Configure UART driver to work in polling mode.
+
+endmenu
+
+
+endif
+
+
diff --git a/arch/arm/plat-armada/Makefile b/arch/arm/plat-armada/Makefile
new file mode 100644
index 0000000..0ee6d82
--- /dev/null
+++ b/arch/arm/plat-armada/Makefile
@@ -0,0 +1,15 @@
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+# This will never compile, because DUMMY will never by defined.
+obj-$(DUMMY)   				:= dummy.o
+
+obj-$(CONFIG_SHEEVA_DEEP_IDLE)		+= cpuidle.o armadaxp_suspend.o power.o
+obj-$(CONFIG_HOTPLUG_CPU)               += hotplug.o power.o
+obj-$(CONFIG_ARCH_ARMADA_XP)		+= pmu.o
+obj-$(CONFIG_PCI_MSI)			+= msi.o
diff --git a/arch/arm/plat-armada/armadaxp_suspend.S b/arch/arm/plat-armada/armadaxp_suspend.S
new file mode 100644
index 0000000..d692ff3
--- /dev/null
+++ b/arch/arm/plat-armada/armadaxp_suspend.S
@@ -0,0 +1,189 @@
+/*
+ * arch/arm/plat-armada/armadaxp_suspend.S
+ *
+ * CPU idle low level implementation for Marvell ARMADA-XP SoCs
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ *
+ */
+#include <linux/linkage.h>
+#include <asm/assembler.h>
+#include <mach/armadaxp.h>
+
+/*
+* armadaxp_cpu_suspend: enter cpu deepIdle state
+* input:
+*/
+ENTRY(armadaxp_cpu_suspend)
+	/* Save ARM registers */
+	stmfd	sp!, {r4-r12, lr}		@ save registers on stack
+        /*
+         * Save the CP15 context
+         */
+        mrc     p15, 0, r2, c1, c0, 0           @ save CP15 - CR
+        mrc     p15, 0, r3, c3, c0, 0           @ save CP15 - DACR
+        mrc     p15, 0, r4, c13, c0, 0          @ save CP15 - FCSE
+        mrc     p15, 0, r5, c2, c0, 0           @ save CP15 - TTBR
+        mrc     p15, 0, r6, c13, c0, 1          @ save CP15 - context ID
+        mrc     p15, 1, r7, c15, c1, 0          @ save CP15 - extra features
+        mrc     p15, 0, r8, c1, c0, 1           @ save CP15 - Aux CR
+        mov     r9, r13                         @ save resume SP
+        stmfd   sp!, {r2-r9}
+	mrc	p15, 1, r3, c15, c2, 0		@ save CP15 - Aux Func Modes Ctrl 0
+	mrc	p15, 1, r4, c15, c1, 2		@ save CP15 - Aux Debug Modes Ctrl 2
+        mrc     p15, 1, r5, c15, c1, 1          @ save CP15 - Aux Debug Modes Ctrl 1
+        mrc     p15, 0, r6, c9, c14, 0          @ save CP15 - PMC
+        mrc     p15, 0, r7, c10, c2, 0          @ save CP15 - PRRR
+        mrc     p15, 0, r8, c10, c2, 1          @ save CP15 - NMRR
+	
+        stmfd   sp!, {r3-r8}
+
+	/*
+	* TODO: Save Debug Registers
+	*/
+
+        /*
+	* Save the physical address of the resume SP
+	*/
+        mov     r0, sp
+        bl      suspend_phys_addr
+        ldr     r1, =suspend_saved_sp
+#ifdef CONFIG_SMP
+        mrc     p15, 0, r2, c0, c0, 5
+        and     r2, r2, #15
+        str     r0, [r1, r2, lsl #2]
+#else
+        str     r0, [r1]
+#endif
+	/*
+	* Flush L1 DCache
+	*/
+#ifdef CONFIG_CPU_V6
+	bl v6_flush_kern_cache_all
+#elif CONFIG_CPU_V7
+	bl v7_flush_kern_cache_all
+#else
+#error "CPU Arch version not defined!\n"
+#endif
+	bl armadaxp_fabric_prepare_deepIdle
+
+	/*
+	* Issue a Data Synchronization Barrier instruction to ensure that all
+	* state saving has been	completed.
+	*/
+#ifdef CONFIG_CPU_V6
+	mcr     p15, 0, r0, c7, c10, 4	@ Data Synchronization Barrier
+#elif defined (CONFIG_CPU_V7)
+	dsb				@ Data Synchronization Barrier
+#endif
+	ldr	r2, =(SDRAM_OPERATION_REG - INTER_REGS_BASE)
+	ldr	r0, =INTER_REGS_BASE
+	orr	r2, r2, r0
+	ldr	r0, [r2]
+#ifdef CONFIG_CPU_BIG_ENDIAN
+	ldr	r3, =0x07000000
+#else
+	ldr	r3, =0x00000007
+#endif
+	orr	r0, r0, r3
+	str	r0, [r2]
+#ifdef CONFIG_CPU_V6
+	mcr     p15, 0, r1, c7, c0, 4	@ wait for interrupt
+#elif defined (CONFIG_CPU_V7)
+	wfi				@ wait for interrupt
+#endif
+	/* if we reach this point then deepIdle returned from regret mode and cpu
+	* state retained
+	*/
+
+	mov	r0, #1
+	ldmfd   sp!, {r3-r8}
+	ldmfd   sp!, {r2-r9}
+	
+	ldmfd   sp!, {r4-r12, pc}
+ENDPROC(armadaxp_cpu_suspend)
+
+
+ENTRY(armadaxp_cpu_resume)
+
+#ifdef CONFIG_CPU_ENDIAN_BE32
+        /* convert CPU to big endian */
+        .word 0x100f11ee /* mrc p15, 0, r0, c1, c0 */
+        .word 0x800080e3 /* orr r0, r0, #0x80 */
+        .word 0x100f01ee /* mcr p15, 0, r0, c1, c0 */
+#endif
+#ifdef CONFIG_CPU_ENDIAN_BE8
+                setend  be
+#endif
+//	mcr	p15, 0, r0, c8, c7, 0   @ flush I,D TLBs
+//	mcr     p15, 0, r0, c7, c6, 0   @ invalidate D cache
+	
+//wait:	
+//	ldr	r0, =0xD0018100
+//	ldr	r1, =0x8000000
+//	str	r1, [r0]                        @ set 7seg
+//	ldr	r1, [r0]
+//	b 	wait
+
+#ifdef CONFIG_SMP
+        adr     r0, suspend_saved_sp
+        mrc     p15, 0, r1, c0, c0, 5
+        and     r1, r1, #15
+        ldr     r0, [r0, r1, lsl #2]    @ stack phys addr
+#else
+        ldr     r0, suspend_saved_sp            @ stack phys addr
+#endif
+
+	ldmfd   r0!, {r3-r8}
+
+	mcr     p15, 1, r3, c15, c2, 0          @ restore CP15 - Aux Func Modes Ctrl 0
+	mcr     p15, 1, r4, c15, c1, 2          @ restore CP15 - Aux Debug Modes Ctrl 2
+	mcr     p15, 1, r5, c15, c1, 1          @ restore CP15 - Aux Debug Modes Ctrl 1
+	mcr     p15, 0, r6, c9, c14, 0          @ restore CP15 - PMC
+	mcr     p15, 0, r7, c10, c2, 0          @ restore CP15 - PRRR
+	mcr     p15, 0, r8, c10, c2, 1          @ restore CP15 - NMRR
+	ldmfd   r0!, {r2-r9}
+	mcr	p15, 0, r8, c1, c0, 1		@ restore CP15 - Aux CR
+	mcr	p15, 1, r7, c15, c1, 0		@ restore CP15 - extra features
+	mcr	p15, 0, r4, c13, c0, 0		@ restore CP15 - FCSE
+	mcr	p15, 0, r3, c3, c0, 0		@ restore CP15 - DACR
+
+	/* load identity page table */
+	ldr	r3, identity_page_table_phys
+	mcr	p15, 0, r3, c2, c0, 0		@ set CP15 - TTBR
+	mov	r3, #0
+	mcr	p15, 0, r3, c13, c0, 1          @ set 0 in CP15 - context ID
+	mcr	p15, 0, r2, c1, c0, 0		@ restore CP15 - CR  @enable mmu
+	mrc     p15, 0, r3, c0, c0, 0           @ read id reg
+	ldr	r3, resume2
+	mov	pc, r3
+ENDPROC(armadaxp_cpu_resume)
+
+	/* stage 2 of the resume function that runs from PAGE_OFFSET virtual space */
+ENTRY(armadaxp_cpu_resume2)	
+	/* restore original page table*/
+	mcr	p15, 0, r5, c2, c0, 0		@ restore CP15 - TTBR
+	mcr	p15, 0, r6, c13, c0, 1          @ restore CP15 - context ID
+	mcr     p15, 0, r0, c8, c7, 0           @ TLB invalidate
+	mov	sp, r9				@ restore virtual sp
+	mov	r0, #0
+	ldmfd   sp!, {r4-r12, pc}               @ restore SVC registers
+
+ENDPROC(armadaxp_cpu_resume2)
+	
+resume2:
+	.long	armadaxp_cpu_resume2
+
+suspend_saved_sp:
+#ifdef CONFIG_SMP
+	.rept	CONFIG_NR_CPUS
+#endif
+	.long	0	@ physical SP saved here
+#ifdef CONFIG_SMP
+	.endr
+#endif
+	.global identity_page_table_phys
+identity_page_table_phys:
+	.long	0
diff --git a/arch/arm/plat-armada/cpuidle.c b/arch/arm/plat-armada/cpuidle.c
new file mode 100644
index 0000000..3fb4eab
--- /dev/null
+++ b/arch/arm/plat-armada/cpuidle.c
@@ -0,0 +1,333 @@
+/*
+ * arch/arm/plat-armada/cpuidle.c
+ *
+ * CPU idle implementation for Marvell ARMADA-XP SoCs
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ *
+ */
+//#define DEBUG
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/platform_device.h>
+#include <linux/proc_fs.h>
+#include <linux/cpuidle.h>
+#include <asm/io.h>
+#include <asm/proc-fns.h>
+#include <plat/cache-aurora-l2.h>
+#include <mach/smp.h>
+#include <asm/vfp.h>
+#include <asm/cacheflush.h>
+#include <asm/tlbflush.h>
+#include <asm/pgalloc.h>
+#include <asm/sections.h>
+
+#include "ctrlEnv/sys/mvCpuIfRegs.h"
+#include "mvOs.h"
+#include "../power.h"
+
+unsigned long suspend_phys_addr(void * physaddr)
+{
+        return virt_to_phys(physaddr);
+}
+
+extern u32 identity_page_table_phys;
+
+/*
+static inline void identity_mapping_add(pgd_t *pgd, unsigned long start,
+					unsigned long end)
+{
+        unsigned long addr, prot;
+        pmd_t *pmd;
+
+        prot = PMD_TYPE_SECT | PMD_SECT_AP_WRITE;
+
+        for (addr = start & PGDIR_MASK; addr < end;) {
+                pmd = pmd_offset(pgd + pgd_index(addr), addr);
+                pmd[0] = __pmd(addr | prot);
+                addr += SECTION_SIZE;
+                pmd[1] = __pmd(addr | prot);
+                addr += SECTION_SIZE;
+                flush_pmd_entry(pmd);
+                outer_clean_range(__pa(pmd), __pa(pmd + 1));
+        }
+}
+
+static inline void identity_mapping_del(pgd_t *pgd, unsigned long start,
+					unsigned long end)
+{
+        unsigned long addr;
+        pmd_t *pmd;
+
+        for (addr = start & PGDIR_MASK; addr < end; addr += PGDIR_SIZE) {
+                pmd = pmd_offset(pgd + pgd_index(addr), addr);
+                pmd[0] = __pmd(0);
+                pmd[1] = __pmd(0);
+                clean_pmd_entry(pmd);
+                outer_clean_range(__pa(pmd), __pa(pmd + 1));
+        }
+}
+*/
+/*
+ * Allocate initial page tables to allow the CPU to
+ * enable the MMU safely.  This essentially means a set
+ * of our "standard" page tables, with the addition of
+ * a 1:1 mapping for the physical address of the kernel.
+ */
+
+static int build_identity_page_table(void)
+{
+	pgd_t *pgd = pgd_alloc(&init_mm);
+	if (!pgd)
+		return -ENOMEM;
+
+	if (PHYS_OFFSET != PAGE_OFFSET) {
+		identity_mapping_add(pgd, __pa(_stext), __pa(_etext));
+		identity_mapping_add(pgd, __pa(_sdata), __pa(_edata)); /* is this needed?*/
+	}
+	identity_page_table_phys = virt_to_phys(*pgd);
+	return 0;
+}
+
+int pm_disable = 0;
+static int __init pm_enable_setup(char *__unused)
+{
+	pm_disable = 1;
+	return 1;
+}
+
+__setup("pm_disable", pm_enable_setup);
+
+
+#define ARMADAXP_IDLE_STATES	2
+
+struct cpuidle_driver armadaxp_idle_driver = {
+	.name =         "armadaxp_idle",
+	.owner =        THIS_MODULE,
+};
+
+DEFINE_PER_CPU(struct cpuidle_device, armadaxp_cpuidle_device);
+
+static void armadaxp_smp_wfi(void)
+{
+	unsigned int processor_id = hard_smp_processor_id();
+	/* prepare for WFI */
+	armadaxp_smp_prepare_idle(processor_id);
+	asm volatile(
+		"       mcr     p15, 0, %0, c7, c10, 4  @ @ DWB - WFI may enter a low-power mode\n"
+		"       mcr     p15, 0, %0, c7, c0, 4   @ wait for interrupt\n"
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_4742
+			"	mcr     p15, 0, %0, c7, c10, 4          @barrier\n"
+#endif
+		:
+		: "r" (0)
+		: "cc");
+
+	armadaxp_smp_restore_idle(processor_id);
+}
+/*
+ * Enter the DEEP IDLE mode (power off CPU only)
+ */
+void armadaxp_deepidle(void)
+{
+	pr_debug("armadaxp_deepidle: Entering DEEP IDLE mode.\n");
+
+#ifdef CONFIG_IWMMXT
+	/* force any iWMMXt context to ram **/
+	if (elf_hwcap & HWCAP_IWMMXT)
+		iwmmxt_task_disable(NULL);
+#endif
+
+#if defined(CONFIG_VFP)
+        vfp_save();
+#endif
+	aurora_l2_pm_enter();
+//	armadaxp_fabric_prepare_deepIdle();
+
+	/* none zero means deepIdle wasn't entered and regret event happened */
+	armadaxp_cpu_suspend();
+	cpu_init();
+
+	armadaxp_fabric_restore_deepIdle();
+
+	aurora_l2_pm_exit();
+#if defined(CONFIG_VFP)
+	vfp_restore();
+#endif
+	pr_debug("armadaxp_deepidle: Exiting DEEP IDLE.\n");
+}
+
+/* Actual code that puts the SoC in different idle states */
+static int armadaxp_enter_idle(struct cpuidle_device *dev,
+			       struct cpuidle_state *state)
+{
+	struct timeval before, after;
+	int idle_time;
+
+	local_irq_disable();
+	local_fiq_disable();
+	do_gettimeofday(&before);
+	if (state == &dev->states[0]) {
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_BTS61
+		armadaxp_smp_wfi();
+#else
+		/* Wait for interrupt state */
+		cpu_do_idle();
+#endif
+
+	}
+	else if (state == &dev->states[1]) {
+		/* Deep Idle */
+		armadaxp_deepidle();
+	}
+	do_gettimeofday(&after);
+	local_fiq_enable();
+	local_irq_enable();
+	idle_time = (after.tv_sec - before.tv_sec) * USEC_PER_SEC +
+			(after.tv_usec - before.tv_usec);
+#if 0
+	if ( state == &dev->states[1])
+	printk(KERN_INFO "%s: state %d idle time %d\n", __func__, state == &dev->states[0]? 0 : 1,
+	       idle_time);
+#endif
+	return idle_time;
+}
+
+#ifdef CONFIG_MV_PMU_PROC
+static int device_registered;
+struct proc_dir_entry *cpu_idle_proc;
+
+static int mv_cpu_idle_write(struct file *file, const char *buffer,
+			     unsigned long count, void *data)
+{
+	struct cpuidle_device *	device = &per_cpu(armadaxp_cpuidle_device, smp_processor_id());
+
+        if (!strncmp (buffer, "enable", strlen("enable"))) {
+                if(device_registered == 0) {
+                        device_registered = 1;
+                        if (cpuidle_register_device(device)) {
+                                printk(KERN_ERR "mv_cpu_idle_write: Failed registering\n");
+                                return -EIO;
+                        }
+                }
+                cpuidle_enable_device(device);
+        } else if (!strncmp (buffer, "disable", strlen("disable"))) {
+                cpuidle_disable_device(device);
+        } else if (!strncmp (buffer, "test", strlen("test"))) {
+
+
+//for debug
+		disable_irq(IRQ_AURORA_TIMER0);
+		disable_irq(IRQ_AURORA_GBE0_FIC);
+		disable_irq(IRQ_AURORA_SDIO);
+		disable_irq(IRQ_AURORA_SATA0);
+//		disable_irq(IRQ_AURORA_UART0);
+
+                printk(KERN_INFO "Press any key to leave deep idle:");
+//		cpu_do_idle();
+		armadaxp_deepidle();
+
+
+		enable_irq(IRQ_AURORA_TIMER0);
+		enable_irq(IRQ_AURORA_GBE0_FIC);
+		enable_irq(IRQ_AURORA_SDIO);
+		enable_irq(IRQ_AURORA_SATA0);
+//		enable_irq(IRQ_AURORA_UART0);
+
+        }
+
+        return count;
+}
+
+static int mv_cpu_idle_read(char *buffer, char **buffer_location, off_t offset,
+			    int buffer_length, int *zero, void *ptr)
+{
+        if (offset > 0)
+                return 0;
+        return sprintf(buffer, "enable - Enable CPU Idle framework.\n"
+                                "disable - Disable CPU idle framework.\n"
+		       "test - Manually enter CPU Idle state, exit by ket stroke (DEBUG ONLY).\n");
+
+}
+
+#endif /* CONFIG_MV_PMU_PROC */
+
+/* 
+ * Register Armadaxp IDLE states
+ */
+int armadaxp_init_cpuidle(void)
+{
+	struct cpuidle_device *device;
+	int i;
+
+	printk("Initializing Armada-XP CPU power management ");
+
+	if (build_identity_page_table()) {
+		printk(KERN_ERR "armadaxp_init_cpuidle: Failed to build identity page table\n");
+                return -ENOMEM;
+        }
+
+	cpuidle_register_driver(&armadaxp_idle_driver);
+
+	armadaxp_fabric_setup_deepIdle();
+
+#ifdef CONFIG_MV_PMU_PROC
+	/* Create proc entry. */
+	cpu_idle_proc = create_proc_entry("cpu_idle", 0666, NULL);
+	cpu_idle_proc->read_proc = mv_cpu_idle_read;
+	cpu_idle_proc->write_proc = mv_cpu_idle_write;
+	cpu_idle_proc->nlink = 1;
+#endif
+	if (pm_disable) {
+		printk(KERN_INFO " (DISABLED)\n");
+		return 0;
+	}
+
+	for_each_online_cpu(i) {
+		device = &per_cpu(armadaxp_cpuidle_device, i);
+		device->cpu = i;
+#ifdef CONFIG_SMP
+		/* in smp mode, only wfi supported */
+		device->state_count = 1;
+
+		/* Wait for interrupt state */
+		device->states[0].enter = armadaxp_enter_idle;
+		device->states[0].exit_latency = 1;             /* Few CPU clock cycles */
+		device->states[0].target_residency = 1000;
+		device->states[0].flags = CPUIDLE_FLAG_TIME_VALID;
+		strcpy(device->states[0].name, "WFI");
+		strcpy(device->states[0].desc, "Wait for interrupt");
+#else
+		device->state_count = ARMADAXP_IDLE_STATES;
+
+		/* Wait for interrupt state */
+		device->states[0].enter = armadaxp_enter_idle;
+		device->states[0].exit_latency = 1;             /* Few CPU clock cycles */
+		device->states[0].target_residency = 10;
+		device->states[0].flags = CPUIDLE_FLAG_TIME_VALID;
+		strcpy(device->states[0].name, "WFI");
+		strcpy(device->states[0].desc, "Wait for interrupt");
+
+		/* Deep Idle Mode */
+		device->states[1].enter = armadaxp_enter_idle;
+		device->states[1].exit_latency = 100;
+		device->states[1].target_residency = 1000;
+		device->states[1].flags = CPUIDLE_FLAG_TIME_VALID;
+		strcpy(device->states[1].name, "DEEP IDLE");
+		strcpy(device->states[1].desc, "Deep Idle");
+#endif
+		if (cpuidle_register_device(device)) {
+			printk(KERN_ERR "armadaxp_init_cpuidle: Failed registering\n");
+			return -EIO;
+		}
+	}
+
+	printk("\n");
+
+	return 0;
+}
+
+device_initcall(armadaxp_init_cpuidle);
diff --git a/arch/arm/plat-armada/hotplug.c b/arch/arm/plat-armada/hotplug.c
new file mode 100644
index 0000000..7ed8c78
--- /dev/null
+++ b/arch/arm/plat-armada/hotplug.c
@@ -0,0 +1,125 @@
+/*
+ *  linux/arch/arm/plat-armada/hotplug.c
+ *
+ *  Copyright (C) 2002 ARM Ltd.
+ *  All Rights Reserved
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/smp.h>
+#include <linux/completion.h>
+
+#include <asm/cacheflush.h>
+#include <../power.h>
+
+extern volatile int pen_release;
+
+static DECLARE_COMPLETION(cpu_killed);
+
+static inline void cpu_enter_lowpower(void)
+{
+
+	flush_cache_all();
+
+	armadaxp_smp_prepare_idle(hard_smp_processor_id());
+}
+
+static inline void cpu_leave_lowpower(void)
+{
+	armadaxp_smp_restore_idle(hard_smp_processor_id());
+}
+
+static inline void platform_do_lowpower(unsigned int cpu)
+{
+	/*
+	 * there is no power-control hardware on this platform, so all
+	 * we can do is put the core into WFI; this is safe as the calling
+	 * code will have already disabled interrupts
+	 */
+	for (;;) {
+		/*
+		 * here's the WFI
+		 */
+		asm volatile(
+			"       mcr     p15, 0, %0, c7, c10, 4  @ @ DWB - WFI may enter a low-power mode\n"
+			"       mcr     p15, 0, %0, c7, c0, 4   @ wait for interrupt\n"
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_4742
+			"	mcr     p15, 0, %0, c7, c10, 4          @barrier\n"
+#endif
+			:
+			: "r" (0)
+			: "cc");
+
+		if (pen_release == cpu) {
+			/*
+			 * OK, proper wakeup, we're done
+			 */
+			//		printk("%s %d\n", __func__, __LINE__);
+			break;
+		}
+
+		/*
+		 * getting here, means that we have come out of WFI without
+		 * having been woken up - this shouldn't happen
+		 *
+		 * The trouble is, letting people know about this is not really
+		 * possible, since we are currently running incoherently, and
+		 * therefore cannot safely call printk() or anything else
+		 */
+#ifdef DEBUG
+		printk("CPU%u: spurious wakeup call\n", cpu);
+#endif
+	}
+}
+
+int platform_cpu_kill(unsigned int cpu)
+{
+	return wait_for_completion_timeout(&cpu_killed, 5000);
+}
+
+/*
+ * platform-specific code to shutdown a CPU
+ *
+ * Called with IRQs disabled
+ */
+void __ref platform_cpu_die(unsigned int cpu)
+{
+#ifdef DEBUG
+	unsigned int this_cpu = hard_smp_processor_id();
+
+	if (cpu != this_cpu) {
+		printk(KERN_CRIT "Eek! platform_cpu_die running on %u, should be %u\n",
+			   this_cpu, cpu);
+		BUG();
+	}
+#endif
+
+	printk(KERN_NOTICE "CPU%u: shutdown\n", cpu);
+	complete(&cpu_killed);
+
+	/*
+	 * we're ready for shutdown now, so do it
+	 */
+	cpu_enter_lowpower();
+	platform_do_lowpower(cpu);
+
+	/*
+	 * bring this CPU back into the world of cache
+	 * coherency, and then restore interrupts
+	 */
+	cpu_leave_lowpower();
+}
+
+int platform_cpu_disable(unsigned int cpu)
+{
+	/*
+	 * we don't allow CPU 0 to be shutdown (it is still too special
+	 * e.g. clock tick interrupts)
+	 */
+	return cpu == 0 ? -EPERM : 0;
+}
+
diff --git a/arch/arm/plat-armada/include/plat/cache-aurora-l2.h b/arch/arm/plat-armada/include/plat/cache-aurora-l2.h
new file mode 100644
index 0000000..197891d
--- /dev/null
+++ b/arch/arm/plat-armada/include/plat/cache-aurora-l2.h
@@ -0,0 +1,164 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File under the following licensing terms. 
+Redistribution and use in source and binary forms, with or without modification, 
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer. 
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution. 
+
+    *   Neither the name of Marvell nor the names of its contributors may be 
+        used to endorse or promote products derived from this software without 
+        specific prior written permission. 
+    
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND 
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE 
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR 
+ANY PER_CPU, INPER_CPU, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES 
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; 
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON 
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT 
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS 
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+
+#ifndef __INCmvCpuIfL2Regsh
+#define __INCmvCpuIfL2Regsh
+
+#define L2_MAX_COUNTERS	2
+
+/**********************************
+* Discovery Level-2 Cache registers
+***********************************/
+
+/* Cache Controls and Configurations */
+#define L2_CTRL_REG                     0x100
+#define L2_AUX_CTRL_REG		        0x104
+#define L2_CNTR_CTRL_REG		0x200
+#define L2_CNTR_CONFIG_REG(cntrNum)     (0x204 + cntrNum * 0xc)
+#define L2_CNTR_VAL_LOW_REG(cntrNum)    (0x208 + cntrNum * 0xc)
+#define L2_CNTR_VAL_HIGH_REG(cntrNum)   (0x20c + cntrNum * 0xc)
+#define L2_INT_CAUSE_REG         	0x220
+#define L2_INT_MASK_REG         	0x224
+#define L2_ERR_INJECT_CTRL_REG          0x228
+#define L2_ECC_ERR_INJECT_MASK_REG      0x22c
+#define WAY_SRAM_CONFIG_REG(wayNum)     (0x500 + wayNum * 0x4)
+#define L2_ECC_ERR_COUNT_REG            0x600
+#define L2_ECC_ERR_THRESHOLD_REG        0x604
+#define L2_ECC_ERR_ADDR_CAPTURE_REG     0x608
+#define L2_PARITY_ERR_WAY_SET_LATCH_REG 0x60c
+#define L2_ECC_ERR_WAY_SET_LATCH_REG    0x610
+#define L2_RANGE_BASE_ADDR_REG(cpuNum)  (0x710 + cpuNum * 0x4)
+#define L2_CACHE_SYNC_REG               0x730
+#define L2_INVAL_PHY_ADDR_REG           0x770
+#define L2_INVAL_RANGE_REG              0x774
+#define L2_INVAL_INDEX_WAY_REG          0x778
+#define L2_INVAL_WAY_REG                0x77c
+#define L2_CLEAN_PHY_ADDR_REG           0x7b0
+#define L2_CLEAN_RANGE_REG              0x7b4
+#define L2_CLEAN_INDEX_WAY_REG          0x7b8
+#define L2_CLEAN_WAY_REG                0x7bc
+#define L2_FLUSH_PHY_ADDR_REG           0x7f0
+#define L2_FLUSH_RANGE_REG              0x7f4
+#define L2_FLUSH_INDEX_WAY_REG          0x7f8
+#define L2_FLUSH_WAY_REG                0x7fc
+#define L2_DATA_LOC_REG(cpuNum)         (0x900 + cpuNum * 0x8)
+#define L2_INST_LOC_REG(cpuNum)         (0x904 + cpuNum * 0x8)
+#define L2_PFU_LOCK_REG                 0x980
+#define IO_BRIDGE_LOCK_REG              0x984
+
+/*  L2_CTRL_REG (L2CR) */
+#define L2CR_ENABLE			BIT0
+
+/*  L2_AUX_CTRL_REG (L2ACR) */
+#define L2ACR_FORCE_WRITE_POLICY_OFFSET	0
+#define L2ACR_FORCE_WRITE_POLICY_MASK	(0x3 << L2ACR_FORCE_WRITE_POLICY_OFFSET)
+#define L2ACR_FORCE_WRITE_POLICY_DIS	(0 << L2ACR_FORCE_WRITE_POLICY_OFFSET)
+#define L2ACR_FORCE_WRITE_BACK_POLICY	(1 << L2ACR_FORCE_WRITE_POLICY_OFFSET)
+#define L2ACR_FORCE_WRITE_THRO_POLICY	(2 << L2ACR_FORCE_WRITE_POLICY_OFFSET)
+#define L2ACR_ASSOCIATIVITY_OFFSET	13
+#define L2ACR_ASSOCIATIVITY_MASK	(0xF << L2ACR_ASSOCIATIVITY_OFFSET)
+#define L2ACR_ASSOCIATIVITY_4WAY	(3 << L2ACR_ASSOCIATIVITY_OFFSET)
+#define L2ACR_ASSOCIATIVITY_8WAY	(7 << L2ACR_ASSOCIATIVITY_OFFSET)
+#define L2ACR_WAY_SIZE_OFFSET		17			
+#define L2ACR_WAY_SIZE_MASK		(0x7 << L2ACR_WAY_SIZE_OFFSE)
+#define L2ACR_WAY_SIZE_16KB		(1 << L2ACR_WAY_SIZE_OFFSET)
+#define L2ACR_WAY_SIZE_32KB		(2 << L2ACR_WAY_SIZE_OFFSET)
+#define L2ACR_WAY_SIZE_64KB		(3 << L2ACR_WAY_SIZE_OFFSET)
+#define L2ACR_WAY_SIZE_128KB		(4 << L2ACR_WAY_SIZE_OFFSET)
+#define L2ACR_WAY_SIZE_256KB		(5 << L2ACR_WAY_SIZE_OFFSET)
+#define L2ACR_WAY_SIZE_512KB		(6 << L2ACR_WAY_SIZE_OFFSET)
+#define L2ACR_ECC_ENABLE		BIT20
+#define L2ACR_PARITY_ENABLE		BIT21
+#define L2ACR_INV_EVIC_LINE_UC_ERR	BIT22
+#define L2ACR_FORCE_WR_ALLOC_OFFSET	23
+#define L2ACR_FORCE_WR_ALLOC_MASK	(0x3 << L2ACR_FORCE_WR_ALLOC_OFFSET)
+#define L2ACR_FORCE_WR_ALLOC_DISABLE	(0 << L2ACR_FORCE_WR_ALLOC_OFFSET)
+#define L2ACR_FORCE_NO_WR_ALLOC		(1 << L2ACR_FORCE_WR_ALLOC_OFFSET)
+#define L2ACR_FORCE_WR_ALLOC		(2 << L2ACR_FORCE_WR_ALLOC_OFFSET)
+#define L2ACR_REPLACEMENT_OFFSET	27
+#define L2ACR_REPLACEMENT_MASK		(0x3 << L2ACR_REPLACEMENT_OFFSET)
+#define L2ACR_REPLACEMENT_TYPE_WAYRR	(0 << L2ACR_REPLACEMENT_OFFSET)
+#define L2ACR_REPLACEMENT_TYPE_LFSR	(1 << L2ACR_REPLACEMENT_OFFSET)
+#define L2ACR_REPLACEMENT_TYPE_SEMIPLRU	(2 << L2ACR_REPLACEMENT_OFFSET)
+
+/* L2_CNTR_CTRL_REG (L2CCR) */
+#define L2CCR_CPU0_EVENT_ENABLE		(1 << 16)
+#define L2CCR_CPU1_EVENT_ENABLE		(1 << 17)
+#define L2CCR_FPU_EVENT_ENABLE		(1 << 30)
+#define L2CCR_IO_BRIDGE_EVENT_ENABLE	(1 << 31)
+
+
+extern int __init aurora_l2_init(void __iomem *base);
+inline void l2_clean_pa(unsigned int);
+#ifdef CONFIG_CACHE_AURORA_L2
+int aurora_l2_pm_enter(void);
+int aurora_l2_pm_exit(void);
+void auroraL2_flush_all(void);
+#else
+static inline int aurora_l2_pm_enter(void) { return 0;};
+static inline int aurora_l2_pm_exit(void) { return 0;};
+static inline void auroraL2_flush_all(void) {};
+#endif
+#endif /* __INCmvCpuIfL2Regsh */
diff --git a/arch/arm/plat-armada/include/plat/gpio.h b/arch/arm/plat-armada/include/plat/gpio.h
new file mode 100644
index 0000000..e336005
--- /dev/null
+++ b/arch/arm/plat-armada/include/plat/gpio.h
@@ -0,0 +1,26 @@
+/*
+ * arch/arm/plat-feroceon/include/plat/gpio.h
+ *
+ * Marvell Feroceon SoC GPIO handling.
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#ifndef __PLAT_GPIO_H
+#define __PLAT_GPIO_H
+
+#include <linux/init.h>
+
+#define gpio_get_value  __gpio_get_value
+#define gpio_set_value  __gpio_set_value
+#define gpio_cansleep   __gpio_cansleep
+
+#define GPIO_INPUT_OK		(1 << 0)
+#define GPIO_OUTPUT_OK		(1 << 1)
+
+/* Initialize gpiolib. */
+void __init mv_gpio_init(void);
+
+#endif
diff --git a/arch/arm/plat-armada/include/plat/i2s-orion.h b/arch/arm/plat-armada/include/plat/i2s-orion.h
new file mode 100644
index 0000000..4ae4edf
--- /dev/null
+++ b/arch/arm/plat-armada/include/plat/i2s-orion.h
@@ -0,0 +1,23 @@
+/*
+ * include/asm-arm/plat-orion/i2s-orion.h
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#ifndef __ASM_PLAT_ORION_I2S_ORION_H
+#define __ASM_PLAT_ORION_I2S_ORION_H
+
+#include <linux/mbus.h>
+
+struct orion_i2s_platform_data {
+	struct mbus_dram_target_info	*dram;
+	int	spdif_rec;
+	int	spdif_play;
+	int	i2s_rec;
+	int	i2s_play;
+};
+
+
+#endif
diff --git a/arch/arm/plat-armada/include/plat/msi.h b/arch/arm/plat-armada/include/plat/msi.h
new file mode 100644
index 0000000..64c9152
--- /dev/null
+++ b/arch/arm/plat-armada/include/plat/msi.h
@@ -0,0 +1,11 @@
+#ifndef _ARMADA_MSI_H_
+#define _ARMADA_MSI_H_
+#ifdef CONFIG_PCI_MSI
+void armada_msi_init(void);
+#else
+static inline void armada_msi_init(void)
+{
+	return;
+}
+#endif
+#endif
diff --git a/arch/arm/plat-armada/include/plat/mv_xor.h b/arch/arm/plat-armada/include/plat/mv_xor.h
new file mode 100644
index 0000000..bd5f3bd
--- /dev/null
+++ b/arch/arm/plat-armada/include/plat/mv_xor.h
@@ -0,0 +1,30 @@
+/*
+ * arch/arm/plat-orion/include/plat/mv_xor.h
+ *
+ * Marvell XOR platform device data definition file.
+ */
+
+#ifndef __PLAT_MV_XOR_H
+#define __PLAT_MV_XOR_H
+
+#include <linux/dmaengine.h>
+#include <linux/mbus.h>
+
+#define MV_XOR_SHARED_NAME	"mv_xor_shared"
+#define MV_XOR_NAME		"mv_xor"
+
+struct mbus_dram_target_info;
+
+struct mv_xor_platform_shared_data {
+	struct mbus_dram_target_info	*dram;
+};
+
+struct mv_xor_platform_data {
+	struct platform_device		*shared;
+	int				hw_id;
+	dma_cap_mask_t			cap_mask;
+	size_t				pool_size;
+};
+
+
+#endif
diff --git a/arch/arm/plat-armada/include/plat/mvsdio.h b/arch/arm/plat-armada/include/plat/mvsdio.h
new file mode 100644
index 0000000..14ca886
--- /dev/null
+++ b/arch/arm/plat-armada/include/plat/mvsdio.h
@@ -0,0 +1,21 @@
+/*
+ * arch/arm/plat-orion/include/plat/mvsdio.h
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#ifndef __MACH_MVSDIO_H
+#define __MACH_MVSDIO_H
+
+#include <linux/mbus.h>
+
+struct mvsdio_platform_data {
+	struct mbus_dram_target_info *dram;
+	unsigned int clock;
+	int gpio_card_detect;
+	int gpio_write_protect;
+};
+
+#endif
diff --git a/arch/arm/plat-armada/include/plat/orion_wdt.h b/arch/arm/plat-armada/include/plat/orion_wdt.h
new file mode 100644
index 0000000..a7d5814
--- /dev/null
+++ b/arch/arm/plat-armada/include/plat/orion_wdt.h
@@ -0,0 +1,18 @@
+/*
+ * arch/arm/plat-feroceon/include/plat/orion_wdt.h
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2. This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#ifndef __PLAT_ORION_WDT_H
+#define __PLAT_ORION_WDT_H
+
+struct orion_wdt_platform_data {
+	u32	tclk;		/* no <linux/clk.h> support yet */
+};
+
+
+#endif
+
diff --git a/arch/arm/plat-armada/include/plat/xor.h b/arch/arm/plat-armada/include/plat/xor.h
new file mode 100644
index 0000000..d730e02
--- /dev/null
+++ b/arch/arm/plat-armada/include/plat/xor.h
@@ -0,0 +1,26 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <linux/device.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/sysdev.h>
+#include <asm/mach/time.h>
+
+int xor_memxor(unsigned int src_count, unsigned int bytes, void *dest, void **srcs);
diff --git a/arch/arm/plat-armada/linux_oss/mvOs.c b/arch/arm/plat-armada/linux_oss/mvOs.c
new file mode 100644
index 0000000..db7018e
--- /dev/null
+++ b/arch/arm/plat-armada/linux_oss/mvOs.c
@@ -0,0 +1,245 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* mvOsCpuArchLib.c - Marvell CPU architecture library
+*
+* DESCRIPTION:
+*       This library introduce Marvell API for OS dependent CPU architecture 
+*       APIs. This library introduce single CPU architecture services APKI 
+*       cross OS.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+/* includes */
+//#include <asm/processor.h>
+#include "mvOs.h"
+
+static MV_U32 read_p15_c0 (void);
+static MV_U32 read_p15_c1 (void);
+
+/* defines  */
+#define ARM_ID_REVISION_OFFS	0
+#define ARM_ID_REVISION_MASK	(0xf << ARM_ID_REVISION_OFFS)
+
+#define ARM_ID_PART_NUM_OFFS	4
+#define ARM_ID_PART_NUM_MASK	(0xfff << ARM_ID_PART_NUM_OFFS)
+
+#define ARM_ID_ARCH_OFFS	16
+#define ARM_ID_ARCH_MASK	(0xf << ARM_ID_ARCH_OFFS)
+
+#define ARM_ID_VAR_OFFS		20
+#define ARM_ID_VAR_MASK		(0xf << ARM_ID_VAR_OFFS)
+
+#define ARM_ID_ASCII_OFFS	24
+#define ARM_ID_ASCII_MASK	(0xff << ARM_ID_ASCII_OFFS)
+
+#define ARM_FEATURE_THUMBEE_OFFS	12
+#define ARM_FEATURE_THUMBEE_MASK	(0xf << ARM_FEATURE_THUMBEE_OFFS)
+
+
+void* mvOsIoCachedMalloc( void* osHandle, MV_U32 size, MV_ULONG* pPhyAddr,
+			  MV_U32 *memHandle)
+{
+    void *p = kmalloc( size, GFP_ATOMIC );
+    *pPhyAddr = pci_map_single( osHandle, p, 0, PCI_DMA_BIDIRECTIONAL );
+    return p;
+}
+void* mvOsIoUncachedMalloc( void* osHandle, MV_U32 size, MV_ULONG* pPhyAddr,
+			    MV_U32 *memHandle)
+{
+    return pci_alloc_consistent( osHandle, size, (dma_addr_t *)pPhyAddr );
+}
+ 
+void mvOsIoUncachedFree( void* osHandle, MV_U32 size, MV_ULONG phyAddr, void* pVirtAddr,
+			 MV_U32 memHandle)
+{
+    return pci_free_consistent( osHandle, size, pVirtAddr, (dma_addr_t)phyAddr );
+} 
+                                                                                                                                               
+void mvOsIoCachedFree( void* osHandle, MV_U32 size, MV_ULONG phyAddr, void* pVirtAddr,
+		       MV_U32 memHandle )
+{
+    return kfree( pVirtAddr );
+}
+ 
+int mvOsRand(void)
+{
+    int rand;
+    get_random_bytes(&rand, sizeof(rand) );
+    return rand;
+}
+
+/*******************************************************************************
+* mvOsCpuVerGet() - 
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       32bit CPU Revision
+*
+*******************************************************************************/
+MV_U32 mvOsCpuRevGet( MV_VOID )
+{
+	return ((read_p15_c0() & ARM_ID_REVISION_MASK ) >> ARM_ID_REVISION_OFFS);
+}
+/*******************************************************************************
+* mvOsCpuPartGet() - 
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       32bit CPU Part number
+*
+*******************************************************************************/
+MV_U32 mvOsCpuPartGet( MV_VOID )
+{
+	return ((read_p15_c0() & ARM_ID_PART_NUM_MASK ) >> ARM_ID_PART_NUM_OFFS);
+}
+/*******************************************************************************
+* mvOsCpuArchGet() - 
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       32bit CPU Architicture number
+*
+*******************************************************************************/
+MV_U32 mvOsCpuArchGet( MV_VOID )
+{
+    return ((read_p15_c0() & ARM_ID_ARCH_MASK ) >> ARM_ID_ARCH_OFFS);
+}
+/*******************************************************************************
+* mvOsCpuVarGet() - 
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       32bit CPU Variant number
+*
+*******************************************************************************/
+MV_U32 mvOsCpuVarGet( MV_VOID )
+{
+    return ((read_p15_c0() & ARM_ID_VAR_MASK ) >> ARM_ID_VAR_OFFS);
+}
+/*******************************************************************************
+* mvOsCpuAsciiGet() - 
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       32bit CPU Variant number
+*
+*******************************************************************************/
+MV_U32 mvOsCpuAsciiGet( MV_VOID )
+{
+    return ((read_p15_c0() & ARM_ID_ASCII_MASK ) >> ARM_ID_ASCII_OFFS);
+}
+
+/*******************************************************************************
+* mvOsCpuThumbEEGet() -
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       32bit CPU Variant number
+*
+*******************************************************************************/
+MV_U32 mvOsCpuThumbEEGet( MV_VOID )
+{
+	return ((read_p15_c1() & ARM_FEATURE_THUMBEE_MASK ) >> ARM_FEATURE_THUMBEE_OFFS);
+}
+
+/*
+static unsigned long read_p15_c0 (void)
+*/
+/* read co-processor 15, register #0 (ID register) */
+static MV_U32 read_p15_c0 (void)
+{
+	MV_U32 value;
+
+	__asm__ __volatile__(
+		"mrc	p15, 0, %0, c0, c0, 0   @ read control reg\n"
+		: "=r" (value)
+		:
+		: "memory");
+
+	return value;
+}
+
+/* read co-processor 15, register #1 (Feature 0) */
+static MV_U32 read_p15_c1 (void)
+{
+	MV_U32 value;
+
+	__asm__ __volatile__(
+						 "mrc	p15, 0, %0, c0, c1, 0   @ read feature0 reg\n"
+	: "=r" (value)
+	:
+	: "memory");
+
+	return value;
+}
diff --git a/arch/arm/plat-armada/linux_oss/mvOs.h b/arch/arm/plat-armada/linux_oss/mvOs.h
new file mode 100644
index 0000000..c8818fb
--- /dev/null
+++ b/arch/arm/plat-armada/linux_oss/mvOs.h
@@ -0,0 +1,573 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+#ifndef _MV_OS_LNX_H_
+#define _MV_OS_LNX_H_
+                                                                                                                                               
+                                                                                                                                               
+#ifdef __KERNEL__
+/* for kernel space */
+#include <linux/stddef.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/reboot.h>
+#include <linux/pci.h>
+#include <linux/kdev_t.h>
+#include <linux/major.h>
+#include <linux/blkdev.h>
+#include <linux/console.h>
+#include <linux/delay.h>
+#include <linux/seq_file.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+#include <linux/kernel.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+  
+#include <asm/system.h>
+#include <asm/pgtable.h>
+#include <asm/page.h>
+#include <asm/hardirq.h>
+#include <asm/dma.h>
+#include <asm/io.h>
+ 
+#include <linux/random.h>
+
+#include "dbg-trace.h"
+
+#include "ctrlEnv/mvCtrlEnvRegs.h"
+#include "mvSysHwConfig.h"
+
+extern void mv_early_printk(char *fmt,...);
+
+#define MV_ASM              __asm__ __volatile__  
+#define INLINE              inline
+#define _INIT				__init
+#define MV_TRC_REC	        TRC_REC
+#define mvOsPrintf          printk
+#define mvOsEarlyPrintf	    mv_early_printk
+#define mvOsOutput          printk
+#define mvOsSPrintf         sprintf
+#define mvOsMalloc(_size_)  kmalloc(_size_,GFP_ATOMIC)
+#define mvOsFree            kfree
+#define mvOsMemcpy          memcpy
+#define mvOsMemset          memset
+#define mvOsSleep(_mils_)   mdelay(_mils_)
+#define mvOsTaskLock()
+#define mvOsTaskUnlock()
+#define strtol              simple_strtoul
+#define mvOsDelay(x)        mdelay(x)
+#define mvOsUDelay(x)       udelay(x)
+#define mvCopyFromOs        copy_from_user
+#define mvCopyToOs          copy_to_user
+#define mvOsWarning()       WARN_ON(1)
+
+ 
+#include "mvTypes.h"
+#include "mvCommon.h"
+  
+#ifdef MV_NDEBUG
+#define mvOsAssert(cond)
+#else
+#define mvOsAssert(cond) { do { if(!(cond)) { BUG(); } }while(0); }
+#endif /* MV_NDEBUG */
+ 
+#else /* __KERNEL__ */
+ 
+/* for user space applications */
+#include <stdlib.h>
+#include <stdio.h>
+#include <assert.h>
+#include <string.h>
+ 
+#define INLINE inline
+#define mvOsPrintf printf
+#define mvOsOutput printf
+#define mvOsMalloc(_size_) malloc(_size_)
+#define mvOsFree free
+#define mvOsAssert(cond) assert(cond)
+ 
+#endif /* __KERNEL__ */                                                                                                                                               
+#define mvOsIoVirtToPhy(pDev, pVirtAddr)        virt_to_dma( (pDev), (pVirtAddr) )
+/*    pci_map_single( (pDev), (pVirtAddr), 0, PCI_DMA_BIDIRECTIONAL ) */
+
+#define mvOsIoVirtToPhys(pDev, pVirtAddr)       virt_to_dma( (pDev), (pVirtAddr) )
+
+#define mvOsCacheFlushInv(pDev, p, size )                            \
+	    pci_map_single( (pDev), (p), (size), PCI_DMA_BIDIRECTIONAL)
+/*
+ * This was omitted because as of 2.6.35 the Biderection performs only
+ * flush for outer cache because of the speculative issues.
+ * This should be replaced by Flush then invalidate
+ *
+#define mvOsCacheClear(pDev, p, size )                              \
+    pci_map_single( (pDev), (p), (size), PCI_DMA_BIDIRECTIONAL)
+*/
+ 
+#define mvOsCacheFlush(pDev, p, size )                              \
+    pci_map_single( (pDev), (p), (size), PCI_DMA_TODEVICE)
+ 
+#define mvOsCacheInvalidate(pDev, p, size)                          \
+    pci_map_single( (pDev), (p), (size), PCI_DMA_FROMDEVICE )
+
+#define mvOsCacheUnmap(pDev, phys, size)                          \
+    pci_unmap_single( (pDev), (dma_addr_t)(phys), (size), PCI_DMA_FROMDEVICE )
+
+#define CPU_PHY_MEM(x)              (MV_U32)x
+#define CPU_MEMIO_CACHED_ADDR(x)    (void*)x
+#define CPU_MEMIO_UNCACHED_ADDR(x)  (void*)x
+
+
+/* CPU architecture dependent 32, 16, 8 bit read/write IO addresses */
+#define MV_MEMIO32_WRITE(addr, data)    \
+    ((*((volatile unsigned int*)(addr))) = ((unsigned int)(data)))
+
+#define MV_MEMIO32_READ(addr)           \
+    ((*((volatile unsigned int*)(addr))))
+
+#define MV_MEMIO16_WRITE(addr, data)    \
+    ((*((volatile unsigned short*)(addr))) = ((unsigned short)(data)))
+
+#define MV_MEMIO16_READ(addr)           \
+    ((*((volatile unsigned short*)(addr))))
+
+#define MV_MEMIO8_WRITE(addr, data)     \
+    ((*((volatile unsigned char*)(addr))) = ((unsigned char)(data)))
+
+#define MV_MEMIO8_READ(addr)            \
+    ((*((volatile unsigned char*)(addr))))
+
+
+/* No Fast Swap implementation (in assembler) for ARM */
+#define MV_32BIT_LE_FAST(val)            MV_32BIT_LE(val)
+#define MV_16BIT_LE_FAST(val)            MV_16BIT_LE(val)
+#define MV_32BIT_BE_FAST(val)            MV_32BIT_BE(val)
+#define MV_16BIT_BE_FAST(val)            MV_16BIT_BE(val)
+    
+/* 32 and 16 bit read/write in big/little endian mode */
+
+/* 16bit write in little endian mode */
+#define MV_MEMIO_LE16_WRITE(addr, data) \
+        MV_MEMIO16_WRITE(addr, MV_16BIT_LE_FAST(data))
+
+/* 16bit read in little endian mode */
+static __inline MV_U16 MV_MEMIO_LE16_READ(MV_U32 addr)
+{
+    MV_U16 data;
+
+    data= (MV_U16)MV_MEMIO16_READ(addr);
+
+    return (MV_U16)MV_16BIT_LE_FAST(data);
+}
+
+/* 32bit write in little endian mode */
+#define MV_MEMIO_LE32_WRITE(addr, data) \
+        MV_MEMIO32_WRITE(addr, MV_32BIT_LE_FAST(data))
+
+/* 32bit read in little endian mode */
+static __inline MV_U32 MV_MEMIO_LE32_READ(MV_U32 addr)
+{
+    MV_U32 data;
+
+    data= (MV_U32)MV_MEMIO32_READ(addr);
+
+    return (MV_U32)MV_32BIT_LE_FAST(data);
+}
+
+static __inline void mvOsBCopy(char* srcAddr, char* dstAddr, int byteCount)
+{
+    while(byteCount != 0)
+    {
+        *dstAddr = *srcAddr;
+        dstAddr++;
+        srcAddr++;
+        byteCount--;
+    }
+}
+
+static INLINE MV_U64 mvOsDivMod64(MV_U64 divided, MV_U64 divisor, MV_U64* modulu)
+{
+    MV_U64  division = 0;
+
+    if(divisor == 1)
+	return divided;
+
+    while(divided >= divisor)
+    {
+	    division++;
+	    divided -= divisor;
+    }
+    if (modulu != NULL)
+        *modulu = divided;
+
+    return division;
+}
+
+#if defined(MV_BRIDGE_SYNC_REORDER)
+extern MV_U32 *mvUncachedParam;
+
+static __inline void mvOsBridgeReorderWA(void)
+{
+	volatile MV_U32 val = 0;
+
+	val = mvUncachedParam[0];
+}
+#endif
+
+
+/* Flash APIs */
+#define MV_FL_8_READ            MV_MEMIO8_READ
+#define MV_FL_16_READ           MV_MEMIO_LE16_READ
+#define MV_FL_32_READ           MV_MEMIO_LE32_READ
+#define MV_FL_8_DATA_READ       MV_MEMIO8_READ
+#define MV_FL_16_DATA_READ      MV_MEMIO16_READ
+#define MV_FL_32_DATA_READ      MV_MEMIO32_READ
+#define MV_FL_8_WRITE           MV_MEMIO8_WRITE
+#define MV_FL_16_WRITE          MV_MEMIO_LE16_WRITE
+#define MV_FL_32_WRITE          MV_MEMIO_LE32_WRITE
+#define MV_FL_8_DATA_WRITE      MV_MEMIO8_WRITE
+#define MV_FL_16_DATA_WRITE     MV_MEMIO16_WRITE
+#define MV_FL_32_DATA_WRITE     MV_MEMIO32_WRITE
+
+
+/* CPU cache information */
+#define CPU_I_CACHE_LINE_SIZE   32    /* 2do: replace 32 with linux core macro */
+#define CPU_D_CACHE_LINE_SIZE   32    /* 2do: replace 32 with linux core macro */
+
+#if defined (SHEEVA_ERRATA_ARM_CPU_4413)
+#define	 DSBWA_4413(x)	dmb() 		/* replaced dsb() for optimization */
+#else
+#define  DSBWA_4413(x)
+#endif
+
+#if defined (SHEEVA_ERRATA_ARM_CPU_4611)
+#define	 DSBWA_4611(x)	dmb()		/* replaced dsb() for optimization */
+#else
+#define  DSBWA_4611(x)
+#endif
+
+#if defined(CONFIG_AURORA_IO_CACHE_COHERENCY)
+ #define mvOsCacheLineFlushInv(handle, addr)
+ #define mvOsCacheLineInv(handle,addr)
+ #define mvOsCacheLineFlush(handle, addr)
+ #define mvOsCacheIoSync()			{ MV_REG_WRITE(0x21810, 0x1); while (MV_REG_READ(0x21810) & 0x1);}
+#else
+ #define mvOsCacheIoSync()			/* Dummy - not needed in s/w cache coherency */
+ /*************************************/
+ /* FLUSH & INVALIDATE single D$ line */
+ /*************************************/
+ #if defined(CONFIG_L2_CACHE_ENABLE) || defined(CONFIG_CACHE_FEROCEON_L2)
+  #define mvOsCacheLineFlushInv(handle, addr)                     \
+  {                                                               \
+    __asm__ __volatile__ ("mcr p15, 0, %0, c7, c14, 1" : : "r" (addr));\
+    __asm__ __volatile__ ("mcr p15, 1, %0, c15, c10, 1" : : "r" (addr));\
+    __asm__ __volatile__ ("mcr p15, 0, r0, c7, c10, 4");		\
+  }
+ #elif defined(CONFIG_CACHE_AURORA_L2)
+  #define mvOsCacheLineFlushInv(handle, addr)                     \
+  {                                                               \
+    DSBWA_4611(addr);						 \
+    __asm__ __volatile__ ("mcr p15, 0, %0, c7, c14, 1" : : "r" (addr));  /* Clean and Inv D$ by MVA to PoC */ \
+    writel(__virt_to_phys((int)(((int)addr) & ~0x1f)), (INTER_REGS_BASE + MV_AURORA_L2_REGS_OFFSET + 0x7F0/*L2_FLUSH_PA*/)); \
+    writel(0x0, (INTER_REGS_BASE + MV_AURORA_L2_REGS_OFFSET + 0x700/*L2_SYNC*/)); \
+    __asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 4" : : "r" (addr));  /* DSB */ \
+  }
+ #else
+  #define mvOsCacheLineFlushInv(handle, addr)                     \
+  {                                                               \
+    DSBWA_4611(addr);						 \
+    __asm__ __volatile__ ("mcr p15, 0, %0, c7, c14, 1" : : "r" (addr));\
+    __asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 4" : : "r" (addr)); \
+  }
+ #endif
+ 
+ /*****************************/
+ /* INVALIDATE single D$ line */
+ /*****************************/
+ #if defined(CONFIG_L2_CACHE_ENABLE) || defined(CONFIG_CACHE_FEROCEON_L2)
+ #define mvOsCacheLineInv(handle,addr)                           \
+ {                                                               \
+   __asm__ __volatile__ ("mcr p15, 0, %0, c7, c6, 1" : : "r" (addr)); \
+  __asm__ __volatile__ ("mcr p15, 1, %0, c15, c11, 1" : : "r" (addr)); \
+ }
+ #elif defined(CONFIG_CACHE_AURORA_L2)
+ #define mvOsCacheLineInv(handle,addr)                           \
+ {                                                               \
+   DSBWA_4413(addr);								\
+   __asm__ __volatile__ ("mcr p15, 0, %0, c7, c6, 1" : : "r" (addr));   /* Invalidate D$ by MVA to PoC */ \
+   writel(__virt_to_phys(((int)addr) & ~0x1f), (INTER_REGS_BASE + MV_AURORA_L2_REGS_OFFSET + 0x770/*L2_INVALIDATE_PA*/)); \
+   writel(0x0, (INTER_REGS_BASE + MV_AURORA_L2_REGS_OFFSET + 0x700/*L2_SYNC*/)); \
+   __asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 4" : : "r" (addr));  /* DSB */ \
+ }
+ #else
+ #define mvOsCacheLineInv(handle,addr)                           \
+ {                                                               \
+   DSBWA_4413(addr);							\
+   __asm__ __volatile__ ("mcr p15, 0, %0, c7, c6, 1" : : "r" (addr)); \
+   __asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 4" : : "r" (addr)); \
+ }
+ #endif
+
+ /************************/
+ /* FLUSH single D$ line */
+ /************************/
+ #if defined(CONFIG_L2_CACHE_ENABLE) || defined(CONFIG_CACHE_FEROCEON_L2)
+ #define mvOsCacheLineFlush(handle, addr)                     \
+ {                                                               \
+   __asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 1" : : "r" (addr));\
+   __asm__ __volatile__ ("mcr p15, 1, %0, c15, c9, 1" : : "r" (addr));\
+   __asm__ __volatile__ ("mcr p15, 0, r0, c7, c10, 4");          \
+ }
+ #elif defined(CONFIG_CACHE_AURORA_L2)
+ #define mvOsCacheLineFlush(handle, addr)                     \
+ {                                                               \
+   DSBWA_4611(addr);						 \
+   __asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 1" : : "r" (addr)); /* Clean D$ line by MVA to PoC */ \
+   writel(__virt_to_phys(((int)addr) & ~0x1f), (INTER_REGS_BASE + MV_AURORA_L2_REGS_OFFSET + 0x7B0/*L2_CLEAN_PA*/)); \
+   writel(0x0, (INTER_REGS_BASE + MV_AURORA_L2_REGS_OFFSET + 0x700/*L2_SYNC*/)); \
+   __asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 4" : : "r" (addr)); /* DSB */ \
+ }
+ #else
+ #define mvOsCacheLineFlush(handle, addr)                     \
+ {                                                               \
+   DSBWA_4611(addr);						 \
+   __asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 1" : : "r" (addr));\
+   __asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 4" : : "r" (addr)); \
+ }
+ #endif
+#endif /* CONFIG_AURORA_IO_CACHE_COHERENCY */
+
+#define MV_OS_CACHE_MULTI_THRESH	256	
+static inline void mvOsCacheMultiLineFlush(void *handle, void *addr, int size)
+{
+	if (size <= MV_OS_CACHE_MULTI_THRESH) {
+#if defined(CONFIG_CACHE_AURORA_L2) && !defined(CONFIG_AURORA_IO_CACHE_COHERENCY)
+		DSBWA_4611(addr);
+		while (size > 0) {
+			__asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 1" : : "r" (addr)); /* Clean D$ line by MVA to PoC */
+			writel(__virt_to_phys(((int)addr) & ~0x1f), (INTER_REGS_BASE + MV_AURORA_L2_REGS_OFFSET + 0x7B0/*L2_CLEAN_PA*/));
+			size -= CPU_D_CACHE_LINE_SIZE;
+			addr += CPU_D_CACHE_LINE_SIZE;
+		}
+		writel(0x0, (INTER_REGS_BASE + MV_AURORA_L2_REGS_OFFSET + 0x700/*L2_SYNC*/));
+		__asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 4" : : "r" (addr)); /* DSB */
+#else
+		while (size > 0) {
+			mvOsCacheLineFlush(handle, addr);
+			size -= CPU_D_CACHE_LINE_SIZE;
+			addr += CPU_D_CACHE_LINE_SIZE;
+		}
+#endif
+	} else
+		pci_map_single(handle, addr, size, PCI_DMA_TODEVICE);
+}
+
+static inline void mvOsCacheMultiLineInv(void *handle, void *addr, int size)
+{
+        if( size <= MV_OS_CACHE_MULTI_THRESH) {
+#if defined(CONFIG_CACHE_AURORA_L2) && !defined(CONFIG_AURORA_IO_CACHE_COHERENCY)
+		DSBWA_4413(addr);
+		while (size > 0) {
+			__asm__ __volatile__ ("mcr p15, 0, %0, c7, c6, 1" : : "r" (addr));   /* Invalidate D$ by MVA to PoC */
+			writel(__virt_to_phys(((int)addr) & ~0x1f), (INTER_REGS_BASE + MV_AURORA_L2_REGS_OFFSET + 0x770/*L2_INVALIDATE_PA*/));
+			size -= CPU_D_CACHE_LINE_SIZE;
+			addr += CPU_D_CACHE_LINE_SIZE;
+		}
+		writel(0x0, (INTER_REGS_BASE + MV_AURORA_L2_REGS_OFFSET + 0x700/*L2_SYNC*/));
+		__asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 4" : : "r" (addr));  /* DSB */
+#else
+		while (size > 0) {
+			mvOsCacheLineInv(handle, addr);
+			size -= CPU_D_CACHE_LINE_SIZE;
+			addr += CPU_D_CACHE_LINE_SIZE;
+		}
+#endif
+	} else
+		pci_map_single(handle, addr, size, PCI_DMA_FROMDEVICE);
+	
+}
+
+static inline void mvOsCacheMultiLineFlushInv(void *handle, void *addr, int size)
+{
+        if(size <= MV_OS_CACHE_MULTI_THRESH) {
+#if defined(CONFIG_CACHE_AURORA_L2) && !defined(CONFIG_AURORA_IO_CACHE_COHERENCY)
+		DSBWA_4611(addr);
+		while(size > 0) {
+			__asm__ __volatile__ ("mcr p15, 0, %0, c7, c14, 1" : : "r" (addr));  /* Clean and Inv D$ by MVA to PoC */
+			writel(__virt_to_phys((int)(((int)addr) & ~0x1f)), (INTER_REGS_BASE + MV_AURORA_L2_REGS_OFFSET + 0x7F0/*L2_FLUSH_PA*/));
+			size -= CPU_D_CACHE_LINE_SIZE;
+			addr += CPU_D_CACHE_LINE_SIZE;
+		}
+		writel(0x0, (INTER_REGS_BASE + MV_AURORA_L2_REGS_OFFSET + 0x700/*L2_SYNC*/));
+		__asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 4" : : "r" (addr));  /* DSB */
+#else
+		while(size > 0) {
+			mvOsCacheLineFlushInv(handle, addr);
+			size -= CPU_D_CACHE_LINE_SIZE;
+			addr += CPU_D_CACHE_LINE_SIZE;
+		}
+#endif
+	} else 
+                pci_map_single(handle, addr, size, PCI_DMA_BIDIRECTIONAL);
+}
+
+static __inline void mvOsPrefetch(const void *ptr)
+{
+        __asm__ __volatile__(
+                "pld\t%0"
+                :
+                : "o" (*(char *)ptr)
+                : "cc");
+}
+
+
+/* Flush CPU pipe */
+#define CPU_PIPE_FLUSH
+
+
+
+
+
+/* register manipulations  */
+
+/******************************************************************************
+* This debug function enable the write of each register that u-boot access to 
+* to an array in the DRAM, the function record only MV_REG_WRITE access.
+* The function could not be operate when booting from flash.
+* In order to print the array we use the printreg command.
+******************************************************************************/
+/* #define REG_DEBUG */
+#if defined(REG_DEBUG)
+extern int reg_arry[2048][2];
+extern int reg_arry_index;
+#endif
+
+/* Marvell controller register read/write macros */
+#define MV_REG_VALUE(offset)          \
+                (MV_MEMIO32_READ((INTER_REGS_BASE | (offset))))
+
+#define MV_REG_READ(offset)             \
+        (MV_MEMIO_LE32_READ(INTER_REGS_BASE | (offset)))
+
+#if defined(REG_DEBUG)
+#define MV_REG_WRITE(offset, val)    \
+        MV_MEMIO_LE32_WRITE((INTER_REGS_BASE | (offset)), (val)); \
+        { \
+                reg_arry[reg_arry_index][0] = (INTER_REGS_BASE | (offset));\
+                reg_arry[reg_arry_index][1] = (val);\
+                reg_arry_index++;\
+        }
+#else
+#define MV_REG_WRITE(offset, val)    \
+        MV_MEMIO_LE32_WRITE((INTER_REGS_BASE | (offset)), (val))
+#endif
+                                                
+#define MV_REG_BYTE_READ(offset)        \
+        (MV_MEMIO8_READ((INTER_REGS_BASE | (offset))))
+
+#if defined(REG_DEBUG)
+#define MV_REG_BYTE_WRITE(offset, val)  \
+        MV_MEMIO8_WRITE((INTER_REGS_BASE | (offset)), (val)); \
+        { \
+                reg_arry[reg_arry_index][0] = (INTER_REGS_BASE | (offset));\
+                reg_arry[reg_arry_index][1] = (val);\
+                reg_arry_index++;\
+        }
+#else
+#define MV_REG_BYTE_WRITE(offset, val)  \
+        MV_MEMIO8_WRITE((INTER_REGS_BASE | (offset)), (val))
+#endif
+
+#if defined(REG_DEBUG)
+#define MV_REG_BIT_SET(offset, bitMask)                 \
+        (MV_MEMIO32_WRITE((INTER_REGS_BASE | (offset)), \
+         (MV_MEMIO32_READ(INTER_REGS_BASE | (offset)) | \
+          MV_32BIT_LE_FAST(bitMask)))); \
+        { \
+                reg_arry[reg_arry_index][0] = (INTER_REGS_BASE | (offset));\
+                reg_arry[reg_arry_index][1] = (MV_MEMIO32_READ(INTER_REGS_BASE | (offset)));\
+                reg_arry_index++;\
+        }
+#else
+#define MV_REG_BIT_SET(offset, bitMask)                 \
+        (MV_MEMIO32_WRITE((INTER_REGS_BASE | (offset)), \
+         (MV_MEMIO32_READ(INTER_REGS_BASE | (offset)) | \
+          MV_32BIT_LE_FAST(bitMask))))
+#endif
+        
+#if defined(REG_DEBUG)
+#define MV_REG_BIT_RESET(offset,bitMask)                \
+        (MV_MEMIO32_WRITE((INTER_REGS_BASE | (offset)), \
+         (MV_MEMIO32_READ(INTER_REGS_BASE | (offset)) & \
+          MV_32BIT_LE_FAST(~bitMask)))); \
+        { \
+                reg_arry[reg_arry_index][0] = (INTER_REGS_BASE | (offset));\
+                reg_arry[reg_arry_index][1] = (MV_MEMIO32_READ(INTER_REGS_BASE | (offset)));\
+                reg_arry_index++;\
+        }
+#else
+#define MV_REG_BIT_RESET(offset,bitMask)                \
+        (MV_MEMIO32_WRITE((INTER_REGS_BASE | (offset)), \
+         (MV_MEMIO32_READ(INTER_REGS_BASE | (offset)) & \
+          MV_32BIT_LE_FAST(~bitMask))))
+#endif
+
+/* Assembly functions */
+
+/*
+** MV_ASM_READ_CPU_EXTRA_FEATURES
+** Read Marvell extra features register.
+*/
+#define MV_ASM_READ_EXTRA_FEATURES(x) __asm__ volatile("mrc  p15, 1, %0, c15, c1, 0" : "=r" (x));
+
+/*
+** MV_ASM_WAIT_FOR_INTERRUPT
+** Wait for interrupt.
+*/
+#define MV_ASM_WAIT_FOR_INTERRUPT      __asm__ volatile("mcr  p15, 0, r0, c7, c0, 4");
+
+
+/* ARM architecture APIs */
+MV_U32  mvOsCpuRevGet (MV_VOID);
+MV_U32  mvOsCpuPartGet (MV_VOID);
+MV_U32  mvOsCpuArchGet (MV_VOID);
+MV_U32  mvOsCpuVarGet (MV_VOID);
+MV_U32  mvOsCpuAsciiGet (MV_VOID);
+MV_U32 mvOsCpuThumbEEGet (MV_VOID);
+
+/*  Other APIs  */
+void* mvOsIoCachedMalloc( void* osHandle, MV_U32 size, MV_ULONG* pPhyAddr, MV_U32 *memHandle);
+void* mvOsIoUncachedMalloc( void* osHandle, MV_U32 size, MV_ULONG* pPhyAddr, MV_U32 *memHandle );
+void mvOsIoUncachedFree( void* osHandle, MV_U32 size, MV_ULONG phyAddr, void* pVirtAddr, MV_U32 memHandle );
+void mvOsIoCachedFree( void* osHandle, MV_U32 size, MV_ULONG phyAddr, void* pVirtAddr, MV_U32 memHandle );
+int mvOsRand(void);
+
+#endif /* _MV_OS_LNX_H_ */
+
+
diff --git a/arch/arm/plat-armada/linux_oss/mvOsSata.h b/arch/arm/plat-armada/linux_oss/mvOsSata.h
new file mode 100644
index 0000000..2cb064b
--- /dev/null
+++ b/arch/arm/plat-armada/linux_oss/mvOsSata.h
@@ -0,0 +1,157 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* mvOsLinux.h - O.S. interface header file for Linux  
+*
+* DESCRIPTION:
+*       This header file contains OS dependent definition under Linux
+*
+* DEPENDENCIES:
+*       Linux kernel header files.
+*
+* FILE REVISION NUMBER:
+*       $Revision: 1.1 $
+*******************************************************************************/
+
+#ifndef __INCmvOsLinuxh
+#define __INCmvOsLinuxh
+
+/* Includes */
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/string.h>
+#include <linux/kernel.h>
+#include <linux/timer.h>
+#include <linux/mm.h>
+#include <linux/interrupt.h>
+#include <linux/major.h>
+#include <linux/errno.h>
+#include <linux/genhd.h>
+#include <linux/slab.h>
+#include <linux/delay.h>
+#include <linux/ide.h>
+#include <linux/pci.h>
+
+#include <asm/byteorder.h>
+#include <asm/irq.h>
+#include <asm/uaccess.h>
+#include <asm/io.h>
+#include "mvOs.h"
+
+
+/* Definitions */
+#define MV_DEFAULT_QUEUE_DEPTH 2
+#define MV_SATA_SUPPORT_EDMA_SINGLE_DATA_REGION
+#define MV_SATA_SUPPORT_GEN2E_128_QUEUE_LEN
+
+#ifdef CONFIG_MV88F6082
+ #define MV_SATA_OVERRIDE_SW_QUEUE_SIZE
+ #define MV_SATA_REQUESTED_SW_QUEUE_SIZE 2
+ #undef MV_SATA_SUPPORT_GEN2E_128_QUEUE_LEN
+#endif
+
+/* System dependent macro for flushing CPU write cache */
+#if defined (MV_BRIDGE_SYNC_REORDER)
+#define MV_CPU_WRITE_BUFFER_FLUSH()	do {	\
+						wmb();	\
+						mvOsBridgeReorderWA();	\
+					} while (0)
+#else
+#define MV_CPU_WRITE_BUFFER_FLUSH()     wmb()
+#endif /* CONFIG_MV78XX0 */
+
+/* System dependent little endian from / to CPU conversions */
+#define MV_CPU_TO_LE16(x)   cpu_to_le16(x)
+#define MV_CPU_TO_LE32(x)   cpu_to_le32(x)
+
+#define MV_LE16_TO_CPU(x)   le16_to_cpu(x)
+#define MV_LE32_TO_CPU(x)   le32_to_cpu(x)
+
+#ifdef __BIG_ENDIAN_BITFIELD
+#define MV_BIG_ENDIAN_BITFIELD
+#endif
+
+/* System dependent register read / write in byte/word/dword variants */
+#define MV_REG_WRITE_BYTE(base, offset, val)    writeb(val, base + offset)
+#define MV_REG_WRITE_WORD(base, offset, val)    writew(val, base + offset)
+#define MV_REG_WRITE_DWORD(base, offset, val)   writel(val, base + offset)
+#define MV_REG_READ_BYTE(base, offset)          readb(base + offset)
+#define MV_REG_READ_WORD(base, offset)          readw(base + offset)
+#define MV_REG_READ_DWORD(base, offset)         readl(base + offset)
+
+
+/* Typedefs    */
+
+/* System dependant typedefs */
+typedef void            *MV_VOID_PTR;
+typedef u32             *MV_U32_PTR;
+typedef u16             *MV_U16_PTR;
+typedef u8              *MV_U8_PTR;
+typedef char            *MV_CHAR_PTR;
+typedef void            *MV_BUS_ADDR_T;
+typedef unsigned long   MV_CPU_FLAGS;
+
+
+/* Structures  */
+/* System dependent structure */
+typedef struct mvOsSemaphore
+{
+  int notUsed;
+} MV_OS_SEMAPHORE;
+
+
+/* Functions (User implemented)*/
+
+/* Semaphore init, take and release */
+#define mvOsSemInit(x) MV_TRUE
+#define mvOsSemTake(x)
+#define mvOsSemRelease(x)
+
+/* Interrupt masking and unmasking functions */
+MV_CPU_FLAGS mvOsSaveFlagsAndMaskCPUInterrupts(MV_VOID);
+MV_VOID      mvOsRestoreFlags(MV_CPU_FLAGS);
+
+/* Delay function in micro seconds resolution */
+void mvMicroSecondsDelay(MV_VOID_PTR, MV_U32);
+
+/* Typedefs    */
+typedef enum mvBoolean
+{
+    MV_SFALSE, MV_STRUE
+} MV_BOOLEAN;
+
+/* System logging function */
+#include "mvLog.h"
+/* Enable READ/WRITE Long SCSI command only when driver is compiled for debugging */
+#ifdef MV_LOGGER
+#define MV_SATA_SUPPORT_READ_WRITE_LONG
+#endif
+
+#define MV_IAL_LOG_ID       3
+
+#endif /* __INCmvOsLinuxh */
diff --git a/arch/arm/plat-armada/msi.c b/arch/arm/plat-armada/msi.c
new file mode 100644
index 0000000..100c757
--- /dev/null
+++ b/arch/arm/plat-armada/msi.c
@@ -0,0 +1,154 @@
+/*
+ * arch/arm/plat-armada/msi.c
+ *
+ * Marvell Armada SoC MSI,MSI-X handling.
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#include <linux/pci.h>
+#include <linux/msi.h>
+#include <asm/mach/irq.h>
+#include <asm/irq.h>
+#include "mvOs.h"
+
+static DECLARE_BITMAP(msi_irq_in_use, NR_PRIVATE_MSI_IRQS);
+
+void armada_msi_irq_handler(unsigned int irq, struct irq_desc *desc)
+{
+	int j;
+	unsigned long status;
+
+	/* Read Inbound Shared Doorbell registers and find any active interrupts,
+	* then call ISR for each active interrupt
+	*/
+	status = MV_REG_READ(AXP_IN_DRBEL_CAUSE) & 0xFFFF0000;
+	if (!status)
+		return;
+
+	j = find_first_bit(&status, 32);
+	
+	MV_REG_WRITE(AXP_IN_DRBEL_CAUSE, ~(1 << j));
+	status = MV_REG_READ(AXP_IN_DRBEL_CAUSE);
+	/* write back to clear bit */
+	generic_handle_irq(IRQ_AURORA_MSI_START + j - NR_PRIVATE_MSI_IRQS);
+}
+
+void __init armada_msi_init(void)
+{
+	unsigned long temp;
+
+	set_irq_chained_handler(IRQ_AURORA_IN_DRBL_HIGH, armada_msi_irq_handler);
+
+	/* Unmask private doorbells 16-31 */
+	temp = MV_REG_READ(AXP_IN_DRBEL_MSK) | (0xFFFF0000);
+	MV_REG_WRITE(AXP_IN_DRBEL_MSK, temp);
+}
+
+/*
+ * Dynamic irq allocate and deallocation
+ */
+int create_irq(void)
+{
+	int irq, pos;
+
+again:
+	pos = find_first_zero_bit(msi_irq_in_use, NR_PRIVATE_MSI_IRQS);
+	irq = IRQ_AURORA_MSI_START + pos;
+	if (irq > NR_IRQS)
+		return -ENOSPC;
+	/* test_and_set_bit operates on 32-bits at a time */
+	if (test_and_set_bit(pos, msi_irq_in_use))
+		goto again;
+
+	dynamic_irq_init(irq);
+	
+	return irq;
+}
+
+void destroy_irq(unsigned int irq)
+{
+	int pos = irq - IRQ_AURORA_MSI_START;
+
+	dynamic_irq_cleanup(irq);
+
+	clear_bit(pos, msi_irq_in_use);
+}
+
+void arch_teardown_msi_irq(unsigned int irq)
+{
+	destroy_irq(irq);
+}
+
+static void armada_msi_nop(unsigned int irq)
+{
+	return;
+}
+
+#ifdef CONFIG_SMP
+int armada_msi_set_affinity(unsigned int irq, const struct cpumask *mask_val)
+{
+	struct msi_msg msg;
+	int msi_irq;
+	int i;
+	
+	msi_irq = irq - IRQ_AURORA_MSI_START;
+	msg.address_hi = 0x0;
+	msg.address_lo = AXP_SW_TRIG_IRQ_PHYS;
+	msg.data = ((msi_irq + NR_PRIVATE_MSI_GROUP) & AXP_SW_TRIG_IRQ_INITID_MASK);
+
+	for_each_cpu(i, mask_val)
+		msg.data |= (0x1 << (AXP_SW_TRIG_IRQ_CPU_TARGET_OFFS + i));
+
+	write_msi_msg(irq, &msg);
+	cpumask_copy(irq_desc[irq].affinity, mask_val);
+	
+	return 0;
+}
+
+void second_cpu_msi_init(void)
+{
+	unsigned long temp;
+	/* Unmask private doorbells 16-31 */
+	temp = MV_REG_READ(AXP_IN_DRBEL_MSK) | (0xFFFF0000);
+	MV_REG_WRITE(AXP_IN_DRBEL_MSK, temp);
+}
+#endif
+
+struct irq_chip armada_msi_irq_chip = {
+	.name		= "axp_msi_irq",
+	.ack 		= armada_msi_nop,
+	.enable 	= unmask_msi_irq,
+	.disable 	= mask_msi_irq,
+	.mask 		= mask_msi_irq,
+	.unmask 	= unmask_msi_irq,
+#ifdef CONFIG_SMP
+	.set_affinity	= armada_msi_set_affinity,
+#endif
+};
+
+int arch_setup_msi_irq(struct pci_dev *pdev, struct msi_desc *desc)
+{
+	int irq = create_irq();
+	int msi_irq;
+	struct msi_msg msg;
+
+	if (irq < 0)
+		return irq;
+
+	msi_irq = irq - IRQ_AURORA_MSI_START;
+	set_irq_msi(irq, desc);
+
+	msg.address_hi = 0x0;
+	msg.address_lo = AXP_SW_TRIG_IRQ_PHYS;
+	msg.data = (0x1 << AXP_SW_TRIG_IRQ_CPU_TARGET_OFFS) | 
+			((msi_irq + NR_PRIVATE_MSI_GROUP) & AXP_SW_TRIG_IRQ_INITID_MASK);
+
+	write_msi_msg(irq, &msg);
+	set_irq_chip_and_handler(irq, &armada_msi_irq_chip, handle_edge_irq);
+
+	return 0;
+}
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/Makefile
new file mode 100644
index 0000000..6d3cf80
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/Makefile
@@ -0,0 +1,15 @@
+#
+# Makefile for the Marvell Audio ALSA Device Driver
+#
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+obj-$(CONFIG_SND_MRVL_AUDIO) += snd-mv88fx.o
+#snd-mv88fx-objs		     += mv_snd.o ../../../../../sound/arm/devdma.o
+snd-mv88fx-objs		     += mv88fx-pcm.o  cs42l51-hal.o mv88fx-hal.o #../../../../../sound/arm/devdma.o
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/cs42l51-hal.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/cs42l51-hal.c
new file mode 100644
index 0000000..1d15ccb
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/cs42l51-hal.c
@@ -0,0 +1,178 @@
+/*
+ *
+ *	Marvell Orion Alsa Sound driver
+ *
+ *	Author: Maen Suleiman
+ *	Copyright (C) 2008 Marvell Ltd.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+#include <linux/ioport.h>
+#include <linux/interrupt.h>
+#include <sound/driver.h>
+#include <linux/platform_device.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/version.h>
+#include <sound/core.h>
+#include <sound/initval.h>
+#include <sound/control.h>
+#include <sound/pcm.h>
+#include <sound/asoundef.h>
+#include <sound/asound.h>
+
+#include "twsi/mvTwsi.h"
+#include "audio/dac/mvCLAudioCodec.h"
+#include "boardEnv/mvBoardEnvLib.h"
+
+
+
+/*
+ * Initialize the audio decoder.
+ */
+int
+cs42l51_init(void)
+{
+    MV_AUDIO_CODEC_DEV codec_params;
+    unsigned char reg_data;
+    
+
+    codec_params.ADCMode = MV_I2S_MODE;
+    codec_params.DACDigitalIFFormat = MV_I2S_UP_TO_24_BIT;
+    codec_params.twsiSlave.moreThen256 = MV_FALSE;
+    codec_params.twsiSlave.validOffset = MV_TRUE;
+    codec_params.twsiSlave.slaveAddr.address = mvBoardA2DTwsiAddrGet();
+    codec_params.twsiSlave.slaveAddr.type = mvBoardA2DTwsiAddrTypeGet();
+    if(mvCLAudioCodecInit(&codec_params) == MV_FALSE)
+    {
+        printk("Error - Cannot initialize audio decoder.at address =0x%x",
+				codec_params.twsiSlave.slaveAddr.address);
+        return -1;
+    }
+
+    /* Use the signal processor.               */
+    mvCLAudioCodecRegSet(&codec_params,0x9,0x40);
+    
+    /* Unmute PCM-A & PCM-B and set default      */
+    mvCLAudioCodecRegSet(&codec_params,0x10,0x60);
+    mvCLAudioCodecRegSet(&codec_params,0x11,0x60);
+
+    /* default for AOUTx*/
+    mvCLAudioCodecRegSet(&codec_params,0x16,0x05);
+    mvCLAudioCodecRegSet(&codec_params,0x17,0x05);
+
+    /* swap channels */
+    mvCLAudioCodecRegSet(&codec_params,0x18,0xff);
+    if (0) {
+	    int i;
+	    for (i=1; i<= 0x21 ; i++) {
+		    reg_data = mvCLAudioCodecRegGet(&codec_params,i);
+		    printk("CLS reg=0x%02x val=0x%02x\n",i,reg_data);
+	    }
+	    
+    }
+    
+    return 0;
+}
+
+#define MVAUD_NUM_VOLUME_STEPS  (40)
+static MV_U8 auddec_volume_mapping[MVAUD_NUM_VOLUME_STEPS] =
+{
+	0x19,	0xB2,	0xB7,	0xBD,	0xC3,	0xC9,	0xCF,	0xD5,
+	0xD8,	0xE1,	0xE7,	0xED,	0xF3,	0xF9,	0xFF,	0x00,	
+	0x01,	0x02,	0x03,	0x04,	0x05,	0x06,	0x07,	0x08,	
+	0x09,	0x0A,	0x0B,	0x0C,	0x0D,	0x0E,	0x0F,	0x10,	
+	0x11,	0x12,	0x13,	0x14,	0x15,	0x16,	0x17,	0x18
+};
+
+
+/*
+ * Get the audio decoder volume for both channels.
+ * 0 is lowest volume, MVAUD_NUM_VOLUME_STEPS-1 is the highest volume.
+ */
+
+void
+cs42l51_vol_get(MV_U8 *vol_list)
+{
+    MV_AUDIO_CODEC_DEV  codec_params;
+    MV_U8   reg_data;
+    MV_U32  i;
+    MV_U32  vol_idx;
+
+    codec_params.ADCMode = MV_I2S_MODE;
+    codec_params.DACDigitalIFFormat = MV_I2S_UP_TO_24_BIT;
+    codec_params.twsiSlave.moreThen256 = MV_FALSE;
+    codec_params.twsiSlave.validOffset = MV_TRUE;
+	codec_params.twsiSlave.slaveAddr.address = mvBoardA2DTwsiAddrGet();
+	codec_params.twsiSlave.slaveAddr.type = mvBoardA2DTwsiAddrTypeGet();
+
+
+    for(vol_idx = 0; vol_idx < 2; vol_idx++)
+    {
+        reg_data = mvCLAudioCodecRegGet(&codec_params,0x16 + vol_idx);
+
+       /*printk("\tVolume was get: 0x%x.\n",
+                                reg_data);*/
+
+        /* Look for the index that mapps to this dB value.  */
+        for(i = 0; i < MVAUD_NUM_VOLUME_STEPS; i++)
+        {
+		if (reg_data == auddec_volume_mapping[i])
+			break;
+		if (( auddec_volume_mapping[i] > auddec_volume_mapping[MVAUD_NUM_VOLUME_STEPS-1]) 
+					&& (reg_data > auddec_volume_mapping[i]) 
+					&& (reg_data < auddec_volume_mapping[i+1]))
+			break;
+		 
+        }
+
+        vol_list[vol_idx] = i;
+       /*printk("\tvol_list[%d] = %d.\n",vol_idx,
+                                vol_list[vol_idx]);*/
+
+    }
+
+    return;
+}
+
+
+/*
+ * Set the audio decoder volume for both channels.
+ * 0 is lowest volume, MVAUD_NUM_VOLUME_STEPS-1 is the highest volume.
+ */
+void
+cs42l51_vol_set(MV_U8 *vol_list)
+{
+    MV_AUDIO_CODEC_DEV  codec_params;
+    MV_U32  vol_idx;
+
+    codec_params.ADCMode = MV_I2S_MODE;
+    codec_params.DACDigitalIFFormat = MV_I2S_UP_TO_24_BIT;
+    codec_params.twsiSlave.moreThen256 = MV_FALSE;
+    codec_params.twsiSlave.validOffset = MV_TRUE;
+    codec_params.twsiSlave.slaveAddr.address = mvBoardA2DTwsiAddrGet();
+    codec_params.twsiSlave.slaveAddr.type = mvBoardA2DTwsiAddrTypeGet();
+
+   
+    for(vol_idx = 0; vol_idx < 2; vol_idx++)
+    {
+        /*printk("\tvol_list[%d] = %d.\n",vol_idx,
+                                vol_list[vol_idx]);*/
+
+        if(vol_list[vol_idx] >= MVAUD_NUM_VOLUME_STEPS)
+		vol_list[vol_idx] = MVAUD_NUM_VOLUME_STEPS -1;
+
+        mvCLAudioCodecRegSet(&codec_params,0x16 + vol_idx,
+                             auddec_volume_mapping[vol_list[vol_idx]]);
+
+        /*printk("\tVolume was set to 0x%x.\n",
+                                auddec_volume_mapping[vol_list[vol_idx]]);*/
+    }
+
+    return;
+}
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/mv88fx-hal.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/mv88fx-hal.c
new file mode 100644
index 0000000..48b2425
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/mv88fx-hal.c
@@ -0,0 +1,342 @@
+/*
+ *
+ *	Marvell Orion Alsa Sound driver
+ *
+ *	Author: Maen Suleiman
+ *	Copyright (C) 2008 Marvell Ltd.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/ioport.h>
+#include <linux/interrupt.h>
+#include <sound/driver.h>
+#include <linux/platform_device.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/version.h>
+#include <sound/core.h>
+#include <sound/initval.h>
+#include <sound/control.h>
+#include <sound/pcm.h>
+#include <sound/asoundef.h>
+#include <sound/asound.h>
+#include <asm/dma.h>
+#include <asm/io.h>
+#include <asm/scatterlist.h>
+#include <asm/sizes.h>
+
+#include "mv88fx-pcm.h"
+/*#define AUDIO_REG_BASE	0x0*/
+#include "audio/mvAudio.h"
+#include "ctrlEnv/sys/mvSysAudio.h"
+
+int cs42l51_init(void);
+
+int mv88fx_snd_hw_init(struct mv88fx_snd_chip	*chip)
+{
+	if((chip->audio_info->i2s_rec) || (chip->audio_info->i2s_play)) {
+	/* Clear ints */
+	cs42l51_init();
+	}
+		
+        mv88fx_snd_writel(chip, MV_AUDIO_INT_CAUSE_REG(0), 0xffffffff);
+        mv88fx_snd_writel(chip, MV_AUDIO_INT_MASK_REG(0), 0);
+        mv88fx_snd_writel(chip, MV_AUDIO_SPDIF_REC_INT_CAUSE_MASK_REG(0), 
+				0);
+	
+	if (MV_OK != mvAudioInit())
+		return EIO;
+
+        /* Disable all playback/recording */
+	mv88fx_snd_bitreset(chip, MV_AUDIO_PLAYBACK_CTRL_REG(0),
+			    (APCR_PLAY_I2S_ENABLE_MASK | 
+			     APCR_PLAY_SPDIF_ENABLE_MASK));
+
+	mv88fx_snd_bitreset(chip, MV_AUDIO_RECORD_CTRL_REG(0),
+			    (ARCR_RECORD_SPDIF_EN_MASK | 
+			     ARCR_RECORD_I2S_EN_MASK));
+	
+	if (MV_OK != mvSPDIFRecordTclockSet(0)) {
+		mv88fx_snd_debug("Marvell ALSA driver ERR. mvSPDIFRecordTclockSet failed\n");
+                return -ENOMEM;
+	}
+
+        return 0;
+}
+
+int mv88fx_snd_hw_playback_set(struct mv88fx_snd_chip	*chip)
+{
+        struct mv88fx_snd_stream *audio_stream = 
+		chip->stream[PLAYBACK]; 
+	struct snd_pcm_substream *substream = audio_stream->substream;
+	struct snd_pcm_runtime *runtime = substream->runtime;
+        
+	MV_AUDIO_PLAYBACK_CTRL	pcm_play_ctrl;
+	MV_I2S_PLAYBACK_CTRL	i2s_play_ctrl;
+	MV_SPDIF_PLAYBACK_CTRL	spdif_play_ctrl;
+	MV_AUDIO_FREQ_DATA 	dco_ctrl;
+
+
+	dco_ctrl.offset = chip->dco_ctrl_offst;
+	
+	switch(audio_stream->rate) {
+	case 44100:
+		dco_ctrl.baseFreq = AUDIO_FREQ_44_1KH;
+		break;
+	case 48000:
+		dco_ctrl.baseFreq = AUDIO_FREQ_48KH;
+		break;
+	case 96000:
+		dco_ctrl.baseFreq = AUDIO_FREQ_96KH;
+		break;
+	default:
+		snd_printk("Requested rate %d is not supported\n", 
+				runtime->rate); return -1;
+	}
+
+	pcm_play_ctrl.burst = (chip->burst == 128)?AUDIO_128BYTE_BURST:
+				AUDIO_32BYTE_BURST;
+	
+	pcm_play_ctrl.loopBack = chip->loopback;
+	
+	if (audio_stream->stereo) {
+		pcm_play_ctrl.monoMode = AUDIO_PLAY_MONO_OFF;
+	}
+	else {
+		switch (audio_stream->mono_mode) {
+		case MONO_LEFT:
+			pcm_play_ctrl.monoMode = AUDIO_PLAY_LEFT_MONO;
+			break;
+		case MONO_RIGHT:
+			pcm_play_ctrl.monoMode = AUDIO_PLAY_RIGHT_MONO;
+			break;
+		case MONO_BOTH:
+		default:
+			pcm_play_ctrl.monoMode = AUDIO_PLAY_BOTH_MONO;
+			break;
+		}
+	}
+	
+	if (audio_stream->format == SAMPLE_16IN16) {
+		pcm_play_ctrl.sampleSize = SAMPLE_16BIT;
+		i2s_play_ctrl.sampleSize = SAMPLE_16BIT;
+	}
+	else if (audio_stream->format == SAMPLE_24IN32) {
+		pcm_play_ctrl.sampleSize = SAMPLE_24BIT;
+		i2s_play_ctrl.sampleSize = SAMPLE_24BIT;
+		
+	}
+	else if (audio_stream->format == SAMPLE_32IN32) {
+		pcm_play_ctrl.sampleSize = SAMPLE_32BIT;
+		i2s_play_ctrl.sampleSize = SAMPLE_32BIT;
+	}
+	else {
+		snd_printk("Requested format %d is not supported\n", runtime->format);
+		return -1;
+	}
+
+	/* buffer and period sizes in frame */
+	pcm_play_ctrl.bufferPhyBase = audio_stream->dma_addr;
+	pcm_play_ctrl.bufferSize = audio_stream->dma_size;
+	pcm_play_ctrl.intByteCount = audio_stream->period_size;
+
+	/* I2S playback streem stuff */
+	/*i2s_play_ctrl.sampleSize = pcm_play_ctrl.sampleSize;*/
+	i2s_play_ctrl.justification = I2S_JUSTIFIED;
+	i2s_play_ctrl.sendLastFrame = 0;
+
+	spdif_play_ctrl.nonPcm = MV_FALSE;
+	
+	spdif_play_ctrl.validity = chip->ch_stat_valid;
+
+	if (audio_stream->stat_mem) {
+		spdif_play_ctrl.userBitsFromMemory = MV_TRUE;
+		spdif_play_ctrl.validityFromMemory = MV_TRUE;
+		spdif_play_ctrl.blockStartInternally = MV_FALSE;
+	} else {
+		spdif_play_ctrl.userBitsFromMemory = MV_FALSE;
+		spdif_play_ctrl.validityFromMemory = MV_FALSE;
+		spdif_play_ctrl.blockStartInternally = MV_TRUE;
+	}
+
+	/* If this is non-PCM sound, mute I2S channel */
+	spin_lock_irq(&chip->reg_lock);
+
+	if (!(mv88fx_snd_readl(chip, MV_AUDIO_PLAYBACK_CTRL_REG(0)) & 
+			(APCR_PLAY_I2S_ENABLE_MASK | APCR_PLAY_SPDIF_ENABLE_MASK))) {
+
+	if (MV_OK != mvAudioDCOCtrlSet(0, &dco_ctrl)) {
+		snd_printk("Failed to initialize DCO clock control.\n");
+		return -1;
+	}
+	}
+
+	if (audio_stream->clock_src == DCO_CLOCK)
+		while ((mv88fx_snd_readl(chip, MV_AUDIO_SPCR_DCO_STATUS_REG(0)) & 
+			ASDSR_DCO_LOCK_MASK) == 0);
+	else if (audio_stream->clock_src == SPCR_CLOCK)
+		while ((mv88fx_snd_readl(chip, MV_AUDIO_SPCR_DCO_STATUS_REG(0)) & 
+			ASDSR_SPCR_LOCK_MASK) == 0);
+			
+	if (MV_OK != mvAudioPlaybackControlSet(0, &pcm_play_ctrl)) {
+		snd_printk("Failed to initialize PCM playback control.\n");
+		return -1;
+	}
+
+	if (MV_OK != mvI2SPlaybackCtrlSet(0, &i2s_play_ctrl)) {
+		snd_printk("Failed to initialize I2S playback control.\n");
+		return -1;
+	}
+
+	mvSPDIFPlaybackCtrlSet(0, &spdif_play_ctrl);
+
+	spin_unlock_irq(&chip->reg_lock);
+
+#if 0 
+	mv88fx_snd_debug("runtime->xfer_align=%d\n",(int)runtime->xfer_align);
+	mv88fx_snd_debug("runtime->format=%d\n",runtime->format);
+	mv88fx_snd_debug("runtime->channels=%d\n",runtime->channels);
+	mv88fx_snd_debug("runtime->rate=%d\n",runtime->rate);
+	mv88fx_snd_debug("runtime->dma_addr=0x%x\n",runtime->dma_addr);
+
+	mv88fx_snd_debug("runtime->dma_area=0x%x\n",(unsigned int)runtime->dma_area);
+	mv88fx_snd_debug("runtime->frame_bits=0x%x\n",runtime->frame_bits);
+	mv88fx_snd_debug("runtime->period_size=0x%x\n",
+		   (unsigned int)runtime->period_size);
+	mv88fx_snd_debug("runtime->buffer_size=0x%x\n",
+		   (unsigned int)runtime->buffer_size); 
+	mv88fx_snd_debug("bufferPhyBase=0x%x\n",runtime->dma_addr);
+	mv88fx_snd_debug("bufferSize=0x%x\n",pcm_play_ctrl.bufferSize);
+	mv88fx_snd_debug("intByteCount=0x%x.\n",pcm_play_ctrl.intByteCount);
+
+#endif
+	
+	return 0;
+}
+
+
+int mv88fx_snd_hw_capture_set(struct mv88fx_snd_chip	*chip)
+{
+        struct mv88fx_snd_stream *audio_stream = 
+		chip->stream[CAPTURE]; 
+	struct snd_pcm_substream *substream = audio_stream->substream;
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	
+	MV_AUDIO_RECORD_CTRL 	pcm_rec_ctrl;
+	MV_I2S_RECORD_CTRL	i2s_rec_ctrl;
+	MV_AUDIO_FREQ_DATA	dco_ctrl;
+
+
+	dco_ctrl.offset = chip->dco_ctrl_offst;
+
+	switch(audio_stream->rate) {
+	case 44100:
+		dco_ctrl.baseFreq = AUDIO_FREQ_44_1KH;
+		break;
+	case 48000:
+		dco_ctrl.baseFreq = AUDIO_FREQ_48KH;
+		break;
+	case 96000:
+		dco_ctrl.baseFreq = AUDIO_FREQ_96KH;
+		break;
+	default:
+		snd_printk("Requested rate %d is not supported\n", 
+				runtime->rate); return -1;
+	}
+	
+	pcm_rec_ctrl.burst = (chip->burst == 128)?AUDIO_128BYTE_BURST:
+				AUDIO_32BYTE_BURST;
+
+	if (audio_stream->format == SAMPLE_16IN16) {
+		pcm_rec_ctrl.sampleSize = SAMPLE_16BIT;
+	}
+	else if (audio_stream->format == SAMPLE_24IN32) {
+		pcm_rec_ctrl.sampleSize = SAMPLE_24BIT;
+	}
+	else if (audio_stream->format == SAMPLE_32IN32) {
+		pcm_rec_ctrl.sampleSize = SAMPLE_32BIT;
+	}
+	else {
+		snd_printk("Requested format %d is not supported\n", runtime->format);
+		return -1;
+	}
+
+	pcm_rec_ctrl.mono = (audio_stream->stereo) ? MV_FALSE : MV_TRUE;
+
+	if (pcm_rec_ctrl.mono) {
+		switch (audio_stream->mono_mode) {
+		case MONO_LEFT:
+			pcm_rec_ctrl.monoChannel = AUDIO_REC_LEFT_MONO;
+			break;
+		default:
+		case MONO_RIGHT:
+			pcm_rec_ctrl.monoChannel = AUDIO_REC_RIGHT_MONO;
+			break;
+		}
+		
+	}
+	else pcm_rec_ctrl.monoChannel = AUDIO_REC_LEFT_MONO;
+		
+
+	pcm_rec_ctrl.bufferPhyBase = audio_stream->dma_addr;
+	pcm_rec_ctrl.bufferSize = audio_stream->dma_size;
+	
+	pcm_rec_ctrl.intByteCount = audio_stream->period_size;
+
+	/* I2S record streem stuff */
+	i2s_rec_ctrl.sample = pcm_rec_ctrl.sampleSize;
+	i2s_rec_ctrl.justf = I2S_JUSTIFIED;
+
+	spin_lock_irq(&chip->reg_lock);
+
+	/* set clock only if record is not enabled*/
+	if (!(mv88fx_snd_readl(chip, MV_AUDIO_RECORD_CTRL_REG(0)) & 
+			(ARCR_RECORD_SPDIF_EN_MASK | ARCR_RECORD_I2S_EN_MASK))) {
+
+	if (MV_OK != mvAudioDCOCtrlSet(0, &dco_ctrl)) {
+		snd_printk("Failed to initialize DCO clock control.\n");
+		return -1;
+	}
+	}
+	
+	if (MV_OK != mvAudioRecordControlSet(0, &pcm_rec_ctrl)) {
+		snd_printk("Failed to initialize PCM record control.\n");
+		return -1;
+	}
+
+	if (MV_OK != mvI2SRecordCntrlSet(0, &i2s_rec_ctrl)) {
+		snd_printk("Failed to initialize I2S record control.\n");
+		return -1;
+	}
+	spin_unlock_irq(&chip->reg_lock);
+
+#if 0
+
+	mv88fx_snd_debug("pcm_rec_ctrl.bufferSize=0x%x\n",(int)pcm_rec_ctrl.bufferSize);
+	mv88fx_snd_debug("pcm_rec_ctrl.intByteCount=0x%x\n",(int)pcm_rec_ctrl.intByteCount);
+
+	mv88fx_snd_debug("runtime->xfer_align=%d\n",(int)runtime->xfer_align);
+	mv88fx_snd_debug("runtime->format=%d\n",runtime->format);
+	mv88fx_snd_debug("runtime->channels=%d\n",runtime->channels);
+	mv88fx_snd_debug("runtime->rate=%d\n",runtime->rate);
+	mv88fx_snd_debug("runtime->dma_addr=0x%x\n",runtime->dma_addr);
+
+	mv88fx_snd_debug("runtime->dma_area=0x%x\n",(unsigned int)runtime->dma_area);
+	mv88fx_snd_debug("runtime->frame_bits=0x%x\n",runtime->frame_bits);
+	mv88fx_snd_debug("runtime->period_size=0x%x\n",
+		   (unsigned int)runtime->period_size);
+	mv88fx_snd_debug("runtime->buffer_size=0x%x\n",
+		   (unsigned int)runtime->buffer_size); 
+	mv88fx_snd_debug("bufferPhyBase=0x%x\n",runtime->dma_addr);
+
+#endif
+	
+
+	return 0;
+
+}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/mv88fx-pcm.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/mv88fx-pcm.c
new file mode 100644
index 0000000..6c764f0
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/mv88fx-pcm.c
@@ -0,0 +1,1678 @@
+/*
+ *
+ *	Marvell Orion Alsa Sound driver
+ *
+ *	Author: Maen Suleiman
+ *	Copyright (C) 2008 Marvell Ltd.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/ioport.h>
+#include <linux/interrupt.h>
+#include <sound/driver.h>
+#include <linux/platform_device.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/version.h>
+#include <sound/core.h>
+#include <sound/initval.h>
+#include <sound/control.h>
+#include <sound/pcm.h>
+#include <sound/asoundef.h>
+#include <sound/asound.h>
+#include <linux/dma-mapping.h>
+#include <linux/device.h>
+#include <asm/dma.h>
+#include <asm/io.h>
+#include <asm/scatterlist.h>
+#include <asm/sizes.h>
+#include "mv88fx-pcm.h"
+/*#define AUDIO_REG_BASE	0x0*/
+#include "audio/mvAudioRegs.h"
+
+
+int mv88fx_snd_hw_init(struct mv88fx_snd_chip	*chip);
+int mv88fx_snd_hw_playback_set(struct mv88fx_snd_chip	*chip);
+int mv88fx_snd_hw_capture_set(struct mv88fx_snd_chip	*chip);
+
+struct mv88fx_snd_chip	*chip = NULL;
+/*
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+*/
+int test_memory(struct mv88fx_snd_chip *chip,
+		unsigned int base,
+		unsigned int size)
+{
+	unsigned int i;
+
+	for (i=0; i<6; i++) {
+
+		/* check if we get to end */
+		if ((chip->audio_info->mem_array[i].base == 0) && 
+		   (chip->audio_info->mem_array[i].size == 0)) 
+			break;
+
+		/* check if we fit into one memory window only */
+		if ((base >= chip->audio_info->mem_array[i].base) &&
+		   ((base + size) <=  chip->audio_info->mem_array[i].base + chip->audio_info->mem_array[i].size))
+			return 1;
+
+	}
+
+	return 0;
+}
+
+/*
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+*/
+
+
+
+void devdma_hw_free(struct device *dev, struct snd_pcm_substream *substream)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	struct snd_dma_buffer *buf = runtime->dma_buffer_p;
+
+	if (runtime->dma_area == NULL)
+		return;
+
+	if (buf != &substream->dma_buffer) {
+		kfree(runtime->dma_buffer_p);
+	}
+
+	snd_pcm_set_runtime_buffer(substream, NULL);
+}
+
+int devdma_hw_alloc(struct device *dev, struct snd_pcm_substream *substream, size_t size)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	struct snd_dma_buffer *buf = runtime->dma_buffer_p;
+	struct mv88fx_snd_stream *audio_stream = 
+		snd_pcm_substream_chip(substream); 
+
+	int ret = 0;
+
+	if (buf) {
+		if (buf->bytes >= size) {
+			mv88fx_snd_debug(KERN_ERR "devdma_hw_alloc:buf->bytes >= size\n");
+			goto out;
+		}
+		devdma_hw_free(dev, substream);
+	}
+
+	if (substream->dma_buffer.area != NULL && substream->dma_buffer.bytes >= size) {
+		buf = &substream->dma_buffer;
+	} else {
+		buf = kmalloc(sizeof(struct snd_dma_buffer), GFP_KERNEL);
+		if (!buf) {
+			mv88fx_snd_debug(KERN_ERR "devdma_hw_alloc:buf == NULL\n");
+			goto nomem;
+		}
+
+		buf->dev.type = SNDRV_DMA_TYPE_DEV;
+		buf->dev.dev = dev;
+		buf->area = audio_stream->area;
+		buf->addr = audio_stream->addr;
+		buf->bytes = size;
+		buf->private_data = NULL;
+
+		if (!buf->area) {
+			mv88fx_snd_debug(KERN_ERR "devdma_hw_alloc:buf->area == NULL\n");
+			goto free;
+		}
+	}
+	snd_pcm_set_runtime_buffer(substream, buf);
+	ret = 1;
+ out:
+	runtime->dma_bytes = size;
+	return ret;
+
+ free:
+	kfree(buf);
+ nomem:
+	return -ENOMEM;
+}
+
+int devdma_mmap(struct device *dev, struct snd_pcm_substream *substream, struct vm_area_struct *vma)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	return dma_mmap_coherent(dev, vma, runtime->dma_area, runtime->dma_addr, runtime->dma_bytes);
+}
+
+
+/*
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+*/
+
+/*
+ * hw preparation for spdif
+ */
+
+
+static int mv88fx_snd_spdif_mask_info(struct snd_kcontrol *kcontrol,
+				      struct snd_ctl_elem_info *uinfo)
+{
+	uinfo->type = SNDRV_CTL_ELEM_TYPE_IEC958;
+	uinfo->count = 1;
+	return 0;
+}
+
+static int mv88fx_snd_spdif_mask_get(struct snd_kcontrol *kcontrol,
+				     struct snd_ctl_elem_value *ucontrol)
+{
+	ucontrol->value.iec958.status[0] = 0xff;
+	ucontrol->value.iec958.status[1] = 0xff;
+	ucontrol->value.iec958.status[2] = 0xff;
+	ucontrol->value.iec958.status[3] = 0xff;
+	return 0;
+}
+
+static struct snd_kcontrol_new mv88fx_snd_spdif_mask  =
+{
+	.access =	SNDRV_CTL_ELEM_ACCESS_READ,
+	.iface =	SNDRV_CTL_ELEM_IFACE_PCM,
+	.name =		SNDRV_CTL_NAME_IEC958("",PLAYBACK,CON_MASK),
+	.info =		mv88fx_snd_spdif_mask_info,
+	.get =		mv88fx_snd_spdif_mask_get,
+};
+
+static int mv88fx_snd_spdif_stream_info(struct snd_kcontrol *kcontrol,
+					struct snd_ctl_elem_info *uinfo)
+{
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	uinfo->type = SNDRV_CTL_ELEM_TYPE_IEC958;
+	uinfo->count = 1;
+	return 0;
+}
+
+static int mv88fx_snd_spdif_stream_get(struct snd_kcontrol *kcontrol,
+				       struct snd_ctl_elem_value *ucontrol)
+{
+	struct mv88fx_snd_chip *chip = snd_kcontrol_chip(kcontrol);
+	int i,word;
+
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	spin_lock_irq(&chip->reg_lock);
+	for (word=0 ; word < 4; word++) {
+		chip->stream[PLAYBACK]->spdif_status[word] = 
+		mv88fx_snd_readl(chip,
+				 MV_AUDIO_SPDIF_PLAY_CH_STATUS_LEFT_REG(0, word));
+		for (i = 0; i < 4; i++)
+			ucontrol->value.iec958.status[word + i] = 
+			(chip->stream[PLAYBACK]->spdif_status[word] >>
+								(i * 8)) & 0xff;
+
+	}
+	spin_unlock_irq(&chip->reg_lock);
+	return 0;
+}
+
+static int mv88fx_snd_spdif_stream_put(struct snd_kcontrol *kcontrol,
+				       struct snd_ctl_elem_value *ucontrol)
+{
+	struct mv88fx_snd_chip *chip = snd_kcontrol_chip(kcontrol);
+	int i, change =0 , word;
+	unsigned int val;
+
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+        val = 0;
+	spin_lock_irq(&chip->reg_lock);
+	for (word=0 ; word < 4; word++) {
+		for (i = 0; i < 4; i++){
+                        chip->stream[PLAYBACK]->spdif_status[word] |= 
+			ucontrol->value.iec958.status[word + i] << (i * 8);
+		}
+		 mv88fx_snd_writel(chip, 
+			MV_AUDIO_SPDIF_PLAY_CH_STATUS_LEFT_REG(0, word),
+			chip->stream[PLAYBACK]->spdif_status[word]);
+		 
+		 mv88fx_snd_writel(chip, 
+			MV_AUDIO_SPDIF_PLAY_CH_STATUS_RIGHT_REG(0, word),
+			chip->stream[PLAYBACK]->spdif_status[word]);
+
+	}
+	
+	if (chip->stream[PLAYBACK]->spdif_status[0] & IEC958_AES0_NONAUDIO) {
+                chip->pcm_mode = NON_PCM;
+	}
+	spin_unlock_irq(&chip->reg_lock);
+	return change;
+}
+
+static struct snd_kcontrol_new mv88fx_snd_spdif_stream  =
+{
+	.access =	SNDRV_CTL_ELEM_ACCESS_READWRITE | 
+			SNDRV_CTL_ELEM_ACCESS_INACTIVE,
+	.iface =	SNDRV_CTL_ELEM_IFACE_PCM,
+	.name =		SNDRV_CTL_NAME_IEC958("",PLAYBACK,PCM_STREAM),
+	.info =		mv88fx_snd_spdif_stream_info,
+	.get =		mv88fx_snd_spdif_stream_get,
+	.put =		mv88fx_snd_spdif_stream_put
+};
+
+
+static int mv88fx_snd_spdif_default_info(struct snd_kcontrol *kcontrol,
+					 struct snd_ctl_elem_info *uinfo)
+{
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	uinfo->type = SNDRV_CTL_ELEM_TYPE_IEC958;
+	uinfo->count = 1;
+	return 0;
+}
+
+static int mv88fx_snd_spdif_default_get(struct snd_kcontrol *kcontrol,
+					struct snd_ctl_elem_value *ucontrol)
+{
+	struct mv88fx_snd_chip *chip = snd_kcontrol_chip(kcontrol);
+	int i,word;
+
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	spin_lock_irq(&chip->reg_lock);
+	for (word=0 ; word < 4; word++) {
+		chip->stream_defaults[PLAYBACK]->spdif_status[word] = 
+		mv88fx_snd_readl(chip,
+				 MV_AUDIO_SPDIF_PLAY_CH_STATUS_LEFT_REG(0, word));
+		
+                for (i = 0; i < 4; i++)
+			ucontrol->value.iec958.status[word + i] = 
+			(chip->stream_defaults[PLAYBACK]->spdif_status[word] >> 
+								(i * 8)) & 0xff;
+
+	}
+	spin_unlock_irq(&chip->reg_lock);
+	return 0;
+}
+
+static int mv88fx_snd_spdif_default_put(struct snd_kcontrol *kcontrol,
+					 struct snd_ctl_elem_value *ucontrol)
+{
+	struct mv88fx_snd_chip *chip = snd_kcontrol_chip(kcontrol);
+	int i, change = 0, word;
+	unsigned int val;
+
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+        val = 0;
+	spin_lock_irq(&chip->reg_lock);
+	for (word=0 ; word < 4; word++) {
+		for (i = 0; i < 4; i++){
+                        chip->stream_defaults[PLAYBACK]->spdif_status[word] |= 
+			ucontrol->value.iec958.status[word + i] << (i * 8);
+		}
+		 mv88fx_snd_writel(chip, 
+			MV_AUDIO_SPDIF_PLAY_CH_STATUS_LEFT_REG(0, word),
+			chip->stream_defaults[PLAYBACK]->spdif_status[word]);
+		 mv88fx_snd_writel(chip, 
+			MV_AUDIO_SPDIF_PLAY_CH_STATUS_RIGHT_REG(0, word),
+			chip->stream_defaults[PLAYBACK]->spdif_status[word]);
+		 
+		 
+	}
+	if (chip->stream_defaults[PLAYBACK]->spdif_status[0] & 
+				IEC958_AES0_NONAUDIO) {
+		chip->pcm_mode = NON_PCM;
+	}
+	
+	spin_unlock_irq(&chip->reg_lock);
+	return change;
+}
+static struct snd_kcontrol_new mv88fx_snd_spdif_default __devinitdata =
+{
+	.iface =	SNDRV_CTL_ELEM_IFACE_PCM,
+	.name =		SNDRV_CTL_NAME_IEC958("",PLAYBACK,DEFAULT),
+	.info =		mv88fx_snd_spdif_default_info,
+	.get =		mv88fx_snd_spdif_default_get,
+	.put =		mv88fx_snd_spdif_default_put
+};
+
+
+
+
+/*
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+*/
+void cs42l51_vol_get(unsigned char *vol_list);
+void cs42l51_vol_set(unsigned char *vol_list);
+
+unsigned char mv88fx_snd_vol[2];
+
+static int mv88fx_snd_mixer_vol_info(struct snd_kcontrol *kcontrol, 
+			       struct snd_ctl_elem_info *uinfo)
+{
+	uinfo->type = SNDRV_CTL_ELEM_TYPE_INTEGER;
+	uinfo->count = 2;
+	uinfo->value.integer.min = 0;
+	uinfo->value.integer.max = 39;
+	return 0;
+}
+
+static int mv88fx_snd_mixer_vol_get(struct snd_kcontrol *kcontrol, 
+				    struct snd_ctl_elem_value *ucontrol)
+{
+	cs42l51_vol_get(mv88fx_snd_vol);
+	ucontrol->value.integer.value[0] = (long)mv88fx_snd_vol[0];
+	ucontrol->value.integer.value[1] = (long)mv88fx_snd_vol[1];
+	return 0;
+}
+
+static int mv88fx_snd_mixer_vol_put(struct snd_kcontrol *kcontrol, 
+				    struct snd_ctl_elem_value *ucontrol) {
+	
+	mv88fx_snd_vol[0] = (unsigned char)ucontrol->value.integer.value[0];
+	mv88fx_snd_vol[1] = (unsigned char)ucontrol->value.integer.value[1];
+	cs42l51_vol_set(mv88fx_snd_vol);
+
+	return 0;
+}
+
+static struct snd_kcontrol_new mv88fx_snd_dac_vol =
+{
+	.iface =	SNDRV_CTL_ELEM_IFACE_MIXER,
+	.name =		"Playback DAC Volume",
+	.info =		mv88fx_snd_mixer_vol_info,
+	.get =		mv88fx_snd_mixer_vol_get,
+	.put =		mv88fx_snd_mixer_vol_put
+};
+
+
+/*
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+*/
+
+
+struct mv88fx_snd_mixer_enum {
+	char 	**names;	/* enum names*/
+	int	*values;	/* values to be updated*/
+	int 	count;		/* number of elements */
+	void*	rec;		/* field to be updated*/
+};
+
+
+int mv88fx_snd_mixer_enum_info (struct snd_kcontrol * kcontrol, 
+			       struct snd_ctl_elem_info * uinfo)
+{
+	struct mv88fx_snd_mixer_enum	*mixer_enum = 
+		(struct mv88fx_snd_mixer_enum*)kcontrol->private_value;
+
+	uinfo->type = SNDRV_CTL_ELEM_TYPE_ENUMERATED;
+	uinfo->count = 1;
+	uinfo->value.enumerated.items = mixer_enum->count;
+
+	if (uinfo->value.enumerated.item >= uinfo->value.enumerated.items)
+		uinfo->value.enumerated.item =
+		    uinfo->value.enumerated.items - 1;
+
+	strcpy(uinfo->value.enumerated.name,
+	       mixer_enum->names[uinfo->value.enumerated.item]);
+
+	return 0;
+}
+int mv88fx_snd_mixer_enum_get (struct snd_kcontrol * kcontrol, 
+			      struct snd_ctl_elem_value * ucontrol)
+{
+	struct mv88fx_snd_mixer_enum	*mixer_enum = 
+		(struct mv88fx_snd_mixer_enum*)kcontrol->private_value;
+	int i;
+	unsigned int val;
+
+	val = *(unsigned int*)mixer_enum->rec;
+	
+	for (i=0 ; i<mixer_enum->count ; i++) {
+		
+		if (val ==  (unsigned int)mixer_enum->values[i]) {
+			ucontrol->value.enumerated.item[0] = i;
+			break;
+		}
+	}
+	
+	return 0;
+}
+
+int mv88fx_snd_mixer_enum_put (struct snd_kcontrol * kcontrol, 
+			      struct snd_ctl_elem_value * ucontrol)
+{
+	unsigned int val,*rec;
+	struct mv88fx_snd_mixer_enum	*mixer_enum = 
+		(struct mv88fx_snd_mixer_enum*)kcontrol->private_value;
+	int i;
+
+	rec = (unsigned int*)mixer_enum->rec;
+	val = ucontrol->value.enumerated.item[0];
+
+	if (val < 0)
+		val = 0;
+	if (val > mixer_enum->count)
+		val = mixer_enum->count;
+
+	for (i=0 ; i<mixer_enum->count ; i++) {
+
+		if (val ==  i) {
+			*rec = (unsigned int)mixer_enum->values[i];
+			break;
+		}
+	}
+	
+	return 0;
+}
+
+
+
+#define MV88FX_PCM_MIXER_ENUM(xname, xindex, value)	\
+{ .iface = SNDRV_CTL_ELEM_IFACE_MIXER, \
+  .name = xname, \
+  .index = xindex, \
+  .info = mv88fx_snd_mixer_enum_info, \
+  .get = mv88fx_snd_mixer_enum_get, \
+  .put = mv88fx_snd_mixer_enum_put, \
+  .private_value = (unsigned long)value,	\
+}
+
+char *playback_src_mixer_names[] = {"SPDIF","I2S", "SPDIF And I2S"};
+int playback_src_mixer_values[] = { SPDIF, I2S, (SPDIF|I2S)};
+
+struct mv88fx_snd_mixer_enum playback_src_mixer	= 
+{
+	.names	= playback_src_mixer_names,
+	.values	= playback_src_mixer_values,
+	.count	= 3,
+};
+
+char *playback_mono_mixer_names[] = {"Mono Both","Mono Left", "Mono Right"};
+int playback_mono_mixer_values[] = { MONO_BOTH, MONO_LEFT, MONO_RIGHT};
+
+struct mv88fx_snd_mixer_enum playback_mono_mixer	= 
+{
+	.names	= playback_mono_mixer_names,
+	.values	= playback_mono_mixer_values,
+	.count	= 3,
+};
+
+
+
+
+char *capture_src_mixer_names[] = {"SPDIF","I2S"};
+int capture_src_mixer_values[] = { SPDIF, I2S};
+
+struct mv88fx_snd_mixer_enum capture_src_mixer	= 
+{
+	.names	= capture_src_mixer_names,
+	.values	= capture_src_mixer_values,
+	.count	= 2,
+};
+
+char *capture_mono_mixer_names[] = {"Mono Left", "Mono Right"};
+int capture_mono_mixer_values[] = { MONO_LEFT, MONO_RIGHT};
+
+struct mv88fx_snd_mixer_enum capture_mono_mixer	= 
+{
+	.names	= capture_mono_mixer_names,
+	.values	= capture_mono_mixer_values,
+	.count	= 2,
+};
+
+
+static struct snd_kcontrol_new mv88fx_snd_mixers[] = {
+	MV88FX_PCM_MIXER_ENUM("Playback output type", 0,
+				    &playback_src_mixer), 
+
+	MV88FX_PCM_MIXER_ENUM("Playback mono type", 0,
+				    &playback_mono_mixer), 
+
+	MV88FX_PCM_MIXER_ENUM("Capture input Type", 0,
+				    &capture_src_mixer),
+	
+	MV88FX_PCM_MIXER_ENUM("Capture mono type", 0,
+				    &capture_mono_mixer), 
+
+};
+
+#define	PLAYBACK_MIX_INDX	0
+#define PLAYBACK_MONO_MIX_INDX	1
+#define CAPTURE_MIX_INDX	2
+#define	CAPTURE_MONO_MIX_INDX	3
+
+static int
+mv88fx_snd_ctrl_new(struct snd_card *card)
+{
+	int err=0;
+
+	playback_src_mixer.rec = &chip->stream_defaults[PLAYBACK]->dig_mode;
+	playback_mono_mixer.rec = &chip->stream_defaults[PLAYBACK]->mono_mode;
+	
+	capture_src_mixer.rec = &chip->stream_defaults[CAPTURE]->dig_mode;
+	capture_mono_mixer.rec = &chip->stream_defaults[CAPTURE]->mono_mode;
+
+	if((chip->audio_info->i2s_play) && (chip->audio_info->spdif_play)) {
+		err = snd_ctl_add(card, snd_ctl_new1(&mv88fx_snd_mixers[PLAYBACK_MIX_INDX],
+						     chip));
+		if (err < 0)
+			return err;
+	}
+
+	err = snd_ctl_add(card, snd_ctl_new1(&mv88fx_snd_mixers[PLAYBACK_MONO_MIX_INDX],
+						     chip));
+	if (err < 0)
+		return err;
+
+	if((chip->audio_info->i2s_rec) && (chip->audio_info->spdif_rec)) {
+		err = snd_ctl_add(card, snd_ctl_new1(&mv88fx_snd_mixers[CAPTURE_MIX_INDX],
+							     chip));
+		if (err < 0)
+			return err;
+	}
+	
+	err = snd_ctl_add(card, snd_ctl_new1(&mv88fx_snd_mixers[CAPTURE_MONO_MIX_INDX],
+						     chip));
+	if (err < 0)
+		return err;
+
+	if(chip->audio_info->i2s_play) {
+	err = snd_ctl_add(card, snd_ctl_new1(&mv88fx_snd_dac_vol,
+					     chip));
+	if (err < 0)
+		return err;
+	}
+		
+	err = snd_ctl_add(card, snd_ctl_new1(&mv88fx_snd_spdif_mask,
+					     chip));
+	if (err < 0)
+		return err;
+
+	err = snd_ctl_add(card, snd_ctl_new1(&mv88fx_snd_spdif_default,
+					     chip));
+	if (err < 0)
+		return err;
+
+	err = snd_ctl_add(card, snd_ctl_new1(&mv88fx_snd_spdif_stream,
+					     chip));
+	if (err < 0)
+		return err;
+	
+	
+
+	return err;
+}
+
+
+/*
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+*/
+
+
+
+static struct snd_pcm_hardware mv88fx_snd_capture_hw =
+{
+	.info =			(SNDRV_PCM_INFO_INTERLEAVED |
+				 SNDRV_PCM_INFO_MMAP |
+				 SNDRV_PCM_INFO_MMAP_VALID |
+				 SNDRV_PCM_INFO_BLOCK_TRANSFER |
+				 SNDRV_PCM_INFO_PAUSE ), 
+	.formats =		(SNDRV_PCM_FMTBIT_S16_LE |
+				 SNDRV_PCM_FMTBIT_S24_LE |
+				 SNDRV_PCM_FMTBIT_S32_LE),
+	.rates =		(SNDRV_PCM_RATE_44100 |
+				 SNDRV_PCM_RATE_48000 |
+				 SNDRV_PCM_RATE_96000),
+	.rate_min =		44100,
+	.rate_max =		96000,
+	.channels_min =		1,
+	.channels_max =		2,
+	.buffer_bytes_max =	(16*1024*1024),
+	.period_bytes_min =	MV88FX_SND_MIN_PERIOD_BYTES,
+	.period_bytes_max =	MV88FX_SND_MAX_PERIOD_BYTES,
+	.periods_min =		MV88FX_SND_MIN_PERIODS,
+	.periods_max =		MV88FX_SND_MAX_PERIODS,
+	.fifo_size =		0,
+
+};
+
+
+
+static int
+mv88fx_snd_capture_open(struct snd_pcm_substream * substream)
+{
+	int err;
+
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	chip->stream_defaults[CAPTURE]->substream = substream;
+	chip->stream_defaults[CAPTURE]->direction = CAPTURE;
+	substream->private_data = chip->stream_defaults[CAPTURE];
+	substream->runtime->hw = mv88fx_snd_capture_hw;
+
+	if (chip->stream_defaults[CAPTURE]->dig_mode & SPDIF) {
+		substream->runtime->hw.formats &= ~SNDRV_PCM_FMTBIT_S32_LE;
+	}
+	
+	/* check if playback is already running with specific rate */
+	if (chip->stream[PLAYBACK]->rate) {
+		switch 	(chip->stream[PLAYBACK]->rate) {
+			case 44100:
+				substream->runtime->hw.rates = SNDRV_PCM_RATE_44100;
+				break;
+			case 48000:
+				substream->runtime->hw.rates = SNDRV_PCM_RATE_48000;
+				break;
+			case 96000:
+				substream->runtime->hw.rates = SNDRV_PCM_RATE_96000;
+				break;
+
+		}
+	}
+	
+	
+	err = snd_pcm_hw_constraint_minmax(substream->runtime,
+					   SNDRV_PCM_HW_PARAM_BUFFER_BYTES,
+					   chip->burst * 2, 
+					   AUDIO_REG_TO_SIZE(APBBCR_SIZE_MAX));
+        if (err < 0)
+                return err;
+	
+	err = snd_pcm_hw_constraint_step(substream->runtime, 0,
+					 SNDRV_PCM_HW_PARAM_BUFFER_BYTES,
+					 chip->burst); 
+        if (err < 0)
+                return err;
+	
+	err = snd_pcm_hw_constraint_step(substream->runtime, 0, 
+					 SNDRV_PCM_HW_PARAM_PERIOD_BYTES,
+					 chip->burst);
+        if (err < 0)
+                return err;
+
+	err = snd_pcm_hw_constraint_minmax(substream->runtime,
+					   SNDRV_PCM_HW_PARAM_PERIODS,
+					   MV88FX_SND_MIN_PERIODS, 
+					   MV88FX_SND_MAX_PERIODS);
+        if (err < 0)
+                return err;
+	
+        err = snd_pcm_hw_constraint_integer(substream->runtime, 
+					    SNDRV_PCM_HW_PARAM_PERIODS);
+        if (err < 0)
+                return err;
+        
+	return 0;
+
+}
+
+static int
+mv88fx_snd_capture_close(struct snd_pcm_substream * substream)
+{
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	chip->stream_defaults[CAPTURE]->substream = NULL;
+	memset(chip->stream[CAPTURE] , 
+		0, 
+		sizeof(struct mv88fx_snd_stream));
+
+	return 0;
+}
+static int
+mv88fx_snd_capture_hw_params(struct snd_pcm_substream * substream,
+					struct snd_pcm_hw_params* params)
+{
+	struct mv88fx_snd_stream *audio_stream = 
+		snd_pcm_substream_chip(substream); int err = 0; 
+	
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	
+        err = devdma_hw_alloc(audio_stream->dev, substream,
+			      params_buffer_bytes(params));
+	return err;
+}
+
+static int
+mv88fx_snd_capture_hw_free(struct snd_pcm_substream * substream)
+{
+	struct mv88fx_snd_stream *audio_stream = 
+		snd_pcm_substream_chip(substream); 
+
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	/*
+	 * Clear out the DMA and any allocated buffers.
+	 */
+	devdma_hw_free(audio_stream->dev, substream);
+	return 0;
+	
+}
+
+static int
+mv88fx_snd_capture_prepare(struct snd_pcm_substream * substream)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	
+	struct mv88fx_snd_stream *audio_stream = 
+		snd_pcm_substream_chip(substream); 
+
+
+	audio_stream->rate = runtime->rate;
+        audio_stream->stereo= (runtime->channels == 1) ? 0 : 1;
+
+	if (runtime->format == SNDRV_PCM_FORMAT_S16_LE) {
+		audio_stream->format = SAMPLE_16IN16;
+	} else if (runtime->format == SNDRV_PCM_FORMAT_S24_LE) {
+		audio_stream->format = SAMPLE_24IN32;
+	} else if (runtime->format == SNDRV_PCM_FORMAT_S32_LE) {
+		audio_stream->format = SAMPLE_32IN32;
+	} else {
+		mv88fx_snd_debug("Requested format %d is not supported\n", 
+			   runtime->format);
+		return -1;
+	}
+
+	/* buffer and period sizes in frame */
+	audio_stream->dma_addr = runtime->dma_addr;
+	audio_stream->dma_size = 
+		frames_to_bytes(runtime, runtime->buffer_size);
+	audio_stream->period_size = 
+		frames_to_bytes(runtime, runtime->period_size);
+
+	memcpy(chip->stream[CAPTURE], 
+	       chip->stream_defaults[CAPTURE],
+	       sizeof(struct mv88fx_snd_stream));
+	return mv88fx_snd_hw_capture_set(chip);
+}
+
+static int
+mv88fx_snd_capture_trigger(struct snd_pcm_substream *substream, int cmd)
+{
+	struct mv88fx_snd_stream *audio_stream = 
+		snd_pcm_substream_chip(substream); 
+	int result = 0;
+
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	
+	spin_lock(chip->reg_lock);
+	switch (cmd) {
+	case SNDRV_PCM_TRIGGER_START:
+		/* FIXME: should check if busy before */
+
+		/* make sure the dma in pause state*/
+		mv88fx_snd_bitset(chip, MV_AUDIO_RECORD_CTRL_REG(0),
+				  ARCR_RECORD_PAUSE_MASK);
+
+		/* enable interrupt */
+		mv88fx_snd_bitset(chip, MV_AUDIO_INT_MASK_REG(0), 
+				  AICR_RECORD_BYTES_INT);
+
+
+		/* enable dma */
+		if (audio_stream->dig_mode & I2S)
+			mv88fx_snd_bitset(chip, MV_AUDIO_RECORD_CTRL_REG(0),
+					  ARCR_RECORD_I2S_EN_MASK);
+
+		if (audio_stream->dig_mode & SPDIF)
+			mv88fx_snd_bitset(chip, MV_AUDIO_RECORD_CTRL_REG(0),
+					  ARCR_RECORD_SPDIF_EN_MASK);
+
+		/* start dma */
+		mv88fx_snd_bitreset(chip, MV_AUDIO_RECORD_CTRL_REG(0),
+				  ARCR_RECORD_PAUSE_MASK);
+		
+		
+		break;
+	case SNDRV_PCM_TRIGGER_STOP:
+
+		/* make sure the dma in pause state*/
+		mv88fx_snd_bitset(chip, MV_AUDIO_RECORD_CTRL_REG(0),
+				  ARCR_RECORD_PAUSE_MASK);
+		
+                /* disable interrupt */
+		mv88fx_snd_bitreset(chip, MV_AUDIO_INT_MASK_REG(0), 
+				  AICR_RECORD_BYTES_INT);
+
+		
+		/* always stop both I2S and SPDIF*/
+		mv88fx_snd_bitreset(chip, MV_AUDIO_RECORD_CTRL_REG(0),
+				    (ARCR_RECORD_I2S_EN_MASK | 
+				     ARCR_RECORD_SPDIF_EN_MASK));
+		
+                /* FIXME: should check if busy after */
+		
+		break;
+	case SNDRV_PCM_TRIGGER_PAUSE_PUSH:
+	case SNDRV_PCM_TRIGGER_SUSPEND:
+		mv88fx_snd_bitset(chip, MV_AUDIO_RECORD_CTRL_REG(0),
+				  ARCR_RECORD_PAUSE_MASK);
+		break;
+	case SNDRV_PCM_TRIGGER_RESUME:
+	case SNDRV_PCM_TRIGGER_PAUSE_RELEASE:
+		mv88fx_snd_bitreset(chip, MV_AUDIO_RECORD_CTRL_REG(0),
+				    ARCR_RECORD_PAUSE_MASK);
+
+		break;
+	default:
+		result = -EINVAL;
+		break;
+	}
+	spin_unlock(&chip->reg_lock);
+	return result;
+}
+
+
+static snd_pcm_uframes_t 
+mv88fx_snd_capture_pointer(struct snd_pcm_substream * substream)
+{
+	return bytes_to_frames(substream->runtime, 
+			       (ssize_t)mv88fx_snd_readl(chip, 
+		       		MV_AUDIO_RECORD_BUF_BYTE_CNTR_REG(0)));
+}
+
+int 
+mv88fx_snd_capture_mmap(struct snd_pcm_substream *substream, 
+			 struct vm_area_struct *vma)
+{
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	return devdma_mmap(NULL, substream, vma);	
+	
+}
+
+static struct snd_pcm_ops mv88fx_snd_capture_ops = {
+	.open			= mv88fx_snd_capture_open,
+	.close			= mv88fx_snd_capture_close,
+	.ioctl			= snd_pcm_lib_ioctl,
+	.hw_params	        = mv88fx_snd_capture_hw_params,
+	.hw_free	        = mv88fx_snd_capture_hw_free,
+	.prepare		= mv88fx_snd_capture_prepare,
+	.trigger		= mv88fx_snd_capture_trigger,
+	.pointer		= mv88fx_snd_capture_pointer,
+	.mmap 			= mv88fx_snd_capture_mmap,
+};
+
+/*
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+*/
+
+
+
+struct snd_pcm_hardware mv88fx_snd_playback_hw =
+{
+	.info =			(SNDRV_PCM_INFO_INTERLEAVED |
+				 SNDRV_PCM_INFO_MMAP |
+				 SNDRV_PCM_INFO_MMAP_VALID |
+				 SNDRV_PCM_INFO_BLOCK_TRANSFER |
+				 SNDRV_PCM_INFO_PAUSE ), 
+	.formats =		(SNDRV_PCM_FMTBIT_S16_LE |
+				 SNDRV_PCM_FMTBIT_S24_LE |
+				 SNDRV_PCM_FMTBIT_S32_LE),
+	.rates =		(SNDRV_PCM_RATE_44100 |
+				 SNDRV_PCM_RATE_48000 |
+				 SNDRV_PCM_RATE_96000),
+	.rate_min =		44100,
+	.rate_max =		96000,
+	.channels_min =		1,
+	.channels_max =		2,
+	.buffer_bytes_max =	(16*1024*1024),
+	.period_bytes_min =	MV88FX_SND_MIN_PERIOD_BYTES,
+	.period_bytes_max =	MV88FX_SND_MAX_PERIOD_BYTES,
+	.periods_min =		MV88FX_SND_MIN_PERIODS,
+	.periods_max =		MV88FX_SND_MAX_PERIODS,
+	.fifo_size =		0,
+
+};
+
+static int
+mv88fx_snd_playback_open(struct snd_pcm_substream * substream)
+{
+	int err = 0; 
+
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	chip->stream_defaults[PLAYBACK]->substream = substream;
+	chip->stream_defaults[PLAYBACK]->direction = PLAYBACK;
+	substream->private_data = chip->stream_defaults[PLAYBACK];
+	substream->runtime->hw = mv88fx_snd_playback_hw;
+
+	if (chip->stream_defaults[PLAYBACK]->dig_mode & SPDIF) {
+		substream->runtime->hw.formats &= ~SNDRV_PCM_FMTBIT_S32_LE;
+	}
+
+	/* check if capture is already running with specific rate */
+	if (chip->stream[CAPTURE]->rate) {
+		switch 	(chip->stream[CAPTURE]->rate) {
+			case 44100:
+				substream->runtime->hw.rates = SNDRV_PCM_RATE_44100;
+				break;
+			case 48000:
+				substream->runtime->hw.rates = SNDRV_PCM_RATE_48000;
+				break;
+			case 96000:
+				substream->runtime->hw.rates = SNDRV_PCM_RATE_96000;
+				break;
+
+		}
+	}
+
+	err = snd_pcm_hw_constraint_minmax(substream->runtime,
+					   SNDRV_PCM_HW_PARAM_BUFFER_BYTES,
+					   chip->burst * 2, 
+					   AUDIO_REG_TO_SIZE(APBBCR_SIZE_MAX));
+        if (err < 0)
+                return err;
+	
+	err = snd_pcm_hw_constraint_step(substream->runtime, 0,
+					 SNDRV_PCM_HW_PARAM_BUFFER_BYTES,
+					 chip->burst); 
+        if (err < 0)
+                return err;
+	
+	err = snd_pcm_hw_constraint_step(substream->runtime, 0, 
+					 SNDRV_PCM_HW_PARAM_PERIOD_BYTES,
+					 chip->burst);
+        if (err < 0)
+                return err;
+
+	err = snd_pcm_hw_constraint_minmax(substream->runtime,
+					   SNDRV_PCM_HW_PARAM_PERIODS,
+					   MV88FX_SND_MIN_PERIODS, 
+					   MV88FX_SND_MAX_PERIODS);
+        if (err < 0)
+                return err;
+	
+        err = snd_pcm_hw_constraint_integer(substream->runtime, 
+					    SNDRV_PCM_HW_PARAM_PERIODS);
+
+        if (err < 0)
+                return err;
+        
+	return 0;
+
+}
+
+static int
+mv88fx_snd_playback_close(struct snd_pcm_substream * substream)
+{
+	int i;
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	chip->stream_defaults[PLAYBACK]->substream = NULL;
+
+	chip->pcm_mode = PCM;
+
+	for (i=0; i<4 ; i++) {
+		chip->stream_defaults[PLAYBACK]->spdif_status[i] = 0;
+		chip->stream[PLAYBACK]->spdif_status[i] = 0;
+
+		 mv88fx_snd_writel(chip, 
+			MV_AUDIO_SPDIF_PLAY_CH_STATUS_LEFT_REG(0, i),
+			chip->stream_defaults[PLAYBACK]->spdif_status[i]);
+		 mv88fx_snd_writel(chip, 
+			MV_AUDIO_SPDIF_PLAY_CH_STATUS_RIGHT_REG(0, i),
+			chip->stream_defaults[PLAYBACK]->spdif_status[i]);
+
+	}
+
+	memset(chip->stream[PLAYBACK] , 
+		0, 
+		sizeof(struct mv88fx_snd_stream));
+
+	
+	return 0;
+}
+static int
+mv88fx_snd_playback_hw_params(struct snd_pcm_substream * substream,
+					struct snd_pcm_hw_params* params)
+{
+	struct mv88fx_snd_stream *audio_stream = 
+		snd_pcm_substream_chip(substream); int err = 0; 
+	
+	
+        err = devdma_hw_alloc(audio_stream->dev, substream,
+			      params_buffer_bytes(params));
+
+	//mv88fx_snd_debug("=>%s addr=0x%x size=0x%x\n",__FUNCTION__,
+	//	   substream->runtime->dma_addr,
+	//	   frames_to_bytes(substream->runtime, 
+	//			   substream->runtime->buffer_size));
+	
+
+	return err;
+}
+
+static int
+mv88fx_snd_playback_hw_free(struct snd_pcm_substream * substream)
+{
+	struct mv88fx_snd_stream *audio_stream = 
+		snd_pcm_substream_chip(substream); 
+
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	/*
+	 * Clear out the DMA and any allocated buffers.
+	 */
+	devdma_hw_free(audio_stream->dev, substream);
+	return 0;
+	
+}
+
+static int
+mv88fx_snd_playback_prepare(struct snd_pcm_substream * substream)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	
+	struct mv88fx_snd_stream *audio_stream = 
+		snd_pcm_substream_chip(substream); 
+
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+        if ((audio_stream->dig_mode == I2S) && 
+	    (chip->pcm_mode == NON_PCM))
+		return -1;
+
+	audio_stream->rate = runtime->rate;
+        audio_stream->stereo= (runtime->channels == 1) ? 0 : 1;
+
+	if (runtime->format == SNDRV_PCM_FORMAT_S16_LE) {
+		audio_stream->format = SAMPLE_16IN16;
+	} else if (runtime->format == SNDRV_PCM_FORMAT_S24_LE) {
+		audio_stream->format = SAMPLE_24IN32;
+	} else if (runtime->format == SNDRV_PCM_FORMAT_S32_LE) {
+		audio_stream->format = SAMPLE_32IN32;
+	} else {
+		mv88fx_snd_debug("Requested format %d is not supported\n", 
+			   runtime->format);
+		return -1;
+	}
+
+	/* buffer and period sizes in frame */
+	audio_stream->dma_addr = runtime->dma_addr;
+	audio_stream->dma_size = 
+		frames_to_bytes(runtime, runtime->buffer_size);
+	audio_stream->period_size = 
+		frames_to_bytes(runtime, runtime->period_size);
+
+	memcpy(chip->stream[PLAYBACK], 
+	       chip->stream_defaults[PLAYBACK],
+	       sizeof(struct mv88fx_snd_stream));
+	
+	return mv88fx_snd_hw_playback_set(chip);
+}
+
+static int
+mv88fx_snd_playback_trigger(struct snd_pcm_substream *substream, int cmd)
+{
+	struct mv88fx_snd_stream *audio_stream = 
+		snd_pcm_substream_chip(substream); 
+	int result = 0;
+
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	
+	spin_lock(chip->reg_lock);
+	switch (cmd) {
+	case SNDRV_PCM_TRIGGER_START:
+		/* enable interrupt */
+		mv88fx_snd_bitset(chip, MV_AUDIO_INT_MASK_REG(0), 
+				  AICR_PLAY_BYTES_INT);
+
+		/* make sure the dma in pause state*/
+		mv88fx_snd_bitset(chip, MV_AUDIO_PLAYBACK_CTRL_REG(0),
+				  APCR_PLAY_PAUSE_MASK);
+
+		/* enable dma */
+                if ((audio_stream->dig_mode & I2S) && 
+		    (chip->pcm_mode == PCM))
+			mv88fx_snd_bitset(chip, MV_AUDIO_PLAYBACK_CTRL_REG(0),
+					  APCR_PLAY_I2S_ENABLE_MASK);
+		
+		if (audio_stream->dig_mode & SPDIF)
+			mv88fx_snd_bitset(chip, MV_AUDIO_PLAYBACK_CTRL_REG(0),
+					  APCR_PLAY_SPDIF_ENABLE_MASK);
+
+		/* start dma */
+		mv88fx_snd_bitreset(chip, MV_AUDIO_PLAYBACK_CTRL_REG(0),
+				    APCR_PLAY_PAUSE_MASK);
+		
+		break;
+	case SNDRV_PCM_TRIGGER_STOP:
+		
+                /* disable interrupt */
+		mv88fx_snd_bitreset(chip, MV_AUDIO_INT_MASK_REG(0), 
+				  AICR_PLAY_BYTES_INT);
+
+
+		/* make sure the dma in pause state*/
+		mv88fx_snd_bitset(chip, MV_AUDIO_PLAYBACK_CTRL_REG(0),
+				  APCR_PLAY_PAUSE_MASK);
+		
+		/* always stop both I2S and SPDIF*/
+		mv88fx_snd_bitreset(chip, MV_AUDIO_PLAYBACK_CTRL_REG(0),
+				    (APCR_PLAY_I2S_ENABLE_MASK | 
+				     APCR_PLAY_SPDIF_ENABLE_MASK));
+
+		/* check if busy twice*/
+		while (mv88fx_snd_readl(chip, MV_AUDIO_PLAYBACK_CTRL_REG(0)) & 
+		       APCR_PLAY_BUSY_MASK);
+		
+		while (mv88fx_snd_readl(chip, MV_AUDIO_PLAYBACK_CTRL_REG(0)) & 
+		       APCR_PLAY_BUSY_MASK);
+		
+		break;
+	case SNDRV_PCM_TRIGGER_PAUSE_PUSH:
+	case SNDRV_PCM_TRIGGER_SUSPEND:
+		mv88fx_snd_bitset(chip, MV_AUDIO_PLAYBACK_CTRL_REG(0),
+				  APCR_PLAY_PAUSE_MASK);
+		break;
+	case SNDRV_PCM_TRIGGER_RESUME:
+	case SNDRV_PCM_TRIGGER_PAUSE_RELEASE:
+		mv88fx_snd_bitreset(chip, MV_AUDIO_PLAYBACK_CTRL_REG(0),
+				    APCR_PLAY_PAUSE_MASK);
+
+		break;
+	default:
+		result = -EINVAL;
+		break;
+	}
+	spin_unlock(&chip->reg_lock);
+	return result;
+}
+
+
+static snd_pcm_uframes_t 
+mv88fx_snd_playback_pointer(struct snd_pcm_substream * substream)
+{
+	return bytes_to_frames(substream->runtime, 
+			       (ssize_t)mv88fx_snd_readl(chip, 
+		       		MV_AUDIO_PLAYBACK_BUFF_BYTE_CNTR_REG(0)));
+}
+
+int 
+mv88fx_snd_playback_mmap(struct snd_pcm_substream *substream, 
+			 struct vm_area_struct *vma)
+{
+	//mv88fx_snd_debug("=>%s\n",__FUNCTION__);
+	return devdma_mmap(NULL, substream, vma);	
+	
+}
+
+
+static struct snd_pcm_ops mv88fx_snd_playback_ops = {
+	.open			= mv88fx_snd_playback_open,
+	.close			= mv88fx_snd_playback_close,
+	.ioctl			= snd_pcm_lib_ioctl,
+	.hw_params	        = mv88fx_snd_playback_hw_params,
+	.hw_free	        = mv88fx_snd_playback_hw_free,
+	.prepare		= mv88fx_snd_playback_prepare,
+	.trigger		= mv88fx_snd_playback_trigger,
+	.pointer		= mv88fx_snd_playback_pointer,
+	.mmap 			= mv88fx_snd_playback_mmap,
+};
+
+
+/*
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+-----------------------------------------------------------------------------
+*/
+
+
+static int __init 
+mv88fx_snd_pcm_new(struct snd_card *card)
+{
+	struct snd_pcm *pcm;
+	int err, i;
+
+	mv88fx_snd_debug("=>%s card->dev=0x%x\n",__FUNCTION__, 
+		   (unsigned int)card->dev);
+	
+	if ((err = snd_pcm_new(card, "Marvell mv88fx_snd IEC958 and I2S", 
+			       0, 1, 1, &pcm)) < 0) 
+		return err;
+
+	snd_pcm_set_ops(pcm, SNDRV_PCM_STREAM_PLAYBACK, 
+			&mv88fx_snd_playback_ops);
+	
+	snd_pcm_set_ops(pcm, SNDRV_PCM_STREAM_CAPTURE, 
+			&mv88fx_snd_capture_ops);
+	if((chip->audio_info->i2s_play) && (chip->audio_info->spdif_play))	
+	chip->stream_defaults[PLAYBACK]->dig_mode = (SPDIF | I2S);
+	else if((chip->audio_info->i2s_play))
+		chip->stream_defaults[PLAYBACK]->dig_mode = I2S;
+	else if((chip->audio_info->spdif_play))
+		chip->stream_defaults[PLAYBACK]->dig_mode = SPDIF;
+	else
+		chip->stream_defaults[PLAYBACK]->dig_mode = 0;
+	chip->stream_defaults[PLAYBACK]->mono_mode = MONO_BOTH;
+	chip->pcm_mode = PCM;
+	chip->stream_defaults[PLAYBACK]->stat_mem = 0;
+	chip->stream_defaults[PLAYBACK]->clock_src = DCO_CLOCK;
+
+	if((chip->audio_info->i2s_rec))
+	chip->stream_defaults[CAPTURE]->dig_mode = I2S;
+	else if((chip->audio_info->spdif_rec))
+		chip->stream_defaults[CAPTURE]->dig_mode = SPDIF;
+	else
+		chip->stream_defaults[CAPTURE]->dig_mode = 0;
+
+	chip->stream_defaults[CAPTURE]->mono_mode = MONO_LEFT;
+	chip->pcm_mode = PCM;
+	chip->stream_defaults[CAPTURE]->stat_mem = 0;
+	chip->stream_defaults[CAPTURE]->clock_src = DCO_CLOCK;
+
+	for (i=0; i<4 ; i++) {
+		chip->stream_defaults[PLAYBACK]->spdif_status[i] = 0;
+		chip->stream[PLAYBACK]->spdif_status[i] = 0;
+		
+		mv88fx_snd_writel(chip, 
+			MV_AUDIO_SPDIF_PLAY_CH_STATUS_LEFT_REG(0, i),
+			chip->stream_defaults[PLAYBACK]->spdif_status[i]);
+		mv88fx_snd_writel(chip, 
+			MV_AUDIO_SPDIF_PLAY_CH_STATUS_RIGHT_REG(0, i),
+			chip->stream_defaults[PLAYBACK]->spdif_status[i]);
+		mv88fx_snd_writel(chip, 
+			MV_AUDIO_SPDIF_PLAY_USR_BITS_LEFT_REG(0, i),
+			0);
+		mv88fx_snd_writel(chip, 
+			MV_AUDIO_SPDIF_PLAY_USR_BITS_RIGHT_REG(0, i),
+			0);
+		
+	}
+	
+
+	pcm->private_data = chip;
+	pcm->info_flags = 0;
+        strcpy(pcm->name, "Marvell mv88fx_snd IEC958 and I2S");
+
+	return 0;
+}
+
+static irqreturn_t
+mv88fx_snd_interrupt(int irq, void *dev_id)
+{
+	struct mv88fx_snd_chip *chip = dev_id;
+	struct mv88fx_snd_stream *play_stream =
+		chip->stream_defaults[PLAYBACK];
+	struct mv88fx_snd_stream *capture_stream =
+		chip->stream_defaults[CAPTURE];
+	
+			
+	unsigned int status, mask;
+
+	spin_lock(&chip->reg_lock);
+	
+	/* read the active interrupt */
+	mask = mv88fx_snd_readl(chip, MV_AUDIO_INT_MASK_REG(0));
+	status = mv88fx_snd_readl(chip, MV_AUDIO_INT_CAUSE_REG(0)) & mask;
+
+	do {
+	
+
+		if (status & ~(AICR_RECORD_BYTES_INT|AICR_PLAY_BYTES_INT)) {
+	
+	                spin_unlock(&chip->reg_lock);
+			snd_BUG(); /* FIXME: should enable error interrupts*/
+			return IRQ_NONE;
+		}
+	
+		/* acknowledge interrupt */
+		mv88fx_snd_writel(chip, MV_AUDIO_INT_CAUSE_REG(0), status);
+	
+		/* This is record event */
+		if (status & AICR_RECORD_BYTES_INT) {
+	
+			snd_pcm_period_elapsed(capture_stream->substream);
+			//printk("int:capture_stream=0x%x rec_count=0x%x\n",(unsigned int)capture_stream, mv88fx_snd_readl(chip, 
+			  //     		MV_AUDIO_RECORD_BUF_BYTE_CNTR_REG));
+		}
+		/* This is play event */
+		if (status & AICR_PLAY_BYTES_INT) {
+			
+			snd_pcm_period_elapsed(play_stream->substream);
+			//printk("int:play_stream=0x%x rec_count=0x%x\n",(unsigned int)play_stream, mv88fx_snd_readl(chip, 
+			  //     		MV_AUDIO_PLAYBACK_BUFF_BYTE_CNTR_REG));
+		
+		}
+	
+		/* read the active interrupt */
+		mask = mv88fx_snd_readl(chip, MV_AUDIO_INT_MASK_REG(0));
+		status = mv88fx_snd_readl(chip, MV_AUDIO_INT_CAUSE_REG(0)) & mask;
+
+	} while(status);
+
+	spin_unlock(&chip->reg_lock);
+
+	return IRQ_HANDLED;
+}
+
+static void 
+mv88fx_snd_free(struct snd_card *card)
+{
+	struct mv88fx_snd_chip *chip = card->private_data;
+
+	mv88fx_snd_debug("=>%s chip=0x%x\n",__FUNCTION__,(unsigned int)chip);
+	
+	/* free irq */
+	free_irq(chip->irq, (void *)chip);
+
+	mv88fx_snd_debug(KERN_ERR "chip->res =0x%x\n", (unsigned int)chip->res);
+
+	if (chip->base)
+		iounmap(chip->base);
+	
+	if (chip->res) 
+		release_resource(chip->res);
+	
+	chip->res = NULL;
+	
+		
+	/* Free memory allocated for streems */
+	if (chip->stream_defaults[PLAYBACK]) {
+		kfree(chip->stream_defaults[PLAYBACK]);
+		chip->stream_defaults[PLAYBACK] = NULL;
+	}
+	if (chip->stream[PLAYBACK]) {
+		kfree(chip->stream[PLAYBACK]);
+		chip->stream[PLAYBACK] = NULL;
+	}	
+	if (chip->stream_defaults[CAPTURE]) {
+		kfree(chip->stream_defaults[CAPTURE]);
+		chip->stream_defaults[CAPTURE] = NULL;
+	}
+	if (chip->stream[CAPTURE]) {
+		kfree(chip->stream[CAPTURE]);
+		chip->stream[CAPTURE] = NULL;
+	}
+
+	if (chip->stream_defaults[PLAYBACK]->area)
+		dma_free_coherent(chip->dev, 
+				MV88FX_SND_MAX_PERIODS * MV88FX_SND_MAX_PERIOD_BYTES, 
+				chip->stream_defaults[PLAYBACK]->area, 
+				chip->stream_defaults[PLAYBACK]->addr);	
+
+	if (chip->stream_defaults[CAPTURE]->area)
+		dma_free_coherent(chip->dev, 
+				MV88FX_SND_MAX_PERIODS * MV88FX_SND_MAX_PERIOD_BYTES, 
+				chip->stream_defaults[CAPTURE]->area, 
+				chip->stream_defaults[CAPTURE]->addr);	
+
+
+	chip = NULL;
+}
+
+static int mv88fx_snd_probe(struct platform_device *dev)
+{
+	int err = 0, irq = NO_IRQ;	
+	struct snd_card *card = NULL;
+	struct resource *r = NULL;	
+	static struct snd_device_ops ops = {
+		.dev_free =	NULL,
+	};
+	
+	mv88fx_snd_debug("=>%s", __FUNCTION__);
+
+
+        card = snd_card_new(-1, "mv88fx_snd", THIS_MODULE, 
+			    sizeof(struct mv88fx_snd_chip));
+
+	if (card == NULL) {
+		mv88fx_snd_debug(KERN_ERR "snd_card_new failed\n");
+		return -ENOMEM;
+	}
+
+        chip = card->private_data;
+	card->dev = &dev->dev;
+        chip->dev = &dev->dev;
+	chip->audio_info = (_audio_info*)dev->dev.platform_data;
+	card->private_free = mv88fx_snd_free;
+
+	r = platform_get_resource(dev, IORESOURCE_MEM, 0);
+	if (!r) {
+		mv88fx_snd_debug(KERN_ERR "platform_get_resource failed\n");
+		err = -ENXIO;
+		goto error;
+	}
+
+	
+        mv88fx_snd_debug(KERN_ERR "chip->res =0x%x\n", (unsigned int)chip->res);
+	
+	r = request_mem_region(r->start, SZ_16K, DRIVER_NAME);
+	if (!r){
+		mv88fx_snd_debug(KERN_ERR "request_mem_region failed\n");
+		err = -EBUSY;
+		goto error;
+	} 
+	chip->res = r;
+
+	irq = platform_get_irq(dev, 0);
+	if (irq == NO_IRQ){
+		mv88fx_snd_debug(KERN_ERR "platform_get_irq failed\n");
+		err = -ENXIO;
+		goto error;
+	}
+
+        
+	mv88fx_snd_debug("%s card = 0x%x card->dev 0x%x\n",__FUNCTION__,
+						(unsigned int)card,
+						(unsigned int)card->dev);
+        chip->base = ioremap(r->start, SZ_16K);
+
+	if (!chip->base) {
+		mv88fx_snd_debug(KERN_ERR "ioremap failed\n");
+		err = -ENOMEM;
+                goto error;
+	}
+
+	mv88fx_snd_debug("%s: chip->base=0x%x r->start0x%x\n",__FUNCTION__,
+		   (unsigned int)chip->base,r->start);
+
+	chip->pdata = (struct mv88fx_snd_platform_data*) dev->dev.platform_data;
+		
+        strncpy(card->driver, dev->dev.driver->name, 
+		sizeof(card->driver));	
+	
+        
+	/* Allocate memory for our device */
+	chip->stream_defaults[PLAYBACK] = 
+		kzalloc(sizeof(struct mv88fx_snd_stream), GFP_KERNEL);
+	
+        if (chip->stream_defaults[PLAYBACK] == NULL) {
+		mv88fx_snd_debug(KERN_ERR "kzalloc failed for default playback\n");
+		err = -ENOMEM;
+		goto error;
+	}
+	chip->stream_defaults[PLAYBACK]->direction = PLAYBACK;
+	chip->stream_defaults[PLAYBACK]->dev = card->dev;
+
+	chip->stream[PLAYBACK] = kzalloc(sizeof(struct mv88fx_snd_stream),
+					 GFP_KERNEL);
+
+	if (chip->stream[PLAYBACK] == NULL) {
+		mv88fx_snd_debug(KERN_ERR "kzalloc failed for runtime playback\n");
+		err = -ENOMEM;
+		goto error;
+	}
+	
+	
+	chip->stream_defaults[CAPTURE] = 
+		kzalloc(sizeof(struct mv88fx_snd_stream), GFP_KERNEL);
+	
+	if (chip->stream_defaults[CAPTURE] == NULL) {
+		mv88fx_snd_debug(KERN_ERR "kzalloc failed for capture\n");
+		err = -ENOMEM;
+		goto error;
+	}
+	chip->stream_defaults[CAPTURE]->direction = CAPTURE;
+        chip->stream_defaults[CAPTURE]->dev = card->dev;
+
+	chip->stream[CAPTURE] = kzalloc(sizeof(struct mv88fx_snd_stream),
+					 GFP_KERNEL);
+
+	if (chip->stream[CAPTURE] == NULL) {
+		mv88fx_snd_debug(KERN_ERR "kzalloc failed for runtime capture\n");
+		err = -ENOMEM;
+		goto error;
+	}
+	
+	chip->irq = irq;
+	chip->stream_defaults[PLAYBACK]->area = 
+		dma_alloc_coherent(chip->dev,
+				MV88FX_SND_MAX_PERIODS * MV88FX_SND_MAX_PERIOD_BYTES, 
+				&chip->stream_defaults[PLAYBACK]->addr, 
+				GFP_KERNEL);
+
+	if (!chip->stream_defaults[PLAYBACK]->area) {
+		mv88fx_snd_debug(KERN_ERR "dma_alloc_coherent failed for playback buffer\n");
+		err = -ENOMEM;
+		goto error;
+	}
+
+	if (0 == test_memory(chip, 
+			(unsigned int)chip->stream_defaults[PLAYBACK]->addr, 
+			(unsigned int)MV88FX_SND_MAX_PERIODS * MV88FX_SND_MAX_PERIOD_BYTES)) {
+
+		mv88fx_snd_debug(KERN_ERR "error: playback buffer not in one memory window\n");
+		err = -ENOMEM;
+		goto error;
+
+	}
+	
+	chip->stream_defaults[CAPTURE]->area = 
+		dma_alloc_coherent(chip->dev,	
+				MV88FX_SND_MAX_PERIODS * MV88FX_SND_MAX_PERIOD_BYTES, 
+				&chip->stream_defaults[CAPTURE]->addr, 
+				GFP_KERNEL);
+
+	if (!chip->stream_defaults[CAPTURE]->area) {
+		mv88fx_snd_debug(KERN_ERR "dma_alloc_coherent failed for capture buffer\n");
+		err = -ENOMEM;
+		goto error;
+	}
+
+	if (0 == test_memory(chip, 
+			(unsigned int)chip->stream_defaults[CAPTURE]->addr, 
+			(unsigned int)MV88FX_SND_MAX_PERIODS * MV88FX_SND_MAX_PERIOD_BYTES)) {
+
+		mv88fx_snd_debug(KERN_ERR "error: playback buffer not in one memory window\n");
+		err = -ENOMEM;
+		goto error;
+
+	}
+
+	if (request_irq(chip->irq, mv88fx_snd_interrupt, 0, DRIVER_NAME, 
+			(void *)chip)) {
+		
+		mv88fx_snd_debug("Unable to grab IRQ %d\n", chip->irq);
+		err = -ENOMEM;
+		goto error;
+	}
+
+	chip->ch_stat_valid = 1; 
+	chip->burst = 128;	
+        chip->loopback = 0; 
+        chip->dco_ctrl_offst = 0x800;
+	
+	err = mv88fx_snd_hw_init(chip);
+
+	if (err != 0) {
+		mv88fx_snd_debug(KERN_ERR "mv88fx_snd_hw_init failed\n");
+		err = -ENOMEM;
+		goto error;
+	}
+	
+	/* Set default values */
+	if ((err = snd_device_new(card, SNDRV_DEV_LOWLEVEL, chip, &ops)) < 0) {
+		mv88fx_snd_debug(KERN_ERR "Creating chip device failed.\n");
+		err = -ENOMEM;
+		goto error;
+	}
+	
+	/* create pcm devices */
+	if ((err = mv88fx_snd_pcm_new(card)) < 0) {
+		mv88fx_snd_debug(KERN_ERR "Creating PCM device failed.\n");
+		err = -ENOMEM;
+		goto error;
+	}
+	/* create controll interfaces & switches */
+	if ((err = mv88fx_snd_ctrl_new(card)) < 0) {
+		mv88fx_snd_debug(KERN_ERR "Creating non-PCM device failed.\n");
+		err = -ENOMEM;
+		goto error;
+	}
+	
+	strcpy(card->driver, "mv88fx_snd");
+	strcpy(card->shortname, "Marvell mv88fx_snd");
+	sprintf(card->longname, "Marvell mv88fx_snd ALSA driver");
+
+	
+	if ((err = snd_card_register(card)) < 0) {
+		mv88fx_snd_debug("Card registeration failed.\n");
+		err = -ENOMEM;
+		goto error;
+	}
+
+	if (dma_set_mask(&dev->dev, 0xFFFFFFUL) < 0)
+		goto error;
+	
+	platform_set_drvdata(dev, card);
+	return 0;
+error:
+	if (card) 
+                snd_card_free(card);
+	platform_set_drvdata(dev, NULL);
+	return err;
+}
+
+static int mv88fx_snd_remove(struct platform_device *dev)
+{
+	struct snd_card *card = platform_get_drvdata(dev);
+	
+	mv88fx_snd_debug("=>%s", __FUNCTION__);
+
+	if (card)
+		snd_card_free(card);
+        platform_set_drvdata(dev, NULL);
+	return 0;
+}
+
+#define mv88fx_snd_resume	NULL
+#define mv88fx_snd_suspend	NULL
+
+static struct platform_driver mv88fx_snd_driver = {
+	.probe		= mv88fx_snd_probe,
+	.remove		= mv88fx_snd_remove,
+	.suspend	= mv88fx_snd_suspend,
+	.resume		= mv88fx_snd_resume,
+	.driver		= {
+		.name	= DRIVER_NAME,
+	},
+
+};
+
+static int __init 
+mv88fx_snd_init(void)
+{
+	mv88fx_snd_debug("=>%s\n", __FUNCTION__);
+	return platform_driver_register(&mv88fx_snd_driver);
+}
+
+static void __exit mv88fx_snd_exit(void)
+{
+	mv88fx_snd_debug("=>%s\n", __FUNCTION__);
+	platform_driver_unregister(&mv88fx_snd_driver);	
+        
+}
+
+MODULE_AUTHOR("Maen Suleiman <maen@marvell.com>");
+MODULE_DESCRIPTION("Marvell MV88Fx Alsa Sound driver");
+MODULE_LICENSE("GPL");
+
+module_init(mv88fx_snd_init);
+module_exit(mv88fx_snd_exit);
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/mv88fx-pcm.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/mv88fx-pcm.h
new file mode 100644
index 0000000..2cdb8fa
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio/mv88fx-pcm.h
@@ -0,0 +1,124 @@
+/*
+ *
+ *	Marvell Orion Alsa Sound driver
+ *
+ *	Author: Maen Suleiman
+ *	Copyright (C) 2008 Marvell Ltd.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+#define DRIVER_NAME	"mv88fx_snd"
+
+#undef MV88FX_SND_DEBUG
+#ifdef MV88FX_SND_DEBUG
+#define mv88fx_snd_debug(fmt, arg...) printk(KERN_DEBUG fmt, ##arg)
+#else
+	#define mv88fx_snd_debug(a...)
+#endif
+
+typedef struct {
+	unsigned int base;
+	unsigned int size;
+} _audio_mem_info;
+
+typedef struct {
+ 	u32 spdif_rec;
+ 	u32 spdif_play;
+ 	u32 i2s_rec;
+ 	u32 i2s_play;
+ 	_audio_mem_info mem_array[5]; 
+} _audio_info;
+
+
+struct mv88fx_snd_stream {
+	struct snd_pcm_substream	*substream;
+        struct device*		dev;
+	int 	direction; 	/* playback or capture */ 
+	#define PLAYBACK	0
+	#define CAPTURE		1
+	unsigned int	dig_mode;	/* i2s,spdif,both*/ 
+	#define I2S		1
+	#define SPDIF		2
+        int	stereo;		/* mono , stereo*/
+        int	mono_mode;	/* both mono, left mono, right mono*/
+	#define MONO_BOTH	0
+	#define MONO_LEFT	1
+	#define MONO_RIGHT	2
+	int	clock_src;
+	#define DCO_CLOCK	0
+	#define SPCR_CLOCK	1
+	#define EXTERN_CLOCK	2
+	int	rate;		
+	int	stat_mem;	/* Channel status source*/
+	int	format;
+        #define SAMPLE_32IN32	0
+	#define SAMPLE_24IN32	1
+	#define SAMPLE_20IN32	2
+	#define SAMPLE_16IN32	3
+	#define SAMPLE_16IN16	4
+	unsigned int	dma_addr;
+	unsigned int	dma_size;
+	unsigned int	period_size;
+	unsigned int spdif_status[4];	/* SPDIF status */
+	unsigned char 	*area;	/* virtual pointer */
+	dma_addr_t 	addr;	/* physical address */
+
+	
+};
+
+struct mv88fx_snd_chip {
+	struct snd_card *card;
+	struct device	*dev;
+	struct mv88fx_snd_platform_data	*pdata;	/* platform dara*/
+	struct mv88fx_snd_stream	*stream[2];	/* run time values*/
+	struct mv88fx_snd_stream	*stream_defaults[2]; /* default values*/
+        spinlock_t	reg_lock;	/* Register access spinlock */
+	struct resource	*res;		/* resource for IRQ and base*/
+	void __iomem	*base;		/* base address of the host */
+	int	irq;
+	int	loopback;		/* When Loopback is enabled, playback 
+					  data is looped back to be recorded */
+	int	ch_stat_valid;		/* Playback SPDIF channel validity bit 
+					value when REG selected */
+        int	burst;			/* DMA Burst Size */
+
+	#define SPDIF_MEM_STAT		0
+	#define SPDIF_REG_STAT		1
+	unsigned int dco_ctrl_offst;
+	int	pcm_mode;	/* pcm, nonpcm*/
+	#define PCM		0
+	#define NON_PCM		1
+	_audio_info	*audio_info;
+	
+};
+
+#define MV88FX_SND_MIN_PERIODS		8
+#define MV88FX_SND_MAX_PERIODS		16
+#define	MV88FX_SND_MIN_PERIOD_BYTES	0x4000
+#define	MV88FX_SND_MAX_PERIOD_BYTES	0x4000
+
+
+/* read/write registers */
+
+#define mv88fx_snd_writel(chip, offs, val)	\
+		writel((val), (0xf1000000 + offs))
+
+static inline unsigned int mv88fx_snd_readl(struct mv88fx_snd_chip *chip, 
+					   unsigned int offs)
+{
+	unsigned int val = readl((0xf1000000 + offs));
+	return (val);
+}
+#define mv88fx_snd_bitset(chip, offs, bitmask)	\
+		writel( (readl(0xf1000000 + offs) | (bitmask)),	\
+			0xf1000000 + offs)
+
+#define mv88fx_snd_bitreset(chip, offs, bitmask)	\
+		writel( (readl(0xf1000000 + offs) & (~(bitmask))), \
+			0xf1000000 + offs)
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/Makefile
new file mode 100644
index 0000000..821ff91
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/Makefile
@@ -0,0 +1,22 @@
+#
+# Makefile for the Marvell Audio ALSA Device Driver
+#
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+obj-$(CONFIG_SND_MRVL_AUDIO) += snd-mv88fx-soc.o
+obj-$(CONFIG_SND_MRVL_AUDIO) += snd-mv88fx-i2s-soc.o
+obj-$(CONFIG_SND_MRVL_AUDIO) += snd-mv88fx-pcm-soc.o
+
+snd-mv88fx-i2s-soc-objs               += mv88fx-i2s.o
+snd-mv88fx-pcm-soc-objs		      += mv88fx-pcm.o
+
+#snd-mv88fx-soc-objs                  += cs42l51-hal.o
+snd-mv88fx-soc-objs                  += mv88fx.o
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-i2s.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-i2s.c
new file mode 100644
index 0000000..4c51970
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-i2s.c
@@ -0,0 +1,827 @@
+/*
+ *
+ *	Marvell Orion Alsa SOC Sound driver
+ *
+ *	Author: Yuval Elmaliah
+ *	Copyright (C) 2008 Marvell Ltd.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/delay.h>
+#include <linux/version.h>
+#include <sound/core.h>
+#include <sound/pcm.h>
+#include <sound/initval.h>
+#include <linux/platform_device.h>
+#include <sound/soc.h>
+#include <sound/soc-dai.h>
+#include <asm/sizes.h>
+#include <linux/io.h>
+#include <plat/i2s-orion.h>
+#include <asm/dma.h>
+#include <linux/scatterlist.h>
+#include <asm/sizes.h>
+#include <mvTypes.h>
+#include "mv88fx-pcm.h"
+#include "audio/mvAudioRegs.h"
+#include "audio/mvAudio.h"
+#include "mvSysAudioApi.h"
+
+#ifdef CONFIG_MACH_DOVE_RD_AVNG
+#include <linux/gpio.h>
+#include <asm/mach-types.h>
+#endif
+
+
+struct mv88fx_i2s_info {
+	int		port;
+	void __iomem	*base;	/* base address of the host */
+	u32		irq_mask;
+	u32		playback_cntrl_reg;
+	u32		capture_cntrl_reg;
+};
+
+static struct mv88fx_i2s_info mv88fx_i2s_info;
+
+
+static int mv88fx_i2_hw_init(void)
+{
+	mv88fx_snd_debug("");
+
+	mv88fx_snd_writel(mv88fx_i2s_info.base,
+		MV_AUDIO_INT_CAUSE_REG(mv88fx_i2s_info.port), 0xffffffff);
+	mv88fx_snd_writel(mv88fx_i2s_info.base,
+		MV_AUDIO_INT_MASK_REG(mv88fx_i2s_info.port), 0);
+	mv88fx_snd_writel(mv88fx_i2s_info.base,
+		MV_AUDIO_SPDIF_REC_INT_CAUSE_MASK_REG(mv88fx_i2s_info.port), 0);
+
+//	if (MV_OK != mvAudioInit(mv88fx_i2s_info.port))
+//		return -EIO;
+	mvSysAudioInit(mv88fx_i2s_info.port);
+
+	/* Disable all playback/recording */
+	mv88fx_snd_bitreset(mv88fx_i2s_info.base,
+		MV_AUDIO_PLAYBACK_CTRL_REG(mv88fx_i2s_info.port),
+		(APCR_PLAY_I2S_ENABLE_MASK | APCR_PLAY_SPDIF_ENABLE_MASK));
+
+	mv88fx_snd_bitreset(mv88fx_i2s_info.base,
+		MV_AUDIO_RECORD_CTRL_REG(mv88fx_i2s_info.port),
+		(ARCR_RECORD_SPDIF_EN_MASK | ARCR_RECORD_I2S_EN_MASK));
+
+	if (MV_OK != mvSPDIFRecordTclockSet(mv88fx_i2s_info.port)) {
+		mv88fx_snd_error("mvSPDIFRecordTclockSet failed");
+		return -ENOMEM;
+	}
+	return 0;
+}
+
+
+static int mv88fx_i2s_snd_hw_playback_set(struct mv88fx_snd_chip *chip,
+					  struct snd_pcm_substream *substream)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	struct mv88fx_snd_stream *audio_stream = runtime->private_data;
+	MV_AUDIO_PLAYBACK_CTRL pcm_play_ctrl;
+	MV_I2S_PLAYBACK_CTRL i2s_play_ctrl;
+	MV_SPDIF_PLAYBACK_CTRL spdif_play_ctrl;
+	MV_AUDIO_FREQ_DATA dco_ctrl;
+
+	mv88fx_snd_debug("chip=%p chip->base=%p", chip, chip->base);
+
+	memset(&pcm_play_ctrl, 0, sizeof(pcm_play_ctrl));
+	memset(&dco_ctrl, 0, sizeof(dco_ctrl));
+	memset(&i2s_play_ctrl, 0, sizeof(i2s_play_ctrl));
+	memset(&spdif_play_ctrl, 0, sizeof(spdif_play_ctrl));
+
+	dco_ctrl.offset = chip->dco_ctrl_offst;
+
+	mv88fx_snd_debug("rate: %u	", runtime->rate);
+	switch (runtime->rate) {
+	case 44100:
+		dco_ctrl.baseFreq = AUDIO_FREQ_44_1KH;
+		break;
+	case 48000:
+		dco_ctrl.baseFreq = AUDIO_FREQ_48KH;
+		break;
+	case 96000:
+		dco_ctrl.baseFreq = AUDIO_FREQ_96KH;
+		break;
+	default:
+		mv88fx_snd_error("Requested rate %d is not supported",
+				 runtime->rate);
+		return -1;
+	}
+
+	pcm_play_ctrl.burst = (chip->burst == 128) ? AUDIO_128BYTE_BURST :
+	    AUDIO_32BYTE_BURST;
+
+	pcm_play_ctrl.loopBack = chip->loopback;
+
+	if (mv88fx_pcm_is_stereo(runtime)) {
+		pcm_play_ctrl.monoMode = AUDIO_PLAY_MONO_OFF;
+	} else {
+
+		switch (audio_stream->mono_mode) {
+		case MONO_LEFT:
+			pcm_play_ctrl.monoMode = AUDIO_PLAY_LEFT_MONO;
+			break;
+		case MONO_RIGHT:
+			pcm_play_ctrl.monoMode = AUDIO_PLAY_RIGHT_MONO;
+			break;
+		case MONO_BOTH:
+		default:
+			pcm_play_ctrl.monoMode = AUDIO_PLAY_BOTH_MONO;
+			break;
+		}
+	}
+
+	if (runtime->format == SNDRV_PCM_FORMAT_S16_LE) {
+		pcm_play_ctrl.sampleSize = SAMPLE_16BIT;
+		i2s_play_ctrl.sampleSize = SAMPLE_16BIT;
+	} else if (runtime->format == SNDRV_PCM_FORMAT_S24_LE) {
+		pcm_play_ctrl.sampleSize = SAMPLE_24BIT;
+		i2s_play_ctrl.sampleSize = SAMPLE_24BIT;
+
+	} else if (runtime->format == SNDRV_PCM_FORMAT_S32_LE) {
+		pcm_play_ctrl.sampleSize = SAMPLE_32BIT;
+		i2s_play_ctrl.sampleSize = SAMPLE_32BIT;
+	} else {
+		mv88fx_snd_error("Requested format %d is not supported",
+				 runtime->format);
+		return -1;
+	}
+
+	/* buffer and period sizes in frame */
+	pcm_play_ctrl.bufferPhyBase = runtime->dma_addr;
+	pcm_play_ctrl.bufferSize =
+	    frames_to_bytes(runtime, runtime->buffer_size);
+	pcm_play_ctrl.intByteCount =
+	    frames_to_bytes(runtime, runtime->period_size);
+
+	/* I2S playback streem stuff */
+	/*i2s_play_ctrl.sampleSize = pcm_play_ctrl.sampleSize; */
+	i2s_play_ctrl.justification = I2S_JUSTIFIED;
+	i2s_play_ctrl.sendLastFrame = 0;
+
+	spdif_play_ctrl.nonPcm = MV_FALSE;
+
+	spdif_play_ctrl.validity = chip->ch_stat_valid;
+
+	if (audio_stream->stat_mem) {
+		spdif_play_ctrl.userBitsFromMemory = MV_TRUE;
+		spdif_play_ctrl.validityFromMemory = MV_TRUE;
+		spdif_play_ctrl.blockStartInternally = MV_FALSE;
+	} else {
+		spdif_play_ctrl.userBitsFromMemory = MV_FALSE;
+		spdif_play_ctrl.validityFromMemory = MV_FALSE;
+		spdif_play_ctrl.blockStartInternally = MV_TRUE;
+	}
+
+	mv88fx_snd_debug("");
+	/* If this is non-PCM sound, mute I2S channel */
+	spin_lock_irq(&chip->reg_lock);
+
+	mv88fx_snd_debug("chip=%p chip->base=%p port=%d", chip, chip->base,
+			 chip->port);
+
+	if (!(mv88fx_snd_readl(chip->base,
+		MV_AUDIO_PLAYBACK_CTRL_REG(chip->port)) &
+		(APCR_PLAY_I2S_ENABLE_MASK | APCR_PLAY_SPDIF_ENABLE_MASK))) {
+
+		mv88fx_snd_debug("");
+
+		if (MV_OK != mvAudioDCOCtrlSet(chip->port, &dco_ctrl)) {
+			mv88fx_snd_error
+			    ("Failed to initialize DCO clock control.");
+			return -1;
+			mv88fx_snd_debug("");
+
+		}
+	}
+
+	mv88fx_snd_debug("");
+
+	if (audio_stream->clock_src == DCO_CLOCK)
+		while ((mv88fx_snd_readl(chip->base,
+			 MV_AUDIO_SPCR_DCO_STATUS_REG(chip->port)) &
+			ASDSR_DCO_LOCK_MASK) == 0)
+			;
+	else if (audio_stream->clock_src == SPCR_CLOCK)
+		while ((mv88fx_snd_readl(chip->base,
+			 MV_AUDIO_SPCR_DCO_STATUS_REG(chip->port)) &
+			ASDSR_SPCR_LOCK_MASK) == 0)
+			;
+
+	mv88fx_snd_debug("");
+
+	if (MV_OK != mvAudioPlaybackControlSet(chip->port, &pcm_play_ctrl)) {
+		mv88fx_snd_error("Failed to initialize PCM playback control.");
+		return -1;
+	}
+	mv88fx_snd_debug("");
+
+	if (MV_OK != mvI2SPlaybackCtrlSet(chip->port, &i2s_play_ctrl)) {
+		mv88fx_snd_error("Failed to initialize I2S playback control.");
+		return -1;
+	}
+	mv88fx_snd_debug("");
+
+	mvSPDIFPlaybackCtrlSet(chip->port, &spdif_play_ctrl);
+
+	mv88fx_snd_debug("");
+
+	spin_unlock_irq(&chip->reg_lock);
+
+	return 0;
+}
+
+static int mv88fx_i2s_snd_hw_capture_set(struct mv88fx_snd_chip *chip,
+					 struct snd_pcm_substream *substream)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	struct mv88fx_snd_stream *audio_stream = runtime->private_data;
+	MV_AUDIO_RECORD_CTRL pcm_rec_ctrl;
+	MV_I2S_RECORD_CTRL i2s_rec_ctrl;
+	MV_AUDIO_FREQ_DATA dco_ctrl;
+
+#ifdef CONFIG_MACH_DOVE_RD_AVNG
+	int phoneInDetected;
+#endif
+
+	mv88fx_snd_debug("chip=%p chip->base=%p", chip, chip->base);
+
+	dco_ctrl.offset = chip->dco_ctrl_offst;
+
+	switch (runtime->rate) {
+	case 44100:
+		dco_ctrl.baseFreq = AUDIO_FREQ_44_1KH;
+		break;
+	case 48000:
+		dco_ctrl.baseFreq = AUDIO_FREQ_48KH;
+		break;
+	case 96000:
+		dco_ctrl.baseFreq = AUDIO_FREQ_96KH;
+		break;
+	default:
+		mv88fx_snd_debug("ERROR");
+		mv88fx_snd_error("Requested rate %d is not supported",
+				 runtime->rate);
+		return -1;
+	}
+
+	pcm_rec_ctrl.burst = (chip->burst == 128) ? AUDIO_128BYTE_BURST :
+	    AUDIO_32BYTE_BURST;
+
+	if (runtime->format == SNDRV_PCM_FORMAT_S16_LE) {
+		pcm_rec_ctrl.sampleSize = SAMPLE_16BIT;
+	} else if (runtime->format == SNDRV_PCM_FORMAT_S24_LE) {
+		pcm_rec_ctrl.sampleSize = SAMPLE_24BIT;
+	} else if (runtime->format == SNDRV_PCM_FORMAT_S32_LE) {
+		pcm_rec_ctrl.sampleSize = SAMPLE_32BIT;
+	} else {
+		mv88fx_snd_error("Requested format %d is not supported",
+				 runtime->format);
+		return -1;
+	}
+
+	pcm_rec_ctrl.mono =
+	    (mv88fx_pcm_is_stereo(runtime)) ? MV_FALSE : MV_TRUE;
+
+	if (pcm_rec_ctrl.mono) {
+		switch (audio_stream->mono_mode) {
+		case MONO_LEFT:
+			pcm_rec_ctrl.monoChannel = AUDIO_REC_LEFT_MONO;
+			break;
+		default:
+		case MONO_RIGHT:
+			pcm_rec_ctrl.monoChannel = AUDIO_REC_RIGHT_MONO;
+			break;
+		}
+
+	} else
+		pcm_rec_ctrl.monoChannel = AUDIO_REC_LEFT_MONO;
+
+	pcm_rec_ctrl.bufferPhyBase = runtime->dma_addr;
+	pcm_rec_ctrl.bufferSize =
+	    frames_to_bytes(runtime, runtime->buffer_size);
+	pcm_rec_ctrl.intByteCount =
+	    frames_to_bytes(runtime, runtime->period_size);
+
+	/* I2S record streem stuff */
+	i2s_rec_ctrl.sample = pcm_rec_ctrl.sampleSize;
+	i2s_rec_ctrl.justf = I2S_JUSTIFIED;
+
+	spin_lock_irq(&chip->reg_lock);
+
+	/* set clock only if record is not enabled */
+	if (!(mv88fx_snd_readl(chip->base,
+		MV_AUDIO_RECORD_CTRL_REG(chip->port)) &
+		(ARCR_RECORD_SPDIF_EN_MASK | ARCR_RECORD_I2S_EN_MASK))) {
+
+		if (MV_OK != mvAudioDCOCtrlSet(chip->port, &dco_ctrl)) {
+			mv88fx_snd_debug("ERROR");
+			mv88fx_snd_error
+			    ("Failed to initialize DCO clock control.");
+			return -1;
+		}
+	}
+	mv88fx_snd_debug("");
+	if (MV_OK != mvAudioRecordControlSet(chip->port, &pcm_rec_ctrl)) {
+		mv88fx_snd_error("Failed to initialize PCM record control.");
+		return -1;
+	}
+
+	if (MV_OK != mvI2SRecordCntrlSet(chip->port, &i2s_rec_ctrl)) {
+		mv88fx_snd_error("Failed to initialize I2S record control.");
+		return -1;
+	}
+	mv88fx_snd_debug("");
+
+#ifdef CONFIG_MACH_DOVE_RD_AVNG
+	if (machine_is_dove_rd_avng()) {
+		phoneInDetected = gpio_get_value(53);
+
+		if (phoneInDetected < 0)
+			mv88fx_snd_error("Failed to detect phone-in.");
+		else {
+			int input_type;
+			mv88fx_snd_error("detect phone-in.");
+			if (!phoneInDetected)
+				input_type = 2;	/* external MIC */
+			else
+				input_type = 1;	/* internal MIC */
+		}
+	}
+#endif
+	mv88fx_snd_debug("");
+
+	spin_unlock_irq(&chip->reg_lock);
+
+	mv88fx_snd_debug("");
+
+	return 0;
+
+}
+
+static int mv88fx_i2s_capture_trigger(struct snd_pcm_substream *substream,
+				      int cmd)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	struct mv88fx_snd_stream *audio_stream = runtime->private_data;
+	struct mv88fx_snd_chip *chip = mv88fx_pcm_get_chip();
+	int result = 0;
+
+	mv88fx_snd_debug("substream=%p cmd=%d audio_stream=%p", substream, cmd,
+			 audio_stream);
+
+	spin_lock(&chip->reg_lock);
+	switch (cmd) {
+	case SNDRV_PCM_TRIGGER_START:
+		/* FIXME: should check if busy before */
+		mv88fx_snd_debug("");
+		/* make sure the dma in pause state */
+		mv88fx_snd_bitset(chip->base,
+			MV_AUDIO_RECORD_CTRL_REG(chip->port),
+			ARCR_RECORD_PAUSE_MASK);
+
+		/* enable interrupt */
+		mv88fx_snd_bitset(chip->base, MV_AUDIO_INT_MASK_REG(chip->port),
+				  AICR_RECORD_BYTES_INT);
+
+		/* enable dma */
+		mv88fx_snd_debug("dig_mode=%x", audio_stream->dig_mode);
+		if (audio_stream->dig_mode & I2S) {
+			mv88fx_snd_debug("enable dma");
+			mv88fx_snd_bitset(chip->base,
+					  MV_AUDIO_RECORD_CTRL_REG(chip->port),
+					  ARCR_RECORD_I2S_EN_MASK);
+		}
+
+		if (audio_stream->dig_mode & SPDIF) {
+			mv88fx_snd_debug("enable spdif dma");
+			mv88fx_snd_bitset(chip->base,
+					  MV_AUDIO_RECORD_CTRL_REG(chip->port),
+					  ARCR_RECORD_SPDIF_EN_MASK);
+		}
+
+		/* start dma */
+		mv88fx_snd_bitreset(chip->base,
+			MV_AUDIO_RECORD_CTRL_REG(chip->port),
+			ARCR_RECORD_PAUSE_MASK);
+
+		break;
+	case SNDRV_PCM_TRIGGER_STOP:
+
+		/* make sure the dma in pause state */
+		mv88fx_snd_bitset(chip->base,
+			MV_AUDIO_RECORD_CTRL_REG(chip->port),
+			ARCR_RECORD_PAUSE_MASK);
+
+		/* disable interrupt */
+		mv88fx_snd_bitreset(chip->base,
+			MV_AUDIO_INT_MASK_REG(chip->port),
+			AICR_RECORD_BYTES_INT);
+
+		/* always stop both I2S and SPDIF */
+		mv88fx_snd_bitreset(chip->base,
+			MV_AUDIO_RECORD_CTRL_REG(chip->port),
+			(ARCR_RECORD_I2S_EN_MASK | ARCR_RECORD_SPDIF_EN_MASK));
+
+		/* FIXME: should check if busy after */
+
+		break;
+	case SNDRV_PCM_TRIGGER_PAUSE_PUSH:
+	case SNDRV_PCM_TRIGGER_SUSPEND:
+		mv88fx_snd_bitset(chip->base,
+			MV_AUDIO_RECORD_CTRL_REG(chip->port),
+			ARCR_RECORD_PAUSE_MASK);
+		break;
+	case SNDRV_PCM_TRIGGER_RESUME:
+	case SNDRV_PCM_TRIGGER_PAUSE_RELEASE:
+		mv88fx_snd_bitreset(chip->base,
+			MV_AUDIO_RECORD_CTRL_REG(chip->port),
+			ARCR_RECORD_PAUSE_MASK);
+
+		break;
+	default:
+		result = -EINVAL;
+		break;
+	}
+	spin_unlock(&chip->reg_lock);
+	mv88fx_snd_debug("result=%d", result);
+	return result;
+}
+
+static int mv88fx_i2s_playback_trigger(struct snd_pcm_substream *substream,
+				       int cmd)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	struct mv88fx_snd_stream *audio_stream = runtime->private_data;
+	struct mv88fx_snd_chip *chip = mv88fx_pcm_get_chip();
+	int result = 0;
+
+	mv88fx_snd_debug("substream=%p cmd=%d audio_stream=%p", substream, cmd,
+			 audio_stream);
+
+	spin_lock(&chip->reg_lock);
+	switch (cmd) {
+	case SNDRV_PCM_TRIGGER_START:
+
+		mv88fx_snd_debug("");
+		/* enable interrupt */
+		mv88fx_snd_bitset(chip->base, MV_AUDIO_INT_MASK_REG(chip->port),
+				  AICR_PLAY_BYTES_INT);
+
+		/* make sure the dma in pause state */
+		mv88fx_snd_bitset(chip->base,
+			MV_AUDIO_PLAYBACK_CTRL_REG(chip->port),
+			APCR_PLAY_PAUSE_MASK);
+
+		/* enable dma */
+		if ((audio_stream->dig_mode & I2S) && (chip->pcm_mode == PCM))
+			mv88fx_snd_bitset(chip->base,
+				MV_AUDIO_PLAYBACK_CTRL_REG(chip->port),
+				APCR_PLAY_I2S_ENABLE_MASK);
+
+		if (audio_stream->dig_mode & SPDIF)
+			mv88fx_snd_bitset(chip->base,
+				MV_AUDIO_PLAYBACK_CTRL_REG(chip->port),
+				APCR_PLAY_SPDIF_ENABLE_MASK);
+
+		/* start dma */
+		mv88fx_snd_bitreset(chip->base,
+				    MV_AUDIO_PLAYBACK_CTRL_REG(chip->port),
+				    APCR_PLAY_PAUSE_MASK);
+
+		break;
+	case SNDRV_PCM_TRIGGER_STOP:
+
+		mv88fx_snd_debug("");
+
+		/* disable interrupt */
+		mv88fx_snd_bitreset(chip->base,
+			MV_AUDIO_INT_MASK_REG(chip->port),
+			AICR_PLAY_BYTES_INT);
+
+		/* make sure the dma in pause state */
+		mv88fx_snd_bitset(chip->base,
+			MV_AUDIO_PLAYBACK_CTRL_REG(chip->port),
+			APCR_PLAY_PAUSE_MASK);
+
+		/* always stop both I2S and SPDIF */
+		mv88fx_snd_bitreset(chip->base,
+				    MV_AUDIO_PLAYBACK_CTRL_REG(chip->port),
+				    (APCR_PLAY_I2S_ENABLE_MASK |
+				     APCR_PLAY_SPDIF_ENABLE_MASK));
+
+		/* check if busy twice */
+		while (mv88fx_snd_readl(chip->base,
+			MV_AUDIO_PLAYBACK_CTRL_REG(chip->port)) &
+		       APCR_PLAY_BUSY_MASK)
+			;
+
+		while (mv88fx_snd_readl(chip->base,
+			MV_AUDIO_PLAYBACK_CTRL_REG(chip->port)) &
+		       APCR_PLAY_BUSY_MASK)
+			;
+
+		break;
+	case SNDRV_PCM_TRIGGER_PAUSE_PUSH:
+	case SNDRV_PCM_TRIGGER_SUSPEND:
+		mv88fx_snd_debug("");
+
+		mv88fx_snd_bitset(chip->base,
+			MV_AUDIO_PLAYBACK_CTRL_REG(chip->port),
+			APCR_PLAY_PAUSE_MASK);
+		break;
+	case SNDRV_PCM_TRIGGER_RESUME:
+	case SNDRV_PCM_TRIGGER_PAUSE_RELEASE:
+		mv88fx_snd_debug("");
+
+		mv88fx_snd_bitreset(chip->base,
+				    MV_AUDIO_PLAYBACK_CTRL_REG(chip->port),
+				    APCR_PLAY_PAUSE_MASK);
+
+		break;
+	default:
+		result = -EINVAL;
+		break;
+	}
+	spin_unlock(&chip->reg_lock);
+	mv88fx_snd_debug("result=%d", result);
+	return result;
+}
+
+static int mv88fx_i2s_startup(struct snd_pcm_substream *stream,
+				struct snd_soc_dai *dai)
+{
+	mv88fx_snd_debug("");
+
+	return 0;
+}
+
+static void mv88fx_i2s_shutdown(struct snd_pcm_substream *stream,
+				struct snd_soc_dai *dai)
+{
+	mv88fx_snd_debug("");
+}
+
+static int mv88fx_i2s_hw_params(struct snd_pcm_substream *stream,
+				struct snd_pcm_hw_params *hw_params,
+				struct snd_soc_dai *dai)
+{
+	mv88fx_snd_debug("");
+
+	return 0;
+}
+
+static int mv88fx_i2s_hw_free(struct snd_pcm_substream *stream,
+				struct snd_soc_dai *dai)
+{
+	mv88fx_snd_debug("");
+
+	return 0;
+}
+
+static int mv88fx_i2s_prepare(struct snd_pcm_substream *substream,
+				struct snd_soc_dai *dai)
+{
+	struct mv88fx_snd_chip *chip = mv88fx_pcm_get_chip();
+	mv88fx_snd_debug("");
+
+	if (substream->stream == SNDRV_PCM_STREAM_CAPTURE)
+		return mv88fx_i2s_snd_hw_capture_set(chip, substream);
+	else
+		return mv88fx_i2s_snd_hw_playback_set(chip, substream);
+
+}
+
+static int mv88fx_i2s_trigger(struct snd_pcm_substream *substream, int cmd,
+				struct snd_soc_dai *dai)
+{
+	if (substream->stream == SNDRV_PCM_STREAM_CAPTURE)
+		return mv88fx_i2s_capture_trigger(substream, cmd);
+	else
+		return mv88fx_i2s_playback_trigger(substream, cmd);
+}
+
+static int mv88fx_i2s_set_sysclk(struct snd_soc_dai *codec_dai,
+				 int clk_id, unsigned int freq, int dir)
+{
+	mv88fx_snd_debug("");
+
+	return 0;
+}
+
+static int mv88fx_i2s_set_fmt(struct snd_soc_dai *codec_dai,
+			      unsigned int fmt)
+{
+	mv88fx_snd_debug("");
+
+	return 0;
+}
+
+static int mv88fx_i2s_dai_probe(struct platform_device *pdev,
+				struct snd_soc_dai *dai)
+{
+	struct mv88fx_snd_machine_data *machine_data = pdev->dev.platform_data;
+
+	mv88fx_snd_debug("");
+
+	mv88fx_i2s_info.base = machine_data->base;
+	mv88fx_i2s_info.port = machine_data->port;
+
+
+	mv88fx_i2_hw_init();
+
+
+	return 0;
+}
+
+static void mv88fx_i2s_dai_remove(struct platform_device *pdev,
+				struct snd_soc_dai *dai)
+{
+	mv88fx_snd_debug("");
+
+}
+
+
+static int mv88fx_i2s_suspend(struct snd_soc_dai *cpu_dai)
+{
+	struct mv88fx_snd_chip *chip = mv88fx_pcm_get_chip();
+
+	mv88fx_snd_debug("");
+
+	if (!cpu_dai->active)
+		return 0;
+
+
+	spin_lock(&chip->reg_lock);
+
+	/* save registers */
+	mv88fx_i2s_info.irq_mask = mv88fx_snd_readl(chip->base,
+			MV_AUDIO_INT_MASK_REG(chip->port));
+	mv88fx_i2s_info.capture_cntrl_reg = mv88fx_snd_readl(chip->base,
+			MV_AUDIO_RECORD_CTRL_REG(chip->port));
+	mv88fx_i2s_info.playback_cntrl_reg = mv88fx_snd_readl(chip->base,
+			MV_AUDIO_PLAYBACK_CTRL_REG(chip->port));
+
+	/* clear all interrupts */
+	mv88fx_snd_writel(chip->base,
+		MV_AUDIO_INT_CAUSE_REG(chip->port), 0xffffffff);
+	/* disable all interrupts */
+	mv88fx_snd_writel(chip->base,
+		MV_AUDIO_INT_MASK_REG(chip->port), 0);
+	/* pause dma */
+	mv88fx_snd_bitset(chip->base,
+		MV_AUDIO_RECORD_CTRL_REG(chip->port), ARCR_RECORD_PAUSE_MASK);
+	mv88fx_snd_bitset(chip->base,
+		MV_AUDIO_PLAYBACK_CTRL_REG(chip->port), APCR_PLAY_PAUSE_MASK);
+
+
+	spin_unlock(&chip->reg_lock);
+
+	return 0;
+}
+
+
+
+static int mv88fx_i2s_resume(struct snd_soc_dai *cpu_dai)
+{
+	struct mv88fx_snd_chip *chip = mv88fx_pcm_get_chip();
+
+	mv88fx_snd_debug("");
+
+	if (!cpu_dai->active)
+		return 0;
+
+	mv88fx_i2_hw_init();
+
+	spin_lock(&chip->reg_lock);
+
+	mv88fx_snd_writel(chip->base,
+		MV_AUDIO_INT_CAUSE_REG(chip->port), 0xffffffff);
+	/* restore registers */
+	mv88fx_snd_writel(chip->base,
+		MV_AUDIO_RECORD_CTRL_REG(chip->port),
+		mv88fx_i2s_info.capture_cntrl_reg);
+	mv88fx_snd_writel(chip->base,
+		MV_AUDIO_PLAYBACK_CTRL_REG(chip->port),
+		mv88fx_i2s_info.playback_cntrl_reg);
+	/* enable interrupts */
+	mv88fx_snd_writel(chip->base,
+		MV_AUDIO_INT_MASK_REG(chip->port),
+		mv88fx_i2s_info.irq_mask);
+
+	spin_unlock(&chip->reg_lock);
+
+	return 0;
+}
+
+static struct snd_soc_dai_ops mv88fx_i2s_dai_ops = {
+	.startup = mv88fx_i2s_startup,
+	.shutdown = mv88fx_i2s_shutdown,
+	.hw_params = mv88fx_i2s_hw_params,
+	.hw_free = mv88fx_i2s_hw_free,
+	.prepare = mv88fx_i2s_prepare,
+	.trigger = mv88fx_i2s_trigger,
+	.hw_params = mv88fx_i2s_hw_params,
+	.set_sysclk = mv88fx_i2s_set_sysclk,
+	.set_fmt = mv88fx_i2s_set_fmt,
+};
+
+struct snd_soc_dai mv88fx_i2s_dai = {
+	.name = "mv88fx-i2s",
+	.id = 0,
+	.probe = mv88fx_i2s_dai_probe,
+	.remove = mv88fx_i2s_dai_remove,
+	.suspend = mv88fx_i2s_suspend,
+	.resume = mv88fx_i2s_resume,
+	.ops = &mv88fx_i2s_dai_ops,
+	.capture = {
+		    .stream_name = "i2s-capture",
+		    .formats = (SNDRV_PCM_FMTBIT_S16_LE |
+				SNDRV_PCM_FMTBIT_S24_LE |
+				SNDRV_PCM_FMTBIT_S32_LE),
+		    .rate_min = 44100,
+		    .rate_max = 96000,
+		    .rates = (SNDRV_PCM_RATE_44100 |
+			      SNDRV_PCM_RATE_48000 | SNDRV_PCM_RATE_96000),
+		    .channels_min = 1,
+		    .channels_max = 2,
+		    },
+	.playback = {
+		     .stream_name = "i2s-playback",
+		     .formats = (SNDRV_PCM_FMTBIT_S16_LE |
+				 SNDRV_PCM_FMTBIT_S24_LE |
+				 SNDRV_PCM_FMTBIT_S32_LE),
+		     .rate_min = 44100,
+		     .rate_max = 96000,
+		     .rates = (SNDRV_PCM_RATE_44100 |
+			       SNDRV_PCM_RATE_48000 | SNDRV_PCM_RATE_96000),
+		     .channels_min = 1,
+		     .channels_max = 2,
+		     },
+
+	.runtime = NULL,
+	.active = 0,
+	.dma_data = NULL,
+	.private_data = NULL,
+};
+EXPORT_SYMBOL_GPL(mv88fx_i2s_dai);
+
+
+
+
+
+static int mv88fx_i2s_probe(struct platform_device *pdev)
+{
+	mv88fx_snd_debug("");
+	mv88fx_i2s_dai.dev = &pdev->dev;
+	return snd_soc_register_dai(&mv88fx_i2s_dai);
+}
+
+static int __devexit mv88fx_i2s_remove(struct platform_device *pdev)
+{
+	snd_soc_unregister_dai(&mv88fx_i2s_dai);
+	return 0;
+}
+
+static struct platform_driver mv88fx_i2s_driver = {
+	.probe = mv88fx_i2s_probe,
+	.remove = __devexit_p(mv88fx_i2s_remove),
+
+	.driver = {
+		.name = "mv88fx-i2s",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int __init mv88fx_i2s_init(void)
+{
+	mv88fx_snd_debug("");
+	return platform_driver_register(&mv88fx_i2s_driver);
+}
+
+static void __exit mv88fx_i2s_exit(void)
+{
+	mv88fx_snd_debug("");
+	platform_driver_unregister(&mv88fx_i2s_driver);
+}
+
+module_init(mv88fx_i2s_init);
+module_exit(mv88fx_i2s_exit);
+
+
+/* Module information */
+MODULE_AUTHOR("Yuval Elmaliah <eyuval@marvell.com>");
+MODULE_DESCRIPTION("mv88fx I2S SoC Interface");
+MODULE_LICENSE("GPL");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-i2s.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-i2s.h
new file mode 100644
index 0000000..6b7912c
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-i2s.h
@@ -0,0 +1,20 @@
+/*
+ *
+ *	Marvell Orion Alsa SOC Sound driver
+ *
+ *	Author: Yuval Elmaliah
+ *	Copyright (C) 2008 Marvell Ltd.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#ifndef _MV88FX_I2S_H
+#define _MV88FX_I2S_H
+
+extern struct snd_soc_dai mv88fx_i2s_dai;
+
+#endif
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-pcm.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-pcm.c
new file mode 100644
index 0000000..498a962
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-pcm.c
@@ -0,0 +1,617 @@
+/*
+ *
+ *	Marvell Orion Alsa SOC Sound driver
+ *
+ *	Author: Yuval Elmaliah
+ *	Copyright (C) 2008 Marvell Ltd.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/dma-mapping.h>
+#include <sound/core.h>
+#include <sound/pcm.h>
+#include <sound/pcm_params.h>
+#include <linux/platform_device.h>
+#include <sound/soc.h>
+#include <sound/soc-dai.h>
+#include <linux/mbus.h>
+#include <linux/irqreturn.h>
+#include <linux/version.h>
+#include <linux/interrupt.h>
+#include <asm/dma.h>
+#include <linux/io.h>
+#include <linux/scatterlist.h>
+#include <asm/sizes.h>
+#include <mvTypes.h>
+#include <plat/i2s-orion.h>
+#include "audio/mvAudioRegs.h"
+#include "mv88fx-pcm.h"
+
+#include "audio/mvAudio.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+
+#ifdef CONFIG_MACH_DOVE_RD_AVNG
+#include <linux/gpio.h>
+#include <asm/mach-types.h>
+#endif
+
+struct mv88fx_snd_chip *mv88fx_pcm_snd_chip;
+EXPORT_SYMBOL_GPL(mv88fx_pcm_snd_chip);
+
+static struct snd_pcm_hardware mv88fx_pcm_hardware = {
+	.info = (SNDRV_PCM_INFO_INTERLEAVED |
+		 SNDRV_PCM_INFO_MMAP |
+		 SNDRV_PCM_INFO_MMAP_VALID |
+		 SNDRV_PCM_INFO_BLOCK_TRANSFER | SNDRV_PCM_INFO_PAUSE),
+	.formats = (SNDRV_PCM_FMTBIT_S16_LE |
+		    SNDRV_PCM_FMTBIT_S24_LE | SNDRV_PCM_FMTBIT_S32_LE),
+	.rates = (SNDRV_PCM_RATE_44100 |
+		  SNDRV_PCM_RATE_48000 | SNDRV_PCM_RATE_96000),
+	.rate_min = 44100,
+	.rate_max = 96000,
+	.channels_min = 1,
+	.channels_max = 2,
+	.buffer_bytes_max = (16 * 1024 * 1024),
+	.period_bytes_min = MV88FX_SND_MIN_PERIOD_BYTES,
+	.period_bytes_max = MV88FX_SND_MAX_PERIOD_BYTES,
+	.periods_min = MV88FX_SND_MIN_PERIODS,
+	.periods_max = MV88FX_SND_MAX_PERIODS,
+	.fifo_size = 0,
+
+};
+
+static void mv88fx_pcm_init_stream(struct mv88fx_snd_chip *chip,
+				   struct mv88fx_snd_stream *stream,
+				   int stream_id)
+{
+	memset(stream, 0, sizeof(*stream));
+	if (stream_id == SNDRV_PCM_STREAM_PLAYBACK) {
+		stream->dig_mode = 0;
+		if (chip->pdata->i2s_play)
+			stream->dig_mode |= I2S;
+		if (chip->pdata->spdif_play)
+			stream->dig_mode |= SPDIF;
+
+		stream->mono_mode = MONO_BOTH;
+		stream->stat_mem = 0;
+		stream->clock_src = DCO_CLOCK;
+	} else {
+		if (chip->pdata->i2s_rec)
+			stream->dig_mode = I2S;
+		else if (chip->pdata->spdif_rec)
+			stream->dig_mode = SPDIF;
+
+		stream->mono_mode = MONO_LEFT;
+		stream->stat_mem = 0;
+		stream->clock_src = DCO_CLOCK;
+	}
+}
+
+
+
+static int mv88fx_find_dram_cs(struct mbus_dram_target_info *dram,
+			       u32 base, u32 size)
+{
+	int i;
+
+	mv88fx_snd_debug("base=0x%x size=%u dram=%p", base, size, dram);
+
+	for (i = 0; i < dram->num_cs; i++) {
+		struct mbus_dram_window *cs = dram->cs + i;
+		/* check if we fit into one memory window only */
+		if ((base >= cs->base) &&
+		    ((base + size) <= cs->base + cs->size))
+			return i;
+
+	}
+
+	mv88fx_snd_error("");
+	return -1;
+}
+static int mv88fx_config_dma_window(struct mv88fx_snd_chip *chip,
+				    int dma, struct mbus_dram_target_info *dram)
+{
+	struct mbus_dram_window *cs;
+	struct snd_pcm_substream *substream = chip->pcm->streams[dma].substream;
+
+	int win;
+
+#define WINDOW_CTRL(dma)		(0xA0C - ((dma) << 3))
+#define WINDOW_BASE(dma)		(0xA08 - ((dma) << 3))
+
+	mv88fx_snd_debug("");
+	/*
+	 * we have one window for each dma (playback dma and recording),
+	 * confiure it to point to the dram window where the buffer falls in
+	 */
+	win = mv88fx_find_dram_cs(dram,
+				  (u32) substream->dma_buffer.addr,
+				  (u32) MV88FX_SND_MAX_PERIODS *
+				  MV88FX_SND_MAX_PERIOD_BYTES);
+	if (win < 0)
+		return -1;
+
+	cs = dram->cs + win;
+	writel(((cs->size - 1) & 0xffff0000) |
+	       (cs->mbus_attr << 8) |
+	       (dram->mbus_dram_target_id << 4) | 1,
+	       chip->base + MV_AUDIO_REGS_OFFSET(chip->port) + WINDOW_CTRL(dma));
+	writel(cs->base,
+	       chip->base + MV_AUDIO_REGS_OFFSET(chip->port) + WINDOW_BASE(dma));
+
+
+#undef WINDOW_CTRL
+#undef WINDOW_BASE
+
+	return win;
+}
+static int mv88fx_conf_mbus_windows(struct mv88fx_snd_chip *chip,
+				    struct mbus_dram_target_info *dram)
+{
+	mv88fx_snd_debug("");
+	/*
+	 * we have one window for playback and one for recording
+	 */
+	if (mv88fx_config_dma_window(chip, SNDRV_PCM_STREAM_PLAYBACK, dram) < 0)
+		return -1;
+
+	if (mv88fx_config_dma_window(chip, SNDRV_PCM_STREAM_CAPTURE, dram) < 0)
+		return -1;
+	return 0;
+}
+
+
+static irqreturn_t mv88fx_pcm_dma_interrupt(int irq, void *dev_id)
+{
+	struct mv88fx_snd_chip *chip = dev_id;
+	struct snd_pcm_substream *play_stream =
+	    chip->pcm->streams[SNDRV_PCM_STREAM_PLAYBACK].substream;
+	struct snd_pcm_substream *capture_stream =
+	    chip->pcm->streams[SNDRV_PCM_STREAM_CAPTURE].substream;
+	unsigned int status, mask;
+
+	mv88fx_snd_debug("");
+
+	spin_lock(&chip->reg_lock);
+
+	/* read the active interrupt */
+	mask = mv88fx_snd_readl(chip->base,
+			MV_AUDIO_INT_MASK_REG(chip->port));
+	status = mv88fx_snd_readl(chip->base,
+			MV_AUDIO_INT_CAUSE_REG(chip->port)) & mask;
+
+	do {
+
+		if (status & ~(AICR_RECORD_BYTES_INT | AICR_PLAY_BYTES_INT)) {
+			spin_unlock(&chip->reg_lock);
+			snd_BUG();/* FIXME: should enable error interrupts */
+			return IRQ_NONE;
+		}
+
+		/* acknowledge interrupt */
+		mv88fx_snd_writel(chip->base,
+			MV_AUDIO_INT_CAUSE_REG(chip->port), status);
+
+		/* This is record event */
+		if (status & AICR_RECORD_BYTES_INT) {
+			mv88fx_snd_debug("capture");
+			spin_unlock(&chip->reg_lock);
+			if (capture_stream)
+				snd_pcm_period_elapsed(capture_stream);
+			spin_lock(&chip->reg_lock);
+		}
+		/* This is play event */
+		if (status & AICR_PLAY_BYTES_INT) {
+			mv88fx_snd_debug("playback");
+			spin_unlock(&chip->reg_lock);
+			if (play_stream)
+				snd_pcm_period_elapsed(play_stream);
+			spin_lock(&chip->reg_lock);
+
+		}
+
+		/* read the active interrupt */
+		mask = mv88fx_snd_readl(chip->base,
+				MV_AUDIO_INT_MASK_REG(chip->port));
+		status = mv88fx_snd_readl(chip->base,
+				MV_AUDIO_INT_CAUSE_REG(chip->port)) & mask;
+
+	} while (status);
+
+	spin_unlock(&chip->reg_lock);
+	return IRQ_HANDLED;
+
+}
+
+static int mv88fx_pcm_hw_params(struct snd_pcm_substream *substream,
+				struct snd_pcm_hw_params *params)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	int err = 0;
+
+	mv88fx_snd_debug("substream=%p", substream);
+
+	snd_pcm_set_runtime_buffer(substream, &substream->dma_buffer);
+	runtime->dma_bytes = params_buffer_bytes(params);
+	return err;
+
+}
+
+static int mv88fx_pcm_hw_free(struct snd_pcm_substream *substream)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	struct snd_dma_buffer *buf = runtime->dma_buffer_p;
+
+	mv88fx_snd_debug("");
+
+	if (runtime->dma_area == NULL)
+		return 0;
+
+	if (buf != &substream->dma_buffer)
+		kfree(runtime->dma_buffer_p);
+
+	snd_pcm_set_runtime_buffer(substream, NULL);
+	return 0;
+}
+
+static int mv88fx_pcm_prepare(struct snd_pcm_substream *substream)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	struct mv88fx_snd_stream *audio_stream = runtime->private_data;
+	struct mv88fx_snd_chip *chip = mv88fx_pcm_get_chip();
+
+	mv88fx_snd_debug("substream=%p chip=%p,chip->base=%p audio_stream=%p",
+			 substream, chip, chip->base, audio_stream);
+
+	if (substream->stream == SNDRV_PCM_STREAM_PLAYBACK)
+		if ((audio_stream->dig_mode == I2S) &&
+		    (chip->pcm_mode == NON_PCM)) {
+			mv88fx_snd_error("");
+			return -1;
+		}
+
+	return 0;
+}
+
+static int mv88fx_pcm_trigger(struct snd_pcm_substream *substream, int cmd)
+{
+	mv88fx_snd_debug("");
+	return 0;
+}
+
+static snd_pcm_uframes_t mv88fx_pcm_pointer(struct snd_pcm_substream *substream)
+{
+	struct mv88fx_snd_chip *chip = mv88fx_pcm_get_chip();
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	snd_pcm_uframes_t offset;
+	ssize_t size;
+
+	mv88fx_snd_debug("");
+
+	if (substream->stream == SNDRV_PCM_STREAM_PLAYBACK) {
+		size = (ssize_t) mv88fx_snd_readl(chip->base,
+		       MV_AUDIO_PLAYBACK_BUFF_BYTE_CNTR_REG(chip->port));
+		offset = bytes_to_frames(substream->runtime, size);
+	} else {
+		size = (ssize_t) mv88fx_snd_readl(chip->base,
+			MV_AUDIO_RECORD_BUF_BYTE_CNTR_REG(chip->port));
+		offset = bytes_to_frames(substream->runtime, size);
+	}
+	if (offset >= runtime->buffer_size)
+		offset = 0;
+
+	return offset;
+}
+
+static int mv88fx_pcm_open(struct snd_pcm_substream *substream)
+{
+	struct mv88fx_snd_chip *chip = mv88fx_pcm_get_chip();
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	int err = 0;
+
+	mv88fx_snd_debug("");
+
+	runtime->private_data = &chip->stream[substream->stream];
+
+	snd_soc_set_runtime_hwparams(substream, &mv88fx_pcm_hardware);
+
+	err = snd_pcm_hw_constraint_minmax(runtime,
+					   SNDRV_PCM_HW_PARAM_BUFFER_BYTES,
+					   chip->burst * 2,
+					   AUDIO_REG_TO_SIZE(APBBCR_SIZE_MAX));
+	if (err < 0)
+		return err;
+
+	err = snd_pcm_hw_constraint_step(runtime, 0,
+					 SNDRV_PCM_HW_PARAM_BUFFER_BYTES,
+					 chip->burst);
+	if (err < 0)
+		return err;
+
+	err = snd_pcm_hw_constraint_step(runtime, 0,
+					 SNDRV_PCM_HW_PARAM_PERIOD_BYTES,
+					 chip->burst);
+	if (err < 0)
+		return err;
+
+	err = snd_pcm_hw_constraint_minmax(runtime,
+					   SNDRV_PCM_HW_PARAM_PERIODS,
+					   MV88FX_SND_MIN_PERIODS,
+					   MV88FX_SND_MAX_PERIODS);
+	if (err < 0)
+		return err;
+
+	err = snd_pcm_hw_constraint_integer(runtime,
+					    SNDRV_PCM_HW_PARAM_PERIODS);
+	if (err < 0)
+		return err;
+
+	return 0;
+}
+
+static void mv88fx_pcm_reset_spdif_status(struct mv88fx_snd_chip *chip,
+					  int usr_bits)
+{
+	int i;
+
+	mv88fx_snd_debug("");
+
+	for (i = 0; i < 4; i++) {
+		chip->stream[SNDRV_PCM_STREAM_PLAYBACK].spdif_status[i] = 0;
+
+		mv88fx_snd_writel(chip->base,
+				  MV_AUDIO_SPDIF_PLAY_CH_STATUS_LEFT_REG(chip->
+									 port,
+									 i), 0);
+		mv88fx_snd_writel(chip->base,
+				  MV_AUDIO_SPDIF_PLAY_CH_STATUS_RIGHT_REG(chip->
+									  port,
+									  i),
+				  0);
+		if (usr_bits) {
+			mv88fx_snd_writel(chip->base,
+					  MV_AUDIO_SPDIF_PLAY_USR_BITS_LEFT_REG
+					  (chip->port, i), 0);
+			mv88fx_snd_writel(chip->base,
+					  MV_AUDIO_SPDIF_PLAY_USR_BITS_RIGHT_REG
+					  (chip->port, i), 0);
+		}
+	}
+
+}
+
+static int mv88fx_pcm_close(struct snd_pcm_substream *substream)
+{
+	struct mv88fx_snd_chip *chip = mv88fx_pcm_get_chip();
+
+	mv88fx_snd_debug("");
+
+	if (substream->stream == SNDRV_PCM_STREAM_PLAYBACK) {
+		chip->pcm_mode = PCM;
+		mv88fx_pcm_reset_spdif_status(chip, 0);
+	}
+	return 0;
+}
+
+static int mv88fx_pcm_mmap(struct snd_pcm_substream *substream,
+			   struct vm_area_struct *vma)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+
+	mv88fx_snd_debug("");
+
+	return dma_mmap_coherent(NULL, vma, runtime->dma_area,
+				 runtime->dma_addr, runtime->dma_bytes);
+}
+
+struct snd_pcm_ops mv88fx_pcm_ops = {
+	.open = mv88fx_pcm_open,
+	.close = mv88fx_pcm_close,
+	.ioctl = snd_pcm_lib_ioctl,
+	.hw_params = mv88fx_pcm_hw_params,
+	.hw_free = mv88fx_pcm_hw_free,
+	.prepare = mv88fx_pcm_prepare,
+	.trigger = mv88fx_pcm_trigger,
+	.pointer = mv88fx_pcm_pointer,
+	.mmap = mv88fx_pcm_mmap,
+};
+
+static int mv88fx_pcm_preallocate_dma_buffer(struct snd_pcm *pcm, int stream)
+{
+	struct snd_pcm_substream *substream = pcm->streams[stream].substream;
+	struct snd_dma_buffer *buf = &substream->dma_buffer;
+	size_t size = MV88FX_SND_MAX_PERIODS * MV88FX_SND_MAX_PERIOD_BYTES;
+
+	mv88fx_snd_debug("");
+
+	buf->dev.type = SNDRV_DMA_TYPE_DEV;
+	buf->dev.dev = pcm->card->dev;
+	buf->private_data = NULL;
+	buf->area = dma_alloc_coherent(pcm->card->dev,
+				       size, &buf->addr, GFP_KERNEL);
+	if (!buf->area) {
+		mv88fx_snd_error("unable to allocate");
+		return -ENOMEM;
+	}
+	buf->bytes = size;
+	return 0;
+}
+
+static struct mv88fx_snd_chip *mv88fx_pcm_init(struct snd_pcm *pcm,
+					       struct platform_device *pdev,
+					       struct mv88fx_snd_machine_data
+					       *machine_data)
+{
+	struct mv88fx_snd_chip *chip;
+
+	mv88fx_snd_debug("");
+	chip = mv88fx_pcm_snd_chip =
+	    kzalloc(sizeof(struct mv88fx_snd_chip), GFP_KERNEL);
+	if (!chip)
+		return NULL;
+
+	chip->base = machine_data->base;
+
+	spin_lock_init(&chip->reg_lock);
+	chip->dev = &pdev->dev;
+	chip->port = machine_data->port;
+	chip->pcm = pcm;
+	chip->pdata = machine_data->pdata;
+	chip->ch_stat_valid = 1;
+	chip->burst = 128;
+	chip->loopback = 0;
+	chip->dco_ctrl_offst = 0x800;
+	chip->irq = machine_data->irq;
+
+	if (request_irq(machine_data->irq, mv88fx_pcm_dma_interrupt,
+		0, DRIVER_NAME, (void *)chip)) {
+		mv88fx_snd_error("");
+		goto error;
+	}
+	if (chip->pdata->dram != NULL)
+		if (mv88fx_conf_mbus_windows(chip, chip->pdata->dram)) {
+			mv88fx_snd_error("");
+			goto error;
+
+		}
+
+
+	mv88fx_pcm_init_stream(chip, &chip->stream[SNDRV_PCM_STREAM_PLAYBACK],
+			       SNDRV_PCM_STREAM_PLAYBACK);
+	mv88fx_pcm_init_stream(chip, &chip->stream[SNDRV_PCM_STREAM_CAPTURE],
+			       SNDRV_PCM_STREAM_CAPTURE);
+	chip->pcm_mode = PCM;
+
+	mv88fx_pcm_reset_spdif_status(chip, 1);
+
+	return chip;
+error:
+	free_irq(chip->irq, chip);
+	kfree(chip);
+	mv88fx_pcm_snd_chip = NULL;
+	return NULL;
+}
+
+static int mv88fx_pcm_new(struct snd_card *card, struct snd_soc_dai *dai,
+			  struct snd_pcm *pcm)
+{
+	static u64 mv88fx_pcm_dmamask = DMA_BIT_MASK(32);
+	int ret = 0;
+	struct platform_device *pdev = to_platform_device(card->dev);
+	struct mv88fx_snd_machine_data *machine_data = pdev->dev.platform_data;
+	struct mv88fx_snd_chip *chip;
+
+	mv88fx_snd_debug("");
+
+	if (!card->dev->dma_mask)
+		card->dev->dma_mask = &mv88fx_pcm_dmamask;
+	if (!card->dev->coherent_dma_mask)
+		card->dev->coherent_dma_mask = DMA_BIT_MASK(32);
+
+	if (dai->playback.channels_min) {
+		ret = mv88fx_pcm_preallocate_dma_buffer(pcm,
+					SNDRV_PCM_STREAM_PLAYBACK);
+		if (ret) {
+			mv88fx_snd_error("");
+			goto out;
+		}
+	}
+
+	if (dai->capture.channels_min) {
+		ret = mv88fx_pcm_preallocate_dma_buffer(pcm,
+					SNDRV_PCM_STREAM_CAPTURE);
+		if (ret) {
+			mv88fx_snd_error("");
+			goto out;
+		}
+	}
+	chip = mv88fx_pcm_init(pcm, pdev, machine_data);
+	if (!chip)
+		return -ENOMEM;
+
+	return 0;
+out:
+	return ret;
+}
+
+static void mv88fx_pcm_free(struct snd_pcm *pcm)
+{
+	struct snd_pcm_substream *substream;
+	struct snd_dma_buffer *buf;
+	int stream;
+
+	mv88fx_snd_debug("");
+
+	for (stream = 0; stream < ARRAY_SIZE(pcm->streams); stream++) {
+		substream = pcm->streams[stream].substream;
+		if (!substream)
+			continue;
+
+		buf = &substream->dma_buffer;
+		if (!buf->area)
+			continue;
+		dma_free_coherent(pcm->card->dev,
+				  buf->bytes, buf->area, buf->addr);
+		buf->area = NULL;
+		buf->addr = 0;
+	}
+	free_irq(mv88fx_pcm_snd_chip->irq, mv88fx_pcm_snd_chip);
+	kfree(mv88fx_pcm_snd_chip);
+	mv88fx_pcm_snd_chip = NULL;
+}
+
+
+static int mv88fx_pcm_suspend(struct snd_soc_dai *cpu_dai)
+{
+	mv88fx_snd_debug("");
+
+
+	return 0;
+}
+
+
+
+static int mv88fx_pcm_resume(struct snd_soc_dai *cpu_dai)
+{
+	mv88fx_snd_debug("");
+
+
+	return 0;
+}
+
+
+
+struct snd_soc_platform mv88fx_soc_platform = {
+	.name = DRIVER_NAME,
+	.pcm_new = mv88fx_pcm_new,
+	.pcm_free = mv88fx_pcm_free,
+	.suspend  = mv88fx_pcm_suspend,
+	.resume   = mv88fx_pcm_resume,
+	.pcm_ops = &mv88fx_pcm_ops,
+};
+EXPORT_SYMBOL_GPL(mv88fx_soc_platform);
+
+
+static int __init mv88fx_soc_platform_init(void)
+{
+	return snd_soc_register_platform(&mv88fx_soc_platform);
+}
+module_init(mv88fx_soc_platform_init);
+
+static void __exit mv88fx_soc_platform_exit(void)
+{
+	snd_soc_unregister_platform(&mv88fx_soc_platform);
+}
+module_exit(mv88fx_soc_platform_exit);
+
+
+
+
+MODULE_AUTHOR("Yuval Elmaliah <eyuval@marvell.com>");
+MODULE_DESCRIPTION("mv88fx ASoc Platform driver");
+MODULE_LICENSE("GPL");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-pcm.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-pcm.h
new file mode 100644
index 0000000..9443823
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-pcm.h
@@ -0,0 +1,126 @@
+/*
+ *
+ *	Marvell Orion Alsa SOC Sound driver
+ *
+ *	Author: Yuval Elmaliah
+ *	Copyright (C) 2008 Marvell Ltd
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation
+ *
+ */
+
+
+#ifndef _MV88FX_PCM_H
+#define _MV88FX_PCM_H
+
+#define DRIVER_NAME	"mv88fx_snd"
+
+#ifdef MV88FX_SND_DEBUG
+#define mv88fx_snd_debug(format, args...) \
+	printk(KERN_DEBUG "%s(%d): "format"\n", __func__, __LINE__, ##args)
+#else
+#define mv88fx_snd_debug(a...)
+#endif
+#define mv88fx_snd_error(format, args...) \
+	printk(KERN_ERR "%s(%d): "format"\n", __func__, __LINE__, ##args)
+
+
+struct mv88fx_snd_stream {
+
+unsigned int dig_mode;	/* i2s,spdif,both */
+
+#define I2S		1
+#define SPDIF		2
+	int mono_mode;	/* both mono, left mono, right mono */
+#define MONO_BOTH	0
+#define MONO_LEFT	1
+#define MONO_RIGHT	2
+	int clock_src;
+
+#define DCO_CLOCK	0
+#define SPCR_CLOCK	1
+#define EXTERN_CLOCK	2
+	int stat_mem;	/* Channel status source */
+
+ unsigned int spdif_status[4];	/* SPDIF status */
+
+};
+
+
+struct mv88fx_snd_chip {
+	struct snd_card *card;
+	struct snd_pcm *pcm;
+	struct device *dev;
+	int port;
+	struct orion_i2s_platform_data *pdata;	/* platform dara */
+	struct mv88fx_snd_stream stream[2];	/* run time values */
+	spinlock_t reg_lock;	/* Register access spinlock */
+	void __iomem *base;	/* base address of the host */
+	int loopback;		/* When Loopback is enabled, playback
+				data is looped back to be recorded */
+	int ch_stat_valid;	/* Playback SPDIF channel validity bit
+				   value when REG selected */
+	int burst;		/* DMA Burst Size */
+#define SPDIF_MEM_STAT		0
+#define SPDIF_REG_STAT		1
+	unsigned int dco_ctrl_offst;
+	int pcm_mode;		/* pcm, nonpcm */
+#define PCM		0
+#define NON_PCM		1
+	int irq;
+
+};
+
+
+
+struct mv88fx_snd_machine_data {
+	struct platform_device *snd_dev;
+	int port;
+	void __iomem *base;	/* base address of the host */
+	int irq;
+	struct resource *res;	/* resource for IRQ and base */
+	struct orion_i2s_platform_data *pdata;	/* platform dara */
+#if defined(CONFIG_HAVE_CLK)
+	struct clk		*clk;
+#endif
+};
+
+
+#define MV88FX_SND_MIN_PERIODS		8
+#define MV88FX_SND_MAX_PERIODS		16
+#define	MV88FX_SND_MIN_PERIOD_BYTES	0x4000
+#define	MV88FX_SND_MAX_PERIOD_BYTES	0x4000
+
+
+/* read/write registers */
+#define mv88fx_snd_writel(base, offs, val)	\
+	writel((val), (base + offs))
+
+#define mv88fx_snd_readl(base, offs)	\
+	readl(base + offs)
+
+#define mv88fx_snd_bitset(base, offs, bitmask)	\
+	writel((readl(base + offs) | (bitmask)),	\
+	base + offs)
+
+#define mv88fx_snd_bitreset(base, offs, bitmask) \
+	writel((readl(base + offs) & (~(bitmask))), \
+	base + offs)
+
+
+
+
+extern struct mv88fx_snd_chip *mv88fx_pcm_snd_chip;
+
+#define mv88fx_pcm_get_chip() mv88fx_pcm_snd_chip
+#define mv88fx_pcm_is_stereo(runtime)        ((runtime)->channels != 1)
+
+
+extern struct snd_soc_platform mv88fx_soc_platform;
+
+
+
+#endif
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-rt5623.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-rt5623.c
new file mode 100644
index 0000000..6f45b59
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx-rt5623.c
@@ -0,0 +1,359 @@
+/*
+ *
+ *	Marvell Orion Alsa SOC Sound driver
+ *
+ *	Author: Yuval Elmaliah
+ *	Author: Ethan Ku
+ *	Copyright (C) 2008 Marvell Ltd.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/device.h>
+#include <linux/ioport.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/clk.h>
+#include <sound/core.h>
+#include <sound/pcm.h>
+#include <sound/soc.h>
+#include <sound/soc-dapm.h>
+#include <sound/asoundef.h>
+#include <asm/mach-types.h>
+//#include <asm/arch/hardware.h>
+#include "../sound/soc/codecs/rt5623.h"
+#include <linux/mbus.h>
+#include <asm/setup.h>
+#include <asm/mach/arch.h>
+#include <../arch/arm/mach-dove/common.h>
+//#include <asm/plat-orion/i2s-orion.h>
+#include "mv88fx-pcm.h"
+#include "mv88fx-i2s.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+#include "audio/mvAudioRegs.h"
+
+extern int mvmpp_gpio_get_value(unsigned int);
+extern int mvmpp_gpio_set_value(unsigned int,int);
+
+static struct mv88fx_snd_machine_data mv88fx_machine_data;
+static struct rt5623_setup_data rt5623_setup;
+
+
+static int mv88fx_machine_startup(struct snd_pcm_substream *substream)
+{
+//	struct snd_soc_pcm_runtime *rtd = substream->private_data;
+//	struct snd_soc_codec_dai *codec_dai = rtd->dai->codec_dai;
+//	struct snd_soc_cpu_dai *cpu_dai = rtd->dai->cpu_dai;
+//	int ret;
+#if 0
+	int phoneInDetected;
+
+//	printk("%s\n",__func__);
+
+	/* check the jack status at stream startup */
+	phoneInDetected = mvmpp_gpio_get_value(MPP_PhLine_IN);
+
+	if (phoneInDetected < 0) {
+		snd_printk("Failed to detect phone-in.\n");
+	} else {
+
+		if (! phoneInDetected) {
+			rt5623_setup.mic2_input = 0;
+		} else {
+			rt5623_setup.mic2_input = 1;
+		}
+	}
+#endif
+	return 0;
+
+}
+
+
+static void mv88fx_machine_shutdown(struct snd_pcm_substream *substream)
+{
+//	printk("%s\n",__func__);
+}
+
+
+
+static int mv88fx_machine_hw_params(struct snd_pcm_substream *substream,	
+				   struct snd_pcm_hw_params *params)
+{
+	struct snd_soc_pcm_runtime *rtd = substream->private_data;
+	struct snd_soc_dai *codec_dai = rtd->dai->codec_dai;
+	struct snd_soc_dai *cpu_dai = rtd->dai->cpu_dai;
+	unsigned int clk = 0;
+	int ret = 0;
+	unsigned int format;
+
+//	printk("%s\n",__func__);
+	/* set codec DAI configuration */
+
+
+	switch (params_rate(params)) {
+	case 44100:
+		clk = 11289600;
+		break;
+	case 48000:
+		clk = 12288000;
+		break;
+	case 96000:
+		clk = 24576000;
+		break;
+	}
+
+	format = SND_SOC_DAIFMT_CBS_CFS | SND_SOC_DAIFMT_I2S | SND_SOC_DAIFMT_NB_NF;
+	ret = codec_dai->ops->set_fmt(codec_dai, format);
+	if (ret < 0)
+		return ret;
+
+	/* set cpu DAI configuration */
+	ret = cpu_dai->ops->set_fmt(cpu_dai, format);
+	if (ret < 0)
+		return ret;
+
+	/* cpu clock is the mv88fx master clock sent to codec */
+	ret = cpu_dai->ops->set_sysclk(cpu_dai, 0, 0, SND_SOC_CLOCK_IN);
+	if (ret < 0)
+		return ret;
+
+	/* codec system clock is supplied by mv88fx*/
+	ret = codec_dai->ops->set_sysclk(codec_dai, 0, clk, SND_SOC_CLOCK_IN);
+	if (ret < 0)
+		return ret;
+
+	return 0;
+}
+
+static int mv88fx_machine_trigger(struct snd_pcm_substream *substream,int cmd)
+{
+	switch (cmd) {
+	case SNDRV_PCM_TRIGGER_START:
+		if(substream->stream==SNDRV_PCM_STREAM_PLAYBACK)
+		{
+//			mvmpp_gpio_set_value(MPP_Amp_PwrDn,1);
+		}
+		break;
+	case SNDRV_PCM_TRIGGER_STOP:
+		if(substream->stream==SNDRV_PCM_STREAM_PLAYBACK)
+		{
+//			mvmpp_gpio_set_value(MPP_Amp_PwrDn,0);
+		}
+		break;
+
+	}
+	return 0;
+}
+
+static int mv88fx_rt5623_init(struct snd_soc_codec *codec)
+{
+	mv88fx_snd_debug("");
+//	mvmpp_gpio_set_value(MPP_Amp_PwrDn,0);
+	return 0;
+}
+
+
+/* machine stream operations */
+static struct snd_soc_ops mv88fx_rt5623_machine_ops =
+{
+	.startup = mv88fx_machine_startup,
+	.shutdown = mv88fx_machine_shutdown,
+	.hw_params = mv88fx_machine_hw_params,
+	.trigger = mv88fx_machine_trigger,
+
+};
+
+
+
+static struct snd_soc_dai_link mv88fx_dai = {
+	.name = "RT5623",
+	.stream_name = "RT5623",
+	.cpu_dai = &mv88fx_i2s_dai,
+	.codec_dai = &rt5623_dai,
+	.ops = &mv88fx_rt5623_machine_ops,
+	.init = mv88fx_rt5623_init,
+};
+
+static int mv88fx_probe(struct platform_device *pdev)
+{
+	return 0;
+}
+
+static int mv88fx_remove(struct platform_device *pdev)
+{
+	return 0;
+}
+
+static struct snd_soc_card dove = {
+	.name = "Dove",
+	.platform = &mv88fx_soc_platform,
+	.probe = mv88fx_probe,
+	.remove = mv88fx_remove,
+
+	/* CPU <--> Codec DAI links */
+	.dai_link = &mv88fx_dai,
+	.num_links = 1,
+};
+
+static struct rt5623_setup_data rt5623_setup = {
+	.i2c_address = 0x1a,
+	.mic2_input = 1,
+};
+
+
+static struct snd_soc_device mv88fx_snd_devdata = {
+	.card = &dove,
+	.codec_dev = &soc_codec_dev_rt5623,
+	.codec_data = &rt5623_setup,
+};
+
+static int mv88fx_initalize_machine_data(struct platform_device *pdev)
+{
+	struct resource *r = NULL;
+	int err = 0;
+
+	mv88fx_snd_debug("");
+
+	mv88fx_machine_data.port = pdev->id;
+	mv88fx_machine_data.pdata =
+		(struct orion_i2s_platform_data *)pdev->dev.platform_data;
+
+	r = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!r) {
+		err = -ENXIO;
+		goto error;
+	}
+	r = request_mem_region(r->start, SZ_16K, DRIVER_NAME);
+	if (!r) {
+		err = -EBUSY;
+		goto error;
+	}
+	mv88fx_machine_data.res = r;
+	mv88fx_machine_data.base = ioremap(r->start, SZ_16K);
+
+	if (!mv88fx_machine_data.base) {
+		mv88fx_snd_error("ioremap failed");
+		err = -ENOMEM;
+		goto error;
+	}
+	mv88fx_machine_data.base -= MV_AUDIO_REGS_OFFSET(mv88fx_machine_data.port);
+
+	mv88fx_machine_data.irq = platform_get_irq(pdev, 0);
+	if (mv88fx_machine_data.irq == NO_IRQ) {
+		err = -ENXIO;
+		goto error;
+	}
+#if defined(CONFIG_HAVE_CLK)
+	mv88fx_machine_data.clk = clk_get(&pdev->dev, NULL);
+	if (IS_ERR(mv88fx_machine_data.clk))
+		dev_notice(&pdev->dev, "cannot get clkdev\n");
+	else
+		clk_enable(mv88fx_machine_data.clk);
+#endif
+	return 0;
+error:
+	if (mv88fx_machine_data.base) {
+		iounmap(mv88fx_machine_data.base);
+		mv88fx_machine_data.base = NULL;
+	}
+	release_mem_region(mv88fx_machine_data.res->start, SZ_16K);
+	return err;
+}
+
+static int mv88fx_snd_probe(struct platform_device *pdev)
+{
+	int ret = 0;
+
+	mv88fx_snd_debug("");
+
+	if (mv88fx_initalize_machine_data(pdev) != 0)
+		goto error;
+
+	mv88fx_machine_data.snd_dev = platform_device_alloc("soc-audio", -1);
+	if (!mv88fx_machine_data.snd_dev) {
+		ret = -ENOMEM;
+		goto error;
+	}
+
+	platform_set_drvdata(mv88fx_machine_data.snd_dev, &mv88fx_snd_devdata);
+	mv88fx_snd_devdata.dev = &mv88fx_machine_data.snd_dev->dev;
+
+	mv88fx_machine_data.snd_dev->dev.platform_data = &mv88fx_machine_data;
+
+	ret = platform_device_add(mv88fx_machine_data.snd_dev);
+
+	if(ret)
+	{
+                platform_device_put(mv88fx_machine_data.snd_dev);
+	}
+
+	return ret;
+error:
+	mv88fx_snd_error("");
+#if defined(CONFIG_HAVE_CLK)
+	if (!IS_ERR(mv88fx_machine_data.clk)) {
+		clk_disable(mv88fx_machine_data.clk);
+		clk_put(mv88fx_machine_data.clk);
+	}
+#endif
+	if (mv88fx_machine_data.snd_dev)
+		platform_device_unregister(mv88fx_machine_data.snd_dev);
+	return ret;
+
+}
+
+static int mv88fx_snd_remove(struct platform_device *dev)
+{
+	mv88fx_snd_debug("");
+#if defined(CONFIG_HAVE_CLK)
+	if (!IS_ERR(mv88fx_machine_data.clk)) {
+		clk_disable(mv88fx_machine_data.clk);
+		clk_put(mv88fx_machine_data.clk);
+	}
+#endif
+	mv88fx_machine_data.snd_dev->dev.platform_data = NULL;
+	platform_device_unregister(mv88fx_machine_data.snd_dev);
+	release_mem_region(mv88fx_machine_data.res->start, SZ_16K);
+	return 0;
+}
+
+static struct platform_driver mv88fx_snd_driver = {
+	.probe = mv88fx_snd_probe,
+	.remove = mv88fx_snd_remove,
+	.suspend = NULL,
+	.resume = NULL,
+	.driver = {
+		   .name = DRIVER_NAME,
+		   },
+
+};
+
+static int __init mv88fx_snd_init(void)
+{
+	if (!machine_is_dove_rd_avng())
+		return -ENODEV;
+
+	mv88fx_snd_debug("");
+	return platform_driver_register(&mv88fx_snd_driver);
+}
+
+static void __exit mv88fx_snd_exit(void)
+{
+	mv88fx_snd_debug("");
+	platform_driver_unregister(&mv88fx_snd_driver);
+
+}
+
+module_init(mv88fx_snd_init);
+module_exit(mv88fx_snd_exit);
+
+/* Module information */
+MODULE_AUTHOR("Yuval Elmaliah <eyuval@marvell.com>");
+MODULE_AUTHOR("Ethan Ku <eku@marvell.com>");
+MODULE_DESCRIPTION("ALSA SoC Dove");
+MODULE_LICENSE("GPL");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx.c
new file mode 100644
index 0000000..239394e
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_audio_soc/mv88fx.c
@@ -0,0 +1,648 @@
+/*
+ *
+ *	Marvell Orion Alsa SOC Sound driver
+ *
+ *	Author: Yuval Elmaliah
+ *	Copyright (C) 2008 Marvell Ltd.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/device.h>
+#include <linux/ioport.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/clk.h>
+#include <sound/core.h>
+#include <sound/pcm.h>
+#include <sound/soc.h>
+#include <sound/soc-dai.h>
+#include <sound/soc-dapm.h>
+#include <sound/asoundef.h>
+#include <asm/mach-types.h>
+#include "../sound/soc/codecs/cs42l51.h"
+#include <linux/mbus.h>
+#include <asm/setup.h>
+#include <asm/mach/arch.h>
+//#include <../arch/arm/mach-dove/common.h>
+#include <plat/i2s-orion.h>
+#include "mv88fx-pcm.h"
+#include "mv88fx-i2s.h"
+#include "audio/mvAudioRegs.h"
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+
+static struct mv88fx_snd_machine_data mv88fx_machine_data;
+
+static int mv88fx_snd_spdif_mask_info(struct snd_kcontrol *kcontrol,
+				      struct snd_ctl_elem_info *uinfo)
+{
+	uinfo->type = SNDRV_CTL_ELEM_TYPE_IEC958;
+	uinfo->count = 1;
+	return 0;
+}
+
+static int mv88fx_snd_spdif_mask_get(struct snd_kcontrol *kcontrol,
+				     struct snd_ctl_elem_value *ucontrol)
+{
+	ucontrol->value.iec958.status[0] = 0xff;
+	ucontrol->value.iec958.status[1] = 0xff;
+	ucontrol->value.iec958.status[2] = 0xff;
+	ucontrol->value.iec958.status[3] = 0xff;
+	return 0;
+}
+
+static struct snd_kcontrol_new mv88fx_snd_spdif_mask = {
+	.access = SNDRV_CTL_ELEM_ACCESS_READ,
+	.iface = SNDRV_CTL_ELEM_IFACE_PCM,
+	.name = SNDRV_CTL_NAME_IEC958("", PLAYBACK, CON_MASK),
+	.info = mv88fx_snd_spdif_mask_info,
+	.get = mv88fx_snd_spdif_mask_get,
+};
+
+static int mv88fx_snd_spdif_stream_info(struct snd_kcontrol *kcontrol,
+					struct snd_ctl_elem_info *uinfo)
+{
+	mv88fx_snd_debug("");
+	uinfo->type = SNDRV_CTL_ELEM_TYPE_IEC958;
+	uinfo->count = 1;
+	return 0;
+}
+
+static int mv88fx_snd_spdif_stream_get(struct snd_kcontrol *kcontrol,
+				       struct snd_ctl_elem_value *ucontrol)
+{
+	struct mv88fx_snd_chip *chip = snd_kcontrol_chip(kcontrol);
+	int i, word;
+
+	mv88fx_snd_debug("");
+	spin_lock_irq(&chip->reg_lock);
+	for (word = 0; word < 4; word++) {
+		chip->stream[SNDRV_PCM_STREAM_PLAYBACK].spdif_status[word] =
+		    mv88fx_snd_readl(chip->base,
+		     MV_AUDIO_SPDIF_PLAY_CH_STATUS_LEFT_REG(chip->port, word));
+		for (i = 0; i < 4; i++)
+			ucontrol->value.iec958.status[word + i] =
+			    (chip->stream[SNDRV_PCM_STREAM_PLAYBACK].
+			     spdif_status[word] >> (i * 8)) & 0xff;
+
+	}
+	spin_unlock_irq(&chip->reg_lock);
+	return 0;
+}
+
+static int mv88fx_snd_spdif_stream_put(struct snd_kcontrol *kcontrol,
+				       struct snd_ctl_elem_value *ucontrol)
+{
+	struct mv88fx_snd_chip *chip = snd_kcontrol_chip(kcontrol);
+	int i, change = 0, word;
+	unsigned int val;
+	struct mv88fx_snd_stream *pbstream =
+		&chip->stream[SNDRV_PCM_STREAM_PLAYBACK];
+	int port = chip->port;
+
+	mv88fx_snd_debug("");
+	val = 0;
+	port = port;
+	spin_lock_irq(&chip->reg_lock);
+	for (word = 0; word < 4; word++) {
+		for (i = 0; i < 4; i++) {
+			chip->stream[SNDRV_PCM_STREAM_PLAYBACK].
+			    spdif_status[word] |=
+			    ucontrol->value.iec958.status[word + i] << (i * 8);
+		}
+		mv88fx_snd_writel(chip->base,
+			MV_AUDIO_SPDIF_PLAY_CH_STATUS_LEFT_REG(port, word),
+			pbstream->spdif_status[word]);
+
+		mv88fx_snd_writel(chip->base,
+			MV_AUDIO_SPDIF_PLAY_CH_STATUS_RIGHT_REG(port, word),
+			pbstream->spdif_status[word]);
+
+	}
+
+	if (pbstream->spdif_status[0] & IEC958_AES0_NONAUDIO)
+		chip->pcm_mode = NON_PCM;
+
+	spin_unlock_irq(&chip->reg_lock);
+	return change;
+}
+
+static struct snd_kcontrol_new mv88fx_snd_spdif_stream = {
+	.access = SNDRV_CTL_ELEM_ACCESS_READWRITE |
+	    SNDRV_CTL_ELEM_ACCESS_INACTIVE,
+	.iface = SNDRV_CTL_ELEM_IFACE_PCM,
+	.name = SNDRV_CTL_NAME_IEC958("", PLAYBACK, PCM_STREAM),
+	.info = mv88fx_snd_spdif_stream_info,
+	.get = mv88fx_snd_spdif_stream_get,
+	.put = mv88fx_snd_spdif_stream_put
+};
+
+static int mv88fx_snd_spdif_default_info(struct snd_kcontrol *kcontrol,
+					 struct snd_ctl_elem_info *uinfo)
+{
+	mv88fx_snd_debug("");
+	uinfo->type = SNDRV_CTL_ELEM_TYPE_IEC958;
+	uinfo->count = 1;
+	return 0;
+}
+
+static int mv88fx_snd_spdif_default_get(struct snd_kcontrol *kcontrol,
+					struct snd_ctl_elem_value *ucontrol)
+{
+	struct mv88fx_snd_chip *chip = snd_kcontrol_chip(kcontrol);
+	struct mv88fx_snd_stream *pbstream =
+		&chip->stream[SNDRV_PCM_STREAM_PLAYBACK];
+	int port = chip->port;
+	int i, word;
+
+	mv88fx_snd_debug("");
+
+	port = port;
+	spin_lock_irq(&chip->reg_lock);
+	for (word = 0; word < 4; word++) {
+		pbstream->spdif_status[word] =
+		    mv88fx_snd_readl(chip->base,
+			MV_AUDIO_SPDIF_PLAY_CH_STATUS_LEFT_REG(port, word));
+
+		for (i = 0; i < 4; i++)
+			ucontrol->value.iec958.status[word + i] =
+			(pbstream->spdif_status[word] >> (i * 8)) & 0xff;
+
+	}
+	spin_unlock_irq(&chip->reg_lock);
+	return 0;
+}
+
+static int mv88fx_snd_spdif_default_put(struct snd_kcontrol *kcontrol,
+					struct snd_ctl_elem_value *ucontrol)
+{
+	struct mv88fx_snd_chip *chip = snd_kcontrol_chip(kcontrol);
+	struct mv88fx_snd_stream *pbstream =
+		&chip->stream[SNDRV_PCM_STREAM_PLAYBACK];
+	int port = chip->port;
+	int i, change = 0, word;
+	unsigned int val;
+
+	mv88fx_snd_debug("");
+
+	port = port;
+	val = 0;
+	spin_lock_irq(&chip->reg_lock);
+	for (word = 0; word < 4; word++) {
+		for (i = 0; i < 4; i++) {
+			pbstream->spdif_status[word] |=
+			    ucontrol->value.iec958.status[word + i] << (i * 8);
+		}
+		mv88fx_snd_writel(chip->base,
+			MV_AUDIO_SPDIF_PLAY_CH_STATUS_LEFT_REG(port, word),
+			pbstream->spdif_status[word]);
+		mv88fx_snd_writel(chip->base,
+			MV_AUDIO_SPDIF_PLAY_CH_STATUS_RIGHT_REG(port, word),
+			pbstream->spdif_status[word]);
+
+	}
+	if (pbstream->spdif_status[0] & IEC958_AES0_NONAUDIO)
+		chip->pcm_mode = NON_PCM;
+
+
+	spin_unlock_irq(&chip->reg_lock);
+	return change;
+}
+static struct snd_kcontrol_new mv88fx_snd_spdif_default = {
+	.iface = SNDRV_CTL_ELEM_IFACE_PCM,
+	.name = SNDRV_CTL_NAME_IEC958("", PLAYBACK, DEFAULT),
+	.info = mv88fx_snd_spdif_default_info,
+	.get = mv88fx_snd_spdif_default_get,
+	.put = mv88fx_snd_spdif_default_put
+};
+
+struct mv88fx_snd_mixer_enum {
+	char **names;		/* enum names */
+	int *values;		/* values to be updated */
+	int count;		/* number of elements */
+	void *rec;		/* field to be updated */
+};
+
+int mv88fx_snd_mixer_enum_info(struct snd_kcontrol *kcontrol,
+			       struct snd_ctl_elem_info *uinfo)
+{
+	struct mv88fx_snd_mixer_enum *mixer_enum =
+	    (struct mv88fx_snd_mixer_enum *)kcontrol->private_value;
+
+	mv88fx_snd_debug("");
+
+	uinfo->type = SNDRV_CTL_ELEM_TYPE_ENUMERATED;
+	uinfo->count = 1;
+	uinfo->value.enumerated.items = mixer_enum->count;
+
+	if (uinfo->value.enumerated.item >= uinfo->value.enumerated.items)
+		uinfo->value.enumerated.item =
+		    uinfo->value.enumerated.items - 1;
+
+	strcpy(uinfo->value.enumerated.name,
+	       mixer_enum->names[uinfo->value.enumerated.item]);
+
+	return 0;
+}
+int mv88fx_snd_mixer_enum_get(struct snd_kcontrol *kcontrol,
+			      struct snd_ctl_elem_value *ucontrol)
+{
+	struct mv88fx_snd_mixer_enum *mixer_enum =
+	    (struct mv88fx_snd_mixer_enum *)kcontrol->private_value;
+	int i;
+	unsigned int val;
+
+	mv88fx_snd_debug("");
+
+	val = *(unsigned int *)mixer_enum->rec;
+
+	for (i = 0; i < mixer_enum->count; i++) {
+
+		if (val == (unsigned int)mixer_enum->values[i]) {
+			ucontrol->value.enumerated.item[0] = i;
+			break;
+		}
+	}
+
+	return 0;
+}
+
+int mv88fx_snd_mixer_enum_put(struct snd_kcontrol *kcontrol,
+			      struct snd_ctl_elem_value *ucontrol)
+{
+	unsigned int val, *rec;
+	struct mv88fx_snd_mixer_enum *mixer_enum =
+	    (struct mv88fx_snd_mixer_enum *)kcontrol->private_value;
+	int i;
+
+	mv88fx_snd_debug("");
+
+	rec = (unsigned int *)mixer_enum->rec;
+	val = ucontrol->value.enumerated.item[0];
+
+	if (val < 0)
+		val = 0;
+	if (val > mixer_enum->count)
+		val = mixer_enum->count;
+
+	for (i = 0; i < mixer_enum->count; i++) {
+
+		if (val == i) {
+			*rec = (unsigned int)mixer_enum->values[i];
+			break;
+		}
+	}
+
+	return 0;
+}
+
+#define MV88FX_PCM_MIXER_ENUM(xname, xindex, value)	\
+{ .iface = SNDRV_CTL_ELEM_IFACE_MIXER, \
+  .name = xname, \
+  .index = xindex, \
+  .info = mv88fx_snd_mixer_enum_info, \
+  .get = mv88fx_snd_mixer_enum_get, \
+  .put = mv88fx_snd_mixer_enum_put, \
+  .private_value = (unsigned long)value,	\
+}
+
+char *playback_src_mixer_names[] = { "SPDIF", "I2S", "SPDIF And I2S" };
+int playback_src_mixer_values[] = { SPDIF, I2S, (SPDIF | I2S) };
+
+struct mv88fx_snd_mixer_enum playback_src_mixer = {
+	.names = playback_src_mixer_names,
+	.values = playback_src_mixer_values,
+	.count = 3,
+};
+
+char *playback_mono_mixer_names[] = { "Mono Both", "Mono Left", "Mono Right" };
+int playback_mono_mixer_values[] = { MONO_BOTH, MONO_LEFT, MONO_RIGHT };
+
+struct mv88fx_snd_mixer_enum playback_mono_mixer = {
+	.names = playback_mono_mixer_names,
+	.values = playback_mono_mixer_values,
+	.count = 3,
+};
+
+char *capture_src_mixer_names[] = { "SPDIF", "I2S" };
+int capture_src_mixer_values[] = { SPDIF, I2S };
+
+struct mv88fx_snd_mixer_enum capture_src_mixer = {
+	.names = capture_src_mixer_names,
+	.values = capture_src_mixer_values,
+	.count = 2,
+};
+
+char *capture_mono_mixer_names[] = { "Mono Left", "Mono Right" };
+int capture_mono_mixer_values[] = { MONO_LEFT, MONO_RIGHT };
+
+struct mv88fx_snd_mixer_enum capture_mono_mixer = {
+	.names = capture_mono_mixer_names,
+	.values = capture_mono_mixer_values,
+	.count = 2,
+};
+
+static struct snd_kcontrol_new mv88fx_snd_mixers[] = {
+	MV88FX_PCM_MIXER_ENUM("Playback output type", 0,
+			      &playback_src_mixer),
+
+	MV88FX_PCM_MIXER_ENUM("Playback mono type", 0,
+			      &playback_mono_mixer),
+
+	MV88FX_PCM_MIXER_ENUM("Capture input Type", 0,
+			      &capture_src_mixer),
+
+	MV88FX_PCM_MIXER_ENUM("Capture mono type", 0,
+			      &capture_mono_mixer),
+
+};
+
+#define	PLAYBACK_MIX_INDX	0
+#define PLAYBACK_MONO_MIX_INDX	1
+#define CAPTURE_MIX_INDX	2
+#define	CAPTURE_MONO_MIX_INDX	3
+
+static int mv88fx_snd_ctrl_new(struct snd_card *card)
+{
+	int err = 0;
+	struct mv88fx_snd_chip *chip = mv88fx_pcm_get_chip();
+
+	playback_src_mixer.rec =
+	    &chip->stream[SNDRV_PCM_STREAM_PLAYBACK].dig_mode;
+	playback_mono_mixer.rec =
+	    &chip->stream[SNDRV_PCM_STREAM_PLAYBACK].mono_mode;
+
+	capture_src_mixer.rec =
+	    &chip->stream[SNDRV_PCM_STREAM_CAPTURE].dig_mode;
+	capture_mono_mixer.rec =
+	    &chip->stream[SNDRV_PCM_STREAM_CAPTURE].mono_mode;
+
+	if (chip->pdata->i2s_play && chip->pdata->spdif_play) {
+		err =
+		    snd_ctl_add(card,
+				snd_ctl_new1(&mv88fx_snd_mixers
+					     [PLAYBACK_MIX_INDX], chip));
+		if (err < 0)
+			return err;
+	}
+
+	if (chip->pdata->i2s_play || chip->pdata->spdif_play) {
+		err =
+		    snd_ctl_add(card,
+				snd_ctl_new1(&mv88fx_snd_mixers
+					     [PLAYBACK_MONO_MIX_INDX], chip));
+		if (err < 0)
+			return err;
+	}
+
+	if (chip->pdata->i2s_rec && chip->pdata->spdif_rec) {
+		err =
+		    snd_ctl_add(card,
+				snd_ctl_new1(&mv88fx_snd_mixers
+					     [CAPTURE_MIX_INDX], chip));
+		if (err < 0)
+			return err;
+	}
+
+	if (chip->pdata->i2s_rec || chip->pdata->spdif_rec) {
+		err =
+		    snd_ctl_add(card,
+				snd_ctl_new1(&mv88fx_snd_mixers
+					     [CAPTURE_MONO_MIX_INDX], chip));
+		if (err < 0)
+			return err;
+	}
+
+	if (chip->pdata->spdif_play) {
+		err = snd_ctl_add(card, snd_ctl_new1(&mv88fx_snd_spdif_mask,
+						     chip));
+		if (err < 0)
+			return err;
+	}
+	if (chip->pdata->spdif_play) {
+		err = snd_ctl_add(card, snd_ctl_new1(&mv88fx_snd_spdif_default,
+						     chip));
+		if (err < 0)
+			return err;
+	}
+	if (chip->pdata->spdif_play) {
+		err = snd_ctl_add(card, snd_ctl_new1(&mv88fx_snd_spdif_stream,
+						     chip));
+		if (err < 0)
+			return err;
+	}
+
+	return err;
+}
+
+
+static int mv88fx_cs42l51_init(struct snd_soc_codec *codec)
+{
+	mv88fx_snd_debug("");
+
+#ifdef CONFIG_MACH_DOVE_RD_AVNG
+	/* Default Gain */
+	snd_soc_update_bits(codec, CS42L51_REG_DAC_OUTPUT_CTRL, 0xE0, 0xE0);
+
+#endif
+
+	mv88fx_snd_ctrl_new(codec->card);
+
+	return 0;
+}
+
+static struct snd_soc_dai_link mv88fx_dai[] = {
+	{
+	 .name = "CS42L51",
+	 .stream_name = "CS42L51",
+	 .cpu_dai = &mv88fx_i2s_dai,
+	 .codec_dai = &cs42l51_dai,
+	 .init = mv88fx_cs42l51_init,
+	 },
+};
+
+static int mv88fx_probe(struct platform_device *pdev)
+{
+	return 0;
+}
+
+static int mv88fx_remove(struct platform_device *pdev)
+{
+	return 0;
+}
+
+static struct snd_soc_card mv_i2s = {
+	.name = "mv_i2s",
+	.platform = &mv88fx_soc_platform,
+	.probe = mv88fx_probe,
+	.remove = mv88fx_remove,
+	/* CPU <--> Codec DAI links */
+	.dai_link = mv88fx_dai,
+	.num_links = ARRAY_SIZE(mv88fx_dai),
+};
+
+struct cs42l51_setup_data mv88fx_codec_setup_data = {
+	.i2c_address = 0x4A,
+};
+
+static struct snd_soc_device mv88fx_snd_devdata = {
+	.card = &mv_i2s,
+	.codec_dev = &soc_codec_dev_cs42l51,
+	.codec_data = &mv88fx_codec_setup_data,
+};
+
+static int mv88fx_initalize_machine_data(struct platform_device *pdev)
+{
+	struct resource *r = NULL;
+	int err = 0;
+
+	mv88fx_snd_debug("");
+
+	mv88fx_machine_data.port = pdev->id;
+	mv88fx_machine_data.pdata =
+	    (struct orion_i2s_platform_data *)pdev->dev.platform_data;
+
+	r = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!r) {
+		mv88fx_snd_error("");
+		err = -ENXIO;
+		goto error;
+	}
+	r = request_mem_region(r->start, SZ_16K, DRIVER_NAME);
+	if (!r) {
+		mv88fx_snd_error("");
+		err = -EBUSY;
+		goto error;
+	}
+	mv88fx_machine_data.res = r;
+	mv88fx_machine_data.base = ioremap(r->start, SZ_16K);
+
+	if (!mv88fx_machine_data.base) {
+		mv88fx_snd_error("ioremap failed");
+		err = -ENOMEM;
+		goto error;
+	}
+	mv88fx_machine_data.base -= MV_AUDIO_REGS_OFFSET(mv88fx_machine_data.port);
+
+	mv88fx_machine_data.irq = platform_get_irq(pdev, 0);
+	if (mv88fx_machine_data.irq == NO_IRQ) {
+		mv88fx_snd_error("");
+		err = -ENXIO;
+		goto error;
+	}
+#if defined(CONFIG_HAVE_CLK)
+	mv88fx_machine_data.clk = clk_get(&pdev->dev, NULL);
+	if (IS_ERR(mv88fx_machine_data.clk))
+		dev_notice(&pdev->dev, "cannot get clkdev\n");
+	else
+		clk_enable(mv88fx_machine_data.clk);
+#endif
+
+	return 0;
+error:
+	if (mv88fx_machine_data.base) {
+		iounmap(mv88fx_machine_data.base);
+		mv88fx_machine_data.base = NULL;
+	}
+	release_mem_region(mv88fx_machine_data.res->start, SZ_16K);
+	return err;
+}
+
+static int mv88fx_snd_probe(struct platform_device *pdev)
+{
+	int ret = 0;
+
+	mv88fx_snd_debug("");
+
+	if (mv88fx_initalize_machine_data(pdev) != 0)
+		goto error;
+	mv88fx_machine_data.snd_dev = platform_device_alloc("soc-audio", 1);
+	if (!mv88fx_machine_data.snd_dev) {
+		ret = -ENOMEM;
+		goto error;
+	}
+
+	platform_set_drvdata(mv88fx_machine_data.snd_dev, &mv88fx_snd_devdata);
+	mv88fx_snd_devdata.dev = &mv88fx_machine_data.snd_dev->dev;
+
+	mv88fx_machine_data.snd_dev->dev.platform_data = &mv88fx_machine_data;
+
+	ret = platform_device_add(mv88fx_machine_data.snd_dev);
+
+	mv88fx_snd_debug("");
+
+	return 0;
+error:
+	mv88fx_snd_error("");
+
+#if defined(CONFIG_HAVE_CLK)
+	if (!IS_ERR(mv88fx_machine_data.clk)) {
+		clk_disable(mv88fx_machine_data.clk);
+		clk_put(mv88fx_machine_data.clk);
+	}
+#endif
+
+	if (mv88fx_machine_data.snd_dev)
+		platform_device_unregister(mv88fx_machine_data.snd_dev);
+	return ret;
+
+}
+
+static int mv88fx_snd_remove(struct platform_device *dev)
+{
+	mv88fx_snd_debug("");
+
+#if defined(CONFIG_HAVE_CLK)
+	if (!IS_ERR(mv88fx_machine_data.clk)) {
+		clk_disable(mv88fx_machine_data.clk);
+		clk_put(mv88fx_machine_data.clk);
+	}
+#endif
+	mv88fx_machine_data.snd_dev->dev.platform_data = NULL;
+	platform_device_unregister(mv88fx_machine_data.snd_dev);
+	release_mem_region(mv88fx_machine_data.res->start, SZ_16K);
+	return 0;
+}
+
+static struct platform_driver mv88fx_snd_driver = {
+	.probe = mv88fx_snd_probe,
+	.remove = mv88fx_snd_remove,
+	.suspend = NULL,
+	.resume = NULL,
+	.driver = {
+		   .name = DRIVER_NAME,
+		   },
+
+};
+
+static int __init mv88fx_snd_init(void)
+{
+#ifdef CONFIG_ARCH_DOVE
+	if (!machine_is_dove_db() && !machine_is_dove_db_z0())
+		return -ENODEV;
+#endif
+
+	mv88fx_snd_debug("");
+	return platform_driver_register(&mv88fx_snd_driver);
+}
+
+static void __exit mv88fx_snd_exit(void)
+{
+	mv88fx_snd_debug("");
+	platform_driver_unregister(&mv88fx_snd_driver);
+
+}
+
+module_init(mv88fx_snd_init);
+module_exit(mv88fx_snd_exit);
+
+/* Module information */
+MODULE_AUTHOR("Yuval Elmaliah <eyuval@marvell.com>");
+MODULE_DESCRIPTION("ALSA Marvell SoC");
+MODULE_LICENSE("GPL");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_btns/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_btns/Makefile
new file mode 100644
index 0000000..afc2800
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_btns/Makefile
@@ -0,0 +1,12 @@
+#
+# Makefile for the Marvell btns Driver
+#
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+obj-y += btns_driver.o
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_btns/btns_driver.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_btns/btns_driver.c
new file mode 100644
index 0000000..8f89f04
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_btns/btns_driver.c
@@ -0,0 +1,360 @@
+/*******************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/platform_device.h>
+#include <linux/miscdevice.h>
+#include "btns_dev.h"
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "gpp/mvGpp.h"
+#include "gpp/mvGppRegs.h"
+#include "btns_driver.h"
+
+
+/* MACROS */
+#define GPP_GROUP(gpp) 	gpp/32
+#define GPP_ID(gpp)   	gpp%32
+#define GPP_BIT(gpp)	0x1 << GPP_ID(gpp)
+
+/* waiting Q */
+wait_queue_head_t btns_waitq;
+
+/*
+ * common debug for all
+ */
+#undef DEBUG
+
+#ifdef DEBUG
+#define dprintk   printk
+#else
+#define dprintk(a...)
+#endif
+
+/* At GPP initialization, this strucure is filled with what       
+ * operation will be monitored for each button (Push and/or          
+ * Release) */ 
+BTN_OP 	btn_op_cfg[CONFIG_MV_GPP_MAX_PINS] = {BTN_NO_OP};
+
+/* At GPP initialization, this strucure is filled with what       
+ * operation will be monitored for each button (Push and/or          
+ * Release) */ 
+u32 	gpp_default_val_cfg[CONFIG_MV_GPP_MAX_PINS] = {-1};
+
+/* This structures monitors how many time each button was 	  
+ * Push/Released since the last time it was sampled */ 
+BTN		btns_status[CONFIG_MV_GPP_MAX_PINS];
+
+u32		is_opend = 0;
+u32		gpp_changed = 0;
+u32		gpp_changed_id = -1;
+
+
+/*
+ * Get GPP real value....
+ * When Gpp is input:
+ * Since reading GPP_DATA_IN_REG return the GPP real value after considering the active polarity
+ * active low = 1, active high = 0
+ * we will use: val^0 -> val, val^1->not(val)
+ * when output don't consider the active polarity
+ */
+static unsigned int 
+mv_gpp_value_real_get(unsigned int gpp_group, unsigned int mask)
+{
+        unsigned int temp, in_out, gpp_val;
+        /* in ->1,  out -> 0 */
+        in_out = MV_REG_READ(GPP_DATA_OUT_EN_REG(gpp_group)) & mask;
+
+	gpp_val = MV_REG_READ(GPP_DATA_IN_REG(gpp_group)) & mask;
+
+        /* outputs values */
+        temp = (gpp_val & ~in_out);
+
+        /* input */
+        temp |= (( gpp_val ^ MV_REG_READ(GPP_DATA_IN_POL_REG(gpp_group)) ) & in_out) & mask;
+
+        return temp;
+}
+
+
+static irqreturn_t
+mv_btns_handler(int irq , void *dev_id)
+{
+	u32 gpp = (u32) irq - IRQ_GPP_START;
+	u32 gpp_level, gppVal;
+	BTN_OP btn_op;
+	
+	/* get gpp real val */
+	gppVal = mv_gpp_value_real_get(GPP_GROUP(gpp), GPP_BIT(gpp));
+
+	dprintk("Gpp value was changed: ");
+        if (btn_op_cfg[gpp] != BTN_NO_OP) {
+                dprintk("gpp %d has changed. now it's %x \n",gpp,
+				mv_gpp_value_real_get(GPP_GROUP(gpp), GPP_BIT(gpp)) );
+		
+		/* Count button Pushes/Releases
+		 * mv_gpp_value_real_get == gpp_default_val_cfg[gpp] --> Button push, 
+		 * else --> Button release
+		 */
+		btn_op = (gppVal == gpp_default_val_cfg[gpp]) ? BTN_PUSH : BTN_RELEASE;
+
+		if(btn_op == BTN_RELEASE)
+		{
+			dprintk("button (of gpp %d) was released \n",gpp);
+
+			btns_status[gpp].btn_release_cntr++;
+		} else {
+			dprintk("button (of gpp %d) was pressed \n",gpp);
+			
+			btns_status[gpp].btn_push_cntr++;
+		}
+		
+                /* change polarity */
+                gpp_level = MV_REG_READ(GPP_DATA_IN_POL_REG(GPP_GROUP(gpp)));
+                gpp_level = gpp_level^GPP_BIT(gpp);
+                MV_REG_WRITE(GPP_DATA_IN_POL_REG(GPP_GROUP(gpp)), gpp_level);
+
+		/* Check if current botton operation should be monitored */
+		if(btn_op_cfg[gpp] == btn_op || btn_op_cfg[gpp] == BTN_CHANGE)
+		{
+			gpp_changed = 1;
+			gpp_changed_id = gpp;
+			wake_up_interruptible(&btns_waitq);
+		}
+	}
+
+	return IRQ_HANDLED;
+}
+
+static int
+btnsdev_ioctl(
+        struct inode *inode,
+        struct file *filp,
+        unsigned int cmd,
+        unsigned long arg)
+{
+	unsigned int btn_id;
+	BTN btn_sts;
+	BTN_PTR user_btn_sts_ptr;
+	unsigned int error = 0;
+	int i;	
+
+        dprintk("%s()\n", __FUNCTION__);
+
+        switch (cmd) {
+        case CIOCWAIT_P:
+		/* Haim - Is the condition here correct? */
+            	error = wait_event_interruptible(btns_waitq, gpp_changed);
+		/* Reset Wait Q condition */
+		gpp_changed = 0;
+
+		if(error < 0)
+			dprintk("%s(CIOCWAIT_P) - got interrupted\n", __FUNCTION__);
+		
+		/* Set information for user*/
+		btn_sts.btn_id = gpp_changed_id;
+		btn_sts.btn_push_cntr   =btns_status[gpp_changed_id].btn_push_cntr;
+		btn_sts.btn_release_cntr=btns_status[gpp_changed_id].btn_release_cntr;
+		
+		dprintk("Button ID %d was pressed %d and released %d\n",gpp_changed_id,
+			btns_status[gpp_changed_id].btn_push_cntr,btns_status[gpp_changed_id].btn_release_cntr);
+
+		user_btn_sts_ptr = &(((BTNS_STS_PTR)arg)->btns[0]);
+		if ( copy_to_user((void*)user_btn_sts_ptr, &btn_sts,  sizeof(BTN)) ) {
+                        dprintk("%s(CIOCWAIT_P) - bad copy\n", __FUNCTION__);
+                        error = EFAULT;
+                }
+
+		/* Reset changed button operations counters*/
+		btns_status[gpp_changed_id].btn_push_cntr = 0;
+		btns_status[gpp_changed_id].btn_release_cntr = 0;
+
+                break;
+	case CIOCNOWAIT_P:
+		/* Eventhough we don't monitor for a button status change, we need to 
+ 			reset the indication of a change in case it happend */
+		gpp_changed = 0;
+
+		dprintk("There are %d buttons to be checked\n", ((BTNS_STS_PTR)arg)->btns_number);
+
+		/* Set information for user*/
+		for (i=0; i<((BTNS_STS_PTR)arg)->btns_number; i++)
+		{
+			btn_id = ((BTNS_STS_PTR)arg)->btns[i].btn_id;
+
+			/* initialize temp strucure which will be copied to user */
+			btn_sts.btn_id = btn_id;
+			btn_sts.btn_push_cntr = btns_status[btn_id].btn_push_cntr;
+			btn_sts.btn_release_cntr = btns_status[btn_id].btn_release_cntr;
+
+			/* Reset button's operations counters*/
+			btns_status[btn_id].btn_push_cntr = 0;
+			btns_status[btn_id].btn_release_cntr = 0;
+
+			/* Copy temp structure to user */
+			user_btn_sts_ptr = &(((BTNS_STS_PTR)arg)->btns[i]);
+
+			if ( copy_to_user((void*)user_btn_sts_ptr, &btn_sts,  sizeof(BTN)) ) {
+				dprintk("%s(CIOCNOWAIT_P) - bad copy\n", __FUNCTION__);
+				error = EFAULT;
+			}
+		}
+		
+		break;
+        default:
+                dprintk("%s(unknown ioctl 0x%x)\n", __FUNCTION__, cmd);
+                error = EINVAL;
+                break;
+        }
+        return(-error);
+}
+
+/*
+ * btn_gpp_init
+ * initialize on button's GPP and registers its IRQ
+ *
+ */
+static int  
+btn_gpp_init(unsigned int gpp, unsigned int default_gpp_val, BTN_OP btn_op, char* btn_name)
+{
+	unsigned int pol;
+	/* Set Polarity bit */
+	pol = MV_REG_READ(GPP_DATA_IN_POL_REG(GPP_GROUP(gpp)));
+	pol |= GPP_BIT(gpp);
+	MV_REG_WRITE(GPP_DATA_IN_POL_REG(GPP_GROUP(gpp)), pol);
+	
+	/* Set which button operation should be monitored */
+	btn_op_cfg[gpp] = btn_op;
+
+	/* Set GPP default value*/
+	gpp_default_val_cfg[gpp] = default_gpp_val;
+
+	/* Register IRQ */
+	if( request_irq( IRQ_GPP_START + gpp, mv_btns_handler,
+		IRQF_DISABLED, btn_name, NULL ) ) 
+	{
+		printk( KERN_ERR "btnsdev:  can't get irq for button %s (GPP %d)\n",btn_name,gpp );
+		return -1;
+	}
+
+	return 0;
+}
+
+static int
+btnsdev_open(struct inode *inode, struct file *filp)
+{
+        dprintk("%s()\n", __FUNCTION__);
+
+	if(!is_opend) {
+		is_opend = 1;
+		
+		/* Reset button operations counters*/
+		memset(&btns_status,0,CONFIG_MV_GPP_MAX_PINS);
+	}
+
+        return(0);
+}
+
+static int
+btnsdev_release(struct inode *inode, struct file *filp)
+{
+        dprintk("%s()\n", __FUNCTION__);
+        return(0);
+}
+
+
+static struct file_operations btnsdev_fops = {
+        .open = btnsdev_open,
+        .release = btnsdev_release,
+        .ioctl = btnsdev_ioctl,
+};
+
+static struct miscdevice btnsdev = {
+        .minor = BTNSDEV_MINOR,
+        .name = "btns",
+        .fops = &btnsdev_fops,
+};
+
+
+static int 
+btns_probe(struct platform_device *pdev)
+{
+        struct btns_platform_data *btns_data = pdev->dev.platform_data;
+        int ret, i;
+	
+	dprintk("%s\n", __FUNCTION__);
+	printk(KERN_NOTICE "MV Buttons Driver Load\n");
+
+        for (i = 0; i < btns_data->btns_num; i++) {
+		ret = btn_gpp_init(btns_data->btns_data_arr[i].gpp_id, btns_data->btns_data_arr[i].default_gpp_val, 
+					btns_data->btns_data_arr[i].btn_op, btns_data->btns_data_arr[i].btn_name);
+
+		if (ret != 0) {
+			return ret;
+		}
+        }
+
+        return 0;
+}
+
+
+static struct platform_driver btns_driver = {
+	.probe          = btns_probe,
+	.driver  = {
+        	.name		= MV_BTNS_NAME,
+	},
+};
+
+
+static int __init
+btnsdev_init(void)
+{
+	int rc;
+
+	dprintk("%s\n", __FUNCTION__);
+
+	/* Initialize Wait Q*/
+	init_waitqueue_head(&btns_waitq);
+	
+	/* Register btns device */
+	if (misc_register(&btnsdev)) 
+        {
+            printk(KERN_ERR "btnsdev: registration of /dev/btnsdev failed\n");
+            return -1;
+        }
+
+	/* Register platform driver*/
+	rc = platform_driver_register(&btns_driver);
+	if (rc) {
+		printk(KERN_ERR "btnsdev: registration of platform driver failed\n");
+		return rc;
+	}
+
+        return 0;
+}
+
+static void __exit
+btnsdev_exit(void)
+{
+	dprintk("%s() should never be called.\n", __FUNCTION__);
+}
+
+module_init(btnsdev_init);
+module_exit(btnsdev_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Ronen Shitrit & Haim Boot");
+MODULE_DESCRIPTION("PH: Buttons press handling.");
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_btns/btns_driver.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_btns/btns_driver.h
new file mode 100644
index 0000000..31876cf
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_btns/btns_driver.h
@@ -0,0 +1,60 @@
+/*******************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef _BTNS_DRIVER_H_
+#define _BTNS_DRIVER_H_
+
+typedef enum
+{
+	BTN_NO_OP,
+	BTN_PUSH,
+	BTN_RELEASE,
+	BTN_CHANGE /* Both Push & Release will be monitored */
+} BTN_OP;
+
+
+typedef struct {
+        unsigned int btn_id;
+        unsigned int btn_push_cntr;
+        unsigned int btn_release_cntr;
+} BTN, *BTN_PTR;
+
+
+typedef struct {
+	unsigned int btns_number;
+        BTN* btns;
+} BTNS_STS, *BTNS_STS_PTR;
+
+#define MV_BTNS_NAME       "BTNS"
+
+
+struct btn_data {
+        unsigned int    gpp_id;
+        unsigned int    default_gpp_val;
+        BTN_OP          btn_op;
+        char            *btn_name;
+};
+
+
+/*
+ *  done against open of /dev/gpp, to get a cloned descriptor.
+ */
+#define CIOCWAIT_P       _IOWR('c', 150, BTNS_STS)
+#define CIOCNOWAIT_P     _IOWR('c', 151, BTNS_STS)
+
+
+#endif /* _BTNS_DRIVER_H_ */
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Kconfig
new file mode 100644
index 0000000..749d3b0
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Kconfig
@@ -0,0 +1,51 @@
+menu "Cesa options"
+	depends on MV_INCLUDE_CESA
+
+config  MV_CESA
+	bool "Support for Marvell Cryptographic Engine and Security Acceleration"
+	default y
+
+config  MV_CESA_TOOL
+	tristate "Support for Marvell CESA Tool"
+	depends on MV_CESA
+	---help---
+
+config MV_CESA_CHANNELS
+	int "Total CESA HW channels supported"
+        depends on MV_CESA
+	range 1 2
+        default 1
+         ---help---
+	Select the number of CESA channels to be used for crypto operations acceleration.
+
+config MV_CESA_CHAIN_MODE
+	bool "Support CESA chain-mode"
+        depends on MV_CESA
+        default n
+         ---help---
+        Choosing this option will enable crypto engine(CESA) chain mode support.
+	Warning: currently this feature is supported only by NFP-IPSec.
+
+choice 
+        prompt "CESA Mode"
+        depends on MV_CESA
+        default MV_CESA_OCF
+
+config	MV_CESA_OCF
+	tristate "Support for Marvell CESA OCF driver"
+	depends on OCF_OCF
+	---help---
+	  Choosing this option will enable you to use the Marvell Cryptographic Engine and
+	  Security Accelerator, under the OCF package.
+
+config  MV_CESA_TEST
+	bool "Support for Marvell CESA test driver"
+	depends on MV_CESA_TOOL 
+	---help---
+	  Choosing this option will enable you to use the Marvell Cryptographic Engine and
+	  Security Accelerator, with the mv_cesa_tool in test mode.
+endchoice
+
+endmenu
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Makefile
new file mode 100644
index 0000000..efc58b6
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Makefile
@@ -0,0 +1,18 @@
+#
+# Makefile for the Marvell CESA driver
+#
+ifeq ($(CONFIG_PLAT_ARMADA),y)
+	#include $(srctree)/$(MACHINE)/config/mvRules.mk
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+
+endif
+
+ifeq ($(CONFIG_MV_CESA_OCF),y)
+EXTRA_CFLAGS    += -I$(srctree)/crypto/ocf
+endif
+
+obj-$(CONFIG_MV_INCLUDE_CESA) += cesa_if.o
+obj-$(CONFIG_MV_CESA_TOOL) += cesa_dev.o
+obj-$(CONFIG_MV_CESA_TEST) += cesa_test.o
+obj-$(CONFIG_MV_CESA_OCF)  += cesa_ocf_drv.o
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_dev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_dev.c
new file mode 100644
index 0000000..81502f8
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_dev.c
@@ -0,0 +1,276 @@
+#ifdef CONFIG_PLAT_ARMADA
+#include <generated/autoconf.h>
+#else
+#include <linux/autoconf.h>
+#endif
+#include <linux/types.h>
+#include <linux/time.h>
+#include <linux/delay.h>
+#include <linux/list.h>
+#include <linux/init.h>
+#include <linux/sched.h>
+#include <linux/unistd.h>
+#include <linux/module.h>
+#include <linux/wait.h>
+#include <linux/slab.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/miscdevice.h>
+#include <linux/version.h>
+#include <asm/uaccess.h>
+
+#include "cesa_dev.h"
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)
+#include <linux/syscalls.h>
+#endif
+#include "mvOs.h"
+#include "mvCommon.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "cesa/mvCesa.h" 
+#include "mvSysCesaApi.h"
+
+
+static int debug = 1;
+module_param(debug, int, 0);
+MODULE_PARM_DESC(debug,
+	   "Enable debug");
+
+#ifdef CONFIG_MV_CESA_TEST
+
+static int buf_size = 20000;
+/*MODULE_PARM(buf_size, "i");*/
+module_param(buf_size,int,0644);
+MODULE_PARM_DESC(buf_size, "Size of each data buffer");
+
+static int buf_num = 1;
+/*MODULE_PARM(buf_num, "i");*/
+module_param(buf_num,int,0644);
+
+MODULE_PARM_DESC(buf_num, "Number of data buffers for each request");
+
+extern void cesaTestStart(int bufNum, int bufSize);
+extern void cesaTestStop(void);
+extern void cesaTest(int iter, int reqSize, int checkMode);
+extern void combiTest(int iter, int reqSize, int checkMode);
+extern void cesaOneTest(int testIdx, int caseIdx, int iter, int reqSize, int checkMode);
+extern void multiSizeTest(int idx, int checkMode, int iter, char* inputData);
+extern void aesTest(int iter, int reqSize, int checkMode);
+extern void desTest(int iter, int reqSize, int checkMode);
+extern void tripleDesTest(int iter, int reqSize, int checkMode);
+extern void mdTest(int iter, int reqSize, int checkMode);
+extern void sha1Test(int iter, int reqSize, int checkMode);
+extern void sha2Test(int iter, int reqSize, int checkMode);
+
+int run_cesa_test(CESA_TEST *cesa_test)
+{
+	switch(cesa_test->test){
+		case(MULTI):
+			combiTest(cesa_test->iter, cesa_test->req_size, cesa_test->checkmode);
+			break;
+		case(SIZE):
+                        multiSizeTest(cesa_test->req_size, cesa_test->iter, cesa_test->checkmode, NULL);
+			break;
+		case(SINGLE):
+			cesaOneTest(cesa_test->session_id, cesa_test->data_id, cesa_test->iter, 
+					cesa_test->req_size, cesa_test->checkmode);
+			break;
+		case(AES):
+			aesTest(cesa_test->iter, cesa_test->req_size, cesa_test->checkmode);		
+			break;
+		case(DES):
+			desTest(cesa_test->iter, cesa_test->req_size, cesa_test->checkmode);
+			break;
+		case(TRI_DES):
+			tripleDesTest(cesa_test->iter, cesa_test->req_size, cesa_test->checkmode);
+			break;
+		case(MD5):
+                        mdTest(cesa_test->iter, cesa_test->req_size, cesa_test->checkmode);
+                        break;
+		case(SHA1):
+                        sha1Test(cesa_test->iter, cesa_test->req_size, cesa_test->checkmode);
+                        break;
+		case(SHA2):
+                        sha2Test(cesa_test->iter, cesa_test->req_size, cesa_test->checkmode);
+                        break;
+
+		default:
+			dprintk("%s(unknown test 0x%x)\n", __FUNCTION__, cesa_test->test);
+			return -EINVAL;
+	}
+	return 0;
+}
+#endif /* CONFIG_MV_CESA_TEST */
+
+extern void    		mvCesaDebugSAD(int mode);
+extern void    		mvCesaDebugSA(short sid, int mode);
+extern void    		mvCesaDebugQueue(int mode);
+extern void    		mvCesaDebugStatus(void);
+extern void    		mvCesaDebugSram(int mode);
+extern void    		cesaTestPrintReq(int req, int offset, int size);
+extern void	   	    cesaTestPrintSession(int idx);
+extern void	   	    cesaTestPrintStatus(void);
+
+
+int run_cesa_debug(CESA_DEBUG *cesa_debug)
+{
+	int error = 0;
+	switch(cesa_debug->debug){
+		case(STATUS):
+			mvCesaDebugStatus();
+			break;
+		case(QUEUE):
+			mvCesaDebugQueue(cesa_debug->mode);
+			break;
+		case(SA):
+			mvCesaDebugSA(cesa_debug->index, cesa_debug->mode);
+			break;
+		case(SRAM):
+			mvCesaDebugSram(cesa_debug->mode);
+			break;
+		case(SAD):
+			mvCesaDebugSAD(cesa_debug->mode);
+			break;
+
+#ifdef CONFIG_MV_CESA_TEST
+		case(TST_REQ):
+			cesaTestPrintReq(cesa_debug->index, 0, cesa_debug->size);
+			break;
+		case(TST_SES):
+			cesaTestPrintSession(cesa_debug->index);
+			break;
+        case(TST_STATS):
+            cesaTestPrintStatus();
+            break;
+#endif /* CONFIG_MV_CESA_TEST */
+
+		default:
+			dprintk("%s(unknown debug 0x%x)\n", __FUNCTION__, cesa_debug->debug);
+			error = EINVAL;
+			break;
+
+	}
+
+	return(-error);
+}
+
+
+static int
+cesadev_ioctl(
+	struct inode *inode,
+	struct file *filp,
+	unsigned int cmd,
+	unsigned long arg)
+{	
+	CESA_DEBUG cesa_debug;
+	u32 error = 0;
+
+	dprintk("%s: cmd=0x%x, CIOCDEBUG=0x%x, CIOCTEST=0x%x\n", 
+                __FUNCTION__, cmd, CIOCDEBUG, CIOCTEST);
+
+	switch (cmd) {
+	case CIOCDEBUG:
+		if(copy_from_user(&cesa_debug, (void*)arg, sizeof(CESA_DEBUG)))
+				error = -EFAULT;
+		dprintk("%s(CIOCDEBUG): debug %d index %d mode %d size %d\n", 
+			__FUNCTION__, cesa_debug.debug, cesa_debug.index, cesa_debug.mode, cesa_debug.size);
+		error = run_cesa_debug(&cesa_debug);
+		break;
+
+#ifdef CONFIG_MV_CESA_TEST
+    case CIOCTEST:
+		{
+		CESA_TEST cesa_test;
+
+		if(copy_from_user(&cesa_test, (void*)arg, sizeof(CESA_TEST)))
+			error = -EFAULT;
+		dprintk("%s(CIOCTEST): test %d iter %d req_size %d checkmode %d sess_id %d data_id %d \n", 
+			__FUNCTION__, cesa_test.test, cesa_test.iter, cesa_test.req_size, cesa_test.checkmode,
+			cesa_test.session_id, cesa_test.data_id );
+		error = run_cesa_test(&cesa_test);
+		}
+		break;
+#endif /* CONFIG_MV_CESA_TEST */
+
+	default:
+		dprintk("%s (unknown ioctl 0x%x)\n", __FUNCTION__, cmd);
+		error = EINVAL;
+		break;
+	}
+	return(-error);
+}
+
+
+static int
+cesadev_open(struct inode *inode, struct file *filp)
+{
+	dprintk("%s()\n", __FUNCTION__);
+	return(0);
+}
+
+static int
+cesadev_release(struct inode *inode, struct file *filp)
+{
+	dprintk("%s()\n", __FUNCTION__);
+	return(0);
+}
+
+
+static struct file_operations cesadev_fops = {
+	.owner = THIS_MODULE,
+	.open = cesadev_open,
+	.release = cesadev_release,
+	.unlocked_ioctl = cesadev_ioctl,
+};
+
+static struct miscdevice cesadev = {
+	.minor = CESADEV_MINOR,
+	.name = "cesa",
+	.fops = &cesadev_fops,
+};
+
+static int __init
+cesadev_init(void)
+{
+	int rc;
+
+	if (mvCtrlPwrClckGet(CESA_UNIT_ID, 0) == MV_FALSE)
+		return 0;
+
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+	if (MV_FALSE == mvSocUnitIsMappedToThisCpu(CESA))
+	{
+		dprintk("CESA is not mapped to this CPU\n");
+		return -ENODEV;
+	}		
+#endif
+
+#ifdef CONFIG_MV_CESA_TEST
+    cesaTestStart(buf_num, buf_size);
+#endif
+
+	dprintk("%s(%p)\n", __FUNCTION__, cesadev_init);
+	rc = misc_register(&cesadev);
+	if (rc) {
+		printk(KERN_ERR "cesadev: registration of /dev/cesadev failed\n");
+		return(rc);
+	}
+	return(0);
+}
+
+static void __exit
+cesadev_exit(void)
+{
+#ifdef CONFIG_MV_CESA_TEST
+	cesaTestStop();
+#endif
+	dprintk("%s()\n", __FUNCTION__);
+	misc_deregister(&cesadev);
+}
+
+module_init(cesadev_init);
+module_exit(cesadev_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Ronen Shitrit");
+MODULE_DESCRIPTION("Cesadev (user interface to CESA)");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_dev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_dev.h
new file mode 100644
index 0000000..c426623
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_dev.h
@@ -0,0 +1,63 @@
+#ifndef _CESA_DEV_H_
+#define _CESA_DEV_H_
+
+/*
+ * common debug for all
+ */
+#if 1
+#define dprintk(a...)	if (debug) { printk(a); } else
+#else
+#define dprintk(a...)
+#endif
+
+typedef enum {
+	MULTI = 0,
+	SIZE,
+	SINGLE,
+	AES,
+	DES,
+	TRI_DES,
+	MD5,
+	SHA1,
+	SHA2,
+	MAX_CESA_TEST_TYPE	
+} CESA_TEST_TYPE;
+
+typedef struct {
+	CESA_TEST_TYPE 		test;
+	unsigned int	  	iter;		/* How many interation to run */
+	unsigned int	  	req_size;	/* request buffer size */
+	unsigned int		checkmode;	/* check mode: verify or not */
+	unsigned int		session_id; 	/* relevant only for single test */
+	unsigned int		data_id;   	/* relevant only for single test */
+} CESA_TEST;
+
+typedef enum {
+	STATUS = 0,
+	CHAN,
+	QUEUE,
+	SA,
+	CACHE_IDX,
+	SRAM,
+	SAD,
+	TST_REQ,
+	TST_SES,
+    TST_STATS,
+	MAX_CESA_DEBUG_TYPE
+} CESA_DEBUG_TYPE;
+
+typedef struct {
+	CESA_DEBUG_TYPE	debug;
+	unsigned int	index; /* general index */
+	unsigned int	mode;  /* verbos mode */
+	unsigned int 	size;  /* size of buffer */
+} CESA_DEBUG;
+
+
+/*
+ * done against open of /dev/cesa, to get a cloned descriptor.
+ */
+#define	CIOCDEBUG	_IOWR('c', 150, CESA_DEBUG)
+#define	CIOCTEST	_IOWR('c', 151, CESA_TEST)
+
+#endif /* _CESA_DEV_H_ */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_if.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_if.c
new file mode 100644
index 0000000..330c113
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_if.c
@@ -0,0 +1,392 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "cesa_if.h"
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/spinlock_types.h>
+
+
+
+
+
+#define MV_CESA_IF_MAX_WEIGHT	0xFFFFFFFF
+
+/* Globals */
+static MV_CESA_RESULT **pResQ;
+static MV_CESA_RESULT *resQ;
+static MV_CESA_RESULT *pEmptyResult;
+static MV_CESA_FLOW_TYPE flowType[MV_CESA_CHANNELS];
+static MV_U32 chanWeight[MV_CESA_CHANNELS];
+static MV_STATUS isReady[MV_CESA_CHANNELS];
+static MV_CESA_POLICY cesaPolicy;
+static MV_U8 splitChanId;
+static MV_U32 resQueueDepth;
+static MV_U32 reqId;
+static MV_U32 resId;
+static spinlock_t chanLock[MV_CESA_CHANNELS];
+//static spinlock_t cesaLock = SPIN_LOCK_UNLOCKED;
+//static spinlock_t cesaIsrLock = SPIN_LOCK_UNLOCKED;
+
+
+//static DEFINE_SPINLOCK (chanLock[MV_CESA_CHANNELS]);
+static DEFINE_SPINLOCK (cesaLock);
+static DEFINE_SPINLOCK (cesaIsrLock);
+
+MV_STATUS mvCesaIfInit(int numOfSession, int queueDepth, void *osHandle, MV_CESA_HAL_DATA *halData)
+{
+	MV_U8 chan = 0;
+
+	/* Init parameters */
+	reqId = 0;
+	resId = 0;
+	resQueueDepth = queueDepth;
+	cesaPolicy = CESA_NULL_POLICY;
+
+	/* Allocate reordered queue for completed results */
+	resQ = (MV_CESA_RESULT *)mvOsMalloc(resQueueDepth * sizeof(MV_CESA_RESULT));
+	if (resQ == NULL) {
+		mvOsPrintf("%s: Error, resQ malloc failed\n", __func__);
+		return MV_ERROR;
+	}
+	pEmptyResult = &resQ[0];
+
+	/* Allocate result pointers queue */
+	pResQ = (MV_CESA_RESULT **)mvOsMalloc(resQueueDepth * sizeof(MV_CESA_RESULT*));
+	if (pResQ == NULL) {
+		mvOsPrintf("%s: Error, pResQ malloc failed\n", __func__);
+		return MV_ERROR;
+	}
+
+	/* Init shared spinlocks */
+	spin_lock_init(&cesaLock);
+	spin_lock_init(&cesaIsrLock);
+
+	/* Per channel init */
+	for (chan = 0; chan < MV_CESA_CHANNELS; chan++) {
+		spin_lock_init(&chanLock[chan]);
+		chanWeight[chan] = 0;
+		flowType[chan] = 0;
+		isReady[chan] = MV_TRUE;
+	}
+
+	/* Clear global resources */
+	memset(pResQ, 0, (resQueueDepth * sizeof(MV_CESA_RESULT *)));
+	memset(resQ, 0, (resQueueDepth * sizeof(MV_CESA_RESULT)));
+
+	return mvCesaHalInit(numOfSession, queueDepth, osHandle, halData);
+}
+
+MV_STATUS mvCesaIfAction(MV_CESA_COMMAND *pCmd)
+{
+	MV_U8 chan = 0, chanId = 0xff;
+	MV_U32 min = MV_CESA_IF_MAX_WEIGHT; /* max possible value */
+	MV_STATUS status;
+	MV_ULONG flags = 0;
+
+	/* Handle request according to selected policy */
+	switch (cesaPolicy) {
+	case CESA_WEIGHTED_CHAN_POLICY:
+	case CESA_NULL_POLICY:
+		for (chan = 0; chan < MV_CESA_CHANNELS; chan++) {
+			if ((cesaReqResources[chan] > 0) && (chanWeight[chan] < min)) {
+				min = chanWeight[chan];
+				chanId = chan;
+			}
+		}
+
+		/* Any room for the request ? */
+		if (cesaReqResources[chanId] == 0) {
+			spin_unlock_irqrestore(&cesaLock, flags);
+			return MV_NO_RESOURCE;
+		}
+
+		spin_lock_irqsave(&chanLock[chanId], flags);
+		chanWeight[chanId] += pCmd->pSrc->mbufSize;
+		spin_unlock_irqrestore(&chanLock[chanId], flags);
+		break;
+
+	case CESA_FLOW_ASSOC_CHAN_POLICY:
+		for (chan = 0; chan < MV_CESA_CHANNELS; chan++) {
+			if (flowType[chan] == pCmd->flowType) {
+				chanId = chan;
+				break;
+			}	
+		}
+
+		if(chanId == 0xff) {
+			mvOsPrintf("%s: Error, policy was not set correctly\n", __func__);
+			return MV_ERROR;
+		}
+
+		break;
+
+	case CESA_SINGLE_CHAN_POLICY:
+		break;
+
+	default:
+		mvOsPrintf("%s: Error, policy not supported\n", __func__);
+		return MV_ERROR;
+	}
+
+	/* Check if we need to handle split packet */
+	if (pCmd->split != MV_CESA_SPLIT_NONE) {
+		if (pCmd->split == MV_CESA_SPLIT_FIRST) {
+			spin_lock(&cesaLock);
+			splitChanId = chanId;
+			spin_unlock(&cesaLock);
+		} else	/* MV_CESA_SPLIT_SECOND */
+			chanId = splitChanId;
+	}
+
+	/* Update current request id then increament */
+	spin_lock(&cesaLock);
+	pCmd->reqId = reqId;
+	reqId = ((reqId + 1) % resQueueDepth);
+	spin_unlock(&cesaLock);
+
+	/* Inject request to CESA driver */
+	spin_lock_irqsave(&chanLock[chanId], flags);
+	status = mvCesaAction(chanId, pCmd);
+	spin_unlock_irqrestore(&chanLock[chanId], flags);
+
+	/* Check if request handled properly */
+	if ((status != MV_OK) && (status != MV_NO_MORE)) {
+		/* Shouldn't get here */
+		spin_lock(&cesaLock);
+		reqId--;
+		spin_unlock(&cesaLock);
+	}
+
+	return status;
+}
+
+MV_STATUS mvCesaIfReadyGet(MV_U8 chan, MV_CESA_RESULT *pResult)
+{
+	MV_STATUS status;
+	MV_CESA_RESULT *pCurrResult;
+	MV_ULONG flags;
+
+	/* Prevent pushing requests till extracting pending requests is done */
+	spin_lock_irqsave(&chanLock[chan], flags);
+
+	/* Are there any pending requests in CESA driver ? */
+	if (isReady[chan] == MV_FALSE)
+		goto out;
+
+	while (1) {
+
+		spin_lock(&cesaIsrLock);
+		pCurrResult = pEmptyResult;
+		pEmptyResult = ((pEmptyResult != &resQ[resQueueDepth-1]) ? (pEmptyResult + 1) : &resQ[0]);
+		spin_unlock(&cesaIsrLock);
+
+		/* Get next result */
+		status = mvCesaReadyGet(chan, pCurrResult);
+
+		if (status != MV_OK)
+			break;
+
+		/* Handle request according to selected policy */
+		switch (cesaPolicy) {
+		case CESA_WEIGHTED_CHAN_POLICY:
+		case CESA_NULL_POLICY:
+			chanWeight[chan] -= pCurrResult->mbufSize;
+			break;
+
+		case CESA_FLOW_ASSOC_CHAN_POLICY:
+			/* TBD - handle policy */
+			break;
+
+		case CESA_SINGLE_CHAN_POLICY:
+			break;
+
+		default:
+			mvOsPrintf("%s: Error, policy not supported\n", __func__);
+			return MV_ERROR;
+		}
+
+
+		if (pResQ[pCurrResult->reqId] != NULL)
+			mvOsPrintf("%s: Warning, result entry not empty(reqId=%d)\n", __func__, pCurrResult->reqId);
+
+		/* Save current result */
+		spin_lock(&cesaIsrLock);
+		pResQ[pCurrResult->reqId] = pCurrResult;
+		spin_unlock(&cesaIsrLock);
+
+#ifndef MV_CESA_CHAIN_MODE
+		break;
+#endif
+	}
+
+out:
+	spin_lock(&cesaIsrLock);
+
+	if (pResQ[resId] == NULL) {
+		isReady[chan] = MV_TRUE;
+		status = MV_NOT_READY;
+	} else {
+		/* Send results in order */
+		isReady[chan] = MV_FALSE;
+		/* Fill result data */
+		pResult->retCode = pResQ[resId]->retCode;
+		pResult->pReqPrv = pResQ[resId]->pReqPrv;
+		pResult->sessionId = pResQ[resId]->sessionId;
+		pResult->mbufSize = pResQ[resId]->mbufSize;
+		pResult->reqId = pResQ[resId]->reqId;
+		pResQ[resId] = NULL;
+		resId = ((resId + 1) % resQueueDepth);
+		status = MV_OK;
+	}
+
+	spin_unlock(&cesaIsrLock);
+
+	/* Release per channel lock */
+	spin_unlock_irqrestore(&chanLock[chan], flags);
+
+	return status;
+}
+
+MV_STATUS mvCesaIfPolicySet(MV_CESA_POLICY policy, MV_CESA_FLOW_TYPE flow)
+{
+	MV_U8 chan = 0;
+
+	spin_lock(&cesaLock);
+
+	if (cesaPolicy == CESA_NULL_POLICY) {
+		cesaPolicy = policy;
+	} else {
+		/* Check if more than 1 policy was assigned */
+		if (cesaPolicy != policy) {
+			spin_unlock(&cesaLock);
+			mvOsPrintf("%s: Error, can not support multiple policies\n", __func__);
+			return MV_ERROR;
+		}
+	}
+
+	if (policy == CESA_FLOW_ASSOC_CHAN_POLICY) {
+
+		if (flow == CESA_NULL_FLOW_TYPE) {
+			spin_unlock(&cesaLock);
+			mvOsPrintf("%s: Error, bad policy configuration\n", __func__);
+			return MV_ERROR;
+		}
+
+		/* Find next empty entry */
+		for (chan = 0; chan < MV_CESA_CHANNELS; chan++) {
+			if (flowType[chan] == CESA_NULL_FLOW_TYPE)
+				flowType[chan] = flow;
+		}
+
+		if (chan == MV_CESA_CHANNELS) {
+			spin_unlock(&cesaLock);
+			mvOsPrintf("%s: Error, no empty entry is available\n", __func__);
+			return MV_ERROR;
+		}
+
+	}
+
+	spin_unlock(&cesaLock);
+
+	return MV_OK;
+}
+
+MV_STATUS mvCesaIfPolicyGet(MV_CESA_POLICY *pCesaPolicy)
+{
+	*pCesaPolicy = cesaPolicy;
+
+	return MV_OK;
+}
+
+MV_STATUS mvCesaIfTdmaWinInit(MV_U8 chan, MV_UNIT_WIN_INFO *addrWinMap)
+{
+	return mvCesaTdmaWinInit(chan, addrWinMap);
+}
+
+MV_STATUS mvCesaIfFinish(void)
+{
+	/* Free global resources */
+	mvOsFree(pResQ);
+	mvOsFree(resQ);
+
+	return mvCesaFinish();
+}
+
+MV_STATUS mvCesaIfSessionOpen(MV_CESA_OPEN_SESSION *pSession, short *pSid)
+{
+	return mvCesaSessionOpen(pSession, pSid);
+}
+
+MV_STATUS mvCesaIfSessionClose(short sid)
+{
+	return mvCesaSessionClose(sid);
+}
+
+MV_VOID mvCesaIfDebugMbuf(const char *str, MV_CESA_MBUF *pMbuf, int offset, int size)
+{
+	return mvCesaDebugMbuf(str, pMbuf, offset, size);
+}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_if.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_if.h
new file mode 100644
index 0000000..2dd7c0bf4
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_if.h
@@ -0,0 +1,102 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+		notice, this list of conditions and the following disclaimer in the
+		documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+		used to endorse or promote products derived from this software without
+		specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+/*******************************************************************************
+* mvCesa.h - Header File for Cryptographic Engines and Security Accelerator
+*
+* DESCRIPTION:
+*       This header file contains macros typedefs and function declaration for
+*       the Marvell Cryptographic Engines and Security Accelerator.
+*
+*******************************************************************************/
+
+#ifndef __mvCesaIf_h__
+#define __mvCesaIf_h__
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+#include "mvSysCesaConfig.h"
+#include "cesa/mvCesa.h"
+#include "cesa/mvCesaRegs.h"
+
+
+	MV_STATUS mvCesaIfInit(int numOfSession, int queueDepth, void *osHandle, MV_CESA_HAL_DATA *halData);
+	MV_STATUS mvCesaIfTdmaWinInit(MV_U8 chan, MV_UNIT_WIN_INFO *addrWinMap);
+	MV_STATUS mvCesaIfFinish(void);
+	MV_STATUS mvCesaIfSessionOpen(MV_CESA_OPEN_SESSION *pSession, short *pSid);
+	MV_STATUS mvCesaIfSessionClose(short sid);
+	MV_STATUS mvCesaIfAction(MV_CESA_COMMAND *pCmd);
+	MV_STATUS mvCesaIfReadyGet(MV_U8 chan, MV_CESA_RESULT *pResult);
+	MV_STATUS mvCesaIfPolicySet(MV_CESA_POLICY policy, MV_CESA_FLOW_TYPE flow);
+	MV_STATUS mvCesaIfPolicyGet(MV_CESA_POLICY *pCesaPolicy);
+	MV_VOID mvCesaIfDebugMbuf(const char *str, MV_CESA_MBUF *pMbuf, int offset, int size);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* __mvCesaIf_h__ */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_ocf_drv.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_ocf_drv.c
new file mode 100644
index 0000000..91790a0
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_ocf_drv.c
@@ -0,0 +1,1248 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef AUTOCONF_INCLUDED
+#include <linux/config.h>
+#endif
+#include <linux/interrupt.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <linux/slab.h>
+#include <linux/sched.h>
+#include <linux/wait.h>
+#include <linux/crypto.h>
+#include <linux/mm.h>
+#include <linux/skbuff.h>
+#include <linux/random.h>
+#include <asm/scatterlist.h>
+#include <linux/spinlock.h>
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "cesa_if.h" /* moved here before cryptodev.h due to include dependencies */
+#include "mvSysCesaApi.h"
+#include <cryptodev.h>
+#include <uio.h>
+
+#include "mvDebug.h"
+
+#include "cesa/mvMD5.h"
+#include "cesa/mvSHA1.h"
+
+#include "cesa/mvCesaRegs.h"
+#include "cesa/AES/mvAes.h"
+#include "cesa/mvLru.h"
+
+
+#undef RT_DEBUG
+#ifdef RT_DEBUG
+static int debug = 1;
+module_param(debug, int, 1);
+MODULE_PARM_DESC(debug, "Enable debug");
+#undef dprintk
+#define dprintk(a...)	if (debug) { printk(a); } else
+#else
+static int debug = 0;
+#undef dprintk
+#define dprintk(a...)
+#endif
+
+/* interrupt handling */
+#undef CESA_OCF_TASKLET
+
+extern int cesaReqResources[MV_CESA_CHANNELS];
+/* support for spliting action into 2 actions */
+#define CESA_OCF_SPLIT
+
+/* general defines */
+#define CESA_OCF_MAX_SES 	128
+#define CESA_Q_SIZE	 	64
+#define CESA_RESULT_Q_SIZE	1024
+
+/* data structures */
+struct cesa_ocf_data {
+        int                                      cipher_alg;
+        int                                      auth_alg;
+	int					 encrypt_tn_auth;
+#define  auth_tn_decrypt  encrypt_tn_auth
+	int					 ivlen;
+	int 					 digestlen;
+	short					 sid_encrypt;
+	short					 sid_decrypt;
+	/* fragment workaround sessions */
+	short					 frag_wa_encrypt;
+	short					 frag_wa_decrypt;
+	short					 frag_wa_auth;
+};
+
+#define DIGEST_BUF_SIZE	32
+struct cesa_ocf_process {
+	MV_CESA_COMMAND 			cesa_cmd;
+	MV_CESA_MBUF 				cesa_mbuf;	
+	MV_BUF_INFO  				cesa_bufs[MV_CESA_MAX_MBUF_FRAGS];
+	char					digest[DIGEST_BUF_SIZE];
+	int					digest_len;
+	struct cryptop 				*crp;
+	int 					need_cb;
+	int					valid;
+};
+
+/* global variables */
+static int32_t			cesa_ocf_id 		= -1;
+static struct cesa_ocf_data 	**cesa_ocf_sessions = NULL;
+static u_int32_t		cesa_ocf_sesnum = 0;
+static DEFINE_SPINLOCK(cesa_lock);
+static atomic_t result_count;
+static struct cesa_ocf_process *result_Q[CESA_RESULT_Q_SIZE];
+static unsigned int next_result;
+static unsigned int result_done;
+static unsigned char chan_id[MV_CESA_CHANNELS];
+
+/* static APIs */
+static int 		cesa_ocf_process	(device_t, struct cryptop *, int);
+static int 		cesa_ocf_newsession	(device_t, u_int32_t *, struct cryptoini *);
+static int 		cesa_ocf_freesession	(device_t, u_int64_t);
+static inline void 	cesa_callback		(unsigned long);
+static irqreturn_t	cesa_interrupt_handler	(int, void *);
+static int		cesa_ocf_init		(void);
+static void		cesa_ocf_exit		(void);
+#ifdef CESA_OCF_TASKLET
+static struct tasklet_struct cesa_ocf_tasklet;
+#endif
+
+static struct timeval          tt_start;
+static struct timeval          tt_end;
+static struct cesa_ocf_process *cesa_ocf_pool = NULL;
+static int proc_empty;
+/*
+ * dummy device structure
+ */
+static struct {
+	softc_device_decl	sc_dev;
+} mv_cesa_dev;
+
+static device_method_t mv_cesa_methods = {
+	/* crypto device methods */
+	DEVMETHOD(cryptodev_newsession,	cesa_ocf_newsession),
+	DEVMETHOD(cryptodev_freesession,cesa_ocf_freesession),
+	DEVMETHOD(cryptodev_process,	cesa_ocf_process),
+	DEVMETHOD(cryptodev_kprocess,	NULL),
+};
+
+unsigned int
+get_usec(unsigned int start)
+{
+	if(start) {
+		do_gettimeofday (&tt_start);
+		return 0;
+	}
+	else {
+        	do_gettimeofday (&tt_end);
+        	tt_end.tv_sec -= tt_start.tv_sec;
+        	tt_end.tv_usec -= tt_start.tv_usec;
+        	if (tt_end.tv_usec < 0) {
+                	tt_end.tv_usec += 1000 * 1000;
+                	tt_end.tv_sec -= 1;
+        	}
+	}
+	printk("time taken is  %d\n", (unsigned int)(tt_end.tv_usec + tt_end.tv_sec * 1000000));
+	return (tt_end.tv_usec + tt_end.tv_sec * 1000000);
+}
+
+static void
+skb_copy_bits_back(struct sk_buff *skb, int offset, caddr_t cp, int len)
+{
+        int i;
+        if (offset < skb_headlen(skb)) {
+                memcpy(skb->data + offset, cp, min_t(int, skb_headlen(skb), len));
+                len -= skb_headlen(skb);
+                cp += skb_headlen(skb);
+        }
+        offset -= skb_headlen(skb);
+        for (i = 0; len > 0 && i < skb_shinfo(skb)->nr_frags; i++) {
+                if (offset < skb_shinfo(skb)->frags[i].size) {
+                        memcpy(page_address(skb_shinfo(skb)->frags[i].page) +
+                                        skb_shinfo(skb)->frags[i].page_offset,
+                                        cp, min_t(int, skb_shinfo(skb)->frags[i].size, len));
+                        len -= skb_shinfo(skb)->frags[i].size;
+                        cp += skb_shinfo(skb)->frags[i].size;
+                }
+                offset -= skb_shinfo(skb)->frags[i].size;
+        }
+}
+
+
+#ifdef RT_DEBUG
+/* 
+ * check that the crp action match the current session
+ */
+static int 
+ocf_check_action(struct cryptop *crp, struct cesa_ocf_data *cesa_ocf_cur_ses) {
+	int count = 0;
+	int encrypt = 0, decrypt = 0, auth = 0;
+	struct cryptodesc *crd;
+
+        /* Go through crypto descriptors, processing as we go */
+        for (crd = crp->crp_desc; crd; crd = crd->crd_next, count++) {
+		if(count > 2) {
+			printk("%s,%d: session mode is not supported.\n", __FILE__, __LINE__);
+			return 1;
+		}
+		
+		/* Encryption /Decryption */
+		if(crd->crd_alg == cesa_ocf_cur_ses->cipher_alg) {
+			/* check that the action is compatible with session */
+			if(encrypt || decrypt) {
+				printk("%s,%d: session mode is not supported.\n", __FILE__, __LINE__);
+				return 1;
+			}
+
+			if(crd->crd_flags & CRD_F_ENCRYPT) { /* encrypt */
+				if( (count == 2) && (cesa_ocf_cur_ses->encrypt_tn_auth) ) {
+					printk("%s,%d: sequence isn't supported by this session.\n", __FILE__, __LINE__);
+					return 1;
+				}
+				encrypt++;
+			}
+			else { 					/* decrypt */
+				if( (count == 2) && !(cesa_ocf_cur_ses->auth_tn_decrypt) ) {
+					printk("%s,%d: sequence isn't supported by this session.\n", __FILE__, __LINE__);
+					return 1;
+				}
+				decrypt++;
+			}
+
+		}
+		/* Authentication */
+		else if(crd->crd_alg == cesa_ocf_cur_ses->auth_alg) {
+			/* check that the action is compatible with session */
+			if(auth) {
+				printk("%s,%d: session mode is not supported.\n", __FILE__, __LINE__);
+				return 1;
+			}
+			if( (count == 2) && (decrypt) && (cesa_ocf_cur_ses->auth_tn_decrypt)) {
+				printk("%s,%d: sequence isn't supported by this session.\n", __FILE__, __LINE__);
+				return 1;
+			}
+			if( (count == 2) && (encrypt) && !(cesa_ocf_cur_ses->encrypt_tn_auth)) {
+				printk("%s,%d: sequence isn't supported by this session.\n", __FILE__, __LINE__);
+				return 1;
+			}
+			auth++;
+		} 
+		else {
+			printk("%s,%d: Alg isn't supported by this session.\n", __FILE__, __LINE__);
+			return 1;
+		}
+	}
+	return 0;
+
+}
+#endif
+
+static inline struct cesa_ocf_process* cesa_ocf_alloc(void)
+{
+	int proc = 0;
+	unsigned long flags;
+	
+	spin_lock_irqsave(&cesa_lock, flags);
+
+	if(cesa_ocf_pool[proc_empty].valid != 0) {
+		spin_unlock_irqrestore(&cesa_lock, flags);
+		printk("%s,%d: Error, entry is overrided in cesa_ocf_pool(%d)\n", __FILE__, __LINE__,proc_empty);
+		return NULL;
+	}
+
+	cesa_ocf_pool[proc_empty].valid = 1;
+	proc = proc_empty;
+	proc_empty = ((proc_empty+1) % (CESA_Q_SIZE * MV_CESA_CHANNELS * 2));
+	spin_unlock_irqrestore(&cesa_lock, flags);
+
+	return &cesa_ocf_pool[proc];
+}
+
+static inline void cesa_ocf_free(struct cesa_ocf_process *ocf_process_p)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&cesa_lock, flags);
+	ocf_process_p->valid = 0;
+	spin_unlock_irqrestore(&cesa_lock, flags);
+}
+
+
+/*
+ * Process a request.
+ */
+static int 
+cesa_ocf_process(device_t dev, struct cryptop *crp, int hint)
+{
+	struct cesa_ocf_process *cesa_ocf_cmd = NULL;
+	struct cesa_ocf_process *cesa_ocf_cmd_wa = NULL;
+	MV_CESA_COMMAND	*cesa_cmd;
+	struct cryptodesc *crd;
+	struct cesa_ocf_data *cesa_ocf_cur_ses;
+	int sid = 0, temp_len = 0, i;
+	int encrypt = 0, decrypt = 0, auth = 0;
+	int  status, cesa_resources = 0;
+	struct sk_buff *skb = NULL;
+	struct uio *uiop = NULL;
+	unsigned char *ivp;
+	MV_BUF_INFO *p_buf_info;	
+	MV_CESA_MBUF *p_mbuf_info;
+	unsigned long flags;
+	unsigned char chan = 0;
+	
+
+        dprintk("%s()\n", __func__);
+
+	for(chan = 0; chan < MV_CESA_CHANNELS; chan++)
+		cesa_resources += cesaReqResources[chan];
+
+		if (cesa_resources == 0) {
+                	dprintk("%s,%d: ERESTART\n", __FILE__, __LINE__);
+                	return ERESTART;
+		}
+
+#ifdef RT_DEBUG
+        /* Sanity check */
+        if (crp == NULL) {
+                printk("%s,%d: EINVAL\n", __FILE__, __LINE__);
+                return EINVAL;
+        }
+
+        if (crp->crp_desc == NULL || crp->crp_buf == NULL ) {
+                printk("%s,%d: EINVAL\n", __FILE__, __LINE__);
+                crp->crp_etype = EINVAL;
+                return EINVAL;
+        }
+
+        sid = crp->crp_sid & 0xffffffff;
+        if ((sid >= cesa_ocf_sesnum) || (cesa_ocf_sessions[sid] == NULL)) {
+                crp->crp_etype = ENOENT;
+                printk("%s,%d: ENOENT session %d \n", __FILE__, __LINE__, sid);
+                return EINVAL;
+        }
+#endif
+
+	sid = crp->crp_sid & 0xffffffff;
+	crp->crp_etype = 0;
+	cesa_ocf_cur_ses = cesa_ocf_sessions[sid];
+
+#ifdef RT_DEBUG
+	if(ocf_check_action(crp, cesa_ocf_cur_ses)){
+		goto p_error;
+	}
+#endif
+
+	/* Allocate new cesa process from local pool */	
+	cesa_ocf_cmd = cesa_ocf_alloc();
+	if (cesa_ocf_cmd == NULL) {
+            	printk("%s,%d: ENOBUFS \n", __FILE__, __LINE__);
+            	goto p_error;
+      	}
+
+	/* init cesa_process */
+	cesa_ocf_cmd->crp = crp;
+	/* always call callback */
+	cesa_ocf_cmd->need_cb = 1;
+
+	/* init cesa_cmd for usage of the HALs */
+	cesa_cmd = &cesa_ocf_cmd->cesa_cmd;
+	cesa_cmd->pReqPrv = (void *)cesa_ocf_cmd;
+	cesa_cmd->sessionId = cesa_ocf_cur_ses->sid_encrypt; /* defualt use encrypt */
+
+	/* prepare src buffer 	*/
+	/* we send the entire buffer to the HAL, even if only part of it should be encrypt/auth.  */
+	/* if not using seesions for both encrypt and auth, then it will be wiser to to copy only */
+	/* from skip to crd_len. 								  */
+	p_buf_info = cesa_ocf_cmd->cesa_bufs;	
+	p_mbuf_info = &cesa_ocf_cmd->cesa_mbuf;
+
+	p_buf_info += 2; /* save 2 first buffers for IV and digest - 
+			    we won't append them to the end since, they 
+			    might be places in an unaligned addresses. */
+	
+	p_mbuf_info->pFrags = p_buf_info;
+	temp_len = 0;
+
+	/* handle SKB */
+	if (crp->crp_flags & CRYPTO_F_SKBUF) {
+		
+		dprintk("%s,%d: handle SKB.\n", __FILE__, __LINE__);
+		skb = (struct sk_buff *) crp->crp_buf;
+
+                if (skb_shinfo(skb)->nr_frags >= (MV_CESA_MAX_MBUF_FRAGS - 1)) {
+                        printk("%s,%d: %d nr_frags > MV_CESA_MAX_MBUF_FRAGS", __FILE__, __LINE__, skb_shinfo(skb)->nr_frags);
+                        goto p_error;
+                }
+
+		p_mbuf_info->mbufSize = skb->len;
+		temp_len = skb->len;
+        	/* first skb fragment */
+        	p_buf_info->bufSize = skb_headlen(skb);
+        	p_buf_info->bufVirtPtr = skb->data;
+		p_buf_info++;
+
+        	/* now handle all other skb fragments */
+        	for ( i = 0; i < skb_shinfo(skb)->nr_frags; i++ ) {
+            		skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
+            		p_buf_info->bufSize = frag->size;
+            		p_buf_info->bufVirtPtr = page_address(frag->page) + frag->page_offset;
+            		p_buf_info++;
+        	}
+        	p_mbuf_info->numFrags = skb_shinfo(skb)->nr_frags + 1;
+	}
+	/* handle UIO */
+	else if(crp->crp_flags & CRYPTO_F_IOV) {
+	
+		dprintk("%s,%d: handle UIO.\n", __FILE__, __LINE__);
+		uiop = (struct uio *) crp->crp_buf;
+
+                if (uiop->uio_iovcnt > (MV_CESA_MAX_MBUF_FRAGS - 1)) {
+                        printk("%s,%d: %d uio_iovcnt > MV_CESA_MAX_MBUF_FRAGS \n", __FILE__, __LINE__, uiop->uio_iovcnt);
+                        goto p_error;
+                }
+
+		p_mbuf_info->mbufSize = crp->crp_ilen;
+		p_mbuf_info->numFrags = uiop->uio_iovcnt;
+		for(i = 0; i < uiop->uio_iovcnt; i++) {
+			p_buf_info->bufVirtPtr = uiop->uio_iov[i].iov_base;
+			p_buf_info->bufSize = uiop->uio_iov[i].iov_len;
+			temp_len += p_buf_info->bufSize;
+			dprintk("%s,%d: buf %x-> addr %x, size %x \n"
+				, __FILE__, __LINE__, i, (unsigned int)p_buf_info->bufVirtPtr, p_buf_info->bufSize);
+			p_buf_info++;			
+		}
+
+	}
+	/* handle CONTIG */
+	else {
+		dprintk("%s,%d: handle CONTIG.\n", __FILE__, __LINE__); 
+		p_mbuf_info->numFrags = 1;
+		p_mbuf_info->mbufSize = crp->crp_ilen;
+		p_buf_info->bufVirtPtr = crp->crp_buf;
+		p_buf_info->bufSize = crp->crp_ilen;
+		temp_len = crp->crp_ilen;
+		p_buf_info++;
+	}
+	
+	/* Support up to 64K why? cause! */
+	if(crp->crp_ilen > 64*1024) {
+		printk("%s,%d: buf too big %x \n", __FILE__, __LINE__, crp->crp_ilen);
+		goto p_error;
+	}
+
+	if( temp_len != crp->crp_ilen ) {
+		printk("%s,%d: warning size don't match.(%x %x) \n", __FILE__, __LINE__, temp_len, crp->crp_ilen);
+	}	
+
+	cesa_cmd->pSrc = p_mbuf_info;
+	cesa_cmd->pDst = p_mbuf_info;
+	
+	/* restore p_buf_info to point to first available buf */
+	p_buf_info = cesa_ocf_cmd->cesa_bufs;	
+	p_buf_info += 1; 
+
+
+        /* Go through crypto descriptors, processing as we go */
+        for (crd = crp->crp_desc; crd; crd = crd->crd_next) {
+		
+		/* Encryption /Decryption */
+		if(crd->crd_alg == cesa_ocf_cur_ses->cipher_alg) {
+
+			dprintk("%s,%d: cipher", __FILE__, __LINE__);
+
+			cesa_cmd->cryptoOffset = crd->crd_skip;
+    	              	cesa_cmd->cryptoLength = crd->crd_len;
+
+			if(crd->crd_flags & CRD_F_ENCRYPT) { /* encrypt */
+				dprintk(" encrypt \n");
+				encrypt++;
+
+				/* handle IV */
+				if (crd->crd_flags & CRD_F_IV_EXPLICIT) {  /* IV from USER */
+					dprintk("%s,%d: IV from USER (offset %x) \n", __FILE__, __LINE__, crd->crd_inject);
+					cesa_cmd->ivFromUser = 1;
+					ivp = crd->crd_iv;
+
+                                	/*
+                                 	 * do we have to copy the IV back to the buffer ?
+                                 	 */
+                                	if ((crd->crd_flags & CRD_F_IV_PRESENT) == 0) {
+						dprintk("%s,%d: copy the IV back to the buffer\n", __FILE__, __LINE__);
+						cesa_cmd->ivOffset = crd->crd_inject;
+                                        	if (crp->crp_flags & CRYPTO_F_SKBUF)
+                                                	skb_copy_bits_back(skb, crd->crd_inject, ivp, cesa_ocf_cur_ses->ivlen);
+                                        	else if (crp->crp_flags & CRYPTO_F_IOV)
+                                                	cuio_copyback(uiop,crd->crd_inject, cesa_ocf_cur_ses->ivlen,(caddr_t)ivp);
+						else
+							memcpy(crp->crp_buf + crd->crd_inject, ivp, cesa_ocf_cur_ses->ivlen);
+                                	}
+					else {
+						dprintk("%s,%d: don't copy the IV back to the buffer \n", __FILE__, __LINE__);
+						p_mbuf_info->numFrags++;
+						p_mbuf_info->mbufSize += cesa_ocf_cur_ses->ivlen; 
+						p_mbuf_info->pFrags = p_buf_info;
+
+						p_buf_info->bufVirtPtr = ivp;
+						p_buf_info->bufSize = cesa_ocf_cur_ses->ivlen; 
+						p_buf_info--;
+
+						/* offsets */
+						cesa_cmd->ivOffset = 0;
+						cesa_cmd->cryptoOffset += cesa_ocf_cur_ses->ivlen;
+						if(auth) {
+							cesa_cmd->macOffset += cesa_ocf_cur_ses->ivlen;
+							cesa_cmd->digestOffset += cesa_ocf_cur_ses->ivlen; 
+						}	
+					}
+                                }
+				else {					/* random IV */
+					dprintk("%s,%d: random IV \n", __FILE__, __LINE__);
+					cesa_cmd->ivFromUser = 0;
+
+                                	/*
+                                 	 * do we have to copy the IV back to the buffer ?
+                                 	 */
+					/* in this mode the HAL will always copy the IV */
+					/* given by the session to the ivOffset  	*/
+					if ((crd->crd_flags & CRD_F_IV_PRESENT) == 0) {
+						cesa_cmd->ivOffset = crd->crd_inject;
+					} 
+					else {
+						/* if IV isn't copy, then how will the user know which IV did we use??? */
+						printk("%s,%d: EINVAL\n", __FILE__, __LINE__);
+						goto p_error; 
+					}
+				}
+			}
+			else { 					/* decrypt */
+				dprintk(" decrypt \n");
+				decrypt++;
+				cesa_cmd->sessionId = cesa_ocf_cur_ses->sid_decrypt;
+
+				/* handle IV */
+				if (crd->crd_flags & CRD_F_IV_EXPLICIT) {
+					dprintk("%s,%d: IV from USER \n", __FILE__, __LINE__);
+					/* append the IV buf to the mbuf */
+					cesa_cmd->ivFromUser = 1;	
+					p_mbuf_info->numFrags++;
+					p_mbuf_info->mbufSize += cesa_ocf_cur_ses->ivlen; 
+					p_mbuf_info->pFrags = p_buf_info;
+
+					p_buf_info->bufVirtPtr = crd->crd_iv;
+					p_buf_info->bufSize = cesa_ocf_cur_ses->ivlen; 
+					p_buf_info--;
+
+					/* offsets */
+					cesa_cmd->ivOffset = 0;
+					cesa_cmd->cryptoOffset += cesa_ocf_cur_ses->ivlen;
+					if(auth) {
+						cesa_cmd->macOffset += cesa_ocf_cur_ses->ivlen;
+						cesa_cmd->digestOffset += cesa_ocf_cur_ses->ivlen; 
+					}
+                                }
+				else {
+					dprintk("%s,%d: IV inside the buffer \n", __FILE__, __LINE__);
+					cesa_cmd->ivFromUser = 0;
+					cesa_cmd->ivOffset = crd->crd_inject;
+				}
+			}
+
+		}
+		/* Authentication */
+		else if(crd->crd_alg == cesa_ocf_cur_ses->auth_alg) {
+			dprintk("%s,%d:  Authentication \n", __FILE__, __LINE__);
+			auth++;
+			cesa_cmd->macOffset = crd->crd_skip;
+			cesa_cmd->macLength = crd->crd_len;
+
+			/* digest + mac */
+			cesa_cmd->digestOffset = crd->crd_inject;
+		} 
+		else {
+			printk("%s,%d: Alg isn't supported by this session.\n", __FILE__, __LINE__);
+			goto p_error;
+		}
+	}
+
+	dprintk("\n");
+	dprintk("%s,%d: Sending Action: \n", __FILE__, __LINE__);
+	dprintk("%s,%d: IV from user: %d. IV offset %x \n",  __FILE__, __LINE__, cesa_cmd->ivFromUser, cesa_cmd->ivOffset);
+	dprintk("%s,%d: crypt offset %x len %x \n", __FILE__, __LINE__, cesa_cmd->cryptoOffset, cesa_cmd->cryptoLength);
+	dprintk("%s,%d: Auth offset %x len %x \n", __FILE__, __LINE__, cesa_cmd->macOffset, cesa_cmd->macLength);
+	dprintk("%s,%d: set digest in offset %x . \n", __FILE__, __LINE__, cesa_cmd->digestOffset);
+	if(debug) {
+		mvCesaIfDebugMbuf("SRC BUFFER", cesa_cmd->pSrc, 0, cesa_cmd->pSrc->mbufSize);
+	}
+
+	cesa_cmd->split = MV_CESA_SPLIT_NONE;
+	
+	/* send action to HAL */
+	spin_lock_irqsave(&cesa_lock, flags);
+	status = mvCesaIfAction(cesa_cmd);
+	spin_unlock_irqrestore(&cesa_lock, flags);
+
+	/* action not allowed */
+	if(status == MV_NOT_ALLOWED) {
+#ifdef CESA_OCF_SPLIT
+		/* if both encrypt and auth try to split */
+		if(auth && (encrypt || decrypt)) {
+			MV_CESA_COMMAND	*cesa_cmd_wa;
+
+			/* Allocate new cesa process from local pool and initialize it */	
+			cesa_ocf_cmd_wa = cesa_ocf_alloc();
+	
+        		if (cesa_ocf_cmd_wa == NULL) {
+            			printk("%s,%d: ENOBUFS \n", __FILE__, __LINE__);
+            			goto p_error;
+      			}
+			memcpy(cesa_ocf_cmd_wa, cesa_ocf_cmd, sizeof(struct cesa_ocf_process));
+			cesa_cmd_wa = &cesa_ocf_cmd_wa->cesa_cmd;
+			cesa_cmd_wa->pReqPrv = (void *)cesa_ocf_cmd_wa;
+			cesa_ocf_cmd_wa->need_cb = 0;
+			cesa_cmd_wa->split = MV_CESA_SPLIT_FIRST;
+			cesa_cmd->split = MV_CESA_SPLIT_SECOND;
+
+			/* break requests to two operation, first operation completion won't call callback */
+			if((decrypt) && (cesa_ocf_cur_ses->auth_tn_decrypt)) {
+				cesa_cmd_wa->sessionId = cesa_ocf_cur_ses->frag_wa_auth;
+				cesa_cmd->sessionId = cesa_ocf_cur_ses->frag_wa_decrypt;
+			}
+			else if((decrypt) && !(cesa_ocf_cur_ses->auth_tn_decrypt)) {
+				cesa_cmd_wa->sessionId = cesa_ocf_cur_ses->frag_wa_decrypt;
+				cesa_cmd->sessionId = cesa_ocf_cur_ses->frag_wa_auth;
+			}
+			else if((encrypt) && (cesa_ocf_cur_ses->encrypt_tn_auth)) {
+				cesa_cmd_wa->sessionId = cesa_ocf_cur_ses->frag_wa_encrypt;
+				cesa_cmd->sessionId = cesa_ocf_cur_ses->frag_wa_auth;
+			}
+			else if((encrypt) && !(cesa_ocf_cur_ses->encrypt_tn_auth)){
+				cesa_cmd_wa->sessionId = cesa_ocf_cur_ses->frag_wa_auth;
+				cesa_cmd->sessionId = cesa_ocf_cur_ses->frag_wa_encrypt;
+			}
+			else {
+				printk("%s,%d: Unsupporterd fragment wa mode \n", __FILE__, __LINE__);
+            			goto p_error;
+			}
+
+			/* send the 2 actions to the HAL */
+			spin_lock_irqsave(&cesa_lock, flags);
+			status = mvCesaIfAction(cesa_cmd_wa);
+			spin_unlock_irqrestore(&cesa_lock, flags);
+
+			if((status != MV_NO_MORE) && (status != MV_OK)) {
+				printk("%s,%d: cesa action failed, status = 0x%x\n", __FILE__, __LINE__, status);
+				goto p_error;
+			}
+			spin_lock_irqsave(&cesa_lock, flags);
+			status = mvCesaIfAction(cesa_cmd);
+			spin_unlock_irqrestore(&cesa_lock, flags);
+
+		}
+		/* action not allowed and can't split */
+		else 
+#endif
+		{
+			goto p_error;
+		}
+	}
+
+	/* Hal Q is full, send again. This should never happen */
+	if(status == MV_NO_RESOURCE) {
+		printk("%s,%d: cesa no more resources \n", __FILE__, __LINE__);
+		if(cesa_ocf_cmd)
+			cesa_ocf_free(cesa_ocf_cmd);
+		if(cesa_ocf_cmd_wa)
+			cesa_ocf_free(cesa_ocf_cmd_wa);
+		
+		return ERESTART;
+	} 
+	else if((status != MV_NO_MORE) && (status != MV_OK)) {
+                printk("%s,%d: cesa action failed, status = 0x%x\n", __FILE__, __LINE__, status);
+		goto p_error;
+        }
+
+	return 0;
+p_error:
+	crp->crp_etype = EINVAL;
+	if(cesa_ocf_cmd)
+		cesa_ocf_free(cesa_ocf_cmd);
+	if(cesa_ocf_cmd_wa)
+		cesa_ocf_free(cesa_ocf_cmd_wa);
+       	return EINVAL;
+}
+
+/*
+ * cesa callback. 
+ */
+static inline void
+cesa_callback(unsigned long dummy)
+{
+	struct cesa_ocf_process *cesa_ocf_cmd = NULL;
+	struct cryptop 		*crp = NULL;
+
+	dprintk("%s()\n", __func__);
+
+	spin_lock(&cesa_lock);
+
+	while (atomic_read(&result_count) != 0) {
+		cesa_ocf_cmd = result_Q[result_done];
+		crp = cesa_ocf_cmd->crp; 
+
+		if (cesa_ocf_cmd->need_cb) {
+			if (debug) {
+				mvCesaIfDebugMbuf("DST BUFFER", cesa_ocf_cmd->cesa_cmd.pDst, 0,
+							cesa_ocf_cmd->cesa_cmd.pDst->mbufSize);
+			}
+			crypto_done(crp);
+		}
+	
+		result_done = ((result_done + 1) % CESA_RESULT_Q_SIZE);
+		atomic_dec(&result_count);
+		cesa_ocf_cmd->valid = 0;
+	}
+
+	spin_unlock(&cesa_lock);
+
+	return;
+}
+
+/*
+ * cesa Interrupt Service Routine.
+ */
+static irqreturn_t
+cesa_interrupt_handler(int irq, void *arg)
+{
+	MV_CESA_RESULT  	result;
+	MV_STATUS               status;
+        unsigned int cause;
+	unsigned char chan = *((u8 *)arg);
+
+	dprintk("%s()\n", __func__);
+
+  	/* Read cause register */
+	cause = MV_REG_READ(MV_CESA_ISR_CAUSE_REG(chan));
+
+    	if (likely((cause & MV_CESA_CAUSE_ACC_DMA_MASK) != 0)) {
+			
+		/* Clear pending irq */
+    		MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+
+		spin_lock(&cesa_lock);
+
+		/* Get completed results */
+		while (1) {
+			if (atomic_read(&result_count) < CESA_RESULT_Q_SIZE) {
+				status = mvCesaIfReadyGet(chan, &result);
+				if (status == MV_OK) {
+					result_Q[next_result] = (struct cesa_ocf_process *)result.pReqPrv;
+					next_result = ((next_result + 1) % CESA_RESULT_Q_SIZE);
+					atomic_inc(&result_count);
+					continue;
+				} else
+					break;
+			} else {
+				spin_unlock(&cesa_lock);
+				/* In case reaching this point -result_Q should be tuned   */
+				printk("%s: Error: Q request is full(chan=%d)\n", __func__, chan);
+				return IRQ_HANDLED;
+			}
+		}
+
+		spin_unlock(&cesa_lock);
+	}
+
+	if(likely(atomic_read(&result_count) > 0))
+#ifdef CESA_OCF_TASKLET	
+		tasklet_hi_schedule(&cesa_ocf_tasklet);
+#else
+		cesa_callback(0);
+#endif
+
+	return IRQ_HANDLED;
+}
+
+/*
+ * Open a session.
+ */
+static int 
+/*cesa_ocf_newsession(void *arg, u_int32_t *sid, struct cryptoini *cri)*/
+cesa_ocf_newsession(device_t dev, u_int32_t *sid, struct cryptoini *cri)
+{
+	u32 status = 0, i = 0;
+	unsigned long flags = 0;
+	u32 count = 0, auth = 0, encrypt =0;
+	struct cesa_ocf_data *cesa_ocf_cur_ses;
+	MV_CESA_OPEN_SESSION cesa_session;
+	MV_CESA_OPEN_SESSION *cesa_ses = &cesa_session;
+
+
+        dprintk("%s()\n", __func__);
+        if (sid == NULL || cri == NULL) {
+                printk("%s,%d: EINVAL\n", __FILE__, __LINE__);
+                return EINVAL;
+        }
+
+	if (cesa_ocf_sessions) {
+		for (i = 1; i < cesa_ocf_sesnum; i++)
+			if (cesa_ocf_sessions[i] == NULL)
+				break;
+	} else
+		i = 1;
+
+	if (cesa_ocf_sessions == NULL || i == cesa_ocf_sesnum) {
+		struct cesa_ocf_data **cesa_ocf_new_sessions;
+
+		if (cesa_ocf_sessions == NULL) {
+			i = 1; /* We leave cesa_ocf_sessions[0] empty */
+			cesa_ocf_sesnum = CESA_OCF_MAX_SES;
+		}
+		else
+			cesa_ocf_sesnum *= 2;
+
+		cesa_ocf_new_sessions = kmalloc(cesa_ocf_sesnum * sizeof(struct cesa_ocf_data *), SLAB_ATOMIC);
+		if (cesa_ocf_new_sessions == NULL) {
+			/* Reset session number */
+			if (cesa_ocf_sesnum == CESA_OCF_MAX_SES)
+				cesa_ocf_sesnum = 0;
+			else
+				cesa_ocf_sesnum /= 2;
+			printk("%s,%d: ENOBUFS\n", __FILE__, __LINE__);
+			return ENOBUFS;
+		}
+		memset(cesa_ocf_new_sessions, 0, cesa_ocf_sesnum * sizeof(struct cesa_ocf_data *));
+
+		/* Copy existing sessions */
+		if (cesa_ocf_sessions) {
+			memcpy(cesa_ocf_new_sessions, cesa_ocf_sessions,
+			    (cesa_ocf_sesnum / 2) * sizeof(struct cesa_ocf_data *));
+			kfree(cesa_ocf_sessions);
+		}
+
+		cesa_ocf_sessions = cesa_ocf_new_sessions;
+	}
+
+	cesa_ocf_sessions[i] = (struct cesa_ocf_data *) kmalloc(sizeof(struct cesa_ocf_data),
+			SLAB_ATOMIC);
+	if (cesa_ocf_sessions[i] == NULL) {
+		cesa_ocf_freesession(NULL, i);
+		dprintk("%s,%d: EINVAL\n", __FILE__, __LINE__);
+		return ENOBUFS;
+	}
+
+	dprintk("%s,%d: new session %d \n", __FILE__, __LINE__, i);
+	
+        *sid = i;
+        cesa_ocf_cur_ses = cesa_ocf_sessions[i];
+        memset(cesa_ocf_cur_ses, 0, sizeof(struct cesa_ocf_data));
+	cesa_ocf_cur_ses->sid_encrypt = -1;
+	cesa_ocf_cur_ses->sid_decrypt = -1;
+	cesa_ocf_cur_ses->frag_wa_encrypt = -1;
+	cesa_ocf_cur_ses->frag_wa_decrypt = -1;
+	cesa_ocf_cur_ses->frag_wa_auth = -1;
+
+	/* init the session */	
+	memset(cesa_ses, 0, sizeof(MV_CESA_OPEN_SESSION));
+	count = 1;
+        while (cri) {	
+		if(count > 2) {
+        		printk("%s,%d: don't support more then 2 operations\n", __FILE__, __LINE__);
+        		goto error;
+		}
+                switch (cri->cri_alg) {
+		case CRYPTO_AES_CBC:
+			dprintk("%s,%d: (%d) AES CBC \n", __FILE__, __LINE__, count);
+			cesa_ocf_cur_ses->cipher_alg = cri->cri_alg;
+			cesa_ocf_cur_ses->ivlen = MV_CESA_AES_BLOCK_SIZE;
+			cesa_ses->cryptoAlgorithm = MV_CESA_CRYPTO_AES;
+			cesa_ses->cryptoMode = MV_CESA_CRYPTO_CBC;
+			if(cri->cri_klen/8 > MV_CESA_MAX_CRYPTO_KEY_LENGTH) {
+        			printk("%s,%d: CRYPTO key too long.\n", __FILE__, __LINE__);
+        			goto error;
+			}
+			memcpy(cesa_ses->cryptoKey, cri->cri_key, cri->cri_klen/8);
+			dprintk("%s,%d: key length %d \n", __FILE__, __LINE__, cri->cri_klen/8);
+			cesa_ses->cryptoKeyLength = cri->cri_klen/8;
+			encrypt += count;
+			break;
+                case CRYPTO_3DES_CBC:
+			dprintk("%s,%d: (%d) 3DES CBC \n", __FILE__, __LINE__, count);
+			cesa_ocf_cur_ses->cipher_alg = cri->cri_alg;
+			cesa_ocf_cur_ses->ivlen = MV_CESA_3DES_BLOCK_SIZE;
+			cesa_ses->cryptoAlgorithm = MV_CESA_CRYPTO_3DES;
+			cesa_ses->cryptoMode = MV_CESA_CRYPTO_CBC;
+			if(cri->cri_klen/8 > MV_CESA_MAX_CRYPTO_KEY_LENGTH) {
+        			printk("%s,%d: CRYPTO key too long.\n", __FILE__, __LINE__);
+        			goto error;
+			}
+			memcpy(cesa_ses->cryptoKey, cri->cri_key, cri->cri_klen/8);
+			cesa_ses->cryptoKeyLength = cri->cri_klen/8;
+			encrypt += count;
+			break;
+                case CRYPTO_DES_CBC:
+			dprintk("%s,%d: (%d) DES CBC \n", __FILE__, __LINE__, count);
+			cesa_ocf_cur_ses->cipher_alg = cri->cri_alg;
+			cesa_ocf_cur_ses->ivlen = MV_CESA_DES_BLOCK_SIZE;
+			cesa_ses->cryptoAlgorithm = MV_CESA_CRYPTO_DES;
+			cesa_ses->cryptoMode = MV_CESA_CRYPTO_CBC;
+			if(cri->cri_klen/8 > MV_CESA_MAX_CRYPTO_KEY_LENGTH) {
+        			printk("%s,%d: CRYPTO key too long.\n", __FILE__, __LINE__);
+        			goto error;
+			}
+			memcpy(cesa_ses->cryptoKey, cri->cri_key, cri->cri_klen/8);
+			cesa_ses->cryptoKeyLength = cri->cri_klen/8;
+			encrypt += count;
+			break;
+                case CRYPTO_MD5:
+                case CRYPTO_MD5_HMAC:
+			dprintk("%s,%d: (%d) %sMD5 CBC \n", __FILE__, __LINE__, count, (cri->cri_alg != CRYPTO_MD5)? "H-":" ");
+                        cesa_ocf_cur_ses->auth_alg = cri->cri_alg;
+			cesa_ocf_cur_ses->digestlen = (cri->cri_alg == CRYPTO_MD5)? MV_CESA_MD5_DIGEST_SIZE : 12;
+			cesa_ses->macMode = (cri->cri_alg == CRYPTO_MD5)? MV_CESA_MAC_MD5 : MV_CESA_MAC_HMAC_MD5;
+			if(cri->cri_klen/8 > MV_CESA_MAX_CRYPTO_KEY_LENGTH) {
+        			printk("%s,%d: MAC key too long. \n", __FILE__, __LINE__);
+        			goto error;
+			}
+			cesa_ses->macKeyLength = cri->cri_klen/8;
+			memcpy(cesa_ses->macKey, cri->cri_key, cri->cri_klen/8);
+			cesa_ses->digestSize = cesa_ocf_cur_ses->digestlen; 
+			auth += count;
+			break;
+                case CRYPTO_SHA1:
+                case CRYPTO_SHA1_HMAC:
+			dprintk("%s,%d: (%d) %sSHA1 CBC \n", __FILE__, __LINE__, count, (cri->cri_alg != CRYPTO_SHA1)? "H-":" ");
+                        cesa_ocf_cur_ses->auth_alg = cri->cri_alg;
+			cesa_ocf_cur_ses->digestlen = (cri->cri_alg == CRYPTO_SHA1)? MV_CESA_SHA1_DIGEST_SIZE : 12; 
+			cesa_ses->macMode = (cri->cri_alg == CRYPTO_SHA1)? MV_CESA_MAC_SHA1 : MV_CESA_MAC_HMAC_SHA1;
+			if(cri->cri_klen/8 > MV_CESA_MAX_CRYPTO_KEY_LENGTH) {
+        			printk("%s,%d: MAC key too long. \n", __FILE__, __LINE__);
+        			goto error;
+			}
+			cesa_ses->macKeyLength = cri->cri_klen/8;
+			memcpy(cesa_ses->macKey, cri->cri_key, cri->cri_klen/8);
+			cesa_ses->digestSize = cesa_ocf_cur_ses->digestlen;
+			auth += count;
+			break;
+                default:
+                        printk("%s,%d: unknown algo 0x%x\n", __FILE__, __LINE__, cri->cri_alg);
+                        goto error;
+                }
+                cri = cri->cri_next;
+		count++;
+        }
+
+	if((encrypt > 2) || (auth > 2)) {
+		printk("%s,%d: session mode is not supported.\n", __FILE__, __LINE__);
+                goto error;
+	}
+
+	/* create new sessions in HAL */
+	if(encrypt) {
+		cesa_ses->operation = MV_CESA_CRYPTO_ONLY;
+		/* encrypt session */
+		if(auth == 1) {
+			cesa_ses->operation = MV_CESA_MAC_THEN_CRYPTO;
+		}
+		else if(auth == 2) {
+			cesa_ses->operation = MV_CESA_CRYPTO_THEN_MAC;
+			cesa_ocf_cur_ses->encrypt_tn_auth = 1;
+		}
+		else {
+			cesa_ses->operation = MV_CESA_CRYPTO_ONLY;
+		}
+		cesa_ses->direction = MV_CESA_DIR_ENCODE;
+		spin_lock_irqsave(&cesa_lock, flags);
+		status = mvCesaIfSessionOpen(cesa_ses, &cesa_ocf_cur_ses->sid_encrypt);
+		spin_unlock_irqrestore(&cesa_lock, flags);
+    		if(status != MV_OK) {
+        		printk("%s,%d: Can't open new session - status = 0x%x\n", __FILE__, __LINE__, status);
+        		goto error;
+    		}	
+		/* decrypt session */
+		if( cesa_ses->operation == MV_CESA_MAC_THEN_CRYPTO ) {
+			cesa_ses->operation = MV_CESA_CRYPTO_THEN_MAC;
+		}
+		else if( cesa_ses->operation == MV_CESA_CRYPTO_THEN_MAC ) {
+			cesa_ses->operation = MV_CESA_MAC_THEN_CRYPTO;
+		}
+		cesa_ses->direction = MV_CESA_DIR_DECODE;
+		spin_lock_irqsave(&cesa_lock, flags);
+		status = mvCesaIfSessionOpen(cesa_ses, &cesa_ocf_cur_ses->sid_decrypt);
+		spin_unlock_irqrestore(&cesa_lock, flags);
+		if(status != MV_OK) {
+        		printk("%s,%d: Can't open new session - status = 0x%x\n", __FILE__, __LINE__, status);
+        		goto error;
+    		}
+
+		/* preapre one action sessions for case we will need to split an action */
+#ifdef CESA_OCF_SPLIT
+		if(( cesa_ses->operation == MV_CESA_MAC_THEN_CRYPTO ) || 
+			( cesa_ses->operation == MV_CESA_CRYPTO_THEN_MAC )) {
+			/* open one session for encode and one for decode */
+			cesa_ses->operation = MV_CESA_CRYPTO_ONLY;
+			cesa_ses->direction = MV_CESA_DIR_ENCODE;
+			spin_lock_irqsave(&cesa_lock, flags);
+			status = mvCesaIfSessionOpen(cesa_ses, &cesa_ocf_cur_ses->frag_wa_encrypt);
+			spin_unlock_irqrestore(&cesa_lock, flags);
+    			if(status != MV_OK) {
+        			printk("%s,%d: Can't open new session - status = 0x%x\n", __FILE__, __LINE__, status);
+        			goto error;
+    			}
+
+			cesa_ses->direction = MV_CESA_DIR_DECODE;
+			spin_lock_irqsave(&cesa_lock, flags);
+			status = mvCesaIfSessionOpen(cesa_ses, &cesa_ocf_cur_ses->frag_wa_decrypt);
+			spin_unlock_irqrestore(&cesa_lock, flags);
+    			if(status != MV_OK) {
+        			printk("%s,%d: Can't open new session - status = 0x%x\n", __FILE__, __LINE__, status);
+        			goto error;
+    			}
+			/* open one session for auth */	
+			cesa_ses->operation = MV_CESA_MAC_ONLY;
+			cesa_ses->direction = MV_CESA_DIR_ENCODE;
+			spin_lock_irqsave(&cesa_lock, flags);
+			status = mvCesaIfSessionOpen(cesa_ses, &cesa_ocf_cur_ses->frag_wa_auth);
+			spin_unlock_irqrestore(&cesa_lock, flags);
+			if(status != MV_OK) {
+        			printk("%s,%d: Can't open new session - status = 0x%x\n", __FILE__, __LINE__, status);
+				goto error;
+    			}
+		}
+#endif
+	}
+	else { /* only auth */
+		cesa_ses->operation = MV_CESA_MAC_ONLY;
+		cesa_ses->direction = MV_CESA_DIR_ENCODE;
+		spin_lock_irqsave(&cesa_lock, flags);
+        	status = mvCesaIfSessionOpen(cesa_ses, &cesa_ocf_cur_ses->sid_encrypt);
+		spin_unlock_irqrestore(&cesa_lock, flags);
+		if(status != MV_OK) {
+        		printk("%s,%d: Can't open new session - status = 0x%x\n", __FILE__, __LINE__, status);
+			goto error;
+    		}
+	}
+
+	return 0;
+error:
+     	cesa_ocf_freesession(NULL, *sid);
+      	return EINVAL;	
+
+}
+
+
+/*
+ * Free a session.
+ */
+static int
+cesa_ocf_freesession(device_t dev, u_int64_t tid)
+{
+        struct cesa_ocf_data *cesa_ocf_cur_ses;
+        u_int32_t sid = CRYPTO_SESID2LID(tid);
+	unsigned long flags = 0;
+
+        dprintk("%s() %d \n", __func__, sid);
+	if (sid > cesa_ocf_sesnum || cesa_ocf_sessions == NULL ||
+			cesa_ocf_sessions[sid] == NULL) {
+		dprintk("%s,%d: EINVAL\n", __FILE__, __LINE__);
+		return EINVAL;
+	}
+
+        /* Silently accept and return */
+        if (sid == 0)
+                return(0);
+
+	/* release session from HAL */
+	cesa_ocf_cur_ses = cesa_ocf_sessions[sid];
+     	if (cesa_ocf_cur_ses->sid_encrypt != -1) {
+		spin_lock_irqsave(&cesa_lock, flags);
+		mvCesaIfSessionClose(cesa_ocf_cur_ses->sid_encrypt);
+		spin_unlock_irqrestore(&cesa_lock, flags);
+	}
+	if (cesa_ocf_cur_ses->sid_decrypt != -1) {
+		spin_lock_irqsave(&cesa_lock, flags);
+		mvCesaIfSessionClose(cesa_ocf_cur_ses->sid_decrypt);
+		spin_unlock_irqrestore(&cesa_lock, flags);
+	}
+     	if (cesa_ocf_cur_ses->frag_wa_encrypt != -1) {
+		spin_lock_irqsave(&cesa_lock, flags);
+		mvCesaIfSessionClose(cesa_ocf_cur_ses->frag_wa_encrypt);
+		spin_unlock_irqrestore(&cesa_lock, flags);
+	}
+	if (cesa_ocf_cur_ses->frag_wa_decrypt != -1) {
+		spin_lock_irqsave(&cesa_lock, flags);
+		mvCesaIfSessionClose(cesa_ocf_cur_ses->frag_wa_decrypt);
+		spin_unlock_irqrestore(&cesa_lock, flags);
+	}
+	if (cesa_ocf_cur_ses->frag_wa_auth != -1) {
+		spin_lock_irqsave(&cesa_lock, flags);
+		mvCesaIfSessionClose(cesa_ocf_cur_ses->frag_wa_auth);
+		spin_unlock_irqrestore(&cesa_lock, flags);
+	}
+
+      	kfree(cesa_ocf_cur_ses);
+	cesa_ocf_sessions[sid] = NULL;
+
+        return 0;
+}
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,30))
+extern int crypto_init(void);
+#endif
+
+/*
+ * our driver startup and shutdown routines
+ */
+static int
+cesa_ocf_init(void)
+{
+	u8 chan = 0;
+	const char *irq_name[] = {"mv_cesa:0","mv_cesa:1"};
+
+	if (mvCtrlPwrClckGet(CESA_UNIT_ID, 0) == MV_FALSE)
+		return 0;
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,30))
+	crypto_init();
+#endif
+
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+	if (MV_FALSE == mvSocUnitIsMappedToThisCpu(CESA))
+	{
+		dprintk("CESA is not mapped to this CPU\n");
+		return -ENODEV;
+	}		
+#endif
+
+	dprintk("%s\n", __func__);
+
+	next_result = 0;
+	result_done = 0;
+
+	/* The pool size here is twice the requests queue size due to reordering */
+	cesa_ocf_pool = (struct cesa_ocf_process*)kmalloc((sizeof(struct cesa_ocf_process) * 
+					CESA_Q_SIZE * MV_CESA_CHANNELS * 2), GFP_KERNEL);
+	if (cesa_ocf_pool == NULL) {
+            	printk("%s,%d: ENOBUFS \n", __FILE__, __LINE__);
+            	return EINVAL;
+      	}
+
+	proc_empty = 0;
+	memset(cesa_ocf_pool, 0, (sizeof(struct cesa_ocf_process) * CESA_Q_SIZE * MV_CESA_CHANNELS * 2));
+	memset(&mv_cesa_dev, 0, sizeof(mv_cesa_dev));
+	softc_device_init(&mv_cesa_dev, "MV CESA", 0, mv_cesa_methods);
+	cesa_ocf_id = crypto_get_driverid(softc_get_device(&mv_cesa_dev),CRYPTOCAP_F_HARDWARE);
+
+	if (cesa_ocf_id < 0)
+		panic("MV CESA crypto device cannot initialize!");
+
+	dprintk("%s,%d: cesa ocf device id is %d \n", __FILE__, __LINE__, cesa_ocf_id);
+
+	/* CESA unit is auto power on off */
+#if 0
+	if (MV_FALSE == mvCtrlPwrClckGet(CESA_UNIT_ID,0))
+	{
+		printk("\nWarning CESA %d is Powered Off\n",0);
+		return EINVAL;
+	}
+#endif
+
+	if( MV_OK != mvSysCesaInit(CESA_OCF_MAX_SES*5, CESA_Q_SIZE, NULL) ) {
+            	printk("%s,%d: mvCesaInit Failed. \n", __FILE__, __LINE__);
+		return EINVAL;
+	}
+
+	for(chan = 0; chan < MV_CESA_CHANNELS; chan++) {
+
+		/* clear and unmask Int */
+		MV_REG_WRITE( MV_CESA_ISR_CAUSE_REG(chan), 0);
+    		MV_REG_WRITE( MV_CESA_ISR_MASK_REG(chan), MV_CESA_CAUSE_ACC_DMA_MASK);
+
+		chan_id[chan] = chan;
+
+		/* register interrupt */
+		if( request_irq( CESA_IRQ(chan), cesa_interrupt_handler,
+                             	(IRQF_DISABLED) , irq_name[chan], &chan_id[chan]) < 0) {
+            		printk("%s,%d: cannot assign irq %x\n", __FILE__, __LINE__, CESA_IRQ(chan));
+			return EINVAL;
+        	}
+	}
+
+#ifdef CESA_OCF_TASKLET
+	tasklet_init(&cesa_ocf_tasklet, cesa_callback, (unsigned int) 0);
+#endif
+
+
+#define	REGISTER(alg) \
+	crypto_register(cesa_ocf_id, alg, 0,0)
+	REGISTER(CRYPTO_AES_CBC);
+	REGISTER(CRYPTO_DES_CBC);
+	REGISTER(CRYPTO_3DES_CBC);
+	REGISTER(CRYPTO_MD5);
+	REGISTER(CRYPTO_MD5_HMAC);
+	REGISTER(CRYPTO_SHA1);
+	REGISTER(CRYPTO_SHA1_HMAC);
+#undef REGISTER
+
+	return 0;
+}
+
+static void
+cesa_ocf_exit(void)
+{
+	u8 chan = 0;
+
+	dprintk("%s()\n", __func__);
+
+	crypto_unregister_all(cesa_ocf_id);
+	cesa_ocf_id = -1;
+	kfree(cesa_ocf_pool);
+
+	for(chan = 0; chan < MV_CESA_CHANNELS; chan++) {
+		free_irq(CESA_IRQ(chan), NULL);
+	
+		/* mask and clear Int */
+		MV_REG_WRITE( MV_CESA_ISR_MASK_REG(chan), 0);
+		MV_REG_WRITE( MV_CESA_ISR_CAUSE_REG(chan), 0);
+    	
+	}
+
+	if( MV_OK != mvCesaIfFinish() ) {
+            	printk("%s,%d: mvCesaFinish Failed. \n", __FILE__, __LINE__);
+		return;
+	}
+}
+
+module_init(cesa_ocf_init);
+module_exit(cesa_ocf_exit);
+
+MODULE_LICENSE("Marvell/GPL");
+MODULE_AUTHOR("Ronen Shitrit");
+MODULE_DESCRIPTION("OCF module for Marvell CESA based SoC");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_test.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_test.c
new file mode 100644
index 0000000..2e94825
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/cesa_test.c
@@ -0,0 +1,3038 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+		this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+		notice, this list of conditions and the following disclaimer in the
+		documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+		used to endorse or promote products derived from this software without
+		specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvOs.h"
+
+#if defined(MV_VXWORKS)
+
+#include "sysLib.h"
+#include "logLib.h"
+#include "tickLib.h"
+#include "intLib.h"
+#include "config.h"
+
+SEM_ID cesaSemId = NULL;
+SEM_ID cesaWaitSemId = NULL;
+
+#define CESA_TEST_LOCK(flags)       flags = intLock()
+#define CESA_TEST_UNLOCK(flags)     intUnlock(flags)
+
+#define CESA_TEST_WAIT_INIT()       cesaWaitSemId = semBCreate(SEM_Q_PRIORITY, SEM_EMPTY)
+#define CESA_TEST_WAKE_UP()         semGive(cesaWaitSemId)
+#define CESA_TEST_WAIT(cond, ms)    semTake(cesaWaitSemId, (sysClkRateGet()*ms)/1000)
+
+#define CESA_TEST_TICK_GET()        tickGet()
+#define CESA_TEST_TICK_TO_MS(tick)  (((tick)*1000)/sysClkRateGet())
+
+#elif defined(MV_LINUX)
+#include <linux/interrupt.h>
+#include <linux/wait.h>
+static wait_queue_head_t cesaTest_waitq;
+static spinlock_t cesaLock;
+static struct timeval tv;
+
+#define CESA_TEST_LOCK(flags)       spin_lock_irqsave(&cesaLock, flags)
+#define CESA_TEST_UNLOCK(flags)     spin_unlock_irqrestore(&cesaLock, flags);
+
+#define CESA_TEST_WAIT_INIT()       init_waitqueue_head(&cesaTest_waitq)
+#define CESA_TEST_WAKE_UP()         wake_up(&cesaTest_waitq)
+#define CESA_TEST_WAIT(cond, ms)    wait_event_timeout(cesaTest_waitq, (cond), msecs_to_jiffies(ms))
+
+#elif defined(MV_NETBSD)
+
+#include <sys/param.h>
+#include <sys/kernel.h>
+static int cesaLock;
+
+#define	CESA_TEST_LOCK(flags)		flags = splnet()
+#define	CESA_TEST_UNLOCK(flags)		splx(flags)
+
+#define	CESA_TEST_WAIT_INIT()	/* nothing */
+#define	CESA_TEST_WAKE_UP()		wakeup(&cesaLock)
+#define	CESA_TEST_WAIT(cond, ms)	\
+do {					\
+	while (!(cond))			\
+		tsleep(&cesaLock, PWAIT, "cesatest", mstohz(ms)); \
+} while (/*CONSTCOND*/0)
+
+#define	CESA_TEST_TICK_GET()		hardclock_ticks
+#define	CESA_TEST_TICK_TO_MS(tick)	((1000/hz)*(tick))
+
+#define	request_irq(i, h, t, n, a)	\
+	(!mv_intr_establish((i), IPL_NET, (int(*)(void *))(h), (a)))
+
+#else
+#error "Only Linux, VxWorks, or NetBSD OS are supported"
+#endif
+
+#include "mvDebug.h"
+
+#include "mvSysCesaConfig.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "ctrlEnv/sys/mvCpuIf.h"
+#include "cntmr/mvCntmr.h"
+#include "cesa_if.h"
+#include "cesa/mvMD5.h"
+#include "cesa/mvSHA1.h"
+#include "cesa/mvSHA256.h"
+
+#if defined(CONFIG_MV646xx)
+#include "marvell_pic.h"
+#endif
+
+#define MV_CESA_USE_TIMER_ID    0
+#define CESA_DEF_BUF_SIZE       1500
+#define CESA_DEF_BUF_NUM        1
+#define CESA_DEF_SESSION_NUM    32
+
+#define CESA_DEF_ITER_NUM       100
+
+#define CESA_DEF_REQ_SIZE       256
+
+/* CESA Tests Debug */
+#undef CESA_TEST_DEBUG
+
+#ifdef CESA_TEST_DEBUG
+
+#   define CESA_TEST_DEBUG_PRINT(msg)   mvOsPrintf msg
+#   define CESA_TEST_DEBUG_CODE(code)   code
+
+typedef struct {
+	int type;		/* 0 - isrEmpty, 1 - cesaReadyGet, 2 - cesaAction */
+	MV_U32 timeStamp;
+	MV_U32 cause;
+	MV_U32 realCause;
+	MV_U32 dmaErrCause;
+	int resources;
+	MV_CESA_REQ *pReqReady;
+	MV_CESA_REQ *pReqEmpty;
+	MV_CESA_REQ *pReqProcess;
+} MV_CESA_TEST_TRACE;
+
+#define MV_CESA_TEST_TRACE_SIZE      25
+
+static int cesaTestTraceIdx;
+static MV_CESA_TEST_TRACE cesaTestTrace[MV_CESA_TEST_TRACE_SIZE];
+
+#if 0
+static void cesaTestTraceAdd(int type, MV_U32 cause)
+{
+	cesaTestTrace[cesaTestTraceIdx].type = type;
+	cesaTestTrace[cesaTestTraceIdx].cause = cause;
+	cesaTestTrace[cesaTestTraceIdx].realCause = MV_REG_READ(MV_CESA_ISR_CAUSE_REG);
+	cesaTestTrace[cesaTestTraceIdx].dmaErrCause = MV_REG_READ(MV_CESA_TDMA_ERROR_CAUSE_REG);
+	cesaTestTrace[cesaTestTraceIdx].resources = cesaReqResources;
+	cesaTestTrace[cesaTestTraceIdx].pReqReady = pCesaReqReady;
+	cesaTestTrace[cesaTestTraceIdx].pReqEmpty = pCesaReqEmpty;
+	cesaTestTrace[cesaTestTraceIdx].pReqProcess = pCesaReqProcess;
+	cesaTestTrace[cesaTestTraceIdx].timeStamp = mvCntmrRead(MV_CESA_USE_TIMER_ID);
+	cesaTestTraceIdx++;
+	if (cesaTestTraceIdx == MV_CESA_TEST_TRACE_SIZE)
+		cesaTestTraceIdx = 0;
+}
+#endif
+#else
+
+#   define CESA_TEST_DEBUG_PRINT(msg)
+#   define CESA_TEST_DEBUG_CODE(code)
+
+#endif /* CESA_TEST_DEBUG */
+
+int cesaExpReqId = 0;
+int cesaCbIter = 0;
+unsigned int cmdReqId = 0;
+
+int cesaIdx;
+int cesaIteration;
+int cesaRateSize;
+int cesaReqSize;
+unsigned long cesaTaskId;
+int cesaBufNum;
+int cesaBufSize;
+int cesaCheckOffset;
+int cesaCheckSize;
+int cesaCheckMode;
+int cesaTestIdx;
+int cesaCaseIdx;
+
+MV_U32 cesaTestIsrCount = 0;
+MV_U32 cesaTestIsrMissCount = 0;
+
+MV_U32 cesaCryptoError = 0;
+MV_U32 cesaReqIdError = 0;
+MV_U32 cesaError = 0;
+
+char *cesaHexBuffer = NULL;
+
+char *cesaBinBuffer = NULL;
+char *cesaExpBinBuffer = NULL;
+
+char *cesaInputHexStr = NULL;
+char *cesaOutputHexStr = NULL;
+
+MV_BUF_INFO cesaReqBufs[CESA_DEF_REQ_SIZE];
+static u8 chanId[MV_CESA_CHANNELS];
+static spinlock_t cesaChanLock[MV_CESA_CHANNELS];
+
+MV_CESA_COMMAND *cesaCmdRing;
+MV_CESA_RESULT cesaResult;
+
+int cesaTestFull = 0;
+
+MV_BOOL cesaIsReady = MV_FALSE;
+MV_U32 cesaCycles = 0;
+MV_U32 cesaBeginTicks = 0;
+MV_U32 cesaEndTicks = 0;
+MV_U32 cesaRate = 0;
+MV_U32 cesaRateAfterDot = 0;
+
+void *cesaTestOSHandle = NULL;
+
+enum {
+	CESA_FAST_CHECK_MODE = 0,
+	CESA_FULL_CHECK_MODE,
+	CESA_NULL_CHECK_MODE,
+	CESA_SHOW_CHECK_MODE,
+	CESA_SW_SHOW_CHECK_MODE,
+	CESA_SW_NULL_CHECK_MODE,
+
+	CESA_MAX_CHECK_MODE
+};
+
+enum {
+	DES_TEST_TYPE = 0,
+	TRIPLE_DES_TEST_TYPE = 1,
+	AES_TEST_TYPE = 2,
+	MD5_TEST_TYPE = 3,
+	SHA1_TEST_TYPE = 4,
+	SHA2_TEST_TYPE = 5,
+	COMBINED_TEST_TYPE = 6,
+	MAX_TEST_TYPE
+};
+
+/* Tests data base */
+typedef struct {
+	short sid;
+	char cryptoAlgorithm;	/* DES/3DES/AES */
+	char cryptoMode;	/* ECB or CBC */
+	char macAlgorithm;	/* MD5 / SHA1 / SHA2 */
+	char operation;		/* CRYPTO/HMAC/CRYPTO+HMAC/HMAC+CRYPTO */
+	char direction;		/* ENCODE(SIGN)/DECODE(VERIFY) */
+	unsigned char *pCryptoKey;
+	int cryptoKeySize;
+	unsigned char *pMacKey;
+	int macKeySize;
+	const char *name;
+} MV_CESA_TEST_SESSION;
+
+typedef struct {
+	MV_CESA_TEST_SESSION *pSessions;
+	int numSessions;
+} MV_CESA_TEST_DB_ENTRY;
+
+typedef struct {
+	char *plainHexStr;
+	char *cipherHexStr;
+	unsigned char *pCryptoIV;
+	int cryptoLength;
+	int macLength;
+	int digestOffset;
+} MV_CESA_TEST_CASE;
+
+typedef struct {
+	int size;
+	const char *outputHexStr;
+} MV_CESA_SIZE_TEST;
+
+static unsigned char cryptoKey1[] = { 0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef,
+	0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef,
+	0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef
+};
+
+static unsigned char cryptoKey7[] = { 0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef };
+static unsigned char iv1[] = { 0x12, 0x34, 0x56, 0x78, 0x90, 0xab, 0xcd, 0xef };
+
+static unsigned char cryptoKey2[] = { 0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07,
+	0x08, 0x09, 0x0A, 0x0B, 0x0C, 0x0D, 0x0E, 0x0F
+};
+
+static unsigned char cryptoKey3[] = { 0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07,
+	0x08, 0x09, 0x0A, 0x0B, 0x0C, 0x0D, 0x0E, 0x0F,
+	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17
+};
+
+static unsigned char cryptoKey4[] = { 0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07,
+	0x08, 0x09, 0x0A, 0x0B, 0x0C, 0x0D, 0x0E, 0x0F,
+	0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17,
+	0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f
+};
+
+static unsigned char cryptoKey5[] = { 0x56, 0xe4, 0x7a, 0x38, 0xc5, 0x59, 0x89, 0x74,
+	0xbc, 0x46, 0x90, 0x3d, 0xba, 0x29, 0x03, 0x49
+};
+
+static unsigned char key3des1[] = { 0x01, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF,
+	0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF, 0x01,
+	0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF, 0x01, 0x23
+};
+
+/*  Input ASCII string: The quick brown fox jump  */
+static char plain3des1[] = "54686520717566636B2062726F776E20666F78206A756D70";
+static char cipher3des1[] = "A826FD8CE53B855FCCE21C8112256FE668D5C05DD9B6B900";
+
+static unsigned char key3des2[] = { 0x62, 0x7f, 0x46, 0x0e, 0x08, 0x10, 0x4a, 0x10,
+	0x43, 0xcd, 0x26, 0x5d, 0x58, 0x40, 0xea, 0xf1,
+	0x31, 0x3e, 0xdf, 0x97, 0xdf, 0x2a, 0x8a, 0x8c
+};
+
+static unsigned char iv3des2[] = { 0x8e, 0x29, 0xf7, 0x5e, 0xa7, 0x7e, 0x54, 0x75 };
+
+static char plain3des2[] = "326a494cd33fe756";
+
+static char cipher3desCbc2[] = "8e29f75ea77e5475" "b22b8d66de970692";
+
+static unsigned char key3des3[] = { 0x37, 0xae, 0x5e, 0xbf, 0x46, 0xdf, 0xf2, 0xdc,
+	0x07, 0x54, 0xb9, 0x4f, 0x31, 0xcb, 0xb3, 0x85,
+	0x5e, 0x7f, 0xd3, 0x6d, 0xc8, 0x70, 0xbf, 0xae
+};
+
+static unsigned char iv3des3[] = { 0x3d, 0x1d, 0xe3, 0xcc, 0x13, 0x2e, 0x3b, 0x65 };
+
+static char plain3des3[] = "84401f78fe6c10876d8ea23094ea5309";
+
+static char cipher3desCbc3[] = "3d1de3cc132e3b65" "7b1f7c7e3b1c948ebd04a75ffba7d2f5";
+
+static unsigned char iv5[] = { 0x8c, 0xe8, 0x2e, 0xef, 0xbe, 0xa0, 0xda, 0x3c,
+	0x44, 0x69, 0x9e, 0xd7, 0xdb, 0x51, 0xb7, 0xd9
+};
+
+static unsigned char aesCtrKey[] = { 0x76, 0x91, 0xBE, 0x03, 0x5E, 0x50, 0x20, 0xA8,
+	0xAC, 0x6E, 0x61, 0x85, 0x29, 0xF9, 0xA0, 0xDC
+};
+
+static unsigned char mdKey1[] = { 0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b,
+	0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b
+};
+
+static unsigned char mdKey2[] = { 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa,
+	0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa
+};
+
+static unsigned char shaKey1[] = { 0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b,
+	0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b,
+	0x0b, 0x0b, 0x0b, 0x0b
+};
+
+static unsigned char shaKey2[] = { 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa,
+	0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa,
+	0xaa, 0xaa, 0xaa, 0xaa
+};
+
+static unsigned char mdKey4[] = { 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08,
+	0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, 0x10
+};
+
+static unsigned char shaKey4[] = { 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08,
+	0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, 0x10,
+	0x11, 0x12, 0x13, 0x14
+};
+
+static unsigned char sha2Key1[] = { 0x0, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07,
+	0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, 0x10, 0x11, 0x12, 0x13, 0x14,
+	0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f
+};
+
+
+static MV_CESA_TEST_SESSION desTestSessions[] = {
+/*000*/ {-1, MV_CESA_CRYPTO_DES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey7, sizeof(cryptoKey7) / sizeof(cryptoKey7[0]),
+	 NULL, 0,
+	 "DES ECB encode",
+	 }
+	,
+/*001*/ {-1, MV_CESA_CRYPTO_DES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 cryptoKey7, sizeof(cryptoKey7) / sizeof(cryptoKey7[0]),
+	 NULL, 0,
+	 "DES ECB decode",
+	 }
+	,
+/*002*/ {-1, MV_CESA_CRYPTO_DES, MV_CESA_CRYPTO_CBC,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey7, sizeof(cryptoKey7) / sizeof(cryptoKey7[0]),
+	 NULL, 0,
+	 "DES CBC encode"}
+	,
+/*003*/ {-1, MV_CESA_CRYPTO_DES, MV_CESA_CRYPTO_CBC,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 cryptoKey7, sizeof(cryptoKey7) / sizeof(cryptoKey7[0]),
+	 NULL, 0,
+	 "DES CBC decode"}
+	,
+/*004*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 NULL, 0, NULL, 0,
+	 "NULL Crypto Algorithm encode"}
+	,
+};
+
+static MV_CESA_TEST_SESSION tripleDesTestSessions[] = {
+/*100*/ {-1, MV_CESA_CRYPTO_3DES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey1, sizeof(cryptoKey1) / sizeof(cryptoKey1[0]),
+	 NULL, 0,
+	 "3DES ECB encode",
+	 }
+	,
+/*101*/ {-1, MV_CESA_CRYPTO_3DES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 cryptoKey1, sizeof(cryptoKey1) / sizeof(cryptoKey1[0]),
+	 NULL, 0,
+	 "3DES ECB decode",
+	 }
+	,
+/*102*/ {-1, MV_CESA_CRYPTO_3DES, MV_CESA_CRYPTO_CBC,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey1, sizeof(cryptoKey1) / sizeof(cryptoKey1[0]),
+	 NULL, 0,
+	 "3DES CBC encode"}
+	,
+/*103*/ {-1, MV_CESA_CRYPTO_3DES, MV_CESA_CRYPTO_CBC,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 cryptoKey1, sizeof(cryptoKey1) / sizeof(cryptoKey1[0]),
+	 NULL, 0,
+	 "3DES CBC decode"}
+	,
+/*104*/ {-1, MV_CESA_CRYPTO_3DES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 key3des1, sizeof(key3des1),
+	 NULL, 0,
+	 "3DES ECB encode"}
+	,
+/*105*/ {-1, MV_CESA_CRYPTO_3DES, MV_CESA_CRYPTO_CBC,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 key3des2, sizeof(key3des2),
+	 NULL, 0,
+	 "3DES ECB encode"}
+	,
+/*106*/ {-1, MV_CESA_CRYPTO_3DES, MV_CESA_CRYPTO_CBC,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 key3des3, sizeof(key3des3),
+	 NULL, 0,
+	 "3DES ECB encode"}
+	,
+};
+
+static MV_CESA_TEST_SESSION aesTestSessions[] = {
+/*200*/ {-1, MV_CESA_CRYPTO_AES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey2, sizeof(cryptoKey2) / sizeof(cryptoKey2[0]),
+	 NULL, 0,
+	 "AES-128 ECB encode"}
+	,
+/*201*/ {-1, MV_CESA_CRYPTO_AES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 cryptoKey2, sizeof(cryptoKey2) / sizeof(cryptoKey2[0]),
+	 NULL, 0,
+	 "AES-128 ECB decode"}
+	,
+/*202*/ {-1, MV_CESA_CRYPTO_AES, MV_CESA_CRYPTO_CBC,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey5, sizeof(cryptoKey5) / sizeof(cryptoKey5[0]),
+	 NULL, 0,
+	 "AES-128 CBC encode"}
+	,
+/*203*/ {-1, MV_CESA_CRYPTO_AES, MV_CESA_CRYPTO_CBC,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 cryptoKey5, sizeof(cryptoKey5) / sizeof(cryptoKey5[0]),
+	 NULL, 0,
+	 "AES-128 CBC decode"}
+	,
+/*204*/ {-1, MV_CESA_CRYPTO_AES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey3, sizeof(cryptoKey3) / sizeof(cryptoKey3[0]),
+	 NULL, 0,
+	 "AES-192 ECB encode"}
+	,
+/*205*/ {-1, MV_CESA_CRYPTO_AES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 cryptoKey3, sizeof(cryptoKey3) / sizeof(cryptoKey3[0]),
+	 NULL, 0,
+	 "AES-192 ECB decode"}
+	,
+/*206*/ {-1, MV_CESA_CRYPTO_AES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey4, sizeof(cryptoKey4) / sizeof(cryptoKey4[0]),
+	 NULL, 0,
+	 "AES-256 ECB encode"}
+	,
+/*207*/ {-1, MV_CESA_CRYPTO_AES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 cryptoKey4, sizeof(cryptoKey4) / sizeof(cryptoKey4[0]),
+	 NULL, 0,
+	 "AES-256 ECB decode"}
+	,
+/*208*/ {-1, MV_CESA_CRYPTO_AES, MV_CESA_CRYPTO_CTR,
+	 MV_CESA_MAC_NULL, MV_CESA_CRYPTO_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 aesCtrKey, sizeof(aesCtrKey) / sizeof(aesCtrKey[0]),
+	 NULL, 0,
+	 "AES-128 CTR encode"}
+	,
+};
+
+static MV_CESA_TEST_SESSION md5TestSessions[] = {
+/*300*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_MD5, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 NULL, 0,
+	 mdKey1, sizeof(mdKey1),
+	 "HMAC-MD5 Generate Signature"}
+	,
+/*301*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_MD5, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 NULL, 0,
+	 mdKey1, sizeof(mdKey1),
+	 "HMAC-MD5 Verify Signature"}
+	,
+/*302*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_MD5, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 NULL, 0,
+	 mdKey2, sizeof(mdKey2),
+	 "HMAC-MD5 Generate Signature"}
+	,
+/*303*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_MD5, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 NULL, 0,
+	 mdKey2, sizeof(mdKey2),
+	 "HMAC-MD5 Verify Signature"}
+	,
+/*304*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_MD5, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 NULL, 0,
+	 mdKey4, sizeof(mdKey4),
+	 "HMAC-MD5 Generate Signature"}
+	,
+/*305*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_MD5, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 NULL, 0,
+	 NULL, 0,
+	 "HASH-MD5 Generate Signature"}
+	,
+};
+
+static MV_CESA_TEST_SESSION sha1TestSessions[] = {
+/*400*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_SHA1, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 NULL, 0,
+	 shaKey1, sizeof(shaKey1),
+	 "HMAC-SHA1 Generate Signature"}
+	,
+/*401*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_SHA1, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 NULL, 0,
+	 shaKey1, sizeof(shaKey1),
+	 "HMAC-SHA1 Verify Signature"}
+	,
+/*402*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_SHA1, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 NULL, 0,
+	 shaKey2, sizeof(shaKey2),
+	 "HMAC-SHA1 Generate Signature"}
+	,
+/*403*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_SHA1, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 NULL, 0,
+	 shaKey2, sizeof(shaKey2),
+	 "HMAC-SHA1 Verify Signature"}
+	,
+/*404*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_SHA1, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 NULL, 0,
+	 shaKey4, sizeof(shaKey4),
+	 "HMAC-SHA1 Generate Signature"}
+	,
+/*405*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_SHA1, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 NULL, 0,
+	 NULL, 0,
+	 "HASH-SHA1 Generate Signature"}
+	,
+};
+
+static MV_CESA_TEST_SESSION sha2TestSessions[] = {
+/*500*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_SHA2, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 NULL, 0,
+	 sha2Key1, sizeof(sha2Key1),
+	 "HMAC-SHA2 Generate Signature"}
+	,
+/*501*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_SHA2, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 NULL, 0,
+	 sha2Key1, sizeof(sha2Key1),
+	 "HMAC-SHA2 Verify Signature"}
+	,
+/*502*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_SHA2, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_ENCODE,
+	 NULL, 0,
+	 NULL, 0,
+	 "HASH-SHA2 Generate Signature"}
+	,
+/*503*/ {-1, MV_CESA_CRYPTO_NULL, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_SHA2, MV_CESA_MAC_ONLY,
+	 MV_CESA_DIR_DECODE,
+	 NULL, 0,
+	 NULL, 0,
+	 "HASH-SHA2 Verify Signature"}
+	,
+};
+
+static MV_CESA_TEST_SESSION combinedTestSessions[] = {
+/*600*/ {-1, MV_CESA_CRYPTO_DES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_MD5, MV_CESA_CRYPTO_THEN_MAC,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey1, MV_CESA_DES_KEY_LENGTH,
+	 mdKey4, sizeof(mdKey4),
+	 "DES + MD5 encode"}
+	,
+/*601*/ {-1, MV_CESA_CRYPTO_DES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_SHA1, MV_CESA_CRYPTO_THEN_MAC,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey1, MV_CESA_DES_KEY_LENGTH,
+	 shaKey4, sizeof(shaKey4),
+	 "DES + SHA1 encode"}
+	,
+/*602*/ {-1, MV_CESA_CRYPTO_3DES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_MD5, MV_CESA_CRYPTO_THEN_MAC,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey1, sizeof(cryptoKey1) / sizeof(cryptoKey1[0]),
+	 mdKey4, sizeof(mdKey4),
+	 "3DES + MD5 encode"}
+	,
+/*603*/ {-1, MV_CESA_CRYPTO_3DES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_SHA1, MV_CESA_CRYPTO_THEN_MAC,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey1, sizeof(cryptoKey1) / sizeof(cryptoKey1[0]),
+	 shaKey4, sizeof(shaKey4),
+	 "3DES + SHA1 encode"}
+	,
+/*604*/ {-1, MV_CESA_CRYPTO_3DES, MV_CESA_CRYPTO_CBC,
+	 MV_CESA_MAC_HMAC_MD5, MV_CESA_CRYPTO_THEN_MAC,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey1, sizeof(cryptoKey1) / sizeof(cryptoKey1[0]),
+	 mdKey4, sizeof(mdKey4),
+	 "3DES CBC + MD5 encode"}
+	,
+/*605*/ {-1, MV_CESA_CRYPTO_3DES, MV_CESA_CRYPTO_CBC,
+	 MV_CESA_MAC_HMAC_SHA1, MV_CESA_CRYPTO_THEN_MAC,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey1, sizeof(cryptoKey1) / sizeof(cryptoKey1[0]),
+	 shaKey4, sizeof(shaKey4),
+	 "3DES CBC + SHA1 encode"}
+	,
+/*606*/ {-1, MV_CESA_CRYPTO_AES, MV_CESA_CRYPTO_CBC,
+	 MV_CESA_MAC_HMAC_MD5, MV_CESA_CRYPTO_THEN_MAC,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey5, sizeof(cryptoKey5) / sizeof(cryptoKey5[0]),
+	 mdKey4, sizeof(mdKey4),
+	 "AES-128 CBC + MD5 encode"}
+	,
+/*607*/ {-1, MV_CESA_CRYPTO_AES, MV_CESA_CRYPTO_CBC,
+	 MV_CESA_MAC_HMAC_SHA1, MV_CESA_CRYPTO_THEN_MAC,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey5, sizeof(cryptoKey5) / sizeof(cryptoKey5[0]),
+	 shaKey4, sizeof(shaKey4),
+	 "AES-128 CBC + SHA1 encode"}
+	,
+/*608*/ {-1, MV_CESA_CRYPTO_3DES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_MD5, MV_CESA_MAC_THEN_CRYPTO,
+	 MV_CESA_DIR_DECODE,
+	 cryptoKey1, sizeof(cryptoKey1) / sizeof(cryptoKey1[0]),
+	 mdKey4, sizeof(mdKey4),
+	 "HMAC-MD5 + 3DES decode"}
+	,
+/*609*/ {-1, MV_CESA_CRYPTO_AES, MV_CESA_CRYPTO_ECB,
+	 MV_CESA_MAC_HMAC_SHA2, MV_CESA_CRYPTO_THEN_MAC,
+	 MV_CESA_DIR_ENCODE,
+	 cryptoKey2, sizeof(cryptoKey2) / sizeof(cryptoKey2[0]),
+	 sha2Key1, sizeof(sha2Key1),
+	 "AES-128 CBC + SHA2 encode"}
+	,
+};
+
+static MV_CESA_TEST_DB_ENTRY cesaTestsDB[MAX_TEST_TYPE + 1] = {
+	{desTestSessions, sizeof(desTestSessions) / sizeof(desTestSessions[0])}
+	,
+	{tripleDesTestSessions, sizeof(tripleDesTestSessions) / sizeof(tripleDesTestSessions[0])}
+	,
+	{aesTestSessions, sizeof(aesTestSessions) / sizeof(aesTestSessions[0])}
+	,
+	{md5TestSessions, sizeof(md5TestSessions) / sizeof(md5TestSessions[0])}
+	,
+	{sha1TestSessions, sizeof(sha1TestSessions) / sizeof(sha1TestSessions[0])}
+	,
+	{sha2TestSessions, sizeof(sha2TestSessions) / sizeof(sha2TestSessions[0])}
+	,
+	{combinedTestSessions, sizeof(combinedTestSessions) / sizeof(combinedTestSessions[0])}
+	,
+	{NULL, 0}
+};
+
+char cesaNullPlainHexText[] = "000000000000000000000000000000000000000000000000";
+
+char cesaPlainAsciiText[] = "Now is the time for all ";
+char cesaPlainHexEbc[] = "4e6f77206973207468652074696d6520666f7220616c6c20";
+char cesaCipherHexEcb[] = "3fa40e8a984d48156a271787ab8883f9893d51ec4b563b53";
+char cesaPlainHexCbc[] = "1234567890abcdef4e6f77206973207468652074696d6520666f7220616c6c20";
+char cesaCipherHexCbc[] = "1234567890abcdefe5c7cdde872bf27c43e934008c389c0f683788499a7c05f6";
+
+char cesaAesPlainHexEcb[] = "000102030405060708090a0b0c0d0e0f";
+char cesaAes128cipherHexEcb[] = "0a940bb5416ef045f1c39458c653ea5a";
+char cesaAes192cipherHexEcb[] = "0060bffe46834bb8da5cf9a61ff220ae";
+char cesaAes256cipherHexEcb[] = "5a6e045708fb7196f02e553d02c3a692";
+
+char cesaAsciiStr1[] = "Hi There";
+char cesaDataHexStr1[] = "4869205468657265";
+char cesaHmacMd5digestHex1[] = "9294727a3638bb1c13f48ef8158bfc9d";
+char cesaHmacSha1digestHex1[] = "b617318655057264e28bc0b6fb378c8ef146be00";
+char cesaHmacSha2digestHex1[] = "a28cf43130ee696a98f14a37678b56bcfcbdd9e5cf69717fecf5480f0ebdf790";
+char cesaDataAndMd5digest1[] = "48692054686572659294727a3638bb1c13f48ef8158bfc9d";
+char cesaDataAndSha1digest1[] = "4869205468657265b617318655057264e28bc0b6fb378c8ef146be00";
+char cesaDataAndSha2digest1[] = "53616D706C65206D65737361676520666F72206B65796C656E3C626C6F636B6C656E"
+				"000000000000" "a28cf43130ee696a98f14a37678b56bcfcbdd9e5cf69717fecf5480f0ebdf790";
+
+char cesaAesPlainText[] = "a0a1a2a3a4a5a6a7a8a9aaabacadaeaf"
+    "b0b1b2b3b4b5b6b7b8b9babbbcbdbebf" "c0c1c2c3c4c5c6c7c8c9cacbcccdcecf" "d0d1d2d3d4d5d6d7d8d9dadbdcdddedf";
+
+char cesaAes128CipherCbc[] = "c30e32ffedc0774e6aff6af0869f71aa"
+    "0f3af07a9a31a9c684db207eb0ef8e4e" "35907aa632c3ffdf868bb7b29d3d46ad" "83ce9f9a102ee99d49a53e87f4c3da55";
+
+char cesaAesIvPlainText[] = "8ce82eefbea0da3c44699ed7db51b7d9"
+    "a0a1a2a3a4a5a6a7a8a9aaabacadaeaf"
+    "b0b1b2b3b4b5b6b7b8b9babbbcbdbebf" "c0c1c2c3c4c5c6c7c8c9cacbcccdcecf" "d0d1d2d3d4d5d6d7d8d9dadbdcdddedf";
+
+char cesaAes128IvCipherCbc[] = "8ce82eefbea0da3c44699ed7db51b7d9"
+    "c30e32ffedc0774e6aff6af0869f71aa"
+    "0f3af07a9a31a9c684db207eb0ef8e4e" "35907aa632c3ffdf868bb7b29d3d46ad" "83ce9f9a102ee99d49a53e87f4c3da55";
+
+char cesaAesCtrPlain[] = "00E0017B27777F3F4A1786F000000001"
+    "000102030405060708090A0B0C0D0E0F" "101112131415161718191A1B1C1D1E1F" "20212223";
+
+char cesaAesCtrCipher[] = "00E0017B27777F3F4A1786F000000001"
+    "C1CF48A89F2FFDD9CF4652E9EFDB72D7" "4540A42BDE6D7836D59A5CEAAEF31053" "25B2072F";
+
+/* Input cesaHmacHex3 is '0xdd' repeated 50 times */
+char cesaHmacMd5digestHex3[] = "56be34521d144c88dbb8c733f0e8b3f6";
+char cesaHmacSha1digestHex3[] = "125d7342b9ac11cd91a39af48aa17b4f63f175d3";
+char cesaDataHexStr3[50 * 2 + 1] = "";
+char cesaDataAndMd5digest3[sizeof(cesaDataHexStr3) + sizeof(cesaHmacMd5digestHex3) + 8 * 2 + 1] = "";
+char cesaDataAndSha1digest3[sizeof(cesaDataHexStr3) + sizeof(cesaHmacSha1digestHex3) + 8 * 2 + 1] = "";
+char cesaDataAndSha2digest3[] = "6162630000000000"
+				"ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad";
+
+/* Ascii string is "abc" */
+char hashHexStr3[] = "616263";
+char hashMd5digest3[] = "900150983cd24fb0d6963f7d28e17f72";
+char hashSha1digest3[] = "a9993e364706816aba3e25717850c26c9cd0d89d";
+char hashSha2digest3[] = "ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad";
+
+char hashHexStr80[] = "31323334353637383930"
+    "31323334353637383930"
+    "31323334353637383930"
+    "31323334353637383930" "31323334353637383930" "31323334353637383930" "31323334353637383930" "31323334353637383930";
+
+char hashMd5digest80[] = "57edf4a22be3c955ac49da2e2107b67a";
+
+char tripleDesThenMd5digest80[] = "b7726a03aad490bd6c5a452a89a1b271";
+char tripleDesThenSha1digest80[] = "b2ddeaca91030eab5b95a234ef2c0f6e738ff883";
+
+char cbc3desThenMd5digest80[] = "6f463057e1a90e0e91ae505b527bcec0";
+char cbc3desThenSha1digest80[] = "1b002ed050be743aa98860cf35659646bb8efcc0";
+
+char cbcAes128ThenMd5digest80[] = "6b6e863ac5a71d15e3e9b1c86c9ba05f";
+char cbcAes128ThenSha1digest80[] = "13558472d1fc1c90dffec6e5136c7203452d509b";
+
+char cesaDataHexStr4[] = "53616D706C65206D65737361676520666F72206B65796C656E3C626C6F636B6C656E";
+char aes128EcbThenHmacSha2[] = "631cb14ab7f43a46c7517a32f793d64c8a7814ebfb32294b9d20f2f79eb6baba";
+
+static MV_CESA_TEST_CASE cesaTestCases[] = {
+/*     plainHexStr          cipherHexStr               IV    crypto  mac     digest */
+/*                                                           Length  Length  Offset */
+/*0 */ {NULL, NULL, NULL, 0, 0, -1},
+/*1 */ {cesaPlainHexEbc, cesaCipherHexEcb, NULL, 24, 0, -1},
+/*2 */ {cesaPlainHexCbc, cesaCipherHexCbc, NULL, 24, 0, -1},
+/*3 */ {cesaAesPlainHexEcb, cesaAes128cipherHexEcb, NULL, 16, 0, -1},
+/*4 */ {cesaAesPlainHexEcb, cesaAes192cipherHexEcb, NULL, 16, 0, -1},
+/*5 */ {cesaAesPlainHexEcb, cesaAes256cipherHexEcb, NULL, 16, 0, -1},
+/*6 */ {cesaDataHexStr1, cesaHmacMd5digestHex1, NULL, 0, 8, -1},
+/*7 */ {NULL, cesaDataAndMd5digest1, NULL, 0, 8, -1},
+/*8 */ {cesaDataHexStr3, cesaHmacMd5digestHex3, NULL, 0, 50, -1},
+/*9 */ {NULL, cesaDataAndMd5digest3, NULL, 0, 50, -1},
+/*10*/ {cesaAesPlainText, cesaAes128IvCipherCbc, iv5, 64, 0, -1},
+/*11*/ {cesaDataHexStr1, cesaHmacSha1digestHex1, NULL, 0, 8, -1},
+/*12*/ {NULL, cesaDataAndSha1digest1, NULL, 0, 8, -1},
+/*13*/ {cesaDataHexStr3, cesaHmacSha1digestHex3, NULL, 0, 50, -1},
+/*14*/ {NULL, cesaDataAndSha1digest3, NULL, 0, 50, -1},
+/*15*/ {hashHexStr3, hashMd5digest3, NULL, 0, 3, -1},
+/*16*/ {hashHexStr3, hashSha1digest3, NULL, 0, 3, -1},
+/*17*/ {hashHexStr80, tripleDesThenMd5digest80, NULL, 80, 80, -1},
+/*18*/ {hashHexStr80, tripleDesThenSha1digest80, NULL, 80, 80, -1},
+/*19*/ {hashHexStr80, cbc3desThenMd5digest80, iv1, 80, 80, -1},
+/*20*/ {hashHexStr80, cbc3desThenSha1digest80, iv1, 80, 80, -1},
+/*21*/ {hashHexStr80, cbcAes128ThenMd5digest80, iv5, 80, 80, -1},
+/*22*/ {hashHexStr80, cbcAes128ThenSha1digest80, iv5, 80, 80, -1},
+/*23*/ {cesaAesCtrPlain, cesaAesCtrCipher, NULL, 36, 0, -1},
+/*24*/ {cesaAesIvPlainText, cesaAes128IvCipherCbc, NULL, 64, 0, -1},
+/*25*/ {plain3des1, cipher3des1, NULL, 0, 0, -1},
+/*26*/ {plain3des2, cipher3desCbc2, iv3des2, 0, 0, -1},
+/*27*/ {plain3des3, cipher3desCbc3, iv3des3, 0, 0, -1},
+/*28*/ {cesaDataHexStr4, cesaHmacSha2digestHex1, NULL, 0, 34, -1},
+/*29*/ {NULL, cesaDataAndSha2digest1, NULL, 0, 34, -1},
+/*30*/ {hashHexStr3, hashSha2digest3, NULL, 0, 3, -1},
+/*31*/ {NULL, cesaDataAndSha2digest3, NULL, 0, 3, -1},
+/*32*/ {cesaAesPlainHexEcb, aes128EcbThenHmacSha2, NULL, 16, 16, -1},
+};
+
+/* Key         = 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa,
+ *               0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa
+ * Input 0xdd repeated "size" times
+ */
+static MV_CESA_SIZE_TEST mdMultiSizeTest302[] = {
+	{80, "7a031a640c14a4872814930b1ef3a5b2"},
+	{512, "5488e6c5a14dc72a79f28312ca5b939b"},
+	{1000, "d00814f586a8b78a05724239d2531821"},
+	{1001, "bf07df7b7f49d3f5b5ecacd4e9e63281"},
+	{1002, "1ed4a1a802e87817a819d4e37bb4d0f7"},
+	{1003, "5972ab64a4f265ee371dac2f2f137f90"},
+	{1004, "71f95e7ec3aa7df2548e90898abdb28e"},
+	{1005, "e082790b4857fcfc266e92e59e608814"},
+	{1006, "9500f02fd8ac7fde8b10e4fece9a920d"},
+	{1336, "e42edcce57d0b75b01aa09d71427948b"},
+	{1344, "bb5454ada0deb49ba0a97ffd60f57071"},
+	{1399, "0f44d793e744b24d53f44f295082ee8c"},
+	{1400, "359de8a03a9b707928c6c60e0e8d79f1"},
+	{1401, "e913858b484cbe2b384099ea88d8855b"},
+	{1402, "d9848a164af53620e0540c1d7d87629e"},
+	{1403, "0c9ee1c2c9ef45e9b625c26cbaf3e822"},
+	{1404, "12edd4f609416e3c936170360561b064"},
+	{1405, "7fc912718a05446395345009132bf562"},
+	{1406, "882f17425e579ff0d85a91a59f308aa0"},
+	{1407, "005cae408630a2fb5db82ad9db7e59da"},
+	{1408, "64655f8b404b3fea7a3e3e609bc5088f"},
+	{1409, "4a145284a7f74e01b6bb1a0ec6a0dd80"},
+	{2048, "67caf64475650732def374ebb8bde3fd"},
+	{2049, "6c84f11f472825f7e6cd125c2981884b"},
+	{2050, "8999586754a73a99efbe4dbad2816d41"},
+	{2051, "ba6946b610e098d286bc81091659dfff"},
+	{2052, "d0afa01c92d4d13def2b024f36faed83"},
+	{3072, "61d8beac61806afa2585d74a9a0e6974"},
+	{3074, "f6501a28dcc24d1e4770505c51a87ed3"},
+	{3075, "ea4a6929be67e33e61ff475369248b73"},
+	{4048, "aa8c4d68f282a07e7385acdfa69f4bed"},
+	{4052, "afb5ed2c0e1d430ea59e59ed5ed6b18a"},
+	{4058, "9e8553f9bdd43aebe0bd729f0e600c99"},
+	{6144, "f628f3e5d183fe5cdd3a5abee39cf872"},
+	{6150, "89a3efcea9a2f25f919168ad4a1fd292"},
+	{6400, "cdd176b7fb747873efa4da5e32bdf88f"},
+	{6528, "b1d707b027354aca152c45ee559ccd3f"},
+	{8192, "c600ea4429ac47f9941f09182166e51a"},
+	{16384, "16e8754bfbeb4c649218422792267a37"},
+	{18432, "0fd0607521b0aa8b52219cfbe215f63e"},
+	{0, NULL},
+};
+
+/* Key         = 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08,
+ *               0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, 0x10
+ * InputHexStr = "31323334353637383930" (ASCII = "1234567890")
+ */
+static MV_CESA_SIZE_TEST mdMultiSizeTest304[] = {
+	{80, "a456c4723fee6068530af5a2afa71627"},
+	{512, "f85c2a2344f5de68b432208ad13e5794"},
+	{1000, "35464d6821fd4a293a41eb84e274c8c5"},
+	{1001, "c08eedbdce60cceb54bc2d732bb32c8b"},
+	{1002, "5664f71800c011cc311cb6943339c1b8"},
+	{1003, "779c723b044c585dc7802b13e8501bdc"},
+	{1004, "55e500766a2c307bc5c5fdd15e4cacd4"},
+	{1005, "d5f978954f5c38529d1679d2b714f068"},
+	{1006, "cd3efc827ce628b7281b72172693abf9"},
+	{1336, "6f04479910785878ae6335b8d1e87edf"},
+	{1344, "b6d27b50c2bce1ba2a8e1b5cc4324368"},
+	{1399, "65f70a1d4c86e5eaeb0704c8a7816795"},
+	{1400, "3394b5adc4cb3ff98843ca260a44a88a"},
+	{1401, "3a06f3582033a66a4e57e0603ce94e74"},
+	{1402, "e4d97f5ed51edc48abfa46eeb5c31752"},
+	{1403, "3d05e40b080ee3bedf293cb87b7140e7"},
+	{1404, "8cf294fc3cd153ab18dccb2a52cbf244"},
+	{1405, "d1487bd42f6edd9b4dab316631159221"},
+	{1406, "0527123b6bf6936cf5d369dc18c6c70f"},
+	{1407, "3224a06639db70212a0cd1ae1fcc570a"},
+	{1408, "a9e13335612c0356f5e2c27086e86c43"},
+	{1409, "a86d1f37d1ed8a3552e9a4f04dceea98"},
+	{2048, "396905c9b961cd0f6152abfb69c4449c"},
+	{2049, "49f39bff85d9dcf059fadb89efc4a70f"},
+	{2050, "3a2b4823bc4d0415656550226a63e34a"},
+	{2051, "dec60580d406c782540f398ad0bcc7e0"},
+	{2052, "32f76610a14310309eb748fe025081bf"},
+	{3072, "45edc1a42bf9d708a621076b63b774da"},
+	{3074, "9be1b333fe7c0c9f835fb369dc45f778"},
+	{3075, "8c06fcac7bd0e7b7a17fd6508c09a549"},
+	{4048, "0ddaef848184bf0ad98507a10f1e90e4"},
+	{4052, "81976bcaeb274223983996c137875cb8"},
+	{4058, "0b0a7a1c82bc7cbc64d8b7cd2dc2bb22"},
+	{6144, "1c24056f52725ede2dff0d7f9fc9855f"},
+	{6150, "b7f4b65681c4e43ee68ca466ca9ca4ec"},
+	{6400, "443bbaab9f7331ddd4bf11b659cd43c8"},
+	{6528, "216f44f23047cfee03a7a64f88f9a995"},
+	{8192, "ac7a993b2cad54879dba1bde63e39097"},
+	{8320, "55ed7be9682d6c0025b3221a62088d08"},
+	{16384, "c6c722087653b62007aea668277175e5"},
+	{18432, "f1faca8e907872c809e14ffbd85792d6"},
+	{0, NULL},
+};
+
+/* HASH-MD5
+ * InputHexStr = "31323334353637383930" (ASCII = "1234567890")
+ *               repeated "size" times
+ */
+static MV_CESA_SIZE_TEST mdMultiSizeTest305[] = {
+	{80, "57edf4a22be3c955ac49da2e2107b67a"},
+	{512, "c729ae8f0736cc377a9767a660eaa04e"},
+	{1000, "f1257a8659eb92d36fe14c6bf3852a6a"},
+	{1001, "f8a46fe8ea04fdc8c7de0e84042d3878"},
+	{1002, "da188dd67bff87d58aa3c02af2d0cc0f"},
+	{1003, "961753017feee04c9b93a8e51658a829"},
+	{1004, "dd68c4338608dcc87807a711636bf2af"},
+	{1005, "e338d567d3ce66bf69ada29658a8759b"},
+	{1006, "443c9811e8b92599b0b149e8d7ec700a"},
+	{1336, "89a98511706008ba4cbd0b4a24fa5646"},
+	{1344, "335a919805f370b9e402a62c6fe01739"},
+	{1399, "5d18d0eddcd84212fe28d812b5e80e3b"},
+	{1400, "6b695c240d2dffd0dffc99459ca76db6"},
+	{1401, "49590f61298a76719bc93a57a30136f5"},
+	{1402, "94c2999fa3ef1910a683d69b2b8476f2"},
+	{1403, "37073a02ab00ecba2645c57c228860db"},
+	{1404, "1bcd06994fce28b624f0c5fdc2dcdd2b"},
+	{1405, "11b93671a64c95079e8cf9e7cddc8b3d"},
+	{1406, "4b6695772a4c66313fa4871017d05f36"},
+	{1407, "d1539b97fbfda1c075624e958de19c5b"},
+	{1408, "b801b9b69920907cd018e8063092ede9"},
+	{1409, "b765f1406cfe78e238273ed01bbcaf7e"},
+	{2048, "1d7e2c64ac29e2b3fb4c272844ed31f5"},
+	{2049, "71d38fac49c6b1f4478d8d88447bcdd0"},
+	{2050, "141c34a5592b1bebfa731e0b23d0cdba"},
+	{2051, "c5e1853f21c59f5d6039bd13d4b380d8"},
+	{2052, "dd44a0d128b63d4b5cccd967906472d7"},
+	{3072, "37d158e33b21390822739d13db7b87fe"},
+	{3074, "aef3b209d01d39d0597fe03634bbf441"},
+	{3075, "335ffb428eabf210bada96d74d5a4012"},
+	{4048, "2434c2b43d798d2819487a886261fc64"},
+	{4052, "ac2fa84a8a33065b2e92e36432e861f8"},
+	{4058, "856781f85616c341c3533d090c1e1e84"},
+	{6144, "e5d134c652c18bf19833e115f7a82e9b"},
+	{6150, "a09a353be7795fac2401dac5601872e6"},
+	{6400, "08b9033ac6a1821398f50af75a2dbc83"},
+	{6528, "3d47aa193a8540c091e7e02f779e6751"},
+	{8192, "d3164e710c0626f6f395b38f20141cb7"},
+	{8320, "b727589d9183ff4e8491dd24466974a3"},
+	{16384, "3f54d970793d2274d5b20d10a69938ac"},
+	{18432, "f558511dcf81985b7a1bb57fad970531"},
+	{0, NULL},
+};
+
+/* Key         = 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa,
+ *               0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa
+ *               0xaa, 0xaa, 0xaa, 0xaa
+ * InputHexStr = "31323334353637383930" (ASCII = "1234567890")
+ */
+static MV_CESA_SIZE_TEST sha1MultiSizeTest402[] = {
+	{80, "e812f370e659705a1649940d1f78cd7af18affd3"},
+	{512, "e547f886b2c15d995ed76a8a924cb408c8080f66"},
+	{1000, "239443194409f1a5342ecde1a092c8f3a3ed790a"},
+	{1001, "f278ab9a102850a9f48dc4e9e6822afe2d0c52b5"},
+	{1002, "8bcc667df5ab6ece988b3af361d09747c77f4e72"},
+	{1003, "0fae6046c7dc1d3e356b25af836f6077a363f338"},
+	{1004, "0ea48401cc92ae6bc92ae76685269cb0167fbe1a"},
+	{1005, "ecbcd7c879b295bafcd8766cbeac58cc371e31d1"},
+	{1006, "eb4a4a3d07d1e9a15e6f1ab8a9c47f243e27324c"},
+	{1336, "f5950ee1d77c10e9011d2149699c9366fe52529c"},
+	{1344, "b04263604a63c351b0b3b9cf1785b4bdba6c8838"},
+	{1399, "8cb1cff61d5b784045974a2fc69386e3b8d24218"},
+	{1400, "9bb2f3fcbeddb2b90f0be797cd647334a2816d51"},
+	{1401, "23ae462a7a0cb440f7445791079a5d75a535dd33"},
+	{1402, "832974b524a4d3f9cc2f45a3cabf5ccef65cd2aa"},
+	{1403, "d1c683742fe404c3c20d5704a5430e7832a7ec95"},
+	{1404, "867c79042e64f310628e219d8b85594cd0c7adc3"},
+	{1405, "c9d81d49d13d94358f56ccfd61af02b36c69f7c3"},
+	{1406, "0df43daab2786172f9b8d07d61f14a070cf1287a"},
+	{1407, "0fd8f3ad7f169534b274d4c66bbddd89f759e391"},
+	{1408, "3987511182b18473a564436003139b808fa46343"},
+	{1409, "ef667e063c9e9f539a8987a8d0bd3066ee85d901"},
+	{2048, "921109c99f3fedaca21727156d5f2b4460175327"},
+	{2049, "47188600dd165eb45f27c27196d3c46f4f042c1b"},
+	{2050, "8831939904009338de10e7fa670847041387807d"},
+	{2051, "2f8ebb5db2997d614e767be1050366f3641e7520"},
+	{2052, "669e51cd730dae158d3bef8adba075bd95a0d011"},
+	{3072, "cfee66cfd83abc8451af3c96c6b35a41cc6c55f5"},
+	{3074, "216ea26f02976a261b7d21a4dd3085157bedfabd"},
+	{3075, "bd612ebba021fd8e012b14c3bd60c8c5161fabc0"},
+	{4048, "c2564c1fdf2d5e9d7dde7aace2643428e90662e8"},
+	{4052, "91ce61fe924b445dfe7b5a1dcd10a27caec16df6"},
+	{4058, "db2a9be5ee8124f091c7ebd699266c5de223c164"},
+	{6144, "855109903feae2ba3a7a05a326b8a171116eb368"},
+	{6150, "37520bb3a668294d9c7b073e7e3daf8fee248a78"},
+	{6400, "60a353c841b6d2b1a05890349dad2fa33c7536b7"},
+	{6528, "9e53a43a69bb42d7c8522ca8bd632e421d5edb36"},
+	{8192, "a918cb0da862eaea0a33ee0efea50243e6b4927c"},
+	{8320, "29a5dcf55d1db29cd113fcf0572ae414f1c71329"},
+	{16384, "6fb27966138e0c8d5a0d65ace817ebd53633cee1"},
+	{18432, "ca09900d891c7c9ae2a559b10f63a217003341c1"},
+	{0, NULL},
+};
+
+/* Key         = 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08,
+ *               0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, 0x10
+ *               0x11, 0x12, 0x13, 0x14
+ * InputHexStr = "31323334353637383930" (ASCII = "1234567890")
+ */
+static MV_CESA_SIZE_TEST sha1MultiSizeTest404[] = {
+	{80, "beaf20a34b06a87558d156c0949bc3957d40222e"},
+	{512, "3353955358d886bc2940a3c7f337ff7dafb59c7b"},
+	{1000, "8737a542c5e9b2b6244b757ebb69d5bd602a829f"},
+	{1001, "fd9e7582d8a5d3c9fe3b923e4e6a41b07a1eb4d4"},
+	{1002, "a146d14a6fc3c274ff600568f4d75b977989e00d"},
+	{1003, "be22601bbc027ddef2dec97d30b3dc424fd803c5"},
+	{1004, "3e71fe99b2fe2b7bfdf4dbf0c7f3da25d7ea35e7"},
+	{1005, "2c422735d7295408fddd76f5e8a83a2a8da13df3"},
+	{1006, "6d875319049314b61855101a647b9ba3313428e6"},
+	{1336, "c1631ea80bad9dc43a180712461b65a0598c711c"},
+	{1344, "816069bf91d34581005746e2e0283d0f9c7b7605"},
+	{1399, "4e139866dc61cfcb8b67ca2ebd637b3a538593af"},
+	{1400, "ff2a0f8dd2b02c5417910f6f55d33a78e081a723"},
+	{1401, "ab00c12be62336964cbce31ae97fe2a0002984d5"},
+	{1402, "61349e7f999f3a1acc56c3e9a5060a9c4a7b05b6"},
+	{1403, "3edbc0f61e435bc1317fa27d840076093fb79353"},
+	{1404, "d052c6dfdbe63d45dab23ef9893e2aa4636aca1e"},
+	{1405, "0cc16b7388d67bf0add15a31e6e6c753cfae4987"},
+	{1406, "c96ba7eaad74253c38c22101b558d2850b1d1b90"},
+	{1407, "3445428a40d2c6556e7c55797ad8d323b61a48d9"},
+	{1408, "8d6444f937a09317c89834187b8ea9b8d3a8c56b"},
+	{1409, "c700acd3ecd19014ea2bdb4d42510c467e088475"},
+	{2048, "ee27d2a0cb77470c2f496212dfd68b5bb7b04e4b"},
+	{2049, "683762d7a02983b26a6d046e6451d9cd82c25932"},
+	{2050, "0fd20f1d55a9ee18363c2a6fd54aa13aee69992f"},
+	{2051, "86c267d8cc4bc8d59090e4f8b303da960fd228b7"},
+	{2052, "452395ae05b3ec503eea34f86fc0832485ad97c1"},
+	{3072, "75198e3cfd0b9bcff2dabdf8e38e6fdaa33ca49a"},
+	{3074, "4e24785ef080141ce4aab4675986d9acea624d7c"},
+	{3075, "3a20c5978dd637ec0e809bf84f0d9ccf30bc65bf"},
+	{4048, "3c32da256be7a7554922bf5fed51b0d2d09e59ad"},
+	{4052, "fff898426ea16e54325ae391a32c6c9bce4c23c0"},
+	{4058, "c800b9e562e1c91e1310116341a3c91d37f848ec"},
+	{6144, "d91d509d0cc4376c2d05bf9a5097717a373530e6"},
+	{6150, "d957030e0f13c5df07d9eec298542d8f94a07f12"},
+	{6400, "bb745313c3d7dc17b3f955e5534ad500a1082613"},
+	{6528, "77905f80d9ca82080bbb3e5654896dabfcfd1bdb"},
+	{8192, "5237fd9a81830c974396f99f32047586612ff3c0"},
+	{8320, "57668e28d5f2dba0839518a11db0f6af3d7e08bf"},
+	{16384, "62e093fde467f0748087beea32e9af97d5c61241"},
+	{18432, "845fb33130c7d6ea554fd5aacb9c50cf7ccb5929"},
+	{0, NULL},
+};
+
+/* HASH-SHA1
+ * InputHexStr = "31323334353637383930" (ASCII = "1234567890")
+ *               repeated "size" times
+ */
+static MV_CESA_SIZE_TEST sha1MultiSizeTest405[] = {
+	{80, "50abf5706a150990a08b2c5ea40fa0e585554732"},
+	{512, "f14516a08948fa27917a974d219741a697ba0087"},
+	{1000, "0bd18c378d5788817eb4f1e5dc07d867efa5cbf4"},
+	{1001, "ca29b85c35db1b8aef83c977893a11159d1b7aa2"},
+	{1002, "d83bc973eaaedb8a31437994dabbb3304b0be086"},
+	{1003, "2cf7bbef0acd6c00536b5c58ca470df9a3a90b6c"},
+	{1004, "e4375d09b1223385a8a393066f8209acfd936a80"},
+	{1005, "1029b38043e027745d019ce1d2d68e3d8b9d8f99"},
+	{1006, "deea16dcebbd8ac137e2b984deb639b9fb5e9680"},
+	{1336, "ea031b065fff63dcfb6a41956e4777520cdbc55d"},
+	{1344, "b52096c6445e6c0a8355995c70dc36ae186c863c"},
+	{1399, "cde2f6f8379870db4b32cf17471dc828a8dbff2b"},
+	{1400, "e53ff664064bc09fe5054c650806bd42d8179518"},
+	{1401, "d1156db5ddafcace64cdb510ff0d4af9b9a8ad64"},
+	{1402, "34ede0e9a909dd84a2ae291539105c0507b958e1"},
+	{1403, "a772ca3536da77e6ad3251e4f9e1234a4d7b87c0"},
+	{1404, "29740fd2b04e7a8bfd32242db6233156ad699948"},
+	{1405, "65b17397495b70ce4865dad93bf991b74c97cce1"},
+	{1406, "a7ee89cd0754061fdb91af7ea6abad2c69d542e3"},
+	{1407, "3eebf82f7420188e23d328b7ce93580b279a5715"},
+	{1408, "e08d3363a8b9a490dfb3a4c453452b8f114deeec"},
+	{1409, "95d74df739181a4ff30b8c39e28793a36598e924"},
+	{2048, "aa40262509c2abf84aab0197f83187fc90056d91"},
+	{2049, "7dec28ef105bc313bade8d9a7cdeac58b99de5ea"},
+	{2050, "d2e30f77ec81197de20f56588a156094ecb88450"},
+	{2051, "6b22ccc874833e96551a39da0c0edcaa0d969d92"},
+	{2052, "f843141e57875cd669af58744bc60aa9ea59549c"},
+	{3072, "09c5fedeaa62c132e673cc3c608a00142273d086"},
+	{3074, "b09e95eea9c7b1b007a58accec488301901a7f3d"},
+	{3075, "e6226b77b4ada287a8c9bbcf4ed71eec5ce632dc"},
+	{4048, "e99394894f855821951ddddf5bfc628547435f5c"},
+	{4052, "32d2f1af38be9cfba6cd03d55a254d0b3e1eb382"},
+	{4058, "d906552a4f2aca3a22e1fecccbcd183d7289d0ef"},
+	{6144, "2e7f62d35a860988e1224dc0543204af19316041"},
+	{6150, "d6b89698ee133df46fec9d552fadc328aa5a1b51"},
+	{6400, "dff50e90c46853988fa3a4b4ce5dda6945aae976"},
+	{6528, "9e63ec0430b96db02d38bc78357a2f63de2ab7f8"},
+	{8192, "971eb71ed60394d5ab5abb12e88420bdd41b5992"},
+	{8320, "91606a31b46afeaac965cecf87297e791b211013"},
+	{16384, "547f830a5ec1f5f170ce818f156b1002cabc7569"},
+	{18432, "f16f272787f3b8d539652e4dc315af6ab4fda0ef"},
+	{0, NULL},
+};
+
+/* CryptoKey   = 0x01234567, 0x89abcdef,
+ *               0x01234567, 0x89abcdef,
+ *               0x01234567, 0x89abcdef;
+ * MacKey      = 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08,
+ *               0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, 0x10
+ * InputHexStr = "31323334353637383930" (ASCII = "1234567890")
+ * Note: only sizes aligned to 3DES block size (8 bytes) allowed
+ */
+static MV_CESA_SIZE_TEST tripleDesMdMultiSizeTest602[] = {
+	{64, "9586962a2aaaef28803dec2e17807a7f"},
+	{80, "b7726a03aad490bd6c5a452a89a1b271"},
+	{352, "f1ed9563aecc3c0d2766eb2bed3b4e4c"},
+	{512, "0f9decb11ab40fe86f4d4d9397bc020e"},
+	{1000, "3ba69deac12cab8ff9dff7dbd9669927"},
+	{1336, "6cf47bf1e80e03e2c1d0945bc50d37d2"},
+	{1344, "4be388dab21ceb3fa1b8d302e9b821f7"},
+	{1400, "a58b79fb21dd9bfc6ec93e3b99fb0ef1"},
+	{1408, "8bc97379fc2ac3237effcdd4f7a86528"},
+	{2048, "1339f03ab3076f25a20bc4cba16eb5bf"},
+	{3072, "731204d2d90c4b36ae41f5e1fb874288"},
+	{4048, "c028d998cfda5642547b7e1ed5ea16e4"},
+	{6144, "b1b19cd910cc51bd22992f1e59f1e068"},
+	{6400, "44e4613496ba622deb0e7cb768135a2f"},
+	{6528, "3b06b0a86f8db9cd67f9448dfcf10549"},
+	{8192, "d581780b7163138a0f412be681457d82"},
+	{16384, "03b8ac05527faaf1bed03df149c65ccf"},
+	{18432, "677c8a86a41dab6c5d81b85b8fb10ff6"},
+	{0, NULL},
+};
+
+/* CryptoKey   = 0x01234567, 0x89abcdef,
+ *               0x01234567, 0x89abcdef,
+ *               0x01234567, 0x89abcdef;
+ * MacKey      = 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08,
+ *               0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, 0x10
+ *               0x11, 0x12, 0x13, 0x14
+ * InputHexStr = "31323334353637383930" (ASCII = "1234567890")
+ * Note: only sizes aligned to 3DES block size (8 bytes) allowed
+ */
+static MV_CESA_SIZE_TEST tripleDesShaMultiSizeTest603[] = {
+	{64, "44a1e9bcbfc1429630d9ea68b7a48b0427a684f2"},
+	{80, "b2ddeaca91030eab5b95a234ef2c0f6e738ff883"},
+	{352, "4b91864c7ff629bdff75d9726421f76705452aaf"},
+	{512, "6dd37faceeb2aa98ba74f4242ed6734a4d546af5"},
+	{1000, "463661c30300be512a9df40904f0757cde5f1141"},
+	{1336, "b931f831d9034fe59c65176400b039fe9c1f44a5"},
+	{1344, "af8866b1cd4a4887d6185bfe72470ffdfb3648e1"},
+	{1400, "49c6caf07296d5e31d2504d088bc5b20c3ee7cdb"},
+	{1408, "fcae8deedbc6ebf0763575dc7e9de075b448a0f4"},
+	{2048, "edece5012146c1faa0dd10f50b183ba5d2af58ac"},
+	{3072, "5b83625adb43a488b8d64fecf39bb766818547b7"},
+	{4048, "d2c533678d26c970293af60f14c8279dc708bfc9"},
+	{6144, "b8f67af4f991b08b725f969b049ebf813bfacc5c"},
+	{6400, "d9a6c7f746ac7a60ef2edbed2841cf851c25cfb0"},
+	{6528, "376792b8c8d18161d15579fb7829e6e3a27e9946"},
+	{8192, "d890eabdca195b34ef8724b28360cffa92ae5655"},
+	{16384, "a167ee52639ec7bf19aee9c6e8f76667c14134b9"},
+	{18432, "e4396ab56f67296b220985a12078f4a0e365d2cc"},
+	{0, NULL},
+};
+
+/* CryptoKey   = 0x01234567, 0x89abcdef,
+ *               0x01234567, 0x89abcdef,
+ *               0x01234567, 0x89abcdef
+ * IV          = 0x12345678, 0x90abcdef
+ * MacKey      = 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08,
+ *               0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, 0x10
+ * InputHexStr = "31323334353637383930" (ASCII = "1234567890")
+ * Note: only sizes aligned to 3DES block size (8 bytes) allowed
+ */
+static MV_CESA_SIZE_TEST cbc3desMdMultiSizeTest604[] = {
+	{64, "8d10e00802460ede0058c139ba48bd2d"},
+	{80, "6f463057e1a90e0e91ae505b527bcec0"},
+	{352, "4938d48bdf86aece2c6851e7c6079788"},
+	{512, "516705d59f3cf810ebf2a13a23a7d42e"},
+	{1000, "a5a000ee5c830e67ddc6a2d2e5644b31"},
+	{1336, "44af60087b74ed07950088efbe3b126a"},
+	{1344, "1f5b39e0577920af731dabbfcf6dfc2a"},
+	{1400, "6804ea640e29b9cd39e08bc37dbce734"},
+	{1408, "4fb436624b02516fc9d1535466574bf9"},
+	{2048, "c909b0985c423d8d86719f701e9e83db"},
+	{3072, "cfe0bc34ef97213ee3d3f8b10122db21"},
+	{4048, "03ea10b5ae4ddeb20aed6af373082ed1"},
+	{6144, "b9a0ff4f87fc14b3c2dc6f0ed0998fdf"},
+	{6400, "6995f85d9d4985dd99e974ec7dda9dd6"},
+	{6528, "bbbb548ce2fa3d58467f6a6a5168a0e6"},
+	{8192, "afe101fbe745bb449ae4f50d10801456"},
+	{16384, "9741706d0b1c923340c4660ff97cacdf"},
+	{18432, "b0217becb73cb8f61fd79c7ce9d023fb"},
+	{0, NULL},
+};
+
+/* CryptoKey   = 0x01234567, 0x89abcdef,
+ *               0x01234567, 0x89abcdef,
+ *               0x01234567, 0x89abcdef;
+ * IV          = 0x12345678, 0x90abcdef
+ * MacKey      = 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08,
+ *               0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, 0x10
+ *               0x11, 0x12, 0x13, 0x14
+ * InputHexStr = "31323334353637383930" (ASCII = "1234567890")
+ * Note: only sizes aligned to 3DES block size (8 bytes) allowed
+ */
+static MV_CESA_SIZE_TEST cbc3desShaMultiSizeTest605[] = {
+	{64, "409187e5bdb0be4a7754ca3747f7433dc4f01b98"},
+	{80, "1b002ed050be743aa98860cf35659646bb8efcc0"},
+	{352, "6cbf7ebe50fa4fa6eecc19eca23f9eae553ccfff"},
+	{512, "cfb5253fb4bf72b743320c30c7e48c54965853b0"},
+	{1000, "95e04e1ca2937e7c5a9aba9e42d2bcdb8a7af21f"},
+	{1336, "3b5c1f5eee5837ebf67b83ae01405542d77a6627"},
+	{1344, "2b3d42ab25615437f98a1ee310b81d07a02badc2"},
+	{1400, "7f8687df7c1af44e4baf3c934b6cca5ab6bc993e"},
+	{1408, "473a581c5f04f7527d50793c845471ac87e86430"},
+	{2048, "e41d20cae7ebe34e6e828ed62b1e5734019037bb"},
+	{3072, "275664afd7a561d804e6b0d204e53939cde653ae"},
+	{4048, "0d220cc5b34aeeb46bbbd637dde6290b5a8285a3"},
+	{6144, "cb393ddcc8b1c206060625b7d822ef9839e67bc5"},
+	{6400, "dd3317e2a627fc04800f74a4b05bfda00fab0347"},
+	{6528, "8a74c3b2441ab3f5a7e08895cc432566219a7c41"},
+	{8192, "b8e6ef3a549ed0e005bd5b8b1a5fe6689e9711a7"},
+	{16384, "55f59404008276cdac0e2ba0d193af2d40eac5ce"},
+	{18432, "86ae6c4fc72369a54cce39938e2d0296cd9c6ec5"},
+	{0, NULL},
+};
+
+/* CryptoKey   = 0x01234567, 0x89abcdef,
+ *               0x01234567, 0x89abcdef,
+ *               0x01234567, 0x89abcdef
+ * IV          = 0x12345678, 0x90abcdef
+ * MacKey      = 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08,
+ *               0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, 0x10
+ * InputHexStr = "31323334353637383930" (ASCII = "1234567890")
+ * Note: only sizes aligned to AES block size (16 bytes) allowed
+ */
+static MV_CESA_SIZE_TEST cbcAes128md5multiSizeTest606[] = {
+	{16, "7ca4c2ba866751598720c5c4aa0d6786"},
+	{64, "7dba7fb988e80da609b1fea7254bced8"},
+	{80, "6b6e863ac5a71d15e3e9b1c86c9ba05f"},
+	{352, "a1ceb9c2e3021002400d525187a9f38c"},
+	{512, "596c055c1c55db748379223164075641"},
+	{1008, "f920989c02f3b3603f53c99d89492377"},
+	{1344, "2e496b73759d77ed32ea222dbd2e7b41"},
+	{1408, "7178c046b3a8d772efdb6a71c4991ea4"},
+	{2048, "a917f0099c69eb94079a8421714b6aad"},
+	{3072, "693cd5033d7f5391d3c958519fa9e934"},
+	{4048, "139dca91bcff65b3c40771749052906b"},
+	{6144, "428d9cef6df4fb70a6e9b6bbe4819e55"},
+	{6400, "9c0b909e76daa811e12b1fc17000a0c4"},
+	{6528, "ad876f6297186a7be1f1b907ed860eda"},
+	{8192, "479cbbaca37dd3191ea1f3e8134a0ef4"},
+	{16384, "60fda559c74f91df538100c9842f2f15"},
+	{18432, "4a3eb1cba1fa45f3981270953f720c42"},
+	{0, NULL},
+};
+
+/* CryptoKey   = 0x01234567, 0x89abcdef,
+ *               0x01234567, 0x89abcdef,
+ *               0x01234567, 0x89abcdef;
+ * IV          = 0x12345678, 0x90abcdef
+ * MacKey      = 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08,
+ *               0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, 0x10
+ *               0x11, 0x12, 0x13, 0x14
+ * InputHexStr = "31323334353637383930" (ASCII = "1234567890")
+ * Note: only sizes aligned to AES block size (16 bytes) allowed
+ */
+static MV_CESA_SIZE_TEST cbcAes128sha1multiSizeTest607[] = {
+	{16, "9aa8dc1c45f0946daf78057fa978759c625c1fee"},
+	{64, "9f588fc1ede851e5f8b20256abc9979465ae2189"},
+	{80, "13558472d1fc1c90dffec6e5136c7203452d509b"},
+	{352, "6b93518e006cfaa1f7adb24615e7291fb0a27e06"},
+	{512, "096874951a77fbbf333e49d80c096ee2016e09bd"},
+	{1008, "696fc203c2e4b5ae0ec5d1db3f623c490bc6dbac"},
+	{1344, "79bf77509935ccd3528caaac6a5eb6481f74029b"},
+	{1408, "627f9462b95fc188e8cfa7eec15119bdc5d4fcf1"},
+	{2048, "3d50d0c005feba92fe41502d609fced9c882b4d1"},
+	{3072, "758807e5b983e3a91c06fb218fe0f73f77111e94"},
+	{4048, "ca90e85242e33f005da3504416a52098d0d31fb2"},
+	{6144, "8044c1d4fd06642dfc46990b4f18b61ef1e972cf"},
+	{6400, "166f1f4ea57409f04feba9fb1e39af0e00bd6f43"},
+	{6528, "0389016a39485d6e330f8b4215ddf718b404f7e9"},
+	{8192, "6df7ee2a8b61d6f7f860ce8dbf778f0c2a5b508b"},
+	{16384, "a70a6d8dfa1f91ded621c3dbaed34162bc48783f"},
+	{18432, "8dfad627922ce15df1eed10bdbed49244efa57db"},
+	{0, NULL},
+};
+
+void cesaTestPrintStatus(void);
+
+/*------------------------- LOCAL FUNCTIONs ---------------------------------*/
+MV_STATUS testCmd(int sid, int iter, MV_CESA_COMMAND *pCmd,
+		  MV_CESA_TEST_SESSION *pTestSession, MV_U8 *pIV, int ivSize);
+MV_STATUS testClose(int idx);
+MV_STATUS testOpen(int idx);
+void close_session(int sid);
+void cesaTestCheckReady(const MV_CESA_RESULT *r);
+void cesaCheckReady(MV_CESA_RESULT *r);
+void printTestResults(int idx, MV_STATUS status, int checkMode);
+void cesaLastResult(void);
+void cesaTestPrintReq(int req, int offset, int size);
+
+void cesaTestPrintStatus(void);
+void cesaTestPrintSession(int idx);
+void sizeTest(int testIdx, int iter, int checkMode);
+void multiTest(int iter, int reqSize, int checkMode);
+void oneTest(int testIdx, int caseIdx, int iter, int reqSize, int checkMode);
+void multiSizeTest(int idx, int iter, int checkMode, char *inputData);
+void cesaTest(int iter, int reqSize, int checkMode);
+void cesaOneTest(int testIdx, int caseIdx, int iter, int reqSize, int checkMode);
+void combiTest(int iter, int reqSize, int checkMode);
+void sha1Test(int iter, int reqSize, int checkMode);
+void sha2Test(int iter, int reqSize, int checkMode);
+void mdTest(int iter, int reqSize, int checkMode);
+void aesTest(int iter, int reqSize, int checkMode);
+void tripleDesTest(int iter, int reqSize, int checkMode);
+void desTest(int iter, int reqSize, int checkMode);
+void cesaTestStop(void);
+MV_STATUS testRun(int idx, int caseIdx, int iter, int reqSize, int checkMode);
+void cesaTestStart(int bufNum, int bufSize);
+
+static MV_U32 getRate(MV_U32 *remainder)
+{
+	MV_U32 rate;
+#ifdef MV_LINUX
+	rate = ((cesaIteration * cesaRateSize * 8) / (cesaEndTicks - cesaBeginTicks));
+	*remainder = 0;
+#else
+	MV_U32 kBits, milliSec;
+
+	milliSec = 0;
+	if ((cesaEndTicks - cesaBeginTicks) > 0)
+		milliSec = CESA_TEST_TICK_TO_MS(cesaEndTicks - cesaBeginTicks);
+
+	if (milliSec == 0) {
+		if (remainder != NULL)
+			*remainder = 0;
+		return 0;
+	}
+
+	kBits = (cesaIteration * cesaRateSize * 8) / 1000;
+	rate = kBits / milliSec;
+	if (remainder != NULL)
+		*remainder = ((kBits % milliSec) * 10) / milliSec;
+#endif
+	return rate;
+}
+
+static char *extractMbuf(MV_CESA_MBUF *pMbuf, int offset, int size, char *hexStr)
+{
+	mvCesaCopyFromMbuf((MV_U8 *)cesaBinBuffer, pMbuf, offset, size);
+	mvBinToHex((const MV_U8 *)cesaBinBuffer, hexStr, size);
+
+	return hexStr;
+}
+
+static MV_BOOL cesaCheckMbuf(MV_CESA_MBUF *pMbuf, const char *hexString, int offset, int checkSize)
+{
+	MV_BOOL isFailed = MV_FALSE;
+	MV_STATUS status;
+	int size = strlen(hexString) / 2;
+	int checkedSize = 0;
+/*
+	mvOsPrintf("cesaCheckMbuf: pMbuf=%p, offset=%d, checkSize=%d, mBufSize=%d\n",
+			pMbuf, offset, checkSize, pMbuf->mbufSize);
+*/
+	if (pMbuf->mbufSize < (checkSize + offset)) {
+		mvOsPrintf("checkSize (%d) is too large: offset=%d, mbufSize=%d\n", checkSize, offset, pMbuf->mbufSize);
+		return MV_TRUE;
+	}
+	status = mvCesaCopyFromMbuf((MV_U8 *)cesaBinBuffer, pMbuf, offset, checkSize);
+	if (status != MV_OK) {
+		mvOsPrintf("CesaTest: Can't copy %d bytes from Mbuf=%p to checkBuf=%p\n",
+			   checkSize, pMbuf, cesaBinBuffer);
+		return MV_TRUE;
+	}
+/*
+    mvDebugMemDump(cesaBinBuffer, size, 1);
+*/
+	mvHexToBin(hexString, (MV_U8 *)cesaExpBinBuffer, size);
+
+	/* Compare buffers */
+	while (checkSize > checkedSize) {
+		size = MV_MIN(size, (checkSize - checkedSize));
+		if (memcmp(cesaExpBinBuffer, &cesaBinBuffer[checkedSize], size) != 0) {
+			mvOsPrintf("CheckMbuf failed: checkSize=%d, size=%d, checkedSize=%d\n",
+				   checkSize, size, checkedSize);
+			mvDebugMemDump(&cesaBinBuffer[checkedSize], size, 1);
+			mvDebugMemDump(cesaExpBinBuffer, size, 1);
+
+			isFailed = MV_TRUE;
+			break;
+		}
+		checkedSize += size;
+	}
+
+	return isFailed;
+}
+
+static MV_STATUS cesaSetMbuf(MV_CESA_MBUF *pMbuf, const char *hexString, int offset, int reqSize)
+{
+	MV_STATUS status = MV_OK;
+	int copySize, size = strlen(hexString) / 2;
+
+	mvHexToBin(hexString, (MV_U8 *)cesaBinBuffer, size);
+
+	copySize = 0;
+	while (reqSize > copySize) {
+		size = MV_MIN(size, (reqSize - copySize));
+
+		status = mvCesaCopyToMbuf((MV_U8 *)cesaBinBuffer, pMbuf, offset + copySize, size);
+		if (status != MV_OK) {
+			mvOsPrintf("cesaSetMbuf Error: Copy %d of %d bytes to MBuf\n", copySize, reqSize);
+			break;
+		}
+		copySize += size;
+	}
+	pMbuf->mbufSize = offset + copySize;
+	return status;
+}
+
+static MV_CESA_TEST_SESSION *getTestSessionDb(int idx, int *pTestIdx)
+{
+	int testIdx, dbIdx = idx / 100;
+
+	if (dbIdx > MAX_TEST_TYPE) {
+		mvOsPrintf("Wrong index %d - No such test type\n", idx);
+		return NULL;
+	}
+	testIdx = idx % 100;
+
+	if (testIdx >= cesaTestsDB[dbIdx].numSessions) {
+		mvOsPrintf("Wrong index %d - No such test\n", idx);
+		return NULL;
+	}
+	if (pTestIdx != NULL)
+		*pTestIdx = testIdx;
+
+	return cesaTestsDB[dbIdx].pSessions;
+}
+
+/* Debug */
+void cesaTestPrintReq(int req, int offset, int size)
+{
+	MV_CESA_MBUF *pMbuf;
+
+	mvOsPrintf("cesaTestPrintReq: req=%d, offset=%d, size=%d\n", req, offset, size);
+	mvDebugMemDump(cesaCmdRing, 128, 4);
+
+	pMbuf = cesaCmdRing[req].pSrc;
+	mvCesaIfDebugMbuf("src", pMbuf, offset, size);
+	pMbuf = cesaCmdRing[req].pDst;
+	mvCesaIfDebugMbuf("dst", pMbuf, offset, size);
+
+	cesaTestPrintStatus();
+}
+
+void cesaLastResult(void)
+{
+	mvOsPrintf("Last Result: ReqId = %d, SessionId = %d, rc = (%d)\n",
+		   (MV_U32) cesaResult.pReqPrv, cesaResult.sessionId, cesaResult.retCode);
+}
+
+void printTestResults(int idx, MV_STATUS status, int checkMode)
+{
+	int testIdx;
+	MV_CESA_TEST_SESSION *pTestSessions = getTestSessionDb(idx, &testIdx);
+
+	if (pTestSessions == NULL)
+		return;
+
+	mvOsPrintf("%-35s %4dx%-4d : ", pTestSessions[testIdx].name, cesaIteration, cesaReqSize);
+	if ((status == MV_OK) && (cesaCryptoError == 0) && (cesaError == 0) && (cesaReqIdError == 0)) {
+		mvOsPrintf("Passed, Rate=%3u.%u Mbps (%5u cpp)\n",
+			   cesaRate, cesaRateAfterDot, cesaEndTicks - cesaBeginTicks);
+	} else {
+		mvOsPrintf("Failed, Status = 0x%x\n", status);
+		if (cesaCryptoError > 0)
+			mvOsPrintf("cryptoError : %d\n", cesaCryptoError);
+		if (cesaReqIdError > 0)
+			mvOsPrintf("reqIdError  : %d\n", cesaReqIdError);
+		if (cesaError > 0)
+			mvOsPrintf("cesaError  : %d\n", cesaError);
+	}
+	if (cesaTestIsrMissCount > 0)
+		mvOsPrintf("cesaIsrMissed  : %d\n", cesaTestIsrMissCount);
+}
+
+void cesaCheckReady(MV_CESA_RESULT *r)
+{
+	int reqId;
+	MV_CESA_MBUF *pMbuf;
+	MV_BOOL isFailed;
+
+	reqId = (int)r->pReqPrv;
+	cesaResult = *r;
+	pMbuf = cesaCmdRing[reqId].pDst;
+
+/*
+	mvOsPrintf("cesaCheckReady: reqId=%d, checkOffset=%d, checkSize=%d\n",
+			reqId, cesaCheckOffset, cesaCheckSize);
+*/
+	/* Check expected reqId */
+	if (reqId != cesaExpReqId) {
+		cesaReqIdError++;
+	mvOsPrintf("CESA reqId Error: cbIter=%d (%d), reqId=%d, expReqId=%d\n",
+				cesaCbIter, cesaIteration, reqId, cesaExpReqId);
+
+	} else {
+
+		if ((cesaCheckMode == CESA_FULL_CHECK_MODE) || (cesaCheckMode == CESA_FAST_CHECK_MODE)) {
+			if (r->retCode != MV_OK) {
+				cesaError++;
+
+				mvOsPrintf("CESA Error: cbIter=%d (%d), reqId=%d, rc=%d\n",
+					   cesaCbIter, cesaIteration, reqId, r->retCode);
+			} else {
+				if ((cesaCheckSize > 0) && (cesaOutputHexStr != NULL)) {
+					/* Check expected output */
+
+					isFailed =
+					    cesaCheckMbuf(pMbuf, cesaOutputHexStr, cesaCheckOffset, cesaCheckSize);
+					if (isFailed) {
+						mvOsPrintf("CESA Crypto Error: cbIter=%d (%d), reqId=%d\n",
+							   cesaCbIter, cesaIteration, reqId);
+
+						CESA_TEST_DEBUG_PRINT(("Error: reqId=%d, reqSize=%d, checkOffset=%d, checkSize=%d\n",
+											   reqId, cesaReqSize, cesaCheckOffset, cesaCheckSize));
+
+						CESA_TEST_DEBUG_PRINT(("Output str: %s\n", cesaOutputHexStr));
+
+						CESA_TEST_DEBUG_CODE(mvCesaIfDebugMbuf
+								     ("error", pMbuf, 0,
+								      cesaCheckOffset + cesaCheckSize));
+
+						cesaCryptoError++;
+					}
+				}
+			}
+		}
+	}
+	if (cesaCheckMode == CESA_SHOW_CHECK_MODE) {
+		extractMbuf(pMbuf, cesaCheckOffset, cesaCheckSize, cesaHexBuffer);
+		mvOsPrintf("%4d, %s\n", cesaCheckOffset, cesaHexBuffer);
+	}
+
+	cesaCbIter++;
+
+	if (cesaCbIter >= cesaIteration) {
+		cesaCbIter = 0;
+		cesaExpReqId = 0;
+		cesaIsReady = MV_TRUE;
+#ifdef MV_LINUX
+		do_gettimeofday(&tv);
+		cesaEndTicks = ((tv.tv_sec * 1000000) + tv.tv_usec);
+#else
+		cesaEndTicks = CESA_TEST_TICK_GET();
+#endif
+		cesaRate = getRate(&cesaRateAfterDot);
+	} else {
+		cesaExpReqId = reqId + 1;
+		if (cesaExpReqId == CESA_DEF_REQ_SIZE)
+			cesaExpReqId = 0;
+	}
+}
+
+#ifdef MV_NETBSD
+static int cesaTestReadyIsr(void *arg)
+#else
+#ifdef __KERNEL__
+static irqreturn_t cesaTestReadyIsr(int irq, void *dev_id)
+#endif
+#ifdef MV_VXWORKS
+void cesaTestReadyIsr(void)
+#endif
+#endif
+{
+	MV_U32 cause;
+	MV_STATUS status;
+	MV_CESA_RESULT result;
+	MV_U8 chan = *((MV_U8 *)dev_id);
+
+	/* Read cause register */
+	cause = MV_REG_READ(MV_CESA_ISR_CAUSE_REG(chan));
+
+    	if ((cause & MV_CESA_CAUSE_ACC_DMA_MASK) != 0) {
+			
+		/* Clear pending irq */
+    		MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+
+		spin_lock(&cesaLock);
+
+		cesaTestIsrCount++;
+
+		/* Get Ready requests */
+		while (1) {
+				status = mvCesaIfReadyGet(chan, &result);
+				if (status != MV_OK)
+					break;
+
+				cesaCheckReady(&result);
+		}
+
+		spin_unlock(&cesaLock);
+
+		if (cesaTestFull == 1) {
+			spin_lock(&cesaLock);
+			cesaTestFull = 0;
+			spin_unlock(&cesaLock);
+			CESA_TEST_WAKE_UP();
+		}
+	}
+ 
+
+#ifdef MV_NETBSD
+		return 0;
+#else
+#ifdef __KERNEL__
+		return IRQ_HANDLED;
+#else
+		return;
+#endif
+#endif
+
+}
+
+void cesaTestCheckReady(const MV_CESA_RESULT *r)
+{
+	MV_CESA_RESULT result = *r;
+
+	cesaCheckReady(&result);
+
+	if (cesaTestFull == 1) {
+		cesaTestFull = 0;
+		CESA_TEST_WAKE_UP();
+	}
+}
+
+static INLINE int open_session(MV_CESA_OPEN_SESSION *pOs)
+{
+	MV_U16 sid;
+	MV_STATUS status;
+
+	status = mvCesaIfSessionOpen(pOs, (short *)&sid);
+	if (status != MV_OK) {
+		mvOsPrintf("CesaTest: Can't open new session - status = 0x%x\n", status);
+		return -1;
+	}
+
+	return (int)sid;
+}
+
+void close_session(int sid)
+{
+	MV_STATUS status;
+
+	status = mvCesaIfSessionClose(sid);
+	if (status != MV_OK)
+		mvOsPrintf("CesaTest: Can't close session %d - status = 0x%x\n", sid, status);
+
+}
+
+MV_STATUS testOpen(int idx)
+{
+	MV_CESA_OPEN_SESSION os;
+	int sid, i, testIdx;
+	MV_CESA_TEST_SESSION *pTestSession;
+	MV_U16 digestSize = 0;
+
+	pTestSession = getTestSessionDb(idx, &testIdx);
+	if (pTestSession == NULL) {
+		mvOsPrintf("Test %d is not exist\n", idx);
+		return MV_BAD_PARAM;
+	}
+	pTestSession = &pTestSession[testIdx];
+
+	if (pTestSession->sid != -1) {
+		mvOsPrintf("Session for test %d already created: sid=%d\n", idx, pTestSession->sid);
+		return MV_OK;
+	}
+
+	os.cryptoAlgorithm = pTestSession->cryptoAlgorithm;
+	os.macMode = pTestSession->macAlgorithm;
+	switch (os.macMode) {
+	case MV_CESA_MAC_MD5:
+	case MV_CESA_MAC_HMAC_MD5:
+		digestSize = MV_CESA_MD5_DIGEST_SIZE;
+		break;
+
+	case MV_CESA_MAC_SHA1:
+	case MV_CESA_MAC_HMAC_SHA1:
+		digestSize = MV_CESA_SHA1_DIGEST_SIZE;
+		break;
+
+	case MV_CESA_MAC_SHA2:
+	case MV_CESA_MAC_HMAC_SHA2:
+		digestSize = MV_CESA_SHA2_DIGEST_SIZE;
+		break;
+
+	case MV_CESA_MAC_NULL:
+		digestSize = 0;
+	}
+	os.cryptoMode = pTestSession->cryptoMode;
+	os.direction = pTestSession->direction;
+	os.operation = pTestSession->operation;
+
+	for (i = 0; i < pTestSession->cryptoKeySize; i++)
+		os.cryptoKey[i] = pTestSession->pCryptoKey[i];
+
+	os.cryptoKeyLength = pTestSession->cryptoKeySize;
+
+	for (i = 0; i < pTestSession->macKeySize; i++)
+		os.macKey[i] = pTestSession->pMacKey[i];
+
+	os.macKeyLength = pTestSession->macKeySize;
+	os.digestSize = digestSize;
+
+	sid = open_session(&os);
+	if (sid == -1) {
+		mvOsPrintf("Can't open session for test %d: rc=0x%x\n", idx, cesaResult.retCode);
+		return cesaResult.retCode;
+	}
+	CESA_TEST_DEBUG_PRINT(("Opened session: sid = %d\n", sid));
+	pTestSession->sid = sid;
+	return MV_OK;
+}
+
+MV_STATUS testClose(int idx)
+{
+	int testIdx;
+	MV_CESA_TEST_SESSION *pTestSession;
+
+	pTestSession = getTestSessionDb(idx, &testIdx);
+	if (pTestSession == NULL) {
+		mvOsPrintf("Test %d is not exist\n", idx);
+		return MV_BAD_PARAM;
+	}
+	pTestSession = &pTestSession[testIdx];
+
+	if (pTestSession->sid == -1) {
+		mvOsPrintf("Test session %d is not opened\n", idx);
+		return MV_NO_SUCH;
+	}
+
+	close_session(pTestSession->sid);
+	pTestSession->sid = -1;
+
+	return MV_OK;
+}
+
+MV_STATUS testCmd(int sid, int iter, MV_CESA_COMMAND *pCmd,
+		  MV_CESA_TEST_SESSION *pTestSession, MV_U8 *pIV, int ivSize)
+{
+	int i;
+	MV_STATUS rc = MV_OK;
+	char ivZeroHex[] = "0000";
+	unsigned char chan = 0;
+	static unsigned long flags;
+
+	if (iter == 0)
+		iter = CESA_DEF_ITER_NUM;
+
+	if (pCmd == NULL) {
+		mvOsPrintf("testCmd failed: pCmd=NULL\n");
+		return MV_BAD_PARAM;
+	}
+	pCmd->sessionId = sid;
+
+	cesaCryptoError = 0;
+	cesaReqIdError = 0;
+	cesaError = 0;
+	cesaTestIsrMissCount = 0;
+	cesaIsReady = MV_FALSE;
+	cesaIteration = iter;
+	cmdReqId = 0;
+
+	if (cesaInputHexStr == NULL)
+		cesaInputHexStr = cesaPlainHexEbc;
+
+	for (i = 0; i < CESA_DEF_REQ_SIZE; i++) {
+		pCmd->pSrc = (MV_CESA_MBUF *) (cesaCmdRing[i].pSrc);
+		if (pIV != NULL) {
+			/* If IV from SA - set IV in Source buffer to zeros */
+			cesaSetMbuf(pCmd->pSrc, ivZeroHex, 0, pCmd->cryptoOffset);
+			cesaSetMbuf(pCmd->pSrc, cesaInputHexStr, pCmd->cryptoOffset,
+				    (cesaReqSize - pCmd->cryptoOffset));
+		} else {
+			cesaSetMbuf(pCmd->pSrc, cesaInputHexStr, 0, cesaReqSize);
+		}
+		pCmd->pDst = (MV_CESA_MBUF *) (cesaCmdRing[i].pDst);
+		cesaSetMbuf(pCmd->pDst, cesaNullPlainHexText, 0, cesaReqSize);
+
+		memcpy(&cesaCmdRing[i], pCmd, sizeof(*pCmd));
+	}
+
+	if (cesaCheckMode == CESA_SW_SHOW_CHECK_MODE) {
+		MV_U8 pDigest[MV_CESA_MAX_DIGEST_SIZE];
+
+		if (pTestSession->macAlgorithm == MV_CESA_MAC_MD5) {
+			mvMD5(pCmd->pSrc->pFrags[0].bufVirtPtr, pCmd->macLength, pDigest);
+			mvOsPrintf("SW HASH_MD5: reqSize=%d, macLength=%d\n", cesaReqSize, pCmd->macLength);
+			mvDebugMemDump(pDigest, MV_CESA_MD5_DIGEST_SIZE, 1);
+			return MV_OK;
+		}
+		if (pTestSession->macAlgorithm == MV_CESA_MAC_SHA1) {
+			mvSHA1(pCmd->pSrc->pFrags[0].bufVirtPtr, pCmd->macLength, pDigest);
+			mvOsPrintf("SW HASH_SHA1: reqSize=%d, macLength=%d\n", cesaReqSize, pCmd->macLength);
+			mvDebugMemDump(pDigest, MV_CESA_SHA1_DIGEST_SIZE, 1);
+			return MV_OK;
+		}
+		if (pTestSession->macAlgorithm == MV_CESA_MAC_SHA2) {
+			mvSHA256(pCmd->pSrc->pFrags[0].bufVirtPtr, pCmd->macLength, pDigest);
+			mvOsPrintf("SW HASH_SHA2: reqSize=%d, macLength=%d\n", cesaReqSize, pCmd->macLength);
+			mvDebugMemDump(pDigest, MV_CESA_SHA2_DIGEST_SIZE, 1);
+			return MV_OK;
+		}
+	}
+#ifdef MV_LINUX
+	do_gettimeofday(&tv);
+	cesaBeginTicks = ((tv.tv_sec * 1000000) + tv.tv_usec);
+#else
+	cesaBeginTicks = CESA_TEST_TICK_GET();
+#endif
+	CESA_TEST_DEBUG_CODE(memset(cesaTestTrace, 0, sizeof(cesaTestTrace)); cesaTestTraceIdx = 0;);
+
+	if (cesaCheckMode == CESA_SW_NULL_CHECK_MODE) {
+		MV_U8 pDigest[MV_CESA_MAX_DIGEST_SIZE];
+
+		for (i = 0; i < iter; i++) {
+
+			if (pTestSession->macAlgorithm == MV_CESA_MAC_MD5)
+				mvMD5(pCmd->pSrc->pFrags[0].bufVirtPtr, pCmd->macLength, (unsigned char *)pDigest);
+
+			if (pTestSession->macAlgorithm == MV_CESA_MAC_SHA1)
+				mvSHA1(pCmd->pSrc->pFrags[0].bufVirtPtr, pCmd->macLength, (MV_U8 *) pDigest);
+
+			if (pTestSession->macAlgorithm == MV_CESA_MAC_SHA2)
+				mvSHA256(pCmd->pSrc->pFrags[0].bufVirtPtr, pCmd->macLength, (MV_U8 *) pDigest);
+		}
+#ifdef MV_LINUX
+		do_gettimeofday(&tv);
+		cesaEndTicks = ((tv.tv_sec * 1000000) + tv.tv_usec);
+#else
+		cesaEndTicks = CESA_TEST_TICK_GET();
+#endif
+		cesaRate = getRate(&cesaRateAfterDot);
+		cesaIsReady = MV_TRUE;
+
+		return MV_OK;
+	}
+
+	/*cesaTestIsrCount = 0; */
+	/*mvCesaDebugStatsClear(); */
+
+#ifndef MV_NETBSD
+	for (chan = 0; chan < MV_CESA_CHANNELS; chan++)
+		MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+#endif
+
+	for (i = 0; i < iter; i++) {
+		
+		CESA_TEST_LOCK(flags);
+
+		pCmd = &cesaCmdRing[cmdReqId];
+		pCmd->pReqPrv = (void *)cmdReqId;
+
+		cmdReqId++;
+		if (cmdReqId >= CESA_DEF_REQ_SIZE)
+			cmdReqId = 0;
+
+		CESA_TEST_UNLOCK(flags);
+
+		pCmd->split = MV_CESA_SPLIT_NONE;
+
+		rc = mvCesaIfAction(pCmd);
+
+		if (rc == MV_NO_RESOURCE) {
+			CESA_TEST_LOCK(flags);
+			cesaTestFull = 1;
+			CESA_TEST_UNLOCK(flags);
+			
+			CESA_TEST_WAIT((cesaTestFull == 0), 1000);
+			
+			if (cesaTestFull == 1) {
+				mvOsPrintf("CESA Test timeout: i=%d, iter=%d, cesaTestFull=%d\n",
+					   i, iter, cesaTestFull);
+				CESA_TEST_LOCK(flags);
+				cesaTestFull = 0;
+				CESA_TEST_UNLOCK(flags);
+				return MV_TIMEOUT;
+			}
+			rc = mvCesaIfAction(pCmd);
+		}
+
+		if ((rc != MV_OK) && (rc != MV_NO_MORE)) {
+			mvOsPrintf("mvCesaIfAction failed: rc=%d\n", rc);
+			return rc;
+		}
+
+#ifdef MV_LINUX
+		/* Reschedule each 16 requests */
+		if ((i & 0xF) == 0)
+			schedule();
+#endif
+	}
+	return MV_OK;
+}
+
+extern MV_STATUS mvSysCesaInit(int numOfSession, int queueDepth, void *osHandle);
+
+void cesaTestStart(int bufNum, int bufSize)
+{
+	int i, j, idx;
+	MV_CESA_MBUF *pMbufSrc, *pMbufDst;
+	MV_BUF_INFO *pFragsSrc, *pFragsDst;
+	char *pBuf;
+#ifndef MV_NETBSD
+	int numOfSessions, queueDepth;
+	MV_STATUS status;
+#endif
+	MV_U8 chan = 0;
+	const char* irqName[] = {"cesa_test:0", "cesa_test:1"};
+
+	cesaCmdRing = mvOsMalloc(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
+	if (cesaCmdRing == NULL) {
+		mvOsPrintf("testStart: Can't allocate %d bytes of memory\n",
+			   (int)(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE));
+		return;
+	}
+	memset(cesaCmdRing, 0, sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
+
+	if (bufNum == 0)
+		bufNum = CESA_DEF_BUF_NUM;
+
+	if (bufSize == 0)
+		bufSize = CESA_DEF_BUF_SIZE;
+
+	cesaBufNum = bufNum;
+	cesaBufSize = bufSize;
+	mvOsPrintf("CESA test started: bufNum = %d, bufSize = %d\n", bufNum, bufSize);
+
+	cesaHexBuffer = mvOsMalloc(2 * bufNum * bufSize);
+	if (cesaHexBuffer == NULL) {
+		mvOsPrintf("testStart: Can't malloc %d bytes for cesaHexBuffer.\n", 2 * bufNum * bufSize);
+		return;
+	}
+	memset(cesaHexBuffer, 0, (2 * bufNum * bufSize));
+
+	cesaBinBuffer = mvOsMalloc(bufNum * bufSize);
+	if (cesaBinBuffer == NULL) {
+		mvOsPrintf("testStart: Can't malloc %d bytes for cesaBinBuffer\n", bufNum * bufSize);
+		return;
+	}
+	memset(cesaBinBuffer, 0, (bufNum * bufSize));
+
+	cesaExpBinBuffer = mvOsMalloc(bufNum * bufSize);
+	if (cesaExpBinBuffer == NULL) {
+		mvOsPrintf("testStart: Can't malloc %d bytes for cesaExpBinBuffer\n", bufNum * bufSize);
+		return;
+	}
+	memset(cesaExpBinBuffer, 0, (bufNum * bufSize));
+
+	CESA_TEST_WAIT_INIT();
+
+	pMbufSrc = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	pFragsSrc = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	pMbufDst = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	pFragsDst = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	if ((pMbufSrc == NULL) || (pFragsSrc == NULL) || (pMbufDst == NULL) || (pFragsDst == NULL)) {
+		mvOsPrintf("testStart: Can't malloc Src and Dst pMbuf and pFrags structures.\n");
+		/* !!!! Dima cesaTestCleanup(); */
+		return;
+	}
+
+	memset(pMbufSrc, 0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	memset(pFragsSrc, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	memset(pMbufDst, 0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	memset(pFragsDst, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	mvOsPrintf("Cesa Test Start: pMbufSrc=%p, pFragsSrc=%p, pMbufDst=%p, pFragsDst=%p\n",
+		   pMbufSrc, pFragsSrc, pMbufDst, pFragsDst);
+
+	idx = 0;
+	for (i = 0; i < CESA_DEF_REQ_SIZE; i++) {
+		pBuf = mvOsIoCachedMalloc(cesaTestOSHandle, bufSize * bufNum * 2,
+					  &cesaReqBufs[i].bufPhysAddr, &cesaReqBufs[i].memHandle);
+		if (pBuf == NULL) {
+			mvOsPrintf("testStart: Can't malloc %d bytes for pBuf\n", bufSize * bufNum * 2);
+			return;
+		}
+
+		memset(pBuf, 0, bufSize * bufNum * 2);
+		mvOsCacheFlush(cesaTestOSHandle, pBuf, bufSize * bufNum * 2);
+		if (pBuf == NULL) {
+			mvOsPrintf("cesaTestStart: Can't allocate %d bytes for req_%d buffers\n",
+				   bufSize * bufNum * 2, i);
+			return;
+		}
+
+		cesaReqBufs[i].bufVirtPtr = (MV_U8 *) pBuf;
+		cesaReqBufs[i].bufSize = bufSize * bufNum * 2;
+
+		cesaCmdRing[i].pSrc = &pMbufSrc[i];
+		cesaCmdRing[i].pSrc->pFrags = &pFragsSrc[idx];
+		cesaCmdRing[i].pSrc->numFrags = bufNum;
+		cesaCmdRing[i].pSrc->mbufSize = 0;
+
+		cesaCmdRing[i].pDst = &pMbufDst[i];
+		cesaCmdRing[i].pDst->pFrags = &pFragsDst[idx];
+		cesaCmdRing[i].pDst->numFrags = bufNum;
+		cesaCmdRing[i].pDst->mbufSize = 0;
+
+		for (j = 0; j < bufNum; j++) {
+			cesaCmdRing[i].pSrc->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf;
+			cesaCmdRing[i].pSrc->pFrags[j].bufSize = bufSize;
+			pBuf += bufSize;
+			cesaCmdRing[i].pDst->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf;
+			cesaCmdRing[i].pDst->pFrags[j].bufSize = bufSize;
+			pBuf += bufSize;
+		}
+		idx += bufNum;
+	}
+
+#ifndef MV_NETBSD
+	numOfSessions = CESA_DEF_SESSION_NUM;
+	queueDepth = CESA_DEF_REQ_SIZE;
+
+	status = mvSysCesaInit(numOfSessions, queueDepth, NULL);
+	if (status != MV_OK) {
+		mvOsPrintf("mvCesaInit is Failed: status = 0x%x\n", status);
+		/* !!!! Dima cesaTestCleanup(); */
+		return;
+	}
+#endif /* !MV_NETBSD */
+
+	/* Prepare data for tests */
+	for (i = 0; i < 50; i++)
+		strcat((char *)cesaDataHexStr3, "dd");
+
+	strcpy((char *)cesaDataAndMd5digest3, cesaDataHexStr3);
+	strcpy((char *)cesaDataAndSha1digest3, cesaDataHexStr3);
+
+	/* Digest must be 8 byte aligned */
+	for (; i < 56; i++) {
+		strcat((char *)cesaDataAndMd5digest3, "00");
+		strcat((char *)cesaDataAndSha1digest3, "00");
+	}
+	strcat((char *)cesaDataAndMd5digest3, cesaHmacMd5digestHex3);
+	strcat((char *)cesaDataAndSha1digest3, cesaHmacSha1digestHex3);
+
+	for (chan = 0; chan < MV_CESA_CHANNELS; chan++) {
+#ifndef MV_NETBSD
+		MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+		MV_REG_WRITE(MV_CESA_ISR_MASK_REG(chan), MV_CESA_CAUSE_ACC_DMA_MASK);
+#endif
+
+#ifdef MV_VXWORKS
+	{
+		MV_STATUS status;
+
+		status = intConnect((VOIDFUNCPTR *) INT_LVL_CESA, cesaTestReadyIsr, (int)NULL);
+		if (status != OK) {
+			mvOsPrintf("CESA: Can't connect CESA (%d) interrupt, status=0x%x \n", INT_LVL_CESA, status);
+			/* !!!! Dima cesaTestCleanup(); */
+			return;
+		}
+		cesaSemId = semMCreate(SEM_Q_PRIORITY | SEM_INVERSION_SAFE | SEM_DELETE_SAFE);
+		if (cesaSemId == NULL) {
+			mvOsPrintf("cesaTestStart: Can't create semaphore\n");
+			return;
+		}
+		intEnable(INT_LVL_CESA);
+	}
+#endif /* MV_VXWORKS */
+
+#if !defined(MV_NETBSD) && defined(__KERNEL__)
+		chanId[chan] = chan;
+		spin_lock_init(&cesaChanLock[chan]);
+		if (request_irq(CESA_IRQ(chan), cesaTestReadyIsr, (IRQF_DISABLED), irqName[chan], &chanId[chan])) {
+			mvOsPrintf("cannot assign irq\n");
+			/* !!!! Dima cesaTestCleanup(); */
+			return;
+		}
+	}
+	spin_lock_init(&cesaLock);
+
+#endif
+}
+
+MV_STATUS testRun(int idx, int caseIdx, int iter, int reqSize, int checkMode)
+{
+	int testIdx, count, sid, digestSize;
+	int blockSize;
+	MV_CESA_TEST_SESSION *pTestSession;
+	MV_CESA_COMMAND cmd;
+	MV_STATUS status;
+	MV_U8 chan;
+
+	memset(&cmd, 0, sizeof(cmd));
+
+	pTestSession = getTestSessionDb(idx, &testIdx);
+	if (pTestSession == NULL) {
+		mvOsPrintf("Test %d is not exist\n", idx);
+		return MV_BAD_PARAM;
+	}
+	pTestSession = &pTestSession[testIdx];
+
+	sid = pTestSession->sid;
+	if (sid == -1) {
+		mvOsPrintf("Test %d is not opened\n", idx);
+		return MV_BAD_STATE;
+	}
+	switch (pTestSession->cryptoAlgorithm) {
+	case MV_CESA_CRYPTO_DES:
+	case MV_CESA_CRYPTO_3DES:
+		blockSize = MV_CESA_DES_BLOCK_SIZE;
+		break;
+
+	case MV_CESA_CRYPTO_AES:
+		blockSize = MV_CESA_AES_BLOCK_SIZE;
+		break;
+
+	case MV_CESA_CRYPTO_NULL:
+		blockSize = 0;
+		break;
+
+	default:
+		mvOsPrintf("cesaTestRun: Bad CryptoAlgorithm=%d\n", pTestSession->cryptoAlgorithm);
+		return MV_BAD_PARAM;
+	}
+	switch (pTestSession->macAlgorithm) {
+	case MV_CESA_MAC_MD5:
+	case MV_CESA_MAC_HMAC_MD5:
+		digestSize = MV_CESA_MD5_DIGEST_SIZE;
+		break;
+
+	case MV_CESA_MAC_SHA1:
+	case MV_CESA_MAC_HMAC_SHA1:
+		digestSize = MV_CESA_SHA1_DIGEST_SIZE;
+		break;
+
+	case MV_CESA_MAC_SHA2:
+	case MV_CESA_MAC_HMAC_SHA2:
+		digestSize = MV_CESA_SHA2_DIGEST_SIZE;
+		break;
+
+	default:
+		digestSize = 0;
+	}
+
+	if (iter == 0)
+		iter = CESA_DEF_ITER_NUM;
+
+	if (pTestSession->direction == MV_CESA_DIR_ENCODE) {
+		cesaOutputHexStr = cesaTestCases[caseIdx].cipherHexStr;
+		cesaInputHexStr = cesaTestCases[caseIdx].plainHexStr;
+	} else {
+		cesaOutputHexStr = cesaTestCases[caseIdx].plainHexStr;
+		cesaInputHexStr = cesaTestCases[caseIdx].cipherHexStr;
+	}
+
+	cmd.sessionId = sid;
+	if (checkMode == CESA_FAST_CHECK_MODE) {
+		cmd.cryptoLength = cesaTestCases[caseIdx].cryptoLength;
+		cmd.macLength = cesaTestCases[caseIdx].macLength;
+	} else {
+		cmd.cryptoLength = reqSize;
+		cmd.macLength = reqSize;
+	}
+	cesaRateSize = cmd.cryptoLength;
+	cesaReqSize = cmd.cryptoLength;
+	cmd.cryptoOffset = 0;
+	if (pTestSession->operation != MV_CESA_MAC_ONLY) {
+		if ((pTestSession->cryptoMode == MV_CESA_CRYPTO_CBC) ||
+		    (pTestSession->cryptoMode == MV_CESA_CRYPTO_CTR)) {
+			cmd.ivOffset = 0;
+			cmd.cryptoOffset = blockSize;
+			if (cesaTestCases[caseIdx].pCryptoIV == NULL) {
+				cmd.ivFromUser = 1;
+			} else {
+				cmd.ivFromUser = 0;
+				for (chan = 0; chan < MV_CESA_CHANNELS; chan++)
+					mvCesaCryptoIvSet(chan, cesaTestCases[caseIdx].pCryptoIV, blockSize);
+			}
+			cesaReqSize = cmd.cryptoOffset + cmd.cryptoLength;
+		}
+	}
+
+/*
+	mvOsPrintf("ivFromUser=%d, cryptoLength=%d, cesaReqSize=%d, cryptoOffset=%d\n",
+				cmd.ivFromUser, cmd.cryptoLength, cesaReqSize, cmd.cryptoOffset);
+*/
+	if (pTestSession->operation != MV_CESA_CRYPTO_ONLY) {
+		cmd.macOffset = cmd.cryptoOffset;
+
+		if (cesaTestCases[caseIdx].digestOffset == -1) {
+			cmd.digestOffset = cmd.macOffset + cmd.macLength;
+			cmd.digestOffset = MV_ALIGN_UP(cmd.digestOffset, 8);
+		} else {
+			cmd.digestOffset = cesaTestCases[caseIdx].digestOffset;
+		}
+		if ((cmd.digestOffset + digestSize) > cesaReqSize)
+			cesaReqSize = cmd.digestOffset + digestSize;
+	}
+
+	cesaCheckMode = checkMode;
+
+	if (checkMode == CESA_NULL_CHECK_MODE) {
+		cesaCheckSize = 0;
+		cesaCheckOffset = 0;
+	} else {
+		if (pTestSession->operation == MV_CESA_CRYPTO_ONLY) {
+			cesaCheckOffset = 0;
+			cesaCheckSize = cmd.cryptoLength;
+		} else {
+			cesaCheckSize = digestSize;
+			cesaCheckOffset = cmd.digestOffset;
+		}
+	}
+/*
+	mvOsPrintf("reqSize=%d, checkSize=%d, checkOffset=%d, checkMode=%d\n",
+			cesaReqSize, cesaCheckSize, cesaCheckOffset, cesaCheckMode);
+
+	mvOsPrintf("blockSize=%d, ivOffset=%d, ivFromUser=%d, crOffset=%d, crLength=%d\n",
+			blockSize, cmd.ivOffset, cmd.ivFromUser,
+			cmd.cryptoOffset, cmd.cryptoLength);
+
+	mvOsPrintf("macOffset=%d, digestOffset=%d, macLength=%d\n",
+			cmd.macOffset, cmd.digestOffset, cmd.macLength);
+*/
+	status = testCmd(sid, iter, &cmd, pTestSession, cesaTestCases[caseIdx].pCryptoIV, blockSize);
+
+	if (status != MV_OK)
+		return status;
+
+	/* Wait when all callbacks is received */
+	count = 0;
+	while (cesaIsReady == MV_FALSE) {
+		mvOsSleep(10);
+		count++;
+		if (count > 100) {
+			mvOsPrintf("testRun: Timeout occured\n");
+			return MV_TIMEOUT;
+		}
+	}
+
+	return MV_OK;
+}
+
+void cesaTestStop(void)
+{
+	MV_CESA_MBUF *pMbufSrc, *pMbufDst;
+	MV_BUF_INFO *pFragsSrc, *pFragsDst;
+	int i;
+
+	/* Release all allocated memories */
+	pMbufSrc = (MV_CESA_MBUF *) (cesaCmdRing[0].pSrc);
+	pFragsSrc = cesaCmdRing[0].pSrc->pFrags;
+
+	pMbufDst = (MV_CESA_MBUF *) (cesaCmdRing[0].pDst);
+	pFragsDst = cesaCmdRing[0].pDst->pFrags;
+
+	mvOsFree(pMbufSrc);
+	mvOsFree(pMbufDst);
+	mvOsFree(pFragsSrc);
+	mvOsFree(pFragsDst);
+
+	for (i = 0; i < CESA_DEF_REQ_SIZE; i++) {
+		mvOsIoCachedFree(cesaTestOSHandle, cesaReqBufs[i].bufSize,
+				 cesaReqBufs[i].bufPhysAddr, cesaReqBufs[i].bufVirtPtr, cesaReqBufs[i].memHandle);
+	}
+	cesaDataHexStr3[0] = '\0';
+
+	/* Free CESA HAL resources */
+	mvCesaIfFinish();
+}
+
+void desTest(int iter, int reqSize, int checkMode)
+{
+	int mode, i;
+	MV_STATUS status;
+
+	mode = checkMode;
+	if (checkMode == CESA_FULL_CHECK_MODE)
+		mode = CESA_FAST_CHECK_MODE;
+	i = iter;
+	if (mode != CESA_NULL_CHECK_MODE)
+		i = 1;
+
+	testOpen(0);
+	testOpen(1);
+	testOpen(2);
+	testOpen(3);
+
+/* DES / ECB mode / Encrypt only */
+	status = testRun(0, 1, iter, reqSize, checkMode);
+	printTestResults(0, status, checkMode);
+
+/* DES / ECB mode / Decrypt only */
+	status = testRun(1, 1, iter, reqSize, checkMode);
+	printTestResults(1, status, checkMode);
+
+/* DES / CBC mode / Encrypt only */
+	status = testRun(2, 2, i, reqSize, mode);
+	printTestResults(2, status, mode);
+
+/* DES / CBC mode / Decrypt only */
+	status = testRun(3, 2, iter, reqSize, mode);
+	printTestResults(3, status, mode);
+
+	testClose(0);
+	testClose(1);
+	testClose(2);
+	testClose(3);
+}
+
+void tripleDesTest(int iter, int reqSize, int checkMode)
+{
+	int mode, i;
+	MV_STATUS status;
+
+	mode = checkMode;
+	if (checkMode == CESA_FULL_CHECK_MODE)
+		mode = CESA_FAST_CHECK_MODE;
+	i = iter;
+	if (mode != CESA_NULL_CHECK_MODE)
+		i = 1;
+
+	testOpen(100);
+	testOpen(101);
+	testOpen(102);
+	testOpen(103);
+
+/* 3DES / ECB mode / Encrypt only */
+	status = testRun(100, 1, iter, reqSize, checkMode);
+	printTestResults(100, status, checkMode);
+
+/* 3DES / ECB mode / Decrypt only */
+	status = testRun(101, 1, iter, reqSize, checkMode);
+	printTestResults(101, status, checkMode);
+
+/* 3DES / CBC mode / Encrypt only */
+	status = testRun(102, 2, i, reqSize, mode);
+	printTestResults(102, status, mode);
+
+/* 3DES / CBC mode / Decrypt only */
+	status = testRun(103, 2, iter, reqSize, mode);
+	printTestResults(103, status, mode);
+
+	testClose(100);
+	testClose(101);
+	testClose(102);
+	testClose(103);
+}
+
+void aesTest(int iter, int reqSize, int checkMode)
+{
+	MV_STATUS status;
+	int mode, i;
+
+	mode = checkMode;
+	if (checkMode == CESA_FULL_CHECK_MODE)
+		mode = CESA_FAST_CHECK_MODE;
+
+	i = iter;
+	if (mode != CESA_NULL_CHECK_MODE)
+		i = 1;
+
+	testOpen(200);
+	testOpen(201);
+	testOpen(202);
+	testOpen(203);
+	testOpen(204);
+	testOpen(205);
+	testOpen(206);
+	testOpen(207);
+	testOpen(208);
+
+/* AES-128 Encode ECB mode */
+	status = testRun(200, 3, iter, reqSize, checkMode);
+	printTestResults(200, status, checkMode);
+
+/* AES-128 Decode ECB mode */
+	status = testRun(201, 3, iter, reqSize, checkMode);
+	printTestResults(201, status, checkMode);
+
+/* AES-128 Encode CBC mode (IV from SA) */
+	status = testRun(202, 10, i, reqSize, mode);
+	printTestResults(202, status, mode);
+
+/* AES-128 Encode CBC mode (IV from User) */
+	status = testRun(202, 24, i, reqSize, mode);
+	printTestResults(202, status, mode);
+
+/* AES-128 Decode CBC mode */
+	status = testRun(203, 24, iter, reqSize, mode);
+	printTestResults(203, status, checkMode);
+
+/* AES-192 Encode ECB mode */
+	status = testRun(204, 4, iter, reqSize, checkMode);
+	printTestResults(204, status, checkMode);
+
+/* AES-192 Decode ECB mode */
+	status = testRun(205, 4, iter, reqSize, checkMode);
+	printTestResults(205, status, checkMode);
+
+/* AES-256 Encode ECB mode */
+	status = testRun(206, 5, iter, reqSize, checkMode);
+	printTestResults(206, status, checkMode);
+
+/* AES-256 Decode ECB mode */
+	status = testRun(207, 5, iter, reqSize, checkMode);
+	printTestResults(207, status, checkMode);
+
+#if 0
+/* AES-128 Encode CTR mode */
+	status = testRun(208, 23, iter, reqSize, mode);
+	printTestResults(208, status, checkMode);
+#endif
+
+	testClose(200);
+	testClose(201);
+	testClose(202);
+	testClose(203);
+	testClose(204);
+	testClose(205);
+	testClose(206);
+	testClose(207);
+	testClose(208);
+}
+
+void mdTest(int iter, int reqSize, int checkMode)
+{
+	int mode;
+	MV_STATUS status;
+
+	if (iter == 0)
+		iter = CESA_DEF_ITER_NUM;
+
+	mode = checkMode;
+	if (checkMode == CESA_FULL_CHECK_MODE)
+		mode = CESA_FAST_CHECK_MODE;
+
+	testOpen(300);
+	testOpen(301);
+	testOpen(302);
+	testOpen(303);
+	testOpen(305);
+
+/* HMAC-MD5 Generate signature test */
+	status = testRun(300, 6, iter, reqSize, mode);
+	printTestResults(300, status, checkMode);
+
+/* HMAC-MD5 Verify Signature test */
+	status = testRun(301, 7, iter, reqSize, mode);
+	printTestResults(301, status, checkMode);
+
+/* HMAC-MD5 Generate signature test */
+	status = testRun(302, 8, iter, reqSize, mode);
+	printTestResults(302, status, checkMode);
+
+/* HMAC-MD5 Verify Signature test */
+	status = testRun(303, 9, iter, reqSize, mode);
+	printTestResults(303, status, checkMode);
+
+/* HASH-MD5 Generate signature test */
+	status = testRun(305, 15, iter, reqSize, mode);
+	printTestResults(305, status, checkMode);
+
+	testClose(300);
+	testClose(301);
+	testClose(302);
+	testClose(303);
+	testClose(305);
+}
+
+void sha1Test(int iter, int reqSize, int checkMode)
+{
+	int mode;
+	MV_STATUS status;
+
+	if (iter == 0)
+		iter = CESA_DEF_ITER_NUM;
+
+	mode = checkMode;
+	if (checkMode == CESA_FULL_CHECK_MODE)
+		mode = CESA_FAST_CHECK_MODE;
+
+	testOpen(400);
+	testOpen(401);
+	testOpen(402);
+	testOpen(403);
+	testOpen(405);
+
+/* HMAC-SHA1 Generate signature test */
+	status = testRun(400, 11, iter, reqSize, mode);
+	printTestResults(400, status, checkMode);
+
+/* HMAC-SHA1 Verify Signature test */
+	status = testRun(401, 12, iter, reqSize, mode);
+	printTestResults(401, status, checkMode);
+
+/* HMAC-SHA1 Generate signature test */
+	status = testRun(402, 13, iter, reqSize, mode);
+	printTestResults(402, status, checkMode);
+
+/* HMAC-SHA1 Verify Signature test */
+	status = testRun(403, 14, iter, reqSize, mode);
+	printTestResults(403, status, checkMode);
+
+/* HMAC-SHA1 Generate signature test */
+	status = testRun(405, 16, iter, reqSize, mode);
+	printTestResults(405, status, checkMode);
+
+	testClose(400);
+	testClose(401);
+	testClose(402);
+	testClose(403);
+	testClose(405);
+}
+
+void sha2Test(int iter, int reqSize, int checkMode)
+{
+	int mode;
+	MV_STATUS status;
+
+	if (iter == 0)
+		iter = CESA_DEF_ITER_NUM;
+
+	mode = checkMode;
+	if (checkMode == CESA_FULL_CHECK_MODE)
+		mode = CESA_FAST_CHECK_MODE;
+
+	testOpen(500);
+	testOpen(501);
+	testOpen(502);
+	testOpen(503);
+
+/* HMAC-SHA2 Generate signature test */
+	status = testRun(500, 28, iter, reqSize, mode);
+	printTestResults(500, status, checkMode);
+/* HMAC-SHA2 Verify signature test */
+	status = testRun(501, 29, iter, reqSize, mode);
+	printTestResults(501, status, checkMode);
+/* HMAC-SHA2 Generate signature test */
+	status = testRun(502, 30, iter, reqSize, mode);
+	printTestResults(502, status, checkMode);
+/* HMAC-SHA2 Verify signature test */
+	status = testRun(503, 31, iter, reqSize, mode);
+	printTestResults(503, status, checkMode);
+
+	testClose(500);
+	testClose(501);
+	testClose(502);
+	testClose(503);
+}
+
+void combiTest(int iter, int reqSize, int checkMode)
+{
+	MV_STATUS status;
+	int mode, i;
+
+	mode = checkMode;
+	if (checkMode == CESA_FULL_CHECK_MODE)
+		mode = CESA_FAST_CHECK_MODE;
+
+	if (iter == 0)
+		iter = CESA_DEF_ITER_NUM;
+
+	i = iter;
+	if (mode != CESA_NULL_CHECK_MODE)
+		i = 1;
+
+	testOpen(600);
+	testOpen(601);
+	testOpen(602);
+	testOpen(603);
+	testOpen(604);
+	testOpen(605);
+	testOpen(606);
+	testOpen(607);
+	testOpen(609);
+
+/* DES ECB + MD5 encode test */
+	status = testRun(600, 17, iter, reqSize, mode);
+	printTestResults(600, status, mode);
+
+/* DES ECB + SHA1 encode test */
+	status = testRun(601, 18, iter, reqSize, mode);
+	printTestResults(601, status, mode);
+
+/* 3DES ECB + MD5 encode test */
+	status = testRun(602, 17, iter, reqSize, mode);
+	printTestResults(602, status, mode);
+
+/* 3DES ECB + SHA1 encode test */
+	status = testRun(603, 18, iter, reqSize, mode);
+	printTestResults(603, status, mode);
+
+/* 3DES CBC + MD5 encode test */
+	status = testRun(604, 19, i, reqSize, mode);
+	printTestResults(604, status, mode);
+
+/* 3DES CBC + SHA1 encode test */
+	status = testRun(605, 20, i, reqSize, mode);
+	printTestResults(605, status, mode);
+
+/* AES-128 CBC + MD5 encode test */
+	status = testRun(606, 21, i, reqSize, mode);
+	printTestResults(606, status, mode);
+
+/* AES-128 CBC + SHA1 encode test */
+	status = testRun(607, 22, i, reqSize, mode);
+	printTestResults(607, status, mode);
+
+/* AES-128 CBC + SHA2 encode test */
+	status = testRun(609, 32, i, reqSize, mode);
+	printTestResults(609, status, mode);
+
+	testClose(600);
+	testClose(601);
+	testClose(602);
+	testClose(603);
+	testClose(604);
+	testClose(605);
+	testClose(606);
+	testClose(607);
+	testClose(609);
+}
+
+void cesaOneTest(int testIdx, int caseIdx, int iter, int reqSize, int checkMode)
+{
+	MV_STATUS status;
+
+	if (iter == 0)
+		iter = CESA_DEF_ITER_NUM;
+
+	mvOsPrintf("test=%d, case=%d, size=%d, iter=%d\n", testIdx, caseIdx, reqSize, iter);
+
+	status = testOpen(testIdx);
+
+	status = testRun(testIdx, caseIdx, iter, reqSize, checkMode);
+	printTestResults(testIdx, status, checkMode);
+	status = testClose(testIdx);
+
+}
+
+void cesaTest(int iter, int reqSize, int checkMode)
+{
+	if (iter == 0)
+		iter = CESA_DEF_ITER_NUM;
+
+	mvOsPrintf("%d iteration\n", iter);
+	mvOsPrintf("%d size\n\n", reqSize);
+
+/* DES tests */
+	desTest(iter, reqSize, checkMode);
+
+/* 3DES tests */
+	tripleDesTest(iter, reqSize, checkMode);
+
+/* AES tests */
+	aesTest(iter, reqSize, checkMode);
+
+/* MD5 tests */
+	mdTest(iter, reqSize, checkMode);
+
+/* SHA-1 tests */
+	sha1Test(iter, reqSize, checkMode);
+
+/* SHA-2 tests */
+	sha2Test(iter, reqSize, checkMode);
+}
+
+void multiSizeTest(int idx, int iter, int checkMode, char *inputData)
+{
+	MV_STATUS status;
+	int i;
+	MV_CESA_SIZE_TEST *pMultiTest;
+
+	if (testOpen(idx) != MV_OK)
+		return;
+
+	if (iter == 0)
+		iter = CESA_DEF_ITER_NUM;
+
+	if (checkMode == CESA_SHOW_CHECK_MODE)
+		iter = 1;
+	else
+		checkMode = CESA_FULL_CHECK_MODE;
+
+	cesaTestCases[0].plainHexStr = inputData;
+	cesaTestCases[0].pCryptoIV = NULL;
+
+	switch (idx) {
+	case 302:
+		pMultiTest = mdMultiSizeTest302;
+		if (inputData == NULL)
+			cesaTestCases[0].plainHexStr = cesaDataHexStr3;
+		break;
+
+	case 304:
+		pMultiTest = mdMultiSizeTest304;
+		if (inputData == NULL)
+			cesaTestCases[0].plainHexStr = hashHexStr80;
+		break;
+
+	case 305:
+		pMultiTest = mdMultiSizeTest305;
+		if (inputData == NULL)
+			cesaTestCases[0].plainHexStr = hashHexStr80;
+		break;
+
+	case 402:
+		pMultiTest = sha1MultiSizeTest402;
+		if (inputData == NULL)
+			cesaTestCases[0].plainHexStr = hashHexStr80;
+		break;
+
+	case 404:
+		pMultiTest = sha1MultiSizeTest404;
+		if (inputData == NULL)
+			cesaTestCases[0].plainHexStr = hashHexStr80;
+		break;
+
+	case 405:
+		pMultiTest = sha1MultiSizeTest405;
+		if (inputData == NULL)
+			cesaTestCases[0].plainHexStr = hashHexStr80;
+		break;
+
+	case 602:
+		pMultiTest = tripleDesMdMultiSizeTest602;
+		if (inputData == NULL)
+			cesaTestCases[0].plainHexStr = hashHexStr80;
+		break;
+
+	case 603:
+		pMultiTest = tripleDesShaMultiSizeTest603;
+		if (inputData == NULL)
+			cesaTestCases[0].plainHexStr = hashHexStr80;
+		break;
+
+	case 604:
+		iter = 1;
+		pMultiTest = cbc3desMdMultiSizeTest604;
+		cesaTestCases[0].pCryptoIV = iv1;
+		if (inputData == NULL)
+			cesaTestCases[0].plainHexStr = hashHexStr80;
+		break;
+
+	case 605:
+		iter = 1;
+		pMultiTest = cbc3desShaMultiSizeTest605;
+		cesaTestCases[0].pCryptoIV = iv1;
+		if (inputData == NULL)
+			cesaTestCases[0].plainHexStr = hashHexStr80;
+		break;
+
+	case 606:
+		iter = 1;
+		pMultiTest = cbcAes128md5multiSizeTest606;
+		cesaTestCases[0].pCryptoIV = iv5;
+		if (inputData == NULL)
+			cesaTestCases[0].plainHexStr = hashHexStr80;
+		break;
+
+	case 607:
+		iter = 1;
+		pMultiTest = cbcAes128sha1multiSizeTest607;
+		cesaTestCases[0].pCryptoIV = iv5;
+		if (inputData == NULL)
+			cesaTestCases[0].plainHexStr = hashHexStr80;
+		break;
+
+	default:
+		iter = 1;
+		checkMode = CESA_SHOW_CHECK_MODE;
+		pMultiTest = mdMultiSizeTest302;
+		if (inputData == NULL)
+			cesaTestCases[0].plainHexStr = hashHexStr80;
+	}
+	i = 0;
+	while (pMultiTest[i].outputHexStr != NULL) {
+		cesaTestCases[0].cipherHexStr = (char *)pMultiTest[i].outputHexStr;
+		status = testRun(idx, 0, iter, pMultiTest[i].size, checkMode);
+		if (checkMode != CESA_SHOW_CHECK_MODE) {
+			cesaReqSize = pMultiTest[i].size;
+			printTestResults(idx, status, checkMode);
+		}
+		if (status != MV_OK)
+			break;
+		i++;
+	}
+	testClose(idx);
+/*
+    mvCesaDebugStatus();
+    cesaTestPrintStatus();
+*/
+}
+
+void open_session_test(int idx, int caseIdx, int iter)
+{
+	int reqIdError, cryptoError, openErrors, i;
+	int openErrDisp[100];
+	MV_STATUS status;
+
+	memset(openErrDisp, 0, sizeof(openErrDisp));
+	openErrors = 0;
+	reqIdError = 0;
+	cryptoError = 0;
+	for (i = 0; i < iter; i++) {
+		status = testOpen(idx);
+		if (status != MV_OK) {
+			openErrors++;
+			openErrDisp[status]++;
+		} else {
+			testRun(idx, caseIdx, 1, 0, CESA_FAST_CHECK_MODE);
+			if (cesaCryptoError > 0)
+				cryptoError++;
+			if (cesaReqIdError > 0)
+				reqIdError++;
+
+			testClose(idx);
+		}
+	}
+	if (cryptoError > 0)
+		mvOsPrintf("cryptoError : %d\n", cryptoError);
+	if (reqIdError > 0)
+		mvOsPrintf("reqIdError  : %d\n", reqIdError);
+
+	if (openErrors > 0) {
+		mvOsPrintf("Open Errors = %d\n", openErrors);
+		for (i = 0; i < 100; i++) {
+			if (openErrDisp[i] != 0)
+				mvOsPrintf("Error %d - occurs %d times\n", i, openErrDisp[i]);
+		}
+	}
+}
+
+void loopback_test(int idx, int iter, int size, char *pPlainData)
+{
+}
+
+#if defined(MV_VXWORKS)
+int testMode = 0;
+unsigned __TASKCONV cesaTask(void *args)
+{
+	int reqSize = cesaReqSize;
+
+	if (testMode == 0) {
+		cesaOneTest(cesaTestIdx, cesaCaseIdx, cesaIteration, reqSize, cesaCheckMode);
+	} else {
+		if (testMode == 1) {
+			cesaTest(cesaIteration, reqSize, cesaCheckMode);
+			combiTest(cesaIteration, reqSize, cesaCheckMode);
+		} else {
+			multiSizeTest(cesaIdx, cesaIteration, cesaCheckMode, NULL);
+		}
+	}
+	return 0;
+}
+
+void oneTest(int testIdx, int caseIdx, int iter, int reqSize, int checkMode)
+{
+	long rc;
+
+	cesaIteration = iter;
+	cesaReqSize = cesaRateSize = reqSize;
+	cesaCheckMode = checkMode;
+	testMode = 0;
+	cesaTestIdx = testIdx;
+	cesaCaseIdx = caseIdx;
+	rc = mvOsTaskCreate("CESA_T", 100, 4 * 1024, cesaTask, NULL, &cesaTaskId);
+	if (rc != MV_OK)
+		mvOsPrintf("hMW: Can't create CESA multiCmd test task, rc = %d\n", (int)rc);
+}
+
+void multiTest(int iter, int reqSize, int checkMode)
+{
+	long rc;
+
+	cesaIteration = iter;
+	cesaCheckMode = checkMode;
+	cesaReqSize = reqSize;
+	testMode = 1;
+	rc = mvOsTaskCreate("CESA_T", 100, 4 * 1024, cesaTask, NULL, &cesaTaskId);
+	if (rc != MV_OK)
+		mvOsPrintf("hMW: Can't create CESA multiCmd test task, rc = %d\n", (int)rc);
+}
+
+void sizeTest(int testIdx, int iter, int checkMode)
+{
+	long rc;
+
+	cesaIteration = iter;
+	cesaCheckMode = checkMode;
+	testMode = 2;
+	cesaIdx = testIdx;
+	rc = mvOsTaskCreate("CESA_T", 100, 4 * 1024, cesaTask, NULL, &cesaTaskId);
+	if (rc != MV_OK)
+		mvOsPrintf("hMW: Can't create CESA test task, rc = %d\n", (int)rc);
+}
+
+#endif /* MV_VXWORKS */
+
+extern void mvCesaDebugSA(short sid, int mode);
+void cesaTestPrintSession(int idx)
+{
+	int testIdx;
+	MV_CESA_TEST_SESSION *pTestSession;
+
+	pTestSession = getTestSessionDb(idx, &testIdx);
+	if (pTestSession == NULL) {
+		mvOsPrintf("Test %d is not exist\n", idx);
+		return;
+	}
+	pTestSession = &pTestSession[testIdx];
+
+	if (pTestSession->sid == -1) {
+		mvOsPrintf("Test session %d is not opened\n", idx);
+		return;
+	}
+
+	mvCesaDebugSA(pTestSession->sid, 1);
+}
+
+void cesaTestPrintStatus(void)
+{
+	mvOsPrintf("\n\t Cesa Test Status\n\n");
+
+	mvOsPrintf("isrCount=%d\n", cesaTestIsrCount);
+
+#ifdef CESA_TEST_DEBUG
+	{
+		int i, j;
+		j = cesaTestTraceIdx;
+		mvOsPrintf("No  Type  Cause   rCause   errCause   Res     Time     pReady    pProc    pEmpty\n");
+		for (i = 0; i < MV_CESA_TEST_TRACE_SIZE; i++) {
+			mvOsPrintf
+			    ("%02d.  %d   0x%04x  0x%04x   0x%04x   0x%02x   0x%02x   %02d   0x%06x  %p  %p  %p\n", j,
+			     cesaTestTrace[j].type, cesaTestTrace[j].cause, cesaTestTrace[j].realCause,
+			     cesaTestTrace[j].dmaErrCause, cesaTestTrace[j].resources, cesaTestTrace[j].timeStamp,
+			     cesaTestTrace[j].pReqReady, cesaTestTrace[j].pReqProcess, cesaTestTrace[j].pReqEmpty);
+			j++;
+			if (j == MV_CESA_TEST_TRACE_SIZE)
+				j = 0;
+		}
+	}
+#endif /* CESA_TEST_DEBUG */
+}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_dma/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_dma/Kconfig
new file mode 100644
index 0000000..85bcaf6
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_dma/Kconfig
@@ -0,0 +1,55 @@
+config MV_USE_IDMA_ENGINE
+        bool "Use the IDMA engine to offload CPU tasks"   
+        depends on (MV_INCLUDE_IDMA && !MV_USE_XOR_ENGINE) && EXPERIMENTAL
+        default n
+        help
+            Say Y of you want to use the IDMA engine to offload some of the 
+            CPU tasks.
+
+config MV_IDMA_COPYUSER
+        bool "Use the IDMA enignes to accelerate the copy_to_user() and copy_from_user functions"
+        depends on (MV_USE_IDMA_ENGINE) && !MV_USE_XOR_COPY_TO_USER && !MV_USE_XOR_COPY_FROM_USER
+        default n
+        help
+          Say Y here if you want to use the IDMA engine to perform
+          copy_to_user() and copy_from_user() functionality.
+
+config MV_IDMA_COPYUSER_THRESHOLD
+        int "Minimum number of bytes to use IDMA acceleration for copy_to_user() and copy_from_user()"
+        depends on MV_IDMA_COPYUSER
+        default "1260"
+        help
+          This is the minimum buffer size needed in order to operate the IDMA engine
+          for accelerating the copy_to_user() and copy_from_user() operations
+
+config MV_IDMA_MEMZERO
+        bool "Use the IDMA to accelerate memzero"
+        depends on (MV_USE_IDMA_ENGINE) && 0
+        default n
+        help
+          Say Y here if you want to use the IDMA engine to perform the memzero. (not supported)
+
+config MV_IDMA_MEMZERO_THRESHOLD
+        int "Minimum number of bytes to use IDMA acceleration for memzero()"
+        depends on MV_IDMA_MEMZERO
+        default "192"
+        help
+          This is the minimum buffer size needed in order to operate the IDMA engine
+          for accelerating the memzero operation
+
+config MV_IDMA_MEMCOPY
+        bool "Use the IDMA to accelerate memcpy and memmove"
+        depends on (MV_USE_IDMA_ENGINE) && !MV_XOR_MEMCOPY
+        default n
+        help
+          Say Y here if you want to use the IDMA engine to perform the memcpy 
+          and memmove.
+
+config MV_IDMA_MEMCOPY_THRESHOLD
+        int "Minimum number of bytes to use IDMA acceleration for memcpy()"
+        depends on MV_IDMA_MEMCOPY
+        default "128"
+        help
+          This is the minimum buffer size needed in order to operate the IDMA engine
+          for accelerating the memcpy() and memmove() operations
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_dma/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_dma/Makefile
new file mode 100644
index 0000000..8cae7c9
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_dma/Makefile
@@ -0,0 +1,14 @@
+#
+# Makefile for the Marvell DMA Driver
+#
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+obj-$(CONFIG_MV_USE_IDMA_ENGINE) += mv_dma.o 
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_dma/mv_dma.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_dma/mv_dma.c
new file mode 100644
index 0000000..509aca2
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_dma/mv_dma.c
@@ -0,0 +1,798 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <linux/device.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/sysdev.h>
+#include <asm/mach/time.h>
+#include <asm/uaccess.h>
+#include <linux/proc_fs.h>
+
+#include "idma/mvIdma.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+
+#if defined (CONFIG_MV_XOR_MEMCOPY) || defined (CONFIG_MV_IDMA_MEMCOPY)
+#define memcpy asm_memcpy
+#define asm_memmove memmove
+#endif
+
+#ifndef COPYUSER_MIN_SIZE
+#define COPYUSER_MIN_SIZE	CONFIG_MV_IDMA_COPYUSER_THRESHOLD
+#endif
+
+#undef DEBUG
+//#define DEBUG
+
+#ifdef DEBUG
+	#define DPRINTK(s, args...)  printk("MV_DMA: " s, ## args)
+#else
+	#define DPRINTK(s, args...)
+#endif
+
+#undef CPY_USE_DESC
+#undef RT_DEBUG
+#define RT_DEBUG
+
+#define CPY_IDMA_CTRL_LOW_VALUE      ICCLR_DST_BURST_LIM_128BYTE   \
+                                    | ICCLR_SRC_BURST_LIM_128BYTE   \
+                                    | ICCLR_INT_MODE_MASK           \
+                                    | ICCLR_BLOCK_MODE              \
+                                    | ICCLR_CHAN_ENABLE             \
+                                    | ICCLR_DESC_MODE_16M
+
+#define CPY_CHAN1	2
+#define CPY_CHAN2	3
+
+#define CPY_DMA_TIMEOUT	0x100000
+
+#define NEXT_CHANNEL(channel) ((CPY_CHAN1 + CPY_CHAN2) - (channel))
+#define PREV_CHANNEL(channel) NEXT_CHANNEL(channel)
+static MV_U32 current_dma_channel =  CPY_CHAN1;
+static int idma_init = 0;
+static int idma_busy = 0;
+
+#ifdef RT_DEBUG
+static int dma_wait_loops = 0;
+#endif
+
+#ifdef CONFIG_MV_IDMA_MEMZERO
+#define	DMA_MEMZERO_CHUNK    0x80 /*128*/    /* this is based on the size of the DST and SRC burst limits */
+static MV_U8	dmaMemInitBuff[DMA_MEMZERO_CHUNK] __attribute__(( aligned(128) ));
+#endif
+
+#define IDMA_MIN_COPY_CHUNK CONFIG_MV_IDMA_COPYUSER_THRESHOLD
+
+static inline u32 page_remainder(u32 virt)
+{
+	return PAGE_SIZE - (virt & ~PAGE_MASK);
+}
+
+/*
+ * map a kernel virtual address or kernel logical address to a phys address
+ */
+static inline u32 physical_address(u32 virt, int write)
+{
+    struct page *page;
+       /* kernel static-mapped address */
+    DPRINTK(" get physical address: virt %x , write %d\n", virt, write);
+    if (virt_addr_valid(virt)) 
+    {
+        return __pa((u32) virt);
+    }
+    if (virt >= high_memory)
+	    return 0;
+    
+    if (virt >= TASK_SIZE)
+    {
+        page = follow_page(find_extend_vma(&init_mm, virt), (u32) virt, write);
+    }
+    else
+    {
+        page = follow_page(find_extend_vma(current->mm, virt), (u32) virt, write);
+    }
+    
+    if (pfn_valid(page_to_pfn(page)))
+    {
+        return ((page_to_pfn(page) << PAGE_SHIFT) |
+                       ((u32) virt & (PAGE_SIZE - 1)));
+    }
+    else
+    {
+        return 0;
+    }
+}
+
+unsigned int wait_for_idma(MV_U32   channel)
+{
+	u32 timeout = 0;
+
+	/* wait for completion */
+        while( mvDmaStateGet(channel) != MV_IDLE )
+	{
+		DPRINTK(" ctrl low is %x \n", MV_REG_READ(IDMA_CTRL_LOW_REG(channel)));
+		//udelay(1);
+#ifdef RT_DEBUG
+                dma_wait_loops++; 
+#endif
+		if(timeout++ > CPY_DMA_TIMEOUT)
+                {
+		    printk("dma_copy: IDMA %d timed out , ctrl low is %x \n",
+                    channel, MV_REG_READ(IDMA_CTRL_LOW_REG(channel)));
+                    return 1;
+                }		
+	}
+	DPRINTK("IDMA complete in %x \n", timeout);
+	return 0;
+}
+
+static struct proc_dir_entry *dma_proc_entry;
+static int dma_to_user = 0;
+static int dma_from_user = 0;
+static int dma_memcpy_cnt = 0;
+static int dma_memzero_cnt = 0;
+#ifdef RT_DEBUG
+static int dma_activations = 0;
+#endif
+static int dma_read_proc(char *, char **, off_t, int, int *, void *);
+
+static int dma_read_proc(char *buf, char **start, off_t offset, int len,
+						 int *eof, void *data)
+{
+	len = 0;
+#ifdef CONFIG_MV_IDMA_COPYUSER
+        len += sprintf(buf + len, "DMA min buffer size for copy to/from user %d\n", COPYUSER_MIN_SIZE);
+#endif
+#ifdef CONFIG_MV_IDMA_MEMCOPY
+	len += sprintf(buf + len, "DMA min buffer size for memcpy and memmove %d\n", CONFIG_MV_IDMA_MEMCOPY_THRESHOLD);
+#endif
+#ifdef CONFIG_MV_IDMA_MEMZERO
+	len += sprintf(buf + len, "DMA min buffer size for memzero %d\n", CONFIG_MV_IDMA_MEMZERO_THRESHOLD);
+#endif
+	len += sprintf(buf + len, "Number of DMA copy to user %d copy from user %d \n", dma_to_user, dma_from_user);
+	len += sprintf(buf + len, "Number of DMA memzero %d \n", dma_memzero_cnt);
+	len += sprintf(buf + len, "Number of DMA memcpy %d \n", dma_memcpy_cnt);
+#ifdef RT_DEBUG
+	len += sprintf(buf + len, "Number of dma activations %d\n", dma_activations);
+	len += sprintf(buf + len, "Number of wait for dma loops %d\n", dma_wait_loops);
+#endif
+        
+	return len;
+}
+#ifdef CONFIG_MV_IDMA_COPYUSER
+#warning "no protection from speculative I fetch"
+//probably not needed since operation is closed in spin_lock_irq 
+/*=======================================================================*/
+/*  Procedure:  dma_copy()                                               */
+/*                                                                       */
+/*  Description:    DMA-based copy_to_user.                              */
+/*                                                                       */
+/*  Parameters:  to: destination address                                 */
+/*               from: source address                                    */
+/*               n: number of bytes to transfer (n must be greater       */
+/*                   equal than 64)                                     */
+/*		 to_user: (1) Copy TO user (0) Copy FROM user	 	 */
+/*                                                                       */
+/*  Returns:     unsigned long: number of bytes NOT copied               */
+/*                                                                       */
+/*=======================================================================*/
+static unsigned long dma_copy(void *to, const void *from, unsigned long n, unsigned int to_user)
+{
+	u32 chunk,i;
+	u32 k_chunk = 0;
+	u32 u_chunk = 0;
+	u32 phys_from, phys_to;
+	
+        unsigned long flags;
+	u32 unaligned_to;
+	u32 index = 0;
+        u32 temp;
+
+        unsigned long uaddr, kaddr;
+        unsigned char kaddr_kernel_static = 0;
+	DPRINTK("dma_copy: entering\n");
+
+
+	/* 
+      	 * The unaligned is taken care seperatly since the dst might be part of a cache line that is changed 
+	 * by other process -> we must not invalidate this cache lines and we can't also flush it, since other 
+	 * process (or the exception handler) might fetch the cache line before we copied it. 
+	 */
+
+	/*
+	 * Ok, start addr is not cache line-aligned, so we need to make it so.
+	 */
+	unaligned_to = (u32)to & 31;
+	if(unaligned_to)
+	{
+		DPRINTK("Fixing up starting address %d bytes\n", 32 - unaligned_to);
+
+		if(to_user)
+			__arch_copy_to_user(to, from, 32 - unaligned_to);
+		else
+			__arch_copy_from_user(to, from, 32 - unaligned_to);
+
+		temp = (u32)to + (32 - unaligned_to);
+		to = (void *)temp;
+		temp = (u32)from + (32 - unaligned_to);
+		from = (void *)temp;
+
+                /*it's ok, n supposed to be greater than 32 bytes at this point*/
+		n -= (32 - unaligned_to);
+	}
+
+	/*
+	 * Ok, we're aligned at the top, now let's check the end
+	 * of the buffer and align that. After this we should have
+	 * a block that is a multiple of cache line size.
+	 */
+	unaligned_to = ((u32)to + n) & 31;
+	if(unaligned_to)
+	{	
+		u32 tmp_to = (u32)to + (n - unaligned_to);
+		u32 tmp_from = (u32)from + (n - unaligned_to);
+		DPRINTK("Fixing ending alignment %d bytes\n", unaligned_to);
+
+		if(to_user)
+			__arch_copy_to_user((void *)tmp_to, (void *)tmp_from, unaligned_to);
+		else
+			__arch_copy_from_user((void *)tmp_to, (void *)tmp_from, unaligned_to);
+
+                /*it's ok, n supposed to be greater than 32 bytes at this point*/
+		n -= unaligned_to;
+	}
+
+        if(to_user)
+        {
+            uaddr = (unsigned long)to;  
+            kaddr = (unsigned long)from;
+        }
+        else
+        {
+             uaddr = (unsigned long)from;
+             kaddr = (unsigned long)to;
+        }
+        if(virt_addr_valid(kaddr))
+        {
+            kaddr_kernel_static = 1;
+            k_chunk = n;
+        }
+	else
+	{
+		DPRINTK("kernel address is not linear, fall back\n");
+		goto exit_dma;
+	}
+         
+        spin_lock_irqsave(&current->mm->page_table_lock, flags);
+	if (idma_busy)
+	{
+	    BUG();
+	}
+	idma_busy = 1;
+     
+        i = 0;
+	while(n > 0)
+	{
+	    if(k_chunk == 0)
+	    {
+                /* virtual address */
+	        k_chunk = page_remainder((u32)kaddr);
+		DPRINTK("kaddr reminder %d \n",k_chunk);
+	    }
+
+	    if(u_chunk == 0)
+	    {
+                u_chunk = page_remainder((u32)uaddr);
+                DPRINTK("uaddr reminder %d \n", u_chunk);
+            }
+        
+            chunk = ((u_chunk < k_chunk) ? u_chunk : k_chunk);
+            if(n < chunk)
+	    {
+		chunk = n;
+	    }
+
+	    if(chunk == 0)
+	    {
+	    	break;
+	    }
+            phys_from = physical_address((u32)from, 0);
+            phys_to = physical_address((u32)to, 1);
+	    DPRINTK("choose chunk %d \n",chunk);
+	    /*
+	     *  Prepare the IDMA.
+	     */
+            if (chunk < IDMA_MIN_COPY_CHUNK)
+            {
+        	DPRINTK(" chunk %d too small , use memcpy \n",chunk);
+                /* the "to" address might cross cache line boundary, so part of the line*/  
+                /* may be subject to DMA, so we need to wait to last DMA engine to finish */
+                if (index > 0)
+                {
+                    if(wait_for_idma(PREV_CHANNEL(current_dma_channel)))
+                    {
+	                BUG();
+                    }
+                }
+                
+        	if(to_user)
+	       	    __arch_copy_to_user((void *)to, (void *)from, chunk);
+	        else
+		    __arch_copy_from_user((void *)to, (void *)from, chunk);
+            }
+            else if ((!phys_from) || (!phys_to))
+            {
+                /* The requested page isn't available, fall back to */
+                DPRINTK(" no physical address, fall back: from %p , to %p \n", from, to);
+                goto wait_for_idmas;
+   
+            }
+            else
+            {
+                /* 
+	 	 * Ensure that the cache is clean:
+	 	 *      - from range must be cleaned
+        	 *      - to range must be invalidated
+	         */
+		dmac_flush_range(from, from + chunk);
+		dmac_inv_range(to, to + chunk);
+               
+               	    if(index > 1)
+		    {
+		        if(wait_for_idma(current_dma_channel))
+                        {
+		            BUG(); 
+                            goto unlock_dma;
+                        }
+                    }
+		    /* Start DMA */
+                    DPRINTK(" activate DMA: channel %d from %x to %x len %x\n",
+                            current_dma_channel, phys_from, phys_to, chunk);
+		    mvDmaTransfer(current_dma_channel, phys_from, phys_to, chunk, 0);
+                    current_dma_channel = NEXT_CHANNEL(current_dma_channel); 
+#ifdef RT_DEBUG
+                    dma_activations++;
+#endif
+		    index++;
+                }
+                
+
+		/* go to next chunk */
+		from += chunk;
+		to += chunk;
+                kaddr += chunk;
+                uaddr += chunk;
+		n -= chunk;
+		u_chunk -= chunk;
+		k_chunk -= chunk;		
+	}
+        
+wait_for_idmas:
+        if (index > 1)
+        {
+	    if(wait_for_idma(current_dma_channel))
+            {
+	        BUG(); 
+            }
+        }
+
+        if (index > 0)
+        {
+            if(wait_for_idma(PREV_CHANNEL(current_dma_channel)))
+            {
+	        BUG();
+            }
+        }
+
+unlock_dma:    
+	idma_busy = 0;    
+        spin_unlock_irqrestore(&current->mm->page_table_lock, flags);
+ exit_dma:
+        
+        DPRINTK("dma_copy(0x%x, 0x%x, %lu): exiting\n", (u32) to,
+                (u32) from, n);
+       
+
+        if(n != 0)
+        {
+       	    if(to_user)
+                return __arch_copy_to_user((void *)to, (void *)from, n);
+	            else
+                return __arch_copy_from_user((void *)to, (void *)from, n);
+        }
+        return 0;
+}
+
+/*=======================================================================*/
+/*  Procedure:  dma_copy_to_user()                                       */
+/*                                                                       */
+/*  Description:    DMA-based copy_to_user.                              */
+/*                                                                       */
+/*  Parameters:  to: destination address                                 */
+/*               from: source address                                    */
+/*               n: number of bytes to transfer                          */
+/*                                                                       */
+/*  Returns:     unsigned long: number of bytes NOT copied               */
+/*                                                                       */
+/*  Notes/Assumptions:                                                   */
+/*              Assumes that kernel physical memory is contiguous, i.e., */
+/*              the physical addresses of contiguous virtual addresses   */
+/*              are also contiguous.                                     */
+/*              Assumes that kernel memory doesn't get paged.            */
+/*              Assumes that to/from memory regions cannot overlap       */
+/*                                                                       */
+/*=======================================================================*/
+unsigned long dma_copy_to_user(void *to, const void *from, unsigned long n)
+{
+	if(!idma_init)
+    		return __arch_copy_to_user((void *)to, (void *)from, n);
+
+     	dma_to_user++;
+     	DPRINTK(KERN_CRIT "dma_copy_to_user(%#10x, 0x%#10x, %lu): entering\n", (u32) to, (u32) from, n);
+    
+        return  dma_copy(to, from, n, 1);
+}
+
+/*=======================================================================*/
+/*  Procedure:  dma_copy_from_user()                                     */
+/*                                                                       */
+/*  Description:    DMA-based copy_from_user.                            */
+/*                                                                       */
+/*  Parameters:  to: destination address                                 */
+/*               from: source address                                    */
+/*               n: number of bytes to transfer                          */
+/*                                                                       */
+/*  Returns:     unsigned long: number of bytes NOT copied               */
+/*                                                                       */
+/*  Notes/Assumptions:                                                   */
+/*              Assumes that kernel virtual memory is contiguous, i.e.,  */
+/*              the physical addresses of contiguous virtual addresses   */
+/*              are also contiguous.                                     */
+/*              Assumes that kernel memory doesn't get paged.            */
+/*              Assumes that to/from memory regions cannot overlap       */
+/*              XXX this one doesn't quite work right yet                */
+/*                                                                       */
+/*=======================================================================*/
+unsigned long dma_copy_from_user(void *to, const void *from, unsigned long n)
+{
+	if(!idma_init)
+		return __arch_copy_from_user((void *)to, (void *)from, n);
+
+	dma_from_user++;
+	DPRINTK(KERN_CRIT "dma_copy_from_user(0x%x, 0x%x, %lu): entering\n", (u32) to, (u32) from, n);
+	return  dma_copy(to, from, n, 0);
+}
+
+#endif /* CONFIG_MV_IDMA_COPYUSER */
+
+#ifdef CONFIG_MV_IDMA_MEMZERO
+/*=======================================================================*/
+/*  Procedure:  dma_memzero()                                             */
+/*                                                                       */
+/*  Description:    DMA-based in-kernel memzero.                          */
+/*                                                                       */
+/*  Parameters:  to: destination address                                 */
+/*               n: number of bytes to transfer                          */
+/*                                                                       */
+/*  Notes/Assumptions:                                                   */
+/*              Assumes that kernel physical memory is contiguous, i.e., */
+/*              the physical addresses of contiguous virtual addresses   */
+/*              are also contiguous.                                     */
+/*              Assumes that kernel memory doesn't get paged.            */
+/*              The DMA is polling                                       */
+/*                                                                       */
+/*=======================================================================*/
+void dma_memzero(void *to, __kernel_size_t n)
+{
+	u32 phys_from, phys_to;	
+	u32 unaligned_to;
+	unsigned long flags;	
+
+	DPRINTK("dma_memcopy: entering\n");
+
+	/* This is used in the very early stages */
+	if(!idma_init)
+    		return asm_memzero(to ,n);
+
+	/* Fallback for the case that one or both buffers are not physically contiguous  */
+	if(!virt_addr_valid(to))
+        {
+		DPRINTK("Failing back to asm_memzero because of limitations\n");
+            return asm_memzero(to ,n);
+        }	
+
+	++dma_memzero_cnt;	
+
+	/*
+	 * If buffer start addr is not cache line-aligned, so we need to make it so.
+	 */
+	unaligned_to = (u32)to & 31;
+	if(unaligned_to)
+	{
+		DPRINTK("Fixing up starting address %d bytes\n", 32 - unaligned_to);
+
+		asm_memzero(to, 32 - unaligned_to);
+
+		to = (void*)((u32)to + (32 - unaligned_to));
+
+                /*it's ok, n supposed to be greater than 32 bytes at this point*/
+		n -= (32 - unaligned_to);
+	}	
+
+	/*
+	 * If buffer end addr is not cache line-aligned, so we need to make it so.
+	 */
+	unaligned_to = ((u32)to + n) & 31;
+	if(unaligned_to)
+	{	
+		u32 tmp_to = (u32)to + (n - unaligned_to);
+		DPRINTK("Fixing ending alignment %d bytes\n", unaligned_to);
+
+		asm_memzero((void *)tmp_to, unaligned_to);
+
+                /*it's ok, n supposed to be greater than 32 bytes at this point*/
+		n -= unaligned_to;
+	}
+
+	phys_from = physical_address((u32)dmaMemInitBuff, 0);
+        phys_to = physical_address((u32)to, 1);
+
+	/*
+	 *  Prepare the IDMA.
+	 */
+	if ((!phys_from) || (!phys_to))
+        {
+	    /* The requested page isn't available, fall back to */
+            DPRINTK(" no physical address, fall back: to %p \n", to);
+            return asm_memzero(to,n);
+        }
+
+        spin_lock_irqsave(&current->mm->page_table_lock, flags);
+	if (idma_busy)
+	{
+	    BUG();
+	}
+	idma_busy = 1;
+
+	/* Ensure that the destination revion is invalidated */
+	mvOsCacheInvalidate(NULL, (void *)to, n);
+	
+	/* Start DMA */
+        DPRINTK(" activate DMA: channel %d from %x with source hold to %x len %x\n",CPY_CHAN1, phys_from, phys_to, n);
+     	mvDmaMemInit(CPY_CHAN1, phys_from, phys_to, n);
+	
+#ifdef RT_DEBUG
+	dma_activations++;
+#endif
+        
+	if(wait_for_idma(CPY_CHAN1))
+        {
+	    BUG(); 
+	}	
+
+	dma_unmap_single(NULL, virt_to_phys(to), n, DMA_FROM_DEVICE);
+
+        DPRINTK("dma_memzero(0x%x, %lu): exiting\n", (u32) to, n);
+
+	idma_busy = 0;
+	spin_unlock_irqrestore(&current->mm->page_table_lock, flags);
+}
+#endif  /* CONFIG_MV_IDMA_MEMZERO */
+
+#ifdef CONFIG_MV_IDMA_MEMCOPY
+//*=======================================================================*/
+/*  Procedure:  dma_memcpy()                                             */
+/*                                                                       */
+/*  Description:    DMA-based in-kernel memcpy.                          */
+/*                                                                       */
+/*  Parameters:  to: destination address                                 */
+/*               from: source address                                    */
+/*               n: number of bytes to transfer                          */
+/*                                                                       */
+/*  Returns:     void*: to                                               */
+/*                                                                       */
+/*  Notes/Assumptions:                                                   */
+/*              Assumes that kernel physical memory is contiguous, i.e., */
+/*              the physical addresses of contiguous virtual addresses   */
+/*              are also contiguous.                                     */
+/*              Assumes that kernel memory doesn't get paged.            */
+/*              The DMA is polling                                       */
+/*		source and destination buffers can overlap(like memmove) */
+/*                                                                       */
+/*=======================================================================*/
+void *dma_memcpy(void *to, const void *from, __kernel_size_t n)
+{
+	u32 phys_from, phys_to;	
+	u32 unaligned_to;
+	unsigned long flags;
+
+	DPRINTK("dma_memcopy: entering\n");
+
+	/* This is used in the very early stages */
+	if(!idma_init)
+    		return asm_memmove(to, from,n);
+
+	/* Fallback for the case that one or both buffers are not physically contiguous  */
+	if(!virt_addr_valid(to) || !virt_addr_valid(from))
+        {
+		DPRINTK("Failing back to asm_memmove because of limitations\n");
+            return asm_memmove(to,from,n);
+        }	
+
+	/* Check for Overlap */
+	if (((to + n > from) && (to < from)) ||((from < to) && (from + n > to))) 
+	{
+		DPRINTK("overlapping copy region (0x%x, 0x%x, %lu), falling back\n",
+		     to, from, (unsigned long)n);
+		return asm_memmove(to, from, n);
+	}
+
+	++dma_memcpy_cnt;
+
+	/*
+	 * Ok, start addr is not cache line-aligned, so we need to make it so.
+	 */
+	unaligned_to = (u32)to & 31;
+	if(unaligned_to)
+	{
+		DPRINTK("Fixing up starting address %d bytes\n", 32 - unaligned_to);
+
+		asm_memmove(to, from, 32 - unaligned_to);
+
+		to = (void*)((u32)to + (32 - unaligned_to));
+		from = (void*)((u32)from + (32 - unaligned_to));
+
+                /*it's ok, n supposed to be greater than 32 bytes at this point*/
+		n -= (32 - unaligned_to);
+	}	
+
+        spin_lock_irqsave(&current->mm->page_table_lock, flags);
+	if (idma_busy)
+	{
+	    BUG();
+	}
+	idma_busy = 1;
+     
+        phys_from = physical_address((u32)from, 0);
+        phys_to = physical_address((u32)to, 1);
+	
+    	/*
+	 *  Prepare the IDMA.
+	 */
+	if ((!phys_from) || (!phys_to))
+        {
+	    /* The requested page isn't available, fall back to */
+            DPRINTK(" no physical address, fall back: from %p , to %p \n", from, to);
+	    idma_busy = 0;
+	    spin_unlock_irqrestore(&current->mm->page_table_lock, flags);
+            return asm_memmove(to, from,n);
+        }
+        else
+        {
+	    /* 
+	     * Ensure that the cache is clean:
+	     *      - from range must be cleaned
+	     *      - to range must be invalidated
+	     */
+		dmac_flush_range(from, from + n);
+		dmac_inv_range(to, to + n);
+
+               
+	    /* Start DMA */
+            DPRINTK(" activate DMA: channel %d from %x to %x len %x\n",CPY_CHAN1, phys_from, phys_to, n);
+	    mvDmaTransfer(CPY_CHAN1, phys_from, phys_to, n, 0);
+#ifdef RT_DEBUG
+                    dma_activations++;
+#endif
+	}
+        
+	if(wait_for_idma(CPY_CHAN1))
+        {
+	    BUG(); 
+	}	
+
+	dma_unmap_single(NULL, virt_to_phys(to), n, DMA_FROM_DEVICE);
+
+        DPRINTK("dma_memcopy(0x%x, 0x%x, %lu): exiting\n", (u32) to, (u32) from, n);
+
+	idma_busy = 0;
+	spin_unlock_irqrestore(&current->mm->page_table_lock, flags);
+       
+        return 0;
+}
+
+#endif  /* CONFIG_MV_IDMA_MEMCOPY */
+
+int mv_dma_init(void)
+{
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+	if (MV_FALSE == mvSocUnitIsMappedToThisCpu(IDMA))
+	{
+		printk(KERN_INFO"IDMA is not mapped to this CPU\n");
+		return -ENODEV;
+	}
+#endif
+	printk(KERN_INFO "Use IDMA channels %d and %d for enhancing the following function:\n",
+                CPY_CHAN1, CPY_CHAN2);
+#ifdef CONFIG_MV_IDMA_COPYUSER
+        printk(KERN_INFO "  o Copy From/To user space operations.\n");
+#endif
+#ifdef CONFIG_MV_IDMA_MEMCOPY
+	printk(KERN_INFO "  o memcpy() and memmove() operations.\n");
+#endif
+#ifdef CONFIG_MV_IDMA_MEMZERO
+	printk(KERN_INFO "  o memzero() operations.\n");
+#endif
+
+#ifdef CONFIG_MV_IDMA_MEMZERO
+	DPRINTK(KERN_ERR "ZERO buffer address 0x%08x\n", (u32)dmaMemInitBuff);
+	
+	asm_memzero(dmaMemInitBuff, sizeof(dmaMemInitBuff));
+	dmac_flush_range(dmaMemInitBuff, dmaMemInitBuff + sizeof(dmaMemInitBuff));
+#endif
+
+        MV_REG_WRITE(IDMA_BYTE_COUNT_REG(CPY_CHAN1), 0);
+        MV_REG_WRITE(IDMA_CURR_DESC_PTR_REG(CPY_CHAN1), 0);
+        MV_REG_WRITE(IDMA_CTRL_HIGH_REG(CPY_CHAN1), ICCHR_ENDIAN_LITTLE 
+#ifdef MV_CPU_LE
+      		| ICCHR_DESC_BYTE_SWAP_EN
+#endif
+		 );
+        MV_REG_WRITE(IDMA_CTRL_LOW_REG(CPY_CHAN1), CPY_IDMA_CTRL_LOW_VALUE);
+
+        MV_REG_WRITE(IDMA_BYTE_COUNT_REG(CPY_CHAN2), 0);
+        MV_REG_WRITE(IDMA_CURR_DESC_PTR_REG(CPY_CHAN2), 0);
+        MV_REG_WRITE(IDMA_CTRL_HIGH_REG(CPY_CHAN2), ICCHR_ENDIAN_LITTLE 
+#ifdef MV_CPU_LE
+      		| ICCHR_DESC_BYTE_SWAP_EN
+#endif
+		 );
+        MV_REG_WRITE(IDMA_CTRL_LOW_REG(CPY_CHAN2), CPY_IDMA_CTRL_LOW_VALUE);
+
+        current_dma_channel = CPY_CHAN1;
+	dma_proc_entry = create_proc_entry("dma_copy", S_IFREG | S_IRUGO, 0);
+	dma_proc_entry->read_proc = dma_read_proc;
+//	dma_proc_entry->write_proc = dma_write_proc;
+	dma_proc_entry->nlink = 1;
+
+	idma_init = 1;
+
+	return 0;
+}
+
+void mv_dma_exit(void)
+{
+}
+
+module_init(mv_dma_init);
+module_exit(mv_dma_exit);
+MODULE_LICENSE(GPL);
+
+#ifdef CONFIG_MV_IDMA_MEMCOPY
+EXPORT_SYMBOL(dma_memcpy);
+#endif
+
+#ifdef CONFIG_MV_IDMA_MEMZERO
+EXPORT_SYMBOL(dma_memzero);
+#endif
+
+#ifdef CONFIG_MV_IDMA_COPYUSER
+EXPORT_SYMBOL(dma_copy_to_user);
+EXPORT_SYMBOL(dma_copy_from_user);			
+#endif
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_gpio/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_gpio/Makefile
new file mode 100644
index 0000000..773cf5b
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_gpio/Makefile
@@ -0,0 +1,12 @@
+#
+# Makefile for the Marvell GPIO Driver
+#
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+obj-y += mv_gpio.o
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_gpio/mv_gpio.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_gpio/mv_gpio.c
new file mode 100644
index 0000000..1d92103
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_gpio/mv_gpio.c
@@ -0,0 +1,160 @@
+/*
+ * arch/arm/plat-feroceon/mv_drivers_lsp/mv_gpio/mv_gpio.c
+ *
+ * Marvell Feroceon SoC GPIO handling.
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/irq.h>
+#include <linux/module.h>
+#include <linux/spinlock.h>
+#include <linux/bitops.h>
+#include <linux/io.h>
+#include <linux/gpio.h>
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "gpp/mvGpp.h"
+#include "gpp/mvGppRegs.h"
+
+static DEFINE_SPINLOCK(gpio_lock);
+
+static inline void __set_direction(unsigned pin, int input)
+{
+	u32 grp = pin >> 5;
+	u32 mask = (1 << (pin & 0x1F));
+
+	if (input)
+		mvGppTypeSet(grp, mask, MV_GPP_IN & mask);
+	else
+		mvGppTypeSet(grp, mask, MV_GPP_OUT & mask);
+}
+
+static void __set_level(unsigned pin, int high)
+{
+	u32 grp = pin >> 5;
+	u32 mask = (1 << (pin & 0x1F));
+
+	if (high)
+		mvGppValueSet (grp, mask, mask);
+	else
+		mvGppValueSet (grp, mask, 0);
+}
+
+static inline void __set_blinking(unsigned pin, int blink)
+{
+	u32 grp = pin >> 5;
+	u32 mask = (1 << (pin & 0x1F));
+
+	if (blink)
+		mvGppBlinkEn(grp, mask, mask);
+	else
+		mvGppBlinkEn(grp, mask, 0);
+}
+
+static inline int mv_gpio_is_valid(unsigned pin, int mode)
+{
+	return true;
+}
+
+/*
+ * GENERIC_GPIO primitives.
+ */
+static int mv_gpio_direction_input(struct gpio_chip *chip, unsigned pin)
+{
+	unsigned long flags;
+
+	if (!mv_gpio_is_valid(pin, GPIO_INPUT_OK))
+		return -EINVAL;
+
+	spin_lock_irqsave(&gpio_lock, flags);
+
+	/* Configure GPIO direction. */
+	__set_direction(pin, 1);
+
+	spin_unlock_irqrestore(&gpio_lock, flags);
+
+	return 0;
+}
+
+static int mv_gpio_get_value(struct gpio_chip *chip, unsigned pin)
+{
+	u32 val;
+	u32 grp = pin >> 5;
+	u32 mask = (1 << (pin & 0x1F));
+
+	if (MV_REG_READ(GPP_DATA_OUT_EN_REG(grp)) & mask)
+		val = mvGppValueGet(grp, mask) ^ mvGppPolarityGet(grp, mask);
+	else
+		val = MV_REG_READ(GPP_DATA_OUT_REG(grp));
+
+	return (val >> (pin & 31)) & 1;
+}
+
+static int mv_gpio_direction_output(struct gpio_chip *chip, unsigned pin,
+	int value)
+{
+	unsigned long flags;
+
+	if (!mv_gpio_is_valid(pin, GPIO_OUTPUT_OK))
+		return -EINVAL;
+
+	spin_lock_irqsave(&gpio_lock, flags);
+
+	/* Disable blinking. */
+	__set_blinking(pin, 0);
+
+	/* Configure GPIO output value. */
+	__set_level(pin, value);
+
+	/* Configure GPIO direction. */
+	__set_direction(pin, 0);
+
+	spin_unlock_irqrestore(&gpio_lock, flags);
+
+	return 0;
+}
+
+static void mv_gpio_set_value(struct gpio_chip *chip, unsigned pin,
+	int value)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&gpio_lock, flags);
+
+	/* Configure GPIO output value. */
+	__set_level(pin, value);
+
+	spin_unlock_irqrestore(&gpio_lock, flags);
+}
+
+static int mv_gpio_request(struct gpio_chip *chip, unsigned pin)
+{
+	if (mv_gpio_is_valid(pin, GPIO_INPUT_OK) ||
+	    mv_gpio_is_valid(pin, GPIO_OUTPUT_OK))
+		return 0;
+	return -EINVAL;
+}
+
+static struct gpio_chip mv_gpiochip = {
+	.label			= "mv_gpio",
+	.direction_input	= mv_gpio_direction_input,
+	.get			= mv_gpio_get_value,
+	.direction_output	= mv_gpio_direction_output,
+	.set			= mv_gpio_set_value,
+	.request		= mv_gpio_request,
+	.base			= 0,
+	.ngpio			= MV_GPP_MAX_PINS,
+	.can_sleep		= 0,
+};
+
+void __init mv_gpio_init(void)
+{
+	gpiochip_add(&mv_gpiochip);
+}
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/Makefile
new file mode 100644
index 0000000..e295c01
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/Makefile
@@ -0,0 +1,13 @@
+
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+ 
+obj-$(CONFIG_MV_INCLUDE_SFLASH_MTD) 	+= sflash.o
+obj-$(CONFIG_MV_INCLUDE_MFLASH_MTD) 	+= mflash.o
+obj-$(CONFIG_MTD_NAND_LNC)		+= nand_lnc.o
+obj-$(CONFIG_MTD_NAND_NFC)		+= nand_nfc.o
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/mflash.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/mflash.c
new file mode 100644
index 0000000..bd08825
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/mflash.c
@@ -0,0 +1,361 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+********************************************************************************/
+
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/sched.h>
+#include <linux/errno.h>
+#include <linux/interrupt.h>
+#include <linux/mtd/map.h>
+#include <linux/mtd/mtd.h>
+#include <mflash/mvMFlash.h>
+#include "mflash/mvMFlashSpec.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+
+/*#define MTD_MFLASH_DEBUG*/
+
+#ifdef MTD_MFLASH_DEBUG
+#define DB(x)	x
+#else
+#define DB(x)
+#endif
+
+
+/* Configuration options */
+static struct mtd_info *mflash_probe(struct map_info *map);
+static void mflash_destroy(struct mtd_info *mtd);
+static int mflash_read(struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, u_char *buf);
+static int mflash_write(struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, const u_char *buf);
+static int mflash_erase(struct mtd_info *mtd, struct erase_info *instr);
+static void mflash_sync(struct mtd_info *mtd);
+static int mflash_suspend(struct mtd_info *mtd);
+static void mflash_resume(struct mtd_info *mtd);
+static int mflash_lock (struct mtd_info *mtd, loff_t ofs, size_t len);
+static int mflash_unlock (struct mtd_info *mtd, loff_t ofs, size_t len);
+static int mflash_block_isbad (struct mtd_info *mtd, loff_t ofs);
+static int mflash_block_markbad (struct mtd_info *mtd, loff_t ofs);
+
+static struct mtd_chip_driver mflash_chipdrv = {
+	.probe		= mflash_probe,
+	.destroy	= mflash_destroy,
+	.name		= "mflash",
+	.module		= THIS_MODULE
+};
+
+
+static struct mtd_info *mflash_probe(struct map_info *map)
+{
+	struct mtd_info *mtd = NULL;
+	MV_MFLASH_INFO *mflash = NULL;
+	
+	DB(printk("\nINFO: enterring %s",__FUNCTION__));
+
+	/* allocate the memory for the mtd_info */
+	mtd = kmalloc(sizeof(*mtd), GFP_KERNEL);
+	if(!mtd)
+	{
+		printk(KERN_NOTICE "\nERROR: %s - Failed to allocate memory for mtd structure",__FUNCTION__);
+		return NULL;
+	}
+
+	/* allocate memory for the mflash private structure */
+	mflash = kmalloc(sizeof(MV_MFLASH_INFO), GFP_KERNEL);
+	if(!mflash) 
+	{
+		printk(KERN_NOTICE "\nERROR: %s - Failed to allocate memory for mflash structure",__FUNCTION__);
+		kfree(mtd);
+		return NULL;
+	}
+		
+	/* clear both structures before usage */
+	memset(mtd, 0, sizeof(*mtd));
+	memset(mflash, 0, sizeof(*mflash));
+	    
+	DB(printk("\nINFO: %s - Base address %08x",__FUNCTION__, mflash->baseAddr));
+	
+    /* based on the SPI mode try to detect the Mflash device interface type */
+    if (mvCtrlSpiBusModeDetect() == MV_SPI_CONN_TO_MFLASH)
+        mflash->ifMode = MV_MFLASH_SPI; 
+    else               
+        mflash->ifMode = MV_MFLASH_PARALLEL;
+	
+	/* Try to detect the Marvell flash and initialize */	
+	mflash->baseAddr = map->phys;
+	if (mvMFlashInit(mflash) != MV_OK)
+	{
+		printk(KERN_NOTICE "ERROR: %s - Failed to initialize the mflash.", __FUNCTION__);
+		kfree(mtd);
+		kfree(mflash);
+		return NULL;
+	}
+	
+	if (mvMFlashSectorSizeSet(mflash, 0x1000 /*4K*/) != MV_OK)
+	{
+		printk(KERN_NOTICE "ERROR: %s - Failed to sector sector size to small.", __FUNCTION__);
+		kfree(mtd);
+		kfree(mflash);
+		return NULL;
+	}
+	
+	/* After success fill in the MTD structure with the appropriate info */
+	mtd->erasesize = mflash->sectorSize;
+	mtd->size = mflash->sectorSize * mflash->sectorNumber;
+	mtd->priv = map;
+	mtd->type = MTD_NORFLASH;
+	mtd->erase = mflash_erase;
+	mtd->read = mflash_read;
+	mtd->write = mflash_write;
+	mtd->sync = mflash_sync;
+	mtd->suspend = mflash_suspend;
+	mtd->resume = mflash_resume;	
+	mtd->lock = mflash_lock;
+	mtd->unlock = mflash_unlock;
+	mtd->block_isbad = mflash_block_isbad;
+	mtd->block_markbad = mflash_block_markbad;	
+	mtd->flags = (MTD_WRITEABLE | MTD_BIT_WRITEABLE); /* just like MTD_CAP_NORFLASH */
+	mtd->name = map->name;
+	mtd->writesize = 1;
+	
+	map->fldrv = &mflash_chipdrv;
+	map->fldrv_priv = mflash;
+	
+	/* Print some debug messages with the detected mflash info */
+	DB(printk("\nINFO: %s - Detected mflash device (size %d)", __FUNCTION__, mtd->size));
+	DB(printk("\n           Base Address    : 0x%08x", mflash->baseAddr));
+	DB(printk("\n           Interface Mode  : %d", mflash->ifMode));
+	DB(printk("\n           Sector Size     : 0x%x", mflash->sectorSize));
+	DB(printk("\n           Sector Number   : %d", mflash->sectorNumber));
+	DB(printk("\n           Info Region Size: 0x%x", mflash->infoSize));
+	
+	printk("Marvell Flash Detected @ 0x%08x, %dKB Main region (%dsec x %dKB), %dKB Information region\n",
+	         mflash->baseAddr, ((mflash->sectorNumber * mflash->sectorSize)/1024),
+	         mflash->sectorNumber, (mflash->sectorSize/1024), (mflash->infoSize/1024));
+	
+	__module_get(THIS_MODULE);
+	return mtd;
+}
+
+static void mflash_destroy(struct mtd_info *mtd)
+{
+	struct map_info *map = mtd->priv;
+	MV_MFLASH_INFO *mflash = map->fldrv_priv;
+
+	DB(printk("\nINFO: %s called", __FUNCTION__));
+
+	/* free memory allocated at probe for the private mflash structure */
+	if (mflash)
+		kfree(mflash);	
+}
+
+static int mflash_read(struct mtd_info *mtd, loff_t from, size_t len,
+	size_t *retlen, u_char *buf)
+{
+	struct map_info *map = mtd->priv;
+	MV_MFLASH_INFO *mflash = map->fldrv_priv;
+	MV_U32 offset = ((MV_U32)from);
+	
+	*retlen = 0;
+
+	DB(printk("\nINFO: %s  - offset %08x, len %d",__FUNCTION__, offset, (int)len));
+		
+	if (mvMFlashBlockRd(mflash, offset, len, buf) != MV_OK)
+	{
+		printk(KERN_NOTICE "\nERROR: %s - Failed to read block.", __FUNCTION__);
+		return -1;
+	}
+	
+	*retlen = len;
+	
+	DB(printk(" - OK"));
+
+	return 0;	
+}
+
+static int mflash_write(struct mtd_info *mtd, loff_t to, size_t len,
+	size_t *retlen, const u_char *buf)
+{
+	struct map_info *map = mtd->priv;
+	MV_MFLASH_INFO *mflash = map->fldrv_priv;
+	MV_U32 offset = ((MV_U32)to);
+	
+	*retlen = 0;
+	
+	DB(printk("\nINFO: %s - offset %08x, len %d",__FUNCTION__, offset, len));
+		
+	if (mvMFlashBlockWr(mflash, offset, len, (MV_U8*)buf, MV_FALSE) != MV_OK)
+	{
+		printk(KERN_NOTICE "\nERROR: %s - Failed to write block", __FUNCTION__);
+		return -1;
+	}
+	
+	*retlen = len;
+	
+	DB(printk(" - OK"));
+
+	return 0;	
+
+}
+
+
+static int mflash_erase(struct mtd_info *mtd, struct erase_info *instr)
+{
+	struct map_info *map = mtd->priv;
+	MV_MFLASH_INFO *mflash = map->fldrv_priv;
+	MV_U32 fsec, lsec;
+	int i;
+
+	DB(printk("\nINFO: %s - Addr %08x, len %d",__FUNCTION__, instr->addr, instr->len));
+	
+	if(instr->addr & (mtd->erasesize - 1))
+	{
+		printk(KERN_NOTICE "\nError: %s - Erase address not sector alligned",__FUNCTION__);
+		return -EINVAL;
+	}
+	if(instr->len & (mtd->erasesize - 1))
+	{
+		printk(KERN_NOTICE "\nError: %s - Erase length is not sector alligned",__FUNCTION__);
+		return -EINVAL;
+	}
+	if(instr->len + instr->addr > mtd->size)
+	{
+		printk(KERN_NOTICE "\nError: %s - Erase exceeded flash size",__FUNCTION__);
+		return -EINVAL;
+	}
+
+	fsec = (instr->addr / mtd->erasesize);
+	lsec = (fsec +(instr->len / mtd->erasesize));
+	
+	DB(printk("\nINFO: %s - from sector %u to %u",__FUNCTION__, fsec, lsec));
+	
+	for (i=fsec; i<lsec; i++)
+	{
+		if (mvMFlashSecErase(mflash, i) != MV_OK)
+		{
+			printk(KERN_NOTICE "\nError: %s - mvMFlashSecErase on sector %d",__FUNCTION__, i);
+			return -1;
+		}
+	}
+	
+	instr->state = MTD_ERASE_DONE;
+	mtd_erase_callback(instr);
+
+	return 0;
+}
+
+static int mflash_lock (struct mtd_info *mtd, loff_t ofs, size_t len)
+{
+	struct map_info *map = mtd->priv;
+	MV_MFLASH_INFO *mflash = map->fldrv_priv;
+	
+	DB(printk("\nINFO: %s called", __FUNCTION__));
+	
+	if (mvMFlashWriteProtectSet(mflash, MV_TRUE) != MV_OK)
+	{
+		printk(KERN_NOTICE "\nError: %s - mvmflashWpRegionSet failed",__FUNCTION__);
+		return -1;
+	}
+	
+	printk("\nNotice: Marvell flash (%s) lock per sector is not supported!\n        Locking the whole device.", mtd->name);
+		
+	return 0;
+}
+
+static int mflash_unlock (struct mtd_info *mtd, loff_t ofs, size_t len)
+{
+	struct map_info *map = mtd->priv;
+	MV_MFLASH_INFO *mflash = map->fldrv_priv;
+
+	DB(printk("\nINFO: %s called", __FUNCTION__));
+	
+	if (mvMFlashWriteProtectSet(mflash, MV_FALSE) != MV_OK)
+	{
+		printk(KERN_NOTICE "\nError: %s - mvmflashWpRegionSet failed",__FUNCTION__);
+		return -1;
+	}
+		
+	printk("\nNotice: Marvell flash (%s) unlock per sector is not supported!\n        Unlocking the whole device.", mtd->name);
+	return 0;
+}
+
+static void mflash_sync(struct mtd_info *mtd)
+{
+	DB(printk("\nINFO: %s called - DUMMY", __FUNCTION__));
+}
+
+static int mflash_suspend(struct mtd_info *mtd)
+{
+	DB(printk("\nINFO: %s called - DUMMY()", __FUNCTION__));
+	return 0;
+}
+
+static void mflash_resume(struct mtd_info *mtd)
+{
+	DB(printk("\nINFO: %s called - DUMMY", __FUNCTION__));
+}
+
+static int mflash_block_isbad (struct mtd_info *mtd, loff_t ofs)
+{
+	DB(printk("\nINFO: %s called - DUMMY", __FUNCTION__));
+	return 0;
+}
+
+static int mflash_block_markbad (struct mtd_info *mtd, loff_t ofs)
+{
+	DB(printk("\nINFO: %s called - DUMMY", __FUNCTION__));
+	return 0;
+}
+
+static int __init mflash_probe_init(void)
+{
+	DB(printk("\nINFO: %s - MTD mflash chip driver.", __FUNCTION__));
+
+	register_mtd_chip_driver(&mflash_chipdrv);
+
+	return 0;
+}
+
+static void __exit mflash_probe_exit(void)
+{
+	DB(printk(KERN_ALERT "\nINFO: %s - MTD mflash driver exit", __FUNCTION__));
+	unregister_mtd_chip_driver(&mflash_chipdrv);
+}
+
+module_init(mflash_probe_init);
+module_exit(mflash_probe_exit);
+
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_DESCRIPTION("MTD chip driver for the Marvell SUNOL flash device");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_lnc.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_lnc.c
new file mode 100644
index 0000000..b52c38d
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_lnc.c
@@ -0,0 +1,702 @@
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/mtd/partitions.h>
+#include <linux/mtd/nand.h>
+#include <asm/io.h>
+#include "ctrlEnv/sys/mvCpuIf.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "nand_lnc.h"
+
+#undef DEBUG
+#ifdef DEBUG
+#define DBG(fmt, arg...)	mvOsPrintf(KERN_INFO fmt, ##arg) 
+#else 
+#define DBG(fmt, arg...)
+#endif
+
+extern MV_U32    boardGetDevCSNum(MV_32 devNum, MV_BOARD_DEV_CLASS devType);
+
+static struct mtd_info *mv_mtd;
+static unsigned long baseaddr;
+
+unsigned int mv_nand_ecc;
+
+#ifdef CONFIG_MTD_PARTITIONS
+#define MV_NUM_OF_NAND_PARTS 3
+static struct mtd_partition parts_info[] = {
+	{ .name = "u-boot",
+	  .offset = 0,
+	  .size = 2 * 1024 * 1024 },
+	{ .name = "uImage",
+	  .offset = MTDPART_OFS_NXTBLK,
+	  .size = 2 * 1024 * 1024 },
+	{ .name = "root",
+	  .offset = MTDPART_OFS_NXTBLK,
+	  .size = MTDPART_SIZ_FULL },
+};
+static const char *part_probes[] __initdata = { "cmdlinepart", NULL };
+#endif
+
+static void board_hwcontrol(struct mtd_info *mtd, int cmd, unsigned int ctrl)
+{
+	struct nand_chip *this = (struct nand_chip *)mtd->priv;
+	if (ctrl & NAND_CTRL_CHANGE) {        
+		this->IO_ADDR_W = (void __iomem *)((unsigned long)this->IO_ADDR_W & ~3);
+		ctrl &= ~NAND_CTRL_CHANGE;
+		switch(ctrl) {
+			case NAND_CTRL_CLE: 
+				this->IO_ADDR_W = (void __iomem *)((unsigned long)this->IO_ADDR_W | 1); //x8=>1, x16=>2
+				break;
+			case NAND_CTRL_ALE:
+				this->IO_ADDR_W = (void __iomem *)((unsigned long)this->IO_ADDR_W | 2); //x8=>2, x16=>4
+				break;
+		}				
+	}
+	if (cmd != NAND_CMD_NONE) 
+	{
+		writeb(cmd, this->IO_ADDR_W);		
+	}	
+}
+
+static void mv_nand_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
+{
+	struct nand_chip *chip = mtd->priv;
+	void __iomem *io_base = chip->IO_ADDR_R;
+	uint64_t *buf64;
+	int i = 0;
+
+	while (len && (unsigned long)buf & 7)
+	{
+		*buf++ = readb(io_base);
+		len--;
+	}
+
+	buf64 = (uint64_t *)buf;
+	while (i < len/8)
+	{
+		uint64_t x;
+		__asm__ __volatile__ ("ldrd\t%0, [%1]" : "=r" (x) : "r" (io_base));
+		buf64[i++] = x;
+	}
+
+	i *= 8;
+	while (i < len)
+	{
+		buf[i++] = readb(io_base);
+	}
+}
+
+
+int __init mv_nand_init(void)
+{
+	struct nand_chip *this;
+	int err = 0;
+	int num_of_parts = 0;
+	const char *part_type = 0;
+	struct mtd_partition *mtd_parts = 0;
+	u32 physaddr;
+	int nand_dev_num;
+	MV_CPU_DEC_WIN addr_win;
+
+	nand_dev_num = boardGetDevCSNum(0, BOARD_DEV_NAND_FLASH);
+	if(-1 == nand_dev_num) {
+		printk("NAND init: NAND device not found on board\n");
+		err = -ENODEV;
+		goto out;
+	}
+
+	if( MV_OK != mvCpuIfTargetWinGet((nand_dev_num), &addr_win) ) {
+                printk("Failed to init NAND MTD (boot-CS window %d err).\n", nand_dev_num);
+		err = -ENODEV;
+		goto out;
+	}
+
+	if(!addr_win.enable) {
+                printk("Failed to init NAND MTD (boot-CS window disabled).\n" );
+		err = -ENODEV;
+		goto out;
+	}
+	physaddr = addr_win.addrWin.baseLow;
+
+	mv_mtd = (struct mtd_info *)kmalloc(sizeof(struct mtd_info)+sizeof(struct nand_chip), GFP_KERNEL);
+	if(!mv_mtd){
+		printk("Failed to allocate NAND MTD structure\n");
+		err = -ENOMEM;
+		goto out;
+	}
+
+	memset((char*)mv_mtd,0,sizeof(struct mtd_info)+sizeof(struct nand_chip));
+
+	baseaddr = (unsigned long)ioremap(physaddr, 1024);
+	if(!baseaddr) {
+		printk("Failed to remap NAND MTD\n");
+		err = -EIO;
+		goto out_mtd;
+	}
+
+	this = (struct nand_chip *)((char *)mv_mtd+sizeof(struct mtd_info));
+	mv_mtd->priv = this;
+	this->IO_ADDR_R = this->IO_ADDR_W = (void __iomem *)baseaddr;
+	this->cmd_ctrl = board_hwcontrol;
+#ifdef	CONFIG_MTD_NAND_LNC_8BYTE_READ
+	this->read_buf = mv_nand_read_buf;
+#endif
+#ifdef	CONFIG_MTD_NAND_LNC_RS_ECC
+	printk("Using %s ECC for NAND device\n",(mv_nand_ecc == MV_NAND_ECC_4BIT ? 
+		"Reed-Solomon 4-bit" : "Hamming 1-bit"));
+	if(mv_nand_ecc == MV_NAND_ECC_4BIT) {
+		this->ecc.hwctl		= mv_nand_enable_hwecc; 
+		this->ecc.calculate	= mv_nand_calculate_ecc_rs;
+		this->ecc.correct	= mv_nand_correct_data_rs;
+		this->ecc.size		= 512;
+		this->ecc.bytes		= 10;
+		this->ecc.layout	= &mv_nand_rs_oobinfo;
+		this->ecc.mode		= NAND_ECC_HW;
+	}
+	else
+#endif
+		this->ecc.mode = NAND_ECC_SOFT;
+
+	this->chip_delay = 30;
+	if(nand_scan(mv_mtd,1)) {
+		err = -ENXIO;
+		goto out_ior;
+	}
+
+#ifdef CONFIG_MTD_PARTITIONS
+        mv_mtd->name = "nand_mtd";
+        num_of_parts = parse_mtd_partitions(mv_mtd, part_probes, &mtd_parts, 0);
+        if(num_of_parts > 0)
+                part_type = "command line";
+        else
+                num_of_parts = 0;
+        if(num_of_parts == 0) {
+                mtd_parts = parts_info;
+                num_of_parts = MV_NUM_OF_NAND_PARTS;
+                part_type = "static";
+        }
+
+	printk("Using %s partition definition\n", part_type);
+	add_mtd_partitions(mv_mtd, mtd_parts, num_of_parts);
+#endif
+	goto out;
+
+out_ior:
+	iounmap((void *)baseaddr);
+out_mtd:
+	kfree(mv_mtd);
+out:
+	return err;
+}
+
+module_init(mv_nand_init);
+
+#ifdef MODULE
+static void __exit board_cleanup(void)
+{
+	nand_release(mv_mtd);
+	iounmap((void*)baseaddr);
+	kfree(mv_mtd);
+}
+module_exit(board_cleanup);
+#endif
+
+#ifdef CONFIG_MTD_NAND_LNC_RS_ECC
+
+#define mm 10	  /* RS code over GF(2**mm) - the size in bits of a symbol*/
+#define	nn 1023   /* nn=2^mm -1   length of codeword */
+#define tt 4      /* number of errors that can be corrected */
+#define kk 1015   /* kk = number of information symbols  kk = nn-2*tt  */
+
+
+static char rs_initialized = 0;
+
+//typedef unsigned int gf;
+typedef u_short tgf;  /* data type of Galois Functions */
+
+/* Primitive polynomials -  irriducibile polynomial  [ 1+x^3+x^10 ]*/
+short pp[mm+1] = { 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1 };
+
+
+/* index->polynomial form conversion table */
+tgf alpha_to[nn + 1];
+
+/* Polynomial->index form conversion table */
+tgf index_of[nn + 1];
+
+/* Generator polynomial g(x) = 2*tt with roots @, @^2, .. ,@^(2*tt) */
+tgf Gg[nn - kk + 1];
+
+
+#define	minimum(a,b)	((a) < (b) ? (a) : (b))
+
+#define	BLANK(a,n) {\
+	short ci;\
+	for(ci=0; ci<(n); ci++)\
+		(a)[ci] = 0;\
+	}
+
+#define	COPY(a,b,n) {\
+	short ci;\
+	for(ci=(n)-1;ci >=0;ci--)\
+		(a)[ci] = (b)[ci];\
+	}
+#define	COPYDOWN(a,b,n) {\
+	short ci;\
+	for(ci=(n)-1;ci >=0;ci--)\
+		(a)[ci] = (b)[ci];\
+	}
+
+
+/* generate GF(2^m) from the irreducible polynomial p(X) in p[0]..p[mm]
+   lookup tables:  index->polynomial form   alpha_to[] contains j=alpha^i;
+                   polynomial form -> index form  index_of[j=alpha^i] = i
+   alpha=2 is the primitive element of GF(2^m) 
+*/
+
+void generate_gf(void)
+{
+	register int i, mask;
+
+	mask = 1;
+	alpha_to[mm] = 0;
+	for (i = 0; i < mm; i++) {
+		alpha_to[i] = mask;
+		index_of[alpha_to[i]] = i;
+		if (pp[i] != 0)
+			alpha_to[mm] ^= mask;	
+		mask <<= 1;	
+	}
+	index_of[alpha_to[mm]] = mm;
+	
+	mask >>= 1;
+	for (i = mm + 1; i < nn; i++) {
+		if (alpha_to[i - 1] >= mask)
+			alpha_to[i] = alpha_to[mm] ^ ((alpha_to[i - 1] ^ mask) << 1);
+		else
+			alpha_to[i] = alpha_to[i - 1] << 1;
+		index_of[alpha_to[i]] = i;
+	}
+	index_of[0] = nn;  
+	alpha_to[nn] = 0;
+}
+
+
+/*
+ * Obtain the generator polynomial of the tt-error correcting, 
+ * length nn = (2^mm -1) 
+ * Reed Solomon code from the product of (X + @^i), i=1..2*tt
+*/
+void gen_poly(void)
+{
+	register int i, j;
+
+	Gg[0] = alpha_to[1]; /* primitive element*/ 
+	Gg[1] = 1;		     /* g(x) = (X+@^1) initially */
+	for (i = 2; i <= nn - kk; i++) {
+		Gg[i] = 1;
+		/*
+		 * Below multiply (Gg[0]+Gg[1]*x + ... +Gg[i]x^i) by
+		 * (@^i + x)
+		 */
+		for (j = i - 1; j > 0; j--)
+			if (Gg[j] != 0)
+				Gg[j] = Gg[j - 1] ^ alpha_to[((index_of[Gg[j]]) + i)%nn];
+			else
+				Gg[j] = Gg[j - 1];
+		Gg[0] = alpha_to[((index_of[Gg[0]]) + i) % nn];
+	}
+	/* convert Gg[] to index form for quicker encoding */
+	for (i = 0; i <= nn - kk; i++)
+		Gg[i] = index_of[Gg[i]];
+}
+
+
+/*
+ * take the string of symbols in data[i], i=0..(k-1) and encode
+ * systematically to produce nn-kk parity symbols in bb[0]..bb[nn-kk-1] data[]
+ * is input and bb[] is output in polynomial form. Encoding is done by using
+ * a feedback shift register with appropriate connections specified by the
+ * elements of Gg[], which was generated above. Codeword is   c(X) =
+ * data(X)*X**(nn-kk)+ b(X)
+ */
+static inline char encode_rs(dtype data[kk], dtype bb[nn-kk])
+{
+	register int i, j;
+	tgf feedback;
+
+	BLANK(bb,nn-kk);
+	for (i = kk - 1; i >= 0; i--) {
+		if(data[i] > nn)
+			return -1;	/* Illegal symbol */
+		feedback = index_of[data[i] ^ bb[nn - kk - 1]];
+		if (feedback != nn) {	/* feedback term is non-zero */
+			for (j = nn - kk - 1; j > 0; j--)
+				if (Gg[j] != nn)					
+					bb[j] = bb[j - 1] ^ alpha_to[(Gg[j] + feedback)%nn];
+				else
+					bb[j] = bb[j - 1];			
+			bb[0] = alpha_to[(Gg[0] + feedback)%nn];
+		} else {	
+			for (j = nn - kk - 1; j > 0; j--)
+				bb[j] = bb[j - 1];
+			bb[0] = 0;
+		}
+	}
+	return 0;
+}
+
+
+
+
+/* assume we have received bits grouped into mm-bit symbols in data[i],
+   i=0..(nn-1), We first compute the 2*tt syndromes, then we use the 
+   Berlekamp iteration to find the error location polynomial  elp[i].   
+   If the degree of the elp is >tt, we cannot correct all the errors
+   and hence just put out the information symbols uncorrected. If the 
+   degree of elp is <=tt, we  get the roots, hence the inverse roots, 
+   the error location numbers. If the number of errors located does not 
+   equal the degree of the elp, we have more than tt errors and cannot 
+   correct them.  Otherwise, we then solve for the error value at the 
+   error location and correct the error.The procedure is that found in
+   Lin and Costello.*/
+
+static inline int decode_rs(dtype data[nn])
+{
+	int deg_lambda, el, deg_omega;
+	int i, j, r;
+	tgf q,tmp,num1,num2,den,discr_r;
+	tgf recd[nn];
+	tgf lambda[nn-kk + 1], s[nn-kk + 1];	/* Err+Eras Locator poly
+						                 * and syndrome poly  */
+	tgf b[nn-kk + 1], t[nn-kk + 1], omega[nn-kk + 1];
+	tgf root[nn-kk], reg[nn-kk + 1], loc[nn-kk];
+	int syn_error, count;
+
+	
+
+	/* data[] is in polynomial form, copy and convert to index form */
+	for (i = nn-1; i >= 0; i--){
+
+	  if(data[i] > nn)
+		return -1;	/* Illegal symbol */
+
+	  recd[i] = index_of[data[i]];
+	}
+
+	/* first form the syndromes; i.e., evaluate recd(x) at roots of g(x)
+	 * namely @**(1+i), i = 0, ... ,(nn-kk-1)
+	 */
+
+	syn_error = 0;
+
+	for (i = 1; i <= nn-kk; i++) {
+		tmp = 0;
+		
+		for (j = 0; j < nn; j++)
+			if (recd[j] != nn)	/* recd[j] in index form */
+								tmp ^= alpha_to[(recd[j] + (1+i-1)*j)%nn];
+		
+			syn_error |= tmp;	/* set flag if non-zero syndrome =>
+					 * error */
+	/* store syndrome in index form  */
+		s[i] = index_of[tmp];
+	}
+
+	if (!syn_error) {
+		/*
+		 * if syndrome is zero, data[] is a codeword and there are no
+		 * errors to correct. So return data[] unmodified
+		 */
+		return 0;
+	}
+
+	BLANK(&lambda[1],nn-kk);
+	
+	lambda[0] = 1;
+	
+	for(i=0;i<nn-kk+1;i++)
+		b[i] = index_of[lambda[i]];
+
+	/*
+	 * Begin Berlekamp-Massey algorithm to determine error
+	 * locator polynomial
+	 */
+	r = 0; 
+	el = 0; 
+	while (++r <= nn-kk) {	/* r is the step number */
+		/* Compute discrepancy at the r-th step in poly-form */
+		discr_r = 0;
+		
+		for (i = 0; i < r; i++){
+			if ((lambda[i] != 0) && (s[r - i] != nn)) {				
+				discr_r ^= alpha_to[(index_of[lambda[i]] + s[r - i])%nn];
+			}
+		}
+		
+
+		discr_r = index_of[discr_r];	/* Index form */
+		if (discr_r == nn) {
+			/* 2 lines below: B(x) <-- x*B(x) */
+			COPYDOWN(&b[1],b,nn-kk);
+			b[0] = nn;
+		} else {
+			/* 7 lines below: T(x) <-- lambda(x) - discr_r*x*b(x) */
+			t[0] = lambda[0];
+			for (i = 0 ; i < nn-kk; i++) {
+				if(b[i] != nn)
+					//t[i+1] = lambda[i+1] ^ alpha_to[modnn(discr_r + b[i])];
+					t[i+1] = lambda[i+1] ^ alpha_to[(discr_r + b[i])%nn];
+				else
+					t[i+1] = lambda[i+1];
+			}
+			if (2 * el <= r - 1) {
+				el = r - el;
+				/*
+				 * 2 lines below: B(x) <-- inv(discr_r) *
+				 * lambda(x)
+				 */
+				for (i = 0; i <= nn-kk; i++)
+					//b[i] = (lambda[i] == 0) ? nn : modnn(index_of[lambda[i]] - discr_r + nn);
+					b[i] = (lambda[i] == 0) ? nn : ((index_of[lambda[i]] - discr_r + nn)%nn);
+			} else {
+				/* 2 lines below: B(x) <-- x*B(x) */
+				COPYDOWN(&b[1],b,nn-kk);
+				b[0] = nn;
+			}
+			COPY(lambda,t,nn-kk+1);
+		}
+	}
+
+	/* Convert lambda to index form and compute deg(lambda(x)) */
+	deg_lambda = 0;
+	for(i=0;i<nn-kk+1;i++){
+		lambda[i] = index_of[lambda[i]];
+		if(lambda[i] != nn)
+			deg_lambda = i;
+	}
+	/*
+	 * Find roots of the error locator polynomial. By Chien
+	 * Search
+	 */
+	COPY(&reg[1],&lambda[1],nn-kk);
+	count = 0;		/* Number of roots of lambda(x) */
+	for (i = 1; i <= nn; i++) {
+		q = 1;
+		for (j = deg_lambda; j > 0; j--)
+			if (reg[j] != nn) {
+				//reg[j] = modnn(reg[j] + j);
+				reg[j] = (reg[j] + j)%nn;
+				q ^= alpha_to[reg[j]];
+			}
+		if (!q) {
+			/* store root (index-form) and error location number */
+			root[count] = i;
+			loc[count] = nn - i;
+			count++;
+		}
+	}
+
+#ifdef DEBUG
+/*
+	printk("\n Final error positions:\t");
+	for (i = 0; i < count; i++)
+		printk("%d ", loc[i]);
+	printk("\n");
+*/
+#endif
+	
+	
+	
+	if (deg_lambda != count) {
+		/*
+		 * deg(lambda) unequal to number of roots => uncorrectable
+		 * error detected
+		 */
+		return -1;
+	}
+	/*
+	 * Compute err evaluator poly omega(x) = s(x)*lambda(x) (modulo
+	 * x**(nn-kk)). in index form. Also find deg(omega).
+	 */
+	
+	deg_omega = 0;
+	for (i = 0; i < nn-kk;i++){
+		tmp = 0;
+		j = (deg_lambda < i) ? deg_lambda : i;
+		for(;j >= 0; j--){
+			if ((s[i + 1 - j] != nn) && (lambda[j] != nn))
+				//tmp ^= alpha_to[modnn(s[i + 1 - j] + lambda[j])];
+				tmp ^= alpha_to[(s[i + 1 - j] + lambda[j])%nn];
+		}
+		if(tmp != 0)
+			deg_omega = i;
+		omega[i] = index_of[tmp];
+	}
+	omega[nn-kk] = nn;
+
+
+
+
+	/*
+	 * Compute error values in poly-form. num1 = omega(inv(X(l))), num2 =
+	 * inv(X(l))**(1-1) and den = lambda_pr(inv(X(l))) all in poly-form
+	 */
+	for (j = count-1; j >=0; j--) {
+		num1 = 0;
+		for (i = deg_omega; i >= 0; i--) {
+			if (omega[i] != nn)
+				//num1  ^= alpha_to[modnn(omega[i] + i * root[j])];
+				num1  ^= alpha_to[(omega[i] + i * root[j])%nn];
+		}
+		//num2 = alpha_to[modnn(root[j] * (1 - 1) + nn)];
+		num2 = alpha_to[(root[j] * (1 - 1) + nn)%nn];
+		den = 0;
+
+		/* lambda[i+1] for i even is the formal derivative lambda_pr of lambda[i] */
+		for (i = minimum(deg_lambda,nn-kk-1) & ~1; i >= 0; i -=2) {
+			if(lambda[i+1] != nn)
+				//den ^= alpha_to[modnn(lambda[i+1] + i * root[j])];
+				den ^= alpha_to[(lambda[i+1] + i * root[j])%nn];
+		}
+		if (den == 0) {
+#ifdef DEBUG
+			printk("\n ERROR: denominator = 0\n");
+#endif
+			return -1;
+		}
+		/* Apply error to data */
+		if (num1 != 0) {
+			//data[loc[j]] ^= alpha_to[modnn(index_of[num1] + index_of[num2] + nn - index_of[den])];
+			data[loc[j]] ^= alpha_to[(index_of[num1] + index_of[num2] + nn - index_of[den])%nn];
+		}
+	}
+	return count;
+}
+
+/**
+ * mv_nand_calculate_ecc_rs - [NAND Interface] Calculate 4 symbol ECC code for 512 byte block
+ * @mtd:	MTD block structure
+ * @dat:	raw data
+ * @ecc_code:	buffer for ECC
+ */
+int mv_nand_calculate_ecc_rs(struct mtd_info *mtd, const u_char *data, u_char *ecc_code)
+{
+    	int i;	
+	u_short rsdata[nn];
+	
+	/* Generate Tables in first run */
+	if (!rs_initialized) {
+		generate_gf();
+		gen_poly();		
+		rs_initialized = 1;
+	}
+
+	for(i=512; i<nn; i++)
+		rsdata[i] = 0;
+
+		for(i=0; i<512; i++)
+			rsdata[i] = (u_short) data[i];	
+		if ((encode_rs(rsdata,&(rsdata[kk]))) != 0) 
+			return -1;
+		*(ecc_code) 	= (unsigned char) rsdata[kk];
+		*(ecc_code+1) 	= ((rsdata[0x3F7])   >> 8) | ((rsdata[0x3F7+1]) << 2);
+		*(ecc_code+2) 	= ((rsdata[0x3F7+1]) >> 6) | ((rsdata[0x3F7+2]) << 4);  
+		*(ecc_code+3) 	= ((rsdata[0x3F7+2]) >> 4) | ((rsdata[0x3F7+3]) << 6);
+		*(ecc_code+4) 	= ((rsdata[0x3F7+3]) >> 2);
+		*(ecc_code+5) 	= (unsigned char) rsdata[kk+4];
+		*(ecc_code+6)	= ((rsdata[0x3F7+4])   >> 8) | ((rsdata[0x3F7+1+4]) << 2);
+		*(ecc_code+7) 	= ((rsdata[0x3F7+1+4]) >> 6) | ((rsdata[0x3F7+2+4]) << 4);
+		*(ecc_code+8) 	= ((rsdata[0x3F7+2+4]) >> 4) | ((rsdata[0x3F7+3+4]) << 6);
+		*(ecc_code+9) 	= ((rsdata[0x3F7+3+4]) >> 2);
+
+	return 0;
+}
+
+/**
+ * mv_nand_correct_data - [NAND Interface] Detect and correct bit error(s)
+ * @mtd:	MTD block structure
+ * @dat:	raw data read from the chip
+ * @store_ecc:	ECC from the chip
+ * @calc_ecc:	the ECC calculated from raw data
+ *
+ * Detect and correct a 1 bit error for 256 byte block
+ */
+int mv_nand_correct_data_rs(struct mtd_info *mtd, u_char *data, u_char *store_ecc, u_char *calc_ecc)
+{
+	int ret,i=0;
+	u_short rsdata[nn];
+	
+	/* Generate Tables in first run */
+	if (!rs_initialized) {
+		generate_gf();
+		gen_poly();		
+		rs_initialized = 1;
+	}
+
+	/* is decode needed ? */
+	if((*(u32*)store_ecc == *(u32*)calc_ecc) &&
+	   (*(u32*)(store_ecc + 4) == *(u32*)(calc_ecc + 4)) &&
+	   (*(u16*)(store_ecc + 8) == *(u16*)(calc_ecc + 8)))
+		return 0;
+
+	/* did we read an erased page ? */
+	for(i = 0; i < 512 ;i += 4) {
+		if(*(u32*)(data+i) != 0xFFFFFFFF) {
+			DBG("%s: trying to correct data\n",__FUNCTION__);
+			goto correct;
+		}
+	}
+	/* page was erased, return gracefully */
+	return 0;
+	
+correct:
+
+	for(i=512; i<nn; i++) 
+	rsdata[i] = 0;
+
+    	/* errors*/
+	//data[20] = 0xDD;
+	//data[30] = 0xDD;
+	//data[40] = 0xDD;
+	//data[50] = 0xDD;
+	//data[60] = 0xDD;
+
+	/* Ecc is calculated on chunks of 512B */
+		for(i=0; i<512; i++)
+			rsdata[i] = (u_short) data[i];
+
+		rsdata[kk]   = ( (*(store_ecc+1) & 0x03) <<8) | (*(store_ecc));
+		rsdata[kk+1] = ( (*(store_ecc+2) & 0x0F) <<6) | (*(store_ecc+1)>>2);
+		rsdata[kk+2] = ( (*(store_ecc+3) & 0x3F) <<4) | (*(store_ecc+2)>>4);
+		rsdata[kk+3] = (*(store_ecc+4) <<2) | (*(store_ecc+3)>>6);
+
+		rsdata[kk+4] = ( (*(store_ecc+1+5) & 0x03) <<8) | (*(store_ecc+5));
+		rsdata[kk+5] = ( (*(store_ecc+2+5) & 0x0F) <<6) | (*(store_ecc+1+5)>>2);
+		rsdata[kk+6] = ( (*(store_ecc+3+5) & 0x3F) <<4) | (*(store_ecc+2+5)>>4);
+		rsdata[kk+7] = (*(store_ecc+4+5) <<2) | (*(store_ecc+3+5)>>6);
+
+		ret = decode_rs(rsdata);
+
+		/* Check for excessive errors */
+		if ((ret > tt) || (ret < 0)) {
+			printk("%s: uncorrectable error !!!\n",__FUNCTION__); 
+			return -1;
+		}
+	
+		/* Copy corrected data */
+		for (i=0; i<512; i++)
+			data[i] = (unsigned char) rsdata[i];
+
+	return 0;
+}
+
+static void mv_nand_enable_hwecc(struct mtd_info *mtd, int mode)
+{
+	return;
+}
+
+#endif	/* CONFIG_MTD_NAND_LNC_RS_ECC */
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_lnc.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_lnc.h
new file mode 100644
index 0000000..fdd8ab9
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_lnc.h
@@ -0,0 +1,85 @@
+/*******************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef _NAND_H_
+#define _NAND_H_
+
+/* defines */
+#define	MV_NAND_ECC_4BIT	4
+#define MV_NAND_ECC_1BIT	1
+
+#ifdef	CONFIG_MTD_NAND_LNC_RS_ECC
+static struct nand_ecclayout mv_nand_rs_oobinfo = {
+	.eccbytes = 40,
+	.eccpos = {
+			24, 25, 26, 27, 28, 29, 30, 31,
+			32, 33, 34, 35, 36, 37, 38, 39,
+			40, 41, 42, 43, 44, 45, 46, 47,
+			48, 49, 50, 51, 52, 53, 54, 55,
+			56, 57, 58, 59, 60, 61, 62, 63
+		  },
+
+	.oobfree = {{6, 18}}
+};
+
+//typedef unsigned int dtype;
+typedef u_short dtype;
+
+void generate_gf(void); /* Generate Galois Field */
+void gen_poly(void);    /* Generate generator polynomial */
+
+/* Reed-Solomon encoding
+ * data[] is the input block, parity symbols are placed in bb[]
+ * bb[] may lie past the end of the data, e.g., for (255,223):
+ *      encode_rs(&data[0],&data[223]);
+ */
+static inline char encode_rs(dtype data[], dtype bb[]);
+
+
+/* Reed-Solomon errors decoding
+ * The received block goes into data[]
+ *
+ * The decoder corrects the symbols in place, if possible and returns
+ * the number of corrected symbols. If the codeword is illegal or
+ * uncorrectible, the data array is unchanged and -1 is returned
+ */
+static inline int decode_rs(dtype data[]);
+
+/**
+ * nand_calculate_ecc - [NAND Interface] Calculate 3 byte ECC code for 256 byte block
+ * @mtd:        MTD block structure
+ * @dat:        raw data
+ * @ecc_code:   buffer for ECC
+ */
+int mv_nand_calculate_ecc_rs(struct mtd_info *mtd, const u_char *data, u_char *ecc_code);
+
+/**
+ * nand_correct_data - [NAND Interface] Detect and correct bit error(s)
+ * @mtd:        MTD block structure
+ * @dat:        raw data read from the chip
+ * @store_ecc:  ECC from the chip
+ * @calc_ecc:   the ECC calculated from raw data
+ *
+ * Detect and correct a 1 bit error for 256 byte block
+ */
+int mv_nand_correct_data_rs(struct mtd_info *mtd, u_char *data, u_char *store_ecc, u_char *calc_ecc);
+
+static void mv_nand_enable_hwecc(struct mtd_info *mtd, int mode);
+#endif
+
+
+#endif /* _NAND_H_ */
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_nfc.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_nfc.c
new file mode 100644
index 0000000..c886baf
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_nfc.c
@@ -0,0 +1,1760 @@
+/*
+ * nand_nfc.c
+ *
+ * Copyright c 2005 Intel Corporation
+ * Copyright c 2006 Marvell International Ltd.
+ *
+ * This driver is based on the PXA drivers/mtd/nand/pxa3xx_nand.c
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include <linux/module.h>
+#include <linux/interrupt.h>
+#include <linux/platform_device.h>
+#include <linux/dma-mapping.h>
+#include <linux/delay.h>
+#if 0
+#include <linux/clk.h>
+#endif
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/nand.h>
+#include <linux/mtd/partitions.h>
+#include <linux/io.h>
+#include <linux/irq.h>
+#include <linux/slab.h>
+#include <asm/dma.h>
+
+#include "mvCommon.h"
+#include "mvOs.h"
+
+#ifdef MV_INCLUDE_PDMA
+#include <asm/hardware/pxa-dma.h>
+#include "pdma/mvPdma.h"
+#include "pdma/mvPdmaRegs.h"
+#endif
+#include "nand_nfc.h"
+
+#define	DRIVER_NAME	"armada-nand"
+
+#define NFC_DPRINT(x) 		//printk x
+#define PRINT_LVL		KERN_DEBUG
+
+#define	CHIP_DELAY_TIMEOUT		(20 * HZ/10)
+#define NFC_MAX_NUM_OF_DESCR	(33) /* worst case in 8K ganaged */
+#define NFC_8BIT1K_ECC_SPARE	(32)
+
+#define NFC_SR_MASK		(0xfff)
+#define NFC_SR_BBD_MASK		(NFC_SR_CS0_BBD_MASK | NFC_SR_CS1_BBD_MASK)
+
+
+char *cmd_text[]= {
+	"MV_NFC_CMD_READ_ID",
+	"MV_NFC_CMD_READ_STATUS",
+	"MV_NFC_CMD_ERASE",
+	"MV_NFC_CMD_MULTIPLANE_ERASE",
+	"MV_NFC_CMD_RESET",
+
+	"MV_NFC_CMD_CACHE_READ_SEQ",
+	"MV_NFC_CMD_CACHE_READ_RAND",
+	"MV_NFC_CMD_EXIT_CACHE_READ",
+	"MV_NFC_CMD_CACHE_READ_START",
+	"MV_NFC_CMD_READ_MONOLITHIC",
+	"MV_NFC_CMD_READ_MULTIPLE",
+	"MV_NFC_CMD_READ_NAKED",
+	"MV_NFC_CMD_READ_LAST_NAKED",
+	"MV_NFC_CMD_READ_DISPATCH",
+
+	"MV_NFC_CMD_WRITE_MONOLITHIC",
+	"MV_NFC_CMD_WRITE_MULTIPLE",
+	"MV_NFC_CMD_WRITE_NAKED",
+	"MV_NFC_CMD_WRITE_LAST_NAKED",
+	"MV_NFC_CMD_WRITE_DISPATCH",
+	"MV_NFC_CMD_WRITE_DISPATCH_START",
+	"MV_NFC_CMD_WRITE_DISPATCH_END",
+
+	"MV_NFC_CMD_COUNT"	/* This should be the last enum */
+
+};
+
+MV_U32 pg_sz[NFC_PAGE_SIZE_MAX_CNT] = {512, 2048, 4096, 8192, 16384};
+
+/* error code and state */
+enum {
+	ERR_NONE	= 0,
+	ERR_DMABUSERR	= -1,
+	ERR_CMD_TO	= -2,
+	ERR_DATA_TO	= -3,
+	ERR_DBERR	= -4,
+	ERR_BBD		= -5,
+};
+
+enum {
+	STATE_READY	= 0,
+	STATE_CMD_HANDLE,
+	STATE_DMA_READING,
+	STATE_DMA_WRITING,
+	STATE_DMA_DONE,
+	STATE_PIO_READING,
+	STATE_PIO_WRITING,
+};
+
+struct orion_nfc_info {
+	struct platform_device	 *pdev;
+#if 0
+	struct clk		*clk;
+#endif
+	void __iomem		*mmio_base;
+	unsigned int		mmio_phys_base;
+
+	unsigned int 		buf_start;
+	unsigned int		buf_count;
+
+	unsigned char		*data_buff;
+	dma_addr_t 		data_buff_phys;
+	size_t			data_buff_size;
+
+	/* saved column/page_addr during CMD_SEQIN */
+	int			seqin_column;
+	int			seqin_page_addr;
+
+	/* relate to the command */
+	unsigned int		state;
+	unsigned int		use_dma;	/* use DMA ? */
+
+	/* flash information */
+	unsigned int		tclk;		/* Clock supplied to NFC */
+	unsigned int		nfc_width;	/* Width of NFC 16/8 bits */
+	unsigned int		num_devs;	/* Number of NAND devices 
+						   (2 for ganged mode).   */
+	unsigned int		num_cs;		/* Number of NAND devices 
+						   chip-selects.	  */
+	MV_NFC_ECC_MODE		ecc_type;
+	enum nfc_page_size	page_size;
+	uint32_t 		page_per_block;	/* Pages per block (PG_PER_BLK) */	
+	uint32_t 		flash_width;	/* Width of Flash memory (DWIDTH_M) */
+	size_t	 		read_id_bytes;
+
+	size_t			data_size;	/* data size in FIFO */
+	size_t			read_size;
+	int 			retcode;
+	uint32_t		dscr;		/* IRQ events - status */
+	struct completion 	cmd_complete;
+
+	int			chained_cmd;
+	uint32_t		column;
+	uint32_t		page_addr;
+	MV_NFC_CMD_TYPE		cmd;
+	MV_NFC_CTRL		nfcCtrl;
+
+	/* RW buffer chunks config */
+	MV_U32			sgBuffAddr[MV_NFC_RW_MAX_BUFF_NUM];
+	MV_U32			sgBuffSize[MV_NFC_RW_MAX_BUFF_NUM];
+	MV_U32			sgNumBuffs;
+
+	/* suspend / resume data */
+	MV_U32			nfcUnitData[128];
+	MV_U32			nfcDataLen;
+	MV_U32			pdmaUnitData[128];
+	MV_U32			pdmaDataLen;
+};
+
+/*
+ * ECC Layout
+ */
+
+static struct nand_ecclayout ecc_latout_512B_hamming = {
+	.eccbytes = 6,
+	.eccpos = {8, 9, 10, 11, 12, 13 },
+	.oobfree = { {2, 6} }
+};
+
+static struct nand_ecclayout ecc_layout_2KB_hamming = {
+	.eccbytes = 24,
+	.eccpos = {
+		40, 41, 42, 43, 44, 45, 46, 47,
+		48, 49, 50, 51, 52, 53, 54, 55,
+		56, 57, 58, 59, 60, 61, 62, 63},
+	.oobfree = { {2, 38} }
+};
+
+static struct nand_ecclayout ecc_layout_2KB_bch4bit = {
+	.eccbytes = 32,
+	.eccpos = {
+		32, 33, 34, 35, 36, 37, 38, 39,
+		40, 41, 42, 43, 44, 45, 46, 47,
+		48, 49, 50, 51, 52, 53, 54, 55,
+		56, 57, 58, 59, 60, 61, 62, 63},
+	.oobfree = { {2, 30} }
+};
+
+static struct nand_ecclayout ecc_layout_4KB_bch4bit = {
+	.eccbytes = 64,
+	.eccpos = {
+		32,  33,  34,  35,  36,  37,  38,  39,
+		40,  41,  42,  43,  44,  45,  46,  47,
+		48,  49,  50,  51,  52,  53,  54,  55,
+		56,  57,  58,  59,  60,  61,  62,  63,
+		96,  97,  98,  99,  100, 101, 102, 103,
+		104, 105, 106, 107, 108, 109, 110, 111,
+		112, 113, 114, 115, 116, 117, 118, 119,
+		120, 121, 122, 123, 124, 125, 126, 127},
+	/* Bootrom looks in bytes 0 & 5 for bad blocks */
+	.oobfree = { {1, 4}, {6, 26}, { 64, 32} }
+};
+
+static struct nand_ecclayout ecc_layout_8KB_bch4bit = {
+	.eccbytes = 128,
+	.eccpos = {
+		32,  33,  34,  35,  36,  37,  38,  39,
+		40,  41,  42,  43,  44,  45,  46,  47,
+		48,  49,  50,  51,  52,  53,  54,  55,
+		56,  57,  58,  59,  60,  61,  62,  63,
+
+		96,  97,  98,  99,  100, 101, 102, 103,
+		104, 105, 106, 107, 108, 109, 110, 111,
+		112, 113, 114, 115, 116, 117, 118, 119,
+		120, 121, 122, 123, 124, 125, 126, 127,
+
+		160, 161, 162, 163, 164, 165, 166, 167,
+		168, 169, 170, 171, 172, 173, 174, 175,
+		176, 177, 178, 179, 180, 181, 182, 183,
+		184, 185, 186, 187, 188, 189, 190, 191,
+
+		224, 225, 226, 227, 228, 229, 230, 231,
+		232, 233, 234, 235, 236, 237, 238, 239,
+		240, 241, 242, 243, 244, 245, 246, 247,
+		248, 249, 250, 251, 252, 253, 254, 255},
+
+	/* Bootrom looks in bytes 0 & 5 for bad blocks */
+	.oobfree = { {1, 4}, {6, 26}, { 64, 32}, {128, 32}, {192, 32} }
+};
+
+static struct nand_ecclayout ecc_layout_4KB_bch8bit = {
+	.eccbytes = 64,
+	.eccpos = {
+		32,  33,  34,  35,  36,  37,  38,  39,
+		40,  41,  42,  43,  44,  45,  46,  47,
+		48,  49,  50,  51,  52,  53,  54,  55,
+		56,  57,  58,  59,  60,  61,  62,  63},
+	/* Bootrom looks in bytes 0 & 5 for bad blocks */
+	.oobfree = { {1, 4}, {6, 26},  }
+};
+
+static struct nand_ecclayout ecc_layout_8KB_bch8bit = {
+	.eccbytes = 160,
+	.eccpos = {
+		128, 129, 130, 131, 132, 133, 134, 135,
+		136, 137, 138, 139, 140, 141, 142, 143,
+		144, 145, 146, 147, 148, 149, 150, 151,
+		152, 153, 154, 155, 156, 157, 158, 159},
+	/* Bootrom looks in bytes 0 & 5 for bad blocks */
+	.oobfree = { {1, 4}, {6, 122},  }
+};
+
+static struct nand_ecclayout ecc_layout_8KB_bch12bit = {
+	.eccbytes = 0,
+	.eccpos = { },
+	/* Bootrom looks in bytes 0 & 5 for bad blocks */
+	.oobfree = { {1, 4}, {6, 58}, }
+};
+
+static struct nand_ecclayout ecc_layout_16KB_bch12bit = {
+	.eccbytes = 0,
+	.eccpos = { },
+	/* Bootrom looks in bytes 0 & 5 for bad blocks */
+	.oobfree = { {1, 4}, {6, 122},  }
+};
+
+/*
+ * Define bad block scan pattern when scanning a device for factory 
+ * marked blocks.
+ */
+static uint8_t mv_scan_pattern[] = { 0xff, 0xff };
+
+static struct nand_bbt_descr mv_sp_bb = {
+	.options = NAND_BBT_SCANMVCUSTOM,
+	.offs = 5,
+	.len = 1,
+	.pattern = mv_scan_pattern
+};
+
+static struct nand_bbt_descr mv_lp_bb = {
+	.options = NAND_BBT_SCANMVCUSTOM,
+	.offs = 0,
+	.len = 2,
+	.pattern = mv_scan_pattern
+};
+
+/*
+ * Lookup Tables
+ */
+
+struct orion_nfc_naked_info {
+	
+	struct nand_ecclayout* 	ecc_layout;
+	struct nand_bbt_descr*	bb_info;
+	uint32_t		bb_bytepos;
+	uint32_t		chunk_size;
+	uint32_t		chunk_spare;
+	uint32_t		chunk_cnt;
+	uint32_t		last_chunk_size;
+	uint32_t		last_chunk_spare;
+};
+
+			                     /* PageSize*/          /* ECc Type */
+static struct orion_nfc_naked_info orion_nfc_naked_info_lkup[NFC_PAGE_SIZE_MAX_CNT][MV_NFC_ECC_MAX_CNT] = {
+	/* 512B Pages */
+	{{    	/* Hamming */
+		&ecc_latout_512B_hamming, &mv_sp_bb, 512, 512, 16, 1, 0, 0
+	}, { 	/* BCH 4bit */
+		NULL, NULL, 0, 0, 0, 0, 0, 0
+	}, { 	/* BCH 8bit */
+		NULL, NULL, 0, 0, 0, 0, 0, 0
+	}, { 	/* BCH 12bit */
+		NULL, NULL, 0, 0, 0, 0, 0, 0
+	}, { 	/* BCH 16bit */
+		NULL, NULL, 0, 0, 0, 0, 0, 0
+	}, { 	/* No ECC */
+		NULL, NULL, 0, 0, 0, 0, 0, 0
+	}},
+	/* 2KB Pages */
+	{{	/* Hamming */
+		&ecc_layout_2KB_hamming, &mv_lp_bb, 2048, 2048, 40, 1, 0, 0
+	}, { 	/* BCH 4bit */
+		&ecc_layout_2KB_bch4bit, &mv_lp_bb, 2048, 2048, 32, 1, 0, 0
+	}, { 	/* BCH 8bit */
+		NULL, NULL, 2018, 1024, 0, 1, 1024, 32
+	}, { 	/* BCH 12bit */
+		NULL, NULL, 1988, 704, 0, 2, 640, 0
+	}, { 	/* BCH 16bit */
+		NULL, NULL, 1958, 512, 0, 4, 0, 32
+	}, { 	/* No ECC */
+		NULL, NULL, 0, 0, 0, 0, 0, 0
+	}},
+	/* 4KB Pages */
+	{{	/* Hamming */
+		NULL, 0, 0, 0, 0, 0, 0, 0
+	}, { 	/* BCH 4bit */
+		&ecc_layout_4KB_bch4bit, &mv_lp_bb, 4034, 2048, 32, 2, 0, 0
+	}, { 	/* BCH 8bit */
+		&ecc_layout_4KB_bch8bit, &mv_lp_bb, 4006, 1024, 0, 4, 0, 64
+	}, { 	/* BCH 12bit */
+		NULL, NULL, 3946, 704,  0, 5, 576, 32
+	}, { 	/* BCH 16bit */
+		NULL, NULL, 3886, 512, 0, 8, 0, 32
+	}, { 	/* No ECC */
+		NULL, NULL, 0, 0, 0, 0, 0, 0
+	}},
+	/* 8KB Pages */
+	{{	/* Hamming */
+		NULL, 0, 0, 0, 0, 0, 0, 0
+	}, { 	/* BCH 4bit */
+		&ecc_layout_8KB_bch4bit, &mv_lp_bb, 8102, 2048, 32, 4, 0, 0
+	}, { 	/* BCH 8bit */
+		&ecc_layout_8KB_bch8bit, &mv_lp_bb, 7982, 1024, 0, 8, 0, 160
+	}, { 	/* BCH 12bit */
+		&ecc_layout_8KB_bch12bit, &mv_lp_bb,7862, 704, 0, 11, 448, 64
+	}, { 	/* BCH 16bit */
+		NULL, NULL, 7742, 512, 0, 16, 0, 32
+	}, { 	/* No ECC */
+		NULL, NULL, 0, 0, 0, 0, 0, 0
+	}},
+	/* 16KB Pages */
+	{{	/* Hamming */
+		NULL, NULL, 0, 0, 0, 0, 0, 0
+	}, { 	/* BCH 4bit */
+		NULL, NULL, 15914, 2048, 32, 8, 0, 0
+	}, { 	/* BCH 8bit */
+		NULL, NULL, 15930, 1024, 0, 16, 0, 352
+	}, { 	/* BCH 12bit */
+		&ecc_layout_16KB_bch12bit, &mv_lp_bb, 15724, 704, 0, 23, 192, 128
+	}, { 	/* BCH 16bit */
+		NULL, NULL, 15484, 512, 0, 32, 0, 32
+	}, { 	/* No ECC */
+		NULL, NULL, 0, 0, 0, 0, 0, 0
+	}}};
+		
+
+#define ECC_LAYOUT	(orion_nfc_naked_info_lkup[info->page_size][info->ecc_type].ecc_layout)
+#define BB_INFO		(orion_nfc_naked_info_lkup[info->page_size][info->ecc_type].bb_info)
+#define	BB_BYTE_POS	(orion_nfc_naked_info_lkup[info->page_size][info->ecc_type].bb_bytepos)
+#define CHUNK_CNT	(orion_nfc_naked_info_lkup[info->page_size][info->ecc_type].chunk_cnt)
+#define CHUNK_SZ	(orion_nfc_naked_info_lkup[info->page_size][info->ecc_type].chunk_size)
+#define CHUNK_SPR	(orion_nfc_naked_info_lkup[info->page_size][info->ecc_type].chunk_spare)
+#define LST_CHUNK_SZ	(orion_nfc_naked_info_lkup[info->page_size][info->ecc_type].last_chunk_size)
+#define LST_CHUNK_SPR	(orion_nfc_naked_info_lkup[info->page_size][info->ecc_type].last_chunk_spare)
+
+struct orion_nfc_cmd_info {
+	
+	uint32_t		events_p1;	/* post command events */
+	uint32_t		events_p2;	/* post data events */
+	MV_NFC_PIO_RW_MODE	rw;
+};
+
+static struct orion_nfc_cmd_info orion_nfc_cmd_info_lkup[MV_NFC_CMD_COUNT] = {
+	/* Phase 1 interrupts */			/* Phase 2 interrupts */			/* Read/Write */  /* MV_NFC_CMD_xxxxxx */
+	{(NFC_SR_RDDREQ_MASK), 				(0),						MV_NFC_PIO_READ}, /* READ_ID */
+	{(NFC_SR_RDDREQ_MASK), 				(0),						MV_NFC_PIO_READ}, /* READ_STATUS */
+	{(0), 						(MV_NFC_STATUS_RDY | MV_NFC_STATUS_BBD),	MV_NFC_PIO_NONE}, /* ERASE */
+	{(0), 						(0), 						MV_NFC_PIO_NONE}, /* MULTIPLANE_ERASE */
+	{(0), 						(MV_NFC_STATUS_RDY), 				MV_NFC_PIO_NONE}, /* RESET */
+	{(0), 						(0), 						MV_NFC_PIO_READ}, /* CACHE_READ_SEQ */
+	{(0), 						(0), 						MV_NFC_PIO_READ}, /* CACHE_READ_RAND */
+	{(0), 						(0), 						MV_NFC_PIO_NONE}, /* EXIT_CACHE_READ */
+	{(0), 						(0), 						MV_NFC_PIO_READ}, /* CACHE_READ_START */
+	{(NFC_SR_RDDREQ_MASK | NFC_SR_UNCERR_MASK), 	(0), 						MV_NFC_PIO_READ}, /* READ_MONOLITHIC */
+	{(0), 						(0),						MV_NFC_PIO_READ}, /* READ_MULTIPLE */
+	{(NFC_SR_RDDREQ_MASK | NFC_SR_UNCERR_MASK), 	(0), 						MV_NFC_PIO_READ}, /* READ_NAKED */
+	{(NFC_SR_RDDREQ_MASK | NFC_SR_UNCERR_MASK), 	(0), 						MV_NFC_PIO_READ}, /* READ_LAST_NAKED */
+	{(0), 						(0), 						MV_NFC_PIO_NONE}, /* READ_DISPATCH */
+	{(MV_NFC_STATUS_WRD_REQ), 			(MV_NFC_STATUS_RDY | MV_NFC_STATUS_BBD),	MV_NFC_PIO_WRITE},/* WRITE_MONOLITHIC */
+	{(0), 						(0), 						MV_NFC_PIO_WRITE},/* WRITE_MULTIPLE */
+	{(MV_NFC_STATUS_WRD_REQ),			(MV_NFC_STATUS_PAGED),				MV_NFC_PIO_WRITE},/* WRITE_NAKED */
+	{(0), 						(0), 						MV_NFC_PIO_WRITE},/* WRITE_LAST_NAKED */
+	{(0), 						(0), 						MV_NFC_PIO_NONE}, /* WRITE_DISPATCH */
+	{(MV_NFC_STATUS_CMDD),				(0),						MV_NFC_PIO_NONE}, /* WRITE_DISPATCH_START */
+	{(0),						(MV_NFC_STATUS_RDY | MV_NFC_STATUS_BBD), 	MV_NFC_PIO_NONE}, /* WRITE_DISPATCH_END */
+};
+
+static int prepare_read_prog_cmd(struct orion_nfc_info *info,
+			int column, int page_addr)
+{
+	MV_U32 size;
+
+	if (mvNfcFlashPageSizeGet(&info->nfcCtrl, &size, &info->data_size) 
+	    != MV_OK)
+		return -EINVAL;
+
+	return 0;
+}
+int orion_nfc_wait_for_completion_timeout(struct orion_nfc_info *info, int timeout)
+{
+	return wait_for_completion_timeout(&info->cmd_complete, timeout);
+
+}
+
+#ifdef CONFIG_MV_INCLUDE_PDMA
+static void orion_nfc_data_dma_irq(int irq, void *data)
+{
+	struct orion_nfc_info *info = data;
+	uint32_t dcsr, intr;
+	int channel = info->nfcCtrl.dataChanHndl.chanNumber;
+
+	intr = MV_REG_READ(PDMA_INTR_CAUSE_REG);
+	dcsr = MV_REG_READ(PDMA_CTRL_STATUS_REG(channel));
+	MV_REG_WRITE(PDMA_CTRL_STATUS_REG(channel), dcsr);
+
+	NFC_DPRINT((PRINT_LVL "orion_nfc_data_dma_irq(0x%x, 0x%x) - 1.\n", dcsr, intr));
+
+	if(info->chained_cmd) {
+		if (dcsr & DCSR_BUSERRINTR) {
+			info->retcode = ERR_DMABUSERR;
+			complete(&info->cmd_complete);
+		}
+		if ((info->state == STATE_DMA_READING) && (dcsr & DCSR_ENDINTR)) {
+			info->state = STATE_READY;
+			complete(&info->cmd_complete);
+		}
+		return;
+	}
+
+	if (dcsr & DCSR_BUSERRINTR) {
+		info->retcode = ERR_DMABUSERR;
+		complete(&info->cmd_complete);
+	}
+
+	if (info->state == STATE_DMA_WRITING) {
+		info->state = STATE_DMA_DONE;
+		mvNfcIntrSet(&info->nfcCtrl,  MV_NFC_STATUS_BBD | MV_NFC_STATUS_RDY , MV_TRUE);
+	} else {
+		info->state = STATE_READY;
+		complete(&info->cmd_complete);
+	}
+
+	return;
+}
+#endif
+
+static irqreturn_t orion_nfc_irq_pio(int irq, void *devid)
+{
+	struct orion_nfc_info *info = devid;
+
+	/* Disable all interrupts */
+	mvNfcIntrSet(&info->nfcCtrl, 0xFFF, MV_FALSE);
+
+	/* Clear the interrupt and pass the status UP */
+	info->dscr = MV_REG_READ(NFC_STATUS_REG);
+	NFC_DPRINT((PRINT_LVL ">>> orion_nfc_irq_pio(0x%x)\n", info->dscr));
+	MV_REG_WRITE(NFC_STATUS_REG, info->dscr);
+	complete(&info->cmd_complete);
+
+	return IRQ_HANDLED;
+}
+	
+#ifdef CONFIG_MV_INCLUDE_PDMA
+static irqreturn_t orion_nfc_irq_dma(int irq, void *devid)
+{
+	struct orion_nfc_info *info = devid;
+	unsigned int status;
+
+	status = MV_REG_READ(NFC_STATUS_REG);
+
+	NFC_DPRINT((PRINT_LVL "orion_nfc_irq_dma(0x%x) - 1.\n", status));
+
+	if(!info->chained_cmd) {
+		if (status & (NFC_SR_RDDREQ_MASK | NFC_SR_UNCERR_MASK)) {
+			if (status & NFC_SR_UNCERR_MASK)
+				info->retcode = ERR_DBERR;
+			mvNfcIntrSet(&info->nfcCtrl, NFC_SR_RDDREQ_MASK | NFC_SR_UNCERR_MASK, MV_FALSE);
+			if (info->use_dma) {
+				info->state = STATE_DMA_READING;
+				mvNfcReadWrite(&info->nfcCtrl, info->cmd, (MV_U32*)info->data_buff, info->data_buff_phys);
+			} else {
+				info->state = STATE_PIO_READING;
+				complete(&info->cmd_complete);
+			}
+		} else if (status & NFC_SR_WRDREQ_MASK) {
+			mvNfcIntrSet(&info->nfcCtrl, NFC_SR_WRDREQ_MASK, MV_FALSE);
+			if (info->use_dma) {
+				info->state = STATE_DMA_WRITING;
+				NFC_DPRINT((PRINT_LVL "Calling mvNfcReadWrite().\n"));
+				if (mvNfcReadWrite(&info->nfcCtrl, info->cmd,
+						   (MV_U32 *)info->data_buff,
+						   info->data_buff_phys) 
+				    != MV_OK)
+					printk(KERN_ERR "mvNfcReadWrite() failed.\n");
+			} else {
+				info->state = STATE_PIO_WRITING;
+				complete(&info->cmd_complete);
+			}
+		} else if (status & (NFC_SR_BBD_MASK | MV_NFC_CS0_CMD_DONE_INT |
+				     NFC_SR_RDY0_MASK | MV_NFC_CS1_CMD_DONE_INT |
+				     NFC_SR_RDY1_MASK)) {
+			if (status & NFC_SR_BBD_MASK)
+				info->retcode = ERR_BBD;
+			mvNfcIntrSet(&info->nfcCtrl,  MV_NFC_STATUS_BBD |
+					MV_NFC_STATUS_CMDD | MV_NFC_STATUS_RDY,
+					MV_FALSE);
+			info->state = STATE_READY;
+			complete(&info->cmd_complete);
+		}
+	} else if (status & (NFC_SR_BBD_MASK | NFC_SR_RDY0_MASK |
+				NFC_SR_RDY1_MASK | NFC_SR_UNCERR_MASK)) {
+		if (status & (NFC_SR_BBD_MASK | NFC_SR_UNCERR_MASK))
+			info->retcode = ERR_DBERR;
+		mvNfcIntrSet(&info->nfcCtrl, MV_NFC_STATUS_BBD |
+				MV_NFC_STATUS_RDY | MV_NFC_STATUS_CMDD,
+				MV_FALSE);
+		if ((info->state != STATE_DMA_READING) ||
+		    (info->retcode == ERR_DBERR)) {
+			info->state = STATE_READY;
+			complete(&info->cmd_complete);
+		}
+	}
+	MV_REG_WRITE(NFC_STATUS_REG, status);
+	return IRQ_HANDLED;
+}
+#endif
+
+static int orion_nfc_cmd_prepare(struct orion_nfc_info *info,
+		MV_NFC_MULTI_CMD *descInfo, u32 *numCmds)
+{
+	MV_U32	i;
+	MV_NFC_MULTI_CMD *currDesc;	
+
+	currDesc = descInfo;
+	if (info->cmd == MV_NFC_CMD_READ_MONOLITHIC) {
+		/* Main Chunks */
+		for (i=0; i<CHUNK_CNT; i++)
+		{
+			if (i == 0)
+				currDesc->cmd = MV_NFC_CMD_READ_MONOLITHIC;
+			else if ((i == (CHUNK_CNT-1)) && (LST_CHUNK_SZ == 0) && (LST_CHUNK_SPR == 0))
+				currDesc->cmd = MV_NFC_CMD_READ_LAST_NAKED;
+			else
+				currDesc->cmd = MV_NFC_CMD_READ_NAKED;
+
+			currDesc->pageAddr = info->page_addr;
+			currDesc->pageCount = 1;
+			currDesc->virtAddr = (MV_U32 *)(info->data_buff + (i * CHUNK_SZ));
+			currDesc->physAddr = info->data_buff_phys + (i * CHUNK_SZ);
+			currDesc->length = (CHUNK_SZ + CHUNK_SPR);
+
+			if (CHUNK_SPR == 0)
+				currDesc->numSgBuffs = 1;
+			else
+			{
+				currDesc->numSgBuffs = 2;
+				currDesc->sgBuffAddr[0] = (info->data_buff_phys + (i * CHUNK_SZ));
+				currDesc->sgBuffAddrVirt[0] = (MV_U32 *)(info->data_buff + (i * CHUNK_SZ));
+				currDesc->sgBuffSize[0] = CHUNK_SZ;
+				currDesc->sgBuffAddr[1] = (info->data_buff_phys + (CHUNK_SZ * CHUNK_CNT) + LST_CHUNK_SZ + (i * CHUNK_SPR));
+				currDesc->sgBuffAddrVirt[1] = (MV_U32 *)(info->data_buff + (CHUNK_SZ * CHUNK_CNT) + LST_CHUNK_SZ + (i * CHUNK_SPR));
+				currDesc->sgBuffSize[1] = CHUNK_SPR;
+			}
+
+			currDesc++;
+		}
+		
+		/* Last chunk if existing */
+		if ((LST_CHUNK_SZ != 0) || (LST_CHUNK_SPR != 0))
+		{
+			currDesc->cmd = MV_NFC_CMD_READ_LAST_NAKED;
+			currDesc->pageAddr = info->page_addr;
+			currDesc->pageCount = 1;				
+			currDesc->length = (LST_CHUNK_SPR + LST_CHUNK_SZ);
+
+			if ((LST_CHUNK_SZ == 0) && (LST_CHUNK_SPR != 0))	/* Spare only */
+			{
+				currDesc->virtAddr = (MV_U32 *)(info->data_buff + (CHUNK_SZ * CHUNK_CNT) + LST_CHUNK_SZ + (CHUNK_SPR * CHUNK_CNT));
+				currDesc->physAddr = info->data_buff_phys + (CHUNK_SZ * CHUNK_CNT) + LST_CHUNK_SZ + (CHUNK_SPR * CHUNK_CNT);
+				currDesc->numSgBuffs = 1;
+				currDesc->length = LST_CHUNK_SPR;
+			}
+			else if ((LST_CHUNK_SZ != 0) && (LST_CHUNK_SPR == 0))	/* Data only */
+			{
+				currDesc->virtAddr = (MV_U32 *)(info->data_buff + (CHUNK_SZ * CHUNK_CNT));
+				currDesc->physAddr = info->data_buff_phys + (CHUNK_SZ * CHUNK_CNT);
+				currDesc->numSgBuffs = 1;
+				currDesc->length = LST_CHUNK_SZ;
+			}
+			else /* Both spare and data */
+			{
+				currDesc->numSgBuffs = 2;
+				currDesc->sgBuffAddr[0] = (info->data_buff_phys + (CHUNK_SZ * CHUNK_CNT));
+				currDesc->sgBuffAddrVirt[0] = (MV_U32 *)(info->data_buff + (CHUNK_SZ * CHUNK_CNT));
+				currDesc->sgBuffSize[0] = LST_CHUNK_SZ;
+				currDesc->sgBuffAddr[1] = (info->data_buff_phys + (CHUNK_SZ * CHUNK_CNT) + LST_CHUNK_SZ + (CHUNK_SPR * CHUNK_CNT));
+				currDesc->sgBuffAddrVirt[1] =  (MV_U32 *)(info->data_buff + (CHUNK_SZ * CHUNK_CNT) + LST_CHUNK_SZ + (CHUNK_SPR * CHUNK_CNT));
+				currDesc->sgBuffSize[1] = LST_CHUNK_SPR;
+			}
+			currDesc++;
+		}
+
+		*numCmds = CHUNK_CNT + (((LST_CHUNK_SZ) || (LST_CHUNK_SPR)) ? 1 : 0);
+	} else if (info->cmd == MV_NFC_CMD_WRITE_MONOLITHIC) {
+		/* Write Dispatch */
+		currDesc->cmd = MV_NFC_CMD_WRITE_DISPATCH_START;
+		currDesc->pageAddr = info->page_addr;
+		currDesc->pageCount = 1;
+		currDesc->numSgBuffs = 1;
+		currDesc->length = 0;
+		currDesc++;
+
+		/* Main Chunks */
+		for (i=0; i<CHUNK_CNT; i++)
+		{
+			currDesc->cmd = MV_NFC_CMD_WRITE_NAKED;
+			currDesc->pageAddr = info->page_addr;
+			currDesc->pageCount = 1;
+			currDesc->virtAddr = (MV_U32 *)(info->data_buff + (i * CHUNK_SZ));
+			currDesc->physAddr = info->data_buff_phys + (i * CHUNK_SZ);
+			currDesc->length = (CHUNK_SZ + CHUNK_SPR);
+
+			if (CHUNK_SPR == 0)
+				currDesc->numSgBuffs = 1;
+			else
+			{
+				currDesc->numSgBuffs = 2;
+				currDesc->sgBuffAddr[0] = (info->data_buff_phys + (i * CHUNK_SZ));
+				currDesc->sgBuffAddrVirt[0] = (MV_U32 *)(info->data_buff + (i * CHUNK_SZ));
+				currDesc->sgBuffSize[0] = CHUNK_SZ;
+				currDesc->sgBuffAddr[1] = (info->data_buff_phys + (CHUNK_SZ * CHUNK_CNT) + LST_CHUNK_SZ + (i * CHUNK_SPR));
+				currDesc->sgBuffAddrVirt[1] = (MV_U32 *)(info->data_buff + (CHUNK_SZ * CHUNK_CNT) + LST_CHUNK_SZ + (i * CHUNK_SPR));
+				currDesc->sgBuffSize[1] = CHUNK_SPR;
+			}
+
+			currDesc++;
+		}
+		
+		/* Last chunk if existing */
+		if ((LST_CHUNK_SZ != 0) || (LST_CHUNK_SPR != 0))
+		{
+			currDesc->cmd = MV_NFC_CMD_WRITE_NAKED;
+			currDesc->pageAddr = info->page_addr;
+			currDesc->pageCount = 1;
+			currDesc->length = (LST_CHUNK_SZ + LST_CHUNK_SPR);
+
+			if ((LST_CHUNK_SZ == 0) && (LST_CHUNK_SPR != 0))	/* Spare only */
+			{
+				currDesc->virtAddr = (MV_U32 *)(info->data_buff + (CHUNK_SZ * CHUNK_CNT) + LST_CHUNK_SZ + (CHUNK_SPR * CHUNK_CNT));
+				currDesc->physAddr = info->data_buff_phys + (CHUNK_SZ * CHUNK_CNT) + LST_CHUNK_SZ + (CHUNK_SPR * CHUNK_CNT);
+				currDesc->numSgBuffs = 1;
+			}
+			else if ((LST_CHUNK_SZ != 0) && (LST_CHUNK_SPR == 0))	/* Data only */
+			{
+				currDesc->virtAddr = (MV_U32 *)(info->data_buff + (CHUNK_SZ * CHUNK_CNT));
+				currDesc->physAddr = info->data_buff_phys + (CHUNK_SZ * CHUNK_CNT);
+				currDesc->numSgBuffs = 1;
+			}
+			else /* Both spare and data */
+			{
+				currDesc->numSgBuffs = 2;
+				currDesc->sgBuffAddr[0] = (info->data_buff_phys + (CHUNK_SZ * CHUNK_CNT));
+				currDesc->sgBuffAddrVirt[0] = (MV_U32 *)(info->data_buff + (CHUNK_SZ * CHUNK_CNT));
+				currDesc->sgBuffSize[0] = LST_CHUNK_SZ;
+				currDesc->sgBuffAddr[1] = (info->data_buff_phys + (CHUNK_SZ * CHUNK_CNT) + LST_CHUNK_SZ + (CHUNK_SPR * CHUNK_CNT));
+				currDesc->sgBuffAddrVirt[1] = (MV_U32 *)(info->data_buff + (CHUNK_SZ * CHUNK_CNT) + LST_CHUNK_SZ + (CHUNK_SPR * CHUNK_CNT));
+				currDesc->sgBuffSize[1] = LST_CHUNK_SPR;
+			}
+			currDesc++;
+		}
+
+		/* Write Dispatch END */
+		currDesc->cmd = MV_NFC_CMD_WRITE_DISPATCH_END;
+		currDesc->pageAddr = info->page_addr;
+		currDesc->pageCount = 1;
+		currDesc->numSgBuffs = 1;
+		currDesc->length = 0;
+
+		*numCmds = CHUNK_CNT + (((LST_CHUNK_SZ) || (LST_CHUNK_SPR)) ? 1 : 0) + 2;
+	} else {
+		descInfo[0].cmd = info->cmd;
+		descInfo[0].pageAddr = info->page_addr;
+		descInfo[0].pageCount = 1;
+		descInfo[0].virtAddr = (MV_U32 *)info->data_buff;
+		descInfo[0].physAddr = info->data_buff_phys;
+		descInfo[0].numSgBuffs = 1;
+		descInfo[0].length = info->data_size;
+		*numCmds = 1;
+	}
+
+	return 0;
+}
+
+#ifdef CONFIG_MV_INCLUDE_PDM
+static int orion_nfc_do_cmd_dma(struct orion_nfc_info *info,
+		uint32_t event)
+{
+	uint32_t ndcr;
+	int ret, timeout = CHIP_DELAY_TIMEOUT;
+	MV_STATUS status;
+	MV_U32	numCmds;
+
+	/* static allocation to avoid stack overflow*/
+	static MV_NFC_MULTI_CMD descInfo[NFC_MAX_NUM_OF_DESCR];
+
+	/* Clear all status bits. */
+	MV_REG_WRITE(NFC_STATUS_REG, NFC_SR_MASK);
+
+	mvNfcIntrSet(&info->nfcCtrl, event, MV_TRUE);
+
+	NFC_DPRINT((PRINT_LVL "\nAbout to issue dma cmd %d (cs %d) - 0x%x.\n",
+				info->cmd, info->nfcCtrl.currCs,
+				MV_REG_READ(NFC_CONTROL_REG)));
+	if ((info->cmd == MV_NFC_CMD_READ_MONOLITHIC) ||
+	    (info->cmd == MV_NFC_CMD_READ_ID) ||
+	    (info->cmd == MV_NFC_CMD_READ_STATUS))
+		info->state = STATE_DMA_READING;
+	else
+		info->state = STATE_CMD_HANDLE;
+	info->chained_cmd = 1;
+
+	orion_nfc_cmd_prepare(info, descInfo, &numCmds);
+
+	status = mvNfcCommandMultiple(&info->nfcCtrl,descInfo, numCmds);
+	if (status != MV_OK) {
+		printk(KERN_ERR "nfcCmdMultiple() failed for cmd %d (%d).\n",
+				info->cmd, status);
+		goto fail;
+	}
+
+	NFC_DPRINT((PRINT_LVL "After issue command %d - 0x%x.\n",
+				info->cmd, MV_REG_READ(NFC_STATUS_REG)));
+
+	ret = orion_nfc_wait_for_completion_timeout(info, timeout);
+	if (!ret) {
+		printk(KERN_ERR "Cmd %d execution timed out (0x%x) - cs %d.\n",
+				info->cmd, MV_REG_READ(NFC_STATUS_REG),
+				info->nfcCtrl.currCs);
+		info->retcode = ERR_CMD_TO;
+		goto fail_stop;
+	}
+
+	mvNfcIntrSet(&info->nfcCtrl, event | MV_NFC_STATUS_CMDD, MV_FALSE);
+
+	while (MV_PDMA_CHANNEL_STOPPED !=
+			mvPdmaChannelStateGet(&info->nfcCtrl.dataChanHndl)) {
+		if (info->retcode == ERR_NONE)
+			BUG();
+
+	}
+
+	return 0;
+
+fail_stop:
+	ndcr = MV_REG_READ(NFC_CONTROL_REG);
+	MV_REG_WRITE(NFC_CONTROL_REG, ndcr & ~NFC_CTRL_ND_RUN_MASK);
+	udelay(10);
+fail:
+	return -ETIMEDOUT;
+}
+#endif
+
+static int orion_nfc_error_check(struct orion_nfc_info *info)
+{
+	switch (info->cmd) {
+		case MV_NFC_CMD_ERASE:
+		case MV_NFC_CMD_MULTIPLANE_ERASE:
+		case MV_NFC_CMD_WRITE_MONOLITHIC:
+		case MV_NFC_CMD_WRITE_MULTIPLE:
+		case MV_NFC_CMD_WRITE_NAKED:
+		case MV_NFC_CMD_WRITE_LAST_NAKED:
+		case MV_NFC_CMD_WRITE_DISPATCH:
+		case MV_NFC_CMD_WRITE_DISPATCH_START:
+		case MV_NFC_CMD_WRITE_DISPATCH_END:
+			if (info->dscr & (MV_NFC_CS0_BAD_BLK_DETECT_INT | MV_NFC_CS1_BAD_BLK_DETECT_INT)) {
+				info->retcode = ERR_BBD;
+				return 1;
+			}
+			break;
+		
+		case MV_NFC_CMD_CACHE_READ_SEQ:
+		case MV_NFC_CMD_CACHE_READ_RAND:
+		case MV_NFC_CMD_EXIT_CACHE_READ:
+		case MV_NFC_CMD_CACHE_READ_START:
+		case MV_NFC_CMD_READ_MONOLITHIC:
+		case MV_NFC_CMD_READ_MULTIPLE:
+		case MV_NFC_CMD_READ_NAKED:
+		case MV_NFC_CMD_READ_LAST_NAKED:
+		case MV_NFC_CMD_READ_DISPATCH:
+			if (info->dscr & MV_NFC_UNCORR_ERR_INT) {
+				info->dscr = ERR_DBERR;
+				return 1;
+			}
+			break;
+
+		default:
+			break;
+	}
+
+	info->retcode = ERR_NONE;
+	return 0;
+}
+
+/* ==================================================================================================
+ *           STEP  1		|   STEP  2   |   STEP  3   |   STEP  4   |   STEP  5   |   STEP 6
+ *           COMMAND		|   WAIT FOR  |   CHK ERRS  |     PIO     |   WAIT FOR  |   CHK ERRS
+ * =========================|=============|=============|=============|=============|============
+ *   READ MONOLITHIC		|   RDDREQ    |   UNCERR    |    READ     |     NONE    |    NONE
+ *   READ NAKED				|   RDDREQ    |   UNCERR    |    READ     |     NONE    |    NONE
+ *   READ LAST NAKED		|   RDDREQ    |   UNCERR    |    READ     |     NONE    |    NONE
+ *   WRITE MONOLITHIC		|   WRDREQ    |    NONE     |    WRITE    |     RDY     |    BBD
+ *   WRITE DISPATCH START	|   CMDD      |    NONE     |    NONE     |     NONE    |    NONE
+ *   WRITE NAKED			|   WRDREQ    |    NONE     |    WRITE    |     PAGED   |    NONE
+ *   WRITE DISPATCH END		|   NONE      |    NONE     |    NONE     |     RDY     |    BBD
+ *   ERASE					|   NONE      |    NONE     |    NONE     |     RDY     |    BBD
+ *   READ ID				|   RDDREQ    |    NONE     |    READ     |     NONE    |    NONE
+ *   READ STAT				|   RDDREQ    |    NONE     |    READ     |     NONE    |    NONE
+ *   RESET					|   NONE      |    NONE     |    NONE     |     RDY     |    NONE
+ */
+static int orion_nfc_do_cmd_pio(struct orion_nfc_info *info)
+{
+	int timeout = CHIP_DELAY_TIMEOUT;
+	MV_STATUS status;
+	MV_U32	i, j, numCmds;
+	MV_U32 ndcr;
+
+	/* static allocation to avoid stack overflow */
+	static MV_NFC_MULTI_CMD descInfo[NFC_MAX_NUM_OF_DESCR];
+
+	/* Clear all status bits */
+	MV_REG_WRITE(NFC_STATUS_REG, NFC_SR_MASK);	
+	
+	NFC_DPRINT((PRINT_LVL "\nStarting PIO command %d (cs %d) - NDCR=0x%08x\n",
+				info->cmd, info->nfcCtrl.currCs, MV_REG_READ(NFC_CONTROL_REG)));
+
+	/* Build the chain of commands */
+	orion_nfc_cmd_prepare(info, descInfo, &numCmds);
+	NFC_DPRINT((PRINT_LVL "Prepared %d commands in sequence\n", numCmds));
+
+	/* Execute the commands */
+	for (i=0; i < numCmds; i++) {
+		/* Verify that command is supported in PIO mode */
+		if ((orion_nfc_cmd_info_lkup[descInfo[i].cmd].events_p1 == 0) &&
+		    (orion_nfc_cmd_info_lkup[descInfo[i].cmd].events_p2 == 0)) {
+			goto fail_stop;
+		}
+		
+		/* clear the return code */
+		info->dscr = 0;
+
+		/* STEP1: Initiate the command */
+		NFC_DPRINT((PRINT_LVL "About to issue Descriptor #%d (command %d, pageaddr 0x%x, length %d).\n", 
+			    i, descInfo[i].cmd, descInfo[i].pageAddr, descInfo[i].length));
+		if ((status = mvNfcCommandPio(&info->nfcCtrl, &descInfo[i], MV_FALSE)) != MV_OK) {
+			printk(KERN_ERR "mvNfcCommandPio() failed for command %d (%d).\n", descInfo[i].cmd, status);
+			goto fail_stop;
+		}
+		NFC_DPRINT((PRINT_LVL "After issue command %d (NDSR=0x%x)\n", descInfo[i].cmd, MV_REG_READ(NFC_STATUS_REG)));
+	
+		/* Check if command phase interrupts events are needed */
+		if (orion_nfc_cmd_info_lkup[descInfo[i].cmd].events_p1) {
+			/* Enable necessary interrupts for command phase */
+			NFC_DPRINT((PRINT_LVL "Enabling part1 interrupts (IRQs 0x%x)\n", orion_nfc_cmd_info_lkup[descInfo[i].cmd].events_p1));
+			mvNfcIntrSet(&info->nfcCtrl, orion_nfc_cmd_info_lkup[descInfo[i].cmd].events_p1, MV_TRUE);	
+			
+			/* STEP2: wait for interrupt */
+			if (!orion_nfc_wait_for_completion_timeout(info, timeout)) {
+				printk(KERN_ERR "command %d execution timed out (CS %d, NDCR=0x%x, NDSR=0x%x).\n",
+				       descInfo[i].cmd, info->nfcCtrl.currCs, MV_REG_READ(NFC_CONTROL_REG), MV_REG_READ(NFC_STATUS_REG));
+				info->retcode = ERR_CMD_TO;
+				goto fail_stop;
+			}
+		
+			/* STEP3: Check for errors */
+			if (orion_nfc_error_check(info)) {
+				NFC_DPRINT((PRINT_LVL "Command level errors (DSCR=%08x, retcode=%d)\n", info->dscr, info->retcode));
+				goto fail_stop;
+			}
+		}		
+				
+		/* STEP4: PIO Read/Write data if needed */
+		if (descInfo[i].numSgBuffs > 1)
+		{
+			for (j=0; j< descInfo[i].numSgBuffs; j++) {
+				NFC_DPRINT((PRINT_LVL "Starting SG#%d PIO Read/Write (%d bytes, R/W mode %d)\n", j, 
+					    descInfo[i].sgBuffSize[j], orion_nfc_cmd_info_lkup[descInfo[i].cmd].rw));
+				mvNfcReadWritePio(&info->nfcCtrl, descInfo[i].sgBuffAddrVirt[j], 
+						  descInfo[i].sgBuffSize[j], orion_nfc_cmd_info_lkup[descInfo[i].cmd].rw);
+			}
+		}
+		else {
+			NFC_DPRINT((PRINT_LVL "Starting nonSG PIO Read/Write (%d bytes, R/W mode %d)\n", 
+				    descInfo[i].length, orion_nfc_cmd_info_lkup[descInfo[i].cmd].rw));
+			mvNfcReadWritePio(&info->nfcCtrl, descInfo[i].virtAddr, 
+					  descInfo[i].length, orion_nfc_cmd_info_lkup[descInfo[i].cmd].rw);
+		}
+
+		/* check if data phase events are needed */
+		if (orion_nfc_cmd_info_lkup[descInfo[i].cmd].events_p2) {
+			/* Enable the RDY interrupt to close the transaction */
+			NFC_DPRINT((PRINT_LVL "Enabling part2 interrupts (IRQs 0x%x)\n", orion_nfc_cmd_info_lkup[descInfo[i].cmd].events_p2));
+			mvNfcIntrSet(&info->nfcCtrl, orion_nfc_cmd_info_lkup[descInfo[i].cmd].events_p2, MV_TRUE);			
+
+			/* STEP5: Wait for transaction to finish */
+			if (!orion_nfc_wait_for_completion_timeout(info, timeout)) {
+				printk(KERN_ERR "command %d execution timed out (NDCR=0x%08x, NDSR=0x%08x, NDECCCTRL=0x%08x)\n", descInfo[i].cmd, 
+						MV_REG_READ(NFC_CONTROL_REG), MV_REG_READ(NFC_STATUS_REG), MV_REG_READ(NFC_ECC_CONTROL_REG));
+				info->retcode = ERR_DATA_TO;
+				goto fail_stop;
+			}
+		
+			/* STEP6: Check for errors BB errors (in erase) */
+			if (orion_nfc_error_check(info)) {
+				NFC_DPRINT((PRINT_LVL "Data level errors (DSCR=0x%08x, retcode=%d)\n", info->dscr, info->retcode));
+				goto fail_stop;
+			}
+		}
+	
+		/* Fallback - in case the NFC did not reach the idle state */
+		ndcr = MV_REG_READ(NFC_CONTROL_REG);
+		if (ndcr & NFC_CTRL_ND_RUN_MASK) {
+			printk(KERN_DEBUG "WRONG NFC STAUS: command %d, NDCR=0x%08x, NDSR=0x%08x, NDECCCTRL=0x%08x)\n", 
+		       	info->cmd, MV_REG_READ(NFC_CONTROL_REG), MV_REG_READ(NFC_STATUS_REG), MV_REG_READ(NFC_ECC_CONTROL_REG));
+			MV_REG_WRITE(NFC_CONTROL_REG, (ndcr & ~NFC_CTRL_ND_RUN_MASK));
+		}
+	}
+
+	NFC_DPRINT((PRINT_LVL "Command done (NDCR=0x%08x, NDSR=0x%08x)\n", MV_REG_READ(NFC_CONTROL_REG), MV_REG_READ(NFC_STATUS_REG)));
+	info->retcode = ERR_NONE;	
+	
+	return 0;
+
+fail_stop:
+	ndcr = MV_REG_READ(NFC_CONTROL_REG);
+	if (ndcr & NFC_CTRL_ND_RUN_MASK) {
+		printk(KERN_ERR "WRONG NFC STAUS: command %d, NDCR=0x%08x, NDSR=0x%08x, NDECCCTRL=0x%08x)\n", 
+		       info->cmd, MV_REG_READ(NFC_CONTROL_REG), MV_REG_READ(NFC_STATUS_REG), MV_REG_READ(NFC_ECC_CONTROL_REG));
+		MV_REG_WRITE(NFC_CONTROL_REG, (ndcr & ~NFC_CTRL_ND_RUN_MASK));
+	}
+	mvNfcIntrSet(&info->nfcCtrl, 0xFFF, MV_FALSE);
+	udelay(10);
+	return -ETIMEDOUT;
+}
+
+static int orion_nfc_dev_ready(struct mtd_info *mtd)
+{
+	return (MV_REG_READ(NFC_STATUS_REG) & (NFC_SR_RDY0_MASK | NFC_SR_RDY1_MASK)) ? 1 : 0;
+}
+
+static inline int is_buf_blank(uint8_t *buf, size_t len)
+{
+	for (; len > 0; len--)
+		if (*buf++ != 0xff)
+			return 0;
+	return 1;
+}
+
+static void orion_nfc_cmdfunc(struct mtd_info *mtd, unsigned command,
+				int column, int page_addr)
+{
+	struct orion_nfc_info *info = (struct orion_nfc_info *)((struct nand_chip *)mtd->priv)->priv;
+	int ret = 0;
+
+	info->data_size = 0;
+	info->state = STATE_READY;
+	info->chained_cmd = 0;
+	info->retcode = ERR_NONE;
+
+	init_completion(&info->cmd_complete);
+
+	switch (command) {
+	case NAND_CMD_READOOB:
+		info->buf_count = mtd->writesize + mtd->oobsize;
+		info->buf_start = mtd->writesize + column;
+		info->cmd = MV_NFC_CMD_READ_MONOLITHIC;
+		info->column = column;
+		info->page_addr = page_addr;
+		if (prepare_read_prog_cmd(info, column, page_addr))
+			break;
+
+		if (info->use_dma)
+#ifdef CONFIG_MV_INCLUDE_PDM
+			orion_nfc_do_cmd_dma(info, MV_NFC_STATUS_RDY | NFC_SR_UNCERR_MASK);
+#else
+			printk(KERN_ERR "DMA mode not supported!\n");
+#endif
+		else
+			orion_nfc_do_cmd_pio(info);
+
+		/* We only are OOB, so if the data has error, does not matter */
+		if (info->retcode == ERR_DBERR)
+			info->retcode = ERR_NONE;
+		break;
+
+	case NAND_CMD_READ0:
+		info->buf_start = column;
+		info->buf_count = mtd->writesize + mtd->oobsize;
+		memset(info->data_buff, 0xff, info->buf_count);
+		info->cmd = MV_NFC_CMD_READ_MONOLITHIC;
+		info->column = column;
+		info->page_addr = page_addr;
+
+		if (prepare_read_prog_cmd(info, column, page_addr))
+			break;
+
+		if (info->use_dma)
+#ifdef CONFIG_MV_INCLUDE_PDM
+			orion_nfc_do_cmd_dma(info, MV_NFC_STATUS_RDY | NFC_SR_UNCERR_MASK);
+#else
+			printk(KERN_ERR "DMA mode not supported!\n");
+#endif
+		else
+			orion_nfc_do_cmd_pio(info);
+
+		if (info->retcode == ERR_DBERR) {
+			/* for blank page (all 0xff), HW will calculate its ECC as
+			 * 0, which is different from the ECC information within
+			 * OOB, ignore such double bit errors
+			 */
+			if (is_buf_blank(info->data_buff, mtd->writesize))
+				info->retcode = ERR_NONE;
+			else
+				printk(PRINT_LVL "%s: retCode == ERR_DBERR\n", __FUNCTION__);
+		}
+		break;
+	case NAND_CMD_SEQIN:
+		info->buf_start = column;
+		info->buf_count = mtd->writesize + mtd->oobsize;
+		memset(info->data_buff + mtd->writesize, 0xff, mtd->oobsize);
+
+		/* save column/page_addr for next CMD_PAGEPROG */
+		info->seqin_column = column;
+		info->seqin_page_addr = page_addr;
+		break;
+	case NAND_CMD_PAGEPROG:
+		info->column = info->seqin_column;
+		info->page_addr = info->seqin_page_addr;
+		info->cmd = MV_NFC_CMD_WRITE_MONOLITHIC;
+		if (prepare_read_prog_cmd(info,
+				info->seqin_column, info->seqin_page_addr)) {
+			printk(KERN_ERR "prepare_read_prog_cmd() failed.\n");
+			break;
+		}
+	
+		if (info->use_dma)
+#ifdef CONFIG_MV_INCLUDE_PDM
+			orion_nfc_do_cmd_dma(info, MV_NFC_STATUS_RDY);
+#else
+			printk(KERN_ERR "DMA mode not supported!\n");
+#endif
+		else
+			orion_nfc_do_cmd_pio(info);
+
+		break;
+	case NAND_CMD_ERASE1:
+		info->column = 0;
+		info->page_addr = page_addr;
+		info->cmd = MV_NFC_CMD_ERASE;
+
+		if (info->use_dma)
+#ifdef CONFIG_MV_INCLUDE_PDM
+			orion_nfc_do_cmd_dma(info, MV_NFC_STATUS_BBD | MV_NFC_STATUS_RDY);
+#else
+			printk(KERN_ERR "DMA mode not supported!\n");
+#endif
+		else
+			orion_nfc_do_cmd_pio(info);
+
+		break;
+	case NAND_CMD_ERASE2:
+		break;
+	case NAND_CMD_READID:
+	case NAND_CMD_STATUS:
+		info->buf_start = 0;
+		info->buf_count = (command == NAND_CMD_READID) ?
+				info->read_id_bytes : 1;
+		info->data_size = 8;
+		info->column = 0;
+		info->page_addr = 0;
+		info->cmd = (command == NAND_CMD_READID) ?
+			MV_NFC_CMD_READ_ID : MV_NFC_CMD_READ_STATUS;
+
+		if (info->use_dma)
+#ifdef CONFIG_MV_INCLUDE_PDM
+			orion_nfc_do_cmd_dma(info,MV_NFC_STATUS_RDY);
+#else
+			printk(KERN_ERR "DMA mode not supported!\n");
+#endif
+		else
+			orion_nfc_do_cmd_pio(info);
+
+		break;
+	case NAND_CMD_RESET:
+		info->column = 0;
+		info->page_addr = 0;
+		info->cmd = MV_NFC_CMD_RESET;
+
+		if (info->use_dma)
+#ifdef CONFIG_MV_INCLUDE_PDM
+			ret = orion_nfc_do_cmd_dma(info, MV_NFC_STATUS_CMDD);
+#else
+			printk(KERN_ERR "DMA mode not supported!\n");
+#endif
+		else
+			ret = orion_nfc_do_cmd_pio(info);
+
+		if (ret == 0) {
+			int timeout = 2;
+			uint32_t ndcr;
+
+			while (timeout--) {
+				if (MV_REG_READ(NFC_STATUS_REG) & (NFC_SR_RDY0_MASK | NFC_SR_RDY1_MASK))
+					break;
+				msleep(10);
+			}
+
+			ndcr = MV_REG_READ(NFC_CONTROL_REG);
+			MV_REG_WRITE(NFC_CONTROL_REG, ndcr & ~NFC_CTRL_ND_RUN_MASK);
+		}
+		break;
+	default:
+		printk(KERN_ERR "non-supported command.\n");
+		break;
+	}
+
+	if (info->retcode == ERR_DBERR) {
+		printk(KERN_ERR "double bit error @ page %08x (%d)\n",
+				page_addr, info->cmd);
+		info->retcode = ERR_NONE;
+	}
+}
+
+static uint8_t orion_nfc_read_byte(struct mtd_info *mtd)
+{
+	struct orion_nfc_info *info = (struct orion_nfc_info *)((struct nand_chip *)mtd->priv)->priv;
+	char retval = 0xFF;
+
+	if (info->buf_start < info->buf_count)
+		/* Has just send a new command? */
+		retval = info->data_buff[info->buf_start++];
+	return retval;
+}
+
+static u16 orion_nfc_read_word(struct mtd_info *mtd)
+{
+	struct orion_nfc_info *info = (struct orion_nfc_info *)((struct nand_chip *)mtd->priv)->priv;
+	u16 retval = 0xFFFF;
+
+	if (!(info->buf_start & 0x01) && info->buf_start < info->buf_count) {
+		retval = *((u16 *)(info->data_buff+info->buf_start));
+		info->buf_start += 2;
+	}
+	else
+		printk(KERN_ERR "\n%s: returning 0xFFFF (%d, %d).\n",__FUNCTION__, info->buf_start,info->buf_count);
+
+	return retval;
+}
+
+static void orion_nfc_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
+{
+	struct orion_nfc_info *info = (struct orion_nfc_info *)((struct nand_chip *)mtd->priv)->priv;
+	int real_len = min_t(size_t, len, info->buf_count - info->buf_start);
+
+	memcpy(buf, info->data_buff + info->buf_start, real_len);
+	info->buf_start += real_len;
+}
+
+static void orion_nfc_write_buf(struct mtd_info *mtd,
+		const uint8_t *buf, int len)
+{
+	struct orion_nfc_info *info = (struct orion_nfc_info *)((struct nand_chip *)mtd->priv)->priv;
+	int real_len = min_t(size_t, len, info->buf_count - info->buf_start);
+
+	memcpy(info->data_buff + info->buf_start, buf, real_len);
+	info->buf_start += real_len;
+}
+
+static int orion_nfc_verify_buf(struct mtd_info *mtd,
+		const uint8_t *buf, int len)
+{
+	return 0;
+}
+
+static void orion_nfc_select_chip(struct mtd_info *mtd, int chip)
+{
+	struct orion_nfc_info *info = (struct orion_nfc_info *)((struct nand_chip *)mtd->priv)->priv;
+	mvNfcSelectChip(&info->nfcCtrl, MV_NFC_CS_0 + chip);
+	return;
+}
+
+static int orion_nfc_waitfunc(struct mtd_info *mtd, struct nand_chip *this)
+{
+	struct orion_nfc_info *info = (struct orion_nfc_info *)((struct nand_chip *)mtd->priv)->priv;
+
+	/* orion_nfc_send_command has waited for command complete */
+	if (this->state == FL_WRITING || this->state == FL_ERASING) {
+		if (info->retcode == ERR_NONE)
+			return 0;
+		else {
+			/*
+			 * any error make it return 0x01 which will tell
+			 * the caller the erase and write fail
+			 */
+			return 0x01;
+		}
+	}
+
+	return 0;
+}
+
+static void orion_nfc_ecc_hwctl(struct mtd_info *mtd, int mode)
+{
+	return;
+}
+
+static int orion_nfc_ecc_calculate(struct mtd_info *mtd,
+		const uint8_t *dat, uint8_t *ecc_code)
+{
+	return 0;
+}
+
+static int orion_nfc_ecc_correct(struct mtd_info *mtd,
+		uint8_t *dat, uint8_t *read_ecc, uint8_t *calc_ecc)
+{
+	struct orion_nfc_info *info = (struct orion_nfc_info *)((struct nand_chip *)mtd->priv)->priv;
+	/*
+	 * Any error include ERR_SEND_CMD, ERR_DBERR, ERR_BUSERR, we
+	 * consider it as a ecc error which will tell the caller the
+	 * read fail We have distinguish all the errors, but the
+	 * nand_read_ecc only check this function return value
+	 */
+	if (info->retcode != ERR_NONE)
+		return -1;
+
+	return 0;
+}
+
+static int orion_nfc_detect_flash(struct orion_nfc_info *info)
+{
+	MV_U32 my_page_size;
+
+	mvNfcFlashPageSizeGet(&info->nfcCtrl, &my_page_size, NULL);
+
+	/* Translate page size to enum */
+	switch (my_page_size)
+	{
+		case 512:
+			info->page_size = NFC_PAGE_512B;
+			break;
+
+		case 2048:
+			info->page_size = NFC_PAGE_2KB;
+			break;
+
+		case 4096:
+			info->page_size = NFC_PAGE_4KB;
+			break;
+		
+		case 8192:
+			info->page_size = NFC_PAGE_8KB;
+			break;
+
+		case 16384:
+			info->page_size = NFC_PAGE_16KB;
+			break;
+
+		default:
+			return -EINVAL;
+	}
+
+	info->flash_width = info->nfc_width;
+	if (info->flash_width != 16 && info->flash_width != 8)
+		return -EINVAL;
+
+	/* calculate flash information */
+	info->read_id_bytes = (pg_sz[info->page_size] >= 2048) ? 4 : 2;
+
+	return 0;
+}
+
+/* the maximum possible buffer size for ganaged 8K page with OOB data
+ * is: 2 * (8K + Spare) ==> to be alligned allocate 5 MMU (4K) pages
+ */
+#define MAX_BUFF_SIZE	(PAGE_SIZE * 5)
+
+static int orion_nfc_init_buff(struct orion_nfc_info *info)
+{
+	struct platform_device *pdev = info->pdev;
+
+	if (info->use_dma == 0) {
+		info->data_buff = kmalloc(MAX_BUFF_SIZE, GFP_KERNEL);
+		if (info->data_buff == NULL)
+			return -ENOMEM;
+		return 0;
+	}
+
+	info->data_buff = dma_alloc_coherent(&pdev->dev, MAX_BUFF_SIZE,
+				&info->data_buff_phys, GFP_KERNEL);
+	if (info->data_buff == NULL) {
+		dev_err(&pdev->dev, "failed to allocate dma buffer\n");
+		return -ENOMEM;
+	}
+	memset(info->data_buff, 0xff, MAX_BUFF_SIZE);
+
+#ifdef CONFIG_MV_INCLUDE_PDM
+	if (pxa_request_dma_intr ("nand-data", info->nfcCtrl.dataChanHndl.chanNumber,
+			orion_nfc_data_dma_irq, info) < 0) {
+		dev_err(&pdev->dev, "failed to request PDMA IRQ\n");
+		return -ENOMEM;
+	}
+#endif
+	return 0;
+}
+
+static uint8_t mv_bbt_pattern[] = {'M', 'V', 'B', 'b', 't', '0' };
+static uint8_t mv_mirror_pattern[] = {'1', 't', 'b', 'B', 'V', 'M' };
+
+static struct nand_bbt_descr mvbbt_main_descr = {
+	.options = NAND_BBT_LASTBLOCK | NAND_BBT_CREATE | NAND_BBT_WRITE
+		| NAND_BBT_2BIT | NAND_BBT_VERSION,
+	.offs =	8,
+	.len = 6,
+	.veroffs = 14,
+	.maxblocks = 8,		/* Last 8 blocks in each chip */
+	.pattern = mv_bbt_pattern
+};
+
+static struct nand_bbt_descr mvbbt_mirror_descr = {
+	.options = NAND_BBT_LASTBLOCK | NAND_BBT_CREATE | NAND_BBT_WRITE
+		| NAND_BBT_2BIT | NAND_BBT_VERSION,
+	.offs =	8,
+	.len = 6,
+	.veroffs = 14,
+	.maxblocks = 8,		/* Last 8 blocks in each chip */
+	.pattern = mv_mirror_pattern
+};
+
+
+static int orion_nfc_markbad(struct mtd_info *mtd, loff_t ofs)
+{
+	struct nand_chip *chip = mtd->priv;
+	uint8_t buf[6] = {0, 0, 0, 0, 0, 0};
+	int block, ret = 0;
+	loff_t page_addr;
+
+	/* Get block number */
+	block = (int)(ofs >> chip->bbt_erase_shift);
+	if (chip->bbt)
+		chip->bbt[block >> 2] |= 0x01 << ((block & 0x03) << 1);
+	ret = nand_update_bbt(mtd, ofs);
+
+	if (ret == 0) {
+		/* Get address of the next block */
+		ofs += mtd->erasesize;
+		ofs &= ~(mtd->erasesize - 1);
+
+		/* Get start of oob in last page */
+		ofs -= mtd->oobsize;
+
+		page_addr = ofs;
+		do_div(page_addr, mtd->writesize);
+
+		orion_nfc_cmdfunc(mtd, NAND_CMD_SEQIN, mtd->writesize,
+				page_addr);
+		orion_nfc_write_buf(mtd, buf, 6);
+		orion_nfc_cmdfunc(mtd, NAND_CMD_PAGEPROG, 0, page_addr);
+	}
+
+	return ret;
+}
+
+
+static void orion_nfc_init_nand(struct nand_chip *nand, struct orion_nfc_info *info)
+{
+	
+	if (info->nfc_width == 16)
+		nand->options 	= (NAND_USE_FLASH_BBT | NAND_BUSWIDTH_16);
+	else
+		nand->options 	= NAND_USE_FLASH_BBT;
+	nand->num_devs		= info->num_devs;
+	nand->oobsize_ovrd	= ((CHUNK_SPR * CHUNK_CNT) + LST_CHUNK_SPR);
+	nand->bb_location	= BB_BYTE_POS;
+	nand->bb_page		= mvNfcBadBlockPageNumber(&info->nfcCtrl);
+	nand->waitfunc		= orion_nfc_waitfunc;
+	nand->select_chip	= orion_nfc_select_chip;
+	nand->dev_ready		= orion_nfc_dev_ready;
+	nand->cmdfunc		= orion_nfc_cmdfunc;
+	nand->read_word		= orion_nfc_read_word;
+	nand->read_byte		= orion_nfc_read_byte;
+	nand->read_buf		= orion_nfc_read_buf;
+	nand->write_buf		= orion_nfc_write_buf;
+	nand->verify_buf	= orion_nfc_verify_buf;
+	nand->block_markbad	= orion_nfc_markbad;
+	nand->ecc.mode		= NAND_ECC_HW;
+	nand->ecc.hwctl		= orion_nfc_ecc_hwctl;
+	nand->ecc.calculate	= orion_nfc_ecc_calculate;
+	nand->ecc.correct	= orion_nfc_ecc_correct;
+	nand->ecc.size		= pg_sz[info->page_size];
+	nand->ecc.layout	= ECC_LAYOUT;
+	nand->bbt_td 		= &mvbbt_main_descr;
+	nand->bbt_md 		= &mvbbt_mirror_descr;
+	nand->badblock_pattern	= BB_INFO;
+	nand->chip_delay 	= 25;
+}
+
+static int orion_nfc_probe(struct platform_device *pdev)
+{
+	struct nfc_platform_data *pdata;
+	struct orion_nfc_info *info;
+	struct nand_chip *nand;
+	struct mtd_info *mtd;
+	struct resource *r;
+	int nr_parts=0;
+	int ret = 0/*, irq*/;
+	char * stat[2] = {"Disabled", "Enabled"};
+	char * ecc_stat[] = {"Hamming", "BCH 4bit", "BCH 8bit", "BCH 12bit", "BCH 16bit", "No"};
+	MV_NFC_INFO nfcInfo;
+
+	pdata = dev_get_platdata(&pdev->dev);
+
+	if (!pdata) {
+		dev_err(&pdev->dev, "no platform data defined\n");
+		return -ENODEV;
+	}
+
+	dev_info(&pdev->dev, "Initialize HAL based NFC in %dbit mode with DMA %s using %s ECC\n",
+			  pdata->nfc_width, stat[pdata->use_dma], ecc_stat[pdata->ecc_type]);
+
+	/* Allocate all data: mtd_info -> nand_chip -> orion_nfc_info */
+	mtd = kzalloc(sizeof(struct mtd_info),	GFP_KERNEL);
+	if (!mtd) {
+		dev_err(&pdev->dev, "failed to allocate memory for mtd_info\n");
+		return -ENOMEM;
+	}
+
+	info = kzalloc(sizeof(struct orion_nfc_info), GFP_KERNEL);
+	if (!info) {
+		dev_err(&pdev->dev, "failed to allocate memory for orion_nfc_info\n");
+		return -ENOMEM;
+	}
+
+	nand = kzalloc(sizeof(struct nand_chip), GFP_KERNEL);
+	if (!nand) {
+		dev_err(&pdev->dev, "failed to allocate memory for nand_chip\n");
+		return -ENOMEM;
+	}
+
+	/* Hookup pointers */
+	info->pdev = pdev;
+	nand->priv = info;
+	mtd->priv = nand;
+	mtd->name = DRIVER_NAME;
+	mtd->owner = THIS_MODULE;
+
+	/* Copy all necessary information from platform data */
+	info->use_dma = pdata->use_dma;
+	info->ecc_type = pdata->ecc_type;
+	info->nfc_width = pdata->nfc_width;
+	info->num_devs = pdata->num_devs;
+	info->num_cs = pdata->num_cs;
+	info->tclk = pdata->tclk;
+#if 0
+	/* Get the TCLK */
+	info->clk = clk_get_sys("armada-nand", NULL);
+	if (IS_ERR(info->clk)) {
+		dev_err(&pdev->dev, "failed to get nand clock\n");
+		ret = PTR_ERR(info->clk);
+		goto fail_free_mtd;
+	}
+	clk_enable(info->clk);
+#endif
+#if 0
+	irq = platform_get_irq(pdev, 0);
+	if (irq < 0) {
+		dev_err(&pdev->dev, "no IRQ resource defined\n");
+		ret = -ENXIO;
+		goto fail_put_clk;
+	}
+#endif
+	r = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (r == NULL) {
+		dev_err(&pdev->dev, "no IO memory resource defined\n");
+		ret = -ENODEV;
+		goto fail_put_clk;
+	}
+
+	r = devm_request_mem_region(&pdev->dev, r->start, r->end - r->start + 1,
+				    pdev->name);
+	if (r == NULL) {
+		dev_err(&pdev->dev, "failed to request memory resource\n");
+		ret = -EBUSY;
+		goto fail_put_clk;
+	}
+
+	info->mmio_base = devm_ioremap(&pdev->dev, r->start,
+				       r->end - r->start + 1);
+	if (info->mmio_base == NULL) {
+		dev_err(&pdev->dev, "ioremap() failed\n");
+		ret = -ENODEV;
+		goto fail_put_clk;
+	}
+
+	info->mmio_phys_base = r->start;
+
+#ifdef CONFIG_MV_INCLUDE_PDMA
+	if (mvPdmaHalInit(MV_PDMA_MAX_CHANNELS_NUM) != MV_OK) {
+		dev_err(&pdev->dev, "mvPdmaHalInit() failed.\n");
+		goto fail_put_clk;
+	}
+#endif
+	/* Initialize NFC HAL */
+	nfcInfo.ioMode = (info->use_dma ? MV_NFC_PDMA_ACCESS : MV_NFC_PIO_ACCESS);
+	nfcInfo.eccMode = info->ecc_type;
+		
+	if(info->num_devs == 1)
+		nfcInfo.ifMode = ((info->nfc_width == 8) ? MV_NFC_IF_1X8 : MV_NFC_IF_1X16);
+	else
+		nfcInfo.ifMode = MV_NFC_IF_2X8;
+	nfcInfo.autoStatusRead = MV_FALSE;
+	nfcInfo.tclk = info->tclk;
+	nfcInfo.readyBypass = MV_FALSE;
+	nfcInfo.osHandle = NULL;
+	nfcInfo.regsPhysAddr = INTER_REGS_BASE;
+#ifdef CONFIG_MV_INCLUDE_PDMA
+	nfcInfo.dataPdmaIntMask = MV_PDMA_END_OF_RX_INTR_EN | MV_PDMA_END_INTR_EN;
+	nfcInfo.cmdPdmaIntMask = 0x0;
+#endif
+	if (mvNfcInit(&nfcInfo, &info->nfcCtrl) != MV_OK) {
+		dev_err(&pdev->dev, "mvNfcInit() failed.\n");
+		goto fail_put_clk;
+	}
+
+	mvNfcSelectChip(&info->nfcCtrl, MV_NFC_CS_0);
+	mvNfcIntrSet(&info->nfcCtrl,  0xFFF, MV_FALSE);
+	mvNfcSelectChip(&info->nfcCtrl, MV_NFC_CS_1);
+	mvNfcIntrSet(&info->nfcCtrl,  0xFFF, MV_FALSE);
+	mvNfcSelectChip(&info->nfcCtrl, MV_NFC_CS_NONE);
+
+	ret = orion_nfc_init_buff(info);
+	if (ret)
+		goto fail_put_clk;
+
+	/* Clear all old events on the status register */
+	MV_REG_WRITE(NFC_STATUS_REG, MV_REG_READ(NFC_STATUS_REG));
+	if (info->use_dma)
+#ifdef CONFIG_MV_INCLUDE_PDMA
+		ret = request_irq(IRQ_AURORA_NFC, orion_nfc_irq_dma, IRQF_DISABLED,
+				pdev->name, info);
+#else
+		printk(KERN_ERR "DMA mode not supported!\n");
+#endif
+	else
+		ret = request_irq(IRQ_AURORA_NFC, orion_nfc_irq_pio, IRQF_DISABLED,
+				pdev->name, info);
+
+	if (ret < 0) {
+		dev_err(&pdev->dev, "failed to request IRQ\n");
+		goto fail_free_buf;
+	}	
+
+	ret = orion_nfc_detect_flash(info);
+	if (ret) {
+		dev_err(&pdev->dev, "failed to detect flash\n");
+		ret = -ENODEV;
+		goto fail_free_irq;
+	}
+
+	orion_nfc_init_nand(nand, info);
+
+	if (nand->ecc.layout == NULL) {
+		dev_err(&pdev->dev, "Undefined ECC layout for selected nand device\n");
+		ret = -ENXIO;
+		goto fail_free_irq;
+	}
+
+	platform_set_drvdata(pdev, mtd);
+
+	if (nand_scan(mtd, info->num_cs)) {
+		dev_err(&pdev->dev, "failed to scan nand\n");
+		ret = -ENXIO;
+		goto fail_free_irq;
+	}
+	
+#ifdef CONFIG_MTD_CMDLINE_PARTS
+			static const char *probes[] = { "cmdlinepart", NULL };
+			struct mtd_partition *parts=NULL;
+
+			nr_parts = parse_mtd_partitions(mtd, probes, &parts, 0);
+
+#endif
+
+
+	if (nr_parts <= 0) {
+		nr_parts = pdata->nr_parts;
+		parts = pdata->parts;
+	}
+
+	return mtd_device_register(mtd, parts, nr_parts);
+
+
+fail_free_irq:
+	free_irq(IRQ_AURORA_NFC, info);
+fail_free_buf:
+	if (pdata->use_dma) {
+		dma_free_coherent(&pdev->dev, info->data_buff_size,
+			info->data_buff, info->data_buff_phys);
+	} else
+		kfree(info->data_buff);
+fail_put_clk:
+#if 0
+	clk_disable(info->clk);
+	clk_put(info->clk);
+fail_free_mtd:
+#endif
+	kfree(mtd);
+	kfree(nand);
+	kfree(info);
+	return ret;
+}
+
+static int orion_nfc_remove(struct platform_device *pdev)
+{
+	struct mtd_info *mtd = platform_get_drvdata(pdev);
+	struct orion_nfc_info *info = (struct orion_nfc_info *)((struct nand_chip *)mtd->priv)->priv;
+
+	platform_set_drvdata(pdev, NULL);
+
+	/*del_mtd_device(mtd);*/
+	 mtd_device_unregister(mtd);
+#ifdef CONFIG_MTD_PARTITIONS
+	del_mtd_partitions(mtd);
+#endif
+	free_irq(IRQ_AURORA_NFC, info);
+	if (info->use_dma) {
+		dma_free_writecombine(&pdev->dev, info->data_buff_size,
+				info->data_buff, info->data_buff_phys);
+	} else
+		kfree(info->data_buff);
+#if 0
+	clk_disable(info->clk);
+	clk_put(info->clk);
+#endif
+	kfree(mtd);
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int orion_nfc_suspend(struct platform_device *pdev, pm_message_t state)
+{
+#if 0 /* Code dropped because standby WoL does not power off the device */
+	struct mtd_info *mtd = (struct mtd_info *)platform_get_drvdata(pdev);
+	struct orion_nfc_info *info = (struct orion_nfc_info *)((struct nand_chip *)mtd->priv)->priv;
+
+	if (info->state != STATE_READY) {
+		dev_err(&pdev->dev, "driver busy, state = %d\n", info->state);
+		return -EAGAIN;
+	}
+#ifdef CONFIG_MV_INCLUDE_PDMA
+	/* Store PDMA registers.	*/
+	info->pdmaDataLen = 128;
+	mvPdmaUnitStateStore(info->pdmaUnitData, &info->pdmaDataLen);
+#endif
+	
+	/* Store NFC registers.	*/
+	info->nfcDataLen = 128;
+	mvNfcUnitStateStore(info->nfcUnitData, &info->nfcDataLen);
+#if 0
+	clk_disable(info->clk);
+#endif
+#endif
+	return 0;
+}
+
+static int orion_nfc_resume(struct platform_device *pdev)
+{
+#if 0  /* Code dropped because standby WoL does not power off the device */
+	struct mtd_info *mtd = (struct mtd_info *)platform_get_drvdata(pdev);
+	struct orion_nfc_info *info = (struct orion_nfc_info *)((struct nand_chip *)mtd->priv)->priv;
+	MV_U32	i;
+#if 0
+	clk_enable(info->clk);
+#endif
+	/* restore PDMA registers */
+	for(i = 0; i < info->pdmaDataLen; i+=2)
+		MV_REG_WRITE(info->pdmaUnitData[i], info->pdmaUnitData[i+1]);
+
+	/* Clear all NAND interrupts */
+	MV_REG_WRITE(NFC_STATUS_REG, MV_REG_READ(NFC_STATUS_REG));
+
+	/* restore NAND registers */
+	for(i = 0; i < info->nfcDataLen; i+=2)
+		MV_REG_WRITE(info->nfcUnitData[i], info->nfcUnitData[i+1]);
+#endif
+	return 0;
+}
+#else
+#define orion_nfc_suspend	NULL
+#define orion_nfc_resume	NULL
+#endif
+
+static struct platform_driver orion_nfc_driver = {
+	.driver = {
+		.name	= DRIVER_NAME,
+		.owner	= THIS_MODULE,
+	},
+	.probe		= orion_nfc_probe,
+	.remove		= orion_nfc_remove,
+	.suspend	= orion_nfc_suspend,
+	.resume		= orion_nfc_resume,
+};
+
+static int __init orion_nfc_init(void)
+{
+	return platform_driver_register(&orion_nfc_driver);
+}
+module_init(orion_nfc_init);
+
+static void __exit orion_nfc_exit(void)
+{
+	platform_driver_unregister(&orion_nfc_driver);
+}
+module_exit(orion_nfc_exit);
+
+MODULE_ALIAS(DRIVER_NAME);
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("ArmadaXP NAND controller driver");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_nfc.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_nfc.h
new file mode 100644
index 0000000..df1cdb1
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/nand_nfc.h
@@ -0,0 +1,36 @@
+#ifndef __ASM_ARCH_ORION_NFC_H
+#define __ASM_ARCH_ORION_NFC_H
+
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/partitions.h>
+#include "mvCommon.h"
+#include "mvOs.h"
+#ifdef MV_INCLUDE_PDMA
+#include "pdma/mvPdma.h"
+#endif
+#include "nfc/mvNfc.h"
+#include "nfc/mvNfcRegs.h"
+
+enum nfc_page_size
+{
+	NFC_PAGE_512B = 0,
+	NFC_PAGE_2KB,
+	NFC_PAGE_4KB,
+	NFC_PAGE_8KB,
+	NFC_PAGE_16KB,
+	NFC_PAGE_SIZE_MAX_CNT
+};
+
+struct nfc_platform_data {
+	unsigned int		tclk;		/* Clock supplied to NFC */
+	unsigned int		nfc_width;	/* Width of NFC 16/8 bits */
+	unsigned int		num_devs;	/* Number of NAND devices 
+						   (2 for ganged mode).   */
+	unsigned int		num_cs;		/* Number of NAND devices 
+						   chip-selects.	  */
+	unsigned int		use_dma;	/* Enable/Disable DMA 1/0 */
+	MV_NFC_ECC_MODE		ecc_type;
+	struct mtd_partition *	parts;
+	unsigned int		nr_parts;	
+};
+#endif /* __ASM_ARCH_ORION_NFC_H */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/sflash.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/sflash.c
new file mode 100644
index 0000000..b4da128
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_mtd/sflash.c
@@ -0,0 +1,419 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+********************************************************************************/
+
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/sched.h>
+#include <linux/errno.h>
+#include <linux/version.h>
+#include <linux/interrupt.h>
+#include <linux/mtd/map.h>
+#include <linux/mtd/mtd.h>
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "sflash/mvSFlash.h"
+#include "sflash/mvSFlashSpec.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+
+/*#define MTD_SFLASH_DEBUG*/
+
+#ifdef MTD_SFLASH_DEBUG
+#define DB(x)	x
+#else
+#define DB(x)
+#endif
+
+/* macros for interrupts enable/disable */
+#define sflash_disable_irqs(flags, sflash_in_irq)	\
+	sflash_in_irq = in_interrupt();			\
+	if(!sflash_in_irq)	 	 		\
+		local_irq_save(flags);	 
+
+#define sflash_enable_irqs(flags, sflash_in_irq)	\
+	if(!sflash_in_irq)				\
+		local_irq_restore(flags);	 
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+	typedef	uint32_t 	sflash_size_t;
+#else
+	typedef uint64_t	sflash_size_t;
+#endif
+
+/* Configuration options */
+static struct mtd_info *sflash_probe(struct map_info *map);
+static void sflash_destroy(struct mtd_info *mtd);
+static int sflash_read(struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, u_char *buf);
+static int sflash_write(struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, const u_char *buf);
+static int sflash_erase(struct mtd_info *mtd, struct erase_info *instr);
+static void sflash_sync(struct mtd_info *mtd);
+static int sflash_suspend(struct mtd_info *mtd);
+static void sflash_resume(struct mtd_info *mtd);
+static int sflash_lock (struct mtd_info *mtd, loff_t ofs, sflash_size_t len);
+static int sflash_unlock (struct mtd_info *mtd, loff_t ofs, sflash_size_t len);
+static int sflash_block_isbad (struct mtd_info *mtd, loff_t ofs);
+static int sflash_block_markbad (struct mtd_info *mtd, loff_t ofs);
+
+static struct mtd_chip_driver sflash_chipdrv = {
+	.probe		= sflash_probe,
+	.destroy	= sflash_destroy,
+	.name		= "sflash",
+	.module		= THIS_MODULE
+};
+
+
+static struct mtd_info *sflash_probe(struct map_info *map)
+{
+	struct mtd_info *mtd = NULL;
+	MV_SFLASH_INFO *sflash = NULL;
+	MV_ULONG flags = 0, sflash_in_irq = 0;
+
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+	if (MV_FALSE == mvSocUnitIsMappedToThisCpu(SPI_FLASH))
+	{
+		printk(KERN_INFO"SPI flash is not mapped to this CPU\n");
+		return -ENODEV;
+	}		
+#endif
+
+	DB(printk("\nINFO: entering %s",__FUNCTION__));
+
+	/* allocate the memory for the mtd_info */
+	mtd = kmalloc(sizeof(*mtd), GFP_KERNEL);
+	if(!mtd)
+	{
+		printk(KERN_NOTICE "\nERROR: %s - Failed to allocate memory for mtd structure",__FUNCTION__);
+		return NULL;
+	}
+
+	/* allocate memory for the sflash private structure */
+	sflash = kmalloc(sizeof(MV_SFLASH_INFO), GFP_KERNEL);
+	if(!sflash) 
+	{
+		printk(KERN_NOTICE "\nERROR: %s - Failed to allocate memory for sflash structure",__FUNCTION__);
+		kfree(mtd);
+		return NULL;
+	}
+		
+	/* clear both structures before usage */
+	memset(mtd, 0, sizeof(*mtd));
+	memset(sflash, 0, sizeof(*sflash));
+	    
+	DB(printk("\nINFO: %s - Base address %08x",__FUNCTION__, sflash->baseAddr));
+#ifdef CONFIG_ARCH_FEROCEON_ORION	
+	/* First check that SPI bus mode is configured to connect to an external SFlash */
+    if (mvCtrlSpiBusModeDetect() != MV_SPI_CONN_TO_EXT_FLASH)
+    {
+        printk(KERN_NOTICE "\nERROR: %s - SPI interface is not routed to external SPI flash!", __FUNCTION__);
+		kfree(mtd);
+		kfree(sflash);
+		return NULL;
+    }
+#endif
+	/* Try to detect the flash and initialize it over SPI */	
+	sflash->baseAddr         = map->phys;
+    sflash->index            = MV_INVALID_DEVICE_NUMBER; /* will be detected in init */	
+	sflash_disable_irqs(flags, sflash_in_irq);	
+	if (mvSFlashInit(sflash) != MV_OK)
+	{
+		sflash_enable_irqs(flags, sflash_in_irq);
+		printk(KERN_NOTICE "ERROR: %s - Failed to initialize the SFlash.", __FUNCTION__);
+		kfree(mtd);
+		kfree(sflash);
+		return NULL;
+	}
+	sflash_enable_irqs(flags, sflash_in_irq);
+	
+	/* After success fill in the MTD structure with the appropriate info */
+	mtd->erasesize = sflash->sectorSize;
+	mtd->size = sflash->sectorSize * sflash->sectorNumber;
+	mtd->priv = map; /*sflash;*/
+	mtd->type = MTD_NORFLASH;
+	mtd->erase = sflash_erase;
+	mtd->read = sflash_read;
+	mtd->write = sflash_write;
+	mtd->sync = sflash_sync;
+	mtd->suspend = sflash_suspend;
+	mtd->resume = sflash_resume;	
+	mtd->lock = sflash_lock;
+	mtd->unlock = sflash_unlock;
+	mtd->block_isbad = sflash_block_isbad;
+	mtd->block_markbad = sflash_block_markbad;	
+	mtd->flags = (MTD_WRITEABLE | MTD_BIT_WRITEABLE); /* just like MTD_CAP_NORFLASH */
+	mtd->name = map->name;
+	mtd->writesize = 1;
+	
+	map->fldrv = &sflash_chipdrv;
+	map->fldrv_priv = sflash;
+	
+	/* Print some debug messages with the detected sflash info */
+	DB(printk("\nINFO: %s - Detected SFlash device (size %d)", __FUNCTION__, mtd->size));
+	DB(printk("\n           Base Address    : 0x%08x", sflash->baseAddr));
+	DB(printk("\n           Manufacturer ID : 0x%02x", sflash->manufacturerId));
+	DB(printk("\n           Device ID       : 0x%04x", sflash->deviceId));
+	DB(printk("\n           Sector Size     : 0x%x", sflash->sectorSize));
+	DB(printk("\n           Sector Number   : %d", sflash->sectorNumber));
+	
+	printk("SPI Serial flash detected @ 0x%08x, %dKB (%dsec x %dKB)\n",
+	         sflash->baseAddr, ((sflash->sectorNumber * sflash->sectorSize)/1024), 
+	         sflash->sectorNumber, (sflash->sectorSize/1024));
+	
+	__module_get(THIS_MODULE);
+	return mtd;
+}
+
+static void sflash_destroy(struct mtd_info *mtd)
+{
+	struct map_info *map = mtd->priv;
+	MV_SFLASH_INFO *sflash = map->fldrv_priv;
+
+	DB(printk("\nINFO: %s called", __FUNCTION__));
+
+	/* free memory allocated at probe for the private sflash structure */
+	if (sflash)
+		kfree(sflash);	
+}
+
+static int sflash_read(struct mtd_info *mtd, loff_t from, size_t len,
+	size_t *retlen, u_char *buf)
+{
+	struct map_info *map = mtd->priv;
+	MV_SFLASH_INFO *sflash = map->fldrv_priv;
+	MV_U32 offset = ((MV_U32)from);
+	MV_ULONG flags = 0, sflash_in_irq = 0;
+
+	
+	*retlen = 0;
+
+	DB(printk("\nINFO: %s  - offset %08x, len %d",__FUNCTION__, offset, (int)len));
+
+	sflash_disable_irqs(flags, sflash_in_irq);
+	if (mvSFlashBlockRd(sflash, offset, buf, len) != MV_OK)
+	{
+		sflash_enable_irqs(flags, sflash_in_irq);
+		printk(KERN_NOTICE "\nERROR: %s - Failed to read block.", __FUNCTION__);
+		return -1;
+	}
+	sflash_enable_irqs(flags, sflash_in_irq);
+	
+	*retlen = len;
+	
+	DB(printk(" - OK"));
+	return 0;	
+}
+
+static int sflash_write(struct mtd_info *mtd, loff_t to, size_t len,
+	size_t *retlen, const u_char *buf)
+{
+	struct map_info *map = mtd->priv;
+	MV_SFLASH_INFO *sflash = map->fldrv_priv;
+/*	MV_SFLASH_INFO *sflash = mtd->priv;*/
+	MV_U32 offset = ((MV_U32)to);
+	MV_ULONG flags = 0, sflash_in_irq = 0;
+	
+	*retlen = 0;
+	
+	DB(printk("\nINFO: %s - offset %08x, len %d",__FUNCTION__, offset, len));
+		
+	sflash_disable_irqs(flags, sflash_in_irq);
+	if (mvSFlashBlockWr(sflash, offset, (MV_U8*)buf, len) != MV_OK)
+	{
+		sflash_enable_irqs(flags, sflash_in_irq);
+		printk(KERN_NOTICE "\nERROR: %s - Failed to write block", __FUNCTION__);
+		return -1;
+	}
+	sflash_enable_irqs(flags, sflash_in_irq);
+	
+	*retlen = len;
+	
+	DB(printk(" - OK"));
+	return 0;	
+
+}
+
+
+static int sflash_erase(struct mtd_info *mtd, struct erase_info *instr)
+{
+	struct map_info *map = mtd->priv;
+	MV_SFLASH_INFO *sflash = map->fldrv_priv;
+/*	MV_SFLASH_INFO *sflash = mtd->priv;*/
+	MV_U32 fsec, lsec;
+	int i;
+	MV_ULONG flags = 0, sflash_in_irq = 0;
+
+	DB(printk("\nINFO: %s - Addr %08x, len %d",__FUNCTION__, instr->addr, instr->len));
+	
+	if(instr->addr & (mtd->erasesize - 1))
+	{
+		printk(KERN_NOTICE "\nError: %s - Erase address not sector alligned",__FUNCTION__);
+		return -EINVAL;
+	}
+	if(instr->len & (mtd->erasesize - 1))
+	{
+		printk(KERN_NOTICE "\nError: %s - Erase length is not sector alligned",__FUNCTION__);
+		return -EINVAL;
+	}
+	if(instr->len + instr->addr > mtd->size)
+	{
+		printk(KERN_NOTICE "\nError: %s - Erase exceeded flash size",__FUNCTION__);
+		return -EINVAL;
+	}
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+	fsec = (instr->addr / mtd->erasesize);
+	lsec = (fsec +(instr->len / mtd->erasesize));
+#else
+	fsec = instr->addr;
+	do_div(fsec, mtd->erasesize);
+	lsec = instr->len;
+	do_div(lsec, mtd->erasesize);
+	lsec = (fsec + lsec);
+#endif
+
+	DB(printk("\nINFO: %s - from sector %u to %u",__FUNCTION__, fsec, 
+		  lsec-1));
+	
+	sflash_disable_irqs(flags, sflash_in_irq);
+	for (i=fsec; i<lsec; i++)
+	{
+		if (mvSFlashSectorErase(sflash, i) != MV_OK)
+		{
+			sflash_enable_irqs(flags, sflash_in_irq);
+			printk(KERN_NOTICE "\nError: %s - mvSFlashSectorErase on sector %d",__FUNCTION__, i);
+			return -1;
+		}
+	}
+	sflash_enable_irqs(flags, sflash_in_irq);
+	
+	instr->state = MTD_ERASE_DONE;
+	mtd_erase_callback(instr);
+
+	return 0;
+}
+
+static int sflash_lock (struct mtd_info *mtd, loff_t ofs, sflash_size_t len)
+{
+	struct map_info *map = mtd->priv;
+	MV_SFLASH_INFO *sflash = map->fldrv_priv;
+	MV_ULONG flags = 0, sflash_in_irq = 0;
+/*	MV_SFLASH_INFO *sflash = mtd->priv;*/
+	
+	DB(printk("\nINFO: %s called", __FUNCTION__));
+	
+	sflash_disable_irqs(flags, sflash_in_irq);
+	if (mvSFlashWpRegionSet(sflash, MV_WP_ALL) != MV_OK)
+	{
+		sflash_enable_irqs(flags, sflash_in_irq);
+		printk(KERN_NOTICE "\nError: %s - mvSFlashWpRegionSet failed",__FUNCTION__);
+		return -1;
+	}
+	sflash_enable_irqs(flags, sflash_in_irq);
+	
+	printk("\nNotice: Serial SPI flash (%s) lock per sector is not supported!\n        Locking the whole device.", mtd->name);
+		
+	return 0;
+}
+
+static int sflash_unlock (struct mtd_info *mtd, loff_t ofs, sflash_size_t len)
+{
+	struct map_info *map = mtd->priv;
+	MV_SFLASH_INFO *sflash = map->fldrv_priv;
+	MV_ULONG flags = 0, sflash_in_irq = 0;
+/*	MV_SFLASH_INFO *sflash = mtd->priv;*/
+
+	DB(printk("\nINFO: %s called", __FUNCTION__));
+	
+	sflash_disable_irqs(flags, sflash_in_irq);
+	if (mvSFlashWpRegionSet(sflash, MV_WP_NONE) != MV_OK)
+	{
+		sflash_enable_irqs(flags, sflash_in_irq);
+		printk(KERN_NOTICE "\nError: %s - mvSFlashWpRegionSet failed",__FUNCTION__);
+		return -1;
+	}
+	sflash_enable_irqs(flags, sflash_in_irq);
+		
+	printk("\nNotice: Serial SPI flash (%s) unlock per sector is not supported!\n        Unlocking the whole device.", mtd->name);
+	return 0;
+}
+
+static void sflash_sync(struct mtd_info *mtd)
+{
+	DB(printk("\nINFO: %s called - DUMMY", __FUNCTION__));
+}
+
+static int sflash_suspend(struct mtd_info *mtd)
+{
+	DB(printk("\nINFO: %s called - DUMMY()", __FUNCTION__));
+	return 0;
+}
+
+static void sflash_resume(struct mtd_info *mtd)
+{
+	DB(printk("\nINFO: %s called - DUMMY", __FUNCTION__));
+}
+
+static int sflash_block_isbad (struct mtd_info *mtd, loff_t ofs)
+{
+	DB(printk("\nINFO: %s called - DUMMY", __FUNCTION__));
+	return 0;
+}
+
+static int sflash_block_markbad (struct mtd_info *mtd, loff_t ofs)
+{
+	DB(printk("\nINFO: %s called - DUMMY", __FUNCTION__));
+	return 0;
+}
+
+static int __init sflash_probe_init(void)
+{
+	DB(printk("\nINFO: %s - MTD SFlash chip driver.\n", __FUNCTION__));
+
+	register_mtd_chip_driver(&sflash_chipdrv);
+
+	return 0;
+}
+
+static void __exit sflash_probe_exit(void)
+{
+	DB(printk(KERN_ALERT "\nINFO: %s - MTD SFlash driver exit", __FUNCTION__));
+	unregister_mtd_chip_driver(&sflash_chipdrv);
+}
+
+subsys_initcall(sflash_probe_init);
+//module_exit(sflash_probe_exit);
+
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_DESCRIPTION("MTD chip driver for the SPI serial flash device");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/Kconfig
new file mode 100644
index 0000000..9d4b634
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/Kconfig
@@ -0,0 +1,819 @@
+config MV_ETH_PORTS_NUM
+	int "Number of Marvell GbE ports"
+	depends on MV_ETH_NETA
+	default 1 
+
+config MV_ETH_MTU_PKT_MULT
+        int "Multiplier for number of buffers of MTU size pool"
+        default 3
+        ---help---
+        Number of buffers allocated for MTU size pool for each port calculated as:
+        MV_ETH_RXQ * MV_ETH_RXQ_DESC * MV_ETH_MTU_PKT_MULT
+
+menu "BM configuration"
+
+config MV_ETH_BM
+	depends on MV_ETH_NETA
+        bool "Buffer Management support (BM)"
+	default y
+        ---help---
+
+config MV_ETH_BM_CPU
+        depends on MV_ETH_BM
+        bool "Use BM for CPU processed traffic"
+        default y
+        ---help---
+	BM pools is used for traffic processed by CPU and HWF both
+
+config MV_ETH_SHORT_PKT_SIZE    
+	depends on MV_ETH_BM
+	int "Buffer size for short packets pool"
+	default 256
+	---help---
+	Size of buffers allocated for short packets pool
+
+config MV_ETH_SHORT_PKT_MULT
+        depends on MV_ETH_BM
+        int "Multiplier for number of buffers of short size pool"
+        default 5
+        ---help---
+        Number of buffers allocated for short size pool for each port calculated as:
+	MV_ETH_RXQ * MV_ETH_RXQ_DESC * MV_ETH_SHORT_PKT_MULT
+
+config MV_ETH_POOL_PREDEFINED
+	depends on MV_ETH_BM
+	bool "Use predefined MTU size values for long pools"
+	default n
+	---help---
+
+config MV_ETH_POOL_0_MTU
+        depends on MV_ETH_POOL_PREDEFINED
+        int "MTU value match for buffers in pool #0"
+        default 1500
+        ---help---
+	Giga port with MTU less or equal to MV_ETH_POOL_0_MTU can use pool0
+	as its long packets pool
+
+config MV_ETH_POOL_1_MTU
+        depends on MV_ETH_POOL_PREDEFINED
+        int "MTU value match for buffers in pool #1"
+        default 4096
+        ---help---
+        Giga port with MTU less or equal to MV_ETH_POOL_1_MTU can use pool1
+        as its long packets pool
+	
+config MV_ETH_POOL_2_MTU
+        depends on MV_ETH_POOL_PREDEFINED
+        int "MTU value match for buffers in pool #2"
+        default 9192
+        ---help---
+        Giga port with MTU less or equal to MV_ETH_POOL_2_MTU can use pool2
+        as its long packets pool
+
+endmenu
+
+config MV_ETH_LEGACY_PARSER
+	depends on !MV_ETH_PNC
+	bool "Use legacy parser for incoming traffic"
+	default y
+	---help---
+
+menuconfig MV_ETH_PNC
+        depends on MV_ETH_NETA
+        bool "PnC support "
+	default y
+        ---help---
+
+config MV_PNC_TCAM_LINES
+        depends on MV_ETH_PNC
+        int "Number of TCAM lines supported by PNC"
+        default 512
+        ---help---
+
+config MV_ETH_PNC_PARSER
+	depends on MV_ETH_PNC
+	bool "Use PnC as parser for incoming traffic"
+	default y
+	---help---
+
+config MV_ETH_PNC_MCAST_NUM
+        depends on MV_ETH_PNC_PARSER
+        int "Use PnC for Multicast MAC addresses filtering"
+        default 8
+        ---help---
+	Number of Multicast addresses can be matched and accepted 
+	for all ports
+
+config MV_ETH_PNC_VLAN_PRIO
+        depends on MV_ETH_PNC_PARSER
+        int "Use PnC for VLAN priority mapping"
+        default 1
+        ---help---
+	Number of VLAN priorities can be mapped to different RXQs.
+	Valid range from 1 to 8.
+
+config MV_ETH_PNC_SNAP
+        depends on MV_ETH_PNC_PARSER
+        bool "Use PnC for SNAP packets detection"
+        default n
+        ---help---
+
+config MV_ETH_PNC_ETYPE
+        depends on MV_ETH_PNC_PARSER
+        int "Use PnC for extra ETYPE detection"
+        default 0
+        ---help---
+        Number of extra ETYPEs can be detected in addition to 
+	ARP, IPv4, IPv6, PPPoE are detected by default.
+
+config MV_ETH_PNC_DSCP_PRIO
+        depends on MV_ETH_PNC_PARSER
+        int "Use PnC for DSCP priority mapping"
+        default 4
+        ---help---
+        Number of DSCP priorities can be mapped to different RXQs.
+        Valid range from 1 to 8.
+
+config MV_ETH_PNC_WOL
+	depends on MV_ETH_PNC_PARSER
+	bool "Use PNC for Wake On LAN support"
+	default n
+	---help---
+	Use PNC rules for TCAM filtering for Wake on LAN support.
+	When enabled, MV_ETH_NFP_PNC will be disabled.
+
+menuconfig MV_ETH_HWF
+	depends on (MV_ETH_PNC && MV_ETH_BM)
+        bool "Hardware Forwarding support (HWF)"
+        default y
+        ---help---
+
+menuconfig  MV_ETH_HWF_0_BM
+	depends on (MV_ETH_HWF && !MV_ETH_BM_CPU && (MV_ETH_PORTS_NUM != 0))
+	bool "BM configuration for GbE #0"
+	default y
+	---help---
+
+config  MV_ETH_HWF_0_BM_LONG_POOL
+        int "Long BM pool for GbE #0"
+        depends on MV_ETH_HWF_0_BM
+        range 0 3
+        default 0
+        ---help---
+	BM pool to be used for GbE #0 port to process long packets via HWF only
+
+config  MV_ETH_HWF_0_BM_SHORT_POOL
+        int "Short BM pool for GbE #0"
+        depends on MV_ETH_HWF_0_BM
+        range 0 3
+        default 1
+        ---help---
+	BM pool to be used for GbE #0 port to process short packets via HWF only
+	If BM pool for short packets set to the same as pool for long packets 
+	only one (long) pool will be used for this port
+
+config  MV_ETH_HWF_0_BM_LONG_BUF_NUM
+        int "Number of buffers for Long pool of GbE #0"
+        depends on MV_ETH_HWF_0_BM
+        range 128 16384
+        default 2048
+        ---help---
+
+config  MV_ETH_HWF_0_BM_SHORT_BUF_NUM
+        int "Number of buffers for Short pool of GbE #0"
+        depends on MV_ETH_HWF_0_BM && (MV_ETH_HWF_0_BM_SHORT_POOL != MV_ETH_HWF_0_BM_LONG_POOL)
+        range 128 16384
+        default 4096
+        ---help---
+
+config  MV_ETH_HWF_0_BM_SHORT_BUF_SIZE
+        int "Size of buffers for Short pool of GbE #0"
+        depends on MV_ETH_HWF_0_BM && (MV_ETH_HWF_0_BM_SHORT_POOL != MV_ETH_HWF_0_BM_LONG_POOL)
+        range 128 1024
+        default 256
+        ---help---
+
+menuconfig  MV_ETH_HWF_1_BM
+        depends on (MV_ETH_HWF && !MV_ETH_BM_CPU && (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1))
+        bool "BM configuration for GbE #1"
+        default y
+        ---help---
+
+config  MV_ETH_HWF_1_BM_LONG_POOL
+	depends on MV_ETH_HWF_1_BM
+        int "Long BM pool for GbE #1"
+        range 0 3
+        default 0
+        ---help---
+        BM pool to be used for GbE #1 port to process long packets via HWF only
+
+config  MV_ETH_HWF_1_BM_SHORT_POOL
+	depends on MV_ETH_HWF_1_BM
+        int "Short BM pool for GbE #1"
+        range 0 3
+        default 1
+        ---help---
+        BM pool to be used for GbE #1 port to process short packets via HWF only
+        If BM pool for short packets set to the same as pool for long packets
+        only one (long) pool will be used for this port
+
+config  MV_ETH_HWF_1_BM_LONG_BUF_NUM
+        int "Number of buffers for Long pool of GbE #1"
+        depends on MV_ETH_HWF_1_BM
+        range 128 16384
+        default 2048
+        ---help---
+
+config  MV_ETH_HWF_1_BM_SHORT_BUF_NUM
+        int "Number of buffers for Short pool of GbE #1"
+        depends on MV_ETH_HWF_1_BM && (MV_ETH_HWF_1_BM_SHORT_POOL != MV_ETH_HWF_1_BM_LONG_POOL)
+        range 128 16384
+        default 4096
+        ---help---
+
+config  MV_ETH_HWF_1_BM_SHORT_BUF_SIZE
+        int "Size of buffers for Short pool of GbE #1"
+        depends on MV_ETH_HWF_1_BM && (MV_ETH_HWF_1_BM_SHORT_POOL != MV_ETH_HWF_1_BM_LONG_POOL)
+        range 128 1024
+        default 256
+        ---help---
+
+menuconfig  MV_ETH_HWF_2_BM
+        depends on (MV_ETH_HWF && !MV_ETH_BM_CPU && (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1) && (MV_ETH_PORTS_NUM != 2))
+        bool "BM configuration for GbE #2"
+        default y
+        ---help---
+
+config  MV_ETH_HWF_2_BM_LONG_POOL
+        depends on MV_ETH_HWF_2_BM
+        int "Long BM pool for GbE #2"
+        range 0 3
+        default 2
+        ---help---
+        BM pool to be used for GbE #2 port to process long packets via HWF only
+
+config  MV_ETH_HWF_2_BM_SHORT_POOL
+        depends on MV_ETH_HWF_2_BM
+        int "Short BM pool for GbE #2"
+        range 0 3
+        default 3
+        ---help---
+        BM pool to be used for GbE #2 port to process short packets via HWF only
+        If BM pool for short packets set to the same as pool for long packets
+        only one (long) pool will be used for this port
+
+config  MV_ETH_HWF_2_BM_LONG_BUF_NUM
+        int "Number of buffers for Long pool of GbE #2"
+        depends on MV_ETH_HWF_2_BM
+        range 128 16384
+        default 2048
+        ---help---
+
+config  MV_ETH_HWF_2_BM_SHORT_BUF_NUM
+        int "Number of buffers for Short pool of GbE #2"
+        depends on MV_ETH_HWF_2_BM && (MV_ETH_HWF_2_BM_SHORT_POOL != MV_ETH_HWF_2_BM_LONG_POOL)
+        range 128 16384
+        default 4096
+        ---help---
+
+config  MV_ETH_HWF_2_BM_SHORT_BUF_SIZE
+        int "Size of buffers for Short pool of GbE #2"
+        depends on MV_ETH_HWF_2_BM && (MV_ETH_HWF_2_BM_SHORT_POOL != MV_ETH_HWF_2_BM_LONG_POOL)
+        range 128 1024
+        default 256
+        ---help---
+
+config MV_ETH_HWF_TXQ_DROP
+	depends on MV_ETH_HWF
+	int "HWF Drop Threshold [%]"
+	default 60
+	---help---
+
+config MV_ETH_HWF_TXQ_DROP_RND
+        depends on MV_ETH_HWF
+        int "HWF Drop Random Generator bits"
+        default 0
+        ---help---
+
+config MV_ETH_PMT
+        depends on MV_ETH_NETA
+        bool "Packet Modification Table (PMT)"
+        default y
+        ---help---
+
+menu "Network Interface configuration"
+
+config  MV_ETH_0_MTU
+	int "Giga port #0 MTU value"
+	depends on (MV_ETH_PORTS_NUM != 0)
+ 	default 1500
+        ---help---
+	Default MTU value for Marvell GbE port #0
+
+config  MV_ETH_0_MACADDR
+        string "Giga port #0 MAC address"
+        depends on (MV_ETH_PORTS_NUM != 0)
+        default "00:00:00:00:00:80"
+        ---help---
+        Default MAC address for Marvell GbE port #0 
+
+config  MV_ETH_1_MTU
+        int "Giga port #1 MTU value"
+        depends on (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1)
+        default 1500
+        ---help---
+	Default MTU value for Marvell GbE port #1
+
+config  MV_ETH_1_MACADDR
+        string "Giga port #1 MAC address"
+        depends on (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1)
+        default "00:00:00:00:00:81"
+        ---help---
+        Default MAC address for Marvell GbE port #1
+
+config  MV_ETH_2_MTU
+        int "Giga port #2 MTU value"
+        depends on (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1) && (MV_ETH_PORTS_NUM != 2)
+        default 1500
+        ---help---
+        Default MTU value for Marvell GbE port #2
+
+config  MV_ETH_2_MACADDR
+        string "Giga port #2 MAC address"
+        depends on (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1) && (MV_ETH_PORTS_NUM != 2)
+        default "00:00:00:00:00:82"
+        ---help---
+        Default MAC address for Marvell GbE port #2
+
+config  MV_ETH_3_MTU
+        int "Giga port #3 MTU value"
+        depends on (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1) && (MV_ETH_PORTS_NUM != 2) && (MV_ETH_PORTS_NUM != 3)
+        default 1500
+        ---help---
+        Default MTU value for Marvell GbE port #3
+
+config  MV_ETH_3_MACADDR
+        string "Giga port #3 MAC address"
+        depends on (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1) && (MV_ETH_PORTS_NUM != 2) && (MV_ETH_PORTS_NUM != 3)
+        default "00:00:00:00:00:83"
+        ---help---
+        Default MAC address for Marvell GbE port #3
+
+endmenu
+
+menu "Rx/Tx Queue configuration"
+
+config  MV_ETH_RXQ
+        int "Number of RX queues"
+        default 1
+        ---help---
+          Multiple RX queue support.
+
+config  MV_ETH_TXQ
+        int "Number of TX queues"
+        default 1
+        ---help---
+          Multiple TX queue support.
+
+config MV_ETH_RXQ_DESC
+	int "Number of Rx descriptors"
+	depends on (MV_ETH_PORTS_NUM != 0)
+	default 128
+        ---help---
+	The number of Rx descriptors in each Rx queue.
+
+config MV_ETH_RXQ_DEF
+        int "Default RXQ to recieve packets"
+        default 0
+        ---help---
+
+config MV_ETH_TXQ_DESC
+	int "Number of Tx descriptors"
+	depends on (MV_ETH_PORTS_NUM != 0)
+	default 532
+        ---help---
+	The number of Tx descriptors in each Tx queue.
+
+config MV_ETH_TXQ_DEF
+        int "Default TXQ to send local generated packets"
+        default 0
+        ---help---
+
+endmenu
+
+menu "IP/TCP/UDP Offloading"
+
+config  MV_ETH_TX_CSUM_OFFLOAD
+        bool "L3/L4 TX checksum offload support for Marvell network interface"
+        default y
+        ---help---
+	Marvell network driver compiled with TCP/UDP over IPv4/IPv6 TX checksum offload support.
+
+config MV_ETH_TX_CSUM_OFFLOAD_DEF
+	depends on MV_ETH_TX_CSUM_OFFLOAD
+        bool "Default value for L3/L4 TX checksum offload: enable/disable"
+        default y
+        ---help---
+	Can be changed in run-time using ethtool
+
+config  MV_ETH_RX_CSUM_OFFLOAD
+        bool "L3/L4 RX checksum offload support for Marvell network interface"
+        default y
+        ---help---
+        Marvell network driver compiled with TCP/UDP over IPv4/IPv6 RX checksum offload support.
+
+config MV_ETH_RX_CSUM_OFFLOAD_DEF
+	depends on MV_ETH_RX_CSUM_OFFLOAD
+        bool "Default value for L3/L4 RX checksum offload: enable/disable"
+        default y
+        ---help---
+	Can be changed in run-time using ethtool
+
+config  MV_ETH_GRO
+        bool "GRO Support for Marvell network interface"
+	default y
+        ---help---
+        Marvell network driver compiled with GRO (Generic Receive Offload) support.
+		
+config  MV_ETH_GRO_DEF
+	depends on MV_ETH_GRO
+        bool "Default value for GRO feature: enable/disable"
+	default y
+        ---help---
+        Can be changed in run-time using ethtool
+		
+config  MV_ETH_TSO
+        bool "TSO Support for Marvell network interface"
+	default y
+        ---help---
+        Marvell network driver compiled with TSO (TCP Segmentation Offload) support.
+
+config  MV_ETH_TSO_DEF
+	depends on MV_ETH_TSO
+        bool "Default value for TSO feature: enable/disable"
+	default n
+        ---help---
+	Can be changed in run-time using ethtool
+
+endmenu
+
+menu "Control and Statistics"
+
+config  MV_ETH_PROC
+	bool "Support procfs"
+	default y
+	---help---
+	  Use mv_eth_tool to control Marvell network interface driver through procfs.
+
+config  MV_ETH_DEBUG_CODE
+	bool "Add run-time debug code"
+	default n
+	---help---
+	Enable run-time enable/disable enter debug code blocks
+
+config  MV_ETH_STAT_ERR
+        bool "Collect error statistics"
+        default y
+	---help---
+	Marvell network interface driver collect minimal number of statistics. 
+	Only for error conditions. Can be displayed using mv_eth_tool.
+
+config  MV_ETH_STAT_INF
+        bool "Collect event statistics"
+        default y
+        ---help---
+	Marvell network interface driver collect event statistics. 
+	Provide more information about driver functionality and almost doesn't 
+	effect performance. Can be displayed using mv_eth_tool.
+
+config  MV_ETH_STAT_DBG
+        bool "Collect debug statistics"
+        default n
+        ---help---
+	Marvell network interface driver collect a lot of statistics. 
+	Used for Debug mode. Decrease performance. Can be displayed using mv_eth_tool.
+
+config  MV_ETH_STAT_DIST
+        bool "Collect debug distribution statistics"
+        default n
+        ---help---
+        Marvell network interface driver collect a lot of statistics.
+        Used for Debug mode. Decrease performance. Can be displayed using mv_eth_tool.
+
+config  MV_LINUX_COUNTERS_DISABLE
+	bool "Disable collection of SNMP statistics and Netfilter Contract statistics"
+	default n
+	---help---
+	Disable collection of SNMP statistics and Netfilter Contract statistics to improve performance.
+
+config  MV_ETH_TOOL	
+	bool "Support ethtool controls"
+	default y
+	---help---
+	Support kernel's SIOCETHTOOL for ethtool utility	
+endmenu
+
+menu "Advanced Features"
+
+config  NET_SKB_HEADROOM
+        int "SKB headroom size"
+        default 64
+        ---help---
+          Customize SKB headroom size. Must be power of 2.
+
+config NET_SKB_RECYCLE
+        bool "Skb recycle"
+        default y
+        ---help---
+          Work-in-progress and experimental.
+
+          This option enables skb's to be returned via a callback at kfree to
+          the allocator to make a fastpath for very skb consuming network
+          applications.
+
+config NET_SKB_RECYCLE_DEF
+        depends on NET_SKB_RECYCLE
+        int "Default value for SKB recycle:  0 - disable, 1 - enable"
+        default 1
+        ---help---
+
+config  MV_ETH_TX_DONE_TIMER_PERIOD
+        int "Periodical Tx Done timer period"
+        default 10
+        ---help---
+          Periodical timer period for Tx Done operation in [msec].
+
+config  MV_ETH_CLEANUP_TIMER_PERIOD
+        int "Periodical Cleanup timer period"
+        default 10
+        ---help---
+          Periodical timer period for cleanup operation in [msec].
+
+config  MV_ETH_TXDONE_ISR
+	bool "Use interrupt to process TX_DONE event"
+	default n
+	---help---
+	When chosen TX_DONE event will be process in interrupt mode
+	When unchosen TX_DONE event will be processed in polling mode
+
+config  MV_ETH_TXDONE_COAL_PKTS
+	int "Threshold for TX_DONE event trigger"
+	default 16
+	---help---
+	Number of packets will be sent before TX_DONE event will be triggered	
+	by interrupt or polling.
+
+config  MV_ETH_RX_COAL_PKTS
+        int "Threshold [number of packets] for RX interrupt"
+        default 64
+        ---help---
+        Number of packets will be received before RX interrupt will be generated by HW.
+
+config  MV_ETH_RX_COAL_USEC
+        int "Threshold [usec] for RX interrupt"
+        default 200
+        ---help---
+        Time delay in usec before RX interrupt will be generated by HW if number of 
+	received packets larger than 0 but smaller than MV_ETH_RX_COAL_PKTS
+
+config  MV_ETH_RX_DESC_PREFETCH
+	bool "Enable RX descriptor prefetch"
+	default n
+	---help---
+	Use pld instruction to prefetch one RX descriptor ahead
+
+config  MV_ETH_RX_PKT_PREFETCH
+        bool "Enable RX packet prefetch"
+        default n
+        ---help---
+        Use pld instruction to prefetch first two cache lines of received packet data
+
+config  MV_ETH_IGMP
+        bool "IGMP special processing support"
+        default n
+        ---help---
+
+config MV_ETH_RX_SPECIAL
+	depends on MV_ETH_PNC
+        bool "Enable special RX processing"
+        default n
+        ---help---
+        Enable special RX processing for packets with RI_RX_SEPCIAL PNC result info bit set
+
+config MV_ETH_TX_SPECIAL
+	bool "Enable special TX processing"
+ 	default n
+	---help---
+	Enable special TX processing for packets with signal header (SH)
+
+config MV_ETH_L2FW
+	bool "L2 Forwarding support"
+	select MV_ETH_NFP_SEC
+	depends on !MV_CESA_TOOL && !MV_CESA_TEST && !MV_CESA_OCF && MV_INCLUDE_XOR
+	default n
+	---help---
+	Enable L2 Forwarding support for received packets.
+	Three modes are supported: Send packet without change, Swap MAC DA<->SA,
+	Copy the whole packet and swap MAC
+
+config MV_ETH_L2FW_DEBUG
+	depends on MV_ETH_L2FW
+	bool "Add run-time L2FW debug code"
+	default n
+	---help---
+	Enable L2FW run-time enable/disable enter debug code blocks
+	
+config MV_ETH_RX_POLL_WEIGHT
+	int "poll weight for the RX poll() function"
+	default 64
+	range 1 255
+	---help---
+	poll weight for the RX poll() function; must be less or equal to 255 	
+
+config MV_ETH_EXTRA_BUF_SIZE
+	int "Extra buffer size in bytes"
+	default 120
+	range 120 16384
+	---help---
+	Size of buffers allocated for extra pool and used in special cases like TSO,
+	fragmentattion and others
+
+config MV_ETH_EXTRA_BUF_NUM
+        int "Number of extra buffers allocated for each port"
+        default MV_ETH_TXQ_DESC
+	---help---
+	Number of extra buffers allocated for each port 
+endmenu
+
+menu "NFP support"
+
+config  MV_ETH_NFP
+        bool "Use Network Fast Processing (NFP)"
+	default y
+        ---help---
+        Choosing this option will enable Network Fast Processing.
+
+config MV_ETH_NFP_DEF
+        depends on MV_ETH_NFP
+        int "Default value for NFP:  0 - disable, 1 - enable"
+        default 0
+        ---help---
+
+config MV_ETH_NFP_BRIDGE
+        bool "Support NFP bridging"
+        default y
+        depends on MV_ETH_NFP
+        ---help---
+        Choosing this option will enable NFP bridging support.
+
+config MV_ETH_NFP_FIB
+        bool "Support NFP routing"
+	default y
+        depends on MV_ETH_NFP
+        ---help---
+        Choosing this option will enable NFP routing support.
+
+config MV_ETH_NFP_NAT
+        bool "Support NFP NAT"
+        depends on MV_ETH_NFP_FIB && NF_CONNTRACK
+	default y
+        ---help---
+        Choosing this option will enable NFP NAT support.
+
+config  MV_ETH_NFP_PPP
+	bool "Support NFP PPPoE"
+	depends on MV_ETH_NFP_FIB && PPPOE
+	default n
+	 ---help---
+	Choosing this option will enable NFP PPPoE protocol.
+
+config MV_ETH_NFP_PNC
+	bool "Support NFP forwarding with PnC"
+	depends on MV_ETH_NFP && MV_ETH_PNC_PARSER && !MV_ETH_PNC_WOL
+	default y 
+	---help---
+	Choosing this option will add PNC(TCAM) assistance to NFP.
+
+config MV_ETH_NFP_PMT
+        bool "Use PMT for NFP forwarding with PNC"
+	depends on MV_ETH_PMT && MV_ETH_NFP_PNC
+        default n
+        ---help---
+
+config MV_ETH_PMT_FLOWS
+	int "Number of different flows can be set to PMT"
+	depends on MV_ETH_NFP_PMT
+	default 256
+	---help---
+	Depend on total number of PMT entries and 
+	number of PMT entires reserved for each flow.
+	MV_ETH_PMT_SIZE >= (MV_ETH_PMT_FLOWS * (MV_ETH_PMT_CMD_PER_FLOW + 1))
+
+config MV_ETH_PMT_CMD_PER_FLOW
+        int "Number of PMT entries reserved for each flow"
+        depends on MV_ETH_NFP_PMT
+        default 12
+        ---help---
+        Depend on total number of PMT entries and
+        number of flows to be supported.
+	MV_ETH_PMT_SIZE >= (MV_ETH_PMT_FLOWS * (MV_ETH_PMT_CMD_PER_FLOW + 1))
+
+config MV_ETH_NFP_HWF
+        bool "Use HWF for NFP forwarding with PNC and PMT"
+        depends on MV_ETH_HWF && MV_ETH_NFP_PNC && MV_ETH_NFP_PMT
+        default n
+        ---help---
+
+config MV_ETH_NFP_SWF
+	bool "Support NFP SW Forwarding (simulate HWF)"
+	depends on MV_ETH_NFP && MV_ETH_PNC
+	default n
+	---help---
+	Choosing this option will enable NFP SW Forwarding.
+
+config  MV_ETH_NFP_STATS
+        bool "Collect NFP statistics"
+	depends on MV_ETH_NFP
+        default n
+        ---help---
+        Collect NFP statistics. Can be displayed using mv_eth_tool.
+
+config  MV_ETH_NFP_DEBUG
+	bool "Add NFP debug code"
+	depends on MV_ETH_NFP	
+	default n
+        ---help---
+	Add NFP sanity check code	
+	
+config MV_ETH_NFP_SEC
+	bool "Support NFP IPSec"
+	depends on MV_ETH_NFP 
+	default n
+	---help---
+	Choosing this option will IPSec support in NFP.
+endmenu
+
+menu "PON support for Network driver"
+
+config MV_PON
+        bool "PON support"
+        depends on MV_ETH_NETA && MV_INCLUDE_PON
+        ---help---
+        Choose this option to support PON port in Marvell network driver
+
+config MV_PON_TXP_DEF
+        int "Default T-CONT to send local generated packets"
+        depends on MV_PON
+        default 0
+        ---help---
+
+config MV_PON_TXQ_DEF
+        int "Default TXQ to send local generated packets"
+        depends on MV_PON
+        default 0
+        ---help---
+
+endmenu
+
+menu "Switch support"
+
+config MV_ETH_SWITCH
+        bool "Switch support"
+	depends on MV_INCLUDE_SWITCH
+        ---help---
+	Choose this option to support Gigabit Ethernet Controller connected to 
+        on-board QuarterDeck switch family
+
+config  MV_ETH_SWITCH_NETDEV_NUM
+	int "Maximum number of subnets on switch ports"
+	depends on MV_ETH_SWITCH
+	default 4
+	---help---
+	Valid range range from 1 to BOARD_ETH_SWITCH_PORT_NUM
+
+config  MV_ETH_SWITCH_NETCONFIG
+	string "Switch network configuration"
+	depends on MV_ETH_SWITCH
+	default "3,(00:11:66:11:66:11,0)(00:22:77:22:77:22,1:2:3:4),mtu=1500"
+	---help---
+	 Set the network configuration when giga port connected to switch. 
+         For each interface, define the interface 
+	 name, MAC address and participating ports. 
+
+config  MV_ETH_SWITCH_LINK
+	bool "Link status change indications"
+	depends on MV_ETH_SWITCH
+	default y
+	---help---
+	  Support Phy link status change indications.
+endmenu
+
+config ARMADA_XP_ERRATA_SMI_1
+	bool "use SMI port 1 instead of SMI port 0"
+	        ---help---
+	Using SMI port 1 instead of SMI port 0 prevents the 
+	link up/link down on a different port than the port on which 
+	an action such as changing speed or starting autonegotiation is done.
+	(NetA BTS #313, DSMP LSP #42, ARMADA XP Z1).
+	
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/bm/bm_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/bm/bm_sysfs.c
new file mode 100644
index 0000000..d8ca6d3
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/bm/bm_sysfs.c
@@ -0,0 +1,145 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+
+#include "gbe/mvNeta.h"
+#include "net_dev/mv_netdev.h"
+#include "bm/mvBm.h"
+
+static ssize_t bm_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "cat                regs         - show BM registers\n");
+	off += sprintf(buf+off, "cat                stat         - show BM status\n");
+	off += sprintf(buf+off, "echo p v           > dump       - dump BM pool <p>. v=0-brief, v=1-full\n");
+
+	return off;
+}
+
+static ssize_t bm_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	int          err = 0;
+	const char   *name = attr->attr.name;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help"))
+		return bm_help(buf);
+	else if (!strcmp(name, "regs"))
+		mvBmRegs();
+	else if (!strcmp(name, "stat"))
+		mvBmStatus();
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	return err;
+}
+static ssize_t bm_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  err = 0, pool = 0, mode = 0;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%d %d", &pool, &mode);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "dump")) {
+		mvBmPoolDump(pool, mode);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(dump,  S_IWUSR, NULL, bm_store);
+static DEVICE_ATTR(stat,  S_IRUSR, bm_show, NULL);
+static DEVICE_ATTR(regs,  S_IRUSR, bm_show, NULL);
+static DEVICE_ATTR(help,  S_IRUSR, bm_show, NULL);
+
+static struct attribute *bm_attrs[] = {
+	&dev_attr_dump.attr,
+	&dev_attr_regs.attr,
+	&dev_attr_stat.attr,
+	&dev_attr_help.attr,
+	NULL
+};
+
+static struct attribute_group bm_group = {
+	.name = "bm",
+	.attrs = bm_attrs,
+};
+
+int __devinit bm_sysfs_init(void)
+{
+		int err;
+		struct device *pd;
+
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+		if (!pd) {
+			platform_device_register_simple("neta", -1, NULL, 0);
+			pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+		}
+
+		if (!pd) {
+			printk(KERN_ERR "%s: cannot find neta device\n", __func__);
+			pd = &platform_bus;
+		}
+
+		err = sysfs_create_group(&pd->kobj, &bm_group);
+		if (err) {
+			printk(KERN_INFO "sysfs group failed %d\n", err);
+			goto out;
+		}
+out:
+		return err;
+}
+
+module_init(bm_sysfs_init);
+
+MODULE_AUTHOR("Dmitri Epshtein");
+MODULE_DESCRIPTION("BM for Marvell NetA");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/hwf/hwf_bm.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/hwf/hwf_bm.c
new file mode 100644
index 0000000..2648ab3
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/hwf/hwf_bm.c
@@ -0,0 +1,254 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+
+#include "gbe/mvNeta.h"
+#include "bm/mvBm.h"
+
+#include "net_dev/mv_netdev.h"
+
+static MV_BM_POOL	hwfBmPool[MV_BM_POOLS];
+static MV_BM_CONFIG	hwfBmConfig[CONFIG_MV_ETH_PORTS_NUM];
+
+static MV_STATUS mv_hwf_bm_config_get(int port, MV_BM_CONFIG *bmConfig)
+{
+	switch (port) {
+
+#ifdef CONFIG_MV_ETH_HWF_0_BM
+	case 0:
+		bmConfig->valid = 1;
+		bmConfig->longPool = CONFIG_MV_ETH_HWF_0_BM_LONG_POOL;
+		bmConfig->shortPool = CONFIG_MV_ETH_HWF_0_BM_SHORT_POOL;
+		bmConfig->longBufNum = CONFIG_MV_ETH_HWF_0_BM_LONG_BUF_NUM;
+
+#if (CONFIG_MV_ETH_HWF_0_BM_SHORT_POOL != CONFIG_MV_ETH_HWF_0_BM_LONG_POOL)
+		bmConfig->shortBufNum = CONFIG_MV_ETH_HWF_0_BM_SHORT_BUF_NUM;
+		bmConfig->shortBufSize = CONFIG_MV_ETH_HWF_0_BM_SHORT_BUF_SIZE;
+#endif /* CONFIG_MV_ETH_HWF_0_BM_SHORT_POOL != CONFIG_MV_ETH_HWF_0_BM_LONG_POOL */
+
+		break;
+#endif /* CONFIG_MV_ETH_HWF_0_BM */
+
+#ifdef CONFIG_MV_ETH_HWF_1_BM
+	case 1:
+		bmConfig->valid = 1;
+		bmConfig->longPool = CONFIG_MV_ETH_HWF_1_BM_LONG_POOL;
+		bmConfig->shortPool = CONFIG_MV_ETH_HWF_1_BM_SHORT_POOL;
+		bmConfig->longBufNum = CONFIG_MV_ETH_HWF_1_BM_LONG_BUF_NUM;
+
+#if (CONFIG_MV_ETH_HWF_1_BM_SHORT_POOL != CONFIG_MV_ETH_HWF_1_BM_LONG_POOL)
+		bmConfig->shortBufNum = CONFIG_MV_ETH_HWF_1_BM_SHORT_BUF_NUM;
+		bmConfig->shortBufSize = CONFIG_MV_ETH_HWF_1_BM_SHORT_BUF_SIZE;
+#endif /* CONFIG_MV_ETH_HWF_1_BM_SHORT_POOL != CONFIG_MV_ETH_HWF_1_BM_LONG_POOL */
+
+		break;
+#endif /* CONFIG_MV_ETH_HWF_1_BM */
+
+#ifdef CONFIG_MV_ETH_HWF_2_BM
+	case 2:
+		bmConfig->valid = 1;
+		bmConfig->longPool = CONFIG_MV_ETH_HWF_2_BM_LONG_POOL;
+		bmConfig->shortPool = CONFIG_MV_ETH_HWF_2_BM_SHORT_POOL;
+		bmConfig->longBufNum = CONFIG_MV_ETH_HWF_2_BM_LONG_BUF_NUM;
+
+#if (CONFIG_MV_ETH_HWF_2_BM_SHORT_POOL != CONFIG_MV_ETH_HWF_2_BM_LONG_POOL)
+		bmConfig->shortBufNum = CONFIG_MV_ETH_HWF_2_BM_SHORT_BUF_NUM;
+		bmConfig->shortBufSize = CONFIG_MV_ETH_HWF_2_BM_SHORT_BUF_SIZE;
+#endif /* CONFIG_MV_ETH_HWF_2_BM_SHORT_POOL != CONFIG_MV_ETH_HWF_2_BM_LONG_POOL */
+
+		break;
+#endif /* CONFIG_MV_ETH_HWF_2_BM */
+
+	default:
+		mvOsPrintf("%s: port = %d is out of range\n", __func__, port);
+		return MV_OUT_OF_RANGE;
+	}
+
+	return MV_OK;
+}
+
+static int mv_eth_hwf_pool_add(MV_BM_POOL *pBmPool, int bufNum)
+{
+	int      i;
+	void     *pVirt;
+	MV_ULONG physAddr;
+
+	/* Check total number of buffers doesn't exceed capacity */
+	if ((bufNum < 0) ||
+		((bufNum + pBmPool->bufNum) > (pBmPool->capacity))) {
+
+		mvOsPrintf("%s: to many %d buffers for BM pool #%d: capacity=%d, buf_num=%d\n",
+			   __func__, bufNum, pBmPool->pool, pBmPool->capacity, pBmPool->bufNum);
+		return 0;
+	}
+	/* Allocate buffers for the pool */
+	for (i = 0; i < bufNum; i++) {
+
+		pVirt = mvOsIoCachedMalloc(NULL, pBmPool->bufSize, &physAddr, NULL);
+		if (pVirt == NULL) {
+			mvOsPrintf("%s: Warning! Not all buffers of %d bytes allocated\n",
+						__func__, pBmPool->bufSize);
+			break;
+		}
+		mvBmPoolPut(pBmPool->pool, (MV_ULONG) physAddr);
+	}
+	pBmPool->bufNum += i;
+
+	mvOsPrintf("BM pool #%d for HWF: bufSize=%4d - %4d of %4d buffers added\n",
+	       pBmPool->pool, pBmPool->bufSize, i, bufNum);
+
+	return i;
+}
+
+/*******************************************************************************
+ * mvNetaHwfBmPoolsCfg - create BM pools used by the port for HWF only
+ *
+ * INPUT:
+ *       int        port	- port number
+ *
+ * RETURN:   MV_STATUS
+ *               MV_OK - Success, Others - Failure
+ *
+ *******************************************************************************/
+MV_STATUS mv_eth_hwf_bm_create(int port, int mtuPktSize)
+{
+	static bool		isFirst = true;
+	MV_BM_POOL		*pBmPool;
+	MV_BM_CONFIG	*pBmConfig;
+
+	/* Check validity of the parameters */
+	if (mvNetaPortCheck(port))
+		return MV_FAIL;
+
+	/* For the first time - clean hwfBmPool array */
+	if (isFirst == true) {
+		memset(&hwfBmPool, 0, sizeof(hwfBmPool));
+		memset(&hwfBmConfig, 0, sizeof(hwfBmConfig));
+		mvBmControl(MV_START);
+		isFirst = false;
+	}
+
+	pBmConfig = &hwfBmConfig[port];
+	/* Get compile time BM pools configuration for this port */
+	if (mv_hwf_bm_config_get(port, pBmConfig) != MV_OK)
+		return MV_FAIL;
+
+	/* For HWF Packet offset in the packet is 8 bytes */
+	pBmConfig->longBufSize = mtuPktSize + 8;
+
+	/* Check validity of the parameters */
+	if (mvNetaMaxCheck(pBmConfig->longPool,  MV_BM_POOLS))
+		return MV_FAIL;
+
+	/* Create long pool */
+	pBmPool = &hwfBmPool[pBmConfig->longPool];
+	if (pBmPool->pVirt == NULL) {
+		/* Allocate new pool */
+		pBmPool->pVirt = mv_eth_bm_pool_create(pBmConfig->longPool, MV_BM_POOL_CAP_MAX, &pBmPool->physAddr);
+		if (pBmPool->pVirt == NULL) {
+			mvOsPrintf("%s: Can't allocate %d bytes for Long pool #%d of port #%d\n",
+					__func__, MV_BM_POOL_CAP_MAX * sizeof(MV_U32), pBmConfig->longPool, port);
+			return MV_OUT_OF_CPU_MEM;
+		}
+		pBmPool->pool = pBmConfig->longPool;
+		pBmPool->capacity = MV_BM_POOL_CAP_MAX;
+		pBmPool->bufSize = pBmConfig->longBufSize;
+	} else {
+		/* Share pool with other port - check buffer size */
+		if (pBmConfig->longBufSize > pBmPool->bufSize) {
+			/* The BM pool doesn't match the mtuPktSize */
+			mvOsPrintf("%s: longBufSize=%d is too match for the pool #%d (%d bytes)\n",
+						__func__, pBmConfig->longBufSize, pBmPool->pool, pBmPool->bufSize);
+			return MV_FAIL;
+		}
+	}
+	mv_eth_hwf_pool_add(pBmPool, pBmConfig->longBufNum);
+
+	/* Create short pool */
+	if (pBmConfig->shortPool != pBmConfig->longPool) {
+		pBmPool = &hwfBmPool[pBmConfig->shortPool];
+		if (pBmPool->pVirt == NULL) {
+			/* Allocate new pool */
+			pBmPool->pVirt = mv_eth_bm_pool_create(pBmConfig->shortPool, MV_BM_POOL_CAP_MAX, &pBmPool->physAddr);
+			if (pBmPool->pVirt == NULL) {
+				mvOsPrintf("%s: Can't allocate %d bytes for Short pool #%d of port #%d\n",
+						__func__, MV_BM_POOL_CAP_MAX * sizeof(MV_U32), pBmConfig->shortPool, port);
+				return MV_OUT_OF_CPU_MEM;
+			}
+			pBmPool->pool = pBmConfig->shortPool;
+			pBmPool->capacity = MV_BM_POOL_CAP_MAX;
+			pBmPool->bufSize = pBmConfig->shortBufSize;
+		} else {
+			/* Share pool with other port - check buffer size */
+			if (pBmConfig->shortBufSize > pBmPool->bufSize) {
+				/* The BM pool doesn't match the mtuPktSize */
+				mvOsPrintf("%s: shortBufSize=%d is too match for the pool #%d (%d bytes)\n",
+							__func__, pBmConfig->shortBufSize, pBmPool->pool, pBmPool->bufSize);
+				return MV_FAIL;
+			}
+		}
+		/* Add buffers to short pool */
+		mv_eth_hwf_pool_add(pBmPool, pBmConfig->shortBufNum);
+	}
+	mvNetaHwfBmPoolsSet(port, pBmConfig->shortPool, pBmConfig->longPool);
+	return MV_OK;
+}
+
+void mv_hwf_bm_dump(void)
+{
+	int          i;
+	MV_BM_CONFIG *bmConfig;
+	MV_BM_POOL   *bmPool;
+
+	mvOsPrintf("HWF BM Ports compile time configuration\n");
+	mvOsPrintf("port:  longPool  shortPool  longBufNum  longBufSize  shortBufNum  shortBufSize\n");
+	for (i = 0; i < CONFIG_MV_ETH_PORTS_NUM; i++) {
+		bmConfig = &hwfBmConfig[i];
+		if (bmConfig->valid)
+			mvOsPrintf("  %2d:   %4d       %4d        %4d        %4d        %4d         %4d\n",
+					i, bmConfig->longPool, bmConfig->shortPool, bmConfig->longBufNum, bmConfig->longBufSize,
+					bmConfig->shortBufNum, bmConfig->shortBufSize);
+	}
+	mvOsPrintf("\n");
+
+	mvOsPrintf("HWF BM Pools configuration\n");
+	mvOsPrintf("pool:    capacity    bufSize    bufNum      virtPtr       physAddr\n");
+	for (i = 0; i < MV_BM_POOLS; i++) {
+		bmPool = &hwfBmPool[i];
+		if (bmPool->pVirt)
+			mvOsPrintf("  %2d:     %4d       %4d       %4d      %p      0x%08x\n",
+						bmPool->pool, bmPool->capacity, bmPool->bufSize, bmPool->bufNum,
+						bmPool->pVirt, (unsigned)bmPool->physAddr);
+	}
+}
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/hwf/hwf_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/hwf/hwf_sysfs.c
new file mode 100644
index 0000000..669a3b1
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/hwf/hwf_sysfs.c
@@ -0,0 +1,162 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+
+#include "gbe/mvNeta.h"
+#include "net_dev/mv_netdev.h"
+
+static ssize_t hwf_help(char *buf)
+{
+	int off = 0;
+
+	off += mvOsSPrintf(buf+off, "cat                      bm    - print HWF BM information\n");
+	off += mvOsSPrintf(buf+off, "echo rxp p txp         > regs  - print HWF registers of port <p>\n");
+	off += mvOsSPrintf(buf+off, "echo rxp p txp         > cntrs - print HWF counters of port <p>\n");
+	off += mvOsSPrintf(buf+off, "echo rxp p txp txq en  > en    - enable HWF from <rxp> to specific <txq>\n");
+	off += mvOsSPrintf(buf+off, "echo rxp p txp txq a b > drop  - set HWF drop threshold <a> and Random bits <b>\n");
+
+	return off;
+}
+
+static ssize_t hwf_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char   *name = attr->attr.name;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help"))
+		return hwf_help(buf);
+	else if (!strcmp(name, "bm"))
+		mv_hwf_bm_dump();
+
+	return 0;
+}
+static ssize_t hwf_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  err = 0, rxp = 0, p = 0, txp = 0, txq = 0, a = 0, b = 0;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%d %d %d %d %d %d", &rxp, &p, &txp, &txq, &a, &b);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "regs")) {
+		mvNetaHwfRxpRegs(rxp);
+		mvNetaHwfTxpRegs(rxp, p, txp);
+	} else if (!strcmp(name, "cntrs")) {
+		mvNetaHwfTxpCntrs(rxp, p, txp);
+	} else if (!strcmp(name, "en")) {
+		if (a)        {
+			/* Set txp/txq ownership to HWF */
+			if (mv_eth_ctrl_txq_hwf_own(p, txp, txq, rxp)) {
+				printk(KERN_ERR "%s failed: p=%d, txp=%d, txq=%d\n",
+					__func__, p, txp, txq);
+				return -EINVAL;
+			}
+		} else
+			mv_eth_ctrl_txq_hwf_own(p, txp, txq, -1);
+
+		mvNetaHwfTxqEnable(rxp, p, txp, txq, a);
+	} else if (!strcmp(name, "drop")) {
+		mvNetaHwfTxqDropSet(rxp, p, txp, txq, a, b);
+	} else
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(regs,  S_IWUSR, hwf_show, hwf_store);
+static DEVICE_ATTR(cntrs, S_IWUSR, hwf_show, hwf_store);
+static DEVICE_ATTR(en,    S_IWUSR, hwf_show, hwf_store);
+static DEVICE_ATTR(drop,  S_IWUSR, hwf_show, hwf_store);
+static DEVICE_ATTR(bm,    S_IRUSR, hwf_show, hwf_store);
+static DEVICE_ATTR(help,  S_IRUSR, hwf_show, hwf_store);
+
+static struct attribute *hwf_attrs[] = {
+	&dev_attr_regs.attr,
+	&dev_attr_cntrs.attr,
+	&dev_attr_en.attr,
+	&dev_attr_drop.attr,
+	&dev_attr_bm.attr,
+	&dev_attr_help.attr,
+	NULL
+};
+
+static struct attribute_group hwf_group = {
+	.name = "hwf",
+	.attrs = hwf_attrs,
+};
+
+int __devinit hwf_sysfs_init(void)
+{
+		int err;
+		struct device *pd;
+
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+		if (!pd) {
+			platform_device_register_simple("neta", -1, NULL, 0);
+			pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+		}
+
+		if (!pd) {
+			printk(KERN_ERR "%s: cannot find neta device\n", __func__);
+			pd = &platform_bus;
+		}
+
+		err = sysfs_create_group(&pd->kobj, &hwf_group);
+		if (err) {
+			printk(KERN_INFO "sysfs group failed %d\n", err);
+			goto out;
+		}
+out:
+		return err;
+}
+
+module_init(hwf_sysfs_init);
+
+MODULE_AUTHOR("Dmitri Epshtein");
+MODULE_DESCRIPTION("HWF for Marvell NetA MV65xxx");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/l2fw_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/l2fw_sysfs.c
new file mode 100644
index 0000000..18af0ae
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/l2fw_sysfs.c
@@ -0,0 +1,200 @@
+/* l2fw_sysfs.c */
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+
+#include "mvTypes.h"
+#include "mv_eth_l2fw.h"
+#include "linux/inet.h"
+
+static ssize_t l2fw_help(char *buf)
+{
+	int off = 0;
+	off += sprintf(buf+off, "help\n");
+	off += sprintf(buf+off, "echo mode rxp txp > l2fw - set l2f <rxp>->");
+	off += sprintf(buf+off, "<txp><mode> 0-dis,1-as_is,2-swap,3-copy\n");
+	off += sprintf(buf+off, "echo threshold > l2fw_xor: set threshold\n");
+	off += sprintf(buf+off, "echo 1 > esp   - enable ESP\n");
+	off += sprintf(buf+off, "cat dump - display L2fw rules DB\n");
+	off += sprintf(buf+off, "echo 1 > flush - flush L2fw rules DB\n");
+	return off;
+}
+
+static ssize_t l2fw_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+    const char	*name = attr->attr.name;
+    int             off = 0;
+
+    if (!capable(CAP_NET_ADMIN))
+	return -EPERM;
+
+	if (!strcmp(name, "help")) {
+	    off = l2fw_help(buf);
+		return off;
+	}
+	if (!strcmp(name, "dump")) {
+		l2fw_dump();
+		return off;
+	}
+	if (!strcmp(name, "numHashEntries")) {
+		l2fw_show_numHashEntries();
+		return off;
+	}
+	if (!strcmp(name, "esp")) {
+		l2fw_esp_show();
+		return off;
+	}
+
+	if (!strcmp(name, "help")) {
+	    off = l2fw_help(buf);
+		return off;
+	}
+	if (!strcmp(name, "stats")) {
+	    l2fw_stats();
+		return off;
+	}
+
+	return off;
+}
+
+
+
+static ssize_t l2fw_hex_store(struct device *dev, struct device_attribute *attr,
+				const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    addr1, addr2;
+	int port;
+	unsigned long   flags;
+	int             enableEsp;
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+	err = addr1 = addr2 = port = 0;
+
+	local_irq_save(flags);
+	if (!strcmp(name, "l2fw_add")) {
+		sscanf(buf, "%x %x %d", &addr1, &addr2, &port);
+		l2fw_add(addr1, addr2, port);
+	} else if (!strcmp(name, "l2fw_add_ip")) {
+		l2fw_add_ip(buf);
+	} else if (!strcmp(name, "esp")) {
+		sscanf(buf, "%d", &enableEsp);
+		l2fw_esp_set(enableEsp);
+	} else if (!strcmp(name, "flush")) {
+		l2fw_flush();
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t l2fw_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char	*name = attr->attr.name;
+	int             err;
+
+	unsigned int    p, txp, txq, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	err = p = txp = txq = v = 0;
+	sscanf(buf, "%d %d %d %d", &p, &txp, &txq, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "l2fw_xor"))
+		l2fw_xor(p);
+
+	else if (!strcmp(name, "l2fw"))
+		l2fw(p, txp, txq);
+
+	else if (!strcmp(name, "cesa_chan"))
+		err = l2fw_set_cesa_chan(p, txp);
+	
+	local_irq_restore(flags);
+
+	if (err)
+		mvOsPrintf("%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+
+}
+
+
+static DEVICE_ATTR(l2fw,			S_IWUSR, l2fw_show, l2fw_store);
+static DEVICE_ATTR(l2fw_xor,		S_IWUSR, l2fw_show, l2fw_store);
+static DEVICE_ATTR(l2fw_add,		S_IWUSR, l2fw_show, l2fw_hex_store);
+static DEVICE_ATTR(l2fw_add_ip,		S_IWUSR, l2fw_show, l2fw_hex_store);
+static DEVICE_ATTR(help,			S_IRUSR, l2fw_show,  NULL);
+static DEVICE_ATTR(dump,			S_IRUSR, l2fw_show,  NULL);
+static DEVICE_ATTR(numHashEntries,	S_IRUSR, l2fw_show,  NULL);
+static DEVICE_ATTR(stats,			S_IRUSR, l2fw_show, NULL);
+static DEVICE_ATTR(flush,			S_IWUSR, NULL,  	 l2fw_hex_store);
+static DEVICE_ATTR(esp,				S_IWUSR, l2fw_show,  l2fw_hex_store);
+static DEVICE_ATTR(cesa_chan,		S_IWUSR, NULL,  l2fw_store);
+
+
+
+
+static struct attribute *l2fw_attrs[] = {
+	&dev_attr_l2fw.attr,
+	&dev_attr_l2fw_xor.attr,
+	&dev_attr_l2fw_add.attr,
+	&dev_attr_l2fw_add_ip.attr,
+	&dev_attr_help.attr,
+	&dev_attr_dump.attr,
+	&dev_attr_flush.attr,
+	&dev_attr_esp.attr,
+	&dev_attr_numHashEntries.attr,
+	&dev_attr_stats.attr,
+	&dev_attr_cesa_chan.attr,	
+	NULL
+};
+
+static struct attribute_group l2fw_group = {
+	.name = "l2fw",
+	.attrs = l2fw_attrs,
+};
+
+#ifdef CONFIG_MV_ETH_L2FW
+int __devinit mv_l2fw_sysfs_init(void)
+{
+	int err;
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+	if (!pd) {
+		platform_device_register_simple("neta", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+	}
+
+	if (!pd) {
+		printk(KERN_ERR "%s: cannot find neta device\n", __func__);
+		pd = &platform_bus;
+	}
+
+	err = sysfs_create_group(&pd->kobj, &l2fw_group);
+	if (err) {
+		printk(KERN_ERR "sysfs group failed %d\n", err);
+		goto out;
+	}
+out:
+	return err;
+}
+#endif
+
+module_init(mv_l2fw_sysfs_init);
+
+MODULE_AUTHOR("Rami Rosen");
+MODULE_DESCRIPTION("sysfs for marvell l2fw");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.c
new file mode 100644
index 0000000..69e5171
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.c
@@ -0,0 +1,1878 @@
+/* mv_eth_l2fw.c */
+#include <linux/ctype.h>
+
+#include "xor/mvXor.h"
+#include "xor/mvXorRegs.h"
+#include "mv_hal_if/mvSysXorApi.h"
+
+#include "mvOs.h"
+#include "mv_eth_l2fw.h"
+#include "mv_neta/net_dev/mv_netdev.h"
+#include "gbe/mvNeta.h"
+#include "gbe/mvNetaRegs.h"
+#include "nfp/mvNfp.h"
+#include "mv_eth_l2fw.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "cesa/mvCesa.h"
+#include "eth/nfp/mvNfpSec.h"
+
+
+
+
+
+#define CESA_0    0 
+#define CESA_1    1
+/* for future - handle by CPU */
+#define CESA_NONE 2
+
+atomic_t req_count[2];
+
+
+#define MV_NFP_SEC_REQ_Q_SIZE 1000
+#define CESA_DEF_REQ_SIZE       (256*4)
+
+extern u32 mv_crypto_virt_base_get(u8 chan);
+
+static MV_NFP_SEC_SA_ENTRY sa;
+
+typedef struct _mv_nfp_sec_cesa_priv_l2fw {
+	MV_NFP_SEC_SA_ENTRY *pSaEntry;
+	MV_PKT_INFO *pPktInfo;
+	MV_U8 orgDigest[MV_CESA_MAX_DIGEST_SIZE];
+	MV_CESA_COMMAND *pCesaCmd;
+	struct eth_pbuf *pPkt;
+	int ifout;
+	int ownerId;
+	int inPort;
+} MV_NFP_SEC_CESA_PRIV_L2FW;
+
+
+static MV_PKT_INFO *pPktInfoNewArray_0;
+static MV_PKT_INFO *pPktInfoNewArray_1;
+static MV_BUF_INFO *pBufInfoArray_0;
+static MV_BUF_INFO *pBufInfoArray_1;
+
+MV_BUF_INFO cesaBufs_0[CESA_DEF_REQ_SIZE];
+MV_BUF_INFO cesaBufs_1[CESA_DEF_REQ_SIZE];
+
+spinlock_t cesa_lock[2];
+static int cesaPrivIndx_0 = 0;
+static int cesaPrivIndx_1 = 0;
+
+MV_NFP_SEC_CESA_PRIV_L2FW *cesaPrivArray_0;
+MV_NFP_SEC_CESA_PRIV_L2FW *cesaPrivArray_1;
+
+static int cesaCmdIndx_0 = 0;
+static int cesaCmdIndx_1 = 0;
+
+
+void *cesaOSHandle = NULL;
+static MV_CESA_MBUF *cesaMbufArray_0;
+static MV_CESA_MBUF *cesaMbufArray_1;
+
+static MV_CESA_COMMAND *cesaCmdArray_0;
+static MV_CESA_COMMAND *cesaCmdArray_1;
+
+static int mv_eth_ports_l2fw_num;
+static int espEnabled = 0;
+
+static L2FW_RULE **l2fw_hash = NULL;
+#define CESA_RESULT_Q_SIZE	1024
+#define	L2FW_HASH_MASK   (L2FW_HASH_SIZE - 1)
+unsigned int req_empty[2] = {0, 0};
+unsigned int req_ready[2] = {0, 0};
+
+static MV_U32 l2fw_jhash_iv;
+
+static int numHashEntries;
+
+static int counterNoResources[4] = {0, 0, 0, 0};
+
+struct eth_port_l2fw **mv_eth_ports_l2fw;
+static inline MV_STATUS mv_eth_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp,
+									   int withXor, struct neta_rx_desc *rx_desc);
+
+void printkPkt(struct eth_pbuf *pkt);
+void cesaStart(void);
+static inline MV_STATUS mv_eth_cesa_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp);
+
+
+INLINE void  nfp_sec_pkt_info_free(struct eth_pbuf *pkt, int inPort)
+{
+	struct bm_pool *pool;
+	pool = &mv_eth_pool[pkt->pool];
+
+	mvStackPush(pool->stack, (MV_U32) pkt);
+
+}
+
+void mv_eth_pkt_print_new(struct eth_pbuf *pkt)
+{
+	printk(KERN_ERR "pkt: pkt=%p len=%d off=%d cmd=0x%x pool=%d "
+	       "tos=%d gpon=0x%x\n skb=%p pa=%lx buf=%p\n",
+	       pkt, pkt->bytes, pkt->offset, pkt->tx_cmd, pkt->pool,
+	       pkt->tos, pkt->hw_cmd, pkt->osInfo, pkt->physAddr, pkt->pBuf);
+}
+
+
+void printBufVirtPtr(MV_BUF_INFO *pBuf)
+{
+	int i;
+	if (pBuf->bufVirtPtr == NULL) {
+		printk(KERN_INFO "pBuf->bufVirtPt==NULL in %s\n", __func__);
+		return;
+	}
+	for (i = 0; i < 40; i++) {
+		printk(KERN_INFO "KERN_INFO [%d]=%x ", i, pBuf->bufVirtPtr[i]);
+		if (!(i%10) && i > 1)
+			printk(KERN_INFO "\n");
+	}
+	printk(KERN_INFO "\n****************** %s\n", __func__);
+
+}
+void printBufInfo(MV_BUF_INFO *pbuf)
+{
+	printk(KERN_INFO "bufSize=%d\n"      , pbuf->bufSize);
+	printk(KERN_INFO "dataSize=%d\n"     , pbuf->dataSize);
+	printk(KERN_INFO "memHandle=%d\n"    , pbuf->memHandle);
+	printk(KERN_INFO "bufAddrShift=%d\n" , pbuf->bufAddrShift);
+	printk(KERN_INFO "*****************************************\n\n");
+
+}
+
+
+static inline void nfp_sec_complete_out(unsigned long data)
+
+{
+	MV_NFP_SEC_CESA_PRIV_L2FW *nfp_sec_cesa_priv = (MV_NFP_SEC_CESA_PRIV_L2FW *)data;		MV_U32            ifout;
+	MV_PKT_INFO       *pkt;
+	MV_BUF_INFO       *pBuf;
+	struct eth_port   *pp;
+	struct eth_pbuf   *pPkt;
+	int oldOfsset;
+	MV_STATUS status = MV_FAIL;
+	static int counterOfFailed = 0;
+	if (!nfp_sec_cesa_priv) {
+		printk(KERN_INFO "nfp_sec_cesa_priv is NULL in %s\n", __func__);
+		return;
+	}
+	ifout = nfp_sec_cesa_priv->ifout;
+
+	pkt = nfp_sec_cesa_priv->pPktInfo;
+	if (!pkt) {
+		printk(KERN_INFO "pPktInfo is NULL in %s\n", __func__);
+		return;
+	}
+	pBuf = pkt->pFrags;
+	if (!pBuf) {
+		printk(KERN_INFO "pBuf is NULL in %s\n", __func__);
+		return;
+	}
+	pPkt = nfp_sec_cesa_priv->pPkt;
+	if (!pPkt) {
+		printk(KERN_INFO "!pPkt) in %s\n", __func__);
+		return;
+	}
+	pPkt->bytes    = pBuf->dataSize;
+	pPkt->bytes += MV_NFP_SEC_ESP_OFFSET;
+	oldOfsset      = pPkt->offset;
+	pPkt->offset   = pPkt->offset - (sizeof(MV_ESP_HEADER) + sizeof(MV_IP_HEADER) + MV_CESA_AES_BLOCK_SIZE);
+
+	pp     = mv_eth_ports[ifout];
+
+	status = 	mv_eth_cesa_l2fw_tx(pPkt, pp);
+	if (status == MV_DROPPED)
+		counterOfFailed++;
+	 else
+		pPkt->offset = oldOfsset;
+}
+
+void openCesaSession(void)
+{
+	unsigned char sha1Key[]  = {0x12, 0x34, 0x56, 0x78, 0x9a, 0xbc, 0xde, 0xf0,
+								0x24, 0x68, 0xac, 0xe0, 0x24, 0x68, 0xac, 0xe0,
+								0x13, 0x57, 0x9b, 0xdf};
+	/* sizeof(cryptoKey) should be 128 for AES-128 */
+	unsigned char cryptoKey[] = {0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef,
+									0x02, 0x46, 0x8a, 0xce, 0x13, 0x57, 0x9b, 0xdf};
+
+	int i;
+	MV_NFP_SEC_SA_ENTRY sa;
+	MV_CESA_OPEN_SESSION os;
+	unsigned short digest_size = 0;
+	memset(&sa, 0, sizeof(MV_NFP_SEC_SA_ENTRY));
+	memset(&os, 0, sizeof(MV_CESA_OPEN_SESSION));
+
+	os.operation 		= MV_CESA_MAC_THEN_CRYPTO;
+	os.cryptoAlgorithm  = MV_CESA_CRYPTO_AES;
+	os.macMode  		= MV_CESA_MAC_HMAC_SHA1;
+	digest_size 		= MV_CESA_SHA1_DIGEST_SIZE;
+	os.cryptoMode 		= MV_CESA_CRYPTO_ECB;
+	for (i = 0; i < sizeof(cryptoKey); i++)
+		os.cryptoKey[i] = cryptoKey[i];
+
+	os.cryptoKeyLength = sizeof(cryptoKey);
+
+	for (i = 0; i < sizeof(sha1Key); i++)
+		os.macKey[i] = sha1Key[i];
+	os.macKeyLength = sizeof(sha1Key);
+	os.digestSize = digest_size;
+
+	if (mvCesaSessionOpen(&os, (short *)&(sa.sid)))
+		printk(KERN_INFO "mvCesaSessionOpen failed in %s\n", __func__);
+}
+
+
+static s32 atoi(char *psz_buf)
+{
+	char *pch = psz_buf;
+	s32 base = 0;
+	unsigned long res;
+	int ret_val;
+
+	while (isspace(*pch))
+			pch++;
+
+	if (*pch == '-' || *pch == '+') {
+			base = 10;
+			pch++;
+	} else if (*pch && tolower(pch[strlen(pch) - 1]) == 'h') {
+			base = 16;
+	}
+
+	ret_val = strict_strtoul(pch, base, &res);
+
+	return ret_val ? : res;
+}
+
+
+
+static L2FW_RULE *l2fw_lookup(MV_U32 srcIP, MV_U32 dstIP)
+{
+	MV_U32 hash;
+	L2FW_RULE *rule;
+
+	hash = mv_jhash_3words(srcIP, dstIP, (MV_U32) 0, l2fw_jhash_iv);
+	hash &= L2FW_HASH_MASK;
+	rule = l2fw_hash[hash];
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+	if (rule)
+		printk(KERN_INFO "rule is not NULL in %s\n", __func__);
+	else
+		printk(KERN_INFO "rule is NULL in %s\n", __func__);
+#endif
+	while (rule) {
+		if ((rule->srcIP == srcIP) && (rule->dstIP == dstIP))
+			return rule;
+
+		rule = rule->next;
+	}
+	return NULL;
+}
+
+int l2fw_set_cesa_chan(int port, int cesaChan)
+{
+	struct eth_port *pp;
+	printk("setting cesaChan to %d for port=%d \n", cesaChan, port);
+	if ( (cesaChan != CESA_0) && (cesaChan !=CESA_1) )  {
+		printk("non permitted value for CESA channel \n");
+		return -EINVAL;
+	}
+	pp = mv_eth_ports[port];
+	if (pp)
+		pp->cesaChan = cesaChan;
+	return 0;
+}
+
+
+void l2fw_stats(void)
+{
+	int i;
+	for (i = 0; i < 4; i++) {
+		mvOsPrintf("number of Cesa No Resources error is port[%d]=%d \n", i, counterNoResources[i]);
+		counterNoResources[i] = 0;
+	}
+	
+}
+
+void l2fw_show_numHashEntries(void)
+{
+	mvOsPrintf("number of Hash Entries is %d \n", numHashEntries);
+
+}
+
+
+void l2fw_flush(void)
+{
+	MV_U32 i = 0;
+	mvOsPrintf("\nFlushing L2fw Rule Database: \n");
+	mvOsPrintf("*******************************\n");
+	for (i = 0; i < L2FW_HASH_SIZE; i++)
+		l2fw_hash[i] = NULL;
+	numHashEntries = 0;
+}
+
+
+void l2fw_dump(void)
+{
+	MV_U32 i = 0;
+	L2FW_RULE *currRule;
+
+	mvOsPrintf("\nPrinting L2fw Rule Database: \n");
+	mvOsPrintf("*******************************\n");
+
+	for (i = 0; i < L2FW_HASH_SIZE; i++) {
+		currRule = l2fw_hash[i];
+		while (currRule != NULL) {
+			mvOsPrintf("%u.%u.%u.%u->%u.%u.%u.%u    out port=%d (hash=%x)\n",
+				NIPQUAD(currRule->srcIP), NIPQUAD(currRule->dstIP),
+				currRule->port, i);
+			currRule = currRule->next;
+		}
+	}
+
+}
+
+
+MV_STATUS l2fw_add(MV_U32 srcIP, MV_U32 dstIP, int port)
+{
+	L2FW_RULE *l2fw_rule;
+
+	MV_U32 hash = mv_jhash_3words(srcIP, dstIP, (MV_U32) 0, l2fw_jhash_iv);
+	hash &= L2FW_HASH_MASK;
+	if (numHashEntries == L2FW_HASH_SIZE) {
+		printk(KERN_INFO "cannot add entry, hash table is full, there are %d entires \n", L2FW_HASH_SIZE);
+		return MV_ERROR;
+	}
+
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+	mvOsPrintf("srcIP=%x dstIP=%x in %s\n", srcIP, dstIP, __func__);
+	mvOsPrintf("srcIp = %u.%u.%u.%u in %s\n", NIPQUAD(srcIP), __func__);
+	mvOsPrintf("dstIp = %u.%u.%u.%u in %s\n", NIPQUAD(dstIP), __func__);
+#endif
+
+	l2fw_rule = l2fw_lookup(srcIP, dstIP);
+	if (l2fw_rule)
+		return MV_OK;
+
+	l2fw_rule = (L2FW_RULE *)mvOsMalloc(sizeof(L2FW_RULE));
+	if (!l2fw_rule) {
+		mvOsPrintf("%s: OOM\n", __func__);
+		return MV_FAIL;
+	}
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+	mvOsPrintf("adding a rule to l2fw hash in %s\n", __func__);
+#endif
+	l2fw_rule->srcIP = srcIP;
+	l2fw_rule->dstIP = dstIP;
+	l2fw_rule->port = port;
+
+	l2fw_rule->next = l2fw_hash[hash];
+	l2fw_hash[hash] = l2fw_rule;
+	numHashEntries++;
+    return MV_OK;
+}
+
+MV_STATUS l2fw_add_ip(const char *buf)
+{
+	char *addr1, *addr2;
+	L2FW_RULE *l2fw_rule;
+	MV_U32 srcIP;
+	MV_U32 dstIP;
+	char dest1[15];
+	char dest2[15];
+	char *portStr;
+	int offset1, offset2, port;
+	MV_U32 hash    = 0;
+	if (numHashEntries == L2FW_HASH_SIZE) {
+		printk(KERN_INFO "cannot add entry, hash table is full, there are %d entires \n", L2FW_HASH_SIZE);
+		return MV_ERROR;
+	}
+
+	memset(dest1,   0, sizeof(dest1));
+	memset(dest2,   0, sizeof(dest2));
+
+	addr1 = strchr(buf, ',');
+	addr2 =	strchr(addr1+1, ',');
+	offset1 = addr1-buf;
+	offset2 = addr2-addr1;
+	if (!addr1) {
+			printk(KERN_INFO "first separating comma (',') missing in input in %s\n", __func__);
+			return MV_FAIL;
+	}
+	if (!addr2) {
+			printk(KERN_INFO "second separating comma (',') missing in input in %s\n", __func__);
+			return MV_FAIL;
+	}
+
+	strncpy(dest1, buf, addr1-buf);
+	srcIP = in_aton(dest1);
+	strncpy(dest2, buf+offset1+1, addr2-addr1-1);
+	dstIP = in_aton(dest2);
+	portStr = addr2+1;
+	if (*portStr == 'D') {
+		L2FW_RULE *l2fw_rule_to_del, *prev;
+		hash = mv_jhash_3words(srcIP, dstIP, (MV_U32) 0, l2fw_jhash_iv);
+		hash &= L2FW_HASH_MASK;
+		l2fw_rule_to_del = l2fw_hash[hash];
+		prev = NULL;
+
+		while (l2fw_rule_to_del) {
+		if ((l2fw_rule_to_del->srcIP == srcIP) &&
+			(l2fw_rule_to_del->dstIP == dstIP)) {
+			if (prev)
+				prev->next = l2fw_rule_to_del->next;
+			else
+				l2fw_hash[hash] = l2fw_rule_to_del->next;
+			mvOsPrintf("%u.%u.%u.%u->%u.%u.%u.%u deleted\n", NIPQUAD(srcIP), NIPQUAD(dstIP));
+			mvOsFree(l2fw_rule_to_del);
+			numHashEntries--;
+			return MV_OK;
+		}
+
+		prev = l2fw_rule_to_del;
+		l2fw_rule_to_del = l2fw_rule_to_del->next;
+	}
+		mvOsPrintf("%u.%u.%u.%u->%u.%u.%u.%u : entry not found\n", NIPQUAD(srcIP), NIPQUAD(dstIP));
+		return MV_NOT_FOUND;
+	}
+
+	port = atoi(portStr);
+	hash = mv_jhash_3words(srcIP, dstIP, (MV_U32) 0, l2fw_jhash_iv);
+	hash &= L2FW_HASH_MASK;
+
+	l2fw_rule = l2fw_lookup(srcIP, dstIP);
+	if (l2fw_rule) {
+		mvOsPrintf("%u.%u.%u.%u->%u.%u.%u.%u : entry already exist\n",
+				NIPQUAD(srcIP), NIPQUAD(dstIP));
+		return MV_OK;
+	}
+
+	l2fw_rule = (L2FW_RULE *)mvOsMalloc(sizeof(L2FW_RULE));
+	if (!l2fw_rule) {
+		mvOsPrintf("%s: OOM\n", __func__);
+		return MV_FAIL;
+	}
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+	mvOsPrintf("adding a rule to l2fw hash in %s\n", __func__);
+#endif
+	l2fw_rule->srcIP = srcIP;
+	l2fw_rule->dstIP = dstIP;
+	l2fw_rule->port = port;
+
+	l2fw_rule->next = l2fw_hash[hash];
+	l2fw_hash[hash] = l2fw_rule;
+	numHashEntries++;
+    return MV_OK;
+
+}
+
+void l2fw_esp_show(void)
+{
+	if (espEnabled)
+		printk(KERN_INFO "ESP is enabled in %s\n", __func__);
+	else
+		printk(KERN_INFO "ESP is not enabled in %s\n", __func__);
+}
+
+void l2fw_esp_set(int enableEsp)
+{
+	if (enableEsp) {
+		openCesaSession();
+		printk(KERN_INFO "calling cesaStart() in %s\n", __func__);
+		cesaStart();
+	} else
+		printk(KERN_INFO "enableEsp=%d disabling ESP in %s\n", enableEsp, __func__);
+	espEnabled = enableEsp;
+}
+
+
+static inline
+struct neta_tx_desc *mv_eth_tx_desc_get(struct tx_queue *txq_ctrl, int num)
+{
+	/* Is enough TX descriptors to send packet */
+	if ((txq_ctrl->txq_count + num) >= txq_ctrl->txq_size) {
+		/*
+		printk("eth_tx: txq_ctrl->txq=%d - no_resource: txq_count=%d,
+				txq_size=%d, num=%d\n",
+				txq_ctrl->txq, txq_ctrl->txq_count,
+				txq_ctrl->txq_size, num);
+		*/
+		STAT_DBG(txq_ctrl->stats.txq_err++);
+		return NULL;
+	}
+	return mvNetaTxqNextDescGet(txq_ctrl->q);
+}
+
+
+static int mv_ctrl_txdone = CONFIG_MV_ETH_TXDONE_COAL_PKTS;
+static void dump_xor(void)
+{
+	mvOsPrintf(" CHANNEL_ARBITER_REG %08x\n",
+		MV_REG_READ(XOR_CHANNEL_ARBITER_REG(1)));
+	mvOsPrintf(" CONFIG_REG          %08x\n",
+		MV_REG_READ(XOR_CONFIG_REG(1, XOR_CHAN(0))));
+	mvOsPrintf(" ACTIVATION_REG      %08x\n",
+		MV_REG_READ(XOR_ACTIVATION_REG(1, XOR_CHAN(0))));
+	mvOsPrintf(" CAUSE_REG           %08x\n",
+		MV_REG_READ(XOR_CAUSE_REG(1)));
+	mvOsPrintf(" MASK_REG            %08x\n",
+		MV_REG_READ(XOR_MASK_REG(1)));
+	mvOsPrintf(" ERROR_CAUSE_REG     %08x\n",
+		MV_REG_READ(XOR_ERROR_CAUSE_REG(1)));
+	mvOsPrintf(" ERROR_ADDR_REG      %08x\n",
+		MV_REG_READ(XOR_ERROR_ADDR_REG(1)));
+	mvOsPrintf(" NEXT_DESC_PTR_REG   %08x\n",
+		MV_REG_READ(XOR_NEXT_DESC_PTR_REG(1, XOR_CHAN(0))));
+	mvOsPrintf(" CURR_DESC_PTR_REG   %08x\n",
+		MV_REG_READ(XOR_CURR_DESC_PTR_REG(1, XOR_CHAN(0))));
+	mvOsPrintf(" BYTE_COUNT_REG      %08x\n\n",
+		MV_REG_READ(XOR_BYTE_COUNT_REG(1, XOR_CHAN(0))));
+	mvOsPrintf("  %08x\n\n", XOR_WINDOW_CTRL_REG(1, XOR_CHAN(0))) ;
+		mvOsPrintf(" XOR_WINDOW_CTRL_REG      %08x\n\n",
+		MV_REG_READ(XOR_WINDOW_CTRL_REG(1, XOR_CHAN(0)))) ;
+}
+
+
+
+/* L2fw defines */
+#define L2FW_DISABLE				0
+#define TX_AS_IS					1
+#define SWAP_MAC					2
+#define COPY_AND_SWAP		        3
+
+#define XOR_CAUSE_DONE_MASK(chan) ((BIT0|BIT1) << (chan * 16))
+
+static int         l2fw_xor_threshold = 200;
+static MV_XOR_DESC *eth_xor_desc = NULL;
+static MV_LONG      eth_xor_desc_phys_addr;
+
+
+static int mv_eth_poll_l2fw(struct napi_struct *napi, int budget)
+{
+	int rx_done = 0;
+	MV_U32 causeRxTx;
+	struct eth_port *pp = MV_ETH_PRIV(napi->dev);
+	read_lock(&pp->rwlock);
+
+	STAT_INFO(pp->stats.poll++);
+
+	/* Read cause register */
+	causeRxTx = MV_REG_READ(NETA_INTR_NEW_CAUSE_REG(pp->port)) &
+	    (MV_ETH_MISC_SUM_INTR_MASK | MV_ETH_TXDONE_INTR_MASK |
+		 MV_ETH_RX_INTR_MASK);
+
+	if (causeRxTx & MV_ETH_MISC_SUM_INTR_MASK) {
+		MV_U32 causeMisc;
+
+		/* Process MISC events - Link, etc ??? */
+		causeRxTx &= ~MV_ETH_MISC_SUM_INTR_MASK;
+		causeMisc = MV_REG_READ(NETA_INTR_MISC_CAUSE_REG(pp->port));
+
+		if (causeMisc & NETA_CAUSE_LINK_CHANGE_MASK)
+			mv_eth_link_event(pp, 1);
+		MV_REG_WRITE(NETA_INTR_MISC_CAUSE_REG(pp->port), 0);
+	}
+
+	causeRxTx |= pp->causeRxTx[smp_processor_id()];
+#ifdef CONFIG_MV_ETH_TXDONE_ISR
+	if (causeRxTx & MV_ETH_TXDONE_INTR_MASK) {
+		/* TX_DONE process */
+
+		mv_eth_tx_done_gbe(pp,
+				(causeRxTx & MV_ETH_TXDONE_INTR_MASK));
+
+		causeRxTx &= ~MV_ETH_TXDONE_INTR_MASK;
+	}
+#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+
+#if (CONFIG_MV_ETH_RXQ > 1)
+	while ((causeRxTx != 0) && (budget > 0)) {
+		int count, rx_queue;
+
+		rx_queue = mv_eth_rx_policy(causeRxTx);
+		if (rx_queue == -1)
+			break;
+
+		count = mv_eth_rx_l2f(pp, budget, rx_queue);
+		rx_done += count;
+		budget -= count;
+		if (budget > 0)
+			causeRxTx &=
+			 ~((1 << rx_queue) << NETA_CAUSE_RXQ_OCCUP_DESC_OFFS);
+	}
+#else
+	rx_done = mv_eth_rx_l2f(pp, budget, CONFIG_MV_ETH_RXQ_DEF);
+	budget -= rx_done;
+#endif /* (CONFIG_MV_ETH_RXQ > 1) */
+
+
+	if (budget > 0) {
+		unsigned long flags;
+		causeRxTx = 0;
+
+		napi_complete(napi);
+		STAT_INFO(pp->stats.poll_exit++);
+
+		local_irq_save(flags);
+		MV_REG_WRITE(NETA_INTR_NEW_MASK_REG(pp->port),
+			(MV_ETH_MISC_SUM_INTR_MASK | MV_ETH_TXDONE_INTR_MASK |
+				  MV_ETH_RX_INTR_MASK));
+
+		local_irq_restore(flags);
+	}
+	pp->causeRxTx[smp_processor_id()] = causeRxTx;
+
+	read_unlock(&pp->rwlock);
+
+	return rx_done;
+}
+
+
+void mv_eth_set_l2fw(int cmd, int rx_port, int out_tx_port)
+{
+	struct eth_port *pp;
+	struct net_device *dev;
+	pp     = mv_eth_ports[rx_port];
+
+	if (!pp) {
+		mvOsPrintf("pp is NULL in setting L2FW (%s)\n", __func__);
+		return;
+	}
+	clear_bit(MV_ETH_F_CONNECT_LINUX_BIT, &(pp->flags));
+
+	dev = pp->dev;
+	if (dev == NULL) {
+		mvOsPrintf("device is NULL in in setting L2FW (%s)\n", __func__);
+		return;
+	}
+	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
+		mvOsPrintf("Device is down for port=%d ; MV_ETH_F_STARTED_BIT is not set in %s\n", rx_port, __func__);
+		mvOsPrintf("Cannot set to L2FW mode in %s\n", __func__);
+		return;
+	}
+
+	if (cmd == L2FW_DISABLE) {
+		if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
+			napi_disable(pp->napiGroup[CPU_GROUP_DEF]);
+		netif_napi_del(pp->napiGroup[CPU_GROUP_DEF]);
+		netif_napi_add(dev, pp->napiGroup[CPU_GROUP_DEF], mv_eth_poll,
+			pp->weight);
+		if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
+			napi_enable(pp->napiGroup[CPU_GROUP_DEF]);
+	} else {
+		if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
+			napi_disable(pp->napiGroup[CPU_GROUP_DEF]);
+		netif_napi_del(pp->napiGroup[CPU_GROUP_DEF]);
+		printk("pp->weight=%d in %s\n",pp->weight,__FUNCTION__);
+		netif_napi_add(dev, pp->napiGroup[CPU_GROUP_DEF], mv_eth_poll_l2fw,
+			pp->weight);
+		if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
+			napi_enable(pp->napiGroup[CPU_GROUP_DEF]);
+		}
+
+}
+
+
+static inline struct eth_pbuf *l2fw_swap_mac(struct eth_pbuf *pRxPktInfo)
+{
+	MV_U16 *pSrc;
+	int i;
+	MV_U16 swap;
+	pSrc = (MV_U16 *)(pRxPktInfo->pBuf + pRxPktInfo->offset + MV_ETH_MH_SIZE);
+
+	for (i = 0; i < 3; i++) {
+		swap = pSrc[i];
+		pSrc[i] = pSrc[i+3];
+		pSrc[i+3] = swap;
+		}
+
+	return  pRxPktInfo;
+}
+
+static inline void l2fw_copy_mac(struct eth_pbuf *pRxPktInfo,
+					 struct eth_pbuf *pTxPktInfo)
+	{
+	/* copy 30 bytes (start after MH header) */
+    /* 12 for SA + DA */
+	/* 18 for the rest */
+	MV_U16 *pSrc;
+	MV_U16 *pDst;
+	int i;
+	pSrc = (MV_U16 *)(pRxPktInfo->pBuf + pRxPktInfo->offset + MV_ETH_MH_SIZE);
+	pDst = (MV_U16 *)(pTxPktInfo->pBuf + pTxPktInfo->offset + MV_ETH_MH_SIZE);
+	/* swap mac SA and DA */
+	for (i = 0; i < 3; i++) {
+		pDst[i]   = pSrc[i+3];
+		pDst[i+3] = pSrc[i];
+		}
+	for (i = 6; i < 15; i++)
+		pDst[i] = pSrc[i];
+	}
+
+static inline void l2fw_copy_and_swap_mac(struct eth_pbuf *pRxPktInfo, struct eth_pbuf *pTxPktInfo)
+{
+	MV_U16 *pSrc;
+	MV_U16 *pDst;
+	int i;
+
+	pSrc = (MV_U16 *)(pRxPktInfo->pBuf +  pRxPktInfo->offset + MV_ETH_MH_SIZE);
+	pDst = (MV_U16 *)(pTxPktInfo->pBuf +  pTxPktInfo->offset + MV_ETH_MH_SIZE);
+	for (i = 0; i < 3; i++) {
+		pDst[i]   = pSrc[i+3];
+		pDst[i+3] = pSrc[i];
+		}
+}
+
+static inline
+struct eth_pbuf *eth_l2fw_copy_packet_withoutXor(struct eth_pbuf *pRxPktInfo)
+{
+	MV_U8 *pSrc;
+	MV_U8 *pDst;
+	struct bm_pool *pool;
+	struct eth_pbuf *pTxPktInfo;
+
+	mvOsCacheInvalidate(NULL, pRxPktInfo->pBuf + pRxPktInfo->offset,
+						pRxPktInfo->bytes);
+
+	pool = &mv_eth_pool[pRxPktInfo->pool];
+	pTxPktInfo = mv_eth_pool_get(pool);
+	if (pTxPktInfo == NULL) {
+		mvOsPrintf("pTxPktInfo == NULL in %s\n", __func__);
+		return NULL;
+		}
+	pSrc = pRxPktInfo->pBuf +  pRxPktInfo->offset + MV_ETH_MH_SIZE;
+	pDst = pTxPktInfo->pBuf +  pTxPktInfo->offset + MV_ETH_MH_SIZE;
+
+	memcpy(pDst+12, pSrc+12, pRxPktInfo->bytes-12);
+	l2fw_copy_and_swap_mac(pRxPktInfo, pTxPktInfo);
+	pTxPktInfo->bytes = pRxPktInfo->bytes;
+	mvOsCacheFlush(NULL, pTxPktInfo->pBuf + pTxPktInfo->offset, pTxPktInfo->bytes);
+
+	return pTxPktInfo;
+}
+
+static inline
+struct eth_pbuf *eth_l2fw_copy_packet_withXor(struct eth_pbuf *pRxPktInfo)
+{
+	struct bm_pool *pool;
+	struct eth_pbuf *pTxPktInfo;
+
+	pool = &mv_eth_pool[pRxPktInfo->pool];
+	pTxPktInfo = mv_eth_pool_get(pool);
+	if (pTxPktInfo == NULL) {
+		mvOsPrintf("pTxPktInfo == NULL in %s\n", __func__);
+		return NULL;
+		}
+
+	/* sync between giga and XOR to avoid errors (like checksum errors in TX)
+	   when working with IOCC */
+
+	mvOsCacheIoSync();
+
+	eth_xor_desc->srcAdd0    = pRxPktInfo->physAddr + pRxPktInfo->offset + MV_ETH_MH_SIZE + 30;
+	eth_xor_desc->phyDestAdd = pTxPktInfo->physAddr + pTxPktInfo->offset + MV_ETH_MH_SIZE + 30;
+
+	eth_xor_desc->byteCnt    = pRxPktInfo->bytes - 30;
+
+	eth_xor_desc->phyNextDescPtr = 0;
+	eth_xor_desc->status         = BIT31;
+	/* we had changed only the first part of eth_xor_desc, so flush only one
+	 line of cache */
+	mvOsCacheLineFlush(NULL, eth_xor_desc);
+	MV_REG_WRITE(XOR_NEXT_DESC_PTR_REG(1, XOR_CHAN(0)), eth_xor_desc_phys_addr);
+
+	MV_REG_WRITE(XOR_ACTIVATION_REG(1, XOR_CHAN(0)), XEXACTR_XESTART_MASK);
+
+	mvOsCacheLineInv(NULL, pRxPktInfo->pBuf + pRxPktInfo->offset);
+	l2fw_copy_mac(pRxPktInfo, pTxPktInfo);
+	mvOsCacheLineFlush(NULL, pTxPktInfo->pBuf + pTxPktInfo->offset);
+
+    /* Update TxPktInfo */
+	pTxPktInfo->bytes = pRxPktInfo->bytes;
+	return pTxPktInfo;
+}
+
+void setXorDesc(void)
+{
+	unsigned int mode;
+	eth_xor_desc = mvOsMalloc(sizeof(MV_XOR_DESC) + XEXDPR_DST_PTR_DMA_MASK + 32);
+	eth_xor_desc = (MV_XOR_DESC *)MV_ALIGN_UP((MV_U32)eth_xor_desc, XEXDPR_DST_PTR_DMA_MASK+1);
+	eth_xor_desc_phys_addr = mvOsIoVirtToPhys(NULL, eth_xor_desc);
+	mvSysXorInit();
+
+	mode = MV_REG_READ(XOR_CONFIG_REG(1, XOR_CHAN(0)));
+	mode &= ~XEXCR_OPERATION_MODE_MASK;
+	mode |= XEXCR_OPERATION_MODE_DMA;
+	MV_REG_WRITE(XOR_CONFIG_REG(1, XOR_CHAN(0)), mode);
+
+    MV_REG_WRITE(XOR_NEXT_DESC_PTR_REG(1, XOR_CHAN(0)), eth_xor_desc_phys_addr);
+	dump_xor();
+}
+
+
+static inline int xorReady(void)
+{
+	int timeout = 0;
+
+	while (!(MV_REG_READ(XOR_CAUSE_REG(1)) & XOR_CAUSE_DONE_MASK(XOR_CHAN(0)))) {
+		if (timeout > 0x100000) {
+			mvOsPrintf("XOR timeout\n");
+			return 0;
+			}
+		timeout++;
+	}
+
+	/* Clear int */
+	MV_REG_WRITE(XOR_CAUSE_REG(1), ~(XOR_CAUSE_DONE_MASK(XOR_CHAN(0))));
+
+	return 1;
+}
+
+
+void l2fw(int cmd, int rx_port, int tx_port)
+{
+	struct eth_port_l2fw *ppl2fw;
+	int port;
+
+	MV_U32 regVal;
+	mv_eth_ports_l2fw_num = mvCtrlEthMaxPortGet();
+	ppl2fw = mv_eth_ports_l2fw[rx_port];
+	mvOsPrintf("cmd=%d rx_port=%d tx_port=%d in %s \n",
+				cmd, rx_port, tx_port, __func__);
+	ppl2fw->txPort = tx_port;
+	ppl2fw->cmd	= cmd;
+	mv_eth_set_l2fw(cmd, rx_port, tx_port);
+	regVal = 0;
+	regVal |= ETH_TX_BURST_SIZE_MASK(ETH_BURST_SIZE_16_64BIT_VALUE);
+	regVal |= ETH_RX_BURST_SIZE_MASK(ETH_BURST_SIZE_16_64BIT_VALUE);
+	regVal |= (ETH_RX_NO_DATA_SWAP_MASK | ETH_TX_NO_DATA_SWAP_MASK | ETH_NO_DESC_SWAP_MASK);
+	for (port = 0; port < mv_eth_ports_l2fw_num; port++) {
+	/* Assign port SDMA configuration */
+
+	/* setting Tx/Rx burst
+		TBD - unset BURST size back to default when exiting L2FW mode */
+
+		MV_REG_WRITE(ETH_SDMA_CONFIG_REG(port), regVal);
+	}
+}
+
+void l2fw_xor(int threshold)
+{
+	mvOsPrintf("setting threshold to %d in %s\n", threshold, __func__);
+	l2fw_xor_threshold = threshold;
+}
+
+void printCesaCmd(MV_CESA_COMMAND *pCesaCmd)
+{
+	printk(KERN_INFO "pCesaCmd->sessionId = %d in %s\n", pCesaCmd->sessionId, __func__);
+	printk(KERN_INFO "ivFromUser =%d\n", pCesaCmd->ivFromUser);
+	printk(KERN_INFO"ivOffset=%d\n", pCesaCmd->ivOffset);
+	printk(KERN_INFO "cryptoOffset=%d\n", pCesaCmd->cryptoOffset);
+	printk(KERN_INFO "cryptoLength=%d\n", pCesaCmd->cryptoLength);
+	printk(KERN_INFO "digestOffset=%d\n", pCesaCmd->digestOffset);
+	printk(KERN_INFO "macOffset=%d\n", pCesaCmd->macOffset);
+	printk(KERN_INFO "macLength=%d\n", pCesaCmd->macLength);
+	printk(KERN_INFO "reqId=%d\n", pCesaCmd->reqId);
+	printk(KERN_INFO "pCesaCmd->pDst->pFrags[0].bufSize=%d\n", pCesaCmd->pDst->pFrags[0].bufSize);
+}
+
+INLINE MV_VOID mvNfpSecBuildMac(MV_PKT_INFO *pPktInfo, MV_NFP_SEC_SA_ENTRY* pSAEntry)
+{
+	MV_802_3_HEADER *pMacHdr;
+
+	pMacHdr = (MV_802_3_HEADER *)((MV_U8 *)(pPktInfo->pFrags[0].bufVirtPtr));
+	memcpy(pMacHdr, &pSAEntry->tunnelHdr.dstMac, 12);
+	/* stands for IP protocol code 16bit swapped */
+	pMacHdr->typeOrLen = 0x08;
+	return;
+}
+
+INLINE MV_VOID mvNfpSecBuildIPTunnel(MV_PKT_INFO *pPktInfo, MV_NFP_SEC_SA_ENTRY *pSAEntry)
+{
+	MV_IP_HEADER *pIpHdr, *pIntIpHdr;
+	MV_U16 newIpTotalLength;
+
+	newIpTotalLength = pPktInfo->pFrags[0].dataSize - sizeof(MV_802_3_HEADER);
+
+	pIpHdr = (MV_IP_HEADER *)(pPktInfo->pFrags[0].bufVirtPtr +
+				sizeof(MV_802_3_HEADER));
+	pIntIpHdr = (MV_IP_HEADER *)((MV_U8 *)(pIpHdr) + sizeof(MV_IP_HEADER) + sizeof(MV_ESP_HEADER) +
+			pSAEntry->ivSize);
+
+	pIpHdr->version = 0x45;
+	pIpHdr->tos = 0;
+	pIpHdr->checksum = 0;
+	pIpHdr->totalLength = MV_16BIT_BE(newIpTotalLength);
+	pIpHdr->identifier = 0;
+	pIpHdr->fragmentCtrl = 0;
+	pIpHdr->ttl = pIntIpHdr->ttl - 1 ;
+	pIpHdr->protocol = MV_IP_PROTO_ESP;
+	pIpHdr->srcIP = pSAEntry->tunnelHdr.sIp;
+	pIpHdr->dstIP = pSAEntry->tunnelHdr.dIp;
+	return;
+}
+
+/* Append sequence number and spi, save some space for IV */
+INLINE MV_VOID mvNfpSecBuildEspHdr(MV_PKT_INFO *pPktInfo, MV_NFP_SEC_SA_ENTRY* pSAEntry)
+{
+	MV_ESP_HEADER *pEspHdr;
+
+	pEspHdr = (MV_ESP_HEADER *)(pPktInfo->pFrags[0].bufVirtPtr +
+			sizeof(MV_802_3_HEADER) + sizeof(MV_IP_HEADER));
+	pEspHdr->spi = pSAEntry->spi;
+	pSAEntry->seqNum = (pSAEntry->seqNum++);
+	pEspHdr->seqNum = pSAEntry->seqNum;
+}
+
+void printEspHdr(MV_ESP_HEADER *pEspHdr)
+{
+	printk(KERN_INFO "pEspHdr->spi=%d in %s\n"  , pEspHdr->spi, __func__);
+	printk(KERN_INFO "pEspHdr->seqNum=%d in %s\n", pEspHdr->seqNum, __func__);
+}
+
+void printIpHdr(MV_IP_HEADER *pIpHdr)
+{
+	printk(KERN_INFO "%u.%u.%u.%u->%u.%u.%u.%u in %s\n", NIPQUAD(pIpHdr->srcIP), NIPQUAD(pIpHdr->dstIP), __func__);
+	printk(KERN_INFO "MV_16BIT_BE(pIpHdr->totalLength)=%d  in %s\n", MV_16BIT_BE(pIpHdr->totalLength), __func__);
+	printk(KERN_INFO "pIpHdr->protocol=%d \n", pIpHdr->protocol);
+}
+
+void printCesaMbuf(MV_CESA_MBUF *pCesaMbuf)
+{
+	printk(KERN_INFO "pCesaMbuf->pFrags->bufSize=%d  \n", pCesaMbuf->pFrags->bufSize);
+	printk(KERN_INFO "pCesaMbuf->pFrags->dataSize=%d  \n", pCesaMbuf->pFrags->dataSize);
+	printk(KERN_INFO "pCesaMbuf->pFrags->bufAddrShift=%d  \n", pCesaMbuf->pFrags->bufAddrShift);
+	printk(KERN_INFO "pCesaMbuf->mbufSize=%d  \n", pCesaMbuf->mbufSize);
+}
+
+
+inline MV_STATUS mvSecEspProcess_0(struct eth_pbuf *pPkt, MV_PKT_INFO *pPktInfo,
+							MV_NFP_SEC_SA_ENTRY *pSAEntry, struct eth_port *newpp,
+							MV_U8 channel, int inPort)
+{
+	MV_CESA_COMMAND	*pCesaCmd;
+	MV_CESA_MBUF *pCesaMbuf;
+	MV_NFP_SEC_CESA_PRIV_L2FW *pCesaPriv;
+	MV_STATUS status;
+	MV_IP_HEADER *pIpHdr;
+	MV_BUF_INFO  *pBuf;
+
+	pCesaCmd  = &cesaCmdArray_0[cesaCmdIndx_0];
+	pCesaMbuf = &cesaMbufArray_0[cesaCmdIndx_0];
+	cesaCmdIndx_0++;
+
+	cesaCmdIndx_0 %= CESA_DEF_REQ_SIZE;
+	pCesaPriv = &cesaPrivArray_0[cesaPrivIndx_0++];
+
+	cesaPrivIndx_0 = cesaPrivIndx_0%(CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE);
+
+	pCesaPriv->pPktInfo = pPktInfo;
+	pCesaPriv->pSaEntry = pSAEntry;
+	pCesaPriv->pCesaCmd = pCesaCmd;
+
+	pCesaPriv->pPkt   = pPkt;
+	pCesaPriv->ifout  = newpp->port;
+	pCesaPriv->inPort = inPort;
+	/*
+	 *  Fix, encrypt/decrypt the IP payload only, --BK 20091027
+	 */
+	pBuf = pPktInfo->pFrags;
+	pIpHdr = (MV_IP_HEADER *)(pBuf->bufVirtPtr + sizeof(MV_802_3_HEADER));
+	pBuf->dataSize = MV_16BIT_BE(pIpHdr->totalLength) + sizeof(MV_802_3_HEADER);
+	/* after next command, pBuf->bufVirtPtr will point to ESP */
+	pBuf->bufVirtPtr += MV_NFP_SEC_ESP_OFFSET;
+	pBuf->bufPhysAddr += MV_NFP_SEC_ESP_OFFSET;
+	pBuf->dataSize -= MV_NFP_SEC_ESP_OFFSET;
+
+	pBuf->bufAddrShift -= MV_NFP_SEC_ESP_OFFSET;
+	pCesaMbuf->pFrags = pPktInfo->pFrags;
+	pCesaMbuf->numFrags = 1;
+	pCesaMbuf->mbufSize = pBuf->dataSize;
+
+	pCesaMbuf->pFrags->bufSize = pBuf->dataSize;
+
+	pCesaCmd->pReqPrv = (MV_VOID *)pCesaPriv;
+	pCesaCmd->sessionId = pSAEntry->sid;
+	pCesaCmd->pSrc = pCesaMbuf;
+	pCesaCmd->pDst = pCesaMbuf;
+	pCesaCmd->skipFlush = MV_TRUE;
+
+	/* Assume ESP */
+	pCesaCmd->cryptoOffset = sizeof(MV_ESP_HEADER) + pSAEntry->ivSize;
+	pCesaCmd->cryptoLength =  pBuf->dataSize - (sizeof(MV_ESP_HEADER)
+				  + pSAEntry->ivSize + pSAEntry->digestSize);
+	pCesaCmd->ivFromUser = 0; /* relevant for encode only */
+	pCesaCmd->ivOffset = sizeof(MV_ESP_HEADER);
+	pCesaCmd->macOffset = 0;
+	pCesaCmd->macLength = pBuf->dataSize - pSAEntry->digestSize;
+	if ((pCesaCmd->digestOffset != 0) && ((pCesaCmd->digestOffset%4)))  {
+		printk(KERN_INFO "pBuf->dataSize=%d pSAEntry->digestSize=%d in %s\n",
+			pBuf->dataSize, pSAEntry->digestSize, __func__);
+		printk(KERN_INFO "pCesaCmd->digestOffset=%d in %s\n",
+			pCesaCmd->digestOffset, __func__);
+	}
+	pCesaCmd->digestOffset = pBuf->dataSize - pSAEntry->digestSize ;
+
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+	printCesaCmd(pCesaCmd);
+	printCesaMbuf(pCesaMbuf);
+#endif
+
+	disable_irq(CESA_IRQ(channel));
+
+	status = mvCesaAction(channel, pCesaCmd);
+	enable_irq(CESA_IRQ(channel));
+	if (status != MV_OK) {
+		pSAEntry->stats.rejected++;
+		mvOsPrintf("%s: mvCesaAction failed %d\n", __func__, status);
+	}
+	return status;
+}
+
+inline MV_STATUS mvSecEspProcess_1(struct eth_pbuf *pPkt, MV_PKT_INFO *pPktInfo,
+						  MV_NFP_SEC_SA_ENTRY *pSAEntry, struct eth_port *newpp,
+						  MV_U8 channel, int inPort)
+
+{
+	MV_CESA_COMMAND	*pCesaCmd;
+	MV_CESA_MBUF *pCesaMbuf;
+	MV_NFP_SEC_CESA_PRIV_L2FW *pCesaPriv;
+	MV_STATUS status;
+	MV_IP_HEADER *pIpHdr;
+	MV_BUF_INFO  *pBuf;
+	pCesaCmd  = &cesaCmdArray_1[cesaCmdIndx_1];
+	pCesaMbuf = &cesaMbufArray_1[cesaCmdIndx_1];
+	cesaCmdIndx_1++;
+	cesaCmdIndx_1 %= CESA_DEF_REQ_SIZE;
+	pCesaPriv = &cesaPrivArray_1[cesaPrivIndx_1++];
+	cesaPrivIndx_1 = cesaPrivIndx_1%(CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE);
+
+	pCesaPriv->pPktInfo = pPktInfo;
+	pCesaPriv->pSaEntry = pSAEntry;
+	pCesaPriv->pCesaCmd = pCesaCmd;
+
+	pCesaPriv->pPkt   = pPkt;
+	pCesaPriv->ifout  = newpp->port;
+	pCesaPriv->inPort = inPort;
+	/*
+	 *  Fix, encrypt/decrypt the IP payload only, --BK 20091027
+	 */
+	pBuf = pPktInfo->pFrags;
+	pIpHdr = (MV_IP_HEADER *)(pBuf->bufVirtPtr + sizeof(MV_802_3_HEADER));
+	pBuf->dataSize = MV_16BIT_BE(pIpHdr->totalLength) + sizeof(MV_802_3_HEADER);
+	/* after next command, pBuf->bufVirtPtr will point to ESP */
+	pBuf->bufVirtPtr += MV_NFP_SEC_ESP_OFFSET;
+	pBuf->bufPhysAddr += MV_NFP_SEC_ESP_OFFSET;
+	pBuf->dataSize -= MV_NFP_SEC_ESP_OFFSET;
+	pBuf->bufAddrShift -= MV_NFP_SEC_ESP_OFFSET;
+	pCesaMbuf->pFrags = pPktInfo->pFrags;
+	pCesaMbuf->numFrags = 1;
+	pCesaMbuf->mbufSize = pBuf->dataSize;
+	pCesaMbuf->pFrags->bufSize = pBuf->dataSize;
+
+	pCesaCmd->pReqPrv = (MV_VOID *)pCesaPriv;
+	pCesaCmd->sessionId = pSAEntry->sid;
+	pCesaCmd->pSrc = pCesaMbuf;
+	pCesaCmd->pDst = pCesaMbuf;
+	pCesaCmd->skipFlush = MV_TRUE;
+
+	/* Assume ESP */
+	pCesaCmd->cryptoOffset = sizeof(MV_ESP_HEADER) + pSAEntry->ivSize;
+	pCesaCmd->cryptoLength =  pBuf->dataSize - (sizeof(MV_ESP_HEADER)
+				  + pSAEntry->ivSize + pSAEntry->digestSize);
+	pCesaCmd->ivFromUser = 0; /* relevant for encode only */
+	pCesaCmd->ivOffset = sizeof(MV_ESP_HEADER);
+	pCesaCmd->macOffset = 0;
+	pCesaCmd->macLength = pBuf->dataSize - pSAEntry->digestSize;
+	if ((pCesaCmd->digestOffset != 0) && ((pCesaCmd->digestOffset%4)))  {
+		printk(KERN_INFO "pBuf->dataSize=%d pSAEntry->digestSize=%d in %s\n",
+			pBuf->dataSize, pSAEntry->digestSize, __func__);
+		printk(KERN_INFO "pCesaCmd->digestOffset=%d in %s\n",
+			pCesaCmd->digestOffset, __func__);
+	}
+	pCesaCmd->digestOffset = pBuf->dataSize - pSAEntry->digestSize ;
+
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+	printCesaCmd(pCesaCmd);
+	printCesaMbuf(pCesaMbuf);
+#endif
+	disable_irq(CESA_IRQ(channel));
+	
+	status = mvCesaAction(channel, pCesaCmd);
+	enable_irq(CESA_IRQ(channel));
+	if (status != MV_OK) {
+		pSAEntry->stats.rejected++;
+		mvOsPrintf("%s: mvCesaAction failed %d\n", __func__, status);
+	}
+
+	return status;
+}
+
+
+
+inline MV_STATUS mvSecOutgoing(struct eth_pbuf *pkt, MV_PKT_INFO *pPktInfo,
+						MV_NFP_SEC_SA_ENTRY *pSAEntry, struct eth_port *new_pp,
+						int inPort, MV_U8 chan)
+{
+	MV_U8 *pTmp;
+	MV_U32 cryptoSize, encBlockMod, dSize;
+	MV_BUF_INFO *pBuf = pPktInfo->pFrags;
+	/* CESA Q is full drop. */
+	if (cesaReqResources[chan] <= 1) {
+		counterNoResources[inPort]++;
+		return MV_DROPPED;
+	}
+	cryptoSize = pBuf->dataSize - sizeof(MV_802_3_HEADER);
+
+	/* Align buffer address to beginning of new packet - TBD handle VLAN tag, LLC */
+	dSize = pSAEntry->ivSize + sizeof(MV_ESP_HEADER) + sizeof(MV_IP_HEADER);
+	pBuf->bufVirtPtr -= dSize;
+	pBuf->bufPhysAddr -= dSize;
+	pBuf->dataSize += dSize;
+	pBuf->bufAddrShift += dSize;
+
+	encBlockMod = (cryptoSize % MV_NFP_SEC_ENC_BLOCK_SIZE);
+	/* leave space for padLen + Protocol */
+	if (encBlockMod > 14) {
+		encBlockMod =  MV_NFP_SEC_ENC_BLOCK_SIZE - encBlockMod;
+		encBlockMod += MV_NFP_SEC_ENC_BLOCK_SIZE;
+	} else
+		encBlockMod =  MV_NFP_SEC_ENC_BLOCK_SIZE - encBlockMod;
+	/* expected frame size */
+	dSize = pBuf->dataSize + encBlockMod + pSAEntry->digestSize;
+
+	pBuf->dataSize += encBlockMod;
+	pTmp = pBuf->bufVirtPtr + pBuf->dataSize;
+	memset(pTmp - encBlockMod, 0, encBlockMod - 2);
+	*((MV_U8 *)(pTmp-2)) = (MV_U8)(encBlockMod-2);
+	*((MV_U8 *)(pTmp-1)) = (MV_U8)4;
+
+	pBuf->dataSize += pSAEntry->digestSize;
+
+	mvNfpSecBuildEspHdr(pPktInfo, pSAEntry);
+	mvNfpSecBuildIPTunnel(pPktInfo, pSAEntry);
+	mvNfpSecBuildMac(pPktInfo, pSAEntry);
+
+	/* flush & invalidate new MAC, IP, & ESP headers + old ip*/
+	dSize = pBuf->bufAddrShift + sizeof(MV_IP_HEADER) + sizeof(MV_802_3_HEADER);
+
+	if (chan == 0)
+	  return mvSecEspProcess_0(pkt, pPktInfo, pSAEntry, new_pp, chan, inPort);
+	else
+	  return mvSecEspProcess_1(pkt, pPktInfo, pSAEntry, new_pp, chan, inPort);
+}
+
+
+static inline MV_STATUS handleEsp(struct eth_pbuf *pkt, struct neta_rx_desc *rx_desc,
+							struct eth_port  *new_pp, int inPort, MV_U8 chan)
+{
+	if (chan == 0) {
+		pBufInfoArray_0[cesaCmdIndx_0].bufAddrShift = 0;
+		pBufInfoArray_0[cesaCmdIndx_0].dataSize    = pkt->bytes;
+
+		pBufInfoArray_0[cesaCmdIndx_0].bufSize     = pkt->bytes;
+		pBufInfoArray_0[cesaCmdIndx_0].bufVirtPtr  = pkt->pBuf + pkt->offset + MV_ETH_MH_SIZE;
+
+		pBufInfoArray_0[cesaCmdIndx_0].bufPhysAddr = mvOsIoVirtToPhy(NULL, pkt->pBuf + pkt->offset + MV_ETH_MH_SIZE);
+		pBufInfoArray_0[cesaCmdIndx_0].memHandle   = 0;
+
+		pPktInfoNewArray_0[cesaCmdIndx_0].pFrags = &pBufInfoArray_0[cesaCmdIndx_0];
+		pPktInfoNewArray_0[cesaCmdIndx_0].numFrags = 1;
+	} else {
+		pBufInfoArray_1[cesaCmdIndx_1].bufAddrShift = 0;
+		pBufInfoArray_1[cesaCmdIndx_1].dataSize    = pkt->bytes;
+
+		pBufInfoArray_1[cesaCmdIndx_1].bufSize     = pkt->bytes;
+		pBufInfoArray_1[cesaCmdIndx_1].bufVirtPtr  = pkt->pBuf + pkt->offset + MV_ETH_MH_SIZE;
+
+		pBufInfoArray_1[cesaCmdIndx_1].bufPhysAddr = mvOsIoVirtToPhy(NULL, pkt->pBuf + pkt->offset + MV_ETH_MH_SIZE);
+		pBufInfoArray_1[cesaCmdIndx_1].memHandle   = 0;
+
+		pPktInfoNewArray_1[cesaCmdIndx_1].pFrags = &pBufInfoArray_1[cesaCmdIndx_1];
+		pPktInfoNewArray_1[cesaCmdIndx_1].numFrags = 1;
+	}
+
+	if (chan == 0)
+		return mvSecOutgoing(pkt, &pPktInfoNewArray_0[cesaCmdIndx_0], &sa, new_pp, inPort, chan);
+	else
+		return mvSecOutgoing(pkt, &pPktInfoNewArray_1[cesaCmdIndx_1], &sa, new_pp, inPort, chan);
+}
+
+void printkPkt(struct eth_pbuf *pkt)
+{
+	int i;
+	MV_IP_HEADER  *pIpHdr  = (MV_IP_HEADER *)(pkt->pBuf+16);
+	MV_ESP_HEADER *pEspHdr = (MV_ESP_HEADER *)(pkt->pBuf+16+sizeof(MV_IP_HEADER));
+	printk(KERN_INFO "****************** \n");
+	printk(KERN_INFO "printkPkt, pkt->bytes=%d \n", pkt->bytes);
+	for (i = 0; i < pkt->bytes; i++) {
+		printk(KERN_INFO "[%d]=%x", i, pkt->pBuf[i]);
+		if (!(i%10) && (i > 1))
+			printk(KERN_INFO "\n");
+	}
+	printk(KERN_INFO "\n");
+	printIpHdr(pIpHdr);
+
+	printEspHdr(pEspHdr);
+	printk(KERN_INFO "****************** \n");
+}
+
+
+
+static inline MV_STATUS mv_eth_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp, int withXor,
+									   struct neta_rx_desc *rx_desc)
+{
+	struct neta_tx_desc *tx_desc;
+	u32 tx_cmd = 0;
+	struct tx_queue *txq_ctrl;
+	/* assigning different txq for each rx port , to avoid waiting on the
+	same txq lock when traffic on several rx ports are destined to the same
+	outgoing interface */
+	int txq = 0;
+	read_lock(&pp->rwlock);
+	txq_ctrl = &pp->txq_ctrl[pp->txp * CONFIG_MV_ETH_TXQ + txq];
+	spin_lock(&txq_ctrl->queue_lock);
+
+	if (txq_ctrl->txq_count >= mv_ctrl_txdone)
+		mv_eth_txq_done(pp, txq_ctrl);
+	/* Get next descriptor for tx, single buffer, so FIRST & LAST */
+	tx_desc = mv_eth_tx_desc_get(txq_ctrl, 1);
+	if (tx_desc == NULL) {
+		spin_unlock(&txq_ctrl->queue_lock);
+		read_unlock(&pp->rwlock);
+		/* No resources: Drop */
+		pp->dev->stats.tx_dropped++;
+		if (withXor)
+			xorReady();
+		return MV_DROPPED;
+	}
+	txq_ctrl->txq_count++;
+
+	tx_cmd |= NETA_TX_BM_ENABLE_MASK | NETA_TX_BM_POOL_ID_MASK(pkt->pool);
+	txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = (u32) NULL;
+	mv_eth_shadow_inc_put(txq_ctrl);
+
+	tx_desc->command = tx_cmd | NETA_TX_L4_CSUM_NOT |
+		NETA_TX_FLZ_DESC_MASK | NETA_TX_F_DESC_MASK
+		| NETA_TX_L_DESC_MASK |
+		NETA_TX_PKT_OFFSET_MASK(pkt->offset + MV_ETH_MH_SIZE);
+
+	tx_desc->dataSize    = pkt->bytes;
+	tx_desc->bufPhysAddr = pkt->physAddr;
+
+	mv_eth_tx_desc_flush(tx_desc);
+
+	if (withXor) {
+		if (!xorReady()) {
+			mvOsPrintf("MV_DROPPED in %s\n", __func__);
+			return MV_DROPPED;
+		}
+	}
+	mvNetaTxqPendDescAdd(pp->port, pp->txp, 0, 1);
+
+	spin_unlock(&txq_ctrl->queue_lock);
+	read_unlock(&pp->rwlock);
+
+	return MV_OK;
+}
+
+static inline MV_STATUS mv_eth_cesa_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp)
+{
+	struct neta_tx_desc *tx_desc;
+	u32 tx_cmd = 0;
+	struct tx_queue *txq_ctrl;
+
+	/* assigning different txq for each rx port , to avoid waiting on the
+	same txq lock when traffic on several rx ports are destined to the same
+	outgoing interface */
+	int txq = 0;
+	txq_ctrl = &pp->txq_ctrl[pp->txp * CONFIG_MV_ETH_TXQ + txq];
+	spin_lock(&txq_ctrl->queue_lock);
+
+	if (txq_ctrl->txq_count >= mv_ctrl_txdone)
+		mv_eth_txq_done(pp, txq_ctrl);
+	/* Get next descriptor for tx, single buffer, so FIRST & LAST */
+	tx_desc = mv_eth_tx_desc_get(txq_ctrl, 1);
+	if (tx_desc == NULL) {
+		/* printk("tx_desc == NULL pp->port=%d in %s\n", pp->port, ,__func__); */
+		spin_unlock(&txq_ctrl->queue_lock);
+		/* No resources: Drop */
+		pp->dev->stats.tx_dropped++;
+		return MV_DROPPED;
+	}
+	txq_ctrl->txq_count++;
+
+	tx_cmd |= NETA_TX_BM_ENABLE_MASK | NETA_TX_BM_POOL_ID_MASK(pkt->pool);
+	txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = (u32) NULL;
+	mv_eth_shadow_inc_put(txq_ctrl);
+
+	tx_desc->command = tx_cmd | NETA_TX_L4_CSUM_NOT |
+		NETA_TX_FLZ_DESC_MASK | NETA_TX_F_DESC_MASK
+		| NETA_TX_L_DESC_MASK |
+		NETA_TX_PKT_OFFSET_MASK(pkt->offset + MV_ETH_MH_SIZE);
+
+	tx_desc->dataSize    = pkt->bytes;
+	tx_desc->bufPhysAddr = pkt->physAddr;
+	mv_eth_tx_desc_flush(tx_desc);
+	mvNetaTxqPendDescAdd(pp->port, pp->txp, 0, 1);
+	spin_unlock(&txq_ctrl->queue_lock);
+	return MV_OK;
+}
+
+
+inline int mv_eth_rx_l2f(struct eth_port *pp, int rx_todo, int rxq)
+{
+	struct eth_port  *new_pp;
+	L2FW_RULE *l2fw_rule;
+	MV_NETA_RXQ_CTRL *rx_ctrl = pp->rxq_ctrl[rxq].q;
+	int rx_done, rx_filled;
+	struct neta_rx_desc *rx_desc;
+	u32 rx_status = MV_OK;
+	struct eth_pbuf *pkt;
+	struct eth_pbuf *newpkt = NULL;
+	struct bm_pool *pool;
+	MV_STATUS status = MV_OK;
+	struct eth_port_l2fw *ppl2fw = mv_eth_ports_l2fw[pp->port];
+	MV_IP_HEADER *pIph = NULL;
+	MV_U8 *pData;
+	int	ipOffset;
+	rx_done = mvNetaRxqBusyDescNumGet(pp->port, rxq);
+	mvOsCacheIoSync();
+	if (rx_todo > rx_done)
+		rx_todo = rx_done;
+	rx_done = 0;
+	rx_filled = 0;
+
+	/* Fairness NAPI loop */
+	while (rx_done < rx_todo) {
+#ifdef CONFIG_MV_ETH_RX_DESC_PREFETCH
+		rx_desc = mv_eth_rx_prefetch(pp, rx_ctrl, rx_done, rx_todo);
+		if (!rx_desc)
+			printk(KERN_INFO "rx_desc is NULL in %s\n", __func__);
+#else
+		rx_desc = mvNetaRxqNextDescGet(rx_ctrl);
+		mvOsCacheLineInv(NULL, rx_desc);
+		prefetch(rx_desc);
+#endif /* CONFIG_MV_ETH_RX_DESC_PREFETCH */
+
+		rx_done++;
+		rx_filled++;
+
+		pkt = (struct eth_pbuf *)rx_desc->bufCookie;
+		if (!pkt) {
+			printk(KERN_INFO "pkt is NULL in ; rx_done=%d %s\n", rx_done, __func__);
+			return rx_done;
+		}
+
+		pool = &mv_eth_pool[pkt->pool];
+		rx_status = rx_desc->status;
+		if (((rx_status & NETA_RX_FL_DESC_MASK) != NETA_RX_FL_DESC_MASK) ||
+			(rx_status & NETA_RX_ES_MASK)) {
+			STAT_ERR(pp->stats.rx_error++);
+
+			if (pp->dev)
+				pp->dev->stats.rx_errors++;
+
+			mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+			continue;
+		}
+
+		pkt->bytes = rx_desc->dataSize - (MV_ETH_CRC_SIZE + MV_ETH_MH_SIZE);
+
+		pData = pkt->pBuf + pkt->offset;
+		if ((rx_desc->status & ETH_RX_VLAN_TAGGED_FRAME_MASK))
+			ipOffset = MV_ETH_MH_SIZE + sizeof(MV_802_3_HEADER) + MV_VLAN_HLEN;
+		else
+			ipOffset = MV_ETH_MH_SIZE + sizeof(MV_802_3_HEADER);
+		pIph = (MV_IP_HEADER *)(pData + ipOffset);
+		if (pIph == NULL) {
+			printk(KERN_INFO "pIph==NULL in %s\n", __func__);
+			continue;
+		}
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+		if (pIph) {
+			printk(KERN_INFO "%u.%u.%u.%u->%u.%u.%u.%u in %s\n", NIPQUAD(pIph->srcIP), NIPQUAD(pIph->dstIP), __func__);
+		} else
+			printk(KERN_INFO "pIph is NULL in %s\n", __func__);
+#endif
+		if (espEnabled)
+			new_pp  = mv_eth_ports[ppl2fw->txPort];
+		else {
+			 l2fw_rule = l2fw_lookup(pIph->srcIP, pIph->dstIP);
+
+			 if (!l2fw_rule) {
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+				printk(KERN_INFO "l2fw_lookup() failed in %s\n", __func__);
+#endif
+				mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+				continue;
+			 }
+
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+				printk(KERN_INFO "l2fw_lookup() is ok l2fw_rule->port=%d in %s\n", l2fw_rule->port, __func__);
+#endif
+			new_pp  = mv_eth_ports[l2fw_rule->port];
+			}
+
+		switch (ppl2fw->cmd) {
+		case TX_AS_IS:
+					if (espEnabled) {
+						spin_lock(&cesa_lock[pp->cesaChan]);
+						status = handleEsp(pkt, rx_desc, new_pp, pp->port, pp->cesaChan);						
+						spin_unlock(&cesa_lock[pp->cesaChan]);						
+					}
+				else
+					status = mv_eth_l2fw_tx(pkt, new_pp, 0, rx_desc);
+				break;
+
+		case SWAP_MAC:
+				mvOsCacheLineInv(NULL, pkt->pBuf + pkt->offset);
+				l2fw_swap_mac(pkt);
+				mvOsCacheLineFlush(NULL, pkt->pBuf+pkt->offset);
+				status = mv_eth_l2fw_tx(pkt, new_pp, 0, rx_desc);
+				break;
+
+		case COPY_AND_SWAP:
+				if (pkt->bytes >= l2fw_xor_threshold) {
+					newpkt = eth_l2fw_copy_packet_withXor(pkt);
+					if (newpkt)
+						status = mv_eth_l2fw_tx(newpkt, new_pp, 1, rx_desc);
+					else
+						status = MV_ERROR;
+				} else {
+						newpkt = eth_l2fw_copy_packet_withoutXor(pkt);
+						if (newpkt)
+							status = mv_eth_l2fw_tx(newpkt, new_pp, 0, rx_desc);
+						else
+							status = MV_ERROR;
+				}
+		}
+		if (status == MV_OK) {
+			mvOsCacheLineInv(NULL, rx_desc);
+			/* we do not need the pkt , we do not do anything with it*/
+			if  ((ppl2fw->cmd	== COPY_AND_SWAP) && !(espEnabled))
+				mv_eth_pool_put(pool, pkt);
+			continue;
+		} else if (status == MV_DROPPED) {
+			mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+			if ((ppl2fw->cmd	== COPY_AND_SWAP) && !(espEnabled))
+				mv_eth_pool_put(pool, newpkt);
+
+			continue;
+		} else if (status == MV_ERROR) {
+			printk(KERN_INFO "MV_ERROR in %s\n", __func__);
+			mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+		}
+
+	} /* of while */
+	/* Update RxQ management counters */
+	mvOsCacheIoSync();
+
+	mvNetaRxqDescNumUpdate(pp->port, rxq, rx_done, rx_filled);
+
+	return rx_done;
+}
+
+static irqreturn_t nfp_sec_interrupt_handler_0(int irq, void *arg)
+{
+	MV_CESA_RESULT  	result;
+	MV_STATUS           status;
+	MV_U8 chan = 0;
+
+    MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+
+	while (1) {
+	/* Get Ready requests */
+
+	status = mvCesaReadyGet(chan, &result);
+	if (status != MV_OK)
+		break;
+	
+	nfp_sec_complete_out((unsigned long)((MV_NFP_SEC_CESA_PRIV_L2FW *)result.pReqPrv));
+	}
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t nfp_sec_interrupt_handler_1(int irq, void *arg)
+{
+	MV_CESA_RESULT  	result;
+	MV_STATUS           status;
+	MV_U8 chan = 1;
+    MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+	while (1) {
+	/* Get Ready requests */
+	status = mvCesaReadyGet(chan, &result);
+	if (status != MV_OK)
+		break;
+	
+	nfp_sec_complete_out((unsigned long)((MV_NFP_SEC_CESA_PRIV_L2FW *)result.pReqPrv));
+	}
+
+	return IRQ_HANDLED;
+}
+
+
+
+MV_STATUS my_mvSysCesaInit(int numOfSession, int queueDepth, void *osHandle)
+{
+	MV_CESA_HAL_DATA halData;
+	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+	MV_STATUS status;
+	MV_U8 chan;
+
+	status = mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1);
+
+	if (status == MV_OK) {
+		for (chan = 0; chan < MV_CESA_CHANNELS; chan++) {
+			status = mvCesaTdmaWinInit(chan, addrWinMap);
+			if (status != MV_OK) {
+				mvOsPrintf("Error, unable to initialize CESA windows for channel(%d)\n", chan);
+				break;
+			}
+			halData.sramPhysBase[chan] = (MV_ULONG)mv_crypto_virt_base_get(chan);
+			halData.sramVirtBase[chan] = (MV_U8 *)mv_crypto_virt_base_get(chan);
+			halData.sramOffset[chan] = 0;
+		}
+
+		if (status == MV_OK) {
+		halData.ctrlModel = mvCtrlModelGet();
+		halData.ctrlRev = mvCtrlRevGet();
+			status = mvCesaHalInit(numOfSession, queueDepth,
+					osHandle, &halData);
+	}
+	}
+
+	return status;
+}
+
+void cesaStart(void)
+{
+	int bufNum, bufSize;
+	int i, j, idx;
+	MV_CESA_MBUF *pMbufSrc_0, *pMbufDst_0;
+	MV_BUF_INFO *pFragsSrc_0, *pFragsDst_0;
+	char *pBuf_0;
+
+	MV_CESA_MBUF *pMbufSrc_1, *pMbufDst_1;
+	MV_BUF_INFO *pFragsSrc_1, *pFragsDst_1;
+	char *pBuf_1;
+
+	printk(KERN_INFO "in %s\n", __func__);
+
+	cesaCmdArray_0 = 	mvOsMalloc(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
+
+	if (cesaCmdArray_0 == NULL) {
+		mvOsPrintf("Can't allocate %d bytes of memory\n",
+			   (int)(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE));
+		return;
+	}
+	memset(cesaCmdArray_0, 0, sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
+	/* CESA_DEF_BUF_NUM */
+	bufNum    =  1;
+	/* CESA_DEF_BUF_SIZE */
+	bufSize   = 1500;
+
+	pMbufSrc_0  = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	pFragsSrc_0 = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	pMbufDst_0  = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	pFragsDst_0 = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	if ((pMbufSrc_0 == NULL) || (pFragsSrc_0 == NULL) ||
+		(pMbufDst_0 == NULL) || (pFragsDst_0 == NULL)) {
+		mvOsPrintf(" Can't malloc Src and Dst pMbuf and pFrags structures.\n");
+		return;
+	}
+
+	memset(pMbufSrc_0,  0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	memset(pFragsSrc_0, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	memset(pMbufDst_0,  0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	memset(pFragsDst_0, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	idx = 0;
+	for (i = 0; i < CESA_DEF_REQ_SIZE; i++) {
+		pBuf_0 = mvOsIoCachedMalloc(cesaOSHandle, bufSize * bufNum * 2,
+					  &cesaBufs_0[i].bufPhysAddr, &cesaBufs_0[i].memHandle);
+		if (pBuf_0 == NULL) {
+			mvOsPrintf("testStart: Can't malloc %d bytes for pBuf\n", bufSize * bufNum * 2);
+			return;
+		}
+
+		memset(pBuf_0, 0, bufSize * bufNum * 2);
+		mvOsCacheFlush(cesaOSHandle, pBuf_0, bufSize * bufNum * 2);
+		if (pBuf_0 == NULL) {
+			mvOsPrintf("Can't allocate %d bytes for req_%d buffers\n",
+				   bufSize * bufNum * 2, i);
+			return;
+		}
+
+		cesaBufs_0[i].bufVirtPtr = (MV_U8 *) pBuf_0;
+		cesaBufs_0[i].bufSize = bufSize * bufNum * 2;
+
+		cesaCmdArray_0[i].pSrc = &pMbufSrc_0[i];
+		cesaCmdArray_0[i].pSrc->pFrags = &pFragsSrc_0[idx];
+		cesaCmdArray_0[i].pSrc->numFrags = bufNum;
+		cesaCmdArray_0[i].pSrc->mbufSize = 0;
+
+		cesaCmdArray_0[i].pDst = &pMbufDst_0[i];
+		cesaCmdArray_0[i].pDst->pFrags = &pFragsDst_0[idx];
+		cesaCmdArray_0[i].pDst->numFrags = bufNum;
+		cesaCmdArray_0[i].pDst->mbufSize = 0;
+
+		for (j = 0; j < bufNum; j++) {
+			cesaCmdArray_0[i].pSrc->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf_0;
+			cesaCmdArray_0[i].pSrc->pFrags[j].bufSize = bufSize;
+			pBuf_0 += bufSize;
+			cesaCmdArray_0[i].pDst->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf_0;
+
+			cesaCmdArray_0[i].pDst->pFrags[j].bufSize = bufSize;
+			pBuf_0 += bufSize;
+		}
+		idx += bufNum;
+	}
+
+	cesaMbufArray_0 = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	if (cesaMbufArray_0 == NULL) {
+		mvOsPrintf("Can't allocate %d bytes of memory\n",
+			   (int)(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE));
+		return;
+	}
+	memset(cesaMbufArray_0, 0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+
+	cesaPrivArray_0 = mvOsMalloc(sizeof(MV_NFP_SEC_CESA_PRIV_L2FW) * (CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE));
+	memset(cesaPrivArray_0, 0, sizeof(MV_NFP_SEC_CESA_PRIV_L2FW) * (CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE));
+
+	/* second engine */
+	cesaCmdArray_1 = 	mvOsMalloc(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
+
+	if (cesaCmdArray_1 == NULL) {
+		mvOsPrintf("Can't allocate %d bytes of memory\n",
+			   (int)(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE));
+		return;
+	}
+	memset(cesaCmdArray_1, 0, sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
+
+	/* CESA_DEF_BUF_NUM */
+	bufNum    =  1;
+	/* CESA_DEF_BUF_SIZE */
+	bufSize   = 1500;
+
+	pMbufSrc_1  = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	pFragsSrc_1 = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	pMbufDst_1  = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	pFragsDst_1 = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	if ((pMbufSrc_1 == NULL) || (pFragsSrc_1 == NULL) || (pMbufDst_1 == NULL)
+		|| (pFragsDst_1 == NULL)) {
+		mvOsPrintf(" Can't malloc Src and Dst pMbuf and pFrags structures.\n");
+		return;
+	}
+
+	memset(pMbufSrc_1,  0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	memset(pFragsSrc_1, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	memset(pMbufDst_1,  0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	memset(pFragsDst_1, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	idx = 0;
+	for (i = 0; i < CESA_DEF_REQ_SIZE; i++) {
+		pBuf_1 = mvOsIoCachedMalloc(cesaOSHandle, bufSize * bufNum * 2,
+					  &cesaBufs_1[i].bufPhysAddr, &cesaBufs_1[i].memHandle);
+		if (pBuf_1 == NULL) {
+			mvOsPrintf("testStart: Can't malloc %d bytes for pBuf\n", bufSize * bufNum * 2);
+			return;
+		}
+
+		memset(pBuf_1, 0, bufSize * bufNum * 2);
+		mvOsCacheFlush(cesaOSHandle, pBuf_1, bufSize * bufNum * 2);
+		if (pBuf_1 == NULL) {
+			mvOsPrintf("Can't allocate %d bytes for req_%d buffers\n",
+				   bufSize * bufNum * 2, i);
+			return;
+		}
+
+		cesaBufs_1[i].bufVirtPtr = (MV_U8 *) pBuf_1;
+		cesaBufs_1[i].bufSize = bufSize * bufNum * 2;
+
+		cesaCmdArray_1[i].pSrc = &pMbufSrc_1[i];
+		cesaCmdArray_1[i].pSrc->pFrags = &pFragsSrc_1[idx];
+		cesaCmdArray_1[i].pSrc->numFrags = bufNum;
+		cesaCmdArray_1[i].pSrc->mbufSize = 0;
+
+		cesaCmdArray_1[i].pDst = &pMbufDst_1[i];
+		cesaCmdArray_1[i].pDst->pFrags = &pFragsDst_1[idx];
+		cesaCmdArray_1[i].pDst->numFrags = bufNum;
+		cesaCmdArray_1[i].pDst->mbufSize = 0;
+
+		for (j = 0; j < bufNum; j++) {
+			cesaCmdArray_1[i].pSrc->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf_1;
+			cesaCmdArray_1[i].pSrc->pFrags[j].bufSize = bufSize;
+			pBuf_1 += bufSize;
+			cesaCmdArray_1[i].pDst->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf_1;
+
+			cesaCmdArray_1[i].pDst->pFrags[j].bufSize = bufSize;
+			pBuf_1 += bufSize;
+		}
+		idx += bufNum;
+	}
+
+	cesaMbufArray_1 = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	if (cesaMbufArray_1 == NULL) {
+		mvOsPrintf("Can't allocate %d bytes of memory\n",
+			   (int)(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE));
+		return;
+	}
+	memset(cesaMbufArray_1, 0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+
+	cesaPrivArray_1 = mvOsMalloc(sizeof(MV_NFP_SEC_CESA_PRIV_L2FW) * (CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE));
+	memset(cesaPrivArray_1, 0, sizeof(MV_NFP_SEC_CESA_PRIV_L2FW) * (CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE));
+
+	pPktInfoNewArray_0 = mvOsMalloc(sizeof(MV_PKT_INFO) * MV_NFP_SEC_REQ_Q_SIZE);
+
+	if (!pPktInfoNewArray_0) {
+		printk(KERN_INFO "mvOsMalloc() failed in %s\n", __func__);
+		return;
+	}
+
+	pBufInfoArray_0 = mvOsMalloc(sizeof(MV_BUF_INFO) * MV_NFP_SEC_REQ_Q_SIZE);
+	if (!pBufInfoArray_0) {
+		printk(KERN_INFO "could not allocate MV_BUF_INFO in %s\n", __func__);
+		return;
+	}
+
+	pPktInfoNewArray_1 = mvOsMalloc(sizeof(MV_PKT_INFO) * MV_NFP_SEC_REQ_Q_SIZE);
+
+	if (!pPktInfoNewArray_1) {
+		printk(KERN_INFO "mvOsMalloc() failed in %s\n", __func__);
+		return;
+	}
+	pBufInfoArray_1 = mvOsMalloc(sizeof(MV_BUF_INFO) * MV_NFP_SEC_REQ_Q_SIZE);
+	if (!pBufInfoArray_0) {
+		printk(KERN_INFO "could not allocate MV_BUF_INFO in %s\n", __func__);
+		return;
+	}
+	printk(KERN_INFO "start finished in %s\n", __func__);
+}
+
+
+static int cesa_init(void)
+{
+	u8 chan = 0;
+	int i;
+	const char *irq_str[] = {"cesa0", "cesa1"};
+	printk(KERN_INFO "in %s\n", __func__);
+	for (i = 0; i < 2; i++)
+		spin_lock_init(&cesa_lock[i]);
+	if (mvCtrlPwrClckGet(CESA_UNIT_ID, 0) == MV_FALSE)
+		return 0;
+	if (MV_OK != my_mvSysCesaInit(1, 256, NULL)) {
+		printk(KERN_INFO "%s,%d: mvCesaInit Failed. \n", __FILE__, __LINE__);
+		return EINVAL;
+	}
+
+	/* clear and unmask Int */
+	MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+	MV_REG_WRITE(MV_CESA_ISR_MASK_REG(chan), MV_CESA_CAUSE_ACC_DMA_MASK);
+	if (request_irq(CESA_IRQ(0), nfp_sec_interrupt_handler_0,
+							(IRQF_DISABLED) , irq_str[chan], NULL)) {
+				printk(KERN_INFO "%s,%d: cannot assign irq %x\n", __FILE__, __LINE__, CESA_IRQ(chan));
+		return EINVAL;
+	}
+
+	chan = 1;
+	MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+	MV_REG_WRITE(MV_CESA_ISR_MASK_REG(chan), MV_CESA_CAUSE_ACC_DMA_MASK);
+
+	if (request_irq(CESA_IRQ(1), nfp_sec_interrupt_handler_1,
+							(IRQF_DISABLED) , irq_str[chan], NULL)) {
+				printk(KERN_INFO "%s,%d: cannot assign irq %x\n", __FILE__, __LINE__, CESA_IRQ(chan));
+		return EINVAL;
+		}
+
+	atomic_set(&req_count[0], 0);
+	atomic_set(&req_count[1], 0);
+	mvOsPrintf("MV_CESA_TDMA_CTRL_REG address 0 %08x\n\n", MV_CESA_TDMA_CTRL_REG(0));
+	mvOsPrintf("MV_CESA_TDMA_CTRL_REG address 1 %08x\n\n", MV_CESA_TDMA_CTRL_REG(1));
+	mvOsPrintf("MV_CESA_TDMA_CTRL_REG(0)  %08x\n",
+		MV_REG_READ(MV_CESA_TDMA_CTRL_REG(0)));
+	mvOsPrintf("MV_CESA_TDMA_CTRL_REG(1)  %08x\n",
+		MV_REG_READ(MV_CESA_TDMA_CTRL_REG(1)));
+
+	memset(&sa, 0, sizeof(MV_NFP_SEC_SA_ENTRY));
+	sa.digestSize = MV_CESA_SHA1_DIGEST_SIZE;
+	sa.ivSize = MV_CESA_AES_BLOCK_SIZE;
+	sa.spi = 3;
+
+	sa.tunProt = MV_NFP_SEC_TUNNEL;
+	sa.encap   = MV_NFP_SEC_ESP;
+	sa.seqNum  = 4;
+	sa.tunnelHdr.sIp = 0x6400A8C0;
+	sa.tunnelHdr.dIp = 0x6401A8C0;
+	sa.tunnelHdr.outIfIndex = 0;
+	sa.lifeTime = 0;
+
+	sa.secOp = MV_NFP_SEC_ENCRYPT;
+	strcpy(sa.tunnelHdr.dstMac, "aabbccddeeff");
+	strcpy(sa.tunnelHdr.srcMac, "abacadaeafaa");
+
+	return 0;
+}
+
+
+#ifdef CONFIG_MV_ETH_L2FW
+int __devinit mv_l2fw_init(void)
+{
+	int size, port;
+	MV_U32 bytes;
+	MV_U32 regVal;
+	mv_eth_ports_l2fw_num = mvCtrlEthMaxPortGet();
+	mvOsPrintf("in %s: mv_eth_ports_l2fw_num=%d\n", __func__, mv_eth_ports_l2fw_num);
+	size = mv_eth_ports_l2fw_num * sizeof(struct eth_port_l2fw *);
+	mv_eth_ports_l2fw = mvOsMalloc(size);
+	if (!mv_eth_ports_l2fw)
+		goto oom;
+	memset(mv_eth_ports_l2fw, 0, size);
+	for (port = 0; port < mv_eth_ports_l2fw_num; port++) {
+		mv_eth_ports_l2fw[port] =
+			mvOsMalloc(sizeof(struct eth_port_l2fw));
+		if (!mv_eth_ports_l2fw[port])
+			goto oom1;
+		mv_eth_ports_l2fw[port]->cmd    = L2FW_DISABLE;
+		mv_eth_ports_l2fw[port]->txPort = -1;
+	}
+
+	bytes = sizeof(L2FW_RULE *) * L2FW_HASH_SIZE;
+	l2fw_jhash_iv = mvOsRand();
+
+	l2fw_hash = (L2FW_RULE **)mvOsMalloc(bytes);
+	if (l2fw_hash == NULL) {
+		mvOsPrintf("l2fw hash: not enough memory\n");
+		return MV_NO_RESOURCE;
+	}
+
+	mvOsMemset(l2fw_hash, 0, bytes);
+
+	mvOsPrintf("L2FW hash init %d entries, %d bytes\n", L2FW_HASH_SIZE, bytes);
+	regVal = 0;
+
+	cesa_init();
+	setXorDesc();
+	return 0;
+oom:
+	mvOsPrintf("%s: out of memory in L2FW initialization\n", __func__);
+oom1:
+	mvOsFree(mv_eth_ports_l2fw);
+	return -ENOMEM;
+
+}
+#endif
+
+module_init(mv_l2fw_init);
+
+MODULE_AUTHOR("Rami Rosen");
+MODULE_DESCRIPTION("l2fw module");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.h
new file mode 100644
index 0000000..666db47
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.h
@@ -0,0 +1,40 @@
+/* l2fw/mv_eth_l2fw.h */
+
+#ifndef L2FW_MV_ETH_L2FW_H
+#define L2FW_MV_ETH_L2FW_H
+
+#include "mvOs.h"
+#include "mv_neta/net_dev/mv_netdev.h"
+
+#define	L2FW_HASH_SIZE   (1 << 17)
+
+struct eth_port_l2fw {
+	int cmd;
+	int txPort;
+};
+
+typedef struct l2fw_rule {
+	MV_U32 srcIP;
+	MV_U32 dstIP;
+	MV_U8 port;
+	struct l2fw_rule *next;
+} L2FW_RULE;
+
+
+
+void l2fw(int cmd, int rx_port, int tx_port);
+void l2fw_xor(int threshold);
+int mv_eth_rx_l2f(struct eth_port *pp, int rx_todo, int rxq);
+MV_STATUS l2fw_add(MV_U32 srcIP, MV_U32 dstIP, int port);
+MV_STATUS l2fw_add_ip(const char *buf);
+void l2fw_esp_show(void);
+void l2fw_esp_set(int enableEsp);
+void l2fw_flush(void);
+void l2fw_dump(void);
+void l2fw_show_numHashEntries(void);
+void l2fw_stats(void);
+void l2fw_mode_show(void);
+void l2fw_mode(int mode);
+int l2fw_set_cesa_chan(int port, int cesaChan);
+
+#endif
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/Makefile
new file mode 100644
index 0000000..252b124
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/Makefile
@@ -0,0 +1,17 @@
+#
+# Makefile for the Marvell Gigabit Ethernet driver
+#
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+obj-$(CONFIG_MV_ETHERNET) += mv_netdev.o mv_ethernet.o mv_eth_sysfs.o
+obj-$(CONFIG_MV_ETH_PROC) += mv_eth_proc.o
+obj-$(CONFIG_MV_PON)      += mv_pon_sysfs.o
+obj-$(CONFIG_MV_ETH_SWITCH) +=  mv_eth_switch.o
+obj-$(CONFIG_MV_ETH_TOOL) += mv_eth_tool.o
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_proc.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_proc.c
new file mode 100644
index 0000000..691852e
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_proc.c
@@ -0,0 +1,520 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/stddef.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/reboot.h>
+#include <linux/pci.h>
+#include <linux/kdev_t.h>
+#include <linux/major.h>
+#include <linux/console.h>
+#include <linux/delay.h>
+#include <linux/ide.h>
+#include <linux/seq_file.h>
+
+#include <asm/system.h>
+#include <asm/dma.h>
+#include <asm/io.h>
+
+#include <linux/netdevice.h>
+#include "ctrlEnv/mvCtrlEnvLib.h"
+
+#include "gbe/mvNeta.h"
+#include "pmt/mvPmt.h"
+
+#ifdef CONFIG_MV_ETH_BM
+#include "bm/mvBm.h"
+#endif
+
+#ifdef CONFIG_MV_ETH_NFP
+#include "nfp_mgr/mv_nfp_mgr.h"
+#endif
+
+#include "mv_switch.h"
+
+#include "mv_eth_proc.h"
+#include "mv_netdev.h"
+
+
+//#define MV_DEBUG
+#ifdef MV_DEBUG
+#define DP printk
+#else
+#define DP(fmt,args...)
+#endif
+
+
+/* global variables from 'regdump' */
+static struct proc_dir_entry *mv_eth_tool;
+
+static unsigned int port = 0, txp=0, q = 0, status = 0;
+static unsigned int command = 0;
+static unsigned int value = 0;
+static char name[20] = {'\0', };
+
+
+#ifndef CONFIG_MV_ETH_PNC
+void run_com_rxq_type(void)
+{
+    void* port_hndl = mvNetaPortHndlGet(port);
+
+    if(port_hndl == NULL)
+        return;
+
+    switch(value) {
+	case PT_BPDU:
+		mvNetaBpduRxq(port, q);
+		break;
+	case PT_ARP:
+		mvNetaArpRxq(port, q);
+		break;
+	case PT_TCP:
+		mvNetaTcpRxq(port, q);
+		break;
+	case PT_UDP:
+		mvNetaUdpRxq(port, q);
+		break;
+	default:
+		printk("eth proc unknown packet type: value=%d\n", value);
+    }
+}
+#endif /* CONFIG_MV_ETH_PNC */
+
+
+void run_com_stats(const char *buffer)
+{
+    int scan_count;
+
+    scan_count = sscanf(buffer, STATUS_CMD_STRING, STATUS_SCANF_LIST);
+    if( scan_count != STATUS_LIST_LEN)
+    {
+	    printk("STATUS_CMD bad format %x != %x\n", scan_count, STATUS_LIST_LEN );
+	    return;
+    }
+	printk("\n\n#########################################################################################\n\n");
+
+	switch(status) {
+		case STS_PORT:
+            mv_eth_status_print();
+            mv_eth_port_status_print(port);
+			mvNetaPortStatus(port);
+			break;
+
+        case STS_PORT_MAC:
+            mv_eth_mac_show(port);
+        	break;
+
+		case STS_PORT_TXQ:
+			mvNetaTxqShow(port, txp, q, value);
+			break;
+
+		case STS_PORT_RXQ:
+			mvNetaRxqShow(port, q, value);
+			break;
+
+		case STS_PORT_TOS_MAP:
+			mv_eth_tos_map_show(port);
+			break;
+
+		case STS_TXP_WRR:
+			mvEthTxpWrrRegs(port, txp);
+			break;
+
+		case STS_PORT_REGS:
+			mvEthRegs(port);
+			mvEthPortRegs(port);
+			break;
+
+        case STS_NETA_REGS:
+			mvNetaPortRegs(port);
+        	break;
+
+#ifdef MV_ETH_GMAC_NEW
+        case STS_GMAC_REGS:
+            mvNetaGmacRegs(port);
+            break;
+#endif /* MV_ETH_GMAC_NEW */
+
+		case STS_TXP_REGS:
+			mvNetaTxpRegs(port, txp);
+			break;
+
+   		case STS_RXQ_REGS:
+			mvNetaRxqRegs(port, q);
+			break;
+
+   		case STS_TXQ_REGS:
+			mvNetaTxqRegs(port, txp, q);
+			break;
+
+#ifdef CONFIG_MV_ETH_PMT
+		case STS_PMT_REGS:
+			mvNetaPmtRegs(port, txp);
+			break;
+#endif /* CONFIG_MV_ETH_PMT */
+
+#ifdef CONFIG_MV_ETH_PNC
+        case STS_PNC_REGS:
+        	mvNetaPncRegs();
+        	break;
+#endif /* CONFIG_MV_ETH_PNC */
+
+#ifdef CONFIG_MV_ETH_HWF
+        case STS_HWF_REGS:
+            mvNetaHwfRxpRegs(port);
+			break;
+#endif /* CONFIG_MV_ETH_HWF */
+
+#ifdef CONFIG_MV_ETH_BM
+        case STS_BM_REGS:
+        	mvBmRegs();
+        	break;
+#endif /* CONFIG_MV_ETH_BM */
+
+		case STS_PORT_MIB:
+	    	mvEthPortCounters(port, txp);
+	    	mvEthPortRmonCounters(port, txp);
+			break;
+
+		case STS_PORT_STATS:
+			printk("  PORT %d: GET ETH PORT STATISTIC\n\n", port);
+			mv_eth_port_stats_print(port);
+            break;
+
+       	case STS_SWITCH_STATS:
+#ifdef CONFIG_MV_ETH_SWITCH
+            mv_eth_switch_status_print(port);
+            printk("\n");
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+#ifdef CONFIG_MV_INCLUDE_SWITCH
+   	    mv_switch_stats_print();
+#endif /* CONFIG_MV_INCLUDE_SWITCH */
+       	    break;
+
+	default:
+			printk(" Unknown status command \n");
+	}
+}
+
+int run_eth_com(const char *buffer) {
+
+    int scan_count;
+
+    scan_count = sscanf(buffer, ETH_CMD_STRING, ETH_SCANF_LIST);
+    if( scan_count != ETH_LIST_LEN) {
+	    printk("eth command bad format %x != %x\n", scan_count, ETH_LIST_LEN );
+	    return 1;
+    }
+    switch(command) {
+
+        case COM_TXDONE_Q:
+            mv_eth_ctrl_txdone(value);
+            break;
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+        case COM_SKB_RECYCLE:
+            mv_eth_ctrl_recycle(value);
+            break;
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+#ifdef CONFIG_MV_ETH_NFP
+        case COM_NFP_ENABLE:
+            mv_eth_ctrl_nfp(value);
+			nfp_mgr_enable(value);
+            break;
+#endif /* CONFIG_MV_ETH_NFP */
+
+	    default:
+            printk(" Unknown ETH command \n");
+    }
+    return 0;
+}
+
+/* NetDev commands */
+int run_netdev_cmd(const char *buffer) {
+    int 			    scan_count;
+	struct net_device* 	dev;
+
+        scan_count = sscanf(buffer, NETDEV_CMD_STRING, NETDEV_SCANF_LIST);
+
+        if( scan_count != NETDEV_LIST_LEN) {
+                printk("netdev command bad format %x != %x\n", scan_count, NETDEV_LIST_LEN );
+                return 1;
+        }
+
+        switch(command) {
+
+		case COM_TX_NOQUEUE:
+		    dev = dev_get_by_name(&init_net, name);
+                    if(dev != NULL)
+                    {
+			mv_eth_set_noqueue(dev, value);
+			dev_put(dev);
+		    }
+		    break;
+
+                case COM_NETDEV_STS:
+                    dev = dev_get_by_name(&init_net, name);
+                    if(dev != NULL)
+                    {
+			            mv_eth_netdev_print(dev);
+                        dev_put(dev);
+                    }
+                    break;
+
+#ifdef CONFIG_MV_ETH_SWITCH
+
+                case COM_NETDEV_PORT_ADD:
+                        dev = dev_get_by_name(&init_net, name);
+                        if(dev != NULL)
+                        {
+                            mv_eth_switch_port_add(dev, value);
+                            dev_put(dev);
+                        }
+                        break;
+
+                case COM_NETDEV_PORT_DEL:
+			dev = dev_get_by_name(&init_net, name);
+			if(dev != NULL)
+                        {
+                            mv_eth_switch_port_del(dev, value);
+                            dev_put(dev);
+                        }
+                        break;
+
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+                default:
+                        printk(" Unknown netdev command \n");
+        }
+        return 0;
+}
+
+/* Giga Port commands */
+int run_port_com(const char *buffer) {
+
+	int scan_count;
+    void*   port_hndl;
+
+	scan_count = sscanf(buffer, PORT_CMD_STRING, PORT_SCANF_LIST);
+
+	if( scan_count != PORT_LIST_LEN) {
+		printk("eth port command bad format %x != %x\n", scan_count, PORT_LIST_LEN );
+		return 1;
+	}
+    port_hndl = mvNetaPortHndlGet(port);
+    if(port_hndl == NULL)
+        return 1;
+
+    	switch(command) {
+	    case COM_TXP_BW:
+	        mvNetaTxpRateSet(port, txp, value);
+	        break;
+
+/*
+            case COM_EJP_MODE:
+                mvEthEjpModeSet(port, value);
+                break;
+*/
+  	    default:
+	        printk(" Unknown port command \n");
+    	}
+   	return 0;
+}
+
+/* Giga RX Queue commands */
+int run_port_rxq_cmd(const char *buffer) {
+
+	int scan_count;
+
+	scan_count = sscanf(buffer, RXQ_CMD_STRING, RXQ_SCANF_LIST);
+
+	if( scan_count != RXQ_LIST_LEN) {
+		printk("eth RXQ command bad format %x != %x\n", scan_count, RXQ_LIST_LEN );
+		return 1;
+	}
+
+	switch(command) {
+		case COM_RXQ_TOS_MAP:
+			mv_eth_rxq_tos_map_set(port, q, value);
+			break;
+
+		case COM_RXQ_TIME_COAL:
+			mvNetaRxqTimeCoalSet(port, q, value);
+			break;
+
+		case COM_RXQ_PKTS_COAL:
+			mvNetaRxqPktsCoalSet(port, q, value);
+			break;
+
+#ifndef CONFIG_MV_ETH_PNC
+		case COM_RXQ_TYPE:
+			run_com_rxq_type();
+			break;
+#endif /* CONFIG_MV_ETH_PNC */
+
+		default:
+			printk(" Unknown RXQ command \n");
+	}
+	return 0;
+}
+
+/* Giga TX Queue commands */
+int run_port_txq_cmd(const char *buffer) {
+
+    int scan_count;
+
+    scan_count = sscanf(buffer, TXQ_CMD_STRING, TXQ_SCANF_LIST);
+
+    if( scan_count != TXQ_LIST_LEN) {
+            printk("eth TXQ command bad format %x != %x\n", scan_count, TXQ_LIST_LEN );
+            return 1;
+    }
+
+    switch(command)
+    {
+    	case COM_TXQ_COAL:
+        		mvNetaTxDonePktsCoalSet(port, txp, q, value);
+    		break;
+
+        case COM_TXQ_TOS:
+            mv_eth_txq_tos_map_set(port, q, value);
+        	break;
+
+        case COM_TXQ_BW:
+		    mvNetaTxqRateSet(port, txp, q, value);
+		    break;
+
+	    case COM_TXQ_WRR:
+		    if(value == 0)
+			    mvNetaTxqFixPrioSet(port, txp, q);
+		    else
+			    mvNetaTxqWrrPrioSet(port, txp, q, value);
+		    break;
+
+        default:
+            printk(" Unknown TXQ command \n");
+    }
+    return 0;
+}
+
+int mv_eth_tool_write (struct file *file, const char *buffer,
+                      unsigned long count, void *data) {
+
+	sscanf(buffer, "%x", &command);
+
+	switch (command) {
+        case COM_EJP_MODE:
+		case COM_TXP_BW:
+			run_port_com(buffer);
+			break;
+
+		case COM_TXDONE_Q:
+       	case COM_SKB_RECYCLE:
+	    case COM_NFP_ENABLE:
+			run_eth_com(buffer);
+			break;
+
+		case COM_RXQ_TOS_MAP:
+		case COM_RXQ_PKTS_COAL:
+		case COM_RXQ_TIME_COAL:
+		case COM_RXQ_TYPE:
+            run_port_rxq_cmd(buffer);
+			break;
+
+		case COM_TXQ_COAL:
+		case COM_TXQ_TOS:
+		case COM_TXQ_WRR:
+		case COM_TXQ_BW:
+            run_port_txq_cmd(buffer);
+			break;
+
+		case COM_TX_NOQUEUE:
+        case COM_NETDEV_STS:
+		case COM_NETDEV_PORT_ADD:
+		case COM_NETDEV_PORT_DEL:
+            run_netdev_cmd(buffer);
+            break;
+
+   		case COM_STS:
+			run_com_stats(buffer);
+			break;
+
+		default:
+			printk("eth proc unknown command.\n");
+			break;
+	}
+	return count;
+}
+
+static int proc_calc_metrics(char *page, char **start, off_t off,
+                                 int count, int *eof, int len)
+{
+        if (len <= off+count)
+		*eof = 1;
+
+        *start = page + off;
+        len -= off;
+
+        if (len > count)
+		len = count;
+
+        if (len < 0)
+		len = 0;
+
+        return len;
+}
+
+
+
+int mv_eth_tool_read (char *page, char **start, off_t off,
+                            int count, int *eof, void *data) {
+	unsigned int len = 0;
+
+   	return proc_calc_metrics(page, start, off, count, eof, len);
+}
+
+
+
+int __init start_mv_eth_tool(void)
+{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+     mv_eth_tool = proc_net_create(FILE_NAME , 0666 , NULL);
+#else
+     mv_eth_tool = create_proc_entry(FILE_NAME , 0666 , init_net.proc_net);
+#endif
+  mv_eth_tool->read_proc = mv_eth_tool_read;
+  mv_eth_tool->write_proc = mv_eth_tool_write;
+  mv_eth_tool->nlink = 1;
+  return 0;
+}
+
+module_init(start_mv_eth_tool);
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_proc.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_proc.h
new file mode 100644
index 0000000..6dc04ba
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_proc.h
@@ -0,0 +1,126 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_eth_proc
+#define __mv_eth_proc
+
+#define FILE_NAME	"mv_eth_tool"
+#define FILE_PATH	"/proc/net/"
+#define STS_FILE	"mvethtool.sts"
+
+
+#define ETH_CMD_STRING      "%2x %x"
+#define ETH_PRINTF_LIST     command, value
+#define ETH_SCANF_LIST      &command, &value
+#define ETH_LIST_LEN        2
+
+#define PORT_CMD_STRING     "%2x %2x %2x %x"
+#define PORT_PRINTF_LIST    command, port, txp, value
+#define PORT_SCANF_LIST     &command, &port, &txp, &value
+#define PORT_LIST_LEN       4
+
+#define RXQ_CMD_STRING      "%2x %2x %2x %x"
+#define RXQ_PRINTF_LIST     command, port, q, value
+#define RXQ_SCANF_LIST      &command, &port, &q, &value
+#define RXQ_LIST_LEN        4
+
+#define TXQ_CMD_STRING      "%2x %2x %2x %2x %x"
+#define TXQ_PRINTF_LIST     command, port, txp, q, value
+#define TXQ_SCANF_LIST      &command, &port, &txp, &q, &value
+#define TXQ_LIST_LEN        5
+
+#define STATUS_CMD_STRING   "%2x %2x %2x %2x %2x %x"
+#define STATUS_PRINTF_LIST  command, status, port, txp, q, value
+#define STATUS_SCANF_LIST   &command, &status, &port, &txp, &q, &value
+#define STATUS_LIST_LEN     6
+
+#define NETDEV_CMD_STRING  "%2x %s %d"
+#define NETDEV_PRINTF_LIST command, name, value
+#define NETDEV_SCANF_LIST  &command, name, &value
+#define NETDEV_LIST_LEN    3
+
+typedef enum {
+    COM_RXQ_TYPE = 0,
+    COM_RXQ_MC,
+    COM_RXQ_TIME_COAL,
+    COM_RXQ_PKTS_COAL,
+    COM_TXQ_COAL,
+    COM_TXDONE_Q,
+    COM_SKB_RECYCLE,
+    COM_EJP_MODE,
+    COM_RXQ_TOS_MAP,
+    COM_TX_NOQUEUE,
+    COM_STS,
+    COM_NFP_ENABLE,
+    COM_NETDEV_STS,
+    COM_TXP_BW,
+    COM_TXQ_WRR,
+    COM_TXQ_BW,
+    COM_NETDEV_PORT_ADD,
+    COM_NETDEV_PORT_DEL,
+    COM_TXQ_TOS,
+
+} command_t;
+
+typedef enum {
+	PT_BPDU = 0,
+	PT_ARP,
+	PT_TCP,
+	PT_UDP,
+	PT_NONE
+} packet_t;
+
+typedef enum {
+	STS_PORT = 0,
+	STS_PORT_RXQ,
+	STS_PORT_TXQ,
+	STS_TXP_WRR,
+	STS_PORT_REGS,
+	STS_PORT_MIB,
+	STS_PORT_STATS,
+    STS_PORT_MAC,
+    STS_PORT_TOS_MAP,
+    STS_SWITCH_STATS,
+    STS_NETA_REGS,
+    STS_PNC_REGS,
+    STS_BM_REGS,
+	STS_HWF_REGS,
+	STS_TXP_REGS,
+    STS_GMAC_REGS,
+    STS_RXQ_REGS,
+    STS_TXQ_REGS,
+    STS_PMT_REGS,
+
+} status_t;
+
+typedef enum {
+	DB_ROUTING = 0,
+	DB_NAT,
+} db_type_t;
+
+#endif
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_switch.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_switch.c
new file mode 100644
index 0000000..90bfbe9
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_switch.c
@@ -0,0 +1,767 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mvCommon.h"  /* Should be included before mvSysHwConfig */
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/pci.h>
+#include <linux/ip.h>
+#include <linux/in.h>
+#include <linux/tcp.h>
+#include <linux/version.h>
+#include <net/ip.h>
+#include <net/xfrm.h>
+
+#include "mvOs.h"
+#include "dbg-trace.h"
+#include "mvSysHwConfig.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#ifdef MV_INCLUDE_ETH_COMPLEX
+#include "ctrlEnv/mvCtrlEthCompLib.h"
+#endif /* MV_INCLUDE_ETH_COMPLEX */
+
+#include "mv_switch.h"
+#include "mv_netdev.h"
+
+extern int mv_net_devs_num;
+
+/* Example: "mv_net_config=4,(00:99:88:88:99:77,0)(00:55:44:55:66:77,1:2:3:4)(00:11:22:33:44:55,),mtu=1500" */
+static char			*net_config_str = NULL;
+struct mv_eth_switch_config     switch_net_config;
+static int                      mv_eth_switch_started = 0;
+unsigned int                    switch_enabled_ports = 0;
+
+/* Required to get the configuration string from the Kernel Command Line */
+int mv_eth_cmdline_config(char *s);
+__setup("mv_net_config=", mv_eth_cmdline_config);
+
+int mv_eth_cmdline_config(char *s)
+{
+	net_config_str = s;
+	return 1;
+}
+
+/* Local function prototypes */
+static int mv_eth_check_open_bracket(char **p_net_config)
+{
+	if (**p_net_config == '(') {
+		(*p_net_config)++;
+		return 0;
+	}
+	printk(KERN_ERR "Syntax error: could not find opening bracket\n");
+	return -EINVAL;
+}
+
+static int mv_eth_check_closing_bracket(char **p_net_config)
+{
+	if (**p_net_config == ')') {
+		(*p_net_config)++;
+		return 0;
+	}
+	printk(KERN_ERR "Syntax error: could not find closing bracket\n");
+	return -EINVAL;
+}
+
+static int mv_eth_check_comma(char **p_net_config)
+{
+	if (**p_net_config == ',') {
+		(*p_net_config)++;
+		return 0;
+	}
+	printk(KERN_ERR "Syntax error: could not find comma\n");
+	return -EINVAL;
+}
+
+static int mv_eth_netconfig_mac_addr_get(char **p_net_config, int idx)
+{
+	int     num;
+	char *config_str = *p_net_config;
+	MV_U32  mac[MV_MAC_ADDR_SIZE];
+
+	/* the MAC address should look like: 00:99:88:88:99:77 */
+	/* that is, 6 two-digit numbers, separated by :        */
+	num = sscanf(config_str, "%2x:%2x:%2x:%2x:%2x:%2x",
+		&mac[0], &mac[1], &mac[2], &mac[3], &mac[4], &mac[5]);
+	if (num == MV_MAC_ADDR_SIZE) {
+		while (--num >= 0)
+			switch_net_config.mac_addr[idx][num] = (mac[num] & 0xFF);
+
+		(*p_net_config) = config_str + 17;
+		return 0;
+	}
+	printk(KERN_ERR "Syntax error while parsing MAC address from command line\n");
+	return -EINVAL;
+}
+
+static int mv_eth_netconfig_ports_get(char **p_net_config, int idx)
+{
+	char ch;
+	char *config_str = *p_net_config;
+	int  port, mask = 0, status = -EINVAL;
+
+	/* the port list should look like this: */
+	/* example 0: )         - no ports */
+	/* example 1: 0)        - single port 0 */
+	/* example 2: 1:2:3:4)  - multiple ports */
+
+	while (1) {
+		ch = *config_str++;
+
+		if (ch == ')') {
+			/* Finished */
+			status = 0;
+			break;
+		}
+		port = mvCharToDigit(ch);
+		if (port < 0)
+			break;
+
+		/* TBD - Check port validity */
+		mask |= (1 << port);
+
+		if (*config_str == ':')
+			config_str++;
+	}
+	*p_net_config = config_str;
+
+	if (status == 0) {
+		switch_net_config.board_port_map[idx] = mask;
+		return 0;
+	}
+	printk(KERN_ERR "Syntax error while parsing port mask from command line\n");
+	return -EINVAL;
+}
+
+/* the mtu value is constructed as follows: */
+/* mtu=value                                */
+static int  mv_eth_netconfig_mtu_get(char **p_net_config)
+{
+	unsigned int mtu;
+
+	if (strncmp(*p_net_config, "mtu=", 4) == 0) {
+		*p_net_config += 4;
+		mtu = strtol(*p_net_config, p_net_config, 10);
+		if (mtu > 0) {
+			switch_net_config.mtu = mtu;
+			printk(KERN_ERR "      o MTU set to %d.\n", mtu);
+			return 0;
+		}
+		printk(KERN_ERR "Syntax error while parsing mtu value from command line\n");
+		return -EINVAL;
+	}
+
+	switch_net_config.mtu = 1500;
+	printk(KERN_ERR "      o Using default MTU %d\n", switch_net_config.mtu);
+	return 0;
+}
+
+static int mv_eth_netconfig_max_get(char **p_net_config)
+{
+	char num = **p_net_config;
+	int netdev_num;
+
+	netdev_num = mvCharToDigit(num);
+	if (netdev_num >= 0) {
+		switch_net_config.netdev_max = netdev_num;
+		(*p_net_config) += 1;
+		return 0;
+	}
+	printk(KERN_ERR "Syntax error while parsing number of netdevs from command line\n");
+	return -EINVAL;
+}
+
+int mv_eth_switch_config_get(int use_existing_config)
+{
+	char *p_net_config;
+	int i = 0;
+
+	if (!use_existing_config) {
+		memset(&switch_net_config, 0, sizeof(switch_net_config));
+
+		if (net_config_str != NULL) {
+			printk(KERN_ERR "      o Using UBoot netconfig string\n");
+		} else {
+			printk(KERN_ERR "      o Using default netconfig string from Kconfig\n");
+			net_config_str = CONFIG_MV_ETH_SWITCH_NETCONFIG;
+		}
+		printk(KERN_ERR "        net_config_str: %s\n", net_config_str);
+
+		p_net_config = net_config_str;
+		if (mv_eth_netconfig_max_get(&p_net_config))
+			return -EINVAL;
+
+		if (switch_net_config.netdev_max == 0)
+			return 1;
+
+		if (switch_net_config.netdev_max > CONFIG_MV_ETH_SWITCH_NETDEV_NUM) {
+			printk(KERN_ERR "Too large number of netdevs (%d) in command line: cut to %d\n",
+				switch_net_config.netdev_max, CONFIG_MV_ETH_SWITCH_NETDEV_NUM);
+			switch_net_config.netdev_max = CONFIG_MV_ETH_SWITCH_NETDEV_NUM;
+		}
+
+		if (mv_eth_check_comma(&p_net_config))
+			return -EINVAL;
+
+		for (i = 0; (i < CONFIG_MV_ETH_SWITCH_NETDEV_NUM) && (*p_net_config != '\0'); i++) {
+			if (mv_eth_check_open_bracket(&p_net_config))
+				return -EINVAL;
+
+			if (mv_eth_netconfig_mac_addr_get(&p_net_config, i))
+				return -EINVAL;
+
+			if (mv_eth_check_comma(&p_net_config))
+				return -EINVAL;
+
+			if (mv_eth_netconfig_ports_get(&p_net_config, i))
+				return -EINVAL;
+
+			switch_net_config.netdev_cfg++;
+
+			/* If we have a comma after the closing bracket, then interface */
+			/* definition is done.                                          */
+			if (*p_net_config == ',') {
+				p_net_config++;
+				break;
+			}
+		}
+
+		/* there is a chance the previous loop did not end because a comma was found but because	*/
+		/* the maximum number of interfaces was reached, so check for the comma now.		*/
+		if (i == CONFIG_MV_ETH_SWITCH_NETDEV_NUM)
+			if (mv_eth_check_comma(&p_net_config))
+				return -EINVAL;
+
+		if (*p_net_config != '\0') {
+			if (mv_eth_netconfig_mtu_get(&p_net_config))
+				return -EINVAL;
+		} else {
+			switch_net_config.mtu = 1500;
+			printk(KERN_ERR "      o Using default MTU %d\n", switch_net_config.mtu);
+		}
+
+		/* at this point, we have parsed up to CONFIG_MV_ETH_SWITCH_NETDEV_NUM, and the mtu value */
+		/* if the net_config string is not finished yet, then its format is invalid */
+		if (*p_net_config != '\0') {
+			printk(KERN_ERR "Switch netconfig string is too long: %s\n", p_net_config);
+			return -EINVAL;
+		}
+	} else {
+		/* leave most of the configuration as-is, but update MAC addresses */
+		/* MTU is saved in mv_eth_switch_change_mtu */
+
+		/* Note: at this point, since this is a re-init, mv_eth_switch_netdev_first */
+		/* and mv_eth_switch_netdev_last, as well as mv_net_devs[], are valid.      */
+		for (i = mv_eth_switch_netdev_first; i <= mv_eth_switch_netdev_last; i++) {
+			if (mv_net_devs[i] != NULL)
+				memcpy(switch_net_config.mac_addr[i - mv_eth_switch_netdev_first],
+					mv_net_devs[i]->dev_addr, MV_MAC_ADDR_SIZE);
+		}
+
+		if (switch_net_config.netdev_max == 0)
+			return 1;
+	}
+
+	return 0;
+}
+
+int    mv_eth_switch_set_mac_addr(struct net_device *dev, void *mac)
+{
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+	struct sockaddr *addr = (struct sockaddr *)mac;
+
+	if (!is_valid_ether_addr(addr->sa_data))
+		return -EADDRNOTAVAIL;
+
+	/* remove old mac addr from VLAN DB */
+	mv_switch_mac_addr_set(dev->dev_addr, MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id), (1 << dev_priv->cpu_port), 0);
+
+	memcpy(dev->dev_addr, addr->sa_data, MV_MAC_ADDR_SIZE);
+
+	/* add new mac addr to VLAN DB */
+	mv_switch_mac_addr_set(dev->dev_addr, MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id), (1 << dev_priv->cpu_port), 1);
+
+	printk(KERN_ERR "mv_eth_switch: %s change mac address to %02x:%02x:%02x:%02x:%02x:%02x\n",
+		dev->name, *(dev->dev_addr), *(dev->dev_addr+1), *(dev->dev_addr+2),
+		*(dev->dev_addr+3), *(dev->dev_addr+4), *(dev->dev_addr+5));
+
+	return 0;
+}
+
+void    mv_eth_switch_set_multicast_list(struct net_device *dev)
+{
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+
+	if (dev->flags & IFF_PROMISC) {
+		/* promiscuous mode - connect the CPU port to the VLAN (port based + 802.1q) */
+		/* printk(KERN_ERR "mv_eth_switch: setting promiscuous mode\n"); */
+		if (mv_switch_promisc_set(dev_priv->vlan_grp_id, dev_priv->port_map, dev_priv->cpu_port, 1))
+			printk(KERN_ERR "mv_switch_promisc_set to 1 failed\n");
+	} else {
+		/* not in promiscuous mode - disconnect the CPU port to the VLAN (port based + 802.1q) */
+		if (mv_switch_promisc_set(dev_priv->vlan_grp_id, dev_priv->port_map, dev_priv->cpu_port, 0))
+			printk(KERN_ERR "mv_switch_promisc_set to 0 failed\n");
+
+		if (dev->flags & IFF_ALLMULTI) {
+			/* allmulticast - not supported. There is no way to tell the Switch to accept only	*/
+			/* the multicast addresses but not Unicast addresses, so the alternatives are:	*/
+			/* 1) Don't support multicast and do nothing					*/
+			/* 2) Support multicast with same implementation as promiscuous			*/
+			/* 3) Don't rely on Switch for MAC filtering, but use PnC			*/
+			/* Currently option 1 is selected						*/
+			printk(KERN_ERR "mv_eth_switch: setting all-multicast mode is not supported\n");
+		}
+
+		/* Add or delete specific multicast addresses:						*/
+		/* Linux provides a list of the current multicast addresses for the device.		*/
+		/* First, we delete all the multicast addresses in the ATU.				*/
+		/* Then we add the specific multicast addresses Linux provides.				*/
+		if (mv_switch_all_multicasts_del(MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id)))
+			printk(KERN_ERR "mv_eth_switch: mv_switch_all_multicasts_del failed\n");
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 34)
+		if (!netdev_mc_empty(dev)) {
+			struct netdev_hw_addr *ha;
+
+			netdev_for_each_mc_addr(ha, dev) {
+				mv_switch_mac_addr_set(ha->addr,
+					MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id),
+					(dev_priv->port_map | (1 << dev_priv->cpu_port)), 1);
+			}
+		}
+#else
+		{
+			int i;
+			struct dev_mc_list *curr_addr = dev->mc_list;
+
+			/* accept specific multicasts */
+			for (i = 0; i < dev->mc_count; i++, curr_addr = curr_addr->next) {
+				if (!curr_addr)
+					break;
+
+				/*
+				printk(KERN_ERR "Setting MC = %02X:%02X:%02X:%02X:%02X:%02X\n",
+				curr_addr->dmi_addr[0], curr_addr->dmi_addr[1], curr_addr->dmi_addr[2],
+				curr_addr->dmi_addr[3], curr_addr->dmi_addr[4], curr_addr->dmi_addr[5]);
+				*/
+				mv_switch_mac_addr_set(curr_addr->dmi_addr,
+					MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id),
+					(dev_priv->port_map | (1 << dev_priv->cpu_port)), 1);
+			}
+		}
+#endif /* KERNEL_VERSION >= 2.6.34 */
+	}
+}
+
+int     mv_eth_switch_change_mtu(struct net_device *dev, int mtu)
+{
+	int i;
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+
+	if (netif_running(dev)) {
+		printk(KERN_ERR "mv_eth_switch does not support changing MTU for active interfaces.\n");
+		return -EPERM;
+	}
+
+	/* check mtu - can't change mtu if there is a gateway interface that */
+	/* is currently up and has a different mtu */
+	for (i = mv_eth_switch_netdev_first; i <= mv_eth_switch_netdev_last; i++) {
+		if ((mv_net_devs[i] != NULL)	 &&
+		    (mv_net_devs[i]->mtu != mtu) &&
+		    (netif_running(mv_net_devs[i]))) {
+			printk(KERN_ERR "All gateway devices must have same MTU\n");
+			return -EPERM;
+		}
+	}
+
+	if (dev->mtu != mtu) {
+		int old_mtu = dev->mtu;
+
+		/* stop tx/rx activity, mask all interrupts, relese skb in rings,*/
+		mv_eth_stop_internals(priv);
+
+		if (mv_eth_change_mtu_internals(dev, mtu) == -1)
+			return -EPERM;
+
+		/* fill rx buffers, start rx/tx activity, set coalescing */
+		if (mv_eth_start_internals(priv, dev->mtu) != 0) {
+			printk(KERN_ERR "%s: start internals failed\n", dev->name);
+			return -EPERM;
+		}
+
+		printk(KERN_NOTICE "%s: change mtu %d (pkt-size %d) to %d (pkt-size %d)\n",
+			dev->name, old_mtu, RX_PKT_SIZE(old_mtu),
+			dev->mtu, RX_PKT_SIZE(dev->mtu));
+	}
+
+	if (switch_net_config.mtu != mtu) {
+		mv_switch_jumbo_mode_set(RX_PKT_SIZE(mtu));
+		switch_net_config.mtu = mtu;
+	}
+
+	return 0;
+}
+
+int    mv_eth_switch_start(struct net_device *dev)
+{
+	struct eth_port	*priv = MV_ETH_PRIV(dev);
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+	unsigned char broadcast[MV_MAC_ADDR_SIZE] = {0xff, 0xff, 0xff, 0xff, 0xff, 0xff};
+	int i, cpu;
+
+	/* check mtu */
+	for (i = mv_eth_switch_netdev_first; i <= mv_eth_switch_netdev_last; i++) {
+		if ((mv_net_devs[i] != NULL) && (mv_net_devs[i]->mtu != dev->mtu)) {
+			printk(KERN_ERR "All gateway devices must have same MTU\n");
+			return -EPERM;
+		}
+	}
+
+	/* in default link is down */
+	netif_carrier_off(dev);
+
+	/* Stop the TX queue - it will be enabled upon PHY status change after link-up interrupt/timer */
+	netif_stop_queue(dev);
+
+	/* start upper layer accordingly with ports_map */
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+	dev_priv->link_map = 0;
+	mv_switch_link_update_event(dev_priv->port_map, 1);
+#else
+	dev_priv->link_map = dev_priv->port_map;
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+
+	if (mv_eth_switch_started == 0)	{
+		/* enable polling on the port, must be used after netif_poll_disable */
+		for_each_possible_cpu(cpu)
+			napi_enable(&priv->napi[cpu]);
+
+		/* fill rx buffers, start rx/tx activity, set coalescing */
+		if (mv_eth_start_internals(priv, dev->mtu) != 0) {
+			printk(KERN_ERR "%s: start internals failed\n", dev->name);
+			goto error;
+		}
+
+		/* connect to port interrupt line */
+		if (request_irq(dev->irq, mv_eth_isr, IRQF_DISABLED|IRQF_SAMPLE_RANDOM, "mv_eth", priv)) {
+			printk(KERN_ERR "cannot request irq %d for %s port %d\n",
+				dev->irq, dev->name, priv->port);
+			dev->irq = 0;
+			goto error;
+		}
+
+		/* unmask interrupts */
+		mv_eth_interrupts_unmask(priv);
+	}
+
+	mv_eth_switch_started++;
+
+	/* Add our MAC addr to the VLAN DB at switch level to forward packets with this DA   */
+	/* to CPU port by using the tunneling feature. The device is always in promisc mode. */
+	mv_switch_mac_addr_set(dev->dev_addr, MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id), (1 << dev_priv->cpu_port), 1);
+
+	/* We also need to allow L2 broadcasts comming up for this interface */
+	mv_switch_mac_addr_set(broadcast, MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id),
+			(dev_priv->port_map | (1 << dev_priv->cpu_port)), 1);
+
+	printk(KERN_ERR "%s: started (on switch)\n", dev->name);
+	return 0;
+
+error:
+	printk(KERN_ERR "%s: start failed\n", dev->name);
+	return -1;
+}
+
+int     mv_eth_switch_stop(struct net_device *dev)
+{
+	int cpu;
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+
+	/* stop upper layer */
+	netif_carrier_off(dev);
+	netif_stop_queue(dev);
+
+	/* stop switch from forwarding packets from this VLAN toward CPU port */
+	mv_switch_atu_db_flush(MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id));
+
+	/* It is possible that the interface is in promiscuous mode */
+	/* If so, the CPU port is connected with port based VLAN to the other ports, and */
+	/* we must disconnect it now to stop the Switch from forwarding packets to the CPU */
+	/* when the interface is down. */
+	/* mv_eth_switch_set_multicast_list will be called anyway by Linux when we do ifconfig up */
+	/* and will re-set the promiscuous feature if needed */
+	if (dev->flags & IFF_PROMISC) {
+		if (mv_switch_promisc_set(dev_priv->vlan_grp_id, dev_priv->port_map, dev_priv->cpu_port, 0))
+			printk(KERN_ERR "mv_switch_promisc_set to 0 failed\n");
+	}
+	mv_eth_switch_started--;
+	if (mv_eth_switch_started == 0)	{
+		/* first make sure that the port finished its Rx polling - see tg3 */
+		/* otherwise it may cause issue in SMP, one CPU is here and the other is doing the polling */
+		/* and both of it are messing with the descriptors rings!! */
+		for_each_possible_cpu(cpu)
+			napi_disable(&priv->napi[cpu]);
+
+		/* stop tx/rx activity, mask all interrupts, relese skb in rings,*/
+		mv_eth_stop_internals(priv);
+
+		del_timer(&priv->tx_done_timer);
+		clear_bit(MV_ETH_F_TX_DONE_TIMER_BIT, &(priv->flags));
+		del_timer(&priv->cleanup_timer);
+		clear_bit(MV_ETH_F_CLEANUP_TIMER_BIT, &(priv->flags));
+
+		if (dev->irq != 0)
+			free_irq(dev->irq, priv);
+	}
+	printk(KERN_NOTICE "%s: stopped\n", dev->name);
+
+	return 0;
+}
+
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+
+void mv_eth_switch_interrupt_unmask(int qsgmii_module, int gephy_on_port)
+{
+#ifdef MV_INCLUDE_ETH_COMPLEX
+	MV_U32 reg;
+
+	reg = MV_REG_READ(MV_ETHCOMP_INT_MAIN_MASK_REG);
+
+	if (qsgmii_module) {
+		reg |= (MV_ETHCOMP_PCS0_LINK_INT_MASK |
+			MV_ETHCOMP_PCS1_LINK_INT_MASK |
+			MV_ETHCOMP_PCS2_LINK_INT_MASK |
+			MV_ETHCOMP_PCS3_LINK_INT_MASK);
+	}
+
+	if (gephy_on_port >= 0)
+		reg |= MV_ETHCOMP_GEPHY_INT_MASK;
+
+	reg |= MV_ETHCOMP_SWITCH_INT_MASK;
+
+	MV_REG_WRITE(MV_ETHCOMP_INT_MAIN_MASK_REG, reg);
+#endif /* MV_INCLUDE_ETH_COMPLEX */
+}
+
+void mv_eth_switch_interrupt_clear(int qsgmii_module, int gephy_on_port)
+{
+#ifdef MV_INCLUDE_ETH_COMPLEX
+	MV_U32 reg;
+
+	reg = MV_REG_READ(MV_ETHCOMP_INT_MAIN_CAUSE_REG);
+
+	if (qsgmii_module) {
+		reg &= ~(MV_ETHCOMP_PCS0_LINK_INT_MASK |
+			 MV_ETHCOMP_PCS1_LINK_INT_MASK |
+			 MV_ETHCOMP_PCS2_LINK_INT_MASK |
+			 MV_ETHCOMP_PCS3_LINK_INT_MASK);
+	}
+
+	if (gephy_on_port >= 0)
+		reg &= ~MV_ETHCOMP_GEPHY_INT_MASK;
+
+	reg &= ~MV_ETHCOMP_SWITCH_INT_MASK;
+
+	MV_REG_WRITE(MV_ETHCOMP_INT_MAIN_CAUSE_REG, reg);
+#endif /* MV_INCLUDE_ETH_COMPLEX */
+}
+
+void mv_eth_switch_update_link(unsigned int p, unsigned int link_up)
+{
+	struct eth_netdev *dev_priv = NULL;
+	struct eth_port *priv = NULL;
+	int i = 0;
+	unsigned int prev_ports_link = 0;
+
+	for (i = 0; i < mv_net_devs_num; i++) {
+
+		if (mv_net_devs[i] == NULL)
+			break;
+
+		priv = MV_ETH_PRIV(mv_net_devs[i]);
+		if (priv == NULL)
+			break;
+
+		if (!(priv->flags & (MV_ETH_F_SWITCH | MV_ETH_F_EXT_SWITCH)))
+			continue;
+
+		dev_priv = MV_DEV_PRIV(mv_net_devs[i]);
+		if (dev_priv == NULL)
+			break;
+
+		if ((dev_priv->port_map & (1 << p)) == 0)
+			continue;
+
+		prev_ports_link = dev_priv->link_map;
+
+		if (link_up)
+			dev_priv->link_map |= (1 << p);
+		else
+			dev_priv->link_map &= ~(1 << p);
+
+		if ((prev_ports_link != 0) && (dev_priv->link_map == 0) && netif_running(mv_net_devs[i])) {
+			/* link down */
+			netif_carrier_off(mv_net_devs[i]);
+			netif_stop_queue(mv_net_devs[i]);
+			printk(KERN_ERR "%s: link down\n", mv_net_devs[i]->name);
+		} else if ((prev_ports_link == 0) && (dev_priv->link_map != 0) && netif_running(mv_net_devs[i])) {
+			/* link up */
+			if (mv_eth_ctrl_is_tx_enabled(priv) == 1) {
+				netif_carrier_on(mv_net_devs[i]);
+				netif_wake_queue(mv_net_devs[i]);
+				printk(KERN_ERR "%s: link up\n", mv_net_devs[i]->name);
+			}
+		}
+	}
+}
+
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+
+int     mv_eth_switch_port_add(struct net_device *dev, int port)
+{
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+	int i, switch_port, err = 0;
+
+	if (dev_priv == NULL) {
+		printk(KERN_ERR "%s is not connected to the switch\n", dev->name);
+		return 1;
+	}
+
+	if (netif_running(dev)) {
+		printk(KERN_ERR "%s must be down to change switch ports map\n", dev->name);
+		return 1;
+	}
+
+	switch_port = mvBoardSwitchPortGet(0, port);
+
+	if (switch_port < 0) {
+		printk(KERN_ERR "Switch port %d can't be added\n", port);
+		return 1;
+	}
+
+	if (MV_BIT_CHECK(switch_enabled_ports, switch_port)) {
+		printk(KERN_ERR "Switch port %d is already enabled\n", port);
+		return 0;
+	}
+
+	/* Update data base */
+	dev_priv->port_map |= (1 << switch_port);
+	for (i = mv_eth_switch_netdev_first; i <= mv_eth_switch_netdev_last; i++) {
+		if ((mv_net_devs[i] != NULL) && (mv_net_devs[i] == dev))
+			switch_net_config.board_port_map[i - mv_eth_switch_netdev_first] |= (1 << switch_port);
+	}
+	switch_enabled_ports |= (1 << switch_port);
+	dev_priv->tx_vlan_mh = cpu_to_be16((MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id) << 12) | dev_priv->port_map);
+
+	err = mv_switch_port_add(switch_port, dev_priv->vlan_grp_id, dev_priv->port_map);
+	if (!err)
+		printk(KERN_ERR "%s: Switch port #%d mapped\n", dev->name, port);
+
+	return err;
+}
+
+int     mv_eth_switch_port_del(struct net_device *dev, int port)
+{
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+	int i, switch_port, err = 0;
+
+	if (dev_priv == NULL) {
+		printk(KERN_ERR "%s is not connected to the switch\n", dev->name);
+		return 1;
+	}
+
+	if (netif_running(dev)) {
+		printk(KERN_ERR "%s must be down to change switch ports map\n", dev->name);
+		return 1;
+	}
+
+	switch_port = mvBoardSwitchPortGet(0, port);
+
+	if (switch_port < 0) {
+		printk(KERN_ERR "Switch port %d can't be added\n", port);
+		return 1;
+	}
+
+	if (!MV_BIT_CHECK(switch_enabled_ports, switch_port)) {
+		printk(KERN_ERR "Switch port %d is already disabled\n", port);
+		return 0;
+	}
+
+	if (!MV_BIT_CHECK(dev_priv->port_map, switch_port)) {
+		printk(KERN_ERR "Switch port %d is not mapped on %s\n", port, dev->name);
+		return 0;
+	}
+
+	/* Update data base */
+	dev_priv->port_map &= ~(1 << switch_port);
+	for (i = mv_eth_switch_netdev_first; i <= mv_eth_switch_netdev_last; i++) {
+		if ((mv_net_devs[i] != NULL) && (mv_net_devs[i] == dev))
+			switch_net_config.board_port_map[i - mv_eth_switch_netdev_first] &= ~(1 << switch_port);
+	}
+	dev_priv->link_map &= ~(1 << switch_port);
+	switch_enabled_ports &= ~(1 << switch_port);
+	dev_priv->tx_vlan_mh = cpu_to_be16((MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id) << 12) | dev_priv->port_map);
+
+	err = mv_switch_port_del(switch_port, dev_priv->vlan_grp_id, dev_priv->port_map);
+	if (!err)
+		printk(KERN_ERR "%s: Switch port #%d unmapped\n", dev->name, port);
+
+	return err;
+}
+
+void    mv_eth_switch_status_print(int port)
+{
+	int i;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct net_device *dev;
+
+	if (pp->flags & MV_ETH_F_SWITCH) {
+		printk(KERN_ERR "ethPort=%d: mv_eth_switch status - pp=%p, flags=0x%lx\n", port, pp, pp->flags);
+
+		printk(KERN_ERR "mtu=%d, netdev_max=%d, netdev_cfg=%d, first=%d, last=%d\n",
+			switch_net_config.mtu, switch_net_config.netdev_max, switch_net_config.netdev_cfg,
+			mv_eth_switch_netdev_first, mv_eth_switch_netdev_last);
+
+		for (i = 0; i < switch_net_config.netdev_cfg; i++) {
+			printk(KERN_ERR "MAC="MV_MACQUAD_FMT", board_port_map=0x%x\n",
+				MV_MACQUAD(switch_net_config.mac_addr[i]), switch_net_config.board_port_map[i]);
+		}
+		for (i = mv_eth_switch_netdev_first; i <= mv_eth_switch_netdev_last; i++) {
+			dev = mv_eth_netdev_by_id(i);
+			if (dev)
+				mv_eth_netdev_print(dev);
+		}
+	} else {
+		printk(KERN_ERR "ethPort=%d: switch is not connected - pp=%p, flags=0x%lx\n", port, pp, pp->flags);
+	}
+}
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_sysfs.c
new file mode 100644
index 0000000..1f51325
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_sysfs.c
@@ -0,0 +1,478 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "gbe/mvNeta.h"
+#include "mv_netdev.h"
+
+static ssize_t mv_eth_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "cat                ports           - show all ports info\n");
+	off += sprintf(buf+off, "echo {0|1}         > skb           - enable / disable SKB recycle\n");
+	off += sprintf(buf+off, "echo p             > port          - show a port info\n");
+	off += sprintf(buf+off, "echo p             > stats         - show a port statistics\n");
+	off += sprintf(buf+off, "echo p mib         > cntrs         - show a port counters\n");
+	off += sprintf(buf+off, "echo p             > tos           - show RX and TX TOS map for port <p>\n");
+	off += sprintf(buf+off, "echo p             > mac           - show MAC info for port <p>\n");
+	off += sprintf(buf+off, "echo p             > p_regs        - show port registers for <p>\n");
+#ifdef MV_ETH_GMAC_NEW
+	off += sprintf(buf+off, "echo p             > gmac_regs     - show gmac registers for <p>\n");
+#endif /* MV_ETH_GMAC_NEW */
+	off += sprintf(buf+off, "echo p rxq         > rxq_regs      - show RXQ registers for <p/rxq>\n");
+	off += sprintf(buf+off, "echo p txp         > wrr_regs      - show WRR registers for <p/txp>\n");
+	off += sprintf(buf+off, "echo p txp         > txp_regs      - show TX registers for <p/txp>\n");
+	off += sprintf(buf+off, "echo p txp txq     > txq_regs      - show TXQ registers for <p/txp/txq>\n");
+	off += sprintf(buf+off, "echo p rxq v       > rxq           - show RXQ descriptors ring for <p/rxq>. v=0-brief, v=1-full\n");
+	off += sprintf(buf+off, "echo p txp txq v   > txq           - show TXQ descriptors ring for <p/txp/txq>. v=0-brief, v=1-full\n");
+	off += sprintf(buf+off, "echo p {0|1}       > mh_en         - enable Marvell Header\n");
+	off += sprintf(buf+off, "echo p {0|1}       > tx_nopad      - disable zero padding\n");
+	off += sprintf(buf+off, "echo p hex         > mh_2B         - set 2 bytes of Marvell Header\n");
+	off += sprintf(buf+off, "echo p hex         > tx_cmd        - set 4 bytes of TX descriptor offset 0xc\n");
+	off += sprintf(buf+off, "echo p hex         > debug         - bit0:rx, bit1:tx, bit2:isr, bit3:poll, bit4:dump\n");
+	off += sprintf(buf+off, "echo p l s         > buf_num       - set number of long <l> and short <s> buffers allocated for port <p>\n");
+	off += sprintf(buf+off, "echo p rxq tos     > rxq_tos       - set <rxq> for incoming IP packets with <tos>\n");
+	off += sprintf(buf+off, "echo p rxq cpus    > rxq_cpus      - set <cpus> enable to process packets incoming to <rxq>\n");
+	off += sprintf(buf+off, "echo p rxq v       > rxq_size      - set number of descriptors <v> for <port/rxq>.\n");
+	off += sprintf(buf+off, "echo p rxq v       > rxq_pkts_coal - set RXQ interrupt coalesing. <v> - number of received packets\n");
+	off += sprintf(buf+off, "echo p rxq v       > rxq_time_coal - set RXQ interrupt coalesing. <v> - time in microseconds\n");
+#ifndef CONFIG_MV_ETH_PNC
+	off += sprintf(buf+off, "echo p rxq t       > rxq_type      - set RXQ for different packet types. t=0-bpdu, 1-arp, 2-tcp, 3-udp\n");
+#endif /* CONFIG_MV_ETH_PNC */
+	off += sprintf(buf+off, "echo p             > rx_reset      - reset RX part of the port <p>\n");
+	off += sprintf(buf+off, "echo p txp         > txp_reset     - reset TX part of the port <p/txp>\n");
+	off += sprintf(buf+off, "echo p txq tos     > txq_tos       - set <txq> for outgoing IP packets with <tos>\n");
+	off += sprintf(buf+off, "echo p txp txq cpu > txq_def       - set default <txp/txq> for packets sent to port <p> by <cpu>\n");
+	off += sprintf(buf+off, "echo p txp {0|1}   > ejp           - enable/disable EJP mode for <port/txp>\n");
+	off += sprintf(buf+off, "echo p txp v       > txp_rate      - set outgoing rate <v> in [kbps] for <port/txp>\n");
+	off += sprintf(buf+off, "echo p txp v       > txp_burst     - set maximum burst <v> in [Bytes] for <port/txp>\n");
+	off += sprintf(buf+off, "echo p txp txq v   > txq_rate      - set outgoing rate <v> in [kbps] for <port/txp/txq>\n");
+	off += sprintf(buf+off, "echo p txp txq v   > txq_burst     - set maximum burst <v> in [Bytes] for <port/txp/txq>\n");
+	off += sprintf(buf+off, "echo p txp txq v   > txq_wrr       - set outgoing WRR weight for <port/txp/txq>. <v=0> - fixed\n");
+	off += sprintf(buf+off, "echo p txp txq v   > txq_size      - set number of descriptors <v> for <port/txp/txq>.\n");
+	off += sprintf(buf+off, "echo p txp txq v   > txq_coal      - set TXP/TXQ interrupt coalesing. <v> - number of sent packets\n");
+	off += sprintf(buf+off, "echo v             > tx_done       - set threshold to start tx_done operations\n");
+	off += sprintf(buf+off, "echo p v           > rx_weight     - set weight for the poll function; <v> - new weight, max val: 255\n");
+	return off;
+}
+
+#ifndef CONFIG_MV_ETH_PNC
+int run_rxq_type(int port, int q, int t)
+{
+	void *port_hndl = mvNetaPortHndlGet(port);
+
+	if (port_hndl == NULL)
+		return 1;
+
+	switch (t) {
+	case 0:
+		mvNetaBpduRxq(port, q);
+		break;
+	case 1:
+		mvNetaArpRxq(port, q);
+		break;
+	case 2:
+		mvNetaTcpRxq(port, q);
+		break;
+	case 3:
+		mvNetaUdpRxq(port, q);
+		break;
+	default:
+		printk(KERN_ERR "unknown packet type: value=%d\n", t);
+		return 1;
+	}
+	return 0;
+}
+#endif /* CONFIG_MV_ETH_PNC */
+
+static ssize_t mv_eth_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	unsigned int    p;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "ports")) {
+		mv_eth_status_print();
+
+		for (p = 0; p <= CONFIG_MV_ETH_PORTS_NUM; p++)
+			mv_eth_port_status_print(p);
+	} else {
+		off = mv_eth_help(buf);
+	}
+
+	return off;
+}
+
+static ssize_t mv_eth_port_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = p = v = 0;
+	sscanf(buf, "%d %x", &p, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "debug")) {
+		err = mv_eth_ctrl_flag(p, MV_ETH_F_DBG_RX,   v & 0x1);
+		err = mv_eth_ctrl_flag(p, MV_ETH_F_DBG_TX,   v & 0x2);
+		err = mv_eth_ctrl_flag(p, MV_ETH_F_DBG_ISR,  v & 0x4);
+		err = mv_eth_ctrl_flag(p, MV_ETH_F_DBG_POLL, v & 0x8);
+		err = mv_eth_ctrl_flag(p, MV_ETH_F_DBG_DUMP, v & 0x10);
+	} else if (!strcmp(name, "skb")) {
+		mv_eth_ctrl_recycle(p);
+	} else if (!strcmp(name, "tx_cmd")) {
+		err = mv_eth_ctrl_tx_cmd(p, v);
+	} else if (!strcmp(name, "mh_2B")) {
+		err = mv_eth_ctrl_tx_mh(p, (u16)v);
+	} else if (!strcmp(name, "mh_en")) {
+		err = mv_eth_ctrl_flag(p, MV_ETH_F_MH, v);
+	} else if (!strcmp(name, "tx_nopad")) {
+		err = mv_eth_ctrl_flag(p, MV_ETH_F_NO_PAD, v);
+	} else if (!strcmp(name, "port")) {
+		mv_eth_status_print();
+		mvNetaPortStatus(p);
+		mv_eth_port_status_print(p);
+	} else if (!strcmp(name, "stats")) {
+		mv_eth_port_stats_print(p);
+	} else if (!strcmp(name, "tos")) {
+		mv_eth_tos_map_show(p);
+	} else if (!strcmp(name, "mac")) {
+		mv_eth_mac_show(p);
+	} else if (!strcmp(name, "p_regs")) {
+		printk(KERN_INFO "\n[NetA Port: port=%d]\n", p);
+		mvEthRegs(p);
+		printk(KERN_INFO "\n");
+		mvEthPortRegs(p);
+		mvNetaPortRegs(p);
+#ifdef MV_ETH_GMAC_NEW
+	} else if (!strcmp(name, "gmac_regs")) {
+		mvNetaGmacRegs(p);
+#endif /* MV_ETH_GMAC_NEW */
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t mv_eth_3_hex_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, i, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	err = p = i = v = 0;
+	sscanf(buf, "%d %d %x", &p, &i, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "txq_tos")) {
+		err = mv_eth_txq_tos_map_set(p, i, v);
+	} else if (!strcmp(name, "rxq_tos")) {
+		err = mv_eth_rxq_tos_map_set(p, i, v);
+	} else if (!strcmp(name, "rxq_cpus")) {
+		err = mvNetaRxqCpuMaskSet(p, i, v);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t mv_eth_3_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, i, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	err = p = i = v = 0;
+	sscanf(buf, "%d %d %d", &p, &i, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "txp_rate")) {
+		err = mvNetaTxpRateSet(p, i, v);
+	} else if (!strcmp(name, "txp_burst")) {
+		err = mvNetaTxpBurstSet(p, i, v);
+	} else if (!strcmp(name, "ejp")) {
+		err = mvNetaTxpEjpSet(p, i, v);
+	} else if (!strcmp(name, "rxq_size")) {
+		err = mv_eth_ctrl_rxq_size_set(p, i, v);
+	} else if (!strcmp(name, "rxq_pkts_coal")) {
+		err = mv_eth_rx_ptks_coal_set(p, i, v);
+	} else if (!strcmp(name, "rxq_time_coal")) {
+		err = mv_eth_rx_time_coal_set(p, i, v);
+	} else if (!strcmp(name, "rxq")) {
+		mvNetaRxqShow(p, i, v);
+	} else if (!strcmp(name, "rxq_regs")) {
+		mvNetaRxqRegs(p, i);
+	} else if (!strcmp(name, "buf_num")) {
+		err = mv_eth_ctrl_port_buf_num_set(p, i, v);
+	} else if (!strcmp(name, "rx_reset")) {
+		err = mv_eth_rx_reset(p);
+	} else if (!strcmp(name, "txp_reset")) {
+		err = mv_eth_txp_reset(p, i);
+	} else if (!strcmp(name, "rx_weight")) {
+		err = mv_eth_ctrl_set_poll_rx_weight(p, i);
+	} else if (!strcmp(name, "tx_done")) {
+		mv_eth_ctrl_txdone(p);
+#ifndef CONFIG_MV_ETH_PNC
+	} else if (!strcmp(name, "rxq_type")) {
+		err = run_rxq_type(p, i, v);
+#endif /* CONFIG_MV_ETH_PNC */
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t mv_eth_4_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, txp, txq, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	err = p = txp = txq = v = 0;
+	sscanf(buf, "%d %d %d %d", &p, &txp, &txq, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "txq_def")) {
+		err = mv_eth_ctrl_txq_cpu_def(p, txp, txq, v);
+	} else if (!strcmp(name, "cntrs")) {
+		mvEthPortCounters(p, txp);
+		mvEthPortRmonCounters(p, txp);
+	} else if (!strcmp(name, "wrr_regs")) {
+		mvEthTxpWrrRegs(p, txp);
+	} else if (!strcmp(name, "txp_regs")) {
+		mvNetaTxpRegs(p, txp);
+	} else if (!strcmp(name, "txq_rate")) {
+		err = mvNetaTxqRateSet(p, txp, txq, v);
+	} else if (!strcmp(name, "txq_burst")) {
+		err = mvNetaTxqBurstSet(p, txp, txq, v);
+	} else if (!strcmp(name, "txq_wrr")) {
+		if (v == 0)
+			err = mvNetaTxqFixPrioSet(p, txp, txq);
+		else
+			err = mvNetaTxqWrrPrioSet(p, txp, txq, v);
+	} else if (!strcmp(name, "txq_size")) {
+		err = mv_eth_ctrl_txq_size_set(p, txp, txq, v);
+	} else if (!strcmp(name, "txq_coal")) {
+		mv_eth_tx_done_ptks_coal_set(p, txp, txq, v);
+	} else if (!strcmp(name, "txq")) {
+		mvNetaTxqShow(p, txp, txq, v);
+	} else if (!strcmp(name, "txq_regs")) {
+		mvNetaTxqRegs(p, txp, txq);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(rxq,	        S_IWUSR, mv_eth_show, mv_eth_3_store);
+static DEVICE_ATTR(txq,         S_IWUSR, mv_eth_show, mv_eth_4_store);
+static DEVICE_ATTR(rxq_size,    S_IWUSR, mv_eth_show, mv_eth_3_store);
+static DEVICE_ATTR(rxq_pkts_coal, S_IWUSR, mv_eth_show, mv_eth_3_store);
+static DEVICE_ATTR(rxq_time_coal, S_IWUSR, mv_eth_show, mv_eth_3_store);
+static DEVICE_ATTR(rx_reset,    S_IWUSR, mv_eth_show, mv_eth_3_store);
+static DEVICE_ATTR(txq_size,    S_IWUSR, mv_eth_show, mv_eth_4_store);
+static DEVICE_ATTR(txq_coal,    S_IWUSR, mv_eth_show, mv_eth_4_store);
+static DEVICE_ATTR(txq_def,     S_IWUSR, mv_eth_show, mv_eth_4_store);
+static DEVICE_ATTR(txq_wrr,     S_IWUSR, mv_eth_show, mv_eth_4_store);
+static DEVICE_ATTR(txq_rate,    S_IWUSR, mv_eth_show, mv_eth_4_store);
+static DEVICE_ATTR(txq_burst,   S_IWUSR, mv_eth_show, mv_eth_4_store);
+static DEVICE_ATTR(txp_rate,    S_IWUSR, mv_eth_show, mv_eth_3_store);
+static DEVICE_ATTR(txp_burst,   S_IWUSR, mv_eth_show, mv_eth_3_store);
+static DEVICE_ATTR(txp_reset,   S_IWUSR, mv_eth_show, mv_eth_3_store);
+static DEVICE_ATTR(ejp,         S_IWUSR, mv_eth_show, mv_eth_3_store);
+static DEVICE_ATTR(buf_num,     S_IWUSR, mv_eth_show, mv_eth_3_store);
+static DEVICE_ATTR(rxq_tos,     S_IWUSR, mv_eth_show, mv_eth_3_hex_store);
+static DEVICE_ATTR(rxq_cpus,    S_IWUSR, mv_eth_show, mv_eth_3_hex_store);
+static DEVICE_ATTR(txq_tos,     S_IWUSR, mv_eth_show, mv_eth_3_hex_store);
+static DEVICE_ATTR(mh_en,       S_IWUSR, mv_eth_show, mv_eth_port_store);
+static DEVICE_ATTR(mh_2B,       S_IWUSR, mv_eth_show, mv_eth_port_store);
+static DEVICE_ATTR(tx_cmd,      S_IWUSR, mv_eth_show, mv_eth_port_store);
+static DEVICE_ATTR(tx_nopad,    S_IWUSR, mv_eth_show, mv_eth_port_store);
+static DEVICE_ATTR(debug,       S_IWUSR, mv_eth_show, mv_eth_port_store);
+static DEVICE_ATTR(wrr_regs,    S_IWUSR, mv_eth_show, mv_eth_4_store);
+static DEVICE_ATTR(cntrs,       S_IWUSR, mv_eth_show, mv_eth_4_store);
+static DEVICE_ATTR(port,        S_IWUSR, mv_eth_show, mv_eth_port_store);
+static DEVICE_ATTR(rxq_regs,    S_IWUSR, mv_eth_show, mv_eth_3_store);
+static DEVICE_ATTR(txq_regs,    S_IWUSR, mv_eth_show, mv_eth_4_store);
+static DEVICE_ATTR(mac,         S_IWUSR, mv_eth_show, mv_eth_port_store);
+static DEVICE_ATTR(tos,         S_IWUSR, mv_eth_show, mv_eth_port_store);
+static DEVICE_ATTR(stats,       S_IWUSR, mv_eth_show, mv_eth_port_store);
+static DEVICE_ATTR(skb,	        S_IWUSR, mv_eth_show, mv_eth_port_store);
+static DEVICE_ATTR(ports,       S_IRUSR, mv_eth_show, NULL);
+static DEVICE_ATTR(help,        S_IRUSR, mv_eth_show, NULL);
+static DEVICE_ATTR(rx_weight,   S_IWUSR, NULL, mv_eth_3_store);
+static DEVICE_ATTR(p_regs,      S_IWUSR, mv_eth_show, mv_eth_port_store);
+static DEVICE_ATTR(gmac_regs,   S_IWUSR, mv_eth_show, mv_eth_port_store);
+static DEVICE_ATTR(txp_regs,    S_IWUSR, mv_eth_show, mv_eth_4_store);
+static DEVICE_ATTR(rxq_type,    S_IWUSR, mv_eth_show, mv_eth_3_store);
+static DEVICE_ATTR(tx_done,     S_IWUSR, mv_eth_show, mv_eth_3_store);
+
+static struct attribute *mv_eth_attrs[] = {
+
+	&dev_attr_rxq.attr,
+	&dev_attr_txq.attr,
+	&dev_attr_rxq_time_coal.attr,
+	&dev_attr_rx_reset.attr,
+	&dev_attr_rxq_size.attr,
+	&dev_attr_rxq_pkts_coal.attr,
+	&dev_attr_txq_size.attr,
+	&dev_attr_txq_coal.attr,
+	&dev_attr_txq_def.attr,
+	&dev_attr_txq_wrr.attr,
+	&dev_attr_txq_rate.attr,
+	&dev_attr_txq_burst.attr,
+	&dev_attr_txp_rate.attr,
+	&dev_attr_txp_burst.attr,
+	&dev_attr_txp_reset.attr,
+	&dev_attr_ejp.attr,
+	&dev_attr_buf_num.attr,
+	&dev_attr_rxq_cpus.attr,
+	&dev_attr_rxq_tos.attr,
+	&dev_attr_txq_tos.attr,
+	&dev_attr_mh_en.attr,
+	&dev_attr_mh_2B.attr,
+	&dev_attr_tx_cmd.attr,
+	&dev_attr_tx_nopad.attr,
+	&dev_attr_debug.attr,
+	&dev_attr_wrr_regs.attr,
+	&dev_attr_rxq_regs.attr,
+	&dev_attr_txq_regs.attr,
+	&dev_attr_port.attr,
+	&dev_attr_stats.attr,
+	&dev_attr_cntrs.attr,
+	&dev_attr_ports.attr,
+	&dev_attr_tos.attr,
+	&dev_attr_mac.attr,
+	&dev_attr_skb.attr,
+	&dev_attr_p_regs.attr,
+	&dev_attr_gmac_regs.attr,
+	&dev_attr_txp_regs.attr,
+	&dev_attr_rxq_type.attr,
+	&dev_attr_tx_done.attr,
+	&dev_attr_help.attr,
+	&dev_attr_rx_weight.attr,
+	NULL
+};
+
+static struct attribute_group mv_eth_group = {
+	.name = "gbe",
+	.attrs = mv_eth_attrs,
+};
+
+int __devinit mv_eth_sysfs_init(void)
+{
+	int err;
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+	if (!pd) {
+		platform_device_register_simple("neta", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+	}
+
+	if (!pd) {
+		printk(KERN_ERR"%s: cannot find neta device\n", __func__);
+		pd = &platform_bus;
+	}
+
+	err = sysfs_create_group(&pd->kobj, &mv_eth_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+out:
+	return err;
+}
+
+module_init(mv_eth_sysfs_init);
+
+MODULE_AUTHOR("Kostya Belezko");
+MODULE_DESCRIPTION("sysfs for marvell GbE");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_tool.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_tool.c
new file mode 100644
index 0000000..175426e
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_tool.c
@@ -0,0 +1,839 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <net/ip.h>
+#include <net/ipv6.h>
+#include <linux/mii.h>
+
+#include "mvOs.h"
+#include "mvDebug.h"
+#include "dbg-trace.h"
+#include "mvSysHwConfig.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "eth-phy/mvEthPhy.h"
+#include "mvSysEthPhyApi.h"
+#include "mvSysNetaApi.h"
+
+
+#include "gbe/mvNeta.h"
+#include "bm/mvBm.h"
+#include "pnc/mvPnc.h"
+#include "nfp/mvNfp.h"
+
+#include "mv_switch.h"
+#include "mv_netdev.h"
+
+#include "mvOs.h"
+#include "mvSysHwConfig.h"
+
+#define MV_ETH_TOOL_AN_TIMEOUT	5000
+
+extern spinlock_t          mv_eth_mii_lock;
+
+static int isSwitch(struct eth_port *priv)
+{
+	return (priv->flags & (MV_ETH_F_SWITCH | MV_ETH_F_EXT_SWITCH));
+}
+
+
+/******************************************************************************
+* mv_eth_tool_restore_settings
+* Description:
+*	restore saved speed/dublex/an settings
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	0 for success
+*
+*******************************************************************************/
+int mv_eth_tool_restore_settings(struct net_device *netdev)
+{
+	struct eth_port 	*priv = MV_ETH_PRIV(netdev);
+	int 				mv_phy_speed, mv_phy_duplex;
+	MV_U32			    mv_phy_addr = mvBoardPhyAddrGet(priv->port);
+	MV_ETH_PORT_SPEED	mv_mac_speed;
+	MV_ETH_PORT_DUPLEX	mv_mac_duplex;
+	int			err = -EINVAL;
+
+	 if ((priv == NULL) || (isSwitch(priv)))
+		 return -EOPNOTSUPP;
+
+	switch (priv->speed_cfg) {
+	case SPEED_10:
+		mv_phy_speed  = 0;
+		mv_mac_speed = MV_ETH_SPEED_10;
+		break;
+	case SPEED_100:
+		mv_phy_speed  = 1;
+		mv_mac_speed = MV_ETH_SPEED_100;
+		break;
+	case SPEED_1000:
+		mv_phy_speed  = 2;
+		mv_mac_speed = MV_ETH_SPEED_1000;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	switch (priv->duplex_cfg) {
+	case DUPLEX_HALF:
+		mv_phy_duplex = 0;
+		mv_mac_duplex = MV_ETH_DUPLEX_HALF;
+		break;
+	case DUPLEX_FULL:
+		mv_phy_duplex = 1;
+		mv_mac_duplex = MV_ETH_DUPLEX_FULL;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	if (priv->autoneg_cfg == AUTONEG_ENABLE) {
+		err = mvNetaSpeedDuplexSet(priv->port, MV_ETH_SPEED_AN, MV_ETH_DUPLEX_AN);
+		if (!err)
+			err = mvEthPhyAdvertiseSet(mv_phy_addr, priv->advertise_cfg);
+		/* Restart AN on PHY enables it */
+		if (!err) {
+
+			err = mvEthPhyRestartAN(mv_phy_addr, MV_ETH_TOOL_AN_TIMEOUT);
+			if (err == MV_TIMEOUT) {
+				MV_ETH_PORT_STATUS ps;
+
+				mvNetaLinkStatus(priv->port, &ps);
+
+				if (!ps.linkup)
+					err = 0;
+			}
+		}
+	} else if (priv->autoneg_cfg == AUTONEG_DISABLE) {
+		err = mvEthPhyDisableAN(mv_phy_addr, mv_phy_speed, mv_phy_duplex);
+		if (!err)
+			err = mvNetaSpeedDuplexSet(priv->port, mv_mac_speed, mv_mac_duplex);
+	} else {
+		err = -EINVAL;
+	}
+	return err;
+}
+
+
+
+
+/******************************************************************************
+* mv_eth_tool_get_settings
+* Description:
+*	ethtool get standard port settings
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	cmd		command (settings)
+* RETURN:
+*	0 for success
+*
+*******************************************************************************/
+int mv_eth_tool_get_settings(struct net_device *netdev, struct ethtool_cmd *cmd)
+{
+	struct eth_port 	*priv = MV_ETH_PRIV(netdev);
+	u16			lp_ad, stat1000;
+	MV_U32			mv_phy_addr;
+	MV_ETH_PORT_SPEED 	speed;
+	MV_ETH_PORT_DUPLEX 	duplex;
+	MV_ETH_PORT_STATUS      status;
+
+	if ((priv == NULL) || (isSwitch(priv)) || (MV_PON_PORT(priv->port))) {
+		printk(KERN_ERR "%s is not supported on %s\n", __func__, netdev->name);
+		return -EOPNOTSUPP;
+	}
+
+	cmd->supported = (SUPPORTED_10baseT_Half | SUPPORTED_10baseT_Full | SUPPORTED_100baseT_Half
+			| SUPPORTED_100baseT_Full | SUPPORTED_Autoneg | SUPPORTED_TP | SUPPORTED_MII
+			| SUPPORTED_1000baseT_Full);
+
+	mv_phy_addr = mvBoardPhyAddrGet(priv->port);
+
+	mvNetaLinkStatus(priv->port, &status);
+
+	switch (status.speed) {
+	case MV_ETH_SPEED_1000:
+		cmd->speed = SPEED_1000;
+		break;
+	case MV_ETH_SPEED_100:
+		cmd->speed = SPEED_100;
+		break;
+	case MV_ETH_SPEED_10:
+		cmd->speed = SPEED_10;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	if (status.duplex == MV_ETH_DUPLEX_FULL)
+		cmd->duplex = 1;
+	else
+		cmd->duplex = 0;
+
+	cmd->port = PORT_MII;
+	cmd->phy_address = mv_phy_addr;
+	cmd->transceiver = XCVR_INTERNAL;
+	/* check if speed and duplex are AN */
+	mvNetaSpeedDuplexGet(priv->port, &speed, &duplex);
+	if (speed == MV_ETH_SPEED_AN && duplex == MV_ETH_DUPLEX_AN) {
+		cmd->lp_advertising = cmd->advertising = 0;
+		cmd->autoneg = AUTONEG_ENABLE;
+		mvEthPhyAdvertiseGet(mv_phy_addr, (MV_U16 *)&(cmd->advertising));
+
+		mvEthPhyRegRead(mv_phy_addr, MII_LPA, &lp_ad);
+		if (lp_ad & LPA_LPACK)
+			cmd->lp_advertising |= ADVERTISED_Autoneg;
+		if (lp_ad & ADVERTISE_10HALF)
+			cmd->lp_advertising |= ADVERTISED_10baseT_Half;
+		if (lp_ad & ADVERTISE_10FULL)
+			cmd->lp_advertising |= ADVERTISED_10baseT_Full;
+		if (lp_ad & ADVERTISE_100HALF)
+			cmd->lp_advertising |= ADVERTISED_100baseT_Half;
+		if (lp_ad & ADVERTISE_100FULL)
+			cmd->lp_advertising |= ADVERTISED_100baseT_Full;
+
+		mvEthPhyRegRead(mv_phy_addr, MII_STAT1000, &stat1000);
+		if (stat1000 & LPA_1000HALF)
+			cmd->lp_advertising |= ADVERTISED_1000baseT_Half;
+		if (stat1000 & LPA_1000FULL)
+			cmd->lp_advertising |= ADVERTISED_1000baseT_Full;
+	} else
+		cmd->autoneg = AUTONEG_DISABLE;
+
+	return 0;
+}
+
+
+/******************************************************************************
+* mv_eth_tool_set_settings
+* Description:
+*	ethtool set standard port settings
+* INPUT:
+*	netdev		Network device structure pointer
+*	cmd		command (settings)
+* OUTPUT
+*	None
+* RETURN:
+*	0 for success
+*
+*******************************************************************************/
+int mv_eth_tool_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+	int _speed, _duplex, _autoneg, _advertise, err;
+
+	if ((priv == NULL) || (isSwitch(priv)) || (MV_PON_PORT(priv->port))) {
+		printk(KERN_ERR "%s is not supported on %s\n", __func__, dev->name);
+		return -EOPNOTSUPP;
+	}
+
+	_duplex  = priv->duplex_cfg;
+	_speed   = priv->speed_cfg;
+	_autoneg = priv->autoneg_cfg;
+	_advertise = priv->advertise_cfg;
+
+	priv->duplex_cfg = cmd->duplex;
+	priv->speed_cfg = cmd->speed;
+	priv->autoneg_cfg = cmd->autoneg;
+	priv->advertise_cfg = cmd->advertising;
+	err = mv_eth_tool_restore_settings(dev);
+
+	if (err) {
+		priv->duplex_cfg = _duplex;
+		priv->speed_cfg = _speed;
+		priv->autoneg_cfg = _autoneg;
+		priv->advertise_cfg = _advertise;
+	}
+	return err;
+}
+
+
+
+
+/******************************************************************************
+* mv_eth_tool_get_regs_len
+* Description:
+*	ethtool get registers array length
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	registers array length
+*
+*******************************************************************************/
+int mv_eth_tool_get_regs_len(struct net_device *netdev)
+{
+#define MV_ETH_TOOL_REGS_LEN 32
+
+	return MV_ETH_TOOL_REGS_LEN * sizeof(uint32_t);
+}
+
+
+/******************************************************************************
+* mv_eth_tool_get_drvinfo
+* Description:
+*	ethtool get driver information
+* INPUT:
+*	netdev		Network device structure pointer
+*	info		driver information
+* OUTPUT
+*	info		driver information
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_drvinfo(struct net_device *netdev,
+			     struct ethtool_drvinfo *info)
+{
+	strcpy(info->driver, "mv_eth");
+	/*strcpy(info->version, LSP_VERSION);*/
+	strcpy(info->fw_version, "N/A");
+	strcpy(info->bus_info, "Mbus");
+/*   TBD
+	info->n_stats = MV_ETH_TOOL_STATS_LEN;
+*/
+	info->testinfo_len = 0;
+	info->regdump_len = mv_eth_tool_get_regs_len(netdev);
+	info->eedump_len = 0;
+}
+
+
+/******************************************************************************
+* mv_eth_tool_get_regs
+* Description:
+*	ethtool get registers array
+* INPUT:
+*	netdev		Network device structure pointer
+*	regs		registers information
+* OUTPUT
+*	p		registers array
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_regs(struct net_device *netdev,
+			  struct ethtool_regs *regs, void *p)
+{
+	struct eth_port	*priv = MV_ETH_PRIV(netdev);
+	uint32_t 	*regs_buff = p;
+
+	if ((priv == NULL) || MV_PON_PORT(priv->port)) {
+		printk(KERN_ERR "%s is not supported on %s\n", __func__, netdev->name);
+		return;
+	}
+
+	memset(p, 0, MV_ETH_TOOL_REGS_LEN * sizeof(uint32_t));
+
+	regs->version = mvCtrlModelRevGet();
+
+	/* ETH port registers */
+	regs_buff[0]  = MV_REG_READ(ETH_PORT_STATUS_REG(priv->port));
+	regs_buff[1]  = MV_REG_READ(ETH_PORT_SERIAL_CTRL_REG(priv->port));
+	regs_buff[2]  = MV_REG_READ(ETH_PORT_CONFIG_REG(priv->port));
+	regs_buff[3]  = MV_REG_READ(ETH_PORT_CONFIG_EXTEND_REG(priv->port));
+	regs_buff[4]  = MV_REG_READ(ETH_SDMA_CONFIG_REG(priv->port));
+/*	regs_buff[5]  = MV_REG_READ(ETH_TX_FIFO_URGENT_THRESH_REG(priv->port)); */
+	regs_buff[6]  = MV_REG_READ(ETH_RX_QUEUE_COMMAND_REG(priv->port));
+	/* regs_buff[7]  = MV_REG_READ(ETH_TX_QUEUE_COMMAND_REG(priv->port)); */
+	regs_buff[8]  = MV_REG_READ(ETH_INTR_CAUSE_REG(priv->port));
+	regs_buff[9]  = MV_REG_READ(ETH_INTR_CAUSE_EXT_REG(priv->port));
+	regs_buff[10] = MV_REG_READ(ETH_INTR_MASK_REG(priv->port));
+	regs_buff[11] = MV_REG_READ(ETH_INTR_MASK_EXT_REG(priv->port));
+	/* ETH Unit registers */
+	regs_buff[16] = MV_REG_READ(ETH_PHY_ADDR_REG(priv->port));
+	regs_buff[17] = MV_REG_READ(ETH_UNIT_INTR_CAUSE_REG(priv->port));
+	regs_buff[18] = MV_REG_READ(ETH_UNIT_INTR_MASK_REG(priv->port));
+	regs_buff[19] = MV_REG_READ(ETH_UNIT_ERROR_ADDR_REG(priv->port));
+	regs_buff[20] = MV_REG_READ(ETH_UNIT_INT_ADDR_ERROR_REG(priv->port));
+
+}
+
+
+
+
+/******************************************************************************
+* mv_eth_tool_nway_reset
+* Description:
+*	ethtool restart auto negotiation
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_nway_reset(struct net_device *netdev)
+{
+	struct eth_port *priv = MV_ETH_PRIV(netdev);
+	MV_U32	        phy_addr;
+
+	if ((priv == NULL) || (isSwitch(priv)) || (MV_PON_PORT(priv->port))) {
+		printk(KERN_ERR "interface %s is not supported\n", netdev->name);
+		return -EOPNOTSUPP;
+	}
+
+	phy_addr = mvBoardPhyAddrGet(priv->port);
+	if (mvEthPhyRestartAN(phy_addr, MV_ETH_TOOL_AN_TIMEOUT) != MV_OK)
+		return -EINVAL;
+
+	return 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_link
+* Description:
+*	ethtool get link status
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	0 if link is down, 1 if link is up
+*
+*******************************************************************************/
+u32 mv_eth_tool_get_link(struct net_device *netdev)
+{
+	struct eth_port     *pp = MV_ETH_PRIV(netdev);
+	struct eth_netdev   *dev_priv = MV_DEV_PRIV(netdev);
+
+	if ((pp == NULL) || (MV_PON_PORT(pp->port))) {
+		printk(KERN_ERR "interface %s is not supported\n", netdev->name);
+		return -EOPNOTSUPP;
+	}
+
+	if (isSwitch(pp)) {
+		if (dev_priv == NULL)
+			return -EOPNOTSUPP;
+		return (dev_priv->link_map != 0);
+	}
+
+	if (mvNetaLinkIsUp(pp->port))
+		return 1;
+
+	return 0;
+}
+/******************************************************************************
+* mv_eth_tool_get_coalesce
+* Description:
+*	ethtool get RX/TX coalesce parameters
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	cmd		Coalesce parameters
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_get_coalesce(struct net_device *netdev,
+			     struct ethtool_coalesce *cmd)
+{
+	struct eth_port *pp = MV_ETH_PRIV(netdev);
+	/* get coal parameters only for rxq=0, txp=txq=0 !!! 
+	   notice that if you use ethtool to set coal, then all queues have the same value */
+	cmd->rx_coalesce_usecs = mvNetaRxqTimeCoalGet(pp->port, 0);
+	cmd->rx_max_coalesced_frames = mvNetaRxqPktsCoalGet(pp->port, 0);
+	cmd->tx_max_coalesced_frames = mvNetaTxDonePktsCoalGet(pp->port, 0, 0);
+	return 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_set_coalesce
+* Description:
+*	ethtool set RX/TX coalesce parameters
+* INPUT:
+*	netdev		Network device structure pointer
+*	cmd		Coalesce parameters
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_coalesce(struct net_device *netdev,
+			     struct ethtool_coalesce *cmd)
+{
+	struct eth_port *pp = MV_ETH_PRIV(netdev);
+	int rxq, txp, txq;
+
+	/* can't set rx coalesce with both 0 pkts and 0 usecs,  tx coalesce supports only pkts */
+	if ((!cmd->rx_coalesce_usecs && !cmd->rx_max_coalesced_frames) || (!cmd->tx_max_coalesced_frames))
+		return -EPERM;
+
+	for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++) {
+		mv_eth_rx_ptks_coal_set(pp->port, rxq, cmd->rx_max_coalesced_frames);
+		mv_eth_rx_time_coal_set(pp->port, rxq, cmd->rx_coalesce_usecs);
+	}
+	for (txp = 0; txp < pp->txp_num; txp++)
+		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++)
+			mv_eth_tx_done_ptks_coal_set(pp->port, txp, txq, cmd->tx_max_coalesced_frames);
+
+	return 0;
+}
+
+
+/******************************************************************************
+* mv_eth_tool_get_ringparam
+* Description:
+*	ethtool get ring parameters
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	ring		Ring paranmeters
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_ringparam(struct net_device *netdev,
+				struct ethtool_ringparam *ring)
+{
+/*	printk("in %s \n",__FUNCTION__); */
+}
+
+/******************************************************************************
+* mv_eth_tool_get_pauseparam
+* Description:
+*	ethtool get pause parameters
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	pause		Pause paranmeters
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_pauseparam(struct net_device *netdev,
+				struct ethtool_pauseparam *pause)
+{
+	struct eth_port      *priv = MV_ETH_PRIV(netdev);
+	int                  port = priv->port;
+	MV_ETH_PORT_STATUS   portStatus;
+	MV_ETH_PORT_FC       flowCtrl;
+
+	if ((priv == NULL) || (isSwitch(priv)) || (MV_PON_PORT(priv->port))) {
+		printk(KERN_ERR "%s is not supported on %s\n", __func__, netdev->name);
+		return;
+	}
+
+	mvNetaFlowCtrlGet(port, &flowCtrl);
+	if ((flowCtrl == MV_ETH_FC_AN_NO) || (flowCtrl == MV_ETH_FC_AN_SYM) || (flowCtrl == MV_ETH_FC_AN_ASYM))
+		pause->autoneg = AUTONEG_ENABLE;
+	else
+		pause->autoneg = AUTONEG_DISABLE;
+
+	mvNetaLinkStatus(port, &portStatus);
+	if (portStatus.rxFc == MV_ETH_FC_DISABLE)
+		pause->rx_pause = 0;
+	else
+		pause->rx_pause = 1;
+
+	if (portStatus.txFc == MV_ETH_FC_DISABLE)
+		pause->tx_pause = 0;
+	else
+		pause->tx_pause = 1;
+}
+
+
+
+
+/******************************************************************************
+* mv_eth_tool_set_pauseparam
+* Description:
+*	ethtool configure pause parameters
+* INPUT:
+*	netdev		Network device structure pointer
+*	pause		Pause paranmeters
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_pauseparam(struct net_device *netdev,
+				struct ethtool_pauseparam *pause)
+{
+	struct eth_port *priv = MV_ETH_PRIV(netdev);
+	int				port = priv->port;
+	MV_U32			phy_addr;
+	MV_STATUS		status = MV_FAIL;
+
+	if ((priv == NULL) || (isSwitch(priv)) || (MV_PON_PORT(priv->port))) {
+		printk(KERN_ERR "%s is not supported on %s\n", __func__, netdev->name);
+		return -EOPNOTSUPP;
+	}
+
+	if (pause->rx_pause && pause->tx_pause) { /* Enable FC */
+		if (pause->autoneg) { /* autoneg enable */
+			status = mvNetaFlowCtrlSet(port, MV_ETH_FC_AN_SYM);
+		} else { /* autoneg disable */
+			status = mvNetaFlowCtrlSet(port, MV_ETH_FC_ENABLE);
+		}
+	} else if (!pause->rx_pause && !pause->tx_pause) { /* Disable FC */
+		if (pause->autoneg) { /* autoneg enable */
+			status = mvNetaFlowCtrlSet(port, MV_ETH_FC_AN_NO);
+		} else { /* autoneg disable */
+			status = mvNetaFlowCtrlSet(port, MV_ETH_FC_DISABLE);
+		}
+	}
+	/* Only symmetric change for RX and TX flow control is allowed */
+	if (status == MV_OK) {
+		phy_addr = mvBoardPhyAddrGet(priv->port);
+		status = mvEthPhyRestartAN(phy_addr, MV_ETH_TOOL_AN_TIMEOUT);
+	}
+	if (status != MV_OK)
+		return -EINVAL;
+
+	return 0;
+}
+
+
+/******************************************************************************
+* mv_eth_tool_get_rx_csum
+* Description:
+*	ethtool get RX checksum offloading status
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	RX checksum
+*
+*******************************************************************************/
+u32 mv_eth_tool_get_rx_csum(struct net_device *netdev)
+{
+#ifdef CONFIG_MV_ETH_RX_CSUM_OFFLOAD
+	struct eth_port *priv = MV_ETH_PRIV(netdev);
+
+	return (priv->rx_csum_offload != 0);
+#else
+	return 0;
+#endif
+}
+
+/******************************************************************************
+* mv_eth_tool_set_rx_csum
+* Description:
+*	ethtool enable/disable RX checksum offloading
+* INPUT:
+*	netdev		Network device structure pointer
+*	data		Command data
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_rx_csum(struct net_device *netdev, uint32_t data)
+{
+#ifdef CONFIG_MV_ETH_RX_CSUM_OFFLOAD
+	struct eth_port *priv = MV_ETH_PRIV(netdev);
+
+	priv->rx_csum_offload = data;
+	return 0;
+#else
+	return -EOPNOTSUPP;
+#endif
+}
+
+/******************************************************************************
+* mv_eth_tool_set_tx_csum
+* Description:
+*	ethtool enable/disable TX checksum offloading
+* INPUT:
+*	netdev		Network device structure pointer
+*	data		Command data
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_tx_csum(struct net_device *netdev, uint32_t data)
+{
+#ifdef CONFIG_MV_ETH_TX_CSUM_OFFLOAD
+	if (data)
+		netdev->features |= NETIF_F_IP_CSUM;
+	else
+		netdev->features &= ~NETIF_F_IP_CSUM;
+
+	return 0;
+#else
+	return -EOPNOTSUPP;
+#endif /* TX_CSUM_OFFLOAD */
+}
+
+
+/******************************************************************************
+* mv_eth_tool_set_tso
+* Description:
+*	ethtool enable/disable TCP segmentation offloading
+* INPUT:
+*	netdev		Network device structure pointer
+*	data		Command data
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_tso(struct net_device *netdev, uint32_t data)
+{
+#if defined(CONFIG_MV_ETH_TSO)
+	if (data)
+		netdev->features |= NETIF_F_TSO;
+	else
+		netdev->features &= ~NETIF_F_TSO;
+
+	return 0;
+#else
+	return -EOPNOTSUPP;
+#endif
+}
+/******************************************************************************
+* mv_eth_tool_set_ufo
+* Description:
+*	ethtool enable/disable UDP segmentation offloading
+* INPUT:
+*	netdev		Network device structure pointer
+*	data		Command data
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_ufo(struct net_device *netdev, uint32_t data)
+{
+/*	printk("in %s \n",__FUNCTION__);*/
+	return -EOPNOTSUPP;
+}
+/******************************************************************************
+* mv_eth_tool_get_strings
+* Description:
+*	ethtool get strings (used for statistics and self-test descriptions)
+* INPUT:
+*	netdev		Network device structure pointer
+*	stringset	strings parameters
+* OUTPUT
+*	data		output data
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_strings(struct net_device *netdev,
+			     uint32_t stringset, uint8_t *data)
+{
+/*	printk("in %s \n",__FUNCTION__);*/
+
+}
+
+/*******************************************************************************/
+int mv_eth_tool_phys_id(struct net_device *netdev, u32 data)
+{
+/*	printk("in %s \n",__FUNCTION__);*/
+	return 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_stats_count
+* Description:
+*	ethtool get statistics count (number of stat. array entries)
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	statistics count
+*
+*******************************************************************************/
+int mv_eth_tool_get_stats_count(struct net_device *netdev)
+{
+/*	printk("in %s \n",__FUNCTION__);*/
+	return 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_ethtool_stats
+* Description:
+*	ethtool get statistics
+* INPUT:
+*	netdev		Network device structure pointer
+*	stats		stats parameters
+* OUTPUT
+*	data		output data
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_ethtool_stats(struct net_device *netdev,
+				   struct ethtool_stats *stats, uint64_t *data)
+{
+
+}
+
+const struct ethtool_ops mv_eth_tool_ops = {
+	.get_settings				= mv_eth_tool_get_settings,
+	.set_settings				= mv_eth_tool_set_settings,
+	.get_drvinfo				= mv_eth_tool_get_drvinfo,
+	.get_regs_len				= mv_eth_tool_get_regs_len,
+	.get_regs					= mv_eth_tool_get_regs,
+	.nway_reset					= mv_eth_tool_nway_reset,
+	.get_link					= mv_eth_tool_get_link,
+	.get_coalesce				= mv_eth_tool_get_coalesce,
+	.set_coalesce				= mv_eth_tool_set_coalesce,
+	.get_ringparam  			= mv_eth_tool_get_ringparam,
+	.get_pauseparam				= mv_eth_tool_get_pauseparam,
+	.set_pauseparam				= mv_eth_tool_set_pauseparam,
+	.get_rx_csum				= mv_eth_tool_get_rx_csum,
+	.set_rx_csum				= mv_eth_tool_set_rx_csum,
+	.get_tx_csum				= ethtool_op_get_tx_csum,
+	.set_tx_csum				= mv_eth_tool_set_tx_csum,
+	.get_sg						= ethtool_op_get_sg,
+	.set_sg						= ethtool_op_set_sg,
+	.get_tso					= ethtool_op_get_tso,
+	.set_tso					= mv_eth_tool_set_tso,
+	.get_ufo					= ethtool_op_get_ufo,
+	.set_ufo					= mv_eth_tool_set_ufo,
+	.get_strings				= mv_eth_tool_get_strings,
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 32)
+	.get_stats_count			= mv_eth_tool_get_stats_count,
+#endif
+	.get_ethtool_stats			= mv_eth_tool_get_ethtool_stats,
+};
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_tool.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_tool.h
new file mode 100644
index 0000000..5000fbc
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_tool.h
@@ -0,0 +1,7 @@
+// mv_eth_tool.h
+#ifndef NET_DEV_MV_ETH_TOOL_H
+#define NET_DEV_MV_ETH_TOOL_H
+
+extern const struct ethtool_ops mv_eth_tool_ops;
+
+#endif
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_ethernet.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_ethernet.c
new file mode 100644
index 0000000..be5b30d
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_ethernet.c
@@ -0,0 +1,411 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/interrupt.h>
+#include <linux/netdevice.h>
+#include <linux/skbuff.h>
+
+#include "mvOs.h"
+#include "dbg-trace.h"
+#include "mvSysHwConfig.h"
+#include "boardEnv/mvBoardEnvLib.h"
+
+#include "eth-phy/mvEthPhy.h"
+#include "gbe/mvNeta.h"
+#include "pnc/mvPnc.h"
+#include "mv_netdev.h"
+
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+#include "mv_switch.h"
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+
+static int mv_eth_start(struct net_device *dev);
+static int mv_eth_set_mac_addr_internals(struct net_device *dev, void *addr);
+
+/***********************************************************
+ * mv_eth_start --                                         *
+ *   start a network device. connect and enable interrupts *
+ *   set hw defaults. fill rx buffers. restart phy link    *
+ *   auto neg. set device link flags. report status.       *
+ ***********************************************************/
+static int mv_eth_start(struct net_device *dev)
+{
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+
+	/* in default link is down */
+	netif_carrier_off(dev);
+
+	/* Stop the TX queue - it will be enabled upon PHY status change after link-up interrupt/timer */
+	netif_stop_queue(dev);
+
+	/* enable polling on the port, must be used after netif_poll_disable */
+	if (priv->flags & MV_ETH_F_CONNECT_LINUX) 
+			napi_enable(priv->napiGroup[CPU_GROUP_DEF]);
+
+	/* fill rx buffers, start rx/tx activity, set coalescing */
+	if (mv_eth_start_internals(priv, dev->mtu) != 0) {
+		printk(KERN_ERR "%s: start internals failed\n", dev->name);
+		goto error;
+	}
+
+	if ((priv->flags & MV_ETH_F_LINK_UP) && !(priv->flags & MV_ETH_F_EXT_SWITCH)) {
+
+		if (mv_eth_ctrl_is_tx_enabled(priv)) {
+			netif_carrier_on(dev);
+			netif_wake_queue(dev);
+		}
+		printk(KERN_NOTICE "%s: link up\n", dev->name);
+	}
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+	if (priv->flags & MV_ETH_F_EXT_SWITCH) {
+		struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+
+		dev_priv->link_map = 0;
+		mv_switch_link_update_event(dev_priv->port_map, 1);
+	}
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+
+	if (priv->flags & MV_ETH_F_CONNECT_LINUX) {
+		/* connect to port interrupt line */
+		if (request_irq(dev->irq, mv_eth_isr, (IRQF_DISABLED|IRQF_SAMPLE_RANDOM), "mv_eth", priv)) {
+			printk(KERN_ERR "cannot request irq %d for %s port %d\n", dev->irq, dev->name, priv->port);
+			dev->irq = 0;
+			goto error;
+		}
+
+		/* unmask interrupts */
+		mv_eth_interrupts_unmask(priv);
+
+		printk(KERN_NOTICE "%s: started\n", dev->name);
+	}
+
+	return 0;
+
+error:
+	if (dev->irq != 0)
+		free_irq(dev->irq, priv);
+
+	printk(KERN_ERR "%s: start failed\n", dev->name);
+	return -1;
+}
+
+/***********************************************************
+ * mv_eth_stop --                                          *
+ *   stop interface with linux core. stop port activity.   *
+ *   free skb's from rings.                                *
+ ***********************************************************/
+int mv_eth_stop(struct net_device *dev)
+{
+	int	cpu;
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+
+	/* first make sure that the port finished its Rx polling - see tg3 */
+	napi_disable(priv->napiGroup[CPU_GROUP_DEF]);
+				
+	/* stop upper layer */
+	netif_carrier_off(dev);
+	netif_stop_queue(dev);
+
+	/* stop tx/rx activity, mask all interrupts, relese skb in rings,*/
+	mv_eth_stop_internals(priv);
+
+	del_timer(&priv->tx_done_timer);
+	clear_bit(MV_ETH_F_TX_DONE_TIMER_BIT, &(priv->flags));
+	del_timer(&priv->cleanup_timer);
+	clear_bit(MV_ETH_F_CLEANUP_TIMER_BIT, &(priv->flags));
+
+	if (dev->irq != 0)
+		free_irq(dev->irq, priv);
+
+	printk(KERN_NOTICE "%s: stopped\n", dev->name);
+
+	return 0;
+}
+
+
+int mv_eth_change_mtu(struct net_device *dev, int mtu)
+{
+	int old_mtu = dev->mtu;
+
+	if (mtu < 64) {
+		printk("MTU must be at least 64, change mtu failed\n");
+		return -EINVAL;
+	}
+
+	if (!netif_running(dev)) {
+		if (mv_eth_change_mtu_internals(dev, mtu) == -1)
+			goto error;
+
+		printk(KERN_NOTICE "%s: change mtu %d (buffer-size %d) to %d (buffer-size %d)\n",
+				dev->name, old_mtu, RX_PKT_SIZE(old_mtu),
+				dev->mtu, RX_PKT_SIZE(dev->mtu));
+		return 0;
+	}
+
+	if (mv_eth_stop(dev)) {
+		printk(KERN_ERR "%s: stop interface failed\n", dev->name);
+		goto error;
+	}
+
+	if (mv_eth_change_mtu_internals(dev, mtu) == -1) {
+		printk(KERN_ERR "%s change mtu internals failed\n", dev->name);
+		goto error;
+	}
+
+	if (mv_eth_start(dev)) {
+		printk(KERN_ERR "%s: start interface failed\n", dev->name);
+		goto error;
+	}
+	printk(KERN_NOTICE "%s: change mtu %d (buffer-size %d) to %d (buffer-size %d)\n",
+				dev->name, old_mtu, RX_PKT_SIZE(old_mtu), dev->mtu,
+				RX_PKT_SIZE(dev->mtu));
+	return 0;
+
+error:
+	printk(KERN_ERR "%s: change mtu failed\n", dev->name);
+	return -1;
+}
+
+/***********************************************************
+ * eth_set_mac_addr --                                   *
+ *   stop port activity. set new addr in device and hw.    *
+ *   restart port activity.                                *
+ ***********************************************************/
+static int mv_eth_set_mac_addr_internals(struct net_device *dev, void *addr)
+{
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+	u8              *mac = &(((u8 *)addr)[2]);  /* skip on first 2B (ether HW addr type) */
+	int             i;
+
+#ifdef CONFIG_MV_ETH_PNC_PARSER
+	if (pnc_mac_me(priv->port, mac, CONFIG_MV_ETH_RXQ_DEF)) {
+		printk(KERN_ERR "%s: ethSetMacAddr failed\n", dev->name);
+		return -1;
+	}
+#endif /* CONFIG_MV_ETH_PNC_PARSER */
+
+#ifdef CONFIG_MV_ETH_LEGACY_PARSER
+	/* remove previous address table entry */
+	if (mvNetaMacAddrSet(priv->port, dev->dev_addr, -1) != MV_OK) {
+		printk(KERN_ERR "%s: ethSetMacAddr failed\n", dev->name);
+		return -1;
+	}
+
+	/* set new addr in hw */
+	if (mvNetaMacAddrSet(priv->port, mac, CONFIG_MV_ETH_RXQ_DEF) != MV_OK) {
+		printk(KERN_ERR "%s: ethSetMacAddr failed\n", dev->name);
+		return -1;
+	}
+#endif /* CONFIG_MV_ETH_LEGACY_PARSER */
+
+	/* set addr in the device */
+	for (i = 0; i < 6; i++)
+		dev->dev_addr[i] = mac[i];
+
+	printk(KERN_NOTICE "%s: mac address changed\n", dev->name);
+
+	return 0;
+}
+
+#ifdef CONFIG_MV_ETH_PNC_PARSER
+void mv_eth_set_multicast_list(struct net_device *dev)
+{
+	struct eth_port     *priv = MV_ETH_PRIV(dev);
+	int                 rxq = CONFIG_MV_ETH_RXQ_DEF;
+/*
+	printk("%s - mv_eth_set_multicast_list: flags=0x%x, mc_count=%d\n",
+		dev->name, dev->flags, dev->mc_count);
+*/
+	if (dev->flags & IFF_PROMISC) {
+		/* Accept all */
+		pnc_mac_me(priv->port, NULL, rxq);
+		pnc_mcast_all(priv->port, 1);
+	} else {
+		/* Accept Unicast to me */
+		pnc_mac_me(priv->port, dev->dev_addr, rxq);
+
+		if (dev->flags & IFF_ALLMULTI) {
+			/* Accept all multicast */
+			pnc_mcast_all(priv->port, 1);
+		} else {
+			/* Accept only initialized Multicast */
+			pnc_mcast_all(priv->port, 0);
+			pnc_mcast_me(priv->port, NULL);
+
+			/* Number of entires for all ports is restricted by CONFIG_MV_ETH_PNC_MCAST_NUM */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 34)
+			if (!netdev_mc_empty(dev)) {
+				struct netdev_hw_addr *ha;
+
+				netdev_for_each_mc_addr(ha, dev) {
+					if (pnc_mcast_me(priv->port, ha->addr)) {
+						printk(KERN_ERR "%s: Mcast init failed\n", dev->name);
+						break;
+					}
+				}
+			}
+#else
+			{
+				struct dev_mc_list *curr_addr = dev->mc_list;
+				int                i;
+				for (i = 0; i < dev->mc_count; i++, curr_addr = curr_addr->next) {
+					if (!curr_addr)
+						break;
+					if (pnc_mcast_me(priv->port, curr_addr->dmi_addr)) {
+						printk(KERN_ERR "%s: Mcast init failed - %d of %d\n",
+							dev->name, i, dev->mc_count);
+						break;
+					}
+				}
+			}
+#endif /* KERNEL_VERSION >= 2.6.34 */
+		}
+	}
+}
+#endif /* CONFIG_MV_ETH_PNC_PARSER */
+
+#ifdef CONFIG_MV_ETH_LEGACY_PARSER
+/***********************************************************
+ * eth_set_multicast_list --                             *
+ *   Add multicast addresses or set promiscuous mode.      *
+ *   This function should have been but was not included   *
+ *   by Marvell. -bbozarth                                 *
+ ***********************************************************/
+void mv_eth_set_multicast_list(struct net_device *dev)
+{
+	struct eth_port    *priv = MV_ETH_PRIV(dev);
+	int                queue = CONFIG_MV_ETH_RXQ_DEF;
+
+	if (dev->flags & IFF_PROMISC) {
+		/* Accept all: Multicast + Unicast */
+		mvNetaRxUnicastPromiscSet(priv->port, MV_TRUE);
+		mvNetaSetUcastTable(priv->port, queue);
+		mvNetaSetSpecialMcastTable(priv->port, queue);
+		mvNetaSetOtherMcastTable(priv->port, queue);
+	} else {
+		/* Accept single Unicast */
+		mvNetaRxUnicastPromiscSet(priv->port, MV_FALSE);
+		mvNetaSetUcastTable(priv->port, -1);
+		if (mvNetaMacAddrSet(priv->port, dev->dev_addr, queue) != MV_OK)
+			printk(KERN_ERR "%s: netaSetMacAddr failed\n", dev->name);
+
+		if (dev->flags & IFF_ALLMULTI) {
+			/* Accept all Multicast */
+			mvNetaSetSpecialMcastTable(priv->port, queue);
+			mvNetaSetOtherMcastTable(priv->port, queue);
+		} else {
+			/* Accept only initialized Multicast */
+			mvNetaSetSpecialMcastTable(priv->port, -1);
+			mvNetaSetOtherMcastTable(priv->port, -1);
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 34)
+			if (!netdev_mc_empty(dev)) {
+				struct netdev_hw_addr *ha;
+
+				netdev_for_each_mc_addr(ha, dev) {
+					mvNetaMcastAddrSet(priv->port, ha->addr, queue);
+				}
+			}
+#else
+			{
+				struct dev_mc_list *curr_addr = dev->mc_list;
+				int                i;
+				for (i = 0; i < dev->mc_count; i++, curr_addr = curr_addr->next) {
+					if (!curr_addr)
+						break;
+					mvNetaMcastAddrSet(priv->port, curr_addr->dmi_addr, queue);
+				}
+			}
+#endif /* KERNEL_VERSION >= 2.6.34 */
+		}
+	}
+}
+#endif /* CONFIG_MV_ETH_LEGACY_PARSER */
+
+
+int     mv_eth_set_mac_addr(struct net_device *dev, void *addr)
+{
+	if (!netif_running(dev)) {
+		if (mv_eth_set_mac_addr_internals(dev, addr) == -1)
+			goto error;
+		return 0;
+	}
+
+	if (mv_eth_stop(dev)) {
+		printk(KERN_ERR "%s: stop interface failed\n", dev->name);
+		goto error;
+	}
+
+	if (mv_eth_set_mac_addr_internals(dev, addr) == -1)
+		goto error;
+
+	if (mv_eth_start(dev)) {
+		printk(KERN_ERR "%s: start interface failed\n", dev->name);
+		goto error;
+	}
+
+	return 0;
+
+error:
+	printk(KERN_ERR "%s: set mac addr failed\n", dev->name);
+	return -1;
+}
+
+
+/************************************************************
+ * mv_eth_open -- Restore MAC address and call to   *
+ *                mv_eth_start                               *
+ ************************************************************/
+int mv_eth_open(struct net_device *dev)
+{
+	struct eth_port	*priv = MV_ETH_PRIV(dev);
+	int         queue = CONFIG_MV_ETH_RXQ_DEF;
+
+#ifdef CONFIG_MV_ETH_PNC_PARSER
+	if (pnc_mac_me(priv->port, dev->dev_addr, queue)) {
+		printk(KERN_ERR "%s: ethSetMacAddr failed\n", dev->name);
+		return -1;
+	}
+#endif /* CONFIG_MV_ETH_PNC_PARSER */
+
+#ifdef CONFIG_MV_ETH_LEGACY_PARSER
+	if (mvNetaMacAddrSet(priv->port, dev->dev_addr, queue) != MV_OK) {
+		printk(KERN_ERR "%s: ethSetMacAddr failed\n", dev->name);
+		return -1;
+	}
+#endif /* CONFIG_MV_ETH_LEGACY_PARSER */
+
+	if (mv_eth_start(dev)) {
+		printk(KERN_ERR "%s: start interface failed\n", dev->name);
+		return -1;
+	}
+	return 0;
+}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c
new file mode 100644
index 0000000..85818ed
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c
@@ -0,0 +1,4994 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/platform_device.h>
+#include <linux/skbuff.h>
+#include <net/ip.h>
+#include <net/ipv6.h>
+
+#include "mvOs.h"
+#include "mvDebug.h"
+#include "dbg-trace.h"
+#include "mvSysHwConfig.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "eth-phy/mvEthPhy.h"
+#include "mvSysEthPhyApi.h"
+#include "mvSysNetaApi.h"
+
+#include "gbe/mvNeta.h"
+#include "bm/mvBm.h"
+#include "pnc/mvPnc.h"
+#include "pnc/mvTcam.h"
+#include "pmt/mvPmt.h"
+#include "nfp/mvNfp.h"
+
+#include "mv_switch.h"
+
+#include "nfp_mgr/mv_nfp_mgr.h"
+
+#include "mv_netdev.h"
+#include "mv_eth_tool.h"
+#ifdef CONFIG_MV_ETH_GRO
+#include <linux/inetdevice.h>
+#endif
+
+#include "cpu/mvCpuCntrs.h"
+
+#ifdef CONFIG_MV_CPU_PERF_CNTRS
+MV_CPU_CNTRS_EVENT	*event0 = NULL;
+MV_CPU_CNTRS_EVENT	*event1 = NULL;
+MV_CPU_CNTRS_EVENT	*event2 = NULL;
+MV_CPU_CNTRS_EVENT	*event3 = NULL;
+MV_CPU_CNTRS_EVENT	*event4 = NULL;
+MV_CPU_CNTRS_EVENT	*event5 = NULL;
+#endif /* CONFIG_MV_CPU_PERF_CNTRS */
+
+
+unsigned int ext_switch_port_mask = 0;
+spinlock_t   mv_eth_mii_lock;
+
+/* uncomment if you want to debug the SKB recycle feature */
+/* #define ETH_SKB_DEBUG */
+
+#ifdef CONFIG_MV_ETH_NFP
+static int mv_ctrl_nfp = CONFIG_MV_ETH_NFP_DEF;
+
+void mv_eth_ctrl_nfp(int en)
+{
+	mv_ctrl_nfp = en;
+}
+
+
+static MV_STATUS mv_eth_nfp(struct eth_port *pp, struct neta_rx_desc *rx_desc, struct eth_pbuf *pkt);
+extern void nfp_port_register(int, int);
+#endif /* CONFIG_MV_ETH_NFP */
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+static int mv_ctrl_recycle = CONFIG_NET_SKB_RECYCLE_DEF;
+
+void mv_eth_ctrl_recycle(int en)
+{
+	mv_ctrl_recycle = en;
+}
+
+#define mv_eth_is_recycle()     (mv_ctrl_recycle)
+#else
+#define mv_eth_is_recycle()     0
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+extern u8 mvMacAddr[CONFIG_MV_ETH_PORTS_NUM][MV_MAC_ADDR_SIZE];
+extern u16 mvMtu[CONFIG_MV_ETH_PORTS_NUM];
+
+extern unsigned int switch_enabled_ports;
+
+struct bm_pool mv_eth_pool[MV_ETH_BM_POOLS];
+struct eth_port **mv_eth_ports;
+struct net_device **mv_net_devs;
+
+int mv_net_devs_num = 0;
+
+/*
+ * Static declarations
+ */
+static int mv_eth_ports_num = 0;
+static int mv_net_devs_max = 0;
+
+static int mv_eth_initialized = 0;
+static int mv_ctrl_txdone = CONFIG_MV_ETH_TXDONE_COAL_PKTS;
+
+/*
+ * Local functions
+ */
+static void mv_eth_txq_delete(struct eth_port *pp, struct tx_queue *txq_ctrl);
+static void mv_eth_tx_timeout(struct net_device *dev);
+static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev);
+static struct sk_buff *mv_eth_skb_alloc(struct bm_pool *bm, struct eth_pbuf *pkt);
+static void mv_eth_tx_frag_process(struct eth_port *pp, struct sk_buff *skb, struct tx_queue *txq_ctrl, u16 flags);
+
+static inline int mv_eth_refill(struct eth_port *pp, int rxq, struct eth_pbuf *pkt,
+				struct bm_pool *pool, struct neta_rx_desc *rx_desc);
+
+static void mv_eth_config_show(void);
+static int  mv_eth_priv_init(struct eth_port *pp, int port);
+static void mv_eth_priv_cleanup(struct eth_port *pp);
+static int  mv_eth_config_get(struct eth_port *pp, u8 *mac);
+static int  mv_eth_hal_init(struct eth_port *pp);
+struct net_device *mv_eth_netdev_init(struct eth_port *pp, int mtu, u8 *mac);
+void mv_eth_netdev_update(int dev_index, struct eth_port *pp);
+static void mv_eth_netdev_set_features(struct net_device *dev);
+
+static MV_STATUS mv_eth_pool_create(int pool, int capacity);
+static int mv_eth_pool_add(int pool, int buf_num);
+static int mv_eth_pool_free(int pool, int num);
+static int mv_eth_pool_destroy(int pool);
+
+#ifdef CONFIG_MV_ETH_TSO
+int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_eth_tx_spec *tx_spec,
+		struct tx_queue *txq_ctrl);
+#endif
+
+/* Get the configuration string from the Kernel Command Line */
+static char *port0_config_str = NULL, *port1_config_str = NULL, *port2_config_str = NULL, *port3_config_str = NULL;
+int mv_eth_cmdline_port0_config(char *s);
+__setup("mv_port0_config=", mv_eth_cmdline_port0_config);
+int mv_eth_cmdline_port1_config(char *s);
+__setup("mv_port1_config=", mv_eth_cmdline_port1_config);
+int mv_eth_cmdline_port2_config(char *s);
+__setup("mv_port2_config=", mv_eth_cmdline_port2_config);
+int mv_eth_cmdline_port3_config(char *s);
+__setup("mv_port3_config=", mv_eth_cmdline_port3_config);
+
+int mv_eth_cmdline_port0_config(char *s)
+{
+	port0_config_str = s;
+	return 1;
+}
+
+int mv_eth_cmdline_port1_config(char *s)
+{
+	port1_config_str = s;
+	return 1;
+}
+
+int mv_eth_cmdline_port2_config(char *s)
+{
+	port2_config_str = s;
+	return 1;
+}
+
+int mv_eth_cmdline_port3_config(char *s)
+{
+	port3_config_str = s;
+	return 1;
+}
+
+static int mv_eth_port_config_parse(struct eth_port *pp)
+{
+	char *str;
+
+	printk(KERN_ERR "\n");
+	if (pp == NULL) {
+		printk(KERN_ERR "  o mv_eth_port_config_parse: got NULL pp\n");
+		return -1;
+	}
+
+	switch (pp->port) {
+	case 0:
+		str = port0_config_str;
+		break;
+	case 1:
+		str = port1_config_str;
+		break;
+	case 2:
+		str = port2_config_str;
+		break;
+	case 3:
+		str = port3_config_str;
+		break;
+	default:
+		printk(KERN_ERR "  o mv_eth_port_config_parse: got unknown port %d\n", pp->port);
+		return -1;
+	}
+
+	if (str != NULL) {
+		if ((!strcmp(str, "disconnected")) || (!strcmp(str, "Disconnected"))) {
+			printk(KERN_ERR "  o Port %d is disconnected from Linux netdevice\n", pp->port);
+			clear_bit(MV_ETH_F_CONNECT_LINUX_BIT, &(pp->flags));
+			return 0;
+		}
+	}
+
+	printk(KERN_ERR "  o Port %d is connected to Linux netdevice\n", pp->port);
+	set_bit(MV_ETH_F_CONNECT_LINUX_BIT, &(pp->flags));
+	return 0;
+}
+
+
+static void mv_eth_add_cleanup_timer(struct eth_port *pp)
+{
+	if (test_and_set_bit(MV_ETH_F_CLEANUP_TIMER_BIT, &(pp->flags)) == 0) {
+		pp->cleanup_timer.expires = jiffies + ((HZ * CONFIG_MV_ETH_CLEANUP_TIMER_PERIOD) / 1000); /* ms */
+		add_timer(&pp->cleanup_timer);
+	}
+}
+
+static void mv_eth_add_tx_done_timer(struct eth_port *pp)
+{
+	if (test_and_set_bit(MV_ETH_F_TX_DONE_TIMER_BIT, &(pp->flags)) == 0) {
+
+		pp->tx_done_timer.expires = jiffies + ((HZ * CONFIG_MV_ETH_TX_DONE_TIMER_PERIOD) / 1000); /* ms */
+		add_timer(&pp->tx_done_timer);
+	}
+}
+
+
+#ifdef ETH_SKB_DEBUG
+struct sk_buff *mv_eth_skb_debug[MV_BM_POOL_CAP_MAX * MV_ETH_BM_POOLS];
+static spinlock_t skb_debug_lock;
+
+void mv_eth_skb_check(struct sk_buff *skb)
+{
+	int i;
+	struct sk_buff *temp;
+	unsigned long flags;
+
+	if (skb == NULL)
+		printk(KERN_ERR "mv_eth_skb_check: got NULL SKB\n");
+
+	spin_lock_irqsave(&skb_debug_lock, flags);
+
+	i = *((u32 *)&skb->cb[0]);
+
+	if ((i >= 0) && (i < MV_BM_POOL_CAP_MAX * MV_ETH_BM_POOLS)) {
+		temp = mv_eth_skb_debug[i];
+		if (mv_eth_skb_debug[i] != skb) {
+			printk(KERN_ERR "mv_eth_skb_check: Unexpected skb: %p (%d) != %p (%d)\n",
+			       skb, i, temp, *((u32 *)&temp->cb[0]));
+		}
+		mv_eth_skb_debug[i] = NULL;
+	} else {
+		printk(KERN_ERR "mv_eth_skb_check: skb->cb=%d is out of range\n", i);
+	}
+
+	spin_unlock_irqrestore(&skb_debug_lock, flags);
+}
+
+void mv_eth_skb_save(struct sk_buff *skb, const char *s)
+{
+	int i;
+	int saved = 0;
+	unsigned long flags;
+
+	spin_lock_irqsave(&skb_debug_lock, flags);
+
+	for (i = 0; i < MV_BM_POOL_CAP_MAX * MV_ETH_BM_POOLS; i++) {
+		if (mv_eth_skb_debug[i] == skb) {
+			printk(KERN_ERR "%s: mv_eth_skb_debug Duplicate: i=%d, skb=%p\n", s, i, skb);
+			mv_eth_skb_print(skb);
+		}
+
+		if ((!saved) && (mv_eth_skb_debug[i] == NULL)) {
+			mv_eth_skb_debug[i] = skb;
+			*((u32 *)&skb->cb[0]) = i;
+			saved = 1;
+		}
+	}
+
+	spin_unlock_irqrestore(&skb_debug_lock, flags);
+
+	if ((i == MV_BM_POOL_CAP_MAX * MV_ETH_BM_POOLS) && (!saved))
+		printk(KERN_ERR "mv_eth_skb_debug is FULL, skb=%p\n", skb);
+}
+#endif /* ETH_SKB_DEBUG */
+
+#ifdef CONFIG_MV_ETH_GRO
+static INLINE unsigned int mv_eth_dev_ip(struct net_device *dev)
+{
+	struct in_device *ip = dev->ip_ptr;
+	if (ip && ip->ifa_list)
+		return ip->ifa_list->ifa_address;
+
+	return 0;
+
+}
+#endif /* CONFIG_MV_ETH_GRO */
+
+struct eth_port *mv_eth_port_by_id(unsigned int port)
+{
+	if (port < mv_eth_ports_num)
+		return mv_eth_ports[port];
+
+	return NULL;
+}
+
+struct net_device *mv_eth_netdev_by_id(unsigned int idx)
+{
+	if (idx < mv_net_devs_num)
+		return mv_net_devs[idx];
+
+	return NULL;
+}
+
+static inline void mv_eth_shadow_inc_get(struct tx_queue *txq)
+{
+	txq->shadow_txq_get_i++;
+	if (txq->shadow_txq_get_i == txq->txq_size)
+		txq->shadow_txq_get_i = 0;
+}
+
+inline void mv_eth_shadow_inc_put(struct tx_queue *txq)
+{
+	txq->shadow_txq_put_i++;
+	if (txq->shadow_txq_put_i == txq->txq_size)
+		txq->shadow_txq_put_i = 0;
+}
+
+inline void mv_eth_shadow_dec_put(struct tx_queue *txq)
+{
+	if (txq->shadow_txq_put_i == 0)
+		txq->shadow_txq_put_i = txq->txq_size - 1;
+	else
+		txq->shadow_txq_put_i--;
+}
+
+static inline int mv_eth_skb_mh_add(struct sk_buff *skb, u16 mh)
+{
+	/* sanity: Check that there is place for MH in the buffer */
+	if (skb_headroom(skb) < MV_ETH_MH_SIZE) {
+		printk(KERN_ERR "%s: skb (%p) doesn't have place for MH, head=%p, data=%p\n",
+		       __func__, skb, skb->head, skb->data);
+		return 1;
+	}
+
+	/* Prepare place for MH header */
+	skb->len += MV_ETH_MH_SIZE;
+	skb->data -= MV_ETH_MH_SIZE;
+	*((u16 *) skb->data) = mh;
+
+	return 0;
+}
+
+static inline struct neta_tx_desc *mv_eth_tx_desc_get(struct tx_queue *txq_ctrl, int num)
+{
+	/* Is enough TX descriptors to send packet */
+	if ((txq_ctrl->txq_count + num) >= txq_ctrl->txq_size) {
+		/*
+		printk(KERN_ERR "eth_tx: txq_ctrl->txq=%d - no_resource: txq_count=%d, txq_size=%d, num=%d\n",
+			txq_ctrl->txq, txq_ctrl->txq_count, txq_ctrl->txq_size, num);
+		*/
+		STAT_ERR(txq_ctrl->stats.txq_err++);
+		return NULL;
+	}
+	return mvNetaTxqNextDescGet(txq_ctrl->q);
+}
+
+inline void mv_eth_tx_desc_flush(struct neta_tx_desc *tx_desc)
+{
+#if defined(MV_CPU_BE)
+	mvNetaTxqDescSwap(tx_desc);
+#endif /* MV_CPU_BE */
+
+	mvOsCacheLineFlush(NULL, tx_desc);
+}
+
+void mv_eth_ctrl_txdone(int num)
+{
+	mv_ctrl_txdone = num;
+}
+
+int mv_eth_ctrl_flag(int port, u32 flag, u32 val)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	u32 bit_flag = (fls(flag) - 1);
+
+	if (!pp)
+		return -ENODEV;
+
+	if ((flag == MV_ETH_F_MH) && (pp->flags & MV_ETH_F_SWITCH)) {
+		printk(KERN_ERR "Error: cannot change Marvell Header on a port used by the Gateway driver\n");
+		return -EPERM;
+	}
+
+	if (val)
+		set_bit(bit_flag, &(pp->flags));
+	else
+		clear_bit(bit_flag, &(pp->flags));
+
+	if (flag == MV_ETH_F_MH) {
+		mvNetaMhSet(pp->port, val ? MV_NETA_MH : MV_NETA_MH_NONE);
+
+#ifdef CONFIG_MV_ETH_NFP
+		mvNfpPortCapSet(pp->port, NFP_P_MH, val);
+#endif
+	}
+	return 0;
+}
+
+int mv_eth_ctrl_port_buf_num_set(int port, int long_num, int short_num)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "Port %d must be stopped before\n", port);
+		return -EINVAL;
+	}
+	if (pp->pool_long != NULL) {
+		/* Update number of buffers in existing pool (allocate or free) */
+		if (pp->pool_long_num > long_num)
+			mv_eth_pool_free(pp->pool_long->pool, pp->pool_long_num - long_num);
+		else if (long_num > pp->pool_long_num)
+			mv_eth_pool_add(pp->pool_long->pool, long_num - pp->pool_long_num);
+	}
+	pp->pool_long_num = long_num;
+
+#ifdef CONFIG_MV_ETH_BM_CPU
+	if (pp->pool_short != NULL) {
+		/* Update number of buffers in existing pool (allocate or free) */
+		if (pp->pool_short_num > short_num)
+			mv_eth_pool_free(pp->pool_short->pool, pp->pool_short_num - short_num);
+		else if (short_num > pp->pool_short_num)
+			mv_eth_pool_add(pp->pool_short->pool, short_num - pp->pool_short_num);
+	}
+	pp->pool_short_num = short_num;
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	return 0;
+}
+
+int mv_eth_ctrl_set_poll_rx_weight(int port, u32 weight)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	int cpu;
+
+	if (pp == NULL) {
+		printk(KERN_INFO "port doens not exist (%d) in %s\n" , port, __func__);
+		return -EINVAL;
+	}
+
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "Port %d must be stopped before\n", port);
+		return -EINVAL;
+	}
+
+	if (weight > 255)
+		weight = 255;
+	pp->weight = weight;
+
+	for_each_possible_cpu(cpu) {
+		pp->napi[cpu]->weight = pp->weight;
+	}
+
+	return 0;
+}
+
+int mv_eth_ctrl_rxq_size_set(int port, int rxq, int value)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct rx_queue	*rxq_ctrl;
+
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "Port %d must be stopped before\n", port);
+		return -EINVAL;
+	}
+	rxq_ctrl = &pp->rxq_ctrl[rxq];
+	if ((rxq_ctrl->q) && (rxq_ctrl->rxq_size != value)) {
+		/* Reset is required when RXQ ring size is changed */
+		mv_eth_rx_reset(pp->port);
+
+		mvNetaRxqDelete(pp->port, rxq);
+		rxq_ctrl->q = NULL;
+	}
+	pp->rxq_ctrl[rxq].rxq_size = value;
+
+	/* New RXQ will be created during mv_eth_start_internals */
+	return 0;
+}
+
+int mv_eth_ctrl_txq_size_set(int port, int txp, int txq, int value)
+{
+	struct tx_queue *txq_ctrl;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "Port %d must be stopped before\n", port);
+		return -EINVAL;
+	}
+	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+	if ((txq_ctrl->q) && (txq_ctrl->txq_size != value)) {
+		mv_eth_txq_delete(pp, txq_ctrl);
+		/* Reset of port/txp is required when TXQ ring size is changed */
+		/* Reset done before as part of stop_internals function */
+	}
+	txq_ctrl->txq_size = value;
+
+	/* New TXQ will be created during mv_eth_start_internals */
+	return 0;
+}
+
+int mv_eth_ctrl_txq_mode_get(int port, int txp, int txq, int *value)
+{
+	int mode = MV_ETH_TXQ_FREE, val = 0;
+	struct tx_queue *txq_ctrl;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+	if (txq_ctrl->cpu_owner) {
+		mode = MV_ETH_TXQ_CPU;
+		val = txq_ctrl->cpu_owner;
+	} else if (txq_ctrl->hwf_rxp < (MV_U8) mv_eth_ports_num) {
+		mode = MV_ETH_TXQ_HWF;
+		val = txq_ctrl->hwf_rxp;
+	}
+	if (value)
+		*value = val;
+
+	return mode;
+}
+
+/* Increment/Decrement CPU ownership for this TXQ */
+int mv_eth_ctrl_txq_cpu_own(int port, int txp, int txq, int add)
+{
+	int mode;
+	struct tx_queue *txq_ctrl;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if ((pp == NULL) || (pp->txq_ctrl == NULL))
+		return -ENODEV;
+
+	/* Check that new txp/txq can be allocated for CPU */
+	mode = mv_eth_ctrl_txq_mode_get(port, txp, txq, NULL);
+
+	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+	if (add) {
+		if ((mode != MV_ETH_TXQ_CPU) && (mode != MV_ETH_TXQ_FREE))
+			return -EINVAL;
+
+		txq_ctrl->cpu_owner++;
+	} else {
+		if (mode != MV_ETH_TXQ_CPU)
+			return -EINVAL;
+
+		txq_ctrl->cpu_owner--;
+	}
+	return 0;
+}
+
+/* Set TXQ ownership to HWF from the RX port.  rxp=-1 - free TXQ ownership */
+int mv_eth_ctrl_txq_hwf_own(int port, int txp, int txq, int rxp)
+{
+	int mode;
+	struct tx_queue *txq_ctrl;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if ((pp == NULL) || (pp->txq_ctrl == NULL))
+		return -ENODEV;
+
+	/* Check that new txp/txq can be allocated for HWF */
+	mode = mv_eth_ctrl_txq_mode_get(port, txp, txq, NULL);
+
+	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+
+	if (rxp == -1) {
+		if (mode != MV_ETH_TXQ_HWF)
+			return -EINVAL;
+	} else {
+		if ((mode != MV_ETH_TXQ_HWF) && (mode != MV_ETH_TXQ_FREE))
+			return -EINVAL;
+	}
+
+	txq_ctrl->hwf_rxp = (MV_U8) rxp;
+
+	return 0;
+}
+
+/* Set TXQ for CPU originated packets */
+int mv_eth_ctrl_txq_cpu_def(int port, int txp, int txq, int cpu)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (cpu >= CONFIG_NR_CPUS) {
+		printk(KERN_ERR "cpu #%d is out of range: from 0 to %d\n",
+			cpu, CONFIG_NR_CPUS - 1);
+		return -EINVAL;
+	}
+
+	if (mvNetaTxpCheck(port, txp))
+		return -EINVAL;
+
+	if ((pp == NULL) || (pp->txq_ctrl == NULL))
+		return -ENODEV;
+
+	/* Decrement CPU ownership for old txq */
+	mv_eth_ctrl_txq_cpu_own(port, pp->txp, pp->txq[cpu], 0);
+
+	if (txq != -1) {
+		if (mvNetaMaxCheck(txq, CONFIG_MV_ETH_TXQ))
+			return -EINVAL;
+
+		/* Increment CPU ownership for new txq */
+		if (mv_eth_ctrl_txq_cpu_own(port, txp, txq, 1))
+			return -EINVAL;
+	}
+	pp->txp = txp;
+	pp->txq[cpu] = txq;
+
+	return 0;
+}
+
+int mv_eth_ctrl_tx_cmd(int port, u32 tx_cmd)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (!pp)
+		return -ENODEV;
+
+	pp->hw_cmd = tx_cmd;
+
+	return 0;
+}
+
+int mv_eth_ctrl_tx_mh(int port, u16 mh)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (!pp)
+		return -ENODEV;
+
+	pp->tx_mh = mh;
+
+	return 0;
+}
+
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+/* Register special transmit check function */
+void mv_eth_tx_special_check_func(int port,
+					int (*func)(int port, struct net_device *dev, struct sk_buff *skb,
+								struct mv_eth_tx_spec *tx_spec_out))
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	pp->tx_special_check = func;
+}
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+
+#ifdef CONFIG_MV_ETH_RX_SPECIAL
+/* Register special transmit check function */
+void mv_eth_rx_special_proc_func(int port, void (*func)(int port, int rxq, struct net_device *dev,
+							struct sk_buff *skb, struct neta_rx_desc *rx_desc))
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	pp->rx_special_proc = func;
+}
+#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+
+static const struct net_device_ops mv_eth_netdev_ops = {
+	.ndo_open = mv_eth_open,
+	.ndo_stop = mv_eth_stop,
+	.ndo_start_xmit = mv_eth_tx,
+#if defined(CONFIG_MV_ETH_PNC_PARSER) || defined(CONFIG_MV_ETH_LEGACY_PARSER)
+	.ndo_set_multicast_list = mv_eth_set_multicast_list,
+#endif /* CONFIG_MV_ETH_PNC_PARSER || CONFIG_MV_ETH_LEGACY_PARSER */
+	.ndo_set_mac_address = mv_eth_set_mac_addr,
+	.ndo_change_mtu = mv_eth_change_mtu,
+	.ndo_tx_timeout = mv_eth_tx_timeout,
+};
+
+#ifdef CONFIG_MV_ETH_SWITCH
+
+static const struct net_device_ops mv_switch_netdev_ops = {
+	.ndo_open = mv_eth_switch_start,
+	.ndo_stop = mv_eth_switch_stop,
+	.ndo_start_xmit = mv_eth_tx,
+	.ndo_set_multicast_list = mv_eth_switch_set_multicast_list,
+	.ndo_set_mac_address = mv_eth_switch_set_mac_addr,
+	.ndo_change_mtu = mv_eth_switch_change_mtu,
+	.ndo_tx_timeout = mv_eth_tx_timeout,
+};
+
+int mv_eth_switch_netdev_first = 0;
+int mv_eth_switch_netdev_last = 0;
+
+static inline struct net_device *mv_eth_switch_netdev_get(struct eth_port *pp, struct eth_pbuf *pkt)
+{
+	MV_U8 *data;
+	int db_num;
+
+	if (pp->flags & MV_ETH_F_SWITCH) {
+		data = pkt->pBuf + pkt->offset;
+
+		/* bits[4-7] of MSB in Marvell header */
+		db_num = ((*data) >> 4);
+
+		return mv_net_devs[mv_eth_switch_netdev_first + db_num];
+	}
+	return pp->dev;
+}
+
+
+void mv_eth_switch_priv_update(struct net_device *netdev, int i)
+{
+	struct eth_netdev *dev_priv;
+	int print_flag, port, switch_port;
+
+	/* Update dev_priv structure */
+	dev_priv = MV_DEV_PRIV(netdev);
+	dev_priv->port_map = 0;
+	dev_priv->link_map = 0;
+
+	print_flag = 1;
+	for (port = 0; port < BOARD_ETH_SWITCH_PORT_NUM; port++) {
+		if (switch_net_config.board_port_map[i] & (1 << port)) {
+			if (print_flag) {
+				printk(KERN_CONT ". Interface ports: ");
+				print_flag = 0;
+			}
+			printk(KERN_CONT "%d ", port);
+			switch_port = mvBoardSwitchPortGet(MV_SWITCH_ID_0, port);
+			if (switch_port >= 0) {
+				dev_priv->port_map |= (1 << switch_port);
+				switch_enabled_ports |= (1 << switch_port);
+			}
+		}
+	}
+	printk(KERN_CONT "\n");
+	dev_priv->group = i;
+	dev_priv->vlan_grp_id = MV_SWITCH_GROUP_VLAN_ID(i);	/* e.g. 0x100, 0x200... */
+	dev_priv->tx_vlan_mh = cpu_to_be16((i << 12) | dev_priv->port_map);
+	dev_priv->cpu_port = mvBoardSwitchCpuPortGet(MV_SWITCH_ID_0);
+
+	mv_eth_switch_vlan_set(dev_priv->vlan_grp_id, dev_priv->port_map, dev_priv->cpu_port);
+}
+
+
+int mv_eth_switch_netdev_init(struct eth_port *pp, int dev_i)
+{
+	int i;
+	struct net_device *netdev;
+
+	switch_enabled_ports = 0;
+
+	for (i = 0; i < switch_net_config.netdev_max; i++) {
+		netdev = mv_eth_netdev_init(pp, switch_net_config.mtu, switch_net_config.mac_addr[i]);
+		if (netdev == NULL) {
+			printk(KERN_ERR "mv_eth_switch_netdev_init: can't create netdevice\n");
+			break;
+		}
+		mv_net_devs[dev_i++] = netdev;
+
+		mv_eth_switch_priv_update(netdev, i);
+
+	}
+	return dev_i;
+}
+
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+void mv_eth_link_status_print(int port)
+{
+	MV_ETH_PORT_STATUS link;
+
+	mvNetaLinkStatus(port, &link);
+
+	if (link.linkup) {
+		printk(KERN_CONT "link up");
+		printk(KERN_CONT ", %s duplex", (link.duplex == MV_ETH_DUPLEX_FULL) ? "full" : "half");
+		printk(KERN_CONT ", speed ");
+
+		if (link.speed == MV_ETH_SPEED_1000)
+			printk(KERN_CONT "1 Gbps\n");
+		else if (link.speed == MV_ETH_SPEED_100)
+			printk(KERN_CONT "100 Mbps\n");
+		else
+			printk(KERN_CONT "10 Mbps\n");
+	} else
+		printk(KERN_CONT "link down\n");
+}
+
+static void mv_eth_rx_error(struct eth_port *pp, struct neta_rx_desc *rx_desc)
+{
+	STAT_ERR(pp->stats.rx_error++);
+
+	if (pp->dev)
+		pp->dev->stats.rx_errors++;
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if ((pp->flags & MV_ETH_F_DBG_RX) == 0)
+		return;
+
+	if (!printk_ratelimit())
+		return;
+
+	if ((rx_desc->status & NETA_RX_FL_DESC_MASK) != NETA_RX_FL_DESC_MASK) {
+		printk(KERN_ERR "giga #%d: bad rx status %08x (buffer oversize), size=%d\n",
+				pp->port, rx_desc->status, rx_desc->dataSize);
+		return;
+	}
+
+	switch (rx_desc->status & NETA_RX_ERR_CODE_MASK) {
+	case NETA_RX_ERR_CRC:
+		printk(KERN_ERR "giga #%d: bad rx status %08x (crc error), size=%d\n",
+				pp->port, rx_desc->status, rx_desc->dataSize);
+		break;
+	case NETA_RX_ERR_OVERRUN:
+		printk(KERN_ERR "giga #%d: bad rx status %08x (overrun error), size=%d\n",
+				pp->port, rx_desc->status, rx_desc->dataSize);
+		break;
+	case NETA_RX_ERR_LEN:
+		printk(KERN_ERR "giga #%d: bad rx status %08x (max frame length error), size=%d\n",
+				pp->port, rx_desc->status, rx_desc->dataSize);
+		break;
+	case NETA_RX_ERR_RESOURCE:
+		printk(KERN_ERR "giga #%d: bad rx status %08x (resource error), size=%d\n",
+				pp->port, rx_desc->status, rx_desc->dataSize);
+		break;
+	}
+	mv_eth_rx_desc_print(rx_desc);
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+}
+
+void mv_eth_skb_print(struct sk_buff *skb)
+{
+	printk(KERN_ERR "skb=%p: head=%p data=%p tail=%p end=%p\n", skb, skb->head, skb->data, skb->tail, skb->end);
+	printk(KERN_ERR "\t truesize=%d len=%d, data_len=%d mac_len=%d\n",
+		skb->truesize, skb->len, skb->data_len, skb->mac_len);
+	printk(KERN_ERR "\t users=%d dataref=%d nr_frags=%d gso_size=%d gso_segs=%d\n",
+	       atomic_read(&skb->users), atomic_read(&skb_shinfo(skb)->dataref),
+	       skb_shinfo(skb)->nr_frags, skb_shinfo(skb)->gso_size, skb_shinfo(skb)->gso_segs);
+	printk(KERN_ERR "\t proto=%d, ip_summed=%d\n", ntohs(skb->protocol), skb->ip_summed);
+#ifdef CONFIG_NET_SKB_RECYCLE
+	printk(KERN_ERR "\t skb_recycle=%p hw_cookie=%p\n", skb->skb_recycle, skb->hw_cookie);
+#endif /* CONFIG_NET_SKB_RECYCLE */
+}
+
+void mv_eth_rx_desc_print(struct neta_rx_desc *desc)
+{
+	int i;
+	u32 *words = (u32 *) desc;
+
+	printk(KERN_ERR "RX desc - %p: ", desc);
+	for (i = 0; i < 8; i++)
+		printk(KERN_CONT "%8.8x ", *words++);
+	printk(KERN_CONT "\n");
+
+	if (desc->status & NETA_RX_IP4_FRAG_MASK)
+		printk(KERN_ERR "Frag, ");
+
+	printk(KERN_CONT "size=%d, L3_offs=%d, IP_hlen=%d, L4_csum=%s, L3=",
+	       desc->dataSize,
+	       (desc->status & NETA_RX_L3_OFFSET_MASK) >> NETA_RX_L3_OFFSET_OFFS,
+	       (desc->status & NETA_RX_IP_HLEN_MASK) >> NETA_RX_IP_HLEN_OFFS,
+	       (desc->status & NETA_RX_L4_CSUM_OK_MASK) ? "Ok" : "Bad");
+
+	if (NETA_RX_L3_IS_IP4(desc->status))
+		printk(KERN_CONT "IPv4, ");
+	else if (NETA_RX_L3_IS_IP4_ERR(desc->status))
+		printk(KERN_CONT "IPv4 bad, ");
+	else if (NETA_RX_L3_IS_IP6(desc->status))
+		printk(KERN_CONT "IPv6, ");
+	else
+		printk(KERN_CONT "Unknown, ");
+
+	printk(KERN_CONT "L4=");
+	if (NETA_RX_L4_IS_TCP(desc->status))
+		printk(KERN_CONT "TCP");
+	else if (NETA_RX_L4_IS_UDP(desc->status))
+		printk(KERN_CONT "UDP");
+	else
+		printk(KERN_CONT "Unknown");
+	printk(KERN_CONT "\n");
+
+#ifdef CONFIG_MV_ETH_PNC
+	printk(KERN_ERR "RINFO: ");
+	if (desc->pncInfo & NETA_PNC_DA_MC)
+		printk(KERN_CONT "DA_MC, ");
+	if (desc->pncInfo & NETA_PNC_DA_BC)
+		printk(KERN_CONT "DA_BC, ");
+	if (desc->pncInfo & NETA_PNC_DA_UC)
+		printk(KERN_CONT "DA_UC, ");
+	if (desc->pncInfo & NETA_PNC_IGMP)
+		printk(KERN_CONT "IGMP, ");
+	if (desc->pncInfo & NETA_PNC_SNAP)
+		printk(KERN_CONT "SNAP, ");
+	if (desc->pncInfo & NETA_PNC_VLAN)
+		printk(KERN_CONT "VLAN, ");
+	if (desc->pncInfo & NETA_PNC_PPPOE)
+		printk(KERN_CONT "PPPOE, ");
+	if (desc->pncInfo & NETA_PNC_NFP)
+		printk(KERN_CONT "NFP, ");
+	if (desc->pncInfo & NETA_PNC_SWF)
+		printk(KERN_CONT "SWF, ");
+#endif /* CONFIG_MV_ETH_PNC */
+
+	printk(KERN_CONT "\n");
+}
+
+void mv_eth_tx_desc_print(struct neta_tx_desc *desc)
+{
+	int i;
+	u32 *words = (u32 *) desc;
+
+	printk(KERN_ERR "TX desc - %p: ", desc);
+	for (i = 0; i < 8; i++)
+		printk(KERN_CONT "%8.8x ", *words++);
+	printk(KERN_CONT "\n");
+}
+
+void mv_eth_pkt_print(struct eth_pbuf *pkt)
+{
+	printk(KERN_ERR "pkt: len=%d off=%d cmd=0x%x pool=%d "
+	       "tos=%d gpon=0x%x skb=%p pa=%lx buf=%p\n",
+	       pkt->bytes, pkt->offset, pkt->tx_cmd, pkt->pool,
+	       pkt->tos, pkt->hw_cmd, pkt->osInfo, pkt->physAddr, pkt->pBuf);
+/*
+	mvDebugMemDump(pkt->pBuf + pkt->offset, 64, 1);
+	mvOsCacheInvalidate(NULL, pkt->pBuf + pkt->offset, pkt->bytes);
+*/
+}
+
+static inline void mv_eth_rx_csum(struct eth_port *pp, struct neta_rx_desc *rx_desc, struct sk_buff *skb)
+{
+#if defined(CONFIG_MV_ETH_RX_CSUM_OFFLOAD)
+	if (pp->rx_csum_offload &&
+	    ((NETA_RX_L3_IS_IP4(rx_desc->status) ||
+	      NETA_RX_L3_IS_IP6(rx_desc->status)) && (rx_desc->status & NETA_RX_L4_CSUM_OK_MASK))) {
+		skb->csum = 0;
+		skb->ip_summed = CHECKSUM_UNNECESSARY;
+		STAT_DBG(pp->stats.rx_csum_hw++);
+		return;
+	}
+#endif /* CONFIG_MV_ETH_RX_CSUM_OFFLOAD */
+
+	skb->ip_summed = CHECKSUM_NONE;
+	STAT_DBG(pp->stats.rx_csum_sw++);
+}
+
+inline int mv_eth_pool_put(struct bm_pool *pool, struct eth_pbuf *pkt)
+{
+	unsigned long flags = 0;
+
+	MV_ETH_LOCK(&pool->lock, flags);
+	if (mvStackIsFull(pool->stack)) {
+		STAT_ERR(pool->stats.stack_full++);
+		MV_ETH_UNLOCK(&pool->lock, flags);
+
+		/* free pkt+skb */
+		dev_kfree_skb_any((struct sk_buff *)pkt->osInfo);
+		mvOsFree(pkt);
+		return 1;
+	}
+	mvStackPush(pool->stack, (MV_U32) pkt);
+	STAT_DBG(pool->stats.stack_put++);
+	MV_ETH_UNLOCK(&pool->lock, flags);
+	return 0;
+}
+
+inline struct eth_pbuf *mv_eth_pool_get(struct bm_pool *pool)
+{
+	struct eth_pbuf *pkt = NULL;
+	struct sk_buff *skb;
+	unsigned long flags = 0;
+
+	MV_ETH_LOCK(&pool->lock, flags);
+
+	if (mvStackIndex(pool->stack) > 0) {
+		STAT_DBG(pool->stats.stack_get++);
+		pkt = (struct eth_pbuf *)mvStackPop(pool->stack);
+	} else
+		STAT_ERR(pool->stats.stack_empty++);
+
+	MV_ETH_UNLOCK(&pool->lock, flags);
+	if (pkt)
+		return pkt;
+
+	/* Try to allocate new pkt + skb */
+	pkt = mvOsMalloc(sizeof(struct eth_pbuf));
+	if (pkt) {
+		skb = mv_eth_skb_alloc(pool, pkt);
+		if (!skb) {
+			mvOsFree(pkt);
+			pkt = NULL;
+		}
+	}
+	return pkt;
+}
+
+inline void *mv_eth_extra_pool_get(struct eth_port *pp)
+{
+	void *ext_buf;
+
+	spin_lock(&pp->extLock);
+	if (mvStackIndex(pp->extArrStack) == 0) {
+		STAT_ERR(pp->stats.ext_stack_empty++);
+		ext_buf = mvOsMalloc(CONFIG_MV_ETH_EXTRA_BUF_SIZE);
+	} else {
+		STAT_DBG(pp->stats.ext_stack_get++);
+		ext_buf = (void *)mvStackPop(pp->extArrStack);
+	}
+	spin_unlock(&pp->extLock);
+
+	return ext_buf;
+}
+
+inline int mv_eth_extra_pool_put(struct eth_port *pp, void *ext_buf)
+{
+	spin_lock(&pp->extLock);
+	if (mvStackIsFull(pp->extArrStack)) {
+		STAT_ERR(pp->stats.ext_stack_full++);
+		spin_unlock(&pp->extLock);
+		mvOsFree(ext_buf);
+		return 1;
+	}
+	mvStackPush(pp->extArrStack, (MV_U32)ext_buf);
+	STAT_DBG(pp->stats.ext_stack_put++);
+	spin_unlock(&pp->extLock);
+	return 0;
+}
+
+/* Pass pkt to BM Pool or RXQ ring */
+inline void mv_eth_rxq_refill(struct eth_port *pp, int rxq,
+				     struct eth_pbuf *pkt, struct bm_pool *pool, struct neta_rx_desc *rx_desc)
+{
+	if (mv_eth_pool_bm(pool)) {
+		/* Refill BM pool */
+		STAT_DBG(pool->stats.bm_put++);
+		mvBmPoolPut(pkt->pool, (MV_ULONG) pkt->physAddr);
+		mvOsCacheLineInv(NULL, rx_desc);
+	} else {
+		/* Refill Rx descriptor */
+		STAT_DBG(pp->stats.rxq_fill[rxq]++);
+		mvNetaRxDescFill(rx_desc, pkt->physAddr, (MV_U32)pkt);
+	}
+}
+
+static inline int mv_eth_tx_done_policy(u32 cause)
+{
+	return fls(cause >> NETA_CAUSE_TXQ_SENT_DESC_OFFS) - 1;
+}
+
+inline int mv_eth_rx_policy(u32 cause)
+{
+	return fls(cause >> NETA_CAUSE_RXQ_OCCUP_DESC_OFFS) - 1;
+}
+
+static inline int mv_eth_txq_tos_map_get(struct eth_port *pp, MV_U8 tos)
+{
+	MV_U8 q = pp->txq_tos_map[tos];
+
+	if (q == MV_ETH_TXQ_INVALID)
+		return pp->txq[smp_processor_id()];
+
+	return q;
+}
+
+static inline int mv_eth_tx_policy(struct eth_port *pp, struct sk_buff *skb)
+{
+	int txq = pp->txq[smp_processor_id()];
+
+	if (ip_hdr(skb)) {
+		MV_U8 tos;
+
+		tos = ip_hdr(skb)->tos;
+		txq = mv_eth_txq_tos_map_get(pp, tos);
+	}
+	return txq;
+}
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+static int mv_eth_skb_recycle(struct sk_buff *skb)
+{
+	struct eth_pbuf *pkt = skb->hw_cookie;
+	struct bm_pool *pool = &mv_eth_pool[pkt->pool];
+	int status = 0;
+
+	if (skb_recycle_check(skb, pool->pkt_size)) {
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+		/* Sanity check */
+		if (skb->truesize != ((skb->end - skb->head) + sizeof(struct sk_buff)))
+			mv_eth_skb_print(skb);
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+		STAT_DBG(pool->stats.skb_recycled_ok++);
+		mvOsCacheInvalidate(NULL, skb->head, RX_BUF_SIZE(pool->pkt_size));
+
+		status = mv_eth_pool_put(pool, pkt);
+
+#ifdef ETH_SKB_DEBUG
+		if (status == 0)
+			mv_eth_skb_save(skb, "recycle");
+#endif /* ETH_SKB_DEBUG */
+
+		return 0;
+	}
+	mvOsFree(pkt);
+	skb->hw_cookie = NULL;
+
+	STAT_DBG(pool->stats.skb_recycled_err++);
+	/* printk(KERN_ERR "mv_eth_skb_recycle failed: pkt=%p, skb=%p\n", pkt, skb); */
+	return 1;
+}
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+static struct sk_buff *mv_eth_skb_alloc(struct bm_pool *pool, struct eth_pbuf *pkt)
+{
+	struct sk_buff *skb;
+
+	skb = dev_alloc_skb(pool->pkt_size);
+	if (!skb) {
+		STAT_ERR(pool->stats.skb_alloc_oom++);
+		return NULL;
+	}
+	STAT_DBG(pool->stats.skb_alloc_ok++);
+
+#ifdef ETH_SKB_DEBUG
+	mv_eth_skb_save(skb, "alloc");
+#endif /* ETH_SKB_DEBUG */
+
+#ifdef CONFIG_MV_ETH_BM_CPU
+	/* Save pkt as first 4 bytes in the buffer */
+	*((MV_U32 *) skb->head) = (MV_U32) pkt;
+	mvOsCacheLineFlush(NULL, skb->head);
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	pkt->osInfo = (void *)skb;
+	pkt->pBuf = skb->head;
+	pkt->physAddr = mvOsCacheInvalidate(NULL, skb->head, RX_BUF_SIZE(pool->pkt_size));
+	pkt->offset = NET_SKB_PAD;
+	pkt->pool = pool->pool;
+
+	return skb;
+}
+
+static inline MV_U32 mv_eth_skb_tx_csum(struct eth_port *pp, struct sk_buff *skb)
+{
+#ifdef CONFIG_MV_ETH_TX_CSUM_OFFLOAD
+	if (skb->ip_summed == CHECKSUM_PARTIAL) {
+		int   ip_hdr_len = 0;
+		MV_U8 l4_proto;
+
+		if (skb->protocol == htons(ETH_P_IP)) {
+			struct iphdr *ip4h = ip_hdr(skb);
+
+			/* Calculate IPv4 checksum and L4 checksum */
+			ip_hdr_len = ip4h->ihl;
+			l4_proto = ip4h->protocol;
+		} else if (skb->protocol == htons(ETH_P_IPV6)) {
+			/* If not IPv4 - must be ETH_P_IPV6 - Calculate only L4 checksum */
+			struct ipv6hdr *ip6h = ipv6_hdr(skb);
+
+			/* Read l4_protocol from one of IPv6 extra headers ?????? */
+			if (skb_network_header_len(skb) > 0)
+				ip_hdr_len = (skb_network_header_len(skb) >> 2);
+			l4_proto = ip6h->nexthdr;
+		} else {
+			STAT_DBG(pp->stats.tx_csum_sw++);
+			return NETA_TX_L4_CSUM_NOT;
+		}
+		STAT_DBG(pp->stats.tx_csum_hw++);
+
+		return mvNetaTxqDescCsum(skb_network_offset(skb), skb->protocol, ip_hdr_len, l4_proto);
+	}
+#endif /* CONFIG_MV_ETH_TX_CSUM_OFFLOAD */
+
+	STAT_DBG(pp->stats.tx_csum_sw++);
+	return NETA_TX_L4_CSUM_NOT;
+}
+
+#ifdef CONFIG_MV_ETH_RX_DESC_PREFETCH
+inline struct neta_rx_desc *mv_eth_rx_prefetch(struct eth_port *pp, MV_NETA_RXQ_CTRL *rx_ctrl,
+									  int rx_done, int rx_todo)
+{
+	struct neta_rx_desc	*rx_desc, *next_desc;
+
+	rx_desc = mvNetaRxqNextDescGet(rx_ctrl);
+	if (rx_done == 0) {
+		/* First descriptor in the NAPI loop */
+		mvOsCacheLineInv(NULL, rx_desc);
+		prefetch(rx_desc);
+	}
+	if ((rx_done + 1) == rx_todo) {
+		/* Last descriptor in the NAPI loop - prefetch are not needed */
+		return rx_desc;
+	}
+	/* Prefetch next descriptor */
+	next_desc = mvNetaRxqDescGet(rx_ctrl);
+	mvOsCacheLineInv(NULL, next_desc);
+	prefetch(next_desc);
+
+	return rx_desc;
+}
+#endif /* CONFIG_MV_ETH_RX_DESC_PREFETCH */
+
+static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq)
+{
+	struct net_device *dev;
+	MV_NETA_RXQ_CTRL *rx_ctrl = pp->rxq_ctrl[rxq].q;
+	int rx_done, rx_filled, err;
+	struct neta_rx_desc *rx_desc;
+	u32 rx_status;
+	int rx_bytes;
+	struct eth_pbuf *pkt;
+	struct sk_buff *skb;
+	struct bm_pool *pool;
+
+	/* Get number of received packets */
+	rx_done = mvNetaRxqBusyDescNumGet(pp->port, rxq);
+	mvOsCacheIoSync();
+
+	if (rx_todo > rx_done)
+		rx_todo = rx_done;
+
+	rx_done = 0;
+	rx_filled = 0;
+
+	/* Fairness NAPI loop */
+	while (rx_done < rx_todo) {
+
+#ifdef CONFIG_MV_ETH_RX_DESC_PREFETCH
+		rx_desc = mv_eth_rx_prefetch(pp, rx_ctrl, rx_done, rx_todo);
+#else
+		rx_desc = mvNetaRxqNextDescGet(rx_ctrl);
+		mvOsCacheLineInv(NULL, rx_desc);
+		prefetch(rx_desc);
+#endif /* CONFIG_MV_ETH_RX_DESC_PREFETCH */
+
+		rx_done++;
+		rx_filled++;
+
+#if defined(MV_CPU_BE)
+		mvNetaRxqDescSwap(rx_desc);
+#endif /* MV_CPU_BE */
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+		if (pp->flags & MV_ETH_F_DBG_RX) {
+			printk(KERN_ERR "\n%s: port=%d, cpu=%d\n", __func__, pp->port, smp_processor_id());
+			mv_eth_rx_desc_print(rx_desc);
+		}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+		rx_status = rx_desc->status;
+		pkt = (struct eth_pbuf *)rx_desc->bufCookie;
+		pool = &mv_eth_pool[pkt->pool];
+
+		if (((rx_status & NETA_RX_FL_DESC_MASK) != NETA_RX_FL_DESC_MASK) ||
+			(rx_status & NETA_RX_ES_MASK)) {
+
+			mv_eth_rx_error(pp, rx_desc);
+
+			mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+			continue;
+		}
+
+		/* Speculative ICache prefetch WA: should be replaced with dma_unmap_single (invalidate l2) */
+		mvOsCacheMultiLineInv(NULL, pkt->pBuf + pkt->offset, rx_desc->dataSize);
+
+#ifdef CONFIG_MV_ETH_RX_PKT_PREFETCH
+		prefetch(pkt->pBuf + pkt->offset);
+		prefetch(pkt->pBuf + pkt->offset + CPU_D_CACHE_LINE_SIZE);
+#endif /* CONFIG_MV_ETH_RX_PKT_PREFETCH */
+
+#ifdef CONFIG_MV_ETH_SWITCH
+		dev = mv_eth_switch_netdev_get(pp, pkt);
+#else
+		dev = pp->dev;
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+		STAT_DBG(pp->stats.rxq[rxq]++);
+		dev->stats.rx_packets++;
+
+		rx_bytes = rx_desc->dataSize - (MV_ETH_CRC_SIZE + MV_ETH_MH_SIZE);
+		dev->stats.rx_bytes += rx_bytes;
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+		if (pp->flags & MV_ETH_F_DBG_RX)
+			mvDebugMemDump(pkt->pBuf + pkt->offset, 64, 1);
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+#if defined(CONFIG_MV_ETH_PNC) && defined(CONFIG_MV_ETH_RX_SPECIAL)
+		/* Special RX processing */
+		if (rx_desc->pncInfo & NETA_PNC_RX_SPECIAL) {
+			if (pp->rx_special_proc) {
+				pp->rx_special_proc(pp->port, rxq, dev, (struct sk_buff *)(pkt->osInfo), rx_desc);
+				STAT_INFO(pp->stats.rx_special++);
+
+				/* Refill processing */
+				err = mv_eth_refill(pp, rxq, pkt, pool, rx_desc);
+				if (err) {
+					printk(KERN_ERR "Linux processing - Can't refill\n");
+					pp->rxq_ctrl[rxq].missed++;
+					rx_filled--;
+				}
+				continue;
+			}
+		}
+#endif /* CONFIG_MV_ETH_PNC && CONFIG_MV_ETH_RX_SPECIAL */
+
+#ifdef CONFIG_MV_ETH_NFP
+		if (mv_ctrl_nfp) {
+			MV_STATUS status;
+
+			pkt->bytes = rx_bytes + MV_ETH_MH_SIZE;
+			pkt->offset = NET_SKB_PAD;
+			pkt->tx_cmd = NETA_TX_L4_CSUM_NOT;
+			pkt->hw_cmd = 0;
+
+			status = mv_eth_nfp(pp, rx_desc, pkt);
+			if (status == MV_OK) {
+				STAT_DBG(pp->stats.rx_nfp++);
+
+				/* Packet moved to transmit - refill now */
+				if (!mv_eth_pool_bm(pool)) {
+					/* No BM, refill descriptor from rx pool */
+					pkt = mv_eth_pool_get(pool);
+					if (pkt) {
+						STAT_DBG(pp->stats.rxq_fill[rxq]++);
+						mvNetaRxDescFill(rx_desc, pkt->physAddr, (MV_U32)pkt);
+					} else {
+						/* RX resource error - RX descriptor is done but not refilled */
+						/* FIXME: remember to refill later */
+
+						printk(KERN_ERR "Alloc failed - Can't refill\n");
+						rx_filled--;
+						pp->rxq_ctrl[rxq].missed++;
+						mv_eth_add_cleanup_timer(pp);
+						break;
+					}
+				} else {
+					/* BM - no refill */
+					mvOsCacheLineInv(NULL, rx_desc);
+				}
+				continue;
+			} else if (status == MV_DROPPED) {
+				/* Refill the same buffer - ??? reset pkt and skb */
+				STAT_DBG(pp->stats.rx_nfp_drop++);
+				mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+				continue;
+			}
+			/* MV_TERMINATE - packet returned to slow path */
+		}
+#endif /* CONFIG_MV_ETH_NFP */
+
+		/* Linux processing */
+		skb = (struct sk_buff *)(pkt->osInfo);
+
+		skb->data += MV_ETH_MH_SIZE;
+		skb->tail += (rx_bytes + MV_ETH_MH_SIZE);
+		skb->len = rx_bytes;
+
+#ifdef ETH_SKB_DEBUG
+		mv_eth_skb_check(skb);
+#endif /* ETH_SKB_DEBUG */
+
+		skb->protocol = eth_type_trans(skb, dev);
+
+		mv_eth_rx_csum(pp, rx_desc, skb);
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+		if (mv_eth_is_recycle()) {
+			skb->skb_recycle = mv_eth_skb_recycle;
+			skb->hw_cookie = pkt;
+			pkt = NULL;
+		}
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+#ifdef CONFIG_MV_ETH_GRO
+		if (dev->features & NETIF_F_GRO) {
+			if (!(rx_status & NETA_RX_IP4_FRAG_MASK) && (NETA_RX_L4_IS_TCP(rx_status))) {
+				struct iphdr *iph = (struct iphdr *)skb->data;
+				if (iph->daddr == mv_eth_dev_ip(dev)) {
+					rx_status = 0;
+					STAT_DBG(pp->stats.rx_gro++);
+					STAT_DBG(pp->stats.rx_gro_bytes += skb->len);
+
+					napi_gro_receive(pp->napi[smp_processor_id()], skb);
+					skb = NULL;
+				}
+			}
+		}
+#endif /* CONFIG_MV_ETH_GRO */
+
+		if (skb) {
+			STAT_DBG(pp->stats.rx_netif++);
+			rx_status = netif_receive_skb(skb);
+			STAT_DBG(if (rx_status)	(pp->stats.rx_drop_sw++));
+		}
+
+		/* Refill processing: */
+		err = mv_eth_refill(pp, rxq, pkt, pool, rx_desc);
+		if (err) {
+			printk(KERN_ERR "Linux processing - Can't refill\n");
+			pp->rxq_ctrl[rxq].missed++;
+			mv_eth_add_cleanup_timer(pp);
+			rx_filled--;
+		}
+	}
+
+	/* Update RxQ management counters */
+	mvOsCacheIoSync();
+	mvNetaRxqDescNumUpdate(pp->port, rxq, rx_done, rx_filled);
+
+	return rx_done;
+}
+
+#ifdef CONFIG_MV_ETH_NFP
+static MV_STATUS mv_eth_nfp_tx(struct neta_rx_desc *rx_desc, struct eth_pbuf *pkt)
+{
+	struct net_device *dev = (struct net_device *)pkt->dev;
+	struct eth_port *pp = MV_ETH_PRIV(dev);
+	struct neta_tx_desc *tx_desc;
+	u32 tx_cmd;
+	MV_STATUS status = MV_OK;
+#ifndef CONFIG_MV_ETH_TXDONE_ISR
+	u32 tx_done = 0;
+#endif
+	int txq, txp;
+	struct tx_queue *txq_ctrl;
+
+	read_lock(&pp->rwlock);
+
+	/* Get TxQ to send packet */
+	txq = mv_eth_txq_tos_map_get(pp, pkt->tos);
+	txp = pp->txp;
+	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+	spin_lock(&txq_ctrl->queue_lock);
+
+	/* Get next descriptor for tx, single buffer, so FIRST & LAST */
+	tx_desc = mv_eth_tx_desc_get(txq_ctrl, 1);
+	if (tx_desc == NULL) {
+
+		/* No resources: Drop */
+		dev->stats.tx_dropped++;
+		status = MV_DROPPED;
+		goto out;
+	}
+	txq_ctrl->txq_count++;
+
+	/* tx_cmd - word accumulated by NFP processing */
+	tx_cmd = pkt->tx_cmd;
+
+#ifdef CONFIG_MV_ETH_BM_CPU
+	tx_cmd |= NETA_TX_BM_ENABLE_MASK | NETA_TX_BM_POOL_ID_MASK(pkt->pool);
+	txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = (u32) NULL;
+	mv_eth_shadow_inc_put(txq_ctrl);
+#else
+	/* Remember pkt in separate TxQ shadow */
+	txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = (u32) pkt;
+	mv_eth_shadow_inc_put(txq_ctrl);
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	tx_desc->command = tx_cmd | NETA_TX_FLZ_DESC_MASK;
+	tx_desc->dataSize = pkt->bytes;
+	tx_desc->bufPhysAddr = pkt->physAddr;
+
+	/* FIXME: PON only? --BK */
+	tx_desc->hw_cmd = pkt->hw_cmd;
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if (pp->flags & MV_ETH_F_DBG_TX) {
+		printk(KERN_ERR "\n");
+		mv_eth_tx_desc_print(tx_desc);
+		mv_eth_pkt_print(pkt);
+	}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+	mv_eth_tx_desc_flush(tx_desc);
+
+	/* Enable transmit by update PENDING counter */
+	mvNetaTxqPendDescAdd(pp->port, txp, txq, 1);
+
+	/* FIXME: stats includes MH --BK */
+	dev->stats.tx_packets++;
+	dev->stats.tx_bytes += pkt->bytes;
+	STAT_DBG(txq_ctrl->stats.txq_tx++);
+
+#ifdef CONFIG_MV_PON
+	if (MV_PON_PORT(pp->port))
+		mvNetaPonTxqBytesAdd(pp->port, txp, txq, pkt->bytes);
+#endif /* CONFIG_MV_PON */
+
+out:
+#ifndef CONFIG_MV_ETH_TXDONE_ISR
+	if (txq_ctrl->txq_count >= mv_ctrl_txdone)
+		tx_done = mv_eth_txq_done(pp, txq_ctrl);
+
+	STAT_DIST(if (tx_done < pp->dist_stats.tx_done_dist_size)
+			pp->dist_stats.tx_done_dist[tx_done]++);
+
+	/* If after calling mv_eth_txq_done, txq_ctrl->txq_count is 1, we need to set the timer */
+	if ((txq_ctrl->txq_count == 1))
+		mv_eth_add_tx_done_timer(pp);
+#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+
+	spin_unlock(&txq_ctrl->queue_lock);
+	read_unlock(&pp->rwlock);
+
+	return status;
+}
+
+/* Function returns the following error codes:
+ *  MV_OK - packet processed and sent successfully by NFP
+ *  MV_TERMINATE - packet can't be processed by NFP - pass to Linux processing
+ *  MV_DROPPED - packet processed by NFP, but not sent (dropped)
+ */
+static MV_STATUS mv_eth_nfp(struct eth_port *pp, struct neta_rx_desc *rx_desc, struct eth_pbuf *pkt)
+{
+	MV_STATUS status;
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if (pp->flags & MV_ETH_F_DBG_RX) {
+		mv_eth_rx_desc_print(rx_desc);
+		mv_eth_pkt_print(pkt);
+	}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+#ifdef CONFIG_MV_ETH_NFP_SWF
+	if (rx_desc->pncInfo & NETA_PNC_SWF) {
+		status = mvNfpSwf(pp->port, rx_desc, pkt);
+		goto tx;
+	}
+#endif /* CONFIG_MV_ETH_NFP_SWF */
+
+#ifdef NFP_PNC
+	if (rx_desc->pncInfo & NETA_PNC_NFP) {
+		status = mvNfpPnC(pp->port, rx_desc, pkt);
+		goto tx;
+	}
+#endif /* NFP_PNC */
+
+	status = mvNfpRx(pp->port, rx_desc, pkt);
+#if defined(CONFIG_MV_ETH_NFP_SWF) || defined(NFP_PNC)
+tx:
+#endif
+	if (status == MV_OK)
+		status = mv_eth_nfp_tx(rx_desc, pkt);
+	return status;
+}
+#endif /* CONFIG_MV_ETH_NFP */
+
+/* Reuse pkt if possible, allocate new skb and move BM pool or RXQ ring */
+static inline int mv_eth_refill(struct eth_port *pp, int rxq,
+				struct eth_pbuf *pkt, struct bm_pool *pool, struct neta_rx_desc *rx_desc)
+{
+	if (pkt == NULL) {
+		pkt = mv_eth_pool_get(pool);
+		if (pkt == NULL)
+			return 1;
+	} else {
+		struct sk_buff *skb;
+
+		/* No recycle -  alloc new skb */
+		skb = mv_eth_skb_alloc(pool, pkt);
+		if (!skb) {
+			mvOsFree(pkt);
+			pool->missed++;
+			mv_eth_add_cleanup_timer(pp);
+			return 1;
+		}
+	}
+	mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+
+	return 0;
+}
+
+static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
+{
+	struct eth_port *pp = MV_ETH_PRIV(dev);
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+	int frags = 0;
+	bool tx_spec_ready = false;
+	struct mv_eth_tx_spec tx_spec;
+	u32 tx_cmd;
+	u16 mh;
+	struct tx_queue *txq_ctrl = NULL;
+	struct neta_tx_desc *tx_desc;
+
+	read_lock(&pp->rwlock);
+
+	if (!(netif_running(dev))) {
+		printk(KERN_ERR "!netif_running() in %s\n", __func__);
+		goto out;
+	}
+
+#if defined(CONFIG_MV_ETH_TX_SPECIAL)
+	if (pp->tx_special_check) {
+
+		if (pp->tx_special_check(pp->port, dev, skb, &tx_spec)) {
+			STAT_INFO(pp->stats.tx_special++);
+			if (tx_spec.tx_func) {
+				tx_spec.tx_func(skb->data, skb->len, &tx_spec);
+				goto out;
+			} else {
+				/* Check validity of tx_spec txp/txq must be CPU owned */
+				tx_spec_ready = true;
+			}
+		}
+	}
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+
+	/* Get TXQ (without BM) to send packet generated by Linux */
+	if (tx_spec_ready == false) {
+		tx_spec.txp = pp->txp;
+		tx_spec.txq = mv_eth_tx_policy(pp, skb);
+		tx_spec.hw_cmd = pp->hw_cmd;
+		tx_spec.flags = pp->flags;
+	}
+
+	txq_ctrl = &pp->txq_ctrl[tx_spec.txp * CONFIG_MV_ETH_TXQ + tx_spec.txq];
+	if (txq_ctrl == NULL) {
+		printk(KERN_ERR "%s: invalidate txp/txq (%d/%d)\n", __func__, tx_spec.txp, tx_spec.txq);
+		goto out;
+	}
+	spin_lock(&txq_ctrl->queue_lock);
+
+#ifdef CONFIG_MV_ETH_TSO
+	/* GSO/TSO */
+	if (skb_is_gso(skb)) {
+		frags = mv_eth_tx_tso(skb, dev, &tx_spec, txq_ctrl);
+		goto out;
+	}
+#endif /* CONFIG_MV_ETH_TSO */
+
+	frags = skb_shinfo(skb)->nr_frags + 1;
+
+	if (tx_spec.flags & MV_ETH_F_MH) {
+		if (tx_spec.flags & MV_ETH_F_SWITCH)
+			mh = dev_priv->tx_vlan_mh;
+		else
+			mh = pp->tx_mh;
+
+		if (mv_eth_skb_mh_add(skb, mh)) {
+			frags = 0;
+			goto out;
+		}
+	}
+
+	tx_desc = mv_eth_tx_desc_get(txq_ctrl, frags);
+	if (tx_desc == NULL) {
+		frags = 0;
+		goto out;
+	}
+
+	/* Don't use BM for Linux packets: NETA_TX_BM_ENABLE_MASK = 0 */
+	/* NETA_TX_PKT_OFFSET_MASK = 0 - for all descriptors */
+	tx_cmd = mv_eth_skb_tx_csum(pp, skb);
+
+#ifdef CONFIG_MV_PON
+	tx_desc->hw_cmd = tx_spec.hw_cmd;
+#endif
+
+	/* FIXME: beware of nonlinear --BK */
+	tx_desc->dataSize = skb_headlen(skb);
+
+	tx_desc->bufPhysAddr = mvOsCacheFlush(NULL, skb->data, tx_desc->dataSize);
+
+	if (frags == 1) {
+		/*
+		 * First and Last descriptor
+		 */
+		if (tx_spec.flags & MV_ETH_F_NO_PAD)
+			tx_cmd |= NETA_TX_F_DESC_MASK | NETA_TX_L_DESC_MASK;
+		else
+			tx_cmd |= NETA_TX_FLZ_DESC_MASK;
+
+		tx_desc->command = tx_cmd;
+		mv_eth_tx_desc_flush(tx_desc);
+
+		txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = ((MV_ULONG) skb | MV_ETH_SHADOW_SKB);
+		mv_eth_shadow_inc_put(txq_ctrl);
+	} else {
+
+		/* First but not Last */
+		tx_cmd |= NETA_TX_F_DESC_MASK;
+
+		txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = 0;
+		mv_eth_shadow_inc_put(txq_ctrl);
+
+		tx_desc->command = tx_cmd;
+		mv_eth_tx_desc_flush(tx_desc);
+
+		/* Continue with other skb fragments */
+		mv_eth_tx_frag_process(pp, skb, txq_ctrl, tx_spec.flags);
+		STAT_DBG(pp->stats.tx_sg++);
+	}
+/*
+	printk(KERN_ERR "tx: frags=%d, tx_desc[0x0]=%x [0xc]=%x, wr_id=%d, rd_id=%d, skb=%p\n",
+			frags, tx_desc->command,tx_desc->hw_cmd,
+			txq_ctrl->shadow_txq_put_i, txq_ctrl->shadow_txq_get_i, skb);
+*/
+	txq_ctrl->txq_count += frags;
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if (pp->flags & MV_ETH_F_DBG_TX) {
+		printk(KERN_ERR "\n");
+		printk(KERN_ERR "%s - eth_tx_%lu: port=%d, txp=%d, txq=%d, skb=%p, head=%p, data=%p, size=%d\n",
+		       dev->name, dev->stats.tx_packets, pp->port, tx_spec.txp, tx_spec.txq, skb,
+			   skb->head, skb->data, skb->len);
+		mv_eth_tx_desc_print(tx_desc);
+		/*mv_eth_skb_print(skb);*/
+		mvDebugMemDump(skb->data, 64, 1);
+	}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+	/* Enable transmit */
+	mvNetaTxqPendDescAdd(pp->port, tx_spec.txp, tx_spec.txq, frags);
+
+	STAT_DBG(txq_ctrl->stats.txq_tx += frags);
+
+out:
+	if (frags > 0) {
+		dev->stats.tx_packets++;
+		dev->stats.tx_bytes += skb->len;
+#ifdef CONFIG_MV_PON
+		if (MV_PON_PORT(pp->port))
+			mvNetaPonTxqBytesAdd(pp->port, tx_spec.txp, tx_spec.txq, skb->len);
+#endif /* CONFIG_MV_PON */
+	} else {
+		dev->stats.tx_dropped++;
+		dev_kfree_skb_any(skb);
+	}
+
+#ifndef CONFIG_MV_ETH_TXDONE_ISR
+	if (txq_ctrl) {
+		if (txq_ctrl->txq_count >= mv_ctrl_txdone) {
+			STAT_DIST(u32 tx_done =) mv_eth_txq_done(pp, txq_ctrl);
+
+			STAT_DIST(if (tx_done < pp->dist_stats.tx_done_dist_size)
+					pp->dist_stats.tx_done_dist[tx_done]++);
+		}
+		/* If after calling mv_eth_txq_done, txq_ctrl->txq_count equals frags, we need to set the timer */
+		if ((txq_ctrl->txq_count == frags) && (frags > 0))
+			mv_eth_add_tx_done_timer(pp);
+	}
+#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+
+	if (txq_ctrl)
+		spin_unlock(&txq_ctrl->queue_lock);
+
+	read_unlock(&pp->rwlock);
+	return NETDEV_TX_OK;
+}
+
+#ifdef CONFIG_MV_ETH_TSO
+/* Validate TSO */
+static inline int mv_eth_tso_validate(struct sk_buff *skb, struct net_device *dev)
+{
+	if (!(dev->features & NETIF_F_TSO)) {
+		printk(KERN_ERR "error: (skb_is_gso(skb) returns true but features is not NETIF_F_TSO\n");
+		return 1;
+	}
+
+	if (skb_shinfo(skb)->frag_list != NULL) {
+		printk(KERN_ERR "***** ERROR: frag_list is not null\n");
+		return 1;
+	}
+
+	if (skb_shinfo(skb)->gso_segs == 1) {
+		printk(KERN_ERR "***** ERROR: only one TSO segment\n");
+		return 1;
+	}
+
+	if (skb->len <= skb_shinfo(skb)->gso_size) {
+		printk(KERN_ERR "***** ERROR: total_len (%d) less than gso_size (%d)\n", skb->len, skb_shinfo(skb)->gso_size);
+		return 1;
+	}
+	if ((htons(ETH_P_IP) != skb->protocol) || (ip_hdr(skb)->protocol != IPPROTO_TCP) || (tcp_hdr(skb) == NULL)) {
+		printk(KERN_ERR "***** ERROR: Protocol is not TCP over IP\n");
+		return 1;
+	}
+	return 0;
+}
+
+static inline int mv_eth_tso_build_hdr_desc(struct neta_tx_desc *tx_desc, struct eth_port *priv, struct sk_buff *skb,
+					     struct tx_queue *txq_ctrl, u16 *mh, int hdr_len, int size,
+					     MV_U32 tcp_seq, MV_U16 ip_id, int left_len)
+{
+	struct iphdr *iph;
+	struct tcphdr *tcph;
+	MV_U8 *data, *mac;
+	int mac_hdr_len = skb_network_offset(skb);
+
+	data = mv_eth_extra_pool_get(priv);
+	if (!data)
+		return -1;
+
+	txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = ((MV_ULONG)data | MV_ETH_SHADOW_EXT);
+
+	/* Reserve 2 bytes for IP header alignment */
+	mac = data + MV_ETH_MH_SIZE;
+	iph = (struct iphdr *)(mac + mac_hdr_len);
+
+	memcpy(mac, skb->data, hdr_len);
+
+	if (iph) {
+		iph->id = htons(ip_id);
+		iph->tot_len = htons(size + hdr_len - mac_hdr_len);
+	}
+
+	tcph = (struct tcphdr *)(mac + skb_transport_offset(skb));
+	tcph->seq = htonl(tcp_seq);
+
+	if (left_len) {
+		/* Clear all special flags for not last packet */
+		tcph->psh = 0;
+		tcph->fin = 0;
+		tcph->rst = 0;
+	}
+
+	if (mh) {
+		/* Start tarnsmit from MH - add 2 bytes to size */
+		*((MV_U16 *)data) = *mh;
+		/* increment ip_offset field in TX descriptor by 2 bytes */
+		mac_hdr_len += MV_ETH_MH_SIZE;
+		hdr_len += MV_ETH_MH_SIZE;
+	} else {
+		/* Start transmit from MAC */
+		data = mac;
+	}
+
+	tx_desc->dataSize = hdr_len;
+	tx_desc->command = mvNetaTxqDescCsum(mac_hdr_len, skb->protocol, ((u8 *)tcph - (u8 *)iph) >> 2, IPPROTO_TCP);
+	tx_desc->command |= NETA_TX_F_DESC_MASK;
+
+	tx_desc->bufPhysAddr = mvOsCacheFlush(NULL, data, tx_desc->dataSize);
+	mv_eth_shadow_inc_put(txq_ctrl);
+
+	mv_eth_tx_desc_flush(tx_desc);
+
+	return 0;
+}
+
+static inline int mv_eth_tso_build_data_desc(struct neta_tx_desc *tx_desc, struct sk_buff *skb,
+					     struct tx_queue *txq_ctrl, char *frag_ptr,
+					     int frag_size, int data_left, int total_left)
+{
+	int size;
+
+	size = MV_MIN(frag_size, data_left);
+
+	tx_desc->dataSize = size;
+	tx_desc->bufPhysAddr = mvOsCacheFlush(NULL, frag_ptr, size);
+	tx_desc->command = 0;
+	txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = 0;
+
+	if (size == data_left) {
+		/* last descriptor in the TCP packet */
+		tx_desc->command = NETA_TX_L_DESC_MASK;
+
+		if (total_left == 0) {
+			/* last descriptor in SKB */
+			txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = ((MV_ULONG) skb | MV_ETH_SHADOW_SKB);
+		}
+	}
+	mv_eth_shadow_inc_put(txq_ctrl);
+	mv_eth_tx_desc_flush(tx_desc);
+
+	return size;
+}
+
+/***********************************************************
+ * mv_eth_tx_tso --                                        *
+ *   send a packet.                                        *
+ ***********************************************************/
+int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev,
+		struct mv_eth_tx_spec *tx_spec, struct tx_queue *txq_ctrl)
+{
+	int frag = 0;
+	int total_len, hdr_len, size, frag_size, data_left;
+	char *frag_ptr;
+	int totalDescNum;
+	struct neta_tx_desc *tx_desc;
+	MV_U16 ip_id;
+	MV_U32 tcp_seq = 0;
+	skb_frag_t *skb_frag_ptr;
+	const struct tcphdr *th = tcp_hdr(skb);
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+	MV_U16 *mh = NULL;
+	int i;
+
+	STAT_DBG(priv->stats.tx_tso++);
+/*
+	printk(KERN_ERR "mv_eth_tx_tso_%d ENTER: skb=%p, total_len=%d\n", priv->stats.tx_tso, skb, skb->len);
+*/
+	if (mv_eth_tso_validate(skb, dev))
+		return 0;
+
+	/* Calculate expected number of TX descriptors */
+	totalDescNum = skb_shinfo(skb)->gso_segs * 2 + skb_shinfo(skb)->nr_frags;
+
+	if ((txq_ctrl->txq_count + totalDescNum) >= txq_ctrl->txq_size) {
+/*
+		printk(KERN_ERR "%s: no TX descriptors - txq_count=%d, len=%d, nr_frags=%d, gso_segs=%d\n",
+					__func__, txq_ctrl->txq_count, skb->len, skb_shinfo(skb)->nr_frags,
+					skb_shinfo(skb)->gso_segs);
+*/
+		STAT_ERR(txq_ctrl->stats.txq_err++);
+		return 0;
+	}
+
+	total_len = skb->len;
+	hdr_len = (skb_transport_offset(skb) + tcp_hdrlen(skb));
+
+	total_len -= hdr_len;
+	ip_id = ntohs(ip_hdr(skb)->id);
+	tcp_seq = ntohl(th->seq);
+
+	frag_size = skb_headlen(skb);
+	frag_ptr = skb->data;
+
+	if (frag_size < hdr_len) {
+		printk(KERN_ERR "***** ERROR: frag_size=%d, hdr_len=%d\n", frag_size, hdr_len);
+		return 0;
+	}
+
+	frag_size -= hdr_len;
+	frag_ptr += hdr_len;
+	if (frag_size == 0) {
+		skb_frag_ptr = &skb_shinfo(skb)->frags[frag];
+
+		/* Move to next segment */
+		frag_size = skb_frag_ptr->size;
+		frag_ptr = page_address(skb_frag_ptr->page) + skb_frag_ptr->page_offset;
+		frag++;
+	}
+	totalDescNum = 0;
+
+	while (total_len > 0) {
+		data_left = MV_MIN(skb_shinfo(skb)->gso_size, total_len);
+
+		tx_desc = mv_eth_tx_desc_get(txq_ctrl, 1);
+		if (tx_desc == NULL)
+			goto outNoTxDesc;
+
+		totalDescNum++;
+		total_len -= data_left;
+		txq_ctrl->txq_count++;
+
+		if (tx_spec->flags & MV_ETH_F_MH) {
+			if (tx_spec->flags & MV_ETH_F_SWITCH)
+				mh = &dev_priv->tx_vlan_mh;
+			else
+				mh = &priv->tx_mh;
+		}
+
+		/* prepare packet headers: MAC + IP + TCP */
+		if (mv_eth_tso_build_hdr_desc(tx_desc, priv, skb, txq_ctrl, mh,
+					hdr_len, data_left, tcp_seq, ip_id, total_len))
+			goto outNoTxDesc;
+
+/*
+		printk(KERN_ERR "Header desc: tx_desc=%p, skb=%p, hdr_len=%d, data_left=%d\n",
+						tx_desc, skb, hdr_len, data_left);
+*/
+		ip_id++;
+
+		while (data_left > 0) {
+			tx_desc = mv_eth_tx_desc_get(txq_ctrl, 1);
+			if (tx_desc == NULL)
+				goto outNoTxDesc;
+
+			totalDescNum++;
+			txq_ctrl->txq_count++;
+
+			size = mv_eth_tso_build_data_desc(tx_desc, skb, txq_ctrl,
+							  frag_ptr, frag_size, data_left, total_len);
+
+/*
+			printk(KERN_ERR "Data desc: tx_desc=%p, skb=%p, size=%d, frag_size=%d, data_left=%d\n",
+							tx_desc, skb, size, frag_size, data_left);
+ */
+			data_left -= size;
+			tcp_seq += size;
+
+			frag_size -= size;
+			frag_ptr += size;
+
+			if ((frag_size == 0) && (frag < skb_shinfo(skb)->nr_frags)) {
+				skb_frag_ptr = &skb_shinfo(skb)->frags[frag];
+
+				/* Move to next segment */
+				frag_size = skb_frag_ptr->size;
+				frag_ptr = page_address(skb_frag_ptr->page) + skb_frag_ptr->page_offset;
+				frag++;
+			}
+		}		/* of while data_left > 0 */
+	}			/* of while (total_len > 0) */
+
+	STAT_DBG(priv->stats.tx_tso_bytes += skb->len);
+	STAT_DBG(txq_ctrl->stats.txq_tx += totalDescNum);
+
+	mvNetaTxqPendDescAdd(priv->port, txq_ctrl->txp, txq_ctrl->txq, totalDescNum);
+/*
+	printk(KERN_ERR "mv_eth_tx_tso EXIT: totalDescNum=%d\n", totalDescNum);
+*/
+	return totalDescNum;
+
+outNoTxDesc:
+	/* No enough TX descriptors for the whole skb - rollback */
+	printk(KERN_ERR "%s: No TX descriptors - rollback %d, txq_count=%d, nr_frags=%d, skb=%p, len=%d, gso_segs=%d\n",
+			__func__, totalDescNum, txq_ctrl->txq_count, skb_shinfo(skb)->nr_frags,
+			skb, skb->len, skb_shinfo(skb)->gso_segs);
+
+	for (i = 0; i < totalDescNum; i++) {
+		txq_ctrl->txq_count--;
+		mv_eth_shadow_dec_put(txq_ctrl);
+		mvNetaTxqPrevDescGet(txq_ctrl->q);
+	}
+	return 0;
+}
+#endif /* CONFIG_MV_ETH_TSO */
+
+
+static inline void mv_eth_txq_bufs_free(struct eth_port *pp, struct tx_queue *txq_ctrl, int num)
+{
+	u32 shadow;
+	int i;
+
+	/* Free buffers that was not freed automatically by BM */
+	for (i = 0; i < num; i++) {
+		shadow = txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_get_i];
+		mv_eth_shadow_inc_get(txq_ctrl);
+
+		if (!shadow)
+			continue;
+/*
+		printk(KERN_ERR "tx_done: p=%d, txp=%d, txq=%d, writeIdx=%d, readIdx=%d, shadow=0x%x\n",
+					pp->port, txq_ctrl->txp, txq_ctrl->txq, txq_ctrl->shadow_txq_put_i,
+					txq_ctrl->shadow_txq_get_i, shadow);
+*/
+		if (shadow & MV_ETH_SHADOW_SKB) {
+			shadow &= ~MV_ETH_SHADOW_SKB;
+			dev_kfree_skb_any((struct sk_buff *)shadow);
+			STAT_DBG(pp->stats.tx_skb_free++);
+		} else {
+			if (shadow & MV_ETH_SHADOW_EXT) {
+				shadow &= ~MV_ETH_SHADOW_EXT;
+				mv_eth_extra_pool_put(pp, (void *)shadow);
+			} else {
+				/* packet from NFP without BM */
+				struct eth_pbuf *pkt = (struct eth_pbuf *)shadow;
+				struct bm_pool *pool = &mv_eth_pool[pkt->pool];
+
+				mv_eth_pool_put(pool, pkt);
+			}
+		}
+	}
+}
+
+/* Drop packets received by the RXQ and free buffers */
+static void mv_eth_rxq_drop_pkts(struct eth_port *pp, int rxq)
+{
+	struct neta_rx_desc *rx_desc;
+	struct eth_pbuf     *pkt;
+	struct bm_pool      *pool;
+	int	                rx_done, i;
+	MV_NETA_RXQ_CTRL    *rx_ctrl = pp->rxq_ctrl[rxq].q;
+
+	if (rx_ctrl == NULL)
+		return;
+
+	rx_done = mvNetaRxqBusyDescNumGet(pp->port, rxq);
+	mvOsCacheIoSync();
+
+	for (i = 0; i < rx_done; i++) {
+		rx_desc = mvNetaRxqNextDescGet(rx_ctrl);
+		mvOsCacheLineInv(NULL, rx_desc);
+
+#if defined(MV_CPU_BE)
+		mvNetaRxqDescSwap(rx_desc);
+#endif /* MV_CPU_BE */
+
+		pkt = (struct eth_pbuf *)rx_desc->bufCookie;
+		pool = &mv_eth_pool[pkt->pool];
+		mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+	}
+	if (rx_done) {
+		mvOsCacheIoSync();
+		mvNetaRxqDescNumUpdate(pp->port, rxq, rx_done, rx_done);
+	}
+}
+
+static void mv_eth_txq_done_force(struct eth_port *pp, struct tx_queue *txq_ctrl)
+{
+	int tx_done = txq_ctrl->txq_count;
+
+	mv_eth_txq_bufs_free(pp, txq_ctrl, tx_done);
+
+	STAT_DBG(txq_ctrl->stats.txq_txdone += tx_done);
+
+	/* reset txq */
+	txq_ctrl->txq_count = 0;
+	txq_ctrl->shadow_txq_put_i = 0;
+	txq_ctrl->shadow_txq_get_i = 0;
+}
+
+inline u32 mv_eth_txq_done(struct eth_port *pp, struct tx_queue *txq_ctrl)
+{
+	int tx_done;
+
+	tx_done = mvNetaTxqSentDescProc(pp->port, txq_ctrl->txp, txq_ctrl->txq);
+	if (!tx_done)
+		return tx_done;
+/*
+	printk(KERN_ERR "tx_done: txq_count=%d, port=%d, txp=%d, txq=%d, tx_done=%d\n",
+			txq_ctrl->txq_count, pp->port, txq_ctrl->txp, txq_ctrl->txq, tx_done);
+*/
+	if (!mv_eth_txq_bm(txq_ctrl))
+		mv_eth_txq_bufs_free(pp, txq_ctrl, tx_done);
+
+	txq_ctrl->txq_count -= tx_done;
+	STAT_DBG(txq_ctrl->stats.txq_txdone += tx_done);
+
+	return tx_done;
+}
+
+inline u32 mv_eth_tx_done_pon(struct eth_port *pp, int *tx_todo)
+{
+	int txp, txq;
+	struct tx_queue *txq_ctrl;
+	u32 tx_done = 0;
+
+	*tx_todo = 0;
+
+	STAT_INFO(pp->stats.tx_done++);
+
+	/* simply go over all TX ports and TX queues */
+	txp = pp->txp_num;
+	while (txp--) {
+		txq = CONFIG_MV_ETH_TXQ;
+
+		while (txq--) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+			spin_lock(&txq_ctrl->queue_lock);
+			if ((txq_ctrl) && (txq_ctrl->txq_count)) {
+				tx_done += mv_eth_txq_done(pp, txq_ctrl);
+				*tx_todo += txq_ctrl->txq_count;
+			}
+			spin_unlock(&txq_ctrl->queue_lock);
+		}
+	}
+
+	STAT_DIST(if (tx_done < pp->dist_stats.tx_done_dist_size)
+			pp->dist_stats.tx_done_dist[tx_done]++);
+
+	return tx_done;
+}
+
+
+inline u32 mv_eth_tx_done_gbe(struct eth_port *pp, u32 cause_tx_done, int *tx_todo)
+{
+	int txp, txq;
+	struct tx_queue *txq_ctrl;
+	u32 tx_done = 0;
+
+	*tx_todo = 0;
+
+	STAT_INFO(pp->stats.tx_done++);
+
+	while (cause_tx_done != 0) {
+		/* For GbE ports we get TX Buffers Threshold Cross per queue in bits [7:0] */
+		txp = pp->txp_num; /* 1 for GbE ports */
+		while (txp--) {
+			txq = mv_eth_tx_done_policy(cause_tx_done);
+			if (txq == -1)
+				break;
+
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+			spin_lock(&txq_ctrl->queue_lock);
+			if ((txq_ctrl) && (txq_ctrl->txq_count)) {
+				tx_done += mv_eth_txq_done(pp, txq_ctrl);
+				*tx_todo += txq_ctrl->txq_count;
+			}
+			spin_unlock(&txq_ctrl->queue_lock);
+
+			cause_tx_done &= ~((1 << txq) << NETA_CAUSE_TXQ_SENT_DESC_OFFS);
+		}
+	}
+
+	STAT_DIST(if (tx_done < pp->dist_stats.tx_done_dist_size)
+			pp->dist_stats.tx_done_dist[tx_done]++);
+
+	return tx_done;
+}
+
+
+static void mv_eth_tx_frag_process(struct eth_port *pp, struct sk_buff *skb, struct tx_queue *txq_ctrl,	u16 flags)
+{
+	int i;
+	struct neta_tx_desc *tx_desc;
+
+	for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {
+		skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
+
+		tx_desc = mvNetaTxqNextDescGet(txq_ctrl->q);
+
+		/* NETA_TX_BM_ENABLE_MASK = 0 */
+		/* NETA_TX_PKT_OFFSET_MASK = 0 */
+		tx_desc->dataSize = frag->size;
+		tx_desc->bufPhysAddr = mvOsCacheFlush(NULL, page_address(frag->page) + frag->page_offset,
+						      tx_desc->dataSize);
+
+		if (i == (skb_shinfo(skb)->nr_frags - 1)) {
+			/* Last descriptor */
+			if (flags & MV_ETH_F_NO_PAD)
+				tx_desc->command = NETA_TX_L_DESC_MASK;
+			else
+				tx_desc->command = (NETA_TX_L_DESC_MASK | NETA_TX_Z_PAD_MASK);
+
+			txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = ((MV_ULONG) skb | MV_ETH_SHADOW_SKB);
+			mv_eth_shadow_inc_put(txq_ctrl);
+		} else {
+			/* Descriptor in the middle: Not First, Not Last */
+			tx_desc->command = 0;
+
+			txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = 0;
+			mv_eth_shadow_inc_put(txq_ctrl);
+		}
+
+		mv_eth_tx_desc_flush(tx_desc);
+	}
+}
+
+
+/* Free "num" buffers from the pool */
+static int mv_eth_pool_free(int pool, int num)
+{
+	struct eth_pbuf *pkt;
+	int i = 0;
+	struct bm_pool *ppool = &mv_eth_pool[pool];
+	unsigned long flags = 0;
+
+	MV_ETH_LOCK(&ppool->lock, flags);
+
+	if (num >= ppool->buf_num) {
+		/* Free all buffers from the pool */
+		num = ppool->buf_num;
+
+#ifdef CONFIG_MV_ETH_BM_CPU
+		mvBmConfigSet(MV_BM_EMPTY_LIMIT_MASK);
+#endif /* CONFIG_MV_ETH_BM_CPU */
+	}
+
+	while (i < num) {
+		pkt = NULL;
+
+		if (mv_eth_pool_bm(ppool)) {
+#ifdef CONFIG_MV_ETH_BM_CPU
+			MV_U32 *va;
+			MV_U32 pa = mvBmPoolGet(pool);
+
+			if (pa != 0) {
+				va = phys_to_virt(pa);
+				pkt = (struct eth_pbuf *)*va;
+/*
+			printk(KERN_ERR "mv_eth_pool_free_%d: pool=%d, pkt=%p, head=%p (%x)\n",
+				i, pool, pkt, va, pa);
+*/
+			}
+#endif /* CONFIG_MV_ETH_BM_CPU */
+		} else {
+			if (mvStackIndex(ppool->stack) > 0)
+				pkt = (struct eth_pbuf *)mvStackPop(ppool->stack);
+		}
+		if (pkt) {
+			struct sk_buff *skb = (struct sk_buff *)pkt->osInfo;
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+			skb->skb_recycle = NULL;
+			skb->hw_cookie = NULL;
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+#ifdef ETH_SKB_DEBUG
+			mv_eth_skb_check(skb);
+#endif /* ETH_SKB_DEBUG */
+
+			i++;
+			dev_kfree_skb_any(skb);
+			mvOsFree(pkt);
+		} else
+			break;
+	}
+	printk(KERN_ERR "pool #%d: pkt_size=%d, buf_size=%d - %d of %d buffers free\n",
+	       pool, ppool->pkt_size, RX_BUF_SIZE(ppool->pkt_size), i, num);
+
+	ppool->buf_num -= num;
+
+#ifdef CONFIG_MV_ETH_BM_CPU
+		mvBmConfigClear(MV_BM_EMPTY_LIMIT_MASK);
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	MV_ETH_UNLOCK(&ppool->lock, flags);
+
+	return i;
+}
+
+
+static int mv_eth_pool_destroy(int pool)
+{
+	int num, status = 0;
+	struct bm_pool *ppool = &mv_eth_pool[pool];
+
+	num = mv_eth_pool_free(pool, ppool->buf_num);
+	if (num != ppool->buf_num) {
+		printk(KERN_ERR "Warning: could not free all buffers in pool %d while destroying pool\n", pool);
+		return MV_ERROR;
+	}
+
+	status = mvStackDelete(ppool->stack);
+
+#ifdef CONFIG_MV_ETH_BM_CPU
+	mvBmPoolDisable(pool);
+
+	/* Note: we don't free the bm_pool here ! */
+	if (ppool->bm_pool)
+		mvOsFree(ppool->bm_pool);
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	memset(ppool, 0, sizeof(struct bm_pool));
+
+	return status;
+}
+
+
+static int mv_eth_pool_add(int pool, int buf_num)
+{
+	struct bm_pool *bm_pool;
+	struct sk_buff *skb;
+	struct eth_pbuf *pkt;
+	int i;
+	unsigned long flags = 0;
+
+	if ((pool < 0) || (pool >= MV_ETH_BM_POOLS)) {
+		printk(KERN_ERR "%s: invalid pool number %d\n", __func__, pool);
+		return 0;
+	}
+
+	bm_pool = &mv_eth_pool[pool];
+
+	/* Check buffer size */
+	if (bm_pool->pkt_size == 0) {
+		printk(KERN_ERR "%s: invalid pool #%d state: pkt_size=%d, buf_size=%d, buf_num=%d\n",
+		       __func__, pool, bm_pool->pkt_size, RX_BUF_SIZE(bm_pool->pkt_size), bm_pool->buf_num);
+		return 0;
+	}
+
+	/* Insure buf_num is smaller than capacity */
+	if ((buf_num < 0) || ((buf_num + bm_pool->buf_num) > (bm_pool->capacity))) {
+
+		printk(KERN_ERR "%s: can't add %d buffers into bm_pool=%d: capacity=%d, buf_num=%d\n",
+		       __func__, buf_num, pool, bm_pool->capacity, bm_pool->buf_num);
+		return 0;
+	}
+
+	MV_ETH_LOCK(&bm_pool->lock, flags);
+
+	for (i = 0; i < buf_num; i++) {
+		pkt = mvOsMalloc(sizeof(struct eth_pbuf));
+		if (!pkt) {
+			printk(KERN_ERR "%s: can't allocate %d bytes\n", __func__, sizeof(struct eth_pbuf));
+			break;
+		}
+
+		skb = mv_eth_skb_alloc(bm_pool, pkt);
+		if (!skb) {
+			kfree(pkt);
+			break;
+		}
+/*
+	printk(KERN_ERR "skb_alloc_%d: pool=%d, skb=%p, pkt=%p, head=%p (%lx), skb->truesize=%d\n",
+				i, bm_pool->pool, skb, pkt, pkt->pBuf, pkt->physAddr, skb->truesize);
+*/
+
+#ifdef CONFIG_MV_ETH_BM_CPU
+		mvBmPoolPut(pool, (MV_ULONG) pkt->physAddr);
+		STAT_DBG(bm_pool->stats.bm_put++);
+#else
+		mvStackPush(bm_pool->stack, (MV_U32) pkt);
+		STAT_DBG(bm_pool->stats.stack_put++);
+#endif /* CONFIG_MV_ETH_BM_CPU */
+	}
+	bm_pool->buf_num += i;
+
+	printk(KERN_ERR "pool #%d: pkt_size=%d, buf_size=%d - %d of %d buffers added\n",
+	       pool, bm_pool->pkt_size, RX_BUF_SIZE(bm_pool->pkt_size), i, buf_num);
+
+	MV_ETH_UNLOCK(&bm_pool->lock, flags);
+
+	return i;
+}
+
+#ifdef CONFIG_MV_ETH_BM
+void	*mv_eth_bm_pool_create(int pool, int capacity, MV_ULONG *pPhysAddr)
+{
+		MV_ULONG			physAddr;
+		MV_UNIT_WIN_INFO	winInfo;
+		void				*pVirt;
+		MV_STATUS			status;
+
+		pVirt = mvOsIoUncachedMalloc(NULL, sizeof(MV_U32) * capacity, &physAddr, NULL);
+		if (pVirt == NULL) {
+			mvOsPrintf("%s: Can't allocate %d bytes for Long pool #%d\n",
+					__func__, MV_BM_POOL_CAP_MAX * sizeof(MV_U32), pool);
+			return NULL;
+		}
+
+		/* Pool address must be MV_BM_POOL_PTR_ALIGN bytes aligned */
+		if (MV_IS_NOT_ALIGN((unsigned)pVirt, MV_BM_POOL_PTR_ALIGN)) {
+			mvOsPrintf("memory allocated for BM pool #%d is not %d bytes aligned\n",
+						pool, MV_BM_POOL_PTR_ALIGN);
+			mvOsIoCachedFree(NULL, sizeof(MV_U32) * capacity, physAddr, pVirt, 0);
+			return NULL;
+		}
+		status = mvBmPoolInit(pool, pVirt, physAddr, capacity);
+		if (status != MV_OK) {
+			mvOsPrintf("%s: Can't init #%d BM pool. status=%d\n", __func__, pool, status);
+			mvOsIoCachedFree(NULL, sizeof(MV_U32) * capacity, physAddr, pVirt, 0);
+			return NULL;
+		}
+		status = mvCtrlAddrWinInfoGet(&winInfo, physAddr);
+		if (status != MV_OK) {
+			printk(KERN_ERR "%s: Can't map BM pool #%d. phys_addr=0x%x, status=%d\n",
+			       __func__, pool, (unsigned)physAddr, status);
+			mvOsIoCachedFree(NULL, sizeof(MV_U32) * capacity, physAddr, pVirt, 0);
+			return NULL;
+		}
+		mvBmPoolTargetSet(pool, winInfo.targetId, winInfo.attrib);
+		mvBmPoolEnable(pool);
+
+		if (pPhysAddr != NULL)
+			*pPhysAddr = physAddr;
+
+		return pVirt;
+}
+#endif /* CONFIG_MV_ETH_BM */
+
+static MV_STATUS mv_eth_pool_create(int pool, int capacity)
+{
+	struct bm_pool *bm_pool;
+
+	if ((pool < 0) || (pool >= MV_ETH_BM_POOLS)) {
+		printk(KERN_ERR "%s: pool=%d is out of range\n", __func__, pool);
+		return MV_BAD_VALUE;
+	}
+
+	bm_pool = &mv_eth_pool[pool];
+	memset(bm_pool, 0, sizeof(struct bm_pool));
+
+#ifdef CONFIG_MV_ETH_BM_CPU
+	bm_pool->bm_pool = mv_eth_bm_pool_create(pool, capacity, NULL);
+	if (bm_pool->bm_pool == NULL)
+		return MV_FAIL;
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	/* Create Stack as container of alloacted skbs for SKB_RECYCLE and for RXQs working without BM support */
+	bm_pool->stack = mvStackCreate(capacity);
+
+	if (bm_pool->stack == NULL) {
+		printk(KERN_ERR "Can't create MV_STACK structure for %d elements\n", capacity);
+		return MV_OUT_OF_CPU_MEM;
+	}
+
+	bm_pool->pool = pool;
+	bm_pool->capacity = capacity;
+	bm_pool->pkt_size = 0;
+	bm_pool->buf_num = 0;
+	spin_lock_init(&bm_pool->lock);
+
+	return MV_OK;
+}
+
+/* Interrupt handling */
+irqreturn_t mv_eth_isr(int irq, void *dev_id)
+{
+	struct eth_port *pp = (struct eth_port *)dev_id;
+	struct napi_struct *napi = pp->napi[smp_processor_id()];
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if (pp->flags & MV_ETH_F_DBG_ISR) {
+		printk(KERN_ERR "%s: port=%d, cpu=%d, mask=0x%x, cause=0x%x\n",
+			__func__, pp->port, smp_processor_id(),
+			MV_REG_READ(NETA_INTR_NEW_MASK_REG(pp->port)), MV_REG_READ(NETA_INTR_NEW_CAUSE_REG(pp->port)));
+	}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+	STAT_INFO(pp->stats.irq++);
+
+	/* Mask all interrupts */
+	MV_REG_WRITE(NETA_INTR_NEW_MASK_REG(pp->port), 0);
+	/* To be sure that itterrupt already masked Dummy read is required */
+	/* MV_REG_READ(NETA_INTR_NEW_MASK_REG(pp->port));*/
+
+	/* Verify that the device not already on the polling list */
+	if (napi_schedule_prep(napi)) {
+		/* schedule the work (rx+txdone+link) out of interrupt contxet */
+		__napi_schedule(napi);
+	} else {
+		STAT_INFO(pp->stats.irq_err++);
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+		printk(KERN_ERR "mv_eth_isr ERROR: port=%d, cpu=%d\n", pp->port, smp_processor_id());
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+	}
+	return IRQ_HANDLED;
+}
+
+void mv_eth_link_event(struct eth_port *pp, int print)
+{
+	struct net_device *dev = pp->dev;
+
+	STAT_INFO(pp->stats.link++);
+
+	/* Check Link status on ethernet port */
+	if (mvNetaLinkIsUp(pp->port)) {
+		mvNetaPortUp(pp->port);
+		set_bit(MV_ETH_F_LINK_UP_BIT, &(pp->flags));
+
+		if (mv_eth_ctrl_is_tx_enabled(pp)) {
+			if (dev) {
+				netif_carrier_on(dev);
+				netif_wake_queue(dev);
+			}
+		}
+	} else {
+		if (dev) {
+			netif_carrier_off(dev);
+			netif_stop_queue(dev);
+		}
+		mvNetaPortDown(pp->port);
+		clear_bit(MV_ETH_F_LINK_UP_BIT, &(pp->flags));
+	}
+
+	if (print) {
+		if (dev)
+			printk(KERN_ERR "%s: ", dev->name);
+		else
+			printk(KERN_ERR "%s: ", "none");
+
+		mv_eth_link_status_print(pp->port);
+	}
+}
+
+/***********************************************************************************************/
+int mv_eth_poll(struct napi_struct *napi, int budget)
+{
+	int rx_done = 0;
+	MV_U32 causeRxTx;
+	struct eth_port *pp = MV_ETH_PRIV(napi->dev);
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if (pp->flags & MV_ETH_F_DBG_POLL) {
+		printk(KERN_ERR "%s_%d ENTER: port=%d, cpu=%d, mask=0x%x, cause=0x%x\n",
+			__func__, pp->stats.poll, pp->port, smp_processor_id(),
+			MV_REG_READ(NETA_INTR_NEW_MASK_REG(pp->port)), MV_REG_READ(NETA_INTR_NEW_CAUSE_REG(pp->port)));
+	}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+	read_lock(&pp->rwlock);
+
+	STAT_INFO(pp->stats.poll++);
+
+	/* Read cause register */
+	causeRxTx = MV_REG_READ(NETA_INTR_NEW_CAUSE_REG(pp->port)) &
+	    (MV_ETH_MISC_SUM_INTR_MASK | MV_ETH_TXDONE_INTR_MASK | MV_ETH_RX_INTR_MASK);
+
+	if (causeRxTx & MV_ETH_MISC_SUM_INTR_MASK) {
+		MV_U32 causeMisc;
+
+		/* Process MISC events - Link, etc ??? */
+		causeRxTx &= ~MV_ETH_MISC_SUM_INTR_MASK;
+		causeMisc = MV_REG_READ(NETA_INTR_MISC_CAUSE_REG(pp->port));
+
+		if (causeMisc & NETA_CAUSE_LINK_CHANGE_MASK)
+			mv_eth_link_event(pp, 1);
+
+		MV_REG_WRITE(NETA_INTR_MISC_CAUSE_REG(pp->port), 0);
+	}
+	causeRxTx |= pp->causeRxTx[smp_processor_id()];
+
+#ifdef CONFIG_MV_ETH_TXDONE_ISR
+	if (causeRxTx & MV_ETH_TXDONE_INTR_MASK) {
+		int tx_todo = 0;
+		/* TX_DONE process */
+
+		if (MV_PON_PORT(pp->port))
+			mv_eth_tx_done_pon(pp, &tx_todo);
+		else
+			mv_eth_tx_done_gbe(pp, (causeRxTx & MV_ETH_TXDONE_INTR_MASK), &tx_todo);
+
+		causeRxTx &= ~MV_ETH_TXDONE_INTR_MASK;
+	}
+#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+
+#if (CONFIG_MV_ETH_RXQ > 1)
+	while ((causeRxTx != 0) && (budget > 0)) {
+		int count, rx_queue;
+
+		rx_queue = mv_eth_rx_policy(causeRxTx);
+		if (rx_queue == -1)
+			break;
+
+		count = mv_eth_rx(pp, budget, rx_queue);
+		rx_done += count;
+		budget -= count;
+		if (budget > 0)
+			causeRxTx &= ~((1 << rx_queue) << NETA_CAUSE_RXQ_OCCUP_DESC_OFFS);
+	}
+#else
+	rx_done = mv_eth_rx(pp, budget, CONFIG_MV_ETH_RXQ_DEF);
+	budget -= rx_done;
+#endif /* (CONFIG_MV_ETH_RXQ > 1) */
+
+	STAT_DIST(if (rx_done < pp->dist_stats.rx_dist_size)
+			pp->dist_stats.rx_dist[rx_done]++);
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if (pp->flags & MV_ETH_F_DBG_POLL) {
+		printk(KERN_ERR "%s_%d  EXIT: port=%d, cpu=%d, budget=%d, rx_done=%d\n",
+			__func__, pp->stats.poll, pp->port, smp_processor_id(), budget, rx_done);
+	}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+	if (budget > 0) {
+		unsigned long flags;
+
+		causeRxTx = 0;
+
+		napi_complete(napi);
+		STAT_INFO(pp->stats.poll_exit++);
+
+		local_irq_save(flags);
+		MV_REG_WRITE(NETA_INTR_NEW_MASK_REG(pp->port),
+			     (MV_ETH_MISC_SUM_INTR_MASK | MV_ETH_TXDONE_INTR_MASK | MV_ETH_RX_INTR_MASK));
+
+		local_irq_restore(flags);
+	}
+	pp->causeRxTx[smp_processor_id()] = causeRxTx;
+	read_unlock(&pp->rwlock);
+	return rx_done;
+}
+
+static void mv_eth_cpu_counters_init(void)
+{
+#ifdef CONFIG_MV_CPU_PERF_CNTRS
+
+	mvCpuCntrsInitialize();
+
+#ifdef CONFIG_PLAT_ARMADA
+	/*  cycles counter via special CCNT counter */
+	mvCpuCntrsProgram(0, MV_CPU_CNTRS_CYCLES, "Cycles", 13);
+
+	/* instruction counters */
+	mvCpuCntrsProgram(1, MV_CPU_CNTRS_INSTRUCTIONS, "Instr", 13);
+	/* mvCpuCntrsProgram(0, MV_CPU_CNTRS_DCACHE_READ_HIT, "DcRdHit", 0); */
+
+	/* ICache misses counter */
+	mvCpuCntrsProgram(2, MV_CPU_CNTRS_ICACHE_READ_MISS, "IcMiss", 0);
+
+	/* DCache read misses counter */
+	mvCpuCntrsProgram(3, MV_CPU_CNTRS_DCACHE_READ_MISS, "DcRdMiss", 0);
+
+	/* DCache write misses counter */
+	mvCpuCntrsProgram(4, MV_CPU_CNTRS_DCACHE_WRITE_MISS, "DcWrMiss", 0);
+
+	/* DTLB Miss counter */
+	mvCpuCntrsProgram(5, MV_CPU_CNTRS_DTLB_MISS, "dTlbMiss", 0);
+
+	/* mvCpuCntrsProgram(3, MV_CPU_CNTRS_TLB_MISS, "TlbMiss", 0); */
+#else /* CONFIG_FEROCEON */
+	/* 0 - instruction counters */
+	mvCpuCntrsProgram(0, MV_CPU_CNTRS_INSTRUCTIONS, "Instr", 16);
+	/* mvCpuCntrsProgram(0, MV_CPU_CNTRS_DCACHE_READ_HIT, "DcRdHit", 0); */
+
+	/* 1 - ICache misses counter */
+	mvCpuCntrsProgram(1, MV_CPU_CNTRS_ICACHE_READ_MISS, "IcMiss", 0);
+
+	/* 2 - cycles counter */
+	mvCpuCntrsProgram(2, MV_CPU_CNTRS_CYCLES, "Cycles", 18);
+
+	/* 3 - DCache read misses counter */
+	mvCpuCntrsProgram(3, MV_CPU_CNTRS_DCACHE_READ_MISS, "DcRdMiss", 0);
+	/* mvCpuCntrsProgram(3, MV_CPU_CNTRS_TLB_MISS, "TlbMiss", 0); */
+#endif /* CONFIG_PLAT_ARMADA */
+
+	event0 = mvCpuCntrsEventCreate("RX_DESC_PREF", 100000);
+	event1 = mvCpuCntrsEventCreate("RX_DESC_READ", 100000);
+	event2 = mvCpuCntrsEventCreate("RX_BUF_INV", 100000);
+	event3 = mvCpuCntrsEventCreate("RX_DESC_FILL", 100000);
+	event4 = mvCpuCntrsEventCreate("TX_START", 100000);
+	event5 = mvCpuCntrsEventCreate("RX_BUF_INV", 100000);
+	if ((event0 == NULL) || (event1 == NULL) || (event2 == NULL) ||
+		(event3 == NULL) || (event4 == NULL) || (event5 == NULL))
+		printk(KERN_ERR "Can't create cpu counter events\n");
+#endif /* CONFIG_MV_CPU_PERF_CNTRS */
+}
+
+#ifdef CONFIG_MV_ETH_NFP
+static MV_STATUS mv_eth_register_nfp_devices(void)
+{
+	int i;
+	MV_STATUS status = MV_OK;
+	struct eth_port *curr_pp;
+
+	/* Register all network devices mapped to NETA as internal for NFP */
+	for (i = 0; i < mv_net_devs_num; i++) {
+		if (mv_net_devs[i] != NULL) {
+			curr_pp = MV_ETH_PRIV(mv_net_devs[i]);
+			if (curr_pp->flags & MV_ETH_F_CONNECT_LINUX) {
+				status = nfp_mgr_if_register(mv_net_devs[i]->ifindex,
+								MV_NFP_IF_INT,
+								mv_net_devs[i],	curr_pp);
+				if (status != MV_OK) {
+					printk(KERN_ERR "fp_mgr_if_register failed\n");
+					return MV_ERROR;
+				}
+			}
+		}
+	}
+	return MV_OK;
+}
+
+
+MV_STATUS mv_eth_unregister_nfp_devices(void)
+{
+	nfp_eth_dev_db_clear();
+
+	return MV_OK;
+}
+#endif /* CONFIG_MV_ETH_NFP */
+
+
+static void mv_eth_port_promisc_set(int port, int queue)
+{
+#ifdef CONFIG_MV_ETH_PNC_PARSER
+	/* Accept all */
+	pnc_mac_me(port, NULL, queue);
+	pnc_mcast_all(port, 1);
+#endif /* CONFIG_MV_ETH_PNC_PARSER */
+
+#ifdef CONFIG_MV_ETH_LEGACY_PARSER
+	mvNetaRxUnicastPromiscSet(port, MV_TRUE);
+	mvNetaSetUcastTable(port, queue);
+	mvNetaSetSpecialMcastTable(port, queue);
+	mvNetaSetOtherMcastTable(port, queue);
+#endif /* CONFIG_MV_ETH_LEGACY_PARSER */
+}
+
+void mv_eth_port_filtering_cleanup(int port)
+{
+#ifdef CONFIG_MV_ETH_PNC_PARSER
+	if (port == 0)
+		/* clean TCAM only one, no need to do this per port. Assume this function is called with port 0 */
+		tcam_hw_init();
+#endif /* CONFIG_MV_ETH_PNC_PARSER */
+
+#ifdef CONFIG_MV_ETH_LEGACY_PARSER
+	mvNetaRxUnicastPromiscSet(port, MV_FALSE);
+	mvNetaSetUcastTable(port, -1);
+	mvNetaSetSpecialMcastTable(port, -1);
+	mvNetaSetOtherMcastTable(port, -1);
+#endif /* CONFIG_MV_ETH_LEGACY_PARSER */
+}
+
+
+static MV_STATUS mv_eth_bm_pools_init(void)
+{
+	int i, j;
+	MV_STATUS status;
+
+	/* Create all pools with maximum capacity */
+	for (i = 0; i < MV_ETH_BM_POOLS; i++) {
+		status = mv_eth_pool_create(i, MV_BM_POOL_CAP_MAX);
+		if (status != MV_OK) {
+			printk(KERN_ERR "%s: can't create bm_pool=%d - capacity=%d\n", __func__, i, MV_BM_POOL_CAP_MAX);
+			for (j = 0; j < i; j++)
+				mv_eth_pool_destroy(j);
+			return status;
+		}
+	}
+#ifdef CONFIG_MV_ETH_BM_CPU
+	mvBmControl(MV_START);
+	mv_eth_pool[MV_ETH_SHORT_BM_POOL].pkt_size = CONFIG_MV_ETH_SHORT_PKT_SIZE;
+	mvBmPoolBufSizeSet(MV_ETH_SHORT_BM_POOL, RX_BUF_SIZE(CONFIG_MV_ETH_SHORT_PKT_SIZE));
+
+#ifdef CONFIG_MV_ETH_POOL_PREDEFINED
+	/* use predefined pools */
+	mv_eth_pool[0].pkt_size = RX_PKT_SIZE(CONFIG_MV_ETH_POOL_0_MTU);
+	mvBmPoolBufSizeSet(0, RX_BUF_SIZE(mv_eth_pool[0].pkt_size));
+	mv_eth_pool[1].pkt_size = RX_PKT_SIZE(CONFIG_MV_ETH_POOL_1_MTU);
+	mvBmPoolBufSizeSet(1, RX_BUF_SIZE(mv_eth_pool[1].pkt_size));
+	mv_eth_pool[2].pkt_size = RX_PKT_SIZE(CONFIG_MV_ETH_POOL_2_MTU);
+	mvBmPoolBufSizeSet(2, RX_BUF_SIZE(mv_eth_pool[2].pkt_size));
+#endif /* CONFIG_MV_ETH_POOL_PREDEFINED */
+
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	return 0;
+}
+
+/* Note: call this function only after mv_eth_ports_num is initialized */
+static int mv_eth_load_network_interfaces(void)
+{
+	u32 port, dev_i = 0;
+	struct eth_port *pp;
+	int mtu, err;
+	u8 mac[MV_MAC_ADDR_SIZE];
+
+	printk(KERN_ERR "  o Loading network interface(s)\n");
+
+	for (port = 0; port < mv_eth_ports_num; port++) {
+		if (!mvCtrlPwrClckGet(ETH_GIG_UNIT_ID, port)) {
+			printk(KERN_ERR "\n  o Warning: GbE port %d is powered off\n\n", port);
+			continue;
+		}
+		if (!MV_PON_PORT(port) && !mvBoardIsGbEPortConnected(port)) {
+			printk(KERN_ERR "\n  o Warning: GbE port %d is not connected to PHY/RGMII/Switch, skip initialization\n\n",
+					port);
+			continue;
+		}
+
+		pp = mv_eth_ports[port] = mvOsMalloc(sizeof(struct eth_port));
+		if (!pp) {
+			printk(KERN_ERR "Error: failed to allocate memory for port %d\n", port);
+			return -ENOMEM;
+		}
+
+		err = mv_eth_priv_init(pp, port);
+		if (err)
+			return err;
+
+#ifdef CONFIG_MV_ETH_PMT
+		if (MV_PON_PORT(port))
+			mvNetaPmtInit(port, (MV_NETA_PMT *)ioremap(PMT_PON_PHYS_BASE, PMT_MEM_SIZE));
+		else
+			mvNetaPmtInit(port, (MV_NETA_PMT *)ioremap(PMT_GIGA_PHYS_BASE + port * 0x40000, PMT_MEM_SIZE));
+#endif /* CONFIG_MV_ETH_PMT */
+
+#ifdef CONFIG_MV_ETH_SWITCH
+		if (pp->flags & (MV_ETH_F_SWITCH | MV_ETH_F_EXT_SWITCH)) {
+			MV_STATUS status;
+
+			status = mv_eth_switch_config_get(mv_eth_initialized);
+			if (status < 0) {
+				printk(KERN_ERR "\nWarning: port %d - Invalid netconfig string\n", port);
+				mv_eth_priv_cleanup(pp);
+				continue;
+			} else if (status == 0) {	/* User selected to work with Gateway driver    */
+				clear_bit(MV_ETH_F_EXT_SWITCH_BIT, &(pp->flags));
+			} else if (status == 1) {
+				/* User selected to work without Gateway driver */
+				clear_bit(MV_ETH_F_SWITCH_BIT, &(pp->flags));
+				printk(KERN_ERR "  o Working in External Switch mode\n");
+				ext_switch_port_mask = mv_switch_link_detection_init();
+			}
+		}
+
+		if (pp->flags & MV_ETH_F_SWITCH) {
+			set_bit(MV_ETH_F_MH_BIT, &(pp->flags));
+			mtu = switch_net_config.mtu;
+			if (mv_switch_init(RX_PKT_SIZE(mtu), SWITCH_CONNECTED_PORTS_MASK)) {
+				printk(KERN_ERR "\nWarning: port %d - Switch initialization failed\n", port);
+				mv_eth_priv_cleanup(pp);
+				continue;
+			}
+		} else
+#endif /* CONFIG_MV_ETH_SWITCH */
+			mtu = mv_eth_config_get(pp, mac);
+
+		printk(KERN_ERR "\t%s p=%d: mtu=%d, mac=%p\n", MV_PON_PORT(port) ? "pon" : "giga", port, mtu, mac);
+
+		if (mv_eth_hal_init(pp)) {
+			printk(KERN_ERR "%s: can't init eth hal\n", __func__);
+			mv_eth_priv_cleanup(pp);
+			return -EIO;
+		}
+#ifdef CONFIG_MV_ETH_SWITCH
+		if (pp->flags & MV_ETH_F_SWITCH) {
+			int queue = CONFIG_MV_ETH_RXQ_DEF;
+
+			mv_eth_switch_netdev_first = dev_i;
+			dev_i = mv_eth_switch_netdev_init(pp, dev_i);
+			if (dev_i < (mv_eth_switch_netdev_first + switch_net_config.netdev_max)) {
+				printk(KERN_ERR "%s: can't create netdevice for switch\n", __func__);
+				mv_eth_priv_cleanup(pp);
+				return -EIO;
+			}
+			mv_eth_switch_netdev_last = dev_i - 1;
+
+			/* set this port to be in promiscuous mode. MAC filtering is performed by the Switch */
+			mv_eth_port_promisc_set(pp->port, queue);
+
+			continue;
+		}
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+		mv_net_devs[dev_i] = mv_eth_netdev_init(pp, mtu, mac);
+		if (!mv_net_devs[dev_i]) {
+			printk(KERN_ERR "%s: can't create netdevice\n", __func__);
+			mv_eth_priv_cleanup(pp);
+			return -EIO;
+		}
+		pp->dev = mv_net_devs[dev_i];
+		dev_i++;
+	}
+
+	mv_net_devs_num = dev_i;
+
+	return 0;
+}
+
+
+/***********************************************************
+ * mv_eth_probe --                                         *
+ *   main driver initialization. loading the interfaces.   *
+ ***********************************************************/
+static int mv_eth_probe(struct platform_device *pdev)
+{
+	u32 port;
+	struct eth_port *pp;
+	int size;
+	MV_STATUS status = MV_OK;
+
+#ifdef ETH_SKB_DEBUG
+	memset(mv_eth_skb_debug, 0, sizeof(mv_eth_skb_debug));
+	spin_lock_init(&skb_debug_lock);
+#endif
+
+	if (!mv_eth_initialized) {
+		mvSysNetaInit(); /* init MAC Unit */
+
+		mv_eth_ports_num = mvCtrlEthMaxPortGet();
+		if (mv_eth_ports_num > CONFIG_MV_ETH_PORTS_NUM)
+			mv_eth_ports_num = CONFIG_MV_ETH_PORTS_NUM;
+
+		mv_net_devs_max = mv_eth_ports_num;
+
+#ifdef CONFIG_MV_ETH_SWITCH
+		mv_net_devs_max += (CONFIG_MV_ETH_SWITCH_NETDEV_NUM - 1);
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+		mv_eth_config_show();
+
+		size = mv_eth_ports_num * sizeof(struct eth_port *);
+		mv_eth_ports = mvOsMalloc(size);
+		if (!mv_eth_ports)
+			goto oom;
+
+		memset(mv_eth_ports, 0, size);
+
+		/* Allocate array of pointers to struct net_device */
+		size = mv_net_devs_max * sizeof(struct net_device *);
+		mv_net_devs = mvOsMalloc(size);
+		if (!mv_net_devs)
+			goto oom;
+
+		memset(mv_net_devs, 0, size);
+	}
+
+#ifdef CONFIG_MV_ETH_PNC_PARSER
+	status = pnc_default_init();
+	if (status)
+		printk(KERN_ERR "%s: Warning PNC init failed %d\n", __func__, status);
+#endif /* CONFIG_MV_ETH_PNC_PARSER */
+
+	if (mv_eth_bm_pools_init())
+		goto oom;
+
+#ifdef CONFIG_MV_INCLUDE_SWITCH
+	if ((mvBoardSwitchConnectedPortGet(0) != -1) || (mvBoardSwitchConnectedPortGet(1) != -1)) {
+		if (mv_switch_load(SWITCH_CONNECTED_PORTS_MASK))
+			printk(KERN_ERR "\nWarning: Switch load failed\n");
+	}
+#endif /* CONFIG_MV_INCLUDE_SWITCH */
+
+	if (!mv_eth_initialized) {
+		if (mv_eth_load_network_interfaces())
+			goto oom;
+	}
+#ifdef CONFIG_MV_ETH_NFP
+	status = mv_eth_register_nfp_devices();
+	if (status) {
+		/* FIXME: cleanup */
+		printk(KERN_ERR "Error: mv_eth_register_nfp_devices failed\n");
+		return status;
+	}
+#endif /* CONFIG_MV_ETH_NFP */
+
+#ifdef CONFIG_MV_ETH_HWF
+	for (port = 0; port < mv_eth_ports_num; port++) {
+		if (mv_eth_ports[port])
+			mvNetaHwfInit(port);
+	}
+#endif /* CONFIG_MV_ETH_HWF */
+
+	/* Call mv_eth_open specifically for ports not connected to Linux netdevice */
+	for (port = 0; port < mv_eth_ports_num; port++) {
+		pp = mv_eth_port_by_id(port);
+		if (pp) {
+			if (!(pp->flags & MV_ETH_F_CONNECT_LINUX)) /* TODO, check this is not a Switch port */
+				mv_eth_open(pp->dev);
+		}
+	}
+
+	if (!mv_eth_initialized)
+		mv_eth_cpu_counters_init();
+
+	printk(KERN_ERR "\n");
+
+	mv_eth_initialized = 1;
+
+	return 0;
+oom:
+	if (mv_eth_ports)
+		mvOsFree(mv_eth_ports);
+
+	if (mv_net_devs)
+		mvOsFree(mv_net_devs);
+
+	printk(KERN_ERR "%s: out of memory\n", __func__);
+	return -ENOMEM;
+}
+
+
+static int mv_eth_config_get(struct eth_port *pp, MV_U8 *mac_addr)
+{
+	char *mac_str = NULL;
+	u8 zero_mac[MV_MAC_ADDR_SIZE] = { 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 };
+	int mtu;
+
+	switch (pp->port) {
+	case 0:
+		if (mvMtu[0] != 0)
+			mtu = mvMtu[0];
+		else
+			mtu = CONFIG_MV_ETH_0_MTU;
+
+		/* use default MAC address from Kconfig only if the MAC address we got is all 0 */
+		if (memcmp(mvMacAddr[0], zero_mac, MV_MAC_ADDR_SIZE) == 0)
+			mac_str = CONFIG_MV_ETH_0_MACADDR;
+		else
+			memcpy(mac_addr, mvMacAddr[0], MV_MAC_ADDR_SIZE);
+
+		break;
+
+#if (CONFIG_MV_ETH_PORTS_NUM > 1)
+	case 1:
+		if (mvMtu[1] != 0)
+			mtu = mvMtu[1];
+		else
+			mtu = CONFIG_MV_ETH_1_MTU;
+
+		/* use default MAC address from Kconfig only if the MAC address we got is all 0 */
+		if (memcmp(mvMacAddr[1], zero_mac, MV_MAC_ADDR_SIZE) == 0)
+			mac_str = CONFIG_MV_ETH_1_MACADDR;
+		else
+			memcpy(mac_addr, mvMacAddr[1], MV_MAC_ADDR_SIZE);
+
+		break;
+#endif /* CONFIG_MV_ETH_PORTS_NUM > 1 */
+
+#if (CONFIG_MV_ETH_PORTS_NUM > 2)
+	case 2:
+		if (mvMtu[2] != 0)
+			mtu = mvMtu[2];
+		else
+			mtu = CONFIG_MV_ETH_2_MTU;
+
+		/* use default MAC address from Kconfig only if the MAC address we got is all 0 */
+		if (memcmp(mvMacAddr[2], zero_mac, MV_MAC_ADDR_SIZE) == 0)
+			mac_str = CONFIG_MV_ETH_2_MACADDR;
+		else
+			memcpy(mac_addr, mvMacAddr[2], MV_MAC_ADDR_SIZE);
+		break;
+#endif /* CONFIG_MV_ETH_PORTS_NUM > 2 */
+
+#if (CONFIG_MV_ETH_PORTS_NUM > 3)
+	case 3:
+		if (mvMtu[3] != 0)
+			mtu = mvMtu[3];
+		else
+			mtu = CONFIG_MV_ETH_3_MTU;
+
+		/* use default MAC address from Kconfig only if the MAC address we got is all 0 */
+		if (memcmp(mvMacAddr[3], zero_mac, MV_MAC_ADDR_SIZE) == 0)
+			mac_str = CONFIG_MV_ETH_3_MACADDR;
+		else
+			memcpy(mac_addr, mvMacAddr[3], MV_MAC_ADDR_SIZE);
+
+		break;
+#endif /* CONFIG_MV_ETH_PORTS_NUM > 3 */
+
+	default:
+		printk(KERN_ERR "eth_get_config: Unexpected port number %d\n", pp->port);
+		return -1;
+	}
+	if ((mac_str != NULL) && (mac_addr != NULL))
+		mvMacStrToHex(mac_str, mac_addr);
+
+	return mtu;
+}
+
+/***********************************************************
+ * mv_eth_tx_timeout --                                    *
+ *   nothing to be done (?)                                *
+ ***********************************************************/
+static void mv_eth_tx_timeout(struct net_device *dev)
+{
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	struct eth_port *pp = MV_ETH_PRIV(dev);
+
+	pp->stats.tx_timeout++;
+#endif /* #ifdef CONFIG_MV_ETH_STAT_ERR */
+
+	printk(KERN_INFO "%s: tx timeout\n", dev->name);
+}
+
+/***************************************************************
+ * mv_eth_netdev_init -- Allocate and initialize net_device    *
+ *                   structure                                 *
+ ***************************************************************/
+struct net_device *mv_eth_netdev_init(struct eth_port *pp, int mtu, u8 *mac)
+{
+	int cpu, i;
+	struct net_device *dev;
+	struct eth_dev_priv *dev_priv;
+	dev = alloc_etherdev(sizeof(struct eth_dev_priv));
+	if (!dev)
+		return NULL;
+
+	dev_priv = (struct eth_dev_priv *)netdev_priv(dev);
+	if (!dev_priv)
+		return NULL;
+
+	memset(dev_priv, 0, sizeof(struct eth_dev_priv));
+	dev_priv->port_p = pp;
+
+	dev->irq = NET_TH_RXTX_IRQ_NUM(pp->port);
+
+	dev->mtu = mtu;
+	memcpy(dev->dev_addr, mac, MV_MAC_ADDR_SIZE);
+	dev->tx_queue_len = CONFIG_MV_ETH_TXQ_DESC;
+	dev->watchdog_timeo = 5 * HZ;
+
+#ifdef CONFIG_MV_ETH_SWITCH
+	if (pp->flags & (MV_ETH_F_SWITCH | MV_ETH_F_EXT_SWITCH)) {
+
+		if (pp->flags & MV_ETH_F_SWITCH)
+			dev->netdev_ops = &mv_switch_netdev_ops;
+		else
+			dev->netdev_ops = &mv_eth_netdev_ops;
+
+		dev_priv->netdev_p = mvOsMalloc(sizeof(struct eth_netdev));
+		if (!dev_priv->netdev_p) {
+			printk(KERN_ERR "failed to allocate eth_netdev\n");
+			free_netdev(dev);
+			return NULL;
+		}
+		memset(dev_priv->netdev_p, 0, sizeof(struct eth_netdev));
+		/* For correct link information of Linux interface: */
+		if (pp->flags & MV_ETH_F_EXT_SWITCH) {
+			dev_priv->netdev_p->port_map = ext_switch_port_mask;
+			dev_priv->netdev_p->link_map = 0;
+		}
+	} else
+#endif /* CONFIG_MV_ETH_SWITCH */
+		dev->netdev_ops = &mv_eth_netdev_ops;
+
+#ifdef CONFIG_MV_ETH_TOOL
+	SET_ETHTOOL_OPS(dev, &mv_eth_tool_ops);
+#endif
+	/* Default NAPI initialization */
+	for (i = 0; i < NR_GROUPS; i++) {
+		pp->napiGroup[i] = (struct napi_struct *)kmalloc(sizeof(struct napi_struct), GFP_KERNEL);
+		memset(pp->napiGroup[i], 0, sizeof(struct napi_struct));
+	}
+	for (cpu = 0; cpu < CONFIG_NR_CPUS; cpu++)
+		pp->napi[cpu] = pp->napiGroup[CPU_GROUP_DEF];
+
+	/* Add NAPI default group */
+	if (pp->flags & MV_ETH_F_CONNECT_LINUX)
+		netif_napi_add(dev, pp->napiGroup[CPU_GROUP_DEF], mv_eth_poll, pp->weight);
+
+	pp->tx_done_timer.data = (unsigned long)dev;
+	pp->cleanup_timer.data = (unsigned long)dev;
+
+	mv_eth_netdev_set_features(dev);
+
+	if (pp->flags & MV_ETH_F_CONNECT_LINUX) {
+		if (register_netdev(dev)) {
+			printk(KERN_ERR "failed to register %s\n", dev->name);
+			free_netdev(dev);
+			return NULL;
+		} else {
+			printk(KERN_ERR "    o %s, ifindex = %d, GbE port = %d", dev->name, dev->ifindex, pp->port);
+#ifdef CONFIG_MV_ETH_SWITCH
+			if (!(pp->flags & MV_ETH_F_SWITCH))
+				printk(KERN_CONT "\n");
+#else
+			printk(KERN_CONT "\n");
+#endif
+		}
+	}
+	return dev;
+}
+
+
+void mv_eth_netdev_update(int dev_index, struct eth_port *pp)
+{
+	int weight, cpu;
+	struct eth_dev_priv *dev_priv;
+#ifdef CONFIG_MV_ETH_SWITCH
+	struct eth_netdev *eth_netdev_priv;
+#endif /* CONFIG_MV_ETH_SWITCH */
+	struct net_device *dev = mv_net_devs[dev_index];
+
+	dev_priv = (struct eth_dev_priv *)netdev_priv(dev); /* assuming dev_priv has to be valid here */
+
+	dev_priv->port_p = pp;
+
+	dev->irq = NET_TH_RXTX_IRQ_NUM(pp->port);
+	weight = CONFIG_MV_ETH_RX_POLL_WEIGHT;
+
+	if (pp->flags & MV_ETH_F_CONNECT_LINUX) {
+			netif_napi_add(dev, pp->napi[CPU_GROUP_DEF], mv_eth_poll, pp->weight);
+	}
+	for (cpu = 0; cpu < CONFIG_NR_CPUS; cpu++)
+		pp->napi[cpu] = pp->napiGroup[CPU_GROUP_DEF];
+
+	pp->tx_done_timer.data = (unsigned long)dev;
+	pp->cleanup_timer.data = (unsigned long)dev;
+
+	printk(KERN_ERR "    o %s, ifindex = %d, GbE port = %d", dev->name, dev->ifindex, pp->port);
+
+#ifdef CONFIG_MV_ETH_SWITCH
+	if (pp->flags & MV_ETH_F_SWITCH) {
+		eth_netdev_priv = MV_DEV_PRIV(dev);
+		mv_eth_switch_priv_update(dev, MV_SWITCH_VLAN_TO_GROUP(eth_netdev_priv->vlan_grp_id));
+	} else {
+		printk(KERN_CONT "\n");
+	}
+#else
+	printk(KERN_CONT "\n");
+#endif /* CONFIG_MV_ETH_SWITCH */
+}
+
+
+int mv_eth_hal_init(struct eth_port *pp)
+{
+	int rxq, txp, txq, size;
+	struct tx_queue *txq_ctrl;
+	struct rx_queue *rxq_ctrl;
+
+	if (!MV_PON_PORT(pp->port)) {
+		int phyAddr;
+
+		/* Set the board information regarding PHY address */
+		phyAddr = mvBoardPhyAddrGet(pp->port);
+		mvNetaPhyAddrSet(pp->port, phyAddr);
+	}
+
+	/* Init port */
+	pp->port_ctrl = mvNetaPortInit(pp->port, NULL);
+	if (!pp->port_ctrl) {
+		printk(KERN_ERR "%s: failed to load port=%d\n", __func__, pp->port);
+		return -ENODEV;
+	}
+
+	size = pp->txp_num * CONFIG_MV_ETH_TXQ * sizeof(struct tx_queue);
+	pp->txq_ctrl = mvOsMalloc(size);
+	if (!pp->txq_ctrl)
+		goto oom;
+
+	memset(pp->txq_ctrl, 0, size);
+
+	/* Create TX descriptor rings */
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+
+			txq_ctrl->q = NULL;
+			txq_ctrl->cpu_owner = 0;
+			txq_ctrl->hwf_rxp = 0xFF;
+			txq_ctrl->txp = txp;
+			txq_ctrl->txq = txq;
+			txq_ctrl->txq_size = CONFIG_MV_ETH_TXQ_DESC;
+			txq_ctrl->txq_count = 0;
+			txq_ctrl->bm_only = MV_FALSE;
+
+			txq_ctrl->shadow_txq_put_i = 0;
+			txq_ctrl->shadow_txq_get_i = 0;
+			txq_ctrl->txq_done_pkts_coal = mv_ctrl_txdone;
+		}
+	}
+
+	pp->rxq_ctrl = mvOsMalloc(CONFIG_MV_ETH_RXQ * sizeof(struct rx_queue));
+	if (!pp->rxq_ctrl)
+		goto oom;
+
+	memset(pp->rxq_ctrl, 0, CONFIG_MV_ETH_RXQ * sizeof(struct rx_queue));
+
+	/* Create Rx descriptor rings */
+	for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++) {
+		rxq_ctrl = &pp->rxq_ctrl[rxq];
+		rxq_ctrl->rxq_size = CONFIG_MV_ETH_RXQ_DESC;
+		rxq_ctrl->rxq_pkts_coal = CONFIG_MV_ETH_RX_COAL_PKTS;
+		rxq_ctrl->rxq_time_coal = CONFIG_MV_ETH_RX_COAL_USEC;
+	}
+
+	if (pp->flags & MV_ETH_F_MH) {
+		mvNetaMhSet(pp->port, MV_NETA_MH);
+#ifdef CONFIG_MV_ETH_NFP
+		mvNfpPortCapSet(pp->port, NFP_P_MH, MV_TRUE);
+#endif
+	}
+
+#ifdef CONFIG_MV_ETH_TOOL
+	/* Configure defaults */
+	pp->autoneg_cfg  = AUTONEG_ENABLE;
+	pp->speed_cfg    = SPEED_1000;
+	pp->duplex_cfg  = DUPLEX_FULL;
+	pp->advertise_cfg = 0x2f;
+#endif /* CONFIG_MV_ETH_TOOL */
+
+	return 0;
+oom:
+	printk(KERN_ERR "%s: port=%d: out of memory\n", __func__, pp->port);
+	return -ENODEV;
+}
+
+/* Show network driver configuration */
+void mv_eth_config_show(void)
+{
+	/* Check restrictions */
+#if (CONFIG_MV_ETH_PORTS_NUM > MV_ETH_MAX_PORTS)
+#   error "CONFIG_MV_ETH_PORTS_NUM is large than MV_ETH_MAX_PORTS"
+#endif
+
+#if (CONFIG_MV_ETH_RXQ > MV_ETH_MAX_RXQ)
+#   error "CONFIG_MV_ETH_RXQ is large than MV_ETH_MAX_RXQ"
+#endif
+
+#if CONFIG_MV_ETH_TXQ > MV_ETH_MAX_TXQ
+#   error "CONFIG_MV_ETH_TXQ is large than MV_ETH_MAX_TXQ"
+#endif
+
+#if defined(CONFIG_MV_ETH_TSO) && !defined(CONFIG_MV_ETH_TX_CSUM_OFFLOAD)
+#   error "If GSO enabled - TX checksum offload must be enabled too"
+#endif
+
+	printk(KERN_ERR "  o %d Giga ports supported\n", CONFIG_MV_ETH_PORTS_NUM);
+
+#ifdef CONFIG_MV_PON
+	printk(KERN_ERR "  o Giga PON port is #%d: - %d TCONTs supported\n", MV_PON_PORT_ID, MV_ETH_MAX_TCONT());
+#endif
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+	printk(KERN_ERR "  o SKB recycle supported (%s)\n", mv_ctrl_recycle ? "Enabled" : "Disabled");
+#endif
+
+#ifdef CONFIG_MV_ETH_NETA
+	printk(KERN_ERR "  o NETA acceleration mode %d\n", mvNetaAccMode());
+#endif
+
+#ifdef CONFIG_MV_ETH_BM_CPU
+	printk(KERN_ERR "  o BM supported for CPU: short buffer size is %d bytes\n", CONFIG_MV_ETH_SHORT_PKT_SIZE);
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+#ifdef CONFIG_MV_ETH_PNC
+	printk(KERN_ERR "  o PnC supported\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_HWF
+	printk(KERN_ERR "  o HWF supported\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_PMT
+	printk(KERN_ERR "  o PMT supported\n");
+#endif
+
+	printk(KERN_ERR "  o RX Queue support: %d Queues * %d Descriptors\n", CONFIG_MV_ETH_RXQ, CONFIG_MV_ETH_RXQ_DESC);
+
+	printk(KERN_ERR "  o TX Queue support: %d Queues * %d Descriptors\n", CONFIG_MV_ETH_TXQ, CONFIG_MV_ETH_TXQ_DESC);
+
+#if defined(CONFIG_MV_ETH_TSO)
+	printk(KERN_ERR "  o GSO supported\n");
+#endif /* CONFIG_MV_ETH_TSO */
+
+#if defined(CONFIG_MV_ETH_GRO)
+	printk(KERN_ERR "  o GRO supported\n");
+#endif /* CONFIG_MV_ETH_GRO */
+
+#if defined(CONFIG_MV_ETH_RX_CSUM_OFFLOAD)
+	printk(KERN_ERR "  o Receive checksum offload supported\n");
+#endif
+#if defined(CONFIG_MV_ETH_TX_CSUM_OFFLOAD)
+	printk(KERN_ERR "  o Transmit checksum offload supported\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_NFP
+	printk(KERN_ERR "  o Network Fast Processing (Routing) supported\n");
+
+#ifdef CONFIG_MV_ETH_NFP_NAT
+	printk(KERN_ERR "  o Network Fast Processing (NAT) supported\n");
+#endif /* CONFIG_MV_ETH_NFP_NAT */
+
+#endif /* CONFIG_MV_ETH_NFP */
+
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	printk(KERN_ERR "  o Driver ERROR statistics enabled\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_STAT_INF
+	printk(KERN_ERR "  o Driver INFO statistics enabled\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+	printk(KERN_ERR "  o Driver DEBUG statistics enabled\n");
+#endif
+
+#ifdef ETH_DEBUG
+	printk(KERN_ERR "  o Driver debug messages enabled\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_PROC
+	printk(KERN_ERR "  o Proc tool API enabled\n");
+#endif
+
+#if defined(CONFIG_MV_ETH_SWITCH)
+	printk(KERN_ERR "  o Switch support enabled\n");
+
+#ifdef CONFIG_MV_ETH_IGMP
+	printk(KERN_ERR "     o IGMP special processing support\n");
+#endif /* CONFIG_MV_ETH_IGMP */
+
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+	printk(KERN_ERR "\n");
+}
+
+static void mv_eth_netdev_set_features(struct net_device *dev)
+{
+	dev->features = NETIF_F_SG | NETIF_F_LLTX;
+
+#ifdef CONFIG_MV_ETH_TX_CSUM_OFFLOAD_DEF
+	if (dev->mtu <= MV_ETH_TX_CSUM_MAX_SIZE)
+		dev->features |= NETIF_F_IP_CSUM;
+#endif /* CONFIG_MV_ETH_TX_CSUM_OFFLOAD_DEF */
+
+#ifdef CONFIG_MV_ETH_GRO_DEF
+	dev->features |= NETIF_F_GRO;
+#endif /* CONFIG_MV_ETH_GRO_DEF */
+
+#ifdef CONFIG_MV_ETH_TSO_DEF
+	dev->features |= NETIF_F_TSO;
+#endif /* CONFIG_MV_ETH_TSO_DEF */
+
+}
+
+void mv_eth_priv_cleanup(struct eth_port *pp)
+{
+	/* TODO */
+}
+
+static inline struct bm_pool *mv_eth_pool_find(struct eth_port *pp, int pkt_size)
+{
+	int				pool, i;
+	struct bm_pool	*bm_pool, *temp_pool = NULL;
+	unsigned long flags = 0;
+
+	/* look for free pool pkt_size == 0. First check pool == pp->port */
+	/* if no free pool choose larger than required */
+	for (i = 0; i < MV_ETH_BM_POOLS; i++) {
+		pool = (pp->port + i) % MV_ETH_BM_POOLS;
+		bm_pool = &mv_eth_pool[pool];
+
+		MV_ETH_LOCK(&bm_pool->lock, flags);
+
+		if (bm_pool->pkt_size == 0) {
+			/* found free pool */
+			bm_pool->pkt_size = pkt_size;
+			mvBmPoolBufSizeSet(pool, RX_BUF_SIZE(pkt_size));
+
+			MV_ETH_UNLOCK(&bm_pool->lock, flags);
+			return bm_pool;
+		}
+		if (bm_pool->pkt_size >= pkt_size) {
+			if (temp_pool == NULL)
+				temp_pool = bm_pool;
+			else if (bm_pool->pkt_size < temp_pool->pkt_size)
+				temp_pool = bm_pool;
+		}
+		MV_ETH_UNLOCK(&bm_pool->lock, flags);
+	}
+	return temp_pool;
+}
+
+static int mv_eth_rxq_fill(struct eth_port *pp, int rxq, int num)
+{
+	int i;
+
+#ifndef CONFIG_MV_ETH_BM_CPU
+	struct eth_pbuf *pkt;
+	struct bm_pool *bm_pool;
+	MV_NETA_RXQ_CTRL *rx_ctrl;
+	struct neta_rx_desc *rx_desc;
+
+	bm_pool = pp->pool_long;
+
+	rx_ctrl = pp->rxq_ctrl[rxq].q;
+	if (!rx_ctrl) {
+		printk(KERN_ERR "%s: rxq %d is not initialized\n", __func__, rxq);
+		return 0;
+	}
+
+	for (i = 0; i < num; i++) {
+		pkt = mv_eth_pool_get(bm_pool);
+		if (pkt) {
+			rx_desc = (struct neta_rx_desc *)MV_NETA_QUEUE_DESC_PTR(&rx_ctrl->queueCtrl, i);
+			memset(rx_desc, 0, sizeof(rx_desc));
+
+			mvNetaRxDescFill(rx_desc, pkt->physAddr, (MV_U32)pkt);
+		} else {
+			printk(KERN_ERR "%s: rxq %d, %d of %d buffers are filled\n", __func__, rxq, i, num);
+			break;
+		}
+	}
+#else
+	i = num;
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	mvNetaRxqNonOccupDescAdd(pp->port, rxq, i);
+
+	return i;
+}
+
+static int mv_eth_txq_create(struct eth_port *pp, struct tx_queue *txq_ctrl)
+{
+	txq_ctrl->q = mvNetaTxqInit(pp->port, txq_ctrl->txp, txq_ctrl->txq, txq_ctrl->txq_size);
+	if (txq_ctrl->q == NULL) {
+		printk(KERN_ERR "%s: can't create TxQ - port=%d, txp=%d, txq=%d, desc=%d\n",
+		       __func__, pp->port, txq_ctrl->txp, txq_ctrl->txp, txq_ctrl->txq_size);
+		return -ENODEV;
+	}
+
+	txq_ctrl->shadow_txq = mvOsMalloc(txq_ctrl->txq_size * sizeof(MV_ULONG));
+	if (txq_ctrl->shadow_txq == NULL)
+		goto no_mem;
+
+	/* reset txq */
+	txq_ctrl->txq_count = 0;
+	txq_ctrl->shadow_txq_put_i = 0;
+	txq_ctrl->shadow_txq_get_i = 0;
+
+#ifdef CONFIG_MV_ETH_HWF
+	mvNetaHwfTxqInit(pp->port, txq_ctrl->txp, txq_ctrl->txq);
+#endif /* CONFIG_MV_ETH_HWF */
+
+	return 0;
+
+no_mem:
+	mv_eth_txq_delete(pp, txq_ctrl);
+	return -ENOMEM;
+}
+
+
+static int mv_force_port_link_speed_fc(int port, MV_ETH_PORT_SPEED port_speed, int en_force)
+{
+	if (en_force) {
+		if (mvNetaForceLinkModeSet(port, 1, 0)) {
+			printk(KERN_ERR "mvNetaForceLinkModeSet failed\n");
+			return -EIO;
+		}
+		if (mvNetaSpeedDuplexSet(port, port_speed, MV_ETH_DUPLEX_FULL)) {
+			printk(KERN_ERR "mvNetaSpeedDuplexSet failed\n");
+			return -EIO;
+		}
+		if (mvNetaFlowCtrlSet(port, MV_ETH_FC_ENABLE)) {
+			printk(KERN_ERR "mvNetaFlowCtrlSet failed\n");
+			return -EIO;
+		}
+	} else {
+		if (mvNetaForceLinkModeSet(port, 0, 0)) {
+			printk(KERN_ERR "mvNetaForceLinkModeSet failed\n");
+			return -EIO;
+		}
+		if (mvNetaSpeedDuplexSet(port, MV_ETH_SPEED_AN, MV_ETH_DUPLEX_AN)) {
+			printk(KERN_ERR "mvNetaSpeedDuplexSet failed\n");
+			return -EIO;
+		}
+		if (mvNetaFlowCtrlSet(port, MV_ETH_FC_AN_SYM)) {
+			printk(KERN_ERR "mvNetaFlowCtrlSet failed\n");
+			return -EIO;
+		}
+	}
+	return 0;
+}
+
+static void mv_eth_txq_delete(struct eth_port *pp, struct tx_queue *txq_ctrl)
+{
+	if (txq_ctrl->shadow_txq) {
+		mvOsFree(txq_ctrl->shadow_txq);
+		txq_ctrl->shadow_txq = NULL;
+	}
+
+	if (txq_ctrl->q) {
+		mvNetaTxqDelete(pp->port, txq_ctrl->txp, txq_ctrl->txq);
+		txq_ctrl->q = NULL;
+	}
+}
+
+/* Free all packets pending transmit from all TXQs and reset TX port */
+int mv_eth_txp_reset(int port, int txp)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	int queue;
+
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "Port %d must be stopped before\n", port);
+		return -EINVAL;
+	}
+
+	/* free the skb's in the hal tx ring */
+	for (queue = 0; queue < CONFIG_MV_ETH_TXQ; queue++) {
+		struct tx_queue *txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + queue];
+
+		if (txq_ctrl->q)
+			mv_eth_txq_done_force(pp, txq_ctrl);
+	}
+	mvNetaTxpReset(port, txp);
+	return 0;
+}
+
+/* Free received packets from all RXQs and reset RX of the port */
+int mv_eth_rx_reset(int port)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "Port %d must be stopped before\n", port);
+		return -EINVAL;
+	}
+
+#ifndef CONFIG_MV_ETH_BM_CPU
+	{
+		int rxq = 0;
+
+		for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++) {
+			struct eth_pbuf *pkt;
+			struct neta_rx_desc *rx_desc;
+			struct bm_pool *pool;
+			int i, rx_done;
+			MV_NETA_RXQ_CTRL *rx_ctrl = pp->rxq_ctrl[rxq].q;
+
+			if (rx_ctrl == NULL)
+				continue;
+
+			rx_done = mvNetaRxqFreeDescNumGet(pp->port, rxq);
+			mvOsCacheIoSync();
+			for (i = 0; i < rx_done; i++) {
+				rx_desc = mvNetaRxqNextDescGet(rx_ctrl);
+				mvOsCacheLineInv(NULL, rx_desc);
+
+#if defined(MV_CPU_BE)
+				mvNetaRxqDescSwap(rx_desc);
+#endif /* MV_CPU_BE */
+
+				pkt = (struct eth_pbuf *)rx_desc->bufCookie;
+				pool = &mv_eth_pool[pkt->pool];
+				mv_eth_pool_put(pool, pkt);
+			}
+		}
+	}
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	mvNetaRxReset(port);
+	return 0;
+}
+
+/***********************************************************
+ * coal set functions		                           *
+ ***********************************************************/
+MV_STATUS mv_eth_rx_ptks_coal_set(int port, int rxq, MV_U32 value)
+{
+	MV_STATUS status = mvNetaRxqPktsCoalSet(port, rxq, value);
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	if (status == MV_OK)
+		pp->rxq_ctrl[rxq].rxq_pkts_coal = value;
+	return status;
+}
+
+MV_STATUS mv_eth_rx_time_coal_set(int port, int rxq, MV_U32 value)
+{
+	MV_STATUS status = mvNetaRxqTimeCoalSet(port, rxq, value);
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	if (status == MV_OK)
+		pp->rxq_ctrl[rxq].rxq_time_coal = value;
+	return status;
+}
+
+MV_STATUS mv_eth_tx_done_ptks_coal_set(int port, int txp, int txq, MV_U32 value)
+{
+	MV_STATUS status = mvNetaTxDonePktsCoalSet(port, txp, txq, value);
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	if (status == MV_OK)
+		pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq].txq_done_pkts_coal = value;
+	return status;
+}
+
+/***********************************************************
+ * mv_eth_start_internals --                               *
+ *   fill rx buffers. start rx/tx activity. set coalesing. *
+ *   clear and unmask interrupt bits                       *
+ ***********************************************************/
+int mv_eth_start_internals(struct eth_port *pp, int mtu)
+{
+	unsigned long rwflags;
+	unsigned int status;
+	int rxq, txp, txq, num, err = 0;
+	int pkt_size = RX_PKT_SIZE(mtu);
+	MV_BOARD_MAC_SPEED mac_speed;
+
+	write_lock_irqsave(&pp->rwlock, rwflags);
+
+	if (mvNetaMaxRxSizeSet(pp->port, RX_PKT_SIZE(mtu))) {
+		printk(KERN_ERR "%s: can't set maxRxSize=%d for port=%d, mtu=%d\n",
+		       __func__, RX_PKT_SIZE(mtu), pp->port, mtu);
+		err = -EINVAL;
+		goto out;
+	}
+
+	if (mv_eth_ctrl_is_tx_enabled(pp)) {
+		int cpu;
+		for_each_possible_cpu(cpu) {
+			if (mv_eth_ctrl_txq_cpu_own(pp->port, pp->txp, pp->txq[cpu], 1) < 0) {
+				err = -EINVAL;
+				goto out;
+			}
+		}
+	}
+
+	/* Allocate buffers for Long buffers pool */
+	if (pp->pool_long == NULL) {
+		pp->pool_long = mv_eth_pool_find(pp, pkt_size);
+
+		if (pp->pool_long == NULL) {
+			printk(KERN_ERR "%s FAILED: port=%d, Can't find pool for pkt_size=%d\n",
+			       __func__, pp->port, pkt_size);
+			err = -ENOMEM;
+			goto out;
+		}
+
+		num = mv_eth_pool_add(pp->pool_long->pool, pp->pool_long_num);
+		if (num != pp->pool_long_num) {
+			printk(KERN_ERR "%s FAILED: pool=%d, pkt_size=%d, only %d of %d allocated\n",
+			       __func__, pp->pool_long->pool, pkt_size, num, pp->pool_long_num);
+			err = -ENOMEM;
+			goto out;
+		}
+	}
+#ifdef CONFIG_MV_ETH_BM_CPU
+	/* Allocate packets for short pool */
+	if (pp->pool_short == NULL) {
+		pp->pool_short = &mv_eth_pool[MV_ETH_SHORT_BM_POOL];
+		num = mv_eth_pool_add(pp->pool_short->pool, pp->pool_short_num);
+		if (num != pp->pool_short_num) {
+			printk(KERN_ERR "%s FAILED: pool=%d, pkt_size=%d - %d of %d buffers added\n",
+			       __func__, MV_ETH_SHORT_BM_POOL, CONFIG_MV_ETH_SHORT_PKT_SIZE,
+			       num, pp->pool_short_num);
+			err = -ENOMEM;
+			goto out;
+		}
+	}
+	mvNetaBmPoolBufSizeSet(pp->port, pp->pool_short->pool, RX_BUF_SIZE(CONFIG_MV_ETH_SHORT_PKT_SIZE));
+	mvNetaBmPoolBufSizeSet(pp->port, pp->pool_long->pool, RX_BUF_SIZE(pkt_size));
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++) {
+		if (pp->rxq_ctrl[rxq].q == NULL) {
+			pp->rxq_ctrl[rxq].q = mvNetaRxqInit(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_size);
+			if (!pp->rxq_ctrl[rxq].q) {
+				printk(KERN_ERR "%s: can't create RxQ port=%d, rxq=%d, desc=%d\n",
+				       __func__, pp->port, rxq, pp->rxq_ctrl[rxq].rxq_size);
+				err = -ENODEV;
+				goto out;
+			}
+		}
+
+		/* Set Offset */
+		mvNetaRxqOffsetSet(pp->port, rxq, NET_SKB_PAD);
+
+		/* Set coalescing pkts and time */
+		mv_eth_rx_ptks_coal_set(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_pkts_coal);
+		mv_eth_rx_time_coal_set(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_time_coal);
+
+#if defined(CONFIG_MV_ETH_BM_CPU)
+		/* Enable / Disable - BM support */
+		mvNetaRxqBmEnable(pp->port, rxq, pp->pool_short->pool, pp->pool_long->pool);
+#else
+		/* Fill RXQ with buffers from RX pool */
+		mvNetaRxqBufSizeSet(pp->port, rxq, RX_BUF_SIZE(pkt_size));
+		mvNetaRxqBmDisable(pp->port, rxq);
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+		if (mvNetaRxqFreeDescNumGet(pp->port, rxq) == 0)
+			mv_eth_rxq_fill(pp, rxq, pp->rxq_ctrl[rxq].rxq_size);
+	}
+
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++) {
+			struct tx_queue *txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+
+			if ((txq_ctrl->q == NULL) && (txq_ctrl->txq_size > 0)) {
+				err = mv_eth_txq_create(pp, txq_ctrl);
+				if (err)
+					goto out;
+				spin_lock_init(&txq_ctrl->queue_lock);
+			}
+			mv_eth_tx_done_ptks_coal_set(pp->port, txp, txq,
+					pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq].txq_done_pkts_coal);
+		}
+		mvNetaTxpMaxTxSizeSet(pp->port, txp, RX_PKT_SIZE(mtu));
+	}
+
+#ifdef CONFIG_MV_ETH_HWF
+#ifdef CONFIG_MV_ETH_BM_CPU
+	mvNetaHwfBmPoolsSet(pp->port, pp->pool_short->pool, pp->pool_long->pool);
+#else
+	mv_eth_hwf_bm_create(pp->port, RX_PKT_SIZE(mtu));
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	mvNetaHwfEnable(pp->port, 1);
+#endif /* CONFIG_MV_ETH_HWF */
+
+	if (!MV_PON_PORT(pp->port)) {
+		/* force link, speed and duplex if necessary (e.g. Switch is connected) based on board information */
+		mac_speed = mvBoardMacSpeedGet(pp->port);
+		switch (mac_speed) {
+		case BOARD_MAC_SPEED_10M:
+			err = mv_force_port_link_speed_fc(pp->port, MV_ETH_SPEED_10, 1);
+			if (err)
+				goto out;
+			break;
+		case BOARD_MAC_SPEED_100M:
+			err = mv_force_port_link_speed_fc(pp->port, MV_ETH_SPEED_100, 1);
+			if (err)
+				goto out;
+			break;
+		case BOARD_MAC_SPEED_1000M:
+			err = mv_force_port_link_speed_fc(pp->port, MV_ETH_SPEED_1000, 1);
+			if (err)
+				goto out;
+			break;
+		case BOARD_MAC_SPEED_AUTO:
+		default:
+			/* do nothing */
+			break;
+		}
+	}
+
+	/* start the hal - rx/tx activity */
+	status = mvNetaPortEnable(pp->port);
+	if (status == MV_OK) {
+		set_bit(MV_ETH_F_LINK_UP_BIT, &(pp->flags));
+	} else if (MV_PON_PORT(pp->port)) {
+		mvNetaPortUp(pp->port);
+		set_bit(MV_ETH_F_LINK_UP_BIT, &(pp->flags));
+	}
+	set_bit(MV_ETH_F_STARTED_BIT, &(pp->flags));
+
+ out:
+	write_unlock_irqrestore(&pp->rwlock, rwflags);
+	return err;
+}
+
+/***********************************************************
+ * mv_eth_stop_internals --                                *
+ *   stop port rx/tx activity. free skb's from rx/tx rings.*
+ ***********************************************************/
+int mv_eth_stop_internals(struct eth_port *pp)
+{
+	unsigned long rwflags;
+	int queue;
+
+	write_lock_irqsave(&pp->rwlock, rwflags);
+
+	clear_bit(MV_ETH_F_STARTED_BIT, &(pp->flags));
+
+	/* stop the port activity, mask all interrupts */
+	if (mvNetaPortDisable(pp->port) != MV_OK) {
+		printk(KERN_ERR "GbE port %d: ethPortDisable failed\n", pp->port);
+		goto error;
+	}
+
+	/* clear all ethernet port interrupts ???? */
+	MV_REG_WRITE(NETA_INTR_MISC_CAUSE_REG(pp->port), 0);
+	MV_REG_WRITE(NETA_INTR_OLD_CAUSE_REG(pp->port), 0);
+
+	/* mask all ethernet port interrupts ???? */
+	MV_REG_WRITE(NETA_INTR_NEW_MASK_REG(pp->port), 0);
+	MV_REG_WRITE(NETA_INTR_OLD_MASK_REG(pp->port), 0);
+	MV_REG_WRITE(NETA_INTR_MISC_MASK_REG(pp->port), 0);
+
+#ifdef CONFIG_MV_ETH_HWF
+	mvNetaHwfEnable(pp->port, 0);
+#else
+	{
+		int txp;
+		/* Reset TX port here. If HWF is supported reset must be called externally */
+		for (txp = 0; txp < pp->txp_num; txp++)
+			mv_eth_txp_reset(pp->port, txp);
+	}
+#endif /* !CONFIG_MV_ETH_HWF */
+
+	if (mv_eth_ctrl_is_tx_enabled(pp)) {
+		int cpu;
+		for_each_possible_cpu(cpu)
+			mv_eth_ctrl_txq_cpu_own(pp->port, pp->txp, pp->txq[cpu], 0);
+	}
+
+	/* free the skb's in the hal rx ring */
+	for (queue = 0; queue < CONFIG_MV_ETH_RXQ; queue++)
+		mv_eth_rxq_drop_pkts(pp, queue);
+
+	write_unlock_irqrestore(&pp->rwlock, rwflags);
+
+	return 0;
+
+error:
+	printk(KERN_ERR "GbE port %d: stop internals failed\n", pp->port);
+	write_unlock_irqrestore(&pp->rwlock, rwflags);
+
+	return -1;
+}
+
+/***********************************************************
+ * mv_eth_change_mtu_internals --                          *
+ *   stop port activity. release skb from rings. set new   *
+ *   mtu in device and hw. restart port activity and       *
+ *   and fill rx-buiffers with size according to new mtu.  *
+ ***********************************************************/
+int mv_eth_change_mtu_internals(struct net_device *dev, int mtu)
+{
+	struct bm_pool	*new_pool = NULL;
+	struct eth_port *pp = MV_ETH_PRIV(dev);
+	unsigned long	rwflags;
+
+	if (mtu < 64) {
+		printk(KERN_INFO "MTU must be at least 64, change mtu failed\n");
+		return -EINVAL;
+	}
+	if (mtu > 9676 /* 9700 - 20 and rounding to 8 */) {
+		printk(KERN_ERR "%s: Illegal MTU value %d, ", dev->name, mtu);
+		mtu = 9676;
+		printk(KERN_CONT " rounding MTU to: %d \n", mtu);
+	}
+
+	if (MV_IS_NOT_ALIGN(RX_PKT_SIZE(mtu), 8)) {
+		printk(KERN_ERR "%s: Illegal MTU value %d, ", dev->name, mtu);
+		mtu = MV_ALIGN_UP(RX_PKT_SIZE(mtu), 8);
+		printk(KERN_CONT " rounding MTU to: %d \n", mtu);
+	}
+
+	if (mtu != dev->mtu) {
+
+		write_lock_irqsave(&pp->rwlock, rwflags);
+
+		mv_eth_rx_reset(pp->port);
+
+#ifdef CONFIG_MV_ETH_POOL_PREDEFINED
+		/* Check if new MTU require pool change */
+		new_pool = mv_eth_pool_find(pp, RX_PKT_SIZE(mtu));
+		if (new_pool == NULL)
+			printk(KERN_ERR "%s FAILED: port=%d, Can't find pool for pkt_size=%d\n",
+					__func__, pp->port, RX_PKT_SIZE(mtu));
+#endif /* CONFIG_MV_ETH_POOL_PREDEFINED */
+
+		/* Free all buffers from long pool */
+		if ((pp->pool_long) && (pp->pool_long != new_pool)) {
+			mv_eth_pool_free(pp->pool_long->pool, pp->pool_long_num);
+
+			/* redefine pool pkt_size */
+			if (new_pool == NULL) {
+				pp->pool_long->pkt_size = 0;
+				mvBmPoolBufSizeSet(pp->pool_long->pool, 0);
+			}
+
+			pp->pool_long = NULL;
+		}
+
+		/* DIMA debug; Free all buffers from short pool */
+/*
+		if(pp->pool_short) {
+			mv_eth_pool_free(pp->pool_short->pool, pp->pool_short_num);
+			pp->pool_short = NULL;
+		}
+*/
+		write_unlock_irqrestore(&pp->rwlock, rwflags);
+	}
+
+	dev->mtu = mtu;
+
+	mv_eth_netdev_set_features(dev);
+
+	return 0;
+}
+
+/***********************************************************
+ * mv_eth_tx_done_timer_callback --			   *
+ *   N msec periodic callback for tx_done                  *
+ ***********************************************************/
+static void mv_eth_tx_done_timer_callback(unsigned long data)
+{
+	struct net_device *dev = (struct net_device *)data;
+	struct eth_port *pp = MV_ETH_PRIV(dev);
+	int tx_done = 0, tx_todo = 0;
+
+	read_lock(&pp->rwlock);
+	STAT_INFO(pp->stats.tx_done_timer++);
+
+	clear_bit(MV_ETH_F_TX_DONE_TIMER_BIT, &(pp->flags));
+
+	if (MV_PON_PORT(pp->port))
+		tx_done = mv_eth_tx_done_pon(pp, &tx_todo);
+	else
+		/* check all possible queues, as there is no indication from interrupt */
+		tx_done = mv_eth_tx_done_gbe(pp,
+			(((1 << CONFIG_MV_ETH_TXQ) - 1) & NETA_CAUSE_TXQ_SENT_DESC_ALL_MASK), &tx_todo);
+
+	if (tx_todo > 0)
+		mv_eth_add_tx_done_timer(pp);
+
+	read_unlock(&pp->rwlock);
+}
+
+/***********************************************************
+ * mv_eth_cleanup_timer_callback --			   *
+ *   N msec periodic callback for error cleanup            *
+ ***********************************************************/
+static void mv_eth_cleanup_timer_callback(unsigned long data)
+{
+	struct net_device *dev = (struct net_device *)data;
+	struct eth_port *pp = MV_ETH_PRIV(dev);
+
+	read_lock(&pp->rwlock);
+	STAT_INFO(pp->stats.cleanup_timer++);
+
+	/* FIXME: check bm_pool->missed and pp->rxq_ctrl[rxq].missed counters and allocate */
+	/* re-add timer if necessary (check bm_pool->missed and pp->rxq_ctrl[rxq].missed   */
+
+	clear_bit(MV_ETH_F_CLEANUP_TIMER_BIT, &(pp->flags));
+	read_unlock(&pp->rwlock);
+}
+
+void mv_eth_mac_show(int port)
+{
+#ifdef CONFIG_MV_ETH_PNC_PARSER
+	mvOsPrintf("PnC MAC Rules - port #%d:\n", port);
+	pnc_mac_show();
+#endif /* CONFIG_MV_ETH_PNC_PARSER */
+
+#ifdef CONFIG_MV_ETH_LEGACY_PARSER
+	mvEthPortUcastShow(port);
+	mvEthPortMcastShow(port);
+#endif /* CONFIG_MV_ETH_LEGACY_PARSER */
+}
+
+void mv_eth_tos_map_show(int port)
+{
+	int tos, txq;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+#ifdef CONFIG_MV_ETH_PNC_PARSER
+	pnc_ipv4_dscp_show();
+#endif /* CONFIG_MV_ETH_PNC_PARSER */
+
+#ifdef CONFIG_MV_ETH_LEGACY_PARSER
+	for (tos = 0; tos < 0xFF; tos += 0x4) {
+		int rxq;
+
+		rxq = mvNetaTosToRxqGet(port, tos);
+		if (rxq > 0)
+			printk(KERN_ERR "tos=0x%02x: codepoint=0x%02x, rxq=%d\n",
+					tos, tos >> 2, rxq);
+	}
+#endif /* CONFIG_MV_ETH_LEGACY_PARSER */
+
+	printk(KERN_ERR "\n");
+	printk(KERN_ERR " TOS <=> TXQ map for port #%d\n\n", port);
+
+	for (tos = 0; tos < sizeof(pp->txq_tos_map); tos++) {
+		txq = pp->txq_tos_map[tos];
+		if (txq != MV_ETH_TXQ_INVALID)
+			printk(KERN_ERR "0x%02x <=> %d\n", tos, txq);
+	}
+}
+
+int mv_eth_rxq_tos_map_set(int port, int rxq, unsigned char tos)
+{
+	int status = 1;
+
+#ifdef CONFIG_MV_ETH_PNC_PARSER
+	status = pnc_ip4_dscp(tos, 0xFF, rxq);
+#endif /* CONFIG_MV_ETH_PNC_PARSER */
+
+#ifdef CONFIG_MV_ETH_LEGACY_PARSER
+	status = mvNetaTosToRxqSet(port, tos, rxq);
+#endif /* CONFIG_MV_ETH_LEGACY_PARSER */
+
+	if (status == 0)
+		printk(KERN_ERR "Succeeded\n");
+	else if (status == 1)
+		printk(KERN_ERR "Not supported\n");
+	else
+		printk(KERN_ERR "Failed\n");
+
+	return status;
+}
+
+/* Set TXQ for special TOS value. txq=-1 - use default TXQ for this port */
+int mv_eth_txq_tos_map_set(int port, int txq, unsigned char tos)
+{
+	MV_U8 old_txq;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (mvNetaPortCheck(port))
+		return -EINVAL;
+
+	if ((pp == NULL) || (pp->txq_ctrl == NULL))
+		return -ENODEV;
+
+	old_txq = pp->txq_tos_map[tos];
+
+	if (old_txq != MV_ETH_TXQ_INVALID) {
+		if (old_txq == (MV_U8) txq)
+			return 0;
+
+		if (mv_eth_ctrl_txq_cpu_own(port, pp->txp, old_txq, 0))
+			return -EINVAL;
+	}
+
+	if (txq == -1) {
+		pp->txq_tos_map[tos] = MV_ETH_TXQ_INVALID;
+		return 0;
+	}
+
+	if (mvNetaMaxCheck(txq, CONFIG_MV_ETH_TXQ))
+		return -EINVAL;
+
+	if (mv_eth_ctrl_txq_cpu_own(port, pp->txp, txq, 1))
+		return -EINVAL;
+
+	pp->txq_tos_map[tos] = (MV_U8) txq;
+
+	return 0;
+}
+
+static int mv_eth_priv_init(struct eth_port *pp, int port)
+{
+	int i;
+	u8	*ext_buf;
+
+	TRC_INIT(0, 0, 0, 0);
+	TRC_START();
+
+	memset(pp, 0, sizeof(struct eth_port));
+
+	pp->port = port;
+	pp->txp_num = 1;
+	pp->txp = 0;
+	for_each_possible_cpu(i)
+		pp->txq[i] = CONFIG_MV_ETH_TXQ_DEF;
+
+	pp->flags = 0;
+	pp->pool_long_num = CONFIG_MV_ETH_RXQ * CONFIG_MV_ETH_RXQ_DESC * CONFIG_MV_ETH_MTU_PKT_MULT;
+
+#ifdef CONFIG_MV_ETH_BM_CPU
+	if (pp->pool_long_num > MV_BM_POOL_CAP_MAX)
+		pp->pool_long_num = MV_BM_POOL_CAP_MAX;
+
+	pp->pool_short_num = CONFIG_MV_ETH_RXQ * CONFIG_MV_ETH_RXQ_DESC * CONFIG_MV_ETH_SHORT_PKT_MULT;
+	if (pp->pool_short_num > MV_BM_POOL_CAP_MAX / CONFIG_MV_ETH_PORTS_NUM)
+		pp->pool_short_num = MV_BM_POOL_CAP_MAX / CONFIG_MV_ETH_PORTS_NUM;
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+#ifdef CONFIG_MV_ETH_POOL_PREDEFINED
+	if (pp->pool_long_num > MV_BM_POOL_CAP_MAX / CONFIG_MV_ETH_PORTS_NUM)
+		pp->pool_long_num = MV_BM_POOL_CAP_MAX / CONFIG_MV_ETH_PORTS_NUM;
+#endif /* CONFIG_MV_ETH_POOL_PREDEFINED */
+
+	for (i = 0; i < 256; i++) {
+		pp->txq_tos_map[i] = MV_ETH_TXQ_INVALID;
+
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+		pp->tx_special_check = NULL;
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+	}
+
+	mv_eth_port_config_parse(pp);
+
+#ifdef CONFIG_MV_PON
+	if (MV_PON_PORT(port)) {
+		set_bit(MV_ETH_F_MH_BIT, &(pp->flags));
+		pp->txp_num = MV_ETH_MAX_TCONT();
+		pp->txp = CONFIG_MV_PON_TXP_DEF;
+		for_each_possible_cpu(i)
+			pp->txq[i] = CONFIG_MV_PON_TXQ_DEF;
+	}
+#endif /* CONFIG_MV_PON */
+
+#if defined(CONFIG_MV_ETH_RX_CSUM_OFFLOAD_DEF)
+	pp->rx_csum_offload = 1;
+#endif /* CONFIG_MV_ETH_RX_CSUM_OFFLOAD_DEF */
+
+#ifdef CONFIG_MV_INCLUDE_SWITCH
+	if (mvBoardSwitchConnectedPortGet(port) != -1) {
+		set_bit(MV_ETH_F_SWITCH_BIT, &(pp->flags));
+		set_bit(MV_ETH_F_EXT_SWITCH_BIT, &(pp->flags));
+	}
+#endif /* CONFIG_MV_INCLUDE_SWITCH */
+
+	memset(&pp->tx_done_timer, 0, sizeof(struct timer_list));
+	pp->tx_done_timer.function = mv_eth_tx_done_timer_callback;
+	init_timer(&pp->tx_done_timer);
+	clear_bit(MV_ETH_F_TX_DONE_TIMER_BIT, &(pp->flags));
+	memset(&pp->cleanup_timer, 0, sizeof(struct timer_list));
+	pp->cleanup_timer.function = mv_eth_cleanup_timer_callback;
+	init_timer(&pp->cleanup_timer);
+	clear_bit(MV_ETH_F_CLEANUP_TIMER_BIT, &(pp->flags));
+
+	pp->weight = CONFIG_MV_ETH_RX_POLL_WEIGHT;
+	rwlock_init(&pp->rwlock);
+
+	/* Init pool of external buffers for TSO, fragmentation, etc */
+	spin_lock_init(&pp->extLock);
+	pp->extBufSize = CONFIG_MV_ETH_EXTRA_BUF_SIZE;
+	pp->extArrStack = mvStackCreate(CONFIG_MV_ETH_EXTRA_BUF_NUM);
+	if (pp->extArrStack == NULL) {
+		printk(KERN_ERR "Error: failed create  extArrStack for port #%d\n", port);
+		return -ENOMEM;
+	}
+	for (i = 0; i < CONFIG_MV_ETH_EXTRA_BUF_NUM; i++) {
+		ext_buf = mvOsMalloc(CONFIG_MV_ETH_EXTRA_BUF_SIZE);
+		if (ext_buf == NULL) {
+			printk(KERN_WARNING "%s Warning: %d of %d extra buffers allocated\n",
+				__func__, i, CONFIG_MV_ETH_EXTRA_BUF_NUM);
+			break;
+		}
+		mvStackPush(pp->extArrStack, (MV_U32)ext_buf);
+	}
+
+#ifdef CONFIG_MV_ETH_STAT_DIST
+	pp->dist_stats.rx_dist = mvOsMalloc(sizeof(u32) * (CONFIG_MV_ETH_RXQ * CONFIG_MV_ETH_RXQ_DESC + 1));
+	if (pp->dist_stats.rx_dist != NULL) {
+		pp->dist_stats.rx_dist_size = CONFIG_MV_ETH_RXQ * CONFIG_MV_ETH_RXQ_DESC + 1;
+		memset(pp->dist_stats.rx_dist, 0, sizeof(u32) * pp->dist_stats.rx_dist_size);
+	} else
+		printk(KERN_ERR "ethPort #%d: Can't allocate %d bytes for rx_dist\n",
+		       pp->port, sizeof(u32) * (CONFIG_MV_ETH_RXQ * CONFIG_MV_ETH_RXQ_DESC + 1));
+
+	pp->dist_stats.tx_done_dist =
+	    mvOsMalloc(sizeof(u32) * (pp->txp_num * CONFIG_MV_ETH_TXQ * CONFIG_MV_ETH_TXQ_DESC + 1));
+	if (pp->dist_stats.tx_done_dist != NULL) {
+		pp->dist_stats.tx_done_dist_size = pp->txp_num * CONFIG_MV_ETH_TXQ * CONFIG_MV_ETH_TXQ_DESC + 1;
+		memset(pp->dist_stats.tx_done_dist, 0, sizeof(u32) * pp->dist_stats.tx_done_dist_size);
+	} else
+		printk(KERN_ERR "ethPort #%d: Can't allocate %d bytes for tx_done_dist\n",
+		       pp->port, sizeof(u32) * (pp->txp_num * CONFIG_MV_ETH_TXQ * CONFIG_MV_ETH_TXQ_DESC + 1));
+#endif /* CONFIG_MV_ETH_STAT_DIST */
+
+	return 0;
+}
+
+/***********************************************************************************
+ ***  noqueue net device
+ ***********************************************************************************/
+extern struct Qdisc noop_qdisc;
+void mv_eth_set_noqueue(struct net_device *dev, int enable)
+{
+	struct netdev_queue *txq = netdev_get_tx_queue(dev, 0);
+
+	if (dev->flags & IFF_UP) {
+		printk(KERN_ERR "%s: device or resource busy, take it down\n", dev->name);
+		return;
+	}
+	dev->tx_queue_len = enable ? 0 : CONFIG_MV_ETH_TXQ_DESC;
+
+	if (txq)
+		txq->qdisc_sleeping = &noop_qdisc;
+	else
+		printk(KERN_ERR "%s: txq #0 is NULL\n", dev->name);
+
+	printk(KERN_ERR "%s: device tx queue len is %d\n", dev->name, (int)dev->tx_queue_len);
+
+}
+
+/***********************************************************************************
+ ***  print RX bm_pool status
+ ***********************************************************************************/
+void mv_eth_pool_status_print(int pool)
+{
+	struct bm_pool *bm_pool = &mv_eth_pool[pool];
+
+	printk(KERN_ERR "\nRX Pool #%d: pkt_size=%d, BM-HW support - %s\n",
+	       pool, bm_pool->pkt_size, mv_eth_pool_bm(bm_pool) ? "Yes" : "No");
+
+	printk(KERN_ERR "bm_pool=%p, stack=%p, capacity=%d, buf_num=%d, missed=%d\n",
+	       bm_pool->bm_pool, bm_pool->stack, bm_pool->capacity, bm_pool->buf_num, bm_pool->missed);
+
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	printk(KERN_ERR "Errors: skb_alloc_oom=%u, stack_empty=%u, stack_full=%u\n",
+	       bm_pool->stats.skb_alloc_oom, bm_pool->stats.stack_empty, bm_pool->stats.stack_full);
+#endif /* #ifdef CONFIG_MV_ETH_STAT_ERR */
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+	printk(KERN_ERR "skb_alloc_ok=%u, bm_put=%u, stack_put=%u, stack_get=%u\n",
+	       bm_pool->stats.skb_alloc_ok, bm_pool->stats.bm_put, bm_pool->stats.stack_put, bm_pool->stats.stack_get);
+
+	printk(KERN_ERR "skb_recycled_ok=%u, skb_recycled_err=%u\n",
+	       bm_pool->stats.skb_recycled_ok, bm_pool->stats.skb_recycled_err);
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+
+	if (bm_pool->stack)
+		mvStackStatus(bm_pool->stack, 0);
+
+	memset(&bm_pool->stats, 0, sizeof(bm_pool->stats));
+}
+
+
+/***********************************************************************************
+ ***  print ext pool status
+ ***********************************************************************************/
+void mv_eth_ext_pool_print(struct eth_port *pp)
+{
+	printk(KERN_ERR "\nExt Pool Stack: bufSize = %u bytes\n", pp->extBufSize);
+	mvStackStatus(pp->extArrStack, 0);
+}
+
+/***********************************************************************************
+ ***  print net device status
+ ***********************************************************************************/
+void mv_eth_netdev_print(struct net_device *dev)
+{
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+
+	printk(KERN_ERR "%s net_device status: dev=%p, pp=%p\n\n", dev->name, dev, MV_ETH_PRIV(dev));
+	printk(KERN_ERR "ifIdx=%d, features=0x%x, flags=0x%x, mtu=%u, size=%d, MAC=" MV_MACQUAD_FMT "\n",
+	       dev->ifindex, (unsigned int)(dev->features), (unsigned int)(dev->flags),
+	       dev->mtu, RX_PKT_SIZE(dev->mtu), MV_MACQUAD(dev->dev_addr));
+
+	if (dev_priv)
+		printk(KERN_ERR "group=%d, tx_vlan_mh=0x%04x, switch_port_map=0x%x, switch_port_link_map=0x%x\n",
+		       dev_priv->group, dev_priv->tx_vlan_mh, dev_priv->port_map, dev_priv->link_map);
+}
+
+void mv_eth_status_print(void)
+{
+	printk(KERN_ERR "totals: ports=%d, devs=%d\n", mv_eth_ports_num, mv_net_devs_num);
+
+#ifdef CONFIG_MV_ETH_NFP
+	printk(KERN_ERR "NFP         = %s\n", mv_ctrl_nfp ? "Enabled" : "Disabled");
+#endif
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+	printk(KERN_ERR "SKB recycle = %s\n", mv_ctrl_recycle ? "Enabled" : "Disabled");
+#endif
+}
+
+/***********************************************************************************
+ ***  print Ethernet port status
+ ***********************************************************************************/
+void mv_eth_port_status_print(unsigned int port)
+{
+	int txp, q;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (!pp)
+		return;
+
+	printk(KERN_ERR "\n");
+	printk(KERN_ERR "port=%d, flags=0x%lx\n", port, pp->flags);
+	if ((!(pp->flags & MV_ETH_F_SWITCH)) && (pp->flags & MV_ETH_F_CONNECT_LINUX))
+		printk(KERN_ERR "%s: ", pp->dev->name);
+	else
+		printk(KERN_ERR "port %d: ", port);
+
+	mv_eth_link_status_print(port);
+
+	printk(KERN_ERR "rxq_coal(pkts)[ q]   = ");
+	for (q = 0; q < CONFIG_MV_ETH_RXQ; q++)
+		printk(KERN_CONT "%3d ", mvNetaRxqPktsCoalGet(port, q));
+
+	printk(KERN_CONT "\n");
+	printk(KERN_ERR "rxq_coal(usec)[ q]   = ");
+	for (q = 0; q < CONFIG_MV_ETH_RXQ; q++)
+		printk(KERN_CONT "%3d ", mvNetaRxqTimeCoalGet(port, q));
+
+	printk(KERN_CONT "\n");
+	printk(KERN_ERR "rxq_desc(num)[ q]    = ");
+	for (q = 0; q < CONFIG_MV_ETH_RXQ; q++)
+		printk(KERN_CONT "%3d ", pp->rxq_ctrl[q].rxq_size);
+
+	printk(KERN_CONT "\n");
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		printk(KERN_ERR "txq_coal(pkts)[%2d.q] = ", txp);
+		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++)
+			printk(KERN_CONT "%3d ", mvNetaTxDonePktsCoalGet(port, txp, q));
+		printk(KERN_CONT "\n");
+
+		printk(KERN_ERR "txq_mod(F,C,H)[%2d.q] = ", txp);
+		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
+			int val, mode;
+
+			mode = mv_eth_ctrl_txq_mode_get(port, txp, q, &val);
+			if (mode == MV_ETH_TXQ_CPU)
+				printk(KERN_CONT " C%-d ", val);
+			else if (mode == MV_ETH_TXQ_HWF)
+				printk(KERN_CONT " H%-d ", val);
+			else
+				printk(KERN_CONT "  F ");
+		}
+		printk(KERN_CONT "\n");
+
+		printk(KERN_ERR "txq_desc(num) [%2d.q] = ", txp);
+		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
+			struct tx_queue *txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + q];
+			printk(KERN_CONT "%3d ", txq_ctrl->txq_size);
+		}
+		printk(KERN_CONT "\n");
+	}
+	printk(KERN_ERR "\n");
+
+#ifdef CONFIG_MV_ETH_TXDONE_ISR
+	printk(KERN_ERR "Do tx_done in NAPI context triggered by ISR\n");
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		printk(KERN_ERR "txcoal(pkts)[%2d.q] = ", txp);
+		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++)
+			printk(KERN_CONT "%3d ", mvNetaTxDonePktsCoalGet(port, txp, q));
+		printk(KERN_CONT "\n");
+	}
+	printk(KERN_ERR "\n");
+#else
+	printk(KERN_ERR "Do tx_done in TX or Timer context: tx_done_threshold=%d\n", mv_ctrl_txdone);
+#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+
+	printk(KERN_ERR "txp=%d, zero_pad=%s, mh_en=%s (0x%04x), tx_cmd=0x%08x\n",
+	       pp->txp, (pp->flags & MV_ETH_F_NO_PAD) ? "Disabled" : "Enabled",
+	       (pp->flags & MV_ETH_F_MH) ? "Enabled" : "Disabled", pp->tx_mh, pp->hw_cmd);
+
+	printk(KERN_CONT "\n");
+	printk(KERN_CONT "CPU:   txq_def   causeRxTx    napi\n");
+	{
+		int cpu;
+		for_each_possible_cpu(cpu)
+			printk(KERN_ERR "  %d:      %d      0x%08x     %d\n",
+				cpu, pp->txq[cpu], pp->causeRxTx[cpu], test_bit(NAPI_STATE_SCHED, &pp->napi[cpu]->state));
+	}
+	printk(KERN_CONT "\n");
+
+#ifdef CONFIG_MV_ETH_SWITCH
+	if (pp->flags & MV_ETH_F_SWITCH)
+		mv_eth_switch_status_print(port);
+#endif /* CONFIG_MV_ETH_SWITCH */
+}
+
+/***********************************************************************************
+ ***  print port statistics
+ ***********************************************************************************/
+
+void mv_eth_port_stats_print(unsigned int port)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct port_stats *stat = NULL;
+	struct tx_queue *txq_ctrl;
+	int txp, queue;
+	u32 total_rx_ok, total_rx_fill_ok;
+
+	TRC_OUTPUT();
+
+	if (pp == NULL) {
+		printk(KERN_ERR "eth_stats_print: wrong port number %d\n", port);
+		return;
+	}
+	stat = &(pp->stats);
+
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	printk(KERN_ERR "\n====================================================\n");
+	printk(KERN_ERR "ethPort_%d: Errors", port);
+	printk(KERN_CONT "\n-------------------------------\n");
+	printk(KERN_ERR "rx_error......................%10u\n", stat->rx_error);
+	printk(KERN_ERR "tx_timeout....................%10u\n", stat->tx_timeout);
+	printk(KERN_ERR "tx_netif_stop.................%10u\n", stat->netif_stop);
+	printk(KERN_ERR "netif_wake....................%10u\n", stat->netif_wake);
+	printk(KERN_ERR "ext_stack_empty...............%10u\n", stat->ext_stack_empty);
+	printk(KERN_ERR "ext_stack_full ...............%10u\n", stat->ext_stack_full);
+#endif /* CONFIG_MV_ETH_STAT_ERR */
+
+#ifdef CONFIG_MV_ETH_STAT_INF
+	printk(KERN_ERR "\n====================================================\n");
+	printk(KERN_ERR "ethPort_%d: interrupt statistics", port);
+	printk(KERN_CONT "\n-------------------------------\n");
+	printk(KERN_ERR "irq...........................%10u\n", stat->irq);
+	printk(KERN_ERR "irq_err.......................%10u\n", stat->irq_err);
+
+	printk(KERN_ERR "\n====================================================\n");
+	printk(KERN_ERR "ethPort_%d: Events", port);
+	printk(KERN_CONT "\n-------------------------------\n");
+	printk(KERN_ERR "poll..........................%10u\n", stat->poll);
+	printk(KERN_ERR "poll_exit.....................%10u\n", stat->poll_exit);
+	printk(KERN_ERR "tx_done_event.................%10u\n", stat->tx_done);
+	printk(KERN_ERR "tx_done_timer_event...........%10u\n", stat->tx_done_timer);
+	printk(KERN_ERR "cleanup_timer_event...........%10u\n", stat->cleanup_timer);
+	printk(KERN_ERR "link..........................%10u\n", stat->link);
+#ifdef CONFIG_MV_ETH_RX_SPECIAL
+	printk(KERN_ERR "rx_special....................%10u\n", stat->rx_special);
+#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+	printk(KERN_ERR "tx_special....................%10u\n", stat->tx_special);
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+#endif /* CONFIG_MV_ETH_STAT_INF */
+
+	printk(KERN_ERR "\n");
+	total_rx_ok = total_rx_fill_ok = 0;
+	printk(KERN_ERR "RXQ:       rx_ok      rx_fill_ok     missed\n\n");
+	for (queue = 0; queue < CONFIG_MV_ETH_RXQ; queue++) {
+		u32 rxq_ok = 0, rxq_fill = 0;
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+		rxq_ok = stat->rxq[queue];
+		rxq_fill = stat->rxq_fill[queue];
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+
+		printk(KERN_ERR "%3d:  %10u    %10u          %d\n",
+			queue, rxq_ok, rxq_fill,
+			pp->rxq_ctrl[queue].missed);
+		total_rx_ok += rxq_ok;
+		total_rx_fill_ok += rxq_fill;
+	}
+	printk(KERN_ERR "SUM:  %10u    %10u\n", total_rx_ok, total_rx_fill_ok);
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+	{
+		printk(KERN_ERR "\n====================================================\n");
+		printk(KERN_ERR "ethPort_%d: Debug statistics", port);
+		printk(KERN_CONT "\n-------------------------------\n");
+
+		printk(KERN_ERR "\n");
+
+		printk(KERN_ERR "rx_nfp....................%10u\n", stat->rx_nfp);
+		printk(KERN_ERR "rx_nfp_drop...............%10u\n", stat->rx_nfp_drop);
+
+		printk(KERN_ERR "rx_gro....................%10u\n", stat->rx_gro);
+		printk(KERN_ERR "rx_gro_bytes .............%10u\n", stat->rx_gro_bytes);
+
+		printk(KERN_ERR "tx_tso....................%10u\n", stat->tx_tso);
+		printk(KERN_ERR "tx_tso_bytes .............%10u\n", stat->tx_tso_bytes);
+
+		printk(KERN_ERR "rx_netif..................%10u\n", stat->rx_netif);
+		printk(KERN_ERR "rx_drop_sw................%10u\n", stat->rx_drop_sw);
+		printk(KERN_ERR "rx_csum_hw................%10u\n", stat->rx_csum_hw);
+		printk(KERN_ERR "rx_csum_sw................%10u\n", stat->rx_csum_sw);
+
+
+		printk(KERN_ERR "tx_skb_free...............%10u\n", stat->tx_skb_free);
+		printk(KERN_ERR "tx_sg.....................%10u\n", stat->tx_sg);
+		printk(KERN_ERR "tx_csum_hw................%10u\n", stat->tx_csum_hw);
+		printk(KERN_ERR "tx_csum_sw................%10u\n", stat->tx_csum_sw);
+
+		printk(KERN_ERR "ext_stack_get.............%10u\n", stat->ext_stack_get);
+		printk(KERN_ERR "ext_stack_put ............%10u\n", stat->ext_stack_put);
+
+		printk(KERN_ERR "\n");
+	}
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+
+	printk(KERN_ERR "\n");
+	printk(KERN_ERR "TXP-TXQ:  count        send          done      no_resource\n\n");
+
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		for (queue = 0; queue < CONFIG_MV_ETH_TXQ; queue++) {
+			u32 txq_tx = 0, txq_txdone = 0, txq_err = 0;
+
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + queue];
+#ifdef CONFIG_MV_ETH_STAT_DBG
+			txq_tx = txq_ctrl->stats.txq_tx;
+			txq_txdone =  txq_ctrl->stats.txq_txdone;
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+#ifdef CONFIG_MV_ETH_STAT_ERR
+			txq_err = txq_ctrl->stats.txq_err;
+#endif /* CONFIG_MV_ETH_STAT_ERR */
+
+			printk(KERN_ERR "%d-%d:      %3d    %10u    %10u    %10u\n",
+			       txp, queue, txq_ctrl->txq_count, txq_tx,
+			       txq_txdone, txq_err);
+
+			memset(&txq_ctrl->stats, 0, sizeof(txq_ctrl->stats));
+		}
+	}
+	printk(KERN_ERR "\n\n");
+
+	memset(stat, 0, sizeof(struct port_stats));
+
+	/* RX pool statistics */
+#ifdef CONFIG_MV_ETH_BM_CPU
+	if (pp->pool_short)
+		mv_eth_pool_status_print(pp->pool_short->pool);
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	if (pp->pool_long)
+		mv_eth_pool_status_print(pp->pool_long->pool);
+
+		mv_eth_ext_pool_print(pp);
+
+#ifdef CONFIG_MV_ETH_STAT_DIST
+	{
+		int i;
+		struct dist_stats *dist_stats = &(pp->dist_stats);
+
+		if (dist_stats->rx_dist) {
+			printk(KERN_ERR "\n      Linux Path RX distribution\n");
+			for (i = 0; i < dist_stats->rx_dist_size; i++) {
+				if (dist_stats->rx_dist[i] != 0) {
+					printk(KERN_ERR "%3d RxPkts - %u times\n", i, dist_stats->rx_dist[i]);
+					dist_stats->rx_dist[i] = 0;
+				}
+			}
+		}
+
+		if (dist_stats->tx_done_dist) {
+			printk(KERN_ERR "\n      tx-done distribution\n");
+			for (i = 0; i < dist_stats->tx_done_dist_size; i++) {
+				if (dist_stats->tx_done_dist[i] != 0) {
+					printk(KERN_ERR "%3d TxDoneDesc - %u times\n", i, dist_stats->tx_done_dist[i]);
+					dist_stats->tx_done_dist[i] = 0;
+				}
+			}
+		}
+#ifdef CONFIG_MV_ETH_TSO
+		if (dist_stats->tx_tso_dist) {
+			printk(KERN_ERR "\n      TSO stats\n");
+			for (i = 0; i < dist_stats->tx_tso_dist_size; i++) {
+				if (dist_stats->tx_tso_dist[i] != 0) {
+					printk(KERN_ERR "%3d KBytes - %u times\n", i, dist_stats->tx_tso_dist[i]);
+					dist_stats->tx_tso_dist[i] = 0;
+				}
+			}
+		}
+#endif /* CONFIG_MV_ETH_TSO */
+	}
+#endif /* CONFIG_MV_ETH_STAT_DIST */
+}
+
+
+static int mv_eth_port_cleanup(int port)
+{
+	int txp, txq, rxq;
+	struct eth_port *pp;
+	struct tx_queue *txq_ctrl;
+	struct rx_queue *rxq_ctrl;
+
+	pp = mv_eth_port_by_id(port);
+
+	if (pp == NULL)
+		return -1;
+
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "%s: port %d is started, cannot cleanup\n", __func__, port);
+		return -1;
+	}
+
+	/* Reset Tx ports */
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		if (mv_eth_txp_reset(port, txp))
+			printk(KERN_ERR "Warning: Port %d Tx port %d reset failed\n", port, txp);
+	}
+
+	/* Delete Tx queues */
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+			mv_eth_txq_delete(pp, txq_ctrl);
+		}
+	}
+
+	mvOsFree(pp->txq_ctrl);
+	pp->txq_ctrl = NULL;
+
+#ifdef CONFIG_MV_ETH_STAT_DIST
+	/* Free Tx Done distribution statistics */
+	mvOsFree(pp->dist_stats.tx_done_dist);
+#endif
+
+	/* Reset RX ports */
+	if (mv_eth_rx_reset(port))
+		printk(KERN_ERR "Warning: Rx port %d reset failed\n", port);
+
+	/* Delete Rx queues */
+	for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++) {
+		rxq_ctrl = &pp->rxq_ctrl[rxq];
+		mvNetaRxqDelete(pp->port, rxq);
+		rxq_ctrl->q = NULL;
+	}
+
+	mvOsFree(pp->rxq_ctrl);
+	pp->rxq_ctrl = NULL;
+
+#ifdef CONFIG_MV_ETH_STAT_DIST
+	/* Free Rx distribution statistics */
+	mvOsFree(pp->dist_stats.rx_dist);
+#endif
+
+	/* Free buffer pools */
+	if (pp->pool_long) {
+		mv_eth_pool_free(pp->pool_long->pool, pp->pool_long_num);
+		pp->pool_long = NULL;
+	}
+#ifdef CONFIG_MV_ETH_BM_CPU
+	if (pp->pool_short) {
+		mv_eth_pool_free(pp->pool_short->pool, pp->pool_short_num);
+		pp->pool_short = NULL;
+	}
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	/* Clear Marvell Header related modes - will be set again if needed on re-init */
+	mvNetaMhSet(port, MV_NETA_MH_NONE);
+#ifdef CONFIG_MV_ETH_NFP
+	mvNfpPortCapSet(port, NFP_P_MH, MV_FALSE);
+#endif
+
+	/* Clear any forced link, speed and duplex */
+	mv_force_port_link_speed_fc(port, MV_ETH_SPEED_AN, 0);
+
+	mvNetaPortDestroy(port);
+
+	if (pp->flags & MV_ETH_F_CONNECT_LINUX) {
+			netif_napi_del(pp->napi[CPU_GROUP_DEF]);
+	}
+
+	return 0;
+}
+
+
+int mv_eth_all_ports_cleanup(void)
+{
+	int port, pool, status = 0;
+
+	for (port = 0; port < mv_eth_ports_num; port++) {
+		status = mv_eth_port_cleanup(port);
+		if (status != 0) {
+			printk(KERN_ERR "Error: mv_eth_port_cleanup failed on port %d, stopping all ports cleanup\n", port);
+			return status;
+		}
+	}
+
+	for (pool = 0; pool < MV_ETH_BM_POOLS; pool++)
+		mv_eth_pool_destroy(pool);
+
+	for (port = 0; port < mv_eth_ports_num; port++) {
+		if (mv_eth_ports[port])
+			mvOsFree(mv_eth_ports[port]);
+	}
+
+	memset(mv_eth_ports, 0, (mv_eth_ports_num * sizeof(struct eth_port *)));
+	/* Note: not freeing mv_eth_ports - we will reuse them */
+
+	return 0;
+}
+
+#ifdef CONFIG_MV_ETH_PNC_WOL
+
+#define DEF_WOL_SIZE	42
+MV_U8	wol_data[DEF_WOL_SIZE] = { 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
+				   0x00, 0x00, 0x00, 0x00, 0x00, 0x39, 0x08, 0x00,
+				   0x45, 0x00, 0x00, 0x4E, 0x00, 0x00, 0x00, 0x00,
+				   0x00, 0x11, 0x00, 0x00, 0xc0, 0xa8, 0x01, 0xFA,
+				   0x00, 0x00, 0x00, 0x00, 0x00, 0x89, 0x00, 0x89,
+				   0x00, 0x3A };
+
+MV_U8	wol_mask[DEF_WOL_SIZE] = { 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
+				   0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
+				   0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,
+				   0x00, 0xff, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,
+				   0x00, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,
+				   0xff, 0xff };
+
+int mv_eth_wol_pkts_check(int port)
+{
+	struct eth_port		*pp = mv_eth_port_by_id(port);
+	struct neta_rx_desc *rx_desc;
+	struct eth_pbuf     *pkt;
+	struct bm_pool      *pool;
+	int	                rxq, rx_done, i, wakeup, ruleId;
+	MV_NETA_RXQ_CTRL    *rx_ctrl;
+
+	write_lock(&pp->rwlock);
+	wakeup = 0;
+	for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++) {
+		rx_ctrl = pp->rxq_ctrl[rxq].q;
+
+		if (rx_ctrl == NULL)
+			continue;
+
+		rx_done = mvNetaRxqBusyDescNumGet(pp->port, rxq);
+
+		for (i = 0; i < rx_done; i++) {
+			rx_desc = mvNetaRxqNextDescGet(rx_ctrl);
+			mvOsCacheLineInv(NULL, rx_desc);
+
+#if defined(MV_CPU_BE)
+			mvNetaRxqDescSwap(rx_desc);
+#endif /* MV_CPU_BE */
+
+			pkt = (struct eth_pbuf *)rx_desc->bufCookie;
+			mvOsCacheInvalidate(NULL, pkt->pBuf + pkt->offset, rx_desc->dataSize);
+
+			if (mv_pnc_wol_pkt_match(pp->port, pkt->pBuf + pkt->offset, rx_desc->dataSize, &ruleId))
+				wakeup = 1;
+
+			pool = &mv_eth_pool[pkt->pool];
+			mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+
+			if (wakeup) {
+				printk(KERN_INFO "packet match WoL rule=%d found on port=%d, rxq=%d\n",
+						ruleId, port, rxq);
+				i++;
+				break;
+			}
+		}
+		if (i) {
+			mvNetaRxqDescNumUpdate(pp->port, rxq, i, i);
+			printk(KERN_INFO "port=%d, rxq=%d: %d of %d packets dropped\n", port, rxq, i, rx_done);
+		}
+		if (wakeup) {
+			/* Failed enter WoL mode */
+			write_unlock(&pp->rwlock);
+			return 1;
+		}
+	}
+	write_unlock(&pp->rwlock);
+	return 0;
+}
+
+void mv_eth_wol_wakeup(int port)
+{
+	int rxq;
+
+	/* Restore RXQ coalescing */
+	for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++) {
+		mvNetaRxqPktsCoalSet(port, rxq, CONFIG_MV_ETH_RX_COAL_PKTS);
+		mvNetaRxqTimeCoalSet(port, rxq, CONFIG_MV_ETH_RX_COAL_USEC);
+	}
+
+	/* Set PnC to Active filtering mode */
+	mv_pnc_wol_wakeup(port);
+	printk(KERN_INFO "Exit wakeOnLan mode on port #%d\n", port);
+
+}
+
+int mv_eth_wol_sleep(int port)
+{
+	int rxq;
+
+	/* Set PnC to WoL filtering mode */
+	mv_pnc_wol_sleep(port);
+
+	/* Check received packets in all RXQs */
+	/* If match one of WoL pattern - wakeup, not match - drop */
+	if (mv_eth_wol_pkts_check(port)) {
+		/* Set PNC to Active filtering mode */
+		mv_pnc_wol_wakeup(port);
+		printk(KERN_INFO "Failed to enter wakeOnLan mode on port #%d\n", port);
+		return 1;
+	}
+	printk(KERN_INFO "Enter wakeOnLan mode on port #%d\n", port);
+
+	/* Set RXQ coalescing to minimum */
+	for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++) {
+		mvNetaRxqPktsCoalSet(port, rxq, 0);
+		mvNetaRxqTimeCoalSet(port, rxq, 0);
+	}
+
+	return 0;
+}
+#endif /* CONFIG_MV_ETH_PNC_WOL */
+
+/* Support for platform driver */
+
+#ifdef CONFIG_PM
+int mv_eth_suspend(struct platform_device *pdev, pm_message_t state)
+{
+#ifdef CONFIG_MV_ETH_PNC_WOL
+	int port;
+
+	printk(KERN_INFO "Entering WoL mode on All Neta interfaces\n");
+	for (port = 0; port < mv_eth_ports_num; port++) {
+		/* Configure ETH port to be in WoL mode */
+		if (mv_eth_wol_sleep(port))
+			return 1;
+	}
+#endif /* CONFIG_MV_ETH_PNC_WOL */
+
+	return 0;
+}
+
+int mv_eth_resume(struct platform_device *pdev)
+{
+#ifdef CONFIG_MV_ETH_PNC_WOL
+	int port;
+
+	printk(KERN_INFO "Exiting WoL mode on All Neta interfaces\n");
+	for (port = 0; port < mv_eth_ports_num; port++) {
+		/* Configure ETH port to work in normal mode */
+		mv_eth_wol_wakeup(port);
+	}
+#endif /* CONFIG_MV_ETH_PNC_WOL */
+	return 0;
+}
+#endif /* CONFIG_PM */
+
+static int mv_eth_remove(struct platform_device *pdev)
+{
+    printk(KERN_INFO "Removing Marvell Ethernet Driver\n");
+    return 0;
+}
+
+static void mv_eth_shutdown(struct platform_device *pdev)
+{
+    printk(KERN_INFO "Shutting Down Marvell Ethernet Driver\n");
+}
+
+static struct platform_driver mv_eth_driver = {
+	.probe = mv_eth_probe,
+	.remove = mv_eth_remove,
+	.shutdown = mv_eth_shutdown,
+#ifdef CONFIG_PM
+	.suspend = mv_eth_suspend,
+	.resume = mv_eth_resume,
+#endif /* CONFIG_PM */
+	.driver = {
+		.name = "mv88fx_neta",
+	},
+};
+
+static int __init mv_eth_init_module(void)
+{
+	return platform_driver_register(&mv_eth_driver);
+}
+module_init(mv_eth_init_module);
+
+static void __exit mv_eth_cleanup_module(void)
+{
+	platform_driver_unregister(&mv_eth_driver);
+}
+module_exit(mv_eth_cleanup_module);
+
+
+MODULE_DESCRIPTION("Marvell Ethernet Driver - www.marvell.com");
+MODULE_AUTHOR("Dmitri Epshtein <dima@marvell.com>");
+MODULE_LICENSE("GPL");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h
new file mode 100644
index 0000000..d5c72fa
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h
@@ -0,0 +1,536 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_netdev_h__
+#define __mv_netdev_h__
+
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <net/ip.h>
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "mv802_3.h"
+#include "mvStack.h"
+
+#include "gbe/mvNeta.h"
+#include "neta/bm/mvBmRegs.h"
+
+/******************************************************
+ * driver statistics control --                       *
+ ******************************************************/
+#ifdef CONFIG_MV_ETH_STAT_ERR
+#define STAT_ERR(c) c
+#else
+#define STAT_ERR(c)
+#endif
+
+#ifdef CONFIG_MV_ETH_STAT_INF
+#define STAT_INFO(c) c
+#else
+#define STAT_INFO(c)
+#endif
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+#define STAT_DBG(c) c
+#else
+#define STAT_DBG(c)
+#endif
+
+#ifdef CONFIG_MV_ETH_STAT_DIST
+#define STAT_DIST(c) c
+#else
+#define STAT_DIST(c)
+#endif
+
+/****************************************************************************
+ * Rx buffer size: MTU + 2(Marvell Header) + 4(VLAN) + 14(MAC hdr) + 4(CRC) *
+ ****************************************************************************/
+#define RX_PKT_SIZE(mtu) \
+		MV_ALIGN_UP((mtu) + 2 + 4 + ETH_HLEN + 4, CPU_D_CACHE_LINE_SIZE)
+
+#define RX_BUF_SIZE(pkt_size)   ((pkt_size) + NET_SKB_PAD)
+
+/******************************************************
+ * interrupt control --                               *
+ ******************************************************/
+#ifdef CONFIG_MV_ETH_TXDONE_ISR
+#define MV_ETH_TXDONE_INTR_MASK       (((1 << CONFIG_MV_ETH_TXQ) - 1) << NETA_CAUSE_TXQ_SENT_DESC_OFFS)
+#else
+#define MV_ETH_TXDONE_INTR_MASK       0
+#endif
+
+#define MV_ETH_MISC_SUM_INTR_MASK     (NETA_CAUSE_TX_ERR_SUM_MASK | NETA_CAUSE_MISC_SUM_MASK)
+#define MV_ETH_RX_INTR_MASK           (((1 << CONFIG_MV_ETH_RXQ) - 1) << NETA_CAUSE_RXQ_OCCUP_DESC_OFFS)
+#define NETA_RX_FL_DESC_MASK          (NETA_RX_F_DESC_MASK|NETA_RX_L_DESC_MASK)
+
+/* NAPI CPU defualt group */
+#define CPU_GROUP_DEF 0
+
+#define MV_ETH_TRYLOCK(lock, flags)                           \
+	(in_interrupt() ? spin_trylock((lock)) :              \
+		spin_trylock_irqsave((lock), (flags)))
+
+#define MV_ETH_LOCK(lock, flags)                              \
+	if (in_interrupt())                                   \
+		spin_lock((lock));                            \
+	else                                                  \
+		spin_lock_irqsave((lock), (flags));
+
+#define MV_ETH_UNLOCK(lock, flags)                            \
+	if (in_interrupt())                                   \
+		spin_unlock((lock));                          \
+	else                                                  \
+		spin_unlock_irqrestore((lock), (flags));
+
+/******************************************************
+ * rx / tx queues --                                  *
+ ******************************************************/
+#define NR_GROUPS 4
+/*
+ * Debug statistics
+ */
+struct txq_stats {
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	u32 txq_err;
+#endif /* CONFIG_MV_ETH_STAT_ERR */
+#ifdef CONFIG_MV_ETH_STAT_DBG
+	u32 txq_tx;
+	u32 txq_txdone;
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+};
+
+struct port_stats {
+
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	u32 rx_error;
+	u32 tx_timeout;
+	u32 netif_stop;
+	u32 ext_stack_empty;
+	u32 ext_stack_full;
+	u32 netif_wake;
+#endif /* CONFIG_MV_ETH_STAT_ERR */
+
+#ifdef CONFIG_MV_ETH_STAT_INF
+	u32 irq;
+	u32 irq_err;
+	u32 poll;
+	u32 poll_exit;
+	u32 tx_done;
+	u32 tx_done_timer;
+	u32 cleanup_timer;
+	u32 link;
+
+#ifdef CONFIG_MV_ETH_RX_SPECIAL
+	u32 rx_special;
+#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+	u32	tx_special;
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+
+#endif /* CONFIG_MV_ETH_STAT_INF */
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+	u32 rxq[CONFIG_MV_ETH_RXQ];
+	u32 rxq_fill[CONFIG_MV_ETH_RXQ];
+	u32 rx_netif;
+	u32 rx_nfp;
+	u32 rx_nfp_drop;
+	u32 rx_gro;
+	u32 rx_gro_bytes;
+	u32 rx_drop_sw;
+	u32 rx_csum_hw;
+	u32 rx_csum_sw;
+	u32 tx_csum_hw;
+	u32 tx_csum_sw;
+	u32 tx_skb_free;
+	u32 tx_sg;
+	u32 tx_tso;
+	u32 ext_stack_put;
+	u32 ext_stack_get;
+	u32 tx_tso_bytes;
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+};
+
+/* Used for define type of data saved in shadow: SKB or eth_pbuf or nothing */
+#define MV_ETH_SHADOW_SKB		0x1
+#define MV_ETH_SHADOW_EXT		0x2
+
+/* Masks used for pp->flags */
+#define MV_ETH_F_STARTED_BIT		0
+#define MV_ETH_F_TX_DONE_TIMER_BIT	1
+#define MV_ETH_F_SWITCH_BIT		2	/* port is connected to the Switch using the Gateway driver */
+#define MV_ETH_F_MH_BIT			3
+#define MV_ETH_F_NO_PAD_BIT		4
+#define MV_ETH_F_DBG_RX_BIT		5
+#define MV_ETH_F_DBG_TX_BIT		6
+#define MV_ETH_F_EXT_SWITCH_BIT		7	/* port is connected to the Switch without the Gateway driver */
+#define MV_ETH_F_CONNECT_LINUX_BIT	8	/* port is connected to Linux netdevice */
+#define MV_ETH_F_LINK_UP_BIT		9
+#define MV_ETH_F_DBG_DUMP_BIT		10
+#define MV_ETH_F_DBG_ISR_BIT		11
+#define MV_ETH_F_DBG_POLL_BIT		12
+#define MV_ETH_F_CLEANUP_TIMER_BIT	13
+
+#define MV_ETH_F_STARTED		(1 << MV_ETH_F_STARTED_BIT)		/* 0x01 */
+#define MV_ETH_F_TX_DONE_TIMER		(1 << MV_ETH_F_TX_DONE_TIMER_BIT)	/* 0x02 */
+#define MV_ETH_F_SWITCH			(1 << MV_ETH_F_SWITCH_BIT)		/* 0x04 */
+#define MV_ETH_F_MH			(1 << MV_ETH_F_MH_BIT)			/* 0x08 */
+#define MV_ETH_F_NO_PAD			(1 << MV_ETH_F_NO_PAD_BIT)		/* 0x10 */
+#define MV_ETH_F_DBG_RX			(1 << MV_ETH_F_DBG_RX_BIT)		/* 0x20 */
+#define MV_ETH_F_DBG_TX			(1 << MV_ETH_F_DBG_TX_BIT)		/* 0x40 */
+#define MV_ETH_F_EXT_SWITCH		(1 << MV_ETH_F_EXT_SWITCH_BIT)		/* 0x80 */
+#define MV_ETH_F_CONNECT_LINUX		(1 << MV_ETH_F_CONNECT_LINUX_BIT)	/* 0x100 */
+#define MV_ETH_F_LINK_UP		(1 << MV_ETH_F_LINK_UP_BIT)		/* 0x200 */
+#define MV_ETH_F_DBG_DUMP		(1 << MV_ETH_F_DBG_DUMP_BIT)		/* 0x400 */
+#define MV_ETH_F_DBG_ISR		(1 << MV_ETH_F_DBG_ISR_BIT)		/* 0x800 */
+#define MV_ETH_F_DBG_POLL		(1 << MV_ETH_F_DBG_POLL_BIT)		/* 0x1000 */
+#define MV_ETH_F_CLEANUP_TIMER		(1 << MV_ETH_F_CLEANUP_TIMER_BIT)	/* 0x2000 */
+
+
+/* One of three TXQ states */
+#define MV_ETH_TXQ_FREE         0
+#define MV_ETH_TXQ_CPU          1
+#define MV_ETH_TXQ_HWF          2
+
+#define MV_ETH_TXQ_INVALID		0xFF
+
+struct mv_eth_tx_spec {
+	u32		hw_cmd;	/* tx_desc offset = 0xC */
+	u16		flags;
+	u8		txp;
+	u8		txq;
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+	void		(*tx_func) (u8 *data, int size, struct mv_eth_tx_spec *tx_spec);
+#endif
+};
+
+struct tx_queue {
+	MV_NETA_TXQ_CTRL   *q;
+	u8                  cpu_owner; /* counter */
+	u8                  hwf_rxp;
+	u8                  txp;
+	u8                  txq;
+	int                 txq_size;
+	int                 txq_count;
+	int                 bm_only;
+	u32                 *shadow_txq; /* can be MV_ETH_PKT* or struct skbuf* */
+	int                 shadow_txq_put_i;
+	int                 shadow_txq_get_i;
+	struct txq_stats    stats;
+	spinlock_t          queue_lock;
+	MV_U32              txq_done_pkts_coal;
+};
+
+struct rx_queue {
+	MV_NETA_RXQ_CTRL    *q;
+	int                 rxq_size;
+	int                 missed;
+	MV_U32	            rxq_pkts_coal;
+	MV_U32	            rxq_time_coal;
+};
+
+struct dist_stats {
+	u32     *rx_dist;
+	int     rx_dist_size;
+	u32     *tx_done_dist;
+	int     tx_done_dist_size;
+	u32     *tx_tso_dist;
+	int     tx_tso_dist_size;
+};
+
+struct eth_port {
+	int                 port;
+	MV_NETA_PORT_CTRL   *port_ctrl;
+	struct rx_queue     *rxq_ctrl;
+	struct tx_queue     *txq_ctrl;
+	int                 txp_num;
+	struct timer_list   tx_done_timer;
+	struct timer_list   cleanup_timer;
+	struct net_device   *dev;
+	rwlock_t            rwlock;
+	struct bm_pool      *pool_long;
+	int                 pool_long_num;
+#ifdef CONFIG_MV_ETH_BM_CPU
+	struct bm_pool      *pool_short;
+	int                 pool_short_num;
+#endif /* CONFIG_MV_ETH_BM_CPU */
+	MV_U32              causeRxTx[CONFIG_NR_CPUS];
+	struct napi_struct  *napi[CONFIG_NR_CPUS];
+	struct napi_struct  *napiGroup[NR_GROUPS];	
+	
+	unsigned long       flags;	/* MH, TIMER, etc. */
+	u32                 hw_cmd;	/* offset 0xc in TX descriptor */
+	int                 txp;
+	int                 txq[CONFIG_NR_CPUS];
+	u16                 tx_mh;	/* 2B MH */
+	struct port_stats   stats;
+	struct dist_stats   dist_stats;
+	MV_U8               txq_tos_map[256];
+	int                 weight;
+	MV_STACK            *extArrStack;
+	int                 extBufSize;
+	spinlock_t          extLock;
+#ifdef CONFIG_MV_ETH_TOOL
+	__u16               speed_cfg;
+	__u8                duplex_cfg;
+	__u8                autoneg_cfg;
+	__u16		    advertise_cfg;
+#endif/* CONFIG_MV_ETH_TOOL */
+#ifdef CONFIG_MV_ETH_RX_CSUM_OFFLOAD
+	MV_U32              rx_csum_offload;
+#endif /* CONFIG_MV_ETH_RX_CSUM_OFFLOAD */
+#ifdef CONFIG_MV_ETH_RX_SPECIAL
+	void    (*rx_special_proc)(int port, int rxq, struct net_device *dev,
+					struct sk_buff *skb, struct neta_rx_desc *rx_desc);
+#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+	int     (*tx_special_check)(int port, struct net_device *dev, struct sk_buff *skb,
+					struct mv_eth_tx_spec *tx_spec_out);
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+	int cesaChan;
+};
+
+struct eth_netdev {
+	u16     tx_vlan_mh;		/* 2B MH */
+	u16     vlan_grp_id;		/* vlan group ID */
+	u16     port_map;		/* switch port map */
+	u16     link_map;		/* switch port link map */
+	u16     cpu_port;		/* switch CPU port */
+	u16     group;
+};
+
+struct eth_dev_priv {
+	struct eth_port     *port_p;
+	struct eth_netdev   *netdev_p;
+};
+
+#define MV_ETH_PRIV(dev)        (((struct eth_dev_priv *)(netdev_priv(dev)))->port_p)
+#define MV_DEV_PRIV(dev)        (((struct eth_dev_priv *)(netdev_priv(dev)))->netdev_p)
+#define MV_DEV_STAT(dev)        (&((dev)->stats))
+
+/* define which Switch ports are relevant */
+#define SWITCH_CONNECTED_PORTS_MASK	0x7F
+
+#define MV_SWITCH_ID_0			0
+
+struct pool_stats {
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	u32 skb_alloc_oom;
+	u32 stack_empty;
+	u32 stack_full;
+#endif /* CONFIG_MV_ETH_STAT_ERR */
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+	u32 bm_put;
+	u32 stack_put;
+	u32 stack_get;
+	u32 skb_alloc_ok;
+	u32 skb_recycled_ok;
+	u32 skb_recycled_err;
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+};
+
+struct bm_pool {
+	int         pool;
+	int         capacity;
+	int         buf_num;
+	int         pkt_size;
+	u32         *bm_pool;
+	MV_STACK    *stack;
+	spinlock_t  lock;
+	int         missed;		/* FIXME: move to stats */
+	struct pool_stats  stats;
+};
+
+#ifdef CONFIG_MV_ETH_BM_CPU
+#define MV_ETH_BM_POOLS	        MV_BM_POOLS
+#define MV_ETH_SHORT_BM_POOL    (MV_BM_POOLS - 1)
+#define mv_eth_pool_bm(p)       (p->bm_pool)
+#define mv_eth_txq_bm(q)        (q->bm_only)
+#else
+#define MV_ETH_BM_POOLS			CONFIG_MV_ETH_PORTS_NUM
+#define mv_eth_pool_bm(p)       0
+#define mv_eth_txq_bm(q)        0
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+extern struct bm_pool mv_eth_pool[MV_ETH_BM_POOLS];
+extern struct eth_port **mv_eth_ports;
+
+static inline void mv_eth_interrupts_unmask(struct eth_port *pp)
+{
+	/* unmask interrupts */
+	if (!(pp->flags & (MV_ETH_F_SWITCH | MV_ETH_F_EXT_SWITCH)))
+		MV_REG_WRITE(NETA_INTR_MISC_MASK_REG(pp->port), NETA_CAUSE_LINK_CHANGE_MASK);
+
+	MV_REG_WRITE(NETA_INTR_NEW_MASK_REG(pp->port),
+		(MV_ETH_MISC_SUM_INTR_MASK |
+		MV_ETH_TXDONE_INTR_MASK |
+		MV_ETH_RX_INTR_MASK));
+}
+
+static inline int mv_eth_ctrl_is_tx_enabled(struct eth_port *pp)
+{
+	if (!pp)
+		return -ENODEV;
+
+	if (pp->flags & MV_ETH_F_CONNECT_LINUX)
+		return 1;
+
+	return 0;
+}
+
+#ifdef CONFIG_MV_ETH_SWITCH
+struct mv_eth_switch_config {
+	int             mtu;
+	int             netdev_max;
+	int             netdev_cfg;
+	unsigned char   mac_addr[CONFIG_MV_ETH_SWITCH_NETDEV_NUM][MV_MAC_ADDR_SIZE];
+	u16             board_port_map[CONFIG_MV_ETH_SWITCH_NETDEV_NUM];
+};
+
+extern int  mv_eth_switch_netdev_first, mv_eth_switch_netdev_last;
+extern struct mv_eth_switch_config      switch_net_config;
+extern struct net_device **mv_net_devs;
+
+int     mv_eth_switch_config_get(int use_existing_config);
+int     mv_eth_switch_set_mac_addr(struct net_device *dev, void *mac);
+void    mv_eth_switch_set_multicast_list(struct net_device *dev);
+int     mv_eth_switch_change_mtu(struct net_device *dev, int mtu);
+int     mv_eth_switch_start(struct net_device *dev);
+int     mv_eth_switch_stop(struct net_device *dev);
+void    mv_eth_switch_status_print(int port);
+int     mv_eth_switch_port_add(struct net_device *dev, int port);
+int     mv_eth_switch_port_del(struct net_device *dev, int port);
+
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+/******************************************************
+ * Function prototypes --                             *
+ ******************************************************/
+int         mv_eth_stop(struct net_device *dev);
+int         mv_eth_change_mtu(struct net_device *dev, int mtu);
+int         mv_eth_set_mac_addr(struct net_device *dev, void *mac);
+void        mv_eth_set_multicast_list(struct net_device *dev);
+int         mv_eth_open(struct net_device *dev);
+
+irqreturn_t mv_eth_isr(int irq, void *dev_id);
+int         mv_eth_start_internals(struct eth_port *pp, int mtu);
+int         mv_eth_stop_internals(struct eth_port *pp);
+int         mv_eth_change_mtu_internals(struct net_device *netdev, int mtu);
+
+int         mv_eth_rx_reset(int port);
+int         mv_eth_txp_reset(int port, int txp);
+
+MV_STATUS   mv_eth_rx_ptks_coal_set(int port, int rxq, MV_U32 value);
+MV_STATUS   mv_eth_rx_time_coal_set(int port, int rxq, MV_U32 value);
+MV_STATUS   mv_eth_tx_done_ptks_coal_set(int port, int txp, int txq, MV_U32 value);
+
+struct eth_port     *mv_eth_port_by_id(unsigned int port);
+struct net_device   *mv_eth_netdev_by_id(unsigned int idx);
+
+void        mv_eth_mac_show(int port);
+void        mv_eth_tos_map_show(int port);
+int         mv_eth_rxq_tos_map_set(int port, int rxq, unsigned char tos);
+int         mv_eth_txq_tos_map_set(int port, int txq, unsigned char tos);
+
+void        mv_eth_netdev_print(struct net_device *netdev);
+void        mv_eth_status_print(void);
+void        mv_eth_port_status_print(unsigned int port);
+void        mv_eth_port_stats_print(unsigned int port);
+
+void        mv_eth_set_noqueue(struct net_device *dev, int enable);
+
+void        mv_eth_ctrl_nfp(int en);
+void        mv_eth_ctrl_recycle(int en);
+void        mv_eth_ctrl_txdone(int num);
+int         mv_eth_ctrl_tx_mh(int port, u16 mh);
+int         mv_eth_ctrl_tx_cmd(int port, u32 cmd);
+int         mv_eth_ctrl_txq_cpu_def(int port, int txp, int txq, int cpu);
+int         mv_eth_ctrl_txq_mode_get(int port, int txp, int txq, int *rx_port);
+int         mv_eth_ctrl_txq_cpu_own(int port, int txp, int txq, int add);
+int         mv_eth_ctrl_txq_hwf_own(int port, int txp, int txq, int rxp);
+int         mv_eth_ctrl_flag(int port, u32 flag, u32 val);
+int         mv_eth_ctrl_txq_size_set(int port, int txp, int txq, int value);
+int         mv_eth_ctrl_rxq_size_set(int port, int rxq, int value);
+int         mv_eth_ctrl_port_buf_num_set(int port, int long_num, int short_num);
+int         mv_eth_ctrl_set_poll_rx_weight(int port, u32 weight);
+
+void        mv_eth_tx_desc_print(struct neta_tx_desc *desc);
+void        mv_eth_pkt_print(struct eth_pbuf *pkt);
+void        mv_eth_rx_desc_print(struct neta_rx_desc *desc);
+void        mv_eth_skb_print(struct sk_buff *skb);
+void        mv_eth_link_status_print(int port);
+
+#ifdef CONFIG_MV_PON
+void        mv_pon_ctrl_omci_type(MV_U16 type);
+void        mv_pon_ctrl_omci_rx_gh(int en);
+void        mv_pon_omci_print(void);
+#endif /* CONFIG_MV_PON */
+
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+void        mv_eth_tx_special_check_func(int port, int (*func)(int port, struct net_device *dev,
+				  struct sk_buff *skb, struct mv_eth_tx_spec *tx_spec_out));
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+
+#ifdef CONFIG_MV_ETH_RX_SPECIAL
+void        mv_eth_rx_special_proc_func(int port, void (*func)(int port, int rxq, struct net_device *dev,
+							struct sk_buff *skb, struct neta_rx_desc *rx_desc));
+#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+
+int  mv_eth_poll(struct napi_struct *napi, int budget);
+void mv_eth_link_event(struct eth_port *pp, int print);
+
+inline void mv_eth_shadow_inc_put(struct tx_queue *txq);
+inline void mv_eth_shadow_dec_put(struct tx_queue *txq);
+inline int mv_eth_rx_policy(u32 cause);
+inline u32 mv_eth_tx_done_gbe(struct eth_port *pp, u32 cause_tx_done, int *tx_todo);
+inline u32 mv_eth_tx_done_pon(struct eth_port *pp, int *tx_todo);
+inline u32 mv_eth_txq_done(struct eth_port *pp, struct tx_queue *txq_ctrl);
+inline void mv_eth_tx_desc_flush(struct neta_tx_desc *tx_desc);
+inline void mv_eth_rxq_refill(struct eth_port *pp, int rxq,
+				struct eth_pbuf *pkt, struct bm_pool *pool, struct neta_rx_desc *rx_desc);
+inline struct eth_pbuf *mv_eth_pool_get(struct bm_pool *pool);
+inline int mv_eth_pool_put(struct bm_pool *pool, struct eth_pbuf *pkt);
+
+#ifdef CONFIG_MV_ETH_RX_DESC_PREFETCH
+inline struct neta_rx_desc *mv_eth_rx_prefetch(struct eth_port *pp,
+						MV_NETA_RXQ_CTRL *rx_ctrl, int rx_done, int rx_todo);
+#endif /* CONFIG_MV_ETH_RX_DESC_PREFETCH */
+
+#ifdef CONFIG_MV_ETH_BM
+void	*mv_eth_bm_pool_create(int pool, int capacity, MV_ULONG *physAddr);
+#endif /* CONFIG_MV_ETH_BM */
+
+#ifdef CONFIG_MV_ETH_HWF
+MV_STATUS mv_eth_hwf_bm_create(int port, int mtuPktSize);
+void      mv_hwf_bm_dump(void);
+#endif /* CONFIG_MV_ETH_HWF */
+
+#endif /* __mv_netdev_h__ */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_pon_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_pon_sysfs.c
new file mode 100644
index 0000000..647d620
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_pon_sysfs.c
@@ -0,0 +1,181 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "gbe/mvNeta.h"
+#include "pnc/mvPnc.h"
+
+#include "mv_netdev.h"
+
+static ssize_t mv_pon_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "cat help                   - show this help\n");
+	off += sprintf(buf+off, "echo p txp   > txp_regs    - show TX registers for <p/txp>\n");
+
+#ifdef MV_PON_MIB_SUPPORT
+	off += sprintf(buf+off, "echo mib gp  > mib_gpid    - MIB set <mib> for incoming packets with GemPID <gp>\n");
+	off += sprintf(buf+off, "echo mib     > mib_def     - MIB set <mib> for incoming packets not matched any GemPID\n");
+#endif /* MV_PON_MIB_SUPPORT */
+
+	return off;
+}
+
+
+static ssize_t mv_pon_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	int        off = 0;
+	const char *name = attr->attr.name;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help"))
+		off = mv_pon_help(buf);
+	else
+		off = mv_pon_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_pon_1_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	unsigned int    v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read input */
+	v = 0;
+
+	sscanf(buf, "%x", &v);
+
+	local_irq_save(flags);
+
+#ifdef MV_PON_MIB_SUPPORT
+	if (!strcmp(name, "mib_def")) {
+		mvNetaPonRxMibDefault(v);
+	} else
+#endif /* MV_PON_MIB_SUPPORT */
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+
+	local_irq_restore(flags);
+
+	return len;
+}
+
+static ssize_t mv_pon_2_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char	*name = attr->attr.name;
+	unsigned int    p, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read input */
+	v = 0;
+	sscanf(buf, "%d %x", &p, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "txp_regs"))
+		mvNetaPonTxpRegs(p, v);
+#ifdef MV_PON_MIB_SUPPORT
+	else if (!strcmp(name, "mib_gpid"))
+		mvNetaPonRxMibGemPid(p, v);
+#endif /* MV_PON_MIB_SUPPORT */
+	else
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+
+	local_irq_restore(flags);
+
+	return len;
+}
+
+static DEVICE_ATTR(txp_regs,   S_IWUSR, mv_pon_show, mv_pon_2_store);
+static DEVICE_ATTR(mib_gpid,   S_IWUSR, mv_pon_show, mv_pon_2_store);
+static DEVICE_ATTR(mib_def,    S_IWUSR, mv_pon_show, mv_pon_1_store);
+static DEVICE_ATTR(help,       S_IRUSR, mv_pon_show, NULL);
+
+static struct attribute *mv_pon_attrs[] = {
+	&dev_attr_txp_regs.attr,
+	&dev_attr_mib_def.attr,
+	&dev_attr_mib_gpid.attr,
+	&dev_attr_help.attr,
+	NULL
+};
+
+static struct attribute_group mv_pon_group = {
+	.name = "pon",
+	.attrs = mv_pon_attrs,
+};
+
+int __devinit mv_pon_sysfs_init(void)
+{
+		int err;
+		struct device *pd;
+
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+		if (!pd) {
+			platform_device_register_simple("neta", -1, NULL, 0);
+			pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+		}
+
+		if (!pd) {
+			printk(KERN_ERR"%s: cannot find neta device\n", __func__);
+			pd = &platform_bus;
+		}
+
+		err = sysfs_create_group(&pd->kobj, &mv_pon_group);
+		if (err) {
+			printk(KERN_INFO "sysfs group failed %d\n", err);
+			goto out;
+		}
+out:
+		return err;
+}
+
+module_init(mv_pon_sysfs_init);
+
+MODULE_AUTHOR("Dmitri Epshtein");
+MODULE_DESCRIPTION("sysfs for Marvell PON");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/pmt/pmt_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/pmt/pmt_sysfs.c
new file mode 100644
index 0000000..a320934
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/pmt/pmt_sysfs.c
@@ -0,0 +1,180 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+
+#include "pmt/mvPmt.h"
+
+static ssize_t pmt_help(char *buf)
+{
+	int off = 0;
+
+	off += mvOsSPrintf(buf+off, "echo p         > hw_dump   - dump PMT on port <p>\n");
+	off += mvOsSPrintf(buf+off, "echo p         > hw_init   - init PMT on port <p>\n");
+	off += mvOsSPrintf(buf+off, "echo p i a b c > hw_write  - add {a,b,c} into port <p> entry <i>\n");
+	off += mvOsSPrintf(buf+off, "echo p i       > hw_read   - read entry <i> on port <p>\n");
+	off += mvOsSPrintf(buf+off, "echo p i       > hw_inv    - disable entry <i> on port <p>\n");
+   	off += mvOsSPrintf(buf+off, "echo p txp     > hw_regs   - show PM registers\n");
+   	off += mvOsSPrintf(buf+off, "echo p txp i v > mh_reg    - set MH register <i=0..5> with value <v>\n");
+   	off += mvOsSPrintf(buf+off, "echo p txp i v > eth_reg   - set ETH register <i=0..3> with value <v>\n");
+
+	return off;
+}
+
+static ssize_t pmt_show(struct device *dev, 
+				  struct device_attribute *attr, char *buf)
+{
+	const char* name = attr->attr.name;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help")) 
+		return pmt_help(buf);
+
+	return 0;
+}
+
+static ssize_t pmt_store(struct device *dev, 
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+    const char* name = attr->attr.name;
+	unsigned int err=0, p=0, i=0, a=0, b=0, c=0;
+	unsigned long flags;
+	struct mv_neta_pmt_t pmt_e;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf,"%x %x %x %x %x",&p, &i, &a, &b, &c);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "hw_dump"))
+		err = mvNetaPmtDump(p);
+	else if (!strcmp(name, "hw_regs"))
+		mvNetaPmtRegs(p, i);
+	else if (!strcmp(name, "hw_init"))
+		err = mvNetaPmtInit(p);
+	else if (!strcmp(name, "hw_write")) {
+		pmt_e.mt_w0 = a;
+		pmt_e.mt_w1 = b;
+		pmt_e.mt_w2 = c;
+		err = mvNetaPmtWrite(p, i, &pmt_e);
+	}
+	else if (!strcmp(name, "hw_read")) {
+		memset(&pmt_e, 0, sizeof(struct mv_neta_pmt_t));
+        err = mvNetaPmtRead(p, i, &pmt_e);
+		printk("%x %x %x\n", pmt_e.mt_w0, pmt_e.mt_w1, pmt_e.mt_w2);
+	}
+	else if (!strcmp(name, "hw_inv")) {
+		memset(&pmt_e, 0, sizeof(struct mv_neta_pmt_t));
+        err = mvNetaPmtWrite(p, i, &pmt_e);
+	}
+	else if (!strcmp(name, "mh_reg")) {
+		memset(&pmt_e, 0, sizeof(struct mv_neta_pmt_t));
+        err = mvNetaPmtMhRegSet(p, i, a, b);
+	}
+	else if (!strcmp(name, "eth_reg")) {
+		memset(&pmt_e, 0, sizeof(struct mv_neta_pmt_t));
+        err = mvNetaPmtEthTypeRegSet(p, i, a, b);
+	}
+	else 
+		printk("%s: illegal operation <%s>\n", __FUNCTION__, attr->attr.name);
+
+	local_irq_restore(flags);
+
+	if (err) 
+		printk("%s: <%s>, error %d\n", __FUNCTION__, attr->attr.name, err);
+	
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(mh_reg,  S_IWUSR, pmt_show, pmt_store);
+static DEVICE_ATTR(eth_reg, S_IWUSR, pmt_show, pmt_store);
+static DEVICE_ATTR(hw_write,S_IWUSR, pmt_show, pmt_store);
+static DEVICE_ATTR(hw_read, S_IWUSR, pmt_show, pmt_store);
+static DEVICE_ATTR(hw_dump, S_IWUSR, pmt_show, pmt_store);
+static DEVICE_ATTR(hw_regs, S_IWUSR, pmt_show, pmt_store);
+static DEVICE_ATTR(hw_init, S_IWUSR, pmt_show, pmt_store);
+static DEVICE_ATTR(hw_inv,  S_IWUSR, pmt_show, pmt_store);
+static DEVICE_ATTR(help,    S_IRUSR, pmt_show, pmt_store);
+
+static struct attribute *pmt_attrs[] = {
+	&dev_attr_mh_reg.attr,
+	&dev_attr_eth_reg.attr,
+	&dev_attr_hw_write.attr,
+	&dev_attr_hw_read.attr,
+	&dev_attr_hw_dump.attr,
+	&dev_attr_hw_regs.attr,
+	&dev_attr_hw_init.attr,
+	&dev_attr_hw_inv.attr,
+	&dev_attr_help.attr,
+	NULL
+};
+
+static struct attribute_group pmt_group = {
+	.name = "pmt",
+	.attrs = pmt_attrs,
+};
+
+int __devinit pmt_sysfs_init(void)
+{
+		int err;
+		struct device *pd;
+
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+		if (!pd) {
+			platform_device_register_simple("neta", -1, NULL, 0);
+			pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+		}
+
+		if (!pd) {
+			printk(KERN_ERR"%s: cannot find neta device\n", __FUNCTION__);
+			pd = &platform_bus;
+		}
+
+		err = sysfs_create_group(&pd->kobj, &pmt_group);
+		if (err) {
+			printk(KERN_INFO "sysfs group failed %d\n", err);
+			goto out;
+		}
+out:
+		return err;
+}
+
+module_init(pmt_sysfs_init); 
+
+MODULE_AUTHOR("Kostya Belezko");
+MODULE_DESCRIPTION("PMT for Marvell NetA MV65xxx");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/pnc/pnc_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/pnc/pnc_sysfs.c
new file mode 100644
index 0000000..efef7be
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/pnc/pnc_sysfs.c
@@ -0,0 +1,363 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+
+#include "mvOs.h"
+#include "mvCommon.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+
+#include "gbe/mvNeta.h"
+
+#include "pnc/mvPnc.h"
+#include "pnc/mvTcam.h"
+
+static struct tcam_entry te;
+
+static ssize_t tcam_help(char *buf)
+{
+	int off = 0;
+
+	off += mvOsSPrintf(buf+off, "cat <file>\n");
+	off += mvOsSPrintf(buf+off, " sw_dump - dump sw entry\n");
+	off += mvOsSPrintf(buf+off, " hw_dump - dump valid entries\n");
+	off += mvOsSPrintf(buf+off, " hw_regs - dump registers\n");
+	off += mvOsSPrintf(buf+off, " hw_hits - decode hit sequences\n");
+#ifdef MV_ETH_PNC_AGING
+	off += mvOsSPrintf(buf+off, " age_dump        - dump non-zero aging counters\n");
+	off += mvOsSPrintf(buf+off, " age_dump_all    - dump all aging counters\n");
+	off += mvOsSPrintf(buf+off, " age_scan        - dump aging Scanner log\n");
+	off += mvOsSPrintf(buf+off, " age_reset       - reset all aging counters\n");
+#endif /* MV_ETH_PNC_AGING */
+
+	off += mvOsSPrintf(buf+off, "echo a > <file>\n");
+	off += mvOsSPrintf(buf+off, " hw_write   - write sw entry into tcam entry <a>\n");
+	off += mvOsSPrintf(buf+off, " hw_read    - read tcam entry <a> into sw entry\n");
+	off += mvOsSPrintf(buf+off, " hw_inv     -  disable tcam entry <a>\n");
+	off += mvOsSPrintf(buf+off, " hw_inv_all -  disable all tcam entries\n");
+	off += mvOsSPrintf(buf+off, " hw_hits    -  start recording for port <a>\n");
+
+	off += mvOsSPrintf(buf+off, " s_rinfo    -  set result info bit <a>\n");
+
+#ifdef MV_ETH_PNC_AGING
+	off += mvOsSPrintf(buf+off, " age_clear  - clear aging counter for tcam entry <a>\n");
+	off += mvOsSPrintf(buf+off, " age_cntr   - show aging counter for tcam entry <a>\n");
+#endif /* MV_ETH_PNC_AGING */
+
+	off += mvOsSPrintf(buf+off, "echo a b > <file>\n");
+	off += mvOsSPrintf(buf+off, " t_offset_byte   - on offset <a> match value <b>\n");
+	off += mvOsSPrintf(buf+off, " t_offset_mask   - on offset <a> use mask <b>\n");
+	off += mvOsSPrintf(buf+off, " t_port          - match port value <a> with mask <b>\n");
+	off += mvOsSPrintf(buf+off, " t_ainfo         - match ainfo value <a> with mask <b>\n");
+	off += mvOsSPrintf(buf+off, " s_shift_update  - fill sram shift index <a> with value <b>\n");
+	off += mvOsSPrintf(buf+off, " s_ainfo         - set ainfo value <a> with mask <b>\n");
+	off += mvOsSPrintf(buf+off, " s_flowid        - fill sram flowid nibbles <b> from value <a>\n");
+	off += mvOsSPrintf(buf+off, " s_flowid_part   - fill sram flowid part <b> with value <a>\n");
+
+#ifdef MV_ETH_PNC_NEW
+	off += mvOsSPrintf(buf+off, " s_rinfo_extra   - set 2 bits value <a> to extra result info offset <b>\n");
+#endif
+
+#ifdef MV_ETH_PNC_AGING
+	off += mvOsSPrintf(buf+off, " age_gr_set      - set group <b> of aging counter for tcam entry <a>\n");
+#endif /* MV_ETH_PNC_AGING */
+
+	return off;
+}
+
+static ssize_t tcam_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char   *name = attr->attr.name;
+	unsigned int v, m;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "t_port")) {
+		tcam_sw_get_port(&te, &v, &m);
+		return mvOsSPrintf(buf, "value:0x%x mask:0x%x\n", v, m);
+	}
+	else if (!strcmp(name, "t_lookup")) {
+		tcam_sw_get_lookup(&te, &v, &m);
+		return mvOsSPrintf(buf, "value:0x%x mask:0x%x\n", v, m);
+	}
+	else if (!strcmp(name, "sw_dump"))
+		return tcam_sw_dump(&te, buf);
+	else if (!strcmp(name, "hw_dump"))
+		return tcam_hw_dump(0);
+	else if (!strcmp(name, "hw_dump_all"))
+		return tcam_hw_dump(1);
+	else if (!strcmp(name, "hw_regs"))
+		mvNetaPncRegs();
+	else if (!strcmp(name, "hw_hits"))
+		return tcam_hw_hits(buf);
+#ifdef MV_ETH_PNC_AGING
+	else if (!strcmp(name, "age_dump"))
+		mvPncAgingDump(0);
+	else if (!strcmp(name, "age_dump_all"))
+		mvPncAgingDump(1);
+	else if (!strcmp(name, "age_scan"))
+		mvPncAgingScannerDump();
+	else if (!strcmp(name, "age_reset"))
+		mvPncAgingReset();
+#endif /* MV_ETH_PNC_AGING */
+	else if (!strcmp(name, "help"))
+		return tcam_help(buf);
+
+	return 0;
+}
+static ssize_t tcam_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  err = 0, a = 0, b = 0;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%x %x", &a, &b);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "hw_write"))
+		tcam_hw_write(&te, a);
+	else if (!strcmp(name, "hw_read"))
+		tcam_hw_read(&te, a);
+	else if (!strcmp(name, "hw_debug"))
+		tcam_hw_debug(a);
+	else if (!strcmp(name, "hw_inv"))
+		tcam_hw_inv(a);
+	else if (!strcmp(name, "hw_inv_all"))
+		tcam_hw_inv_all();
+	else if (!strcmp(name, "hw_hits"))
+		tcam_hw_record(a);
+#ifdef MV_ETH_PNC_AGING
+	else if (!strcmp(name, "age_clear"))
+		mvPncAgingCntrClear(a);
+	else if (!strcmp(name, "age_cntr")) {
+		b = mvPncAgingCntrRead(a);
+		printk(KERN_INFO "tid=%d: age_cntr = 0x%08x\n", a, b);
+	}
+#endif /* MV_ETH_PNC_AGING */
+	else if (!strcmp(name, "sw_clear"))
+		tcam_sw_clear(&te);
+	else if (!strcmp(name, "sw_text")) {
+		/* Remove last byte (new line) from the buffer */
+		int  len = strlen(buf);
+		char *temp = mvOsMalloc(len + 1);
+
+		strncpy(temp, buf, len-1);
+		temp[len-1] = 0;
+		tcam_sw_text(&te, temp);
+		mvOsFree(temp);
+	}
+	else if (!strcmp(name, "t_port"))
+		tcam_sw_set_port(&te, a, b);
+	else if (!strcmp(name, "t_lookup"))
+		tcam_sw_set_lookup(&te, a);
+	else if (!strcmp(name, "t_ainfo_0"))
+		tcam_sw_set_ainfo(&te, 0<<a, 1<<a);
+	else if (!strcmp(name, "t_ainfo_1"))
+		tcam_sw_set_ainfo(&te, 1<<a, 1<<a);
+	else if (!strcmp(name, "t_ainfo"))
+		tcam_sw_set_ainfo(&te, a, b);
+	else if (!strcmp(name, "t_offset_byte"))
+		tcam_sw_set_byte(&te, a, b);
+	else if (!strcmp(name, "t_offset_mask"))
+		tcam_sw_set_mask(&te, a, b);
+	else if (!strcmp(name, "s_lookup"))
+		sram_sw_set_next_lookup(&te, a);
+	else if (!strcmp(name, "s_ainfo"))
+		sram_sw_set_ainfo(&te, a, b);
+	else if (!strcmp(name, "s_lookup_done"))
+		sram_sw_set_lookup_done(&te, a);
+	else if (!strcmp(name, "s_next_lookup_shift"))
+		sram_sw_set_next_lookup_shift(&te, a);
+	else if (!strcmp(name, "s_rxq"))
+		sram_sw_set_rxq(&te, a, b);
+	else if (!strcmp(name, "s_shift_update"))
+		sram_sw_set_shift_update(&te, a, b);
+	else if (!strcmp(name, "s_rinfo"))
+		sram_sw_set_rinfo(&te, 1 << a);
+#ifdef MV_ETH_PNC_NEW
+	else if (!strcmp(name, "s_rinfo_extra"))
+		sram_sw_set_rinfo_extra(&te, a << (b & ~1));
+#endif /* MV_ETH_PNC_NEW */
+	else if (!strcmp(name, "s_flowid"))
+		sram_sw_set_flowid(&te, a, b);
+	else if (!strcmp(name, "s_flowid_part"))
+		sram_sw_set_flowid_partial(&te, a, b);
+#ifdef MV_ETH_PNC_AGING
+	else if (!strcmp(name, "age_gr_set"))
+		mvPncAgingCntrGroupSet(a, b);
+#endif /* MV_ETH_PNC_AGING */
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+#ifdef MV_ETH_PNC_AGING
+static DEVICE_ATTR(age_dump,     S_IRUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(age_dump_all, S_IRUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(age_scan,     S_IRUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(age_reset,    S_IRUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(age_clear,    S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(age_cntr,     S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(age_gr_set,   S_IWUSR, tcam_show, tcam_store);
+#endif /* MV_ETH_PNC_AGING */
+
+#ifdef MV_ETH_PNC_NEW
+static DEVICE_ATTR(s_rinfo_extra, S_IWUSR, tcam_show, tcam_store);
+#endif
+
+static DEVICE_ATTR(hw_write,    S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(hw_read,     S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(hw_debug,    S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(hw_inv,      S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(hw_inv_all,  S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(hw_dump,     S_IRUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(hw_dump_all, S_IRUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(hw_regs,     S_IRUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(hw_hits,     S_IRUSR | S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(sw_dump,     S_IRUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(sw_clear,    S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(sw_text,     S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(t_port,      S_IRUSR | S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(t_lookup,    S_IRUSR | S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(t_ainfo_0,   S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(t_ainfo_1,   S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(t_ainfo,     S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(t_offset_byte, S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(t_offset_mask, S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(s_lookup,    S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(s_ainfo,     S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(s_lookup_done, S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(s_next_lookup_shift, S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(s_rxq,       S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(s_shift_update, S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(s_rinfo,     S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(s_flowid, 	S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(s_flowid_part, S_IWUSR, tcam_show, tcam_store);
+static DEVICE_ATTR(help,        S_IRUSR, tcam_show, tcam_store);
+
+static struct attribute *pnc_attrs[] = {
+#ifdef MV_ETH_PNC_AGING
+    &dev_attr_age_dump.attr,
+    &dev_attr_age_dump_all.attr,
+    &dev_attr_age_scan.attr,
+    &dev_attr_age_reset.attr,
+    &dev_attr_age_clear.attr,
+    &dev_attr_age_cntr.attr,
+    &dev_attr_age_gr_set.attr,
+#endif /* MV_ETH_PNC_AGING */
+
+#ifdef MV_ETH_PNC_NEW
+    &dev_attr_s_rinfo_extra.attr,
+#endif
+
+    &dev_attr_hw_write.attr,
+    &dev_attr_hw_read.attr,
+    &dev_attr_hw_debug.attr,
+    &dev_attr_hw_inv.attr,
+    &dev_attr_hw_inv_all.attr,
+    &dev_attr_hw_dump.attr,
+    &dev_attr_hw_dump_all.attr,
+    &dev_attr_hw_regs.attr,
+    &dev_attr_hw_hits.attr,
+    &dev_attr_sw_dump.attr,
+    &dev_attr_sw_clear.attr,
+    &dev_attr_sw_text.attr,
+    &dev_attr_t_port.attr,
+    &dev_attr_t_lookup.attr,
+    &dev_attr_t_ainfo_0.attr,
+    &dev_attr_t_ainfo.attr,
+    &dev_attr_t_ainfo_1.attr,
+    &dev_attr_t_offset_byte.attr,
+    &dev_attr_t_offset_mask.attr,
+    &dev_attr_s_lookup.attr,
+    &dev_attr_s_ainfo.attr,
+    &dev_attr_s_lookup_done.attr,
+    &dev_attr_s_next_lookup_shift.attr,
+    &dev_attr_s_rxq.attr,
+    &dev_attr_s_shift_update.attr,
+    &dev_attr_s_rinfo.attr,
+    &dev_attr_s_flowid.attr,
+    &dev_attr_s_flowid_part.attr,
+    &dev_attr_help.attr,
+    NULL
+};
+
+static struct attribute_group pnc_group = {
+	.name = "pnc",
+	.attrs = pnc_attrs,
+};
+
+int __devinit pnc_sysfs_init(void)
+{
+	int err;
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+	if (!pd) {
+		platform_device_register_simple("neta", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+	}
+
+	if (!pd) {
+		printk(KERN_ERR "%s: cannot find neta device\n", __func__);
+		pd = &platform_bus;
+	}
+
+	err = sysfs_create_group(&pd->kobj, &pnc_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+out:
+	return err;
+}
+
+module_init(pnc_sysfs_init);
+
+MODULE_AUTHOR("Kostya Belezko");
+MODULE_DESCRIPTION("PNC for Marvell NetA MV65xxx");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/pnc/wol_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/pnc/wol_sysfs.c
new file mode 100644
index 0000000..cb153df
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/pnc/wol_sysfs.c
@@ -0,0 +1,201 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+
+#include "mvOs.h"
+#include "mvCommon.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+
+#include "gbe/mvNeta.h"
+#include "pnc/mvPnc.h"
+
+#include "net_dev/mv_netdev.h"
+
+static char	wol_data[MV_PNC_TOTAL_DATA_SIZE];
+static int  wol_data_size = 0;
+static char	wol_mask[MV_PNC_TOTAL_DATA_SIZE];
+static int  wol_mask_size = 0;
+
+extern void mv_eth_wol_wakeup(int port);
+extern int mv_eth_wol_sleep(int port);
+
+static ssize_t wol_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "cat                  dump_all      - dump all wol rules\n");
+	off += sprintf(buf+off, "echo idx           > dump          - dump rule <idx>\n");
+	off += sprintf(buf+off, "echo port          > sleep         - enter WoL mode on <port>\n");
+	off += sprintf(buf+off, "echo port          > wakeup        - exit WoL mode on <port>\n");
+	off += sprintf(buf+off, "echo str           > data          - set data string\n");
+	off += sprintf(buf+off, "echo str           > mask          - set mask string\n");
+	off += sprintf(buf+off, "echo port          > add           - add new rule with <data> and <mask> on <port>\n");
+	off += sprintf(buf+off, "echo idx           > del           - delete existing WoL rule <idx>\n");
+	off += sprintf(buf+off, "echo port          > del_all       - delete all WoL rules added to <port>\n");
+
+	return off;
+}
+
+static ssize_t wol_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char   *name = attr->attr.name;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "dump_all"))
+		mv_pnc_wol_dump();
+	else if (!strcmp(name, "help"))
+		return wol_help(buf);
+
+	return 0;
+}
+
+static ssize_t wol_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  p, size, err = 0;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%d", &p);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "sleep"))
+		mv_eth_wol_sleep(p);
+	else if (!strcmp(name, "wakeup"))
+		mv_eth_wol_wakeup(p);
+	else if (!strcmp(name, "dump")) {
+		if (mv_pnc_wol_rule_dump(p))
+			printk(KERN_INFO "WoL rule #%d doesn't exist\n", p);
+	} else if (!strcmp(name, "data")) {
+		memset(wol_data, 0, sizeof(wol_data));
+		size = strlen(buf) / 2;
+		if (size > sizeof(wol_data))
+			size = sizeof(wol_data);
+		mvHexToBin(buf, wol_data, size);
+		wol_data_size = size;
+	} else if (!strcmp(name, "mask")) {
+		memset(wol_mask, 0, sizeof(wol_mask));
+		size = strlen(buf) / 2;
+		if (size > sizeof(wol_mask))
+			size = sizeof(wol_mask);
+		mvHexToBin(buf, wol_mask, size);
+		wol_mask_size = size;
+	} else if (!strcmp(name, "add")) {
+		int idx;
+		idx = mv_pnc_wol_rule_set(p, wol_data, wol_mask, MV_MIN(wol_data_size, wol_mask_size));
+		if (idx < 0)
+			err = 1;
+	} else if (!strcmp(name, "del")) {
+		err = mv_pnc_wol_rule_del(p);
+	} else if (!strcmp(name, "del_all")) {
+		err = mv_pnc_wol_rule_del_all(p);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,        S_IRUSR, wol_show, wol_store);
+static DEVICE_ATTR(dump_all,    S_IRUSR, wol_show, wol_store);
+static DEVICE_ATTR(dump,        S_IWUSR, wol_show, wol_store);
+static DEVICE_ATTR(data,        S_IWUSR, wol_show, wol_store);
+static DEVICE_ATTR(mask,        S_IWUSR, wol_show, wol_store);
+static DEVICE_ATTR(add,         S_IWUSR, wol_show, wol_store);
+static DEVICE_ATTR(del,         S_IWUSR, wol_show, wol_store);
+static DEVICE_ATTR(del_all,     S_IWUSR, wol_show, wol_store);
+static DEVICE_ATTR(sleep,       S_IWUSR, wol_show, wol_store);
+static DEVICE_ATTR(wakeup,      S_IWUSR, wol_show, wol_store);
+
+static struct attribute *wol_attrs[] = {
+    &dev_attr_help.attr,
+    &dev_attr_dump_all.attr,
+    &dev_attr_dump.attr,
+    &dev_attr_data.attr,
+    &dev_attr_mask.attr,
+    &dev_attr_add.attr,
+    &dev_attr_del.attr,
+    &dev_attr_del_all.attr,
+    &dev_attr_sleep.attr,
+    &dev_attr_wakeup.attr,
+    NULL
+};
+
+static struct attribute_group wol_group = {
+	.name = "wol",
+	.attrs = wol_attrs,
+};
+
+int __devinit wol_sysfs_init(void)
+{
+	int err;
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+	if (!pd) {
+		platform_device_register_simple("neta", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+	}
+
+	if (!pd) {
+		printk(KERN_ERR "%s: cannot find neta device\n", __func__);
+		pd = &platform_bus;
+	}
+
+	err = sysfs_create_group(&pd->kobj, &wol_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+out:
+	return err;
+}
+
+module_init(wol_sysfs_init);
+
+MODULE_AUTHOR("Dmitri Epshtein");
+MODULE_DESCRIPTION("WoL for Marvell NetA");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/Kconfig
new file mode 100644
index 0000000..102412b
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/Kconfig
@@ -0,0 +1,320 @@
+config MV_ETH_PORTS_NUM
+	int "Number of Marvell Giga Ethernet controllers"
+	depends on MV_ETH_LEGACY
+	default 1 
+
+menu "Network Interface Configuration"
+
+config  OVERRIDE_ETH_CMDLINE
+	bool "Override command line definitions for SoC Networking"
+	default n
+	---help---
+	Choosing this option will override MAC address and MTU definition of kernel command line.
+	The GbE driver will use the setting from kernel config
+
+config  MV_ETH_0_MTU
+	int "Giga port #0 MTU value"
+	depends on (MV_ETH_PORTS_NUM != 0)
+ 	default 1500
+        ---help---
+	Default MTU value for Marvell Giga port #0
+
+config  MV_ETH_0_MACADDR
+        string "Giga port #0 MAC Address"
+        depends on (MV_ETH_PORTS_NUM != 0)
+        default "00:00:00:00:00:80"
+        ---help---
+        Default MAC address for Marvell Giga port #0 
+
+config  MV_ETH_1_MTU
+        int "Giga port #1 MTU value"
+        depends on (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1)
+        default 1500
+        ---help---
+	Default MTU value for Marvell Giga port #1
+
+config  MV_ETH_1_MACADDR
+        string "Giga port #1 MAC Address"
+        depends on (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1)
+        default "00:00:00:00:00:81"
+        ---help---
+        Default MAC address for Marvell Giga port #1
+
+config  MV_ETH_2_MTU
+        int "Giga port #2 MTU value"
+        depends on (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1) && (MV_ETH_PORTS_NUM != 2)
+        default 1500
+        ---help---
+        Default MTU value for Marvell Giga port #2
+
+config  MV_ETH_2_MACADDR
+        string "Giga port #2 MAC Address"
+        depends on (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1) && (MV_ETH_PORTS_NUM != 2)
+        default "00:00:00:00:00:82"
+        ---help---
+        Default MAC address for Marvell Giga port #2
+
+config  MV_ETH_3_MTU
+        int "Giga port #3 MTU value"
+        depends on (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1) && (MV_ETH_PORTS_NUM != 2) && (MV_ETH_PORTS_NUM != 3)
+        default 1500
+        ---help---
+        Default MTU value for Marvell Giga port #3
+
+config  MV_ETH_3_MACADDR
+        string "Giga port #3 MAC Address"
+        depends on (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1) && (MV_ETH_PORTS_NUM != 2) && (MV_ETH_PORTS_NUM != 3)
+        default "00:00:00:00:00:83"
+        ---help---
+        Default MAC address for Marvell Giga port #3
+
+endmenu
+
+menu "Rx/Tx Queue Configuration"
+
+config  MV_ETH_RXQ
+        int "Number of RX queues"
+        default 1
+        ---help---
+          Multiple RX queue support.
+
+config  MV_ETH_TXQ
+        int "Number of TX queues"
+        default 1
+        ---help---
+          Multiple TX queue support.
+
+config MV_ETH_NUM_OF_RX_DESCR
+	int "Number of Rx descriptors"
+	depends on (MV_ETH_PORTS_NUM != 0)
+	default 128
+        ---help---
+	The number of Rx descriptors in each Rx queue.
+
+config MV_ETH_NUM_OF_TX_DESCR
+	int "Number of Tx descriptors"
+	depends on (MV_ETH_PORTS_NUM != 0)
+	default 532
+        ---help---
+	The number of Tx descriptors in each Tx queue.
+
+endmenu
+
+menu "TCP/UDP Offloading"
+
+config  MV_ETH_TSO
+        bool "TSO Support for Marvell network interface"
+	default y
+        ---help---
+        Adds TSO support for TCP segmentation offload on Marvell network interface.
+
+config  MV_ETH_UFO
+        bool "UFO Support for Marvell network interface"
+        ---help---
+        Adds UFO support for transmit UDP buffers larger than MTU size on 
+        Marvell network interface.
+        UFO stands for UDP Fragmentation Offload
+endmenu
+
+menu "Control and Statistics"
+
+config  MV_ETH_TOOL
+	bool "Support ethtool controls"
+	default y
+	---help---
+	Support kernel's SIOCETHTOOL for ethtool utility
+
+config  MV_ETH_PROC
+	bool "Support eth proc FS "
+	default y
+	---help---
+	  Use mv_eth_tool to control Marvell network interface driver.
+
+config  MV_ETH_STATS_ERROR
+        bool "Collect error statistics"
+	---help---
+	Marvell network interface driver collect minimal number of statistics. 
+	Only for error conditions. Can be displayed using mv_eth_tool.
+
+config  MV_ETH_STATS_INFO
+        bool "Collect event statistics"
+        ---help---
+	Marvell network interface driver collect event statistics. 
+	Provide more information about driver functionality and almost doesn't 
+	effect performance. Can be displayed using mv_eth_tool.
+
+config  MV_ETH_STATS_DEBUG
+        bool "Collect debug statistics"
+        ---help---
+	Marvell network interface driver collect a lot of statistics. 
+	Used for Debug mode. Decrease performance. Can be displayed using mv_eth_tool.
+
+config  MV_LINUX_COUNTERS_DISABLE
+	bool "Disable collection of SNMP statistics and Netfilter Contract statistics"
+	default n
+	---help---
+	Disable collection of SNMP statistics and Netfilter Contract statistics to improve performance.
+
+endmenu
+
+menu "Advanced Features"
+
+config  MV_ETH_TIMER_PERIOD
+        int "Periodical timer period"
+        default 10
+        ---help---
+          Periodical timer period for clenup in [msec].
+
+config	MV_ETH_SKB_REUSE
+	bool "Try to reuse SKB"
+	default y
+	---help---
+	  Reuse SKB from TX to RX
+
+config MV_ETH_SKB_REUSE_DEF
+        depends on MV_ETH_SKB_REUSE
+        int "Default value for SKB reuse:  0 - disable, 1 - enable"
+        default 0
+        ---help---
+
+config  NET_SKB_HEADROOM
+        int "SKB headroom size"
+        default 64
+        ---help---
+          Customize SKB headroom size. Must be power of 2.
+
+config  NET_SKB_RECYCLE
+        bool "Try to recycle SKB"
+        default y
+        ---help---
+          Recycle SKB via callback in 'struct sk_buff'
+
+config NET_SKB_RECYCLE_DEF
+        depends on NET_SKB_RECYCLE
+        int "Default value for SKB recycle:  0 - disable, 1 - enable"
+        default 0
+        ---help---
+
+config  MV_ETH_NFP
+        bool "Use Network Fast Processing (NFP)"
+	default y
+        ---help---
+        Choosing this option will include NFP support in the image.
+
+config MV_ETH_NFP_DEF
+        depends on MV_ETH_NFP
+        int "Default value for NFP:  0 - disable, 1 - enable"
+        default 0
+        ---help---
+
+config MV_ETH_NFP_AGING_TIMER
+        int "NFP aging timer interval"
+        depends on MV_ETH_NFP
+        default 15
+        ---help---
+        The NFP aging mechanism timer interval. If unsure, leave default value.
+
+config  MV_ETH_NFP_TOS
+        bool "Support ToS on NFP routing path"
+	depends on MV_ETH_NFP && IP_NF_TARGET_TOS
+        ---help---
+        Choosing this option will include NFP ToS support in the image.
+
+config MV_ETH_NFP_FIB
+        bool "Support NFP routing"
+        default y
+        depends on MV_ETH_NFP
+        ---help---
+        Choosing this option will enable NFP routing support.
+
+config MV_ETH_NFP_NAT
+        bool "Support NFP NAT"
+        depends on MV_ETH_NFP_FIB && (NF_CONNTRACK_ENABLED || NF_CONNTRACK_IPV4)
+        ---help---
+        Choosing this option will enable NFP NAT support.
+
+config MV_ETH_NFP_FDB
+	bool "Support NFP Bridging"
+	depends on MV_ETH_NFP && BRIDGE
+	default n
+	 ---help---
+	Choosing this option will enable NFP Bridging.
+
+config MV_ETH_NFP_PPP
+        bool "Support NFP PPPoE"
+        depends on MV_ETH_NFP && PPPOE
+        default n
+         ---help---
+        Choosing this option will enable NFP PPPoE protocol.
+
+config MV_ETH_NFP_SEC
+	bool "Support NFP Ipsec"
+        depends on MV_ETH_NFP && !MV_CESA_OCF && !MV_CESA_TEST
+        default n
+         ---help---
+        Choosing this option will enable NFP IPsec protocol.
+
+config	MV_NFP_SEC_5TUPLE_KEY_SUPPORT 
+	bool "Support 5 tuple key search match"
+        depends on MV_ETH_NFP_SEC
+        default y
+         ---help---
+        Choosing this option will enable 5 tuple key search match support.
+
+config MV_ETH_NFP_SEC_HUB
+	bool "Support hub and spoke vpn"
+	depends on MV_ETH_NFP_SEC
+	default n
+	---help---
+	Choosing this option will enable hub-and-spoke vpn with NFP.
+
+config  MV_NFP_STATS
+        bool "Collect NFP statistics"
+	depends on MV_ETH_NFP
+        default n
+        ---help---
+        Collect NFP statistics. Can be displayed using mv_eth_tool.
+
+endmenu
+
+config MV_GATEWAY
+        bool "Gateway support"
+	depends on MV_ETH_LEGACY
+        ---help---
+	Choose this option to support Gigabit Ethernet Controller connected to 
+        on-board QuarterDeck switch family
+
+if MV_GATEWAY
+
+menu "Gateway Interface Configuration"
+
+config  MV_GTW_CONFIG
+	string "Network interface configuration"
+	default "(00:11:66:11:66:11,0)(00:22:77:22:77:22,1:2:3:4),mtu=1500"
+	---help---
+	 Set the network interface configuration. For each interface, define the interface 
+	 name, MAC address and participating ports, at the end (optionally) set the 
+         interfaces MTU. For example, the default configuration defines two interfaces, 
+         eth0 and eth1, and sets the MTU to 1500.
+
+endmenu
+
+menu "Gateway Features"
+
+config  MV_GTW_IGMP
+        bool "L2 IGMP Snooping support"
+        default y
+        ---help---
+          Support L2 IGMP snooping at the switch level, i.e. directing L3 routed multicast
+          stream to the specific L2 port which originally received an IGMP Join message,
+          instead of fluding all VLAN ports.
+
+config  MV_GTW_LINK_STATUS
+	bool "Link status change indications"
+	default y
+	---help---
+	  Support Phy link status change indications.
+
+endmenu
+
+endif # MV_GATEWAY
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/Makefile
new file mode 100644
index 0000000..bb198d5
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/Makefile
@@ -0,0 +1,17 @@
+#
+# Makefile for the Marvell Gigabit Ethernet driver
+#
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+obj-$(CONFIG_MV_ETHERNET) += mv_netdev.o mv_ethernet.o
+obj-$(CONFIG_MV_ETH_PROC) += mv_eth_proc.o
+obj-$(CONFIG_MV_GATEWAY) +=  mv_gateway.o
+obj-$(CONFIG_MV_GTW_IGMP) += mv_gtw_igmp.o
+obj-$(CONFIG_MV_ETH_TOOL) += mv_eth_tool.o
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_proc.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_proc.c
new file mode 100644
index 0000000..5838b50
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_proc.c
@@ -0,0 +1,571 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+#include <linux/stddef.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/reboot.h>
+#include <linux/pci.h>
+#include <linux/kdev_t.h>
+#include <linux/major.h>
+#include <linux/console.h>
+#include <linux/delay.h>
+#include <linux/ide.h>
+#include <linux/seq_file.h>
+
+#include <asm/system.h>
+#include <asm/dma.h>
+#include <asm/io.h>
+
+#include <linux/netdevice.h>
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "eth/gbe/mvEthGbe.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "mv_eth_proc.h"
+
+#ifdef CONFIG_MV_ETH_NFP
+#include "../nfp_mgr/mv_nfp_mgr.h"
+#endif
+
+#include "mv_netdev.h"
+
+//#define MV_DEBUG
+#ifdef MV_DEBUG
+#define DP printk
+#else
+#define DP(fmt,args...)
+#endif
+
+
+/* global variables from 'regdump' */
+static struct proc_dir_entry *mv_eth_tool;
+
+static unsigned int port = 0, q = 0, weight = 0, status = 0, mac[6] = {0,};
+static unsigned int policy =0, command = 0, packet = 0;
+static unsigned int value = 0;
+
+#ifdef CONFIG_MV_ETH_NFP
+static unsigned int  dip, sip, inport, outport;
+static unsigned int  da[6] = {0,}, sa[6] = {0,};
+static unsigned int  db_type;
+#endif /* CONFIG_MV_ETH_NFP */
+
+void run_com_srq(void) 
+{
+    void* port_hndl = mvEthPortHndlGet(port);
+
+    if(port_hndl == NULL)
+        return;
+
+    if(q >= MV_ETH_RX_Q_NUM)
+	    q = -1;
+
+    switch(packet) {
+	case PT_BPDU:
+		mvEthBpduRxQueue(port_hndl, q);
+		break;
+	case PT_ARP:
+		mvEthArpRxQueue(port_hndl, q);
+		break;
+	case PT_TCP:
+		mvEthTcpRxQueue(port_hndl, q);
+		break;
+	case PT_UDP:
+		mvEthUdpRxQueue(port_hndl, q);
+		break;
+	default:
+		printk("eth proc unknown packet type.\n");	
+    }
+	
+}
+
+extern void    		ethMcastAdd(int port, char* macStr, int queue);
+void run_com_sq(void) {
+
+    char mac_addr[20];
+
+    if(q >= MV_ETH_RX_Q_NUM)
+	    q = -1;
+    
+    sprintf(mac_addr, "%02x:%02x:%02x:%02x:%02x:%02x",mac[0],mac[1],mac[2],mac[3],mac[4],mac[5]);
+    ethMcastAdd(port, mac_addr, q);
+}
+
+extern void    	ethPortStatus (int port);
+extern void    	ethPortQueues( int port, int rxQueue, int txQueue, int mode);
+extern void    	ethPortMcast(int port);
+extern void    	ethPortUcastShow(int port);
+extern void    	ethPortRegs(int port);
+extern void     ethTxPolicyRegs(int port);
+extern void    	ethPortCounters(int port);
+extern void 	ethPortRmonCounters(int port);
+
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+extern void    eth_remote_port_status_print(int port, int mode);
+#endif
+
+void run_com_stats(void) {
+	printk("\n\n#########################################################################################\n\n");
+	switch(status) {
+		case STS_PORT:
+			printk("  PORT %d: GET ETH STATUS\n\n",port);
+            mv_eth_status_print(port);
+			ethPortStatus(port);
+			break;
+
+        case STS_PORT_MAC:
+            ethPortUcastShow(port);
+			ethPortMcast(port);
+            break;
+
+		case STS_PORT_Q:
+			printk("  PORT %d: GET ETH STATUS ON Q %d\n\n",port,q);
+			ethPortQueues(port, q, q, 1);
+			break;
+
+#if (MV_ETH_RX_Q_NUM > 1)
+		case STS_PORT_RXP:
+			printk("  PORT %d: GET ETH RX POLICY STATUS\n\n",port);
+			printk("Not supported\n");
+			break;
+#endif /* MV_ETH_RX_Q_NUM > 1 */
+
+		case STS_PORT_TOS_MAP:
+			mv_eth_tos_map_show(port);
+			break;
+
+		case STS_PORT_TXP:
+			printk("  PORT %d: GET ETH TX POLICY STATUS\n\n",port);
+			ethTxPolicyRegs(port);
+			break;
+
+		case STS_PORT_REGS:
+			printk("  PORT %d: GET ETH PORT REGS STATUS\n\n",port);
+			ethPortRegs(port);
+			break;
+
+		case STS_PORT_MIB:
+			ethPortCounters(port);
+			ethPortRmonCounters(port);	
+			break;
+
+		case STS_PORT_STATS:
+			printk("  PORT %d: GET ETH STATISTIC STATUS\n\n",port);
+			mv_eth_stats_print(port);
+			break;
+
+        case STS_NETDEV:
+			mv_eth_netdev_print(port);
+            break;
+
+#ifdef CONFIG_MV_ETH_NFP
+		case STS_PORT_NFP_STATS:
+			printk("  PORT %d: NFP statistics\n\n",port);
+			mv_eth_nfp_stats_print(port);
+			break;
+#endif /* CONFIG_MV_ETH_NFP */
+
+#ifdef CONFIG_MV_GATEWAY
+        case STS_SWITCH_STATS:
+            mv_gtw_switch_stats(port);
+            break;
+#endif /* CONFIG_MV_GATEWAY */
+
+		default:
+			printk(" Unknown status command \n");
+	}
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+    eth_remote_port_status_print(port, status);
+#endif
+}
+
+int run_eth_com(const char *buffer) {
+
+    int scan_count;
+    scan_count = sscanf(buffer, ETH_CMD_STRING, ETH_SCANF_LIST);
+    if( scan_count != ETH_LIST_LEN) {
+	printk("eth command bad format %x != %x\n", scan_count, ETH_LIST_LEN );
+	return 1;
+    }
+    switch(command) {
+
+        case COM_TXDONE_Q:
+            mv_eth_tx_done_quota = value;
+            break;
+
+#ifdef CONFIG_MV_ETH_SKB_REUSE
+        case COM_SKB_REUSE:
+            eth_skb_reuse_enable = value;
+            break;
+#endif /* CONFIG_MV_ETH_SKB_REUSE */
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+        case COM_SKB_RECYCLE:
+            eth_skb_recycle_enable = value;
+	    break;
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+#ifdef CONFIG_MV_ETH_NFP
+        case COM_NFP:
+	    if (value) 
+	    {
+		printk("Enabling NFP\n");
+		fp_mgr_enable();
+	    }
+	    else
+	    {
+		printk("Disabling NFP\n");
+		fp_mgr_disable();
+	    }
+            break;
+#endif /* CONFIG_MV_ETH_NFP */
+
+	default:
+            printk(" Unknown ETH command \n");
+    }
+    return 0;
+}
+
+/* Giga Queue commands */
+int run_port_queue_cmd(const char *buffer) {
+
+        int scan_count;
+
+        scan_count = sscanf(buffer, QUEUE_CMD_STRING, QUEUE_SCANF_LIST);
+
+        if( scan_count != QUEUE_LIST_LEN) {
+                printk("eth port/queue command bad format %x != %x\n", scan_count, QUEUE_LIST_LEN );
+                return 1;
+        }
+
+        switch(command) {
+		case COM_TOS_MAP:
+			mv_eth_tos_map_set(port, value, q);
+			break;
+	
+		default:
+			printk(" Unknown port/queue command \n");
+	}
+	return 0;
+}
+
+/* Giga Port commands */
+int run_port_com(const char *buffer) {
+
+	int scan_count;
+    void*   port_hndl;
+
+	scan_count = sscanf(buffer, PORT_CMD_STRING, PORT_SCANF_LIST);
+    
+	if( scan_count != PORT_LIST_LEN) {
+		printk("eth port command bad format %x != %x\n", scan_count, PORT_LIST_LEN );
+		return 1;
+	}
+    if( (port < 0) || (port > mvCtrlEthMaxPortGet()) )
+        return 1;
+
+    port_hndl = mvEthPortHndlGet(port);
+    if(port_hndl == NULL)
+        return 1;
+
+    	switch(command) {
+        	case COM_RX_COAL:
+            	mvEthRxCoalSet(mvEthPortHndlGet(port), value);
+            	break;
+
+        	case COM_TX_COAL:
+            	mvEthTxCoalSet(mvEthPortHndlGet(port), value);
+        	break;
+
+#ifdef ETH_MV_TX_EN
+            case COM_TX_EN:
+                if(value > CONFIG_MV_ETH_NUM_OF_RX_DESCR)
+            {
+                    printk("Eth TX_EN command bad param: value=%d\n", value);
+                return 1;
+            }
+
+                eth_tx_en_config(port, value);
+            break;
+#endif /* ETH_MV_TX_EN */
+
+#if (MV_ETH_VERSION >= 4)
+        	case COM_EJP_MODE:
+            		mvEthEjpModeSet(mvEthPortHndlGet(port), value);
+            	break;
+#endif /* (MV_ETH_VERSION >= 4) */
+			case COM_LRO:
+				mv_eth_set_lro(port, value);
+				break;
+			case COM_LRO_DESC:
+				mv_eth_set_lro_desc(port, value);
+				break;
+
+			case COM_TX_NOQUEUE:
+				mv_eth_set_noqueue(port, value);
+			break;
+
+  		default:
+			printk(" Unknown port command \n");
+    	}
+   	return 0;
+}
+
+#ifdef CONFIG_MV_ETH_NFP
+int run_ip_rule_set_com(const char *buffer)
+{
+    int scan_count, i;
+    MV_FP_RULE  ip_rule;
+    MV_STATUS   status = MV_OK;
+
+    scan_count = sscanf(buffer, IP_RULE_STRING, IP_RULE_SCANF_LIST);
+
+    if( scan_count != IP_RULE_LIST_LEN) {
+	printk("eth proc bad format %x != %x\n", scan_count, IP_RULE_LIST_LEN);
+	return 1;
+    }
+    memset(&ip_rule, 0, sizeof(ip_rule));
+    
+    printk("run_ip_rule_set_com: dip=%08x, sip=%08x, inport=%d, outport=%d\n", 
+            dip, sip, inport, outport);
+
+    ip_rule.routingInfo.dstIp = MV_32BIT_BE(dip);
+    ip_rule.routingInfo.srcIp = MV_32BIT_BE(sip);
+    ip_rule.routingInfo.defGtwIp = MV_32BIT_BE(dip);
+    ip_rule.routingInfo.inIfIndex = inport;
+    ip_rule.routingInfo.outIfIndex = outport;
+    ip_rule.routingInfo.aware_flags = 0;
+
+    for(i=0; i<MV_MAC_ADDR_SIZE; i++)
+    {
+        ip_rule.routingInfo.dstMac[i] = (MV_U8)(da[i] & 0xFF);
+        ip_rule.routingInfo.srcMac[i] = (MV_U8)(sa[i] & 0xFF);;
+    }
+    ip_rule.mgmtInfo.actionType = MV_FP_ROUTE_CMD;
+    ip_rule.mgmtInfo.ruleType = MV_FP_STATIC_RULE;
+
+    status = fp_rule_set(&ip_rule);
+    if(status != MV_OK)
+    {
+        printk("fp_rule_set FAILED: status=%d\n", status);
+    }
+    return status;
+}
+
+int run_ip_rule_del_com(const char *buffer)
+{
+    int scan_count;
+    MV_STATUS status = MV_OK;
+
+    scan_count = sscanf(buffer, IP_RULE_DEL_STRING, IP_RULE_DEL_SCANF_LIST);
+
+    if( scan_count != IP_RULE_DEL_LIST_LEN) {
+	printk("eth proc bad format %x != %x\n", scan_count, IP_RULE_DEL_LIST_LEN);
+	return 1;
+    }
+
+    status = fp_rule_delete(MV_32BIT_BE(sip), MV_32BIT_BE(dip), MV_FP_STATIC_RULE);
+    if(status != MV_OK)
+    {
+        printk("fp_rule_delete FAILED: status=%d\n", status);
+    }
+    return status;
+}
+
+int run_fp_db_print_com(const char *buffer)
+{
+    int scan_count;
+    MV_STATUS status = MV_OK;
+
+    scan_count = sscanf(buffer, NFP_DB_PRINT_STRING, NFP_DB_PRINT_SCANF_LIST);
+
+    if( scan_count != NFP_DB_PRINT_LIST_LEN) {
+	    printk("eth proc bad format %x != %x\n", scan_count, NFP_DB_PRINT_LIST_LEN);
+	    return 1;
+    }
+
+    if (db_type == DB_ROUTING)
+	    status = fp_rule_db_print(MV_FP_DATABASE); 
+#ifdef CONFIG_MV_ETH_NFP_NAT 
+    else if (db_type == DB_NAT)
+	    status = fp_nat_db_print(MV_FP_DATABASE);
+#endif /* CONFIG_MV_ETH_NFP_NA */
+#ifdef CONFIG_MV_ETH_NFP_FDB
+    else if (db_type == DB_FDB)
+            status = fp_fdb_db_print(MV_FP_DATABASE);
+#endif /* CONFIG_MV_ETH_NFP_FDB */
+#ifdef CONFIG_MV_ETH_NFP_PPP
+    else if (db_type == DB_PPP)
+            status = fp_ppp_db_print(MV_FP_DATABASE);
+#endif /* CONFIG_MV_ETH_NFP_PPP */
+#ifdef CONFIG_MV_ETH_NFP_SEC
+    else if (db_type == DB_SEC)
+            status = fp_sec_db_print(MV_FP_DATABASE);
+#endif /* CONFIG_MV_ETH_NFP_SEC */
+    else {
+	    printk("Failed to print rule database: unknown DB type\n");
+	    return 1;
+    }
+    return status;
+}
+#endif /* CONFIG_MV_ETH_NFP */
+
+int run_com_general(const char *buffer) {
+
+	int scan_count;
+
+	scan_count = sscanf(buffer, PROC_STRING, PROC_SCANF_LIST);
+
+	if( scan_count != LIST_LEN) {
+		printk("eth proc bad format %x != %x\n", scan_count, LIST_LEN );
+		return 1;
+	}
+
+	switch(command){
+		case COM_SRQ:
+			DP(" Port %x: Got SRQ command Q %x and packet type is %x <bpdu/arp/tcp/udp> \n",port,q,packet);
+			run_com_srq();
+			break;
+		case COM_SQ:
+			DP(" Port %x: Got SQ command Q %x mac %2x:%2x:%2x:%2x:%2x:%2x\n",port, q, 
+				mac[0],  mac[1],  mac[2],  mac[3],  mac[4],  mac[5]);
+			run_com_sq();
+			break;
+
+#if (MV_ETH_RX_Q_NUM > 1)
+		case COM_SRP:
+			DP(" Port %x: Got SRP command Q %x policy %x <Fixed/WRR> \n",port,q,policy); 
+            printk("Not supported\n");
+			break;
+		case COM_SRQW:
+			DP(" Port %x: Got SQRW command Q %x weight %x \n",port,q,weight);
+			printk("Not supported\n");
+			break;
+		case COM_STP:
+			DP("STP cmd - Unsupported: Port %x Q %x policy %x <WRR/FIXED> weight %x\n",port,q,policy,weight); 
+			break;
+#endif /* MV_ETH_RX_Q_NUM > 1 */
+
+		case COM_STS:
+			DP("  Port %x: Got STS command status %x\n",port,status);
+			run_com_stats();
+			break;
+		default:
+			printk("eth proc unknown command.\n");
+	}
+  	return 0;
+}
+
+int mv_eth_tool_write (struct file *file, const char *buffer,
+                      unsigned long count, void *data) {
+
+	sscanf(buffer,"%x",&command);
+
+	switch (command) {
+		case COM_RX_COAL:
+		case COM_TX_COAL:
+        	case COM_TX_EN:
+        	case COM_EJP_MODE:
+		case COM_TX_NOQUEUE:
+		case COM_LRO:
+		case COM_LRO_DESC:
+			run_port_com(buffer);
+			break;
+		case COM_TXDONE_Q:
+        	case COM_SKB_REUSE:
+                case COM_SKB_RECYCLE:
+		case COM_NFP:
+			run_eth_com(buffer);
+			break;
+
+		case COM_TOS_MAP:
+            run_port_queue_cmd(buffer);
+			break;
+
+#ifdef CONFIG_MV_ETH_NFP
+		case COM_IP_RULE_SET:
+			run_ip_rule_set_com(buffer);
+			break;
+		case COM_IP_RULE_DEL:
+			run_ip_rule_del_com(buffer);
+			break;
+		case COM_NFP_STATUS:
+			fp_mgr_status();
+			break;
+		case COM_NFP_PRINT:
+			run_fp_db_print_com(buffer);
+			break;
+#endif /* CONFIG_MV_ETH_NFP */
+
+		default:
+			run_com_general(buffer);
+			break;
+	}
+	return count;
+}
+
+static int proc_calc_metrics(char *page, char **start, off_t off,
+                                 int count, int *eof, int len)
+{
+        if (len <= off+count) *eof = 1;
+        *start = page + off;
+        len -= off;
+        if (len>count) len = count;
+        if (len<0) len = 0;
+        return len;
+}
+
+
+
+int mv_eth_tool_read (char *page, char **start, off_t off,
+                            int count, int *eof, void *data) {
+	unsigned int len = 0;
+
+	//len  = sprintf(page, "\n");
+	//len += sprintf(page+len, "\n");
+	
+   	return proc_calc_metrics(page, start, off, count, eof, len);
+}
+
+
+
+int __init start_mv_eth_tool(void)
+{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+  mv_eth_tool = proc_net_create(FILE_NAME , 0666 , NULL);
+#else
+  mv_eth_tool = create_proc_entry(FILE_NAME , 0666 , init_net.proc_net);
+#endif
+  mv_eth_tool->read_proc = mv_eth_tool_read;
+  mv_eth_tool->write_proc = mv_eth_tool_write;
+  mv_eth_tool->nlink = 1;
+  return 0;
+}
+
+module_init(start_mv_eth_tool);
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_proc.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_proc.h
new file mode 100644
index 0000000..cdeaf07
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_proc.h
@@ -0,0 +1,138 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_eth_proc
+#define __mv_eth_proc
+
+#define FILE_NAME	"mv_eth_tool"
+#define FILE_PATH	"/proc/net/"
+#define STS_FILE	"mvethtool.sts"
+
+#define IP_RULE_STRING	    "%2x %2x %2x %4x %4x %2x:%2x:%2x:%2x:%2x:%2x %2x:%2x:%2x:%2x:%2x:%2x"
+#define IP_RULE_PRINT_LIST	 command, inport, outport, dip, sip, da[0], da[1], da[2], da[3], da[4], da[5], sa[0], sa[1], sa[2], sa[3], sa[4], sa[5]
+#define IP_RULE_SCANF_LIST	&command, &inport, &outport, &dip, &sip, &da[0], &da[1], &da[2], &da[3], &da[4], &da[5], &sa[0], &sa[1], &sa[2], &sa[3], &sa[4], &sa[5]
+#define IP_RULE_LIST_LEN	17
+
+#define IP_RULE_DEL_STRING	"%2x %4x %4x"
+#define IP_RULE_DEL_PRINT_LIST	command, dip, sip
+#define IP_RULE_DEL_SCANF_LIST	&command, &dip, &sip
+#define IP_RULE_DEL_LIST_LEN	3
+
+#define NFP_DB_PRINT_STRING	"%2x %2x"
+#define NFP_DB_PRINT_PRINT_LIST	command, db_type
+#define NFP_DB_PRINT_SCANF_LIST	&command, &db_type
+#define NFP_DB_PRINT_LIST_LEN	2
+
+#define PROC_STRING	"%2x %2x %2x %2x %2x %2x %2x:%2x:%2x:%2x:%2x:%2x %x"
+#define PROC_PRINT_LIST	 command,  port,  q,  policy,  packet,  status,  mac[0],  mac[1],  mac[2],  mac[3],  mac[4],  mac[5],  weight
+#define PROC_SCANF_LIST	&command, &port, &q, &policy, &packet, &status, &mac[0], &mac[1], &mac[2], &mac[3], &mac[4], &mac[5], &weight
+#define LIST_LEN	13
+
+#define PORT_CMD_STRING     "%2x %2x %x"
+#define PORT_PRINTF_LIST    command, port, value
+#define PORT_SCANF_LIST     &command, &port, &value
+#define PORT_LIST_LEN       3
+
+#define QUEUE_CMD_STRING     "%2x %2x %2x %x"
+#define QUEUE_PRINTF_LIST    command, port, q, value
+#define QUEUE_SCANF_LIST     &command, &port, &q, &value
+#define QUEUE_LIST_LEN       4
+
+
+#define ETH_CMD_STRING     "%2x %x"
+#define ETH_PRINTF_LIST    command, value
+#define ETH_SCANF_LIST     &command, &value
+#define ETH_LIST_LEN       2
+
+#define CMD_STRING         "%2x"
+#define CMD_SCANF_LIST     &command
+#define CMD_PRINT_LIST     command
+#define CMD_LIST_LEN       1
+
+typedef enum {
+	COM_SRQ = 0,
+	COM_SQ,
+	COM_SRP,
+	COM_SRQW,
+	COM_STP,
+	COM_STS,
+	COM_HEAD,
+	COM_RX_COAL,
+	COM_TX_COAL,
+	COM_TXDONE_Q,
+ 	COM_IP_RULE_SET,
+	COM_IP_RULE_DEL, 
+	COM_NFP, 
+	COM_NFP_STATUS,
+	COM_NFP_PRINT,
+    	COM_TX_EN,
+    	COM_SKB_REUSE,
+    	COM_SKB_RECYCLE,
+    	COM_EJP_MODE,
+    	COM_TOS_MAP,
+	COM_TX_NOQUEUE,
+	COM_LRO,
+	COM_LRO_DESC,
+} command_t;
+
+typedef enum { 	/**/
+	WRR = 0,
+	FIXED
+} policy_t;
+
+typedef enum {
+	PT_BPDU = 0,
+	PT_ARP,
+	PT_TCP,
+	PT_UDP
+} packet_t;
+
+typedef enum {
+	STS_PORT = 0,
+	STS_PORT_Q,
+	STS_PORT_RXP,
+	STS_PORT_TXP,
+	STS_PORT_REGS,
+	STS_PORT_MIB,
+	STS_PORT_STATS,
+    	STS_PORT_MAC,
+   	STS_PORT_NFP_STATS,
+    	STS_PORT_TOS_MAP,
+    	STS_NETDEV,
+    	STS_SWITCH_STATS,
+} status_t;
+
+typedef enum {
+	DB_ROUTING = 0, 
+	DB_NAT,
+	DB_FDB,
+	DB_PPP,
+	DB_SEC,
+} db_type_t;
+
+#endif
+	
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_tool.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_tool.c
new file mode 100644
index 0000000..11b072c
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_tool.c
@@ -0,0 +1,1061 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+
+#include "mvCommon.h"  /* Should be included before mvSysHwConfig */
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/pci.h>
+#include <linux/ip.h>
+#include <linux/in.h>
+#include <linux/tcp.h>
+#include <linux/string.h>
+#include <net/ip.h>
+#include <net/xfrm.h>
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+#include <asm/arch/system.h>
+#else
+#include <mach/system.h>
+#endif
+
+#include "mvOs.h"
+#include "dbg-trace.h"
+#include "mvSysHwConfig.h"
+#include "eth/mvEth.h"
+#include "eth-phy/mvEthPhy.h"
+#include "mvSysEthApi.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+
+#include "mv_netdev.h"
+#include "mv_eth_tool.h"
+
+extern spinlock_t          mii_lock;
+
+const struct ethtool_ops mv_eth_tool_ops = {
+	.get_settings		= mv_eth_tool_get_settings,
+	.set_settings		= mv_eth_tool_set_settings,
+	.get_drvinfo		= mv_eth_tool_get_drvinfo,
+	.get_regs_len		= mv_eth_tool_get_regs_len,
+	.get_regs		= mv_eth_tool_get_regs,
+	.nway_reset		= mv_eth_tool_nway_reset,
+	.get_link		= mv_eth_tool_get_link,
+	.get_coalesce		= mv_eth_tool_get_coalesce,
+	.set_coalesce		= mv_eth_tool_set_coalesce,
+	.get_ringparam          = mv_eth_tool_get_ringparam,
+	.get_pauseparam		= mv_eth_tool_get_pauseparam,
+	.set_pauseparam		= mv_eth_tool_set_pauseparam,
+	.get_rx_csum		= mv_eth_tool_get_rx_csum,
+	.set_rx_csum		= mv_eth_tool_set_rx_csum,
+	.get_tx_csum		= ethtool_op_get_tx_csum,
+	.set_tx_csum		= mv_eth_tool_set_tx_csum,
+	.get_sg			= ethtool_op_get_sg,
+	.set_sg			= ethtool_op_set_sg,
+	.get_tso		= ethtool_op_get_tso,
+	.set_tso		= mv_eth_tool_set_tso,
+	.get_ufo		= ethtool_op_get_ufo,
+	.set_ufo		= mv_eth_tool_set_ufo,
+	.get_strings		= mv_eth_tool_get_strings,
+	.phys_id		= mv_eth_tool_phys_id,
+	.get_stats_count	= mv_eth_tool_get_stats_count,
+	.get_ethtool_stats	= mv_eth_tool_get_ethtool_stats,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+	.get_perm_addr		= ethtool_op_get_perm_addr,
+#endif
+};
+
+struct mv_eth_tool_stats {
+	char stat_string[ETH_GSTRING_LEN];
+	int stat_offset;
+};
+
+#define MV_ETH_TOOL_STAT(m)	offsetof(mv_eth_priv, m)
+
+static const struct mv_eth_tool_stats mv_eth_tool_global_strings_stats[] = {
+	{"skb_alloc_fail", MV_ETH_TOOL_STAT(eth_stat.skb_alloc_fail)},
+	{"tx_timeout", MV_ETH_TOOL_STAT(eth_stat.tx_timeout)},
+	{"tx_netif_stop", MV_ETH_TOOL_STAT(eth_stat.tx_netif_stop)},
+	{"tx_done_netif_wake", MV_ETH_TOOL_STAT(eth_stat.tx_done_netif_wake)},
+	{"tx_skb_no_headroom", MV_ETH_TOOL_STAT(eth_stat.tx_skb_no_headroom)},
+#ifdef CONFIG_MV_ETH_STATS_INFO
+	{"irq_total", MV_ETH_TOOL_STAT(eth_stat.irq_total)},
+	{"irq_none_events", MV_ETH_TOOL_STAT(eth_stat.irq_none)},
+	{"irq_while_polling", MV_ETH_TOOL_STAT(eth_stat.irq_while_polling)},
+	{"picr is", MV_ETH_TOOL_STAT(picr)},
+	{"picer is", MV_ETH_TOOL_STAT(picer)},
+	{"poll_events", MV_ETH_TOOL_STAT(eth_stat.poll_events)},
+	{"poll_complete", MV_ETH_TOOL_STAT(eth_stat.poll_complete)},
+	{"tx_events", MV_ETH_TOOL_STAT(eth_stat.tx_events)},
+	{"tx_done_events", MV_ETH_TOOL_STAT(eth_stat.tx_done_events)},
+	{"timer_events", MV_ETH_TOOL_STAT(eth_stat.timer_events)},
+#if defined(CONFIG_MV_ETH_NFP) || defined(CONFIG_MV_SKB_REUSE)
+	{"rx_pool_empty", MV_ETH_TOOL_STAT(eth_stat.rx_pool_empty)},
+#endif /* CONFIG_MV_ETH_NFP || CONFIG_MV_SKB_REUSE */
+#endif /* CONFIG_MV_ETH_STATS_INFO */
+
+#ifdef CONFIG_MV_ETH_STATS_DEBUG
+	{"skb_alloc_ok", MV_ETH_TOOL_STAT(eth_stat.skb_alloc_ok)},
+	{"skb_free_ok", MV_ETH_TOOL_STAT(eth_stat.skb_free_ok)},
+#ifdef CONFIG_MV_SKB_REUSE
+	{"skb_reuse_rx", MV_ETH_TOOL_STAT(eth_stat.skb_reuse_rx)},
+	{"skb_reuse_tx", MV_ETH_TOOL_STAT(eth_stat.skb_reuse_tx)},
+	{"skb_reuse_alloc", MV_ETH_TOOL_STAT(eth_stat.skb_reuse_alloc)},
+#endif /* CONFIG_MV_SKB_REUSE */
+	{"tx_csum_hw", MV_ETH_TOOL_STAT(eth_stat.tx_csum_hw)},
+	{"tx_csum_sw", MV_ETH_TOOL_STAT(eth_stat.tx_csum_sw)},
+	{"rx_netif_drop", MV_ETH_TOOL_STAT(eth_stat.rx_netif_drop)},
+	{"rx_csum_hw", MV_ETH_TOOL_STAT(eth_stat.rx_csum_hw)},
+	{"rx_csum_hw_frags", MV_ETH_TOOL_STAT(eth_stat.rx_csum_hw_frags)},
+	{"rx_csum_sw", MV_ETH_TOOL_STAT(eth_stat.rx_csum_sw)},
+#ifdef ETH_INCLUDE_LRO
+	{"rx_lro_aggregated", MV_ETH_TOOL_STAT(lro_mgr.stats.aggregated)},
+	{"rx_lro_flushed", MV_ETH_TOOL_STAT(lro_mgr.stats.flushed)},
+	{"rx_lro_defragmented", MV_ETH_TOOL_STAT(lro_mgr.stats.defragmented)},
+	{"rx_lro_no_resources", MV_ETH_TOOL_STAT(lro_mgr.stats.no_desc)},
+#endif /* ETH_INCLUDE_LRO */
+#ifdef ETH_MV_TX_EN
+	{"tx_en_done", MV_ETH_TOOL_STAT(eth_stat.tx_en_done)},
+	{"tx_en_busy", MV_ETH_TOOL_STAT(eth_stat.tx_en_busy)},
+	{"tx_en_wait", MV_ETH_TOOL_STAT(eth_stat.tx_en_wait)},
+	{"tx_en_wait_count", MV_ETH_TOOL_STAT(eth_stat.tx_en_wait_count)},
+#endif /* ETH_MV_TX_EN */
+#endif /* CONFIG_MV_ETH_STATS_DEBUG */
+};
+
+static const struct mv_eth_tool_stats mv_eth_tool_rx_queue_strings_stats[] = {
+#ifdef CONFIG_MV_ETH_STATS_DEBUG
+	{"rx_hal_ok", MV_ETH_TOOL_STAT(eth_stat.rx_hal_ok)},
+	{"rx_fill_ok", MV_ETH_TOOL_STAT(eth_stat.rx_fill_ok)},
+#endif /* CONFIG_MV_ETH_STATS_DEBUG */
+};
+
+static const struct mv_eth_tool_stats mv_eth_tool_tx_queue_strings_stats[] = {
+#ifdef CONFIG_MV_ETH_STATS_DEBUG
+	{"tx_count", MV_ETH_TOOL_STAT(tx_count)},
+	{"tx_hal_ok", MV_ETH_TOOL_STAT(eth_stat.tx_hal_ok)},
+	{"tx_hal_no_resource", MV_ETH_TOOL_STAT(eth_stat.tx_hal_no_resource)},
+	{"tx_done_hal_ok", MV_ETH_TOOL_STAT(eth_stat.tx_done_hal_ok)},
+#endif /* CONFIG_MV_ETH_STATS_DEBUG */
+};
+
+#define MV_ETH_TOOL_RX_QUEUE_STATS_LEN  \
+	sizeof(mv_eth_tool_rx_queue_strings_stats) / sizeof(struct mv_eth_tool_stats)
+	
+#define MV_ETH_TOOL_TX_QUEUE_STATS_LEN  \
+	sizeof(mv_eth_tool_tx_queue_strings_stats) / sizeof(struct mv_eth_tool_stats)
+	
+#define MV_ETH_TOOL_QUEUE_STATS_LEN 	\
+	((MV_ETH_TOOL_RX_QUEUE_STATS_LEN * MV_ETH_RX_Q_NUM) + \
+	(MV_ETH_TOOL_TX_QUEUE_STATS_LEN * MV_ETH_TX_Q_NUM))
+
+#define MV_ETH_TOOL_GLOBAL_STATS_LEN	\
+	sizeof(mv_eth_tool_global_strings_stats) / sizeof(struct mv_eth_tool_stats)
+	
+#define MV_ETH_TOOL_STATS_LEN 		\
+	(MV_ETH_TOOL_GLOBAL_STATS_LEN + MV_ETH_TOOL_QUEUE_STATS_LEN)
+
+/******************************************************************************
+* mv_eth_tool_read_mdio
+* Description:
+*	MDIO read implementation for kernel core MII calls
+* INPUT:
+*	netdev		Network device structure pointer
+*	addr		PHY address
+*	reg		PHY register number (offset)
+* OUTPUT
+*	Register value or -1 on error
+*
+*******************************************************************************/
+int mv_eth_tool_read_mdio(struct net_device *netdev, int addr, int reg)
+{
+	unsigned long 	flags;
+	unsigned short 	value;
+	MV_STATUS 	status;
+	
+	spin_lock_irqsave(&mii_lock, flags);
+	status = mvEthPhyRegRead(addr, reg, &value);
+	spin_unlock_irqrestore(&mii_lock, flags);
+
+	if (status == MV_OK)
+		return value;
+
+	return -1;
+}
+
+/******************************************************************************
+* mv_eth_tool_write_mdio
+* Description:
+*	MDIO write implementation for kernel core MII calls
+* INPUT:
+*	netdev		Network device structure pointer
+*	addr		PHY address
+*	reg		PHY register number (offset)
+*	data		Data to be written into PHY register
+* OUTPUT
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_write_mdio(struct net_device *netdev, int addr, int reg, int data)
+{
+	unsigned long   flags;
+	unsigned short  tmp   = (unsigned short)data;
+
+	spin_lock_irqsave(&mii_lock, flags);
+	mvEthPhyRegWrite(addr, reg, tmp);
+	spin_unlock_irqrestore(&mii_lock, flags);
+}
+
+
+/******************************************************************************
+* mv_eth_tool_read_phy_reg
+* Description:
+*	Marvell PHY register read (includes page number)
+* INPUT:
+*	phy_addr	PHY address
+*	page		PHY register page (region)
+*	reg		PHY register number (offset)
+* OUTPUT
+*	val		PHY register value
+* RETURN:
+*	0 for success
+*
+*******************************************************************************/
+#define MV_ETH_TOOL_PHY_PAGE_ADDR_REG	22
+int mv_eth_tool_read_phy_reg(int phy_addr, u16 page, u16 reg, u16 *val)
+{
+	unsigned long 	flags;
+	MV_STATUS 	status = 0;
+	
+	spin_lock_irqsave(&mii_lock, flags);
+	/* setup register address page first */
+	if (!mvEthPhyRegWrite(phy_addr, MV_ETH_TOOL_PHY_PAGE_ADDR_REG, page)) {
+		status = mvEthPhyRegRead(phy_addr, reg, val);
+	}
+	spin_unlock_irqrestore(&mii_lock, flags);
+
+	return status;
+}
+
+/******************************************************************************
+* mv_eth_tool_write_phy_reg
+* Description:
+*	Marvell PHY register write (includes page number)
+* INPUT:
+*	phy_addr	PHY address
+*	page		PHY register page (region)
+*	reg		PHY register number (offset)
+*	data		Data to be written into PHY register
+* OUTPUT
+*	None
+* RETURN:
+*	0 for success
+*
+*******************************************************************************/
+int mv_eth_tool_write_phy_reg(int phy_addr, u16 page, u16 reg, u16 data)
+{
+	unsigned long   flags;
+	MV_STATUS 	status = 0;
+	
+	spin_lock_irqsave(&mii_lock, flags);
+	/* setup register address page first */
+	if (!mvEthPhyRegWrite(phy_addr, MV_ETH_TOOL_PHY_PAGE_ADDR_REG,
+						(unsigned int)page)) {
+		status = mvEthPhyRegWrite(phy_addr, reg, data);
+	}
+	spin_unlock_irqrestore(&mii_lock, flags);
+
+	return status;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_settings
+* Description:
+*	ethtool get standard port settings
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	cmd		command (settings)
+* RETURN:
+*	0 for success
+*
+*******************************************************************************/
+int mv_eth_tool_get_settings(struct net_device *netdev, struct ethtool_cmd *cmd)
+{
+	mv_eth_priv 		*priv = MV_ETH_PRIV(netdev);
+	struct mii_if_info 	mii;
+	int			retval;
+	MV_ETH_PORT_STATUS 	status;
+	
+#ifdef CONFIG_MII	
+	mii.dev			= netdev;
+	mii.phy_id_mask 	= 0x1F;
+	mii.reg_num_mask 	= 0x1F;
+	mii.mdio_read 		= mv_eth_tool_read_mdio;
+	mii.mdio_write 		= mv_eth_tool_write_mdio;
+	mii.phy_id 		= priv->phy_id;
+	mii.supports_gmii 	= 1;
+
+	/* Get values from PHY */
+	retval = mii_ethtool_gset(&mii, cmd);
+	if (retval)
+		return retval;
+#endif
+
+	/* Get some values from MAC */
+	mvEthStatusGet(priv->hal_priv, &status);
+	
+	switch (status.speed) {
+	case MV_ETH_SPEED_1000:
+		cmd->speed = SPEED_1000;
+		break;	
+	case MV_ETH_SPEED_100:
+		cmd->speed = SPEED_100;
+		break;
+	case MV_ETH_SPEED_10:
+		cmd->speed = SPEED_10;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	if (status.duplex == MV_ETH_DUPLEX_FULL) 
+		cmd->duplex = 1;
+	else
+		cmd->duplex = 0;
+
+	cmd->port = PORT_MII;
+	cmd->phy_address = priv->phy_id;
+
+	return 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_restore_settings
+* Description:
+*	restore saved speed/dublex/an settings
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	0 for success
+*
+*******************************************************************************/
+int mv_eth_tool_restore_settings(struct net_device *netdev)
+{
+	mv_eth_priv 		*priv = MV_ETH_PRIV(netdev);
+	int 			mv_phy_speed, mv_phy_duplex;
+	MV_U32			mv_phy_addr = priv->phy_id;
+	MV_ETH_PORT_SPEED	mv_mac_speed;
+	MV_ETH_PORT_DUPLEX	mv_mac_duplex;
+	int			err = -EINVAL;
+
+	switch (priv->speed_cfg) {
+		case SPEED_10:
+			mv_phy_speed  = 0;
+			mv_mac_speed = MV_ETH_SPEED_10;
+			break;
+		case SPEED_100:
+			mv_phy_speed  = 1;
+			mv_mac_speed = MV_ETH_SPEED_100;
+			break;
+		case SPEED_1000:
+			mv_phy_speed  = 2;
+			mv_mac_speed = MV_ETH_SPEED_1000;
+			break;
+		default:
+			return -EINVAL;
+	}
+
+	switch (priv->duplex_cfg) {
+		case DUPLEX_HALF:
+			mv_phy_duplex = 0;
+			mv_mac_duplex = MV_ETH_DUPLEX_HALF;
+			break;
+		case DUPLEX_FULL:
+			mv_phy_duplex = 1;
+			mv_mac_duplex = MV_ETH_DUPLEX_FULL;
+			break;
+		default:
+			return -EINVAL;
+	}
+	
+	if (priv->autoneg_cfg == AUTONEG_ENABLE) {
+		err = mvEthSpeedDuplexSet(priv->hal_priv,
+					  MV_ETH_SPEED_AN, MV_ETH_DUPLEX_AN);
+
+		/* Restart AN on PHY enables it */
+		if (!err) {
+
+			err = mvEthPhyRestartAN(mv_phy_addr, MV_ETH_TOOL_AN_TIMEOUT);
+			if (err == MV_TIMEOUT) {
+				MV_ETH_PORT_STATUS ps;
+				mvEthStatusGet(priv->hal_priv, &ps);
+				if (!ps.isLinkUp)
+					err = 0;
+			}
+		}
+	} else if (priv->autoneg_cfg == AUTONEG_DISABLE) {
+		err = mvEthPhyDisableAN(mv_phy_addr, mv_phy_speed, mv_phy_duplex);
+		if (!err) {
+			err = mvEthSpeedDuplexSet(priv->hal_priv,
+					mv_mac_speed, mv_mac_duplex);
+		}
+	} else {
+		err = -EINVAL;
+	}
+
+	return err;
+}
+
+/******************************************************************************
+* mv_eth_tool_set_settings
+* Description:
+*	ethtool set standard port settings
+* INPUT:
+*	netdev		Network device structure pointer
+*	cmd		command (settings)
+* OUTPUT
+*	None
+* RETURN:
+*	0 for success
+*
+*******************************************************************************/
+int mv_eth_tool_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	mv_eth_priv *priv = MV_ETH_PRIV(dev);
+	int _speed, _duplex, _autoneg, err;
+
+#ifdef CONFIG_MV_GATEWAY
+	if (priv->isGtw)
+		return -EPERM;
+#endif /* CONFIG_MV_GATEWAY */
+
+	_duplex = priv->duplex_cfg;
+	_speed = priv->speed_cfg;
+	_autoneg = priv->autoneg_cfg;
+
+	priv->duplex_cfg = cmd->duplex;
+	priv->speed_cfg = cmd->speed;
+	priv->autoneg_cfg = cmd->autoneg;
+
+	err = mv_eth_tool_restore_settings(dev);
+
+	if (err) {
+		priv->duplex_cfg = _duplex;
+		priv->speed_cfg = _speed;
+		priv->autoneg_cfg = _autoneg;
+	}
+	return err;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_drvinfo
+* Description:
+*	ethtool get driver information
+* INPUT:
+*	netdev		Network device structure pointer
+*	info		driver information
+* OUTPUT
+*	info		driver information
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_drvinfo(struct net_device *netdev,
+			     struct ethtool_drvinfo *info)
+{
+	strcpy(info->driver, "mv_eth");
+	strcpy(info->version, LSP_VERSION);
+	strcpy(info->fw_version, "N/A");
+	strcpy(info->bus_info, "Mbus");
+	info->n_stats = MV_ETH_TOOL_STATS_LEN;
+	info->testinfo_len = 0;
+	info->regdump_len = mv_eth_tool_get_regs_len(netdev);
+	info->eedump_len = 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_regs_len
+* Description:
+*	ethtool get registers array length
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	registers array length
+*
+*******************************************************************************/
+int mv_eth_tool_get_regs_len(struct net_device *netdev)
+{
+#define MV_ETH_TOOL_REGS_LEN 32
+	return MV_ETH_TOOL_REGS_LEN * sizeof(uint32_t);
+}
+
+/******************************************************************************
+* mv_eth_tool_get_regs
+* Description:
+*	ethtool get registers array
+* INPUT:
+*	netdev		Network device structure pointer
+*	regs		registers information
+* OUTPUT
+*	p		registers array
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_regs(struct net_device *netdev,
+			  struct ethtool_regs *regs, void *p)
+{
+	mv_eth_priv 	*priv = MV_ETH_PRIV(netdev);
+	uint32_t 	*regs_buff = p;
+
+	memset(p, 0, MV_ETH_TOOL_REGS_LEN * sizeof(uint32_t));
+
+	regs->version = mvCtrlModelRevGet(); 
+
+	/* ETH port registers */
+	regs_buff[0]  = MV_REG_READ(ETH_PORT_STATUS_REG(priv->port));
+	regs_buff[1]  = MV_REG_READ(ETH_PORT_SERIAL_CTRL_REG(priv->port));
+	regs_buff[2]  = MV_REG_READ(ETH_PORT_CONFIG_REG(priv->port));
+	regs_buff[3]  = MV_REG_READ(ETH_PORT_CONFIG_EXTEND_REG(priv->port));
+	regs_buff[4]  = MV_REG_READ(ETH_SDMA_CONFIG_REG(priv->port));
+	regs_buff[5]  = MV_REG_READ(ETH_TX_FIFO_URGENT_THRESH_REG(priv->port));
+	regs_buff[6]  = MV_REG_READ(ETH_RX_QUEUE_COMMAND_REG(priv->port));
+	regs_buff[7]  = MV_REG_READ(ETH_TX_QUEUE_COMMAND_REG(priv->port));
+	regs_buff[8]  = MV_REG_READ(ETH_INTR_CAUSE_REG(priv->port));
+	regs_buff[9]  = MV_REG_READ(ETH_INTR_CAUSE_EXT_REG(priv->port));
+	regs_buff[10] = MV_REG_READ(ETH_INTR_MASK_REG(priv->port));
+	regs_buff[11] = MV_REG_READ(ETH_INTR_MASK_EXT_REG(priv->port));
+	regs_buff[12] = MV_REG_READ(ETH_RX_DESCR_STAT_CMD_REG(priv->port, 0));
+	regs_buff[13] = MV_REG_READ(ETH_RX_BYTE_COUNT_REG(priv->port, 0));
+	regs_buff[14] = MV_REG_READ(ETH_RX_BUF_PTR_REG(priv->port, 0));
+	regs_buff[15] = MV_REG_READ(ETH_RX_CUR_DESC_PTR_REG(priv->port, 0));
+	/* ETH Unit registers */
+	regs_buff[16] = MV_REG_READ(ETH_PHY_ADDR_REG(priv->port));
+	regs_buff[17] = MV_REG_READ(ETH_UNIT_INTR_CAUSE_REG(priv->port));
+	regs_buff[18] = MV_REG_READ(ETH_UNIT_INTR_MASK_REG(priv->port));
+	regs_buff[19] = MV_REG_READ(ETH_UNIT_ERROR_ADDR_REG(priv->port));
+	regs_buff[20] = MV_REG_READ(ETH_UNIT_INT_ADDR_ERROR_REG(priv->port));
+	
+}
+
+/******************************************************************************
+* mv_eth_tool_nway_reset
+* Description:
+*	ethtool restart auto negotiation
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_nway_reset(struct net_device *netdev)
+{
+	mv_eth_priv 	*priv = MV_ETH_PRIV(netdev);
+	MV_U32		mv_phy_addr = (MV_U32)(priv->phy_id);
+
+	if (mvEthPhyRestartAN(mv_phy_addr, MV_ETH_TOOL_AN_TIMEOUT) != MV_OK)
+		return -EINVAL;
+
+	return 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_link
+* Description:
+*	ethtool get link status
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	0 if link is down, 1 if link is up
+*
+*******************************************************************************/
+u32 mv_eth_tool_get_link(struct net_device *netdev)
+{
+	mv_eth_priv 		*priv = MV_ETH_PRIV(netdev);
+	MV_ETH_PORT_STATUS	status;
+
+	mvEthStatusGet(priv->hal_priv, &status);
+	if (status.isLinkUp == MV_TRUE)
+		return 1;
+	
+	return 0;
+}
+
+
+/******************************************************************************
+* mv_eth_tool_get_coalesce
+* Description:
+*	ethtool get RX/TX coalesce parameters
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	cmd		Coalesce parameters
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_get_coalesce(struct net_device *netdev,
+			     struct ethtool_coalesce *cmd)
+{
+	mv_eth_priv 	*priv = MV_ETH_PRIV(netdev);
+
+	if (mvEthCoalGet(priv->hal_priv, &cmd->rx_coalesce_usecs,
+	    &cmd->tx_coalesce_usecs) != MV_OK)
+		return -EINVAL;
+	
+	return 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_set_coalesce
+* Description:
+*	ethtool set RX/TX coalesce parameters
+* INPUT:
+*	netdev		Network device structure pointer
+*	cmd		Coalesce parameters
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_coalesce(struct net_device *netdev,
+			     struct ethtool_coalesce *cmd)
+{
+	mv_eth_priv 	*priv = MV_ETH_PRIV(netdev);
+
+	if ((cmd->rx_coalesce_usecs == 0) ||
+		(cmd->tx_coalesce_usecs == 0)) {
+		/* coalesce usec=0 means that coalesce frames should be used,
+		 * which is not permitted (unsupported) */
+		return -EPERM;
+	}
+
+	if ((cmd->rx_coalesce_usecs * 166 / 64 > 0x3FFF) ||
+		(cmd->tx_coalesce_usecs * 166 / 64 > 0x3FFF))
+		return -EINVAL;
+	
+	/* Save values for mv_eth_start_internals() */
+	priv->rx_coal_usec = cmd->rx_coalesce_usecs;
+	priv->tx_coal_usec = cmd->tx_coalesce_usecs;
+	
+	mvEthRxCoalSet (priv->hal_priv, cmd->rx_coalesce_usecs);
+	mvEthTxCoalSet (priv->hal_priv, cmd->tx_coalesce_usecs);
+
+	return 0;
+}
+
+
+/******************************************************************************
+* mv_eth_tool_get_ringparam
+* Description:
+*	ethtool get ring parameters
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	ring		Ring paranmeters
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_ringparam( struct net_device *netdev,
+				struct ethtool_ringparam *ring)
+{
+	ring->rx_max_pending = 4096;
+	ring->tx_max_pending = 4096;
+	ring->rx_mini_max_pending = 0;
+	ring->rx_jumbo_max_pending = 0;
+	ring->rx_pending = CONFIG_MV_ETH_NUM_OF_RX_DESCR;
+	ring->tx_pending = CONFIG_MV_ETH_NUM_OF_TX_DESCR;
+	ring->rx_mini_pending = 0;
+	ring->rx_jumbo_pending = 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_pauseparam
+* Description:
+*	ethtool get pause parameters
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	pause		Pause paranmeters
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_pauseparam(struct net_device *netdev,
+				struct ethtool_pauseparam *pause)
+{
+	mv_eth_priv 		*priv = MV_ETH_PRIV(netdev);
+	ETH_PORT_CTRL		*pPortCtrl = (ETH_PORT_CTRL*)(priv->hal_priv);
+	MV_U32			reg;
+
+	reg = MV_REG_READ(ETH_PORT_SERIAL_CTRL_REG(pPortCtrl->portNo));
+	
+	pause->rx_pause = 0;
+	pause->tx_pause = 0;
+
+	if (reg & ETH_DISABLE_FC_AUTO_NEG_MASK) { /* autoneg disabled */
+		pause->autoneg = AUTONEG_DISABLE;
+		if (reg & ETH_SET_FLOW_CTRL_MASK)
+		{
+			pause->rx_pause = 1;
+			pause->tx_pause = 1;
+		}
+	} else { /* autoneg enabled */
+		pause->autoneg = AUTONEG_ENABLE;
+		if (reg & ETH_ADVERTISE_SYM_FC_MASK)
+		{
+			pause->rx_pause = 1;
+			pause->tx_pause = 1;
+		}
+	}
+}
+
+/******************************************************************************
+* mv_eth_tool_set_pauseparam
+* Description:
+*	ethtool configure pause parameters
+* INPUT:
+*	netdev		Network device structure pointer
+*	pause		Pause paranmeters
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_pauseparam( struct net_device *netdev,
+				struct ethtool_pauseparam *pause)
+{
+	mv_eth_priv 		*priv = MV_ETH_PRIV(netdev);
+	ETH_PORT_CTRL		*pPortCtrl = (ETH_PORT_CTRL*)(priv->hal_priv);
+	
+	if (pause->rx_pause && pause->tx_pause) { /* Enable FC */
+		if (pause->autoneg) { /* autoneg enable */
+			return mvEthFlowCtrlSet(priv->hal_priv, MV_ETH_FC_AN_ADV_SYM);
+		} else { /* autoneg disable */
+			return mvEthFlowCtrlSet(priv->hal_priv, MV_ETH_FC_ENABLE);
+		}
+	} else if (!pause->rx_pause && !pause->tx_pause) { /* Disable FC */
+		if (pause->autoneg) { /* autoneg enable */
+			return mvEthFlowCtrlSet(priv->hal_priv, MV_ETH_FC_AN_ADV_DIS);
+		} else { /* autoneg disable */
+			return mvEthFlowCtrlSet(priv->hal_priv, MV_ETH_FC_DISABLE);
+		}
+	}
+
+	/* Only symmetric change for RX and TX flow control is allowed */
+	return -EINVAL;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_rx_csum
+* Description:
+*	ethtool get RX checksum offloading status
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	RX checksum
+*
+*******************************************************************************/
+u32 mv_eth_tool_get_rx_csum(struct net_device *netdev)
+{
+	mv_eth_priv 	*priv = MV_ETH_PRIV(netdev);
+#ifdef RX_CSUM_OFFLOAD
+	return (priv->rx_csum_offload != 0);
+#else
+	return 0;
+#endif
+}
+
+/******************************************************************************
+* mv_eth_tool_set_rx_csum
+* Description:
+*	ethtool enable/disable RX checksum offloading
+* INPUT:
+*	netdev		Network device structure pointer
+*	data		Command data
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_rx_csum(struct net_device *netdev, uint32_t data)
+{
+	mv_eth_priv 	*priv = MV_ETH_PRIV(netdev);
+#ifdef RX_CSUM_OFFLOAD
+	priv->rx_csum_offload = data;
+	return 0;
+#else
+	return data ? -EINVAL : 0;
+#endif
+}
+
+/******************************************************************************
+* mv_eth_tool_set_tx_csum
+* Description:
+*	ethtool enable/disable TX checksum offloading
+* INPUT:
+*	netdev		Network device structure pointer
+*	data		Command data
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_tx_csum(struct net_device *netdev, uint32_t data)
+{
+#ifdef TX_CSUM_OFFLOAD
+	if (data) {
+		netdev->features |= NETIF_F_IP_CSUM;
+	} else {
+		netdev->features &= ~NETIF_F_IP_CSUM;
+	}
+	return 0;
+#else
+	return data ? -EINVAL : 0;
+#endif /* TX_CSUM_OFFLOAD */
+}
+
+/******************************************************************************
+* mv_eth_tool_set_tso
+* Description:
+*	ethtool enable/disable TCP segmentation offloading
+* INPUT:
+*	netdev		Network device structure pointer
+*	data		Command data
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_tso(struct net_device *netdev, uint32_t data)
+{
+#ifdef ETH_INCLUDE_TSO
+	if (data) {
+		netdev->features |= NETIF_F_TSO;
+	} else {
+		netdev->features &= ~NETIF_F_TSO;
+	}
+	return 0;
+#else
+	return data ? -EINVAL : 0;
+#endif /* ETH_INCLUDE_TSO */
+}
+
+/******************************************************************************
+* mv_eth_tool_set_ufo
+* Description:
+*	ethtool enable/disable UDP segmentation offloading
+* INPUT:
+*	netdev		Network device structure pointer
+*	data		Command data
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_ufo(struct net_device *netdev, uint32_t data)
+{
+#ifdef ETH_INCLUDE_UFO
+	if (data) {
+		netdev->features |= NETIF_F_UFO;
+	} else {
+		netdev->features &= ~NETIF_F_UFO;
+	}
+	return 0;
+#else
+	return data ? -EINVAL : 0;
+#endif /* ETH_INCLUDE_UFO */
+}
+
+/******************************************************************************
+* mv_eth_tool_get_strings
+* Description:
+*	ethtool get strings (used for statistics and self-test descriptions)
+* INPUT:
+*	netdev		Network device structure pointer
+*	stringset	strings parameters
+* OUTPUT
+*	data		output data
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_strings(struct net_device *netdev,
+			     uint32_t stringset, uint8_t *data)
+{
+	uint8_t *p = data;
+	int i, q;
+	char qnum[8][4] = {" Q0"," Q1"," Q2"," Q3"," Q4"," Q5"," Q6"," Q7"};
+
+	switch (stringset) {
+		case ETH_SS_TEST:
+			/*
+			memcpy(data, *mv_eth_tool_gstrings_test,
+			       MV_ETH_TOOL_TEST_LEN*ETH_GSTRING_LEN); */
+			break;
+		case ETH_SS_STATS:
+			for (i = 0; i < MV_ETH_TOOL_GLOBAL_STATS_LEN; i++) {
+				memcpy(p, mv_eth_tool_global_strings_stats[i].stat_string,
+				       ETH_GSTRING_LEN);
+				p += ETH_GSTRING_LEN;
+			}
+			for (q = 0; q < MV_ETH_RX_Q_NUM; q++) {
+				for (i = 0; i < MV_ETH_TOOL_RX_QUEUE_STATS_LEN; i++) {
+					const char *str = mv_eth_tool_rx_queue_strings_stats[i].stat_string;
+					memcpy(p, str, ETH_GSTRING_LEN);
+					strcat(p, qnum[q]);
+					p += ETH_GSTRING_LEN;
+				}
+			}
+			for (q = 0; q < MV_ETH_TX_Q_NUM; q++) {
+				for (i = 0; i < MV_ETH_TOOL_TX_QUEUE_STATS_LEN; i++) {
+					const char *str = mv_eth_tool_tx_queue_strings_stats[i].stat_string;
+					memcpy(p, str, ETH_GSTRING_LEN);
+					strcat(p, qnum[q]);
+					p += ETH_GSTRING_LEN;
+				}
+			}
+			break;
+	}
+}
+
+#define ETH_TOOL_PHY_LED_CTRL_PAGE	3
+#define ETH_TOOL_PHY_LED_CTRL_REG	16
+
+/******************************************************************************
+* mv_eth_tool_get_link
+* Description:
+*	ethtool physically identify port by LED blinking
+* INPUT:
+*	netdev		Network device structure pointer
+*	data		Number of secunds to blink the LED
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_phys_id(struct net_device *netdev, u32 data)
+{
+	mv_eth_priv 	*priv = MV_ETH_PRIV(netdev);
+	u16		old_led_state;
+
+	if(!data || data > (u32)(MAX_SCHEDULE_TIMEOUT / HZ))
+		data = (u32)(MAX_SCHEDULE_TIMEOUT / HZ);
+	
+	mv_eth_tool_read_phy_reg(priv->phy_id, ETH_TOOL_PHY_LED_CTRL_PAGE,
+				ETH_TOOL_PHY_LED_CTRL_REG, &old_led_state);
+	/* Forse LED blinking (all LED pins) */
+	mv_eth_tool_write_phy_reg(priv->phy_id, ETH_TOOL_PHY_LED_CTRL_PAGE,
+				ETH_TOOL_PHY_LED_CTRL_REG, 0x0BBB);
+	msleep_interruptible(data * 1000);
+	mv_eth_tool_write_phy_reg(priv->phy_id, ETH_TOOL_PHY_LED_CTRL_PAGE,
+				  ETH_TOOL_PHY_LED_CTRL_REG, old_led_state);
+	return 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_stats_count
+* Description:
+*	ethtool get statistics count (number of stat. array entries)
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	statistics count
+*
+*******************************************************************************/
+int mv_eth_tool_get_stats_count(struct net_device *netdev)
+{
+	return MV_ETH_TOOL_STATS_LEN;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_ethtool_stats
+* Description:
+*	ethtool get statistics
+* INPUT:
+*	netdev		Network device structure pointer
+*	stats		stats parameters
+* OUTPUT
+*	data		output data
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_ethtool_stats(struct net_device *netdev,
+				   struct ethtool_stats *stats, uint64_t *data)
+{
+	mv_eth_priv 	*priv = MV_ETH_PRIV(netdev);
+	uint64_t	*pdest = data;
+	int 		i, q;
+
+	for (i = 0; i < MV_ETH_TOOL_GLOBAL_STATS_LEN; i++) {
+		char *p = (char *)priv +
+			mv_eth_tool_global_strings_stats[i].stat_offset;
+		pdest[i] =  *(uint32_t *)p;
+	}
+	pdest += MV_ETH_TOOL_GLOBAL_STATS_LEN;
+	
+	for (q = 0; q < MV_ETH_RX_Q_NUM; q++) {
+		for (i = 0; i < MV_ETH_TOOL_RX_QUEUE_STATS_LEN; i++) {
+			char *p = (char *)priv +
+				mv_eth_tool_rx_queue_strings_stats[i].stat_offset;
+			pdest[i] =  *((uint32_t *)p + q);
+		}
+		pdest += MV_ETH_TOOL_RX_QUEUE_STATS_LEN;
+	}
+
+	for (q = 0; q < MV_ETH_TX_Q_NUM; q++) {
+		for (i = 0; i < MV_ETH_TOOL_TX_QUEUE_STATS_LEN; i++) {
+			char *p = (char *)priv +
+				mv_eth_tool_tx_queue_strings_stats[i].stat_offset;
+			pdest[i] =  *((uint32_t *)p + q);
+		}
+		pdest += MV_ETH_TOOL_TX_QUEUE_STATS_LEN;
+	}
+}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_tool.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_tool.h
new file mode 100644
index 0000000..0274459
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_tool.h
@@ -0,0 +1,85 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_eth_tool
+#define __mv_eth_tool
+
+#include <linux/ethtool.h>
+
+#define MV_ETH_TOOL_AN_TIMEOUT	2000
+
+extern const struct ethtool_ops mv_eth_tool_ops;
+
+int mv_eth_tool_read_mdio
+		(struct net_device *netdev, int addr, int reg);
+void mv_eth_tool_write_mdio
+		(struct net_device *netdev, int addr, int reg, int data);
+int mv_eth_tool_restore_settings(struct net_device *netdev);
+int mv_eth_tool_get_settings
+		(struct net_device *netdev, struct ethtool_cmd *cmd);
+int mv_eth_tool_set_settings
+		(struct net_device *netdev, struct ethtool_cmd *cmd);
+int mv_eth_tool_nway_reset
+		(struct net_device *netdev);
+int mv_eth_tool_get_regs_len
+		(struct net_device *netdev);
+void mv_eth_tool_get_regs
+		(struct net_device *netdev, struct ethtool_regs *regs, void *p);
+u32 mv_eth_tool_get_link
+		(struct net_device *netdev);
+int mv_eth_tool_get_coalesce
+		(struct net_device *netdev, struct ethtool_coalesce *cmd);
+int mv_eth_tool_set_coalesce
+		(struct net_device *netdev, struct ethtool_coalesce *cmd);
+void mv_eth_tool_get_ringparam
+		(struct net_device *netdev, struct ethtool_ringparam *ring);
+void mv_eth_tool_get_pauseparam
+		(struct net_device *netdev, struct ethtool_pauseparam *pause);
+int mv_eth_tool_set_pauseparam
+		(struct net_device *netdev, struct ethtool_pauseparam *pause);
+void mv_eth_tool_get_drvinfo
+		(struct net_device *netdev, struct ethtool_drvinfo *info);
+u32 mv_eth_tool_get_rx_csum
+		(struct net_device *netdev);
+int mv_eth_tool_set_rx_csum
+		(struct net_device *netdev, uint32_t data);
+int mv_eth_tool_set_tx_csum
+		(struct net_device *netdev, uint32_t data);
+int mv_eth_tool_set_tso
+		(struct net_device *netdev, uint32_t data);
+int mv_eth_tool_set_ufo
+		(struct net_device *netdev, uint32_t data);
+void mv_eth_tool_get_strings
+		(struct net_device *netdev, uint32_t stringset, uint8_t *data);
+int mv_eth_tool_phys_id
+		(struct net_device *netdev, u32 data);
+int mv_eth_tool_get_stats_count
+		(struct net_device *netdev);
+void mv_eth_tool_get_ethtool_stats
+		(struct net_device *netdev, struct ethtool_stats *stats, uint64_t *data);
+
+#endif /* __mv_eth_tool */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_ethernet.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_ethernet.c
new file mode 100644
index 0000000..02f5931
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_ethernet.c
@@ -0,0 +1,410 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+
+#include "mvCommon.h"  /* Should be included before mvSysHwConfig */
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/pci.h>
+#include <linux/ip.h>
+#include <linux/in.h>
+#include <linux/tcp.h>
+#include <net/ip.h>
+#include <net/xfrm.h>
+
+#include "mvOs.h"
+#include "dbg-trace.h"
+#include "mvSysHwConfig.h"
+#include "eth/mvEth.h"
+#include "eth/gbe/mvEthGbe.h"
+#include "eth-phy/mvEthPhy.h"
+#include "eth-phy/mvEthPhyRegs.h"
+#include "mvSysEthApi.h"
+#include "boardEnv/mvBoardEnvLib.h"
+
+#include "mv_netdev.h"
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+#include "mv78200/mvSemaphore.h"
+#endif
+
+int mv_eth_read_mii(unsigned int portNumber, unsigned int MIIReg, unsigned int* value)
+{
+    unsigned long flags;
+    unsigned short tmp;
+    MV_STATUS status;
+
+    spin_lock_irqsave(&mii_lock, flags);
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+    mvSemaLock(MV_SEMA_SMI);
+#endif
+    status = mvEthPhyRegRead(mvBoardPhyAddrGet(portNumber), MIIReg, &tmp);
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+    mvSemaUnlock(MV_SEMA_SMI);
+#endif
+    spin_unlock_irqrestore(&mii_lock, flags);	
+    *value = tmp;
+    if (status == MV_OK)
+        return 0;
+
+    return -1;
+}
+
+
+int mv_eth_write_mii(unsigned int portNumber, unsigned int MIIReg, unsigned int data)
+{
+    unsigned long   flags;
+    unsigned short  tmp;
+    MV_STATUS       status;
+
+    spin_lock_irqsave(&mii_lock, flags);
+    tmp = (unsigned short)data;
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+    mvSemaLock(MV_SEMA_SMI);
+#endif
+    status = mvEthPhyRegWrite(mvBoardPhyAddrGet(portNumber), MIIReg, tmp);
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+    mvSemaUnlock(MV_SEMA_SMI);
+#endif
+    spin_unlock_irqrestore(&mii_lock, flags);
+
+    if (status == MV_OK)
+        return 0;
+
+    return -1;
+}
+
+#ifndef CONFIG_MV_ETH_TOOL
+static int mv_eth_restart_autoneg( int port )
+{
+    u32 phy_reg_val = 0;
+
+    /* enable auto-negotiation */
+    mv_eth_read_mii(port, ETH_PHY_CTRL_REG, &phy_reg_val);
+    phy_reg_val |= BIT12;
+    mv_eth_write_mii(port, ETH_PHY_CTRL_REG, phy_reg_val);
+
+    mdelay(10);
+
+    /* restart auto-negotiation */
+    phy_reg_val |= BIT9;
+    mv_eth_write_mii(port, ETH_PHY_CTRL_REG, phy_reg_val);
+
+    mdelay(10);
+
+    return 0;
+}
+#endif
+
+/*********************************************************** 
+ * mv_eth_start --                                          *
+ *   start a network device. connect and enable interrupts *
+ *   set hw defaults. fill rx buffers. restart phy link    *
+ *   auto neg. set device link flags. report status.       *
+ ***********************************************************/
+int mv_eth_start( struct net_device *dev ) 
+{
+    mv_eth_priv *priv = MV_ETH_PRIV(dev);
+    int             err;
+
+    ETH_DBG( ETH_DBG_LOAD, ("%s: starting... ", dev->name ) );
+
+    /* in default link is down */
+    netif_carrier_off( dev );
+
+    /* Stop the TX queue - it will be enabled upon PHY status change after link-up interrupt/timer */
+    netif_stop_queue( dev );
+
+    /* enable polling on the port, must be used after netif_poll_disable */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    netif_poll_enable(dev);
+#else
+    napi_enable(&priv->napi);
+#endif
+
+    /* fill rx buffers, start rx/tx activity, set coalescing */
+    if( mv_eth_start_internals( priv, dev->mtu) != 0 ) {
+        printk( KERN_ERR "%s: start internals failed\n", dev->name );
+        goto error;
+    }
+
+#ifdef CONFIG_MV_ETH_TOOL
+    if ((err = mv_eth_tool_restore_settings( dev )) != 0) 
+    {
+        printk( KERN_ERR "%s: mv_eth_tool_restore_settings failed %d\n",
+                          dev->name, err );
+        goto error;
+    }
+    if (priv->autoneg_cfg == AUTONEG_DISABLE) 
+    {
+        if ( MV_REG_READ(ETH_PORT_STATUS_REG( priv->port )) & ETH_LINK_UP_MASK ) 
+	{
+	    netif_carrier_on( dev );
+	    netif_wake_queue( dev );
+        }
+    }
+#else
+    mv_eth_restart_autoneg( priv->port );
+#endif /* #ifdef CONFIG_MV_ETH_TOOL */
+
+    if (priv->timer_flag == 0)
+    {
+        priv->timer.expires = jiffies + ((HZ*CONFIG_MV_ETH_TIMER_PERIOD)/1000); /*ms*/
+        add_timer( &priv->timer );
+        priv->timer_flag = 1;
+    }
+
+    /* connect to port interrupt line */
+    if (request_irq(dev->irq, mv_eth_interrupt_handler,
+        (IRQF_DISABLED | IRQF_SAMPLE_RANDOM), "mv_ethernet", priv) ) {
+        printk( KERN_ERR "cannot assign irq%d to %s port%d\n", dev->irq, dev->name, priv->port );
+        dev->irq = 0;
+    	goto error;
+    }
+
+    mv_eth_unmask_interrupts(priv);
+
+    ETH_DBG( ETH_DBG_LOAD, ("%s: start ok\n", dev->name) );
+
+    printk( KERN_NOTICE "%s: started\n", dev->name );
+
+    return 0;
+
+ error:
+
+    if( dev->irq != 0 )
+    {
+        free_irq( dev->irq, priv );
+    }
+
+    printk( KERN_ERR "%s: start failed\n", dev->name );
+    return -1;
+}
+
+/*********************************************************** 
+ * mv_eth_stop --                                       *
+ *   stop interface with linux core. stop port activity.   *
+ *   free skb's from rings.                                *
+ ***********************************************************/
+int mv_eth_stop( struct net_device *dev )
+{
+    unsigned long   flags;
+    mv_eth_priv     *priv = MV_ETH_PRIV(dev);
+
+    /* first make sure that the port finished its Rx polling - see tg3 */
+    /* otherwise it may cause issue in SMP, one CPU is here and the other is doing the polling
+    and both of it are messing with the descriptors rings!! */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    netif_poll_disable(dev);
+#else
+    napi_disable(&priv->napi);
+#endif
+    spin_lock_irqsave( priv->lock, flags);
+
+    /* stop upper layer */
+    netif_carrier_off( dev );
+    netif_stop_queue( dev );
+
+    /* stop tx/rx activity, mask all interrupts, relese skb in rings,*/
+    mv_eth_stop_internals( priv );
+    
+    spin_unlock_irqrestore( priv->lock, flags);
+
+    if( dev->irq != 0 )
+    {
+        free_irq( dev->irq, priv );
+    }
+    printk( KERN_NOTICE "%s: stopped\n", dev->name );
+
+    return 0;
+}
+
+
+int mv_eth_change_mtu( struct net_device *dev, int mtu )
+{
+    int old_mtu = dev->mtu;
+
+    if(!netif_running(dev)) {
+    	if(mv_eth_change_mtu_internals(dev, mtu) == -1) {
+            goto error;
+    }
+        printk( KERN_NOTICE "%s: change mtu %d (buffer-size %d) to %d (buffer-size %d)\n",
+                dev->name, old_mtu, MV_RX_BUF_SIZE( old_mtu), 
+                dev->mtu, MV_RX_BUF_SIZE( dev->mtu) );
+        return 0;
+    }
+
+    if( mv_eth_stop( dev )) {
+        printk( KERN_ERR "%s: stop interface failed\n", dev->name );
+        goto error;
+    }
+
+    if(mv_eth_change_mtu_internals(dev, mtu) == -1) {
+        goto error;
+    }
+
+    if(mv_eth_start( dev )) {
+        printk( KERN_ERR "%s: start interface failed\n", dev->name );
+        goto error;
+    } 
+    printk( KERN_NOTICE "%s: change mtu %d (buffer-size %d) to %d (buffer-size %d)\n",
+                dev->name, old_mtu, MV_RX_BUF_SIZE(old_mtu), dev->mtu, 
+                MV_RX_BUF_SIZE(dev->mtu));
+ 
+    return 0;
+
+ error:
+    printk( "%s: change mtu failed\n", dev->name );
+    return -1;
+}
+
+/*********************************************************** 
+ * eth_set_mac_addr --                                   *
+ *   stop port activity. set new addr in device and hw.    *
+ *   restart port activity.                                *
+ ***********************************************************/
+static int mv_eth_set_mac_addr_internals(struct net_device *dev, void *addr )
+{
+    mv_eth_priv *priv = MV_ETH_PRIV(dev);
+    u8          *mac = &(((u8*)addr)[2]);  /* skip on first 2B (ether HW addr type) */
+    int i;
+
+    /* remove previous address table entry */
+    if( mvEthMacAddrSet( priv->hal_priv, dev->dev_addr, -1) != MV_OK ) {
+        printk( KERN_ERR "%s: ethSetMacAddr failed\n", dev->name );
+        return -1;
+    }
+
+    /* set new addr in hw */
+    if( mvEthMacAddrSet( priv->hal_priv, mac, ETH_DEF_RXQ) != MV_OK ) {
+        printk( KERN_ERR "%s: ethSetMacAddr failed\n", dev->name );
+    return -1;
+    }
+
+    /* set addr in the device */ 
+    for( i = 0; i < 6; i++ )
+        dev->dev_addr[i] = mac[i];
+
+    printk( KERN_NOTICE "%s: mac address changed\n", dev->name );
+
+    return 0;
+}
+
+/***********************************************************
+ * eth_set_multicast_list --                             *
+ *   Add multicast addresses or set promiscuous mode.      *
+ *   This function should have been but was not included   *
+ *   by Marvell. -bbozarth                                 *
+ ***********************************************************/
+void mv_eth_set_multicast_list(struct net_device *dev) {
+
+     mv_eth_priv        *priv = MV_ETH_PRIV(dev);
+     int                queue = ETH_DEF_RXQ;
+     struct dev_mc_list *curr_addr = dev->mc_list;
+     int                i;
+
+     if (dev->flags & IFF_PROMISC)
+     {
+        mvEthRxFilterModeSet(priv->hal_priv, 1);
+     }
+     else if (dev->flags & IFF_ALLMULTI)
+     {
+        mvEthRxFilterModeSet(priv->hal_priv, 0);
+        mvEthMacAddrSet(priv->hal_priv, dev->dev_addr, queue);
+        mvEthSetSpecialMcastTable(priv->port, queue);
+        mvEthSetOtherMcastTable(priv->port, queue);
+     }
+     else if (dev->mc_count)
+     {
+        mvEthRxFilterModeSet(priv->hal_priv, 0);
+        mvEthMacAddrSet(priv->hal_priv, dev->dev_addr, queue);
+        for (i=0; i<dev->mc_count; i++, curr_addr = curr_addr->next)
+        {
+            if (!curr_addr)
+                break;
+            mvEthMcastAddrSet(priv->hal_priv, curr_addr->dmi_addr, queue);
+        }
+     }
+     else /* No Mcast addrs, not promisc or all multi - clear tables */
+     {
+        mvEthRxFilterModeSet(priv->hal_priv, 0);
+        mvEthMacAddrSet(priv->hal_priv, dev->dev_addr, queue);
+     }
+}
+
+
+int     mv_eth_set_mac_addr( struct net_device *dev, void *addr )
+{
+    if(!netif_running(dev)) {
+        if(mv_eth_set_mac_addr_internals(dev, addr) == -1)
+            goto error;
+        return 0;
+    }
+
+    if( mv_eth_stop( dev )) {
+        printk( KERN_ERR "%s: stop interface failed\n", dev->name );
+        goto error;
+    }
+
+    if(mv_eth_set_mac_addr_internals(dev, addr) == -1)
+        goto error;
+
+    if(mv_eth_start( dev )) {
+        printk( KERN_ERR "%s: start interface failed\n", dev->name );
+    goto error;
+    } 
+
+    return 0;
+
+ error:
+    printk( "%s: set mac addr failed\n", dev->name );
+    return -1;
+}
+
+
+/************************************************************ 
+ * mv_eth_open -- Restore MAC address and call to   *
+ *                mv_eth_start                               *
+ ************************************************************/
+int mv_eth_open( struct net_device *dev )
+{
+    mv_eth_priv	*priv = MV_ETH_PRIV(dev);
+    int         queue = ETH_DEF_RXQ;
+
+    if( mvEthMacAddrSet( priv->hal_priv, dev->dev_addr, queue) != MV_OK ) {
+        printk( KERN_ERR "%s: ethSetMacAddr failed\n", dev->name );
+        return -1;
+    }
+
+    if(mv_eth_start( dev )){
+        printk( KERN_ERR "%s: start interface failed\n", dev->name );
+        return -1;
+    } 
+    return 0;
+}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_gateway.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_gateway.c
new file mode 100644
index 0000000..910991e
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_gateway.c
@@ -0,0 +1,1443 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+
+#include "mvCommon.h"  /* Should be included before mvSysHwConfig */
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/pci.h>
+#include <linux/ip.h>
+#include <linux/in.h>
+#include <linux/tcp.h>
+#include <linux/version.h>
+#include <net/ip.h>
+#include <net/xfrm.h>
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "dbg-trace.h"
+#include "mvSysHwConfig.h"
+#include "eth/mvEth.h"
+#include "eth/gbe/mvEthGbe.h"
+#include "eth-phy/mvEthPhy.h"
+#include "mvSysEthApi.h"
+#include "msApi.h"
+#include "boardEnv/mvBoardEnvLib.h"
+
+#include "mv_netdev.h"
+
+int SWITCH_PORT_CPU;
+int SWITCH_PORT_0;
+int SWITCH_PORT_1;
+int SWITCH_PORT_2;
+int SWITCH_PORT_3;
+int SWITCH_PORT_4;
+
+
+/* use this MACRO to find if a certain port (0-7) is actually connected */
+#define SWITCH_IS_PORT_CONNECTED(p)	                            \
+            ( ((p) == SWITCH_PORT_CPU) || ((p) == SWITCH_PORT_0) || \
+			  ((p) == SWITCH_PORT_1)   || ((p) == SWITCH_PORT_2) || \
+			  ((p) == SWITCH_PORT_3)   || ((p) == SWITCH_PORT_4) ) 
+
+/* helpers for VLAN tag handling */
+#define MV_GTW_PORT_VLAN_ID(grp,port)  ((grp)+(port)+1)
+#define MV_GTW_GROUP_VLAN_ID(grp)      (((grp)+1)<<8)
+#define MV_GTW_VLANID_TO_PORT(vlanid)  (((vlanid) & 0xf)-1)
+
+unsigned int        switch_enabled_ports;
+
+#ifdef CONFIG_MV_GTW_LINK_STATUS
+static int          switch_irq = -1;
+struct timer_list   switch_link_timer;
+#endif
+
+#ifdef CONFIG_MV_GTW_IGMP
+extern int mv_gtw_igmp_snoop_init(void);
+extern int mv_gtw_igmp_snoop_exit(void);
+extern int mv_gtw_igmp_snoop_process(struct sk_buff* skb, unsigned char port, unsigned char vlan_dbnum);
+#endif 
+
+/* Example: "mv_net_config=(eth0,00:99:88:88:99:77,0)(eth1,00:55:44:55:66:77,1:2:3:4),mtu=1500" */
+static char *cmdline = NULL;
+
+struct mv_gtw_config    gtw_config;
+
+GT_QD_DEV qddev,        *qd_dev = NULL;
+static GT_SYS_CONFIG    qd_cfg;
+
+static int mv_gtw_port2lport(int port)
+{
+    if(port==SWITCH_PORT_0) return 0;
+    if(port==SWITCH_PORT_1) return 1;
+    if(port==SWITCH_PORT_2) return 2;
+    if(port==SWITCH_PORT_3) return 3;
+    if(port==SWITCH_PORT_4) return 4;
+    return -1;
+} 
+
+/* Local function prototypes */
+
+/* Required to get the configuration string from the Kernel Command Line */
+int mv_gtw_cmdline_config(char *s);
+__setup("mv_net_config=", mv_gtw_cmdline_config);
+
+int mv_gtw_cmdline_config(char *s)
+{
+    cmdline = s;
+    return 1;
+}
+
+static int mv_gtw_check_open_bracket(char **p_net_config)
+{
+    if (**p_net_config == '(') {
+        (*p_net_config)++;
+	return 0;
+    }
+    printk("Syntax error: could not find opening bracket\n");
+    return -EINVAL;
+}
+
+static int mv_gtw_check_closing_bracket(char **p_net_config)
+{
+    if (**p_net_config == ')') {
+        (*p_net_config)++;
+	return 0;
+    }
+    printk("Syntax error: could not find closing bracket\n");
+    return -EINVAL;
+}
+
+static int mv_gtw_check_comma(char **p_net_config)
+{
+    if (**p_net_config == ',') {
+        (*p_net_config)++;
+	    return 0;
+    }
+    printk("Syntax error: could not find comma\n");
+    return -EINVAL;
+}
+
+
+static int mv_gtw_is_digit(char ch)
+{
+    if( ((ch >= '0') && (ch <= '9')) ||
+	((ch >= 'a') && (ch <= 'f')) ||
+	((ch >= 'A') && (ch <= 'F')) )
+	    return 0;
+
+    return -1;
+}
+
+static int mv_gtw_get_cmdline_mac_addr(char **p_net_config, int idx)
+{
+    /* the MAC address should look like: 00:99:88:88:99:77 */
+    /* that is, 6 two-digit numbers, separated by :        */
+    /* 6 times two-digits, plus 5 colons, total: 17 characters */
+    const int   exact_len = 17; 
+    int         i = 0;
+    int         syntax_err = 0;
+    char	    *p_mac_addr = *p_net_config;
+
+    /* check first 15 characters in groups of 3 characters at a time */
+    for (i = 0; i < exact_len-2; i+=3) 
+    {
+	    if ( (mv_gtw_is_digit(**p_net_config) == 0) &&
+	         (mv_gtw_is_digit(*(*p_net_config+1)) == 0) &&
+	         ((*(*p_net_config+2)) == ':') )
+	    {
+	        (*p_net_config) += 3;
+	    }
+	    else {
+	        syntax_err = 1;
+	        break;
+	    }
+    }
+
+    /* two characters remaining, must be two digits */
+    if ( (mv_gtw_is_digit(**p_net_config) == 0) &&
+         (mv_gtw_is_digit(*(*p_net_config+1)) == 0) )
+    {
+	    (*p_net_config) += 2;
+    }
+    else
+	    syntax_err = 1;
+
+    if (syntax_err == 0) {
+        mvMacStrToHex(p_mac_addr, gtw_config.vlan_cfg[idx].macaddr);
+        return 0;
+    }
+    printk("Syntax error while parsing MAC address from command line\n");
+    return -EINVAL;
+}
+
+static void mv_gtw_update_curr_port_mask(char digit, unsigned int *curr_port_mask)
+{
+    if (digit == '0')
+	    *curr_port_mask |= (1<<SWITCH_PORT_0);
+    if (digit == '1')
+	    *curr_port_mask |= (1<<SWITCH_PORT_1);
+    if (digit == '2')
+	    *curr_port_mask |= (1<<SWITCH_PORT_2);
+    if (digit == '3')
+	    *curr_port_mask |= (1<<SWITCH_PORT_3);
+    if (digit == '4')
+	    *curr_port_mask |= (1<<SWITCH_PORT_4);
+}
+
+static int mv_gtw_get_port_mask(char **p_net_config, int idx)
+{
+    /* the port mask should look like this: */
+    /* example 1: 0 */
+    /* example 2: 1:2:3:4 */
+    /* that is, one or more one-digit numbers, separated with : */
+    /* we have up to GTW_MAX_NUM_OF_IFS interfaces */
+
+    unsigned int curr_port_mask = 0, i = 0;
+    int syntax_err = 0;
+
+    for (i = 0; i < GTW_MAX_NUM_OF_IFS; i++) 
+    {
+	    if (mv_gtw_is_digit(**p_net_config) == 0) 
+        {
+	        if (*(*p_net_config+1) == ':') 
+            {
+		        mv_gtw_update_curr_port_mask(**p_net_config, &curr_port_mask);
+		        (*p_net_config) += 2;
+	        }
+	        else if (*(*p_net_config+1) == ')') 
+            {
+		        mv_gtw_update_curr_port_mask(**p_net_config, &curr_port_mask);
+		        (*p_net_config)++;
+		        break;
+	        }
+	        else {
+		        syntax_err = 1;
+		        break;
+	        }
+	    }
+	    else {
+	        syntax_err = 1;
+	        break;
+	    }
+    }
+
+    if (syntax_err == 0) {
+	    gtw_config.vlan_cfg[idx].ports_mask = curr_port_mask;
+	    return 0;
+    }
+    printk("Syntax error while parsing port mask from command line\n");
+    return -EINVAL;
+}
+
+static int mv_gtw_get_mtu(char **p_net_config)
+{
+    /* the mtu value is constructed as follows: */
+    /* mtu=value                                */
+    unsigned int mtu;
+    int syntax_err = 0;
+
+    if(strncmp(*p_net_config,"mtu=",4) == 0)
+    {
+        *p_net_config += 4;
+        mtu = 0;
+        while((**p_net_config >= '0') && (**p_net_config <= '9'))
+        {       
+            mtu = (mtu * 10) + (**p_net_config - '0');
+            *p_net_config += 1;
+        }
+        if(**p_net_config != '\0')
+            syntax_err = 1;
+    }
+    else
+    {
+        syntax_err = 1;
+    }
+
+    if(syntax_err == 0)
+    {
+        gtw_config.mtu = mtu;
+        printk("      o MTU set to %d.\n", mtu);
+        return 0;
+    }
+
+    printk("Syntax error while parsing mtu value from command line\n");
+    return -EINVAL;
+}
+
+static int mv_gtw_parse_net_config(char* cmdline)
+{
+    char    *p_net_config = cmdline;
+    int     i = 0;
+    int     status = 0;
+
+    if (p_net_config == NULL)
+	    return -EINVAL;
+
+    for (i=0; (i<GTW_MAX_NUM_OF_IFS) && (*p_net_config != '\0'); i++) 
+    {
+        status = mv_gtw_check_open_bracket(&p_net_config);
+	    if (status != 0)
+	        break;
+	    status = mv_gtw_get_cmdline_mac_addr(&p_net_config, i);
+	    if (status != 0)
+	        break;
+	    status = mv_gtw_check_comma(&p_net_config);
+	    if (status != 0)
+	        break;
+	    status = mv_gtw_get_port_mask(&p_net_config, i);
+	    if (status != 0)
+	        break;
+	    status = mv_gtw_check_closing_bracket(&p_net_config);
+	    if (status != 0)
+	        break;
+
+	    gtw_config.vlans_num++;
+
+        /* If we have a comma after the closing bracket, then interface */
+        /* definition is done.                                          */
+        if(*p_net_config == ',')
+            break;
+    }
+
+    if(*p_net_config != '\0')
+    {
+        status = mv_gtw_check_comma(&p_net_config);
+        if (status == 0)
+        {
+            status = mv_gtw_get_mtu(&p_net_config);
+        }
+    }
+    else
+    {
+        gtw_config.mtu = 1500;
+        printk("      o Using default MTU %d\n", gtw_config.mtu);
+    }
+    
+    /* at this point, we have parsed up to GTW_MAX_NUM_OF_IFS, and the mtu value */
+    /* if the net_config string is not finished yet, then its format is invalid */
+    if (*p_net_config != '\0')
+    {
+        printk("Gateway config string is too long: %s\n", p_net_config);
+        status = -EINVAL;
+    }
+    return status;
+}
+
+GT_BOOL gtwReadMiiWrap(GT_QD_DEV* dev, unsigned int portNumber, unsigned int MIIReg, unsigned int* value)
+{
+    unsigned long   flags;
+    unsigned short  tmp;
+    MV_STATUS       status;
+
+    spin_lock_irqsave(&mii_lock, flags);
+
+    status = mvEthPhyRegRead(portNumber, MIIReg , &tmp);
+    spin_unlock_irqrestore(&mii_lock, flags);
+    *value = tmp;
+
+    if (status == MV_OK)
+        return GT_TRUE;
+
+    return GT_FALSE;
+}
+
+
+GT_BOOL gtwWriteMiiWrap(GT_QD_DEV* dev, unsigned int portNumber, unsigned int MIIReg, unsigned int data)
+{
+    unsigned long   flags;
+    unsigned short  tmp;
+    MV_STATUS       status;
+
+    spin_lock_irqsave(&mii_lock, flags);
+    tmp = (unsigned short)data;
+    status = mvEthPhyRegWrite(portNumber, MIIReg, tmp);
+
+    spin_unlock_irqrestore(&mii_lock, flags);
+
+    if (status == MV_OK)
+        return GT_TRUE;
+
+    return GT_FALSE;
+} 
+
+static int mv_gtw_set_port_based_vlan(unsigned int ports_mask)
+{
+    unsigned int p, pl;
+    unsigned char cnt;
+    GT_LPORT port_list[MAX_SWITCH_PORTS];
+
+    for(p=0; p<qd_dev->numOfPorts; p++) {
+	if( MV_BIT_CHECK(ports_mask, p) && (p != SWITCH_PORT_CPU) ) {
+	    ETH_DBG( ETH_DBG_LOAD|ETH_DBG_MCAST|ETH_DBG_VLAN, ("port based vlan, port %d: ",p));
+	    for(pl=0,cnt=0; pl<qd_dev->numOfPorts; pl++) {
+		if( MV_BIT_CHECK(ports_mask, pl) && (pl != p) ) {
+		    ETH_DBG( ETH_DBG_LOAD|ETH_DBG_MCAST|ETH_DBG_VLAN, ("%d ",pl));
+		    port_list[cnt] = pl;
+                    cnt++;
+                }
+	    }
+            if( gvlnSetPortVlanPorts(qd_dev, p, port_list, cnt) != GT_OK) {
+	        printk("gvlnSetPortVlanPorts failed\n");
+                return -1;
+            }
+	    ETH_DBG( ETH_DBG_LOAD|ETH_DBG_MCAST|ETH_DBG_VLAN, ("\n"));
+        }
+    }
+    return 0;
+}
+
+
+static int mv_gtw_set_vlan_in_vtu(unsigned short vlan_id,unsigned int ports_mask)
+{
+    GT_VTU_ENTRY vtu_entry;
+    unsigned int p;
+
+    vtu_entry.vid = vlan_id;
+    vtu_entry.DBNum = MV_GTW_VLAN_TO_GROUP(vlan_id);
+    vtu_entry.vidPriOverride = GT_FALSE;
+    vtu_entry.vidPriority = 0;
+    vtu_entry.vidExInfo.useVIDFPri = GT_FALSE;
+    vtu_entry.vidExInfo.vidFPri = 0;
+    vtu_entry.vidExInfo.useVIDQPri = GT_FALSE;
+    vtu_entry.vidExInfo.vidQPri = 0;
+    vtu_entry.vidExInfo.vidNRateLimit = GT_FALSE;
+    ETH_DBG( ETH_DBG_LOAD|ETH_DBG_MCAST|ETH_DBG_VLAN, ("vtu entry: vid=0x%x, port ", vtu_entry.vid));
+    for(p=0; p<qd_dev->numOfPorts; p++) {
+        if(MV_BIT_CHECK(ports_mask, p)) {
+	    ETH_DBG( ETH_DBG_LOAD|ETH_DBG_MCAST|ETH_DBG_VLAN, ("%d ", p));
+	    if(qd_dev->deviceId == GT_88E6061) {
+                /* for 6061 device, no double/provider tag controlling on ingress. */
+                /* therefore, we need to strip the tag on egress on all ports except cpu port */
+                /* anyway, if we're using header mode no vlan-tag need to be added here */
+		vtu_entry.vtuData.memberTagP[p] = MEMBER_EGRESS_UNMODIFIED;
+	    }
+	    else {
+		vtu_entry.vtuData.memberTagP[p] = MEMBER_EGRESS_UNMODIFIED;
+	    }
+	}
+	else {
+	    vtu_entry.vtuData.memberTagP[p] = NOT_A_MEMBER;
+	}
+	vtu_entry.vtuData.portStateP[p] = 0;
+    }
+    if(gvtuAddEntry(qd_dev, &vtu_entry) != GT_OK) {
+        printk("gvtuAddEntry failed\n");
+        return -1;
+    }
+
+    ETH_DBG( ETH_DBG_LOAD|ETH_DBG_MCAST|ETH_DBG_VLAN, ("\n"));
+    return 0;
+}
+
+int mv_gtw_set_mac_addr_to_switch(unsigned char *mac_addr, unsigned char db, unsigned int ports_mask, unsigned char op)
+{
+    GT_ATU_ENTRY mac_entry;
+    struct mv_vlan_cfg *nc;
+
+    /* validate db with VLAN id */
+    nc = &gtw_config.vlan_cfg[db];
+    if(MV_GTW_VLAN_TO_GROUP(nc->vlan_grp_id) != db) {
+        printk("mv_gtw_set_mac_addr_to_switch (invalid db)\n");
+	return -1;
+    }
+
+    memset(&mac_entry,0,sizeof(GT_ATU_ENTRY));
+
+    mac_entry.trunkMember = GT_FALSE;
+    mac_entry.prio = 0;
+    mac_entry.exPrio.useMacFPri = GT_FALSE;
+    mac_entry.exPrio.macFPri = 0;
+    mac_entry.exPrio.macQPri = 0;
+    mac_entry.DBNum = db;
+    mac_entry.portVec = ports_mask;
+    memcpy(mac_entry.macAddr.arEther,mac_addr,6);
+
+    if(is_multicast_ether_addr(mac_addr))
+	mac_entry.entryState.mcEntryState = GT_MC_STATIC;
+    else
+	mac_entry.entryState.ucEntryState = GT_UC_NO_PRI_STATIC;
+
+    ETH_DBG(ETH_DBG_ALL, ("mv_gateway: db%d port-mask=0x%x, %02x:%02x:%02x:%02x:%02x:%02x ",
+	    db, (unsigned int)mac_entry.portVec,
+	    mac_entry.macAddr.arEther[0],mac_entry.macAddr.arEther[1],mac_entry.macAddr.arEther[2],
+	    mac_entry.macAddr.arEther[3],mac_entry.macAddr.arEther[4],mac_entry.macAddr.arEther[5]));
+
+    if((op == 0) || (mac_entry.portVec == 0)) {
+        if(gfdbDelAtuEntry(qd_dev, &mac_entry) != GT_OK) {
+	    printk("gfdbDelAtuEntry failed\n");
+	    return -1;
+        }
+	ETH_DBG(ETH_DBG_ALL, ("deleted\n"));
+    }
+    else {
+        if(gfdbAddMacEntry(qd_dev, &mac_entry) != GT_OK) {
+	    printk("gfdbAddMacEntry failed\n");
+	    return -1;
+        }
+	ETH_DBG(ETH_DBG_ALL, ("added\n"));
+    }
+
+    return 0;
+}
+
+#ifdef CONFIG_MV_GTW_IGMP
+int mv_gtw_enable_igmp(void)
+{
+    unsigned char p;
+
+    ETH_DBG( ETH_DBG_IGMP, ("enabling L2 IGMP snooping\n"));
+
+    /* enable IGMP snoop on all ports (except cpu port) */
+    for(p=0; p<qd_dev->numOfPorts; p++) {
+	if(p != SWITCH_PORT_CPU) {
+	    if(gprtSetIGMPSnoop(qd_dev, p, GT_TRUE) != GT_OK) {
+		printk("gprtSetIGMPSnoop failed\n");
+		return -1;
+	    }
+	}
+    }
+    return -1;
+}
+#endif /* CONFIG_MV_GTW_IGMP */
+
+
+int __init mv_gtw_net_setup(int port)
+{
+    struct mv_vlan_cfg  *nc;
+    int                 i = 0;
+
+    SWITCH_PORT_CPU = mvBoardSwitchCpuPortGet(port);
+    SWITCH_PORT_0   = mvBoardSwitchPortGet(port, 0);
+    SWITCH_PORT_1   = mvBoardSwitchPortGet(port, 1);
+    SWITCH_PORT_2   = mvBoardSwitchPortGet(port, 2);
+    SWITCH_PORT_3   = mvBoardSwitchPortGet(port, 3);
+    SWITCH_PORT_4   = mvBoardSwitchPortGet(port, 4);
+
+#ifdef CONFIG_MV_GTW_LINK_STATUS
+    switch_irq = mvBoardLinkStatusIrqGet(port);
+    if(switch_irq != -1)
+        switch_irq += IRQ_GPP_START;
+#endif
+
+    /* build the net config table */
+    memset(&gtw_config, 0, sizeof(struct mv_gtw_config));
+
+    if(cmdline != NULL) 
+    {
+	    printk("      o Using command line network interface configuration\n");
+    }
+    else
+    {
+	    printk("      o Using default network configuration, overriding boot MAC address\n");
+	    cmdline = CONFIG_MV_GTW_CONFIG;
+    }
+
+	if (mv_gtw_parse_net_config(cmdline) < 0) 
+    {
+	    printk("Error parsing mv_net_config\n");
+	    return -EINVAL;
+    }           
+
+    /* CPU port should always be enabled */
+    switch_enabled_ports = (1 << SWITCH_PORT_CPU); 
+
+    for(i=0, nc=&gtw_config.vlan_cfg[i]; i<gtw_config.vlans_num; i++, nc++) 
+    {
+	    /* VLAN ID */
+	    nc->vlan_grp_id = MV_GTW_GROUP_VLAN_ID(i);
+	    nc->ports_link = 0;
+	    nc->header = cpu_to_be16(	(MV_GTW_VLAN_TO_GROUP(nc->vlan_grp_id) << 12) 
+                    			| nc->ports_mask);
+	    /* print info */
+	    printk("      o mac_addr %02x:%02x:%02x:%02x:%02x:%02x, VID 0x%03x, port list: ", 
+                nc->macaddr[0], nc->macaddr[1], nc->macaddr[2], 
+		        nc->macaddr[3], nc->macaddr[4], nc->macaddr[5], nc->vlan_grp_id);
+
+	    if(nc->ports_mask & (1<<SWITCH_PORT_CPU)) 
+            printk("port-CPU ");
+	    if(nc->ports_mask & (1<<SWITCH_PORT_0)) 
+            printk("port-0 ");
+	    if(nc->ports_mask & (1<<SWITCH_PORT_1)) 
+            printk("port-1 ");
+	    if(nc->ports_mask & (1<<SWITCH_PORT_2)) 
+            printk("port-2 ");
+	    if(nc->ports_mask & (1<<SWITCH_PORT_3)) 
+            printk("port-3 ");
+	    if(nc->ports_mask & (1<<SWITCH_PORT_4)) 
+            printk("port-4 ");
+	    printk("\n");
+
+	    /* collect per-interface port_mask into a global port_mask, used for enabling the Switch ports */
+	    switch_enabled_ports |= nc->ports_mask;
+    }
+
+    return 0;
+}
+
+static int mv_switch_init(int port)
+{
+    unsigned int        i, p;
+    unsigned char       cnt;
+    GT_LPORT            port_list[MAX_SWITCH_PORTS];
+    struct mv_vlan_cfg  *nc;
+    GT_JUMBO_MODE       jumbo_mode;
+
+    /* printk("init switch layer... "); */
+
+    memset((char*)&qd_cfg,0,sizeof(GT_SYS_CONFIG));
+
+    /* init config structure for qd package */
+    qd_cfg.BSPFunctions.readMii   = gtwReadMiiWrap;
+    qd_cfg.BSPFunctions.writeMii  = gtwWriteMiiWrap;
+    qd_cfg.BSPFunctions.semCreate = NULL;
+    qd_cfg.BSPFunctions.semDelete = NULL;
+    qd_cfg.BSPFunctions.semTake   = NULL;
+    qd_cfg.BSPFunctions.semGive   = NULL;
+    qd_cfg.initPorts = GT_TRUE;
+    qd_cfg.cpuPortNum = SWITCH_PORT_CPU;
+    if (mvBoardSmiScanModeGet(port) == 1) {
+	qd_cfg.mode.baseAddr = 0;
+        qd_cfg.mode.scanMode = SMI_MANUAL_MODE;
+    }
+    else if (mvBoardSmiScanModeGet(port) == 2) {
+	qd_cfg.mode.baseAddr = 0xA;
+        qd_cfg.mode.scanMode = SMI_MULTI_ADDR_MODE;
+    }
+    /* load switch sw package */
+    if( qdLoadDriver(&qd_cfg, &qddev) != GT_OK) {
+	printk("qdLoadDriver failed\n");
+        return -1;
+    }
+    qd_dev = &qddev;
+
+    ETH_DBG( ETH_DBG_LOAD, ("Device ID     : 0x%x\n",qd_dev->deviceId));
+    ETH_DBG( ETH_DBG_LOAD, ("Base Reg Addr : 0x%x\n",qd_dev->baseRegAddr));
+    ETH_DBG( ETH_DBG_LOAD, ("No. of Ports  : %d\n",qd_dev->numOfPorts));
+    ETH_DBG( ETH_DBG_LOAD, ("CPU Ports     : %ld\n",qd_dev->cpuPortNum));
+
+    /* disable all ports */
+    for(p=0; p<qd_dev->numOfPorts; p++) {
+	    gstpSetPortState(qd_dev, p, GT_PORT_DISABLE);
+    }
+
+    /* initialize Switch according to Switch ID */
+    switch (qd_dev->deviceId) 
+    {
+	    case GT_88E6131:
+	    case GT_88E6108:
+	        /* enable external ports */
+	        ETH_DBG( ETH_DBG_LOAD, ("enable phy polling for external ports\n"));
+	        if(gsysSetPPUEn(qd_dev, GT_TRUE) != GT_OK) {
+		        printk("gsysSetPPUEn failed\n");
+		        return -1;
+	        }
+	        /* Note: The GbE unit in SoCs connected to these switches does not support Marvell Header Mode */
+	        /* so we always use VLAN tags here */
+	        /* set cpu-port with ingress double-tag mode */
+	        ETH_DBG( ETH_DBG_LOAD, ("cpu port ingress double-tag mode\n"));
+	        if(gprtSetDoubleTag(qd_dev, SWITCH_PORT_CPU, GT_TRUE) != GT_OK) {
+	            printk("gprtSetDoubleTag failed\n");
+	            return -1;
+	        }
+	        /* set cpu-port with egrees add-tag mode */
+	        ETH_DBG( ETH_DBG_LOAD, ("cpu port egrees add-tag mode\n"));
+	        if(gprtSetEgressMode(qd_dev, SWITCH_PORT_CPU, GT_ADD_TAG) != GT_OK) {
+		        printk("gprtSetEgressMode failed\n");
+		    return -1;
+	        }
+	        /* config the switch to use the double tag data (relevant to cpu-port only) */
+	        ETH_DBG( ETH_DBG_LOAD, ("use double-tag and remove\n"));
+	        if(gsysSetUseDoubleTagData(qd_dev,GT_TRUE) != GT_OK) {
+	            printk("gsysSetUseDoubleTagData failed\n");
+	            return -1;
+	        }
+	        /* set cpu-port with 802.1q secured mode */
+	        ETH_DBG( ETH_DBG_LOAD, ("cpu port-based 802.1q secure mode\n"));
+	        if(gvlnSetPortVlanDot1qMode(qd_dev,SWITCH_PORT_CPU,GT_SECURE) != GT_OK) {
+		        printk("gvlnSetPortVlanDot1qMode failed\n");
+	            return -1;
+	        }
+	        break;
+	
+	    case GT_88E6065:
+	        /* set CPU port number */
+            if(gsysSetCPUPort(qd_dev, SWITCH_PORT_CPU) != GT_OK) {
+	            printk("gsysSetCPUPort failed\n");
+	            return -1;
+	        }
+
+	        if(gstatsFlushAll(qd_dev) != GT_OK)
+    	        printk("gstatsFlushAll failed\n");
+
+	        /* set all ports not to unmodify the vlan tag on egress */
+	        for(i=0; i<qd_dev->numOfPorts; i++) 
+            {
+		        if(gprtSetEgressMode(qd_dev, i, GT_UNMODIFY_EGRESS) != GT_OK) {
+		            printk("gprtSetEgressMode GT_UNMODIFY_EGRESS failed\n");
+		            return -1;
+		        }
+	        }
+	        if(gprtSetHeaderMode(qd_dev, SWITCH_PORT_CPU, GT_TRUE) != GT_OK) {
+		        printk("gprtSetHeaderMode GT_TRUE failed\n");
+		        return -1;
+	        }
+
+	        /* init counters */
+	        if(gprtClearAllCtr(qd_dev) != GT_OK)
+	            printk("gprtClearAllCtr failed\n");
+	        if(gprtSetCtrMode(qd_dev, GT_CTR_ALL) != GT_OK)
+	            printk("gprtSetCtrMode failed\n");
+
+	        break;
+
+	    case GT_88E6061: 
+	        /* set CPU port number */
+            if(gsysSetCPUPort(qd_dev, SWITCH_PORT_CPU) != GT_OK) {
+	            printk("gsysSetCPUPort failed\n");
+	            return -1;
+	        }
+
+	        /* set all ports not to unmodify the vlan tag on egress */
+	        for(i=0; i<qd_dev->numOfPorts; i++) {
+		        if(gprtSetEgressMode(qd_dev, i, GT_UNMODIFY_EGRESS) != GT_OK) {
+		            printk("gprtSetEgressMode GT_UNMODIFY_EGRESS failed\n");
+		            return -1;
+		        }
+	        }
+	    
+            if(gprtSetHeaderMode(qd_dev,SWITCH_PORT_CPU,GT_TRUE) != GT_OK) {
+		        printk("gprtSetHeaderMode GT_TRUE failed\n");
+		        return -1;
+	        }   
+
+	        /* init counters */
+	        if(gprtClearAllCtr(qd_dev) != GT_OK)
+	            printk("gprtClearAllCtr failed\n");
+	        if(gprtSetCtrMode(qd_dev, GT_CTR_ALL) != GT_OK)
+	            printk("gprtSetCtrMode failed\n");
+
+	        break;
+
+	    case GT_88E6161:
+	    case GT_88E6165:
+            if(gstatsFlushAll(qd_dev) != GT_OK) {
+                printk("gstatsFlushAll failed\n");
+            }
+
+	        /* set all ports not to unmodify the vlan tag on egress */
+	        for(i=0; i<qd_dev->numOfPorts; i++) {
+		        if(gprtSetEgressMode(qd_dev, i, GT_UNMODIFY_EGRESS) != GT_OK) {
+		            printk("gprtSetEgressMode GT_UNMODIFY_EGRESS failed\n");
+		            return -1;
+		        }
+	        }
+	        if(gprtSetHeaderMode(qd_dev,SWITCH_PORT_CPU,GT_TRUE) != GT_OK) {
+		        printk("gprtSetHeaderMode GT_TRUE failed\n");
+		        return -1;
+	        }
+
+            	/* Setup jumbo frames mode.                         */
+	        if( MV_RX_BUF_SIZE(gtw_config.mtu) <= 1522)
+                	jumbo_mode = GT_JUMBO_MODE_1522;
+            	else if( MV_RX_BUF_SIZE(gtw_config.mtu) <= 2048)
+                	jumbo_mode = GT_JUMBO_MODE_2048;
+            	else
+                	jumbo_mode = GT_JUMBO_MODE_10240;
+
+            	for(i=0; i<qd_dev->numOfPorts; i++) {
+                	if(gsysSetJumboMode(qd_dev, i, jumbo_mode) != GT_OK) {
+                    		printk("gsysSetJumboMode %d failed\n",jumbo_mode);
+                    		return -1;
+                	}
+            	}
+	        break;	
+
+	    default:
+	        printk("Unsupported Switch. Switch ID is 0x%X.\n",qd_dev->deviceId);
+	        return -1;
+    }
+
+    /* set priorities rules */
+    for(i=0; i<qd_dev->numOfPorts; i++) {
+        /* default port priority to queue zero */
+	    if(gcosSetPortDefaultTc(qd_dev, i, 0) != GT_OK)
+	        printk("gcosSetPortDefaultTc failed (port %d)\n", i);
+        
+        /* enable IP TOS Prio */
+	    if(gqosIpPrioMapEn(qd_dev, i, GT_TRUE) != GT_OK)
+	        printk("gqosIpPrioMapEn failed (port %d)\n",i);
+	
+        /* set IP QoS */
+	    if(gqosSetPrioMapRule(qd_dev, i, GT_FALSE) != GT_OK)
+	        printk("gqosSetPrioMapRule failed (port %d)\n",i);
+        
+        /* disable Vlan QoS Prio */
+	    if(gqosUserPrioMapEn(qd_dev, i, GT_FALSE) != GT_OK)
+	        printk("gqosUserPrioMapEn failed (port %d)\n",i);
+        
+        /* Set force flow control to FALSE for all ports */
+	    if(gprtSetForceFc(qd_dev, i, GT_FALSE) != GT_OK)
+	        printk("gprtSetForceFc failed (port %d)\n",i);
+    }
+
+    /* The switch CPU port is not part of the VLAN, but rather connected by tunneling to each */
+    /* of the VLAN's ports. Our MAC addr will be added during start operation to the VLAN DB  */
+    /* at switch level to forward packets with this DA to CPU port.                           */
+    ETH_DBG( ETH_DBG_LOAD, ("Enabling Tunneling on ports: "));
+    for(i=0; i<qd_dev->numOfPorts; i++) {
+	    if(i != SWITCH_PORT_CPU) {
+	        if(gprtSetVlanTunnel(qd_dev, i, GT_TRUE) != GT_OK) {
+		        printk("gprtSetVlanTunnel failed (port %d)\n",i);
+		        return -1;
+	        }
+	        else {
+		        ETH_DBG( ETH_DBG_LOAD, ("%d ",i));
+	        }
+	    }
+    }
+    ETH_DBG( ETH_DBG_LOAD, ("\n"));
+
+    /* configure ports (excluding CPU port) for each network interface (VLAN): */
+    for(i=0, nc=&gtw_config.vlan_cfg[i]; i<gtw_config.vlans_num; i++,nc++) {
+        ETH_DBG( ETH_DBG_LOAD, ("vlan%d configuration (nc->ports_mask = 0x%08x) \n",
+                                i, nc->ports_mask));
+	    /* set port's defaul private vlan id and database number (DB per group): */
+	    for(p=0; p<qd_dev->numOfPorts; p++) {
+	        if( MV_BIT_CHECK(nc->ports_mask, p) && (p != SWITCH_PORT_CPU) ) {
+		        ETH_DBG(ETH_DBG_LOAD,("port %d default private vlan id: 0x%x\n", p, MV_GTW_PORT_VLAN_ID(nc->vlan_grp_id,p)));
+		        if( gvlnSetPortVid(qd_dev, p, MV_GTW_PORT_VLAN_ID(nc->vlan_grp_id,p)) != GT_OK ) {
+			        printk("gvlnSetPortVid failed");
+			        return -1;
+		        }
+		        if( gvlnSetPortVlanDBNum(qd_dev, p, MV_GTW_VLAN_TO_GROUP(nc->vlan_grp_id)) != GT_OK) {
+		            printk("gvlnSetPortVlanDBNum failed\n");
+		            return -1;
+		        }
+	        }
+	    }
+
+	    /* set port's port-based vlan (CPU port is not part of VLAN) */
+        if(mv_gtw_set_port_based_vlan(nc->ports_mask & ~(1<<SWITCH_PORT_CPU)) != 0) {
+	        printk("mv_gtw_set_port_based_vlan failed\n");
+	    }
+
+        /* set vtu with group vlan id (used in tx) */
+        if(mv_gtw_set_vlan_in_vtu(nc->vlan_grp_id, nc->ports_mask | (1<<SWITCH_PORT_CPU)) != 0) {
+	        printk("mv_gtw_set_vlan_in_vtu failed\n");
+	    }
+
+        /* set vtu with each port private vlan id (used in rx) */
+ 	    for(p=0; p<qd_dev->numOfPorts; p++) {
+	        if(MV_BIT_CHECK(nc->ports_mask, p) && (p!=SWITCH_PORT_CPU)) {
+                if(mv_gtw_set_vlan_in_vtu(MV_GTW_PORT_VLAN_ID(nc->vlan_grp_id,p),
+                                          nc->ports_mask & ~(1<<SWITCH_PORT_CPU)) != 0) {
+		            printk("mv_gtw_set_vlan_in_vtu failed\n");
+		        }
+	        }
+	    }
+    }
+
+    /* set cpu-port with port-based vlan to all other ports */
+    ETH_DBG( ETH_DBG_LOAD, ("cpu port-based vlan:"));
+    for(p=0,cnt=0; p<qd_dev->numOfPorts; p++) {
+        if(p != SWITCH_PORT_CPU) {
+	        ETH_DBG( ETH_DBG_LOAD, ("%d ",p));
+            port_list[cnt] = p;
+            cnt++;
+        }
+    }
+    ETH_DBG( ETH_DBG_LOAD, ("\n"));
+    if( gvlnSetPortVlanPorts(qd_dev, SWITCH_PORT_CPU, port_list, cnt) != GT_OK) {
+        printk("gvlnSetPortVlanPorts failed\n");
+        return -1;
+    }
+
+    if(gfdbFlush(qd_dev,GT_FLUSH_ALL) != GT_OK) {
+	    printk("gfdbFlush failed\n");
+    }
+
+    /* done! enable all Switch ports according to the net config table */
+    ETH_DBG( ETH_DBG_LOAD, ("enabling: ports "));
+    for(p=0; p<qd_dev->numOfPorts; p++) {
+	    if (MV_BIT_CHECK(switch_enabled_ports, p)) {
+	        ETH_DBG( ETH_DBG_LOAD, ("%d ",p));
+	        if(gstpSetPortState(qd_dev, p, GT_PORT_FORWARDING) != GT_OK) {
+	            printk("gstpSetPortState failed\n");
+	        }
+	    }
+    }
+    ETH_DBG( ETH_DBG_LOAD, ("\n"));
+
+#ifdef CONFIG_MV_GTW_LINK_STATUS
+    /* Enable Phy Link Status Changed interrupt at Phy level for the all enabled ports */
+    for(p=0; p<qd_dev->numOfPorts; p++) {
+	    if(MV_BIT_CHECK(switch_enabled_ports, p) && (p != SWITCH_PORT_CPU)) {
+	        if(gprtPhyIntEnable(qd_dev, p, (GT_LINK_STATUS_CHANGED)) != GT_OK) {
+		        printk("gprtPhyIntEnable failed port %d\n", p);
+	        }
+	    }
+    }
+
+    if ((qd_dev->deviceId != GT_88E6161) && (qd_dev->deviceId != GT_88E6165)) {
+    	if (switch_irq != -1) {
+            if(eventSetActive(qd_dev, GT_PHY_INTERRUPT) != GT_OK) {
+	    	    printk("eventSetActive failed\n");
+            }
+    	}
+    }
+    else {
+	    GT_DEV_EVENT gt_event = {GT_DEV_INT_PHY, 0, 0x1F}; /* 0x1F is a bit mask for ports 0-4 */
+	    if (switch_irq != -1) {
+	        if(eventSetDevInt(qd_dev, &gt_event) != GT_OK) {
+		        printk("eventSetDevInt failed\n");
+	        }
+	        if(eventSetActive(qd_dev, GT_DEVICE_INT) != GT_OK) {
+    	    	printk("eventSetActive failed\n");
+            }
+	    }
+    }
+#endif /* CONFIG_MV_GTW_LINK_STATUS */
+
+    /* Configure Ethernet related LEDs, currently according to Switch ID */
+    switch (qd_dev->deviceId) {
+	    case GT_88E6131:
+	    case GT_88E6108:
+            /* config LEDs: Bi-Color Mode-4:  */
+            /* 1000 Mbps Link - Solid Green; 1000 Mbps Activity - Blinking Green */
+            /* 100 Mbps Link - Solid Red; 100 Mbps Activity - Blinking Red */
+            for(p=0; p<qd_dev->numOfPorts; p++) {	        
+                if( (p != SWITCH_PORT_CPU) && (SWITCH_IS_PORT_CONNECTED(p)) ) {
+			/* Configure Register 16 page 3 to 0x888F for mode 4 */
+	                if(gprtSetPagedPhyReg(qd_dev,p,16,3,0x888F)) { 
+		                printk("gprtSetPagedPhyReg failed (port=%d)\n", p);
+	                }
+			    /* Configure Register 17 page 3 to 0x4400 50% mixed LEDs */
+		            if(gprtSetPagedPhyReg(qd_dev,p,17,3,0x4400)) {
+		                printk("gprtSetPagedPhyReg failed (port=%d)\n", p);
+	                }
+	            }
+            }
+	        break;
+
+	    case GT_88E6161:
+	    case GT_88E6165:
+		    break; /* do nothing */
+
+	    default:
+	        for(p=0; p<qd_dev->numOfPorts; p++) {
+	            if( (p != SWITCH_PORT_CPU) && (SWITCH_IS_PORT_CONNECTED(p)) ) {
+	                if(gprtSetPhyReg(qd_dev,p,22,0x1FFA)) { 
+                        /* Configure Register 22 LED0 to 0xA for Link/Act */
+	    	            printk("gprtSetPhyReg failed (port=%d)\n", p);
+		            }
+	            }
+	        }
+	        break;
+    }
+
+    /* printk("done\n"); */
+
+    return 0;
+}
+
+int mv_gtw_switch_tos_get(int port, unsigned char tos)
+{
+    unsigned char   queue;
+    int             rc;
+
+    rc = gcosGetDscp2Tc(qd_dev, tos>>2, &queue);
+    if(rc)
+        return -1;
+
+    return (int)queue;
+}
+
+int mv_gtw_switch_tos_set(int port, unsigned char tos, int queue)
+{
+    return gcosSetDscp2Tc(qd_dev, tos>>2, (unsigned char)queue);
+}
+
+static struct net_device* mv_gtw_main_net_dev_get(void)
+{
+    int                 i;
+    mv_eth_priv         *priv;
+    struct net_device   *dev;
+
+    for (i=0; i<mv_net_devs_num; i++) {
+        dev = mv_net_devs[i];
+        priv = MV_ETH_PRIV(dev);
+
+        if (netif_running(dev) && priv->isGtw)
+            return dev;
+    }
+    return NULL;
+}
+
+int mv_gtw_set_mac_addr( struct net_device *dev, void *p )
+{
+    struct mv_vlan_cfg *vlan_cfg = MV_NETDEV_VLAN(dev);
+    struct sockaddr *addr = p;
+
+    if(!is_valid_ether_addr(addr->sa_data))
+	    return -EADDRNOTAVAIL;
+
+    /* remove old mac addr from VLAN DB */
+    mv_gtw_set_mac_addr_to_switch(dev->dev_addr,MV_GTW_VLAN_TO_GROUP(vlan_cfg->vlan_grp_id),(1<<SWITCH_PORT_CPU),0);
+
+    memcpy(dev->dev_addr, addr->sa_data, 6);
+
+    /* add new mac addr to VLAN DB */
+    mv_gtw_set_mac_addr_to_switch(dev->dev_addr,MV_GTW_VLAN_TO_GROUP(vlan_cfg->vlan_grp_id),(1<<SWITCH_PORT_CPU),1);
+
+    printk("mv_gateway: %s change mac address to %02x:%02x:%02x:%02x:%02x:%02x\n", 
+        dev->name, *(dev->dev_addr), *(dev->dev_addr+1), *(dev->dev_addr+2), 
+       *(dev->dev_addr+3), *(dev->dev_addr+4), *(dev->dev_addr+5));
+
+    return 0;
+}
+
+void    mv_gtw_set_multicast_list(struct net_device *dev)
+{
+    struct dev_mc_list *curr_addr = dev->mc_list;
+    struct mv_vlan_cfg *vlan_cfg = MV_NETDEV_VLAN(dev);
+    int i;
+    GT_ATU_ENTRY mac_entry;
+    GT_BOOL found = GT_FALSE;
+    GT_STATUS status;
+
+    if((dev->flags & IFF_PROMISC) || (dev->flags & IFF_ALLMULTI)) {
+	/* promiscuous mode - connect the CPU port to the VLAN (port based + 802.1q) */
+	/*
+	if(dev->flags & IFF_PROMISC)
+	    printk("mv_gateway: setting promiscuous mode\n");
+	if(dev->flags & IFF_ALLMULTI)
+	    printk("mv_gateway: setting multicast promiscuous mode\n");
+	*/
+	mv_gtw_set_port_based_vlan(vlan_cfg->ports_mask|(1<<SWITCH_PORT_CPU));
+	    for(i=0; i<qd_dev->numOfPorts; i++) 
+        {
+	        if(MV_BIT_CHECK(vlan_cfg->ports_mask, i) && (i!=SWITCH_PORT_CPU)) 
+            {
+		        if(mv_gtw_set_vlan_in_vtu(MV_GTW_PORT_VLAN_ID(vlan_cfg->vlan_grp_id,i),
+                                          vlan_cfg->ports_mask | (1<<SWITCH_PORT_CPU)) != 0) 
+                {
+		            printk("mv_gtw_set_vlan_in_vtu failed\n");
+		        }
+	        }
+	    }
+    }
+    else 
+    {
+	/* not in promiscuous or allmulti mode - disconnect the CPU port to the VLAN (port based + 802.1q) */
+	mv_gtw_set_port_based_vlan(vlan_cfg->ports_mask&(~(1<<SWITCH_PORT_CPU)));
+	for(i=0; i<qd_dev->numOfPorts; i++) {
+	    if(MV_BIT_CHECK(vlan_cfg->ports_mask, i) && (i!=SWITCH_PORT_CPU)) {
+		if(mv_gtw_set_vlan_in_vtu(MV_GTW_PORT_VLAN_ID(vlan_cfg->vlan_grp_id,i),vlan_cfg->ports_mask&(~(1<<SWITCH_PORT_CPU))) != 0) {
+		    printk("mv_gtw_set_vlan_in_vtu failed\n");
+		}
+	   }
+	}
+	if(dev->mc_count) {
+	    /* accept specific multicasts */
+	    for(i=0; i<dev->mc_count; i++, curr_addr = curr_addr->next) {
+	        if (!curr_addr)
+		    break;
+		/* The Switch may already have information about this multicast address in      */
+		/* its ATU. If this address is already in the ATU, use the existing port vector */
+		/* ORed with the CPU port. Otherwise, just use the CPU port.                    */
+		memset(&mac_entry,0,sizeof(GT_ATU_ENTRY));
+		        mac_entry.DBNum = MV_GTW_VLAN_TO_GROUP(vlan_cfg->vlan_grp_id);
+		memcpy(mac_entry.macAddr.arEther, curr_addr->dmi_addr, 6);
+		status = gfdbFindAtuMacEntry(qd_dev, &mac_entry, &found);
+		        if ( (status != GT_OK) || (found != GT_TRUE) ) 
+                {
+		            mv_gtw_set_mac_addr_to_switch(curr_addr->dmi_addr,
+		    				  MV_GTW_VLAN_TO_GROUP(vlan_cfg->vlan_grp_id),
+						  (1<<SWITCH_PORT_CPU)|(vlan_cfg->ports_mask), 1);
+		}
+		        else 
+                {
+		            mv_gtw_set_mac_addr_to_switch(curr_addr->dmi_addr,
+						  MV_GTW_VLAN_TO_GROUP(vlan_cfg->vlan_grp_id),
+						  (mac_entry.portVec | (1<<SWITCH_PORT_CPU)), 1);
+		        }
+	        }
+	    }
+    }
+}
+ 
+
+int mv_gtw_change_mtu(struct net_device *dev, int mtu)
+{
+	printk("mv_gateway does not support changing MTU at runtime.\n"); 
+	return -EPERM;
+} 
+
+
+int mv_gtw_start( struct net_device *dev )
+{
+    mv_eth_priv		*priv = MV_ETH_PRIV(dev);
+    struct 		mv_vlan_cfg *vlan_cfg = MV_NETDEV_VLAN(dev);
+    unsigned char	broadcast[6] = {0xff,0xff,0xff,0xff,0xff,0xff};
+
+    printk("mv_gateway: starting %s\n",dev->name);
+
+    /* start upper layer */
+    netif_carrier_on(dev);
+    netif_wake_queue(dev);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    netif_poll_enable(dev);
+#else
+    if ( (priv->net_dev == dev) || !netif_running(priv->net_dev) )
+    {
+	napi_enable(&priv->napi);
+    }
+#endif
+
+    /* Add our MAC addr to the VLAN DB at switch level to forward packets with this DA */
+    /* to CPU port by using the tunneling feature. The device is always in promisc mode.      */
+    mv_gtw_set_mac_addr_to_switch(dev->dev_addr, MV_GTW_VLAN_TO_GROUP(vlan_cfg->vlan_grp_id), (1<<SWITCH_PORT_CPU), 1);
+
+    /* We also need to allow L2 broadcasts comming up for this interface */
+    mv_gtw_set_mac_addr_to_switch(broadcast, MV_GTW_VLAN_TO_GROUP(vlan_cfg->vlan_grp_id), 
+					vlan_cfg->ports_mask|(1<<SWITCH_PORT_CPU), 1);
+
+    if (priv->timer_flag == 0)
+    {
+        priv->timer.expires = jiffies + ((HZ*CONFIG_MV_ETH_TIMER_PERIOD)/1000); /*ms*/
+        add_timer( &(priv->timer) );
+        priv->timer_flag = 1;
+    }
+
+    if ( (priv->net_dev == dev) || !netif_running(priv->net_dev) )
+    {
+        priv->net_dev = dev;
+
+	/* connect to MAC port interrupt line */
+    	if ( request_irq( ETH_PORT_IRQ_NUM(priv->port), mv_eth_interrupt_handler, 
+             (IRQF_DISABLED | IRQF_SAMPLE_RANDOM), "mv_gateway", priv) ) 
+	{
+        	printk(KERN_ERR "failed to assign irq%d\n", ETH_PORT_IRQ_NUM(priv->port));
+    	}
+
+        /* unmask interrupts */
+        mv_eth_unmask_interrupts(priv);
+    }
+    
+    return 0;
+}
+
+
+int mv_gtw_stop( struct net_device *dev )
+{
+    mv_eth_priv		    *priv = MV_ETH_PRIV(dev);
+    struct mv_vlan_cfg	*vlan_cfg = MV_NETDEV_VLAN(dev);
+
+    printk("mv_gateway: stopping %s\n",dev->name);
+
+    /* stop upper layer */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    netif_poll_disable(dev);
+#endif
+    netif_carrier_off(dev);
+    netif_stop_queue(dev);
+
+    /* stop switch from forwarding packets from this VLAN toward CPU port */
+    if( gfdbFlushInDB(qd_dev, GT_FLUSH_ALL, MV_GTW_VLAN_TO_GROUP(vlan_cfg->vlan_grp_id)) != GT_OK) {
+        printk("gfdbFlushInDB failed\n");
+    }
+
+    if(priv->net_dev == dev)
+    {
+        struct net_device *main_dev = mv_gtw_main_net_dev_get();
+
+        if(main_dev == NULL)
+        {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,24)
+	    napi_disable(&priv->napi);
+#endif
+            mv_eth_mask_interrupts(priv);
+    	    priv->timer_flag = 0;
+            del_timer(&priv->timer);
+
+            free_irq( dev->irq, priv );
+        }
+        else
+        {
+            priv->net_dev = main_dev;
+        }
+    }
+    return 0;
+}
+
+#ifdef CONFIG_MV_GTW_LINK_STATUS
+static void mv_gtw_update_link_status(unsigned int p, unsigned int link_up)
+{
+    struct mv_vlan_cfg  *vlan_cfg;
+    int                 i = 0;
+    unsigned int        prev_ports_link = 0;
+
+    for(i=0; i<mv_net_devs_num; i++) {
+	if (mv_net_devs[i] == NULL)
+		break;
+        vlan_cfg = MV_NETDEV_VLAN(mv_net_devs[i]);
+	    if ( vlan_cfg != NULL) {
+
+	        if ((vlan_cfg->ports_mask & (1 << p)) == 0)
+		        continue;
+
+	        prev_ports_link = vlan_cfg->ports_link;
+ 
+	        if (link_up)
+	            vlan_cfg->ports_link |= (1 << p);
+	        else
+		        vlan_cfg->ports_link &= ~(1 << p);
+
+	        if ((vlan_cfg->ports_link & vlan_cfg->ports_mask) == 0) {
+                    netif_carrier_off(mv_net_devs[i]);
+                    netif_stop_queue(mv_net_devs[i]);
+	        }
+	        else if (prev_ports_link == 0) {
+		        netif_carrier_on(mv_net_devs[i]);
+                netif_wake_queue(mv_net_devs[i]);          
+	        }
+	    }
+    }
+}
+
+static irqreturn_t mv_gtw_link_interrupt_handler(int irq , void *dev_id)
+{
+    unsigned short switch_cause, phy_cause, phys_port, p;
+
+    if (switch_irq != -1 ) {
+	    if ( (qd_dev->deviceId == GT_88E6161) || (qd_dev->deviceId == GT_88E6165) ) {
+	        OUT GT_DEV_INT_STATUS devIntStatus;
+            /* required to clear the interrupt, and updates phys_port */
+	        geventGetDevIntStatus(qd_dev, &devIntStatus); 
+	        phys_port = devIntStatus.phyInt & 0xFF;
+	        if (phys_port)
+		        switch_cause = GT_PHY_INTERRUPT;
+	    }
+	    else {
+	        if(eventGetIntStatus(qd_dev, &switch_cause) != GT_OK)
+	            switch_cause = 0;
+	    }
+    }
+    else {
+	    switch_cause = GT_PHY_INTERRUPT;
+    }
+
+    if(switch_cause & GT_PHY_INTERRUPT) {
+	    /* If we're using a 6161/6165 Switch and using the Switch interrupt, we already have phys_port updated above */
+	    /* If we're using any other Switch, or if we're using polling, we need to update phys_port now */
+	    if ( (qd_dev->deviceId == GT_88E6161) || (qd_dev->deviceId == GT_88E6165)) {
+		    if (switch_irq == -1) {
+			    gprtGetPhyIntPortSummary(qd_dev,&phys_port);
+			    phys_port |= 0x18; /* we cannot get indication for these ports in this method, so check them */
+		    }
+	    }
+	    else {
+		    /* not 6161 or 6165 */
+        	gprtGetPhyIntPortSummary(qd_dev,&phys_port);
+	    }
+
+        for(p=0; p<qd_dev->numOfPorts; p++) {
+            if (MV_BIT_CHECK(phys_port, p)) {
+		        if(gprtGetPhyIntStatus(qd_dev,p,&phy_cause) == GT_OK) {
+		            if(phy_cause & GT_LINK_STATUS_CHANGED) 
+                    {
+			            char *link=NULL, *duplex=NULL, *speed=NULL;
+			            GT_BOOL flag;
+			            GT_PORT_SPEED_MODE speed_mode;
+
+			            if(gprtGetLinkState(qd_dev,p,&flag) != GT_OK) {
+			                printk("gprtGetLinkState failed (port %d)\n",p);
+			                link = "ERR";
+			            }
+                        else 
+                            link = (flag)?"up":"down";
+
+			            if(flag) {
+			                if(gprtGetDuplex(qd_dev,p,&flag) != GT_OK) {
+			                    printk("gprtGetDuplex failed (port %d)\n",p);
+			                    duplex = "ERR";
+			                }
+                            else 
+                                duplex = (flag)?"Full":"Half";
+
+			                if(gprtGetSpeedMode(qd_dev,p,&speed_mode) != GT_OK) {
+			                    printk("gprtGetSpeedMode failed (port %d)\n",p);
+			                    speed = "ERR";
+			                }
+			                else {
+			                    if (speed_mode == PORT_SPEED_1000_MBPS)
+			                        speed = "1000Mbps";
+			                    else if (speed_mode == PORT_SPEED_100_MBPS)
+			                        speed = "100Mbps";
+			                    else
+			                        speed = "10Mbps";
+			                }
+
+			                mv_gtw_update_link_status(p, 1);
+
+                            printk("Port %d: Link-%s, %s-duplex, Speed-%s.\n",
+                                   mv_gtw_port2lport(p),link,duplex,speed);
+                        }
+			            else {
+			                mv_gtw_update_link_status(p, 0);
+
+			                printk("Port %d: Link-down\n",mv_gtw_port2lport(p));
+			            }
+		            }
+		        }
+	        }
+	    }
+    }
+
+    if (switch_irq == -1 ) {
+    	switch_link_timer.expires = jiffies + (HZ); /* 1 second */
+    	add_timer(&switch_link_timer);
+    }
+
+    return IRQ_HANDLED;
+}
+
+static void mv_gtw_link_timer_function(unsigned long data)
+{
+    mv_gtw_link_interrupt_handler(switch_irq, NULL);
+}
+#endif /* CONFIG_MV_GTW_LINK_STATUS */
+
+
+/*********************************************************** 
+ * gtw_init_complete --                                    *
+ *   complete all initializations relevant for Gateway.    *
+ ***********************************************************/
+int  __init mv_gtw_init_complete(mv_eth_priv* priv)
+{
+    int status = 0;
+
+    status = mv_switch_init(priv->port);
+    if (status != 0)
+	return status;
+
+    status = mv_eth_start_internals(priv, gtw_config.mtu);
+    if (status != 0)
+	return status;
+
+    status = mvEthHeaderModeSet(priv->hal_priv, MV_ETH_ENABLE_HEADER_MODE_PRI_2_1);
+    if (status != 0)
+	return status;
+    
+    /* Mask interrupts */
+    mv_eth_mask_interrupts(priv);
+
+#ifdef CONFIG_MV_GTW_IGMP
+    /* Initialize the IGMP snooping handler */
+    if(mv_gtw_igmp_snoop_init()) {
+        printk("failed to init IGMP snooping handler\n");
+    }
+#endif
+
+#ifdef CONFIG_MV_GTW_LINK_STATUS
+    if (switch_irq != -1) {
+        if(request_irq(switch_irq, mv_gtw_link_interrupt_handler, 
+            (IRQF_DISABLED | IRQF_SAMPLE_RANDOM), "link status", NULL))
+	    {
+                printk(KERN_ERR "failed to assign irq%d\n", switch_irq);
+	    }
+    }
+    else {
+        memset( &switch_link_timer, 0, sizeof(struct timer_list) );
+	init_timer(&switch_link_timer);
+        switch_link_timer.function = mv_gtw_link_timer_function;
+        switch_link_timer.data = -1;
+   	switch_link_timer.expires = jiffies + (HZ); /* 1 second */
+    	add_timer(&switch_link_timer);
+    }
+#endif /* CONFIG_MV_GTW_LINK_STATUS */
+
+    return 0;
+}
+
+#define QD_FMT "%10lu %10lu %10lu %10lu %10lu %10lu\n"
+#define QD_CNT(c,f) c[0].f, c[1].f,c[2].f,c[3].f,c[4].f,c[5].f
+#define QD_MAX 6
+void    mv_gtw_switch_stats(int port)
+{
+    GT_STATS_COUNTER_SET3 counters[QD_MAX];
+    int p;
+
+    if(qd_dev == NULL) {
+        printk("Switch is not initialized\n");
+        return;
+    }
+    memset(counters, 0, sizeof(GT_STATS_COUNTER_SET3) * QD_MAX);
+
+    for (p=0; p<QD_MAX; p++)
+        gstatsGetPortAllCounters3(qd_dev, p, &counters[p]);
+
+    printk("PortNum         " QD_FMT,  (GT_U32)0, (GT_U32)1, (GT_U32)2, (GT_U32)3, (GT_U32)4, (GT_U32)5);
+    printk("-------------------------------------------------------------------------------------\n");
+    printk("InGoodOctetsLo  " QD_FMT,  QD_CNT(counters,InGoodOctetsLo));
+    printk("InGoodOctetsHi  " QD_FMT,  QD_CNT(counters,InGoodOctetsHi));
+    printk("InBadOctets     " QD_FMT,  QD_CNT(counters,InBadOctets));
+    printk("OutFCSErr       " QD_FMT,  QD_CNT(counters,OutFCSErr));
+    printk("Deferred        " QD_FMT,  QD_CNT(counters,Deferred));
+    printk("InBroadcasts    " QD_FMT,  QD_CNT(counters,InBroadcasts));
+    printk("InMulticasts    " QD_FMT,  QD_CNT(counters,InMulticasts));
+    printk("Octets64        " QD_FMT,  QD_CNT(counters,Octets64));
+    printk("Octets127       " QD_FMT,  QD_CNT(counters,Octets127));
+    printk("Octets255       " QD_FMT,  QD_CNT(counters,Octets255));
+    printk("Octets511       " QD_FMT,  QD_CNT(counters,Octets511));
+    printk("Octets1023      " QD_FMT,  QD_CNT(counters,Octets1023));
+    printk("OctetsMax       " QD_FMT,  QD_CNT(counters,OctetsMax));
+    printk("OutOctetsLo     " QD_FMT,  QD_CNT(counters,OutOctetsLo));
+    printk("OutOctetsHi     " QD_FMT,  QD_CNT(counters,OutOctetsHi));
+    printk("OutUnicasts     " QD_FMT,  QD_CNT(counters,OutOctetsHi));
+    printk("Excessive       " QD_FMT,  QD_CNT(counters,Excessive));
+    printk("OutMulticasts   " QD_FMT,  QD_CNT(counters,OutMulticasts));
+    printk("OutBroadcasts   " QD_FMT,  QD_CNT(counters,OutBroadcasts));
+    printk("Single          " QD_FMT,  QD_CNT(counters,OutBroadcasts));
+    printk("OutPause        " QD_FMT,  QD_CNT(counters,OutPause));
+    printk("InPause         " QD_FMT,  QD_CNT(counters,InPause));
+    printk("Multiple        " QD_FMT,  QD_CNT(counters,InPause));
+    printk("Undersize       " QD_FMT,  QD_CNT(counters,Undersize));
+    printk("Fragments       " QD_FMT,  QD_CNT(counters,Fragments));
+    printk("Oversize        " QD_FMT,  QD_CNT(counters,Oversize));
+    printk("Jabber          " QD_FMT,  QD_CNT(counters,Jabber));
+    printk("InMACRcvErr     " QD_FMT,  QD_CNT(counters,InMACRcvErr));
+    printk("InFCSErr        " QD_FMT,  QD_CNT(counters,InFCSErr));
+    printk("Collisions      " QD_FMT,  QD_CNT(counters,Collisions));
+    printk("Late            " QD_FMT,  QD_CNT(counters,Late));
+
+    gstatsFlushAll(qd_dev);
+}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_gtw_igmp.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_gtw_igmp.c
new file mode 100644
index 0000000..5749d79
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_gtw_igmp.c
@@ -0,0 +1,541 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/ip.h>
+#include <linux/in.h>
+#include <linux/igmp.h>
+#include <linux/if_ether.h>
+#include <linux/list.h>
+#include <linux/inetdevice.h>
+#include <linux/version.h>
+#include <net/checksum.h>
+
+/* To enable debugging uncomment CONFIG_IGMPS_DEBUG */
+#define CONFIG_IGMPS_DEBUG
+
+#ifdef CONFIG_IGMPS_DEBUG
+#define IGMPSDEBUG(format, args...)  printk(format , ## args)
+#else
+#define IGMPSDEBUG(format, args...)
+#endif
+
+/* APIs exported by the "mv_gwy_main.c" */
+extern int mv_gtw_enable_igmp(void); 
+extern int mv_gtw_set_mac_addr_to_switch(unsigned char *mac_addr, unsigned char db, unsigned int ports_mask, unsigned char op);
+
+/* MAC node data structure (a member of "ipm_llist") */
+typedef struct mac_node 
+{
+    struct list_head ip_list;
+    unsigned char eth_addr[ETH_ALEN];
+    unsigned int port_bitmap;
+    struct list_head list_node;
+}_mac_node;
+
+/* IP node data structure */
+typedef struct ip_node 
+{
+    unsigned int ip_port_bitmap;
+    unsigned int ip_addr;
+    struct list_head ip_list_node;
+}_ip_node;
+
+static int _igmp_add_mac_node( unsigned char temp_addr[ETH_ALEN], unsigned char vlan_dbnum,
+				__u32		igmp_addr,
+				__u32		port_bitmap);
+			
+/* Linked list of the MAC addresses */
+static LIST_HEAD(ipm_llist);
+
+/* Main process routine */
+int mv_gtw_igmp_snoop_process(struct sk_buff* skb, unsigned char port, unsigned char vlan_dbnum)     
+{
+    struct iphdr      *ipheader;
+    struct igmphdr    *igmpheader;
+    __u32             igmp_addr, igmp_addr_host;
+    unsigned char     mac_found, ip_found, ip_port_found;
+    unsigned char     temp_mac_addr[ETH_ALEN];
+    struct list_head  *l, *ip_l;
+    __u32             temp_port_bitmap = 0;
+    _mac_node         *mac_node_entry;
+    _ip_node          *ip_node_entry;
+    __u16 	      old_igmp_csum, new_igmp_csum;
+
+    ipheader = (struct iphdr*)(skb->data);
+
+    /* First of all, let's filter out non-IGMP traffic */
+    if (ipheader->protocol != IPPROTO_IGMP)
+        goto out;
+		
+    /* Get the pointer to the IGMP header and its data */
+    igmpheader = (struct igmphdr*)((__u32)ipheader + (__u32)(ipheader->ihl * 4));
+
+    /* Filter out unsupported IGMP messages */
+    if ((igmpheader->type != IGMP_HOST_MEMBERSHIP_REPORT) &&
+	(igmpheader->type != IGMPV2_HOST_MEMBERSHIP_REPORT) &&
+	(igmpheader->type != IGMP_HOST_LEAVE_MESSAGE))    	
+	goto out;
+    
+    /* Filter out non-multicast messages */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+    if (!MULTICAST(igmpheader->group))
+#else
+    if (!ipv4_is_multicast(igmpheader->group))
+#endif
+    {
+    	printk(KERN_ERR "\nIGMP snoop: Non-multicast group address in IGMP header\n");
+	goto out;
+    }
+    
+    /* According to "draft-ietf-magma-snoop-12.txt" local multicast messages (224.0.0.x) must be flooded to all ports */
+    /* So, don't do anything with such messages */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+    if (LOCAL_MCAST(igmpheader->group))
+#else
+    if (ipv4_is_local_multicast(igmpheader->group))
+#endif
+    {
+    	IGMPSDEBUG(KERN_INFO "\nIGMP snoop: Local IGMP messages (224.0.0.x) must be flooded \n");
+	goto out;
+    }
+    
+    /* According to RFC 2236 IGMP LEAVE messages should be sent to ALL-ROUTERS address (224.0.0.2) */
+    if (igmpheader->type == IGMP_HOST_LEAVE_MESSAGE)
+    {
+    	if (ntohl(ipheader->daddr) != 0xE0000002)
+	{
+		IGMPSDEBUG(KERN_INFO "\nIGMP snoop: Ignore IGMP LEAVE message sent to non-ALL-ROUTERS address (224.0.0.2) \n");
+		goto out;
+	}	
+    }
+    else
+    {
+    	/* According to RFC 2236 Membership Report (JOIN) IGMP messages should be sent to the IGMP group address */
+	if (ipheader->daddr != igmpheader->group)
+    	{
+    		IGMPSDEBUG(KERN_INFO "\nIGMP snoop: Ignore IGMP JOIN message with different destination IP(%u.%u.%u.%u) and IGMP group address(%u.%u.%u.%u) \n",
+			NIPQUAD(ipheader->daddr), NIPQUAD(igmpheader->group));
+		goto out;
+   	 }
+    }
+    
+    /* According to RFC 2236 the IGMP checksum must be checked before processing */
+    /* Before re-calculation of the IGMP checksum one needs to zero the checksum field */
+    old_igmp_csum = igmpheader->csum;
+    igmpheader->csum = 0;
+	 
+    /* Calculate a new checksum */
+    new_igmp_csum = ip_compute_csum((void *)igmpheader, sizeof(struct igmphdr));
+	
+    /* Restore the old checksum */
+    igmpheader->csum = old_igmp_csum;
+	
+    if (old_igmp_csum != new_igmp_csum)
+    {
+	printk(KERN_ERR "\nIGMP snoop: Wrong IGMP message checksum\n");
+	goto out;
+    }	
+        
+    igmp_addr = igmpheader->group;
+    igmp_addr_host = ntohl(igmpheader->group);
+
+    /* Build the multicast MAC address */
+    temp_mac_addr[0] = 0x01;
+    temp_mac_addr[1] = 0x00;
+    temp_mac_addr[2] = 0x5E;
+    temp_mac_addr[3] = (igmp_addr_host>>16) & 0x000000FF;
+    temp_mac_addr[4] = (igmp_addr_host>>8) & 0x000000FF;
+    temp_mac_addr[5] = igmp_addr_host & 0x000000FF;
+
+    /* Set the bit corresponding to the source port */
+    temp_port_bitmap = 1 << port;
+        
+    switch(igmpheader->type)
+    { 
+	case IGMP_HOST_MEMBERSHIP_REPORT:
+	case IGMPV2_HOST_MEMBERSHIP_REPORT:	
+	    IGMPSDEBUG(KERN_INFO "\n\nIGMP snoop: %s JOIN (if=\"%s\", group=%u.%u.%u.%u, port=%d, vlanDB=%d)\n",
+		(igmpheader->type == IGMP_HOST_MEMBERSHIP_REPORT) ? "IGMPv1" : "IGMPv2",
+		 skb->dev->name, NIPQUAD(igmp_addr), port, vlan_dbnum);
+			
+	    /* If the DB (linked list) is empty, create it and add the MAC node  */
+	    if (list_empty(&ipm_llist)) {
+		IGMPSDEBUG(KERN_INFO "IGMP snoop: Empty MAC node list \n");
+		if (_igmp_add_mac_node(temp_mac_addr, vlan_dbnum, igmp_addr, port) != 0) {
+		    printk(KERN_ERR "IGMP snoop: Failed to add MAC node \n");
+		    goto out;
+		}
+	    }
+	    else {
+		/* Non-empty MAC node list */
+		l = ipm_llist.next;
+		mac_found = 0;
+
+		IGMPSDEBUG(KERN_INFO "IGMP snoop: Searching for MAC(01:00:5e:%x:%x:%x) ...\n", 
+		   temp_mac_addr[3], temp_mac_addr[4], temp_mac_addr[5]); 
+
+		/* Check all entries of the MAC node list */
+		do {
+		    mac_node_entry = list_entry(l, struct mac_node, list_node);	
+	
+		    /* Check whether the node's MAC address is equal to the current one */
+		    if (memcmp(temp_mac_addr,mac_node_entry->eth_addr,ETH_ALEN) == 0) {
+
+			IGMPSDEBUG(KERN_INFO "IGMP snoop: MAC address was found in the list\n");
+			mac_found = 1; /* MAC node was found */
+	
+			/* Now look for ip entry */
+			ip_l = mac_node_entry->ip_list.next;
+			ip_found = 0;
+	
+			/* Check all entries of the IP address list */
+			IGMPSDEBUG(KERN_INFO "IGMP snoop: Searching for IP(%u.%u.%u.%u) ...\n", NIPQUAD(igmp_addr));
+
+			do {
+			    ip_node_entry = list_entry(ip_l, struct ip_node, ip_list_node);	
+	
+			    if (ip_node_entry->ip_addr != igmp_addr) {
+				/* Another IP address was found, continue */	
+				ip_l = ip_l->next;
+			    }
+			    else {
+				/* Current IP address is already in the list */
+				IGMPSDEBUG(KERN_INFO "IGMP snoop: IP address was found in the list\n");
+				ip_found = 1;
+	
+				/* Check whether the port bit is already set in the IP node bitmap */
+				if ((ip_node_entry->ip_port_bitmap & temp_port_bitmap) == 0) {
+				    IGMPSDEBUG(KERN_INFO "IGMP snoop: Port %d is not yet set in IP entry port bitmap\n", port);
+
+				    /* Bit is not set, add a new port to ip entry*/
+				    ip_node_entry->ip_port_bitmap |= temp_port_bitmap;
+	
+				    /* Check whether there is a need to update the MAC entry ? */
+				    if ((mac_node_entry->port_bitmap & temp_port_bitmap) == 0) {
+					/* Bit is not set yet and therefore the switch was not instructed */	
+					mac_node_entry->port_bitmap |= temp_port_bitmap;
+	
+					/* Instruct the switch to add the MAC address + port */
+					IGMPSDEBUG(KERN_INFO "IGMP snoop: Add port (%d) and MAC address (01:00:5e:%d:%d:%d) to switch DB (dbnum=%d)\n", 
+					   port, mac_node_entry->eth_addr[3], mac_node_entry->eth_addr[4], mac_node_entry->eth_addr[5],vlan_dbnum);
+
+					if (mv_gtw_set_mac_addr_to_switch(temp_mac_addr, vlan_dbnum, mac_node_entry->port_bitmap, 1) != 0)
+					    printk(KERN_ERR "IGMP snoop: mv_gtw_set_mac_addr_to_switch() failed \n");
+				    }
+				}
+			    }
+			} while((ip_l != &mac_node_entry->ip_list) && (ip_found==0));
+		
+			/* Check whether the IP node was found */
+			if (ip_found == 0) {
+			    /* Add a new ip node */
+			    _ip_node *new_ip_node;
+						
+			    IGMPSDEBUG(KERN_INFO "IGMP snoop: Add a new IP node to the list (ip=%u.%u.%u.%u port=%d)\n",NIPQUAD(igmp_addr),port);
+
+			    new_ip_node = kmalloc(sizeof(_ip_node), GFP_KERNEL);
+			    if (new_ip_node == NULL) {
+			    	printk(KERN_ERR "IGMP snoop: out-of-memory\n");
+				goto out;
+			    }
+	
+			    /* Fill the IP node with data */
+			    INIT_LIST_HEAD(&new_ip_node->ip_list_node);
+			    new_ip_node->ip_addr = igmp_addr;
+			    new_ip_node->ip_port_bitmap = temp_port_bitmap;
+	
+			    list_add_tail(&new_ip_node->ip_list_node, &mac_node_entry->ip_list);
+	
+			    /* if need to update the mac entry ? */
+			    if ((mac_node_entry->port_bitmap & temp_port_bitmap) == 0) {
+				mac_node_entry->port_bitmap |= temp_port_bitmap;
+				/* Instruct the switch to add the MAC address + port */
+				IGMPSDEBUG(KERN_INFO "IGMP snoop: Add port (%d) and MAC address (01:00:5e:%d:%d:%d) to switch DB (dbnum=%d)\n", 
+				   port,mac_node_entry->eth_addr[3], mac_node_entry->eth_addr[4], mac_node_entry->eth_addr[5],vlan_dbnum);
+
+				if (mv_gtw_set_mac_addr_to_switch(temp_mac_addr,vlan_dbnum,mac_node_entry->port_bitmap, 1) != 0)
+					printk(KERN_ERR "IGMP snoop: mv_gtw_set_mac_addr_to_switch() failed \n");
+			    }
+			}    /* if (ip_found == 0)  */
+		    }  /* if (memcmp(temp_mac_addr,mac_node_entry->eth_addr,ETH_ALEN) == 0)  */
+
+		    else {
+			/* Another MAC address is found in the MAC node linked list */
+			l = l->next;
+		    }
+		} while ((l != &ipm_llist) && (mac_found == 0));
+	
+		/* If the MAC entry was not found, than add a mac entry to the DB */
+		if (mac_found == 0) {
+		    if (_igmp_add_mac_node(temp_mac_addr, vlan_dbnum, igmp_addr, port) != 0) {
+			printk(KERN_ERR "Failed to add MAC node \n");
+			goto out;
+		    }
+		}
+	    }
+	    break;
+
+	case IGMP_HOST_LEAVE_MESSAGE:
+	    IGMPSDEBUG(KERN_INFO "\n\nIGMP snoop: IGMPv2 LEAVE (if=\"%s\", group=%u.%u.%u.%u, port=%d, vlanDB=%d)\n",
+	    skb->dev->name, NIPQUAD(igmp_addr), port, vlan_dbnum);
+
+	    /* Nothing to be done if the MAC node list is empty*/
+	    if (list_empty(&ipm_llist))
+		break;
+	
+	    /* Search for the MAC address in the list */
+	    IGMPSDEBUG(KERN_INFO "IGMP snoop: Searching for MAC(01:00:5e:%x:%x:%x) ...\n", 
+	    temp_mac_addr[3], temp_mac_addr[4], temp_mac_addr[5]); 
+	    l = ipm_llist.next;
+	    mac_found = 0;
+
+	    do {
+		mac_node_entry = list_entry(l, struct mac_node, list_node);
+
+		if (memcmp(temp_mac_addr, mac_node_entry->eth_addr, ETH_ALEN) == 0) {
+
+		    /* MAC address match */
+		    IGMPSDEBUG(KERN_INFO "IGMP snoop: MAC address was found in the list\n");
+		    mac_found = 1;
+		
+		    /* Now look for the IP entry */
+		    ip_l = mac_node_entry->ip_list.next;
+		    ip_found = 0;
+		    ip_port_found = 0;
+
+		    /* First of all, check whether the common bitamp has this bit set */
+		    if ((mac_node_entry->port_bitmap & temp_port_bitmap) != 0) {
+
+			IGMPSDEBUG(KERN_INFO "IGMP snoop: Searching for IP(%u.%u.%u.%u) ...\n", NIPQUAD(igmp_addr));
+								
+			do {
+			    ip_node_entry = list_entry(ip_l, struct ip_node, ip_list_node);
+						
+			    if (ip_node_entry->ip_addr != igmp_addr) {
+				/* Another IP multicast address but need to check if the port to be  */
+				/* removed is set. */ 
+				IGMPSDEBUG(KERN_INFO "IGMP snoop: Port %d is used by IP(%u.%u.%u.%u) ...\n", 
+				    port, NIPQUAD(ip_node_entry->ip_addr)); 
+
+				/* check if the port to be removed is present in the IP entry bitmap */	
+				if((ip_node_entry->ip_port_bitmap & temp_port_bitmap) != 0) {
+				    ip_port_found = 1;
+				}
+			    }
+
+			    else {
+				/* The multicast IP address to remove was found */
+				IGMPSDEBUG(KERN_INFO "IGMP snoop: IP address was found in the list\n");
+				ip_found = 1;
+		
+				/* Check whether the port is set in the IP entry bitmap */
+				if ((ip_node_entry->ip_port_bitmap & temp_port_bitmap) != 0) {
+				    /* Remove the port from the IP entry's bitmap */
+				    ip_node_entry->ip_port_bitmap &= ~temp_port_bitmap;
+			
+				    /* If there are no more bits set to 1, delete the IP entry node */
+				    if (ip_node_entry->ip_port_bitmap == 0) {
+					IGMPSDEBUG(KERN_INFO "IGMP snoop: Last port on IP node, delete the IP entry\n");
+					ip_l = ip_l->next;
+			
+					list_del(&ip_node_entry->ip_list_node);
+			
+					/* MUST FREE MEMORY */
+					kfree(ip_node_entry);
+					continue;
+				    }
+				}
+			    }
+		
+			    ip_l = ip_l->next;
+		
+			} while (ip_l != &mac_node_entry->ip_list); /* walkthrough of IP list */
+		
+		    }
+
+		    /* Check whether we need to update the MAC entry */
+		    if ((ip_found == 1) && (ip_port_found == 0)) {
+			/* If the port to remove is not associated with any IP address, */
+			/* instruct the switch component to remove it */
+			if ((mac_node_entry->port_bitmap & temp_port_bitmap) != 0) {
+			    mac_node_entry->port_bitmap ^= temp_port_bitmap;
+		
+			    /* Send the command to the switch */
+			    IGMPSDEBUG(KERN_INFO "IGMP snoop: Send port bitmap (0x%x) and MAC address (01:00:5e:%d:%d:%d) to switch DB (dbnum=%d)\n", 
+			    mac_node_entry->port_bitmap,mac_node_entry->eth_addr[3], mac_node_entry->eth_addr[4], mac_node_entry->eth_addr[5],vlan_dbnum);
+
+			    /* Is it the last port of the MAC entry ? */ 
+			    if (mac_node_entry->port_bitmap == 0) {
+				IGMPSDEBUG(KERN_INFO "IGMP snoop: Last port on MAC node, delete the MAC entry\n");
+
+				if (mv_gtw_set_mac_addr_to_switch(temp_mac_addr, vlan_dbnum, mac_node_entry->port_bitmap, 0) != 0)
+				    printk(KERN_ERR "IGMP snoop: mv_gtw_set_mac_addr_to_switch() failed \n");
+
+				list_del(&mac_node_entry->list_node);
+				/* MUST FREE MEMORY */
+				kfree(mac_node_entry);
+			    }
+			    else {
+				if (mv_gtw_set_mac_addr_to_switch(temp_mac_addr, vlan_dbnum, mac_node_entry->port_bitmap, 1) != 0)
+				    printk(KERN_ERR "IGMP snoop: mv_gtw_set_mac_addr_to_switch() failed \n");
+			    }
+		    	}
+		    }
+		} /* handling of the found MAC address match */
+		
+		else {
+		    l = l->next;
+		}
+	    } while ((l != &ipm_llist) && (mac_found==0));
+	
+	    break;
+	
+	default:
+	    break;	
+    }
+	
+out:
+    return 0; 
+}
+
+
+
+/* Initialization function */
+int __init mv_gtw_igmp_snoop_init(void)
+{
+    /* Enable the HW-based IGMP snooping */
+    mv_gtw_enable_igmp();
+    return 0;
+}
+
+/* Exit function */
+int __exit mv_gtw_igmp_snoop_exit(void)
+{
+    struct list_head *l, *ip_l;
+    _mac_node *node_entry;
+    _ip_node   *ip_node_entry;
+
+    /* should free all kmalloc allocated memory from llists */
+    if (list_empty(&ipm_llist))
+        goto out;
+
+    l = ipm_llist.next;
+    do
+    {
+        node_entry = list_entry(l, struct mac_node, list_node);
+        IGMPSDEBUG(KERN_INFO "IGMP snoop: Free MAC node (mac=01:00:5e:%x:%x:%x)\n", 
+               node_entry->eth_addr[3], node_entry->eth_addr[4], node_entry->eth_addr[5]); 
+
+	/* now look for ip entry */
+        ip_l = node_entry->ip_list.next;
+        
+	do
+        {
+            ip_node_entry = list_entry(ip_l, struct ip_node, ip_list_node);
+            IGMPSDEBUG(KERN_INFO "IGMP snoop: 	Free IP node (ip=%d.%d.%d.%d)\n", 
+					   NIPQUAD(ip_node_entry->ip_addr));
+                         
+            ip_l = ip_l->next;
+            list_del(&ip_node_entry->ip_list_node);
+
+             /* MUST FREE MEMORY */
+            kfree(ip_node_entry);
+	    
+        }while(ip_l != &node_entry->ip_list); /* walkthrough of IP list */
+
+	l = l->next;
+        
+	list_del(&node_entry->list_node);
+        kfree(node_entry);
+
+    }while(l != &ipm_llist);
+
+out:
+    IGMPSDEBUG(KERN_INFO "IGMP snoop: Exit completed\n");
+    
+    return 0;
+}
+
+/* Add a new MAC node to the list of multicast MAC address structures */
+static int _igmp_add_mac_node(	unsigned char	temp_mac_addr[ETH_ALEN],
+				unsigned char	vlan_dbnum,
+				__u32		igmp_addr,
+				__u32		port)
+{
+	/* should use label , or shorten the code in any other way, I know!!! */
+	_mac_node *new_mac_node;	
+	_ip_node  *new_ip_node;
+
+	IGMPSDEBUG(KERN_INFO "IGMP snoop: Add a new MAC node (mac=01:00:5e:%x:%x:%x, ip=%d.%d.%d.%d, port=%d)\n", 
+				temp_mac_addr[3], temp_mac_addr[4], temp_mac_addr[5], NIPQUAD(igmp_addr), port);
+
+	/* Allocate the memory chunk for the MAC node */
+	new_mac_node = kmalloc(sizeof(_mac_node), GFP_KERNEL);
+	if (new_mac_node == NULL) 
+	{
+		printk(KERN_ERR "out-of-memory\n");
+		return -ENOMEM;
+	}
+
+	/* Initialize the list node */
+	INIT_LIST_HEAD(&new_mac_node->list_node);
+
+	/* Copy the MAC address and port bitmap */
+	memcpy(new_mac_node->eth_addr, temp_mac_addr, ETH_ALEN);
+	new_mac_node->port_bitmap = (1 << port);
+
+	/* Init the head of the IP address list */
+	INIT_LIST_HEAD(&new_mac_node->ip_list);
+
+	/* Create the first element of the IP address list */
+	new_ip_node = kmalloc(sizeof(_ip_node), GFP_KERNEL);
+	if (new_ip_node == NULL) 
+	{
+		printk(KERN_ERR "out-of-memory\n");
+		kfree(new_mac_node);
+		return -ENOMEM;
+	}
+
+	/* Fill the IP address element with data */
+	INIT_LIST_HEAD(&new_ip_node->ip_list_node);	
+	new_ip_node->ip_addr = igmp_addr;
+	new_ip_node->ip_port_bitmap = (1 << port);
+
+	/* Add the IP address element to the list */
+	list_add_tail(&new_ip_node->ip_list_node, &new_mac_node->ip_list);
+
+	/* Add the MAC node element to the list */
+	list_add_tail(&new_mac_node->list_node, &ipm_llist);
+
+	/* Instruct the network driver to add the corresponding entry to the switch table */
+	mv_gtw_set_mac_addr_to_switch(temp_mac_addr, vlan_dbnum, new_mac_node->port_bitmap, 1);
+
+	return 0;
+}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.c
new file mode 100644
index 0000000..1abec53
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.c
@@ -0,0 +1,3637 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+
+#include "mvCommon.h"  /* Should be included before mvSysHwConfig */
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/platform_device.h>
+#include <linux/skbuff.h>
+#include <linux/pci.h>
+#include <linux/ip.h>
+#include <linux/in.h>
+#include <linux/tcp.h>
+#include <net/ip.h>
+#include <net/xfrm.h>
+
+#include "mvOs.h"
+#include "dbg-trace.h"
+#include "mvSysHwConfig.h"
+#include "eth/mvEth.h"
+#include "eth/gbe/mvEthGbe.h"
+#include "eth-phy/mvEthPhy.h"
+#include "mvSysEthApi.h"
+
+#include "boardEnv/mvBoardEnvLib.h"
+
+#ifdef CONFIG_MV_CPU_PERF_CNTRS__ETH
+#include "cpu/mvCpuCntrs.h"
+MV_CPU_CNTRS_EVENT* hal_rx_event = NULL;
+MV_CPU_CNTRS_EVENT* empty_event = NULL;
+MV_CPU_CNTRS_EVENT* routing_event = NULL; 
+#endif /* CONFIG_MV_CPU_PERF_CNTRS__ETH */
+
+#include "mv_netdev.h"
+#ifdef ETH_LRO
+#include <linux/inetdevice.h>
+#endif
+
+static int __init mv_eth_init_module( void );
+static void __exit mv_eth_exit_module( void );
+module_init( mv_eth_init_module );
+module_exit( mv_eth_exit_module);
+MODULE_DESCRIPTION("Marvell Ethernet Driver - www.marvell.com");
+MODULE_AUTHOR("Dmitri Epshtein <dima@marvell.com>");
+MODULE_LICENSE("GPL");
+
+extern u8 mvMacAddr[CONFIG_MV_ETH_PORTS_NUM][6];
+extern u16 mvMtu[CONFIG_MV_ETH_PORTS_NUM];
+
+int     mv_eth_rxq_desc[MV_ETH_RX_Q_NUM];
+int     mv_eth_txq_desc[MV_ETH_TX_Q_NUM];
+
+int     mv_eth_rx_desc_total = 0;
+int     mv_eth_tx_desc_total = 0;
+
+int     mv_eth_tx_done_quota = 16;
+
+mv_eth_priv**       mv_eth_ports;
+int                 mv_eth_ports_num = 0;
+
+struct net_device** mv_net_devs;
+int                 mv_net_devs_num = 0;
+
+int	mv_gtw_dev_offset = 0;
+
+spinlock_t          mii_lock = SPIN_LOCK_UNLOCKED;
+spinlock_t          nfp_lock = SPIN_LOCK_UNLOCKED;
+
+void eth_print_irq_status(mv_eth_priv *priv);
+
+u32 eth_dbg = ETH_DBG_OFF;
+
+static struct platform_device *mv_plat_dev;
+
+static int mv_eth_probe(struct platform_device *pdev)
+{
+	mv_plat_dev = pdev;
+	return 0;
+}
+
+static struct platform_driver mv_eth_driver = {
+	.probe	=	mv_eth_probe,
+	.driver	=	{.name = "mv88fx_eth",},
+};
+
+
+/***********************************************************************************
+ ***  get device by index
+ ***********************************************************************************/
+static struct net_device* eth_net_device_by_idx(unsigned int idx) 
+{
+    if(idx >= mv_net_devs_num)    
+    {
+        printk("No net_device for index %d\n", idx);
+        return NULL;
+    }
+    return mv_net_devs[idx];
+}
+
+/***********************************************************************************
+ ***  get device first ip address
+ ***********************************************************************************/
+#ifdef ETH_LRO
+static INLINE unsigned int mv_eth_dev_ip(struct net_device *dev)
+{
+	struct in_device *ip = dev->ip_ptr;
+	if (ip && ip->ifa_list)
+		return ip->ifa_list->ifa_address;
+
+	return 0;
+
+}
+#endif
+/***********************************************************************************
+ ***  get eth_priv structure by port number
+ ***********************************************************************************/
+static INLINE mv_eth_priv*     eth_priv_by_port(unsigned int port)
+{
+    if(port >= mv_eth_ports_num)    
+    {
+        printk("No eth device for port %d\n", port);
+        return NULL;
+    }
+    return mv_eth_ports[port];
+}
+
+
+static void eth_print_link_status( struct net_device *dev ) 
+{
+    mv_eth_priv *priv = MV_ETH_PRIV(dev);
+    int         port = priv->port;
+    u32         port_status;
+
+    port_status = MV_REG_READ( ETH_PORT_STATUS_REG( port ) );
+    if(port_status & ETH_LINK_UP_MASK)
+    {
+	    printk( KERN_NOTICE "%s: link up", dev->name );
+
+        /* check port status register */
+        printk(", %s",(port_status & ETH_FULL_DUPLEX_MASK) ? "full duplex" : "half duplex" );
+
+        if( port_status & ETH_GMII_SPEED_1000_MASK ) 
+	        printk(", speed 1 Gbps" );
+        else 
+            printk(", %s", (port_status & ETH_MII_SPEED_100_MASK) ? "speed 100 Mbps" : "speed 10 Mbps" );
+	    printk("\n" );
+    }
+    else {
+	    printk( KERN_NOTICE "%s: link down\n", dev->name );
+    }
+}
+
+static int eth_get_config(u32 netdev, MV_U8* mac_addr)
+{
+    char*   mac_str = NULL;
+    u8      zero_mac[ETH_ALEN] = {0x00, 0x00, 0x00, 0x00, 0x00, 0x00};
+    int     mtu;
+
+    switch(netdev)
+    {
+        case 0:
+	    if (mvMtu[0] != 0)
+		mtu = mvMtu[0];
+            else
+		mtu = CONFIG_MV_ETH_0_MTU;
+	    /* use default MAC address from Kconfig only if the MAC address we got is all 0 */
+	    if (memcmp(mvMacAddr[0], zero_mac, ETH_ALEN) == 0)
+            	mac_str = CONFIG_MV_ETH_0_MACADDR; 
+	    else
+		memcpy(mac_addr, mvMacAddr[0], ETH_ALEN);
+            break;
+
+#if (CONFIG_MV_ETH_PORTS_NUM > 1)
+        case 1:
+	    if (mvMtu[1] != 0)
+		mtu = mvMtu[1];
+            else
+		mtu = CONFIG_MV_ETH_1_MTU;
+	    /* use default MAC address from Kconfig only if the MAC address we got is all 0 */
+	    if (memcmp(mvMacAddr[1], zero_mac, ETH_ALEN) == 0)
+            	mac_str = CONFIG_MV_ETH_1_MACADDR;
+	    else
+		memcpy(mac_addr, mvMacAddr[1], ETH_ALEN);
+            break;
+#endif /* CONFIG_MV_ETH_PORTS_NUM > 1 */
+
+#if (CONFIG_MV_ETH_PORTS_NUM > 2)
+        case 2:
+	    if (mvMtu[2] != 0)
+		mtu = mvMtu[2];
+            else
+		mtu = CONFIG_MV_ETH_2_MTU;
+	    /* use default MAC address from Kconfig only if the MAC address we got is all 0 */
+	    if (memcmp(mvMacAddr[2], zero_mac, ETH_ALEN) == 0)
+            	mac_str = CONFIG_MV_ETH_2_MACADDR;
+	    else
+		memcpy(mac_addr, mvMacAddr[2], ETH_ALEN);
+            break;
+#endif /* CONFIG_MV_ETH_PORTS_NUM > 2 */
+
+#if (CONFIG_MV_ETH_PORTS_NUM > 3)
+        case 3:
+	    if (mvMtu[3] != 0)
+		mtu = mvMtu[3];
+            else
+		mtu = CONFIG_MV_ETH_3_MTU;
+	    /* use default MAC address from Kconfig only if the MAC address we got is all 0 */
+	    if (memcmp(mvMacAddr[3], zero_mac, ETH_ALEN) == 0)
+            	mac_str = CONFIG_MV_ETH_3_MACADDR;
+	    else
+		memcpy(mac_addr, mvMacAddr[3], ETH_ALEN);
+            break;
+#endif /* CONFIG_MV_ETH_PORTS_NUM > 3 */
+
+        default:
+            printk("eth_get_config: Unexpected port number %d\n", netdev);
+            return -1;
+    }
+    if ((mac_str != NULL) && (mac_addr != NULL))
+            mvMacStrToHex(mac_str, mac_addr);
+
+    return mtu;
+}
+
+static void eth_print_rx_errors(MV_U32 pkt_status)
+{
+    switch(pkt_status & ETH_RX_ERROR_CODE_MASK)
+    {
+        case ETH_RX_CRC_ERROR:
+            printk("bad rx status %08x, (crc error)", (unsigned int)pkt_status);
+            break;
+
+        case ETH_RX_OVERRUN_ERROR:
+            printk("bad rx status %08x, (overrun error)", (unsigned int)pkt_status);
+            break;
+
+        case ETH_RX_MAX_FRAME_LEN_ERROR:
+            printk("bad rx status %08x, (max frame length error)", (unsigned int)pkt_status);
+            break;
+
+        case ETH_RX_RESOURCE_ERROR:
+            printk("bad rx status %08x, (resource error)", (unsigned int)pkt_status);
+            break;
+    }
+    printk("\n");
+}
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+static inline int mv_eth_skb_check(struct sk_buff *skb, int skb_size)
+{
+    if (atomic_read(&skb->users) != 1)
+		return 0;
+
+	if (skb_cloned(skb))
+		return 0;
+
+	if ((skb_shinfo(skb))->nr_frags)
+		return 0;
+
+	if (skb->data_len) 
+		return 0;
+
+    skb_size = SKB_DATA_ALIGN(skb_size + NET_SKB_PAD);
+    if( (skb->end - skb->head) < skb_size)
+		return 0;
+
+    return 1;
+}
+#endif /* LINUX_VERSION_CODE < 2.6.24 */
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+int eth_skb_recycle_enable = CONFIG_NET_SKB_RECYCLE_DEF;
+static void eth_skb_recycle_clear(mv_eth_priv* priv)
+{
+	struct sk_buff *skb;
+
+	priv->skbRecycleMTU = 0;
+
+    while (!mvStackIsEmpty(priv->skbRecyclePool)) {
+		skb = (struct sk_buff*)mvStackPop(priv->skbRecyclePool);
+		skb->skb_recycle = NULL;
+        dev_kfree_skb_any(skb);
+		ETH_STAT_DBG(priv->eth_stat.skb_recycle_del++);
+    }
+}
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+static inline void mv_eth_skb_recycle_reset(struct sk_buff *skb)
+{
+    /* Reset skb before reuse */
+    skb_shinfo(skb)->gso_size = 0;
+ 
+    skb->dst = NULL;
+    skb->destructor = NULL;
+
+#if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
+    skb->nfct = 0;
+    skb->nfct_reasm = 0;
+#endif /* CONFIG_NF_CONNTRACK || CONFIG_NF_CONNTRACK_MODULE */
+
+#ifdef CONFIG_BRIDGE_NETFILTER
+    skb->nf_bridge = 0;
+#endif /* CONFIG_BRIDGE_NETFILTER */
+
+    skb->truesize = (skb->end - skb->head) + sizeof(struct sk_buff);
+    skb->next = NULL;
+    skb->pkt_type = 0; 
+    skb->iif = 0;
+    skb->sk = 0; 
+    skb->len = 0;
+    skb->data = skb->tail = skb->head + NET_SKB_PAD; 
+
+    return;
+}
+#endif /* LINUX_VERSION_CODE < 2.6.24 */
+
+static int eth_skb_recycle(struct sk_buff *skb)
+{
+    mv_eth_priv *priv = (mv_eth_priv*)skb->hw_cookie;
+    unsigned long flags = 0;
+
+    if (!eth_skb_recycle_enable)
+        goto out;
+
+	if (!priv->skbRecycleMTU)
+		priv->skbRecycleMTU = MV_RX_BUF_SIZE(priv->net_dev->mtu) + CPU_D_CACHE_LINE_SIZE + 8;
+
+	if (unlikely(mvStackIsFull(priv->skbRecyclePool))) {
+		ETH_STAT_DBG(priv->eth_stat.skb_recycle_full++);
+		goto out;
+	}
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    if (mv_eth_skb_check(skb, priv->skbRecycleMTU)) {
+        mv_eth_skb_recycle_reset(skb);
+#else
+    if (skb_recycle_check(skb, priv->skbRecycleMTU)) {
+#endif /* LINUX_VERSION_CODE < 2.6.24 */
+
+	spin_lock_irqsave(priv->lock, flags);
+
+      	ETH_STAT_DBG(priv->eth_stat.skb_recycle_put++);
+        skb->skb_recycle = eth_skb_recycle;
+        skb->hw_cookie = priv;
+
+	mvStackPush(priv->skbRecyclePool, (MV_U32)skb);
+        spin_unlock_irqrestore(priv->lock, flags);    
+        return 0;
+    }
+
+out:
+	ETH_STAT_DBG(priv->eth_stat.skb_recycle_rej++);
+	return 1;
+}
+#endif
+
+static INLINE struct sk_buff* eth_skb_alloc(mv_eth_priv *priv, MV_PKT_INFO* pPktInfo,
+                                            int mtu)
+{
+    int             buf_size;
+    struct sk_buff  *skb;
+
+    /* allocate new skb */
+    /* 32(extra for cache prefetch) + 8 to align on 8B */
+    buf_size = MV_RX_BUF_SIZE(mtu) + CPU_D_CACHE_LINE_SIZE  + 8;
+#ifdef CONFIG_NET_SKB_RECYCLE
+	if (!mvStackIsEmpty(priv->skbRecyclePool)) {
+		skb = (struct sk_buff*)mvStackPop(priv->skbRecyclePool);
+		ETH_STAT_DBG(priv->eth_stat.skb_recycle_get++);
+		/* FIXME: check size */
+	}
+	else
+#endif /* CONFIG_NET_SKB_RECYCLE */
+		skb = dev_alloc_skb( buf_size ); 
+
+    if (!skb) {
+        ETH_DBG( ETH_DBG_RX_FILL, ("%s: rx_fill cannot allocate skb\n", dev->name) );
+        ETH_STAT_ERR(priv->eth_stat.skb_alloc_fail++);
+        return NULL;
+    }
+#ifdef CONFIG_NET_SKB_RECYCLE
+    skb->skb_recycle = eth_skb_recycle;
+    skb->hw_cookie = priv;
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+    ETH_STAT_DBG(priv->eth_stat.skb_alloc_ok++);
+
+    /* align the buffer on 8B */
+    if( (unsigned long)(skb->data) & 0x7 ) {
+        skb_reserve( skb, 8 - ((unsigned long)(skb->data) & 0x7) );
+    }
+        
+    /* Most of PktInfo and BufInfo parameters left unchanged */
+    pPktInfo->osInfo = (MV_ULONG)skb;
+    pPktInfo->pFrags->bufSize = MV_RX_BUF_SIZE( mtu);
+    pPktInfo->pktSize = pPktInfo->pFrags->bufSize;
+    pPktInfo->pFrags->bufPhysAddr = mvOsIoVirtToPhy(NULL, skb->data);
+    pPktInfo->pFrags->bufVirtPtr = skb->data;
+	
+	return skb;
+} 
+
+#ifdef CONFIG_MV_ETH_SKB_REUSE
+int eth_skb_reuse_enable = CONFIG_MV_ETH_SKB_REUSE_DEF;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+static INLINE void  eth_skb_reuse_reset(struct sk_buff *skb)
+{
+    /* Taken from __kfree_skb() */
+    dst_release(skb->dst);
+    skb->dst = NULL;
+
+#ifdef CONFIG_XFRM
+    secpath_put(skb->sp);
+#endif /* CONFIG_XFRM */ 
+
+    if (skb->destructor) {
+            WARN_ON(in_irq());
+            skb->destructor(skb);
+            skb->destructor = NULL;
+    }
+
+#if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
+    if(skb->nfct)
+    {
+        nf_conntrack_put(skb->nfct);
+        skb->nfct = 0;
+    }
+    if(skb->nfct_reasm)
+    {
+        nf_conntrack_put_reasm(skb->nfct_reasm);
+        skb->nfct_reasm = 0;
+    }
+#endif /* CONFIG_NF_CONNTRACK || CONFIG_NF_CONNTRACK_MODULE */
+
+#ifdef CONFIG_BRIDGE_NETFILTER
+        nf_bridge_put(skb->nf_bridge);
+        skb->nf_bridge = 0;
+#endif /* CONFIG_BRIDGE_NETFILTER */
+/* XXX: IS this still necessary? - JHS */
+#ifdef CONFIG_NET_SCHED
+        skb->tc_index = 0;
+#ifdef CONFIG_NET_CLS_ACT
+        skb->tc_verd = 0;
+#endif /* CONFIG_NET_CLS_ACT */
+#endif /* CONFIG_NET_SCHED */
+
+  	skb->truesize = (skb->end - skb->head) + sizeof(struct sk_buff);
+
+	skb->next = NULL;
+    skb->pkt_type = 0; 
+    skb->iif = 0;
+    skb->sk = 0; 
+    skb->len = 0;
+
+    skb->data = skb->tail = skb->head + NET_SKB_PAD;
+
+    /* align the buffer on 8B */
+    if( (unsigned long)(skb->data) & 0x7 ) {
+        skb_reserve( skb, 8 - ((unsigned long)(skb->data) & 0x7) );
+    }
+}
+#endif /* LINUX_VERSION_CODE < 2.6.24 */
+
+
+
+static INLINE mv_eth_priv* eth_skb_reusable(struct sk_buff *skb)
+{
+    int         i, skb_size;
+    mv_eth_priv *priv = NULL;
+
+    if( (!eth_skb_reuse_enable) )
+        return NULL;
+
+    for(i=0; i<mv_eth_ports_num; i++)
+    {
+        priv = mv_eth_ports[i];
+
+	    if (priv == NULL) 
+            continue;
+
+        if(mvStackIndex(priv->skbReusePool) == 0)
+            continue;
+
+    skb_size = MV_RX_BUF_SIZE( priv->net_dev->mtu) + CPU_D_CACHE_LINE_SIZE + 8;
+    
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+        if( mv_eth_skb_check(skb, skb_size) ) {
+            eth_skb_reuse_reset(skb);
+#else
+        if(skb_recycle_check(skb, skb_size) ) {
+#endif /* LINUX_VERSION_CODE <  2.6.24 */
+            return priv;
+        }
+    }
+    return NULL;
+}
+
+
+static INLINE void eth_skb_alloc_for_reuse(mv_eth_priv *priv, int mtu)
+{
+    int             idx;
+    MV_PKT_INFO     *pPktInfo = NULL;
+    struct sk_buff  *skb;
+
+    idx = mvStackIndex(priv->skbReusePool);
+    while(idx > 0)
+    {
+        ETH_STAT_DBG(priv->eth_stat.skb_reuse_alloc++);
+        pPktInfo = (MV_PKT_INFO*)mvStackPop(priv->skbReusePool);
+        idx--;
+
+        skb = eth_skb_alloc(priv, pPktInfo, mtu);
+        if(skb == NULL)
+        {
+            /* return PktInfo to Pool */
+            mvStackPush(priv->skbReusePool, (MV_U32)pPktInfo);
+            break;
+        }
+        mvStackPush(priv->fpRxPool, (MV_U32)pPktInfo);
+    }
+}
+#endif /* CONFIG_MV_ETH_SKB_REUSE */
+
+#if defined(CONFIG_MV_ETH_NFP) || defined(CONFIG_MV_ETH_SKB_REUSE)
+static INLINE MV_PKT_INFO* eth_pkt_info_get(mv_eth_priv  *priv)
+{
+    if(mvStackIndex(priv->fpRxPool) > 0)
+        return (MV_PKT_INFO*)mvStackPop(priv->fpRxPool);
+
+    return NULL;
+}
+#endif /* CONFIG_MV_ETH_NFP || CONFIG_MV_ETH_SKB_REUSE */
+
+INLINE void  eth_pkt_info_free(mv_eth_priv *priv, MV_PKT_INFO* pPktInfo)
+{
+#if defined(CONFIG_MV_ETH_NFP_PPP) || defined(CONFIG_MV_ETH_NFP_SEC)
+		MV_BUF_INFO *pBuf = pPktInfo->pFrags;
+		if (pBuf->bufAddrShift) {
+			pBuf->bufPhysAddr += pBuf->bufAddrShift;
+			pBuf->bufVirtPtr += pBuf->bufAddrShift;
+			pBuf->bufAddrShift = 0;
+		}
+#endif
+
+#ifdef CONFIG_MV_ETH_NFP
+    if(pPktInfo->ownerId != ~0)
+    {
+        mv_eth_priv  *src_priv = mv_eth_ports[(int)pPktInfo->ownerId];
+
+        /* Return to the NFP pool */
+#ifdef CONFIG_MV_GATEWAY
+        if(!priv->isGtw)
+		    pPktInfo->pFrags->bufPhysAddr -= ETH_MV_HEADER_SIZE;
+#else
+        pPktInfo->pFrags->bufPhysAddr -= ETH_MV_HEADER_SIZE;
+#endif /* CONFIG_MV_GATEWAY */
+/*
+	// for debug:
+	mvEthRxDoneTest(pPktInfo->pFrags, CONFIG_NET_SKB_HEADROOM);
+*/
+        mvStackPush(src_priv->fpRxPool, (MV_U32)pPktInfo);
+	return;
+    }
+#endif /* CONFIG_MV_ETH_NFP */
+
+    if(pPktInfo->osInfo)
+    {
+        struct sk_buff *skb = (struct sk_buff *)pPktInfo->osInfo;
+
+#ifdef CONFIG_MV_ETH_SKB_REUSE
+        mv_eth_priv  *rx_priv = eth_skb_reusable(skb);
+
+        if( rx_priv != NULL)
+        {
+            MV_PKT_INFO*    pkt_info = NULL;
+
+            ETH_STAT_DBG(rx_priv->eth_stat.skb_reuse_tx++);
+            pkt_info = (MV_PKT_INFO*)mvStackPop(rx_priv->skbReusePool);
+
+            pkt_info->osInfo = (MV_ULONG)skb;
+            pkt_info->pktSize = pkt_info->pFrags->bufSize;
+            pkt_info->pFrags->bufPhysAddr = mvOsIoVirtToPhy(NULL, skb->data);
+            pkt_info->pFrags->bufVirtPtr = skb->data;
+
+            mvStackPush(rx_priv->fpRxPool, (MV_U32)pkt_info);
+            pPktInfo->osInfo = 0;
+            mvStackPush(priv->txPktInfoPool, (MV_U32)pPktInfo);
+            return;
+        }
+#endif /* CONFIG_MV_ETH_SKB_REUSE */
+
+        dev_kfree_skb_any(skb);
+        ETH_STAT_DBG(priv->eth_stat.skb_free_ok++);
+        pPktInfo->osInfo = 0;
+    }
+    mvStackPush(priv->txPktInfoPool, (MV_U32)pPktInfo);
+}
+/**************************************************************************************************************/
+
+
+#ifdef ETH_MV_TX_EN
+void    eth_tx_en_config(int port, int value)
+{
+    MV_U32          port_status = 0;
+    mv_eth_priv     *priv = eth_priv_by_port(port);
+
+    if (priv == NULL)
+    {
+        printk("eth_tx_en_config: wrong port number %d\n", port);
+	    return;
+    }
+
+    if(value == 0)
+    {
+        /* Disable TX_EN support */
+        priv->tx_en_bk = priv->tx_en = MV_FALSE;
+    }
+    else
+    {
+        /* Enable TX_EN support if possible: Link is Down or Duplex != Half or Speed != 10 Mbps */
+        priv->tx_en_deep = value;
+        priv->tx_en_bk = MV_TRUE;
+
+        /* Check ethernet port status */
+        port_status = MV_REG_READ( ETH_PORT_STATUS_REG( port ) );
+        if( !(port_status & ETH_LINK_UP_MASK) || 
+             (port_status & ETH_FULL_DUPLEX_MASK) ||
+             (port_status & ETH_GMII_SPEED_1000_MASK) ||
+             (port_status & ETH_MII_SPEED_100_MASK) )
+            priv->tx_en = MV_TRUE;
+    }
+    printk("GbE port %d: TxEnable WA - %s, deep=%d, tx_en_bk=%d\n\n", 
+            priv->port, priv->tx_en ? "Enabled" : "Disabled", 
+            priv->tx_en_deep, priv->tx_en_bk);    
+}
+
+static INLINE void  eth_tx_enable(mv_eth_priv *priv, int queue)
+{
+    int             ret;
+
+    ret = mvEthPortTxEnable(priv->hal_priv, queue, priv->tx_en_deep);
+    if(ret < 0)
+    {
+        ETH_STAT_DBG(priv->eth_stat.tx_en_busy++);
+    }
+    else 
+    {
+        if(ret > 0)
+        {
+            ETH_STAT_DBG(priv->eth_stat.tx_en_wait++);
+            ETH_STAT_DBG(priv->eth_stat.tx_en_wait_count += ret);
+        }        
+        else
+        {
+            ETH_STAT_DBG(priv->eth_stat.tx_en_done++);
+        }
+    }
+}
+#endif /* ETH_MV_TX_EN */
+/**************************************************************************************************************/
+
+
+
+/***********************************************************
+ * mv_eth_down_internals --                                 *
+ *   down port rx/tx activity. free skb's from rx/tx rings.*
+ ***********************************************************/
+int     mv_eth_down_internals( struct net_device *dev )
+{
+    mv_eth_priv     *priv = MV_ETH_PRIV(dev);
+    MV_PKT_INFO     *pPktInfo;
+    unsigned int    queue;
+
+    /* stop the port activity, mask all interrupts */
+    if( mvEthPortDown( priv->hal_priv ) != MV_OK ) {
+        printk( KERN_ERR "%s: ethPortDown failed\n", dev->name );
+        goto error;
+    }
+
+    /* free the skb's in the hal tx ring */
+    for(queue=0; queue<MV_ETH_TX_Q_NUM; queue++) 
+    {
+        while( (pPktInfo = mvEthPortForceTxDone(priv->hal_priv, queue)) ) 
+        {
+            eth_pkt_info_free(priv, pPktInfo);
+        }
+        priv->tx_count[queue] = 0;
+    }
+    
+    return 0;
+
+error:
+    printk( KERN_ERR "%s: stop internals failed\n", dev->name );
+    return -1;
+}
+/**************************************************************************************************************/
+
+static void eth_check_link_status(struct net_device *dev)
+{
+    mv_eth_priv     *priv = MV_ETH_PRIV(dev);
+    MV_U32          port_status = 0;
+
+        ETH_STAT_INFO(priv->eth_stat.link_events++);
+
+    	/* Check Link status on ethernet port */
+        port_status = MV_REG_READ( ETH_PORT_STATUS_REG( priv->port ) );
+
+        spin_lock(priv->lock);
+
+        if(port_status & ETH_LINK_UP_MASK) { 
+
+#ifdef ETH_MV_TX_EN
+        /* Disable TX Enable WA if one of Giga ports is Half Duplex or 10 Mbps */
+        if( ((port_status & ETH_FULL_DUPLEX_MASK) ||
+             (port_status & ETH_GMII_SPEED_1000_MASK) ||
+             (port_status & ETH_MII_SPEED_100_MASK)) )
+        {
+            priv->tx_en = priv->tx_en_bk;
+        }
+        else
+        {
+            priv->tx_en_bk = priv->tx_en;
+            priv->tx_en = MV_FALSE;
+        }
+#endif /* ETH_MV_TX_EN */
+
+            mvEthPortUp( priv->hal_priv );
+            netif_carrier_on( dev );
+            netif_wake_queue( dev );            
+        }
+    	else
+        {
+            netif_carrier_off( dev );
+            netif_stop_queue( dev );
+            mv_eth_down_internals( dev );
+        }
+
+        spin_unlock(priv->lock);
+
+   	eth_print_link_status( dev );
+}
+/**************************************************************************************************************/
+
+static INLINE int   eth_rx_policy(mv_eth_priv *priv)
+{
+    u32     rxq_map;
+
+    rxq_map = ( ( (priv->picr & ETH_RXQ_MASK) >> ETH_CAUSE_RX_READY_OFFSET) | 
+		        ( (priv->picr & ETH_RXQ_RES_MASK) >> ETH_CAUSE_RX_ERROR_OFFSET) );
+    
+    return (fls(rxq_map) - 1);
+}
+
+
+static INLINE int   eth_tx_policy(mv_eth_priv *priv, struct sk_buff *skb)
+{
+    int     queue;
+
+#if (MV_ETH_TX_Q_NUM > 1) 
+    if( ip_hdr(skb) )
+    {
+        queue = mv_eth_tos_to_q_map(ip_hdr(skb)->tos, MV_ETH_TX_Q_NUM);
+    }
+    else
+#endif /* (MV_ETH_TX_Q_NUM > 1) */
+    {
+        /* no multiqueue. all packets go to one default queue. */
+        queue = ETH_DEF_TXQ;
+    }
+
+    return queue;
+}
+/**************************************************************************************************************/
+
+
+
+/*********************************************************** 
+ * eth_tx_done --                                             *
+ *   release transmitted packets. interrupt context.       *
+ ***********************************************************/
+u32 eth_tx_done(mv_eth_priv *priv, int queue)
+{
+    MV_PKT_INFO*            pPktInfo;
+    u32                     count = 0;
+
+    ETH_DBG( ETH_DBG_TX_DONE, ("eth%d: tx-done ", priv->port) );
+    ETH_STAT_INFO(priv->eth_stat.tx_done_events++);
+
+    /* release the transmitted packets */
+    while( 1 ) 
+    {
+        /* get a packet */ 
+        pPktInfo = mvEthPortTxDone(priv->hal_priv, queue);
+        if(pPktInfo) 
+        {
+             /* handle tx error */
+            if( pPktInfo->status & (ETH_ERROR_SUMMARY_MASK) ) {
+                ETH_DBG( ETH_DBG_TX_DONE, ("GbE port %d: bad tx-done status\n", priv->port) );
+                priv->net_dev->stats.tx_errors++;
+            }
+
+            count++;
+            ETH_STAT_DBG( priv->eth_stat.tx_done_hal_ok[queue]++);
+
+            eth_pkt_info_free(priv, pPktInfo);
+            continue;
+        }
+        else 
+        {
+            /* no more work */
+            break;
+        }
+    }
+#if (MV_ETH_TX_Q_NUM == 1)
+    /* if transmission was previously stopped, now it can be restarted. */
+    if( netif_queue_stopped( priv->net_dev ) && (priv->net_dev->flags & IFF_UP) && (count > 0) ) {
+        ETH_DBG( ETH_DBG_TX_DONE, ("%s: restart transmit\n", priv->net_dev->name) );
+        ETH_STAT_ERR( priv->eth_stat.tx_done_netif_wake++);
+        netif_wake_queue( priv->net_dev );    
+    }
+#endif /* MV_ETH_TX_Q_NUM == 1 */
+
+    ETH_STAT_DBG( priv->eth_stat.tx_done_dist[count]++);
+    ETH_DBG( ETH_DBG_TX_DONE, ("GbE port %d: tx-done %d\n", priv->port, count) );
+    return count;
+}
+/**************************************************************************************************************/
+
+static INLINE int eth_rx(struct net_device *dev, unsigned int work_to_do, int queue)
+{
+    mv_eth_priv             *priv = MV_ETH_PRIV(dev);
+    struct net_device_stats	*stats = MV_NETDEV_STATS(dev);
+    struct sk_buff          *skb;
+    MV_U8                   *data;
+    MV_PKT_INFO             *pPktInfo;
+    int                     work_done = 0;
+    MV_STATUS               status;
+    struct net_device       *out_dev = NULL;
+    MV_U32		            rx_status; 
+#ifdef CONFIG_MV_ETH_NFP
+    int			            out_if_index;
+    MV_IP_HEADER            *pIpHdr;
+    int                     nfp = fp_is_enabled(); 
+#endif /* CONFIG_MV_ETH_NFP */
+
+    ETH_DBG( ETH_DBG_RX, ("%s: rx_poll work_to_do %d\n", dev->name, work_to_do) );
+
+    /* fairness NAPI loop */
+    while( work_done < work_to_do ) {
+
+        /* get rx packet */ 
+        /* MV_CPU_CNTRS_START(hal_rx_event); */
+        pPktInfo = mvEthPortRx( priv->hal_priv, queue);
+        /* check status */
+        if( pPktInfo == NULL) 
+        {
+            /* no more rx packets ready */
+            break;
+        }
+        /* MV_CPU_CNTRS_STOP(hal_rx_event); */
+        /* MV_CPU_CNTRS_SHOW(hal_rx_event); */
+
+	rx_status = pPktInfo->status;
+	if (rx_status  & (ETH_ERROR_SUMMARY_MASK)) 
+	{
+        	eth_print_rx_errors(rx_status);
+	        mvEthPortRxDone(priv->hal_priv, queue, pPktInfo);
+            	stats->rx_errors++;
+            	continue;
+	}
+	dma_unmap_single(NULL, pPktInfo->pFrags->bufPhysAddr, pPktInfo->pFrags->dataSize, 
+									DMA_FROM_DEVICE);
+	prefetch(pPktInfo->pFrags->bufVirtPtr);
+
+        work_done++;
+        ETH_STAT_DBG( priv->eth_stat.rx_hal_ok[queue]++);
+
+        /* good rx */
+        skb = (struct sk_buff *)( pPktInfo->osInfo );
+        data = (MV_U8*)skb->data;
+        ETH_DBG( ETH_DBG_RX, ("good rx: skb=%p, skb->data=%p\n", skb, skb->data) );
+
+#ifdef CONFIG_MV_GATEWAY
+        if(priv->isGtw)
+        {
+	        dev = mv_gtw_ingress_dev(data);
+	        stats = MV_NETDEV_STATS(dev);
+        }
+#endif /* CONFIG_MV_GATEWAY */
+	
+        stats->rx_packets++;
+        stats->rx_bytes += pPktInfo->pFrags->dataSize - ETH_MV_HEADER_SIZE;
+
+#ifdef CONFIG_MV_ETH_NFP
+	    if (nfp)
+	    {
+            int txq = ETH_DEF_TXQ;
+
+            out_dev = NULL;
+            pIpHdr = mvFpParsing(pPktInfo, &priv->fpStats);
+#ifndef CONFIG_MV_ETH_NFP_PPP
+            if(pIpHdr != NULL)
+#endif
+            {
+                out_if_index = mvFpProcess(dev->ifindex, pPktInfo, pIpHdr, &priv->fpStats);
+                if(out_if_index >= 0)
+                {
+                    out_dev = fp_mgr_get_net_dev(out_if_index);
+                    if(fp_mgr_get_if_type(out_if_index) == MV_FP_IF_INT)
+                    {
+                	    mv_eth_priv    *out_priv = MV_ETH_PRIV(out_dev);
+#if defined(CONFIG_MV_GATEWAY)
+                        if(out_priv->isGtw)
+                        {
+				            struct mv_vlan_cfg* vlan_cfg = MV_NETDEV_VLAN(out_dev);
+				            *(unsigned short *)(pPktInfo->pFrags->bufVirtPtr) = vlan_cfg->header;
+                        }
+                        else
+#endif /* CONFIG_MV_GATEWAY */
+                        {
+				            pPktInfo->pFrags->bufPhysAddr += ETH_MV_HEADER_SIZE;
+				            pPktInfo->pFrags->dataSize -= ETH_MV_HEADER_SIZE;
+                        }
+                        mvOsCacheLineFlushInv(NULL, pPktInfo->pFrags->bufVirtPtr);	
+                        mvOsCacheLineFlushInv(NULL, pPktInfo->pFrags->bufVirtPtr + CPU_D_CACHE_LINE_SIZE);
+            	        spin_lock(out_priv->lock);
+#ifdef CONFIG_MV_ETH_NFP_TOS
+                        txq = pPktInfo->txq;
+#endif
+            	        status = mvEthPortTx(out_priv->hal_priv, txq, pPktInfo);
+            	        if( status != MV_OK ) 
+            	        {
+#ifdef CONFIG_MV_ETH_NFP_PPP
+							//printk("Tx drop: %x %d\n", status);
+							if (pPktInfo->pFrags->bufAddrShift) {
+								pPktInfo->pFrags->bufPhysAddr += pPktInfo->pFrags->bufAddrShift;
+								pPktInfo->pFrags->bufVirtPtr += pPktInfo->pFrags->bufAddrShift;
+								pPktInfo->pFrags->bufAddrShift = 0;
+							}
+#endif
+				            out_dev->stats.tx_dropped++;
+				            spin_unlock(out_priv->lock);
+#if defined(CONFIG_MV_GATEWAY)
+				            if(!out_priv->isGtw)
+#endif /* CONFIG_MV_GATEWAY */
+					            pPktInfo->pFrags->bufPhysAddr -= ETH_MV_HEADER_SIZE;
+
+				            mvEthPortRxDone( priv->hal_priv, queue, pPktInfo );
+				            continue;
+			            }
+                	    out_priv->tx_count[txq]++;
+                	    out_dev->stats.tx_packets++;
+                	    out_dev->stats.tx_bytes += pPktInfo->pFrags->dataSize;
+                	    ETH_STAT_DBG( out_priv->eth_stat.tx_hal_ok[txq]++);
+
+                	    spin_unlock(out_priv->lock);
+
+                	    /* refill RX queue */
+                	    pPktInfo = eth_pkt_info_get(priv);
+			            if (pPktInfo != NULL)
+                	        mvEthPortRxDone( priv->hal_priv, queue, pPktInfo );
+			            else
+			            {
+                            ETH_STAT_ERR(priv->eth_stat.rx_pool_empty++);
+			                priv->refill_needed_flag = 1;
+			            }
+                	    continue;
+                    }
+                }
+#ifdef CONFIG_MV_ETH_NFP_SEC
+		/* NFP will make sure to complete the packet processing */
+		if( out_if_index == MV_NFP_STOLEN)
+		{
+                	    /* refill RX queue */
+                	    pPktInfo = eth_pkt_info_get(priv);
+			            if (pPktInfo != NULL)
+                	        mvEthPortRxDone( priv->hal_priv, queue, pPktInfo );
+			            else
+			            {
+                            ETH_STAT_ERR(priv->eth_stat.rx_pool_empty++);
+			                priv->refill_needed_flag = 1;
+			            }
+                	    continue;		
+		}
+		if( out_if_index == MV_NFP_DROP)
+		{
+			if (pPktInfo->pFrags->bufAddrShift) {
+					pPktInfo->pFrags->bufPhysAddr += pPktInfo->pFrags->bufAddrShift;
+					pPktInfo->pFrags->bufVirtPtr += pPktInfo->pFrags->bufAddrShift;
+					pPktInfo->pFrags->bufAddrShift = 0;
+			}
+			mvOsCacheLineInv(NULL, pPktInfo->pFrags->bufVirtPtr);	
+                        mvOsCacheLineInv(NULL, pPktInfo->pFrags->bufVirtPtr + CPU_D_CACHE_LINE_SIZE);
+			/* TBD - rx drop counters */
+			mvEthPortRxDone( priv->hal_priv, queue, pPktInfo );
+			continue;
+		}
+#endif /* CONFIG_MV_ETH_NFP_SEC */
+            }
+	    }
+#endif /* CONFIG_MV_ETH_NFP */
+
+	    /* skip on 2B Marvell-header */
+	    skb_reserve(skb, ETH_MV_HEADER_SIZE);
+	    skb_put(skb, pPktInfo->pFrags->dataSize - ETH_MV_HEADER_SIZE);
+
+        if(out_dev != NULL)
+        {
+            /* Send to external net_device */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+            out_dev->hard_start_xmit(skb, out_dev);
+#else
+            out_dev->netdev_ops->ndo_start_xmit(skb, out_dev);
+#endif
+        }
+        else
+        {
+            skb->dev = dev;
+
+            skb->ip_summed = CHECKSUM_NONE;
+            skb->protocol = eth_type_trans(skb, dev);
+
+#ifdef RX_CSUM_OFFLOAD
+	    if ((pPktInfo->pFrags->dataSize > (ETH_CSUM_MIN_BYTE_COUNT-4))  && 
+	        (rx_status & ETH_RX_IP_FRAME_TYPE_MASK) && 
+	        (rx_status & ETH_RX_IP_HEADER_OK_MASK)
+#ifdef CONFIG_MV_ETH_TOOL
+		&& (priv->rx_csum_offload != 0)
+#endif
+		) 
+            {  
+		if (!(pPktInfo->fragIP)		&&
+		   (!(rx_status & ETH_RX_L4_OTHER_TYPE)) &&
+		   (rx_status & ETH_RX_L4_CHECKSUM_OK_MASK)) 
+                { 
+		    skb->csum = 0;
+		    skb->ip_summed = CHECKSUM_UNNECESSARY;	
+		    ETH_STAT_DBG(priv->eth_stat.rx_csum_hw++);
+		}
+           	else if (pPktInfo->fragIP &&
+           	    (rx_status & ETH_RX_L4_UDP_TYPE) &&
+                    !(rx_status & ETH_RX_VLAN_TAGGED_FRAME_MASK)) 
+		{
+		    skb->csum = ntohl(0xFFFF ^ ((rx_status & ETH_RX_L4_CHECKSUM_MASK) >> ETH_RX_L4_CHECKSUM_OFFSET));
+		    skb->ip_summed = CHECKSUM_COMPLETE;
+		    ETH_STAT_DBG( priv->eth_stat.rx_csum_hw_frags++);
+		}
+                else
+                {
+                    ETH_STAT_DBG(priv->eth_stat.rx_csum_sw++);
+                }
+	    }
+            else 
+	    {
+                    ETH_DBG( ETH_DBG_RX, ("%s: no RX csum offload\n", dev->name) );
+		    ETH_STAT_DBG(priv->eth_stat.rx_csum_sw++);
+            }
+#endif /* RX_CSUM_OFFLOAD*/
+
+#ifdef CONFIG_MV_GTW_IGMP
+            if (priv->isGtw && (rx_status & ETH_RX_L4_OTHER_TYPE)) {
+		struct iphdr* iph = (struct iphdr*)skb->data;
+		if ((skb->protocol == htons(ETH_P_IP)) && 
+		    (iph->protocol == IPPROTO_IGMP)) {
+			mv_gtw_igmp_snoop_process(skb, mv_gtw_ingress_port(data),
+					       mv_gtw_ingress_vlan(data) );
+		}
+	    }
+#endif /* CONFIG_MV_GTW_IGMP */
+
+#ifdef ETH_LRO
+	        if (priv->lro_en && !pPktInfo->fragIP && 
+				((rx_status & ETH_RX_L4_TYPE_MASK) == ETH_RX_L4_TCP_TYPE))
+			{
+				struct iphdr* iph = (struct iphdr*)skb->data;
+
+				if (iph->daddr == mv_eth_dev_ip(dev)) {
+					status = 0;				
+					lro_receive_skb(&priv->lro_mgr, skb, priv);
+				}
+				else
+					status = netif_receive_skb(skb);				
+            }
+	        else
+#endif /* ETH_LRO */
+            {
+                /* MV_CPU_CNTRS_START(routing_event); */
+                status = netif_receive_skb(skb);
+                /* MV_CPU_CNTRS_STOP(routing_event); */
+                /* MV_CPU_CNTRS_SHOW(routing_event); */
+            }
+            ETH_STAT_DBG( if(status) (priv->eth_stat.rx_netif_drop++) );
+
+#ifdef CONFIG_MV_ETH_SKB_REUSE
+            if( eth_skb_reuse_enable && 
+        	    ( !mvStackIsFull(priv->skbReusePool)) )
+            {
+        	    ETH_STAT_DBG(priv->eth_stat.skb_reuse_rx++);
+        	    mvStackPush(priv->skbReusePool, (MV_U32)pPktInfo);
+        	    /* refill RX queue */
+        	    pPktInfo = eth_pkt_info_get(priv);
+        	    if(pPktInfo != NULL)
+                    mvEthPortRxDone( priv->hal_priv, queue, pPktInfo );
+                else
+                {
+                    ETH_STAT_ERR(priv->eth_stat.rx_pool_empty++);
+		            priv->refill_needed_flag = 1;
+                }
+        	    continue;
+            }
+#endif /* CONFIG_MV_ETH_SKB_REUSE */
+	    }
+
+        /* Refill this buffer */
+        skb = eth_skb_alloc(priv, pPktInfo, dev->mtu);
+        if(skb == NULL)
+        {
+            mvOsFree(pPktInfo);
+            priv->skb_alloc_fail_cnt++;
+            continue;
+        }
+
+        /* give the buffer to hal */
+        status = mvEthPortRxDone(priv->hal_priv, queue, pPktInfo);
+        if( (status != MV_OK) && (status != MV_FULL) )
+        {
+            printk( KERN_ERR "%s: error in rx-fill, status=%d\n", dev->name, status );
+        }
+        ETH_STAT_DBG( priv->eth_stat.rx_fill_ok[queue]++);
+    }
+
+    ETH_STAT_DBG( priv->eth_stat.rx_dist[work_done]++); 
+    ETH_DBG( ETH_DBG_RX, ("\nwork_done %d", work_done));
+
+    /* notify upper layer about more work to do */
+    return work_done;
+}
+/**************************************************************************************************************/
+
+
+/*********************************************************** 
+ * eth_rx_fill --                                        *
+ *   fill new rx buffers to ring.                          *
+ ***********************************************************/
+int     eth_rx_fill(mv_eth_priv *priv, int pool_size, int mtu)
+{
+    MV_PKT_INFO     *pPktInfo;
+    MV_BUF_INFO     *pBufInfo;
+    struct sk_buff  *skb;
+    u32             count;
+    MV_STATUS       status;
+    int             rxq = 0;
+
+	count = 0;
+    while(pool_size > count) {
+
+        pPktInfo = mvOsMalloc(sizeof(MV_PKT_INFO));
+        if(pPktInfo == NULL)
+        {
+            printk("GbE port %d: Can't allocate %d bytes for MV_PKT_INFO\n",
+                        priv->port, sizeof(MV_PKT_INFO));
+            return count;
+        }
+
+        pBufInfo = mvOsMalloc(sizeof(MV_BUF_INFO));
+        if(pBufInfo == NULL)
+        {
+            printk("GbE port %d: Can't allocate %d bytes for MV_BUF_INFO\n",
+                        priv->port, sizeof(MV_BUF_INFO));
+            mvOsFree(pPktInfo);
+            return count;
+        }
+
+        pBufInfo->bufAddrShift = 0;
+		pBufInfo->dataSize = 0;
+        pPktInfo->pFrags = pBufInfo;
+        pPktInfo->numFrags = 1;
+        pPktInfo->status = 0;
+        pPktInfo->ownerId = priv->port;
+        pPktInfo->txq = 0;
+
+        skb = eth_skb_alloc(priv, pPktInfo, mtu);
+        if(skb == NULL)
+        {
+            mvOsFree(pPktInfo);
+            mvOsFree(pBufInfo);
+            return count;
+        }
+
+        /* First of all refill RXQs */
+        for(rxq=0; rxq<MV_ETH_RX_Q_NUM; rxq++)
+        {
+            if( !mvEthRxQueueIsFull(priv->hal_priv, rxq) )
+            {
+                status = mvEthPortRxDone(priv->hal_priv, rxq, pPktInfo);
+                if( (status != MV_OK) && (status != MV_FULL) )
+                {
+                    printk("rx_fill: q=%d, resource=%d, status=%d\n", 
+                               rxq, mvEthRxResourceGet(priv->hal_priv, rxq), status);
+                }
+		        ETH_STAT_DBG( priv->eth_stat.rx_fill_ok[rxq]++);
+                pPktInfo = NULL;
+                count++;
+                break;
+            }
+        }
+
+#if defined(CONFIG_MV_ETH_NFP) || defined(CONFIG_MV_ETH_SKB_REUSE)
+        /* Push extra RX buffers to fpRxPool */
+        if( (pPktInfo != NULL) && !mvStackIsFull(priv->fpRxPool) )
+        {
+            mvStackPush(priv->fpRxPool, (MV_U32)pPktInfo);
+            pPktInfo = NULL;
+            count++;
+        }
+#endif /* CONFIG_MV_ETH_NFP || CONFIG_MV_ETH_SKB_REUSE*/
+        if(pPktInfo != NULL)
+        {
+            printk("rx_fill: No more place to store pkt_info+skb pairs - pool_size=%d, count=%d\n", 
+                               pool_size, count);
+            mvOsFree(pPktInfo);
+            mvOsFree(pBufInfo);
+            dev_kfree_skb_any(skb);           
+            break;
+        }
+    }
+    return count;
+}
+
+
+/*********************************************************** 
+ * mv_eth_interrupt_handler --                              *
+ *   serve rx-q0, tx-done-q0, phy/link state change.       *
+ *   phy is served in interrupt context.           *
+ *   tx and rx are scheduled out of interrupt context (NAPI poll)  *
+ ***********************************************************/
+irqreturn_t     mv_eth_interrupt_handler(int irq , void *dev_id)
+{
+    mv_eth_priv         *priv = (mv_eth_priv*)dev_id;
+    struct net_device   *dev  = priv->net_dev;
+
+    ETH_DBG( ETH_DBG_INT, ("\n%s: isr ", dev->name) );
+    ETH_STAT_INFO(priv->eth_stat.irq_total++);
+
+    /* read port interrupt cause register */
+    mv_eth_save_interrupts(priv);
+
+    ETH_DBG(ETH_DBG_INT, ("%s: mv_eth_interrupt_handler: picr=%x, picer=%x\n", 
+                            dev->name, priv->picr, priv->picer));
+
+#ifdef ETH_DEBUG
+    if( !priv->picr && !priv->picer) {
+        ETH_STAT_INFO(priv->eth_stat.irq_none++);
+        return IRQ_HANDLED;
+    }
+#endif /* ETH_DEBUG */
+
+    /* Verify that the device not already on the polling list */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    if (netif_rx_schedule_prep(dev)) {
+	/* schedule the work (rx+txdone+link) out of interrupt contxet */
+	mv_eth_mask_interrupts(priv);
+	__netif_rx_schedule(dev);
+#else
+	 if (napi_schedule_prep(&priv->napi)) {
+	    /* schedule the work (rx+txdone+link) out of interrupt contxet */
+        mv_eth_mask_interrupts(priv);
+	__napi_schedule(&priv->napi);
+#endif
+    }
+    else {
+	    if(netif_running(dev)) {
+            ETH_STAT_INFO(priv->eth_stat.irq_while_polling++);
+#ifdef ETH_DEBUG
+            printk("%s: Interrupt while in polling list\n", dev->name);
+	        eth_print_irq_status(priv);
+#endif /* ETH_DEBUG */
+	    }
+    }
+    mv_eth_clear_saved_interrupts(priv);
+
+    return IRQ_HANDLED;
+}
+
+void
+eth_check_for_tx_done(void)
+{
+    int i;
+	int queue;
+
+    for(i=0; i<mv_eth_ports_num; i++)
+    {
+        mv_eth_priv  *tx_priv = mv_eth_ports[i];
+        if (tx_priv != NULL)
+        {
+            spin_lock(tx_priv->lock);
+
+            queue = MV_ETH_TX_Q_NUM;
+            while(queue--)
+            {
+                if(tx_priv->tx_count[queue] > mv_eth_tx_done_quota)
+                    tx_priv->tx_count[queue] -= eth_tx_done(tx_priv, queue);
+
+#ifdef ETH_MV_TX_EN
+                if(tx_priv->tx_en && (tx_priv->tx_count[queue] > 0) )
+                    eth_tx_enable(tx_priv, queue);
+#endif /* ETH_MV_TX_EN */
+	        }
+                spin_unlock(tx_priv->lock);
+        }
+    }
+	return;
+}
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+static int eth_poll( struct net_device *dev, int *budget )
+#else
+static int eth_poll( struct napi_struct *napi, int budget )
+#endif
+{
+    int             queue, rx_done=0, rx_todo;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    mv_eth_priv     *priv = MV_ETH_PRIV(dev);
+#else
+    mv_eth_priv     *priv = container_of(napi, mv_eth_priv, napi);
+    struct net_device *dev = priv->net_dev;
+#endif
+
+    ETH_STAT_INFO(priv->eth_stat.poll_events++);
+    ETH_DBG(ETH_DBG_POLL, ("%s: Start eth_poll\n", dev->name));
+
+    if( priv->picer & (1 << ETH_CAUSE_LINK_STATE_CHANGE_BIT) ) 
+    {
+        eth_check_link_status(dev);
+        priv->picer &= ~ETH_LINK_MASK;
+    }
+/*
+    MV_CPU_CNTRS_START(empty_event);
+    MV_CPU_CNTRS_STOP(empty_event);
+    MV_CPU_CNTRS_SHOW(empty_event);
+*/
+#ifdef ETH_TX_DONE_ISR
+        spin_lock(priv->lock);
+
+	queue = MV_ETH_TX_Q_NUM;
+	while(queue--)
+        {
+            if(priv->tx_count[queue] > 0)
+            {
+#ifdef ETH_MV_TX_EN
+                if(priv->tx_en)
+		        eth_tx_enable(priv, queue);
+#endif /* ETH_MV_TX_EN */
+		        priv->tx_count[queue] -= eth_tx_done(priv, queue);
+            }
+        }
+	spin_unlock(priv->lock);
+#endif /* ETH_TX_DONE_ISR */
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    rx_todo = min(*budget, dev->quota);
+#else
+    rx_todo = budget;
+#endif
+
+#if (MV_ETH_RX_Q_NUM > 1)
+    while(MV_TRUE)
+    {
+        queue = eth_rx_policy(priv);
+        if(queue == -1)
+            break;
+
+        rx_done += eth_rx(dev, rx_todo - rx_done, queue);
+        if(rx_done < rx_todo)
+            priv->picr &= ~(ETH_CAUSE_RX_READY_MASK(queue) | 
+                            ETH_CAUSE_RX_ERROR_MASK(queue));
+        else
+            break;
+    }
+#else
+    rx_done = eth_rx( dev, rx_todo, ETH_DEF_RXQ);
+#endif /* (MV_ETH_RX_Q_NUM > 1) */
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    *budget -= rx_done;
+    dev->quota -= rx_done;
+#else
+    budget -= rx_done;
+#endif
+
+#if defined(CONFIG_MV_ETH_NFP) && !defined(ETH_TX_DONE_ISR)
+    if( fp_is_enabled() )
+    {
+	eth_check_for_tx_done();
+    }
+#endif /* CONFIG_MV_ETH_NFP && !ETH_TX_DONE_ISR */
+
+#ifdef ETH_LRO
+    if (rx_done && priv->lro_en)
+        lro_flush_all(&priv->lro_mgr);
+#endif	
+
+    ETH_DBG( ETH_DBG_POLL, ("poll work done: rx-%d\n", rx_done) );
+
+    if ( (!netif_running(dev)) || (rx_done < rx_todo) )
+    { 
+        unsigned long flags;
+        local_irq_save(flags);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+        netif_rx_complete(dev);
+#else
+	napi_complete(&priv->napi);
+#endif
+        ETH_STAT_INFO(priv->eth_stat.poll_complete++);
+        mv_eth_unmask_interrupts(priv);
+	ETH_DBG( ETH_DBG_RX, ("unmask\n") );
+        local_irq_restore(flags);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+        return 0;
+#else
+	return rx_done;
+#endif
+    }
+    else
+    {
+#if (MV_ETH_RX_Q_NUM > 1)
+        /* Leave in NAPI context, so update picr and picer */
+        mv_eth_save_interrupts(priv);
+	    mv_eth_clear_saved_interrupts(priv);
+#endif /* (MV_ETH_RX_Q_NUM > 1) */
+    }
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    return 1;
+#else
+	return rx_done;
+#endif
+}
+
+
+/* Show network driver configuration */
+void	mv_eth_config_show(void)
+{
+    int     i;
+
+    printk( "  o %s\n", ETH_DESCR_CONFIG_STR );
+
+#if defined(ETH_DESCR_IN_SRAM)
+    printk( "  o %s\n", INTEG_SRAM_CONFIG_STR );
+#endif
+
+    printk( "  o %s\n", ETH_SDRAM_CONFIG_STR );
+
+#if (CONFIG_MV_ETH_RXQ > MV_ETH_MAX_RXQ)
+#   error "CONFIG_MV_ETH_RXQ is large than MV_ETH_MAX_RXQ"
+#endif  
+
+#if CONFIG_MV_ETH_TXQ > MV_ETH_MAX_TXQ
+#   error "CONFIG_MV_ETH_TXQ is large than MV_ETH_MAX_TXQ"
+#endif 
+ 
+#if defined(ETH_INCLUDE_TSO) && !defined(TX_CSUM_OFFLOAD)
+#error "If TSO supported - TX checksum offload must be supported too"
+#endif
+
+    printk("  o %d Giga ports supported\n", CONFIG_MV_ETH_PORTS_NUM); 
+
+#if (CONFIG_MV_ETH_RXQ > 1)
+    printk( "  o Multi RX Queue support - %d RX queues\n", CONFIG_MV_ETH_RXQ);
+#else
+    printk( "  o Single RX Queue support - ETH_DEF_RXQ=%d\n", ETH_DEF_RXQ);
+#endif /* CONFIG_MV_ETH_RXQ > 1 */
+
+#if (CONFIG_MV_ETH_TXQ > 1)
+    printk( "  o Multi TX Queue support - %d TX Queues\n", CONFIG_MV_ETH_TXQ);
+#else
+    printk( "  o Single TX Queue support - ETH_DEF_TXQ=%d\n", ETH_DEF_TXQ);
+#endif /* CONFIG_MV_ETH_TXQ > 1 */
+
+#if defined(ETH_INCLUDE_TSO)
+    printk("  o TCP segmentation offload (TSO) supported\n");
+#endif /* ETH_INCLUDE_TSO */
+
+#if defined(ETH_INCLUDE_UFO)
+    printk("  o UDP fragmentation offload (UFO) supported\n");
+#endif /* ETH_INCLUDE_UFO */
+
+#ifdef ETH_LRO
+    printk("  o Large Receive offload (LRO) supported\n");
+#endif
+
+#if defined(RX_CSUM_OFFLOAD)
+    printk("  o Receive checksum offload supported\n");
+#endif
+#if defined(TX_CSUM_OFFLOAD)
+    printk("  o Transmit checksum offload supported\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_NFP
+    printk("  o Network Fast Processing (Routing) supported - (%s)\n", 
+                    fp_is_enabled() ? "Enabled" : "Disabled");
+
+#ifdef CONFIG_MV_ETH_NFP_NAT
+    printk("  o Network Fast Processing (NAT) supported\n");
+#endif /* CONFIG_MV_ETH_NFP_NAT */
+
+#endif /* CONFIG_MV_ETH_NFP */
+
+#ifdef CONFIG_MV_ETH_STATS_ERROR
+    printk("  o Driver ERROR statistics enabled\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_STATS_INFO
+    printk("  o Driver INFO statistics enabled\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_STATS_DEBUG
+    printk("  o Driver DEBUG statistics enabled\n");
+#endif
+
+#ifdef ETH_DEBUG
+    printk("  o Driver debug messages enabled\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_PROC
+    printk("  o Proc tool API enabled\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_SKB_REUSE
+	printk("  o SKB Reuse supported - (%s)\n", 
+                    eth_skb_reuse_enable ? "Enabled" : "Disabled");
+#endif /* CONFIG_MV_ETH_SKB_REUSE */
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+	printk("  o SKB Recycle supported - (%s)\n", 
+                    eth_skb_recycle_enable ? "Enabled" : "Disabled");
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+#if defined(CONFIG_MV_GATEWAY)
+    printk("  o Gateway support enabled\n");
+
+    printk("     o Using Marvell Header Mode\n");
+
+#ifdef CONFIG_MV_GTW_IGMP
+    printk("     o L2 IGMP support\n");
+#endif /* CONFIG_MV_GTW_IGMP */
+
+#endif /* CONFIG_MV_GATEWAY */
+
+    printk("  o Rx descripors:");
+    for(i=0; i<CONFIG_MV_ETH_RXQ; i++) {
+        printk(" q%d=%-3d", i, mv_eth_rxq_desc[i]);
+    }
+    printk("\n");
+
+#if CONFIG_MV_ETH_TXQ > MV_ETH_MAX_TXQ
+#error "CONFIG_MV_ETH_TXQ is large than MV_ETH_MAX_TXQ"
+#endif 
+
+    printk("  o Tx descripors:");
+    for(i=0; i<CONFIG_MV_ETH_TXQ; i++) {
+        printk(" q%d=%-3d", i, mv_eth_txq_desc[i]);
+    }
+    printk("\n");
+}
+
+void    mv_netdev_set_features(struct net_device *dev)
+{
+    dev->features = NETIF_F_SG | NETIF_F_LLTX;
+
+#ifdef TX_CSUM_OFFLOAD
+        if(dev->mtu <= ETH_CSUM_MAX_BYTE_COUNT) 
+        {
+            dev->features |= NETIF_F_IP_CSUM;
+        }
+#endif /* TX_CSUM_OFFLOAD */
+
+#ifdef ETH_INCLUDE_TSO
+    if(dev->features & NETIF_F_IP_CSUM)
+	    dev->features |= NETIF_F_TSO;
+#endif /* ETH_INCLUDE_TSO */
+
+#ifdef ETH_INCLUDE_UFO
+    /* FIXME: HW_CSUM is required by dev.c */
+    if(dev->features & NETIF_F_IP_CSUM)
+        dev->features |= NETIF_F_UFO | NETIF_F_HW_CSUM; 
+#endif /* ETH_INCLUDE_UFO */
+}
+
+/*********************************************************** 
+ * mv_eth_start_internals --                                *
+ *   fill rx buffers. start rx/tx activity. set coalesing. *
+ *   clear and unmask interrupt bits                       *
+ ***********************************************************/
+int     mv_eth_start_internals(mv_eth_priv *priv, int mtu)
+{
+    unsigned long flags;
+    unsigned int status;
+    int num;
+
+    spin_lock_irqsave( priv->lock, flags); 
+
+    /* fill rx ring with buffers */
+#if defined(CONFIG_MV_ETH_NFP) || defined(CONFIG_MV_ETH_SKB_REUSE)
+    num = mvStackFreeElements(priv->fpRxPool);
+#else
+    num = mv_eth_rx_desc_total;
+#endif /* CONFIG_MV_ETH_NFP || CONFIG_MV_ETH_SKB_REUSE */ 
+
+    eth_rx_fill(priv, num, mtu);
+    priv->skb_alloc_fail_cnt = 0;
+
+    mv_eth_clear_interrupts(priv);
+
+    /* start the hal - rx/tx activity */
+    status = mvEthPortEnable( priv->hal_priv );
+    if( (status != MV_OK) && (status != MV_NOT_READY)) {
+        printk( KERN_ERR "GbE port %d: ethPortEnable failed\n", priv->port);
+        spin_unlock_irqrestore( priv->lock, flags);
+      return -1;
+    }
+
+    /* set tx/rx coalescing mechanism */
+#ifdef CONFIG_MV_ETH_TOOL
+    mvEthTxCoalSet( priv->hal_priv, priv->tx_coal_usec );
+    mvEthRxCoalSet( priv->hal_priv, priv->rx_coal_usec );
+#else
+    mvEthTxCoalSet( priv->hal_priv, ETH_TX_COAL );
+    mvEthRxCoalSet( priv->hal_priv, ETH_RX_COAL );
+#endif
+
+    spin_unlock_irqrestore( priv->lock, flags);
+
+    return 0;
+}
+
+/*********************************************************** 
+ * mv_eth_stop_internals --                                 *
+ *   stop port rx/tx activity. free skb's from rx/tx rings.*
+ ***********************************************************/
+int     mv_eth_stop_internals(mv_eth_priv *priv)
+{
+    MV_PKT_INFO     *pPktInfo;
+    unsigned int    queue;
+
+    /* stop the port activity, mask all interrupts */
+    if( mvEthPortDisable( priv->hal_priv ) != MV_OK ) {
+        printk( KERN_ERR "GbE port %d: ethPortDisable failed\n", priv->port );
+        goto error;
+    }
+
+    /* clear all ethernet port interrupts */
+    mv_eth_clear_interrupts(priv);
+
+    mv_eth_mask_interrupts(priv);
+
+    /* free the skb's in the hal tx ring and release memory */
+    for(queue=0; queue<MV_ETH_TX_Q_NUM; queue++)
+    {
+        while( (pPktInfo = mvEthPortForceTxDone(priv->hal_priv, queue)) ) 
+        {
+            eth_pkt_info_free(priv, pPktInfo);
+        }
+        priv->tx_count[queue] = 0;
+    }
+
+    /* free the skb's in the hal rx ring */
+    for(queue=0; queue<MV_ETH_RX_Q_NUM; queue++)
+    {    
+        while( (pPktInfo = mvEthPortForceRx( priv->hal_priv, queue)) ) {
+            dev_kfree_skb_any( (struct sk_buff *)pPktInfo->osInfo );
+            ETH_STAT_DBG(priv->eth_stat.skb_free_ok++);
+            mvOsFree(pPktInfo->pFrags);
+            mvOsFree(pPktInfo);
+        }
+    }
+
+#if defined(CONFIG_MV_ETH_NFP) || defined (CONFIG_MV_ETH_SKB_REUSE)
+    while( (pPktInfo = eth_pkt_info_get(priv)) )
+    {
+        dev_kfree_skb_any( (struct sk_buff *)pPktInfo->osInfo );
+        ETH_STAT_DBG(priv->eth_stat.skb_free_ok++);
+        mvOsFree(pPktInfo->pFrags);
+        mvOsFree(pPktInfo);
+    }
+#endif /* CONFIG_MV_ETH_NFP || CONFIG_MV_ETH_SKB_REUSE */
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+	eth_skb_recycle_clear(priv);
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+    /* Reset Rx descriptors ring */
+    for(queue=0; queue<MV_ETH_RX_Q_NUM; queue++)
+    {
+        ethResetRxDescRing(priv->hal_priv, queue);
+    }
+    /* Reset Tx descriptors ring */
+    for(queue=0; queue<MV_ETH_TX_Q_NUM; queue++)
+    {
+        ethResetTxDescRing(priv->hal_priv, queue);
+    }
+
+    return 0;
+
+ error:
+    printk( KERN_ERR "GbE port %d: stop internals failed\n", priv->port );
+    return -1;
+}
+
+
+/*********************************************************** 
+ * mv_eth_change_mtu_internals --                                     *
+ *   stop port activity. release skb from rings. set new   *
+ *   mtu in device and hw. restart port activity and       *
+ *   and fill rx-buiffers with size according to new mtu.  *
+ ***********************************************************/
+int     mv_eth_change_mtu_internals( struct net_device *dev, int mtu )
+{
+    mv_eth_priv *priv = MV_ETH_PRIV(dev);
+
+    if(mtu > 9676 /* 9700 - 20 and rounding to 8 */) {
+        printk( "%s: Illegal MTU value %d, ", dev->name, mtu);
+        mtu = 9676;
+        printk(" rounding MTU to: %d \n",mtu);  
+    }
+
+    if(MV_RX_BUF_SIZE( mtu) & ~ETH_RX_BUFFER_MASK) {
+        printk( "%s: Illegal MTU value %d, ", dev->name, mtu);
+        mtu = 8 - (MV_RX_BUF_SIZE( mtu) & ~ETH_RX_BUFFER_MASK) + mtu;
+        printk(" rounding MTU to: %d \n",mtu);
+    }
+
+    /* set mtu in device and in hal sw structures */
+    if( mvEthMaxRxSizeSet( priv->hal_priv, MV_RX_BUF_SIZE( mtu)) ) {
+        printk( KERN_ERR "%s: ethPortSetMaxBufSize failed\n", dev->name );
+        return -1;
+    }
+
+    dev->mtu = mtu;
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+	eth_skb_recycle_clear(priv);
+#endif
+
+    mv_netdev_set_features(dev);
+
+    return 0;
+}
+
+
+/*********************************************************** 
+ * mv_netdev_timer_callback --                                *
+ *   N msec periodic callback for cleanup.                 *
+ ***********************************************************/
+static void mv_netdev_timer_callback( unsigned long data )
+{
+    struct net_device   *dev = (struct net_device *)data;
+    mv_eth_priv         *priv = MV_ETH_PRIV(dev);
+    int                 queue;
+
+    ETH_DBG( ETH_DBG_TX, ("%s: timer_callback\n", dev->name) );
+    ETH_STAT_INFO(priv->eth_stat.timer_events++);
+
+    spin_lock(priv->lock);
+
+    mvEthPortTxRestart(priv->hal_priv);
+
+#ifdef ETH_TX_DONE_ISR
+#else
+    /* Call TX done */
+	queue = MV_ETH_TX_Q_NUM;
+	while(queue--) {
+        if (priv->tx_count[queue] > 0) 
+			priv->tx_count[queue] -= eth_tx_done(priv, queue);
+    }
+#endif /* ETH_TX_DONE_ISR */ 
+
+    if(priv->skb_alloc_fail_cnt > 0)
+    {
+        priv->skb_alloc_fail_cnt -= eth_rx_fill(priv, priv->skb_alloc_fail_cnt, dev->mtu);
+    }
+
+#ifdef CONFIG_MV_ETH_SKB_REUSE
+    eth_skb_alloc_for_reuse(priv, dev->mtu);
+#endif /* CONFIG_MV_ETH_SKB_REUSE */
+
+#if defined(CONFIG_MV_ETH_NFP) || defined(CONFIG_MV_ETH_SKB_REUSE)
+    /* Refill pktInfo */
+	if (priv->refill_needed_flag) {
+        int             fill;
+        MV_PKT_INFO*    pPktInfo;
+
+  	    priv->refill_needed_flag = 0;
+        queue = MV_ETH_RX_Q_NUM;
+
+		while (queue--) {
+
+			fill = mv_eth_rxq_desc[queue] - mvEthRxResourceGet(priv->hal_priv, queue);
+
+            while (fill--) {
+		        pPktInfo = eth_pkt_info_get(priv);
+		        if (pPktInfo != NULL) {
+                	mvEthPortRxDone(priv->hal_priv, queue, pPktInfo);
+			        ETH_STAT_DBG(priv->eth_stat.rx_fill_ok[queue]++);
+		        }
+		        else {
+                    ETH_STAT_ERR(priv->eth_stat.rx_pool_empty++);
+                    priv->refill_needed_flag = 1;
+			        break;
+		        }
+            }
+        }
+    }
+#endif /* CONFIG_MV_ETH_NFP || CONFIG_MV_ETH_SKB_REUSE */
+
+
+    spin_unlock(priv->lock);
+
+    if(priv->timer_flag)
+    {
+        priv->timer.expires = jiffies + ((HZ*CONFIG_MV_ETH_TIMER_PERIOD)/1000); /*ms*/
+        add_timer( &priv->timer );
+    }
+}
+
+/* Initialize Ethernet port on chip */
+int  __init mv_eth_hal_init(mv_eth_priv *priv, int mtu, u8* mac)
+{
+    MV_ETH_PORT_INIT    hal_init_struct;
+
+        /* init the hal */
+    hal_init_struct.maxRxPktSize = MV_RX_BUF_SIZE(mtu);
+    hal_init_struct.rxDefQ = ETH_DEF_RXQ;
+    memcpy(hal_init_struct.rxDescrNum,  mv_eth_rxq_desc, sizeof(int)*MV_ETH_RX_Q_NUM);
+    memcpy(hal_init_struct.txDescrNum,  mv_eth_txq_desc, sizeof(int)*MV_ETH_TX_Q_NUM);
+    hal_init_struct.osHandle = NULL;
+
+    priv->hal_priv = mvEthPortInit( priv->port, &hal_init_struct );
+    if( !priv->hal_priv ) {
+        printk( KERN_ERR "eth port=%d: load failed\n", priv->port);
+        return -ENODEV;
+    }
+
+#ifdef CONFIG_ETH_FLOW_CONTROL
+    /* enable flow Control in MAC level */
+    mvEthFlowCtrlSet(priv->hal_priv, MV_ETH_FC_ENABLE);
+#endif
+
+    if(mac)
+    {
+        /* set new addr in hw */
+        if( mvEthMacAddrSet( priv->hal_priv, mac, ETH_DEF_RXQ) != MV_OK ) 
+        {
+            printk("mv_eth_hal_init: ethSetMacAddr failed for port=%d\n", priv->port);
+            return -ENODEV;
+        }
+    }
+    else
+    {
+        mvEthRxFilterModeSet(priv->hal_priv, MV_TRUE);
+    }
+
+    if( mvEthMaxRxSizeSet( priv->hal_priv, MV_RX_BUF_SIZE(mtu)) ) {
+        printk( "mv_eth_hal_init: ethPortSetMaxBufSize failed for port=%d\n", priv->port);
+        return -ENODEV;
+    }
+    return 0;
+}
+
+/* Initialize HAL level of Ethernet driver */
+int __init mv_eth_priv_init(mv_eth_priv *priv, int port)
+{
+    int         txq, i;
+    MV_PKT_INFO *pkt_info;
+
+    memset(priv, 0, sizeof(mv_eth_priv) );
+
+#if defined(ETH_INCLUDE_TSO) || defined(ETH_INCLUDE_UFO) || defined(CONFIG_MV_GATEWAY)
+    for(txq=0; txq<MV_ETH_TX_Q_NUM; txq++)
+    {
+        priv->tx_extra_bufs[txq] = mvOsMalloc(mv_eth_txq_desc[txq]*sizeof(char*));
+        if(priv->tx_extra_bufs[txq] == NULL)
+        {
+            printk("GbE port %d TSO/UFO: txq=%d - Can't alloc %d bytes for tx_extra_bufs array\n", 
+                        port, txq, mv_eth_txq_desc[txq]*sizeof(char*));
+            return -ENOMEM;
+        }
+        for(i=0; i<mv_eth_txq_desc[txq]; i++)
+        {
+            priv->tx_extra_bufs[txq][i] = mvOsMalloc(TX_EXTRA_BUF_SIZE);
+            if(priv->tx_extra_bufs[txq][i] == NULL)
+            {
+                printk("GbE port %d TSO/UFO: txq=%d - Can't alloc %d extra TX buffer (%d bytes)\n", 
+                        port, txq, i, TX_EXTRA_BUF_SIZE);
+                return -ENOMEM;
+            }
+        }
+        priv->tx_extra_buf_idx[txq] = 0;
+    }
+#endif /* ETH_INCLUDE_TSO || ETH_INCLUDE_UFO || CONFIG_MV_GATEWAY */
+
+    priv->txPktInfoPool = mvStackCreate(mv_eth_tx_desc_total);
+    if(priv->txPktInfoPool == NULL)
+    {
+        printk("GbE port %d: Can't create txPktInfoPool for %d elements\n", 
+                    port, mv_eth_tx_desc_total);
+        return -ENOMEM;
+    }
+
+    for(i=0; i<mv_eth_tx_desc_total; i++)
+    {
+        pkt_info = mvOsMalloc(sizeof(MV_PKT_INFO));
+        if(pkt_info == NULL)
+        {
+            printk("GbE port %d: Can't alloc %d bytes for %d MV_PKT_INFO structure\n", 
+                    port, sizeof(MV_PKT_INFO), i);
+            return -ENOMEM;
+        }
+        memset(pkt_info, 0, sizeof(MV_PKT_INFO));
+        pkt_info->ownerId = ~0; 
+
+        pkt_info->pFrags = mvOsMalloc(sizeof(MV_BUF_INFO)*(MAX_SKB_FRAGS+3));
+        if(pkt_info->pFrags == NULL)
+        {
+            printk("GbE port %d: Can't alloc %d bytes for %d MV_BUF_INFO array\n", 
+                    port, (int)(sizeof(MV_BUF_INFO)*(MAX_SKB_FRAGS+3)), i);
+            return -ENOMEM;
+        }
+        memset(pkt_info->pFrags, 0, sizeof(MV_BUF_INFO)*(MAX_SKB_FRAGS+3));
+        mvStackPush(priv->txPktInfoPool, (MV_U32)pkt_info);
+    }
+
+    memset(priv->tx_count, 0, sizeof(priv->tx_count));
+
+    /* init mv_eth_priv */
+    priv->port = port;
+
+    memset( &priv->timer, 0, sizeof(struct timer_list) );
+    priv->timer.function = mv_netdev_timer_callback;
+    init_timer(&priv->timer);
+    priv->timer_flag = 0;
+    priv->skb_alloc_fail_cnt = 0;
+
+#ifdef ETH_LRO
+    priv->lro_en = 0;
+    priv->lro_mgr.max_aggr = 10;
+    priv->lro_mgr.max_desc = 4;
+    priv->lro_mgr.lro_arr = priv->lro_desc;
+    priv->lro_mgr.get_skb_header = NULL;
+    priv->lro_mgr.features = LRO_F_NAPI;
+    priv->lro_mgr.dev = NULL;
+    priv->lro_mgr.ip_summed = CHECKSUM_UNNECESSARY;
+    priv->lro_mgr.ip_summed_aggr = CHECKSUM_UNNECESSARY;
+#endif /* ETH_LRO */
+
+#if defined(CONFIG_MV_ETH_NFP) || defined(CONFIG_MV_ETH_SKB_REUSE)
+    priv->refill_needed_flag = 0;
+    priv->fpRxPool = mvStackCreate(mv_eth_rx_desc_total*2 + mv_eth_tx_desc_total);
+    if(priv->fpRxPool == NULL)
+    {
+        mvOsPrintf("eth_priv_init_%d: Can't create fpRxPool for %d elements\n", 
+                port, (mv_eth_rx_desc_total*2 + mv_eth_tx_desc_total));
+        return -ENOMEM;
+    }
+#endif /* (CONFIG_MV_ETH_NFP) || (CONFIG_MV_ETH_SKB_REUSE) */
+
+#ifdef CONFIG_MV_ETH_NFP
+    memset(&priv->fpStats, 0, sizeof(priv->fpStats) );
+    priv->lock = &nfp_lock;
+#else
+    priv->lock = kmalloc(sizeof(spinlock_t), GFP_ATOMIC);
+    spin_lock_init( priv->lock );
+#endif /* CONFIG_MV_ETH_NFP */
+
+#ifdef CONFIG_MV_ETH_SKB_REUSE
+    priv->skbReusePool = mvStackCreate(mv_eth_rx_desc_total*2);
+    if(priv->skbReusePool == NULL)
+    {
+        printk("eth_priv_init_%d: Can't create skbReusePool for %d elements\n", 
+                port, mv_eth_rx_desc_total*2);
+        return -ENOMEM;
+    }
+#endif /* CONFIG_MV_ETH_SKB_REUSE */
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+    priv->skbRecycleMTU = 0;
+    priv->skbRecyclePool = mvStackCreate(1024);
+    if (!priv->skbRecyclePool) {
+        printk("%s: port %d, failed to allocate pool\n", __FUNCTION__, port);
+        return -ENOMEM;
+    }	
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+#ifdef ETH_MV_TX_EN
+    priv->tx_en = priv->tx_en_bk = MV_ETH_TX_EN_DEFAULT;
+    priv->tx_en_deep = 1;
+#endif /* ETH_MV_TX_EN */
+
+#ifdef CONFIG_MV_ETH_TOOL
+    /* MII address setup */
+    priv->phy_id = mvBoardPhyAddrGet(port);
+    /* Configure defaults */
+    priv->autoneg_cfg  = AUTONEG_ENABLE;
+    priv->speed_cfg    = SPEED_1000;
+    priv->duplex_cfg  = DUPLEX_FULL;
+    priv->tx_coal_usec = ETH_TX_COAL;
+    priv->rx_coal_usec = ETH_RX_COAL;
+#ifdef RX_CSUM_OFFLOAD
+    priv->rx_csum_offload = 1;
+#endif
+
+#endif /* CONFIG_MV_ETH_TOOL */
+
+    return 0;
+}
+
+/* Release all allocated memory */
+void    mv_eth_priv_cleanup(mv_eth_priv *priv)
+{
+    MV_PKT_INFO *pkt_info;
+
+#ifdef CONFIG_MV_ETH_SKB_REUSE
+    if(priv->skbReusePool != NULL)
+    {
+        mvStackDelete(priv->skbReusePool);
+        priv->skbReusePool = NULL;
+    }
+#endif /* CONFIG_MV_ETH_SKB_REUSE */
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+    if (priv->skbRecyclePool) 
+	{
+		mvStackDelete(priv->skbRecyclePool);
+		priv->skbRecyclePool = NULL;
+    }
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+#ifdef CONFIG_MV_ETH_NFP
+#else
+    if(priv->lock != NULL)
+    {
+        kfree(priv->lock);
+        priv->lock = NULL;
+    }
+#endif /* CONFIG_MV_ETH_NFP */
+
+#if defined(CONFIG_MV_ETH_NFP) || defined(CONFIG_MV_ETH_SKB_REUSE)
+    if(priv->fpRxPool != NULL)
+    {
+        mvStackDelete(priv->fpRxPool);
+        priv->fpRxPool = NULL;
+    }
+#endif /* CONFIG_MV_ETH_NFP || CONFIG_MV_ETH_SKB_REUSE */
+
+#if defined(ETH_INCLUDE_TSO) || defined(ETH_INCLUDE_UFO) || defined(CONFIG_MV_GATEWAY)
+    {
+        int     i, txq;
+
+        for(txq=0; txq<MV_ETH_TX_Q_NUM; txq++)
+        {
+            if(priv->tx_extra_bufs[txq] != NULL)
+            {
+                for(i=0; i<mv_eth_txq_desc[txq]; i++)
+                {
+                    if(priv->tx_extra_bufs[txq][i] != NULL)
+                    {
+                        mvOsFree(priv->tx_extra_bufs[txq][i]);
+                        priv->tx_extra_bufs[txq][i] = NULL;
+                    }
+                }
+                mvOsFree(priv->tx_extra_bufs[txq]);
+                priv->tx_extra_bufs[txq] = NULL;
+            }
+        }
+    }
+#endif /* ETH_INCLUDE_TSO || ETH_INCLUDE_UFO || CONFIG_MV_GATEWAY */
+
+    if(priv->txPktInfoPool)
+    {
+        while(mvStackIsEmpty(priv->txPktInfoPool) == MV_FALSE)
+        {
+            pkt_info = (MV_PKT_INFO*)mvStackPop(priv->txPktInfoPool);
+            if(pkt_info != NULL)
+            {
+                if(pkt_info->pFrags != NULL)
+                {
+                    mvOsFree(pkt_info->pFrags);
+                }
+                mvOsFree(pkt_info);
+            }
+        }
+        mvStackDelete(priv->txPktInfoPool);
+    }
+}
+
+
+#ifdef ETH_INCLUDE_TSO
+/*********************************************************** 
+ * eth_tso_tx --                                             *
+ *   send a packet.                                        *
+ ***********************************************************/
+static int eth_tso_tx(struct sk_buff *skb, struct net_device *dev, int txq)
+{
+    MV_STATUS       status;
+    MV_PKT_INFO     *pPktInfo;
+    int             pkt, frag, buf;
+    int             total_len, hdr_len, mac_hdr_len, size, frag_size, data_left;
+    char            *frag_ptr, *extra_ptr;
+    MV_U16          ip_id;
+    MV_U32          tcp_seq;
+    struct iphdr    *iph;
+    struct tcphdr   *tcph;
+    skb_frag_t      *skb_frag_ptr;
+    mv_eth_priv     *priv = MV_ETH_PRIV(dev);
+    const struct tcphdr *th = tcp_hdr(skb);
+
+    pkt = 0;        
+    frag = 0;
+    total_len = skb->len;
+    hdr_len = (skb_transport_offset(skb) + tcp_hdrlen(skb));
+    mac_hdr_len = skb_network_offset(skb);
+
+    total_len -= hdr_len;
+
+    if(skb_shinfo(skb)->frag_list != NULL)
+    {
+        printk("***** ERROR: frag_list is not null\n");
+        print_skb(skb);
+    }
+
+    if(skb_shinfo(skb)->gso_segs == 1)
+    {
+        printk("***** ERROR: only one TSO segment\n");
+        print_skb(skb);
+    }
+
+    if(total_len <= skb_shinfo(skb)->gso_size)
+    {
+        printk("***** ERROR: total_len less than gso_size\n");
+        print_skb(skb);
+    }
+
+    if( (htons(ETH_P_IP) != skb->protocol) || 
+        (ip_hdr(skb)->protocol != IPPROTO_TCP) )
+    {
+        printk("***** ERROR: Unexpected protocol\n");
+        print_skb(skb);
+    }
+
+    ip_id = ntohs(ip_hdr(skb)->id);
+    tcp_seq = ntohl(th->seq);
+
+    frag_size = skb_headlen(skb);
+    frag_ptr = skb->data;
+
+    if(frag_size < hdr_len){
+        printk("***** ERROR: frag_size=%d, hdr_len=%d\n", frag_size, hdr_len);
+        print_skb(skb);
+    }
+
+    frag_size -= hdr_len;
+    frag_ptr += hdr_len;
+    if(frag_size == 0)
+    {
+        skb_frag_ptr = &skb_shinfo(skb)->frags[frag];
+
+        /* Move to next segment */
+        frag_size = skb_frag_ptr->size;
+        frag_ptr = page_address(skb_frag_ptr->page) + skb_frag_ptr->page_offset;
+        frag++;
+    }
+
+    while(total_len > 0)
+    {            
+        pPktInfo = (MV_PKT_INFO*)mvStackPop(priv->txPktInfoPool);
+
+        extra_ptr = priv->tx_extra_bufs[txq][priv->tx_extra_buf_idx[txq]++];
+        if(priv->tx_extra_buf_idx[txq] == mv_eth_txq_desc[txq])
+            priv->tx_extra_buf_idx[txq] = 0;
+
+#ifdef CONFIG_MV_GATEWAY
+	/* Note: supports Marvell Header mode, not VLAN mode */
+        if(priv->isGtw)
+        {
+            struct mv_vlan_cfg* vlan_cfg = MV_NETDEV_VLAN(dev);
+
+	    *(unsigned short *)(extra_ptr) = vlan_cfg->header;
+
+            pPktInfo->pFrags[0].bufVirtPtr = extra_ptr;
+            pPktInfo->pFrags[0].dataSize = ETH_MV_HEADER_SIZE;
+            pPktInfo->pktSize = ETH_MV_HEADER_SIZE;
+        }
+        else
+#endif /* CONFIG_MV_GATEWAY */
+        {
+            pPktInfo->pFrags[0].dataSize = 0;
+            pPktInfo->pktSize = 0;
+            pPktInfo->pFrags[0].bufVirtPtr = extra_ptr + ETH_MV_HEADER_SIZE;
+        }
+
+        extra_ptr += ETH_MV_HEADER_SIZE;
+        memcpy(extra_ptr, skb->data, hdr_len);
+
+        pPktInfo->pFrags[0].dataSize += hdr_len;
+        pPktInfo->pFrags[0].bufSize = TX_EXTRA_BUF_SIZE;
+
+        data_left = MV_MIN(skb_shinfo(skb)->gso_size, total_len);
+        pPktInfo->pktSize += (data_left + hdr_len);
+        total_len -= data_left;
+
+        /* Update fields */
+        iph = (struct iphdr*)(extra_ptr + mac_hdr_len);
+        iph->tot_len = htons(data_left + hdr_len - mac_hdr_len);
+        iph->id = htons(ip_id);
+
+        tcph = (struct tcphdr*)(extra_ptr + skb_transport_offset(skb));
+        tcph->seq = htonl(tcp_seq);
+/*
+        printk("pkt=%d, extra=%p, left=%d, total=%d, iph=%p, tcph=%p, id=%d, seq=0x%x\n",
+                pkt, extra_ptr, data_left, total_len, iph, tcph, ip_id, tcp_seq);
+*/
+        tcp_seq += data_left;
+        ip_id++;
+        if(total_len == 0)
+        {
+            /* Only for last packet */
+            pPktInfo->osInfo = (MV_ULONG)skb;
+        }
+        else
+        {
+            /* Clear all special flags for not last packet */
+            tcph->psh = 0;
+            tcph->fin = 0;
+            tcph->rst = 0;
+            pPktInfo->osInfo = (MV_ULONG)0;
+        }
+
+        buf = 1;
+        while(data_left > 0)
+        {
+            size = MV_MIN(frag_size, data_left);
+            if(size == 0)
+            {
+                printk("***** ERROR: data_left=%d, frag_size=%d\n", data_left, frag_size);
+                print_skb(skb);
+            }
+            data_left -= size;
+            frag_size -= size;
+            pPktInfo->pFrags[buf].bufVirtPtr = frag_ptr;
+            pPktInfo->pFrags[buf].dataSize = size;
+            frag_ptr += size;
+            buf++;
+            if( (frag < skb_shinfo(skb)->nr_frags) && (frag_size == 0) )
+            {                 
+                skb_frag_ptr = &skb_shinfo(skb)->frags[frag];
+
+                /* Move to next segment */
+                frag_size = skb_frag_ptr->size;
+                frag_ptr = page_address(skb_frag_ptr->page) + skb_frag_ptr->page_offset;
+                frag++;
+            }
+        }
+        /* packet is full */
+        pPktInfo->numFrags = buf;
+        pPktInfo->status =  
+                (ETH_TX_IP_NO_FRAG | ETH_TX_L4_TCP_TYPE |
+                 ETH_TX_GENERATE_L4_CHKSUM_MASK | ETH_TX_GENERATE_IP_CHKSUM_MASK |
+                 ((ip_hdr(skb)->ihl) << ETH_TX_IP_HEADER_LEN_OFFSET) );
+
+        status = mvEthPortSgTx( priv->hal_priv, txq, pPktInfo);
+        if( status == MV_OK ) {
+            priv->tx_count[txq]++;
+            dev->stats.tx_packets++;
+            dev->stats.tx_bytes +=  pPktInfo->pktSize;
+            dev->trans_start = jiffies;
+            ETH_STAT_DBG( priv->eth_stat.tx_hal_ok[txq]++);
+        }
+        else
+        {
+            /* tx failed. */
+
+            /* For single TX queue it must not happen because 
+            *   we stop call to netif_stop_queue in advance 
+            * For Multu TX queue config, free skb and continue without stopping. 
+            */
+            dev->stats.tx_dropped++;
+
+            ETH_DBG( ETH_DBG_TX, ("%s: queue=%d is full, stop transmit\n", dev->name, txq) );
+
+            /* we need to reuse this pPktInfo because TX failed */
+            dev_kfree_skb_any(skb);
+            pPktInfo->osInfo = 0;
+            mvStackPush(priv->txPktInfoPool, (MV_U32)pPktInfo);
+
+            /* Release extra buffer too */            
+  			if(priv->tx_extra_buf_idx[txq] == 0)
+            {
+                priv->tx_extra_buf_idx[txq] = mv_eth_txq_desc[txq]-1;
+            }
+            else
+	    	{
+                priv->tx_extra_buf_idx[txq]--;
+            }
+
+            ETH_STAT_DBG( priv->eth_stat.tx_hal_no_resource[txq]++);
+            return 0;
+        }   
+        pkt++;
+    }    
+    return 0;
+}
+#endif /* ETH_INCLUDE_TSO */
+
+#ifdef ETH_INCLUDE_UFO
+/*********************************************************** 
+ * eth_ufo_tx --                                           *
+ *   send a large UDP packet.                              *
+ ***********************************************************/
+static int eth_ufo_tx(struct sk_buff *skb, struct net_device *dev, int txq)
+{
+   	MV_STATUS       status;
+	unsigned int    nr, fn;
+	skb_frag_t      *fp;
+	mv_eth_priv     *priv = MV_ETH_PRIV(dev);
+	struct iphdr    *iph;
+	MV_PKT_INFO     *pPktInfo;
+	int             buf;
+	char            *data;
+	unsigned int    pkt_sz, pkt_nm, size;
+	unsigned int    left, mtu, hlen, hhlen, dlen, offset;
+	int             extra_buf_used = 0;
+
+	ETH_DBG(ETH_DBG_GSO, ("UFO: sbk=%p len=%d gso_type=%d gso_segs=%d, gso_size=%d nr_frags=%d\n",              
+						  skb, skb->len, 
+						  skb_shinfo(skb)->gso_type, 
+						  skb_shinfo(skb)->gso_segs, 
+						  skb_shinfo(skb)->gso_size,
+						  skb_shinfo(skb)->nr_frags));
+
+	ETH_DBG(ETH_DBG_GSO, ("UFO: page[h] %d bytes\n", skb_headlen(skb)));
+
+#ifdef ETH_DEBUG
+	for (fn=0; fn<skb_shinfo(skb)->nr_frags; fn++)
+		ETH_DBG(ETH_DBG_GSO, ("UFO: page[%d] %d bytes\n", fn, skb_shinfo(skb)->frags[fn].size));
+#endif
+
+	iph = ip_hdr(skb);
+	hlen = iph->ihl * 4;
+	hhlen = skb_network_offset(skb);
+	mtu = dev->mtu + hhlen;
+
+	if (skb->ip_summed != CHECKSUM_NONE) {
+		struct udphdr *udph = udp_hdr(skb);
+		udph->check = 0;
+		offset = hhlen + hlen;
+		skb->csum = skb_checksum(skb, offset, skb->len - offset, 0);
+		udph->check = csum_tcpudp_magic(iph->saddr, iph->daddr, skb->len - hhlen - hlen, IPPROTO_UDP, skb->csum);
+	}
+
+	fn = 0;
+	nr = skb_shinfo(skb)->nr_frags;
+
+	/* skb_headlen */
+	size = skb_headlen(skb);
+	data = skb->data;
+	left = skb->len - hhlen - hlen; /* actual data to send */
+	offset = 0;
+
+	while (left) {
+       	pPktInfo = (MV_PKT_INFO*)mvStackPop(priv->txPktInfoPool);
+
+		extra_buf_used = 0;
+		/* ip header */
+		if (offset) { 	
+			data = priv->tx_extra_bufs[txq][priv->tx_extra_buf_idx[txq]++];
+            if(priv->tx_extra_buf_idx[txq] == mv_eth_txq_desc[txq])
+                priv->tx_extra_buf_idx[txq] = 0;
+
+#ifdef CONFIG_MV_GATEWAY
+	    /* Note: supports Marvell Header mode, not VLAN mode */
+            if(priv->isGtw)
+            {
+                struct mv_vlan_cfg *vlan_cfg = MV_NETDEV_VLAN(dev);
+
+	        *(unsigned short *)(data) = vlan_cfg->header;
+
+                pPktInfo->pFrags[0].bufVirtPtr = data;
+                pPktInfo->pFrags[0].dataSize = ETH_MV_HEADER_SIZE;
+          	pPktInfo->pktSize = ETH_MV_HEADER_SIZE;
+            }
+            else
+#endif /* CONFIG_MV_GATEWAY */
+            {
+                pPktInfo->pFrags[0].dataSize = 0;
+                pPktInfo->pktSize = 0;
+                pPktInfo->pFrags[0].bufVirtPtr = data + ETH_MV_HEADER_SIZE;
+            }
+
+			extra_buf_used = 1;
+			data += 2; 
+			size = hhlen + hlen;
+			memcpy(data, skb->data, size);
+		}
+
+		iph = (struct iphdr*)(((u32)data)+hhlen);	
+		pPktInfo->pFrags[0].dataSize += size;
+		buf = 1;
+		pkt_nm = 1;
+		pkt_sz = size;
+		ETH_DBG(ETH_DBG_GSO, ("UFO: add pkt[%d] %d bytes total=%d\n", pkt_nm-1, size, pkt_sz));	
+
+		/* payload */
+		while (fn < nr) {
+			fp = &skb_shinfo(skb)->frags[fn];
+
+			BUG_ON(mtu < pkt_sz);
+
+			size = min_t(int, fp->size, mtu - pkt_sz);
+			data = page_address(fp->page) + fp->page_offset;
+
+			fp->page_offset += size;
+			fp->size -= size;
+
+			if (fp->size == 0)
+				fn++;
+
+			if (size) {
+				pPktInfo->pFrags[buf].dataSize = size;
+				pPktInfo->pFrags[buf].bufVirtPtr = data;
+				buf++;
+				pkt_sz += size; 
+				pkt_nm++;
+				BUG_ON(pkt_nm == MAX_SKB_FRAGS);
+				ETH_DBG(ETH_DBG_GSO, ("UFO: add pkt[%d] %d bytes total=%d frag=%d\n", 
+							pkt_nm-1, size, pkt_sz, fn));	
+			}
+
+			if (mtu == pkt_sz)
+				break;
+		}
+
+		/* fill ip header */
+		dlen = pkt_sz - hhlen - hlen;
+
+		ETH_DBG(ETH_DBG_GSO, ("UFO: ip_payload=%d (bad=%d), offset=%d\n", 
+							   dlen, dlen & 7, offset));
+
+		iph->tot_len = htons(pkt_sz - hhlen);		
+		iph->frag_off = htons(offset>>3);
+		offset += dlen;
+		left -= dlen;
+		if (left)
+			iph->frag_off |= htons(IP_MF);
+
+		pPktInfo->osInfo = left ? 0 : (MV_ULONG)skb;
+		pPktInfo->pktSize += pkt_sz;
+		pPktInfo->numFrags = pkt_nm;
+		pPktInfo->status = ETH_TX_GENERATE_IP_CHKSUM_MASK | ((iph->ihl) << ETH_TX_IP_HEADER_LEN_OFFSET);
+
+		status = mvEthPortSgTx(priv->hal_priv, txq, pPktInfo);
+		ETH_DBG(ETH_DBG_GSO, ("UFO: Tx (ok=%d) %d bytes in %d bufs left=%d\n", 
+			   status, pPktInfo->pktSize, pPktInfo->numFrags, left));
+
+		if (status == MV_OK) {
+			dev->stats.tx_packets++;
+			dev->stats.tx_bytes += pPktInfo->pktSize;
+			dev->trans_start = jiffies;
+			priv->tx_count[txq]++;
+			ETH_STAT_DBG(priv->eth_stat.tx_hal_ok[txq]++);
+		}
+		else {
+            /* tx failed. */
+
+            /* For single TX queue it must not happen because 
+            *   we stop call to netif_stop_queue in advance 
+            * For Multu TX queue config, free skb and continue without stopping. 
+            */
+			dev->stats.tx_dropped++;
+
+			ETH_DBG( ETH_DBG_TX, ("%s: q=%d is full, stop transmit\n", dev->name, txq) );
+
+            /* we need to reuse this pPktInfo because TX failed */
+            dev_kfree_skb_any(skb);
+            pPktInfo->osInfo = 0;
+            mvStackPush(priv->txPktInfoPool, (MV_U32)pPktInfo);
+
+            /* Release extra buffer too */            
+  			if(priv->tx_extra_buf_idx[txq] == 0)
+            {
+                priv->tx_extra_buf_idx[txq] = mv_eth_txq_desc[txq]-1;
+            }
+            else
+	    	{
+                priv->tx_extra_buf_idx[txq]--;
+            }
+
+			ETH_STAT_DBG(priv->eth_stat.tx_hal_no_resource[txq]++);
+			return 0;
+		}   		
+	}
+
+    return 0;
+}
+#endif /* ETH_INCLUDE_UFO */
+
+/*********************************************************** 
+ * mv_eth_tx --                                         *
+ *   send a packet.                                        *
+ ***********************************************************/
+static int eth_tx( struct sk_buff *skb , struct net_device *dev )
+{
+    mv_eth_priv             *priv = MV_ETH_PRIV(dev);
+    struct net_device_stats *stats = MV_NETDEV_STATS(dev);
+    unsigned long           flags = 0;
+    MV_STATUS               status;
+    MV_PKT_INFO             *pPktInfo;
+    int                     ret = 0, i, queue, tx_done_count;
+    int tx_in_interrupt	    = in_interrupt();
+
+    if( netif_queue_stopped( dev ) ) {
+        printk( KERN_ERR "%s: transmitting while stopped\n", dev->name );
+        return 1;
+    }
+
+    if (!tx_in_interrupt)
+    	local_irq_save(flags);
+
+    if (!spin_trylock(priv->lock)) {
+        /* Collision - tell upper layer to requeue */
+	    if (!tx_in_interrupt)
+            local_irq_restore(flags);
+        return NETDEV_TX_LOCKED;
+    }
+
+    ETH_DBG( ETH_DBG_TX, ("%s: tx len=%d headlen=%d frags=%d, ip_summed=%d gso_type=%d\n",
+             dev->name, skb->len, skb_headlen(skb), skb_shinfo(skb)->nr_frags, skb->ip_summed,skb_shinfo(skb)->gso_type));
+    ETH_STAT_INFO(priv->eth_stat.tx_events++);
+
+    /* At this point we need to decide to which tx queue this packet goes, */
+    /* and whether we need to prepend a proprietary header.                */
+    queue = eth_tx_policy(priv, skb);
+
+#ifdef ETH_INCLUDE_TSO
+    if (skb_shinfo(skb)->gso_type & SKB_GSO_TCPV4) {
+        ret = eth_tso_tx(skb, dev, queue);
+	ETH_STAT_DBG( priv->eth_stat.tso_stats[skb->len >> 10]++);
+        goto tx_end;
+    }
+#endif /* ETH_INCLUDE_TSO */
+
+#ifdef ETH_INCLUDE_UFO
+    if (skb_shinfo(skb)->gso_type & SKB_GSO_UDP) {
+	    if (skb->len > dev->mtu) {
+	        ETH_STAT_DBG(priv->eth_stat.ufo_stats[skb->len >> 10]++);
+	        ret = eth_ufo_tx(skb, dev, queue);
+	        goto tx_end;
+	    }
+    }
+#endif /* ETH_INCLUDE_UFO */
+
+    pPktInfo = (MV_PKT_INFO*)mvStackPop(priv->txPktInfoPool);
+    pPktInfo->osInfo = (MV_ULONG)skb;
+    pPktInfo->pktSize = skb->len;
+    pPktInfo->status = 0;
+
+    /* see if this is a single/multiple buffered skb */
+    if( skb_shinfo(skb)->nr_frags == 0 ) {
+        pPktInfo->pFrags->bufVirtPtr = skb->data;
+        pPktInfo->pFrags->dataSize = skb->len;
+        pPktInfo->numFrags = 1;
+    }
+    else {
+
+        MV_BUF_INFO *p_buf_info = pPktInfo->pFrags;
+
+        /* first skb fragment */
+        p_buf_info->dataSize = skb_headlen(skb);
+        p_buf_info->bufVirtPtr = skb->data;
+        p_buf_info++;
+
+        /* now handle all other skb fragments */
+        for ( i = 0; i < skb_shinfo(skb)->nr_frags; i++ ) {
+
+            skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
+
+            p_buf_info->dataSize = frag->size;
+            p_buf_info->bufVirtPtr = page_address(frag->page) + frag->page_offset;
+            p_buf_info++;
+        }
+        pPktInfo->numFrags = skb_shinfo(skb)->nr_frags + 1;
+    }
+
+#ifdef TX_CSUM_OFFLOAD
+    /* if HW is suppose to offload layer3 and layer4 checksum, 
+     *   set some bits in the first pkt_info command.
+    */
+    if(skb->ip_summed == CHECKSUM_PARTIAL) {
+        struct iphdr *iph = ip_hdr(skb); 
+
+        ETH_DBG( ETH_DBG_TX, ("%s: tx csum offload\n", dev->name) );
+        ETH_STAT_DBG( priv->eth_stat.tx_csum_hw++);
+
+        /* we do not handle fragmented IP packets. add check inside iph!! */
+        pPktInfo->status = ETH_TX_IP_NO_FRAG | ETH_TX_GENERATE_IP_CHKSUM_MASK |          
+                           (iph->ihl << ETH_TX_IP_HEADER_LEN_OFFSET);   
+
+        if(iph->protocol == IPPROTO_TCP) 
+            pPktInfo->status |= (ETH_TX_L4_TCP_TYPE | ETH_TX_GENERATE_L4_CHKSUM_MASK);
+        else if(iph->protocol == IPPROTO_UDP)
+            pPktInfo->status |= (ETH_TX_L4_UDP_TYPE | ETH_TX_GENERATE_L4_CHKSUM_MASK);
+    }
+    else {
+        ETH_DBG( ETH_DBG_TX, ("%s: no tx csum offload\n", dev->name) );
+        ETH_STAT_DBG( priv->eth_stat.tx_csum_sw++);
+        pPktInfo->status = 0x5 << ETH_TX_IP_HEADER_LEN_OFFSET; /* Errata BTS #50 */
+    }
+#endif
+
+#ifdef CONFIG_MV_GATEWAY
+    if(priv->isGtw)
+        mv_gtw_update_tx_skb(dev, pPktInfo);
+#endif /* CONFIG_MV_GATEWAY */
+
+    /* now send the packet */
+    status = mvEthPortSgTx( priv->hal_priv, queue, pPktInfo);
+
+    /* check status */
+    if( status == MV_OK ) {
+        priv->tx_count[queue]++;
+        stats->tx_bytes += skb->len;
+        stats->tx_packets ++;
+        dev->trans_start = jiffies;
+        ETH_STAT_DBG( priv->eth_stat.tx_hal_ok[queue]++);
+    }
+    else {
+        /* tx failed. */
+
+        /* For single TX queue it must not happen because 
+         *   we stop call to netif_stop_queue in advance 
+         * For Multu TX queue config, free skb and continue without stopping. 
+         */
+        stats->tx_dropped++;
+
+        /* it must not happen because we call to netif_stop_queue in advance. */
+        ETH_DBG( ETH_DBG_TX, ("%s: TX queue=%d is full\n", dev->name, queue) );
+
+        /* we need to reuse this pPktInfo because TX failed */
+        dev_kfree_skb_any(skb);
+        pPktInfo->osInfo = 0;
+        mvStackPush(priv->txPktInfoPool, (MV_U32)pPktInfo);
+
+        ETH_STAT_DBG( priv->eth_stat.tx_hal_no_resource[queue]++);
+    }
+
+#if defined(ETH_INCLUDE_TSO) || defined(ETH_INCLUDE_UFO)
+tx_end:
+#endif
+
+#ifdef ETH_TX_DONE_ISR
+#else
+
+
+#ifdef ETH_MV_TX_EN
+        if(priv->tx_en)
+            eth_tx_enable(priv, queue);
+#endif /* ETH_MV_TX_EN */
+
+    if( priv->tx_count[queue] >= mv_eth_tx_done_quota)
+    {
+        tx_done_count = eth_tx_done(priv, queue);
+        priv->tx_count[queue] -= tx_done_count;
+    }
+#endif /* ETH_TX_DONE_ISR */ 
+
+#if (MV_ETH_TX_Q_NUM == 1)
+    /* if number of available descriptors left is less than  */
+    /* MAX_SKB_FRAGS stop the stack. if multi queue is used, */
+    /* don't stop the stack just because one queue is full.  */
+    if( mvEthTxResourceGet(priv->hal_priv, ETH_DEF_TXQ) <= MAX_SKB_FRAGS ) {
+        ETH_DBG( ETH_DBG_TX, ("%s: stopping network tx interface\n", dev->name) );
+        netif_stop_queue( dev );
+        ETH_STAT_ERR(priv->eth_stat.tx_netif_stop++);
+    }
+#endif /* (MV_ETH_TX_Q_NUM > 1) */
+
+    if (!tx_in_interrupt)
+	    spin_unlock_irqrestore(priv->lock, flags);	    
+    else
+        spin_unlock(priv->lock);
+
+    return ret;
+}
+
+/*********************************************************** 
+ * eth_tx_timeout --                                       *
+ *   nothing to be done (?)                                *
+ ***********************************************************/
+static void eth_tx_timeout( struct net_device *dev ) 
+{
+#ifdef CONFIG_MV_ETH_STATS_ERR
+    mv_eth_priv  *priv = MV_ETH_PRIV(dev);
+    
+    priv->eth_stat.tx_timeout++;
+#endif /* #ifdef CONFIG_MV_ETH_STATS_INFO */    
+
+    printk( KERN_INFO "%s: tx timeout\n", dev->name );
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,24)
+static const struct net_device_ops mv_eth_netdev_ops = {
+	.ndo_open		= mv_eth_open,
+	.ndo_stop		= mv_eth_stop,
+	.ndo_start_xmit		= eth_tx,
+	.ndo_set_multicast_list	= mv_eth_set_multicast_list,
+	.ndo_set_mac_address	= mv_eth_set_mac_addr,
+	.ndo_change_mtu		= mv_eth_change_mtu,
+	.ndo_tx_timeout		= eth_tx_timeout,
+};
+
+#ifdef CONFIG_MV_GATEWAY
+static const struct net_device_ops mv_eth_gtw_netdev_ops = {
+	.ndo_open		= mv_gtw_start,
+	.ndo_stop		= mv_gtw_stop,
+	.ndo_start_xmit		= eth_tx,
+	.ndo_set_multicast_list	= mv_gtw_set_multicast_list,
+	.ndo_set_mac_address	= mv_gtw_set_mac_addr,
+	.ndo_change_mtu		= mv_gtw_change_mtu,
+	.ndo_tx_timeout		= eth_tx_timeout,
+};
+#endif
+#endif
+
+/*********************************************************** 
+ * mv_netdev_init -- Allocate and initialize net_device    *
+ *                   structure                             *
+ ***********************************************************/
+struct net_device* __init mv_netdev_init(mv_eth_priv *priv, int mtu, u8* mac)
+{
+    struct net_device   *dev;
+    mv_net_priv         *net_priv;
+#if defined(CONFIG_MV_GATEWAY) && LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,24)
+    static int 		once_flag = 0;
+#endif
+
+    dev = alloc_etherdev(sizeof(mv_net_priv));
+    if( !dev ) {
+        return NULL;
+    }
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    net_priv = (mv_net_priv *)dev->priv;
+#else
+    net_priv = (mv_net_priv *)netdev_priv(dev);
+#endif
+    if( !net_priv ) { 
+        return NULL;
+    }
+    memset( net_priv , 0, sizeof(mv_net_priv) );
+    net_priv->giga_priv = priv;
+
+    dev->irq = ETH_PORT_IRQ_NUM(priv->port);
+    dev->mtu = mtu;
+    memcpy(dev->dev_addr, mac, 6);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    dev->weight = (CONFIG_MV_ETH_NUM_OF_RX_DESCR / 2);
+#endif
+    dev->tx_queue_len = CONFIG_MV_ETH_NUM_OF_TX_DESCR;
+    dev->watchdog_timeo = 5*HZ;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    dev->hard_start_xmit = eth_tx;
+    dev->tx_timeout = eth_tx_timeout;
+    dev->poll = eth_poll;
+
+    dev->open = mv_eth_open;
+    dev->stop = mv_eth_stop;
+    dev->set_mac_address = mv_eth_set_mac_addr;
+    dev->set_multicast_list = mv_eth_set_multicast_list;
+    dev->change_mtu = &mv_eth_change_mtu; 
+#else
+    dev->netdev_ops = &mv_eth_netdev_ops;
+#ifdef CONFIG_MV_GATEWAY
+    if (priv->isGtw)
+    {
+	if (once_flag == 0)
+	{
+		once_flag = 1;
+		netif_napi_add(dev, &priv->napi, eth_poll, CONFIG_MV_ETH_NUM_OF_RX_DESCR / 2);
+	}
+    }
+    else
+#endif /* CONFIG_MV_GATEWAY */
+    {
+	netif_napi_add(dev, &priv->napi, eth_poll, CONFIG_MV_ETH_NUM_OF_RX_DESCR / 2);
+    }
+#endif
+
+#ifdef CONFIG_MV_ETH_TOOL
+    SET_ETHTOOL_OPS(dev, &mv_eth_tool_ops);
+#endif
+
+#ifdef CONFIG_MV_GATEWAY
+    if(priv->isGtw)
+    {
+        /* For Gateway driver replace some of callback functions */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+	dev->open = mv_gtw_start;
+	dev->stop = mv_gtw_stop;
+	dev->set_mac_address = mv_gtw_set_mac_addr;
+	dev->set_multicast_list = mv_gtw_set_multicast_list;
+	dev->change_mtu = &mv_gtw_change_mtu;
+#else
+	dev->netdev_ops = &mv_eth_gtw_netdev_ops;
+#endif
+        dev->hard_header_len += ETH_MV_HEADER_SIZE;
+    }
+#endif /* CONFIG_MV_GATEWAY */
+
+#ifdef ETH_LRO
+    if (!priv->lro_mgr.dev)
+	priv->lro_mgr.dev = dev;
+#endif
+
+    priv->timer.data = (unsigned long)dev;
+
+    mv_netdev_set_features(dev);
+
+    if (mv_plat_dev && (priv->port == 0)) {
+	printk("    o  register under %s platform\n", mv_plat_dev->name);
+	platform_set_drvdata(mv_plat_dev, dev);
+	SET_NETDEV_DEV(dev, &mv_plat_dev->dev);
+    }
+
+    if(register_netdev(dev)) {
+	printk(KERN_ERR "failed to register %s\n",dev->name);
+        free_netdev(dev);
+        return NULL;
+    }
+    else {
+	printk("    o %s, ifindex = %d, GbE port = %d\n",dev->name, dev->ifindex, priv->port);
+    }
+    return dev;
+}
+
+int     mv_eth_tos_map_set(int port, unsigned char tos, int queue)
+{
+    int             rc = 0;
+    mv_eth_priv     *priv = eth_priv_by_port(port);
+
+    if (priv == NULL)
+    {
+        printk("eth_status_print: wrong port number %d\n", port);
+	    return 1;
+    }
+#if defined(CONFIG_MV_GATEWAY)
+    if(priv->isGtw)
+    {
+        rc = mv_gtw_switch_tos_set(port, tos, queue);
+    }
+    else
+#endif /* CONFIG_MV_GATEWAY */
+    {
+        rc = mvEthTosToRxqSet(priv->hal_priv, tos, queue);
+    }
+    return rc;
+}
+
+void    mv_eth_tos_map_show(int port)
+{
+    unsigned int    tos;
+    int             queue;
+    mv_eth_priv     *priv = eth_priv_by_port(port);
+
+    if (priv == NULL)
+    {
+        printk("eth_status_print: wrong port number %d\n", port);
+	    return;
+    }
+    printk("ethPort_%d TOS Map: \n\n", port);
+
+    for(tos=0; tos<=0xFC; tos+=0x4) 
+    {
+#if defined(CONFIG_MV_GATEWAY)
+        if(priv->isGtw)
+        {
+            queue = mv_gtw_switch_tos_get(port, tos);
+        }
+        else
+#endif /* CONFIG_MV_GATEWAY */
+        {
+            queue = mvEthTosToRxqGet(priv->hal_priv, tos);
+        }
+	    if (queue != -1)
+        {
+		   printk("tos=0x%x: codepoint=0x%x, queue=%d\n", 
+                   tos, tos>>2, queue);
+        }
+	}
+}
+
+static void __init mv_eth_tos_map_init(int port)
+{
+    unsigned int    tos;
+
+    /* Set all codepoints to ETH_DEF_RXQ */
+    for(tos=0; tos<=0xFC; tos+=0x4) 
+    {
+        mv_eth_tos_map_set(port, tos, ETH_DEF_RXQ);
+    }
+
+#if (MV_ETH_RX_Q_NUM > 1)
+    for(tos=0; tos<=0xFC; tos+=0x4) 
+    {
+        int queue;
+
+        queue = mv_eth_tos_to_q_map(tos, MV_ETH_RX_Q_NUM);
+        mv_eth_tos_map_set(port, tos, queue);
+	}
+#endif /* MV_ETH_RX_Q_NUM > 1 */
+}
+
+/***********************************************************************************
+ ***  print net device status
+ ***********************************************************************************/
+void    mv_eth_netdev_print(unsigned int idx)
+{
+    struct net_device   *dev = eth_net_device_by_idx(idx);
+
+    printk("%s net_device status: dev=%p, priv=%p\n\n", 
+                dev->name, dev, MV_ETH_PRIV(dev));
+    printk("ifIdx=%d, features=0x%x, flags=0x%x, mtu=%u, size=%d\n", 
+            dev->ifindex, (unsigned int)(dev->features), (unsigned int)(dev->flags), 
+            dev->mtu, MV_RX_BUF_SIZE(dev->mtu));
+}
+
+
+/***********************************************************************************
+ ***  noqueue net device
+ ***********************************************************************************/
+extern struct Qdisc noop_qdisc;
+void mv_eth_set_noqueue(int idx, int enable)
+{
+    struct net_device *dev = eth_net_device_by_idx(idx);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+    if (dev->flags & IFF_UP) {
+            printk(KERN_ERR "%s: device or resource busy, take it down\n", dev->name);
+            return;
+    }
+    dev->tx_queue_len = enable ? 0 : CONFIG_MV_ETH_NUM_OF_TX_DESCR;
+
+    dev->qdisc_sleeping = &noop_qdisc;
+#else
+    struct netdev_queue *txq = netdev_get_tx_queue(dev, 0);
+
+    if (dev->flags & IFF_UP) {
+            printk(KERN_ERR "%s: device or resource busy, take it down\n", dev->name);
+            return;
+    }
+    dev->tx_queue_len = enable ? 0 : CONFIG_MV_ETH_NUM_OF_TX_DESCR;
+
+    if (txq)
+    	txq->qdisc_sleeping = &noop_qdisc;
+    else
+	printk(KERN_ERR "%s: txq #0 is NULL\n", dev->name);
+#endif
+    printk(KERN_ERR "%s: device tx queue len is %d\n", dev->name, (int)dev->tx_queue_len);
+}
+
+/***********************************************************************************
+ ***  LRO configuration
+ ***********************************************************************************/
+void mv_eth_set_lro(int port, int enable)
+{
+#ifdef ETH_LRO
+	mv_eth_priv* priv = eth_priv_by_port(port);
+	if (priv)
+		priv->lro_en = enable;
+#endif		 
+}
+void mv_eth_set_lro_desc(int port, unsigned int value)
+{
+#ifdef ETH_LRO
+	mv_eth_priv* priv = eth_priv_by_port(port);
+
+	if (value > ETH_LRO_DESC) 
+		value = ETH_LRO_DESC;
+
+	if (priv) 
+        priv->lro_mgr.max_desc = value;
+#endif
+}
+/***********************************************************************************
+ ***  print Ethernet port status
+ ***********************************************************************************/
+void    mv_eth_status_print( unsigned int port )
+{
+    mv_eth_priv         *priv = eth_priv_by_port(port);
+
+    if (priv == NULL)
+    {
+        printk("eth_status_print: wrong port number %d\n", port);
+	    return;
+    }
+    printk("ethPort_%d Status: priv=%p\n\n", port, priv);
+
+    printk("tx_total=%d, rx_total=%d, tx_done_quota=%d\n\n", 
+            mv_eth_tx_desc_total, mv_eth_rx_desc_total, mv_eth_tx_done_quota);
+
+    printk("txPktInfoPool status:\n");
+    mvStackStatus(priv->txPktInfoPool, 0);
+    printk("\n");
+
+#ifdef ETH_MV_TX_EN
+    printk("TxEnable WA - %s. deep=%d, tx_en_bk=%d\n\n", 
+            priv->tx_en ? "Enabled" : "Disabled", 
+            priv->tx_en_deep, priv->tx_en_bk);    
+#endif /* ETH_MV_TX_EN */
+
+#ifdef CONFIG_MV_ETH_NFP
+    printk("NFP - %s.\n\n", fp_is_enabled() ? "Enabled" : "Disabled");
+#endif /* CONFIG_MV_ETH_NFP */
+
+#if defined(CONFIG_MV_ETH_NFP) || defined(CONFIG_MV_ETH_SKB_REUSE)
+    printk("fpRxPool status:\n");
+    mvStackStatus(priv->fpRxPool, 0);
+    printk("\n");
+#endif /* CONFIG_MV_ETH_NFP | CONFIG_MV_ETH_SKB_REUSE */
+
+#ifdef CONFIG_MV_ETH_SKB_REUSE
+    printk("SKB Reuse - %s. min skb size=%d, skbReusePool status:\n", 
+            eth_skb_reuse_enable ? "Enabled" : "Disabled",
+            SKB_DATA_ALIGN(MV_RX_BUF_SIZE(priv->net_dev->mtu) + 
+						   CPU_D_CACHE_LINE_SIZE + 8 + NET_SKB_PAD));
+    mvStackStatus(priv->skbReusePool, 0);
+    printk("\n");
+#endif /* CONFIG_MV_ETH_SKB_REUSE */
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+    printk("SKB Recycle - %s, min skb size=%d, skbRecyclePool status:\n", 
+            eth_skb_recycle_enable ? "Enabled" : "Disabled",
+            priv->skbRecycleMTU);
+    mvStackStatus(priv->skbRecyclePool, 0);
+    printk("\n");
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+#ifdef ETH_LRO
+	{
+		int i = mv_net_devs_num;
+		struct net_device* dev;
+		u32 ipaddr;
+
+        	printk("LRO - %s, sessions=%d/%d\n", 
+		   priv->lro_en ? "Enabled" : "Disabled", 
+           	priv->lro_mgr.max_desc, ETH_LRO_DESC);
+
+		while (i--) {
+			dev = mv_net_devs[i];
+			if (dev && (priv == MV_ETH_PRIV(dev))) {
+				ipaddr = mv_eth_dev_ip(dev);
+				printk("LRO ip=%d.%d.%d.%d (%s)\n", 
+					   ipaddr & 0xff, (ipaddr >> 8) & 0xff,
+					   (ipaddr >> 16) & 0xff, ipaddr >> 24, dev->name);
+			}
+		}
+	}
+#endif /* ETH_LRO */
+}
+
+/***********************************************************************************
+ ***  print port statistics
+ ***********************************************************************************/
+#define   STAT_PER_Q(qnum,x) for(queue = 0; queue < qnum; queue++) \
+                printk("%10u ",x[queue]); \
+                    printk("\n");
+
+void mv_eth_stats_print( unsigned int port )
+{
+    mv_eth_priv         *priv = eth_priv_by_port(port);
+    eth_statistics      *stat = NULL;
+
+    TRC_OUTPUT();
+
+    if (priv == NULL)
+    {
+	printk("eth_stats_print: wrong port number %d\n", port);
+	return;
+    }
+    stat = &(priv->eth_stat);
+
+    printk( "\n====================================================\n" );
+    printk( "ethPort_%d: Errors", port);
+    printk( "\n-------------------------------\n" );
+    printk( "skb_alloc_fail................%10u\n", stat->skb_alloc_fail );
+    printk( "tx_timeout....................%10u\n", stat->tx_timeout );
+    printk( "tx_netif_stop.................%10u\n", stat->tx_netif_stop );
+    printk( "tx_done_netif_wake............%10u\n", stat->tx_done_netif_wake );
+    printk( "tx_skb_no_headroom............%10u\n", stat->tx_skb_no_headroom );
+
+#ifdef CONFIG_MV_ETH_STATS_INFO
+    printk( "\n====================================================\n" );
+    printk( "ethPort_%d: interrupt statistics", port );
+    printk( "\n-------------------------------\n" );
+    printk( "irq_total.....................%10u\n", stat->irq_total );
+    printk( "irq_none_events...............%10u\n", stat->irq_none );
+    printk( "irq_while_polling.............%10u\n", stat->irq_while_polling );
+    printk( "picr is.......................%10x\n", priv->picr);
+    printk( "picer is......................%10x\n", priv->picer);
+
+    printk( "\n====================================================\n" );
+    printk( "ethPort_%d: Events", port );
+    printk( "\n-------------------------------\n" );
+    printk( "poll_events...................%10u\n", stat->poll_events );
+    printk( "poll_complete.................%10u\n", stat->poll_complete );
+    printk( "tx_events.....................%10u\n", stat->tx_events );
+    printk( "tx_done_events................%10u\n", stat->tx_done_events );
+    printk( "timer_events..................%10u\n", stat->timer_events);
+#if defined(CONFIG_MV_ETH_NFP) || defined(CONFIG_MV_ETH_SKB_REUSE)
+    printk( "rx_pool_empty.................%10u\n", stat->rx_pool_empty );
+#endif /* CONFIG_MV_ETH_NFP || CONFIG_MV_ETH_SKB_REUSE */
+
+#endif /* CONFIG_MV_ETH_STATS_INFO */
+
+#ifdef CONFIG_MV_ETH_STATS_DEBUG
+    {
+        unsigned int queue=0, i=0;
+
+        printk("\n");
+        printk("RXQs:.........................");
+        for(queue=0; queue<MV_ETH_RX_Q_NUM; queue++) 
+            printk( "%10d ", queue);
+        printk("\n");
+
+        printk( "rx_hal_ok....................."); STAT_PER_Q(MV_ETH_RX_Q_NUM, stat->rx_hal_ok);
+        printk( "rx_fill_ok...................."); STAT_PER_Q(MV_ETH_RX_Q_NUM, stat->rx_fill_ok);
+        printk("\n");
+
+        printk("TXQs:.........................");
+        for(queue=0; queue<MV_ETH_TX_Q_NUM; queue++) 
+            printk( "%10d ", queue);
+        printk("\n");
+        printk( "tx_count......................"); STAT_PER_Q(MV_ETH_TX_Q_NUM, priv->tx_count);
+        printk( "tx_hal_ok....................."); STAT_PER_Q(MV_ETH_TX_Q_NUM, stat->tx_hal_ok);
+        printk( "tx_hal_no_resource............"); STAT_PER_Q(MV_ETH_TX_Q_NUM, stat->tx_hal_no_resource );
+        printk( "tx_done_hal_ok................"); STAT_PER_Q(MV_ETH_TX_Q_NUM, stat->tx_done_hal_ok);
+        printk("\n");
+
+        printk( "skb_alloc_ok..................%10u\n", stat->skb_alloc_ok );
+        printk( "skb_free_ok...................%10u\n", stat->skb_free_ok );
+
+#ifdef CONFIG_MV_ETH_SKB_REUSE
+        printk( "skb_reuse_rx..................%10u\n", stat->skb_reuse_rx);
+        printk( "skb_reuse_tx..................%10u\n", stat->skb_reuse_tx);
+        printk( "skb_reuse_alloc...............%10u\n", stat->skb_reuse_alloc);
+#endif /* CONFIG_MV_ETH_SKB_REUSE */
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+	printk("\n");
+        printk( "skb_recycle_put...............%10u\n", stat->skb_recycle_put);
+        printk( "skb_recycle_get...............%10u\n", stat->skb_recycle_get);
+	printk( "skb_recycle_full..............%10u\n", stat->skb_recycle_full);
+	printk( "skb_recycle_del...............%10u\n", stat->skb_recycle_del);
+	printk( "skb_recycle_rej...............%10u\n", stat->skb_recycle_rej);
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+        printk("\n");
+
+	printk( "tx_csum_hw....................%10u\n", stat->tx_csum_hw);
+	printk( "tx_csum_sw....................%10u\n", stat->tx_csum_sw);
+        printk("\n");
+
+        printk( "rx_netif_drop.................%10u\n", stat->rx_netif_drop );
+	printk( "rx_csum_hw....................%10u\n", stat->rx_csum_hw);
+	printk( "rx_csum_hw_frags..............%10u\n", stat->rx_csum_hw_frags);
+	printk( "rx_csum_sw....................%10u\n", stat->rx_csum_sw);
+
+#ifdef ETH_MV_TX_EN
+        printk( "\n");
+        printk( "tx_en_done....................%10u\n", stat->tx_en_done);
+        printk( "tx_en_busy....................%10u\n", stat->tx_en_busy);
+        printk( "tx_en_wait....................%10u\n", stat->tx_en_wait);
+        printk( "tx_en_wait_count..............%10u\n", stat->tx_en_wait_count);
+#endif /* ETH_MV_TX_EN */
+
+        printk("\n      Linux Path RX distribution\n");
+        for(i=0; i<sizeof(stat->rx_dist)/sizeof(u32); i++)
+        {
+            if(stat->rx_dist[i] != 0)
+                printk("%d RxPkts - %d times\n", i, stat->rx_dist[i]);
+        } 
+
+#ifdef ETH_INCLUDE_TSO
+        printk("\n      TSO stats\n");
+        for(i=0; i<64; i++)
+        {
+            if(stat->tso_stats[i] != 0)
+            {
+                printk("\t %d KBytes - %d times\n", i, stat->tso_stats[i]);
+                stat->tso_stats[i] = 0;
+            }
+        }
+#endif /* ETH_INCLUDE_TSO */
+
+#ifdef ETH_INCLUDE_UFO
+        printk("\n      UFO stats\n");
+        for(i=0; i<64; i++)
+        {
+	        if(stat->ufo_stats[i] != 0)
+	        {
+		        printk("\t %d KBytes - %d times\n", i, stat->ufo_stats[i]);
+		        stat->ufo_stats[i] = 0;
+	        }
+	    }
+#endif /* ETH_INCLUDE_UFO */
+
+        printk("\n      tx-done stats\n");
+        for(i=0; i<sizeof(stat->tx_done_dist)/sizeof(u32); i++)
+        {
+          if(stat->tx_done_dist[i] != 0)
+              printk("%d TxDonePkts - %d times\n", i, stat->tx_done_dist[i]);
+        } 
+    }
+#endif /* CONFIG_MV_ETH_STATS_DEBUG */
+
+#ifdef ETH_LRO
+        printk( "\n");
+	    printk( "rx_lro_aggregated.............%10u\n", (u32)priv->lro_mgr.stats.aggregated);
+	    printk( "rx_lro_flushed................%10u\n", (u32)priv->lro_mgr.stats.flushed);
+	    printk( "rx_lro_no_resources...........%10u\n", (u32)priv->lro_mgr.stats.no_desc);
+		memset(&priv->lro_mgr.stats, 0, sizeof(struct net_lro_stats));
+#endif /* ETH_LRO */
+
+		memset( stat, 0, sizeof(eth_statistics) );
+}
+
+#ifdef CONFIG_MV_ETH_NFP
+void     mv_eth_nfp_stats_print(unsigned int port)
+{
+    mv_eth_priv         *priv = eth_priv_by_port(port);
+
+    if (priv == NULL)
+    {
+        printk("eth_nfp_stats_print: wrong port number %d\n", port);
+	    return;
+    }
+
+    mvFpStatsPrint(&priv->fpStats);
+    printk("\n");
+    printk("NFP RX pool status:\n");
+    mvStackStatus(priv->fpRxPool, 0);
+}
+#endif /* CONFIG_MV_ETH_NFP */ 
+
+void eth_print_irq_status(mv_eth_priv *priv)
+{
+    printk("Interrupt Cause Register = 0x%08x (0x%08x)\n", 
+            priv->picr, MV_REG_READ(ETH_INTR_CAUSE_REG(priv->port)));
+
+    printk("Interrupt Mask Register = 0x%08x\n", 
+            MV_REG_READ(ETH_INTR_MASK_REG(priv->port)));
+
+    printk("Interrupt Cause Extend Register = 0x%08x (0x%08x)\n", 
+            priv->picer, MV_REG_READ(ETH_INTR_CAUSE_EXT_REG(priv->port)));
+
+    printk("Interrupt Mask Extend Register = 0x%08x\n", 
+            MV_REG_READ(ETH_INTR_MASK_EXT_REG(priv->port)));
+}
+
+void print_iph(struct iphdr* iph)
+{
+    printk("**************** IP Header: ver=%d, ihl=%d ******************\n", 
+            iph->version, iph->ihl);
+    printk("tot_len=%d, id=0x%x, proto=%d, csum=0x%x, sip=0x%x, dip=0x%x\n",
+            ntohs(iph->tot_len & 0xFFFF), ntohs(iph->id & 0xFFFF), iph->protocol & 0xFF, 
+            ntohs(iph->check & 0xFFFF), ntohl(iph->saddr), ntohl(iph->daddr));
+}
+
+void print_tcph(struct tcphdr* hdr)
+{
+    printk("################## TCP Header: doff=%d ####################\n", hdr->doff); 
+    printk("sPort=%d, dPort=%d, seqId=0x%x, ackId=0x%x, win=0x%x, csum=0x%x\n", 
+            ntohs(hdr->source), ntohs(hdr->dest), ntohl(hdr->seq), ntohl(hdr->ack_seq),
+            ntohs(hdr->window), ntohs(hdr->check) );
+    printk("Flags: fin=%d, syn=%d, rst=%d, psh=%d, ack=%d, urg=%d, ece=%d, cwr=%d\n", 
+            hdr->fin, hdr->syn, hdr->rst, hdr->psh, hdr->ack, hdr->urg, hdr->ece, hdr->cwr);
+}
+
+
+void print_skb(struct sk_buff* skb)
+{
+    int i;
+
+    printk("\nskb=%p: head=%p, data=%p, tail=%p, end=%p\n", 
+                skb, skb->head, skb->data, skb->tail, skb->end);
+    printk("\t users=%d, truesize=%d, len=%d, data_len=%d, mac_len=%d\n", 
+            atomic_read(&skb->users), skb->truesize, skb->len, skb->data_len, skb->mac_len);
+    printk("\t next=%p, prev=%p, csum=0x%x, ip_summed=%d, pkt_type=%d, proto=0x%x, cloned=%d\n",
+            skb->next, skb->prev, skb->csum, skb->ip_summed, skb->pkt_type, 
+            ntohs(skb->protocol & 0xFFFF), skb->cloned);
+    printk("\t mac=%p, nh=%p, h=%p\n", skb_mac_header(skb),  ip_hdr(skb), tcp_hdr(skb));
+    printk("\t dataref=0x%x, nr_frags=%d, gso_size=%d, tso_segs=%d, frag_list=%p\n",
+            atomic_read(&skb_shinfo(skb)->dataref), skb_shinfo(skb)->nr_frags, skb_shinfo(skb)->gso_size,
+            skb_shinfo(skb)->gso_segs, skb_shinfo(skb)->frag_list);
+    for(i=0; i<skb_shinfo(skb)->nr_frags; i++)
+    {
+        printk("\t frag_%d. page=%p, page_offset=0x%x, size=%d\n",
+            i, page_address(skb_shinfo(skb)->frags[i].page), 
+            skb_shinfo(skb)->frags[i].page_offset & 0xFFFF, 
+            skb_shinfo(skb)->frags[i].size & 0xFFFF);
+    }
+    if( (skb->protocol == ntohs(ETH_P_IP)) && (ip_hdr(skb) != NULL) )
+    {
+        print_iph(ip_hdr(skb));
+        if(ip_hdr(skb)->protocol == IPPROTO_TCP)
+            print_tcph(tcp_hdr(skb));
+    }
+    printk("\n");
+}
+
+/*********************************************************** 
+ * eth_init_module --                                    *
+ *   main driver initialization. loading the interfaces.   *
+ ***********************************************************/
+static int __init mv_eth_init_module( void ) 
+{
+    u32             i, port, netdev=0;
+    mv_eth_priv     *priv;
+    u8              mac_addr[6];
+    int             mtu;
+    int             rc;
+
+    rc = platform_driver_register(&mv_eth_driver);
+    if (rc) {
+	printk("can't register Marvell GbE platform driver, %d\n", rc);
+	return rc;
+    }
+
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+    /*if no ports assigned to this CPU, return*/
+    mv_eth_ports_num = mvCtrlEthMaxPortGet();
+#ifdef CONFIG_MV_ETH_PORTS_NUM
+    mv_eth_ports_num = min(mv_eth_ports_num, CONFIG_MV_ETH_PORTS_NUM); 
+#endif
+    for(port=0; port < mv_eth_ports_num; port++)
+    {
+	if (MV_TRUE == mvSocUnitIsMappedToThisCpu(GIGA0+port))
+	{
+		break;
+	}			
+    }
+    if (port == mv_eth_ports_num)
+    {    
+	printk("No Giga ports mapped to this CPU\n");
+	return 1;
+    }
+#endif
+    
+    printk( "Loading Marvell Ethernet Driver:\n");
+
+    /* Initialize mv_eth_rxq_desc array */
+    for(i=0; i<MV_ETH_RX_Q_NUM; i++) 
+    {
+        mv_eth_rxq_desc[i] = CONFIG_MV_ETH_NUM_OF_RX_DESCR;
+	    mv_eth_rx_desc_total += mv_eth_rxq_desc[i];
+    }
+    /* Initialize mv_eth_txq_desc array */
+    for(i=0; i<MV_ETH_TX_Q_NUM; i++) {
+        mv_eth_txq_desc[i] = CONFIG_MV_ETH_NUM_OF_TX_DESCR;
+
+        mv_eth_tx_desc_total += mv_eth_txq_desc[i];
+    }
+
+    spin_lock_init( &mii_lock );
+
+    /* init MAC Unit */
+    mvSysEthInit();
+
+    mv_eth_config_show();
+
+    mv_eth_ports_num = mvCtrlEthMaxPortGet();
+#ifdef CONFIG_MV_ETH_PORTS_NUM
+    if (CONFIG_MV_ETH_PORTS_NUM < mv_eth_ports_num)
+    {
+	    mv_eth_ports_num = CONFIG_MV_ETH_PORTS_NUM;
+    }
+#endif
+    mv_eth_ports = mvOsMalloc(mv_eth_ports_num*sizeof(mv_eth_priv*));
+    if(mv_eth_ports == NULL)
+    {
+        printk("eth_init_module: can't allocate mv_net_devs for %d devices\n", 
+                mv_eth_ports_num);
+        return 1; 
+    }
+    memset(mv_eth_ports, 0, (mv_eth_ports_num*sizeof(struct net_device*)));
+
+    mv_net_devs = mvOsMalloc((mv_eth_ports_num + GTW_MAX_NUM_OF_IFS)*sizeof(struct net_device*));
+    if(mv_net_devs == NULL)
+    {
+        printk("eth_init_module: can't allocate mv_net_devs for %d devices\n", 
+                mv_net_devs_num);
+        return 1; 
+    }
+    memset(mv_net_devs, 0, ((mv_eth_ports_num + GTW_MAX_NUM_OF_IFS) * sizeof(struct net_device*)));
+
+    printk("  o Loading network interface(s):\n");
+
+    for (port = 0; port < mv_eth_ports_num; port++)
+    {
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+	if (MV_FALSE == mvSocUnitIsMappedToThisCpu(GIGA0+port))
+	{
+		printk(KERN_INFO"GbE %d is not mapped to this CPU\n", port);
+		continue;
+	}		
+#endif
+	if (MV_FALSE == mvCtrlPwrClckGet(ETH_GIG_UNIT_ID, port)) 
+	{
+	    printk("\nWarning: Giga %d is Powered Off\n", port);
+	    continue;
+        }
+
+	/* we deal with gateway ports later */
+#if defined(CONFIG_MV_GATEWAY)
+	if (mvBoardIsSwitchConnected(port))
+		continue;
+#endif /* CONFIG_MV_GATEWAY */
+
+        /* Allocate mv_eth_priv structure */
+        priv = mvOsMalloc(sizeof(mv_eth_priv));
+        if(priv == NULL)
+        {
+            printk("GbE port %d: can't allocate mv_eth_priv structure\n", port);
+            return 1;
+        }
+        mv_eth_ports[port] = priv;
+
+        if( mv_eth_priv_init(priv, port) )
+        {
+            printk("GbE port %d: can't create mv_eth_priv structure\n", port);
+            mv_eth_priv_cleanup(priv);
+            return 1;
+        }
+#if defined(CONFIG_MV_GATEWAY)
+	priv->isGtw = mvBoardIsSwitchConnected(port);
+#endif /* CONFIG_MV_GATEWAY */
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+		mtu = eth_get_config(port, mac_addr);
+#else
+        mtu = eth_get_config(netdev, mac_addr);
+#endif
+        if( mv_eth_hal_init(priv, mtu, mac_addr) )
+        {
+            printk("eth_init_module: can't init eth_hal driver\n");
+            mv_eth_priv_cleanup(priv);
+            return 1;
+        }
+
+        mv_net_devs[netdev] = mv_netdev_init(priv, mtu, mac_addr);
+        if(mv_net_devs[netdev] == NULL)
+        {
+            printk("eth_init_module: can't create netdevice\n");
+            mv_eth_priv_cleanup(priv);
+            return 1;
+        }
+        priv->net_dev = mv_net_devs[netdev];
+        netdev++;
+
+	mv_eth_tos_map_init(port);        
+    }
+
+    /* now deal with gateway ports */
+    /* We initialize the Gateway interface last to maintain interface name ordering, */
+    /* e.g: the non-gateway interface will be named eth0 and the gateway interface will be eth1 */
+    /* Naming is done according to the order of initialization. */
+#if defined(CONFIG_MV_GATEWAY)
+    mv_gtw_dev_offset = netdev;
+    for (port = 0; port < mv_eth_ports_num; port++)
+    {
+	if (MV_FALSE == mvCtrlPwrClckGet(ETH_GIG_UNIT_ID, port)) 
+	{
+	    printk("\nWarning: Giga %d is Powered Off\n", port);
+	    continue;
+        }
+
+	/* disregard non-gateway ports */
+	if (!(mvBoardIsSwitchConnected(port)))
+		continue;
+
+        /* Allocate mv_eth_priv structure */
+        priv = mvOsMalloc(sizeof(mv_eth_priv));
+        if(priv == NULL)
+        {
+            printk("GbE port %d: can't allocate mv_eth_priv structure\n", port);
+            return 1;
+        }
+        mv_eth_ports[port] = priv;
+
+        if( mv_eth_priv_init(priv, port) )
+        {
+            printk("GbE port %d: can't create mv_eth_priv structure\n", port);
+            mv_eth_priv_cleanup(priv);
+            return 1;
+        }
+
+        priv->isGtw = mvBoardIsSwitchConnected(port);
+	printk("  o Loading Gateway interface(s):\n");
+        if( mv_gtw_net_setup(port) < 0)
+        {
+            printk("GbE port %d: mv_gtw_net_setup FAILED\n", port);
+            mv_eth_priv_cleanup(priv);
+            return 1;
+        }
+        if( mv_eth_hal_init(priv, gtw_config.mtu, NULL) )
+        {
+            printk("eth_init_module: can't init eth_hal driver\n");
+            mv_eth_priv_cleanup(priv);
+            return 1;
+        }
+        for(i=0; i<gtw_config.vlans_num; i++)
+        {
+            mv_net_devs[netdev] = mv_netdev_init(priv, gtw_config.mtu, gtw_config.vlan_cfg[i].macaddr);
+            if(mv_net_devs[netdev] == NULL)
+            {
+                printk("eth_init_module: can't create netdevice\n");
+                mv_eth_priv_cleanup(priv);
+                return 1;
+            }
+            priv->net_dev = mv_net_devs[netdev];
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+            ((mv_net_priv*)(mv_net_devs[netdev]->priv))->vlan_cfg = &gtw_config.vlan_cfg[i];
+#else
+            ((mv_net_priv*)(netdev_priv(mv_net_devs[netdev])))->vlan_cfg = &gtw_config.vlan_cfg[i];
+#endif
+            netdev++;
+        }
+
+	/* Note: must update mv_net_devs_num here before calling mv_gtw_init_complete */
+	/* because we might get a link interrupt from the switch and go over all net devices */
+	/* based on mv_net_devs_num */
+	mv_net_devs_num = netdev;
+
+        if (mv_gtw_init_complete(priv) != 0)
+	    return 1;
+
+	mv_eth_tos_map_init(port);
+    }
+#endif /* CONFIG_MV_GATEWAY */
+
+    /* Note: if we have gateway support we already updated mv_net_devs_num, but that's OK */
+    /* If we don't have gateway support, we need to update it here anyway. */
+    mv_net_devs_num = netdev;
+
+    printk("\n");
+
+#ifdef CONFIG_MV_ETH_NFP
+    {
+        MV_STATUS       status;
+
+        status = fp_mgr_init();
+        if (status != MV_OK) {
+            printk("fp_mgr_init failed\n");
+	        return 1;
+        }
+        spin_lock_init( &nfp_lock );
+	    for(i=0; i<mv_net_devs_num; i++) 
+        {
+		    if (mv_net_devs[i] != NULL) 
+            {
+			    status = fp_mgr_if_register(mv_net_devs[i]->ifindex, MV_FP_IF_INT, 
+                                            mv_net_devs[i]);
+			    if (status != MV_OK) {
+				    printk("fp_mgr_if_register failed\n");
+				    return 1;
+			    }
+		    }
+        }
+    }
+#endif /* CONFIG_MV_ETH_NFP */
+
+    TRC_INIT(0, 0, 0, 0);
+    TRC_START();
+
+#ifdef CONFIG_MV_CPU_PERF_CNTRS__ETH
+    /* 0 - instruction counters */
+    mvCpuCntrsProgram(0, MV_CPU_CNTRS_INSTRUCTIONS, "Instr", 25);
+
+    /* 1 - ICache misses counter */
+    mvCpuCntrsProgram(1, MV_CPU_CNTRS_ICACHE_READ_MISS, "IcMiss", 0);
+
+    /* 2 - cycles counter */
+    mvCpuCntrsProgram(2, MV_CPU_CNTRS_CYCLES, "Cycles", 21);
+
+    /* 3 - DCache read misses counter */
+    mvCpuCntrsProgram(3, MV_CPU_CNTRS_DCACHE_READ_MISS, "DcRdMiss", 0);
+    /*mvCpuCntrsProgram(3, MV_CPU_CNTRS_TLB_MISS, "TlbMiss", 0);*/
+
+    hal_rx_event = mvCpuCntrsEventCreate("HAL_RX", 10000);
+    empty_event = mvCpuCntrsEventCreate("EMPTY", 10000);
+    routing_event = mvCpuCntrsEventCreate("LINUX_ROUTING", 10000);
+    if( (empty_event == NULL) || (hal_rx_event == NULL) || (routing_event == NULL) )
+        printk("Can't create cpu counter events\n");
+#endif /* CONFIG_MV_CPU_PERF_CNTRS__ETH */
+    return 0;
+}
+
+static void __exit mv_eth_exit_module(void)
+{
+    printk( "EXIT Marvell Ethernet Driver\n");
+}
+
+
+ 
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.h
new file mode 100644
index 0000000..185ba0b
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.h
@@ -0,0 +1,531 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/mii.h>
+#include <linux/skbuff.h>
+#include <linux/pci.h>
+#include <linux/ip.h>
+#include <linux/in.h>
+#include <linux/tcp.h>
+#include <net/ip.h>
+#include <net/xfrm.h>
+
+#include "mvOs.h"
+#include "mvDebug.h"
+#include "mvStack.h"
+#include "mvSysHwConfig.h"
+#include "eth/mvEth.h"
+#include "eth/gbe/mvEthGbe.h"
+#include "eth-phy/mvEthPhy.h"
+#include "mvSysEthApi.h"
+#include "dbg-trace.h"
+
+#if defined(CONFIG_MV_ETH_TSO)
+#   define ETH_INCLUDE_TSO
+#endif /* CONFIG_MV_ETH_TSO */
+
+#if defined(CONFIG_INET_LRO)
+  /* LRO support */
+#   include <linux/inet_lro.h>
+#   define ETH_LRO
+#   define ETH_LRO_DESC		64
+#endif /* CONFIG_INET_LRO */
+
+#if defined(CONFIG_MV_ETH_UFO)
+  /* UFO support */
+#   include <linux/udp.h>
+#   define ETH_INCLUDE_UFO
+#endif
+
+#ifdef CONFIG_MV_ETH_NFP
+#   include "eth/nfp/mvNfp.h"
+#   include "../nfp_mgr/mv_nfp_mgr.h"
+#endif /* CONFIG_MV_ETH_NFP */
+
+#ifdef CONFIG_MV_ETH_TOOL
+#include "mv_eth_tool.h"
+#endif
+
+/****************************************************** 
+ * driver debug control --                            *
+ ******************************************************/
+/* debug main on/off switch (more in debug control below ) */
+#define ETH_DEBUG
+#undef ETH_DEBUG
+
+#define ETH_DBG_OFF     0x0000
+#define ETH_DBG_RX      0x0001
+#define ETH_DBG_TX      0x0002
+#define ETH_DBG_RX_FILL 0x0004
+#define ETH_DBG_TX_DONE 0x0008
+#define ETH_DBG_LOAD    0x0010
+#define ETH_DBG_IOCTL   0x0020
+#define ETH_DBG_INT     0x0040
+#define ETH_DBG_STATS   0x0080
+#define ETH_DBG_POLL    0x0100
+#define ETH_DBG_GSO		0x0200
+#define ETH_DBG_MCAST   0x0400
+#define ETH_DBG_VLAN    0x0800
+#define ETH_DBG_IGMP    0x1000
+#define ETH_DBG_ALL     0xffff
+
+#ifdef ETH_DEBUG
+extern u32 eth_dbg;
+# define ETH_DBG(FLG, X) if( (eth_dbg & (FLG)) == (FLG) ) printk X
+#else
+# define ETH_DBG(FLG, X)
+#endif
+
+
+/****************************************************** 
+ * driver statistics control --                       *
+ ******************************************************/
+/* statistics main on/off switch (more in statistics control below ) */
+
+#ifdef CONFIG_MV_ETH_STATS_ERROR
+# define ETH_STAT_ERR(CODE) CODE;
+#else
+# define ETH_STAT_ERR(CODE) 
+#endif /* CONFIG_MV_ETH_STATS_ERROR */ 
+
+#ifdef CONFIG_MV_ETH_STATS_INFO
+# define ETH_STAT_INFO(CODE) CODE;
+#else
+# define ETH_STAT_INFO(CODE)
+#endif /* CONFIG_MV_ETH_STATS_INFO */
+
+#ifdef CONFIG_MV_ETH_STATS_DEBUG
+# define ETH_STAT_DBG(CODE) CODE;
+#else
+# define ETH_STAT_DBG(CODE)
+#endif /* CONFIG_MV_ETH_STATS_DEBUG */
+
+/* rx buffer size */ 
+/* 2(HW hdr) + 4(VLAN) + 14(MAC hdr) + 4(CRC) */
+#define MV_WRAP             (2 + 4 + ETH_HLEN + 4)  
+
+#define MV_RX_BUF_SIZE(mtu) MV_ALIGN_UP(((mtu) + MV_WRAP), CPU_D_CACHE_LINE_SIZE)
+
+/* Interrupt Cause Masks */
+#define ETH_TXQ_MASK		(((1 << MV_ETH_TX_Q_NUM) - 1) << ETH_CAUSE_TX_BUF_OFFSET) 
+#define ETH_LINK_MASK		((1 << ETH_CAUSE_PHY_STATUS_CHANGE_BIT) | (1 << ETH_CAUSE_LINK_STATE_CHANGE_BIT))
+#define ETH_RXQ_MASK		(((1 << MV_ETH_RX_Q_NUM) - 1) << ETH_CAUSE_RX_READY_OFFSET)
+#define ETH_RXQ_RES_MASK	(((1 << MV_ETH_RX_Q_NUM) - 1) << ETH_CAUSE_RX_ERROR_OFFSET)
+
+/* Gigabit Ethernet Port Interrupt Mask and Port Interrupt Mask Extend Registers (PIMR and PIMER) */
+#define ETH_PICR_MASK		(BIT1  | ETH_RXQ_MASK | ETH_RXQ_RES_MASK)
+/* phy/link-status-change, tx-done-q0 - q7 */
+#define ETH_PICER_MASK		(ETH_LINK_MASK | ETH_TXQ_MASK) 
+
+
+#if defined(CONFIG_MV_GATEWAY)
+#define GTW_MAX_NUM_OF_IFS  5
+
+struct mv_vlan_cfg {
+    char            name[IFNAMSIZ];
+    unsigned int    ports_mask;
+    unsigned int    ports_link;
+    unsigned short  vlan_grp_id;
+    unsigned short  header;
+    unsigned char   macaddr[ETH_ALEN]; 
+};
+
+struct mv_gtw_config
+{
+    int                 vlans_num;
+    int                 mtu;
+    struct mv_vlan_cfg  vlan_cfg[GTW_MAX_NUM_OF_IFS];
+};
+
+extern struct mv_gtw_config    gtw_config;
+
+#else
+#define GTW_MAX_NUM_OF_IFS  0
+#endif /* CONFIG_MV_GATEWAY */
+
+typedef struct _eth_statistics
+{
+    /* erorrs */
+    u32 skb_alloc_fail;
+    u32 tx_timeout, tx_netif_stop;
+    u32 tx_done_netif_wake;
+    u32 tx_skb_no_headroom;
+#if defined(CONFIG_MV_ETH_NFP) || defined(CONFIG_MV_ETH_SKB_REUSE)
+    u32 rx_pool_empty;
+#endif /* CONFIG_MV_ETH_NFP || CONFIG_MV_ETH_SKB_REUSE */
+
+#ifdef CONFIG_MV_ETH_STATS_INFO
+    /* Events */
+    u32 irq_total, irq_none, irq_while_polling;
+    u32 poll_events, poll_complete;
+    u32 tx_events;
+    u32 tx_done_events;
+    u32 timer_events;
+    u32 link_events;
+#endif /* CONFIG_MV_ETH_STATS_INFO */
+
+#ifdef CONFIG_MV_ETH_STATS_DEBUG
+    /* rx stats */
+    u32 rx_hal_ok[MV_ETH_RX_Q_NUM];
+    u32 rx_netif_drop;
+    u32 rx_dist[CONFIG_MV_ETH_NUM_OF_RX_DESCR+1];
+    u32 rx_csum_hw, rx_csum_hw_frags, rx_csum_sw;
+
+    /* skb stats */
+    u32 skb_alloc_ok, skb_free_ok;
+
+    /* rx-fill stats */
+    u32 rx_fill_ok[MV_ETH_RX_Q_NUM];
+
+    /* tx stats */
+    u32 tx_hal_ok[MV_ETH_TX_Q_NUM];
+    u32 tx_hal_no_resource[MV_ETH_TX_Q_NUM];
+    u32 tx_csum_hw, tx_csum_sw;
+    u32 tso_stats[64], ufo_stats[64];
+
+    /* tx-done stats */
+    u32 tx_done_hal_ok[MV_ETH_TX_Q_NUM];
+    u32 tx_done_dist[CONFIG_MV_ETH_NUM_OF_TX_DESCR*MV_ETH_TX_Q_NUM + 1];
+
+#ifdef ETH_MV_TX_EN
+    u32 tx_en_done, tx_en_wait, tx_en_wait_count, tx_en_busy;
+#endif /* ETH_MV_TX_EN */
+
+#ifdef CONFIG_MV_ETH_SKB_REUSE
+    u32 skb_reuse_rx, skb_reuse_tx, skb_reuse_alloc;
+#endif /* CONFIG_MV_ETH_SKB_REUSE */
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+	u32 skb_recycle_put, skb_recycle_get, skb_recycle_full, skb_recycle_del, skb_recycle_rej;
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+#endif /* CONFIG_MV_ETH_STATS_DEBUG */
+
+} eth_statistics;
+
+typedef struct _mv_eth_priv
+{
+    int                 port;
+    void*               hal_priv;
+    spinlock_t*         lock;
+    eth_statistics      eth_stat;
+    u32                 picr;
+    u32                 picer;
+    MV_STACK*           txPktInfoPool;
+    int                 tx_count[MV_ETH_TX_Q_NUM];
+    struct timer_list   timer;
+    unsigned int        timer_flag;
+    unsigned int        skb_alloc_fail_cnt;
+    struct net_device   *net_dev;		/* back reference to the net_device */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,24)
+    struct napi_struct  napi;
+#endif
+
+#if defined(ETH_INCLUDE_TSO) || defined(ETH_INCLUDE_UFO) || defined(CONFIG_MV_GATEWAY)
+#  define TX_EXTRA_BUF_SIZE     128
+
+    char**  tx_extra_bufs[MV_ETH_TX_Q_NUM]; 
+    int     tx_extra_buf_idx[MV_ETH_TX_Q_NUM];
+#endif /* ETH_INCLUDE_TSO || ETH_INCLUDE_UFO */
+
+#ifdef ETH_LRO
+    struct net_lro_mgr  lro_mgr;
+    struct net_lro_desc lro_desc[ETH_LRO_DESC];
+    unsigned int 	lro_en;	/* enable */
+#endif /* ETH_LRO */
+
+#ifdef CONFIG_MV_ETH_SKB_REUSE
+    MV_STACK*       skbReusePool;
+#endif /* CONFIG_MV_ETH_SKB_REUSE */
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+	 MV_STACK*		skbRecyclePool;
+	 unsigned int	skbRecycleMTU;
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+#ifdef CONFIG_MV_ETH_NFP
+    MV_FP_STATS     fpStats;
+#endif /* CONFIG_MV_ETH_NFP */
+
+#if defined(CONFIG_MV_ETH_NFP) || defined(CONFIG_MV_ETH_SKB_REUSE)
+    unsigned int    refill_needed_flag;
+    MV_STACK*       fpRxPool;
+#endif /* (CONFIG_MV_ETH_NFP) || (CONFIG_MV_ETH_SKB_REUSE) */
+
+#if defined(CONFIG_MV_GATEWAY)
+    int             isGtw;
+#endif /* CONFIG_MV_GATEWAY */
+
+#ifdef ETH_MV_TX_EN
+    MV_BOOL         tx_en;
+    int             tx_en_deep;
+    MV_BOOL         tx_en_bk;
+#endif /* ETH_MV_TX_EN */
+#ifdef CONFIG_MV_ETH_TOOL
+    int		phy_id;
+    __u16	speed_cfg;
+    __u8	duplex_cfg;
+    __u8 	autoneg_cfg;
+    MV_U32	rx_coal_usec;
+    MV_U32	tx_coal_usec;
+#ifdef RX_CSUM_OFFLOAD
+    MV_U32	rx_csum_offload;
+#endif
+#endif /* CONFIG_MV_ETH_TOOL */
+} mv_eth_priv; 
+
+typedef struct _mv_priv 
+{
+    mv_eth_priv			*giga_priv;
+#ifdef CONFIG_MV_GATEWAY
+    struct mv_vlan_cfg		*vlan_cfg;	/* reference to entry in net config table */
+#endif
+
+} mv_net_priv;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+#define MV_ETH_PRIV(dev)        (((mv_net_priv*)((dev)->priv))->giga_priv)
+#define MV_NETDEV_VLAN(dev)     (((mv_net_priv*)((dev)->priv))->vlan_cfg)
+#else
+#define MV_ETH_PRIV(dev)        (((mv_net_priv*)(netdev_priv(dev)))->giga_priv)
+#define MV_NETDEV_VLAN(dev)     (((mv_net_priv*)(netdev_priv(dev)))->vlan_cfg)
+#endif
+#define MV_NETDEV_STATS(dev)    (&((dev)->stats))
+#define MV_GTW_VLAN_TO_GROUP(vid)	((((vid) & 0xf00) >> 8)-1)
+
+extern int     mv_eth_rxq_desc[MV_ETH_RX_Q_NUM];
+extern int     mv_eth_txq_desc[MV_ETH_TX_Q_NUM];
+extern int     mv_eth_rx_desc_total;
+extern int     mv_eth_tx_desc_total;
+
+extern int      mv_eth_tx_done_quota;
+
+extern spinlock_t           mii_lock;
+extern spinlock_t           nfp_lock;
+
+extern struct net_device**  mv_net_devs;
+extern int                  mv_net_devs_num;
+
+extern mv_eth_priv**        mv_eth_ports;
+extern int                  mv_eth_ports_num;
+
+#ifdef CONFIG_MV_ETH_SKB_REUSE
+extern int eth_skb_reuse_enable;
+#endif /* CONFIG_MV_ETH_SKB_REUSE */
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+extern int eth_skb_recycle_enable;
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+static INLINE int  mv_eth_tos_to_q_map(unsigned char tos, unsigned char num_of_queues)
+{
+    int  prio;
+
+    if(tos == 0)
+        return 0;
+
+    prio = (tos >> 5);
+    if(prio == 0)
+        return 1;
+
+    if(prio >= num_of_queues)
+        return (num_of_queues - 1);
+    
+    return prio;
+}
+
+static INLINE void mv_eth_save_interrupts(mv_eth_priv *priv)
+{
+    priv->picr |= MV_REG_READ(ETH_INTR_CAUSE_REG(priv->port)) & ETH_PICR_MASK;
+    if(priv->picr & BIT1) 
+    {
+	    priv->picer |= MV_REG_READ(ETH_INTR_CAUSE_EXT_REG(priv->port)) & ETH_PICER_MASK;
+    }
+}
+/**************************************************************************************************************/
+
+static INLINE void mv_eth_mask_interrupts(mv_eth_priv *priv)
+{
+    MV_REG_WRITE( ETH_INTR_MASK_REG(priv->port), 0 );
+    MV_REG_WRITE( ETH_INTR_MASK_EXT_REG(priv->port), 0 );
+}
+
+/**************************************************************************************************************/
+
+static INLINE void mv_eth_unmask_interrupts(mv_eth_priv *priv)
+{
+    /* unmask GbE Rx and Tx interrupts */
+    MV_REG_WRITE( ETH_INTR_MASK_REG(priv->port), ETH_PICR_MASK);
+#ifdef ETH_TX_DONE_ISR
+    MV_REG_WRITE( ETH_INTR_MASK_EXT_REG(priv->port), ETH_PICER_MASK); 
+#else
+    MV_REG_WRITE( ETH_INTR_MASK_EXT_REG(priv->port), ETH_LINK_MASK); 
+#endif /* ETH_TX_DONE_ISR */
+}
+/**************************************************************************************************************/
+
+static INLINE void mv_eth_clear_saved_interrupts(mv_eth_priv *priv)
+{
+    /* clear interrupts */
+    MV_REG_WRITE( ETH_INTR_CAUSE_REG(priv->port), ~(priv->picr));
+    /* clear Tx interrupts */
+    MV_REG_WRITE( ETH_INTR_CAUSE_EXT_REG(priv->port), ~(priv->picer));
+}
+/**************************************************************************************************************/
+
+static INLINE void mv_eth_clear_interrupts(mv_eth_priv *priv)
+{
+    /* clear interrupts */
+    MV_REG_WRITE( ETH_INTR_CAUSE_REG(priv->port), 0 );
+    /* clear Tx interrupts */
+    MV_REG_WRITE( ETH_INTR_CAUSE_EXT_REG(priv->port), 0 );
+}
+/**************************************************************************************************************/
+
+/* Function prototypes */
+
+#ifdef CONFIG_MV_GATEWAY
+extern int  mv_gtw_start(struct net_device *dev);
+extern int  mv_gtw_stop(struct net_device *dev);
+extern int  mv_gtw_change_mtu(struct net_device *dev, int mtu);
+extern int  mv_gtw_set_mac_addr( struct net_device *dev, void *mac );
+extern void mv_gtw_set_multicast_list(struct net_device *dev);
+
+extern int  __init mv_gtw_net_setup(int port);
+extern int __init mv_gtw_init_complete(mv_eth_priv* priv);
+
+extern int  mv_gtw_switch_tos_get(int port, unsigned char codepoint);
+extern int  mv_gtw_switch_tos_set(int port, unsigned char codepoint, int queue);
+
+extern void mv_gtw_switch_stats(int port);
+
+#ifdef CONFIG_MV_GTW_IGMP
+int mv_gtw_igmp_snoop_process(struct sk_buff* skb, unsigned char port, unsigned char vlan);
+#endif /* CONFIG_MV_GTW_IGMP */
+
+/* Note: this function currently supports only working with Marvell Header mode */
+extern int mv_gtw_dev_offset;
+static INLINE struct net_device *mv_gtw_ingress_dev(char* data)
+{
+	return mv_net_devs[(((data[0] & 0xF0) >> 4) + mv_gtw_dev_offset)];
+}
+
+static INLINE char mv_gtw_ingress_port(char* data)
+{
+    return data[1] & 0x0F;	
+}
+
+static INLINE char mv_gtw_ingress_vlan(char* data)
+{
+    return (data[0] & 0xF0) >> 4;
+}
+
+static INLINE void mv_gtw_update_tx_skb(struct net_device *dev, MV_PKT_INFO *pPktInfo)
+{
+	/* Note: this function currently supports only working with Marvell Header mode */
+	struct mv_vlan_cfg  *vlan_cfg = MV_NETDEV_VLAN(dev); 
+	struct sk_buff      *skb = (struct sk_buff *)pPktInfo->osInfo;
+	MV_BUF_INFO         *p_buf_info_first = pPktInfo->pFrags;
+	MV_BUF_INFO         *p_buf_info_last = (pPktInfo->pFrags + pPktInfo->numFrags - 1);
+
+	/* check if we have place inside skb for the header */
+	if(skb_headroom(skb) >= ETH_MV_HEADER_SIZE) {
+		*(unsigned short *)((skb->data)-ETH_MV_HEADER_SIZE) = vlan_cfg->header;
+		pPktInfo->pFrags[0].bufVirtPtr -= ETH_MV_HEADER_SIZE;
+		pPktInfo->pFrags[0].dataSize += ETH_MV_HEADER_SIZE;
+		pPktInfo->pktSize += ETH_MV_HEADER_SIZE;
+	}
+	else {
+#ifdef CONFIG_MV_ETH_STATS_ERR
+            mv_eth_priv *priv = MV_ETH_PRIV(dev);
+            priv->eth_stat.tx_skb_no_headroom++;
+#endif /* CONFIG_MV_ETH_STATS_ERR */
+
+		/* make room for one cell (safe because the array is big enough) */
+		do {
+	        	*(p_buf_info_last+1) = *p_buf_info_last;
+        		p_buf_info_last--;
+		} while(p_buf_info_last >= p_buf_info_first);
+
+		/* the header (safe on stack) */		
+		p_buf_info_first->bufVirtPtr = (void*)&vlan_cfg->header;
+		p_buf_info_first->dataSize = ETH_MV_HEADER_SIZE;
+
+		/* count the new frags */
+		pPktInfo->numFrags += 1;
+		pPktInfo->pktSize += ETH_MV_HEADER_SIZE;
+	}
+}
+#endif /* CONFIG_MV_GATEWAY */
+
+extern int  mv_eth_open(struct net_device *dev);
+extern int  mv_eth_start(struct net_device *dev);
+extern int  mv_eth_stop(struct net_device *dev);
+extern int  mv_eth_change_mtu(struct net_device *dev, int mtu);
+extern int  mv_eth_set_mac_addr( struct net_device *dev, void *mac );
+extern void mv_eth_set_multicast_list(struct net_device *dev);
+
+int __init                  mv_eth_hal_init(mv_eth_priv *priv, int mtu, u8* mac);
+int __init                  mv_eth_priv_init(mv_eth_priv *priv, int port);
+struct net_device* __init   mv_eth_netdev_init(mv_eth_priv *priv, int mtu, u8* mac);
+void __init                 mv_eth_priv_cleanup(mv_eth_priv *priv);
+
+void	            mv_eth_config_show(void);
+void                mv_eth_netdev_print(unsigned int idx);
+void                mv_eth_status_print( unsigned int port );
+void                mv_eth_stats_print( unsigned int port );
+void                mv_eth_set_noqueue(int port, int enable);
+void                mv_eth_set_lro(int port, int enable);
+void                mv_eth_set_lro_desc(int port, unsigned int value);
+
+MV_STATUS           mv_eth_rx_fill(mv_eth_priv *priv, int pool_size, int mtu);
+irqreturn_t         mv_eth_interrupt_handler(int irq , void *dev_id);
+int                 mv_eth_start_internals( mv_eth_priv *priv, int mtu );
+int                 mv_eth_stop_internals(mv_eth_priv *priv);
+int                 mv_eth_down_internals( struct net_device *dev );
+int                 mv_eth_change_mtu_internals( struct net_device *dev, int mtu );
+
+void                mv_eth_tos_map_show(int port);
+int                 mv_eth_tos_map_set(int port, unsigned char tos, int queue);
+
+void                print_skb(struct sk_buff* skb);
+
+#ifdef CONFIG_MV_ETH_NFP
+void                mv_eth_nfp_stats_print(unsigned int port);
+#endif /* CONFIG_MV_ETH_NFP */
+
+#ifdef ETH_MV_TX_EN
+void                eth_tx_en_config(int port, int value);
+#endif /* ETH_MV_TX_EN */
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_mgr.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_mgr.c
new file mode 100644
index 0000000..316c9da
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_mgr.c
@@ -0,0 +1,2087 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+
+/*******************************************************************************
+* mv_nfp_mgr.c - Marvell Network Fast Processing Manager
+*
+* DESCRIPTION:
+*       
+*       Supported Features:
+*
+*******************************************************************************/
+
+/* includes */
+#include "mvCommon.h"  /* Should be included before mvSysHwConfig */
+#include "mvTypes.h"
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/inetdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/ip.h>
+#include <linux/in.h>
+#include <linux/tcp.h>
+#include <net/route.h>
+#include <linux/if_arp.h>
+
+#ifdef CONFIG_MV_ETH_NFP_NAT
+#include <net/netfilter/nf_nat.h>
+#endif
+
+#include "mvDebug.h"
+#include "mvOs.h"
+#include "mvSysHwConfig.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "eth/nfp/mvNfp.h"
+#include "mv_nfp_mgr.h"
+
+/* defines */
+#define FP_MAX_STR_SIZE		256
+#define AGING_TIMER_PERIOD	((CONFIG_MV_ETH_NFP_AGING_TIMER)*HZ) 
+
+#define MV_FTP_CTRL_PORT 21
+
+/* debug control */
+#define FP_MGR_DEBUG
+#undef FP_MGR_DEBUG
+
+#define FP_MGR_DBG_OFF		0x0000
+#define FP_MGR_DBG_INIT		0x0001
+#define FP_MGR_DBG_CLR		0x0002
+#define FP_MGR_DBG_ARP		0x0004
+#define FP_MGR_DBG_ROUTE	0x0008
+#define FP_MGR_DBG_NAT		0x0010
+#define FP_MGR_DBG_FDB		0x0020
+#define FP_MGR_DBG_PPP		0x0040
+#define FP_MGR_DBG_ALL		0xffff
+
+#ifdef FP_MGR_DEBUG 
+static unsigned int mv_fp_mgr_dbg = FP_MGR_DBG_ALL; 
+#define FP_MGR_DBG(FLG, X) if( (mv_fp_mgr_dbg & (FLG)) == (FLG) ) printk X
+#else
+#define FP_MGR_DBG(FLG, X)
+#endif
+
+#define MAX_MSG_SIZE		128 - 4	
+/* structure definitions */
+#ifdef CONFIG_MV_ETH_NFP_NAT
+#define MASQ_TARGET_NAME	"MASQUERADE"
+#define SNAT_TARGET_NAME	"SNAT"
+#define DNAT_TARGET_NAME	"DNAT"
+#define REDIRECT_TARGET_NAME	"REDIRECT"
+
+typedef struct _fp_iptables_nat_rule
+{
+	struct _fp_iptables_nat_rule *next;
+
+	/* Relevant target names are: */
+	/* SNAT, DNAT, MASQUERADE, REDIRECT */
+	char target_name[XT_FUNCTION_MAXNAMELEN-1];
+
+	/* Relevant for SNAT/DNAT: */
+	__be32 sip, dip, smsk, dmsk;
+
+	char iniface[IFNAMSIZ], outiface[IFNAMSIZ];	
+
+	/* Protocol, 0 = ANY */
+	u_int16_t proto;
+
+} FP_IPTABLES_NAT_RULE;
+
+typedef struct _fp_user_nat_table 
+{
+	FP_IPTABLES_NAT_RULE *rule_chain;
+} FP_USER_NAT_TABLE;
+struct nat_rule_db {
+	MV_FP_NAT_RULE *rule_chain;
+	u32 max_size;
+};
+
+static struct nat_rule_db   mgr_nat_rule_db;
+#endif /* CONFIG_MV_ETH_NFP_NAT */
+
+typedef struct _mv_fp_arp_rule {
+	struct _mv_fp_arp_rule *next;
+
+	int     if_index;
+	u32     ip;
+	u8      mac[MV_MAC_ADDR_SIZE];
+	int     confirmed;
+
+} MV_FP_ARP_RULE; 
+
+struct rule_db {
+	MV_FP_RULE  *rule_chain;
+	u32         max_size;
+};
+
+struct arp_rule_db {
+	MV_FP_ARP_RULE *rule_chain;
+	u32 max_size;
+};
+
+/* global variables */
+static struct rule_db       mgr_rule_db;
+static struct arp_rule_db   mgr_arp_rule_db;
+static struct timer_list    aging_timer;
+static spinlock_t	        nfp_mgr_lock;
+
+int                         fp_disable_flag = 1;
+struct map_eth_devs         *fp_eth_devs = NULL;
+#ifdef CONFIG_MV_ETH_NFP_FDB
+
+struct fdb_rule_db {
+	MV_FP_FDB_RULE *rule_chain;
+	u32 max_size;	
+};
+static struct fdb_rule_db   mgr_fdb_rule_db;
+
+#endif /* CONFIG_MV_ETH_NFP_FDB */
+
+#ifdef CONFIG_MV_ETH_NFP_NAT
+/* we have two tables: previous and current */
+static FP_USER_NAT_TABLE    fp_user_nat_table[2];	
+/* user NAT table: 0 or 1 */
+int                         curr_table, old_table;			
+#endif /* CONFIG_MV_ETH_NFP_NAT */
+
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+int mgr_to_fp_chan, fp_to_mgr_chan;
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+
+static void fp_arp_rule_print(const MV_FP_ARP_RULE *rule);
+#ifdef CONFIG_MV_ETH_NFP_NAT
+static int fp_nat_db_clear_and_update(void);
+#endif
+
+
+static void __exit fp_exit_module(void)
+{
+	fp_rule_db_clear();
+	fp_arp_db_clear();
+
+	if (fp_eth_devs != NULL)
+		kfree(fp_eth_devs);
+
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+	mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, MV_FP_RULE_DB_DESTROY_OPCODE, NULL, 0);
+#else
+	mvFpRuleDbDestroy();
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+
+#ifdef CONFIG_MV_ETH_NFP_NAT
+    fp_nat_db_clear();
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+	mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, MV_FP_NAT_DB_DESTROY_OPCODE, NULL, 0);
+#else
+	mvFpNatDbDestroy();	
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+#endif /* CONFIG_MV_ETH_NFP_NAT */
+
+#ifdef CONFIG_MV_ETH_NFP_FDB
+	fp_fdb_db_clear();
+	mvFpFdbDestroy();
+#endif /* CONFIG_MV_ETH_NFP_FDB */
+}
+
+static int is_valid_index(int if_index)
+{
+	if( (if_index < 0) || (if_index >= ETH_FP_IFINDEX_MAX) )
+	{
+		/*printk("if_index %d is OUT of RANGE\n", if_index);*/
+		return 0;
+	}
+    	if( (fp_eth_devs == NULL) || 
+	    (fp_eth_devs[if_index].if_type == MV_FP_IF_INV) )
+		return 0;
+
+	return 1;
+}
+
+/* helper functions */
+struct net_device *mv_dev_get_by_name(const char *name)
+{
+	/* TODO: may need to take a semaphore here, see documentation of __dev_get_by_name */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+	return __dev_get_by_name(name); 
+#else
+	return __dev_get_by_name(&init_net, name);
+#endif
+}
+
+struct net_device *mv_dev_get_by_index(int ifindex)
+{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24)
+	return __dev_get_by_index(ifindex);
+#else
+	return __dev_get_by_index(&init_net, ifindex);
+#endif
+}
+
+/* Find and return the first matching rule in the ARP Database */
+static MV_FP_ARP_RULE* fp_arp_rule_find(u32 ip)
+{
+	MV_FP_ARP_RULE  *curr_rule;
+
+	for (curr_rule = mgr_arp_rule_db.rule_chain; curr_rule != NULL; curr_rule = curr_rule->next) {
+		if (curr_rule->ip == ip) {
+			return curr_rule;
+		}
+	}
+	return NULL;
+}
+
+static MV_FP_RULE* fp_rule_find(u32 sip, u32 dip)
+{
+	MV_FP_RULE      *curr_rule;
+
+	for (curr_rule = mgr_rule_db.rule_chain; curr_rule != NULL; curr_rule = curr_rule->next) {
+		if(	(curr_rule->routingInfo.srcIp == sip) && 
+			(curr_rule->routingInfo.dstIp == dip) ) {
+				return curr_rule;
+		}
+	}
+	return NULL;
+}
+
+static int ip_in_same_network(u32 ip1, u32 ip2, u32 mask)
+{
+	if ((mask != 0) && ((ip1 & mask) == (ip2 & mask)))
+		return 1;
+	return 0;
+}
+
+
+#ifdef CONFIG_MV_ETH_NFP_NAT
+
+static MV_FP_NAT_RULE* fp_nat_rule_find(u32 sip, u32 dip, u16 sport, u16 dport, u8 proto) 
+{
+	MV_FP_NAT_RULE  *curr_rule;
+
+	for (curr_rule = mgr_nat_rule_db.rule_chain; curr_rule != NULL; curr_rule = curr_rule->next) {
+		if (	curr_rule->srcIp == sip && 
+			curr_rule->dstIp == dip && 
+			curr_rule->srcPort == sport && 
+			curr_rule->dstPort == dport && 
+			curr_rule->proto == proto) {
+				return curr_rule;
+		}
+	}
+	return NULL;
+}
+
+/* Update NFP Rule "NAT awareness" according to the given iptables rule */
+static void update_awareness(FP_IPTABLES_NAT_RULE *nat_rule, MV_FP_RULE *fp_rule, int add_del_flag)
+{
+	int                 in_dev_ifindex = -1, out_dev_ifindex = -1;
+	struct net_device   *dev;
+	int                 inport_avail = 0, outport_avail = 0;	
+
+	if (!strcmp(nat_rule->target_name, MASQ_TARGET_NAME) || !strcmp(nat_rule->target_name, SNAT_TARGET_NAME)) {
+		if ((nat_rule->outiface != NULL) && strcmp(nat_rule->outiface, "")) {
+			dev = mv_dev_get_by_name(nat_rule->outiface);
+			if (dev)
+				out_dev_ifindex = dev->ifindex;
+		
+			if (is_valid_index(out_dev_ifindex)) {
+				outport_avail = 1;
+			}
+		}
+	}
+	else if (!strcmp(nat_rule->target_name, REDIRECT_TARGET_NAME) || !strcmp(nat_rule->target_name, DNAT_TARGET_NAME)) {
+		if ((nat_rule->iniface != NULL) && strcmp(nat_rule->iniface, "")) {
+			dev = mv_dev_get_by_name(nat_rule->iniface);
+			if (dev)
+				in_dev_ifindex = dev->ifindex;
+		
+			if (is_valid_index(in_dev_ifindex)) {
+				inport_avail = 1;
+			}
+		}
+	}
+
+	if (!strcmp(nat_rule->target_name, MASQ_TARGET_NAME) || !strcmp(nat_rule->target_name, SNAT_TARGET_NAME)) {
+		if (	(ip_in_same_network(fp_rule->routingInfo.srcIp, nat_rule->sip, nat_rule->smsk)) || 
+			(outport_avail && fp_rule->routingInfo.outIfIndex == out_dev_ifindex) ) {
+			/* update SNAT awareness */
+			if (add_del_flag) {
+				FP_MGR_DBG(FP_MGR_DBG_NAT, ("adding snat awareness\n"));
+				fp_rule->mgmtInfo.snat_aware_refcnt++;
+				fp_rule->routingInfo.aware_flags |= MV_FP_SNAT_CMD_MAP;
+			}
+			else {
+				fp_rule->mgmtInfo.snat_aware_refcnt--;
+				if (fp_rule->mgmtInfo.snat_aware_refcnt == 0) {
+					FP_MGR_DBG(FP_MGR_DBG_NAT, ("deleting snat awareness\n"));
+					fp_rule->routingInfo.aware_flags &= ~MV_FP_SNAT_CMD_MAP;	
+				}
+			}
+		}
+		if (outport_avail && fp_rule->routingInfo.inIfIndex == out_dev_ifindex) {
+			/* update DNAT awareness, because this is the reverse direction of the SNAT */
+			if (add_del_flag) {
+				FP_MGR_DBG(FP_MGR_DBG_NAT, ("adding dnat awareness\n"));
+				fp_rule->mgmtInfo.dnat_aware_refcnt++;
+				fp_rule->routingInfo.aware_flags |= MV_FP_DNAT_CMD_MAP;
+			}
+			else {
+				fp_rule->mgmtInfo.dnat_aware_refcnt--;
+				if (fp_rule->mgmtInfo.dnat_aware_refcnt == 0) {
+					FP_MGR_DBG(FP_MGR_DBG_NAT, ("deleting dnat awareness\n"));
+					fp_rule->routingInfo.aware_flags &= ~MV_FP_DNAT_CMD_MAP;
+				}	
+			}
+		}
+	}
+	else if (!strcmp(nat_rule->target_name, REDIRECT_TARGET_NAME) || !strcmp(nat_rule->target_name, DNAT_TARGET_NAME)) {
+		if (	(ip_in_same_network(fp_rule->routingInfo.dstIp, nat_rule->dip, nat_rule->dmsk)) || 
+			(inport_avail && fp_rule->routingInfo.inIfIndex == in_dev_ifindex) ) {
+			/* update DNAT awareness */
+			if (add_del_flag) {
+				FP_MGR_DBG(FP_MGR_DBG_NAT, ("adding dnat awareness\n"));
+				fp_rule->mgmtInfo.dnat_aware_refcnt++;
+				fp_rule->routingInfo.aware_flags |= MV_FP_DNAT_CMD_MAP;
+			}
+			else {
+				fp_rule->mgmtInfo.dnat_aware_refcnt--;
+				if (fp_rule->mgmtInfo.dnat_aware_refcnt == 0) {
+					FP_MGR_DBG(FP_MGR_DBG_NAT, ("deleting dnat awareness\n"));
+					fp_rule->routingInfo.aware_flags &= ~MV_FP_DNAT_CMD_MAP;
+				}
+			}
+		}
+		if (inport_avail && fp_rule->routingInfo.outIfIndex == in_dev_ifindex) {
+			/* update SNAT awareness, because this is the reverse direction of the DNAT */
+			if (add_del_flag) {
+				FP_MGR_DBG(FP_MGR_DBG_NAT, ("adding snat awareness\n"));
+				fp_rule->mgmtInfo.snat_aware_refcnt++;
+				fp_rule->routingInfo.aware_flags |= MV_FP_SNAT_CMD_MAP;
+			}
+			else {
+				fp_rule->mgmtInfo.snat_aware_refcnt--;
+				if (fp_rule->mgmtInfo.snat_aware_refcnt == 0) {
+					FP_MGR_DBG(FP_MGR_DBG_NAT, ("deleting snat awareness\n"));
+					fp_rule->routingInfo.aware_flags &= ~MV_FP_SNAT_CMD_MAP;
+				}
+			}
+		}
+	}
+}
+#endif /* CONFIG_MV_ETH_NFP_NAT */
+
+/* When setting a rule, check if it needs to be aware of any currently existing user NAT rules */
+static void fp_new_rule_awareness(MV_FP_RULE *rule)
+{
+#ifdef CONFIG_MV_ETH_NFP_NAT
+	FP_IPTABLES_NAT_RULE *nat_rule;
+#endif
+	rule->mgmtInfo.snat_aware_refcnt = 0;
+	rule->mgmtInfo.dnat_aware_refcnt = 0;
+	rule->routingInfo.aware_flags = 0;
+#ifdef CONFIG_MV_ETH_NFP_NAT
+	nat_rule = fp_user_nat_table[1-curr_table].rule_chain;
+	while (nat_rule != NULL) {
+		update_awareness(nat_rule, rule, 1);
+		nat_rule = nat_rule->next;
+	}
+#endif /* CONFIG_MV_ETH_NFP_NAT */
+}
+
+/* Clear all NFP databases and update them with the contents of */
+/* the NFP Manager databases. */
+static int fp_db_clear_and_update(void)
+{
+	int status = 0;
+	unsigned long flags;
+	MV_FP_RULE *curr_rule;
+
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+	status = mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, MV_FP_RULE_DB_CLEAR_OPCODE, NULL, 0);
+#else
+	status = mvFpRuleDbClear();
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	curr_rule = mgr_rule_db.rule_chain;
+	while (curr_rule != NULL) { 
+		if (!is_zero_ether_addr(curr_rule->routingInfo.dstMac)) {
+			fp_new_rule_awareness(curr_rule);
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+			status |= mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, 
+							MV_FP_RULE_SET_OPCODE, curr_rule, sizeof(MV_FP_RULE));
+#else
+			status |= mvFpRuleSet(curr_rule);
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+		}
+		curr_rule = curr_rule->next;
+	}
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+	return status;
+}
+
+
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+static void aging_timer_function(unsigned long data)
+{
+	unsigned long       flags;
+	MV_FP_ARP_RULE      *curr_arp_rule;
+	MV_FP_RULE          *curr_rule;
+	int                 rule_index = 0;
+	ARP_RULE_AGING_MSG  arp_rule_aging_msg;
+	RULE_AGING_MSG      rule_aging_msg;
+	NAT_RULE_AGING_MSG nat_rule_aging_msg;
+#ifdef CONFIG_MV_ETH_NFP_NAT
+	MV_FP_NAT_RULE  *curr_nat_rule;
+#endif
+	static int          current_arp_rule_position = 0;
+	static int          current_rule_position = 0;
+	static int          current_nat_rule_position = 0;
+
+
+	/* Collect ARP information from DB */
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+
+	/* move pointer to rule to the next group of rules we want to handle */
+	for (	curr_arp_rule = mgr_arp_rule_db.rule_chain, rule_index = 0; 
+		(curr_arp_rule != NULL) && (rule_index < (current_arp_rule_position*AGING_QUANTUM)); 
+		curr_arp_rule = curr_arp_rule->next, rule_index++);
+
+	rule_index = 0;
+	memset(&arp_rule_aging_msg, 0, sizeof(ARP_RULE_AGING_MSG));
+	while ((curr_arp_rule != NULL) && (rule_index < AGING_QUANTUM)) {
+		arp_rule_aging_msg.num_tuples++;
+		arp_rule_aging_msg.info[rule_index].ip = curr_arp_rule->ip;
+		curr_arp_rule = curr_arp_rule->next;
+		rule_index++;
+	}
+	current_arp_rule_position++;
+	if( (curr_arp_rule == NULL) || 
+        ((current_arp_rule_position*AGING_QUANTUM) >= mgr_arp_rule_db.max_size))
+		current_arp_rule_position = 0; 
+
+	mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, 
+				MV_FP_MAX_ARP_COUNT_GET_OPCODE, &arp_rule_aging_msg, sizeof(arp_rule_aging_msg));
+
+	/* Collect routing information from DB */	
+
+	/* move pointer to rule to the next group of rules we want to handle */
+	for (	curr_rule = mgr_rule_db.rule_chain, rule_index = 0; 
+		(curr_rule != NULL) && (rule_index < (current_rule_position*AGING_QUANTUM)); 
+		curr_rule = curr_rule->next, rule_index++);
+
+	rule_index = 0;
+	memset(&rule_aging_msg, 0, sizeof(RULE_AGING_MSG));
+
+	while ((curr_rule != NULL) && (rule_index < AGING_QUANTUM)) {
+		rule_aging_msg.num_tuples++;
+		rule_aging_msg.info[rule_index].sip = curr_rule->routingInfo.srcIp;
+		rule_aging_msg.info[rule_index].dip = curr_rule->routingInfo.dstIp;
+		curr_rule = curr_rule->next;
+		rule_index++;
+	}
+	current_rule_position++;
+	if ((curr_rule == NULL) || ((current_rule_position*AGING_QUANTUM) >= mgr_rule_db.max_size))
+		current_rule_position = 0; 
+	mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, 
+				MV_FP_ROUTE_COUNT_GET_OPCODE, &rule_aging_msg, sizeof(rule_aging_msg));
+
+#ifdef CONFIG_MV_ETH_NFP_NAT
+	/* Collect NAT information from DB */
+
+	/* move pointer to rule to the next group of rules we want to handle */
+	for (	curr_nat_rule = mgr_nat_rule_db.rule_chain, rule_index = 0; 
+		(curr_nat_rule != NULL) && (rule_index < (current_nat_rule_position*AGING_QUANTUM)); 
+		curr_nat_rule = curr_nat_rule->next, rule_index++);
+
+	rule_index = 0;
+	memset(&nat_rule_aging_msg, 0, sizeof(NAT_RULE_AGING_MSG));
+
+	while ((curr_nat_rule != NULL) && (rule_index < AGING_QUANTUM)) {
+		nat_rule_aging_msg.num_tuples++;
+		nat_rule_aging_msg.info[rule_index].sip = curr_nat_rule->srcIp;
+		nat_rule_aging_msg.info[rule_index].dip = curr_nat_rule->dstIp;
+		nat_rule_aging_msg.info[rule_index].sport = curr_nat_rule->srcPort;
+		nat_rule_aging_msg.info[rule_index].dport = curr_nat_rule->dstPort;
+		nat_rule_aging_msg.info[rule_index].proto = curr_nat_rule->proto;
+		curr_nat_rule = curr_nat_rule->next;
+		rule_index++;
+	}
+
+	current_nat_rule_position++;
+	if( (curr_nat_rule == NULL) || 
+        	( (current_nat_rule_position*AGING_QUANTUM) >= mgr_nat_rule_db.max_size) )
+			current_nat_rule_position = 0; 
+
+	mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, 
+				MV_FP_NAT_COUNT_GET_OPCODE, &nat_rule_aging_msg, sizeof(nat_rule_aging_msg));
+
+#endif /* CONFIG_MV_ETH_NFP_NAT */
+
+  	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+	aging_timer.expires = jiffies + AGING_TIMER_PERIOD;
+    	add_timer(&aging_timer);
+}
+
+#else /* not CONFIG_MV_ETH_NFP_DUAL */
+
+static void aging_timer_function(unsigned long data)
+{
+	unsigned long   flags;
+	MV_FP_ARP_RULE  *curr_arp_rule;
+	MV_FP_RULE      *curr_rule;
+#ifdef CONFIG_MV_ETH_NFP_NAT
+	MV_FP_NAT_RULE  *curr_nat_rule;
+#endif
+
+    	spin_lock_irqsave(&nfp_mgr_lock, flags);
+
+	/* Collect routing information from DB */	
+	curr_rule = mgr_rule_db.rule_chain;
+	while (curr_rule != NULL) 
+    	{
+		curr_rule->mgmtInfo.new_count = mvFpRouteCountGet(curr_rule->routingInfo.srcIp, 
+						                                  curr_rule->routingInfo.dstIp);
+        	if(curr_rule->mgmtInfo.new_count != curr_rule->mgmtInfo.old_count)
+        	{
+            		/* Lookup ARP entry to confirm */
+            		curr_arp_rule = fp_arp_rule_find(curr_rule->routingInfo.srcIp);
+            		if(curr_arp_rule != NULL)
+            		{
+                		/* ARP Entry Found - confirmed */
+                		curr_arp_rule->confirmed = 1;
+            		}
+            		else
+            		{
+                		/* ARP Entry Not Found - Confirm default gateway for incoming interface */
+                		curr_arp_rule = fp_arp_rule_find(fp_eth_devs[curr_rule->routingInfo.inIfIndex].def_gtw_ip);
+                		if(curr_arp_rule != NULL)
+                		{
+                    			curr_arp_rule->confirmed = 1;
+                		}       		
+            		}
+        	}
+		curr_rule = curr_rule->next;
+	}
+
+#ifdef CONFIG_MV_ETH_NFP_NAT
+	/* Collect NAT information from DB */
+	curr_nat_rule = mgr_nat_rule_db.rule_chain;
+	while (curr_nat_rule != NULL) 
+    	{
+		curr_nat_rule->new_count = mvFpNatCountGet(curr_nat_rule->srcIp, 
+						                           curr_nat_rule->dstIp, 
+						                           curr_nat_rule->srcPort, 
+						                           curr_nat_rule->dstPort, 
+						                           curr_nat_rule->proto);
+		curr_nat_rule = curr_nat_rule->next;
+	}
+#endif /* CONFIG_MV_ETH_NFP_NAT */
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+	aging_timer.expires = jiffies + AGING_TIMER_PERIOD;
+   	add_timer(&aging_timer);
+}
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+
+/* Return ARP rule confirmation status */
+int fp_is_arp_confirmed(u32 ip, const u8 *mac)
+{
+	unsigned long   flags;
+	MV_FP_ARP_RULE  *curr_rule;
+    	int             confirmed;
+
+	if (fp_disable_flag == 1)
+		return 0;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	curr_rule = mgr_arp_rule_db.rule_chain;
+	while (curr_rule != NULL) {
+		if( (curr_rule->ip == ip) && (memcmp(curr_rule->mac, mac, MV_MAC_ADDR_SIZE) == 0) ) 
+        	{
+            		confirmed = curr_rule->confirmed;
+            		curr_rule->confirmed = 0;
+			spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+			return confirmed;
+		}
+		curr_rule = curr_rule->next;
+	}
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return 0;
+}
+
+/* Return routing rule confirmation status */
+int fp_is_route_confirmed(u32 src_ip, u32 dst_ip, int iif, int oif)
+{
+	unsigned long   flags;
+	MV_FP_RULE      *curr_rule;
+    	int             confirmed = 0;
+
+	if (fp_disable_flag == 1)
+		return 0;
+
+        if( !is_valid_index(iif) || !is_valid_index(oif) )
+                return 0;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	curr_rule = mgr_rule_db.rule_chain;
+	while (curr_rule != NULL) {
+		if( (curr_rule->routingInfo.srcIp == src_ip) && 
+			(curr_rule->routingInfo.dstIp == dst_ip) ) 
+        	{
+            		if(curr_rule->mgmtInfo.new_count != curr_rule->mgmtInfo.old_count)
+            		{
+                		confirmed = 1;
+                		curr_rule->mgmtInfo.old_count = curr_rule->mgmtInfo.new_count;
+            		}
+			spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+			return confirmed;
+		}
+		curr_rule = curr_rule->next;
+	}
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return 0;
+}
+
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+void fp_rcv_info_msg(int from_cpu, u16 opcode, void* p_msg, u8 size)
+{
+	int                 i = 0;
+	ARP_RULE_AGING_MSG  *arp_rule_aging_msg;
+	RULE_AGING_MSG      *rule_aging_msg;
+	NAT_RULE_AGING_MSG  *nat_rule_aging_msg;
+	MV_FP_ARP_RULE      *curr_arp_rule;
+	MV_FP_RULE          *curr_rule;
+	MV_FP_NAT_RULE      *curr_nat_rule;
+
+	switch(opcode)
+	{
+		case MV_FP_MAX_ARP_COUNT_REPLY_OPCODE:
+			arp_rule_aging_msg = (ARP_RULE_AGING_MSG *)p_msg;
+			for (i = 0; i < arp_rule_aging_msg->num_tuples; i++) {
+				curr_arp_rule = fp_arp_rule_find(arp_rule_aging_msg->info[i].ip);
+				if (curr_arp_rule != NULL)
+					fp_update_arp_rule_aging(curr_arp_rule, arp_rule_aging_msg->info[i].count);
+			}
+			break;
+		case MV_FP_ROUTE_COUNT_REPLY_OPCODE:
+			rule_aging_msg = (RULE_AGING_MSG *)p_msg;
+			for (i = 0; i < rule_aging_msg->num_tuples; i++) {
+				curr_rule = fp_rule_find(rule_aging_msg->info[i].sip, 
+							rule_aging_msg->info[i].dip);
+				if (curr_rule != NULL) 
+					fp_update_rule_aging(curr_rule, rule_aging_msg->info[i].count);
+			}
+			break;
+		case MV_FP_NAT_COUNT_REPLY_OPCODE:
+			nat_rule_aging_msg = (NAT_RULE_AGING_MSG *)p_msg;
+			for (i = 0; i < nat_rule_aging_msg->num_tuples; i++) {
+				curr_nat_rule = fp_nat_rule_find(nat_rule_aging_msg->info[i].sip, 
+								nat_rule_aging_msg->info[i].dip, 
+								nat_rule_aging_msg->info[i].sport, 
+								nat_rule_aging_msg->info[i].dport, 
+								nat_rule_aging_msg->info[i].proto);
+				if (curr_nat_rule != NULL) 
+					fp_update_nat_rule_aging(curr_nat_rule, nat_rule_aging_msg->info[i].count);
+			}
+			break;
+		default:
+			printk("fp_rcv_info_msg: unknown message type\n"); 
+			break;
+	}
+}
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+
+/* Initialize NFP Manager */
+int fp_mgr_init(void)
+{
+	int i = 0;
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+	int                 status = 0;
+	MV_FP_INIT_STRUCT   fpdb_init_struct;
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+
+    fp_disable_flag = 1;
+
+	fp_eth_devs = kmalloc((ETH_FP_IFINDEX_MAX * sizeof(struct map_eth_devs)), GFP_ATOMIC);
+	if (fp_eth_devs == NULL)
+		return -ENOMEM;
+
+	for (i = 0; i < ETH_FP_IFINDEX_MAX; i++) {
+		fp_eth_devs[i].if_type = MV_FP_IF_INV;
+        	fp_eth_devs[i].dev = NULL;
+        	fp_eth_devs[i].def_gtw_ip = 0;
+	}
+  	spin_lock_init(&nfp_mgr_lock);
+
+	memset(&aging_timer, 0, sizeof(struct timer_list));
+	init_timer(&aging_timer);
+    	aging_timer.function = aging_timer_function;
+    	aging_timer.data = -1;
+	aging_timer.expires = jiffies + AGING_TIMER_PERIOD;
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+	mgr_to_fp_chan = mvIpcChanCreate(MV_IPC_HOST_ID, MV_IPC_COPROCESSOR_ID,
+                                        MV_IPC_RX_CB_MODE, MAX_MSG_SIZE, 64 /*mgr_rule_db.max_size*/);
+ 
+	fp_to_mgr_chan = mvIpcChanCreate(MV_IPC_COPROCESSOR_ID, MV_IPC_HOST_ID, 
+                                        MV_IPC_RX_CB_MODE, MAX_MSG_SIZE, 64 /*mgr_rule_db.max_size*/);
+
+	status = mvIpcChanRcvCbSet(fp_to_mgr_chan, fp_rcv_info_msg);
+	if ((status != 0) || (mgr_to_fp_chan < 0) || (fp_to_mgr_chan < 0))
+        {
+		printk("fp_mgr_init: Error setting up IPC channels\n");
+		return status;
+        }
+
+	/* Connect Channel Dispatch function */
+	mvIpcDbConnect(mvIpcChanDoorbellGet(fp_to_mgr_chan), mvIpcChanDispatchIsr, (void*)fp_to_mgr_chan);
+	/* Enable Doorbell interrupt */
+	MV_IPC_DOORBELL_ENABLE(MV_IPC_HOST_ID, mvIpcChanDoorbellGet(fp_to_mgr_chan));
+
+	memset(&fpdb_init_struct, 0, sizeof(MV_FP_INIT_STRUCT));
+	fpdb_init_struct.mgr_to_fp_chan = mgr_to_fp_chan;
+	fpdb_init_struct.fp_to_mgr_chan = fp_to_mgr_chan;
+	fpdb_init_struct.rule_db_size = mgr_rule_db.max_size;
+	status = mvIpcChanMsgSend(	mvIpcTxSharedChanGet(MV_IPC_COPROCESSOR_ID), 
+					MV_SERVICE_NFP_ID, MV_FP_RULE_DB_INIT_OPCODE,
+					&fpdb_init_struct, sizeof(MV_FP_INIT_STRUCT));
+	if (status != 0) 
+	{
+		printk("fp_mgr_init: Error sending NFP initialization message\n");
+		return status;
+	}
+	return 0;
+#else
+	/* Note at this stage the Manager DB is already initialized so mgr_rule_db.max_size is set */
+	mvFpRuleDbInit(mgr_rule_db.max_size);
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+
+    return 0;
+}
+
+static int fp_mgr_get_iftype(int if_index)
+{
+	if (!fp_eth_devs ||
+		(if_index < 0) || 
+		(if_index >= ETH_FP_IFINDEX_MAX))
+		return MV_FP_IF_INV;
+
+	return fp_eth_devs[if_index].if_type;
+}
+
+/* Register a network interface that works with NFP */
+int fp_mgr_if_register(	int if_index, MV_FP_IF_TYPE if_type, 
+			            struct net_device* dev)
+{
+	/* sanity checks */
+	if( (fp_eth_devs == NULL) || 
+	    (if_index < 0) || (if_index >= ETH_FP_IFINDEX_MAX) )
+		return -1;
+
+	fp_eth_devs[if_index].dev = dev;
+	fp_eth_devs[if_index].if_type = if_type;
+
+	return 0;
+}
+
+int fp_mgr_if_unregister(int if_index)
+{
+	if (fp_eth_devs || 
+		(if_index < 0) || 
+		(if_index >= ETH_FP_IFINDEX_MAX))
+		return -1;
+
+	memset(&fp_eth_devs[if_index], 0, sizeof(struct map_eth_devs));
+	return 0;
+}
+
+/* This function is called when user-space tool disables NFP */
+/* All databases are cleared, and learning of new rules is disabled	*/
+/* for all types of rules: static, dynamic, arp, routing etc.		*/
+void fp_mgr_disable(void)
+{
+	if (fp_disable_flag == 0) {
+		fp_disable_flag = 1;
+		del_timer(&aging_timer);
+	}
+	printk("Network Fast Processing Disabled\n");
+}
+
+/* This function is called when user-space tool enables NFP */
+int fp_mgr_enable(void)
+{
+	int status;
+
+	if (fp_disable_flag == 1) {
+		fp_disable_flag = 0;
+		status = fp_db_clear_and_update();
+
+#ifdef CONFIG_MV_ETH_NFP_NAT
+        status |= fp_nat_db_clear_and_update();
+#endif /* CONFIG_MV_ETH_NFP_NAT */
+		aging_timer.expires = jiffies + AGING_TIMER_PERIOD;
+		add_timer(&aging_timer);
+		printk("Network Fast Processing Enabled\n");
+		return status;
+	}
+	printk("Network Fast Processing Enabled\n");
+	return 0;
+}
+
+/* This function is called when user-space tool asks about NFP status (enabled/disabled) */
+int fp_mgr_status(void)
+{
+	if (fp_disable_flag == 0)
+		printk("Network Fast Processing is currently Enabled\n");
+	else
+		printk("Network Fast Processing is currently Disabled\n");
+
+	return 0;
+}
+
+/* Initialize NFP Rule Database (Routing + ARP information table) */
+int fp_rule_db_init(u32 db_size)
+{
+	FP_MGR_DBG(FP_MGR_DBG_INIT, ("FP_MGR: Initializing Rule Database\n"));
+	mgr_rule_db.rule_chain = NULL;
+	mgr_rule_db.max_size = db_size;
+	/* Initialization of the NFP HAL Database is called from fp_mgr_init */
+	return 0;
+}
+ 
+/* Initialize NFP Manager ARP Database */
+int fp_arp_db_init(u32 db_size)
+{
+	FP_MGR_DBG(FP_MGR_DBG_INIT, ("FP_MGR: Initializing ARP Rule Database\n"));
+	mgr_arp_rule_db.rule_chain = NULL;
+	mgr_arp_rule_db.max_size = db_size;
+	return 0;
+}
+
+/* Clear NFP Rule Database (Routing + ARP information table) */
+int fp_rule_db_clear(void)
+{
+	int status = 0;
+	unsigned long flags;
+	MV_FP_RULE *curr_rule;
+	MV_FP_RULE *tmp_rule;
+
+	FP_MGR_DBG(FP_MGR_DBG_CLR, ("FP_MGR: Clearing Rule Database\n"));
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	curr_rule = mgr_rule_db.rule_chain;
+	while (curr_rule != NULL) {
+		tmp_rule = curr_rule;
+		curr_rule = curr_rule->next;
+		kfree(tmp_rule);
+	}
+	mgr_rule_db.rule_chain = NULL;
+
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+	status = mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, MV_FP_RULE_DB_CLEAR_OPCODE, NULL, 0);
+#else
+	status = mvFpRuleDbClear();
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return status;
+}
+
+/* Clear NFP Manager ARP Database */
+int fp_arp_db_clear(void)
+{
+	unsigned long   flags;
+	MV_FP_ARP_RULE  *curr_rule;
+	MV_FP_ARP_RULE  *tmp_rule;
+
+	FP_MGR_DBG(FP_MGR_DBG_CLR, ("FP_MGR: Clearing ARP Rule Database\n"));
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	curr_rule = mgr_arp_rule_db.rule_chain;
+	while (curr_rule != NULL) {
+		tmp_rule = curr_rule;
+		curr_rule = curr_rule->next;
+		kfree(tmp_rule);
+	}
+	mgr_arp_rule_db.rule_chain = NULL;
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return 0;
+}
+
+/* Print NFP Rule Database (Routing + ARP information table) */
+int fp_rule_db_print(MV_FP_OP_TYPE op)
+{
+	int             status = 0;
+	unsigned long   flags;
+	MV_FP_RULE      *curr_rule;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	if (op == MV_FP_MANAGER) {
+		printk("Printing NFP Manager Rule Database: \n");
+		curr_rule = mgr_rule_db.rule_chain;
+		while (curr_rule != NULL) { 
+			mvFpRulePrint(curr_rule);
+			curr_rule = curr_rule->next;
+		}
+	}
+	else {
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+		status = mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, MV_FP_RULE_DB_PRINT_OPCODE, NULL, 0);
+#else
+		status = mvFpRuleDbPrint();
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+	}
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return status;
+}
+
+/* Print ARP Rule */
+static void fp_arp_rule_print(const MV_FP_ARP_RULE *rule)
+{
+	printk("ARP Rule: ");
+	printk("IP = %u.%u.%u.%u, ", NIPQUAD(rule->ip));
+	printk("MAC = %02X:%02X:%02X:%02X:%02X:%02X\n", rule->mac[0], rule->mac[1], rule->mac[2], 
+							rule->mac[3], rule->mac[4], rule->mac[5]);
+}
+
+/* Print NFP Manager ARP Database */
+int fp_arp_db_print(void)
+{
+	unsigned long   flags;
+	MV_FP_ARP_RULE  *curr_rule;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	printk("Printing NFP Manager ARP Rule Database: \n");
+	curr_rule = mgr_arp_rule_db.rule_chain;
+	while (curr_rule != NULL) {
+		fp_arp_rule_print(curr_rule);
+		curr_rule = curr_rule->next;
+	}
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return 0;
+}
+
+/* Copy 6 bytes. Warning - doesn't perform any checks on memory, just copies */
+static inline void mac_addr_copy(u8 *dst, const u8 *src)
+{
+	dst[0] = src[0];
+	dst[1] = src[1];
+	dst[2] = src[2];
+	dst[3] = src[3];
+	dst[4] = src[4];
+	dst[5] = src[5];
+}
+
+/* Update the Routing + ARP database with new ARP information: */
+/* Go over the database and update the destination MAC address */
+/* for each entry with a matching default gateway IP address.  */
+static int fp_rule_db_arp_update(u32 ip, const u8 *mac)
+{
+	int             status = 0;
+	unsigned long   flags;
+	MV_FP_RULE      *curr_rule;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	for (curr_rule = mgr_rule_db.rule_chain; curr_rule != NULL; curr_rule = curr_rule->next) 
+    	{
+		if(	(curr_rule->routingInfo.defGtwIp == ip) && 
+			(curr_rule->mgmtInfo.ruleType != MV_FP_STATIC_RULE)) 
+        	{
+			mac_addr_copy(curr_rule->routingInfo.dstMac, mac);
+			if (!is_zero_ether_addr(mac)) 
+            		{
+				/* Now we have a full rule - we can update the NFP database */
+				fp_new_rule_awareness(curr_rule);
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+				status |= mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, 
+						MV_FP_RULE_SET_OPCODE, curr_rule, sizeof(MV_FP_RULE));
+#else
+				status |= mvFpRuleSet(curr_rule);
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+			}
+			else
+            		{
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+				status |= mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, 
+						MV_FP_RULE_DELETE_OPCODE, curr_rule, sizeof(MV_FP_RULE));
+#else
+				status |= mvFpRuleDelete(curr_rule);
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+            		}
+		}
+	}
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return status;
+}
+
+/* Set ARP information in the ARP database, and update the Routing + ARP database if necessary */
+/* If we have a complete rule, update the NFP database */
+int fp_arp_info_set(int if_index, u32 ip, const u8 *mac)
+{
+	unsigned long   flags;
+	MV_FP_ARP_RULE  *curr_rule;
+	MV_FP_ARP_RULE  *new_rule;
+
+    	if(!is_valid_index(if_index))
+       		return 0;
+
+	FP_MGR_DBG(FP_MGR_DBG_ARP, ("nfp_mgr Set ARP: if=%d, IP=%u.%u.%u.%u, MAC=%02X:%02X:%02X:%02X:%02X:%02X\n",
+                                if_index, NIPQUAD(ip), mac[0], mac[1], mac[2], mac[3], mac[4], mac[5]));
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	for (curr_rule = mgr_arp_rule_db.rule_chain; curr_rule != NULL; curr_rule = curr_rule->next) {
+		if (curr_rule->ip == ip) {
+			/* We've found a match with an existing entry. Let's update it */
+			mac_addr_copy(curr_rule->mac, mac);
+			curr_rule->confirmed = 1;
+			spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+			return fp_rule_db_arp_update(ip, mac);
+		}
+	}
+	/* We haven't found a matching existing entry. Let's add a new one */
+	new_rule = kmalloc(sizeof(MV_FP_ARP_RULE), GFP_ATOMIC);
+	if (new_rule == NULL) {
+		spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+		return -ENOMEM;
+	}
+	new_rule->ip = ip;
+	mac_addr_copy(new_rule->mac, mac);
+	new_rule->confirmed = 1;
+    	new_rule->if_index = if_index;
+	new_rule->next = NULL;
+	
+	if (mgr_arp_rule_db.rule_chain == NULL) {
+		/* There is no rule in this table yet */
+		mgr_arp_rule_db.rule_chain = new_rule;
+	}
+	else {
+		/* Let's add this rule at the tail of the list */
+		curr_rule = mgr_arp_rule_db.rule_chain;
+		while (curr_rule->next != NULL)
+			curr_rule = curr_rule->next;
+		
+		curr_rule->next = new_rule;		
+	}
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return fp_rule_db_arp_update(ip, mac);
+}
+
+/* Delete ARP information from the ARP database, and update the Routing + ARP database if necessary */
+/* If a rule became incomplete, update the NFP database */
+int fp_arp_info_delete(u32 ip)
+{
+	unsigned long   flags;
+	MV_FP_ARP_RULE  *curr_rule;
+	MV_FP_ARP_RULE  *prev_rule;
+	u8              mac[] = {0x00, 0x00, 0x00, 0x00, 0x00, 0x00};
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+
+	prev_rule = NULL;	
+	for (	curr_rule = mgr_arp_rule_db.rule_chain; 
+		curr_rule != NULL; 
+		prev_rule = curr_rule, curr_rule = curr_rule->next) {
+		if (curr_rule->ip == ip) {
+			/* Note there should only be one matching entry for this IP address */
+			if (prev_rule == NULL)
+				mgr_arp_rule_db.rule_chain = curr_rule->next;	
+			else
+				prev_rule->next = curr_rule->next;
+			kfree(curr_rule);
+			spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+            		FP_MGR_DBG(FP_MGR_DBG_ARP, 
+                		("nfp_mgr: ARP delete: IP=%u.%u.%u.%u, MAC=%02X:%02X:%02X:%02X:%02X:%02X\n",
+                        	NIPQUAD(ip), mac[0], mac[1], mac[2], mac[3], mac[4], mac[5]));
+
+			return fp_rule_db_arp_update(ip, mac);
+		}
+	}
+	/* We haven't found a matching entry, so nothing to do */
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return 0;
+}
+
+/* Set a new rule or update an existing one  */
+/* When looking for an existing rule, search */
+/* a match for SIP, DIP, and default gateway IP */
+/* Rule type is also taken into account: */
+/* a new static rule can overrode an existing rule of any type, */
+/* while a new dynamic rule can only override an existing dynamic rule */
+int fp_rule_set(MV_FP_RULE *rule)
+{
+	unsigned long   flags;
+	MV_FP_RULE      *curr_rule;
+	MV_FP_RULE      *new_rule;
+	int             status = 0;
+
+	/* Static rules are supplied with GbE port numbers, while */
+	/* dynamic rules are supplied with Linux interface indices. */
+	if (rule->mgmtInfo.ruleType == MV_FP_DYNAMIC_RULE) {
+		struct net_device   *in_dev, *out_dev;
+
+		/* We are not interested in this rule if the input interface or */
+		/* the output interface is not one of our GbE interfaces.	*/
+		if (	!is_valid_index(rule->routingInfo.inIfIndex) || 
+            		!is_valid_index(rule->routingInfo.outIfIndex)) 
+		{
+			return 0;
+		}
+
+		in_dev = mv_dev_get_by_index(rule->routingInfo.inIfIndex);
+		out_dev = mv_dev_get_by_index(rule->routingInfo.outIfIndex);
+
+		/* check MTU compatability */
+		if (in_dev && out_dev) {
+#ifdef CONFIG_MV_ETH_NFP_PPP
+			if ((in_dev->type == ARPHRD_PPP) || (out_dev->type == ARPHRD_PPP))
+				;
+			else
+#endif
+			if ((in_dev->mtu != out_dev->mtu) || 
+				(out_dev->mtu > ETH_CSUM_MAX_BYTE_COUNT))
+			{
+				/* printk("%s: invalid mtu %d, %d\n", __FUNCTION__, 
+					   in_dev->mtu, out_dev->mtu); */
+				return 0;
+			}
+		}
+	}
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+    	curr_rule = fp_rule_find(rule->routingInfo.srcIp, rule->routingInfo.dstIp);
+    	if(curr_rule != NULL)
+    	{
+        	if( (curr_rule->mgmtInfo.ruleType == MV_FP_DYNAMIC_RULE) || 
+	        	(rule->mgmtInfo.ruleType == MV_FP_STATIC_RULE) ) 
+        	{
+	        	/* Update existing rule, but only if the current rule is a dynamic rule, */
+	        	/* or the new rule is a static rule which overrides the current rule. */		
+	        	mvFpRuleCopy(curr_rule, rule);
+
+	        	if (!is_zero_ether_addr(curr_rule->routingInfo.dstMac)) {
+		        	/* Now we have a full rule - we can update the NFP database */
+		        	fp_new_rule_awareness(curr_rule);
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+			    	status = mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, 
+			                        MV_FP_RULE_SET_OPCODE, curr_rule, sizeof(MV_FP_RULE));
+#else
+			    	status = mvFpRuleSet(curr_rule);
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+		    	}
+	    	}
+        	/* else, we have found a matching entry, but the current rule is static and */
+	    	/* the new rule is dynamic, so static rule remains unchanged, and we can exit here. */
+	    	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	    	return status;
+    	}
+	/* We haven't found a matching existing entry. Let's add a new one */
+	new_rule = kmalloc(sizeof(MV_FP_RULE), GFP_ATOMIC);
+	if (new_rule == NULL) {
+		spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+		return -ENOMEM;
+	}
+	mvFpRuleCopy(new_rule, rule);	
+	new_rule->next = NULL;
+
+	if (mgr_rule_db.rule_chain == NULL) {
+		/* There is no rule in this table yet */
+		mgr_rule_db.rule_chain = new_rule;
+	}
+	else {
+		/* Let's add this rule at the tail of the list */
+		curr_rule = mgr_rule_db.rule_chain;		
+		while (curr_rule->next != NULL)
+			curr_rule = curr_rule->next;
+		curr_rule->next = new_rule;		
+	}
+	if (!is_zero_ether_addr(new_rule->routingInfo.dstMac)) {
+		/* Now we have a full rule - we can update the the NFP database */
+		fp_new_rule_awareness(new_rule);
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+		status = mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, 
+				MV_FP_RULE_SET_OPCODE, new_rule, sizeof(MV_FP_RULE));
+#else
+		status = mvFpRuleSet(new_rule);
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+	}
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return status;
+}
+
+/* Delete an existing rule */
+/* When looking for an existing rule, search */
+/* a match for SIP, DIP */
+int fp_rule_delete(u32 src_ip, u32 dst_ip, MV_FP_RULE_TYPE rule_type)
+{
+	unsigned long   flags;
+	MV_FP_RULE      *curr_rule;
+	MV_FP_RULE      *prev_rule;
+	int             status = 0;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	prev_rule = NULL;	
+
+	for(curr_rule = mgr_rule_db.rule_chain; 
+		curr_rule != NULL; 
+		prev_rule = curr_rule, curr_rule = curr_rule->next) {
+		if( (curr_rule->routingInfo.srcIp == src_ip) && 
+			(curr_rule->routingInfo.dstIp == dst_ip) && 
+			(curr_rule->mgmtInfo.ruleType == rule_type) ) {
+			/* Note there should only be one matching entry, if any */
+			if (prev_rule == NULL) {
+				mgr_rule_db.rule_chain = curr_rule->next;
+			}
+			else {
+				prev_rule->next = curr_rule->next;
+			}
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+			status = mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, 
+						MV_FP_RULE_DELETE_OPCODE, curr_rule, sizeof(MV_FP_RULE));
+#else
+			status = mvFpRuleDelete(curr_rule);
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+			kfree(curr_rule);
+			spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+			return status;
+		}
+	}
+	/* We haven't found a matching entry, so nothing to do */
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return 0;
+}
+
+/* 
+ * Set Routing ToS for 2-tuple connection
+ */
+#ifdef CONFIG_MV_ETH_NFP_TOS
+int fp_routing_tos_set(u32 src_ip, u32 dst_ip, u32 dscp, u32 txq)
+{
+	MV_FP_RULE* rule;
+	unsigned long flags;
+
+	FP_MGR_DBG(FP_MGR_DBG_ROUTE, 
+			("FP_MGR: Setting ToS Information: SIP = "NIPQUAD_FMT ", DIP = "NIPQUAD_FMT", TOS=0x%x TxQ=%d\n", 
+			NIPQUAD(src_ip), NIPQUAD(dst_ip), dscp, txq));
+
+	if (txq >= CONFIG_MV_ETH_TX_Q_NUM)
+		return -EINVAL;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	rule = fp_rule_find(src_ip,dst_ip);
+	if (rule) {
+		rule->routingInfo.dscp = (u8)dscp;
+		rule->routingInfo.txq = (u8)txq;
+	
+		/* The rule is already applied, update engine db */
+		if (!is_zero_ether_addr(rule->routingInfo.dstMac))
+			mvFpToSSet(rule);
+	}
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+	return 0;
+}
+#endif
+/* Set Routing information received from the IP stack when a new Routing cache entry is created */
+/* Look for matching ARP information to complete the rule */
+/* If we have a complete rule, update the NFP database */
+int fp_routing_info_set(u32 src_ip, u32 dst_ip, u32 def_gtw_ip, int ingress_if, int egress_if)
+{
+	MV_FP_RULE          new_rule;
+	MV_FP_ARP_RULE      *arp_rule;
+	struct net_device   *dev;
+
+        if (fp_disable_flag == 1)
+                return 0;
+
+	FP_MGR_DBG(FP_MGR_DBG_ROUTE, ("FP_MGR: Setting Routing Information\n"));
+	FP_MGR_DBG(FP_MGR_DBG_ROUTE, 
+			("SIP = "NIPQUAD_FMT ", DIP = "NIPQUAD_FMT", GTW = "NIPQUAD_FMT", In IF = %d, Out IF = %d\n", 
+			NIPQUAD(src_ip), NIPQUAD(dst_ip), 
+			NIPQUAD(def_gtw_ip), ingress_if, egress_if));
+
+    	if( !is_valid_index(ingress_if) || !is_valid_index(egress_if) )
+       		return 0;
+
+	memset(&new_rule, 0, sizeof(MV_FP_RULE));
+	new_rule.mgmtInfo.actionType = MV_FP_ROUTE_CMD;
+	new_rule.mgmtInfo.ruleType = MV_FP_DYNAMIC_RULE; 
+
+	new_rule.routingInfo.srcIp = src_ip;
+	new_rule.routingInfo.dstIp = dst_ip;
+	new_rule.routingInfo.defGtwIp = def_gtw_ip;
+	
+	dev = mv_dev_get_by_index(egress_if);
+	if (dev)  
+		mac_addr_copy(new_rule.routingInfo.srcMac, dev->dev_addr);
+
+   	fp_eth_devs[egress_if].def_gtw_ip = def_gtw_ip;
+
+	/* Note: searching destination MAC according to default gateway IP */
+	if ((arp_rule = fp_arp_rule_find(def_gtw_ip)) != NULL) 
+		mac_addr_copy(new_rule.routingInfo.dstMac, arp_rule->mac);
+
+	new_rule.routingInfo.inIfIndex = ingress_if;
+	new_rule.routingInfo.outIfIndex = egress_if;
+#ifdef CONFIG_MV_ETH_NFP_PPP
+	/* DA is defined by pppoe session */
+	if (dev->type == ARPHRD_PPP)
+		new_rule.routingInfo.dstMac[5] = 0xAA;
+#endif
+
+	return fp_rule_set(&new_rule);
+}
+
+/* Delete Routing information from the Routing + ARP database, and update the NFP database */
+int fp_routing_info_delete(u32 src_ip, u32 dst_ip, int iif, int oif)
+{
+        if (fp_disable_flag == 1)
+                return 0;
+
+	FP_MGR_DBG(FP_MGR_DBG_ROUTE, ("FP_MGR: Deleting Routing Information\n"));
+	FP_MGR_DBG(FP_MGR_DBG_ROUTE, (	"SIP = %u.%u.%u.%u, DIP = %u.%u.%u.%u\n", 
+					NIPQUAD(src_ip), NIPQUAD(dst_ip)));
+
+        if( !is_valid_index(iif) || !is_valid_index(oif) )
+                return 0;
+
+	return fp_rule_delete(src_ip, dst_ip, MV_FP_DYNAMIC_RULE);
+}
+
+#ifdef CONFIG_MV_ETH_NFP_NAT
+
+/* Initialize NFP NAT Rule Database (SNAT + DNAT table) */
+int fp_nat_db_init(u32 db_size)
+{
+	FP_MGR_DBG(FP_MGR_DBG_INIT, ("FP_MGR: Initializing NAT Rule Database\n"));
+	mgr_nat_rule_db.rule_chain = NULL;
+	mgr_nat_rule_db.max_size = db_size;
+
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+	return mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, MV_FP_NAT_DB_INIT_OPCODE, 
+				&(mgr_nat_rule_db.max_size), sizeof(mgr_nat_rule_db.max_size));
+#else
+	return mvFpNatDbInit(mgr_nat_rule_db.max_size);
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+}
+
+/* Clear NFP NAT Rule Database (SNAT + DNAT table) */
+int fp_nat_db_clear(void)
+{
+	int             status = 0;
+	unsigned long   flags;
+	MV_FP_NAT_RULE  *curr_rule;
+	MV_FP_NAT_RULE  *tmp_rule;
+
+	FP_MGR_DBG(FP_MGR_DBG_CLR, ("FP_MGR: Clearing NAT Rule Database\n"));
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	curr_rule = mgr_nat_rule_db.rule_chain;
+	while (curr_rule != NULL) {
+		tmp_rule = curr_rule;
+		curr_rule = curr_rule->next;
+		kfree(tmp_rule);
+	}
+	mgr_nat_rule_db.rule_chain = NULL;
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+	status = mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, MV_FP_NAT_DB_CLEAR_OPCODE, NULL, 0);
+#else
+	status = mvFpNatDbClear();
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return status;
+}
+
+static int fp_nat_db_clear_and_update(void)
+{
+    int             status = 0;
+	unsigned long   flags;
+    MV_FP_NAT_RULE  *curr_nat_rule = mgr_nat_rule_db.rule_chain;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+	status = mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, MV_FP_NAT_DB_CLEAR_OPCODE, NULL, 0);
+#else
+	status = mvFpNatDbClear();
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+
+	while (curr_nat_rule != NULL) { 
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+		status |= mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, 
+					MV_FP_NAT_RULE_SET_OPCODE, curr_nat_rule, sizeof(MV_FP_NAT_RULE));
+#else
+		status |= mvFpNatRuleSet(curr_nat_rule);
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+		curr_nat_rule = curr_nat_rule->next;
+    }
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+    return status;
+}
+
+/* Print NFP NAT Rule Database (SNAT + DNAT table) */
+int fp_nat_db_print(MV_FP_OP_TYPE op)
+{
+	int             status = 0;
+	unsigned long   flags;
+	MV_FP_NAT_RULE  *curr_rule;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	if (op == MV_FP_MANAGER) {
+		printk("Printing NFP Manager NAT Rule Database: \n");
+		curr_rule = mgr_nat_rule_db.rule_chain;
+		while (curr_rule != NULL) {
+			mvFpNatRulePrint(curr_rule);
+			curr_rule = curr_rule->next;
+		}
+	}
+	else {
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+		status = mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, MV_FP_NAT_DB_PRINT_OPCODE, NULL, 0);
+#else
+		status = mvFpNatDbPrint();
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+	}
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return status;
+}
+
+static int is_relevant_nat_protocol(u8 proto)
+{
+	/* For now we only knw how to handle NAT rules for TCP/UDP/ICMP/Zero_Hop protocols */
+	/* so we disregard everything else */
+	if (	(proto == MV_IP_PROTO_TCP) || 
+		(proto == MV_IP_PROTO_UDP) || 
+		(proto == MV_IP_PROTO_ICMP) || 
+		(proto == MV_IP_PROTO_ZERO_HOP))
+		return 1;
+
+	return 0;
+}
+
+static int is_relevant_port(u16 src_port, u16 dst_port)
+{
+	/* We want to pass FTP control stream packets to Linux */
+	if (	(MV_16BIT_BE(src_port) != MV_FTP_CTRL_PORT) 
+		&& (MV_16BIT_BE(dst_port) != MV_FTP_CTRL_PORT))
+		return 1;
+	return 0;
+}
+
+/* Set a new NAT rule, or update an existing one */
+int fp_nat_info_set(u32 src_ip, u32 dst_ip, u16 src_port, u16 dst_port, u8 proto, 
+			        u32 new_src_ip, u32 new_dst_ip, u16 new_src_port, u16 new_dst_port, 
+			        int if_index, enum nf_nat_manip_type maniptype)
+{
+	unsigned long   flags;
+	MV_FP_NAT_RULE  *curr_rule;
+	MV_FP_NAT_RULE  *new_rule;
+	int             status = 0;
+
+	/* we are not interested in NAT rules that do not involve our interfaces */
+	if (!is_valid_index(if_index)) {
+		FP_MGR_DBG(FP_MGR_DBG_NAT, ("FP_MGR: invalid_index %d\n", if_index));
+		return 0;
+	}
+
+	if (!is_relevant_nat_protocol(proto)) {
+		FP_MGR_DBG(FP_MGR_DBG_NAT, ("FP_MGR: irrelevant nat protocol %d\n", proto));
+		return 0;
+	}
+
+	if (!is_relevant_port(src_port, dst_port)) {
+		FP_MGR_DBG(FP_MGR_DBG_NAT, ("FP_MGR: irrelevant port %d %d\n", src_port, dst_port));
+		return 0;
+	}
+
+	if ((src_ip == new_src_ip) && (dst_ip == new_dst_ip) && 
+		(src_port == new_src_port) && (dst_port == new_dst_port) ) 
+    	{
+   		return 0;
+	}
+
+   	FP_MGR_DBG(FP_MGR_DBG_NAT, ("FP_MGR: Setting NAT Information\n"));
+	FP_MGR_DBG(FP_MGR_DBG_NAT,
+	        ("SIP=%u.%u.%u.%u, DIP=%u.%u.%u.%u, Proto=%u, SPort=%u, DPort=%u, if_index=%d\n",
+			        NIPQUAD(src_ip), NIPQUAD(dst_ip), proto, MV_16BIT_BE(src_port), 
+			        MV_16BIT_BE(dst_port), if_index));
+
+    	FP_MGR_DBG(FP_MGR_DBG_NAT,
+        	("\tNewSIP=%u.%u.%u.%u, NewDIP=%u.%u.%u.%u, NewSPort=%u, NewDPort=%u\n\n", 
+            	NIPQUAD(new_src_ip), NIPQUAD(new_dst_ip), 
+		MV_16BIT_BE(new_src_port), MV_16BIT_BE(new_dst_port)));
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	for (curr_rule = mgr_nat_rule_db.rule_chain; curr_rule != NULL; curr_rule = curr_rule->next) {
+		if( curr_rule->srcIp == src_ip && 
+			curr_rule->dstIp == dst_ip && 
+			curr_rule->srcPort == src_port && 
+			curr_rule->dstPort == dst_port && 
+			curr_rule->proto == proto) 
+        {
+
+			/* Updating existing rule */
+			curr_rule->new_count = 0;
+            		curr_rule->old_count = 0;
+
+			if (maniptype == IP_NAT_MANIP_DST) {
+				curr_rule->newIp = new_dst_ip;
+				curr_rule->newPort = new_dst_port;
+			}
+			else {
+				curr_rule->newIp = new_src_ip;
+				curr_rule->newPort = new_src_port;
+			}
+			if (maniptype == IP_NAT_MANIP_DST) {
+				if ((dst_port != 0) && (dst_port != new_dst_port))
+					curr_rule->flags |= MV_FP_DNAT_CMD_MAP;
+				else
+					curr_rule->flags |= MV_FP_DIP_CMD_MAP; 
+			}
+			else {
+				if ((src_port != 0) && (src_port != new_src_port))
+					curr_rule->flags |= MV_FP_SNAT_CMD_MAP;
+				else
+					curr_rule->flags |= MV_FP_SIP_CMD_MAP;
+			}	
+			/* Now we have a full rule - we can update the NFP database       */
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+			status = mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, 
+				            MV_FP_NAT_RULE_SET_OPCODE, curr_rule, sizeof(MV_FP_NAT_RULE));
+#else
+			status = mvFpNatRuleSet(curr_rule);
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+			spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+			return status;
+		}
+	}
+	/* We haven't found a matching existing entry. Let's add a new one */
+	new_rule = kmalloc(sizeof(MV_FP_NAT_RULE), GFP_ATOMIC);
+	if (new_rule == NULL) {
+		spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+		return -ENOMEM;
+	}
+	new_rule->srcIp = src_ip;
+	new_rule->dstIp = dst_ip;
+	new_rule->srcPort = src_port;
+	new_rule->dstPort = dst_port;
+	new_rule->proto = proto;
+	new_rule->old_count = 0;
+    	new_rule->new_count = 0;
+	if (maniptype == IP_NAT_MANIP_DST) {
+		new_rule->newIp = new_dst_ip;
+		new_rule->newPort = new_dst_port;
+	}
+	else {
+		new_rule->newIp = new_src_ip;
+		new_rule->newPort = new_src_port;
+	}
+	if (maniptype == IP_NAT_MANIP_DST) {
+		if ((dst_port != 0) && (dst_port != new_dst_port))
+			new_rule->flags = MV_FP_DNAT_CMD_MAP;
+		else
+			new_rule->flags = MV_FP_DIP_CMD_MAP;
+	}
+	else {
+		if ((src_port != 0) && (src_port != new_src_port))
+			new_rule->flags = MV_FP_SNAT_CMD_MAP;
+		else
+			new_rule->flags = MV_FP_SIP_CMD_MAP;
+	}
+	new_rule->next = NULL;
+
+	if (mgr_nat_rule_db.rule_chain == NULL) {
+		/* There is no rule in this table yet */
+		mgr_nat_rule_db.rule_chain = new_rule;
+	}
+	else {
+		/* Let's add this rule at the tail of the list */
+		curr_rule = mgr_nat_rule_db.rule_chain;		
+		while (curr_rule->next != NULL)
+			curr_rule = curr_rule->next;
+		curr_rule->next = new_rule;		
+	}
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+	status = mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, 
+				MV_FP_NAT_RULE_SET_OPCODE, new_rule, sizeof(MV_FP_NAT_RULE));
+#else
+	status = mvFpNatRuleSet(new_rule);
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return status;
+}
+
+/* Delete a NAT rule */
+int fp_nat_info_delete(u32 src_ip, u32 dst_ip, u16 src_port, u16 dst_port, u8 proto)
+{
+	unsigned long   flags;
+	MV_FP_NAT_RULE  *curr_rule;
+	MV_FP_NAT_RULE  *prev_rule;
+	int             status = 0;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	prev_rule = NULL;
+	for (	curr_rule = mgr_nat_rule_db.rule_chain; 
+		curr_rule != NULL; 
+		prev_rule = curr_rule, curr_rule = curr_rule->next) {
+		if (	curr_rule->srcIp == src_ip && 
+			curr_rule->dstIp == dst_ip && 
+			curr_rule->srcPort == src_port && 
+			curr_rule->dstPort == dst_port && 
+			curr_rule->proto == proto) {
+
+			if (prev_rule == NULL)
+				mgr_nat_rule_db.rule_chain = curr_rule->next;	
+			else
+				prev_rule->next = curr_rule->next;
+#ifdef CONFIG_MV_ETH_NFP_DUAL
+			status = mvIpcChanMsgSend(mgr_to_fp_chan, MV_SERVICE_NFP_ID, 
+					MV_FP_NAT_RULE_DELETE_OPCODE, curr_rule, sizeof(MV_FP_NAT_RULE));
+#else
+			status = mvFpNatRuleDelete(curr_rule);
+#endif /* CONFIG_MV_ETH_NFP_DUAL */
+			kfree(curr_rule);
+			spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+			return status;
+		}
+	}
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return 0;
+}
+
+/* Return NAT rule confirmation status */
+int fp_is_nat_confirmed(u32 src_ip, u32 dst_ip, u16 src_port, u16 dst_port, u8 proto)
+{
+	unsigned long   flags;
+	MV_FP_NAT_RULE  *curr_rule;
+    	int             confirmed = 0;
+
+	if (fp_disable_flag == 1)
+		return 0;
+    	
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	curr_rule = mgr_nat_rule_db.rule_chain;
+	while (curr_rule != NULL) {
+		if( (curr_rule->srcIp == src_ip) && 
+			(curr_rule->dstIp == dst_ip) && 
+			(curr_rule->srcPort == src_port) && 
+			(curr_rule->dstPort == dst_port) && 
+			(curr_rule->proto == proto)) 
+        	{
+            		if(curr_rule->new_count != curr_rule->old_count)
+            		{
+                		curr_rule->old_count = curr_rule->new_count;
+                		confirmed = 1;
+            		}
+		    	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+			return confirmed;
+		}
+		curr_rule = curr_rule->next;
+	}
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+	return 0;
+}
+
+/* Set or clear the "NAT Aware" flags according to user's newly added or deleted iptables rule */
+static void fp_handle_user_nat_rule(FP_IPTABLES_NAT_RULE *nat_rule, int add_del_flag)
+{
+	/* This NAT rule that the user added can affect routing entries based on */
+	/* input interface, output interface, SIP, DIP */
+	/* For now, protocol and source/dest port are not taken into consideration */
+
+	MV_FP_RULE      *curr_rule;
+	unsigned long   flags;
+	
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	curr_rule = mgr_rule_db.rule_chain; 
+	while (curr_rule != NULL) {
+		update_awareness(nat_rule, curr_rule, add_del_flag);		
+		mvFpRuleAwareSet(curr_rule);	
+		curr_rule = curr_rule->next;
+	}
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+}
+
+/* Initialize our user NAT tables, mirroring iptables NAT rules table */
+void init_fp_user_nat_tables(void)
+{
+	fp_user_nat_table[0].rule_chain = NULL;
+	fp_user_nat_table[1].rule_chain = NULL;
+	curr_table = 0;
+	old_table = 1 - curr_table;
+}
+
+/* Add a user NAT rule to our mirror table */
+int add_fp_user_nat_rule(struct ipt_entry *e, int table)
+{
+	struct ipt_entry_target *t = NULL;
+	FP_IPTABLES_NAT_RULE *curr_rule = NULL, *new_rule = NULL;
+
+	t = ipt_get_target(e);
+	/* Disregard targets that do not interest us */
+	if (	strcmp(t->u.kernel.target->name, MASQ_TARGET_NAME) && 
+		strcmp(t->u.kernel.target->name, REDIRECT_TARGET_NAME) && 
+		strcmp(t->u.kernel.target->name, SNAT_TARGET_NAME) && 
+		strcmp(t->u.kernel.target->name, DNAT_TARGET_NAME))
+		return 0;
+
+	new_rule = kmalloc(sizeof(FP_IPTABLES_NAT_RULE), GFP_ATOMIC);
+	if (new_rule == NULL)
+		return -ENOMEM;
+	memset(new_rule, 0, sizeof(FP_IPTABLES_NAT_RULE));
+
+	strcpy(new_rule->target_name, t->u.kernel.target->name);
+	strcpy(new_rule->iniface, e->ip.iniface);
+	strcpy(new_rule->outiface, e->ip.outiface);
+	new_rule->sip = e->ip.src.s_addr; 
+	new_rule->dip = e->ip.dst.s_addr;
+	new_rule->smsk = e->ip.smsk.s_addr;
+	new_rule->dmsk = e->ip.dmsk.s_addr;
+	new_rule->proto = e->ip.proto;
+	new_rule->next = NULL;
+
+	if (fp_user_nat_table[table].rule_chain == NULL) {
+		/* There is no rule in this table yet */
+		fp_user_nat_table[table].rule_chain = new_rule;
+	}
+	else {
+		/* Let's add this rule at the tail of the list */
+		curr_rule = fp_user_nat_table[table].rule_chain;		
+		while (curr_rule->next != NULL)
+			curr_rule = curr_rule->next;
+		curr_rule->next = new_rule;		
+	}
+	return 0;
+}
+
+/* Clear our user NAT rule table */
+void clear_fp_user_nat_table(int table)
+{
+	FP_IPTABLES_NAT_RULE *curr_rule;
+	FP_IPTABLES_NAT_RULE *tmp_rule;
+
+	curr_rule = fp_user_nat_table[table].rule_chain;
+	while (curr_rule != NULL) {
+		tmp_rule = curr_rule;
+		curr_rule = curr_rule->next;
+		kfree(tmp_rule);
+	}
+	fp_user_nat_table[table].rule_chain = NULL;
+}
+
+/* Check if two user NAT rules are equal */
+static int rules_are_equal(FP_IPTABLES_NAT_RULE *r1, FP_IPTABLES_NAT_RULE *r2)
+{
+	if (strcmp(r1->target_name, r2->target_name))
+		return 0;
+
+	if (	(r1->sip != r2->sip) || (r1->dip != r2->dip) || 
+		(r1->smsk != r2->smsk) || (r2->dmsk != r2->dmsk) || 
+		(r1->proto != r2->proto))
+		return 0;
+
+	if (strcmp(r1->iniface, r2->iniface) || strcmp(r1->outiface, r2->outiface))
+		return 0;
+
+	return 1;
+}
+
+/* Check if a rule exists in our user NAT table */
+static int rule_exists_in_table(FP_IPTABLES_NAT_RULE *rule, int table)
+{
+	FP_IPTABLES_NAT_RULE *curr_rule;
+
+	curr_rule = fp_user_nat_table[table].rule_chain;
+	while (curr_rule != NULL) {
+		if (rules_are_equal(rule, curr_rule))
+			return 1;
+		curr_rule = curr_rule->next;
+	}
+	return 0;
+}
+
+/* Compare the two mirror tables to discover which new rules were added, and which rules were deleted */
+void compare_fp_user_nat_tables(void)
+{
+	FP_IPTABLES_NAT_RULE *curr_rule;
+	/* Stage 1: */
+	/* Compare current table to previous one to detect newly added rules */
+	/* For each rule in curr_table: */
+	/* If it exists also in old_table, we don't care */
+	/* If not, it is new */
+	curr_rule = fp_user_nat_table[curr_table].rule_chain;
+	while (curr_rule != NULL) {
+		if (!rule_exists_in_table(curr_rule, old_table)) {
+			fp_handle_user_nat_rule(curr_rule, 1); /* pass 1 for adding a new rule */
+		}
+		curr_rule = curr_rule->next;
+	}
+	
+	/* Stage 2: */
+	/* Compare previous table to current one to detect newly deleted rules */
+	/* For each rule in old_table: */
+	/* If it exists also in curr_table, we don't care */
+	/* If not, it was deleted */
+	curr_rule = fp_user_nat_table[old_table].rule_chain;
+	while (curr_rule != NULL) {
+		if (!rule_exists_in_table(curr_rule, curr_table)) {
+			fp_handle_user_nat_rule(curr_rule, 0); /* pass 0 for deleting a rule */
+		}
+		curr_rule = curr_rule->next;
+	}
+}
+
+#endif /* CONFIG_MV_ETH_NFP_NAT */
+
+module_exit(fp_exit_module);
+
+#ifdef CONFIG_MV_ETH_NFP_FDB
+
+/* Initialize Fast Bridge Rule Database */
+int fp_fdb_db_init(u32 db_size)
+{
+        FP_MGR_DBG(FP_MGR_DBG_INIT, ("FP_MGR: Initializing Bridge Rule Database\n"));
+
+		mgr_fdb_rule_db.rule_chain = NULL;
+		mgr_fdb_rule_db.max_size = db_size;
+
+		return mvFpFdbInit(db_size);
+}
+
+/* Set Bridging information in the FDB database */
+int fp_fdb_info_set(u32 if_bridge, u32 if_index, const u8 *mac, int is_local)
+{
+	unsigned long flags;
+	MV_FP_FDB_RULE rule;
+
+	if (is_local && fp_mgr_if_register(if_bridge, MV_FP_IF_BRG, mv_dev_get_by_index(if_bridge))) {
+		FP_MGR_DBG(FP_MGR_DBG_FDB, ("FDB_MNG: failed to register bridge=%d\n", if_bridge));
+	}
+
+	memset(&rule, 0, sizeof(MV_FP_FDB_RULE));
+	rule.mgmtInfo.actionType = MV_FP_BRIDGE_CMD;
+	rule.mgmtInfo.ruleType = MV_FP_DYNAMIC_RULE; 
+
+	mac_addr_copy(rule.fdbInfo.mac, mac);
+	rule.fdbInfo.ifIndex = if_index;
+	rule.fdbInfo.bridge = if_bridge;
+	rule.fdbInfo.flags = (unsigned short)is_local;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	mvFpFdbRuleSet(&rule);
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+	return 0;
+}
+
+/* Delete bridging information in the FDB database */
+int fp_fdb_info_del(u32 if_bridge, u32 if_index, const u8 *mac, int is_local)
+{
+	unsigned long flags;
+	MV_FP_FDB_RULE rule;
+
+	if (is_local && !fp_mgr_if_unregister(if_bridge)) 
+		FP_MGR_DBG(FP_MGR_DBG_FDB, ("FDB_MNG: unregister bridge=%d\n", if_bridge));
+    
+	memset(&rule, 0, sizeof(MV_FP_FDB_RULE));
+
+	mac_addr_copy(rule.fdbInfo.mac, mac);
+	rule.fdbInfo.ifIndex = if_index;
+	rule.fdbInfo.bridge = if_bridge;
+	rule.fdbInfo.flags = (unsigned short)is_local;
+
+	/* has expired */
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	if (!is_local && (mvFpFdbRuleAge(&rule) > 0)) {
+		spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+		return 1; 
+	}
+
+	mvFpFdbRuleDel(&rule);
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+	return 0;
+}
+
+/* Clear Fast Path FDB Rule Database */
+int fp_fdb_db_clear(void)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	mvFpFdbClear();
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+	return 0;
+}
+
+/* Print Fast Path FDB Rule Database */
+int fp_fdb_db_print(MV_FP_OP_TYPE op)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	mvFpFdbPrint();
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+	return 0;
+}
+
+#endif /* CONFIG_MV_ETH_NFP_FDB */
+
+
+#ifdef CONFIG_MV_ETH_NFP_PPP
+
+/* Initialize Rule Database */
+int fp_ppp_db_init(void)
+{
+	FP_MGR_DBG(FP_MGR_DBG_INIT, ("FP_MGR: Initializing PPPoE Rule Database\n"));
+	return mvFpPppInit();
+}
+EXPORT_SYMBOL(fp_ppp_db_init);
+
+/* Set information in the PPP database:
+ * @ifindex - virtual interface, e.g. ppp0
+ * @egress - physical interface, e.g. eth0
+ * @sid - session id
+ * @mac - destination mac
+ */
+int fp_ppp_info_set(u32 if_ppp, u32 if_eth, u16 sid, u8 *mac, u32 channel)
+{
+	unsigned long flags;
+	MV_FP_PPP_RULE rule;
+
+	/* the physical interface is not NFP capable */
+	if (if_eth && fp_mgr_get_iftype(if_eth) != MV_FP_IF_INT)
+		goto out;
+
+	if (if_ppp && fp_mgr_if_register(if_ppp, MV_FP_IF_PPP, mv_dev_get_by_index(if_ppp)))
+        goto out;
+
+	memset(&rule, 0, sizeof(MV_FP_PPP_RULE));
+	rule.mgmtInfo.actionType = MV_FP_PPP_CMD;
+	rule.mgmtInfo.ruleType = MV_FP_DYNAMIC_RULE; 
+
+	if (mac) 
+		mac_addr_copy(rule.pppInfo.u.ppp.da, mac);
+
+	if (if_eth) {
+        	struct net_device* dev = mv_dev_get_by_index(if_eth);
+			mac_addr_copy(rule.pppInfo.u.ppp.sa, dev->dev_addr);
+			rule.pppInfo.u.ppp.tag = 0; /* mvHeader */;
+	}
+
+	rule.pppInfo.u.ppp.ethertype = 0x6488;
+	rule.pppInfo.u.ppp.version  = 0x0011;
+	rule.pppInfo.u.ppp.session = sid;
+	rule.pppInfo.u.ppp.proto = 0x2100;
+
+
+	rule.pppInfo.if_ppp = if_ppp;
+	rule.pppInfo.if_eth = if_eth;
+	rule.pppInfo.channel = channel;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	mvFpPppRuleSet(&rule);
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+	return 0;
+out:
+	if (if_ppp >= ETH_FP_IFINDEX_MAX) 
+		printk("ppp device ifindex (%d) is out of range, please reboot your system\n", if_ppp);
+
+	FP_MGR_DBG(FP_MGR_DBG_PPP, ("PPP_MNG: failed to register ppp=%d over eth=%d\n", if_ppp, if_eth));
+	return 1;
+}
+EXPORT_SYMBOL(fp_ppp_info_set);
+
+/* Delete bridging information in the PPP database */
+int fp_ppp_info_del(u32 channel)
+{
+	unsigned long flags;
+	MV_FP_PPP_RULE rule;
+
+	memset(&rule, 0, sizeof(MV_FP_PPP_RULE));
+	rule.pppInfo.channel = channel;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	mvFpPppRuleDel(&rule);
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL(fp_ppp_info_del);
+
+/* Clear Fast Path PPP Rule Database */
+int fp_ppp_db_clear(void)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	mvFpPppClear();
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL(fp_ppp_db_clear);
+
+/* Print Fast Path PPP Rule Database */
+int fp_ppp_db_print(MV_FP_OP_TYPE op)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	mvFpPppPrint();
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+	return 0;
+}
+
+#endif /* CONFIG_MV_ETH_NFP_PPP */
+
+#ifdef CONFIG_MV_ETH_NFP_SEC
+/* Print Fast Path SEC Rule Database */
+int fp_sec_db_print(MV_FP_OP_TYPE op)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&nfp_mgr_lock, flags);
+	mvNfpSecDbPrint();
+	spin_unlock_irqrestore(&nfp_mgr_lock, flags);
+
+	return 0;
+}
+
+#endif /* CONFIG_MV_ETH_NFP_SEC */
+
+
+
+
+
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_mgr.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_mgr.h
new file mode 100644
index 0000000..9f8b113
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_mgr.h
@@ -0,0 +1,224 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+
+/*******************************************************************************
+* mv_nfp_mgr.h - Header File for Marvell NFP Manager
+*
+* DESCRIPTION:
+*       This header file contains macros, typedefs and function declarations 
+* 	specific to the Marvell Network Fast Processing Manager.
+*
+* DEPENDENCIES:
+*       None.
+*
+*******************************************************************************/
+
+#ifndef __mv_nfp_mgr_h__
+#define __mv_nfp_mgr_h__
+
+/* includes */
+#ifdef CONFIG_MV_ETH_NFP_NAT
+#include <linux/netfilter_ipv4/ip_tables.h>
+#include <net/netfilter/nf_nat.h>
+#endif
+#include "eth/nfp/mvNfp.h"
+
+/* defines */
+
+/* enumerations */
+
+typedef enum {
+	MV_FP_MANAGER = 0, 
+	MV_FP_DATABASE = 1
+
+} MV_FP_OP_TYPE;
+
+/* NFP interface type, used for registration */
+typedef enum {
+	MV_FP_IF_INV,   /* Invalid interface */
+	MV_FP_IF_INT,   /* use to register a Marvell GbE interface */
+	MV_FP_IF_BRG,   /* use to register a virtual interface such as bridge */
+	MV_FP_IF_PPP,   /* use to register a virtual interface such as pppoe */
+	MV_FP_IF_EXT    /* use to register an external interface such as WLAN */
+
+} MV_FP_IF_TYPE;
+
+/* data types */
+struct map_eth_devs {
+	MV_FP_IF_TYPE       if_type;
+	struct net_device*  dev;
+    u32                 def_gtw_ip;
+};
+
+extern struct map_eth_devs *fp_eth_devs;
+extern int  fp_disable_flag;
+
+static INLINE int fp_is_enabled(void)
+{
+	return (!fp_disable_flag);
+}
+
+static INLINE MV_FP_IF_TYPE fp_mgr_get_if_type(int if_index)
+{
+    if( (if_index < 0) || (if_index >= ETH_FP_IFINDEX_MAX) )
+    {
+        mvOsPrintf("if_index %d is OUT of RANGE\n", if_index);
+        return MV_FP_IF_INV;
+    }
+    return fp_eth_devs[if_index].if_type;
+}
+
+static INLINE struct net_device* fp_mgr_get_net_dev(int if_index)
+{
+    if( (if_index < 0) || (if_index >= ETH_FP_IFINDEX_MAX) )
+    {
+        mvOsPrintf("if_index %d is OUT of RANGE\n", if_index);
+        return NULL;
+    }
+    return fp_eth_devs[if_index].dev;
+}
+
+/* function headers: */
+
+/* Initialize NFP Manager */
+int fp_mgr_init(void);
+
+/* Register a network interface that works with NFP	  */
+/* Parameters: 						  */
+/* if_index: Linux network interface index 		  */
+/* if_type: interface type (gateway, external)		  */
+/* dev: pointer to the Linux net_device			  */
+/* Returns port number 					  */
+int fp_mgr_if_register(	int if_index, MV_FP_IF_TYPE if_type, 
+			            struct net_device* dev);
+int fp_mgr_if_unregister(int if_index);
+
+/* This function is called when user-space tool disables the NFP.	*/
+/* All databases are cleared, and learning of new rules is disabled	*/
+/* for all types of rules: static, dynamic, arp, routing etc.		*/
+void fp_mgr_disable(void);
+
+/* This function is called when user-space tool enables the NFP.	*/
+int fp_mgr_enable(void);
+
+/* This function is called when user-space tool asks about NFP status (enabled/disabled) */
+int fp_mgr_status(void);
+
+/* Initialize NFP Rule Database (Routing + ARP information table) 	*/
+int fp_rule_db_init(u32 db_size);
+
+/* Initialize NFP NAT Rule Database (SNAT + DNAT table) 		*/
+int fp_nat_db_init(u32 db_size);
+
+/* Initialize NFP Manager ARP Database 					*/
+int fp_arp_db_init(u32 db_size);
+
+/* Clear NFP Rule Database (Routing + ARP information table) 		*/
+int fp_rule_db_clear(void);
+
+/* Clear NFP NAT Rule Database (SNAT + DNAT table) 			*/
+int fp_nat_db_clear(void);
+
+/* Clear NFP Manager ARP Database */
+int fp_arp_db_clear(void);
+
+/* Print NFPRule Database (Routing + ARP information table) */
+int fp_rule_db_print(MV_FP_OP_TYPE);
+
+/* Print NFP NAT Rule Database (SNAT + DNAT table) */
+int fp_nat_db_print(MV_FP_OP_TYPE);
+
+/* Print NFP Manager ARP Database */
+int fp_arp_db_print(void);
+
+/* Set a new rule or update an existing one  */
+/* When looking for an existing rule, search */
+/* a match for SIP, DIP, and default gateway IP */
+/* Rule type is also taken into account: */
+/* a new static rule can overrode an existing rule of any type, */
+/* while a new dynamic rule can only override an existing dynamic rule */
+int fp_rule_set(MV_FP_RULE *rule);
+
+/* Delete an existing rule */
+/* When looking for an existing rule, search */
+/* a match for SIP, DIP */
+int fp_rule_delete(u32 src_ip, u32 dst_ip, MV_FP_RULE_TYPE rule_type);
+
+/* Set Routing information received from the IP stack when a new Routing cache entry is created */
+/* Look for matching ARP information to complete the rule */
+/* If we have a complete rule, update the NFP database */
+int fp_routing_info_set(u32 src_ip, u32 dst_ip, u32 def_gtw_ip, int ingress_if, int egress_if);
+
+/* Delete Routing information from the Routing + ARP database, and update the NFP database */
+int fp_routing_info_delete(u32 src_ip, u32 dst_ip, int iif, int oif);
+
+/* Set ARP information in the ARP database, and update the Routing + ARP database if necessary */
+/* If we have a complete rule, update the NFP database */
+int fp_arp_info_set(int if_index, u32 ip, const u8 *mac);
+
+/* Delete ARP information from the ARP database, and update the Routing + ARP database if necessary */
+/* If a rule became incomplete, update the NFP database */
+int fp_arp_info_delete(u32 ip);
+
+/* Return ARP rule confirmation status */
+int fp_is_arp_confirmed(u32 ip, const u8 *mac);
+
+/* Return routing rule confirmation status */
+int fp_is_route_confirmed(u32 src_ip, u32 dst_ip, int iif, int oif);
+int fp_is_enabled(void);
+
+#ifdef CONFIG_MV_ETH_NFP_NAT
+/* Set a new NAT rule, or update an existing one */
+int fp_nat_info_set(	u32 src_ip, u32 dst_ip, u16 src_port, u16 dst_port, u8 proto,  
+			u32 new_src_ip, u32 new_dst_ip, u16 new_src_port, u16 new_dst_port, 
+			int if_index, enum nf_nat_manip_type maniptype);
+
+int fp_nat_info_delete(u32 src_ip, u32 dst_ip, u16 src_port, u16 dst_port, u8 proto);
+
+/* Return NAT rule confirmation status */
+int fp_is_nat_confirmed(u32 src_ip, u32 dst_ip, u16 src_port, u16 dst_port, u8 proto);
+#endif /* CONFIG_MV_ETH_NFP_NAT */
+
+#ifdef CONFIG_MV_ETH_NFP_FDB
+int fp_fdb_db_init(u32 db_size);
+int fp_fdb_info_set(u32 ifvlan, u32 ifport, const u8 *mac, int is_local);
+int fp_fdb_info_del(u32 ifvlan, u32 ifport, const u8 *mac, int is_local);
+int fp_fdb_db_print(MV_FP_OP_TYPE op);
+int fp_fdb_db_clear(void);
+#endif	/* CONFIG_MV_ETH_NFP_FDB */
+
+#ifdef CONFIG_MV_ETH_NFP_PPP
+int fp_ppp_db_print(MV_FP_OP_TYPE op);
+#endif	/* CONFIG_MV_ETH_NFP_PPP */
+#ifdef CONFIG_MV_ETH_NFP_SEC
+int fp_sec_db_print(MV_FP_OP_TYPE op);
+#endif	/* CONFIG_MV_ETH_NFP_SEC */
+
+#endif /* __mv_nfp_mgr_h__ */
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_sec.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_sec.c
new file mode 100644
index 0000000..2f19868
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/nfp_mgr/mv_nfp_sec.c
@@ -0,0 +1,716 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef AUTOCONF_INCLUDED
+#include <linux/config.h>
+#endif
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <linux/slab.h>
+#include <linux/sched.h>
+#include <linux/wait.h>
+#include <linux/crypto.h>
+#include <linux/mm.h>
+#include <linux/skbuff.h>
+#include <linux/random.h>
+#include <asm/scatterlist.h>
+#include <linux/spinlock.h>
+#include "ctrlEnv/sys/mvSysCesa.h"
+#include "cesa/mvCesa.h"
+#include "../../../common/mv802_3.h"
+#include "eth/nfp/mvNfpSec.h"
+#include "mvDebug.h"
+#include "eth/mvEth.h"
+#include "eth-phy/mvEthPhy.h"
+#include "ctrlEnv/sys/mvSysGbe.h"
+#include "../mv_ethernet/mv_netdev.h"
+
+#include "cesa/mvMD5.h"
+#include "cesa/mvSHA1.h"
+
+#include "cesa/mvCesaRegs.h"
+#include "cesa/AES/mvAes.h"
+#include "cesa/mvLru.h"
+
+#undef RT_DEBUG
+#undef dprintk
+#ifdef RT_DEBUG
+#define dprintk(a...)    printk(a)
+#else
+#define dprintk(a...)
+#endif
+
+#define MV_NFP_SEC_MAX_SES	100
+
+extern u32 mv_crypto_base_get(void);
+extern void eth_check_for_tx_done(void);
+extern MV_U8 mvFpPortsGet(MV_IP_HEADER* pIpHdr, MV_U16* pDstPort, MV_U16* pSrcPort);
+
+static struct tasklet_struct nfp_sec_tasklet;
+static spinlock_t 	nfp_sec_lock;
+
+int nfp_sec_sent = 0;
+
+static wait_queue_head_t   nfp_sec_waitq;
+atomic_t req_count;
+static MV_NFP_SEC_CESA_PRIV * req_array[MV_NFP_SEC_REQ_Q_SIZE];
+unsigned int req_empty = 0;
+unsigned int req_ready = 0;
+
+
+/* TBD -  should be used from netdev.c */
+INLINE void  nfp_sec_pkt_info_free(MV_PKT_INFO* pPktInfo)
+{
+	MV_BUF_INFO *pBuf = pPktInfo->pFrags;
+	mv_eth_priv *src_priv = mv_eth_ports[(int)pPktInfo->ownerId];
+	
+	if (pBuf->bufAddrShift) {
+		pBuf->bufPhysAddr += pBuf->bufAddrShift;
+		pBuf->bufVirtPtr += pBuf->bufAddrShift;
+		pBuf->bufAddrShift = 0;
+	}
+/*
+	// for debug:	
+	mvEthRxDoneTest(pBuf, CONFIG_NET_SKB_HEADROOM);
+*/	
+	/* Return to the NFP pool */
+	mvStackPush(src_priv->fpRxPool, (MV_U32)pPktInfo);
+}
+
+/* TDB - move to h file */
+static INLINE MV_VOID mvNfpSecClearRange(MV_U8* addr, MV_U32 size)
+{
+	MV_U32 i;
+	MV_U8  *align;
+
+	align = (MV_U8*)((MV_U32)addr & ~0x1f);
+	
+	for(i = 0; align <= (addr+size); align += CPU_D_CACHE_LINE_SIZE) {
+		mvOsCacheLineFlushInv(NULL, align);
+		mvOsCacheIoSync();
+	}
+}
+
+static INLINE MV_VOID mvNfpSecInvRange(MV_U8* addr, MV_U32 size)
+{
+	MV_U32 i;
+	MV_U8  *align;
+
+	align = (MV_U8*)((MV_U32)addr & ~0x1f);
+	
+	for(i = 0; align <= (addr+size); align += CPU_D_CACHE_LINE_SIZE) {
+		mvOsCacheLineInv(NULL, align);
+		mvOsCacheIoSync();
+	}
+}
+
+
+
+static inline void mvNfpSecBuildMac(MV_PKT_INFO *pPktInfo, MV_NFP_SEC_SA_ENTRY* pSAEntry)
+{
+        MV_802_3_HEADER *pMacHdr;
+
+        pMacHdr = (MV_802_3_HEADER*)((MV_U8 *)(pPktInfo->pFrags[0].bufVirtPtr));
+        memcpy(pMacHdr, &pSAEntry->tunnelHdr.dstMac, 12);
+        pMacHdr->typeOrLen = 0x08;  /* stands for IP protocol code 16bit swapped */          
+	return;	
+}
+
+static void inline 
+nfp_sec_complete_out(unsigned long data) 
+{
+	MV_NFP_SEC_CESA_PRIV *nfp_sec_cesa_priv = (MV_NFP_SEC_CESA_PRIV *)data;
+	MV_U32            if_out,if_type,if_ppp;
+	MV_PKT_INFO       *pPktInfo;
+	MV_BUF_INFO       *pBuf;
+	mv_eth_priv       *out_priv;
+	struct net_device *out_dev;
+	int txq = ETH_DEF_TXQ;
+	MV_STATUS status;
+
+	if_ppp = 0;
+	if_out = nfp_sec_cesa_priv->pSaEntry->tunnelHdr.outIfIndex;
+	if_type = fp_mgr_get_if_type(if_out);
+
+#ifdef CONFIG_MV_ETH_NFP_PPP
+	if (if_type == MV_FP_IF_PPP)
+	{
+		if_ppp = if_out;
+		if_out = mvFpPppPhyIf(if_ppp);
+		if_type = fp_mgr_get_if_type(if_out);
+	}
+#endif
+	if (if_type != MV_FP_IF_INT)
+	{
+		printk("%s: NFP Tx on ifindex=%d is not supported\n", __FUNCTION__, if_out);
+		nfp_sec_cesa_priv->pSaEntry->stats.dropped++;
+		nfp_sec_pkt_info_free(nfp_sec_cesa_priv->pPktInfo);
+		return;
+	}
+
+	out_dev = fp_mgr_get_net_dev(if_out);
+	out_priv = MV_ETH_PRIV(out_dev);
+
+	pPktInfo = nfp_sec_cesa_priv->pPktInfo;
+	pBuf = pPktInfo->pFrags;
+	pBuf->bufVirtPtr -= MV_NFP_SEC_ESP_OFFSET + ETH_MV_HEADER_SIZE;
+	pBuf->bufPhysAddr -= MV_NFP_SEC_ESP_OFFSET + ETH_MV_HEADER_SIZE;
+	pBuf->dataSize += MV_NFP_SEC_ESP_OFFSET + ETH_MV_HEADER_SIZE;
+	pBuf->bufAddrShift += MV_NFP_SEC_ESP_OFFSET + ETH_MV_HEADER_SIZE;
+
+#ifdef CONFIG_MV_ETH_NFP_PPP
+	/* PPPoE */
+	if (if_ppp)
+		mvFpPPPoE(if_ppp, pPktInfo, &out_priv->fpStats);
+#endif
+
+#if defined(CONFIG_MV_GATEWAY)
+	if(out_priv->isGtw)
+	{
+		struct mv_vlan_cfg* vlan_cfg = MV_NETDEV_VLAN(out_dev);
+		*(unsigned short *)(pBuf->bufVirtPtr) = vlan_cfg->header;
+		mvOsCacheLineFlushInv(NULL, pBuf->bufVirtPtr);
+		mvOsCacheIoSync();
+	}
+    else
+#endif
+	{
+		pBuf->bufPhysAddr += ETH_MV_HEADER_SIZE;
+		pBuf->dataSize -= ETH_MV_HEADER_SIZE;
+	}
+
+    spin_lock(out_priv->lock);
+	status = mvEthPortTx(out_priv->hal_priv, txq, pPktInfo);
+	spin_unlock(out_priv->lock);
+
+    if (status != MV_OK)
+    {
+		printk("%s: mvEthPortTx failed 0x%x\n", __FUNCTION__, status);
+#ifdef CONFIG_MV_GATEWAY
+		if(!out_priv->isGtw)
+			pBuf->bufPhysAddr -= ETH_MV_HEADER_SIZE;
+#else
+		pBuf->bufPhysAddr -= ETH_MV_HEADER_SIZE;
+#endif /* CONFIG_MV_GATEWAY */
+	
+		nfp_sec_pkt_info_free(pPktInfo);
+		out_dev->stats.tx_dropped++;
+		return;
+	}
+
+	nfp_sec_sent++;
+	out_priv->tx_count[txq]++;
+	out_dev->stats.tx_packets++;
+	out_dev->stats.tx_bytes += pBuf->dataSize;
+	ETH_STAT_DBG( out_priv->eth_stat.tx_hal_ok[txq]++);
+
+#if !defined(ETH_TX_DONE_ISR)
+  	if (nfp_sec_sent > 32)
+    {
+		nfp_sec_sent = 0;
+		eth_check_for_tx_done();
+    }
+#endif /* !ETH_TX_DONE_ISR */
+}
+
+static void inline 
+nfp_sec_complete_in(unsigned long data) 
+{
+	MV_NFP_SEC_CESA_PRIV * nfp_sec_cesa_priv = (MV_NFP_SEC_CESA_PRIV *)data;
+	MV_U8 if_out, proto = 0, *pNewDigest;
+	MV_PKT_INFO *pPktInfo = nfp_sec_cesa_priv->pPktInfo;
+	MV_BUF_INFO *pBuf = pPktInfo->pFrags;
+	MV_NFP_SEC_SA_ENTRY* pSAEntry =  nfp_sec_cesa_priv->pSaEntry;
+	mv_eth_priv  *out_priv;
+	struct net_device *out_dev = NULL;
+	int txq = ETH_DEF_TXQ;
+	MV_STATUS status;
+	MV_U32 dip, sip, calc_digest_off, size;
+	MV_U16 sport = 0, dport = 0;
+	MV_IP_HEADER* pIpHdr;
+	MV_NFP_SEC_SPD_RULE *pSpd;
+
+	/* align pointers to MAC header */
+	size = sizeof(MV_ESP_HEADER) + pSAEntry->ivSize - sizeof(MV_802_3_HEADER);
+	pBuf->bufAddrShift -= size;
+	pBuf->bufVirtPtr += size;
+	pBuf->bufPhysAddr += size;
+	pBuf->dataSize -= (size + pSAEntry->digestSize);
+	calc_digest_off = pBuf->dataSize;
+
+	/* extract parameters for SPD match search */
+	pIpHdr = (MV_IP_HEADER*)(pBuf->bufVirtPtr + sizeof(MV_802_3_HEADER));
+#ifdef	MV_NFP_SEC_5TUPLE_KEY_SUPPORT 
+	proto = mvFpPortsGet(pIpHdr, &dport, &sport);
+#endif
+	dip = pIpHdr->dstIP;
+    sip = pIpHdr->srcIP;
+	
+	/* remove crypto padding */
+	pBuf->dataSize = sizeof(MV_802_3_HEADER) + MV_16BIT_BE(pIpHdr->totalLength);
+
+	/* check what to do with the packet according to SPD */
+	pSpd = mvNfpSecSPDRuleFind(dip, sip, proto, dport, sport, MV_NFP_SEC_RULE_DB_IN);
+	if(pSpd == NULL) {
+		printk("%s(%d): SPD rule not found\n", __FUNCTION__, __LINE__);
+		printk("dip(0x%x) sip(0x%x) proto(0x%x) dport(0x%x) sport(0x%x), dataSize(0x%x)\n",
+			dip, sip, proto, dport, sport, pBuf->dataSize);
+		pBuf->bufVirtPtr -= ETH_MV_HEADER_SIZE;
+		pBuf->bufPhysAddr -= ETH_MV_HEADER_SIZE;
+		pBuf->bufAddrShift += ETH_MV_HEADER_SIZE;
+		nfp_sec_pkt_info_free(pPktInfo);
+		return;
+	}
+
+	/* compare digest */
+	pNewDigest = pBuf->bufVirtPtr + calc_digest_off;
+	if(memcmp(nfp_sec_cesa_priv->orgDigest, pNewDigest, pSAEntry->digestSize)) {
+		printk("%s(%d): ERR. original digest is different from calculated digest(size=%d)\n", __FUNCTION__, __LINE__,calc_digest_off);
+		pBuf->bufVirtPtr -= ETH_MV_HEADER_SIZE;
+		pBuf->bufPhysAddr -= ETH_MV_HEADER_SIZE;
+		pBuf->bufAddrShift += ETH_MV_HEADER_SIZE;
+		nfp_sec_pkt_info_free(pPktInfo);
+		return;
+	}
+
+	/*
+	 * Hub and spoke vpn. Check 2nd tunnel
+	 */
+#ifdef CONFIG_MV_ETH_NFP_SEC_HUB
+	/* ipheader of the original packet */
+	pIpHdr = (MV_IP_HEADER*)(pBuf->bufVirtPtr + sizeof(MV_802_3_HEADER));
+	proto = mvFpPortsGet(pIpHdr, &dport, &sport);
+	sip = pIpHdr->srcIP;
+	dip = pIpHdr->dstIP;
+
+	/* check legitimacy for entring the 2nd tunnel */
+	pSpd = mvNfpSecSPDRuleFind(dip, sip, proto, dport, sport, MV_NFP_SEC_RULE_DB_OUT);
+	if (pSpd && pSpd->actionType == MV_NFP_SEC_SECURE)
+	{
+		pBuf->bufVirtPtr -= ETH_MV_HEADER_SIZE;
+		pBuf->bufPhysAddr -= ETH_MV_HEADER_SIZE;
+		pBuf->dataSize += ETH_MV_HEADER_SIZE;
+		pBuf->bufAddrShift += ETH_MV_HEADER_SIZE;
+
+		status = mvNfpSecOutgoing(pPktInfo, pSpd->pSAEntry);
+		if (status != MV_OK)
+		{
+			if (pSpd->pSAEntry)
+				pSpd->pSAEntry->stats.dropped++;
+			nfp_sec_pkt_info_free(pPktInfo);
+			mvOsPrintf("nfp_sec_complete_in: hub-in-spoke status=%x\n", status);
+		}
+
+		return;
+	}		
+#endif
+
+	/* build MAC header */	
+	mvNfpSecBuildMac(pPktInfo, pSAEntry);
+
+	/* flush & invalidate MAC,IP & TCP headers */ 
+	size = sizeof(MV_802_3_HEADER)+ sizeof(MV_IP_HEADER);
+#ifdef MV_NFP_SEC_5TUPLE_KEY_SUPPORT
+	size += sizeof(MV_TCP_HEADER);
+#endif
+
+	mvNfpSecClearRange(pBuf->bufVirtPtr, size);
+	mvNfpSecInvRange(pNewDigest, pSAEntry->digestSize);
+
+	if_out = pSAEntry->tunnelHdr.outIfIndex;
+	out_dev = fp_mgr_get_net_dev(if_out);
+
+	if(fp_mgr_get_if_type(if_out) != MV_FP_IF_INT)
+	{
+		printk("%s: NFP Tx on ifindex=%d is not supported\n", __FUNCTION__, if_out);
+		pSAEntry->stats.dropped++;
+		nfp_sec_pkt_info_free(pPktInfo);
+		return;
+	}
+
+	pBuf->bufVirtPtr -= ETH_MV_HEADER_SIZE;
+	pBuf->bufPhysAddr -= ETH_MV_HEADER_SIZE;
+	pBuf->dataSize += ETH_MV_HEADER_SIZE;
+	pBuf->bufAddrShift += ETH_MV_HEADER_SIZE;
+
+	out_priv = MV_ETH_PRIV(out_dev);
+
+#if defined(CONFIG_MV_GATEWAY)
+	if(out_priv->isGtw)
+	{
+		struct mv_vlan_cfg* vlan_cfg = MV_NETDEV_VLAN(out_dev);
+		*(unsigned short *)(pBuf->bufVirtPtr) = vlan_cfg->header;
+		mvOsCacheLineFlushInv(NULL, pBuf->bufVirtPtr);
+		mvOsCacheIoSync();
+	}
+    else
+#endif
+	{
+		pBuf->bufPhysAddr += ETH_MV_HEADER_SIZE;
+		pBuf->dataSize -= ETH_MV_HEADER_SIZE;
+	}
+
+	spin_lock(out_priv->lock);
+	status = mvEthPortTx(out_priv->hal_priv, txq, pPktInfo);
+	spin_unlock(out_priv->lock);
+
+    if (status != MV_OK)
+    {
+
+		printk("%s: mvEthPortTx failed 0x%x\n", __FUNCTION__, status);
+#ifdef CONFIG_MV_GATEWAY
+        if(!out_priv->isGtw)
+			pBuf->bufPhysAddr -= ETH_MV_HEADER_SIZE;
+#else
+        	pBuf->bufPhysAddr -= ETH_MV_HEADER_SIZE;
+#endif /* CONFIG_MV_GATEWAY */
+
+		nfp_sec_pkt_info_free(pPktInfo);
+		out_dev->stats.tx_dropped++;
+		return;
+	}
+
+	nfp_sec_sent++;
+	out_priv->tx_count[txq]++;
+	out_dev->stats.tx_packets++;
+	out_dev->stats.tx_bytes += pBuf->dataSize;
+	ETH_STAT_DBG( out_priv->eth_stat.tx_hal_ok[txq]++);
+    
+#if !defined(ETH_TX_DONE_ISR)
+  	if (nfp_sec_sent > 32)
+	{
+		nfp_sec_sent = 0;
+		eth_check_for_tx_done();
+    }
+#endif /* !ETH_TX_DONE_ISR */
+}
+
+
+/*
+ * nfp sec callback. 
+ */
+void
+req_handler(unsigned long dummy)
+{
+	while(atomic_read(&req_count) != 0) {
+		if(req_array[req_ready]->pSaEntry->secOp == MV_NFP_SEC_ENCRYPT)
+			nfp_sec_complete_out((unsigned long)req_array[req_ready]);
+		else
+			nfp_sec_complete_in((unsigned long)req_array[req_ready]);
+		req_ready++;
+		if(req_ready == MV_NFP_SEC_REQ_Q_SIZE)
+			req_ready = 0;
+		
+		atomic_dec(&req_count);
+	}
+
+}
+
+/*
+ * nfp sec Interrupt handler routine.
+ */
+static irqreturn_t
+nfp_sec_interrupt_handler(int irq, void *arg)
+{
+	MV_CESA_RESULT  	result;
+	MV_STATUS               status;
+
+	/* clear interrupts */
+    	MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG, 0);
+#if defined(MV_CESA_CHAIN_MODE_SUPPORT)
+	while(1) {
+#endif
+	/* Get Ready requests */
+	status = mvCesaReadyGet(&result);
+	if(status != MV_OK)
+	{
+#if !defined(MV_CESA_CHAIN_MODE_SUPPORT)
+		printk("ERROR: Ready get return %d\n",status);
+		return IRQ_HANDLED;
+#else
+			break;
+#endif
+	}	
+
+	/* handle result */
+	// TBD - need to verify return code !!!
+	if(atomic_read(&req_count) > (MV_NFP_SEC_REQ_Q_SIZE - 4)){
+		// must take sure that no tx_done will happen on the same time.. 
+		// maybe should be moved to tasklet to handle.. 
+		MV_NFP_SEC_CESA_PRIV *req_priv = (MV_NFP_SEC_CESA_PRIV *)result.pReqPrv;
+		MV_PKT_INFO *pkt_info = req_priv->pPktInfo;
+		printk("Error: Q request is full - TBD test...\n");
+		pkt_info->pFrags->bufVirtPtr -= (MV_NFP_SEC_ESP_OFFSET + ETH_MV_HEADER_SIZE);
+		pkt_info->pFrags->bufPhysAddr -= (MV_NFP_SEC_ESP_OFFSET + ETH_MV_HEADER_SIZE);
+		nfp_sec_pkt_info_free(pkt_info);
+		return IRQ_HANDLED;
+	}
+	req_array[req_empty] = (MV_NFP_SEC_CESA_PRIV *)result.pReqPrv;
+	req_empty++;
+	if(req_empty == MV_NFP_SEC_REQ_Q_SIZE)
+		req_empty = 0;
+	atomic_inc(&req_count);
+#if defined(MV_CESA_CHAIN_MODE_SUPPORT)
+	}
+#endif
+	tasklet_schedule(&nfp_sec_tasklet);
+
+	return IRQ_HANDLED;
+}
+
+
+static int nfp_sec_add_rule(int dir, u32 spi, char* sa_mac, char* da_mac, 
+	u32 left_peer, u32 right_peer, int if_out, u32 left_sub, u32 right_sub)
+{
+	MV_NFP_SEC_SPD_RULE spd;
+	MV_NFP_SEC_SA_ENTRY sa;
+	MV_CESA_OPEN_SESSION os;
+	unsigned short 	digest_size = 0;
+	int i;
+	unsigned int iv_size;
+	unsigned char sha1Key[] = {0x12, 0x34, 0x56, 0x78, 0x9a, 0xbc, 0xde, 0xf0,
+                               0x24, 0x68, 0xac, 0xe0, 0x24, 0x68, 0xac, 0xe0,
+                               0x13, 0x57, 0x9b, 0xdf};
+	unsigned char cryptoKey[] = {0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef,
+                                 0x02, 0x46, 0x8a, 0xce, 0x13, 0x57, 0x9b, 0xdf};
+
+	memset(&spd, 0, sizeof(MV_NFP_SEC_SPD_RULE));
+	memset(&sa, 0, sizeof(MV_NFP_SEC_SA_ENTRY));
+	memset(&os, 0, sizeof(MV_CESA_OPEN_SESSION));
+
+   	os.cryptoAlgorithm = MV_CESA_CRYPTO_AES;
+	switch(os.cryptoAlgorithm)
+	{
+		case MV_CESA_CRYPTO_DES:
+			iv_size = MV_CESA_DES_BLOCK_SIZE;
+			break;
+		case MV_CESA_CRYPTO_3DES:
+			iv_size = MV_CESA_3DES_BLOCK_SIZE;
+			break;
+		
+		case MV_CESA_CRYPTO_AES:
+			iv_size = MV_CESA_AES_BLOCK_SIZE;
+			break;
+		default:
+			printk("Unknown crypto \n");
+
+	}
+   	os.macMode = MV_CESA_MAC_HMAC_SHA1;
+   	switch(os.macMode)
+   	{
+		case MV_CESA_MAC_MD5:
+		case MV_CESA_MAC_HMAC_MD5:
+			digest_size = MV_CESA_MD5_DIGEST_SIZE;
+			break;
+	
+		case MV_CESA_MAC_SHA1:
+		case MV_CESA_MAC_HMAC_SHA1:
+			digest_size = 12;//MV_CESA_SHA1_DIGEST_SIZE;
+			break;
+	
+		case MV_CESA_MAC_NULL:
+			digest_size = 0;
+			break;
+		}
+
+	os.cryptoMode = MV_CESA_CRYPTO_CBC;
+	if (dir == MV_NFP_SEC_RULE_DB_IN) {
+		os.direction = MV_CESA_DIR_DECODE;
+		os.operation = MV_CESA_MAC_THEN_CRYPTO;
+	}
+	else {
+		os.direction = MV_CESA_DIR_ENCODE;
+		os.operation = MV_CESA_CRYPTO_THEN_MAC;
+	}
+
+   	for(i=0; i<sizeof(cryptoKey); i++)
+       	os.cryptoKey[i] = cryptoKey[i];
+
+	os.cryptoKeyLength = sizeof(cryptoKey);
+
+	for(i=0; i<sizeof(sha1Key); i++)
+       		os.macKey[i] = sha1Key[i];
+
+	os.macKeyLength = sizeof(sha1Key);
+	os.digestSize = digest_size;
+
+	if (MV_OK != mvCesaSessionOpen(&os, (short*)&(sa.sid)))
+	{
+		printk("%s: open session failed\n", __FUNCTION__);
+	}
+
+	sa.digestSize = digest_size;
+	sa.ivSize = iv_size;
+	sa.spi = MV_32BIT_BE(spi);
+	sa.tunProt = MV_NFP_SEC_TUNNEL;
+	sa.encap = MV_NFP_SEC_ESP;
+	sa.seqNum = 0;
+	sa.tunnelHdr.sIp = left_peer;
+	sa.tunnelHdr.dIp = right_peer;
+	sa.tunnelHdr.outIfIndex = if_out;
+	sa.lifeTime = 0; 
+
+	if (dir == MV_NFP_SEC_RULE_DB_IN) 
+		sa.secOp = MV_NFP_SEC_DECRYPT;
+	else
+		sa.secOp = MV_NFP_SEC_ENCRYPT;
+
+	for(i=0; i<6; i++)
+	{
+		sa.tunnelHdr.dstMac[i] = da_mac[i];
+		sa.tunnelHdr.srcMac[i] = sa_mac[i];
+	}
+
+	spd.pSAEntry = mvNfpSecSAEntrySet(&sa, dir);	
+	printk("pSAEntry=%p\n",spd.pSAEntry);
+	if (!spd.pSAEntry)
+		printk("%s: SA creation failed \n", __FUNCTION__);
+
+	spd.sIp = left_sub;
+	spd.dIp = right_sub;
+
+#ifdef	MV_NFP_SEC_5TUPLE_KEY_SUPPORT 
+	spd.dstPort = 0x2;       	// dport: 512
+	spd.srcPort = 0x3;      	// sport: 768
+	spd.proto = MV_IP_PROTO_TCP;
+#endif
+	spd.actionType = MV_NFP_SEC_SECURE;
+
+	if (!mvNfpSecSPDRuleSet(&spd, dir))
+		printk("%s: SPD creation failed \n", __FUNCTION__);
+        
+	return 0;
+}
+
+static void nfp_sec_init_rule(void)
+{
+	unsigned char 	sa_wan[] = {0, 0, 0, 0, 0x61, 0x92};
+	unsigned char 	sa_lan[] = {0, 0, 0, 0, 0x61, 0x93};
+	unsigned char 	da_peer_wan[] = {0x0,0x13,0x20,0x8b,0xbc,0x49};
+	unsigned char 	da_host_lan[] = {0x0,0x15,0x58,0x2F,0xF0,0x39};
+	unsigned char 	da_peer_lan[] = {0x0,0x62,0x81,0x00,0x39,0x01};
+	unsigned char 	null_mac[] = {0, 0, 0, 0, 0, 0};
+
+#if 1
+	/* eth0 */
+	nfp_sec_add_rule(MV_NFP_SEC_RULE_DB_OUT, 0x65060000, sa_wan, da_peer_wan,
+					0x0101a8c0, /* left/sip 192.168.1.1 */
+					0x25d2050A, /* right/dip 10.5.210.37 */
+					1,          /* egress ifindex 1=eth0, 4=ppp0 */
+					0x0a010101,	/* left sub */
+					0x0a020202);/* right sub */
+#else
+	/* ppp0 */
+	nfp_sec_add_rule(MV_NFP_SEC_RULE_DB_OUT, 0x65060000, sa_wan, da_peer_wan,
+					0x05000028, /* left/sip 40.0.0.5  use ppp0 */
+					0x25d2050A, /* right/dip 10.5.210.37 */
+					4,          /* egress ifindex 1=eth0, 4=ppp0 */
+					0x0a010101,	/* left sub */
+					0x0a020202);/* right sub */
+#endif
+
+#if 1
+	/* eth0 */
+	nfp_sec_add_rule(MV_NFP_SEC_RULE_DB_IN, 0x65060000, sa_lan, da_host_lan,  
+					0x25d2050A, /* left/sip 10.5.210.37 */
+					0x0101a8c0, /* right/dip 192.168.1.1 */
+					2,          /* egress ifindex 2=eth1 */
+					0x0a020202,	/* left sub */
+					0x0a010101);/* right sub */
+#else
+	/* ppp0 */
+	nfp_sec_add_rule(MV_NFP_SEC_RULE_DB_IN, 0x65060000, sa_lan, da_host_lan,  
+					0x25d2050A, /* left/sip 10.5.210.37 */
+					0x05000028, /* right/dip 40.0.0.5 */
+					2,          /* egress ifindex 2=eth1 */
+					0x0a020202,	/* left sub */
+					0x0a010101);/* right sub */
+#endif
+
+#ifdef CONFIG_MV_ETH_NFP_SEC_HUB
+	/* dummy, will be rerouted to 2nd tunnel on LAN */
+	nfp_sec_add_rule(MV_NFP_SEC_RULE_DB_IN, 0x77070000, null_mac, null_mac,
+					0x6402a8c0, /* sip/remote/peer */
+					0x0102a8c0, /* dip/local/me */
+					4,          /* egress ifindex */
+					0x0a010101,	/* left sub */
+					0x0a020202);/* right sub */
+
+	/* 2nd tunnel on LAN */
+	nfp_sec_add_rule(MV_NFP_SEC_RULE_DB_OUT, 0x77070000, sa_lan, da_peer_lan,  
+					0x0102a8c0, /* left/sip/me 192.168.2.1 */
+					0x6402a8c0, /* right/dip/peer 192.168.2.100 */
+					2,          /* egress ifindex */
+					0x0a020202,	/* left sub */
+					0x0a010101);/* right sub */
+#endif
+}
+
+static int nfp_sec_init(void)
+{
+	spin_lock_init( &nfp_sec_lock );
+	if( MV_OK != mvCesaInit(MV_NFP_SEC_MAX_SES, MV_NFP_SEC_Q_SIZE, (char *)mv_crypto_base_get(),
+				NULL) ) {
+            	printk("%s,%d: mvCesaInit Failed. \n", __FILE__, __LINE__);
+		return EINVAL;
+	}
+	/* clear and unmask Int */
+	MV_REG_WRITE( MV_CESA_ISR_CAUSE_REG, 0);
+	MV_REG_WRITE( MV_CESA_ISR_MASK_REG, MV_CESA_CAUSE_ACC_DMA_MASK);
+
+	tasklet_init(&nfp_sec_tasklet, req_handler, (unsigned long) 0);
+	/* register interrupt */
+	if( request_irq( CESA_IRQ, nfp_sec_interrupt_handler,
+                             (IRQF_DISABLED) , "cesa", NULL) < 0) {
+            	printk("%s,%d: cannot assign irq %x\n", __FILE__, __LINE__, CESA_IRQ);
+		return EINVAL;
+        }
+
+	mvNfpSecInit(10);
+
+	/* add rules manually */
+	nfp_sec_init_rule();
+    
+	/* use for debug */
+	/* mvNfpSecDbPrint(); */ 
+
+	/* init waitqueue */
+	init_waitqueue_head(&nfp_sec_waitq);
+	
+	atomic_set(&req_count, 0);
+
+	return 0;
+}
+
+
+module_init(nfp_sec_init);
+
+MODULE_LICENSE("Marvell/GPL");
+MODULE_AUTHOR("Ronen Shitrit\Eran Ben Avi");
+MODULE_DESCRIPTION("NFP SEC for CESA crypto");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/Kconfig
new file mode 100644
index 0000000..7710d8b
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/Kconfig
@@ -0,0 +1,93 @@
+menu "Telephony options"
+	depends on MV_INCLUDE_TDM
+
+config  MV_PHONE
+	bool "Support for Marvell telephony(VoIP)"
+	depends on MV_INCLUDE_TDM && PHONE
+	default m
+	---help---
+	  Choosing this option enables the Marvell telephony underlying 
+	  support for various VoIP applications. 
+	  Note, kernel Telephony subsystem must be chosen too.
+
+choice 
+	prompt "TDM unit"
+	depends on MV_PHONE
+
+config MV_TDM_SUPPORT
+	bool "Support legacy TDM(2 channels)"
+
+config MV_COMM_UNIT_SUPPORT
+	depends on ARCH_FEROCEON_KW2
+	bool "Support CommUnit(up to 32 channels)"
+
+endchoice
+
+choice 
+	prompt "SLIC vendor"
+	depends on MV_PHONE
+
+config SILABS_SLIC_SUPPORT
+	bool "Support Silicon Labs devices"
+
+config ZARLINK_SLIC_SUPPORT
+	bool "Support Zarlink/Legirity devices"
+
+endchoice
+
+choice 
+	prompt "SLIC type"
+	depends on MV_PHONE && SILABS_SLIC_SUPPORT
+
+config SILABS_SLIC_3215
+	bool "Support Silicon Labs 3215 device"
+
+config SILABS_SLIC_3217
+	bool "Support Silicon Labs 3217 device"
+
+endchoice
+
+choice 
+	prompt "SLIC type"
+	depends on MV_PHONE && ZARLINK_SLIC_SUPPORT
+
+config ZARLINK_SLIC_VE880
+	bool "Support Zarlink VE880 SLIC family"
+
+config ZARLINK_SLIC_VE792
+	bool "Support Zarlink VE792 SLIC family"
+
+endchoice
+
+
+config MV_TDM_USE_EXTERNAL_PCLK_SOURCE
+	bool "Support PCLK from external source"
+	depends on MV_PHONE
+	default n
+	---help---
+	Choosing this option enables TDM unit to use PCLK supplied by external source.
+
+config TDM_DEV_TEST_SUPPORT
+	bool "Support tdm testing"
+	depends on MV_INCLUDE_TDM
+	help
+	   The tdm testing device supports several basic telephony tests on Marvell TDM based platforms.
+
+config MV_PHONE_USE_SLIC_LIBS
+	bool "Use binary slic drivers"
+	default y
+	---help---
+	Unselect this option only if you have source code of slic drivers.
+	If unsure, say "y"
+
+config MV_COMM_UNIT_FSYNC_STRB_SUPPORT
+	bool "Use CommUnit strobe pin as frame sync source"
+	default y
+	depends on MV_COMM_UNIT_SUPPORT
+	help
+	  The CommUnit frame sync 1/2/3 bit delay feature is not working in Z1 silicon revision, therefore
+	  the strobe pin can be used as tunable frame sync source.
+
+endmenu
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/Makefile
new file mode 100644
index 0000000..e268c90
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/Makefile
@@ -0,0 +1,111 @@
+#
+# Makefile for the Marvell Phone Device Driver
+#
+
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+VB_SRC_PATH = ../../mv_hal/voiceband
+
+obj-$(CONFIG_MV_TDM) += mv_phone.o
+
+ifeq ($(CONFIG_MV_TDM_SUPPORT),y)
+	PHONE_OBJS = $(VB_SRC_PATH)/tdm/mvTdm.o $(VB_SRC_PATH)/tdm/mvTdmAddrDec.o
+else # CONFIG_MV_COMM_UNIT_SUPPORT
+	PHONE_OBJS = $(VB_SRC_PATH)/commUnit/mvCommUnit.o $(VB_SRC_PATH)/commUnit/mvCommUnitAddrDec.o
+endif
+
+PHONE_OBJS += tdm_if.o tal.o ../../../../../$(MACHINE)/mv_hal_if/mvSysTdm.o
+
+EXTRA_CFLAGS += -DMV_KERNEL_SLIC_SUPPORT
+
+# Silabs support
+ifeq ($(CONFIG_SILABS_SLIC_SUPPORT),y)
+
+	SILABS_BASE_PATH = $(VB_SRC_PATH)/slic/silabs/
+	SILABS_SRC_PATH = $(SILABS_BASE_PATH)/src
+	SILABS_CUSTOM_PATH = $(SILABS_BASE_PATH)/custom
+	EXTRA_CFLAGS += -I$(srctree)/$(MACHINE)/../plat-feroceon/mv_hal/voiceband/slic/silabs/inc \
+			-I$(srctree)/$(MACHINE)/../plat-feroceon/mv_hal/voiceband/slic/silabs/custom
+
+
+SILABS_OBJS = $(SILABS_SRC_PATH)/proslic.o $(SILABS_SRC_PATH)/proslic_version.o
+
+ifeq ($(CONFIG_SILABS_SLIC_3215),y)
+	SILABS_OBJS += $(SILABS_CUSTOM_PATH)/si321x_constants.o $(SILABS_SRC_PATH)/si321x_intf.o
+endif
+
+ifeq ($(CONFIG_SILABS_SLIC_3217),y)
+	SILABS_OBJS += $(SILABS_SRC_PATH)/si3217x_intf.o $(SILABS_CUSTOM_PATH)/si3217x_patch_B_BB_2009MAY22.o \
+		       $(SILABS_CUSTOM_PATH)/si3217x_BKBT_constants.o  #$(SILABS_CUSTOM_PATH)/si3217x_FLBK_constants.o
+endif
+
+endif
+
+# Zarlink support
+ifeq ($(CONFIG_ZARLINK_SLIC_SUPPORT),y)
+
+ifeq ($(CONFIG_ZARLINK_SLIC_VE880),y)
+	ZARLINK_BASE_PATH = $(VB_SRC_PATH)/slic/zarlink/api_lib
+	ZARLINK_COMMON_SRC_PATH = $(ZARLINK_BASE_PATH)/common
+	ZARLINK_ARCH_MARVELL_PATH = $(VB_SRC_PATH)/slic/zarlink/arch_marvell
+	ZARLINK_VP880API_SRC_PATH = $(ZARLINK_BASE_PATH)/vp880_api
+
+	EXTRA_CFLAGS += -I$(srctree)/$(MACHINE)/../plat-feroceon/mv_hal/voiceband/slic/zarlink/api_lib/includes \
+			-I$(srctree)/$(MACHINE)/../plat-feroceon/mv_hal/voiceband/slic/zarlink/arch_marvell \
+			-I$(srctree)/$(MACHINE)/../plat-feroceon/mv_hal/voiceband/slic/zarlink/api_lib/vp880_api
+
+	ZARLINK_OBJS =  $(ZARLINK_COMMON_SRC_PATH)/vp_api.o  $(ZARLINK_COMMON_SRC_PATH)/vp_api_common.o \
+			$(ZARLINK_COMMON_SRC_PATH)/vp_api_cslac_seq.o $(ZARLINK_COMMON_SRC_PATH)/vp_debug.o \
+			$(ZARLINK_ARCH_MARVELL_PATH)/sys_service.o $(ZARLINK_ARCH_MARVELL_PATH)/vp_hal.o \
+			$(ZARLINK_VP880API_SRC_PATH)/apiCal.o $(ZARLINK_VP880API_SRC_PATH)/apicnt.o \
+			$(ZARLINK_VP880API_SRC_PATH)/apiInit.o $(ZARLINK_VP880API_SRC_PATH)/apiquery.o \
+			$(ZARLINK_VP880API_SRC_PATH)/apiseq.o
+	
+	SLIC_LIB_NAME=zarlink_880.lib
+endif
+
+ifeq ($(CONFIG_ZARLINK_SLIC_VE792),y)
+
+	ZARLINK_BASE_PATH = $(VB_SRC_PATH)/slic/zarlink/vp792_api_lib
+	ZARLINK_COMMON_SRC_PATH = $(ZARLINK_BASE_PATH)/common
+	ZARLINK_ARCH_MARVELL_PATH = $(VB_SRC_PATH)/slic/zarlink/arch_marvell
+	ZARLINK_VP792API_SRC_PATH = $(ZARLINK_BASE_PATH)/vp792_api
+
+	EXTRA_CFLAGS += -I$(srctree)/$(MACHINE)/../plat-feroceon/mv_hal/voiceband/slic/zarlink/vp792_api_lib/includes \
+			-I$(srctree)/$(MACHINE)/../plat-feroceon/mv_hal/voiceband/slic/zarlink/arch_marvell \
+			-I$(srctree)/$(MACHINE)/../plat-feroceon/mv_hal/voiceband/slic/zarlink/vp792_api_lib/vp792_api
+
+	ZARLINK_OBJS =  $(ZARLINK_COMMON_SRC_PATH)/vp_api_config.o  $(ZARLINK_COMMON_SRC_PATH)/vp_api_common.o \
+			$(ZARLINK_COMMON_SRC_PATH)/vp_api_init.o  $(ZARLINK_COMMON_SRC_PATH)/vp_api_query.o \
+			$(ZARLINK_COMMON_SRC_PATH)/vp_api_control.o $(ZARLINK_COMMON_SRC_PATH)/vp_debug.o \
+			$(ZARLINK_ARCH_MARVELL_PATH)/sys_service.o $(ZARLINK_ARCH_MARVELL_PATH)/vp_hal.o \
+			$(ZARLINK_VP792API_SRC_PATH)/vp792_common.o $(ZARLINK_VP792API_SRC_PATH)/vp792_config.o \
+			$(ZARLINK_VP792API_SRC_PATH)/vp792_control.o $(ZARLINK_VP792API_SRC_PATH)/vp792_init.o \
+			$(ZARLINK_VP792API_SRC_PATH)/vp792_query.o $(ZARLINK_VP792API_SRC_PATH)/vp792_firmware.o \
+			$(ZARLINK_ARCH_MARVELL_PATH)/Le71HP0410G_init.o
+			
+	SLIC_LIB_NAME=zarlink_792.lib
+
+endif
+
+PHONE_OBJS += vpapi_dev.o
+
+endif
+
+ifeq ($(CONFIG_MV_PHONE_USE_SLIC_LIBS),y)
+$(obj)/lib.a:
+	cp $(obj)/libs/$(SLIC_LIB_NAME) $(obj)/lib.a
+else
+	lib-$(CONFIG_ZARLINK_SLIC_SUPPORT) := $(ZARLINK_OBJS) $(SILABS_OBJS)
+endif
+
+obj-y := mv_phone.o test/
+
+mv_phone-objs := $(PHONE_OBJS) lib.a
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tal.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tal.c
new file mode 100644
index 0000000..d88c4b7
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tal.c
@@ -0,0 +1,157 @@
+
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************/
+
+/* Marvell Telephony Adaptation Layer */
+
+#include "tal.h"
+#include "tdm_if.h"
+
+/* GLobals */
+static tdm_if_register_ops_t tal_tdm_if_register_ops;
+static tal_mmp_ops_t* tal_mmp_ops;
+static tdm_if_params_t tal_tdm_if_params;
+ 
+/* Static APIs */
+static void tal_pcm_tx_callback(uint8_t* tx_buff, int size);
+static void tal_pcm_rx_callback(uint8_t* rx_buff, int size);
+
+/*---------------------------------------------------------------------------*
+ * tal_init
+ * Issue telephony subsytem initialization and callbacks registration
+ *---------------------------------------------------------------------------*/
+tal_stat_t tal_init(tal_params_t* tal_params, tal_mmp_ops_t* mmp_ops)
+{
+	if((tal_params == NULL) || (mmp_ops == NULL))
+	{
+		mvOsPrintf("%s: Error, bad parameters\n",__FUNCTION__);
+		return TAL_STAT_BAD_PARAM;
+	}
+
+	if(mmp_ops->tal_mmp_rx_callback == NULL ||
+	   mmp_ops->tal_mmp_tx_callback == NULL) 
+	{
+		mvOsPrintf("%s:Error, missing callbacks(MMP)\n",__FUNCTION__);
+		return TAL_STAT_BAD_PARAM;
+	}
+
+	/* Convert tal_params to tdm_if_params */
+	memcpy(&tal_tdm_if_params, tal_params, sizeof(tal_params_t));
+
+	/* Assign MMP operations */
+	tal_mmp_ops = mmp_ops;
+
+	/* Clear tdm_if operations structure */
+	memset(&tal_tdm_if_register_ops, 0, sizeof(tdm_if_register_ops_t));
+	
+	/* Assign tdm_if operations */
+	tal_tdm_if_register_ops.tdm_if_pcm_ops.pcm_tx_callback = tal_pcm_tx_callback;
+	tal_tdm_if_register_ops.tdm_if_pcm_ops.pcm_rx_callback = tal_pcm_rx_callback;
+
+	/* Dispatch tdm_if driver */
+	if(tdm_if_init(&tal_tdm_if_register_ops, &tal_tdm_if_params) != MV_OK)
+	{
+		mvOsPrintf("%s: Error, could not initialize tdm_if driver !!!\n",__FUNCTION__);
+		return TAL_STAT_INIT_ERROR;
+	}
+
+	/* Verify control callbacks were assigned properly */
+	if(tal_tdm_if_register_ops.tdm_if_ctl_ops.ctl_pcm_start == NULL ||
+	   tal_tdm_if_register_ops.tdm_if_ctl_ops.ctl_pcm_stop == NULL)
+	{
+		mvOsPrintf("%s:Error, missing callbacks(tdm_if)\n",__FUNCTION__);
+		return TAL_STAT_BAD_PARAM;
+	}
+
+	return TAL_STAT_OK;
+}
+
+
+/*---------------------------------------------------------------------------*
+ * tal_pcm_tx_completion
+ * Tx callback
+ *---------------------------------------------------------------------------*/
+
+static void tal_pcm_tx_callback(uint8_t* tx_buff, int size)
+{
+	tal_mmp_ops->tal_mmp_tx_callback(tx_buff, size);
+}
+
+/*---------------------------------------------------------------------------*
+ * tal_pcm_rx_completion
+ * Rx callback
+ *---------------------------------------------------------------------------*/
+
+static void tal_pcm_rx_callback(uint8_t* rx_buff, int size)
+{
+	tal_mmp_ops->tal_mmp_rx_callback(rx_buff, size);
+}
+
+/*---------------------------------------------------------------------------*
+ * tal_pcm_start
+ * Start PCM bus
+ *---------------------------------------------------------------------------*/
+tal_stat_t tal_pcm_start(void)
+{
+	tal_tdm_if_register_ops.tdm_if_ctl_ops.ctl_pcm_start();
+	return TAL_STAT_OK;
+}
+
+/*---------------------------------------------------------------------------*
+ * tal_pcm_stop
+ * Stop PCM bus
+ *---------------------------------------------------------------------------*/
+tal_stat_t tal_pcm_stop(void)
+{
+	tal_tdm_if_register_ops.tdm_if_ctl_ops.ctl_pcm_stop();
+	return TAL_STAT_OK;
+}
+
+/*---------------------------------------------------------------------------*
+ * tal_exit
+ * Stop TDM channels and release all resources
+ *---------------------------------------------------------------------------*/
+tal_stat_t tal_exit(void)
+{
+	tdm_if_exit();
+	return TAL_STAT_OK;
+}
+
+/*---------------------------------------------------------------------------*
+ * tal_stats_get
+ * Get TDM statistics
+ *---------------------------------------------------------------------------*/
+tal_stat_t tal_stats_get(tal_stats_t* tal_stats)
+{
+	tdm_if_stats_t stats;
+
+	tdm_if_stats_get(&stats);
+	memcpy(&stats, tal_stats, sizeof(tal_stats_t));
+
+	return TAL_STAT_OK;
+}
+
+
+
+/* EXPORTS */
+EXPORT_SYMBOL(tal_init);
+EXPORT_SYMBOL(tal_pcm_start);
+EXPORT_SYMBOL(tal_pcm_stop);
+EXPORT_SYMBOL(tal_exit);
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tal.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tal.h
new file mode 100644
index 0000000..ea8a112
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tal.h
@@ -0,0 +1,70 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************/
+
+/* Marvell Telephony Adaptation Layer */
+
+#ifndef _TAL_H_
+#define _TAL_H_
+
+#include "mvOs.h" /* for kernel abstraction wrappers */
+
+/* Defines */
+#define TAL_MAX_PHONE_LINES	32
+
+/* Enumerators */
+typedef enum {
+	TAL_PCM_FORMAT_1BYTE = 1,
+	TAL_PCM_FORMAT_2BYTES = 2,
+	TAL_PCM_FORMAT_4BYTES = 4
+} tal_pcm_format_t;
+
+typedef enum {
+	TAL_STAT_OK = 0,
+	TAL_STAT_BAD_PARAM,
+	TAL_STAT_INIT_ERROR
+} tal_stat_t;
+
+/* Structures */
+typedef struct {
+	tal_pcm_format_t pcm_format;
+	unsigned short pcm_slot[TAL_MAX_PHONE_LINES];
+	unsigned char sampling_period;
+	unsigned short total_lines;
+} tal_params_t;
+
+typedef struct {
+	int tdm_init;
+	unsigned int rx_overrun;
+	unsigned int tx_underrun;
+} tal_stats_t;
+
+typedef struct {
+	void (*tal_mmp_rx_callback)(unsigned char* rx_buff, int size);
+	void (*tal_mmp_tx_callback)(unsigned char* tx_buff, int size);
+} tal_mmp_ops_t;
+
+/* APIs */
+tal_stat_t tal_init(tal_params_t* tal_params, tal_mmp_ops_t* mmp_ops);
+tal_stat_t tal_stats_get(tal_stats_t* tal_stats);
+tal_stat_t tal_pcm_start(void);
+tal_stat_t tal_pcm_stop(void);
+tal_stat_t tal_exit(void);
+
+#endif /* _TAL_H */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tdm_if.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tdm_if.c
new file mode 100644
index 0000000..617041f
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tdm_if.c
@@ -0,0 +1,451 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File under the following licensing terms. 
+Redistribution and use in source and binary forms, with or without modification, 
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer. 
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution. 
+
+    *   Neither the name of Marvell nor the names of its contributors may be 
+        used to endorse or promote products derived from this software without 
+        specific prior written permission. 
+    
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND 
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE 
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR 
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES 
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; 
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON 
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT 
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS 
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+******************************************************************************/
+
+#include "tdm_if.h"
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/proc_fs.h>
+#ifndef CONFIG_MV_TDM_SUPPORT
+#include "gpp/mvGppRegs.h"
+#endif
+
+
+/* TDM Interrupt Service Routine */
+static irqreturn_t tdm_if_isr(int irq, void* dev_id);
+
+/* PCM start/stop */
+static void tdm_if_pcm_start(void);
+static void tdm_if_pcm_stop(void);
+
+/* Rx/Tx Tasklets  */
+static void tdm_if_pcm_rx_process(unsigned long arg);
+static void tdm_if_pcm_tx_process(unsigned long arg);
+
+/* TDM proc-fs statistics */
+static int proc_tdm_init_read(char *buffer, char **buffer_location, off_t offset,
+                            int buffer_length, int *zero, void *ptr);
+static int proc_rx_miss_read(char *buffer, char **buffer_location, off_t offset,
+                            int buffer_length, int *zero, void *ptr);
+static int proc_tx_miss_read(char *buffer, char **buffer_location, off_t offset,
+                            int buffer_length, int *zero, void *ptr);
+
+/* Module */
+static int __init tdm_if_module_init(void);
+static void __exit tdm_if_module_exit(void);
+
+/* Globals */
+static tdm_if_register_ops_t* tdm_if_register_ops;
+static DECLARE_TASKLET(tdm_if_rx_tasklet, tdm_if_pcm_rx_process, 0);
+static DECLARE_TASKLET(tdm_if_tx_tasklet, tdm_if_pcm_tx_process, 0);
+static DEFINE_SPINLOCK(tdm_if_lock);
+static unsigned char *rxBuff = NULL, *txBuff = NULL;
+static char irqnr;
+static unsigned int rx_miss = 0, tx_miss = 0;
+static struct proc_dir_entry *tdm_stats;
+static int pcm_enable = 0;
+static int irq_init = 0;
+static int tdm_init = 0;
+static int buff_size = 0;
+
+static int proc_tdm_init_read(char *buffer, char **buffer_location, off_t offset,
+                            int buffer_length, int *zero, void *ptr)
+{
+	return sprintf(buffer, "%u\n", tdm_init);
+}
+
+static int proc_rx_miss_read(char *buffer, char **buffer_location, off_t offset,
+                            int buffer_length, int *zero, void *ptr)
+{
+	return sprintf(buffer, "%u\n", rx_miss);
+}
+
+static int proc_tx_miss_read(char *buffer, char **buffer_location, off_t offset,
+                            int buffer_length, int *zero, void *ptr)
+{
+	return sprintf(buffer, "%u\n", tx_miss);
+}
+
+MV_STATUS tdm_if_init(tdm_if_register_ops_t* register_ops, tdm_if_params_t* tdm_if_params)
+{
+	MV_TDM_PARAMS tdm_params;
+	
+	printk("Loading Marvell Telephony Driver:\n");
+
+	if (MV_FALSE == mvCtrlPwrClckGet(mvCtrlTdmUnitTypeGet(), 0)) {
+		printk("%s: Warning, TDM is powered off\n",__FUNCTION__);
+		return MV_OK;
+	}
+
+	if((register_ops == NULL) || (tdm_if_params == NULL)) {
+		printk("%s: bad parameters\n",__FUNCTION__);
+		return MV_ERROR;
+
+	}
+
+	/* Check callbacks */
+	if(register_ops->tdm_if_pcm_ops.pcm_tx_callback == NULL ||
+	   register_ops->tdm_if_pcm_ops.pcm_rx_callback == NULL ) {
+		printk("%s: missing parameters\n",__FUNCTION__);
+		return MV_ERROR;
+	}
+
+	/* Reset globals */
+	rxBuff = txBuff = NULL;
+	pcm_enable = 0;
+	irq_init = 0;
+	tdm_init = 0;
+	
+	/* Calculate Rx/Tx buffer size(use in callbacks) */
+	buff_size = (tdm_if_params->pcm_format * tdm_if_params->total_lines * 80 * 
+				(tdm_if_params->sampling_period/MV_TDM_BASE_SAMPLING_PERIOD));
+
+	/* Extract TDM irq number */
+	irqnr = mvCtrlTdmUnitIrqGet();
+
+	/* Start Marvell trace */
+	TRC_START(); 
+	TRC_INIT(NULL, NULL, 0, 0);
+	TRC_REC("->%s\n",__FUNCTION__);
+
+#if defined(CONFIG_ARCH_FEROCEON_KW)
+	/* Assign TDM MPPs  - TBD */
+    	mvBoardTdmMppSet(1);
+#endif
+	/* Assign TDM parameters */
+	memcpy(&tdm_params, tdm_if_params, sizeof(MV_TDM_PARAMS));
+
+	/* Assign control callbacks */
+	tdm_if_register_ops = register_ops;
+	tdm_if_register_ops->tdm_if_ctl_ops.ctl_pcm_start = tdm_if_pcm_start;
+	tdm_if_register_ops->tdm_if_ctl_ops.ctl_pcm_stop = tdm_if_pcm_stop;
+
+	/* TDM init */
+	if(mvSysTdmInit(&tdm_params) != MV_OK) {
+			printk("%s: Error, TDM initialization failed !!!\n",__FUNCTION__);
+			return MV_ERROR;
+	}
+	tdm_init = 1;
+	
+	/* Register TDM interrupt */
+	if (request_irq(irqnr, tdm_if_isr, IRQF_DISABLED, "tdm", NULL)) {
+		printk("%s: Failed to connect irq(%d)\n", __FUNCTION__, irqnr);
+		return MV_ERROR;
+	}
+	irq_init = 1;
+	
+	/* Create TDM statistics proc directory & entries */
+	tdm_stats = proc_mkdir("tdm", NULL);
+	create_proc_read_entry("tdm_init", 0, tdm_stats, proc_tdm_init_read, NULL);
+	create_proc_read_entry("rx_overrun", 0, tdm_stats, proc_rx_miss_read, NULL);
+	create_proc_read_entry("tx_underrun", 0, tdm_stats, proc_tx_miss_read, NULL);
+
+	printk("Marvell Telephony Driver Loaded Successfully\n");
+
+	TRC_REC("<-%s\n",__FUNCTION__);
+	return MV_OK;
+}
+
+
+void tdm_if_exit(void)
+{
+	/* Check if already stopped */
+	if(!irq_init && !pcm_enable && !tdm_init)
+		return;
+
+	TRC_REC("->%s\n",__FUNCTION__);
+
+	if(irq_init) {
+		/* Release IRQ */
+		free_irq(irqnr, NULL);
+		irq_init = 0;
+	}
+
+	/* Stop PCM data sampling */
+	if(pcm_enable)
+		tdm_if_pcm_stop();
+
+	if(tdm_init) {
+#ifdef CONFIG_MV_TDM_SUPPORT
+		mvTdmRelease();
+#else
+		mvCommUnitRelease();
+		mvOsDelay(1000);
+#endif
+		tdm_init = 0;
+	}
+		
+	/* Remove proc directory & entries */
+	remove_proc_entry("tdm_init", tdm_stats);
+	remove_proc_entry("rx_overrun", tdm_stats);
+	remove_proc_entry("tx_underrun", tdm_stats);
+	remove_proc_entry("tdm", NULL);
+
+	TRC_REC("<-%s\n",__FUNCTION__);
+
+	TRC_OUTPUT();
+	TRC_RELEASE();
+}
+
+static void tdm_if_pcm_start(void)
+{
+	unsigned long flags;
+
+	TRC_REC("->%s\n",__FUNCTION__);
+
+	spin_lock_irqsave(&tdm_if_lock, flags);
+	if(!pcm_enable) {
+		rxBuff = txBuff = NULL;
+		pcm_enable = 1;
+#ifdef CONFIG_MV_TDM_SUPPORT
+		mvTdmPcmStart();
+#else
+		mvCommUnitPcmStart();
+#endif
+	}
+	spin_unlock_irqrestore(&tdm_if_lock, flags);
+
+	TRC_REC("<-%s\n",__FUNCTION__);
+	return;
+}
+
+static void tdm_if_pcm_stop(void)
+{
+	unsigned long flags;
+
+	TRC_REC("->%s\n",__FUNCTION__);
+
+	spin_lock_irqsave(&tdm_if_lock, flags);
+	if(pcm_enable) {
+		pcm_enable = 0;
+		rxBuff = txBuff = NULL;
+#ifdef CONFIG_MV_TDM_SUPPORT
+		mvTdmPcmStop();
+#else
+		mvCommUnitPcmStop();
+#endif
+	}
+	spin_unlock_irqrestore(&tdm_if_lock, flags);
+
+	TRC_REC("<-%s\n",__FUNCTION__);
+	return;
+}
+
+static irqreturn_t tdm_if_isr(int irq, void* dev_id)
+{
+	MV_TDM_INT_INFO tdm_int_info;
+	unsigned int int_type;
+
+	TRC_REC("->%s\n",__FUNCTION__);
+
+	/* Extract interrupt information from low level ISR */
+#ifdef CONFIG_MV_TDM_SUPPORT
+	mvTdmIntLow(&tdm_int_info);
+#else
+	mvCommUnitIntLow(&tdm_int_info);
+#endif
+
+	int_type = tdm_int_info.intType;
+	/*device_id = tdm_int_info.cs;*/
+	
+	/* Nothing to do - return */
+	if(int_type == MV_EMPTY_INT)
+		goto out;
+
+	/* Support multiple interrupt handling */
+	/* RX interrupt */
+	if(int_type & MV_RX_INT) {
+		if(rxBuff != NULL) {
+			rx_miss++;
+			TRC_REC("%s: Warning, missed Rx buffer processing !!!\n",__FUNCTION__);
+		}
+		else {
+			rxBuff = tdm_int_info.tdmRxBuff;
+
+			/* Schedule Rx processing within SOFT_IRQ context */
+			TRC_REC("%s: schedule Rx tasklet\n", __FUNCTION__);
+			tasklet_hi_schedule(&tdm_if_rx_tasklet);
+		}
+	}
+
+	/* TX interrupt */
+	if(int_type & MV_TX_INT) {
+		if(txBuff != NULL) {
+			tx_miss++;
+			TRC_REC("%s: Warning, missed Tx buffer processing !!!\n",__FUNCTION__);
+		}
+		else {
+			txBuff = tdm_int_info.tdmTxBuff;
+
+			/* Schedule Tx processing within SOFT_IRQ context */
+			TRC_REC("%s: schedule Tx tasklet\n", __FUNCTION__);
+			tasklet_hi_schedule(&tdm_if_tx_tasklet);
+		}
+	}
+
+	/* PHONE interrupt */
+	if(int_type & MV_PHONE_INT) {
+		/* TBD */
+	}
+
+	/* ERROR interrupt */
+	if(int_type & MV_ERROR_INT) {
+		printk("%s: Error was generated by TDM HW !!!\n",__FUNCTION__);
+	}
+
+
+out:
+	TRC_REC("<-%s\n",__FUNCTION__);
+	return IRQ_HANDLED;
+}
+
+/* Rx tasklet */
+static void tdm_if_pcm_rx_process(unsigned long arg)
+{
+	TRC_REC("->%s\n",__FUNCTION__);
+	if(pcm_enable) {
+		if(rxBuff == NULL) {
+			TRC_REC("%s: Error, empty Rx processing\n",__FUNCTION__);
+			return;
+		}
+
+		/* Fill TDM Rx aggregated buffer */
+#ifdef CONFIG_MV_TDM_SUPPORT
+		if(mvTdmRx(rxBuff) == MV_OK)
+#else
+		if(mvCommUnitRx(rxBuff) == MV_OK)
+#endif
+			tdm_if_register_ops->tdm_if_pcm_ops.pcm_rx_callback(rxBuff, buff_size); /* Dispatch Rx handler */
+		else
+			printk("%s: could not fill Rx buffer\n",__FUNCTION__);
+
+	}
+	
+	/* Clear rxBuff for next iteration */
+	rxBuff = NULL;
+
+	TRC_REC("<-%s\n",__FUNCTION__);
+	return;
+}
+
+/* Tx tasklet */
+static void tdm_if_pcm_tx_process(unsigned long arg)
+{
+	TRC_REC("->%s\n",__FUNCTION__);
+
+	if(pcm_enable) {
+		if(txBuff == NULL) {
+			TRC_REC("%s: Error, empty Tx processing\n",__FUNCTION__);
+			return;
+		}
+
+		/* Dispatch Tx handler */
+		tdm_if_register_ops->tdm_if_pcm_ops.pcm_tx_callback(txBuff, buff_size);
+
+#ifndef CONFIG_TDM_DEV_TEST_SUPPORT
+		/* Fill Tx aggregated buffer */
+#ifdef CONFIG_MV_TDM_SUPPORT
+		if(mvTdmTx(txBuff) != MV_OK)
+#else
+		if(mvCommUnitTx(txBuff) != MV_OK)
+#endif /* CONFIG_MV_TDM_SUPPORT */
+			printk("%s: could not fill Tx buffer\n",__FUNCTION__);
+#endif /* CONFIG_TDM_DEV_TEST_SUPPORT */
+
+	}
+
+	/* Clear txBuff for next iteration */
+	txBuff = NULL;
+
+	TRC_REC("<-%s\n",__FUNCTION__);
+	return;
+}
+
+void tdm_if_stats_get(tdm_if_stats_t* tdm_if_stats)
+{
+	tdm_if_stats->tdm_init = tdm_init;
+	tdm_if_stats->rx_overrun = rx_miss;
+	tdm_if_stats->tx_underrun = tx_miss;
+	
+	return;
+}
+
+static int __init tdm_if_module_init(void)
+{
+	/* The real init is done later */
+	return 0;
+}
+
+static void __exit tdm_if_module_exit(void)
+{
+	tdm_if_exit();
+	return;
+}
+
+/* Module stuff */
+module_init(tdm_if_module_init);
+module_exit(tdm_if_module_exit);
+MODULE_DESCRIPTION("Marvell TDM I/F Device Driver - www.marvell.com");
+MODULE_AUTHOR("Eran Ben-Avi <benavi@marvell.com>");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tdm_if.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tdm_if.h
new file mode 100644
index 0000000..e924935
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/tdm_if.h
@@ -0,0 +1,116 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef _TDM_IF_H_
+#define _TDM_IF_H_
+
+#include "mvSysTdmApi.h"
+#ifdef CONFIG_MV_TDM_SUPPORT
+ #include "voiceband/tdm/mvTdm.h"
+#else
+ #include "voiceband/commUnit/mvCommUnit.h"
+#endif
+#include "ctrlEnv/mvCtrlEnvSpec.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "boardEnv/mvBoardEnvLib.h"
+
+
+/* Structures */
+typedef struct {
+	int tdm_init;
+	unsigned int rx_overrun;
+	unsigned int tx_underrun;
+} tdm_if_stats_t;
+
+typedef struct {
+	MV_PCM_FORMAT pcm_format;
+	unsigned short pcm_slot[32];
+	unsigned char sampling_period;
+	unsigned short total_lines;
+} tdm_if_params_t;
+
+/* control callbacks */
+typedef struct {
+	void (*ctl_pcm_start)(void);
+	void (*ctl_pcm_stop)(void);
+} tdm_if_ctl_ops_t;
+
+/* pcm callbacks */
+typedef struct {
+	void (*pcm_tx_callback)(unsigned char* tx_buff, int size);
+	void (*pcm_rx_callback)(unsigned char* rx_buff, int size);
+} tdm_if_pcm_ops_t;
+
+typedef struct {
+	tdm_if_ctl_ops_t tdm_if_ctl_ops;
+	tdm_if_pcm_ops_t tdm_if_pcm_ops;
+} tdm_if_register_ops_t;
+
+/* APIs */
+void tdm_if_stats_get(tdm_if_stats_t* tdm_if_stats);
+MV_STATUS tdm_if_init(tdm_if_register_ops_t* register_ops, tdm_if_params_t* tdm_if_params);
+void tdm_if_exit(void);
+
+#endif /*_TDM_IF_H_*/
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/test/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/test/Makefile
new file mode 100644
index 0000000..0e30359
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/test/Makefile
@@ -0,0 +1,12 @@
+
+
+#
+# Makefile for the Marvell Phone Device Driver Test Module
+#
+#
+
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+obj-$(CONFIG_TDM_DEV_TEST_SUPPORT) += tdm_dev.o
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/test/tdm_dev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/test/tdm_dev.c
new file mode 100644
index 0000000..b5d7fe3
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/test/tdm_dev.c
@@ -0,0 +1,367 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File under the following licensing terms. 
+Redistribution and use in source and binary forms, with or without modification, 
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer. 
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution. 
+
+    *   Neither the name of Marvell nor the names of its contributors may be 
+        used to endorse or promote products derived from this software without 
+        specific prior written permission. 
+    
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND 
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE 
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR 
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES 
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; 
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON 
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT 
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS 
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+******************************************************************************/
+
+#include "tdm_dev.h"
+#include "mv_phone/tal.h"
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/poll.h>
+#include <linux/miscdevice.h>
+#ifdef CONFIG_MV_TDM_SUPPORT
+ #include "voiceband/tdm/mvTdm.h"
+#else
+ #include "voiceband/commUnit/mvCommUnit.h"
+#endif
+
+#define TDM_DEV_NAME 	"tdm"
+#define DISABLE		0
+#define ENABLE		1
+
+/* GLobals */
+static DECLARE_WAIT_QUEUE_HEAD(tdm_dev_wait);
+static DEFINE_SPINLOCK(tdm_dev_lock);
+static tal_params_t tdm_dev_params;
+static tal_mmp_ops_t tdm_dev_ops;
+static atomic_t tdm_init, rx_ready, tx_ready;
+static unsigned char *rx_buff_p = NULL, *tx_buff_p = NULL;
+
+
+/* Forward declarations */
+static int tdm_dev_tdm_start(unsigned long arg);
+static ssize_t tdm_dev_read(struct file *file_p, char __user *buf, size_t size, loff_t * ppos);
+static ssize_t tdm_dev_write(struct file *file_p, const char __user *buf, size_t size, loff_t * ppos);
+static unsigned int tdm_dev_poll(struct file *file_p, poll_table *poll_table_p);
+static int tdm_dev_ioctl(struct inode *inode_p, struct file *file_p, unsigned int cmd, unsigned long arg);
+static int tdm_dev_open(struct inode *inode_p, struct file *file_p);
+static int tdm_dev_release(struct inode *inode_p, struct file *file_p);
+void tdm_dev_tx_callback(unsigned char* tx_buff, int size);
+void tdm_dev_rx_callback(unsigned char* rx_buff, int size);
+static int __init tdm_dev_init(void);
+static void __exit tdm_dev_exit(void);
+
+static struct file_operations tdm_dev_fops = {
+    owner:      THIS_MODULE,
+    llseek:     NULL,
+    read:       tdm_dev_read,
+    write:      tdm_dev_write,
+    poll:       tdm_dev_poll,
+    ioctl:      tdm_dev_ioctl,
+    open:       tdm_dev_open,
+    release:    tdm_dev_release,
+    fasync:     NULL
+};
+
+static struct miscdevice tdm_dev_misc_dev = {
+	.minor = TDMDEV_MINOR,
+	.name = TDM_DEV_NAME,
+	.fops = &tdm_dev_fops,
+};
+
+
+static int __init tdm_dev_init(void)
+{
+	int status;
+
+	printk("Loading Marvell tdm device\n");
+	status = misc_register(&tdm_dev_misc_dev);
+
+	/* Register tdm device */
+	if (status < 0) {
+		printk("Error, failed to load %s device(status %d)\n", TDM_DEV_NAME, status);
+		return status;
+	}
+
+	atomic_set(&tdm_init, DISABLE);
+
+	return 0;
+}
+
+static int tdm_dev_tdm_start(unsigned long arg)
+{
+	tdm_dev_params_t data;
+	int i;
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(tdm_dev_params_t))) {
+		printk("%s: copy_from_user failed\n", __FUNCTION__);
+		return -EFAULT;
+	}
+
+	/* Check parameters */
+	if((data.pcm_format != 1) && (data.pcm_format != 2) && (data.pcm_format != 4)) {
+		printk("%s: bad parameter(pcm_format=%u)\n", __FUNCTION__, data.pcm_format);
+		return -EFAULT;
+	}
+
+	if(data.total_lines > MV_TDM_TOTAL_CHANNELS) {
+		printk("%s: bad parameter(data.total_lines=%u)\n", __FUNCTION__, data.total_lines);
+		return -EFAULT;
+	}
+
+	tdm_dev_params.pcm_format = (tal_pcm_format_t)data.pcm_format;
+	/* Fill time slot table */
+	for(i = 0; i < data.total_lines; i++)
+		tdm_dev_params.pcm_slot[i] = (i * data.pcm_format);
+
+	tdm_dev_params.sampling_period = 10;
+	tdm_dev_params.total_lines = data.total_lines;
+
+	/* Assign Rx/Tx callbacks */
+	tdm_dev_ops.tal_mmp_rx_callback = tdm_dev_rx_callback;
+	tdm_dev_ops.tal_mmp_tx_callback = tdm_dev_tx_callback;
+
+	if(tal_init(&tdm_dev_params, &tdm_dev_ops) != MV_OK) {
+		printk("%s: Error, could not init tdm driver\n",__FUNCTION__);
+		return -EFAULT;
+	}
+
+	/* Prepare globals */
+	atomic_set(&tdm_init, ENABLE);
+	atomic_set(&rx_ready, DISABLE);
+	atomic_set(&tx_ready, DISABLE);
+	rx_buff_p = NULL;
+	tx_buff_p = NULL;
+
+	return 0;
+}
+
+static ssize_t tdm_dev_read(struct file *file_p, char __user *buf, size_t size, loff_t * ppos)
+{
+	TRC_REC("->%s\n",__FUNCTION__);
+
+	if(rx_buff_p != NULL) {
+		memcpy(buf, rx_buff_p, size);
+		rx_buff_p = NULL;
+		atomic_set(&rx_ready, DISABLE);
+	}
+	else
+		TRC_REC("%s: missed Rx buffer\n",__FUNCTION__);
+
+	TRC_REC("<-%s\n",__FUNCTION__);
+
+	return size;
+}
+
+static ssize_t tdm_dev_write(struct file *file_p, const char __user *buf, size_t size, loff_t * ppos)
+{
+	unsigned long flags = 0;
+	MV_STATUS status;
+
+	TRC_REC("->%s\n",__FUNCTION__);
+
+	if(tx_buff_p != NULL) {
+		memcpy(tx_buff_p, buf, size);
+		atomic_set(&tx_ready, DISABLE);
+		spin_lock_irqsave(&tdm_dev_lock, flags);
+#ifdef CONFIG_MV_TDM_SUPPORT
+		status = mvTdmTx(tx_buff_p);
+#else
+		status = mvCommUnitTx(tx_buff_p);
+#endif
+		spin_unlock_irqrestore(&tdm_dev_lock, flags);
+		tx_buff_p = NULL;
+		if(status != MV_OK)
+			printk("%s: could not fill Tx buffer\n",__FUNCTION__);
+	}
+	else
+		TRC_REC("%s: missed Tx buffer\n",__FUNCTION__);
+
+	TRC_REC("<-%s\n",__FUNCTION__);
+
+	return size;
+}
+
+static unsigned int tdm_dev_poll(struct file *file_p, poll_table *poll_table_p)
+{
+	int mask = 0;
+
+	TRC_REC("->%s\n",__FUNCTION__);
+
+	poll_wait(file_p, &tdm_dev_wait, poll_table_p);
+
+	if(atomic_read(&rx_ready)) {
+		mask |= POLLIN | POLLRDNORM;	/* readable */
+		TRC_REC("poll can read\n");
+	}
+
+	if(atomic_read(&tx_ready)) {
+		mask |= POLLOUT | POLLWRNORM;	/* writable */
+		TRC_REC("poll can write\n");
+	}
+
+	TRC_REC("<-%s\n",__FUNCTION__);
+	return mask;
+}
+
+static int tdm_dev_ioctl(struct inode *inode_p, struct file *file_p, unsigned int cmd, unsigned long arg)
+{
+	int ret = 0;
+
+	/* Argument checking */
+	if (_IOC_TYPE(cmd) != TDM_DEV_IOCTL_MAGIC) {
+		printk("%s: invalid TDM DEV Magic Num %i %i\n", __FUNCTION__, _IOC_TYPE(cmd), TDM_DEV_IOCTL_MAGIC);
+		return -ENOTTY;
+	}
+
+	if ((_IOC_NR(cmd) > TDM_DEV_IOCTL_MAX) || (_IOC_NR(cmd) < TDM_DEV_IOCTL_MIN)) {
+		printk("%s: invalid TDM DEV IOCTL request\n", __FUNCTION__);
+		return -ENOTTY;
+	}
+
+	if (_IOC_DIR(cmd) & _IOC_READ) {
+		ret = !access_ok(VERIFY_WRITE, (void __user*)arg, _IOC_SIZE(cmd));
+	} 
+	else if (_IOC_DIR(cmd) & _IOC_WRITE) {
+		ret = !access_ok(VERIFY_READ, (void __user*)arg, _IOC_SIZE(cmd));
+	}
+
+	if (ret) {
+		printk("%s: invalid TDM DEV access type %i from cmd %i\n", __FUNCTION__, _IOC_DIR(cmd), cmd);
+		return -EFAULT;
+	}
+
+	switch (cmd) {
+		case TDM_DEV_TDM_START:
+			printk("ioctl: TDM_DEV_TDM_START\n");
+			ret = tdm_dev_tdm_start(arg);
+			break;
+
+		case TDM_DEV_TDM_STOP:
+			printk("ioctl: TDM_DEV_TDM_STOP\n");
+			atomic_set(&tdm_init, DISABLE);
+			tal_exit();
+			break;
+
+		case TDM_DEV_PCM_START:
+			printk("ioctl: TDM_DEV_PCM_START\n");
+			atomic_set(&rx_ready, DISABLE);
+			atomic_set(&tx_ready, DISABLE);
+			rx_buff_p = NULL;
+			tx_buff_p = NULL;
+			tal_pcm_start();
+			break;
+
+		case TDM_DEV_PCM_STOP:
+			printk("ioctl: TDM_DEV_PCM_STOP\n");
+			tal_pcm_stop();
+			break;
+	}
+
+	return ret;
+}
+static int tdm_dev_open(struct inode *inode_p, struct file *file_p)
+{
+	try_module_get(THIS_MODULE);
+	return 0;
+}
+
+static int tdm_dev_release(struct inode *inode_p, struct file *file_p)
+{
+	module_put(THIS_MODULE);
+	return 0;
+}
+
+void tdm_dev_tx_callback(unsigned char* tx_buff, int size)
+{
+	TRC_REC("->%s\n",__FUNCTION__);
+
+	tx_buff_p = tx_buff;
+	atomic_set(&tx_ready, ENABLE);
+	wake_up_interruptible(&tdm_dev_wait);
+
+	TRC_REC("<-%s\n",__FUNCTION__);
+	return;
+}
+
+void tdm_dev_rx_callback(unsigned char* rx_buff, int size)
+{
+	TRC_REC("->%s\n",__FUNCTION__);
+
+	rx_buff_p = rx_buff;
+	atomic_set(&rx_ready, ENABLE);
+	wake_up_interruptible(&tdm_dev_wait);
+
+	TRC_REC("<-%s\n",__FUNCTION__);
+	return;
+}
+
+static void __exit tdm_dev_exit(void)
+{
+	printk("Marvell telephony test device exits\n");
+
+	/* Stop TDM channels and release all resources */
+	tal_exit();
+
+	/* Unregister tdm misc device */
+	misc_deregister(&tdm_dev_misc_dev);
+}
+
+/* Module stuff */
+module_init(tdm_dev_init);
+module_exit(tdm_dev_exit);
+MODULE_DESCRIPTION("Marvell Telephony Test Device - www.marvell.com");
+MODULE_AUTHOR("Eran Ben-Avi <benavi@marvell.com>");
+MODULE_LICENSE("GPL");
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/test/tdm_dev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/test/tdm_dev.h
new file mode 100644
index 0000000..b09d656
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/test/tdm_dev.h
@@ -0,0 +1,87 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef _TDM_DEV_H_
+#define _TDM_DEV_H_
+
+#define TDM_DEV_IOCTL_MAGIC		't'
+
+#define TDM_DEV_IOCTL_MIN 		1
+
+#define TDM_DEV_TDM_START		_IOWR(TDM_DEV_IOCTL_MAGIC, 1, tdm_dev_params_t)
+#define TDM_DEV_TDM_STOP		_IO(TDM_DEV_IOCTL_MAGIC, 2)
+#define TDM_DEV_PCM_START		_IO(TDM_DEV_IOCTL_MAGIC, 3)
+#define TDM_DEV_PCM_STOP		_IO(TDM_DEV_IOCTL_MAGIC, 4)
+
+#define TDM_DEV_IOCTL_MAX 		4
+
+typedef struct tdm_dev_params {
+	unsigned char pcm_format;
+	unsigned short total_lines;
+} tdm_dev_params_t;
+
+/* APIs */
+
+#endif /*_TDM_DEV_H_*/
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/vpapi_dev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/vpapi_dev.c
new file mode 100644
index 0000000..99346d9
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/vpapi_dev.c
@@ -0,0 +1,1027 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File under the following licensing terms. 
+Redistribution and use in source and binary forms, with or without modification, 
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer. 
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution. 
+
+    *   Neither the name of Marvell nor the names of its contributors may be 
+        used to endorse or promote products derived from this software without 
+        specific prior written permission. 
+    
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND 
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE 
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR 
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES 
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; 
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON 
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT 
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS 
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+******************************************************************************/
+
+#include <linux/poll.h>
+#include <linux/miscdevice.h>
+#include <linux/slab.h>
+#include "vpapi_dev.h"
+
+#if !defined(CONFIG_MV_TDM_SUPPORT) && defined(CONFIG_ZARLINK_SLIC_VE880)
+#include "gpp/mvGppRegs.h"
+#endif
+
+/* Defines */
+#define GET_DEV_STATUS(deviceId)	vpapi_dev_status[deviceId]
+#define GET_LINE_STATUS(lineId)		vpapi_line_status[lineId]
+#define REGISTER_DEVICE(deviceId)	\
+	vpapi_dev_status[deviceId] = 1;
+#define REGISTER_LINE(lineId)		\
+	vpapi_line_status[lineId] = 1;
+
+#define MAX_PROFILE_SIZE		128
+#define GET_DEVICE(lineId)		(lineId/MAX_LINES_PER_DEVICE)
+#define GET_LINE(lineId)		(lineId % MAX_LINES_PER_DEVICE)
+#define MAX_EVENT_QUEUE_SIZE		256
+#define VPAPI_TICK_TIMER_PERIOD		1
+#define VPAPI_MOD_NAME                  "vpapi"
+
+/* VE880 */
+#if defined(CONFIG_ZARLINK_SLIC_VE880)
+
+#define MAX_DEVICES			2
+#define MAX_LINES			4
+#define MAX_LINES_PER_DEVICE		2
+	
+static VpDevCtxType pDevCtx[MAX_DEVICES];
+static VpLineCtxType pLineCtx[MAX_DEVICES][MAX_LINES_PER_DEVICE];
+static Vp880DeviceObjectType pDevObj[MAX_DEVICES];
+static Vp880LineObjectType pLineObj[MAX_DEVICES][MAX_LINES_PER_DEVICE];
+
+/* VE792 */
+#elif defined(CONFIG_ZARLINK_SLIC_VE792)
+
+#define MAX_DEVICES			4
+#define MAX_LINES			32
+#define MAX_LINES_PER_DEVICE		8
+
+static VpDevCtxType pDevCtx[MAX_DEVICES];
+static VpLineCtxType pLineCtx[MAX_DEVICES][MAX_LINES_PER_DEVICE];
+static Vp792DeviceObjectType pDevObj[MAX_DEVICES];
+static Vp792LineObjectType pLineObj[MAX_DEVICES][MAX_LINES_PER_DEVICE];
+
+extern int BattOn(int vbhSetting, int vblSetting, int vbpSetting);
+extern int BattOff(void);
+
+#endif
+
+
+#if !defined(CONFIG_MV_TDM_SUPPORT) && defined(CONFIG_ZARLINK_SLIC_VE880) 
+static irqreturn_t vpapi_slic_isr(int irq, void* dev_id);
+#endif
+static void vpapi_tick_handler(unsigned long data);
+static ssize_t vpapi_read(struct file *file, char __user *buf, size_t size, loff_t * ppos);
+static ssize_t vpapi_write(struct file *file, const char __user *buf, size_t size, loff_t * ppos);
+static unsigned int vpapi_poll(struct file *pFile, poll_table *pPollTable);
+static int vpapi_ioctl(struct inode *pInode, struct file *pFile, unsigned int cmd, unsigned long arg);
+static int vpapi_open(struct inode *pInode, struct file *pFile);
+static int vpapi_release(struct inode *pInode, struct file *pFile);
+//static int __init vpapi_module_init(void);
+//static void __exit vpapi_module_exit(void);
+
+/* VP-API-II Dispatchers */
+static int vpapi_make_dev_object(unsigned long arg);
+static int vpapi_make_line_object(unsigned long arg);
+static int vpapi_map_line_id(unsigned long arg);
+static int vpapi_map_slac_id(unsigned long arg);
+static int vpapi_free_line_context(unsigned long arg);
+static int vpapi_init_device(unsigned long arg);
+static int vpapi_cal_line(unsigned long arg);
+static int vpapi_set_line_state(unsigned long arg);
+static int vpapi_set_option(unsigned long arg);
+int vpapi_get_event(unsigned long arg);
+#if defined(CONFIG_ZARLINK_SLIC_VE792)
+static int vpapi_batt_on(unsigned long arg);
+static int vpapi_batt_off(unsigned long arg);
+#endif
+#if defined(CONFIG_ZARLINK_SLIC_VE880)
+static int vpapi_reg_read(unsigned long arg);
+static int vpapi_reg_write(unsigned long arg);
+#endif
+
+/* Enumurators */
+typedef struct {
+	unsigned char valid;		/* valid event */
+	VpEventType vp_event;
+} vpapi_event;
+
+
+/* Structs */
+static struct file_operations vpapi_fops = {
+    owner:      THIS_MODULE,
+    llseek:     NULL,
+    read:       vpapi_read,
+    write:      vpapi_write,
+    poll:       vpapi_poll,
+    ioctl:      vpapi_ioctl,
+    open:       vpapi_open,
+    release:    vpapi_release,
+    fasync:     NULL
+};
+
+/* Globals */
+static DEFINE_SPINLOCK(vpapi_lock);
+static DECLARE_WAIT_QUEUE_HEAD(vpapi_wait);
+static atomic_t event_count;
+static atomic_t vpapi_init;
+static vpapi_event event_queue[MAX_EVENT_QUEUE_SIZE];
+static u8 vpapi_dev_status[MAX_DEVICES];
+static u8 vpapi_line_status[MAX_LINES];
+static volatile u32 next_event = 0, curr_event = 0;
+static struct timer_list vpapi_timer;
+static u16 total_devs = 0, total_lines = 0;
+
+
+static struct miscdevice vpapi_misc_dev = {
+	.minor = SLICDEV_MINOR,
+	.name = VPAPI_MOD_NAME,
+	.fops = &vpapi_fops,
+};
+
+static ssize_t vpapi_read(struct file *file, char __user *buf, size_t size, loff_t * ppos)
+{
+	return 0;
+}
+
+static ssize_t vpapi_write(struct file *file, const char __user *buf, size_t size, loff_t * ppos)
+{
+	return 0;
+}
+
+static unsigned int vpapi_poll(struct file *pFile, poll_table *pPollTable)
+{
+	int mask = 0;
+
+	poll_wait(pFile, &vpapi_wait, pPollTable);
+	
+	if(atomic_read(&event_count) > 0) {
+		mask |= POLLPRI;
+	}
+
+	return mask;
+}
+
+static int vpapi_ioctl(struct inode *pInode, struct file *pFile, unsigned int cmd, unsigned long arg)
+{
+	int ret = 0;
+	unsigned long flags = 0;
+
+	/* Argument checking */
+	if (_IOC_TYPE(cmd) != VPAPI_MOD_IOCTL_MAGIC) {
+		printk("%s: invalid VPAPI MOD Magic Num %i %i\n", __func__, _IOC_TYPE(cmd), VPAPI_MOD_IOCTL_MAGIC);
+		return -ENOTTY;
+	}
+
+	if ((_IOC_NR(cmd) > VPAPI_MOD_IOCTL_MAX) || (_IOC_NR(cmd) < VPAPI_MOD_IOCTL_MIN)) {
+		printk("%s: invalid VPAPI MOD IOCTL request\n", __func__);
+		return -ENOTTY;
+	}
+
+	if (_IOC_DIR(cmd) & _IOC_READ) {
+		ret = !access_ok(VERIFY_WRITE, (void __user*)arg, _IOC_SIZE(cmd));
+	} 
+	else if (_IOC_DIR(cmd) & _IOC_WRITE) {
+		ret = !access_ok(VERIFY_READ, (void __user*)arg, _IOC_SIZE(cmd));
+	}
+
+	if (ret) {
+		printk("%s: invalid VPAPI MOD access type %i from cmd %i\n", __func__, _IOC_DIR(cmd), cmd);
+		return -EFAULT;
+	}
+
+	spin_lock_irqsave(&vpapi_lock, flags);
+
+	switch (cmd) {
+		case VPAPI_MOD_IOX_MK_DEV_OBJ:
+			//printk("ioctl: VPAPI_MOD_IOX_MK_DEV_OBJ\n");
+			ret = vpapi_make_dev_object(arg);	
+			break;
+		
+		case VPAPI_MOD_IOX_MK_LN_OBJ:
+			//printk("ioctl: VPAPI_MOD_IOX_MK_LN_OBJ\n");
+			ret = vpapi_make_line_object(arg);
+			break;
+
+		case VPAPI_MOD_IOX_MAP_LN_ID:
+			//printk("ioctl: VPAPI_MOD_IOX_MAP_LN_ID\n");
+			ret = vpapi_map_line_id(arg);
+			break;
+
+		case VPAPI_MOD_IOX_MAP_SLAC_ID:
+			//printk("ioctl: VPAPI_MOD_IOX_MAP_SLAC_ID\n");
+			ret  = vpapi_map_slac_id(arg);
+			break;
+
+		case VPAPI_MOD_IOX_FREE_LN_CTX:
+			//printk("ioctl: VPAPI_MOD_IOX_FREE_LN_CTX\n");
+			ret = vpapi_free_line_context(arg);
+			break;
+
+		case VPAPI_MOD_IOX_INIT_DEV:
+			//printk("ioctl: VPAPI_MOD_IOX_INIT_DEV\n");
+			ret = vpapi_init_device(arg);
+			break;
+
+		case VPAPI_MOD_IOX_CAL_LN:
+			//printk("ioctl: VPAPI_MOD_IOX_CAL_LN\n");
+			ret = vpapi_cal_line(arg);
+			break;
+
+		case VPAPI_MOD_IOX_SET_LN_ST:
+			//printk("ioctl: VPAPI_MOD_IOX_SET_LN_ST\n");
+			ret = vpapi_set_line_state(arg);
+			break;
+
+		case VPAPI_MOD_IOX_SET_OPTION:
+			//printk("ioctl: VPAPI_MOD_IOX_SET_OPTION\n");
+			ret = vpapi_set_option(arg);
+			break;
+
+		case VPAPI_MOD_IOX_GET_EVENT:
+			//printk("ioctl: VPAPI_MOD_IOX_GET_EVENT\n");
+			ret = vpapi_get_event(arg);
+			break;
+
+#if defined(CONFIG_ZARLINK_SLIC_VE792)		
+		case VPAPI_MOD_IOX_BATT_ON:
+			//printk("ioctl: VPAPI_MOD_IOX_BATT_ON\n");
+			ret = vpapi_batt_on(arg);
+			break;
+
+		case VPAPI_MOD_IOX_BATT_OFF:
+			//printk("ioctl: VPAPI_MOD_IOX_BATT_OFF\n");
+			ret = vpapi_batt_off(arg);
+			break;
+#endif
+#if defined(CONFIG_ZARLINK_SLIC_VE880)
+		case VPAPI_MOD_IOX_REG_READ:
+			ret = vpapi_reg_read(arg);
+			break;
+
+		case VPAPI_MOD_IOX_REG_WRITE:
+			ret = vpapi_reg_write(arg);
+			break;
+#endif
+		default:
+			printk("%s: error, ioctl command(0x%x) not supported !!!\n", __func__, cmd);
+			ret = -EFAULT;
+			break;
+	}
+
+	spin_unlock_irqrestore(&vpapi_lock, flags);
+
+	return ret;
+}
+
+static int vpapi_make_dev_object(unsigned long arg)
+{
+	VpApiModMkDevObjType data;
+	VpDeviceType deviceType;
+	VpDeviceIdType deviceId;
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpApiModMkDevObjType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+
+	deviceType = data.deviceType;
+	deviceId = data.deviceId;
+	
+	data.status = VpMakeDeviceObject(deviceType, deviceId, &pDevCtx[deviceId], &pDevObj[deviceId]);
+
+	/* Copy status back to user */
+	if(copy_to_user((void*)arg, &data, sizeof(VpApiModMkDevObjType))) {
+		printk("%s: copy_to_user failed\n", __func__);
+		return  -EFAULT;
+	}
+
+	return 0;
+}
+
+static int vpapi_make_line_object(unsigned long arg)
+{
+	VpApiModMkLnObjType data;
+	VpTermType termType;
+	VpLineIdType lineId;
+	VpDeviceIdType deviceId;
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpApiModMkLnObjType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+
+	termType = data.termType;
+	lineId = GET_LINE(data.lineId);
+	deviceId = GET_DEVICE(data.lineId);
+
+	data.status = VpMakeLineObject(termType, lineId, &pLineCtx[deviceId][lineId],
+                        	&pLineObj[deviceId][lineId], &pDevCtx[deviceId]);
+
+	/* Copy status back to user */
+	if(copy_to_user((void*)arg, &data, sizeof(VpApiModMkLnObjType))) {
+		printk("%s: copy_to_user failed\n", __func__);
+		return  -EFAULT;
+	}
+
+	
+	return 0;
+}
+
+static int vpapi_map_line_id(unsigned long arg)
+{
+	VpApiModMapLnIdType data;
+	VpLineIdType lineId;
+	VpDeviceIdType deviceId;
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpApiModMapLnIdType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+
+	lineId = GET_LINE(data.lineId);
+	deviceId = GET_DEVICE(data.lineId);
+
+	data.status = VpMapLineId(&pLineCtx[deviceId][lineId], data.lineId);
+
+	/* Copy status back to user */
+	if(copy_to_user((void*)arg, &data, sizeof(VpApiModMapLnIdType))) {
+		printk("%s: copy_to_user failed\n", __func__);
+		return  -EFAULT;
+	}
+
+	return 0;
+}
+
+static int vpapi_map_slac_id(unsigned long arg)
+{
+	VpApiModMapSlacIdType data;
+	VpDeviceIdType deviceId;
+	u8 slacId;
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpApiModMapSlacIdType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+	
+	deviceId = data.deviceId;
+	slacId = data.slacId;
+
+	data.status = VpMapSlacId(&pDevCtx[deviceId], slacId);
+
+	/* Copy status back to user */
+	if(copy_to_user((void*)arg, &data, sizeof(VpApiModMapSlacIdType))) {
+		printk("%s: copy_to_user failed\n", __func__);
+		return  -EFAULT;
+	}
+
+	return 0;
+	
+}
+
+static int vpapi_free_line_context(unsigned long arg)
+{
+	VpApiModFreeLnCtxType data;
+	VpLineIdType lineId;
+	VpDeviceIdType deviceId;
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpApiModFreeLnCtxType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+
+	lineId = GET_LINE(data.lineId);
+	deviceId = GET_DEVICE(data.lineId);
+
+	data.status = VpFreeLineCtx(&pLineCtx[deviceId][lineId]);
+
+	if(data.status == VP_STATUS_SUCCESS)
+		vpapi_line_status[data.lineId] = 0;
+
+	/* Copy status back to user */
+	if(copy_to_user((void*)arg, &data, sizeof(VpApiModFreeLnCtxType))) {
+		printk("%s: copy_to_user failed\n", __func__);
+		return  -EFAULT;
+	}
+
+	return 0;
+}
+
+static int vpapi_init_device(unsigned long arg)
+{
+	VpApiModInitDeviceType data;
+	VpDeviceIdType deviceId;
+	VpProfileDataType devProfile[MAX_PROFILE_SIZE];
+	VpProfileDataType acProfile[MAX_PROFILE_SIZE];
+	VpProfileDataType dcProfile[MAX_PROFILE_SIZE];
+	VpProfileDataType ringProfile[MAX_PROFILE_SIZE];
+	VpProfileDataType fxoAcProfile[MAX_PROFILE_SIZE];
+	VpProfileDataType fxoCfgProfile[MAX_PROFILE_SIZE];
+	VpProfilePtrType pDevProfile = NULL, pAcProfile = NULL;
+	VpProfilePtrType pDcProfile = NULL, pRingProfile = NULL;
+	VpProfilePtrType pFxoAcProfile = NULL, pFxoCfgProfile = NULL;
+	u16 devProfileSize, acProfileSize, dcProfileSize;
+	u16 ringProfileSize, fxoAcProfileSize, fxoCfgProfileSize;
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpApiModInitDeviceType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+
+	deviceId = data.deviceId;
+	devProfileSize = data.devProfileSize;
+	acProfileSize = data.acProfileSize;
+	dcProfileSize = data.dcProfileSize;
+	ringProfileSize = data.ringProfileSize;
+	fxoAcProfileSize = data.fxoAcProfileSize;
+	fxoCfgProfileSize = data.fxoCfgProfileSize;
+
+	if(devProfileSize) {
+		/* Get device profile */
+		if(copy_from_user(devProfile, (void*)data.pDevProfile, (sizeof(VpProfileDataType)*devProfileSize))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+		}
+		pDevProfile = devProfile;
+	}
+
+	if(acProfileSize) {
+		/* Get AC profile */
+		if(copy_from_user(acProfile, (void*)data.pAcProfile, (sizeof(VpProfileDataType)*acProfileSize))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+		}
+		pAcProfile = acProfile;
+	}
+
+	if(dcProfileSize) {
+		/* Get DC profile */
+		if(copy_from_user(dcProfile, (void*)data.pDcProfile, (sizeof(VpProfileDataType)*dcProfileSize))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+		}
+		pDcProfile = dcProfile;
+	}
+
+	if(ringProfileSize) {
+		/* Get ring profile */
+		if(copy_from_user(ringProfile, (void*)data.pRingProfile, (sizeof(VpProfileDataType)*ringProfileSize))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+		}
+		pRingProfile = ringProfile;
+	}
+
+	if(fxoAcProfileSize) {
+		/* Get FXO AC profile */
+		if(copy_from_user(fxoAcProfile, (void*)data.pFxoAcProfile, (sizeof(VpProfileDataType)*fxoAcProfileSize))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+		}
+		pFxoAcProfile = fxoAcProfile;
+	}
+
+	if(fxoCfgProfileSize) {
+		/* Get FXO configuration profile */
+		if(copy_from_user(fxoCfgProfile, (void*)data.pFxoCfgProfile,
+					 (sizeof(VpProfileDataType)*fxoCfgProfileSize))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+		}
+		pFxoCfgProfile = fxoCfgProfile;
+	}
+
+	data.status = VpInitDevice(&pDevCtx[deviceId], pDevProfile, pAcProfile, pDcProfile, pRingProfile,
+					 pFxoAcProfile, pFxoCfgProfile);
+
+	if(data.status == VP_STATUS_SUCCESS) {
+		total_devs++;
+		REGISTER_DEVICE(deviceId);
+
+		if(!atomic_read(&vpapi_init))
+			atomic_set(&vpapi_init, 1);
+	}
+
+	/* Copy status back to user */
+	if(copy_to_user((void*)arg, &data, sizeof(VpApiModInitDeviceType))) {
+		printk("%s: copy_to_user failed\n", __func__);
+		return  -EFAULT;
+	}
+
+	return 0;
+}
+
+static int vpapi_cal_line(unsigned long arg)
+{
+	VpApiModCalLnType data;
+	VpLineIdType lineId;
+	VpDeviceIdType deviceId;
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpApiModCalLnType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+
+	lineId = GET_LINE(data.lineId);
+	deviceId = GET_DEVICE(data.lineId);
+
+	data.status = VpCalLine(&pLineCtx[deviceId][lineId]);
+
+	if(data.status == VP_STATUS_SUCCESS) {
+		total_lines++;
+		REGISTER_LINE(data.lineId);
+	}
+
+	/* Copy status back to user */
+	if(copy_to_user((void*)arg, &data, sizeof(VpApiModCalLnType))) {
+		printk("%s: copy_to_user failed\n", __func__);
+		return  -EFAULT;
+	}
+
+	return 0;
+}
+
+static int vpapi_set_line_state(unsigned long arg)
+{
+	VpApiModSetLnStType data;
+	VpLineIdType lineId;
+	VpDeviceIdType deviceId;
+	VpLineStateType state;
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpApiModSetLnStType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+
+	lineId = GET_LINE(data.lineId);
+	deviceId = GET_DEVICE(data.lineId);
+	state = data.state;
+
+	data.status = VpSetLineState(&pLineCtx[deviceId][lineId], state);
+
+	/* Copy status back to user */
+	if(copy_to_user((void*)arg, &data, sizeof(VpApiModSetLnStType))) {
+		printk("%s: copy_to_user failed\n", __func__);
+		return  -EFAULT;
+	}
+
+	return 0;
+}
+
+static int vpapi_set_option(unsigned long arg)
+{
+	VpApiModSetOptionType data;
+	u8 lineRequest;
+	VpLineIdType lineId;
+	VpDeviceIdType deviceId;
+	VpOptionIdType option;
+	void *pOptInfo;
+	long size;
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpApiModSetOptionType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+
+	option = data.option;
+	lineRequest = data.lineRequest;
+	deviceId = data.deviceId;
+	lineId = GET_LINE(data.lineId);
+
+	switch(option) {
+		case VP_OPTION_ID_TIMESLOT:
+			size = sizeof(VpOptionTimeslotType);
+			pOptInfo = (VpOptionTimeslotType*)kmalloc(size, GFP_KERNEL);
+			break;
+		case VP_OPTION_ID_CODEC:
+			size = sizeof(VpOptionCodecType);
+			pOptInfo = (VpOptionCodecType*)kmalloc(size, GFP_KERNEL);
+			break;
+		case VP_OPTION_ID_LOOPBACK:
+			size = sizeof(VpOptionLoopbackType);
+			pOptInfo = (VpOptionLoopbackType*)kmalloc(size, GFP_KERNEL);
+			break;
+		case VP_OPTION_ID_EVENT_MASK:
+			size = sizeof(VpOptionEventMaskType);
+			pOptInfo = (VpOptionEventMaskType*)kmalloc(size, GFP_KERNEL);
+			break;
+		default:
+			printk("%s: option(%d) not supported\n",__func__, option);
+			return -EFAULT;
+	}
+
+	/* Get option info */
+	if(copy_from_user(pOptInfo, (void*)data.pValue, size)) {
+			printk("%s: copy_from_user failed\n", __func__);
+			kfree(pOptInfo);
+			return -EFAULT;
+	}
+
+	/* Set option to line/device */
+	if(lineRequest)
+		data.status = VpSetOption(&pLineCtx[deviceId][lineId], VP_NULL, option, pOptInfo);
+	else
+		data.status = VpSetOption(VP_NULL, &pDevCtx[deviceId], option, pOptInfo);
+
+
+	kfree(pOptInfo);
+
+	/* Copy status back to user */
+	if(copy_to_user((void*)arg, &data, sizeof(VpApiModSetOptionType))) {
+		printk("%s: copy_to_user failed\n", __func__);
+		return  -EFAULT;
+	}
+
+	return 0;
+}
+
+int vpapi_get_event(unsigned long arg)
+{
+	VpApiModGetEventType data;
+	VpDeviceIdType deviceId;
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpApiModGetEventType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+
+	deviceId = data.deviceId;
+
+	if(atomic_read(&event_count) == 0) {
+		data.newEvent = FALSE;
+	}
+	else {
+		/* Copy event info back to user */
+		if(copy_to_user(data.pEvent, &event_queue[curr_event].vp_event, sizeof(VpEventType))) {
+			printk("%s: copy_to_user failed\n", __func__);
+			return  -EFAULT;
+		}
+
+		event_queue[curr_event].valid = 0;
+		data.newEvent = TRUE;
+		atomic_dec(&event_count);
+		curr_event++;
+		if(curr_event == MAX_EVENT_QUEUE_SIZE)
+			curr_event = 0;
+	}
+
+	/* Copy status and event info back to user */
+	if(copy_to_user((void*)arg, &data, sizeof(VpApiModGetEventType))) {
+		printk("%s: copy_to_user failed\n", __func__);
+		return  -EFAULT;
+	}
+
+	return 0;
+}
+#if defined(CONFIG_ZARLINK_SLIC_VE792)
+static int vpapi_batt_on(unsigned long arg)
+{
+	VpModBatteryOnType data;
+	int vbh, vbl, vbp;
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpModBatteryOnType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+	
+	vbh = data.vbh;
+	vbl = data.vbl;
+	vbp = data.vbp;
+
+	data.status = BattOn(vbh, vbl, vbp);
+
+	/* Copy status and event info back to user */
+	if(copy_to_user((void*)arg, &data, sizeof(VpModBatteryOnType))) {
+		printk("%s: copy_to_user failed\n", __func__);
+		return  -EFAULT;
+	}
+
+	return 0;
+}
+
+static int vpapi_batt_off(unsigned long arg)
+{
+	VpModBatteryOffType data;
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpModBatteryOffType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+	
+	data.status = BattOff();
+
+	/* Copy status and event info back to user */
+	if(copy_to_user((void*)arg, &data, sizeof(VpModBatteryOffType))) {
+		printk("%s: copy_to_user failed\n", __func__);
+		return  -EFAULT;
+	}
+
+	return 0;
+}
+#endif
+
+#if defined(CONFIG_ZARLINK_SLIC_VE880)
+static int vpapi_reg_read(unsigned long arg)
+{
+	VpModRegOpType data;
+	VpLineIdType	line_id;
+	unsigned char	cmd;
+	unsigned short  cmd_len;
+	unsigned char *buff_p = NULL;
+	unsigned char ec_val[] = {0x1, 0x2};
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpModRegOpType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+
+	line_id = data.lineId;
+	cmd = data.cmd;
+	cmd_len = data.cmdLen;
+	buff_p = data.buff;
+
+	VpMpiCmd(GET_DEVICE(line_id), ec_val[GET_LINE(line_id)], (cmd | 1), cmd_len, buff_p);
+
+	/* Copy status and event info back to user */
+	if(copy_to_user((void*)arg, &data, sizeof(VpModRegOpType))) {
+		printk("%s: copy_to_user failed\n", __func__);
+		return  -EFAULT;
+	}
+
+	return 0;
+}
+
+static int vpapi_reg_write(unsigned long arg)
+{
+	VpModRegOpType data;
+	VpLineIdType	line_id;
+	unsigned char	cmd;
+	unsigned short  cmd_len;
+	unsigned char *buff_p = NULL;
+	unsigned char ec_val[] = {0x1, 0x2};
+
+	/* Get user data */
+	if(copy_from_user(&data, (void*)arg, sizeof(VpModRegOpType))) {
+			printk("%s: copy_from_user failed\n", __func__);
+			return -EFAULT;
+	}
+
+	line_id = data.lineId;
+	cmd = data.cmd;
+	cmd_len = data.cmdLen;
+	buff_p = data.buff;
+
+	VpMpiCmd(GET_DEVICE(line_id), ec_val[GET_LINE(line_id)], cmd, cmd_len, buff_p);
+
+	return 0;
+}
+#endif
+
+static int vpapi_open(struct inode *pInode, struct file *pFile)
+{
+	try_module_get(THIS_MODULE);
+	return 0;
+}
+
+static int vpapi_release(struct inode *pInode, struct file *pFile)
+{
+	module_put(THIS_MODULE);
+	return 0;
+}
+
+#if !defined(CONFIG_MV_TDM_SUPPORT) && defined(CONFIG_ZARLINK_SLIC_VE880) 
+static irqreturn_t vpapi_slic_isr(int irq, void* dev_id)
+{
+	unsigned int gpp;
+	unsigned int deviceId;
+
+	/* Mark interrupt/s for active SLAC device/s */
+	for(deviceId = 0; deviceId < MAX_DEVICES; deviceId++) {
+		if(GET_DEV_STATUS(deviceId))
+			VpVirtualISR(&pDevCtx[deviceId]);
+	}
+	//MV_REG_WRITE(MV_GPP_IRQ_CAUSE_REG(0), ~BIT23);
+
+	/* ack interrupt */
+	gpp = MV_REG_READ(GPP_DATA_IN_POL_REG(0));
+        gpp = gpp^(1 << 23);
+        MV_REG_WRITE(GPP_DATA_IN_POL_REG(0), gpp);
+	
+	return IRQ_HANDLED;
+}
+#endif
+
+#if defined(SLIC_TIMER_EVENT_SUPPORT)
+static void vpapi_tick_handler(unsigned long data)
+{
+	u8 deviceId;
+	unsigned long flags;
+	vpapi_event *pEvent;
+#if !defined(CONFIG_ZARLINK_SLIC_VE792)
+	MV_STD_BOOL eventStatus;
+#endif
+
+	/* Check if events are already active */
+	if(atomic_read(&vpapi_init) == 0)
+		goto timer_exit;
+
+	spin_lock_irqsave(&vpapi_lock, flags);
+
+	for(deviceId = 0; deviceId < MAX_DEVICES; deviceId++) {
+
+		if(GET_DEV_STATUS(deviceId) == 0)
+			continue;
+
+		/* Check for free resources */
+		if(atomic_read(&event_count) >= MAX_EVENT_QUEUE_SIZE)
+			goto timer_exit;
+
+#if !defined(CONFIG_ZARLINK_SLIC_VE792)
+		if(VP_STATUS_SUCCESS == VpApiTick(&pDevCtx[deviceId], &eventStatus)) {
+			if(eventStatus == TRUE) {
+#endif
+				pEvent = &event_queue[next_event];
+				while(VpGetEvent(&pDevCtx[deviceId], &pEvent->vp_event) == TRUE) {
+					if(pEvent->vp_event.status != VP_STATUS_SUCCESS) {
+						printk("%s: bad status(%d)\n", __func__, pEvent->vp_event.status);
+						break;
+					}
+					
+					if(pEvent->vp_event.eventId == 0)  {
+						printk("%s: warning, empty event\n", __func__);
+						break;
+					}
+					
+					next_event++;
+					if(next_event == MAX_EVENT_QUEUE_SIZE) {
+						next_event = 0;
+					}
+
+					atomic_inc(&event_count);
+					
+					if(pEvent->valid == 0) {
+						pEvent->valid = 1;			
+					}
+					else {
+						printk("%s: error, event(%u) was overrided\n", __func__, next_event);
+						break;
+					}
+
+					pEvent = &event_queue[next_event];
+				}
+#if !defined(CONFIG_ZARLINK_SLIC_VE792)
+			}
+		}
+#endif
+	}
+
+	
+	spin_unlock_irqrestore(&vpapi_lock, flags);
+
+timer_exit:
+
+	/* Checks if user application should be signaled */
+	if(atomic_read(&event_count) > 0) {
+		wake_up_interruptible(&vpapi_wait);
+	}
+
+	/* Schedule next timer tick */
+	vpapi_timer.expires = jiffies + VPAPI_TICK_TIMER_PERIOD;
+    	add_timer(&vpapi_timer);
+}
+#endif
+
+int __init vpapi_module_init(void)
+{
+	int status;
+
+	printk("Loading Marvell %s device\n", VPAPI_MOD_NAME);
+	status = misc_register(&vpapi_misc_dev);
+
+	/* Register VPAPI device module */
+	if (status < 0) {
+		printk("Error, failed to load %s module(%d)\n", VPAPI_MOD_NAME, status);
+		return status;
+	}
+
+	atomic_set(&vpapi_init, 0);
+	total_devs = 0;
+	total_lines = 0;
+	next_event = 0;
+	curr_event = 0;
+	memset(vpapi_dev_status, 0, MAX_DEVICES);
+	memset(vpapi_line_status, 0, MAX_LINES);
+
+	/* Reset event counter */
+	atomic_set(&event_count, 0);
+
+	/* Clear event queue */
+	memset(event_queue, 0, (MAX_EVENT_QUEUE_SIZE * sizeof(vpapi_event)));
+
+#if defined(SLIC_TIMER_EVENT_SUPPORT)
+	memset(&vpapi_timer, 0, sizeof(struct timer_list));
+	init_timer(&vpapi_timer);
+    	vpapi_timer.function = vpapi_tick_handler;
+    	vpapi_timer.data = -1;
+	vpapi_timer.expires = jiffies + VPAPI_TICK_TIMER_PERIOD;
+	add_timer(&vpapi_timer);
+#endif
+
+#if !defined(CONFIG_MV_TDM_SUPPORT) && defined(CONFIG_ZARLINK_SLIC_VE880)
+	/* Register SLIC interrupt */
+	if (request_irq((23+IRQ_GPP_START), vpapi_slic_isr, IRQF_DISABLED, "slic", event_queue)) {
+		printk("%s: Failed to connect irq(%d)\n", __func__, (23+IRQ_GPP_START));
+		return MV_ERROR;
+	}
+#endif
+
+	return 0;
+}
+
+void __exit vpapi_module_exit(void)
+{
+	printk("Unloading %s device module\n", VPAPI_MOD_NAME);
+
+#if defined(SLIC_TIMER_EVENT_SUPPORT)
+	del_timer(&vpapi_timer);
+#endif
+
+	/* Unregister VPAPI misc device */
+	misc_deregister(&vpapi_misc_dev);
+
+#if !defined(CONFIG_MV_TDM_SUPPORT) && defined(CONFIG_ZARLINK_SLIC_VE880)
+	free_irq((23+IRQ_GPP_START), event_queue);
+#endif
+
+	return;
+}
+
+/* Module stuff */
+module_init(vpapi_module_init);
+module_exit(vpapi_module_exit);
+MODULE_DESCRIPTION("Zarlink VPAPI-II Device");
+MODULE_AUTHOR("Eran Ben-Avi <benavi@marvell.com>");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/vpapi_dev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/vpapi_dev.h
new file mode 100644
index 0000000..96d2666
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_phone/vpapi_dev.h
@@ -0,0 +1,266 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+        used to endorse or promote products derived from this software without
+        specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef _VPAPI_DEV_H_
+#define _VPAPI_DEV_H_
+
+#include "vp_api_common.h"
+#if defined(CONFIG_ZARLINK_SLIC_VE880)
+#include "vp880_api.h"
+#elif defined(CONFIG_ZARLINK_SLIC_VE792)
+#include "vp792_api.h"
+#endif
+
+#define VPAPI_MOD_IOCTL_MAGIC           'z'
+
+#define VPAPI_MOD_IOCTL_MIN 		1
+
+/* VP-API System Configuration Functions */
+#define VPAPI_MOD_IOX_MK_DEV_OBJ	_IOWR(VPAPI_MOD_IOCTL_MAGIC, 1, VpApiModMkDevObjType)
+#define VPAPI_MOD_IOX_MK_LN_OBJ		_IOWR(VPAPI_MOD_IOCTL_MAGIC, 2, VpApiModMkLnObjType)
+#define VPAPI_MOD_IOX_MAP_LN_ID		_IOWR(VPAPI_MOD_IOCTL_MAGIC, 3, VpApiModMapLnIdType)
+#define VPAPI_MOD_IOX_MAP_SLAC_ID	_IOWR(VPAPI_MOD_IOCTL_MAGIC, 4, VpApiModMapSlacIdType)
+#define VPAPI_MOD_IOX_FREE_LN_CTX	_IOWR(VPAPI_MOD_IOCTL_MAGIC, 5, VpApiModFreeLnCtxType)
+
+/* VP-API Initialization Functions */
+#define VPAPI_MOD_IOX_INIT_DEV		_IOWR(VPAPI_MOD_IOCTL_MAGIC, 6, VpApiModInitDeviceType)
+#define VPAPI_MOD_IOX_CAL_LN		_IOWR(VPAPI_MOD_IOCTL_MAGIC, 7, VpApiModCalLnType)
+
+/* VP-API Control Functions */
+#define VPAPI_MOD_IOX_SET_LN_ST		_IOWR(VPAPI_MOD_IOCTL_MAGIC, 8, VpApiModSetLnStType)
+#define VPAPI_MOD_IOX_SET_OPTION	_IOWR(VPAPI_MOD_IOCTL_MAGIC, 9, VpApiModSetOptionType)
+
+/* VP-API Status and Query Functions */
+#define VPAPI_MOD_IOX_GET_EVENT		_IOWR(VPAPI_MOD_IOCTL_MAGIC, 10, VpApiModGetEventType)
+
+/* VE792 Battery Control */
+#define VPAPI_MOD_IOX_BATT_ON		_IOWR(VPAPI_MOD_IOCTL_MAGIC, 11, VpModBatteryOnType)
+#define VPAPI_MOD_IOX_BATT_OFF		_IOWR(VPAPI_MOD_IOCTL_MAGIC, 12, VpModBatteryOffType)
+
+/* SLIC register read/write */
+#define VPAPI_MOD_IOX_REG_READ		_IOWR(VPAPI_MOD_IOCTL_MAGIC, 13, VpModRegOpType)
+#define VPAPI_MOD_IOX_REG_WRITE		_IOWR(VPAPI_MOD_IOCTL_MAGIC, 14, VpModRegOpType)
+
+#define VPAPI_MOD_IOCTL_MAX 		14
+#define MAX_SLIC_RDWR_BUFF_SIZE		128
+
+
+/******************** VP-API System Configuration Structs *********************/
+typedef struct VpApiModMkDevObj {
+	/* Input arg(s) */
+	VpDeviceType	deviceType;
+	VpDeviceIdType	deviceId;
+    
+	/* Output arg(s) */
+	VpStatusType		status;
+} VpApiModMkDevObjType;
+
+
+typedef struct VpApiModMkLnObj {
+	/* Input arg(s) */
+	VpTermType	termType;
+	VpLineIdType	lineId;
+
+	/* Output arg(s) */
+	VpStatusType	status;
+} VpApiModMkLnObjType;
+
+typedef struct VpApiModMapLnId {
+	/* Input arg(s) */
+	VpLineIdType	lineId;
+
+	/* Output arg(s) */
+	VpStatusType	status;
+} VpApiModMapLnIdType;
+
+typedef struct VpApiModMapSlacId {
+ 	/* Input arg(s) */
+	VpDeviceIdType	deviceId;
+	unsigned char	slacId;
+
+	/* Output arg(s) */
+	VpStatusType	status;
+} VpApiModMapSlacIdType;
+
+typedef struct VpApiModFreeLnCtx {
+ 	/* Input arg(s) */
+	VpLineIdType	lineId;
+
+	/* Output arg(s) */
+	VpStatusType	status;
+} VpApiModFreeLnCtxType;
+
+
+/************************ VP-API Initialization Structs ************************/
+typedef struct VpApiModInitDevice {
+    	/* Input arg(s) */
+	VpDeviceIdType		deviceId;
+	VpProfilePtrType	pDevProfile;
+	VpProfilePtrType	pAcProfile;
+	VpProfilePtrType	pDcProfile;
+	VpProfilePtrType	pRingProfile;
+	VpProfilePtrType	pFxoAcProfile;
+	VpProfilePtrType	pFxoCfgProfile;
+	unsigned short		devProfileSize;
+	unsigned short		acProfileSize;
+	unsigned short		dcProfileSize;
+	unsigned short		ringProfileSize;
+	unsigned short		fxoAcProfileSize;
+	unsigned short		fxoCfgProfileSize;
+
+	/* Output arg(s) */
+	VpStatusType		status;
+} VpApiModInitDeviceType;
+
+typedef struct VpApiModCalLn {
+	/* Input arg(s) */
+	VpLineIdType	lineId;
+
+	/* Output arg(s) */
+	VpStatusType	status;
+} VpApiModCalLnType;
+
+
+/****************************VP-API Control Structs ***************************/
+typedef struct VpApiModSetLnSt {
+	/* Input arg(s) */
+	VpLineIdType	lineId;
+	VpLineStateType	state;
+
+	/* Output arg(s) */
+	VpStatusType	status;
+} VpApiModSetLnStType;
+
+
+typedef struct VpApiModSetOption {
+	/* Input arg(s) */
+	unsigned char	lineRequest;
+	VpLineIdType	lineId;
+	VpDeviceIdType	deviceId;
+	VpOptionIdType	option;
+	void		*pValue;
+
+	/* Output arg(s) */
+	VpStatusType	status;
+} VpApiModSetOptionType;
+
+#if 0
+typedef struct VpApiModLowLvlCmd {
+	/* Input arg(s) */
+	const VpModLineRegNumType	lineRegNum;
+	uint8				*pCmdData;
+	const uint8			len;
+	const uint16			handle;
+
+	/* Output arg(s) */
+	VpStatusType			status;
+} VpApiModLowLvlCmdType;
+#endif
+
+/********************** VP-API Status and Query Structs ***********************/
+typedef struct VpApiModGetEvent {
+	/* Input arg(s) */
+	VpDeviceIdType	deviceId;
+
+	/* Output arg(s) */
+	bool		newEvent;
+	VpEventType	*pEvent;
+} VpApiModGetEventType;
+
+/********************** VE792 Battery Control ***********************/
+typedef struct VpModBatteryOn {
+	/* Input arg(s) */
+	int	vbh;
+	int	vbl;
+	int	vbp;
+
+	/* Output arg(s) */
+	int	status;
+} VpModBatteryOnType;
+
+typedef struct VpModBatteryOff {
+
+	/* Output arg(s) */
+	int	status;
+} VpModBatteryOffType;
+
+/********************** SLIC register read/write ********************/
+typedef struct VpModRegOp {
+	/* Input arg(s) */
+	VpLineIdType	lineId;
+	unsigned char	cmd;
+	unsigned short  cmdLen;
+	unsigned char buff[MAX_SLIC_RDWR_BUFF_SIZE];
+
+	/* Output arg(s) */
+	VpStatusType	status;
+} VpModRegOpType;
+
+/* APIs */
+int vpapi_module_init(void);
+void vpapi_module_exit(void);
+
+
+#endif /*_VPAPI_DEV_H_*/
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_proc/proc.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_proc/proc.c
new file mode 100644
index 0000000..8649cab
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_proc/proc.c
@@ -0,0 +1,533 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <linux/device.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/sysdev.h>
+#include <linux/proc_fs.h>
+#include <linux/version.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/setup.h>
+#include <asm/mach-types.h>
+#include <asm/mach/arch.h>
+#include <asm/mach/irq.h>
+#include <asm/mach/map.h>
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "gpp/mvGpp.h"
+#include "mvOs.h"
+#include "cpu/mvCpu.h"
+#include "cpu/mvCpuCntrs.h"
+#include "cpu/mvCpuL2Cntrs.h"
+#include "eth-phy/mvEthPhy.h"
+#ifdef CONFIG_MV_DRAM_STATS_CNTRS
+#include "ddr2/mvDramCounters.h"
+#endif /*  */
+#ifdef CONFIG_MV_CPU_PERF_CNTRS
+MV_CPU_CNTRS_EVENT *proc_event = NULL;
+#endif /*  */
+
+#ifdef CONFIG_MV_CPU_L2_PERF_CNTRS
+MV_CPU_L2_CNTRS_EVENT *proc_l2_event = NULL;
+#endif /*  */
+
+/* global variables from 'regdump' */
+static struct proc_dir_entry *evb_resource_dump;
+static u32 evb_resource_dump_request, evb_resource_dump_result;
+
+/* Some service routines */
+static int ishex(char ch)
+{
+	if (((ch >= '0') && (ch <= '9')) || ((ch >= 'a') && (ch <= 'f')) || ((ch >= 'A') && (ch <= 'F')))
+		return 1;
+	return 0;
+}
+
+static int hex_value(char ch)
+{
+	if ((ch >= '0') && (ch <= '9'))
+		return ch - '0';
+	if ((ch >= 'a') && (ch <= 'f'))
+		return ch - 'a' + 10;
+	if ((ch >= 'A') && (ch <= 'F'))
+		return ch - 'A' + 10;
+	return 0;
+}
+
+static int atoh(char *s, int len)
+{
+	int i = 0;
+	while (ishex(*s) && len--) {
+		i = i * 0x10 + hex_value(*s);
+		s++;
+	}
+	return i;
+}
+
+
+#ifdef CONFIG_MV_CPU_PERF_CNTRS
+void mv_proc_start_cntrs(int cc0, int cc1, int cc2, int cc3)
+{
+	printk(KERN_NOTICE "configure CPU counters %d %d %d %d \n", cc0, cc1, cc2, cc3);
+	if (mvCpuCntrsProgram(0, cc0, "cc0", 0) != MV_OK)
+		goto error;
+	if (mvCpuCntrsProgram(1, cc1, "cc1", 0) != MV_OK)
+		goto error;
+	if (mvCpuCntrsProgram(2, cc2, "cc2", 0) != MV_OK)
+		goto error;
+	if (mvCpuCntrsProgram(3, cc3, "cc3", 0) != MV_OK)
+		goto error;
+	if (proc_event == NULL) {
+		proc_event = mvCpuCntrsEventCreate("PROC_CPU_CNTRS", 1);
+		if (proc_event == NULL)
+			goto error;
+	}
+	mvCpuCntrsEventClear(proc_event);
+	mvCpuCntrsReset();
+	MV_CPU_CNTRS_START(proc_event);
+	return;
+error:printk(KERN_NOTICE "ERROR configuring counter\n");
+	return;
+}
+
+void mv_proc_show_cntrs(void)
+{
+	if (proc_event != NULL) {
+		MV_CPU_CNTRS_STOP(proc_event);
+		MV_CPU_CNTRS_SHOW(proc_event);
+	}
+}
+
+#endif /*  */
+#ifdef CONFIG_MV_CPU_L2_PERF_CNTRS
+void mv_proc_start_l2_cntrs(int l20, int l21)
+{
+	printk(KERN_NOTICE "configure CPU L2 counters %d %d \n", l20, l21);
+	if (mvCpuL2CntrsProgram(0, l20, "l20", 0) != MV_OK)
+		goto error;
+	if (mvCpuL2CntrsProgram(1, l21, "l21", 0) != MV_OK)
+		goto error;
+	if (proc_l2_event == NULL) {
+		proc_l2_event = mvCpuL2CntrsEventCreate("PROC_CPU_L2_CNTRS", 1);
+		if (proc_l2_event == NULL)
+			goto error;
+	}
+	mvCpuL2CntrsEventClear(proc_l2_event);
+	mvCpuL2CntrsReset();
+	MV_CPU_L2_CNTRS_START(proc_l2_event);
+	return;
+error:printk(KERN_NOTICE "ERROR configuring L2 counter\n");
+	return;
+}
+
+void mv_proc_show_l2_cntrs(void)
+{
+	if (proc_l2_event != NULL) {
+		MV_CPU_L2_CNTRS_STOP(proc_l2_event);
+		MV_CPU_L2_CNTRS_SHOW(proc_l2_event);
+	}
+}
+
+#endif /*  */
+
+#ifdef CONFIG_MV_DRAM_STATS_CNTRS
+void mv_proc_start_dram_stats_cntrs(int mode0, int mode1)
+{
+	printk(KERN_NOTICE "configure DRAM statistics counters %d %d \n", mode0, mode1);
+	mvDramStatStop();
+	mvDramStatClear();
+	mvDramStatConfig(0, mode0);
+	mvDramStatConfig(1, mode1);
+	mvDramStatStart();
+	return;
+}
+
+void mv_proc_show_dram_stats_cntrs(void)
+{
+	MV_U64 cnt0, cnt1, hclk;
+	mvDramStatRead(&cnt0, &cnt1, &hclk);
+	printk(KERN_NOTICE "Counter #0 - 0x%llx.\n", cnt0);
+	printk(KERN_NOTICE "Counter #1 - 0x%llx.\n", cnt1);
+	printk(KERN_NOTICE "HCLK       - 0x%llx.\n", hclk);
+	return;
+}
+
+
+#endif /*  */
+/* The format of writing to this module is as follows -
+   char 0 - r/w (Reading from register or Writing to register/memory)
+   char 1 - space
+   char 2 - register/mem_addr offset 7
+   char 3 - register/mem_addr offset 6
+   char 4 - register/mem_addr offset 5
+   char 5 - register/mem_addr offset 4
+   char 6 - register/mem_addr offset 3
+   char 7 - register/mem_addr offset 2
+   char 8 - register/mem_addr offset 1
+   char 9 - register/mem_addr offset 0
+   // The following is valid only if write request
+   char 10 - space
+   char 11 - register/mem_addr value 7
+   char 12 - register/mem_addr value 6
+   char 13 - register/mem_addr value 5
+   char 14 - register/mem_addr value 4
+   char 15 - register/mem_addr value 3
+   char 16 - register/mem_addr value 2
+   char 17 - register/mem_addr value 1
+   char 18 - register/mem_addr value 0
+
+*/
+/********************************************************************
+* evb_resource_dump_write -
+*
+* When written to the /proc/resource_dump file this function is called
+*
+* Inputs: file / data are not used. Buffer and count are the pointer
+*         and length of the input string
+* Returns: Read from GT register
+* Outputs: count
+*********************************************************************/
+unsigned int kernel_align = 0;
+extern unsigned int support_wait_for_interrupt;
+int evb_resource_dump_write(struct file *file, const char *buffer, unsigned long count, void *data)
+{
+
+	    /* Reading / Writing from system controller internal registers */
+	    if (!strncmp(buffer, "register", 8)) {
+		if (buffer[10] == 'r') {
+			evb_resource_dump_request = atoh((char *)((unsigned int)buffer + 12), 8);
+			evb_resource_dump_result = MV_REG_READ(evb_resource_dump_request);
+		}
+		if (buffer[10] == 'w') {
+			evb_resource_dump_request = atoh((char *)((unsigned int)buffer + 12), 8);
+			evb_resource_dump_result = atoh((char *)((unsigned int)buffer + 12 + 8 + 1), 8);
+			MV_REG_WRITE(evb_resource_dump_request, evb_resource_dump_result);
+		}
+	}
+
+	    /* Reading / Writing from 32bit address - mostly usable for memory */
+	    if (!strncmp(buffer, "memory  ", 8)) {
+		if (buffer[10] == 'r') {
+			evb_resource_dump_request = atoh((char *)((unsigned int)buffer + 12), 8);
+			evb_resource_dump_result = *(unsigned int *)evb_resource_dump_request;
+		}
+		if (buffer[10] == 'w') {
+			evb_resource_dump_request = atoh((char *)((unsigned int)buffer + 12), 8);
+			evb_resource_dump_result = atoh((char *)((unsigned int)buffer + 12 + 8 + 1), 8);
+			*(unsigned int *)evb_resource_dump_request = evb_resource_dump_result;
+		}
+	}
+
+	    /* Reading / Writing from a rgister via SMI */
+	    if (!strncmp(buffer, "smi", 3)) {
+		unsigned short regVal;
+		unsigned int dev_addr = atoh((char *)((unsigned int)buffer + 7), 8);
+		if (buffer[5] == 'r') {
+			evb_resource_dump_request = atoh((char *)((unsigned int)buffer + 7 + 8 + 1), 8);
+			regVal = 0;
+			mvEthPhyRegRead(dev_addr, evb_resource_dump_request, &regVal);
+			evb_resource_dump_result = (u32) regVal;
+		}
+		if (buffer[5] == 'w') {
+			evb_resource_dump_request = atoh((char *)((unsigned int)buffer + 7 + 8 + 1), 8);
+			evb_resource_dump_result = atoh((char *)((unsigned int)buffer + 7 + 8 + 8 + 2), 8);
+			mvEthPhyRegWrite(dev_addr, evb_resource_dump_request, (u16) evb_resource_dump_result);
+		}
+	}
+
+#ifdef CONFIG_MV_CPU_PERF_CNTRS
+	    if (!strncmp(buffer, "start_cc", 8)) {
+		int cc0, cc1, cc2, cc3;
+		sscanf((char *)((unsigned int)buffer + 8), "%d %d %d %d", &cc0, &cc1, &cc2, &cc3);
+		mv_proc_start_cntrs(cc0, cc1, cc2, cc3);
+	}
+	if (!strncmp(buffer, "show__cc", 8))
+		mv_proc_show_cntrs();
+#endif /*  */
+#ifdef CONFIG_MV_CPU_L2_PERF_CNTRS
+	if (!strncmp(buffer, "start_l2", 8)) {
+		int l20, l21;
+		sscanf((char *)((unsigned int)buffer + 8), "%d %d", &l20, &l21);
+		mv_proc_start_l2_cntrs(l20, l21);
+	}
+	if (!strncmp(buffer, "show__l2", 8))
+		mv_proc_show_l2_cntrs();
+#endif /*  */
+
+#ifdef CONFIG_MV_DRAM_STATS_CNTRS
+	if (!strncmp(buffer, "start_dram_stats", strlen("start_dram_stats"))) {
+		int mode0, mode1;
+		sscanf((char *)((unsigned int)buffer + strlen("start_dram_stats")), "%d %d", &mode0, &mode1);
+		mv_proc_start_dram_stats_cntrs(mode0, mode1);
+	}
+	if (!strncmp(buffer, "stop_dram_stats", strlen("stop_dram_stats")))
+		mvDramStatStop();
+
+	if (!strncmp(buffer, "show_dram_stats", strlen("show_dram_stats")))
+		mv_proc_show_dram_stats_cntrs();
+
+#endif /*  */
+	    if (!strncmp(buffer, "idle_wfi", strlen("idle_wfi"))) {
+		int en;
+		sscanf((char *)((unsigned int)buffer + strlen("idle_wfi")), "%d", &en);
+		support_wait_for_interrupt = en;
+	}
+	if (!strncmp(buffer, "show__ua", 8)) {
+		if (kernel_align == 1)
+			kernel_align = 0;
+
+		else
+			kernel_align = 1;
+		printk(KERN_DEBUG "debug kernel align %d\n", kernel_align);
+	}
+
+#if 0
+	    if (!strncmp(buffer, "ddd", 3)) {
+		unsigned int ii[10];
+		int ip, sum = 0;
+		volatile unsigned int *tt = (unsigned int *)((unsigned int)ii + 2);
+		MV_CPU_CNTRS_EVENT *hal_rx_event = NULL;
+
+		/* 0 - instruction counters */
+		mvCpuCntrsProgram(0, MV_CPU_CNTRS_INSTRUCTIONS, "Instr", 25);
+
+		/* 1 - ICache misses counter */
+		mvCpuCntrsProgram(1, MV_CPU_CNTRS_ICACHE_READ_MISS, "IcMiss", 0);
+
+		/* 2 - cycles counter */
+		mvCpuCntrsProgram(2, MV_CPU_CNTRS_CYCLES, "Cycles", 21);
+
+		/* 3 - DCache read misses counter */
+		mvCpuCntrsProgram(3, MV_CPU_CNTRS_DCACHE_READ_MISS, "DcRdMiss", 0);
+		hal_rx_event = mvCpuCntrsEventCreate("HAL_RX", 1);
+		MV_CPU_CNTRS_START(hal_rx_event);
+		for (ip = 0; ip < 1000; ip++)
+			sum += *tt;
+		MV_CPU_CNTRS_STOP(hal_rx_event);
+		MV_CPU_CNTRS_SHOW(hal_rx_event);
+	}
+#endif /*  */
+	return count;
+}
+
+
+/********************************************************************
+* evb_resource_dump_read -
+*
+* When read from the /proc/resource_dump file this function is called
+*
+* Inputs: buffer_location and buffer_length and zero are not used.
+*         buffer is the pointer where to post the result
+* Returns: N/A
+* Outputs: length of string posted
+*********************************************************************/
+int evb_resource_dump_read(char *buffer, char **buffer_location, off_t offset, int buffer_length, int *zero, void *ptr)
+{
+	if (offset > 0)
+		return 0;
+	return sprintf(buffer, "%08x\n", evb_resource_dump_result);
+}
+
+
+/********************************************************************
+* start_regdump_memdump -
+*
+* Register the /proc/regdump file at the /proc filesystem
+* Register the /proc/memdump file at the /proc filesystem
+*
+* Inputs: N/A
+* Returns: N/A
+* Outputs: N/A
+*********************************************************************/
+int __init start_resource_dump(void)
+{
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26)
+	evb_resource_dump = create_proc_entry("resource_dump", 0666, &proc_root);
+
+#else /*  */
+	evb_resource_dump = create_proc_entry("resource_dump", 0666, NULL);
+
+#endif /*  */
+	evb_resource_dump->read_proc = evb_resource_dump_read;
+	evb_resource_dump->write_proc = evb_resource_dump_write;
+	evb_resource_dump->nlink = 1;
+	return 0;
+}
+
+module_init(start_resource_dump);
+
+/* global variables from 'regdump' */
+static struct proc_dir_entry *soc_type;
+static struct proc_dir_entry *board_type;
+
+/********************************************************************
+* soc_type_read -
+*********************************************************************/
+int soc_type_read(char *buffer, char **buffer_location, off_t offset, int buffer_length, int *zero, void *ptr)
+{
+	int count = 0;
+	char tmp_buffer[1000] = { 0 };
+
+#ifdef CONFIG_ARCH_FEROCEON_MV78XX0
+	char name[100] = { 0 };
+
+#endif /*  */
+	if (offset > 0)
+		return 0;
+
+#ifdef CONFIG_ARCH_FEROCEON_MV78XX0
+	mvCtrlModelRevNameGet(name);
+	count += sprintf(tmp_buffer, "%s\n", name);
+
+#endif /*  */
+#ifdef CONFIG_MV88F6281
+	count += sprintf(tmp_buffer, "%s%x Rev %d\n", SOC_NAME_PREFIX, mvCtrlModelGet(), mvCtrlRevGet());
+
+#endif /*  */
+	count += mvCpuIfPrintSystemConfig(tmp_buffer, count);
+	*(tmp_buffer + count) = '\0';
+	sprintf(buffer, "%s", tmp_buffer);
+	return count;
+}
+
+/********************************************************************
+* board_type_read -
+*********************************************************************/
+int board_type_read(char *buffer, char **buffer_location, off_t offset, int buffer_length, int *zero, void *ptr)
+{
+	char name_buff[50];
+	if (offset > 0)
+		return 0;
+	mvBoardNameGet(name_buff);
+	return sprintf(buffer, "%s\n", name_buff);
+}
+
+
+/********************************************************************
+* start_soc_type -
+*********************************************************************/
+int __init start_soc_type(void)
+{
+	struct proc_dir_entry *parent;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26)
+	    parent = &proc_root;
+
+#else /*  */
+	    parent = NULL;
+
+#endif /*  */
+	soc_type = create_proc_entry("soc_type", 0666, parent);
+	soc_type->read_proc = soc_type_read;
+	soc_type->write_proc = NULL;
+	soc_type->nlink = 1;
+	board_type = create_proc_entry("board_type", 0666, parent);
+	board_type->read_proc = board_type_read;
+	board_type->write_proc = NULL;
+	board_type->nlink = 1;
+	return 0;
+}
+
+void __exit stop_soc_type(void)
+{
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26)
+	remove_proc_entry("soc_type", &proc_root);
+
+#else /*  */
+	remove_proc_entry("soc_type", NULL);
+
+#endif /*  */
+	return;
+}
+
+module_init(start_soc_type);
+module_exit(stop_soc_type);
+
+#include <fs/read_write.h>
+
+#ifdef COLLECT_WRITE_SOCK_TO_FILE_STAT
+static struct proc_dir_entry *write_from_sock_stat;
+extern struct write_sock_to_file_stat write_from_sock;
+
+/********************************************************************
+*write_from_sock_read -
+*********************************************************************/
+int write_from_sock_read (char *buffer, char **buffer_location, off_t offset,
+                            int buffer_length, int *zero, void *ptr) {
+	int count = 0;
+	char tmp_buffer[1000] = {0};
+	if (offset > 0)
+		return 0;
+
+	count += sprintf(tmp_buffer + count, "Total errors               %ld\n", write_from_sock.errors);
+	count += sprintf(tmp_buffer + count, "Buffers up to 4K           %ld\n", write_from_sock.buf_4k);
+	count += sprintf(tmp_buffer + count, "Buffers from 4K to 8K      %ld\n", write_from_sock.buf_8k);
+	count += sprintf(tmp_buffer + count, "Buffers from 8K to 16K     %ld\n", write_from_sock.buf_16k);
+	count += sprintf(tmp_buffer + count, "Buffers from 16K to 32K    %ld\n", write_from_sock.buf_32k);
+	count += sprintf(tmp_buffer + count, "Buffers from 32K to 64K    %ld\n", write_from_sock.buf_64k);
+	count += sprintf(tmp_buffer + count, "Buffers greater than 64K   %ld\n", write_from_sock.buf_128k);
+
+	*(tmp_buffer+count) = '\0';
+	sprintf(buffer, "%s", tmp_buffer);
+
+	return count;
+}
+
+/********************************************************************
+* start_write_from_sock_stat -
+*********************************************************************/
+int __init start_write_from_sock_stat(void)
+{
+	struct proc_dir_entry *parent;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26)
+	parent = &proc_root;
+#else
+	parent = NULL;
+#endif
+	write_from_sock_stat = create_proc_entry ("write_from_sock_stat" , 0666 , parent);
+	write_from_sock_stat->read_proc =write_from_sock_read;
+	write_from_sock_stat->write_proc = NULL;
+	write_from_sock_stat->nlink = 1;
+
+  return 0;
+}
+/********************************************************************
+* stop_write_from_sock_stat -
+*********************************************************************/
+void __exit stop_write_from_sock_stat(void)
+{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26)
+	remove_proc_entry("write_from_sock_stat",  &proc_root);
+#else
+	remove_proc_entry("write_from_sock_stat",  NULL);
+#endif
+	return;
+}
+ 
+module_init(start_write_from_sock_stat);
+module_exit(stop_write_from_sock_stat);
+#endif /* COLLECT_WRITE_SOCK_TO_FILE_STAT */
+
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/Kconfig
new file mode 100644
index 0000000..fc8a105
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/Kconfig
@@ -0,0 +1,34 @@
+menu "Sata options"
+	depends on SCSI_MVSATA
+	depends on BLOCK
+	
+config  MV_SATA_SUPPORT_ATAPI
+        bool "Support ATAPI (CR-ROM/DVD-ROM) devices"
+        default n
+
+config  MV_SATA_ENABLE_1MB_IOS
+        bool "Enable 1 MByte requests"
+        default n
+        help
+          Set the maximum io request size to 1 MByte for HDD's the support LBA48 feature,
+          say No if you want to keep the maximum limit on 128KBytes.
+choice
+	prompt "Debug level"
+	default SATA_NO_DEBUG
+
+config SATA_NO_DEBUG
+	bool "No Debug"
+
+config SATA_DEBUG_ON_ERROR
+	bool "Debug on errors"
+	help
+	  print debug messages when EDMA/System/HDD errors occur.
+
+config SATA_FULL_DEBUG
+	bool "Full debug"
+
+endchoice
+
+endmenu
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/Makefile
new file mode 100644
index 0000000..287f3be
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/Makefile
@@ -0,0 +1,19 @@
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+IAL_OBJS        := mvLinuxIalLib.o mvLinuxIalHt.o mvLinuxIalOs.o mvIALCommon.o mvIALCommonUtils.o mvLinuxIalSmart.o
+SAL_OBJS        := mvScsiAtaLayer.o
+
+obj-$(CONFIG_SCSI_MVSATA) := mvsata.o
+mvsata-y        := $(IAL_OBJS) $(SAL_OBJS) ../../$(HAL_SATA_DIR)/mvSata.o ../../$(HAL_SATA_DIR)/mvStorageDev.o		\
+                  ../../$(HAL_SATA_DIR)/mvLog.o
+
+
+
+INCLUDE_DIRS    := -Idrivers/scsi
+EXTRA_CFLAGS += -DLINUX -D__LINUX__ $(INCLUDE_DIRS)
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommon.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommon.c
new file mode 100644
index 0000000..665a5f3
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommon.c
@@ -0,0 +1,2621 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* mvIALCommon.c
+*
+* DESCRIPTION:
+*       C implementation for IAL's common functions.
+*
+* DEPENDENCIES:
+*   mvIALCommon.h
+*
+*******************************************************************************/
+
+/* includes */
+#include "mvOs.h"
+#include "mvScsiAtaLayer.h"
+#include "mvIALCommon.h"
+#include "mvIALCommonUtils.h"
+#include "mvStorageDev.h"
+
+
+MV_BOOLEAN disableNCQ = MV_FALSE;
+MV_BOOLEAN disablePM_NCQ = MV_FALSE;
+/* defines */
+#undef DISABLE_PM_SCC
+/* typedefs */
+
+/*Static functions*/
+static MV_BOOLEAN mvGetDisksModes(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                  MV_SAL_ADAPTER_EXTENSION *pScsiAdapterExt,
+                                  MV_U8 channelIndex,
+                                  MV_BOOLEAN *TCQ,
+                                  MV_BOOLEAN *NCQ,
+                                  MV_U8   *numOfDrives);
+
+static void mvFlushSCSICommandQueue(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                    MV_U8 channelIndex);
+
+static void mvAddToSCSICommandQueue(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                    MV_U8 channelIndex,
+                                    MV_SATA_SCSI_CMD_BLOCK *Scb);
+
+static MV_BOOLEAN mvAdapterStateMachine(
+                                       MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                       MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt);
+
+static MV_BOOLEAN mvChannelStateMachine(
+                                       MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                       MV_U8 channelIndex,
+                                       MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt);
+
+static void mvSetChannelState(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                              MV_U8 channelIndex,
+                              MV_CHANNEL_STATE state);
+
+static MV_BOOLEAN clearSErrorPorts(MV_SATA_ADAPTER *pSataAdapter, MV_U8 channelIndex, 
+				   MV_U8     PMnumberOfPorts);
+/*PM related*/
+static MV_BOOLEAN mvPMCommandCompletionCB(MV_SATA_ADAPTER *pSataAdapter,
+                                          MV_U8 channelIndex,
+                                          MV_COMPLETION_TYPE comp_type,
+                                          MV_VOID_PTR commandId,
+                                          MV_U16 responseFlags,
+                                          MV_U32 timeStamp,
+                                          MV_STORAGE_DEVICE_REGISTERS *registerStruct);
+
+
+static MV_BOOLEAN mvQueuePMAccessRegisterCommand(
+                                                MV_IAL_COMMON_ADAPTER_EXTENSION* ialExt,
+                                                MV_U8 channelIndex,
+                                                MV_U8 PMPort,
+                                                MV_U8 PMReg,
+                                                MV_U32 Value,
+                                                MV_BOOLEAN isRead);
+
+static MV_BOOLEAN mvPMEnableCommStatusChangeBits(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                                 MV_U8 channelIndex,
+                                                 MV_BOOLEAN enable);
+
+static MV_BOOLEAN mvPMEnableAsyncNotify(
+                                       MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                       MV_U8 channelIndex);
+
+#if 0
+static void mvCheckPMForError(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                              MV_U8 channelIndex);
+#endif
+
+/*End PM related*/
+
+static MV_BOOLEAN mvStartChannelInit(MV_SATA_ADAPTER *pSataAdapter,
+                                     MV_U8 channelIndex,
+                                     MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt,
+                                     MV_BOOLEAN *isChannelReady);
+
+static MV_BOOLEAN mvChannelSRSTFinished(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                        MV_SATA_CHANNEL *pSataChannel,
+                                        MV_U8 channelIndex,
+                                        MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt,
+                                        MV_BOOLEAN* bIsChannelReady,
+                                        MV_BOOLEAN* bFatalError);
+
+static MV_BOOLEAN mvConfigChannelQueuingMode(
+                                            MV_IAL_COMMON_ADAPTER_EXTENSION* ialExt,
+                                            MV_U8 channelIndex,
+                                            MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt);
+
+static MV_BOOLEAN mvConfigChannelDMA(
+                                    MV_IAL_COMMON_ADAPTER_EXTENSION* ialExt,
+                                    MV_U8 channelIndex,
+                                    MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt);
+
+static void mvSetChannelTimer(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                              MV_U8 channelIndex,
+                              MV_U32 timeout);
+static void mvDecrementChannelTimer(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                    MV_U8 channelIndex);
+static MV_BOOLEAN mvIsChannelTimerExpired(
+                                         MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                         MV_U8 channelIndex);
+
+
+/*Channel state machine*/
+
+
+static MV_BOOLEAN mvChannelNotConnectedStateHandler(
+                                                   MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                                   MV_U8 channelIndex,
+                                                   MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt);
+
+
+static MV_BOOLEAN mvChannelConnectedStateHandler(
+                                                MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                                MV_U8 channelIndex,
+                                                MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt);
+
+MV_BOOLEAN mvChannelInSrstStateHandler(
+                                      MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                      MV_U8 channelIndex,
+                                      MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt);
+
+static MV_BOOLEAN mvPMInitDevicesStateHandler(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+					      MV_U8 channelIndex,
+					      MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt);
+
+static MV_BOOLEAN mvChannelReadyStateHandler(
+                                            MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                            MV_U8 channelIndex);
+
+static MV_BOOLEAN mvChannelPMHotPlugStateHandler(
+                                                MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                                MV_U8 channelIndex,
+                                                MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt);
+
+
+
+static void mvDrivesInfoSaveAll(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                MV_U8 channelIndex);
+
+static void mvDrivesInfoFlushAll(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                 MV_U8 channelIndex);
+
+static void mvDrivesInfoFlushSingleDrive(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                         MV_U8 channelIndex, MV_U8 PMPort);
+
+static void mvDrivesInfoSaveSingleDrive(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                        MV_U8 channelIndex,
+                                        MV_U8 PMPort,
+                                        MV_BOOLEAN  isDriveAdded,
+                                        MV_U16_PTR identifyBuffer);
+
+static void mvSetDriveReady(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                            MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt,
+                            MV_U8 channelIndex,
+                            MV_U8 PMPort,
+                            MV_BOOLEAN  isReady,
+                            MV_U16_PTR identifyBuffer);
+
+static void mvDrivesInfoGetChannelRescanParams(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                               MV_U8 channelIndex,
+                                               MV_U16 *drivesToRemove,
+                                               MV_U16 *drivesToAdd);
+
+
+
+#ifdef DISABLE_PM_SCC
+MV_BOOLEAN mvPMDisableSSC(MV_SATA_ADAPTER *pSataAdapter, MV_U8 channelIndex);
+#endif
+
+MV_BOOLEAN mvPMEnableLocking(MV_SATA_ADAPTER *pSataAdapter, MV_U8 channelIndex);
+
+
+
+/*Public functions*/
+
+/*******************************************************************************
+* mvAdapterStartInitialization - start adapter initialization
+*
+* DESCRIPTION:
+*  Starts adapter initialization after driver load.
+*  State - machine related data structure is initialized for adapter
+*  and its channels. Begin staggered spin-up.
+*  Adapter state is changed to ADAPTER_READY.
+* INPUT:
+*    pAdapter    - pointer to the adapter data structure.
+*    scsiAdapterExt  - SCSI to ATA layer adapter extension data structure
+* OUTPUT:
+*    None.
+*
+* RETURN:
+*    MV_TRUE on success
+*    MV_FALSE on error
+*
+*******************************************************************************/
+
+MV_BOOLEAN mvAdapterStartInitialization(MV_SATA_ADAPTER *pSataAdapter,
+                                        MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                        MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt)
+{
+    MV_U8 channelIndex;
+    ialExt->pSataAdapter = pSataAdapter;
+    ialExt->adapterState = ADAPTER_INITIALIZING;
+    for (channelIndex = 0; channelIndex < MV_SATA_CHANNELS_NUM; channelIndex++)
+    {
+        ialExt->channelState[channelIndex] = CHANNEL_NOT_CONNECTED;
+        ialExt->IALChannelExt[channelIndex].SRSTTimerThreshold = 0;
+        ialExt->IALChannelExt[channelIndex].SRSTTimerValue = 0;
+        ialExt->IALChannelExt[channelIndex].IALChannelPendingCmdQueue = NULL;
+        ialExt->IALChannelExt[channelIndex].completionError = MV_FALSE;
+        ialExt->IALChannelExt[channelIndex].pmRegAccessInProgress = MV_FALSE;
+        ialExt->IALChannelExt[channelIndex].pmRegPollCounter = 0;
+        ialExt->IALChannelExt[channelIndex].devInSRST =
+        MV_SATA_PM_CONTROL_PORT + 1;
+        ialExt->IALChannelExt[channelIndex].PMdevsToInit = 0;
+        ialExt->IALChannelExt[channelIndex].PMnumberOfPorts = 0;
+        ialExt->IALChannelExt[channelIndex].pmAccessType = 0;
+        ialExt->IALChannelExt[channelIndex].pmReg = 0;
+        ialExt->IALChannelExt[channelIndex].pmAsyncNotifyEnabled = MV_FALSE;
+        ialExt->IALChannelExt[channelIndex].bHotPlug = MV_FALSE;
+        memset(&ialExt->IALChannelExt[channelIndex].drivesInfo, 0, sizeof(MV_DRIVES_INFO));
+    }
+    return mvAdapterStateMachine(ialExt, scsiAdapterExt);
+}
+
+
+/*******************************************************************************
+* mvRestartChannel - restart specific channel
+*
+* DESCRIPTION:
+*  The function is used in channel hot-plug to restart the channel
+*  initialization sequence. The channel stated is changed to
+*  CHANNEL_CONNECTED and any pending command in software queue are flushed
+* INPUT:
+*    pAdapter    - pointer to the adapter data structure.
+*    channelIndex  - channel number
+*    scsiAdapterExt  - SCSI to ATA layer adapter extension data structure
+*    bBusReset       - MV_TRUE if the faunction is called because of bus reset,
+*                       MV_FALSE otherwise
+* OUTPUT:
+*    None.
+*
+* RETURN:
+*    MV_TRUE on success
+*    MV_FALSE on error
+*
+*******************************************************************************/
+
+void mvRestartChannel(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                      MV_U8 channelIndex,
+                      MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt,
+                      MV_BOOLEAN bBusReset)
+{
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+    MV_BOOLEAN bBusChangeNotify = MV_FALSE;
+    ialExt->IALChannelExt[channelIndex].bHotPlug = MV_TRUE;
+    mvSetDriveReady(ialExt,
+                    scsiAdapterExt,
+                    channelIndex, 0xFF, MV_FALSE, NULL);
+    if (pSataAdapter->sataChannel[channelIndex] != NULL)
+    {
+        if (mvStorageDevGetDeviceType(pSataAdapter,channelIndex)
+            == MV_SATA_DEVICE_TYPE_PM)
+        {
+            bBusChangeNotify = MV_TRUE;
+        }
+        mvSataDisableChannelDma(pSataAdapter, channelIndex);
+        mvSataFlushDmaQueue (pSataAdapter, channelIndex,
+                             MV_FLUSH_TYPE_CALLBACK);
+    }
+    mvFlushSCSICommandQueue(ialExt, channelIndex);
+    ialExt->IALChannelExt[channelIndex].SRSTTimerThreshold = 0;
+    ialExt->IALChannelExt[channelIndex].SRSTTimerValue = 0;
+    ialExt->channelState[channelIndex] = CHANNEL_CONNECTED;
+    if (bBusReset == MV_TRUE)
+    {
+        if (bBusChangeNotify == MV_TRUE)
+        {
+            /*Notify about bus change*/
+            IALBusChangeNotify(pSataAdapter, channelIndex);
+        }
+    }
+    else
+    {
+        /*Notify about bus change*/
+        IALBusChangeNotify(pSataAdapter, channelIndex);
+    }
+}
+
+
+
+/*******************************************************************************
+* mvPMHotPlugDetected - restart specific channel
+*
+* DESCRIPTION:
+*  The function is used in PM hot-plug to wait for empty EDMA command queue
+*  and then restart the channel initialization sequence.
+*  The channel stated is changed to CHANNEL_PM_HOT_PLUG if there are any
+*  pending command in EDMA queue
+* INPUT:
+*    pAdapter    - pointer to the adapter data structure.
+*    channelIndex  - channel number
+
+* OUTPUT:
+*    None.
+*
+* RETURN:
+*    None
+*
+*******************************************************************************/
+
+void mvPMHotPlugDetected(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                         MV_U8 channelIndex,
+                         MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt)
+{
+    if (ialExt->channelState[channelIndex] == CHANNEL_NOT_CONNECTED ||
+        ialExt->channelState[channelIndex] == CHANNEL_CONNECTED ||
+        ialExt->channelState[channelIndex] == CHANNEL_IN_SRST)
+    {
+        return;
+    }
+    mvSataDisableChannelDma(ialExt->pSataAdapter, channelIndex);
+    mvSataFlushDmaQueue (ialExt->pSataAdapter,
+                         channelIndex, MV_FLUSH_TYPE_CALLBACK);
+    mvSataChannelHardReset(ialExt->pSataAdapter, channelIndex);
+    mvRestartChannel(ialExt, channelIndex, scsiAdapterExt, MV_FALSE);
+}
+
+/*******************************************************************************
+* mvStopChannel - stop channel
+*
+* DESCRIPTION:
+*  The function is used when the channel is unplugged.
+*  The channel stated is changed to CHANNEL_NOT_CONNECTED
+*  until further connection.
+* INPUT:
+*    pAdapter    - pointer to the adapter data structure.
+*    channelIndex  - channel number
+* OUTPUT:
+*    None.
+*
+* RETURN:
+*    None
+*******************************************************************************/
+void mvStopChannel(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                   MV_U8 channelIndex,
+                   MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt)
+{
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+    MV_U16 drivesSnapshot =
+    ialExt->IALChannelExt[channelIndex].drivesInfo.drivesSnapshotSaved;
+    mvDrivesInfoFlushAll(ialExt, channelIndex);
+    mvSetDriveReady(ialExt, scsiAdapterExt, channelIndex, 0xFF, MV_FALSE, NULL);
+    mvSetChannelState(ialExt, channelIndex, CHANNEL_NOT_CONNECTED);
+    if (pSataAdapter->sataChannel[channelIndex] != NULL)
+    {
+        mvSataDisableChannelDma(ialExt->pSataAdapter, channelIndex);
+        mvSataFlushDmaQueue (ialExt->pSataAdapter, channelIndex,
+                             MV_FLUSH_TYPE_CALLBACK);
+    }
+    mvFlushSCSICommandQueue(ialExt, channelIndex);
+    if (pSataAdapter->sataChannel[channelIndex] != NULL)
+    {
+        mvSataRemoveChannel(pSataAdapter,channelIndex);
+        IALReleaseChannel(pSataAdapter, channelIndex);
+    }
+    pSataAdapter->sataChannel[channelIndex] = NULL;
+    /*Notify about bus change*/
+    IALBusChangeNotify(pSataAdapter, channelIndex);
+    if (drivesSnapshot != 0)
+    {
+        IALBusChangeNotifyEx(pSataAdapter, channelIndex, drivesSnapshot, 0);
+    }
+}
+
+
+/*******************************************************************************
+* mvExecuteScsiCommand - execute SCSI command
+*
+* DESCRIPTION:
+*  IAL common layer wrapper of mvSataExecuteScsiCommand function.
+*  If either the adapter state is either other than ADAPTER_READY
+*  or the channel is connected but channel state is not CHANNEL_READY,
+*  the current SCSI command is queued in channel's SCSI commands
+*  software queue until channel initialization sequence completed.
+*  If channel is found in CHANNEL ready state the SCSI command is passed to
+*  SCSI ATA translation layer.
+* INPUT:
+*    pScb    - SCSI command block structure.
+*
+* OUTPUT:
+*    None.
+*
+* RETURN:
+*    Return MV_SCSI_COMMAND_STATUS_COMPLETED if the command has been added
+*    to channel software queue. Otherwise return the result of
+*    mvSataExecuteScsiCommand function call
+*******************************************************************************/
+MV_SCSI_COMMAND_STATUS_TYPE mvExecuteScsiCommand(MV_SATA_SCSI_CMD_BLOCK *pScb,
+                                                 MV_BOOLEAN canQueue)
+{
+    MV_IAL_COMMON_ADAPTER_EXTENSION* ialExt = pScb->pIalAdapterExtension;
+    MV_U8 channelIndex = pScb->bus;
+
+#if 0
+    if ((ialExt->adapterState == ADAPTER_READY) &&
+        (ialExt->channelState[channelIndex] == CHANNEL_READY))
+    {
+        mvCheckPMForError(ialExt, channelIndex);
+    }
+#endif
+
+    if ((ialExt->adapterState == ADAPTER_READY) &&
+        ((ialExt->channelState[channelIndex] == CHANNEL_READY) ||
+         (ialExt->channelState[channelIndex] == CHANNEL_NOT_CONNECTED)))
+    {
+        return mvSataExecuteScsiCommand(pScb);
+    }
+    if (canQueue == MV_FALSE)
+    {
+        pScb->ScsiStatus = MV_SCSI_STATUS_BUSY;
+        pScb->dataTransfered = 0;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_QUEUE_FULL;
+        if (pScb->completionCallBack)
+        {
+            pScb->completionCallBack(ialExt->pSataAdapter, pScb);
+        }
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+    else
+    {
+        mvAddToSCSICommandQueue(ialExt, channelIndex, pScb);
+        return MV_SCSI_COMMAND_STATUS_QUEUED_BY_IAL;
+    }
+}
+
+
+/*******************************************************************************
+* mvIALTimerCallback - IAL timer callback
+*
+* DESCRIPTION:
+*  The adapter/channel state machine is timer-driven.
+*  After being loaded, the IAL must call this callback every 0.5 seconds
+* INPUT:
+*    pSataAdapter    - pointer to the adapter data structure.
+*    scsiAdapterExt  - SCSI to ATA layer adapter extension data structure
+* OUTPUT:
+*    None.
+*
+* RETURN:
+*
+*******************************************************************************/
+
+MV_BOOLEAN mvIALTimerCallback(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                              MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt)
+{
+
+    return mvAdapterStateMachine(ialExt,
+                                 scsiAdapterExt);
+}
+
+/*******************************************************************************
+* mvCommandCompletionErrorHandler - IAL common command completion error handler
+*
+* DESCRIPTION:
+*  Called by whether SAL completion of SMART completion function. Check whether
+*  command is failed because of PM hot plug
+*
+* INPUT:
+*    pSataAdapter    - pointer to the adapter data structure.
+*    channelIndex    - channelNumber
+* OUTPUT:
+*    None.
+*
+* RETURN:
+*
+*******************************************************************************/
+
+void mvCommandCompletionErrorHandler(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                     MV_U8 channelIndex)
+{
+    MV_SATA_ADAPTER* pSataAdapter = ialExt->pSataAdapter;
+    if (pSataAdapter->sataChannel[channelIndex] == NULL)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: "
+                 "Invalid channel data structure pointer.\n",
+                 pSataAdapter->adapterId, channelIndex);
+    }
+
+    if ((ialExt->channelState[channelIndex] != CHANNEL_READY) ||
+        (mvStorageDevGetDeviceType(pSataAdapter,channelIndex) !=
+         MV_SATA_DEVICE_TYPE_PM) ||
+        (ialExt->IALChannelExt[channelIndex].pmAsyncNotifyEnabled == MV_TRUE))
+    {
+        return;
+    }
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: "
+             "Set completion error to MV_TRUE.\n",
+             pSataAdapter->adapterId, channelIndex);
+    ialExt->IALChannelExt[channelIndex].completionError = MV_TRUE;
+}
+
+/*Static functions*/
+
+
+static void printAtaDeviceRegisters(
+                                   MV_STORAGE_DEVICE_REGISTERS *mvStorageDevRegisters)
+{
+
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "ATA Drive Registers:\n");
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%20s : %04x\n","Error",
+             mvStorageDevRegisters->errorRegister);
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%20s : %04x\n","SectorCount",
+             mvStorageDevRegisters->sectorCountRegister);
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%20s : %04x\n","LBA Low",
+             mvStorageDevRegisters->lbaLowRegister);
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%20s : %04x\n","LBA Mid",
+             mvStorageDevRegisters->lbaMidRegister);
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%20s : %04x\n","LBA High",
+             mvStorageDevRegisters->lbaHighRegister);
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%20s : %04x\n","Device",
+             mvStorageDevRegisters->deviceRegister);
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%20s : %04x\n","Status",
+             mvStorageDevRegisters->statusRegister);
+}
+
+
+
+static void mvDrivesInfoSaveAll(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                MV_U8 channelIndex)
+{
+    /*Save disk drives information for channel*/
+    ialExt->IALChannelExt[channelIndex].drivesInfo.drivesSnapshotSaved =
+    ialExt->IALChannelExt[channelIndex].drivesInfo.drivesSnapshotCurrent;
+    memcpy(ialExt->IALChannelExt[channelIndex].drivesInfo.driveSerialSaved,
+           ialExt->IALChannelExt[channelIndex].drivesInfo.driveSerialCurrent,
+           sizeof(ialExt->IALChannelExt[channelIndex].drivesInfo.driveSerialCurrent));
+    /*Reset current disk drives information*/
+    ialExt->IALChannelExt[channelIndex].drivesInfo.drivesSnapshotCurrent = 0;
+    memset(ialExt->IALChannelExt[channelIndex].drivesInfo.driveSerialCurrent,
+           0,
+           sizeof(ialExt->IALChannelExt[channelIndex].drivesInfo.driveSerialCurrent));
+
+}
+
+static void mvDrivesInfoFlushAll(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                 MV_U8 channelIndex)
+{
+    /*Flush drives info*/
+    memset(&ialExt->IALChannelExt[channelIndex].drivesInfo, 0,
+           sizeof(ialExt->IALChannelExt[channelIndex].drivesInfo));
+}
+
+static void mvDrivesInfoFlushSingleDrive(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                         MV_U8 channelIndex, MV_U8 PMPort)
+{
+    /*Clear bit in disk drive drive snapshot*/
+    ialExt->IALChannelExt[channelIndex].drivesInfo.drivesSnapshotCurrent &=
+    ~(1 << PMPort);
+    ialExt->IALChannelExt[channelIndex].drivesInfo.drivesSnapshotSaved &=
+    ~(1 << PMPort);
+    /*Clear disk drive serial number string*/
+    ialExt->
+    IALChannelExt[channelIndex].drivesInfo.driveSerialSaved[PMPort].serial[0] = 0;
+    ialExt->
+    IALChannelExt[channelIndex].drivesInfo.driveSerialCurrent[PMPort].serial[0] = 0;
+}
+
+
+static void mvDrivesInfoSaveSingleDrive(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                        MV_U8 channelIndex,
+                                        MV_U8 PMPort,
+                                        MV_BOOLEAN  isDriveAdded,
+                                        MV_U16_PTR identifyBuffer)
+{
+    if (MV_TRUE == isDriveAdded)
+    {
+        /*Set bit in disk drive snapshot for current disk drive*/
+        ialExt->IALChannelExt[channelIndex].drivesInfo.drivesSnapshotCurrent |=
+        1 << PMPort;
+        /*Save serial number for current disk drive*/
+        memcpy(ialExt->IALChannelExt[channelIndex].drivesInfo.driveSerialCurrent[PMPort].serial,
+               &identifyBuffer[IDEN_SERIAL_NUM_OFFSET], IDEN_SERIAL_NUM_SIZE);
+    }
+    else
+    {
+        if (0xFF == PMPort)
+        {
+            ialExt->IALChannelExt[channelIndex].drivesInfo.drivesSnapshotCurrent
+            = 0;
+            memset(ialExt->IALChannelExt[channelIndex].drivesInfo.driveSerialCurrent,
+                   0,
+                   sizeof(ialExt->IALChannelExt[channelIndex].drivesInfo.driveSerialCurrent));
+        }
+        else
+        {
+            ialExt->IALChannelExt[channelIndex].drivesInfo.drivesSnapshotCurrent
+            &= ~(1 << PMPort);
+            ialExt->IALChannelExt[channelIndex].drivesInfo.driveSerialCurrent[PMPort].serial[0] = 0;
+        }
+    }
+}
+
+static void mvSetDriveReady(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                            MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt,
+                            MV_U8 channelIndex,
+                            MV_U8 PMPort,
+                            MV_BOOLEAN  isReady,
+                            MV_U16_PTR identifyBuffer)
+{
+    mvDrivesInfoSaveSingleDrive(ialExt,
+                                channelIndex,
+                                PMPort,
+                                isReady,
+                                identifyBuffer);
+    mvSataScsiSetDriveReady(scsiAdapterExt,
+                            channelIndex, PMPort, isReady);
+}
+
+
+static void mvDrivesInfoGetChannelRescanParams(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                               MV_U8 channelIndex,
+                                               MV_U16 *drivesToRemove,
+                                               MV_U16 *drivesToAdd)
+{
+    MV_U8 PMPort;
+
+    *drivesToRemove = 0;
+    *drivesToAdd = 0;
+
+    for (PMPort = 0; PMPort < MV_SATA_PM_MAX_PORTS; PMPort++)
+    {
+        if (ialExt->IALChannelExt[channelIndex].drivesInfo.drivesSnapshotCurrent
+            & (1 << PMPort))
+        {
+            if (ialExt->IALChannelExt[channelIndex].drivesInfo.drivesSnapshotSaved
+                & (1 << PMPort))
+            {
+                if (memcmp(&ialExt->IALChannelExt[channelIndex].drivesInfo.driveSerialCurrent[PMPort].serial,
+                           &ialExt->IALChannelExt[channelIndex].drivesInfo.driveSerialSaved[PMPort].serial,
+                           IDEN_SERIAL_NUM_SIZE))
+                {
+                    /*Disk drive connected to port is replaced*/
+                    *drivesToAdd |= (1 << PMPort);
+                    *drivesToRemove |= (1 << PMPort);
+                }
+            }
+            else
+            {
+                /*New drive connected to port*/
+                *drivesToAdd |= (1 << PMPort);
+            }
+        }
+        else
+        {
+            /*Drive removed from Port*/
+            if (ialExt->IALChannelExt[channelIndex].drivesInfo.drivesSnapshotSaved
+                & (1 << PMPort))
+            {
+                *drivesToRemove |= (1 << PMPort);
+            }
+        }
+    }
+}
+
+
+
+/*SCSI command queue functions*/
+static void mvAddToSCSICommandQueue(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                    MV_U8 channelIndex,
+                                    MV_SATA_SCSI_CMD_BLOCK *pScb)
+{
+
+    MV_SATA_SCSI_CMD_BLOCK *cmdBlock = (MV_SATA_SCSI_CMD_BLOCK *)
+                                       ialExt->IALChannelExt[channelIndex].IALChannelPendingCmdQueue;
+    pScb->pNext = NULL;
+    if (cmdBlock)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d] Adding next command to SW queue\n",
+                 ialExt->pSataAdapter->adapterId, channelIndex);
+        while (cmdBlock->pNext)
+        {
+            cmdBlock = cmdBlock->pNext;
+        }
+        cmdBlock->pNext = pScb;
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d] Adding first command to SW queue\n",
+                 ialExt->pSataAdapter->adapterId, channelIndex);
+        ialExt->IALChannelExt[channelIndex].IALChannelPendingCmdQueue =
+        (MV_VOID_PTR)pScb;
+    }
+}
+
+MV_BOOLEAN mvRemoveFromSCSICommandQueue(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                        MV_U8 channelIndex,
+                                        MV_SATA_SCSI_CMD_BLOCK *pScb)
+{
+
+    MV_SATA_SCSI_CMD_BLOCK *cmdBlock = (MV_SATA_SCSI_CMD_BLOCK *)
+                                       ialExt->IALChannelExt[channelIndex].IALChannelPendingCmdQueue;
+    pScb->pNext = NULL;
+    if (cmdBlock)
+    {
+        if (cmdBlock == pScb)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d] Removing command"
+                     " %p from head of SW queue\n",
+                     ialExt->pSataAdapter->adapterId,channelIndex, pScb);
+            ialExt->IALChannelExt[channelIndex].IALChannelPendingCmdQueue =
+            (MV_VOID_PTR) cmdBlock->pNext;
+            return MV_TRUE;
+        }
+        else
+        {
+            while (cmdBlock->pNext)
+            {
+                if (cmdBlock->pNext == pScb)
+                {
+                    break;
+                }
+                cmdBlock = cmdBlock->pNext;
+            }
+            if (cmdBlock->pNext == NULL)
+            {
+                mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d] Removing"
+                         " command %p from SW queue failed. command not found\n",
+                         ialExt->pSataAdapter->adapterId,channelIndex, pScb);
+                return MV_FALSE;
+            }
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d] Removing command"
+                     " %p from SW queue\n", ialExt->pSataAdapter->adapterId,
+                     channelIndex, pScb);
+            cmdBlock->pNext = cmdBlock->pNext->pNext;
+            return MV_TRUE;
+        }
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d] Removing"
+                 " command %p from SW queue failed. queue empty\n",
+                 ialExt->pSataAdapter->adapterId,channelIndex, pScb);
+        return MV_FALSE;
+    }
+    return MV_FALSE;
+}
+
+static void mvFlushSCSICommandQueue(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                    MV_U8 channelIndex)
+{
+    /*Abort all pending commands in SW queue*/
+    MV_SATA_SCSI_CMD_BLOCK *cmdBlock = (MV_SATA_SCSI_CMD_BLOCK *)
+                                       ialExt->IALChannelExt[channelIndex].IALChannelPendingCmdQueue;
+
+    while (cmdBlock)
+    {
+        MV_SATA_SCSI_CMD_BLOCK *nextBlock = cmdBlock->pNext;
+        if (cmdBlock->completionCallBack)
+        {
+            cmdBlock->ScsiStatus = MV_SCSI_STATUS_BUSY;
+            cmdBlock->dataTransfered = 0;
+            cmdBlock->ScsiCommandCompletion = MV_SCSI_COMPLETION_QUEUE_FULL;
+            cmdBlock->completionCallBack(ialExt->pSataAdapter, cmdBlock);
+        }
+        cmdBlock = nextBlock;
+    }
+    ialExt->IALChannelExt[channelIndex].IALChannelPendingCmdQueue = NULL;
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]: Flush command queue is done\n",
+             ialExt->pSataAdapter->adapterId, channelIndex);
+}
+
+
+/*Port Multilier related functions*/
+static MV_BOOLEAN mvPMCommandCompletionCB(MV_SATA_ADAPTER *pSataAdapter,
+                                          MV_U8 channelIndex,
+                                          MV_COMPLETION_TYPE comp_type,
+                                          MV_VOID_PTR commandId,
+                                          MV_U16 responseFlags,
+                                          MV_U32 timeStamp,
+                                          MV_STORAGE_DEVICE_REGISTERS *registerStruct)
+{
+    MV_U32 value;
+    MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt =
+    (MV_IAL_COMMON_ADAPTER_EXTENSION *)commandId;
+    ialExt->IALChannelExt[channelIndex].pmRegAccessInProgress = MV_FALSE;
+    switch (comp_type)
+    {
+    case MV_COMPLETION_TYPE_NORMAL:
+        if (ialExt->IALChannelExt[channelIndex].pmAccessType
+            == MV_ATA_COMMAND_PM_READ_REG)
+        {
+            value = registerStruct->sectorCountRegister;
+            value |= (registerStruct->lbaLowRegister << 8);
+            value |= (registerStruct->lbaMidRegister << 16);
+            value |= (registerStruct->lbaMidRegister << 24);
+            if (ialExt->IALChannelExt[channelIndex].pmReg
+                == MV_SATA_GSCR_ERROR_REG_NUM)
+            {
+                if (value != 0)
+                {
+                    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]: PM GSCR[32] = 0x%X\n",
+                             pSataAdapter->adapterId, channelIndex, value);
+                    ialExt->IALChannelExt[channelIndex].PMdevsToInit =
+                    (MV_U16)(value & 0x7FFF);
+                    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]: "
+                             "PM Hot plug detected "
+                             "Bitmask = 0x%X\n",
+                             pSataAdapter->adapterId, channelIndex,
+                             ialExt->IALChannelExt[channelIndex].PMdevsToInit);
+                    mvSetChannelState(ialExt, channelIndex,
+                                      CHANNEL_PM_HOT_PLUG);
+                }
+            }
+        }
+        break;
+    case MV_COMPLETION_TYPE_ABORT:
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: read PM register aborted!\n",
+                 pSataAdapter->adapterId, channelIndex);
+
+        break;
+    case MV_COMPLETION_TYPE_ERROR:
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: read PM register error!\n",
+                 pSataAdapter->adapterId, channelIndex);
+        break;
+    default:
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: Unknown completion type (%d)\n",
+                 pSataAdapter->adapterId, channelIndex, comp_type);
+        return MV_FALSE;
+    }
+    return MV_TRUE;
+}
+
+
+static MV_BOOLEAN mvQueuePMAccessRegisterCommand(
+                                                MV_IAL_COMMON_ADAPTER_EXTENSION* ialExt,
+                                                MV_U8 channelIndex,
+                                                MV_U8 PMPort,
+                                                MV_U8 PMReg,
+                                                MV_U32 Value,
+                                                MV_BOOLEAN isRead)
+{
+    MV_QUEUE_COMMAND_RESULT result;
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO *pCommandInfo = &ialExt->IALChannelExt[channelIndex].commandInfo;
+#else
+    MV_QUEUE_COMMAND_INFO commandInfo, *pCommandInfo;
+    pCommandInfo = &commandInfo;
+#endif
+    memset(pCommandInfo, 0, sizeof(MV_QUEUE_COMMAND_INFO));
+    pCommandInfo->type = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pCommandInfo->commandParams.NoneUdmaCommand.protocolType =
+    MV_NON_UDMA_PROTOCOL_NON_DATA;
+    pCommandInfo->commandParams.NoneUdmaCommand.isEXT = MV_TRUE;
+    pCommandInfo->commandParams.NoneUdmaCommand.bufPtr = NULL;
+    pCommandInfo->PMPort = MV_SATA_PM_CONTROL_PORT;
+    pCommandInfo->commandParams.NoneUdmaCommand.count = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.features = PMReg;
+    pCommandInfo->commandParams.NoneUdmaCommand.device = (MV_U8)PMPort;
+    pCommandInfo->commandParams.NoneUdmaCommand.callBack =
+    mvPMCommandCompletionCB;
+
+    ialExt->IALChannelExt[channelIndex].pmReg = PMReg;
+
+    if (isRead == MV_TRUE)
+    {
+        ialExt->IALChannelExt[channelIndex].pmAccessType =
+        MV_ATA_COMMAND_PM_READ_REG;
+        pCommandInfo->commandParams.NoneUdmaCommand.command =
+        MV_ATA_COMMAND_PM_READ_REG;
+        pCommandInfo->commandParams.NoneUdmaCommand.commandId =
+        (MV_VOID_PTR)ialExt;
+        pCommandInfo->commandParams.NoneUdmaCommand.sectorCount = 0;
+        pCommandInfo->commandParams.NoneUdmaCommand.lbaLow = 0;
+        pCommandInfo->commandParams.NoneUdmaCommand.lbaMid = 0;
+        pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh = 0;
+    }
+    else
+    {
+        ialExt->IALChannelExt[channelIndex].pmAccessType =
+        MV_ATA_COMMAND_PM_WRITE_REG;
+        pCommandInfo->commandParams.NoneUdmaCommand.command =
+        MV_ATA_COMMAND_PM_WRITE_REG;
+        pCommandInfo->commandParams.NoneUdmaCommand.commandId =
+        (MV_VOID_PTR)ialExt;
+        pCommandInfo->commandParams.NoneUdmaCommand.sectorCount =
+        (MV_U16)((Value) & 0xff),
+        pCommandInfo->commandParams.NoneUdmaCommand.lbaLow =
+        (MV_U16)(((Value) & 0xff00) >> 8);
+        pCommandInfo->commandParams.NoneUdmaCommand.lbaMid =
+        (MV_U16)(((Value) & 0xff0000) >> 16);
+        pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh =
+        (MV_U16)(((Value) & 0xff000000) >> 24);
+    }
+    ialExt->IALChannelExt[channelIndex].pmRegAccessInProgress = MV_TRUE;
+    result = mvSataQueueCommand(pSataAdapter,
+                                channelIndex,
+                                pCommandInfo);
+    if (result != MV_QUEUE_COMMAND_RESULT_OK)
+    {
+        switch (result)
+        {
+        case MV_QUEUE_COMMAND_RESULT_BAD_LBA_ADDRESS:
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, ": Queue PM command failed. Bad LBA "
+                     "\n");
+            break;
+        case MV_QUEUE_COMMAND_RESULT_QUEUED_MODE_DISABLED:
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, ": Queue PM command failed. EDMA"
+                     " disabled adapter %d channel %d\n",
+                     pSataAdapter->adapterId, channelIndex);
+            break;
+        case MV_QUEUE_COMMAND_RESULT_FULL:
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, ": Queue PM command failed. Queue is"
+                     " Full adapter %d channel %d\n",
+                     pSataAdapter->adapterId, channelIndex);
+
+            break;
+        case MV_QUEUE_COMMAND_RESULT_BAD_PARAMS:
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, ": Queue PM command failed. (Bad "
+                     "Params), pMvSataAdapter: %p, pSataChannel: %p.\n",
+                     pSataAdapter, pSataAdapter->sataChannel[channelIndex]);
+            break;
+        default:
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, ": Queue PM command bad result value (%d) "
+                     "from queue command\n",
+                     result);
+        }
+        ialExt->IALChannelExt[channelIndex].pmRegAccessInProgress = MV_FALSE;
+        return MV_FALSE;
+    }
+    return MV_TRUE;
+}
+
+
+static MV_BOOLEAN mvPMEnableCommStatusChangeBits(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                                 MV_U8 channelIndex,
+                                                 MV_BOOLEAN enable)
+{
+    MV_U32 regVal;
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+
+    if (enable == MV_TRUE)
+    {
+        regVal = MV_BIT16;
+    }
+    else
+    {
+        regVal = 0;
+    }
+
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]: Set PM "
+             "GSCR[33] register to 0x%X\n",
+             pSataAdapter->adapterId, channelIndex, regVal);
+    /*Set N bit reflection in PM GSCR*/
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex,
+                        MV_SATA_PM_CONTROL_PORT,
+                        MV_SATA_GSCR_ERROR_ENABLE_REG_NUM,
+                        regVal, NULL) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: Failed to set "
+                 "PortMultiplier Features Enable register\n",
+                 pSataAdapter->adapterId, channelIndex);
+        return MV_FALSE;
+    }
+    return MV_TRUE;
+}
+
+static MV_BOOLEAN mvPMEnableAsyncNotify(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                        MV_U8 channelIndex)
+{
+    MV_U32 regVal1, regVal2;
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+    /*Features register*/
+    if (mvPMDevReadReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                       MV_SATA_GSCR_FEATURES_REG_NUM,
+                       &regVal1, NULL) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: Failed to get Port Multiplier Features"
+                 " supported register\n",
+                 pSataAdapter->adapterId, channelIndex);
+        return MV_FALSE;
+    }
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]: Port Multiplier features supported: 0x%X\n",
+             pSataAdapter->adapterId, channelIndex, regVal1);
+
+    /*PM asynchronous notification supported*/
+    if (mvPMDevReadReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                       MV_SATA_GSCR_FEATURES_ENABLE_REG_NUM,
+                       &regVal2 ,NULL) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: Failed to get Port Multiplier Features"
+                 " register\n",
+                 pSataAdapter->adapterId, channelIndex);
+        return MV_FALSE;
+
+    }
+
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]: Port Multiplier features enabled "
+             "register: 0x%X\n",
+             pSataAdapter->adapterId, channelIndex, regVal2);
+    if (regVal1 & MV_BIT3)
+    {
+        regVal2 |= MV_BIT3;
+        if (mvPMDevWriteReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                            MV_SATA_GSCR_FEATURES_ENABLE_REG_NUM,
+                            regVal2 ,NULL) == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: Failed to set "
+                     "PortMultiplier Features Enable register\n",
+                     pSataAdapter->adapterId, channelIndex);
+            return MV_FALSE;
+
+        }
+        ialExt->IALChannelExt[channelIndex].pmAsyncNotifyEnabled = MV_TRUE;
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]: PM asynchronous notification is "
+                 "enabled.\n", pSataAdapter->adapterId, channelIndex);
+    }
+    else
+    {
+        regVal2 &= ~MV_BIT3;
+        if (mvPMDevWriteReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                            MV_SATA_GSCR_FEATURES_ENABLE_REG_NUM,
+                            regVal2 ,NULL) == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: Failed to set "
+                     "PortMultiplier Features Enable register\n",
+                     pSataAdapter->adapterId, channelIndex);
+            return MV_FALSE;
+
+        }
+        ialExt->IALChannelExt[channelIndex].pmAsyncNotifyEnabled = MV_FALSE;
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]: PM asynchronous notification is "
+                 "disabled.\n", pSataAdapter->adapterId, channelIndex);
+    }
+
+    return MV_TRUE;
+}
+
+static MV_BOOLEAN mvPMDisableAsyncNotify(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                        MV_U8 channelIndex)
+{
+    MV_U32 regVal2;
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+
+
+    /*PM asynchronous notification supported*/
+    if (mvPMDevReadReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                       MV_SATA_GSCR_FEATURES_ENABLE_REG_NUM,
+                       &regVal2 ,NULL) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: Failed to get Port Multiplier Features"
+                 " register\n",
+                 pSataAdapter->adapterId, channelIndex);
+        return MV_FALSE;
+
+    }
+
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]: Port Multiplier features enabled "
+             "register: 0x%X\n",
+             pSataAdapter->adapterId, channelIndex, regVal2);
+
+        regVal2 &= ~MV_BIT3;
+        if (mvPMDevWriteReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                            MV_SATA_GSCR_FEATURES_ENABLE_REG_NUM,
+                            regVal2 ,NULL) == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: Failed to set "
+                     "PortMultiplier Features Enable register\n",
+                     pSataAdapter->adapterId, channelIndex);
+            return MV_FALSE;
+
+        }
+        ialExt->IALChannelExt[channelIndex].pmAsyncNotifyEnabled = MV_FALSE;
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]: PM asynchronous notification is "
+                 "disabled.\n", pSataAdapter->adapterId, channelIndex);
+
+    return MV_TRUE;
+}
+
+
+
+static MV_BOOLEAN mvConfigurePMDevice(
+                                     MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                     MV_U8 channelIndex)
+{
+    MV_SATA_PM_DEVICE_INFO PMInfo;
+    ialExt->IALChannelExt[channelIndex].pmAsyncNotifyEnabled = MV_FALSE;
+
+    if (mvGetPMDeviceInfo(ialExt->pSataAdapter, channelIndex, &PMInfo)
+        == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: Failed to get PortMultiplier Info\n",
+                 ialExt->pSataAdapter->adapterId, channelIndex);
+        return MV_FALSE;
+    }
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]: PM of %d ports found\n",
+             ialExt->pSataAdapter->adapterId, channelIndex,
+             PMInfo.numberOfPorts);
+    ialExt->IALChannelExt[channelIndex].PMnumberOfPorts = PMInfo.numberOfPorts;
+#ifdef DISABLE_PM_SCC
+    if (PMInfo.vendorId == 0x11AB)
+    {
+
+        if (mvPMDisableSSC(ialExt->pSataAdapter, channelIndex) == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: cannot disable SSC for PM.\n"
+                     "unknown vendor.\n",
+                     ialExt->pSataAdapter->adapterId, channelIndex);
+        }
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: cannot disable SSC for PM - "
+                 "unknown vendor.\n",
+                 ialExt->pSataAdapter->adapterId, channelIndex);
+    }
+#endif
+#if 1
+    if (clearSErrorPorts(ialExt->pSataAdapter, channelIndex,
+			 ialExt->IALChannelExt[channelIndex].PMnumberOfPorts) != 
+	MV_TRUE)
+    {
+	    return MV_FALSE;
+    }
+#endif
+    if (mvPMEnableCommStatusChangeBits(ialExt,
+                                       channelIndex,
+                                       MV_FALSE) != MV_TRUE)
+    {
+        return MV_FALSE;
+    }
+    if (mvPMDisableAsyncNotify(ialExt, channelIndex) == MV_FALSE)
+    {
+        return MV_FALSE;
+    }
+#if 0
+
+    if (mvPMDevEnableStaggeredSpinUpAll(ialExt->pSataAdapter,
+                                        channelIndex,
+                                        ialExt->IALChannelExt[channelIndex].PMnumberOfPorts,
+                                        &ialExt->IALChannelExt[channelIndex].PMdevsToInit) == MV_FALSE)
+    {
+	 mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: PM Enable Staggered Spin-\
+Up Failed\n",
+		  ialExt->pSataAdapter->adapterId, channelIndex);
+	 ialExt->IALChannelExt[channelIndex].PMdevsToInit = 0;
+	 return MV_FALSE;
+    }
+#endif
+    return MV_TRUE;
+}
+
+static MV_BOOLEAN clearSErrorPorts(MV_SATA_ADAPTER *pSataAdapter, MV_U8 channelIndex, 
+				   MV_U8     PMnumberOfPorts)
+{
+	MV_U8 PMPort;
+	
+	for (PMPort = 0; PMPort < PMnumberOfPorts; PMPort++)
+	{
+		if (mvPMDevWriteReg(pSataAdapter, channelIndex, PMPort,
+				    MV_SATA_PSCR_SERROR_REG_NUM, 0xFFFFFFFF, NULL) ==
+		    MV_FALSE)
+		{
+			if (mvStorageDevATASoftResetDevice(pSataAdapter, channelIndex,
+							   MV_SATA_PM_CONTROL_PORT, NULL) == MV_FALSE)
+			{
+				mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: "
+					 "failed to Soft Reset PM control port\n",
+					 pSataAdapter->adapterId, channelIndex);
+				return MV_FALSE;
+			}
+		}
+	}
+	return MV_TRUE;
+}
+
+MV_BOOLEAN mvPMEnableLocking(MV_SATA_ADAPTER *pSataAdapter, MV_U8 channelIndex)
+{
+    MV_STORAGE_DEVICE_REGISTERS regs;
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex,
+                        MV_SATA_PM_CONTROL_PORT,
+                        0x89,
+                        0x8000003F,
+                        &regs) == MV_TRUE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d]: NCQ lock is enabled for PM.\n",
+                 pSataAdapter->adapterId, channelIndex);
+        return MV_TRUE;
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d]: cannot enable NCQ lock for PM.\n",
+                 pSataAdapter->adapterId, channelIndex);
+        return MV_FALSE;
+    }
+    return MV_TRUE;
+}
+
+#ifdef DISABLE_PM_SCC
+MV_BOOLEAN mvPMDisableSSC(MV_SATA_ADAPTER *pSataAdapter, MV_U8 channelIndex)
+{
+    MV_STORAGE_DEVICE_REGISTERS regs;
+    MV_U32 regVal = 0;
+
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d]: "
+             "Disable SSC for all PM ports.\n",
+             pSataAdapter->adapterId, channelIndex);
+
+    if (mvPMDevReadReg(pSataAdapter,channelIndex, MV_SATA_PM_CONTROL_PORT,
+                       MV_SATA_GSCR_FEATURES_ENABLE_REG_NUM,
+                       &regVal,
+                       &regs) != MV_TRUE)
+    {
+        return MV_FALSE;
+    }
+
+    /*Host SSC disable*/
+    regVal &= ~MV_BIT2;
+    if (mvPMDevWriteReg(pSataAdapter,channelIndex, MV_SATA_PM_CONTROL_PORT,
+                        MV_SATA_GSCR_FEATURES_ENABLE_REG_NUM,
+                        regVal,
+                        &regs) != MV_TRUE)
+    {
+        return MV_FALSE;
+    }
+
+    /* disable ssc for port 0*/
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                        0x8C,
+                        0,
+                        &regs) != MV_TRUE)
+    {
+        return MV_FALSE;
+    }
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                        0x92,
+                        0xb02a402a,
+                        &regs) != MV_TRUE)
+    {
+        return MV_FALSE;
+    }
+    /* disable ssc for port 1*/
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                        0x8C,
+                        1,
+                        &regs) != MV_TRUE)
+    {
+        return MV_FALSE;
+    }
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                        0x92,
+                        0xb02a402a,
+                        &regs) != MV_TRUE)
+    {
+        return MV_FALSE;
+    }
+    /* disable ssc for port 2*/
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                        0x8C,
+                        2,
+                        &regs) != MV_TRUE)
+    {
+        return MV_FALSE;
+    }
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                        0x92,
+                        0xb02a402a,
+                        &regs) != MV_TRUE)
+    {
+        return MV_FALSE;
+    }
+
+    /* disable ssc for port 3*/
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                        0x8C,
+                        3,
+                        &regs) != MV_TRUE)
+    {
+        return MV_FALSE;
+    }
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                        0x92,
+                        0xb02a402a,
+                        &regs) != MV_TRUE)
+    {
+        return MV_FALSE;
+    }
+
+    /* disable ssc for port 15*/
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                        0x8C,
+                        MV_SATA_PM_CONTROL_PORT,
+                        &regs) != MV_TRUE)
+    {
+        return MV_FALSE;
+    }
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                        0x92,
+                        0xb02a402a,
+                        &regs) != MV_TRUE)
+    {
+        return MV_FALSE;
+    }
+    return MV_TRUE;
+}
+#endif
+
+static MV_BOOLEAN mvConfigChannelQueuingMode(MV_IAL_COMMON_ADAPTER_EXTENSION* ialExt,
+                                             MV_U8 channelIndex,
+                                             MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt)
+{
+    MV_SATA_ADAPTER         *pSataAdapter = ialExt->pSataAdapter;
+    MV_EDMA_MODE            EDMAMode = MV_EDMA_MODE_NOT_QUEUED;
+    MV_SATA_SWITCHING_MODE  switchingMode;
+    MV_BOOLEAN              isTCQSupported = MV_FALSE;
+    MV_BOOLEAN              isNCQSupported = MV_FALSE;
+    MV_U8                   numOfDrives = 0;
+    MV_SATA_PM_DEVICE_INFO  PMInfo;
+    MV_SATA_DEVICE_TYPE     connectedDevice;
+    MV_BOOLEAN              use128Entries = MV_FALSE;
+
+
+    if (mvGetDisksModes(ialExt,
+                        scsiAdapterExt,
+                        channelIndex,
+                        &isTCQSupported,
+                        &isNCQSupported,
+                        &numOfDrives) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_FATAL_ERROR,
+                 "[%d %d]:mvConfigChannelQueuingMode: failed to get disks modes.\n"
+                 ,pSataAdapter->adapterId, channelIndex);
+        return MV_FALSE;
+    }
+    else
+    {
+
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d]: Supported queuing mode: TCQ = %s, "
+                 "NCQ = %s. number of disks %d\n",
+                 pSataAdapter->adapterId, channelIndex,
+                 (isTCQSupported == MV_TRUE) ? "Yes" : "No",
+                 (isNCQSupported == MV_TRUE) ? "Yes" : "No",
+                 numOfDrives);
+    }
+    connectedDevice = mvStorageDevGetDeviceType(pSataAdapter,channelIndex);
+    if (connectedDevice == MV_SATA_DEVICE_TYPE_UNKNOWN)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_FATAL_ERROR,
+                 "[%d %d] mvConfigChannelQueuingMode: failed to get device type.\n"
+                 ,pSataAdapter->adapterId, channelIndex);
+        return MV_FALSE;
+    }
+    if (connectedDevice == MV_SATA_DEVICE_TYPE_PM)
+    {
+        if (mvGetPMDeviceInfo(ialExt->pSataAdapter, channelIndex, &PMInfo)
+            == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_FATAL_ERROR,
+                     "[%d %d] mvConfigChannelQueuingMode: Failed to get "
+                     "PortMultiplier Info\n",
+                     ialExt->pSataAdapter->adapterId, channelIndex);
+            return MV_FALSE;
+        }
+    }
+    if (disableNCQ == MV_TRUE)
+	    isNCQSupported = MV_FALSE;
+
+    if ((numOfDrives > 1) && (disablePM_NCQ == MV_TRUE))
+	    isNCQSupported = MV_FALSE;
+
+    mvSelectConfiguration(pSataAdapter, channelIndex,
+                          pSataAdapter->sataAdapterGeneration,
+                          connectedDevice,&PMInfo,
+                          isNCQSupported,
+                          isTCQSupported,
+                          numOfDrives,
+                          &EDMAMode,
+                          &switchingMode,
+                          &use128Entries);
+
+#ifndef MV_SATA_SUPPORT_GEN2E_128_QUEUE_LEN
+    use128Entries = MV_FALSE;
+#endif
+    switch (switchingMode)
+    {
+    case MV_SATA_SWITCHING_MODE_FBS:
+        {
+            if (mvSataSetFBSMode(pSataAdapter, channelIndex, MV_TRUE,
+                                 use128Entries) == MV_FALSE)
+            {
+                mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_FATAL_ERROR,
+                         "[%d %d] mvConfigChannelQueuingMode: failed to enable FBS.\n"
+                         ,pSataAdapter->adapterId, channelIndex);
+                return MV_FALSE;
+            }
+        }
+        break;
+    case MV_SATA_SWITCHING_MODE_QCBS:
+        if (mvPMEnableLocking(pSataAdapter,channelIndex) == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_FATAL_ERROR,
+                     "[%d %d] mvConfigChannelQueuingMode: failed to enable QCBS.\n"
+                     ,pSataAdapter->adapterId, channelIndex);
+            return MV_FALSE;
+        }
+        break;
+    default:
+        break;
+    }         
+    IALConfigQueuingMode(pSataAdapter,
+                         channelIndex,
+                         EDMAMode,
+                         switchingMode,
+                         use128Entries);
+    return MV_TRUE;
+}
+
+
+
+/*Channel related functions*/
+
+static void mvSetChannelState(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                              MV_U8 channelIndex,
+                              MV_CHANNEL_STATE state)
+{
+    if (ialExt->channelState[channelIndex] != state)
+    {
+        if ((state == CHANNEL_READY) || (state == CHANNEL_NOT_CONNECTED))
+        {
+            ialExt->IALChannelExt[channelIndex].SRSTTimerThreshold = 0;
+            ialExt->IALChannelExt[channelIndex].SRSTTimerValue = 0;
+        }
+        if (state == CHANNEL_READY)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d]: CHANNEL_READY\n",
+                     ialExt->pSataAdapter->adapterId,
+                     channelIndex);
+            ialExt->IALChannelExt[channelIndex].pmRegAccessInProgress
+            = MV_FALSE;
+            ialExt->IALChannelExt[channelIndex].completionError = MV_FALSE;
+            ialExt->channelState[channelIndex] = state;
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d] flush pending queue\n",
+                     ialExt->pSataAdapter->adapterId, channelIndex);
+            /*Abort all pending commands in SW queue*/
+            mvFlushSCSICommandQueue(ialExt, channelIndex);
+            if (MV_TRUE == ialExt->IALChannelExt[channelIndex].bHotPlug)
+            {
+                MV_U16 drivesToRemove;
+                MV_U16 drivesToAdd;
+                ialExt->IALChannelExt[channelIndex].bHotPlug = MV_FALSE;
+                mvDrivesInfoGetChannelRescanParams(ialExt,
+                                                   channelIndex,
+                                                   &drivesToRemove,
+                                                   &drivesToAdd);
+                if (drivesToRemove != 0 || drivesToAdd != 0)
+                {
+
+                    IALBusChangeNotifyEx(ialExt->pSataAdapter,
+                                         channelIndex,
+                                         drivesToRemove,
+                                         drivesToAdd);
+                }
+            }
+            mvDrivesInfoSaveAll(ialExt, channelIndex);
+        }
+        else
+        {
+            ialExt->channelState[channelIndex] = state;
+        }
+    }
+}
+
+
+static MV_BOOLEAN mvStartChannelInit(MV_SATA_ADAPTER *pSataAdapter,
+                                     MV_U8 channelIndex,
+                                     MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt,
+                                     MV_BOOLEAN* bIsChannelReady)
+{
+    *bIsChannelReady = MV_FALSE;
+
+    if (mvSataConfigureChannel(pSataAdapter, channelIndex) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d]: configure channel failed\n",
+                 pSataAdapter->adapterId,
+                 channelIndex);
+        return MV_FALSE;
+    }
+
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d]: start channel\n",
+             pSataAdapter->adapterId,
+             channelIndex);
+    /*Just check SStatus in case of SATA I adapter*/
+    if (pSataAdapter->sataAdapterGeneration == MV_SATA_GEN_I)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d]: starting SATA I channel.\n",
+                 pSataAdapter->adapterId, channelIndex);
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d]: starting SATA II channel.\n",
+                 pSataAdapter->adapterId, channelIndex);
+    }
+
+    return mvStorageDevATAStartSoftResetDevice(pSataAdapter,
+                                               channelIndex,
+                                               MV_SATA_PM_CONTROL_PORT);
+}
+
+static MV_BOOLEAN mvChannelSRSTFinished(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                        MV_SATA_CHANNEL *pSataChannel,
+                                        MV_U8 channelIndex,
+                                        MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt,
+                                        MV_BOOLEAN* bIsChannelReady,
+                                        MV_BOOLEAN* bFatalError)
+{
+    MV_SATA_DEVICE_TYPE deviceType;
+    MV_STORAGE_DEVICE_REGISTERS mvStorageDevRegisters;
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData;
+    *bIsChannelReady = MV_FALSE;
+    *bFatalError = MV_FALSE;
+    if (pSataAdapter->sataAdapterGeneration > MV_SATA_GEN_I)
+    {
+        if (mvStorageIsDeviceBsyBitOff(pSataAdapter,
+                                       channelIndex,
+                                       &mvStorageDevRegisters)
+            == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d]: soft Reset PM control port "
+                     "in progress\n",
+                     pSataAdapter->adapterId, channelIndex);
+            printAtaDeviceRegisters(&mvStorageDevRegisters);
+            return MV_FALSE;
+        }
+        deviceType = mvGetSataDeviceType(&mvStorageDevRegisters);
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d]: soft reset SATA II channel - "
+                 "device ready.\n",
+                 pSataAdapter->adapterId, channelIndex);
+    }
+    else
+    {
+        if (mvStorageIsDeviceBsyBitOff(pSataAdapter,
+                                       channelIndex,
+                                       &mvStorageDevRegisters)
+            == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d]: soft reset of SATA I channel "
+                     "in progress\n",
+                     pSataAdapter->adapterId, channelIndex);
+            printAtaDeviceRegisters(&mvStorageDevRegisters);
+            return MV_FALSE;
+        }
+        deviceType = mvGetSataDeviceType(&mvStorageDevRegisters);
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d]: soft reset SATA I channel - "
+                 "device ready.\n",
+                 pSataAdapter->adapterId, channelIndex);
+        deviceType = mvGetSataDeviceType(&mvStorageDevRegisters);
+        if (deviceType != MV_SATA_DEVICE_TYPE_ATA_DISK)
+        {
+            deviceType = MV_SATA_DEVICE_TYPE_UNKNOWN;
+        }
+
+    }
+    switch (deviceType)
+    {
+    case MV_SATA_DEVICE_TYPE_ATA_DISK:
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_INFO,"[%d %d]: SATA disk found\n",
+                 pSataAdapter->adapterId, channelIndex);
+        if (mvStorageDevSetDeviceType(pSataAdapter,channelIndex, deviceType) == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d]: Failed to initialize disk\n",
+                     pSataAdapter->adapterId, channelIndex);
+            *bFatalError = MV_TRUE;
+            return MV_FALSE;
+
+        }
+        pDriveData = &scsiAdapterExt->ataDriveData[channelIndex][0];
+        if (mvInitSataDisk(pSataAdapter,
+                           channelIndex,
+                           0,
+                           &pDriveData->identifyInfo,
+                           pDriveData->identifyBuffer) == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d]: Failed to initialize disk\n",
+                     pSataAdapter->adapterId, channelIndex);
+            *bFatalError = MV_TRUE;
+            mvDrivesInfoFlushSingleDrive(ialExt,
+                                         channelIndex,
+                                         0);
+            return MV_FALSE;
+        }
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_INFO,"[%d %d]: Disk ready\n",
+                 pSataAdapter->adapterId, channelIndex);
+        mvSetDriveReady(ialExt,
+                        scsiAdapterExt,
+                        channelIndex,
+                        0,
+                        MV_TRUE,
+                        pDriveData->identifyBuffer);
+        mvSataScsiNotifyUA(scsiAdapterExt, channelIndex, 0);
+        *bIsChannelReady = MV_TRUE;
+        return MV_TRUE;
+        break;
+    case MV_SATA_DEVICE_TYPE_PM:
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_INFO,"[%d %d]: PortMultiplier device found\n",
+                 pSataAdapter->adapterId, channelIndex);
+        if (mvStorageDevSetDeviceType(pSataAdapter,channelIndex, deviceType) == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d]: Failed to initialize PM\n",
+                     pSataAdapter->adapterId, channelIndex);
+            *bFatalError = MV_TRUE;
+            return MV_FALSE;
+
+        }
+        break;
+#ifdef MV_SUPPORT_ATAPI
+    case MV_SATA_DEVICE_TYPE_ATAPI_DEVICE:
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_INFO,"[%d %d]: ATAPI device found\n",
+                 pSataAdapter->adapterId, channelIndex);
+        if (mvStorageDevSetDeviceType(pSataAdapter,channelIndex, deviceType) == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d]: Failed to initialize ATAPI device\n",
+                     pSataAdapter->adapterId, channelIndex);
+            *bFatalError = MV_TRUE;
+            return MV_FALSE;
+
+        }
+        pDriveData = &scsiAdapterExt->ataDriveData[channelIndex][0];
+        if (mvInitSataATAPI(pSataAdapter,
+                           channelIndex,
+                           0,
+                           &pDriveData->identifyInfo,
+                           pDriveData->identifyBuffer) == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d]: Failed to initialize ATAPI device\n",
+                     pSataAdapter->adapterId, channelIndex);
+            *bFatalError = MV_TRUE;
+            mvDrivesInfoFlushSingleDrive(ialExt,
+                                         channelIndex,
+                                         0);
+            return MV_FALSE;
+        }
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_INFO,"[%d %d]: ATAPI Device ready\n",
+                 pSataAdapter->adapterId, channelIndex);
+
+        mvSetDriveReady(ialExt,
+                        scsiAdapterExt,
+                        channelIndex,
+                        0,
+                        MV_TRUE,
+                        pDriveData->identifyBuffer);
+
+
+        mvSataScsiNotifyUA(scsiAdapterExt, channelIndex, 0);
+        *bIsChannelReady = MV_TRUE;
+        return MV_TRUE;
+         break;
+#endif
+    default:
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d]: ERROR: unknown device type\n",
+                 pSataAdapter->adapterId, channelIndex);
+        *bFatalError    =    MV_TRUE;
+        return MV_FALSE;
+    }
+    return MV_TRUE;
+}
+
+
+
+static MV_BOOLEAN mvConfigChannelDMA(
+                                    MV_IAL_COMMON_ADAPTER_EXTENSION* ialExt,
+                                    MV_U8 channelIndex,
+                                    MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt)
+{
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d] config queueing mode\n",
+             pSataAdapter->adapterId, channelIndex);
+
+
+    if (mvConfigChannelQueuingMode(ialExt,
+                                   channelIndex,
+                                   scsiAdapterExt)
+        == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d] Failed to config DMA queuing\n",
+                 pSataAdapter->adapterId, channelIndex);
+        return MV_FALSE;
+    }
+    /* Enable EDMA */
+    if (mvSataEnableChannelDma(pSataAdapter, channelIndex) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d] Failed to enable DMA, channel=%d\n",
+                 pSataAdapter->adapterId, channelIndex);
+        return MV_FALSE;
+    }
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d]: channel started successfully\n",
+             pSataAdapter->adapterId, channelIndex);
+    return MV_TRUE;
+}
+
+
+
+
+
+static void mvSetChannelTimer(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                              MV_U8 channelIndex,
+                              MV_U32 timeout)
+{
+    ialExt->IALChannelExt[channelIndex].SRSTTimerThreshold = timeout;
+    ialExt->IALChannelExt[channelIndex].SRSTTimerValue = 1;
+}
+
+static void mvDecrementChannelTimer(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                    MV_U8 channelIndex)
+{
+    if (ialExt->IALChannelExt[channelIndex].SRSTTimerThreshold > 0)
+    {
+        ialExt->IALChannelExt[channelIndex].SRSTTimerValue +=
+        MV_IAL_ASYNC_TIMER_PERIOD;
+    }
+}
+
+static MV_BOOLEAN mvIsChannelTimerExpired(
+                                         MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                         MV_U8 channelIndex)
+{
+    if (ialExt->IALChannelExt[channelIndex].SRSTTimerValue >
+        ialExt->IALChannelExt[channelIndex].SRSTTimerThreshold)
+    {
+        return MV_TRUE;
+    }
+    else
+    {
+        return MV_FALSE;
+    }
+}
+
+/*******************************************************************************
+*State Machine related functions:
+*  Return MV_TRUE to proceed to the next channel
+*  Return MV_FALSE to proceed to the next state on current channel
+*******************************************************************************/
+
+static MV_BOOLEAN mvChannelNotConnectedStateHandler(
+                                                   MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                                   MV_U8 channelIndex,
+                                                   MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt)
+{
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+    if (pSataAdapter->sataChannel[channelIndex] != NULL)
+    {
+        mvSataRemoveChannel(pSataAdapter,channelIndex);
+        pSataAdapter->sataChannel[channelIndex] = NULL;
+        mvSetDriveReady(ialExt,
+                        scsiAdapterExt,
+                        channelIndex,
+                        0xFF, MV_FALSE, NULL);
+        mvFlushSCSICommandQueue(ialExt, channelIndex);
+    }
+    return MV_TRUE;
+}
+
+
+static MV_BOOLEAN mvChannelConnectedStateHandler(
+     MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+     MV_U8 channelIndex,
+     MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt)
+{
+     MV_BOOLEAN res = MV_FALSE;
+     MV_BOOLEAN isChannelReady;
+     MV_SATA_CHANNEL *pSataChannel;
+     MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+     
+     mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d] CHANNEL_CONNECTED\n",
+	      ialExt->pSataAdapter->adapterId, channelIndex);
+     if (pSataAdapter->sataChannel[channelIndex] == NULL)
+    {
+	 if (IALInitChannel(pSataAdapter, channelIndex) == MV_FALSE)
+	 {
+	      IALReleaseChannel(pSataAdapter, channelIndex);
+	      mvDrivesInfoFlushAll(ialExt, channelIndex);
+	      mvSetChannelState(ialExt, channelIndex, CHANNEL_NOT_CONNECTED);
+	      return MV_TRUE;
+	 }
+    }
+     pSataChannel = pSataAdapter->sataChannel[channelIndex];
+     res = mvStartChannelInit(pSataAdapter,
+			      channelIndex,
+			      scsiAdapterExt,
+			      &isChannelReady);
+     if (res == MV_TRUE)
+     {
+	  if (isChannelReady == MV_FALSE)
+	  {
+	       /*SRST channel, Set polling timer*/
+            mvSetChannelTimer(ialExt, channelIndex,
+                              MV_IAL_SRST_TIMEOUT);
+            mvSetChannelState(ialExt,
+                              channelIndex,
+                              CHANNEL_IN_SRST);
+	  }
+	  else
+	  {
+            if (mvConfigChannelDMA(ialExt,
+                                   channelIndex,
+                                   scsiAdapterExt) == MV_TRUE)
+            {
+		 mvSetChannelState(ialExt,
+				   channelIndex,
+				   CHANNEL_READY);
+            }
+            else
+            {
+		 mvStopChannel(ialExt,
+			       channelIndex,
+			       scsiAdapterExt);
+            }
+	  }
+    }
+     else
+     {
+	  mvStopChannel(ialExt,
+			channelIndex,
+			scsiAdapterExt);
+     }
+     return MV_TRUE;
+}
+
+
+MV_BOOLEAN mvChannelInSrstStateHandler(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                       MV_U8 channelIndex,
+                                       MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt)
+{
+    MV_BOOLEAN bFatalError;
+    MV_BOOLEAN res = MV_FALSE;
+    MV_BOOLEAN isChannelReady;
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+    MV_SATA_CHANNEL *pSataChannel = pSataAdapter->sataChannel[channelIndex];
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d] CHANNEL_IN_SRST\n",
+             pSataAdapter->adapterId, channelIndex);
+    mvDecrementChannelTimer(ialExt, channelIndex);
+    res = mvChannelSRSTFinished(ialExt,
+                                pSataChannel,
+                                channelIndex,
+                                scsiAdapterExt,
+                                &isChannelReady,
+                                &bFatalError);
+    if (res == MV_TRUE)
+    {
+        /*Finishing channel initialization*/
+        if (isChannelReady == MV_TRUE)
+        {
+	     mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_INFO,"[%d %d]: Sata device ready\n",
+		      pSataAdapter->adapterId,channelIndex);
+            if (mvConfigChannelDMA(ialExt,
+                                   channelIndex,
+                                   scsiAdapterExt) == MV_TRUE)
+            {
+                mvSetChannelState(ialExt,
+                                  channelIndex,
+                                  CHANNEL_READY);
+            }
+            else
+            {
+                mvStopChannel(ialExt,
+                              channelIndex,
+                              scsiAdapterExt);
+            }
+        }
+        else
+        {/*If channel not ready and function call succeed -> PM is found*/
+            if (mvConfigurePMDevice(ialExt, channelIndex) == MV_FALSE)
+            {
+                mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d]: Failed to "
+                         "initialize PM\n",
+                         pSataAdapter->adapterId,channelIndex);
+#if 0               
+		mvStopChannel(ialExt,
+                              channelIndex,
+                              scsiAdapterExt);
+#else
+		mvSataChannelHardReset(pSataAdapter, channelIndex);
+		mvRestartChannel(ialExt, channelIndex, scsiAdapterExt, MV_FALSE);
+#endif
+            }
+            else
+            {
+		 MV_IAL_COMMON_CHANNEL_EXTENSION* channelExt = 
+		      &ialExt->IALChannelExt[channelIndex];
+		 
+		 channelExt->port_state = MV_PORT_NOT_INITIALIZED;
+		 channelExt->devInSRST = 0;
+		 
+                mvSetChannelState(ialExt, channelIndex,
+                                  CHANNEL_PM_INIT_DEVICES);
+                return MV_FALSE;
+            }
+        }
+    }
+    else
+    {
+        if (bFatalError == MV_TRUE)
+        {
+            mvStopChannel(ialExt,
+                          channelIndex,
+                          scsiAdapterExt);
+        }
+        else
+        {
+            if (mvIsChannelTimerExpired(ialExt, channelIndex) == MV_TRUE)
+            {
+                mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,
+                         "[%d %d]: SW reset Failed, timer expired\n",
+                         pSataAdapter->adapterId,channelIndex);
+                mvStopChannel(ialExt,
+                              channelIndex,
+                              scsiAdapterExt);
+            }
+        }
+    }
+    return MV_TRUE;
+}
+
+MV_BOOLEAN classifyAndInitDevice(MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt,
+				 MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+				 MV_U8 channelIndex, MV_U8 PMPort)
+{
+     
+     MV_SATA_DEVICE_TYPE deviceType;
+     MV_SATA_ADAPTER *pSataAdapter = scsiAdapterExt->pSataAdapter;
+     MV_IAL_COMMON_CHANNEL_EXTENSION* channelExt = &ialExt->IALChannelExt[channelIndex];
+     MV_SATA_SCSI_DRIVE_DATA *pDriveData = &scsiAdapterExt->ataDriveData[channelIndex][PMPort];
+     MV_STORAGE_DEVICE_REGISTERS *mvStorageDevRegisters = &channelExt->mvStorageDevRegisters;
+
+     deviceType = mvGetSataDeviceType(mvStorageDevRegisters);
+     if (deviceType == MV_SATA_DEVICE_TYPE_ATA_DISK)
+     {
+	  if (mvInitSataDisk(pSataAdapter,
+			     channelIndex ,
+			     PMPort, &pDriveData->identifyInfo,
+			     pDriveData->identifyBuffer) == MV_FALSE)
+	  {
+	       mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d %d]: Failed to initialize disk\n",
+			pSataAdapter->adapterId, channelIndex, PMPort);
+	       mvDrivesInfoFlushSingleDrive(ialExt, channelIndex, PMPort);
+	  }
+	  else
+	  {
+	       mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_INFO, "[%d %d %d]: Disk ready\n",
+			pSataAdapter->adapterId, channelIndex, PMPort);
+	       mvSetDriveReady(ialExt,
+			       scsiAdapterExt,
+			       channelIndex, PMPort,
+			       MV_TRUE,
+			       pDriveData->identifyBuffer);
+	       mvSataScsiNotifyUA(scsiAdapterExt, channelIndex, PMPort);
+	  }
+     }
+#ifdef MV_SUPPORT_ATAPI
+     else if (deviceType == MV_SATA_DEVICE_TYPE_ATAPI_DEVICE)
+     {
+	  if (mvInitSataATAPI(pSataAdapter,
+			      channelIndex ,
+			      PMPort, &pDriveData->identifyInfo,
+			      pDriveData->identifyBuffer) == MV_FALSE)
+	  {
+	       mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d %d]: Failed to initialize ATAPI device\n",
+			pSataAdapter->adapterId, channelIndex, PMPort);
+                    mvDrivesInfoFlushSingleDrive(ialExt, channelIndex, PMPort);
+	  }
+	  else
+	  {
+	       mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_INFO, "[%d %d %d]: ATAPI device ready\n",
+			pSataAdapter->adapterId, channelIndex, PMPort);
+	       mvSetDriveReady(ialExt,
+                                    scsiAdapterExt,
+			       channelIndex, PMPort,
+			       MV_TRUE,
+			       pDriveData->identifyBuffer);
+	       mvSataScsiNotifyUA(scsiAdapterExt, channelIndex, PMPort);
+	  }
+     }
+#endif
+     else  
+     {
+	  mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d %d]: bad type for the connected device, deviceType = %d\n",
+		   pSataAdapter->adapterId, channelIndex, PMPort, deviceType - MV_SATA_DEVICE_TYPE_UNKNOWN);
+	  mvDrivesInfoFlushSingleDrive(ialExt, channelIndex, PMPort);
+     }
+     return MV_TRUE;
+}
+static MV_BOOLEAN mvPMPortProbeLink(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+				    MV_U8 channelIndex,
+				    MV_U8 PMPort,
+				    MV_BOOLEAN force_speed_gen1,
+				    MV_U32 *SStatus,
+				    MV_BOOLEAN *H2DReceived)
+{
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+    
+    mvPMDevEnableStaggeredSpinUpPort(pSataAdapter, channelIndex, PMPort, 
+				     force_speed_gen1);
+    /* clear N bit (16) and X bit (26)in serror */
+    /* some driver expect the host to respond with R_RDY immediatly */
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex, PMPort,
+			MV_SATA_PSCR_SERROR_REG_NUM, 
+			MV_BIT26 | MV_BIT18 |MV_BIT16, NULL) ==
+	MV_FALSE)
+    {
+	 mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,
+		  "[%d %d %d]: PM Write SERROR Failed\n",
+		  pSataAdapter->adapterId, channelIndex, PMPort);
+    }
+    mvMicroSecondsDelay(pSataAdapter, 50000);
+    *H2DReceived = mvSataIfD2HReceived(pSataAdapter, channelIndex, PMPort);
+    
+    /* clear again*/
+    mvPMDevWriteReg(pSataAdapter, channelIndex, PMPort,
+		    MV_SATA_PSCR_SERROR_REG_NUM,
+		    MV_BIT26| MV_BIT18 |MV_BIT16, NULL);
+    
+    if (mvPMDevReadReg(pSataAdapter, channelIndex, PMPort,
+		       MV_SATA_PSCR_SSTATUS_REG_NUM, SStatus, NULL) ==
+	MV_FALSE)
+    {
+	 mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d %d]: mvPMDevReadReg Failed\n",
+		  pSataAdapter->adapterId, channelIndex, PMPort);
+	 return MV_FALSE;
+    }
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_INFO, "[%d %d %d]: S-Status: 0x%x\n",
+	     pSataAdapter->adapterId,
+	     channelIndex, PMPort, *SStatus);
+    
+    /* clear X bit in serror */
+    if (mvPMDevWriteReg(pSataAdapter, channelIndex, PMPort,
+			MV_SATA_PSCR_SERROR_REG_NUM,
+			MV_BIT26 | MV_BIT18 | MV_BIT16, NULL) ==
+	MV_FALSE)
+    {
+	 mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,
+		  "[%d %d %d]: PM Write SERROR Failed\n",
+		  pSataAdapter->adapterId, channelIndex, PMPort);
+    }
+    return MV_TRUE;      
+}
+static MV_BOOLEAN mvPMInitDevicesStateHandler(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+					      MV_U8 channelIndex,
+					      MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt)
+{
+    MV_IAL_COMMON_CHANNEL_EXTENSION* channelExt =
+    &ialExt->IALChannelExt[channelIndex];
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+    MV_U8 PMPort = channelExt->devInSRST;
+    MV_U32 SStatus;
+    MV_STORAGE_DEVICE_REGISTERS *mvStorageDevRegisters = &channelExt->mvStorageDevRegisters;
+    MV_BOOLEAN H2DReceived = MV_FALSE;
+
+
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d] CHANNEL_PM_INIT_DEVICES port:%d status:%d\n",
+             ialExt->pSataAdapter->adapterId, channelIndex, PMPort,
+	     channelExt->port_state);
+    
+    if(channelExt->port_state == MV_PORT_NOT_INITIALIZED)
+    {
+	 MV_BOOLEAN found_device = MV_FALSE;
+	 MV_U32 retry_count = 0;
+	 MV_BOOLEAN force_speed_gen1 = MV_FALSE;
+	 do {
+	      if(mvPMPortProbeLink(ialExt, channelIndex, PMPort, force_speed_gen1,
+				   &SStatus, &H2DReceived) == MV_FALSE) {
+		   if (mvStorageDevATASoftResetDevice(pSataAdapter, channelIndex,
+						      MV_SATA_PM_CONTROL_PORT, NULL)
+		       == MV_FALSE)
+		   {
+			mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,
+				 "[%d %d]:failed to Soft Reset PM control port\n",
+				 pSataAdapter->adapterId, channelIndex);
+			return MV_FALSE;
+		   }
+		   PMPort++;
+		   if(PMPort == channelExt->PMnumberOfPorts)
+			break;
+		   else
+			continue;
+	      }
+	      
+	      if ((SStatus & 0xf) == 3) {
+		   if(H2DReceived == MV_TRUE){
+			channelExt->port_state = MV_PORT_ISSUE_SRST;
+		   }else{
+			mvSetChannelTimer(ialExt, channelIndex,
+					  MV_IAL_WAIT_FOR_RDY_TIMEOUT);
+			channelExt->port_state = MV_PORT_WAIT_FOR_RDY;
+		   }
+		   channelExt->devInSRST = PMPort;
+		   found_device = MV_TRUE;
+		   return MV_FALSE;
+	      }
+	      if((SStatus & 0xf) == 1) {
+		   if(retry_count++ < 5) {
+			/* probe link again 
+			 */
+			mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,
+				 "[%d %d %d]: retry link (%d)\n",
+				 pSataAdapter->adapterId, channelIndex, PMPort,
+				 SStatus & 0xf, retry_count);
+			
+			if((SStatus & 0xf0) == 0x10)
+			     force_speed_gen1 = MV_TRUE;
+			continue;
+		   }
+	      } 
+	      /* next PORT*/
+	      PMPort++;
+	      if(PMPort == channelExt->PMnumberOfPorts)
+	      {
+		   channelExt->port_state = MV_PORT_DONE;
+		   break;
+	      }
+	 }while(found_device == MV_FALSE);
+	 
+    }else if(channelExt->port_state == MV_PORT_WAIT_FOR_RDY){
+	 mvDecrementChannelTimer(ialExt, channelIndex);
+	 if(mvSataIfD2HReceived(pSataAdapter, channelIndex, PMPort) == MV_FALSE){
+	      mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,
+		       "[%d %d %d] - disk not ready: wait a little more\n",
+		       pSataAdapter->adapterId, channelIndex, PMPort);
+
+	      printAtaDeviceRegisters(mvStorageDevRegisters);
+	      if(mvIsChannelTimerExpired(ialExt, channelIndex) == MV_TRUE){
+		   mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,
+			    "[%d %d %d]: PM port signature timed out\n",
+			    pSataAdapter->adapterId, channelIndex, PMPort);
+	      }else{
+		   return MV_TRUE;
+	      }
+	 }else{
+	      mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_INFO, "[%d %d %d]: "
+		       "device signature received.\n",
+		       pSataAdapter->adapterId, channelIndex, PMPort);
+	 }
+	 channelExt->port_state = MV_PORT_ISSUE_SRST;
+	 channelExt->devInSRST = PMPort;
+	 return MV_FALSE; /* re-call this function without delay*/
+    }else if(channelExt->port_state == MV_PORT_ISSUE_SRST){
+	 MV_U32 SError;
+	 /* check if disk is connected*/
+	 mvPMDevReadReg(pSataAdapter, channelIndex, PMPort, 
+			MV_SATA_PSCR_SERROR_REG_NUM, &SError, NULL);
+	 mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d %d]:SError "
+		  " 0x%08x\n",
+		  pSataAdapter->adapterId, channelIndex, PMPort, SError);
+
+	 /*check N bit*/
+	 if(SError & MV_BIT16)
+	 {
+	      mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_INFO, "[%d %d %d]: "
+		       "link was changed\n",
+                       pSataAdapter->adapterId, channelIndex, PMPort);
+	      if(++channelExt->devInSRST == channelExt->PMnumberOfPorts)
+	      {
+		   channelExt->port_state = MV_PORT_DONE;
+	      }else{
+		   channelExt->port_state = MV_PORT_NOT_INITIALIZED;
+	      }
+
+	      return MV_TRUE;
+	 }
+
+
+
+	 if (mvStorageDevATAStartSoftResetDevice(pSataAdapter,
+						 channelIndex,
+						 PMPort) == MV_FALSE)
+	 {
+	      mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d %d]: "
+		       "failed to Soft Reset PM device port.\n",
+		       pSataAdapter->adapterId, channelIndex, PMPort);
+	      /* this port not functional, next port*/
+	      channelExt->port_state = MV_PORT_NOT_INITIALIZED;
+	      channelExt->devInSRST++;
+	 }
+	 else
+	 {
+	      mvSetChannelTimer(ialExt, channelIndex, MV_IAL_SRST_TIMEOUT);
+	      channelExt->port_state = MV_PORT_IN_SRST;
+	      channelExt->devInSRST = PMPort;
+	      return MV_TRUE;
+	 }	 
+    }else if(channelExt->port_state == MV_PORT_IN_SRST){
+	 mvDecrementChannelTimer(ialExt, channelIndex);
+	 if (mvStorageIsDeviceBsyBitOff(pSataAdapter,
+					channelIndex,
+					mvStorageDevRegisters) == MV_FALSE)
+	 {
+	      if (mvIsChannelTimerExpired(ialExt, channelIndex) !=
+		  MV_TRUE)
+	      {
+		   mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d %d] - disk not ready: wait a "
+			    "little more\n",
+			    pSataAdapter->adapterId,
+			    channelIndex, PMPort);
+		   printAtaDeviceRegisters(mvStorageDevRegisters);
+		   return MV_TRUE;
+	      }
+	      /* SRST timeout*/
+	      mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d %d]: Soft Reset PM port time out\n",
+		       pSataAdapter->adapterId, channelIndex, PMPort);
+	      
+	      if (mvStorageDevATASoftResetDevice(pSataAdapter, channelIndex,
+						 MV_SATA_PM_CONTROL_PORT, NULL) == MV_FALSE)
+	      {
+		   mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: "
+			    "failed to Soft Reset PM control port\n",
+			    pSataAdapter->adapterId, channelIndex);
+		   return MV_FALSE;
+	      }
+	      
+	      if(++channelExt->devInSRST == channelExt->PMnumberOfPorts)
+	      {
+		   channelExt->port_state = MV_PORT_DONE;
+	      }else{
+		   channelExt->port_state = MV_PORT_NOT_INITIALIZED;
+		   return MV_TRUE;
+	      }
+	      
+	 }
+	 /* SRST completed*/
+	 channelExt->port_state = MV_PORT_INIT_DEVICE;
+	 return MV_TRUE;
+    }else if(channelExt->port_state == MV_PORT_INIT_DEVICE){
+	 MV_U32 SError;
+	 /* check if disk is connected*/
+	 mvPMDevReadReg(pSataAdapter, channelIndex, PMPort, 
+			MV_SATA_PSCR_SERROR_REG_NUM, &SError, NULL);
+	 mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d %d]:SError "
+		  " 0x%08x\n",
+		  pSataAdapter->adapterId, channelIndex, PMPort, SError);
+
+	 /*check N bit*/
+	 if(SError & MV_BIT16)
+	 {
+	      mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_INFO, "[%d %d %d]: "
+		       "link was changed\n",
+		       pSataAdapter->adapterId, channelIndex, PMPort);
+	 } else {
+	      classifyAndInitDevice(scsiAdapterExt, ialExt,
+				    channelIndex, PMPort);
+	 }
+	 /* next port*/
+	 if(++channelExt->devInSRST == channelExt->PMnumberOfPorts)
+	 {
+	      channelExt->port_state = MV_PORT_DONE;
+	 }else{
+	      channelExt->port_state = MV_PORT_NOT_INITIALIZED;
+	      return MV_TRUE;
+	 }
+    }
+    
+    if(channelExt->port_state == MV_PORT_DONE) {
+	 mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_INFO,"[%d %d]: PM devices initialized\n",  pSataAdapter->adapterId,
+		  channelIndex, PMPort, channelExt->port_state);
+#if 0
+	 if (clearSErrorPorts(ialExt->pSataAdapter, channelIndex,
+			      ialExt->IALChannelExt[channelIndex].PMnumberOfPorts) != 
+	     MV_TRUE)
+	 {
+	      return MV_FALSE;
+	 }
+#endif
+#if 1
+	 if (mvPMEnableCommStatusChangeBits(ialExt,
+					    channelIndex,
+					    MV_TRUE) != MV_TRUE)
+	 {
+	      return MV_FALSE;
+	 }
+	 if (mvPMEnableAsyncNotify(ialExt, channelIndex) == MV_FALSE)
+	 {
+	      return MV_FALSE;
+	 }
+#endif
+	 if (mvConfigChannelDMA(ialExt,
+				channelIndex,
+				scsiAdapterExt) == MV_TRUE)
+	 {
+	      mvSetChannelState(ialExt, channelIndex, CHANNEL_READY);
+	      
+	 }
+	 else
+	 {
+	      mvStopChannel(ialExt, channelIndex, scsiAdapterExt);
+	 }
+    }else if(channelExt->port_state == MV_PORT_FAILED){
+	 mvStopChannel(ialExt, channelIndex, scsiAdapterExt);
+    }else {
+	 mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_FATAL_ERROR,"[%d %d %d] - unknown port"
+		  " status: %d\n",  pSataAdapter->adapterId,
+		  channelIndex, PMPort, channelExt->port_state);
+    }
+    return MV_TRUE;
+}
+
+static MV_BOOLEAN mvChannelReadyStateHandler(
+                                            MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                            MV_U8 channelIndex)
+{
+
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+    if ((ialExt->IALChannelExt[channelIndex].pmRegAccessInProgress == MV_FALSE) &&
+        (mvStorageDevGetDeviceType (pSataAdapter, channelIndex) == MV_SATA_DEVICE_TYPE_PM) &&
+        (ialExt->IALChannelExt[channelIndex].pmAsyncNotifyEnabled == MV_FALSE))
+    {
+        /*poll pm GSCR error register one time of 4 steps (2 seconds)*/
+        if (ialExt->IALChannelExt[channelIndex].pmRegPollCounter++ & 0x3) 
+        {
+            return MV_TRUE;
+        }
+        if (mvQueuePMAccessRegisterCommand(ialExt,
+                                           channelIndex,
+                                           MV_SATA_PM_CONTROL_PORT,
+                                           MV_SATA_GSCR_ERROR_REG_NUM,
+                                           0,
+                                           MV_TRUE) == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d] error reading "
+                     " PM GSCR_ERROR register.\n",
+                     pSataAdapter->adapterId, channelIndex);
+        }
+    }
+    mvSata60X1B2CheckDevError(pSataAdapter, channelIndex);
+    return MV_TRUE;
+}
+
+
+static MV_BOOLEAN mvChannelPMHotPlugStateHandler(
+                                                MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                                MV_U8 channelIndex,
+                                                MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt)
+{
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d] CHANNEL_PM_HOT_PLUG\n",
+             ialExt->pSataAdapter->adapterId, channelIndex);
+    mvSataDisableChannelDma(ialExt->pSataAdapter, channelIndex);
+    mvSataFlushDmaQueue (ialExt->pSataAdapter,
+                         channelIndex, MV_FLUSH_TYPE_CALLBACK);
+    mvSataChannelHardReset(ialExt->pSataAdapter, channelIndex);
+    mvRestartChannel(ialExt, channelIndex, scsiAdapterExt, MV_FALSE);
+    return MV_TRUE;
+}
+
+static MV_BOOLEAN mvChannelStateMachine(
+                                       MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                       MV_U8 channelIndex,
+                                       MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt)
+{
+    MV_BOOLEAN res = MV_FALSE;
+    do
+    {
+        switch (ialExt->channelState[channelIndex])
+        {
+        case CHANNEL_NOT_CONNECTED:
+            res = mvChannelNotConnectedStateHandler(ialExt,
+                                                    channelIndex,
+                                                    scsiAdapterExt);
+            break;
+        case CHANNEL_CONNECTED:
+            res = mvChannelConnectedStateHandler(ialExt,
+                                                 channelIndex,
+                                                 scsiAdapterExt);
+            break;
+        case CHANNEL_IN_SRST:
+            res = mvChannelInSrstStateHandler(ialExt,
+                                              channelIndex,
+                                              scsiAdapterExt);
+            break;
+        case CHANNEL_PM_INIT_DEVICES:
+            res = mvPMInitDevicesStateHandler(ialExt,
+					      channelIndex,
+					      scsiAdapterExt);
+            break;
+        case CHANNEL_READY:
+            res = mvChannelReadyStateHandler(ialExt,
+                                             channelIndex);
+            break;
+        case CHANNEL_PM_HOT_PLUG:
+            res = mvChannelPMHotPlugStateHandler(ialExt,
+                                                 channelIndex,
+                                                 scsiAdapterExt);
+            break;
+        default:
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d]: Unknown channel state.\n",
+                     ialExt->pSataAdapter->adapterId, channelIndex);
+            return MV_FALSE;
+        }
+    } while (res == MV_FALSE);
+
+    return MV_TRUE;
+}
+
+
+static MV_BOOLEAN mvAdapterStateMachine(
+                                       MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                       MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt)
+{
+    MV_BOOLEAN res = MV_TRUE;
+    MV_U8 channelIndex;
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+    switch (ialExt->adapterState)
+    {
+    case ADAPTER_INITIALIZING:     {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d] ADAPTER_INITIALIZING\n",
+                     pSataAdapter->adapterId);
+ 
+            res = mvSataEnableStaggeredSpinUpAll(pSataAdapter);
+            if (res == MV_TRUE)
+            {
+                if (mvSataUnmaskAdapterInterrupt(pSataAdapter) == MV_FALSE)
+                {
+                    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d]: "
+                             "mvSataUnmaskAdapterInterrupt failed\n",
+                             pSataAdapter->adapterId);
+                    ialExt->adapterState = ADAPTER_FATAL_ERROR;
+                    return MV_FALSE;
+                }
+                ialExt->adapterState = ADAPTER_READY;
+            }
+        }
+        break;
+    case ADAPTER_READY:
+        for (channelIndex = 0;
+            channelIndex < pSataAdapter->numberOfChannels; channelIndex++)
+        {
+
+            mvChannelStateMachine(ialExt,
+                                  channelIndex,
+                                  scsiAdapterExt);
+        }
+        return MV_TRUE;
+        break;
+    default:
+        break;
+    }
+
+    if (ialExt->adapterState != ADAPTER_READY)
+    {
+        return res;
+    }
+
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d] ADAPTER_READY\n",
+             pSataAdapter->adapterId);
+
+    /*Start channel initialization for connected channels*/
+    for (channelIndex = 0;
+        channelIndex < pSataAdapter->numberOfChannels;
+        channelIndex++)
+    {
+        mvFlushSCSICommandQueue(ialExt, channelIndex);
+        if (mvSataIsStorageDeviceConnected(pSataAdapter, channelIndex, NULL) ==
+            MV_FALSE)
+        {
+            mvSetChannelState(ialExt,
+                              channelIndex,
+                              CHANNEL_NOT_CONNECTED);
+            continue;
+        }
+
+        mvSetChannelState(ialExt,
+                          channelIndex,
+                          CHANNEL_CONNECTED);
+	
+        if (mvChannelStateMachine(ialExt,
+                                  channelIndex,
+                                  scsiAdapterExt) == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d]: Failed to "
+                     "start channel.\n", pSataAdapter->adapterId, channelIndex);
+            mvSetChannelState(ialExt,
+                              channelIndex,
+                              CHANNEL_NOT_CONNECTED);
+            mvFlushSCSICommandQueue(ialExt, channelIndex);
+            mvSataRemoveChannel(pSataAdapter,channelIndex);
+            IALReleaseChannel(pSataAdapter, channelIndex);
+            pSataAdapter->sataChannel[channelIndex] = NULL;
+            mvDrivesInfoFlushAll(ialExt, channelIndex);
+            mvSetDriveReady(ialExt,
+                            scsiAdapterExt,
+                            channelIndex,
+                            0xFF, MV_FALSE, NULL);
+            continue;
+        }
+    }
+    return res;
+}
+
+static MV_BOOLEAN mvGetDisksModes(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                  MV_SAL_ADAPTER_EXTENSION *pScsiAdapterExt,
+                                  MV_U8 channelIndex,
+                                  MV_BOOLEAN *TCQ,
+                                  MV_BOOLEAN *NCQ,
+                                  MV_U8   *numOfDrives)
+{
+    MV_SATA_ADAPTER *pSataAdapter = ialExt->pSataAdapter;
+    MV_BOOLEAN allNCQ = MV_TRUE;
+    MV_BOOLEAN allTCQ = MV_TRUE;
+    MV_U8               i;
+
+    if ((pSataAdapter == NULL) || (pScsiAdapterExt == NULL))
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_FATAL_ERROR,"[%d %d]"
+                 " mvGetDisksModes failed, bad pointer\n",
+                 pSataAdapter->adapterId, channelIndex);
+        return MV_FALSE;
+    }
+    if ((ialExt->adapterState != ADAPTER_READY) ||
+        (ialExt->channelState[channelIndex] == CHANNEL_NOT_CONNECTED))
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_FATAL_ERROR,"[%d %d] "
+                 "mvGetDisksModes failed,Bad Adapter or Channel State\n",
+                 pSataAdapter->adapterId, channelIndex);
+        return MV_FALSE;
+    }
+    if (pSataAdapter->sataChannel[channelIndex] == NULL)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_FATAL_ERROR,"[%d %d] "
+                 "mvGetDisksModes failed, channel not configured\n",
+                 pSataAdapter->adapterId, channelIndex);
+        return MV_FALSE;
+    }
+    *numOfDrives = 0;
+    for (i = 0; i < MV_SATA_PM_MAX_PORTS; i++)
+    {
+        if ((pScsiAdapterExt->
+            ataDriveData[channelIndex][i].driveReady == MV_TRUE) &&
+           (pScsiAdapterExt->ataDriveData[channelIndex][i].identifyInfo.deviceType == MV_SATA_DEVICE_TYPE_ATA_DISK))
+        {
+            (*numOfDrives)++;
+
+            if (pScsiAdapterExt->ataDriveData[channelIndex][i].
+                identifyInfo.DMAQueuedModeSupported == MV_FALSE)
+            {
+                allTCQ = MV_FALSE;
+            }
+            if (pScsiAdapterExt->
+                ataDriveData[channelIndex][i].identifyInfo.
+                SATACapabilities.NCQSupported == MV_FALSE)
+            {
+                allNCQ = MV_FALSE;
+            }
+        }
+    }
+
+    if (TCQ)
+    {
+        if ((*numOfDrives > 0) && (allTCQ == MV_TRUE))
+        {
+            *TCQ = MV_TRUE;
+        }
+        else
+        {
+            *TCQ = MV_FALSE;
+        }
+    }
+    if (NCQ)
+    {
+        if ((*numOfDrives > 0) && (allNCQ == MV_TRUE))
+        {
+            *NCQ = MV_TRUE;
+        }
+        else
+        {
+            *NCQ = MV_FALSE;
+        }
+    }
+    return MV_TRUE;
+}
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommon.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommon.h
new file mode 100644
index 0000000..b9961d8
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommon.h
@@ -0,0 +1,195 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* mvIALCommon.h
+*
+* DESCRIPTION:
+*       H implementation for IAL's common functions.
+*
+* DEPENDENCIES:
+*   mvSata.h
+*   mvStorageDev.h
+*
+*******************************************************************************/
+#ifndef __INCmvIALCommonh
+#define __INCmvIALCommonh
+
+#ifdef __cplusplus
+extern "C" {
+#endif /* __cplusplus */
+
+/* includes */
+#include "mvSata.h"
+#include "mvStorageDev.h"
+
+/* defines  */
+
+/*Timer period in milliseconds*/
+#define MV_IAL_ASYNC_TIMER_PERIOD       500
+#define MV_IAL_SRST_TIMEOUT             31000
+#define MV_IAL_WAIT_FOR_RDY_TIMEOUT     10000
+/* typedefs */
+
+
+
+typedef enum mvAdapterState
+{
+    ADAPTER_INITIALIZING,
+    ADAPTER_READY,
+    ADAPTER_FATAL_ERROR
+} MV_ADAPTER_STATE;
+
+typedef enum mvChannelState
+{
+    CHANNEL_NOT_CONNECTED,
+    CHANNEL_CONNECTED,
+    CHANNEL_IN_SRST,
+    CHANNEL_PM_INIT_DEVICES,
+    CHANNEL_READY,
+    CHANNEL_PM_HOT_PLUG,
+} MV_CHANNEL_STATE;
+
+typedef struct mvDriveSerialNumber
+{
+    MV_U8 serial[IDEN_SERIAL_NUM_SIZE];    
+}   MV_DRIVE_SERIAL_NUMBER;
+
+
+typedef struct mvDrivesInfo
+{
+    MV_U16                      drivesSnapshotSaved;
+    MV_DRIVE_SERIAL_NUMBER      driveSerialSaved[MV_SATA_PM_MAX_PORTS];    
+    MV_U16                      drivesSnapshotCurrent;
+    MV_DRIVE_SERIAL_NUMBER      driveSerialCurrent[MV_SATA_PM_MAX_PORTS];    
+}   MV_DRIVES_INFO;
+
+typedef enum mvPortState
+{
+    MV_PORT_NOT_INITIALIZED,
+    MV_PORT_WAIT_FOR_RDY, /* wait for the disk's signature*/
+    MV_PORT_ISSUE_SRST,
+    MV_PORT_IN_SRST,
+    MV_PORT_INIT_DEVICE,
+    MV_PORT_DONE, /* PM ports scan is complete successfully*/
+    MV_PORT_FAILED
+} MV_PORT_STATE;
+
+typedef struct mvIALChannelExtension
+{
+    MV_U8                       PMnumberOfPorts;
+    MV_U16                      PMdevsToInit;
+    MV_U8                       devInSRST;
+    MV_PORT_STATE		port_state;
+    MV_BOOLEAN                  completionError;
+    MV_U8                       pmAccessType;
+    MV_U8                       pmReg;
+    MV_BOOLEAN                  pmRegAccessInProgress;
+    MV_BOOLEAN                  pmAsyncNotifyEnabled;
+    MV_U8                       pmRegPollCounter;
+    MV_U32                      SRSTTimerThreshold;
+    MV_U32                      SRSTTimerValue;
+    MV_VOID_PTR                 IALChannelPendingCmdQueue;
+    MV_BOOLEAN                  bHotPlug;
+    MV_DRIVES_INFO              drivesInfo;
+    MV_STORAGE_DEVICE_REGISTERS mvStorageDevRegisters;
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO       commandInfo;
+#endif
+} MV_IAL_COMMON_CHANNEL_EXTENSION;
+
+
+typedef struct mvIALCommonAdapterExtension
+{
+    MV_SATA_ADAPTER   *pSataAdapter;
+    MV_ADAPTER_STATE  adapterState;
+    MV_CHANNEL_STATE  channelState[MV_SATA_CHANNELS_NUM];
+    MV_IAL_COMMON_CHANNEL_EXTENSION IALChannelExt[MV_SATA_CHANNELS_NUM];
+} MV_IAL_COMMON_ADAPTER_EXTENSION;
+
+
+/*Public functions*/
+MV_BOOLEAN mvAdapterStartInitialization(MV_SATA_ADAPTER* pSataAdapter,
+                                        MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                        MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt);
+
+void mvRestartChannel(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                      MV_U8 channelIndex,
+                      MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt,
+                      MV_BOOLEAN    bBusReset);
+
+void mvStopChannel(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                   MV_U8 channelIndex,
+                   MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt);
+
+void mvPMHotPlugDetected(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                         MV_U8 channelIndex,
+                         MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt);
+
+
+MV_SCSI_COMMAND_STATUS_TYPE mvExecuteScsiCommand(MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                                                 MV_BOOLEAN canQueue);
+
+MV_BOOLEAN  mvIALTimerCallback(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                               MV_SAL_ADAPTER_EXTENSION *scsiAdapterExt);
+
+void mvCommandCompletionErrorHandler(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                     MV_U8 channelIndex);
+
+MV_BOOLEAN mvRemoveFromSCSICommandQueue(MV_IAL_COMMON_ADAPTER_EXTENSION *ialExt,
+                                        MV_U8 channelIndex,
+                                        MV_SATA_SCSI_CMD_BLOCK *pScb);
+
+/*The following functions which must be implemented in IAL*/
+
+MV_BOOLEAN IALConfigQueuingMode(MV_SATA_ADAPTER *pSataAdapter,
+                                MV_U8 channelIndex,
+                                MV_EDMA_MODE mode,
+                                MV_SATA_SWITCHING_MODE switchingMode,
+                                MV_BOOLEAN  use128Entries);
+
+
+MV_BOOLEAN IALInitChannel(MV_SATA_ADAPTER *pSataAdapter, MV_U8 channelIndex);
+
+void IALReleaseChannel(MV_SATA_ADAPTER *pSataAdapter, MV_U8 channelIndex);
+MV_BOOLEAN IALBusChangeNotify(MV_SATA_ADAPTER *pSataAdapter,
+                              MV_U8 channelIndex);
+MV_BOOLEAN IALBusChangeNotifyEx(MV_SATA_ADAPTER *pSataAdapter, 
+                                MV_U8 channelIndex, 
+                                MV_U16 targetsToRemove,
+                                MV_U16 targetsToAdd);
+
+
+extern MV_BOOLEAN disableNCQ;
+extern MV_BOOLEAN disablePM_NCQ;
+
+#ifdef __cplusplus
+}
+#endif /* __cplusplus */
+
+#endif /* __INCmvIALCommonh */
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommonUtils.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommonUtils.c
new file mode 100644
index 0000000..d88109d
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommonUtils.c
@@ -0,0 +1,1274 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* mvIALCommonUtils.c
+*
+* DESCRIPTION:
+*       C implementation for IAL's extension utility functions.
+*
+* DEPENDENCIES:
+*   mvIALCommonUtils.h
+*
+*******************************************************************************/
+
+/* includes */
+#include "mvOs.h"
+#include "mvIALCommonUtils.h"
+
+#define MV_ANY_PM {0, 0, 0, 0, 0}
+#define MV_MARVELL_PM_A0 {0x11AB, 0x1116, 0, 0, 0}
+#define MV_MARVELL_PM {0x11AB, 0x1116, 0xFF, 0, 0}
+struct _EDMAConfiguration
+{
+    MV_U8                   configNumber;
+    /*inputs*/
+    MV_SATA_GEN             adapterGen;
+    MV_SATA_DEVICE_TYPE     connectedDevice;
+    MV_BOOLEAN              specificPM;
+    MV_SATA_PM_DEVICE_INFO  PMInfo;
+    MV_BOOLEAN              AllNCQ;
+    MV_BOOLEAN              AllTCQ;
+    MV_U8                   maxDisks;
+    /*outputs*/
+    MV_EDMA_MODE            EDMAMode;
+    MV_SATA_SWITCHING_MODE  switchingMode;
+    MV_BOOLEAN              use128Entries;
+} EDMAConfigurations[] =
+{
+    /*Gen1, TCQ disk*/
+    {1, MV_SATA_GEN_I, MV_SATA_DEVICE_TYPE_ATA_DISK, MV_FALSE, MV_ANY_PM, MV_FALSE, MV_TRUE, 1,
+        MV_EDMA_MODE_QUEUED, MV_SATA_SWITCHING_MODE_NONE, MV_FALSE},
+    /*Gen1, Normal disk*/
+    {2, MV_SATA_GEN_I, MV_SATA_DEVICE_TYPE_ATA_DISK, MV_FALSE, MV_ANY_PM, MV_FALSE, MV_FALSE, 1,
+        MV_EDMA_MODE_NOT_QUEUED, MV_SATA_SWITCHING_MODE_NONE, MV_FALSE},
+    /*Gen2, NCQ disk*/
+    {3, MV_SATA_GEN_II, MV_SATA_DEVICE_TYPE_ATA_DISK, MV_FALSE, MV_ANY_PM, MV_TRUE, MV_FALSE, 1,
+        MV_EDMA_MODE_NATIVE_QUEUING, MV_SATA_SWITCHING_MODE_NONE, MV_FALSE},
+    /*Gen2, TCQ disk*/
+    {4, MV_SATA_GEN_II, MV_SATA_DEVICE_TYPE_ATA_DISK, MV_FALSE, MV_ANY_PM, MV_FALSE, MV_TRUE, 1,
+        MV_EDMA_MODE_QUEUED, MV_SATA_SWITCHING_MODE_NONE, MV_FALSE},
+    /*Gen2, Normal disk*/
+    {5, MV_SATA_GEN_II, MV_SATA_DEVICE_TYPE_ATA_DISK, MV_FALSE, MV_ANY_PM, MV_FALSE, MV_FALSE, 1,
+        MV_EDMA_MODE_NOT_QUEUED, MV_SATA_SWITCHING_MODE_NONE, MV_FALSE},
+    /*Gen2, Marvell PM, NCQ disks*/
+    /*{6, MV_SATA_GEN_II, MV_SATA_DEVICE_TYPE_PM, MV_TRUE, MV_MARVELL_PM, MV_TRUE, MV_FALSE, MV_SATA_PM_MAX_PORTS,
+        MV_EDMA_MODE_NATIVE_QUEUING, MV_SATA_SWITCHING_MODE_QCBS, MV_FALSE},*/
+    /*Gen2, Marvell PM, single TCQ disk*/
+    /*{7, MV_SATA_GEN_II, MV_SATA_DEVICE_TYPE_PM, MV_TRUE, MV_MARVELL_PM, MV_FALSE, MV_TRUE, 1,
+        MV_EDMA_MODE_QUEUED, MV_SATA_SWITCHING_MODE_QCBS, MV_FALSE},*/
+    /*Gen2, Marvell PM, Normal disks*/
+    /*{8, MV_SATA_GEN_II, MV_SATA_DEVICE_TYPE_PM, MV_TRUE, MV_MARVELL_PM, MV_FALSE, MV_FALSE, MV_SATA_PM_MAX_PORTS,
+        MV_EDMA_MODE_NOT_QUEUED, MV_SATA_SWITCHING_MODE_QCBS, MV_FALSE},*/
+    /*Gen2, PM, single NCQ disk*/
+    {9, MV_SATA_GEN_II, MV_SATA_DEVICE_TYPE_PM, MV_FALSE, MV_ANY_PM, MV_TRUE, MV_FALSE, 1,
+        MV_EDMA_MODE_NATIVE_QUEUING, MV_SATA_SWITCHING_MODE_CBS, MV_FALSE},
+    /*Gen2, PM, single TCQ disk*/
+    {10, MV_SATA_GEN_II, MV_SATA_DEVICE_TYPE_PM, MV_FALSE, MV_ANY_PM, MV_FALSE, MV_TRUE, 1,
+        MV_EDMA_MODE_QUEUED, MV_SATA_SWITCHING_MODE_CBS, MV_FALSE},
+    /*Gen2, PM, Normal disks*/
+    {11, MV_SATA_GEN_II, MV_SATA_DEVICE_TYPE_PM, MV_FALSE, MV_ANY_PM, MV_FALSE, MV_FALSE, MV_SATA_PM_MAX_PORTS,
+        MV_EDMA_MODE_NOT_QUEUED, MV_SATA_SWITCHING_MODE_CBS, MV_FALSE},
+    /*Gen2E, NCQ disk*/
+    {12, MV_SATA_GEN_IIE, MV_SATA_DEVICE_TYPE_ATA_DISK, MV_FALSE, MV_ANY_PM, MV_TRUE, MV_FALSE, 1,
+        MV_EDMA_MODE_NATIVE_QUEUING, MV_SATA_SWITCHING_MODE_NONE, MV_FALSE},
+    /*Gen2E, TCQ disk*/
+    {13, MV_SATA_GEN_IIE, MV_SATA_DEVICE_TYPE_ATA_DISK, MV_FALSE, MV_ANY_PM, MV_FALSE, MV_TRUE, 1,
+        MV_EDMA_MODE_QUEUED, MV_SATA_SWITCHING_MODE_NONE, MV_FALSE},
+    /*Gen2E, Normal disk*/
+    {14, MV_SATA_GEN_IIE, MV_SATA_DEVICE_TYPE_ATA_DISK, MV_FALSE, MV_ANY_PM, MV_FALSE, MV_FALSE, 1,
+        MV_EDMA_MODE_NOT_QUEUED, MV_SATA_SWITCHING_MODE_NONE, MV_FALSE},
+    /*Gen2E, Marvell PM <= A0, NCQ disks*/
+    {15, MV_SATA_GEN_IIE, MV_SATA_DEVICE_TYPE_PM, MV_TRUE, MV_MARVELL_PM_A0, MV_TRUE, MV_FALSE, MV_SATA_PM_MAX_PORTS,
+        MV_EDMA_MODE_NOT_QUEUED, MV_SATA_SWITCHING_MODE_CBS, MV_FALSE},
+    /*Gen2E, PM, NCQ disks*/
+    {16, MV_SATA_GEN_IIE, MV_SATA_DEVICE_TYPE_PM, MV_FALSE, MV_ANY_PM, MV_TRUE, MV_FALSE, MV_SATA_PM_MAX_PORTS,
+        MV_EDMA_MODE_NATIVE_QUEUING, MV_SATA_SWITCHING_MODE_FBS, MV_TRUE},
+    /*Gen2E, Marvell PM <= A0, single TCQ disk*/
+    {17, MV_SATA_GEN_IIE, MV_SATA_DEVICE_TYPE_PM, MV_TRUE, MV_MARVELL_PM_A0, MV_FALSE, MV_TRUE, 1,
+        MV_EDMA_MODE_QUEUED, MV_SATA_SWITCHING_MODE_CBS, MV_FALSE},
+    /*Gen2E, PM, TCQ disks*/
+    {18, MV_SATA_GEN_IIE, MV_SATA_DEVICE_TYPE_PM, MV_FALSE, MV_ANY_PM, MV_FALSE, MV_TRUE, MV_SATA_PM_MAX_PORTS,
+        MV_EDMA_MODE_QUEUED, MV_SATA_SWITCHING_MODE_FBS, MV_TRUE},
+    /*Gen2E, Marvell PM <= A0, Normal disks*/
+    {19, MV_SATA_GEN_IIE, MV_SATA_DEVICE_TYPE_PM, MV_TRUE, MV_MARVELL_PM_A0, MV_FALSE, MV_FALSE, MV_SATA_PM_MAX_PORTS,
+        MV_EDMA_MODE_NOT_QUEUED, MV_SATA_SWITCHING_MODE_CBS, MV_FALSE},
+    /*Gen2E, PM, Normal disks*/
+    {20, MV_SATA_GEN_IIE, MV_SATA_DEVICE_TYPE_PM, MV_FALSE, MV_ANY_PM, MV_FALSE, MV_FALSE, MV_SATA_PM_MAX_PORTS,
+        MV_EDMA_MODE_NOT_QUEUED, MV_SATA_SWITCHING_MODE_FBS, MV_FALSE},
+    /*Gen2E , ATAPI device*/
+    {21, MV_SATA_GEN_IIE, MV_SATA_DEVICE_TYPE_ATAPI_DEVICE, MV_FALSE, MV_ANY_PM, MV_FALSE, MV_FALSE, 1,
+        MV_EDMA_MODE_NOT_QUEUED, MV_SATA_SWITCHING_MODE_NONE, MV_FALSE},
+
+};
+
+MV_VOID mvSelectConfiguration(MV_SATA_ADAPTER        *pSataAdapter,
+                              MV_U8                  channelIndex,
+                              MV_SATA_GEN            gen,
+                              MV_SATA_DEVICE_TYPE    connectedDevice,
+                              MV_SATA_PM_DEVICE_INFO *pPMInfo,
+                              MV_BOOLEAN             AllNCQ,
+                              MV_BOOLEAN             AllTCQ,
+                              MV_BOOLEAN             disks,
+                              MV_EDMA_MODE           *pEdmaMode,
+                              MV_SATA_SWITCHING_MODE *pSwitchingMode,
+                              MV_BOOLEAN             *pUse128Entries)
+{
+    MV_U32      i;
+    MV_U32      configurationsNum = sizeof(EDMAConfigurations)/sizeof(struct _EDMAConfiguration);       
+
+    for (i = 0; i < configurationsNum; i++)
+    {
+        if (gen != EDMAConfigurations[i].adapterGen)
+        {
+            continue;
+        }
+        if (connectedDevice != EDMAConfigurations[i].connectedDevice)
+        {
+            continue;
+        }
+        if ((connectedDevice == MV_SATA_DEVICE_TYPE_PM) &&
+            (EDMAConfigurations[i].specificPM == MV_TRUE))
+        {
+            if ((pPMInfo->vendorId != EDMAConfigurations[i].PMInfo.vendorId) ||
+                (pPMInfo->deviceId != EDMAConfigurations[i].PMInfo.deviceId) ||
+                (pPMInfo->productRevision > EDMAConfigurations[i].PMInfo.productRevision))
+            {
+                continue;
+            }
+        }
+        if ((EDMAConfigurations[i].AllNCQ == MV_TRUE) &&
+            (AllNCQ == MV_FALSE))
+        {
+            continue;
+        }
+        if ((EDMAConfigurations[i].AllTCQ == MV_TRUE) &&
+            (AllTCQ == MV_FALSE))
+        {
+            continue;
+        }
+        if (disks > EDMAConfigurations[i].maxDisks)
+        {
+            continue;
+        }
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]: mvSelectConfiguration"
+                 ": Matching configuration found #%d\n",
+                 pSataAdapter->adapterId,
+                 channelIndex, 
+                 EDMAConfigurations[i].configNumber);
+
+        *pEdmaMode = EDMAConfigurations[i].EDMAMode;     
+        *pSwitchingMode = EDMAConfigurations[i].switchingMode;
+        *pUse128Entries = EDMAConfigurations[i].use128Entries;
+	/* some of the integrated adapters doesn't support the EDMA 128 entries mode*/
+	if(pSataAdapter->hostInterface == MV_HOST_IF_INTEGRATED)
+	{
+		*pUse128Entries = MV_FALSE;
+	}
+        break;
+    }
+    if ( i >= configurationsNum)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_FATAL_ERROR, "[%d %d]:"
+                 " in mvSelectConfiguration failed to find matching configuration\n",
+                 pSataAdapter->adapterId,
+                 channelIndex);
+        *pEdmaMode = MV_EDMA_MODE_NOT_QUEUED;
+        *pSwitchingMode = MV_SATA_SWITCHING_MODE_NONE;
+        *pUse128Entries = MV_FALSE;
+    }
+#ifdef MV_LOGGER
+    {
+        char *edmaModeStr[] = { "TCQ", "Normal", "NCQ"};
+        char *switchingModeStr[] = {"None", "CBS", "QCBS", "FBS"};
+
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]:"
+                 "mvSelectConfiguration: EDMA %s, switch mode %s, 128 mode %s\n",
+                 pSataAdapter->adapterId,
+                 channelIndex,
+                 edmaModeStr[(*pEdmaMode - MV_EDMA_MODE_QUEUED) % 3],
+                 switchingModeStr[(*pSwitchingMode - MV_SATA_SWITCHING_MODE_NONE) % 4],
+                 (*pUse128Entries == MV_TRUE) ? "yes":"no");
+
+    }
+#endif
+}
+
+static MV_BOOLEAN mvConfigSataDisk(MV_SATA_ADAPTER *pSataAdapter,
+                                   MV_U8 channelIndex,
+                                   MV_U8 PMPort,
+                                   ATA_IDENTIFY_INFO   *pIdentifyInfo,
+                                   MV_U16_PTR identifyBuffer);
+
+
+static MV_VOID mvAta2HostString(MV_U16 *source, MV_U16 *target,
+                                MV_U32 wordsCount)
+{
+    MV_U32 i;
+    for (i=0 ; i < wordsCount; i++)
+    {
+        /* Big to little*/
+        target[i] = (source[i] >> 8) | ((source[i] & 0xff) << 8);
+        /* Little to cpu*/
+        target[i] = MV_LE16_TO_CPU(target[i]);
+    }
+}
+
+/******************************************************************************
+ *  Name: ParseIdentifyResult
+ *
+ *  Description:    this functions parses the identify command results, checks
+ *                  that the connected deives can be accesed by device EDMA,
+ *                  and updates the ATA drive parameters stucture accordingly.
+ *
+ *  Parameters:     pSataChannel - pointer to the channel data structure.
+ *                  pIdentifyInfo- pointer to the ATA parameters structure.
+ *
+ *  Returns:        MV_TRUE if the ATA drive supported by device.
+ *
+ ******************************************************************************/
+MV_BOOLEAN mvParseIdentifyResult(MV_U16_PTR  iden,
+                                 ATA_IDENTIFY_INFO   *pIdentifyInfo)
+{
+    char    temp[80];
+    MV_U8  version;
+    MV_BOOLEAN  udmaModeEnabled = MV_FALSE;
+
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "Parse IDENTIFY data:\n");
+
+    mvAta2HostString( iden + IDEN_MODEL_OFFSET, (MV_U16_PTR)temp, 24);
+    temp[25] = '\0';
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n","Model", temp);
+    memcpy(&pIdentifyInfo->model[0], iden + IDEN_MODEL_OFFSET, 24);
+    memcpy(&pIdentifyInfo->firmware[0], iden + IDEN_FIRMWARE_OFFSET, 4);
+    /* ATA version supported*/
+    if (iden[IDEN_ATA_VERSION] & MV_BIT7)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %d\n", "ATA version supported", 7);
+        version = 7;
+    }
+    else if (iden[IDEN_ATA_VERSION] & MV_BIT6)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %d\n", "ATA version supported", 6);
+        version = 6;
+    }
+    else if (iden[IDEN_ATA_VERSION] & MV_BIT5)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %d\n", "ATA version supported", 5);
+        version = 5;
+    }
+    else if (iden[IDEN_ATA_VERSION] & MV_BIT4)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %d\n", "ATA version supported", 4);
+        version = 4;
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, " IDENTIFY info: ATA "
+                 "version(%d) not supported\n", iden[IDEN_ATA_VERSION]);
+        return MV_FALSE;
+    }
+    pIdentifyInfo->version = version;
+    /*LBA addressing*/
+    if ((version >= 6) && (!(iden[IDEN_CAPACITY_1_OFFSET] & MV_BIT9)))
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, " IDENTIFY info: LBA not supported\n");
+        return MV_FALSE;
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "Capabilities",
+                 "LBA supported");
+    }
+    /* 48 bit address */
+    if ((version >= 6) && (iden[IDEN_SUPPORTED_COMMANDS2] & MV_BIT10))
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "LBA48 addressing", "supported");
+        pIdentifyInfo->LBA48Supported = MV_TRUE;
+
+	pIdentifyInfo->ATADiskSize = 
+		((MV_U64)iden[103] << 48) |
+		((MV_U64)iden[102] << 32) |
+		((MV_U64)iden[101] << 16) |
+		((MV_U64)iden[100]);
+
+                
+
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - 0x%x%04x%04x%04x sectors\n",
+                 "Number of sectors", iden[103] , iden[102], iden[101],
+                 iden[100]);
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n",
+                 "LBA48 addressing", "Not supported");
+        pIdentifyInfo->LBA48Supported = MV_FALSE;
+        pIdentifyInfo->ATADiskSize = (iden[IDEN_NUM_OF_ADDRESSABLE_SECTORS + 1] << 16) |
+                                     (iden[IDEN_NUM_OF_ADDRESSABLE_SECTORS]);
+
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - 0x%x sectors\n",
+                 "Number of sectors",
+                 (iden[IDEN_NUM_OF_ADDRESSABLE_SECTORS + 1] << 16) |
+                 ((MV_U32)iden[IDEN_NUM_OF_ADDRESSABLE_SECTORS]));
+
+
+    }
+    /*DMA support*/
+    if ((version >= 6) && (!(iden[IDEN_CAPACITY_1_OFFSET] & MV_BIT8)))
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "IDENTIFY info: DMA not "
+                 "supported\n");
+        return MV_FALSE;
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "Capabilities",
+                 "DMA supported");
+    }
+    /* PIO */
+    if ((iden[IDEN_VALID] & MV_BIT1) == 0)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, " IDENTIFY info: not "
+                 "able to find PIO mode\n");
+        return MV_FALSE;
+    }
+    else if (iden[IDEN_PIO_MODE_SPPORTED] & MV_BIT0)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "PIO mode 3",
+                 "supported");
+        pIdentifyInfo->PIOMode = MV_ATA_TRANSFER_PIO_3;
+    }
+    else if (iden[IDEN_PIO_MODE_SPPORTED] & MV_BIT1)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "PIO mode 4",
+                 "supported");
+        pIdentifyInfo->PIOMode = MV_ATA_TRANSFER_PIO_4;
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "IDENTIFY info: PIO "
+                 "modes 3 and 4 not supported\n");
+        pIdentifyInfo->PIOMode = MV_ATA_TRANSFER_PIO_SLOW;
+        return MV_FALSE;
+    }
+
+
+    /*UDMA*/
+    if ((iden[IDEN_VALID] & MV_BIT2) == 0)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, " IDENTIFY info: not "
+                 "able to find UDMA mode\n");
+        return MV_FALSE;
+    }
+
+
+    if ((version >= 7) && (iden[IDEN_UDMA_MODE] & MV_BIT6))
+    {
+        pIdentifyInfo->UdmaMode = MV_ATA_TRANSFER_UDMA_6;
+        if (iden[IDEN_UDMA_MODE] & MV_BIT14)
+        {
+            udmaModeEnabled = MV_TRUE;
+        }
+    }
+    else if ((version >= 6) && (iden[IDEN_UDMA_MODE] & MV_BIT5))
+    {
+        pIdentifyInfo->UdmaMode = MV_ATA_TRANSFER_UDMA_5;
+        if (iden[IDEN_UDMA_MODE] & MV_BIT13)
+        {
+            udmaModeEnabled = MV_TRUE;
+        }
+    }
+    else if ((version >= 5) && (iden[IDEN_UDMA_MODE] & MV_BIT4))
+    {
+        pIdentifyInfo->UdmaMode = MV_ATA_TRANSFER_UDMA_4;
+        if (iden[IDEN_UDMA_MODE] & MV_BIT12)
+        {
+            udmaModeEnabled = MV_TRUE;
+        }
+    }
+    else if ((version >= 4) && (iden[IDEN_UDMA_MODE] & MV_BIT3))
+    {
+        pIdentifyInfo->UdmaMode = MV_ATA_TRANSFER_UDMA_3;
+        if (iden[IDEN_UDMA_MODE] & MV_BIT11)
+        {
+            udmaModeEnabled = MV_TRUE;
+        }
+    }
+    else if (iden[IDEN_UDMA_MODE] & MV_BIT2)
+    {
+        pIdentifyInfo->UdmaMode = MV_ATA_TRANSFER_UDMA_2;
+        if (iden[IDEN_UDMA_MODE] & MV_BIT10)
+        {
+            udmaModeEnabled = MV_TRUE;
+        }
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "IDENTIFY info: Ultra"
+                 " DMA mode < 2 not supported IDENTIFY[88] 0x%04x\n",
+                 iden[IDEN_UDMA_MODE]);
+        pIdentifyInfo->UdmaMode = MV_ATA_TRANSFER_UDMA_0;
+        return MV_FALSE;
+    }
+    if (udmaModeEnabled == MV_TRUE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s%d%s\n",
+                 "Ultra DMA mode","UDMA mode ",
+                 pIdentifyInfo->UdmaMode - MV_ATA_TRANSFER_UDMA_0,
+                 " supported and enabled");
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s%d%s\n",
+                 "Ultra DMA mode","UDMA mode ",
+                 pIdentifyInfo->UdmaMode - MV_ATA_TRANSFER_UDMA_0,
+                 " supported but disabled");
+    }
+
+
+    if ((iden[IDEN_SUPPORTED_COMMANDS1] & MV_BIT13))
+    {
+        if (iden[IDEN_ENABLED_COMMANDS1] & MV_BIT13)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n",
+                     "READ BUFFER", "supported and enabled");
+        }
+        else
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n",
+                     "READ BUFFER", "supported and disabled");
+        }
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "READ BUFFER",
+                 " Not supported");
+    }
+
+    if ((iden[IDEN_SUPPORTED_COMMANDS1] & MV_BIT12))
+    {
+        if (iden[IDEN_ENABLED_COMMANDS1] & MV_BIT12)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n",
+                     "WRITE BUFFER", "supported and enabled");
+        }
+        else
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n",
+                     "WRITE BUFFER", "supported and disabled");
+        }
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "WRITE BUFFER",
+                 "Not supported");
+    }
+
+    if ((iden[IDEN_SUPPORTED_COMMANDS1] & MV_BIT6))
+    {
+        pIdentifyInfo->readAheadSupported = MV_TRUE;
+        if (iden[IDEN_ENABLED_COMMANDS1] & MV_BIT6)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n",
+                     "READ LOOK-AHEAD", "supported and enabled");
+            pIdentifyInfo->readAheadEnabled = MV_TRUE;
+        }
+        else
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n",
+                     "READ LOOK-AHEAD", "supported and disabled");
+            pIdentifyInfo->readAheadEnabled = MV_FALSE;
+        }
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n",
+                 "READ LOOK-AHEAD","Not supported");
+        pIdentifyInfo->readAheadSupported = MV_FALSE;
+        pIdentifyInfo->readAheadEnabled = MV_FALSE;
+    }
+
+    if ((iden[IDEN_SUPPORTED_COMMANDS1] & MV_BIT5))
+    {
+        pIdentifyInfo->writeCacheSupported = MV_TRUE;
+        if (iden[IDEN_ENABLED_COMMANDS1] & MV_BIT5)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n",
+                     "WRITE CACHE", "supported and enabled");
+            pIdentifyInfo->writeCacheEnabled = MV_TRUE;
+        }
+        else
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n",
+                     "WRITE CACHE", "supported and disabled");
+            pIdentifyInfo->writeCacheEnabled = MV_FALSE;
+        }
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "WRITE CACHE",
+                 "Not supported");
+        pIdentifyInfo->writeCacheSupported = MV_FALSE;
+        pIdentifyInfo->writeCacheEnabled = MV_FALSE;
+    }
+
+    if ((iden[IDEN_SUPPORTED_COMMANDS1] & MV_BIT3))
+    {
+
+        if (iden[IDEN_ENABLED_COMMANDS1] & MV_BIT3)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n",
+                     "POWER MANAGMENT", "supported and enabled");
+        }
+        else
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n",
+                     "POWER MANAGMENT", "supported and disabled");
+        }
+
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n",
+                 "POWER MANAGMENT","Not supported");
+    }
+
+    if ((iden[IDEN_SUPPORTED_COMMANDS1] & MV_BIT0))
+    {
+
+        if (iden[IDEN_ENABLED_COMMANDS1] & MV_BIT0)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n", "SMART",
+                     "supported and enabled");
+        }
+        else
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n", "SMART",
+                     "supported and disabled");
+        }
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "SMART",
+                 "Not supported");
+    }
+
+
+    /* check if REAd/WRITE DMA QUEUE commands supported */
+    pIdentifyInfo->DMAQueuedModeDepth = (iden[IDEN_QUEUE_DEPTH] & 0x1f) + 1;
+    if ((version >= 5) &&(iden[IDEN_SUPPORTED_COMMANDS2] & MV_BIT1))
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %15s Queue Depth %d\n",
+                 "READ/WRITE DMA QUEUE","supported",
+                 (iden[IDEN_QUEUE_DEPTH] & 0x1f) + 1);
+        pIdentifyInfo->DMAQueuedModeSupported = MV_TRUE;
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n",
+                 "READ/WRITE DMA QUEUE", "not supported");
+        pIdentifyInfo->DMAQueuedModeSupported = MV_FALSE;
+    }
+
+    /*check that the non-UDMA ATA commands supported*/
+
+    /*FLUSH CHACHE*/
+    if ((version >=6) && ((iden[IDEN_SUPPORTED_COMMANDS2] & MV_BIT12) == 0))
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n",
+                 "FLUSH CACHE command", "not supported");
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n",
+                 "FLUSH CACHE command", "supported");
+    }
+
+    pIdentifyInfo->SATACapabilities.SATA_GEN_I_supported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.SATA_GEN_II_supported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.NCQSupported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.RxHostInitiatedPMSupported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.TxDeviceInitiatedPMSupported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.TxDeviceInitiatedPMEnabled = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.DMASetupAutoActiveSupported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.DMASetupAutoActiveEnables = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.NonZeroBufferOffsetSupported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.NonZeroBufferOffsetEnabled = MV_FALSE;
+
+    if (version >= 6)
+    {
+        if (iden[IDEN_SATA_CAPABILITIES] & MV_BIT1)
+        {
+            pIdentifyInfo->SATACapabilities.SATA_GEN_I_supported = MV_TRUE;
+        }
+        else
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "SATA Gen I",
+                     "not supported");
+        }
+        if (iden[IDEN_SATA_CAPABILITIES] & MV_BIT2)
+        {
+            pIdentifyInfo->SATACapabilities.SATA_GEN_II_supported = MV_TRUE;
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "SATA Gen II",
+                     "supported");
+        }
+
+        if (iden[IDEN_SATA_CAPABILITIES] & MV_BIT8)
+        {
+            pIdentifyInfo->SATACapabilities.NCQSupported = MV_TRUE;
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "NCQ",
+                     "supported");
+        }
+
+        if (iden[IDEN_SATA_CAPABILITIES] & MV_BIT9)
+        {
+            pIdentifyInfo->SATACapabilities.RxHostInitiatedPMSupported = MV_TRUE;
+        }
+
+        if (iden[IDEN_SATA_FEATURES_SUPPORTED] & MV_BIT1)
+        {
+            pIdentifyInfo->SATACapabilities.NonZeroBufferOffsetSupported = MV_TRUE;
+            if (iden[IDEN_SATA_FEATURES_ENABLED] & MV_BIT1)
+            {
+                pIdentifyInfo->SATACapabilities.NonZeroBufferOffsetEnabled = MV_TRUE;
+            }
+        }
+        if (iden[IDEN_SATA_FEATURES_SUPPORTED] & MV_BIT2)
+        {
+            pIdentifyInfo->SATACapabilities.DMASetupAutoActiveSupported = MV_TRUE;
+            if (iden[IDEN_SATA_FEATURES_ENABLED] & MV_BIT2)
+            {
+                pIdentifyInfo->SATACapabilities.DMASetupAutoActiveEnables = MV_TRUE;
+            }
+        }
+        if (iden[IDEN_SATA_FEATURES_SUPPORTED] & MV_BIT3)
+        {
+            pIdentifyInfo->SATACapabilities.TxDeviceInitiatedPMSupported = MV_TRUE;
+            if (iden[IDEN_SATA_FEATURES_ENABLED] & MV_BIT3)
+            {
+                pIdentifyInfo->SATACapabilities.TxDeviceInitiatedPMEnabled = MV_TRUE;
+            }
+        }
+    }
+
+    return MV_TRUE;
+}
+MV_BOOLEAN mvParseIdentifyPacketResult(MV_U16_PTR  iden,
+                                 ATA_IDENTIFY_INFO   *pIdentifyInfo)
+{
+    char    temp[80];
+    MV_U8  version = 6;
+    MV_BOOLEAN  udmaModeEnabled = MV_FALSE;
+
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "Parse IDENTIFY data:\n");
+    if ((iden[0] & 0x3) == 0)
+    {
+        pIdentifyInfo->commandPacketLength = 12;
+    }
+    else if ((iden[0] & 0x3) == 1)
+    {
+        pIdentifyInfo->commandPacketLength = 16;
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "IDENTIFY info: bad command packet length\n");
+        
+        return MV_FALSE;
+    }
+
+    mvAta2HostString( iden + IDEN_MODEL_OFFSET, (MV_U16_PTR)temp, 24);
+    temp[25] = '\0';
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n","Model", temp);
+    memcpy(&pIdentifyInfo->model[0], iden + IDEN_MODEL_OFFSET, 24);
+    memcpy(&pIdentifyInfo->firmware[0], iden + IDEN_FIRMWARE_OFFSET, 4);
+    pIdentifyInfo->version = version;
+    /*DMA support*/
+    if ((version >= 6) && (!(iden[IDEN_CAPACITY_1_OFFSET] & MV_BIT8)))
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "IDENTIFY info: DMA not "
+                 "supported\n");
+        return MV_FALSE;
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "Capabilities",
+                 "DMA supported");
+    }
+
+
+    if ((version >= 7) && (iden[IDEN_UDMA_MODE] & MV_BIT6))
+    {
+        pIdentifyInfo->UdmaMode = MV_ATA_TRANSFER_UDMA_6;
+        if (iden[IDEN_UDMA_MODE] & MV_BIT14)
+        {
+            udmaModeEnabled = MV_TRUE;
+        }
+    }
+    else if ((version >= 6) && (iden[IDEN_UDMA_MODE] & MV_BIT5))
+    {
+        pIdentifyInfo->UdmaMode = MV_ATA_TRANSFER_UDMA_5;
+        if (iden[IDEN_UDMA_MODE] & MV_BIT13)
+        {
+            udmaModeEnabled = MV_TRUE;
+        }
+    }
+    else if ((version >= 5) && (iden[IDEN_UDMA_MODE] & MV_BIT4))
+    {
+        pIdentifyInfo->UdmaMode = MV_ATA_TRANSFER_UDMA_4;
+        if (iden[IDEN_UDMA_MODE] & MV_BIT12)
+        {
+            udmaModeEnabled = MV_TRUE;
+        }
+    }
+    else if ((version >= 4) && (iden[IDEN_UDMA_MODE] & MV_BIT3))
+    {
+        pIdentifyInfo->UdmaMode = MV_ATA_TRANSFER_UDMA_3;
+        if (iden[IDEN_UDMA_MODE] & MV_BIT11)
+        {
+            udmaModeEnabled = MV_TRUE;
+        }
+    }
+    else if (iden[IDEN_UDMA_MODE] & MV_BIT2)
+    {
+        pIdentifyInfo->UdmaMode = MV_ATA_TRANSFER_UDMA_2;
+        if (iden[IDEN_UDMA_MODE] & MV_BIT10)
+        {
+            udmaModeEnabled = MV_TRUE;
+        }
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "IDENTIFY info: Ultra"
+                 " DMA mode < 2 not supported IDENTIFY[88] 0x%04x\n",
+                 iden[IDEN_UDMA_MODE]);
+        pIdentifyInfo->UdmaMode = MV_ATA_TRANSFER_UDMA_0;
+        return MV_FALSE;
+    }
+    if (udmaModeEnabled == MV_TRUE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s%d%s\n",
+                 "Ultra DMA mode","UDMA mode ",
+                 pIdentifyInfo->UdmaMode - MV_ATA_TRANSFER_UDMA_0,
+                 " supported and enabled");
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s%d%s\n",
+                 "Ultra DMA mode","UDMA mode ",
+                 pIdentifyInfo->UdmaMode - MV_ATA_TRANSFER_UDMA_0,
+                 " supported but disabled");
+    }
+
+
+    if ((iden[IDEN_SUPPORTED_COMMANDS1] & MV_BIT3))
+    {
+
+        if (iden[IDEN_ENABLED_COMMANDS1] & MV_BIT3)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n",
+                     "POWER MANAGMENT", "supported and enabled");
+        }
+        else
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n",
+                     "POWER MANAGMENT", "supported and disabled");
+        }
+
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n",
+                 "POWER MANAGMENT","Not supported");
+    }
+
+    if ((iden[IDEN_SUPPORTED_COMMANDS1] & MV_BIT0))
+    {
+
+        if (iden[IDEN_ENABLED_COMMANDS1] & MV_BIT0)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n", "SMART",
+                     "supported and enabled");
+        }
+        else
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %20s\n", "SMART",
+                     "supported and disabled");
+        }
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "SMART",
+                 "Not supported");
+    }
+
+
+
+    /*check that the non-UDMA ATA commands supported*/
+
+    /*FLUSH CHACHE*/
+    if ((version >=6) && ((iden[IDEN_SUPPORTED_COMMANDS2] & MV_BIT12) == 0))
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n",
+                 "FLUSH CACHE command", "not supported");
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n",
+                 "FLUSH CACHE command", "supported");
+    }
+
+    pIdentifyInfo->SATACapabilities.SATA_GEN_I_supported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.SATA_GEN_II_supported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.NCQSupported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.RxHostInitiatedPMSupported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.TxDeviceInitiatedPMSupported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.TxDeviceInitiatedPMEnabled = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.DMASetupAutoActiveSupported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.DMASetupAutoActiveEnables = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.NonZeroBufferOffsetSupported = MV_FALSE;
+    pIdentifyInfo->SATACapabilities.NonZeroBufferOffsetEnabled = MV_FALSE;
+
+    if (version >= 6)
+    {
+        if (iden[IDEN_SATA_CAPABILITIES] & MV_BIT1)
+        {
+            pIdentifyInfo->SATACapabilities.SATA_GEN_I_supported = MV_TRUE;
+        }
+        else
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "SATA Gen I",
+                     "not supported");
+        }
+        if (iden[IDEN_SATA_CAPABILITIES] & MV_BIT2)
+        {
+            pIdentifyInfo->SATACapabilities.SATA_GEN_II_supported = MV_TRUE;
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "SATA Gen II",
+                     "supported");
+        }
+
+        if (iden[IDEN_SATA_CAPABILITIES] & MV_BIT8)
+        {
+            pIdentifyInfo->SATACapabilities.NCQSupported = MV_TRUE;
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %s\n", "NCQ",
+                     "supported");
+        }
+
+        if (iden[IDEN_SATA_CAPABILITIES] & MV_BIT9)
+        {
+            pIdentifyInfo->SATACapabilities.RxHostInitiatedPMSupported = MV_TRUE;
+        }
+
+        if (iden[IDEN_SATA_FEATURES_SUPPORTED] & MV_BIT1)
+        {
+            pIdentifyInfo->SATACapabilities.NonZeroBufferOffsetSupported = MV_TRUE;
+            if (iden[IDEN_SATA_FEATURES_ENABLED] & MV_BIT1)
+            {
+                pIdentifyInfo->SATACapabilities.NonZeroBufferOffsetEnabled = MV_TRUE;
+            }
+        }
+        if (iden[IDEN_SATA_FEATURES_SUPPORTED] & MV_BIT2)
+        {
+            pIdentifyInfo->SATACapabilities.DMASetupAutoActiveSupported = MV_TRUE;
+            if (iden[IDEN_SATA_FEATURES_ENABLED] & MV_BIT2)
+            {
+                pIdentifyInfo->SATACapabilities.DMASetupAutoActiveEnables = MV_TRUE;
+            }
+        }
+        if (iden[IDEN_SATA_FEATURES_SUPPORTED] & MV_BIT3)
+        {
+            pIdentifyInfo->SATACapabilities.TxDeviceInitiatedPMSupported = MV_TRUE;
+            if (iden[IDEN_SATA_FEATURES_ENABLED] & MV_BIT3)
+            {
+                pIdentifyInfo->SATACapabilities.TxDeviceInitiatedPMEnabled = MV_TRUE;
+            }
+        }
+    }
+
+    return MV_TRUE;
+}
+
+/*******************************************************************************
+* mvGetSataDeviceType - short description
+*
+* DESCRIPTION:
+*       None.
+*
+* INPUT:
+*       None.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       None.
+*
+*******************************************************************************/
+MV_SATA_DEVICE_TYPE mvGetSataDeviceType(
+                                       MV_STORAGE_DEVICE_REGISTERS *mvStorageDevRegisters)
+{
+    if (((mvStorageDevRegisters->sectorCountRegister & 0xff) != 1) ||
+        ((mvStorageDevRegisters->lbaLowRegister & 0xff) != 1))
+    {
+        return MV_SATA_DEVICE_TYPE_UNKNOWN;
+    }
+    if (((mvStorageDevRegisters->lbaMidRegister & 0xff) == 0) &&
+         ((mvStorageDevRegisters->lbaHighRegister & 0xff) == 0)) 
+    {
+        return MV_SATA_DEVICE_TYPE_ATA_DISK;
+    }
+    if ((((mvStorageDevRegisters->lbaMidRegister & 0xff) == 0x14) &&
+         ((mvStorageDevRegisters->lbaHighRegister & 0xff) == 0xEB))/* ||
+         (((mvStorageDevRegisters->lbaMidRegister & 0xff) == 0x69) &&
+         ((mvStorageDevRegisters->lbaHighRegister & 0xff) == 0x96))*/)
+    {
+        return MV_SATA_DEVICE_TYPE_ATAPI_DEVICE;
+    }
+    if (((mvStorageDevRegisters->lbaMidRegister & 0xff) == 0x69) &&
+        ((mvStorageDevRegisters->lbaHighRegister & 0xff) == 0x96))
+    {
+        return MV_SATA_DEVICE_TYPE_PM;
+    }
+   return MV_SATA_DEVICE_TYPE_UNKNOWN;
+}
+
+#ifdef MV_LOG_DEBUG
+static void printIdentifyBuffer(MV_U16_PTR identifyBuffer)
+{
+    MV_U8 i,j;
+    /*Print Identify buffer*/
+    for (i = 0; i < 0x20; i++)
+    {
+        mvLogMsg(MV_RAW_MSG_ID,  0, "Words [%03d-%03d]: ", i*8, i*8+7);
+        for (j = 0; j < 0x8; j++)
+        {
+            mvLogMsg(MV_RAW_MSG_ID,  0, "0x%04X ", identifyBuffer[i*8+j]);
+        }
+        mvLogMsg(MV_RAW_MSG_ID,  0, "\n");
+    }
+}
+#endif
+
+/*******************************************************************************
+* mvConfigSataDisk - short description
+*
+* DESCRIPTION:
+*       None.
+*
+* INPUT:
+*       None.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       None.
+*
+*******************************************************************************/
+
+MV_BOOLEAN mvConfigSataDisk(MV_SATA_ADAPTER *pSataAdapter, MV_U8 channelIndex,
+                            MV_U8 PMPort, ATA_IDENTIFY_INFO   *pIdentifyInfo,
+                            MV_U16_PTR identifyBuffer)
+{
+    MV_STORAGE_DEVICE_REGISTERS inATARegs;
+    MV_STORAGE_DEVICE_REGISTERS outATARegs;
+
+    /* identify device*/
+    memset(&inATARegs, 0, sizeof(inATARegs));
+    inATARegs.commandRegister = MV_ATA_COMMAND_IDENTIFY;
+    if (mvStorageDevATAIdentifyDevice(pSataAdapter, channelIndex, PMPort,
+                                      identifyBuffer)
+        == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d %d]: failed "
+                 "to perform ATA Identify command\n", pSataAdapter->adapterId,
+                 channelIndex, PMPort);
+        return MV_FALSE;
+    }
+#ifdef MV_LOG_DEBUG
+    mvLogMsg(MV_RAW_MSG_ID, 0, "Drive [%d,%d,%d] Identify Buffer:\n",
+             pSataAdapter->adapterId, channelIndex, PMPort);
+
+    printIdentifyBuffer(identifyBuffer);
+#endif
+    if (mvParseIdentifyResult(identifyBuffer, pIdentifyInfo) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d %d]: in "
+                 "parsing ATA Identify Data\n", pSataAdapter->adapterId,
+                 channelIndex, PMPort);
+        return MV_FALSE;
+    }
+    if ((pIdentifyInfo->writeCacheSupported == MV_TRUE) &&
+        (pIdentifyInfo->writeCacheEnabled == MV_FALSE))
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG,"[%d %d %d]: Write Cache "
+                 "supported but disabled\n", pSataAdapter->adapterId,
+                 channelIndex, PMPort);
+        memset(&inATARegs, 0, sizeof(inATARegs));
+        inATARegs.commandRegister = MV_ATA_COMMAND_SET_FEATURES;
+        inATARegs.featuresRegister = MV_ATA_SET_FEATURES_ENABLE_WCACHE;
+
+        if (mvStorageDevExecutePIO(pSataAdapter, channelIndex, PMPort,
+                                   MV_NON_UDMA_PROTOCOL_NON_DATA,
+                                   MV_FALSE, NULL,0, &inATARegs, &outATARegs)
+            == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d %d]: "
+                     "Set Features failed(ENABLE WCACHE)\n",
+                     pSataAdapter->adapterId, channelIndex, PMPort);
+            return MV_FALSE;
+        }
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d %d]: Write Cache "
+                 "enabled\n", pSataAdapter->adapterId, channelIndex, PMPort);
+    }
+    if ((pIdentifyInfo->readAheadSupported == MV_TRUE) &&
+        (pIdentifyInfo->readAheadEnabled == MV_FALSE))
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d %d]: Read Look "
+                 "Ahead supported but disabled\n", pSataAdapter->adapterId,
+                 channelIndex, PMPort);
+        memset(&inATARegs, 0, sizeof(inATARegs));
+        inATARegs.commandRegister = MV_ATA_COMMAND_SET_FEATURES;
+        inATARegs.featuresRegister = MV_ATA_SET_FEATURES_ENABLE_RLA;
+        if (mvStorageDevExecutePIO(pSataAdapter, channelIndex, PMPort,
+                                   MV_NON_UDMA_PROTOCOL_NON_DATA,
+                                   MV_FALSE, NULL,0, &inATARegs, &outATARegs)
+            == MV_FALSE)
+        {
+            mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d %d]: "
+                     "Set Features failed(ENABLE RLA)\n",
+                     pSataAdapter->adapterId, channelIndex, PMPort);
+            return MV_FALSE;
+        }
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d %d]: Read Look "
+                 "Ahead enabled\n", pSataAdapter->adapterId, channelIndex,
+                 PMPort);
+    }
+    /* mvStorageDevATASetFeatures */
+
+    /* Set transfer mode */
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d %d]: Set transfer mode "
+             "XFER_PIO_SLOW\n", pSataAdapter->adapterId, channelIndex, PMPort);
+    memset(&inATARegs, 0, sizeof(inATARegs));
+    inATARegs.commandRegister = MV_ATA_COMMAND_SET_FEATURES;
+    inATARegs.featuresRegister = MV_ATA_SET_FEATURES_TRANSFER;
+    inATARegs.sectorCountRegister = MV_ATA_TRANSFER_PIO_SLOW;
+    if (mvStorageDevExecutePIO(pSataAdapter, channelIndex, PMPort,
+                               MV_NON_UDMA_PROTOCOL_NON_DATA,
+                               MV_FALSE, NULL,0, &inATARegs, &outATARegs) ==
+        MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d %d]: "
+                 "Set Features failed to set XFER PIO SLOW\n",
+                 pSataAdapter->adapterId, channelIndex, PMPort);
+
+        return MV_FALSE;
+    }
+
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d %d]: Set transfer mode "
+             "XFER_PIO_%d\n", pSataAdapter->adapterId, channelIndex, PMPort,
+             pIdentifyInfo->PIOMode - MV_ATA_TRANSFER_PIO_0);
+
+    memset(&inATARegs, 0, sizeof(inATARegs));
+    inATARegs.commandRegister = MV_ATA_COMMAND_SET_FEATURES;
+    inATARegs.featuresRegister = MV_ATA_SET_FEATURES_TRANSFER;
+    inATARegs.sectorCountRegister = pIdentifyInfo->PIOMode;
+    if (mvStorageDevExecutePIO(pSataAdapter, channelIndex, PMPort,
+                               MV_NON_UDMA_PROTOCOL_NON_DATA,
+                               MV_FALSE, NULL,0, &inATARegs, &outATARegs) ==
+        MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d %d]: "
+                 "Set Features failed to set XFER PIO %d\n",
+                 pSataAdapter->adapterId, channelIndex, PMPort,
+                 pIdentifyInfo->PIOMode - MV_ATA_TRANSFER_PIO_0);
+        return MV_FALSE;
+    }
+
+
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d %d]: Set transfer mode"
+             " XFER_UDMA_%d\n", pSataAdapter->adapterId, channelIndex, PMPort,
+             pIdentifyInfo->UdmaMode & 0xf);
+    memset(&inATARegs, 0, sizeof(inATARegs));
+    inATARegs.commandRegister = MV_ATA_COMMAND_SET_FEATURES;
+    inATARegs.featuresRegister = MV_ATA_SET_FEATURES_TRANSFER;
+    inATARegs.sectorCountRegister = pIdentifyInfo->UdmaMode;
+    if (mvStorageDevExecutePIO(pSataAdapter, channelIndex, PMPort,
+                               MV_NON_UDMA_PROTOCOL_NON_DATA,
+                               MV_FALSE, NULL,0, &inATARegs, &outATARegs) ==
+        MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d %d]: "
+                 "Set Features failed to set XFER UDMA %d\n",
+                 pSataAdapter->adapterId, channelIndex, PMPort,
+                 pIdentifyInfo->UdmaMode & 0xf);
+        return MV_FALSE;
+    }
+    return MV_TRUE;
+}
+
+/*******************************************************************************
+* mvInitSataDisk - short description
+*
+* DESCRIPTION:
+*       None.
+*
+* INPUT:
+*       None.
+*
+* OUTPUT:
+*       None.
+*
+* RETURN:
+*       None.
+*
+*******************************************************************************/
+MV_BOOLEAN mvInitSataDisk(MV_SATA_ADAPTER   *pSataAdapter, MV_U8 channelIndex,
+                          MV_U8 PMPort, ATA_IDENTIFY_INFO   *pIdentifyInfo,
+                          MV_U16_PTR identifyBuffer
+                         )
+{
+    pIdentifyInfo->deviceType = MV_SATA_DEVICE_TYPE_ATA_DISK;
+    if (mvConfigSataDisk(pSataAdapter, channelIndex, PMPort, pIdentifyInfo,
+                         identifyBuffer) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d %d]: Failed to"
+                 " Config Device\n", pSataAdapter->adapterId, channelIndex,
+                 PMPort);
+        return MV_FALSE;
+    }
+    return MV_TRUE;
+}
+#ifdef MV_SUPPORT_ATAPI
+MV_BOOLEAN mvInitSataATAPI(MV_SATA_ADAPTER   *pSataAdapter, MV_U8 channelIndex,
+                          MV_U8 PMPort, ATA_IDENTIFY_INFO   *pIdentifyInfo,
+                          MV_U16_PTR identifyBuffer
+                         )
+{
+    MV_STORAGE_DEVICE_REGISTERS inATARegs;
+    MV_STORAGE_DEVICE_REGISTERS outATARegs;
+
+    pIdentifyInfo->deviceType = MV_SATA_DEVICE_TYPE_ATAPI_DEVICE;
+    /* identify device*/
+    memset(&inATARegs, 0, sizeof(inATARegs));
+    inATARegs.commandRegister = MV_ATA_COMMAND_ATAPI_IDENTIFY;
+    inATARegs.featuresRegister = 0x1;
+    if (mvStorageDevExecutePIO(pSataAdapter, channelIndex, PMPort,
+                                   MV_NON_UDMA_PROTOCOL_PIO_DATA_IN,
+                                   MV_FALSE, identifyBuffer, 256, &inATARegs, &outATARegs)
+            == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d %d]: "
+                "failed to perform ATAPI Identify command\n",
+                pSataAdapter->adapterId, channelIndex, PMPort);
+        return MV_FALSE;
+    }
+
+#ifdef MV_LOG_DEBUG
+    mvLogMsg(MV_RAW_MSG_ID, 0, "Drive [%d,%d,%d] Identify Buffer:\n",
+             pSataAdapter->adapterId, channelIndex, PMPort);
+
+    printIdentifyBuffer(identifyBuffer);
+#endif
+    if (mvParseIdentifyPacketResult(identifyBuffer, pIdentifyInfo) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR,"[%d %d %d]: in "
+                 "parsing ATA Identify Data\n", pSataAdapter->adapterId,
+                 channelIndex, PMPort);
+        return MV_FALSE;
+    }
+    /* Set transfer mode */
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d %d]: Set transfer mode "
+             "XFER_PIO_SLOW\n", pSataAdapter->adapterId, channelIndex, PMPort);
+    mvMicroSecondsDelay(NULL, 1000);
+    memset(&inATARegs, 0, sizeof(inATARegs));
+    inATARegs.commandRegister = MV_ATA_COMMAND_SET_FEATURES;
+    inATARegs.featuresRegister = MV_ATA_SET_FEATURES_TRANSFER;
+    inATARegs.sectorCountRegister = MV_ATA_TRANSFER_UDMA_2;
+    if (mvStorageDevExecutePIO(pSataAdapter, channelIndex, PMPort,
+                               MV_NON_UDMA_PROTOCOL_NON_DATA,
+                               MV_FALSE, NULL,0, &inATARegs, &outATARegs) ==
+        MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d %d]: "
+                 "Set Features failed to set XFER mode\n",
+                 pSataAdapter->adapterId, channelIndex, PMPort);
+
+        return MV_FALSE;
+    }
+    return MV_TRUE;
+}
+#endif
+MV_BOOLEAN  mvGetPMDeviceInfo(MV_SATA_ADAPTER   *pSataAdapter,
+                              MV_U8 channelIndex,
+                              MV_SATA_PM_DEVICE_INFO *pPMDeviceInfo)
+{
+    MV_U32  regVal;
+
+    if (mvPMDevReadReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                       MV_SATA_GSCR_ID_REG_NUM, &regVal, NULL) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: "
+                 "mvGetPMDeviceInfo Failed", pSataAdapter->adapterId,
+                 channelIndex);
+        return MV_FALSE;
+    }
+    pPMDeviceInfo->vendorId = (MV_U16)(regVal & 0xffff);
+    pPMDeviceInfo->deviceId = (MV_U16)((regVal & 0xffff0000) >> 16);
+
+    if (mvPMDevReadReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                       MV_SATA_GSCR_REVISION_REG_NUM, &regVal, NULL)== MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: "
+                 "mvGetPMDeviceInfo Failed", pSataAdapter->adapterId,
+                 channelIndex);
+        return MV_FALSE;
+    }
+
+    pPMDeviceInfo->PMSpecRevision = (MV_U8)(regVal & 0xff);
+    pPMDeviceInfo->productRevision = (MV_U8)((regVal & 0xff00) >> 8);
+
+    if (mvPMDevReadReg(pSataAdapter, channelIndex, MV_SATA_PM_CONTROL_PORT,
+                       MV_SATA_GSCR_INFO_REG_NUM, &regVal, NULL)== MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: "
+                 "mvGetPMDeviceInfo Failed", pSataAdapter->adapterId,
+                 channelIndex);
+        return MV_FALSE;
+    }
+    pPMDeviceInfo->numberOfPorts = (MV_U8)(regVal & 0xf);
+
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "[%d %d]: PM Information:\n",
+             pSataAdapter->adapterId,channelIndex);
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %04x\n", "Vendor Id", pPMDeviceInfo->vendorId);
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %04x\n", "Device Id", pPMDeviceInfo->deviceId);
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %02x\n", "Product Revision", pPMDeviceInfo->productRevision);
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %02x\n", "Spec Revision", pPMDeviceInfo->PMSpecRevision);
+    mvLogMsg(MV_IAL_COMMON_LOG_ID, MV_DEBUG, "%25s - %02x\n", "Fan-out ports", pPMDeviceInfo->numberOfPorts);
+    return MV_TRUE;
+}
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommonUtils.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommonUtils.h
new file mode 100644
index 0000000..528060d
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvIALCommonUtils.h
@@ -0,0 +1,140 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* mvIALCommonUtils.h
+*
+* DESCRIPTION:
+*       H implementation for IAL's extension utility functions.
+*
+* DEPENDENCIES:
+*   mvSata.h
+*   mvStorageDev.h
+*
+*******************************************************************************/
+#ifndef __INCmvIALCommonUtilsh
+#define __INCmvIALCommonUtilsh
+
+#ifdef __cplusplus
+extern "C"  {
+#endif /* __cplusplus */
+
+/* includes */
+#include "mvSata.h"
+#include "mvStorageDev.h"
+
+/* defines */
+#define MV_IAL_COMMON_LOG_ID            2
+
+/* typedefs */
+typedef struct serialATACapabilites
+{
+    MV_BOOLEAN  SATA_GEN_I_supported:1;
+    MV_BOOLEAN  SATA_GEN_II_supported:1;
+    MV_BOOLEAN  NCQSupported:1;/*native command queuing*/
+    MV_BOOLEAN  RxHostInitiatedPMSupported:1;/* Supports receipt of host-initiated
+                                              interface power management
+                                              requests*/
+    MV_BOOLEAN  TxDeviceInitiatedPMSupported:1;/* device supports initiating
+                                                interface power management*/
+    MV_BOOLEAN  TxDeviceInitiatedPMEnabled:1;
+    MV_BOOLEAN  DMASetupAutoActiveSupported:1;/* supports DMA Setup Auto-Activate
+                                               optimization*/
+    MV_BOOLEAN  DMASetupAutoActiveEnables:1;
+    MV_BOOLEAN  NonZeroBufferOffsetSupported:1;/* supports non-zero buffer offsets
+                                                in DMA Setup FIS*/
+    MV_BOOLEAN  NonZeroBufferOffsetEnabled:1;
+}SERIAL_ATA_CAPABILITIES;
+
+typedef struct ATAIdentifyInfo
+{
+    MV_U8           version;
+    MV_U8           model[24];
+    MV_U8           firmware[4];
+    MV_U8           UdmaMode;
+    MV_U8           PIOMode;
+    MV_BOOLEAN      LBA48Supported:1;/* used for READ/WRITE commands*/
+    MV_BOOLEAN      writeCacheSupported:1;
+    MV_BOOLEAN      writeCacheEnabled:1;
+    MV_BOOLEAN      readAheadSupported:1;
+    MV_BOOLEAN      readAheadEnabled:1;
+    MV_BOOLEAN      DMAQueuedModeSupported:1;
+    MV_U8           DMAQueuedModeDepth;
+    MV_U64          ATADiskSize;
+    SERIAL_ATA_CAPABILITIES SATACapabilities;/*valid only for ATA-7 or higher*/
+    MV_U8           commandPacketLength;
+    MV_SATA_DEVICE_TYPE deviceType;
+} ATA_IDENTIFY_INFO;
+
+
+typedef struct mvSataPMDeviceInfo
+{
+    MV_U16      vendorId;
+    MV_U16      deviceId;
+    MV_U8       productRevision;
+    MV_U8       PMSpecRevision:4;
+    MV_U8       numberOfPorts:4;
+} MV_SATA_PM_DEVICE_INFO;
+
+
+MV_BOOLEAN mvParseIdentifyResult(MV_U16_PTR  iden,ATA_IDENTIFY_INFO *pIdentifyInfo);
+
+MV_SATA_DEVICE_TYPE mvGetSataDeviceType(MV_STORAGE_DEVICE_REGISTERS *mvStorageDevRegisters);
+
+MV_BOOLEAN mvInitSataDisk(MV_SATA_ADAPTER   *pSataAdapter, MV_U8 channelIndex,
+                          MV_U8 PMPort, ATA_IDENTIFY_INFO   *pIdentifyInfo,
+                          MV_U16_PTR identifyBuffer
+                         );
+
+MV_BOOLEAN mvInitSataATAPI(MV_SATA_ADAPTER   *pSataAdapter, MV_U8 channelIndex,
+                          MV_U8 PMPort, ATA_IDENTIFY_INFO   *pIdentifyInfo,
+                          MV_U16_PTR identifyBuffer
+                         );
+
+
+MV_BOOLEAN  mvGetPMDeviceInfo(MV_SATA_ADAPTER   *pSataAdapter,
+                              MV_U8 channelIndex,
+                              MV_SATA_PM_DEVICE_INFO *pPMDeviceInfo);
+
+MV_VOID mvSelectConfiguration(MV_SATA_ADAPTER        *pSataAdapter,
+                              MV_U8                  channelIndex,
+                              MV_SATA_GEN            gen,
+                              MV_SATA_DEVICE_TYPE    connectedDevice,
+                              MV_SATA_PM_DEVICE_INFO *pPMInfo,
+                              MV_BOOLEAN             AllNCQ,
+                              MV_BOOLEAN             AllTCQ,
+                              MV_BOOLEAN             disks,
+                              MV_EDMA_MODE           *pEdmaMode,
+                              MV_SATA_SWITCHING_MODE *pSwitchingMode,
+                              MV_BOOLEAN             *pUse128Entries);
+
+#ifdef __cplusplus
+}
+#endif /* __cplusplus */
+
+#endif /* __INCmvIALCommonh */
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalHt.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalHt.c
new file mode 100644
index 0000000..086e81c
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalHt.c
@@ -0,0 +1,2158 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* file_name - mvLinuxIalHt.c
+*
+* DESCRIPTION:  implementation for Linux IAL.
+*
+* DEPENDENCIES:
+*   mvLinuxIalHt.h
+*   mvLinuxIalLib.h
+*   Linux Os header files
+*   Core driver header files
+*
+*
+*******************************************************************************/
+
+/* includes */
+
+#ifndef LINUX_VERSION_CODE
+    #include <linux/version.h>
+#endif
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,4,0)
+    #error "This driver works only with kernel 2.4.0 or higher!"
+#endif
+
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)))
+    #error "This driver does not support kernel 2.5!"
+#endif
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+#include <linux/pci.h>
+#include <linux/ioport.h>
+#include <linux/delay.h>
+#include <linux/sched.h>
+#include <linux/proc_fs.h>
+#include <linux/stat.h>
+#include <linux/kdev_t.h>
+#include <linux/hdreg.h>
+
+#ifdef CONFIG_MV_INCLUDE_INTEG_SATA
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "mvSysSataApi.h"
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+#include <linux/blk.h>
+#include "scsi.h"
+#include "hosts.h"
+#else
+#include <scsi/scsi.h>
+#include <scsi/scsi_cmnd.h>
+#include <scsi/scsi_device.h>
+#include <scsi/scsi_host.h>
+#include <scsi/scsi_tcq.h>
+#endif
+
+#include <linux/timer.h>
+#include <linux/spinlock.h>
+#include <asm/dma.h>
+#include <asm/system.h>
+#include <asm/io.h>
+
+#include "mvLinuxIalHt.h"
+#include "mvRegs.h"
+#include "mvIALCommon.h"
+#include "mvLinuxIalSmart.h"
+
+extern Scsi_Host_Template driver_template;
+
+static int ncq_disable = 0;
+static int pm_ncq_disable = 0;
+
+static void mv_ial_init_log(void);
+
+static char mv_ial_proc_version[]="Version_1_1";
+extern void release_ata_mem(struct mv_comp_info * pInfo);
+extern MV_BOOLEAN IALCompletion(struct mvSataAdapter *pSataAdapter,
+                                MV_SATA_SCSI_CMD_BLOCK *pCmdBlock);
+
+static struct pci_device_id mvSata_pci_table[] =
+{
+    {MV_SATA_VENDOR_ID, MV_SATA_DEVICE_ID_5080, PCI_ANY_ID, PCI_ANY_ID, 0, 0},
+    {MV_SATA_VENDOR_ID, MV_SATA_DEVICE_ID_5081, PCI_ANY_ID, PCI_ANY_ID, 0, 0},
+    {MV_SATA_VENDOR_ID, MV_SATA_DEVICE_ID_5040, PCI_ANY_ID, PCI_ANY_ID, 0, 0},
+    {MV_SATA_VENDOR_ID, MV_SATA_DEVICE_ID_5041, PCI_ANY_ID, PCI_ANY_ID, 0, 0},
+    {MV_SATA_VENDOR_ID, MV_SATA_DEVICE_ID_6081, PCI_ANY_ID, PCI_ANY_ID, 0, 0},
+    {MV_SATA_VENDOR_ID, MV_SATA_DEVICE_ID_6041, PCI_ANY_ID, PCI_ANY_ID, 0, 0},
+    {MV_SATA_VENDOR_ID, MV_SATA_DEVICE_ID_6042, PCI_ANY_ID, PCI_ANY_ID, 0, 0},
+    {MV_SATA_VENDOR_ID, MV_SATA_DEVICE_ID_7042, PCI_ANY_ID, PCI_ANY_ID, 0, 0},
+    {0,}
+};
+
+
+int          adapterId = 0;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+
+#ifndef __devexit_p
+#define __devexit_p(x)  x
+#endif
+static void mv_ial_ht_select_queue_depths (struct Scsi_Host* pHost,
+                                           struct scsi_device* pDevs);
+
+
+static inline struct Scsi_Host *scsi_host_alloc(Scsi_Host_Template *t, size_t s)
+{
+    return scsi_register(t, s);
+}
+static inline void scsi_host_put(struct Scsi_Host *h)
+{
+    scsi_unregister(h);
+}
+
+#define scsi_scan_host(x...)
+#define scsi_remove_host(x...)
+
+#else
+
+static int mv_ial_ht_slave_configure (struct scsi_device* pDevs);
+static int __devinit  mv_ial_probe_device(struct pci_dev *pci_dev, const struct pci_device_id *ent);
+static void __devexit mv_ial_remove_device(struct pci_dev *pci_dev);
+
+
+MODULE_DEVICE_TABLE(pci, mvSata_pci_table);
+
+static char mv_hot_plug_name[] = "mvSata";
+
+static struct pci_driver mv_ial_pci_driver =
+{
+    .name       = mv_hot_plug_name,
+    .id_table   = mvSata_pci_table,
+    .probe      = mv_ial_probe_device,
+    .remove     = __devexit_p(mv_ial_remove_device),
+};
+
+#ifdef CONFIG_MV_INCLUDE_INTEG_SATA
+static int __devinit mv_ial_init_soc_sata(void);
+#endif
+IAL_ADAPTER_T       *pSocAdapter = NULL;
+
+
+static int __init mv_ial_init(void)
+{
+    mv_ial_init_log();
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "mvSata init.\n");
+    driver_template.module = THIS_MODULE;
+
+    if (ncq_disable)
+	    disableNCQ = MV_TRUE;
+
+    if (pm_ncq_disable)
+	    disablePM_NCQ = MV_TRUE;
+
+#ifdef CONFIG_MV_INCLUDE_INTEG_SATA
+	if (MV_FALSE == mvCtrlPwrClckGet(SATA_UNIT_ID, 0)) 
+	{
+		printk("\nWarning Sata is Powered Off\n");
+	}
+	else
+	{
+		printk("Integrated Sata device found\n");
+        	mv_ial_init_soc_sata();
+	}
+#endif
+    return (int)pci_register_driver(&mv_ial_pci_driver);
+}
+
+static void __exit mv_ial_exit(void)
+{
+
+#ifdef CONFIG_MV_INCLUDE_INTEG_SATA
+      mv_ial_remove_device(NULL);
+#endif
+    pci_unregister_driver(&mv_ial_pci_driver);
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "mvSata exit.\n");
+}
+
+module_init(mv_ial_init);
+module_exit(mv_ial_exit);
+
+#endif
+
+
+static void mv_ial_init_log(void)
+{
+#ifdef MV_LOGGER
+    char *szModules[] = {"Core Driver",
+        "SAL",
+        "Common IAL",
+        "Linux IAL"
+    };
+#if defined (MV_LOG_DEBUG)
+    mvLogRegisterModule(MV_CORE_DRIVER_LOG_ID, MV_DEBUG_ENABLE_ALL,
+                        szModules[MV_CORE_DRIVER_LOG_ID]);
+    mvLogRegisterModule(MV_SAL_LOG_ID, MV_DEBUG_ENABLE_ALL,
+                        szModules[MV_SAL_LOG_ID]);
+    mvLogRegisterModule(MV_IAL_COMMON_LOG_ID, MV_DEBUG_ENABLE_ALL,
+                        szModules[MV_IAL_COMMON_LOG_ID]);
+    mvLogRegisterModule(MV_IAL_LOG_ID, MV_DEBUG_ENABLE_ALL,
+                        szModules[MV_IAL_LOG_ID]);
+#elif defined (MV_LOG_ERROR)
+    mvLogRegisterModule(MV_CORE_DRIVER_LOG_ID, MV_DEBUG_FATAL_ERROR | MV_DEBUG_ERROR |
+			MV_DEBUG_INFO,
+                        szModules[MV_CORE_DRIVER_LOG_ID]);
+    mvLogRegisterModule(MV_SAL_LOG_ID, MV_DEBUG_FATAL_ERROR | MV_DEBUG_ERROR |
+			MV_DEBUG_INFO,
+                        szModules[MV_SAL_LOG_ID]);
+    mvLogRegisterModule(MV_IAL_COMMON_LOG_ID, MV_DEBUG_FATAL_ERROR | MV_DEBUG_ERROR |
+			MV_DEBUG_INFO,
+                        szModules[MV_IAL_COMMON_LOG_ID]);
+    mvLogRegisterModule(MV_IAL_LOG_ID, MV_DEBUG_FATAL_ERROR | MV_DEBUG_ERROR | 
+			MV_DEBUG_INFO,
+                        szModules[MV_IAL_LOG_ID]);
+#endif
+#endif
+}
+
+/****************************************************************
+ *  Name: set_device_regs
+ *
+ *  Description:    initialize the device registers.
+ *
+ *  Parameters:     pMvSataAdapter, pointer to the Device data structure.
+ *          pcidev, pointer to the pci device data structure.
+ *
+ *  Returns:        =0 ->success, < 0 ->failure.
+ *
+ ****************************************************************/
+static int set_device_regs(MV_SATA_ADAPTER *pMvSataAdapter,
+                           struct pci_dev   *pcidev)
+{
+    pMvSataAdapter->intCoalThre[0]= MV_IAL_HT_SACOALT_DEFAULT;
+    pMvSataAdapter->intCoalThre[1]= MV_IAL_HT_SACOALT_DEFAULT;
+    pMvSataAdapter->intTimeThre[0] = MV_IAL_HT_SAITMTH_DEFAULT;
+    pMvSataAdapter->intTimeThre[1] = MV_IAL_HT_SAITMTH_DEFAULT;
+    pMvSataAdapter->pciCommand = MV_PCI_COMMAND_REG_DEFAULT;
+    pMvSataAdapter->pciSerrMask = MV_PCI_SERR_MASK_REG_ENABLE_ALL;
+    pMvSataAdapter->pciInterruptMask = MV_PCI_INTERRUPT_MASK_REG_ENABLE_ALL;
+    pMvSataAdapter->mvSataEventNotify = mv_ial_lib_event_notify;
+
+    return 0;
+}
+
+
+static int mv_ial_get_num_of_ports(const struct pci_device_id *id)
+{
+    switch(id->device)
+    {
+        case MV_SATA_DEVICE_ID_5080:
+        case MV_SATA_DEVICE_ID_5081:
+        case MV_SATA_DEVICE_ID_6081:
+            return 8;
+        case MV_SATA_DEVICE_ID_5040:
+        case MV_SATA_DEVICE_ID_5041:
+        case MV_SATA_DEVICE_ID_6041:
+        case MV_SATA_DEVICE_ID_6042:
+        case MV_SATA_DEVICE_ID_7042:
+            return 4;
+        default:
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_FATAL_ERROR,
+                     "getMaxNumberOfPorts() Unknown device ID.\n");
+            return 0;
+    }
+}
+
+static void mv_ial_free_scsi_hosts(IAL_ADAPTER_T *pAdapter, MV_BOOLEAN freeAdapter)
+{
+    int i;
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        if (pAdapter->host[i] != NULL)
+        {
+            mv_ial_lib_prd_destroy(pAdapter->host[i]);
+            scsi_host_put(pAdapter->host[i]->scsihost);
+            pAdapter->host[i] = NULL;
+        }
+    }
+    pAdapter->activeHosts = 0;
+    if (MV_TRUE == freeAdapter)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG,
+                     "[%d] freeing Adapter data structure.\n", pAdapter->mvSataAdapter.adapterId);
+        kfree(pAdapter);
+    }
+}
+
+
+
+
+static int __devinit  mv_ial_probe_device(struct pci_dev *pcidev,
+                                          const struct pci_device_id *id)
+{
+
+    MV_SATA_ADAPTER     *pMvSataAdapter;
+    IAL_ADAPTER_T       *pAdapter;
+    MV_U8                 i;
+
+    pci_set_drvdata(pcidev, NULL);
+
+    if (pci_enable_device(pcidev))
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR,
+                 "pci_enable_device() failed\n");
+        return -ENODEV;
+    }
+
+    pci_set_master(pcidev);
+    if (0 == pci_set_dma_mask(pcidev, 0xffffffffffffffffULL))
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG,"using 64-bit DMA.\n");
+    }
+    else if (0 == pci_set_dma_mask(pcidev, 0xffffffffUL))
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "using 32-bit DMA.\n");
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "DMA 32-bit not supported"
+                 " in the system\n");
+        pci_disable_device(pcidev);
+        return -ENODEV;
+    }
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+    if (pci_request_regions(pcidev, mv_hot_plug_name) != 0)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "pci_request_regions() failed\n");
+        pci_disable_device(pcidev);
+        return -ENOMEM;
+    }
+#endif
+
+
+    pAdapter = (IAL_ADAPTER_T*)kmalloc(sizeof(IAL_ADAPTER_T), GFP_ATOMIC);
+    if (pAdapter == NULL)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "IAL Adapter allocation failed\n");
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+        pci_release_regions(pcidev);
+#endif
+        pci_disable_device(pcidev);
+        return -ENOMEM;
+    }
+    memset(pAdapter, 0, sizeof(IAL_ADAPTER_T));
+    pAdapter->activeHosts = 0;
+    pAdapter->maxHosts = mv_ial_get_num_of_ports(id);
+    if (pAdapter->maxHosts == 0)
+    {
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "mv_ial_get_num_of_ports() failed\n");
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+        pci_release_regions(pcidev);
+#endif
+        pci_disable_device(pcidev);
+        return -ENOMEM;
+    }
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        struct Scsi_Host    *pshost = scsi_host_alloc(&driver_template, sizeof(IAL_HOST_T));
+        if (pshost == NULL)
+        {
+            mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "Scsi_Host allocation failed\n");
+ #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+            pci_release_regions(pcidev);
+ #endif
+            pci_disable_device(pcidev);
+            return -ENOMEM;
+        }
+        pAdapter->host[i] = HOSTDATA(pshost);
+        memset(pAdapter->host[i], 0, sizeof(IAL_HOST_T));
+        pAdapter->host[i]->scsihost = pshost;
+        pAdapter->host[i]->pAdapter = pAdapter;
+        pAdapter->host[i]->channelIndex = (MV_U8)i;
+        pAdapter->activeHosts |= (1 << i);
+    }
+    pAdapter->pcidev = pcidev;
+    pMvSataAdapter = &(pAdapter->mvSataAdapter);
+    pMvSataAdapter->IALData = pAdapter;
+    spin_lock_init (&pAdapter->adapter_lock);
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        pAdapter->host[i]->scsi_cmnd_done_head = NULL;
+        pAdapter->host[i]->scsi_cmnd_done_tail = NULL;
+    }
+    
+    pAdapter->host[0]->scsihost->base = pci_resource_start(pcidev, 0);
+    for (i = 1; i < pAdapter->maxHosts; i++)
+    {
+        if (pAdapter->host[i] != NULL)
+            pAdapter->host[i]->scsihost->base = pAdapter->host[0]->scsihost->base;
+    }
+    pMvSataAdapter->adapterIoBaseAddress =
+        (MV_BUS_ADDR_T)ioremap(pAdapter->host[0]->scsihost->base,
+                               pci_resource_len(pcidev, 0));
+    if (!pMvSataAdapter->adapterIoBaseAddress)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "Failed to remap memory io spcae\n");
+        
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+        pci_release_regions(pcidev);
+#endif
+        pci_disable_device(pcidev);
+        return -ENOMEM;
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "io base address 0x%08lx\n",
+                 (ulong)pMvSataAdapter->adapterIoBaseAddress);
+    }
+    
+    pMvSataAdapter->adapterId = adapterId++;
+    /* get the revision ID */
+    if (pci_read_config_byte(pcidev, PCI_REVISION_ID, &pAdapter->rev_id))
+    {
+        printk(KERN_WARNING "mvSata: Failed to get revision id.\n");
+        iounmap(pMvSataAdapter->adapterIoBaseAddress);
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+        pci_release_regions(pcidev);
+#endif
+        pci_disable_device(pcidev);
+        return -ENOMEM;
+    }
+    pMvSataAdapter->pciConfigRevisionId = pAdapter->rev_id;
+    pMvSataAdapter->pciConfigDeviceId = id->device;
+    if (set_device_regs(pMvSataAdapter, pcidev))
+    {
+        iounmap(pMvSataAdapter->adapterIoBaseAddress);
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+        pci_release_regions(pcidev);
+#endif
+        pci_disable_device(pcidev);
+        return -ENOMEM;
+    }
+    /*Do not allow hotplug handler to work*/
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+    init_MUTEX(&pAdapter->rescan_mutex);
+    atomic_set(&pAdapter->stopped, 1);
+#endif
+
+    if (mvSataInitAdapter(pMvSataAdapter) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: core failed to initialize the adapter\n",
+                 pMvSataAdapter->adapterId);
+        iounmap(pMvSataAdapter->adapterIoBaseAddress);
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+        pci_release_regions(pcidev);
+#endif
+        pci_disable_device(pcidev);
+        return -ENOMEM;
+    }
+    if (mv_ial_lib_allocate_edma_queues(pAdapter))
+    {
+        mvLogMsg(MV_IAL_LOG_ID,MV_DEBUG_ERROR,
+                 "Failed to allocate memory for EDMA queues\n");
+        iounmap(pMvSataAdapter->adapterIoBaseAddress);
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+        pci_release_regions(pcidev);
+#endif
+        pci_disable_device(pcidev);
+        return -ENOMEM;
+    }
+
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        if ((pAdapter->activeHosts & (1 << i)) == 0)
+        {
+            continue;
+        }
+        if (mv_ial_lib_prd_init(pAdapter->host[i]))
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR,
+                     "Failed to init PRD memory manager - host %d\n", i);
+            iounmap(pMvSataAdapter->adapterIoBaseAddress);
+            mv_ial_lib_free_edma_queues(pAdapter);
+            mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+            pci_release_regions(pcidev);
+#endif
+            pci_disable_device(pcidev);
+            return -ENOMEM;
+        }
+    }
+    pAdapter->ataScsiAdapterExt = (MV_SAL_ADAPTER_EXTENSION*)kmalloc(sizeof(MV_SAL_ADAPTER_EXTENSION),
+                                                                     GFP_ATOMIC);
+    if (pAdapter->ataScsiAdapterExt == NULL)
+    {
+        mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG_ERROR,"[%d]: out of memory, failed to allocate MV_SAL_ADAPTER_EXTENSION\n",
+                 pAdapter->mvSataAdapter.adapterId);
+        iounmap(pMvSataAdapter->adapterIoBaseAddress);
+        mv_ial_lib_free_edma_queues(pAdapter);
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+        pci_release_regions(pcidev);
+#endif
+        pci_disable_device(pcidev);
+        return -ENOMEM;
+    }
+    mvSataScsiInitAdapterExt(pAdapter->ataScsiAdapterExt,
+                             pMvSataAdapter);
+    /* let SAL report only the BUS RESET UA event*/
+    pAdapter->ataScsiAdapterExt->UAMask = MV_BIT0;
+    /* enable device interrupts even if no storage devices connected now*/
+#ifdef MV_SUPPORT_MSI
+    {
+    	int err;
+	if ((err = pci_enable_msi(pcidev)))
+	{
+	    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: Unable to allocate MSI interrupt Error: %d\n",
+		    pMvSataAdapter->adapterId, err);
+	}
+    }
+#endif
+
+    if (request_irq(pcidev->irq, mv_ial_lib_int_handler,
+                    (IRQF_DISABLED | IRQF_SAMPLE_RANDOM | IRQF_SHARED), "mvSata",
+                    pAdapter) < 0)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: unable to allocate IRQ for controler\n",
+                 pMvSataAdapter->adapterId);
+#ifdef MV_SUPPORT_MSI
+	pci_disable_msi(pAdapter->pcidev);
+#endif
+        kfree(pAdapter->ataScsiAdapterExt);
+        iounmap(pMvSataAdapter->adapterIoBaseAddress);
+        mv_ial_lib_free_edma_queues(pAdapter);
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+        pci_release_regions(pcidev);
+#endif
+        pci_disable_device(pcidev);
+        return -ENOMEM;
+    }
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        if ((pAdapter->activeHosts & (1 << i)) == 0)
+        {
+            continue;
+        }
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,13)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+        scsi_set_device(pAdapter->host[i]->scsihost, &pcidev->dev);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+        scsi_set_pci_device(pAdapter->host[i]->scsihost, pcidev);
+#endif
+        pAdapter->host[i]->scsihost->irq = pcidev->irq;
+        /* each SATA channel will emulate scsi host !!!*/
+        if (pMvSataAdapter->sataAdapterGeneration == MV_SATA_GEN_I)
+        {
+            pAdapter->host[i]->scsihost->max_id = 1;
+        }
+        else
+        {
+            pAdapter->host[i]->scsihost->max_id = MV_SATA_PM_MAX_PORTS;
+        }
+        pAdapter->host[i]->scsihost->max_lun = 1;
+        pAdapter->host[i]->scsihost->max_channel = 0;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+        pAdapter->host[i]->scsihost->select_queue_depths = mv_ial_ht_select_queue_depths;
+#endif
+    }
+    if (MV_FALSE == mvAdapterStartInitialization(pMvSataAdapter,
+                                                 &pAdapter->ialCommonExt,
+                                                 pAdapter->ataScsiAdapterExt))
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: mvAdapterStartInitialization"
+                 " Failed\n", pMvSataAdapter->adapterId);
+        free_irq (pcidev->irq, pMvSataAdapter);
+#ifdef MV_SUPPORT_MSI
+	pci_disable_msi(pAdapter->pcidev);
+#endif
+        kfree(pAdapter->ataScsiAdapterExt);
+        iounmap(pMvSataAdapter->adapterIoBaseAddress);
+        mv_ial_lib_free_edma_queues(pAdapter);
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+        pci_release_regions(pcidev);
+#endif
+        pci_disable_device(pcidev);
+        return -ENOMEM;
+    }
+    pci_set_drvdata(pcidev, pAdapter);
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        if ((pAdapter->activeHosts & (1 << i)) == 0)
+        {
+            continue;
+        }
+        mv_ial_block_requests(pAdapter, i);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+        if (scsi_add_host(pAdapter->host[i]->scsihost, &pcidev->dev) != 0)
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: scsi_add_host() failed.\n"
+                     , pMvSataAdapter->adapterId);
+            free_irq (pcidev->irq, pMvSataAdapter);
+#ifdef MV_SUPPORT_MSI
+	    pci_disable_msi(pAdapter->pcidev);
+#endif
+	    kfree(pAdapter->ataScsiAdapterExt);
+            iounmap(pMvSataAdapter->adapterIoBaseAddress);
+            mv_ial_lib_free_edma_queues(pAdapter);
+            mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+            pci_release_regions(pcidev);
+            pci_disable_device(pcidev);
+            return -ENODEV;
+        }
+#endif
+    }
+
+    pAdapter->stopAsyncTimer = MV_FALSE;
+    init_timer(&pAdapter->asyncStartTimer);
+    pAdapter->asyncStartTimer.data = (unsigned long)pAdapter;
+    pAdapter->asyncStartTimer.function = asyncStartTimerFunction;
+    pAdapter->asyncStartTimer.expires = jiffies + MV_LINUX_ASYNC_TIMER_PERIOD;
+    add_timer (&pAdapter->asyncStartTimer);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        if ((pAdapter->activeHosts & (1 << i)) != 0)
+        {
+            scsi_scan_host(pAdapter->host[i]->scsihost);
+        }
+    }
+    /*Enable hotplug handler*/
+    atomic_set(&pAdapter->stopped, 0);
+#endif
+    return 0;
+}
+
+#ifdef CONFIG_MV_INCLUDE_INTEG_SATA
+static int __devinit mv_ial_init_soc_sata(void)
+{
+    MV_SATA_ADAPTER     *pMvSataAdapter;
+    IAL_ADAPTER_T       *pAdapter;
+    MV_U8                 i;
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+    if (MV_FALSE == mvSocUnitIsMappedToThisCpu(SATA))
+    {
+	printk(KERN_INFO"Integrated SATA is not mapped to this CPU\n");
+	return -ENODEV;
+    }	
+#endif        	
+
+    mvSysSataWinInit();
+
+    pAdapter = (IAL_ADAPTER_T*)kmalloc(sizeof(IAL_ADAPTER_T), GFP_ATOMIC);
+    if (pAdapter == NULL)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "IAL Adapter allocation failed\n");
+        return -ENOMEM;
+    }
+    pSocAdapter = pAdapter;
+    memset(pAdapter, 0, sizeof(IAL_ADAPTER_T));
+    pAdapter->activeHosts = 0;
+
+    if(MV_5182_DEV_ID == mvCtrlModelGet())
+	pAdapter->maxHosts = MV_SATA_5182_PORT_NUM;
+    else if(MV_5082_DEV_ID == mvCtrlModelGet())
+	pAdapter->maxHosts = MV_SATA_5082_PORT_NUM;
+    else if(MV_6082_DEV_ID == mvCtrlModelGet())
+	pAdapter->maxHosts = MV_SATA_6082_PORT_NUM;
+#ifdef MV88F6281
+    else if(MV_6281_DEV_ID == mvCtrlModelGet())
+	pAdapter->maxHosts = MV_SATA_6281_PORT_NUM;
+    else if(MV_6192_DEV_ID == mvCtrlModelGet())
+	pAdapter->maxHosts = MV_SATA_6192_PORT_NUM;
+    else if(MV_6190_DEV_ID == mvCtrlModelGet())
+        pAdapter->maxHosts = MV_SATA_6190_PORT_NUM;
+    else if(MV_6282_DEV_ID == mvCtrlModelGet())
+        pAdapter->maxHosts = MV_SATA_6282_PORT_NUM;
+#endif
+    else if ((mvCtrlModelGet() == MV_78100_DEV_ID) || 
+		(mvCtrlModelGet() == MV_78200_DEV_ID) || 
+		(mvCtrlModelGet() == MV_78XX0_DEV_ID))
+	    pAdapter->maxHosts = MV_SATA_78XX0_PORT_NUM;
+    else if (mvCtrlModelGet() == MV_76100_DEV_ID)
+		pAdapter->maxHosts = MV_SATA_76100_PORT_NUM;
+    else if (mvCtrlModelGet() == MV_6323_DEV_ID)
+		pAdapter->maxHosts = MV_SATA_6323_PORT_NUM;
+    else if ((mvCtrlModelGet() == MV_6510_DEV_ID) ||
+	     (mvCtrlModelGet() == MV_6530_DEV_ID) ||
+	     (mvCtrlModelGet() == MV_6550_DEV_ID) ||
+	     (mvCtrlModelGet() == MV_6560_DEV_ID))
+		pAdapter->maxHosts = MV_SATA_65XX_PORT_NUM;
+    else if ((mvCtrlModelGet() == MV_78460_DEV_ID) ||
+	     (mvCtrlModelGet() == MV_78260_DEV_ID) ||
+	     (mvCtrlModelGet() == MV_78230_DEV_ID) ||
+	     (mvCtrlModelGet() == MV_78160_DEV_ID) ||
+	     (mvCtrlModelGet() == MV_78130_DEV_ID))
+		pAdapter->maxHosts = MV_SATA_78460_PORT_NUM;
+    else if (mvCtrlModelGet() == MV_6710_DEV_ID)
+		pAdapter->maxHosts = MV_SATA_6710_PORT_NUM;
+
+	for (i = 0; i < pAdapter->maxHosts; i++)
+	{	
+		if (MV_FALSE == mvCtrlPwrClckGet(SATA_UNIT_ID, (MV_U32)i))
+		{
+			printk("Warning: SATA %d is powered off\n", i);
+			mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+			return -ENOMEM;
+		}
+	}
+
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        struct Scsi_Host    *pshost = scsi_host_alloc(&driver_template, sizeof(IAL_HOST_T));
+        if (pshost == NULL)
+        {
+            mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "Scsi_Host allocation failed\n");
+            return -ENOMEM;
+        }
+        pAdapter->host[i] = HOSTDATA(pshost);
+        memset(pAdapter->host[i], 0, sizeof(IAL_HOST_T));
+        pAdapter->host[i]->scsihost = pshost;
+        pAdapter->host[i]->pAdapter = pAdapter;
+        pAdapter->host[i]->channelIndex = (MV_U8)i;
+        pAdapter->activeHosts |= (1 << i);
+    }
+    pAdapter->pcidev = NULL;
+    pMvSataAdapter = &(pAdapter->mvSataAdapter);
+    pMvSataAdapter->IALData = pAdapter;
+    spin_lock_init (&pAdapter->adapter_lock);
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        pAdapter->host[i]->scsi_cmnd_done_head = NULL;
+        pAdapter->host[i]->scsi_cmnd_done_tail = NULL;
+    }
+    
+    pAdapter->host[0]->scsihost->base = 0/*pci_resource_start(pcidev, 0)*/;
+    for (i = 1; i < pAdapter->maxHosts; i++)
+    {
+        if (pAdapter->host[i] != NULL)
+            pAdapter->host[i]->scsihost->base = pAdapter->host[0]->scsihost->base;
+    }
+    pMvSataAdapter->adapterIoBaseAddress = (MV_BUS_ADDR_T)(INTER_REGS_BASE + MV_SATA_REGS_OFFSET - 
+                                            0x20000);
+    
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "io base address 0x%08lx\n",
+             (ulong)pMvSataAdapter->adapterIoBaseAddress);
+    
+    pMvSataAdapter->adapterId = adapterId++;
+    /* get the revision ID */
+    
+    pMvSataAdapter->pciConfigRevisionId = 0;
+    pMvSataAdapter->pciConfigDeviceId = mvCtrlModelGet();
+    if (set_device_regs(pMvSataAdapter, NULL))
+    {
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+        return -ENOMEM;
+    }
+    /*Do not allow hotplug handler to work*/
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+    init_MUTEX(&pAdapter->rescan_mutex);
+    atomic_set(&pAdapter->stopped, 1);
+#endif
+
+    if (mvSataInitAdapter(pMvSataAdapter) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR,
+                 "[%d]: core failed to initialize the adapter\n",
+                 pMvSataAdapter->adapterId);
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+        return -ENOMEM;
+    }
+    if (mv_ial_lib_allocate_edma_queues(pAdapter))
+    {
+        mvLogMsg(MV_IAL_LOG_ID,MV_DEBUG_ERROR,
+                 "Failed to allocate memory for EDMA queues\n");
+
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+        return -ENOMEM;
+    }
+
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        if ((pAdapter->activeHosts & (1 << i)) == 0)
+        {
+            continue;
+        }
+        if (mv_ial_lib_prd_init(pAdapter->host[i]))
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR,
+                     "Failed to init PRD memory manager - host %d\n", i);
+            mv_ial_lib_free_edma_queues(pAdapter);
+            mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+            return -ENOMEM;
+        }
+    }
+    pAdapter->ataScsiAdapterExt = (MV_SAL_ADAPTER_EXTENSION*)kmalloc(sizeof(MV_SAL_ADAPTER_EXTENSION),
+                                                                     GFP_ATOMIC);
+    if (pAdapter->ataScsiAdapterExt == NULL)
+    {
+        mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG_ERROR,"[%d]: out of memory, failed to allocate MV_SAL_ADAPTER_EXTENSION\n",
+                 pAdapter->mvSataAdapter.adapterId);
+        mv_ial_lib_free_edma_queues(pAdapter);
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+        return -ENOMEM;
+    }
+    mvSataScsiInitAdapterExt(pAdapter->ataScsiAdapterExt,
+                             pMvSataAdapter);
+    /* let SAL report only the BUS RESET UA event*/
+    pAdapter->ataScsiAdapterExt->UAMask = MV_BIT0;
+    /* enable device interrupts even if no storage devices connected now*/
+    if (request_irq(SATA_IRQ_NUM, mv_ial_lib_int_handler,
+                    (IRQF_DISABLED | IRQF_SAMPLE_RANDOM | IRQF_SHARED), "mvSata",
+                    pAdapter) < 0)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: unable to allocate IRQ for controler\n",
+                 pMvSataAdapter->adapterId);
+        kfree(pAdapter->ataScsiAdapterExt);
+        mv_ial_lib_free_edma_queues(pAdapter);
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+        return -ENOMEM;
+    }
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        if ((pAdapter->activeHosts & (1 << i)) == 0)
+        {
+            continue;
+        }
+        pAdapter->host[i]->scsihost->irq = SATA_IRQ_NUM;
+        pAdapter->host[i]->scsihost->max_id = MV_SATA_PM_MAX_PORTS;
+        
+        pAdapter->host[i]->scsihost->max_lun = 1;
+        pAdapter->host[i]->scsihost->max_channel = 0;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+        pAdapter->host[i]->scsihost->select_queue_depths = mv_ial_ht_select_queue_depths;
+#endif
+    }
+    if (MV_FALSE == mvAdapterStartInitialization(pMvSataAdapter,
+                                                 &pAdapter->ialCommonExt,
+                                                 pAdapter->ataScsiAdapterExt))
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: mvAdapterStartInitialization"
+                 " Failed\n", pMvSataAdapter->adapterId);
+        free_irq (SATA_IRQ_NUM, pMvSataAdapter);
+        kfree(pAdapter->ataScsiAdapterExt);
+        mv_ial_lib_free_edma_queues(pAdapter);
+        mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+        return -ENOMEM;
+    }
+
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        if ((pAdapter->activeHosts & (1 << i)) == 0)
+        {
+            continue;
+        }
+        mv_ial_block_requests(pAdapter, i);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+        if (scsi_add_host(pAdapter->host[i]->scsihost, NULL) != 0)
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: scsi_add_host() failed.\n"
+                     , pMvSataAdapter->adapterId);
+            free_irq (SATA_IRQ_NUM , pMvSataAdapter);
+            kfree(pAdapter->ataScsiAdapterExt);
+            mv_ial_lib_free_edma_queues(pAdapter);
+            mv_ial_free_scsi_hosts(pAdapter, MV_TRUE);
+            return -ENODEV;
+        }
+#endif
+    }
+
+    pAdapter->stopAsyncTimer = MV_FALSE;
+    init_timer(&pAdapter->asyncStartTimer);
+    pAdapter->asyncStartTimer.data = (unsigned long)pAdapter;
+    pAdapter->asyncStartTimer.function = asyncStartTimerFunction;
+    pAdapter->asyncStartTimer.expires = jiffies + MV_LINUX_ASYNC_TIMER_PERIOD;
+    add_timer (&pAdapter->asyncStartTimer);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        if ((pAdapter->activeHosts & (1 << i)) != 0)
+        {
+            scsi_scan_host(pAdapter->host[i]->scsihost);
+        }
+    }
+    /*Enable hotplug handler*/
+    atomic_set(&pAdapter->stopped, 0);
+#endif
+    return 0;
+
+}
+#endif 
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+/****************************************************************
+ *  Name: mv_ial_ht_detect
+ *
+ *  Description:    Detect and initialize our boards.
+ *
+ *  Parameters:     tpnt - Pointer to SCSI host template structure.
+ *
+ *  Returns:        Number of adapters installed.
+ *
+ ****************************************************************/
+int mv_ial_ht_detect (Scsi_Host_Template *tpnt)
+{
+    int                 num_hosts=0;
+    struct pci_dev      *pcidev = NULL;
+    int                 index;
+    struct pci_device_id *id = &mvSata_pci_table[0];
+
+    mv_ial_init_log();
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+    if (!pci_present())
+    {
+        printk ("mvSata: PCI BIOS not present\n");
+        return 0;
+    }
+#endif
+
+    if (sizeof(struct mv_comp_info) > sizeof(Scsi_Pointer))
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "WARNING mv_comp_info must be "
+                 "re-defined - its too big");
+        return -1;
+    }
+    index = 0;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+    spin_unlock_irq (&io_request_lock);
+#endif
+
+    while (1)
+    {
+        if (id[index].device == 0)
+        {
+            break;
+        }
+        pcidev = NULL;
+
+        while ((pcidev = pci_find_device (MV_SATA_VENDOR_ID,
+                                          id[index].device, pcidev)) != NULL)
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "PCI device found, DeviceId 0x%x "
+                     "BAR0=%lx\n",
+                      id[index].device, pci_resource_start(pcidev,0));
+            if (mv_ial_probe_device(pcidev, &id[index]) == 0)
+            {
+                IAL_ADAPTER_T *pAdapter = pci_get_drvdata(pcidev);
+                num_hosts += pAdapter->maxHosts;
+            }
+        }
+        index ++;
+    }
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+    spin_lock_irq (&io_request_lock);
+#endif
+    return num_hosts;
+}
+#endif
+
+/****************************************************************
+ *  Name:   mv_ial_ht_release
+ *
+ *  Description:   release scsi host
+ *
+ *  Parameters:     SCpnt - Pointer to SCSI host structure.
+ *
+ *  Returns:          0 on success, otherwise of failure.
+ *
+ ****************************************************************/
+int mv_ial_ht_release (struct Scsi_Host *pHost)
+{
+    IAL_ADAPTER_T *pAdapter = MV_IAL_ADAPTER (pHost);
+    MV_U8 channel;
+    MV_SATA_ADAPTER * pMvSataAdapter = &pAdapter->mvSataAdapter;
+    unsigned long lock_flags;
+    struct scsi_cmnd *cmnds_done_list = NULL;
+    IAL_HOST_T          *ial_host = HOSTDATA(pHost);
+
+    channel = ial_host->channelIndex;
+    pAdapter->activeHosts &= ~ (1 << channel);
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, ": release host %d\n", pHost->host_no);
+    spin_lock_irqsave (&pAdapter->adapter_lock, lock_flags);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+    if (pAdapter->stopAsyncTimer != MV_TRUE)
+    {
+        /* Delete any pending timers */
+        pAdapter->stopAsyncTimer = MV_TRUE;
+        del_timer_sync(&pAdapter->asyncStartTimer);
+    }
+#endif
+
+    if (pMvSataAdapter->sataChannel[channel])
+    {
+        mvSataDisableChannelDma(pMvSataAdapter, channel);
+
+        mvSataFlushDmaQueue(pMvSataAdapter, channel,
+                            MV_FLUSH_TYPE_CALLBACK);
+        mv_ial_lib_free_channel(pAdapter, channel);
+   }
+     /* Check if there are commands in the done queue to be completed */
+
+    cmnds_done_list = mv_ial_lib_get_first_cmnd (pAdapter, channel);
+    if (cmnds_done_list)
+    {
+        unsigned long flags_io_request_lock;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+        spin_lock_irqsave(&io_request_lock, flags_io_request_lock);
+#else
+        spin_lock_irqsave(ial_host->scsihost->host_lock, flags_io_request_lock);
+#endif
+        mv_ial_lib_do_done(cmnds_done_list);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+        spin_unlock_irqrestore(&io_request_lock, flags_io_request_lock);
+#else
+        spin_unlock_irqrestore(ial_host->scsihost->host_lock, flags_io_request_lock);
+#endif
+    }
+    if (0 == pAdapter->activeHosts)
+    {
+      mvSataShutdownAdapter(pMvSataAdapter);
+    }
+    pAdapter->host[channel] = NULL;
+    mv_ial_lib_prd_destroy(ial_host);
+    spin_unlock_irqrestore (&pAdapter->adapter_lock, lock_flags);
+    scsi_remove_host(pHost);
+    scsi_host_put(pHost);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+    if (0 == pAdapter->activeHosts)
+    {
+        struct pci_dev *dev = pAdapter->pcidev;
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG,
+                     "[%d] freeing Adapter resources.\n", pAdapter->mvSataAdapter.adapterId);
+        free_irq (pAdapter->pcidev->irq, pMvSataAdapter);
+#ifdef MV_SUPPORT_MSI
+	pci_disable_msi(pAdapter->pcidev);
+#endif
+        kfree(pAdapter->ataScsiAdapterExt);
+        iounmap(pMvSataAdapter->adapterIoBaseAddress);
+        mv_ial_lib_free_edma_queues(pAdapter);
+        kfree(pAdapter);
+	pci_disable_device(dev);
+    }
+#endif
+    return 0;
+}
+
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+static void __devexit mv_ial_remove_device(struct pci_dev *pdev)
+{
+    IAL_ADAPTER_T       *pAdapter = (pdev != NULL) ? pci_get_drvdata(pdev) : pSocAdapter;
+    int numhosts;
+    int i;
+    unsigned long lock_flags;
+
+    if (pAdapter == NULL)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_FATAL_ERROR,
+                     "mv_ial_remove_device() No valid Adapter IAL structure found.\n");
+        return;
+    }
+
+    numhosts           = pAdapter->maxHosts;
+    /*flush hotplug rescan worker*/
+    atomic_inc(&pAdapter->stopped);
+    flush_scheduled_work();
+    /* Delete any pending timers */
+    spin_lock_irqsave (&pAdapter->adapter_lock, lock_flags);
+    pAdapter->stopAsyncTimer = MV_TRUE;
+    del_timer_sync(&pAdapter->asyncStartTimer);
+    spin_unlock_irqrestore(&pAdapter->adapter_lock, lock_flags);
+
+    for (i = 0; i < numhosts; i++)
+    {
+        if (pAdapter->host[i] != NULL)
+        {
+            mv_ial_ht_release (pAdapter->host[i]->scsihost);
+        }
+    }
+    if (pdev != NULL) /* pci device */
+    {
+        free_irq (pAdapter->pcidev->irq, &pAdapter->mvSataAdapter);
+#ifdef MV_SUPPORT_MSI
+	pci_disable_msi(pAdapter->pcidev);
+#endif
+	kfree(pAdapter->ataScsiAdapterExt);
+	iounmap(pAdapter->mvSataAdapter.adapterIoBaseAddress);
+	mv_ial_lib_free_edma_queues(pAdapter);
+	kfree(pAdapter);
+	pci_release_regions(pdev);
+	pci_disable_device(pdev);
+    }
+#ifdef CONFIG_MV_INCLUDE_INTEG_SATA
+    else /* Soc sata*/
+    {
+        free_irq (SATA_IRQ_NUM, &pAdapter->mvSataAdapter);
+	kfree(pAdapter->ataScsiAdapterExt);
+	mv_ial_lib_free_edma_queues(pAdapter);
+	kfree(pAdapter);
+    }
+#endif
+}
+#endif
+
+ /****************************************************************
+ *  Name:   mv_ial_ht_ata_cmd
+ *
+ *  Description:    handles mv_sata ata IOCTL special drive command (HDIO_DRIVE_CMD)
+ *
+ *  Parameters:     scsidev - Device to which we are issuing command
+ *                  arg     - User provided data for issuing command
+ *
+ *  Returns:        0 on success, otherwise of failure.
+ *
+ ****************************************************************/
+static int mv_ial_ht_ata_cmd(struct scsi_device *scsidev, void __user *arg)
+{
+    int rc = 0;
+    u8 scsi_cmd[MAX_COMMAND_SIZE];
+    u8 args[4], *argbuf = NULL, *sensebuf = NULL;
+    int argsize = 0;
+    enum dma_data_direction data_dir;
+    int cmd_result;
+
+    if (arg == NULL)
+        return -EINVAL;
+
+    if (copy_from_user(args, arg, sizeof(args)))
+        return -EFAULT;
+
+    sensebuf = kzalloc(SCSI_SENSE_BUFFERSIZE, GFP_NOIO);
+    if (!sensebuf)
+        return -ENOMEM;
+
+    memset(scsi_cmd, 0, sizeof(scsi_cmd));
+
+    if (args[3]) {
+        argsize = SECTOR_SIZE * args[3];
+        argbuf = kmalloc(argsize, GFP_KERNEL);
+        if (argbuf == NULL) {
+            rc = -ENOMEM;
+            goto error;
+        }
+
+        scsi_cmd[1]  = (4 << 1); /* PIO Data-in */
+        scsi_cmd[2]  = 0x0e;     /* no off.line or cc, read from dev,
+		                            block count in sector count field */
+        data_dir = DMA_FROM_DEVICE;
+    } else {
+        scsi_cmd[1]  = (3 << 1); /* Non-data */
+        scsi_cmd[2]  = 0x20;     /* cc but no off.line or data xfer */
+        data_dir = DMA_NONE;
+    }
+
+    scsi_cmd[0] = ATA_16;
+
+    scsi_cmd[4] = args[2];
+    if (args[0] == WIN_SMART) { /* hack -- ide driver does this too... */
+        scsi_cmd[6]  = args[3];
+        scsi_cmd[8]  = args[1];
+        scsi_cmd[10] = 0x4f;
+        scsi_cmd[12] = 0xc2;
+    } else {
+        scsi_cmd[6]  = args[1];
+    }
+    scsi_cmd[14] = args[0];
+
+    /* Good values for timeout and retries?  Values below
+       from scsi_ioctl_send_command() for default case... */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+    cmd_result = scsi_execute(scsidev, scsi_cmd, data_dir, argbuf, argsize,
+                              sensebuf, (10*HZ), 5, 0);
+#else
+    cmd_result = scsi_execute(scsidev, scsi_cmd, data_dir, argbuf, argsize,
+                              sensebuf, (10*HZ), 5, 0, NULL);
+#endif
+    if (driver_byte(cmd_result) == DRIVER_SENSE) {/* sense data available */
+        u8 *desc = sensebuf + 8;
+        cmd_result &= ~(0xFF<<24); /* DRIVER_SENSE is not an error */
+
+        /* If we set cc then ATA pass-through will cause a
+        * check condition even if no error. Filter that. */
+        if (cmd_result & SAM_STAT_CHECK_CONDITION) {
+            struct scsi_sense_hdr sshdr;
+            scsi_normalize_sense(sensebuf, SCSI_SENSE_BUFFERSIZE,
+                                 &sshdr);
+            if (sshdr.sense_key==0 &&
+                sshdr.asc==0 && sshdr.ascq==0)
+                cmd_result &= ~SAM_STAT_CHECK_CONDITION;
+        }
+
+        /* Send userspace a few ATA registers (same as drivers/ide) */
+        if (sensebuf[0] == 0x72 &&     /* format is "descriptor" */
+            desc[0] == 0x09 ) {        /* code is "ATA Descriptor" */
+            args[0] = desc[13];    /* status */
+            args[1] = desc[3];     /* error */
+            args[2] = desc[5];     /* sector count (0:7) */
+            if (copy_to_user(arg, args, sizeof(args)))
+                rc = -EFAULT;
+        }
+    }
+
+    if (cmd_result) {
+        rc = -EIO;
+        goto error;
+    }
+
+    if ((argbuf) && copy_to_user(arg + sizeof(args), argbuf, argsize))
+        rc = -EFAULT;
+
+error:
+    if (sensebuf) kfree(sensebuf);
+    if (argbuf) kfree(argbuf);
+    return rc;
+}
+
+/****************************************************************
+ *  Name:   mv_ial_ht_ioctl
+ *
+ *  Description:    mv_sata scsi ioctl
+ *
+ *  Parameters:     scsidev - Device to which we are issuing command
+ *                  cmd     - ioctl command
+ *                  arg     - User provided data for issuing command
+ *
+ *  Returns:        0 on success, otherwise of failure.
+ *
+ ****************************************************************/
+int mv_ial_ht_ioctl(struct scsi_device *scsidev, int cmd, void __user *arg)
+{
+    int rc = -ENOTTY;
+
+    /* No idea how this happens.... */
+    if (!scsidev)
+        return -ENXIO;
+
+    if (arg == NULL)
+        return -EINVAL;
+
+    switch (cmd) {
+        case HDIO_DRIVE_CMD:
+            if (!capable(CAP_SYS_ADMIN) || !capable(CAP_SYS_RAWIO))
+                return -EACCES;
+
+            rc =  mv_ial_ht_ata_cmd(scsidev, arg);
+            break;
+
+        default:
+            rc = -ENOTTY;
+    }
+
+    return rc;
+}
+
+/****************************************************************
+ *  Name:   mv_ial_ht_queuecommand
+ *
+ *  Description:    Process a queued command from the SCSI manager.
+ *
+ *  Parameters:     SCpnt - Pointer to SCSI command structure.
+ *                  done  - Pointer to done function to call.
+ *
+ *  Returns:        Status code.
+ *
+ ****************************************************************/
+int mv_ial_ht_queuecommand (struct scsi_cmnd * SCpnt, void (*done) (struct scsi_cmnd *))
+{
+    IAL_ADAPTER_T   *pAdapter = MV_IAL_ADAPTER(SCpnt->device->host);
+    MV_SATA_ADAPTER *pMvSataAdapter;
+    IAL_HOST_T      *pHost = HOSTDATA(SCpnt->device->host);
+    MV_U8            channel = pHost->channelIndex;
+    int             build_prd_table = 0;
+    unchar *cmd = (unchar *) SCpnt->cmnd;
+    struct mv_comp_info *completion_info;
+    unsigned long lock_flags;
+
+    struct scsi_cmnd   *cmnds_done_list = NULL;
+
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, " :queuecommand host=%d, bus=%d, channel=%d\n",
+             SCpnt->device->host->host_no,
+             SCpnt->device->channel,
+             channel);
+    if (done == NULL)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, ": in queuecommand, done function can't be NULL\n");
+        return 0;
+    }
+
+    if ((pAdapter == NULL) || (channel >= MV_SATA_CHANNELS_NUM)||
+        (pAdapter->host[channel] == NULL))
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_FATAL_ERROR,": in queuecommand, "
+                 "command queued for released host!!\n");
+        SCpnt->result = DID_NO_CONNECT << 16;
+        done(SCpnt);
+        return 0;
+    }
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+    spin_unlock_irq (&io_request_lock);
+#else
+    spin_unlock_irq(pHost->scsihost->host_lock);
+#endif
+
+    spin_lock_irqsave (&pAdapter->adapter_lock, lock_flags);
+
+    if (SCpnt->retries > 0)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR,": retry command host=%d, bus=%d"
+                 " SCpnt = %p\n", SCpnt->device->host->host_no, channel, SCpnt);
+    }
+
+    if (MV_TRUE == pAdapter->host[channel]->hostBlocked)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR,": command received for "
+                 "blocked host=%d, bus=%d, channel=%d, SCpnt = %p\n",
+                 SCpnt->device->host->host_no,
+                 SCpnt->device->channel,
+                 channel, SCpnt);
+#if 0
+        spin_unlock_irqrestore (&pAdapter->adapter_lock, lock_flags);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+        spin_lock_irq (&io_request_lock);
+#else
+        spin_lock_irq(pHost->scsihost->host_lock);
+#endif
+        return SCSI_MLQUEUE_HOST_BUSY;
+#endif
+    }
+
+    pMvSataAdapter = &pAdapter->mvSataAdapter;
+
+    SCpnt->result = DID_ERROR << 16;
+    SCpnt->scsi_done = done;
+
+    completion_info = ( struct mv_comp_info *) &(SCpnt->SCp);
+    completion_info->pSALBlock =
+    (MV_SATA_SCSI_CMD_BLOCK *) kmalloc(sizeof(MV_SATA_SCSI_CMD_BLOCK),
+                                       GFP_ATOMIC);
+    if (completion_info->pSALBlock == NULL)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR,  "in queuecommand: Failed to allocate SAL Block\n");
+        spin_unlock_irqrestore (&pAdapter->adapter_lock, lock_flags);
+		done(SCpnt);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+        spin_lock_irq (&io_request_lock);
+#else
+        spin_lock_irq(pHost->scsihost->host_lock);
+#endif
+        return -1;
+    }
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+    completion_info->kmap_buffer = 0;
+#endif
+    /* prepare the SAL Block paramters*/
+    if ((*cmd == READ_6) || (*cmd == READ_10) || (*cmd == READ_16) ||
+	(*cmd == WRITE_6) || (*cmd == WRITE_10) || (*cmd == WRITE_16))
+    {
+        build_prd_table = 1;
+    }
+    else if((pAdapter->ataScsiAdapterExt->ataDriveData[channel][SCpnt->device->id].identifyInfo.deviceType == MV_SATA_DEVICE_TYPE_ATAPI_DEVICE) && use_sg(SCpnt))
+    {
+	 /*
+	   for the 60x1 devices don't use DMA for control commands as the BMDMA will
+	   not write date to DRAM in case on underrun.
+	 */
+	 if(!(pAdapter->mvSataAdapter.sataAdapterGeneration == MV_SATA_GEN_II)){
+	      mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG,
+		       "in queuecommand: PRD for non data command for ATAPI device\n");
+	      build_prd_table = 1;
+	 }
+    }
+     if((pAdapter->ataScsiAdapterExt->ataDriveData[channel][SCpnt->device->id].identifyInfo.deviceType == MV_SATA_DEVICE_TYPE_ATAPI_DEVICE))
+    {
+        BUG_ON(((unsigned int)SCpnt->cmnd) & 0x1);
+    }
+    completion_info->pSALBlock->singleDataRegion = MV_FALSE;
+
+    /* prepare the SAL Block paramters*/
+    if(build_prd_table)
+    {
+        if(pAdapter->ataScsiAdapterExt->ataDriveData[channel][SCpnt->device->id].identifyInfo.deviceType == MV_SATA_DEVICE_TYPE_ATAPI_DEVICE)
+        {
+           mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "in queuecommand: Data command for ATAPI device\n");
+        }
+        else
+        {
+              mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "in queuecommand: Data command for ATA device\n");
+ 
+        }
+        if (mv_ial_lib_generate_prd(pMvSataAdapter, SCpnt, completion_info))
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "in queuecommand: illegal requested buffer\n");
+            spin_unlock_irqrestore (&pAdapter->adapter_lock, lock_flags);
+	   		done(SCpnt);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+            spin_lock_irq (&io_request_lock);
+#else
+            spin_lock_irq(pHost->scsihost->host_lock);
+#endif
+            return -1;
+        }
+        completion_info->pSALBlock->pDataBuffer = NULL;
+    }
+    else
+    {
+        completion_info->cpu_PRDpnt = NULL;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+	if (use_sg(SCpnt))
+	{
+       	    completion_info->kmap_buffer  = 1;
+	}
+#else
+        completion_info->pSALBlock->pDataBuffer = SCpnt->request_buffer;
+#endif
+    }
+    completion_info->SCpnt = SCpnt;
+
+    completion_info->pSALBlock->bus = channel;
+
+    completion_info->pSALBlock->target = SCpnt->device->id;
+    completion_info->pSALBlock->lun = SCpnt->device->lun;
+    completion_info->pSALBlock->pSalAdapterExtension = pAdapter->ataScsiAdapterExt;
+    completion_info->pSALBlock->pIalAdapterExtension = &pAdapter->ialCommonExt;
+    completion_info->pSALBlock->completionCallBack = IALCompletion;
+    completion_info->pSALBlock->IALData = SCpnt;
+    completion_info->pSALBlock->dataBufferLength = scsi_bufflen(SCpnt);
+    completion_info->pSALBlock->pSenseBuffer = SCpnt->sense_buffer;
+    completion_info->pSALBlock->ScsiCdb = SCpnt->cmnd;
+    completion_info->pSALBlock->ScsiCdbLength = SCpnt->cmd_len;
+    completion_info->pSALBlock->senseBufferLength = SCSI_SENSE_BUFFERSIZE;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+    if (completion_info->kmap_buffer)
+    {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+	struct scatterlist *sg;
+	sg = (struct scatterlist *) SCpnt->request_buffer;
+#endif
+	mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "SCpnt %p, cmd %x need to use"
+		" temp data buffer.lengh %d \n", SCpnt, *cmd , scsi_bufflen(SCpnt));
+	completion_info->pSALBlock->pDataBuffer = kmalloc(scsi_bufflen(SCpnt), GFP_ATOMIC);
+	if (completion_info->pSALBlock->pDataBuffer == NULL)
+    	{
+        	mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR,  "in queuecommand: Failed to allocate temp buffer for kmap\n");
+	        spin_unlock_irqrestore (&pAdapter->adapter_lock, lock_flags);
+		done(SCpnt);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+	        spin_lock_irq (&io_request_lock);
+#else
+        	spin_lock_irq(pHost->scsihost->host_lock);
+#endif
+	        return -1;
+    	}
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+        completion_info->pSALBlock->dataBufferLength = sg->length;
+#else
+        completion_info->pSALBlock->dataBufferLength = scsi_bufflen(SCpnt);
+#endif
+	if( SCpnt->sc_data_direction == DMA_TO_DEVICE) 
+	{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+		struct scatterlist *sg;
+	        MV_U8*          pBuffer;
+        	sg = (struct scatterlist *) SCpnt->request_buffer;
+
+		mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "SCpnt %p, cmd %x kmap temp data buffer and copy data.lengh %d \n", SCpnt, *cmd ,sg->length);
+	        pBuffer = kmap_atomic(sg->page, KM_USER0) + sg->offset;
+	        memcpy(completion_info->pSALBlock->pDataBuffer, pBuffer , sg->length);
+	        kunmap_atomic(pBuffer - sg->offset, KM_USER0);
+#else
+		scsi_sg_copy_to_buffer(SCpnt, completion_info->pSALBlock->pDataBuffer,
+				       scsi_bufflen(SCpnt));
+#endif
+	}
+
+    }
+#endif
+    switch(SCpnt->sc_data_direction)
+    {
+        case DMA_FROM_DEVICE:
+            completion_info->pSALBlock->dataDirection = MV_SCSI_COMMAND_DATA_DIRECTION_IN;
+            break;
+        case DMA_TO_DEVICE:
+            completion_info->pSALBlock->dataDirection = MV_SCSI_COMMAND_DATA_DIRECTION_OUT;
+            break;
+        default:
+           completion_info->pSALBlock->dataDirection = MV_SCSI_COMMAND_DATA_DIRECTION_NON;
+    }
+
+    if (*cmd != SCSI_OPCODE_MVSATA_SMART)
+    {
+        mvExecuteScsiCommand(completion_info->pSALBlock, MV_TRUE);
+    }
+    else
+    {
+        mvScsiAtaSendSmartCommand(pMvSataAdapter, completion_info->pSALBlock);
+    }
+
+    /*
+     * Check if there is valid commands to be completed. This is usually
+     * an immediate completed commands such as INQUIRY etc...
+     */
+    cmnds_done_list = mv_ial_lib_get_first_cmnd(pAdapter, channel);
+    spin_unlock_irqrestore(&pAdapter->adapter_lock, lock_flags);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+    spin_lock_irq (&io_request_lock);
+#else
+    spin_lock_irq(pHost->scsihost->host_lock);
+#endif
+    if (cmnds_done_list)
+    {
+        mv_ial_lib_do_done(cmnds_done_list);
+    }
+    return 0;
+}
+/****************************************************************
+ *  Name:   mv_ial_ht_bus_reset
+ *
+ *  Description:    reset given devise, all pending commands will be aborted
+ *                  with status DID_RESET.
+ *
+ *  Parameters:     SCpnt - Pointer to SCSI command structure.
+ *
+ *  Returns:        Status code.
+ *
+ ****************************************************************/
+int mv_ial_ht_bus_reset (struct scsi_cmnd *SCpnt)
+{
+    IAL_ADAPTER_T   *pAdapter = MV_IAL_ADAPTER(SCpnt->device->host);
+    MV_SATA_ADAPTER *pMvSataAdapter = &pAdapter->mvSataAdapter;
+    IAL_HOST_T      *pHost = HOSTDATA(SCpnt->device->host);
+    MV_U8 channel = pHost->channelIndex;
+
+    unsigned long lock_flags;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+    spin_unlock_irq (&io_request_lock);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2,6,13)
+    spin_unlock_irq(pHost->scsihost->host_lock);
+#endif
+    spin_lock_irqsave (&pAdapter->adapter_lock, lock_flags);
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "Bus Reset: host=%d, channel=%d, target=%d\n",
+             SCpnt->device->host->host_no, SCpnt->device->channel, SCpnt->device->id);
+    if (pMvSataAdapter->sataChannel[channel] == NULL)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "trying to reset disabled channel, host=%d, channel=%d\n",
+                 SCpnt->device->host->host_no, channel);
+        spin_unlock_irqrestore (&pAdapter->adapter_lock, lock_flags);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+        spin_lock_irq(&io_request_lock);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2,6,13)
+        spin_lock_irq(pHost->scsihost->host_lock);
+#endif
+        return FAILED;
+    }
+
+    mvSataDisableChannelDma(pMvSataAdapter, channel);
+
+    /* Flush pending commands */
+    mvSataFlushDmaQueue (pMvSataAdapter, channel, MV_FLUSH_TYPE_CALLBACK);
+
+    /* Hardware reset channel */
+    mvSataChannelHardReset(pMvSataAdapter, channel);
+
+    if (pMvSataAdapter->sataChannel[channel])
+    {
+        mvRestartChannel(&pAdapter->ialCommonExt, channel,
+                         pAdapter->ataScsiAdapterExt, MV_TRUE);
+        mv_ial_block_requests(pAdapter, channel);
+    }
+    /* don't call scsi done for the commands on this channel*/
+    mv_ial_lib_get_first_cmnd(pAdapter, channel);
+    spin_unlock_irqrestore(&pAdapter->adapter_lock, lock_flags);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+    spin_lock_irq(&io_request_lock);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2,6,13)
+    spin_lock_irq(pHost->scsihost->host_lock);
+#endif
+    return SUCCESS;
+}
+
+static MV_VOID mvAta2HostString(IN MV_U16 *source,
+                                OUT MV_U16 *target,
+                                IN MV_U32 wordsCount
+                               )
+{
+    MV_U32 i;
+    for (i=0 ; i < wordsCount; i++)
+    {
+        target[i] = MV_LE16_TO_CPU(target[i]);
+    }
+}
+
+/****************************************************************
+ *  Name:   mv_ial_ht_proc_info
+ *
+ *  Description:   /proc file
+ *
+ *  Parameters:
+ *
+ *  Returns:
+ *
+ ****************************************************************/
+int mv_ial_ht_proc_info(struct Scsi_Host *pshost,
+                        char *buffer, char **start, off_t offset,
+                        int length, int inout)
+{
+    int len = 0, temp, pmPort;
+    IAL_ADAPTER_T       *pAdapter;
+    MV_SATA_ADAPTER *pMvSataAdapter;
+    IAL_HOST_T       *pHost = HOSTDATA(pshost);
+
+    unsigned long lock_flags;
+
+    pAdapter = MV_IAL_ADAPTER(pshost);
+    pMvSataAdapter = &pAdapter->mvSataAdapter;
+    temp = pHost->channelIndex;
+    spin_lock_irqsave (&pAdapter->adapter_lock, lock_flags);
+    if (inout == 1)
+    {                     /* Writing to file */
+        /* The format is 'int_coal <sata unit> <coal_threshold> <timeout>' */
+        int i;
+        /* Check signature 'int_coal' at start of buffer */
+        if (!strncmp (buffer, "int_coal", strlen ("int_coal")))
+        {
+            int sata_unit;
+            u32 time_thre, coal_thre;
+            i = sscanf (buffer + strlen ("int_coal"), "%d %d %d\n",
+                        &sata_unit, &coal_thre, &time_thre);
+            if (i == 3)
+            {        /* Three matched inputs */
+                mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "[%d]: Modifying interrupt coalescing of unit %d to %d threshold and %d timer\n",pMvSataAdapter->adapterId, sata_unit, coal_thre, time_thre);
+                mvSataSetIntCoalParams (pMvSataAdapter, sata_unit, coal_thre, time_thre);
+            }
+            else
+            {
+                mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG, "[%d]: Error in interrupt coalescing parameters\n",
+                         pMvSataAdapter->adapterId);
+            }
+        }
+        /* Check signature 'sata_phy_shutdown' at start of buffer */
+        else if (!strncmp (buffer, "sata_phy_shutdown", strlen ("sata_phy_shutdown")))
+        {
+            int sata_phy;
+            i = sscanf (buffer + strlen ("sata_phy_shutdown"), "%d\n", &sata_phy);
+            if (i == 1)
+            {        /* Three matched inputs */
+
+                if (mvSataIsStorageDeviceConnected (pMvSataAdapter, sata_phy, NULL) == MV_TRUE)
+                {
+                    mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG, "[%d,%d]: Warning - shutting down a phy that is connected to a storage device\n", pMvSataAdapter->adapterId, sata_phy);
+                }
+                if (mvSataChannelPhyShutdown (pMvSataAdapter, sata_phy) == MV_TRUE)
+                {
+                    mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG, "[%d,%d]: Shutting down SATA phy\n", pMvSataAdapter->adapterId, sata_phy);
+                }
+            }
+            else
+            {
+                mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "[%d]: Error in shutting down SATA phy parameters\n",
+                         pMvSataAdapter->adapterId);
+            }
+        }
+        else if (!strncmp (buffer, "sata_phy_powerup", strlen ("sata_phy_powerup")))
+        {
+            int sata_phy;
+            i = sscanf (buffer + strlen ("sata_phy_powerup"), "%d\n", &sata_phy);
+            if (i == 1)
+            {        /* Three matched inputs */
+                if (mvSataChannelPhyPowerOn (pMvSataAdapter, sata_phy) == MV_TRUE)
+                {
+                    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "[%d,%d]: Turning on SATA phy\n", pMvSataAdapter->adapterId, sata_phy);
+                }
+            }
+            else
+            {
+                mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG,"[%d]: Error in powering up SATA phy parameters\n",
+                         pMvSataAdapter->adapterId);
+            }
+        }
+        spin_unlock_irqrestore (&pAdapter->adapter_lock, lock_flags);
+        return length;
+    }
+    else
+    {      /* Reading from file */
+        int i;
+        /*
+         * Write to the file the time stamp which is difference between last
+         * jiffies and current one. Next to it write the HZ parameter which
+         * indicates how many time jiffies parameter is incremented in a
+         * second.
+         */
+        len += snprintf (buffer + len,length - len, "%s\n", mv_ial_proc_version);
+        if (len >= length)
+        {
+            goto out;
+        }
+        len += snprintf (buffer + len,length - len, "\nTimeStamp :\n%ld\t%d\n",
+                         jiffies, HZ);
+        if (len >= length)
+        {
+            goto out;
+        }
+        /* Write the number of interrupts this adapter generated within the
+         * sampling time.
+         */
+        len += snprintf (buffer + len,length - len, "\nNumber of interrupts generated by the adapter is : \n%d\n",
+                         pAdapter->procNumOfInterrupts);
+        if (len >= length)
+        {
+            goto out;
+        }
+        if (pAdapter->pcidev)
+        {
+            len += snprintf (buffer + len, length - len, "\nPCI location: Bus %d, Slot %d\n",
+                             pAdapter->pcidev->bus->number,
+                             PCI_SLOT(pAdapter->pcidev->devfn));
+        
+            if (len >= length)
+            {
+                goto out;
+            }
+            len += snprintf (buffer + len, length - len, "DeviceID: %x, Rev %x,"
+                             " adapterId %d, channel %d \n",
+                             pAdapter->mvSataAdapter.pciConfigDeviceId,
+                             pAdapter->mvSataAdapter.pciConfigRevisionId,   
+                             pAdapter->mvSataAdapter.adapterId,
+                             pHost->channelIndex);
+
+            if (len >= length)
+            {
+                goto out;
+            }
+        }
+        else /*integrated sata*/
+        {
+            len += snprintf (buffer + len, length - len, "\nIntegrated Sata adapterId %d,  "
+                             "channel %d\n",pAdapter->mvSataAdapter.adapterId,
+                             pHost->channelIndex);
+            
+            if (len >= length)
+            {
+                goto out;
+            }  
+        }
+        if (pMvSataAdapter->sataChannel[temp])
+        {
+            if (pMvSataAdapter->sataChannel[temp]->deviceType == MV_SATA_DEVICE_TYPE_PM)
+            {
+                len += snprintf (buffer + len, length - len, 
+                                 "Port Multiplier connected, switching mode: %s\n",
+                                 (pMvSataAdapter->sataChannel[temp]->FBSEnabled == MV_TRUE) ?
+                                 "FBS":"CBS");
+
+                if (len >= length)
+                {
+                    goto out;
+                }
+            }
+        }
+        /*
+         * Check if channel connected.
+         * If not connected write -1 on a line
+         * If connected, write a line that has -
+         * 1.. Adapter number
+         * 2.. SCSI channel number (equivalent to SATA channel number).
+         * 3.. ID
+         * 4.. LUN (always 0)
+         * 5.. vendor name
+         * 6.. number of outstanding commands accumulated
+         * 7.. total sampling of outstanding commands
+         * 8.. total sectors transferred
+         * 9.. flag if queued / non-queued (1/0)
+         * 10. flag if LBA 48 or not (1/0)
+         * 11. flag if the storage device can be removed or not
+         *  (1 means can't be removed / 0 can be removed).
+         */
+        len += snprintf (buffer + len,length - len,"\n%s\t%s\t%s\t%s\t%s\t%s\t%s\t\t%s\t%s\n",
+                         "Adapter", "Channel", "Id", "LUN", "TO", "TS", "Vendor",
+                         "Mode", "LBA48");
+        if (len >= length)
+        {
+            goto out;
+        }
+        if ((len + 100) >= length)
+        {
+            goto out;
+        }
+        for (i = 0 ; i < 80 ; i++)
+            buffer [len + i] = '-';
+        len += i;
+        len += snprintf (buffer + len,length - len, "\n");
+        if (len >= length)
+        {
+            goto out;
+        }
+        
+        if (pMvSataAdapter->sataChannel[temp])
+        {
+            for (pmPort = 0; pmPort < MV_SATA_PM_MAX_PORTS; pmPort++)
+            {
+                if (pmPort > 0 &&
+                    (pMvSataAdapter->sataChannel[temp]->deviceType != MV_SATA_DEVICE_TYPE_PM))
+                {
+                    break;
+                }
+                if (pAdapter->ataScsiAdapterExt->ataDriveData[temp][pmPort].driveReady == MV_FALSE)
+                {
+                    continue;
+                }
+
+                len += snprintf (buffer + len,length - len, "%d\t%d\t%d\t%d\t%u\t%u\t",
+                                 pAdapter->mvSataAdapter.adapterId, temp, pmPort, 0,
+                                 pAdapter->ataScsiAdapterExt->ataDriveData[temp][pmPort].stats.totalIOs,
+                                 pAdapter->ataScsiAdapterExt->ataDriveData[temp][pmPort].stats.totalSectorsTransferred);
+                if (len >= length)
+                {
+                    goto out;
+                }
+                /*
+                 * Copy first 10 characters of the vendor name from the IDENTIFY
+                 * DEVICE ATA command result buffer
+                 */
+                if ((len+10) >= length)
+                {
+                    goto out;
+                }
+                memcpy (buffer+len,
+                        pAdapter->ataScsiAdapterExt->ataDriveData[temp][pmPort].identifyInfo.model, 10);
+                mvAta2HostString((MV_U16 *)(buffer+len), (MV_U16 *)(buffer+len), 5);
+                /*
+                 * Clean spaces in vendor name and swap odd and even characters.
+                 * The swap is due to the format of the IDENTIFY DEVICE command
+                 */
+                for (i=0 ; i<10 ; i+=2)
+                {
+                    char ch = buffer[len + i];
+                    buffer[len + i] = buffer[len+1 + i];
+                    buffer[len+1 + i] = ch;
+                    if (buffer[len + i] == ' ')
+                    {
+                        buffer[len + i + 1] = ' ';
+                        break;
+                    }
+                    if (buffer[len+1 + i] == ' ')
+                    {
+                        break;
+                    }
+                }
+                if ((len + 10) >= length)
+                {
+                    goto out;
+                }
+                for (; i < 10; i++)
+                {
+                    buffer[len + i] = ' ';
+                }
+
+                len += 10;
+                len += snprintf (buffer + len,length - len, "\t%s \t%d\n",
+                                 (pMvSataAdapter->sataChannel[temp]->queuedDMA == MV_EDMA_MODE_QUEUED) ?
+                                  "TCQ" : (pMvSataAdapter->sataChannel[temp]->queuedDMA == MV_EDMA_MODE_NATIVE_QUEUING) ?
+                                  "NCQ":"Normal",
+                                 (pAdapter->ataScsiAdapterExt->ataDriveData[temp][pmPort].identifyInfo.LBA48Supported == MV_TRUE)  ? 1 : 0);
+                if (len >= length)
+                {
+                    goto out;
+                }
+            }
+        }
+        if ((!pMvSataAdapter->sataChannel[temp]) &&
+            (mvSataIsStorageDeviceConnected (pMvSataAdapter, temp, NULL) == MV_TRUE))
+            len += snprintf (buffer + len,length - len, "Storage device connected to channel %d is malfunction\n", temp);
+        if (len >= length)
+        {
+            goto out;
+        }
+        len += snprintf (buffer + len,length - len,"\n\n\nTO           - Total Outstanding commands accumulated\n");
+        if (len >= length)
+        {
+            goto out;
+        }
+        len += snprintf (buffer + len,length - len,"TSA          - Total number of IOs accumulated\n");
+        if (len >= length)
+        {
+            goto out;
+        }
+        len += snprintf (buffer + len,length - len,"TS           - Total number of sectors transferred (both read/write)\n");
+        if (len >= length)
+        {
+            goto out;
+        }
+        len += snprintf (buffer + len,length - len,"Mode         - EDMA mode (TCQ|NCQ|Normal)\n");
+        if (len >= length)
+        {
+            goto out;
+        }
+        len += snprintf (buffer + len,length - len,"LBA48        - Large Block Address 48 feature set enabled\n");
+        if (len >= length)
+        {
+            goto out;
+        }
+    }
+    out:
+    spin_unlock_irqrestore (&pAdapter->adapter_lock, lock_flags);
+    return(len);
+}
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+/****************************************************************
+ *  Name:   mv_ial_ht_proc_info (kernel version < 2.6)
+ *
+ *  Description:   /proc file
+ *
+ *  Parameters:
+ *
+ *  Returns:
+ *
+ ****************************************************************/
+int mv_ial_ht_proc_info24(char *buffer, char **start, off_t offset,
+                        int length, int inode, int inout)
+{
+    struct Scsi_Host *pshost = 0;
+
+    for (pshost = scsi_hostlist; pshost; pshost = pshost->next)
+    {
+        if (pshost->host_no == inode)
+        {
+            return mv_ial_ht_proc_info(pshost, buffer, start,
+                                       offset,length, inout);
+        }
+    }
+    return -EINVAL;
+}
+#endif
+
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+
+static int mv_ial_ht_slave_configure (struct scsi_device* pDevs)
+{
+    IAL_HOST_T *pHost = HOSTDATA (pDevs->host);
+    struct Scsi_Host* scsiHost = pDevs->host;
+    struct scsi_device*    pDevice = NULL;
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "[%d]: slave configure\n",
+                        pHost->pAdapter->mvSataAdapter.adapterId);
+
+    if (pHost->use128Entries == MV_TRUE)
+    {
+        pHost->scsihost->can_queue = MV_SATA_GEN2E_SW_QUEUE_SIZE;
+    }
+    else
+    {
+        pHost->scsihost->can_queue = MV_SATA_SW_QUEUE_SIZE;
+    }
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "[%d %d]: adjust host[channel] queue depth"
+             " to %d\n", pHost->pAdapter->mvSataAdapter.adapterId, pHost->channelIndex,
+                  pHost->scsihost->can_queue);
+    shost_for_each_device(pDevice, scsiHost)
+    {
+        int deviceQDepth = 2;
+        
+        if(pHost->pAdapter->ataScsiAdapterExt->ataDriveData[pHost->channelIndex][pDevice->id].identifyInfo.deviceType == MV_SATA_DEVICE_TYPE_ATAPI_DEVICE)
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "[%d %d %d]: ATAPI device found\n", 
+                  pHost->pAdapter->mvSataAdapter.adapterId, pHost->channelIndex,
+                  pDevice->id);
+            pDevice->use_10_for_rw = 1;
+            pDevice->use_10_for_ms = 1;
+            scsi_adjust_queue_depth(pDevice, 0, 1);
+//                pHost->scsihost->max_cmd_len = 12;
+//	    blk_queue_max_sectors(pDevice->request_queue, 256);
+	    blk_queue_max_hw_sectors(pDevice->request_queue, 256);
+        }
+        else
+        {
+
+            if (pHost->mode != MV_EDMA_MODE_NOT_QUEUED)
+            {
+                deviceQDepth = 31;
+                if (pHost->scsihost->can_queue >= 32)
+                {
+                    deviceQDepth = 32;
+                }
+            }
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "[%d %d %d]: adjust device queue "
+                     "depth to %d\n", pHost->pAdapter->mvSataAdapter.adapterId,
+                     pDevice->channel, pDevice->id, deviceQDepth);
+            scsi_adjust_queue_depth(pDevice, MSG_SIMPLE_TAG, deviceQDepth);
+#ifdef MV_SUPPORT_1MBYTE_IOS
+            if(pHost->pAdapter->ataScsiAdapterExt->ataDriveData[pHost->channelIndex][pDevice->id].identifyInfo.LBA48Supported == MV_TRUE)
+	    {
+	        //blk_queue_max_sectors(pDevice->request_queue, 2048);
+		blk_queue_max_hw_sectors(pDevice->request_queue, 2048);
+ 	        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d %d %d]: set device max sectors to 2048 \n",
+	            pHost->pAdapter->mvSataAdapter.adapterId,
+                    pHost->channelIndex, pDevice->id);
+            }
+#endif
+        }
+    }
+    scsiHost->max_cmd_len = 16;    
+    return 0;
+}
+#else
+static void mv_ial_ht_select_queue_depths (struct Scsi_Host* pHost,
+                                           struct scsi_device* pDevs)
+{
+    IAL_HOST_T *ial_host = HOSTDATA (pHost);
+    struct scsi_device* pDevice;
+    if (ial_host != NULL)
+    {
+        
+        /* linux 2.4 queue depth is not tunable, so we set the device queue */
+        /* to the max value (MV_SATA_SW_QUEUE_SIZE), and limit the number queued */
+        /* commands using the cmd_per_lun */
+
+        /* set can_queue to the max number of queued commands per host (sata */
+        /* channel). This may casue startvation if PortMultiplier is connected*/
+        pHost->cmd_per_lun = 31;
+        if (ial_host->mode != MV_EDMA_MODE_NOT_QUEUED)
+        {   
+            if (ial_host->use128Entries == MV_TRUE)
+            {
+                pHost->can_queue = MV_SATA_GEN2E_SW_QUEUE_SIZE;
+                pHost->cmd_per_lun = 32;
+            }
+            else
+            {
+                pHost->can_queue = MV_SATA_SW_QUEUE_SIZE;
+            }
+        }
+        else
+        {
+            pHost->can_queue = MV_DEFAULT_QUEUE_DEPTH;
+        }
+        
+
+        /*always allocate the max number of commands */
+        for (pDevice = pDevs; pDevice; pDevice = pDevice->next)
+        {
+            if (pDevice->host == pHost)
+            {
+                pDevice->queue_depth = MV_SATA_SW_QUEUE_SIZE;
+            }
+        }
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "[%d %d]: adjust queue depth to %d\n",
+            ial_host->pAdapter->mvSataAdapter.adapterId,
+            ial_host->channelIndex,
+            pHost->can_queue);
+    }
+}
+#endif
+
+int mv_ial_ht_abort(struct scsi_cmnd *SCpnt)
+{
+    IAL_ADAPTER_T   *pAdapter;
+    IAL_HOST_T      *pHost;
+
+    MV_SATA_ADAPTER *pMvSataAdapter;
+    MV_U8           channel;
+    unsigned long lock_flags;
+    struct scsi_cmnd *cmnds_done_list = NULL;
+
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "abort command %p\n", SCpnt);
+    if (SCpnt == NULL)
+    {
+        return FAILED;
+    }
+    pHost = HOSTDATA(SCpnt->device->host);
+    channel = pHost->channelIndex;
+    pAdapter = MV_IAL_ADAPTER(SCpnt->device->host);
+    pMvSataAdapter = &pAdapter->mvSataAdapter;
+    
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+    if (SCpnt->serial_number != SCpnt->serial_number_at_timeout)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d %d %d]: abort failed, "
+                 "serial number mismatch\n",SCpnt->device->host->host_no,
+                 channel, SCpnt->device->id);
+        return FAILED;
+    }
+    spin_unlock_irq (&io_request_lock);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2,6,13)
+    spin_unlock_irq (pHost->scsihost->host_lock);
+#endif
+    spin_lock_irqsave (&pAdapter->adapter_lock, lock_flags);
+
+    mvRestartChannel(&pAdapter->ialCommonExt, channel,
+                     pAdapter->ataScsiAdapterExt, MV_TRUE);
+    mv_ial_block_requests(pAdapter, channel);
+
+    cmnds_done_list = mv_ial_lib_get_first_cmnd(pAdapter, channel);
+
+    spin_unlock_irqrestore (&pAdapter->adapter_lock, lock_flags);
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+    spin_lock_irq(&io_request_lock);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(2,6,13)
+    spin_lock_irq (pHost->scsihost->host_lock);
+#endif
+
+    if (cmnds_done_list)
+    {
+        scsi_report_bus_reset(SCpnt->device->host, SCpnt->device->channel);
+        mv_ial_lib_do_done(cmnds_done_list);
+        return SUCCESS;
+    }
+
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d %d %d]: command abort failed\n",
+             SCpnt->device->host->host_no, SCpnt->device->channel, SCpnt->device->id);
+    return FAILED;
+}
+
+
+Scsi_Host_Template driver_template = mvSata;
+
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_DESCRIPTION("Marvell Serial ATA PCI-X Adapter");
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+#include "scsi_module.c"
+#endif
+module_param_named(noncq, ncq_disable, bool, 0444);
+MODULE_PARM_DESC(ncq, "Disable use of NCQ (Default: false)");
+
+module_param_named(nopmncq, pm_ncq_disable, bool, 0444);
+MODULE_PARM_DESC(pmncq, "Disable use of NCQ (Default: false)");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalHt.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalHt.h
new file mode 100644
index 0000000..bd65540
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalHt.h
@@ -0,0 +1,264 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* file_name - mvLinuxIalHt.h
+*
+* DESCRIPTION: header file for the layer that emulates SCSI adapter on the
+*           SATA adapter
+*
+*
+* DEPENDENCIES:
+*   None.
+*
+*
+******************************************************************************/
+#ifndef __INCmvLinuxIalHth
+#define __INCmvLinuxIalHth
+
+#include <linux/version.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+#include <scsi/scsi.h>
+#include <scsi/scsi_cmnd.h>
+#include <scsi/scsi_device.h>
+#include <scsi/scsi_host.h>
+#include <scsi/scsi_tcq.h>
+#include <scsi/scsi_eh.h>
+#else
+#include <linux/blk.h>
+#include "scsi.h"
+#include "hosts.h"
+#endif
+
+#include "mvOs.h"
+#include "mvSata.h"
+#include "mvStorageDev.h"
+#include "mvScsiAtaLayer.h"
+#include "mvLinuxIalLib.h"
+#include "mvIALCommon.h"
+
+#include <linux/blkdev.h>
+#include <linux/spinlock.h>
+/* Common forward declarations for all Linux-versions: */
+
+/* Interfaces to the midlevel Linux SCSI driver */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+extern int mv_ial_ht_detect (Scsi_Host_Template *);
+#else
+typedef struct scsi_host_template Scsi_Host_Template;
+#endif
+extern int mv_ial_ht_release (struct Scsi_Host *);
+extern int mv_ial_ht_queuecommand (struct scsi_cmnd *, void (*done) (struct scsi_cmnd *));
+extern int mv_ial_ht_bus_reset (struct scsi_cmnd *);
+extern int mv_ial_ht_abort(struct scsi_cmnd *SCpnt);
+extern int mv_ial_ht_ioctl(struct scsi_device *, int, void __user *);
+
+#define HOSTDATA(host) ((IAL_HOST_T *)&host->hostdata)
+#define MV_IAL_ADAPTER(host) (HOSTDATA(host)->pAdapter)
+
+#define TEMP_DATA_BUFFER_LENGTH		    512
+
+/*#define MV_SUPPORT_1MBYTE_IOS*/
+#ifdef CONFIG_PCI_MSI
+/*#define MV_SUPPORT_MSI*/
+#endif
+
+
+#ifndef MRVL_SATA_BUFF_BOUNDARY
+#define MRVL_SATA_BUFF_BOUNDARY (1 << 24)
+#endif /* MRVL_SATA_BUFF_BOUNDARY */
+
+#define MRVL_SATA_BOUNDARY_MASK (MRVL_SATA_BUFF_BOUNDARY - 1)
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+#define mvSata                                                          \
+{                                                                           \
+    module:     THIS_MODULE,\
+    proc_name:          "mvSata",                   /* proc_name */     \
+    proc_info:          mv_ial_ht_proc_info,    /*proc info fn */   \
+    slave_configure:    mv_ial_ht_slave_configure,\
+    name:               "Marvell SCSI to SATA adapter", /*name*/            \
+    release:            mv_ial_ht_release,              /*release fn*/      \
+    queuecommand:       mv_ial_ht_queuecommand,         /*queuecommand fn*/ \
+    ioctl:              mv_ial_ht_ioctl,                /*ioctl fn */       \
+    bios_param:         NULL    /*mv_ial_ht_biosparam*/,/*bios fn*/     \
+    eh_device_reset_handler: NULL/*mv_ial_ht_dev_reset*/,                   \
+    eh_bus_reset_handler: mv_ial_ht_bus_reset,                              \
+    eh_abort_handler:   mv_ial_ht_abort,                                    \
+    can_queue:          MV_SATA_SW_QUEUE_SIZE,           /* unlimited */     \
+    this_id:            MV_SATA_PM_MAX_PORTS,                          /*set by detect*/   \
+    sg_tablesize:       64,                             /*sg_tablesize*/    \
+    max_sectors:        256,                                                \
+    cmd_per_lun:        MV_SATA_SW_QUEUE_SIZE,           /*cmd_per_lun*/     \
+    unchecked_isa_dma:  0,                              /*32-Bit Busmaster*/\
+    emulated:           1,                      /* not real scsi adapter */ \
+    use_clustering:     ENABLE_CLUSTERING               /*use_clustering*/  \
+}
+#else
+#define mvSata                                                          \
+{                                                                           \
+    proc_name:          "mvSata",                   /* proc_name */     \
+    proc_info:          mv_ial_ht_proc_info24,  /*proc info fn */   \
+    select_queue_depths: NULL,              \
+    name:               "Marvell SCSI to SATA adapter", /*name*/            \
+    detect:             mv_ial_ht_detect,               /*detect fn*/       \
+    release:            mv_ial_ht_release,              /*release fn*/      \
+    command:            NULL,                           /*command fn*/      \
+    queuecommand:       mv_ial_ht_queuecommand,         /*queuecommand fn*/ \
+    ioctl:              mv_ial_ht_ioctl,                /*ioctl fn */       \
+    bios_param:         NULL    /*mv_ial_ht_biosparam*/,/*bios fn*/     \
+    eh_device_reset_handler: NULL/*mv_ial_ht_dev_reset*/,                   \
+    eh_bus_reset_handler: mv_ial_ht_bus_reset,                              \
+    eh_abort_handler:   mv_ial_ht_abort,                                    \
+    can_queue:          MV_SATA_SW_QUEUE_SIZE,                         /* unlimited */     \
+    this_id:            MV_SATA_PM_MAX_PORTS,                              /*set by detect*/   \
+    sg_tablesize:       64,                             /*sg_tablesize*/    \
+    max_sectors:        256,                                                \
+    cmd_per_lun:        MV_SATA_SW_QUEUE_SIZE,           /*cmd_per_lun*/     \
+    unchecked_isa_dma:  0,                              /*32-Bit Busmaster*/\
+    emulated:           1,                      /* not real scsi adapter */ \
+    use_new_eh_code:    1,                                                  \
+    highmem_io:         1,                           /*highmem_io enabled*/\
+    use_clustering:     ENABLE_CLUSTERING               /*use_clustering*/  \
+}
+#endif
+
+
+#define MV_IAL_HT_SACOALT_DEFAULT   4
+#define MV_IAL_HT_SAITMTH_DEFAULT   (150 * 50)
+
+/****************************************/
+/*          GENERAL Definitions         */
+/****************************************/
+
+struct IALHost;
+
+/*struct prdPool;*/
+typedef struct IALAdapter
+{
+    MV_SATA_ADAPTER     mvSataAdapter;
+    MV_U8               activeHosts;
+    int                 maxHosts;
+    struct IALHost      *host[MV_SATA_CHANNELS_NUM];
+    struct pci_dev      *pcidev;
+    u8                  rev_id; /* adapter revision id */
+    u8                  *requestsArrayBaseAddr;
+    u8                  *requestsArrayBaseAlignedAddr;
+    dma_addr_t          requestsArrayBaseDmaAddr;
+    dma_addr_t          requestsArrayBaseDmaAlignedAddr;
+    u8                  *responsesArrayBaseAddr;
+    u8                  *responsesArrayBaseAlignedAddr;
+    dma_addr_t          responsesArrayBaseDmaAddr;
+    dma_addr_t          responsesArrayBaseDmaAlignedAddr;
+    u32                  requestQueueSize;
+    u32                  responseQueueSize;
+    u32                 procNumOfInterrupts;
+    MV_IAL_COMMON_ADAPTER_EXTENSION ialCommonExt;
+    MV_BOOLEAN          stopAsyncTimer;
+    struct timer_list   asyncStartTimer;
+    MV_SAL_ADAPTER_EXTENSION  *ataScsiAdapterExt;
+    spinlock_t          adapter_lock;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+    struct semaphore    rescan_mutex;
+    atomic_t            stopped;
+#endif
+    MV_U16		tempDataBuffer[TEMP_DATA_BUFFER_LENGTH/2];
+} IAL_ADAPTER_T;
+
+typedef struct IALHost
+{
+    struct Scsi_Host* scsihost;
+    MV_U8 channelIndex;
+    IAL_ADAPTER_T* pAdapter;
+    MV_EDMA_MODE mode;
+    MV_SATA_SWITCHING_MODE switchingMode;
+    MV_BOOLEAN  use128Entries;
+    void  *prdPool[MV_SATA_GEN2E_SW_QUEUE_SIZE];
+    void  *prdPoolAligned[MV_SATA_GEN2E_SW_QUEUE_SIZE];
+    MV_U32  freePRDsNum;
+    struct scsi_cmnd *scsi_cmnd_done_head, *scsi_cmnd_done_tail;
+    MV_BOOLEAN  hostBlocked;
+} IAL_HOST_T;
+
+/******************************************************************************
+* We use the Scsi_Pointer structure that's included with each command
+* SCSI_Cmnd as a scratchpad for our SRB. This allows us to accept
+* an unlimited number of commands.
+*
+* SCp will always point to mv_comp_info structure
+*******************************************************************************/
+
+/* UDMA command completion info */
+struct mv_comp_info
+{
+    struct scsi_cmnd           *SCpnt;
+    MV_SATA_EDMA_PRD_ENTRY  *cpu_PRDpnt;
+    dma_addr_t      dma_PRDpnt;
+    dma_addr_t      single_buff_busaddr;
+    unsigned int        allocated_entries;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+    unsigned int        kmap_buffer;
+#endif
+    unsigned int        seq_number;
+    MV_SATA_SCSI_CMD_BLOCK  *pSALBlock;
+    struct scsi_cmnd           *next_done;
+};
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,23)
+#define scsi_bufflen(p)		((p)->request_bufflen)
+#define use_sg(p)		((p)->use_sg)
+#else
+#define use_sg(p)		1
+#endif
+
+
+/* Once pci64_ DMA mapping interface is in, kill this. */
+/*#define pci64_alloc_consistent(d,s,p) pci_alloc_consistent((d),(s),(p))*/
+/*#define pci64_free_consistent(d,s,c,a) pci_free_consistent((d),(s),(c),(a))*/
+
+#define pci64_map_single(d,c,s,dir) pci_map_single((d),(c),(s),(dir))
+#define pci64_map_sg(d,s,n,dir) pci_map_sg((d),(s),(n),(dir))
+#define pci64_unmap_single(d,a,s,dir) pci_unmap_single((d),(a),(s),(dir))
+#define pci64_unmap_sg(d,s,n,dir) pci_unmap_sg((d),(s),(n),(dir))
+
+#if (BITS_PER_LONG > 32) || defined(CONFIG_HIGHMEM64G)
+#define pci64_dma_hi32(a) ((u32) (0xffffffff & (((u64)(a))>>32)))
+#define pci64_dma_lo32(a) ((u32) (0xffffffff & (((u64)(a)))))
+#else
+#define pci64_dma_hi32(a) 0
+#define pci64_dma_lo32(a) (a)
+#endif  /* BITS_PER_LONG */
+#define sg_dma64_address(s) sg_dma_address(s)
+#define sg_dma64_len(s) sg_dma_len(s)
+
+
+#endif /* __INCmvLinuxIalHth */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalLib.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalLib.c
new file mode 100644
index 0000000..30725b5
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalLib.c
@@ -0,0 +1,1414 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* file_name - mvLinuxIalLib.c
+*
+* DESCRIPTION:
+*   implementation for linux IAL lib functions.
+*
+* DEPENDENCIES:
+*   mvLinuxIalLib.h
+*   mvLinuxIalHt.h
+*
+*
+*******************************************************************************/
+
+/* includes */
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <linux/pci.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+    #include <linux/workqueue.h>
+#endif
+
+#include "mvLinuxIalLib.h"
+#include "mvIALCommon.h"
+
+#ifndef scsi_to_pci_dma_dir
+    #define scsi_to_pci_dma_dir(scsi_dir) ((int)(scsi_dir))
+#endif
+
+
+/* Connect / disconnect timers. */
+/* Note that the disconnect timer should be smaller than the SCSI */
+/* subsystem timer. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+struct rescan_wrapper
+{
+    struct work_struct     work;
+    IAL_ADAPTER_T       *pAdapter;
+    MV_U8                  channelIndex;
+    MV_U16                 targetsToRemove;
+    MV_U16                 targetsToAdd;
+};
+#endif
+
+
+static void *mv_ial_lib_prd_allocate(IAL_HOST_T *pHost);
+
+static int mv_ial_lib_add_buffer_to_prd_table(MV_SATA_ADAPTER   *pMvSataAdapter,
+                                              MV_SATA_EDMA_PRD_ENTRY *pPRD_table,
+                                              int table_size,
+                                              int *count, dma_addr_t buf_addr,
+                                              unsigned int buf_len, int isEOT);
+
+void release_ata_mem(struct mv_comp_info * pInfo);
+
+dma_addr_t inline pci64_map_page(struct pci_dev *hwdev, void* address,
+                                 size_t size, int direction)
+
+{
+    dma_addr_t mm = pci_map_page(hwdev, virt_to_page(address),
+                                 ((unsigned long)address & ~PAGE_MASK),
+                                 size, direction);
+    return mm;
+}
+
+
+void inline pci64_unmap_page(struct pci_dev *hwdev, dma_addr_t address,
+                             size_t size, int direction)
+{
+    pci_unmap_page(hwdev, address, size, direction);
+}
+
+
+int mv_ial_lib_prd_init(IAL_HOST_T *pHost)
+{
+    MV_U8  i;
+    MV_U32  boolSize = MV_SATA_SW_QUEUE_SIZE;
+
+    if ((pHost->pAdapter->mvSataAdapter.sataAdapterGeneration >= MV_SATA_GEN_IIE)&&
+        (pHost->pAdapter->mvSataAdapter.pciConfigDeviceId != MV_SATA_DEVICE_ID_6082))
+    {
+        boolSize = MV_SATA_GEN2E_SW_QUEUE_SIZE;
+    }
+    /*
+     * Allocate PRD Pool  -
+     * Since the driver supports 64 SG table, then each PRD table can go upto
+     * 1KByte (64 entries * 16byte)
+     */
+    for (i = 0 ; i < boolSize; i++)
+    {
+        pHost->prdPool[i] = kmalloc ((MV_EDMA_PRD_ENTRY_SIZE * MV_PRD_TABLE_SIZE * 2)
+				     + 16, 
+                                     GFP_KERNEL);
+        if (pHost->prdPool[i] == NULL)
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: Could not allocate PRD pool\n",
+                     pHost->pAdapter->mvSataAdapter.adapterId, pHost->channelIndex);
+            return -1;
+        }
+        pHost->prdPoolAligned[i] = (void *)(((ulong)(pHost->prdPool[i]) + 15 ) & ~0xf);
+    }
+
+    pHost->freePRDsNum = boolSize;
+
+    return 0;
+}
+
+static void *mv_ial_lib_prd_allocate(IAL_HOST_T *pHost)
+{
+    return pHost->prdPoolAligned[--pHost->freePRDsNum];
+}
+
+int mv_ial_lib_prd_free(IAL_HOST_T *pHost, int size, dma_addr_t dmaPtr,
+                        void *cpuPtr)
+{
+    pci64_unmap_page(pHost->pAdapter->pcidev,
+                     dmaPtr,
+                     size * MV_EDMA_PRD_ENTRY_SIZE,
+                     PCI_DMA_TODEVICE);
+
+    pHost->prdPoolAligned[pHost->freePRDsNum++] = cpuPtr;
+    return 0;
+}
+
+
+int mv_ial_lib_prd_destroy(IAL_HOST_T *pHost)
+{
+    MV_U8 temp;
+    MV_U32  boolSize = MV_SATA_SW_QUEUE_SIZE;
+
+    if ((pHost->pAdapter->mvSataAdapter.sataAdapterGeneration >= MV_SATA_GEN_IIE)&&
+        (pHost->pAdapter->mvSataAdapter.pciConfigDeviceId != MV_SATA_DEVICE_ID_6082))
+    {
+        boolSize = MV_SATA_GEN2E_SW_QUEUE_SIZE;
+    }
+    
+    for (temp = 0; temp < boolSize; temp++)
+    {
+        if (pHost->prdPool[temp] != NULL)
+        {
+            kfree (pHost->prdPool[temp]);
+        }
+    }
+    return 0;
+}
+
+
+/*******************************************************************************
+ *  Name:   mv_ial_lib_add_done_queue
+ *
+ *  Description:    Add scsi_cmnd to done list. Caller must take care of
+ *                  adapter_lock locking.
+ *
+ *  Parameters:     pAdapter - Adapter data structure
+ *                  scsi_cmnd - SCSI command data sturcture
+ *
+ ******************************************************************************/
+void mv_ial_lib_add_done_queue (struct IALAdapter *pAdapter,
+                                MV_U8 channel,
+                                struct scsi_cmnd   *scsi_cmnd)
+{
+    /* Put new command in the tail of the queue and make it point to NULL */
+    ((struct mv_comp_info *)(&scsi_cmnd->SCp))->next_done = NULL;
+
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Adding command @ %p to done queue, "
+             "channel %d\n",scsi_cmnd, channel);
+    if ((channel >= MV_SATA_CHANNELS_NUM) || (pAdapter->host[channel] == NULL))
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_FATAL_ERROR, "Adding command @ %p to "
+                 " invalid channel (%d)\n",scsi_cmnd, channel);
+    }
+    if (pAdapter->host[channel]->scsi_cmnd_done_head == NULL)
+    {
+        /* First command to the queue */
+        pAdapter->host[channel]->scsi_cmnd_done_head = scsi_cmnd;
+        pAdapter->host[channel]->scsi_cmnd_done_tail = scsi_cmnd;
+    }
+    else
+    {
+        /* We already have commands in the queue ; put this command in the tail */
+        ((struct mv_comp_info *)(&pAdapter->host[channel]->scsi_cmnd_done_tail->SCp))->next_done = scsi_cmnd;
+        pAdapter->host[channel]->scsi_cmnd_done_tail = scsi_cmnd;
+    }
+}
+
+/*******************************************************************************
+ *  Name:   mv_ial_lib_get_first_cmnd
+ *
+ *  Description:    Gets first scsi_cmnd from a chain of scsi commands to be
+ *                  completed, then sets NULL to head and tail.
+ *                  Caller must take care of adapter_lock locking.
+ *
+ *  Parameters:     pAdapter - Adapter data structure
+ *
+ *  Return Value:   Pointer to first scsi command in chain
+ ******************************************************************************/
+struct scsi_cmnd * mv_ial_lib_get_first_cmnd (struct IALAdapter *pAdapter, MV_U8 channel)
+{
+    if (pAdapter->host[channel] != NULL)
+    {
+        struct scsi_cmnd *cmnd = pAdapter->host[channel]->scsi_cmnd_done_head;
+        pAdapter->host[channel]->scsi_cmnd_done_head = NULL;
+        pAdapter->host[channel]->scsi_cmnd_done_tail = NULL;
+        return cmnd;
+    }
+    return NULL;
+}
+
+/*******************************************************************************
+ *  Name:   mv_ial_lib_do_done
+ *
+ *  Description:    Calls scsi_done of chain of scsi commands.
+ *                  Note that adapter_lock can be locked or unlocked, but
+ *                  caller must take care that io_request_lock is locked.
+ *
+ *  Parameters:     cmnd - First command in scsi commands chain
+ *
+ ******************************************************************************/
+void mv_ial_lib_do_done (struct scsi_cmnd *cmnd)
+{
+    /* Call done function for all commands in queue */
+    while (cmnd)
+    {
+        struct scsi_cmnd *temp;
+        temp = ((struct mv_comp_info *)(&cmnd->SCp))->next_done;
+
+        if (cmnd->scsi_done == NULL)
+        {
+            return;
+        }
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Calling done to command @ %p "
+                 "scsi_done = %p\n",cmnd, cmnd->scsi_done);
+        cmnd->scsi_done(cmnd);
+        cmnd = temp;
+    }
+}
+
+
+/*******************************************************************************
+ *  Name:   mv_ial_lib_free_channel
+ *
+ *  Description:    free allocated queues for the given channel
+ *
+ *  Parameters:     pMvSataAdapter - pointer to the adapter controler this
+ *                  channel connected to.
+ *          channelNum - channel number.
+ *
+ ******************************************************************************/
+void mv_ial_lib_free_channel(IAL_ADAPTER_T *pAdapter, MV_U8 channelNum)
+{
+    MV_SATA_CHANNEL *pMvSataChannel;
+
+    if (channelNum >= pAdapter->mvSataAdapter.numberOfChannels)
+    {
+        mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG_ERROR, "[%d]: Bad channelNum=%d\n",
+                 pAdapter->mvSataAdapter.adapterId, channelNum);
+        return;
+    }
+
+    pMvSataChannel = pAdapter->mvSataAdapter.sataChannel[channelNum];
+    kfree(pMvSataChannel);
+    pAdapter->mvSataAdapter.sataChannel[channelNum] = NULL;
+    return;
+}
+/****************************************************************
+ *  Name:   mv_ial_lib_init_channel
+ *
+ *  Description:    allocate request and response queues for the EDMA of the
+ *                  given channel and sets other fields.
+ *
+ *  Parameters:
+ *      pAdapter - pointer to the emulated adapter data structure
+ *      channelNum - channel number.
+ *  Return: 0 on success, otherwise on failure
+ ****************************************************************/
+int mv_ial_lib_init_channel(IAL_ADAPTER_T *pAdapter, MV_U8 channelNum)
+{
+    MV_SATA_CHANNEL *pMvSataChannel;
+    dma_addr_t    req_dma_addr;
+    dma_addr_t    rsp_dma_addr;
+
+    if (channelNum >= pAdapter->mvSataAdapter.numberOfChannels)
+    {
+        mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG_ERROR, "[%d]: Bad channelNum=%d",
+                 pAdapter->mvSataAdapter.adapterId, channelNum);
+        return -1;
+    }
+
+    pMvSataChannel = (MV_SATA_CHANNEL *)kmalloc(sizeof(MV_SATA_CHANNEL),
+                                                GFP_ATOMIC);
+    if (pMvSataChannel == NULL)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: out of memory\n",
+                 pAdapter->mvSataAdapter.adapterId);
+        return -1;
+    }
+    pAdapter->mvSataAdapter.sataChannel[channelNum] = pMvSataChannel;
+    pMvSataChannel->channelNumber = channelNum;
+
+    pMvSataChannel->requestQueue = (struct mvDmaRequestQueueEntry *)
+                                   (pAdapter->requestsArrayBaseAlignedAddr +
+                                    (channelNum * pAdapter->requestQueueSize));
+    req_dma_addr = pAdapter->requestsArrayBaseDmaAlignedAddr +
+                   (channelNum * pAdapter->requestQueueSize);
+
+/* check the 1K alignment of the request queue*/
+    if (((u64)req_dma_addr) & 0x3ffULL)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: request queue allocated isn't 1 K aligned,"
+                 " dma_addr=%x.%x channel=%d\n", pAdapter->mvSataAdapter.adapterId,
+                 (unsigned int)pci64_dma_hi32(req_dma_addr),
+                 (unsigned int)pci64_dma_lo32(req_dma_addr),
+                 channelNum);
+        return -1;
+    }
+    pMvSataChannel->requestQueuePciLowAddress = pci64_dma_lo32(req_dma_addr);
+    pMvSataChannel->requestQueuePciHiAddress = pci64_dma_hi32(req_dma_addr);
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "[%d,%d]: request queue allocated: 0x%p\n",
+             pAdapter->mvSataAdapter.adapterId, channelNum,
+             pMvSataChannel->requestQueue);
+    pMvSataChannel->responseQueue = (struct mvDmaResponseQueueEntry *)
+                                    (pAdapter->responsesArrayBaseAlignedAddr +
+                                     (channelNum * pAdapter->responseQueueSize));
+    rsp_dma_addr = pAdapter->responsesArrayBaseDmaAlignedAddr +
+                   (channelNum * pAdapter->responseQueueSize);
+
+/* check the 256 alignment of the response queue*/
+    if (((u64)rsp_dma_addr) & 0xff)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d,%d]: response queue allocated isn't 256 byte "
+                 "aligned, dma_addr=%x.%x\n",
+                 pAdapter->mvSataAdapter.adapterId, (unsigned int)pci64_dma_hi32(rsp_dma_addr),
+                 (unsigned int)pci64_dma_lo32(rsp_dma_addr), channelNum);
+        return -1;
+    }
+    pMvSataChannel->responseQueuePciLowAddress = pci64_dma_lo32(rsp_dma_addr);
+    pMvSataChannel->responseQueuePciHiAddress = pci64_dma_hi32(rsp_dma_addr);
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "[%d,%d]: response queue allocated: 0x%p\n",
+             pAdapter->mvSataAdapter.adapterId, channelNum,
+             pMvSataChannel->responseQueue);
+    return 0;
+}
+
+/****************************************************************
+ *  Name:   mv_ial_lib_int_handler
+ *
+ *  Description:    Interrupt handler.
+ *
+ *  Parameters:     irq - Hardware IRQ number.assume that different cards will have
+ *                  different IRQ's TBD
+ *                  dev_id  - points to the mvxxxxxxDeviceStruct that generated
+ *                    the interrupt
+ *                  regs    -
+ *
+ *
+ ****************************************************************/
+irqreturn_t mv_ial_lib_int_handler (int irq, void *dev_id )
+{
+    IAL_ADAPTER_T       *pAdapter;
+    unsigned long       flags;
+    int                 handled = 0;
+    struct scsi_cmnd *cmnds_done_list = NULL;
+    pAdapter = (IAL_ADAPTER_T *)dev_id;
+
+/*
+ * Acquire the adapter spinlock. Meantime all completed commands will be added
+ * to done queue.
+ */
+    spin_lock_irqsave(&pAdapter->adapter_lock, flags);
+
+    if (mvSataInterruptServiceRoutine(&pAdapter->mvSataAdapter) == MV_TRUE)
+    {
+        handled = 1;
+        pAdapter->procNumOfInterrupts ++;
+        mvSataScsiPostIntService(pAdapter->ataScsiAdapterExt);
+    }
+    /* Unlock adapter lock */
+    spin_unlock_irqrestore(&pAdapter->adapter_lock, flags);
+    /* Check if there are commands in the done queue to be completed */
+    if (handled == 1)
+    {
+        MV_U8 i;
+
+        for (i = 0; i < pAdapter->maxHosts; i++)
+        {
+            spin_lock_irqsave(&pAdapter->adapter_lock, flags);
+            cmnds_done_list = mv_ial_lib_get_first_cmnd(pAdapter, i);
+            spin_unlock_irqrestore(&pAdapter->adapter_lock, flags);
+            if (cmnds_done_list)
+            {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+                spin_lock_irqsave(&io_request_lock, flags);
+#else
+                spin_lock_irqsave(pAdapter->host[i]->scsihost->host_lock, flags);
+#endif
+                mv_ial_lib_do_done(cmnds_done_list);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+                spin_unlock_irqrestore(&io_request_lock, flags);
+#else
+                spin_unlock_irqrestore(pAdapter->host[i]->scsihost->host_lock, flags);
+#endif
+            }
+        }
+    }
+    return IRQ_RETVAL(handled);
+}
+
+/****************************************************************
+ *  Name: mv_ial_lib_add_buffer_to_prd_table
+ *
+ *  Description:    insert one buffer into number of entries in the PRD table,
+ *                  keeping 64KB boundaries
+ *
+ *  Parameters:     pPRD_table: pointer to the PRD table.
+ *          table_size: number of entries in the PRD table.
+ *          count: index of the next entry to add, should be updated by this
+ *          function
+ *          buf_addr,buf_len: the dma address and the size of the buffer to add.
+ *          isEOT: 1 if this is the last entry
+ *  Returns:        0 on success, otherwise onfailure.
+ *
+ ****************************************************************/
+
+static int mv_ial_lib_add_buffer_to_prd_table(MV_SATA_ADAPTER   *pMvSataAdapter,
+                                              MV_SATA_EDMA_PRD_ENTRY *pPRD_table,
+                                              int table_size, int *count,
+                                              dma_addr_t buf_addr,
+                                              unsigned int buf_len,
+                                              int isEOT)
+{
+    unsigned int    entry = *count;
+    u64             xcount = 0;
+
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG,"insert to PRD table, count=%d, buf_addr=%x, buf_len=%x\n",
+             *count,(unsigned int) buf_addr, buf_len);
+
+
+
+    /*
+    The buffer is splitted in case then either the buffer size exceeds 64 KB
+    or 2 high address bits of all data in the buffer are not identical
+    */
+    while (buf_len)
+    {
+        if (entry >= table_size)
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR,"PRD table too small (entry %d, table_size %d\n",
+                     entry, table_size);
+            mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG_ERROR,"[%d] insert to PRD table, count=%d,"
+                     " buf_addr=%x, buf_len=%x\n",
+                     pMvSataAdapter->adapterId,
+                     *count,(unsigned int) buf_addr, buf_len);
+            return -1;
+        }
+        else
+        {
+            u64 bcount = buf_len;
+            /*buffer size exceeds 64K*/
+            if (bcount > 0x10000)
+                bcount = 0x10000;
+            if (buf_addr & 0x1)
+            {
+                mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, " PRD entry low address is not 1 bit aligned\n");
+                return -1;
+            }
+#if (BITS_PER_LONG > 32) || defined(CONFIG_HIGHMEM64G)
+            /*Split the buffer if 2 high address bits of all
+            data in the buffer are not the same*/
+            if ((buf_addr | 0xFFFFFFFF)  !=
+                ((buf_addr + bcount - 1) | 0xFFFFFFFF))
+            {
+                bcount = 0x100000000ULL - (buf_addr & 0xFFFFFFFF);
+            }
+#endif
+	    if(((buf_addr & MRVL_SATA_BOUNDARY_MASK) + bcount) > 
+	       MRVL_SATA_BUFF_BOUNDARY)
+	    {
+		 bcount = MRVL_SATA_BUFF_BOUNDARY -
+		      (buf_addr & MRVL_SATA_BOUNDARY_MASK);
+	    }
+            /*In case then buffer size is 64K
+            PRD entry byte count is set to zero*/
+            xcount = bcount & 0xffff;
+            pPRD_table[entry].lowBaseAddr =
+            cpu_to_le32(pci64_dma_lo32(buf_addr));
+            pPRD_table[entry].highBaseAddr =
+            cpu_to_le32(pci64_dma_hi32(buf_addr));
+            pPRD_table[entry].byteCount = cpu_to_le16(xcount);
+            pPRD_table[entry].reserved = 0;
+            /* enable snoop on data buffers */
+            pPRD_table[entry].flags = 0;/*cpu_to_le16(MV_EDMA_PRD_NO_SNOOP_FLAG);*/
+            if (xcount & 0x1)
+            {
+                mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR," PRD entry byte count is not 1 bit aligned\n");
+                return -1;
+            }
+            buf_addr += bcount;
+            buf_len -= bcount;
+            entry++;
+        }
+    }
+
+    if (entry)
+    {
+        if (isEOT)/* enable snoop on data buffers */
+            pPRD_table[entry-1].flags = cpu_to_le16(MV_EDMA_PRD_EOT_FLAG /*|
+                                                    MV_EDMA_PRD_NO_SNOOP_FLAG*/);
+
+        *count = entry;
+        return 0;
+    }
+
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "insert zero entries to PRD table \n");
+    return -1;
+}
+
+/* map to pci */
+int mv_ial_lib_generate_prd(MV_SATA_ADAPTER *pMvSataAdapter, struct scsi_cmnd *SCpnt,
+                            struct mv_comp_info *completion_info)
+{
+    IAL_ADAPTER_T   *pAdapter = MV_IAL_ADAPTER(SCpnt->device->host);
+    IAL_HOST_T      *pHost = HOSTDATA(SCpnt->device->host);
+    MV_SATA_EDMA_PRD_ENTRY *pPRD_table = NULL;
+    dma_addr_t PRD_dma_address = 0;
+    dma_addr_t busaddr = 0;
+    unsigned int prd_size = 0;
+    struct scatterlist *sg;
+    unsigned int prd_count;
+    MV_SATA_DEVICE_TYPE deviceType = pAdapter->ataScsiAdapterExt->ataDriveData[pHost->channelIndex][SCpnt->device->id].identifyInfo.deviceType;
+    /*should be removed*/
+#ifndef   MV_SUPPORT_1MBYTE_IOS 
+    if (scsi_bufflen(SCpnt) > (SCpnt->device->host->max_sectors << 9))
+    {
+        printk("ERROR: request length exceeds the maximum alowed value, %x %x\n",
+               pMvSataAdapter->pciConfigDeviceId,
+               pMvSataAdapter->pciConfigRevisionId);
+    }
+#endif
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,23)
+    if (SCpnt->use_sg)
+    {
+        unsigned int sg_count;
+        unsigned int i;
+        sg = (struct scatterlist *) SCpnt->request_buffer;
+
+        sg_count = pci64_map_sg(pAdapter->pcidev, sg,
+                                SCpnt->use_sg,
+                                scsi_to_pci_dma_dir(SCpnt->sc_data_direction));
+
+        if (sg_count != SCpnt->use_sg)
+            printk("WARNING sg_count(%d) != SCpnt->use_sg(%d)\n",
+                   (unsigned int)sg_count, SCpnt->use_sg);
+#else
+	{
+        unsigned int sg_count;
+        unsigned int i;
+
+	sg = scsi_sglist(SCpnt);
+	sg_count = scsi_dma_map(SCpnt);
+	if (sg_count < 0) {
+		dev_err(&pAdapter->pcidev->dev, "pci_map_sg failed!\n");
+		return -1;
+	}
+
+#endif
+        if ((sg_count == 1) && (pAdapter->mvSataAdapter.sataAdapterGeneration >=
+                                MV_SATA_GEN_IIE) && (sg_dma_len(sg) <= 0x10000) && 
+            (deviceType != MV_SATA_DEVICE_TYPE_ATAPI_DEVICE))
+        {
+            completion_info->pSALBlock->singleDataRegion = MV_TRUE;
+            completion_info->cpu_PRDpnt = NULL;
+            completion_info->dma_PRDpnt = 0;
+            completion_info->allocated_entries = 0;
+            completion_info->single_buff_busaddr = 0;
+            PRD_dma_address = sg_dma_address(sg);
+            completion_info->pSALBlock->PRDTableLowPhyAddress = pci64_dma_lo32(PRD_dma_address);
+            completion_info->pSALBlock->PRDTableHighPhyAddress = pci64_dma_hi32(PRD_dma_address);
+            completion_info->pSALBlock->byteCount = sg_dma_len(sg);
+            mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG, "Use single data region"
+                     " buffer, size=%d\n",
+                     completion_info->pSALBlock->byteCount);
+
+            return 0;
+        }
+        prd_size = MV_PRD_TABLE_SIZE;
+        pPRD_table = (MV_SATA_EDMA_PRD_ENTRY*)mv_ial_lib_prd_allocate(pHost);
+        if (pPRD_table == NULL)
+        {
+            mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG_ERROR, "Failed to allocate PRD table, requested size=%d\n"
+                     , prd_size);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,23)
+            pci64_unmap_sg(pAdapter->pcidev, sg, SCpnt->use_sg,
+                           scsi_to_pci_dma_dir(SCpnt->sc_data_direction));
+#else
+	    scsi_dma_unmap(SCpnt);
+#endif
+            return -1;
+        }
+        prd_count=0;
+        for (i=0; (i < sg_count) && (sg_dma_len(sg)); i++, sg++)
+        {
+            int isEOT;
+
+            isEOT =((i+1 < sg_count) && (sg_dma_len(&sg[1]))) ? 0 : 1;
+
+            if (mv_ial_lib_add_buffer_to_prd_table(pMvSataAdapter,
+                                                   pPRD_table,
+                                                   prd_size,
+                                                   &prd_count,
+                                                   sg_dma_address(sg),
+                                                   sg_dma_len(sg),
+                                                   isEOT))
+            {
+                mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG_ERROR," in building PRD table from scatterlist, "
+                         "prd_size=%d, prd_count=%d\n", prd_size,
+                         prd_count);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,23)
+                pci64_unmap_sg(pAdapter->pcidev,
+                               (struct scatterlist *)SCpnt->request_buffer,
+                               SCpnt->use_sg,
+                               scsi_to_pci_dma_dir(SCpnt->sc_data_direction));
+#else
+		scsi_dma_unmap(SCpnt);
+#endif
+
+                return -1;
+            }
+        }
+        PRD_dma_address = pci64_map_page(pAdapter->pcidev,
+                                         pPRD_table,
+                                         MV_EDMA_PRD_ENTRY_SIZE * (prd_size),
+                                         PCI_DMA_TODEVICE);
+    }
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,23)
+    else if (scsi_bufflen(SCpnt) && SCpnt->sc_data_direction != PCI_DMA_NONE)
+    {
+        if ((pAdapter->mvSataAdapter.sataAdapterGeneration >= MV_SATA_GEN_IIE)
+            && (scsi_bufflen(SCpnt) <= 0x10000) && 
+            (deviceType != MV_SATA_DEVICE_TYPE_ATAPI_DEVICE))
+        {
+            completion_info->pSALBlock->singleDataRegion = MV_TRUE;
+            completion_info->cpu_PRDpnt = NULL;
+            completion_info->dma_PRDpnt = 0;
+            completion_info->allocated_entries = 0;
+            busaddr = pci64_map_page(pAdapter->pcidev, SCpnt->request_buffer,
+                                     scsi_bufflen(SCpnt),
+                                     scsi_to_pci_dma_dir(SCpnt->sc_data_direction));
+            completion_info->single_buff_busaddr = busaddr;
+            completion_info->pSALBlock->PRDTableLowPhyAddress = pci64_dma_lo32(busaddr);
+            completion_info->pSALBlock->PRDTableHighPhyAddress = pci64_dma_hi32(busaddr);
+            completion_info->pSALBlock->byteCount = scsi_bufflen(SCpnt);
+            mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG, "Use single data region"
+                     " buffer, size=%d\n",
+                     completion_info->pSALBlock->byteCount);
+            return 0;
+        }
+        prd_size = MV_PRD_TABLE_SIZE;
+        pPRD_table = (MV_SATA_EDMA_PRD_ENTRY*)mv_ial_lib_prd_allocate(pHost);
+        if (pPRD_table == NULL)
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "Failed to allocate PRD table, requested size=%d\n",
+                     prd_size);
+            return -1;
+        }
+
+        busaddr = pci64_map_page(pAdapter->pcidev, SCpnt->request_buffer,
+                                 scsi_bufflen(SCpnt),
+                                 scsi_to_pci_dma_dir(SCpnt->sc_data_direction));
+        prd_count = 0;
+        if (mv_ial_lib_add_buffer_to_prd_table(pMvSataAdapter,
+                                               pPRD_table,
+                                               prd_size,
+                                               &prd_count, busaddr,
+                                               scsi_bufflen(SCpnt), 1))
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, " in building PRD table from buffer\n");
+            pci64_unmap_page(pAdapter->pcidev, busaddr, scsi_bufflen(SCpnt),
+                             scsi_to_pci_dma_dir(SCpnt->sc_data_direction));
+            return -1;
+        }
+        PRD_dma_address = pci64_map_page(pAdapter->pcidev,
+                                         pPRD_table,
+                                         MV_EDMA_PRD_ENTRY_SIZE* (prd_size),
+                                         PCI_DMA_TODEVICE);
+    }
+#endif
+    completion_info->cpu_PRDpnt = pPRD_table;
+    completion_info->dma_PRDpnt = PRD_dma_address;
+    completion_info->allocated_entries = prd_size;
+    completion_info->single_buff_busaddr = busaddr;
+    completion_info->pSALBlock->PRDTableLowPhyAddress = pci64_dma_lo32(PRD_dma_address);
+    completion_info->pSALBlock->PRDTableHighPhyAddress = pci64_dma_hi32(PRD_dma_address);
+    mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG, "PRD table allocated %p\n", pPRD_table);
+    mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG, "PRD table allocated (dma) %x \n", PRD_dma_address);
+    return 0;
+}
+
+
+/****************************************************************
+ *  Name: mv_ial_block_requests
+ *
+ *  Description:    Blocks request from SCSI mid layer while channel
+ *                  initialization is in progress
+ *
+ *  Parameters:     pAdapter, pointer to the IAL adapter data structure.
+ *                  channelIndex, channel number
+ *
+ *  Returns:        None.
+ *
+ ****************************************************************/
+
+void mv_ial_block_requests(struct IALAdapter *pAdapter, MV_U8 channelIndex)
+{
+    if (MV_TRUE == pAdapter->host[channelIndex]->hostBlocked)
+    {
+        return;
+    }
+
+    if ((pAdapter->ialCommonExt.channelState[channelIndex] != CHANNEL_READY) &&
+        (pAdapter->ialCommonExt.channelState[channelIndex] != CHANNEL_NOT_CONNECTED))
+    {
+        pAdapter->host[channelIndex]->hostBlocked = MV_TRUE;
+        mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG, "[%d,%d]: blocking SCSI host.\n",
+                 pAdapter->mvSataAdapter.adapterId, channelIndex);
+        scsi_block_requests(pAdapter->host[channelIndex]->scsihost);
+    }
+    else
+    {
+        pAdapter->host[channelIndex]->hostBlocked = MV_FALSE;
+    }
+}
+
+/****************************************************************
+ *  Name: mv_ial_unblock_requests
+ *
+ *  Description:    Unblocks request from SCSI mid layer for non connected
+ *                  channels or channels whose initialization is finished
+ *
+ *  Parameters:     pAdapter -  pointer to the IAL adapter data structure.
+ *                  channelIndex -  channel number
+ *
+ *  Returns:        None.
+ *
+ ****************************************************************/
+static void mv_ial_unblock_requests(struct IALAdapter *pAdapter, MV_U8 channelIndex)
+{
+    if ((CHANNEL_NOT_CONNECTED == pAdapter->ialCommonExt.channelState[channelIndex]) ||
+        (CHANNEL_READY == pAdapter->ialCommonExt.channelState[channelIndex]))
+    {
+        pAdapter->host[channelIndex]->hostBlocked = MV_FALSE;
+        mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG, "[%d,%d]: unblocking SCSI host.\n",
+                 pAdapter->mvSataAdapter.adapterId, channelIndex);
+        scsi_unblock_requests(pAdapter->host[channelIndex]->scsihost);
+    }
+}
+
+
+
+
+/****************************************************************
+ *  Name: mv_ial_lib_event_notify
+ *
+ *  Description:    this function called by the low  level to notify a certain event
+ *
+ *  Parameters:     pMvSataAdapter, pointer to the Device data structure.
+ *
+ *  Returns:        MV_TRUE on success, MV_FALSE on failure.
+ *
+ ****************************************************************/
+MV_BOOLEAN mv_ial_lib_event_notify(MV_SATA_ADAPTER *pMvSataAdapter, MV_EVENT_TYPE eventType,
+                                   MV_U32 param1, MV_U32 param2)
+{
+    IAL_ADAPTER_T   *pAdapter = pMvSataAdapter->IALData;
+    MV_U8   channel = param2;
+
+    switch (eventType)
+    {
+    case MV_EVENT_TYPE_SATA_CABLE:
+        {
+
+
+            if (param1 == MV_SATA_CABLE_EVENT_CONNECT)
+            {
+
+                mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG, "[%d,%d]: device connected event received\n",
+                         pMvSataAdapter->adapterId, channel);
+                mvRestartChannel(&pAdapter->ialCommonExt, channel,
+                                 pAdapter->ataScsiAdapterExt, MV_FALSE);
+                mv_ial_block_requests(pAdapter, channel);
+            }
+            else if (param1 == MV_SATA_CABLE_EVENT_DISCONNECT)
+            {
+                mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG, "[%d,%d]: device disconnected event received \n",
+                         pMvSataAdapter->adapterId, channel);
+                if (mvSataIsStorageDeviceConnected(pMvSataAdapter, channel, NULL) ==
+                    MV_FALSE)
+                {
+                    mvStopChannel(&pAdapter->ialCommonExt, channel,
+                                  pAdapter->ataScsiAdapterExt);
+                }
+                else
+                {
+                    mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG, "[%d,%d]: device disconnected event ignored.\n",
+                             pMvSataAdapter->adapterId, channel);
+                }
+
+            }
+            else if (param1 == MV_SATA_CABLE_EVENT_PM_HOT_PLUG)
+            {
+                mvPMHotPlugDetected(&pAdapter->ialCommonExt, channel,
+                                    pAdapter->ataScsiAdapterExt);
+                mv_ial_block_requests(pAdapter, channel);
+            }
+            else
+            {
+
+                mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "illegal value for param1(%d) at "
+                         "connect/disconect event, host=%d\n", param1,
+                         pMvSataAdapter->adapterId );
+            }
+        }
+        break;
+    case MV_EVENT_TYPE_ADAPTER_ERROR:
+        mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG_ERROR, "DEVICE error event received, pci cause "
+                 "reg=%x, don't know how to handle this\n", param1);
+        return MV_TRUE;
+    case MV_EVENT_TYPE_SATA_ERROR:
+        switch (param1)
+        {
+        case MV_SATA_RECOVERABLE_COMMUNICATION_ERROR:
+            mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG_ERROR,
+                     " [%d %d] sata recoverable error occured\n",
+                     pMvSataAdapter->adapterId, channel);
+            break;
+        case MV_SATA_UNRECOVERABLE_COMMUNICATION_ERROR:
+            mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG_ERROR,
+                     " [%d %d] sata unrecoverable error occured, restart channel\n",
+                     pMvSataAdapter->adapterId, channel);
+            mvSataChannelHardReset(pMvSataAdapter, channel);
+            mvRestartChannel(&pAdapter->ialCommonExt, channel,
+                             pAdapter->ataScsiAdapterExt, MV_TRUE);
+            mv_ial_block_requests(pAdapter, channel);
+            break;
+        case MV_SATA_DEVICE_ERROR:
+            mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG_ERROR,
+                     " [%d %d] device error occured\n",
+                     pMvSataAdapter->adapterId, channel);
+            break;
+        }
+        break;
+    default:
+        mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG_ERROR,  " adapter %d unknown event %d"
+                 " param1= %x param2 = %x\n", pMvSataAdapter->adapterId,
+                 eventType - MV_EVENT_TYPE_ADAPTER_ERROR, param1, param2);
+        return MV_FALSE;
+
+    }/*switch*/
+    return MV_TRUE;
+}
+
+MV_BOOLEAN IALConfigQueuingMode(MV_SATA_ADAPTER *pSataAdapter,
+                                MV_U8 channelIndex,
+                                MV_EDMA_MODE mode,
+                                MV_SATA_SWITCHING_MODE switchingMode,
+                                MV_BOOLEAN  use128Entries)
+
+{
+    IAL_ADAPTER_T   *pAdapter = pSataAdapter->IALData;
+    pAdapter->host[channelIndex]->mode = mode;
+    pAdapter->host[channelIndex]->switchingMode = switchingMode;
+    pAdapter->host[channelIndex]->use128Entries = use128Entries;
+
+    if (mvSataConfigEdmaMode(pSataAdapter, channelIndex,
+                             mode, 31) == MV_FALSE)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d %d]: mvSataConfigEdmaMode failed\n",
+                 pSataAdapter->adapterId, channelIndex);
+        return -1;
+    }
+    return MV_TRUE;
+}
+
+MV_BOOLEAN IALInitChannel(MV_SATA_ADAPTER *pSataAdapter, MV_U8 channelIndex)
+{
+    if (mv_ial_lib_init_channel(pSataAdapter->IALData, channelIndex) == 0)
+    {
+        return MV_TRUE;
+    }
+    return MV_FALSE;
+}
+void IALReleaseChannel(MV_SATA_ADAPTER *pSataAdapter, MV_U8 channelIndex)
+{
+    mv_ial_lib_free_channel(pSataAdapter->IALData, channelIndex);
+}
+
+void IALChannelCommandsQueueFlushed(MV_SATA_ADAPTER *pSataAdapter, MV_U8 channelIndex)
+{
+
+}
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+
+static void channel_rescan(struct work_struct *work)
+{
+    struct rescan_wrapper* rescan = container_of(work, struct rescan_wrapper, work);
+    struct Scsi_Host *host;
+    struct scsi_device *sdev = NULL;
+    MV_U16 target;
+    if (rescan->pAdapter->host[rescan->channelIndex] == NULL)
+    {
+        kfree(rescan);
+        return;
+    }
+    host = rescan->pAdapter->host[rescan->channelIndex]->scsihost;
+    down(&rescan->pAdapter->rescan_mutex);
+    if (atomic_read(&rescan->pAdapter->stopped) > 0)
+    {
+        up(&rescan->pAdapter->rescan_mutex);
+        kfree(rescan);
+        return;
+    }
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "[%d %d] channel_rescan(): "
+             "targets to add 0x%X, targets to remove 0x%X\n",
+             rescan->pAdapter->mvSataAdapter.adapterId,
+             rescan->channelIndex,
+             rescan->targetsToAdd,
+             rescan->targetsToRemove);
+
+    for (target = 0; (rescan->targetsToRemove != 0) && (target < host->max_id); target++)
+    {
+        if (rescan->targetsToRemove & (1 << target))
+        {
+            sdev = scsi_device_lookup(host, 0, target, 0);
+            if (sdev != NULL)
+            {
+		    /*scsi_device_cancel(sdev, 0);*/
+                scsi_remove_device(sdev);
+                scsi_device_put(sdev);
+            }
+	    else
+	    {
+		    mvLogMsg(MV_IAL_LOG_ID,
+                         MV_DEBUG_ERROR,
+                         "[%d %d %d] failed to deattach scsi device\n",
+                         rescan->pAdapter->mvSataAdapter.adapterId,
+                         rescan->channelIndex,
+                         target);
+	    }
+        }
+    }
+    sdev = NULL;
+    for (target = 0; (rescan->targetsToAdd != 0) && (target < host->max_id); target++)
+    {
+        if (rescan->targetsToAdd & (1 << target))
+        {
+            int error = scsi_add_device(host, 0, target, 0);
+            if (error)
+            {
+                mvLogMsg(MV_IAL_LOG_ID,
+                         MV_DEBUG_ERROR,
+                         "[%d %d %d] Error adding scsi device\n",
+                         rescan->pAdapter->mvSataAdapter.adapterId,
+                         rescan->channelIndex,
+                         target);
+            }
+        }
+    }
+    up(&rescan->pAdapter->rescan_mutex);
+    kfree(rescan);
+}
+#endif
+
+MV_BOOLEAN IALBusChangeNotify(MV_SATA_ADAPTER *pSataAdapter,
+                              MV_U8 channelIndex)
+{
+    return MV_TRUE;
+}
+
+MV_BOOLEAN IALBusChangeNotifyEx(MV_SATA_ADAPTER *pSataAdapter,
+                                MV_U8 channelIndex,
+                                MV_U16 targetsToRemove,
+                                MV_U16 targetsToAdd)
+{
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+    IAL_ADAPTER_T   *pAdapter = pSataAdapter->IALData;
+    if (0 == atomic_read(&pAdapter->stopped))
+    {
+        struct rescan_wrapper* rescan =
+        kmalloc(sizeof(struct rescan_wrapper), GFP_ATOMIC);
+        if (rescan != NULL)
+        {
+            INIT_WORK(&rescan->work, channel_rescan);
+            rescan->pAdapter = pAdapter;
+            rescan->channelIndex = channelIndex;
+            rescan->targetsToRemove = targetsToRemove;
+            rescan->targetsToAdd = targetsToAdd;
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR,
+                     "[%d %d] Rescan bus: remove 0x%X, add 0x%X.\n",
+                     pSataAdapter->adapterId,
+                     channelIndex, targetsToRemove, targetsToAdd);
+            if (schedule_work(&rescan->work) == 0)
+            {
+                mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR,
+                         "[%d %d] Rescan bus: schedule_work() failed.\n",
+                         pSataAdapter->adapterId,
+                         channelIndex);
+                kfree(rescan);
+            }
+        }
+        else
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR,
+                     "[%d %d] Rescan bus: memory allocation error.\n",
+                     pSataAdapter->adapterId,
+                     channelIndex);
+        }
+    }
+#endif
+    return MV_TRUE;
+}
+
+
+void asyncStartTimerFunction(unsigned long data)
+{
+    IAL_ADAPTER_T   *pAdapter = (IAL_ADAPTER_T *)data;
+    unsigned long       flags;
+    struct scsi_cmnd *cmnds_done_list = NULL;
+    MV_U8 i;
+
+    spin_lock_irqsave(&pAdapter->adapter_lock, flags);
+    if (pAdapter->stopAsyncTimer == MV_FALSE)
+    {
+        mvIALTimerCallback(&pAdapter->ialCommonExt,
+                           pAdapter->ataScsiAdapterExt);
+        for (i = 0; i < pAdapter->maxHosts; i++)
+        {
+            if (MV_TRUE == pAdapter->host[i]->hostBlocked)
+            {
+                spin_unlock_irqrestore(&pAdapter->adapter_lock, flags);
+                mv_ial_unblock_requests(pAdapter, i);
+                spin_lock_irqsave(&pAdapter->adapter_lock, flags);
+            }
+        }
+        pAdapter->asyncStartTimer.expires = jiffies + MV_LINUX_ASYNC_TIMER_PERIOD;
+        add_timer (&pAdapter->asyncStartTimer);
+    }
+    else
+    {
+        mvLogMsg(MV_IAL_LOG_ID,  MV_DEBUG,   "[%d]: Async timer stopped\n",
+                 pAdapter->mvSataAdapter.adapterId);
+    }
+    spin_unlock_irqrestore(&pAdapter->adapter_lock, flags);
+    /* Check if there are commands in the done queue to be completed */
+    for (i = 0; i < pAdapter->maxHosts; i++)
+    {
+        spin_lock_irqsave(&pAdapter->adapter_lock, flags);
+        cmnds_done_list = mv_ial_lib_get_first_cmnd(pAdapter, i);
+        spin_unlock_irqrestore(&pAdapter->adapter_lock, flags);
+        if (cmnds_done_list)
+        {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+            spin_lock_irqsave(&io_request_lock, flags);
+#else
+            spin_lock_irqsave(pAdapter->host[i]->scsihost->host_lock, flags);
+#endif
+            mv_ial_lib_do_done(cmnds_done_list);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+            spin_unlock_irqrestore(&io_request_lock, flags);
+#else
+            spin_unlock_irqrestore(pAdapter->host[i]->scsihost->host_lock, flags);
+#endif
+        }
+    }
+}
+
+/****************************************************************
+ *  Name: release_ata_mem
+ *
+ *  Description:   free memory allocated to the PRD table
+ *          unmap the data buffers of the scsi command
+ *          free completion_info data structure.
+ *  Parameters:     pInfo: pointer to the data structure returned by the
+ *          completion call back function to identify the origial command
+ *
+ ****************************************************************/
+void release_ata_mem(struct mv_comp_info * pInfo)
+{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,23)
+    IAL_ADAPTER_T   *pAdapter = MV_IAL_ADAPTER(pInfo->SCpnt->device->host);
+#endif
+    IAL_HOST_T      *pHost = HOSTDATA(pInfo->SCpnt->device->host);
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+    if(pInfo->kmap_buffer)
+    {
+	if( pInfo->SCpnt->sc_data_direction == DMA_FROM_DEVICE)
+	{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+
+		struct scatterlist *sg;
+		MV_U8*		pBuffer;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,23)
+        	sg = (struct scatterlist *) pInfo->SCpnt->request_buffer;
+#else
+		sg = scsi_sglist(pInfo->SCpnt);
+#endif
+		mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "SCpnt %p: copy data from temp"
+			 " buffer to command buffer, length %d \n", pInfo->SCpnt, sg->length);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,23)
+		pBuffer = kmap_atomic(sg->page, KM_IRQ0) + sg->offset;
+#else
+		pBuffer = kmap_atomic(sg_page(sg), KM_IRQ0) + sg->offset;
+#endif
+		memcpy(pBuffer, pInfo->pSALBlock->pDataBuffer , sg->length); 	
+	        kunmap_atomic(pBuffer - sg->offset, KM_IRQ0);
+
+#else
+		scsi_sg_copy_from_buffer(pInfo->SCpnt, pInfo->pSALBlock->pDataBuffer,
+					 scsi_bufflen(pInfo->SCpnt));
+
+#endif
+
+	}
+	mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "SCpnt %p: free temp data "
+		 "buffer\n", pInfo->SCpnt);
+	kfree(pInfo->pSALBlock->pDataBuffer);
+    }
+#endif
+    if (pInfo->cpu_PRDpnt)
+    {
+        mv_ial_lib_prd_free(pHost,
+                            pInfo->allocated_entries,
+                            pInfo->dma_PRDpnt,
+                            pInfo->cpu_PRDpnt);
+    }
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,23)
+    if( pInfo->cpu_PRDpnt || (pInfo->pSALBlock->singleDataRegion == MV_TRUE)) 
+    {
+        if (pInfo->SCpnt->use_sg)
+        {
+            pci64_unmap_sg(pAdapter->pcidev,
+                           (struct scatterlist *)pInfo->SCpnt->request_buffer,
+                           pInfo->SCpnt->use_sg,
+                           scsi_to_pci_dma_dir(pInfo->SCpnt->sc_data_direction));
+        }
+        else
+        {
+            pci64_unmap_page(pAdapter->pcidev,
+                             pInfo->single_buff_busaddr,
+                             scsi_bufflen(pInfo->SCpnt),
+                             scsi_to_pci_dma_dir(pInfo->SCpnt->sc_data_direction));
+        }
+    }
+#else
+	scsi_dma_unmap(pInfo->SCpnt);
+#endif
+    
+    pInfo->cpu_PRDpnt = NULL;
+    kfree(pInfo->pSALBlock);
+}
+
+int mv_ial_lib_allocate_edma_queues(IAL_ADAPTER_T *pAdapter)
+{
+    ulong *tmp;
+    ulong   requests_array_size;
+    ulong   responses_array_size;
+
+    if ((pAdapter->mvSataAdapter.sataAdapterGeneration >= MV_SATA_GEN_IIE) && 
+		(pAdapter->mvSataAdapter.pciConfigDeviceId != MV_SATA_DEVICE_ID_6082))
+    {
+        pAdapter->requestQueueSize = MV_EDMA_GEN2E_REQUEST_QUEUE_SIZE;
+        pAdapter->responseQueueSize = MV_EDMA_GEN2E_RESPONSE_QUEUE_SIZE;
+    }
+    else
+    {
+        pAdapter->requestQueueSize = MV_EDMA_REQUEST_QUEUE_SIZE;
+        pAdapter->responseQueueSize = MV_EDMA_RESPONSE_QUEUE_SIZE;
+    }
+    
+    requests_array_size = (pAdapter->maxHosts + 1) * (pAdapter->requestQueueSize);
+    responses_array_size =(pAdapter->maxHosts + 1) * (pAdapter->responseQueueSize);
+
+    pAdapter->requestsArrayBaseAddr =
+    pci_alloc_consistent(pAdapter->pcidev,
+                         requests_array_size,
+                         &(pAdapter->requestsArrayBaseDmaAddr));
+    if (pAdapter->requestsArrayBaseAddr == NULL)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: Failed to allocate memory for EDMA request"
+                 " queues\n", pAdapter->mvSataAdapter.adapterId);
+        return -1;
+    }
+    pAdapter->requestsArrayBaseAlignedAddr = pAdapter->requestsArrayBaseAddr +
+                                             pAdapter->requestQueueSize;
+    tmp = (ulong*)&pAdapter->requestsArrayBaseAlignedAddr;
+    *tmp &= ~((ulong)pAdapter->requestQueueSize - 1);
+
+    pAdapter->requestsArrayBaseDmaAlignedAddr =
+    pAdapter->requestsArrayBaseDmaAddr + pAdapter->requestQueueSize;
+    pAdapter->requestsArrayBaseDmaAlignedAddr &=
+    ~(pAdapter->requestQueueSize - 1);
+
+    if ((pAdapter->requestsArrayBaseDmaAlignedAddr - pAdapter->requestsArrayBaseDmaAddr) !=
+        (pAdapter->requestsArrayBaseAlignedAddr - pAdapter->requestsArrayBaseAddr))
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: Error in Request Queues Alignment\n",
+                 pAdapter->mvSataAdapter.adapterId
+                );
+        pci_free_consistent(pAdapter->pcidev, requests_array_size,
+                            pAdapter->requestsArrayBaseAddr,
+                            pAdapter->requestsArrayBaseDmaAddr);
+        return -1;
+    }
+/* response queues */
+    pAdapter->responsesArrayBaseAddr =
+    pci_alloc_consistent(pAdapter->pcidev,
+                         responses_array_size,
+                         &(pAdapter->responsesArrayBaseDmaAddr));
+    if (pAdapter->responsesArrayBaseAddr == NULL)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: Failed to allocate memory for EDMA response"
+                 " queues\n", pAdapter->mvSataAdapter.adapterId);
+        pci_free_consistent(pAdapter->pcidev, requests_array_size,
+                            pAdapter->requestsArrayBaseAddr,
+                            pAdapter->requestsArrayBaseDmaAddr);
+        return -1;
+    }
+    pAdapter->responsesArrayBaseAlignedAddr = pAdapter->responsesArrayBaseAddr
+                                              + pAdapter->responseQueueSize;
+    tmp = (ulong*)&pAdapter->responsesArrayBaseAlignedAddr;
+    *tmp &= ~((ulong)pAdapter->responseQueueSize - 1);
+
+    pAdapter->responsesArrayBaseDmaAlignedAddr =
+    pAdapter->responsesArrayBaseDmaAddr + pAdapter->responseQueueSize;
+    pAdapter->responsesArrayBaseDmaAlignedAddr &=
+    ~(pAdapter->responseQueueSize - 1);
+
+
+    if ((pAdapter->responsesArrayBaseDmaAlignedAddr - pAdapter->responsesArrayBaseDmaAddr) !=
+        (pAdapter->responsesArrayBaseAlignedAddr - pAdapter->responsesArrayBaseAddr))
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "[%d]: Error in Response Quueues Alignment\n",
+                 pAdapter->mvSataAdapter.adapterId);
+        pci_free_consistent(pAdapter->pcidev, responses_array_size,
+                            pAdapter->responsesArrayBaseAddr,
+                            pAdapter->responsesArrayBaseDmaAddr);
+        pci_free_consistent(pAdapter->pcidev, requests_array_size,
+                            pAdapter->requestsArrayBaseAddr,
+                            pAdapter->requestsArrayBaseDmaAddr);
+        return -1;
+    }
+    return 0;
+}
+
+void mv_ial_lib_free_edma_queues(IAL_ADAPTER_T *pAdapter)
+{
+    pci_free_consistent(pAdapter->pcidev,
+                        (pAdapter->maxHosts + 1) * (pAdapter->responseQueueSize),
+                        pAdapter->responsesArrayBaseAddr,
+                        pAdapter->responsesArrayBaseDmaAddr);
+    pci_free_consistent(pAdapter->pcidev,
+                        (pAdapter->maxHosts + 1) * (pAdapter->requestQueueSize),
+                        pAdapter->requestsArrayBaseAddr,
+                        pAdapter->requestsArrayBaseDmaAddr);
+}
+
+MV_BOOLEAN IALCompletion(struct mvSataAdapter *pSataAdapter,
+                         MV_SATA_SCSI_CMD_BLOCK *pCmdBlock)
+{
+    struct scsi_cmnd   *SCpnt = (struct scsi_cmnd *)pCmdBlock->IALData;
+    struct mv_comp_info *pInfo = ( struct mv_comp_info *) &(SCpnt->SCp);
+    MV_U8       host_status;
+
+
+     switch (pCmdBlock->ScsiCommandCompletion)
+    {
+    case MV_SCSI_COMPLETION_SUCCESS:
+        host_status = DID_OK;
+        break;
+    case MV_SCSI_COMPLETION_BAD_SCSI_COMMAND:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Scsi command completed with BAD_SCSI_COMMAND\n");
+        host_status = DID_OK;
+        break;
+    case MV_SCSI_COMPLETION_ATA_FAILED:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Scsi command completed with ATA FAILED\n");
+        host_status = DID_OK;
+        break;
+    case MV_SCSI_COMPLETION_UA_RESET:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Scsi command completed with UA BUS"
+                 " RESET\n");
+        scsi_report_bus_reset(pInfo->SCpnt->device->host, pInfo->SCpnt->device->channel);
+        host_status = DID_OK;
+        break;
+    case MV_SCSI_COMPLETION_UA_PARAMS_CHANGED:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Scsi command completed with UA "
+                 "PARAMETERS CHANGED\n");
+        scsi_report_bus_reset(pInfo->SCpnt->device->host, pInfo->SCpnt->device->channel);
+        host_status = DID_OK;
+        break;
+
+    case MV_SCSI_COMPLETION_QUEUE_FULL:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Scsi command completed with QUEUE FULL\n");
+        /* flushed from ial common*/
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+        if (pCmdBlock->ScsiStatus == MV_SCSI_STATUS_BUSY)
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Host status: DID_RESET\n");
+            host_status = DID_RESET;
+
+            pInfo->SCpnt->flags |= IS_RESETTING;
+        }
+        else
+#endif
+        {
+            host_status = DID_OK;
+        }
+        break;
+
+    case MV_SCSI_COMPLETION_ABORTED:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Scsi command completed with ABORTED\n");
+        host_status = DID_ERROR;
+        break;
+
+    case MV_SCSI_COMPLETION_OVERRUN:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Scsi command completed with OVERRUN\n");
+        if (pInfo->SCpnt->underflow > pCmdBlock->dataTransfered)
+        {
+            host_status = DID_ERROR;
+        }
+        else
+        {
+            host_status = DID_OK;
+        }
+        break;
+    case MV_SCSI_COMPLETION_UNDERRUN:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Scsi command completed with UNDERRUN\n");
+        host_status = DID_ERROR;
+        break;
+
+    case MV_SCSI_COMPLETION_PARITY_ERROR:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "Scsi command completed with PARITY ERROR\n");
+        host_status = DID_PARITY;
+        break;
+    case MV_SCSI_COMPLETION_INVALID_BUS:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Scsi command completed with INVALID BUS\n");
+        host_status = DID_BAD_TARGET;
+        break;
+    case MV_SCSI_COMPLETION_NO_DEVICE:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Scsi command completed with NO DEVICE\n");
+        host_status = DID_NO_CONNECT;
+        break;
+    case MV_SCSI_COMPLETION_INVALID_STATUS:
+    case MV_SCSI_COMPLETION_BAD_SCB:
+    case MV_SCSI_COMPLETION_NOT_READY:
+    case MV_SCSI_COMPLETION_DISCONNECT:
+    case MV_SCSI_COMPLETION_BUS_RESET:
+    case MV_SCSI_COMPLETION_BUSY:
+    default:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR,"Bad Scsi completion status %d\n",
+                 pCmdBlock->ScsiCommandCompletion);
+        host_status = DID_ERROR;
+
+    }
+    if ((pCmdBlock->senseDataLength == 0) && (pCmdBlock->senseBufferLength))
+    {
+        pCmdBlock->pSenseBuffer[0] = 0;
+    }
+    pInfo->SCpnt->result = host_status << 16 | (pCmdBlock->ScsiStatus & 0x3f);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,23)
+    pInfo->SCpnt->resid = pCmdBlock->dataBufferLength - pCmdBlock->dataTransfered;
+#else
+    scsi_set_resid(pInfo->SCpnt, pCmdBlock->dataBufferLength - pCmdBlock->dataTransfered);
+#endif
+    if(pCmdBlock->dataBufferLength - pCmdBlock->dataTransfered) 
+    {
+	    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "Scsi command completed with resid 0x%x\n",pCmdBlock->dataBufferLength - pCmdBlock->dataTransfered);
+    }
+
+    {
+        MV_U8   channelIndex = pCmdBlock->bus;
+        release_ata_mem(pInfo);
+        mv_ial_lib_add_done_queue (pSataAdapter->IALData, channelIndex, SCpnt);
+    }
+    return MV_TRUE;
+}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalLib.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalLib.h
new file mode 100644
index 0000000..50952d4
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalLib.h
@@ -0,0 +1,109 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* mvLinuxIalLib - Header File for Linux IAL Lib.
+*
+* DESCRIPTION:
+*       None.
+*
+* DEPENDENCIES:
+*       None.
+*
+*
+*******************************************************************************/
+#ifndef __INCmvLinuxIalLibh
+#define __INCmvLinuxIalLibh
+
+#include "mvLinuxIalHt.h"
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION (2,4,23)
+#define irqreturn_t         void
+#define IRQ_RETVAL(foo)
+#endif
+#define MV_LINUX_ASYNC_TIMER_PERIOD       ((MV_IAL_ASYNC_TIMER_PERIOD * HZ) / 1000)
+
+struct pci_dev;
+struct IALAdapter;
+struct IALHost;
+struct mv_comp_info;
+
+
+/* Adapter Initialization */
+int mv_ial_lib_allocate_edma_queues(struct IALAdapter *pAdapter);
+
+void mv_ial_lib_free_edma_queues(struct IALAdapter *pAdapter);
+
+int mv_ial_lib_init_channel(struct IALAdapter *pAdapter, MV_U8 channelNum);
+
+void mv_ial_lib_free_channel(struct IALAdapter *pAdapter, MV_U8 channelNum);
+
+/* PRD Table Generation */
+#ifndef MV_PRD_TABLE_SIZE
+ #define MV_PRD_TABLE_SIZE                  64 /* 64 entries max in PRD table */
+#endif
+
+
+int mv_ial_lib_prd_destroy(struct IALHost *pHost);
+int mv_ial_lib_prd_init(struct IALHost *);
+
+
+
+int mv_ial_lib_generate_prd(MV_SATA_ADAPTER *pMvSataAdapter, struct scsi_cmnd *SCpnt,
+                            struct mv_comp_info *);
+
+
+/* Interrupt Service Routine*/
+irqreturn_t mv_ial_lib_int_handler (int irq, void *dev_id);
+
+
+/* Event Notification */
+MV_BOOLEAN mv_ial_lib_udma_command_completion_call_back(MV_SATA_ADAPTER *pMvSataAdapter,
+                                           MV_U8 channelNum,
+                                           MV_COMPLETION_TYPE comp_type,
+                                           void *commandId,
+                                           MV_U16 responseFlags,
+                                           MV_U32 timeStamp,
+                                           MV_STORAGE_DEVICE_REGISTERS *registerStruct);
+
+MV_BOOLEAN mv_ial_lib_event_notify(MV_SATA_ADAPTER *pMvSataAdapter, MV_EVENT_TYPE eventType,
+                             MV_U32 param1, MV_U32 param2);
+void asyncStartTimerFunction(unsigned long data);
+
+/* SCSI done queuing and callback */
+void mv_ial_lib_add_done_queue (struct IALAdapter *pAdapter,
+                                MV_U8 channel,
+                                struct scsi_cmnd   *scsi_cmnd);
+
+struct scsi_cmnd * mv_ial_lib_get_first_cmnd (struct IALAdapter *pAdapter,
+                                       MV_U8 channel);
+
+void mv_ial_lib_do_done (struct scsi_cmnd *cmnd);
+
+void mv_ial_block_requests(struct IALAdapter *pAdapter, MV_U8 channelIndex);
+
+#endif /* __INCmvLinuxIalLibh */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalOs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalOs.c
new file mode 100644
index 0000000..84979e8
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalOs.c
@@ -0,0 +1,55 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* file_name - mvLinuxOs.c
+*
+* DESCRIPTION:  implementation for Linux Os layer
+*
+*
+* DEPENDENCIES:
+*   mvLinuxOs.h
+*   Linux header files.
+*
+*
+*******************************************************************************/
+/* Includes */
+#include "mvOsS.h"
+
+void mvMicroSecondsDelay(MV_VOID_PTR pSataAdapter, MV_U32 usecs)
+{
+    MV_U32 msecs = usecs / 1000;
+    MV_U32 i;        
+    MV_U32 tmp = usecs % 1000;
+    for (i = 0; i < msecs; i++)
+    {
+        udelay(1000);
+    }    
+    if (tmp > 0)
+        udelay(tmp);
+}
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalSmart.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalSmart.c
new file mode 100644
index 0000000..0bfabb8
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalSmart.c
@@ -0,0 +1,428 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* file_name - mvLinuxIALSmart.c
+*
+* DESCRIPTION: C file for S.M.A.R.T. features - smartmontools app
+*
+* DEPENDENCIES:
+*   None.
+*
+*
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+#include <linux/pci.h>
+#include <linux/ioport.h>
+#include <linux/delay.h>
+#include <linux/sched.h>
+#include <linux/proc_fs.h>
+#include <linux/stat.h>
+#include <linux/kdev_t.h>
+#include <linux/timer.h>
+#include <linux/spinlock.h>
+#include <asm/dma.h>
+#include <asm/system.h>
+#include <asm/io.h>
+#include <linux/version.h>
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+#include <scsi/scsi.h>
+#include <scsi/scsi_cmnd.h>
+#include <scsi/scsi_device.h>
+#include <scsi/scsi_host.h>
+#include <scsi/scsi_tcq.h>
+#else
+#include <linux/blk.h>
+#include "scsi.h"
+#include "hosts.h"
+#endif
+#include "mvScsiAtaLayer.h"
+#include "mvLinuxIalHt.h"
+#include "mvRegs.h"
+#include "mvIALCommon.h"
+#include "mvLinuxIalSmart.h"
+
+
+extern MV_VOID handleNoneUdmaError(MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                                   MV_STORAGE_DEVICE_REGISTERS *registerStruct);
+
+extern MV_VOID handleUdmaError(MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                               MV_U32 responseFlags,
+                               MV_STORAGE_DEVICE_REGISTERS *registerStruct);
+
+extern MV_VOID  checkQueueCommandResult(MV_SATA_SCSI_CMD_BLOCK *pScb,
+                                        MV_QUEUE_COMMAND_RESULT result);
+
+extern MV_VOID setSenseData(IN MV_SATA_SCSI_CMD_BLOCK *pScb, IN MV_U8 SenseKey,
+                            IN MV_U8 AdditionalSenseCode);
+
+static MV_BOOLEAN
+SmartCommandCompletionCB(MV_SATA_ADAPTER *pSataAdapter,
+                         MV_U8 channelNum,
+                         MV_COMPLETION_TYPE comp_type,
+                         MV_VOID_PTR commandId,
+                         MV_U16 responseFlags,
+                         MV_U32 timeStamp,
+                         MV_STORAGE_DEVICE_REGISTERS *registerStruct);
+
+static void swap_buf_le16(u16 *buf, unsigned int buf_words)
+{
+#ifdef __BIG_ENDIAN
+     unsigned int i;
+
+     for (i = 0; i < buf_words; i++)
+	  buf[i] = le16_to_cpu(buf[i]);
+#endif /* __BIG_ENDIAN */
+}
+
+MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaSendSmartCommand(IN  MV_SATA_ADAPTER* pSataAdapter,
+                                                       IN  MV_SATA_SCSI_CMD_BLOCK *pScb)
+{
+    MV_U8 *buff = (MV_U8*)pScb->pDataBuffer;
+    MV_NON_UDMA_PROTOCOL protocolType = MV_NON_UDMA_PROTOCOL_NON_DATA;
+    MV_QUEUE_COMMAND_RESULT result = MV_QUEUE_COMMAND_RESULT_OK;
+    MV_QUEUE_COMMAND_INFO   qCommandInfo;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "SMART command: command received, bufflen = %d.\n",
+             pScb->dataBufferLength);
+    pScb->dataTransfered = 0;
+    pScb->senseDataLength = 0;
+    if (pScb->bus >= pSataAdapter->numberOfChannels)
+    {
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_INVALID_BUS;
+        pScb->dataTransfered = 0;
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    if ((pScb->target >= MV_SATA_PM_MAX_PORTS) ||
+        (pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target].driveReady == MV_FALSE))
+    {
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_NO_DEVICE;
+        pScb->dataTransfered = 0;
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    if (pScb->dataBufferLength <= 6 || /*six byte opcode*/
+        (buff[SMART_BUF_COMMAND_OFFSET] != WIN_IDENTIFY &&
+        buff[SMART_BUF_COMMAND_OFFSET] != MV_ATA_COMMAND_IDLE &&
+        buff[SMART_BUF_COMMAND_OFFSET] != MV_ATA_COMMAND_IDLE_IMMEDIATE &&
+        buff[SMART_BUF_COMMAND_OFFSET] != MV_ATA_COMMAND_STANDBY_IMMEDIATE &&
+         buff[SMART_BUF_COMMAND_OFFSET] != WIN_SMART))
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "invalid SMART command received");
+        setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+                     SCSI_ADSENSE_NO_SENSE);
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    if (buff[SMART_BUF_COMMAND_OFFSET] == WIN_IDENTIFY)
+    {
+        if (pScb->dataBufferLength < MV_ATA_IDENTIFY_DEV_DATA_LENGTH*2 + 6)
+        {
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "WIN_IDENTIFY: "
+                     "invalid buffer length.%d\n", pScb->dataBufferLength);
+            setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+                         SCSI_ADSENSE_NO_SENSE);
+            pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+            pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+            pScb->completionCallBack(pSataAdapter, pScb);
+            return MV_SCSI_COMMAND_STATUS_COMPLETED;
+        }
+        protocolType = MV_NON_UDMA_PROTOCOL_PIO_DATA_IN;
+        buff[SMART_BUF_COMMAND_OFFSET] = MV_ATA_COMMAND_IDENTIFY;
+        buff[SMART_BUF_SECTORCOUNT_OFFSET] = 0;
+        buff[SMART_BUF_LBALOW_OFFSET] = 0;
+        buff[SMART_BUF_LBAMID_OFFSET] = 0;
+        buff[SMART_BUF_LBAHIGH_OFFSET] = 0;
+        buff[SMART_BUF_FEATURES_OFFSET] = 0;
+    }
+    else  if (buff[SMART_BUF_COMMAND_OFFSET] == MV_ATA_COMMAND_IDLE)
+    {
+         mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "SMART command: IDLE command received, sector count = %d.\n",
+              buff[SMART_BUF_SECTORCOUNT_OFFSET]);
+
+        protocolType = MV_NON_UDMA_PROTOCOL_NON_DATA;
+        buff[SMART_BUF_COMMAND_OFFSET] = MV_ATA_COMMAND_IDLE;
+        buff[SMART_BUF_LBALOW_OFFSET] = 0;
+        buff[SMART_BUF_LBAMID_OFFSET] = 0;
+        buff[SMART_BUF_LBAHIGH_OFFSET] = 0;
+        buff[SMART_BUF_FEATURES_OFFSET] = 0;
+    }
+    else  if (buff[SMART_BUF_COMMAND_OFFSET] == MV_ATA_COMMAND_IDLE_IMMEDIATE)
+    {
+         mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "SMART command: IDLE IMMEDIATE command received\n");
+              
+        protocolType = MV_NON_UDMA_PROTOCOL_NON_DATA;
+        buff[SMART_BUF_COMMAND_OFFSET] = MV_ATA_COMMAND_IDLE_IMMEDIATE;
+        buff[SMART_BUF_LBALOW_OFFSET] = 0;
+        buff[SMART_BUF_LBAMID_OFFSET] = 0;
+        buff[SMART_BUF_LBAHIGH_OFFSET] = 0;
+        buff[SMART_BUF_FEATURES_OFFSET] = 0;
+        buff[SMART_BUF_SECTORCOUNT_OFFSET] = 0;
+
+    }
+    else  if (buff[SMART_BUF_COMMAND_OFFSET] == MV_ATA_COMMAND_STANDBY_IMMEDIATE)
+    {
+         mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "SMART command: STANDBY IMMEDIATE command received\n");
+              
+        protocolType = MV_NON_UDMA_PROTOCOL_NON_DATA;
+        buff[SMART_BUF_COMMAND_OFFSET] = MV_ATA_COMMAND_STANDBY_IMMEDIATE;
+        buff[SMART_BUF_LBALOW_OFFSET] = 0;
+        buff[SMART_BUF_LBAMID_OFFSET] = 0;
+        buff[SMART_BUF_LBAHIGH_OFFSET] = 0;
+        buff[SMART_BUF_FEATURES_OFFSET] = 0;
+        buff[SMART_BUF_SECTORCOUNT_OFFSET] = 0;
+
+    }
+ 
+    else
+    {
+        buff[SMART_BUF_LBAMID_OFFSET] = 0x4F;
+        buff[SMART_BUF_LBAHIGH_OFFSET] = 0xC2;
+        switch (buff[SMART_BUF_FEATURES_OFFSET])
+        {
+        case SMART_READ_VALUES:
+        case SMART_READ_THRESHOLDS:
+        case SMART_READ_LOG_SECTOR:
+            if (pScb->dataBufferLength < ATA_SECTOR_SIZE + 6)
+            {
+                setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+                             SCSI_ADSENSE_NO_SENSE);
+                pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+                pScb->ScsiCommandCompletion =
+                MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+                pScb->completionCallBack(pSataAdapter, pScb);
+                return MV_SCSI_COMMAND_STATUS_COMPLETED;
+            }
+            protocolType = MV_NON_UDMA_PROTOCOL_PIO_DATA_IN;
+            break;
+        case SMART_ENABLE:
+        case SMART_DISABLE:
+        case SMART_AUTO_OFFLINE:
+        case SMART_AUTOSAVE:
+        case SMART_IMMEDIATE_OFFLINE:
+        case SMART_STATUS:
+            protocolType = MV_NON_UDMA_PROTOCOL_NON_DATA;
+            break;
+        default:
+            setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+                         SCSI_ADSENSE_NO_SENSE);
+            pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+            pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+            pScb->completionCallBack(pSataAdapter, pScb);
+            return MV_SCSI_COMMAND_STATUS_COMPLETED;
+        }
+    }
+    qCommandInfo.type = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    qCommandInfo.commandParams.NoneUdmaCommand.protocolType = protocolType;
+    qCommandInfo.commandParams.NoneUdmaCommand.isEXT = MV_FALSE;
+    qCommandInfo.PMPort = pScb->target;
+    if (protocolType == MV_NON_UDMA_PROTOCOL_NON_DATA)
+    {
+        qCommandInfo.commandParams.NoneUdmaCommand.bufPtr = NULL;
+        qCommandInfo.commandParams.NoneUdmaCommand.count = 0;
+    }
+    else
+    {
+        qCommandInfo.commandParams.NoneUdmaCommand.bufPtr =
+        (MV_U16_PTR)&buff[6];
+        qCommandInfo.commandParams.NoneUdmaCommand.count =
+        (MV_U32)(ATA_SECTOR_SIZE/2);
+        /*in words*/
+    }
+    qCommandInfo.commandParams.NoneUdmaCommand.features =
+    (MV_U16)buff[SMART_BUF_FEATURES_OFFSET];
+    qCommandInfo.commandParams.NoneUdmaCommand.sectorCount =
+    (MV_U16)buff[SMART_BUF_SECTORCOUNT_OFFSET];
+    qCommandInfo.commandParams.NoneUdmaCommand.lbaLow =
+    (MV_U16)buff[SMART_BUF_LBALOW_OFFSET];
+    qCommandInfo.commandParams.NoneUdmaCommand.lbaMid =
+    (MV_U16)buff[SMART_BUF_LBAMID_OFFSET];
+    qCommandInfo.commandParams.NoneUdmaCommand.lbaHigh =
+    (MV_U16)buff[SMART_BUF_LBAHIGH_OFFSET];
+    qCommandInfo.commandParams.NoneUdmaCommand.device = (MV_U8)(MV_BIT6);
+    qCommandInfo.commandParams.NoneUdmaCommand.command =
+    buff[SMART_BUF_COMMAND_OFFSET];
+    qCommandInfo.commandParams.NoneUdmaCommand.callBack =
+    SmartCommandCompletionCB;
+    qCommandInfo.commandParams.NoneUdmaCommand.commandId = (MV_VOID_PTR) pScb;
+    result = mvSataQueueCommand(pSataAdapter, pScb->bus, &qCommandInfo);
+    if (result != MV_QUEUE_COMMAND_RESULT_OK)
+    {
+        checkQueueCommandResult(pScb, result);
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+    pDriveData->stats.totalIOs++;
+
+    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "SMART command: SMART command %02X, queued\n",
+             buff[SMART_BUF_FEATURES_OFFSET]);
+    return MV_SCSI_COMMAND_STATUS_QUEUED;
+}
+
+static void SmartFillReturnBuffer(IN MV_U8* buff,
+                                  IN MV_STORAGE_DEVICE_REGISTERS *registerStruct)
+{
+
+    /*For PIO non-data return registers' values*/
+    if (buff[SMART_BUF_COMMAND_OFFSET] == WIN_SMART &&
+        buff[SMART_BUF_FEATURES_OFFSET] != SMART_READ_VALUES &&
+        buff[SMART_BUF_FEATURES_OFFSET] != SMART_READ_THRESHOLDS &&
+        buff[SMART_BUF_FEATURES_OFFSET] != SMART_READ_LOG_SECTOR)
+    {
+        buff[6+SMART_BUF_COMMAND_OFFSET] =
+        buff[SMART_BUF_COMMAND_OFFSET];
+        buff[6+SMART_BUF_FEATURES_OFFSET] =
+        buff[SMART_BUF_FEATURES_OFFSET];
+        buff[6+SMART_BUF_LBALOW_OFFSET] =
+        registerStruct->lbaLowRegister & 0xFF;
+        buff[6+SMART_BUF_SECTORCOUNT_OFFSET] =
+        registerStruct->sectorCountRegister & 0xFF;
+        buff[6+SMART_BUF_LBAMID_OFFSET] =
+        registerStruct->lbaMidRegister & 0xFF;
+        buff[6+SMART_BUF_LBAHIGH_OFFSET] =
+        registerStruct->lbaHighRegister & 0xFF;
+        buff[6+SMART_BUF_DEVICE_OFFSET] =
+        registerStruct->deviceRegister & 0xFF;
+        buff[6+SMART_BUF_ERROR_OFFSET] =
+        registerStruct->errorRegister & 0xFF;
+    }
+    else
+    {
+	 swap_buf_le16((u16 *) (buff + 6), ATA_SECTOR_SIZE/2);
+    }
+}
+
+static MV_BOOLEAN
+SmartCommandCompletionCB(MV_SATA_ADAPTER *pSataAdapter,
+                         MV_U8 channelNum,
+                         MV_COMPLETION_TYPE comp_type,
+                         MV_VOID_PTR commandId,
+                         MV_U16 responseFlags,
+                         MV_U32 timeStamp,
+                         MV_STORAGE_DEVICE_REGISTERS *registerStruct)
+{
+    MV_SATA_SCSI_CMD_BLOCK  *pScb;
+    struct scsi_cmnd   *SCpnt;
+    struct mv_comp_info *pInfo;
+
+    if (commandId == NULL)
+    {
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, " commandId is NULL, can't hanlde this !!!,adapterId=%d,"
+                 " channel=%d \n", pSataAdapter->adapterId, channelNum);
+        return MV_FALSE;
+    }
+
+    pScb = commandId;
+    SCpnt = (struct scsi_cmnd *)pScb->IALData;
+    pInfo = ( struct mv_comp_info *) &(SCpnt->SCp);
+
+    switch (comp_type)
+    {
+    case MV_COMPLETION_TYPE_NORMAL:
+        if (pScb->ScsiCdb[0] == SCSI_OPCODE_MVSATA_SMART)
+        {
+            SmartFillReturnBuffer(pScb->pDataBuffer, registerStruct);
+            mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "SMART PIO command completed: "
+                     "dev=%04X, Low=%04X, Mid=%04X, High=%04X, "
+                     "SC=%04X, status = %04X,\n",
+                     registerStruct->deviceRegister,
+                     registerStruct->lbaLowRegister,
+                     registerStruct->lbaMidRegister,
+                     registerStruct->lbaHighRegister,
+                     registerStruct->sectorCountRegister,
+                     registerStruct->statusRegister);
+
+	    if(pInfo->kmap_buffer)
+	    {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+		    struct scatterlist *sg;
+		    MV_U8*		pBuffer;
+		    sg = (struct scatterlist *)SCpnt->request_buffer;
+		    
+		    mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "SMART PIO command needs kmap for Data-in buffer\n");
+		    
+		    pBuffer = kmap_atomic(sg->page, KM_IRQ0) + sg->offset;
+		    memcpy(pBuffer, pInfo->pSALBlock->pDataBuffer, sg->length); 	
+		    kunmap_atomic(pBuffer - sg->offset, KM_IRQ0);
+#else
+		    scsi_sg_copy_from_buffer(SCpnt, pInfo->pSALBlock->pDataBuffer,
+					     scsi_bufflen(SCpnt));
+#endif
+	    }
+		    
+        }
+        pScb->dataTransfered = MV_ATA_IDENTIFY_DEV_DATA_LENGTH*2;
+        pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG, "command completed. pScb %p\n", pScb);
+        break;
+    case MV_COMPLETION_TYPE_ABORT:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, " command Aborted. Cdb: %02x %02x %02x %02x %02x "
+                 "%02x %02x %02x %02x %02x\n", pScb->ScsiCdb[0],
+                 pScb->ScsiCdb[1], pScb->ScsiCdb[2], pScb->ScsiCdb[3],
+                 pScb->ScsiCdb[4], pScb->ScsiCdb[5], pScb->ScsiCdb[6],
+                 pScb->ScsiCdb[7], pScb->ScsiCdb[8], pScb->ScsiCdb[9]);
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_ABORTED;
+        pScb->dataTransfered = 0;
+        pScb->senseDataLength = 0;
+        break;
+    case MV_COMPLETION_TYPE_ERROR:
+        pScb->dataTransfered = 0;
+        pScb->senseDataLength = 0;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_ATA_FAILED;
+
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, " completion error, adapter =%d, channel=%d, flags=%x\n"
+                 ,pSataAdapter->adapterId, channelNum, responseFlags);
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "Failed command Cdb: %02x %02x %02x %02x %02x "
+                 "%02x %02x %02x %02x %02x\n", pScb->ScsiCdb[0],
+                 pScb->ScsiCdb[1], pScb->ScsiCdb[2], pScb->ScsiCdb[3],
+                 pScb->ScsiCdb[4], pScb->ScsiCdb[5], pScb->ScsiCdb[6],
+                 pScb->ScsiCdb[7], pScb->ScsiCdb[8], pScb->ScsiCdb[9]);
+        /* here the  eDMA will be stopped, so we have to flush  */
+        /* the pending commands                                 */
+        handleNoneUdmaError(pScb, registerStruct);
+        break;
+    default:
+        mvLogMsg(MV_IAL_LOG_ID, MV_DEBUG_ERROR, "Unknown completion type (%d)\n", comp_type);
+        return MV_FALSE;
+    }
+    pScb->completionCallBack(pSataAdapter, pScb);
+    return MV_TRUE;
+}
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalSmart.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalSmart.h
new file mode 100644
index 0000000..206ed2b
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvLinuxIalSmart.h
@@ -0,0 +1,109 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* file_name - mvLinuxIALSmart.h
+*
+* DESCRIPTION: C header file for S.M.A.R.T. features - smartmontools app
+*
+*
+* DEPENDENCIES:
+*   
+*
+*
+*******************************************************************************/
+#ifndef __INCmvScsiSmart
+#define __INCmvScsiSmart
+
+/*Proprietary opcode to support smartmontools app*/
+#define SCSI_OPCODE_MVSATA_SMART            0x0C
+
+
+/*S.M.A.R.T ATA commands used*/
+#ifndef WIN_IDENTIFY
+#define WIN_IDENTIFY                        0xEC
+#endif
+#ifndef WIN_SMART
+#define WIN_SMART                           0xB0    
+#endif
+#ifndef SMART_READ_VALUES
+#define SMART_READ_VALUES                   0xD0
+#endif
+#ifndef SMART_READ_THRESHOLDS   
+#define SMART_READ_THRESHOLDS               0xD1
+#endif
+#ifndef SMART_AUTOSAVE 
+#define SMART_AUTOSAVE                      0xD2
+#endif
+#ifndef SMART_SAVE
+#define SMART_SAVE                          0xD3
+#endif
+#ifndef SMART_IMMEDIATE_OFFLINE 
+#define SMART_IMMEDIATE_OFFLINE             0xD4
+#endif
+#ifndef SMART_READ_LOG_SECTOR
+#define SMART_READ_LOG_SECTOR               0xD5
+#endif
+#ifndef SMART_WRITE_LOG_SECTOR
+#define SMART_WRITE_LOG_SECTOR              0xD6
+#endif
+/* The following is obsolete -- don't use it!*/
+#ifndef SMART_WRITE_THRESHOLDS
+#define SMART_WRITE_THRESHOLDS              0xD7
+#endif
+#ifndef SMART_ENABLE
+#define SMART_ENABLE                        0xD8
+#endif
+#ifndef SMART_DISABLE
+#define SMART_DISABLE                       0xD9
+#endif
+#ifndef SMART_STATUS
+#define SMART_STATUS                        0xDA
+#endif
+
+/* The following is also marked obsolete in ATA-5*/
+#ifndef SMART_AUTO_OFFLINE
+#define SMART_AUTO_OFFLINE                  0xDB
+#endif
+
+/*Definitions of S.M.A.R.T. command buffer offsets*/
+#define SMART_BUF_COMMAND_OFFSET                0
+#define SMART_BUF_LBALOW_OFFSET                 1
+#define SMART_BUF_FEATURES_OFFSET               2
+#define SMART_BUF_SECTORCOUNT_OFFSET            3
+#define SMART_BUF_LBAMID_OFFSET                 4
+#define SMART_BUF_LBAHIGH_OFFSET                5
+#define SMART_BUF_DEVICE_OFFSET                 6
+#define SMART_BUF_ERROR_OFFSET                  7
+
+
+MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaSendSmartCommand
+                (IN  MV_SATA_ADAPTER* pSataAdapter,
+                 IN  MV_SATA_SCSI_CMD_BLOCK *pScb);
+
+
+#endif
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvScsiAtaLayer.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvScsiAtaLayer.c
new file mode 100644
index 0000000..0b92abd
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvScsiAtaLayer.c
@@ -0,0 +1,3553 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* mvScsiAtaLayer.c
+*
+* DESCRIPTION:
+*       C implementation for SCSI to ATA translation layer.
+*
+* DEPENDENCIES:
+*   mvIALCommon.h
+*   mvScsiAtaLayer.h
+*
+*******************************************************************************/
+
+/* includes */
+#include "mvScsiAtaLayer.h"
+#include "mvIALCommon.h"
+
+#ifdef MV_LOGGER
+    #define SAL_SPRINTF     sprintf
+#endif
+
+/* ATA defines */
+/* Bits for HD_ERROR */
+#define NM_ERR          0x02    /* media present */
+#define ABRT_ERR        0x04    /* Command aborted */
+#define MCR_ERR         0x08    /* media change request */
+#define IDNF_ERR        0x10    /* ID field not found */
+#define MC_ERR          0x20    /* media changed */
+#define UNC_ERR         0x40    /* Uncorrect data */
+#define WP_ERR          0x40    /* write protect */
+#define ICRC_ERR        0x80    /* new meaning:  CRC error during transfer */
+
+#ifdef MV_LOGGER
+static MV_VOID reportScbCompletion(MV_SATA_ADAPTER*    pSataAdapter,
+                                   MV_SATA_SCSI_CMD_BLOCK *pScb);
+#endif
+
+/* Locals */
+static MV_VOID mvAta2HostString(IN   MV_U16 *source,
+                                OUT  MV_U16 *target,
+                                IN   MV_U32 wordsCount);
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaGetInquiryData(IN  MV_SATA_ADAPTER*    pSataAdapter,
+                                                            IN  MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaTestUnitReady(IN  MV_SATA_ADAPTER*    pSataAdapter,
+                                                           IN  MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaSendDataCommand(IN  MV_SATA_ADAPTER*    pSataAdapter,
+                                                             IN  MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaGetReadCapacityData(IN MV_SATA_ADAPTER*    pSataAdapter,
+                                                                 IN MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaReportLuns(IN MV_SATA_ADAPTER*    pSataAdapter,
+							IN MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaSendVerifyCommand(IN MV_SATA_ADAPTER*    pSataAdapter,
+                                                               IN MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaReassignBlocks(IN MV_SATA_ADAPTER    *pSataAdapter,
+                                                            IN MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaSendSyncCacheCommand(IN MV_SATA_ADAPTER*    pSataAdapter,
+                                                                  IN MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaGetRequestSenseData(IN MV_SATA_ADAPTER*    pSataAdapter,
+                                                                 IN MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaGetModeSenseData(IN    MV_SATA_ADAPTER*    pSataAdapter,
+                                                              IN    MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_BOOLEAN  mvScsiAtaGetModeSenseDataPhase2(IN MV_SATA_ADAPTER    *pSataAdapter,
+                                                   IN  MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaModeSelect(IN    MV_SATA_ADAPTER*    pSataAdapter,
+                                                        IN    MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_U8 modeSelect(IN MV_SATA_ADAPTER    *pSataAdapter,
+                        IN  MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                        MV_SCSI_COMMAND_STATUS_TYPE *pCommandStatus);
+
+static MV_U8 mvParseModeCachingPage(MV_SATA_ADAPTER *pSataAdapter,
+                                    IN  MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                                    MV_U8 *buffer,
+                                    MV_SCSI_COMMAND_STATUS_TYPE *pCommandStatus);
+static MV_U32 mvModeSenseCachingPage(MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                                     MV_U8 *buffer, MV_U8 pageControl);
+
+static MV_U32 mvModeSenseControlPage(MV_SATA_ADAPTER *pSataAdapter,
+                                     MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                                     MV_U8 *buffer, MV_U8 pageControl);
+
+static MV_BOOLEAN SALCommandCompletionCB(MV_SATA_ADAPTER *pSataAdapter,
+                                         MV_U8 channelNum,
+                                         MV_COMPLETION_TYPE comp_type,
+                                         MV_VOID_PTR commandId,
+                                         MV_U16 responseFlags,
+                                         MV_U32 timeStamp,
+                                         MV_STORAGE_DEVICE_REGISTERS *registerStruct);
+
+MV_VOID setSenseData(IN MV_SATA_SCSI_CMD_BLOCK *pScb, IN MV_U8 SenseKey,
+                     IN MV_U8 AdditionalSenseCode, IN MV_U8 ASCQ);
+
+MV_VOID _fillSenseInformation(IN MV_SATA_SCSI_CMD_BLOCK *pScb, MV_SCSI_SENSE_DATA *SenseData,
+			      MV_STORAGE_DEVICE_REGISTERS *registerStruct);
+
+MV_VOID handleNoneUdmaError(MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                            MV_STORAGE_DEVICE_REGISTERS *registerStruct);
+
+static MV_VOID handleUdmaError(MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                               MV_U32 responseFlags,
+                               MV_STORAGE_DEVICE_REGISTERS *registerStruct);
+
+/*static*/ MV_VOID  checkQueueCommandResult(MV_SATA_SCSI_CMD_BLOCK *pScb,
+                                            MV_QUEUE_COMMAND_RESULT result);
+
+static MV_VOID  mvScsiAtaSendSplittedVerifyCommand(IN MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_VOID  mvScsiAtaSendReadLookAhead(IN MV_SATA_ADAPTER*    pSataAdapter,
+                                           IN MV_SATA_SCSI_CMD_BLOCK  *pScb);
+
+static MV_VOID mvAta2HostString(IN MV_U16 *source,
+                                OUT MV_U16 *target,
+                                IN MV_U32 wordsCount
+                               )
+{
+    MV_U32 i;
+    for (i=0 ; i < wordsCount; i++)
+    {
+        target[i] = (source[i] >> 8) | ((source[i] & 0xff) << 8);
+        target[i] = MV_LE16_TO_CPU(target[i]);
+    }
+}
+
+MV_VOID setSenseData(IN MV_SATA_SCSI_CMD_BLOCK *pScb, IN MV_U8 SenseKey,
+                     IN MV_U8 AdditionalSenseCode, IN MV_U8 ASCQ)
+{
+    MV_SCSI_SENSE_DATA SenseData;
+
+    if (pScb->senseBufferLength == 0)
+    {
+        pScb->senseDataLength = 0;
+        return;
+    }
+    memset(&SenseData, 0, sizeof(MV_SCSI_SENSE_DATA));
+//    SenseData.Valid = 0;
+    SenseData.ResponseCode = MV_SCSI_RESPONSE_CODE;
+    SenseData.SenseKey = SenseKey;
+    SenseData.AdditionalSenseCode = AdditionalSenseCode;
+    SenseData.AdditionalSenseCodeQualifier = ASCQ;
+    SenseData.AdditionalSenseLength = sizeof(MV_SCSI_SENSE_DATA) - 8;
+    pScb->senseDataLength = sizeof(MV_SCSI_SENSE_DATA);
+    if (pScb->senseBufferLength < pScb->senseDataLength)
+    {
+        pScb->senseDataLength = pScb->senseBufferLength;
+    }
+    memcpy(pScb->pSenseBuffer, &SenseData, pScb->senseDataLength);
+}
+
+MV_VOID _fillSenseInformation(IN MV_SATA_SCSI_CMD_BLOCK *pScb, MV_SCSI_SENSE_DATA *SenseData,
+			      MV_STORAGE_DEVICE_REGISTERS *registerStruct)
+{
+        if (pScb->isExtended == MV_TRUE)
+        {
+		/* LBA 48 error handling */
+		SenseData->InformationDesc.information[2] = (MV_U8)((registerStruct->lbaHighRegister >> 8) & 0xff);
+		SenseData->InformationDesc.information[3] = (MV_U8)((registerStruct->lbaMidRegister >> 8) & 0xff);
+		SenseData->InformationDesc.information[4] = (MV_U8)((registerStruct->lbaLowRegister >> 8) & 0xff);
+        }
+        else
+        {
+            /* LBA 28 error handling */
+            SenseData->InformationDesc.information[4] =  (MV_U8)((registerStruct->deviceRegister) & 0x0f);
+        }
+        SenseData->InformationDesc.information[5] = (MV_U8)(registerStruct->lbaHighRegister & 0xff);
+        SenseData->InformationDesc.information[6] = (MV_U8)(registerStruct->lbaMidRegister & 0xff);
+        SenseData->InformationDesc.information[7] = (MV_U8)(registerStruct->lbaLowRegister & 0xff);
+}
+
+/*
+ *  setPassThruSense - Set SCSI PassThru sense block.
+ *
+ *  This function is specific to the ATA passthru command.
+ *  Regardless of whether the command issue or not, fill the sense
+ *  buffer with the ATA descriptor return.
+ */
+static MV_VOID setPassThruSense(MV_SATA_SCSI_CMD_BLOCK *pScb,
+                                MV_STORAGE_DEVICE_REGISTERS *registerStruct)
+{
+    MV_SCSI_SENSE_DATA *sb = (MV_SCSI_SENSE_DATA *) pScb->pSenseBuffer;
+    MV_U8 *desc;
+
+    /* Some sanity checks */
+    if (unlikely(!pScb->pSenseBuffer ||
+                 (pScb->senseBufferLength < sizeof(MV_SCSI_SENSE_DATA))))
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR,
+                 "Can't set ATA pass through sense: invalid buffer\n");
+        return;
+    }
+
+    memset(sb, 0, sizeof(MV_SCSI_SENSE_DATA));
+    desc = (MV_U8 *) &sb->InformationDesc;
+
+    sb->ResponseCode = MV_SCSI_RESPONSE_CODE;
+
+    /* CK_COND bit it on, need to return indication to application */
+    if (pScb->ScsiCdb[2] & MV_BIT5)
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+
+    /*
+     * TODO: Check registerStruct->errorRegister and fill the sense
+     * buffer accordingly.
+     */
+
+    pScb->senseDataLength = 22;
+
+    /* Set length of additional sense data */
+    sb->AdditionalSenseLength = 14;
+
+    /*
+     * Copy registers into the additional sense buffer.
+     * This buffer should map the ATA descriptor return.
+     */
+    desc[0]     = 0x09;
+    desc[1]     = 12; /* Additional length */
+    desc[2]     = 0x00;
+    desc[3]     = registerStruct->errorRegister;
+    desc[5]     = (MV_U8)(registerStruct->sectorCountRegister);
+    desc[7]     = (MV_U8)(registerStruct->lbaLowRegister);
+    desc[9]     = (MV_U8)(registerStruct->lbaMidRegister);
+    desc[11]    = (MV_U8)(registerStruct->lbaHighRegister);
+    desc[12]    = registerStruct->deviceRegister;
+    desc[13]    = registerStruct->statusRegister;
+
+    /* LBA 48 error handling */
+    if (pScb->isExtended == MV_TRUE)
+    {
+        desc[2]     |= 0x01; /* Extended ATA descriptor return bit */
+        desc[4]     = (MV_U8)(registerStruct->sectorCountRegister >> 8);
+        desc[6]     = (MV_U8)(registerStruct->lbaLowRegister >> 8);
+        desc[8]     = (MV_U8)(registerStruct->lbaMidRegister >> 8);
+        desc[10]    = (MV_U8)(registerStruct->lbaHighRegister >> 8);
+    }
+}
+
+static MV_BOOLEAN checkLBAOutOfRange(IN MV_SATA_ADAPTER*    pSataAdapter,
+                                     IN MV_SATA_SCSI_CMD_BLOCK *pScb,
+                                     IN MV_U64 ATADiskSize, IN MV_U64 LBA,
+                                     IN MV_U32 sectors)
+{
+    if ((ATADiskSize <= LBA) ||  ((ATADiskSize - LBA) < sectors) || sectors > 0xFFFF)
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Error LBA out of range. DiskSize %x sectors %x LBA %x\n"
+                 , ATADiskSize, sectors, LBA);
+
+        setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+                     SCSI_ADSENSE_ILLEGAL_BLOCK, 0);
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->dataTransfered = 0;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_TRUE;
+
+    }
+    return MV_FALSE;
+}
+/*******************************************************************************
+* mvScsiAtaGetInquiryData - Get the SCSI-3 standard inquiry(12h) data
+*
+* DESCRIPTION: This function fills the data buffer with Scsi standard inquiry
+*       data according to the ATA Identify data
+*
+* INPUT:
+*   pSataAdapter    - pointer to the SATA adapter data structure.
+*   pScb->bus    - the index of the specific SATA channel.
+*   pScb            - pointer to the Scsi command block.
+*
+* RETURN:
+*   MV_TRUE on success, MV_FALSE on failure.
+*
+* COMMENTS:
+*   No sanity check is done for the parameters.
+*
+*******************************************************************************/
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaGetInquiryData(IN  MV_SATA_ADAPTER*    pSataAdapter,
+                                                            IN  MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+    MV_U8           buff[42];
+    MV_U32          inquiryLen;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+
+    memset(buff, 0, 42);
+
+    if ((pScb->ScsiCdb[1] & (MV_BIT0 | MV_BIT1)) ||
+        (pScb->ScsiCdb[2]))
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%d %d: Inquiry completed with error: cmd[1] %x cmd[2] %x\n",
+                 pSataAdapter->adapterId, pScb->bus, pScb->ScsiCdb[1],
+                 pScb->ScsiCdb[2]);
+        if (pDriveData->UAConditionPending == MV_TRUE)
+        {
+
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Unit Attention condition is pending.\n");
+
+            if (pDriveData->UAEvents & MV_BIT0)
+            {
+                mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Report Bus Reset.\n");
+
+                pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_UA_RESET;
+                setSenseData(pScb, SCSI_SENSE_UNIT_ATTENTION, SCSI_ADSENSE_BUS_RESET
+                             , 2);
+                pDriveData->UAEvents &= ~MV_BIT0;
+            }
+            else if (pDriveData->UAEvents & MV_BIT1)
+            {
+                mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Report Mode Parameters Changed.\n");
+                pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_UA_PARAMS_CHANGED;
+                setSenseData(pScb, SCSI_SENSE_UNIT_ATTENTION,
+                             SCSI_ADSENSE_PARAMETERS_CHANGED, 1);
+                pDriveData->UAEvents &= ~MV_BIT1;
+            }
+
+            pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+            pScb->dataTransfered = 0;
+#ifdef MV_LOGGER
+            reportScbCompletion(pSataAdapter, pScb);
+#endif
+            pScb->completionCallBack(pSataAdapter, pScb);
+            if (pDriveData->UAEvents == 0)
+            {
+                pDriveData->UAConditionPending = MV_FALSE;
+            }
+            return MV_SCSI_COMMAND_STATUS_COMPLETED;
+        }
+
+        setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST, SCSI_ADSENSE_INVALID_CDB,
+                     0);
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->dataTransfered = 0;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    if (pScb->lun)
+    {
+        buff[0] = 0x7f;
+        inquiryLen = 5;
+    }
+    else
+    {
+        MV_U8   Vendor[9],Product[17], temp[24];
+        buff[0] = MV_SCSI_DIRECT_ACCESS_DEVICE;
+        buff[1] = 0;    /* Not Removable disk */
+        buff[2] = 5;    /*claim conformance to SCSI-3*/
+        buff[3] = 2;    /* set RESPONSE DATA FORMAT to 2*/
+        buff[4] = 41 - 4; /* n - 4, n start from 0 */
+#if 0
+        buff[6] = 0x80;     /* basic queuing*/
+        buff[7] = 0;
+#else
+        buff[6] = 0x0;     /* tagged queuing*/
+        buff[7] = 2;
+#endif
+        memcpy(temp, pDriveData->identifyInfo.model, 24);
+        mvAta2HostString((MV_U16 *)temp, (MV_U16 *)(temp), 12);
+        {
+            MV_U32 i;
+            for (i = 0; i < 9; i++)
+            {
+                if (temp[i] == ' ')
+                {
+                    break;
+                }
+            }
+            if (i == 9)
+            {
+                if (((temp[0] == 'I') && (temp[1] == 'C')) ||
+                    ((temp[0] == 'H') && (temp[1] == 'T')) ||
+                    ((temp[0] == 'H') && (temp[1] == 'D')) ||
+                    ((temp[0] == 'D') && (temp[1] == 'K')))
+                { /*Hitachi*/
+                    Vendor[0] = 'H';
+                    Vendor[1] = 'i';
+                    Vendor[2] = 't';
+                    Vendor[3] = 'a';
+                    Vendor[4] = 'c';
+                    Vendor[5] = 'h';
+                    Vendor[6] = 'i';
+                    Vendor[7] = ' ';
+                    Vendor[8] = '\0';
+                }
+                else if ((temp[0] == 'S') && (temp[1] == 'T'))
+                {
+                    /*Seagate*/
+                    Vendor[0] = 'S';
+                    Vendor[1] = 'e';
+                    Vendor[2] = 'a';
+                    Vendor[3] = 'g';
+                    Vendor[4] = 'a';
+                    Vendor[5] = 't';
+                    Vendor[6] = 'e';
+                    Vendor[7] = ' ';
+                    Vendor[8] = '\0';
+                }
+                else
+                {
+                    /*Unkown*/
+                    Vendor[0] = 'A';
+                    Vendor[1] = 'T';
+                    Vendor[2] = 'A';
+                    Vendor[3] = ' ';
+                    Vendor[4] = ' ';
+                    Vendor[5] = ' ';
+                    Vendor[6] = ' ';
+                    Vendor[7] = ' ';
+                    Vendor[8] = '\0';
+                }
+                memcpy(Product, temp, 16);
+                Product[16] = '\0';
+            }
+            else
+            {
+                MV_U32 j = i;
+                memcpy(Vendor, temp, j);
+                for (; j < 9; j++)
+                {
+                    Vendor[j] = ' ';
+                }
+                Vendor[8] = '\0';
+                for (; i < 24; i++)
+                {
+                    if (temp[i] != ' ')
+                    {
+                        break;
+                    }
+                }
+                memcpy(Product, &temp[i], 24 - i);
+                Product[16] = '\0';
+            }
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " Vendor %s Product %s\n", Vendor, Product);
+            memcpy(&buff[8], Vendor, 8);
+            memcpy(&buff[16], Product, 16);
+            memcpy(&buff[32], pDriveData->identifyInfo.firmware, 4);
+            mvAta2HostString((MV_U16 *)(&buff[32]), (MV_U16 *)(&buff[32]), 2);
+        }
+        memcpy(&buff[36], "MVSATA", 6);
+
+        /*buff[32] = '3';*/
+
+        inquiryLen = 42;
+    }
+    if (pScb->dataBufferLength > inquiryLen)
+    {
+        memcpy(pScb->pDataBuffer, buff, inquiryLen);
+        pScb->dataTransfered = inquiryLen;
+    }
+    else
+    {
+        memcpy(pScb->pDataBuffer, buff, pScb->dataBufferLength);
+        pScb->dataTransfered = pScb->dataBufferLength;
+    }
+    pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+    pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+    pScb->senseDataLength = 0;
+#ifdef MV_LOGGER
+    reportScbCompletion(pSataAdapter, pScb);
+#endif
+    pScb->completionCallBack(pSataAdapter, pScb);
+    return MV_SCSI_COMMAND_STATUS_COMPLETED;
+}
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaTestUnitReady(IN  MV_SATA_ADAPTER*    pSataAdapter,
+                                                           IN  MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+    pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+    pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+    pScb->senseDataLength = 0;
+    pScb->dataTransfered = 0;
+
+#ifdef MV_LOGGER
+    reportScbCompletion(pSataAdapter, pScb);
+#endif
+    pScb->completionCallBack(pSataAdapter, pScb);
+    return MV_SCSI_COMMAND_STATUS_COMPLETED;
+}
+
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaSendDataCommand(IN  MV_SATA_ADAPTER*    pSataAdapter,
+                                                             IN  MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+    MV_U8           *cmd = pScb->ScsiCdb;
+    MV_QUEUE_COMMAND_RESULT    result;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+    MV_SAL_ADAPTER_EXTENSION *pAdapterExt = pScb->pSalAdapterExtension;
+    MV_U32                  sectors;
+    MV_U64		    LBA;
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO *pCommandInfo = pScb->pCommandInfo;
+    MV_UDMA_COMMAND_PARAMS  *pUdmaParams = &pCommandInfo->commandParams.udmaCommand;
+    pCommandInfo->type = MV_QUEUED_COMMAND_TYPE_UDMA;
+    pCommandInfo->PMPort = pScb->target;
+    pUdmaParams->readWrite = MV_UDMA_TYPE_WRITE;
+    pUdmaParams->isEXT = MV_FALSE;
+    pUdmaParams->FUA = MV_FALSE;
+    pUdmaParams->highLBAAddress = 0;
+    pUdmaParams->callBack = SALCommandCompletionCB;
+    pUdmaParams->commandId = (MV_VOID_PTR )pScb;
+#ifdef MV_SATA_SUPPORT_EDMA_SINGLE_DATA_REGION
+    pUdmaParams->singleDataRegion = pScb->singleDataRegion;
+    pUdmaParams->byteCount = pScb->byteCount;
+#endif
+#else    
+    MV_QUEUE_COMMAND_INFO commandInfo =
+    {
+        MV_QUEUED_COMMAND_TYPE_UDMA,
+        pScb->target,
+        {
+            {
+                MV_UDMA_TYPE_WRITE, MV_FALSE, MV_FALSE, 0, 0, 0, 0, 0,
+#ifdef MV_SATA_SUPPORT_EDMA_SINGLE_DATA_REGION
+                pScb->singleDataRegion,
+                pScb->byteCount,
+#endif
+                SALCommandCompletionCB, (MV_VOID_PTR )pScb
+            }
+        }
+    };
+    MV_QUEUE_COMMAND_INFO *pCommandInfo = &commandInfo;
+    MV_UDMA_COMMAND_PARAMS  *pUdmaParams = &pCommandInfo->commandParams.udmaCommand;
+#endif
+
+    if ((cmd[0] == SCSI_OPCODE_READ6) || (cmd[0] == SCSI_OPCODE_WRITE6))
+    {
+        pUdmaParams->lowLBAAddress =
+        ( (MV_U32)  cmd[3]) |
+        (((MV_U32)  cmd[2]) << 8) |
+        ((((MV_U32) cmd[1]) & 0x1f) << 16);
+        sectors = (MV_U16) cmd[4];
+    }
+    else if ((cmd[0] == SCSI_OPCODE_READ10) || (cmd[0] == SCSI_OPCODE_WRITE10))
+    {
+        pUdmaParams->lowLBAAddress =
+        (((MV_U32) cmd[5]) << 0) |
+        (((MV_U32) cmd[4]) << 8) |
+        (((MV_U32) cmd[3]) << 16) |
+        (((MV_U32) cmd[2]) << 24);
+
+        sectors = ((MV_U16) cmd[8]) |
+		(((MV_U16) cmd[7]) << 8);
+        if (cmd[1] & MV_BIT3)
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%d %d: READ10/WRITE10 command "
+                     "received with FUA\n",
+                     pSataAdapter->adapterId, pScb->bus);
+            pUdmaParams->FUA = MV_TRUE;
+        }
+    }
+    else
+    {
+        pUdmaParams->lowLBAAddress =
+        (((MV_U32) cmd[9]) << 0) |
+        (((MV_U32) cmd[8]) << 8) |
+        (((MV_U32) cmd[7]) << 16) |
+        (((MV_U32) cmd[6]) << 24);
+
+        pUdmaParams->highLBAAddress =
+        (((MV_U32) cmd[5]) << 0) |
+        (((MV_U32) cmd[4]) << 8) |
+        (((MV_U32) cmd[3]) << 16) |
+        (((MV_U32) cmd[2]) << 24);
+
+        sectors = (cmd[13]) |
+		  (cmd[12] << 8) |
+		  (cmd[11] << 16) |
+		  (cmd[10] << 24);
+
+        if (cmd[1] & MV_BIT3)
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%d %d: READ16/WRITE16 command "
+                     "received with FUA\n",
+                     pSataAdapter->adapterId, pScb->bus);
+            pUdmaParams->FUA = MV_TRUE;
+        }
+    }
+    LBA = ((MV_U64)pUdmaParams->highLBAAddress << 32) | (MV_U64)pUdmaParams->lowLBAAddress;
+    pScb->isExtended = pUdmaParams->isEXT = pDriveData->identifyInfo.LBA48Supported;
+
+    /* If READ10 / WRITE10 with 0 sectors (no data transfer), then complete */
+    /* the command with OK.                                                 */
+    /* If READ6 / WRITE6 with 0 sectors, seemse the Windows have problem with */
+    /* this and doesn't allocate and buffers for this ; so complete this    */
+    /* command with ILLEGAL REQUEST sense and INVLAID CDB in addition sense */
+    /* code.                                                                */
+
+    if (sectors == 0)
+    {
+        if ((cmd[0] == SCSI_OPCODE_READ10) || (cmd[0] == SCSI_OPCODE_WRITE10) || 
+	    (cmd[0] == SCSI_OPCODE_READ16) || (cmd[0] == SCSI_OPCODE_WRITE16))
+        {
+
+            if (checkLBAOutOfRange(pSataAdapter, pScb,
+                                   pDriveData->identifyInfo.ATADiskSize,
+                                   LBA, 0) == MV_TRUE)
+            {
+                return MV_SCSI_COMMAND_STATUS_COMPLETED;
+            }
+            pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+            pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+            pScb->dataTransfered = 0;
+            pScb->senseDataLength = 0;
+#ifdef MV_LOGGER
+            reportScbCompletion(pSataAdapter, pScb);
+#endif
+            pScb->completionCallBack(pSataAdapter, pScb);
+            return MV_SCSI_COMMAND_STATUS_COMPLETED;
+        }
+        else
+        {
+            /* READ6 / WRITE6 with sector count 0, which means 256 sectors */
+            sectors = 256;
+        }
+    }
+    if (checkLBAOutOfRange(pSataAdapter, pScb,
+                           pDriveData->identifyInfo.ATADiskSize,
+                           LBA, sectors) == MV_TRUE)
+    {
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    /* If trying to send more than 256 sectors or DataTransferLength field is
+     * not equal to number of sectors request in CDB then return invalid
+     * request.
+     */
+
+    if (((sectors > 256) && (pUdmaParams->isEXT == MV_FALSE)) ||
+        ((sectors * ATA_SECTOR_SIZE) != pScb->dataBufferLength))
+    {
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCB;
+        pScb->dataTransfered = 0;
+        pScb->senseDataLength = 0;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    if ((cmd[0] == SCSI_OPCODE_READ6) || (cmd[0] == SCSI_OPCODE_READ10) || 
+	(cmd[0] == SCSI_OPCODE_READ16))
+    {
+        pUdmaParams->readWrite = MV_UDMA_TYPE_READ;
+    }
+    pScb->dataTransfered = sectors * ATA_SECTOR_SIZE;
+    pScb->udmaType = pUdmaParams->readWrite;
+    pScb->commandType = MV_QUEUED_COMMAND_TYPE_UDMA;
+    pScb->LowLbaAddress = pUdmaParams->lowLBAAddress;
+    pUdmaParams->numOfSectors = sectors;
+
+    if ((sectors == 256) &&
+        ((pDriveData->identifyInfo.LBA48Supported == MV_FALSE)))
+    {
+        pUdmaParams->numOfSectors = 0;
+    }
+    pUdmaParams->prdLowAddr = pScb->PRDTableLowPhyAddress;
+    pUdmaParams->prdHighAddr = pScb->PRDTableHighPhyAddress;
+
+    result = mvSataQueueCommand(pSataAdapter, pScb->bus, pCommandInfo);
+    if (result != MV_QUEUE_COMMAND_RESULT_OK)
+    {
+        checkQueueCommandResult(pScb, result);
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    /*update statistics*/
+
+    pAdapterExt->totalAccumulatedOutstanding[pScb->bus] +=
+    mvSataNumOfDmaCommands(pSataAdapter,pScb->bus);
+    pDriveData->stats.totalIOs++;
+    pDriveData->stats.totalSectorsTransferred += pUdmaParams->numOfSectors;
+
+    return MV_SCSI_COMMAND_STATUS_QUEUED;
+}
+
+
+/*******************************************************************************
+ *  mvScsiAtaStartStopCommand - Translate SCSI START_STOP UNIT command
+ *
+ *  DESCRIPTION:Enqueue an ATA command to issue STANDBY (to stop) or READ VERIFY
+ *              (to start). Perhaps these commands should be preceded by
+ *              CHECK POWER MODE to see what power mode the device is already in.
+ *              [See SAT revision 5 at www.t10.org]
+ *
+ *  INPUT:
+ *          pSataAdapter - pointer to the SATA adapter data structure.
+ *          pScb         - SCSI command block structure.
+ *
+ *  RETURNS:
+ *          MV_SCSI_COMMAND_STATUS_COMPLETED or MV_SCSI_COMMAND_STATUS_QUEUED.
+ *******************************************************************************/
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaStartStopCommand(IN MV_SATA_ADAPTER        *pSataAdapter,
+                                                              IN MV_SATA_SCSI_CMD_BLOCK *pScb)
+{
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = pScb->pCommandInfo;
+#else
+    MV_QUEUE_COMMAND_INFO   commandInfo;
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = &commandInfo;
+#endif
+    MV_QUEUE_COMMAND_RESULT result;
+    MV_U8                   *cdb = pScb->ScsiCdb;
+    MV_U32                  sectors = 0;
+    MV_U8                   command;
+
+    if (pScb->ScsiCdbLength < 5)
+    {
+        pScb->dataTransfered = 0;
+        pScb->senseDataLength = 0;
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCB;
+        goto error;
+    }
+    /* FIXME : Don't know how to handle Immed flag. */
+    if (cdb[1] & 0x1) {
+        ;
+    }
+    if (cdb[4] & 0x2)   /* LOEJ bit set not supported */
+
+    {
+        pScb->dataTransfered = 0;
+        pScb->senseDataLength = 0;
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCB;
+        goto error;
+    }
+    if (((cdb[4] >> 6) & 0xf) != 0)
+    {
+        pScb->dataTransfered = 0;
+        pScb->senseDataLength = 0;
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCB;
+        goto error;
+    }
+
+    if (cdb[4] & 0x1)   /* START UNIT command */
+    {
+        sectors = 1;
+        command = MV_ATA_COMMAND_READ_VERIFY_SECTORS;
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, 
+                 "Sending VERIFY command (emulate SCSI START UNIT): channel %d, Srb %p\n", pScb->bus, pScb);
+    }
+    else                /* STOP UNIT command */
+    {
+        command = MV_ATA_COMMAND_STANDBY_IMMEDIATE;
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, 
+                 "Sending STANDBY_IMMEDIATE command (emulate SCSI STOP UNIT): channel %d, Srb %p\n", pScb->bus, pScb);
+    }
+
+    memset(pCommandInfo, 0, sizeof(MV_QUEUE_COMMAND_INFO));
+    pScb->commandType = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pCommandInfo->type = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pCommandInfo->PMPort = pScb->target;
+    pCommandInfo->commandParams.NoneUdmaCommand.protocolType = MV_NON_UDMA_PROTOCOL_NON_DATA;
+    pCommandInfo->commandParams.NoneUdmaCommand.isEXT = MV_FALSE;
+    pCommandInfo->commandParams.NoneUdmaCommand.bufPtr = NULL;
+    pCommandInfo->commandParams.NoneUdmaCommand.count = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.features = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.sectorCount = sectors;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaLow = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaMid = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.device = (MV_U8)(MV_BIT6);
+    pCommandInfo->commandParams.NoneUdmaCommand.command = command;
+    pCommandInfo->commandParams.NoneUdmaCommand.callBack = SALCommandCompletionCB;
+    pCommandInfo->commandParams.NoneUdmaCommand.commandId = (MV_VOID_PTR) pScb;
+
+    result = mvSataQueueCommand(pSataAdapter, pScb->bus, pCommandInfo);
+    if (result == MV_QUEUE_COMMAND_RESULT_OK)
+        return MV_SCSI_COMMAND_STATUS_QUEUED;
+    else
+        checkQueueCommandResult(pScb, result);
+
+error:
+#ifdef MV_LOGGER
+    reportScbCompletion(pSataAdapter, pScb);
+#endif
+    pScb->completionCallBack(pSataAdapter, pScb);
+    return MV_SCSI_COMMAND_STATUS_COMPLETED;
+}
+
+
+static inline MV_NON_UDMA_PROTOCOL mvScsiAtaPassThru_MapProto(MV_U8 byte)
+{
+    switch((byte & 0x1e) >> 1)
+    {
+        case 3:  /* Non-data */
+            return MV_NON_UDMA_PROTOCOL_NON_DATA;
+	    case 4:  /* PIO Data-in */
+        case 10: /* UDMA Data-in */
+	        return MV_NON_UDMA_PROTOCOL_PIO_DATA_IN;
+        case 5:  /* PIO Data-out */
+	    case 11: /* UDMA Data-Out */
+            return MV_NON_UDMA_PROTOCOL_PIO_DATA_OUT;
+
+        case 0:  /* Hard Reset */
+        case 1:  /* SRST */
+        case 6:  /* DMA */
+        case 8:  /* Device Diagnostic */
+        case 9:  /* Device Reset */
+        case 7:  /* DMA Queued */
+        case 12: /* FPDMA */
+        case 15: /* Return Response Info */
+        default: /* Reserved */
+            break;
+    }
+    return MV_NON_UDMA_PROTOCOL_UNKNOWN;
+}
+
+/*
+ *      mvScsiAtaPassThru - Enqueue an ATA pass-thru command
+ *
+ *      INPUT:
+ *      pSataAdapter - pointer to the SATA adapter data structure.
+ *      pScb         - SCSI command block structure.
+ *
+ *      RETURNS:
+ *      MV_SCSI_COMMAND_STATUS_COMPLETED or MV_SCSI_COMMAND_STATUS_QUEUED.
+ */
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaPassThru(IN MV_SATA_ADAPTER*    pSataAdapter,
+                                                       IN MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = pScb->pCommandInfo;
+#else
+    MV_QUEUE_COMMAND_INFO   commandInfo;
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = &commandInfo;
+#endif
+    MV_QUEUE_COMMAND_RESULT result;
+    MV_NON_UDMA_PROTOCOL    protocolType;
+    MV_U8                   *cdb = pScb->ScsiCdb;
+
+    memset(pCommandInfo, 0, sizeof(MV_QUEUE_COMMAND_INFO));
+
+    protocolType = mvScsiAtaPassThru_MapProto(cdb[1]);
+    if (protocolType == MV_NON_UDMA_PROTOCOL_UNKNOWN)
+    {
+        pScb->dataTransfered = 0;
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCB;
+        setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+	             SCSI_ADSENSE_INVALID_CDB, 0);
+        goto error;
+    }
+    /* PIO command can process a "multi_count" number of sectors. */
+    if (cdb[1] & 0xe0)
+    {
+        /*
+         * FIXME : How to check the passed "multi_count" value ?
+         *         Please remove the unused attribute when unneeded.
+         */
+        unsigned int multi_count __attribute__((unused)) = 1 << (cdb[1] >> 5);
+    }
+
+    if (cdb[0] == SCSI_OPCODE_ATA16)
+    {
+        /* 16-byte CDB can contain extend commands. */
+        if (cdb[1] & 0x01)
+        {
+            pCommandInfo->commandParams.NoneUdmaCommand.features =	MV_LE16_TO_CPU(*((MV_U16 *) &cdb[3]));
+            pCommandInfo->commandParams.NoneUdmaCommand.sectorCount =   MV_LE16_TO_CPU(*((MV_U16 *) &cdb[5]));
+            pCommandInfo->commandParams.NoneUdmaCommand.lbaLow =        MV_LE16_TO_CPU(*((MV_U16 *) &cdb[7]));
+            pCommandInfo->commandParams.NoneUdmaCommand.lbaMid =        MV_LE16_TO_CPU(*((MV_U16 *) &cdb[9]));
+            pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh =       MV_LE16_TO_CPU(*((MV_U16 *) &cdb[11]));
+            pCommandInfo->commandParams.NoneUdmaCommand.isEXT =         MV_TRUE;
+        }
+        else
+        {
+            pCommandInfo->commandParams.NoneUdmaCommand.features = cdb[4];
+            pCommandInfo->commandParams.NoneUdmaCommand.sectorCount = cdb[6];
+            pCommandInfo->commandParams.NoneUdmaCommand.lbaLow = cdb[8];
+            pCommandInfo->commandParams.NoneUdmaCommand.lbaMid = cdb[10];
+            pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh = cdb[12];
+            pCommandInfo->commandParams.NoneUdmaCommand.isEXT = MV_FALSE;
+        }
+        pCommandInfo->commandParams.NoneUdmaCommand.device = cdb[13];
+        pCommandInfo->commandParams.NoneUdmaCommand.command = cdb[14];
+    }
+    else
+    {
+        pCommandInfo->commandParams.NoneUdmaCommand.features = cdb[3];
+        pCommandInfo->commandParams.NoneUdmaCommand.sectorCount = cdb[4];
+        pCommandInfo->commandParams.NoneUdmaCommand.lbaLow = cdb[5];
+        pCommandInfo->commandParams.NoneUdmaCommand.lbaMid = cdb[6];
+        pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh = cdb[7];
+        pCommandInfo->commandParams.NoneUdmaCommand.device = cdb[8];
+        pCommandInfo->commandParams.NoneUdmaCommand.command = cdb[9];
+        pCommandInfo->commandParams.NoneUdmaCommand.isEXT = MV_FALSE;
+    }
+    pScb->commandType = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pCommandInfo->type = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pCommandInfo->PMPort = pScb->target;
+    pCommandInfo->commandParams.NoneUdmaCommand.protocolType = protocolType;
+    pCommandInfo->commandParams.NoneUdmaCommand.bufPtr = (MV_U16_PTR)pScb->pDataBuffer;
+    /* count is in words (double byte), so we devide by 2 */
+    pCommandInfo->commandParams.NoneUdmaCommand.count = pScb->dataBufferLength >> 1;
+    pCommandInfo->commandParams.NoneUdmaCommand.callBack = SALCommandCompletionCB;
+    pCommandInfo->commandParams.NoneUdmaCommand.commandId = (MV_VOID_PTR) pScb;
+
+    result = mvSataQueueCommand(pSataAdapter, pScb->bus, pCommandInfo);
+    if (result == MV_QUEUE_COMMAND_RESULT_OK)
+        return MV_SCSI_COMMAND_STATUS_QUEUED;
+    else
+        checkQueueCommandResult(pScb, result);
+
+error:
+#ifdef MV_LOGGER
+    reportScbCompletion(pSataAdapter, pScb);
+#endif
+    pScb->completionCallBack(pSataAdapter, pScb);
+    return MV_SCSI_COMMAND_STATUS_COMPLETED;
+}
+
+
+/*******************************************************************************
+* mvScsiAtaGetReadCapacityData - Get the SCSI-3 Read Capacity (10h/16h) data
+*
+* DESCRIPTION: This function fills the data buffer with Scsi Read Capacity 10 or
+*       Read Capacity 16 data according to the disk size as it is reported in
+*       the ATA Identify data.
+*
+* INPUT:
+*   pSataAdapter    - pointer to the SATA adapter data structure.
+*   pScb->bus    - the index of the specific SATA channel.
+*
+* OUTPUT:
+* RETURN:
+*   MV_TRUE on success, MV_FALSE on failure.
+*
+* COMMENTS:
+*   No sanity check is done for the parameters.
+*
+*******************************************************************************/
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaGetReadCapacityData(IN MV_SATA_ADAPTER*    pSataAdapter,
+                                                                 IN    MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+    MV_U32  lastAddressableLBA;
+    MV_U8   *buff;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+
+    if ((pScb->ScsiCdb[8] & MV_BIT1) == 0)
+    {
+        if (pScb->ScsiCdb[2] || pScb->ScsiCdb[3] ||pScb->ScsiCdb[4] ||
+            pScb->ScsiCdb[5])
+        {
+
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Inquiry completed with error: PMI = 0, LBA != 0\n",
+                     pSataAdapter->adapterId, pScb->bus);
+            setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+                         SCSI_ADSENSE_INVALID_CDB, 0);
+            pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+            pScb->dataTransfered = 0;
+            pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+#ifdef MV_LOGGER
+            reportScbCompletion(pSataAdapter, pScb);
+#endif
+            pScb->completionCallBack(pSataAdapter, pScb);
+            return MV_SCSI_COMMAND_STATUS_COMPLETED;
+        }
+    }
+    if((pDriveData->identifyInfo.ATADiskSize >> 32) & 0xFFFFFFFF)
+    {
+	    lastAddressableLBA = 0xFFFFFFFF;
+    }
+    else
+    {
+	    lastAddressableLBA = pDriveData->identifyInfo.ATADiskSize - 1;
+    }
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "MVSATA: last Addressable sector = 0x%x "
+             " (sec size=%d bytes)\n", lastAddressableLBA, ATA_SECTOR_SIZE);
+
+    /* The disk size as indicated by the ATA spec is the total addressable
+     * secotrs on the drive ; while the SCSI translation of the command
+     * should be the last addressable sector.
+     */
+    buff = pScb->pDataBuffer;
+    memset(buff, 0, pScb->dataBufferLength);
+    buff[0] = (MV_U8)(lastAddressableLBA >> 24);
+    buff[1] = (MV_U8)((lastAddressableLBA >> 16) & 0xff);
+    buff[2] = (MV_U8)((lastAddressableLBA >> 8) & 0xff);
+    buff[3] = (MV_U8)(lastAddressableLBA & 0xff);
+    buff[4] = 0;
+    buff[5] = 0;
+    buff[6] = (MV_U8)((ATA_SECTOR_SIZE >> 8) & 0xff);           /* 512 byte sectors */
+    buff[7] = (MV_U8)(ATA_SECTOR_SIZE & 0xff);
+    pScb->dataTransfered = 8;
+    pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+    pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+    pScb->senseDataLength = 0;
+#ifdef MV_LOGGER
+    reportScbCompletion(pSataAdapter, pScb);
+#endif
+    pScb->completionCallBack(pSataAdapter, pScb);
+    return MV_SCSI_COMMAND_STATUS_COMPLETED;
+}
+
+/*******************************************************************************
+* mvScsiAtaGetReadCapacity16Data - Get the SCSI-3 Read Capacity (16h) data
+*
+* DESCRIPTION: This function fills the data buffer with Scsi Read Capacity 16
+* data according to the disk size as it is reported in
+*       the ATA Identify data.
+*
+* INPUT:
+*   pSataAdapter    - pointer to the SATA adapter data structure.
+*   pScb->bus    - the index of the specific SATA channel.
+*
+* OUTPUT:
+* RETURN:
+*   MV_TRUE on success, MV_FALSE on failure.
+*
+* COMMENTS:
+*   No sanity check is done for the parameters.
+*
+*******************************************************************************/
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaGetReadCapacity16Data(IN MV_SATA_ADAPTER*    pSataAdapter,
+                                                                   IN    MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+    MV_U64  lastAddressableLBA;
+    MV_U8   *buff;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+
+    if ((pScb->ScsiCdb[14] & MV_BIT1) == 0)
+    {
+        if (pScb->ScsiCdb[2] || pScb->ScsiCdb[3] ||pScb->ScsiCdb[4] ||
+            pScb->ScsiCdb[5] || pScb->ScsiCdb[6] ||pScb->ScsiCdb[7] ||
+	    pScb->ScsiCdb[8] || pScb->ScsiCdb[9])
+        {
+
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Read Capacity completed with error: PMI = 0, LBA != 0\n",
+                     pSataAdapter->adapterId, pScb->bus);
+            setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+                         SCSI_ADSENSE_INVALID_CDB, 0);
+            pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+            pScb->dataTransfered = 0;
+            pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+#ifdef MV_LOGGER
+            reportScbCompletion(pSataAdapter, pScb);
+#endif
+            pScb->completionCallBack(pSataAdapter, pScb);
+            return MV_SCSI_COMMAND_STATUS_COMPLETED;
+        }
+    }
+
+    lastAddressableLBA = pDriveData->identifyInfo.ATADiskSize - 1;
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "MVSATA: last Addressable sector = 0x%x "
+             " (sec size=%d bytes)\n", lastAddressableLBA, ATA_SECTOR_SIZE);
+
+    /* The disk size as indicated by the ATA spec is the total addressable
+     * secotrs on the drive ; while the SCSI translation of the command
+     * should be the last addressable sector.
+     */
+    buff = pScb->pDataBuffer;
+    memset(buff, 0, pScb->dataBufferLength);
+    buff[0] = (MV_U8)((lastAddressableLBA >> 56) & 0xff);
+    buff[1] = (MV_U8)((lastAddressableLBA >> 48) & 0xff);
+    buff[2] = (MV_U8)((lastAddressableLBA >> 40) & 0xff);
+    buff[3] = (MV_U8)((lastAddressableLBA >> 32) & 0xff);
+    buff[4] = (MV_U8)((lastAddressableLBA >> 24) & 0xff);
+    buff[5] = (MV_U8)((lastAddressableLBA >> 16) & 0xff);
+    buff[6] = (MV_U8)((lastAddressableLBA >> 8) & 0xff);
+    buff[7] = (MV_U8)(lastAddressableLBA & 0xff);
+    buff[8] = 0;
+    buff[9] = 0;
+    buff[10] = (MV_U8)((ATA_SECTOR_SIZE >> 8) & 0xff);           /* 512 byte sectors */
+    buff[11] = (MV_U8)(ATA_SECTOR_SIZE & 0xff);
+    pScb->dataTransfered = 8;
+    pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+    pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+    pScb->senseDataLength = 0;
+#ifdef MV_LOGGER
+    reportScbCompletion(pSataAdapter, pScb);
+#endif
+    pScb->completionCallBack(pSataAdapter, pScb);
+    return MV_SCSI_COMMAND_STATUS_COMPLETED;
+}
+
+
+/*******************************************************************************
+* mvScsiAtaReportLuns - handle the SCSI-3 Report LUNS
+*
+* DESCRIPTION: Report 1 LUN
+*
+* INPUT:
+*   pSataAdapter    - pointer to the SATA adapter data structure.
+*   pScb->bus    - the index of the specific SATA channel.
+*
+* OUTPUT:
+* RETURN:
+*   MV_TRUE on success, MV_FALSE on failure.
+*
+* COMMENTS:
+*   No sanity check is done for the parameters.
+*
+*******************************************************************************/
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaReportLuns(IN MV_SATA_ADAPTER*    pSataAdapter,
+							IN    MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+	MV_U8   *buff;
+
+
+    buff = pScb->pDataBuffer;
+    memset(buff, 0, pScb->dataBufferLength);
+    buff[3] = 8; /* 1 lun*/
+    pScb->dataTransfered = 16;
+    pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+    pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+    pScb->senseDataLength = 0;
+#ifdef MV_LOGGER
+    reportScbCompletion(pSataAdapter, pScb);
+#endif
+    pScb->completionCallBack(pSataAdapter, pScb);
+    return MV_SCSI_COMMAND_STATUS_COMPLETED;
+}
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaSendVerifyCommand(IN MV_SATA_ADAPTER*    pSataAdapter,
+                                                               IN MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = pScb->pCommandInfo;
+#else
+    MV_QUEUE_COMMAND_INFO   commandInfo;
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = &commandInfo;
+#endif
+    MV_QUEUE_COMMAND_RESULT result;
+    MV_U8                   *cmd = pScb->ScsiCdb;
+    MV_U64                   LbaAddress;
+    MV_U32                  sectors;
+    MV_U16                  commands;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+    MV_SAL_ADAPTER_EXTENSION *pAdapterExt = pScb->pSalAdapterExtension;
+
+    if (cmd[0] == SCSI_OPCODE_VERIFY6)
+    {
+	    LbaAddress =
+		    ( (unsigned)  cmd[3]) |
+		    (((unsigned)  cmd[2]) << 8) |
+		    ((((unsigned) cmd[1]) & 0x1f) << 16);
+	    sectors = (unsigned) cmd[4];
+    }
+    else if (cmd[0] == SCSI_OPCODE_VERIFY10)
+    {
+	    LbaAddress =
+		    (((unsigned) cmd[5]) << 0) |
+		    (((unsigned) cmd[4]) << 8) |
+		    (((unsigned) cmd[3]) << 16) |
+		    (((unsigned) cmd[2]) << 24);
+	    
+	    
+	    sectors = ((unsigned) cmd[8]) |
+		    (((unsigned) cmd[7]) << 8);
+    }
+    else
+    {
+	    LbaAddress =
+		    (((MV_U64) cmd[9]) << 0) |
+		    (((MV_U64) cmd[8]) << 8) |
+		    (((MV_U64) cmd[7]) << 16) |
+		    (((MV_U64) cmd[6]) << 24) |
+		    (((MV_U64) cmd[5]) << 32) |
+		    (((MV_U64) cmd[4]) << 40) |
+		    (((MV_U64) cmd[3]) << 48) |
+		    (((MV_U64) cmd[2]) << 56);
+
+
+	    sectors = 
+		    ((unsigned) cmd[13]) |
+		    (((unsigned) cmd[12]) << 8) |
+		    (((unsigned) cmd[11]) << 16) |
+		    (((unsigned) cmd[10]) << 24);
+    }
+
+    if (sectors == 0)
+    {
+        if ((cmd[0] == SCSI_OPCODE_VERIFY10) || (cmd[0] == SCSI_OPCODE_VERIFY16))
+        {
+            if (checkLBAOutOfRange(pSataAdapter, pScb,
+                                   pDriveData->identifyInfo.ATADiskSize,
+                                   LbaAddress, 0) == MV_TRUE)
+            {
+                return MV_SCSI_COMMAND_STATUS_COMPLETED;
+            }
+            pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+            pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+            pScb->senseDataLength = 0;
+            pScb->dataTransfered = 0;
+#ifdef MV_LOGGER
+            reportScbCompletion(pSataAdapter, pScb);
+#endif
+            pScb->completionCallBack(pSataAdapter, pScb);
+            return MV_SCSI_COMMAND_STATUS_COMPLETED;
+        }
+        else
+        {
+            /* If VERIFY6 to 48bit device, then 256 sectors is OK ; otherwise
+            the CORE driver must get sector count of 0 in order to understand that
+            256 sectors must be transferred
+            */
+
+            if (pDriveData->identifyInfo.LBA48Supported == MV_TRUE)
+            {
+                sectors = 256;
+            }
+            else
+            {
+                sectors = 0;
+            }
+        }
+        if (checkLBAOutOfRange(pSataAdapter, pScb,
+                               pDriveData->identifyInfo.ATADiskSize,
+                               LbaAddress, 256) == MV_TRUE)
+        {
+            return MV_SCSI_COMMAND_STATUS_COMPLETED;
+        }
+    }
+    else
+    {
+        if (checkLBAOutOfRange(pSataAdapter, pScb,
+                               pDriveData->identifyInfo.ATADiskSize,
+                               LbaAddress, sectors) == MV_TRUE)
+        {
+            return MV_SCSI_COMMAND_STATUS_COMPLETED;
+        }
+    }
+
+    pScb->commandType = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pScb->LowLbaAddress = (MV_U32)(LbaAddress & 0xFFFFFFFF);
+//    pScb->highLbaAddress = (MV_U32)(LbaAddress >> 32);
+
+    if (pDriveData->identifyInfo.LBA48Supported == MV_TRUE)
+    {
+        pScb->splitCount = 1;
+        pScb->isExtended = MV_TRUE;
+        pCommandInfo->type = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+        pCommandInfo->PMPort = pScb->target;
+        pCommandInfo->commandParams.NoneUdmaCommand.bufPtr = NULL;
+        pCommandInfo->commandParams.NoneUdmaCommand.callBack = SALCommandCompletionCB;
+        pCommandInfo->commandParams.NoneUdmaCommand.command = MV_ATA_COMMAND_READ_VERIFY_SECTORS_EXT;
+        pCommandInfo->commandParams.NoneUdmaCommand.commandId = (MV_VOID_PTR) pScb;
+        pCommandInfo->commandParams.NoneUdmaCommand.count = 0;
+        pCommandInfo->commandParams.NoneUdmaCommand.features = 0;
+        pCommandInfo->commandParams.NoneUdmaCommand.isEXT = MV_TRUE;
+        pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh = 
+	(MV_U16)(((LbaAddress & 0xff0000000000ULL) >> 40) | ((LbaAddress & 0xff0000) >> 16));
+        pCommandInfo->commandParams.NoneUdmaCommand.lbaMid = 
+        (MV_U16)(((LbaAddress & 0xff00000000ULL) >> 32) | ((LbaAddress & 0xff00) >> 8));
+        pCommandInfo->commandParams.NoneUdmaCommand.lbaLow =
+        (MV_U16)(((LbaAddress & 0xff000000) >> 24) | (LbaAddress & 0xff));
+        pCommandInfo->commandParams.NoneUdmaCommand.protocolType = MV_NON_UDMA_PROTOCOL_NON_DATA;
+        pCommandInfo->commandParams.NoneUdmaCommand.sectorCount = sectors;
+        pCommandInfo->commandParams.NoneUdmaCommand.device = (MV_U8)(MV_BIT6);
+
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Sending EXT Verify command: channel %d, code %x lba %x(%x.%x.%x), sectors %d[%d] Srb %p\n",
+                 pScb->bus, cmd[0], LbaAddress,
+                 pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh,
+                 pCommandInfo->commandParams.NoneUdmaCommand.lbaMid,
+                 pCommandInfo->commandParams.NoneUdmaCommand.lbaLow,
+                 pCommandInfo->commandParams.NoneUdmaCommand.sectorCount,
+                 mvSataNumOfDmaCommands(pSataAdapter,pScb->bus), pScb);
+
+        result = mvSataQueueCommand(pSataAdapter, pScb->bus, pCommandInfo);
+
+        if (result != MV_QUEUE_COMMAND_RESULT_OK)
+        {
+            checkQueueCommandResult(pScb, result);
+#ifdef MV_LOGGER
+            reportScbCompletion(pSataAdapter, pScb);
+#endif
+            pScb->completionCallBack(pSataAdapter, pScb);
+            return MV_SCSI_COMMAND_STATUS_COMPLETED;
+        }
+        /* update stats*/
+        pAdapterExt->totalAccumulatedOutstanding[pScb->bus] +=
+        mvSataNumOfDmaCommands(pSataAdapter,pScb->bus);
+        pDriveData->stats.totalIOs++;
+        pDriveData->stats.totalSectorsTransferred += sectors;
+
+    }
+    else
+    {
+        /* The following only in case command is VERIFY 6 with 0 sector count */
+        if (sectors == 0)
+        {
+            commands = 1;
+        }
+        else
+        {
+            commands = (MV_U16)((((MV_U32)sectors + 0xff) & 0x1ff00) >> 8);
+        }
+
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "split Verify to %d commands: channel %d, lba %x, sectors %d\n",
+                 commands,pScb->bus, LbaAddress, sectors);
+
+        pScb->splitCount = commands;
+        pScb->sequenceNumber = 0;
+        pScb->isExtended = MV_FALSE;
+        mvScsiAtaSendSplittedVerifyCommand(pScb);
+    }
+    return MV_SCSI_COMMAND_STATUS_QUEUED;
+}
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaSeek(IN MV_SATA_ADAPTER    *pSataAdapter,
+                                                  IN  MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+    MV_U32 lbaAddress;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+
+    lbaAddress = (((MV_U32) pScb->ScsiCdb[5]) << 0) |
+                 (((MV_U32) pScb->ScsiCdb[4]) << 8) |
+                 (((MV_U32) pScb->ScsiCdb[3]) << 16) |
+                 (((MV_U32) pScb->ScsiCdb[2]) << 24);
+    if (checkLBAOutOfRange(pSataAdapter, pScb,
+                           pDriveData->identifyInfo.ATADiskSize,
+                           lbaAddress, 0) == MV_TRUE)
+    {
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+    pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+    pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+    pScb->dataTransfered = 0;
+    pScb->senseDataLength = 0;
+#ifdef MV_LOGGER
+    reportScbCompletion(pSataAdapter, pScb);
+#endif
+    pScb->completionCallBack(pSataAdapter, pScb);
+    return MV_SCSI_COMMAND_STATUS_COMPLETED;
+
+}
+
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaReassignBlocks(IN MV_SATA_ADAPTER    *pSataAdapter,
+                                                            IN MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+    setSenseData(pScb, SCSI_SENSE_HARDWARE_ERROR, 0x32, 0);
+    pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+    pScb->dataTransfered = 0;
+    pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_ATA_FAILED;
+#ifdef MV_LOGGER
+    reportScbCompletion(pSataAdapter, pScb);
+#endif
+    pScb->completionCallBack(pSataAdapter, pScb);
+    return MV_TRUE;
+
+}
+
+
+#ifdef MV_SATA_SUPPORT_READ_WRITE_LONG
+static MV_SCSI_COMMAND_STATUS_TYPE mvScsiAtaWriteLong(IN MV_SATA_ADAPTER    *pSataAdapter,
+                                                      IN  MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = pScb->pCommandInfo;
+#else
+    MV_QUEUE_COMMAND_INFO   commandInfo;
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = &commandInfo;
+#endif
+    MV_QUEUE_COMMAND_RESULT result;
+    MV_U32                  LBA;
+    MV_U16                  eccBytes;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+    MV_SAL_ADAPTER_EXTENSION *pAdapterExt = pScb->pSalAdapterExtension;
+
+    memset(pCommandInfo, 0, sizeof(MV_QUEUE_COMMAND_INFO));
+
+
+    LBA = (((MV_U32) pScb->ScsiCdb[5]) << 0) |
+          (((MV_U32) pScb->ScsiCdb[4]) << 8) |
+          (((MV_U32) pScb->ScsiCdb[3]) << 16) |
+          (((MV_U32) pScb->ScsiCdb[2]) << 24);
+
+    eccBytes = (MV_U16)pScb->ScsiCdb[8];
+
+    if ((pScb->ScsiCdb[7] != 2) || ((eccBytes != 4) && (eccBytes != 8)))
+    {
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCB;
+        pScb->dataTransfered = 0;
+        pScb->senseDataLength = 0;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+    if (checkLBAOutOfRange(pSataAdapter, pScb,
+                           pDriveData->identifyInfo.ATADiskSize,
+                           LBA, 1) == MV_TRUE)
+    {
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    /*if (checkLBAOutOfRange(pSataAdapter, pScb, MV_BIT28 - 2,
+                        LBA, 1) == MV_TRUE)
+    {
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }*/
+    if (LBA & (MV_BIT31|MV_BIT30|MV_BIT29|MV_BIT28))
+    {
+
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Error LBA (0x%x) out of range.\n", LBA);
+
+        setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+                     SCSI_ADSENSE_ILLEGAL_BLOCK, 0);
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->dataTransfered = 0;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_TRUE;
+    }
+    pScb->commandType = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+
+    pCommandInfo->type = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pCommandInfo->PMPort = pScb->target;
+    pCommandInfo->commandParams.NoneUdmaCommand.bufPtr = (MV_U16_PTR)pScb->pDataBuffer;
+    pCommandInfo->commandParams.NoneUdmaCommand.isEXT = MV_FALSE;
+    pCommandInfo->commandParams.NoneUdmaCommand.callBack = SALCommandCompletionCB;
+    pCommandInfo->commandParams.NoneUdmaCommand.commandId = (MV_VOID_PTR) pScb;
+    pCommandInfo->commandParams.NoneUdmaCommand.count = 256+4;
+    pCommandInfo->commandParams.NoneUdmaCommand.features = eccBytes;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh = (MV_U16)((LBA & 0xff0000) >> 16);
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaMid = (MV_U16)((LBA & 0xff00) >> 8) ;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaLow = (MV_U16)LBA & 0xff;
+    pCommandInfo->commandParams.NoneUdmaCommand.protocolType = MV_NON_UDMA_PROTOCOL_PIO_DATA_OUT;
+    pCommandInfo->commandParams.NoneUdmaCommand.sectorCount = 1;
+    pCommandInfo->commandParams.NoneUdmaCommand.device = MV_BIT6 | (MV_U16)((LBA & 0xf000000) >> 24) ;
+    pScb->isExtended = MV_FALSE;
+    pCommandInfo->commandParams.NoneUdmaCommand.command = 0x32;
+
+
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Sending WRITE LONG command : channel %d, code %x pScb %p\n",
+             pScb->bus, pScb->ScsiCdb[0], pScb);
+
+    result = mvSataQueueCommand(pSataAdapter, pScb->bus, pCommandInfo);
+    if (result != MV_QUEUE_COMMAND_RESULT_OK)
+    {
+        checkQueueCommandResult(pScb, result);
+        /* shoudl complete the Scsi request here*/
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+    /* update stats*/
+    pAdapterExt->totalAccumulatedOutstanding[pScb->bus] += mvSataNumOfDmaCommands(pSataAdapter,pScb->bus);
+    pDriveData->stats.totalIOs++;
+
+    return MV_SCSI_COMMAND_STATUS_QUEUED;
+}
+static MV_SCSI_COMMAND_STATUS_TYPE mvScsiAtaReadLong(IN MV_SATA_ADAPTER    *pSataAdapter,
+                                                     IN  MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = pScb->pCommandInfo;
+#else
+    MV_QUEUE_COMMAND_INFO   commandInfo;
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = &commandInfo;
+#endif
+    MV_QUEUE_COMMAND_RESULT result;
+    MV_U32                  LBA;
+    MV_U16                  eccBytes;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+    MV_SAL_ADAPTER_EXTENSION *pAdapterExt = pScb->pSalAdapterExtension;
+
+    memset(pCommandInfo, 0, sizeof(MV_QUEUE_COMMAND_INFO));
+
+
+    LBA = (((MV_U32) pScb->ScsiCdb[5]) << 0) |
+          (((MV_U32) pScb->ScsiCdb[4]) << 8) |
+          (((MV_U32) pScb->ScsiCdb[3]) << 16) |
+          (((MV_U32) pScb->ScsiCdb[2]) << 24);
+
+    eccBytes = (MV_U16)pScb->ScsiCdb[8];
+
+    if ((pScb->ScsiCdb[7] != 2) || ((eccBytes != 4) && (eccBytes != 8)))
+    {
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCB;
+        pScb->dataTransfered = 0;
+        pScb->senseDataLength = 0;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+    if (checkLBAOutOfRange(pSataAdapter, pScb,
+                           pDriveData->identifyInfo.ATADiskSize,
+                           LBA, 1) == MV_TRUE)
+    {
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    /*if (checkLBAOutOfRange(pSataAdapter, pScb, MV_BIT28 - 2,
+                        LBA, 1) == MV_TRUE)
+    {
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }*/
+    if (LBA & (MV_BIT31|MV_BIT30|MV_BIT29|MV_BIT28))
+    {
+
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Error LBA (0x%x) out of range.\n", LBA);
+
+        setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+                     SCSI_ADSENSE_ILLEGAL_BLOCK, 0);
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->dataTransfered = 0;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_TRUE;
+    }
+    pScb->commandType = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+
+    pCommandInfo->type = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pCommandInfo->PMPort = pScb->target;
+    pCommandInfo->commandParams.NoneUdmaCommand.bufPtr = (MV_U16_PTR)pScb->pDataBuffer;
+    pCommandInfo->commandParams.NoneUdmaCommand.isEXT = MV_FALSE;
+    pCommandInfo->commandParams.NoneUdmaCommand.callBack = SALCommandCompletionCB;
+    pCommandInfo->commandParams.NoneUdmaCommand.commandId = (MV_VOID_PTR) pScb;
+    pCommandInfo->commandParams.NoneUdmaCommand.count = 256+4;
+    pCommandInfo->commandParams.NoneUdmaCommand.features = eccBytes;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh = (MV_U16)((LBA & 0xff0000) >> 16);
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaMid = (MV_U16)((LBA & 0xff00) >> 8) ;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaLow = (MV_U16)LBA & 0xff;
+    pCommandInfo->commandParams.NoneUdmaCommand.protocolType = MV_NON_UDMA_PROTOCOL_PIO_DATA_IN;
+    pCommandInfo->commandParams.NoneUdmaCommand.sectorCount = 1;
+    pCommandInfo->commandParams.NoneUdmaCommand.device = MV_BIT6 | (MV_U16)((LBA & 0xf000000) >> 24) ;
+    pScb->isExtended = MV_FALSE;
+    pCommandInfo->commandParams.NoneUdmaCommand.command = 0x22;
+
+
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Sending READ LONG command : channel %d, code %x pScb %p\n",
+             pScb->bus, pScb->ScsiCdb[0], pScb);
+
+    result = mvSataQueueCommand(pSataAdapter, pScb->bus, pCommandInfo);
+    if (result != MV_QUEUE_COMMAND_RESULT_OK)
+    {
+        checkQueueCommandResult(pScb, result);
+        /* shoudl complete the Scsi request here*/
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+    /* update stats*/
+    pAdapterExt->totalAccumulatedOutstanding[pScb->bus] += mvSataNumOfDmaCommands(pSataAdapter,pScb->bus);
+    pDriveData->stats.totalIOs++;
+
+    return MV_SCSI_COMMAND_STATUS_QUEUED;
+}
+#endif
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaSendSyncCacheCommand(IN MV_SATA_ADAPTER    *pSataAdapter,
+                                                                      IN  MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = pScb->pCommandInfo;
+#else
+    MV_QUEUE_COMMAND_INFO   commandInfo;
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = &commandInfo;
+#endif
+    MV_QUEUE_COMMAND_RESULT result;
+    MV_U64                  LBA;
+    MV_U32                  sectors;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+    MV_SAL_ADAPTER_EXTENSION *pAdapterExt = pScb->pSalAdapterExtension;
+
+    /* Check if IMMED bit is set, if so then return ILLEGAL REQUEST */
+    if (pScb->ScsiCdb[1] & MV_BIT1)
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Synchronise cache completed with error:"
+                 " IMMED is set\n", pSataAdapter->adapterId,
+                 pScb->bus);
+
+        setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST, SCSI_ADSENSE_INVALID_CDB,
+                     0);
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->dataTransfered = 0;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    memset(pCommandInfo, 0, sizeof(MV_QUEUE_COMMAND_INFO));
+
+    if(pScb->ScsiCdb[0] == SCSI_OPCODE_SYNCHRONIZE_CACHE10)
+    {
+	    LBA = (((MV_U64) pScb->ScsiCdb[5]) << 0) |
+		    (((MV_U64) pScb->ScsiCdb[4]) << 8) |
+		    (((MV_U64) pScb->ScsiCdb[3]) << 16) |
+		    (((MV_U64) pScb->ScsiCdb[2]) << 24);
+	    
+	    sectors = ((MV_U32) pScb->ScsiCdb[8]) |
+		    (((MV_U32) pScb->ScsiCdb[7]) << 8);
+    }
+    else
+    {
+	    LBA = (((MV_U64) pScb->ScsiCdb[9]) << 0) |
+		    (((MV_U64) pScb->ScsiCdb[8]) << 8) |
+		    (((MV_U64) pScb->ScsiCdb[7]) << 16) |
+		    (((MV_U64) pScb->ScsiCdb[6]) << 24) |
+		    (((MV_U64) pScb->ScsiCdb[5]) << 32) |
+		    (((MV_U64) pScb->ScsiCdb[4]) << 40) |
+		    (((MV_U64) pScb->ScsiCdb[3]) << 48) |
+		    (((MV_U64) pScb->ScsiCdb[2]) << 56);
+	    
+	    sectors = ((MV_U32) pScb->ScsiCdb[13]) |
+		    (((MV_U32) pScb->ScsiCdb[12]) << 8) |
+		    (((MV_U32) pScb->ScsiCdb[11]) << 16) |
+		    (((MV_U32) pScb->ScsiCdb[10]) << 24);
+    }
+    if (checkLBAOutOfRange(pSataAdapter, pScb,
+                           pDriveData->identifyInfo.ATADiskSize,LBA, sectors)
+        == MV_TRUE)
+    {
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    pScb->commandType = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+
+    pCommandInfo->type = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pCommandInfo->PMPort = pScb->target;
+    pCommandInfo->commandParams.NoneUdmaCommand.bufPtr = NULL;
+    pCommandInfo->commandParams.NoneUdmaCommand.callBack = SALCommandCompletionCB;
+    pCommandInfo->commandParams.NoneUdmaCommand.commandId = (MV_VOID_PTR) pScb;
+    pCommandInfo->commandParams.NoneUdmaCommand.count = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.features = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaMid = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaLow = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.protocolType =
+    MV_NON_UDMA_PROTOCOL_NON_DATA;
+    pCommandInfo->commandParams.NoneUdmaCommand.sectorCount = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.device = (MV_U8)(MV_BIT6);
+
+    if (pDriveData->identifyInfo.LBA48Supported == MV_TRUE)
+    {
+        pScb->isExtended = MV_TRUE;
+        pCommandInfo->commandParams.NoneUdmaCommand.command = MV_ATA_COMMAND_FLUSH_CACHE_EXT;
+        pCommandInfo->commandParams.NoneUdmaCommand.isEXT = MV_TRUE;
+    }
+    else
+    {
+        pScb->isExtended = MV_FALSE;
+        pCommandInfo->commandParams.NoneUdmaCommand.command = MV_ATA_COMMAND_FLUSH_CACHE;
+        pCommandInfo->commandParams.NoneUdmaCommand.isEXT = MV_FALSE;
+
+    }
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Sending Flush Cache command : channel %d, code %x (extended -->"
+             " %s) pScb %p\n", pScb->bus, pScb->ScsiCdb[0],
+             (pScb->isExtended == MV_TRUE) ? "Yes":"No", pScb);
+
+    result = mvSataQueueCommand(pSataAdapter, pScb->bus, pCommandInfo);
+    if (result != MV_QUEUE_COMMAND_RESULT_OK)
+    {
+        checkQueueCommandResult(pScb, result);
+        /* shoudl complete the Scsi request here*/
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+    /* update stats*/
+    pAdapterExt->totalAccumulatedOutstanding[pScb->bus] += mvSataNumOfDmaCommands(pSataAdapter,pScb->bus);
+    pDriveData->stats.totalIOs++;
+
+    return MV_SCSI_COMMAND_STATUS_QUEUED;
+}
+
+/*******************************************************************************
+* mvScsiAtaGetRequestSenseData - Get the SCSI-3 Request Sense(03h) data
+*
+* DESCRIPTION: This function fills the sense buffer with a sense key of NO SENSE
+*       and an additional sense code of NO ADDITIONAL SENSE INFORMATION.
+*
+* INPUT:
+*   pSataAdapter    - pointer to the SATA adapter data structure.
+*   pScb->bus    - the index of the specific SATA channel.
+*   Cdb             - specifies the SCSI-3 command descriptor block.
+*
+* OUTPUT:
+*   pScsiStatus     - pointer to the Scsi status to be returned.
+*   pSenseBuffer    - pointer to the Scsi sense buffer.
+*   senseBufferLength   - the size in bytes of the sense buffer.
+*   pDataTransfered - the size in bytes of the data transfered into the data
+*                     buffer(alwasy zero for this command).
+*
+* RETURN:
+*   MV_TRUE on success, MV_FALSE on failure.
+*
+* COMMENTS:
+*   No sanity check is done for the parameters.
+*
+*******************************************************************************/
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaGetRequestSenseData(IN MV_SATA_ADAPTER*    pSataAdapter,
+                                                                 IN MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+    MV_SCSI_SENSE_DATA SenseData;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+
+    memset(pScb->pDataBuffer, 0, pScb->dataBufferLength);
+
+    memset(&SenseData, 0, sizeof(MV_SCSI_SENSE_DATA));
+//    SenseData.Valid = 0;
+    SenseData.ResponseCode = MV_SCSI_RESPONSE_CODE;
+    SenseData.SenseKey = SCSI_SENSE_NO_SENSE;
+    SenseData.AdditionalSenseCode = SCSI_ADSENSE_NO_SENSE;
+    SenseData.AdditionalSenseLength = sizeof(MV_SCSI_SENSE_DATA) - 8;
+
+    pScb->senseDataLength = 0;
+    if (pDriveData->UAConditionPending == MV_TRUE)
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Unit Attention condition is pending.\n");
+        SenseData.SenseKey = SCSI_SENSE_UNIT_ATTENTION;
+        if (pDriveData->UAEvents & MV_BIT0)
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Report Bus Reset.\n");
+
+            SenseData.AdditionalSenseCode = SCSI_ADSENSE_BUS_RESET;
+            SenseData.AdditionalSenseCodeQualifier = 2;
+            pDriveData->UAEvents &= ~MV_BIT0;
+        }
+        else if (pDriveData->UAEvents & MV_BIT1)
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Report Mode Parameters Changed.\n");
+            SenseData.AdditionalSenseCode = SCSI_ADSENSE_PARAMETERS_CHANGED;
+            SenseData.AdditionalSenseCodeQualifier = 1;
+            pDriveData->UAEvents &= ~MV_BIT1;
+        }
+
+        pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+        if (pDriveData->UAEvents == 0)
+        {
+            pDriveData->UAConditionPending = MV_FALSE;
+        }
+    }
+    else
+    {
+        pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+    }
+    if (pScb->dataBufferLength >= sizeof(MV_SCSI_SENSE_DATA))
+    {
+        pScb->dataTransfered = sizeof(MV_SCSI_SENSE_DATA);
+        memcpy(pScb->pDataBuffer, &SenseData, pScb->dataTransfered);
+        /*pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;*/
+        /*pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;*/
+    }
+    else
+    {
+        pScb->dataTransfered = pScb->dataBufferLength;
+        memcpy(pScb->pDataBuffer, &SenseData, pScb->dataTransfered);
+        pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;/*TBD*/
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+    }
+#ifdef MV_LOGGER
+    reportScbCompletion(pSataAdapter, pScb);
+#endif
+    pScb->completionCallBack(pSataAdapter, pScb);
+    return MV_SCSI_COMMAND_STATUS_COMPLETED;
+}
+
+/*******************************************************************************
+* mvScsiAtaGetModeSenseData - Get the SCSI-3 Mode Sense data
+*
+* DESCRIPTION: This function issues ATA Identify command, in the command
+*       completion, the Mode Sense data will be filled according to the returned
+*       Identify Data.
+*
+* INPUT:
+*   pSataAdapter    - pointer to the SATA adapter data structure.
+*   pScb->bus    - the index of the specific SATA channel.
+*   Cdb             - specifies the SCSI-3 command descriptor block.
+*
+* RETURN:
+*   MV_TRUE on success, MV_FALSE on failure.
+*
+* COMMENTS:
+*   No sanity check is done for the parameters.
+*
+*******************************************************************************/
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaGetModeSenseData(IN MV_SATA_ADAPTER    *pSataAdapter,
+                                                              IN  MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = pScb->pCommandInfo;
+#else
+    MV_QUEUE_COMMAND_INFO   commandInfo;
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = &commandInfo;
+#endif
+    MV_QUEUE_COMMAND_RESULT result;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+
+    memset(pCommandInfo, 0, sizeof(MV_QUEUE_COMMAND_INFO));
+    pScb->commandType = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pCommandInfo->type = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pCommandInfo->PMPort = pScb->target;
+    pCommandInfo->commandParams.NoneUdmaCommand.bufPtr = pDriveData->identifyBuffer;
+    pCommandInfo->commandParams.NoneUdmaCommand.count = 256;         /* 512 bytes */
+    pCommandInfo->commandParams.NoneUdmaCommand.callBack = SALCommandCompletionCB;
+    pCommandInfo->commandParams.NoneUdmaCommand.command = MV_ATA_COMMAND_IDENTIFY;
+    pCommandInfo->commandParams.NoneUdmaCommand.commandId = (MV_VOID_PTR) pScb;
+    pCommandInfo->commandParams.NoneUdmaCommand.isEXT = MV_FALSE;
+    pCommandInfo->commandParams.NoneUdmaCommand.protocolType = MV_NON_UDMA_PROTOCOL_PIO_DATA_IN;
+    pCommandInfo->commandParams.NoneUdmaCommand.device = (MV_U8)(MV_BIT6);
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Sending Identify command: channel %d, Srb %p\n",
+             pScb->bus, pScb);
+
+    result = mvSataQueueCommand(pSataAdapter, pScb->bus, pCommandInfo);
+    if (result != MV_QUEUE_COMMAND_RESULT_OK)
+    {
+        checkQueueCommandResult(pScb, result);
+        /* shoudl complete the Scsi request here*/
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    return MV_SCSI_COMMAND_STATUS_QUEUED;
+}
+static MV_BOOLEAN  mvScsiAtaGetModeSenseDataPhase2(IN MV_SATA_ADAPTER    *pSataAdapter,
+                                                   IN  MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+    MV_U8   AdditionalSenseCode = SCSI_ADSENSE_NO_SENSE;
+    MV_U8   *cmd = pScb->ScsiCdb;
+    MV_U8   pageCode= cmd[2] & 0x3f;
+    MV_U8   pageControl = (MV_U8)((cmd[2] & 0xc0) >> 6);
+    MV_U8   modeSenseResult[MV_MAX_MODE_SENSE_RESULT_LENGTH];
+    MV_U32  offset;
+    MV_U32  pageLength;
+    MV_BOOLEAN  commandFailed = MV_FALSE;
+
+    memset(pScb->pDataBuffer, 0, pScb->dataBufferLength);
+    memset(modeSenseResult, 0, MV_MAX_MODE_SENSE_RESULT_LENGTH);
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Sense: cmd[2] 0x%xcode 0x%x control 0x%x "
+             "allocation length %d \n", pSataAdapter->adapterId, pScb->bus,
+             cmd[2], pageCode, pageControl, (MV_U32)cmd[4]);
+
+
+    if (pageControl == 0x3)
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Sense: save control not supported\n.",
+                 pSataAdapter->adapterId, pScb->bus);
+        AdditionalSenseCode = 0x39; /*SAVING PARAMETERS NOT SUPPORTED */
+        commandFailed = MV_TRUE;
+    }
+    if (commandFailed != MV_TRUE)
+    {
+        memset(modeSenseResult, 0, MV_MAX_MODE_SENSE_RESULT_LENGTH);
+        /*1. Mode parameter header*/
+        /* Mode data length will be set later */
+        /* Medium Type 0: Default medium type */
+        /* Device-specific parameter 0:  write enabled, target */
+        /*      supports the DPO and FUA bits only in NCQ mode*/
+        if (pSataAdapter->sataChannel[pScb->bus]->queuedDMA == MV_EDMA_MODE_NATIVE_QUEUING)
+        {
+            modeSenseResult[2] = MV_BIT4;
+        }
+
+        /* Block descriptor length 0: no block descriptors*/
+
+        /*2. Block descriptor(s): Empty list*/
+        /*3. Page(s)*/
+        offset = 4;
+
+        switch (pageCode)
+        {
+        case 0x3f:
+        case 0x8: /*Caching page */
+            pageLength = mvModeSenseCachingPage(pScb,
+                                                modeSenseResult + offset,
+                                                pageControl);
+
+            offset += pageLength;
+
+            if (pageCode == 0x8)
+            {
+                break;
+            }
+        case 0xa:
+            pageLength = mvModeSenseControlPage(pSataAdapter,pScb,
+                                                modeSenseResult + offset,
+                                                pageControl);
+
+            offset += pageLength;
+            break;
+        default:
+            AdditionalSenseCode = SCSI_ADSENSE_INVALID_CDB;
+            commandFailed = MV_TRUE;
+        }
+
+        /* set the DATA LENGTH of the Mode parameter list not including the number*/
+        /* of bytes of the DATA LENGTH itself ( 1 byte for Mode Selet(6)) */
+        modeSenseResult[0] = (MV_U8)(offset - 1);
+
+        if (pScb->dataBufferLength < offset)
+        {
+            memcpy(pScb->pDataBuffer, modeSenseResult, pScb->dataBufferLength);
+            pScb->dataTransfered = pScb->dataBufferLength;
+        }
+        else
+        {
+            memcpy(pScb->pDataBuffer, modeSenseResult, offset);
+            pScb->dataTransfered = offset;
+        }
+    }
+
+    if (commandFailed == MV_TRUE)
+    {
+        setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST, AdditionalSenseCode, 0);
+
+        pScb->dataTransfered = 0;
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+    }
+    else
+    {
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+        pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+    }
+    return MV_TRUE;
+}
+static MV_SCSI_COMMAND_STATUS_TYPE  mvScsiAtaModeSelect(IN MV_SATA_ADAPTER    *pSataAdapter,
+                                                        IN  MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+    MV_U8 result;
+    MV_SCSI_COMMAND_STATUS_TYPE     commandStatus= MV_SCSI_COMMAND_STATUS_FAILED;
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " MODE SELECT RECEIVED: cmd:");
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %02x, %02x, %02x, %02x, %02x, %02x\n", pScb->ScsiCdb[0], pScb->ScsiCdb[1],
+                 pScb->ScsiCdb[2], pScb->ScsiCdb[3], pScb->ScsiCdb[4], pScb->ScsiCdb[5]);
+    }
+    result = modeSelect(pSataAdapter, pScb, &commandStatus);
+    if (result != 0x0)
+    {
+        if (result == 0x1)/*PARAMETER LIST LENGTH ERROR*/
+        {
+            setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST, 0x1a, 0);
+
+        }
+        else if (result == 0x2)
+        {
+            setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+                         SCSI_ADSENSE_INVALID_CDB, 0);
+
+        }
+        else if (result == 0x3)
+        {
+            setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+                         SCSI_ADSENSE_INVALID_FIELD_IN_PARAMETER_LIST, 0);
+
+        }
+        else
+        {
+            setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+                         SCSI_ADSENSE_NO_SENSE, 0);
+
+        }
+
+        pScb->dataTransfered = 0;
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+    return commandStatus;
+}
+
+static MV_U8
+modeSelect(IN MV_SATA_ADAPTER    *pSataAdapter,
+           IN  MV_SATA_SCSI_CMD_BLOCK  *pScb,
+           MV_SCSI_COMMAND_STATUS_TYPE *pCommandStatus)
+{
+    MV_U8   *cmd = pScb->ScsiCdb;
+    MV_VOID_PTR pBuffer = pScb->pDataBuffer;
+    MV_U32  length = pScb->dataBufferLength;
+    MV_U8   PF = (cmd[1] & MV_BIT4) >> 4;
+    MV_U8   SP = (cmd[1] & MV_BIT0);
+    MV_U8   *list = (MV_U8 *)pBuffer;
+    MV_U32  offset;
+    MV_U32  cachePageOffset = 0;
+
+    {
+        MV_U32 i;
+        for (i =0 ; i < length; i++)
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %02x", list[i]);
+        }
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "\n");
+    }
+    if (PF == 0)
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%d %d: Mode Select Error: PF not supported\n.",
+                 pSataAdapter->adapterId, pScb->bus);
+        return 0x2; /* Invalid field in CDB */
+    }
+    if (SP == 1)
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%d %d: Mode Select Error: SP not supported\n.",
+                 pSataAdapter->adapterId, pScb->bus);
+        return 0x2; /* PARAMETER LIST LENGTH ERROR */
+    }
+    if (length == 0)
+    {
+        pScb->dataTransfered = 0;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+        pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        *pCommandStatus = MV_SCSI_COMMAND_STATUS_COMPLETED;
+        return 0;
+    }
+    if (length < 4)
+    {
+        return 0x1; /* PARAMETER LIST LENGTH ERROR */
+    }
+    if (list[0] || (list[1] != MV_SCSI_DIRECT_ACCESS_DEVICE) || list[2])
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select Error: invalid field in parameter "
+                 "list\n", pSataAdapter->adapterId, pScb->bus);
+        return 0x3; /* Invalid field in parameter list */
+    }
+    if (list[3])
+    {
+        if (list[3] != 8)
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select Error: wrong size for mode parameter"
+                     " block descriptor, BLOCK DESCRIPTOR LENGTH %d\n.",
+                     pSataAdapter->adapterId, pScb->bus, list[3]);
+            return 0x3; /* Invalid field in parameter list */
+        }
+        if (length < 12)
+        {
+            return 0x1; /* PARAMETER LIST LENGTH ERROR */
+        }
+        if (list[4] || list[5] || list[6] || list[7] || list[8] || list[9] ||
+            (list[10] != 0x2) || list[11])
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select Error: invalid field in parameter "
+                     "block descriptor list\n", pSataAdapter->adapterId,
+                     pScb->bus);
+            return 0x3; /* Invalid field in parameter list */
+        }
+    }
+    offset = 4 + list[3];/* skip the mode parameter block descriptor */
+
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select: PF 0x%x SP 0x%x parameter length %x "
+             "length %d(0x%x)\n offset %d", pSataAdapter->adapterId, pScb->bus,
+             PF, SP, (MV_U32)cmd[4], length, length,
+             offset);
+    if (length == offset)
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select : no mode pages available\n",
+                 pSataAdapter->adapterId, pScb->bus);
+        pScb->dataTransfered = 0;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+        pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        *pCommandStatus = MV_SCSI_COMMAND_STATUS_COMPLETED;
+        return 0;
+    }
+
+    while ((offset + 2) < length)
+    {
+        switch (list[offset] & 0x3f)
+        {
+        case 0x8:
+            if (list[offset + 1] != 0x12)
+            {
+                mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select Error: bad length in caching mode "
+                         "page %d\n.",
+                         pSataAdapter->adapterId, pScb->bus, list[offset + 1]);
+                return 0x3; /* Invalid field in parameter list */
+            }
+            cachePageOffset = offset;
+            offset += list[offset + 1] + 2;
+            break;
+        case 0xa:
+            if ((list[offset] != 0xa) || (list[offset+1] != 0xa))
+            {
+                mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select Error: invalid field in"
+                         " mode control page, list[%x] %x, list[%x] %x\n",
+                         pSataAdapter->adapterId, pScb->bus, offset,
+                         list[offset], offset + 1, list[offset+1]);
+                return 0x3;
+            }
+
+            if (list[offset + 3] != MV_BIT4)
+            {
+                mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select Error: invalid field in"
+                         " mode control page, list[%x] %x\n",
+                         pSataAdapter->adapterId, pScb->bus, offset + 3,
+                         list[offset + 3]);
+                return 0x3;
+            }
+
+            if (list[offset + 2] || list[offset + 4] || list[offset + 5] ||
+                list[offset + 6] || list[offset + 7]||list[offset + 8] ||
+                list[offset + 9]|| list[offset + 10] || list[offset + 11])
+            {
+                mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select Error: invalid field in"
+                         " mode control page, line %d\n",
+                         pSataAdapter->adapterId, pScb->bus, __LINE__);
+                return 0x3;
+            }
+            offset += list[offset + 1] + 2;
+            break;
+        default:
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select Error: invalid field in parameter "
+                     "list, mode page %d not supported, offset %d\n",
+                     pSataAdapter->adapterId, pScb->bus, list[offset],
+                     offset);
+            return 0x3; /* Invalid field in parameter list */
+        }
+    }
+
+    if (length != offset)
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select Error: bad length %d\n.",
+                 pSataAdapter->adapterId, pScb->bus, length);
+        return 0x1; /* PARAMETER LIST LENGTH ERROR */
+    }
+
+    if (cachePageOffset)
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " Mode Select: caching Page found, offset %d\n", cachePageOffset);
+        return mvParseModeCachingPage(pSataAdapter, pScb,list + cachePageOffset, pCommandStatus);
+    }
+    else
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " Mode Select: No caching Page found\n");
+        pScb->dataTransfered = 0;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+        pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        *pCommandStatus = MV_SCSI_COMMAND_STATUS_COMPLETED;
+        return 0;
+    }
+}
+
+static MV_U8
+mvParseModeCachingPage(MV_SATA_ADAPTER *pSataAdapter,
+                       IN  MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                       MV_U8 *buffer,
+                       MV_SCSI_COMMAND_STATUS_TYPE *pCommandStatus)
+{
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = pScb->pCommandInfo;
+#else
+    MV_QUEUE_COMMAND_INFO   commandInfo;
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = &commandInfo;
+#endif
+    MV_QUEUE_COMMAND_RESULT result;
+    MV_U8                   index = 0;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+
+
+    if ((buffer[index++] & 0xc0) || (buffer[index++] != 0x12) ||
+        ((buffer[index++] | MV_BIT2)!= MV_BIT2) || (buffer[index++]) ||
+        (buffer[index++] != 0xff) || (buffer[index++] != 0xff) ||
+        buffer[index++] || buffer[index++] || buffer[index++] ||
+        (buffer[index++] != 0x10) || buffer[index++] ||
+        (buffer[index++] != 0x10) || ((buffer[index++] | MV_BIT5) != MV_BIT5) ||
+        (buffer[index++] != 0x1) || (buffer[index++] != 0xff) ||
+        (buffer[index++] != 0xff) || buffer[index++] || buffer[index++]
+        || buffer[index++] || buffer[index++])
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select Error: invalid field in caching mode"
+                 " page, index %d\n", pSataAdapter->adapterId, pScb->bus,
+                 index);
+        return 0x3; /* Invalid field in parameter list */
+    }
+
+    pScb->splitCount = 2;
+    pScb->sequenceNumber = 1;
+    if (buffer[12] & MV_BIT5) /* Disable Look Ahead*/
+    {
+        if (pDriveData->identifyInfo.readAheadSupported == MV_FALSE)
+        {
+            pScb->splitCount--;
+        }
+        pScb->LowLbaAddress = 0;
+    }
+    else
+    {
+        if (pDriveData->identifyInfo.readAheadSupported == MV_FALSE)
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select Error: invalid field in caching mode"
+                     " page, enable read ahead (feature not supported)\n",
+                     pSataAdapter->adapterId, pScb->bus);
+            return 0x3; /* Invalid field in parameter list */
+        }
+        pScb->LowLbaAddress = 1;
+    }
+
+    if (buffer[2] & MV_BIT2) /* enable write cache*/
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " Parse Caching Page: enable Write Cache\n");
+        if (pDriveData->identifyInfo.writeCacheSupported == MV_FALSE)
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d: Mode Select Error: invalid field in caching mode"
+                     " page, enable write cache (feature not supported)\n",
+                     pSataAdapter->adapterId, pScb->bus);
+            return 0x3; /* Invalid field in parameter list */
+        }
+        pCommandInfo->commandParams.NoneUdmaCommand.features = MV_ATA_SET_FEATURES_ENABLE_WCACHE;
+    }
+    else
+    {
+        if (pDriveData->identifyInfo.writeCacheSupported == MV_FALSE)
+        {
+            pScb->splitCount--;
+            if (pScb->splitCount == 1)
+            {
+                mvScsiAtaSendReadLookAhead(pSataAdapter, pScb);
+                *pCommandStatus = MV_SCSI_COMMAND_STATUS_QUEUED;
+                return 0;
+            }
+        }
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " Parse Caching Page: disable Write Cache\n");
+        pCommandInfo->commandParams.NoneUdmaCommand.features = MV_ATA_SET_FEATURES_DISABLE_WCACHE;
+    }
+
+    if (pScb->splitCount == 0)
+    {
+        pScb->dataTransfered = 0;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+        pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        *pCommandStatus = MV_SCSI_COMMAND_STATUS_COMPLETED;
+        return 0;
+    }
+
+    pScb->commandType = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+
+    pCommandInfo->type = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pCommandInfo->PMPort = pScb->target;
+    pCommandInfo->commandParams.NoneUdmaCommand.bufPtr = NULL;
+    pCommandInfo->commandParams.NoneUdmaCommand.callBack = SALCommandCompletionCB;
+    pCommandInfo->commandParams.NoneUdmaCommand.command = MV_ATA_COMMAND_SET_FEATURES;
+    pCommandInfo->commandParams.NoneUdmaCommand.commandId = (MV_VOID_PTR) pScb;
+    pCommandInfo->commandParams.NoneUdmaCommand.count = 0;
+
+    pCommandInfo->commandParams.NoneUdmaCommand.isEXT = MV_FALSE;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaMid = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaLow = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.protocolType = MV_NON_UDMA_PROTOCOL_NON_DATA;
+    pCommandInfo->commandParams.NoneUdmaCommand.sectorCount = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.device = (MV_U8)(MV_BIT6);
+
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Sending SET FEATURES command: features %d\n",
+             pCommandInfo->commandParams.NoneUdmaCommand.features);
+
+    result = mvSataQueueCommand(pSataAdapter, pScb->bus, pCommandInfo);
+
+    if (result != MV_QUEUE_COMMAND_RESULT_OK)
+    {
+        checkQueueCommandResult(pScb, result);
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        *pCommandStatus = MV_SCSI_COMMAND_STATUS_COMPLETED;
+
+        return 0;
+    }
+    *pCommandStatus = MV_SCSI_COMMAND_STATUS_QUEUED;
+    return 0;
+}
+
+static MV_U32
+mvModeSenseCachingPage(MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                       MV_U8 *buffer,MV_U8 pageControl)
+{
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+
+
+    buffer[0] = 0x8; /* caching page*/
+    buffer[1] = 0x12; /* length = 2 + 0x12*/
+    buffer[2] = 0;
+    if (pageControl == 2) /*default values*/
+    {
+        if (pDriveData->identifyInfo.writeCacheSupported == MV_TRUE)
+        {
+            buffer[2] = MV_BIT2;
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " Cache Page: writeCacheEnabledByDefault\n");
+        }
+    }
+    else if (pageControl == 0)  /* current values*/
+    {
+        if ((pDriveData->identifyInfo.writeCacheSupported == MV_TRUE) &&
+            (pDriveData->identifyBuffer[85] & MV_BIT5))
+        {
+            buffer[2] = MV_BIT2;
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " Cache Page: writeCacheEnabled\n");
+        }
+    }
+    else if (pageControl == 1)  /* changeable values*/
+    {
+        if (pDriveData->identifyInfo.writeCacheSupported == MV_TRUE)
+        {
+            buffer[2] = MV_BIT2;
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " Cache Page: writeCacheSupported\n");
+        }
+    }
+
+    buffer[3] = 0;
+    if (pageControl != 1)
+    {
+        buffer[4] = 0xff;
+        buffer[5] = 0xff;
+        buffer[9] = 0x10;
+        buffer[11] = 0x10;
+    }
+    if (pageControl == 2) /*default values*/
+    {
+        if (pDriveData->identifyInfo.readAheadSupported == MV_FALSE)
+        {
+            buffer[12] = MV_BIT5;
+        }
+    }
+    else if (pageControl == 0)  /* current values*/
+    {
+        if ((pDriveData->identifyInfo.readAheadSupported == MV_TRUE) &&
+            (pDriveData->identifyBuffer[85] & MV_BIT6))
+        {
+            buffer[12] = 0;
+        }
+        else
+        {
+            buffer[12] = MV_BIT5;
+        }
+    }
+    else if (pageControl == 1)  /* changeable values*/
+    {
+        if (pDriveData->identifyInfo.readAheadSupported == MV_TRUE)
+        {
+            buffer[12] = MV_BIT5;
+        }
+    }
+    if (pageControl != 1)
+    {
+        buffer[13] = 0x01;
+        buffer[14] = 0xff;
+        buffer[15] = 0xff;
+    }
+
+    {
+        MV_U32 i;
+
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " Cache Page: \n");
+        for (i = 0; i < 0x14; i++)
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "[%d] %x\n",i, buffer[i]);
+        }
+    }
+    return 0x14;
+}
+
+static MV_U32
+mvModeSenseControlPage(MV_SATA_ADAPTER *pSataAdapter,
+                       MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                       MV_U8 *buffer, MV_U8 pageControl)
+{
+    buffer[0] = 0xA;    /* control page */
+    buffer[1] = 0xA;    /* length 2 + 0xa*/
+    if (pageControl != 1)
+    {
+        buffer[3] = MV_BIT4/*Unrestricted reordering allowed*/;
+    }
+
+    {
+        MV_U32 i;
+
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " Control Page: \n");
+        for (i = 0; i < 0xc; i++)
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "[%d] %x\n",i , buffer[i]);
+        }
+    }
+    return 0xc;
+}
+
+static MV_BOOLEAN
+SALCommandCompletionCB(MV_SATA_ADAPTER *pSataAdapter,
+                       MV_U8 channelNum,
+                       MV_COMPLETION_TYPE comp_type,
+                       MV_VOID_PTR commandId,
+                       MV_U16 responseFlags,
+                       MV_U32 timeStamp,
+                       MV_STORAGE_DEVICE_REGISTERS *registerStruct)
+{
+    MV_SATA_SCSI_CMD_BLOCK  *pScb;
+    if (commandId == NULL)
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_FATAL_ERROR, " commandId is NULL, can't hanlde this !!!,adapterId=%d,"
+                 " channel=%d \n", pSataAdapter->adapterId, channelNum);
+        return MV_FALSE;
+    }
+
+    pScb = commandId;
+    switch (comp_type)
+    {
+    case MV_COMPLETION_TYPE_NORMAL:
+        /* finish */
+#ifdef  MV_SUPPORT_ATAPI
+        if(pScb->commandType == MV_QUEUED_COMMAND_TYPE_PACKET)
+        {
+            if ((registerStruct->statusRegister & MV_ATA_ERROR_STATUS) ||
+               (registerStruct->statusRegister & MV_ATA_DEVICE_FAULT_STATUS))  
+            {
+                pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+                mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "packet command completed ",
+                        "with check condition\n", pScb);
+            }
+            else
+            {
+                pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+            }
+            pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+            pScb->dataTransfered = timeStamp;
+            break;
+        }
+#endif
+        /* If splited VERIFY command, then SRB completion will be on the last fragment */
+        if ((((pScb->ScsiCdb[0] == SCSI_OPCODE_VERIFY6) ||
+              (pScb->ScsiCdb[0] == SCSI_OPCODE_VERIFY10) ||
+              (pScb->ScsiCdb[0] == SCSI_OPCODE_VERIFY16) ||
+              (pScb->ScsiCdb[0] == SCSI_OPCODE_MODE_SELECT6)))
+            &&  (pScb->splitCount > pScb->sequenceNumber))
+        {
+            /* add the command to the list for post interrupt service*/
+            pScb->pNext = pScb->pSalAdapterExtension->pHead;
+            pScb->pSalAdapterExtension->pHead = pScb;
+            return MV_TRUE;
+        }
+        if (pScb->ScsiCdb[0] == SCSI_OPCODE_MODE_SENSE6)
+        {
+            mvScsiAtaGetModeSenseDataPhase2(pSataAdapter, pScb);
+        }
+        else
+        {
+            pScb->ScsiStatus = MV_SCSI_STATUS_GOOD;
+            pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_SUCCESS;
+        }
+        /*
+         * ATA passthru command have to return some consistent sense
+         * data when the caller ask for it.
+         */
+        if (((pScb->ScsiCdb[0] == SCSI_OPCODE_ATA12) ||
+             (pScb->ScsiCdb[0] == SCSI_OPCODE_ATA16)) &&
+             (pScb->ScsiCdb[2] & 0x20))
+        {
+            setPassThruSense(pScb, registerStruct);
+        }
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "command completed. pScb %p\n", pScb);
+
+        break;
+    case MV_COMPLETION_TYPE_ABORT:
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, "Error: command Aborted. Cdb: %02x %02x %02x %02x %02x "
+                 "%02x %02x %02x %02x %02x\n", pScb->ScsiCdb[0],
+                 pScb->ScsiCdb[1], pScb->ScsiCdb[2], pScb->ScsiCdb[3],
+                 pScb->ScsiCdb[4], pScb->ScsiCdb[5], pScb->ScsiCdb[6],
+                 pScb->ScsiCdb[7], pScb->ScsiCdb[8], pScb->ScsiCdb[9]);
+
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_ABORTED;
+        pScb->dataTransfered = 0;
+        pScb->senseDataLength = 0;
+        mvCommandCompletionErrorHandler(pScb->pIalAdapterExtension, channelNum);
+        break;
+    case MV_COMPLETION_TYPE_ERROR:
+        pScb->dataTransfered = 0;
+        pScb->senseDataLength = 0;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_ATA_FAILED;
+
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, "COMPLETION ERROR , adapter =%d, channel=%d, flags=%x\n",
+                 pSataAdapter->adapterId, channelNum, responseFlags);
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " Failed command Cdb: %02x %02x %02x %02x %02x "
+                 "%02x %02x %02x %02x %02x\n", pScb->ScsiCdb[0],
+                 pScb->ScsiCdb[1], pScb->ScsiCdb[2], pScb->ScsiCdb[3],
+                 pScb->ScsiCdb[4], pScb->ScsiCdb[5], pScb->ScsiCdb[6],
+                 pScb->ScsiCdb[7], pScb->ScsiCdb[8], pScb->ScsiCdb[9]);
+        /* here the  eDMA will be stopped, so we have to flush  */
+        /* the pending commands                                 */
+
+        if (pScb->commandType == MV_QUEUED_COMMAND_TYPE_UDMA)
+        {
+            handleUdmaError(pScb, responseFlags, registerStruct);
+#ifdef MV_LOGGER
+            memcpy(&pScb->ATAregStruct, registerStruct,
+                   sizeof(pScb->ATAregStruct));
+#endif
+        }
+        else
+        {
+            handleNoneUdmaError(pScb, registerStruct);
+#ifdef MV_LOGGER
+            memcpy(&pScb->ATAregStruct, registerStruct,
+                   sizeof(pScb->ATAregStruct));
+#endif
+        }
+        mvCommandCompletionErrorHandler(pScb->pIalAdapterExtension, channelNum);
+        break;
+    default:
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_FATAL_ERROR, " Unknown completion type (%d)\n", comp_type);
+        return MV_FALSE;
+    }
+#ifdef MV_LOGGER
+    reportScbCompletion(pSataAdapter, pScb);
+#endif
+    if (!virt_addr_valid(pScb->completionCallBack))
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, "IAL ERROR: invalid completionCallBack=0x%X\n",
+                 pScb->completionCallBack);
+        return MV_FALSE;
+    }
+
+    pScb->completionCallBack(pSataAdapter, pScb);
+    return MV_TRUE;
+}
+MV_VOID
+handleNoneUdmaError(MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                    MV_STORAGE_DEVICE_REGISTERS *registerStruct)
+{
+    MV_U8 errorReg = registerStruct->errorRegister;
+    MV_SCSI_SENSE_DATA SenseData;
+
+    memset(&SenseData, 0, sizeof(MV_SCSI_SENSE_DATA));
+
+    pScb->dataBufferLength = 0;
+
+    /*if (pSrb->SenseInfoBufferLength < 13)
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, "IAL ERROR: invalid Sense Info buffer len (%d)\n",
+                 Srb->SenseInfoBufferLength);
+        Srb->SrbStatus = SRB_STATUS_ERROR;
+        return;
+    }*/
+    memset(pScb->pSenseBuffer, 0, pScb->senseBufferLength);
+    /*pScb->ScsiCommandCompletion = ;*/
+    pScb->ScsiStatus =  MV_SCSI_STATUS_CHECK_CONDITION;
+
+    SenseData.ResponseCode = MV_SCSI_RESPONSE_CODE;
+//    SenseData.Valid = 0;
+
+    SenseData.AdditionalSenseLength = 12;
+    SenseData.InformationDesc.type = 0;
+    SenseData.InformationDesc.AdditionalLength = 0xA;
+    SenseData.InformationDesc.valid = 1 << 7;
+
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " ATA Drive Registers:\n");
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","Error", registerStruct->errorRegister);
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","SectorCount", registerStruct->sectorCountRegister);
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","LBA Low", registerStruct->lbaLowRegister);
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","LBA Mid", registerStruct->lbaMidRegister);
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","LBA High", registerStruct->lbaHighRegister);
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","Device", registerStruct->deviceRegister);
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","Status", registerStruct->statusRegister);
+
+    /* If the command is synchronize cache */
+    if ((pScb->ScsiCdb[0] == SCSI_OPCODE_SYNCHRONIZE_CACHE10) || 
+	(pScb->ScsiCdb[0] == SCSI_OPCODE_SYNCHRONIZE_CACHE16))
+    {
+        if (!(registerStruct->errorRegister & ABRT_ERR))
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " received error completion on flush cache command"
+                     " but ABORT bit in error register is not set\n");
+        }
+        SenseData.SenseKey = SCSI_SENSE_MEDIUM_ERROR;
+	_fillSenseInformation(pScb, &SenseData, registerStruct);
+    }
+    else if ((pScb->ScsiCdb[0] == SCSI_OPCODE_VERIFY10) ||
+	     (pScb->ScsiCdb[0] == SCSI_OPCODE_VERIFY6) ||
+	     (pScb->ScsiCdb[0] == SCSI_OPCODE_VERIFY16))
+    {
+        if (errorReg & (NM_ERR | MC_ERR | MCR_ERR))
+        {
+            SenseData.SenseKey = SCSI_SENSE_UNIT_ATTENTION;
+        }
+        else if (errorReg & UNC_ERR)
+        {
+#if 0
+            MV_U32  LowLbaAddress = pScb->LowLbaAddress;
+#endif
+            SenseData.SenseKey = SCSI_SENSE_MEDIUM_ERROR;
+#if 0
+            /* Since high 8 bit address are taken immediatly from LowLbaAddress and
+            not from the completion info ; the following code is relevant for both
+            48bit and 28bit LBA addressing*/
+            SenseData.Information[0] = (MV_U8)((LowLbaAddress & 0xff000000) >> 24);
+            SenseData.Information[1] = (MV_U8)(registerStruct->lbaHighRegister & 0xff);
+            SenseData.Information[2] = (MV_U8)(registerStruct->lbaMidRegister & 0xff);
+            SenseData.Information[3] = (MV_U8)(registerStruct->lbaLowRegister & 0xff);
+#endif
+	    _fillSenseInformation(pScb, &SenseData, registerStruct);
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " Read Verify failed on UNC at sector %02x %02x %02x %02x %02x %02x\n",
+                     SenseData.InformationDesc.information[2],
+                     SenseData.InformationDesc.information[3],
+                     SenseData.InformationDesc.information[4],
+                     SenseData.InformationDesc.information[5],
+                     SenseData.InformationDesc.information[6],
+                     SenseData.InformationDesc.information[7]
+		     );
+        }
+        /*else if (errorReg & IDNF_ERR)
+        {
+            SenseData.SenseKey = SCSI_SENSE_VOL_OVERFLOW;
+        }*/
+        else if ((errorReg & ABRT_ERR) || (errorReg & IDNF_ERR))
+        {
+            SenseData.SenseKey = SCSI_SENSE_ABORTED_COMMAND;
+            SenseData.AdditionalSenseCode = SCSI_ADSENSE_NO_SENSE;
+        }
+        else
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " in mapping ATA error to SCSI error\n");
+            SenseData.SenseKey = SCSI_SENSE_NO_SENSE;
+        }
+    }
+    else if (pScb->ScsiCdb[0] == SCSI_OPCODE_MODE_SELECT6)
+    {
+        /* MODE SELECT is only when enabling / disabling write cache */
+        if (errorReg & ABRT_ERR)
+        {
+            SenseData.SenseKey = SCSI_SENSE_ABORTED_COMMAND;
+            SenseData.AdditionalSenseCode = SCSI_ADSENSE_NO_SENSE;
+        }
+        else
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " in mapping ATA error to SCSI error\n");
+            SenseData.SenseKey = SCSI_SENSE_NO_SENSE;
+        }
+    }
+    pScb->senseDataLength = 20;
+    memcpy(pScb->pSenseBuffer, &SenseData,
+           (pScb->senseBufferLength > pScb->senseDataLength) ?
+           pScb->senseDataLength : pScb->senseBufferLength);
+}
+
+
+
+static MV_VOID
+handleUdmaError(MV_SATA_SCSI_CMD_BLOCK  *pScb,
+                MV_U32 responseFlags,
+                MV_STORAGE_DEVICE_REGISTERS *registerStruct)
+{
+
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, "UDMA %s command failed\n", (pScb->udmaType == MV_UDMA_TYPE_READ) ?
+             "READ" : "WRITE");
+    if (responseFlags & (MV_BIT3))
+    {
+        /* prevent the error_handler from re-send any commands */
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_DISCONNECT;
+    }
+    else if (responseFlags & MV_BIT2)           /* ATA error*/
+    {
+        MV_SCSI_SENSE_DATA SenseData;
+
+        memset(&SenseData, 0, sizeof(MV_SCSI_SENSE_DATA));
+        pScb->ScsiStatus =  MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->dataTransfered = 0;
+        pScb->senseDataLength = 13;
+//        SenseData.Valid = 1;
+        SenseData.ResponseCode = MV_SCSI_RESPONSE_CODE;
+        SenseData.AdditionalSenseLength = 12;
+	SenseData.InformationDesc.type = 0;
+	SenseData.InformationDesc.AdditionalLength = 0xA;
+	SenseData.InformationDesc.valid = 1 << 7;
+
+
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " ATA Drive Registers:\n");
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","Error", registerStruct->errorRegister);
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","SectorCount", registerStruct->sectorCountRegister);
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","LBA Low", registerStruct->lbaLowRegister);
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","LBA Mid", registerStruct->lbaMidRegister);
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","LBA High", registerStruct->lbaHighRegister);
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","Device", registerStruct->deviceRegister);
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "%20s : %04x\n","Status", registerStruct->statusRegister);
+
+        if ((registerStruct->errorRegister & ICRC_ERR)||
+            (registerStruct->errorRegister == 0xC))/*error code injected by 88i8030*/
+        {
+            SenseData.SenseKey = SCSI_SENSE_ABORTED_COMMAND;
+            SenseData.AdditionalSenseCode = SCSI_ADSENSE_NO_SENSE;
+        }
+        else if (registerStruct->errorRegister &
+                 (NM_ERR | MC_ERR | MCR_ERR))
+        {
+            SenseData.SenseKey = SCSI_SENSE_UNIT_ATTENTION;
+            SenseData.AdditionalSenseCode = SCSI_ADSENSE_NO_MEDIA_IN_DEVICE;
+        }
+        else if ((registerStruct->errorRegister & UNC_ERR) ||
+		 (registerStruct->errorRegister == 1))
+        {
+#if 0
+            MV_U32  LowLbaAddress = pScb->LowLbaAddress;
+
+            SenseData.Valid = 1;
+            SenseData.Information[0] = (MV_U8)((LowLbaAddress & 0xff000000) >> 24);
+            SenseData.Information[1] = (MV_U8)(registerStruct->lbaHighRegister & 0xff);
+            SenseData.Information[2] = (MV_U8)(registerStruct->lbaMidRegister & 0xff);
+            SenseData.Information[3] = (MV_U8)(registerStruct->lbaLowRegister & 0xff);
+#endif
+	    _fillSenseInformation(pScb, &SenseData, registerStruct);
+            if (pScb->udmaType == MV_UDMA_TYPE_READ)
+            {
+                SenseData.SenseKey = SCSI_SENSE_MEDIUM_ERROR;
+                SenseData.AdditionalSenseCode = SCSI_ADSENSE_NO_SENSE;
+
+		mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " DMA Read failed on UNC at sector %02x %02x %02x %02x %02x %02x\n",
+			 SenseData.InformationDesc.information[2],
+			 SenseData.InformationDesc.information[3],
+			 SenseData.InformationDesc.information[4],
+			 SenseData.InformationDesc.information[5],
+			 SenseData.InformationDesc.information[6],
+			 SenseData.InformationDesc.information[7]
+		     );
+            }
+            else
+            {
+                SenseData.SenseKey = SCSI_SENSE_DATA_PROTECT;
+                SenseData.AdditionalSenseCode = SCSI_ADSENSE_NO_SENSE;
+            }
+        }
+        else if ((registerStruct->errorRegister & IDNF_ERR) &&
+                 (!(registerStruct->errorRegister & ABRT_ERR)))
+        {
+            /* In case IDNF is set and ABRT reset OR IDNF reset and ABRT is set */
+            SenseData.SenseKey = SCSI_SENSE_ILLEGAL_REQUEST;
+            SenseData.AdditionalSenseCode = SCSI_ADSENSE_ILLEGAL_BLOCK;
+        }
+        else if (registerStruct->errorRegister & ABRT_ERR)
+        {
+            SenseData.SenseKey = SCSI_SENSE_ABORTED_COMMAND;
+            SenseData.AdditionalSenseCode = SCSI_ADSENSE_NO_SENSE;
+        }
+        else
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " in mapping ATA error to SCSI error\n");
+            SenseData.SenseKey = SCSI_SENSE_ABORTED_COMMAND;
+            SenseData.AdditionalSenseCode = SCSI_ADSENSE_NO_SENSE;
+        }
+        pScb->senseDataLength = 20;
+        memcpy(pScb->pSenseBuffer, &SenseData,
+               (pScb->senseBufferLength > pScb->senseDataLength) ?
+               pScb->senseDataLength : pScb->senseBufferLength);
+    }
+    else if (responseFlags & (MV_BIT0 | MV_BIT1))
+    {
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_PARITY_ERROR;
+        pScb->ScsiStatus =  MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->senseDataLength = 0;
+        pScb->dataTransfered = 0;
+    }
+    else if (responseFlags & (MV_BIT6|MV_BIT5))
+    {
+        if (responseFlags & MV_BIT6)
+        {
+            pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_UNDERRUN;
+        }
+        else
+        {
+            pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_OVERRUN;
+        }
+        pScb->dataTransfered = 0;
+
+    }
+}
+
+/*******************************************************************************
+* checkQueueCommandResult -
+*
+* DESCRIPTION:  set the scsi request completion status and the Scsi Status
+*       according to the result returned form the mvSataQueueCommand function
+*
+* INPUT:
+*
+* OUTPUT:
+*
+* RETURN:
+*
+* COMMENTS:
+*
+*
+*******************************************************************************/
+
+/*static*/ MV_VOID  checkQueueCommandResult(MV_SATA_SCSI_CMD_BLOCK *pScb,
+                                            MV_QUEUE_COMMAND_RESULT  result)
+{
+    switch (result)
+    {
+    case MV_QUEUE_COMMAND_RESULT_BAD_LBA_ADDRESS:
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " Edma Queue command failed. Bad LBA \n");
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCB;
+        break;
+    case MV_QUEUE_COMMAND_RESULT_QUEUED_MODE_DISABLED:
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " Edma Queue command failed. EDMA disabled\n");
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_NOT_READY;
+
+        break;
+    case MV_QUEUE_COMMAND_RESULT_FULL:
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " Edma Queue command failed. Queue is Full\n");
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_QUEUE_FULL;
+        pScb->ScsiStatus = MV_SCSI_STATUS_QUEUE_FULL;
+        break;
+    case MV_QUEUE_COMMAND_RESULT_BAD_PARAMS:
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " Edma Queue command failed. (Bad Params)\n");
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCB;
+        break;
+    default:
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " Bad result value (%d) from queue"
+                 " command\n", result);
+    }
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " mvSataQueueUDmaCommand Failed\n");
+    pScb->dataTransfered = 0;
+    pScb->senseDataLength = 0;
+}
+#ifdef MV_LOGGER
+static MV_VOID reportScbCompletion(MV_SATA_ADAPTER*    pSataAdapter,
+                                   MV_SATA_SCSI_CMD_BLOCK *pScb)
+{
+    if (pScb->ScsiCommandCompletion != MV_SCSI_COMPLETION_SUCCESS)
+    {
+        MV_U8   buffer[100];
+        MV_U32  index = 0;
+        MV_BOOLEAN      printInfo = MV_TRUE;
+
+        switch (pScb->ScsiCommandCompletion)
+        {
+        case MV_SCSI_COMPLETION_BAD_SCSI_COMMAND:
+            SAL_SPRINTF(buffer, "%s", "MV_SCSI_COMPLETION_BAD_SCSI_COMMAND");
+            break;
+        case MV_SCSI_COMPLETION_ATA_FAILED:
+            SAL_SPRINTF(buffer, "%s", "MV_SCSI_COMPLETION_ATA_FAILED");
+            break;
+        case MV_SCSI_COMPLETION_PARITY_ERROR:
+            SAL_SPRINTF(buffer, "%s", "MV_SCSI_COMPLETION_PARITY");
+            break;
+        default:
+            printInfo = MV_FALSE;
+        }
+
+        if (printInfo == MV_TRUE)
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " %d %d %d :Scsi command completed. pScb %p, ScsiStatus %d "
+                     "completionStatus %s\n", pSataAdapter->adapterId,
+                     pScb->bus, pScb->target, pScb, pScb->ScsiStatus, buffer);
+        }
+        else
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Scsi command completed. pScb %p, ScsiStatus %d "
+                     "completionStatus %d\n", pScb, pScb->ScsiStatus,
+                     pScb->ScsiCommandCompletion);
+        }
+
+        index = SAL_SPRINTF(buffer, "%s", "CDB:");
+        {
+            MV_U32  i;
+            for (i =0 ; i < pScb->ScsiCdbLength; i++)
+            {
+                index += SAL_SPRINTF(&buffer[index], "%x ",
+                                     pScb->ScsiCdb[i]);
+            }
+            buffer[index] = '\n';
+            buffer[index+1] = 0;
+            mvLogMsg(MV_SAL_LOG_ID,(printInfo == MV_TRUE) ?
+                     MV_DEBUG_ERROR : MV_DEBUG, buffer);
+            if (pScb->ScsiStatus == MV_SCSI_STATUS_CHECK_CONDITION)
+            {
+                if ((pScb->pSenseBuffer != NULL) && (pScb->senseBufferLength > 0))
+                {
+                    MV_U32  len = pScb->senseDataLength > pScb->senseBufferLength ?
+                                  pScb->senseBufferLength:pScb->senseDataLength;
+                    index = SAL_SPRINTF(buffer, "%s", "Sense Data:");
+                    for (i = 0; i < len; i++)
+                    {
+                        index += SAL_SPRINTF(buffer + index, "%x ",
+                                             pScb->pSenseBuffer[i]);
+                    }
+                    buffer[index] = '\n';
+                    buffer[index+1] = 0;
+                    mvLogMsg(MV_SAL_LOG_ID, (printInfo == MV_TRUE) ?
+                             MV_DEBUG_ERROR : MV_DEBUG, buffer);
+                }
+            }
+        }
+        if (pScb->ScsiCommandCompletion == MV_SCSI_COMPLETION_ATA_FAILED)
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " ATA Drive Registers:\n");
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, "%20s : %04x\n","Error", pScb->ATAregStruct.errorRegister);
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, "%20s : %04x\n","SectorCount", pScb->ATAregStruct.sectorCountRegister);
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, "%20s : %04x\n","LBA Low", pScb->ATAregStruct.lbaLowRegister);
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, "%20s : %04x\n","LBA Mid", pScb->ATAregStruct.lbaMidRegister);
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, "%20s : %04x\n","LBA High", pScb->ATAregStruct.lbaHighRegister);
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, "%20s : %04x\n","Device", pScb->ATAregStruct.deviceRegister);
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, "%20s : %04x\n","Status", pScb->ATAregStruct.statusRegister);
+        }
+    }
+    else
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Scsi command completed. pScb %p, ScsiStatus %d "
+                 "completionStatus %d  dataTransfered %d \n", pScb, pScb->ScsiStatus,
+                 pScb->ScsiCommandCompletion,  pScb->dataTransfered);
+    }
+    
+}
+#endif
+static MV_VOID  mvScsiAtaSendSplittedVerifyCommand(IN MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = pScb->pCommandInfo;
+#else
+    MV_QUEUE_COMMAND_INFO   commandInfo;
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = &commandInfo;
+#endif
+    MV_QUEUE_COMMAND_RESULT result;
+    MV_U8                  sectors = 0;/*256 sectors*/
+
+    pScb->sequenceNumber++;
+    if (pScb->sequenceNumber == 1)/*for the first command*/
+    {
+        if (pScb->ScsiCdb[0] == SCSI_OPCODE_VERIFY6)
+        {
+            sectors = pScb->ScsiCdb[4];
+        }
+        else if (pScb->ScsiCdb[0] == SCSI_OPCODE_VERIFY10)
+        {
+            sectors = pScb->ScsiCdb[8];
+        }
+	else 
+        {
+            sectors = pScb->ScsiCdb[13];
+        }
+    }
+    pCommandInfo->type = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pCommandInfo->PMPort = pScb->target;
+    pCommandInfo->commandParams.NoneUdmaCommand.bufPtr = NULL;
+    pCommandInfo->commandParams.NoneUdmaCommand.callBack = SALCommandCompletionCB;
+    pCommandInfo->commandParams.NoneUdmaCommand.command = MV_ATA_COMMAND_READ_VERIFY_SECTORS;
+    pCommandInfo->commandParams.NoneUdmaCommand.commandId = (MV_VOID_PTR) pScb;
+    pCommandInfo->commandParams.NoneUdmaCommand.count = 0;
+
+    pCommandInfo->commandParams.NoneUdmaCommand.features = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.isEXT = MV_FALSE;
+    pCommandInfo->commandParams.NoneUdmaCommand.protocolType = MV_NON_UDMA_PROTOCOL_NON_DATA;
+
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh = (MV_U16)((pScb->LowLbaAddress & 0xff0000) >> 16);
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaMid = (MV_U16)((pScb->LowLbaAddress & 0xff00) >> 8);
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaLow = (MV_U16)(pScb->LowLbaAddress & 0xff);
+    pCommandInfo->commandParams.NoneUdmaCommand.sectorCount = sectors;
+    pCommandInfo->commandParams.NoneUdmaCommand.device = (MV_U8)(MV_BIT6 |
+                                                                 ((pScb->LowLbaAddress & 0xf000000) >> 24));
+
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d %d: Sending Splitted Verify command:seq# %d code %x lba"
+             " %x(%x.%x.%x), sectors %d[%d] Srb %p\n",
+             pScb->pSalAdapterExtension->pSataAdapter->adapterId, pScb->bus,
+             pScb->target,
+             pScb->sequenceNumber,pScb->ScsiCdb[0],
+             pScb->LowLbaAddress,
+             pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh,
+             pCommandInfo->commandParams.NoneUdmaCommand.lbaMid,
+             pCommandInfo->commandParams.NoneUdmaCommand.lbaLow,
+             pCommandInfo->commandParams.NoneUdmaCommand.sectorCount,
+             mvSataNumOfDmaCommands(pScb->pSalAdapterExtension->pSataAdapter,
+                                    pScb->bus), pScb);
+
+    if (sectors)
+    {
+        pScb->LowLbaAddress += sectors;
+    }
+    else
+    {
+        pScb->LowLbaAddress += 0x100;
+    }
+
+    result = mvSataQueueCommand(pScb->pSalAdapterExtension->pSataAdapter,
+                                pScb->bus, pCommandInfo);
+
+    if (result != MV_QUEUE_COMMAND_RESULT_OK)
+    {
+        checkQueueCommandResult(pScb, result);
+#ifdef MV_LOGGER
+        reportScbCompletion(pScb->pSalAdapterExtension->pSataAdapter, pScb);
+#endif
+
+        return;
+    }
+
+    /* update stats*/
+    pScb->pSalAdapterExtension->totalAccumulatedOutstanding[pScb->bus] +=
+    mvSataNumOfDmaCommands(pScb->pSalAdapterExtension->pSataAdapter,pScb->bus);
+    pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target].stats.totalIOs++;
+    pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target].stats.totalSectorsTransferred += sectors;
+
+}
+static MV_VOID  mvScsiAtaSendReadLookAhead(IN MV_SATA_ADAPTER *pSataAdapter,
+                                           IN MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = pScb->pCommandInfo;
+#else
+    MV_QUEUE_COMMAND_INFO   commandInfo;
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = &commandInfo;
+#endif
+    MV_QUEUE_COMMAND_RESULT result;
+
+    if (pScb->LowLbaAddress == 0) /* Disable Look Ahead*/
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " Parse Caching Page: Disable Read Look Ahead\n");
+        pCommandInfo->commandParams.NoneUdmaCommand.features = MV_ATA_SET_FEATURES_DISABLE_RLA;
+    }
+    else
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " Parse Caching Page: Enable Look Ahead\n");
+        pCommandInfo->commandParams.NoneUdmaCommand.features = MV_ATA_SET_FEATURES_ENABLE_RLA;
+    }
+
+    pScb->commandType = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+
+    pCommandInfo->type = MV_QUEUED_COMMAND_TYPE_NONE_UDMA;
+    pCommandInfo->PMPort = pScb->target;
+    pCommandInfo->commandParams.NoneUdmaCommand.bufPtr = NULL;
+    pCommandInfo->commandParams.NoneUdmaCommand.callBack = SALCommandCompletionCB;
+    pCommandInfo->commandParams.NoneUdmaCommand.command = MV_ATA_COMMAND_SET_FEATURES;
+    pCommandInfo->commandParams.NoneUdmaCommand.commandId = (MV_VOID_PTR) pScb;
+    pCommandInfo->commandParams.NoneUdmaCommand.count = 0;
+
+    pCommandInfo->commandParams.NoneUdmaCommand.isEXT = MV_FALSE;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaHigh = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaMid = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.lbaLow = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.protocolType = MV_NON_UDMA_PROTOCOL_NON_DATA;
+    pCommandInfo->commandParams.NoneUdmaCommand.sectorCount = 0;
+    pCommandInfo->commandParams.NoneUdmaCommand.device = (MV_U8)(MV_BIT6);
+
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Sending SET FEATURES command: features %d\n",
+             pCommandInfo->commandParams.NoneUdmaCommand.features);
+
+    pScb->sequenceNumber++;
+    result = mvSataQueueCommand(pSataAdapter, pScb->bus, pCommandInfo);
+
+    if (result != MV_QUEUE_COMMAND_RESULT_OK)
+    {
+        checkQueueCommandResult(pScb, result);
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return;
+    }
+}
+
+MV_VOID     mvSataScsiInitAdapterExt(MV_SAL_ADAPTER_EXTENSION *pAdapterExt,
+                                     MV_SATA_ADAPTER* pSataAdapter)
+{
+    MV_U8   channelIndex;
+    MV_U8   PMPort;
+    pAdapterExt->pSataAdapter = pSataAdapter;
+    pAdapterExt->pHead = NULL;
+    pAdapterExt->UAMask = 0xFF;
+    for (channelIndex = 0; channelIndex < MV_SATA_CHANNELS_NUM; channelIndex++)
+    {
+        for (PMPort = 0; PMPort < MV_SATA_PM_MAX_PORTS; PMPort++)
+        {
+            pAdapterExt->ataDriveData[channelIndex][PMPort].driveReady = MV_FALSE;
+            /* one identify data buffer used for all the drives connected to */
+            /* the same channel*/
+            pAdapterExt->ataDriveData[channelIndex][PMPort].identifyBuffer =
+            pAdapterExt->identifyBuffer[channelIndex];
+        }
+    }
+}
+#ifdef MV_SUPPORT_ATAPI
+MV_SCSI_COMMAND_STATUS_TYPE mvScsiAtaSendATAPICommand(MV_SATA_ADAPTER *pSataAdapter, 
+                                                        MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = pScb->pCommandInfo;
+#else
+    MV_QUEUE_COMMAND_INFO   commandInfo;
+    MV_QUEUE_COMMAND_INFO   *pCommandInfo = &commandInfo;
+#endif
+    MV_QUEUE_COMMAND_RESULT result;
+
+ 
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Send Packet command, adapter %d bus %d target %d lun %"
+             "d pScb %p\n  dir(%d)  Data Buffer %p (%d), cdb %p (%d)\n",
+             pSataAdapter->adapterId, pScb->bus, pScb->target,
+             pScb->lun, pScb, pScb->dataDirection,
+            pScb->pDataBuffer, 
+                pScb->dataBufferLength, pScb->ScsiCdb, pScb->ScsiCdbLength);
+ 
+    pScb->commandType = MV_QUEUED_COMMAND_TYPE_PACKET;
+
+    pCommandInfo->type = MV_QUEUED_COMMAND_TYPE_PACKET;
+    pCommandInfo->PMPort = pScb->target;
+    pCommandInfo->commandParams.packetCommand.bufPtr = (MV_U16_PTR)pScb->pDataBuffer;
+    pCommandInfo->commandParams.packetCommand.buffer_len = pScb->dataBufferLength;
+    pCommandInfo->commandParams.packetCommand.transfered_data = 0;
+    pCommandInfo->commandParams.packetCommand.cdb_len = (pScb->ScsiCdbLength  >> 1);
+    pCommandInfo->commandParams.packetCommand.cdb_buffer = (MV_U16_PTR)pScb->ScsiCdb;
+    pCommandInfo->commandParams.packetCommand.flags = 0;
+    pCommandInfo->commandParams.packetCommand.callBack = SALCommandCompletionCB;
+    pCommandInfo->commandParams.packetCommand.commandId = (MV_VOID_PTR) pScb;
+    pCommandInfo->commandParams.packetCommand.prdLowAddr = pScb->PRDTableLowPhyAddress;
+    pCommandInfo->commandParams.packetCommand.prdHighAddr = pScb->PRDTableHighPhyAddress;
+    
+    if((pScb->dataDirection == MV_SCSI_COMMAND_DATA_DIRECTION_IN) && (pScb->pDataBuffer == NULL))
+    {
+        pCommandInfo->commandParams.packetCommand.protocolType = MV_NON_UDMA_PROTOCOL_PACKET_DMA;
+    }
+    else if((pScb->dataDirection == MV_SCSI_COMMAND_DATA_DIRECTION_OUT) && (pScb->pDataBuffer == NULL))
+    {
+        pCommandInfo->commandParams.packetCommand.protocolType = MV_NON_UDMA_PROTOCOL_PACKET_DMA;
+        pCommandInfo->commandParams.packetCommand.flags = MV_BIT0;
+    }
+    else
+    {
+        switch(pScb->dataDirection)
+        {
+            case MV_SCSI_COMMAND_DATA_DIRECTION_IN:
+                pCommandInfo->commandParams.packetCommand.protocolType = MV_NON_UDMA_PROTOCOL_PACKET_PIO_DATA_IN;
+                break;
+            case MV_SCSI_COMMAND_DATA_DIRECTION_OUT:
+                pCommandInfo->commandParams.packetCommand.protocolType = MV_NON_UDMA_PROTOCOL_PACKET_PIO_DATA_OUT;
+                break;
+        default:
+                pCommandInfo->commandParams.packetCommand.protocolType = MV_NON_UDMA_PROTOCOL_PACKET_PIO_NON_DATA;
+        }
+    }
+    pScb->sequenceNumber = 0;
+    result = mvSataQueueCommand(pSataAdapter, pScb->bus, pCommandInfo);
+
+    if (result != MV_QUEUE_COMMAND_RESULT_OK)
+    {
+        checkQueueCommandResult(pScb, result);
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+    return MV_SCSI_COMMAND_STATUS_QUEUED;
+}
+#endif
+MV_SCSI_COMMAND_STATUS_TYPE mvSataExecuteScsiCommand(MV_SATA_SCSI_CMD_BLOCK  *pScb)
+{
+    MV_U8               *cmd = pScb->ScsiCdb;
+    MV_BOOLEAN          invalidCDB = MV_FALSE;
+    MV_SATA_ADAPTER *pSataAdapter = pScb->pSalAdapterExtension->pSataAdapter;
+    MV_SATA_SCSI_DRIVE_DATA *pDriveData;
+
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Scsi Command Received, adapter %d bus %d target %d lun %"
+             "d pScb %p\n    Data Buffer length %d, Sense buffer length %x\n",
+             pSataAdapter->adapterId, pScb->bus, pScb->target,
+             pScb->lun, pScb, pScb->dataBufferLength, pScb->senseBufferLength);
+
+#ifdef MV_LOGGER
+
+    {
+        MV_U8 buffer[50];
+        MV_U32  i, index;
+
+        index = SAL_SPRINTF(buffer, "%s", "CDB:");
+        for (i =0 ; i < pScb->ScsiCdbLength; i++)
+        {
+            index += SAL_SPRINTF(&buffer[index], "%x ",
+                                 pScb->ScsiCdb[i]);
+        }
+        buffer[index] = '\n';
+        buffer[index+1] = 0;
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, buffer);
+    }
+#endif
+    pScb->dataTransfered = 0;
+    pScb->senseDataLength = 0;
+    pScb->ScsiStatus = 0;
+    if (pScb->bus >= pSataAdapter->numberOfChannels)
+    {
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_INVALID_BUS;
+        pScb->dataTransfered = 0;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    if ((pScb->target >= MV_SATA_PM_MAX_PORTS) ||
+        (pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target].driveReady == MV_FALSE) ||
+        ((pScb->lun) && (pScb->ScsiCdb[0] != SCSI_OPCODE_INQUIRY)))
+    {
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_NO_DEVICE;
+        pScb->dataTransfered = 0;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+    pDriveData = &pScb->pSalAdapterExtension->ataDriveData[pScb->bus][pScb->target];
+#ifdef MV_SUPPORT_ATAPI
+    if(pDriveData->identifyInfo.deviceType == MV_SATA_DEVICE_TYPE_ATAPI_DEVICE)
+    {
+        return mvScsiAtaSendATAPICommand(pSataAdapter, pScb);
+    }
+#endif
+    switch (cmd[0])
+    {
+    case SCSI_OPCODE_READ10:
+    case SCSI_OPCODE_WRITE10:
+    case SCSI_OPCODE_READ_CAPACITY10:
+    case SCSI_OPCODE_VERIFY10:
+    case SCSI_OPCODE_SYNCHRONIZE_CACHE10:
+
+#ifdef MV_SATA_SUPPORT_READ_WRITE_LONG
+    case SCSI_OPCODE_WRITE_LONG10:
+    case SCSI_OPCODE_READ_LONG10:
+#endif
+        if (cmd[1] & MV_BIT0) /* if related address*/
+        {
+            invalidCDB = MV_TRUE;
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d %d: Scsi command received with "
+                     "RELADR bit enabled - returning ILLEGAL REQUEST\n"
+                     ,pSataAdapter->adapterId, pScb->bus, pScb->target);
+
+        }
+    }
+    if (cmd[pScb->ScsiCdbLength - 1] != 0) /*if CONTROL is set*/
+    {
+        MV_BOOLEAN commandSupported = MV_TRUE;
+
+        switch (cmd[0])
+        {
+        case SCSI_OPCODE_READ6:
+        case SCSI_OPCODE_READ10:
+        case SCSI_OPCODE_READ16:
+        case SCSI_OPCODE_WRITE6:
+        case SCSI_OPCODE_WRITE10:
+        case SCSI_OPCODE_WRITE16:
+        case SCSI_OPCODE_INQUIRY:
+        case SCSI_OPCODE_TEST_UNIT_READY:
+        case SCSI_OPCODE_MODE_SELECT6:
+        case SCSI_OPCODE_MODE_SENSE6:
+        case SCSI_OPCODE_START_STOP:
+        case SCSI_OPCODE_READ_CAPACITY10:     /* read capctiy CDB*/
+        case SCSI_OPCODE_REQUEST_SENSE6:
+        case SCSI_OPCODE_VERIFY6:
+        case SCSI_OPCODE_VERIFY10:
+        case SCSI_OPCODE_VERIFY16:
+        case SCSI_OPCODE_SYNCHRONIZE_CACHE10:
+        case SCSI_OPCODE_SYNCHRONIZE_CACHE16:
+        case SCSI_OPCODE_SEEK10:
+        case SCSI_OPCODE_REASSIGN_BLOCKS:
+        case SCSI_OPCODE_REPORT_LUNS:
+#ifdef MV_SATA_SUPPORT_READ_WRITE_LONG
+        case SCSI_OPCODE_WRITE_LONG10:
+        case SCSI_OPCODE_READ_LONG10:
+#endif
+        case SCSI_OPCODE_ATA12:
+        case SCSI_OPCODE_ATA16:
+
+            break;
+        default:
+            commandSupported = MV_FALSE;
+        }
+        if (commandSupported == MV_TRUE)
+        {
+            invalidCDB = MV_TRUE;
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "[%d,%d] Scsi command received with "
+                     "none zero CONTROL bits - returning ILLEGAL REQUEST\n"
+                     ,pSataAdapter->adapterId, pScb->bus);
+        }
+    }
+
+    if (pDriveData->UAConditionPending == MV_TRUE)
+    {
+        if (((cmd[0] != SCSI_OPCODE_INQUIRY) &&
+	     (cmd[0] != SCSI_OPCODE_REPORT_LUNS) &&
+             (cmd[0] != SCSI_OPCODE_REQUEST_SENSE6)) || (invalidCDB == MV_TRUE))
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " Unit Attention condition is pending.\n");
+
+            if (pDriveData->UAEvents & MV_BIT0)
+            {
+                mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Report Bus Reset.\n");
+                pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_UA_RESET;
+                setSenseData(pScb, SCSI_SENSE_UNIT_ATTENTION, SCSI_ADSENSE_BUS_RESET
+                             , 2);
+                pDriveData->UAEvents &= ~MV_BIT0;
+            }
+            else if (pDriveData->UAEvents & MV_BIT1)
+            {
+                mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Report Mode Parameters Changed.\n");
+                pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_UA_PARAMS_CHANGED;
+                setSenseData(pScb, SCSI_SENSE_UNIT_ATTENTION,
+                             SCSI_ADSENSE_PARAMETERS_CHANGED, 1);
+                pDriveData->UAEvents &= ~MV_BIT1;
+            }
+
+            pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+            pScb->dataTransfered = 0;
+#ifdef MV_LOGGER
+            reportScbCompletion(pSataAdapter, pScb);
+#endif
+            pScb->completionCallBack(pSataAdapter, pScb);
+            if (pDriveData->UAEvents == 0)
+            {
+                pDriveData->UAConditionPending = MV_FALSE;
+            }
+            return MV_SCSI_COMMAND_STATUS_COMPLETED;
+        }
+    }
+    if (invalidCDB == MV_TRUE)
+    {
+        setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST, SCSI_ADSENSE_INVALID_CDB,
+                     0);
+        pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+        pScb->dataTransfered = 0;
+        pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+#ifdef MV_LOGGER
+        reportScbCompletion(pSataAdapter, pScb);
+#endif
+        pScb->completionCallBack(pSataAdapter, pScb);
+        return MV_SCSI_COMMAND_STATUS_COMPLETED;
+    }
+
+    switch (cmd[0])
+    {
+    case SCSI_OPCODE_READ6:
+    case SCSI_OPCODE_READ10:
+    case SCSI_OPCODE_READ16:
+    case SCSI_OPCODE_WRITE6:
+    case SCSI_OPCODE_WRITE10:
+    case SCSI_OPCODE_WRITE16:
+        return mvScsiAtaSendDataCommand(pSataAdapter, pScb);
+    case SCSI_OPCODE_START_STOP:
+        return mvScsiAtaStartStopCommand(pSataAdapter, pScb);
+    case SCSI_OPCODE_INQUIRY:
+        return mvScsiAtaGetInquiryData(pSataAdapter, pScb);
+    case SCSI_OPCODE_TEST_UNIT_READY:
+        return mvScsiAtaTestUnitReady(pSataAdapter, pScb);
+    case SCSI_OPCODE_MODE_SELECT6:
+        return mvScsiAtaModeSelect(pSataAdapter, pScb);
+    case SCSI_OPCODE_MODE_SENSE6:
+        return mvScsiAtaGetModeSenseData(pSataAdapter,pScb);
+        /* Used to detect write protected status.*/
+    case SCSI_OPCODE_READ_CAPACITY10:     /* read capctiy CDB*/
+        return mvScsiAtaGetReadCapacityData(pSataAdapter, pScb);
+    case SCSI_OPCODE_READ_CAPACITY16:     /* read capctiy CDB*/
+        return mvScsiAtaGetReadCapacity16Data(pSataAdapter, pScb);
+    case SCSI_OPCODE_REQUEST_SENSE6:
+        return mvScsiAtaGetRequestSenseData(pSataAdapter, pScb);
+    case SCSI_OPCODE_REPORT_LUNS:
+        return mvScsiAtaReportLuns(pSataAdapter, pScb);
+    case SCSI_OPCODE_VERIFY6:
+    case SCSI_OPCODE_VERIFY10:
+    case SCSI_OPCODE_VERIFY16:
+        return mvScsiAtaSendVerifyCommand(pSataAdapter, pScb);
+    case SCSI_OPCODE_SYNCHRONIZE_CACHE10:
+    case SCSI_OPCODE_SYNCHRONIZE_CACHE16:
+        return mvScsiAtaSendSyncCacheCommand(pSataAdapter, pScb);
+    case SCSI_OPCODE_SEEK10:
+        return mvScsiAtaSeek(pSataAdapter, pScb);
+    case SCSI_OPCODE_REASSIGN_BLOCKS:
+        return mvScsiAtaReassignBlocks(pSataAdapter, pScb);
+#ifdef MV_SATA_SUPPORT_READ_WRITE_LONG
+    case SCSI_OPCODE_WRITE_LONG10:
+        return mvScsiAtaWriteLong(pSataAdapter, pScb);
+    case SCSI_OPCODE_READ_LONG10:
+        return mvScsiAtaReadLong(pSataAdapter, pScb);
+#endif
+    case SCSI_OPCODE_ATA12:
+    case SCSI_OPCODE_ATA16:
+        return mvScsiAtaPassThru(pSataAdapter, pScb);
+
+    default:
+        {
+            setSenseData(pScb, SCSI_SENSE_ILLEGAL_REQUEST,
+                         SCSI_ADSENSE_ILLEGAL_COMMAND, 0);
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, "mvExecuteScsiCommand: ERROR: Unsupported command %02X\n", pScb->ScsiCdb[0]);
+            pScb->ScsiStatus = MV_SCSI_STATUS_CHECK_CONDITION;
+            pScb->dataTransfered = 0;
+            pScb->ScsiCommandCompletion = MV_SCSI_COMPLETION_BAD_SCSI_COMMAND;
+#ifdef MV_LOGGER
+            reportScbCompletion(pSataAdapter, pScb);
+#endif
+            pScb->completionCallBack(pSataAdapter, pScb);
+            return MV_SCSI_COMMAND_STATUS_COMPLETED;
+
+        }
+    }
+
+    return MV_SCSI_COMMAND_STATUS_FAILED;
+}
+
+MV_VOID mvSataScsiPostIntService(MV_SAL_ADAPTER_EXTENSION *pAdapterExt)
+{
+    MV_SATA_SCSI_CMD_BLOCK  *pScb = pAdapterExt->pHead;
+    while (pScb)
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, "Post Interrupt Service: pScb %p command %x\n", pScb,
+                 pScb->ScsiCdb[0]);
+        switch (pScb->ScsiCdb[0])
+        {
+	case    SCSI_OPCODE_VERIFY16:
+        case    SCSI_OPCODE_VERIFY10:
+        case    SCSI_OPCODE_VERIFY6:
+            mvScsiAtaSendSplittedVerifyCommand(pScb);
+            break;
+        case    SCSI_OPCODE_MODE_SELECT6:
+            mvScsiAtaSendReadLookAhead(pAdapterExt->pSataAdapter,
+                                       pScb);
+            break;
+        default:
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG_ERROR, " Post Interrupt Service called for bad scsi"
+                     " command(%x)\n", pScb->ScsiCdb[0]);
+        }
+        pScb = pScb->pNext;
+    }
+    pAdapterExt->pHead = NULL;
+    return;
+}
+
+MV_VOID     mvSataScsiSetDriveReady(MV_SAL_ADAPTER_EXTENSION *pAdapterExt,
+                                    MV_U8   channelIndex, MV_U8 PMPort,
+                                    MV_BOOLEAN  isReady)
+{
+    if (isReady == MV_TRUE)
+    {
+        mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d %d: ATA Drive is Ready.\n",
+                 pAdapterExt->pSataAdapter->adapterId, channelIndex, PMPort);
+        pAdapterExt->ataDriveData[channelIndex][PMPort].driveReady = MV_TRUE;
+        pAdapterExt->totalAccumulatedOutstanding[channelIndex] = 0;
+        pAdapterExt->ataDriveData[channelIndex][PMPort].stats.totalIOs = 0;
+        pAdapterExt->ataDriveData[channelIndex][PMPort].stats.totalSectorsTransferred = 0;
+    }
+    else
+    {
+        if (PMPort == 0xFF)
+        {
+            MV_U8   i;
+
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d  : SATA Channel is Removed.\n",
+                     pAdapterExt->pSataAdapter->adapterId, channelIndex);
+            for (i = 0; i < MV_SATA_PM_MAX_PORTS; i++)
+            {
+                mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d %d: SATA Drive is Removed.\n",
+                         pAdapterExt->pSataAdapter->adapterId, channelIndex,
+                         i);
+                pAdapterExt->ataDriveData[channelIndex][i].driveReady = MV_FALSE;
+            }
+
+        }
+        else
+        {
+            mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d %d: SATA Drive is Removed.\n",
+                     pAdapterExt->pSataAdapter->adapterId, channelIndex,
+                     PMPort);
+            pAdapterExt->ataDriveData[channelIndex][PMPort].driveReady = MV_FALSE;
+
+        }
+    }
+}
+
+
+/* notify the translation layer with Reset and Power on reset*/
+MV_VOID mvSataScsiNotifyUA(MV_SAL_ADAPTER_EXTENSION *pAdapterExt,
+                           MV_U8    channelIndex, MV_U8 PMPort)
+{
+    pAdapterExt->ataDriveData[channelIndex][PMPort].UAConditionPending = MV_TRUE;
+    /* bit 0 - reset*/
+    /* bit 1 - parameters changed*/
+    pAdapterExt->ataDriveData[channelIndex][PMPort].UAEvents = MV_BIT1 | MV_BIT0;
+    pAdapterExt->ataDriveData[channelIndex][PMPort].UAEvents &=
+    pAdapterExt->UAMask;
+    mvLogMsg(MV_SAL_LOG_ID, MV_DEBUG, " %d %d %d: Notify SAL with Unit Attention condition.\n",
+             pAdapterExt->pSataAdapter->adapterId, channelIndex, PMPort);
+}
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvScsiAtaLayer.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvScsiAtaLayer.h
new file mode 100644
index 0000000..5abaa9c
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sata/mvScsiAtaLayer.h
@@ -0,0 +1,402 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+/*******************************************************************************
+* mvScsiAtaLayer.c
+*
+* DESCRIPTION:
+*       C implementation for SCSI to ATA translation layer.
+*
+* DEPENDENCIES:
+*   mvIALCommonUtils.h
+*   mvSata.h
+*   mvStorageDev.h
+*   mvOs.h
+*
+*******************************************************************************/
+#ifndef __INCmvScsiAtaLayer
+#define __INCmvScsiAtaLayer
+
+#ifdef __cplusplus
+extern "C" {
+#endif /* __cplusplus */
+
+/* includes */
+#include "mvOs.h"
+#include "mvSata.h"
+#include "mvStorageDev.h"
+#include "mvIALCommonUtils.h"
+
+/* Defines */
+#define MV_SAL_LOG_ID       1
+
+
+#ifndef IN
+#define IN
+#endif
+
+#ifndef OUT
+#define OUT
+#endif
+
+#ifndef INOUT
+#define INOUT
+#endif
+
+/* Scsi opcodes*/
+/* 6 - bytes commands*/
+#define SCSI_OPCODE_TEST_UNIT_READY         0x00
+#define SCSI_OPCODE_REPORT_LUNS		    0xA0
+#define SCSI_OPCODE_REQUEST_SENSE6          0x03
+#define SCSI_OPCODE_REASSIGN_BLOCKS         0x07
+#define SCSI_OPCODE_READ6                   0x08
+#define SCSI_OPCODE_WRITE6                  0x0A
+#define SCSI_OPCODE_INQUIRY                 0x12
+#define SCSI_OPCODE_VERIFY6                 0x13
+#define SCSI_OPCODE_MODE_SELECT6            0x15
+#define SCSI_OPCODE_MODE_SENSE6             0x1A
+#define SCSI_OPCODE_START_STOP              0x1B
+
+/* 10 - bytes commands*/
+#define SCSI_OPCODE_READ_CAPACITY10         0x25
+#define SCSI_OPCODE_READ10                  0x28
+#define SCSI_OPCODE_WRITE10                 0x2A
+#define SCSI_OPCODE_VERIFY10                0x2F
+#define SCSI_OPCODE_SYNCHRONIZE_CACHE10     0x35
+#define SCSI_OPCODE_SEEK10                  0x2B
+#define SCSI_OPCODE_WRITE_LONG10            0x3F
+#define SCSI_OPCODE_READ_LONG10				0x3E
+
+/* 12 - bytes commands */
+/* 16 - bytes commands */
+#define SCSI_OPCODE_READ_CAPACITY16         0x9E
+#define SCSI_OPCODE_READ16                  0x88
+#define SCSI_OPCODE_WRITE16                 0x8A
+#define SCSI_OPCODE_VERIFY16                0x8F
+#define SCSI_OPCODE_SYNCHRONIZE_CACHE16     0x91
+#define SCSI_OPCODE_ATA16                   0x85
+#define SCSI_OPCODE_ATA12                   0xA1
+
+
+    /* SCSI bus status codes */
+#define MV_SCSI_STATUS_GOOD                  0x00
+#define MV_SCSI_STATUS_CHECK_CONDITION       0x02
+#define MV_SCSI_STATUS_CONDITION_MET         0x04
+#define MV_SCSI_STATUS_BUSY                  0x08
+#define MV_SCSI_STATUS_INTERMEDIATE          0x10
+#define MV_SCSI_STATUS_INTERMEDIATE_COND_MET 0x14
+#define MV_SCSI_STATUS_RESERVATION_CONFLICT  0x18
+#define MV_SCSI_STATUS_COMMAND_TERMINATED    0x22
+#define MV_SCSI_STATUS_QUEUE_FULL            0x28
+
+
+/* Typedefs */
+
+#if 0
+/* Scsi Sense Data Format */
+/* Max length - 18 bytes, the additional sense length will not exceed 10 bytes*/
+    typedef struct _mvScsiSenseData
+    {
+#ifdef MV_BIG_ENDIAN_BITFIELD
+        MV_U8 Valid:1;
+        MV_U8 ResponseCode:7;
+#else
+        MV_U8 ResponseCode:7;
+        MV_U8 Valid:1;
+#endif
+        MV_U8 Reserved1;
+#ifdef MV_BIG_ENDIAN_BITFIELD
+        MV_U8 FileMark:1;
+        MV_U8 EOM:1; /* End Of Media */
+        MV_U8 ILI:1; /* Incorrect Length Indicator*/
+        MV_U8 Reserved2:1;
+        MV_U8 SenseKey:4;
+#else
+        MV_U8 SenseKey:4;
+        MV_U8 Reserved2:1;
+        MV_U8 ILI:1; /* Incorrect Length Indicator*/
+        MV_U8 EOM:1; /* End Of Media */
+        MV_U8 FileMark:1;
+#endif        
+        MV_U8 Information[4];
+        MV_U8 AdditionalSenseLength;
+        MV_U8 CommandSpecificInformation[4];
+        MV_U8 AdditionalSenseCode;
+        MV_U8 AdditionalSenseCodeQualifier;
+        MV_U8 FieldReplaceableUnitCode;
+        MV_U8 SenseKeySpecific[3];
+    } MV_SCSI_SENSE_DATA;
+#else
+/* Scsi Sense Data Descriptor Format + information descriptor */
+/* Max length - 18 bytes, the additional sense length will not exceed 10 bytes*/
+    typedef struct _mvScsiInfoSenseDesc
+    {
+	    MV_U8 type;
+	    MV_U8 AdditionalLength;
+	    MV_U8 valid;
+	    MV_U8 reserved;
+	    MV_U8 information[11-4+1];
+    }MV_SCSI_INFO_SENSE_DESC;
+    typedef struct _mvScsiSenseData
+    {
+        MV_U8 ResponseCode;
+#ifdef MV_BIG_ENDIAN_BITFIELD
+        MV_U8 Reserved:4;
+        MV_U8 SenseKey:4;
+#else
+        MV_U8 SenseKey:4;
+        MV_U8 Reserved:4;
+#endif        
+        MV_U8 AdditionalSenseCode;
+        MV_U8 AdditionalSenseCodeQualifier;
+        MV_U8 Reserved2[3];
+        MV_U8 AdditionalSenseLength;
+	MV_SCSI_INFO_SENSE_DESC InformationDesc;
+    } MV_SCSI_SENSE_DATA;
+#endif
+/* Sense codes */
+
+#define SCSI_SENSE_NO_SENSE         0x00
+#define SCSI_SENSE_RECOVERED_ERROR  0x01
+#define SCSI_SENSE_NOT_READY        0x02
+#define SCSI_SENSE_MEDIUM_ERROR     0x03
+#define SCSI_SENSE_HARDWARE_ERROR   0x04
+#define SCSI_SENSE_ILLEGAL_REQUEST  0x05
+#define SCSI_SENSE_UNIT_ATTENTION   0x06
+#define SCSI_SENSE_DATA_PROTECT     0x07
+#define SCSI_SENSE_BLANK_CHECK      0x08
+#define SCSI_SENSE_UNIQUE           0x09
+#define SCSI_SENSE_COPY_ABORTED     0x0A
+#define SCSI_SENSE_ABORTED_COMMAND  0x0B
+#define SCSI_SENSE_EQUAL            0x0C
+#define SCSI_SENSE_VOL_OVERFLOW     0x0D
+#define SCSI_SENSE_MISCOMPARE       0x0E
+#define SCSI_SENSE_RESERVED         0x0F
+
+/* Additional Sense codes */
+
+#define SCSI_ADSENSE_NO_SENSE       0x00
+#define SCSI_ADSENSE_ILLEGAL_COMMAND 0x20
+#define SCSI_ADSENSE_ILLEGAL_BLOCK  0x21
+#define SCSI_ADSENSE_INVALID_CDB    0x24
+#define SCSI_ADSENSE_INVALID_LUN    0x25
+#define SCSI_ADSENSE_INVALID_FIELD_IN_PARAMETER_LIST    0x26
+#define SCSI_ADSENSE_BUS_RESET      0x29
+#define SCSI_ADSENSE_PARAMETERS_CHANGED     0x2A
+#define SCSI_ADSENSE_NO_MEDIA_IN_DEVICE 0x3a
+
+
+#define MV_SCSI_RESPONSE_CODE   0x72
+#define MV_SCSI_DIRECT_ACCESS_DEVICE    0x00
+#define MV_MAX_MODE_SENSE_RESULT_LENGTH 50
+
+
+/* Typedefs */
+    typedef enum _mvScsiCompletionType
+    {
+        MV_SCSI_COMPLETION_INVALID_STATUS,
+        MV_SCSI_COMPLETION_SUCCESS,
+        MV_SCSI_COMPLETION_BAD_SCB,
+        MV_SCSI_COMPLETION_BAD_SCSI_COMMAND,
+        MV_SCSI_COMPLETION_ATA_FAILED,
+        MV_SCSI_COMPLETION_QUEUE_FULL,
+        MV_SCSI_COMPLETION_NOT_READY,
+        MV_SCSI_COMPLETION_ABORTED,
+        MV_SCSI_COMPLETION_OVERRUN,
+        MV_SCSI_COMPLETION_UNDERRUN,
+        MV_SCSI_COMPLETION_PARITY_ERROR,
+        MV_SCSI_COMPLETION_DISCONNECT,
+        MV_SCSI_COMPLETION_NO_DEVICE,
+        MV_SCSI_COMPLETION_INVALID_BUS,
+        MV_SCSI_COMPLETION_BUS_RESET,
+        MV_SCSI_COMPLETION_BUSY,
+        MV_SCSI_COMPLETION_UA_RESET,
+        MV_SCSI_COMPLETION_UA_PARAMS_CHANGED
+    }MV_SCSI_COMPLETION_TYPE;
+
+    typedef enum _mvScsiCommandStatus
+    {
+        MV_SCSI_COMMAND_STATUS_COMPLETED,
+        MV_SCSI_COMMAND_STATUS_QUEUED,
+        MV_SCSI_COMMAND_STATUS_FAILED,
+        MV_SCSI_COMMAND_STATUS_QUEUED_BY_IAL
+    }MV_SCSI_COMMAND_STATUS_TYPE;
+
+    typedef enum _mvScsiCommandDataDirection
+    {
+        MV_SCSI_COMMAND_DATA_DIRECTION_NON,
+        MV_SCSI_COMMAND_DATA_DIRECTION_IN,
+        MV_SCSI_COMMAND_DATA_DIRECTION_OUT
+    } MV_SCSI_COMMAND_DATA_DIRECTION;
+
+    struct _mvSataScsiCmdBlock;
+
+    typedef MV_BOOLEAN (* mvScsiCommandCompletionCallBack)(struct mvSataAdapter *,
+                                                           struct _mvSataScsiCmdBlock*);
+
+    struct mvSalAdapterExtension;
+    struct mvIalCommonAdapterExtension;
+
+    typedef struct _mvSataScsiCmdBlock
+    {
+        /*  the Scsi command data block buffer*/
+        IN MV_U8*       ScsiCdb;
+
+        /* the length in bytes of the CDB (6,10,12,16)*/
+        IN MV_U32       ScsiCdbLength;
+
+        /* the scsi bus*/
+        IN MV_U8        bus;
+
+        /* the target device id*/
+        IN MV_U8        target;
+
+        /* scsi lun number of the device*/
+        IN MV_U8        lun;
+
+        /* True when the data located in the buffer pointed by pDataBuffer  */
+        /* (virtual address), false when the command is READ/WRITE, in this */
+        /* case the data located in a PRD table*/
+        /*IN MV_BOOLEAN useSingleBuffer;*/
+
+        /* pointer to the command data buffer*/
+        IN MV_U8        *pDataBuffer;
+
+        /* length in bytes of the command data buffer*/
+        IN MV_U32       dataBufferLength;
+
+        /* number of entries in the PRD table*/
+        /*IN MV_U32     PRDTableEntries; */
+
+        /* low 32 bits of the PRD table physical address*/
+        IN MV_U32       PRDTableLowPhyAddress;
+
+        /* high 32 bits of the PRD table physical address*/
+        IN MV_U32       PRDTableHighPhyAddress;
+
+#ifdef MV_SATA_SUPPORT_EDMA_SINGLE_DATA_REGION
+        MV_BOOLEAN      singleDataRegion;
+        MV_U16          byteCount;
+#endif
+        /* the Scsi status will be written to this field*/
+        OUT MV_U8       ScsiStatus;
+
+        /* pointer to the Scsi sense buffer*/
+        IN MV_U8*       pSenseBuffer;
+
+        /* length in bytes of the Scsi sense buffer*/
+        IN MV_U32       senseBufferLength;
+
+        /* length in bytes of the generated sense data*/
+        OUT MV_U32      senseDataLength;
+
+        /* length in bytes of the data transferred to the data buffer/s*/
+        OUT MV_U32      dataTransfered;
+
+        /* the translation layer status of the completed Scsi command */
+        OUT MV_SCSI_COMPLETION_TYPE ScsiCommandCompletion;
+        /* call back function called by the translation layer when the Scsi */
+        /* completed    */
+        IN mvScsiCommandCompletionCallBack completionCallBack;
+
+        IN struct mvSalAdapterExtension * pSalAdapterExtension;
+        IN struct mvIALCommonAdapterExtension* pIalAdapterExtension;
+
+        IN MV_SCSI_COMMAND_DATA_DIRECTION dataDirection;
+#ifdef MV_SATA_STORE_COMMANDS_INFO_ON_IAL_STACK
+        MV_QUEUE_COMMAND_INFO   *pCommandInfo;
+#endif
+        /* field for IAL usage only*/
+        MV_VOID_PTR     IALData;
+        /* fields for internal usage for the translation layer*/
+
+
+        MV_UDMA_TYPE            udmaType;
+        MV_QUEUED_COMMAND_TYPE  commandType;
+        /* used for sense buffer */
+        MV_U32                  LowLbaAddress;
+        /* Used for non-UDMA and for sense buffer */
+        MV_BOOLEAN              isExtended;
+        MV_U16                  splitCount;
+        MV_U16                  sequenceNumber;
+        /* used to create list for comands that need post interrupt service */
+        struct _mvSataScsiCmdBlock  *pNext;
+#ifdef MV_LOGGER
+        MV_STORAGE_DEVICE_REGISTERS ATAregStruct;
+#endif
+    }MV_SATA_SCSI_CMD_BLOCK;
+
+    typedef struct
+    {
+        MV_U32              totalIOs;
+        MV_U32              totalSectorsTransferred;
+    }MV_SATA_SCSI_CHANNEL_STATS;
+
+    typedef struct
+    {
+        MV_BOOLEAN          driveReady;
+        ATA_IDENTIFY_INFO   identifyInfo;
+        MV_U16_PTR          identifyBuffer;
+        MV_SATA_SCSI_CHANNEL_STATS stats;
+        MV_BOOLEAN          UAConditionPending;
+        MV_U8               UAEvents;
+    }MV_SATA_SCSI_DRIVE_DATA;
+
+    typedef struct mvSalAdapterExtension
+    {
+        MV_SATA_ADAPTER *pSataAdapter;
+        MV_SATA_SCSI_CMD_BLOCK  *pHead;
+        MV_U8                   UAMask;/*which UA condictions to report*/
+        MV_U32  totalAccumulatedOutstanding[MV_SATA_CHANNELS_NUM];
+        MV_SATA_SCSI_DRIVE_DATA     ataDriveData[MV_SATA_CHANNELS_NUM][MV_SATA_PM_MAX_PORTS];
+        MV_U16  identifyBuffer[MV_SATA_CHANNELS_NUM][MV_ATA_IDENTIFY_DEV_DATA_LENGTH];
+
+    }MV_SAL_ADAPTER_EXTENSION;
+
+
+    MV_VOID     mvSataScsiInitAdapterExt(MV_SAL_ADAPTER_EXTENSION *pAdapterExt,
+                                         MV_SATA_ADAPTER* pSataAdapter);
+
+    MV_VOID     mvSataScsiPostIntService(MV_SAL_ADAPTER_EXTENSION *pAdapterExt);
+
+
+    MV_SCSI_COMMAND_STATUS_TYPE mvSataExecuteScsiCommand(MV_SATA_SCSI_CMD_BLOCK *pMvSataScsiCmdBlock);
+
+    MV_VOID     mvSataScsiSetDriveReady(MV_SAL_ADAPTER_EXTENSION *pAdapterExt,
+                                        MV_U8   channelIndex, MV_U8 PMPort,
+                                        MV_BOOLEAN  isReady);
+
+    MV_VOID mvSataScsiNotifyUA(MV_SAL_ADAPTER_EXTENSION *pAdapterExt,
+                               MV_U8    channelIndex, MV_U8 PMPort);
+
+/* Locals */
+
+#ifdef __cplusplus
+}
+#endif /* __cplusplus */
+
+#endif /* __IsNCmvScsiAtaLayer */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/Kconfig
new file mode 100644
index 0000000..8ae9bf8
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/Kconfig
@@ -0,0 +1,14 @@
+menu "Marvell SDIO\MMC driver"
+	depends on MV_INCLUDE_SDIO
+
+
+config MMC_MVSDMMC
+	tristate "Marvell SDIO host driver"
+	depends on MMC && MV_INCLUDE_SDIO
+	---help---
+	  This selects the Marvell SDIO host driver
+	  say Y or M here.
+	  If unsure, say N.
+
+endmenu
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/Makefile
new file mode 100644
index 0000000..e77618a
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/Makefile
@@ -0,0 +1,12 @@
+#
+# Makefile for the Marvell Audio ALSA Device Driver
+#
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+obj-$(CONFIG_MMC_MVSDMMC)	+= mvsdmmc.o
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/mvsdmmc.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/mvsdmmc.c
new file mode 100644
index 0000000..aeeb982
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/mvsdmmc.c
@@ -0,0 +1,1615 @@
+/*
+*
+* Marvell Orion SD\MMC\SDIO driver
+*
+* Author: Maen Suleiman
+* Copyright (C) 2008 Marvell Ltd.
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License version 2 as
+* published by the Free Software Foundation.
+*
+*/
+/*
+ * mvsdmmc TODO list:
+ *
+ * --> Set timeout value according to timeout_ns and timeout_clks,
+ *  meanwhile a maximum value is set for the host
+ *
+ * --> Report errors in mrq->data->stop->error and in mrq->data->error,
+ *  meanwhile errors are reported in the command itself since always the
+ *  completion of data and AutoCmd12 are done with the originated command.
+ *
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/init.h>
+#include <linux/ioport.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+#include <linux/mbus.h>
+#endif
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/dma-mapping.h>
+#include <linux/scatterlist.h>
+#include <linux/mmc/host.h>
+#include <linux/proc_fs.h>
+#include <linux/irq.h>
+
+
+#include <asm/dma.h>
+#include <asm/sizes.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+#include <asm/plat-orion/mvsdmmc-orion.h>
+#endif
+
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "mvsdmmc.h"
+
+#undef MVSDMMC_DEBUG
+#undef MVSDMMC_DUMP_REGS_ON_CMD
+#define MVSDMMC_DUMP_ALL_REGS_ON_ERROR
+#define MVSDMMC_DBG_ERROR
+
+#undef MVSDMMC_DBG_FUNC_ENTRY
+#ifdef MVSDMMC_DBG_FUNC_ENTRY
+#define mvsdmmc_dbg_enter()	printk(KERN_DEBUG "ENTER <=%s\n",  __func__)
+#define mvsdmmc_dbg_exit()	printk(KERN_DEBUG "EXIT  <=%s\n",  __func__)
+#else
+#define mvsdmmc_dbg_enter()
+#define mvsdmmc_dbg_exit()
+#endif
+
+#undef MVSDMMC_WARN
+#ifdef MVSDMMC_WARN
+#define mvsdmmc_warning(host, fmt, arg...) 	\
+			dev_printk(KERN_INFO, &host->pdev->dev, fmt, ##arg) 
+#else 
+#define mvsdmmc_warning(host, a...) 
+#endif 
+#ifdef MVSDMMC_DEBUG
+#define mvsdmmc_debug(host, fmt, arg...) 	\
+			dev_printk(KERN_DEBUG, &host->pdev->dev, fmt, ##arg) 
+#else 
+#define mvsdmmc_debug(host, a...) 
+#endif
+
+#if defined(MVSDMMC_DBG_ERROR)
+#define mvsdmmc_debug_error(host, fmt, arg...)	\
+			  dev_printk(KERN_ERR, &host->pdev->dev, fmt, ##arg) 
+#else 
+#define mvsdmmc_debug_error(host, a...) 
+#endif
+
+#define DRIVER_NAME	"mvsdmmc"
+
+
+struct mvsdmmc_host_stat {
+
+	int total_requests;
+	int copied_data;
+	int total_data;
+	int unaligned_buf;
+	int cache_unaligned_buf;
+	int ints;
+	int error_ints;
+	int card_ints;
+	int unfinished_dma;
+	int buf_256;
+	int cmd_timeout;
+	int int_timeout;
+	int empty_int;
+	int first_int_status;
+	int first_error_status;
+	int detect_int;
+	int first_err_int;	/* request number of first error interrupt */
+	int first_unfinished_dma;/* request number of first unfinished dma */ 
+};
+
+struct mvsdmmc_host {
+	struct mmc_host		*mmc;		/* associated mmc structure */
+	struct platform_device	*pdev;		/* platform device */
+	spinlock_t		lock;		/* spin lock of the host */
+	struct resource		*res;		/* resource for IRQ and base */
+	void __iomem		*base;		/* base address of the host
+						 *  registers
+						 */
+	int			irq;		/* host IRQ number */
+	int			irq_detect;	/* host IRQ number for
+						 * insertion/detection
+						 */
+	char			*dma_buffer;	/* virtual address for
+						temp buffer*/
+	dma_addr_t		dma_addr;	/* Physical address for
+						remp buffer */
+	unsigned int		dma_len;	/* sg fragments number
+						 * of the request
+						 */
+	int			size;		/* Total size of transfer */
+	unsigned char		power_mode;	/* power status */
+	struct mmc_request	*mrq;		/* current mmc request
+						 *  structure
+						 */
+	struct mmc_command	*cmd;		/* current mmc command
+						 * structure
+						 */
+	struct mmc_data		*data;		/* current mmc data structure */
+	unsigned short		intr_status;	/* interrupt status on IRQ */
+	unsigned short		intr_en;	/* enabled interrupts
+						 * during command- status
+						 */
+	unsigned short		intr_cmd;	/* enabled interrupts
+						 * during command
+						 */
+	unsigned int		cmd_data;	/* if cmd\data are proccesed */
+	#define	MVSDMMC_CMD	0x1
+	#define	MVSDMMC_DATA	0x2
+	#define	MVSDMMC_CMD12	0x4
+	unsigned int		pending_commands;/* commands on process*/
+	int			card_present;	/* if card present*/
+	struct timer_list	timer;		/* Timer for timeouts */
+	unsigned int		copy_buf;	/* copy to host buffer*/
+	unsigned int		bad_size;	/* unaligned size */
+	struct mvsdmmc_host_stat	stat;	/* host statistics */
+};
+
+
+static int maxfreq = MVSDMMC_CLOCKRATE_MAX; 
+static int highspeed = 1;
+static int detect = 1;
+static int dump_on_error;
+
+static void mvsdmmc_request_done(struct mvsdmmc_host *host);
+static void mvsdmmc_power_down(struct mmc_host *mmc);
+static void mvsdmmc_power_up(struct mmc_host *mmc);
+static void mvsdmmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios);
+
+static inline void mvsdmmc_sg_to_dma(struct mvsdmmc_host *host,
+				     struct mmc_data *data);
+static inline void mvsdmmc_dma_to_sg(struct mvsdmmc_host *host,
+				     struct mmc_data *data);
+static irqreturn_t mvsdmmc_irq(int irq, void *dev);
+static irqreturn_t mvsdmmc_irq_detect(int irq, void *dev);
+
+#define mvsdmmc_writew(host, offs, val)	\
+		writew((val), (host->base + offs))
+
+
+static inline unsigned short mvsdmmc_readw(struct mvsdmmc_host *host,
+					   unsigned short offs)
+{
+	unsigned short val = readw((host->base + offs));
+	return (val);
+}
+
+#define mvsdmmc_bitset(host, offs, bitmask)	\
+		writew((readw(host->base + offs) | (bitmask)),	\
+			host->base + offs)
+
+#define mvsdmmc_bitreset(host, offs, bitmask)	\
+		writew((readw(host->base + offs) & (~(bitmask))),	\
+			host->base + offs)
+
+int mvsdmmc_read_procmem(char *buf, char **start, off_t offset,
+			 int count, int *eof, void *data) 
+{
+
+	int len = 0;
+	struct mvsdmmc_host *host = (struct mvsdmmc_host *)data;
+
+	len += sprintf(buf+len, "\ntotal requests=%d\n",
+		host->stat.total_requests);
+	len += sprintf(buf+len, "total data=%d\n",
+		host->stat.total_data);
+	len += sprintf(buf+len, "copied data=%d\n", host->stat.copied_data);
+	len += sprintf(buf+len, "buffers small than 256=%d\n",
+		host->stat.buf_256);
+	len += sprintf(buf+len, "buffers not word aligned=%d\n",
+			 host->stat.unaligned_buf);
+	len += sprintf(buf+len, "buffers not cache line aligned=%d\n",
+			host->stat.cache_unaligned_buf);
+	len += sprintf(buf+len, "total interrupts=%d\n", host->stat.ints);
+	len += sprintf(buf+len, "total card ints=%d\n", host->stat.card_ints);
+	len += sprintf(buf+len, "total error ints=%d\n", host->stat.error_ints);
+	len += sprintf(buf+len, "Request num of first error int=%d\n",
+			host->stat.first_err_int);
+	len += sprintf(buf+len, "Status of int on first error int=0x%x\n",
+			(unsigned int)host->stat.first_int_status);
+	len += sprintf(buf+len, "Status of first error int=0x%x\n",
+			(unsigned int)host->stat.first_error_status);
+	len += sprintf(buf+len, "Empty interrupts=%d\n", host->stat.empty_int);
+	len += sprintf(buf+len, "Detect interrupts=%d\n",
+				host->stat.detect_int);
+	len += sprintf(buf+len, "Unifinished dma=%d\n",
+		host->stat.unfinished_dma);
+	len += sprintf(buf+len, "Request num of first unfinished dma=%d\n",
+			host->stat.first_unfinished_dma);
+	len += sprintf(buf+len, "interrupt timeouts=%d\n",
+		host->stat.int_timeout);
+	len += sprintf(buf+len, "command timeouts=%d\n",
+					host->stat.cmd_timeout);
+
+	*eof = 1;
+
+	memset(&host->stat , sizeof(struct mvsdmmc_host_stat), 0);
+
+	return len;
+
+}
+
+static void mvsdmmc_dump_registers(struct mvsdmmc_host *host,
+				   unsigned short cmdreg)
+{
+	unsigned int reg;
+
+	for (reg = SDIO_SYS_ADDR_LOW; reg <= SDIO_AUTO_RSP2; reg += 4) {
+		if (reg == SDIO_CMD) {
+			mvsdmmc_debug(host, "reg 0x%x = 0x%x \n", reg,
+				      (unsigned int)cmdreg);
+			continue;
+		}
+
+		mvsdmmc_debug(host, "reg 0x%x = 0x%x \n", reg,
+			      (unsigned int)mvsdmmc_readw(host, reg));
+	}
+	for (reg = 0x100; reg <= 0x130; reg += 4) {
+		mvsdmmc_debug(host, "reg 0x%x = 0x%x \n", reg,
+			      (unsigned int)mvsdmmc_readw(host, reg));
+	}
+}
+
+
+static inline u32 mvsdmmc_aligned_size(u32 size)
+{
+	return ((size + 3) / 4) * 4;
+}
+
+/*
+ * Tx alignment. This is a workaround for problems with
+ * data sizes which are not 4-bytes aligned.
+ * Currently this function only works for LSB_FIRST=0.
+ */
+static void mvsdmmc_align_tx_data(struct mvsdmmc_host *host,
+					struct mmc_data *data)
+{
+	u32 size = data->blocks * data->blksz;
+	u32 aligned_size = mvsdmmc_aligned_size(size);
+	u8 *ptr = (u8 *)sg_virt_addr(data->sg);
+	u8 *end = ptr + aligned_size-4;
+	u32 remainder = size%4;
+	u8 tmp[4];
+
+	if (!remainder)
+		return;
+
+	data->sg->length = aligned_size;
+	memcpy(tmp, end, 4);
+	memset(end, 0, 4);
+	memcpy(end+4-remainder, tmp, remainder);
+}
+
+
+/*
+ * Rx alignment. This is a workaround for problems with
+ * data sizes which are not 4-bytes aligned.
+ * Currently this function only works for LSB_FIRST=0
+ */
+static void mvsdmmc_align_rx_data(struct mvsdmmc_host *host,
+					struct mmc_data *data)
+{
+	u32 size = data->blocks * data->blksz;
+	u32 aligned_size = mvsdmmc_aligned_size(size);
+	u8 *ptr = (u8 *)sg_virt_addr(data->sg);
+	u8 *end = ptr + aligned_size-4;
+	u32 remainder = size%4;
+	u8 tmp[4];
+
+	if (!remainder)
+		return;
+
+	data->sg->length = aligned_size;
+	memcpy(tmp, end, 4);
+	memset(end, 0, 4);
+	memcpy(end, &tmp[4-remainder], remainder);
+}
+
+
+
+
+
+
+static void mvsdmmc_stop_clock(struct mvsdmmc_host *host)
+{
+
+	mvsdmmc_dbg_enter();
+	mvsdmmc_bitset(host, SDIO_XFER_MODE, SDIO_XFER_MODE_STOP_CLK);
+	mvsdmmc_dbg_exit();
+}
+
+static void __mvsdmmc_enable_irq(struct mvsdmmc_host *host, unsigned int mask)
+{
+	host->intr_en |= mask;
+	mvsdmmc_writew(host, SDIO_NOR_INTR_EN, host->intr_en);
+	host->intr_cmd |= mask; /* intr_cmd is zeroed in mvsdmmc_start_cmd */
+	if (mask == SDIO_NOR_CARD_INT)
+		mvsdmmc_bitset(host, SDIO_XFER_MODE,
+			       SDIO_XFER_MODE_INT_CHK_EN);
+}
+static void mvsdmmc_enable_irq(struct mvsdmmc_host *host, unsigned int mask)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&host->lock, flags);
+	__mvsdmmc_enable_irq(host, mask);
+	spin_unlock_irqrestore(&host->lock, flags); 
+}
+
+static void __mvsdmmc_disable_irq(struct mvsdmmc_host *host, unsigned int mask)
+{
+	host->intr_en &= ~mask;
+	mvsdmmc_writew(host, SDIO_NOR_INTR_EN, host->intr_en);
+	if (mask == SDIO_NOR_CARD_INT)
+		mvsdmmc_bitreset(host, SDIO_XFER_MODE,
+				 SDIO_XFER_MODE_INT_CHK_EN);
+}
+
+static void mvsdmmc_disable_irq(struct mvsdmmc_host *host, unsigned int mask)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&host->lock, flags);
+	__mvsdmmc_disable_irq(host, mask);
+	spin_unlock_irqrestore(&host->lock, flags); 
+}
+
+static void mvsdmmc_setup_data(struct mvsdmmc_host *host, struct mmc_data *data)
+{
+	char	*virt_addr = NULL;
+	dma_addr_t	phys_addr = 0;
+	u32		reg;
+
+	mvsdmmc_dbg_enter();
+
+	host->stat.total_data++;
+
+	/*
+	 * Calculate size.
+	 */
+	host->size = data->blocks * data->blksz;
+
+	host->bad_size = 0;
+
+	host->copy_buf = 0;
+	
+	if (data->flags & MMC_DATA_READ) {
+
+		if (host->size & 0x3)
+			mvsdmmc_align_rx_data(host, data);
+
+		host->dma_len = dma_map_sg(mmc_dev(host->mmc), data->sg,
+					   data->sg_len,
+					   DMA_FROM_DEVICE);
+
+		BUG_ON(host->dma_len == 0);
+		phys_addr = sg_dma_address(data->sg);
+
+		if (host->dma_len > 1) {
+			host->copy_buf = 1;
+		}
+	}
+
+	if (data->flags & MMC_DATA_WRITE) {
+
+		if (host->size & 0x3)
+			mvsdmmc_align_tx_data(host, data);
+
+		host->dma_len = dma_map_sg(mmc_dev(host->mmc),
+					   data->sg, data->sg_len,
+					   DMA_TO_DEVICE);
+		BUG_ON(host->dma_len == 0);
+		phys_addr = sg_dma_address(data->sg);
+
+		if (host->dma_len > 1)
+			host->copy_buf = 1;
+	}
+
+	if (phys_addr & 0x3)
+		host->copy_buf = 1;
+
+	reg = mvsdmmc_readw(host, SDIO_HOST_CTRL);
+	
+	if (host->bad_size) {
+		reg &= ~SDIO_HOST_CTRL_BIG_ENDIAN;
+		host->copy_buf = 1;
+	} else {
+		reg |= SDIO_HOST_CTRL_BIG_ENDIAN;
+	}
+	mvsdmmc_writew(host, SDIO_HOST_CTRL, reg);
+
+        if (host->copy_buf) {
+
+			virt_addr = host->dma_buffer;
+			phys_addr = host->dma_addr;
+	}
+
+	BUG_ON(host->size > MVSDMMC_DMA_SIZE);
+
+	if ((data->flags & MMC_DATA_WRITE) && (host->copy_buf)) {
+		/*
+		* Transfer data from the SG list to
+		* the DMA buffer.
+		*/
+		BUG_ON(virt_addr == NULL);
+		mvsdmmc_sg_to_dma(host, data);
+		dma_sync_single_for_device(mmc_dev(host->mmc),
+					host->dma_addr,
+					mvsdmmc_aligned_size(host->size),
+					DMA_TO_DEVICE);
+
+	} else if ((data->flags & MMC_DATA_READ) && (host->copy_buf)) {
+
+		dma_sync_single_for_device(mmc_dev(host->mmc),
+					host->dma_addr,
+					mvsdmmc_aligned_size(host->size),
+					DMA_FROM_DEVICE);
+	}
+
+	mvsdmmc_writew(host, SDIO_BLK_COUNT, data->blocks);
+	mvsdmmc_writew(host, SDIO_SYS_ADDR_LOW,
+		       (0xffff & ((unsigned int)phys_addr)));
+	mvsdmmc_writew(host, SDIO_SYS_ADDR_HI,
+		       (0xffff & (((unsigned int)phys_addr) >> 16)));
+
+	mvsdmmc_writew(host, SDIO_BLK_SIZE, data->blksz);
+
+	mvsdmmc_dbg_exit();
+
+}
+
+static void mvsdmmc_start_cmd(struct mvsdmmc_host *host,
+			      struct mmc_command *cmd)
+{
+
+	struct mmc_data		*data = host->mrq->data;
+	struct mmc_request	*mrq = cmd->mrq;
+	unsigned short cmdreg = 0, xfer = 0;
+	unsigned short intr_enable = 0;
+
+	mvsdmmc_dbg_enter();
+	BUG_ON(host->cmd_data);
+	BUG_ON(host->cmd == NULL);
+
+	/* disable interrupts */
+	mvsdmmc_writew(host, SDIO_ERR_INTR_EN, 0);
+	/* clear error status */
+	mvsdmmc_writew(host, SDIO_ERR_INTR_STATUS,
+			mvsdmmc_readw(host, SDIO_ERR_INTR_STATUS));
+
+	BUG_ON(host->intr_en & ~SDIO_NOR_CARD_INT);
+
+	/* reset host->intr_cmd*/
+	host->intr_cmd = 0;
+
+	if (cmd->flags != MMC_RSP_NONE) {
+		intr_enable |= SDIO_NOR_UNEXP_RSP;
+		cmdreg |= SDIO_UNEXPECTED_RESP;
+	}
+	if (cmd->flags & MMC_RSP_OPCODE)
+		cmdreg |= SDIO_CMD_INDX_CHECK;
+
+
+	if (cmd->flags == MMC_RSP_NONE)
+		cmdreg |= SDIO_CMD_RSP_NONE;
+	else if (cmd->flags & MMC_RSP_BUSY)
+		cmdreg |= SDIO_CMD_RSP_48BUSY;
+	else if (cmd->flags & MMC_RSP_136)
+		cmdreg |= SDIO_CMD_RSP_136;
+	else if (cmd->flags & MMC_RSP_PRESENT)
+		cmdreg |= SDIO_CMD_RSP_48;
+
+	if (cmd->flags & MMC_RSP_CRC)
+		cmdreg |= (SDIO_CMD_CHECK_CMDCRC);
+
+	if (data) {
+		host->data = mrq->data;
+		mvsdmmc_setup_data(host, mrq->data);
+
+		/* if multiple blocks and need AutoCMD12*/
+		if (data->stop) {
+			struct mmc_command *stop = data->stop;
+			mvsdmmc_writew(host, SDIO_AUTOCMD12_ARG_LOW,
+				       stop->arg & 0xffff);
+			mvsdmmc_writew(host, SDIO_AUTOCMD12_ARG_HI,
+				       stop->arg >> 16);
+			mvsdmmc_writew(host, SDIO_AUTOCMD12_INDEX,
+				       (stop->opcode << 8) | 3);
+			/* enable autocmd12 interrupt*/
+			intr_enable |= SDIO_NOR_AUTOCMD12_DONE;
+
+			xfer |= SDIO_XFER_MODE_AUTO_CMD12;
+			host->cmd_data = (MVSDMMC_CMD | MVSDMMC_CMD12);
+		} else {
+			/* enable data interrupt*/
+			intr_enable |= SDIO_NOR_DMA_INI;
+			host->cmd_data = (MVSDMMC_CMD|MVSDMMC_DATA);
+		}
+
+		/* default values */
+		cmdreg |= SDIO_CMD_CHECK_DATACRC16;
+		cmdreg |= SDIO_CMD_DATA_PRESENT;
+		xfer |= SDIO_XFER_MODE_HW_WR_DATA_EN;
+
+		if (data->flags & MMC_DATA_READ)
+			xfer |= SDIO_XFER_MODE_TO_HOST;
+		else if (data->flags & MMC_DATA_WRITE)
+			xfer &= ~SDIO_XFER_MODE_TO_HOST;
+	} else {
+		intr_enable |= SDIO_NOR_CMD_DONE;
+		cmdreg &= ~SDIO_CMD_DATA_PRESENT;
+		host->cmd_data = MVSDMMC_CMD;
+	}
+
+	if (host->intr_en & SDIO_NOR_CARD_INT)
+		xfer |= SDIO_XFER_MODE_INT_CHK_EN;
+
+	cmdreg |= ((cmd->opcode & 0xff) << 0x8);
+
+	mvsdmmc_writew(host, SDIO_ARG_LOW, cmd->arg & 0xffff);
+	mvsdmmc_writew(host, SDIO_ARG_HI, cmd->arg >> 16);
+	mvsdmmc_writew(host, SDIO_XFER_MODE, xfer);
+
+	/* start timer */
+	mod_timer(&host->timer, jiffies + 5 * HZ);
+
+	__mvsdmmc_enable_irq(host, intr_enable);
+
+	host->pending_commands++;
+
+	/* enable error interrupts*/
+	mvsdmmc_writew(host, SDIO_ERR_INTR_EN, 0xffff); 
+#if defined(MVSDMMC_DUMP_REGS_ON_CMD)
+	mvsdmmc_debug_error(host, "================================>\n");
+	mvsdmmc_debug_error(host, "CMD%d Start \n", host->cmd->opcode);
+	mvsdmmc_dump_registers(host, cmdreg);
+#endif
+	mvsdmmc_writew(host, SDIO_CMD, cmdreg);
+
+	BUG_ON(host->intr_en == 0);
+	BUG_ON(host->intr_en == SDIO_NOR_UNEXP_RSP);
+
+}
+
+
+static void mvsdmmc_finish_data(struct mvsdmmc_host *host) {
+	char				*virt_addr;
+	struct mmc_data	*data = host->data;
+	u32		blocks_left;
+	unsigned short response[3], resp_indx = 0;
+
+
+	BUG_ON(data == NULL);
+	BUG_ON(!(host->intr_status & SDIO_NOR_AUTOCMD12_DONE) &&
+		!(host->intr_status & SDIO_NOR_DMA_INI));
+
+	if (host->intr_status & SDIO_NOR_AUTOCMD12_DONE) {
+		host->cmd_data &= ~MVSDMMC_CMD12;
+		host->intr_status &= ~(SDIO_NOR_AUTOCMD12_DONE);
+	} else if (host->intr_status & SDIO_NOR_DMA_INI) {
+		host->cmd_data &= ~MVSDMMC_DATA;
+		host->intr_status &= ~(SDIO_NOR_DMA_INI);
+	}
+
+	if (!host->copy_buf)
+		BUG_ON(host->dma_len == 0);
+
+	if ((data->flags & MMC_DATA_READ) && (host->copy_buf)) {
+
+		virt_addr = host->dma_buffer;
+		BUG_ON(virt_addr == NULL);
+		dma_sync_single_for_cpu(mmc_dev(host->mmc),
+					host->dma_addr,
+					host->size,
+					DMA_FROM_DEVICE);
+
+		/*
+		* Transfer data from DMA buffer to
+		* SG list.
+		*/
+		mvsdmmc_dma_to_sg(host, data);
+
+		mvsdmmc_align_rx_data(host, data);
+
+	} else if ((data->flags & MMC_DATA_WRITE) && (host->copy_buf)) {
+
+		dma_sync_single_for_cpu(mmc_dev(host->mmc),
+					host->dma_addr,
+					host->size,
+					DMA_TO_DEVICE);
+
+	}
+
+	if ((!host->copy_buf) && (data->flags & MMC_DATA_READ))
+		dma_unmap_sg(mmc_dev(host->mmc), data->sg, host->dma_len,
+			     DMA_FROM_DEVICE);
+
+	if ((!host->copy_buf) && (data->flags & MMC_DATA_WRITE))
+		dma_unmap_sg(mmc_dev(host->mmc), data->sg, host->dma_len,
+			     DMA_TO_DEVICE);
+
+	/* check how much data was transfered */
+	blocks_left = mvsdmmc_readw(host, SDIO_CURR_BLK_LEFT);
+	if (blocks_left) {
+		u32 bytes_left = mvsdmmc_readw(host, SDIO_CURR_BYTE_LEFT);
+		data->bytes_xfered = host->size -
+			(((blocks_left - 1) * data->blksz) + bytes_left);
+	} else {
+		data->bytes_xfered = host->size;
+	}
+
+	/* Handle Auto cmd 12 response */
+	if (data->stop) {
+
+		for (resp_indx = 0 ; resp_indx < 3; resp_indx++)
+			response[resp_indx] =
+				mvsdmmc_readw(host, SDIO_AUTO_RSP(resp_indx));
+
+		memset(data->stop->resp, 0, 4 * sizeof(data->stop->resp[0]));
+
+		data->stop->resp[0] = ((response[2] & 0x3f) << (8 - 8)) |
+			((response[1] & 0xffff) << (14 - 8)) |
+			((response[0] & 0x3ff) << (30 - 8));
+		data->stop->resp[1] = ((response[0] & 0xfc00) >> 10);
+
+	}
+
+
+	if (data->bytes_xfered != host->size) {
+		host->stat.unfinished_dma++;
+
+		if (host->stat.unfinished_dma == 1)
+			host->stat.first_unfinished_dma =
+				host->stat.total_requests;
+
+		mvsdmmc_warning(host, "data transfere not complete\n");
+		mvsdmmc_warning(host, "data transfered =%d"
+					  "original size= %d\n",
+					data->bytes_xfered, host->size);
+	}
+
+	host->data = NULL;
+}
+
+static void mvsdmmc_finish_cmd(struct mvsdmmc_host *host) {
+	unsigned short response[8], resp_indx = 0;
+	struct mmc_command	*cmd = host->cmd;
+
+	host->intr_status &= ~(SDIO_NOR_CMD_DONE);
+	host->cmd_data &= ~MVSDMMC_CMD;
+
+	for (resp_indx = 0 ; resp_indx < 8; resp_indx++)
+		response[resp_indx] = mvsdmmc_readw(host, SDIO_RSP(resp_indx));
+
+	memset(cmd->resp, 0, 4 * sizeof(cmd->resp[0]));
+
+	if (cmd->flags & MMC_RSP_136) {
+		cmd->resp[3] = ((response[7] & 0x3fff) << 8)	|
+			((response[6] & 0x3ff) << 22);
+		cmd->resp[2] = ((response[6] & 0xfc00) >> 10)	|
+			((response[5] & 0xffff) << 6)	|
+			((response[4] & 0x3ff) << 22);
+		cmd->resp[1] = ((response[4] & 0xfc00) >> 10)	|
+			((response[3] & 0xffff) << 6)	|
+			((response[2] & 0x3ff) << 22);
+		cmd->resp[0] = ((response[2] & 0xfc00) >> 10)	|
+			((response[1] & 0xffff) << 6)	|
+			((response[0] & 0x3ff) << 22);
+	} else  if (cmd->flags & MMC_RSP_PRESENT) {
+		cmd->resp[0] = ((response[2] & 0x3f) << (8 - 8)) |
+			((response[1] & 0xffff) << (14 - 8)) |
+			((response[0] & 0x3ff) << (30 - 8));
+		cmd->resp[1] = ((response[0] & 0xfc00) >> 10);
+	}
+}
+
+static unsigned int mvsdmmc_check_error(struct mvsdmmc_host *host) {
+	unsigned short		error_status;
+	unsigned int		error = 0;
+
+	error_status = mvsdmmc_readw(host, SDIO_NOR_INTR_STATUS);
+	/* make sure if there is an error*/
+	if (error_status & SDIO_NOR_UNEXP_RSP) {
+		error = -EPROTO;
+		mvsdmmc_warning(host, "SDIO_NOR_INTR_STATUS(0x%x)=0x%x"
+				    "\n", SDIO_NOR_INTR_STATUS, error_status);
+	} else if (error_status & SDIO_NOR_ERROR) {
+		/* clear error status*/
+		mvsdmmc_writew(host, SDIO_NOR_INTR_STATUS, SDIO_NOR_ERROR);
+
+		error_status = mvsdmmc_readw(host, SDIO_ERR_INTR_STATUS);
+
+		mvsdmmc_warning(host, "SDIO_ERR_INTR_STATUS(0x%x)=0x%x"
+				    "\n", SDIO_ERR_INTR_STATUS,
+				    error_status);
+
+		if (error_status & (SDIO_ERR_CMD_TIMEOUT |
+				    SDIO_ERR_DATA_TIMEOUT)) {
+			error = -ETIMEDOUT;
+		} else {
+			error = EILSEQ;
+		}
+	}
+
+	if (host->cmd)
+		host->cmd->error = error;
+
+	return error;
+}
+
+static void mvsdmmc_request_done(struct mvsdmmc_host *host) {
+	struct mmc_request *mrq = host->mrq;
+	struct mmc_command	*cmd = host->cmd;
+
+	if ((cmd->error) && (host->data)) {
+		char *virt_addr;
+		int i;
+
+		host->intr_status = host->intr_cmd;
+		__mvsdmmc_disable_irq(host, host->intr_cmd);
+		if (!host->copy_buf)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+			virt_addr = (char *)sg_virt(host->data->sg);
+#else
+			virt_addr = (char *)sg_virt_addr(host->data->sg);
+#endif
+		else
+			virt_addr = (char *)host->dma_buffer;
+
+		mvsdmmc_warning(host, "error: data size =%d, block size= %d "
+				    "block numbers=%d\n",
+				    host->size, host->data->blksz,
+				    host->data->blocks);
+
+		if (dump_on_error) {
+			for (i = 0 ; i < host->size ; i++) {
+				if (i % 32 == 0)
+					mvsdmmc_warning(host, "\n 0x%04X:",
+							    (unsigned int)i);
+				mvsdmmc_warning(host, "%02X ", *virt_addr++);
+			}
+		}
+		mvsdmmc_warning(host, "\n");
+		mvsdmmc_finish_data(host);
+	}
+
+	if ((cmd->error)) {
+
+		/* disable pending interrupts*/
+		__mvsdmmc_disable_irq(host, host->intr_cmd);
+		/* clear pending interrupts*/
+		mvsdmmc_writew(host, SDIO_NOR_INTR_STATUS, host->intr_cmd);
+
+		host->cmd_data = 0;
+		host->intr_status = 0;
+	}
+
+	host->mrq = NULL;
+	host->cmd = NULL;
+	host->pending_commands--;
+
+	mmc_request_done(host->mmc, mrq);
+}
+
+static irqreturn_t mvsdmmc_irq_detect(int irq, void *dev) 
+{
+	struct mmc_host *mmc = (struct mmc_host *)dev;
+	struct mvsdmmc_host *host = mmc_priv(mmc);
+
+	host->stat.detect_int++;
+	mmc_detect_change(mmc, msecs_to_jiffies(100));
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t mvsdmmc_irq(int irq, void *dev) 
+{
+	struct mmc_host *mmc = (struct mmc_host *)dev;
+	struct mvsdmmc_host *host = mmc_priv(mmc);
+	unsigned long flags;
+	int handled = IRQ_NONE;
+	int cardint = 0;
+	int cmd_data_int = 0;
+	unsigned int	error;
+
+	mvsdmmc_dbg_enter();
+	spin_lock_irqsave(&host->lock, flags);
+
+	host->stat.ints++;
+
+	if (host->pending_commands)
+		del_timer(&host->timer);
+
+	/* first make sure if there is an error*/
+	error = mvsdmmc_check_error(host);
+
+
+#if defined(MVSDMMC_DUMP_REGS_ON_CMD)
+	if (host->cmd)  {
+		mvsdmmc_debug_error(host, "==============================>\n");
+		mvsdmmc_debug_error(host, "CMD%d Response \n",
+					host->cmd->opcode);
+		mvsdmmc_dump_registers(host,
+				       mvsdmmc_readw(host, SDIO_CMD));
+	}
+#endif
+
+	if (error) {
+
+		host->stat.error_ints++;
+
+		if (dump_on_error)
+			mvsdmmc_dump_registers(host, mvsdmmc_readw(host,
+								   SDIO_CMD));
+
+		if (host->stat.error_ints == 1) {
+			host->stat.first_err_int = host->stat.total_requests;
+			host->stat.first_int_status =
+				mvsdmmc_readw(host, SDIO_NOR_INTR_STATUS);
+			host->stat.first_error_status =
+				mvsdmmc_readw(host, SDIO_ERR_INTR_STATUS);
+		}
+
+		/* clear error interrupts*/
+		mvsdmmc_writew(host, SDIO_ERR_INTR_STATUS,
+				mvsdmmc_readw(host, SDIO_ERR_INTR_STATUS));
+
+		mvsdmmc_writew(host, SDIO_ERR_INTR_EN, 0);
+
+		mvsdmmc_warning(host, "command,data error \n");
+		handled = IRQ_HANDLED;
+		goto done;
+	}
+
+	/* read interrupts status */
+	host->intr_status = mvsdmmc_readw(host, SDIO_NOR_INTR_STATUS);
+	/* handle only enabled interrupts*/
+	host->intr_status &= mvsdmmc_readw(host, SDIO_NOR_INTR_EN);
+
+	/* disable pending interrupts*/
+	__mvsdmmc_disable_irq(host, host->intr_status);
+	/* clear pending interrupts*/
+	mvsdmmc_writew(host, SDIO_NOR_INTR_STATUS, host->intr_status);
+
+	if (host->intr_status & SDIO_NOR_CARD_INT) {
+		host->intr_status &= ~SDIO_NOR_CARD_INT;
+		host->stat.card_ints++;
+		cardint = 1;
+		handled = IRQ_HANDLED;
+	}
+
+	if (host->intr_status) {
+		cmd_data_int = 1;
+		if ((host->intr_status & SDIO_NOR_AUTOCMD12_DONE) ||
+			(host->intr_status & SDIO_NOR_DMA_INI)) {
+
+			mvsdmmc_finish_data(host);
+			/* if data only interrupt was enable,
+			 * then handle command now as well
+			 */
+			if (!(host->intr_cmd & SDIO_NOR_CMD_DONE))
+				mvsdmmc_finish_cmd(host);
+		}
+
+		if (host->intr_status & SDIO_NOR_CMD_DONE)
+			mvsdmmc_finish_cmd(host);
+
+		handled = IRQ_HANDLED;
+	}
+
+	if (cardint)
+		mmc_signal_sdio_irq(host->mmc);
+
+	if (handled != IRQ_HANDLED) {
+		/* clear interrupts*/
+		__mvsdmmc_disable_irq(host, 0xffff);
+		dev_printk(KERN_WARNING, &host->pdev->dev , "interrupt not handled!!! int status = 0x%x\n", mvsdmmc_readw(host, SDIO_NOR_INTR_STATUS));
+
+		mvsdmmc_writew(host, SDIO_NOR_INTR_STATUS,
+			       mvsdmmc_readw(host, SDIO_NOR_INTR_STATUS));
+
+		if ((host->cmd_data&MVSDMMC_DATA) && (host->data)) {
+			host->data->error = ETIMEDOUT;
+			host->intr_status = SDIO_NOR_DMA_INI; /* dummy */
+			mvsdmmc_finish_data(host);
+		}
+		if ((host->cmd_data&MVSDMMC_CMD) && (host->cmd)) {
+			host->cmd->error = ETIMEDOUT;
+			mvsdmmc_finish_cmd(host);
+		}
+
+		handled = IRQ_HANDLED;
+		host->stat.empty_int++;
+	}
+done:
+	if ((cmd_data_int) ||
+	    ((host->pending_commands) && (host->cmd->error))) {
+		/* Since we may and may not have SDIO_NOR_UNEXP_RSP interrupt
+		 * make sure SDIO_NOR_UNEXP_RSP cleared and disabled before next
+		 * command
+		 */
+		host->intr_status &= ~SDIO_NOR_UNEXP_RSP;
+		__mvsdmmc_disable_irq(host, SDIO_NOR_UNEXP_RSP);
+		mvsdmmc_bitset(host, SDIO_NOR_INTR_STATUS, SDIO_NOR_UNEXP_RSP);
+		mvsdmmc_request_done(host);
+	}
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	mvsdmmc_dbg_exit();
+	return handled;
+
+}
+
+static void mvsdmmc_timeout_timer(unsigned long data)
+{
+	struct mvsdmmc_host *host;
+	irqreturn_t retval;
+
+	host = (struct mvsdmmc_host *)data;
+
+	/* disable interrupts */
+	mvsdmmc_writew(host, SDIO_ERR_INTR_EN, 0);
+
+	host->stat.int_timeout++;
+	mvsdmmc_debug_error(host, "timeout for cmd%d\n",host->cmd->opcode);
+
+	mvsdmmc_bitset(host, SDIO_XFER_MODE, SDIO_XFER_MODE_STOP_CLK); 
+	mvsdmmc_bitset(host, SDIO_HOST_CTRL,
+			 SDIO_HOST_CTRL_HI_SPEED_EN);
+	mvsdmmc_bitreset(host, SDIO_HOST_CTRL,
+			 SDIO_HOST_CTRL_HI_SPEED_EN);
+	/* reset */
+	mvsdmmc_writew(host, SDIO_SW_RESET, 0x100);
+	/* enable the clock*/
+	mvsdmmc_bitreset(host, SDIO_XFER_MODE, SDIO_XFER_MODE_STOP_CLK); 
+
+	if (dump_on_error)
+		mvsdmmc_dump_registers(host, mvsdmmc_readw(host, SDIO_CMD));
+
+	if (host->pending_commands) {
+		mvsdmmc_debug_error(host, "timeout:trying to call interrupt routine\n");
+		/* first try to handle any pending interrupts*/
+		retval =  mvsdmmc_irq(0, (void *)host->mmc);
+	}
+}
+
+/* 32bit byte swap. For example 0x11223344 -> 0x44332211                    */
+#define MV_BYTE_SWAP_32BIT(X) ((((X)&0xff)<<24) |                       \
+                               (((X)&0xff00)<<8) |                      \
+                               (((X)&0xff0000)>>8) |                    \
+                               (((X)&0xff000000)>>24))
+
+static inline void swap_buf(void *buf, int size) {
+
+	int i, aligned_size = (size & 0x3)?((size & ~0x3) + 4):size;
+	u32 temp, *buf32 = (u32*)buf;
+
+	for (i = 0; i < aligned_size; i+=4) {
+		temp = *buf32;
+		*buf32 = MV_BYTE_SWAP_32BIT((temp));
+		buf32++;
+	}
+}
+
+static inline void mvsdmmc_sg_to_dma(struct mvsdmmc_host *host,
+					struct mmc_data *data)
+{
+	unsigned int len, i;
+	struct scatterlist *sg;
+	char *dmabuf = host->dma_buffer;
+	char *sgbuf;
+
+	sg = data->sg;
+	len = data->sg_len;
+
+	for (i = 0; i < len; i++) {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+		sgbuf = (char *)sg_virt((&sg[i]));
+#else
+		sgbuf = (char *)sg_virt_addr((&sg[i]));
+#endif
+
+		memcpy(dmabuf, sgbuf, sg[i].length);
+		dmabuf += sg[i].length;
+	}
+	if (host->bad_size)
+		swap_buf(host->dma_buffer, host->size);
+}
+
+static inline void mvsdmmc_dma_to_sg(struct mvsdmmc_host *host,
+					struct mmc_data *data)
+{
+	unsigned int len, i;
+	struct scatterlist *sg;
+	char *dmabuf = host->dma_buffer;
+	char *sgbuf;
+
+	sg = data->sg;
+	len = data->sg_len;
+
+	if (host->bad_size)
+		swap_buf(host->dma_buffer, host->size);
+
+	for (i = 0; i < len; i++) {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+		sgbuf = (char *)sg_virt((&sg[i]));
+#else
+		sgbuf = (char *)sg_virt_addr((&sg[i]));
+#endif
+		memcpy(sgbuf, dmabuf, sg[i].length);
+		dmabuf += sg[i].length;
+	}
+}
+
+
+static int mvsdmmc_dma_init(struct mmc_host *mmc)
+{
+	struct mvsdmmc_host *host = mmc_priv(mmc);
+
+	mvsdmmc_dbg_enter();
+
+	host->dma_buffer = NULL;
+	host->dma_addr = (dma_addr_t)NULL;
+
+	/*
+	* We need to allocate a special buffer in
+	* order for SDIO host to be able to DMA to it.
+	*/
+
+	host->dma_buffer = kmalloc(MVSDMMC_DMA_SIZE,
+		GFP_NOIO | GFP_DMA | __GFP_REPEAT | __GFP_NOWARN);
+
+	if (!host->dma_buffer)
+		goto err;
+
+	/*
+	* Translate the address to a physical address.
+	*/
+
+	host->dma_addr = dma_map_single(mmc_dev(host->mmc), host->dma_buffer,
+		MVSDMMC_DMA_SIZE, DMA_BIDIRECTIONAL);
+
+	/*
+	* SDIO host DMA must be aligned on a 4 byte basis.
+	*/
+	if ((host->dma_addr & 0x3) != 0) {
+
+		mvsdmmc_warning(host, "mvsdmmc: dma alignment error\n");
+		goto kfree;
+	}
+
+
+
+	mvsdmmc_dbg_exit();
+	return 0;
+kfree:
+	/*
+	 * If we've gotten here then there is some kind of alignment bug
+	 */
+
+	dma_unmap_single(mmc_dev(host->mmc), host->dma_addr,
+		MVSDMMC_DMA_SIZE, DMA_BIDIRECTIONAL);
+	host->dma_addr = (dma_addr_t)NULL;
+
+	kfree(host->dma_buffer);
+	host->dma_buffer = NULL;
+
+	return -ENOMEM;
+
+err:
+	printk(KERN_WARNING DRIVER_NAME ": Unable to allocate DMA %d. "
+		"Falling back on FIFO.\n", (unsigned int)host->dma_buffer);
+
+	return -ENOMEM;
+
+}
+
+
+static void mvsdmmc_request(struct mmc_host *mmc, struct mmc_request *mrq) 
+{
+	struct mvsdmmc_host *host = mmc_priv(mmc);
+	unsigned long flags;
+
+	spin_lock_irqsave(&host->lock, flags);
+	WARN_ON(host->mrq != NULL);
+
+	host->stat.total_requests++;
+
+	BUG_ON(host->pending_commands == 1);
+
+	host->mrq = mrq;
+	host->cmd = mrq->cmd;
+	host->data = mrq->data;
+
+	mvsdmmc_start_cmd(host, mrq->cmd);
+
+	spin_unlock_irqrestore(&host->lock, flags); 
+
+	mvsdmmc_dbg_exit();
+
+}
+
+static void mvsdmmc_set_clock(struct mmc_host *mmc, unsigned int clock)
+{
+	struct mvsdmmc_host *host = mmc_priv(mmc);
+	unsigned int m;
+	mvsdmmc_dbg_enter();
+
+	BUG_ON(clock == 0);
+
+	if(MV_6183_DEV_ID == mvCtrlModelGet())
+		m = MVSDMMC_BASE_FAST_CLOCK_ORION/(2*clock) - 1;
+	else
+		m = MVSDMMC_BASE_FAST_CLOCK_KW/(2*clock) - 1;
+
+	mvsdmmc_debug(host, "mvsdmmc_set_clock: dividor = 0x%x clock=%d\n",
+		      m, clock);
+
+	mvsdmmc_writew(host, SDIO_CLK_DIV, m & 0x7ff);
+
+	msleep(10);
+
+	mvsdmmc_dbg_exit();
+}
+
+static void mvsdmmc_power_up(struct mmc_host *mmc)
+{
+	unsigned int reg;
+	struct mvsdmmc_host *host = mmc_priv(mmc);
+
+
+	mvsdmmc_dbg_enter();
+
+	reg = mvsdmmc_readw(host, SDIO_HOST_CTRL);
+	/* set sd-mem only*/
+	reg &= ~SDIO_HOST_CTRL_CARD_TYPE_MASK;
+	reg |= SDIO_HOST_CTRL_CARD_TYPE_MASK;
+
+	/* set big endian */
+	reg |= SDIO_HOST_CTRL_BIG_ENDIAN;
+	reg &= ~SDIO_HOST_CTRL_LSB_FIRST;
+
+	/* set maximum timeout */
+	reg &= ~SDIO_HOST_CTRL_TMOUT_MASK;
+	reg |= SDIO_HOST_CTRL_TMOUT_MAX;
+	reg |= SDIO_HOST_CTRL_TMOUT_EN;
+	mvsdmmc_writew(host, SDIO_HOST_CTRL, reg);
+
+	mvsdmmc_writew(host, SDIO_NOR_STATUS_EN, 0xffff);
+	mvsdmmc_writew(host, SDIO_ERR_STATUS_EN, 0xffff);
+	mvsdmmc_writew(host, SDIO_NOR_INTR_EN, 0);
+	mvsdmmc_writew(host, SDIO_NOR_INTR_STATUS, 0xffff);
+
+	mvsdmmc_bitreset(host, SDIO_HOST_CTRL,
+			 SDIO_HOST_CTRL_HI_SPEED_EN);
+
+	/* reset */
+	mvsdmmc_writew(host, SDIO_SW_RESET, 0x100);
+	msleep(50);
+
+
+	/* enable the clock*/
+	mvsdmmc_bitreset(host, SDIO_XFER_MODE, SDIO_XFER_MODE_STOP_CLK);
+	mvsdmmc_dbg_exit();
+}
+static void mvsdmmc_power_down(struct mmc_host *mmc)
+{
+	struct mvsdmmc_host *host = mmc_priv(mmc);
+
+	mvsdmmc_dbg_enter();
+	/* stop the clock*/
+	mvsdmmc_bitset(host, SDIO_XFER_MODE, SDIO_XFER_MODE_STOP_CLK);
+	mvsdmmc_writew(host, SDIO_NOR_STATUS_EN, 0);
+	mvsdmmc_writew(host, SDIO_ERR_STATUS_EN, 0);
+	mvsdmmc_writew(host, SDIO_NOR_INTR_EN, 0);
+	mvsdmmc_writew(host, SDIO_NOR_INTR_STATUS, 0xffff);
+
+	mvsdmmc_dbg_exit();
+}
+
+
+
+static void mvsdmmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct mvsdmmc_host *host = mmc_priv(mmc);
+	
+	mvsdmmc_dbg_enter();
+	
+	mvsdmmc_debug(host, "setting clock to %d\n", ios->clock);
+	if (ios->clock)
+		mvsdmmc_set_clock(mmc, ios->clock);
+	else
+		mvsdmmc_stop_clock(host);
+
+	if ((ios->power_mode == MMC_POWER_UP) &&
+	    (host->power_mode != MMC_POWER_UP)) {
+
+		mvsdmmc_debug(host, "power up\n");
+		mvsdmmc_power_up(mmc);
+		host->power_mode = MMC_POWER_UP;
+	}
+
+	if ((ios->power_mode == MMC_POWER_OFF) &&
+	    (host->power_mode != MMC_POWER_OFF)) {
+
+		mvsdmmc_debug(host, " power off\n");
+		mvsdmmc_power_down(mmc);
+		host->power_mode = MMC_POWER_OFF;
+	}
+
+	if ((ios->power_mode == MMC_POWER_ON) &&
+	    (host->power_mode != MMC_POWER_ON)) {
+
+		mvsdmmc_debug(host, " power on\n");
+		host->power_mode = MMC_POWER_ON;
+	}
+
+	if (ios->bus_mode == MMC_BUSMODE_OPENDRAIN) {
+		mvsdmmc_debug(host, " set bus mode to opendrain\n");
+		mvsdmmc_bitreset(host, SDIO_HOST_CTRL,
+				 SDIO_HOST_CTRL_PUSH_PULL_EN);
+	} else if (ios->bus_mode == MMC_BUSMODE_PUSHPULL) {
+
+		mvsdmmc_debug(host, " set bus mode to pushpull\n");
+		mvsdmmc_bitset(host, SDIO_HOST_CTRL,
+				SDIO_HOST_CTRL_PUSH_PULL_EN);
+	}
+
+	if (ios->bus_width == MMC_BUS_WIDTH_1) {
+		mvsdmmc_debug(host, " set width x1\n");
+		mvsdmmc_bitreset(host, SDIO_HOST_CTRL,
+				 SDIO_HOST_CTRL_DATA_WIDTH_4_BITS);
+	} else if (ios->bus_width == MMC_BUS_WIDTH_4) {
+		mvsdmmc_debug(host, " set width x4\n");
+		mvsdmmc_bitset(host, SDIO_HOST_CTRL,
+			       SDIO_HOST_CTRL_DATA_WIDTH_4_BITS);
+	}
+
+	mvsdmmc_dbg_exit();
+}
+
+static void mvsdmmc_enable_sdio_irq(struct mmc_host *host, int enable)
+{
+	struct mvsdmmc_host *mvsdmmc_host = mmc_priv(host);
+	if (enable)
+		mvsdmmc_enable_irq(mvsdmmc_host, SDIO_NOR_CARD_INT);
+	else
+		mvsdmmc_disable_irq(mvsdmmc_host, SDIO_NOR_CARD_INT);
+}
+
+static const struct mmc_host_ops mvsdmmc_ops = {
+	.request	= mvsdmmc_request,
+	.get_ro		= NULL,
+	.set_ios	= mvsdmmc_set_ios,
+	.enable_sdio_irq	= mvsdmmc_enable_sdio_irq,
+};
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+static void mv_conf_mbus_windows(struct mvsdmmc_host *host,
+				 struct mbus_dram_target_info *dram) {
+	int i;
+
+	for (i = 0; i < 4; i++) {
+		writel(0, host->base + WINDOW_CTRL(i));
+		writel(0, host->base + WINDOW_BASE(i));
+	}
+
+	for (i = 0; i < dram->num_cs; i++) {
+		struct mbus_dram_window *cs = dram->cs + i;
+		writel(((cs->size - 1) & 0xffff0000) |
+		       (cs->mbus_attr << 8) |
+		       (dram->mbus_dram_target_id << 4) | 1,
+		       host->base + WINDOW_CTRL(i));
+		writel(cs->base, host->base + WINDOW_BASE(i));
+	}
+}
+#endif
+
+static int mvsdmmc_probe(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = NULL;
+	struct mvsdmmc_host *host = NULL;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+	const struct orion_mvsdmmc_data *mv_platform_data;
+#endif
+	struct resource *r;
+	int ret = 0, irq = NO_IRQ;
+	int irq_detect = NO_IRQ;
+
+	mvsdmmc_dbg_enter();
+
+	BUG_ON(pdev == NULL);
+
+	r = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!r)
+		return -ENXIO;
+
+	r = request_mem_region(r->start, SZ_1K, DRIVER_NAME);
+	if (!r)
+		return -EBUSY;
+
+	irq = platform_get_irq(pdev, 0);
+
+	if (irq == NO_IRQ) {
+		ret = -ENXIO;
+		goto out;
+	}
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+	mv_platform_data = pdev->dev.platform_data;
+#endif
+
+	printk( DRIVER_NAME ": irq =%d start %x\n", irq, r->start);
+
+	if (detect) {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+		irq_detect = mv_platform_data->detect_irq;
+#else
+		irq_detect = platform_get_irq(pdev, 1);
+#endif
+
+		if (irq_detect == NO_IRQ) {
+			detect = 0;
+			printk( DRIVER_NAME ": no IRQ detect\n");
+		}
+		else
+			printk( DRIVER_NAME ": irq_detect=%d\n", irq_detect);
+	}
+
+
+	mmc = mmc_alloc_host(sizeof(struct mvsdmmc_host), &pdev->dev);
+	if (!mmc) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	mmc->ops = &mvsdmmc_ops;
+	mmc->f_min = MVSDMMC_CLOCKRATE_MIN;
+	mmc->f_max = (unsigned int)maxfreq;
+
+	mmc->max_hw_segs = 1;
+	mmc->max_phys_segs = 1;
+
+	mmc->max_req_size = MVSDMMC_DMA_SIZE;
+	mmc->max_seg_size = mmc->max_req_size;
+	mmc->max_blk_count = MVSDMMC_DMA_SIZE;
+	mmc->max_blk_size = 2048;
+
+	host = mmc_priv(mmc);
+	BUG_ON(host == NULL);
+
+	host->pdev = pdev;
+	host->mmc = mmc;
+	host->irq = irq;
+
+	if (detect)
+		host->irq_detect = irq_detect;
+
+	host->res = r;
+	mmc->ocr_avail = MMC_VDD_32_33 | MMC_VDD_33_34;
+
+	mmc->caps |= MMC_CAP_4_BIT_DATA;
+
+	if (highspeed) {
+		mmc->caps |= MMC_CAP_SD_HIGHSPEED;
+		mmc->caps |= MMC_CAP_MMC_HIGHSPEED;
+	}
+
+	mmc->caps |= MMC_CAP_SDIO_IRQ;
+
+	spin_lock_init(&host->lock);
+	host->power_mode = MMC_POWER_OFF;
+
+	host->base = ioremap(r->start, SZ_4K);
+
+	if (!host->base) {
+		ret = -ENOMEM;
+		goto out;
+	}
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+	/*
+	 * (Re-)program MBUS remapping windows if we are asked to.
+	 */
+	if (mv_platform_data->dram != NULL)
+		mv_conf_mbus_windows(host, mv_platform_data->dram);
+#endif
+
+	if (request_irq(host->irq, mvsdmmc_irq,
+			0 , DRIVER_NAME, mmc)) {
+		mvsdmmc_debug(host, "cannot assign irq %d\n", host->irq);
+		ret = -EINVAL;
+		host->irq = NO_IRQ;
+		goto out;
+	}
+
+	if (detect) {
+		if (request_irq(host->irq_detect, mvsdmmc_irq_detect,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+				IRQT_RISING | IRQT_FALLING,
+#else
+				0,
+#endif
+				DRIVER_NAME, mmc)) {
+
+			mvsdmmc_debug(host, "cannot assign irq %d\n",
+				      host->irq_detect);
+			ret = -EINVAL;
+			host->irq_detect = NO_IRQ;
+			goto out;
+		}
+	} else {
+		mmc->caps |= MMC_CAP_NEEDS_POLL;
+		host->irq_detect = NO_IRQ;
+	}
+
+	platform_set_drvdata(pdev, mmc);
+	setup_timer(&host->timer, mvsdmmc_timeout_timer, (unsigned long)host);
+
+	if (mvsdmmc_dma_init(mmc) != 0)
+		goto out;
+
+	if (mmc_add_host(mmc) != 0)
+		goto out;
+
+	create_proc_read_entry("mvsdmmc", 0 , NULL ,
+			       mvsdmmc_read_procmem, host);
+
+	mvsdmmc_dbg_exit();
+	return 0;
+out:
+	if (host) {
+		mvsdmmc_disable_irq(host, 0xffff);
+
+		if (host->base) {
+			mvsdmmc_stop_clock(host);
+			iounmap(host->base);
+		}
+
+
+		if (host->irq != NO_IRQ)
+			free_irq(host->irq, host);
+
+		if (detect) {
+			if (host->irq_detect != NO_IRQ)
+				free_irq(host->irq_detect, host);
+		}
+
+		if (host->res)
+			release_resource(host->res);
+	}
+
+	if (mmc)
+		mmc_free_host(mmc);
+
+	return ret;
+}
+
+static int mvsdmmc_remove(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	platform_set_drvdata(pdev, NULL);
+
+	if (mmc) {
+		struct mvsdmmc_host *host = mmc_priv(mmc);
+		mvsdmmc_disable_irq(host, 0xffff);
+
+		cancel_delayed_work(&mmc->detect);
+
+		mmc_remove_host(mmc);
+
+		if (host) {
+			mvsdmmc_stop_clock(host);
+
+
+			if (host->irq != NO_IRQ)
+				free_irq(host->irq, mmc);
+
+			if (detect) {
+				if (host->irq_detect != NO_IRQ)
+					free_irq(host->irq_detect, mmc);
+			}
+
+			if (host->base)
+				iounmap(host->base);
+
+			if (host->res)
+				release_resource(host->res);
+
+			del_timer_sync(&host->timer);
+		}
+		mmc_free_host(mmc);
+	}
+	remove_proc_entry("mvsdmmc", NULL);
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int mvsdmmc_suspend(struct platform_device *dev, pm_message_t state,
+			   u32 level)
+{
+	struct mmc_host *mmc = platform_get_drvdata(dev);
+	int ret = 0;
+
+	if (mmc && level == SUSPEND_DISABLE)
+		ret = mmc_suspend_host(mmc, state);
+
+	return ret;
+}
+
+static int mvsdmmc_resume(struct platform_device *dev, u32 level)
+{
+	struct mmc_host *mmc = platform_dev_get_drvdata(dev);
+	int ret = 0;
+
+	if (mmc && level == RESUME_ENABLE)
+		ret = mmc_resume_host(mmc);
+
+	return ret;
+}
+#else
+#define mvsdmmc_suspend	NULL
+#define mvsdmmc_resume	NULL
+#endif
+
+
+static struct platform_driver mvsdmmc_driver = {
+	.probe		= mvsdmmc_probe,
+	.remove		= mvsdmmc_remove,
+	.suspend	= mvsdmmc_suspend,
+	.resume		= mvsdmmc_resume,
+	.driver		= {
+		.name	= DRIVER_NAME,
+	},
+};
+
+static int __init mvsdmmc_init(void)
+{
+	int ret = 0;
+	mvsdmmc_dbg_enter();
+
+	if (MV_FALSE == mvCtrlPwrClckGet(SDIO_UNIT_ID, 0)) {
+		printk("\nWarning SDIO unit is Powered Off\n");
+		return;
+	}
+
+	ret = platform_driver_register(&mvsdmmc_driver);
+
+	mvsdmmc_dbg_exit();
+	return ret;
+}
+
+static void __exit mvsdmmc_exit(void)
+{
+	mvsdmmc_dbg_enter();
+	platform_driver_unregister(&mvsdmmc_driver);
+	mvsdmmc_dbg_exit();
+}
+
+module_init(mvsdmmc_init);
+module_exit(mvsdmmc_exit);
+
+/* maximum frequency used in the driver (default 50MHz) */ 
+module_param(maxfreq, int, 0);
+
+/* do we support high speed, default yes*/ 
+module_param(highspeed, int, 0);
+
+module_param(dump_on_error, int, 0);
+
+/* support detection removal\insersion (default = 1) */ 
+module_param(detect, int, 0);
+
+
+MODULE_AUTHOR("Maen Suleiman <maen@marvell.com>"); 
+MODULE_DESCRIPTION("Marvell SD,SDIO,MMC Host Controller driver"); 
+MODULE_LICENSE("GPL");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/mvsdmmc.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/mvsdmmc.h
new file mode 100644
index 0000000..11400a5
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_sdio/mvsdmmc.h
@@ -0,0 +1,199 @@
+/*
+ *  Copyright (C) 2008 Marvell Semiconductors, All Rights Reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#ifndef _MVSDMMC_INCLUDE
+#define _MVSDMMC_INCLUDE
+
+
+#define MVSDMMC_DMA_SIZE			65536
+
+#define MVSDMMC_CMD_TIMEOUT			2 /* 100 usec*/
+
+
+/*
+ * The base MMC clock rate
+ */
+
+#define MVSDMMC_CLOCKRATE_MIN			100000
+#define MVSDMMC_CLOCKRATE_MAX			50000000
+
+#define MVSDMMC_BASE_FAST_CLOCK_ORION	400000000 /* 100000000 */
+#define MVSDMMC_BASE_FAST_CLOCK_KW		200000000 /* 100000000 */
+
+
+
+/*
+ * SDIO register
+ */
+
+#define SDIO_SYS_ADDR_LOW			0x000
+#define SDIO_SYS_ADDR_HI			0x004
+#define SDIO_BLK_SIZE				0x008
+#define SDIO_BLK_COUNT				0x00c
+#define SDIO_ARG_LOW				0x010
+#define SDIO_ARG_HI				0x014
+#define SDIO_XFER_MODE				0x018
+#define SDIO_CMD				0x01c
+#define SDIO_RSP(i)				(0x020 + ((i)<<2))
+#define SDIO_RSP0				0x020
+#define SDIO_RSP1				0x024
+#define SDIO_RSP2				0x028
+#define SDIO_RSP3				0x02c
+#define SDIO_RSP4				0x030
+#define SDIO_RSP5				0x034
+#define SDIO_RSP6				0x038
+#define SDIO_RSP7				0x03c
+#define SDIO_BUF_DATA_PORT			0x040
+#define SDIO_RSVED				0x044
+
+#define SDIO_PRESENT_STATE0			0x048
+#define SDIO_PRESENT_STATE1			0x04c
+#define SDIO_HOST_CTRL				0x050
+#define SDIO_BLK_GAP_CTRL			0x054
+#define SDIO_CLK_CTRL				0x058
+#define SDIO_SW_RESET				0x05c
+#define SDIO_NOR_INTR_STATUS			0x060
+#define SDIO_ERR_INTR_STATUS			0x064
+#define SDIO_NOR_STATUS_EN			0x068
+#define SDIO_ERR_STATUS_EN			0x06c
+#define SDIO_NOR_INTR_EN			0x070
+#define SDIO_ERR_INTR_EN			0x074
+#define SDIO_AUTOCMD12_ERR_STATUS		0x078
+#define SDIO_CURR_BYTE_LEFT			0x07c
+#define SDIO_CURR_BLK_LEFT			0x080
+#define SDIO_AUTOCMD12_ARG_LOW			0x084
+#define SDIO_AUTOCMD12_ARG_HI			0x088
+#define SDIO_AUTOCMD12_INDEX			0x08c
+#define SDIO_AUTO_RSP(i)			(0x090 + ((i)<<2))
+#define SDIO_AUTO_RSP0				0x090
+#define SDIO_AUTO_RSP1				0x094
+#define SDIO_AUTO_RSP2				0x098
+#define SDIO_CLK_DIV				0x128
+
+#define WINDOW_CTRL(i)				(0x108 + ((i) << 3))
+#define WINDOW_BASE(i)				(0x10c + ((i) << 3))
+
+
+/*
+ * SDIO_PRESENT_STATE
+ */
+
+#define CARD_BUSY				(1 << 1)
+#define CMD_INHIBIT				(1 << 0)
+#define CMD_TXACTIVE				(1 << 8)
+#define CMD_RXACTIVE				(1 << 9)
+#define CMD_AUTOCMD12ACTIVE			(1 << 14)
+
+#define CMD_BUS_BUSY				(CMD_AUTOCMD12ACTIVE|	\
+						CMD_RXACTIVE|	\
+						CMD_TXACTIVE|	\
+						CMD_INHIBIT|	\
+						CARD_BUSY)
+
+/*
+ * SDIO_CMD
+ */
+
+#define SDIO_CMD_RSP_NONE			(0 << 0)
+#define SDIO_CMD_RSP_136			(1 << 0)
+#define SDIO_CMD_RSP_48				(2 << 0)
+#define SDIO_CMD_RSP_48BUSY			(3 << 0)
+
+#define SDIO_CMD_CHECK_DATACRC16		(1 << 2)
+#define SDIO_CMD_CHECK_CMDCRC			(1 << 3)
+#define SDIO_CMD_INDX_CHECK			(1 << 4)
+#define SDIO_CMD_DATA_PRESENT			(1 << 5)
+#define SDIO_UNEXPECTED_RESP			(1 << 7)
+
+
+/*
+ * SDIO_XFER_MODE
+ */
+
+#define SDIO_XFER_MODE_STOP_CLK			(1 << 5)
+#define SDIO_XFER_MODE_HW_WR_DATA_EN		(1 << 1)
+#define SDIO_XFER_MODE_AUTO_CMD12		(1 << 2)
+#define SDIO_XFER_MODE_INT_CHK_EN		(1 << 3)
+#define SDIO_XFER_MODE_TO_HOST			(1 << 4)
+
+
+/*
+ * SDIO_HOST_CTRL
+ */
+
+#define SDIO_HOST_CTRL_PUSH_PULL_EN 		(1 << 0)
+
+#define SDIO_HOST_CTRL_CARD_TYPE_MEM_ONLY 	(0 << 1)
+#define SDIO_HOST_CTRL_CARD_TYPE_IO_ONLY 	(1 << 1)
+#define SDIO_HOST_CTRL_CARD_TYPE_IO_MEM_COMBO 	(2 << 1)
+#define SDIO_HOST_CTRL_CARD_TYPE_IO_MMC 	(3 << 1)
+#define SDIO_HOST_CTRL_CARD_TYPE_MASK	 	(3 << 1)
+
+#define SDIO_HOST_CTRL_BIG_ENDIAN 		(1 << 3)
+#define SDIO_HOST_CTRL_LSB_FIRST 		(1 << 4)
+#define SDIO_HOST_CTRL_ID_MODE_LOW_FREQ 	(1 << 5)
+#define SDIO_HOST_CTRL_HALF_SPEED 		(1 << 6)
+#define SDIO_HOST_CTRL_DATA_WIDTH_4_BITS 	(1 << 9)
+#define SDIO_HOST_CTRL_HI_SPEED_EN 		(1 << 10)
+
+
+#define SDIO_HOST_CTRL_TMOUT_MASK 		(0xf << 11)
+#define SDIO_HOST_CTRL_TMOUT_MAX 		(0xf << 11)
+#define SDIO_HOST_CTRL_TMOUT(x) 		((x) << 11)
+#define SDIO_HOST_CTRL_TMOUT_EN 		(1 << 15)
+
+#define SDIO_HOST_CTRL_DFAULT_OPEN_DRAIN 	\
+		(SDIO_HOST_CTRL_TMOUT(x)(0xf))
+#define SDIO_HOST_CTRL_DFAULT_PUSH_PULL 	\
+		(SDIO_HOST_CTRL_TMOUT(x)(0xf) | SDIO_HOST_CTRL_PUSH_PULL_EN)
+
+
+/*
+ * NOR status bits
+ */
+
+#define SDIO_NOR_ERROR				(1 << 15)
+#define SDIO_NOR_UNEXP_RSP			(1 << 14)
+#define SDIO_NOR_AUTOCMD12_DONE			(1 << 13)
+#define SDIO_NOR_SUSPEND_ON			(1 << 12)
+#define SDIO_NOR_LMB_FF_8W_AVAIL		(1 << 11)
+#define SDIO_NOR_LMB_FF_8W_FILLED		(1 << 10)
+#define SDIO_NOR_READ_WAIT_ON			(1 << 9)
+#define SDIO_NOR_CARD_INT			(1 << 8)
+#define SDIO_NOR_READ_READY			(1 << 5)
+#define SDIO_NOR_WRITE_READY			(1 << 4)
+#define SDIO_NOR_DMA_INI			(1 << 3)
+#define SDIO_NOR_BLK_GAP_EVT			(1 << 2)
+#define SDIO_NOR_XFER_DONE			(1 << 1)
+#define SDIO_NOR_CMD_DONE			(1 << 0)
+
+
+/*
+ * ERR status bits
+ */
+
+#define SDIO_ERR_CRC_STATUS			(1 << 14)
+#define SDIO_ERR_CRC_STARTBIT			(1 << 13)
+#define SDIO_ERR_CRC_ENDBIT			(1 << 12)
+#define SDIO_ERR_RESP_TBIT			(1 << 11)
+#define SDIO_ERR_SIZE				(1 << 10)
+#define SDIO_ERR_CMD_STARTBIT			(1 << 9)
+#define SDIO_ERR_AUTOCMD12			(1 << 8)
+#define SDIO_ERR_DATA_ENDBIT			(1 << 6)
+#define SDIO_ERR_DATA_CRC			(1 << 5)
+#define SDIO_ERR_DATA_TIMEOUT			(1 << 4)
+#define SDIO_ERR_CMD_INDEX			(1 << 3)
+#define SDIO_ERR_CMD_ENDBIT			(1 << 2)
+#define SDIO_ERR_CMD_CRC			(1 << 1)
+#define SDIO_ERR_CMD_TIMEOUT			(1 << 0)
+
+#define SDIO_POLL_MASK 				0xffff /* enable all for polling */
+
+
+#endif /* _MVSDMMC_INCLUDE */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_switch/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_switch/Makefile
new file mode 100644
index 0000000..77cd9a1
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_switch/Makefile
@@ -0,0 +1,12 @@
+#
+# Makefile for the Marvell Key
+#
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+ 
+obj-$(CONFIG_MV_INCLUDE_SWITCH)	+= mv_switch.o mv_switch_sysfs.o
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_switch/mv_switch.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_switch/mv_switch.c
new file mode 100644
index 0000000..0a0df27
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_switch/mv_switch.c
@@ -0,0 +1,1374 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mvCommon.h"		/* Should be included before mvSysHwConfig */
+#include <linux/etherdevice.h>
+#include "mvOs.h"
+#include "mvSysHwConfig.h"
+#include "eth-phy/mvEthPhy.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#ifdef MV_INCLUDE_ETH_COMPLEX
+#include "ctrlEnv/mvCtrlEthCompLib.h"
+#endif /* MV_INCLUDE_ETH_COMPLEX */
+
+#include "msApi.h"
+#include "h/platform/gtMiiSmiIf.h"
+#include "mv_switch.h"
+
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+extern void mv_eth_switch_update_link(unsigned int p, unsigned int link_up);
+extern void mv_eth_switch_interrupt_unmask(int qsgmii_module, int gephy_on_port);
+extern void mv_eth_switch_interrupt_clear(int qsgmii_module, int gephy_on_port);
+#endif
+
+#define MV_SWITCH_DEF_INDEX     0
+#define MV_ETH_PORT_0           0
+#define MV_ETH_PORT_1           1
+
+/* uncomment for debug prints */
+/* #define SWITCH_DEBUG */
+
+#define SWITCH_DBG_OFF      0x0000
+#define SWITCH_DBG_LOAD     0x0001
+#define SWITCH_DBG_MCAST    0x0002
+#define SWITCH_DBG_VLAN     0x0004
+#define SWITCH_DBG_ALL      0xffff
+
+#ifdef SWITCH_DEBUG
+static u32 switch_dbg = 0;
+#define SWITCH_DBG(FLG, X) if ((switch_dbg & (FLG)) == (FLG)) printk X
+#else
+#define SWITCH_DBG(FLG, X)
+#endif /* SWITCH_DEBUG */
+
+static GT_QD_DEV qddev, *qd_dev = NULL;
+static GT_SYS_CONFIG qd_cfg;
+
+static int qd_cpu_port = -1;
+static int qsgmii_module = 0;
+static int gephy_on_port = -1;
+static int rgmiia_on_port = -1;
+
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+static int switch_irq = -1;
+int switch_link_poll = 0;
+static struct timer_list switch_link_timer;
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+
+static spinlock_t switch_lock;
+
+static GT_BOOL mv_switch_mii_read(GT_QD_DEV *dev, unsigned int phy, unsigned int reg, unsigned int *data)
+{
+	unsigned long flags;
+	unsigned short tmp;
+	MV_STATUS status;
+
+	spin_lock_irqsave(&switch_lock, flags);
+	status = mvEthPhyRegRead(phy, reg, &tmp);
+	spin_unlock_irqrestore(&switch_lock, flags);
+	*data = tmp;
+
+	if (status == MV_OK)
+		return GT_TRUE;
+
+	return GT_FALSE;
+}
+
+static GT_BOOL mv_switch_mii_write(GT_QD_DEV *dev, unsigned int phy, unsigned int reg, unsigned int data)
+{
+	unsigned long flags;
+	unsigned short tmp;
+	MV_STATUS status;
+
+	spin_lock_irqsave(&switch_lock, flags);
+	tmp = (unsigned short)data;
+	status = mvEthPhyRegWrite(phy, reg, tmp);
+	spin_unlock_irqrestore(&switch_lock, flags);
+
+	if (status == MV_OK)
+		return GT_TRUE;
+
+	return GT_FALSE;
+}
+
+int mv_switch_mac_addr_set(unsigned char *mac_addr, unsigned char db, unsigned int ports_mask, unsigned char op)
+{
+	GT_ATU_ENTRY mac_entry;
+
+	memset(&mac_entry, 0, sizeof(GT_ATU_ENTRY));
+
+	mac_entry.trunkMember = GT_FALSE;
+	mac_entry.prio = 0;
+	mac_entry.exPrio.useMacFPri = GT_FALSE;
+	mac_entry.exPrio.macFPri = 0;
+	mac_entry.exPrio.macQPri = 0;
+	mac_entry.DBNum = db;
+	mac_entry.portVec = ports_mask;
+	memcpy(mac_entry.macAddr.arEther, mac_addr, 6);
+
+	if (is_multicast_ether_addr(mac_addr))
+		mac_entry.entryState.mcEntryState = GT_MC_STATIC;
+	else
+		mac_entry.entryState.ucEntryState = GT_UC_NO_PRI_STATIC;
+
+	if ((op == 0) || (mac_entry.portVec == 0)) {
+		if (gfdbDelAtuEntry(qd_dev, &mac_entry) != GT_OK) {
+			printk(KERN_ERR "gfdbDelAtuEntry failed\n");
+			return -1;
+		}
+	} else {
+		if (gfdbAddMacEntry(qd_dev, &mac_entry) != GT_OK) {
+			printk(KERN_ERR "gfdbAddMacEntry failed\n");
+			return -1;
+		}
+	}
+
+	return 0;
+}
+
+int mv_switch_port_based_vlan_set(unsigned int ports_mask, int set_cpu_port)
+{
+	unsigned int p, pl;
+	unsigned char cnt;
+	GT_LPORT port_list[MAX_SWITCH_PORTS];
+
+	for (p = 0; p < qd_dev->numOfPorts; p++) {
+		if (MV_BIT_CHECK(ports_mask, p) && (set_cpu_port || (p != qd_cpu_port))) {
+			SWITCH_DBG(SWITCH_DBG_LOAD | SWITCH_DBG_MCAST | SWITCH_DBG_VLAN,
+				   ("port based vlan, port %d: ", p));
+			for (pl = 0, cnt = 0; pl < qd_dev->numOfPorts; pl++) {
+				if (MV_BIT_CHECK(ports_mask, pl) && (pl != p)) {
+					SWITCH_DBG(SWITCH_DBG_LOAD | SWITCH_DBG_MCAST | SWITCH_DBG_VLAN, ("%d ", pl));
+					port_list[cnt] = pl;
+					cnt++;
+				}
+			}
+			if (gvlnSetPortVlanPorts(qd_dev, p, port_list, cnt) != GT_OK) {
+				printk(KERN_ERR "gvlnSetPortVlanPorts failed\n");
+				return -1;
+			}
+			SWITCH_DBG(SWITCH_DBG_LOAD | SWITCH_DBG_MCAST | SWITCH_DBG_VLAN, ("\n"));
+		}
+	}
+	return 0;
+}
+
+int mv_switch_vlan_in_vtu_set(unsigned short vlan_id, unsigned short db_num, unsigned int ports_mask)
+{
+	GT_VTU_ENTRY vtu_entry;
+	unsigned int p;
+
+	vtu_entry.vid = vlan_id;
+	vtu_entry.DBNum = db_num;
+	vtu_entry.vidPriOverride = GT_FALSE;
+	vtu_entry.vidPriority = 0;
+	vtu_entry.vidExInfo.useVIDFPri = GT_FALSE;
+	vtu_entry.vidExInfo.vidFPri = 0;
+	vtu_entry.vidExInfo.useVIDQPri = GT_FALSE;
+	vtu_entry.vidExInfo.vidQPri = 0;
+	vtu_entry.vidExInfo.vidNRateLimit = GT_FALSE;
+	SWITCH_DBG(SWITCH_DBG_LOAD | SWITCH_DBG_MCAST | SWITCH_DBG_VLAN, ("vtu entry: vid=0x%x, port ", vtu_entry.vid));
+
+	for (p = 0; p < qd_dev->numOfPorts; p++) {
+		if (MV_BIT_CHECK(ports_mask, p)) {
+			SWITCH_DBG(SWITCH_DBG_LOAD | SWITCH_DBG_MCAST | SWITCH_DBG_VLAN, ("%d ", p));
+			vtu_entry.vtuData.memberTagP[p] = MEMBER_EGRESS_UNMODIFIED;
+		} else {
+			vtu_entry.vtuData.memberTagP[p] = NOT_A_MEMBER;
+		}
+		vtu_entry.vtuData.portStateP[p] = 0;
+	}
+
+	if (gvtuAddEntry(qd_dev, &vtu_entry) != GT_OK) {
+		printk(KERN_ERR "gvtuAddEntry failed\n");
+		return -1;
+	}
+
+	SWITCH_DBG(SWITCH_DBG_LOAD | SWITCH_DBG_MCAST | SWITCH_DBG_VLAN, ("\n"));
+	return 0;
+}
+
+int mv_switch_atu_db_flush(int db_num)
+{
+	if (gfdbFlushInDB(qd_dev, GT_FLUSH_ALL, db_num) != GT_OK) {
+		printk(KERN_ERR "gfdbFlushInDB failed\n");
+		return -1;
+	}
+	return 0;
+}
+
+int mv_switch_promisc_set(u16 vlan_grp_id, u16 port_map, u16 cpu_port, u8 promisc_on)
+{
+	int i;
+
+	if (promisc_on) {
+
+		mv_switch_port_based_vlan_set((port_map | (1 << cpu_port)), 0);
+
+		for (i = 0; i < qd_dev->numOfPorts; i++) {
+			if (MV_BIT_CHECK(port_map, i) && (i != cpu_port)) {
+				if (mv_switch_vlan_in_vtu_set(MV_SWITCH_PORT_VLAN_ID(vlan_grp_id, i),
+							      MV_SWITCH_VLAN_TO_GROUP(vlan_grp_id),
+							      (port_map | (1 << cpu_port))) != 0) {
+					printk(KERN_ERR "mv_switch_vlan_in_vtu_set failed\n");
+					return -1;
+				}
+			}
+		}
+
+	} else {
+
+		mv_switch_port_based_vlan_set((port_map & ~(1 << cpu_port)), 0);
+
+		for (i = 0; i < qd_dev->numOfPorts; i++) {
+			if (MV_BIT_CHECK(port_map, i) && (i != cpu_port)) {
+				if (mv_switch_vlan_in_vtu_set(MV_SWITCH_PORT_VLAN_ID(vlan_grp_id, i),
+							      MV_SWITCH_VLAN_TO_GROUP(vlan_grp_id),
+							      (port_map & ~(1 << cpu_port))) != 0) {
+					printk(KERN_ERR "mv_switch_vlan_in_vtu_set failed\n");
+					return -1;
+				}
+			}
+		}
+
+	}
+
+	return 0;
+}
+
+int mv_eth_switch_vlan_set(u16 vlan_grp_id, u16 port_map, u16 cpu_port)
+{
+	int p;
+
+	/* set port's default private vlan id and database number (DB per group): */
+	for (p = 0; p < qd_dev->numOfPorts; p++) {
+		if (MV_BIT_CHECK(port_map, p) && (p != cpu_port)) {
+			if (gvlnSetPortVid(qd_dev, p, MV_SWITCH_PORT_VLAN_ID(vlan_grp_id, p)) != GT_OK) {
+				printk(KERN_ERR "gvlnSetPortVid failed\n");
+				return -1;
+			}
+			if (gvlnSetPortVlanDBNum(qd_dev, p, MV_SWITCH_VLAN_TO_GROUP(vlan_grp_id)) != GT_OK) {
+				printk(KERN_ERR "gvlnSetPortVlanDBNum failed\n");
+				return -1;
+			}
+		}
+	}
+
+	/* set port's port-based vlan (CPU port is not part of VLAN) */
+	if (mv_switch_port_based_vlan_set((port_map & ~(1 << cpu_port)), 0) != 0)
+		printk(KERN_ERR "mv_switch_port_based_vlan_set failed\n");
+
+	/* set vtu with group vlan id (used in tx) */
+	if (mv_switch_vlan_in_vtu_set(vlan_grp_id, MV_SWITCH_VLAN_TO_GROUP(vlan_grp_id), port_map | (1 << cpu_port)) != 0)
+		printk(KERN_ERR "mv_switch_vlan_in_vtu_set failed\n");
+
+	/* set vtu with each port private vlan id (used in rx) */
+	for (p = 0; p < qd_dev->numOfPorts; p++) {
+		if (MV_BIT_CHECK(port_map, p) && (p != cpu_port)) {
+			if (mv_switch_vlan_in_vtu_set(MV_SWITCH_PORT_VLAN_ID(vlan_grp_id, p),
+						      MV_SWITCH_VLAN_TO_GROUP(vlan_grp_id),
+						      port_map & ~(1 << cpu_port)) != 0) {
+				printk(KERN_ERR "mv_switch_vlan_in_vtu_set failed\n");
+			}
+		}
+	}
+
+	return 0;
+}
+
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+void mv_switch_link_update_event(MV_U32 port_mask, int force_link_check)
+{
+	int p;
+	unsigned short phy_cause = 0;
+
+	for (p = 0; p < qd_dev->numOfPorts; p++) {
+		if (MV_BIT_CHECK(port_mask, p)) {
+			if ((!qsgmii_module) || (p == gephy_on_port)) { /* liron, TODO: || (p == rgmiia_on_port)  */
+				/* this is needed to clear the PHY interrupt */
+				gprtGetPhyIntStatus(qd_dev, p, &phy_cause);
+			} else {
+				phy_cause |= GT_LINK_STATUS_CHANGED;
+			}
+
+			if (force_link_check)
+				phy_cause |= GT_LINK_STATUS_CHANGED;
+
+			if (phy_cause & GT_LINK_STATUS_CHANGED) {
+				char *link = NULL, *duplex = NULL, *speed = NULL;
+				GT_BOOL flag;
+				GT_PORT_SPEED_MODE speed_mode;
+
+				if (gprtGetLinkState(qd_dev, p, &flag) != GT_OK) {
+					printk(KERN_ERR "gprtGetLinkState failed (port %d)\n", p);
+					link = "ERR";
+				} else
+					link = (flag) ? "up" : "down";
+
+				if (flag) {
+					if (gprtGetDuplex(qd_dev, p, &flag) != GT_OK) {
+						printk(KERN_ERR "gprtGetDuplex failed (port %d)\n", p);
+						duplex = "ERR";
+					} else
+						duplex = (flag) ? "Full" : "Half";
+
+					if (gprtGetSpeedMode(qd_dev, p, &speed_mode) != GT_OK) {
+						printk(KERN_ERR "gprtGetSpeedMode failed (port %d)\n", p);
+						speed = "ERR";
+					} else {
+						if (speed_mode == PORT_SPEED_1000_MBPS)
+							speed = "1000Mbps";
+						else if (speed_mode == PORT_SPEED_100_MBPS)
+							speed = "100Mbps";
+						else
+							speed = "10Mbps";
+					}
+					mv_eth_switch_update_link(p, 1);
+					printk(KERN_ERR "Port %d: Link-%s, %s-duplex, Speed-%s.\n",
+					       mvBoardSwitchPortMap(MV_SWITCH_DEF_INDEX, p), link, duplex, speed);
+				} else {
+					mv_eth_switch_update_link(p, 0);
+					printk(KERN_ERR "Port %d: Link-down\n", mvBoardSwitchPortMap(MV_SWITCH_DEF_INDEX, p));
+				}
+			}
+		}
+	}
+}
+
+void mv_switch_link_timer_function(unsigned long data)
+{
+	/* GT_DEV_INT_STATUS devIntStatus; */
+	MV_U32 port_mask = (data & 0xFF);
+
+	mv_switch_link_update_event(port_mask, 0);
+
+	if (switch_link_poll) {
+		switch_link_timer.expires = jiffies + (HZ);	/* 1 second */
+		add_timer(&switch_link_timer);
+	}
+}
+
+static irqreturn_t mv_switch_isr(int irq, void *dev_id)
+{
+	GT_DEV_INT_STATUS devIntStatus;
+	MV_U32 port_mask = 0;
+
+	if (qsgmii_module) {
+#ifdef MV_INCLUDE_ETH_COMPLEX
+		MV_U32 reg = 0;
+
+		reg = MV_REG_READ(MV_ETHCOMP_INT_MAIN_CAUSE_REG);
+
+		if (reg & MV_ETHCOMP_PCS0_LINK_INT_MASK)
+			port_mask |= 0x1;
+		if (reg & MV_ETHCOMP_PCS1_LINK_INT_MASK)
+			port_mask |= 0x2;
+		if (reg & MV_ETHCOMP_PCS2_LINK_INT_MASK)
+			port_mask |= 0x4;
+		if (reg & MV_ETHCOMP_PCS3_LINK_INT_MASK)
+			port_mask |= 0x8;
+#endif /* MV_INCLUDE_ETH_COMPLEX */
+	} else {
+		if (geventGetDevIntStatus(qd_dev, &devIntStatus) != GT_OK)
+			printk(KERN_ERR "geventGetDevIntStatus failed\n");
+
+		if (devIntStatus.devIntCause & GT_DEV_INT_PHY)
+			port_mask = devIntStatus.phyInt & 0xFF;
+	}
+
+	if (gephy_on_port >= 0)
+		port_mask |= (1 << gephy_on_port);
+
+	mv_switch_link_update_event(port_mask, 0);
+
+	mv_eth_switch_interrupt_clear(qsgmii_module, gephy_on_port);
+
+	return IRQ_HANDLED;
+}
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+
+int mv_switch_jumbo_mode_set(int max_size)
+{
+	int i;
+	GT_JUMBO_MODE jumbo_mode;
+
+	/* Set jumbo frames mode */
+	if (max_size <= 1522)
+		jumbo_mode = GT_JUMBO_MODE_1522;
+	else if (max_size <= 2048)
+		jumbo_mode = GT_JUMBO_MODE_2048;
+	else
+		jumbo_mode = GT_JUMBO_MODE_10240;
+
+	for (i = 0; i < qd_dev->numOfPorts; i++) {
+		if (gsysSetJumboMode(qd_dev, i, jumbo_mode) != GT_OK) {
+			printk(KERN_ERR "gsysSetJumboMode %d failed\n", jumbo_mode);
+			return -1;
+		}
+	}
+	return 0;
+}
+
+int mv_switch_load(unsigned int switch_ports_mask)
+{
+	int p;
+
+	printk(KERN_ERR "  o Loading Switch QuarterDeck driver\n");
+
+	if (qd_dev) {
+		printk(KERN_ERR "    o %s: Already initialized\n", __func__);
+		return 0;
+	}
+
+	memset((char *)&qd_cfg, 0, sizeof(GT_SYS_CONFIG));
+	spin_lock_init(&switch_lock);
+
+	/* init config structure for qd package */
+	qd_cfg.BSPFunctions.readMii = mv_switch_mii_read;
+	qd_cfg.BSPFunctions.writeMii = mv_switch_mii_write;
+	qd_cfg.BSPFunctions.semCreate = NULL;
+	qd_cfg.BSPFunctions.semDelete = NULL;
+	qd_cfg.BSPFunctions.semTake = NULL;
+	qd_cfg.BSPFunctions.semGive = NULL;
+	qd_cfg.initPorts = GT_TRUE;
+	qd_cfg.cpuPortNum = mvBoardSwitchCpuPortGet(MV_SWITCH_DEF_INDEX);
+	if (mvBoardSmiScanModeGet(MV_SWITCH_DEF_INDEX) == 1) {
+		qd_cfg.mode.baseAddr = 0;
+		qd_cfg.mode.scanMode = SMI_MANUAL_MODE;
+	} else if (mvBoardSmiScanModeGet(MV_SWITCH_DEF_INDEX) == 2) {
+		qd_cfg.mode.scanMode = SMI_MULTI_ADDR_MODE;
+		if (mvBoardSwitchConnectedPortGet(MV_ETH_PORT_0) != -1) {
+			qd_cfg.mode.baseAddr = mvBoardPhyAddrGet(MV_ETH_PORT_0);
+		} else if (mvBoardSwitchConnectedPortGet(MV_ETH_PORT_1) != -1) {
+			qd_cfg.mode.baseAddr = mvBoardPhyAddrGet(MV_ETH_PORT_1);
+		} else {
+			printk(KERN_ERR "mv_switch_load failed: Wrong SCAN mode\n");
+			return -1;
+		}
+	}
+
+	/* load switch sw package */
+	if (qdLoadDriver(&qd_cfg, &qddev) != GT_OK) {
+		printk(KERN_ERR "qdLoadDriver failed\n");
+		return -1;
+	}
+	qd_dev = &qddev;
+	qd_cpu_port = qd_cfg.cpuPortNum;
+
+	SWITCH_DBG(SWITCH_DBG_LOAD, ("Device ID     : 0x%x\n", qd_dev->deviceId));
+	SWITCH_DBG(SWITCH_DBG_LOAD, ("Base Reg Addr : 0x%x\n", qd_dev->baseRegAddr));
+	SWITCH_DBG(SWITCH_DBG_LOAD, ("No. of Ports  : %d\n", qd_dev->numOfPorts));
+	SWITCH_DBG(SWITCH_DBG_LOAD, ("CPU Ports     : %ld\n", qd_dev->cpuPortNum));
+
+	qsgmii_module = mvBoardIsQsgmiiModuleConnected();
+	if (qsgmii_module)
+		printk(KERN_ERR "    o QSGMII Module Detected\n");
+
+	gephy_on_port = mvBoardGePhySwitchPortGet();
+	if (gephy_on_port >= 0)
+		printk(KERN_ERR "    o Internal GE PHY Connected to Switch Port %d Detected\n", gephy_on_port);
+
+	rgmiia_on_port = mvBoardRgmiiASwitchPortGet();
+	if (rgmiia_on_port >= 0)
+		printk(KERN_ERR "    o RGMII-A Connected to Switch Port %d Detected\n", rgmiia_on_port);
+
+	/* disable all disconnected ports */
+	for (p = 0; p < qd_dev->numOfPorts; p++) {
+		/* Do nothing for ports that are not part of the given switch_port_mask */
+		if (!MV_BIT_CHECK(switch_ports_mask, p))
+			continue;
+
+		if (mvBoardSwitchPortMap(MV_SWITCH_DEF_INDEX, p) != -1) {
+			/* Switch port mapped to connector on the board */
+
+			if ((gpcsSetFCValue(qd_dev, p, GT_FALSE) != GT_OK) ||
+			    (gpcsSetForcedFC(qd_dev, p, GT_FALSE) != GT_OK)) {
+				printk(KERN_ERR "Force Flow Control - Failed\n");
+				return -1;
+			}
+#if 0
+			/* TODO - decide if we want to enable auto-negotiation of Flow Control for external ports */
+			if (qsgmii_module) {
+				/* TODO - configure ports via QSGMII registers */
+			} else {
+				GT_STATUS status;
+
+				status = gprtSetPause(qd_dev, p, GT_PHY_PAUSE);
+				if (status != GT_OK)
+					printk(KERN_ERR "Failed set pause for switch port #%d: status = %d\n", p, status);
+			}
+#endif
+			continue;
+		}
+
+		if ((mvBoardSwitchConnectedPortGet(MV_ETH_PORT_0) == p) ||
+		    (mvBoardSwitchConnectedPortGet(MV_ETH_PORT_1) == p)) {
+			/* Switch port connected to GMAC - force link UP - 1000 Full with FC */
+			printk(KERN_ERR "    o Setting Switch CPU port (port #%d) for 1000 Full with FC\n", p);
+			if (gpcsSetForceSpeed(qd_dev, p, PORT_FORCE_SPEED_1000_MBPS) != GT_OK) {
+				printk(KERN_ERR "Force speed 1000mbps - Failed\n");
+				return -1;
+			}
+
+			if ((gpcsSetDpxValue(qd_dev, p, GT_TRUE) != GT_OK) ||
+			    (gpcsSetForcedDpx(qd_dev, p, GT_TRUE) != GT_OK)) {
+				printk(KERN_ERR "Force duplex FULL - Failed\n");
+				return -1;
+			}
+
+			if ((gpcsSetFCValue(qd_dev, p, GT_TRUE) != GT_OK) ||
+			    (gpcsSetForcedFC(qd_dev, p, GT_TRUE) != GT_OK)) {
+				printk(KERN_ERR "Force Flow Control - Failed\n");
+				return -1;
+			}
+
+			if ((gpcsSetLinkValue(qd_dev, p, GT_TRUE) != GT_OK) ||
+			    (gpcsSetForcedLink(qd_dev, p, GT_TRUE) != GT_OK)) {
+				printk(KERN_ERR "Force Link UP - Failed\n");
+				return -1;
+			}
+			continue;
+		}
+		printk(KERN_ERR "    o Disable disconnected switch port (port #%d) and force link down\n", p);
+
+		if (gstpSetPortState(qd_dev, p, GT_PORT_DISABLE) != GT_OK) {
+			printk(KERN_ERR "gstpSetPortState failed\n");
+			return -1;
+		}
+		if ((gpcsSetLinkValue(qd_dev, p, GT_FALSE) != GT_OK) ||
+		    (gpcsSetForcedLink(qd_dev, p, GT_TRUE) != GT_OK)) {
+			printk(KERN_ERR "Force Link DOWN - Failed\n");
+			return -1;
+		}
+	}
+
+	return 0;
+}
+
+int mv_switch_unload(unsigned int switch_ports_mask)
+{
+	int i;
+
+	printk(KERN_ERR "  o Unloading Switch QuarterDeck driver\n");
+
+	if (qd_dev == NULL) {
+		printk(KERN_ERR "    o %s: Already un-initialized\n", __func__);
+		return 0;
+	}
+
+	/* Flush all addresses from the MAC address table */
+	/* this also happens in mv_switch_init() but we call it here to clean-up nicely */
+	/* Note: per DB address flush (gfdbFlushInDB) happens when doing ifconfig down on a Switch interface */
+	if (gfdbFlush(qd_dev, GT_FLUSH_ALL) != GT_OK)
+		printk(KERN_ERR "gfdbFlush failed\n");
+
+	/* Reset VLAN tunnel mode */
+	for (i = 0; i < qd_dev->numOfPorts; i++) {
+		if (MV_BIT_CHECK(switch_ports_mask, i) && (i != qd_cpu_port))
+			if (gprtSetVlanTunnel(qd_dev, i, GT_FALSE) != GT_OK)
+				printk(KERN_ERR "gprtSetVlanTunnel failed (port %d)\n", i);
+	}
+
+	/* restore port's default private vlan id and database number to their default values after reset: */
+	for (i = 0; i < qd_dev->numOfPorts; i++) {
+		if (gvlnSetPortVid(qd_dev, i, 0x0001) != GT_OK) { /* that's the default according to the spec */
+			printk(KERN_ERR "gvlnSetPortVid failed\n");
+			return -1;
+		}
+		if (gvlnSetPortVlanDBNum(qd_dev, i, 0) != GT_OK) {
+			printk(KERN_ERR "gvlnSetPortVlanDBNum failed\n");
+			return -1;
+		}
+	}
+
+	/* Port based VLAN */
+	if (mv_switch_port_based_vlan_set(switch_ports_mask, 1))
+		printk(KERN_ERR "mv_switch_port_based_vlan_set failed\n");
+
+	/* Remove all entries from the VTU table */
+	if (gvtuFlush(qd_dev) != GT_OK)
+		printk(KERN_ERR "gvtuFlush failed\n");
+
+	/* unload switch sw package */
+	if (qdUnloadDriver(qd_dev) != GT_OK) {
+		printk(KERN_ERR "qdUnloadDriver failed\n");
+		return -1;
+	}
+	qd_dev = NULL;
+	qd_cpu_port = -1;
+	qsgmii_module = 0;
+	gephy_on_port = -1;
+	rgmiia_on_port = -1;
+
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+	switch_irq = -1;
+	switch_link_poll = 0;
+	del_timer(&switch_link_timer);
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+
+	return 0;
+}
+
+int mv_switch_init(int mtu, unsigned int switch_ports_mask)
+{
+	unsigned int i, p;
+	unsigned char cnt;
+	GT_LPORT port_list[MAX_SWITCH_PORTS];
+
+	if (qd_dev == NULL) {
+		printk(KERN_ERR "mv_switch_init: qd_dev not initialized, call mv_switch_load() first\n");
+		return -1;
+	}
+
+	/* general Switch initialization - relevant for all Switch devices */
+
+	/* disable all ports */
+	for (p = 0; p < qd_dev->numOfPorts; p++) {
+		if (MV_BIT_CHECK(switch_ports_mask, p))
+			if (gstpSetPortState(qd_dev, p, GT_PORT_DISABLE) != GT_OK) {
+				printk(KERN_ERR "gstpSetPortState failed\n");
+				return -1;
+			}
+	}
+
+	/* flush All counters for all ports */
+	if (gstatsFlushAll(qd_dev) != GT_OK)
+		printk(KERN_ERR "gstatsFlushAll failed\n");
+
+	/* set all ports not to unmodify the vlan tag on egress */
+	for (i = 0; i < qd_dev->numOfPorts; i++) {
+		if (MV_BIT_CHECK(switch_ports_mask, p))
+			if (gprtSetEgressMode(qd_dev, i, GT_UNMODIFY_EGRESS) != GT_OK) {
+				printk(KERN_ERR "gprtSetEgressMode GT_UNMODIFY_EGRESS failed\n");
+				return -1;
+			}
+	}
+
+	/* initializes the PVT Table (cross-chip port based VLAN) to all one's (initial state) */
+	if (gpvtInitialize(qd_dev) != GT_OK) {
+		printk(KERN_ERR "gpvtInitialize failed\n");
+		return -1;
+	}
+
+	/* set all ports to work in Normal mode */
+	for (p = 0; p < qd_dev->numOfPorts; p++) {
+		if (MV_BIT_CHECK(switch_ports_mask, p))
+			if (gprtSetFrameMode(qd_dev, p, GT_FRAME_MODE_NORMAL) != GT_OK) {
+				printk(KERN_ERR "gprtSetFrameMode GT_FRAME_MODE_NORMAL failed\n");
+				return -1;
+			}
+	}
+
+	/* set priorities rules */
+	for (i = 0; i < qd_dev->numOfPorts; i++) {
+		if (MV_BIT_CHECK(switch_ports_mask, p)) {
+			/* default port priority to queue zero */
+			if (gcosSetPortDefaultTc(qd_dev, i, 0) != GT_OK)
+				printk(KERN_ERR "gcosSetPortDefaultTc failed (port %d)\n", i);
+
+			/* enable IP TOS Prio */
+			if (gqosIpPrioMapEn(qd_dev, i, GT_TRUE) != GT_OK)
+				printk(KERN_ERR "gqosIpPrioMapEn failed (port %d)\n", i);
+
+			/* set IP QoS */
+			if (gqosSetPrioMapRule(qd_dev, i, GT_FALSE) != GT_OK)
+				printk(KERN_ERR "gqosSetPrioMapRule failed (port %d)\n", i);
+
+			/* disable Vlan QoS Prio */
+			if (gqosUserPrioMapEn(qd_dev, i, GT_FALSE) != GT_OK)
+				printk(KERN_ERR "gqosUserPrioMapEn failed (port %d)\n", i);
+		}
+	}
+
+	/* specific Switch initialization according to Switch ID */
+	switch (qd_dev->deviceId) {
+	case GT_88E6161:
+	case GT_88E6165:
+	case GT_88E6171:
+	case GT_88E6351:
+		/* set Header Mode in all ports to False */
+		for (p = 0; p < qd_dev->numOfPorts; p++) {
+			if (MV_BIT_CHECK(switch_ports_mask, p))
+				if (gprtSetHeaderMode(qd_dev, p, GT_FALSE) != GT_OK) {
+					printk(KERN_ERR "gprtSetHeaderMode GT_FALSE failed\n");
+					return -1;
+				}
+		}
+
+		if (gprtSetHeaderMode(qd_dev, qd_cpu_port, GT_TRUE) != GT_OK) {
+			printk(KERN_ERR "gprtSetHeaderMode GT_TRUE failed\n");
+			return -1;
+		}
+
+		mv_switch_jumbo_mode_set(mtu);
+		break;
+
+	default:
+		printk(KERN_ERR "Unsupported Switch. Switch ID is 0x%X.\n", qd_dev->deviceId);
+		return -1;
+	}
+
+	/* The switch CPU port is not part of the VLAN, but rather connected by tunneling to each */
+	/* of the VLAN's ports. Our MAC addr will be added during start operation to the VLAN DB  */
+	/* at switch level to forward packets with this DA to CPU port.                           */
+	SWITCH_DBG(SWITCH_DBG_LOAD, ("Enabling Tunneling on ports: "));
+	for (i = 0; i < qd_dev->numOfPorts; i++) {
+		if (MV_BIT_CHECK(switch_ports_mask, i) && (i != qd_cpu_port)) {
+			if (gprtSetVlanTunnel(qd_dev, i, GT_TRUE) != GT_OK) {
+				printk(KERN_ERR "gprtSetVlanTunnel failed (port %d)\n", i);
+				return -1;
+			} else {
+				SWITCH_DBG(SWITCH_DBG_LOAD, ("%d ", i));
+			}
+		}
+	}
+	SWITCH_DBG(SWITCH_DBG_LOAD, ("\n"));
+
+	/* set cpu-port with port-based vlan to all other ports */
+	SWITCH_DBG(SWITCH_DBG_LOAD, ("cpu port-based vlan:"));
+	for (p = 0, cnt = 0; p < qd_dev->numOfPorts; p++) {
+		if (p != qd_cpu_port) {
+			SWITCH_DBG(SWITCH_DBG_LOAD, ("%d ", p));
+			port_list[cnt] = p;
+			cnt++;
+		}
+	}
+	SWITCH_DBG(SWITCH_DBG_LOAD, ("\n"));
+	if (gvlnSetPortVlanPorts(qd_dev, qd_cpu_port, port_list, cnt) != GT_OK) {
+		printk(KERN_ERR "gvlnSetPortVlanPorts failed\n");
+		return -1;
+	}
+
+	if (gfdbFlush(qd_dev, GT_FLUSH_ALL) != GT_OK)
+		printk(KERN_ERR "gfdbFlush failed\n");
+
+	mv_switch_link_detection_init();
+
+	/* Configure Ethernet related LEDs, currently according to Switch ID */
+	switch (qd_dev->deviceId) {
+	case GT_88E6161:
+	case GT_88E6165:
+	case GT_88E6171:
+	case GT_88E6351:
+		break;		/* do nothing */
+
+	default:
+		for (p = 0; p < qd_dev->numOfPorts; p++) {
+			if ((p != qd_cpu_port) && ((p))) {
+				if (gprtSetPhyReg(qd_dev, p, 22, 0x1FFA)) {
+					/* Configure Register 22 LED0 to 0xA for Link/Act */
+					printk(KERN_ERR "gprtSetPhyReg failed (port=%d)\n", p);
+				}
+			}
+		}
+		break;
+	}
+
+	/* enable all relevant ports (ports connected to the MAC or external ports) */
+	for (p = 0; p < qd_dev->numOfPorts; p++) {
+		if (MV_BIT_CHECK(switch_ports_mask, p)) {
+			if ((mvBoardSwitchPortMap(MV_SWITCH_DEF_INDEX, p) != -1) ||
+			    (mvBoardSwitchConnectedPortGet(MV_ETH_PORT_0) == p) ||
+			    (mvBoardSwitchConnectedPortGet(MV_ETH_PORT_1) == p)) {
+				if (gstpSetPortState(qd_dev, p, GT_PORT_FORWARDING) != GT_OK) {
+					printk(KERN_ERR "gstpSetPortState failed\n");
+					return -1;
+				}
+			}
+		}
+	}
+
+#ifdef SWITCH_DEBUG
+	/* for debug: */
+	mv_switch_status_print();
+#endif
+	return 0;
+}
+
+unsigned int mv_switch_link_detection_init(void)
+{
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+
+	unsigned int p;
+	static int link_init_done = 0;
+	unsigned int connected_phys_mask = 0;
+
+	/* initialize link detection only once */
+	if (link_init_done)
+		return 0;
+
+	switch_irq = mvBoardSwitchIrqGet();
+
+	if (!qsgmii_module) {
+		/* liron, TODO: find a nicer solution or use BoardEnv */
+#ifdef MV_INCLUDE_ETH_COMPLEX
+		/* QSGMII module is not connected, Switch is working in 3xFE mode */
+		connected_phys_mask = 0x0E;	/* KW2: Switch PHYs 1, 2, 3 */
+#else
+		connected_phys_mask = 0x1F;	/* KW40: Switch PHYs 0, 1, 2, 3, 4 */
+#endif
+		/* Enable Phy Link Status Changed interrupt at Phy level for the all enabled ports */
+		for (p = 0; p < qd_dev->numOfPorts; p++) {
+			if (MV_BIT_CHECK(connected_phys_mask, p) && (p != qd_cpu_port)) {
+				if (gprtPhyIntEnable(qd_dev, p, (GT_LINK_STATUS_CHANGED)) != GT_OK)
+					printk(KERN_ERR "gprtPhyIntEnable failed port %d\n", p);
+			}
+		}
+
+		if (switch_irq != -1) {
+			/* Interrupt supported */
+
+			if ((qd_dev->deviceId == GT_88E6161) || (qd_dev->deviceId == GT_88E6165) ||
+			    (qd_dev->deviceId == GT_88E6351) || (qd_dev->deviceId == GT_88E6171)) {
+				GT_DEV_EVENT gt_event = { GT_DEV_INT_PHY, 0, connected_phys_mask };
+
+				if (eventSetDevInt(qd_dev, &gt_event) != GT_OK)
+					printk(KERN_ERR "eventSetDevInt failed\n");
+
+				if (eventSetActive(qd_dev, GT_DEVICE_INT) != GT_OK)
+					printk(KERN_ERR "eventSetActive failed\n");
+			} else {
+				if (eventSetActive(qd_dev, GT_PHY_INTERRUPT) != GT_OK)
+					printk(KERN_ERR "eventSetActive failed\n");
+			}
+		}
+	}
+
+	if (gephy_on_port >= 0) {
+		if (gprtPhyIntEnable(qd_dev, gephy_on_port, (GT_LINK_STATUS_CHANGED)) != GT_OK)
+			printk(KERN_ERR "gprtPhyIntEnable failed port %d\n", gephy_on_port);
+	}
+
+	if (qsgmii_module)
+		connected_phys_mask = 0x0F;	/* Switch ports 0, 1, 2, 3 connected to QSGMII */
+
+	if (gephy_on_port >= 0)
+		connected_phys_mask |= (1 << gephy_on_port);
+
+	if (rgmiia_on_port >= 0)
+		connected_phys_mask |= (1 << rgmiia_on_port);
+
+	/* we want to use a timer for polling link status if no interrupt is available for all or some of the PHYs */
+	if ((switch_irq == -1)) { /* liron, TODO: || (rgmiia_on_port >= 0) */
+		/* Use timer for polling */
+		switch_link_poll = 1;
+		init_timer(&switch_link_timer);
+		switch_link_timer.function = mv_switch_link_timer_function;
+
+		if (switch_irq == -1)
+			switch_link_timer.data = connected_phys_mask;
+		else		/* timer only for RGMII-A connected port */
+			switch_link_timer.data = (1 << rgmiia_on_port);
+
+		switch_link_timer.expires = jiffies + (HZ);	/* 1 second */
+		add_timer(&switch_link_timer);
+	}
+
+	if (switch_irq != -1) {
+		/* Interrupt supported */
+
+		mv_eth_switch_interrupt_unmask(qsgmii_module, gephy_on_port);
+
+		if (request_irq(switch_irq, mv_switch_isr, (IRQF_DISABLED | IRQF_SAMPLE_RANDOM), "switch", NULL))
+			printk(KERN_ERR "failed to assign irq%d\n", switch_irq);
+	}
+
+	link_init_done = 1;
+
+	return connected_phys_mask;
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+}
+
+int mv_switch_tos_get(unsigned char tos)
+{
+	unsigned char queue;
+	int rc;
+
+	rc = gcosGetDscp2Tc(qd_dev, tos >> 2, &queue);
+	if (rc)
+		return -1;
+
+	return (int)queue;
+}
+
+int mv_switch_tos_set(unsigned char tos, int rxq)
+{
+	return gcosSetDscp2Tc(qd_dev, tos >> 2, (unsigned char)rxq);
+}
+
+int mv_switch_get_free_buffers_num(void)
+{
+	MV_U16 regVal;
+
+	if (gsysGetFreeQSize(qd_dev, &regVal) != GT_OK) {
+		printk(KERN_ERR "gsysGetFreeQSize - FAILED\n");
+		return -1;
+	}
+
+	return regVal;
+}
+
+#define QD_FMT "%10lu %10lu %10lu %10lu %10lu %10lu %10lu\n"
+#define QD_CNT(c, f) (GT_U32)c[0].f, (GT_U32)c[1].f, (GT_U32)c[2].f, (GT_U32)c[3].f, (GT_U32)c[4].f, (GT_U32)c[5].f, (GT_U32)c[6].f
+#define QD_MAX 7
+void mv_switch_stats_print(void)
+{
+	GT_STATS_COUNTER_SET3 counters[QD_MAX];
+	GT_PORT_STAT2 port_stats[QD_MAX];
+	int p;
+
+	if (qd_dev == NULL) {
+		printk(KERN_ERR "Switch is not initialized\n");
+		return;
+	}
+	memset(counters, 0, sizeof(GT_STATS_COUNTER_SET3) * QD_MAX);
+
+	printk(KERN_ERR "Total free buffers:      %u\n\n", mv_switch_get_free_buffers_num());
+
+	for (p = 0; p < QD_MAX; p++) {
+		if (gstatsGetPortAllCounters3(qd_dev, p, &counters[p]) != GT_OK)
+			printk(KERN_ERR "gstatsGetPortAllCounters3 for port #%d - FAILED\n", p);
+
+		if (gprtGetPortCtr2(qd_dev, p, &port_stats[p]) != GT_OK)
+			printk(KERN_ERR "gprtGetPortCtr2 for port #%d - FAILED\n", p);
+	}
+
+	printk(KERN_ERR "PortNum         " QD_FMT, (GT_U32) 0, (GT_U32) 1, (GT_U32) 2, (GT_U32) 3, (GT_U32) 4, (GT_U32) 5,
+	       (GT_U32) 6);
+	printk(KERN_ERR "-----------------------------------------------------------------------------------------------\n");
+	printk(KERN_ERR "InGoodOctetsLo  " QD_FMT, QD_CNT(counters, InGoodOctetsLo));
+	printk(KERN_ERR "InGoodOctetsHi  " QD_FMT, QD_CNT(counters, InGoodOctetsHi));
+	printk(KERN_ERR "InBadOctets     " QD_FMT, QD_CNT(counters, InBadOctets));
+	printk(KERN_ERR "InUnicasts      " QD_FMT, QD_CNT(counters, InUnicasts));
+	printk(KERN_ERR "InBroadcasts    " QD_FMT, QD_CNT(counters, InBroadcasts));
+	printk(KERN_ERR "InMulticasts    " QD_FMT, QD_CNT(counters, InMulticasts));
+	printk(KERN_ERR "inDiscardLo     " QD_FMT, QD_CNT(port_stats, inDiscardLo));
+	printk(KERN_ERR "inDiscardHi     " QD_FMT, QD_CNT(port_stats, inDiscardHi));
+	printk(KERN_ERR "InFiltered      " QD_FMT, QD_CNT(port_stats, inFiltered));
+
+	printk(KERN_ERR "OutOctetsLo     " QD_FMT, QD_CNT(counters, OutOctetsLo));
+	printk(KERN_ERR "OutOctetsHi     " QD_FMT, QD_CNT(counters, OutOctetsHi));
+	printk(KERN_ERR "OutUnicasts     " QD_FMT, QD_CNT(counters, OutUnicasts));
+	printk(KERN_ERR "OutMulticasts   " QD_FMT, QD_CNT(counters, OutMulticasts));
+	printk(KERN_ERR "OutBroadcasts   " QD_FMT, QD_CNT(counters, OutBroadcasts));
+	printk(KERN_ERR "OutFiltered     " QD_FMT, QD_CNT(port_stats, outFiltered));
+
+	printk(KERN_ERR "OutPause        " QD_FMT, QD_CNT(counters, OutPause));
+	printk(KERN_ERR "InPause         " QD_FMT, QD_CNT(counters, InPause));
+
+	printk(KERN_ERR "Octets64        " QD_FMT, QD_CNT(counters, Octets64));
+	printk(KERN_ERR "Octets127       " QD_FMT, QD_CNT(counters, Octets127));
+	printk(KERN_ERR "Octets255       " QD_FMT, QD_CNT(counters, Octets255));
+	printk(KERN_ERR "Octets511       " QD_FMT, QD_CNT(counters, Octets511));
+	printk(KERN_ERR "Octets1023      " QD_FMT, QD_CNT(counters, Octets1023));
+	printk(KERN_ERR "OctetsMax       " QD_FMT, QD_CNT(counters, OctetsMax));
+
+	printk(KERN_ERR "Excessive       " QD_FMT, QD_CNT(counters, Excessive));
+	printk(KERN_ERR "Single          " QD_FMT, QD_CNT(counters, Single));
+	printk(KERN_ERR "Multiple        " QD_FMT, QD_CNT(counters, InPause));
+	printk(KERN_ERR "Undersize       " QD_FMT, QD_CNT(counters, Undersize));
+	printk(KERN_ERR "Fragments       " QD_FMT, QD_CNT(counters, Fragments));
+	printk(KERN_ERR "Oversize        " QD_FMT, QD_CNT(counters, Oversize));
+	printk(KERN_ERR "Jabber          " QD_FMT, QD_CNT(counters, Jabber));
+	printk(KERN_ERR "InMACRcvErr     " QD_FMT, QD_CNT(counters, InMACRcvErr));
+	printk(KERN_ERR "InFCSErr        " QD_FMT, QD_CNT(counters, InFCSErr));
+	printk(KERN_ERR "Collisions      " QD_FMT, QD_CNT(counters, Collisions));
+	printk(KERN_ERR "Late            " QD_FMT, QD_CNT(counters, Late));
+	printk(KERN_ERR "OutFCSErr       " QD_FMT, QD_CNT(counters, OutFCSErr));
+	printk(KERN_ERR "Deferred        " QD_FMT, QD_CNT(counters, Deferred));
+
+	gstatsFlushAll(qd_dev);
+}
+
+static char *mv_str_port_state(GT_PORT_STP_STATE state)
+{
+	switch (state) {
+	case GT_PORT_DISABLE:
+		return "Disable";
+	case GT_PORT_BLOCKING:
+		return "Blocking";
+	case GT_PORT_LEARNING:
+		return "Learning";
+	case GT_PORT_FORWARDING:
+		return "Forwarding";
+	default:
+		return "Invalid";
+	}
+}
+
+static char *mv_str_speed_state(int port)
+{
+	GT_PORT_SPEED_MODE speed;
+	char *speed_str;
+
+	if (gprtGetSpeedMode(qd_dev, port, &speed) != GT_OK) {
+		printk(KERN_ERR "gprtGetSpeedMode failed (port %d)\n", port);
+		speed_str = "ERR";
+	} else {
+		if (speed == PORT_SPEED_1000_MBPS)
+			speed_str = "1 Gbps";
+		else if (speed == PORT_SPEED_100_MBPS)
+			speed_str = "100 Mbps";
+		else
+			speed_str = "10 Mbps";
+	}
+	return speed_str;
+}
+
+static char *mv_str_duplex_state(int port)
+{
+	GT_BOOL duplex;
+
+	if (gprtGetDuplex(qd_dev, port, &duplex) != GT_OK) {
+		printk(KERN_ERR "gprtGetDuplex failed (port %d)\n", port);
+		return "ERR";
+	} else
+		return (duplex) ? "Full" : "Half";
+}
+
+static char *mv_str_link_state(int port)
+{
+	GT_BOOL link;
+
+	if (gprtGetLinkState(qd_dev, port, &link) != GT_OK) {
+		printk(KERN_ERR "gprtGetLinkState failed (port %d)\n", port);
+		return "ERR";
+	} else
+		return (link) ? "Up" : "Down";
+}
+
+static char *mv_str_pause_state(int port)
+{
+	GT_BOOL force, pause;
+
+	if (gpcsGetForcedFC(qd_dev, port, &force) != GT_OK) {
+		printk(KERN_ERR "gpcsGetForcedFC failed (port %d)\n", port);
+		return "ERR";
+	}
+	if (force) {
+		if (gpcsGetFCValue(qd_dev, port, &pause) != GT_OK) {
+			printk(KERN_ERR "gpcsGetFCValue failed (port %d)\n", port);
+			return "ERR";
+		}
+	} else {
+		if (gprtGetPauseEn(qd_dev, port, &pause) != GT_OK) {
+			printk(KERN_ERR "gprtGetPauseEn failed (port %d)\n", port);
+			return "ERR";
+		}
+	}
+	return (pause) ? "Enable" : "Disable";
+}
+
+static char *mv_str_egress_mode(GT_EGRESS_MODE mode)
+{
+	switch (mode) {
+	case GT_UNMODIFY_EGRESS:
+		return "Unmodify";
+	case GT_UNTAGGED_EGRESS:
+		return "Untagged";
+	case GT_TAGGED_EGRESS:
+		return "Tagged";
+	case GT_ADD_TAG:
+		return "Add Tag";
+	default:
+		return "Invalid";
+	}
+}
+
+static char *mv_str_frame_mode(GT_FRAME_MODE mode)
+{
+	switch (mode) {
+	case GT_FRAME_MODE_NORMAL:
+		return "Normal";
+	case GT_FRAME_MODE_DSA:
+		return "DSA";
+	case GT_FRAME_MODE_PROVIDER:
+		return "Provider";
+	case GT_FRAME_MODE_ETHER_TYPE_DSA:
+		return "EtherType DSA";
+	default:
+		return "Invalid";
+	}
+}
+
+static char *mv_str_header_mode(GT_BOOL mode)
+{
+	switch (mode) {
+	case GT_FALSE:
+		return "False";
+	case GT_TRUE:
+		return "True";
+	default:
+		return "Invalid";
+	}
+}
+
+void mv_switch_status_print(void)
+{
+	int p;
+	GT_PORT_STP_STATE port_state = -1;
+	GT_EGRESS_MODE egress_mode = -1;
+	GT_FRAME_MODE frame_mode = -1;
+	GT_BOOL header_mode = -1;
+
+	if (qd_dev == NULL) {
+		printk(KERN_ERR "Switch is not initialized\n");
+		return;
+	}
+	printk(KERN_ERR "Printing Switch Status:\n");
+
+	printk(KERN_ERR "Port   State     Link   Duplex   Speed    Pause     Egress     Frame    Header\n");
+	for (p = 0; p < qd_dev->numOfPorts; p++) {
+
+		if (gstpGetPortState(qd_dev, p, &port_state) != GT_OK)
+			printk(KERN_ERR "gstpGetPortState failed\n");
+
+		if (gprtGetEgressMode(qd_dev, p, &egress_mode) != GT_OK)
+			printk(KERN_ERR "gprtGetEgressMode failed\n");
+
+		if (gprtGetFrameMode(qd_dev, p, &frame_mode) != GT_OK)
+			printk(KERN_ERR "gprtGetFrameMode failed\n");
+
+		if (gprtGetHeaderMode(qd_dev, p, &header_mode) != GT_OK)
+			printk(KERN_ERR "gprtGetHeaderMode failed\n");
+
+		printk(KERN_ERR "%2d, %10s,  %4s,  %4s,  %8s,  %7s,  %s,  %s,  %s\n",
+		       p, mv_str_port_state(port_state), mv_str_link_state(p),
+		       mv_str_duplex_state(p), mv_str_speed_state(p), mv_str_pause_state(p),
+		       mv_str_egress_mode(egress_mode), mv_str_frame_mode(frame_mode), mv_str_header_mode(header_mode));
+	}
+}
+
+int mv_switch_reg_read(int port, int reg, int type, MV_U16 *value)
+{
+	GT_STATUS status;
+
+	if (qd_dev == NULL) {
+		printk(KERN_ERR "Switch is not initialized\n");
+		return 1;
+	}
+
+	switch (type) {
+	case MV_SWITCH_PHY_ACCESS:
+		if (qsgmii_module)
+			printk(KERN_ERR "warning: cannot read Switch PHY register when QSGMII module is connected\n");
+		status = gprtGetPhyReg(qd_dev, port, reg, value);
+		break;
+
+	case MV_SWITCH_PORT_ACCESS:
+		status = gprtGetSwitchReg(qd_dev, port, reg, value);
+		break;
+
+	case MV_SWITCH_GLOBAL_ACCESS:
+		status = gprtGetGlobalReg(qd_dev, reg, value);
+		break;
+
+	case MV_SWITCH_GLOBAL2_ACCESS:
+		status = gprtGetGlobal2Reg(qd_dev, reg, value);
+		break;
+
+	case MV_SWITCH_SMI_ACCESS:
+		/* port means phyAddr */
+		status = miiSmiIfReadRegister(qd_dev, port, reg, value);
+		break;
+
+	default:
+		printk(KERN_ERR "%s Failed: Unexpected access type %d\n", __func__, type);
+		return 1;
+	}
+	if (status != GT_OK) {
+		printk(KERN_ERR "%s Failed: status = %d\n", __func__, status);
+		return 2;
+	}
+	return 0;
+}
+
+int mv_switch_reg_write(int port, int reg, int type, MV_U16 value)
+{
+	GT_STATUS status;
+
+	if (qd_dev == NULL) {
+		printk(KERN_ERR "Switch is not initialized\n");
+		return 1;
+	}
+
+	switch (type) {
+	case MV_SWITCH_PHY_ACCESS:
+		if (qsgmii_module)
+			printk(KERN_ERR "warning: cannot write Switch PHY register when QSGMII module is connected\n");
+		status = gprtSetPhyReg(qd_dev, port, reg, value);
+		break;
+
+	case MV_SWITCH_PORT_ACCESS:
+		status = gprtSetSwitchReg(qd_dev, port, reg, value);
+		break;
+
+	case MV_SWITCH_GLOBAL_ACCESS:
+		status = gprtSetGlobalReg(qd_dev, reg, value);
+		break;
+
+	case MV_SWITCH_GLOBAL2_ACCESS:
+		status = gprtSetGlobal2Reg(qd_dev, reg, value);
+		break;
+
+	case MV_SWITCH_SMI_ACCESS:
+		/* port means phyAddr */
+		status = miiSmiIfWriteRegister(qd_dev, port, reg, value);
+		break;
+
+	default:
+		printk(KERN_ERR "%s Failed: Unexpected access type %d\n", __func__, type);
+		return 1;
+	}
+	if (status != GT_OK) {
+		printk(KERN_ERR "%s Failed: status = %d\n", __func__, status);
+		return 2;
+	}
+	return 0;
+}
+
+int mv_switch_all_multicasts_del(int db_num)
+{
+	GT_STATUS status = GT_OK;
+	GT_ATU_ENTRY atu_entry;
+	GT_U8 mc_mac[] = { 0x01, 0x00, 0x00, 0x00, 0x00, 0x00 };
+	GT_U8 bc_mac[] = { 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF };
+
+	memcpy(atu_entry.macAddr.arEther, &mc_mac, 6);
+	atu_entry.DBNum = db_num;
+
+	while ((status = gfdbGetAtuEntryNext(qd_dev, &atu_entry)) == GT_OK) {
+
+		/* we don't want to delete the broadcast entry which is the last one */
+		if (memcmp(atu_entry.macAddr.arEther, &bc_mac, 6) == 0)
+			break;
+
+		SWITCH_DBG(SWITCH_DBG_MCAST, ("Deleting ATU Entry: db = %d, MAC = %02X:%02X:%02X:%02X:%02X:%02X\n",
+					      atu_entry.DBNum, atu_entry.macAddr.arEther[0],
+					      atu_entry.macAddr.arEther[1], atu_entry.macAddr.arEther[2],
+					      atu_entry.macAddr.arEther[3], atu_entry.macAddr.arEther[4],
+					      atu_entry.macAddr.arEther[5]));
+
+		if (gfdbDelAtuEntry(qd_dev, &atu_entry) != GT_OK) {
+			printk(KERN_ERR "gfdbDelAtuEntry failed\n");
+			return -1;
+		}
+		memcpy(atu_entry.macAddr.arEther, &mc_mac, 6);
+		atu_entry.DBNum = db_num;
+	}
+
+	return 0;
+}
+
+int mv_switch_port_add(int switch_port, u16 vlan_grp_id, u16 port_map)
+{
+	int p;
+
+	/* Set default VLAN_ID for port */
+	if (gvlnSetPortVid(qd_dev, switch_port, MV_SWITCH_PORT_VLAN_ID(vlan_grp_id, switch_port)) != GT_OK) {
+		printk(KERN_ERR "gvlnSetPortVid failed\n");
+		return -1;
+	}
+	/* Map port to VLAN DB */
+	if (gvlnSetPortVlanDBNum(qd_dev, switch_port, MV_SWITCH_VLAN_TO_GROUP(vlan_grp_id)) != GT_OK) {
+		printk(KERN_ERR "gvlnSetPortVlanDBNum failed\n");
+		return -1;
+	}
+
+	/* Add port to the VLAN (CPU port is not part of VLAN) */
+	if (mv_switch_port_based_vlan_set((port_map & ~(1 << qd_cpu_port)), 0) != 0)
+		printk(KERN_ERR "mv_switch_port_based_vlan_set failed\n");
+
+	/* Add port to vtu (used in tx) */
+	if (mv_switch_vlan_in_vtu_set(vlan_grp_id, MV_SWITCH_VLAN_TO_GROUP(vlan_grp_id),
+				      (port_map | (1 << qd_cpu_port)))) {
+		printk(KERN_ERR "mv_switch_vlan_in_vtu_set failed\n");
+	}
+
+	/* set vtu with each port private vlan id (used in rx) */
+	for (p = 0; p < qd_dev->numOfPorts; p++) {
+		if (MV_BIT_CHECK(port_map, p) && (p != qd_cpu_port)) {
+			if (mv_switch_vlan_in_vtu_set(MV_SWITCH_PORT_VLAN_ID(vlan_grp_id, p),
+						      MV_SWITCH_VLAN_TO_GROUP(vlan_grp_id),
+						      port_map & ~(1 << qd_cpu_port)) != 0) {
+				printk(KERN_ERR "mv_switch_vlan_in_vtu_set failed\n");
+			}
+		}
+	}
+
+	/* Enable port */
+	if (gstpSetPortState(qd_dev, switch_port, GT_PORT_FORWARDING) != GT_OK)
+		printk(KERN_ERR "gstpSetPortState failed\n");
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+	if (!qsgmii_module) {
+		/* Enable Phy Link Status Changed interrupt at Phy level for the port */
+		if (gprtPhyIntEnable(qd_dev, switch_port, (GT_LINK_STATUS_CHANGED)) != GT_OK)
+			printk(KERN_ERR "gprtPhyIntEnable failed port %d\n", switch_port);
+	}
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+
+	return 0;
+}
+
+int mv_switch_port_del(int switch_port, u16 vlan_grp_id, u16 port_map)
+{
+	int p;
+
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+	if (!qsgmii_module) {
+		/* Disable link change interrupts on unmapped port */
+		if (gprtPhyIntEnable(qd_dev, switch_port, 0) != GT_OK)
+			printk(KERN_ERR "gprtPhyIntEnable failed on port #%d\n", switch_port);
+	}
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+
+	/* Disable unmapped port */
+	if (gstpSetPortState(qd_dev, switch_port, GT_PORT_DISABLE) != GT_OK)
+		printk(KERN_ERR "gstpSetPortState failed on port #%d\n", switch_port);
+
+	/* Remove port from the VLAN (CPU port is not part of VLAN) */
+	if (mv_switch_port_based_vlan_set((port_map & ~(1 << qd_cpu_port)), 0) != 0)
+		printk(KERN_ERR "mv_gtw_set_port_based_vlan failed\n");
+
+	/* Remove port from vtu (used in tx) */
+	if (mv_switch_vlan_in_vtu_set(vlan_grp_id, MV_SWITCH_VLAN_TO_GROUP(vlan_grp_id),
+				      (port_map | (1 << qd_cpu_port))) != 0) {
+		printk(KERN_ERR "mv_gtw_set_vlan_in_vtu failed\n");
+	}
+
+	/* Remove port from vtu of each port private vlan id (used in rx) */
+	for (p = 0; p < qd_dev->numOfPorts; p++) {
+		if (MV_BIT_CHECK(port_map, p) && (p != qd_cpu_port)) {
+			if (mv_switch_vlan_in_vtu_set(MV_SWITCH_PORT_VLAN_ID(vlan_grp_id, p),
+						      MV_SWITCH_VLAN_TO_GROUP(vlan_grp_id),
+						      (port_map & ~(1 << qd_cpu_port))) != 0)
+				printk(KERN_ERR "mv_gtw_set_vlan_in_vtu failed\n");
+		}
+	}
+
+	return 0;
+}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_switch/mv_switch.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_switch/mv_switch.h
new file mode 100644
index 0000000..5c02f89
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_switch/mv_switch.h
@@ -0,0 +1,68 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_switch_h__
+#define __mv_switch_h__
+
+#define MV_SWITCH_PHY_ACCESS			1
+#define MV_SWITCH_PORT_ACCESS			2
+#define MV_SWITCH_GLOBAL_ACCESS			3
+#define MV_SWITCH_GLOBAL2_ACCESS		4
+#define MV_SWITCH_SMI_ACCESS                	5
+
+#define MV_SWITCH_PORT_VLAN_ID(grp, port)  ((grp) + (port) + 1)
+#define MV_SWITCH_GROUP_VLAN_ID(grp)       (((grp) + 1) << 8)
+#define MV_SWITCH_VLAN_TO_GROUP(vid)       ((((vid) & 0xf00) >> 8) - 1)
+
+int     mv_switch_load(unsigned int switch_ports_mask);
+int     mv_switch_unload(unsigned int switch_ports_mask);
+int     mv_switch_init(int mtu, unsigned int switch_ports_mask);
+void    mv_switch_link_update_event(MV_U32 port_mask, int force_link_check);
+int     mv_switch_jumbo_mode_set(int max_size);
+int     mv_switch_tos_get(unsigned char tos);
+int     mv_switch_tos_set(unsigned char tos, int queue);
+int     mv_switch_port_based_vlan_set(unsigned int ports_mask, int set_cpu_port);
+int     mv_switch_vlan_in_vtu_set(unsigned short vlan_id, unsigned short db_num, unsigned int ports_mask);
+int     mv_switch_mac_addr_set(unsigned char *mac_addr, unsigned char db,
+			       unsigned int ports_mask, unsigned char op);
+int     mv_switch_atu_db_flush(int db_num);
+int     mv_eth_switch_vlan_set(u16 vlan_grp_id, u16 port_map, u16 cpu_port);
+int     mv_switch_promisc_set(u16 vlan_grp_id, u16 port_map, u16 cpu_port, u8 promisc_on);
+unsigned int    mv_switch_link_detection_init(void);
+
+int     mv_switch_reg_read(int port, int reg, int type, MV_U16 *value);
+int     mv_switch_reg_write(int port, int reg, int type, MV_U16 value);
+
+void    mv_switch_stats_print(void);
+void    mv_switch_status_print(void);
+
+int     mv_switch_all_multicasts_del(int db_num);
+
+int     mv_switch_port_add(int switch_port, u16 vlan_grp_id, u16 port_map);
+int     mv_switch_port_del(int switch_port, u16 vlan_grp_id, u16 port_map);
+
+#endif /* __mv_switch_h__ */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_switch/mv_switch_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_switch/mv_switch_sysfs.c
new file mode 100644
index 0000000..f6b19e8
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_switch/mv_switch_sysfs.c
@@ -0,0 +1,205 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "mvTypes.h"
+#include "mv_switch.h"
+#include "../mv_neta/net_dev/mv_netdev.h"
+
+static ssize_t mv_switch_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "cat help                            - show this help\n");
+	off += sprintf(buf+off, "cat stats                           - show statistics for switch all ports info\n");
+	off += sprintf(buf+off, "cat status                          - show switch status\n");
+#ifdef CONFIG_MV_ETH_SWITCH
+	off += sprintf(buf+off, "echo <eth_name>   > netdev_sts      - print network device status\n");
+	off += sprintf(buf+off, "echo <eth_name> p > port_add        - map switch port to a network device\n");
+	off += sprintf(buf+off, "echo <eth_name> p > port_del        - unmap switch port from a network device\n");
+#endif /* CONFIG_MV_ETH_SWITCH */
+	off += sprintf(buf+off, "echo p r t   > reg_r                - read switch register.  t: 1-phy, 2-port, 3-global, 4-global2, 5-smi\n");
+	off += sprintf(buf+off, "echo p r t v > reg_w                - write switch register. t: 1-phy, 2-port, 3-global, 4-global2, 5-smi\n");
+	return off;
+}
+
+static ssize_t mv_switch_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	const char *name = attr->attr.name;
+	int off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "stats"))
+		mv_switch_stats_print();
+	else if (!strcmp(name, "status"))
+		mv_switch_status_print();
+	else
+		off = mv_switch_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_switch_store(struct device *dev, struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	unsigned long   flags;
+	int             err, port, reg, type;
+	unsigned int    v;
+	MV_U16          val;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read arguments */
+	err = port = reg = type = val = 0;
+	sscanf(buf, "%d %d %d %x", &port, &reg, &type, &v);
+
+	local_irq_save(flags);
+	if (!strcmp(name, "reg_r")) {
+		err = mv_switch_reg_read(port, reg, type, &val);
+	} else if (!strcmp(name, "reg_w")) {
+		val = (MV_U16)v;
+		err = mv_switch_reg_write(port, reg, type, v);
+	}
+	printk(KERN_ERR "switch register access: type=%d, port=%d, reg=%d", type, port, reg);
+
+	if (err)
+		printk(KERN_ERR " - FAILED, err=%d\n", err);
+	else
+		printk(KERN_ERR " - SUCCESS, val=0x%04x\n", val);
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+#ifdef CONFIG_MV_ETH_SWITCH
+static ssize_t mv_switch_netdev_store(struct device *dev, struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err = 0, port = 0;
+	char            dev_name[30];
+	struct net_device *netdev;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read arguments */
+	sscanf(buf, "%s %d", dev_name, &port);
+	netdev = dev_get_by_name(&init_net, dev_name);
+	if (netdev == NULL) {
+		err = 1;
+	} else {
+		if (!strcmp(name, "netdev_sts"))
+			mv_eth_netdev_print(netdev);
+		else if (!strcmp(name, "port_add"))
+			err = mv_eth_switch_port_add(netdev, port);
+		else if (!strcmp(name, "port_del"))
+			err = mv_eth_switch_port_del(netdev, port);
+
+		dev_put(netdev);
+	}
+
+	if (err)
+		printk(KERN_ERR " - FAILED, err=%d\n", err);
+	else
+		printk(KERN_ERR " - SUCCESS\n");
+
+	return err ? -EINVAL : len;
+}
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+static DEVICE_ATTR(reg_r,       S_IWUSR, mv_switch_show, mv_switch_store);
+static DEVICE_ATTR(reg_w,       S_IWUSR, mv_switch_show, mv_switch_store);
+static DEVICE_ATTR(status,      S_IRUSR, mv_switch_show, mv_switch_store);
+static DEVICE_ATTR(stats,       S_IRUSR, mv_switch_show, mv_switch_store);
+static DEVICE_ATTR(help,        S_IRUSR, mv_switch_show, mv_switch_store);
+#ifdef CONFIG_MV_ETH_SWITCH
+static DEVICE_ATTR(netdev_sts,  S_IWUSR, mv_switch_show, mv_switch_netdev_store);
+static DEVICE_ATTR(port_add,    S_IWUSR, mv_switch_show, mv_switch_netdev_store);
+static DEVICE_ATTR(port_del,    S_IWUSR, mv_switch_show, mv_switch_netdev_store);
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+static struct attribute *mv_switch_attrs[] = {
+	&dev_attr_reg_r.attr,
+	&dev_attr_reg_w.attr,
+	&dev_attr_status.attr,
+	&dev_attr_stats.attr,
+	&dev_attr_help.attr,
+#ifdef CONFIG_MV_ETH_SWITCH
+	&dev_attr_netdev_sts.attr,
+	&dev_attr_port_add.attr,
+	&dev_attr_port_del.attr,
+#endif /* CONFIG_MV_ETH_SWITCH */
+	NULL
+};
+
+static struct attribute_group mv_switch_group = {
+	.name = "switch",
+	.attrs = mv_switch_attrs,
+};
+
+int __devinit mv_switch_sysfs_init(void)
+{
+	int err;
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+	if (!pd) {
+		platform_device_register_simple("neta", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+	}
+
+	if (!pd) {
+		printk(KERN_ERR "%s: cannot find neta device\n", __func__);
+		pd = &platform_bus;
+	}
+
+	err = sysfs_create_group(&pd->kobj, &mv_switch_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+out:
+	return err;
+}
+
+module_init(mv_switch_sysfs_init);
+
+MODULE_AUTHOR("Dima Epshtein");
+MODULE_DESCRIPTION("sysfs for Marvell switch");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/Kconfig
new file mode 100644
index 0000000..1656f68
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/Kconfig
@@ -0,0 +1,63 @@
+menu "TSU options"
+	depends on MV_INCLUDE_TS
+
+config  MV_TSU
+	bool "Support for Marvell Transport Stream Interface"
+#	depends on MV_INCLUDE_TS
+	default n
+choice
+	prompt "TSU interface type"
+	depends on MV_TSU
+	default TSU_PARALLEL_IF
+
+config TSU_SERIAL_IF
+	bool "Serial Interface"
+	---help---
+	The TSU will work in serial mode (2 ports).
+
+config TSU_PARALLEL_IF
+	bool "Parallel Interface"
+	---help---
+	The TSU will work in parallel mode (1 port).
+endchoice
+
+
+choice
+	prompt "TSU Core-Clock"
+	depends on MV_TSU
+	default TSU_CORE_CLK_83MHZ
+
+config TSU_CORE_CLK_71MHZ
+	bool "71 MHz TSU Core Clock"
+
+config TSU_CORE_CLK_83MHZ
+	bool "83 MHz TSU Core Clock"
+
+config TSU_CORE_CLK_91MHZ
+	bool "91 MHz TSU Core Clock"
+config TSU_CORE_CLK_100MHZ
+	bool "100 MHz TSU Core Clock"
+
+endchoice
+
+config  MV_TSU_PKT_SIZE
+        int "TSU packet size"
+        depends on MV_TSU
+	default 188
+	range 188, 256
+        ---help---
+          Define the TS packet size to be used (Same for both ports)
+	  Must be >= 188 and <= 256.
+
+config  MV_TSU_PROC
+	bool "Support for TSU proc interface"
+	depends on MV_TSU
+	default y
+        ---help---
+          Support Proc-fs interface to configuring the TS control driver.
+
+endmenu
+
+
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/Makefile
new file mode 100644
index 0000000..811d010
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/Makefile
@@ -0,0 +1,10 @@
+#
+# Makefile for the Marvell Transport Stream Unit driver
+#
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+obj-$(CONFIG_MV_TSU)	+= mv_tsu.o
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu.c
new file mode 100644
index 0000000..8f5babb
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu.c
@@ -0,0 +1,1552 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <linux/proc_fs.h>
+#include <linux/cdev.h>
+#include <linux/version.h>
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "ts/mvTsu.h"
+#include "ts/mvTsuRegs.h"
+#include "mvSysTsApi.h"
+#include "mv_tsu_ioctl.h"
+#include "mv_tsu.h"
+
+/*
+ * Local Macros and Definiions.
+ */
+#undef TSU_DEBUG
+//#define TSU_DEBUG
+#define TSU_DBG_OFF     0x00
+#define TSU_DBG_INIT    0x01
+#define TSU_DBG_OPEN    0x02
+#define TSU_DBG_RELEASE 0x04
+#define TSU_DBG_READ 	0x08
+#define TSU_DBG_WRITE 	0x10
+#define TSU_DBG_IOCTL 	0x20
+#define TSU_DBG_PROC    0x40
+#define TSU_DBG_INT     0x80
+#define TSU_DBG_ALL     0xFFFFFFFF
+
+#ifdef TSU_DEBUG
+static u32 mvtsu_dbg = TSU_DBG_READ;
+#define TSU_DPRINT(f, x) if((mvtsu_dbg & (f)) == (f)) printk x
+#else
+#define TSU_DPRINT(f, x)
+#endif
+#define TSU_ENTER(f, fname)	TSU_DPRINT(f, ("Entering " fname "()\n"))
+#define TSU_LEAVE(f, fname)	TSU_DPRINT(f, ("Leaving " fname "()\n"))
+
+#undef TSU_UNCACHED_DATA_BUFFERS
+
+#define TSU_DATA_BUFF_HW_2_SW(buf)      (((MV_U32)(buf)) & ~(TSU_DMA_ALIGN - 1))
+
+#define TSU_IS_DEC_DIGIT(c)	(((c) >= '0') && ((c) <= '9'))
+
+#define TSU_DEV_NAME "tsu"
+#define TSU_NUM_DEVICES	2
+#ifdef CONFIG_TSU_SERIAL_IF
+#define DEF_TSU_MODE TSU_MODE_SERIAL
+#else
+#define DEF_TSU_MODE TSU_MODE_PARALLEL
+#endif
+
+#if defined(CONFIG_TSU_CORE_CLK_71MHZ)
+#define DEF_TSU_CORE_CLOCK TSU_CORE_CLK_71_MHZ
+#elif defined(CONFIG_TSU_CORE_CLK_83MHZ)
+#define DEF_TSU_CORE_CLOCK TSU_CORE_CLK_83_MHZ
+#elif defined(CONFIG_TSU_CORE_CLK_91MHZ)
+#define DEF_TSU_CORE_CLOCK TSU_CORE_CLK_91_MHZ
+#elif defined(CONFIG_TSU_CORE_CLK_100MHZ)
+#define DEF_TSU_CORE_CLOCK TSU_CORE_CLK_100_MHZ
+#endif
+
+#define TSU_MIN_READ_SIZE	8
+
+/*
+ * Local data-structures.
+ */
+struct mvtsu_dev {
+	u8 port;
+	struct cdev cdev;
+	MV_TSU_BUFF_INFO buff_info;
+	MV_TSU_SIGNAL_CONFIG signal_cfg;
+	MV_U32 serial_sig_flags;
+	MV_U8 sync_loss;
+	MV_U8 sync_detect;
+	MV_TSU_PORT_DIRECTION port_dir;
+	u32 valid_data_size;	/* Size of data in HW buffers.		*/
+	u32 rd_rw_data_size;	/* Size of buffer for read / write.	*/
+	u8 *data_buff;
+	u32 *stat_buff;
+	u32 stat_buff_size;
+	u32 data_offs;
+	u32 buff_handle;
+	u8 read_all_at_once;
+	u32 clockrate;
+	u32 rd_wr_timeout;
+	u32 tx_tms_gap;
+	u32 tx_tms_val;
+	u8 auto_tms_mode;
+	spinlock_t lock;
+	struct tsu_stat int_stat;
+};
+
+
+/*
+ * Local control variables.
+ */
+static MV_TSU_PORTS_MODE cfg_tsu_mode;
+static MV_TSU_CORE_CLOCK cfg_core_clk;
+static int cfg_pkt_size;
+static struct mvtsu_dev mvtsu_devs[TSU_NUM_DEVICES];
+static dev_t mvtsu_device;
+char *mvtsu_cmdline;
+
+int mvtsu_cmdline_config(char *s);
+static int mvtsu_parse_cmdline(void);
+__setup("mv_tsu_config=", mvtsu_cmdline_config);
+
+#ifdef CONFIG_MV_TSU_PROC
+static struct proc_dir_entry *mvtsu_proc_entry;
+
+static int mvtsu_proc_init(void);
+#endif /* CONFIG_MV_TSU_PROC */
+
+#ifdef TSU_DEBUG
+static void mvtsu_dump_regs(int port)
+{
+	int i;
+
+	for(i = 0x0; i <= 0x68; i+=4) {
+		printk("Reg 0x%08x --> 0x%08x.\n",TSU_REG_BASE(port) + i,
+		       MV_REG_READ(TSU_REG_BASE(port) + i));
+	}
+	return;
+}
+#endif /* TSU_DEBUG */
+
+/*
+ * Calculate the timestamp gap between two packets.
+ */
+static void mvtsu_tx_timestamp_calc(struct mvtsu_dev *dev)
+{
+	u32 base_clock = 4166660;
+
+	dev->tx_tms_gap = (base_clock * cfg_pkt_size) / (dev->clockrate / 10);
+	dev->tx_tms_val = 0;
+	return;
+}
+
+
+/*
+ * Calculate the timeout needed between packets.
+ */
+static void mvtsu_rd_wr_timeout_calc(struct mvtsu_dev *dev)
+{
+        dev->rd_wr_timeout = 0;
+        if(dev->clockrate >= 1000) {
+		/* How much time (in milisec) is needed for a single 	*/
+		/* block of data.					*/
+		dev->rd_wr_timeout = ((dev->valid_data_size * 8) /
+				      (dev->clockrate / 1000));
+	}
+	/* Double the timeout to be on the safe side.	*/
+	dev->rd_wr_timeout *= 2;
+	if(dev->rd_wr_timeout < 50)
+		dev->rd_wr_timeout = 50;
+	return;
+}
+
+
+static void mvtsu_set_defaults(struct mvtsu_dev *dev)
+{
+	TSU_ENTER(TSU_DBG_INIT, "mvtsu_set_defaults");
+
+	/* Set buffer parameters.	*/
+	dev->buff_info.aggrMode = TSU_DFLT_AGGR_MODE;
+	dev->buff_info.aggrMode2TmstmpOff = TSU_DFLT_TMSTMP_OFFS;
+	dev->buff_info.aggrNumPackets = TSU_DFLT_AGGR_PCKT_NUM;
+	dev->buff_info.numTsDesc = TSU_DFLT_TS_DESC_NUM;
+	dev->buff_info.numDoneQEntry = TSU_DFLT_TS_DONEQ_NUM;
+	dev->buff_info.tsDataBuff = NULL;
+	dev->buff_info.tsDoneBuff = NULL;
+	dev->buff_info.dataBlockSize = 0;
+
+	/* Set signal config.		*/
+	dev->signal_cfg.tsDataEdge = TSU_SIGNAL_EDGE_KEEP_DEF;
+	dev->signal_cfg.tsError = TSU_SIGNAL_KEEP_DEF;
+	dev->signal_cfg.tsSync = TSU_SIGNAL_KEEP_DEF;
+	dev->signal_cfg.tsValid = TSU_SIGNAL_KEEP_DEF;
+	dev->serial_sig_flags = 0;
+
+	/* TS Sync detection parameters.	*/
+	mvTsuRxSyncDetectionGet(dev->port,&dev->sync_detect, &dev->sync_loss);
+
+	dev->read_all_at_once = TSU_DFLT_DATA_READ_AT_ONCE;
+	dev->clockrate = TSU_DFLT_CLOCK_RATE;
+
+	TSU_LEAVE(TSU_DBG_INIT, "mvtsu_set_defaults");
+	return;
+}
+
+static irqreturn_t mvtsu_interrupt_handler(int irq , void *arg)
+{
+	struct mvtsu_dev* dev = (struct mvtsu_dev*)arg;
+	u32 cause;
+
+	TSU_ENTER(TSU_DBG_INT, "mvtsu_interrupt_handler");
+
+	cause = MV_REG_READ(MV_TSU_INTERRUPT_SRC_REG(dev->port));
+	TSU_DPRINT(TSU_DBG_INT, ("\tPort %d, Cause = 0x%08x.\n",dev->port,cause));
+
+	if(cause & TSU_INT_TS_IF_ERROR)
+		dev->int_stat.ts_if_err++;
+	if(cause & TSU_INT_FIFO_OVFL_ERROR)
+		dev->int_stat.fifo_ovfl++;
+	if(cause & TSU_INT_TS_CONN_ERROR)
+		dev->int_stat.ts_conn_err++;
+	if(cause & TSU_INT_CLOCK_SYNC_EXP)
+		dev->int_stat.clk_sync_exp++;
+
+	TSU_LEAVE(TSU_DBG_INT, "mvtsu_interrupt_handler");
+	return IRQ_HANDLED;
+}
+
+int mvtsu_open (struct inode *inode, struct file *filp)
+{
+	struct mvtsu_dev *dev;
+	MV_TSU_PORT_CONFIG port_cfg;
+	MV_TSU_BUFF_INFO *binfo = NULL;
+	MV_STATUS status;
+	int result = 0;
+	int stat_size = 0;
+	int data_size = 0;
+	int data_buff_offs;
+
+	TSU_ENTER(TSU_DBG_OPEN, "mvtsu_open");
+
+	if(MV_FALSE == mvCtrlPwrClckGet(TS_UNIT_ID, 0)) {
+		printk("Transport Stream interface is powered off.\n");
+		return 0;
+	}
+
+	/*  Find the device structure.	*/
+	dev = container_of(inode->i_cdev, struct mvtsu_dev, cdev);
+
+    	/* Determine the port direction according to the read / write flag.*/
+	if ((filp->f_mode & (FMODE_WRITE | FMODE_READ)) == FMODE_WRITE) {
+		port_cfg.portDir = TSU_PORT_OUTPUT;
+	} else if ((filp->f_mode & (FMODE_WRITE | FMODE_READ)) == FMODE_READ) {
+		port_cfg.portDir = TSU_PORT_INPUT;
+	} else {
+		result = -EINVAL;
+		goto fail_init;
+	}
+
+	/* Reset the port.		*/
+	mvTsuPortReset(dev->port);
+
+	/* Initialize the port.		*/
+	port_cfg.pktSize = cfg_pkt_size;
+       	status = mvTsuPortInit(dev->port,&port_cfg);
+	if(status != MV_OK) {
+		result = -EINVAL;
+		goto fail_init;
+	}
+
+	TSU_DPRINT(TSU_DBG_OPEN, ("\tTSU unit initialized successfully.\n"));
+
+	/* Initialize the port buffers.	*/
+	binfo = &dev->buff_info;
+	switch(binfo->aggrMode)
+	{
+	case (MV_TSU_AGGR_MODE_DISABLED):
+		binfo->dataBlockSize = port_cfg.pktSize;
+		dev->valid_data_size = port_cfg.pktSize;
+		dev->rd_rw_data_size = binfo->dataBlockSize + TSU_DONE_STATUS_ENTRY_SIZE;
+		binfo->aggrNumPackets = 1;
+		break;
+	case (MV_TSU_AGGR_MODE_1):
+		binfo->dataBlockSize = port_cfg.pktSize * binfo->aggrNumPackets;
+		if(port_cfg.portDir == TSU_PORT_OUTPUT) {
+			binfo->dataBlockSize += MV_MAX(TSU_DMA_ALIGN,TSU_MODE1_OUT_TMS_SIZE);
+			dev->rd_rw_data_size = binfo->dataBlockSize;
+		}
+		else {
+			dev->rd_rw_data_size = binfo->dataBlockSize +
+				(binfo->aggrNumPackets * TSU_DONE_STATUS_ENTRY_SIZE);
+		}
+		dev->valid_data_size = port_cfg.pktSize * binfo->aggrNumPackets;
+		break;
+	case (MV_TSU_AGGR_MODE_2):
+		binfo->aggrMode2TmstmpOff = TSU_DMA_ALIGN -
+			(port_cfg.pktSize & (TSU_DMA_ALIGN - 1));
+		binfo->dataBlockSize =
+			(binfo->aggrNumPackets *
+			 (port_cfg.pktSize + binfo->aggrMode2TmstmpOff) +
+			 TSU_DMA_ALIGN);
+		dev->valid_data_size = (binfo->aggrNumPackets *
+					(port_cfg.pktSize + binfo->aggrMode2TmstmpOff));
+		dev->rd_rw_data_size = dev->valid_data_size;
+	default:
+		break;
+	}
+
+	dev->port_dir = port_cfg.portDir;
+
+	/* Align the data block size to a cache line.	*/
+	binfo->dataBlockSize = MV_ALIGN_UP(binfo->dataBlockSize,32);
+	data_size = binfo->dataBlockSize * binfo->numTsDesc;
+#ifdef TSU_UNCACHED_DATA_BUFFERS
+	binfo->tsDataBuff =
+		mvOsIoUncachedMalloc(NULL,data_size,(MV_ULONG*)(&binfo->tsDataBuffPhys),
+				     NULL);
+#else
+	binfo->tsDataBuff =
+		mvOsIoCachedMalloc(NULL,data_size,(MV_ULONG*)(&binfo->tsDataBuffPhys),
+				   NULL);
+#endif /* TSU_UNCACHED_DATA_BUFFERS */
+	if(binfo->tsDataBuff == NULL) {
+		result = -ENOMEM;
+		goto fail_init;
+	}
+//	memset(binfo->tsDataBuff,0x88,data_size);
+#ifndef TSU_UNCACHED_DATA_BUFFERS
+	mvOsCacheClear(NULL,(MV_U32*)TSU_DATA_BUFF_HW_2_SW(binfo->tsDataBuff),
+		       data_size);
+#endif /* TSU_UNCACHED_DATA_BUFFERS */
+
+	/* Align tsDataBuff according to the HW limitation.	*/
+	if(binfo->aggrMode == MV_TSU_AGGR_MODE_2) {
+		data_buff_offs = port_cfg.pktSize & (TSU_DMA_ALIGN - 1);
+	}
+	else if((binfo->aggrMode == MV_TSU_AGGR_MODE_1) &&
+		(port_cfg.portDir == TSU_PORT_OUTPUT)) {
+        	data_buff_offs = TSU_DMA_ALIGN - TSU_MODE1_OUT_TMS_SIZE;
+	}
+	else {
+		data_buff_offs = 0;
+	}
+
+	binfo->tsDataBuff = (MV_U32*)((MV_U32)binfo->tsDataBuff + data_buff_offs);
+	binfo->tsDataBuffPhys += data_buff_offs;
+
+	TSU_DPRINT(TSU_DBG_OPEN, ("\tTSU Data buffer allocated successfully "
+				  "(%p, %d).\n",binfo->tsDataBuff, data_size));
+	/* Allocate memory for done queue.	*/
+	stat_size = TSU_DONE_STATUS_ENTRY_SIZE * binfo->numDoneQEntry;
+	dev->stat_buff_size = stat_size;
+	binfo->tsDoneBuff =
+		mvOsIoUncachedMalloc(NULL,stat_size,
+				     (MV_ULONG*)(&binfo->tsDoneBuffPhys),NULL);
+	if(binfo->tsDoneBuff == NULL) {
+		result = -ENOMEM;
+		goto fail_init;
+	}
+
+	TSU_DPRINT(TSU_DBG_OPEN, ("\tTSU Done buffer allocated successfully"
+				  "(%p, %d).\n",binfo->tsDoneBuff, stat_size));
+
+	status = mvTsuBuffersInit(dev->port,&dev->buff_info);
+	if(status != MV_OK) {
+		TSU_DPRINT(TSU_DBG_OPEN, ("\tmvTsuBuffersInit() Failed (%d).",
+					  status));
+		result = -EINVAL;
+		goto fail_init;
+	}
+	TSU_DPRINT(TSU_DBG_OPEN, ("\tHAL Buffers initialized successfully.\n"));
+
+	status = mvTsuPortSignalCfgSet(dev->port,&(dev->signal_cfg),dev->serial_sig_flags);
+	if(status != MV_OK) {
+		TSU_DPRINT(TSU_DBG_OPEN, ("\tmvTsuPortSignalCfgSet() Failed (%d).",
+					status));
+		result = -EINVAL;
+		goto fail_init;
+	}
+	TSU_DPRINT(TSU_DBG_OPEN, ("\tPort signal parameters set successfully.\n"));
+
+	status = mvTsuRxSyncDetectionSet(dev->port,dev->sync_detect,dev->sync_loss);
+	if(status != MV_OK) {
+		TSU_DPRINT(TSU_DBG_OPEN, ("\tmvTsuRxSyncDetectionSet() Failed (%d).",
+					status));
+		result = -EINVAL;
+		goto fail_init;
+	}
+	TSU_DPRINT(TSU_DBG_OPEN, ("\tRx sync parameters set successfully.\n"));
+
+	mvtsu_rd_wr_timeout_calc(dev);
+
+	if(dev->port_dir == TSU_PORT_OUTPUT) {
+		mvtsu_tx_timestamp_calc(dev);
+	}
+
+	/* Register IRQ.	*/
+	MV_REG_WRITE(MV_TSU_INTERRUPT_MASK_REG(dev->port),TSU_DFLT_INT_MASK);
+	if(request_irq(IRQ_TS_INT(dev->port),mvtsu_interrupt_handler,
+		       IRQF_DISABLED | IRQF_SAMPLE_RANDOM,"tsu",dev)) {
+		printk(KERN_ERR "Cannot assign irq%d to TSU port%d\n",
+		       IRQ_TS_INT(dev->port), dev->port);
+		goto fail_init;
+	}
+	TSU_DPRINT(TSU_DBG_OPEN, ("\tTSU interrupt registered at IRQ %d.\n",
+				  IRQ_TS_INT(dev->port)));
+
+	if(port_cfg.portDir == TSU_PORT_INPUT) {
+		/* Enable Rx timestamp.	*/
+		mvTsuRxTimestampCntEn(dev->port,MV_TRUE);
+		mvTsuDmaWatermarkSet(dev->port,0x8);
+	}
+
+	/* Make the private_data hold the pointer to the device data.	*/
+	filp->private_data = dev;
+
+	TSU_LEAVE(TSU_DBG_OPEN, "mvtsu_open");
+	return 0;
+
+fail_init:
+	if(binfo != NULL) {
+		if(binfo->tsDataBuff != NULL)
+#ifdef TSU_UNCACHED_DATA_BUFFERS
+			mvOsIoUncachedFree(
+				NULL,data_size,
+				TSU_DATA_BUFF_HW_2_SW(binfo->tsDataBuffPhys),
+				(MV_U32*)TSU_DATA_BUFF_HW_2_SW(binfo->tsDataBuff),0);
+#else
+		mvOsIoCachedFree(
+			NULL,data_size,
+			TSU_DATA_BUFF_HW_2_SW(binfo->tsDataBuffPhys),
+			(MV_U32*)TSU_DATA_BUFF_HW_2_SW(binfo->tsDataBuff),0);
+#endif /* TSU_UNCACHED_DATA_BUFFERS */
+		if(binfo->tsDoneBuff != NULL)
+			mvOsIoUncachedFree(NULL,stat_size,binfo->tsDoneBuffPhys,
+					   binfo->tsDoneBuff,0);
+		binfo->tsDataBuff = NULL;
+		binfo->tsDoneBuff = NULL;
+	}
+	TSU_LEAVE(TSU_DBG_OPEN, "mvtsu_open");
+	return result;
+}
+
+
+int mvtsu_release (struct inode *inode, struct file *filp)
+{
+	struct mvtsu_dev *dev = (struct mvtsu_dev*)filp->private_data;
+	MV_TSU_BUFF_INFO *binfo;
+	int size;
+
+	TSU_ENTER(TSU_DBG_RELEASE, "mvtsu_release");
+
+	free_irq(IRQ_TS_INT(dev->port),dev);
+
+	if(dev->port_dir == TSU_PORT_INPUT) {
+		/* Stop Rx timestamp.	*/
+		mvTsuRxTimestampCntEn(dev->port,MV_FALSE);
+	}
+
+	/* Shutdown the port.		*/
+	mvTsuPortShutdown(dev->port);
+
+	/* Clear interrupt mask.	*/
+	MV_REG_WRITE(MV_TSU_INTERRUPT_MASK_REG(dev->port),0);
+
+	/* Free previously allocated buffers.	*/
+	binfo = &dev->buff_info;
+	if(binfo->tsDataBuff != NULL) {
+		size = binfo->dataBlockSize * binfo->numTsDesc;
+#ifdef TSU_UNCACHED_DATA_BUFFERS
+		mvOsIoUncachedFree(NULL,size,
+				   TSU_DATA_BUFF_HW_2_SW(binfo->tsDataBuffPhys),
+				   (MV_U32*)TSU_DATA_BUFF_HW_2_SW(binfo->tsDataBuff),0);
+#else
+		mvOsIoCachedFree(NULL,size,
+				 TSU_DATA_BUFF_HW_2_SW(binfo->tsDataBuffPhys),
+				 (MV_U32*)TSU_DATA_BUFF_HW_2_SW(binfo->tsDataBuff),0);
+#endif /* TSU_UNCACHED_DATA_BUFFERS */
+	}
+	if(binfo->tsDoneBuff != NULL) {
+		mvOsIoUncachedFree(NULL,dev->stat_buff_size,binfo->tsDoneBuffPhys,
+				   binfo->tsDoneBuff,0);
+	}
+	binfo->tsDataBuff = NULL;
+	binfo->tsDoneBuff = NULL;
+
+	mvtsu_set_defaults(dev);
+
+	TSU_LEAVE(TSU_DBG_RELEASE, "mvtsu_release");
+	return 0;
+}
+
+
+/*
+ * Helper function for retrying read buffer requests.
+ * Assume that the device spinlock is held.
+ */
+static int mvtsu_next_rx_buff_get(struct file *filp, u32 **data_buff,
+				  u32 **stat_buff, u32 *buff_handle,
+				  unsigned long *flags)
+{
+	struct mvtsu_dev *dev = (struct mvtsu_dev*)filp->private_data;
+	int timeout = 0;
+	int cnt = 0;
+	MV_STATUS status;
+
+//	timeout = (dev->rd_wr_timeout == 0) ? 2000 : (dev->rd_wr_timeout + 100);
+	timeout = dev->rd_wr_timeout;
+
+	while(cnt < timeout) {
+		status = mvTsuRxNextBuffGet(dev->port,data_buff,stat_buff,
+					    buff_handle);
+		if(status != MV_OK) {
+			if(status != MV_NO_MORE)
+				return -EIO;
+		}
+		else {
+#if !defined(TSU_UNCACHED_DATA_BUFFERS) && defined(CONFIG_MV_SP_I_FTCH_DB_INV)
+			dma_unmap_single(NULL, mvOsIoVirtToPhy(NULL, *data_buff) ,
+					dev->buff_info.dataBlockSize, DMA_FROM_DEVICE);
+#endif
+			break;
+		}
+		if (filp->f_flags & O_NONBLOCK)
+			break;
+
+		spin_unlock_irqrestore(&(dev->lock), *flags);
+		if(dev->rd_wr_timeout)
+			msleep_interruptible(1);
+		else
+			udelay(1000);
+
+		cnt += 1;
+		spin_lock_irqsave(&(dev->lock), *flags);
+	}
+	if(cnt >= timeout) {
+		printk(KERN_INFO "TSU: Read timeout.\n");
+		return -EAGAIN;
+	}
+	return 0;
+}
+
+
+/*
+ * Helper function for copying timestamp info to user buffer.
+ */
+inline static void mvtsu_rx_tmsstmp_copy(struct mvtsu_dev *dev, u32 *stat_buff,
+					 char *out_buff, int *buf_offs,
+					 int *buf_size)
+{
+	MV_U32 size;
+	MV_U32 all;
+	MV_U32 avail;
+
+	all = TSU_DONE_STATUS_ENTRY_SIZE * dev->buff_info.aggrNumPackets;
+	/* Calculate avilable data at end of buffer.	*/
+	avail = dev->stat_buff_size -
+		((MV_U32)stat_buff - (MV_U32)dev->buff_info.tsDoneBuff);
+	if(avail < all)
+		size = avail;
+	else
+		size = all;
+
+	if(copy_to_user(out_buff,stat_buff,size))
+		panic("TSU: copy_to_user failed.");
+	avail = all - size;
+	if(avail != 0) {
+		if(copy_to_user(out_buff + size,dev->buff_info.tsDoneBuff,avail))
+			panic("TSU: copy_to_user failed.");
+	}
+
+	*buf_offs += all;
+	*buf_size -= all;
+        return;
+}
+
+/*
+ * TSU data read
+ */
+ssize_t mvtsu_read(struct file *filp, char __user *buf, size_t count,
+		   loff_t *f_pos)
+{
+	struct mvtsu_dev *dev = filp->private_data;
+	MV_U8 port = dev->port;
+	MV_U8 *data_buff;
+	MV_U32 size;
+	int status;
+	int buf_offs = 0;
+	unsigned long flags;
+
+	TSU_ENTER(TSU_DBG_READ, "mvtsu_read");
+	spin_lock_irqsave(&(dev->lock), flags);
+
+	if((dev->buff_info.aggrMode != MV_TSU_AGGR_MODE_2) &&
+	   (count < (TSU_DONE_STATUS_ENTRY_SIZE * dev->buff_info.aggrNumPackets))) {
+		printk(KERN_ERR "TSU: Read operations must be at least of size "
+				"%d",
+		       TSU_DONE_STATUS_ENTRY_SIZE * dev->buff_info.aggrNumPackets);
+		status = -EINVAL;
+		goto no_data;
+	}
+
+	if(dev->data_buff == NULL) {
+		TSU_DPRINT(TSU_DBG_READ, ("\tGet new data buffer..."));
+		status = mvtsu_next_rx_buff_get(filp,(MV_U32**)(&dev->data_buff),
+						&dev->stat_buff,
+						&dev->buff_handle,&flags);
+		if(status) {
+			TSU_DPRINT(TSU_DBG_READ, ("FAILED.\n"));
+			goto no_data;
+		}
+
+		TSU_DPRINT(TSU_DBG_READ, ("OK.\n"));
+		if(dev->buff_info.aggrMode != MV_TSU_AGGR_MODE_2)
+			/* Copy the timestamp before the packet's data.	*/
+			mvtsu_rx_tmsstmp_copy(dev,dev->stat_buff,buf,&buf_offs,
+					      &count);
+		dev->data_offs = 0;
+	}
+	data_buff = dev->data_buff;
+	size = dev->rd_rw_data_size - dev->data_offs;
+
+	if(dev->read_all_at_once && (size > count)) {
+		status = -EINVAL;
+		printk(KERN_INFO "TSU: Read buffer too small, "
+				 "(Read All At Once mode)");
+		goto no_data;
+	}
+
+        /* Valid data in data_buff.	*/
+	if(size < count)
+		count = size;
+	TSU_DPRINT(TSU_DBG_READ, ("\tCopy %d Bytes (%d, %p, %d).\n", count,
+				  buf_offs,data_buff,dev->data_offs));
+	if(copy_to_user(buf + buf_offs,data_buff + dev->data_offs,count))
+		panic("TSU: copy_to_user failed.");
+
+	dev->data_offs += count;
+	*f_pos += (count + buf_offs);
+
+	if(dev->data_offs == dev->valid_data_size) {
+		TSU_DPRINT(TSU_DBG_READ, ("\tFree RX buffer.\n"));
+//		memset(dev->data_buff,0x88,dev->buff_info.dataBlockSize);
+#ifndef TSU_UNCACHED_DATA_BUFFERS
+		mvOsCacheClear(NULL,
+			       (MV_U32*)TSU_DATA_BUFF_HW_2_SW(dev->data_buff),
+			       dev->buff_info.dataBlockSize);
+#endif /* TSU_UNCACHED_DATA_BUFFERS */
+		status = mvTsuRxBuffFree(port,(MV_U32*)dev->data_buff,
+					 dev->stat_buff,dev->buff_handle);
+		if(status != MV_OK) {
+			panic("TSU: Error in state machine, mvTsuRxBuffFree() "
+			      "Failed.");
+		}
+		dev->data_buff = NULL;
+		dev->stat_buff = NULL;
+	}
+
+	spin_unlock_irqrestore(&(dev->lock), flags);
+        TSU_LEAVE(TSU_DBG_READ, "mvtsu_read");
+	return count + buf_offs;
+
+no_data:
+	spin_unlock_irqrestore(&(dev->lock), flags);
+	printk(KERN_DEBUG "TSU: Failed to read.\n");
+        TSU_LEAVE(TSU_DBG_READ, "mvtsu_read");
+	return status;
+}
+
+
+/*
+ * Helper function for retrying write buffer requests.
+  * Assume that the device spinlock is held.
+ */
+static int mvtsu_next_tx_buff_get(struct file *filp, u32 **data_buff,
+				  u32 *buff_handle, unsigned long *flags)
+{
+	struct mvtsu_dev *dev = (struct mvtsu_dev*)filp->private_data;
+	int timeout = 0;
+	int cnt = 0;
+	MV_STATUS status;
+
+//	timeout = (dev->rd_wr_timeout == 0) ? 2000000 : (dev->rd_wr_timeout + 100);
+	timeout = dev->rd_wr_timeout;
+
+	while(cnt < timeout) {
+		status = mvTsuTxNextBuffGet(dev->port,data_buff,buff_handle);
+		if(status != MV_OK) {
+			if(status != MV_NO_MORE)
+				return -EIO;
+		}
+		else {
+			break;
+		}
+
+		if (filp->f_flags & O_NONBLOCK)
+			break;
+		spin_unlock_irqrestore(&(dev->lock), *flags);
+		if(dev->rd_wr_timeout)
+			msleep_interruptible(10);
+		else
+			udelay(1000);
+
+		cnt += 10;
+		spin_lock_irqsave(&(dev->lock), *flags);
+	}
+	if(cnt >= timeout) {
+		printk(KERN_INFO "TSU: Write timeout.\n");
+		return -EAGAIN;
+	}
+	return 0;
+}
+
+
+/*
+ * TSU data write
+ */
+ssize_t mvtsu_write (struct file *filp, const char __user *buf, size_t count,
+		     loff_t *f_pos)
+{
+	struct mvtsu_dev *dev = filp->private_data;
+	MV_U8 port = dev->port;
+	int status;
+	int buf_offs = 0;
+	MV_BOOL tsErr = MV_FALSE;
+	MV_U32 tms = 0;
+	MV_U32 data;
+	unsigned long flags;
+	size_t orig_cnt = count;
+
+	TSU_ENTER(TSU_DBG_WRITE, "mvtsu_write");
+	spin_lock_irqsave(&(dev->lock), flags);
+
+	if(count < dev->rd_rw_data_size) {
+		printk(KERN_ERR "TSU: Write operations must hold at least a "
+				"single data block of data(%d , %d)",
+		       dev->rd_rw_data_size, count);
+		status = -EINVAL;
+		goto no_tx;
+	}
+
+	TSU_DPRINT(TSU_DBG_WRITE, ("\tGet new data buffer..."));
+	status = mvtsu_next_tx_buff_get(filp,(MV_U32**)(&dev->data_buff),
+					&dev->buff_handle,&flags);
+	if(status) {
+		TSU_DPRINT(TSU_DBG_WRITE, ("FAILED.\n"));
+		goto no_tx;
+	}
+
+	TSU_DPRINT(TSU_DBG_WRITE, ("OK.\n"));
+
+	if(dev->buff_info.aggrMode == MV_TSU_AGGR_MODE_DISABLED) {
+		if(dev->auto_tms_mode) {
+			tms = dev->tx_tms_val;
+			dev->tx_tms_val += dev->tx_tms_gap;
+		} else {
+			TSU_DPRINT(TSU_DBG_WRITE, ("\tGet timestamp info.\n"));
+			/* Copy the timestamp from the beginning of data buffer. */
+			if(copy_from_user(&data,buf,TSU_DONE_STATUS_ENTRY_SIZE))
+				panic("TSU: copy_to_user failed.");
+
+			tsErr = TSU_STATUS_ERROR_GET(data);
+			tms = TSU_STATUS_TMSSTMP_GET(data);
+			TSU_DPRINT(TSU_DBG_WRITE, ("\tTimestamp = %d.\n",tms));
+		}
+		buf_offs = TSU_DONE_STATUS_ENTRY_SIZE;
+		count -= TSU_DONE_STATUS_ENTRY_SIZE;
+	}
+
+	/* Valid data in data_buff.	*/
+	if(dev->valid_data_size < count)
+		count = dev->valid_data_size;
+
+	TSU_DPRINT(TSU_DBG_WRITE, ("\tCopy %d Bytes.\n", count));
+	if(copy_from_user(dev->data_buff, buf + buf_offs, count))
+		panic("TSU Write: copy_to_user failed.");
+	*f_pos += orig_cnt;
+
+	TSU_DPRINT(TSU_DBG_WRITE, ("\tFree TX buffer.\n"));
+#ifndef TSU_UNCACHED_DATA_BUFFERS
+	mvOsCacheFlush(NULL,(MV_U32*)TSU_DATA_BUFF_HW_2_SW(dev->data_buff),
+		       dev->buff_info.dataBlockSize);
+#endif /* TSU_UNCACHED_DATA_BUFFERS */
+
+	status = mvTsuTxBuffPut(port,(MV_U32*)dev->data_buff,tms,tsErr,
+				dev->buff_handle);
+	if(status != MV_OK)
+		panic("TSU: Error in state machine, mvTsuTxBuffPut() Failed.");
+
+	spin_unlock_irqrestore(&(dev->lock), flags);
+	TSU_LEAVE(TSU_DBG_WRITE, "mvtsu_write");
+	return orig_cnt;
+
+no_tx:
+	spin_unlock_irqrestore(&(dev->lock), flags);
+	printk(KERN_DEBUG "TSU: Failed to write.\n");
+	TSU_LEAVE(TSU_DBG_WRITE, "mvtsu_write");
+	return status;
+}
+
+/*
+ * TSU ioctl()
+ */
+int mvtsu_ioctl (struct inode *inode, struct file *filp, unsigned int cmd,
+		 unsigned long arg)
+{
+	struct mvtsu_dev *dev = filp->private_data;
+	int ret = 0;
+	u32 val;
+	unsigned long flags;
+	MV_STATUS status = MV_OK;
+	struct tsu_tmstmp_info tms_info;
+	struct tsu_buff_info buf_info;
+
+	TSU_ENTER(TSU_DBG_IOCTL, "mvtsu_ioctl");
+	TSU_DPRINT(TSU_DBG_IOCTL, ("\targ = 0x%08x.\n",(unsigned int)arg));
+
+	spin_lock_irqsave(&(dev->lock), flags);
+
+	switch(cmd) {
+	case MVTSU_IOCFREQSET:
+		get_user(val,(u32 __user *)arg);
+		TSU_DPRINT(TSU_DBG_IOCTL, ("\tFrequency set to %d.\n",val));
+		if(dev->port_dir == TSU_PORT_OUTPUT)
+			status = mvTsuTxClockFreqSet(dev->port,val,MV_FALSE);
+		if(status == MV_OK) {
+			dev->clockrate = val;
+			mvtsu_rd_wr_timeout_calc(dev);
+			mvtsu_tx_timestamp_calc(dev);
+		} else {
+			ret = -EINVAL;
+		}
+		break;
+	case MVTSU_IOCTXTMSSET:
+		if(copy_from_user(&tms_info,(struct tsu_tmstmp_info*)arg,
+				  sizeof(tms_info)))
+			panic("TSU IOCTL: copy_from_user failed.\n");
+		TSU_DPRINT(TSU_DBG_IOCTL, ("\tTx timestamp set to (%d,%d).\n",
+					   tms_info.timestamp,
+					   tms_info.enable_tms));
+		status = mvTsuTxInitTimeStampSet(
+			dev->port, (tms_info.enable_tms ? MV_TRUE : MV_FALSE),
+			tms_info.timestamp);
+		if(status != MV_OK)
+			ret = -EINVAL;
+		break;
+	case MVTSU_IOCTXDONE:
+		TSU_DPRINT(TSU_DBG_IOCTL, ("\tTx Done.\n"));
+		if(mvTsuTxDone(dev->port) != MV_OK)
+			ret = -EINVAL;
+		break;
+	case MVTSU_IOCRDPKTATONCE:
+		TSU_DPRINT(TSU_DBG_IOCTL, ("\tRx Read Packet At Once.\n"));
+		get_user(val,(u32 __user *)arg);
+                dev->read_all_at_once = val;
+		break;
+	case MVTSU_IOCBUFFPARAMGET:
+		TSU_DPRINT(TSU_DBG_IOCTL, ("\tGet Buffer Params.\n"));
+		switch(dev->buff_info.aggrMode) {
+		case MV_TSU_AGGR_MODE_DISABLED:
+			buf_info.aggr_mode = aggrModeDisabled;
+			break;
+		case MV_TSU_AGGR_MODE_1:
+			buf_info.aggr_mode = aggrMode1;
+			break;
+		case MV_TSU_AGGR_MODE_2:
+			buf_info.aggr_mode = aggrMode2;
+			break;
+		default:
+			ret = -EINVAL;
+		}
+		buf_info.aggr_mode2_tmstmp_off =
+			dev->buff_info.aggrMode2TmstmpOff;
+		buf_info.aggr_num_packets =
+			dev->buff_info.aggrNumPackets;
+		buf_info.num_done_q_entries =
+			dev->buff_info.numDoneQEntry;
+		buf_info.num_ts_desc =
+			dev->buff_info.numTsDesc;
+		buf_info.pkt_size = cfg_pkt_size;
+
+		if(copy_to_user((struct tsu_buff_info*)arg,&buf_info,
+				sizeof(buf_info)))
+			panic("TSU IOCTL: copy_to_user failed.\n");
+		break;
+	case MVTSU_IOCGETSTAT:
+		TSU_DPRINT(TSU_DBG_IOCTL, ("\tGet Statistics.\n"));
+		if(copy_to_user((struct tsu_stat*)arg,&dev->int_stat,
+				sizeof(struct tsu_stat)))
+			panic("TSU IOCTL: copy_to_user failed.\n");
+		break;
+	case MVTSU_IOCCLEARSTAT:
+		TSU_DPRINT(TSU_DBG_IOCTL, ("\tClear Statistics.\n"));
+		memset(&(dev->int_stat),0,sizeof(dev->int_stat));
+		break;
+	case MVTSU_IOCAUTOTMS:
+		TSU_DPRINT(TSU_DBG_IOCTL, ("\tAuto timestamp mode.\n"));
+		get_user(val,(u32 __user *)arg);
+		dev->auto_tms_mode = val;
+		break;
+	default:
+		TSU_DPRINT(TSU_DBG_IOCTL, ("\tInvalid request.\n"));
+		ret = -EINVAL;
+	}
+
+	spin_unlock_irqrestore(&(dev->lock), flags);
+
+	TSU_LEAVE(TSU_DBG_IOCTL, "mvtsu_ioctl");
+	return ret;
+}
+
+
+#ifdef CONFIG_MV_TSU_PROC
+
+/*
+	Parameter		Port	Value		Possible Values
+
+	sync_detect		x	x		int
+	sync_loss		x	x		int
+	aggr_mode		x	x		(mode1 / mode2 / dis)
+	aggr_mode2_off		x	x		int
+	aggr_num_pckts		x	x		int
+	num_desc		x	x		int
+	num_done_queue		x	x		int
+	sync_sig		x	x		(dis / high / low)
+	valid_sig		x	x		(dis / high / low)
+	error_sig		x	x		(dis / high / low)
+	data_edge		x	x		(fall / rise)
+	data_order		x	x		(msb / lsb)
+	sync_act		x	x		(1 / 8)
+	clk_mode		x	x		(cont / gap)
+*/
+
+#define TSU_AGGR_MODE_2_STR(mode)					\
+	((mode == MV_TSU_AGGR_MODE_DISABLED) ? "dis" : 			\
+	 ((mode == MV_TSU_AGGR_MODE_1) ? "mode1" : "mode2"))
+
+#define TSU_SIGNAL_MODE_2_STR(mode)					\
+	((mode == TSU_SIGNAL_DIS) ? "dis" : 				\
+	 ((mode == TSU_SIGNAL_EN_ACT_LOW) ? "low" : "high"))
+
+#define TSU_STR_2_SIGNAL_MODE(mode,str)					\
+	{								\
+		if(!strncmp((str),"dis",3))				\
+			mode = TSU_SIGNAL_DIS;				\
+		else if(!strncmp((str),"low",3))			\
+			mode = TSU_SIGNAL_EN_ACT_LOW;			\
+		else if(!strncmp((str),"high",4))			\
+			mode = TSU_SIGNAL_EN_ACT_HIGH;			\
+		else							\
+			mode = TSU_SIGNAL_KEEP_DEF;			\
+	}
+
+
+
+int mvtsu_proc_write(struct file *file, const char *buffer,unsigned long count,
+		     void *data)
+{
+	MV_TSU_SIGNAL_CONFIG	signal_cfg;
+	MV_U32 flags;
+	MV_U8 sync_detect;
+	MV_U8 sync_loss;
+	MV_BOOL write_signal = MV_FALSE;
+        MV_BOOL write_sync = MV_FALSE;
+	MV_U8 port;
+	int len = 0;
+	int tmp;
+	char *str;
+	struct mvtsu_dev *dev;
+
+	TSU_ENTER(TSU_DBG_PROC, "mvtsu_proc_write");
+
+	len = sscanf(buffer,"%d ",&tmp);
+
+	if(tmp >= MV_TSU_NUM_PORTS)
+		return count;
+	port = (MV_U8)tmp;
+        len++; /* Skip over the space.	*/
+
+	signal_cfg.tsDataEdge = TSU_SIGNAL_EDGE_FALL;
+	signal_cfg.tsError = TSU_SIGNAL_KEEP_DEF;
+	signal_cfg.tsSync = TSU_SIGNAL_KEEP_DEF;
+	signal_cfg.tsValid = TSU_SIGNAL_KEEP_DEF;
+	flags = 0;
+
+	if(mvTsuRxSyncDetectionGet(port,&sync_detect,&sync_loss) != MV_OK)
+		return count;
+	dev = &mvtsu_devs[port];
+
+	TSU_DPRINT(TSU_DBG_PROC, ("\tbuffer = %s.\n",buffer+len));
+	str = "sync_detect ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		len += sscanf(buffer+len,"%d",&tmp);
+		sync_detect = (MV_U8)tmp;
+		TSU_DPRINT(TSU_DBG_PROC, ("\tsync_detect = %d.\n",sync_detect));
+		write_sync = MV_TRUE;
+		goto done;
+	}
+	str = "sync_loss ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		len += sscanf(buffer+len,"%d",&tmp);
+		sync_loss = (MV_U8)tmp;
+		TSU_DPRINT(TSU_DBG_PROC, ("\tsync_loss = %d.\n",sync_loss));
+		write_sync = MV_TRUE;
+		goto done;
+	}
+
+	str = "aggr_mode ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		str = "dis";
+		if(!strncmp(buffer+len, str,strlen(str))) {
+			len += strlen(str);
+			dev->buff_info.aggrMode = MV_TSU_AGGR_MODE_DISABLED;
+			goto done;
+		}
+		str = "mode1";
+		if(!strncmp(buffer+len, str,strlen(str))) {
+			len += strlen(str);
+			dev->buff_info.aggrMode = MV_TSU_AGGR_MODE_1;
+			goto done;
+		}
+		str = "mode2";
+		if(!strncmp(buffer+len, str,strlen(str))) {
+			len += strlen(str);
+			dev->buff_info.aggrMode = MV_TSU_AGGR_MODE_2;
+			goto done;
+		}
+		goto done;
+	}
+
+        str = "aggr_mode2_off ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		len += sscanf(buffer+len,"%d",&tmp);
+		dev->buff_info.aggrMode2TmstmpOff = tmp;
+		goto done;
+	}
+
+	str = "aggr_num_pckts ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		len += sscanf(buffer+len,"%d",&tmp);
+		dev->buff_info.aggrNumPackets = tmp;
+		goto done;
+	}
+
+	str = "num_desc ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		len += sscanf(buffer+len,"%d",&tmp);
+		dev->buff_info.numTsDesc = tmp;
+		goto done;
+	}
+
+	str = "num_done_queue ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		len += sscanf(buffer+len,"%d",&tmp);
+		dev->buff_info.numDoneQEntry = tmp;
+		goto done;
+	}
+
+	str = "sync_sig ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		TSU_STR_2_SIGNAL_MODE(signal_cfg.tsSync,buffer+len);
+                write_signal = MV_TRUE;
+		goto done;
+	}
+
+	str = "valid_sig ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		TSU_STR_2_SIGNAL_MODE(signal_cfg.tsValid,buffer+len);
+		write_signal = MV_TRUE;
+		goto done;
+	}
+
+	str = "error_sig ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		TSU_STR_2_SIGNAL_MODE(signal_cfg.tsError,buffer+len);
+		write_signal = MV_TRUE;
+		goto done;
+	}
+
+	str = "data_edge ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		str = "fall";
+		if(!strncmp(buffer+len, str,strlen(str))) {
+			len += strlen(str);
+			signal_cfg.tsDataEdge = TSU_SIGNAL_EDGE_FALL;
+			write_signal = MV_TRUE;
+			goto done;
+		}
+		str = "rise";
+		if(!strncmp(buffer+len, str,strlen(str))) {
+			len += strlen(str);
+			signal_cfg.tsDataEdge = TSU_SIGNAL_EDGE_RISE;
+			write_signal = MV_TRUE;
+			goto done;
+		}
+		goto done;
+	}
+
+	str = "data_order ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		str = "msb";
+		if(!strncmp(buffer+len, str,strlen(str))) {
+			len += strlen(str);
+			flags |= MV_TSU_SER_DATA_ORDER_MSB;
+			write_signal = MV_TRUE;
+			goto done;
+		}
+		str = "lsb";
+		if(!strncmp(buffer+len, str,strlen(str))) {
+			len += strlen(str);
+			flags |= MV_TSU_SER_DATA_ORDER_LSB;
+			write_signal = MV_TRUE;
+			goto done;
+		}
+		goto done;
+	}
+
+	str = "sync_act ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		len += sscanf(buffer+len,"%d",&tmp);
+		write_signal = MV_TRUE;
+		if(tmp == 1)
+			flags |= MV_TSU_SER_SYNC_ACT_1_BIT;
+		else if(tmp == 8)
+			flags |= MV_TSU_SER_SYNC_ACT_8_BIT;
+		else
+			write_signal = MV_FALSE;
+		goto done;
+	}
+
+	str = "clk_mode ";
+	if(!strncmp(buffer+len, str,strlen(str))) {
+		len += strlen(str);
+		str = "cont";
+		if(!strncmp(buffer+len, str,strlen(str))) {
+			len += strlen(str);
+			flags |= MV_TSU_SER_TX_CLK_MODE_CONT;
+			write_signal = MV_TRUE;
+			goto done;
+		}
+		str = "gap";
+		if(!strncmp(buffer+len, str,strlen(str))) {
+			len += strlen(str);
+			flags |= MV_TSU_SER_TX_CLK_MODE_GAPPED;
+			write_signal = MV_TRUE;
+			goto done;
+		}
+		goto done;
+	}
+
+done:
+	if(write_signal == MV_TRUE){
+		mvTsuPortSignalCfgSet(port,&signal_cfg,flags);
+		dev->serial_sig_flags = flags;
+		dev->signal_cfg = signal_cfg;
+	}
+	if(write_sync == MV_TRUE){
+		mvTsuRxSyncDetectionSet(port,sync_detect,sync_loss);
+		dev->sync_loss = sync_loss;
+		dev->sync_detect = sync_detect;
+	}
+
+	TSU_LEAVE(TSU_DBG_PROC, "mvtsu_proc_write");
+	return count;
+}
+
+
+int mvtsu_proc_read_port(int port, char *buf)
+{
+	MV_U8	sync_detect, sync_loss;
+	MV_TSU_SIGNAL_CONFIG signal_cfg;
+	MV_U32 flags;
+	int len=0;
+
+	if(mvTsuRxSyncDetectionGet(port,&sync_detect,&sync_loss) != MV_OK)
+		return -1;
+	len += sprintf(buf,"\tsync_detect\t\t%d\t%d\tint\n",port,sync_detect);
+	len += sprintf(buf+len,"\tsync_loss\t\t%d\t%d\tint\n",port,sync_loss);
+
+	len += sprintf(buf+len,"\taggr_mode\t\t%d\t%s\t(mode1 / mode2 / dis)\n",
+		       port,
+		       TSU_AGGR_MODE_2_STR(mvtsu_devs[port].buff_info.aggrMode));
+	len += sprintf(buf+len,"\taggr_mode2_off\t\t%d\t%d\tint\n",
+		       port,mvtsu_devs[port].buff_info.aggrMode2TmstmpOff);
+	len += sprintf(buf+len,"\taggr_num_pckts\t\t%d\t%d\tint\n",
+		       port,mvtsu_devs[port].buff_info.aggrNumPackets);
+	len += sprintf(buf+len,"\tnum_desc\t\t%d\t%d\tint\n",
+		       port,mvtsu_devs[port].buff_info.numTsDesc);
+	len += sprintf(buf+len,"\tnum_done_queue\t\t%d\t%d\tint\n",
+		       port,mvtsu_devs[port].buff_info.numDoneQEntry);
+
+	if(mvTsuPortSignalCfgGet(port,&signal_cfg,&flags) != MV_OK)
+		return -1;
+	len += sprintf(buf+len,"\tsync_sig\t\t%d\t%s\t(dis / high / low)\n",
+		       port,TSU_SIGNAL_MODE_2_STR(signal_cfg.tsSync));
+	len += sprintf(buf+len,"\tvalid_sig\t\t%d\t%s\t(dis / high / low)\n",
+		       port,TSU_SIGNAL_MODE_2_STR(signal_cfg.tsValid));
+	len += sprintf(buf+len,"\terror_sig\t\t%d\t%s\t(dis / high / low)\n",
+		       port,TSU_SIGNAL_MODE_2_STR(signal_cfg.tsError));
+	len += sprintf(buf+len,"\tdata_edge\t\t%d\t%s\t(fall / rise)\n",
+		       port,(signal_cfg.tsDataEdge == TSU_SIGNAL_EDGE_FALL) ?
+		       "fall" : "rise");
+
+	if(cfg_tsu_mode == TSU_MODE_SERIAL) {
+		len += sprintf(buf+len,"\tdata_order\t\t%d\t%s\t(msb / lsb)\n",
+			       port,(flags & MV_TSU_SER_DATA_ORDER_MSB) ? "msb" : "lsb");
+		len += sprintf(buf+len,"\tsync_act\t\t%d\t%d\t(1 / 8)\n",
+			       port,(flags & MV_TSU_SER_SYNC_ACT_1_BIT) ? 1 : 8);
+		len += sprintf(buf+len,"\tclk_mode\t\t%d\t%s\t(cont / gap)\n",
+			       port,
+			       (flags & MV_TSU_SER_TX_CLK_MODE_CONT) ? "cont" : "gap");
+	}
+	return len;
+}
+
+
+int mvtsu_proc_read(char* page, char** start, off_t off, int count,int* eof,
+		    void* data)
+{
+	int len = 0;
+	int i;
+	int res;
+
+	if(off > 0)
+		return 0;
+	len += sprintf(page,"\tParameter\t\tPort\tValue\tPossible Values\n\n");
+
+	for(i = 0; i < MV_TSU_NUM_PORTS; i++) {
+                res = mvtsu_proc_read_port(i,page+len);
+		if(res < 0) {
+			len = -1;
+			break;
+		}
+		len += res;
+	}
+	if(len != -1)
+		len += sprintf(page+len,"\nConfig String: <port> <attr> <val>\n");
+
+	return len;
+}
+
+
+/*
+ * Create TSU proc entry.
+ */
+static int mvtsu_proc_init(void)
+{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26)
+	mvtsu_proc_entry = create_proc_entry("tsu", 0666, &proc_root);
+	mvtsu_proc_entry->owner = THIS_MODULE;
+#else
+	mvtsu_proc_entry = create_proc_entry("tsu", 0666, NULL);
+#endif
+	mvtsu_proc_entry->read_proc = mvtsu_proc_read;
+	mvtsu_proc_entry->write_proc = mvtsu_proc_write;
+	return 0;
+}
+
+#endif /* CONFIG_MV_TSU_PROC */
+
+
+/*
+ * Parse the TSU command line.
+ * The command line looks as follows:
+ * mv_tsu_config=<interface mode>,<packet size>,<core clock in MHz>
+ * e.g. serial,188,73
+ */
+int mvtsu_cmdline_config(char *s)
+{
+    mvtsu_cmdline = s;
+    return 1;
+}
+
+static int mvtsu_parse_core_clk(char **cmdline)
+{
+	char *str = *cmdline;
+	int num = 0;
+
+	while(*str != '\0') {
+		if(!TSU_IS_DEC_DIGIT(*str))
+			return -1;
+		num = (num * 10) + (*str - '0');
+		str++;
+	}
+
+	switch (num) {
+	case(71):
+		cfg_core_clk = TSU_CORE_CLK_71_MHZ;
+                break;
+	case(83):
+		cfg_core_clk = TSU_CORE_CLK_83_MHZ;
+		break;
+	case(91):
+		cfg_core_clk = TSU_CORE_CLK_91_MHZ;
+		break;
+	case(100):
+		cfg_core_clk = TSU_CORE_CLK_100_MHZ;
+		break;
+	default:
+		return -1;
+	}
+
+	*cmdline = str;
+	return 0;
+}
+
+
+static int mvtsu_parse_pkt_size(char **cmdline)
+{
+	char *str = *cmdline;
+	int num = 0;
+
+	while((*str != '\0') && (*str != ',')) {
+		if(!TSU_IS_DEC_DIGIT(*str))
+			return -1;
+		num = (num * 10) + (*str - '0');
+		str++;
+	}
+	if((*str == ',') && (num != 0)) {
+		cfg_pkt_size = num;
+		*cmdline = str;
+		return 0;
+	}
+	return -1;
+}
+
+
+static int mvtsu_parse_mode(char **cmdline)
+{
+	char *str;
+
+	str = "serial";
+	if(!strncmp(*cmdline,str,strlen(str))) {
+		cfg_tsu_mode = TSU_MODE_SERIAL;
+		*cmdline += strlen(str);
+	} else {
+                str = "parallel";
+		if(!strncmp(*cmdline,str,strlen(str))) {
+			cfg_tsu_mode = TSU_MODE_PARALLEL;
+			*cmdline += strlen(str);
+			return 0;
+		}
+	}
+	return 0;
+}
+
+
+static int mvtsu_parse_cmdline(void)
+{
+	char *cmdline;
+
+	if(mvtsu_cmdline) {
+		TSU_DPRINT(TSU_DBG_INIT, ("TSU command line: %s.\n",mvtsu_cmdline));
+		cmdline = mvtsu_cmdline;
+		if(mvtsu_parse_mode(&cmdline) != 0) {
+			printk(KERN_ERR "TSU: Bad interface mode option in command line, using default.\n");
+			goto set_default;
+		}
+                if(cmdline[0] != ',') {
+			printk(KERN_ERR "TSU: Bad command line format (Expected ',' found %c).\n",
+			       cmdline[0]);
+		}
+		cmdline++;
+		if(mvtsu_parse_pkt_size(&cmdline) != 0) {
+			printk(KERN_ERR "TSU: Bad packet size option in command line, using default.\n");
+			goto set_default;
+		}
+		if(cmdline[0] != ',') {
+			printk(KERN_ERR "TSU: Bad command line format (Expected ',' found %c).\n",
+			       cmdline[0]);
+		}
+		cmdline++;
+		if(mvtsu_parse_core_clk(&cmdline) != 0) {
+			printk(KERN_ERR "TSU: Bad core-clock option in command line "
+					"(Expected 71 / 83 / 91 / 100), using default.\n");
+			goto set_default;
+		}
+		goto success;
+	} else {
+		printk(KERN_INFO "TSU: No command line parameters, using default.\n");
+	}
+
+set_default:
+	cfg_tsu_mode = DEF_TSU_MODE;
+	cfg_core_clk = DEF_TSU_CORE_CLOCK;
+	cfg_pkt_size = CONFIG_MV_TSU_PKT_SIZE;
+success:
+	return 0;
+}
+
+
+struct file_operations mvtsu_fops = {
+	.owner =     THIS_MODULE,
+	.read =	     mvtsu_read,
+	.write =     mvtsu_write,
+	.ioctl =     mvtsu_ioctl,
+	.open =	     mvtsu_open,
+	.release =   mvtsu_release,
+};
+
+/*
+ * Initialize the TSU driver
+ */
+int mvtsu_init(void)
+{
+	int result, i;
+	dev_t dev;
+
+        TSU_ENTER(TSU_DBG_INIT, "mvtsu_init");
+
+	/* Check unit power mode.		*/
+	if(mvCtrlPwrClckGet(TS_UNIT_ID,0) == MV_FALSE) {
+		printk("Warning: TS unit is powered off.\n");
+		TSU_LEAVE(TSU_DBG_INIT, "mvtsu_init");
+		return 0;
+	}
+
+	/* Parse command line parameters.	*/
+	mvtsu_parse_cmdline();
+
+	dev = MKDEV(MV_TSU_MAJOR, 0);
+	result = register_chrdev_region(dev, TSU_NUM_DEVICES, TSU_DEV_NAME);
+
+	if (result < 0) {
+		printk("Failed to register char device (%d,%d)\n",result, TSU_NUM_DEVICES);
+		TSU_LEAVE(TSU_DBG_INIT, "mvtsu_init");
+		return result;
+	}
+
+	/* Perform unit initialization.	*/
+	result = mvSysTsuInit(cfg_core_clk, cfg_tsu_mode ,NULL);
+	if(result != MV_OK) {
+		goto fail_init;
+		result = -EINVAL;
+	}
+	TSU_DPRINT(TSU_DBG_INIT, ("\tTSU unit initialized successfully.\n"));
+
+	/* Create the char device.	*/
+	for (i = 0; i < TSU_NUM_DEVICES; i++) {
+		mvtsu_devs[i].port = i;
+		mvtsu_set_defaults(&mvtsu_devs[i]);
+		cdev_init(&mvtsu_devs[i].cdev, &mvtsu_fops);
+		mvtsu_devs[i].cdev.owner = THIS_MODULE;
+		mvtsu_devs[i].cdev.ops = &mvtsu_fops;
+		dev = MKDEV(MV_TSU_MAJOR, i);
+		result = cdev_add (&mvtsu_devs[i].cdev, dev, 1);
+		if (result) {
+			printk(KERN_ERR "Error %d adding tsu%d", result, i);
+			goto fail_add;
+		}
+		spin_lock_init(&mvtsu_devs[i].lock);
+		TSU_DPRINT(TSU_DBG_INIT, ("\tChar device %d initialized.\n",i));
+	}
+
+#ifdef CONFIG_MV_TSU_PROC
+	TSU_DPRINT(TSU_DBG_INIT, ("\tCreating Proc entry.\n"));
+	mvtsu_proc_init();
+#endif /* CONFIG_MV_TSU_PROC */
+
+	printk("Transport Stream interface registered.\n");
+	printk("  o %s Mode.\n",
+	       (cfg_tsu_mode == TSU_MODE_PARALLEL) ? "Parallel" : "Serial");
+	printk("  o Core-Clock - ");
+	switch (cfg_core_clk) {
+	case (TSU_CORE_CLK_83_MHZ):
+		printk("83");
+		break;
+	case (TSU_CORE_CLK_71_MHZ):
+		printk("71");
+		break;
+	case (TSU_CORE_CLK_91_MHZ):
+		printk("91");
+		break;
+	case (TSU_CORE_CLK_100_MHZ):
+		printk("100");
+		break;
+	}
+	printk(" MHz.\n");
+	printk("  o Packet Size - %d Bytes.\n",cfg_pkt_size);
+	TSU_LEAVE(TSU_DBG_INIT, "mvtsu_init");
+	return 0;
+
+fail_add:
+	while(i > 0) {
+		cdev_del(&mvtsu_devs[i-1].cdev);
+		i--;
+	}
+
+fail_init:
+	dev = MKDEV(MV_TSU_MAJOR, 0);
+	unregister_chrdev_region(dev, TSU_NUM_DEVICES);
+
+	TSU_LEAVE(TSU_DBG_INIT, "mvtsu_init");
+	return result;
+}
+
+
+/*
+ * Cleanup the TSU driver.
+ */
+void mvtsu_cleanup(void)
+{
+	int i;
+
+	TSU_ENTER(TSU_DBG_INIT, "mvtsu_cleanup");
+	for(i = 0; i < TSU_NUM_DEVICES; i++) {
+		cdev_del(&mvtsu_devs[i].cdev);
+	}
+
+	unregister_chrdev_region(mvtsu_device, TSU_NUM_DEVICES);
+
+	mvTsuShutdown();
+
+	TSU_LEAVE(TSU_DBG_INIT, "mvtsu_cleanup");
+}
+
+module_init(mvtsu_init);
+module_exit(mvtsu_cleanup);
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu.h
new file mode 100644
index 0000000..9845a8c
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu.h
@@ -0,0 +1,49 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __MV_TSU_H__
+#define __MV_TSU_H__
+
+
+#define MV_TSU_MAJOR		MV_TS_MAJOR
+
+#define TSU_DFLT_AGGR_MODE 	MV_TSU_AGGR_MODE_DISABLED
+#define TSU_DFLT_TMSTMP_OFFS	4
+#define TSU_DFLT_AGGR_PCKT_NUM	1
+#define TSU_DFLT_TS_DESC_NUM	512 //Rx: 512 // Tx: 256
+#define TSU_DFLT_TS_DONEQ_NUM	TSU_DFLT_TS_DESC_NUM * TSU_DFLT_AGGR_PCKT_NUM
+#define TSU_DFLT_DATA_READ_AT_ONCE	0
+#define TSU_DFLT_CLOCK_RATE	20000000
+
+
+#define TSU_DFLT_INT_MASK	(TSU_INT_TS_IF_ERROR |		\
+                                 TSU_INT_FIFO_OVFL_ERROR |	\
+                                 TSU_INT_TS_CONN_ERROR |	\
+                                 TSU_INT_CLOCK_SYNC_EXP | 0x7F)
+
+#endif /* __MV_TSU_H__ */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu_ioctl.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu_ioctl.h
new file mode 100644
index 0000000..2a5d954
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_tsu/mv_tsu_ioctl.h
@@ -0,0 +1,79 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef __MV_TSU_IOCTL_H__
+#define __MV_TSU_IOCTL_H__
+
+#define TSU_STATUS_ERROR_GET(status)		((status >> 28) & 0x1)
+#define TSU_STATUS_ERROR_SET(status)		(status = status | (0x1 << 28))
+#define TSU_STATUS_TMSSTMP_GET(status)		(status & 0xFFFFFFF)
+#define TSU_STATUS_TMSSTMP_SET(status,tms)	(status = status | (tms & 0xFFFFFFF))
+
+struct tsu_tmstmp_info {
+	unsigned int timestamp;
+	unsigned char enable_tms;
+};
+
+
+enum tsu_aggr_mode {
+	aggrModeDisabled,
+	aggrMode1,
+	aggrMode2
+};
+
+struct tsu_buff_info {
+	enum tsu_aggr_mode aggr_mode;
+	unsigned char aggr_mode2_tmstmp_off;
+	unsigned char aggr_num_packets;
+
+	unsigned int num_ts_desc;
+	unsigned int num_done_q_entries;
+	int pkt_size;
+};
+
+
+struct tsu_stat {
+	unsigned int ts_if_err;
+	unsigned int fifo_ovfl;
+	unsigned int ts_conn_err;
+	unsigned int clk_sync_exp;
+};
+
+
+#define MVTSU_IOC_MAGIC  'T'
+
+#define MVTSU_IOCFREQSET	_IOW(MVTSU_IOC_MAGIC,1, unsigned int)
+#define MVTSU_IOCTXTMSSET	_IOW(MVTSU_IOC_MAGIC,2, struct tsu_tmstmp_info)
+#define MVTSU_IOCTXDONE		_IO(MVTSU_IOC_MAGIC,3)
+#define MVTSU_IOCRDPKTATONCE	_IOW(MVTSU_IOC_MAGIC,4, unsigned int)
+#define MVTSU_IOCBUFFPARAMGET	_IOR(MVTSU_IOC_MAGIC,5, struct tsu_buff_info)
+#define MVTSU_IOCGETSTAT	_IOR(MVTSU_IOC_MAGIC,6, struct tsu_stat)
+#define MVTSU_IOCCLEARSTAT	_IO(MVTSU_IOC_MAGIC,7)
+#define MVTSU_IOCAUTOTMS	_IOW(MVTSU_IOC_MAGIC,8, unsigned int)
+
+#endif /* __MV_TSU_IOCTL_H__ */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_udc/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_udc/Makefile
new file mode 100644
index 0000000..a333829
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_udc/Makefile
@@ -0,0 +1,25 @@
+#
+# Makefile for the Marvell USB device controller
+#
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+USB_DIR := ../mv_hal/usb/
+USB_PATH := $(srctree)/arch/arm/plat-feroceon/mv_hal/usb
+
+USB_DEV_DIR := $(USB_DIR)/device
+
+EXTRA_CFLAGS += -I$(USB_PATH)/api -I$(USB_PATH)/common -I$(USB_PATH)/device
+
+OBJS        := mv_udc_main.o ../$(USB_DEV_DIR)/mvUsbDevCh9.o ../$(USB_DEV_DIR)/mvUsbDevMain.o 	\
+               ../$(USB_DEV_DIR)/mvUsbDevRecv.o ../$(USB_DEV_DIR)/mvUsbDevSend.o ../$(USB_DEV_DIR)/mvUsbDevUtl.o 	\
+	       ../$(USB_DEV_DIR)/mvUsbHsDevUtl.o  ../$(USB_DEV_DIR)/mvUsbHsDevMain.o ../$(USB_DEV_DIR)/mvUsbHsDevCncl.o
+
+mv_udc-objs := $(OBJS)
+obj-m := mv_udc.o
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_udc/README b/arch/arm/plat-armada/mv_drivers_lsp/mv_udc/README
new file mode 100644
index 0000000..9b7fbaa
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_udc/README
@@ -0,0 +1,86 @@
+
+Introduction:
++++++++++++++
+This is a USB gadget driver for Marvell SoC:
+There are two Linux Gadget examples are working above the gadget driver
+mv_usb_gadget.ko  - an USB device Gadget driver module.
+g_file_storage.ko - a Kernel USB file storage gadget module.
+g_ether.ko        - a Kernel USB Ethernet gadget module
+
+In order to use this module make sure that one of USB Controllers on the board 
+is configured as a USB device. It means that the UBoot environment variable usb0Mode 
+(or usb1Mode if exist) is set to "device".
+
+Compile:
+++++++++
+
+To compile mv_usb_gadget.ko:
+1. Go to linux Kernel directory
+...
+To compile g_file_storage.ko and g_ether.ko:
+1. Choose in the config option 'Support for USB Gadgets' to be module 'M' 
+   and choose 'USB Peripheral Controller' to be 'Dummy HCD'
+2. => M=arch/arm/plat-feroceon/mv_drivers_lsp/mv_udc
+3. Copy g_file_storage.ko and g_ether.ko from drivers/usb/gadget/
+
+
+Run g_file_storage.ko example:
+++++
+Under the ARM FS:
+    On the first time we need to create a file which will be use as the gadget file storage:
+    'dd bs=1M count=64 if=/dev/zero of=/root/diskFile'   # 64M file storage initialized with zeros 
+
+    Load modules:
+    'insmod mv_udc.ko'
+    With NFS:
+    --------
+    'insmod g_file_storage.ko file=/root/diskFile use_directio=0'
+
+    With HD:
+    --------
+    'insmod g_file_storage.ko file=/root/diskFile'	
+
+Connect a USB cable from the device connector to a Host computer.
+
+On the first connection we need to initialize the disk:
+----------------------
+ on windows :
+	    choose my computer + right_click -> manage:
+	    choose Disk management:	
+	    initialize the new Disk and create a partition on it.
+ on Linux :
+  X - storage id (a,b,c ..)  Y - partition id (1,2,..) DIR - directory name.
+  --create partition table:
+        'fdisk /dev/sdX' (check help for more info, p - display all partition
+                                                n - create a new partition (use primary)
+                                                d - delete a partition
+                                                w - write changes made to the HD)
+  --create a new FS on one of the partitions:
+        'mkfs.ext3 /dev/sdXY'
+
+  --mount one of the partitions:
+        'mkdir /root/mnt/DIR'
+        'mount /dev/sdXY /root/mnt/DIR'
+
+
+Run g_ether.ko example:
+++++
+Under the ARM FS:
+-----------------
+    Load modules:
+    'insmod mv_usb_gadget.ko'
+    'insmod g_ether.ko'
+
+    Configure USB interface:
+    'ifconfig usb0 11.4.0.1'
+
+Connect a USB cable from the device connector to a Host computer.
+
+On Host computer:
+-----------------
+on windows :
+    choose My Network Places + right_click -> Properties
+    choose Linux USB Ethernet/RNDIS Gadget connection + right_click -> Properties
+    Configure specific IP address for this interface (e.g. 11.4.0.100)
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_udc/mv_udc_main.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_udc/mv_udc_main.c
new file mode 100644
index 0000000..7e860fc
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_udc/mv_udc_main.c
@@ -0,0 +1,2025 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File under the following licensing terms. 
+Redistribution and use in source and binary forms, with or without modification, 
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+        this list of conditions and the following disclaimer. 
+
+    *   Redistributions in binary form must reproduce the above copyright
+        notice, this list of conditions and the following disclaimer in the
+        documentation and/or other materials provided with the distribution. 
+
+    *   Neither the name of Marvell nor the names of its contributors may be 
+        used to endorse or promote products derived from this software without 
+        specific prior written permission. 
+    
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND 
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE 
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR 
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES 
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; 
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON 
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT 
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS 
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+ 
+#include "mvOs.h"
+#include "config/mvSysHwConfig.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "usb/api/mvUsbDevApi.h"
+#include "usb/api/mvUsbCh9.h"
+#include "usb/mvUsb.h"
+#include "usb/mvUsbRegs.h"
+
+#include <linux/module.h> 
+#include <linux/moduleparam.h>
+#include <linux/wait.h>
+#include <linux/usb/ch9.h>
+#include <linux/version.h>
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+#include <linux/usb_gadget.h>
+#else
+#include <linux/usb/gadget.h>
+#endif
+#include <linux/proc_fs.h>
+#include <linux/platform_device.h>
+
+#include <asm/irq.h>
+#include <linux/device.h>
+#include <linux/workqueue.h>
+
+#include <linux/signal.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+
+#ifdef MV_USB_VOLTAGE_FIX
+
+#define MV_USB_CONNECTED	1
+#define MV_USB_DISCONNECTED	2
+
+static int mv_usb_initialize_kobject (void);
+
+#endif /* MV_USB_VOLTAGE_FIX */
+
+#if defined(CONFIG_MV645xx) || defined(CONFIG_MV646xx)
+#   include "marvell_pic.h"
+#endif /* CONFIG_MV645xx */
+
+#ifdef CONFIG_SMP
+#define MV_SPIN_LOCK_IRQSAVE(spinlock,flags) \
+if(!in_interrupt())  \
+spin_lock_irqsave(spinlock, flags)
+
+#define MV_SPIN_UNLOCK_IRQRESTORE(spinlock,flags) \
+if(!in_interrupt())  \
+spin_unlock_irqrestore(spinlock, flags)
+
+#else /* CONFIG_SMP */
+
+#define MV_SPIN_LOCK_IRQSAVE(spinlock,flags) spin_lock_irqsave(spinlock, flags)
+#define MV_SPIN_UNLOCK_IRQRESTORE(spinlock,flags) spin_unlock_irqrestore(spinlock, flags)
+
+#endif /* CONFIG_SMP */
+
+static char usb_dev_name[]  = "mv_udc";
+
+/*  
+ *  Enable/Disable Streaming mode for USB Core
+ */
+/*#if (defined(CONFIG_MV88F6082) || defined(CONFIG_MV645xx) || defined(USB_UNDERRUN_WA))*/
+#if (MV_USB_VERSION >= 1) || defined(USB_UNDERRUN_WA)
+static int streaming = 1;  
+#else
+static int streaming = 0;  
+#endif
+module_param_named(streaming, streaming, int, S_IRUGO);
+MODULE_PARM_DESC(streaming, "0 - Streaming Disable, 1 - Streaming Enable");
+
+static int epin_first = 1;  
+module_param_named(epin_first, epin_first, int, S_IRUGO);
+MODULE_PARM_DESC(epin_first, "First choose of IN endpoint number");
+
+static int epout_first = 1;  
+module_param_named(epout_first, epout_first, int, S_IRUGO);
+MODULE_PARM_DESC(epout_first, "First choose of OUT endpoint number");
+
+#if defined(USB_UNDERRUN_WA)
+#include "mvIdma.h" 
+
+extern int              mv_idma_usage_get(int* free_map);
+extern unsigned char*   mv_sram_usage_get(int* sram_size_ptr);
+
+
+#define USB_IDMA_CTRL_LOW_VALUE       ICCLR_DST_BURST_LIM_128BYTE   \
+                                    | ICCLR_SRC_BURST_LIM_128BYTE   \
+                                    | ICCLR_BLOCK_MODE              \
+                                    | ICCLR_DESC_MODE_16M
+
+/*  
+ *  0..3   - use specifed IDMA engine. If the engine is busy - find free one.
+ *  Other  - don't use IDMA (use memcpy instead)
+ */
+static int idma = 1;  
+module_param_named(idma, idma, int, S_IRUGO);
+MODULE_PARM_DESC(idma, "IDMA engine used for copy from DRAM to SRAM [0..3]");
+
+/*  
+ */
+static int wa_sram_parts  = 2;  
+module_param_named(wa_sram_parts, wa_sram_parts, int, S_IRUGO);
+MODULE_PARM_DESC(wa_sram_parts, "");
+
+static int wa_sram_descr  = 1;  
+module_param_named(wa_sram_descr, wa_sram_descr, int, S_IRUGO);
+MODULE_PARM_DESC(wa_sram_descr, "");
+
+/*  
+ */
+static int wa_threshold = 64;  
+module_param_named(wa_threshold, wa_threshold, int, S_IRUGO);
+MODULE_PARM_DESC(wa_threshold, "");
+
+
+static char*    sramBase = (char*)NULL;
+static int      sramSize = 0;
+
+u32     mvUsbSramGet(u32* pSize)
+{
+    char*   pBuf;
+
+    /* Align address to 64 bytes */
+    pBuf = (char*)MV_ALIGN_UP((u32)sramBase, 64);
+
+    if(pSize != NULL)
+    {
+        *pSize = sramSize - (pBuf - sramBase);
+    }
+/*
+    mvOsPrintf("mvUsbSramGet: Base=%p (%p), Size=%d (%d)\n", 
+                sramBase, pBuf, sramSize, *pSize);
+*/
+    return (u32)pBuf;
+}
+
+void        mvUsbIdmaToSramCopy(void* sram_buf, void* src_buf, unsigned int size)
+{
+    unsigned long phys_addr;
+
+/*
+    mvOsPrintf("IdmaToSramCopy: idma=%d, sram=%p, src=%p (0x%x)\n", 
+                    usbWaIdma, sram_buf, src_buf, phys_addr);
+*/
+    if( (idma >= 0) && (idma < MV_IDMA_MAX_CHAN) )
+    {
+        phys_addr = pci_map_single(NULL, src_buf, size, PCI_DMA_TODEVICE );
+
+        /* !!!! SRAM Uncached */
+        /*mvOsCacheInvalidate(NULL, sram_buf, size);*/
+
+        mvDmaTransfer(idma, (MV_U32)phys_addr, 
+                      (MV_U32)sram_buf, size, 0);
+
+        /* Wait until copy is finished */
+        while( mvDmaStateGet(idma) != MV_IDLE );
+    }
+    else
+    {
+        /* mvOsPrintf("usbWA: copy to SRAM %d bytes: \n", size); */
+        memcpy(sram_buf, src_buf, size);
+        /* !!!! SRAM Uncached */
+        /*mvOsCacheFlush(NULL, sram_buf, size);*/
+    }
+}
+
+USB_WA_FUNCS    usbWaFuncs = 
+{
+    mvUsbSramGet,
+    mvUsbIdmaToSramCopy
+};
+
+int mv_usb_find_idma_engine(int idma_no)
+{
+    int idma, free = 0;
+    int free_map[MV_IDMA_MAX_CHAN];
+
+    if( (idma_no < 0) || (idma_no >= MV_IDMA_MAX_CHAN) )
+    {
+        mvOsPrintf("Wrong IDMA number (%d): Valid range [0..%d]\n", 
+                    idma_no, (MV_IDMA_MAX_CHAN-1) );
+        return -1;
+    }
+    free = mv_idma_usage_get(free_map);
+    if(free == 0)
+    {
+        mvOsPrintf("No free IDMAs for USB Underrun WA: use memcpy\n");
+        return -1;
+    }
+    /* First of all check user idma_no */
+    if(free_map[idma_no] != 0)
+        return idma_no;
+
+    /* User idma_no is Busy. Look for free IDMA engine */
+    for(idma=0; idma<MV_IDMA_MAX_CHAN; idma++)
+    {
+        if(free_map[idma] != 0)
+            break;
+    }
+    mvOsPrintf("IDMA engine #%d is Busy. Use IDMA engine #%d instead\n", idma_no, idma);
+    return idma;
+}
+#endif /* USB_UNDERRUN_WA */
+
+
+#undef DEBUG
+
+#ifdef DEBUG
+#define DBGMSG(fmt,args...)    \
+             mvOsPrintf(fmt , ## args)
+#else
+#   define DBGMSG(fmt,args...)
+#endif /* DEBUG */
+
+#define DRIVER_VERSION  "05-July-2006"
+#define DRIVER_DESC "Marvell Gadget USB Peripheral Controller"
+
+struct mv_usb_dev;
+
+struct mv_usb_ep 
+{
+    struct usb_ep       ep;
+    struct mv_usb_dev*  usb_dev;
+    struct list_head    req_list;
+    unsigned            num : 8,
+                        is_enabled : 1,
+                        is_in : 1;
+};
+
+struct mv_usb_dev 
+{
+    /* each pci device provides one gadget, several endpoints */
+    struct usb_gadget           gadget;
+    spinlock_t                  lock;
+    struct usb_gadget_driver    *driver;
+    struct mv_usb_ep            ep[2*ARC_USB_MAX_ENDPOINTS];
+    unsigned                    enabled : 1,
+                                protocol_stall : 1,
+                                got_irq : 1;
+    u16                         chiprev;
+    struct device               *dev; 
+    void*                       mv_usb_handle;
+    int                         dev_no;
+    MV_U8                       vbus_gpp_no;
+};
+
+void    mv_usb_show(struct mv_usb_dev* mv_dev, unsigned int mode);
+
+extern void   _usb_dci_vusb20_isr(pointer);
+
+static void* mvUsbMalloc(unsigned int size)
+{
+    return kmalloc(size,GFP_ATOMIC);
+}
+
+static void mvUsbFree(void* buf)
+{
+    return kfree(buf);
+}
+
+static void* mvUsbIoUncachedMalloc( void* pDev, MV_U32 size, MV_U32 alignment, 
+                                    MV_ULONG* pPhyAddr )
+{
+#if defined(USB_UNDERRUN_WA)
+    if(wa_sram_descr != 0)
+    {
+        char*   pBuf;
+
+        pBuf = (char*)MV_ALIGN_UP((MV_U32)sramBase, alignment);
+        size += (pBuf - sramBase);
+        if( (sramSize < size) )
+        {
+            mvOsPrintf("SRAM malloc failed: Required %d bytes - Free %d bytes\n", 
+                        size, sramSize);
+            return NULL;
+        }
+        if(pPhyAddr != NULL)
+            *pPhyAddr = (MV_ULONG)sramBase;
+/*
+        mvOsPrintf("usbUncachedMalloc: , pBuf=%p (%p), size=%d, align=%d\n", 
+                sramBase, pBuf, size, alignment);
+*/
+        pBuf = sramBase;
+
+        sramSize -= size;
+        sramBase += size;
+
+        return pBuf;
+    }
+#endif 
+    return pci_alloc_consistent( pDev, size+alignment, (dma_addr_t *)pPhyAddr );
+}
+
+static void mvUsbIoUncachedFree( void* pDev, MV_U32 size, MV_ULONG phyAddr, void* pVirtAddr )
+{
+#if defined(USB_UNDERRUN_WA)
+    if(wa_sram_descr != 0)
+    {
+        return;
+    }
+#endif 
+    return pci_free_consistent( pDev, size, pVirtAddr, (dma_addr_t)phyAddr );
+} 
+
+static MV_ULONG mvUsbCacheInvalidate( void* pDev, void* p, int size )
+{
+#if defined(USB_UNDERRUN_WA)
+    if( ((char*)p >= sramBase) && 
+        ((char*)p < (sramBase + sramSize)) )
+        return (unsigned long)p;
+#endif
+
+    return pci_map_single( pDev, p, size, PCI_DMA_FROMDEVICE );
+}
+
+static MV_ULONG mvUsbCacheFlush( void* pDev, void* p, int size )
+{
+#if defined(USB_UNDERRUN_WA)
+    if( ((char*)p >= sramBase) && 
+        ((char*)p < (sramBase + sramSize)) )
+        return (unsigned long)p;
+#endif
+
+    return pci_map_single( pDev, p, size, PCI_DMA_TODEVICE );
+}
+
+static unsigned long mvUsbVirtToPhys(void* pDev, void* pVirtAddr)
+{
+#if defined(USB_UNDERRUN_WA)
+    if( ((char*)pVirtAddr >= sramBase) && 
+        ((char*)pVirtAddr < (sramBase + sramSize)) )
+        return (unsigned long)pVirtAddr;
+#endif 
+
+    return virt_to_phys(pVirtAddr);
+}
+
+static void   usbDevResetComplete(int devNo)
+{
+    MV_U32  regVal; 
+
+    regVal = MV_USB_CORE_MODE_DEVICE | MV_USB_CORE_SETUP_LOCK_DISABLE_MASK;
+    if(streaming == 0)    
+        regVal |= MV_USB_CORE_STREAM_DISABLE_MASK; 
+
+    /* Set USB_MODE register */
+    MV_REG_WRITE(MV_USB_CORE_MODE_REG(devNo), regVal); 
+}
+
+extern MV_U32   mvUsbGetCapRegAddr(int devNo);
+
+
+USB_IMPORT_FUNCS    usbImportFuncs =
+{
+    mvOsPrintf,
+    mvOsSPrintf,
+    mvUsbIoUncachedMalloc,
+    mvUsbIoUncachedFree,
+    mvUsbMalloc,
+    mvUsbFree,
+    memset,
+    memcpy,
+    mvUsbCacheFlush,
+    mvUsbCacheInvalidate,
+    mvUsbVirtToPhys,
+    NULL,
+    NULL,
+    mvUsbGetCapRegAddr,
+    usbDevResetComplete
+};
+
+
+static struct mv_usb_dev*   the_controllers[MV_USB_MAX_PORTS] = {NULL};
+
+static const char driver_name [] = "mv_udc";
+static const char driver_desc [] = DRIVER_DESC;
+
+static char ep_names [2*ARC_USB_MAX_ENDPOINTS][10] = 
+{
+    "ep0out", "ep0in", 
+};
+ 
+
+ 
+
+static struct usb_ep_ops mv_usb_ep_ops;
+
+static void mv_usb_ep_cancel_all_req(struct mv_usb_ep *mv_ep)
+{
+    struct mv_usb_dev*      mv_dev = mv_ep->usb_dev;
+    struct usb_request*     usb_req;
+    int                     req_cntr, tr_cntr;
+
+    req_cntr = tr_cntr = 0;
+
+    /* Cancel all transfers */
+    while(_usb_device_get_transfer_status(mv_dev->mv_usb_handle, mv_ep->num, 
+           mv_ep->is_in ? ARC_USB_SEND : ARC_USB_RECV) != ARC_USB_STATUS_IDLE)
+   {
+        tr_cntr++;
+       _usb_device_cancel_transfer(mv_dev->mv_usb_handle, mv_ep->num, 
+                           mv_ep->is_in ? ARC_USB_SEND : ARC_USB_RECV);
+    }
+/*
+    if(tr_cntr > 0)
+    {
+        mvOsPrintf("Cancel ALL transfers: ep=%d-%s, %d transfers\n", 
+                        mv_ep->num, mv_ep->is_in ? "in" : "out", tr_cntr);
+    }
+*/
+    while (!list_empty (&mv_ep->req_list)) 
+    {
+        usb_req = list_entry (mv_ep->req_list.next, struct usb_request, list);
+
+        /* Dequeue request and call complete function */
+        list_del_init (&usb_req->list);
+
+        if (usb_req->status == -EINPROGRESS)
+            usb_req->status = -ESHUTDOWN;
+
+        usb_req->complete (&mv_ep->ep, usb_req);
+        req_cntr++;
+        if(req_cntr >= MAX_XDS_FOR_TR_CALLS)
+            break;
+    }
+/*
+    if(req_cntr > 0)
+    {
+        mvOsPrintf("Cancel ALL Requests: ep=%d-%s, %d requests\n", 
+                        mv_ep->num, mv_ep->is_in ? "in" : "out", req_cntr);
+        _usb_stats(mv_dev->mv_usb_handle);
+    }
+*/
+}
+
+static uint_8 mv_usb_start_ep0(struct mv_usb_dev *mv_dev)
+{
+    DBGMSG("%s: mv_dev=%p, mv_usb_handle=%p, mv_ep=%p, usb_ep=%p\n", 
+           __FUNCTION__, mv_dev, mv_dev->mv_usb_handle, &mv_dev->ep[0], &mv_dev->ep[0].ep);
+
+    /* Init ep0 IN and OUT */
+    mv_dev->ep[0].is_enabled = 1;
+
+    _usb_device_init_endpoint(mv_dev->mv_usb_handle, 0, mv_dev->ep[0].ep.maxpacket, 
+                                ARC_USB_SEND,  ARC_USB_CONTROL_ENDPOINT, 0);
+
+    _usb_device_init_endpoint(mv_dev->mv_usb_handle, 0, mv_dev->ep[0].ep.maxpacket, 
+                                ARC_USB_RECV, ARC_USB_CONTROL_ENDPOINT, 0);
+
+    return USB_OK;
+}
+
+static void   mv_usb_ep_init(struct mv_usb_ep *ep, int num, int is_in)
+{
+    sprintf(&ep_names[num*2+is_in][0], "ep%d%s", num, is_in ? "in" : "out");
+    ep->ep.name = &ep_names[num*2+is_in][0];
+
+    ep->num = num;
+    ep->is_in = is_in;
+    ep->is_enabled = 0;
+
+    INIT_LIST_HEAD (&ep->req_list);
+    
+    ep->ep.maxpacket = ~0;
+    ep->ep.ops = &mv_usb_ep_ops;
+}
+
+static uint_8 mv_usb_reinit (struct mv_usb_dev *usb_dev)
+{
+    int                 i, ep_num;
+    struct mv_usb_ep    *ep;
+
+    DBGMSG("%s: mv_dev=%p, mv_usb_handle=%p\n", 
+           __FUNCTION__, usb_dev, usb_dev->mv_usb_handle);
+
+    INIT_LIST_HEAD (&usb_dev->gadget.ep_list);
+
+    /* Enumerate IN endpoints */
+    ep_num = epin_first;
+    for(i=0; i<_usb_device_get_max_endpoint(usb_dev->mv_usb_handle); i++)
+    {
+        ep = &usb_dev->ep[ep_num*2+1];
+        if (ep_num != 0)
+        {
+            INIT_LIST_HEAD(&ep->ep.ep_list);
+            list_add_tail (&ep->ep.ep_list, &usb_dev->gadget.ep_list);
+        }
+        mv_usb_ep_init(ep, ep_num, 1);
+        ep->usb_dev = usb_dev;
+
+        ep_num++;
+        if(ep_num == _usb_device_get_max_endpoint(usb_dev->mv_usb_handle))
+            ep_num = 0;
+    }
+
+    /* Enumerate OUT endpoints */
+    ep_num = epout_first;
+    for(i=0; i<_usb_device_get_max_endpoint(usb_dev->mv_usb_handle); i++)
+    {
+        ep = &usb_dev->ep[ep_num*2];
+        if (ep_num != 0)
+        {
+            INIT_LIST_HEAD(&ep->ep.ep_list);
+            list_add_tail (&ep->ep.ep_list, &usb_dev->gadget.ep_list);
+        }
+        mv_usb_ep_init(ep, ep_num, 0);
+        ep->usb_dev = usb_dev;
+
+        ep_num++;
+        if(ep_num == _usb_device_get_max_endpoint(usb_dev->mv_usb_handle))
+            ep_num = 0;
+    }
+    usb_dev->ep[0].ep.maxpacket = 64;
+    usb_dev->gadget.ep0 = &usb_dev->ep[0].ep;
+    INIT_LIST_HEAD (&usb_dev->gadget.ep0->ep_list);
+    return USB_OK;
+}
+
+void mv_usb_bus_reset_service(void*      handle, 
+                               uint_8     type, 
+                               boolean    setup,
+                               uint_8     direction, 
+                               uint_8_ptr buffer,
+                               uint_32    length, 
+                               uint_8     error)
+{
+    int                     i, dev_no = _usb_device_get_dev_num(handle);
+    struct mv_usb_dev       *mv_dev = the_controllers[dev_no];
+    struct mv_usb_ep        *mv_ep;
+
+    if(setup == 0)
+    {
+        /* mv_usb_show(mv_dev, 0x3ff); */
+
+        /* Stop Hardware and cancel all pending requests */
+        for (i=0; i<2*_usb_device_get_max_endpoint(handle); i++)
+        {
+            mv_ep = &mv_dev->ep[i];
+
+            if(mv_ep->is_enabled == 0)
+                continue;
+
+            mv_usb_ep_cancel_all_req(mv_ep);
+        }
+        /* If connected call Function disconnect callback */
+        if( (mv_dev->gadget.speed != USB_SPEED_UNKNOWN) && 
+            (mv_dev->driver != NULL) &&
+            (mv_dev->driver->disconnect != NULL) )
+
+        {
+/*
+            USB_printf("USB gadget device disconnect or port reset: frindex=0x%x\n",
+                    MV_REG_READ(MV_USB_CORE_FRAME_INDEX_REG(dev_no)) );    
+*/
+            mv_dev->driver->disconnect (&mv_dev->gadget);
+        }
+        mv_dev->gadget.speed = USB_SPEED_UNKNOWN;
+
+        /* Reinit all endpoints */
+        mv_usb_reinit(mv_dev);
+    }
+    else
+    {
+        _usb_device_start(mv_dev->mv_usb_handle);
+        /* Restart Control Endpoint #0 */
+        mv_usb_start_ep0(mv_dev);
+    }
+}
+
+
+void mv_usb_speed_service(void*      handle, 
+                           uint_8     type, 
+                           boolean    setup,
+                           uint_8     direction, 
+                           uint_8_ptr buffer,
+                           uint_32    length, 
+                           uint_8     error)
+{
+    int                     dev_no = _usb_device_get_dev_num(handle);
+    struct mv_usb_dev       *mv_dev = the_controllers[dev_no];
+
+    DBGMSG("Speed = %s\n", (length == ARC_USB_SPEED_HIGH) ? "High" : "Full");
+
+    if(length == ARC_USB_SPEED_HIGH)
+        mv_dev->gadget.speed = USB_SPEED_HIGH;
+    else
+        mv_dev->gadget.speed = USB_SPEED_FULL;
+
+    return;
+}
+
+void mv_usb_suspend_service(void*      handle, 
+                            uint_8     type, 
+                            boolean    setup,
+                            uint_8     direction, 
+                            uint_8_ptr buffer,
+                            uint_32    length, 
+                            uint_8     error)
+{
+    int                     dev_no = _usb_device_get_dev_num(handle);
+    struct mv_usb_dev       *mv_dev = the_controllers[dev_no];
+
+    DBGMSG("%s\n", __FUNCTION__);
+
+    if( (mv_dev->driver != NULL) &&
+        (mv_dev->driver->suspend != NULL) )
+        mv_dev->driver->suspend (&mv_dev->gadget);
+}
+
+void mv_usb_resume_service(void*      handle, 
+                            uint_8     type, 
+                            boolean    setup,
+                            uint_8     direction, 
+                            uint_8_ptr buffer,
+                            uint_32    length, 
+                            uint_8     error)
+{
+    int                     dev_no = _usb_device_get_dev_num(handle);
+    struct mv_usb_dev       *mv_dev = the_controllers[dev_no];
+
+    DBGMSG("%s\n", __FUNCTION__);
+
+    if( (mv_dev->driver != NULL) &&
+        (mv_dev->driver->resume != NULL) )
+        mv_dev->driver->resume (&mv_dev->gadget);
+}
+
+void mv_usb_tr_complete_service(void*      handle, 
+                                 uint_8     type, 
+                                 boolean    setup,
+                                 uint_8     direction, 
+                                 uint_8_ptr buffer,
+                                 uint_32    length, 
+                                 uint_8     error)
+{
+    int                     dev_no = _usb_device_get_dev_num(handle);
+    struct mv_usb_dev       *mv_dev = the_controllers[dev_no];
+    struct mv_usb_ep       *mv_ep;
+    struct usb_request      *usb_req;
+    int                     ep_num = (type*2) + direction;
+
+    DBGMSG("%s: ep_num=%d, setup=%s, direction=%s, pBuf=0x%x, length=%d, error=0x%x\n", 
+             __FUNCTION__, type, setup ? "YES" : "NO", 
+             (direction == ARC_USB_RECV) ? "RECV" : "SEND", 
+             (unsigned)buffer, (int)length, error);
+
+    mv_ep = &mv_dev->ep[ep_num];
+    if( !list_empty(&mv_ep->req_list) )
+    {
+        usb_req = list_entry (mv_ep->req_list.next, struct usb_request, list);
+        if(usb_req->buf != buffer)
+        {
+                mvOsPrintf("ep=%d-%s: req=%p, Unexpected buffer pointer: %p, len=%d, expected=%p\n", 
+                    ep_num, (direction == ARC_USB_RECV) ? "out" : "in",
+                    usb_req, buffer, length, usb_req->buf);
+                return;       
+        }
+        /* Dequeue request and call complete function */
+        list_del_init (&usb_req->list);
+
+        usb_req->actual += length;
+        usb_req->status = error;
+
+        usb_req->complete (&mv_ep->ep, usb_req);
+
+        if(error != 0)
+        {
+            _usb_device_stall_endpoint(mv_ep->usb_dev->mv_usb_handle, mv_ep->num,
+                mv_ep->is_in ? ARC_USB_SEND : ARC_USB_RECV);
+        }
+    }
+    else
+        mvOsPrintf("ep=%p, epName=%s, epNum=%d - reqList EMPTY\n", 
+                mv_ep, mv_ep->ep.name, mv_ep->num);
+}
+
+void mv_usb_ep0_complete_service(void*      handle, 
+                                 uint_8     type, 
+                                 boolean    setup,
+                                 uint_8     direction, 
+                                 uint_8_ptr buffer,
+                                 uint_32    length, 
+                                 uint_8     error)
+{ /* Body */
+    int                     dev_no = _usb_device_get_dev_num(handle);
+    struct mv_usb_dev       *mv_dev = the_controllers[dev_no];
+    struct mv_usb_ep       *mv_ep;
+    struct usb_request*     usb_req;
+    int                     rc;
+    boolean                 is_delegate = FALSE;
+    SETUP_STRUCT            ctrl_req_org;
+    static SETUP_STRUCT     mv_ctrl_req;
+   
+    DBGMSG("%s: EP0(%d), setup=%s, direction=%s, pBuf=0x%x, length=%d, error=0x%x\n", 
+                __FUNCTION__, type, setup ? "YES" : "NO", 
+                (direction == ARC_USB_RECV) ? "RECV" : "SEND", 
+                (unsigned)buffer, (int)length, error);
+
+    mv_ep = &mv_dev->ep[type];
+
+    if (setup) 
+    {
+        _usb_device_read_setup_data(handle, type, (u8 *)&ctrl_req_org);
+        mv_ctrl_req.REQUESTTYPE = ctrl_req_org.REQUESTTYPE;
+        mv_ctrl_req.REQUEST = ctrl_req_org.REQUEST;
+        mv_ctrl_req.VALUE = le16_to_cpu (ctrl_req_org.VALUE);
+        mv_ctrl_req.INDEX = le16_to_cpu (ctrl_req_org.INDEX);
+        mv_ctrl_req.LENGTH = le16_to_cpu (ctrl_req_org.LENGTH);
+
+        while(_usb_device_get_transfer_status(handle, mv_ep->num, 
+                ARC_USB_SEND) != ARC_USB_STATUS_IDLE)
+        {
+            _usb_device_cancel_transfer(mv_dev->mv_usb_handle, mv_ep->num, 
+                           ARC_USB_SEND);
+        }
+        while(_usb_device_get_transfer_status(handle, mv_ep->num, 
+                ARC_USB_RECV) != ARC_USB_STATUS_IDLE)
+        {
+            _usb_device_cancel_transfer(mv_dev->mv_usb_handle, mv_ep->num, 
+                           ARC_USB_RECV);
+        }
+        /* make sure any leftover request state is cleared */
+        while (!list_empty (&mv_ep->req_list)) 
+        {
+            usb_req = list_entry (mv_ep->req_list.next, struct usb_request, list);
+
+            /* Dequeue request and call complete function */
+            list_del_init (&usb_req->list);
+
+            if (usb_req->status == -EINPROGRESS)
+                usb_req->status = -EPROTO;
+
+            usb_req->complete (&mv_ep->ep, usb_req);
+        }
+    }
+    /* Setup request direction */
+    mv_ep->is_in = (mv_ctrl_req.REQUESTTYPE & REQ_DIR_IN) != 0;     
+
+    if(setup)
+        DBGMSG("Setup: dir=%s, reqType=0x%x, req=0x%x, value=0x%02x, index=0x%02x, length=0x%02x\n", 
+                (direction == ARC_USB_SEND) ? "In" : "Out",
+                mv_ctrl_req.REQUESTTYPE, mv_ctrl_req.REQUEST, mv_ctrl_req.VALUE,
+                mv_ctrl_req.INDEX, mv_ctrl_req.LENGTH); 
+
+    /* Handle most lowlevel requests;
+     * everything else goes uplevel to the gadget code.
+     */
+    if( (mv_ctrl_req.REQUESTTYPE & REQ_TYPE_MASK) == REQ_TYPE_STANDARD)
+    {
+        switch (mv_ctrl_req.REQUEST) 
+        {
+            case REQ_GET_STATUS: 
+                mvUsbCh9GetStatus(handle, setup, &mv_ctrl_req);
+                break;
+
+            case REQ_CLEAR_FEATURE:
+                mvUsbCh9ClearFeature(handle, setup, &mv_ctrl_req);
+                break;
+
+            case REQ_SET_FEATURE:
+                mvUsbCh9SetFeature(handle, setup, &mv_ctrl_req);
+                break;
+
+            case REQ_SET_ADDRESS:
+                mvUsbCh9SetAddress(handle, setup, &mv_ctrl_req);
+                break;
+
+            default:
+                /* All others delegate call up-layer gadget code */
+                is_delegate = TRUE;
+        }
+    }
+    else
+        is_delegate = TRUE;
+
+    /* delegate call up-layer gadget code */
+    if(is_delegate)
+    {
+        if(setup)
+        {
+            rc = mv_dev->driver->setup (&mv_dev->gadget, (struct usb_ctrlrequest*)&ctrl_req_org);
+            if(rc < 0)
+            {
+                mvOsPrintf("Setup is failed: rc=%d, req=0x%02x, reqType=0x%x, value=0x%04x, index=0x%04x\n", 
+                    rc, ctrl_req_org.REQUEST, ctrl_req_org.REQUESTTYPE, 
+                    ctrl_req_org.VALUE, ctrl_req_org.INDEX);
+                _usb_device_stall_endpoint(handle, 0, ARC_USB_RECV);
+                return;
+            }
+            /* Acknowledge  */
+            if( mv_ep->is_in ) {
+                _usb_device_recv_data(handle, 0, NULL, 0);
+            } 
+            else if( mv_ctrl_req.LENGTH ) {
+                _usb_device_send_data(handle, 0, NULL, 0);
+            }
+        }
+    }
+
+    if(!setup)
+    {
+        if( !list_empty(&mv_ep->req_list) )
+        {
+            usb_req = list_entry (mv_ep->req_list.next, struct usb_request, list);
+
+            /* Dequeue request and call complete function */
+            list_del_init (&usb_req->list);
+
+            usb_req->actual = length;
+            usb_req->status = error;
+            usb_req->complete (&mv_ep->ep, usb_req);
+        }
+        DBGMSG("Setup complete: dir=%s, is_in=%d, length=%d\n", 
+                (direction == ARC_USB_SEND) ? "In" : "Out",
+                mv_ep->is_in, length);
+    }
+}
+
+#ifdef MV_USB_VOLTAGE_FIX
+
+/* usb_state - state of usb:connected(1)/disconnected(2) */
+static int usb_state = MV_USB_DISCONNECTED;
+
+/* usb_device-device structure for kobject functionality */
+static struct device mv_usb_device;
+
+/* mv_usb_work_struct - workqueue structure using for creating and run work tasks */
+static struct work_struct mv_usb_work_struct;
+
+/* mv_bustype for inizialization usb_device structure */
+static struct bus_type mv_usb_bustype = {
+		.name		= "mv_udc",
+};
+
+/*******************************************************************************
+* mv_usb_work_struct_routine
+* DESCRIPTION: 	notify userspace by ending an uevent
+* INPUTS:       *ignored - structure work_struct - N/A
+* OUTPUTS:      N/A
+* RETURNS:      N/A
+*******************************************************************************/
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+static int mv_usb_work_struct_routine(struct work_struct *ignored)
+#else
+static void mv_usb_work_struct_routine(struct work_struct *ignored)
+#endif
+{
+	int retval=1;
+
+	/* Usb device connected */
+	if(usb_state == MV_USB_CONNECTED)
+	{
+		retval = kobject_uevent(&mv_usb_device.kobj, KOBJ_ADD);
+		mvOsPrintf("Usb device connected\n");
+	}
+	/* Usb device disconnected */
+	else
+	{
+		retval = kobject_uevent(&mv_usb_device.kobj, KOBJ_REMOVE);
+		mvOsPrintf("Usb device disconnected\n");
+	}
+	
+	/* on error */
+	if(retval != 0)
+	{
+		mvOsPrintf("ERROR: %d, kobject_uevent() failed\n",retval);
+	}
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+	return retval;
+#endif
+}
+
+/* initialize a work-struct with work task -mv_usb_work_struct_routine */
+static DECLARE_WORK(mv_usb_work_struct, mv_usb_work_struct_routine);
+
+static irqreturn_t mv_usb_vbus_irq (int irq, void *_dev)
+{
+    struct mv_usb_dev       *mv_dev = _dev;
+    int                     vbus_change, retval=0;
+
+    vbus_change = mvUsbBackVoltageUpdate(mv_dev->dev_no, (int)mv_dev->vbus_gpp_no);
+    if(vbus_change == 2)
+    {
+        if( (mv_dev->gadget.speed != USB_SPEED_UNKNOWN) &&
+            (mv_dev->driver != NULL)                    &&
+            (mv_dev->driver->disconnect != NULL) )
+            mv_dev->driver->disconnect (&mv_dev->gadget);
+    }
+    /*
+    printk("%s: vbus_change = %d, usb_state=%d\n", 
+            __FUNCTION__, vbus_change, usb_state);
+    */
+
+	/* 
+	   set state of usb device (1-connected;2-disconnected) and
+	   schedule mv_usb_work_struct_routine in workqueue 
+	   if mv_usb_work_struct entry is empty 
+	*/
+	usb_state=(vbus_change==2) ? MV_USB_DISCONNECTED : MV_USB_CONNECTED;
+	if(list_empty(&mv_usb_work_struct.entry))
+	{
+		retval = schedule_work(&mv_usb_work_struct);
+ 		if(retval == 0)
+		{
+			mvOsPrintf("ERROR: %d, schedule_work() failed\n",retval);
+		}
+	}
+    return IRQ_HANDLED;
+}
+#endif /* MV_USB_VOLTAGE_FIX */
+
+static irqreturn_t mv_usb_dev_irq (int irq, void *_dev)
+{
+    struct mv_usb_dev       *mv_dev = _dev;
+
+    spin_lock (&mv_dev->lock);
+
+    /* handle ARC USB Device interrupts */
+    _usb_dci_vusb20_isr(mv_dev->mv_usb_handle);
+
+    spin_unlock (&mv_dev->lock);
+
+    return IRQ_HANDLED;
+}
+
+#ifdef MV_USB_VOLTAGE_FIX
+
+/*******************************************************************************
+* mv_usb_initialize_kobject
+* DESCRIPTION: 	init device,set bus type, create and add kobject
+* INPUTS:       *dev - pointer for device structure
+* OUTPUTS:      N/A
+* RETURNS:      status USB_OK on success
+*******************************************************************************/
+static int mv_usb_initialize_kobject (void)
+{
+	int retval = 1;
+
+	/* init device */
+	device_initialize(&mv_usb_device);
+
+	/* set bus_type for device */
+	mv_usb_device.bus = &mv_usb_bustype;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+	/* init kobject */
+	retval = kobject_set_name(&mv_usb_device.kobj, "mv_udc_d");
+	if(retval != USB_OK)
+	{
+		mvOsPrintf("ERROR: %d, kobject_set_name() failed\n",retval);
+		return retval;
+	}
+	retval = kobject_add(&mv_usb_device.kobj);
+#else
+	retval = kobject_add(&mv_usb_device.kobj, NULL, "mv_udc_d");
+
+#endif
+
+	/* add kobject */
+	if(retval != USB_OK)
+	{
+		mvOsPrintf("ERROR: %d, kobject_add() failed\n",retval);
+		return retval;
+	}
+	return USB_OK;
+}
+#endif /* MV_USB_VOLTAGE_FIX */
+
+/* when a driver is successfully registered, it will receive
+ * control requests including set_configuration(), which enables
+ * non-control requests.  then usb traffic follows until a
+ * disconnect is reported.  then a host may connect again, or
+ * the driver might get unbound.
+ */
+int usb_gadget_register_driver (struct usb_gadget_driver *driver)
+{
+    int                 retval, dev_no;
+    struct mv_usb_dev   *mv_dev = NULL;
+    uint_8              error;
+
+/*    mvOsPrintf("ENTER usb_gadget_register_driver: \n");*/
+
+    /* Find USB Gadget device controller */
+    for(dev_no=0; dev_no<mvCtrlUsbMaxGet(); dev_no++)
+    {
+        mv_dev = the_controllers[dev_no];
+        if(mv_dev != NULL)
+            break;
+    }
+
+    if ( (driver == NULL)
+            || (driver->speed != USB_SPEED_HIGH)
+            || !driver->bind
+            || !driver->unbind
+            || !driver->setup)
+    {
+        mvOsPrintf("ERROR: speed=%d, bind=%p,  unbind=%p, setup=%p\n",
+                    driver->speed, driver->bind, driver->unbind, driver->setup);
+        return -EINVAL;
+    }
+
+    if (!mv_dev)
+    {
+        mvOsPrintf("ERROR: max_dev=%d, mv_dev=%p\n", mvCtrlUsbMaxGet(), mv_dev);
+        return -ENODEV;
+    }
+    if (mv_dev->driver)
+    {
+        mvOsPrintf("ERROR: driver=%p is busy\n", mv_dev->driver);
+        return -EBUSY;
+    }
+/*
+    mvOsPrintf("usb_gadget_register_driver: dev=%d, mv_dev=%p, pDriver=%p\n", 
+                dev_no, mv_dev, driver);
+*/
+    /* first hook up the driver ... */
+    mv_dev->driver = driver;
+    mv_dev->gadget.dev.driver = &driver->driver;
+    retval = driver->bind (&mv_dev->gadget);
+    if (retval) {
+        mvOsPrintf("bind to driver %s --> %d\n",
+                driver->driver.name, retval);
+        mv_dev->driver = 0;
+        mv_dev->gadget.dev.driver = 0;
+        return retval;
+    }
+    /* request_irq */
+    if (request_irq ( (container_of(mv_dev->dev,struct platform_device,dev) )->resource[1].start, mv_usb_dev_irq, IRQF_DISABLED, 
+                     driver_name, mv_dev) != 0) 
+    {
+        mvOsPrintf("%s register: request interrupt %d failed\n", 
+                driver->driver.name, container_of(mv_dev->dev,struct platform_device,dev)->resource[1].start);
+        return -EBUSY;
+    }
+
+    _usb_device_start(mv_dev->mv_usb_handle);
+    error = mv_usb_start_ep0(mv_dev);
+
+    mvOsPrintf("registered Marvell USB-%d gadget driver %s\n", dev_no, driver->driver.name);
+    return error;
+}
+EXPORT_SYMBOL (usb_gadget_register_driver);
+
+int usb_gadget_unregister_driver (struct usb_gadget_driver *driver)
+{
+    int                 i, dev_no;
+    struct mv_usb_ep    *mv_ep;
+    struct mv_usb_dev   *mv_dev = NULL;
+    unsigned long       flags = 0;
+
+    /* Find USB Gadget device controller */
+    for(dev_no=0; dev_no<mvCtrlUsbMaxGet(); dev_no++)
+    {
+        if( (the_controllers[dev_no] != NULL) && (the_controllers[dev_no]->driver == driver) )
+        {
+            mv_dev = the_controllers[dev_no];
+            break;
+        }
+    }
+    
+    if (!mv_dev)
+    {
+        mvOsPrintf("usb_gadget_unregister_driver FAILED: no such device\n");
+        return -ENODEV;
+    }
+    if (!driver || (driver != mv_dev->driver) )
+    {
+        mvOsPrintf("usb_gadget_unregister_driver FAILED: no such driver, dev_no=%d\n", dev_no);
+        return -EINVAL;
+    }
+
+    /* Stop and Disable ARC USB device */
+    MV_SPIN_LOCK_IRQSAVE(&mv_dev->lock, flags);
+
+    /* Stop Endpoints */
+    for (i=0; i<2*_usb_device_get_max_endpoint(mv_dev->mv_usb_handle); i++)
+    {
+        mv_ep = &mv_dev->ep[i];
+        if(mv_ep->is_enabled == 0)
+            continue;
+
+        mv_ep->is_enabled = 0;
+        mv_usb_ep_cancel_all_req(mv_ep);
+
+        _usb_device_deinit_endpoint(mv_dev->mv_usb_handle, mv_ep->num, 
+                                mv_ep->is_in ? ARC_USB_SEND : ARC_USB_RECV);
+    }
+    _usb_device_stop(mv_dev->mv_usb_handle);
+
+    MV_SPIN_UNLOCK_IRQRESTORE(&mv_dev->lock, flags);
+
+    if (mv_dev->gadget.speed != USB_SPEED_UNKNOWN)
+        mv_dev->driver->disconnect (&mv_dev->gadget);
+
+    driver->unbind (&mv_dev->gadget);
+
+    /* free_irq */
+    free_irq (container_of(mv_dev->dev,struct platform_device,dev)->resource[1].start, mv_dev);
+
+    mv_dev->gadget.dev.driver = 0;
+    mv_dev->driver = 0;
+
+    mv_dev->gadget.speed = USB_SPEED_UNKNOWN;
+
+    /* Reinit all endpoints */
+    mv_usb_reinit(mv_dev);
+
+    /*device_remove_file(dev->dev, &dev_attr_function); ?????*/
+    mvOsPrintf("unregistered Marvell USB %d gadget driver %s\n", dev_no, driver->driver.name);
+
+    return 0;
+}
+EXPORT_SYMBOL (usb_gadget_unregister_driver);
+
+void    mv_usb_show(struct mv_usb_dev* mv_dev, unsigned int mode)
+{
+    int     i;
+
+    mvOsPrintf("\n-------------------------------------------------------------\n");
+
+    if( MV_BIT_CHECK(mode, 0) )
+        _usb_regs(mv_dev->mv_usb_handle);
+
+    if( MV_BIT_CHECK(mode, 1) )
+        _usb_status(mv_dev->mv_usb_handle);
+
+    if( MV_BIT_CHECK(mode, 2) )
+        _usb_stats(mv_dev->mv_usb_handle);
+
+    if( MV_BIT_CHECK(mode, 3) )
+        _usb_debug_print_trace_log();
+
+    for(i=0; i<_usb_device_get_max_endpoint(mv_dev->mv_usb_handle); i++)
+    {
+        if( MV_BIT_CHECK(mode, (8+i)) )
+        {
+            _usb_ep_status(mv_dev->mv_usb_handle, i, ARC_USB_RECV);
+            _usb_ep_status(mv_dev->mv_usb_handle, i, ARC_USB_SEND);
+        }
+    }
+    mvOsPrintf("-------------------------------------------------------------\n\n");
+}
+EXPORT_SYMBOL (mv_usb_show);
+
+static int  mv_usb_ep_enable(struct usb_ep *_ep, 
+                              const struct usb_endpoint_descriptor *desc)
+{
+    struct mv_usb_dev* usb_dev;
+    struct mv_usb_ep*  usb_ep;
+    uint_16             maxSize;
+    uint_8              epType; 
+    unsigned long       flags = 0;
+
+    usb_ep = container_of (_ep, struct mv_usb_ep, ep);
+    if( (_ep == NULL) || (desc == NULL) )
+        return -EINVAL;
+    
+    usb_dev = usb_ep->usb_dev;
+
+    if(usb_ep->is_enabled)
+    {
+        mvOsPrintf("mv_usb: %d%s Endpoint (%s) is already in use\n", 
+                    usb_ep->num, usb_ep->is_in ? "In" : "Out", usb_ep->ep.name);
+        return -EINVAL;
+    }
+/*
+    mvOsPrintf("USB Enable %s: type=%d, maxPktSize=%d\n",
+                _ep->name, desc->bmAttributes & 0x3, desc->wMaxPacketSize);
+*/
+    if(usb_ep->num == 0)
+    {
+        mvOsPrintf("mv_usb: ep0 is reserved\n");
+        return -EINVAL;
+    }
+
+    if(desc->bDescriptorType != USB_DT_ENDPOINT)
+    {
+        mvOsPrintf("mv_usb: wrong descriptor type %d\n", desc->bDescriptorType);
+        return -EINVAL;
+    }
+
+    MV_SPIN_LOCK_IRQSAVE(&usb_dev->lock, flags);
+
+    usb_dev = usb_ep->usb_dev;
+    if( (usb_dev->driver == NULL) || 
+        (usb_dev->gadget.speed == USB_SPEED_UNKNOWN) )
+    {
+        MV_SPIN_UNLOCK_IRQRESTORE(&usb_dev->lock, flags);
+        return -ESHUTDOWN;
+    }
+    /* Max packet size */
+    maxSize = le16_to_cpu (desc->wMaxPacketSize);
+
+    /* Endpoint type */
+    if( (desc->bmAttributes & USB_ENDPOINT_XFERTYPE_MASK) == USB_ENDPOINT_XFER_CONTROL)
+        epType = ARC_USB_CONTROL_ENDPOINT;
+    else if( (desc->bmAttributes & USB_ENDPOINT_XFERTYPE_MASK) == USB_ENDPOINT_XFER_ISOC) 
+        epType = ARC_USB_ISOCHRONOUS_ENDPOINT;
+    else if( (desc->bmAttributes & USB_ENDPOINT_XFERTYPE_MASK) == USB_ENDPOINT_XFER_BULK) 
+        epType = ARC_USB_BULK_ENDPOINT;
+    else
+        epType = ARC_USB_INTERRUPT_ENDPOINT;
+
+    _ep->maxpacket = maxSize & 0x7ff;
+    usb_ep->is_enabled = 1;
+
+    _usb_device_init_endpoint(usb_dev->mv_usb_handle, usb_ep->num, maxSize, 
+            usb_ep->is_in ? ARC_USB_SEND : ARC_USB_RECV, epType,
+            (epType == ARC_USB_BULK_ENDPOINT) ? ARC_USB_DEVICE_DONT_ZERO_TERMINATE : 0);
+
+    MV_SPIN_UNLOCK_IRQRESTORE(&usb_dev->lock, flags);
+    return 0;
+}
+
+static int  mv_usb_ep_disable (struct usb_ep *_ep)
+{
+    struct mv_usb_dev*  mv_dev;
+    struct mv_usb_ep*   mv_ep;
+    unsigned long       flags = 0;
+    uint_8              direction;
+
+    mv_ep = container_of (_ep, struct mv_usb_ep, ep);
+    if( (_ep == NULL) || (mv_ep->is_enabled == 0) || (mv_ep->num == 0))
+        return -EINVAL;
+
+    mv_dev = mv_ep->usb_dev;
+/*
+    mvOsPrintf("mv_usb_ep_disable: mv_dev=%p, ep=0x%x (%d-%s), name=%s\n", 
+                mv_dev, (unsigned)_ep, mv_ep->num, mv_ep->is_in ? "in" : "out", 
+                _ep->name);
+*/    
+    MV_SPIN_LOCK_IRQSAVE(&mv_dev->lock, flags);
+
+    direction = mv_ep->is_in ? ARC_USB_SEND : ARC_USB_RECV;
+
+    mv_ep->is_enabled = 0;
+
+    /* Cancell all requests */
+    mv_usb_ep_cancel_all_req(mv_ep);
+
+    /* Disable endpoint */
+    _usb_device_deinit_endpoint(mv_dev->mv_usb_handle, mv_ep->num, direction);
+
+    MV_SPIN_UNLOCK_IRQRESTORE(&mv_dev->lock, flags);
+    return 0;
+}
+
+
+static struct usb_request* mv_usb_ep_alloc_request(struct usb_ep *_ep, gfp_t gfp_flags)
+{
+    struct usb_request* req;
+
+    if (!_ep)
+        return NULL;
+
+    req = kmalloc (sizeof *req, gfp_flags);
+    if (!req)
+        return NULL;
+
+    memset (req, 0, sizeof *req);
+    INIT_LIST_HEAD (&req->list);
+
+    return req;
+}
+
+static void     mv_usb_ep_free_request(struct usb_ep *_ep, struct usb_request *_req)
+{
+
+    if (!_ep || !_req)
+    {
+        mvOsPrintf("ep_free_request Error: _ep=%p, _req=%p\n", _ep, _req);
+        return;
+    }
+    kfree (_req);
+}
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+static void *mv_usb_ep_alloc_buffer(struct usb_ep *_ep, unsigned bytes,
+		dma_addr_t *dma, gfp_t gfp_flags)
+{
+	struct mv_usb_ep *ep;
+
+	if (!_ep)
+		return NULL;
+
+	ep = container_of(_ep, struct mv_usb_ep, ep);
+
+	return dma_alloc_coherent(ep->usb_dev->gadget.dev.parent,
+			bytes, dma, gfp_flags);
+}
+
+/*------------------------------------------------------------------
+ * frees an i/o buffer
+*---------------------------------------------------------------------*/
+static void mv_usb_ep_free_buffer(struct usb_ep *_ep, void *buf,
+		dma_addr_t dma, unsigned bytes)
+{
+	struct mv_usb_ep *ep;
+
+	if (!_ep)
+		return;
+
+	ep = container_of(_ep, struct mv_usb_ep, ep);
+
+	dma_free_coherent(ep->usb_dev->gadget.dev.parent, bytes, buf, dma);
+}
+#endif
+
+static int      mv_usb_ep_queue (struct usb_ep *_ep, struct usb_request *_req, 
+                                 gfp_t gfp_flags)
+{
+    struct mv_usb_dev* usb_dev;
+    struct mv_usb_ep*  usb_ep;
+    unsigned long       flags = 0;
+    uint_8              error;
+
+    usb_ep = container_of (_ep, struct mv_usb_ep, ep);
+    /* check parameters */
+    if( (_ep == NULL) || (_req == NULL) )
+    {
+        mvOsPrintf("ep_queue Failed: _ep=%p, _req=%p\n", _ep, _req);
+        return -EINVAL;
+    }
+    usb_dev = usb_ep->usb_dev;
+
+    if ( (usb_dev->driver == NULL) || (usb_dev->gadget.speed == USB_SPEED_UNKNOWN) )
+        return -ESHUTDOWN;
+
+    if(usb_ep->is_enabled == 0)
+    {
+        mvOsPrintf("ep_queue Failed - %s is disabled: usb_ep=%p\n", _ep->name, usb_ep);
+        return -EINVAL;
+    }
+
+    DBGMSG("%s: num=%d-%s, name=%s, _req=%p, buf=%p, length=%d\n", 
+                __FUNCTION__, usb_ep->num, usb_ep->is_in ? "in" : "out", 
+                _ep->name, _req, _req->buf, _req->length);
+
+    MV_SPIN_LOCK_IRQSAVE(&usb_dev->lock, flags);
+                
+    _req->status = -EINPROGRESS;
+    _req->actual = 0;
+
+    /* Add request to list */
+    if( ((usb_ep->num == 0) && (_req->length == 0)) || (usb_ep->is_in) )
+    {
+        int     send_size, size;
+        uint_8  *send_ptr, *buf_ptr;
+
+        send_ptr = buf_ptr = _req->buf;
+        send_size = size = _req->length;
+        list_add_tail(&_req->list, &usb_ep->req_list);
+
+        error = _usb_device_send_data(usb_dev->mv_usb_handle, usb_ep->num, send_ptr, send_size);
+        if(error != USB_OK)
+        {
+            mvOsPrintf("ep_queue: Can't SEND data (err=%d): ep_num=%d, pBuf=0x%x, send_size=%d\n",
+                    error, usb_ep->num, (unsigned)_req->buf, _req->length);
+            list_del_init (&_req->list);
+        }
+
+        size -= send_size;
+        buf_ptr += send_size;
+    }
+    else
+    {
+        error = _usb_device_recv_data(usb_dev->mv_usb_handle, usb_ep->num, _req->buf, _req->length);
+        if(error != USB_OK)
+        {
+            mvOsPrintf("mv_usb_ep_queue: Can't RCV data (err=%d): ep_num=%d, pBuf=0x%x, size=%d\n",
+                        error, usb_ep->num, (unsigned)_req->buf, _req->length);
+        }
+        else
+            list_add_tail(&_req->list, &usb_ep->req_list);
+    }
+
+    MV_SPIN_UNLOCK_IRQRESTORE(&usb_dev->lock, flags);
+
+    return (int)error;
+}
+
+/* Cancell request */
+static int      mv_usb_ep_dequeue (struct usb_ep *_ep, struct usb_request *_req)
+{
+    struct mv_usb_dev* usb_dev;
+    struct usb_request *usb_req;
+    struct mv_usb_ep*  usb_ep;
+    unsigned long       flags = 0;
+    int                 status = 0;
+
+    usb_ep = container_of (_ep, struct mv_usb_ep, ep);
+    /* check parameters */
+    if( (_ep == NULL) || (_req == NULL) || (usb_ep->is_enabled == 0) )
+        return -EINVAL;
+
+    usb_dev = usb_ep->usb_dev;
+        
+    if ( (usb_dev->driver == NULL) || (usb_dev->gadget.speed == USB_SPEED_UNKNOWN) )
+    {
+        mvOsPrintf("mv_usb_ep_dequeue: ep=0x%x, num=%d-%s, name=%s, driver=0x%x, speed=%d\n", 
+                (unsigned)_ep, usb_ep->num, usb_ep->is_in ? "in" : "out", 
+                _ep->name, (unsigned)usb_dev->driver, usb_dev->gadget.speed);
+
+        return -ESHUTDOWN;
+    }
+
+    MV_SPIN_LOCK_IRQSAVE(&usb_dev->lock, flags);
+
+    /* ????? Currently supported only dequeue request from the HEAD of List */
+    if( !list_empty(&usb_ep->req_list) )
+    {
+        usb_req = list_entry (usb_ep->req_list.next, struct usb_request, list);
+
+        if(usb_req == _req)
+        {
+            /* Cancel transfer */
+            _usb_device_cancel_transfer(usb_dev->mv_usb_handle, usb_ep->num, 
+                            usb_ep->is_in ? ARC_USB_SEND : ARC_USB_RECV);
+            /* Dequeue request and call complete function */
+            list_del_init (&_req->list);
+
+            if (_req->status == -EINPROGRESS)
+                _req->status = -ECONNRESET;
+
+            /* ????? what about enable interrupts */
+            _req->complete (&usb_ep->ep, _req);
+        }
+        else
+        {
+            mvOsPrintf("Cancel request failed: ep=%p, usb_req=%p, req=%p\n", 
+                        _ep, usb_req, _req);
+            status = EINVAL;
+        }
+    }
+    /*
+    else
+        mvOsPrintf("%s: ep=%p, epName=%s, epNum=%d - reqList EMPTY\n", 
+                    __FUNCTION__, usb_ep, usb_ep->ep.name, usb_ep->num);
+    */
+    MV_SPIN_UNLOCK_IRQRESTORE(&usb_dev->lock, flags);
+
+    return status;
+}
+
+static int      mv_usb_ep_set_halt (struct usb_ep *_ep, int value)
+{
+    struct mv_usb_ep*   mv_ep;
+    unsigned long       flags = 0;
+    int                 retval = 0;
+
+    mv_ep = container_of (_ep, struct mv_usb_ep, ep);
+    if (_ep == NULL)
+        return -EINVAL;
+    if( (mv_ep->usb_dev->driver == NULL) || 
+        (mv_ep->usb_dev->gadget.speed == USB_SPEED_UNKNOWN) )
+        return -ESHUTDOWN;
+
+/*
+    mvOsPrintf("%s - %s \n", 
+                _ep->name, value ? "Stalled" : "Unstalled");
+*/
+    MV_SPIN_LOCK_IRQSAVE(&mv_ep->usb_dev->lock, flags);
+    if (!list_empty (&mv_ep->req_list))
+        retval = -EAGAIN;
+    else 
+    {
+        /* set/clear, then synch memory views with the device */
+        if (value) 
+        {
+            if (mv_ep->num == 0)
+                mv_ep->usb_dev->protocol_stall = 1;
+            else
+                _usb_device_stall_endpoint(mv_ep->usb_dev->mv_usb_handle, mv_ep->num,
+                mv_ep->is_in ? ARC_USB_SEND : ARC_USB_RECV);
+        } 
+        else
+        {
+            _usb_device_unstall_endpoint(mv_ep->usb_dev->mv_usb_handle, mv_ep->num, 
+                                    mv_ep->is_in ? ARC_USB_SEND : ARC_USB_RECV);
+        }
+    }
+    MV_SPIN_UNLOCK_IRQRESTORE(&mv_ep->usb_dev->lock, flags);
+
+    return retval;
+}
+
+
+static void     mv_usb_ep_fifo_flush (struct usb_ep *_ep)
+{
+    DBGMSG("%s: ep=%p, ep_name=%s - NOT supported\n", __FUNCTION__, _ep, _ep->name);
+}
+
+
+static struct usb_ep_ops mv_usb_ep_ops = 
+{
+    .enable         = mv_usb_ep_enable,
+    .disable        = mv_usb_ep_disable,
+
+    .alloc_request  = mv_usb_ep_alloc_request,
+    .free_request   = mv_usb_ep_free_request,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+    .alloc_buffer  = mv_usb_ep_alloc_buffer,
+    .free_buffer   = mv_usb_ep_free_buffer,
+#endif
+    .queue          = mv_usb_ep_queue,
+    .dequeue        = mv_usb_ep_dequeue,
+
+    .set_halt       = mv_usb_ep_set_halt,
+    .fifo_flush     = mv_usb_ep_fifo_flush,
+    /*.fifo_status    =  Not supported */
+};
+
+static int mv_usb_get_frame (struct usb_gadget *_gadget)
+{
+    DBGMSG("Call mv_usb_get_frame - NOT supported\n");
+    return 0;
+}
+
+static int mv_usb_wakeup(struct usb_gadget *_gadget)
+{
+    DBGMSG("Call mv_usb_wakeup - NOT supported\n");
+    return 0;
+}
+
+static int mv_usb_set_selfpowered (struct usb_gadget *_gadget, int value)
+{
+    DBGMSG("Call mv_usb_set_selfpowered - NOT supported\n");
+    return 0;
+}
+
+static const struct usb_gadget_ops mv_usb_ops = 
+{
+    .get_frame       = mv_usb_get_frame,
+    .wakeup          = mv_usb_wakeup,
+    .set_selfpowered = mv_usb_set_selfpowered,
+    .ioctl           = NULL,
+};
+
+static void mv_usb_gadget_release (struct device *_dev)
+{
+    struct mv_usb_dev   *usb_dev = dev_get_drvdata (_dev);
+
+    /*mvOsPrintf("Call mv_usb_gadget_release \n");*/
+    mvOsFree(usb_dev);
+}
+
+
+static int __init mv_usb_gadget_probe(struct platform_device *pDev) 
+{
+    struct device	        *_dev = &pDev->dev; 
+    struct mv_usb_dev       *mv_dev;
+    int                     dev_no, retval, i;
+    uint_8                  error;
+
+    /*mvOsPrintf("Call mv_usb_gadget_probe: _dev=%p, pDev=%p\n", _dev, pDev);*/
+
+    for(dev_no=0; dev_no<mvCtrlUsbMaxGet(); dev_no++)
+    {
+        if( (pDev->resource[1].flags == IORESOURCE_IRQ)&& 
+		(!strcmp(pDev->name,usb_dev_name) )&& (pDev->id==dev_no) )
+        {
+            break;
+        }
+    }
+    if(dev_no >= mvCtrlUsbMaxGet())
+    {
+        mvOsPrintf("mv_udc_probe: device is not found\n");
+        return -EINVAL;
+    }
+    mvOsPrintf("USB-%d Gadget driver probed\n", dev_no);
+
+    if (the_controllers[dev_no]) 
+    {
+        mvOsPrintf("mv_dev_load: USB-%d controller is BUSY\n", dev_no);
+        return -EBUSY;
+    }
+
+    /* alloc, and start init */
+    mv_dev = mvOsMalloc (sizeof(struct mv_usb_dev));
+    if (mv_dev == NULL)
+    {
+        mvOsPrintf("mv_dev_load: malloc failed\n");
+        return -ENOMEM;
+    }
+
+    memset (mv_dev, 0, sizeof *mv_dev);
+    spin_lock_init (&mv_dev->lock);
+    mv_dev->dev = _dev; 
+    mv_dev->gadget.ops = &mv_usb_ops;
+    mv_dev->gadget.is_dualspeed = 1;
+
+    /* the "gadget" abstracts/virtualizes the controller */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+    strcpy (mv_dev->gadget.dev.bus_id, "gadget");
+#else
+    dev_set_name(&mv_dev->gadget.dev, "gadget");
+#endif
+    mv_dev->gadget.dev.parent = _dev;
+    mv_dev->gadget.dev.dma_mask = _dev->dma_mask; /* ?????? */
+    mv_dev->gadget.dev.release = mv_usb_gadget_release;
+    mv_dev->gadget.name = driver_name;
+    mv_dev->mv_usb_handle = NULL;
+    mv_dev->dev_no = dev_no;
+
+    dev_set_drvdata(_dev, mv_dev);
+    the_controllers[dev_no] = mv_dev;
+
+#ifdef MV_USB_VOLTAGE_FIX
+
+    mv_dev->vbus_gpp_no = mvUsbGppInit(dev_no);
+    mvOsPrintf("USB gadget device #%d: vbus_gpp_no = %d\n", 
+                    dev_no, mv_dev->vbus_gpp_no);
+
+    if(mv_dev->vbus_gpp_no != (MV_U8)N_A)
+    {
+        if (request_irq (IRQ_GPP_START + mv_dev->vbus_gpp_no, mv_usb_vbus_irq, IRQF_DISABLED, 
+                     driver_name, mv_dev) != 0) 
+        {
+            mvOsPrintf("%s probe: request interrupt %d failed\n", 
+                    driver_name, IRQ_GPP_START + mv_dev->vbus_gpp_no);
+            return -EBUSY;
+        }
+    }
+
+#endif /* MV_USB_VOLTAGE_FIX */
+
+    /* Reset ARC USB device ????? */
+    /* Reinit ARC USB device ????? */
+
+    /* First of all. */
+    _usb_device_set_bsp_funcs(&usbImportFuncs);
+
+#if defined(USB_UNDERRUN_WA)
+
+    if(wa_sram_parts > USB_SRAM_MAX_PARTS)
+    {
+        mvOsPrintf("Wrong <wa_sram_parts> param (%d): Valid range [1 .. %d]\n",
+                wa_sram_parts, USB_SRAM_MAX_PARTS);
+        return -EINVAL;
+    }
+
+    global_wa_funcs = &usbWaFuncs;
+    global_wa_threshold = wa_threshold;
+    global_wa_sram_parts = wa_sram_parts;
+
+    sramBase = mv_sram_usage_get(&sramSize);
+    if(sramBase == NULL)
+    {
+        mvOsPrintf("USB Underrun WA: No free SRAM space\n");
+        return -ENOMEM;
+    }
+    memset(sramBase, 0, sramSize);
+    
+    idma = mv_usb_find_idma_engine(idma);
+    if(idma != -1)
+    {
+        MV_REG_WRITE(IDMA_BYTE_COUNT_REG(idma), 0);
+        MV_REG_WRITE(IDMA_CURR_DESC_PTR_REG(idma), 0);
+        MV_REG_WRITE(IDMA_CTRL_HIGH_REG(idma), ICCHR_ENDIAN_LITTLE 
+#ifdef MV_CPU_LE
+					 | ICCHR_DESC_BYTE_SWAP_EN
+#endif
+					 );
+        MV_REG_WRITE(IDMA_CTRL_LOW_REG(idma), USB_IDMA_CTRL_LOW_VALUE);
+    }
+    mvOsPrintf("USB underrun WA: idma=%d, streaming=%d, threshold=%d, SRAM: base=%p, size=%d, parts=%d\n", 
+                idma, streaming, global_wa_threshold, sramBase, sramSize, global_wa_sram_parts);
+#endif /* USB_UNDERRUN_WA */
+
+    /*_usb_debug_set_flags(MV_USB_GADGET_DEBUG_FLAGS);*/
+
+    /* Enable ARC USB device */
+    retval = (int)_usb_device_init(dev_no, &mv_dev->mv_usb_handle);
+    if (retval != USB_OK) 
+    {
+        mvOsPrintf("\nUSB Initialization failed. Error: %x", retval);
+        return -EINVAL;
+    } /* Endif */
+
+    if( (epin_first < 1) || (epin_first >= _usb_device_get_max_endpoint(mv_dev->mv_usb_handle)) )
+    {
+        mvOsPrintf("\nUSB_%d: epin_first=%d is out of range 1..%d. Use default epin_first=1\n", 
+                    dev_no, epin_first, _usb_device_get_max_endpoint(mv_dev->mv_usb_handle) );
+        epin_first = 1;
+    }
+
+    if( (epout_first < 1) || (epout_first >= _usb_device_get_max_endpoint(mv_dev->mv_usb_handle)) )
+    {
+        mvOsPrintf("\nUSB_%d: epout_first=%d is out of range 1..%d. Use default epout_first=1\n", 
+                    dev_no, epout_first, _usb_device_get_max_endpoint(mv_dev->mv_usb_handle) );
+        epout_first = 1;
+    }
+
+    /* Self Power, Remote wakeup disable */
+    _usb_device_set_status(mv_dev->mv_usb_handle, ARC_USB_STATUS_DEVICE, (1 << DEVICE_SELF_POWERED));
+
+    /* Register all ARC Services */  
+    error = _usb_device_register_service(mv_dev->mv_usb_handle, 
+                                ARC_USB_SERVICE_BUS_RESET, mv_usb_bus_reset_service);
+    if (error != USB_OK) 
+    {
+        mvOsPrintf("\nUSB BUS_RESET Service Registration failed. Error: 0x%x", error);
+        return -EINVAL;
+    } /* Endif */
+   
+    error = _usb_device_register_service(mv_dev->mv_usb_handle, 
+                        ARC_USB_SERVICE_SPEED_DETECTION, mv_usb_speed_service);
+    if (error != USB_OK) 
+    {
+        mvOsPrintf("\nUSB SPEED_DETECTION Service Registration failed. Error: 0x%x", 
+                        error);
+        return -EINVAL;
+    } /* Endif */
+         
+    error = _usb_device_register_service(mv_dev->mv_usb_handle, 
+                                ARC_USB_SERVICE_SUSPEND, mv_usb_suspend_service);
+    if (error != USB_OK) 
+    {
+        mvOsPrintf("\nUSB SUSPEND Service Registration failed. Error: 0x%x", error);
+        return -EINVAL;
+    } /* Endif */
+
+    error = _usb_device_register_service(mv_dev->mv_usb_handle, 
+                                ARC_USB_SERVICE_SLEEP, mv_usb_suspend_service);
+    if (error != USB_OK) 
+    {
+        mvOsPrintf("\nUSB SUSPEND Service Registration failed. Error: 0x%x", error);
+        return -EINVAL;
+    } /* Endif */    
+
+    error = _usb_device_register_service(mv_dev->mv_usb_handle, 
+                                ARC_USB_SERVICE_RESUME, mv_usb_resume_service);
+    if (error != USB_OK) 
+    {
+        mvOsPrintf("\nUSB RESUME Service Registration failed. Error: 0x%x", error);
+        return -EINVAL;
+    } /* Endif */
+
+    error = _usb_device_register_service(mv_dev->mv_usb_handle, 0, 
+                                            mv_usb_ep0_complete_service);   
+    if (error != USB_OK) 
+    {
+        mvOsPrintf("\nUSB ep0 TR_COMPLETE Service Registration failed. Error: 0x%x", error);
+        return error;
+    } /* Endif */
+
+    for (i=1; i<_usb_device_get_max_endpoint(mv_dev->mv_usb_handle); i++)
+    {
+        error = _usb_device_register_service(mv_dev->mv_usb_handle, i, 
+                                                    mv_usb_tr_complete_service);   
+        if (error != USB_OK) 
+        {
+            mvOsPrintf("\nUSB ep0 TR_COMPLETE Service Registration failed. Error: 0x%x", error);
+            return error;
+        } /* Endif */
+    }
+    mv_dev->gadget.speed = USB_SPEED_UNKNOWN;
+
+    if( mv_usb_reinit (mv_dev) != USB_OK)
+        return -EINVAL;
+
+    retval = device_register (&mv_dev->gadget.dev);
+
+#ifdef MV_USB_VOLTAGE_FIX
+
+	if(retval!= USB_OK)
+	{
+		mvOsPrintf("ERROR: %d, device_register() failed\n", retval);
+		return retval;
+	}
+
+	/* create and init kobject */
+ 	retval = mv_usb_initialize_kobject();
+	if(retval != USB_OK)
+	{
+		mvOsPrintf("ERROR: %d, kobject_init() failed\n", retval);
+		return retval;
+	}
+
+#endif /* MV_USB_VOLTAGE_FIX */
+
+    return retval; 
+}
+
+static int __exit mv_usb_gadget_remove(struct platform_device *pDev)
+{
+    int                 i;
+    struct device	    *_dev = &pDev->dev; 
+    struct mv_usb_dev   *mv_dev = dev_get_drvdata(_dev); 
+
+    mvOsPrintf("mv_usb_gadget_remove: mv_dev=%p, driver=%p\n", 
+                mv_dev, mv_dev->driver);
+    /* start with the driver above us */
+    if (mv_dev->driver) 
+    {
+        /* should have been done already by driver model core */
+        mvOsPrintf("pci remove, driver '%s' is still registered\n",
+                    mv_dev->driver->driver.name);
+
+        usb_gadget_unregister_driver (mv_dev->driver);
+    }
+
+    spin_lock (&mv_dev->lock);
+
+    for (i=0; i<_usb_device_get_max_endpoint(mv_dev->mv_usb_handle); i++)
+        _usb_device_unregister_service(mv_dev->mv_usb_handle, i);   
+
+    /* Deregister all other services */
+    _usb_device_unregister_service(mv_dev->mv_usb_handle, ARC_USB_SERVICE_BUS_RESET);   
+    _usb_device_unregister_service(mv_dev->mv_usb_handle, ARC_USB_SERVICE_SPEED_DETECTION);
+
+    _usb_device_unregister_service(mv_dev->mv_usb_handle, ARC_USB_SERVICE_SUSPEND);
+
+    _usb_device_unregister_service(mv_dev->mv_usb_handle, ARC_USB_SERVICE_RESUME);
+
+    _usb_device_shutdown(mv_dev->mv_usb_handle);
+
+    spin_unlock (&mv_dev->lock);
+
+#ifdef MV_USB_VOLTAGE_FIX
+
+    if(mv_dev->vbus_gpp_no != (MV_U8)N_A)
+    {
+        free_irq (IRQ_GPP_START + mv_dev->vbus_gpp_no, mv_dev); 
+    }
+    /* delete kobject */
+	kobject_del(&mv_usb_device.kobj);
+
+#endif /* MV_USB_VOLTAGE_FIX */
+
+    the_controllers[mv_dev->dev_no] = 0;
+    device_unregister (&mv_dev->gadget.dev);
+
+    kfree(mv_dev);
+
+    dev_set_drvdata(_dev, 0);
+    return 0;
+}
+ 
+
+/* global variables from 'regdump' */
+static struct proc_dir_entry *usb_resource_dump;
+static u32  usb_resource_dump_result;
+
+int usb_resource_dump_write (struct file *file, const char *buffer,
+                      unsigned long count, void *data) 
+{
+    return 0;
+}
+
+int usb_resource_dump_read (char *buffer, char **buffer_location, off_t offset,
+                            int buffer_length, int *zero, void *ptr) 
+{
+    int                 i, dev;
+    static int          count = 0;
+    struct mv_usb_dev*  mv_dev;
+
+    printk("usb_resource_dump_read_%-3d\n",  count);
+    if(offset > 0)
+        return 0;
+
+    count++;
+    usb_resource_dump_result = count;
+
+    for(dev=0; dev<mvCtrlUsbMaxGet(); dev++)
+    {
+        mv_dev = the_controllers[dev];
+
+        if(mv_dev != NULL)
+        {
+            mv_usb_show(mv_dev, 0xff);
+
+            _usb_ep_status(mv_dev->mv_usb_handle, 0, ARC_USB_RECV);
+            _usb_ep_status(mv_dev->mv_usb_handle, 0, ARC_USB_SEND);
+
+            for(i=1; i<_usb_device_get_max_endpoint(mv_dev->mv_usb_handle); i++)
+            {
+                struct mv_usb_ep    *ep;
+
+                /* OUT endpoint (RECV) */ 
+                ep = &mv_dev->ep[i*2];
+                if(ep->is_enabled)
+                    _usb_ep_status(mv_dev->mv_usb_handle, i, ARC_USB_RECV);
+
+                /* IN endpoint (SEND) */
+                ep = &mv_dev->ep[i*2+1];
+                if(ep->is_enabled)
+                    _usb_ep_status(mv_dev->mv_usb_handle, i, ARC_USB_SEND);
+            }
+        }
+    }
+    return sprintf(buffer, "%x\n", usb_resource_dump_result);
+}
+
+int usb_start_resource_dump(void)
+{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+  usb_resource_dump = create_proc_entry ("usb_dump" , 0666 , &proc_root);
+#else
+  usb_resource_dump = create_proc_entry ("usb_dump" , 0666, 0);
+#endif
+  usb_resource_dump->read_proc = usb_resource_dump_read;
+  usb_resource_dump->write_proc = usb_resource_dump_write;
+  usb_resource_dump->nlink = 1;
+  return 0;
+}
+/*
+static struct device_driver mv_usb_gadget_driver = 
+{
+    .name       = (char *) driver_name,
+    .id_table   = NULL,
+    .bus        = &platform_bus_type,
+    .probe      = mv_usb_gadget_probe,
+    .remove     = __exit_p(mv_usb_gadget_remove), 
+};
+*/
+
+static struct platform_driver mv_usb_gadget_driver = {
+        .probe          = mv_usb_gadget_probe,
+        .remove         = __exit_p(mv_usb_gadget_remove),
+        .id_table       = NULL,
+        .driver = {
+                .name = driver_name,
+                .bus = &platform_bus_type
+        }
+};
+
+MODULE_VERSION (DRIVER_VERSION);
+MODULE_DESCRIPTION (DRIVER_DESC);
+MODULE_AUTHOR ("Dima Epshtein");
+MODULE_LICENSE ("GPL");
+
+static int __init init (void)
+{
+    int dev_no;
+
+    mvOsPrintf("%s: version %s loaded\n", driver_name, DRIVER_VERSION);
+    for(dev_no=0; dev_no<mvCtrlUsbMaxGet(); dev_no++)
+    {
+	    the_controllers[dev_no] = NULL;
+    }
+    usb_start_resource_dump();
+    return platform_driver_register(&mv_usb_gadget_driver); 
+}
+module_init (init);
+
+static void __exit cleanup (void)
+{
+    mvOsPrintf("%s: version %s unloaded\n", driver_name, DRIVER_VERSION);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+    remove_proc_entry("usb_dump" , &proc_root);
+#else
+    remove_proc_entry("usb_dump", NULL);
+#endif
+    platform_driver_unregister(&mv_usb_gadget_driver);
+}
+module_exit (cleanup);
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_xor/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_xor/Kconfig
new file mode 100644
index 0000000..83aea75
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_xor/Kconfig
@@ -0,0 +1,87 @@
+config MV_XOR_NET_DMA
+        bool "Use the XOR engine as NET DMA"
+        depends on NET_DMA
+        default n
+        help
+          Invokes XOR as NET DMA engine
+
+config MV_USE_XOR_ENGINE
+        bool "Use the XOR engines to offload CPU tasks"   
+        depends on (MV_INCLUDE_XOR) && EXPERIMENTAL
+        default n
+        help
+            Say Y of you want to use the XOR engine to offload some of the 
+            CPU tasks.
+
+config MV_XOR_MEMCOPY
+        bool "Use the XOR engine to accelerate memcpy()"
+        depends on MV_USE_XOR_ENGINE
+        default n
+        help
+          Say Y here if you want to use the XOR engine to perform
+          the memcpy and memmove.
+
+config MV_XOR_MEMCOPY_THRESHOLD
+        int "Minimum number of bytes to use XOR acceleration for memcpy()"
+        depends on MV_XOR_MEMCOPY
+        default "128"
+        help
+          This is the minimum buffer size needed in order to operate the XOR engine
+          for accelerating the memcpy() operations
+
+config MV_XOR_MEMXOR
+        bool "Use the XOR engine to perform xor bitmap calculations"
+        depends on MV_USE_XOR_ENGINE
+        default n
+        help
+          Say Y to accelerate the RAID4/5 xor bitmap calculations.
+
+config MV_XOR_MEMXOR_THRESHOLD
+        int "Minimum number of bytes to perform xor bitmap calculations"
+        depends on MV_XOR_MEMXOR
+        default "4096"
+        help
+          This is the minimum buffer size to operate the XOR engine
+          for xor bitmap operations
+
+config MV_XOR_COPY_TO_USER
+	bool "Use XOR hardware to accelerate copy_to_user function"
+	depends on MV_USE_XOR_ENGINE
+	default n
+	help
+	  Say Y here to accelerate the copy_to_user function
+
+config MV_XOR_COPY_TO_USER_THRESHOLD
+        int "A threshold to employ XOR hardware for copy_to_user()"
+        depends on MV_XOR_COPY_TO_USER
+        default "1260"
+        help
+          This is the minimum buffer size required to operate XOR engine
+          to accelerate the copy_to_user() operation.
+
+config MV_XOR_COPY_FROM_USER
+	bool "Use XOR hardware to accelerate copy_from_user function"
+	depends on MV_USE_XOR_ENGINE
+	default n
+	help
+	  Say Y here to accelerate the copy_from_user function
+
+config MV_XOR_COPY_FROM_USER_THRESHOLD
+        int "A threshold to employ XOR hardware for copy_from_user()"
+        depends on MV_XOR_COPY_FROM_USER
+        default "1260"
+        help
+          This is the minimum buffer size required to operate XOR engine
+          to accelerate the copy_from_user() operation.
+
+config MV_XOR_CHANNELS
+        int "Number of XOR channels"
+        depends on MV_USE_XOR_ENGINE
+        range 1 4
+        default 2
+	help
+	  Select the number of XOR channels to be used for kernel functions
+	  accelerations.
+#endmenu
+
+##source	"drivers/dma/Kconfig"
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_xor/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_xor/Makefile
new file mode 100644
index 0000000..5a94a9b
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_xor/Makefile
@@ -0,0 +1,12 @@
+#
+# Makefile for the Marvell XOR/DMA Driver
+#
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+obj-$(CONFIG_MV_USE_XOR_ENGINE) += mv_netdma.o
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_xor/mv_netdma.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_xor/mv_netdma.c
new file mode 100644
index 0000000..39d0be6
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_xor/mv_netdma.c
@@ -0,0 +1,1619 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell 
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or 
+modify this File in accordance with the terms and conditions of the General 
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is 
+available along with the File in the license.txt file or by writing to the Free 
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or 
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt. 
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED 
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY 
+DISCLAIMED.  The GPL License provides additional details about this warranty 
+disclaimer.
+*******************************************************************************/
+
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/string.h>
+#include <linux/sysdev.h>
+#include <linux/version.h>
+#include <asm/uaccess.h>
+#include <linux/proc_fs.h>
+#include <linux/dmaengine.h>
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "xor/mvXor.h"
+#include "xor/mvXorRegs.h"
+#include "mvSysXorApi.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+
+#define DUBUG
+#undef DEBUG
+#ifdef DEBUG
+#define DPRINTK(s, args...)  printk("xor: " s, ## args)
+#else
+#define DPRINTK(s, args...)
+#endif
+
+/* 
+ * Perform integrity test.
+ * Upon completion of xor dma operation, 
+ * each descriptor will be checked to success bit.
+ */
+#define XOR_INTEGRITY
+#undef XOR_INTEGRITY
+
+/* 
+ * Double invalidate WA
+ */
+#ifdef CONFIG_MV_SP_I_FTCH_DB_INV
+#define XOR_UNMAP
+#endif
+
+/* 
+ * Perform benchmark
+ */
+#define XOR_BENCH
+#undef XOR_BENCH
+
+
+#define XOR_STATS
+//#undef XOR_STATS
+#ifdef XOR_STATS
+#define STAT_INC(s) 	xor_stats->s++
+#define STAT_ADD(s,n) 	xor_stats->s[((n)>>STAT_SHIFT)&(STAT_BYTES-1)]++
+#define STAT_SHIFT	7
+#define STAT_BYTES	(1 << 9)
+#else
+#define STAT_INC(s)
+#define STAT_ADD(s,n)
+#endif
+#if defined (CONFIG_MV_XOR_MEMCOPY) || defined (CONFIG_MV_IDMA_MEMCOPY)
+#define memcpy asm_memcpy
+#endif
+
+#define XOR_BUG(c) if (c) {xor_dump(); BUG();}
+
+#define CHANNELS    		CONFIG_MV_XOR_CHANNELS
+#define ENGINES    			(CHANNELS >> 1)
+#define XOR_TIMEOUT 		0x8000000
+#define XOR_MIN_COPY_CHUNK 	16		/* A0 specification */
+#define NET_DESC 			128		/* NET DMA descriptors */
+#define DMA_DESC 			2		/* memcpy descriptors */
+
+#define to_dma_channel(dch) container_of(dch, struct xor_dma_channel, common)
+
+enum {
+	CHAIN_NETDMA = CHANNELS,
+#ifdef CONFIG_MV_XOR_MEMCOPY
+	CHAIN_MEMCPY,
+#endif
+#ifdef CONFIG_MV_XOR_MEMXOR
+	CHAIN_MEMXOR,
+#endif
+#ifdef CONFIG_MV_XOR_COPY_TO_USER
+	CHAIN_TO_USR,
+#endif
+#ifdef CONFIG_MV_XOR_COPY_FROM_USER
+	CHAIN_FROM_USR,
+#endif
+	CHAINS,
+};
+
+typedef MV_XOR_DESC xor_desc_t;
+
+struct xor_chain {
+	unsigned int 		idx;
+	unsigned int		pending;
+	xor_desc_t*    		desc;			/* N descriptors 	*/
+	dma_addr_t     	 	base;			/* phy address  	*/
+	struct xor_channel*	owner;			/* owned by channel	*/
+	unsigned int		busy;			/* busy by cpu		*/
+	unsigned int		cookie_used;	/* last used 		*/
+	unsigned int		cookie_done;	/* last completed 	*/
+};
+
+struct xor_channel {
+	unsigned int 		idx;
+	unsigned int		busy;
+	struct xor_chain* 	chain;			/* busy on chain	*/
+	unsigned int		pad;
+};
+
+#ifdef CONFIG_MV_XOR_NET_DMA
+struct xor_dma_device {
+	struct dma_device common;
+};
+
+struct xor_dma_channel {
+	struct dma_chan		common;
+	struct xor_chain* 	chain;
+	spinlock_t 			lock;
+};
+#endif
+
+struct xor_net_stats
+{
+#ifdef XOR_STATS
+	unsigned int err_chann_busy;
+	unsigned int err_chain_busy;
+	unsigned int err_addr;
+	unsigned int err_dma;
+
+#ifdef CONFIG_MV_XOR_NET_DMA
+	unsigned int netdma_b2p;
+	unsigned int netdma_p2p;
+	unsigned int netdma_b2b;
+	unsigned int netdma_cpu;
+	unsigned int netdma_dma;
+	unsigned int netdma_complete;
+	unsigned int netdma_pending;
+	unsigned int netdma_bytes[STAT_BYTES];
+#endif
+#ifdef CONFIG_MV_XOR_MEMCOPY
+	unsigned int memcp;
+	unsigned int memcp_dma;
+	unsigned int memcp_bytes[STAT_BYTES];
+#endif
+#ifdef CONFIG_MV_XOR_MEMXOR
+	unsigned int memxor;
+	unsigned int memxor_dma;
+	unsigned int memxor_bytes[STAT_BYTES];
+#endif
+#ifdef CONFIG_MV_XOR_COPY_TO_USER
+	unsigned int to_usr;
+	unsigned int to_usr_dma;
+	unsigned int to_usr_bytes[STAT_BYTES];		
+#endif
+#ifdef CONFIG_MV_XOR_COPY_FROM_USER
+	unsigned int from_usr;
+	unsigned int from_usr_dma;
+	unsigned int from_usr_bytes[STAT_BYTES];		
+#endif
+#endif
+};
+
+#ifdef CONFIG_MV_XOR_NET_DMA
+static struct xor_dma_device xor_dma_dev;
+static struct xor_dma_channel xor_dma_chn[1];
+#endif
+
+struct xor_channel* xor_channels;
+struct xor_chain* xor_chains;
+struct xor_net_stats* xor_stats;
+
+static unsigned int xor_enabled __read_mostly;
+
+
+
+/*
+ * channel busy test
+ */
+static inline unsigned int xor_is_active(unsigned int i)
+{
+	return MV_REG_READ(XOR_ACTIVATION_REG(XOR_UNIT(i),XOR_CHAN(i))) 
+			/* & XEXACTR_XESTATUS_MASK */;
+}
+
+/*
+ * set dma operation mode for channel i
+ */
+static inline void xor_mode_dma(unsigned int i)
+{
+	unsigned int mode = MV_REG_READ(XOR_CONFIG_REG(XOR_UNIT(i),XOR_CHAN(i)));
+	mode &= ~XEXCR_OPERATION_MODE_MASK;
+	mode |= XEXCR_OPERATION_MODE_DMA;
+	MV_REG_WRITE(XOR_CONFIG_REG(XOR_UNIT(i), XOR_CHAN(i)), mode);
+}
+
+/*
+ * set xor operation mode for channel i
+ */
+static inline void xor_mode_xor(unsigned int i)
+{
+	unsigned int mode = MV_REG_READ(XOR_CONFIG_REG(XOR_UNIT(i),XOR_CHAN(i)));
+	mode &= ~XEXCR_OPERATION_MODE_MASK;
+	mode |= XEXCR_OPERATION_MODE_XOR;
+	MV_REG_WRITE(XOR_CONFIG_REG(XOR_UNIT(i), XOR_CHAN(i)), mode);
+}
+
+/*
+ * run dma operation on channel
+ */
+static inline void xor_dma(unsigned int i, unsigned int base)
+{
+#ifdef MV_BRIDGE_SYNC_REORDER
+	mvOsBridgeReorderWA();
+#endif
+	MV_REG_WRITE(XOR_NEXT_DESC_PTR_REG(XOR_UNIT(i), XOR_CHAN(i)), base);                    
+	MV_REG_WRITE(XOR_ACTIVATION_REG(XOR_UNIT(i), XOR_CHAN(i)), XEXACTR_XESTART_MASK);
+}
+
+/*
+ * xor engine busy wait
+ */
+static void xor_dump(void);
+#define XOR_CAUSE_DONE_MASK(chan) ((BIT0|BIT1) << (chan * 16))
+void xor_wait(unsigned int chan)
+{
+    unsigned int timeout;
+	unsigned int addr = XOR_CAUSE_REG(XOR_UNIT(chan));
+	unsigned int mask = XOR_CAUSE_DONE_MASK(XOR_CHAN(chan));
+
+	timeout = XOR_TIMEOUT;
+    while(!(MV_REG_READ(addr) & mask))
+		XOR_BUG(!timeout--);			
+
+	MV_REG_WRITE(addr, ~mask);
+
+    timeout = XOR_TIMEOUT;
+	while(xor_is_active(chan))
+		XOR_BUG(!timeout--);
+}
+
+/*
+ * Second L2 invalidate (WA)
+ */
+#ifdef XOR_UNMAP
+static void xor_chain_unmap(struct xor_chain* chain)
+{
+	u32 va;
+	u32 i = chain->pending;
+	xor_desc_t* desc = chain->desc;
+	unsigned long flags;
+
+	raw_local_irq_save(flags);
+
+	while(i--) {
+		va = __phys_to_virt(desc->phyDestAdd);
+		/* invalidate l2 */
+		__asm__ __volatile__ ("mcr p15, 1, %0, c15, c11, 4" : : "r" (va));
+		__asm__ __volatile__ ("mcr p15, 1, %0, c15, c11, 5" : : "r" (va+desc->byteCnt-1));
+		desc++;
+	}
+
+	raw_local_irq_restore(flags);
+}
+#endif
+/*
+ * Chain integrity test
+ */
+#ifdef XOR_INTEGRITY
+static void xor_integrity(struct xor_chain* chain)
+{
+	unsigned int i;
+
+	for (i=0; i<chain->pending; i++) {
+		mvOsCacheLineInv(0, chain->desc + i);
+		mvOsCacheIoSync();
+		if (chain->desc[i].status != 0x40000000) {
+			printk("XOR: violation chain[%d] desc=%d status=%x active=%d %x<-%x %d bytes\n", 
+				   chain->idx, i, 
+				   chain->desc[i].status,
+				   xor_is_active(chain->idx),
+				   chain->desc[i].phyDestAdd, chain->desc[i].srcAdd0, chain->desc[i].byteCnt);
+		}
+	}
+}
+#endif
+
+static void xor_dump(void)
+{
+	unsigned int i;
+
+	for (i=0; i<CHANNELS; i++) {
+		printk(" CHANNEL_ARBITER_REG %08x\n", MV_REG_READ(XOR_CHANNEL_ARBITER_REG(XOR_UNIT(i))));
+		printk(" CONFIG_REG          %08x\n", MV_REG_READ(XOR_CONFIG_REG(XOR_UNIT(i),XOR_CHAN(i))));
+		printk(" ACTIVATION_REG      %08x\n", MV_REG_READ(XOR_ACTIVATION_REG(XOR_UNIT(i), XOR_CHAN(i))));
+		printk(" CAUSE_REG           %08x\n", MV_REG_READ(XOR_CAUSE_REG(XOR_UNIT(i))));
+		printk(" MASK_REG            %08x\n", MV_REG_READ(XOR_MASK_REG(XOR_UNIT(i))));
+		printk(" ERROR_CAUSE_REG     %08x\n", MV_REG_READ(XOR_ERROR_CAUSE_REG(XOR_UNIT(i))));
+		printk(" ERROR_ADDR_REG      %08x\n", MV_REG_READ(XOR_ERROR_ADDR_REG(XOR_UNIT(i))));
+		printk(" NEXT_DESC_PTR_REG   %08x\n", MV_REG_READ(XOR_NEXT_DESC_PTR_REG(XOR_UNIT(i),XOR_CHAN(i))));
+		printk(" CURR_DESC_PTR_REG   %08x\n", MV_REG_READ(XOR_CURR_DESC_PTR_REG(XOR_UNIT(i),XOR_CHAN(i))));
+		printk(" BYTE_COUNT_REG      %08x\n\n", MV_REG_READ(XOR_BYTE_COUNT_REG(XOR_UNIT(i),XOR_CHAN(i))));
+	}
+
+	for (i=0; i<CHANNELS; i++) {
+		printk("channel[%d] active=0x%x busy=%d chain=%x\n", 
+						xor_channels[i].idx,
+						xor_is_active(i), 
+						xor_channels[i].busy, 
+						xor_channels[i].chain ? xor_channels[i].chain->idx : ~0);
+	}
+
+	for (i=0; i<CHAINS; i++) {		
+		printk("chain[%d] on channel=%8x desc=%x cookies(%x,%x) pending=%d\n", i,
+						xor_chains[i].owner ? xor_chains[i].owner->idx : ~0,
+						xor_chains[i].base, 
+						xor_chains[i].cookie_done,
+						xor_chains[i].cookie_used,
+						xor_chains[i].pending);
+	}
+}
+
+static void xor_stat(void)
+{	
+#ifdef XOR_STATS
+		int i;
+
+		printk("XOR errors...........%10u\n", xor_stats->err_dma);
+		printk("XOR busy channel.....%10u\n", xor_stats->err_chann_busy); 
+		printk("XOR busy chain.......%10u\n", xor_stats->err_chain_busy);
+		printk("XOR invalid address..%10u\n", xor_stats->err_addr);
+#ifdef CONFIG_MV_XOR_NET_DMA
+		printk("\n");
+		printk("NETDMA b2p...........%10u\n", xor_stats->netdma_b2p);
+		printk("NETDMA p2p...........%10u\n", xor_stats->netdma_p2p);
+		printk("NETDMA b2b...........%10u\n", xor_stats->netdma_b2b);
+		printk("NETDMA by cpu........%10u\n", xor_stats->netdma_cpu);
+		printk("NETDMA by hw.........%10u\n", xor_stats->netdma_dma);
+		printk("NETDMA pending.......%10u\n", xor_stats->netdma_pending);
+		printk("NETDMA complete......%10u\n", xor_stats->netdma_complete);
+#endif
+#ifdef CONFIG_MV_XOR_MEMCOPY
+		printk("\n");
+		printk("MEMCPY total.........%10u\n", xor_stats->memcp);
+		printk("MEMCPY by hw.........%10u\n", xor_stats->memcp_dma);
+#endif
+#ifdef CONFIG_MV_XOR_MEMXOR
+		printk("\n");
+		printk("MEMXOR total.........%10u\n", xor_stats->memxor);
+		printk("MEMXOR by hw.........%10u\n", xor_stats->memxor_dma);
+#endif
+#ifdef CONFIG_MV_XOR_COPY_TO_USER
+		printk("\n");
+		printk("TO_USER total.........%10u\n", xor_stats->to_usr);
+		printk("TO_USER by hw.........%10u\n", xor_stats->to_usr_dma);
+#endif
+#ifdef CONFIG_MV_XOR_COPY_FROM_USER
+		printk("\n");
+		printk("FROM_USER total.........%10u\n", xor_stats->from_usr);
+		printk("FROM_USER by hw.........%10u\n", xor_stats->from_usr_dma);
+#endif
+
+		printk("BYTES  NETDMA   MEMCPY   MEMXOR   TO_USER  FROM_USER\n");
+		for (i=0; i<STAT_BYTES; i++) {
+			u32 a=0, b=0, c=0, d=0, e=0;
+#ifdef CONFIG_MV_XOR_NET_DMA
+			a = xor_stats->netdma_bytes[i];
+#endif
+#ifdef CONFIG_MV_XOR_MEMCOPY
+			b = xor_stats->memcp_bytes[i];
+#endif
+#ifdef CONFIG_MV_XOR_MEMXOR
+			c = xor_stats->memxor_bytes[i];
+#endif
+#ifdef CONFIG_MV_XOR_COPY_TO_USER
+			d = xor_stats->to_usr_bytes[i];
+#endif
+#ifdef CONFIG_MV_XOR_COPY_FROM_USER
+			e = xor_stats->from_usr_bytes[i];
+#endif
+			if (a || b || c || d || e)
+				printk("%5d%8u %8u %8u %8u %8u\n", i<<STAT_SHIFT, a, b, c, d, e);
+		}
+
+		memset(xor_stats, 0, sizeof(struct xor_net_stats));
+#endif       
+}
+
+/*
+ * Allocate chain
+ */
+static inline unsigned int xor_try_chain(struct xor_chain* chain)
+{
+	unsigned long flags=0;
+	local_irq_save(flags);	
+	if (chain->busy) {
+		local_irq_restore(flags);
+		STAT_INC(err_chain_busy);
+		return 1;
+	}
+	chain->busy = 1;
+	local_irq_restore(flags);
+	return 0;
+}
+
+/*
+ * Connect channel to chain
+ */
+static inline void xor_attach(struct xor_chain* chain, struct xor_channel* xch)
+{
+	xch->chain = chain;
+	chain->owner = xch;
+}
+
+/*
+ * Disconnect channel and chain
+ */
+static inline void xor_detach(struct xor_chain* chain, struct xor_channel* xch)
+{
+#ifdef XOR_INTEGRITY
+	xor_integrity(chain);
+#endif	
+#ifdef XOR_UNMAP
+	if (chain->pending) 
+		xor_chain_unmap(chain);
+#endif
+	chain->cookie_done = chain->cookie_used;
+	chain->pending = 0;
+	chain->owner = NULL;
+	chain->busy = 0;
+	xch->chain = NULL;
+}
+
+/*
+ * Allocate channel
+ */
+static struct xor_channel* xor_get(void)
+{
+    static int rr=0;
+	int retry=CHANNELS;
+	struct xor_channel* xch = NULL;	
+	unsigned long flags=0;
+
+	local_irq_save(flags);
+
+	rr += ENGINES;
+
+	while(retry--) { 
+		rr &= (CHANNELS-1);
+
+		if (xor_channels[rr].busy || xor_is_active(rr)) {
+			rr++;
+			continue;
+		}
+	
+		xch = &xor_channels[rr];
+		xch->busy = 1;
+
+		if (xch->chain)
+			xor_detach(xch->chain, xch);
+
+		break;
+	}
+
+	local_irq_restore(flags);
+
+	if (!xch) 
+		STAT_INC(err_chann_busy);
+
+	return xch;
+}
+
+static inline void xor_put(struct xor_channel* xch)
+{
+	xch->busy = 0;
+}
+
+/*
+ * Fast clean, dsb() required
+ * The call is intended for multiple calls and when dsb() on commit endpoint
+ */
+static inline void dmac_clean_dcache_line(void* addr)
+{
+//#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+	__asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 1" : : "r" (addr));
+	__asm__ __volatile__ ("mcr p15, 1, %0, c15, c9, 1" : : "r" (addr));
+
+//#else
+//	dma_cache_maint(addr, 32, DMA_TO_DEVICE);
+//#endif
+}
+
+#ifdef CONFIG_MV_XOR_NET_DMA
+static int xor_alloc_chan_resources(struct dma_chan *dch)
+{
+	return 1;
+}
+
+static void xor_free_chan_resources(struct dma_chan *dch)
+{
+	printk("xor: free netdma chain[%d] resources\n", dch->chan_id);
+}
+
+/*
+ *  Start xmit of chain 
+ */
+static struct xor_chain* xor_xmit(struct xor_chain* chain)
+{
+	struct xor_channel* xch;
+	int i;
+
+	xch = xor_get();
+	if (!xch) 
+		goto out;
+
+	xor_attach(chain, xch);
+
+	i = chain->pending;
+	while(i--)
+		dmac_clean_dcache_line(chain->desc + i);
+	dsb();
+
+	STAT_INC(netdma_dma);
+	xor_dma(xch->idx, chain->base);
+	xor_put(xch);
+
+	/*
+	 * find free chain,
+	 * always succedded since chains >> channels
+	 */
+	i = CHAIN_NETDMA;
+	while(i--) {	
+		if (likely(chain->idx < CHAIN_NETDMA))
+			chain++;
+		else
+			chain = xor_chains;
+
+		if (chain->owner)
+			continue;
+			
+		if (chain->busy)
+			continue;
+
+        chain->busy = 1;
+		break;
+	}
+
+out:
+	return chain;	
+}
+
+static dma_cookie_t xor_memcpy_buf_to_pg(struct dma_chan *chan,
+										 struct page *page, unsigned int offset, void *_from, size_t n)
+{
+	u32 to, from=(u32)_from;
+	xor_desc_t* desc;
+	struct xor_dma_channel* dch = to_dma_channel(chan);
+	struct xor_chain* chain;
+	int irq = in_interrupt();
+	u32 c;
+
+	STAT_INC(netdma_b2p);
+	STAT_ADD(netdma_bytes, n);
+
+	to = (u32)page_address(page) + offset;
+
+	DPRINTK("%s: %p<-%p %d bytes\n", __FUNCTION__, to, from, n);
+
+	if (!virt_addr_valid(to) || !virt_addr_valid(from)) {
+		STAT_INC(err_addr);
+		goto out;
+	}
+
+	/* at least two cache lines or XOR minimum */
+	if (n < 96)
+		goto out;
+
+	if (to & 31) {
+		c = 32 - (to & 31);
+		memcpy((void*)to, (void*)from, c);
+		to += c;
+		from += c;
+		n -= c;
+	}
+
+	c = (to+n) & 31;
+	if (c) {
+		n -= c;
+		memcpy((void*)to+n, (void*)from+n, c);
+	}
+
+	if (n < 32) 
+		goto out;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+	dmac_clean_range((void*)from, (void*)from + n);
+	dmac_inv_range((void*)to, (void*)to + n);
+#else
+	dma_cache_maint((void*)from, n, DMA_TO_DEVICE);
+	dma_cache_maint((void*)to, n, DMA_FROM_DEVICE);
+#endif
+
+	if (!irq)
+		spin_lock_bh(&dch->lock);
+
+	chain = dch->chain; 
+
+	XOR_BUG(chain->owner || chain->pending>=NET_DESC);
+
+	desc = chain->desc + chain->pending++;
+	desc->srcAdd0 = __pa((void*)from);
+	desc->phyDestAdd = __pa((void*)to);	
+	desc->byteCnt = n;
+	desc->status = BIT31;
+
+	if (chain->pending == 1)
+		chain->cookie_done = chan->cookie;
+
+	if (++chan->cookie < 0)
+		chan->cookie = 1;
+
+	chain->cookie_used = chan->cookie;
+
+    if (chain->pending > 1)
+		dch->chain = xor_xmit(chain);
+
+	if (!irq)
+		spin_unlock_bh(&dch->lock);
+
+	return chan->cookie;
+
+out:
+	STAT_INC(netdma_cpu);
+	memcpy((void*)to, (void*)from, n);
+	return chan->cookie;
+}
+
+static dma_cookie_t xor_memcpy_pg_to_pg(struct dma_chan *chan,
+									struct page *dest_pg, unsigned int dest_off,
+									struct page *src_pg, unsigned int src_off, size_t n)
+{
+	STAT_INC(netdma_p2p);
+	return xor_memcpy_buf_to_pg(chan,
+								dest_pg, 
+								dest_off, 
+								(void*)((u32)page_address(src_pg) + src_off), n);
+}
+
+static dma_cookie_t xor_memcpy_buf_to_buf(struct dma_chan *chan,void *dest, void *src, size_t n)
+{
+	/* kernel copies (e.g. smbfs) 
+	 * not really tested
+	 */
+	STAT_INC(netdma_b2b);
+	return xor_memcpy_buf_to_pg(chan,
+								page_address(dest),
+								page_offset(dest),
+								src, n);
+}
+
+/*
+ * cookies compare
+ */
+static inline int before(__s32 c1, __s32 c2)
+{
+	/*
+	 * Cookies are continuous. 
+	 * The distance between cookies should not exceed FFFF,
+	 * otherwise is considered as overflow.
+	 */
+	if (c1 <= c2) 
+		return (c2 - c1) <= 0xFFFF;
+    else 
+		return (c1 - c2) > 0xFFFF;
+}
+
+/*
+ * Find completed cookie across all chains. 
+ * Each one has [done,used] section. If for sections done=used, report max,
+ * otherwise, the minimum 'done' is returned.
+ */
+static /*inline*/ dma_cookie_t xor_get_completed(void)
+{
+	dma_cookie_t min_cookie = 0;
+	dma_cookie_t max_cookie = 0;
+	dma_cookie_t c_used, c_done;
+
+	struct xor_chain* chain = xor_chains;
+	int i = CHAIN_NETDMA;
+
+	do {
+			c_used = chain->cookie_used;
+			c_done = chain->cookie_done;
+
+			if (c_used != c_done) {
+				if (chain->owner && !xor_is_active(chain->owner->idx)) {
+					c_used = c_done = chain->cookie_used;
+				}
+			}
+
+			if (c_used != c_done) {
+			/*
+			 * at least one chain is incomplete. 
+			 * find minimal cookie which is done across all chains
+			 */		
+				if (!min_cookie || before(c_done, min_cookie))
+					min_cookie = c_done;
+			}
+
+			/*
+			 * in the case whether all chains are completed, 
+			 * find their max cookie
+			 */		
+			else if (!c_done)  {
+				;
+			}
+			else if (!max_cookie || before(max_cookie, c_done))
+					max_cookie = c_done;
+
+			chain++;
+
+	} while(i--);
+
+	return min_cookie ? min_cookie: max_cookie;
+}
+#ifdef XOR_UNMAP
+static void xor_memcpy_cleanup(struct dma_chan *chan, dma_cookie_t cookie)
+{
+	struct xor_chain* chain = xor_chains;
+	struct xor_dma_channel* dch = to_dma_channel(chan);
+	int i = CHAIN_NETDMA;
+
+	spin_lock_bh(&dch->lock);
+
+	do {
+		if (chain->owner && 
+			chain->pending && !xor_is_active(chain->owner->idx)) {
+				xor_detach(chain, chain->owner);
+		}
+
+		chain++;
+
+	} while(i--);
+
+	spin_unlock_bh(&dch->lock);
+}
+#endif
+
+static enum dma_status xor_memcpy_complete(struct dma_chan *chan,
+										dma_cookie_t cookie, 
+										dma_cookie_t *pdone,
+										dma_cookie_t *pused)
+{
+	dma_cookie_t done;
+	dma_cookie_t used;
+	enum dma_status ret;
+
+	STAT_INC(netdma_complete);
+
+	done = xor_get_completed();
+	used = chan->cookie;
+	
+	if (pdone)
+		*pdone = done;
+	if (pused)
+		*pused = used;
+
+	ret = dma_async_is_complete(cookie, done, used);
+#ifdef XOR_UNMAP
+	if (ret == DMA_SUCCESS)
+		xor_memcpy_cleanup(chan, cookie);
+#endif
+
+	return ret;
+}
+
+static void xor_memcpy_issue_pending(struct dma_chan *chan)
+{
+	struct xor_dma_channel* dch = to_dma_channel(chan);
+	struct xor_chain* chain;
+	unsigned int irq = in_interrupt();
+
+	STAT_INC(netdma_pending);
+
+	chain = dch->chain;
+	if (chain->owner)
+		return;
+
+	if (!irq)
+		spin_lock_bh(&dch->lock);
+
+	chain = dch->chain;
+
+	if (!chain->owner && chain->pending) {
+		do {
+			dch->chain = xor_xmit(chain);
+		} while (dch->chain == chain);
+	}
+ 
+	if (!irq)
+		spin_unlock_bh(&dch->lock);
+}
+#endif /* CONFIG_MV_XOR_NET_DMA */
+
+static int xor_proc_write(struct file *file, const char __user *buffer,
+			   unsigned long count, void *data)
+{
+#ifdef XOR_BENCH
+	xor_bench(NULL,NULL,0);
+#endif
+	return count;
+}
+
+static int xor_proc_read(char *page, char **start, off_t off, 
+						 int count, int *eof, void *data)
+{
+	xor_dump();
+	xor_stat();
+	return 0;
+}
+
+int __init mv_xor_init(void)
+{
+		unsigned int i;
+		struct proc_dir_entry *proc_e;
+		struct xor_chain* chain;
+		u32 va;	
+
+		if ((MV_FALSE == mvCtrlPwrClckGet(XOR_UNIT_ID, 0)) || 
+		    (MV_FALSE == mvCtrlPwrClckGet(XOR_UNIT_ID, 1)))
+		{
+			printk("\nWarning at least one XOR port is Powered Off\n");
+			return 0;
+			
+		}
+	
+
+#if defined(CONFIG_MV78200) || defined(CONFIG_MV632X)
+		if (MV_FALSE == mvSocUnitIsMappedToThisCpu(XOR)) {
+			printk(KERN_INFO"XOR engine is not mapped to this CPU\n");
+			return -ENODEV;
+		}	
+#endif
+
+		mvSysXorInit();
+
+		/* stats */
+		va = (u32)kmalloc(32 + (sizeof(struct xor_net_stats)), GFP_KERNEL);
+		va += 32 - (va & 31);
+		xor_stats = (struct xor_net_stats*)va;
+		memset(xor_stats, 0, sizeof(struct xor_net_stats));
+
+		/* channels */
+		va = (u32)kmalloc(32 + (sizeof(struct xor_channel) * CHANNELS), GFP_KERNEL);
+		va += 32 - (va & 31);
+		xor_channels = (struct xor_channel*)va;
+		memset(xor_channels, 0, sizeof(struct xor_channel) * CHANNELS);
+
+		/* chains */
+		va = (u32)kmalloc(32 + (sizeof(struct xor_chain) * CHAINS), GFP_KERNEL);
+		va += 32 - (va & 31);
+		xor_chains = (struct xor_chain*)va;
+		memset(xor_chains, 0, sizeof(struct xor_chain) * CHAINS);
+
+		/*
+		 * init channels
+		 */
+		for(i=0; i<CHANNELS; i++) {
+			xor_channels[i].idx = i;
+			xor_channels[i].busy = 0;
+			xor_channels[i].chain = NULL;
+
+			xor_mode_dma(i);
+		}
+
+		/*
+		 * init chains
+         */                                 
+        i = CHAINS;
+		while(i--) {
+			u32 sz, va=0;	
+
+			chain = &xor_chains[i];
+			
+			chain->idx = i;			
+
+			if (i <= CHAIN_NETDMA)
+				sz = sizeof(xor_desc_t) * NET_DESC;
+			else
+				sz = sizeof(xor_desc_t) * DMA_DESC;
+
+			va = (u32)kmalloc(sz+64, GFP_KERNEL);
+			va += 64 - (va & 63);
+			chain->desc = (void*)va;
+			chain->base = __pa(va);
+
+			memset(chain->desc, 0, sz);	
+			BUG_ON(63 & (u32)chain->desc);
+
+			/*
+			 * Init next pointer
+             */
+			if (i <= CHAIN_NETDMA) {
+				int d = NET_DESC - 1;
+				while(d--)
+					chain->desc[d].phyNextDescPtr = 
+						chain->base + (sizeof(xor_desc_t) * (d+1));
+			}
+
+		}
+    
+
+#ifdef CONFIG_PROC_FS
+		/* FIXME: /proc/sys/dev/ */
+		proc_e = create_proc_entry("mvxor", 0666, 0);
+        proc_e->read_proc = xor_proc_read;
+        proc_e->write_proc = xor_proc_write;
+		proc_e->nlink = 1;
+#endif
+
+#ifdef CONFIG_MV_XOR_NET_DMA
+		memset(&xor_dma_dev, 0, sizeof(struct xor_dma_device));
+		memset(xor_dma_chn, 0, sizeof(struct xor_dma_channel));
+		INIT_LIST_HEAD(&xor_dma_dev.common.channels);
+
+		xor_dma_dev.common.chancnt = 1;
+		xor_dma_chn[0].common.device = &xor_dma_dev.common;
+		xor_dma_chn[0].chain = &xor_chains[0];
+		xor_dma_chn[0].chain->busy = 1;
+
+		spin_lock_init(&xor_dma_chn[0].lock);
+		list_add_tail(&xor_dma_chn[0].common.device_node, 
+						  &xor_dma_dev.common.channels);
+
+		xor_dma_dev.common.device_alloc_chan_resources = xor_alloc_chan_resources;
+		xor_dma_dev.common.device_free_chan_resources = xor_free_chan_resources;
+		xor_dma_dev.common.device_memcpy_buf_to_buf = xor_memcpy_buf_to_buf;
+		xor_dma_dev.common.device_memcpy_buf_to_pg = xor_memcpy_buf_to_pg;
+		xor_dma_dev.common.device_memcpy_pg_to_pg = xor_memcpy_pg_to_pg;
+		xor_dma_dev.common.device_memcpy_complete = xor_memcpy_complete;
+		xor_dma_dev.common.device_memcpy_issue_pending = xor_memcpy_issue_pending;
+
+		if (dma_async_device_register(&xor_dma_dev.common)) {
+			printk(KERN_ERR" XOR engine cannot be registered as async NET_DMA\n");    
+			return -ENODEV;
+		}
+
+		printk(KERN_INFO "XOR registered %d NET_DMA over %d channels\n", 
+			   xor_dma_dev.common.chancnt, CHANNELS);
+
+#else
+		printk(KERN_INFO "XOR registered %d channels\n", CHANNELS);
+
+#endif
+
+#ifdef XOR_UNMAP
+		printk(KERN_INFO "XOR 2nd invalidate WA enabled\n");
+#endif
+		xor_enabled = 1;
+		return 0;
+}
+
+void __exit mv_xor_exit(void)
+{
+    return;
+}
+
+module_init(mv_xor_init);
+module_exit(mv_xor_exit);
+MODULE_LICENSE(GPL);
+
+
+/* = ====================================================================== */
+#ifdef CONFIG_MV_XOR_MEMCOPY
+void* xor_memcpy(void *_to, const void* _from, __kernel_size_t n)
+{
+	u32 to = (u32)_to;
+	u32 from = (u32)_from;
+	u32 sa, da;
+
+	struct xor_chain* chain;
+	struct xor_channel *xch;
+
+	if (!xor_enabled)			
+		return asm_memcpy((void*)to, (void*)from, n);
+
+	STAT_INC(memcp);
+	STAT_ADD(memcp_bytes,n);
+
+	DPRINTK("%s:%x<-%x %d bytes\n", __FUNCTION__, to, from, n);
+
+	if (n < 128)
+		goto out;
+
+	if (!virt_addr_valid(to) || !virt_addr_valid(from)) {
+		STAT_INC(err_addr);
+		goto out;
+	}
+
+	da = __pa((void*)to);	
+	sa = __pa((void*)from);
+
+	if (((da < sa) && (sa < da+n)) || 
+		((sa < da) && (da < sa+n))) 
+		return memmove((void*)to, (void*)from, n);
+	
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+	dmac_clean_range((void*)from, (void*)from + n);
+	dmac_inv_range((void*)to, (void*)to + n);
+#else
+	dma_cache_maint((void*)from, n, DMA_TO_DEVICE);
+	dma_cache_maint((void*)to, n, DMA_FROM_DEVICE);
+#endif
+
+	da = virt_to_phys((void*)to);	
+	sa = virt_to_phys((void*)from);
+
+	if (unlikely(!sa || !da)) {
+		STAT_INC(err_addr);
+		goto out;
+	}
+
+	chain = &xor_chains[CHAIN_MEMCPY];
+	if (xor_try_chain(chain)) 
+		goto out;
+
+	DPRINTK("%s: %x<-%x %d bytes\n", __FUNCTION__, da, sa, n);
+	chain->pending = 1;
+	chain->desc->srcAdd0 = sa;
+	chain->desc->phyDestAdd = da;
+	chain->desc->byteCnt = n;
+	chain->desc->phyNextDescPtr = 0;
+	chain->desc->status = BIT31;
+
+	dmac_clean_dcache_line(chain->desc);
+	dsb();
+
+	xch = xor_get();
+	if (!xch) 
+		goto out2;
+
+	STAT_INC(memcp_dma);
+	xor_attach(chain, xch);
+	xor_dma(xch->idx, chain->base);
+
+	{
+		u32 c;
+
+		da = to & 31;
+		sa = from & 31;		
+		if (sa || da) {
+			c = (sa > da) ? 32 - da : 32 - sa;
+			memmove((void*)to, (void*)from, c);
+		}
+
+		da = (to+n) & 31;
+		sa = (from+n) & 31;
+		if (sa || da) {
+			c = (da > sa) ? da : sa;
+			memmove((void*)(to+n-c), (void*)(from+n-c), c);
+		}
+	}
+
+	xor_wait(xch->idx);
+	xor_detach(chain, xch);
+	xor_put(xch);
+
+	return (void*)to;
+
+out2:
+	chain->busy = 0;
+out:
+	return asm_memcpy((void*)to, (void*)from, n);
+}
+EXPORT_SYMBOL(xor_memcpy);
+#endif /* CONFIG_MV_XOR_MEMCOPY */
+
+#ifdef CONFIG_MV_XOR_MEMXOR
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+int xor_memxor(unsigned int count, unsigned int n, void **va)
+{
+	struct xor_chain* chain;
+	struct xor_channel *xch;
+	u32* p;
+
+	if (!xor_enabled)
+		goto out;
+
+	BUG_ON(count <= 1);
+
+	DPRINTK("%s: %d sources %d bytes\n", __FUNCTION__, count, n);
+
+	chain = &xor_chains[CHAIN_MEMXOR];
+	if (xor_try_chain(chain)) 
+		goto out;
+
+	chain->pending = 1;
+	chain->desc->phyDestAdd = __pa(va[0]);
+	chain->desc->byteCnt = n;
+	chain->desc->phyNextDescPtr = 0;
+	chain->desc->descCommand = (1 << count) - 1;
+	chain->desc->status = BIT31;
+
+	p = &chain->desc->srcAdd0;
+
+#ifdef MV_CPU_BE
+	p = &chain->desc->srcAdd1;
+	if (count & 1) 
+		p[count] = __pa(va[count-1]);
+#endif
+
+	while(count--) {
+		dmac_clean_range(va[count], (void*)va[count] + n);
+		p[count] = __pa(va[count]);
+	}
+
+	dmac_clean_dcache_line(chain->desc);
+	dmac_clean_dcache_line(chain->desc+32);
+	dsb();
+
+	xch = xor_get();
+	if (!xch) 
+		goto out2;
+
+	STAT_ADD(memxor_bytes, n);
+	STAT_INC(memxor_dma);
+
+	xor_attach(chain, xch);
+	xor_mode_xor(xch->idx);
+	xor_dma(xch->idx, chain->base);
+
+	/* could be useful before busywait, because we already have it clean */
+	dmac_inv_range(va[0], (void*)va[0] + n);
+	xor_wait(xch->idx);
+
+	xor_mode_dma(xch->idx);
+	xor_detach(chain, xch);
+	wmb();
+	xor_put(xch);
+
+	return 0;
+
+out2:
+	chain->busy = 0;
+out:
+	return 1;
+}
+#else /* LINUX_VERSION_CODE > KERNEL_VERSION(2,6,26) */
+int xor_memxor(unsigned int src_count, unsigned int bytes, void *dest, void **srcs)
+{
+	struct xor_chain* chain;
+	struct xor_channel *xch;
+	u32* p;
+
+	if (!xor_enabled)
+		goto out;
+
+	BUG_ON(src_count < 1);
+
+	DPRINTK("%s: %d sources %d bytes\n", __FUNCTION__, src_count, bytes);
+
+	chain = &xor_chains[CHAIN_MEMXOR];
+	if (xor_try_chain(chain)) 
+		goto out;
+
+	chain->pending = 1;
+	chain->desc->phyDestAdd = __pa(dest);
+	chain->desc->byteCnt = bytes;
+	chain->desc->phyNextDescPtr = 0;
+	chain->desc->descCommand = (1 << (src_count+1)) - 1; /* add dest to the count */
+	chain->desc->status = BIT31;
+
+#ifdef MV_CPU_BE
+    /* set the first (srcAdd1) desc to be the dest */
+	chain->desc->srcAdd1 = chain->desc->phyDestAdd;
+	p = &chain->desc->srcAdd0;
+	if ((src_count+1) & 1)
+		p[src_count] = __pa(srcs[src_count-1]);
+#else
+	/* set the first desc (srcAdd0) to be the dest */
+	chain->desc->srcAdd0 = chain->desc->phyDestAdd;
+	p = &chain->desc->srcAdd1;
+#endif
+
+	dma_cache_maint(dest, bytes, DMA_TO_DEVICE);
+    
+	while(src_count--) {
+		dma_cache_maint((void*)srcs[src_count], bytes, DMA_TO_DEVICE);
+		p[src_count] = __pa(srcs[src_count]);
+	}
+
+	dmac_clean_dcache_line(chain->desc);
+	dmac_clean_dcache_line(chain->desc+32);
+	dsb();
+
+	xch = xor_get();
+	if (!xch) 
+		goto out2;
+
+	STAT_ADD(memxor_bytes, bytes);
+	STAT_INC(memxor_dma);
+
+	xor_attach(chain, xch);
+	xor_mode_xor(xch->idx);
+	xor_dma(xch->idx, chain->base);
+
+	/* could be useful before busywait, because we already have it clean */
+	dma_cache_maint(dest, bytes, DMA_FROM_DEVICE);
+	xor_wait(xch->idx);
+
+	xor_mode_dma(xch->idx);
+	xor_detach(chain, xch);
+	wmb();
+	xor_put(xch);
+
+	return 0;
+
+out2:
+	chain->busy = 0;
+out:
+	return 1;
+}
+
+#endif
+EXPORT_SYMBOL(xor_memxor);
+#endif /* CONFIG_MV_XOR_MEMXOR */
+
+
+#if defined(CONFIG_MV_XOR_COPY_TO_USER) || defined(CONFIG_MV_XOR_COPY_FROM_USER)
+/*
+ * Obtain pa address from user va
+ */
+static inline u32 __pa_user(u32 va, int write)
+{
+    struct page *page;
+    struct vm_area_struct *vm;
+    struct mm_struct * mm = (va >= TASK_SIZE)? &init_mm : current->mm;
+    unsigned int flags;
+
+    if (virt_addr_valid(va)) 
+        return __pa(va);
+
+    if (va >= (u32)high_memory)
+	    return 0;
+    
+    flags  = write ? (VM_WRITE | VM_MAYWRITE) : (VM_READ | VM_MAYREAD);
+
+    vm = find_extend_vma(mm, va);
+    if (!vm || (vm->vm_flags & (VM_IO|VM_PFNMAP)) || !(flags & vm->vm_flags))
+		return 0;
+
+    flags = FOLL_PTE_EXIST | FOLL_TOUCH;
+    flags |= (write) ? FOLL_WRITE : 0;
+		 
+    page = follow_page(vm, va, flags);
+    
+    if (pfn_valid(page_to_pfn(page))) 
+        return ((page_to_pfn(page) << PAGE_SHIFT) | (va & (PAGE_SIZE - 1)));
+
+	return 0;
+}
+#endif /* COPY_XX_USER */
+
+#ifdef CONFIG_MV_XOR_COPY_TO_USER
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+unsigned long xor_copy_to_user(unsigned long to, unsigned long from, unsigned long n)
+{
+	u32 sa, da, copy;
+	struct xor_chain* chain;
+	struct xor_channel* xch;
+	unsigned int i = 0;
+	unsigned long rc;
+	unsigned long flags=0;
+
+	if (unlikely(!xor_enabled))
+		goto out;
+
+	STAT_INC(to_usr);
+	STAT_ADD(to_usr_bytes, n);
+
+	DPRINTK("%s: %p<-%p %d bytes\n", __FUNCTION__, to, from, n);
+
+	if (!virt_addr_valid(from)) {
+		STAT_INC(err_addr);
+		goto out;
+	}
+
+	if (to & 31) {
+		mvOsCacheLineFlushInv(0, to);
+		mvOsCacheIoSync();
+	}
+
+	if ((to+n) & 31) {
+		mvOsCacheLineFlushInv(0, to+n);
+		mvOsCacheIoSync();
+	}
+
+	dmac_clean_range((void*)from, (void*)from + n);
+	
+	chain = &xor_chains[CHAIN_TO_USR];
+	if (xor_try_chain(chain)) 
+		goto out;
+
+	local_irq_save(flags);	
+
+	while(n) {
+		copy = PAGE_SIZE - (to & ~PAGE_MASK);
+		if (copy > n)
+			copy = n;
+
+		if (!copy) 
+			break;
+
+		if (copy < XOR_MIN_COPY_CHUNK) {
+			rc= __arch_copy_to_user((void*)to, (void*)from, copy);
+			if (rc)
+				goto out2;
+		}
+		else {
+
+			sa = __pa(from);
+			da = __pa_user(to, 1);
+	
+			if (unlikely(!sa || !da)) {
+				STAT_INC(err_addr);
+				goto out2;
+			}
+
+            DPRINTK("%s: desc[%d] %x<-%x %d bytes\n", __FUNCTION__, i, da, sa, copy);
+
+			dmac_inv_range((void*)to, (void*)to + copy);
+
+			chain->desc[i].srcAdd0 = sa;
+			chain->desc[i].phyDestAdd = da;
+			chain->desc[i].byteCnt = copy;
+			chain->desc[i].phyNextDescPtr = 0;
+			chain->desc[i].status = BIT31;
+			if (i) 
+				chain->desc[i-1].phyNextDescPtr = 
+						chain->base + (sizeof(xor_desc_t) * i);
+			
+			i++;
+		}
+
+		from += copy;
+		to += copy;
+		n -= copy;
+	}
+
+	if (i) {       
+
+		while(i--)
+			dmac_clean_dcache_line(chain->desc + i);
+		dsb();
+
+		xch = xor_get();		
+		if (!xch) 
+			goto out2;
+
+		xor_attach(chain, xch);
+
+		DPRINTK("%s: ch[%d] chain=%d\n", __FUNCTION__, xch->idx, chain->idx);
+
+		STAT_INC(to_usr_dma);
+		xor_dma(xch->idx, chain->base);
+		xor_wait(xch->idx);
+
+		xor_detach(chain, xch);
+		xor_put(xch);
+	}
+
+	local_irq_restore(flags);
+
+	return 0;
+
+out2:
+	chain->busy=0;
+	local_irq_restore(flags);
+out:
+	return __arch_copy_to_user((void*)to, (void*)from, n);
+}
+EXPORT_SYMBOL(xor_copy_to_user);
+#else
+#error "Kernel version >= 2,6,26 does not support XOR copy_to_user"
+#endif /* LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26) */
+#endif /* CONFIG_MV_XOR_COPY_TO_USER */
+
+#ifdef CONFIG_MV_XOR_COPY_FROM_USER
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+unsigned long xor_copy_from_user(unsigned long to, unsigned long from, unsigned long n)
+{
+	u32 sa, da, copy;
+	struct xor_chain* chain;
+	struct xor_channel* xch;
+	unsigned int i = 0;
+	unsigned long flags=0;
+	unsigned long rc;
+
+	if (unlikely(!xor_enabled))
+		goto out;
+
+	STAT_INC(from_usr);
+	STAT_ADD(from_usr_bytes, n);
+
+	DPRINTK("%s: %p<-%p %d bytes\n", __FUNCTION__, to, from, n);
+
+	if (!virt_addr_valid(to)) {
+		STAT_INC(err_addr);
+		goto out;
+	}
+
+	if (to & 31) {
+		mvOsCacheLineFlushInv(0, to);
+		mvOsCacheIoSync();
+	}
+
+	if ((to+n) & 31) {
+		mvOsCacheLineFlushInv(0, to+n);
+		mvOsCacheIoSync();
+	}
+
+	dmac_inv_range((void*)to, (void*)to + n);
+	
+	chain = &xor_chains[CHAIN_FROM_USR];
+	if (xor_try_chain(chain)) 
+		goto out;
+
+	local_irq_save(flags);	
+
+	while(n) {
+		copy = PAGE_SIZE - (from & ~PAGE_MASK);
+		if (copy > n)
+			copy = n;
+
+		if (!copy) 
+			break;
+
+		if (copy < XOR_MIN_COPY_CHUNK) {
+			rc = __arch_copy_from_user((void*)to, (void*)from, copy);
+			if (rc)
+				goto out2;
+		}
+		else {
+
+			sa = __pa_user(from, 0);
+			da = __pa(to);
+
+			if (unlikely(!sa || !da)) {
+				STAT_INC(err_addr);
+				goto out2;
+			}
+            
+			DPRINTK("%s: desc[%d] %x<-%x %d bytes\n", __FUNCTION__, i, da, sa, copy);
+
+			dmac_clean_range((void*)from, (void*)from + copy);
+
+			chain->desc[i].srcAdd0 = sa;
+			chain->desc[i].phyDestAdd = da;
+			chain->desc[i].byteCnt = copy;
+			chain->desc[i].phyNextDescPtr = 0;
+			chain->desc[i].status = BIT31;
+			if (i) 
+				chain->desc[i-1].phyNextDescPtr = 
+						chain->base + (sizeof(xor_desc_t) * i);
+			
+			i++;
+		}
+
+		from += copy;
+		to += copy;
+		n -= copy;
+	}
+
+	if (i) {       
+
+		while(i--)
+			dmac_clean_dcache_line(chain->desc + i);
+		dsb();
+
+		xch = xor_get();		
+		if (!xch) 
+			goto out2;
+
+		xor_attach(chain, xch);
+
+		DPRINTK("%s: ch[%d] chain=%d\n", __FUNCTION__, xch->idx, chain->idx);
+
+		STAT_INC(from_usr_dma);
+		xor_dma(xch->idx, chain->base);
+		xor_wait(xch->idx);
+
+		xor_detach(chain, xch);
+		xor_put(xch);
+	}
+
+	local_irq_restore(flags);
+
+	return 0;
+
+out2:
+	chain->busy=0;
+	local_irq_restore(flags);
+out:
+	return __arch_copy_from_user((void*)to, (void*)from, n);
+}
+EXPORT_SYMBOL(xor_copy_from_user);
+#else
+#error "Kernel version >= 2,6,26 does not support XOR copy_from_user"
+#endif /* LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26) */
+#endif /* CONFIG_MV_XOR_COPY_FROM_USER */
+
+
+#ifdef XOR_BENCH
+void xor_bench(void *to, void *from, unsigned long n)
+{
+		unsigned long time;
+		u32 i;
+		u32 t;
+		 //	
+		 // functions under benchmark, use / to skip.
+         //
+		char* fn[] = {"/", "asm_memzero", "/", 
+						"/xor_memcpy", "/memcpy", 
+						"/xor_memxor", "/xor_block", NULL};
+		void* va[3];
+
+		for (n=128; n<=0x100000; n*=2) {
+
+			va[0] =  kmalloc(n, GFP_KERNEL);;
+			va[1] = kmalloc(n, GFP_KERNEL);;
+			va[2] = kmalloc(n, GFP_KERNEL);;
+
+			if (!va[1] || !va[0]) {
+				printk("%s: kmalloc failed on %luB\n", __FUNCTION__, n);
+				return;
+			}
+
+			for (t=0; fn[t]; t++) {
+				if (fn[t][0] == '/') 
+					continue;
+
+				cond_resched();
+				i = 0;
+				time = jiffies + msecs_to_jiffies(1000);
+	
+				while (jiffies <= time) {
+					switch (t) {
+						case 1: 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+								dmac_inv_range((void*)va[0], (void*)va[0] + n);
+#else
+								dma_cache_maint((void*)va[0], n, DMA_FROM_DEVICE);
+#endif
+								memzero(va[0], n); 
+						break;
+#ifdef CONFIG_MV_XOR_MEMCOPY
+						case 3: xor_memcpy(va[0], va[1], n); 
+							break;
+						case 4: asm_memcpy(va[0], va[1], n); 
+							break;
+#else
+						case 4: memcpy(va[0], va[1], n); 
+							break;
+#endif
+#ifdef CONFIG_MV_XOR_MEMXOR
+						case 5: xor_memxor(3, n ,va); 
+							break;
+#endif
+						case 6: xor_block(3, n ,va); 
+							break;
+						default:
+							printk("%s skipped\n", fn[t]);
+							time = 0;
+					}
+					
+					i++;
+				}
+
+				printk("%s: %lu8B %8luMBs %s()\n", __FUNCTION__, 
+					   n, (i * n) >> 20, fn[t]);
+
+			}
+
+			kfree(va[2]);
+			kfree(va[1]);
+			kfree(va[0]);
+		}
+}
+#endif
+
diff --git a/arch/arm/plat-armada/pmu.c b/arch/arm/plat-armada/pmu.c
new file mode 100644
index 0000000..a9fabb7
--- /dev/null
+++ b/arch/arm/plat-armada/pmu.c
@@ -0,0 +1,32 @@
+/*
+ * PMU IRQ registration for the ARMADA XP PMU families.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/platform_device.h>
+#include <asm/pmu.h>
+#include <mach/irqs.h>
+
+static struct resource pmu_resource = {
+	.start	= IRQ_AURORA_MP,
+	.end	= IRQ_AURORA_MP,
+	.flags	= IORESOURCE_IRQ,
+};
+
+static struct platform_device pmu_device = {
+	.name		= "arm-pmu",
+	.id		= ARM_PMU_DEVICE_CPU,
+	.resource	= &pmu_resource,
+	.num_resources	= 1,
+};
+
+static int __init armadaxp_pmu_init(void)
+{
+	platform_device_register(&pmu_device);
+	return 0;
+}
+arch_initcall(armadaxp_pmu_init);
diff --git a/arch/arm/plat-armada/power.c b/arch/arm/plat-armada/power.c
new file mode 100644
index 0000000..eafbb72
--- /dev/null
+++ b/arch/arm/plat-armada/power.c
@@ -0,0 +1,286 @@
+/*
+ * arch/arm/plat-armada/power.c
+ *
+ * CPU power management functions
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ *
+ */
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/platform_device.h>
+#include <linux/proc_fs.h>
+#include <linux/cpuidle.h>
+#include <asm/io.h>
+#include <asm/proc-fns.h>
+#include <plat/cache-aurora-l2.h>
+#include <mach/smp.h>
+#include <asm/vfp.h>
+#include <asm/cacheflush.h>
+#include <asm/tlbflush.h>
+#include <asm/pgalloc.h>
+#include <asm/sections.h>
+
+#include "ctrlEnv/sys/mvCpuIfRegs.h"
+#include "mvOs.h"
+
+static void hw_sem_lock(void)
+{
+	unsigned int cpu = hard_smp_processor_id();
+
+	while(cpu != (readb(INTER_REGS_BASE + MV_CPU_HW_SEM_OFFSET) & 0xf));
+}
+
+static void hw_sem_unlock(void)
+{
+	writeb(0xff, INTER_REGS_BASE + MV_CPU_HW_SEM_OFFSET);
+}
+
+extern int armadaxp_cpu_resume(void);
+u32 cib_ctrl_cfg_reg;
+
+void armadaxp_fabric_setup_deepIdle(void)
+{
+	MV_U32  reg;
+	MV_U32	i;
+
+	reg = MV_REG_READ(MV_L2C_NFABRIC_PM_CTRL_CFG_REG);
+	reg |= MV_L2C_NFABRIC_PM_CTRL_CFG_PWR_DOWN;
+	MV_REG_WRITE(MV_L2C_NFABRIC_PM_CTRL_CFG_REG, reg);
+
+	for (i=0; i<4; i++) {
+		/* Enable L2 & Fabric powerdown in Deep-Idle mode */
+		reg = MV_REG_READ(PM_CONTROL_AND_CONFIG_REG(i));
+		reg |= PM_CONTROL_AND_CONFIG_L2_PWDDN;
+		MV_REG_WRITE(PM_CONTROL_AND_CONFIG_REG(i), reg);
+	}
+
+	/* Configure CPU_DivClk_Control0 */
+	reg = MV_REG_READ(0x18700);
+	reg &= ~0xFFFF00;
+	reg |= 0x10EF00;
+	MV_REG_WRITE(0x18700, reg); 
+	
+	/* Configure  PMU_DFS_Control_1 */
+	reg = MV_REG_READ(0x1C054);
+	reg &= 0xFF000000;
+	reg >>= 24;
+	reg = (reg << 24) | ((reg + 1) << 16) | 0x10404;
+	MV_REG_WRITE(0x1C054, reg);
+
+	/* Configure  PMU Program registers */
+	MV_REG_WRITE(0x1C270, 0x00c108a8);
+	MV_REG_WRITE(0x1C274, 0x0000005a);
+	MV_REG_WRITE(0x1C278, 0x00000000);
+	MV_REG_WRITE(0x1C27c, 0x195b0000);
+	MV_REG_WRITE(0x1C280, 0x00ff0014);
+
+#ifdef CONFIG_ARMADA_XP_DEEP_IDLE_L2_WA
+	/* disable HW L2C Flush configure 0x22008:
+	 *  Set bit 4 -> Will skip HW L2C flush triggering.
+	 *  Set bit 5 -> Will skip waiting for HW L2C flush done indication.
+	 */
+	reg = MV_REG_READ(MV_L2C_NFABRIC_PWR_DOWN_FLOW_CTRL_REG);
+	reg |= 3 << 4;
+
+	/* Configure skiping the RA & WA Disable */
+	reg |= 1;
+	/* Configure skiping the Sharing Disable */
+	reg |= 1 << 8;
+	/* Configure skiping the CIB Ack Disable */
+	reg |= 1 << 6;
+	/* Configure skiping the RA & WA Resume */
+	reg |= 1 << 12;
+	/* Configure skiping the CIB Ack Resume */
+	reg |= 1 << 15;
+	/* Configure skiping the Sharing Resume */
+	reg |= 1 << 14;
+
+	MV_REG_WRITE(MV_L2C_NFABRIC_PWR_DOWN_FLOW_CTRL_REG, reg);
+#endif
+
+#ifdef CONFIG_ARMADA_XP_DEEP_IDLE_L2_WA
+	/* neet to restore this register on resume */
+	cib_ctrl_cfg_reg = MV_REG_READ(MV_CIB_CTRL_CFG_REG);
+#endif
+	
+	/* Set the resume control registers to do nothing */
+	MV_REG_WRITE(0x20980, 0);
+	MV_REG_WRITE(0x20988, 0);
+
+	/* configure the MPP29 used for CPU0+L2+Fabric power control*/
+	reg = MV_REG_READ(MPP_CONTROL_REG(3));
+	reg &= ~0x00F00000;
+	reg |= 0x00500000;
+	MV_REG_WRITE(MPP_CONTROL_REG(3), reg);
+
+	/* configure the MPP40 used for CPU1 power control*/
+	reg = MV_REG_READ(MPP_CONTROL_REG(5));
+	reg &= ~0x0000000F;
+	reg |= 0x00000003;
+	MV_REG_WRITE(MPP_CONTROL_REG(5), reg);
+
+	/* configure the MPP57 used for CPU2+3 power control*/
+	reg = MV_REG_READ(MPP_CONTROL_REG(7));
+	reg &= ~0x000000F0;
+	reg |= 0x00000020;
+	MV_REG_WRITE(MPP_CONTROL_REG(7), reg);
+}
+EXPORT_SYMBOL(armadaxp_fabric_setup_deepIdle);
+
+void armadaxp_fabric_prepare_deepIdle(void)
+{
+	unsigned int processor_id = hard_smp_processor_id();
+	MV_U32  reg;
+
+	MV_REG_WRITE(PM_CPU_BOOT_ADDR_REDIRECT(processor_id), virt_to_phys(armadaxp_cpu_resume));
+#if defined CONFIG_AURORA_IO_CACHE_COHERENCY || CONFIG_SMP
+	hw_sem_lock();
+	/* Disable delivery of snoop requests to the CPU core by setting */
+	reg = MV_REG_READ(MV_COHERENCY_FABRIC_CTRL_REG);
+	reg &= ~(1 << (24 + processor_id));
+	MV_REG_WRITE(MV_COHERENCY_FABRIC_CTRL_REG, reg);
+	hw_sem_unlock();
+#endif
+
+	reg = MV_REG_READ(PM_STATUS_AND_MASK_REG(processor_id));
+	/* set WaitMask fields */
+	reg |= PM_STATUS_AND_MASK_CPU_IDLE_WAIT;
+	reg |= PM_STATUS_AND_MASK_SNP_Q_EMPTY_WAIT;
+	/* Enable wakeup events */
+	reg |= PM_STATUS_AND_MASK_IRQ_WAKEUP | PM_STATUS_AND_MASK_FIQ_WAKEUP;
+//	reg |= PM_STATUS_AND_MASK_DBG_WAKEUP;
+
+#ifdef CONFIG_ARMADA_XP_DEEP_IDLE_UNMASK_INTS_WA
+	/* don't mask interrupts due to known issue */
+#else
+	/* Mask interrupts */
+	reg |= PM_STATUS_AND_MASK_IRQ_MASK | PM_STATUS_AND_MASK_FIQ_MASK;
+#endif
+	MV_REG_WRITE(PM_STATUS_AND_MASK_REG(processor_id), reg);
+
+	/* Disable delivering of other CPU core cache maintenance instruction,
+	 * TLB, and Instruction synchronization to the CPU core 
+	 */
+	/* TODO */
+#ifdef CONFIG_CACHE_AURORA_L2
+	/* ask HW to power down the L2 Cache if possible */
+	reg = MV_REG_READ(PM_CONTROL_AND_CONFIG_REG(processor_id));
+	reg |= PM_CONTROL_AND_CONFIG_L2_PWDDN;
+	MV_REG_WRITE(PM_CONTROL_AND_CONFIG_REG(processor_id), reg);
+#endif
+
+	/* request power down */
+	reg = MV_REG_READ(PM_CONTROL_AND_CONFIG_REG(processor_id));
+	reg |= PM_CONTROL_AND_CONFIG_PWDDN_REQ;
+	MV_REG_WRITE(PM_CONTROL_AND_CONFIG_REG(processor_id), reg);
+
+#ifdef CONFIG_ARMADA_XP_DEEP_IDLE_L2_WA
+	/* Disable RA & WA allocate */
+	reg = MV_REG_READ(MV_CIB_CTRL_CFG_REG);
+	reg &= ~0x1E;
+	reg |= 0x12;
+	MV_REG_WRITE(MV_CIB_CTRL_CFG_REG, reg);
+
+	auroraL2_flush_all();
+
+	/* Disable CIB Ack */
+	reg = MV_REG_READ(MV_CIB_CTRL_CFG_REG);
+	reg |= 1 << 9;
+	MV_REG_WRITE(MV_CIB_CTRL_CFG_REG, reg);
+	
+	/* wait for CIB empty */
+	udelay(1);
+
+	/* Disable CIB Sharing */
+	reg = MV_REG_READ(MV_CIB_CTRL_CFG_REG);
+	reg &=  ~(3 << 10);
+	reg |= 0x2 << 10;
+	MV_REG_WRITE(MV_CIB_CTRL_CFG_REG, reg);
+#endif
+}
+EXPORT_SYMBOL(armadaxp_fabric_prepare_deepIdle);
+
+void armadaxp_fabric_restore_deepIdle(void)
+{
+	unsigned int processor_id = hard_smp_processor_id();
+	MV_U32  reg;
+
+	/* cancel request power down */
+	reg = MV_REG_READ(PM_CONTROL_AND_CONFIG_REG(processor_id));
+	reg &= ~PM_CONTROL_AND_CONFIG_PWDDN_REQ;
+	MV_REG_WRITE(PM_CONTROL_AND_CONFIG_REG(processor_id), reg);
+
+#ifdef CONFIG_CACHE_AURORA_L2
+	/* cancel ask HW to power down the L2 Cache if possible */
+	reg = MV_REG_READ(PM_CONTROL_AND_CONFIG_REG(processor_id));
+	reg &= ~PM_CONTROL_AND_CONFIG_L2_PWDDN;
+	MV_REG_WRITE(PM_CONTROL_AND_CONFIG_REG(processor_id), reg);
+#endif
+	/* cancel Disable delivering of other CPU core cache maintenance instruction,
+	 * TLB, and Instruction synchronization to the CPU core 
+	 */
+	/* TODO */
+
+	/* cancel Enable wakeup events */
+	reg = MV_REG_READ(PM_STATUS_AND_MASK_REG(processor_id));
+	reg &= ~(PM_STATUS_AND_MASK_IRQ_WAKEUP | PM_STATUS_AND_MASK_FIQ_WAKEUP);
+	reg &= ~PM_STATUS_AND_MASK_CPU_IDLE_WAIT;
+	reg &= ~PM_STATUS_AND_MASK_SNP_Q_EMPTY_WAIT;
+//	reg &= ~PM_STATUS_AND_MASK_DBG_WAKEUP;
+
+	/* Mask interrupts */
+	reg &= ~(PM_STATUS_AND_MASK_IRQ_MASK | PM_STATUS_AND_MASK_FIQ_MASK);
+	MV_REG_WRITE(PM_STATUS_AND_MASK_REG(processor_id), reg);
+#if defined CONFIG_AURORA_IO_CACHE_COHERENCY || CONFIG_SMP
+	/* cancel Disable delivery of snoop requests to the CPU core by setting */
+	hw_sem_lock();
+	reg = MV_REG_READ(MV_COHERENCY_FABRIC_CTRL_REG);
+	reg |= 1 << (24 + processor_id);
+	MV_REG_WRITE(MV_COHERENCY_FABRIC_CTRL_REG, reg);
+	hw_sem_unlock();
+#endif
+#ifdef CONFIG_ARMADA_XP_DEEP_IDLE_L2_WA
+	/* restore CIB  Control and Configuration register except CIB Ack */
+	MV_REG_WRITE(MV_CIB_CTRL_CFG_REG, cib_ctrl_cfg_reg & ~(1 << 9));
+	/* add delay needed for erratum "Dunit MBus starvation causes poor performance during deep-idle " */
+	udelay(10);
+	/* restore CIB Control including CIB Ack */
+	MV_REG_WRITE(MV_CIB_CTRL_CFG_REG, cib_ctrl_cfg_reg);
+#endif
+}
+EXPORT_SYMBOL(armadaxp_fabric_restore_deepIdle);
+
+void armadaxp_smp_prepare_idle(unsigned int processor_id)
+{
+	u32 reg;
+
+	flush_cache_all();
+
+	/* Disable delivery of snoop requests to the CPU core */
+	hw_sem_lock();
+	reg = MV_REG_READ(MV_COHERENCY_FABRIC_CTRL_REG);
+	reg &= ~(1 << (24 + processor_id));
+	MV_REG_WRITE(MV_COHERENCY_FABRIC_CTRL_REG, reg);
+	MV_REG_READ(MV_COHERENCY_FABRIC_CTRL_REG);
+	hw_sem_unlock();
+	udelay(1);
+}
+EXPORT_SYMBOL(armadaxp_smp_prepare_idle);
+
+void armadaxp_smp_restore_idle(unsigned int processor_id)
+{
+	u32 reg;
+
+	/* Enable delivery of snoop requests to the CPU core */
+	hw_sem_lock();
+	reg = MV_REG_READ(MV_COHERENCY_FABRIC_CTRL_REG);
+	reg |= 1 << (24 + processor_id);
+	MV_REG_WRITE(MV_COHERENCY_FABRIC_CTRL_REG, reg);
+	MV_REG_READ(MV_COHERENCY_FABRIC_CTRL_REG);
+	hw_sem_unlock();
+}
+EXPORT_SYMBOL(armadaxp_smp_restore_idle);
diff --git a/arch/arm/plat-armada/power.h b/arch/arm/plat-armada/power.h
new file mode 100644
index 0000000..5c52cb3
--- /dev/null
+++ b/arch/arm/plat-armada/power.h
@@ -0,0 +1,22 @@
+/*
+ * arch/arm/plat-armada/power.h
+ *
+ * CPU power management functions
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#ifndef __PLAT_ARMADA_POWER_H
+#define __PLAT_ARMADA_POWER_H
+
+int armadaxp_cpu_suspend(void);
+void armadaxp_fabric_setup_deepIdle(void);
+void armadaxp_fabric_prepare_deepIdle(void);
+void armadaxp_fabric_restore_deepIdle(void);
+
+void armadaxp_smp_prepare_idle(unsigned int processor_id);
+void armadaxp_smp_restore_idle(unsigned int processor_id);
+
+#endif /* __PLAT_ARMADA_POWER_H*/
-- 
1.7.5.4

