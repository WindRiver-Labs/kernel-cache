From 9efbdb233f544724c6ee1715ef65399e7342779e Mon Sep 17 00:00:00 2001
From: Dmitri Epshtein <dima@marvell.com>
Date: Tue, 25 Feb 2014 15:24:31 -0500
Subject: [PATCH 1398/1825] fix: pp2: WA for mixed HWF/SWF data corruption

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit fe87658e1354107102f03d52389f101cf1647916

	- Invalidate L1 and L2 cache for RX buffers from BM pools
	that shared between SWF and HWF traffic.
	- New entry added to Kconfig CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
	depending on (AURORA_IO_CACHE_COHERENCY && MV_ETH_HWF)
	- New sysfs command to enable/disable this WA is added under
	/sys/devices/platform/pp2/gbe/hwf directory. Default is enabled.
	"echo en  > c_inv"   - on/off L1 and L2 cache invalidation

Change-Id: Ibb6097b88893e5493755e6d5eee2603b044ec348
Signed-off-by: Dmitri Epshtein <dima@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/5932
Tested-by: Star_Automation <star@marvell.com>
Reviewed-by: Joe Zhou <shjzhou@marvell.com>
Reviewed-by: Yehuda Yitschak <yehuday@marvell.com>
Reviewed-by: Ofir Drang <ofir@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig |   11 ++++
 .../mv_pp2/net_dev/mv_eth_hwf_sysfs.c              |   16 +++++-
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c      |   53 +++++++++++++++-----
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h      |    5 ++
 4 files changed, 71 insertions(+), 14 deletions(-)

diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig
index a68a3fc..6a491f2 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig
@@ -336,3 +336,14 @@ config MV_PON_TXQ_DEF
 
 endmenu
 
+menu "ERRATA / WA"
+
+config MV_ETH_SWF_HWF_CORRUPTION_WA
+        bool "Prevent data corruption in IOCC mode"
+        depends on (AURORA_IO_CACHE_COHERENCY && MV_ETH_HWF)
+        default y
+        ---help---
+	Enable this feature to avoid data corruption in IOCC mode
+	when HWF and SWF traffic use buffers from the same BM pools.
+
+endmenu
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_hwf_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_hwf_sysfs.c
index 040bdf3..8f6dbe5 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_hwf_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_hwf_sysfs.c
@@ -47,7 +47,9 @@ static ssize_t mv_pp2_hwf_help(char *buf)
 	o += scnprintf(buf+o, PAGE_SIZE-o, "cat                    status  - show SWF to HWF switching status\n");
 	o += scnprintf(buf+o, PAGE_SIZE-o, "echo msec            > timeout - set SWF to HWF switching timeout\n");
 	o += scnprintf(buf+o, PAGE_SIZE-o, "echo id txq rxq msec > switch  - start SWF to HWF switching process\n");
-
+#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+	o += scnprintf(buf+o, PAGE_SIZE-o, "echo en              > c_inv   - on/off L1 and L2 cache invalidation\n");
+#endif
 	return o;
 }
 
@@ -114,7 +116,7 @@ static ssize_t mv_pp2_hwf_dec_store(struct device *dev,
 				   struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
-	int             err;
+	int             err = 0;
 	unsigned int    val;
 	unsigned long   flags;
 
@@ -129,6 +131,10 @@ static ssize_t mv_pp2_hwf_dec_store(struct device *dev,
 
 	if (!strcmp(name, "timeout")) {
 		fwd_switch_msec = val;
+#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+	} else if (!strcmp(name, "c_inv")) {
+		mv_pp2_cache_inv_wa_ctrl(val);
+#endif
 	} else {
 		err = 1;
 		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
@@ -147,6 +153,9 @@ static DEVICE_ATTR(regs,		S_IRUSR, mv_pp2_hwf_show, NULL);
 static DEVICE_ATTR(status,		S_IRUSR, mv_pp2_hwf_show, NULL);
 static DEVICE_ATTR(switch,		S_IWUSR, NULL, mv_pp2_hwf_store);
 static DEVICE_ATTR(timeout,		S_IWUSR, NULL, mv_pp2_hwf_dec_store);
+#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+static DEVICE_ATTR(c_inv,		S_IWUSR, NULL, mv_pp2_hwf_dec_store);
+#endif
 
 static struct attribute *mv_pp2_hwf_attrs[] = {
 	&dev_attr_help.attr,
@@ -154,6 +163,9 @@ static struct attribute *mv_pp2_hwf_attrs[] = {
 	&dev_attr_status.attr,
 	&dev_attr_switch.attr,
 	&dev_attr_timeout.attr,
+#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+	&dev_attr_c_inv.attr,
+#endif
 	NULL
 };
 
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
index 45d689c..f8d0c32 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
@@ -59,6 +59,19 @@ disclaimer.
 
 #define MV_ETH_TX_PENDING_TIMEOUT_MSEC     1000
 
+#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+static unsigned int mv_pp2_swf_hwf_wa_en;
+void mv_pp2_cache_inv_wa_ctrl(int en)
+{
+	mv_pp2_swf_hwf_wa_en = en;
+}
+void mv_eth_iocc_l1_l2_cache_inv(unsigned char *v_start, int size)
+{
+	if (mv_pp2_swf_hwf_wa_en)
+		___dma_single_dev_to_cpu(v_start, size, DMA_FROM_DEVICE);
+}
+#endif /* CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA */
+
 static struct mv_mux_eth_ops mux_eth_ops;
 
 static struct  platform_device *pp2_sysfs;
@@ -134,7 +147,7 @@ static u32 mv_eth_netdev_fix_features(struct net_device *dev, u32 features);
 static netdev_features_t mv_eth_netdev_fix_features(struct net_device *dev, netdev_features_t features);
 #endif
 
-static struct sk_buff *mv_eth_skb_alloc(struct bm_pool *pool, MV_ULONG *phys_addr, gfp_t gfp_mask);
+static struct sk_buff *mv_eth_skb_alloc(struct bm_pool *pool, phys_addr_t *phys_addr, gfp_t gfp_mask);
 static MV_STATUS mv_eth_pool_create(int pool, int capacity);
 static int mv_eth_pool_add(int pool, int buf_num);
 static int mv_eth_pool_free(int pool, int num);
@@ -1435,7 +1448,7 @@ int mv_eth_skb_recycle(struct sk_buff *skb)
 {
 	int pool, cpu;
 	__u32 bm = skb->hw_cookie;
-	unsigned long phys_addr;
+	phys_addr_t phys_addr;
 	struct bm_pool *ppool;
 	bool is_recyclable;
 
@@ -1483,6 +1496,11 @@ int mv_eth_skb_recycle(struct sk_buff *skb)
 
 		phys_addr = dma_map_single(NULL, skb->head, RX_BUF_SIZE(ppool->pkt_size), DMA_FROM_DEVICE);
 		/*phys_addr = virt_to_phys(skb->head);*/
+#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+		/* Invalidate only part of the buffer used by CPU */
+		if ((ppool->type == MV_ETH_BM_MIXED_LONG) || (ppool->type == MV_ETH_BM_MIXED_SHORT))
+			mv_eth_iocc_l1_l2_cache_inv(skb->head, skb->len + skb_headroom(skb));
+#endif /* CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA */
 	} else {
 /*
 		pr_err("%s: Failed - skb=%p, pool=%d, bm_cookie=0x%x\n",
@@ -1514,25 +1532,33 @@ EXPORT_SYMBOL(mv_eth_skb_recycle);
 
 #endif /* CONFIG_NET_SKB_RECYCLE */
 
-static struct sk_buff *mv_eth_skb_alloc(struct bm_pool *pool, MV_ULONG *phys_addr, gfp_t gfp_mask)
+static struct sk_buff *mv_eth_skb_alloc(struct bm_pool *pool, phys_addr_t *phys_addr, gfp_t gfp_mask)
 {
 	struct sk_buff *skb;
+	phys_addr_t pa;
 
 	skb = __dev_alloc_skb(pool->pkt_size, gfp_mask);
 	if (!skb) {
 		STAT_ERR(pool->stats.skb_alloc_oom++);
 		return NULL;
 	}
-	if (phys_addr)
-		*phys_addr = dma_map_single(NULL, skb->head, RX_BUF_SIZE(pool->pkt_size), DMA_FROM_DEVICE);
-		/* *phys_addr = virt_to_phys(skb->head); */
+	/* pa = virt_to_phys(skb->head); */
+	if (phys_addr) {
+		pa = dma_map_single(NULL, skb->head, RX_BUF_SIZE(pool->pkt_size), DMA_FROM_DEVICE);
+		*phys_addr = pa;
+
+#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+		if ((pool->type == MV_ETH_BM_MIXED_LONG) || (pool->type == MV_ETH_BM_MIXED_SHORT))
+			mv_eth_iocc_l1_l2_cache_inv(skb->head, RX_BUF_SIZE(pool->pkt_size));
+#endif
+	}
 
 	STAT_DBG(pool->stats.skb_alloc_ok++);
 
 	return skb;
 }
 
-static unsigned char *mv_eth_hwf_buff_alloc(struct bm_pool *pool, MV_ULONG *phys_addr)
+static unsigned char *mv_eth_hwf_buff_alloc(struct bm_pool *pool, phys_addr_t *phys_addr)
 {
 	unsigned char *buff;
 	int size = RX_HWF_BUF_SIZE(pool->pkt_size);
@@ -1608,7 +1634,7 @@ EXPORT_SYMBOL(mv_eth_txq_done);
 inline int mv_eth_refill(struct bm_pool *ppool, __u32 bm, int is_recycle)
 {
 	struct sk_buff *skb;
-	MV_ULONG phys_addr;
+	phys_addr_t phys_addr;
 
 	if (is_recycle && (mv_eth_bm_in_use_read(ppool) < ppool->in_use_thresh))
 		return 0;
@@ -2710,7 +2736,7 @@ static int mv_eth_pool_add(int pool, int buf_num)
 	unsigned char *hwf_buff;
 	int i, buf_size, total_size;
 	__u32 bm = 0;
-	unsigned long phys_addr;
+	phys_addr_t phys_addr;
 
 	if (mvPp2MaxCheck(pool, MV_ETH_BM_POOLS, "bm_pool"))
 		return 0;
@@ -5072,9 +5098,12 @@ void mv_eth_status_print(void)
 	printk(KERN_ERR "totals: ports=%d\n", mv_eth_ports_num);
 
 #ifdef CONFIG_NET_SKB_RECYCLE
-	printk(KERN_ERR "SKB recycle = %s\n", mv_ctrl_recycle ? "Enabled" : "Disabled");
+	pr_info("SKB recycle                  : %s\n", mv_ctrl_recycle ? "Enabled" : "Disabled");
 #endif /* CONFIG_NET_SKB_RECYCLE */
 
+#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+	pr_info("HWF + SWF data corruption WA : %s\n", mv_pp2_swf_hwf_wa_en ? "Enabled" : "Disabled");
+#endif /* CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA */
 }
 
 /***********************************************************************************
@@ -5094,10 +5123,10 @@ void mv_eth_port_status_print(unsigned int port)
 	printk(KERN_ERR "\n");
 	printk(KERN_ERR "port=%d, flags=0x%lx, rx_weight=%d\n", port, pp->flags, pp->weight);
 
-	pr_info("RX next descriptor prefetch : %s\n",
+	pr_info("RX next descriptor prefetch  : %s\n",
 			pp->flags & MV_ETH_F_RX_DESC_PREFETCH ? "Enabled" : "Disabled");
 
-	pr_info("RX packet header prefetch   : %s\n\n",
+	pr_info("RX packet header prefetch    : %s\n\n",
 			pp->flags & MV_ETH_F_RX_PKT_PREFETCH ? "Enabled" : "Disabled");
 
 	if (pp->flags & MV_ETH_F_CONNECT_LINUX)
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
index 73cbc17..20f0896 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
@@ -1027,5 +1027,10 @@ MV_STATUS mv_eth_hwf_bm_create(int port, int mtuPktSize);
 void      mv_hwf_bm_dump(void);
 #endif /* CONFIG_MV_ETH_HWF && !CONFIG_MV_ETH_BM_CPU */
 
+#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+extern void ___dma_single_dev_to_cpu(const void *, size_t, enum dma_data_direction);
+void mv_pp2_cache_inv_wa_ctrl(int en);
+#endif
+
 #endif /* __mv_netdev_h__ */
 
-- 
1.7.5.4

