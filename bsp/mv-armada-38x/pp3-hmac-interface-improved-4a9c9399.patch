From 8a768e3e5d2a9f0ac553eadfbce533e6728e5b3f Mon Sep 17 00:00:00 2001
From: Yelena <yelena@marvell.com>
Date: Sun, 2 Feb 2014 15:30:28 +0200
Subject: [PATCH 1330/1825] pp3: hmac interface improved

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit 88248fbe9916ee7b4682c34b9859d0fb7087ad83

     HMAC driver store queues control structure.
     HMAC interface function were changed to use this.
     New functions added to connect queue to SPI group.

Change-Id: Id7391dbb6d3a428038cb3a9dffdd6579c7dba5d2
Signed-off-by: Yelena <yelena@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/5444
Tested-by: Star_Automation <star@marvell.com>
Reviewed-by: Dmitri Epshtein <dima@marvell.com>
Tested-by: Dmitri Epshtein <dima@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.c    |  101 +++++++++++++++++---
 drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.h    |   61 +++++++-----
 drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_bm.h |   21 ++--
 .../net/ethernet/marvell/pp3/hmac/mv_hmac_regs.h   |   17 +++-
 4 files changed, 151 insertions(+), 49 deletions(-)

diff --git a/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.c b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.c
index 1ee36f5..47b9d06 100644
--- a/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.c
+++ b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.c
@@ -71,13 +71,18 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #include "hmac/mv_hmac_regs.h"
 
 /* bitmap to store queues state (allocated/free) per frame */
-static unsigned int mv_pp3_hmac_queue_act[MV_PP3_HMAC_MAX_FRAME] = {0};
+static u32 mv_pp3_hmac_queue_act[MV_PP3_HMAC_MAX_FRAME] = {0};
 /* */
 struct pp3_unit_info pp3_hmac_gl;
 struct pp3_unit_info pp3_hmac_fr;
 
+/* Array of pointers to HMAC queue control structure */
+struct mv_pp3_hmac_queue_ctrl *mv_hmac_rxq_handle[MV_PP3_HMAC_MAX_FRAME][MV_PP3_QUEUES_PER_FRAME];
+struct mv_pp3_hmac_queue_ctrl *mv_hmac_txq_handle[MV_PP3_HMAC_MAX_FRAME][MV_PP3_QUEUES_PER_FRAME];
+
+
 /* local functions declaration */
-static int mv_pp3_hmac_queue_create(struct mv_pp3_queue_ctrl *q_ctrl, int desc_num);
+static int mv_pp3_hmac_queue_create(struct mv_pp3_hmac_queue_ctrl *q_ctrl, int bytes);
 
 /* general functions */
 /* store unit base address = silicon base address + unit offset */
@@ -121,16 +126,23 @@ void mv_pp3_hmac_queue_qm_mode_cfg(int frame, int queue, int qm_num)
 }
 
 
-/* RX queue functions */
+/************************ RX queue functions **************************************************/
 /* Allocate memory and init RX queue HW facility
- * size is a queue size in datagrams (16 bytes each) */
-u32 mv_pp3_hmac_rxq_init(int frame, int queue, int size, struct mv_pp3_queue_ctrl *qctrl)
+ * size is a queue size in datagrams (16 bytes each)
+ * Returns - pointer to HMAC RX queue structure */
+void *mv_pp3_hmac_rxq_init(int frame, int queue, int size)
 {
+	struct mv_pp3_hmac_queue_ctrl *qctrl;
 	u32 reg_data;
 
 	/* check if already created */
 	if ((mv_pp3_hmac_queue_act[frame] >> queue) & 1)
-		return 1;
+		return NULL;
+
+	/* allocate hmac queue control stucture */
+	qctrl = kmalloc(sizeof(struct mv_pp3_hmac_queue_ctrl), GFP_KERNEL);
+	if (qctrl == NULL)
+		return NULL;
 
 	qctrl->size = size;
 	qctrl->occ_dg = 0;
@@ -146,8 +158,10 @@ u32 mv_pp3_hmac_rxq_init(int frame, int queue, int size, struct mv_pp3_queue_ctr
 	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_REC_Q_CTRL_REG(queue), reg_data);
 
 	/* mark queue as created */
+	mv_hmac_rxq_handle[frame][queue] = qctrl;
 	mv_pp3_hmac_queue_act[frame] |= (1 << queue);
-	return 0;
+
+	return qctrl;
 }
 
 void mv_pp3_hmac_rxq_flush(int frame, int queue)
@@ -180,11 +194,49 @@ void mv_pp3_hmac_rxq_disable(int frame, int queue)
 	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_REC_Q_CTRL_REG(queue), reg_data);
 }
 
-/* TX queue functions */
-u32 mv_pp3_hmac_txq_init(int frame, int queue, int size, int cfh_size, struct mv_pp3_queue_ctrl *qctrl)
+/* Connect one of queue RX events to SPI interrupt group
+Inputs:
+	event - HMAC Rx event
+	 * 0 - QM queue - Timeout or new items added to the queue
+	 *     BM queue - allocate completed
+	 * 1 - QM queue only - Receive queue almost full
+	group - SPI group for event (0 - 7)
+*/
+void mv_pp3_hmac_rxq_event_cfg(int frame, int queue, int event, int group)
 {
 	u32 reg_data;
 
+	/* Configure event group */
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_RQ_EVENT_GROUP(queue));
+	if (event == 0) {
+		/* set group for event 0 */
+		U32_SET_FIELD(reg_data, MV_PP3_HMAC_RQ_EVENT0_GROUP_OFFS, MV_PP3_HMAC_RQ_EVENT0_GROUP_MASK, group);
+		/* enable event */
+		U32_SET_FIELD(reg_data, MV_PP3_HMAC_RQ_EVENT0_EN_OFFS, MV_PP3_HMAC_RQ_EVENT0_EN_MASK, 1);
+	} else if (event == 1) {
+		U32_SET_FIELD(reg_data, MV_PP3_HMAC_RQ_EVENT1_GROUP_OFFS, MV_PP3_HMAC_RQ_EVENT1_GROUP_MASK, group);
+		/* enable event */
+		U32_SET_FIELD(reg_data, MV_PP3_HMAC_RQ_EVENT1_EN_OFFS, MV_PP3_HMAC_RQ_EVENT1_EN_MASK, 1);
+	}
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_RQ_EVENT_GROUP(queue), reg_data);
+}
+
+
+/************************ TX queue functions **************************************************/
+/* Allocate memory and init TX queue HW facility
+ * size - queue size in datagrams (16 bytes each)
+ * cfh_size - if not 0, define queue with constant CFH size (number of datagrams in CFH)
+ * Returns - pointer to HMAC TX queue structure */
+void *mv_pp3_hmac_txq_init(int frame, int queue, int size, int cfh_size)
+{
+	struct mv_pp3_hmac_queue_ctrl *qctrl;
+	u32 reg_data;
+
+	/* allocate hmac queue control stucture */
+	qctrl = kmalloc(sizeof(struct mv_pp3_hmac_queue_ctrl), GFP_KERNEL);
+	if (qctrl == NULL)
+		return NULL;
+
 	qctrl->size = size;
 	qctrl->occ_dg = 0;
 	qctrl->cfh_size = cfh_size;
@@ -194,13 +246,16 @@ u32 mv_pp3_hmac_txq_init(int frame, int queue, int size, int cfh_size, struct mv
 	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_SQ_ADDR_LOW(queue), (u32)qctrl->first);
 	/* Store queue size in rq_size table, number of 16B units */
 	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_SQ_SIZE(queue), (u32)qctrl->size);
+
 	/* Configure Transmit Threshold TBD */
 	/* Disable queue */
 	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_HMAC_SEND_Q_CTRL_REG(queue));
 	U32_SET_FIELD(reg_data, MV_HMAC_SEND_Q_CTRL_SEND_Q_EN_OFFS, MV_HMAC_SEND_Q_CTRL_SEND_Q_EN_MASK, 0);
 	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_SEND_Q_CTRL_REG(queue), reg_data);
 
-	return 0;
+	mv_hmac_txq_handle[frame][queue] = qctrl;
+
+	return qctrl;
 }
 
 void mv_pp3_hmac_txq_enable(int frame, int queue)
@@ -236,16 +291,16 @@ static u8 *mv_pp3_queue_mem_alloc(int size)
 	return p_virt;
 }
 
-static int mv_pp3_hmac_queue_create(struct mv_pp3_queue_ctrl *q_ctrl, int desc_num)
+static int mv_pp3_hmac_queue_create(struct mv_pp3_hmac_queue_ctrl *q_ctrl, int bytes)
 {
 	int size;
 
+	size = bytes + MV_PP3_HMAC_Q_ALIGN;
 	/* Allocate memory for queue */
-	size = ((desc_num * MV_PP3_CFH_MIN_SIZE) + MV_PP3_HMAC_Q_ALIGN);
 	q_ctrl->first = mv_pp3_queue_mem_alloc(size);
 
 	if (q_ctrl->first == NULL) {
-		printk(KERN_ERR "%s: Can't allocate %d bytes for %d descr\n", __func__, size, desc_num);
+		pr_err("%s: Can't allocate %d bytes for HMAC queue.\n", __func__, size);
 		return 1;
 	}
 
@@ -256,7 +311,25 @@ static int mv_pp3_hmac_queue_create(struct mv_pp3_queue_ctrl *q_ctrl, int desc_n
 	return 0;
 }
 
-/* Print HMAC Frame unit register */
+/* Connect queue TX event to SPI interrupt group (BM queue only)
+Inputs:
+	group - SPI group for event (0 - 7)
+*/
+void mv_pp3_hmac_txq_event_cfg(int frame, int queue, int group)
+{
+	u32 reg_data;
+
+	/* Configure event group */
+	reg_data = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_SQ_EVENT_GROUP(queue));
+	/* set group for event 0 */
+	U32_SET_FIELD(reg_data, MV_PP3_HMAC_SQ_EVENT_GROUP_OFFS, MV_PP3_HMAC_SQ_EVENT_GROUP_MASK, group);
+	/* enable event */
+	U32_SET_FIELD(reg_data, MV_PP3_HMAC_SQ_EVENT_EN_OFFS, MV_PP3_HMAC_SQ_EVENT_EN_MASK, 1);
+
+	mv_pp3_hmac_frame_reg_write(frame, MV_PP3_HMAC_SQ_EVENT_GROUP(queue), reg_data);
+}
+
+/************************ Print HMAC Frame unit register **************************************/
 static void mv_pp3_hmac_fr_reg_print(int frame, char *reg_name, u32 reg)
 {
 	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name, reg, mv_pp3_hmac_frame_reg_read(frame, reg));
diff --git a/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.h b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.h
index 73fc897..366dd64 100644
--- a/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.h
+++ b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac.h
@@ -68,7 +68,9 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #include "hmac/mv_hmac_regs.h"
 
 #define MV_PP3_HMAC_MAX_FRAME			(16)
-#define MV_PP3_HMAC_DG_SIZE				(16)
+#define MV_PP3_QUEUES_PER_FRAME			(16)
+
+#define MV_PP3_HMAC_DG_SIZE				(16)	/* bytes */
 #define MV_PP3_CFH_MIN_SIZE				(32)
 #define MV_PP3_CFH_MAX_SIZE				(128)
 #define MV_PP3_CFH_DG_NUM				(MV_PP3_CFH_MIN_SIZE / MV_PP3_HMAC_DG_SIZE)
@@ -78,15 +80,17 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 extern struct pp3_unit_info pp3_hmac_gl;
 extern struct pp3_unit_info pp3_hmac_fr;
+extern struct mv_pp3_hmac_queue_ctrl *mv_hmac_rxq_handle[MV_PP3_HMAC_MAX_FRAME][MV_PP3_QUEUES_PER_FRAME];
+extern struct mv_pp3_hmac_queue_ctrl *mv_hmac_txq_handle[MV_PP3_HMAC_MAX_FRAME][MV_PP3_QUEUES_PER_FRAME];
 
-struct mv_pp3_queue_ctrl {
+struct mv_pp3_hmac_queue_ctrl {
 	u8 *first;		/* pointer to first byte in queue */
 	u8 *next_proc;	/* pointer to next CFH to procces in queue */
 	u8 *end;		/* pointer to first byte not belong to queue */
 	int occ_dg;		/* number of occupated datagram in queue */
 	int dummy_dg;	/* number of dummy datagrams added by last wraparound */
 	int size;		/* number of 16 bytes units (datagram) in queue */
-	int cfh_size;	/* for queue with constant CFH size is number of datargarms in CFH, (or -1) */
+	int cfh_size;	/* for queue with constant CFH size is number of datargarms in CFH, (or 0) */
 };
 
 /* CFH structure */
@@ -160,10 +164,11 @@ void mv_pp3_hmac_frame_unit_base(u32 unit_offset, u32 frame_offset);
  *****************************************/
 /* Allocate memory and init RX queue HW facility
  * size is a queue size in datagrams (16 bytes each) */
-u32 mv_pp3_hmac_rxq_init(int frame, int queue, int size, struct mv_pp3_queue_ctrl *qctrl);
+void *mv_pp3_hmac_rxq_init(int frame, int queue, int size);
 void mv_pp3_hmac_rxq_flush(int frame, int queue);
 void mv_pp3_hmac_rxq_enable(int frame, int queue);
 void mv_pp3_hmac_rxq_disable(int frame, int queue);
+void mv_pp3_hmac_rxq_event_cfg(int frame, int queue, int event, int group);
 
 /* Return number of received datagrams */
 static inline int mv_pp3_hmac_rxq_occ_get(int frame, int queue)
@@ -177,31 +182,29 @@ static inline void mv_pp3_hmac_rxq_occ_set(int frame, int queue, int size)
 	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_REC_Q_OCC_STATUS_UPDATE_REG(queue), size);
 }
 
-/* size - number of datagram in proccesed CFH */
-static inline u8 *mv_pp3_hmac_rxq_next_cfh(struct mv_pp3_queue_ctrl *qctrl, int *size)
+/* Returns pointer to next CFH buffer and it size */
+/* size - number of datagram                      */
+static inline u8 *mv_pp3_hmac_rxq_next_cfh(struct mv_pp3_hmac_queue_ctrl *qctrl, int *size)
 {
 	struct cfh_common_format *cfh;
-	int dg;
-	u8	*cfh_ptr;
 
 	/* Read 16 bytes of CFH pointed by "next_proc" field and calculate size of CFH in bytes */
 	cfh = (struct cfh_common_format *)qctrl->next_proc;
-	dg = cfh->cfh_length / MV_PP3_HMAC_DG_SIZE;
-
-	/* Store "next_proc" field value to return */
-	cfh_ptr = qctrl->next_proc;
-	/* Move "next_proc" pointer to next CFH ("next_proc" + size) */
-	qctrl->next_proc += cfh->cfh_length;
 
 	/* if get NULL CFH with "W" bit set, do wraparound */
 	if (cfh->qm_cntrl & MV_PP3_HMAC_CFH_DUMMY) {
 		qctrl->next_proc = qctrl->first;
 		/* return first CFH in queue */
 		cfh = (struct cfh_common_format *)qctrl->next_proc;
-		dg += cfh->cfh_length / MV_PP3_HMAC_DG_SIZE;
+		*size = cfh->cfh_length / MV_PP3_HMAC_DG_SIZE;
+		return NULL;
 	}
-	*size = dg;
-	return cfh_ptr;
+
+	/* Move "next_proc" pointer to next CFH ("next_proc" + size) */
+	qctrl->next_proc += cfh->cfh_length;
+
+	*size = cfh->cfh_length / MV_PP3_HMAC_DG_SIZE;
+	return (u8 *)cfh;
 }
 
 /*****************************************
@@ -209,16 +212,19 @@ static inline u8 *mv_pp3_hmac_rxq_next_cfh(struct mv_pp3_queue_ctrl *qctrl, int
  *****************************************/
 /* Allocate memory and init TX queue HW facility:
  * size is a queue size in datagrams (16 bytes each) */
-u32 mv_pp3_hmac_txq_init(int frame, int queue, int size, int cfh_size, struct mv_pp3_queue_ctrl *qctrl);
+void *mv_pp3_hmac_txq_init(int frame, int queue, int size, int cfh_size);
 void mv_pp3_hmac_txq_flush(int frame, int queue);
 void mv_pp3_hmac_txq_enable(int frame, int queue);
 void mv_pp3_hmac_txq_disable(int frame, int queue);
+void mv_pp3_hmac_txq_event_cfg(int frame, int queue, int group);
 
 /* Check for space in the queue.
  * Return 0 for positive answer, or 1 for negative.
  * dg_num - number of datagrams we are looking for */
-static inline int mv_pp3_hmac_txq_check_for_space(int frame, int queue, struct mv_pp3_queue_ctrl *qctrl, int dg_num)
+static inline int mv_pp3_hmac_txq_check_for_space(int frame, int queue, int dg_num)
 {
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_txq_handle[frame][queue];
+
 	if ((qctrl->size - qctrl->occ_dg) >= dg_num)
 		return 0;
 
@@ -228,14 +234,16 @@ static inline int mv_pp3_hmac_txq_check_for_space(int frame, int queue, struct m
 }
 
 /* Return number of free space in the end of queue (in datagrams) */
-static inline int mv_pp3_hmac_txq_free_room(struct mv_pp3_queue_ctrl *qctrl)
+static inline int mv_pp3_hmac_txq_free_room(struct mv_pp3_hmac_queue_ctrl *qctrl)
 {
 	return (qctrl->end - qctrl->next_proc) / MV_PP3_HMAC_DG_SIZE;
 }
 
 /* Return number of currently occupated datagrams in queue */
-static inline int mv_pp3_hmac_txq_occ_get(int frame, int queue, struct mv_pp3_queue_ctrl *qctrl)
+static inline int mv_pp3_hmac_txq_occ_get(int frame, int queue)
 {
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_txq_handle[frame][queue];
+
 	qctrl->occ_dg = mv_pp3_hmac_frame_reg_read(frame, MV_PP3_HMAC_SQ_OCC_STATUS(queue)) &
 					MV_PP3_HMAC_OCC_COUNTER_MASK;
 	return qctrl->occ_dg;
@@ -243,9 +251,10 @@ static inline int mv_pp3_hmac_txq_occ_get(int frame, int queue, struct mv_pp3_qu
 
 /* Return pointer to first free one CFH from queue with constant CFH size
  * (do queue wraparound, if needed) */
-static inline u8 *mv_pp3_hmac_const_txq_next_cfh(struct mv_pp3_queue_ctrl *qctrl)
+static inline u8 *mv_pp3_hmac_const_txq_next_cfh(int frame, int queue)
 {
 	u8 *cfh_ptr;
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_txq_handle[frame][queue];
 
 	if ((qctrl->cfh_size + qctrl->occ_dg) > qctrl->size)
 		return NULL;
@@ -262,11 +271,12 @@ static inline u8 *mv_pp3_hmac_const_txq_next_cfh(struct mv_pp3_queue_ctrl *qctrl
 
 /* Return pointer to first free one CFH (run queue wraparound, if needed) :
  * size is CFH size in datagrams (16 bytes each)     */
-static inline u8 *mv_pp3_hmac_txq_next_cfh(struct mv_pp3_queue_ctrl *qctrl, int size)
+static inline u8 *mv_pp3_hmac_txq_next_cfh(int frame, int queue, int size)
 {
 	u8 *cfh_ptr;
 	int end_free_dg;	/* number of free datagram in the queue end */
 	int start_free_dg;	/* number of free datagram in the queue start */
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_txq_handle[frame][queue];
 
 	/* calculate number of unused datagram n the queue end */
 	end_free_dg = (qctrl->end - qctrl->next_proc) / MV_PP3_HMAC_DG_SIZE;
@@ -303,8 +313,10 @@ static inline u8 *mv_pp3_hmac_txq_next_cfh(struct mv_pp3_queue_ctrl *qctrl, int
 }
 
 /* size - is number of datagrams to transmit         */
-static inline void mv_pp3_hmac_txq_send(int frame, int queue, int size, struct mv_pp3_queue_ctrl *qctrl)
+static inline void mv_pp3_hmac_txq_send(int frame, int queue, int size)
 {
+	struct mv_pp3_hmac_queue_ctrl *qctrl = mv_hmac_txq_handle[frame][queue];
+
 	size += qctrl->dummy_dg;
 	mv_pp3_hmac_frame_reg_write(frame, MV_HMAC_SEND_Q_OCC_STATUS_UPDATE_REG(queue), size);
 	qctrl->dummy_dg = 0;
@@ -316,4 +328,5 @@ void mv_pp3_hmac_queue_bm_mode_cfg(int frame, int queue);
  * q_num - is a number of QM queue                   */
 void mv_pp3_hmac_queue_qm_mode_cfg(int frame, int queue, int q_num);
 
+
 #endif /* __mvHmac_h__ */
diff --git a/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_bm.h b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_bm.h
index 9b03710..c220cfa 100644
--- a/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_bm.h
+++ b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_bm.h
@@ -83,23 +83,24 @@ struct mv_pp3_hmac_bm_cfh {
 };
 
 /* configure queue parameters used by BM queue       */
-u32 mv_pp3_hmac_bm_queue_init(int frame, int queue, int q_size,
-	struct mv_pp3_queue_ctrl *rxq_ctrl, struct mv_pp3_queue_ctrl *txq_ctrl)
+static int mv_pp3_hmac_bm_queue_init(int frame, int queue, int q_size)
 {
-	u32 ret = 0;
 	int size;
+	void *rxq_ctrl, *txq_ctrl;
 
 	size = MV_PP3_BM_PE_DG; /* number of descriptors * 1 datagrams (per PE) */
-	ret = mv_pp3_hmac_rxq_init(frame, queue, size, rxq_ctrl);
-	ret = mv_pp3_hmac_txq_init(frame, queue, size, MV_PP3_BM_PE_DG, txq_ctrl);
+	rxq_ctrl = mv_pp3_hmac_rxq_init(frame, queue, size);
+	txq_ctrl = mv_pp3_hmac_txq_init(frame, queue, size, MV_PP3_BM_PE_DG);
+	if ((rxq_ctrl == NULL) || (txq_ctrl == NULL))
+		return -1;
 
 	mv_pp3_hmac_queue_bm_mode_cfg(frame, queue);
 
-	return ret;
+	return 0;
 }
 
 /* send to BM pool (bp_id) request for (buff_num) buffers */
-void mv_pp3_hmac_bm_buff_request(int frame, int queue, int bp_id, int buff_num)
+static void mv_pp3_hmac_bm_buff_request(int frame, int queue, int bp_id, int buff_num)
 {
 	u32 data;
 
@@ -110,7 +111,7 @@ void mv_pp3_hmac_bm_buff_request(int frame, int queue, int bp_id, int buff_num)
 
 /* process BM pool (bp_id) responce for (buff_num) buffers
  * return pointer to buffer and move to next CFH           */
-struct mv_pp3_hmac_bm_cfh *mv_pp3_hmac_bm_buff_get(struct mv_pp3_queue_ctrl *rxq_ctrl)
+static struct mv_pp3_hmac_bm_cfh *mv_pp3_hmac_bm_buff_get(struct mv_pp3_hmac_queue_ctrl *rxq_ctrl)
 {
 	struct mv_pp3_hmac_bm_cfh *bm_cfh;
 
@@ -123,12 +124,12 @@ struct mv_pp3_hmac_bm_cfh *mv_pp3_hmac_bm_buff_get(struct mv_pp3_queue_ctrl *rxq
 
 /* fill request for BM buffer release.
  * return ERROR, if no space for message */
-int mv_pp3_hmac_bm_buff_free(int bp_id, u32 buff_addr, struct mv_pp3_queue_ctrl *qctrl)
+static int mv_pp3_hmac_bm_buff_free(int bp_id, u32 buff_addr, int frame, int queue)
 {
 	struct mv_pp3_hmac_bm_cfh *bm_cfh;
 
 	/* get pointer to PE and write parameters */
-	bm_cfh = (struct mv_pp3_hmac_bm_cfh *)mv_pp3_hmac_const_txq_next_cfh(qctrl);
+	bm_cfh = (struct mv_pp3_hmac_bm_cfh *)mv_pp3_hmac_const_txq_next_cfh(frame, queue);
 	if (bm_cfh == NULL)
 		return 1;
 
diff --git a/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_regs.h b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_regs.h
index 13a03c3..35fc823 100644
--- a/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_regs.h
+++ b/drivers/net/ethernet/marvell/pp3/hmac/mv_hmac_regs.h
@@ -309,7 +309,22 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #define MV_PP3_HMAC_SQ_EVENT_GROUP(n)	(0x0054 + 0x100*n)
 #define MV_PP3_HMAC_SQ_SW_QNUM_TDEST(n)	(0x0058 + 0x100*n)
 
-#define MV_PP3_HMAC_OCC_COUNTER_MASK	0xFFFF
+#define MV_PP3_HMAC_OCC_COUNTER_MASK	(0xFFFF)
+
+#define MV_PP3_HMAC_RQ_EVENT0_GROUP_OFFS		0
+#define MV_PP3_HMAC_RQ_EVENT0_GROUP_MASK		(0x7)
+#define MV_PP3_HMAC_RQ_EVENT0_EN_OFFS		3
+#define MV_PP3_HMAC_RQ_EVENT0_EN_MASK	(1 << MV_PP3_HMAC_RQ_EVENT0_EN_OFFS)
+
+#define MV_PP3_HMAC_RQ_EVENT1_GROUP_OFFS		4
+#define MV_PP3_HMAC_RQ_EVENT1_GROUP_MASK		(0x7)
+#define MV_PP3_HMAC_RQ_EVENT1_EN_OFFS		7
+#define MV_PP3_HMAC_RQ_EVENT1_EN_MASK	(1 << MV_PP3_HMAC_RQ_EVENT1_EN_OFFS)
+
+#define MV_PP3_HMAC_SQ_EVENT_GROUP_OFFS		0
+#define MV_PP3_HMAC_SQ_EVENT_GROUP_MASK		(0x7)
+#define MV_PP3_HMAC_SQ_EVENT_EN_OFFS		3
+#define MV_PP3_HMAC_SQ_EVENT_EN_MASK	(1 << MV_PP3_HMAC_SQ_EVENT_EN_OFFS)
 /**/
 
 #endif /* __mvHmacRegs_h__ */
-- 
1.7.5.4

