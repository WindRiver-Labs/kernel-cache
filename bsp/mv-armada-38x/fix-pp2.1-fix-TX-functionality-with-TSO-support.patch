From 4022202bf4a65dbf289c081afab955afefa6d25a Mon Sep 17 00:00:00 2001
From: Dmitri Epshtein <dima@marvell.com>
Date: Thu, 22 May 2014 16:53:54 -0400
Subject: [PATCH 1673/1825] fix: pp2.1: fix TX functionality with TSO support

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit d3ab8618770246a1d4fddc591ffb6051b1e4e8ad

	- Add MV_ETH_LIGHT_LOCK for syncronization between TX and TX_DONE on the same CPU.
	- Remove extra txq_done call in the mv_eth_tx_tso() function.
	- Add missing decrement of "reserved_num" field in mv_eth_tx_tso() function.
	Fix JIRA bug SYSTEMSW-623: "Kernel Panic occurs at multiple TCP sessions".
	- Improve TX debug statistics.

Signed-off-by: Dmitri Epshtein <dima@marvell.com>

Change-Id: Ia2351173002df8816c9d72177fc286e5a73c4e1e
Reviewed-on: http://vgitil04.il.marvell.com:8080/8178
Tested-by: Star_Automation <star@marvell.com>
Reviewed-by: Uri Eliyahu <uriel@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c      |  102 ++++++++++----------
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h      |   15 ++-
 2 files changed, 59 insertions(+), 58 deletions(-)

diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
index ede8265..349d079 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
@@ -2014,6 +2014,7 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 	struct txq_cpu_ctrl *txq_cpu_ptr = NULL;
 	struct aggr_tx_queue *aggr_txq_ctrl = NULL;
 	struct pp2_tx_desc *tx_desc;
+	unsigned long flags = 0;
 
 	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
 		STAT_INFO(pp->stats.netdev_stop++);
@@ -2071,6 +2072,8 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 	}
 	txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
 
+	MV_ETH_LIGHT_LOCK(flags);
+
 #ifdef CONFIG_MV_ETH_TSO
 	/* GSO/TSO */
 	if (skb_is_gso(skb)) {
@@ -2214,9 +2217,11 @@ out:
 		if ((txq_cpu_ptr->txq_count == frags) && (frags > 0))
 			mv_eth_add_tx_done_timer(pp->cpu_config[smp_processor_id()]);
 	}
-
 #endif /* CONFIG_MV_ETH_TXDONE_ISR */
 
+	if (txq_ctrl)
+		MV_ETH_LIGHT_UNLOCK(flags);
+
 	return NETDEV_TX_OK;
 }
 
@@ -2259,8 +2264,11 @@ static inline int mv_eth_tso_build_hdr_desc(struct pp2_tx_desc *tx_desc, struct
 	int mac_hdr_len = skb_network_offset(skb);
 
 	data = mv_eth_extra_pool_get(priv);
-	if (!data)
+	if (!data) {
+		pr_err("Can't allocate extra buffer for TSO\n");
 		return 0;
+	}
+	mv_eth_shadow_push(txq_ctrl, ((MV_ULONG)data | MV_ETH_SHADOW_EXT));
 
 	/* Reserve 2 bytes for IP header alignment */
 	mac = data + MV_ETH_MH_SIZE;
@@ -2302,8 +2310,6 @@ static inline int mv_eth_tso_build_hdr_desc(struct pp2_tx_desc *tx_desc, struct
 	tx_desc->pktOffset = bufPhysAddr & MV_ETH_TX_DESC_ALIGN;
 	tx_desc->bufPhysAddr = bufPhysAddr & (~MV_ETH_TX_DESC_ALIGN);
 
-	mv_eth_shadow_push(txq_ctrl, ((MV_ULONG)data | MV_ETH_SHADOW_EXT));
-
 	mv_eth_tx_desc_flush(tx_desc);
 
 	return hdr_len;
@@ -2422,28 +2428,8 @@ int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_eth_tx_
 #else
 		if (mv_eth_phys_desc_num_check(txq_cpu_ptr, seg_desc_num)) {
 #endif
-#ifndef CONFIG_MV_ETH_TXDONE_ISR
-			/* Try TX done and check resource again */
-#ifdef CONFIG_MV_ETH_STAT_DIST
-			u32 tx_done = mv_eth_txq_done(priv, txq_ctrl);
-
-			if (tx_done < priv->dist_stats.tx_done_dist_size)
-				priv->dist_stats.tx_done_dist[tx_done]++;
-#else
-			mv_eth_txq_done(priv, txq_ctrl);
-#endif /* CONFIG_MV_ETH_STAT_DIST */
-#ifdef CONFIG_MV_ETH_PP2_1
-		if (mv_eth_reserved_desc_num_proc(priv, tx_spec->txp, tx_spec->txq, seg_desc_num)) {
-#else
-		if (mv_eth_phys_desc_num_check(txq_cpu_ptr, seg_desc_num)) {
-#endif
-				STAT_DBG(priv->stats.tx_tso_no_resource++);
-				return 0;
-			}
-#else
 			STAT_DBG(priv->stats.tx_tso_no_resource++);
 			return 0;
-#endif /* CONFIG_MV_ETH_TXDONE_ISR */
 		}
 
 		seg_desc_num = 0;
@@ -2513,6 +2499,11 @@ int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_eth_tx_
 			}
 		}
 
+#ifdef CONFIG_MV_ETH_PP2_1
+		/* PPv2.1 - MAS 3.16, decrease number of reserved descriptors */
+		txq_cpu_ptr->reserved_num -= seg_desc_num;
+#endif
+
 		/* TCP segment is ready - transmit it */
 		wmb();
 		mvPp2AggrTxqPendDescAdd(seg_desc_num);
@@ -3052,6 +3043,7 @@ void mv_eth_link_tasklet(unsigned long data)
 	struct eth_port *pp;
 
 	regVal = mvGmacIsrSummaryCauseGet();
+
 	/* check only relevant interrupts - ports0 and 1 */
 	regVal &= (ETH_ISR_SUM_PORT0_MASK | ETH_ISR_SUM_PORT1_MASK);
 
@@ -5215,49 +5207,54 @@ void mv_eth_port_status_print(unsigned int port)
 	mv_eth_link_status_print(port);
 
 	pr_cont("\n");
-	printk(KERN_ERR "rxq_coal(pkts)[ q]      = ");
+	pr_info("rxq_coal(pkts)[ q]         = ");
 	for (q = 0; q < pp->rxq_num; q++)
 		printk(KERN_CONT "%4d ", mvPp2RxqPktsCoalGet(port, q));
 
-	printk(KERN_CONT "\n");
-	printk(KERN_ERR "rxq_coal(usec)[ q]      = ");
+	pr_cont("\n");
+	pr_info("rxq_coal(usec)[ q]         = ");
 	for (q = 0; q < pp->rxq_num; q++)
-		printk(KERN_CONT "%4d ", mvPp2RxqTimeCoalGet(port, q));
+		pr_cont("%4d ", mvPp2RxqTimeCoalGet(port, q));
 
-	printk(KERN_CONT "\n");
-	printk(KERN_ERR "rxq_desc(num)[ q]       = ");
+	pr_cont("\n");
+	pr_info("rxq_desc(num)[ q]          = ");
 	for (q = 0; q < pp->rxq_num; q++)
-		printk(KERN_CONT "%4d ", pp->rxq_ctrl[q].rxq_size);
+		pr_info("%4d ", pp->rxq_ctrl[q].rxq_size);
 
-	printk(KERN_CONT "\n");
+	pr_cont("\n");
 	for (txp = 0; txp < pp->txp_num; txp++) {
-		printk(KERN_ERR "txq_coal(pkts)[%2d.q]    = ", txp);
+		pr_info("txq_coal(pkts)[%2d.q]       = ", txp);
 		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++)
-			printk(KERN_CONT "%4d ", mvPp2TxDonePktsCoalGet(port, txp, q));
-		printk(KERN_CONT "\n");
+			pr_cont("%4d ", mvPp2TxDonePktsCoalGet(port, txp, q));
+		pr_cont("\n");
 
-		printk(KERN_ERR "txq_desc(num) [%2d.q]    = ", txp);
+		pr_info("txq_desc(num) [%2d.q]       = ", txp);
 		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
 			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + q];
-			printk(KERN_CONT "%4d ", txq_ctrl->txq_size);
+			pr_cont("%4d ", txq_ctrl->txq_size);
 		}
-		printk(KERN_CONT "\n");
+		pr_cont("\n");
 
-		printk(KERN_ERR "txq_hwf_desc(num) [%2d.q] = ", txp);
+		pr_info("txq_hwf_desc(num) [%2d.q]   = ", txp);
 		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
 			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + q];
-			printk(KERN_CONT "%4d ", txq_ctrl->hwf_size);
+			pr_cont("%4d ", txq_ctrl->hwf_size);
 		}
-		printk(KERN_CONT "\n");
+		pr_cont("\n");
 
-		printk(KERN_ERR "txq_swf_desc(num) [%2d.q] = ", txp);
+		pr_info("txq_swf_desc(num) [%2d.q]   = ", txp);
 		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
 			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + q];
-			printk(KERN_CONT "%4d ", txq_ctrl->txq_cpu[0].txq_size);
+			pr_cont("%4d ", txq_ctrl->txq_cpu[0].txq_size);
 		}
-		printk(KERN_CONT "\n");
+		pr_info("txq_rsvd_chunk(num) [%2d.q] = ", txp);
+		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + q];
+			pr_cont("%4d ", txq_ctrl->rsvd_chunk);
+		}
+		pr_cont("\n");
 	}
-	printk(KERN_ERR "\n");
+	pr_info("\n");
 
 #ifdef CONFIG_MV_ETH_TXDONE_ISR
 	printk(KERN_ERR "Do tx_done in NAPI context triggered by ISR\n");
@@ -5439,28 +5436,29 @@ void mv_eth_port_stats_print(unsigned int port)
 	}
 
 	pr_info("\n");
-	pr_info("TXP-TXQ:  count          send          done      reserved      chunk_alloc      no_resource\n\n");
+	pr_info("TXP-TXQ:  count  res_num      send          done     no_resource      res_req      res_total\n\n");
 
 	for (txp = 0; txp < pp->txp_num; txp++) {
 		for (queue = 0; queue < CONFIG_MV_ETH_TXQ; queue++)
 			for_each_possible_cpu(cpu) {
-				u32 txq_tx = 0, txq_txdone = 0, txq_txreq = 0, txq_err = 0;
+				u32 txq_tx = 0, txq_done = 0, txq_reserved_req = 0, txq_reserved_total = 0, txq_err = 0;
 
 				txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + queue];
 				txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
 #ifdef CONFIG_MV_ETH_STAT_DBG
 				txq_tx = txq_cpu_ptr->stats.txq_tx;
-				txq_txdone =  txq_cpu_ptr->stats.txq_txdone;
-				txq_txreq =  txq_cpu_ptr->stats.txq_txreq;
+				txq_done = txq_cpu_ptr->stats.txq_txdone;
+				txq_reserved_req = txq_cpu_ptr->stats.txq_reserved_req;
+				txq_reserved_total = txq_cpu_ptr->stats.txq_reserved_total;
 
 #endif /* CONFIG_MV_ETH_STAT_DBG */
 #ifdef CONFIG_MV_ETH_STAT_ERR
 				txq_err = txq_cpu_ptr->stats.txq_err;
 #endif /* CONFIG_MV_ETH_STAT_ERR */
 
-				printk(KERN_ERR "%d-%d-cpu#%d: %3d    %10u    %10u    %10u    %10u    %10u\n",
-				       txp, queue, cpu, txq_cpu_ptr->txq_count, txq_tx,
-				       txq_txdone,  txq_cpu_ptr->reserved_num, txq_txreq, txq_err);
+				pr_info("%d-%d-cpu#%d: %3d    %3d   %10u    %10u    %10u    %10u    %10u\n",
+				       txp, queue, cpu, txq_cpu_ptr->txq_count, txq_cpu_ptr->reserved_num,
+				       txq_tx, txq_done, txq_err, txq_reserved_req, txq_reserved_total);
 
 				memset(&txq_cpu_ptr->stats, 0, sizeof(txq_cpu_ptr->stats));
 			}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
index da16938..370f4e2 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
@@ -150,7 +150,8 @@ struct txq_stats {
 #endif /* CONFIG_MV_ETH_STAT_ERR */
 #ifdef CONFIG_MV_ETH_STAT_DBG
 	u32 txq_tx;
-	u32 txq_txreq; /*request reserved tx descriptors*/
+	u32 txq_reserved_req;   /* Number of requests to reserve TX descriptors */
+	u32 txq_reserved_total; /* Accumulated number of reserved TX descriptors */
 	u32 txq_txdone;
 #endif /* CONFIG_MV_ETH_STAT_DBG */
 };
@@ -257,7 +258,7 @@ struct port_stats {
 #define TOS_TO_DSCP(tos)	((tos >> 2) & 0x3F)
 
 /* Used in PPv2.1 */
-#define MV_ETH_CPU_DESC_CHUNK	20
+#define MV_ETH_CPU_DESC_CHUNK	64
 
 /* Masks used for tx_spec->flags */
 #define MV_ETH_TX_F_NO_PAD	0x0001
@@ -674,15 +675,17 @@ static inline int mv_eth_reserved_desc_num_proc(struct eth_port *pp, int txp, in
 			return 1;
 		}
 
-
 		new_reserved = mvPp2TxqAllocReservedDesc(pp->port, txp, txq, req);
+
+		STAT_DBG(txq_cpu_ptr->stats.txq_reserved_total += new_reserved);
 		txq_cpu_ptr->reserved_num += new_reserved;
 
-		if (txq_cpu_ptr->reserved_num < num)
-			/* out of resources - drop packet*/
+		if (txq_cpu_ptr->reserved_num < num) {
+			STAT_ERR(txq_cpu_ptr->stats.txq_err++);
 			return 1;
+		}
 
-		STAT_DBG(txq_cpu_ptr->stats.txq_txreq++);
+		STAT_DBG(txq_cpu_ptr->stats.txq_reserved_req++);
 	}
 
 	return 0;
-- 
1.7.5.4

