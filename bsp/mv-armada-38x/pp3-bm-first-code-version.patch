From fbaaf6eef913884fab1d739c045ab6b9e7672e59 Mon Sep 17 00:00:00 2001
From: Yelena <yelena@marvell.com>
Date: Sun, 23 Mar 2014 15:41:17 +0200
Subject: [PATCH 1514/1825] pp3: bm: first code version

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit 6da0bfcd8d8d64bb06ec7824df576df47fa42037

Change-Id: Id3446bc16514be635dbf7e68a7d07ac0ae8dada8
Signed-off-by: Yelena <yelena@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/6616
Reviewed-by: Dmitri Epshtein <dima@marvell.com>
Reviewed-by: Dovrat Zifroni <dovrat@marvell.com>
Reviewed-by: Eliezer Ben Zeev <eliezerb@marvell.com>
Tested-by: Dmitri Epshtein <dima@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 drivers/net/ethernet/marvell/pp3/Makefile          |    1 +
 drivers/net/ethernet/marvell/pp3/bm/mv_bm.c        | 3171 ++++++++++++++++++++
 drivers/net/ethernet/marvell/pp3/bm/mv_bm.h        |  759 +++++
 drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.c   |  560 ++++
 drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.h   |  910 ++++++
 drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c  |  782 +++++
 drivers/net/ethernet/marvell/pp3/bm/mv_qm.h        |  879 ++++++
 drivers/net/ethernet/marvell/pp3/common/mv_hw_if.h |    7 +
 drivers/net/ethernet/marvell/pp3/common/mv_sw_if.h |   16 +
 9 files changed, 7085 insertions(+), 0 deletions(-)
 create mode 100644 drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/bm/mv_bm.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/bm/mv_qm.h

diff --git a/drivers/net/ethernet/marvell/pp3/Makefile b/drivers/net/ethernet/marvell/pp3/Makefile
index 07c353f..c4f4b92 100644
--- a/drivers/net/ethernet/marvell/pp3/Makefile
+++ b/drivers/net/ethernet/marvell/pp3/Makefile
@@ -10,3 +10,4 @@ mv_pp3-objs := net_dev/mv_netdev.o hmac/mv_hmac.o emac/mv_emac.o
 mv_pp3-objs += emac/mv_emac_sysfs.o hmac/mv_hmac_sysfs.o net_dev/mv_dev_sysfs.o
 mv_pp3-objs += gmac/mv_gmac.o fw/mv_channel_if.o common/mv_stack.o
 mv_pp3-objs += fw/mv_fw.o fw/mv_fw_sysfs.o
+mv_pp3-objs += bm/mv_bm.o bm/mv_bm_sysfs.o bm/mv_bm_regs.o
\ No newline at end of file
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
new file mode 100644
index 0000000..e2ca576
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
@@ -0,0 +1,3171 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+/* includes */
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+/*
+*/
+
+#include "bm/mv_bm.h"
+#include "bm/mv_qm.h"
+#include "bm/mv_bm_regs.h"
+
+int bm_open(void)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+
+	rc = bm_reg_address_alias_init();
+	if (rc != OK)
+		return rc;
+	rc = bm_reg_size_alias_init();
+	if (rc != OK)
+		return rc;
+	rc = bm_reg_offset_alias_init();
+	if (rc != OK)
+		return rc;
+	rc = bm_pid_bid_init();
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+/*BM User Application Interface*/
+int bm_attr_all_pools_def_set(void)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 arDomain, awDomain, arCache, awCache, arQOS, awQOS;
+
+	arDomain = 0;
+	awDomain = 0;
+	arCache  = 3;
+	awCache  = 3;
+	arQOS    = 1;
+	awQOS    = 0;
+
+	rc = bm_attr_qm_pool_set(arDomain, awDomain, arCache, awCache, arQOS, awQOS);
+	if (rc != OK)
+		return rc;
+	rc = bm_attr_gp_pool_set(arDomain, awDomain, arCache, awCache, arQOS, awQOS);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_attr_qm_pool_set(u32 arDomain, u32 awDomain, u32 arCache, u32 awCache, u32 arQOS, u32 awQOS)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 bm_req_rcv_en;
+	struct bm_dram_domain_conf reg_dram_domain_conf;
+	struct bm_dram_cache_conf  reg_dram_cache_conf;
+	struct bm_dram_qos_conf    reg_dram_qos_conf;
+
+	if ((arDomain < BM_ADOMAIN_MIN) || (arDomain > BM_ADOMAIN_MAX))
+		return rc;
+	if ((awDomain < BM_ADOMAIN_MIN) || (awDomain > BM_ADOMAIN_MAX))
+		return rc;
+	if ((arCache  <  BM_ACACHE_MIN) || (arCache  >  BM_ACACHE_MAX))
+		return rc;
+	if ((awCache  <  BM_ACACHE_MIN) || (awCache  >  BM_ACACHE_MAX))
+		return rc;
+	if ((arQOS    <    BM_AQOS_MIN) || (arQOS    >    BM_AQOS_MAX))
+		return rc;
+	if ((awQOS    <    BM_AQOS_MIN) || (awQOS    >    BM_AQOS_MAX))
+		return rc;
+
+	rc = bm_enable_status_get(&bm_req_rcv_en);
+	if (rc != OK)
+		return rc;
+	if (bm_req_rcv_en == 1) {
+		rc = -BM_ATTR_CHANGE_AFTER_BM_ENABLE;
+		return rc;
+	}
+
+	reg_base_address =      bm.dram_domain_conf;
+	reg_size   =   bm_reg_size.dram_domain_conf;
+	reg_offset = bm_reg_offset.dram_domain_conf * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_domain_conf);
+	if (rc != OK)
+		return rc;
+
+	reg_dram_domain_conf.dwm_awdomain_b0 = awDomain;
+	reg_dram_domain_conf.drm_ardomain_b0 = arDomain;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_domain_conf);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      bm.dram_cache_conf;
+	reg_size   =   bm_reg_size.dram_cache_conf;
+	reg_offset = bm_reg_offset.dram_cache_conf * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_cache_conf);
+	if (rc != OK)
+		return rc;
+
+	reg_dram_cache_conf.dwm_awcache_b0   = awCache;
+	reg_dram_cache_conf.drm_arcache_b0   = arCache;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_cache_conf);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      bm.dram_qos_conf;
+	reg_size   =   bm_reg_size.dram_qos_conf;
+	reg_offset = bm_reg_offset.dram_qos_conf * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_qos_conf);
+	if (rc != OK)
+		return rc;
+
+	reg_dram_qos_conf.dwm_awqos_b0       = awQOS;
+	reg_dram_qos_conf.drm_arqos_b0       = arQOS;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_qos_conf);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_attr_gp_pool_set(u32 arDomain, u32 awDomain, u32 arCache, u32 awCache, u32 arQOS, u32 awQOS)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 bm_req_rcv_en;
+	struct bm_dram_domain_conf reg_dram_domain_conf;
+	struct bm_dram_cache_conf  reg_dram_cache_conf;
+	struct bm_dram_qos_conf    reg_dram_qos_conf;
+
+	if ((arDomain < BM_ADOMAIN_MIN) || (arDomain > BM_ADOMAIN_MAX))
+		return rc;
+	if ((awDomain < BM_ADOMAIN_MIN) || (awDomain > BM_ADOMAIN_MAX))
+		return rc;
+	if ((arCache  <  BM_ACACHE_MIN) || (arCache  >  BM_ACACHE_MAX))
+		return rc;
+	if ((awCache  <  BM_ACACHE_MIN) || (awCache  >  BM_ACACHE_MAX))
+		return rc;
+	if ((arQOS    <    BM_AQOS_MIN) || (arQOS    >    BM_AQOS_MAX))
+		return rc;
+	if ((awQOS    <    BM_AQOS_MIN) || (awQOS    >    BM_AQOS_MAX))
+		return rc;
+
+	rc = bm_enable_status_get(&bm_req_rcv_en);
+	if (rc != OK)
+		return rc;
+	if (bm_req_rcv_en == 1) {
+		rc = -BM_ATTR_CHANGE_AFTER_BM_ENABLE;
+		return rc;
+	}
+
+	reg_base_address =      bm.dram_domain_conf;
+	reg_size   =   bm_reg_size.dram_domain_conf;
+	reg_offset = bm_reg_offset.dram_domain_conf * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_domain_conf);
+	if (rc != OK)
+		return rc;
+
+	reg_dram_domain_conf.dwm_awdomain_bgp = awDomain;
+	reg_dram_domain_conf.drm_ardomain_bgp = arDomain;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_domain_conf);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      bm.dram_cache_conf;
+	reg_size   =   bm_reg_size.dram_cache_conf;
+	reg_offset = bm_reg_offset.dram_cache_conf * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_cache_conf);
+	if (rc != OK)
+		return rc;
+
+	reg_dram_cache_conf.dwm_awcache_bgp   = awCache;
+	reg_dram_cache_conf.drm_arcache_bgp   = arCache;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_cache_conf);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      bm.dram_qos_conf;
+	reg_size   =   bm_reg_size.dram_qos_conf;
+	reg_offset = bm_reg_offset.dram_qos_conf * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_qos_conf);
+	if (rc != OK)
+		return rc;
+
+	reg_dram_qos_conf.dwm_awqos_bgp       = awQOS;
+	reg_dram_qos_conf.drm_arqos_bgp       = arQOS;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_qos_conf);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_enable_status_get(u32 *bm_req_rcv_en)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	struct bm_common_general_conf          reg_common_general_conf;
+
+	reg_base_address =      bm.common_general_conf;
+	reg_size   =   bm_reg_size.common_general_conf;
+	reg_offset = bm_reg_offset.common_general_conf * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_common_general_conf);
+	if (rc != OK)
+		return rc;
+
+	*bm_req_rcv_en = reg_common_general_conf.bm_req_rcv_en;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_qm_gpm_pools_def_quick_init(u32 num_of_buffers, u32 *qece_base_address, u32 *pl_base_address)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
+
+	ae_thr               = BM_AE_THR_DEF;
+	af_thr               = BM_AF_THR_DEF;
+	cache_vmid           = BM_CACHE_VMID_DEF;
+	cache_attr           = BM_CACHE_ATTR_DEF;
+	cache_si_thr         = BM_CACHE_SI_THR_QM_DEF;
+	cache_so_thr         = BM_CACHE_SO_THR_QM_DEF;
+	cache_num_of_buffers = BM_CACHE_NUM_OF_BUFFERS_QM_DEF;
+
+	rc = bm_qm_gpm_pools_quick_init(num_of_buffers, qece_base_address, pl_base_address,
+		ae_thr, af_thr,	cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_qm_dram_pools_def_quick_init(u32 num_of_buffers, u32 *qece_base_address,	u32 *pl_base_address)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
+
+	ae_thr               = BM_AE_THR_DEF;
+	af_thr               = BM_AF_THR_DEF;
+	cache_vmid           = BM_CACHE_VMID_DEF;
+	cache_attr           = BM_CACHE_ATTR_DEF;
+	cache_si_thr         = BM_CACHE_SI_THR_QM_DEF;
+	cache_so_thr         = BM_CACHE_SO_THR_QM_DEF;
+	cache_num_of_buffers = BM_CACHE_NUM_OF_BUFFERS_QM_DEF;
+
+	rc = bm_qm_dram_pools_quick_init(num_of_buffers, qece_base_address,
+				pl_base_address, ae_thr, af_thr,
+				cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_qm_gpm_pools_quick_init(u32 num_of_buffers, u32 *qece_base_address,
+						u32 *pl_base_address, u32 ae_thr, u32 af_thr,
+						u32 cache_vmid, u32 cache_attr, u32 cache_so_thr, u32 cache_si_thr,
+						u32 cache_num_of_buffers)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pool, quick_init, pe_size, bm_req_rcv_en;
+	struct mv_word40 base_address;
+	u32 granularity_of_pe_in_dram, granularity_of_pe_in_cache;
+
+	granularity_of_pe_in_dram  = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_DRAM;		/* 64/4 */
+	granularity_of_pe_in_cache = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_CACHE;	/* 64/8 */
+
+	if       ((num_of_buffers % granularity_of_pe_in_dram)  != 0)
+		return rc;  /*qm PE are always 22bits which is 4Bytes */
+	if               ((ae_thr % granularity_of_pe_in_dram)  != 0)
+		return rc;
+	if               ((af_thr % granularity_of_pe_in_dram)  != 0)
+		return rc;
+	if ((cache_num_of_buffers % granularity_of_pe_in_cache) != 0)
+		return rc;
+	if (ae_thr       >= af_thr)
+		return rc;
+	if (cache_so_thr >= cache_si_thr + 16)
+		return rc;
+	if ((num_of_buffers       < BM_NUM_OF_BUFFERS_QM_MIN) || (num_of_buffers > BM_NUM_OF_BUFFERS_QM_GPM_MAX))
+		return rc;
+/*	if ((qece_base_address_hi <  BM_DRAM_ADDRESS_HI_MIN) || (qece_base_address_hi >  BM_DRAM_ADDRESS_HI_MAX)) */
+	if ((((struct mv_word40 *)qece_base_address)->hi < BM_DRAM_ADDRESS_HI_MIN) ||
+		(((struct mv_word40 *)qece_base_address)->hi > BM_DRAM_ADDRESS_HI_MAX))
+		return rc;
+/*	if ((qece_base_address_lo <  BM_DRAM_ADDRESS_LO_MIN) || (qece_base_address_lo >  BM_DRAM_ADDRESS_LO_MAX)) */
+	if ((((struct mv_word40 *)qece_base_address)->lo < BM_DRAM_ADDRESS_LO_MIN) ||
+		(((struct mv_word40 *)qece_base_address)->lo > BM_DRAM_ADDRESS_LO_MAX))
+		return rc;
+/*	if ((pl_base_address_hi   <  BM_DRAM_ADDRESS_HI_MIN) || (pl_base_address_hi   >  BM_DRAM_ADDRESS_HI_MAX)) */
+	if ((((struct mv_word40 *)pl_base_address)->hi < BM_DRAM_ADDRESS_HI_MIN) ||
+		(((struct mv_word40 *)pl_base_address)->hi > BM_DRAM_ADDRESS_HI_MAX))
+		return rc;
+/*	if ((pl_base_address_lo   <  BM_DRAM_ADDRESS_LO_MIN) || (pl_base_address_lo   >  BM_DRAM_ADDRESS_LO_MAX)) */
+	if ((((struct mv_word40 *)pl_base_address)->lo < BM_DRAM_ADDRESS_LO_MIN) ||
+		(((struct mv_word40 *)pl_base_address)->lo > BM_DRAM_ADDRESS_LO_MAX))
+		return rc;
+	if ((ae_thr               <           BM_AE_THR_MIN) || (ae_thr               >           BM_AE_THR_MAX))
+		return rc;
+	if ((af_thr               <           BM_AF_THR_MIN) || (af_thr               >           BM_AF_THR_MAX))
+		return rc;
+	if ((cache_vmid           <             BM_VMID_MIN) || (cache_vmid           >             BM_VMID_MAX))
+		return rc;
+	if ((cache_attr           <       BM_CACHE_ATTR_MIN) || (cache_attr           >       BM_CACHE_ATTR_MAX))
+		return rc;
+	if ((cache_so_thr         <     BM_CACHE_SO_THR_MIN) || (cache_so_thr         >     BM_CACHE_SO_THR_MAX))
+		return rc;
+	if ((cache_si_thr         <     BM_CACHE_SI_THR_MIN) || (cache_si_thr         >     BM_CACHE_SI_THR_MAX))
+		return rc;
+	if ((cache_num_of_buffers < BM_CACHE_NUM_OF_BUFFERS_QM_MIN)	||
+		(cache_num_of_buffers > BM_CACHE_NUM_OF_BUFFERS_QM_MAX))
+		return rc;
+
+	rc = bm_enable_status_get(&bm_req_rcv_en);
+	if (rc != OK)
+		return rc;
+
+	if (bm_req_rcv_en == 1) {
+		rc = -BM_ATTR_CHANGE_AFTER_BM_ENABLE;
+		return rc;
+	}
+
+	pool = 0;
+	base_address.hi = ((struct mv_word40 *)pl_base_address)->hi;
+	base_address.lo = ((struct mv_word40 *)pl_base_address)->lo;
+	quick_init = 1;
+	pe_size = 1;
+	rc = bm_pool_dram_set(pool, num_of_buffers, pe_size, (u32 *)&base_address, ae_thr, af_thr);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_cache_set(pool, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_fill_level_set(pool, num_of_buffers, pe_size, quick_init);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_memory_fill(pool, num_of_buffers, (u32 *)&base_address);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_enable(pool, quick_init);
+	if (rc != OK)
+		return rc;
+
+	pool = 1;
+	base_address.hi = ((struct mv_word40 *)qece_base_address)->hi;
+	base_address.lo = ((struct mv_word40 *)qece_base_address)->lo;
+	quick_init = 1;
+	pe_size = 1;
+	rc = bm_pool_dram_set(pool, num_of_buffers, pe_size, (u32 *)&base_address, ae_thr, af_thr);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_cache_set(pool, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_fill_level_set(pool, num_of_buffers, pe_size, quick_init);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_memory_fill(pool, num_of_buffers, (u32 *)&base_address);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_enable(pool, quick_init);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_qm_dram_pools_quick_init(u32 num_of_buffers, u32 *qece_base_address,
+			u32 *pl_base_address, u32 ae_thr, u32 af_thr,
+			u32 cache_vmid, u32 cache_attr, u32 cache_so_thr, u32 cache_si_thr,
+			u32 cache_num_of_buffers)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pool, base_address_allocate, quick_init, pe_size, bm_req_rcv_en, buffer_size;
+	struct mv_word40 base_address;
+	u32 granularity_of_pe_in_dram, granularity_of_pe_in_cache;
+
+	granularity_of_pe_in_dram  = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_DRAM;		/* 64/4 */
+	granularity_of_pe_in_cache = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_CACHE;	/* 64/4 */
+
+	if       ((num_of_buffers % granularity_of_pe_in_dram)  != 0)
+		return rc;  /*qm PE are always 22bits which is 4Bytes */
+	if               ((ae_thr % granularity_of_pe_in_dram)  != 0)
+		return rc;
+	if               ((af_thr % granularity_of_pe_in_dram)  != 0)
+		return rc;
+	if ((cache_num_of_buffers % granularity_of_pe_in_cache) != 0)
+		return rc;
+	if (ae_thr       >= af_thr)
+		return rc;
+	if (cache_so_thr >= cache_si_thr + 16)
+		return rc;
+
+	if ((num_of_buffers < BM_NUM_OF_BUFFERS_QM_MIN) || (num_of_buffers > BM_NUM_OF_BUFFERS_QM_DRAM_MAX))
+		return rc;
+/*	if ((qece_base_address_hi <  BM_DRAM_ADDRESS_HI_MIN) || (qece_base_address_hi >  BM_DRAM_ADDRESS_HI_MAX)) */
+	if ((((struct mv_word40 *)qece_base_address)->hi < BM_DRAM_ADDRESS_HI_MIN) ||
+		(((struct mv_word40 *)qece_base_address)->hi > BM_DRAM_ADDRESS_HI_MAX))
+		return rc;
+/*	if ((qece_base_address_lo <  BM_DRAM_ADDRESS_LO_MIN) || (qece_base_address_lo >  BM_DRAM_ADDRESS_LO_MAX)) */
+	if ((((struct mv_word40 *)qece_base_address)->lo < BM_DRAM_ADDRESS_LO_MIN) ||
+		(((struct mv_word40 *)qece_base_address)->lo > BM_DRAM_ADDRESS_LO_MAX))
+		return rc;
+/*	if ((pl_base_address_hi   <  BM_DRAM_ADDRESS_HI_MIN) || (pl_base_address_hi   >  BM_DRAM_ADDRESS_HI_MAX)) */
+	if ((((struct mv_word40 *)pl_base_address)->hi < BM_DRAM_ADDRESS_HI_MIN) ||
+		(((struct mv_word40 *)pl_base_address)->hi > BM_DRAM_ADDRESS_HI_MAX))
+		return rc;
+/*	if ((pl_base_address_lo   <  BM_DRAM_ADDRESS_LO_MIN) || (pl_base_address_lo   >  BM_DRAM_ADDRESS_LO_MAX)) */
+	if ((((struct mv_word40 *)pl_base_address)->hi < BM_DRAM_ADDRESS_LO_MIN) ||
+		(((struct mv_word40 *)pl_base_address)->hi > BM_DRAM_ADDRESS_LO_MAX))
+		return rc;
+	if ((ae_thr               <           BM_AE_THR_MIN) || (ae_thr               >           BM_AE_THR_MAX))
+		return rc;
+	if ((af_thr               <           BM_AF_THR_MIN) || (af_thr               >           BM_AF_THR_MAX))
+		return rc;
+	if ((cache_vmid           <             BM_VMID_MIN) || (cache_vmid           >             BM_VMID_MAX))
+		return rc;
+	if ((cache_attr           <       BM_CACHE_ATTR_MIN) || (cache_attr           >       BM_CACHE_ATTR_MAX))
+		return rc;
+	if ((cache_so_thr         <     BM_CACHE_SO_THR_MIN) || (cache_so_thr         >     BM_CACHE_SO_THR_MAX))
+		return rc;
+	if ((cache_si_thr         <     BM_CACHE_SI_THR_MIN) || (cache_si_thr         >     BM_CACHE_SI_THR_MAX))
+		return rc;
+	if ((cache_num_of_buffers < BM_CACHE_NUM_OF_BUFFERS_QM_MIN)	||
+		(cache_num_of_buffers > BM_CACHE_NUM_OF_BUFFERS_QM_MAX))
+		return rc;
+
+	rc = bm_enable_status_get(&bm_req_rcv_en);
+	if (rc != OK)
+		return rc;
+	if (bm_req_rcv_en == 1) {
+		rc = -BM_ATTR_CHANGE_AFTER_BM_ENABLE;
+		return rc;
+	}
+
+	pool = 2;
+	base_address.hi = ((struct mv_word40 *)pl_base_address)->hi;
+	base_address.lo = ((struct mv_word40 *)pl_base_address)->lo;
+	quick_init = 1;
+	pe_size = 1;
+	buffer_size = BM_BUFFER_SIZE_P2;
+	rc = bm_pool_dram_set(pool, num_of_buffers, pe_size, (u32 *)&base_address, ae_thr, af_thr);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_cache_set(pool, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_fill_level_set(pool, num_of_buffers, pe_size, quick_init);
+	if (rc != OK)
+		return rc;
+	/*	for pools 2&3 it allocates the buffer memory before filling the pool	*/
+	rc = ENOMEM;
+	base_address_allocate = (u32)MV_MALLOC((num_of_buffers + 1) * buffer_size, GFP_KERNEL);
+	if (base_address_allocate == (u32)NULL)
+		return rc;
+		/*base_address_hi need to be resolved - ???*/
+	base_address.hi = 0;
+	base_address.lo = base_address_allocate;
+	rc = bm_pool_memory_fill(pool, num_of_buffers, (u32 *)&base_address);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_enable(pool, quick_init);
+	if (rc != OK)
+		return rc;
+	((struct mv_word40 *)pl_base_address)->hi = base_address.hi;
+	((struct mv_word40 *)pl_base_address)->lo = base_address.lo;
+
+	pool = 3;
+	base_address.hi = ((struct mv_word40 *)qece_base_address)->hi;
+	base_address.lo = ((struct mv_word40 *)qece_base_address)->lo;
+	quick_init = 1;
+	pe_size = 1;
+	buffer_size = BM_BUFFER_SIZE_P3;
+	rc = bm_pool_dram_set(pool, num_of_buffers, pe_size, (u32 *)&base_address, ae_thr, af_thr);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_cache_set(pool, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_fill_level_set(pool, num_of_buffers, pe_size, quick_init);
+	if (rc != OK)
+		return rc;
+	/*	for pools 2&3 it allocates the buffer memory before filling the pool	*/
+	rc = ENOMEM;
+	base_address_allocate = (u32)MV_MALLOC((num_of_buffers + 1) * buffer_size, GFP_KERNEL);
+	if (base_address_allocate == (u32)NULL)
+		return rc;
+		/*base_address_hi need to be resolved - ???*/
+	base_address.hi = 0;
+	base_address.lo = base_address_allocate;
+	rc = bm_pool_memory_fill(pool, num_of_buffers, (u32 *)&base_address);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_enable(pool, quick_init);
+	if (rc != OK)
+		return rc;
+	((struct mv_word40 *)qece_base_address)->hi = base_address.hi;
+	((struct mv_word40 *)qece_base_address)->lo = base_address.lo;
+
+	rc = qm_pfe_base_address_pool_set(pl_base_address, qece_base_address);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_pool_quick_init_status_get(u32 pool, u32 *completed)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pid, bid, pid_local;
+	struct bm_pool_st   reg_pool_st;
+
+	if ((pool           <     BM_POOL_MIN) || (pool           >     BM_POOL_MAX))
+		return rc;
+	if ((pool           >  BM_POOL_QM_MAX) && (pool           <  BM_POOL_GP_MIN))
+		return rc; /* pools 4, 5, 6, 7 don't exist */
+	if (((u32)completed < BM_DATA_PTR_MIN) || ((u32)completed > BM_DATA_PTR_MAX))
+		return rc;
+
+	pid       = (int)pool;
+	bid       = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	reg_base_address =            bm.b_pool_n_st[bid];
+	reg_size         =   bm_reg_size.b_pool_n_st[bid];
+	reg_offset       = bm_reg_offset.b_pool_n_st[bid] * pid_local;
+
+	rc = bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pool_st);
+	if (rc != OK)
+		return rc;
+	*completed = reg_pool_st.pool_fill_bgt_si_thr_st;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_gp_pool_def_basic_init(u32 pool, u32 num_of_buffers, u32 *base_address, u32 partition_model)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pe_size, pool_pair, ae_thr, af_thr, cache_vmid, cache_attr,
+			cache_so_thr, cache_si_thr, cache_num_of_buffers;
+
+	pe_size              = BM_PE_SIZE_DEF;
+	pool_pair            = BM_POOL_PAIR_GP_DEF;
+	ae_thr               = BM_AE_THR_DEF;
+	af_thr               = BM_AF_THR_DEF;
+	cache_vmid           = BM_CACHE_VMID_DEF;
+	cache_attr           = BM_CACHE_ATTR_DEF;
+
+	if (partition_model == 0) {			/* large partition in cache */
+		cache_si_thr         = BM_CACHE_SI_THR_GP_BIG_DEF;
+		cache_so_thr         = BM_CACHE_SO_THR_GP_BIG_DEF;
+		cache_num_of_buffers = BM_CACHE_NUM_OF_BUFFERS_GP_BIG_DEF;
+	} else if (partition_model == 1) {	/* small partition in cache */
+		cache_si_thr         = BM_CACHE_SI_THR_GP_SMALL_DEF;
+		cache_so_thr         = BM_CACHE_SO_THR_GP_SMALL_DEF;
+		cache_num_of_buffers = BM_CACHE_NUM_OF_BUFFERS_GP_SMALL_DEF;
+	} else
+		return rc;
+
+	rc = bm_gp_pool_basic_init(pool, num_of_buffers, base_address, pe_size, pool_pair,
+					ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr,
+					cache_num_of_buffers);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_gp_pool_basic_init(u32 pool, u32 num_of_buffers, u32 *base_address,
+				u32 pe_size, u32 pool_pair, u32 ae_thr, u32 af_thr,
+				u32 cache_vmid, u32 cache_attr, u32 cache_so_thr, u32 cache_si_thr,
+				u32 cache_num_of_buffers)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 quick_init = 0;	/* quick_init is FALSE */
+	u32 granularity_of_pe_in_dram, granularity_of_pe_in_cache;
+
+	if (pe_size == BM_PE_SIZE_IS_40_BITS) {
+		granularity_of_pe_in_dram  =
+			GRANULARITY_OF_64_BYTES / GP_PE_SIZE_OF_40_BITS_IN_BYTES_IN_DRAM;	/* 64/8 */
+		granularity_of_pe_in_cache =
+			GRANULARITY_OF_64_BYTES / GP_PE_SIZE_IN_BYTES_IN_CACHE;			/* 64/8 */
+	} else if (pe_size == BM_PE_SIZE_IS_32_BITS) {
+		granularity_of_pe_in_dram  =
+			GRANULARITY_OF_64_BYTES / GP_PE_SIZE_OF_32_BITS_IN_BYTES_IN_DRAM;	/* 64/4 */
+		granularity_of_pe_in_cache =
+			GRANULARITY_OF_64_BYTES / GP_PE_SIZE_IN_BYTES_IN_CACHE;			/* 64/8 */
+	} else
+		return rc;
+
+	if       ((num_of_buffers %  granularity_of_pe_in_dram) != 0)
+		return rc;
+	if               ((ae_thr %  granularity_of_pe_in_dram) != 0)
+		return rc;
+	if               ((af_thr %  granularity_of_pe_in_dram) != 0)
+		return rc;
+	if ((((struct mv_word40 *)base_address)->lo %  granularity_of_pe_in_dram) != 0)
+		return rc;
+	if ((cache_num_of_buffers % granularity_of_pe_in_cache) != 0)
+		return rc;
+	if (ae_thr       >= af_thr)
+		return rc;
+	if (cache_so_thr >= cache_si_thr + 16)
+		return rc;
+
+
+
+
+	if ((pool                 <          BM_POOL_GP_MIN) || (pool                 >          BM_POOL_GP_MAX))
+		return rc;
+	if ((num_of_buffers       < BM_NUM_OF_BUFFERS_GP_MIN) || (num_of_buffers       > BM_NUM_OF_BUFFERS_GP_MAX))
+		return rc;
+/*	if ((base_address_hi      <  BM_DRAM_ADDRESS_HI_MIN) || (base_address_hi      >  BM_DRAM_ADDRESS_HI_MAX)) */
+	if ((((struct mv_word40 *)base_address)->hi < BM_DRAM_ADDRESS_HI_MIN) ||
+		(((struct mv_word40 *)base_address)->hi > BM_DRAM_ADDRESS_HI_MAX))
+		return rc;
+/*	if ((base_address_lo      <  BM_DRAM_ADDRESS_LO_MIN) || (base_address_lo      >  BM_DRAM_ADDRESS_LO_MAX)) */
+	if ((((struct mv_word40 *)base_address)->lo < BM_DRAM_ADDRESS_LO_MIN) ||
+		(((struct mv_word40 *)base_address)->lo > BM_DRAM_ADDRESS_LO_MAX))
+		return rc;
+	if ((pe_size              <          BM_PE_SIZE_MIN) || (pe_size              >          BM_PE_SIZE_MAX))
+		return rc;
+	if ((pool_pair            <        BM_POOL_PAIR_MIN) || (pool_pair            >        BM_POOL_PAIR_MAX))
+		return rc;
+	if ((ae_thr               <           BM_AE_THR_MIN) || (ae_thr               >           BM_AE_THR_MAX))
+		return rc;
+	if ((af_thr               <           BM_AF_THR_MIN) || (af_thr               >           BM_AF_THR_MAX))
+		return rc;
+	if ((cache_vmid           <       BM_CACHE_VMID_MIN) || (cache_vmid           >       BM_CACHE_VMID_MAX))
+		return rc;
+	if ((cache_attr           <       BM_CACHE_ATTR_MIN) || (cache_attr           >       BM_CACHE_ATTR_MAX))
+		return rc;
+	if ((cache_so_thr         <     BM_CACHE_SO_THR_MIN) || (cache_so_thr         >     BM_CACHE_SO_THR_MAX))
+		return rc;
+	if ((cache_si_thr         <     BM_CACHE_SI_THR_MIN) || (cache_si_thr         >     BM_CACHE_SI_THR_MAX))
+		return rc;
+	if ((cache_num_of_buffers < BM_CACHE_NUM_OF_BUFFERS_GP_MIN)	||
+		(cache_num_of_buffers > BM_CACHE_NUM_OF_BUFFERS_GP_MAX))
+		return rc;
+
+	rc = bm_pool_dram_set(pool, num_of_buffers, pe_size, base_address, ae_thr, af_thr);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_cache_set(pool, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_fill_level_set(pool, num_of_buffers, pe_size, quick_init);
+	if (rc != OK)
+		return rc;
+	rc = bm_gp_pool_pe_size_set(pool, pe_size);
+	if (rc != OK)
+		return rc;
+	rc = bm_gp_pool_pair_set(pool, pool_pair);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_enable(pool, quick_init);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_enable(void)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	struct bm_common_general_conf          reg_common_general_conf;
+	u32 bm_req_rcv_en;
+
+	reg_base_address =      bm.common_general_conf;
+	reg_size   =   bm_reg_size.common_general_conf;
+	reg_offset = bm_reg_offset.common_general_conf * 0;
+
+	rc = bm_enable_status_get(&bm_req_rcv_en);
+	if (rc != OK)
+		return rc;
+	if (bm_req_rcv_en == 1) {
+		rc = -BM_CHANGE_AFTER_BM_ENABLE;
+		return rc;
+	}
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_common_general_conf);
+	if (rc != OK)
+		return rc;
+	reg_common_general_conf.drm_si_decide_extra_fill = 0;
+	reg_common_general_conf.bm_req_rcv_en = 1;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_common_general_conf);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_disable(void)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	struct bm_common_general_conf          reg_common_general_conf;
+	u32 pool;
+
+	for (pool = BM_POOL_GP_MIN; pool <= BM_POOL_GP_MAX; pool++) {
+		rc = bm_pool_disable(pool);
+		if (rc != OK)
+			return rc;
+	}
+
+	for (pool = BM_POOL_QM_MIN; pool <= BM_POOL_QM_MAX; pool++) {
+		rc = bm_pool_disable(pool);
+		if (rc != OK)
+			return rc;
+	}
+
+	reg_base_address =      bm.common_general_conf;
+	reg_size   =   bm_reg_size.common_general_conf;
+	reg_offset = bm_reg_offset.common_general_conf * 0;
+
+	rc = bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_common_general_conf);
+	if (rc != OK)
+		return rc;
+	reg_common_general_conf.bm_req_rcv_en = 1;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_common_general_conf);
+	if (rc != OK)
+		return rc;
+
+/*	free(base_address_lo);	- ???*/
+
+	rc = OK;
+	return rc;
+}
+
+int bm_pool_fill_level_get(u32 pool, u32 *fill_level)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pid, bid, pid_local;
+	struct bm_tpr_drw_mng_ball_dyn_data         tab_tpr_drw_mng_ball_dyn;
+
+	if ((pool            <     BM_POOL_MIN) || (pool            >     BM_POOL_MAX))
+		return rc;
+	if ((pool            >  BM_POOL_QM_MAX) && (pool            <  BM_POOL_GP_MIN))
+		return rc; /* pools 4, 5, 6, 7 don't exist */
+	if (((u32)fill_level < BM_DATA_PTR_MIN) || ((u32)fill_level > BM_DATA_PTR_MAX))
+		return rc;
+
+	pid       = (int)pool;
+	bid       = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	reg_base_address =      bm.tpr_drw_mng_ball_dyn;
+	reg_size   =   bm_reg_size.tpr_drw_mng_ball_dyn;
+	reg_offset = bm_reg_offset.tpr_drw_mng_ball_dyn * BM_PID_TO_GLOBAL_POOL_IDX(pid);
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_tpr_drw_mng_ball_dyn);
+	if (rc != OK)
+		return rc;
+	*fill_level = tab_tpr_drw_mng_ball_dyn.dram_fill * UNIT_OF__8_BYTES;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_vmid_set(u32 bm_vmid)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	struct bm_common_general_conf          reg_common_general_conf;
+	u32 bm_req_rcv_en;
+
+	if ((bm_vmid < BM_VMID_MIN) || (bm_vmid > BM_VMID_MAX))
+		return rc;
+
+	rc = bm_enable_status_get(&bm_req_rcv_en);
+	if (rc != OK)
+		return rc;
+	if (bm_req_rcv_en == 1) {
+		rc = -BM_CHANGE_AFTER_BM_ENABLE;
+		return rc;
+	}
+
+	reg_base_address =      bm.common_general_conf;
+	reg_size   =   bm_reg_size.common_general_conf;
+	reg_offset = bm_reg_offset.common_general_conf * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_common_general_conf);
+	if (rc != OK)
+		return rc;
+	reg_common_general_conf.dm_vmid = bm_vmid;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_common_general_conf);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_gp_pool_def_quick_init(u32 pool, u32 num_of_buffers, u32 fill_level,
+					u32 *base_address, u32 partition_model)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pe_size, pool_pair, ae_thr, af_thr, cache_vmid, cache_attr,
+					cache_so_thr, cache_si_thr, cache_num_of_buffers;
+/*	u32 large_cache;*/
+
+	pe_size              = BM_PE_SIZE_IS_32_BITS;
+	pool_pair            = BM_POOL_PAIR_GP_DEF;
+	ae_thr               = BM_AE_THR_DEF;
+	af_thr               = BM_AF_THR_DEF;
+	cache_vmid           = BM_CACHE_VMID_DEF;
+	cache_attr           = BM_CACHE_ATTR_DEF;
+
+/*	large_cache = !(partition_model);	???*/
+
+	if (partition_model == 0) {			/* large partition in cache */
+		cache_si_thr         = BM_CACHE_SI_THR_GP_BIG_DEF;
+		cache_so_thr         = BM_CACHE_SO_THR_GP_BIG_DEF;
+		cache_num_of_buffers = BM_CACHE_NUM_OF_BUFFERS_GP_BIG_DEF;
+	} else if (partition_model == 1) {	/* small partition in cache */
+		cache_si_thr         = BM_CACHE_SI_THR_GP_SMALL_DEF;
+		cache_so_thr         = BM_CACHE_SO_THR_GP_SMALL_DEF;
+		cache_num_of_buffers = BM_CACHE_NUM_OF_BUFFERS_GP_SMALL_DEF;
+	} else
+		return rc;
+
+	rc = bm_gp_pool_quick_init(pool, num_of_buffers, fill_level, base_address,
+					pe_size, pool_pair, ae_thr, af_thr,
+					cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_gp_pool_quick_init(u32 pool, u32 num_of_buffers, u32 fill_level, u32 *base_address,
+				u32 pe_size, u32 pool_pair, u32 ae_thr, u32 af_thr,
+				u32 cache_vmid, u32 cache_attr, u32 cache_so_thr, u32 cache_si_thr,
+				u32 cache_num_of_buffers)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 quick_init, bm_req_rcv_en;
+	u32 granularity_of_pe_in_dram, granularity_of_pe_in_cache;
+
+	quick_init = 1;	/*quick_init is TRUE*/
+
+	if (pe_size == BM_PE_SIZE_IS_40_BITS) {
+		granularity_of_pe_in_dram  =
+			GRANULARITY_OF_64_BYTES / GP_PE_SIZE_OF_40_BITS_IN_BYTES_IN_DRAM;	/* 64/8 */
+		granularity_of_pe_in_cache =
+			GRANULARITY_OF_64_BYTES / GP_PE_SIZE_IN_BYTES_IN_CACHE;			/* 64/8 */
+	} else if (pe_size == BM_PE_SIZE_IS_32_BITS) {
+		granularity_of_pe_in_dram  =
+			GRANULARITY_OF_64_BYTES / GP_PE_SIZE_OF_32_BITS_IN_BYTES_IN_DRAM;	/* 64/4 */
+		granularity_of_pe_in_cache =
+			GRANULARITY_OF_64_BYTES / GP_PE_SIZE_IN_BYTES_IN_CACHE;			/* 64/8 */
+	} else
+		return rc;
+
+	if ((num_of_buffers % granularity_of_pe_in_dram) != 0)
+		return rc;
+	if         ((ae_thr % granularity_of_pe_in_dram) != 0)
+		return rc;
+	if         ((af_thr % granularity_of_pe_in_dram) != 0)
+		return rc;
+	if ((((struct mv_word40 *)base_address)->lo % granularity_of_pe_in_dram)  != 0)
+		return rc;
+	if ((cache_num_of_buffers % granularity_of_pe_in_cache) != 0)
+		return rc;
+
+	if (ae_thr       >= af_thr)
+		return rc;
+	if (cache_so_thr >= cache_si_thr + 16)
+		return rc;
+
+	if ((pool                 <          BM_POOL_GP_MIN) || (pool                 >          BM_POOL_GP_MAX))
+		return rc;
+	if ((num_of_buffers       < BM_NUM_OF_BUFFERS_GP_MIN) || (num_of_buffers      > BM_NUM_OF_BUFFERS_GP_MAX))
+		return rc;
+	if ((fill_level           <       BM_FILL_LEVEL_MIN) || (fill_level           >       BM_FILL_LEVEL_MAX))
+		return rc;
+/*	if ((base_address_hi      <  BM_DRAM_ADDRESS_HI_MIN) || (base_address_hi      >  BM_DRAM_ADDRESS_HI_MAX)) */
+	if ((((struct mv_word40 *)base_address)->hi < BM_DRAM_ADDRESS_HI_MIN) ||
+		(((struct mv_word40 *)base_address)->hi > BM_DRAM_ADDRESS_HI_MAX))
+		return rc;
+/*	if ((base_address_lo      <  BM_DRAM_ADDRESS_LO_MIN) || (base_address_lo      >  BM_DRAM_ADDRESS_LO_MAX)) */
+	if ((((struct mv_word40 *)base_address)->lo < BM_DRAM_ADDRESS_LO_MIN) ||
+		(((struct mv_word40 *)base_address)->lo > BM_DRAM_ADDRESS_LO_MAX))
+		return rc;
+	if ((pe_size              <          BM_PE_SIZE_MIN) || (pe_size              >          BM_PE_SIZE_MAX))
+		return rc;
+	if ((pool_pair            <        BM_POOL_PAIR_MIN) || (pool_pair            >        BM_POOL_PAIR_MAX))
+		return rc;
+	if ((ae_thr               <           BM_AE_THR_MIN) || (ae_thr               >           BM_AE_THR_MAX))
+		return rc;
+	if ((af_thr               <           BM_AF_THR_MIN) || (af_thr               >           BM_AF_THR_MAX))
+		return rc;
+	if ((cache_vmid           <             BM_VMID_MIN) || (cache_vmid           >             BM_VMID_MAX))
+		return rc;
+	if ((cache_attr           <       BM_CACHE_ATTR_MIN) || (cache_attr           >       BM_CACHE_ATTR_MAX))
+		return rc;
+	if ((cache_so_thr         <     BM_CACHE_SO_THR_MIN) || (cache_so_thr         >     BM_CACHE_SI_THR_MAX))
+		return rc;
+	if ((cache_si_thr         <     BM_CACHE_SI_THR_MIN) || (cache_si_thr         >     BM_CACHE_SI_THR_MAX))
+		return rc;
+	if ((cache_num_of_buffers < BM_CACHE_NUM_OF_BUFFERS_GP_MIN)	||
+		(cache_num_of_buffers > BM_CACHE_NUM_OF_BUFFERS_GP_MAX))
+		return rc;
+
+	rc = bm_pool_dram_set(pool, num_of_buffers, pe_size, base_address, ae_thr, af_thr);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_fill_level_set(pool, num_of_buffers, pe_size, quick_init);
+	if (rc != OK)
+		return rc;
+	rc = bm_gp_pool_pe_size_set(pool, pe_size);
+	if (rc != OK)
+		return rc;
+	rc = bm_gp_pool_pair_set(pool, pool_pair);
+	if (rc != OK)
+		return rc;
+	rc = bm_pool_enable(pool, quick_init);
+	if (rc != OK)
+		return rc;
+
+	rc = bm_enable_status_get(&bm_req_rcv_en);
+	if (rc != OK)
+		return rc;
+	if (bm_req_rcv_en == ON) {
+		rc = -BM_ATTR_CHANGE_AFTER_BM_ENABLE;
+		return rc;
+	}
+
+	rc = OK;
+	return rc;
+}
+
+/*BM Debug functions*/
+int bm_global_registers_dump(void)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	char reg_name[50];
+
+	struct bm_sys_nrec_common_d0_st  reg_sys_nrec_common_d0_st;
+	struct bm_sys_nrec_common_d1_st  reg_sys_nrec_common_d1_st;
+	struct bm_sys_nrec_common_d2_st  reg_sys_nrec_common_d2_st;
+	struct bm_sys_nrec_common_d3_st  reg_sys_nrec_common_d3_st;
+	struct bm_common_general_conf    reg_common_general_conf;
+	struct bm_dram_domain_conf       reg_dram_domain_conf;
+	struct bm_dram_cache_conf        reg_dram_cache_conf;
+	struct bm_dram_qos_conf          reg_dram_qos_conf;
+	struct bm_dm_axi_fifos_st        reg_dm_axi_fifos_st;
+	struct bm_drm_pend_fifo_st       reg_drm_pend_fifo_st;
+	struct bm_dm_axi_wr_pend_fifo_st reg_dm_axi_wr_pend_fifo_st;
+	struct bm_bm_idle_st             reg_bm_idle_st;
+
+	reg_base_address =      bm.sys_nrec_common_d0_st;
+	reg_size   =   bm_reg_size.sys_nrec_common_d0_st;
+	reg_offset = bm_reg_offset.sys_nrec_common_d0_st * 0;
+
+	pr_info("\n-------------- BM Global registers dump -----------");
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_sys_nrec_common_d0_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset,
+		*((u32 *)&reg_sys_nrec_common_d0_st));
+
+	pr_info("\t sys_nrec_common_d0_st.qm_last_alc_viol_pid_st  = 0x%08X\n",
+				reg_sys_nrec_common_d0_st.qm_last_alc_viol_pid_st);
+	pr_info("\t sys_nrec_common_d0_st.qm_last_rls_viol_pid_st  = 0x%08X\n",
+				reg_sys_nrec_common_d0_st.qm_last_rls_viol_pid_st);
+	pr_info("\t sys_nrec_common_d0_st.ppe_last_alc_viol_pid_st = 0x%08X\n",
+				reg_sys_nrec_common_d0_st.ppe_last_alc_viol_pid_st);
+	pr_info("\t sys_nrec_common_d0_st.ppe_last_rls_viol_pid_st = 0x%08X\n",
+				reg_sys_nrec_common_d0_st.ppe_last_rls_viol_pid_st);
+
+	reg_base_address =      bm.sys_nrec_common_d1_st;
+	reg_size   =   bm_reg_size.sys_nrec_common_d1_st;
+	reg_offset = bm_reg_offset.sys_nrec_common_d1_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_sys_nrec_common_d1_st);
+	if (rc != OK)
+		return rc;
+	pr_info("\n");
+
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset,
+		*((u32 *)&reg_sys_nrec_common_d1_st));
+
+	pr_info("\t sys_nrec_common_d1_st.mac_last_alc_viol_pid_st = 0x%08X\n",
+				reg_sys_nrec_common_d1_st.mac_last_alc_viol_pid_st);
+	pr_info("\t sys_nrec_common_d1_st.mac_last_rls_viol_pid_st = 0x%08X\n",
+				reg_sys_nrec_common_d1_st.mac_last_rls_viol_pid_st);
+	pr_info("\t sys_nrec_common_d1_st.drm_last_dram_err_pid_st = 0x%08X\n",
+				reg_sys_nrec_common_d1_st.drm_last_dram_err_pid_st);
+	pr_info("\t sys_nrec_common_d1_st.dwm_last_fail_so_pid_st  = 0x%08X\n",
+				reg_sys_nrec_common_d1_st.dwm_last_fail_so_pid_st);
+
+	reg_base_address =      bm.sys_nrec_common_d2_st;
+	reg_size   =   bm_reg_size.sys_nrec_common_d2_st;
+	reg_offset = bm_reg_offset.sys_nrec_common_d2_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_sys_nrec_common_d2_st);
+	if (rc != OK)
+		return rc;
+	pr_info("\n");
+
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset,
+		*((u32 *)&reg_sys_nrec_common_d2_st));
+
+	pr_info("\t sys_nrec_common_d2_st.qm_last_alc_viol_blen_st  = 0x%08X\n",
+				reg_sys_nrec_common_d2_st.qm_last_alc_viol_blen_st);
+	pr_info("\t sys_nrec_common_d2_st.qm_last_rls_viol_blen_st  = 0x%08X\n",
+				reg_sys_nrec_common_d2_st.qm_last_rls_viol_blen_st);
+	pr_info("\t sys_nrec_common_d2_st.ppe_last_alc_viol_blen_st = 0x%08X\n",
+				reg_sys_nrec_common_d2_st.ppe_last_alc_viol_blen_st);
+	pr_info("\t sys_nrec_common_d2_st.ppe_last_rls_viol_blen_st = 0x%08X\n",
+				reg_sys_nrec_common_d2_st.ppe_last_rls_viol_blen_st);
+
+	reg_base_address =      bm.sys_nrec_common_d3_st;
+	reg_size   =   bm_reg_size.sys_nrec_common_d3_st;
+	reg_offset = bm_reg_offset.sys_nrec_common_d3_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_sys_nrec_common_d3_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset,
+		*((u32 *)&reg_sys_nrec_common_d3_st));
+
+	pr_info("\t sys_nrec_common_d3_st.mac_last_alc_viol_blen_st = 0x%08X\n",
+				reg_sys_nrec_common_d3_st.mac_last_alc_viol_blen_st);
+	pr_info("\t sys_nrec_common_d3_st.mac_last_rls_viol_blen_st = 0x%08X\n",
+				reg_sys_nrec_common_d3_st.mac_last_rls_viol_blen_st);
+
+	reg_base_address =      bm.common_general_conf;
+	reg_size   =   bm_reg_size.common_general_conf;
+	reg_offset = bm_reg_offset.common_general_conf * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_common_general_conf);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset,
+		*((u32 *)&reg_common_general_conf));
+
+	pr_info("\t common_general_conf.mac_last_alc_viol_pid_st = 0x%08X\n",
+				reg_common_general_conf.drm_si_decide_extra_fill);
+	pr_info("\t common_general_conf.mac_last_rls_viol_pid_st = 0x%08X\n",
+				reg_common_general_conf.dm_vmid);
+	pr_info("\t common_general_conf.drm_last_dram_err_pid_st = 0x%08X\n",
+				reg_common_general_conf.bm_req_rcv_en);
+
+	reg_base_address =      bm.dram_domain_conf;
+	reg_size   =   bm_reg_size.dram_domain_conf;
+	reg_offset = bm_reg_offset.dram_domain_conf * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_domain_conf);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset,
+		*((u32 *)&reg_dram_domain_conf));
+
+	pr_info("\t dram_domain_conf.dwm_awdomain_b0  = 0x%08X\n", reg_dram_domain_conf.dwm_awdomain_b0);
+	pr_info("\t dram_domain_conf.dwm_awdomain_bgp = 0x%08X\n", reg_dram_domain_conf.dwm_awdomain_bgp);
+	pr_info("\t dram_domain_conf.drm_ardomain_b0  = 0x%08X\n", reg_dram_domain_conf.drm_ardomain_b0);
+	pr_info("\t dram_domain_conf.drm_ardomain_bgp = 0x%08X\n", reg_dram_domain_conf.drm_ardomain_bgp);
+
+	reg_base_address =      bm.dram_cache_conf;
+	reg_size   =   bm_reg_size.dram_cache_conf;
+	reg_offset = bm_reg_offset.dram_cache_conf * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_cache_conf);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset,
+		*((u32 *)&reg_dram_cache_conf));
+
+	pr_info("\t dram_cache_conf.dwm_awcache_b0  = 0x%08X\n", reg_dram_cache_conf.dwm_awcache_b0);
+	pr_info("\t dram_cache_conf.dwm_awcache_bgp = 0x%08X\n", reg_dram_cache_conf.dwm_awcache_bgp);
+	pr_info("\t dram_cache_conf.drm_arcache_b0  = 0x%08X\n", reg_dram_cache_conf.drm_arcache_b0);
+	pr_info("\t dram_cache_conf.drm_arcache_bgp = 0x%08X\n", reg_dram_cache_conf.drm_arcache_bgp);
+
+	reg_base_address =      bm.dram_qos_conf;
+	reg_size   =   bm_reg_size.dram_qos_conf;
+	reg_offset = bm_reg_offset.dram_qos_conf * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_qos_conf);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_dram_qos_conf));
+
+	pr_info("\t dram_qos_conf.dwm_awqos_b0  = 0x%08X\n", reg_dram_qos_conf.dwm_awqos_b0);
+	pr_info("\t dram_qos_conf.dwm_awqos_bgp = 0x%08X\n", reg_dram_qos_conf.dwm_awqos_bgp);
+	pr_info("\t dram_qos_conf.drm_arqos_b0  = 0x%08X\n", reg_dram_qos_conf.drm_arqos_b0);
+	pr_info("\t dram_qos_conf.drm_arqos_bgp = 0x%08X\n", reg_dram_qos_conf.drm_arqos_bgp);
+
+	reg_base_address =      bm.dm_axi_fifos_st;
+	reg_size   =   bm_reg_size.dm_axi_fifos_st;
+	reg_offset = bm_reg_offset.dm_axi_fifos_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dm_axi_fifos_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_dm_axi_fifos_st));
+
+	pr_info("\t dm_axi_fifos_st.dwm_waddr_fifo_fill_st = 0x%08X\n",
+				reg_dm_axi_fifos_st.dwm_waddr_fifo_fill_st);
+	pr_info("\t dm_axi_fifos_st.dwm_wdata_fifo_fill_st = 0x%08X\n",
+				reg_dm_axi_fifos_st.dwm_wdata_fifo_fill_st);
+	pr_info("\t dm_axi_fifos_st.drm_raddr_fifo_fill_st = 0x%08X\n",
+				reg_dm_axi_fifos_st.drm_raddr_fifo_fill_st);
+	pr_info("\t dm_axi_fifos_st.drm_rdata_fifo_fill_st = 0x%08X\n",
+				reg_dm_axi_fifos_st.drm_rdata_fifo_fill_st);
+
+	reg_base_address =      bm.drm_pend_fifo_st;
+	reg_size   =   bm_reg_size.drm_pend_fifo_st;
+	reg_offset = bm_reg_offset.drm_pend_fifo_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_drm_pend_fifo_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_drm_pend_fifo_st));
+
+	pr_info("\t drm_pend_fifo_st.drm_pend_fifo_fill_st = 0x%08X\n",
+						reg_drm_pend_fifo_st.drm_pend_fifo_fill_st);
+
+	reg_base_address =      bm.dm_axi_wr_pend_fifo_st;
+	reg_size   =   bm_reg_size.dm_axi_wr_pend_fifo_st;
+	reg_offset = bm_reg_offset.dm_axi_wr_pend_fifo_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dm_axi_wr_pend_fifo_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_dm_axi_wr_pend_fifo_st));
+
+	pr_info("\t dm_axi_wr_pend_fifo_st.axi_wr_pend_fifo_fill_st = 0x%08X\n",
+						reg_dm_axi_wr_pend_fifo_st.axi_wr_pend_fifo_fill_st);
+
+	reg_base_address =      bm.bm_idle_st;
+	reg_size   =   bm_reg_size.bm_idle_st;
+	reg_offset = bm_reg_offset.bm_idle_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bm_idle_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_bm_idle_st));
+
+	pr_info("\t bm_idle_st.bm_idle_st = 0x%08X\n", reg_bm_idle_st.bm_idle_st);
+
+	rc = OK;
+	return rc;
+}
+
+int bm_pool_registers_dump(u32 pool)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pid, bid, pid_local;
+	char reg_name[50];
+
+	struct bm_pool_conf_b0              reg_pool_conf_b0;
+	struct bm_pool_conf_bgp             reg_pool_conf_bgp;
+	struct bm_pool_st                   reg_pool_st;
+	struct bm_c_mng_stat_data           tab_dpr_c_mng_stat;
+	struct bm_c_mng_dyn_data            tab_tpr_c_mng_dyn;
+	struct bm_d_mng_ball_stat_data      tab_dpr_d_mng_ball_stat_data;
+	struct bm_tpr_dro_mng_ball_dyn_data tab_tpr_dro_mng_ball_dyn_data;
+	struct bm_tpr_drw_mng_ball_dyn_data tab_tpr_drw_mng_ball_dyn_data;
+	struct bm_tpr_ctrs_0_data           tab_tpr_ctrs_0_data;
+
+	if ((pool            <     BM_POOL_MIN) || (pool            >    BM_POOL_MAX))
+		return rc;
+	if ((pool            >  BM_POOL_QM_MAX) && (pool            < BM_POOL_GP_MIN))
+		return rc; /* pools 4, 5, 6, 7 don't exist */
+
+	pid       = (int)pool;
+	bid       = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	pr_info("\n bm_pool_registers_dump:");
+
+	reg_base_address =      bm.b_pool_n_conf[bid];
+	reg_size   =   bm_reg_size.b_pool_n_conf[bid];
+	reg_offset = bm_reg_offset.b_pool_n_conf[bid] * pid_local;
+
+	if  (bid == 0) {	/* QM pools */
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pool_conf_b0);
+		if (rc != OK)
+			return rc;
+
+		pr_info("\n");
+		rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+		if (rc != OK)
+			return rc;
+		pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+			reg_base_address + reg_offset, *((u32 *)&reg_pool_conf_b0));
+
+		pr_info("\t b%d_pool_%d_conf.pool_enable     = 0x%08X\n",
+					bid, pid_local, reg_pool_conf_b0.pool_enable);
+		pr_info("\t b%d_pool_%d_conf.pool_quick_init = 0x%08X\n",
+					bid, pid_local, reg_pool_conf_b0.pool_quick_init);
+	} else if ((bid == 1) || (bid == 2) || (bid == 3) || (bid == 4)) {	/* QP pools */
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pool_conf_bgp);
+		if (rc != OK)
+			return rc;
+
+		pr_info("\n");
+		rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+		if (rc != OK)
+			return rc;
+		pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+			reg_base_address + reg_offset, *((u32 *)&reg_pool_conf_bgp));
+
+		pr_info("\t b%d_pool_%d_conf.pool_enable     = 0x%08X\n",
+					bid, pid_local, reg_pool_conf_bgp.pool_enable);
+		pr_info("\t b%d_pool_%d_conf.pool_in_pairs   = 0x%08X\n",
+					bid, pid_local, reg_pool_conf_bgp.pool_in_pairs);
+		pr_info("\t b%d_pool_%d_conf.PE_size         = 0x%08X\n",
+					bid, pid_local, reg_pool_conf_bgp.pe_size);
+		pr_info("\t b%d_pool_%d_conf.pool_quick_init = 0x%08X\n",
+					bid, pid_local, reg_pool_conf_bgp.pool_quick_init);
+	} else {
+		rc = -BM_INPUT_NOT_IN_RANGE;
+		return rc;
+	}
+
+	reg_base_address =      bm.b_pool_n_st[bid];
+	reg_size   =   bm_reg_size.b_pool_n_st[bid];
+	reg_offset = bm_reg_offset.b_pool_n_st[bid] * pid_local;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pool_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_pool_st));
+
+	pr_info("\t b%d_pool_%d_st.pool_nempty_st          = 0x%08X\n",
+			bid, pid_local, reg_pool_st.pool_nempty_st);
+	pr_info("\t b%d_pool_%d_st.dpool_ae_st             = 0x%08X\n",
+			bid, pid_local, reg_pool_st.dpool_ae_st);
+	pr_info("\t b%d_pool_%d_st.dpool_af_st             = 0x%08X\n",
+			bid, pid_local, reg_pool_st.dpool_af_st);
+	pr_info("\t b%d_pool_%d_st.pool_fill_bgt_si_thr_st = 0x%08X\n",
+			bid, pid_local, reg_pool_st.pool_fill_bgt_si_thr_st);
+
+	reg_base_address =      bm.dpr_c_mng_stat[bid];
+	reg_size   =   bm_reg_size.dpr_c_mng_stat[bid];
+	reg_offset = bm_reg_offset.dpr_c_mng_stat[bid] * pid_local;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_dpr_c_mng_stat);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&tab_dpr_c_mng_stat));
+
+	pr_info("\t dpr_c_mng_b%d_stat.cache_start  = 0x%08X\n", bid, tab_dpr_c_mng_stat.cache_start);
+	pr_info("\t dpr_c_mng_b%d_stat.cache_end    = 0x%08X\n", bid, tab_dpr_c_mng_stat.cache_end);
+	pr_info("\t dpr_c_mng_b%d_stat.cache_si_thr = 0x%08X\n", bid, tab_dpr_c_mng_stat.cache_si_thr);
+	pr_info("\t dpr_c_mng_b%d_stat.cache_so_thr = 0x%08X\n", bid, tab_dpr_c_mng_stat.cache_so_thr);
+	pr_info("\t dpr_c_mng_b%d_stat.cache_attr   = 0x%08X\n", bid, tab_dpr_c_mng_stat.cache_attr);
+	pr_info("\t dpr_c_mng_b%d_stat.cache_vmid   = 0x%08X\n", bid, tab_dpr_c_mng_stat.cache_vmid);
+
+	reg_base_address =      bm.tpr_c_mng_b_dyn[bid];
+	reg_size   =   bm_reg_size.tpr_c_mng_b_dyn[bid];
+	reg_offset = bm_reg_offset.tpr_c_mng_b_dyn[bid] * pid_local;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_tpr_c_mng_dyn);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&tab_tpr_c_mng_dyn));
+
+	pr_info("\t tpr_c_mng_b%d_dyn.cache_fill_min = 0x%08X\n", bid, tab_tpr_c_mng_dyn.cache_fill_min);
+	pr_info("\t tpr_c_mng_b%d_dyn.cache_fill_max = 0x%08X\n", bid, tab_tpr_c_mng_dyn.cache_fill_max);
+	pr_info("\t tpr_c_mng_b%d_dyn.cache_rd_ptr   = 0x%08X\n", bid, tab_tpr_c_mng_dyn.cache_rd_ptr);
+	pr_info("\t tpr_c_mng_b%d_dyn.cache_wr_ptr   = 0x%08X\n", bid, tab_tpr_c_mng_dyn.cache_wr_ptr);
+
+	reg_base_address =      bm.dpr_d_mng_ball_stat;
+	reg_size   =   bm_reg_size.dpr_d_mng_ball_stat;
+	reg_offset = bm_reg_offset.dpr_d_mng_ball_stat * BM_PID_TO_GLOBAL_POOL_IDX(pid);
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_dpr_d_mng_ball_stat_data);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&tab_dpr_d_mng_ball_stat_data));
+
+	pr_info("\t dpr_d_mng_ball_stat.dram_ae_thr = 0x%08X\n",     tab_dpr_d_mng_ball_stat_data.dram_ae_thr);
+	pr_info("\t dpr_d_mng_ball_stat.dram_af_thr = 0x%08X\n",     tab_dpr_d_mng_ball_stat_data.dram_af_thr);
+	pr_info("\t dpr_d_mng_ball_stat.dram_start  = 0x%02X%08X\n",
+		tab_dpr_d_mng_ball_stat_data.dram_start_hi, tab_dpr_d_mng_ball_stat_data.dram_start_lo);
+	pr_info("\t dpr_d_mng_ball_stat.dram_size   = 0x%08X\n",     tab_dpr_d_mng_ball_stat_data.dram_size);
+
+	reg_base_address =      bm.tpr_dro_mng_ball_dyn;
+	reg_size   =   bm_reg_size.tpr_dro_mng_ball_dyn;
+	reg_offset = bm_reg_offset.tpr_dro_mng_ball_dyn * BM_PID_TO_GLOBAL_POOL_IDX(pid);
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_tpr_dro_mng_ball_dyn_data);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&tab_tpr_dro_mng_ball_dyn_data));
+
+	pr_info("\t tpr_dro_mng_ball_dyn.dram_rd_ptr = 0x%08X\n", tab_tpr_dro_mng_ball_dyn_data.dram_rd_ptr);
+	pr_info("\t tpr_dro_mng_ball_dyn.dram_wr_ptr = 0x%08X\n", tab_tpr_dro_mng_ball_dyn_data.dram_wr_ptr);
+
+	reg_base_address =      bm.tpr_drw_mng_ball_dyn;
+	reg_size   =   bm_reg_size.tpr_drw_mng_ball_dyn;
+	reg_offset = bm_reg_offset.tpr_drw_mng_ball_dyn * BM_PID_TO_GLOBAL_POOL_IDX(pid);
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_tpr_drw_mng_ball_dyn_data);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&tab_tpr_drw_mng_ball_dyn_data));
+
+	pr_info("\t tpr_drw_mng_ball_dyn.dram_fill = 0x%08X\n", tab_tpr_drw_mng_ball_dyn_data.dram_fill);
+
+	reg_base_address =      bm.tpr_ctrs_0_b[bid];
+	reg_size   =   bm_reg_size.tpr_ctrs_0_b[bid];
+	reg_offset = bm_reg_offset.tpr_ctrs_0_b[bid] * pid_local;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_tpr_ctrs_0_data);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&tab_tpr_ctrs_0_data));
+
+	pr_info("\t tpr_ctrs_0_b%d.delayed_releases_ctr = 0x%08X\n",
+		bid, tab_tpr_ctrs_0_data.delayed_releases_ctr);
+	pr_info("\t tpr_ctrs_0_b%d.failed_allocs_ctr    = 0x%08X\n",
+		bid, tab_tpr_ctrs_0_data.failed_allocs_ctr);
+	pr_info("\t tpr_ctrs_0_b%d.released_pes_ctr     = 0x%08X\n",
+		bid, tab_tpr_ctrs_0_data.released_pes_ctr);
+	pr_info("\t tpr_ctrs_0_b%d.allocated_pes_ctr    = 0x%08X\n",
+		bid, tab_tpr_ctrs_0_data.allocated_pes_ctr);
+
+	rc = OK;
+	return rc;
+}
+
+int bm_bank_registers_dump(u32 bank)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 bid;
+	char reg_name[50];
+
+	struct bm_b_sys_rec_bank_d0_st       reg_b_sys_rec_bank_d0_st;
+	struct bm_b_sys_rec_bank_d1_st       reg_b_sys_rec_bank_d1_st;
+	struct bm_b_bank_req_fifos_st        reg_b_bank_req_fifos_st;
+	struct bm_b0_past_alc_fifos_st       reg_b0_past_alc_fifos_st;
+	struct bm_bgp_past_alc_fifos_st      reg_bgp_past_alc_fifos_st;
+	struct bm_b0_rls_wrp_ppe_fifos_st    reg_b0_rls_wrp_ppe_fifos_st;
+
+	if ((bank            <     BM_BANK_MIN) || (bank            >     BM_BANK_MAX))
+		return rc;
+
+	bid       = bank;
+
+	pr_info("\n bm_bank_registers_dump:");
+
+	reg_base_address =      bm.b_sys_rec_bank_d0_st[bid];
+	reg_size   =   bm_reg_size.b_sys_rec_bank_d0_st[bid];
+	reg_offset = bm_reg_offset.b_sys_rec_bank_d0_st[bid] * bid;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b_sys_rec_bank_d0_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_b_sys_rec_bank_d0_st));
+
+	pr_info("\t b%d_sys_rec_bank_d0_st.b_last_vmid_mis_alc_vmid_st = 0x%08X\n",
+				bid, reg_b_sys_rec_bank_d0_st.b_last_vmid_mis_alc_vmid_st);
+	pr_info("\t b%d_sys_rec_bank_d0_st.b_last_vmid_mis_rls_vmid_st = 0x%08X\n",
+				bid, reg_b_sys_rec_bank_d0_st.b_last_vmid_mis_rls_vmid_st);
+	pr_info("\t b%d_sys_rec_bank_d0_st.b_last_vmid_mis_alc_pid_st  = 0x%08X\n",
+				bid, reg_b_sys_rec_bank_d0_st.b_last_vmid_mis_alc_pid_st);
+	pr_info("\t b%d_sys_rec_bank_d0_st.b_last_vmid_mis_rls_pid_st  = 0x%08X\n",
+				bid, reg_b_sys_rec_bank_d0_st.b_last_vmid_mis_rls_pid_st);
+
+	reg_base_address =      bm.b_sys_rec_bank_d1_st[bid];
+	reg_size   =   bm_reg_size.b_sys_rec_bank_d1_st[bid];
+	reg_offset = bm_reg_offset.b_sys_rec_bank_d1_st[bid] * bid;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b_sys_rec_bank_d1_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_b_sys_rec_bank_d1_st));
+
+	pr_info("\t b%d_sys_rec_bank_d1_st.b_last_vmid_mis_alc_src_st = 0x%08X\n",
+				bid, reg_b_sys_rec_bank_d1_st.b_last_vmid_mis_alc_src_st);
+	pr_info("\t b%d_sys_rec_bank_d1_st.b_last_vmid_mis_rls_src_st = 0x%08X\n",
+				bid, reg_b_sys_rec_bank_d1_st.b_last_vmid_mis_rls_src_st);
+	pr_info("\t b%d_sys_rec_bank_d1_st.b_last_alc_dis_pool_src_st = 0x%08X\n",
+				bid, reg_b_sys_rec_bank_d1_st.b_last_alc_dis_pool_src_st);
+	pr_info("\t b%d_sys_rec_bank_d1_st.b_last_rls_dis_pool_src_st = 0x%08X\n",
+				bid, reg_b_sys_rec_bank_d1_st.b_last_rls_dis_pool_src_st);
+	pr_info("\t b%d_sys_rec_bank_d1_st.b_last_alc_dis_pool_pid_st = 0x%08X\n",
+				bid, reg_b_sys_rec_bank_d1_st.b_last_alc_dis_pool_pid_st);
+	pr_info("\t b%d_sys_rec_bank_d1_st.b_last_rls_dis_pool_pid_st = 0x%08X\n",
+				bid, reg_b_sys_rec_bank_d1_st.b_last_rls_dis_pool_pid_st);
+
+	reg_base_address =      bm.b_bank_req_fifos_st;
+	reg_size   =   bm_reg_size.b_bank_req_fifos_st;
+	reg_offset = bm_reg_offset.b_bank_req_fifos_st * bid;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b_bank_req_fifos_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_b_bank_req_fifos_st));
+
+	pr_info("\t b%d_bank_req_fifos_st.b_alc_fifo_fill_st = 0x%08X\n",
+				bid, reg_b_bank_req_fifos_st.b_alc_fifo_fill_st);
+	pr_info("\t b%d_bank_req_fifos_st.b_rls_fifo_fill_st = 0x%08X\n",
+				bid, reg_b_bank_req_fifos_st.b_rls_fifo_fill_st);
+	pr_info("\t b%d_bank_req_fifos_st.b_so_fifo_fill_st: = 0x%08X\n",
+				bid, reg_b_bank_req_fifos_st.b_so_fifo_fill_st);
+	pr_info("\t b%d_bank_req_fifos_st.b_si_fifo_fill_st: = 0x%08X\n",
+				bid, reg_b_bank_req_fifos_st.b_si_fifo_fill_st);
+
+	if  (bid == 0) {	/* QM pools */
+		reg_base_address =      bm.b0_past_alc_fifos_st;
+		reg_size   =   bm_reg_size.b0_past_alc_fifos_st;
+		reg_offset = bm_reg_offset.b0_past_alc_fifos_st * bid;
+
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b0_past_alc_fifos_st);
+		if (rc != OK)
+			return rc;
+
+		pr_info("\n");
+		rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+		if (rc != OK)
+			return rc;
+		pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+			reg_base_address + reg_offset, *((u32 *)&reg_b0_past_alc_fifos_st));
+
+		pr_info("\t b0_past_alc_fifos_st.b0_past_alc_fifo_fill_st     = 0x%08X\n",
+				reg_b0_past_alc_fifos_st.b0_past_alc_fifo_fill_st);
+		pr_info("\t b0_past_alc_fifos_st.b0_past_alc_ppe_fifo_fill_st = 0x%08X\n",
+				reg_b0_past_alc_fifos_st.b0_past_alc_ppe_fifo_fill_st);
+	} else if ((bid == 1) || (bid == 2) || (bid == 3) || (bid == 4)) {	/* QP pools */
+		reg_base_address =      bm.bgp_past_alc_fifos_st;
+		reg_size   =   bm_reg_size.bgp_past_alc_fifos_st;
+		reg_offset = bm_reg_offset.bgp_past_alc_fifos_st * bid;
+
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_past_alc_fifos_st);
+		if (rc != OK)
+			return rc;
+
+		pr_info("\n");
+		rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+		if (rc != OK)
+			return rc;
+		pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+			reg_base_address + reg_offset, *((u32 *)&reg_bgp_past_alc_fifos_st));
+
+		pr_info("\t bgp_past_alc_fifos_st.b1_past_alc_fifo_fill_st = 0x%08X\n",
+				reg_bgp_past_alc_fifos_st.b1_past_alc_fifo_fill_st);
+		pr_info("\t bgp_past_alc_fifos_st.b2_past_alc_fifo_fill_st = 0x%08X\n",
+				reg_bgp_past_alc_fifos_st.b2_past_alc_fifo_fill_st);
+		pr_info("\t bgp_past_alc_fifos_st.b3_past_alc_fifo_fill_st = 0x%08X\n",
+				reg_bgp_past_alc_fifos_st.b3_past_alc_fifo_fill_st);
+		pr_info("\t bgp_past_alc_fifos_st.b4_past_alc_fifo_fill_st = 0x%08X\n",
+				reg_bgp_past_alc_fifos_st.b4_past_alc_fifo_fill_st);
+	} else {
+		rc = -BM_INPUT_NOT_IN_RANGE;
+		return rc;
+	}
+
+	reg_base_address =      bm.b0_rls_wrp_ppe_fifos_st;
+	reg_size   =   bm_reg_size.b0_rls_wrp_ppe_fifos_st;
+	reg_offset = bm_reg_offset.b0_rls_wrp_ppe_fifos_st * bid;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b0_rls_wrp_ppe_fifos_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_b0_rls_wrp_ppe_fifos_st));
+
+	pr_info("\t b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_0_fill_st = 0x%08X\n",
+			reg_b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_0_fill_st);
+	pr_info("\t b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_1_fill_st = 0x%08X\n",
+			reg_b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_1_fill_st);
+	pr_info("\t b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_2_fill_st = 0x%08X\n",
+			reg_b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_2_fill_st);
+	pr_info("\t b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_3_fill_st = 0x%08X\n",
+			reg_b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_3_fill_st);
+
+	rc = OK;
+	return rc;
+}
+
+int bm_cache_memory_dump(u32 bank)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 bid, line;
+	char reg_name[50];
+
+	struct bm_cache_b0_mem_data     reg_cache_b0_data;
+	struct bm_cache_bgp_data        reg_cache_bgp_data;
+
+	if ((bank            <     BM_BANK_MIN) || (bank            >     BM_BANK_MAX))
+		return rc;
+
+	bid       = bank;
+
+	pr_info("\n bm_cache_memory_dump:");
+
+	if  (bid == 0) {	/* QM pools */
+		for (line = 0; line < BM_NUM_OF_LINE_QM; line++) {
+			reg_base_address =      bm.sram_b_cache[bid];
+			reg_size   =   bm_reg_size.sram_b_cache[bid];
+			reg_offset = bm_reg_offset.sram_b_cache[bid] * line;
+
+			rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_cache_b0_data);
+			if (rc != OK)
+				return rc;
+
+			pr_info("\n");
+			rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+			if (rc != OK)
+				return rc;
+			pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+				reg_base_address + reg_offset, *((u32 *)&reg_cache_b0_data));
+
+			pr_info("\t line %04d: sram_b%d_cache.cache_b0_data_0 = 0x%08X\n",
+						line, bid, reg_cache_b0_data.cache_b0_data_0);
+			pr_info("\t line %04d: sram_b%d_cache.cache_b0_data_1 = 0x%08X\n",
+						line, bid, reg_cache_b0_data.cache_b0_data_1);
+			pr_info("\t line %04d: sram_b%d_cache.cache_b0_data_2 = 0x%08X\n",
+						line, bid, reg_cache_b0_data.cache_b0_data_2);
+			pr_info("\t line %04d: sram_b%d_cache.cache_b0_data_3 = 0x%08X\n",
+						line, bid, reg_cache_b0_data.cache_b0_data_3);
+		}
+	} else if ((bid == 1) || (bid == 2) || (bid == 3) || (bid == 4)) {	/* QP pools */
+		pr_info("\n");
+
+		for (line = 0; line < BM_NUM_OF_LINE_GP; line++) {
+			reg_base_address =      bm.sram_b_cache[bid];
+			reg_size   =   bm_reg_size.sram_b_cache[bid];
+			reg_offset = bm_reg_offset.sram_b_cache[bid] * line;
+
+			rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_cache_bgp_data);
+			if (rc != OK)
+				return rc;
+
+			pr_info("\n");
+			rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+			if (rc != OK)
+				return rc;
+			pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+			reg_base_address + reg_offset, *((u32 *)&reg_cache_bgp_data));
+
+			pr_info("\t line %04d: sram_b%d_cache.cache_bgp_data = 0x%02X_%08X\n",
+				line, bid, reg_cache_bgp_data.cache_bgp_data_hi,
+							reg_cache_bgp_data.cache_bgp_data_lo);
+		}
+	} else {
+		rc = -BM_INPUT_NOT_IN_RANGE;
+		return rc;
+	}
+
+	rc = OK;
+	return rc;
+}
+
+int bm_idle_status_get(u32 *status)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	struct bm_bm_idle_st reg_bm_idle_st;
+
+	if (((u32)status < BM_DATA_PTR_MIN) || ((u32)status > BM_DATA_PTR_MAX))
+		return rc;
+
+	reg_base_address =      bm.bm_idle_st;
+	reg_size   =   bm_reg_size.bm_idle_st;
+	reg_offset = bm_reg_offset.bm_idle_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size,  (u32 *)&reg_bm_idle_st);
+/*	rc =  bm_register_read(reg_base_address, reg_offset, reg_size,  &status);  if (rc != 0) return rc; */
+	if (rc != OK)
+		return rc;
+	*status = reg_bm_idle_st.bm_idle_st;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_pool_status_get(u32 pool, u32 *pool_nempty, u32 *dpool_ae, u32 *dpool_af)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pid, bid, pid_local;
+	struct bm_pool_st   reg_pool_st;
+
+	if ((pool             <     BM_POOL_MIN) || (pool             >     BM_POOL_MAX))
+		return rc;
+	if ((pool             >  BM_POOL_QM_MAX) && (pool             <  BM_POOL_GP_MIN))
+		return rc; /* pools 4, 5, 6, 7 don't exist */
+	if (((u32)pool_nempty < BM_DATA_PTR_MIN) || ((u32)pool_nempty > BM_DATA_PTR_MAX))
+		return rc;
+	if (((u32)dpool_ae    < BM_DATA_PTR_MIN) || ((u32)dpool_ae    > BM_DATA_PTR_MAX))
+		return rc;
+	if (((u32)dpool_af    < BM_DATA_PTR_MIN) || ((u32)dpool_af    > BM_DATA_PTR_MAX))
+		return rc;
+
+	pid = (int)pool;
+	bid = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	reg_base_address =      bm.b_pool_n_st[bid];
+	reg_size   =   bm_reg_size.b_pool_n_st[bid];
+	reg_offset = bm_reg_offset.b_pool_n_st[bid] * pid_local;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pool_st);
+	if (rc != OK)
+		return rc;
+
+	*pool_nempty = reg_pool_st.pool_nempty_st;
+	*dpool_ae    = reg_pool_st.dpool_ae_st;
+	*dpool_af    = reg_pool_st.dpool_af_st;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_idle_debug(void)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 bid;
+	struct bm_b_bank_req_fifos_st          reg_b_bank_req_fifos_st;
+	struct bm_b0_past_alc_fifos_st         reg_b0_past_alc_fifos_st;
+	struct bm_bgp_past_alc_fifos_st        reg_bgp_past_alc_fifos_st;
+	struct bm_b0_rls_wrp_ppe_fifos_st      reg_b0_rls_wrp_ppe_fifos_st;
+	struct bm_dm_axi_fifos_st              reg_dm_axi_fifos_st;
+	struct bm_drm_pend_fifo_st             reg_drm_pend_fifo_st;
+	struct bm_dm_axi_wr_pend_fifo_st       reg_dm_axi_wr_pend_fifo_st;
+	char reg_name[50];
+
+	for (bid = 0; bid < BM_NUMBER_OF_BANKS; bid++) {
+		reg_base_address =      bm.b_bank_req_fifos_st;
+		reg_size   =   bm_reg_size.b_bank_req_fifos_st;
+		reg_offset = bm_reg_offset.b_bank_req_fifos_st * bid;
+
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b_bank_req_fifos_st);
+		if (rc != OK)
+			return rc;
+
+		pr_info("\n for bank = %d:\n", bid);
+		rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+		if (rc != OK)
+			return rc;
+		pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+			reg_base_address + reg_offset, *((u32 *)&reg_b_bank_req_fifos_st));
+
+		pr_info("\t b%d_bank_req_fifos_st.b_alc_fifo_fill_st = 0x%08X\n",
+					bid, reg_b_bank_req_fifos_st.b_alc_fifo_fill_st);
+		pr_info("\t b%d_bank_req_fifos_st.b_rls_fifo_fill_st = 0x%08X\n",
+					bid, reg_b_bank_req_fifos_st.b_rls_fifo_fill_st);
+		pr_info("\t b%d_bank_req_fifos_st.b_so_fifo_fill_st  = 0x%08X\n",
+					bid, reg_b_bank_req_fifos_st.b_so_fifo_fill_st);
+		pr_info("\t b%d_bank_req_fifos_st.b_si_fifo_fill_st  = 0x%08X\n",
+					bid, reg_b_bank_req_fifos_st.b_si_fifo_fill_st);
+	}
+
+	reg_base_address =      bm.b0_past_alc_fifos_st;
+	reg_size   =   bm_reg_size.b0_past_alc_fifos_st;
+	reg_offset = bm_reg_offset.b0_past_alc_fifos_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b0_past_alc_fifos_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n for bank 0:\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_b0_past_alc_fifos_st));
+
+	pr_info("\t b0_past_alc_fifos_st.b0_past_alc_fifo_fill_st     = 0x%08X\n",
+				reg_b0_past_alc_fifos_st.b0_past_alc_fifo_fill_st);
+	pr_info("\t b0_past_alc_fifos_st.b0_past_alc_ppe_fifo_fill_st = 0x%08X\n",
+				reg_b0_past_alc_fifos_st.b0_past_alc_ppe_fifo_fill_st);
+
+	reg_base_address =      bm.bgp_past_alc_fifos_st;
+	reg_size   =   bm_reg_size.bgp_past_alc_fifos_st;
+	reg_offset = bm_reg_offset.bgp_past_alc_fifos_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_past_alc_fifos_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n for banks 1,2,3,4:\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_bgp_past_alc_fifos_st));
+
+	pr_info("\t bgp_past_alc_fifos_st.b1_past_alc_fifo_fill_st = 0x%08X\n",
+				reg_bgp_past_alc_fifos_st.b1_past_alc_fifo_fill_st);
+	pr_info("\t bgp_past_alc_fifos_st.b2_past_alc_fifo_fill_st = 0x%08X\n",
+				reg_bgp_past_alc_fifos_st.b2_past_alc_fifo_fill_st);
+	pr_info("\t bgp_past_alc_fifos_st.b3_past_alc_fifo_fill_st = 0x%08X\n",
+				reg_bgp_past_alc_fifos_st.b3_past_alc_fifo_fill_st);
+	pr_info("\t bgp_past_alc_fifos_st.b4_past_alc_fifo_fill_st = 0x%08X\n",
+				reg_bgp_past_alc_fifos_st.b4_past_alc_fifo_fill_st);
+
+	reg_base_address =      bm.b0_rls_wrp_ppe_fifos_st;
+	reg_size   =   bm_reg_size.b0_rls_wrp_ppe_fifos_st;
+	reg_offset = bm_reg_offset.b0_rls_wrp_ppe_fifos_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b0_rls_wrp_ppe_fifos_st);
+	if (rc != OK)
+		return rc;
+
+	pr_info("\n for bank 0:\n");
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_b0_rls_wrp_ppe_fifos_st));
+
+	pr_info("\t b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_0_fill_st = 0x%08X\n",
+					reg_b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_0_fill_st);
+	pr_info("\t b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_1_fill_st = 0x%08X\n",
+					reg_b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_1_fill_st);
+	pr_info("\t b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_2_fill_st = 0x%08X\n",
+					reg_b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_2_fill_st);
+	pr_info("\t b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_3_fill_st = 0x%08X\n",
+					reg_b0_rls_wrp_ppe_fifos_st.rls_wrp_ppe_fifo_3_fill_st);
+
+	pr_info("\n for all banks:\n");
+	reg_base_address =      bm.dm_axi_fifos_st;
+	reg_size   =   bm_reg_size.dm_axi_fifos_st;
+	reg_offset = bm_reg_offset.dm_axi_fifos_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dm_axi_fifos_st);
+	if (rc != OK)
+		return rc;
+
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_dm_axi_fifos_st));
+
+	pr_info("\t dm_axi_fifos_st.dwm_waddr_fifo_fill_st = 0x%08X\n",
+						reg_dm_axi_fifos_st.dwm_waddr_fifo_fill_st);
+	pr_info("\t dm_axi_fifos_st.dwm_wdata_fifo_fill_st = 0x%08X\n",
+						reg_dm_axi_fifos_st.dwm_wdata_fifo_fill_st);
+	pr_info("\t dm_axi_fifos_st.drm_raddr_fifo_fill_st = 0x%08X\n",
+						reg_dm_axi_fifos_st.drm_raddr_fifo_fill_st);
+	pr_info("\t dm_axi_fifos_st.drm_rdata_fifo_fill_st = 0x%08X\n",
+						reg_dm_axi_fifos_st.drm_rdata_fifo_fill_st);
+
+	reg_base_address =      bm.drm_pend_fifo_st;
+	reg_size   =   bm_reg_size.drm_pend_fifo_st;
+	reg_offset = bm_reg_offset.drm_pend_fifo_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_drm_pend_fifo_st);
+	if (rc != OK)
+		return rc;
+
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_drm_pend_fifo_st));
+
+	pr_info("\t drm_pend_fifo_st.drm_pend_fifo_fill_st = 0x%08X\n",
+					reg_drm_pend_fifo_st.drm_pend_fifo_fill_st);
+
+	reg_base_address =      bm.dm_axi_wr_pend_fifo_st;
+	reg_size   =   bm_reg_size.dm_axi_wr_pend_fifo_st;
+	reg_offset = bm_reg_offset.dm_axi_wr_pend_fifo_st * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dm_axi_wr_pend_fifo_st);
+	if (rc != OK)
+		return rc;
+
+	rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+	if (rc != OK)
+		return rc;
+	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+		reg_base_address + reg_offset, *((u32 *)&reg_dm_axi_wr_pend_fifo_st));
+
+	pr_info("\t dm_axi_wr_pend_fifo_st.axi_wr_pend_fifo_fill_st = 0x%08X\n",
+			reg_dm_axi_wr_pend_fifo_st.axi_wr_pend_fifo_fill_st);
+
+	rc = OK;
+	return rc;
+}
+
+/*Errors and interrupts handling  TBD*/
+/*
+1.	bm_inter_read(u32 group, u32 *dataPtr)
+2.	bm_inter_clean(u32 group)
+3.	bm_inter_mask_set(u32 group, u32 mask)
+Note: it is recommended that interrupts mask will be set after BM is enabled and that the interrupted will be
+							unmasked with correlation to the specific configuration
+4.	bm_error_read(u32 group, u32 *dataPtr)
+5.	bm_error_clean(u32 group)
+6.	bm_error_mask_set (u32 group, u32 mask)
+7.	List of registers that are used for interrupt handling. API will be defined later with the interrupt
+							handling definition
+a.	bn_sys_rec_bank_d0_st: PID/VMID of last VMID-miss event for alloc/release:
+							Postponed till we handle interupts
+b.	bn_sys_rec_bank_d1_st: PID/source client of last release/alloc request to disabled pool:
+							Postponed till we handle interupts
+c.	sys_nrec_common_d0_st: PID of last alloc/release. Postponed till we handle interupts
+d.	sys_nrec_common_d1_st: PID of last DRAM read. Postponed till we handle interupts
+e.	common_general_conf: field drm_si_decide_extra_fill. According to Koby this is currently not in used
+*/
+
+int bm_error_dump(void)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 bid, error_sum_bit;
+	struct bm_b_sys_rec_bank_intr_cause     reg_b_sys_rec_bank_intr_cause;
+	struct bm_sw_debug_rec_intr_cause       reg_sw_debug_rec_intr_cause;
+	struct bm_sys_nrec_common_intr_cause    reg_sys_nrec_common_intr_cause;
+	struct bm_error_intr_cause              reg_error_intr_cause;
+	struct bm_func_intr_cause               reg_func_intr_cause;
+	struct bm_ecc_err_intr_cause            reg_ecc_err_intr_cause;
+	struct bm_b_pool_nempty_intr_cause      reg_b_pool_nempty_intr_cause;
+	struct bm_b_dpool_ae_intr_cause         reg_b_dpool_ae_intr_cause;
+	struct bm_b_dpool_af_intr_cause         reg_b_dpool_af_intr_cause;
+	char reg_name[50];
+
+	for (bid = 0; bid < BM_NUMBER_OF_BANKS; bid++) {
+		reg_base_address =      bm.b_sys_rec_bank_intr_cause[bid];
+		reg_size   =   bm_reg_size.b_sys_rec_bank_intr_cause[bid];
+		reg_offset = bm_reg_offset.b_sys_rec_bank_intr_cause[bid] * 0;
+
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b_sys_rec_bank_intr_cause);
+		if (rc != OK)
+			return rc;
+
+		error_sum_bit = reg_b_sys_rec_bank_intr_cause.sys_rec_bank_intr_cause_sum;
+		if (error_sum_bit != OK) {
+			pr_info("\n for bank = %d:\n", bid);
+			rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+			if (rc != OK)
+				return rc;
+			pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+				reg_base_address + reg_offset, *((u32 *)&reg_b_sys_rec_bank_intr_cause));
+
+			pr_info("\t b%d_sys_rec_bank_intr_cause.sys_rec_bank_intr_cause_sum = %d\n",
+						bid, reg_b_sys_rec_bank_intr_cause.sys_rec_bank_intr_cause_sum);
+			pr_info("\t b%d_sys_rec_bank_intr_cause.alc_vmid_mis_s = 0x%08X\n",
+						bid, reg_b_sys_rec_bank_intr_cause.alc_vmid_mis_s);
+			pr_info("\t b%d_sys_rec_bank_intr_cause.rls_vmid_mis_s = 0x%08X\n",
+						bid, reg_b_sys_rec_bank_intr_cause.rls_vmid_mis_s);
+			pr_info("\t b%d_sys_rec_bank_intr_cause.alc_dis_pool_s = 0x%08X\n",
+						bid, reg_b_sys_rec_bank_intr_cause.alc_dis_pool_s);
+			pr_info("\t b%d_sys_rec_bank_intr_cause.rls_dis_pool_s = 0x%08X\n",
+						bid, reg_b_sys_rec_bank_intr_cause.rls_dis_pool_s);
+		}
+	}
+
+	reg_base_address =      bm.sw_debug_rec_intr_cause;
+	reg_size   =   bm_reg_size.sw_debug_rec_intr_cause;
+	reg_offset = bm_reg_offset.sw_debug_rec_intr_cause * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_sw_debug_rec_intr_cause);
+	if (rc != OK)
+		return rc;
+	error_sum_bit = reg_sw_debug_rec_intr_cause.sw_debug_rec_intr_cause_sum;
+	if (error_sum_bit != OK) {
+		rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+		if (rc != OK)
+			return rc;
+		pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+			reg_base_address + reg_offset, *((u32 *)&reg_sw_debug_rec_intr_cause));
+
+		pr_info("\t reg_sw_debug_rec_intr_cause.sw_debug_rec_intr_cause_sum = %d\n",
+					reg_sw_debug_rec_intr_cause.sw_debug_rec_intr_cause_sum);
+		pr_info("\t reg_sw_debug_rec_intr_cause.rams_ctl_sw_wr_c_s = %d\n",
+					reg_sw_debug_rec_intr_cause.rams_ctl_sw_wr_c_s);
+		pr_info("\t reg_sw_debug_rec_intr_cause.rams_ctl_sw_wr_c_dyn_s = %d\n",
+					reg_sw_debug_rec_intr_cause.rams_ctl_sw_wr_c_dyn_s);
+		pr_info("\t reg_sw_debug_rec_intr_cause.rams_ctl_sw_wr_d_dro_s = %d\n",
+					reg_sw_debug_rec_intr_cause.rams_ctl_sw_wr_d_dro_s);
+		pr_info("\t reg_sw_debug_rec_intr_cause.qm_bm_rf_err_s = %d\n",
+					reg_sw_debug_rec_intr_cause.qm_bm_rf_err_s);
+	}
+
+	reg_base_address =      bm.sys_nrec_common_intr_cause;
+	reg_size   =   bm_reg_size.sys_nrec_common_intr_cause;
+	reg_offset = bm_reg_offset.sys_nrec_common_intr_cause * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_sys_nrec_common_intr_cause);
+	if (rc != OK)
+		return rc;
+	error_sum_bit = reg_sys_nrec_common_intr_cause.sys_nrec_common_intr_cause_sum;
+	if (error_sum_bit != OK) {
+		rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+		if (rc != OK)
+			return rc;
+		pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+			reg_base_address + reg_offset, *((u32 *)&reg_sys_nrec_common_intr_cause));
+
+		pr_info("\t reg_sys_nrec_common_intr_cause.sys_nrec_common_intr_cause_sum = %d\n",
+					reg_sys_nrec_common_intr_cause.sys_nrec_common_intr_cause_sum);
+		pr_info("\t reg_sys_nrec_common_intr_cause.qm_alc_pairs_viol_s = %d\n",
+					reg_sys_nrec_common_intr_cause.qm_alc_pairs_viol_s);
+		pr_info("\t reg_sys_nrec_common_intr_cause.qm_rls_pairs_viol_s = %d\n",
+					reg_sys_nrec_common_intr_cause.qm_rls_pairs_viol_s);
+		pr_info("\t reg_sys_nrec_common_intr_cause.ppe_alc_pairs_viol_s = %d\n",
+					reg_sys_nrec_common_intr_cause.ppe_alc_pairs_viol_s);
+		pr_info("\t reg_sys_nrec_common_intr_cause.ppe_rls_pairs_viol_s = %d\n",
+					reg_sys_nrec_common_intr_cause.ppe_rls_pairs_viol_s);
+		pr_info("\t reg_sys_nrec_common_intr_cause.ppe_alc_blen_viol_s = %d\n",
+					reg_sys_nrec_common_intr_cause.ppe_alc_blen_viol_s);
+		pr_info("\t reg_sys_nrec_common_intr_cause.ppe_rls_blen_viol_s = %d\n",
+					reg_sys_nrec_common_intr_cause.ppe_rls_blen_viol_s);
+		pr_info("\t reg_sys_nrec_common_intr_cause.mac_alc_pairs_viol_s = %d\n",
+					reg_sys_nrec_common_intr_cause.mac_alc_pairs_viol_s);
+		pr_info("\t reg_sys_nrec_common_intr_cause.mac_rls_pairs_viol_s = %d\n",
+					reg_sys_nrec_common_intr_cause.mac_rls_pairs_viol_s);
+		pr_info("\t reg_sys_nrec_common_intr_cause.mac_alc_pid_viol_s = %d\n",
+					reg_sys_nrec_common_intr_cause.mac_alc_pid_viol_s);
+		pr_info("\t reg_sys_nrec_common_intr_cause.mac_rls_pid_viol_s = %d\n",
+					reg_sys_nrec_common_intr_cause.mac_rls_pid_viol_s);
+		pr_info("\t reg_sys_nrec_common_intr_cause.drm_dram_err_s = %d\n",
+					reg_sys_nrec_common_intr_cause.drm_dram_err_s);
+		pr_info("\t reg_sys_nrec_common_intr_cause.dwm_dram_err_s = %d\n",
+					reg_sys_nrec_common_intr_cause.dwm_dram_err_s);
+		pr_info("\t reg_sys_nrec_common_intr_cause.dwm_fail_so_dram_fill_s = %d\n",
+					reg_sys_nrec_common_intr_cause.dwm_fail_so_dram_fill_s);
+	}
+
+	reg_base_address =      bm.error_intr_cause;
+	reg_size   =   bm_reg_size.error_intr_cause;
+	reg_offset = bm_reg_offset.error_intr_cause * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_error_intr_cause);
+	if (rc != OK)
+		return rc;
+	error_sum_bit = reg_error_intr_cause.qm_bm_err_intr_sum;
+	if (error_sum_bit != OK) {
+		rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+		if (rc != OK)
+			return rc;
+		pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+			reg_base_address + reg_offset, *((u32 *)&reg_error_intr_cause));
+
+		pr_info("\t reg_error_intr_cause.qm_bm_err_intr_sum = %d\n",
+					reg_error_intr_cause.qm_bm_err_intr_sum);
+		pr_info("\t reg_error_intr_cause.ecc_err_intr_s = %d\n",
+					reg_error_intr_cause.ecc_err_intr_s);
+		pr_info("\t reg_error_intr_cause.b0_sys_events_rec_bank_s = %d\n",
+					reg_error_intr_cause.b0_sys_events_rec_bank_s);
+		pr_info("\t reg_error_intr_cause.b0_sys_events_rec_bank_s = %d\n",
+					reg_error_intr_cause.b0_sys_events_rec_bank_s);
+		pr_info("\t reg_error_intr_cause.b2_sys_events_rec_bank_s = %d\n",
+					reg_error_intr_cause.b1_sys_events_rec_bank_s);
+		pr_info("\t reg_error_intr_cause.b3_sys_events_rec_bank_s = %d\n",
+					reg_error_intr_cause.b3_sys_events_rec_bank_s);
+		pr_info("\t reg_error_intr_cause.b4_sys_events_rec_bank_s = %d\n",
+					reg_error_intr_cause.b4_sys_events_rec_bank_s);
+		pr_info("\t reg_error_intr_cause.sw_debug_events_rec_s = %d\n",
+					reg_error_intr_cause.sw_debug_events_rec_s);
+		pr_info("\t reg_error_intr_cause.sys_events_nrec_common_s = %d\n",
+					reg_error_intr_cause.sys_events_nrec_common_s);
+	}
+
+	reg_base_address =      bm.func_intr_cause;
+	reg_size   =   bm_reg_size.func_intr_cause;
+	reg_offset = bm_reg_offset.func_intr_cause * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_func_intr_cause);
+	if (rc != OK)
+		return rc;
+	error_sum_bit = reg_func_intr_cause.qm_bm_func_intr_sum;
+	if (error_sum_bit != OK) {
+		rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+		if (rc != OK)
+			return rc;
+		pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+			reg_base_address + reg_offset, *((u32 *)&reg_func_intr_cause));
+
+		pr_info("\t reg_func_intr_cause.qm_bm_func_intr_sum = %d\n",
+					reg_func_intr_cause.qm_bm_func_intr_sum);
+		pr_info("\t reg_func_intr_cause.b0_pool_nempty_intr_s = %d\n",
+					reg_func_intr_cause.b0_pool_nempty_intr_s);
+		pr_info("\t reg_func_intr_cause.b0_dpool_ae_intr_s = %d\n",
+					reg_func_intr_cause.b0_dpool_ae_intr_s);
+		pr_info("\t reg_func_intr_cause.b0_dpool_af_intr_s = %d\n",
+					reg_func_intr_cause.b0_dpool_af_intr_s);
+		pr_info("\t reg_func_intr_cause.b1_pool_nempty_intr_s = %d\n",
+					reg_func_intr_cause.b1_pool_nempty_intr_s);
+		pr_info("\t reg_func_intr_cause.b1_dpool_ae_intr_s = %d\n",
+					reg_func_intr_cause.b1_dpool_ae_intr_s);
+		pr_info("\t reg_func_intr_cause.b1_dpool_af_intr_s = %d\n",
+					reg_func_intr_cause.b1_dpool_af_intr_s);
+		pr_info("\t reg_func_intr_cause.b2_pool_nempty_intr_s = %d\n",
+					reg_func_intr_cause.b2_pool_nempty_intr_s);
+		pr_info("\t reg_func_intr_cause.b2_dpool_ae_intr_s = %d\n",
+					reg_func_intr_cause.b2_dpool_ae_intr_s);
+		pr_info("\t reg_func_intr_cause.b2_dpool_af_intr_s = %d\n",
+					reg_func_intr_cause.b2_dpool_af_intr_s);
+		pr_info("\t reg_func_intr_cause.b3_pool_nempty_intr_s = %d\n",
+					reg_func_intr_cause.b3_pool_nempty_intr_s);
+		pr_info("\t reg_func_intr_cause.b3_dpool_ae_intr_s = %d\n",
+					reg_func_intr_cause.b3_dpool_ae_intr_s);
+		pr_info("\t reg_func_intr_cause.b3_dpool_af_intr_s = %d\n",
+					reg_func_intr_cause.b3_dpool_af_intr_s);
+		pr_info("\t reg_func_intr_cause.b4_pool_nempty_intr_s = %d\n",
+					reg_func_intr_cause.b4_pool_nempty_intr_s);
+		pr_info("\t reg_func_intr_cause.b4_dpool_ae_intr_s = %d\n",
+					reg_func_intr_cause.b4_dpool_ae_intr_s);
+		pr_info("\t reg_func_intr_cause.b4_dpool_af_intr_s = %d\n",
+					reg_func_intr_cause.b4_dpool_af_intr_s);
+	}
+
+	reg_base_address =      bm.ecc_err_intr_cause;
+	reg_size   =   bm_reg_size.ecc_err_intr_cause;
+	reg_offset = bm_reg_offset.ecc_err_intr_cause * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_ecc_err_intr_cause);
+	if (rc != OK)
+		return rc;
+	error_sum_bit = reg_ecc_err_intr_cause.ecc_err_intr_sum;
+	if (error_sum_bit != OK) {
+		rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+		if (rc != OK)
+			return rc;
+		pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+			reg_base_address + reg_offset, *((u32 *)&reg_ecc_err_intr_cause));
+
+		pr_info("\t reg_ecc_err_intr_cause.ecc_err_intr_sum = %d\n",
+					reg_ecc_err_intr_cause.ecc_err_intr_sum);
+		pr_info("\t reg_ecc_err_intr_cause.dpr_c_mng_b0_stat_ser_err_1_s = %d\n",
+					reg_ecc_err_intr_cause.dpr_c_mng_b0_stat_ser_err_1_s);
+		pr_info("\t reg_ecc_err_intr_cause.dpr_c_mng_b0_stat_ser_err_2_s = %d\n",
+					reg_ecc_err_intr_cause.dpr_c_mng_b0_stat_ser_err_2_s);
+		pr_info("\t reg_ecc_err_intr_cause.dpr_c_mng_b1_stat_ser_err_1_s = %d\n",
+					reg_ecc_err_intr_cause.dpr_c_mng_b1_stat_ser_err_1_s);
+		pr_info("\t reg_ecc_err_intr_cause.dpr_c_mng_b1_stat_ser_err_2_s = %d\n",
+					reg_ecc_err_intr_cause.dpr_c_mng_b1_stat_ser_err_2_s);
+		pr_info("\t reg_ecc_err_intr_cause.dpr_c_mng_b2_stat_ser_err_1_s = %d\n",
+					reg_ecc_err_intr_cause.dpr_c_mng_b2_stat_ser_err_1_s);
+		pr_info("\t reg_ecc_err_intr_cause.dpr_c_mng_b2_stat_ser_err_2_s = %d\n",
+					reg_ecc_err_intr_cause.dpr_c_mng_b2_stat_ser_err_2_s);
+		pr_info("\t reg_ecc_err_intr_cause.dpr_c_mng_b3_stat_ser_err_1_s = %d\n",
+					reg_ecc_err_intr_cause.dpr_c_mng_b3_stat_ser_err_1_s);
+		pr_info("\t reg_ecc_err_intr_cause.dpr_c_mng_b3_stat_ser_err_2_s = %d\n",
+					reg_ecc_err_intr_cause.dpr_c_mng_b3_stat_ser_err_2_s);
+		pr_info("\t reg_ecc_err_intr_cause.dpr_c_mng_b4_stat_ser_err_1_s = %d\n",
+					reg_ecc_err_intr_cause.dpr_c_mng_b4_stat_ser_err_1_s);
+		pr_info("\t reg_ecc_err_intr_cause.dpr_c_mng_b4_stat_ser_err_2_s = %d\n",
+					reg_ecc_err_intr_cause.dpr_c_mng_b4_stat_ser_err_2_s);
+		pr_info("\t reg_ecc_err_intr_cause.dpr_d_mng_ball_stat_ser_err_1_s = %d\n",
+					reg_ecc_err_intr_cause.dpr_d_mng_ball_stat_ser_err_1_s);
+		pr_info("\t reg_ecc_err_intr_cause.dpr_d_mng_ball_stat_ser_err_2_s = %d\n",
+					reg_ecc_err_intr_cause.dpr_d_mng_ball_stat_ser_err_2_s);
+		pr_info("\t reg_ecc_err_intr_cause.sram_b0_cache_ser_err_s = %d\n",
+					reg_ecc_err_intr_cause.sram_b0_cache_ser_err_s);
+		pr_info("\t reg_ecc_err_intr_cause.sram_b1_cache_ser_err_s = %d\n",
+					reg_ecc_err_intr_cause.sram_b1_cache_ser_err_s);
+		pr_info("\t reg_ecc_err_intr_cause.sram_b2_cache_ser_err_s = %d\n",
+					reg_ecc_err_intr_cause.sram_b2_cache_ser_err_s);
+		pr_info("\t reg_ecc_err_intr_cause.sram_b3_cache_ser_err_s = %d\n",
+					reg_ecc_err_intr_cause.sram_b3_cache_ser_err_s);
+		pr_info("\t reg_ecc_err_intr_cause.sram_b4_cache_ser_err_s = %d\n",
+					reg_ecc_err_intr_cause.sram_b4_cache_ser_err_s);
+		pr_info("\t reg_ecc_err_intr_cause.tpr_c_mng_b0_dyn_ser_err_s = %d\n",
+					reg_ecc_err_intr_cause.tpr_c_mng_b0_dyn_ser_err_s);
+		pr_info("\t reg_ecc_err_intr_cause.tpr_c_mng_b1_dyn_ser_err_s = %d\n",
+					reg_ecc_err_intr_cause.tpr_c_mng_b1_dyn_ser_err_s);
+		pr_info("\t reg_ecc_err_intr_cause.tpr_c_mng_b2_dyn_ser_err_s = %d\n",
+					reg_ecc_err_intr_cause.tpr_c_mng_b2_dyn_ser_err_s);
+		pr_info("\t reg_ecc_err_intr_cause.tpr_c_mng_b3_dyn_ser_err_s = %d\n",
+					reg_ecc_err_intr_cause.tpr_c_mng_b3_dyn_ser_err_s);
+		pr_info("\t reg_ecc_err_intr_cause.tpr_c_mng_b4_dyn_ser_err_s = %d\n",
+					reg_ecc_err_intr_cause.tpr_c_mng_b4_dyn_ser_err_s);
+		pr_info("\t reg_ecc_err_intr_cause.tpr_dro_mng_ball_dyn_ser_err_s = %d\n",
+					reg_ecc_err_intr_cause.tpr_dro_mng_ball_dyn_ser_err_s);
+		pr_info("\t reg_ecc_err_intr_cause.tpr_drw_mng_ball_dyn_ser_err_s = %d\n",
+					reg_ecc_err_intr_cause.tpr_drw_mng_ball_dyn_ser_err_s);
+	}
+
+	for (bid = 0; bid < BM_NUMBER_OF_BANKS; bid++) {
+		reg_base_address =      bm.pool_nempty_intr_cause[bid];
+		reg_size   =   bm_reg_size.pool_nempty_intr_cause[bid];
+		reg_offset = bm_reg_offset.pool_nempty_intr_cause[bid] * 0;
+
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b_pool_nempty_intr_cause);
+		if (rc != OK)
+			return rc;
+		error_sum_bit = reg_b_pool_nempty_intr_cause.b_pool_nempty_intr_sum;
+		if (error_sum_bit != OK) {
+			pr_info("\n for bank = %d:\n", bid);
+			rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+			if (rc != OK)
+				return rc;
+			pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+				reg_base_address + reg_offset, *((u32 *)&reg_b_pool_nempty_intr_cause));
+
+			pr_info("\t b%d_pool_nempty_intr_cause.b_pool_nempty_intr_sum = %d\n",
+						bid, reg_b_pool_nempty_intr_cause.b_pool_nempty_intr_sum);
+			pr_info("\t b%d_pool_nempty_intr_cause.b_pool_0_nempty_s = 0x%08X\n",
+						bid, reg_b_pool_nempty_intr_cause.b_pool_0_nempty_s);
+			pr_info("\t b%d_pool_nempty_intr_cause.b_pool_1_nempty_s = 0x%08X\n",
+						bid, reg_b_pool_nempty_intr_cause.b_pool_1_nempty_s);
+			pr_info("\t b%d_pool_nempty_intr_cause.b_pool_2_nempty_s = 0x%08X\n",
+						bid, reg_b_pool_nempty_intr_cause.b_pool_2_nempty_s);
+			pr_info("\t b%d_pool_nempty_intr_cause.b_pool_3_nempty_s = 0x%08X\n",
+						bid, reg_b_pool_nempty_intr_cause.b_pool_3_nempty_s);
+			if (bid != 0) {
+				pr_info("\t b%d_pool_nempty_intr_cause.b_pool_4_nempty_s = 0x%08X\n",
+							bid, reg_b_pool_nempty_intr_cause.b_pool_4_nempty_s);
+				pr_info("\t b%d_pool_nempty_intr_cause.b_pool_5_nempty_s = 0x%08X\n",
+							bid, reg_b_pool_nempty_intr_cause.b_pool_5_nempty_s);
+				pr_info("\t b%d_pool_nempty_intr_cause.b_pool_6_nempty_s = 0x%08X\n",
+							bid, reg_b_pool_nempty_intr_cause.b_pool_6_nempty_s);
+			}
+		}
+
+		reg_base_address =      bm.dpool_ae_intr_cause[bid];
+		reg_size   =   bm_reg_size.dpool_ae_intr_cause[bid];
+		reg_offset = bm_reg_offset.dpool_ae_intr_cause[bid] * 0;
+
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b_dpool_ae_intr_cause);
+		if (rc != OK)
+			return rc;
+		error_sum_bit = reg_b_dpool_ae_intr_cause.b_dpool_ae_intr_sum;
+		if (error_sum_bit != OK) {
+			pr_info("\n for bank = %d:\n", bid);
+			rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+			if (rc != OK)
+				return rc;
+			pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+				reg_base_address + reg_offset, *((u32 *)&reg_b_dpool_ae_intr_cause));
+
+			pr_info("\t b%d_dpool_ae_intr_cause.b_dpool_ae_intr_sum = %d\n",
+						bid, reg_b_dpool_ae_intr_cause.b_dpool_ae_intr_sum);
+			pr_info("\t b%d_dpool_ae_intr_cause.b_dpool_0_ae_s = 0x%08X\n",
+						bid, reg_b_dpool_ae_intr_cause.b_dpool_0_ae_s);
+			pr_info("\t b%d_dpool_ae_intr_cause.b_dpool_1_ae_s = 0x%08X\n",
+						bid, reg_b_dpool_ae_intr_cause.b_dpool_1_ae_s);
+			pr_info("\t b%d_dpool_ae_intr_cause.b_dpool_2_ae_s = 0x%08X\n",
+						bid, reg_b_dpool_ae_intr_cause.b_dpool_2_ae_s);
+			pr_info("\t b%d_dpool_ae_intr_cause.b_dpool_3_ae_s = 0x%08X\n",
+						bid, reg_b_dpool_ae_intr_cause.b_dpool_3_ae_s);
+			if (bid != 0) {
+				pr_info("\t b%d_dpool_ae_intr_cause.b_dpool_4_ae_s = 0x%08X\n",
+							bid, reg_b_dpool_ae_intr_cause.b_dpool_4_ae_s);
+				pr_info("\t b%d_dpool_ae_intr_cause.b_dpool_5_ae_s = 0x%08X\n",
+							bid, reg_b_dpool_ae_intr_cause.b_dpool_5_ae_s);
+				pr_info("\t b%d_dpool_ae_intr_cause.b_dpool_6_ae_s = 0x%08X\n",
+							bid, reg_b_dpool_ae_intr_cause.b_dpool_6_ae_s);
+			}
+		}
+
+		reg_base_address =      bm.dpool_af_intr_cause[bid];
+		reg_size   =   bm_reg_size.dpool_af_intr_cause[bid];
+		reg_offset = bm_reg_offset.dpool_af_intr_cause[bid];
+
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b_dpool_af_intr_cause);
+		if (rc != OK)
+			return rc;
+		error_sum_bit = reg_b_dpool_af_intr_cause.b_dpool_af_intr_sum;
+		if (error_sum_bit != OK) {
+			pr_info("\n for bank = %d:\n", bid);
+			rc =  bm_register_name_get(reg_base_address, reg_offset, reg_name);
+			if (rc != OK)
+				return rc;
+			pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name,
+				reg_base_address + reg_offset, *((u32 *)&reg_b_dpool_af_intr_cause));
+
+			pr_info("\t b%d_dpool_af_intr_cause.b_dpool_af_intr_sum = %d\n",
+						bid, reg_b_dpool_af_intr_cause.b_dpool_af_intr_sum);
+			pr_info("\t b%d_dpool_af_intr_cause.b_dpool_0_af_s = 0x%08X\n",
+						bid, reg_b_dpool_af_intr_cause.b_dpool_0_af_s);
+			pr_info("\t b%d_dpool_af_intr_cause.b_dpool_1_af_s = 0x%08X\n",
+						bid, reg_b_dpool_af_intr_cause.b_dpool_1_af_s);
+			pr_info("\t b%d_dpool_af_intr_cause.b_dpool_2_af_s = 0x%08X\n",
+						bid, reg_b_dpool_af_intr_cause.b_dpool_2_af_s);
+			pr_info("\t b%d_dpool_af_intr_cause.b_dpool_3_af_s = 0x%08X\n",
+						bid, reg_b_dpool_af_intr_cause.b_dpool_3_af_s);
+			if (bid != 0) {
+				pr_info("\t b%d_dpool_af_intr_cause.b_dpool_4_af_s = 0x%08X\n",
+							bid, reg_b_dpool_af_intr_cause.b_dpool_4_af_s);
+				pr_info("\t b%d_dpool_af_intr_cause.b_dpool_5_af_s = 0x%08X\n",
+							bid, reg_b_dpool_af_intr_cause.b_dpool_5_af_s);
+				pr_info("\t b%d_dpool_af_intr_cause.b_dpool_6_af_s = 0x%08X\n",
+							bid, reg_b_dpool_af_intr_cause.b_dpool_6_af_s);
+			}
+		}
+	}
+
+	rc = OK;
+	return rc;
+}
+
+/*BM Internal functions*/
+int bm_pool_memory_fill(u32 pool, u32 num_of_buffers, u32 *base_address)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 granularity_of_pe_in_dram;
+	u32 i, *p;
+/*
+	u64 p_long;
+	uint64_t p_long;
+	uintptr_t p_long;
+*/
+	granularity_of_pe_in_dram = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_DRAM;	/* 64/4 */
+
+	if ((num_of_buffers % granularity_of_pe_in_dram) != 0) /* UNIT_OF__1_BYTES = 1 */
+		return rc; /* PE_size is 22 bit */
+	if ((pool            <         BM_POOL_QM_MIN) || (pool            >         BM_POOL_QM_MAX))
+		return rc;
+	if ((pool == 0) || (pool == 1)) {
+		if ((num_of_buffers < BM_NUM_OF_BUFFERS_QM_MIN) || (num_of_buffers >  BM_NUM_OF_BUFFERS_QM_GPM_MAX))
+			return rc;
+	}
+	if ((pool == 2) || (pool == 3)) {
+		if ((num_of_buffers < BM_NUM_OF_BUFFERS_QM_MIN) || (num_of_buffers > BM_NUM_OF_BUFFERS_QM_DRAM_MAX))
+			return rc;
+	}
+/*	if ((base_address_hi < BM_DRAM_ADDRESS_HI_MIN) || (base_address_hi > BM_DRAM_ADDRESS_HI_MAX)) */
+	if ((((struct mv_word40 *)base_address)->hi < BM_DRAM_ADDRESS_HI_MIN) ||
+		(((struct mv_word40 *)base_address)->hi > BM_DRAM_ADDRESS_HI_MAX))
+		return rc;
+/*	if ((base_address_lo < BM_DRAM_ADDRESS_LO_MIN) || (base_address_lo > BM_DRAM_ADDRESS_LO_MAX)) */
+	if ((((struct mv_word40 *)base_address)->lo < BM_DRAM_ADDRESS_LO_MIN) ||
+		(((struct mv_word40 *)base_address)->lo > BM_DRAM_ADDRESS_LO_MAX))
+		return rc;
+
+/*
+	action
+	Takes pool_base_address and use it as a pointer to fill all PE's with incrementing value (starting with 1)
+	Write in Dram in BM pool section an incrementing index */
+
+	p = (u32 *)(((struct mv_word40 *)base_address)->lo);
+/*
+	base_address->hi - ???
+	p = (u32 *)((base_address->hi << 32) + base_address->lo);
+	p = (u32 *)temp;
+	p++;*/
+	for (i = 0; i < num_of_buffers; i++)
+		*p++ = i + 1;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_pool_dram_set(u32 pool, u32 num_of_buffers, u32 pe_size, u32 *base_address,
+						u32 ae_thr, u32 af_thr)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pid, bid, pid_local, dram_size, dram_ae_thr, dram_af_thr;
+	struct bm_d_mng_ball_stat_data          tab_dpr_d_mng_ball_stat;
+	u32 granularity_of_pe_in_dram;
+
+	if ((pool >= BM_POOL_QM_MIN) && (pool <= BM_POOL_QM_MAX)) { /* QM pools */
+		granularity_of_pe_in_dram = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_DRAM;	/* 64/4 */
+	} else if ((pool >= BM_POOL_GP_MIN) && (pool <= BM_POOL_GP_MAX)) { /* GP pools */
+		if (pe_size == BM_PE_SIZE_IS_40_BITS)
+			granularity_of_pe_in_dram =
+				GRANULARITY_OF_64_BYTES / GP_PE_SIZE_OF_40_BITS_IN_BYTES_IN_DRAM;	/* 64/8 */
+		else if (pe_size == BM_PE_SIZE_IS_32_BITS)
+			granularity_of_pe_in_dram =
+				GRANULARITY_OF_64_BYTES / GP_PE_SIZE_OF_32_BITS_IN_BYTES_IN_DRAM;	/* 64/4 */
+		else
+			return rc;
+	} else
+		return rc;
+
+	if ((num_of_buffers % granularity_of_pe_in_dram) != 0)
+		return rc;
+	if         ((ae_thr % granularity_of_pe_in_dram) != 0)
+		return rc;
+	if         ((af_thr % granularity_of_pe_in_dram) != 0)
+		return rc;
+	if ((((struct mv_word40 *)base_address)->lo % GRANULARITY_OF_64_BYTES) != 0)
+		return rc;
+
+	if (ae_thr       >= af_thr)
+		return rc;
+
+	if ((pool            <            BM_POOL_MIN) || (pool            >            BM_POOL_MAX))
+		return rc;
+	if ((pool            >         BM_POOL_QM_MAX) && (pool            <         BM_POOL_GP_MIN))
+		return rc; /* pools 4, 5, 6, 7 don't exist */
+	if ((pool == 0) || (pool == 1)) {
+		if ((num_of_buffers < BM_NUM_OF_BUFFERS_QM_MIN) || (num_of_buffers >  BM_NUM_OF_BUFFERS_QM_GPM_MAX))
+			return rc;
+	} else if ((pool == 2) || (pool == 3)) {
+		if ((num_of_buffers < BM_NUM_OF_BUFFERS_QM_MIN) || (num_of_buffers > BM_NUM_OF_BUFFERS_QM_DRAM_MAX))
+			return rc;
+	} else if ((pool >= BM_POOL_GP_MIN) && (pool <= BM_POOL_GP_MAX)) {
+		if ((num_of_buffers < BM_NUM_OF_BUFFERS_GP_MIN) || (num_of_buffers >      BM_NUM_OF_BUFFERS_GP_MAX))
+			return rc; /* pools 4, 5, 6, 7 don't exist */
+	} else
+		return rc;
+
+	if ((pe_size         <         BM_PE_SIZE_MIN) || (pe_size         >         BM_PE_SIZE_MAX))
+		return rc;
+
+/*	if ((base_address_hi < BM_DRAM_ADDRESS_HI_MIN) || (base_address_hi > BM_DRAM_ADDRESS_HI_MAX)) */
+	if ((((struct mv_word40 *)base_address)->hi < BM_DRAM_ADDRESS_HI_MIN) ||
+		(((struct mv_word40 *)base_address)->hi > BM_DRAM_ADDRESS_HI_MAX))
+		return rc;
+/*	if ((base_address_lo < BM_DRAM_ADDRESS_LO_MIN) || (base_address_lo > BM_DRAM_ADDRESS_LO_MAX)) */
+	if ((((struct mv_word40 *)base_address)->lo < BM_DRAM_ADDRESS_LO_MIN) ||
+		(((struct mv_word40 *)base_address)->lo > BM_DRAM_ADDRESS_LO_MAX))
+		return rc;
+	if ((ae_thr          <          BM_AE_THR_MIN) || (ae_thr          >          BM_AE_THR_MAX))
+		return rc;
+	if ((af_thr          <          BM_AF_THR_MIN) || (af_thr          >          BM_AF_THR_MAX))
+		return rc;
+
+	pid       = (int)pool;
+	bid       = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	reg_base_address =      bm.dpr_d_mng_ball_stat;
+	reg_size   =   bm_reg_size.dpr_d_mng_ball_stat;
+	reg_offset = bm_reg_offset.dpr_d_mng_ball_stat * BM_PID_TO_GLOBAL_POOL_IDX(pid);
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_dpr_d_mng_ball_stat);
+	if (rc != OK)
+		return rc;
+
+	tab_dpr_d_mng_ball_stat.dram_start_hi = ((struct mv_word40 *)base_address)->hi;
+	tab_dpr_d_mng_ball_stat.dram_start_lo = ((struct mv_word40 *)base_address)->lo;
+	if (bid == 0) {
+		dram_ae_thr = BM_QM_PE_UNITS_TO_BYTES(ae_thr);
+		dram_af_thr = BM_QM_PE_UNITS_TO_BYTES(af_thr);
+		dram_size   = BM_QM_PE_UNITS_TO_BYTES(num_of_buffers);
+	} else if (bid != 0) {
+		dram_ae_thr = BM_GP_PE_UNITS_TO_BYTES(ae_thr,         pe_size);
+		dram_af_thr = BM_GP_PE_UNITS_TO_BYTES(af_thr,         pe_size);
+		dram_size   = BM_GP_PE_UNITS_TO_BYTES(num_of_buffers, pe_size);
+	} else
+		return rc;
+
+	tab_dpr_d_mng_ball_stat.dram_ae_thr	=    ae_thr / UNIT_OF_64_BYTES;
+	tab_dpr_d_mng_ball_stat.dram_af_thr	=    af_thr / UNIT_OF_64_BYTES;
+	tab_dpr_d_mng_ball_stat.dram_size   = dram_size / UNIT_OF_64_BYTES;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&tab_dpr_d_mng_ball_stat);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_pool_fill_level_set(u32 pool, u32 num_of_buffers, u32 pe_size, u32 quick_init)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pid, bid, pid_local, dram_fill;
+	struct bm_tpr_drw_mng_ball_dyn_data         tab_tpr_drw_mng_ball_dyn;
+	u32 granularity_of_pe_in_dram;
+
+	if ((pool >= BM_POOL_QM_MIN) && (pool <= BM_POOL_QM_MAX)) { /* QM pools */
+		granularity_of_pe_in_dram = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_DRAM;	/* 64/4 */
+	} else if ((pool >= BM_POOL_GP_MIN) && (pool <= BM_POOL_GP_MAX)) { /* GP pools */
+		if (pe_size == BM_PE_SIZE_IS_40_BITS)
+			granularity_of_pe_in_dram =
+				GRANULARITY_OF_64_BYTES / GP_PE_SIZE_OF_40_BITS_IN_BYTES_IN_DRAM;	/* 64/8 */
+		else if (pe_size == BM_PE_SIZE_IS_32_BITS)
+			granularity_of_pe_in_dram =
+				GRANULARITY_OF_64_BYTES / GP_PE_SIZE_OF_32_BITS_IN_BYTES_IN_DRAM;	/* 64/4 */
+		else
+			return rc;
+	} else
+		return rc;
+
+	if ((num_of_buffers % granularity_of_pe_in_dram) != 0)
+		return rc;
+
+	if ((pool           <       BM_POOL_MIN) || (pool           >            BM_POOL_MAX))
+		return rc;
+	if ((pool           >    BM_POOL_QM_MAX) && (pool           <         BM_POOL_GP_MIN))
+		return rc; /* pools 4, 5, 6, 7 don't exist */
+	if ((pool == 0) || (pool == 1)) {
+		if ((num_of_buffers < BM_NUM_OF_BUFFERS_QM_MIN) || (num_of_buffers >  BM_NUM_OF_BUFFERS_QM_GPM_MAX))
+			return rc;
+	} else if ((pool == 2) || (pool == 3)) {
+		if ((num_of_buffers < BM_NUM_OF_BUFFERS_QM_MIN) || (num_of_buffers > BM_NUM_OF_BUFFERS_QM_DRAM_MAX))
+			return rc;
+	} else if ((pool >= BM_POOL_GP_MIN) && (pool <= BM_POOL_GP_MAX)) {
+		if ((num_of_buffers < BM_NUM_OF_BUFFERS_GP_MIN) || (num_of_buffers >      BM_NUM_OF_BUFFERS_GP_MAX))
+			return rc; /* pools 4, 5, 6, 7 don't exist */
+	} else
+		return rc;
+
+	if ((pe_size        <    BM_PE_SIZE_MIN) || (pe_size        >         BM_PE_SIZE_MAX))
+		return rc;
+	if ((quick_init     < BM_QUICK_INIT_MIN) || (quick_init     >      BM_QUICK_INIT_MAX))
+		return rc;
+
+	pid       = (int)pool;
+	bid       = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	reg_base_address =      bm.tpr_drw_mng_ball_dyn;
+	reg_size   =   bm_reg_size.tpr_drw_mng_ball_dyn;
+	reg_offset = bm_reg_offset.tpr_drw_mng_ball_dyn * BM_PID_TO_GLOBAL_POOL_IDX(pid);
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_tpr_drw_mng_ball_dyn);
+	if (rc != OK)
+		return rc;
+
+	if (bid == 0)
+		dram_fill	= BM_QM_PE_UNITS_TO_BYTES(num_of_buffers);
+	if (bid != 0)
+		dram_fill	= BM_GP_PE_UNITS_TO_BYTES(num_of_buffers, pe_size);
+	tab_tpr_drw_mng_ball_dyn.dram_fill	= dram_fill/UNIT_OF__8_BYTES;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&tab_tpr_drw_mng_ball_dyn);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_pool_enable(u32 pool, u32 quick_init)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pid, bid, pid_local;
+	struct bm_pool_conf_b0  reg_b0_pool_conf;
+	struct bm_pool_conf_bgp reg_bgp_pool_conf;
+
+	if ((pool       <       BM_POOL_MIN) || (pool       >       BM_POOL_MAX))
+		return rc;
+	if ((pool       >    BM_POOL_QM_MAX) && (pool       <    BM_POOL_GP_MIN))
+		return rc; /* pools 4, 5, 6, 7 don't exist */
+	if ((quick_init < BM_QUICK_INIT_MIN) || (quick_init > BM_QUICK_INIT_MAX))
+		return rc;
+
+	pid = (int)pool;
+	bid = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	reg_base_address =      bm.b_pool_n_conf[bid];
+	reg_size   =   bm_reg_size.b_pool_n_conf[bid];
+	reg_offset = bm_reg_offset.b_pool_n_conf[bid] * pid_local;
+
+	if  (bid == 0) { /* QM pools */
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b0_pool_conf);
+		if (rc != OK)
+			return rc;
+
+		reg_b0_pool_conf.pool_enable		= ON;
+		reg_b0_pool_conf.pool_quick_init	= quick_init;
+		rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b0_pool_conf);
+		if (rc != OK)
+			return rc;
+	} else if ((bid == 1) || (bid == 2) || (bid == 3) || (bid == 4)) { /* QP pools */
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_pool_conf);
+		if (rc != OK)
+			return rc;
+
+		reg_bgp_pool_conf.pool_enable		= ON;
+		reg_bgp_pool_conf.pool_quick_init	= quick_init;
+		rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_pool_conf);
+		if (rc != OK)
+			return rc;
+	} else {
+		rc = -BM_INPUT_NOT_IN_RANGE;
+		return rc;
+	}
+
+	rc = OK;
+	return rc;
+}
+
+int bm_gp_pool_pe_size_set(u32 pool, u32 pe_size)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pid, bid, pid_local;
+	struct bm_pool_conf_bgp reg_bgp_pool_conf;
+
+	if ((pool    < BM_POOL_GP_MIN) || (pool    > BM_POOL_GP_MAX))
+		return rc;
+	if ((pe_size < BM_PE_SIZE_MIN) || (pe_size > BM_PE_SIZE_MAX))
+		return rc;
+
+	pid = (int)pool;
+	bid = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	reg_base_address =      bm.b_pool_n_conf[bid];
+	reg_size   =   bm_reg_size.b_pool_n_conf[bid];
+	reg_offset = bm_reg_offset.b_pool_n_conf[bid] * pid_local;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_pool_conf);
+	if (rc != OK)
+		return rc;
+
+	reg_bgp_pool_conf.pe_size	= pe_size;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_pool_conf);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_gp_pool_pair_set(u32 pool, u32 pool_pair)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pid, bid, pid_local;
+	struct bm_pool_conf_bgp reg_bgp_pool_n_conf;
+
+	if ((pool      <   BM_POOL_GP_MIN) || (pool      >   BM_POOL_GP_MAX))
+		return rc;
+	if ((pool_pair < BM_POOL_PAIR_MIN) || (pool_pair > BM_POOL_PAIR_MAX))
+		return rc;
+
+	pid = (int)pool;
+	bid = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	reg_base_address =      bm.b_pool_n_conf[bid];
+	reg_size   =   bm_reg_size.b_pool_n_conf[bid];
+	reg_offset = bm_reg_offset.b_pool_n_conf[bid] * pid_local;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_pool_n_conf);
+	if (rc != OK)
+		return rc;
+
+	reg_bgp_pool_n_conf.pool_in_pairs	= pool_pair;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_pool_n_conf);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+/*int bm_pool_cache_set(u32 pool, u32 vmid, u32 attr, u32 so_thr, u32 si_thr, u32 end, u32 start)*/
+int bm_pool_cache_set(u32 pool, u32 cache_vmid, u32 cache_attr, u32 cache_so_thr, u32 cache_si_thr,
+						u32 cache_num_of_buffers)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pid, bid, pid_local, pid_temp, bid_temp, pid_local_temp;
+	u32 granularity_of_pe_in_cache, cache_start, cache_end, cache_end_max[BM_BANK_MAX], pool_enable;
+	struct bm_pool_conf_b0    reg_b0_pool_conf;
+	struct bm_pool_conf_bgp   reg_bgp_pool_conf;
+	struct bm_c_mng_stat_data tab_dpr_c_mng_stat;
+
+	if ((pool >= BM_POOL_QM_MIN) || (pool <= BM_POOL_QM_MAX)) /* QM pools */
+		granularity_of_pe_in_cache = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_CACHE;	/* 64/4 */
+	else if ((pool >= BM_POOL_GP_MIN) || (pool <= BM_POOL_GP_MAX)) /* GM pools */
+		granularity_of_pe_in_cache = GRANULARITY_OF_64_BYTES / GP_PE_SIZE_IN_BYTES_IN_CACHE;	/* 64/8 */
+	else
+		return rc;
+
+	if ((cache_num_of_buffers % granularity_of_pe_in_cache) != 0)
+		return rc;
+	if (cache_so_thr >= cache_si_thr + 16)
+		return rc;
+
+	if ((pool                 <          BM_POOL_MIN) || (pool                 >          BM_POOL_MAX))
+		return rc;
+	if ((pool                 >       BM_POOL_QM_MAX) && (pool                 <       BM_POOL_GP_MIN))
+		return rc; /* pools 4, 5, 6, 7 don't exist */
+	if ((cache_vmid           <          BM_VMID_MIN) || (cache_vmid           >          BM_VMID_MAX))
+		return rc;
+	if ((cache_attr           <    BM_CACHE_ATTR_MIN) || (cache_attr           >    BM_CACHE_ATTR_MAX))
+		return rc;
+	if ((cache_so_thr         <  BM_CACHE_SO_THR_MIN) || (cache_so_thr         >  BM_CACHE_SO_THR_MAX))
+		return rc;
+	if ((cache_si_thr         <  BM_CACHE_SI_THR_MIN) || (cache_si_thr         >  BM_CACHE_SI_THR_MAX))
+		return rc;
+	if ((pool >= BM_POOL_QM_MIN) || (pool <= BM_POOL_QM_MAX)) { /* QM pools */
+		if ((cache_num_of_buffers < BM_CACHE_NUM_OF_BUFFERS_QM_MIN) ||
+			(cache_num_of_buffers > BM_CACHE_NUM_OF_BUFFERS_QM_MAX))
+			return rc;
+	} else if ((pool >= BM_POOL_GP_MIN) || (pool <= BM_POOL_GP_MAX)) { /* GM pools */
+		if ((cache_num_of_buffers < BM_CACHE_NUM_OF_BUFFERS_GP_MIN) ||
+			(cache_num_of_buffers > BM_CACHE_NUM_OF_BUFFERS_GP_MAX))
+			return rc;
+	} else
+		return rc;
+
+	for (bid_temp = BM_BANK_MIN; bid_temp < BM_BANK_MAX; bid_temp++)
+		cache_end_max[bid_temp] = 0;
+
+	for (pid_temp = BM_POOL_MIN; pid_temp < BM_POOL_MAX; pid_temp++) {
+		bid_temp = BM_PID_TO_BANK(pid_temp);
+		pid_local_temp = BM_PID_TO_PID_LOCAL(pid_temp);
+
+		if ((pid_temp > BM_POOL_QM_MAX) && (pid_temp < BM_POOL_GP_MIN))
+			continue; /* pools 4, 5, 6, 7 don't exist */
+
+		reg_base_address =      bm.b_pool_n_conf[bid_temp];
+		reg_size   =   bm_reg_size.b_pool_n_conf[bid_temp];
+		reg_offset = bm_reg_offset.b_pool_n_conf[bid_temp] * pid_local_temp;
+
+		if  (bid_temp == 0) { /* QM pools */
+			rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b0_pool_conf);
+			if (rc != OK)
+				return rc;
+			pool_enable = reg_b0_pool_conf.pool_enable;
+		} else if ((bid_temp == 1) || (bid_temp == 2) || (bid_temp == 3) || (bid_temp == 4)) { /* QP pools */
+			rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_pool_conf);
+			if (rc != OK)
+				return rc;
+			pool_enable = reg_bgp_pool_conf.pool_enable;
+		} else {
+			rc = -BM_INPUT_NOT_IN_RANGE;
+			return rc;
+		}
+
+		if (pool_enable == OFF)
+			continue;	/* pool pid_local_temp is not enabled */
+
+		reg_base_address =      bm.dpr_c_mng_stat[bid_temp];
+		reg_size   =   bm_reg_size.dpr_c_mng_stat[bid_temp];
+		reg_offset = bm_reg_offset.dpr_c_mng_stat[bid_temp] * pid_local_temp;
+
+		rc = bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_dpr_c_mng_stat);
+		if (rc != OK)
+			return rc;
+		cache_end_max[bid_temp] = MV_MAX(cache_end_max[bid_temp],
+						tab_dpr_c_mng_stat.cache_end * UNIT_OF_64_BYTES);
+	}
+
+	pid = pool;
+	bid = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	if ((cache_end_max[bid]   < BM_CACHE_END_MIN) || (cache_end_max[bid]    >      BM_CACHE_END_MAX))
+		return rc;
+
+	reg_base_address =      bm.dpr_c_mng_stat[bid];
+	reg_size   =   bm_reg_size.dpr_c_mng_stat[bid];
+	reg_offset = bm_reg_offset.dpr_c_mng_stat[bid] * pid_local;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_dpr_c_mng_stat);
+	if (rc != OK)
+		return rc;
+	cache_start  = cache_end_max[bid] + 1;
+	cache_end    = cache_start + (cache_num_of_buffers / granularity_of_pe_in_cache - 1);
+	cache_end    = cache_start + (cache_num_of_buffers / granularity_of_pe_in_cache - 1);
+
+	if ((cache_start <     BM_START_MIN) || (cache_start  >    BM_START_MAX))
+		return rc;
+	if ((cache_end   < BM_CACHE_END_MIN) || (cache_end    >    BM_CACHE_END_MAX))
+		return rc;
+
+	tab_dpr_c_mng_stat.cache_start  = cache_start / UNIT_OF_64_BYTES;
+	tab_dpr_c_mng_stat.cache_end    = cache_end   / UNIT_OF_64_BYTES;
+	tab_dpr_c_mng_stat.cache_si_thr = cache_si_thr;
+	tab_dpr_c_mng_stat.cache_so_thr = cache_so_thr;
+	tab_dpr_c_mng_stat.cache_attr   = cache_attr;
+	tab_dpr_c_mng_stat.cache_vmid   = cache_vmid;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&tab_dpr_c_mng_stat);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_pool_disable(u32 pool)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pid, bid, pid_local;
+	struct bm_pool_conf_b0  reg_b0_pool_conf;
+	struct bm_pool_conf_bgp reg_bgp_pool_conf;
+
+	if ((pool  <    BM_POOL_MIN) || (pool  >     BM_POOL_MAX))
+		return rc;
+	if ((pool  > BM_POOL_QM_MAX) && (pool  < BM_POOL_GP_MIN))
+		return rc; /* pools 4, 5, 6, 7 don't exist */
+
+	pid = (int)pool;
+	bid = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	reg_base_address =      bm.b_pool_n_conf[bid];
+	reg_size   =   bm_reg_size.b_pool_n_conf[bid];
+	reg_offset = bm_reg_offset.b_pool_n_conf[bid] * pid_local;
+
+	if  (bid == 0) { /* QM pools */
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b0_pool_conf);
+		if (rc != OK)
+			return rc;
+		reg_b0_pool_conf.pool_enable = OFF;
+		rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b0_pool_conf);
+		if (rc != OK)
+			return rc;
+	} else if ((bid == 1) || (bid == 2) || (bid == 3) || (bid == 4)) { /* QP pools */
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_pool_conf);
+		if (rc != OK)
+			return rc;
+
+		reg_bgp_pool_conf.pool_enable = OFF;
+		rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_pool_conf);
+		if (rc != OK)
+			return rc;
+	} else {
+		rc = -BM_INPUT_NOT_IN_RANGE;
+		return rc;
+	}
+
+	rc = OK;
+	return rc;
+}
+
+#ifdef __linux__
+/*
+	DUMMY
+	See QM project in mv_qm.c
+*/
+int qm_pfe_base_address_pool_set(u32 *pl_base_address, u32 *qece_base_address)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+
+	rc = OK;
+	return rc;
+}
+/*
+int qm_pfe_base_address_pool_set(u32 *qece_base_address, u32 *pyld_base_address)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct pfe_qece_dram_base_address_hi         reg_qece_dram_base_address_hi;
+	struct pfe_qece_dram_base_address_lo         reg_qece_dram_base_address_lo;
+	struct pfe_pyld_dram_base_address_hi         reg_pyld_dram_base_address_hi;
+	struct pfe_pyld_dram_base_address_lo         reg_pyld_dram_base_address_lo;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((((struct mv_word40 *)qece_base_address)->hi < BM_DRAM_ADDRESS_HI_MIN) ||
+		(((struct mv_word40 *)qece_base_address)->hi > BM_DRAM_ADDRESS_HI_MAX))
+		return rc;
+	if ((((struct mv_word40 *)qece_base_address)->lo < BM_DRAM_ADDRESS_LO_MIN) ||
+		(((struct mv_word40 *)qece_base_address)->lo > BM_DRAM_ADDRESS_LO_MAX))
+		return rc;
+	if ((((struct mv_word40 *)pyld_base_address)->hi < BM_DRAM_ADDRESS_HI_MIN) ||
+		(((struct mv_word40 *)pyld_base_address)->hi > BM_DRAM_ADDRESS_HI_MAX))
+		return rc;
+	if ((((struct mv_word40 *)pyld_base_address)->lo < BM_DRAM_ADDRESS_LO_MIN) ||
+		(((struct mv_word40 *)pyld_base_address)->lo > BM_DRAM_ADDRESS_LO_MAX))
+		return rc;
+
+	reg_base_address =      qm.pfe.qece_dram_base_address_hi;
+	reg_size   =   qm_reg_size.pfe.qece_dram_base_address_hi;
+	reg_offset = qm_reg_offset.pfe.qece_dram_base_address_hi * 0;
+
+	rc = bm_register_read( reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_hi);
+	if (rc != OK)
+		return rc;
+
+	reg_qece_dram_base_address_hi.qece_dram_base_address_hi	= ((struct mv_word40 *)qece_base_address)->hi;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_hi);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.qece_dram_base_address_lo;
+	reg_size   =   qm_reg_size.pfe.qece_dram_base_address_lo;
+	reg_offset = qm_reg_offset.pfe.qece_dram_base_address_lo * 0;
+
+	rc = bm_register_read( reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_lo);
+	if (rc != OK)
+		return rc;
+	reg_qece_dram_base_address_lo.qece_dram_base_address_low = ((struct mv_word40 *)qece_base_address)->lo;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_lo);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.pyld_dram_base_address_hi;
+	reg_size   =   qm_reg_size.pfe.pyld_dram_base_address_hi;
+	reg_offset = qm_reg_offset.pfe.pyld_dram_base_address_hi * 0;
+
+	rc = bm_register_read( reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_hi);
+	if (rc != OK)
+		return rc;
+	reg_pyld_dram_base_address_hi.pyld_dram_base_address_hi	 = ((struct mv_word40 *)pyld_base_address)->hi;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_hi);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.pyld_dram_base_address_lo;
+	reg_size   =   qm_reg_size.pfe.pyld_dram_base_address_lo;
+	reg_offset = qm_reg_offset.pfe.pyld_dram_base_address_lo * 0;
+
+	rc = bm_register_read( reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_lo);
+	if (rc != OK)
+		return rc;
+	reg_pyld_dram_base_address_lo.pyld_dram_base_address_low = ((struct mv_word40 *)pyld_base_address)->lo;
+	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_lo);
+	if (rc != OK)
+		return rc;
+
+	rc = OK;
+	return rc;
+}
+*/
+
+#else /* __linux__ */
+#endif /* __linux__ */
+
+#define	COMPLETE_HW_WRITE
+
+#define	my_RW_DEBUG_UNITEST	/* for unitest */
+#ifdef my_RW_DEBUG_UNITEST
+int bm_register_read(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+/*	char reg_name[50];
+*/
+	u32 *temp;
+	u32 i;
+
+	if ((base_address <   BM_ADDRESS_MIN) || (base_address >   BM_ADDRESS_MAX))
+		return rc;
+	if ((offset       <    BM_OFFSET_MIN) || (offset       >    BM_OFFSET_MAX))
+		return rc;
+	if ((wordsNumber  < BM_DATA_SIZE_MIN) || (wordsNumber  > BM_DATA_SIZE_MAX))
+		return rc;
+	if (((u32)dataPtr <  BM_DATA_PTR_MIN) || ((u32)dataPtr >  BM_DATA_PTR_MAX))
+		return rc;
+
+/*	In the future we can also add printing of the fields of the register */
+/*	pr_info(" DUMMY_PRINT  read by function <%s>,  result = 0x%08X\n", __func__, *(u32 *)dataPtr);
+
+	bm_register_name_get(base_address, offset, reg_name);
+	pr_info("[QM-BM]  READ_REG add = 0x%08X : name = %s : value =", base_address, reg_name);
+*/
+	temp = dataPtr;
+	for (i = 0; i < wordsNumber; i++) {
+		/*
+		pr_info(" 0x%08X", *(u32 *)temp);*/
+		*(u32 *)temp = 0;
+		temp++;
+	}
+	pr_info("\n");
+/*	return OK;	 */
+/*
+	rc = mv_pp3_hw_read(base_address+offset, wordsNumber, dataPtr);
+	if (rc != OK) {
+		pr_info(" Not Available\n");
+		return rc;
+	}
+*/
+/*	if (rc != OK)
+		return rc;*/
+
+	COMPLETE_HW_WRITE
+	rc = OK;
+	return rc;
+}
+
+int bm_register_write(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr)
+{
+	char reg_name[50];
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 *temp;
+	u32 i;
+
+	if ((base_address <   BM_ADDRESS_MIN) || (base_address >   BM_ADDRESS_MAX))
+		return rc;
+	if ((offset       <    BM_OFFSET_MIN) || (offset       >    BM_OFFSET_MAX))
+		return rc;
+	if ((wordsNumber  < BM_DATA_SIZE_MIN) || (wordsNumber  > BM_DATA_SIZE_MAX))
+		return rc;
+	if (((u32)dataPtr <  BM_DATA_PTR_MIN) || ((u32)dataPtr >  BM_DATA_PTR_MAX))
+		return rc;
+
+	bm_register_name_get(base_address, offset, reg_name);
+	pr_info("[QM-BM] WROTE_REG add = 0x%08X : name = %s : value =", base_address, reg_name);
+	temp = dataPtr;
+	for (i = 0; i < wordsNumber; i++) {
+		pr_info(" 0x%08X", *(u32 *)temp);
+		temp++;
+	}
+	pr_info("\n");
+
+/*	pr_info(" DUMMY_PRINT, result=%d\n", *(u32 *)dataPtr);*/
+/*	pr_info(" DUMMY_PRINT, result = 0x%08X\n", *(u32 *)dataPtr);*/
+/*	pr_info(" DUMMY_PRINT write by function <%s>, result = 0x%08X\n", __func__, *(u32 *)dataPtr);*/
+
+/*	return OK;	 */
+/*
+	rc = mv_pp3_hw_write(base_address+offset, wordsNumber, dataPtr);
+	if (rc != OK)
+		return rc;
+*/
+
+	COMPLETE_HW_WRITE
+	rc = OK;
+	return rc;
+}
+#else
+int bm_register_read(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+
+	if ((base_address <   BM_ADDRESS_MIN) || (base_address >   BM_ADDRESS_MAX))
+		return rc;
+	if ((offset       <    BM_OFFSET_MIN) || (offset       >    BM_OFFSET_MAX))
+		return rc;
+	if ((wordsNumber  < BM_DATA_SIZE_MIN) || (wordsNumber  > BM_DATA_SIZE_MAX))
+		return rc;
+	if (((u32)dataPtr <  BM_DATA_PTR_MIN) || ((u32)dataPtr >  BM_DATA_PTR_MAX))
+		return rc;
+
+	/*rc = */
+	mv_pp3_hw_read(base_address+offset, wordsNumber, dataPtr);
+	if (rc != OK)
+		return rc;
+
+	COMPLETE_HW_WRITE
+	rc = OK;
+	return rc;
+}
+
+int bm_register_write(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr)
+{
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+
+	if ((base_address <   BM_ADDRESS_MIN) || (base_address >   BM_ADDRESS_MAX))
+		return rc;
+	if ((offset       <    BM_OFFSET_MIN) || (offset       >    BM_OFFSET_MAX))
+		return rc;
+	if ((wordsNumber  < BM_DATA_SIZE_MIN) || (wordsNumber  > BM_DATA_SIZE_MAX))
+		return rc;
+	if (((u32)dataPtr <  BM_DATA_PTR_MIN) || ((u32)dataPtr >  BM_DATA_PTR_MAX))
+		return rc;
+
+	/*rc = */
+	mv_pp3_hw_write(base_address+offset, wordsNumber, dataPtr);
+	if (rc != OK)
+		return rc;
+
+	COMPLETE_HW_WRITE
+	rc = OK;
+	return rc;
+}
+#endif
+
+void bm_register_register_fields_print(u32 base_address, u32 value)
+{
+
+}
+#ifdef MY_HIDE_DEBUG
+#endif /* MY_HIDE_DEBUG */
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h
new file mode 100644
index 0000000..47132b1
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h
@@ -0,0 +1,759 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef	__MV_BM_H__
+#define	__MV_BM_H__
+
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+
+/* Error Codes */
+#define BM_WRONG_MEMORY_TYPE           -EINVAL
+#define BM_BANK_NOT_IN_RANGE           -EINVAL
+#define BM_ATTR_CHANGE_AFTER_BM_ENABLE -EINVAL
+#define BM_CHANGE_AFTER_BM_ENABLE      -EINVAL
+#define BM_ALIAS_ERROR                 -EINVAL
+#define BM_INPUT_NOT_IN_RANGE          -EDOM
+
+/* Input definitions */
+#define BM_NUMBER_OF_BANKS_QM			(BM_BANK_QP_MAX - BM_BANK_QP_MIN + 1)
+#define BM_NUMBER_OF_BANKS_GP			(BM_BANK_GP_MAX - BM_BANK_GP_MIN + 1)
+#define BM_NUMBER_OF_BANKS				(BM_BANK_MAX    - BM_BANK_MIN    + 1)
+
+#define BM_NUMBER_OF_POOLS_QM			(BM_POOL_QM_MAX - BM_POOL_QM_MIN + 1)
+#define BM_NUMBER_OF_POOLS_GP			(BM_POOL_GP_MAX - BM_POOL_GP_MIN + 1)
+#define BM_NUMBER_OF_POOLS				(BM_POOL_MAX    - BM_POOL_MIN    + 1)
+
+#define BM_NUM_OF_LINE_QM				       512
+#define BM_NUM_OF_LINE_GP				      1024
+
+#define GRANULARITY_OF_64_BYTES			        64
+#define GRANULARITY_OF_16				        16
+/*
+#define GRANULARITY_OF_64				        64
+*/
+
+#define QM_PE_SIZE_IN_BYTES				         4
+#define QM_PE_SIZE_IN_BYTES_IN_DRAM		QM_PE_SIZE_IN_BYTES
+#define QM_PE_SIZE_IN_BYTES_IN_CACHE	QM_PE_SIZE_IN_BYTES
+#define GP_PE_SIZE_OF_32_BITS_IN_BYTES_IN_DRAM   4
+#define GP_PE_SIZE_OF_40_BITS_IN_BYTES_IN_DRAM   8
+#define GP_PE_SIZE_IN_BYTES_IN_CACHE	         8
+/*
+#define PE_SIZE_OF_32_BITS_IN_BYTES		         4
+#define PE_SIZE_OF_40_BITS_IN_BYTES		         8
+#define GP_PE_SIZE 32
+#define PE_SIZE 1 / * for pe = 22 bits or pe = 32 bits * /
+#define PE_SIZE 2 / * for pe = 40 bits * /
+#define BM_PE_SIZE_IS_4_BYTES			         4
+#define BM_PE_SIZE_IS_8_BYTES			         8
+#define BM_GRANULARITY_OF_16_PE			(16*PE_SIZE)
+*/
+
+#define BM_BUFFER_SIZE_P2				      1024
+#define BM_BUFFER_SIZE_P3				        16
+
+/* Default values */
+#define BM_PE_SIZE_IS_32_BITS			         1
+#define BM_PE_SIZE_IS_40_BITS			         0
+#define BM_PE_SIZE_DEF					BM_PE_SIZE_IS_32_BITS	/* 0 - 40 bits, 1 - 32 bits */
+#define BM_POOL_PAIR_GP_DEF				         0	/* 0 -   false, 1 -    true */
+
+#define BM_AE_THR_DEF TRUNCATE((num_of_buffers * 1/4), GRANULARITY_OF_16) /*
+#define BM_AE_THR_DEF \
+	(((num_of_buffers * 1/4) + (GRANULARITY_OF_16-1))&(0xFFFFFFF0))
+	Almost empty default threshold is  of num_of_buffers truncated to multiplication of 16,
+		otherwise the range is 0 or 16 to num_of_buffers-32 */
+#define BM_AF_THR_DEF TRUNCATE((num_of_buffers * 3/4), GRANULARITY_OF_16) /*
+#define BM_AF_THR_DEF \
+	(((num_of_buffers * 3/4) + (GRANULARITY_OF_16-1))&(0xFFFFFFF0))
+	Almost full  default threshold is  of num_of_buffers rounded   to multiplication of 16,
+		otherwise the range is 0 or 32 to num_of_buffers-16 */
+#define BM_CACHE_VMID_DEF                        0
+#define BM_CACHE_ATTR_DEF                        1
+
+#define BM_CACHE_SI_THR_QM_DEF                 448
+#define BM_CACHE_SO_THR_QM_DEF                 480
+#define BM_CACHE_NUM_OF_BUFFERS_QM_DEF         512
+
+#define BM_CACHE_SI_THR_GP_BIG_DEF             304
+#define BM_CACHE_SO_THR_GP_BIG_DEF             336
+#define BM_CACHE_NUM_OF_BUFFERS_GP_BIG_DEF     352
+
+#define BM_CACHE_SI_THR_GP_SMALL_DEF            80
+#define BM_CACHE_SO_THR_GP_SMALL_DEF            96
+#define BM_CACHE_NUM_OF_BUFFERS_GP_SMALL_DEF   112
+
+/* Range Definitions */
+#define BM_BANK_QM_MIN				         0
+#define BM_BANK_QM_MAX				         0
+#define BM_BANK_GP_MIN				         1
+#define BM_BANK_GP_MAX				         4
+#define BM_BANK_MIN					BM_BANK_QM_MIN
+#define BM_BANK_MAX					BM_BANK_GP_MAX
+
+#define BM_POOL_QM_MIN				         0
+#define BM_POOL_QM_MAX				         3
+#define BM_POOL_GP_MIN				         8
+#define BM_POOL_GP_MAX				        35
+#define BM_POOL_MIN					BM_POOL_QM_MIN
+#define BM_POOL_MAX					BM_POOL_GP_MAX
+
+#define BM_GLOBAL_POOL_IDX_QM_MIN	         0
+#define BM_GLOBAL_POOL_IDX_QM_MAX	         3
+#define BM_GLOBAL_POOL_IDX_GP_MIN	         4
+#define BM_GLOBAL_POOL_IDX_GP_MAX	        31
+#define BM_GLOBAL_POOL_IDX_MIN		BM_GLOBAL_POOL_IDX_QM_MIN
+#define BM_GLOBAL_POOL_IDX_MAX		BM_GLOBAL_POOL_IDX_GP_MAX
+
+#define BM_PID_LOCAL_QM_MIN			         0
+#define BM_PID_LOCAL_QM_MAX			         3
+#define BM_PID_LOCAL_GP_MIN			         0
+#define BM_PID_LOCAL_GP_MAX			         6
+#define BM_PID_LOCAL_MIN			BM_PID_LOCAL_QM_MIN
+#define BM_PID_LOCAL_MAX			BM_PID_LOCAL_GP_MAX
+
+#define BM_ACACHE_MIN				0x00000020	/*  32 */
+#define BM_ACACHE_MAX				0x0000007F	/* 127 */
+#define BM_ADOMAIN_MIN				         0
+#define BM_ADOMAIN_MAX				0x00000003	/*   3 */
+#define BM_AQOS_MIN					         0
+#define BM_AQOS_MAX					0x00000003	/*   3 */
+
+/* #define BM_BUFFERS_MIN				0x00000030 */	/*  48 */
+#define BM_NUM_OF_BUFFERS_QM_MIN			0x00000030	/*  48 */
+#define BM_NUM_OF_BUFFERS_QM_GPM_MAX		(0x00001400 - 16)	/* 5120 - 16 for P0 & P1 */
+#define BM_NUM_OF_BUFFERS_QM_DRAM_MAX		(0x00400000 - 16)	/*   4M - 16 for P2 & P3 */
+#define BM_NUM_OF_BUFFERS_QM_MAX \
+			MV_MAX(BM_NUM_OF_BUFFERS_QM_GPM_MAX, BM_NUM_OF_BUFFERS_QM_DRAM_MAX)
+#define BM_NUM_OF_BUFFERS_GP_MIN			0x00000030	/*  48 */
+#define BM_NUM_OF_BUFFERS_GP_MAX			(0x00200000 - 16)	/*  2M - 16 */
+/* #define BM_NUM_OF_BUFFERS_MAX				MV_MAX(BM_BUFFERS_QM_MAX, BM_BUFFERS_GP_MAX) */
+#define BM_CACHE_NUM_OF_BUFFERS_MIN			0x00000030	/*  48 */
+#define BM_CACHE_NUM_OF_BUFFERS_QM_MIN		BM_CACHE_NUM_OF_BUFFERS_MIN
+#define BM_CACHE_NUM_OF_BUFFERS_QM_MAX		(0x00000800 - (4-1)*BM_CACHE_NUM_OF_BUFFERS_QM_MIN) /*
+	the sum for bank 0 is up to 2048, then for one pool it is 2048-3*48   */
+#define BM_CACHE_NUM_OF_BUFFERS_GP_MIN		BM_CACHE_NUM_OF_BUFFERS_MIN
+#define BM_CACHE_NUM_OF_BUFFERS_GP_MAX		(0x00000400 - 8)	/* 1024-8 */
+/* #define BM_CACHE_BUFFERS_MAX		MV_MAX(BM_CACHE_BUFFERS_QM_MAX, BM_CACHE_BUFFERS_GP_MAX) */
+#define BM_FILL_LEVEL_MIN			         0
+#define BM_FILL_LEVEL_MAX			num_of_buffers
+#define BM_ADDRESS_MIN				         0
+#define BM_ADDRESS_MAX				0xFFFFFFFF
+#define BM_QUICK_INIT_MIN			         0
+#define BM_QUICK_INIT_MAX			0x00000001
+#define BM_POOL_PAIR_MIN			         0
+#define BM_POOL_PAIR_MAX			0x00000001
+#define BM_PE_SIZE_MIN				0x00000001
+#define BM_PE_SIZE_MAX				0x00000001
+#define BM_VMID_MIN					         0
+#define BM_VMID_MAX					0x0000003F	/*  63 */
+#define BM_CACHE_VMID_MIN			         0
+#define BM_CACHE_VMID_MAX			0x0000003F	/*  63 */
+#define BM_CACHE_ATTR_MIN			         0
+#define BM_CACHE_ATTR_MAX			0x000000FF	/* 255 */
+#define BM_AE_THR_MIN				MV_MIN(0x00000010, num_of_buffers) /*
+	16                unless number of buffers is 0 and then it is also 0 */
+#define BM_AE_THR_MAX				MV_MAX((num_of_buffers - 0x00000020), 0) /*
+	num_of_buffers-32 unless number of buffers is 0 and then it is also 0 */
+#define BM_AF_THR_MIN				MV_MIN(0x00000020, num_of_buffers) /*
+	32                unless number of buffers is 0 and then it is also 0 */
+#define BM_AF_THR_MAX				MV_MAX((num_of_buffers - 0x00000010), 0) /*
+	num_of_buffers-16 unless number of buffers is 0 and then it is also 0 */
+#define BM_CACHE_SI_THR_MIN			0x00000010	/*  16 */
+#define BM_CACHE_SI_THR_MAX			(cache_num_of_buffers - 0x00000010)	/* cache_num_of_buffers - 16 */
+#define BM_CACHE_SO_THR_MIN			0x00000018	/*  24 */
+#define BM_CACHE_SO_THR_MAX			(cache_num_of_buffers - 0x00000008)	/* cache_num_of_buffers -  8 */
+#define BM_CACHE_END_MIN			0x00000020	/*  32 */
+#define BM_CACHE_END_MAX			0x0000007F	/* 127 */
+
+#define BM_START_MIN				         0
+#define BM_START_MAX				0xFFFFFFFF
+#define BM_OFFSET_MIN				         0
+#define BM_OFFSET_MAX				0xFFFFFFFF
+#define BM_DATA_SIZE_MIN			         0
+#define BM_DATA_SIZE_MAX			0xFFFFFFFF
+#define BM_DRAM_ADDRESS_LO_MIN		         0
+#define BM_DRAM_ADDRESS_LO_MAX		0xFFFFFFFF
+#define BM_DRAM_ADDRESS_HI_MIN		         0
+#define BM_DRAM_ADDRESS_HI_MAX		0xFFFFFFFF
+
+#define BM_DATA_PTR_MIN				         0
+#define BM_DATA_PTR_MAX				0xFFFFFFFF
+
+/*
+#define BM_QM_BUFFERS_MIN			48
+#define BM_GP_BUFFERS_MIN			48 (but can also be 0)
+
+#define BM_AE_THR_QM_MIN			16
+#define BM_AE_THR_GP_MIN			16 (unless number of buffers is 0 and then it is also 0)
+#define BM_AE_THR_QM_MAX			(num_of_buffers-32)
+#define BM_AE_THR_GP_MAX			(num_of_buffers-32) (unless number of buffers is
+										0 and then it is also 0)
+#define BM_AF_THR_QM_MIN			32
+#define BM_AF_THR_GP_MIN			32 (unless number of buffers is 0 and then it is 0)
+#define BM_AF_THR_QM_MAX			(num_of_buffers-16)
+#define BM_AF_THR_GP_MAX			(num_of_buffers-16)	(unless number of buffers is
+										0 and then it is also 0)
+
+#define BM_QM_BUFFERS_CACHE_MIN		32
+#define BM_GP_BUFFERS_CACHE_MIN		32
+#define BM_GP_BUFFERS_CACHE_MAX		1024 (if there is one pool then it is (1024-8)=1016
+
+#define BM_QM_SI_THR_MIN			8
+#define BM_GP_SI_THR_MIN			8
+#define BM_QM_SI_THR_MAX			cache_num_of_buffers - 16
+#define BM_GP_SI_THR_MAX			cache_num_of_buffers - 16
+#define BM_QM_SO_THR_MIN			24
+#define BM_GP_SO_THR_MIN			24
+#define BM_QM_SO_THR_MAX			cache_num_of_buffers - 8
+#define BM_GP_SO_THR_MAX			cache_num_of_buffers - 8
+
+#define BM_END_MIN					32
+*/
+
+/*
+#define BM_PID_TO_BANK(_pid)                \
+{									        \
+	_bid =                                  \
+	(((_pid >= 0) && (_pid   <=  7)) ?	0 :	\
+	(((_pid >= 8) && (_pid%4 ==  0)) ?	1 :	\
+	(((_pid >= 8) && (_pid%4 ==  1)) ?	2 :	\
+	(((_pid >= 8) && (_pid%4 ==  2)) ?	3 :	\
+	(((_pid >= 8) && (_pid%4 ==  3)) ?	4 :	\
+	-1)))))                                 \
+	if ((_bid >= 0) && (_bid <= 4))         \
+		return _bid;                        \
+	else                                    \
+		return EDOM;                        \
+}
+*/
+
+#define BM_PID_TO_BANK(_pid)                \
+	(((_pid >= 0) && (_pid   <=  3)) ?	0 :	\
+	(((_pid >= 8) && (_pid%4 ==  0)) ?	1 :	\
+	(((_pid >= 8) && (_pid%4 ==  1)) ?	2 :	\
+	(((_pid >= 8) && (_pid%4 ==  2)) ?	3 :	\
+	(((_pid >= 8) && (_pid%4 ==  3)) ?	4 :	\
+	-1)))))
+
+#define BM_PID_TO_PID_LOCAL(_pid)                    \
+	(((_pid >= 0) && (_pid   <=  3)) ?  _pid       : \
+	(((_pid >= 8) && (_pid   <= 35)) ? (_pid-8)>>2 : \
+	-1))
+
+#define BM_PID_TO_GLOBAL_POOL_IDX(_pid)              \
+	(((_pid >= 0) && (_pid   <=  3)) ?  _pid       : \
+	(((_pid >= 8) && (_pid   <= 35)) ? (_pid-4)    : \
+	-1))
+
+#define BM_GLOBAL_POOL_IDX_TO_PID(_pid)              \
+	(((_pid >= 0) && (_pid   <=  3)) ?  _pid       : \
+	(((_pid >= 4) && (_pid   <= 31)) ? (_pid+4)    : \
+	-1))
+
+/*
+#define BM_MAGIC 0x24051974
+
+#define  DECLARE_BM_CTL_PTR(name, value)	{struct  bm_ctl *name = (struct  bm_ctl *)value; }
+
+#define CHECK_BM_CTL_PTR(ptr)		\
+{									\
+	if (!ptr)						\
+		return -EINVAL;				\
+	if (ptr->magic !=  BM_MAGIC)	\
+		return -EBADF;				\
+}
+
+#define  BM_CTL(name, handle)    {DECLARE_BM_CTL_PTR(name, handle);  CHECK_BM_CTL_PTR(name); }
+#define  BM_ENV(var) (var->hEnv)
+*/
+
+#define TRUNCATE(_truncated_value, _truncating_value) (_truncated_value - (_truncated_value % _truncating_value))
+
+#define BM_QM_PE_UNITS_TO_BYTES(_num_of_buffers) (_num_of_buffers * 4)
+#define BM_GP_PE_UNITS_TO_BYTES(_num_of_buffers, _pe_size)	\
+				(((_pe_size) == (40)) ? (_num_of_buffers * 8) : (_num_of_buffers * 4))
+/*
+#define BM_GP_POOL_DRAM_SIZE_IN_BYTES(_num_of_buffers, _pe_size)
+	if (_pe_size==32) (_num_of_buffers * 4)
+	if (_pe_size==40) (_num_of_buffers * 8)
+#if (_pe_size==32) (_num_of_buffers * 4)
+#if (_pe_size==40) (_num_of_buffers * 8)
+#define MIN(a,b) (((a)<(b))?(a):(b))
+
+#define CHECK_BM_CTL_PTR(ptr)		\
+{									\
+	if (!ptr)						\
+		return -EINVAL;				\
+	if (ptr->magic !=  BM_MAGIC)	\
+		return -EBADF;				\
+}
+*/
+
+/*
+typedef void * bm_handle;
+*/
+
+/**
+ *  Initialize BM module
+ *  Return values:
+ *		0 - success
+ */
+int bm_open(void);
+
+/**
+ *  Global functions, configures BM attributes for read/write in DRAM
+ *  configures all 12 attributes with default values
+ *  Return values:
+ *		0 - success
+ */
+int bm_attr_all_pools_def_set(void);
+
+/**
+ *  Global functions, configures BM attributes for read/write in DRAM
+ *  configures attributes for 4 pools of QM
+ *  Return values:
+ *		0 - success
+ */
+int bm_attr_qm_pool_set(u32 arDomain, u32 awDomain, u32 arCache, u32 awCache, u32 arQOS, u32 awQOS);
+
+/**
+ *  Global functions, configures BM attributes for read/write in DRAM
+ *  configures attributes for general purpose pools (8-35)
+ *  Return values:
+ *		0 - success
+ */
+int bm_attr_gp_pool_set(u32 arDomain, u32 awDomain, u32 arCache, u32 awCache, u32 arQOS, u32 awQOS);
+
+/**
+ *  Get BM enable status
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_enable_status_get(u32 *bm_req_rcv_en);
+
+/**
+ *  Initiates of GPM pools with default values
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_qm_gpm_pools_def_quick_init(u32 num_of_buffers, u32 *qece_base_address, u32 *pl_base_address);
+
+/**
+ *  Initiates of DRAM pools with default values
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_qm_dram_pools_def_quick_init(u32 num_of_buffers, u32 *qece_base_address, u32 *pl_base_address);
+
+/**
+ *  Initiates QM GPM pools
+ *	Configures BM for pool initialization and enables the pool.  Doesn't configure cache parameters.
+ *  This function is a super set of several bm function that are listed below
+ *  Note: No change can be made to pool after this function is called.
+ *  Return values:
+ *		0 - success
+ */
+int bm_qm_gpm_pools_quick_init(u32 num_of_buffers, u32 *qece_base_address,
+				u32 *pl_base_address, u32 ae_thr, u32 af_thr,
+				u32 cache_vmid, u32 cache_attr, u32 cache_so_thr, u32 cache_si_thr,
+				u32 cache_num_of_buffers);
+
+/**
+ *  Initiates QM DRAM pools
+ *	Configures BM for pool initialization and enables the pool.  Doesn't configure cache parameters.
+ *  This function is a super set of several bm function that are listed below
+ *  Note: No change can be made to pool after this function is called.
+ *  Return values:
+ *		0 - success
+ */
+int bm_qm_dram_pools_quick_init(u32 num_of_buffers, u32 *qece_base_address,
+					u32 *pl_base_address, u32 ae_thr, u32 af_thr,
+					u32 cache_vmid, u32 cache_attr, u32 cache_so_thr, u32 cache_si_thr,
+					u32 cache_num_of_buffers);
+
+/**
+ *  Get pool quick init status - to get indication if quick init is completed
+ *  and client can start allocate/release from pool
+ *  Return values:
+ *		0 - success
+ */
+int bm_pool_quick_init_status_get(
+		u32 pool, /* all pools, QM and General purpose. Range 0 to 3 and 8 to 35 */
+		u32 *completed); /*	1 - quick init completed,
+							0 - still in quick init process */
+
+/**
+ *  Basic initialization of general purpose pools with default values
+ *  Return values:
+ *		0 - success
+ */
+int bm_gp_pool_def_basic_init(
+							u32 pool, /* pool number: general purpose pools 8 to 35 */
+							u32 num_of_buffers, /* equal or less
+								than num_of_buffers passed when initializing pool */
+							u32 *base_address,  /* DRAM base address */
+							u32 partition_model);  /* for small partition in cache */
+
+/**
+ *  Basic initialization of general purpose pools
+ *  Return values:
+ *		0 - success
+ */
+int bm_gp_pool_basic_init(
+							u32 pool, /* pool number: general purpose pools 8 to 35 */
+							u32 num_of_buffers, /* equal or less
+								than num_of_buffers passed when initializing pool */
+							u32 *base_address,  /* DRAM base address */
+							u32 pe_size, /* PE size can be either 32bits or 40 bits */
+							u32 pool_pair, /* Pool_pair is
+								either 0 for false or 1 for true */
+							u32 ae_thr, /* almost empty threshold for pool */
+							u32 af_thr, /* almost full threshold for pool */
+							u32 cache_vmid, /* cache_vmid */
+							u32 cache_attr, /* cache_attr */
+							u32 cache_so_thr, /* cache_so_thr */
+							u32 cache_si_thr, /* cache_si_thr */
+							u32 cache_num_of_buffers); /* cache_num_of_buffers */
+
+/**
+ *  Global enable for BM
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_enable(void);
+
+/**
+ *  Global disable for BM
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_disable(void);
+
+
+/**
+ *  gives fill level of pool in DRAM
+ *	Return values:
+ *		0 - success
+ */
+int bm_pool_fill_level_get(
+					u32 pool, /* pool number: any pool QM and general purpose */
+					u32 *fill_level);  /* fill level */
+
+/**
+ *  Set BM VMID
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_vmid_set(u32 bm_vmid);
+
+/**
+ *  Configure BM registers and allocate memory for pools with default values
+ *  Return values:
+ *		0 - success
+ */
+int bm_gp_pool_def_quick_init(u32 pool, u32 num_of_buffers, u32 fill_level,
+							u32 *base_address, u32 partition_model);
+
+/**
+ *  Configure BM registers and allocate memory for pools
+ *  Return values:
+ *		0 - success
+ */
+int bm_gp_pool_quick_init(u32 pool, u32 num_of_buffers, u32 fill_level, u32 *base_address,
+					u32 pe_size, u32 pool_pair, u32 ae_thr, u32 af_thr,
+					u32 cache_vmid, u32 cache_attr,	u32 cache_so_thr, u32 cache_si_thr,
+					u32 cache_num_of_buffers);
+
+
+/*BM Debug functions*/
+
+/**
+ *  Print all global registers
+ *  Return values:
+ *		0 - success
+ */
+int bm_global_registers_dump(void);
+
+/**
+ *  Print values of all BM pool registers
+ *  Return values:
+ *		0 - success
+ */
+int bm_pool_registers_dump(u32 pool);
+
+/**
+ *  Print values of all BM bank registers
+ *  Return values:
+ *		0 - success
+ */
+int bm_bank_registers_dump(u32 bank);
+
+/**
+ *  Print all 512 lines of cache per input bank sram_b0...b4_cache_mem
+ *  Return values:
+ *		0 - success
+ */
+int bm_cache_memory_dump(u32 bank);
+
+/**
+ *  Read BM idle status
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_idle_status_get(u32 *status);
+
+/**
+ *  Get status per pool: almost full, almost empty and pool in cache is not empty
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_pool_status_get(u32 pool, u32 *pool_nempty, u32 *dpool_ae, u32 *dpool_af);
+
+/**
+ *  Print several registers status that gives indication why BM is busy
+ *  This funciton is useful to call if BM is not reaching idle after a long time.
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_idle_debug(void);
+
+/**
+ *  Check error bits If set to 1, and print the error that occurred.
+ *  Bit 0 is always an OR of all the other errors.
+ *  So bit 0 with value 0 indicates there are no errors.
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_error_dump(void);
+
+/*BM Internal functions*/
+/**
+ *  Fill memory of pool with PE index
+ *	PE index is incrementing value of 1 to num_of_buffers
+ *  Mark PE with its location (GPM or DRAM)
+ *  Return values:
+ *		0 - success
+ */
+int bm_pool_memory_fill(
+						u32 pool, /* pool number: 0 to 3 */
+						u32 num_of_buffers, /* equal or less
+						than num_of_buffers passed when initializing pool */
+						u32 *base_address); /* pool base address.
+						same as the address passed when initializing pool */
+
+/**
+ *  Configure BM with Fill level of pool in DRAM
+ *  Note: Must be called before pool is enabled
+ *  Return values:
+ *		0 - success
+ */
+int bm_pool_dram_set(
+					u32 pool, /* pool number: any pool QM and general purpose */
+					u32 num_of_buffers,  /* number of buffers/PEs in pool*/
+					u32 pe_size, /* PE size can be either 32bits or 40 bits */
+					u32 *base_address, /* DRAM base address */
+					u32 ae_thr, /* almost empty threshold for pool */
+					u32 af_thr); /* almost full threshold for pool */
+
+/**
+ *  Configure BM with Fill level of pool in DRAM
+ *	Supports all pools (QM and general purpose)
+ *  Note: Must be called before pool is enabled
+ *  Return values:
+ *		0 - success
+ */
+int bm_pool_fill_level_set(
+					u32 pool, /* pool number: any pool QM and general purpose */
+					u32 num_of_buffers, /* number of buffers/PEs in pool */
+					u32 pe_size, /* PE size can be either 32bits or 40 bits */
+					u32 quick_init);  /* configures fill level relevant
+									  only when pool is in quick init mode */
+
+/**
+ *  Enables BM pool
+ *
+ *  Note: Must be called after all other pool related configuration is complete
+ *  Return values:
+ *		0 - success
+ */
+int bm_pool_enable(
+					u32 pool, /* pool number: any pool QM and general purpose */
+					u32 quick_init); /* 1- enable quick init of pool,
+										0 - disable quick init of pool */
+
+/**
+ *  Set PE pointer size in general purpose pool
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_gp_pool_pe_size_set(
+							u32 pool, /* pool number:
+						general purpose pools range: 8 to 35 */
+							u32 pe_size); /* PE size can be either 32bits or 40 bits */
+
+/**
+ *  Configure if pool is defined to work in pairs
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_gp_pool_pair_set(
+					u32 pool, /* pool number: general purpose pools range: 8 to 35 */
+					u32 pool_pair); /* Pool_pair is either 0 for false or 1 for true */
+
+/**
+ *  Configure pool cache parameters
+ *
+ *  Note: Must be called before pool is enabled
+ *  Return values:
+ *		0 - success
+ */
+int bm_pool_cache_set(
+						u32 pool, /* pool number: any pool QM and general purpose.
+								  range 0 to 3 and 8 to 35 */
+						u32 cache_vmid,
+						u32 cache_attr,
+						u32 cache_so_thr,
+						u32 cache_si_thr,
+						u32 cache_num_of_buffers);
+
+/**
+ *  Set Pool to disable - TBD
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_pool_disable(u32 pool);
+
+/**
+ * access_addr - absolute address: Silicon base + unit base + register offset
+ * return register value
+ */
+/*static INLINE
+int mv_pp3_hw_reg_read(u32 access_addr);
+*/
+/**
+ * access_addr - absolute address: Silicon base + unit base + register offset
+ * write data to register
+ */
+/*static INLINE
+int mv_pp3_hw_reg_write(u32 access_addr, u32 data);
+*/
+/**
+ *  Read register from BM units
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_register_read(
+					u32 base_address, /* register address as appears in CIDER */
+					u32 offset,       /* offset from this address */
+					u32 wordsNumber,  /* how many words (32bits) to read */
+					u32 *dataPtr);    /* returning data. It is the user responsibility
+								that dataPtr points to wordsNumber words */
+
+/**
+ *  Write register in BM units
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_register_write(
+					u32 base_address, /* register address as appears in CIDER */
+					u32 offset,       /* offset from this address */
+					u32 wordsNumber,  /* how many words (32bits) to read */
+					u32 *dataPtr);    /* Data to write. It is the user responsibility
+									that dataPtr points to wordsNumber words */
+
+
+/**
+ *  Print per pool several registers which are helpful for advanced debugging
+ *
+ *  Return values:
+ *		0 - success
+int bm_per_pool_advanced_debug(u32 pool, u32 line);
+ */
+
+/**
+ *  Print TBD
+ *
+ *  Return values:
+ *		0 - success
+int bm_debug(void);
+ */
+
+#endif /* MV_BM_H */
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.c b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.c
new file mode 100644
index 0000000..764ffc4
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.c
@@ -0,0 +1,560 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+/* includes */
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+#include "bm/mv_bm_regs.h"
+
+struct bm_alias bm;
+struct bm_alias bm_reg_size;
+struct bm_alias bm_reg_offset;
+
+/*
+*/
+
+int bm_reg_address_alias_init(void)
+{
+	int rc = -BM_ALIAS_ERROR;
+	u32 bid;
+	u32 siliconBase;
+
+	siliconBase = mv_hw_silicon_base_addr_get();
+
+	bm.base = siliconBase + QM_UNIT_OFFSET + BM_UNIT_OFFSET;	/*0x004D0000*/
+
+	for (bid = 0; bid < 5; bid++) {
+		if (bid == 0) {
+			bm.b_pool_n_conf[bid]             = bm.base + 0x00008000;
+			bm.b_pool_n_st[bid]               = bm.base + 0x00008004;
+			bm.b_sys_rec_bank_intr_cause[bid] = bm.base + 0x000090A0;
+			bm.b_sys_rec_bank_intr_mask[bid]  = bm.base + 0x000090A4;
+			bm.b_sys_rec_bank_d0_st[bid]      = bm.base + 0x000090B0;
+			bm.b_sys_rec_bank_d1_st[bid]      = bm.base + 0x000090B4;
+		} else if ((bid > 0) && (bid < 5)) {
+			bm.b_pool_n_conf[bid]             = bm.base + 0x00008040 + (bid-1)*0x0200;
+			bm.b_pool_n_st[bid]               = bm.base + 0x00008044 + (bid-1)*0x0200;
+			bm.b_sys_rec_bank_intr_cause[bid] = bm.base + 0x000090D0 + (bid-1)*0x0030;
+			bm.b_sys_rec_bank_intr_mask[bid]  = bm.base + 0x000090D4 + (bid-1)*0x0030;
+			bm.b_sys_rec_bank_d0_st[bid]      = bm.base + 0x000090E0 + (bid-1)*0x0030;
+			bm.b_sys_rec_bank_d1_st[bid]      = bm.base + 0x000090E4 + (bid-1)*0x0030;
+		} else {
+			rc = -BM_BANK_NOT_IN_RANGE;
+			return rc;
+		}
+	}
+
+	bm.sw_debug_rec_intr_cause    = bm.base + 0x00009190;
+	bm.sw_debug_rec_intr_mask     = bm.base + 0x00009194;
+	bm.sys_nrec_common_intr_cause = bm.base + 0x000091A0;
+	bm.sys_nrec_common_intr_mask  = bm.base + 0x000091A4;
+	bm.sys_nrec_common_d0_st      = bm.base + 0x000091B0;
+	bm.sys_nrec_common_d1_st      = bm.base + 0x000091B4;
+	bm.sys_nrec_common_d2_st      = bm.base + 0x000091B8;
+	bm.sys_nrec_common_d3_st      = bm.base + 0x000091BC;
+	bm.common_general_conf        = bm.base + 0x00009300;
+	bm.dram_domain_conf           = bm.base + 0x00009304;
+	bm.dram_cache_conf            = bm.base + 0x00009308;
+	bm.dram_qos_conf              = bm.base + 0x0000930C;
+	bm.error_intr_cause           = bm.base + 0x0000A000;
+	bm.error_intr_mask            = bm.base + 0x0000A004;
+	bm.func_intr_cause            = bm.base + 0x0000A010;
+	bm.func_intr_mask             = bm.base + 0x0000A014;
+	bm.ecc_err_intr_cause         = bm.base + 0x0000A020;
+	bm.ecc_err_intr_mask          = bm.base + 0x0000A024;
+
+	for (bid = 0; bid < 5; bid++) {
+		if (bid == 0) {
+			bm.pool_nempty_intr_cause[bid] = bm.base + 0x0000A040;
+			bm.pool_nempty_intr_mask[bid]  = bm.base + 0x0000A044;
+			bm.dpool_ae_intr_cause[bid]    = bm.base + 0x0000A048;
+			bm.dpool_ae_intr_mask[bid]     = bm.base + 0x0000A04C;
+			bm.dpool_af_intr_cause[bid]    = bm.base + 0x0000A050;
+			bm.dpool_af_intr_mask[bid]     = bm.base + 0x0000A054;
+		} else if ((bid > 0) && (bid < 5)) {
+			bm.pool_nempty_intr_cause[bid] = bm.base + 0x0000A060 + (bid-1)*0x0010;
+			bm.pool_nempty_intr_mask[bid]  = bm.base + 0x0000A064 + (bid-1)*0x0010;
+			bm.dpool_ae_intr_cause[bid]    = bm.base + 0x0000A0A0 + (bid-1)*0x0010;
+			bm.dpool_ae_intr_mask[bid]     = bm.base + 0x0000A0A4 + (bid-1)*0x0010;
+			bm.dpool_af_intr_cause[bid]    = bm.base + 0x0000A0E0 + (bid-1)*0x0010;
+			bm.dpool_af_intr_mask[bid]     = bm.base + 0x0000A0E4 + (bid-1)*0x0010;
+		} else {
+			rc = -BM_BANK_NOT_IN_RANGE;
+			return rc;
+		}
+	}
+
+	bm.b_bank_req_fifos_st         = bm.base + 0x0000A200;
+	bm.b0_past_alc_fifos_st        = bm.base + 0x0000A220;
+	bm.bgp_past_alc_fifos_st       = bm.base + 0x0000A224;
+	bm.b0_rls_wrp_ppe_fifos_st     = bm.base + 0x0000A230;
+	bm.dm_axi_fifos_st             = bm.base + 0x0000A240;
+	bm.drm_pend_fifo_st            = bm.base + 0x0000A244;
+	bm.dm_axi_wr_pend_fifo_st      = bm.base + 0x0000A248;
+	bm.bm_idle_st                  = bm.base + 0x0000A250;
+
+	for (bid = 0; bid < 5; bid++) {
+		bm.dpr_c_mng_stat[bid]  = bm.base + 0x00000000 + (bid-0)*0x0400;
+		bm.tpr_c_mng_b_dyn[bid] = bm.base + 0x00001400 + (bid-0)*0x0200;
+		bm.tpr_ctrs_0_b[bid]    = bm.base + 0x00005000 + (bid-0)*0x0400;
+		bm.sram_b_cache[bid]    = bm.base + 0x00010000 + (bid-0)*0x4000;
+	}
+
+	bm.dpr_d_mng_ball_stat         = bm.base + 0x00002000;
+	bm.tpr_dro_mng_ball_dyn        = bm.base + 0x00004000;
+	bm.tpr_drw_mng_ball_dyn        = bm.base + 0x00004800;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_reg_size_alias_init(void)
+{
+	int rc = -BM_ALIAS_ERROR;
+	u32 bid, word_size_in_bits, byte_size_in_bits = 8;
+
+	word_size_in_bits = 32/byte_size_in_bits;	/* word_size_in_bits = 4 */
+
+	/*memset(&bm_reg_size,0,sizeof(bm_reg_size));*/
+
+	for (bid = 0; bid < 5; bid++) {
+		bm_reg_size.b_pool_n_conf[bid]             = 32/byte_size_in_bits/word_size_in_bits;
+		bm_reg_size.b_pool_n_st[bid]               = 32/byte_size_in_bits/word_size_in_bits;
+		bm_reg_size.b_sys_rec_bank_intr_cause[bid] = 32/byte_size_in_bits/word_size_in_bits;
+		bm_reg_size.b_sys_rec_bank_intr_mask[bid]  = 32/byte_size_in_bits/word_size_in_bits;
+		bm_reg_size.b_sys_rec_bank_d0_st[bid]      = 32/byte_size_in_bits/word_size_in_bits;
+		bm_reg_size.b_sys_rec_bank_d1_st[bid]      = 32/byte_size_in_bits/word_size_in_bits;
+	}
+
+	bm_reg_size.sw_debug_rec_intr_cause    = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.sw_debug_rec_intr_mask     = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.sys_nrec_common_intr_cause = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.sys_nrec_common_intr_mask  = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.sys_nrec_common_d0_st      = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.sys_nrec_common_d1_st      = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.sys_nrec_common_d2_st      = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.sys_nrec_common_d3_st      = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.common_general_conf        = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.dram_domain_conf           = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.dram_cache_conf            = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.dram_qos_conf              = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.error_intr_cause           = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.error_intr_mask            = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.func_intr_cause            = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.func_intr_mask             = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.ecc_err_intr_cause         = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.ecc_err_intr_mask          = 32/byte_size_in_bits/word_size_in_bits;
+
+	for (bid = 0; bid < 5; bid++) {
+		bm_reg_size.pool_nempty_intr_cause[bid] = 32/byte_size_in_bits/word_size_in_bits;
+		bm_reg_size.pool_nempty_intr_mask[bid]  = 32/byte_size_in_bits/word_size_in_bits;
+		bm_reg_size.dpool_ae_intr_cause[bid]    = 32/byte_size_in_bits/word_size_in_bits;
+		bm_reg_size.dpool_ae_intr_mask[bid]     = 32/byte_size_in_bits/word_size_in_bits;
+		bm_reg_size.dpool_af_intr_cause[bid]    = 32/byte_size_in_bits/word_size_in_bits;
+		bm_reg_size.dpool_af_intr_mask[bid]     = 32/byte_size_in_bits/word_size_in_bits;
+	}
+
+	bm_reg_size.b_bank_req_fifos_st     = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.b0_past_alc_fifos_st    = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.bgp_past_alc_fifos_st   = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.b0_rls_wrp_ppe_fifos_st = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.dm_axi_fifos_st         = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.drm_pend_fifo_st        = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.dm_axi_wr_pend_fifo_st  = 32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.bm_idle_st              = 32/byte_size_in_bits/word_size_in_bits;
+
+	for (bid = 0; bid < 5; bid++) {
+		bm_reg_size.dpr_c_mng_stat[bid]  =  96/byte_size_in_bits/word_size_in_bits;
+		bm_reg_size.tpr_c_mng_b_dyn[bid] =  64/byte_size_in_bits/word_size_in_bits;
+		bm_reg_size.tpr_ctrs_0_b[bid]    = 128/byte_size_in_bits/word_size_in_bits;
+		bm_reg_size.sram_b_cache[bid]    =  64/byte_size_in_bits/word_size_in_bits;
+	}
+
+	bm_reg_size.dpr_d_mng_ball_stat  = 160/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.tpr_dro_mng_ball_dyn =  64/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.tpr_drw_mng_ball_dyn =  32/byte_size_in_bits/word_size_in_bits;
+	bm_reg_size.sram_b_cache[0]      = 128/byte_size_in_bits/word_size_in_bits;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_reg_offset_alias_init(void)
+{
+	int rc = -BM_ALIAS_ERROR;
+	u32 bid/*, word_size = 32/8*/;
+	/*memset(&bm_reg_offset,0,sizeof(bm_reg_offset));*/
+
+	for (bid = 0; bid < 5; bid++) {
+		bm_reg_offset.b_pool_n_conf[bid]             = 8;
+		bm_reg_offset.b_pool_n_st[bid]               = 8;
+		bm_reg_offset.b_sys_rec_bank_intr_cause[bid] = 0;
+		bm_reg_offset.b_sys_rec_bank_intr_mask[bid]  = 0;
+		bm_reg_offset.b_sys_rec_bank_d0_st[bid]      = 0;
+		bm_reg_offset.b_sys_rec_bank_d1_st[bid]      = 0;
+	}
+
+	bm_reg_offset.sw_debug_rec_intr_cause    = 0;
+	bm_reg_offset.sw_debug_rec_intr_mask     = 0;
+	bm_reg_offset.sys_nrec_common_intr_cause = 0;
+	bm_reg_offset.sys_nrec_common_intr_mask  = 0;
+	bm_reg_offset.sys_nrec_common_d0_st      = 0;
+	bm_reg_offset.sys_nrec_common_d1_st      = 0;
+	bm_reg_offset.sys_nrec_common_d2_st      = 0;
+	bm_reg_offset.sys_nrec_common_d3_st      = 0;
+	bm_reg_offset.common_general_conf        = 0;
+	bm_reg_offset.dram_domain_conf           = 0;
+	bm_reg_offset.dram_cache_conf            = 0;
+	bm_reg_offset.dram_qos_conf              = 0;
+	bm_reg_offset.error_intr_cause           = 0;
+	bm_reg_offset.error_intr_mask            = 0;
+	bm_reg_offset.func_intr_cause            = 0;
+	bm_reg_offset.func_intr_mask             = 0;
+	bm_reg_offset.ecc_err_intr_cause         = 0;
+	bm_reg_offset.ecc_err_intr_mask          = 0;
+
+	for (bid = 0; bid < 5; bid++) {
+		bm_reg_offset.pool_nempty_intr_cause[bid] = 0;
+		bm_reg_offset.pool_nempty_intr_mask[bid]  = 0;
+		bm_reg_offset.dpool_ae_intr_cause[bid]    = 0;
+		bm_reg_offset.dpool_ae_intr_mask[bid]     = 0;
+		bm_reg_offset.dpool_af_intr_cause[bid]    = 0;
+		bm_reg_offset.dpool_af_intr_mask[bid]     = 0;
+	}
+
+	bm_reg_offset.b_bank_req_fifos_st     = 4;
+	bm_reg_offset.b0_past_alc_fifos_st    = 0;
+	bm_reg_offset.bgp_past_alc_fifos_st   = 0;
+	bm_reg_offset.b0_rls_wrp_ppe_fifos_st = 0;
+	bm_reg_offset.dm_axi_fifos_st         = 0;
+	bm_reg_offset.drm_pend_fifo_st        = 0;
+	bm_reg_offset.dm_axi_wr_pend_fifo_st  = 0;
+	bm_reg_offset.bm_idle_st              = 0;
+
+	for (bid = 0; bid < 5; bid++) {
+		bm_reg_offset.dpr_c_mng_stat[bid]  = 16;
+		bm_reg_offset.tpr_c_mng_b_dyn[bid] =  8;
+		bm_reg_offset.tpr_ctrs_0_b[bid]    = 16;
+		bm_reg_offset.sram_b_cache[bid]    =  8;
+	}
+
+	bm_reg_offset.dpr_d_mng_ball_stat  = 32;
+	bm_reg_offset.tpr_dro_mng_ball_dyn =  8;
+	bm_reg_offset.tpr_drw_mng_ball_dyn =  4;
+	bm_reg_offset.sram_b_cache[0]      = 16;
+
+	rc = OK;
+	return rc;
+}
+
+int bm_register_name_get(u32 reg_base_address, u32 reg_offset, char *reg_name)
+{
+/*	u32 reg_size; */
+	int rc = -BM_ALIAS_ERROR;
+	u32 pid, bid, pid_local, global_pool_idx, line;
+
+	for (bid = 0; bid < 5; bid++) {
+		if (reg_base_address == bm.b_pool_n_conf[bid]) {
+			pid_local = reg_offset / bm_reg_offset.b_pool_n_conf[bid];
+			/*
+			sprintf_s(reg_name, sizeof(reg_name), "b%d_pool_%d_conf", bid, pid_local); */
+			sprintf(reg_name, "b%d_pool_%d_conf", bid, pid_local);
+			return OK;
+		} else if (reg_base_address == bm.b_pool_n_st[bid]) {
+			pid_local = reg_offset / bm_reg_offset.b_pool_n_st[bid];
+			/*
+			sprintf_s(reg_name, sizeof(reg_name), "b%d_pool_%d_st", bid, pid_local); */
+			sprintf(reg_name, "b%d_pool_%d_st", bid, pid_local);
+			return OK;
+		} else if (reg_base_address == bm.b_sys_rec_bank_intr_cause[bid]) {
+			/*
+			sprintf_s(reg_name, sizeof(reg_name), "b%d_sys_rec_bank_intr_cause", bid); */
+			sprintf(reg_name, "b%d_sys_rec_bank_intr_cause", bid);
+			return OK;
+		} else if (reg_base_address == bm.b_sys_rec_bank_intr_mask[bid]) {
+			/*
+			sprintf_s(reg_name, sizeof(reg_name), "b%_sys_rec_bank_intr_mask", bid); */
+			sprintf(reg_name, "b%d_sys_rec_bank_intr_mask", bid);
+			return OK;
+		} else if (reg_base_address == bm.b_sys_rec_bank_d0_st[bid]) {
+			/*
+			sprintf_s(reg_name, sizeof(reg_name), "b%_sys_rec_bank_d0_st", bid); */
+			sprintf(reg_name, "b%d_sys_rec_bank_d0_st", bid);
+			return OK;
+		} else if (reg_base_address == bm.b_sys_rec_bank_d1_st[bid]) {
+			/*
+			sprintf_s(reg_name, sizeof(reg_name), "b%_sys_rec_bank_d1_st", bid); */
+			sprintf(reg_name, "b%d_sys_rec_bank_d1_st", bid);
+			return OK;
+		}
+	}
+
+	if (reg_base_address == bm.sw_debug_rec_intr_cause) {
+		sprintf(reg_name, "sw_debug_rec_intr_cause");
+		return OK;
+	} else if (reg_base_address == bm.sw_debug_rec_intr_mask) {
+		sprintf(reg_name, "sw_debug_rec_intr_mask");
+		return OK;
+	} else if (reg_base_address == bm.sys_nrec_common_intr_cause) {
+		sprintf(reg_name, "sys_nrec_common_intr_cause");
+		return OK;
+	} else if (reg_base_address == bm.sys_nrec_common_intr_mask) {
+		sprintf(reg_name, "sys_nrec_common_intr_mask");
+		return OK;
+	} else if (reg_base_address == bm.sys_nrec_common_d0_st) {
+		sprintf(reg_name, "sys_nrec_common_d0_st");
+		return OK;
+	} else if (reg_base_address == bm.sys_nrec_common_d1_st) {
+		sprintf(reg_name, "sys_nrec_common_d1_st");
+		return OK;
+	} else if (reg_base_address == bm.sys_nrec_common_d2_st) {
+		sprintf(reg_name, "sys_nrec_common_d2_st");
+		return OK;
+	} else if (reg_base_address == bm.sys_nrec_common_d3_st) {
+		sprintf(reg_name, "sys_nrec_common_d3_st");
+		return OK;
+	} else if (reg_base_address == bm.common_general_conf) {
+		sprintf(reg_name, "common_general_conf");
+		return OK;
+	} else if (reg_base_address == bm.dram_domain_conf) {
+		sprintf(reg_name, "dram_domain_conf");
+		return OK;
+	} else if (reg_base_address == bm.dram_cache_conf) {
+		sprintf(reg_name, "dram_cache_conf");
+		return OK;
+	} else if (reg_base_address == bm.dram_qos_conf) {
+		sprintf(reg_name, "dram_qos_conf");
+		return OK;
+	} else if (reg_base_address == bm.error_intr_cause) {
+		sprintf(reg_name, "error_intr_cause");
+		return OK;
+	} else if (reg_base_address == bm.error_intr_mask) {
+		sprintf(reg_name, "error_intr_mask");
+		return OK;
+	} else if (reg_base_address == bm.func_intr_cause) {
+		sprintf(reg_name, "func_intr_cause");
+		return OK;
+	} else if (reg_base_address == bm.func_intr_mask) {
+		sprintf(reg_name, "func_intr_mask");
+		return OK;
+	} else if (reg_base_address == bm.ecc_err_intr_cause) {
+		sprintf(reg_name, "ecc_err_intr_cause");
+		return OK;
+	} else if (reg_base_address == bm.ecc_err_intr_mask) {
+		sprintf(reg_name, "ecc_err_intr_mask");
+		return OK;
+	}
+
+	for (bid = 0; bid < 5; bid++) {
+		if (reg_base_address == bm.pool_nempty_intr_cause[bid]) {
+			sprintf(reg_name, "b%d_pool_nempty_intr_cause", bid);
+			return OK;
+		} else if (reg_base_address == bm.pool_nempty_intr_mask[bid]) {
+			sprintf(reg_name, "b%d_pool_nempty_intr_mask", bid);
+			return OK;
+		} else if (reg_base_address == bm.dpool_ae_intr_cause[bid]) {
+			sprintf(reg_name, "b%d_dpool_ae_intr_cause", bid);
+			return OK;
+		} else if (reg_base_address == bm.dpool_ae_intr_mask[bid]) {
+			sprintf(reg_name, "b%d_dpool_ae_intr_mask", bid);
+			return OK;
+		} else if (reg_base_address == bm.dpool_af_intr_cause[bid]) {
+			sprintf(reg_name, "b%d_dpool_af_intr_cause", bid);
+			return OK;
+		} else if (reg_base_address == bm.dpool_af_intr_mask[bid]) {
+			sprintf(reg_name, "b%d_dpool_af_intr_mask", bid);
+			return OK;
+		}
+	}
+
+	if (reg_base_address == bm.b_bank_req_fifos_st) {
+		bid = reg_offset / bm_reg_offset.b_bank_req_fifos_st;
+		sprintf(reg_name, "b%d_bank_req_fifos_st", bid);
+		return OK;
+	} else if  (reg_base_address == bm.b0_past_alc_fifos_st) {
+		sprintf(reg_name, "b0_past_alc_fifos_st");
+		return OK;
+	} else if  (reg_base_address == bm.bgp_past_alc_fifos_st) {
+		sprintf(reg_name, "bgp_past_alc_fifos_st");
+		return OK;
+	} else if  (reg_base_address == bm.b0_rls_wrp_ppe_fifos_st) {
+		sprintf(reg_name, "b0_rls_wrp_ppe_fifos_st");
+		return OK;
+	} else if  (reg_base_address == bm.dm_axi_fifos_st) {
+		sprintf(reg_name, "dm_axi_fifos_st");
+		return OK;
+	} else if  (reg_base_address == bm.drm_pend_fifo_st) {
+		sprintf(reg_name, "drm_pend_fifo_st");
+		return OK;
+	} else if  (reg_base_address == bm.dm_axi_wr_pend_fifo_st) {
+		sprintf(reg_name, "dm_axi_wr_pend_fifo_st");
+		return OK;
+	} else if  (reg_base_address == bm.bm_idle_st) {
+		sprintf(reg_name, "bm_idle_st");
+		return OK;
+	}
+
+	for (bid = 0; bid < 5; bid++) {
+		if  (reg_base_address == bm.dpr_c_mng_stat[bid]) {
+			pid_local = reg_offset / bm_reg_offset.dpr_c_mng_stat[bid];
+			sprintf(reg_name, "dpr_c_mng_b%d_stat_PID_local_%d", bid, pid_local);
+			return OK;
+		} else if  (reg_base_address == bm.tpr_c_mng_b_dyn[bid]) {
+			pid_local = reg_offset / bm_reg_offset.tpr_c_mng_b_dyn[bid];
+			sprintf(reg_name, "tpr_c_mng_b%d_dyn_PID_local_%d", bid, pid_local);
+			return OK;
+		} else if  (reg_base_address == bm.tpr_ctrs_0_b[bid]) {
+			pid_local = reg_offset / bm_reg_offset.tpr_ctrs_0_b[bid];
+			sprintf(reg_name, "tpr_ctrs_0_b%d_PID_local_%d", bid, pid_local);
+			return OK;
+		} else if  (reg_base_address == bm.sram_b_cache[bid]) {
+			line = reg_offset / bm_reg_offset.sram_b_cache[bid];
+			sprintf(reg_name, "sram_b%d_cache_line_%04d", bid, line);
+			return OK;
+		}
+	}
+
+	if  (reg_base_address == bm.dpr_d_mng_ball_stat) {
+		global_pool_idx = reg_offset / bm_reg_offset.dpr_d_mng_ball_stat;
+		pid = BM_GLOBAL_POOL_IDX_TO_PID(global_pool_idx);
+		sprintf(reg_name, "dpr_d_mng_ball_stat_PID_%02d", pid);
+		return OK;
+	} else if  (reg_base_address == bm.tpr_dro_mng_ball_dyn) {
+		global_pool_idx = reg_offset / bm_reg_offset.tpr_dro_mng_ball_dyn;
+		pid = BM_GLOBAL_POOL_IDX_TO_PID(global_pool_idx);
+		sprintf(reg_name, "tpr_dro_mng_ball_dyn_PID_%02d", pid);
+		return OK;
+	} else if  (reg_base_address == bm.tpr_drw_mng_ball_dyn) {
+		global_pool_idx = reg_offset / bm_reg_offset.tpr_drw_mng_ball_dyn;
+		pid = BM_GLOBAL_POOL_IDX_TO_PID(global_pool_idx);
+		sprintf(reg_name, "tpr_drw_mng_ball_dyn_PID_%02d", pid);
+		return OK;
+	}
+
+	sprintf(reg_name, "unknown");
+	return rc;
+}
+
+int bm_pid_bid_init()
+{
+	u32 pid, bid, pid_local, pool, global_pool_idx;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+
+	for (pool = BM_POOL_QM_MIN; pool < BM_POOL_QM_MAX; pool++) {
+		if ((pool            <            BM_POOL_QM_MIN) || (pool            >            BM_POOL_QM_MAX))
+			return rc;
+
+		pid       = (int)pool;
+		if ((pid             <            BM_POOL_QM_MIN) || (pid             >            BM_POOL_QM_MAX))
+			return rc;
+
+		bid       = BM_PID_TO_BANK(pid);
+		if ((bid             <            BM_BANK_QM_MIN) || (bid             >            BM_BANK_QM_MAX))
+			return rc;
+
+		pid_local = BM_PID_TO_PID_LOCAL(pid);
+		if ((pid_local       <       BM_PID_LOCAL_QM_MIN) || (pid_local       >       BM_PID_LOCAL_QM_MAX))
+			return rc;
+
+		global_pool_idx = BM_PID_TO_GLOBAL_POOL_IDX(pid);
+		if ((global_pool_idx < BM_GLOBAL_POOL_IDX_QM_MIN) || (global_pool_idx > BM_GLOBAL_POOL_IDX_QM_MAX))
+			return rc;
+
+		pid = BM_GLOBAL_POOL_IDX_TO_PID(global_pool_idx);
+		if ((pid             <            BM_POOL_QM_MIN) || (pid             >            BM_POOL_QM_MAX))
+			return rc;
+	}
+
+	for (pool = BM_POOL_GP_MIN; pool < BM_POOL_GP_MAX; pool++) {
+		if ((pool            <            BM_POOL_GP_MIN) || (pool            >            BM_POOL_GP_MAX))
+			return rc;
+
+		pid       = (int)pool;
+		if ((pid             <            BM_POOL_GP_MIN) || (pid             >            BM_POOL_GP_MAX))
+			return rc;
+
+		bid       = BM_PID_TO_BANK(pid);
+		if ((bid             <            BM_BANK_GP_MIN) || (bid             >            BM_BANK_GP_MAX))
+			return rc;
+
+		pid_local = BM_PID_TO_PID_LOCAL(pid);
+		if ((pid_local       <       BM_PID_LOCAL_GP_MIN) || (pid_local       >       BM_PID_LOCAL_GP_MAX))
+			return rc;
+
+		global_pool_idx = BM_PID_TO_GLOBAL_POOL_IDX(pid);
+		if ((global_pool_idx < BM_GLOBAL_POOL_IDX_GP_MIN) || (global_pool_idx > BM_GLOBAL_POOL_IDX_GP_MAX))
+			return rc;
+
+		pid = BM_GLOBAL_POOL_IDX_TO_PID(global_pool_idx);
+		if ((pid             <            BM_POOL_GP_MIN) || (pid             >            BM_POOL_GP_MAX))
+			return rc;
+	}
+
+	rc = OK;
+	return rc;
+}
+
+
+/*
+*/
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.h b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.h
new file mode 100644
index 0000000..137bb5e
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_regs.h
@@ -0,0 +1,910 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef	__MV_BM_REGS_H__
+#define	__MV_BM_REGS_H__
+
+#include "bm/mv_bm.h"
+
+#define BM_UNIT_OFFSET		0x0D0000
+#define QM_UNIT_OFFSET		0x400000
+
+/*********************************/
+/* Internal Databases Structures */
+/*********************************/
+
+/** Global arrays structures definitions */
+
+/*
+typedef void * bm_handle;
+*/
+
+/*
+struct bm_dpr_c_mng_stat {
+    u32 bank;
+    u32 cache_start;
+    u32 cache_end;
+    u32 cache_si_thr;
+    u32 cache_so_thr;
+    u32 cache_attr;
+    u32 cache_vmid;
+} __ATTRIBUTE_PACKED__;
+*/
+
+struct bm_c_mng_stat_data {
+	u32 cache_start:7;		/* byte[ 0-11],bit[ 0- 7]	0x0 */
+	u32 _reserved_1:9;		/* byte[ 0-11],bit[ 8-15] */
+	u32 cache_end:7;		/* byte[ 0-11],bit[16-22]	0x0 */
+	u32 _reserved_2:9;		/* byte[ 0-11],bit[23-31] */
+	u32 cache_si_thr:10;	/* byte[ 0-11],bit[32-41]	0x0 */
+	u32 _reserved_3:6;		/* byte[ 0-11],bit[42-47] */
+	u32 cache_so_thr:10;	/* byte[ 0-11],bit[48-57]	0x0 */
+	u32 _reserved_4:6;		/* byte[ 0-11],bit[58-63] */
+	u32 cache_attr:8;		/* byte[ 0-11],bit[64-71]	0x0 */
+	u32 _reserved_5:8;		/* byte[ 0-11],bit[72-79] */
+	u32 cache_vmid:8;		/* byte[ 0-11],bit[80-87]	0x0 */
+	u32 _reserved_6:8;		/* byte[ 0-11],bit[88-95] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct bm_dpr_c_mng_stat {
+	struct bm_c_mng_stat_data reg_c_mng_stat_data[5][31];	/ * byte[ 0- 0x3FFF] * /
+} __ATTRIBUTE_PACKED__;
+
+struct bm_tpr_c_mng_dyn {
+	u32 cache_fill_min;
+	u32 cache_fill_max;
+	u32 cache_rd_ptr;
+	u32 cache_wr_ptr;
+} __ATTRIBUTE_PACKED__;
+*/
+
+struct bm_c_mng_dyn_data {
+	u32 cache_fill_min:10;		/* byte[ 0- 7],bit[ 0- 9]	0x0 */
+	u32 _reserved_1:6;			/* byte[ 0- 7],bit[10-15] */
+	u32 cache_fill_max:10;		/* byte[ 0- 7],bit[16-25]	0x0 */
+	u32 _reserved_2:6;			/* byte[ 0- 7],bit[25-31] */
+	u32 cache_rd_ptr:10;		/* byte[ 0- 7],bit[32-41]	0x0 */
+	u32 _reserved_3:6;			/* byte[ 0- 7],bit[42-47] */
+	u32 cache_wr_ptr:10;		/* byte[ 0- 7],bit[48-57]	0x0 */
+	u32 _reserved_4:6;			/* byte[ 0- 7],bit[58-63] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct bm_tpr_c_mng_dyn {
+	struct bm_c_mng_dyn_data reg_c_mng_dyn_data[5][31];	/ * byte[ 0- 0x3FFF] * /
+} __ATTRIBUTE_PACKED__;
+*/
+
+struct bm_d_mng_ball_stat_data {
+	u32 dram_ae_thr:18;			/* byte[ 0-20],bit[ 0-17]	0x0 */
+	u32 _reserved_1:14;			/* byte[ 0-20],bit[18-31] */
+	u32 dram_af_thr:18;			/* byte[ 0-20],bit[32-49]	0x0 */
+	u32 _reserved_2:14;			/* byte[ 0-20],bit[50-63] */
+/*	int64_t dram_start:40;		 byte[ 0-20],bit[ 64-103]	0x0 */
+	u32 dram_start_lo:32;		/* byte[ 0-20],bit[ 64- 95]	0x0 */
+	u32 dram_start_hi:8;		/* byte[ 0-20],bit[ 97-103]	0x0 */
+	u32 _reserved_3:24;			/* byte[ 0-20],bit[104-127] */
+	u32 dram_size:18;			/* byte[ 0-20],bit[128-145]	0x0 */
+	u32 _reserved_4:14;			/* byte[ 0-20],bit[146-159] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct bm_dpr_d_mng_ball_stat {
+	struct bm_d_mng_ball_stat_data reg_d_mng_ball_stat_data[POOL_NUM];	*//* byte[ 0- 0x3FFF] 128+4 *//*
+} __ATTRIBUTE_PACKED__;
+*/
+
+struct bm_tpr_dro_mng_ball_dyn_data {
+	u32 dram_rd_ptr:21;		/* byte[ 0- 7],bit[ 0-20]	0x0 */
+	u32 _reserved_1:11;		/* byte[ 0- 7],bit[21-31] */
+	u32 dram_wr_ptr:21;		/* byte[ 0- 7],bit[32-52]	0x0 */
+	u32 _reserved_2:11;		/* byte[ 0- 7],bit[53-63] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct bm_tpr_dro_mng_ball_dyn {
+	struct bm_tpr_dro_mng_ball_dyn_data reg_tpr_dro_mng_ball_dyn_data[POOL_NUM];	*//* byte[ 0- 0x3FFF] *//*
+} __ATTRIBUTE_PACKED__;
+*/
+struct bm_tpr_drw_mng_ball_dyn_data {
+	u32 dram_fill:21;		/* byte[ 0- 3],bit[ 0-20]	0x0 */
+	u32 _reserved_1:11;		/* byte[ 0- 3],bit[21-31] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct bm_tpr_drw_mng_ball_dyn {
+	struct bm_tpr_drw_mng_ball_dyn_data reg_tpr_drw_mng_ball_dyn_data[POOL_NUM];	*//* byte[ 0- 0x3FFF] *//*
+} __ATTRIBUTE_PACKED__;
+*/
+struct bm_tpr_ctrs_0_data {
+	u32 delayed_releases_ctr:32;	/* byte[ 0-15],bit[ 0-31]	0x0 */
+	u32 failed_allocs_ctr:32;		/* byte[ 0-15],bit[32-63]	0x0 */
+	u32 released_pes_ctr:32;		/* byte[ 0-15],bit[64-95]	0x0 */
+	u32 allocated_pes_ctr:32;		/* byte[ 0-15],bit[96-127]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct bm_tpr_ctrs_0 {
+	struct bm_tpr_ctrs_0_data reg_tpr_ctrs_0_data[5][31];	*//* byte[ 0- 0x3FFF] *//*
+} __ATTRIBUTE_PACKED__;
+*/
+
+/*
+struct bm_sram_cache{
+	u32 cache_b0_data_0;
+	u32 cache_b0_data_1;
+	u32 cache_b0_data_2;
+	u32 cache_b0_data_3;
+	u32 cache_bgp_data;
+} __ATTRIBUTE_PACKED__;
+*/
+struct bm_cache_b0_mem_data {
+	u32 cache_b0_data_0:22;			/* byte[ 0- 3],bit[  0- 21]	0x0 */
+	u32 _reserved_1:10;				/* byte[ 0- 3],bit[ 22- 31] */
+	u32 cache_b0_data_1:22;			/* byte[ 4- 7],bit[ 32- 53]	0x0 */
+	u32 _reserved_2:10;				/* byte[ 4- 7],bit[ 54- 63] */
+	u32 cache_b0_data_2:22;			/* byte[ 8-11],bit[ 64- 85]	0x0 */
+	u32 _reserved_3:10;				/* byte[ 8-11],bit[ 86- 95] */
+	u32 cache_b0_data_3:22;			/* byte[12-15],bit[ 96-117]	0x0 */
+	u32 _reserved_4:10;				/* byte[12-15],bit[118-127] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_cache_bgp_data {
+/*	uint64_t cache_bgp_data:40; */	/* byte[ 0- 7],bit[ 0-39]	0x0 */
+	u32 cache_bgp_data_lo:32;		/* byte[ 0- 7],bit[ 0-31]	0x0 */
+	u32 cache_bgp_data_hi:8;		/* byte[ 0- 7],bit[32-39]	0x0 */
+	u32 _reserved:24;				/* byte[ 0- 7],bit[40-63] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct bm_sram_cache {
+	struct bm_cache_b0_mem_data reg_cache_b0_data[31];	*//* byte[ 0- 0x3FFF] *//*
+	struct bm_cache_bgp_data    reg_cache_b1_data[31];	*//* byte[ 0- 0x3FFF] *//*
+	struct bm_cache_bgp_data    reg_cache_b2_data[31];	*//* byte[ 0- 0x3FFF] *//*
+	struct bm_cache_bgp_data    reg_cache_b3_data[31];	*//* byte[ 0- 0x3FFF] *//*
+	struct bm_cache_bgp_data    reg_cache_b4_data[31];	*//* byte[ 0- 0x3FFF] *//*
+} __ATTRIBUTE_PACKED__;
+*/
+
+struct bm_pool_conf_b0 {
+	u32 pool_enable:1;				/* byte[ 0- 3],bit[ 0- 0] */
+	u32 pool_quick_init:1;			/* byte[ 0- 3],bit[ 1- 1] */
+	u32 _reserved:30;				/* byte[ 0- 3],bit[ 2-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_pool_conf_bgp {
+	u32 pool_enable:1;				/* byte[ 0- 3],bit[ 0- 0] */
+	u32 pool_in_pairs:1;			/* byte[ 0- 3],bit[ 1- 1] */
+	u32 pe_size:1;					/* byte[ 0- 3],bit[ 2- 2] */
+	u32 pool_quick_init:1;			/* byte[ 0- 3],bit[ 3- 3] */
+	u32 _reserved:28;				/* byte[ 0- 3],bit[ 4-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_pool_st {
+	u32 pool_nempty_st:1;			/* byte[ 0- 3],bit[ 0- 0] */
+	u32 dpool_ae_st:1;				/* byte[ 0- 3],bit[ 1- 1] */
+	u32 dpool_af_st:1;				/* byte[ 0- 3],bit[ 2- 2] */
+	u32 pool_fill_bgt_si_thr_st:1;	/* byte[ 0- 3],bit[ 3- 3] */
+	u32 _reserved:28;				/* byte[ 0- 3],bit[ 4-31] */
+} __ATTRIBUTE_PACKED__;
+
+#ifdef my_HIDE
+struct BM_pool {
+	struct BM_pool_conf_b0  reg_b0_pool_conf[31];
+	struct BM_pool_conf_bgp reg_bgp_pool_conf[31];
+	struct BM_pool_st       reg_pool_st[31];
+} __ATTRIBUTE_PACKED__;
+
+struct bm_pool_conf {
+	u32 pool_enable:1;				/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 pool_in_pairs:1;			/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 PE_size:1;					/* byte[ 0- 3],bit[ 2- 2]	0x1 */
+	u32 pool_quick_init:1;			/* byte[ 0- 3],bit[ 3- 3]	0x1 */
+	u32 _reserved:28;				/* byte[ 0- 3],bit[ 4-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_pool_st {
+	u32 pool_nempty_st:1;			/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 dpool_ae_st:1;				/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 dpool_af_st:1;				/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 pool_fill_bgt_si_thr_st:1;	/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 _reserved:28;				/* byte[ 0- 3],bit[ 4-31] */
+} __ATTRIBUTE_PACKED__;
+#endif
+
+struct bm_b0_internal_dbg_nrec_bank_st {
+	u32 alc_fifo_of_st:1;			/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 alc_fifo_uf_st:1;			/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 alc_resp_fifo_of_st:1;		/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 alc_resp_fifo_uf_st:1;		/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 past_alc_fifo_of_st:1;		/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 past_alc_fifo_uf_st:1;		/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 past_alc_ppe_fifo_of_st:1;	/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 past_alc_ppe_fifo_uf_st:1;	/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 rls_fifo_of_st:1;			/* byte[ 0- 3],bit[ 8- 8]	0x0 */
+	u32 rls_fifo_uf_st:1;			/* byte[ 0- 3],bit[ 9- 9]	0x0 */
+	u32 si_fifo_of_st:1;			/* byte[ 0- 3],bit[10-10]	0x0 */
+	u32 si_fifo_uf_st:1;			/* byte[ 0- 3],bit[11-11]	0x0 */
+	u32 si_size_viol_in_pipe_st:1;	/* byte[ 0- 3],bit[12-12]	0x0 */
+	u32 so_fifo_of_st:1;			/* byte[ 0- 3],bit[13-13]	0x0 */
+	u32 so_fifo_uf_st:1;			/* byte[ 0- 3],bit[14-14]	0x0 */
+	u32 so_size_viol_in_pipe_st:1;	/* byte[ 0- 3],bit[15-15]	0x0 */
+	u32 dram_w_fifo_of_st:1;		/* byte[ 0- 3],bit[16-16]	0x0 */
+	u32 dram_w_fifo_uf_st:1;		/* byte[ 0- 3],bit[17-17]	0x0 */
+	u32 _reserved:14;				/* byte[ 0- 3],bit[18-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_b0_internal_dbg_nrec_pool_st {
+	u32 b0_alc_resp_ppe_fifos_of_st:4;	/* byte[ 0- 3],bit[ 0- 3]	0x0 */
+	u32 _reserved_1:4;					/* byte[ 0- 3],bit[ 4- 7] */
+	u32 b0_alc_resp_ppe_fifos_uf_st:4;	/* byte[ 0- 3],bit[ 8-11]	0x0 */
+	u32 _reserved_2:4;					/* byte[ 0- 3],bit[12-15] */
+	u32 b0_rls_wrp_ppe_fifos_of_st:4;	/* byte[ 0- 3],bit[16-19]	0x0 */
+	u32 _reserved_3:4;					/* byte[ 0- 3],bit[20-23] */
+	u32 b0_rls_wrp_ppe_fifos_uf_st:4;	/* byte[ 0- 3],bit[24-27]	0x0 */
+	u32 _reserved_4:4;					/* byte[ 0- 3],bit[28-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_bgp_internal_dbg_nrec_bank_st {
+	u32 alc_fifo_of_st:1;				/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 alc_fifo_uf_st:1;				/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 alc_resp_fifo_of_st:1;			/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 alc_resp_fifo_uf_st:1;			/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 past_alc_fifo_of_st:1;			/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 past_alc_fifo_uf_st:1;			/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 rls_fifo_of_st:1;				/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 rls_fifo_uf_st:1;				/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 si_fifo_of_st:1;				/* byte[ 0- 3],bit[ 8- 8]	0x0 */
+	u32 si_fifo_uf_st:1;				/* byte[ 0- 3],bit[ 9- 9]	0x0 */
+	u32 si_size_viol_in_pipe_st:1;		/* byte[ 0- 3],bit[10-10]	0x0 */
+	u32 so_fifo_of_st:1;				/* byte[ 0- 3],bit[11-11]	0x0 */
+	u32 so_fifo_uf_st:1;				/* byte[ 0- 3],bit[12-12]	0x0 */
+	u32 so_size_viol_in_pipe_st:1;		/* byte[ 0- 3],bit[13-13]	0x0 */
+	u32 dram_w_fifo_of_st:1;			/* byte[ 0- 3],bit[14-14]	0x0 */
+	u32 dram_w_fifo_uf_st:1;			/* byte[ 0- 3],bit[15-15]	0x0 */
+	u32 b_dwm_in_32b_pend_no_2nd_st:1;	/* byte[ 0- 3],bit[16-16]	0x0 */
+	u32 _reserved:15;					/* byte[ 0- 3],bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_b_sys_rec_bank_intr_cause {
+	u32 sys_rec_bank_intr_cause_sum:1;	/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 alc_vmid_mis_s:1;				/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 rls_vmid_mis_s:1;				/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 alc_dis_pool_s:1;				/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 rls_dis_pool_s:1;				/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 _reserved:27;					/* byte[ 0- 3],bit[ 5-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_sys_rec_bank_intr_mask {
+	u32 _reserved_1:1;					/* byte[ 0- 3],bit[ 0- 0] */
+	u32 alc_vmid_mis_m:1;				/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 rls_vmid_mis_m:1;				/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 alc_dis_pool_m:1;				/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 rls_dis_pool_m:1;				/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 _reserved_2:27;					/* byte[ 0- 3],bit[ 5-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_b_sys_rec_bank_d0_st {
+	u32 b_last_vmid_mis_alc_vmid_st:8;	/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 b_last_vmid_mis_rls_vmid_st:8;	/* byte[ 0- 3],bit[ 8-15]	0x0 */
+	u32 b_last_vmid_mis_alc_pid_st:8;	/* byte[ 0- 3],bit[16-23]	0x0 */
+	u32 b_last_vmid_mis_rls_pid_st:8;	/* byte[ 0- 3],bit[24-31]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_b_sys_rec_bank_d1_st {
+	u32 b_last_vmid_mis_alc_src_st:2;	/* byte[ 0- 3],bit[ 0- 1]	0x0 */
+	u32 b_last_vmid_mis_rls_src_st:2;	/* byte[ 0- 3],bit[ 2- 3]	0x0 */
+	u32 b_last_alc_dis_pool_src_st:2;	/* byte[ 0- 3],bit[ 4- 5]	0x0 */
+	u32 b_last_rls_dis_pool_src_st:2;	/* byte[ 0- 3],bit[ 6- 7]	0x0 */
+	u32 b_last_alc_dis_pool_pid_st:8;	/* byte[ 0- 3],bit[ 8-15]	0x0 */
+	u32 b_last_rls_dis_pool_pid_st:8;	/* byte[ 0- 3],bit[16-23]	0x0 */
+	u32 _reserved:8;					/* byte[ 0- 3],bit[24-31] */
+} __ATTRIBUTE_PACKED__;
+
+#ifdef my_HIDE
+struct bm_bgp_sys_rec_bank_d0_st {
+	u32 b_last_vmid_mis_alc_vmid_st:8;	/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 b_last_vmid_mis_rls_vmid_st:8;	/* byte[ 0- 3],bit[ 8-15]	0x0 */
+	u32 b_last_vmid_mis_alc_pid_st:8;	/* byte[ 0- 3],bit[16-23]	0x0 */
+	u32 b_last_vmid_mis_rls_pid_st:8;	/* byte[ 0- 3],bit[24-31]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_bgp_sys_rec_bank_d1_st {
+	u32 b_last_vmid_mis_alc_src_st:2;	/* byte[ 0- 3],bit[ 0- 1]	0x0 */
+	u32 b_last_vmid_mis_rls_src_st:2;	/* byte[ 0- 3],bit[ 2- 3]	0x0 */
+	u32 b_last_alc_dis_pool_src_st:2;	/* byte[ 0- 3],bit[ 4- 5]	0x0 */
+	u32 b_last_rls_dis_pool_src_st:2;	/* byte[ 0- 3],bit[ 6- 7]	0x0 */
+	u32 b_last_alc_dis_pool_pid_st:8;	/* byte[ 0- 3],bit[ 8-15]	0x0 */
+	u32 b_last_rls_dis_pool_pid_st:8;	/* byte[ 0- 3],bit[16-23]	0x0 */
+	u32 _reserved:8;					/* byte[ 0- 3],bit[24-31] */
+} __ATTRIBUTE_PACKED__;
+#endif
+
+struct bm_b_pool_nempty_intr_cause {
+	u32 b_pool_nempty_intr_sum:1;		/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 b_pool_0_nempty_s:1;			/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 b_pool_1_nempty_s:1;			/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 b_pool_2_nempty_s:1;			/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 b_pool_3_nempty_s:1;			/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 b_pool_4_nempty_s:1;			/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 b_pool_5_nempty_s:1;			/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 b_pool_6_nempty_s:1;			/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 _reserved:8;					/* byte[ 0- 3],bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct bm_pool_nempty_intr_mask {
+	u32 _reserved_1:1;					*//* byte[ 0- 3],bit[ 0- 0] *//*
+	u32 nempty_m[31];					*//* byte[ 0- 3],bit[ 1-31]	0x0 *//*
+} __ATTRIBUTE_PACKED__;
+*/
+
+
+struct bm_b_dpool_ae_intr_cause {
+	u32 b_dpool_ae_intr_sum:1;			/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 b_dpool_0_ae_s:1;				/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 b_dpool_1_ae_s:1;				/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 b_dpool_2_ae_s:1;				/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 b_dpool_3_ae_s:1;				/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 b_dpool_4_ae_s:1;				/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 b_dpool_5_ae_s:1;				/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 b_dpool_6_ae_s:1;				/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 _reserved:8;					/* byte[ 0- 3],bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct bm_dpool_ae_intr_mask {
+	u32 _reserved_1:1;				*//* byte[ 0- 3],bit[ 0- 0] *//*
+	u32 ae_m[31];					*//* byte[ 0- 3],bit[ 1-31]	0x0 *//*
+} __ATTRIBUTE_PACKED__;
+*/
+
+struct bm_b_dpool_af_intr_cause {
+	u32 b_dpool_af_intr_sum:1;			/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 b_dpool_0_af_s:1;				/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 b_dpool_1_af_s:1;				/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 b_dpool_2_af_s:1;				/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 b_dpool_3_af_s:1;				/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 b_dpool_4_af_s:1;				/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 b_dpool_5_af_s:1;				/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 b_dpool_6_af_s:1;				/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 _reserved:8;					/* byte[ 0- 3],bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct bm_dpool_af_intr_mask {
+	u32 _reserved_1:1;				*//* byte[ 0- 3],bit[ 0- 0] *//*
+	u32 af_m[31];					*//* byte[ 0- 3],bit[ 1-31]	0x0 *//*
+} __ATTRIBUTE_PACKED__;
+*/
+struct bm_b_bank_req_fifos_st {
+	u32 b_alc_fifo_fill_st:8;			/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 b_rls_fifo_fill_st:8;			/* byte[ 0- 3],bit[ 8-15]	0x0 */
+	u32 b_so_fifo_fill_st:8;			/* byte[ 0- 3],bit[16-23]	0x0 */
+	u32 b_si_fifo_fill_st:8;			/* byte[ 0- 3],bit[24-31]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_b0_past_alc_fifos_st {
+	u32 b0_past_alc_fifo_fill_st:8;		/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 b0_past_alc_ppe_fifo_fill_st:8;	/* byte[ 0- 3],bit[ 8-15]	0x0 */
+	u32 _reserved:16;					/* byte[ 0- 3],bit[16-31]	    */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_bgp_past_alc_fifos_st {
+	u32 b1_past_alc_fifo_fill_st:8;		/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 b2_past_alc_fifo_fill_st:8;		/* byte[ 0- 3],bit[ 8-15]	0x0 */
+	u32 b3_past_alc_fifo_fill_st:8;		/* byte[ 0- 3],bit[16-23]	0x0 */
+	u32 b4_past_alc_fifo_fill_st:8;		/* byte[ 0- 3],bit[24-31]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_b0_rls_wrp_ppe_fifos_st {
+	u32 rls_wrp_ppe_fifo_0_fill_st:8;	/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 rls_wrp_ppe_fifo_1_fill_st:8;	/* byte[ 0- 3],bit[ 8-15]	0x0 */
+	u32 rls_wrp_ppe_fifo_2_fill_st:8;	/* byte[ 0- 3],bit[16-23]	0x0 */
+	u32 rls_wrp_ppe_fifo_3_fill_st:8;	/* byte[ 0- 3],bit[24-31]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct bm_bank_profile {
+	struct bm_dpr_c_mng_stat                reg_dpr_c_mng_stat[31];/
+	struct bm_tpr_c_mng_dyn                 reg_tpr_c_mng_dyn[31];
+	struct bm_tpr_ctrs_0                    reg_tpr_ctrs_0[31];
+	struct bm_sram_cache                    reg_sram_cache[31];
+	struct bm_pool_conf                     reg_pool_conf[31];
+	struct bm_pool_st                       reg_pool_st[31];
+	struct bm_b0_internal_dbg_nrec_bank_st  reg_b0_internal_dbg_nrec_bank_st;
+	struct bm_b0_internal_dbg_nrec_pool_st  reg_b0_internal_dbg_nrec_pool_st;
+	struct bm_bgp_internal_dbg_nrec_bank_st reg_bgp_internal_dbg_nrec_bank_st;
+	struct bm_sys_rec_bank_intr_cause       reg_sys_rec_bank_intr_cause;
+	struct bm_sys_rec_bank_intr_mask        reg_sys_rec_bank_intr_mask;
+	struct bm_sys_rec_bank_d0_st            reg_sys_rec_bank_d0_st;
+	struct bm_sys_rec_bank_d1_st            reg_sys_rec_bank_d1_st;
+	struct bm_pool_nempty_intr_cause        reg_pool_nempty_intr_cause;
+	struct bm_pool_nempty_intr_mask         reg_pool_nempty_intr_mask;
+	struct bm_dpool_ae_intr_cause           reg_dpool_ae_intr_cause;
+	struct bm_dpool_ae_intr_mask            reg_dpool_ae_intr_mask;
+	struct bm_dpool_af_intr_cause           reg_dpool_af_intr_cause;
+	struct bm_dpool_af_intr_mask            reg_dpool_af_intr_mask;
+	struct bm_bank_req_fifos_st             reg_req_fifos_fill_st;
+} __ATTRIBUTE_PACKED__;
+*/
+struct bm_internal_dbg_nrec_common_st {
+	u32 aggr_0_fifo_of_st:1;			/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 aggr_1_fifo_of_st:1;			/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 aggr_2_fifo_of_st:1;			/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 aggr_0_fifo_uf_st:1;			/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 aggr_1_fifo_uf_st:1;			/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 aggr_2_fifo_uf_st:1;			/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 rams_ctl_d_mng_rd_coll_st:1;	/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 rams_ctl_d_mng_wr_coll_st:1;	/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 dram_r_pend_fifo_of_st:1;		/* byte[ 0- 3],bit[ 8- 8]	0x0 */
+	u32 dram_r_pend_fifo_uf_st:1;		/* byte[ 0- 3],bit[ 9- 9]	0x0 */
+	u32 dram_axi_wd_fifo_of_st:1;		/* byte[ 0- 3],bit[10-10]	0x0 */
+	u32 dram_axi_wd_fifo_uf_st:1;		/* byte[ 0- 3],bit[11-11]	0x0 */
+	u32 dram_axi_wa_fifo_of_st:1;		/* byte[ 0- 3],bit[12-12]	0x0 */
+	u32 dram_axi_wa_fifo_uf_st:1;		/* byte[ 0- 3],bit[13-13]	0x0 */
+	u32 dram_axi_rd_fifo_of_st:1;		/* byte[ 0- 3],bit[14-14]	0x0 */
+	u32 dram_axi_rd_fifo_uf_st:1;		/* byte[ 0- 3],bit[15-15]	0x0 */
+	u32 dram_axi_ra_fifo_of_st:1;		/* byte[ 0- 3],bit[16-10]	0x0 */
+	u32 dram_axi_ra_fifo_uf_st:1;		/* byte[ 0- 3],bit[17-17]	0x0 */
+	u32 _reserved:14;					/* byte[ 0- 3],bit[18-31]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_sw_debug_rec_intr_cause {
+	u32 sw_debug_rec_intr_cause_sum:1;	/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 rams_ctl_sw_wr_c_s:1;			/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 rams_ctl_sw_wr_c_dyn_s:1;		/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 rams_ctl_sw_wr_d_dro_s:1;		/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 qm_bm_rf_err_s:1;				/* byte[ 0- 3],bit[ 4- 5]	0x0 */
+	u32 _reserved:27;					/* byte[ 0- 3],bit[ 5-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_sw_debug_rec_intr_mask {
+	u32 _reserved_1:1;					/* byte[ 0- 3],bit[ 0- 0] */
+	u32 rams_ctl_sw_wr_c_m:1;			/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 rams_ctl_sw_wr_c_dyn_m:1;		/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 rams_ctl_sw_wr_d_dro_m:1;		/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 qm_bm_rf_err_m:1;				/* byte[ 0- 3],bit[ 4- 5]	0x0 */
+	u32 _reserved_2:27;					/* byte[ 0- 3],bit[ 5-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_sys_nrec_common_intr_cause {
+	u32 sys_nrec_common_intr_cause_sum:1;	/* byte[ 0- 3],bit[ 0- 0] */
+	u32 qm_alc_pairs_viol_s:1;				/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 qm_rls_pairs_viol_s:1;				/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 ppe_alc_pairs_viol_s:1;				/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 ppe_rls_pairs_viol_s:1;				/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 ppe_alc_blen_viol_s:1;				/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 ppe_rls_blen_viol_s:1;				/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 mac_alc_pairs_viol_s:1;				/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 mac_rls_pairs_viol_s:1;				/* byte[ 0- 3],bit[ 8- 8]	0x0 */
+	u32 mac_alc_pid_viol_s:1;				/* byte[ 0- 3],bit[ 9- 9]	0x0 */
+	u32 mac_rls_pid_viol_s:1;				/* byte[ 0- 3],bit[10-10]	0x0 */
+	u32 drm_dram_err_s:1;					/* byte[ 0- 3],bit[11-11]	0x0 */
+	u32 dwm_dram_err_s:1;					/* byte[ 0- 3],bit[12-12]	0x0 */
+	u32 dwm_fail_so_dram_fill_s:1;			/* byte[ 0- 3],bit[13-13]	0x0 */
+	u32 _reserved:18;						/* byte[ 0- 3],bit[14-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_sys_nrec_common_intr_mask {
+	u32 _reserved_0:1;						/* byte[ 0- 3],bit[ 0- 0] */
+	u32 qm_alc_pairs_viol_m:1;				/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 qm_rls_pairs_viol_m:1;				/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 ppe_alc_pairs_viol_m:1;				/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 ppe_rls_pairs_viol_m:1;				/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 ppe_alc_blen_viol_m:1;				/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 ppe_rls_blen_viol_m:1;				/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 mac_alc_pairs_viol_m:1;				/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 mac_rls_pairs_viol_m:1;				/* byte[ 0- 3],bit[ 8- 8]	0x0 */
+	u32 mac_alc_pid_viol_m:1;				/* byte[ 0- 3],bit[ 9- 9]	0x0 */
+	u32 mac_rls_pid_viol_m:1;				/* byte[ 0- 3],bit[10-10]	0x0 */
+	u32 drm_dram_err_m:1;					/* byte[ 0- 3],bit[11-11]	0x0 */
+	u32 dwm_dram_err_m:1;					/* byte[ 0- 3],bit[12-12]	0x0 */
+	u32 dwm_fail_so_dram_fill_m:1;			/* byte[ 0- 3],bit[13-13]	0x0 */
+	u32 _reserved_1:18;						/* byte[ 0- 3],bit[14-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_sys_nrec_common_d0_st {
+	u32 qm_last_alc_viol_pid_st:8;		/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 qm_last_rls_viol_pid_st:8;		/* byte[ 0- 3],bit[ 8-15]	0x0 */
+	u32 ppe_last_alc_viol_pid_st:8;		/* byte[ 0- 3],bit[16-23]	0x0 */
+	u32 ppe_last_rls_viol_pid_st:8;		/* byte[ 0- 3],bit[24-31]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_sys_nrec_common_d1_st {
+	u32 mac_last_alc_viol_pid_st:8;		/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 mac_last_rls_viol_pid_st:8;		/* byte[ 0- 3],bit[ 8-15]	0x0 */
+	u32 drm_last_dram_err_pid_st:8;		/* byte[ 0- 3],bit[16-23]	0x0 */
+	u32 dwm_last_fail_so_pid_st:8;		/* byte[ 0- 3],bit[24-31]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_sys_nrec_common_d2_st {
+	u32 qm_last_alc_viol_blen_st:8;		/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 qm_last_rls_viol_blen_st:8;		/* byte[ 0- 3],bit[ 8-15]	0x0 */
+	u32 ppe_last_alc_viol_blen_st:8;	/* byte[ 0- 3],bit[16-23]	0x0 */
+	u32 ppe_last_rls_viol_blen_st:8;	/* byte[ 0- 3],bit[24-31]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_sys_nrec_common_d3_st {
+	u32 mac_last_alc_viol_blen_st:8;	/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 mac_last_rls_viol_blen_st:8;	/* byte[ 0- 3],bit[ 8-15]	0x0 */
+	u32 _reserved:15;					/* byte[ 0- 3],bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_common_general_conf {
+	u32 drm_si_decide_extra_fill:8;		/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 dm_vmid:8;						/* byte[ 0- 3],bit[ 8-15]	0x3 */
+	u32 bm_req_rcv_en:1;				/* byte[ 0- 3],bit[16-16]	0x0 */
+	u32 _reserved:15;					/* byte[ 0- 3],bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_dram_domain_conf {
+	u32 dwm_awdomain_b0:2;				/* byte[ 0- 3],bit[ 0- 1]	0x1 */
+	u32 dwm_awdomain_bgp:2;				/* byte[ 0- 3],bit[ 2- 3]	0x2 */
+	u32 drm_ardomain_b0:2;				/* byte[ 0- 3],bit[ 4- 5]	0x1 */
+	u32 drm_ardomain_bgp:2;				/* byte[ 0- 3],bit[ 6- 7]	0x2 */
+	u32 _reserved:24;					/* byte[ 0- 3],bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_dram_cache_conf {
+	u32 dwm_awcache_b0:4;				/* byte[ 0- 3],bit[ 0- 3]	0x1 */
+	u32 dwm_awcache_bgp:4;				/* byte[ 0- 3],bit[ 4- 7]	0x2 */
+	u32 drm_arcache_b0:4;				/* byte[ 0- 3],bit[ 8-11]	0x1 */
+	u32 drm_arcache_bgp:4;				/* byte[ 0- 3],bit[12-15]	0x2 */
+	u32 _reserved:16;					/* byte[ 0- 3],bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_dram_qos_conf {
+	u32 dwm_awqos_b0:2;					/* byte[ 0- 3],bit[ 0- 1]	0x1 */
+	u32 dwm_awqos_bgp:2;				/* byte[ 0- 3],bit[ 2- 3]	0x2 */
+	u32 drm_arqos_b0:2;					/* byte[ 0- 3],bit[ 4- 5]	0x1 */
+	u32 drm_arqos_bgp:2;				/* byte[ 0- 3],bit[ 6- 7]	0x2 */
+	u32 _reserved:24;					/* byte[ 0- 3],bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_error_intr_cause {
+	u32 qm_bm_err_intr_sum:1;		/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 ecc_err_intr_s:1;			/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 b0_sys_events_rec_bank_s:1;	/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 b1_sys_events_rec_bank_s:1;	/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 b2_sys_events_rec_bank_s:1;	/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 b3_sys_events_rec_bank_s:1;	/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 b4_sys_events_rec_bank_s:1;	/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 sw_debug_events_rec_s:1;	/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 sys_events_nrec_common_s:1;	/* byte[ 0- 3],bit[ 8- 8]	0x0 */
+	u32 _reserved:23;				/* byte[ 0- 3],bit[ 9-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_error_intr_mask {
+	u32 ecc_err_intr_m:1;			/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 b0_sys_events_rec_bank_m:1;	/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 b1_sys_events_rec_bank_m:1;	/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 b2_sys_events_rec_bank_m:1;	/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 b3_sys_events_rec_bank_m:1;	/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 b4_sys_events_rec_bank_m:1;	/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 sw_debug_events_rec_m:1;	/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 sys_events_nrec_common_m:1;	/* byte[ 0- 3],bit[ 8- 8]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_func_intr_cause {
+	u32 qm_bm_func_intr_sum:1;		/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 b0_pool_nempty_intr_s:1;	/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 b0_dpool_ae_intr_s:1;		/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 b0_dpool_af_intr_s:1;		/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 b1_pool_nempty_intr_s:1;	/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 b1_dpool_ae_intr_s:1;		/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 b1_dpool_af_intr_s:1;		/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 b2_pool_nempty_intr_s:1;	/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 b2_dpool_ae_intr_s:1;		/* byte[ 0- 3],bit[ 8- 8]	0x0 */
+	u32 b2_dpool_af_intr_s:1;		/* byte[ 0- 3],bit[ 9- 9]	0x0 */
+	u32 b3_pool_nempty_intr_s:1;	/* byte[ 0- 3],bit[10-10]	0x0 */
+	u32 b3_dpool_ae_intr_s:1;		/* byte[ 0- 3],bit[11-11]	0x0 */
+	u32 b3_dpool_af_intr_s:1;		/* byte[ 0- 3],bit[12-12]	0x0 */
+	u32 b4_pool_nempty_intr_s:1;	/* byte[ 0- 3],bit[13-13]	0x0 */
+	u32 b4_dpool_ae_intr_s:1;		/* byte[ 0- 3],bit[14-14]	0x0 */
+	u32 b4_dpool_af_intr_s:1;		/* byte[ 0- 3],bit[15-15]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_func_intr_mask {
+	u32 b0_pool_nempty_intr_m:1;	/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 b0_dpool_ae_intr_m:1;		/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 b0_dpool_af_intr_m:1;		/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 b1_pool_nempty_intr_m:1;	/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 b1_dpool_ae_intr_m:1;		/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 b1_dpool_af_intr_m:1;		/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 b2_pool_nempty_intr_m:1;	/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 b2_dpool_ae_intr_m:1;		/* byte[ 0- 3],bit[ 8- 8]	0x0 */
+	u32 b2_dpool_af_intr_m:1;		/* byte[ 0- 3],bit[ 9- 9]	0x0 */
+	u32 b3_pool_nempty_intr_m:1;	/* byte[ 0- 3],bit[10-10]	0x0 */
+	u32 b3_dpool_ae_intr_m:1;		/* byte[ 0- 3],bit[11-11]	0x0 */
+	u32 b3_dpool_af_intr_m:1;		/* byte[ 0- 3],bit[12-12]	0x0 */
+	u32 b4_pool_nempty_intr_m:1;	/* byte[ 0- 3],bit[13-13]	0x0 */
+	u32 b4_dpool_ae_intr_m:1;		/* byte[ 0- 3],bit[14-14]	0x0 */
+	u32 b4_dpool_af_intr_m:1;		/* byte[ 0- 3],bit[15-15]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_ecc_err_intr_cause {
+	u32 ecc_err_intr_sum:1;					/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 dpr_c_mng_b0_stat_ser_err_1_s:1;	/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 dpr_c_mng_b0_stat_ser_err_2_s:1;	/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 dpr_c_mng_b1_stat_ser_err_1_s:1;	/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 dpr_c_mng_b1_stat_ser_err_2_s:1;	/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 dpr_c_mng_b2_stat_ser_err_1_s:1;	/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 dpr_c_mng_b2_stat_ser_err_2_s:1;	/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 dpr_c_mng_b3_stat_ser_err_1_s:1;	/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 dpr_c_mng_b3_stat_ser_err_2_s:1;	/* byte[ 0- 3],bit[ 8- 8]	0x0 */
+	u32 dpr_c_mng_b4_stat_ser_err_1_s:1;	/* byte[ 0- 3],bit[ 9- 9]	0x0 */
+	u32 dpr_c_mng_b4_stat_ser_err_2_s:1;	/* byte[ 0- 3],bit[10-10]	0x0 */
+	u32 dpr_d_mng_ball_stat_ser_err_1_s:1;	/* byte[ 0- 3],bit[11-11]	0x0 */
+	u32 dpr_d_mng_ball_stat_ser_err_2_s:1;	/* byte[ 0- 3],bit[12-12]	0x0 */
+	u32 sram_b0_cache_ser_err_s:1;			/* byte[ 0- 3],bit[13-13]	0x0 */
+	u32 sram_b1_cache_ser_err_s:1;			/* byte[ 0- 3],bit[14-14]	0x0 */
+	u32 sram_b2_cache_ser_err_s:1;			/* byte[ 0- 3],bit[15-15]	0x0 */
+	u32 sram_b3_cache_ser_err_s:1;			/* byte[ 0- 3],bit[16-10]	0x0 */
+	u32 sram_b4_cache_ser_err_s:1;			/* byte[ 0- 3],bit[17-17]	0x0 */
+	u32 tpr_c_mng_b0_dyn_ser_err_s:1;		/* byte[ 0- 3],bit[18-18]	0x0 */
+	u32 tpr_c_mng_b1_dyn_ser_err_s:1;		/* byte[ 0- 3],bit[19-19]	0x0 */
+	u32 tpr_c_mng_b2_dyn_ser_err_s:1;		/* byte[ 0- 3],bit[20-20]	0x0 */
+	u32 tpr_c_mng_b3_dyn_ser_err_s:1;		/* byte[ 0- 3],bit[21-21]	0x0 */
+	u32 tpr_c_mng_b4_dyn_ser_err_s:1;		/* byte[ 0- 3],bit[22-22]	0x0 */
+	u32 tpr_dro_mng_ball_dyn_ser_err_s:1;	/* byte[ 0- 3],bit[23-23]	0x0 */
+	u32 tpr_drw_mng_ball_dyn_ser_err_s:1;	/* byte[ 0- 3],bit[24-24]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_ecc_err_intr_mask {
+	u32 dpr_c_mng_b0_stat_ser_err_1_m:1;	/* byte[ 0- 3],bit[ 1- 1]	0x0 */
+	u32 dpr_c_mng_b0_stat_ser_err_2_m:1;	/* byte[ 0- 3],bit[ 2- 2]	0x0 */
+	u32 dpr_c_mng_b1_stat_ser_err_1_m:1;	/* byte[ 0- 3],bit[ 3- 3]	0x0 */
+	u32 dpr_c_mng_b1_stat_ser_err_2_m:1;	/* byte[ 0- 3],bit[ 4- 4]	0x0 */
+	u32 dpr_c_mng_b2_stat_ser_err_1_m:1;	/* byte[ 0- 3],bit[ 5- 5]	0x0 */
+	u32 dpr_c_mng_b2_stat_ser_err_2_m:1;	/* byte[ 0- 3],bit[ 6- 6]	0x0 */
+	u32 dpr_c_mng_b3_stat_ser_err_1_m:1;	/* byte[ 0- 3],bit[ 7- 7]	0x0 */
+	u32 dpr_c_mng_b3_stat_ser_err_2_m:1;	/* byte[ 0- 3],bit[ 8- 8]	0x0 */
+	u32 dpr_c_mng_b4_stat_ser_err_1_m:1;	/* byte[ 0- 3],bit[ 9- 9]	0x0 */
+	u32 dpr_c_mng_b4_stat_ser_err_2_m:1;	/* byte[ 0- 3],bit[10-10]	0x0 */
+	u32 dpr_d_mng_ball_stat_ser_err_1_m:1;	/* byte[ 0- 3],bit[11-11]	0x0 */
+	u32 dpr_d_mng_ball_stat_ser_err_2_m:1;	/* byte[ 0- 3],bit[12-12]	0x0 */
+	u32 sram_b0_cache_ser_err_m:1;			/* byte[ 0- 3],bit[13-13]	0x0 */
+	u32 sram_b1_cache_ser_err_m:1;			/* byte[ 0- 3],bit[14-14]	0x0 */
+	u32 sram_b2_cache_ser_err_m:1;			/* byte[ 0- 3],bit[15-15]	0x0 */
+	u32 sram_b3_cache_ser_err_m:1;			/* byte[ 0- 3],bit[16-10]	0x0 */
+	u32 sram_b4_cache_ser_err_m:1;			/* byte[ 0- 3],bit[17-17]	0x0 */
+	u32 tpr_c_mng_b0_dyn_ser_err_m:1;		/* byte[ 0- 3],bit[18-18]	0x0 */
+	u32 tpr_c_mng_b1_dyn_ser_err_m:1;		/* byte[ 0- 3],bit[19-19]	0x0 */
+	u32 tpr_c_mng_b2_dyn_ser_err_m:1;		/* byte[ 0- 3],bit[20-20]	0x0 */
+	u32 tpr_c_mng_b3_dyn_ser_err_m:1;		/* byte[ 0- 3],bit[21-21]	0x0 */
+	u32 tpr_c_mng_b4_dyn_ser_err_m:1;		/* byte[ 0- 3],bit[22-22]	0x0 */
+	u32 tpr_dro_mng_ball_dyn_ser_err_m:1;	/* byte[ 0- 3],bit[23-23]	0x0 */
+	u32 tpr_drw_mng_ball_dyn_ser_err_m:1;	/* byte[ 0- 3],bit[24-24]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_dm_axi_fifos_st {
+	u32 dwm_waddr_fifo_fill_st:8;		/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 dwm_wdata_fifo_fill_st:8;		/* byte[ 0- 3],bit[ 8-15]	0x0 */
+	u32 drm_raddr_fifo_fill_st:8;		/* byte[ 0- 3],bit[16-23]	0x0 */
+	u32 drm_rdata_fifo_fill_st:8;		/* byte[ 0- 3],bit[24-31]	0x0 */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_drm_pend_fifo_st {
+	u32 drm_pend_fifo_fill_st:8;			/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 _reserved:24;						/* byte[ 0- 3],bit[ 8-31]	    */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_dm_axi_wr_pend_fifo_st {
+	u32 axi_wr_pend_fifo_fill_st:8;			/* byte[ 0- 3],bit[ 0- 7]	0x0 */
+	u32 _reserved:24;						/* byte[ 0- 3],bit[ 8-31]	    */
+} __ATTRIBUTE_PACKED__;
+
+struct bm_bm_idle_st {
+	u32 bm_idle_st:1;						/* byte[ 0- 3],bit[ 0- 0]	0x0 */
+	u32 _reserved_1:31;						/* byte[ 0- 3],bit[ 1-31] */
+} __ATTRIBUTE_PACKED__;
+
+/*extern struct bm_ctl BM_default, BM_profile_1;  */
+
+/*
+#define bm_ctl qm_bm_profile
+struct bm_profile {
+	u32                                    address_base;
+	struct bm_dpr_c_mng_stat               tab_dpr_c_mng_stat;
+	struct bm_tpr_c_mng_dyn                tab_tpr_c_mng_dyn;
+	struct bm_dpr_d_mng_ball_stat          tab_dpr_d_mng_ball_stat;
+	struct bm_tpr_dro_mng_ball_dyn         tab_tpr_dro_mng_ball_dyn;
+	struct bm_tpr_drw_mng_ball_dyn         tab_tpr_drw_mng_ball_dyn;
+	struct bm_tpr_ctrs_0                   tab_tpr_ctrs_0;
+	struct bm_sram_cache                   tab_sram_cache;
+	struct bm_bank_profile                 vec_bank[5];
+	struct bm_b0_past_alc_fifos_st         reg_b0_past_alc_fifos_st;
+	struct bm_bgp_past_alc_fifos_st        reg_bgp_past_alc_fifos_st;
+	struct bm_b0_rls_wrp_ppe_fifos_st      reg_b0_rls_wrp_ppe_fifos_st;
+	struct bm_internal_dbg_nrec_common_st  reg_internal_dbg_nrec_common_st;
+	struct bm_sw_debug_rec_intr_cause      reg_sw_debug_rec_intr_cause;
+	struct bm_sw_debug_rec_intr_mask       reg_sw_debug_rec_intr_mask;
+	struct bm_sys_nrec_common_intr_cause   reg_sys_nrec_common_intr_cause;
+	struct bm_sys_nrec_common_intr_mask    reg_sys_nrec_common_intr_mask;
+	struct bm_sys_nrec_common_d0_st        reg_sys_nrec_common_d0_st;
+	struct bm_sys_nrec_common_d1_st        reg_sys_nrec_common_d1_st;
+	struct bm_common_general_conf          reg_common_general_conf;
+	struct bm_dram_domain_conf             reg_dram_domain_conf;
+	struct bm_dram_cache_conf              reg_dram_cache_conf;
+	struct bm_dram_qos_conf                reg_dram_qos_conf;
+	struct bm_error_intr_cause             reg_error_intr_cause;
+	struct bm_error_intr_mask              reg_error_intr_mask;
+	struct bm_func_intr_cause              reg_func_intr_cause;
+	struct bm_func_intr_mask               reg_func_intr_mask;
+	struct bm_ecc_err_intr_cause           reg_ecc_err_intr_cause;
+	struct bm_ecc_err_intr_mask            reg_ecc_err_intr_mask;
+	struct bm_dm_axi_fifos_st              reg_dm_axi_fifos_st;
+	struct bm_drm_pend_fifo_st             reg_drm_pend_fifo_st;
+	struct bm_dm_axi_wr_pend_fifo_st       reg_dm_axi_wr_pend_fifo_st;
+	struct bm_bm_idle_st                   reg_bm_idle_st;
+	/ * environment * /
+	bm_handle hEnv;
+	u32    magic;
+} __ATTRIBUTE_PACKED__;
+*/
+
+/* SW structures  */
+struct dram_ctrl_profile {
+	u32 dwm_awdomain_b0;
+	u32 dwm_awdomain_bgp;
+	u32 drm_ardomain_b0;
+	u32 drm_ardomain_bgp;
+	u32 dwm_awcache_b0;
+	u32 dwm_awcache_bgp;
+	u32 drm_arcache_b0;
+	u32 drm_arcache_bgp;
+	u32 dwm_awqos_b0;
+	u32 dwm_awqos_bgp;
+	u32 drm_arqos_b0;
+	u32 drm_arqos_bgp;
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct pool_buffer_bank_profile {
+	struct bm_pool_conf pool_conf[31];
+	struct bm_pool_st   pool_st[31];
+} __ATTRIBUTE_PACKED__;
+
+struct pool_buffer_profile {
+	struct pool_buffer_bank_profile bank[5];
+} __ATTRIBUTE_PACKED__;
+
+struct sram_cache_bank_profile {
+	struct bm_sram_cache sram_cache[31];
+} __ATTRIBUTE_PACKED__;
+
+struct sram_cache_profile {
+	struct sram_cache_bank_profile bank[5];
+} __ATTRIBUTE_PACKED__;
+
+struct mask_profile {
+	u32 XXXXX;
+} __ATTRIBUTE_PACKED__;
+*/
+
+/* registers addresses definitons */
+
+struct bm_alias {
+	u32 base;
+	u32 b_pool_n_conf[BM_NUMBER_OF_BANKS];
+	u32 b_pool_n_st[BM_NUMBER_OF_BANKS];
+	u32 b_sys_rec_bank_intr_cause[BM_NUMBER_OF_BANKS];
+	u32 b_sys_rec_bank_intr_mask[BM_NUMBER_OF_BANKS];
+	u32 b_sys_rec_bank_d0_st[BM_NUMBER_OF_BANKS];
+	u32 b_sys_rec_bank_d1_st[BM_NUMBER_OF_BANKS];
+	u32 sw_debug_rec_intr_cause;
+	u32 sw_debug_rec_intr_mask;
+	u32 sys_nrec_common_intr_cause;
+	u32 sys_nrec_common_intr_mask;
+	u32 sys_nrec_common_d0_st;
+	u32 sys_nrec_common_d1_st;
+	u32 sys_nrec_common_d2_st;
+	u32 sys_nrec_common_d3_st;
+	u32 common_general_conf;
+	u32 dram_domain_conf;
+	u32 dram_cache_conf;
+	u32 dram_qos_conf;
+	u32 error_intr_cause;
+	u32 error_intr_mask;
+	u32 func_intr_cause;
+	u32 func_intr_mask;
+	u32 ecc_err_intr_cause;
+	u32 ecc_err_intr_mask;
+	u32 pool_nempty_intr_cause[BM_NUMBER_OF_BANKS];
+	u32 pool_nempty_intr_mask[BM_NUMBER_OF_BANKS];
+	u32 dpool_ae_intr_cause[BM_NUMBER_OF_BANKS];
+	u32 dpool_ae_intr_mask[BM_NUMBER_OF_BANKS];
+	u32 dpool_af_intr_cause[BM_NUMBER_OF_BANKS];
+	u32 dpool_af_intr_mask[BM_NUMBER_OF_BANKS];
+	u32 b_bank_req_fifos_st;
+	u32 b0_past_alc_fifos_st;
+	u32 bgp_past_alc_fifos_st;
+	u32 b0_rls_wrp_ppe_fifos_st;
+	u32 dm_axi_fifos_st;
+	u32 drm_pend_fifo_st;
+	u32 dm_axi_wr_pend_fifo_st;
+	u32 bm_idle_st;
+	u32 dpr_c_mng_stat[BM_NUMBER_OF_BANKS];
+	u32 tpr_c_mng_b_dyn[BM_NUMBER_OF_BANKS];
+	u32 dpr_d_mng_ball_stat;
+	u32 tpr_dro_mng_ball_dyn;
+	u32 tpr_drw_mng_ball_dyn;
+	u32 tpr_ctrs_0_b[BM_NUMBER_OF_BANKS];
+	u32 sram_b_cache[BM_NUMBER_OF_BANKS];
+} __ATTRIBUTE_PACKED__;
+
+
+extern struct bm_alias bm;
+extern struct bm_alias bm_reg_size;
+extern struct bm_alias bm_reg_offset;
+
+int bm_reg_address_alias_init(void);
+int bm_reg_size_alias_init(void);
+int bm_reg_offset_alias_init(void);
+int bm_pid_bid_init(void);
+int bm_register_name_get(u32 reg_base_address, u32 reg_offset, char *reg_name);
+
+#endif	/*__MV_BM_REGS_H__*/
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c
new file mode 100644
index 0000000..fbe6fdc
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c
@@ -0,0 +1,782 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+#include "bm/mv_bm.h"
+#include "bm/mv_bm_regs.h"
+
+static struct  platform_device *neta_sysfs;
+
+/*
+#define PR_ERR_CODE(_rc, _func)	\
+{								\
+	pr_err("error code = 0x%08X on illegal operation at line %05d in function <%s> in file <%s>\n", rc, __LINE__, __func__, __FILE__);			\
+	pr_err("%s: error code = 0x%08X on illegal operation at line %05d in function <%s> in file <%s>\n", _func, _rc, __LINE__, __func__, __FILE__);	\
+}
+*/
+#define PR_ERR_CODE(_rc)	\
+{							\
+	pr_err("%s: error code = 0x%08X on illegal operation in function <%s>\n", __func__, _rc, attr->attr.name);	\
+}
+/*
+	pr_err("%s: illegal operation in function <%s> at line %05d in file <%s>, error code = 0x%08X\n", __func__, attr->attr.name, __LINE__, __FILE__, rc);	\
+	pr_err("%s: illegal operation in function <%s>, error code = 0x%08X\n", __func__, attr->attr.name, rc);		\
+	pr_err("%s: error code = 0x%08X on illegal operation at line %05d in function <%s> in file <%s>\n", _func, _rc, __LINE__, __func__, __FILE__);	\
+*/
+
+#define PR_INFO_CALLED		\
+{							\
+	pr_info("%s is called\n", attr->attr.name);	\
+}
+
+#define BM_MALLOC_SIZE 0x00000100
+
+#ifdef __linux__
+#define BM_MALLOC(_size)	((u32)kmalloc(_size, GFP_KERNEL))
+#else
+#define BM_MALLOC(_size)	 ((u32)malloc(_size))
+#endif
+
+
+static ssize_t mv_bm_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "cat  status                            - show BM status\n");
+	off += sprintf(buf+off, "echo > bm_open                         - Init BM registers\n");
+	off += sprintf(buf+off, "echo > bm_attr_all_pools_def_set             - configures BM read/write default attributes\n");
+	off += sprintf(buf+off, "echo rD wD rC wC rQ wQ > bm_attr_qm_pool_set - configures BM read/write attributes for qm pools\n");
+/*      : o += sprintf(b+o, "echo rD wD rC wC rQ wQ > bm_attr_gp_pool_set - configures BM read/write attributes for gp pools\n"); */
+	off += sprintf(buf+off, "echo rD wD rC wC rQ wQ > bm_attr_gp_pool_set - configures BM read/write attributes for gp pools\n");
+	off += sprintf(buf+off, "echo > bm_enable_status_get                  - Get BM enable status\n");
+	off += sprintf(buf+off, "echo nb > bm_qm_gpm_pools_def_quick_init     - Initiates of GPM pools with default values\n");
+	off += sprintf(buf+off, "echo nb > bm_qm_dram_pools_def_quick_init    - Initiates of DRAM pools with default values\n");
+	off += sprintf(buf+off, "echo nb et ft id ca cot cit, cnb > bm_qm_gpm_pools_quick_init  - Initiates QM GPM pools\n");
+	off += sprintf(buf+off, "echo nb et ft id ca cot cit, cnb > bm_qm_dram_pools_quick_init - Initiates QM DRAM pools\n");
+	off += sprintf(buf+off, "echo p > bm_pool_quick_init_status_get       - Get pool quick init status\n");
+	off += sprintf(buf+off, "echo p nb pm > bm_gp_pool_def_basic_init     - Basic init of gp pools with default values\n");
+	off += sprintf(buf+off, "echo p nb ps pp et ft id ca cot cit cnb > bm_gp_pool_basic_init - Basic init of gp pools\n");
+	off += sprintf(buf+off, "echo > bm_enable                            - Global enable BM\n");
+	off += sprintf(buf+off, "echo > bm_disable                           - Global disable BM\n");
+	off += sprintf(buf+off, "echo p > bm_pool_fill_level_get             - gives fill level of pool in DRAM\n");
+	off += sprintf(buf+off, "echo id > bm_vmid_set                       - Set BM VMID\n");
+	off += sprintf(buf+off, "echo p nb fl pm > bm_gp_pool_def_quick_init - Configure BM registers and allocate memory for pools with default values\n");
+	off += sprintf(buf+off, "echo p nb fl ps pp et at cid ca cot cit cnb > bm_gp_pool_quick_init - Configure BM registers and allocate memory for pools\n");
+	off += sprintf(buf+off, "echo > bm_global_registers_dump        - Print all global registers\n");
+	off += sprintf(buf+off, "echo > bm_pool_registers_dump pool     - Print values of all BM pool registers\n");
+	off += sprintf(buf+off, "echo > bm_bank_registers_dump bank     - Print values of all BM bank registers\n");
+	off += sprintf(buf+off, "echo > bm_cache_memory_dump bank       - Print all 512 lines of cache per input bank sram_b0...b4_cache_mem\n");
+	off += sprintf(buf+off, "echo > bm_idle_status_get              - Read BM idle status\n");
+	off += sprintf(buf+off, "echo p pn dpe dpf > bm_pool_status_get - Get status per pool: pool_nempty, dpool_ae, dpool_af\n");
+	off += sprintf(buf+off, "echo > bm_idle_debug                   - Print several registers status that gives indication why BM is busy\n");
+	off += sprintf(buf+off, "echo > bm_error_dump                   - Print several registers status that gives indication why BM is busy\n");
+	off += sprintf(buf+off, "echo p nb > bm_pool_memory_fill         - Fill memory of pool with PE index\n");
+	off += sprintf(buf+off, "echo p nb ps et ft > bm_pool_dram_set   - Configure BM with Fill level of pool in DRAM\n");
+	off += sprintf(buf+off, "echo p nb ps qi > bm_pool_fill_level_set      - Configure BM with Fill level of pool in DRAM\n");
+	off += sprintf(buf+off, "echo p qi > bm_pool_enable                    - Enables BM pool\n");
+	off += sprintf(buf+off, "echo p ps > bm_gp_pool_pe_size_set            - Set PE pointer size in general purpose pool\n");
+	off += sprintf(buf+off, "echo p pp > bm_gp_pool_pair_set               - Configure if pool is defined to work in pairs\n");
+	off += sprintf(buf+off, "echo p cid ca cot cit cnb > bm_pool_cache_set - Configure pool cache parameters\n");
+	off += sprintf(buf+off, "echo pool > bm_pool_disable                   - Set Pool to disable\n");
+/*
+	off += sprintf(buf+off, "echo > qm_gpm_init  b qah qal pah pal  - init QM QM GPM pools (0,1)\n");
+	off += sprintf(buf+off, "echo > qm_dram_init b qah qal pah pal  - init QM DRAM pools (2,3)\n");
+*/
+	off += sprintf(buf+off, "echo ba, ofs, wN, dP > bm_register_read  - Read register from BM units\n");
+	off += sprintf(buf+off, "echo ba, ofs, wN, dP > bm_register_write - Write register in BM units\n");
+	off += sprintf(buf+off, "\n");
+
+	return off;
+}
+
+static ssize_t mv_bm_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	pr_info("mv_bm_show is called\n");
+	if (!strcmp(name, "status")) {
+		u32 status = 0;
+		pr_info("bm_enable_status_get: ");
+		/*bm_enable_status_get(&status);*/
+		pr_info("status is %d\n", status);
+	} else if (!strcmp(name, "help")) {
+		off = mv_bm_help(buf);
+	} else if (!strcmp(name, "debug")) {
+		pr_info("debug\n");
+	} else {
+		off = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	return off;
+}
+
+static ssize_t mv_bm_config(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	int             err = 0;
+/*
+	u32 flags;
+*/
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "bm_open")) {
+		pr_info("bm_open is called\n");
+		rc = bm_open();
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_attr_all_pools_def_set")) {
+		PR_INFO_CALLED
+		rc = bm_attr_all_pools_def_set();
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_attr_qm_pool_set")) {
+		u32 arDomain, awDomain, arCache, awCache, arQOS, awQOS;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		arDomain = awDomain = arCache = awCache = arQOS = awQOS = 0xFFFFFFFF;
+		sscanf(buf, "%d %d %d %d %d %d", &arDomain, &awDomain, &arCache, &awCache, &arQOS, &awQOS);
+		rc = bm_attr_qm_pool_set(arDomain, awDomain, arCache, awCache, arQOS, awQOS);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_attr_gp_pool_set")) {
+		u32 arDomain, awDomain, arCache, awCache, arQOS, awQOS;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		arDomain = awDomain = arCache = awCache = arQOS = awQOS = 0xFFFFFFFF;
+		sscanf(buf, "%d %d %d %d %d %d", &arDomain, &awDomain, &arCache, &awCache, &arQOS, &awQOS);
+		rc = bm_attr_gp_pool_set(arDomain, awDomain, arCache, awCache, arQOS, awQOS);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_enable_status_get"))	{
+		u32 bm_req_rcv_en;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		bm_req_rcv_en = 0xFFFFFFFF;
+		rc = bm_enable_status_get(&bm_req_rcv_en);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+		pr_info("\t bm_req_rcv_en = %d\n", bm_req_rcv_en);
+	} else if (!strcmp(name, "bm_qm_gpm_pools_def_quick_init")) {
+		u32 num_of_buffers;
+		struct mv_word40 qece_base_address, pl_base_address;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		num_of_buffers = qece_base_address.hi = qece_base_address.lo = pl_base_address.hi = pl_base_address.lo = 0xFFFFFFFF;
+		qece_base_address.hi = 0;
+		qece_base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		pl_base_address.hi = 0;
+		pl_base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		sscanf(buf, "%d", &num_of_buffers);
+		rc = bm_qm_gpm_pools_def_quick_init(num_of_buffers, (u32 *)&qece_base_address, (u32 *)&pl_base_address);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_qm_dram_pools_def_quick_init")) {
+		u32 num_of_buffers;
+		struct mv_word40 qece_base_address, pl_base_address;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		num_of_buffers = qece_base_address.hi = qece_base_address.lo = pl_base_address.hi = pl_base_address.lo = 0xFFFFFFFF;
+		qece_base_address.hi = 0;
+		qece_base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		pl_base_address.hi = 0;
+		pl_base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		sscanf(buf, "%d", &num_of_buffers);
+		rc = bm_qm_dram_pools_def_quick_init(num_of_buffers, (u32 *)&qece_base_address, (u32 *)&pl_base_address);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_qm_gpm_pools_quick_init")) {
+		u32 num_of_buffers, ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
+		struct mv_word40 qece_base_address, pl_base_address;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		num_of_buffers = qece_base_address.hi = qece_base_address.lo = pl_base_address.hi = pl_base_address.lo = ae_thr = af_thr = cache_vmid = cache_attr = cache_so_thr = cache_si_thr = cache_num_of_buffers = 0xFFFFFFFF;
+		qece_base_address.hi = 0;
+		qece_base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		pl_base_address.hi = 0;
+		pl_base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		sscanf(buf, "%d %d %d %d %d %d %d %d", &num_of_buffers, &ae_thr, &af_thr, &cache_vmid, &cache_attr, &cache_so_thr, &cache_si_thr, &cache_num_of_buffers);
+		rc = bm_qm_gpm_pools_quick_init(num_of_buffers, (u32 *)&qece_base_address, (u32 *)&pl_base_address, ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_qm_dram_pools_quick_init")) {
+		u32 num_of_buffers, ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
+		struct mv_word40 qece_base_address, pl_base_address;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		num_of_buffers = qece_base_address.hi = qece_base_address.lo = pl_base_address.hi = pl_base_address.lo = ae_thr = af_thr = cache_vmid = cache_attr = cache_so_thr = cache_si_thr = cache_num_of_buffers = 0xFFFFFFFF;
+		qece_base_address.hi = 0;
+		qece_base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		pl_base_address.hi = 0;
+		pl_base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		sscanf(buf, "%d %d %d %d %d %d %d %d", &num_of_buffers, &ae_thr, &af_thr, &cache_vmid, &cache_attr, &cache_so_thr, &cache_si_thr, &cache_num_of_buffers);
+		rc = bm_qm_dram_pools_quick_init(num_of_buffers, (u32 *)&qece_base_address, (u32 *)&pl_base_address, ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_pool_quick_init_status_get")) {
+		u32 pool, completed;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = completed = 0xFFFFFFFF;
+		sscanf(buf, "%d", &pool);
+		rc = bm_pool_quick_init_status_get(pool, &completed);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+		pr_info("\t completed = %d\n", completed);
+	} else if (!strcmp(name, "bm_gp_pool_def_basic_init")) {
+		u32 pool, num_of_buffers, partition_model;
+		struct mv_word40 base_address;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = num_of_buffers = base_address.hi = base_address.lo = partition_model = 0xFFFFFFFF;
+		base_address.hi = 0;
+		base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		sscanf(buf, "%d %d %d", &pool, &num_of_buffers, &partition_model);
+		rc = bm_gp_pool_def_basic_init(pool, num_of_buffers, (u32 *)&base_address, partition_model);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_gp_pool_basic_init")) {
+		u32 pool, num_of_buffers, pe_size, pool_pair, ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
+		struct mv_word40 base_address;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = num_of_buffers = base_address.hi = base_address.lo = pe_size = pool_pair = ae_thr = af_thr = cache_vmid = cache_attr = cache_so_thr = cache_si_thr = cache_num_of_buffers = 0xFFFFFFFF;
+		base_address.hi = 0;
+		base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		sscanf(buf, "%d %d %d %d %d %d %d %d %d %d %d", &pool, &num_of_buffers, &pe_size, &pool_pair, &ae_thr, &af_thr, &cache_vmid, &cache_attr, &cache_so_thr, &cache_si_thr, &cache_num_of_buffers);
+		rc = bm_gp_pool_basic_init(pool, num_of_buffers, (u32 *)&base_address, pe_size, pool_pair, ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_enable")) {
+		PR_INFO_CALLED
+		rc = bm_enable();
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_disable")) {
+		PR_INFO_CALLED
+		rc = bm_disable();
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_pool_fill_level_get")) {
+		u32 pool, fill_level;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = fill_level = 0xFFFFFFFF;
+		sscanf(buf, "%d", &pool);
+		rc = bm_pool_fill_level_get(pool, &fill_level);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+		pr_info("\t fill_level = %d\n", fill_level);
+	} else if (!strcmp(name, "bm_vmid_set")) {
+		u32 bm_vmid;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		bm_vmid = 0xFFFFFFFF;
+		sscanf(buf, "%d", &bm_vmid);
+		rc = bm_vmid_set(bm_vmid);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_gp_pool_def_quick_init")) {
+		u32 pool, num_of_buffers, fill_level, partition_model;
+		struct mv_word40 base_address;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = num_of_buffers = fill_level = base_address.hi = base_address.lo = partition_model = 0xFFFFFFFF;
+		base_address.hi = 0;
+		base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		sscanf(buf, "%d %d %d %d", &pool, &num_of_buffers, &fill_level, &partition_model);
+		rc = bm_gp_pool_def_quick_init(pool, num_of_buffers, fill_level, (u32 *)&base_address, partition_model);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_gp_pool_quick_init")) {
+		u32 pool, num_of_buffers, fill_level, pe_size, pool_pair, ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
+		struct mv_word40 base_address;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = num_of_buffers = fill_level = base_address.hi = base_address.lo = pe_size = pool_pair = ae_thr = af_thr = cache_vmid = cache_attr = cache_so_thr = cache_si_thr = cache_num_of_buffers = 0xFFFFFFFF;
+		base_address.hi = 0;
+		base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		sscanf(buf, "%d %d %d %d %d %d %d %d %d %d %d %d", &pool, &num_of_buffers, &fill_level, &pe_size, &pool_pair, &ae_thr, &af_thr, &cache_vmid, &cache_attr, &cache_so_thr, &cache_si_thr, &cache_num_of_buffers);
+		rc = bm_gp_pool_quick_init(pool, num_of_buffers, fill_level, (u32 *)&base_address, pe_size, pool_pair, ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_global_registers_dump")) {
+		PR_INFO_CALLED
+		rc = bm_global_registers_dump();
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_pool_registers_dump")) {
+		u32 pool;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = 0xFFFFFFFF;
+		sscanf(buf, "%d", &pool);
+		rc = bm_pool_registers_dump(pool);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_bank_registers_dump")) {
+		u32 bank;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		bank = 0xFFFFFFFF;
+		sscanf(buf, "%d", &bank);
+		rc = bm_bank_registers_dump(bank);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_cache_memory_dump")) {
+		u32 bank;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		bank = 0xFFFFFFFF;
+		sscanf(buf, "%d", &bank);
+		rc = bm_cache_memory_dump(bank);
+		if (rc != OK)
+			pr_err("%s: illegal operation in function <%s>, error code = 0x%08X\n", __func__, attr->attr.name, rc);
+	} else if (!strcmp(name, "bm_idle_status_get")) {
+		u32 status;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		status = 0xFFFFFFFF;
+		rc = bm_idle_status_get(&status);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+		pr_info("\t status = %d\n", status);
+	} else if (!strcmp(name, "bm_pool_status_get")) {
+		u32 pool, pool_nempty, dpool_ae, dpool_af;
+
+		PR_INFO_CALLED
+		pool = pool_nempty = dpool_ae = dpool_af = 0xFFFFFFFF;
+		/* Read input values */
+		sscanf(buf, "%d %d %d %d", &pool, &pool_nempty, &dpool_ae, &dpool_af);
+		rc = bm_pool_status_get(pool, &pool_nempty, &dpool_ae, &dpool_af);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_idle_debug")) {
+		PR_INFO_CALLED
+		rc = bm_idle_debug();
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_error_dump")) {
+		PR_INFO_CALLED
+		rc = bm_error_dump();
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_pool_memory_fill")) {
+		u32 pool,  num_of_buffers;
+		struct mv_word40 base_address;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = num_of_buffers = base_address.hi = base_address.lo = 0xFFFFFFFF;
+		base_address.hi = 0;
+		base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		sscanf(buf, "%d %d", &pool, &num_of_buffers);
+		rc = bm_pool_memory_fill(pool, num_of_buffers, (u32 *)&base_address);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_pool_dram_set"))	{
+		u32 pool,  num_of_buffers, pe_size, ae_thr, af_thr;
+		struct mv_word40 base_address;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = num_of_buffers = pe_size = base_address.hi = base_address.lo = ae_thr = af_thr = 0xFFFFFFFF;
+		base_address.hi = 0;
+		base_address.lo = BM_MALLOC(BM_MALLOC_SIZE);
+		sscanf(buf, "%d %d %d %d %d", &pool, &num_of_buffers, &pe_size, &ae_thr, &af_thr);
+		rc = bm_pool_dram_set(pool,  num_of_buffers, pe_size,  (u32 *)&base_address, ae_thr, af_thr);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_pool_fill_level_set")) {
+		u32 pool,  num_of_buffers, pe_size,  quick_init;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = num_of_buffers = pe_size = quick_init = 0xFFFFFFFF;
+		sscanf(buf, "%d %d %d %d", &pool, &num_of_buffers, &pe_size, &quick_init);
+		rc = bm_pool_fill_level_set(pool, num_of_buffers, pe_size, quick_init);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_pool_enable")) {
+		u32 pool, quick_init;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = quick_init = 0xFFFFFFFF;
+		sscanf(buf, "%d %d", &pool, &quick_init);
+		rc = bm_pool_enable(pool, quick_init);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_gp_pool_pe_size_set")) {
+		u32 pool, pe_size;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = pe_size = 0xFFFFFFFF;
+		sscanf(buf, "%d %d", &pool, &pe_size);
+		rc = bm_gp_pool_pe_size_set(pool, pe_size);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_gp_pool_pair_set")) {
+		u32 pool, pool_pair;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = pool_pair = 0xFFFFFFFF;
+		sscanf(buf, "%d %d", &pool, &pool_pair);
+		rc = bm_gp_pool_pair_set(pool, pool_pair);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_pool_cache_set")) {
+		u32 pool, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = cache_vmid = cache_attr = cache_so_thr = cache_si_thr = cache_num_of_buffers = 0xFFFFFFFF;
+		sscanf(buf, "%d %d %d %d %d %d", &pool, &cache_vmid, &cache_attr, &cache_so_thr, &cache_si_thr, &cache_num_of_buffers);
+		rc = bm_pool_cache_set(pool, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_pool_disable")) {
+		u32 pool;
+
+		/* Read input values */
+		PR_INFO_CALLED
+		pool = 0xFFFFFFFF;
+		sscanf(buf, "%d", &pool);
+		rc = bm_pool_disable(pool);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+/*not used*/
+	} else if (!strcmp(name, "bm_register_read")) {
+		u32 base_address, offset, wordsNumber, dataPtr;
+
+		PR_INFO_CALLED
+		base_address = offset = wordsNumber = dataPtr = 0xFFFFFFFF;
+		/* Read input values */
+		sscanf(buf, "%x %x %x %x", &base_address, &offset, &wordsNumber, &dataPtr);
+		rc = bm_register_read(base_address, offset, wordsNumber, (u32 *)&dataPtr);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "bm_register_write")) {
+		u32 base_address, offset, wordsNumber, dataPtr;
+
+		PR_INFO_CALLED
+		base_address = offset = wordsNumber = dataPtr = 0xFFFFFFFF;
+		/* Read input values */
+		sscanf(buf, "%x %x %x %x", &base_address, &offset, &wordsNumber, &dataPtr);
+		rc = bm_register_write(base_address, offset, wordsNumber, (u32 *)&dataPtr);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else {
+		err = 1;
+/*		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);*/
+		pr_err("%s: wrong name of BM function <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,                            S_IRUSR, mv_bm_show, NULL);
+static DEVICE_ATTR(status,                          S_IRUSR, mv_bm_show, NULL);
+static DEVICE_ATTR(bm_open,                         S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_attr_all_pools_def_set,       S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_attr_qm_pool_set,             S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_attr_gp_pool_set,             S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_enable_status_get,            S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_qm_gpm_pools_def_quick_init,  S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_qm_dram_pools_def_quick_init, S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_qm_gpm_pools_quick_init,      S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_qm_dram_pools_quick_init,     S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_pool_quick_init_status_get,   S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_gp_pool_def_basic_init,       S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_gp_pool_basic_init,           S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_enable,                       S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_disable,                      S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_pool_fill_level_get,          S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_vmid_set,                     S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_gp_pool_def_quick_init,       S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_gp_pool_quick_init,           S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_global_registers_dump,        S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_pool_registers_dump,          S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_bank_registers_dump,          S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_cache_memory_dump,            S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_idle_status_get,              S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_pool_status_get,              S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_idle_debug,                   S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_error_dump,                   S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_pool_memory_fill,             S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_pool_dram_set,                S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_pool_fill_level_set,          S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_pool_enable,                  S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_gp_pool_pe_size_set,          S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_gp_pool_pair_set,             S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_pool_cache_set,               S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_pool_disable,                 S_IWUSR, NULL,       mv_bm_config);
+/*
+static DEVICE_ATTR(qm_gpm_init,                     S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(qm_dram_init,                    S_IWUSR, NULL,       mv_bm_config);
+*/
+static DEVICE_ATTR(bm_register_read,                S_IWUSR, NULL,       mv_bm_config);
+static DEVICE_ATTR(bm_register_write,               S_IWUSR, NULL,       mv_bm_config);
+
+
+static struct attribute *mv_bm_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_status.attr,
+	&dev_attr_bm_open.attr,
+	&dev_attr_bm_attr_all_pools_def_set.attr,
+	&dev_attr_bm_attr_qm_pool_set.attr,
+	&dev_attr_bm_attr_gp_pool_set.attr,
+	&dev_attr_bm_enable_status_get.attr,
+	&dev_attr_bm_qm_gpm_pools_def_quick_init.attr,
+	&dev_attr_bm_qm_dram_pools_def_quick_init.attr,
+	&dev_attr_bm_qm_gpm_pools_quick_init.attr,
+	&dev_attr_bm_qm_dram_pools_quick_init.attr,
+	&dev_attr_bm_pool_quick_init_status_get.attr,
+	&dev_attr_bm_gp_pool_def_basic_init.attr,
+	&dev_attr_bm_gp_pool_basic_init.attr,
+	&dev_attr_bm_enable.attr,
+	&dev_attr_bm_disable.attr,
+	&dev_attr_bm_pool_fill_level_get.attr,
+	&dev_attr_bm_vmid_set.attr,
+	&dev_attr_bm_gp_pool_def_quick_init.attr,
+	&dev_attr_bm_gp_pool_quick_init.attr,
+	&dev_attr_bm_global_registers_dump.attr,
+	&dev_attr_bm_pool_registers_dump.attr,
+	&dev_attr_bm_bank_registers_dump.attr,
+	&dev_attr_bm_cache_memory_dump.attr,
+	&dev_attr_bm_idle_status_get.attr,
+	&dev_attr_bm_pool_status_get.attr,
+	&dev_attr_bm_idle_debug.attr,
+	&dev_attr_bm_error_dump.attr,
+	&dev_attr_bm_pool_memory_fill.attr,
+	&dev_attr_bm_pool_dram_set.attr,
+	&dev_attr_bm_pool_fill_level_set.attr,
+	&dev_attr_bm_pool_enable.attr,
+	&dev_attr_bm_gp_pool_pe_size_set.attr,
+	&dev_attr_bm_gp_pool_pair_set.attr,
+	&dev_attr_bm_pool_cache_set.attr,
+	&dev_attr_bm_pool_disable.attr,
+/*
+	&dev_attr_qm_gpm_init.attr,
+	&dev_attr_qm_dram_init.attr,
+*/
+	&dev_attr_bm_register_read.attr,
+	&dev_attr_bm_register_write.attr,
+	NULL
+};
+
+
+static struct attribute_group mv_bm_group = {
+	.name = "bm",
+	.attrs = mv_bm_attrs,
+};
+
+int mv_pp3_bm_sysfs_init(struct kobject *neta_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(neta_kobj, &mv_bm_group);
+	if (err) {
+		pr_err(KERN_INFO "sysfs group failed for bm%d\n", err);
+		return err;
+	}
+
+	return err;
+}
+
+int mv_sysfs_exit(struct kobject *neta_kobj)
+{
+	sysfs_remove_group(neta_kobj, &mv_bm_group);
+
+	return 0;
+}
+
+
+int mv_pp3_bm_sysfs_init_main(void)
+{
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+	if (!pd) {
+		neta_sysfs = platform_device_register_simple("neta", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+	}
+	if (!pd) {
+		pr_err(KERN_ERR"%s: cannot find neta device\n", __func__);
+		return -1;
+	}
+
+	mv_pp3_bm_sysfs_init(&pd->kobj);
+
+	return 0;
+}
+void mv_eth_sysfs_exit_main(void)
+{
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "neta");
+	if (!pd) {
+		pr_err(KERN_ERR"%s: cannot find pp2 device\n", __func__);
+		return;
+	}
+
+	platform_device_unregister(neta_sysfs);
+
+	return;
+}
+
+
+/*
+Examples for running the functions above.
+
+1.	Set BM attributes
+		bm_attr_all_pools_def_set();
+2.	Init QM GPM pools (function bm_qm_gpm_pools_def_quick_init)
+		bm_qm_gpm_pools_def_quick_init( num_of_buffers,
+				qece_base_address_hi, qece_base_address_lo,
+					pl_base_address_hi, pl_base_address_lo);
+3.	Optional: Init QM DRAM pools (function )
+		bm_qm_dram_pools_def_quick_init(num_of_buffers,
+				qece_base_address_hi, qece_base_address_lo,
+					pl_base_address_hi, pl_base_address_lo);
+4.	Init GP purpose pool  - at least one (function bm_gp_pool_def_basic_init  or bm_gp_pool_def_quick_init )
+		bm_gp_pool_def_basic_init(pool, num_of_buffers, base_address_hi, base_address_lo, partition_model);
+		bm_gp_pool_def_quick_init(pool, num_of_buffers, fill_level, base_address_hi, base_address_lo, partition_model);
+5.	Enable BM (function bm_enable)
+		bm_enable();
+
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+echo > bm_open
+echo > bm_attr_all_pools_def_set
+echo > bm_attr_qm_pool_set 2 1 11 14 2 1
+echo > bm_attr_gp_pool_set 2 1 11 14 2 1
+echo > bm_enable_status_get
+echo > bm_qm_gpm_pools_def_quick_init  266
+echo > bm_qm_dram_pools_def_quick_init  416
+echo > bm_qm_gpm_pools_quick_init 416 16 32 30 59 16 15 16
+echo > bm_qm_dram_pools_quick_init 416 16 32 30 59 16 15 16
+echo > bm_pool_quick_init_status_get 0
+echo > bm_gp_pool_def_basic_init 10 416 1
+echo > bm_gp_pool_basic_init 10 16 1 1 0 16
+echo > bm_enable
+echo > bm_disable
+echo > bm_pool_fill_level_get 3
+echo > bm_vmid_set 11
+echo > bm_gp_pool_def_quick_init 10 416 256 1
+echo > bm_gp_pool_quick_init 10 416 256 1 1
+echo > bm_global_registers_dump
+echo > bm_pool_registers_dump 10
+echo > bm_bank_registers_dump 3
+echo > bm_cache_memory_dump 3
+echo > bm_idle_status_get
+echo > bm_pool_status_get 0 1 2 3
+echo > bm_idle_debug
+echo > bm_error_dump
+echo > bm_pool_memory_fill 0 16
+echo > bm_pool_dram_set 0 16 0 16
+echo > bm_pool_fill_level_set 0 16 1 1
+echo > bm_pool_enable 0 1
+echo > bm_gp_pool_pe_size_set 20 1
+echo > bm_gp_pool_pair_set 30 1
+echo > bm_pool_cache_set 0 10 16777216 16777316 50 16
+echo > bm_pool_disable 0
+
+
+
+*/
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_qm.h b/drivers/net/ethernet/marvell/pp3/bm/mv_qm.h
new file mode 100644
index 0000000..06cf72e
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_qm.h
@@ -0,0 +1,879 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS;OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef	__MV_QM_H__
+#define	__MV_QM_H__
+
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+
+/* Error Codes */
+#define QM_WRONG_MEMORY_TYPE           -EINVAL
+#define QM_ALIAS_ERROR                 -EINVAL
+#define QM_INPUT_NOT_IN_RANGE          -EINVAL
+
+/* Input definitions*/
+#define GPM_MEMORY_TYPE				 0
+#define DRAM_MEMORY_TYPE			 1
+#define GRANULARITY_OF_16_BYTES		16
+
+#define QM_QUEUE_PROFILE_INVALID			0x00000000	/*    0 */
+#define QM_QUEUE_PROFILE_0					0x00000001	/*    1 */
+#define QM_QUEUE_PROFILE_1					0x00000002	/*    2 */
+#define QM_QUEUE_PROFILE_2					0x00000003	/*    3 */
+#define QM_QUEUE_PROFILE_3					0x00000004	/*    4 */
+#define QM_QUEUE_PROFILE_4					0x00000005	/*    5 */
+#define QM_QUEUE_PROFILE_5					0x00000006	/*    6 */
+#define QM_QUEUE_PROFILE_6					0x00000007	/*    7 */
+
+
+/* Default values */
+#define QM_THR_HI_DEF			0x0000000C	/*  12 */
+#define QM_THR_LO_DEF			0x00000018	/*  24 */
+#define QM_GPM_QE_THR_HI_DEF	QM_THR_HI_DEF
+#define QM_GPM_QE_THR_LO_DEF	QM_THR_LO_DEF
+#define QM_GPM_PL_THR_HI_DEF	QM_THR_HI_DEF
+#define QM_GPM_PL_THR_LO_DEF	QM_THR_LO_DEF
+#define QM_DRAM_QE_THR_HI_DEF	QM_THR_HI_DEF
+#define QM_DRAM_QE_THR_LO_DEF	QM_THR_LO_DEF
+#define QM_DRAM_PL_THR_HI_DEF	QM_THR_HI_DEF
+#define QM_DRAM_PL_THR_LO_DEF	QM_THR_LO_DEF
+
+#define QM_POOL0_SID_NUM_DEF	QM_POOL0_SID_NUM_MAX
+#define QM_POOL1_SID_NUM_DEF	QM_POOL1_SID_NUM_MIN
+
+#define QM_CLASS_ARR_CMAC_EMAC_DEF	input_port	/*    0 */
+#define QM_CLASS_ARR_HMAC_DEF		0x00000008	/*    8 */
+#define QM_CLASS_ARR_PPC_DEF		0x00000009	/*    9 */
+#define QM_PORT_ARR_DEF				         0	/*    0 */
+#define QM_ARRAYS_SIZE_DEF			0x0000005A	/*   90 */
+
+#define QM_PORT_DEPTH_ARR_PPC0_DEF		    (2 * QM_SIZE_OF_PORT_DEPTH_ARR_PPC_IN_BYTES)	/* 2*144B */
+#define QM_PORT_DEPTH_ARR_PPC1_DEF		    (1 * QM_SIZE_OF_PORT_DEPTH_ARR_PPC_IN_BYTES)	/* 1*144B */
+#define QM_PORT_DEPTH_ARR_EMAC_DEF		  (160 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*  2560B */
+#define QM_PORT_DEPTH_ARR_CMAC0_DEF		  (160 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*  2560B */
+#define QM_PORT_DEPTH_ARR_CMAC1_DEF		   (32 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*   512B */
+#define QM_PORT_DEPTH_ARR_HMAC_DEF		   (32 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*   512B */
+
+#define QM_PORT_CREDIT_THR_ARR_EMAC_DEF		  (152 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*  2432B */
+#define QM_PORT_CREDIT_THR_ARR_CMAC0_DEF	  (152 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*  2432B */
+#define QM_PORT_CREDIT_THR_ARR_CMAC1_DEF	   (24 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*   384B */
+#define QM_PORT_CREDIT_THR_ARR_HMAC_DEF		   (24 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*   384B */
+
+#define QM_PORT_PPC_ARR_PPC0_DEF	    1	/* packets are processed by data        PPC */
+#define QM_PORT_PPC_ARR_PPC1_DEF	    2	/* packets are processed by maintenance PPC */
+
+#define QM_SWF_AWQOS_DEF			0x00000001	/*    1 */
+#define QM_RDMA_AWQOS_DEF			0x00000001	/*    1 */
+#define QM_HWF_QE_CE_AWQOS_DEF		0x00000001	/*    1 */
+#define QM_HWF_SFH_PL_AWQOS_DEF		0x00000001	/*    1 */
+
+#define QM_SWF_AWCACHE_DEF			0x0000000B	/*   11 */
+#define QM_RDMA_AWCACHE_DEF			0x0000000B	/*   11 */
+#define QM_HWF_QE_CE_AWCACHE_DEF	0x00000003	/*    3 */
+#define QM_HWF_SFH_PL_AWCACHE_DEF	0x00000003	/*    3 */
+
+#define QM_SWF_AWDOMAIN_DEF			0x00000002	/*    2 */
+#define QM_RDMA_AWDOMAIN_DEF		0x00000002	/*    2 */
+#define QM_HWF_QE_CE_AWDOMAIN_DEF	         0	/*    0 */
+#define QM_HWF_SFH_PL_AWDOMAIN_DEF	         0	/*    0 */
+
+#define QM_SWF_ARQOS_DEF			0x00000001	/*    1 */
+#define QM_RDMA_ARQOS_DEF			0x00000001	/*    1 */
+#define QM_HWF_QE_CE_ARQOS_DEF		0x00000001	/*    1 */
+#define QM_HWF_SFH_PL_ARQOS_DEF		0x00000001	/*    1 */
+
+#define QM_SWF_ARCACHE_DEF			0x0000000B	/*   11 */
+#define QM_RDMA_ARCACHE_DEF			0x0000000B	/*   11 */
+#define QM_HWF_QE_CE_ARCACHE_DEF	0x00000003	/*    3 */
+#define QM_HWF_SFH_PL_ARCACHE_DEF	0x00000003	/*    3 */
+
+#define QM_SWF_ARDOMAIN_DEF			0x00000002	/*    2 */
+#define QM_RDMA_ARDOMAIN_DEF		0x00000002	/*    2 */
+#define QM_HWF_QE_CE_ARDOMAIN_DEF	         0	/*    0 */
+#define QM_HWF_SFH_PL_ARDOMAIN_DEF	         0	/*    0 */
+
+/* Range Definitions */
+#define QM_QUEUE_MIN			         0	/*    0 */
+#define QM_QUEUE_MAX			0x00000200	/*  512 */
+#define QM_PORT_MIN				         0	/*    0 */
+#define QM_PORT_MAX				0x0000000F	/*   15 */
+#define QM_PORT_PPC_MIN			QM_PORT_MIN
+#define QM_PORT_PPC_MAX			0x00000002	/*    2 */
+#define QM_PORT_MAC_MIN			0x00000003	/*    3 */
+#define QM_PORT_MAC_MAX			0x0000000A	/*   10 */
+#define QM_QUEUE_PROFILE_MIN	         1	/*    1 */
+#define QM_QUEUE_PROFILE_MAX	0x00000007	/*    7 */
+
+#define QM_PPC_MIN				         0
+#define QM_PPC_MAX				0x7FFFFFFF
+#define QM_BASE_MIN				         0
+#define QM_BASE_MAX				0x7FFFFFFF
+#define QM_SIZE_MIN				         0
+#define QM_SIZE_MAX				0x7FFFFFFF
+
+#define QM_VMID_MIN				         0	/*   0 */
+#define QM_VMID_MAX				0x0000003F	/*  63 */
+#define QM_THR_MIN				         0	/*   0 */
+#define QM_THR_MAX				0x00000020	/*  32 */
+#define QM_GPM_QE_THR_HI_MIN	QM_THR_MIN
+#define QM_GPM_QE_THR_HI_MAX	QM_THR_MAX
+#define QM_GPM_QE_THR_LO_MIN	QM_THR_MIN
+#define QM_GPM_QE_THR_LO_MAX	QM_THR_MAX
+#define QM_GPM_PL_THR_HI_MIN	QM_THR_MIN
+#define QM_GPM_PL_THR_HI_MAX	QM_THR_MAX
+#define QM_GPM_PL_THR_LO_MIN	QM_THR_MIN
+#define QM_GPM_PL_THR_LO_MAX	QM_THR_MAX
+#define QM_DRAM_QE_THR_HI_MIN	QM_THR_MIN
+#define QM_DRAM_QE_THR_HI_MAX	QM_THR_MAX
+#define QM_DRAM_QE_THR_LO_MIN	QM_THR_MIN
+#define QM_DRAM_QE_THR_LO_MAX	QM_THR_MAX
+#define QM_DRAM_PL_THR_HI_MIN	QM_THR_MIN
+#define QM_DRAM_PL_THR_HI_MAX	QM_THR_MAX
+#define QM_DRAM_PL_THR_LO_MIN	QM_THR_MIN
+#define QM_DRAM_PL_THR_LO_MAX	QM_THR_MAX
+#define QM_POOL_SID_NUM_MIN		         0
+#define QM_POOL_SID_NUM_MAX		0x00001000	/* 4096 */
+
+#define QM_POOL0_SID_NUM_MIN	QM_POOL_SID_NUM_MIN
+#define QM_POOL0_SID_NUM_MAX	QM_POOL_SID_NUM_MAX
+#define QM_POOL1_SID_NUM_MIN	QM_POOL_SID_NUM_MIN
+#define QM_POOL1_SID_NUM_MAX	QM_POOL_SID_NUM_MAX
+
+#define QM_CLASS_ARR_MIN		         0	/*    0 */
+#define QM_CLASS_ARR_MAX		0x00000009	/*    9 */
+#define QM_PORT_ARR_MIN			         0	/*    0 */
+#define QM_PORT_ARR_MAX			0x00000001	/*    1 */
+#define QM_ARRAYS_SIZE_MIN		0x0000005A	/*   90 */
+#define QM_ARRAYS_SIZE_MAX		0x00000120	/*  288 */
+
+#define QM_INPUT_PORT_CMAC_EMAC_MIN	         0	/*    0 */
+#define QM_INPUT_PORT_CMAC_EMAC_MAX	0x00000007	/*    7 */
+#define QM_INPUT_PORT_HMAC_MIN		0x00000008	/*    8 */
+#define QM_INPUT_PORT_HMAC_MAX		0x00000047	/*   71 */
+#define QM_INPUT_PORT_PPC_MIN		0x00000048	/*   72 */
+#define QM_INPUT_PORT_PPC_MAX		0x00000059	/*   89 */
+
+#define QM_MEMORY_TYPE_MIN		         0
+#define QM_MEMORY_TYPE_MAX		         1
+
+#define QM_SIZE_OF_PORT_DEPTH_ARR_PPC_IN_BYTES		0x00000090	/*  144 */
+#define QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES		0x00000010	/*   16 */
+#define QM_SIZE_OF_PORT_CREDIT_THR_ARR_MAC_IN_BYTES	0x00000010	/*   16 */
+
+#define QM_PORT_DEPTH_ARR_MIN			     0	/*     0 */
+#define QM_PORT_DEPTH_ARR_SUM_MAX	0x00004000	/* 16384 */
+
+#define QM_PORT_CREDIT_THR_ARR_MIN	GRANULARITY_OF_16_BYTES	/*     16 */
+#define QM_PORT_CREDIT_THR_ARR_MAX	(data_fifo_depth_p - 8 * GRANULARITY_OF_16_BYTES)	/* 8 * 16 */
+
+#define QM_SWF_ARDOMAIN_MIN				         0	/*    0 */
+#define QM_SWF_ARDOMAIN_MAX				0x00000003	/*    3 */
+#define QM_SWF_ARCACHE_MIN				         0	/*    0 */
+#define QM_SWF_ARCACHE_MAX				0x0000000F	/*   15 */
+#define QM_SWF_ARQOS_MIN					     0	/*    0 */
+#define QM_SWF_ARQOS_MAX				0x00000003	/*    3 */
+
+#define QM_RDMA_ARDOMAIN_MIN			         0	/*    0 */
+#define QM_RDMA_ARDOMAIN_MAX			0x00000003	/*    3 */
+#define QM_RDMA_ARCACHE_MIN				         0	/*    0 */
+#define QM_RDMA_ARCACHE_MAX				0x0000000F	/*   15 */
+#define QM_RDMA_ARQOS_MIN					     0	/*    0 */
+#define QM_RDMA_ARQOS_MAX				0x00000003	/*    3 */
+
+#define QM_HWF_QE_CE_ARDOMAIN_MIN		         0	/*    0 */
+#define QM_HWF_QE_CE_ARDOMAIN_MAX		0x00000003	/*    3 */
+#define QM_HWF_QE_CE_ARCACHE_MIN		         0	/*    0 */
+#define QM_HWF_QE_CE_ARCACHE_MAX		0x0000000F	/*   15 */
+#define QM_HWF_QE_CE_ARQOS_MIN				     0	/*    0 */
+#define QM_HWF_QE_CE_ARQOS_MAX			0x00000003	/*    3 */
+
+#define QM_HWF_SFH_PL_ARQOS_MIN			         0	/*    0 */
+#define QM_HWF_SFH_PL_ARQOS_MAX			0x00000003	/*    3 */
+#define QM_HWF_SFH_PL_ARCACHE_MIN		         0	/*    0 */
+#define QM_HWF_SFH_PL_ARCACHE_MAX		0x0000000F	/*   15 */
+#define QM_HWF_SFH_PL_ARDOMAIN_MIN			     0	/*    0 */
+#define QM_HWF_SFH_PL_ARDOMAIN_MAX		0x00000003	/*    3 */
+
+#define QM_SWF_AWDOMAIN_MIN				         0	/*    0 */
+#define QM_SWF_AWDOMAIN_MAX				0x00000003	/*    3 */
+#define QM_SWF_AWCACHE_MIN				         0	/*    0 */
+#define QM_SWF_AWCACHE_MAX				0x0000000F	/*   15 */
+#define QM_SWF_AWQOS_MIN					     0	/*    0 */
+#define QM_SWF_AWQOS_MAX				0x00000003	/*    3 */
+
+#define QM_RDMA_AWDOMAIN_MIN			         0	/*    0 */
+#define QM_RDMA_AWDOMAIN_MAX			0x00000003	/*    3 */
+#define QM_RDMA_AWCACHE_MIN				         0	/*    0 */
+#define QM_RDMA_AWCACHE_MAX				0x0000000F	/*   15 */
+#define QM_RDMA_AWQOS_MIN					     0	/*    0 */
+#define QM_RDMA_AWQOS_MAX				0x00000003	/*    3 */
+
+#define QM_HWF_QE_CE_AWDOMAIN_MIN		         0	/*    0 */
+#define QM_HWF_QE_CE_AWDOMAIN_MAX		0x00000003	/*    3 */
+#define QM_HWF_QE_CE_AWCACHE_MIN		         0	/*    0 */
+#define QM_HWF_QE_CE_AWCACHE_MAX		0x0000000F	/*   15 */
+#define QM_HWF_QE_CE_AWQOS_MIN				     0	/*    0 */
+#define QM_HWF_QE_CE_AWQOS_MAX			0x00000003	/*    3 */
+
+#define QM_HWF_SFH_PL_AWQOS_MIN			         0	/*    0 */
+#define QM_HWF_SFH_PL_AWQOS_MAX			0x00000003	/*    3 */
+#define QM_HWF_SFH_PL_AWCACHE_MIN		         0	/*    0 */
+#define QM_HWF_SFH_PL_AWCACHE_MAX		0x0000000F	/*   15 */
+#define QM_HWF_SFH_PL_AWDOMAIN_MIN			     0	/*    0 */
+#define QM_HWF_SFH_PL_AWDOMAIN_MAX		0x00000003	/*    3 */
+
+#define QM_LOW_THRESHOLD_MIN				     0
+#define QM_LOW_THRESHOLD_MAX			0x7FFFFFFF
+#define QM_PAUSE_THRESHOLD_MIN			         0
+#define QM_PAUSE_THRESHOLD_MAX			0x7FFFFFFF
+#define QM_HIGH_THRESHOLD_MIN			         0
+#define QM_HIGH_THRESHOLD_MAX			0x7FFFFFFF
+#define QM_TRAFFIC_SOURCE_MIN			         0
+#define QM_TRAFFIC_SOURCE_MAX			0x7FFFFFFF
+#define QM_HOST_MIN				         0
+#define QM_HOST_MAX				         1
+#define QM_REORDER_CLASS_MIN	         0
+#define QM_REORDER_CLASS_MAX	        64
+#define QM_SID_MIN				         0
+#define QM_SID_MAX				0x7FFFFFFF
+#define QM_CMD_MIN				         0
+#define QM_CMD_MAX				0x7FFFFFFF
+
+/* typedef void *      qm_handle;*/
+
+/**
+ *
+ *  Return values:
+ *		0 - success
+ */
+int qm_open(void);
+
+/**
+ *
+ *  Return values:
+ *		0 - success
+ */
+int qm_close(void);
+
+/**
+ *
+ *  Return values:
+ *		0 - success
+ */
+int qm_restart(void);
+
+/**
+ *  Set base address in Dram for pool
+ *
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_base_address_pool_set(
+							u32 *pl_base_address, /* Payload DRAM base address */
+							u32 *qece_base_address);/* QE/CE DRAM base address */
+
+/**
+ *  Enables QM,
+ *  Configure DMA with GPM pool thresholds with default values
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_gpm_pools_def_enable(void);
+
+/**
+ *  Enables QM,
+ *  Configure DMA with GPM pool thresholds
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_gpm_pools_enable(
+				u32 qece_thr_hi, /* GPM qe pool (pool 0) high 32bits threshold */
+				u32 qece_thr_lo, /* GPM qe pool (pool 0) low 32bits threshold */
+				u32 pl_thr_hi, /* GPM payload pool (pool 1) hi 32bits threshold */
+				u32 pl_thr_lo);/* GPM payload pool (pool 1) low 32bits threshold */
+
+/**
+ *  Configure DMA with DRAM pool thresholds with default values
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_dram_pools_def_enable(void);
+
+/**
+ *  Configure DMA with DRAM pool thresholds
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_dram_pools_enable(
+				u32 qece_thr_hi, /* DRAM qe pool (pool 2) high 32bits threshold */
+				u32 qece_thr_lo, /* DRAM qe pool (pool 2) low 32bits threshold */
+				u32 pl_thr_hi, /* DRAM payload pool (pool 3) hi 32bits threshold */
+				u32 pl_thr_lo);/* DRAM payload pool (pool 3) low 32bits threshold */
+
+/**
+ *  Configures for each queue in DMA if the queue resides in GPM or in DRAM
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_queue_memory_type_set(
+				u32 queue, /* Queue number 0 to 511 */
+				u32 memory_type);/* Memory type 0 - for DRAM 1 - for GPM */
+
+/**
+ *  Disable prefetching of BM from DMA and PFE - TBD
+ *  Return values:
+ *		0 - success
+int qm_disable(void);
+TBD - ask yuval peleg defined bits to stops and bit to check if it is stopped
+*/
+
+/**
+ *  verify if there is any Queue (0 to 511),
+ *  that has a queue length larger than 0
+ *  Return values:
+ *		0 - success
+ */
+int qm_packets_in_queues(
+				u32 *status);
+
+/**
+ *  Set default for QM units for mandatory parameters
+ *  Return values:
+ *		0 - success
+ */
+int qm_default_set(void);
+
+/**
+ *  Set SID number for each pool (0 and 1) in REORDER unit with default values
+ *  Return values:
+ *		0 - success
+ */
+int qm_ru_pool_sid_number_def_set(void);
+
+/**
+ *  Set SID number for each pool (0 and 1) in REORDER unit
+ *  Return values:
+ *		0 - success
+ */
+int qm_ru_pool_sid_number_set(
+				u32 pool0_sid_num, /* SID number fo pool 0. Total number of SID is 4k */
+				u32 pool1_sid_num);/* SID number fo pool 1. Total number of SID is 4k */
+
+/**
+ * Configure REORDER with class command when permission is granted with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_ru_port_to_class_def_set(void);
+
+/**
+ * Configure REORDER with class command when permission is granted.
+ *  Return values:
+ *		0 - success
+ */
+int qm_ru_port_to_class_set(
+				u32 *port_class_arr, /* class number in reorder unit. 0 to 63 */
+				u32 *port_pool_arr, /* holds pool  values which are either 0 or 1 */
+				u32 input_port);/* input port that arrive with the packet. 0 to 287 */
+/*
+				u32 reorder_class, / * class number in reorder unit. 0 to 63 * /
+				u32 input_port, / * input port that arrive with the packet. 0 to 287 * /
+*/
+
+/**
+ *  Configure DQF fifo base and depth thresholds with default values
+ *  Return values:
+ *		0 - success
+ */
+int qm_dqf_port_data_fifo_def_set(void);
+
+/**
+ *  Configure DQF fifo base and depth thresholds
+ *  Return values:
+ *		0 - success
+ */
+int qm_dqf_port_data_fifo_set(
+				u32 *port_depth_arr);/* holds depth in Bytes for ports 0 to 15 */
+
+/**
+ *  Configure DQF fifo credit thresholds with default values
+ *  Return values:
+ *		0 - success
+ */
+int qm_dqf_port_credit_thr_def_set(void);
+
+/**
+ *  Configure DQF fifo credit thresholds
+ *  Return values:
+ *		0 - success
+ */
+int qm_dqf_port_credit_thr_set(
+				u32 *port_credit_thr_arr);/* Configures credits thresholds for xMac input ports */
+
+/**
+ *  Configure DQF for each port which PPC (data or maintenance) handles the packet,
+ *  relevant only for PPC port with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dqf_port_ppc_map_def_set(void);
+
+/**
+ *  Configure DQF for each port which PPC (data or maintenance) handles the packet,
+ *  relevant only for PPC port.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dqf_port_ppc_map_set(
+				u32 *port_ppc_arr, /* holds indication which PPC process packets from this port */
+				u32 port);/* input ports */
+
+/**
+ *  Configure DMA QOS write attributes with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_qos_attr_def_set(void);
+
+/**
+ *  Configure DMA QOS write attributes.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_qos_attr_set(
+				u32 swf_awqos,
+				u32 rdma_awqos,
+				u32 hwf_qe_ce_awqos,
+				u32 hwf_sfh_pl_awqos);
+
+/**
+ *  Configure DMA CACHE write attributes with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_cache_attr_def_set(void);
+
+/**
+ *  Configure DMA CACHE write attributes.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_cache_attr_set(
+				u32 swf_awcache,
+				u32 rdma_awcache,
+				u32 hwf_qe_ce_awcache,
+				u32 hwf_sfh_pl_awcache);
+
+/**
+ *  Configure DMA DOMAIN write attributes with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_domain_attr_def_set(void);
+
+/**
+ *  Configure DMA DOMAIN write attributes.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_domain_attr_set(
+				u32 swf_awdomain,
+				u32 rdma_awdomain,
+				u32 hwf_qe_ce_awdomain,
+				u32 hwf_sfh_pl_awdomain);
+
+/**
+ *  Configure PFE QOS read attributes with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_qos_attr_def_set(void);
+
+/**
+ *  Configure PFE QOS read attributes.
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_qos_attr_set(
+				u32 swf_arqos,
+				u32 rdma_arqos,
+				u32 hwf_qe_ce_arqos,
+				u32 hwf_sfh_pl_arqos);
+
+/**
+ *  Configure PFE CACHE read attributes with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_cache_attr_def_set(void);
+
+/**
+ *  Configure PFE CACHE read attributes.
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_cache_attr_set(
+				u32 swf_arcache,
+				u32 rdma_arcache,
+				u32 hwf_qe_ce_arcache,
+				u32 hwf_sfh_pl_arcache);
+
+/**
+ *  Configure PFE DOMAIN read attributes with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_domain_attr_def_set(void);
+
+/**
+ *  Configure PFE DOMAIN read attributes.
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_domain_attr_set(
+				u32 swf_ardomain,
+				u32 rdma_ardomain,
+				u32 hwf_qe_ce_ardomain,
+				u32 hwf_sfh_pl_ardomain);
+
+/**
+ *  Configures per queue threshold profile with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_ql_q_profile_def_set(void);
+
+/**
+ *  Configures per queue threshold profile.
+ *  Return values:
+ *		0 - success
+ */
+int qm_ql_q_profile_set(
+				u32 queue_profile,
+				u32 queue);
+
+/**
+ *  Configures QL threshold for pause, on (low) and off (high)
+ *  and the to whom to send it (source) with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_ql_thr_def_set(void);
+
+/**
+ *  Configures QL threshold for pause, on (low) and off (high)
+ *  and the to whom to send it (source).
+ *  Return values:
+ *		0 - success
+ */
+int qm_ql_thr_set(
+				u32 low_threshold,
+				u32 pause_threshold,
+				u32 high_threshold,
+				u32 traffic_source,
+				u32 queue_profile);
+
+
+/**
+ *  Configure DMA write attributes for software forwarding mode
+ *  Return values:
+ *		0 - success
+ */
+int qm_axi_swf_write_attr_set(
+						u32 qos,
+						u32 cache,
+						u32 domain);
+
+/**
+ *  Configure DMA write attributes for rdma mode
+ *  Return values:
+ *		0 - success
+ */
+int qm_axi_rdma_write_attr_set(
+						u32 qos,
+						u32 cache,
+						u32 domain);
+
+/**
+ *  Configure DMA write attributes for hardware forwarding mode for qe/ce
+ *  Return values:
+ *		0 - success
+ */
+int qm_axi_hwf_qece_write_attr_set(
+						u32 qos,
+						u32 cache,
+						u32 domain);
+
+/**
+ *  Configure DMA write attributes for hardware forwarding mode for payload
+ *  Return values:
+ *		0 - success
+ */
+int qm_axi_hwf_pyl_write_attr_set(
+						u32 qos,
+						u32 cache,
+						u32 domain);
+
+
+/**
+ *  Initiate QM DRAM pools
+ *	Configures BM for pool initialization and enable the pool.  Doesn't configure cache parameters.
+ *  This function is a super set of several bm function that are listed below
+ *  Note: No change can be made to pool after this function is called.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dram_qm_pool_quick_init(
+		u32 pool, /* pool number: 2 or 3 */
+		u32 num_of_buffers,  /* number of buffers/PEs in pool max pool = 2M x 8B*/
+		u32 base_address_hi, /* hi part of DRAM base address */
+		u32 base_address_lo, /* low part of DRAM base address */
+		u32 ae_thr, /* almost empty threshold for pool */
+		u32 af_thr);/* almost full threshold for pool */
+
+/**
+ *  Enables DMA and PFE by configuring the registers that represents GPM and DRAM thresholds
+ *  Note: BM is not enabled from here since BM should be enabled the last
+ *  Return values:
+ *		0 - success
+ */
+int qm_enable(
+			u32 gpm_qe_thr_hi,
+			u32 gpm_qe_thr_lo,
+			u32 gpm_pl_thr_hi,
+			u32 gpm_pl_thr_lo,
+			u32 dram_qe_thr_hi,
+			u32 dram_qe_thr_lo,
+			u32 dram_pl_thr_hi,
+			u32 dram_pl_thr_lo);
+
+
+/**
+ *  Get Idle status from DMA
+ *  Return values:
+ *		0 - success
+ */
+int qm_idle_status_get(
+			u32 *dma_status);/* DMA status is output to the called */
+
+/**
+ *  Set VMID in DMA and PFE
+ *  Return values:
+ *		0 - success
+ */
+int qm_vmid_set(u32 qm_vmid);/* VMID value for DAM and PFE */
+int dma_vmid_set(u32 qm_vmid);/* VMID value for DAM and PFE */
+int pfe_vmid_set(u32 qm_vmid);/* VMID value for DAM and PFE */
+
+
+/**
+ *  Interupts handling - TBD
+ *  Return values:
+ *		0 - success
+ */
+int qm_inter_read(
+					u32 group,
+					u32 *dataPtr);
+
+/**
+ *  Interupts handling - TBD
+ *  Return values:
+ *		0 - success
+ */
+int qm_inter_clean(
+					u32 group);
+
+/**
+ *  Interupts handling - TBD
+ *  Return values:
+ *		0 - success
+ */
+int qm_inter_mask(
+					u32 group,
+					u32 mask);
+
+/**
+ *  Errors handling - TBD
+ *  Return values:
+ *		0 - success
+ */
+int qm_error_read(
+					u32 group,
+					u32 *dataPtr);
+
+/**
+ *  Errors handling - TBD
+ *  Return values:
+ *		0 - success
+ */
+int qm_error_clean(
+					u32 group);
+
+/**
+ *  Errors handling - TBD
+ *  Return values:
+ *		0 - success
+ */
+int qm_error_mask(
+					u32 group,
+					u32 mask);
+
+/**
+ *  Dump registers values from all modules apart of BM
+ *  Return values:
+ *		0 - success
+ */
+int qm_debug_dump_registers(void);
+
+/**
+ *  Configre PFE to start Flushing Queue. This process takes a while.
+ *  Indication for its completion is when Queue is empty
+ *  Return values:
+ *		0 - success
+ */
+int qm_queue_flush_start(
+						u32 queue);/* queue number from 0 to 511 */
+
+/**
+ *  Configure PFE to stop Flushing Queue.
+ *  Return values:
+ *		0 - success
+ */
+int qm_queue_flush_stop(u32 queue);
+
+/**
+ *  Configre PFE to start Flushing Port. This process takes a while.
+ *  Indication for its completion is when Port is empty
+ *  Return values:
+ *		0 - success
+ */
+int qm_port_flush_start(
+							u32 port);/* port number from 0 to 15 */
+
+/**
+ *  Configure PFE to stop Flushing Port.
+ *  Return values:
+ *		0 - success
+ */
+int qm_port_flush_stop(
+						u32 port);/* port number from 0 to 15 */
+
+/**
+ *  Get from DQF read and write pointers for specific port
+ *  Return values:
+ *		0 - success
+ */
+int qm_port_fifo_ptr_get(
+						u32 port, /* port number 0 to 15 */
+						u32 *read,
+						u32 *write);
+
+/**
+ *  Configures QL thresholds for EMAC and HMAC (configured per source )
+ *  Return values:
+ *		0 - success
+ */
+int qm_ql_source_thr_set(
+				u32 low, /* low threshold: beneath it will turn ON*/
+				u32 pause, /* pause threshold above it will send PAUSE*/
+				u32 high, /* high threshold above it will turn OFF*/
+				u32 source);/* source 0 to 6 */
+
+/**
+ *  Get head of class from REORDER unit
+ *  Return values:
+ *		0 - success
+ */
+int qm_class_head_get(
+					u32 reorder_class, /* class number in reorder unit. 0 to 63 */
+					u32 *head);/* output to caller */
+
+/**
+ * Configure REORDER with class command when permission is granted.
+ *  Return values:
+ *		0 - success
+ */
+int qm_class_cmd_set(
+					u32 host,
+					u32 reorder_class, /* class number in reorder unit. 0 to 63 */
+					u32 sid, /* sid is in the range 0 to 4k */
+					u32 cmd);/* cmd is either update or release */
+
+/**
+ *  Write QM register
+ *  Return values:
+ *		0 - success
+ */
+int qm_register_write(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr);
+
+/**
+ *  Read QM register
+ *  Return values:
+ *		0 - success
+ */
+int qm_register_read(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr);
+
+
+#endif /* MV_QM_H */
diff --git a/drivers/net/ethernet/marvell/pp3/common/mv_hw_if.h b/drivers/net/ethernet/marvell/pp3/common/mv_hw_if.h
index 861b7bf..4fbd9be 100644
--- a/drivers/net/ethernet/marvell/pp3/common/mv_hw_if.h
+++ b/drivers/net/ethernet/marvell/pp3/common/mv_hw_if.h
@@ -68,6 +68,13 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #include <linux/kernel.h>
 #include <linux/io.h>
 
+struct mv_word40 {
+	u32 lo;				/* byte[ 0- 7],bit[ 0-31] */
+	u8  hi;				/* byte[ 0- 7],bit[32-39] */
+	u8 _reserved_6[3];		/* byte[ 0- 7],bit[40-63] */
+};
+
+
 struct pp3_unit_info {
 	u32 base_addr; /* unit base address = silicon addr + unit offset */
 	u32 ins_offs;  /* unit instance offset - for multiple units */
diff --git a/drivers/net/ethernet/marvell/pp3/common/mv_sw_if.h b/drivers/net/ethernet/marvell/pp3/common/mv_sw_if.h
index 24ee432..db271d9 100644
--- a/drivers/net/ethernet/marvell/pp3/common/mv_sw_if.h
+++ b/drivers/net/ethernet/marvell/pp3/common/mv_sw_if.h
@@ -73,6 +73,8 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #include <linux/netdevice.h>
 #include <linux/platform_device.h>
 
+#define __ATTRIBUTE_PACKED__	__packed
+#define MV_MALLOC	kmalloc
 
 #define	MV_MAC_ADDR_SIZE	(6)
 #define MV_MAC_STR_SIZE		(20)
@@ -128,4 +130,18 @@ do {								\
 /* Sets the field located at the specified in data.     */
 #define U32_SET_FIELD(data, mask, val)		((data) = (((data) & ~(mask)) | (val)))
 
+/* QM/BM related */
+#define MV_MIN(a , b) (((a) < (b)) ? (a) : (b))
+#define MV_MAX(a , b) (((a) > (b)) ? (a) : (b))
+
+#define UNIT_OF__8_BYTES  8
+#define UNIT_OF_64_BYTES 64
+
+/* Error definitions*/
+/* Error Codes */
+
+#define OK                                  0
+#define ON                                  1
+#define OFF                                 0
+
 #endif /* __mvSwIf_h__ */
-- 
1.7.5.4

