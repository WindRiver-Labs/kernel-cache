From 0c604d01733376cd0cc1f1485cf22885233d8bcf Mon Sep 17 00:00:00 2001
From: Kosta Zertsekel <konszert@marvell.com>
Date: Mon, 11 Mar 2013 18:02:11 +0200
Subject: [PATCH 0462/1825] PPv2: add support for PPv2 network driver

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit 52dcd74b7b3abfe3ded77d05eac45c7de682fc6f

Signed-off-by: Kosta Zertsekel <konszert@marvell.com>
Change-Id: I757b0bcf85628d17eaf4ffbffb91bf79f70ef6f0
Reviewed-on: http://vgitil04.il.marvell.com:8080/1250
Reviewed-by: Eran Ben-Avi <benavi@marvell.com>
Tested-by: Eran Ben-Avi <benavi@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 arch/arm/mach-avantalp/Kconfig                     |   36 +-
 arch/arm/mach-avantalp/Makefile                    |   46 +-
 arch/arm/mach-avantalp/config/mvRules.mk           |   19 +
 arch/arm/mach-avantalp/config/mvSysEthConfig.h     |   24 +-
 arch/arm/mach-avantalp/config/mvSysHwConfig.h      |    3 +
 arch/arm/mach-avantalp/core.c                      |  213 +-
 arch/arm/mach-avantalp/mv_hal_if/mvSysEthPhy.c     |   11 +-
 arch/arm/mach-avantalp/mv_hal_if/mvSysPp2.c        |  137 +
 arch/arm/mach-avantalp/mv_hal_if/mvSysPp2Api.h     |   71 +
 arch/arm/plat-armada/Kconfig                       |   60 +-
 .../plat-armada/mv_drivers_lsp/mv_phy/phy_sysfs.c  |    5 +-
 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig |  764 +++
 .../mv_drivers_lsp/mv_pp2/bm/mv_eth_bm.c           |  276 ++
 .../mv_drivers_lsp/mv_pp2/cls/cls2_sysfs.c         |  334 ++
 .../mv_drivers_lsp/mv_pp2/cls/cls3_sysfs.c         |  373 ++
 .../mv_drivers_lsp/mv_pp2/cls/cls4_sysfs.c         |  274 ++
 .../mv_drivers_lsp/mv_pp2/cls/cls_mc_sysfs.c       |  207 +
 .../mv_drivers_lsp/mv_pp2/cls/cls_sysfs.c          |  324 ++
 .../mv_drivers_lsp/mv_pp2/net_dev/Makefile         |   27 +
 .../mv_pp2/net_dev/mv_eth_bm_sysfs.c               |  134 +
 .../mv_pp2/net_dev/mv_eth_napi_sysfs.c             |  171 +
 .../mv_pp2/net_dev/mv_eth_pme_sysfs.c              |  134 +
 .../mv_pp2/net_dev/mv_eth_pon_sysfs.c              |  162 +
 .../mv_pp2/net_dev/mv_eth_qos_sysfs.c              |  156 +
 .../mv_pp2/net_dev/mv_eth_rx_sysfs.c               |  147 +
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_eth_switch.c  |  791 ++++
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.c   |  284 ++
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h   |   47 +
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.c    |  948 ++++
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.h    |   35 +
 .../mv_pp2/net_dev/mv_eth_tx_sched_sysfs.c         |  153 +
 .../mv_pp2/net_dev/mv_eth_tx_sysfs.c               |  155 +
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_ethernet.c    |  351 ++
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_fpga_sysfs.c  |  218 +
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c      | 4966 ++++++++++++++++++++
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h      |  859 ++++
 .../mv_drivers_lsp/mv_pp2/plcr/plcr_sysfs.c        |  213 +
 .../mv_drivers_lsp/mv_pp2/pme/pme_sysfs.c          |  334 ++
 .../mv_drivers_lsp/mv_pp2/prs/prs_sysfs.c          |  289 ++
 include/linux/mv_pp2.h                             |  109 +
 40 files changed, 13743 insertions(+), 117 deletions(-)
 create mode 100644 arch/arm/mach-avantalp/mv_hal_if/mvSysPp2.c
 create mode 100644 arch/arm/mach-avantalp/mv_hal_if/mvSysPp2Api.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/bm/mv_eth_bm.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls2_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls3_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls4_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls_mc_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/Makefile
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_bm_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_napi_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pme_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pon_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_qos_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_rx_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_switch.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tx_sched_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tx_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_ethernet.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_fpga_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/plcr/plcr_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/pme/pme_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/prs/prs_sysfs.c
 create mode 100644 include/linux/mv_pp2.h

diff --git a/arch/arm/mach-avantalp/Kconfig b/arch/arm/mach-avantalp/Kconfig
index 836f843..7d0f567 100644
--- a/arch/arm/mach-avantalp/Kconfig
+++ b/arch/arm/mach-avantalp/Kconfig
@@ -1,11 +1,10 @@
 if ARCH_AVANTA_LP
 
 config  MV_HAL_RULES_PATH
-        string "path of the mvRules.mk file for HAL drivers"
-        default "arch/arm/mach-avantalp/mv_hal_support/mvRules.mk"
-        ---help---
-
-#source "arch/arm/plat-orion/mv_hal_drivers/Kconfig"
+	string "path of the mvRules.mk file for HAL drivers"
+	default "arch/arm/mach-avantalp/mv_hal_support/mvRules.mk"
+	help
+	  No help currently.
 
 menu "Marvell Avanta Options"
 
@@ -35,6 +34,7 @@ config MACH_AVANTA_LP_FPGA
 	select MACH_GENERAL_FPGA
 	default y
 	help
+	  No help currently.
 
 config MACH_GENERAL_FPGA
 	bool "Marvell FPGA Development Board"
@@ -47,6 +47,7 @@ config CFU_DRAM_BYPASS
         bool "Bypass CFU to DRAM via Punit"
 	default n
 	help
+	  No help currently.
 
 config AVANTA_LP_SPARSEMEM
 	bool "Use sparse memory model"
@@ -57,20 +58,21 @@ config AVANTA_LP_USE_IRQ_INDIRECT_MODE
 	bool "Use indirect mode for handling interrupt controller"
 	default n
 	help
-		This mode enables using indirect mode for handling interrupts, in this
-		mode, the Interrupt Set Enable/Clear Enable registers are used for
-		unmasking/masking shared interrupts, and Interrupt Set Mask/Clear Mask
-		used for masking/unmasking per-cpu interrupts. Without this mode, the
-		Interrupt Source register is used directly. and this requires the
-		following:
-		- Locking mechanism to protect the access to the Interrupt Source Register
-		- Reads operation of those registers.
-		- Using the affinity variable for restoring the mask values
+	  This mode enables using indirect mode for handling interrupts, in this
+	  mode, the Interrupt Set Enable/Clear Enable registers are used for
+	  unmasking/masking shared interrupts, and Interrupt Set Mask/Clear Mask
+	  used for masking/unmasking per-cpu interrupts. Without this mode, the
+	  Interrupt Source register is used directly. and this requires the
+	  following:
+	  Locking mechanism to protect the access to the Interrupt Source Register
+	  Reads operation of those registers.
+	  Using the affinity variable for restoring the mask values
 
 config AVANTA_LP_USE_IRQ_INTERRUPT_ACK
-       bool "Use Interrupt Ack register to detect pending interrupts"
-       default n
-       help
+	bool "Use Interrupt Ack register to detect pending interrupts"
+	default n
+	help
+	  No help currently.
 
 endmenu
 
diff --git a/arch/arm/mach-avantalp/Makefile b/arch/arm/mach-avantalp/Makefile
index 898113b..2e24948 100644
--- a/arch/arm/mach-avantalp/Makefile
+++ b/arch/arm/mach-avantalp/Makefile
@@ -65,7 +65,7 @@ avantalp-$(CONFIG_MV_INCLUDE_PEX) 	+= $(HAL_PEX_DIR)/mvPex.o					\
 avantalp-$(CONFIG_MV_INCLUDE_PCI) 	+= $(HAL_PCI_DIR)/mvPci.o $(HAL_IF_DIR)/mvSysPci.o
 avantalp-$(CONFIG_MV_INCLUDE_USB) 	+= $(HAL_USB_DIR)/mvUsb.o $(HAL_USB_DIR)/mvUsbAddrDec.o		\
 					   $(HAL_IF_DIR)/mvSysUsb.o
-avantalp-y				+= $(HAL_ETHPHY_DIR)/mvEthPhy.o $(HAL_IF_DIR)/mvSysEthPhy.o
+avantalp-$(CONFIG_MV_INCLUDE_ETH_PHY)	+= $(HAL_ETHPHY_DIR)/mvEthPhy.o $(HAL_IF_DIR)/mvSysEthPhy.o
 
 # Legacy Giga driver
 ifeq ($(CONFIG_MV_ETH_LEGACY),y)
@@ -86,6 +86,21 @@ avantalp-$(CONFIG_MV_ETH_PMT)	        += $(HAL_ETH_PMT_DIR)/mvPmt.o
 avantalp-$(CONFIG_MV_ETH_HWF)           += $(HAL_ETH_GBE_DIR)/mvHwf.o
 endif
 
+ifeq ($(CONFIG_MV_ETH_PP2),y)
+avantalp-$(CONFIG_MV_ETH_PP2)		+= $(HAL_ETH_GMAC_DIR)/mvEthGmacApi.o
+avantalp-$(CONFIG_MV_ETH_PP2)		+= $(HAL_ETH_GBE_DIR)/mvPp2Gbe.o $(HAL_ETH_GBE_DIR)/mvPp2GbeDebug.o \
+					   $(HAL_ETH_GBE_DIR)/mvPp2AddrDec.o $(HAL_IF_DIR)/mvSysPp2.o
+avantalp-$(CONFIG_MV_ETH_PP2)		+= $(HAL_ETH_BM_DIR)/mvBm.o
+avantalp-$(CONFIG_MV_ETH_PP2)		+= $(HAL_ETH_PRS_DIR)/mvPp2PrsHw.o $(HAL_ETH_PRS_DIR)/mvPp2Prs.o
+avantalp-$(CONFIG_MV_ETH_PP2)		+= $(HAL_ETH_CLS_DIR)/mvPp2ClsHw.o $(HAL_ETH_CLS_DIR)/mvPp2Cls2Hw.o \
+					   $(HAL_ETH_CLS_DIR)/mvPp2Cls3Hw.o $(HAL_ETH_CLS_DIR)/mvPp2Cls4Hw.o \
+					   $(HAL_ETH_CLS_DIR)/mvPp2ClsMcHw.o $(HAL_ETH_CLS_DIR)/mvPp2Classifier.o
+avantalp-$(CONFIG_MV_ETH_PP2)		+= $(HAL_ETH_PME_DIR)/mvPp2PmeHw.o
+avantalp-$(CONFIG_MV_ETH_PP2)		+= $(HAL_ETH_PLCR_DIR)/mvPp2PlcrHw.o
+avantalp-$(CONFIG_MV_ETH_PP2)		+= $(HAL_ETH_BM_DIR)/mvBm.o
+avantalp-$(CONFIG_MV_ETH_PP2)		+= $(HAL_ETH_COMMON)/mvPp2Common.o
+endif
+
 avantalp-$(CONFIG_MV_INCLUDE_CESA) 	+= $(HAL_CESA_DIR)/mvCesa.o $(HAL_CESA_DIR)/mvCesaIf.o		\
 					   $(HAL_CESA_DIR)/mvCesaDebug.o 				\
 					   $(HAL_CESA_DIR)/mvCesaAddrDec.o				\
@@ -127,7 +142,34 @@ obj-$(CONFIG_MV_ETH_L2FW)               += $(LSP_L2FW_DIR)/l2fw_sysfs.o $(LSP_L2
 obj-$(CONFIG_MV_ETH_L2SEC)              += $(LSP_L2FW_DIR)/mv_eth_l2sec.o
 endif
 
-obj-$(CONFIG_MV_INCLUDE_GIG_ETH)        += $(LSP_PHY_DIR)/phy_sysfs.o
+################################################################################
+ifeq ($(CONFIG_MV_ETH_PP2),y)
+obj-$(CONFIG_MV_ETH_PP2)		+= $(LSP_NET_DEV_DIR)/mv_netdev.o \
+					   $(LSP_NET_DEV_DIR)/mv_ethernet.o \
+					   $(LSP_NET_DEV_DIR)/mv_eth_sysfs.o \
+					   $(LSP_NET_DEV_DIR)/mv_eth_bm_sysfs.o \
+					   $(LSP_NET_DEV_DIR)/mv_eth_napi_sysfs.o \
+					   $(LSP_NET_DEV_DIR)/mv_eth_rx_sysfs.o \
+					   $(LSP_NET_DEV_DIR)/mv_eth_tx_sysfs.o \
+					   $(LSP_NET_DEV_DIR)/mv_eth_tx_sched_sysfs.o \
+					   $(LSP_NET_DEV_DIR)/mv_eth_qos_sysfs.o \
+					   $(LSP_NET_DEV_DIR)/mv_eth_pon_sysfs.o \
+					   $(LSP_NET_DEV_DIR)/mv_eth_pme_sysfs.o
+obj-$(CONFIG_MV_ETH_PP2)		+= $(LSP_NET_DEV_DIR)/mv_fpga_sysfs.o
+obj-$(CONFIG_MV_ETH_SWITCH)		+= $(LSP_NET_DEV_DIR)/mv_eth_switch.o
+obj-$(CONFIG_MV_ETH_PP2)		+= $(LSP_BM_DIR)/mv_eth_bm.o
+obj-$(CONFIG_MV_ETH_PP2)		+= $(LSP_PRS_DIR)/prs_sysfs.o
+obj-$(CONFIG_MV_ETH_PP2)		+= $(LSP_CLS_DIR)/cls_sysfs.o \
+					   $(LSP_CLS_DIR)/cls2_sysfs.o \
+					   $(LSP_CLS_DIR)/cls3_sysfs.o \
+					   $(LSP_CLS_DIR)/cls4_sysfs.o
+obj-$(CONFIG_MV_ETH_PP2)		+= $(LSP_CLS_DIR)/cls_mc_sysfs.o
+obj-$(CONFIG_MV_ETH_PP2)		+= $(LSP_PME_DIR)/pme_sysfs.o
+obj-$(CONFIG_MV_ETH_PP2)		+= $(LSP_PLCR_DIR)/plcr_sysfs.o
+obj-$(CONFIG_MV_ETH_TOOL)		+= $(LSP_NET_DEV_DIR)/mv_eth_tool.o
+endif
+
+obj-$(CONFIG_MV_INCLUDE_GIG_ETH)	+= $(LSP_PHY_DIR)/phy_sysfs.o
 
 obj-$(CONFIG_MV_USE_XOR_ENGINE) 	+= $(PLAT_DRIVERS)/mv_xor/
 obj-$(CONFIG_MV_CESA) 			+= $(PLAT_DRIVERS)/mv_cesa/
diff --git a/arch/arm/mach-avantalp/config/mvRules.mk b/arch/arm/mach-avantalp/config/mvRules.mk
index 95fdde7..d51b6b4 100644
--- a/arch/arm/mach-avantalp/config/mvRules.mk
+++ b/arch/arm/mach-avantalp/config/mvRules.mk
@@ -42,6 +42,25 @@ HAL_TWSI_DIR      = $(HAL_DIR)/twsi
 HAL_TWSI_ARCH_DIR = $(SOC_TWSI_DIR)/Arch$(CPU_ARCH)
 HAL_UART_DIR      = $(HAL_DIR)/uart
 
+ifeq ($(CONFIG_MV_ETH_PP2),y)
+HAL_ETH_DIR	  = $(HAL_DIR)/pp2
+HAL_ETH_GMAC_DIR  = $(HAL_DIR)/pp2/gmac
+HAL_ETH_GBE_DIR   = $(HAL_DIR)/pp2/gbe
+HAL_ETH_BM_DIR    = $(HAL_DIR)/pp2/bm
+HAL_ETH_PRS_DIR   = $(HAL_DIR)/pp2/prs
+HAL_ETH_CLS_DIR   = $(HAL_DIR)/pp2/cls
+HAL_ETH_PME_DIR   = $(HAL_DIR)/pp2/pme
+HAL_ETH_PLCR_DIR  = $(HAL_DIR)/pp2/plcr
+HAL_ETH_COMMON    = $(HAL_DIR)/pp2/common
+LSP_NETWORK_DIR   = $(PLAT_DRIVERS)/mv_pp2
+LSP_NET_DEV_DIR   = $(LSP_NETWORK_DIR)/net_dev
+LSP_BM_DIR        = $(LSP_NETWORK_DIR)/bm
+LSP_PRS_DIR       = $(LSP_NETWORK_DIR)/prs
+LSP_CLS_DIR       = $(LSP_NETWORK_DIR)/cls
+LSP_PME_DIR       = $(LSP_NETWORK_DIR)/pme
+LSP_PLCR_DIR      = $(LSP_NETWORK_DIR)/plcr
+endif
+
 ifeq ($(CONFIG_MV_ETH_NETA),y)
 HAL_ETH_DIR       = $(HAL_DIR)/neta 
 HAL_ETH_GBE_DIR   = $(HAL_DIR)/neta/gbe
diff --git a/arch/arm/mach-avantalp/config/mvSysEthConfig.h b/arch/arm/mach-avantalp/config/mvSysEthConfig.h
index 62f898e..c8d0040 100644
--- a/arch/arm/mach-avantalp/config/mvSysEthConfig.h
+++ b/arch/arm/mach-avantalp/config/mvSysEthConfig.h
@@ -79,33 +79,17 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #include "mvSysHwConfig.h"
 #include "ctrlEnv/mvCtrlEnvSpec.h"
 
-/*
-** Base address for ethernet registers.
-*/
-#ifdef CONFIG_MV_PON
-#define MV_PON_PORT_ID_GET()	MV_PON_PORT_ID
-#define MV_PON_PORT(p)		((p) == MV_PON_PORT_ID)
-#define MV_PON_REG_BASE         MV_PON_REGS_OFFSET
-#define MV_ETH_REGS_BASE(p)	(MV_PON_PORT(p) ? MV_PON_REGS_OFFSET : MV_ETH_REGS_OFFSET(p))
-#else
-#define MV_PON_PORT(p)		MV_FALSE
-#define MV_ETH_REGS_BASE(p)	MV_ETH_REGS_OFFSET(p)
-#endif /* CONFIG_MV_PON */ 
-
-#define MV_BM_REG_BASE		MV_BM_REGS_OFFSET
-#define MV_PNC_REG_BASE         MV_PNC_REGS_OFFSET
 #define MV_ETH_COMPLEX_BASE		(MV_ETH_COMPLEX_OFFSET)
 #define MV_ETH_ONLY_REGS_BASE		(MV_ETH_ONLY_REGS_OFFSET)
 
 #if defined(CONFIG_MV_INCLUDE_GIG_ETH)
-
 /* put descriptors in uncached memory */
 /* #define ETH_DESCR_UNCACHED */
 
 /* port's default queueus */
-#define ETH_DEF_RXQ         0  
+#define ETH_DEF_RXQ         0
 
-#ifdef CONFIG_MV_ETH_LEGACY 
+#ifdef CONFIG_MV_ETH_LEGACY
 
 #ifdef CONFIG_MV_NFP_STATS
 #define MV_FP_STATISTICS
@@ -135,7 +119,7 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #else
  #define ETH_DESCR_CONFIG_STR    "Cached descriptors in DRAM"
 #endif
-#else 
+#else
  #error "Ethernet descriptors location undefined"
 #endif /* ETH_DESCR_IN_SRAM or ETH_DESCR_IN_SDRAM*/
 
@@ -149,7 +133,7 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #ifndef MV_CACHE_COHER_SW
 /* Taken from mvCommon.h */
 /* Memory uncached, HW or SW cache coherency is not needed */
-#define MV_UNCACHED             0   
+#define MV_UNCACHED             0
 /* Memory cached, HW cache coherency supported in WriteThrough mode */
 #define MV_CACHE_COHER_HW_WT    1
 /* Memory cached, HW cache coherency supported in WriteBack mode */
diff --git a/arch/arm/mach-avantalp/config/mvSysHwConfig.h b/arch/arm/mach-avantalp/config/mvSysHwConfig.h
index 3280aba..4fbdfb5 100755
--- a/arch/arm/mach-avantalp/config/mvSysHwConfig.h
+++ b/arch/arm/mach-avantalp/config/mvSysHwConfig.h
@@ -34,6 +34,9 @@ disclaimer.
 /* Glue between Linux .config and defines for shared code */
 #ifdef CONFIG_MACH_AVANTA_LP_FPGA
 #define MACH_AVANTA_LP_FPGA
+#define CONFIG_SYS_FPGA_DRAM_SIZE	_256M
+#define MV_FPGA_SYS_CLK			25000000
+#define MV_FPGA_CORE_CLK		12500000
 #endif
 
 #define CONFIG_MARVELL	1
diff --git a/arch/arm/mach-avantalp/core.c b/arch/arm/mach-avantalp/core.c
index 1e1235f..0a47466 100755
--- a/arch/arm/mach-avantalp/core.c
+++ b/arch/arm/mach-avantalp/core.c
@@ -44,7 +44,6 @@
 #include <linux/serial_8250.h>
 #include <linux/serial_reg.h>
 #include <linux/ata_platform.h>
-#include <linux/mv_neta.h>
 #include <asm/serial.h>
 #include <plat/cache-aurora-l2.h>
 
@@ -69,6 +68,12 @@
 
 #include <plat/mv_xor.h>
 
+#if defined(CONFIG_MV_ETH_NETA)
+#include <linux/mv_neta.h>
+#elif defined (CONFIG_MV_ETH_PP2)
+#include <linux/mv_pp2.h>
+#endif
+
 /* I2C */
 #include <linux/i2c.h>
 #include <linux/mv643xx_i2c.h>
@@ -92,7 +97,7 @@ extern unsigned int irq_int_type[];
 extern void __init alp_map_io(void);
 extern void __init mv_init_irq(void);
 extern struct sys_timer alp_timer;
-extern void alp_timer_resume();
+extern void alp_timer_resume(void);
 extern MV_CPU_DEC_WIN* mv_sys_map(void);
 #if defined(CONFIG_MV_INCLUDE_CESA)
 extern u32 mv_crypto_virt_base_get(u8 chan);
@@ -100,7 +105,12 @@ extern u32 mv_crypto_virt_base_get(u8 chan);
 
 extern void alp_init_irq(void);
 extern void __init set_core_count(unsigned int cpu_count);
+
+#ifdef CONFIG_SMP
 extern unsigned int group_cpu_mask;
+#else
+static unsigned int group_cpu_mask = 1;
+#endif /* CONFIG_SMP */
 
 /* for debug putstr */
 static char arr[256];
@@ -108,8 +118,8 @@ MV_U32 mvTclk = 166666667;
 MV_U32 mvSysclk = 200000000;
 
 #ifdef CONFIG_MV_INCLUDE_GIG_ETH
-MV_U8 mvMacAddr[CONFIG_MV_ETH_PORTS_NUM][6];
-MV_U16 mvMtu[CONFIG_MV_ETH_PORTS_NUM] = {0};
+MV_U8 mvMacAddr[MV_UBOOT_ETH_PORTS][6];
+MV_U16 mvMtu[MV_UBOOT_ETH_PORTS] = {0};
 #endif
 
 /*
@@ -154,7 +164,7 @@ static void putstr(const char *s)
 		MV_UART0_THR = *s;
 
                 if (*s == '\n') {
-                        while ((MV_UART0_LSR & UART_LSR_THRE) == 0); 
+                        while ((MV_UART0_LSR & UART_LSR_THRE) == 0);
                         MV_UART0_THR = '\r';
                 }
                 s++;
@@ -200,14 +210,9 @@ static int __init parse_tag_mv_uboot(const struct tag *tag)
 	mvBoardIdSet(mvUbootVer & 0xff);
 
 #ifdef CONFIG_MV_INCLUDE_GIG_ETH
-	for (i = 0; i < CONFIG_MV_ETH_PORTS_NUM; i++) {
-#if defined (CONFIG_OVERRIDE_ETH_CMDLINE)
-		memset(mvMacAddr[i], 0, 6);
-		mvMtu[i] = 0;
-#else
+	for (i = 0; i < MV_UBOOT_ETH_PORTS; i++) {
 		memcpy(mvMacAddr[i], tag->u.mv_uboot.macAddr[i], 6);
 		mvMtu[i] = read_mtu(tag->u.mv_uboot.mtu[i]);
-#endif
 	}
 #endif
 
@@ -443,58 +448,164 @@ static struct platform_device mv88fx_neta = {
 	.id		= 0,
 	.num_resources	= 0,
 };
+#elif defined(CONFIG_MV_ETH_PP2)
+static void mv_pp2_giga_pdev_register(struct platform_device *pdev)
+{
+	struct mv_pp2_pdata *plat_data = (struct mv_pp2_pdata *)pdev->dev.platform_data;
+	int speed, port = pdev->id;
+
+	plat_data->cpu_mask  = group_cpu_mask;
+	plat_data->phy_addr = mvBoardPhyAddrGet(port);
+	plat_data->lb_enable = mvBoardIsPortLoopback(port);
+	plat_data->is_sgmii = mvBoardIsPortInSgmii(port);
+	plat_data->is_rgmii = MV_FALSE;
+	plat_data->duplex = DUPLEX_FULL;
+
+	if (port < MV_UBOOT_ETH_PORTS) {
+		plat_data->mtu = mvMtu[port];
+		memcpy(plat_data->mac_addr, mvMacAddr[port], 6);
+	} else {
+		plat_data->mtu = 1500;
+		memset(plat_data->mac_addr, 0, 6);
+	}
+
+	speed = mvBoardMacSpeedGet(port);
+	switch (speed) {
+	case BOARD_MAC_SPEED_10M:
+		plat_data->speed = SPEED_10;
+		break;
+	case BOARD_MAC_SPEED_100M:
+		plat_data->speed = SPEED_100;
+		break;
+	case BOARD_MAC_SPEED_1000M:
+		plat_data->speed = SPEED_1000;
+		break;
+	case BOARD_MAC_SPEED_AUTO:
+	default:
+		plat_data->speed = 0;
+		break;
+	}
+
+	platform_device_register(pdev);
+}
+
+static struct resource mv_pp2_ge0_resources[] = {
+	{
+		.start          = IRQ_AURORA_GBE0_FIC,
+		.end            = IRQ_AURORA_GBE0_FIC,
+		.flags          = IORESOURCE_IRQ,
+	},
+};
+
+static struct mv_pp2_pdata mv_pp2_ge0_pdata = {
+	.mtu = 1500,
+	.phy_addr = 0,
+};
+
+static struct platform_device mv_pp2_ge0_plat = {
+	.name           = MV_PP2_PORT_NAME,
+	.id             = 0,
+	.num_resources  = ARRAY_SIZE(mv_pp2_ge0_resources),
+	.resource       = mv_pp2_ge0_resources,
+	.dev            = {
+		.platform_data = &mv_pp2_ge0_pdata,
+	},
+};
+
+static struct resource mv_pp2_ge2_resources[] = {
+	{
+		.start          = IRQ_AURORA_GBE2_FIC,
+		.end            = IRQ_AURORA_GBE2_FIC,
+		.flags          = IORESOURCE_IRQ,
+	},
+};
+
+static struct mv_pp2_pdata mv_pp2_ge2_pdata = {
+	.mtu = 1500,
+	.phy_addr = -1,
+};
+
+static struct platform_device mv_pp2_ge2_plat = {
+	.name           = MV_PP2_PORT_NAME,
+	.id             = 2,
+	.num_resources  = ARRAY_SIZE(mv_pp2_ge2_resources),
+	.resource       = mv_pp2_ge2_resources,
+	.dev            = {
+		.platform_data = &mv_pp2_ge2_pdata,
+	},
+};
+
+static struct mv_pp2_pdata mv_pp2_ge3_pdata = {
+	.mtu = 1500,
+	.phy_addr = -1,
+};
+
+static struct resource mv_pp2_ge3_resources[] = {
+	{
+		.start          = IRQ_AURORA_GBE3_FIC,
+		.end            = IRQ_AURORA_GBE3_FIC,
+		.flags          = IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device mv_pp2_ge3_plat = {
+	.name           = MV_PP2_PORT_NAME,
+	.id             = 3,
+	.num_resources  = ARRAY_SIZE(mv_pp2_ge3_resources),
+	.resource       = mv_pp2_ge3_resources,
+	.dev            = {
+		.platform_data = &mv_pp2_ge3_pdata,
+	},
+};
 #else
-#error "Ethernet Mode is not defined (should be Legacy or NETA)"
-#endif /* Ethernet mode: legacy or NETA */
+#error "Ethernet Mode is not defined (should be Legacy or NETA or PPv2)"
+#endif /* Ethernet mode: Legacy or NETA or PPv2 */
 
 static void __init eth_init(void)
 {
- struct netaSmpGroupStruct *netaSmpGroupStruct;
-        int cpu, found = 0, portMask;
-
-        netaSmpGroupStruct = kzalloc(sizeof(struct netaSmpGroupStruct), GFP_KERNEL);
-
-        if (!netaSmpGroupStruct) {
-                        printk(KERN_ERR "no memory for private data\n");
-                        return;
-        }
-        else {
+#ifdef CONFIG_MV_ETH_NETA
+	struct netaSmpGroupStruct *netaSmpGroupStruct;
+	int cpu, found = 0, portMask;
+	netaSmpGroupStruct = kzalloc(sizeof(struct netaSmpGroupStruct), GFP_KERNEL);
 
+	if (!netaSmpGroupStruct) {
+		printk(KERN_ERR "no memory for private data\n");
+		return;
+	} else {
 #ifdef  CONFIG_SMP
-                netaSmpGroupStruct->cpuMask  = group_cpu_mask;
+		netaSmpGroupStruct->cpuMask  = group_cpu_mask;
 #else
-                netaSmpGroupStruct->cpuMask  = 1;
+		netaSmpGroupStruct->cpuMask  = 1;
 #endif
+		portMask  = (mvUnitMapIsMine(ETH0) == MV_TRUE);
+		portMask |= (mvUnitMapIsMine(ETH1) == MV_TRUE) << 1;
+		portMask |= (mvUnitMapIsMine(ETH2) == MV_TRUE) << 2;
+		portMask |= (mvUnitMapIsMine(ETH3) == MV_TRUE) << 3;
 
-                portMask  = (mvUnitMapIsMine(ETH0) == MV_TRUE);
-                portMask |= (mvUnitMapIsMine(ETH1) == MV_TRUE) << 1;
-                portMask |= (mvUnitMapIsMine(ETH2) == MV_TRUE) << 2;
-                portMask |= (mvUnitMapIsMine(ETH3) == MV_TRUE) << 3;
+		netaSmpGroupStruct->portMask = portMask;
+	}
 
-                netaSmpGroupStruct->portMask = portMask;
-        }
+	for (cpu = 0; cpu < CONFIG_NR_CPUS; cpu++) {
+		if (MV_BIT_CHECK(netaSmpGroupStruct->cpuMask, cpu))
+			found = 1;
+	}
 
-        for (cpu = 0; cpu < CONFIG_NR_CPUS; cpu++) {
-                if (MV_BIT_CHECK(netaSmpGroupStruct->cpuMask, cpu))
-                        found = 1;
-        }
-        if (!found) {
-                printk(KERN_ERR "%s: cpuMask does not contain any of the CPUs \n", __func__);
-                printk(KERN_ERR "%s: not initializing network driver\n", __func__);
-                return;
-        }
-        mv88fx_neta.dev.platform_data = netaSmpGroupStruct;
+	if (!found) {
+		printk(KERN_ERR "%s: cpuMask does not contain any of the CPUs \n", __func__);
+		printk(KERN_ERR "%s: not initializing network driver\n", __func__);
+		return;
+	}
+	mv88fx_neta.dev.platform_data = netaSmpGroupStruct;
 
-#if defined(CONFIG_MV_ETH_LEGACY)
-        platform_device_register(&mv88fx_eth);
-#elif defined(CONFIG_MV_ETH_NETA)
-        platform_device_register(&mv88fx_neta);
-#endif /* Ethernet mode: legacy or NETA */
+#elif defined (CONFIG_MV_ETH_PP2)
+	mv_pp2_giga_pdev_register(&mv_pp2_ge0_plat);
+	mv_pp2_giga_pdev_register(&mv_pp2_ge2_plat);
+	mv_pp2_giga_pdev_register(&mv_pp2_ge3_plat);
+#endif
 }
 
 #endif /* CONFIG_MV_ETHERNET */
 
-
 /************
  * GPIO
  ***********/
@@ -723,6 +834,14 @@ static void __init alp_fpga_init(void)
 
 	/* RTC */
 	rtc_init();
+
+#ifdef CONFIG_MV_ETHERNET
+	mvSysEthPhyInit();
+
+	/* Ethernet */
+	eth_init();
+#endif
+
 #endif
 
 	serial_initialize(0);
diff --git a/arch/arm/mach-avantalp/mv_hal_if/mvSysEthPhy.c b/arch/arm/mach-avantalp/mv_hal_if/mvSysEthPhy.c
index 0c9cdf5..5dfd76e 100644
--- a/arch/arm/mach-avantalp/mv_hal_if/mvSysEthPhy.c
+++ b/arch/arm/mach-avantalp/mv_hal_if/mvSysEthPhy.c
@@ -68,13 +68,15 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #include "ctrlEnv/mvCtrlEnvSpec.h"
 #include "boardEnv/mvBoardEnvLib.h"
 #include "eth-phy/mvEthPhy.h"
-#if defined(MV_ETH_LEGACY)
+
+#if defined(CONFIG_MV_ETH_LEGACY)
 #include "eth/gbe/mvEthRegs.h"
-#else
+#elif defined(CONFIG_MV_ETH_NETA)
 #include "neta/gbe/mvEthRegs.h"
+#elif defined(CONFIG_MV_ETH_PP2)
+#include "pp2/gbe/mvPp2GbeRegs.h"
 #endif
 
-
 /*******************************************************************************
 * mvSysEthPhyInit - Initialize the EthPhy subsystem
 *
@@ -93,12 +95,11 @@ MV_STATUS mvSysEthPhyInit(void)
 	MV_ETHPHY_HAL_DATA halData;
 	MV_U32 port;
 
-	for (port=0; port < mvCtrlEthMaxPortGet(); port++) {
+	for (port = 0; port < mvCtrlEthMaxPortGet(); port++) {
 		halData.phyAddr[port] = mvBoardPhyAddrGet(port);
 		halData.boardSpecInit = MV_FALSE;
 	}
 
 	halData.ethPhySmiReg = ETH_SMI_REG(MV_ETH_SMI_PORT); 
-
 	return mvEthPhyHalInit(&halData);
 }
diff --git a/arch/arm/mach-avantalp/mv_hal_if/mvSysPp2.c b/arch/arm/mach-avantalp/mv_hal_if/mvSysPp2.c
new file mode 100644
index 0000000..1f4b40a
--- /dev/null
+++ b/arch/arm/mach-avantalp/mv_hal_if/mvSysPp2.c
@@ -0,0 +1,137 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "cpu/mvCpu.h"
+#include "gbe/mvPp2Gbe.h"
+#include "gmac/mvEthGmacApi.h"
+
+
+/*******************************************************************************
+* mvSysPp2Init - Initialize the Eth subsystem
+*
+* DESCRIPTION:
+*
+* INPUT:
+*       None
+* OUTPUT:
+*		None
+* RETURN:
+*       None
+*
+*******************************************************************************/
+void 	mvSysPp2Init(void)
+{
+	MV_PP2_HAL_DATA halData;
+	MV_UNIT_WIN_INFO *addrWinMap;
+	MV_STATUS status;
+	int i;
+
+	addrWinMap = mvOsMalloc((MAX_TARGETS + 1) * sizeof(MV_UNIT_WIN_INFO));
+	if (!addrWinMap)
+		return;
+
+	memset(&halData, 0, sizeof(halData));
+	status = mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1);
+	if (status != MV_OK)
+		return;
+
+	for (i = 0; i < MAX_TARGETS; i++) {
+		if (addrWinMap[i].enable == MV_FALSE)
+			continue;
+
+#ifdef CONFIG_MV_SUPPORT_L2_DEPOSIT
+		/* Setting DRAM windows attribute to :
+		   0x3 - Shared transaction + L2 write allocate (L2 Deposit) */
+		if (MV_TARGET_IS_DRAM(i)) {
+			addrWinMap[i].attrib &= ~(0x30);
+			addrWinMap[i].attrib |= 0x30;
+		}
+#endif
+		mvOsPrintf("%d - Base 0x%08x , Size = 0x%08x. , Target = 0x%08x\n", i,
+				addrWinMap[i].addrWin.baseLow,
+				(unsigned int)addrWinMap[i].addrWin.size, addrWinMap[i].targetId);
+	}
+	halData.maxPort = mvCtrlEthMaxPortGet();
+
+#ifdef CONFIG_MV_PON
+	halData.maxTcont = MV_ETH_MAX_TCONT;
+#endif /* CONFIG_MV_PON */
+
+	halData.pClk = mvCpuPclkGet();
+	halData.tClk = mvBoardTclkGet();
+	halData.maxCPUs = mvCtrlEthMaxCPUsGet();
+	halData.iocc = arch_is_coherent();
+	halData.ctrlModel = mvCtrlModelGet();
+	halData.ctrlRev = mvCtrlRevGet();
+	halData.aggrTxqSize = CONFIG_MV_ETH_AGGR_TXQ_SIZE;
+
+	mvPp2WinInit(0, addrWinMap);
+	mvPp2HalInit(&halData);
+
+	return;
+}
diff --git a/arch/arm/mach-avantalp/mv_hal_if/mvSysPp2Api.h b/arch/arm/mach-avantalp/mv_hal_if/mvSysPp2Api.h
new file mode 100644
index 0000000..1946cdb
--- /dev/null
+++ b/arch/arm/mach-avantalp/mv_hal_if/mvSysPp2Api.h
@@ -0,0 +1,71 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	    this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef __MV_SYS_PP2_API_H__
+#define __MV_SYS_PP2_API_H__
+
+
+void 	mvSysPp2Init(void);
+
+#endif /* __MV_SYS_PP2_API_H__ */
diff --git a/arch/arm/plat-armada/Kconfig b/arch/arm/plat-armada/Kconfig
index c822411f..fed12dd 100644
--- a/arch/arm/plat-armada/Kconfig
+++ b/arch/arm/plat-armada/Kconfig
@@ -4,11 +4,11 @@ menu "Marvell SoC options"
 	depends on PLAT_ARMADA
 
 config JTAG_DEBUG
-        bool "Enable JTAG by disable \"wait for interrupt\"."
+	bool "Enable JTAG by disable \"wait for interrupt\"."
 	depends on MV88F6500 || MV88F6281 || MV78XX0
-        default n
-        ---help---
-           Enable the JTAG debugger taking over the CPU by disabling "wait for interrupt" idle loop."
+	default n
+	---help---
+	   Enable the JTAG debugger taking over the CPU by disabling "wait for interrupt" idle loop."
 
 
 menu "Marvell SoC Included Features"
@@ -164,7 +164,7 @@ config MV_INCLUDE_TS
 
 config MV_INCLUDE_PON
 	bool "PON Support"
-	depends on MV88F6500
+	depends on MV88F6500 || MV_ETH_PP2
 	default y
         ---help---
         Please don't change this configs unless you know what you are doing.
@@ -250,7 +250,7 @@ config MV_GPP_MAX_PINS
 	default 70 if MV88F6500
 	default 67 if ARMADA_XP
 	default 67 if ARMADA_370
-	
+
 config MV_DCACHE_SIZE
 	hex
 	default 0x8000 if MV78XX0 || ARMADA_XP || ARMADA_370
@@ -260,7 +260,7 @@ config MV_ICACHE_SIZE
 	hex
 	default 0x8000 if MV78XX0 || ARMADA_XP || ARMADA_370
 	default 0x4000 if MV88F6500 || MV88F6281
-	          
+
 menu "Armada SoC MTD support"
 
 config MV_FLASH_CTRL
@@ -298,7 +298,7 @@ config MTD_NAND_LNC_BOOT
 	depends on MTD_NAND_LNC
 	default n
 	---help---
-	Choose this option if NAND MTD is the system boot device.	            
+	Choose this option if NAND MTD is the system boot device.
 	This option controls the various flash types support in the board
 	device chip-select information structure under mvBoardEnvSpec.c
 
@@ -389,7 +389,7 @@ config USE_DSP
 config  FEROCEON_PROC
 	bool "Support for MV-shell proc file system"
 	depends on PROC_FS
-	---help---	
+	---help---
 	  Choosing this option will enable you to use the MV-shell through the Proc
 	  File system.
 	  The MV-shell is a debug utility which can be run from the shell.
@@ -434,13 +434,9 @@ config	ERROR_HANDLING_DRAM_ECC
         Choosing this option will enable DRAM ECC error notification by netlink
 
 
-
 menu "Soc DMA accelerations"
-
 source arch/arm/plat-armada/mv_drivers_lsp/mv_xor/Kconfig
-
 source arch/arm/plat-armada/mv_drivers_lsp/mv_dma/Kconfig
-
 endmenu
 
 
@@ -452,26 +448,39 @@ config MV_ETHERNET
 	depends on MV_INCLUDE_GIG_ETH
 	default y
         ---help---
-        Choose this option to support Marvell Gigabit Ethernet Controller 
+        Choose this option to support Marvell Gigabit Ethernet Controller
 
-if MV_ETHERNET
+choice
 
-choice 
-        prompt "GbE Mode"
-        depends on MV_INCLUDE_GIG_ETH 
-        default MV_ETH_LEGACY
+	prompt "GbE Mode"
+	depends on MV_INCLUDE_GIG_ETH
+	default MV_ETH_LEGACY
 
 config MV_ETH_LEGACY
-        bool "Legacy mode "
-        ---help---
+	bool "Legacy mode "
+	---help---
 
 config MV_ETH_NETA
-        bool "Acceleration mode "
+	bool "Acceleration mode "
 	depends on ARCH_FEROCEON_KW2 || ARCH_ARMADA_XP || ARCH_ARMADA370
-        ---help---
+	---help---
+
+config MV_ETH_PP2
+	bool "PPv2 mode "
+	depends on ARCH_FEROCEON_KW2 || ARCH_ARMADA_XP || ARCH_ARMADA370
+	select MV_ETH_PP2_CLS2
+	select MV_ETH_PP2_CLS3
+	select MV_ETH_PP2_CLS4
+	select MV_ETH_PP2_CLS_MC
+	---help---
 
 endchoice
 
+config MV_INCLUDE_ETH_PHY
+	bool "Choose to compile Ethernet PHY support
+	depends on MV_ETH_LEGACY || MV_ETH_NETA || MV_ETH_PP2
+	help
+	  No help currently.
 
 if MV_ETH_LEGACY
 source arch/arm/plat-armada/mv_drivers_lsp/mv_network/Kconfig
@@ -481,7 +490,10 @@ if MV_ETH_NETA
 source arch/arm/plat-armada/mv_drivers_lsp/mv_neta/Kconfig
 endif
 
-endif # MV_ETHERNET
+if MV_ETH_PP2
+source arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig
+endif
+
 endmenu # "SoC Networking support"
 
 source arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Kconfig
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_phy/phy_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_phy/phy_sysfs.c
index b2e599f..2eac635 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_phy/phy_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_phy/phy_sysfs.c
@@ -32,8 +32,9 @@ disclaimer.
 #include <linux/kernel.h>
 #include <linux/platform_device.h>
 
-#include "gbe/mvNeta.h"
-#include "net_dev/mv_netdev.h"
+#include "mvCommon.h"
+#include "mvTypes.h"
+
 #include "eth-phy/mvEthPhy.h"
 
 static ssize_t phy_help(char *buf)
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig
new file mode 100644
index 0000000..a81043a
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig
@@ -0,0 +1,764 @@
+config MV_ETH_PP2_CLS2
+	bool
+	prompt "cls engine 2" if (0)
+	default y
+
+config MV_ETH_PP2_CLS3
+	bool
+	prompt "cls engine 3" if (0)
+	default y
+
+config MV_ETH_PP2_CLS4
+	bool
+	prompt "cls engine 4" if (0)
+	default y
+
+config MV_ETH_PP2_CLS_MC
+	bool
+	prompt "cls mc" if (0)
+	default y
+
+menu "BM configuration"
+
+config MV_ETH_BM_0_PKT_SIZE
+	depends on MV_ETH_PP2
+	int "Packet size [bytes] can use buffers from pool #0"
+	default 0
+	---help---
+	0 - means that packet size for the pool will be defined accordingly
+        with MTU of the port that use this pool.
+
+config MV_ETH_BM_1_PKT_SIZE
+	depends on MV_ETH_PP2
+	int "Packet size [bytes] can use buffers from pool #1"
+	default 256
+        ---help---
+        0 - means that packet size for the pool will be defined accordingly
+        with MTU of the port that use this pool.
+
+config MV_ETH_BM_2_PKT_SIZE
+	depends on MV_ETH_PP2
+	int "Packet size [bytes] can use buffers from pool #2"
+	default 0
+	---help---
+        0 - means that packet size for the pool will be defined accordingly
+        with MTU of the port that use this pool.
+
+config MV_ETH_BM_3_PKT_SIZE
+	depends on MV_ETH_PP2
+	int "Packet size [bytes] can use buffers from pool #3"
+	default 256
+	---help---
+        0 - means that packet size for the pool will be defined accordingly
+        with MTU of the port that use this pool.
+
+config MV_ETH_BM_4_PKT_SIZE
+	depends on MV_ETH_PP2
+	int "Packet size [bytes] can use buffers from pool #4"
+	default 0
+	---help---
+        0 - means that packet size for the pool will be defined accordingly
+        with MTU of the port that use this pool.
+
+config MV_ETH_BM_5_PKT_SIZE
+	depends on MV_ETH_PP2
+	int "Packet size [bytes] can use buffers from pool #5"
+	default 256
+	---help---
+        0 - means that packet size for the pool will be defined accordingly
+        with MTU of the port that use this pool.
+
+config MV_ETH_BM_6_PKT_SIZE
+	depends on MV_ETH_PP2
+	int "Packet size [bytes] can use buffers from pool #6"
+	default 0
+	---help---
+        0 - means that packet size for the pool will be defined accordingly
+        with MTU of the port that use this pool.
+
+config MV_ETH_BM_7_PKT_SIZE
+	depends on MV_ETH_PP2
+	int "Packet size [bytes] can use buffers from pool #7"
+	default 256
+	---help---
+        0 - means that packet size for the pool will be defined accordingly
+        with MTU of the port that use this pool.
+
+menuconfig  MV_ETH_BM_HWF_PORT_0
+        depends on (MV_ETH_PP2 && (MV_ETH_PORTS_NUM != 0))
+        bool "BM HWF configuration for GbE #0"
+        default y
+        ---help---
+
+config  MV_ETH_BM_HWF_PORT_0_LONG_POOL
+	int "Long BM pool for GbE #0"
+	depends on MV_ETH_BM_HWF_PORT_0
+	range -1 7
+	default 4
+	---help---
+	BM pool to be used for GbE #0 port to process long packets
+	-1 means that port will choose BM pool closest to required buffers size.
+
+config  MV_ETH_BM_HWF_PORT_0_SHORT_POOL
+        int "Short BM pool for GbE #0"
+        depends on MV_ETH_BM_HWF_PORT_0
+        range 0 7
+        default 5
+	---help---
+	BM pool to be used for GbE #0 port to process short packets
+
+config  MV_ETH_BM_HWF_PORT_0_LONG_BUF_NUM
+        int "Number of buffers for Long pool of GbE #0"
+        depends on MV_ETH_BM_HWF_PORT_0
+        range 128 16384
+        default 2048
+        ---help---
+	Number of long buffers allocated for this port.
+
+config  MV_ETH_BM_HWF_PORT_0_SHORT_BUF_NUM
+        int "Number of buffers for Short pool of GbE #0"
+        depends on MV_ETH_BM_HWF_PORT_0 && (MV_ETH_BM_HWF_PORT_0_LONG_POOL != MV_ETH_BM_HWF_PORT_0_SHORT_POOL)
+        range 128 16384
+        default 3072
+	---help---
+        Number of short buffers allocated for this port.
+
+menuconfig  MV_ETH_BM_HWF_PORT_1
+        depends on (MV_ETH_PP2 && (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1))
+        bool "BM HWF configuration for GbE #1"
+        default y
+        ---help---
+
+config  MV_ETH_BM_HWF_PORT_1_LONG_POOL
+        int "Long BM pool for GbE #1"
+        depends on MV_ETH_BM_HWF_PORT_1
+	range -1 7
+        default 7
+        ---help---
+        BM pool to be used for GbE #1 port to process long packets.
+	-1 means that port will choose BM pool closest to required buffers size.
+
+config  MV_ETH_BM_HWF_PORT_1_SHORT_POOL
+        int "Short BM pool for GbE #1"
+        depends on MV_ETH_BM_HWF_PORT_1
+        range 0 7
+        default 7
+        ---help---
+        BM pool to be used for GbE #1 port to process short packets.
+
+config  MV_ETH_BM_HWF_PORT_1_LONG_BUF_NUM
+        int "Number of buffers for Long pool of GbE #1"
+        depends on MV_ETH_BM_HWF_PORT_1
+        range 128 16384
+        default 2048
+        ---help---
+	Number of long buffers allocated for this port.
+
+config  MV_ETH_BM_HWF_PORT_1_SHORT_BUF_NUM
+        int "Number of buffers for Short pool of GbE #1"
+        depends on MV_ETH_BM_HWF_PORT_1 && (MV_ETH_BM_HWF_PORT_1_LONG_POOL != MV_ETH_BM_HWF_PORT_1_SHORT_POOL)
+        range 128 16384
+        default 3072
+        ---help---
+	Number of short buffers allocated for this port.
+
+menuconfig  MV_ETH_BM_HWF_PORT_2
+        depends on (MV_ETH_PP2 && (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1) &&  (MV_ETH_PORTS_NUM != 2))
+        bool "BM HWF configuration for GbE #2"
+        default y
+        ---help---
+
+config  MV_ETH_BM_HWF_PORT_2_LONG_POOL
+        int "Long BM pool for GbE #2"
+        depends on MV_ETH_BM_HWF_PORT_2
+        range -1 7
+        default 7
+        ---help---
+        BM pool to be used for GbE #2 port to process long packets.
+	-1 means that port will choose BM pool closest to required buffers size.
+
+config  MV_ETH_BM_HWF_PORT_2_SHORT_POOL
+        int "Short BM pool for GbE #2"
+        depends on MV_ETH_BM_HWF_PORT_2
+        range 0 7
+        default 7
+        ---help---
+	BM pool to be used for GbE #2 port to process short packets.
+
+config  MV_ETH_BM_HWF_PORT_2_LONG_BUF_NUM
+        int "Number of buffers for Long pool of GbE #2"
+        depends on MV_ETH_BM_HWF_PORT_2
+        range 128 16384
+        default 2048
+        ---help---
+        Number of long buffers allocated for this port.
+
+config  MV_ETH_BM_HWF_PORT_2_SHORT_BUF_NUM
+        int "Number of buffers for Short pool of GbE #2"
+        depends on MV_ETH_BM_HWF_PORT_2 && (MV_ETH_BM_HWF_PORT_2_LONG_POOL != MV_ETH_BM_HWF_PORT_2_SHORT_POOL)
+        range 128 16384
+        default 3072
+        ---help---
+        Number of short buffers allocated for this port.
+
+menuconfig  MV_ETH_BM_HWF_PORT_3
+        depends on (MV_ETH_PP2 && (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1) && (MV_ETH_PORTS_NUM != 2) && (MV_ETH_PORTS_NUM != 3))
+        bool "BM HWF configuration for GbE #3"
+        default y
+        ---help---
+
+config  MV_ETH_BM_HWF_PORT_3_LONG_POOL
+        int "Long BM pool for GbE #3"
+        depends on MV_ETH_BM_HWF_PORT_3
+        range -1 7
+        default 6
+        ---help---
+        BM pool to be used for GbE #3 port to process long packets.
+	-1 means that port will choose BM pool closest to required buffers size.
+
+config  MV_ETH_BM_HWF_PORT_3_SHORT_POOL
+        int "Short BM pool for GbE #3"
+        depends on MV_ETH_BM_HWF_PORT_3
+        range 0 7
+        default 7
+        ---help---
+	BM pool to be used for GbE #3 port to process short packets.
+
+config  MV_ETH_BM_HWF_PORT_3_LONG_BUF_NUM
+        int "Number of buffers for Long pool of GbE #3"
+        depends on MV_ETH_BM_HWF_PORT_3
+        range 128 16384
+        default 2048
+        ---help---
+        Number of long buffers allocated for this port.
+
+config  MV_ETH_BM_HWF_PORT_3_SHORT_BUF_NUM
+        int "Number of buffers for Short pool of GbE #3"
+        depends on MV_ETH_BM_HWF_PORT_3 && (MV_ETH_BM_HWF_PORT_3_LONG_POOL != MV_ETH_BM_HWF_PORT_3_SHORT_POOL)
+        range 128 16384
+        default 3072
+        ---help---
+        Number of short buffers allocated for this port.
+
+menuconfig  MV_ETH_BM_PORT_0
+        depends on (MV_ETH_PP2 && (MV_ETH_PORTS_NUM != 0))
+        bool "BM configuration for GbE #0"
+        default y
+        ---help---
+
+config  MV_ETH_BM_PORT_0_LONG_POOL
+	int "Long BM pool for GbE #0"
+	depends on MV_ETH_BM_PORT_0
+	range -1 7
+	default 2
+	---help---
+	BM pool to be used for GbE #0 port to process long packets
+	-1 means that port will choose BM pool closest to required buffers size.
+
+config  MV_ETH_BM_PORT_0_SHORT_POOL
+        int "Short BM pool for GbE #0"
+        depends on MV_ETH_BM_PORT_0
+        range 0 7
+        default 3
+	---help---
+	BM pool to be used for GbE #0 port to process short packets
+
+config  MV_ETH_BM_PORT_0_LONG_BUF_NUM
+        int "Number of buffers for Long pool of GbE #0"
+        depends on MV_ETH_BM_PORT_0
+        range 128 16384
+        default 2048
+        ---help---
+	Number of long buffers allocated for this port.
+
+config  MV_ETH_BM_PORT_0_SHORT_BUF_NUM
+        int "Number of buffers for Short pool of GbE #0"
+        depends on MV_ETH_BM_PORT_0 && (MV_ETH_BM_PORT_0_LONG_POOL != MV_ETH_BM_PORT_0_SHORT_POOL)
+        range 128 16384
+        default 3072
+	---help---
+        Number of short buffers allocated for this port.
+
+menuconfig  MV_ETH_BM_PORT_1
+        depends on (MV_ETH_PP2 && (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1))
+        bool "BM configuration for GbE #1"
+        default y
+        ---help---
+
+config  MV_ETH_BM_PORT_1_LONG_POOL
+        int "Long BM pool for GbE #1"
+        depends on MV_ETH_BM_PORT_1
+	range -1 7
+        default 7
+        ---help---
+        BM pool to be used for GbE #1 port to process long packets.
+	-1 means that port will choose BM pool closest to required buffers size.
+
+config  MV_ETH_BM_PORT_1_SHORT_POOL
+        int "Short BM pool for GbE #1"
+        depends on MV_ETH_BM_PORT_1
+        range 0 7
+        default 7
+        ---help---
+        BM pool to be used for GbE #1 port to process short packets.
+
+config  MV_ETH_BM_PORT_1_LONG_BUF_NUM
+        int "Number of buffers for Long pool of GbE #1"
+        depends on MV_ETH_BM_PORT_1
+        range 128 16384
+        default 2048
+        ---help---
+	Number of long buffers allocated for this port.
+
+config  MV_ETH_BM_PORT_1_SHORT_BUF_NUM
+        int "Number of buffers for Short pool of GbE #1"
+        depends on MV_ETH_BM_PORT_1 && (MV_ETH_BM_PORT_1_LONG_POOL != MV_ETH_BM_PORT_1_SHORT_POOL)
+        range 128 16384
+        default 3072
+        ---help---
+	Number of short buffers allocated for this port.
+
+menuconfig  MV_ETH_BM_PORT_2
+        depends on (MV_ETH_PP2 && (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1) &&  (MV_ETH_PORTS_NUM != 2))
+        bool "BM configuration for GbE #2"
+        default y
+        ---help---
+
+config  MV_ETH_BM_PORT_2_LONG_POOL
+        int "Long BM pool for GbE #2"
+        depends on MV_ETH_BM_PORT_2
+        range -1 7
+        default 7
+        ---help---
+        BM pool to be used for GbE #2 port to process long packets.
+	-1 means that port will choose BM pool closest to required buffers size.
+
+config  MV_ETH_BM_PORT_2_SHORT_POOL
+        int "Short BM pool for GbE #2"
+        depends on MV_ETH_BM_PORT_2
+        range 0 7
+        default 7
+        ---help---
+	BM pool to be used for GbE #2 port to process short packets.
+
+config  MV_ETH_BM_PORT_2_LONG_BUF_NUM
+        int "Number of buffers for Long pool of GbE #2"
+        depends on MV_ETH_BM_PORT_2
+        range 128 16384
+        default 2048
+        ---help---
+        Number of long buffers allocated for this port.
+
+config  MV_ETH_BM_PORT_2_SHORT_BUF_NUM
+        int "Number of buffers for Short pool of GbE #2"
+        depends on MV_ETH_BM_PORT_2 && (MV_ETH_BM_PORT_2_LONG_POOL != MV_ETH_BM_PORT_2_SHORT_POOL)
+        range 128 16384
+        default 3072
+        ---help---
+        Number of short buffers allocated for this port.
+
+menuconfig  MV_ETH_BM_PORT_3
+        depends on (MV_ETH_PP2 && (MV_ETH_PORTS_NUM != 0) && (MV_ETH_PORTS_NUM != 1) && (MV_ETH_PORTS_NUM != 2) && (MV_ETH_PORTS_NUM != 3))
+        bool "BM configuration for GbE #3"
+        default y
+        ---help---
+
+config  MV_ETH_BM_PORT_3_LONG_POOL
+        int "Long BM pool for GbE #3"
+        depends on MV_ETH_BM_PORT_3
+        range -1 7
+        default 0
+        ---help---
+        BM pool to be used for GbE #3 port to process long packets.
+	-1 means that port will choose BM pool closest to required buffers size.
+
+config  MV_ETH_BM_PORT_3_SHORT_POOL
+        int "Short BM pool for GbE #3"
+        depends on MV_ETH_BM_PORT_3
+        range 0 7
+        default 1
+        ---help---
+	BM pool to be used for GbE #3 port to process short packets.
+
+config  MV_ETH_BM_PORT_3_LONG_BUF_NUM
+        int "Number of buffers for Long pool of GbE #3"
+        depends on MV_ETH_BM_PORT_3
+        range 128 16384
+        default 2048
+        ---help---
+        Number of long buffers allocated for this port.
+
+config  MV_ETH_BM_PORT_3_SHORT_BUF_NUM
+        int "Number of buffers for Short pool of GbE #3"
+        depends on MV_ETH_BM_PORT_3 && (MV_ETH_BM_PORT_3_LONG_POOL != MV_ETH_BM_PORT_3_SHORT_POOL)
+        range 128 16384
+        default 3072
+        ---help---
+        Number of short buffers allocated for this port.
+
+endmenu
+
+menu "Rx/Tx Queue configuration"
+
+config  MV_ETH_RXQ
+        int "Number of RX queues per port"
+        default 8
+        ---help---
+          Multiple RX queue support.
+
+config  MV_ETH_TXQ
+        int "Number of TX queues"
+        default 1
+        ---help---
+          Multiple TX queue support.
+
+config MV_ETH_RXQ_DESC
+	int "Number of Rx descriptors"
+	depends on (MV_ETH_PORTS_NUM != 0)
+	default 128
+        ---help---
+	The number of Rx descriptors in each Rx queue.
+
+config MV_ETH_RXQ_DEF
+        int "Default RXQ to recieve packets"
+        default 0
+        ---help---
+
+config MV_ETH_TXQ_DESC
+	int "Number of Tx descriptors"
+	depends on (MV_ETH_PORTS_NUM != 0)
+	default 532
+        ---help---
+	The number of Tx descriptors in each Tx queue.
+
+config MV_ETH_TXQ_DEF
+        int "Default TXQ to send local generated packets"
+        default 0
+        ---help---
+
+config MV_ETH_TXQ_HWF_DESC
+	int "Number of HWF Tx descriptors"
+	depends on (MV_ETH_PORTS_NUM != 0)
+	default 16
+        ---help---
+	The number of HWF dedicated Tx descriptors in each Tx queue.
+
+config MV_ETH_AGGR_TXQ_SIZE
+	int "Number of aggregated Tx descriptors"
+	depends on (MV_ETH_PORTS_NUM != 0)
+	default 256
+        ---help---
+	The number of Tx descriptors in each aggregated Tx queue.
+
+endmenu
+
+menu "IP/TCP/UDP Offloading"
+
+config  MV_ETH_TX_CSUM_OFFLOAD
+        bool "L3/L4 TX checksum offload support for Marvell network interface"
+        default y
+        ---help---
+	Marvell network driver compiled with TCP/UDP over IPv4/IPv6 TX checksum offload support.
+
+config MV_ETH_TX_CSUM_OFFLOAD_DEF
+	depends on MV_ETH_TX_CSUM_OFFLOAD
+        bool "Default value for L3/L4 TX checksum offload: enable/disable"
+        default y
+        ---help---
+	Can be changed in run-time using ethtool
+
+config  MV_ETH_RX_CSUM_OFFLOAD
+        bool "L3/L4 RX checksum offload support for Marvell network interface"
+        default y
+        ---help---
+        Marvell network driver compiled with TCP/UDP over IPv4/IPv6 RX checksum offload support.
+
+config MV_ETH_RX_CSUM_OFFLOAD_DEF
+	depends on MV_ETH_RX_CSUM_OFFLOAD
+        bool "Default value for L3/L4 RX checksum offload: enable/disable"
+        default y
+        ---help---
+	Can be changed in run-time using ethtool
+
+config  MV_ETH_GRO
+        bool "GRO Support for Marvell network interface"
+	default y
+        ---help---
+        Marvell network driver compiled with GRO (Generic Receive Offload) support.
+
+config  MV_ETH_GRO_DEF
+	depends on MV_ETH_GRO
+        bool "Default value for GRO feature: enable/disable"
+	default n
+        ---help---
+        Can be changed in run-time using ethtool
+
+config  MV_ETH_TSO
+        bool "TSO Support for Marvell network interface"
+	default y
+        ---help---
+        Marvell network driver compiled with TSO (TCP Segmentation Offload) support.
+
+config  MV_ETH_TSO_DEF
+	depends on MV_ETH_TSO
+        bool "Default value for TSO feature: enable/disable"
+	default n
+        ---help---
+	Can be changed in run-time using ethtool
+
+endmenu
+
+menu "Control and Statistics"
+
+config  MV_ETH_DEBUG_CODE
+	bool "Add run-time debug code"
+	default n
+	---help---
+	Enable run-time enable/disable enter debug code blocks
+
+config  MV_ETH_STAT_ERR
+        bool "Collect error statistics"
+        default y
+	---help---
+	Marvell network interface driver collect minimal number of statistics.
+	Only for error conditions. Can be displayed using mv_eth_tool.
+
+config  MV_ETH_STAT_INF
+        bool "Collect event statistics"
+        default y
+        ---help---
+	Marvell network interface driver collect event statistics.
+	Provide more information about driver functionality and almost doesn't
+	effect performance. Can be displayed using mv_eth_tool.
+
+config  MV_ETH_STAT_DBG
+        bool "Collect debug statistics"
+        default n
+        ---help---
+	Marvell network interface driver collect a lot of statistics.
+	Used for Debug mode. Decrease performance. Can be displayed using mv_eth_tool.
+
+config  MV_ETH_STAT_DIST
+        bool "Collect debug distribution statistics"
+        default n
+        ---help---
+        Marvell network interface driver collect a lot of statistics.
+        Used for Debug mode. Decrease performance. Can be displayed using mv_eth_tool.
+
+config  MV_LINUX_COUNTERS_DISABLE
+	bool "Disable collection of SNMP statistics and Netfilter Contract statistics"
+	default n
+	---help---
+	Disable collection of SNMP statistics and Netfilter Contract statistics to improve performance.
+
+config  MV_ETH_TOOL
+	bool "Support ethtool controls"
+	default y
+	---help---
+	Support kernel's SIOCETHTOOL for ethtool utility
+endmenu
+
+menu "Advanced Features"
+
+config  NET_SKB_HEADROOM
+        int "SKB headroom size"
+        default 64
+        ---help---
+          Customize SKB headroom size. Must be power of 2.
+
+config NET_SKB_RECYCLE
+        bool "Skb recycle"
+        default y
+        ---help---
+          Work-in-progress and experimental.
+
+          This option enables skb's to be returned via a callback at kfree to
+          the allocator to make a fastpath for very skb consuming network
+          applications.
+
+config NET_SKB_RECYCLE_DEF
+        depends on NET_SKB_RECYCLE
+        int "Default value for SKB recycle:  0 - disable, 1 - enable"
+        default 1
+        ---help---
+
+config  MV_ETH_TX_DONE_TIMER_PERIOD
+        int "Periodical Tx Done timer period"
+        default 10
+        ---help---
+          Periodical timer period for Tx Done operation in [msec].
+
+config  MV_ETH_CLEANUP_TIMER_PERIOD
+        int "Periodical Cleanup timer period"
+        default 10
+        ---help---
+          Periodical timer period for cleanup operation in [msec].
+
+config  MV_ETH_TXDONE_ISR
+	bool "Use interrupt to process TX_DONE event"
+	default n
+	---help---
+	When chosen TX_DONE event will be process in interrupt mode
+	When unchosen TX_DONE event will be processed in polling mode
+
+config  MV_ETH_TXDONE_COAL_PKTS
+	int "Threshold for TX_DONE event trigger"
+	default 16
+	---help---
+	Number of packets will be sent before TX_DONE event will be triggered
+	by interrupt or polling.
+
+config  MV_ETH_RX_COAL_PKTS
+        int "Threshold [number of packets] for RX interrupt"
+        default 32
+        ---help---
+        Number of packets will be received before RX interrupt will be generated by HW.
+
+config  MV_ETH_RX_COAL_USEC
+        int "Threshold [usec] for RX interrupt"
+        default 100
+        ---help---
+        Time delay in usec before RX interrupt will be generated by HW if number of
+	received packets larger than 0 but smaller than MV_ETH_RX_COAL_PKTS
+
+config  MV_ETH_RX_DESC_PREFETCH
+	bool "Enable RX descriptor prefetch"
+	default n
+	---help---
+	Use pld instruction to prefetch one RX descriptor ahead
+
+config  MV_ETH_RX_PKT_PREFETCH
+        bool "Enable RX packet prefetch"
+        default n
+        ---help---
+        Use pld instruction to prefetch first two cache lines of received packet data
+
+config MV_ETH_RX_SPECIAL
+        bool "Enable special RX processing"
+        default n
+        ---help---
+        Enable special RX processing for packets with RI_RX_SEPCIAL PNC result info bit set
+
+config MV_ETH_TX_SPECIAL
+	bool "Enable special TX processing"
+	default n
+	---help---
+	Enable special TX processing for packets with signal header (SH)
+
+config MV_ETH_L2FW
+	bool "L2 Forwarding support"
+	default n
+	---help---
+	Enable L2 Forwarding support for received packets.
+	Three modes are supported: Send packet without change, Swap MAC DA<->SA,
+	Copy the whole packet and swap MAC
+
+config MV_ETH_L2SEC
+	bool "L2 Forwarding IPSec support"
+	depends on MV_ETH_L2FW
+	default n
+	---help---
+	Handle encrypted packets with CESA.
+
+config MV_ETH_L2FW_DEBUG
+	depends on MV_ETH_L2FW
+	bool "Add run-time L2FW debug code"
+	default n
+	---help---
+	Enable L2FW run-time enable/disable enter debug code blocks
+
+config MV_ETH_RX_POLL_WEIGHT
+	int "poll weight for the RX poll() function"
+	default 64
+	range 1 255
+	---help---
+	poll weight for the RX poll() function; must be less or equal to 255
+
+config MV_ETH_EXTRA_BUF_SIZE
+	int "Extra buffer size in bytes"
+	default 120
+	range 120 16384
+	---help---
+	Size of buffers allocated for extra pool and used in special cases like TSO,
+	fragmentattion and others
+
+config MV_ETH_EXTRA_BUF_NUM
+        int "Number of extra buffers allocated for each port"
+        default MV_ETH_TXQ_DESC
+	---help---
+	Number of extra buffers allocated for each port
+endmenu
+
+menu "PON support for Network driver"
+
+config MV_PON
+        bool "PON support"
+        depends on MV_ETH_PP2 && MV_INCLUDE_PON
+        ---help---
+        Choose this option to support PON port in Marvell network driver
+
+config MV_PON_TXP_DEF
+        int "Default T-CONT to send local generated packets"
+        depends on MV_PON
+        default 0
+        ---help---
+
+config MV_PON_TXQ_DEF
+        int "Default TXQ to send local generated packets"
+        depends on MV_PON
+        default 0
+        ---help---
+
+endmenu
+
+menu "HWF support"
+
+config MV_ETH_HWF
+	bool "Enable Harware Forwarding"
+	default y
+	---help---
+
+endmenu
+
+menu "Switch support"
+
+config MV_ETH_SWITCH
+        bool "Switch support"
+	depends on MV_INCLUDE_SWITCH
+        ---help---
+	Choose this option to support Gigabit Ethernet Controller connected to
+        on-board QuarterDeck switch family
+
+config  MV_ETH_SWITCH_NETDEV_NUM
+	int "Maximum number of subnets on switch ports"
+	depends on MV_ETH_SWITCH
+	default 4
+	---help---
+	Valid range range from 1 to BOARD_ETH_SWITCH_PORT_NUM
+
+config  MV_ETH_SWITCH_NETCONFIG_0
+	string "Switch network configuration for GbE port 0"
+	depends on MV_ETH_SWITCH
+	default "3,(00:11:66:11:66:11,0)(00:22:77:22:77:22,1:2:3:4),mtu=1500"
+	---help---
+	 Set the network configuration when giga port connected to switch.
+         For each interface, define the interface
+	 name, MAC address and participating ports.
+
+config  MV_ETH_SWITCH_NETCONFIG_1
+	string "Switch network configuration for GbE port 1"
+	depends on MV_ETH_SWITCH
+	default "0"
+	---help---
+	 Set the network configuration when giga port connected to switch.
+         For each interface, define the interface
+	 name, MAC address and participating ports.
+
+config  MV_ETH_SWITCH_LINK
+	bool "Link status change indications"
+	depends on MV_ETH_SWITCH
+	default y
+	---help---
+	  Support Phy link status change indications.
+endmenu
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/bm/mv_eth_bm.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/bm/mv_eth_bm.c
new file mode 100644
index 0000000..d618d4c
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/bm/mv_eth_bm.c
@@ -0,0 +1,276 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+
+
+#include "gbe/mvPp2Gbe.h"
+#include "bm/mvBm.h"
+
+#include "net_dev/mv_netdev.h"
+
+typedef struct {
+	int             pool_pkt_size[MV_BM_POOLS];
+	MV_BM_CONFIG	port_config[MV_ETH_MAX_PORTS];
+	MV_U8		pool_hwf_mask;
+} MV_ETH_BM_CONFIG;
+
+static MV_ETH_BM_CONFIG mv_eth_bm_config;
+
+int mv_eth_bm_config_is_hwf_pool(int pool)
+{
+	return (mv_eth_bm_config.pool_hwf_mask & (1 << pool));
+}
+
+int mv_eth_bm_config_pkt_size_get(int pool)
+{
+	if ((pool < 0) || (pool >= MV_BM_POOLS))
+		return -EINVAL;
+
+	return mv_eth_bm_config.pool_pkt_size[pool];
+}
+
+int mv_eth_bm_config_pkt_size_set(int pool, int pkt_size)
+{
+	if ((pool < 0) || (pool >= MV_BM_POOLS))
+		return -EINVAL;
+
+	mv_eth_bm_config.pool_pkt_size[pool] = pkt_size;
+	return 0;
+}
+
+int mv_eth_bm_config_long_pool_get(int port)
+{
+	if (mvPp2PortCheck(port))
+		return -EINVAL;
+
+	return mv_eth_bm_config.port_config[port].longPool;
+}
+
+int mv_eth_bm_config_hwf_long_pool_get(int port)
+{
+	if (mvPp2PortCheck(port))
+		return -EINVAL;
+
+	return mv_eth_bm_config.port_config[port].hwfLongPool;
+}
+
+
+int mv_eth_bm_config_long_buf_num_get(int port)
+{
+	if (mvPp2PortCheck(port))
+		return -EINVAL;
+
+	return mv_eth_bm_config.port_config[port].longBufNum;
+}
+
+int mv_eth_bm_config_hwf_long_buf_num_get(int port)
+{
+	if (mvPp2PortCheck(port))
+		return -EINVAL;
+
+	return mv_eth_bm_config.port_config[port].hwfLongBufNum;
+}
+
+
+int mv_eth_bm_config_short_pool_get(int port)
+{
+	if (mvPp2PortCheck(port))
+		return -EINVAL;
+
+	return mv_eth_bm_config.port_config[port].shortPool;
+}
+
+int mv_eth_bm_config_hwf_short_pool_get(int port)
+{
+	if (mvPp2PortCheck(port))
+		return -EINVAL;
+
+	return mv_eth_bm_config.port_config[port].hwfShortPool;
+}
+
+int mv_eth_bm_config_short_buf_num_get(int port)
+{
+	if (mvPp2PortCheck(port))
+		return -EINVAL;
+
+	return mv_eth_bm_config.port_config[port].shortBufNum;
+}
+
+int mv_eth_bm_config_hwf_short_buf_num_get(int port)
+{
+	if (mvPp2PortCheck(port))
+		return -EINVAL;
+
+	return mv_eth_bm_config.port_config[port].hwfShortBufNum;
+}
+/* Once time call: init configuration structure accordingly with compile time parameters */
+MV_STATUS mv_eth_bm_config_get(void)
+{
+	MV_BM_CONFIG *bmConfig;
+	int           port;
+
+	mv_eth_bm_config.pool_hwf_mask = 0;
+
+	mv_eth_bm_config.pool_pkt_size[0] = CONFIG_MV_ETH_BM_0_PKT_SIZE;
+	mv_eth_bm_config.pool_pkt_size[1] = CONFIG_MV_ETH_BM_1_PKT_SIZE;
+	mv_eth_bm_config.pool_pkt_size[2] = CONFIG_MV_ETH_BM_2_PKT_SIZE;
+	mv_eth_bm_config.pool_pkt_size[3] = CONFIG_MV_ETH_BM_3_PKT_SIZE;
+	mv_eth_bm_config.pool_pkt_size[4] = CONFIG_MV_ETH_BM_4_PKT_SIZE;
+	mv_eth_bm_config.pool_pkt_size[5] = CONFIG_MV_ETH_BM_5_PKT_SIZE;
+	mv_eth_bm_config.pool_pkt_size[6] = CONFIG_MV_ETH_BM_6_PKT_SIZE;
+	mv_eth_bm_config.pool_pkt_size[7] = CONFIG_MV_ETH_BM_7_PKT_SIZE;
+
+#ifdef CONFIG_MV_ETH_BM_PORT_0
+	port = 0;
+	bmConfig = &mv_eth_bm_config.port_config[port];
+	memset(bmConfig, 0, sizeof(MV_BM_CONFIG));
+	bmConfig->valid = 1;
+	bmConfig->longPool = CONFIG_MV_ETH_BM_PORT_0_LONG_POOL;
+	bmConfig->shortPool = CONFIG_MV_ETH_BM_PORT_0_SHORT_POOL;
+	bmConfig->longBufNum = CONFIG_MV_ETH_BM_PORT_0_LONG_BUF_NUM;
+
+#if (CONFIG_MV_ETH_BM_PORT_0_SHORT_POOL != CONFIG_MV_ETH_BM_PORT_0_LONG_POOL)
+	bmConfig->shortBufNum = CONFIG_MV_ETH_BM_PORT_0_SHORT_BUF_NUM;
+#endif /* CONFIG_MV_ETH_BM_PORT_0_SHORT_POOL != CONFIG_MV_ETH_BM_PORT_0_LONG_POOL */
+
+#ifdef CONFIG_MV_ETH_BM_HWF_PORT_0
+	bmConfig->hwfLongPool = CONFIG_MV_ETH_BM_HWF_PORT_0_LONG_POOL;
+	bmConfig->hwfShortPool = CONFIG_MV_ETH_BM_HWF_PORT_0_SHORT_POOL;
+	bmConfig->hwfLongBufNum = CONFIG_MV_ETH_BM_HWF_PORT_0_LONG_BUF_NUM;
+
+	mv_eth_bm_config.pool_hwf_mask |= ((1 << bmConfig->hwfLongPool) | (1 << bmConfig->hwfShortPool));
+#if (CONFIG_MV_ETH_BM_HWF_PORT_0_SHORT_POOL != CONFIG_MV_ETH_BM_HWF_PORT_0_LONG_POOL)
+	bmConfig->hwfShortBufNum = CONFIG_MV_ETH_BM_HWF_PORT_0_SHORT_BUF_NUM;
+#endif /* CONFIG_MV_ETH_BM_HWF_PORT_0_SHORT_POOL != CONFIG_MV_ETH_BM_HWF_PORT_0_LONG_POOL */
+#endif /* CONFIG_MV_ETH_BM_HWF_PORT_0 */
+#endif /* CONFIG_MV_ETH_BM_PORT_0 */
+
+#ifdef CONFIG_MV_ETH_BM_PORT_1
+	port = 1;
+	bmConfig = &mv_eth_bm_config.port_config[port];
+	memset(bmConfig, 0, sizeof(MV_BM_CONFIG));
+	bmConfig->valid = 1;
+	bmConfig->longPool = CONFIG_MV_ETH_BM_PORT_1_LONG_POOL;
+	bmConfig->shortPool = CONFIG_MV_ETH_BM_PORT_1_SHORT_POOL;
+	bmConfig->longBufNum = CONFIG_MV_ETH_BM_PORT_1_LONG_BUF_NUM;
+
+#if (CONFIG_MV_ETH_BM_PORT_1_SHORT_POOL != CONFIG_MV_ETH_BM_PORT_1_LONG_POOL)
+	bmConfig->shortBufNum = CONFIG_MV_ETH_BM_PORT_1_SHORT_BUF_NUM;
+#endif /* CONFIG_MV_ETH_BM_PORT_1_SHORT_POOL != CONFIG_MV_ETH_BM_PORT_1_LONG_POOL */
+
+#ifdef CONFIG_MV_ETH_BM_HWF_PORT_1
+	bmConfig->hwfLongPool = CONFIG_MV_ETH_BM_HWF_PORT_1_LONG_POOL;
+	bmConfig->hwfShortPool = CONFIG_MV_ETH_BM_HWF_PORT_1_SHORT_POOL;
+	bmConfig->hwfLongBufNum = CONFIG_MV_ETH_BM_HWF_PORT_1_LONG_BUF_NUM;
+
+	mv_eth_bm_config.pool_hwf_mask |= ((1 << bmConfig->hwfLongPool) | (1 << bmConfig->hwfShortPool));
+#if (CONFIG_MV_ETH_BM_HWF_PORT_1_SHORT_POOL != CONFIG_MV_ETH_BM_HWF_PORT_1_LONG_POOL)
+	bmConfig->hwfShortBufNum = CONFIG_MV_ETH_BM_HWF_PORT_1_SHORT_BUF_NUM;
+#endif /* CONFIG_MV_ETH_BM_HWF_PORT_1_SHORT_POOL != CONFIG_MV_ETH_BM_HWF_PORT_1_LONG_POOL */
+#endif /* CONFIG_MV_ETH_BM_HWF_PORT_1 */
+#endif /* CONFIG_MV_ETH_BM_PORT_1 */
+
+#ifdef CONFIG_MV_ETH_BM_PORT_2
+	port = 2;
+	bmConfig = &mv_eth_bm_config.port_config[port];
+	memset(bmConfig, 0, sizeof(MV_BM_CONFIG));
+	bmConfig->valid = 1;
+	bmConfig->longPool = CONFIG_MV_ETH_BM_PORT_2_LONG_POOL;
+	bmConfig->shortPool = CONFIG_MV_ETH_BM_PORT_2_SHORT_POOL;
+	bmConfig->longBufNum = CONFIG_MV_ETH_BM_PORT_2_LONG_BUF_NUM;
+
+#if (CONFIG_MV_ETH_BM_PORT_2_SHORT_POOL != CONFIG_MV_ETH_BM_PORT_2_LONG_POOL)
+	bmConfig->shortBufNum = CONFIG_MV_ETH_BM_PORT_2_SHORT_BUF_NUM;
+#endif /* CONFIG_MV_ETH_BM_PORT_2_SHORT_POOL != CONFIG_MV_ETH_BM_PORT_2_LONG_POOL */
+
+#ifdef CONFIG_MV_ETH_BM_HWF_PORT_2
+	bmConfig->hwfLongPool = CONFIG_MV_ETH_BM_HWF_PORT_2_LONG_POOL;
+	bmConfig->hwfShortPool = CONFIG_MV_ETH_BM_HWF_PORT_2_SHORT_POOL;
+	bmConfig->hwfLongBufNum = CONFIG_MV_ETH_BM_HWF_PORT_2_LONG_BUF_NUM;
+
+	mv_eth_bm_config.pool_hwf_mask |= ((1 << bmConfig->hwfLongPool) | (1 << bmConfig->hwfShortPool));
+#if (CONFIG_MV_ETH_BM_HWF_PORT_2_SHORT_POOL != CONFIG_MV_ETH_BM_HWF_PORT_2_LONG_POOL)
+	bmConfig->hwfShortBufNum = CONFIG_MV_ETH_BM_HWF_PORT_2_SHORT_BUF_NUM;
+#endif /* CONFIG_MV_ETH_BM_HWF_PORT_2_SHORT_POOL != CONFIG_MV_ETH_BM_HWF_PORT_2_LONG_POOL */
+#endif /* CONFIG_MV_ETH_BM_HWF_PORT_2 */
+#endif /* CONFIG_MV_ETH_BM_PORT_2 */
+
+#ifdef CONFIG_MV_ETH_BM_PORT_3
+	port = 3;
+	bmConfig = &mv_eth_bm_config.port_config[port];
+	memset(bmConfig, 0, sizeof(MV_BM_CONFIG));
+	bmConfig->valid = 1;
+	bmConfig->longPool = CONFIG_MV_ETH_BM_PORT_3_LONG_POOL;
+	bmConfig->shortPool = CONFIG_MV_ETH_BM_PORT_3_SHORT_POOL;
+	bmConfig->longBufNum = CONFIG_MV_ETH_BM_PORT_3_LONG_BUF_NUM;
+
+#if (CONFIG_MV_ETH_BM_PORT_3_SHORT_POOL != CONFIG_MV_ETH_BM_PORT_3_LONG_POOL)
+	bmConfig->shortBufNum = CONFIG_MV_ETH_BM_PORT_3_SHORT_BUF_NUM;
+#endif /* CONFIG_MV_ETH_BM_PORT_3_SHORT_POOL != CONFIG_MV_ETH_BM_PORT_3_LONG_POOL */
+
+#ifdef CONFIG_MV_ETH_BM_HWF_PORT_3
+	bmConfig->hwfLongPool = CONFIG_MV_ETH_BM_HWF_PORT_3_LONG_POOL;
+	bmConfig->hwfShortPool = CONFIG_MV_ETH_BM_HWF_PORT_3_SHORT_POOL;
+	bmConfig->hwfLongBufNum = CONFIG_MV_ETH_BM_HWF_PORT_3_LONG_BUF_NUM;
+
+	mv_eth_bm_config.pool_hwf_mask |= ((1 << bmConfig->hwfLongPool) | (1 << bmConfig->hwfShortPool));
+#if (CONFIG_MV_ETH_BM_HWF_PORT_0_SHORT_POOL != CONFIG_MV_ETH_BM_HWF_PORT_3_LONG_POOL)
+	bmConfig->hwfShortBufNum = CONFIG_MV_ETH_BM_HWF_PORT_3_SHORT_BUF_NUM;
+#endif /* CONFIG_MV_ETH_BM_HWF_PORT_3_SHORT_POOL != CONFIG_MV_ETH_BM_HWF_PORT_3_LONG_POOL */
+#endif /* CONFIG_MV_ETH_BM_HWF_PORT_3 */
+#endif /* CONFIG_MV_ETH_BM_PORT_3 */
+
+	return MV_OK;
+}
+
+void mv_eth_bm_config_print(void)
+{
+	int           i;
+	MV_BM_CONFIG *bmConfig;
+
+	mvOsPrintf("BM compile time configuration\n");
+	for (i = 0; i < MV_BM_POOLS; i++)
+		mvOsPrintf("pool %d: pkt_size = %d bytes\n", i, mv_eth_bm_config.pool_pkt_size[i]);
+
+	mvOsPrintf("\n");
+	mvOsPrintf("port:  longPool  shortPool  longBufNum  shortBufNum   hwfLongPool  hwfShortPool  hwfLongBufNum  hwfShortBufNum\n");
+	for (i = 0; i < MV_ETH_MAX_PORTS; i++) {
+		bmConfig = &mv_eth_bm_config.port_config[i];
+		if (bmConfig->valid)
+			mvOsPrintf("  %2d:   %4d       %4d        %4d         %4d      %4d          %4d           %4d            %4d\n",
+				i, bmConfig->longPool, bmConfig->shortPool, bmConfig->longBufNum, bmConfig->shortBufNum,
+				bmConfig->hwfLongPool, bmConfig->hwfShortPool, bmConfig->hwfLongBufNum, bmConfig->hwfShortBufNum);
+	}
+	mvOsPrintf("\n");
+}
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls2_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls2_sysfs.c
new file mode 100644
index 0000000..bcc9360
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls2_sysfs.c
@@ -0,0 +1,334 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include "mvOs.h"
+#include "mvCommon.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "../../../mv_hal/pp2/cls/mvPp2Cls2Hw.h"
+
+
+static MV_PP2_CLS_C2_QOS_ENTRY		qos_entry;
+static MV_PP2_CLS_C2_ENTRY		act_entry;
+
+
+
+
+static ssize_t mv_cls_help(char *buf)
+{
+	int off = 0;
+	off += scnprintf(buf + off, PAGE_SIZE, "cat                qos_sw_dump             - dump QoS table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat                prio_hw_dump            - dump all QoS priority tables from HW.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat                dscp_hw_dump            - dump all QoS dscp tables from HW.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat                act_sw_dump             - dump action table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat                act_hw_dump             - dump all action table enrties from HW.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat                hw_regs                 - dump classifier C2 registers.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat                cnt_dump                - dump all hit counters that are not zeroed.\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo 1             > qos_sw_clear           - clear QoS table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo 1             > act_sw_clear           - clear action table SW entry.\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo id s ln       > qos_hw_write           - write QoS table SW entry into HW <id,s,ln>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo id s ln       > qos_hw_read            - read QoS table entry from HW <id,s,ln>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo prio          > qos_sw_prio            - set priority <prio> value to QoS table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo dscp          > qos_sw_dscp            - set DSCP <dscp> value to QoS table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo color         > qos_sw_color           - set color value to QoS table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo id            > qos_sw_gemid           - set GemPortId <id> value to QoS table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo q             > qos_sw_queue           - set queue number <q> value to QoS table SW entry.\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo idx           > act_hw_write           - write action table SW entry into HW <idx>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo idx           > act_hw_read            - read action table entry from HW <idx> into SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo idx	   > act_hw_inv		    - invalidate C2 entry <idx> in hw.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo        	   > act_hw_inv_all	    - invalidate all C2 entries in HW.\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE, "echo o d m         > act_sw_byte            - set byte <d,m> to TCAM offset <o> to action table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo id sel	   > act_sw_qos             - set QoS table <id,sel> to action table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd from      > act_sw_color           - set color command <cmd> to action table SW.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "                                             <from> - source for color command.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd prio from > act_sw_prio            - set priority command <cmd> and value <prio> to action\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "                                             table SW entry. <from> - source for priority command.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd prio from > act_sw_dscp            - set DSCP command <cmd> and value <dscp> to action\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "                                             table SW entry. <from> - source for DSCP command.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd gpid from > act_sw_gpid            - set GemPortID command <cmd> and value <gpid> to action\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "                                             table SW entry. <from> - source for GemPortID command.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd q from	   > act_sw_qh		   - set queue high command <cmd> and value <q> to action\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "					     table software entry. <from> -source for Queue High command.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd q from	   > act_sw_ql		   - set queue low command <cmd> and value <q> to action\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "					     table software entry. <from> -source for Queue Low command.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd q from	   > act_sw_queue	   - set full queue command <cmd> and value <q> to action\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "					     table software entry.  <from> -source for Queue command.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd           > act_sw_hwf             - set Forwarding command <cmd> to action table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd id        > act_sw_pol             - set PolicerID command <cmd> and number <id> to action.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "                                             table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo d i cs        > act_sw_mdf             - set modification parameters to action table SW entry\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "                                             data pointer <d>, instruction pointrt <i>,\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "                                             <cs> enable L4 checksum generation.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo id cnt        > act_sw_dup              - set packet duplication parameters <id,cnt> to action.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "                                             table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo               > cnt_clr_all            - clear all hit counters from action tabe.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo idx           > cnt_read               - show hit counter for action table entry.\n");
+
+	return off;
+}
+
+
+static ssize_t mv_cls_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "qos_sw_dump"))
+		off += mvPp2ClsC2QosSwDump(&qos_entry);
+	else if (!strcmp(name, "prio_hw_dump"))
+		off += mvPp2ClsC2QosPrioHwDump();
+	else if (!strcmp(name, "dscp_hw_dump"))
+		off += mvPp2ClsC2QosDscpHwDump();
+	else if (!strcmp(name, "act_sw_dump"))
+		off += mvPp2ClsC2SwDump(&act_entry);
+	else if (!strcmp(name, "act_hw_dump"))
+		off += mvPp2ClsC2HwDump();
+	else if (!strcmp(name, "cnt_dump"))
+		off += mvPp2ClsC2HitCntrsDump();
+	else if (!strcmp(name, "hw_regs"))
+		off += mvPp2ClsC2RegsDump();
+	else
+		off += mv_cls_help(buf);
+
+	return off;
+}
+
+
+static ssize_t mv_cls_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  err = 0, a = 0, b = 0, c = 0, d = 0, e = 0;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%x %x %x %x %x", &a, &b, &c, &d, &e);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "act_hw_inv_all"))
+		mvPp2ClsC2HwInvAll();
+	else if (!strcmp(name, "act_hw_inv"))
+		mvPp2ClsC2HwInv(a);
+	else if (!strcmp(name, "qos_sw_clear"))
+		mvPp2ClsC2QosSwClear(&qos_entry);
+	else if (!strcmp(name, "qos_hw_write"))
+		mvPp2ClsC2QosHwWrite(a, b, c, &qos_entry);
+	else if (!strcmp(name, "qos_hw_read"))
+		mvPp2ClsC2QosHwRead(a, b, c, &qos_entry);
+	else if (!strcmp(name, "qos_sw_prio"))
+		mvPp2ClsC2QosPrioSet(&qos_entry, a);
+	else if (!strcmp(name, "qos_sw_dscp"))
+		mvPp2ClsC2QosDscpSet(&qos_entry, a);
+	else if (!strcmp(name, "qos_sw_color"))
+		mvPp2ClsC2QosColorSet(&qos_entry, a);
+	else if (!strcmp(name, "qos_sw_gemid"))
+		mvPp2ClsC2QosGpidSet(&qos_entry, a);
+	else if (!strcmp(name, "qos_sw_queue"))
+		mvPp2ClsC2QosQueueSet(&qos_entry, a);
+	else if (!strcmp(name, "act_sw_clear"))
+		mvPp2ClsC2SwClear(&act_entry);
+	else if (!strcmp(name, "act_hw_write"))
+		mvPp2ClsC2HwWrite(a, &act_entry);
+	else if (!strcmp(name, "act_hw_read"))
+		mvPp2ClsC2HwRead(a, &act_entry);
+	else if (!strcmp(name, "act_sw_byte"))
+		mvPp2ClsC2TcamByteSet(&act_entry, a, b, c);
+	else if (!strcmp(name, "act_sw_qos"))
+		mvPp2ClsC2QosTblSet(&act_entry, a, b);
+	else if (!strcmp(name, "act_sw_color"))
+		mvPp2ClsC2ColorSet(&act_entry, a, b);
+	else if (!strcmp(name, "act_sw_prio"))
+		mvPp2ClsC2PrioSet(&act_entry, a, b, c);
+	else if (!strcmp(name, "act_sw_dscp"))
+		mvPp2ClsC2DscpSet(&act_entry, a, b, c);
+	else if (!strcmp(name, "act_sw_gpid"))
+		mvPp2ClsC2GpidSet(&act_entry, a, b, c);
+	else if (!strcmp(name, "act_sw_qh"))
+		mvPp2ClsC2QueueHighSet(&act_entry, a, b, c);
+	else if (!strcmp(name, "act_sw_ql"))
+		mvPp2ClsC2QueueLowSet(&act_entry, a, b, c);
+	else if (!strcmp(name, "act_sw_queue"))
+		mvPp2ClsC2QueueSet(&act_entry, a, b, c);
+	else if (!strcmp(name, "act_sw_hwf"))
+		mvPp2ClsC2ForwardSet(&act_entry, a);
+	else if (!strcmp(name, "act_sw_pol"))
+		mvPp2ClsC2PolicerSet(&act_entry, a, b);
+	else if (!strcmp(name, "act_sw_mdf"))
+		mvPp2ClsC2ModSet(&act_entry, a, b, c);
+	else if (!strcmp(name, "act_sw_dup"))
+		mvPp2ClsC2DupSet(&act_entry, a, b);
+	else if (!strcmp(name, "cnt_clr_all"))
+		mvPp2ClsC2HitCntrsClearAll();
+	else if (!strcmp(name, "cnt_read"))
+		mvPp2ClsC2HitCntrRead(a, NULL);
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+
+static DEVICE_ATTR(prio_hw_dump,		S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(dscp_hw_dump,		S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(qos_sw_dump,			S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(act_sw_dump,			S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(act_hw_dump,			S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(cnt_dump,			S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(hw_regs,			S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(help,			S_IRUSR, mv_cls_show, NULL);
+
+static DEVICE_ATTR(qos_sw_clear,    		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(qos_hw_write,     		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(qos_hw_read,    	  	S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(qos_sw_prio,    		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(qos_sw_dscp, 		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(qos_sw_color,		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(qos_sw_gemid,      		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(qos_sw_queue,		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_hw_inv,    		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_hw_inv_all,     		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_clear,		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_hw_write,		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_hw_read,			S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_byte,			S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_color,		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_prio,			S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_dscp,			S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_gpid,			S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_qh,			S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_ql,			S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_queue,		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_hwf,			S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_pol,			S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_mdf,			S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_dup,			S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(cnt_clr_all,			S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(act_sw_qos,  		S_IWUSR, mv_cls_show, mv_cls_store);
+static DEVICE_ATTR(cnt_read,	  		S_IWUSR, mv_cls_show, mv_cls_store);
+
+static struct attribute *cls2_attrs[] = {
+	&dev_attr_prio_hw_dump.attr,
+	&dev_attr_dscp_hw_dump.attr,
+	&dev_attr_qos_sw_dump.attr,
+	&dev_attr_act_sw_dump.attr,
+	&dev_attr_act_hw_dump.attr,
+	&dev_attr_cnt_dump.attr,
+	&dev_attr_hw_regs.attr,
+	&dev_attr_help.attr,
+	&dev_attr_qos_sw_clear.attr,
+	&dev_attr_qos_hw_write.attr,
+	&dev_attr_qos_hw_read.attr,
+	&dev_attr_qos_sw_prio.attr,
+	&dev_attr_qos_sw_dscp.attr,
+	&dev_attr_qos_sw_color.attr,
+	&dev_attr_qos_sw_gemid.attr,
+	&dev_attr_qos_sw_queue.attr,
+	&dev_attr_act_hw_inv.attr,
+	&dev_attr_act_hw_inv_all.attr,
+	&dev_attr_act_sw_clear.attr,
+	&dev_attr_act_hw_write.attr,
+	&dev_attr_act_hw_read.attr,
+	&dev_attr_act_sw_byte.attr,
+	&dev_attr_act_sw_color.attr,
+	&dev_attr_act_sw_prio.attr,
+	&dev_attr_act_sw_dscp.attr,
+	&dev_attr_act_sw_gpid.attr,
+	&dev_attr_act_sw_qh.attr,
+	&dev_attr_act_sw_ql.attr,
+	&dev_attr_act_sw_queue.attr,
+	&dev_attr_act_sw_hwf.attr,
+	&dev_attr_act_sw_pol.attr,
+	&dev_attr_act_sw_mdf.attr,
+	&dev_attr_act_sw_dup.attr,
+	&dev_attr_cnt_clr_all.attr,
+	&dev_attr_act_sw_qos.attr,
+	&dev_attr_cnt_read.attr,
+	NULL
+};
+
+static struct attribute_group cls2_group = {
+	.name = "cls2",
+	.attrs = cls2_attrs,
+};
+
+int __devinit cls2_sysfs_init(void)
+{
+	int err;
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	if (!pd) {
+		platform_device_register_simple("pp2", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	}
+
+	if (!pd) {
+		printk(KERN_ERR "%s: cannot find neta device\n", __func__);
+		pd = &platform_bus;
+	}
+
+	err = sysfs_create_group(&pd->kobj, &cls2_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+out:
+	return err;
+}
+
+module_init(cls2_sysfs_init);
+
+MODULE_AUTHOR("Uri Eliyahu");
+MODULE_DESCRIPTION("cls engine C2 for Marvell NetA2");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls3_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls3_sysfs.c
new file mode 100644
index 0000000..0bf3652
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls3_sysfs.c
@@ -0,0 +1,373 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This SW file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+SW Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include "mvOs.h"
+#include "mvCommon.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "../../../mv_hal/pp2/cls/mvPp2Cls3Hw.h"
+
+static MV_PP2_CLS_C3_ENTRY		c3;
+
+
+static ssize_t mv_cls3_help(char *buf)
+{
+	int off = 0;
+	off += scnprintf(buf + off, PAGE_SIZE, "cat		init_database  - Internal SW database init.\n");/*TODO: remove after debugginig*/
+	off += scnprintf(buf + off, PAGE_SIZE, "cat		hw_dump        - Dump all occupied entries from HW.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat		hw_ext_dump    - Dump all occupied extension table entries from HW.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat		sw_dump	       - Dump SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat		sc_res_dump    - Dump all valid scan results from HW.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat		sc_regs        - Dump scan registers.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat		hw_query       - Get query for HEK in the SW entry and show result.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat             cnt_read_all   - Dump all hit counters for all changed indices\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo depth      > hw_query_add - Get query for HEK in the SW entry and Write entry into HW hash entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "				 free entry search depth <depth>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo idx	> hw_read      - Read entry from HW <idx> into SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo idx extIdx	> hw_add       - Write entry from SW into HW hash table <idx>\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "				 external table entry index <extIdx> optionally used for long entries.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo idx	> hw_del       - Delete entry from HW <idx>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo 1		> hw_del_all   - Delete all c3 entries from HW. \n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo 1		> sw_clear     - Clear SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo val	> sw_init_cnt  - Set initial hit counter value <val> (in units of 64 hits) to SW.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo info	> key_sw_l4    - Set L4 information <info> to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo type	> key_sw_lkp_type - Set key lookup type to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo id type	> key_sw_port  - Set key port ID <id> and port ID type to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo size	> key_sw_size  - Set key HEK size port ID <id> and port ID type to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo o d	> key_sw_byte  - Set byte of HEK data <d> and offset <o> to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo o d	> key_sw_word  - Set byte of HEK data <d> and offset <o> to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd	> act_sw_color - Set color command <cmd> to action table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd qh	> act_sw_qh    - Set Queue High command <cmd> and value <qh> to action table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd ql	> act_sw_ql    - Set Queue Low command <cmd> and value <ql> to action table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd q	> act_sw_queue - Set full Queue command <cmd> and value <q> to action table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd id	> act_sw_fwd   - Set Forwarding command <cmd> to action table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd id	> act_sw_pol   - Set PolicerID command <cmd> and number <id> to action table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo d i cs 	> act_sw_modif - Set modification parameters to action table SW entry data pointer <d>\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "				 instruction offset <i>, <cs> enable L4 checksum generation\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo id cnt	> act_sw_dup   - Set packet duplication parameters <id, cnt> to action SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo idx	> cnt_read     - Show hit counter for action table entry <idx>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo 1		> cnt_clr_all  - Clear hit counters for all action table entries.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo t 		> cnt_clr_lkp  - Clear hit counters for all action table entries with lookup type <t>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo 1		> sc_start     - Start new multi-hash scanning.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo m t	> sc_thresh    - Set scan threshold <t> and mode to above <m=1> or below <m=0> thresh.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo e 		> sc_clear_before - clear hit counter before scan enable <e=1> or disable<e=0> in HW.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo t		> sc_lkp       - Set lookup type <t> for scan operation, <t=-1> all entries are scanned\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo idx	> sc_start_idx - Set scan start entry <idx> in HW.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo time	> sc_delay     - Set scan delay <time> in HW.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo  idx	> sc_res_read  - Show result entry <idx> form scan result table in HW.\n");
+
+	return off;
+}
+
+
+static ssize_t mv_cls3_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+	if (!strcmp(name, "init_database"))
+		mvPp2ClsC3ShadowInit();
+	else if (!strcmp(name, "hw_dump"))
+		mvPp2ClsC3HwDump();
+	else if (!strcmp(name, "hw_ext_dump"))
+		mvPp2ClsC3HwExtDump();
+	else if (!strcmp(name, "sw_dump"))
+		mvPp2ClsC3SwDump(&c3);
+	else if (!strcmp(name, "sc_res_dump"))
+		mvPp2ClsC3ScanResDump();
+	else if (!strcmp(name, "sc_regs"))
+		mvPp2ClsC3ScanRegs();
+	else if (!strcmp(name, "hw_query"))
+		mvPp2ClsC3HwQuery(&c3, NULL, NULL);
+	else if (!strcmp(name, "cnt_read_all"))
+		mvPp2ClsC3HitCntrsReadAll();
+	else
+		off += mv_cls3_help(buf);
+
+	return off;
+}
+
+
+
+static ssize_t mv_cls3_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  err = 0, a = 0, b = 0, c = 0, d = 0;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%x %x %x %x", &a, &b, &c, &d);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "hw_read"))
+		mvPp2ClsC3HwRead(&c3, a);
+	else if (!strcmp(name, "hw_query_add"))
+		mvPp2ClsC3HwQueryAdd(&c3, a);
+	else if (!strcmp(name, "hw_add"))
+		mvPp2ClsC3HwAdd(&c3, a, b);
+	else if (!strcmp(name, "hw_del"))
+		mvPp2ClsC3HwDel(a);
+	else if (!strcmp(name, "hw_del_all"))
+		mvPp2ClsC3HwDelAll();
+	else if (!strcmp(name, "sw_clear"))
+		mvPp2ClsC3SwClear(&c3);
+	else if (!strcmp(name, "sw_init_cnt"))
+		mvPp2ClsC3HwInitCtrSet(a);
+	else if (!strcmp(name, "key_sw_l4"))
+		 mvPp2ClsC3SwL4infoSet(&c3, a);
+	else if (!strcmp(name, "key_sw_lkp_type"))
+		mvPp2ClsC3SwLkpTypeSet(&c3, a);
+	else if (!strcmp(name, "key_sw_port"))
+		mvPp2ClsC3SwPortIDSet(&c3, b, a);
+	else if (!strcmp(name, "key_sw_size"))
+		mvPp2ClsC3SwHekSizeSet(&c3, a);
+	else if (!strcmp(name, "key_sw_byte"))
+		mvPp2ClsC3SwHekByteSet(&c3, a, b);
+	else if (!strcmp(name, "key_sw_word"))
+		mvPp2ClsC3SwHekWordSet(&c3, a, b);
+	else if (!strcmp(name, "act_sw_color"))
+		mvPp2ClsC3ColorSet(&c3, a);
+	else if (!strcmp(name, "act_sw_qh"))
+		mvPp2ClsC3QueueHighSet(&c3, a, b);
+	else if (!strcmp(name, "act_sw_ql"))
+		mvPp2ClsC3QueueLowSet(&c3, a, b);
+	else if (!strcmp(name, "act_sw_queue"))
+		mvPp2ClsC3QueueSet(&c3, a, b);
+	else if (!strcmp(name, "act_sw_fwd"))
+		mvPp2ClsC3ForwardSet(&c3, a);
+	else if (!strcmp(name, "act_sw_pol"))
+		mvPp2ClsC3PolicerSet (&c3, a, b);
+	else if (!strcmp(name, "act_sw_modif"))
+		mvPp2ClsC3ModSet (&c3, a, b, c);
+	else if (!strcmp(name, "act_sw_dup"))
+		mvPp2ClsC3DupSet (&c3, a, b);
+	else if (!strcmp(name, "cnt_read"))
+		mvPp2ClsC3HitCntrsRead(a, NULL);
+	else if (!strcmp(name, "cnt_clr_all"))
+		mvPp2ClsC3HitCntrsClearAll();
+	else if (!strcmp(name, "cnt_clr_lkp"))
+		mvPp2ClsC3HitCntrsClear (a);
+	else if (!strcmp(name, "sc_start"))
+		mvPp2ClsC3ScanStart();
+	else if (!strcmp(name, "sc_thresh"))
+		mvPp2ClsC3ScanThreshSet(a, b);
+	else if (!strcmp(name, "sc_clear_before"))
+		mvPp2ClsC3ScanClearBeforeEnSet(a);
+	else if (!strcmp(name, "sc_start_idx"))
+		mvPp2ClsC3ScanStartIndexSet(a);
+	else if (!strcmp(name, "sc_delay"))
+		mvPp2ClsC3ScanDelaySet(a);
+	else if (!strcmp(name, "sc_res_read"))
+		mvPp2ClsC3ScanResRead(a, NULL, NULL);
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t mv_cls3_signed_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  err = 0;
+	unsigned long flags;
+	int           a = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%d", &a);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "sc_lkp"))
+		mvPp2ClsC3ScanLkpTypeSet(a);
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+
+static DEVICE_ATTR(init_database,	S_IRUSR, mv_cls3_show, NULL);
+static DEVICE_ATTR(hw_dump,		S_IRUSR, mv_cls3_show, NULL);
+static DEVICE_ATTR(hw_ext_dump,		S_IRUSR, mv_cls3_show, NULL);
+static DEVICE_ATTR(sw_dump,		S_IRUSR, mv_cls3_show, NULL);
+static DEVICE_ATTR(sc_res_dump,		S_IRUSR, mv_cls3_show, NULL);
+static DEVICE_ATTR(sc_regs,		S_IRUSR, mv_cls3_show, NULL);
+static DEVICE_ATTR(hw_query,		S_IRUSR, mv_cls3_show, NULL);
+static DEVICE_ATTR(cnt_read_all,	S_IRUSR, mv_cls3_show, NULL);
+static DEVICE_ATTR(help,		S_IRUSR, mv_cls3_show, NULL);
+
+static DEVICE_ATTR(hw_query_add,	S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(hw_read,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(hw_add,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(hw_del,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(hw_del_all,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(sw_clear,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(sw_init_cnt,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(key_sw_l4,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(key_sw_lkp_type,	S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(key_sw_port,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(key_sw_size,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(key_sw_byte,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(key_sw_word,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(act_sw_color,	S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(act_sw_qh,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(act_sw_ql,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(act_sw_queue,	S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(act_sw_fwd,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(act_sw_pol,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(act_sw_modif,	S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(act_sw_dup,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(cnt_read,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(cnt_clr_all,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(cnt_clr_lkp,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(sc_start,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(sc_thresh,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(sc_clear_before,	S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(sc_lkp,		S_IWUSR, NULL, mv_cls3_signed_store);
+static DEVICE_ATTR(sc_start_idx,	S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(sc_delay,		S_IWUSR, NULL, mv_cls3_store);
+static DEVICE_ATTR(sc_res_read,		S_IWUSR, NULL, mv_cls3_store);
+
+
+
+static struct attribute *cls3_attrs[] = {
+	&dev_attr_init_database.attr,
+	&dev_attr_hw_dump.attr,
+	&dev_attr_hw_ext_dump.attr,
+	&dev_attr_sw_dump.attr,
+	&dev_attr_sc_res_dump.attr,
+	&dev_attr_sc_regs.attr,
+	&dev_attr_hw_query.attr,
+	&dev_attr_cnt_read_all.attr,
+	&dev_attr_help.attr,
+	&dev_attr_hw_query_add.attr,
+	&dev_attr_hw_read.attr,
+	&dev_attr_hw_add.attr,
+	&dev_attr_hw_del.attr,
+	&dev_attr_hw_del_all.attr,
+	&dev_attr_sw_clear.attr,
+	&dev_attr_sw_init_cnt.attr,
+	&dev_attr_key_sw_l4.attr,
+	&dev_attr_key_sw_lkp_type.attr,
+	&dev_attr_key_sw_port.attr,
+	&dev_attr_key_sw_size.attr,
+	&dev_attr_key_sw_byte.attr,
+	&dev_attr_key_sw_word.attr,
+	&dev_attr_act_sw_color.attr,
+	&dev_attr_act_sw_qh.attr,
+	&dev_attr_act_sw_ql.attr,
+	&dev_attr_act_sw_queue.attr,
+	&dev_attr_act_sw_fwd.attr,
+	&dev_attr_act_sw_pol.attr,
+	&dev_attr_act_sw_modif.attr,
+	&dev_attr_act_sw_dup.attr,
+	&dev_attr_cnt_read.attr,
+	&dev_attr_cnt_clr_all.attr,
+	&dev_attr_cnt_clr_lkp.attr,
+	&dev_attr_sc_start.attr,
+	&dev_attr_sc_thresh.attr,
+	&dev_attr_sc_clear_before.attr,
+	&dev_attr_sc_lkp.attr,
+	&dev_attr_sc_start_idx.attr,
+	&dev_attr_sc_delay.attr,
+	&dev_attr_sc_res_read.attr,
+	NULL
+};
+
+
+static struct attribute_group cls3_group = {
+	.name = "cls3",
+	.attrs = cls3_attrs,
+};
+
+int __devinit cls3_sysfs_init(void)
+{
+	int err;
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	if (!pd) {
+		platform_device_register_simple("pp2", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	}
+
+	if (!pd) {
+		printk(KERN_ERR "%s: cannot find neta device\n", __func__);
+		pd = &platform_bus;
+	}
+
+	err = sysfs_create_group(&pd->kobj, &cls3_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+out:
+	return err;
+}
+
+module_init(cls3_sysfs_init);
+
+MODULE_AUTHOR("Uri Eliyahu");
+MODULE_DESCRIPTION("cls engine C3 for Marvell NetA2");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls4_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls4_sysfs.c
new file mode 100644
index 0000000..20a1309
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls4_sysfs.c
@@ -0,0 +1,274 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include "mvOs.h"
+#include "mvCommon.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "../../../mv_hal/pp2/cls/mvPp2Cls4Hw.h"
+
+
+static MV_PP2_CLS_C4_ENTRY		C4;
+
+
+
+static ssize_t mv_cls_help(char *buf)
+{
+	int off = 0;
+	off += scnprintf(buf + off, PAGE_SIZE, "cat		  sw_dump 		- dump software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat		  hw_regs 		- dump hardware registers.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat		  hw_dump 		- dump all hardware entries.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE, "echo p s r	> hw_port_rules		- set physical port number <p> for rules set <s>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "                                          <rules> - number of rules.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo p s r	> hw_uni_rules		- set uni port number <p> for rules set <s>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "                                          <rules> - number of rules.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE, "echo s r    	> hw_write		- write software entry into hardware <set=s,rule=r>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo s r	> hw_read 		- read entry <set=s,rule=r> from hardware into software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo 1		> sw_clear		- clear software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo 1		> hw_clear_all		- clear all C4 rules in hardware.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo f o d	> rule_two_b 		- set two bytes of data <d> in field <f> with offset <o> to\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "					  software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo f id op	> rule_params 		- set ID <id> and OpCode <op> to filed <f> in software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo mode	> rule_sw_pppoe		- set PPPOE mode to software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo mode	> rule_sw_vlan		- set VLAN mode to software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo mode	> rule_sw_mac		- set mac to me mode to software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo mode	> rule_sw_l4		- set L4 info mode to software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo mode	> rule_sw_l3		- set L3 info mode to software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd	> act_sw_color		- set Color command <cmd> to action table software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd prio	> act_sw_prio		- set priority command <cmd> and value <prio> to action\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "					  table software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd dscp	> act_sw_dscp		- set DSCP command <cmd> and value <dscp> to action\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "					  table software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd gpid	> act_sw_gpid		- set GemPortID command <cmd> and value <gpid> to action\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "					  table software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd q	> act_sw_qh		- set queue high command <cmd> and value <q> to action\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "					  table software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd q	> act_sw_ql		- set queue low command <cmd> and value <q> to action\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "					  table software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd q	> act_sw_queue		- set full queue command <cmd> and value <q> to action\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "					  table software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo cmd id	> act_sw_pol		- set PolicerId command <cmd> and numver <id> to action\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "					  table software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+
+	return off;
+}
+
+
+static ssize_t mv_cls_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "sw_dump"))
+		mvPp2ClsC4SwDump(&C4);
+	else if (!strcmp(name, "hw_regs"))
+		mvPp2ClsC4RegsDump();
+	else if (!strcmp(name, "hw_dump"))
+		mvPp2ClsC4HwDumpAll();
+	else
+		off += mv_cls_help(buf);
+
+	return off;
+}
+
+
+static ssize_t mv_cls_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  err = 0, a = 0, b = 0, c = 0, d = 0, e = 0;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%x %x %x %x %x", &a, &b, &c, &d, &e);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "hw_port_rules"))
+		mvPp2ClsC4HwPortToRulesSet(a, b, c);
+	else if (!strcmp(name, "hw_uni_rules"))
+		mvPp2ClsC4HwUniToRulesSet(a, b, c);
+	else if (!strcmp(name, "hw_read"))
+		mvPp2ClsC4HwRead(&C4, b, a);
+	else if (!strcmp(name, "hw_write"))
+		mvPp2ClsC4HwWrite(&C4, b, a);
+	else if (!strcmp(name, "sw_clear"))
+		mvPp2ClsC4SwClear(&C4);
+	else if (!strcmp(name, "hw_clear_all"))
+		mvPp2ClsC4HwClearAll();
+	else if (!strcmp(name, "rule_two_b"))
+		mvPp2ClsC4FieldsShortSet(&C4, a, b, (unsigned short) c);
+	else if (!strcmp(name, "rule_params"))
+		mvPp2ClsC4FieldsParamsSet(&C4, a, b, c);
+	else if (!strcmp(name, "rule_sw_vlan"))
+		mvPp2ClsC4SwVlanSet(&C4, a);
+	else if (!strcmp(name, "rule_sw_pppoe"))
+		mvPp2ClsC4SwPppoeSet(&C4, a);
+	else if (!strcmp(name, "rule_sw_mac"))
+		mvPp2ClsC4SwMacMeSet(&C4, a);
+	else if (!strcmp(name, "rule_sw_l4"))
+		mvPp2ClsC4SwL4InfoSet(&C4, a);
+	else if (!strcmp(name, "rule_sw_l3"))
+		mvPp2ClsC4SwL3InfoSet(&C4, a);
+	else if (!strcmp(name, "act_sw_color"))
+		mvPp2ClsC4ColorSet(&C4, a);
+	else if (!strcmp(name, "act_sw_prio"))
+		mvPp2ClsC4PrioSet(&C4, a, b);
+	else if (!strcmp(name, "act_sw_dscp"))
+		mvPp2ClsC4DscpSet(&C4, a, b);
+	else if (!strcmp(name, "act_sw_gpid"))
+		mvPp2ClsC4GpidSet(&C4, a, b);
+	else if (!strcmp(name, "act_sw_qh"))
+		mvPp2ClsC4QueueHighSet(&C4, a, b);
+	else if (!strcmp(name, "act_sw_ql"))
+		mvPp2ClsC4QueueLowSet(&C4, a, b);
+	else if (!strcmp(name, "act_sw_queue"))
+		mvPp2ClsC4QueueSet(&C4, a, b);
+	else if (!strcmp(name, "act_sw_pol"))
+		mvPp2ClsC4PolicerSet(&C4, a, b);
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(hw_dump,			S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(sw_dump,			S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(hw_regs,			S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(help,			S_IRUSR, mv_cls_show, NULL);
+
+static DEVICE_ATTR(hw_port_rules,		S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(hw_uni_rules,		S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(hw_read,   	 	  	S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(hw_write,     		S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(sw_clear,     		S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(hw_clear_all,     		S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(rule_two_b,    		S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(rule_params,    		S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(rule_sw_vlan,		S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(rule_sw_pppoe,		S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(rule_sw_mac,			S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(rule_sw_l4,			S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(rule_sw_l3,			S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(act_sw_color,		S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(act_sw_prio,			S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(act_sw_dscp,			S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(act_sw_gpid,			S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(act_sw_qh,			S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(act_sw_ql,			S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(act_sw_queue,		S_IWUSR, NULL, mv_cls_store);
+static DEVICE_ATTR(act_sw_pol,			S_IWUSR, NULL, mv_cls_store);
+
+
+static struct attribute *cls4_attrs[] = {
+	&dev_attr_sw_dump.attr,
+	&dev_attr_hw_dump.attr,
+	&dev_attr_hw_regs.attr,
+	&dev_attr_help.attr,
+	&dev_attr_hw_port_rules.attr,
+	&dev_attr_hw_uni_rules.attr,
+	&dev_attr_hw_read.attr,
+	&dev_attr_hw_write.attr,
+	&dev_attr_sw_clear.attr,
+	&dev_attr_hw_clear_all.attr,
+	&dev_attr_rule_two_b.attr,
+	&dev_attr_rule_params.attr,
+	&dev_attr_rule_sw_vlan.attr,
+	&dev_attr_rule_sw_pppoe.attr,
+	&dev_attr_rule_sw_mac.attr,
+	&dev_attr_rule_sw_l4.attr,
+	&dev_attr_rule_sw_l3.attr,
+	&dev_attr_act_sw_color.attr,
+	&dev_attr_act_sw_prio.attr,
+	&dev_attr_act_sw_dscp.attr,
+	&dev_attr_act_sw_gpid.attr,
+	&dev_attr_act_sw_qh.attr,
+	&dev_attr_act_sw_ql.attr,
+	&dev_attr_act_sw_queue.attr,
+	&dev_attr_act_sw_pol.attr,
+	NULL
+};
+
+static struct attribute_group cls4_group = {
+	.name = "cls4",
+	.attrs = cls4_attrs,
+};
+
+int __devinit cls4_sysfs_init(void)
+{
+	int err;
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	if (!pd) {
+		platform_device_register_simple("pp2", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	}
+
+	if (!pd) {
+		printk(KERN_ERR "%s: cannot find neta device\n", __func__);
+		pd = &platform_bus;
+	}
+
+	err = sysfs_create_group(&pd->kobj, &cls4_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+out:
+	return err;
+}
+
+module_init(cls4_sysfs_init);
+
+MODULE_AUTHOR("Uri Eliyahu");
+MODULE_DESCRIPTION("cls engine C4 for Marvell PP2");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls_mc_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls_mc_sysfs.c
new file mode 100644
index 0000000..1667e93
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls_mc_sysfs.c
@@ -0,0 +1,207 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include "mvOs.h"
+#include "mvCommon.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "../../../mv_hal/pp2/cls/mvPp2ClsMcHw.h"
+
+
+static MV_PP2_MC_ENTRY		mc;
+
+
+
+static ssize_t mv_mc_help(char *buf)
+{
+	int off = 0;
+	off += scnprintf(buf + off, PAGE_SIZE, "cat		  sw_dump 		- Dump software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "cat		  hw_dump 		- Dump all hardware entries.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE, "echo i		> hw_write		- Write software entry into hardware <i>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo i		> hw_read 		- Read entry <i> from hardware into software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo 1		> sw_clear		- Clear software entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo 1		> hw_clear_all		- Clear all multicast table entries in hardware.\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE, "echo prio en	> mc_sw_prio		- Set modified priority enable <en> and value <prio> to sw entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo dscp en	> mc_sw_dscp		- Set modified DSCP enable <en> and value <dscp> to sw entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo gpid en	> mc_sw_gpid		- Set modified GemPortID enable <en> and value <gpid> to sw entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo d i        > mc_sw_modif             - Set modification data pointer <d> and instruction pointer <i> to sw entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo q		> mc_sw_queue		- Set Queue <q> value to sw entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo en		> mc_sw_hwf		- Set HWF enabled <en=1> or disable <en=0> to sw entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE, "echo next	> mc_sw_next		- Set next pointer <next> to sw entry.\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE, "\n");
+
+	return off;
+}
+
+static ssize_t mv_mc_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "sw_dump"))
+		mvPp2McSwDump(&mc);
+	else if (!strcmp(name, "hw_dump"))
+		mvPp2McHwDump();
+	else
+		off += mv_mc_help(buf);
+
+	return off;
+}
+
+
+static ssize_t mv_mc_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  err = 0, a = 0, b = 0, c = 0, d = 0, e = 0;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%x %x %x %x %x", &a, &b, &c, &d, &e);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "hw_read"))
+		mvPp2McHwRead(&mc, a);
+	else if (!strcmp(name, "hw_write"))
+		mvPp2McHwWrite(&mc, a);
+	else if (!strcmp(name, "sw_clear"))
+		mvPp2McSwClear(&mc);
+	else if (!strcmp(name, "hw_clear_all"))
+		mvPp2McHwClearAll();
+	else if (!strcmp(name, "mc_sw_prio"))
+		mvPp2McSwPrioSet(&mc, a, b);
+	else if (!strcmp(name, "mc_sw_dscp"))
+		mvPp2McSwDscpSet(&mc, a, b);
+	else if (!strcmp(name, "mc_sw_gpid"))
+		mvPp2McSwGpidSet(&mc, a, b);
+	else if (!strcmp(name, "mc_sw_modif"))
+		mvPp2McSwModSet(&mc, a, b);
+	else if (!strcmp(name, "mc_sw_queue"))
+		mvPp2McSwQueueSet(&mc, a);
+	else if (!strcmp(name, "mc_sw_hwf"))
+		mvPp2McSwForwardEn(&mc, a);
+	else if (!strcmp(name, "mc_sw_next"))
+		mvPp2McSwNext(&mc, a);
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(hw_dump,			S_IRUSR, mv_mc_show, NULL);
+static DEVICE_ATTR(sw_dump,			S_IRUSR, mv_mc_show, NULL);
+static DEVICE_ATTR(help,			S_IRUSR, mv_mc_show, NULL);
+
+static DEVICE_ATTR(hw_read,   	 	  	S_IWUSR, NULL, mv_mc_store);
+static DEVICE_ATTR(hw_write,     		S_IWUSR, NULL, mv_mc_store);
+static DEVICE_ATTR(sw_clear,     		S_IWUSR, NULL, mv_mc_store);
+static DEVICE_ATTR(hw_clear_all,     		S_IWUSR, NULL, mv_mc_store);
+static DEVICE_ATTR(mc_sw_prio,   	  	S_IWUSR, NULL, mv_mc_store);
+static DEVICE_ATTR(mc_sw_dscp,     		S_IWUSR, NULL, mv_mc_store);
+static DEVICE_ATTR(mc_sw_gpid,     		S_IWUSR, NULL, mv_mc_store);
+static DEVICE_ATTR(mc_sw_modif,     		S_IWUSR, NULL, mv_mc_store);
+static DEVICE_ATTR(mc_sw_queue,     		S_IWUSR, NULL, mv_mc_store);
+static DEVICE_ATTR(mc_sw_hwf,     		S_IWUSR, NULL, mv_mc_store);
+static DEVICE_ATTR(mc_sw_next,     		S_IWUSR, NULL, mv_mc_store);
+
+
+static struct attribute *mc_attrs[] = {
+	&dev_attr_sw_dump.attr,
+	&dev_attr_hw_dump.attr,
+	&dev_attr_help.attr,
+	&dev_attr_hw_read.attr,
+	&dev_attr_hw_write.attr,
+	&dev_attr_sw_clear.attr,
+	&dev_attr_hw_clear_all.attr,
+	&dev_attr_mc_sw_prio.attr,
+	&dev_attr_mc_sw_dscp.attr,
+	&dev_attr_mc_sw_gpid.attr,
+	&dev_attr_mc_sw_modif.attr,
+	&dev_attr_mc_sw_queue.attr,
+	&dev_attr_mc_sw_hwf.attr,
+	&dev_attr_mc_sw_next.attr,
+	NULL
+};
+
+static struct attribute_group mc_group = {
+	.name = "mc",
+	.attrs = mc_attrs,
+};
+
+int __devinit mc_sysfs_init(void)
+{
+	int err;
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	if (!pd) {
+		platform_device_register_simple("pp2", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	}
+
+	if (!pd) {
+		printk(KERN_ERR "%s: cannot find neta device\n", __func__);
+		pd = &platform_bus;
+	}
+
+	err = sysfs_create_group(&pd->kobj, &mc_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+out:
+	return err;
+}
+
+module_init(mc_sysfs_init);
+
+MODULE_AUTHOR("Uri Eliyahu");
+MODULE_DESCRIPTION("Multicast table for Marvell PP2");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls_sysfs.c
new file mode 100644
index 0000000..eac7442
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cls/cls_sysfs.c
@@ -0,0 +1,324 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include "mvOs.h"
+#include "mvCommon.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "../../../mv_hal/pp2/cls/mvPp2ClsHw.h"
+
+static MV_PP2_CLS_LKP_ENTRY	lkp_entry;
+static MV_PP2_CLS_FLOW_ENTRY	flow_entry;
+
+
+static ssize_t mv_cls_help(char *buf)
+{
+	int off = 0;
+	off += scnprintf(buf + off, PAGE_SIZE,  "cat		lkp_sw_dump		- dump lookup ID table sw entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "cat		flow_sw_dump		- dump flow table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "cat		lkp_hw_dump		- dump lookup ID tabel from hardware.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "cat		flow_hw_dump		- dump flow table from hardware.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "cat		len_change_hw_dump	- lkp dump sw entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "cat		hw_regs			- dump classifier top registers.\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE,  "\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo 1		>lkp_sw_clear		- clear lookup ID table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo 1		>flow_sw_clear	        - clear flow table SW entry.\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE,  "\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo en         >hw_enable              - classifier enable/disable <en = 1/0>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo p w        >hw_port_way		- set lookup way <w> for physical port <p>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo p mode	>hw_port_spid		- set SPID extraction mode <mode> for physical port <p>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo uni spid	>hw_uni_spid		- set port <uni> for spid <spid>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo virt gpid	>hw_virt_gpid		- set virtual port number <virt> for GemPortId <gpid>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo a b c d	>hw_udf			- set UDF field <a> as: base <b>, offset <c> bits, size<d> bits.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo p txp m	>hw_mtu       		- set MTU value <m> for egress port <p, txp>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo p rxq	>hw_over_rxq		- set  RXQ <rxq> for oversize ingress via port <p>.\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE,  "\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo idx way	>lkp_hw_write		- write lookup ID table SW entry HW <idx,way>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo idx way	>lkp_hw_read		- read lookup ID table entry from HW <idx,way>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo rxq	>lkp_sw_rxq		- set default RXQ <rxq> to lookup ID table.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo f		>lkp_sw_flow		- set index of firs insruction <f> in flow table\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "					  to lookup ID SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo m		>lkp_sw_mod		- set modification instruction offset <m> to lookup ID SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo e		>lkp_sw_en		- Enable <e=1> or disable <e=0> lookup ID table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo id         >flow_hw_write		- write flow table SW entry to HW <id>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo id         >flow_hw_read		- read flow table entry <id> from HW.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo t p        >flow_sw_port		- set port type <t> and number <p> to flow table SW entry\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo e l        >flow_sw_engine		- set engine <e> nember to flow table SW entry.  <l> - last bit.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo l p        >flow_sw_extra		- set lookup type <l> and priority <p> to flow table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo idx id     >flow_sw_hek		- set HEK field <idx, id> flow table SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo n          >flow_sw_num_of_heks	- set number of HEK fields <n> to flow table SW entry.\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE,  "\n");
+	off += scnprintf(buf + off, PAGE_SIZE,  "echo i len      >len_change_hw_set	- set signed length <len> (in decimal) change for modification index <idx> (in hex).\n");
+
+	return off;
+}
+
+
+static ssize_t mv_cls_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "lkp_sw_dump"))
+		mvPp2ClsSwLkpDump(&lkp_entry);
+	else if (!strcmp(name, "flow_sw_dump"))
+		mvPp2ClsSwFlowDump(&flow_entry);
+	else if (!strcmp(name, "lkp_hw_dump"))
+		mvPp2ClsHwLkpDump();
+	else if (!strcmp(name, "flow_hw_dump"))
+		mvPp2ClsHwFlowDump();
+	else if (!strcmp(name, "len_change_hw_dump"))
+		mvPp2ClsPktLenChangeDump();
+	else if (!strcmp(name, "hw_regs"))
+		mvPp2ClsHwRegsDump();
+	else
+		off += mv_cls_help(buf);
+
+	return off;
+}
+
+
+
+static ssize_t mv_prs_store_unsigned(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  err = 0, a = 0, b = 0, c = 0, d = 0;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%x %x %x %x", &a, &b, &c, &d);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "lkp_sw_clear"))
+		mvPp2ClsSwLkpClear(&lkp_entry);
+	else if (!strcmp(name, "lkp_hw_write"))
+		mvPp2ClsHwLkpWrite(a, b, &lkp_entry);
+	else if (!strcmp(name, "lkp_hw_read"))
+		mvPp2ClsHwLkpRead(a, b, &lkp_entry);
+	else if (!strcmp(name, "lkp_sw_rxq"))
+		mvPp2ClsSwLkpRxqSet(&lkp_entry, a);
+	else if (!strcmp(name, "lkp_sw_flow"))
+		mvPp2ClsSwLkpFlowSet(&lkp_entry, a);
+	else if (!strcmp(name, "lkp_sw_mod"))
+		mvPp2ClsSwLkpModSet(&lkp_entry, a);
+	else if (!strcmp(name, "lkp_sw_en"))
+		mvPp2ClsSwLkpEnSet(&lkp_entry, a);
+	else if (!strcmp(name, "flow_sw_clear"))
+		mvPp2ClsSwFlowClear(&flow_entry);
+	else if (!strcmp(name, "flow_hw_write"))
+		mvPp2ClsHwFlowWrite(a, &flow_entry);
+	else if (!strcmp(name, "flow_hw_read"))
+		mvPp2ClsHwFlowRead(a, &flow_entry);
+	else if (!strcmp(name, "flow_sw_port"))
+		mvPp2ClsSwFlowPortSet(&flow_entry, a, b);
+	else if (!strcmp(name, "flow_sw_engine"))
+		mvPp2ClsSwFlowEngineSet(&flow_entry, a, b);
+	else if (!strcmp(name, "flow_sw_extra"))
+		mvPp2ClsSwFlowExtraSet(&flow_entry, a, b);
+	else if (!strcmp(name, "flow_sw_hek"))
+		mvPp2ClsSwFlowHekSet(&flow_entry, a, b);
+	else if (!strcmp(name, "flow_sw_num_of_heks"))
+		mvPp2ClsSwFlowHekNumSet(&flow_entry, a);
+	else if (!strcmp(name, "hw_enable"))
+		mvPp2ClsHwEnable(a);
+	else if (!strcmp(name, "hw_port_way"))
+		mvPp2ClsHwPortWaySet(a, b);
+	else if (!strcmp(name, "hw_port_spid"))
+		mvPp2ClsHwPortSpidSet(a, b);
+	else if (!strcmp(name, "hw_uni_spid"))
+		mvPp2ClsHwUniPortSet(a, b);
+	else if (!strcmp(name, "hw_virt_gpid"))
+		mvPp2ClsHwVirtPortSet(a, b);
+	else if (!strcmp(name, "hw_udf"))
+		mvPp2ClsHwUdfSet(a, b, c, d);
+	else if (!strcmp(name, "hw_mtu"))
+		mvPp2ClsHwMtuSet(a, b, c);
+	else if (!strcmp(name, "hw_over_rxq"))
+		mvPp2ClsHwOversizeRxqSet(a, b);
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+
+static ssize_t mv_prs_store_signed(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  err = 0, a = 0;
+	unsigned long flags;
+	int b = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%x %d", &a, &b);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "len_change_hw_set"))
+		mvPp2ClsPktLenChangeSet(a, b);
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(lkp_hw_dump,			S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(flow_hw_dump,		S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(lkp_sw_dump,			S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(flow_sw_dump,		S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(len_change_hw_dump,		S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(help,			S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(hw_regs,			S_IRUSR, mv_cls_show, NULL);
+static DEVICE_ATTR(lkp_sw_clear,    		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(lkp_hw_write,     		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(lkp_hw_read,      		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(lkp_sw_rxq,    		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(lkp_sw_flow, 		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(lkp_sw_mod,			S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(lkp_sw_en,      		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(flow_sw_clear,		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(flow_hw_write,		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(flow_hw_read,		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(flow_sw_port,		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(flow_sw_engine,		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(flow_sw_extra,		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(flow_sw_hek,			S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(flow_sw_num_of_heks,		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(len_change_hw_set,		S_IWUSR, mv_cls_show, mv_prs_store_signed);
+static DEVICE_ATTR(hw_enable,			S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(hw_port_way,			S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(hw_port_spid,		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(hw_uni_spid,			S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(hw_virt_gpid,		S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(hw_udf,			S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(hw_mtu,			S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(hw_over_rxq,			S_IWUSR, mv_cls_show, mv_prs_store_unsigned);
+
+static struct attribute *cls_attrs[] = {
+    &dev_attr_lkp_sw_dump.attr,
+    &dev_attr_flow_sw_dump.attr,
+    &dev_attr_lkp_hw_dump.attr,
+    &dev_attr_flow_hw_dump.attr,
+    &dev_attr_len_change_hw_dump.attr,
+    &dev_attr_hw_regs.attr,
+    &dev_attr_lkp_sw_clear.attr,
+    &dev_attr_lkp_hw_write.attr,
+    &dev_attr_lkp_hw_read.attr,
+    &dev_attr_lkp_sw_rxq.attr,
+    &dev_attr_lkp_sw_flow.attr,
+    &dev_attr_lkp_sw_mod.attr,
+    &dev_attr_lkp_sw_en.attr,
+    &dev_attr_flow_sw_clear.attr,
+    &dev_attr_flow_hw_write.attr,
+    &dev_attr_flow_hw_read.attr,
+    &dev_attr_flow_sw_port.attr,
+    &dev_attr_flow_sw_engine.attr,
+    &dev_attr_flow_sw_extra.attr,
+    &dev_attr_flow_sw_hek.attr,
+    &dev_attr_flow_sw_num_of_heks.attr,
+    &dev_attr_len_change_hw_set.attr,
+    &dev_attr_hw_enable.attr,
+    &dev_attr_hw_port_way.attr,
+    &dev_attr_hw_port_spid.attr,
+    &dev_attr_hw_uni_spid.attr,
+    &dev_attr_hw_virt_gpid.attr,
+    &dev_attr_hw_udf.attr,
+    &dev_attr_hw_mtu.attr,
+    &dev_attr_hw_over_rxq.attr,
+    &dev_attr_help.attr,
+    NULL
+};
+
+static struct attribute_group cls_group = {
+	.name = "cls",
+	.attrs = cls_attrs,
+};
+
+int __devinit cls_sysfs_init(void)
+{
+	int err;
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	if (!pd) {
+		platform_device_register_simple("pp2", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	}
+
+	if (!pd) {
+		printk(KERN_ERR "%s: cannot find neta device\n", __func__);
+		pd = &platform_bus;
+	}
+
+	err = sysfs_create_group(&pd->kobj, &cls_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+out:
+	return err;
+}
+
+module_init(cls_sysfs_init);
+
+MODULE_AUTHOR("Uri Eliyahu");
+MODULE_DESCRIPTION("cls for Marvell NetA2");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/Makefile
new file mode 100644
index 0000000..bf33d29
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/Makefile
@@ -0,0 +1,27 @@
+#
+# Makefile for the Marvell Gigabit Ethernet driver
+#
+
+ifeq ($(CONFIG_ARCH_FEROCEON),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA370),y)
+	include $(srctree)/$(MACHINE)/config/mvRules.mk
+endif
+
+ifeq ($(CONFIG_ARCH_ARMADA_XP),y)
+	include $(srctree)/arch/arm/mach-armadaxp/config/mvRules.mk
+endif
+
+#obj-$(CONFIG_MV_ETHERNET) += mv_netdev.o mv_ethernet.o mv_eth_sysfs.o
+#obj-$(CONFIG_MV_ETH_PP2) += mv_netdev.o mv_ethernet.o
+#obj-$(CONFIG_MV_PON)      += mv_pon_sysfs.o
+#obj-$(CONFIG_MV_ETH_SWITCH) +=  mv_eth_switch.o
+#obj-$(CONFIG_MV_ETH_TOOL) += mv_eth_tool.o
+
+obj-$(CONFIG_MV_ETH_PP2) 		+= $(LSP_NET_DEV_DIR)/mv_netdev.o $(LSP_NET_DEV_DIR)/mv_ethernet.o
+obj-$(CONFIG_MV_ETH_SWITCH) 		+= $(LSP_NET_DEV_DIR)/mv_eth_switch.o
+obj-$(CONFIG_MV_ETH_PP2)                 += $(LSP_BM_DIR)/mv_eth_bm.o
+obj-$(CONFIG_MV_ETH_PP2) 	        += $(LSP_PRS_DIR)/prs_sysfs.o
+obj-$(CONFIG_MV_ETH_PP2) 	        += $(LSP_CLS_DIR)/cls_sysfs.o $(LSP_CLS_DIR)/cls2_sysfs.o
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_bm_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_bm_sysfs.c
new file mode 100644
index 0000000..b7684d0
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_bm_sysfs.c
@@ -0,0 +1,134 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "mv_eth_sysfs.h"
+#include "gbe/mvPp2Gbe.h"
+#include "mv_netdev.h"
+
+static ssize_t mv_eth_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "echo [pool]         > poolRegs    - print BM pool registers\n");
+	off += sprintf(buf+off, "echo [pool]         > poolStatus  - print BM pool status\n");
+	off += sprintf(buf+off, "echo [pool] [size]  > poolSize    - set packet size <size> to BM pool <pool>\n");
+
+	return off;
+}
+
+static ssize_t mv_eth_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = mv_eth_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_eth_port_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = p = v = 0;
+	sscanf(buf, "%d %d", &p, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "poolRegs")) {
+		mvPp2BmPoolRegs(p);
+	} else if (!strcmp(name, "poolStatus")) {
+		mv_eth_pool_status_print(p);
+	} else if (!strcmp(name, "poolSize")) {
+		err = mv_eth_ctrl_pool_size_set(p, v);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,        S_IRUSR, mv_eth_show, NULL);
+static DEVICE_ATTR(poolRegs,   	S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(poolStatus, 	S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(poolSize, 	S_IWUSR, NULL, mv_eth_port_store);
+
+static struct attribute *mv_eth_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_poolRegs.attr,
+	&dev_attr_poolStatus.attr,
+	&dev_attr_poolSize.attr,
+	NULL
+};
+
+static struct attribute_group mv_eth_group = {
+	.name = "bm",
+	.attrs = mv_eth_attrs,
+};
+
+int mv_eth_bm_sysfs_init(struct kobject *pp2_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp2_kobj, &mv_eth_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+
+out:
+	return err;
+}
+
+MODULE_AUTHOR("Kostya Belezko");
+MODULE_DESCRIPTION("sysfs for marvell GbE");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_napi_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_napi_sysfs.c
new file mode 100644
index 0000000..40dd6e3
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_napi_sysfs.c
@@ -0,0 +1,171 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "mv_eth_sysfs.h"
+#include "gbe/mvPp2Gbe.h"
+#include "mv_netdev.h"
+
+static ssize_t mv_eth_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "echo [p]                     > napiShow      - show port's napi groups info\n");
+	off += sprintf(buf+off, "echo [p] [group]             > napiCreate    - create an empty napi group (cpu_mask = rxq_mask = 0)\n");
+	off += sprintf(buf+off, "echo [p] [group]             > napiDelete    - delete an existing empty napi group\n");
+	off += sprintf(buf+off, "echo [p] [group] [cpus]      > cpuGroup      - set <cpus mask> for <port/napi group>\n");
+	off += sprintf(buf+off, "echo [p] [group] [rxqs]      > rxqGroup      - set <rxqs mask> for <port/napi group>\n");
+
+	return off;
+}
+
+static ssize_t mv_eth_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = mv_eth_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_eth_port_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = p = v = 0;
+	sscanf(buf, "%d %d", &p, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "napiShow")) {
+		mv_eth_napi_groups_print(p);
+	} else if (!strcmp(name, "napiCreate")) {
+		mv_eth_port_napi_group_create(p, v);
+	} else if (!strcmp(name, "napiDelete")) {
+		mv_eth_port_napi_group_delete(p, v);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t mv_eth_3_hex_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, i, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	err = p = i = v = 0;
+	sscanf(buf, "%d %d %x", &p, &i, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "cpuGroup")) {
+		err = mv_eth_napi_set_cpu_affinity(p, i, v);
+	} else if (!strcmp(name, "rxqGroup")) {
+		err = mv_eth_napi_set_rxq_affinity(p, i, v);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+
+static DEVICE_ATTR(help,         S_IRUSR, mv_eth_show, NULL);
+static DEVICE_ATTR(napiCreate,   S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(napiDelete,   S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(napiShow,     S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(cpuGroup,     S_IWUSR, NULL, mv_eth_3_hex_store);
+static DEVICE_ATTR(rxqGroup,     S_IWUSR, NULL, mv_eth_3_hex_store);
+
+static struct attribute *mv_eth_attrs[] = {
+	&dev_attr_napiCreate.attr,
+	&dev_attr_napiDelete.attr,
+	&dev_attr_cpuGroup.attr,
+	&dev_attr_rxqGroup.attr,
+	&dev_attr_help.attr,
+	&dev_attr_napiShow.attr,
+	NULL
+};
+
+static struct attribute_group mv_eth_group = {
+	.name = "napi",
+	.attrs = mv_eth_attrs,
+};
+
+int mv_eth_napi_sysfs_init(struct kobject *pp2_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp2_kobj, &mv_eth_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+
+out:
+	return err;
+}
+
+MODULE_AUTHOR("Kostya Belezko");
+MODULE_DESCRIPTION("sysfs for marvell GbE");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pme_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pme_sysfs.c
new file mode 100644
index 0000000..e2be6d7
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pme_sysfs.c
@@ -0,0 +1,134 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "mv_eth_sysfs.h"
+#include "gbe/mvPp2Gbe.h"
+#include "mv_netdev.h"
+
+static ssize_t mv_eth_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "echo [p] [hex]       > modCmd       - set 2 bytes of TX descriptor offset 0x16\n");
+	off += sprintf(buf+off, "echo [p] [hex]       > pmeDptr      - set 2 bytes of PME_DPTR field in TX descriptor\n");
+	off += sprintf(buf+off, "echo [p] [hex]       > pmeProgram   - set 1 bytes of PME_Prpgram field in TX descriptor\n");
+
+	return off;
+}
+
+static ssize_t mv_eth_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = mv_eth_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_eth_port_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = p = v = 0;
+	sscanf(buf, "%d %x", &p, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "modCmd")) {
+		err = mv_eth_ctrl_tx_cmd_mod(p, v);
+	} else if (!strcmp(name, "pmeDptr")) {
+		err = mv_eth_ctrl_tx_cmd_pme_dptr(p, v);
+	} else if (!strcmp(name, "pmeProgram")) {
+		err = mv_eth_ctrl_tx_cmd_pme_prog(p, v);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,        S_IRUSR, mv_eth_show, NULL);
+static DEVICE_ATTR(modCmd,	S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(pmeDptr,	S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(pmeProgram,	S_IWUSR, NULL, mv_eth_port_store);
+
+static struct attribute *mv_eth_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_modCmd.attr,
+	&dev_attr_pmeDptr.attr,
+	&dev_attr_pmeProgram.attr,
+	NULL
+};
+
+static struct attribute_group mv_eth_group = {
+	.name = "pme",
+	.attrs = mv_eth_attrs,
+};
+
+int mv_eth_pme_sysfs_init(struct kobject *pp2_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp2_kobj, &mv_eth_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+
+out:
+	return err;
+}
+
+MODULE_AUTHOR("Kostya Belezko");
+MODULE_DESCRIPTION("sysfs for marvell GbE");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pon_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pon_sysfs.c
new file mode 100644
index 0000000..fa05c1f
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pon_sysfs.c
@@ -0,0 +1,162 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "mv_eth_sysfs.h"
+#include "gbe/mvPp2Gbe.h"
+#include "prs/mvPp2Prs.h"
+#include "mv_netdev.h"
+
+static ssize_t mv_eth_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "echo [p] [0|1]       > mhEn         - enable Marvell Header\n");
+	off += sprintf(buf+off, "echo [p] [hex]       > mh_2B        - set 2 bytes of Marvell Header\n");
+
+	off += sprintf(buf+off, "echo [p] [hex]       > dsaTag       - set 2 bits of DSA tag in tx descriptor\n");
+	off += sprintf(buf+off, "echo [p] [hex]       > pktColor     - set 2 bits of packet color in tx descriptor\n");
+	off += sprintf(buf+off, "echo [p] [hex]       > gemPortId    - set 12 bits of GEM port id in tx descriptor\n");
+	off += sprintf(buf+off, "echo [p] [hex]       > ponFec       - set 1 bit of PON fec in tx descriptor\n");
+	off += sprintf(buf+off, "echo [p] [hex]       > gemOem       - set 1 bit of GEM OEM in tx descriptor\n");
+	off += sprintf(buf+off, "echo [p] [hex]       > mhRxSpecial  - set RX MH value for RX special packets\n");
+
+	return off;
+}
+
+static ssize_t mv_eth_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = mv_eth_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_eth_port_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = p = v = 0;
+	sscanf(buf, "%d %x", &p, &v);
+
+	local_irq_save(flags);
+
+
+	if (!strcmp(name, "mh_2B")) {
+		err = mv_eth_ctrl_tx_mh(p, (u16)v);
+	} else if (!strcmp(name, "mhEn")) {
+		err = mv_eth_ctrl_flag(p, MV_ETH_F_MH, v);
+	} else if (!strcmp(name, "dsaTag")) {
+		err = mv_eth_ctrl_tx_cmd_dsa(p, v);
+	} else if (!strcmp(name, "pktColor")) {
+		err = mv_eth_ctrl_tx_cmd_color(p, v);
+	} else if (!strcmp(name, "gemPortId")) {
+		err = mv_eth_ctrl_tx_cmd_gem_id(p, v);
+	} else if (!strcmp(name, "ponFec")) {
+		err = mv_eth_ctrl_tx_cmd_pon_fec(p, v);
+	} else if (!strcmp(name, "gemOem")) {
+		err = mv_eth_ctrl_tx_cmd_gem_oem(p, v);
+	} else if (!strcmp(name, "mhRxSpecial")) {
+		mvPrsMhRxSpecialSet(MV_PON_PORT_ID, 1, v);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,        S_IRUSR, mv_eth_show, NULL);
+static DEVICE_ATTR(mh_2B,	S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(mhEn,	S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(dsaTag,	S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(pktColor,	S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(gemPortId,	S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(ponFec,	S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(gemOem,	S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(mhRxSpecial,	S_IWUSR, NULL, mv_eth_port_store);
+
+static struct attribute *mv_eth_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_mh_2B.attr,
+	&dev_attr_mhEn.attr,
+	&dev_attr_dsaTag.attr,
+	&dev_attr_pktColor.attr,
+	&dev_attr_gemPortId.attr,
+	&dev_attr_ponFec.attr,
+	&dev_attr_gemOem.attr,
+	&dev_attr_mhRxSpecial.attr,
+	NULL
+};
+
+static struct attribute_group mv_eth_group = {
+	.name = "pon",
+	.attrs = mv_eth_attrs,
+};
+
+int mv_eth_pon_sysfs_init(struct kobject *pp2_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp2_kobj, &mv_eth_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+
+out:
+	return err;
+}
+
+MODULE_AUTHOR("Kostya Belezko");
+MODULE_DESCRIPTION("sysfs for marvell GbE");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_qos_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_qos_sysfs.c
new file mode 100644
index 0000000..0a31f44
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_qos_sysfs.c
@@ -0,0 +1,156 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "mv_eth_sysfs.h"
+#include "gbe/mvPp2Gbe.h"
+#include "mv_netdev.h"
+
+static ssize_t mv_eth_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "echo [p]                     > dscp          - show RX and TX DSCP map for port <p>\n");
+	off += sprintf(buf+off, "echo [p] [txq] [dscp]        > txqDscp       - set <txq> for outgoing IP packets with <dscp>\n");
+
+	return off;
+}
+
+static ssize_t mv_eth_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = mv_eth_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_eth_port_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = p = 0;
+	sscanf(buf, "%d", &p);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "dscp")) {
+		mv_eth_dscp_map_show(p);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t mv_eth_3_hex_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, i, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	err = p = i = v = 0;
+	sscanf(buf, "%d %d %x", &p, &i, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "txqDscp")) {
+		err = mv_eth_txq_dscp_map_set(p, i, v);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+
+static DEVICE_ATTR(help,         S_IRUSR, mv_eth_show, NULL);
+static DEVICE_ATTR(dscp,         S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(txqDscp,      S_IWUSR, NULL, mv_eth_3_hex_store);
+
+
+static struct attribute *mv_eth_attrs[] = {
+	&dev_attr_dscp.attr,
+	&dev_attr_txqDscp.attr,
+	&dev_attr_help.attr,
+	NULL
+};
+
+static struct attribute_group mv_eth_group = {
+	.name = "qos",
+	.attrs = mv_eth_attrs,
+};
+
+int mv_eth_qos_sysfs_init(struct kobject *pp2_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp2_kobj, &mv_eth_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+out:
+	return err;
+}
+
+MODULE_AUTHOR("Kostya Belezko");
+MODULE_DESCRIPTION("sysfs for marvell GbE");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_rx_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_rx_sysfs.c
new file mode 100644
index 0000000..a0f3b53
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_rx_sysfs.c
@@ -0,0 +1,147 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "mv_eth_sysfs.h"
+#include "gbe/mvPp2Gbe.h"
+#include "mv_netdev.h"
+
+static ssize_t mv_eth_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "cat                    rxDmaRegs     - print RX DMA registers\n");
+	off += sprintf(buf+off, "echo [p]             > rxFifoRegs    - show Rx Fifo registers for port <p> range [0..max]\n");
+	off += sprintf(buf+off, "echo [rxq]           > gRxqRegs      - show RXQ registers for global <Rxq> range [0..max]\n");
+	off += sprintf(buf+off, "echo [p] [rxq] [v]   > rxqShow       - show RXQ descriptors ring for <p/rxq>. v=0-brief, v=1-full\n");
+	off += sprintf(buf+off, "echo [p] [rxq] [v]   > rxqSize       - set number of descriptors <v> for <port/rxq>.\n");
+
+	return off;
+}
+
+static ssize_t mv_eth_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "rxDmaRegs")) {
+		mvPp2RxDmaRegsPrint();
+	} else {
+		off = mv_eth_help(buf);
+	}
+
+	return off;
+}
+
+static ssize_t mv_eth_port_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, v, a;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = p = v = a = 0;
+	sscanf(buf, "%d %d %d", &p, &v, &a);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "rxqShow")) {
+		mvPp2RxqShow(p, v, a);
+	} else if (!strcmp(name, "gRxqRegs")) {
+		mvPp2PhysRxqRegs(p);
+	} else if (!strcmp(name, "rxFifoRegs")) {
+		mvPp2RxFifoRegs(p);
+	} else if (!strcmp(name, "rxqSize")) {
+		mv_eth_ctrl_rxq_size_set(p, v, a);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,        S_IRUSR, mv_eth_show, NULL);
+static DEVICE_ATTR(rxDmaRegs,  	S_IRUSR, mv_eth_show, NULL);
+static DEVICE_ATTR(rxqShow,     S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(gRxqRegs,    S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(rxFifoRegs,  S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(rxqSize,   	S_IWUSR, NULL, mv_eth_port_store);
+
+static struct attribute *mv_eth_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_rxDmaRegs.attr,
+	&dev_attr_rxqShow.attr,
+	&dev_attr_gRxqRegs.attr,
+	&dev_attr_rxFifoRegs.attr,
+	&dev_attr_rxqSize.attr,
+	NULL
+};
+
+static struct attribute_group mv_eth_group = {
+	.name = "rx",
+	.attrs = mv_eth_attrs,
+};
+
+int mv_eth_rx_sysfs_init(struct kobject *pp2_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp2_kobj, &mv_eth_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+
+out:
+	return err;
+}
+
+MODULE_AUTHOR("Kostya Belezko");
+MODULE_DESCRIPTION("sysfs for marvell GbE");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_switch.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_switch.c
new file mode 100644
index 0000000..5a7b306
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_switch.c
@@ -0,0 +1,791 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mvCommon.h"  /* Should be included before mvSysHwConfig */
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/pci.h>
+#include <linux/ip.h>
+#include <linux/in.h>
+#include <linux/tcp.h>
+#include <linux/version.h>
+#include <net/ip.h>
+#include <net/xfrm.h>
+
+#include "mvOs.h"
+#include "dbg-trace.h"
+#include "mvSysHwConfig.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#ifdef MV_INCLUDE_ETH_COMPLEX
+#include "ctrlEnv/mvCtrlEthCompLib.h"
+#endif /* MV_INCLUDE_ETH_COMPLEX */
+#include "gbe/mvPp2Gbe.h"
+
+#include "mv_switch.h"
+#include "mv_netdev.h"
+
+extern int mv_net_devs_num;
+
+/* Example: "mv_net_config=4,(00:99:88:88:99:77,0)(00:55:44:55:66:77,1:2:3:4)(00:11:22:33:44:55,),mtu=1500" */
+static char			*net_config_str[CONFIG_MV_ETH_PORTS_NUM] = {NULL};
+struct mv_eth_switch_config     switch_net_config[CONFIG_MV_ETH_PORTS_NUM];
+
+static int                      mv_eth_switch_started = 0;
+unsigned int                    switch_enabled_ports = 0;
+
+/* Required to get the configuration string from the Kernel Command Line */
+int mv_eth0_cmdline_config(char *s);
+__setup("mv_net_config=", mv_eth0_cmdline_config);
+
+int mv_eth0_cmdline_config(char *s)
+{
+	net_config_str[MV_ETH_PORT_0] = s;
+	return 1;
+}
+
+int mv_eth1_cmdline_config(char *s);
+__setup("mv_net_config1=", mv_eth1_cmdline_config);
+
+int mv_eth1_cmdline_config(char *s)
+{
+	net_config_str[MV_ETH_PORT_1] = s;
+	return 1;
+}
+
+
+/* Local function prototypes */
+static int mv_eth_check_open_bracket(char **p_net_config)
+{
+	if (**p_net_config == '(') {
+		(*p_net_config)++;
+		return 0;
+	}
+	printk(KERN_ERR "Syntax error: could not find opening bracket\n");
+	return -EINVAL;
+}
+
+static int mv_eth_check_closing_bracket(char **p_net_config)
+{
+	if (**p_net_config == ')') {
+		(*p_net_config)++;
+		return 0;
+	}
+	printk(KERN_ERR "Syntax error: could not find closing bracket\n");
+	return -EINVAL;
+}
+
+static int mv_eth_check_comma(char **p_net_config)
+{
+	if (**p_net_config == ',') {
+		(*p_net_config)++;
+		return 0;
+	}
+	printk(KERN_ERR "Syntax error: could not find comma\n");
+	return -EINVAL;
+}
+
+static int mv_eth_netconfig_mac_addr_get(char **p_net_config, int idx, int port)
+{
+	int     num;
+	char *config_str = *p_net_config;
+	MV_U32  mac[MV_MAC_ADDR_SIZE];
+
+	/* the MAC address should look like: 00:99:88:88:99:77 */
+	/* that is, 6 two-digit numbers, separated by :        */
+	num = sscanf(config_str, "%2x:%2x:%2x:%2x:%2x:%2x",
+		&mac[0], &mac[1], &mac[2], &mac[3], &mac[4], &mac[5]);
+	if (num == MV_MAC_ADDR_SIZE) {
+		while (--num >= 0)
+			switch_net_config[port].mac_addr[idx][num] = (mac[num] & 0xFF);
+
+		(*p_net_config) = config_str + 17;
+		return 0;
+	}
+	printk(KERN_ERR "Syntax error while parsing MAC address from command line\n");
+	return -EINVAL;
+}
+
+static int mv_eth_netconfig_ports_get(char **p_net_config, int idx, int port)
+{
+	char ch;
+	char *config_str = *p_net_config;
+	int  sw_port, mask = 0, status = -EINVAL;
+
+	/* the switch port list should look like this: */
+	/* example 0: )         - no ports */
+	/* example 1: 0)        - single port 0 */
+	/* example 2: 1:2:3:4)  - multiple ports */
+
+	while (1) {
+		ch = *config_str++;
+
+		if (ch == ')') {
+			/* Finished */
+			status = 0;
+			break;
+		}
+		sw_port = mvCharToDigit(ch);
+		if (sw_port < 0)
+			break;
+
+		/* TBD - Check sw_port validity */
+		mask |= (1 << sw_port);
+
+		if (*config_str == ':')
+			config_str++;
+	}
+	*p_net_config = config_str;
+
+	if (status == 0) {
+		switch_net_config[port].board_port_map[idx] = mask;
+		return 0;
+	}
+	printk(KERN_ERR "Syntax error while parsing switch port mask from command line\n");
+	return -EINVAL;
+}
+
+/* the mtu value is constructed as follows: */
+/* mtu=value                                */
+static int  mv_eth_netconfig_mtu_get(char **p_net_config, int port)
+{
+	unsigned int mtu;
+
+	if (strncmp(*p_net_config, "mtu=", 4) == 0) {
+		*p_net_config += 4;
+		mtu = strtol(*p_net_config, p_net_config, 10);
+		if (mtu > 0) {
+			switch_net_config[port].mtu = mtu;
+			printk(KERN_ERR "      o MTU set to %d.\n", mtu);
+			return 0;
+		}
+		printk(KERN_ERR "Syntax error while parsing mtu value from command line\n");
+		return -EINVAL;
+	}
+
+	switch_net_config[port].mtu = 1500;
+	printk(KERN_ERR "      o Using default MTU %d\n", switch_net_config[port].mtu);
+	return 0;
+}
+
+static int mv_eth_netconfig_max_get(char **p_net_config, int port)
+{
+	char num = **p_net_config;
+	int netdev_num;
+
+	netdev_num = mvCharToDigit(num);
+	if (netdev_num >= 0) {
+		switch_net_config[port].netdev_max = netdev_num;
+		(*p_net_config) += 1;
+		return 0;
+	}
+	printk(KERN_ERR "Syntax error while parsing number of netdevs from command line\n");
+	return -EINVAL;
+}
+
+int mv_eth_switch_config_get(int use_existing_config, int port)
+{
+	char *p_net_config;
+	int i = 0;
+
+	if ((port != MV_ETH_PORT_0) && (port != MV_ETH_PORT_1))	{
+		printk(KERN_ERR "%s: invalid port number %d\n", __func__, port);
+		return -EINVAL;
+	}
+
+	if (!use_existing_config) {
+		memset(&(switch_net_config[port]), 0, sizeof((switch_net_config[port])));
+
+		if (net_config_str[port] != NULL) {
+			printk(KERN_ERR "      o Using UBoot netconfig string for port %d\n", port);
+		} else {
+			printk(KERN_ERR "      o Using default netconfig string from Kconfig for port %d\n", port);
+			if (port == MV_ETH_PORT_0)
+				net_config_str[port] = CONFIG_MV_ETH_SWITCH_NETCONFIG_0;
+			else if (port == MV_ETH_PORT_1)
+				net_config_str[port] = CONFIG_MV_ETH_SWITCH_NETCONFIG_1;
+		}
+		printk(KERN_ERR "        net_config_str[%d]: %s\n", port, net_config_str[port]);
+
+		p_net_config = net_config_str[port];
+		if (mv_eth_netconfig_max_get(&p_net_config, port))
+			return -EINVAL;
+
+		/* check restriction: at least one of the configuration strings must be 0 */
+		if ((net_config_str[MV_ETH_PORT_0] != NULL) &&
+		    (net_config_str[MV_ETH_PORT_1] != NULL) &&
+		    (switch_net_config[MV_ETH_PORT_0].netdev_max != 0) &&
+		    (switch_net_config[MV_ETH_PORT_1].netdev_max != 0)) {
+			printk(KERN_ERR "%s: cannot have both GbE ports using the Gateway driver, change mv_net_config\n", __func__);
+			return -EINVAL;
+		}
+
+		if (switch_net_config[port].netdev_max == 0)
+			return 1;
+
+		if (switch_net_config[port].netdev_max > CONFIG_MV_ETH_SWITCH_NETDEV_NUM) {
+			printk(KERN_ERR "Too large number of netdevs (%d) in command line: cut to %d\n",
+				switch_net_config[port].netdev_max, CONFIG_MV_ETH_SWITCH_NETDEV_NUM);
+			switch_net_config[port].netdev_max = CONFIG_MV_ETH_SWITCH_NETDEV_NUM;
+		}
+
+		if (mv_eth_check_comma(&p_net_config))
+			return -EINVAL;
+
+		for (i = 0; (i < CONFIG_MV_ETH_SWITCH_NETDEV_NUM) && (*p_net_config != '\0'); i++) {
+			if (mv_eth_check_open_bracket(&p_net_config))
+				return -EINVAL;
+
+			if (mv_eth_netconfig_mac_addr_get(&p_net_config, i, port))
+				return -EINVAL;
+
+			if (mv_eth_check_comma(&p_net_config))
+				return -EINVAL;
+
+			if (mv_eth_netconfig_ports_get(&p_net_config, i, port))
+				return -EINVAL;
+
+			switch_net_config[port].netdev_cfg++;
+
+			/* If we have a comma after the closing bracket, then interface */
+			/* definition is done.                                          */
+			if (*p_net_config == ',') {
+				p_net_config++;
+				break;
+			}
+		}
+
+		/* there is a chance the previous loop did not end because a comma was found but because	*/
+		/* the maximum number of interfaces was reached, so check for the comma now.		*/
+		if (i == CONFIG_MV_ETH_SWITCH_NETDEV_NUM)
+			if (mv_eth_check_comma(&p_net_config))
+				return -EINVAL;
+
+		if (*p_net_config != '\0') {
+			if (mv_eth_netconfig_mtu_get(&p_net_config, port))
+				return -EINVAL;
+		} else {
+			switch_net_config[port].mtu = 1500;
+			printk(KERN_ERR "      o Using default MTU %d\n", switch_net_config[port].mtu);
+		}
+
+		/* at this point, we have parsed up to CONFIG_MV_ETH_SWITCH_NETDEV_NUM, and the mtu value */
+		/* if the net_config string is not finished yet, then its format is invalid */
+		if (*p_net_config != '\0') {
+			printk(KERN_ERR "Switch netconfig string is too long: %s\n", p_net_config);
+			return -EINVAL;
+		}
+	} else {
+		/* leave most of the configuration as-is, but update MAC addresses */
+		/* MTU is saved in mv_eth_switch_change_mtu */
+
+		/* Note: at this point, since this is a re-init, mv_eth_switch_netdev_first */
+		/* and mv_eth_switch_netdev_last, as well as mv_net_devs[], are valid.      */
+		for (i = mv_eth_switch_netdev_first; i <= mv_eth_switch_netdev_last; i++) {
+			if (mv_net_devs[i] != NULL)
+				memcpy(switch_net_config[port].mac_addr[i - mv_eth_switch_netdev_first],
+					mv_net_devs[i]->dev_addr, MV_MAC_ADDR_SIZE);
+		}
+
+		if (switch_net_config[port].netdev_max == 0)
+			return 1;
+	}
+
+	return 0;
+}
+
+int    mv_eth_switch_set_mac_addr(struct net_device *dev, void *mac)
+{
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+	struct sockaddr *addr = (struct sockaddr *)mac;
+
+	if (!is_valid_ether_addr(addr->sa_data))
+		return -EADDRNOTAVAIL;
+
+	/* remove old mac addr from VLAN DB */
+	mv_switch_mac_addr_set(dev->dev_addr, MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id), (1 << dev_priv->cpu_port), 0);
+
+	memcpy(dev->dev_addr, addr->sa_data, MV_MAC_ADDR_SIZE);
+
+	/* add new mac addr to VLAN DB */
+	mv_switch_mac_addr_set(dev->dev_addr, MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id), (1 << dev_priv->cpu_port), 1);
+
+	printk(KERN_ERR "mv_eth_switch: %s change mac address to %02x:%02x:%02x:%02x:%02x:%02x\n",
+		dev->name, *(dev->dev_addr), *(dev->dev_addr+1), *(dev->dev_addr+2),
+		*(dev->dev_addr+3), *(dev->dev_addr+4), *(dev->dev_addr+5));
+
+	return 0;
+}
+
+void    mv_eth_switch_set_multicast_list(struct net_device *dev)
+{
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+
+	if (dev->flags & IFF_PROMISC) {
+		/* promiscuous mode - connect the CPU port to the VLAN (port based + 802.1q) */
+		/* printk(KERN_ERR "mv_eth_switch: setting promiscuous mode\n"); */
+		if (mv_switch_promisc_set(dev_priv->vlan_grp_id, dev_priv->port_map, dev_priv->cpu_port, 1))
+			printk(KERN_ERR "mv_switch_promisc_set to 1 failed\n");
+	} else {
+		/* not in promiscuous mode - disconnect the CPU port to the VLAN (port based + 802.1q) */
+		if (mv_switch_promisc_set(dev_priv->vlan_grp_id, dev_priv->port_map, dev_priv->cpu_port, 0))
+			printk(KERN_ERR "mv_switch_promisc_set to 0 failed\n");
+
+		if (dev->flags & IFF_ALLMULTI) {
+			/* allmulticast - not supported. There is no way to tell the Switch to accept only	*/
+			/* the multicast addresses but not Unicast addresses, so the alternatives are:	*/
+			/* 1) Don't support multicast and do nothing					*/
+			/* 2) Support multicast with same implementation as promiscuous			*/
+			/* 3) Don't rely on Switch for MAC filtering, but use PnC			*/
+			/* Currently option 1 is selected						*/
+			printk(KERN_ERR "mv_eth_switch: setting all-multicast mode is not supported\n");
+		}
+
+		/* Add or delete specific multicast addresses:						*/
+		/* Linux provides a list of the current multicast addresses for the device.		*/
+		/* First, we delete all the multicast addresses in the ATU.				*/
+		/* Then we add the specific multicast addresses Linux provides.				*/
+		if (mv_switch_all_multicasts_del(MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id)))
+			printk(KERN_ERR "mv_eth_switch: mv_switch_all_multicasts_del failed\n");
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 34)
+		if (!netdev_mc_empty(dev)) {
+			struct netdev_hw_addr *ha;
+
+			netdev_for_each_mc_addr(ha, dev) {
+				mv_switch_mac_addr_set(ha->addr,
+					MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id),
+					(dev_priv->port_map | (1 << dev_priv->cpu_port)), 1);
+			}
+		}
+#else
+		{
+			int i;
+			struct dev_mc_list *curr_addr = dev->mc_list;
+
+			/* accept specific multicasts */
+			for (i = 0; i < dev->mc_count; i++, curr_addr = curr_addr->next) {
+				if (!curr_addr)
+					break;
+
+				/*
+				printk(KERN_ERR "Setting MC = %02X:%02X:%02X:%02X:%02X:%02X\n",
+				curr_addr->dmi_addr[0], curr_addr->dmi_addr[1], curr_addr->dmi_addr[2],
+				curr_addr->dmi_addr[3], curr_addr->dmi_addr[4], curr_addr->dmi_addr[5]);
+				*/
+				mv_switch_mac_addr_set(curr_addr->dmi_addr,
+					MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id),
+					(dev_priv->port_map | (1 << dev_priv->cpu_port)), 1);
+			}
+		}
+#endif /* KERNEL_VERSION >= 2.6.34 */
+	}
+}
+
+int     mv_eth_switch_change_mtu(struct net_device *dev, int mtu)
+{
+	int i;
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+
+	/* All gateway interfaces must be down before changing MTU */
+	for (i = mv_eth_switch_netdev_first; i <= mv_eth_switch_netdev_last; i++) {
+		if ((mv_net_devs[i] != NULL) && (netif_running(mv_net_devs[i]))) {
+			printk(KERN_ERR "All gateway interfaces must be down before changing MTU. %s is not down\n", mv_net_devs[i]->name);
+			return -EPERM;
+		}
+	}
+
+	if (dev->mtu != mtu) {
+		int old_mtu = dev->mtu;
+
+		mtu = mv_eth_check_mtu_valid(dev, mtu);
+		if (mtu < 0)
+			return -EPERM;
+
+		if (mv_eth_change_mtu_internals(dev, mtu))
+			return -EPERM;
+
+		printk(KERN_NOTICE "%s: change mtu %d (pkt-size %d) to %d (pkt-size %d)\n",
+			dev->name, old_mtu, RX_PKT_SIZE(old_mtu),
+			dev->mtu, RX_PKT_SIZE(dev->mtu));
+	}
+
+	if (switch_net_config[priv->port].mtu != mtu) {
+		mv_switch_jumbo_mode_set(RX_PKT_SIZE(mtu));
+		switch_net_config[priv->port].mtu = mtu;
+	}
+
+	return 0;
+}
+
+int    mv_eth_switch_start(struct net_device *dev)
+{
+	struct eth_port	*priv = MV_ETH_PRIV(dev);
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+	unsigned char broadcast[MV_MAC_ADDR_SIZE] = {0xff, 0xff, 0xff, 0xff, 0xff, 0xff};
+	int i;
+	int group;
+
+	/* Check that MTU value is identical for all gateway interfaces */
+	for (i = mv_eth_switch_netdev_first; i <= mv_eth_switch_netdev_last; i++) {
+		if ((mv_net_devs[i] != NULL) && (mv_net_devs[i]->mtu != dev->mtu)) {
+			printk(KERN_ERR "All gateway devices must have same MTU\n");
+			return -EPERM;
+		}
+	}
+
+	/* in default link is down */
+	netif_carrier_off(dev);
+
+	/* Stop the TX queue - it will be enabled upon PHY status change after link-up interrupt/timer */
+	netif_tx_stop_all_queues(dev);
+
+	/* start upper layer accordingly with ports_map */
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+	dev_priv->link_map = 0;
+	mv_switch_link_update_event(dev_priv->port_map, 1);
+#else
+	dev_priv->link_map = dev_priv->port_map;
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+
+	if (mv_eth_switch_started == 0)	{
+		/* fill rx buffers, start rx/tx activity, set coalescing */
+		if (mv_eth_start_internals(priv, dev->mtu) != 0) {
+			printk(KERN_ERR "%s: start internals failed\n", dev->name);
+			goto error;
+		}
+
+		/* enable polling on the port, must be used after netif_poll_disable */
+		for (group = 0; group < CONFIG_MV_ETH_NAPI_GROUPS; group++)
+			napi_enable(priv->napiGroup[group]);
+
+		/* connect to port interrupt line */
+		if (request_irq(dev->irq, mv_eth_isr, IRQF_DISABLED|IRQF_SAMPLE_RANDOM, "mv_eth", priv)) {
+			printk(KERN_ERR "cannot request irq %d for %s port %d\n",
+				dev->irq, dev->name, priv->port);
+			for (group = 0; group < CONFIG_MV_ETH_NAPI_GROUPS; group++)
+				napi_disable(priv->napiGroup[group]);
+			goto error;
+		}
+
+		/* unmask interrupts */
+		mv_eth_interrupts_unmask(priv);
+		smp_call_function_many(cpu_online_mask, mv_eth_interrupts_unmask, (void *)priv, 1);
+	}
+
+	mv_eth_switch_started++;
+
+	/* Add our MAC addr to the VLAN DB at switch level to forward packets with this DA   */
+	/* to CPU port by using the tunneling feature. The device is always in promisc mode. */
+	mv_switch_mac_addr_set(dev->dev_addr, MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id), (1 << dev_priv->cpu_port), 1);
+
+	/* We also need to allow L2 broadcasts comming up for this interface */
+	mv_switch_mac_addr_set(broadcast, MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id),
+			(dev_priv->port_map | (1 << dev_priv->cpu_port)), 1);
+
+	printk(KERN_ERR "%s: started (on switch)\n", dev->name);
+	return 0;
+
+error:
+	printk(KERN_ERR "%s: start failed\n", dev->name);
+	return -1;
+}
+
+int     mv_eth_switch_stop(struct net_device *dev)
+{
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+	struct cpu_ctrl	*cpuCtrl;
+	int group, cpu;
+
+	/* stop upper layer */
+	netif_carrier_off(dev);
+	netif_tx_stop_all_queues(dev);
+
+	/* stop switch from forwarding packets from this VLAN toward CPU port */
+	mv_switch_atu_db_flush(MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id));
+
+	/* It is possible that the interface is in promiscuous mode */
+	/* If so, the CPU port is connected with port based VLAN to the other ports, and */
+	/* we must disconnect it now to stop the Switch from forwarding packets to the CPU */
+	/* when the interface is down. */
+	/* mv_eth_switch_set_multicast_list will be called anyway by Linux when we do ifconfig up */
+	/* and will re-set the promiscuous feature if needed */
+	if (dev->flags & IFF_PROMISC) {
+		if (mv_switch_promisc_set(dev_priv->vlan_grp_id, dev_priv->port_map, dev_priv->cpu_port, 0))
+			printk(KERN_ERR "mv_switch_promisc_set to 0 failed\n");
+	}
+	mv_eth_switch_started--;
+	if (mv_eth_switch_started == 0)	{
+		/* first make sure that the port finished its Rx polling - see tg3 */
+		/* otherwise it may cause issue in SMP, one CPU is here and the other is doing the polling */
+		/* and both of it are messing with the descriptors rings!! */
+		for (group = 0; group < CONFIG_MV_ETH_NAPI_GROUPS; group++)
+			napi_disable(priv->napiGroup[group]);
+
+		/* stop tx/rx activity, mask all interrupts, relese skb in rings,*/
+		mv_eth_stop_internals(priv);
+
+		for_each_possible_cpu(cpu) {
+			cpuCtrl = priv->cpu_config[cpu];
+			del_timer(&cpuCtrl->tx_done_timer);
+			clear_bit(MV_ETH_F_TX_DONE_TIMER_BIT, &(priv->flags));
+			del_timer(&cpuCtrl->cleanup_timer);
+			clear_bit(MV_ETH_F_CLEANUP_TIMER_BIT, &(cpuCtrl->flags));
+		}
+
+		if (dev->irq != 0)
+			free_irq(dev->irq, priv);
+	}
+	printk(KERN_NOTICE "%s: stopped\n", dev->name);
+
+	return 0;
+}
+
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+
+void mv_eth_switch_interrupt_unmask(int qsgmii_module, int gephy_on_port)
+{
+#ifdef MV_INCLUDE_ETH_COMPLEX
+	MV_U32 reg;
+
+	reg = MV_REG_READ(MV_ETHCOMP_INT_MAIN_MASK_REG);
+
+	if (qsgmii_module) {
+		reg |= (MV_ETHCOMP_PCS0_LINK_INT_MASK |
+			MV_ETHCOMP_PCS1_LINK_INT_MASK |
+			MV_ETHCOMP_PCS2_LINK_INT_MASK |
+			MV_ETHCOMP_PCS3_LINK_INT_MASK);
+	}
+
+	if (gephy_on_port >= 0)
+		reg |= MV_ETHCOMP_GEPHY_INT_MASK;
+
+	reg |= MV_ETHCOMP_SWITCH_INT_MASK;
+
+	MV_REG_WRITE(MV_ETHCOMP_INT_MAIN_MASK_REG, reg);
+#endif /* MV_INCLUDE_ETH_COMPLEX */
+}
+
+void mv_eth_switch_interrupt_clear(int qsgmii_module, int gephy_on_port)
+{
+#ifdef MV_INCLUDE_ETH_COMPLEX
+	MV_U32 reg;
+
+	reg = MV_REG_READ(MV_ETHCOMP_INT_MAIN_CAUSE_REG);
+
+	if (qsgmii_module) {
+		reg &= ~(MV_ETHCOMP_PCS0_LINK_INT_MASK |
+			 MV_ETHCOMP_PCS1_LINK_INT_MASK |
+			 MV_ETHCOMP_PCS2_LINK_INT_MASK |
+			 MV_ETHCOMP_PCS3_LINK_INT_MASK);
+	}
+
+	if (gephy_on_port >= 0)
+		reg &= ~MV_ETHCOMP_GEPHY_INT_MASK;
+
+	reg &= ~MV_ETHCOMP_SWITCH_INT_MASK;
+
+	MV_REG_WRITE(MV_ETHCOMP_INT_MAIN_CAUSE_REG, reg);
+#endif /* MV_INCLUDE_ETH_COMPLEX */
+}
+
+void mv_eth_switch_update_link(unsigned int p, unsigned int link_up)
+{
+	struct eth_netdev *dev_priv = NULL;
+	struct eth_port *priv = NULL;
+	int i = 0;
+	unsigned int prev_ports_link = 0;
+
+	for (i = 0; i < mv_net_devs_num; i++) {
+
+		if (mv_net_devs[i] == NULL)
+			break;
+
+		priv = MV_ETH_PRIV(mv_net_devs[i]);
+		if (priv == NULL)
+			break;
+
+		if (!(priv->flags & (MV_ETH_F_SWITCH | MV_ETH_F_EXT_SWITCH)))
+			continue;
+
+		dev_priv = MV_DEV_PRIV(mv_net_devs[i]);
+		if (dev_priv == NULL)
+			break;
+
+		if ((dev_priv->port_map & (1 << p)) == 0)
+			continue;
+
+		prev_ports_link = dev_priv->link_map;
+
+		if (link_up)
+			dev_priv->link_map |= (1 << p);
+		else
+			dev_priv->link_map &= ~(1 << p);
+
+		if ((prev_ports_link != 0) && (dev_priv->link_map == 0) && netif_running(mv_net_devs[i])) {
+			/* link down */
+			netif_carrier_off(mv_net_devs[i]);
+			netif_tx_stop_all_queues(mv_net_devs[i]);
+			printk(KERN_ERR "%s: link down\n", mv_net_devs[i]->name);
+		} else if ((prev_ports_link == 0) && (dev_priv->link_map != 0) && netif_running(mv_net_devs[i])) {
+			/* link up */
+			if (mv_eth_ctrl_is_tx_enabled(priv) == 1) {
+				netif_carrier_on(mv_net_devs[i]);
+				netif_tx_wake_all_queues(mv_net_devs[i]);
+				printk(KERN_ERR "%s: link up\n", mv_net_devs[i]->name);
+			}
+		}
+	}
+}
+
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+
+int     mv_eth_switch_port_add(struct net_device *dev, int port)
+{
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+	struct eth_port	*priv = MV_ETH_PRIV(dev);
+	int i, switch_port, err = 0;
+
+	if (dev_priv == NULL) {
+		printk(KERN_ERR "%s is not connected to the switch\n", dev->name);
+		return 1;
+	}
+
+	if (netif_running(dev)) {
+		printk(KERN_ERR "%s must be down to change switch ports map\n", dev->name);
+		return 1;
+	}
+
+	switch_port = mvBoardSwitchPortGet(0, port);
+
+	if (switch_port < 0) {
+		printk(KERN_ERR "Switch port %d can't be added\n", port);
+		return 1;
+	}
+
+	if (MV_BIT_CHECK(switch_enabled_ports, switch_port)) {
+		printk(KERN_ERR "Switch port %d is already enabled\n", port);
+		return 0;
+	}
+
+	/* Update data base */
+	dev_priv->port_map |= (1 << switch_port);
+	for (i = mv_eth_switch_netdev_first; i <= mv_eth_switch_netdev_last; i++) {
+		if ((mv_net_devs[i] != NULL) && (mv_net_devs[i] == dev))
+			switch_net_config[priv->port].board_port_map[i - mv_eth_switch_netdev_first] |= (1 << switch_port);
+	}
+	switch_enabled_ports |= (1 << switch_port);
+	dev_priv->tx_vlan_mh = cpu_to_be16((MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id) << 12) | dev_priv->port_map);
+
+	err = mv_switch_port_add(switch_port, dev_priv->vlan_grp_id, dev_priv->port_map);
+	if (!err)
+		printk(KERN_ERR "%s: Switch port #%d mapped\n", dev->name, port);
+
+	return err;
+}
+
+int     mv_eth_switch_port_del(struct net_device *dev, int port)
+{
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+	struct eth_port	*priv = MV_ETH_PRIV(dev);
+	int i, switch_port, err = 0;
+
+	if (dev_priv == NULL) {
+		printk(KERN_ERR "%s is not connected to the switch\n", dev->name);
+		return 1;
+	}
+
+	if (netif_running(dev)) {
+		printk(KERN_ERR "%s must be down to change switch ports map\n", dev->name);
+		return 1;
+	}
+
+	switch_port = mvBoardSwitchPortGet(0, port);
+
+	if (switch_port < 0) {
+		printk(KERN_ERR "Switch port %d can't be added\n", port);
+		return 1;
+	}
+
+	if (!MV_BIT_CHECK(switch_enabled_ports, switch_port)) {
+		printk(KERN_ERR "Switch port %d is already disabled\n", port);
+		return 0;
+	}
+
+	if (!MV_BIT_CHECK(dev_priv->port_map, switch_port)) {
+		printk(KERN_ERR "Switch port %d is not mapped on %s\n", port, dev->name);
+		return 0;
+	}
+
+	/* Update data base */
+	dev_priv->port_map &= ~(1 << switch_port);
+	for (i = mv_eth_switch_netdev_first; i <= mv_eth_switch_netdev_last; i++) {
+		if ((mv_net_devs[i] != NULL) && (mv_net_devs[i] == dev))
+			switch_net_config[priv->port].board_port_map[i - mv_eth_switch_netdev_first] &= ~(1 << switch_port);
+	}
+	dev_priv->link_map &= ~(1 << switch_port);
+	switch_enabled_ports &= ~(1 << switch_port);
+	dev_priv->tx_vlan_mh = cpu_to_be16((MV_SWITCH_VLAN_TO_GROUP(dev_priv->vlan_grp_id) << 12) | dev_priv->port_map);
+
+	err = mv_switch_port_del(switch_port, dev_priv->vlan_grp_id, dev_priv->port_map);
+	if (!err)
+		printk(KERN_ERR "%s: Switch port #%d unmapped\n", dev->name, port);
+
+	return err;
+}
+
+void    mv_eth_switch_status_print(int port)
+{
+	int i;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct net_device *dev;
+
+	if (pp->flags & MV_ETH_F_SWITCH) {
+		printk(KERN_ERR "ethPort=%d: mv_eth_switch status - pp=%p, flags=0x%lx\n", port, pp, pp->flags);
+
+		printk(KERN_ERR "mtu=%d, netdev_max=%d, netdev_cfg=%d, first=%d, last=%d\n",
+			switch_net_config[port].mtu, switch_net_config[port].netdev_max, switch_net_config[port].netdev_cfg,
+			mv_eth_switch_netdev_first, mv_eth_switch_netdev_last);
+
+		for (i = 0; i < switch_net_config[port].netdev_cfg; i++) {
+			printk(KERN_ERR "MAC="MV_MACQUAD_FMT", board_port_map=0x%x\n",
+				MV_MACQUAD(switch_net_config[port].mac_addr[i]), switch_net_config[port].board_port_map[i]);
+		}
+		for (i = mv_eth_switch_netdev_first; i <= mv_eth_switch_netdev_last; i++) {
+			dev = mv_eth_netdev_by_id(i);
+			if (dev)
+				mv_eth_netdev_print(dev);
+		}
+	} else
+		printk(KERN_ERR "ethPort=%d: switch is not connected - pp=%p, flags=0x%lx\n", port, pp, pp->flags);
+}
+
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.c
new file mode 100644
index 0000000..44e50fb
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.c
@@ -0,0 +1,284 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "gbe/mvPp2Gbe.h"
+#include "prs/mvPp2Prs.h"
+#include "mv_netdev.h"
+#include "mv_eth_sysfs.h"
+
+static struct kobject *pp2_kobj;
+
+
+static ssize_t mv_eth_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "cd                             bm            - move to BM sysfs directory\n");
+	off += sprintf(buf+off, "cd                             napi          - move to NAPI groups API sysfs directory\n");
+	off += sprintf(buf+off, "cd                             rx            - move to RX sysfs directory\n");
+	off += sprintf(buf+off, "cd                             tx            - move to TX sysfs directory\n");
+	off += sprintf(buf+off, "cd                             tx_sched      - move to TX Scheduler sysfs directory\n");
+	off += sprintf(buf+off, "cd                             pon           - move to PON sysfs directory\n");
+	off += sprintf(buf+off, "cd                             pme           - move to PME sysfs directory\n");
+	off += sprintf(buf+off, "cd                             qos           - move to QoS sysfs directory\n\n");
+
+	off += sprintf(buf+off, "cat                            addrDec       - print address decode registers\n");
+	off += sprintf(buf+off, "echo p {0|1|2|3}             > tag           - None[3], Use Marvell Header[1], use DSA tag[2], Use EDSA tag[3]\n");
+	off += sprintf(buf+off, "echo {0|1}                   > pnc           - enable / disable Parser and Classifier access\n");
+	off += sprintf(buf+off, "echo [p]                     > port          - show a port info\n");
+	off += sprintf(buf+off, "echo [p]                     > cntrs         - show a port MIB counters\n");
+	off += sprintf(buf+off, "echo [p] [hex]               > debug         - bit0:rx, bit1:tx, bit2:isr, bit3:poll, bit4:dump\n");
+	off += sprintf(buf+off, "echo [p]                     > stats         - show port [p] statistics\n");
+	off += sprintf(buf+off, "echo [p]                     > isrRegs       - show ISR registers for port <p> range [0..max]\n");
+	off += sprintf(buf+off, "echo [p]                     > dropCntrs     - show drop counters for port <p> range [0..max]\n");
+
+	return off;
+}
+
+static ssize_t mv_eth_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "addrDec")) {
+		/*mvPp2AddressDecodeRegsPrint();*/
+		mvPp2AddrDecodeRegs();
+	} else {
+		off = mv_eth_help(buf);
+	}
+
+	return off;
+}
+
+static ssize_t mv_eth_port_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = p = v = 0;
+	sscanf(buf, "%d %d", &p, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "port")) {
+		mv_eth_status_print();
+		mv_eth_port_status_print(p);
+		mvPp2PortStatus(p);
+	} else if (!strcmp(name, "cntrs")) {
+		mvEthMibCountersShow(p);
+	} else if (!strcmp(name, "isrRegs")) {
+		mvPp2IsrRegs(p);
+	} else if (!strcmp(name, "dropCntrs")) {
+		mvPp2DropCntrs(p);
+	} else if (!strcmp(name, "stats")) {
+		mv_eth_port_stats_print(p);
+	} else if (!strcmp(name, "pnc")) {
+		mv_eth_ctrl_pnc(p);
+	} else if (!strcmp(name, "tag")) {
+		mvPp2PrsTagModeSet(p, v);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t mv_eth_2_hex_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = p = v = 0;
+	sscanf(buf, "%d %x", &p, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "debug")) {
+		err = mv_eth_ctrl_dbg_flag(p, MV_ETH_F_DBG_RX,   v & 0x1);
+		err = mv_eth_ctrl_dbg_flag(p, MV_ETH_F_DBG_TX,   v & 0x2);
+		err = mv_eth_ctrl_dbg_flag(p, MV_ETH_F_DBG_ISR,  v & 0x4);
+		err = mv_eth_ctrl_dbg_flag(p, MV_ETH_F_DBG_POLL, v & 0x8);
+		err = mv_eth_ctrl_dbg_flag(p, MV_ETH_F_DBG_DUMP, v & 0x10);
+	}
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t mv_eth_reg_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    r, v;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = r = v = 0;
+	sscanf(buf, "%x %x", &r, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "regRead")) {
+		v = mvPp2RdReg(r);
+		printk("regRead val: 0x%08x\n", v);
+	}  else if (!strcmp(name, "regWrite")) {
+		mvPp2WrReg(r, v);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(addrDec,      S_IRUSR, mv_eth_show, NULL);
+static DEVICE_ATTR(help,         S_IRUSR, mv_eth_show, NULL);
+static DEVICE_ATTR(debug,        S_IWUSR, NULL, mv_eth_2_hex_store);
+static DEVICE_ATTR(isrRegs,      S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(dropCntrs,    S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(stats,        S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(pnc,        S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(tag,        S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(port,         S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(cntrs,        S_IWUSR, NULL, mv_eth_port_store);
+
+static DEVICE_ATTR(regRead,       S_IWUSR, NULL, mv_eth_reg_store);
+static DEVICE_ATTR(regWrite,      S_IWUSR, NULL, mv_eth_reg_store);
+
+static struct attribute *mv_eth_attrs[] = {
+	&dev_attr_addrDec.attr,
+	&dev_attr_help.attr,
+	&dev_attr_debug.attr,
+	&dev_attr_port.attr,
+	&dev_attr_cntrs.attr,
+	&dev_attr_isrRegs.attr,
+	&dev_attr_dropCntrs.attr,
+	&dev_attr_stats.attr,
+	&dev_attr_pnc.attr,
+	&dev_attr_tag.attr,
+	&dev_attr_regRead.attr,
+	&dev_attr_regWrite.attr,
+	NULL
+};
+
+static struct attribute_group mv_eth_group = {
+	.attrs = mv_eth_attrs,
+};
+
+int __devinit mv_eth_sysfs_init(void)
+{
+	int err;
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	if (!pd) {
+		platform_device_register_simple("pp2", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	}
+
+	if (!pd) {
+		printk(KERN_ERR"%s: cannot find pp2 device\n", __func__);
+		pd = &platform_bus;
+	}
+
+	pp2_kobj = kobject_create_and_add("gbe", &pd->kobj);
+	if (!pp2_kobj) {
+		printk(KERN_ERR"%s: cannot create gbe kobject\n", __func__);
+		return -ENOMEM;
+	}
+
+	err = sysfs_create_group(pp2_kobj, &mv_eth_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+
+	mv_eth_bm_sysfs_init(pp2_kobj);
+
+	mv_eth_napi_sysfs_init(pp2_kobj);
+
+	mv_eth_rx_sysfs_init(pp2_kobj);
+
+	mv_eth_tx_sysfs_init(pp2_kobj);
+
+	mv_eth_tx_sched_sysfs_init(pp2_kobj);
+
+	mv_eth_qos_sysfs_init(pp2_kobj);
+
+	mv_eth_pon_sysfs_init(pp2_kobj);
+
+	mv_eth_pme_sysfs_init(pp2_kobj);
+
+out:
+	return err;
+}
+
+module_init(mv_eth_sysfs_init);
+
+MODULE_AUTHOR("Kostya Belezko");
+MODULE_DESCRIPTION("sysfs for marvell GbE");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h
new file mode 100644
index 0000000..e6b6196
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h
@@ -0,0 +1,47 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_eth_sysfs_h__
+#define __mv_eth_sysfs_h__
+
+int mv_eth_bm_sysfs_init(struct kobject *pp2_kobj);
+
+int mv_eth_napi_sysfs_init(struct kobject *pp2_kobj);
+
+int mv_eth_rx_sysfs_init(struct kobject *pp2_kobj);
+
+int mv_eth_tx_sysfs_init(struct kobject *pp2_kobj);
+
+int mv_eth_tx_sched_sysfs_init(struct kobject *pp2_kobj);
+
+int mv_eth_qos_sysfs_init(struct kobject *pp2_kobj);
+
+int mv_eth_pon_sysfs_init(struct kobject *pp2_kobj);
+
+int mv_eth_pme_sysfs_init(struct kobject *pp2_kobj);
+
+#endif /* __mv_eth_sysfs_h__ */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.c
new file mode 100644
index 0000000..0a0cac6
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.c
@@ -0,0 +1,948 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <net/ip.h>
+#include <net/ipv6.h>
+#include <linux/mii.h>
+
+#include "mvOs.h"
+#include "mvDebug.h"
+#include "dbg-trace.h"
+#include "mvSysHwConfig.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "eth-phy/mvEthPhy.h"
+#include "mvSysEthPhyApi.h"
+#include "gmac/mvEthGmacApi.h"
+
+#include "gbe/mvPp2Gbe.h"
+#include "bm/mvBm.h"
+
+#include "mv_switch.h"
+#include "mv_netdev.h"
+
+#include "mvOs.h"
+#include "mvSysHwConfig.h"
+#include "prs/mvPp2Prs.h"
+
+#define MV_ETH_TOOL_AN_TIMEOUT	5000
+
+
+static int isSwitch(struct eth_port *priv)
+{
+	return (priv->flags & (MV_ETH_F_SWITCH | MV_ETH_F_EXT_SWITCH));
+}
+
+
+/******************************************************************************
+* mv_eth_tool_get_settings
+* Description:
+*	ethtool get standard port settings
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	cmd		command (settings)
+* RETURN:
+*	0 for success
+*
+*******************************************************************************/
+int mv_eth_tool_get_settings(struct net_device *netdev, struct ethtool_cmd *cmd)
+{
+	struct eth_port 	*priv = MV_ETH_PRIV(netdev);
+	u16			lp_ad, stat1000;
+	MV_U32			mv_phy_addr;
+	MV_ETH_PORT_SPEED 	speed;
+	MV_ETH_PORT_DUPLEX 	duplex;
+	MV_ETH_PORT_STATUS      status;
+
+	if ((priv == NULL) || (isSwitch(priv)) || (MV_PON_PORT(priv->port))) {
+		printk(KERN_ERR "%s is not supported on %s\n", __func__, netdev->name);
+		return -EOPNOTSUPP;
+	}
+
+	cmd->supported = (SUPPORTED_10baseT_Half | SUPPORTED_10baseT_Full | SUPPORTED_100baseT_Half
+			| SUPPORTED_100baseT_Full | SUPPORTED_Autoneg | SUPPORTED_TP | SUPPORTED_MII
+			| SUPPORTED_1000baseT_Full);
+
+	mv_phy_addr = mvBoardPhyAddrGet(priv->port);
+
+	mvEthLinkStatus(priv->port, &status);
+
+	if (status.linkup != MV_TRUE) {
+		/* set to Unknown */
+		cmd->speed  = -1;
+		cmd->duplex = -1;
+	} else {
+		switch (status.speed) {
+		case MV_ETH_SPEED_1000:
+			cmd->speed = SPEED_1000;
+			break;
+		case MV_ETH_SPEED_100:
+			cmd->speed = SPEED_100;
+			break;
+		case MV_ETH_SPEED_10:
+			cmd->speed = SPEED_10;
+			break;
+		default:
+			return -EINVAL;
+		}
+		if (status.duplex == MV_ETH_DUPLEX_FULL)
+			cmd->duplex = 1;
+		else
+			cmd->duplex = 0;
+	}
+
+	cmd->port = PORT_MII;
+	cmd->phy_address = mv_phy_addr;
+	cmd->transceiver = XCVR_INTERNAL;
+	/* check if speed and duplex are AN */
+	mvEthSpeedDuplexGet(priv->port, &speed, &duplex);
+	if (speed == MV_ETH_SPEED_AN && duplex == MV_ETH_DUPLEX_AN) {
+		cmd->lp_advertising = cmd->advertising = 0;
+		cmd->autoneg = AUTONEG_ENABLE;
+		mvEthPhyAdvertiseGet(mv_phy_addr, (MV_U16 *)&(cmd->advertising));
+
+		mvEthPhyRegRead(mv_phy_addr, MII_LPA, &lp_ad);
+		if (lp_ad & LPA_LPACK)
+			cmd->lp_advertising |= ADVERTISED_Autoneg;
+		if (lp_ad & ADVERTISE_10HALF)
+			cmd->lp_advertising |= ADVERTISED_10baseT_Half;
+		if (lp_ad & ADVERTISE_10FULL)
+			cmd->lp_advertising |= ADVERTISED_10baseT_Full;
+		if (lp_ad & ADVERTISE_100HALF)
+			cmd->lp_advertising |= ADVERTISED_100baseT_Half;
+		if (lp_ad & ADVERTISE_100FULL)
+			cmd->lp_advertising |= ADVERTISED_100baseT_Full;
+
+		mvEthPhyRegRead(mv_phy_addr, MII_STAT1000, &stat1000);
+		if (stat1000 & LPA_1000HALF)
+			cmd->lp_advertising |= ADVERTISED_1000baseT_Half;
+		if (stat1000 & LPA_1000FULL)
+			cmd->lp_advertising |= ADVERTISED_1000baseT_Full;
+	} else
+		cmd->autoneg = AUTONEG_DISABLE;
+
+	return 0;
+}
+
+
+/******************************************************************************
+* mv_eth_tool_restore_settings
+* Description:
+*	restore saved speed/dublex/an settings
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	0 for success
+*
+*******************************************************************************/
+int mv_eth_tool_restore_settings(struct net_device *netdev)
+{
+	struct eth_port 	*priv = MV_ETH_PRIV(netdev);
+	int 				mv_phy_speed, mv_phy_duplex;
+	MV_U32			    mv_phy_addr = mvBoardPhyAddrGet(priv->port);
+	MV_ETH_PORT_SPEED	mv_mac_speed;
+	MV_ETH_PORT_DUPLEX	mv_mac_duplex;
+	int			err = -EINVAL;
+
+	 if ((priv == NULL) || (isSwitch(priv)))
+		 return -EOPNOTSUPP;
+
+	switch (priv->speed_cfg) {
+	case SPEED_10:
+		mv_phy_speed  = 0;
+		mv_mac_speed = MV_ETH_SPEED_10;
+		break;
+	case SPEED_100:
+		mv_phy_speed  = 1;
+		mv_mac_speed = MV_ETH_SPEED_100;
+		break;
+	case SPEED_1000:
+		mv_phy_speed  = 2;
+		mv_mac_speed = MV_ETH_SPEED_1000;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	switch (priv->duplex_cfg) {
+	case DUPLEX_HALF:
+		mv_phy_duplex = 0;
+		mv_mac_duplex = MV_ETH_DUPLEX_HALF;
+		break;
+	case DUPLEX_FULL:
+		mv_phy_duplex = 1;
+		mv_mac_duplex = MV_ETH_DUPLEX_FULL;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	if (priv->autoneg_cfg == AUTONEG_ENABLE) {
+		err = mvEthSpeedDuplexSet(priv->port, MV_ETH_SPEED_AN, MV_ETH_DUPLEX_AN);
+		if (!err)
+			err = mvEthPhyAdvertiseSet(mv_phy_addr, priv->advertise_cfg);
+		/* Restart AN on PHY enables it */
+		if (!err) {
+
+			err = mvEthPhyRestartAN(mv_phy_addr, MV_ETH_TOOL_AN_TIMEOUT);
+			if (err == MV_TIMEOUT) {
+				MV_ETH_PORT_STATUS ps;
+
+				mvEthLinkStatus(priv->port, &ps);
+
+				if (!ps.linkup)
+					err = 0;
+			}
+		}
+	} else if (priv->autoneg_cfg == AUTONEG_DISABLE) {
+		err = mvEthPhyDisableAN(mv_phy_addr, mv_phy_speed, mv_phy_duplex);
+		if (!err)
+			err = mvEthSpeedDuplexSet(priv->port, mv_mac_speed, mv_mac_duplex);
+	} else {
+		err = -EINVAL;
+	}
+	return err;
+}
+
+
+
+/******************************************************************************
+* mv_eth_tool_set_settings
+* Description:
+*	ethtool set standard port settings
+* INPUT:
+*	netdev		Network device structure pointer
+*	cmd		command (settings)
+* OUTPUT
+*	None
+* RETURN:
+*	0 for success
+*
+*******************************************************************************/
+int mv_eth_tool_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+	int _speed, _duplex, _autoneg, _advertise, err;
+
+	if ((priv == NULL) || (isSwitch(priv)) || (MV_PON_PORT(priv->port))) {
+		printk(KERN_ERR "%s is not supported on %s\n", __func__, dev->name);
+		return -EOPNOTSUPP;
+	}
+
+	_duplex  = priv->duplex_cfg;
+	_speed   = priv->speed_cfg;
+	_autoneg = priv->autoneg_cfg;
+	_advertise = priv->advertise_cfg;
+
+	priv->duplex_cfg = cmd->duplex;
+	priv->speed_cfg = cmd->speed;
+	priv->autoneg_cfg = cmd->autoneg;
+	priv->advertise_cfg = cmd->advertising;
+	err = mv_eth_tool_restore_settings(dev);
+
+	if (err) {
+		priv->duplex_cfg = _duplex;
+		priv->speed_cfg = _speed;
+		priv->autoneg_cfg = _autoneg;
+		priv->advertise_cfg = _advertise;
+	}
+	return err;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_regs_len
+* Description:
+*	ethtool get registers array length
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	registers array length
+*
+*******************************************************************************/
+int mv_eth_tool_get_regs_len(struct net_device *netdev)
+{
+#define MV_ETH_TOOL_REGS_LEN 32
+
+	return (MV_ETH_TOOL_REGS_LEN * sizeof(uint32_t));
+}
+
+
+/******************************************************************************
+* mv_eth_tool_get_drvinfo
+* Description:
+*	ethtool get driver information
+* INPUT:
+*	netdev		Network device structure pointer
+*	info		driver information
+* OUTPUT
+*	info		driver information
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_drvinfo(struct net_device *netdev,
+			     struct ethtool_drvinfo *info)
+{
+	strcpy(info->driver, "mv_eth");
+	/*strcpy(info->version, LSP_VERSION);*/
+	strcpy(info->fw_version, "N/A");
+	strcpy(info->bus_info, "Mbus");
+/*   TBD
+	info->n_stats = MV_ETH_TOOL_STATS_LEN;
+*/
+	info->testinfo_len = 0;
+	info->regdump_len = mv_eth_tool_get_regs_len(netdev);
+	info->eedump_len = 0;
+}
+
+
+/******************************************************************************
+* mv_eth_tool_get_regs
+* Description:
+*	ethtool get registers array
+* INPUT:
+*	netdev		Network device structure pointer
+*	regs		registers information
+* OUTPUT
+*	p		registers array
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_regs(struct net_device *netdev,
+			  struct ethtool_regs *regs, void *p)
+{
+	struct eth_port	*priv = MV_ETH_PRIV(netdev);
+/*
+	uint32_t 	*regs_buff = p;
+*/
+
+	if ((priv == NULL) || MV_PON_PORT(priv->port)) {
+		printk(KERN_ERR "%s is not supported on %s\n", __func__, netdev->name);
+		return;
+	}
+
+	memset(p, 0, MV_ETH_TOOL_REGS_LEN * sizeof(uint32_t));
+
+	regs->version = mvCtrlModelRevGet();
+
+	/* ETH port registers */
+	/* TODO read ETH registers into p - reference at NETA */
+
+}
+
+
+/******************************************************************************
+* mv_eth_tool_nway_reset
+* Description:
+*	ethtool restart auto negotiation
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_nway_reset(struct net_device *netdev)
+{
+	struct eth_port *priv = MV_ETH_PRIV(netdev);
+	MV_U32	        phy_addr;
+
+	if ((priv == NULL) || (isSwitch(priv)) || (MV_PON_PORT(priv->port))) {
+		printk(KERN_ERR "interface %s is not supported\n", netdev->name);
+		return -EOPNOTSUPP;
+	}
+
+	phy_addr = mvBoardPhyAddrGet(priv->port);
+	if (mvEthPhyRestartAN(phy_addr, MV_ETH_TOOL_AN_TIMEOUT) != MV_OK)
+		return -EINVAL;
+
+	return 0;
+}
+
+
+/******************************************************************************
+* mv_eth_tool_get_link
+* Description:
+*	ethtool get link status
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	0 if link is down, 1 if link is up
+*
+*******************************************************************************/
+u32 mv_eth_tool_get_link(struct net_device *netdev)
+{
+	struct eth_port     *pp = MV_ETH_PRIV(netdev);
+	struct eth_netdev   *dev_priv = MV_DEV_PRIV(netdev);
+
+	if (pp == NULL) {
+		printk(KERN_ERR "interface %s is not supported\n", netdev->name);
+		return -EOPNOTSUPP;
+	}
+
+	if (isSwitch(pp)) {
+		if (dev_priv == NULL)
+			return -EOPNOTSUPP;
+		return (dev_priv->link_map != 0);
+	}
+#ifdef CONFIG_MV_PON
+	if (MV_PON_PORT(pp->port))
+		return mv_pon_link_status();
+#endif /* CONFIG_MV_PON */
+	return mvEthPortIsLinkUp(pp->port);
+}
+
+
+/******************************************************************************
+* mv_eth_tool_get_coalesce
+* Description:
+*	ethtool get RX/TX coalesce parameters
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	cmd		Coalesce parameters
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_get_coalesce(struct net_device *netdev,
+			     struct ethtool_coalesce *cmd)
+{
+	struct eth_port *pp = MV_ETH_PRIV(netdev);
+	/* get coal parameters only for rxq=0, txp=txq=0 !!!
+	   notice that if you use ethtool to set coal, then all queues have the same value */
+	cmd->rx_coalesce_usecs = mvPp2RxqTimeCoalGet(pp->port, 0);
+	cmd->rx_max_coalesced_frames = mvPp2RxqPktsCoalGet(pp->port, 0);
+	cmd->tx_max_coalesced_frames = mvPp2TxDonePktsCoalGet(pp->port, 0, 0);
+	return 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_set_coalesce
+* Description:
+*	ethtool set RX/TX coalesce parameters
+* INPUT:
+*	netdev		Network device structure pointer
+*	cmd		Coalesce parameters
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_coalesce(struct net_device *netdev,
+			     struct ethtool_coalesce *cmd)
+{
+	struct eth_port *pp = MV_ETH_PRIV(netdev);
+	int rxq, txp, txq;
+
+	/* can't set rx coalesce with both 0 pkts and 0 usecs,  tx coalesce supports only pkts */
+	if ((!cmd->rx_coalesce_usecs && !cmd->rx_max_coalesced_frames) || (!cmd->tx_max_coalesced_frames))
+		return -EPERM;
+
+	for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++) {
+		mvPp2RxqPktsCoalSet(pp->port, rxq, cmd->rx_max_coalesced_frames);
+		mvPp2RxqTimeCoalSet(pp->port, rxq, cmd->rx_coalesce_usecs);
+	}
+	for (txp = 0; txp < pp->txp_num; txp++)
+		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++)
+			mvPp2TxDonePktsCoalSet(pp->port, txp, txq, cmd->tx_max_coalesced_frames);
+
+	return 0;
+}
+
+
+/******************************************************************************
+* mv_eth_tool_get_ringparam
+* Description:
+*	ethtool get ring parameters
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	ring		Ring paranmeters
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_ringparam(struct net_device *netdev,
+				struct ethtool_ringparam *ring)
+{
+	struct eth_port *priv = MV_ETH_PRIV(netdev);
+
+	memset(ring, 0, sizeof(struct ethtool_ringparam));
+	ring->rx_pending = priv->rxq_ctrl[0].rxq_size;
+	//TODO: ring->tx_pending = ? aggr? txq? per cpu? what about hwf?
+}
+
+/******************************************************************************
+* mv_eth_tool_set_ringparam
+* Description:
+*	ethtool set ring parameters
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	ring		Ring paranmeters
+* RETURN:
+*	None
+*
+*******************************************************************************/
+int mv_eth_tool_set_ringparam(struct net_device *netdev,
+				 struct ethtool_ringparam *ring)
+{
+	struct eth_port *priv = MV_ETH_PRIV(netdev);
+	int i, rxq_size, netdev_running = 0;
+
+	if (ring->rx_jumbo_pending || ring->rx_mini_pending)
+		return -EINVAL;
+
+	rxq_size = MV_ALIGN_UP(ring->rx_pending, 16);
+
+	if (netif_running(netdev))
+		netdev_running = 1;
+
+	if (netdev_running)
+		mv_eth_stop(netdev);
+
+	if (rxq_size != priv->rxq_ctrl[0].rxq_size)
+		for (i = 0; i < priv->rxq_num; i++)
+			mv_eth_ctrl_rxq_size_set(priv->port, i, rxq_size);
+
+	if (netdev_running)
+		mv_eth_open(netdev);
+
+	return 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_pauseparam
+* Description:
+*	ethtool get pause parameters
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	pause		Pause paranmeters
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_pauseparam(struct net_device *netdev,
+				struct ethtool_pauseparam *pause)
+{
+	struct eth_port      *priv = MV_ETH_PRIV(netdev);
+	int                  port = priv->port;
+	MV_ETH_PORT_STATUS   portStatus;
+	MV_ETH_PORT_FC       flowCtrl;
+
+	if ((priv == NULL) || (isSwitch(priv)) || (MV_PON_PORT(priv->port))) {
+		printk(KERN_ERR "%s is not supported on %s\n", __func__, netdev->name);
+		return;
+	}
+
+	mvEthFlowCtrlGet(port, &flowCtrl);
+	if ((flowCtrl == MV_ETH_FC_AN_NO) || (flowCtrl == MV_ETH_FC_AN_SYM) || (flowCtrl == MV_ETH_FC_AN_ASYM))
+		pause->autoneg = AUTONEG_ENABLE;
+	else
+		pause->autoneg = AUTONEG_DISABLE;
+
+	mvEthLinkStatus(port, &portStatus);
+	if (portStatus.rxFc == MV_ETH_FC_DISABLE)
+		pause->rx_pause = 0;
+	else
+		pause->rx_pause = 1;
+
+	if (portStatus.txFc == MV_ETH_FC_DISABLE)
+		pause->tx_pause = 0;
+	else
+		pause->tx_pause = 1;
+}
+
+
+
+
+/******************************************************************************
+* mv_eth_tool_set_pauseparam
+* Description:
+*	ethtool configure pause parameters
+* INPUT:
+*	netdev		Network device structure pointer
+*	pause		Pause paranmeters
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_pauseparam(struct net_device *netdev,
+				struct ethtool_pauseparam *pause)
+{
+	struct eth_port *priv = MV_ETH_PRIV(netdev);
+	int				port = priv->port;
+	MV_U32			phy_addr;
+	MV_STATUS		status = MV_FAIL;
+
+	if ((priv == NULL) || (isSwitch(priv)) || (MV_PON_PORT(priv->port))) {
+		printk(KERN_ERR "%s is not supported on %s\n", __func__, netdev->name);
+		return -EOPNOTSUPP;
+	}
+
+	if (pause->rx_pause && pause->tx_pause) { /* Enable FC */
+		if (pause->autoneg) { /* autoneg enable */
+			status = mvEthFlowCtrlSet(port, MV_ETH_FC_AN_SYM);
+		} else { /* autoneg disable */
+			status = mvEthFlowCtrlSet(port, MV_ETH_FC_ENABLE);
+		}
+	} else if (!pause->rx_pause && !pause->tx_pause) { /* Disable FC */
+		if (pause->autoneg) { /* autoneg enable */
+			status = mvEthFlowCtrlSet(port, MV_ETH_FC_AN_NO);
+		} else { /* autoneg disable */
+			status = mvEthFlowCtrlSet(port, MV_ETH_FC_DISABLE);
+		}
+	}
+	/* Only symmetric change for RX and TX flow control is allowed */
+	if (status == MV_OK) {
+		phy_addr = mvBoardPhyAddrGet(priv->port);
+		status = mvEthPhyRestartAN(phy_addr, MV_ETH_TOOL_AN_TIMEOUT);
+	}
+	if (status != MV_OK)
+		return -EINVAL;
+
+	return 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_rx_csum
+* Description:
+*	ethtool get RX checksum offloading status
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	RX checksum
+*
+*******************************************************************************/
+u32 mv_eth_tool_get_rx_csum(struct net_device *netdev)
+{
+#ifdef CONFIG_MV_ETH_RX_CSUM_OFFLOAD
+	struct eth_port *priv = MV_ETH_PRIV(netdev);
+
+	return (priv->rx_csum_offload != 0);
+#else
+	return 0;
+#endif
+}
+
+/******************************************************************************
+* mv_eth_tool_set_rx_csum
+* Description:
+*	ethtool enable/disable RX checksum offloading
+* INPUT:
+*	netdev		Network device structure pointer
+*	data		Command data
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_rx_csum(struct net_device *netdev, uint32_t data)
+{
+#ifdef CONFIG_MV_ETH_RX_CSUM_OFFLOAD
+	struct eth_port *priv = MV_ETH_PRIV(netdev);
+
+	priv->rx_csum_offload = data;
+	return 0;
+#else
+	return -EOPNOTSUPP;
+#endif
+}
+
+/******************************************************************************
+* mv_eth_tool_set_tx_csum
+* Description:
+*	ethtool enable/disable TX checksum offloading
+* INPUT:
+*	netdev		Network device structure pointer
+*	data		Command data
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_tx_csum(struct net_device *netdev, uint32_t data)
+{
+#ifdef CONFIG_MV_ETH_TX_CSUM_OFFLOAD
+	if (data) {
+		if (netdev->mtu > MV_ETH_TX_CSUM_MAX_SIZE) {
+			printk(KERN_ERR "Cannot set TX checksum when MTU > %d\n", MV_ETH_TX_CSUM_MAX_SIZE);
+			return -EOPNOTSUPP;
+		}
+		netdev->features |= NETIF_F_IP_CSUM;
+	} else {
+		netdev->features &= ~NETIF_F_IP_CSUM;
+	}
+
+	return 0;
+#else
+	return -EOPNOTSUPP;
+#endif /* TX_CSUM_OFFLOAD */
+}
+
+/******************************************************************************
+* mv_eth_tool_set_tso
+* Description:
+*	ethtool enable/disable TCP segmentation offloading
+* INPUT:
+*	netdev		Network device structure pointer
+*	data		Command data
+* OUTPUT
+*	None
+* RETURN:
+*	0 on success
+*
+*******************************************************************************/
+int mv_eth_tool_set_tso(struct net_device *netdev, uint32_t data)
+{
+#if defined(CONFIG_MV_ETH_TSO)
+	if (data)
+		netdev->features |= NETIF_F_TSO;
+	else
+		netdev->features &= ~NETIF_F_TSO;
+
+	return 0;
+#else
+	return -EOPNOTSUPP;
+#endif
+}
+/******************************************************************************
+* mv_eth_tool_get_strings
+* Description:
+*	ethtool get strings (used for statistics and self-test descriptions)
+* INPUT:
+*	netdev		Network device structure pointer
+*	stringset	strings parameters
+* OUTPUT
+*	data		output data
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_strings(struct net_device *netdev,
+			     uint32_t stringset, uint8_t *data)
+{
+/*	printk("in %s \n",__FUNCTION__);*/
+
+}
+
+/******************************************************************************
+* mv_eth_tool_get_stats_count
+* Description:
+*	ethtool get statistics count (number of stat. array entries)
+* INPUT:
+*	netdev		Network device structure pointer
+* OUTPUT
+*	None
+* RETURN:
+*	statistics count
+*
+*******************************************************************************/
+int mv_eth_tool_get_stats_count(struct net_device *netdev)
+{
+/*	printk("in %s \n",__FUNCTION__);*/
+	return 0;
+}
+
+static int mv_eth_tool_get_rxfh_indir(struct net_device *netdev,
+							struct ethtool_rxfh_indir *indir)
+{
+/*HW support in PPv2 step 2 */
+#if defined(MV_ETH_PNC_LB)
+	struct eth_port 	*priv = MV_ETH_PRIV(netdev);
+	size_t copy_size =
+		min_t(size_t, indir->size, ARRAY_SIZE(priv->rx_indir_table));
+
+	indir->size = ARRAY_SIZE(priv->rx_indir_table);
+
+	memcpy(indir->ring_index, priv->rx_indir_table,
+	       copy_size * sizeof(indir->ring_index[0]));
+	return 0;
+#else
+	return -EOPNOTSUPP;
+#endif
+}
+
+static int mv_eth_tool_set_rxfh_indir(struct net_device *netdev,
+							   const struct ethtool_rxfh_indir *indir)
+{
+/*HW support in PPv2 step 2 */
+#if defined(MV_ETH_PNC_LB)
+	int i;
+	struct eth_port 	*priv = MV_ETH_PRIV(netdev);
+	for (i = 0; i < indir->size; i++) {
+		priv->rx_indir_table[i] = indir->ring_index[i];
+		/* TODO support in PPv2 parser and classifier sw - Step 2 */
+		/* mvPncLbRxqSet(i, priv->rx_indir_table[i]);*/
+	}
+	return 0;
+#else
+	return -EOPNOTSUPP;
+#endif
+}
+
+static int mv_eth_tool_get_rxnfc(struct net_device *dev, struct ethtool_rxnfc *info,
+									 u32 *rules)
+{
+	if (info->cmd == ETHTOOL_GRXRINGS) {
+		struct eth_port *pp = MV_ETH_PRIV(dev);
+		if (pp)
+			info->data = ARRAY_SIZE(pp->rx_indir_table);
+	}
+	return 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_set_rx_ntuple
+* Description:
+*	ethtool set mapping from 2t/5t rule to rxq/drop
+*	ignore mask parameters (assume mask=0xFF for each byte provided)
+*	support only tcp4 / udp4 protocols
+*	support only full 2t/5t rules:
+*		** 2t - must provide src-ip, dst-ip
+*		** 5t - must provide src-ip, dst-ip, src-port, dst-port
+* INPUT:
+*	netdev		Network device structure pointer
+*	ntuple
+* OUTPUT
+*	None
+* RETURN:
+*
+*******************************************************************************/
+static int mv_eth_tool_set_rx_ntuple(struct net_device *dev, struct ethtool_rx_ntuple *ntuple)
+{
+/*TODO*/
+	unsigned int sip, dip, ports, sport, dport, proto;
+	struct eth_port *pp;
+
+	return -EOPNOTSUPP;
+
+	if ((ntuple->fs.flow_type != TCP_V4_FLOW) && (ntuple->fs.flow_type != UDP_V4_FLOW))
+		return -EOPNOTSUPP;
+
+	if ((ntuple->fs.action >= CONFIG_MV_ETH_RXQ) || (ntuple->fs.action < ETHTOOL_RXNTUPLE_ACTION_CLEAR))
+		return -EINVAL;
+
+	if (ntuple->fs.flow_type == TCP_V4_FLOW)
+		proto = 6;/*tcp*/
+	else
+		proto = 17;/*udp*/
+
+	sip = ntuple->fs.h_u.tcp_ip4_spec.ip4src;
+	dip = ntuple->fs.h_u.tcp_ip4_spec.ip4dst;
+	sport = ntuple->fs.h_u.tcp_ip4_spec.psrc;
+	dport = ntuple->fs.h_u.tcp_ip4_spec.pdst;
+	if (!sip || !dip)
+		return -EINVAL;
+
+	pp = MV_ETH_PRIV(dev);
+	if (!sport || !dport) {/*2-tuple*/
+		/*pnc_ip4_2tuple_rxq(pp->port, sip, dip, ntuple->fs.action);*/
+	} else {
+		ports = (dport << 16) | ((sport << 16) >> 16);
+		/*pnc_ip4_5tuple_rxq(pp->port, sip, dip, ports, proto, ntuple->fs.action);*/
+	}
+
+	return 0;
+}
+
+/******************************************************************************
+* mv_eth_tool_get_ethtool_stats
+* Description:
+*	ethtool get statistics
+* INPUT:
+*	netdev		Network device structure pointer
+*	stats		stats parameters
+* OUTPUT
+*	data		output data
+* RETURN:
+*	None
+*
+*******************************************************************************/
+void mv_eth_tool_get_ethtool_stats(struct net_device *netdev,
+				   struct ethtool_stats *stats, uint64_t *data)
+{
+
+}
+
+const struct ethtool_ops mv_eth_tool_ops = {
+	.get_settings				= mv_eth_tool_get_settings,
+	.set_settings				= mv_eth_tool_set_settings,
+	.get_drvinfo				= mv_eth_tool_get_drvinfo,
+	.get_regs_len				= mv_eth_tool_get_regs_len,
+	.get_regs				= mv_eth_tool_get_regs,/*TODO: complete implementation */
+	.nway_reset				= mv_eth_tool_nway_reset,
+	.get_link				= mv_eth_tool_get_link,
+	.get_coalesce				= mv_eth_tool_get_coalesce,
+	.set_coalesce				= mv_eth_tool_set_coalesce,
+	.get_ringparam  			= mv_eth_tool_get_ringparam,
+	.set_ringparam 				= mv_eth_tool_set_ringparam,
+	.get_pauseparam				= mv_eth_tool_get_pauseparam,
+	.set_pauseparam				= mv_eth_tool_set_pauseparam,
+	.get_rx_csum				= mv_eth_tool_get_rx_csum,
+	.set_rx_csum				= mv_eth_tool_set_rx_csum,
+	.get_tx_csum				= ethtool_op_get_tx_csum,
+	.set_tx_csum				= mv_eth_tool_set_tx_csum,
+	.get_sg					= ethtool_op_get_sg,
+	.set_sg					= ethtool_op_set_sg,
+	.get_tso				= ethtool_op_get_tso,
+	.set_tso				= mv_eth_tool_set_tso,
+	.get_strings				= mv_eth_tool_get_strings,/*TODO: complete implementation */
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 32)
+	.get_stats_count			= mv_eth_tool_get_stats_count,/*TODO: complete implementation */
+#endif
+	.get_ethtool_stats			= mv_eth_tool_get_ethtool_stats,/*TODO: complete implementation */
+	.get_rxfh_indir				= mv_eth_tool_get_rxfh_indir,
+	.set_rxfh_indir				= mv_eth_tool_set_rxfh_indir,
+	.get_rxnfc                  		= mv_eth_tool_get_rxnfc,/*TODO new implementation*/
+	.set_rx_ntuple				= mv_eth_tool_set_rx_ntuple,/*TODO new implementation*/
+};
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.h
new file mode 100644
index 0000000..a2c600c
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.h
@@ -0,0 +1,35 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef NET_DEV_MV_ETH_TOOL_H
+#define NET_DEV_MV_ETH_TOOL_H
+
+#include <linux/ethtool.h>
+
+extern const struct ethtool_ops mv_eth_tool_ops;
+
+#endif
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tx_sched_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tx_sched_sysfs.c
new file mode 100644
index 0000000..eb78caf
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tx_sched_sysfs.c
@@ -0,0 +1,153 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "mv_eth_sysfs.h"
+#include "gbe/mvPp2Gbe.h"
+#include "mv_netdev.h"
+
+static ssize_t mv_eth_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "echo [p] [txp]               > txSchedRegs   - show TXP Scheduler registers for egress port <p/txp>\n");
+	off += sprintf(buf+off, "echo [p] [txp] [v]           > txpRate       - set outgoing rate <v> in [kbps] for <port/txp>\n");
+	off += sprintf(buf+off, "echo [p] [txp] [v]           > txpBurst      - set maximum burst <v> in [Bytes] for <port/txp>\n");
+	off += sprintf(buf+off, "echo [p] [txp] [txq] [v]     > txqRate       - set outgoing rate <v> in [kbps] for <port/txp/txq>\n");
+	off += sprintf(buf+off, "echo [p] [txp] [txq] [v]     > txqBurst      - set maximum burst <v> in [Bytes] for <port/txp/txq>\n");
+	off += sprintf(buf+off, "echo [p] [txp] [txq] [v]     > txqWrr        - set outgoing WRR weight for <port/txp/txq>. <v=0> - fixed\n");
+
+	return off;
+}
+
+static ssize_t mv_eth_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = mv_eth_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_eth_port_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, v, a, b;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = p = v = a = b = 0;
+	sscanf(buf, "%d %d %d %d", &p, &v, &a, &b);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "txSchedRegs")) {
+		mvPp2TxSchedRegs(p, v);
+	} else if (!strcmp(name, "txpRate")) {
+		err = mvPp2TxpRateSet(p, v, a);
+	} else if (!strcmp(name, "txpBurst")) {
+		err = mvPp2TxpBurstSet(p, v, a);
+	} else if (!strcmp(name, "txqRate")) {
+		err = mvPp2TxqRateSet(p, v, a, b);
+	} else if (!strcmp(name, "txqBurst")) {
+		err = mvPp2TxqBurstSet(p, v, a, b);
+	} else if (!strcmp(name, "txqWrr")) {
+		if (a == 0)
+			err = mvPp2TxqFixPrioSet(p, v, a);
+		else
+			err = mvPp2TxqWrrPrioSet(p, v, a, b);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+
+static DEVICE_ATTR(help,         S_IRUSR, mv_eth_show, NULL);
+static DEVICE_ATTR(txSchedRegs,  S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(txpRate,      S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(txpBurst,     S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(txqRate,      S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(txqBurst,     S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(txqWrr,       S_IWUSR, NULL, mv_eth_port_store);
+
+static struct attribute *mv_eth_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_txSchedRegs.attr,
+	&dev_attr_txpRate.attr,
+	&dev_attr_txpBurst.attr,
+	&dev_attr_txqRate.attr,
+	&dev_attr_txqBurst.attr,
+	&dev_attr_txqWrr.attr,
+	NULL
+};
+
+static struct attribute_group mv_eth_group = {
+	.name = "tx_sched",
+	.attrs = mv_eth_attrs,
+};
+
+int mv_eth_tx_sched_sysfs_init(struct kobject *pp2_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp2_kobj, &mv_eth_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+
+out:
+	return err;
+}
+
+MODULE_AUTHOR("Kostya Belezko");
+MODULE_DESCRIPTION("sysfs for marvell GbE");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tx_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tx_sysfs.c
new file mode 100644
index 0000000..c4c3793
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tx_sysfs.c
@@ -0,0 +1,155 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "mv_eth_sysfs.h"
+#include "gbe/mvPp2Gbe.h"
+#include "mv_netdev.h"
+
+
+static ssize_t mv_eth_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "echo [p] [txp] [txq]            > pTxqRegs      - show TXQ registers for port <p/txp/txq> where <txq> range [0..7]\n");
+	off += sprintf(buf+off, "echo [txq]                      > gTxqRegs      - show TXQ registers for global <txq> range [0..255]\n");
+	off += sprintf(buf+off, "echo [cpu]                      > aggrTxqRegs   - show Aggregation TXQ registers for <cpu> range [0..max]\n");
+	off += sprintf(buf+off, "echo [cpu] [v]                  > aggrTxqShow   - show aggregated TXQ descriptors ring for <cpu>.\n");
+	off += sprintf(buf+off, "echo [p] [txp] [txq] [v]        > txqShow       - show TXQ descriptors ring for <p/txp/txq>. v=0-brief, v=1-full\n");
+	off += sprintf(buf+off, "echo [p] [txp] [txq] [cpu]      > txqDef        - set default <txp/txq> for packets sent to port <p> by <cpu>\n");
+	off += sprintf(buf+off, "echo [p] [txp] [txq] [v] [hwf]  > txqSize      - set descriptor Q size <v>, and HWF share <hwf> for <p/txp/txq>. \n");
+
+	return off;
+}
+
+static ssize_t mv_eth_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	off = mv_eth_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_eth_port_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    p, v, a, b, c;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = p = v = a = b = c = 0;
+	sscanf(buf, "%d %d %d %d %d", &p, &v, &a, &b, &c);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "txqDef")) {
+		err = mv_eth_ctrl_txq_cpu_def(p, v, a, b);
+	} else if (!strcmp(name, "txqShow")) {
+		mvPp2TxqShow(p, v, a, b);
+	}  else if (!strcmp(name, "aggrTxqShow")) {
+		mvPp2AggrTxqShow(p, v);
+	} else if (!strcmp(name, "gTxqRegs")) {
+		mvPp2PhysTxqRegs(p);
+	} else if (!strcmp(name, "pTxqRegs")) {
+		mvPp2PortTxqRegs(p, v, a);
+	} else if (!strcmp(name, "aggrTxqRegs")) {
+		mvPp2AggrTxqRegs(p);
+	} else if (!strcmp(name, "txqSize")) {
+		mv_eth_ctrl_txq_size_set(p, v, a, b, c);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,         S_IRUSR, mv_eth_show, NULL);
+static DEVICE_ATTR(aggrTxqRegs,  S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(txqShow,      S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(gTxqRegs,     S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(pTxqRegs,     S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(aggrTxqShow,  S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(txqDef,     	 S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(txqSize,    	 S_IWUSR, NULL, mv_eth_port_store);
+
+static struct attribute *mv_eth_attrs[] = {
+	&dev_attr_txqDef.attr,
+	&dev_attr_aggrTxqRegs.attr,
+	&dev_attr_help.attr,
+	&dev_attr_txqShow.attr,
+	&dev_attr_gTxqRegs.attr,
+	&dev_attr_pTxqRegs.attr,
+	&dev_attr_aggrTxqShow.attr,
+	&dev_attr_txqSize.attr,
+	NULL
+};
+
+static struct attribute_group mv_eth_group = {
+	.name = "tx",
+	.attrs = mv_eth_attrs,
+};
+
+int mv_eth_tx_sysfs_init(struct kobject *pp2_kobj)
+{
+	int err;
+
+	err = sysfs_create_group(pp2_kobj, &mv_eth_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+
+out:
+	return err;
+}
+
+MODULE_AUTHOR("Kostya Belezko");
+MODULE_DESCRIPTION("sysfs for marvell GbE");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_ethernet.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_ethernet.c
new file mode 100644
index 0000000..09bb5e2
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_ethernet.c
@@ -0,0 +1,351 @@
+
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/skbuff.h>
+#include <linux/interrupt.h>
+
+#include "mvOs.h"
+#include "dbg-trace.h"
+#include "mvSysHwConfig.h"
+#include "boardEnv/mvBoardEnvLib.h"
+
+#include "eth-phy/mvEthPhy.h"
+#include "gbe/mvPp2Gbe.h"
+#include "prs/mvPp2Prs.h"
+#include "cls/mvPp2ClsHw.h"
+
+#include "mv_netdev.h"
+
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+#include "mv_switch.h"
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+
+extern unsigned int mv_eth_pnc_ctrl_en;
+
+static int mv_eth_start(struct net_device *dev);
+static int mv_eth_set_mac_addr_internals(struct net_device *dev, void *addr);
+
+/***********************************************************
+ * mv_eth_start --                                         *
+ *   start a network device. connect and enable interrupts *
+ *   set hw defaults. fill rx buffers. restart phy link    *
+ *   auto neg. set device link flags. report status.       *
+ ***********************************************************/
+static int mv_eth_start(struct net_device *dev)
+{
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+	int group;
+
+	/* in default link is down */
+	netif_carrier_off(dev);
+	/* Stop the TX queue - it will be enabled upon PHY status change after link-up interrupt/timer */
+
+	printk(KERN_NOTICE "%s: mv_eth_start\n", dev->name);
+	netif_tx_stop_all_queues(dev);
+
+	/* fill rx buffers, start rx/tx activity, set coalescing */
+	if (mv_eth_start_internals(priv, dev->mtu) != 0) {
+		printk(KERN_ERR "%s: start internals failed\n", dev->name);
+		goto error;
+	}
+	/* enable polling on the port, must be used after netif_poll_disable */
+	if (priv->flags & MV_ETH_F_CONNECT_LINUX) {
+		for (group = 0; group < MV_ETH_MAX_RXQ; group++)
+			if (priv->napi_group[group] && priv->napi_group[group]->napi)
+				napi_enable(priv->napi_group[group]->napi);
+	}
+	if ((priv->flags & MV_ETH_F_LINK_UP) && !(priv->flags & MV_ETH_F_EXT_SWITCH)) {
+
+		if (mv_eth_ctrl_is_tx_enabled(priv)) {
+			netif_carrier_on(dev);
+			netif_tx_wake_all_queues(dev);
+		}
+		printk(KERN_NOTICE "%s: link up\n", dev->name);
+	}
+#ifdef CONFIG_MV_ETH_SWITCH_LINK
+	if (priv->flags & MV_ETH_F_EXT_SWITCH) {
+		struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+
+		dev_priv->link_map = 0;
+		mv_switch_link_update_event(dev_priv->port_map, 1);
+	}
+#endif /* CONFIG_MV_ETH_SWITCH_LINK */
+	if (priv->flags & MV_ETH_F_CONNECT_LINUX) {
+		/* connect to port interrupt line */
+		if (request_irq(dev->irq, mv_eth_isr, (IRQF_DISABLED|IRQF_SAMPLE_RANDOM), "mv_eth", priv)) {
+			printk(KERN_ERR "cannot request irq %d for %s port %d\n", dev->irq, dev->name, priv->port);
+			for (group = 0; group < MV_ETH_MAX_RXQ; group++)
+				if (priv->napi_group[group] && priv->napi_group[group]->napi)
+					napi_disable(priv->napi_group[group]->napi);
+			goto error;
+		}
+
+		/* unmask interrupts */
+		mv_eth_interrupts_unmask(priv);
+		smp_call_function_many(cpu_online_mask, (smp_call_func_t)mv_eth_interrupts_unmask, (void *)priv, 1);
+
+		printk(KERN_NOTICE "%s: started\n", dev->name);
+	}
+
+	/* allow new packets to RXQs */
+	mvPrsMacDropAllSet(priv->port, 0);
+
+	return 0;
+
+error:
+	printk(KERN_ERR "%s: start failed\n", dev->name);
+	return -1;
+}
+
+/***********************************************************
+ * mv_eth_stop --                                          *
+ *   stop interface with linux core. stop port activity.   *
+ *   free skb's from rings.                                *
+ ***********************************************************/
+int mv_eth_stop(struct net_device *dev)
+{
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+	struct cpu_ctrl *cpuCtrl;
+	int group, cpu;
+
+	/* stop new packets from arriving to RXQs */
+	mvPrsMacDropAllSet(priv->port, 1);
+
+	mdelay(10);
+
+	mv_eth_interrupts_mask(priv);
+
+	/* make sure that the port finished its Rx polling */
+	for (group = 0; group < MV_ETH_MAX_RXQ; group++)
+		if (priv->napi_group[group] && priv->napi_group[group]->napi)
+			napi_disable(priv->napi_group[group]->napi);
+
+	/* stop upper layer */
+	netif_carrier_off(dev);
+	printk(KERN_NOTICE "%s: mv_eth_stop\n", dev->name);
+	netif_tx_stop_all_queues(dev);
+
+	/* stop tx/rx activity, mask all interrupts, relese skb in rings,*/
+	mv_eth_stop_internals(priv);
+	for_each_possible_cpu(cpu) {
+		cpuCtrl = priv->cpu_config[cpu];
+		del_timer(&cpuCtrl->tx_done_timer);
+		clear_bit(MV_ETH_F_TX_DONE_TIMER_BIT, &(cpuCtrl->flags));
+		del_timer(&cpuCtrl->cleanup_timer);
+		clear_bit(MV_ETH_F_CLEANUP_TIMER_BIT, &(cpuCtrl->flags));
+	}
+	if (dev->irq != 0)
+		free_irq(dev->irq, priv);
+
+	printk(KERN_NOTICE "%s: stopped\n", dev->name);
+
+	return 0;
+}
+
+
+int mv_eth_change_mtu(struct net_device *dev, int mtu)
+{
+	int old_mtu = dev->mtu;
+
+	mtu = mv_eth_check_mtu_valid(dev, mtu);
+	if (mtu < 0)
+		return -EINVAL;
+
+	if (!netif_running(dev)) {
+		if (mv_eth_change_mtu_internals(dev, mtu) == -1)
+			goto error;
+
+		printk(KERN_NOTICE "%s: change mtu %d (buffer-size %d) to %d (buffer-size %d)\n",
+				dev->name, old_mtu, RX_PKT_SIZE(old_mtu),
+				dev->mtu, RX_PKT_SIZE(dev->mtu));
+		return 0;
+	}
+
+	if (mv_eth_check_mtu_internals(dev, mtu))
+		goto error;
+
+	if (mv_eth_stop(dev)) {
+		printk(KERN_ERR "%s: stop interface failed\n", dev->name);
+		goto error;
+	}
+
+	if (mv_eth_change_mtu_internals(dev, mtu) == -1) {
+		printk(KERN_ERR "%s change mtu internals failed\n", dev->name);
+		goto error;
+	}
+
+	if (mv_eth_start(dev)) {
+		printk(KERN_ERR "%s: start interface failed\n", dev->name);
+		goto error;
+	}
+	printk(KERN_NOTICE "%s: change mtu %d (buffer-size %d) to %d (buffer-size %d)\n",
+				dev->name, old_mtu, RX_PKT_SIZE(old_mtu), dev->mtu,
+				RX_PKT_SIZE(dev->mtu));
+	return 0;
+
+error:
+	printk(KERN_ERR "%s: change mtu failed\n", dev->name);
+	return -1;
+}
+
+/***********************************************************
+ * eth_set_mac_addr --                                   *
+ *   stop port activity. set new addr in device and hw.    *
+ *   restart port activity.                                *
+ ***********************************************************/
+static int mv_eth_set_mac_addr_internals(struct net_device *dev, void *addr)
+{
+	u8              *mac = &(((u8 *)addr)[2]);  /* skip on first 2B (ether HW addr type) */
+	int             i;
+
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+
+	if (!mv_eth_pnc_ctrl_en) {
+		printk(KERN_ERR "%s Error: PARSER and CLASSIFIER control is disabled\n", __func__);
+
+		/* linux stop the port */
+		mv_eth_open(dev);
+		return -1;
+	}
+
+	/* remove old parser entry*/
+	mvPrsMacDaAccept(MV_PPV2_PORT_PHYS(priv->port), dev->dev_addr, 0);
+
+	/*add new parser entry*/
+	mvPrsMacDaAccept(MV_PPV2_PORT_PHYS(priv->port), mac, 1);
+
+	/* set addr in the device */
+	for (i = 0; i < 6; i++)
+		dev->dev_addr[i] = mac[i];
+
+	printk(KERN_NOTICE "%s: mac address changed\n", dev->name);
+
+	return 0;
+}
+
+
+void mv_eth_set_multicast_list(struct net_device *dev, int flags)
+{
+
+	struct eth_port     *priv = MV_ETH_PRIV(dev);
+	int                 phyPort = MV_PPV2_PORT_PHYS(priv->port);
+
+/*
+	printk("%s - mv_eth_set_multicast_list: dev flags=0x%x func flags 0x%x, mc_count=%d\n",
+		dev->name, dev->flags, flags, dev->mc.count);
+*/
+	if (!mv_eth_pnc_ctrl_en) {
+		printk(KERN_ERR "%s Error: PARSER and CLASSIFIER control is disabled\n", __func__);
+		return;
+	}
+
+	if (dev->flags & IFF_PROMISC)
+		mvPrsMacPromiscousSet(phyPort, 1);
+	else
+		mvPrsMacPromiscousSet(phyPort, 0);
+
+	if (dev->flags & IFF_ALLMULTI)
+		mvPrsMacAllMultiSet(phyPort, 1);
+	else
+		mvPrsMacAllMultiSet(phyPort, 0);
+
+	/* TODO - upadte parser according to dev multicast list ? */
+}
+
+
+int     mv_eth_set_mac_addr(struct net_device *dev, void *addr)
+{
+	if (!netif_running(dev)) {
+		if (mv_eth_set_mac_addr_internals(dev, addr) == -1)
+			goto error;
+		return 0;
+	}
+
+	if (mv_eth_stop(dev)) {
+		printk(KERN_ERR "%s: stop interface failed\n", dev->name);
+		goto error;
+	}
+
+	if (mv_eth_set_mac_addr_internals(dev, addr) == -1)
+		goto error;
+
+	if (mv_eth_start(dev)) {
+		printk(KERN_ERR "%s: start interface failed\n", dev->name);
+		goto error;
+	}
+
+	return 0;
+
+error:
+	printk(KERN_ERR "%s: set mac addr failed\n", dev->name);
+	return -1;
+}
+
+
+/************************************************************
+ * mv_eth_open -- Restore MAC address and call to   *
+ *                mv_eth_start                               *
+ ************************************************************/
+int mv_eth_open(struct net_device *dev)
+{
+
+	struct	eth_port *priv = MV_ETH_PRIV(dev);
+	int	phyPort = MV_PPV2_PORT_PHYS(priv->port);
+	static u8 mac_bcast[MV_MAC_ADDR_SIZE] = { 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF };
+
+	if (mv_eth_pnc_ctrl_en) {
+
+		if (mvPrsMacDaAccept(phyPort, mac_bcast, 1 /*add*/)) {
+			printk(KERN_ERR "%s: mvPrsMacDaAccept failed\n", dev->name);
+				return -1;
+		}
+		if (mvPrsMacDaAccept(phyPort, dev->dev_addr, 1 /*add*/)) {
+			printk(KERN_ERR "%s: mvPrsMacDaAccept failed\n", dev->name);
+				return -1;
+		}
+		if (mvPp2PrsTagModeSet(phyPort, MV_PP2_MH)) {
+			printk(KERN_ERR "%s: mvPp2PrsTagModeSet failed\n", dev->name);
+				return -1;
+		}
+		if (mvPrsDefFlow(phyPort)) {
+			printk(KERN_ERR "%s: mvPp2PrsDefFlow failed\n", dev->name);
+				return -1;
+		}
+	}
+	if (mv_eth_start(dev)) {
+		printk(KERN_ERR "%s: start interface failed\n", dev->name);
+		return -1;
+	}
+	return 0;
+}
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_fpga_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_fpga_sysfs.c
new file mode 100644
index 0000000..7a80c23
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_fpga_sysfs.c
@@ -0,0 +1,218 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <linux/netdevice.h>
+
+#include "gbe/mvPp2Gbe.h"
+#include "mv_netdev.h"
+
+void	mvPp2FpgaDebugDump(void)
+{
+	int i, entry_no, dword_no;
+
+	mvEthRegPrint(0x5800, "0x5800");
+	mvEthRegPrint(0x5804, "0x5804");
+	mvEthRegPrint(0x5840, "0x5804");
+	mvEthRegPrint(0x5844, "0x5844");
+	mvEthRegPrint(0x5848, "0x5844");
+
+	for (i = 0; i < 8; i++) {
+		mvEthRegPrint2(0x5860 + 4 * i, "0x5860 + i", i);
+	}
+	for (i = 0; i < 8; i++) {
+		mvEthRegPrint2(0x5880 + 4 * i, "0x5880", i);
+	}
+
+	for (entry_no = 0; entry_no < 256; entry_no++) {
+		mvOsPrintf("\nEntry number #%d\n", entry_no);
+		for (dword_no = 0; dword_no < 8; dword_no++) {
+			MV_REG_WRITE(0x58a0, 256 * dword_no + entry_no);
+			mvEthRegPrint2(0x58a4, "0x58a4 + 256 * d + e", 256 * dword_no + entry_no);
+		}
+	}
+}
+
+void	mvPp2FpgaPtrnSet(int ptrn_no, unsigned int mask, unsigned int data)
+{
+	MV_U32	regVal;
+
+	regVal = (((mask & 0xFFFF) << 16) | ((data & 0xFFFF) << 0));
+	mvOsPrintf("ptrn_no=%d, mask=0x%04x, data=0x%04x: 0x%08x => 0x%x\n",
+				ptrn_no, mask, data, regVal, (0x5860 + 4 * ptrn_no));
+	MV_REG_WRITE(0x5860 + 4 * ptrn_no, regVal);
+}
+
+void	mvPp2FpgaStageSet(int stage_no, unsigned int find_count, unsigned int start_ptrn,
+						  unsigned int restart_stage_no, unsigned int restart_opcode,
+						  unsigned int find_opcode, unsigned int store_opcode)
+{
+	MV_U32	regVal = 0;
+
+	regVal = (((find_count       & 0xFF) << 24) |
+			  ((start_ptrn       & 0x7)  << 21) |
+			  ((restart_stage_no & 0x7)  << 18) |
+			  ((restart_opcode   & 0x3F) << 12) |
+			  ((find_opcode      & 0x3F) << 6) |
+			  ((store_opcode     & 0x3F) << 0));
+
+	mvOsPrintf("stage_no=%d: 0x%08x => 0x%x\n",
+				stage_no, regVal, (0x5880 + 4 * stage_no));
+
+	MV_REG_WRITE(0x5880 + 4 * stage_no, regVal);
+}
+
+void	mvPp2FpgaDebugInit(void)
+{
+	int ptrn_no, stage_no;
+
+	for (ptrn_no = 0; ptrn_no < 8; ptrn_no++) {
+		mvPp2FpgaPtrnSet(ptrn_no, 0xFFFF, 0x0);
+	}
+	for (stage_no = 0; stage_no < 8; stage_no++) {
+		mvPp2FpgaStageSet(stage_no, 0x1, 0x0, 0x0, 0xC, 0xF, 0xF);
+	}
+}
+
+static ssize_t mv_fpga_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "cat                            help     - print this help\n");
+	off += sprintf(buf+off, "cat                            dump     - print FPGA debug state\n");
+	off += sprintf(buf+off, "echo i mask data             > ptrn     - configure FPGA debug pattern\n");
+	off += sprintf(buf+off, "echo i v1 v2 v3 v4 v5 v6     > stage    - configure FPGA debug stage\n");
+
+	return off;
+}
+
+static ssize_t mv_fpga_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "dump")) {
+		mvPp2FpgaDebugDump();
+	} else {
+		off = mv_fpga_help(buf);
+	}
+
+	return off;
+}
+
+static ssize_t mv_fpga_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    i, v1, v2, v3, v4, v5, v6;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	/* Read port and value */
+	err = i = v1 = v2 = v3 = v4 = v5 = v6 = 0;
+	sscanf(buf, "%d %x %x %x %x %x %x", &i, &v1, &v2, &v3, &v4, &v5, &v6);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "ptrn")) {
+		mvPp2FpgaPtrnSet(i, v1, v2);
+	} else if (!strcmp(name, "stage")) {
+		mvPp2FpgaStageSet(i, v1, v2, v3, v4, v5, v6);
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,        S_IRUSR, mv_fpga_show, NULL);
+static DEVICE_ATTR(dump,        S_IRUSR, mv_fpga_show, NULL);
+static DEVICE_ATTR(ptrn,       	S_IWUSR, NULL, mv_fpga_store);
+static DEVICE_ATTR(stage,       S_IWUSR, NULL, mv_fpga_store);
+
+static struct attribute *mv_fpga_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_dump.attr,
+	&dev_attr_ptrn.attr,
+	&dev_attr_stage.attr,
+	NULL
+};
+
+static struct attribute_group mv_fpga_group = {
+	.name = "fpga",
+	.attrs = mv_fpga_attrs,
+};
+
+int __devinit mv_fpga_sysfs_init(void)
+{
+	int err;
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	if (!pd) {
+		platform_device_register_simple("pp2", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	}
+
+	if (!pd) {
+		printk(KERN_ERR"%s: cannot find pp2 device\n", __func__);
+		pd = &platform_bus;
+	}
+
+	err = sysfs_create_group(&pd->kobj, &mv_fpga_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+	mvPp2FpgaDebugInit();
+out:
+	return err;
+}
+
+module_init(mv_fpga_sysfs_init);
+
+MODULE_AUTHOR("Dima Epshtein");
+MODULE_DESCRIPTION("sysfs for marvell FPGA");
+MODULE_LICENSE("GPL");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
new file mode 100644
index 0000000..24980a6
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
@@ -0,0 +1,4966 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include "mvCommon.h"
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/platform_device.h>
+#include <linux/skbuff.h>
+#include <linux/module.h>
+#include <linux/inetdevice.h>
+#include <linux/mv_pp2.h>
+#include <asm/setup.h>
+#include <net/ip.h>
+#include <net/ipv6.h>
+
+#include "mvOs.h"
+#include "mvDebug.h"
+#include "dbg-trace.h"
+#include "mvSysHwConfig.h"
+#include "boardEnv/mvBoardEnvLib.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "eth-phy/mvEthPhy.h"
+#include "mvSysEthPhyApi.h"
+#include "mvSysPp2Api.h"
+
+#include "gbe/mvPp2Gbe.h"
+#include "prs/mvPp2Prs.h"
+#include "prs/mvPp2PrsHw.h"
+#include "cls/mvPp2Classifier.h"
+#include "mv_switch.h"
+#include "mv_netdev.h"
+#include "mv_eth_tool.h"
+
+#define MV_ETH_MAX_NAPI_GROUPS	MV_ETH_MAX_RXQ
+
+#define MV_ETH_TX_PENDING_TIMEOUT_MSEC     1000
+
+static inline int mv_eth_tx_policy(struct eth_port *pp, struct sk_buff *skb);
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+int mv_ctrl_recycle = CONFIG_NET_SKB_RECYCLE_DEF;
+EXPORT_SYMBOL(mv_ctrl_recycle);
+
+int mv_eth_ctrl_recycle(int en)
+{
+	mv_ctrl_recycle = en;
+	return 0;
+}
+#else
+int mv_eth_ctrl_recycle(int en)
+{
+	printk(KERN_ERR "SKB recycle is not supported\n");
+	return 1;
+}
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+extern unsigned int switch_enabled_ports;
+unsigned int ext_switch_port_mask = 0;
+
+struct bm_pool mv_eth_pool[MV_ETH_BM_POOLS];
+struct eth_port **mv_eth_ports;
+struct net_device **mv_net_devs;
+struct aggr_tx_queue *aggr_txqs;
+
+int mv_net_devs_num = 0;
+int mv_ctrl_txdone = CONFIG_MV_ETH_TXDONE_COAL_PKTS;
+EXPORT_SYMBOL(mv_ctrl_txdone);
+
+unsigned int mv_eth_pnc_ctrl_en = 1;
+
+/*
+ * Static declarations
+ */
+static int mv_eth_ports_num = 0;
+static int mv_net_devs_max = 0;
+
+static int mv_eth_initialized = 0;
+
+/*
+ * Local functions
+ */
+static void mv_eth_txq_delete(struct eth_port *pp, struct tx_queue *txq_ctrl);
+static void mv_eth_tx_timeout(struct net_device *dev);
+static int  mv_eth_tx(struct sk_buff *skb, struct net_device *dev);
+static void mv_eth_tx_frag_process(struct eth_port *pp, struct sk_buff *skb, struct aggr_tx_queue *aggr_txq_ctrl,
+		struct tx_queue *txq_ctrl, struct mv_eth_tx_spec *tx_spec);
+
+static void mv_eth_config_show(void);
+static int  mv_eth_priv_init(struct eth_port *pp, int port);
+static void mv_eth_priv_cleanup(struct eth_port *pp);
+static int  mv_eth_config_get(struct platform_device *pdev, u8 *mac);
+static int  mv_eth_hal_init(struct eth_port *pp);
+struct net_device *mv_eth_netdev_init(struct eth_port *pp, int mtu, u8 *mac,
+					struct platform_device *pdev);
+static void mv_eth_netdev_set_features(struct net_device *dev);
+static void mv_eth_netdev_update_features(struct net_device *dev);
+
+static MV_STATUS mv_eth_pool_create(int pool, int capacity);
+static int mv_eth_pool_add(int pool, int buf_num);
+static int mv_eth_pool_free(int pool, int num);
+static int mv_eth_pool_destroy(int pool);
+
+#ifdef CONFIG_MV_ETH_TSO
+int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_eth_tx_spec *tx_spec,
+			struct txq_cpu_ctrl *txq_ctrl, struct aggr_tx_queue *aggr_txq_ctrl);
+#endif
+
+/* Get the configuration string from the Kernel Command Line */
+static char *port0_config_str = NULL, *port1_config_str = NULL, *port2_config_str = NULL, *port3_config_str = NULL,
+	    *port4_config_str = NULL, *port5_config_str = NULL, *port6_config_str = NULL, *port7_config_str = NULL;
+int mv_eth_cmdline_port0_config(char *s);
+__setup("mv_port0_config=", mv_eth_cmdline_port0_config);
+int mv_eth_cmdline_port1_config(char *s);
+__setup("mv_port1_config=", mv_eth_cmdline_port1_config);
+int mv_eth_cmdline_port2_config(char *s);
+__setup("mv_port2_config=", mv_eth_cmdline_port2_config);
+int mv_eth_cmdline_port3_config(char *s);
+__setup("mv_port3_config=", mv_eth_cmdline_port3_config);
+int mv_eth_cmdline_port4_config(char *s);
+__setup("mv_port4_config=", mv_eth_cmdline_port4_config);
+int mv_eth_cmdline_port5_config(char *s);
+__setup("mv_port5_config=", mv_eth_cmdline_port5_config);
+int mv_eth_cmdline_port6_config(char *s);
+__setup("mv_port6_config=", mv_eth_cmdline_port6_config);
+int mv_eth_cmdline_port7_config(char *s);
+__setup("mv_port7_config=", mv_eth_cmdline_port7_config);
+
+int mv_eth_cmdline_port0_config(char *s)
+{
+	port0_config_str = s;
+	return 1;
+}
+
+int mv_eth_cmdline_port1_config(char *s)
+{
+	port1_config_str = s;
+	return 1;
+}
+
+int mv_eth_cmdline_port2_config(char *s)
+{
+	port2_config_str = s;
+	return 1;
+}
+
+int mv_eth_cmdline_port3_config(char *s)
+{
+	port3_config_str = s;
+	return 1;
+}
+
+int mv_eth_cmdline_port4_config(char *s)
+{
+	port4_config_str = s;
+	return 1;
+}
+
+int mv_eth_cmdline_port5_config(char *s)
+{
+	port5_config_str = s;
+	return 1;
+}
+
+int mv_eth_cmdline_port6_config(char *s)
+{
+	port6_config_str = s;
+	return 1;
+}
+
+int mv_eth_cmdline_port7_config(char *s)
+{
+	port7_config_str = s;
+	return 1;
+}
+
+void mv_eth_ctrl_pnc(int en)
+{
+	mv_eth_pnc_ctrl_en = en;
+}
+/*****************************************
+ *            NAPI Group API             *
+ *****************************************/
+/* Add/update a new empty napi_group */
+int mv_eth_port_napi_group_create(int port, int group)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct napi_group_ctrl *napi_group;
+
+	if ((group < 0) || (group >= MV_ETH_MAX_NAPI_GROUPS)) {
+		printk(KERN_ERR "%s: invalid napi group number - %d\n", __func__, group);
+		return 1;
+	}
+
+	napi_group = pp->napi_group[group];
+	if (napi_group) {
+		printk(KERN_ERR "%s: group already exist - %d\n", __func__, group);
+		return 1;
+	}
+
+	napi_group = mvOsMalloc(sizeof(struct napi_group_ctrl));
+	if (!napi_group)
+		return 1;
+
+	napi_group->napi = kmalloc(sizeof(struct napi_struct), GFP_KERNEL);
+	if (!napi_group->napi) {
+		mvOsFree(napi_group);
+		return 1;
+	}
+
+	memset(napi_group->napi, 0, sizeof(struct napi_struct));
+	netif_napi_add(pp->dev, napi_group->napi, mv_eth_poll, pp->weight);
+	pp->napi_group[group] = napi_group;
+
+	return 0;
+}
+
+/* Delete napi_group */
+int mv_eth_port_napi_group_delete(int port, int group)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct napi_group_ctrl *napi_group;
+
+	if ((group < 0) || (group >= MV_ETH_MAX_NAPI_GROUPS)) {
+		printk(KERN_ERR "%s: invalid napi group number - %d\n", __func__, group);
+		return 1;
+	}
+
+	napi_group = pp->napi_group[group];
+	if (!napi_group)
+		return 1;
+
+	if ((napi_group->cpu_mask != 0) || (napi_group->rxq_mask != 0)) {
+		printk(KERN_ERR "%s: group %d still has cpus/rxqs - cpus=0x%02x  rxqs=0x%04x\n", __func__,
+			group, napi_group->cpu_mask, napi_group->rxq_mask);
+		return 1;
+	}
+
+	netif_napi_del(napi_group->napi);
+	mvOsFree(napi_group->napi);
+	mvOsFree(napi_group);
+	pp->napi_group[group] = NULL;
+
+	return 0;
+}
+
+int mv_eth_napi_set_cpu_affinity(int port, int group, int cpu_mask)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct napi_group_ctrl *napi_group;
+	int i, cpu;
+
+	if (pp == NULL) {
+		printk(KERN_ERR "%s: pp is null \n", __func__);
+		return MV_FAIL;
+	}
+	if ((group < 0) || (group >= MV_ETH_MAX_NAPI_GROUPS)) {
+		printk(KERN_ERR "%s: group number is higher than %d\n", __func__, MV_ETH_MAX_NAPI_GROUPS - 1);
+		return -1;
+	}
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "%s: port %d must be stopped\n", __func__, port);
+		return -EINVAL;
+	}
+
+	/* check that cpu_mask doesn't have cpu that belong to other group */
+	for (i = 0; i < MV_ETH_MAX_NAPI_GROUPS; i++) {
+		napi_group = pp->napi_group[i];
+		if ((!napi_group) || (i == group))
+			continue;
+
+		if (napi_group->cpu_mask & cpu_mask) {
+			printk(KERN_ERR "%s: cpus mask contains cpu that is already in other group(%d) - %d\n",
+				__func__, i, cpu_mask);
+			return MV_FAIL;
+		}
+	}
+
+	napi_group = pp->napi_group[group];
+	if (napi_group == NULL) {
+		printk(KERN_ERR "%s: napi group #%d doesn't exist\n", __func__, group);
+		return MV_FAIL;
+	}
+
+	mv_eth_interrupts_mask(pp);
+	smp_call_function_many(cpu_online_mask, (smp_call_func_t)mv_eth_interrupts_mask, (void *)pp, 1);
+	/* remove group id from cpus that were belong to this group */
+	for_each_possible_cpu(cpu) {
+		if (pp->cpu_config[cpu]->napi_group_id == group) {
+			mvPp2GbeCpuInterruptsDisable(port, cpu);
+			pp->cpu_config[cpu]->napi_group_id = -1;
+		}
+	}
+	napi_group->cpu_mask = cpu_mask;
+	napi_group->cause_rx_tx = 0;
+
+	for_each_possible_cpu(cpu)
+		if ((1 << cpu) & cpu_mask) {
+			mvPp2GbeCpuInterruptsEnable(port, cpu);
+			pp->cpu_config[cpu]->napi_group_id = group;
+		}
+	/* mask rx interrupts for every cpu according to its napi group */
+	mv_eth_interrupts_unmask(pp);
+	smp_call_function_many(cpu_online_mask, (smp_call_func_t)mv_eth_interrupts_unmask, (void *)pp, 1);
+
+	return 0;
+}
+
+int mv_eth_napi_set_rxq_affinity(int port, int group, int rxq_mask)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct napi_group_ctrl *napi_group;
+	int i;
+
+	if (pp == NULL) {
+		printk(KERN_ERR "%s: pp is null \n", __func__);
+		return MV_FAIL;
+	}
+	if ((group < 0) || (group >= MV_ETH_MAX_NAPI_GROUPS)) {
+		printk(KERN_ERR "%s: group number is higher than %d\n", __func__, MV_ETH_MAX_NAPI_GROUPS - 1);
+		return -1;
+	}
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "%s: port %d must be stopped\n", __func__, port);
+		return -EINVAL;
+	}
+
+	/* check that rxq_mask doesn't have rxq that belong to other group */
+	for (i = 0; i < MV_ETH_MAX_NAPI_GROUPS; i++) {
+		napi_group = pp->napi_group[i];
+		if ((!napi_group) || (i == group))
+			continue;
+
+		if (napi_group->rxq_mask & rxq_mask) {
+			printk(KERN_ERR "%s: rxqs/cpus mask contains rxq that is already in other group(%d) - %d\n",
+				__func__, i, rxq_mask);
+			return MV_FAIL;
+		}
+	}
+
+	napi_group = pp->napi_group[group];
+	if (napi_group == NULL) {
+		printk(KERN_ERR "%s: napi group #%d doesn't exist\n", __func__, group);
+		return MV_FAIL;
+	}
+
+	mv_eth_interrupts_mask(pp);
+	smp_call_function_many(cpu_online_mask, (smp_call_func_t)mv_eth_interrupts_mask, (void *)pp, 1);
+
+	napi_group->rxq_mask = rxq_mask;
+	napi_group->cause_rx_tx = 0;
+
+	/* mask rx interrupts for every cpu according to its napi group */
+	mv_eth_interrupts_unmask(pp);
+	smp_call_function_many(cpu_online_mask, (smp_call_func_t)mv_eth_interrupts_unmask, (void *)pp, 1);
+
+	return 0;
+}
+
+/**********************************************************/
+
+static int mv_eth_port_config_parse(struct eth_port *pp)
+{
+	char *str;
+
+	printk(KERN_ERR "\n");
+	if (pp == NULL) {
+		printk(KERN_ERR "  o mv_eth_port_config_parse: got NULL pp\n");
+		return -1;
+	}
+
+	switch (pp->port) {
+	case 0:
+		str = port0_config_str;
+		break;
+	case 1:
+		str = port1_config_str;
+		break;
+	case 2:
+		str = port2_config_str;
+		break;
+	case 3:
+		str = port3_config_str;
+		break;
+	case 4:
+		str = port4_config_str;
+		break;
+	case 5:
+		str = port5_config_str;
+		break;
+	case 6:
+		str = port6_config_str;
+		break;
+	case 7:
+		str = port7_config_str;
+		break;
+	default:
+		printk(KERN_ERR "  o mv_eth_port_config_parse: got unknown port %d\n", pp->port);
+		return -1;
+	}
+
+	if (str != NULL) {
+		if ((!strcmp(str, "disconnected")) || (!strcmp(str, "Disconnected"))) {
+			printk(KERN_ERR "  o Port %d is disconnected from Linux netdevice\n", pp->port);
+			clear_bit(MV_ETH_F_CONNECT_LINUX_BIT, &(pp->flags));
+			return 0;
+		}
+	}
+
+	printk(KERN_ERR "  o Port %d is connected to Linux netdevice\n", pp->port);
+	set_bit(MV_ETH_F_CONNECT_LINUX_BIT, &(pp->flags));
+	return 0;
+}
+
+struct eth_port *mv_eth_port_by_id(unsigned int port)
+{
+	if (port < mv_eth_ports_num)
+		return mv_eth_ports[port];
+
+	return NULL;
+}
+
+struct net_device *mv_eth_netdev_by_id(unsigned int idx)
+{
+	if (idx < mv_net_devs_num)
+		return mv_net_devs[idx];
+
+	return NULL;
+}
+
+static inline int mv_eth_skb_mh_add(struct sk_buff *skb, u16 mh)
+{
+	/* sanity: Check that there is place for MH in the buffer */
+	if (skb_headroom(skb) < MV_ETH_MH_SIZE) {
+		printk(KERN_ERR "%s: skb (%p) doesn't have place for MH, head=%p, data=%p\n",
+		       __func__, skb, skb->head, skb->data);
+		return 1;
+	}
+
+	/* Prepare place for MH header */
+	skb->len += MV_ETH_MH_SIZE;
+	skb->data -= MV_ETH_MH_SIZE;
+	*((u16 *) skb->data) = mh;
+
+	return 0;
+}
+
+void mv_eth_ctrl_txdone(int num)
+{
+	mv_ctrl_txdone = num;
+}
+
+int mv_eth_ctrl_flag(int port, u32 flag, u32 val)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	u32 bit_flag = (fls(flag) - 1);
+
+	if (!pp)
+		return -ENODEV;
+
+	if ((flag == MV_ETH_F_MH) && (pp->flags & MV_ETH_F_SWITCH)) {
+		printk(KERN_ERR "Error: cannot change Marvell Header on a port used by the Gateway driver\n");
+		return -EPERM;
+	}
+
+	if (val)
+		set_bit(bit_flag, &(pp->flags));
+	else
+		clear_bit(bit_flag, &(pp->flags));
+
+	if (flag == MV_ETH_F_MH)
+		mvPp2MhSet(pp->port, val ? MV_PP2_MH : MV_PP2_MH_NONE);
+
+	return 0;
+}
+
+int mv_eth_ctrl_dbg_flag(int port, u32 flag, u32 val)
+{
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	u32 bit_flag = (fls(flag) - 1);
+
+	if (!pp)
+		return -ENODEV;
+
+	if (val)
+		set_bit(bit_flag, (unsigned long *)&(pp->dbg_flags));
+	else
+		clear_bit(bit_flag, (unsigned long *)&(pp->dbg_flags));
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+	return 0;
+}
+
+int mv_eth_ctrl_port_buf_num_set(int port, int long_num, int short_num)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (pp == NULL) {
+		printk(KERN_INFO "port doens not exist (%d) in %s\n" , port, __func__);
+		return -EINVAL;
+	}
+
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "Port %d must be stopped before\n", port);
+		return -EINVAL;
+	}
+	if (pp->pool_long != NULL) {
+		/* Update number of buffers in existing pool (allocate or free) */
+		if (pp->pool_long_num > long_num)
+			mv_eth_pool_free(pp->pool_long->pool, pp->pool_long_num - long_num);
+		else if (long_num > pp->pool_long_num)
+			mv_eth_pool_add(pp->pool_long->pool, long_num - pp->pool_long_num);
+	}
+	pp->pool_long_num = long_num;
+
+	if (pp->pool_short != NULL) {
+		/* Update number of buffers in existing pool (allocate or free) */
+		if (pp->pool_short_num > short_num)
+			mv_eth_pool_free(pp->pool_short->pool, pp->pool_short_num - short_num);
+		else if (short_num > pp->pool_short_num)
+			mv_eth_pool_add(pp->pool_short->pool, short_num - pp->pool_short_num);
+	}
+	pp->pool_short_num = short_num;
+
+	return 0;
+}
+
+/* Set pkt_size for the pool. Check that pool not in use (all ports are stopped) */
+/* Free all buffers from the pool */
+/* Detach the pool from all ports */
+int mv_eth_ctrl_pool_size_set(int pool, int pkt_size)
+{
+	int port;
+	struct bm_pool *ppool;
+	struct eth_port *pp;
+
+	if ((pool < 0) || (pool >= MV_ETH_BM_POOLS))
+		return -EINVAL;
+
+	ppool = &mv_eth_pool[pool];
+
+	for (port = 0; port < mv_eth_ports_num; port++) {
+		/* Check that all ports using this pool are stopped */
+		if (ppool->port_map & (1 << port)) {
+			pp = mv_eth_port_by_id(port);
+			if (pp == NULL)
+				continue;
+
+			if (pp->flags & MV_ETH_F_STARTED) {
+				printk(KERN_ERR "Port %d use pool #%d and must be stopped before change pkt_size\n",
+					port, pool);
+				return -EINVAL;
+			}
+		}
+	}
+	for (port = 0; port < mv_eth_ports_num; port++) {
+		/* Free all buffers and detach pool */
+		if (ppool->port_map & (1 << port)) {
+			pp = mv_eth_port_by_id(port);
+			if (pp == NULL)
+				continue;
+
+			if (ppool == pp->pool_long) {
+				mv_eth_pool_free(pool, pp->pool_long_num);
+				ppool->port_map &= ~(1 << pp->port);
+				pp->pool_long = NULL;
+			}
+			if (ppool == pp->pool_short) {
+				mv_eth_pool_free(pool, pp->pool_short_num);
+				ppool->port_map &= ~(1 << pp->port);
+				pp->pool_short = NULL;
+			}
+		}
+	}
+	ppool->pkt_size = pkt_size;
+
+	mv_eth_bm_config_pkt_size_set(pool, pkt_size);
+	if (pkt_size == 0)
+		mvBmPoolBufSizeSet(pool, 0);
+	else
+		mvBmPoolBufSizeSet(pool, RX_BUF_SIZE(pkt_size));
+
+	return 0;
+}
+
+int mv_eth_ctrl_set_poll_rx_weight(int port, u32 weight)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	int i;
+
+	if (pp == NULL) {
+		printk(KERN_INFO "port doens not exist (%d) in %s\n" , port, __func__);
+		return -EINVAL;
+	}
+
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "Port %d must be stopped before\n", port);
+		return -EINVAL;
+	}
+
+	if (weight > 255)
+		weight = 255;
+	pp->weight = weight;
+
+	for (i = 0; i < MV_ETH_MAX_NAPI_GROUPS; i++) {
+		if (!pp->napi_group[i])
+			continue;
+		pp->napi_group[i]->napi->weight = pp->weight;
+	}
+
+	return 0;
+}
+
+int mv_eth_ctrl_rxq_size_set(int port, int rxq, int value)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct rx_queue	*rxq_ctrl;
+
+	if (pp == NULL) {
+		printk(KERN_INFO "port doens not exist (%d) in %s\n" , port, __func__);
+		return -EINVAL;
+	}
+
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "Port %d must be stopped before\n", port);
+		return -EINVAL;
+	}
+	rxq_ctrl = &pp->rxq_ctrl[rxq];
+	if ((rxq_ctrl->q) && (rxq_ctrl->rxq_size != value)) {
+		/* Reset is required when RXQ ring size is changed */
+		mv_eth_rx_reset(pp->port);
+		mvPp2RxqDelete(pp->port, rxq);
+		rxq_ctrl->q = NULL;
+	}
+	pp->rxq_ctrl[rxq].rxq_size = value;
+
+	/* New RXQ will be created during mv_eth_start_internals */
+	return 0;
+}
+
+int mv_eth_ctrl_txq_size_set(int port, int txp, int txq, int txq_size, int hwf_size)
+{
+	int cpu, cpu_size;
+	struct tx_queue *txq_ctrl;
+	struct txq_cpu_ctrl *txq_cpu_ptr;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (pp == NULL) {
+		printk(KERN_INFO "port doens not exist (%d) in %s\n" , port, __func__);
+		return -EINVAL;
+	}
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "Port %d must be stopped before\n", port);
+		return -EINVAL;
+	}
+	if ((txq_size % 16 != 0) || (hwf_size % 16 != 0) || (txq_size < hwf_size)) {
+		printk(KERN_ERR "invalid txq size\n");
+		return -EINVAL;
+	}
+
+	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+	if ((txq_ctrl->q) && ((txq_ctrl->txq_size != txq_size) || (txq_ctrl->hwf_size != hwf_size))) {
+		mv_eth_txq_delete(pp, txq_ctrl);
+		/* Reset of port/txp is required when TXQ ring size is changed */
+		/* Reset done before as part of stop_internals function */
+	}
+
+	txq_ctrl->txq_size = txq_size;
+	txq_ctrl->hwf_size = hwf_size;
+
+	/* right now, all cpus have same size */
+	cpu_size = (txq_size - hwf_size) / MV_ETH_MAX_CPU;
+	for_each_possible_cpu(cpu) {
+		txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
+		txq_cpu_ptr->txq_size = cpu_size;
+	}
+	/* New TXQ will be created during mv_eth_start_internals */
+	return 0;
+}
+
+/* Set TXQ for CPU originated packets */
+int mv_eth_ctrl_txq_cpu_def(int port, int txp, int txq, int cpu)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if ((cpu >= CONFIG_NR_CPUS) || (cpu < 0)) {
+		printk(KERN_ERR "cpu #%d is out of range: from 0 to %d\n",
+			cpu, CONFIG_NR_CPUS - 1);
+		return -EINVAL;
+	}
+
+	if (mvPp2TxpCheck(port, txp))
+		return -EINVAL;
+
+	if ((pp == NULL) || (pp->txq_ctrl == NULL))
+		return -ENODEV;
+
+	pp->txp = txp;
+	pp->cpu_config[cpu]->txq = txq;
+
+	return 0;
+}
+
+int mv_eth_ctrl_tx_mh(int port, u16 mh)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (!pp)
+		return -ENODEV;
+
+	pp->tx_mh = mh;
+
+	return 0;
+}
+
+int mv_eth_ctrl_tx_cmd_dsa(int port, u16 dsa_tag)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (!pp)
+		return -ENODEV;
+
+	pp->hw_cmd[0] &= ~((0x3) << 14);
+	pp->hw_cmd[0] |= (dsa_tag & 0x3) << 14;
+
+	return 0;
+}
+
+int mv_eth_ctrl_tx_cmd_color(int port, u16 color)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (!pp)
+		return -ENODEV;
+
+	pp->hw_cmd[0] &= ~((0x3) << 12);
+	pp->hw_cmd[0] |= (color & 0x3) << 12;
+
+	return 0;
+}
+
+int mv_eth_ctrl_tx_cmd_gem_id(int port, u16 gem_port_id)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (!pp)
+		return -ENODEV;
+
+	pp->hw_cmd[0] &= ~(0xfff);
+	pp->hw_cmd[0] |= (gem_port_id & 0xfff);
+
+	return 0;
+}
+
+int mv_eth_ctrl_tx_cmd_pon_fec(int port, u16 pon_fec)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (!pp)
+		return -ENODEV;
+
+	pp->hw_cmd[3] &= ~((0x1) << 11);
+	pp->hw_cmd[3] |= (pon_fec & 0x1) << 11;
+
+	return 0;
+}
+
+int mv_eth_ctrl_tx_cmd_gem_oem(int port, u16 gem_oem)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (!pp)
+		return -ENODEV;
+
+	pp->hw_cmd[3] &= ~((0x1) << 9);
+	pp->hw_cmd[3] |= (gem_oem & 0x1) << 9;
+
+	return 0;
+}
+
+int mv_eth_ctrl_tx_cmd_mod(int port, u16 mod)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (!pp)
+		return -ENODEV;
+
+	pp->hw_cmd[1] = mod;
+
+	return 0;
+}
+
+int mv_eth_ctrl_tx_cmd_pme_dptr(int port, u16 pme_dptr)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (!pp)
+		return -ENODEV;
+
+	pp->hw_cmd[2] = pme_dptr;
+
+	return 0;
+}
+
+int mv_eth_ctrl_tx_cmd_pme_prog(int port, u16 pme_prog)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (!pp)
+		return -ENODEV;
+
+	pp->hw_cmd[3] &= ~(0xff);
+	pp->hw_cmd[3] |= (pme_prog & 0xff);
+
+	return 0;
+}
+
+
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+/* Register special transmit check function */
+void mv_eth_tx_special_check_func(int port,
+					int (*func)(int port, struct net_device *dev, struct sk_buff *skb,
+								struct mv_eth_tx_spec *tx_spec_out))
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (pp)
+		pp->tx_special_check = func;
+}
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+
+#ifdef CONFIG_MV_ETH_RX_SPECIAL
+/* Register special transmit check function */
+void mv_eth_rx_special_proc_func(int port, void (*func)(int port, int rxq, struct net_device *dev,
+							struct sk_buff *skb, struct pp2_rx_desc *rx_desc))
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (pp)
+		pp->rx_special_proc = func;
+}
+#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+
+static inline u16 mv_eth_select_txq(struct net_device *dev,
+									struct sk_buff *skb)
+{
+	struct eth_port *pp = MV_ETH_PRIV(dev);
+	return mv_eth_tx_policy(pp, skb);
+}
+
+static inline void mv_eth_change_rx_flags(struct net_device *dev, int flags)
+{
+	printk(KERN_ERR "%s: function %s imlemantation is not ready\n", dev->name, __func__);
+}
+
+static inline void mv_eth_set_rx_mode(struct net_device *dev)
+{
+	printk(KERN_ERR "%s: function %s imlemantation is not ready\n", dev->name, __func__);
+}
+
+
+static const struct net_device_ops mv_eth_netdev_ops = {
+	.ndo_open = mv_eth_open,
+	.ndo_stop = mv_eth_stop,
+	.ndo_start_xmit = mv_eth_tx,
+/*TODO - this is a hack by Seif M. need to fix this to properly move to linux 3.2!!!
+.ndo_set_multicast_list = mv_eth_set_multicast_list,
+*/
+	.ndo_change_rx_flags = mv_eth_set_multicast_list,
+	.ndo_set_mac_address = mv_eth_set_mac_addr,
+	.ndo_change_mtu = mv_eth_change_mtu,
+	.ndo_tx_timeout = mv_eth_tx_timeout,
+	.ndo_select_queue = mv_eth_select_txq,
+/*
+.ndo_change_rx_flags = mv_eth_change_rx_flags,
+.ndo_set_rx_mode = mv_eth_set_rx_mode,
+*/
+};
+
+#ifdef CONFIG_MV_ETH_SWITCH
+static const struct net_device_ops mv_switch_netdev_ops = {
+	.ndo_open = mv_eth_switch_start,
+	.ndo_stop = mv_eth_switch_stop,
+	.ndo_start_xmit = mv_eth_tx,
+	.ndo_set_multicast_list = mv_eth_switch_set_multicast_list,
+	.ndo_set_mac_address = mv_eth_switch_set_mac_addr,
+	.ndo_change_mtu = mv_eth_switch_change_mtu,
+	.ndo_tx_timeout = mv_eth_tx_timeout,
+	.ndo_change_rx_flags = mv_eth_change_rx_flags,
+	.ndo_set_rx_mode = mv_eth_set_rx_mode,
+};
+
+int mv_eth_switch_netdev_first = 0;
+int mv_eth_switch_netdev_last = 0;
+
+static inline struct net_device *mv_eth_switch_netdev_get(struct eth_port *pp, struct eth_pbuf *pkt)
+{
+	MV_U8 *data;
+	int db_num;
+
+	if (pp->flags & MV_ETH_F_SWITCH) {
+		data = pkt->pBuf + pkt->offset;
+
+		/* bits[4-7] of MSB in Marvell header */
+		db_num = ((*data) >> 4);
+
+		return mv_net_devs[mv_eth_switch_netdev_first + db_num];
+	}
+	return pp->dev;
+}
+
+
+void mv_eth_switch_priv_update(struct net_device *netdev, int i)
+{
+	struct eth_netdev *dev_priv;
+	struct eth_port *pp = MV_ETH_PRIV(netdev);
+	int print_flag, port, switch_port;
+
+	/* Update dev_priv structure */
+	dev_priv = MV_DEV_PRIV(netdev);
+	dev_priv->port_map = 0;
+	dev_priv->link_map = 0;
+
+	print_flag = 1;
+	for (port = 0; port < BOARD_ETH_SWITCH_PORT_NUM; port++) {
+		if (switch_net_config[pp->port].board_port_map[i] & (1 << port)) {
+			if (print_flag) {
+				printk(KERN_CONT ". Interface ports: ");
+				print_flag = 0;
+			}
+			printk(KERN_CONT "%d ", port);
+			switch_port = mvBoardSwitchPortGet(MV_SWITCH_ID_0, port);
+			if (switch_port >= 0) {
+				dev_priv->port_map |= (1 << switch_port);
+				switch_enabled_ports |= (1 << switch_port);
+			}
+		}
+	}
+	printk(KERN_CONT "\n");
+	dev_priv->group = i;
+	dev_priv->vlan_grp_id = MV_SWITCH_GROUP_VLAN_ID(i);	/* e.g. 0x100, 0x200... */
+	dev_priv->tx_vlan_mh = cpu_to_be16((i << 12) | dev_priv->port_map);
+	dev_priv->cpu_port = mvBoardSwitchCpuPortGet(MV_SWITCH_ID_0);
+
+	mv_eth_switch_vlan_set(dev_priv->vlan_grp_id, dev_priv->port_map, dev_priv->cpu_port);
+}
+
+
+int mv_eth_switch_netdev_init(struct eth_port *pp, int dev_i,
+				struct platform_device *pdev)
+{
+	int i;
+	struct net_device *netdev;
+
+	switch_enabled_ports = 0;
+
+	for (i = 0; i < switch_net_config[pp->port].netdev_max; i++) {
+		netdev = mv_eth_netdev_init(pp, switch_net_config[pp->port].mtu, switch_net_config[pp->port].mac_addr[i],
+						pdev);
+		if (netdev == NULL) {
+			printk(KERN_ERR "mv_eth_switch_netdev_init: can't create netdevice\n");
+			break;
+		}
+		mv_net_devs[dev_i++] = netdev;
+
+		mv_eth_switch_priv_update(netdev, i);
+
+	}
+	return dev_i;
+}
+
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+void mv_eth_link_status_print(int port)
+{
+	MV_ETH_PORT_STATUS link;
+
+	mvEthLinkStatus(port, &link);
+#ifdef CONFIG_MV_PON
+	if (MV_PON_PORT(port))
+		link.linkup = mv_pon_link_status();
+#endif /* CONFIG_MV_PON */
+
+	if (link.linkup) {
+		printk(KERN_CONT "link up");
+		printk(KERN_CONT ", %s duplex", (link.duplex == MV_ETH_DUPLEX_FULL) ? "full" : "half");
+		printk(KERN_CONT ", speed ");
+
+		if (link.speed == MV_ETH_SPEED_1000)
+			printk(KERN_CONT "1 Gbps\n");
+		else if (link.speed == MV_ETH_SPEED_100)
+			printk(KERN_CONT "100 Mbps\n");
+		else
+			printk(KERN_CONT "10 Mbps\n");
+	} else
+		printk(KERN_CONT "link down\n");
+
+}
+
+static void mv_eth_rx_error(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
+{
+	STAT_ERR(pp->stats.rx_error++);
+
+	if (pp->dev)
+		pp->dev->stats.rx_errors++;
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if ((pp->dbg_flags & MV_ETH_F_DBG_RX) == 0)
+		return;
+
+	if (!printk_ratelimit())
+		return;
+
+	switch (rx_desc->status & PP2_RX_ERR_CODE_MASK) {
+	case PP2_RX_ERR_CRC:
+		printk(KERN_ERR "giga #%d: bad rx status %08x (crc error), size=%d\n",
+				pp->port, rx_desc->status, rx_desc->dataSize);
+		break;
+	case PP2_RX_ERR_OVERRUN:
+		printk(KERN_ERR "giga #%d: bad rx status %08x (overrun error), size=%d\n",
+				pp->port, rx_desc->status, rx_desc->dataSize);
+		break;
+	/*case NETA_RX_ERR_LEN:*/
+	case PP2_RX_ERR_RESOURCE:
+		printk(KERN_ERR "giga #%d: bad rx status %08x (resource error), size=%d\n",
+				pp->port, rx_desc->status, rx_desc->dataSize);
+		break;
+	}
+	mv_eth_rx_desc_print(rx_desc);
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+}
+
+void mv_eth_skb_print(struct sk_buff *skb)
+{
+	printk(KERN_ERR "skb=%p: head=%p, data=%p, tail=%p, end=%p\n", skb, skb->head, skb->data, skb->tail, skb->end);
+	printk(KERN_ERR "\t mac=%p, network=%p, transport=%p\n",
+			skb->mac_header, skb->network_header, skb->transport_header);
+	printk(KERN_ERR "\t truesize=%d, len=%d, data_len=%d, mac_len=%d\n",
+		skb->truesize, skb->len, skb->data_len, skb->mac_len);
+	printk(KERN_ERR "\t users=%d, dataref=%d, nr_frags=%d, gso_size=%d, gso_segs=%d\n",
+	       atomic_read(&skb->users), atomic_read(&skb_shinfo(skb)->dataref),
+	       skb_shinfo(skb)->nr_frags, skb_shinfo(skb)->gso_size, skb_shinfo(skb)->gso_segs);
+	printk(KERN_ERR "\t proto=%d, ip_summed=%d, priority=%d\n", ntohs(skb->protocol), skb->ip_summed, skb->priority);
+#ifdef CONFIG_NET_SKB_RECYCLE
+	printk(KERN_ERR "\t skb_recycle=%p, hw_cookie=%p\n", skb->skb_recycle, skb->hw_cookie);
+#endif /* CONFIG_NET_SKB_RECYCLE */
+}
+
+void mv_eth_rx_desc_print(struct pp2_rx_desc *desc)
+{
+	int i;
+	u32 *words = (u32 *) desc;
+
+	printk(KERN_ERR "RX desc - %p: ", desc);
+	for (i = 0; i < 8; i++)
+		printk(KERN_CONT "%8.8x ", *words++);
+	printk(KERN_CONT "\n");
+
+	printk(KERN_CONT "pkt_size=%d, L3_offs=%d, IP_hlen=%d, L3=",
+	       desc->dataSize,
+	       (desc->status & PP2_RX_L3_OFFSET_MASK) >> PP2_RX_L3_OFFSET_OFFS,
+	       (desc->status & PP2_RX_IP_HLEN_MASK) >> PP2_RX_IP_HLEN_OFFS);
+
+	if (PP2_RX_L3_IS_IP4(desc->status))
+		printk(KERN_CONT "IPv4 (hdr=%s), ", PP2_RX_IP4_HDR_ERR(desc->status) ? "bad" : "ok");
+	else if (PP2_RX_L3_IS_IP4_OPT(desc->status))
+		printk(KERN_CONT "IPv4 Options (hdr=%s), ", PP2_RX_IP4_HDR_ERR(desc->status) ? "bad" : "ok");
+	else if (PP2_RX_L3_IS_IP4_OTHER(desc->status))
+		printk(KERN_CONT "IPv4 Other (hdr=%s), ", PP2_RX_IP4_HDR_ERR(desc->status) ? "bad" : "ok");
+	else if (PP2_RX_L3_IS_IP6(desc->status))
+		printk(KERN_CONT "IPv6, ");
+	else if (PP2_RX_L3_IS_IP6_EXT(desc->status))
+		printk(KERN_CONT "IPv6 Ext, ");
+	else
+		printk(KERN_CONT "Unknown, ");
+
+	if (desc->status & PP2_RX_IP_FRAG_MASK)
+		printk(KERN_CONT "Frag, ");
+
+	printk(KERN_CONT "L4=");
+	if (PP2_RX_L4_IS_TCP(desc->status))
+		printk(KERN_CONT "TCP (csum=%s)", (desc->status & PP2_RX_L4_CHK_OK_MASK) ? "Ok" : "Bad");
+	else if (PP2_RX_L4_IS_UDP(desc->status))
+		printk(KERN_CONT "UDP (csum=%s)", (desc->status & PP2_RX_L4_CHK_OK_MASK) ? "Ok" : "Bad");
+	else
+		printk(KERN_CONT "Unknown");
+
+	printk(KERN_CONT "\n");
+
+	printk(KERN_INFO "Lookup_ID=0x%X\n", desc->parserInfo & PP2_RX_LKP_ID_MASK);
+}
+EXPORT_SYMBOL(mv_eth_rx_desc_print);
+
+void mv_eth_tx_desc_print(struct pp2_tx_desc *desc)
+{
+	int i;
+	u32 *words = (u32 *) desc;
+
+	printk(KERN_ERR "TX desc - %p: ", desc);
+	for (i = 0; i < 8; i++)
+		printk(KERN_CONT "%8.8x ", *words++);
+	printk(KERN_CONT "\n");
+}
+EXPORT_SYMBOL(mv_eth_tx_desc_print);
+
+void mv_eth_pkt_print(struct eth_pbuf *pkt)
+{
+	printk(KERN_ERR "pkt: len=%d off=%d pool=%d "
+	       "skb=%p pa=%lx buf=%p\n",
+	       pkt->bytes, pkt->offset, pkt->pool,
+	       pkt->osInfo, pkt->physAddr, pkt->pBuf);
+
+	mvDebugMemDump(pkt->pBuf + pkt->offset, 64, 1);
+	mvOsCacheInvalidate(NULL, pkt->pBuf + pkt->offset, 64);
+}
+EXPORT_SYMBOL(mv_eth_pkt_print);
+
+static inline void mv_eth_rx_csum(struct eth_port *pp, struct pp2_rx_desc *rx_desc, struct sk_buff *skb)
+{
+#if defined(CONFIG_MV_ETH_RX_CSUM_OFFLOAD)
+	if (pp->rx_csum_offload) {
+		if ((PP2_RX_L3_IS_IP4(rx_desc->status) && !PP2_RX_IP4_HDR_ERR(rx_desc->status)) ||
+			(PP2_RX_L3_IS_IP6(rx_desc->status))) {
+			if ((PP2_RX_L4_IS_UDP(rx_desc->status) || PP2_RX_L4_IS_TCP(rx_desc->status)) &&
+				(PP2_RX_L4_CHK_OK(rx_desc->status))) {
+				skb->csum = 0;
+				skb->ip_summed = CHECKSUM_UNNECESSARY;
+				STAT_DBG(pp->stats.rx_csum_hw++);
+				return;
+			}
+		}
+	}
+#endif /* CONFIG_MV_ETH_RX_CSUM_OFFLOAD */
+
+	skb->ip_summed = CHECKSUM_NONE;
+	STAT_DBG(pp->stats.rx_csum_sw++);
+}
+
+static inline int mv_eth_tx_done_policy(u32 cause)
+{
+	return fls(cause) - 1;
+}
+
+inline int mv_eth_rx_policy(u32 cause)
+{
+	return fls(cause) - 1;
+}
+
+static inline int mv_eth_txq_dscp_map_get(struct eth_port *pp, MV_U8 dscp)
+{
+	MV_U8 q = pp->txq_dscp_map[dscp];
+
+	if (q == MV_ETH_TXQ_INVALID)
+		return pp->cpu_config[smp_processor_id()]->txq;
+
+	return q;
+}
+
+static inline int mv_eth_tx_policy(struct eth_port *pp, struct sk_buff *skb)
+{
+	int txq = pp->cpu_config[smp_processor_id()]->txq;
+
+	if (skb->protocol == htons(ETH_P_IP)) {
+		struct iphdr *iph = ip_hdr(skb);
+
+		txq = mv_eth_txq_dscp_map_get(pp, TOS_TO_DSCP(iph->tos));
+	}
+	return txq;
+}
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+int mv_eth_skb_recycle(struct sk_buff *skb)
+{
+	struct eth_pbuf *pkt = skb->hw_cookie;
+	struct bm_pool *pool = &mv_eth_pool[pkt->pool];
+	int status = 0;
+
+	if (skb_recycle_check(skb, pool->pkt_size)) {
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+		/* Sanity check */
+		/*if (skb->truesize != ((skb->end - skb->head) + sizeof(struct sk_buff)))
+			mv_eth_skb_print(skb);*/
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+		STAT_DBG(pool->stats.skb_recycled_ok++);
+		mvOsCacheInvalidate(NULL, skb->head, RX_BUF_SIZE(pool->pkt_size));
+
+		status = mv_eth_pool_put(pool, pkt);
+
+		return 0;
+	}
+
+	/* printk(KERN_ERR "mv_eth_skb_recycle failed: pool=%d, pkt=%p, skb=%p\n", pkt->pool, pkt, skb); */
+
+	mvOsFree(pkt);
+	skb->hw_cookie = NULL;
+
+	STAT_DBG(pool->stats.skb_recycled_err++);
+
+	return 1;
+}
+EXPORT_SYMBOL(mv_eth_skb_recycle);
+
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+static struct sk_buff *mv_eth_skb_alloc(struct bm_pool *pool, struct eth_pbuf *pkt)
+{
+	struct sk_buff *skb;
+
+	skb = dev_alloc_skb(pool->pkt_size);
+	if (!skb) {
+		STAT_ERR(pool->stats.skb_alloc_oom++);
+		return NULL;
+	}
+	STAT_DBG(pool->stats.skb_alloc_ok++);
+
+	pkt->osInfo = (void *)skb;
+	pkt->pBuf = skb->head;
+	pkt->physAddr = mvOsCacheInvalidate(NULL, skb->head, RX_BUF_SIZE(pool->pkt_size));
+	pkt->offset = NET_SKB_PAD;
+	pkt->pool = pool->pool;
+
+	return skb;
+}
+
+static unsigned char *mv_eth_hwf_buff_alloc(struct bm_pool *pool, struct eth_pbuf *pkt)
+{
+	unsigned char *buff;
+
+	buff = mvOsMalloc(RX_HWF_BUF_SIZE(pool->pkt_size));
+	if (!buff)
+		return NULL;
+
+	pkt->osInfo = NULL;
+	pkt->pBuf = buff;
+	pkt->physAddr = mvOsCacheInvalidate(NULL, buff, RX_HWF_BUF_SIZE(pool->pkt_size));
+	pkt->offset = RX_HWF_PKT_OFFS;
+	pkt->pool = pool->pool;
+
+	return buff;
+}
+
+static inline void mv_eth_txq_bufs_free(struct eth_port *pp, struct txq_cpu_ctrl *txq_cpu, int num)
+{
+	u32 shadow;
+	int i;
+
+	/* Free buffers that was not freed automatically by BM */
+	for (i = 0; i < num; i++) {
+		shadow = mv_eth_shadow_get_pop(txq_cpu);
+
+		if (!shadow)
+			continue;
+
+		if (shadow & MV_ETH_SHADOW_SKB) {
+			shadow &= ~MV_ETH_SHADOW_SKB;
+			dev_kfree_skb_any((struct sk_buff *)shadow);
+			STAT_DBG(pp->stats.tx_skb_free++);
+		} else if (shadow & MV_ETH_SHADOW_EXT) {
+			shadow &= ~MV_ETH_SHADOW_EXT;
+			mv_eth_extra_pool_put(pp, (void *)shadow);
+		} else {
+			/* TBD - if NFP is supported then pass packet back to BM */
+			printk(KERN_ERR "%s: unexpected buffer - not skb and not ext\n", __func__);
+		}
+	}
+}
+
+inline u32 mv_eth_txq_done(struct eth_port *pp, struct tx_queue *txq_ctrl)
+{
+	int tx_done;
+	struct txq_cpu_ctrl *txq_cpu_ptr = &txq_ctrl->txq_cpu[smp_processor_id()];
+
+	/* get number of transmitted TX descriptors by this CPU */
+	tx_done = mvPp2TxqSentDescProc(pp->port, txq_ctrl->txp, txq_ctrl->txq);
+	if (!tx_done)
+		return tx_done;
+/*
+	printk(KERN_ERR "tx_done: txq_count=%d, port=%d, txp=%d, txq=%d, tx_done=%d\n",
+			txq_ctrl->txq_count, pp->port, txq_ctrl->txp, txq_ctrl->txq, tx_done);
+*/
+	mv_eth_txq_bufs_free(pp, txq_cpu_ptr, tx_done);
+
+	txq_cpu_ptr->txq_count -= tx_done;
+	STAT_DBG(txq_ctrl->stats.txq_txdone += tx_done);
+
+	return tx_done;
+}
+EXPORT_SYMBOL(mv_eth_txq_done);
+
+static int mv_eth_attach_long_pool(struct eth_port *pp, struct bm_pool *new_pool, int pkts_num, int pkt_size)
+{
+	struct bm_pool **port_long_pool;
+	int num, buffer_size, is_hwf = new_pool->is_hwf;
+
+	buffer_size = (is_hwf) ? RX_HWF_BUF_SIZE(pkt_size) : RX_BUF_SIZE(pkt_size);
+#ifdef CONFIG_MV_ETH_HWF
+	port_long_pool = (is_hwf) ? &pp->hwf_pool_long : &pp->pool_long;
+#else
+	port_long_pool = &pp->pool_long;
+#endif /* CONFIG_MV_ETH_HWF */
+
+	if (new_pool->pkt_size == 0) {
+		new_pool->pkt_size = pkt_size;
+		mvPp2BmPoolBufSizeSet(new_pool->pool, buffer_size);
+	}
+	if (new_pool->pkt_size < pkt_size) {
+		printk(KERN_ERR "%s FAILED: port=%d, long pool #%d, pkt_size=%d less than required %d\n",
+				__func__, pp->port, new_pool->pool, new_pool->pkt_size, pkt_size);
+		return 1;
+	}
+
+	*port_long_pool = new_pool;
+	new_pool->port_map |= (1 << pp->port);
+
+	num = mv_eth_pool_add(new_pool->pool, pkts_num);
+	if (num != pkts_num) {
+		printk(KERN_ERR "%s FAILED: pool=%d, pkt_size=%d, only %d of %d allocated\n",
+		       __func__, new_pool->pool, new_pool->pkt_size, num, pkts_num);
+		return 1;
+	}
+
+	return 0;
+}
+
+inline struct eth_pbuf *mv_eth_pool_get(struct bm_pool *pool)
+{
+	struct eth_pbuf *pkt = NULL;
+	struct sk_buff *skb;
+	unsigned long flags = 0;
+
+	MV_ETH_LOCK(&pool->lock, flags);
+
+	if (mvStackIndex(pool->stack) > 0) {
+		STAT_DBG(pool->stats.stack_get++);
+		pkt = (struct eth_pbuf *)mvStackPop(pool->stack);
+	} else
+		STAT_ERR(pool->stats.stack_empty++);
+
+	MV_ETH_UNLOCK(&pool->lock, flags);
+	if (pkt)
+		return pkt;
+
+	/* Try to allocate new pkt + skb */
+	pkt = mvOsMalloc(sizeof(struct eth_pbuf));
+	if (pkt) {
+		skb = mv_eth_skb_alloc(pool, pkt);
+		if (!skb) {
+			mvOsFree(pkt);
+			pkt = NULL;
+		}
+	}
+	return pkt;
+}
+
+/* Reuse pkt if possible, allocate new skb and move BM pool or RXQ ring */
+inline int mv_eth_refill(struct eth_port *pp, int rxq,
+				struct eth_pbuf *pkt, struct bm_pool *pool, struct pp2_rx_desc *rx_desc)
+{
+	if (pkt == NULL) {
+		pkt = mv_eth_pool_get(pool);
+		if (pkt == NULL)
+			return 1;
+	} else {
+		struct sk_buff *skb;
+
+		/* No recycle -  alloc new skb */
+		skb = mv_eth_skb_alloc(pool, pkt);
+		if (!skb) {
+			mvOsFree(pkt);
+			pool->missed++;
+			mv_eth_add_cleanup_timer(pp->cpu_config[smp_processor_id()]);
+			return 1;
+		}
+	}
+	mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+
+	return 0;
+}
+EXPORT_SYMBOL(mv_eth_refill);
+
+static inline MV_U32 mv_eth_skb_tx_csum(struct eth_port *pp, struct sk_buff *skb)
+{
+#ifdef CONFIG_MV_ETH_TX_CSUM_OFFLOAD
+	if (skb->ip_summed == CHECKSUM_PARTIAL) {
+		int   ip_hdr_len = 0;
+		MV_U8 l4_proto;
+
+		if (skb->protocol == htons(ETH_P_IP)) {
+			struct iphdr *ip4h = ip_hdr(skb);
+
+			/* Calculate IPv4 checksum and L4 checksum */
+			ip_hdr_len = ip4h->ihl;
+			l4_proto = ip4h->protocol;
+		} else if (skb->protocol == htons(ETH_P_IPV6)) {
+			/* If not IPv4 - must be ETH_P_IPV6 - Calculate only L4 checksum */
+			struct ipv6hdr *ip6h = ipv6_hdr(skb);
+
+			/* Read l4_protocol from one of IPv6 extra headers ?????? */
+			if (skb_network_header_len(skb) > 0)
+				ip_hdr_len = (skb_network_header_len(skb) >> 2);
+			l4_proto = ip6h->nexthdr;
+		} else {
+			STAT_DBG(pp->stats.tx_csum_sw++);
+			return PP2_TX_L4_CSUM_NOT;
+		}
+		STAT_DBG(pp->stats.tx_csum_hw++);
+
+		return mvPp2TxqDescCsum(skb_network_offset(skb), skb->protocol, ip_hdr_len, l4_proto);
+	}
+#endif /* CONFIG_MV_ETH_TX_CSUM_OFFLOAD */
+
+	STAT_DBG(pp->stats.tx_csum_sw++);
+	return PP2_TX_L4_CSUM_NOT | PP2_TX_IP_CSUM_DISABLE_MASK;
+}
+
+#ifdef CONFIG_MV_ETH_RX_DESC_PREFETCH
+inline struct pp2_rx_desc *mv_eth_rx_prefetch(struct eth_port *pp, MV_PP2_PHYS_RXQ_CTRL *rx_ctrl,
+									  int rx_done, int rx_todo)
+{
+	struct pp2_rx_desc	*rx_desc, *next_desc;
+
+	rx_desc = mvPp2RxqNextDescGet(rx_ctrl);
+	if (rx_done == 0) {
+		/* First descriptor in the NAPI loop */
+		mvOsCacheLineInv(NULL, rx_desc);
+		prefetch(rx_desc);
+	}
+	if ((rx_done + 1) == rx_todo) {
+		/* Last descriptor in the NAPI loop - prefetch are not needed */
+		return rx_desc;
+	}
+	/* Prefetch next descriptor */
+	next_desc = mvPp2RxqDescGet(rx_ctrl);
+	mvOsCacheLineInv(NULL, next_desc);
+	prefetch(next_desc);
+
+	return rx_desc;
+}
+#endif /* CONFIG_MV_ETH_RX_DESC_PREFETCH */
+
+#define GET_BUFF_FROM_PKT(pkt) 	((MV_U32)((struct eth_pbuf *)pkt)->pBuf)
+static inline void mv_eth_buff_hdr_rx(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
+{
+	u32 rx_status = rx_desc->status;
+	int mc_id, count = 0, pool_id, is_hwf;
+	PP2_BUFF_HDR *buff_hdr;
+	MV_U32 buff_phys_addr, buff_virt_addr;
+
+	pool_id = (rx_status & PP2_RX_BM_POOL_ALL_MASK) >> PP2_RX_BM_POOL_ID_OFFS;
+	buff_phys_addr = rx_desc->bufPhysAddr;
+	/* for SWF we need pkt structure. for HWF we just need the buffer virt address */
+	buff_virt_addr = GET_BUFF_FROM_PKT(rx_desc->bufCookie);
+
+	do {
+		buff_hdr = (PP2_BUFF_HDR *)buff_virt_addr;
+		mc_id = PP2_BUFF_HDR_INFO_MC_ID(buff_hdr->info);
+
+		if (pp->dbg_flags & MV_ETH_F_DBG_RX) {
+			printk(KERN_ERR "buff header #%d:\n", ++count);
+			mvDebugMemDump(buff_hdr, 32, 1);
+
+			printk(KERN_ERR "byte count = %d   MC ID = %d   last = %d\n",
+				buff_hdr->byteCount, mc_id,
+				PP2_BUFF_HDR_INFO_IS_LAST(buff_hdr->info));
+		}
+
+		/* release buffer */
+		mvBmPoolMcPut(pool_id, buff_phys_addr, buff_virt_addr, mc_id, 0);
+
+		buff_phys_addr = buff_hdr->nextBuffPhysAddr;
+		buff_virt_addr = GET_BUFF_FROM_PKT(buff_hdr->nextBuffVirtAddr);
+	} while (!PP2_BUFF_HDR_INFO_IS_LAST(buff_hdr->info));
+
+	pp->stats.rx_drop_sw++;
+}
+
+static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq)
+{
+	struct net_device *dev;
+	MV_PP2_PHYS_RXQ_CTRL *rx_ctrl = pp->rxq_ctrl[rxq].q;
+	int rx_done, rx_filled, err;
+	struct pp2_rx_desc *rx_desc;
+	u32 rx_status;
+	int rx_bytes;
+	struct eth_pbuf *pkt;
+	struct sk_buff *skb;
+	struct bm_pool *pool;
+
+	/* Get number of received packets */
+	rx_done = mvPp2RxqBusyDescNumGet(pp->port, rxq);
+	mvOsCacheIoSync();
+
+	if ((rx_todo > rx_done) || (rx_todo < 0))
+		rx_todo = rx_done;
+
+	if (rx_todo == 0)
+		return 0;
+
+	rx_done = 0;
+	rx_filled = 0;
+
+	/* Fairness NAPI loop */
+	while (rx_done < rx_todo) {
+
+#ifdef CONFIG_MV_ETH_RX_DESC_PREFETCH
+		rx_desc = mv_eth_rx_prefetch(pp, rx_ctrl, rx_done, rx_todo);
+#else
+		rx_desc = mvPp2RxqNextDescGet(rx_ctrl);
+		mvOsCacheLineInv(NULL, rx_desc);
+		prefetch(rx_desc);
+#endif /* CONFIG_MV_ETH_RX_DESC_PREFETCH */
+
+		rx_done++;
+		rx_filled++;
+
+#if defined(MV_CPU_BE)
+	/*	mvNetaRxqDescSwap(rx_desc);*/
+#endif /* MV_CPU_BE */
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+		if (pp->dbg_flags & MV_ETH_F_DBG_RX) {
+			printk(KERN_ERR "\n%s: port=%d, cpu=%d\n", __func__, pp->port, smp_processor_id());
+			mv_eth_rx_desc_print(rx_desc);
+		}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+		rx_status = rx_desc->status;
+		/* check if buffer header is used */
+		if (rx_status & PP2_RX_BUF_HDR_MASK) {
+			mv_eth_buff_hdr_rx(pp, rx_desc);
+			continue;
+		}
+
+		pkt = (struct eth_pbuf *)rx_desc->bufCookie;
+		pool = &mv_eth_pool[pkt->pool];
+
+
+		if (rx_status & PP2_RX_ES_MASK) {
+
+			mv_eth_rx_error(pp, rx_desc);
+
+			mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+			continue;
+		}
+
+		/* Speculative ICache prefetch WA: should be replaced with dma_unmap_single (invalidate l2) */
+		mvOsCacheMultiLineInv(NULL, pkt->pBuf + pkt->offset, rx_desc->dataSize);
+
+#ifdef CONFIG_MV_ETH_SWITCH
+		dev = mv_eth_switch_netdev_get(pp, pkt);
+#else
+		dev = pp->dev;
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+		STAT_DBG(pp->stats.rxq[rxq]++);
+		dev->stats.rx_packets++;
+
+		rx_bytes = rx_desc->dataSize - MV_ETH_MH_SIZE;
+		dev->stats.rx_bytes += rx_bytes;
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+		if (pp->dbg_flags & MV_ETH_F_DBG_RX) {
+			printk(KERN_ERR "pkt=%p, pBuf=%p, ksize=%d\n", pkt, pkt->pBuf, ksize(pkt->pBuf));
+			mvDebugMemDump(pkt->pBuf + pkt->offset, 64, 1);
+		}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+#if defined(CONFIG_MV_ETH_RX_SPECIAL)
+		/* Special RX processing */
+		if (PP2_RX_IS_RX_SPECIAL(rx_desc->parserInfo)) {
+			if (pp->rx_special_proc) {
+				pp->rx_special_proc(pp->port, rxq, dev, (struct sk_buff *)(pkt->osInfo), rx_desc);
+				STAT_INFO(pp->stats.rx_special++);
+
+				/* Refill processing */
+				err = mv_eth_refill(pp, rxq, pkt, pool, rx_desc);
+				if (err) {
+					printk(KERN_ERR "Linux processing - Can't refill\n");
+					pp->rxq_ctrl[rxq].missed++;
+					rx_filled--;
+				}
+				continue;
+			}
+		}
+#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+
+		/* Linux processing */
+		skb = (struct sk_buff *)(pkt->osInfo);
+
+		skb->data += MV_ETH_MH_SIZE;
+		skb->tail += (rx_bytes + MV_ETH_MH_SIZE);
+		skb->len = rx_bytes;
+
+		skb->protocol = eth_type_trans(skb, dev);
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+		if (mv_eth_is_recycle()) {
+			skb->skb_recycle = mv_eth_skb_recycle;
+			skb->hw_cookie = pkt;
+			pkt = NULL;
+		}
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+		if (skb)
+			mv_eth_rx_csum(pp, rx_desc, skb);
+
+		if (skb) {
+			STAT_DBG(pp->stats.rx_netif++);
+			rx_status = netif_receive_skb(skb);
+			STAT_DBG((rx_status == 0) ? pp->stats.rx_drop_sw += 0 : pp->stats.rx_drop_sw++);
+		}
+
+		/* Refill processing: */
+		err = mv_eth_refill(pp, rxq, pkt, pool, rx_desc);
+		if (err) {
+			printk(KERN_ERR "Linux processing - Can't refill\n");
+			pp->rxq_ctrl[rxq].missed++;
+			mv_eth_add_cleanup_timer(pp->cpu_config[smp_processor_id()]);
+			rx_filled--;
+		}
+	}
+
+	/* Update RxQ management counters */
+	mvOsCacheIoSync();
+	mvPp2RxqDescNumUpdate(pp->port, rxq, rx_done, rx_filled);
+
+	return rx_done;
+}
+
+static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
+{
+	struct eth_port *pp = MV_ETH_PRIV(dev);
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+	int frags = 0, cpu = smp_processor_id();
+	bool tx_spec_ready = false;
+	struct mv_eth_tx_spec tx_spec;
+	u32 tx_cmd;
+	u16 mh;
+	struct tx_queue *txq_ctrl = NULL;
+	struct txq_cpu_ctrl *txq_cpu_ptr = NULL;
+	struct aggr_tx_queue *aggr_txq_ctrl = NULL;
+	struct pp2_tx_desc *tx_desc;
+
+	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
+		STAT_INFO(pp->stats.netdev_stop++);
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+		if (pp->dbg_flags & MV_ETH_F_DBG_TX)
+			printk(KERN_ERR "%s: STARTED_BIT = 0, packet is dropped.\n", __func__);
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+		goto out;
+	}
+
+	if (!(netif_running(dev))) {
+		printk(KERN_ERR "!netif_running() in %s\n", __func__);
+		goto out;
+	}
+
+#if defined(CONFIG_MV_ETH_TX_SPECIAL)
+	if (pp->tx_special_check) {
+
+		if (pp->tx_special_check(pp->port, dev, skb, &tx_spec)) {
+			STAT_INFO(pp->stats.tx_special++);
+			if (tx_spec.tx_func) {
+				tx_spec.tx_func(skb->data, skb->len, &tx_spec);
+				goto out;
+			} else {
+				/* Check validity of tx_spec txp/txq must be CPU owned */
+				tx_spec_ready = true;
+			}
+		}
+	}
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+	/* Get TXQ (without BM) to send packet generated by Linux */
+	if (tx_spec_ready == false) {
+		tx_spec.txp = pp->txp;
+		tx_spec.txq = mv_eth_tx_policy(pp, skb);
+		tx_spec.hw_cmd[0] = pp->hw_cmd[0];
+		tx_spec.hw_cmd[1] = pp->hw_cmd[1];
+		tx_spec.hw_cmd[2] = pp->hw_cmd[2];
+		tx_spec.hw_cmd[3] = pp->hw_cmd[3];
+		tx_spec.flags = pp->flags;
+	}
+
+	aggr_txq_ctrl = &aggr_txqs[smp_processor_id()];
+	txq_ctrl = &pp->txq_ctrl[tx_spec.txp * CONFIG_MV_ETH_TXQ + tx_spec.txq];
+	if (txq_ctrl == NULL) {
+		printk(KERN_ERR "%s: invalidate txp/txq (%d/%d)\n", __func__, tx_spec.txp, tx_spec.txq);
+		goto out;
+	}
+	txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
+
+#ifdef CONFIG_MV_ETH_TSO
+	/* GSO/TSO */
+	if (skb_is_gso(skb)) {
+		frags = mv_eth_tx_tso(skb, dev, &tx_spec, txq_cpu_ptr, aggr_txq_ctrl);
+		goto out;
+	}
+#endif /* CONFIG_MV_ETH_TSO */
+
+	frags = skb_shinfo(skb)->nr_frags + 1;
+
+	if (tx_spec.flags & MV_ETH_F_MH) {
+		if (tx_spec.flags & MV_ETH_F_SWITCH)
+			mh = dev_priv->tx_vlan_mh;
+		else
+			mh = pp->tx_mh;
+
+		if (mv_eth_skb_mh_add(skb, mh)) {
+			frags = 0;
+			goto out;
+		}
+	}
+	/* is enough descriptors? */
+	if ((!mv_eth_phys_desc_num_check(txq_cpu_ptr, frags)) ||
+		(!mv_eth_aggr_desc_num_check(aggr_txq_ctrl, frags))) {
+		frags = 0;
+		goto out;
+	}
+
+	tx_desc = mvPp2AggrTxqNextDescGet(aggr_txq_ctrl->q);
+
+	tx_desc->physTxq = MV_PPV2_TXQ_PHYS(pp->port, tx_spec.txp, tx_spec.txq);
+
+	/* Don't use BM for Linux packets: NETA_TX_BM_ENABLE_MASK = 0 */
+	/* NETA_TX_PKT_OFFSET_MASK = 0 - for all descriptors */
+	tx_cmd = mv_eth_skb_tx_csum(pp, skb);
+
+#ifdef CONFIG_MV_PON
+	tx_desc->ponHwCmd = tx_spec.hw_cmd[0];
+	tx_desc->modifyInfo[0] = tx_spec.hw_cmd[1];
+	tx_desc->modifyInfo[1] = tx_spec.hw_cmd[2];
+	tx_desc->modifyInfo[2] = tx_spec.hw_cmd[3];
+#endif
+
+	/* FIXME: beware of nonlinear --BK */
+	tx_desc->dataSize = skb_headlen(skb);
+
+	tx_desc->bufPhysAddr = mvOsCacheFlush(NULL, skb->data, tx_desc->dataSize);
+
+	if (frags == 1) {
+		/*
+		 * First and Last descriptor
+		 */
+		if (tx_spec.flags & MV_ETH_F_NO_PAD)
+			tx_cmd |= PP2_TX_F_DESC_MASK | PP2_TX_L_DESC_MASK | PP2_TX_PADDING_DISABLE_MASK;
+		else
+			tx_cmd |= PP2_TX_F_DESC_MASK | PP2_TX_L_DESC_MASK;
+
+		tx_desc->command = tx_cmd;
+		mv_eth_tx_desc_flush(tx_desc);
+
+		mv_eth_shadow_push(txq_cpu_ptr, ((MV_ULONG) skb | MV_ETH_SHADOW_SKB));
+	} else {
+		/* First but not Last */
+		tx_cmd |= PP2_TX_F_DESC_MASK | PP2_TX_PADDING_DISABLE_MASK;
+
+		mv_eth_shadow_push(txq_cpu_ptr, 0);
+
+		tx_desc->command = tx_cmd;
+		mv_eth_tx_desc_flush(tx_desc);
+
+		/* Continue with other skb fragments */
+		mv_eth_tx_frag_process(pp, skb, aggr_txq_ctrl, txq_ctrl, &tx_spec);
+		STAT_DBG(pp->stats.tx_sg++);
+	}
+/*
+	printk(KERN_ERR "tx: frags=%d, tx_desc[0x0]=%x [0xc]=%x, wr_id=%d, rd_id=%d, skb=%p\n",
+			frags, tx_desc->command,tx_desc->hw_cmd,
+			txq_ctrl->shadow_txq_put_i, txq_ctrl->shadow_txq_get_i, skb);
+*/
+	txq_cpu_ptr->txq_count += frags;
+	aggr_txq_ctrl->txq_count += frags;
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if (pp->dbg_flags & MV_ETH_F_DBG_TX) {
+		printk(KERN_ERR "\n");
+		printk(KERN_ERR "%s - eth_tx_%lu: cpu=%d, in_intr=0x%lx, port=%d, txp=%d, txq=%d\n",
+			dev->name, dev->stats.tx_packets, smp_processor_id(), in_interrupt(),
+			pp->port, tx_spec.txp, tx_spec.txq);
+		printk(KERN_ERR "\t skb=%p, head=%p, data=%p, size=%d\n", skb, skb->head, skb->data, skb->len);
+		mv_eth_tx_desc_print(tx_desc);
+		/*mv_eth_skb_print(skb);*/
+		mvDebugMemDump(skb->data, 64, 1);
+	}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+	/* Enable transmit */
+	mvPp2AggrTxqPendDescAdd(frags);
+
+	STAT_DBG(aggr_txq_ctrl->stats.txq_tx += frags);
+	STAT_DBG(txq_ctrl->stats.txq_tx += frags);
+	STAT_DBG(txq_ctrl->txq_cpu[cpu].stats.txq_tx += frags);
+
+out:
+	if (frags > 0) {
+		dev->stats.tx_packets++;
+		dev->stats.tx_bytes += skb->len;
+	} else {
+		dev->stats.tx_dropped++;
+		dev_kfree_skb_any(skb);
+	}
+
+#ifndef CONFIG_MV_ETH_TXDONE_ISR
+	if (txq_ctrl) {
+		if (txq_cpu_ptr->txq_count >= mv_ctrl_txdone) {
+			STAT_DIST(u32 tx_done = )mv_eth_txq_done(pp, txq_ctrl);
+
+			STAT_DIST((tx_done < pp->dist_stats.tx_done_dist_size) ? pp->dist_stats.tx_done_dist[tx_done]++ : 0);
+
+		}
+		/* If after calling mv_eth_txq_done, txq_ctrl->txq_count equals frags, we need to set the timer */
+		if ((txq_cpu_ptr->txq_count == frags) && (frags > 0))
+			mv_eth_add_tx_done_timer(pp->cpu_config[smp_processor_id()]);
+	}
+
+#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+
+	return NETDEV_TX_OK;
+}
+
+#ifdef CONFIG_MV_ETH_TSO
+/* Validate TSO */
+static inline int mv_eth_tso_validate(struct sk_buff *skb, struct net_device *dev)
+{
+	if (!(dev->features & NETIF_F_TSO)) {
+		printk(KERN_ERR "error: (skb_is_gso(skb) returns true but features is not NETIF_F_TSO\n");
+		return 1;
+	}
+
+	if (skb_shinfo(skb)->frag_list != NULL) {
+		printk(KERN_ERR "***** ERROR: frag_list is not null\n");
+		return 1;
+	}
+
+	if (skb_shinfo(skb)->gso_segs == 1) {
+		printk(KERN_ERR "***** ERROR: only one TSO segment\n");
+		return 1;
+	}
+
+	if (skb->len <= skb_shinfo(skb)->gso_size) {
+		printk(KERN_ERR "***** ERROR: total_len (%d) less than gso_size (%d)\n", skb->len, skb_shinfo(skb)->gso_size);
+		return 1;
+	}
+	if ((htons(ETH_P_IP) != skb->protocol) || (ip_hdr(skb)->protocol != IPPROTO_TCP) || (tcp_hdr(skb) == NULL)) {
+		printk(KERN_ERR "***** ERROR: Protocol is not TCP over IP\n");
+		return 1;
+	}
+	return 0;
+}
+
+static inline int mv_eth_tso_build_hdr_desc(struct pp2_tx_desc *tx_desc, struct eth_port *priv, struct sk_buff *skb,
+					     struct txq_cpu_ctrl *txq_ctrl, u16 *mh, int hdr_len, int size,
+					     MV_U32 tcp_seq, MV_U16 ip_id, int left_len)
+{
+	struct iphdr *iph;
+	struct tcphdr *tcph;
+	MV_U8 *data, *mac;
+	int mac_hdr_len = skb_network_offset(skb);
+
+	data = mv_eth_extra_pool_get(priv);
+	if (!data)
+		return 0;
+
+	/* Reserve 2 bytes for IP header alignment */
+	mac = data + MV_ETH_MH_SIZE;
+	iph = (struct iphdr *)(mac + mac_hdr_len);
+
+	memcpy(mac, skb->data, hdr_len);
+
+	if (iph) {
+		iph->id = htons(ip_id);
+		iph->tot_len = htons(size + hdr_len - mac_hdr_len);
+	}
+
+	tcph = (struct tcphdr *)(mac + skb_transport_offset(skb));
+	tcph->seq = htonl(tcp_seq);
+
+	if (left_len) {
+		/* Clear all special flags for not last packet */
+		tcph->psh = 0;
+		tcph->fin = 0;
+		tcph->rst = 0;
+	}
+
+	if (mh) {
+		/* Start tarnsmit from MH - add 2 bytes to size */
+		*((MV_U16 *)data) = *mh;
+		/* increment ip_offset field in TX descriptor by 2 bytes */
+		mac_hdr_len += MV_ETH_MH_SIZE;
+		hdr_len += MV_ETH_MH_SIZE;
+	} else {
+		/* Start transmit from MAC */
+		data = mac;
+	}
+
+	tx_desc->dataSize = hdr_len;
+	tx_desc->command = mvPp2TxqDescCsum(mac_hdr_len, skb->protocol, ((u8 *)tcph - (u8 *)iph) >> 2, IPPROTO_TCP);
+	tx_desc->command |= PP2_TX_F_DESC_MASK;
+
+	tx_desc->bufPhysAddr = mvOsCacheFlush(NULL, data, tx_desc->dataSize);
+
+	mv_eth_shadow_push(txq_ctrl, ((MV_ULONG)data | MV_ETH_SHADOW_EXT));
+
+	mv_eth_tx_desc_flush(tx_desc);
+
+	return hdr_len;
+}
+
+static inline int mv_eth_tso_build_data_desc(struct pp2_tx_desc *tx_desc, struct sk_buff *skb,
+					     struct txq_cpu_ctrl *txq_ctrl, char *frag_ptr,
+					     int frag_size, int data_left, int total_left)
+{
+	int size, val = 0;
+
+	size = MV_MIN(frag_size, data_left);
+
+	tx_desc->dataSize = size;
+	tx_desc->bufPhysAddr = mvOsCacheFlush(NULL, frag_ptr, size);
+	tx_desc->command = 0;
+
+	if (size == data_left) {
+		/* last descriptor in the TCP packet */
+		tx_desc->command = PP2_TX_L_DESC_MASK;
+
+		if (total_left == 0) {
+			/* last descriptor in SKB */
+			val = ((MV_ULONG) skb | MV_ETH_SHADOW_SKB);
+		}
+	}
+	mv_eth_shadow_push(txq_ctrl, val);
+	mv_eth_tx_desc_flush(tx_desc);
+
+	return size;
+}
+
+/***********************************************************
+ * mv_eth_tx_tso --                                        *
+ *   send a packet.                                        *
+ ***********************************************************/
+int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_eth_tx_spec *tx_spec,
+			struct txq_cpu_ctrl *txq_ctrl, struct aggr_tx_queue *aggr_txq_ctrl)
+{
+	int frag = 0;
+	int total_len, hdr_len, size, frag_size, data_left;
+	char *frag_ptr;
+	int totalDescNum, totalBytes = 0;
+	struct pp2_tx_desc *tx_desc;
+	MV_U16 ip_id;
+	MV_U32 tcp_seq = 0;
+	skb_frag_t *skb_frag_ptr;
+	const struct tcphdr *th = tcp_hdr(skb);
+	struct eth_port *priv = MV_ETH_PRIV(dev);
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+	MV_U16 *mh = NULL;
+	int i;
+
+	STAT_DBG(priv->stats.tx_tso++);
+/*
+	printk(KERN_ERR "mv_eth_tx_tso_%d ENTER: skb=%p, total_len=%d\n", priv->stats.tx_tso, skb, skb->len);
+*/
+	if (mv_eth_tso_validate(skb, dev))
+		return 0;
+
+	/* Calculate expected number of TX descriptors */
+	totalDescNum = skb_shinfo(skb)->gso_segs * 2 + skb_shinfo(skb)->nr_frags;
+
+	/* check if there is enough descriptors */
+	if ((!mv_eth_phys_desc_num_check(txq_ctrl, totalDescNum)) ||
+		(!mv_eth_aggr_desc_num_check(aggr_txq_ctrl, totalDescNum))) {
+
+		printk(KERN_ERR "%s: no TX descriptors - txq_count=%d, len=%d, nr_frags=%d, gso_segs=%d\n",
+					__func__, txq_ctrl->txq_count, skb->len, skb_shinfo(skb)->nr_frags,
+					skb_shinfo(skb)->gso_segs);
+
+		STAT_ERR(txq_ctrl->stats.txq_err++);
+		return 0;
+	}
+
+	total_len = skb->len;
+	hdr_len = (skb_transport_offset(skb) + tcp_hdrlen(skb));
+
+	total_len -= hdr_len;
+	ip_id = ntohs(ip_hdr(skb)->id);
+	tcp_seq = ntohl(th->seq);
+
+	frag_size = skb_headlen(skb);
+	frag_ptr = skb->data;
+
+	if (frag_size < hdr_len) {
+		printk(KERN_ERR "***** ERROR: frag_size=%d, hdr_len=%d\n", frag_size, hdr_len);
+		return 0;
+	}
+
+	frag_size -= hdr_len;
+	frag_ptr += hdr_len;
+	if (frag_size == 0) {
+		skb_frag_ptr = &skb_shinfo(skb)->frags[frag];
+
+		/* Move to next segment */
+		frag_size = skb_frag_ptr->size;
+		frag_ptr = page_address(skb_frag_ptr->page.p) + skb_frag_ptr->page_offset;
+		frag++;
+	}
+	totalDescNum = 0;
+
+	while (total_len > 0) {
+		data_left = MV_MIN(skb_shinfo(skb)->gso_size, total_len);
+
+		tx_desc = mvPp2AggrTxqNextDescGet(aggr_txq_ctrl->q);
+		if (tx_desc == NULL)
+			goto outNoTxDesc;
+		tx_desc->physTxq = MV_PPV2_TXQ_PHYS(priv->port, tx_spec->txp, tx_spec->txq);
+
+		totalDescNum++;
+		total_len -= data_left;
+
+		aggr_txq_ctrl->txq_count++;
+		txq_ctrl->txq_count++;
+
+		if (tx_spec->flags & MV_ETH_F_MH) {
+			if (tx_spec->flags & MV_ETH_F_SWITCH)
+				mh = &dev_priv->tx_vlan_mh;
+			else
+				mh = &priv->tx_mh;
+		}
+
+		/* prepare packet headers: MAC + IP + TCP */
+		size = mv_eth_tso_build_hdr_desc(tx_desc, priv, skb, txq_ctrl, mh,
+					hdr_len, data_left, tcp_seq, ip_id, total_len);
+		if (size == 0)
+			goto outNoTxDesc;
+
+		totalBytes += size;
+/*
+		printk(KERN_ERR "Header desc: tx_desc=%p, skb=%p, hdr_len=%d, data_left=%d\n",
+						tx_desc, skb, hdr_len, data_left);
+*/
+		ip_id++;
+
+		while (data_left > 0) {
+			tx_desc = mvPp2AggrTxqNextDescGet(aggr_txq_ctrl->q);
+			if (tx_desc == NULL)
+				goto outNoTxDesc;
+			tx_desc->physTxq = MV_PPV2_TXQ_PHYS(priv->port, tx_spec->txp, tx_spec->txq);
+
+			totalDescNum++;
+			aggr_txq_ctrl->txq_count++;
+			txq_ctrl->txq_count++;
+
+			size = mv_eth_tso_build_data_desc(tx_desc, skb, txq_ctrl,
+							  frag_ptr, frag_size, data_left, total_len);
+			totalBytes += size;
+/*
+			printk(KERN_ERR "Data desc: tx_desc=%p, skb=%p, size=%d, frag_size=%d, data_left=%d\n",
+							tx_desc, skb, size, frag_size, data_left);
+ */
+			data_left -= size;
+			tcp_seq += size;
+
+			frag_size -= size;
+			frag_ptr += size;
+
+			if ((frag_size == 0) && (frag < skb_shinfo(skb)->nr_frags)) {
+				skb_frag_ptr = &skb_shinfo(skb)->frags[frag];
+
+				/* Move to next segment */
+				frag_size = skb_frag_ptr->size;
+				frag_ptr = page_address(skb_frag_ptr->page.p) + skb_frag_ptr->page_offset;
+				frag++;
+			}
+		}		/* of while data_left > 0 */
+	}			/* of while (total_len > 0) */
+
+	STAT_DBG(priv->stats.tx_tso_bytes += totalBytes);
+	STAT_DBG(txq_ctrl->stats.txq_tx += totalDescNum);
+
+	mvPp2AggrTxqPendDescAdd(totalDescNum);
+
+	return totalDescNum;
+
+outNoTxDesc:
+	/* No enough TX descriptors for the whole skb - rollback */
+	printk(KERN_ERR "%s: No TX descriptors - rollback %d, txq_count=%d, nr_frags=%d, skb=%p, len=%d, gso_segs=%d\n",
+			__func__, totalDescNum, txq_ctrl->txq_count, skb_shinfo(skb)->nr_frags,
+			skb, skb->len, skb_shinfo(skb)->gso_segs);
+
+	for (i = 0; i < totalDescNum; i++) {
+		txq_ctrl->txq_count--;
+		mv_eth_shadow_dec_put(txq_ctrl);
+		mvPp2AggrTxqPrevDescGet(aggr_txq_ctrl->q);
+	}
+	return 0;
+}
+#endif /* CONFIG_MV_ETH_TSO */
+
+/* Drop packets received by the RXQ and free buffers */
+static void mv_eth_rxq_drop_pkts(struct eth_port *pp, int rxq)
+{
+	struct pp2_rx_desc *rx_desc;
+	struct eth_pbuf     *pkt;
+	struct bm_pool      *pool;
+	int	                rx_done, i;
+	MV_PP2_PHYS_RXQ_CTRL    *rx_ctrl = pp->rxq_ctrl[rxq].q;
+
+	if (rx_ctrl == NULL)
+		return;
+
+	rx_done = mvPp2RxqBusyDescNumGet(pp->port, rxq);
+	mvOsCacheIoSync();
+
+	for (i = 0; i < rx_done; i++) {
+		rx_desc = mvPp2RxqNextDescGet(rx_ctrl);
+		mvOsCacheLineInv(NULL, rx_desc);
+
+#if defined(MV_CPU_BE)
+		/*mvNetaRxqDescSwap(rx_desc);*/
+#endif /* MV_CPU_BE */
+
+		pkt = (struct eth_pbuf *)rx_desc->bufCookie;
+		pool = &mv_eth_pool[pkt->pool];
+		mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+	}
+	if (rx_done) {
+		mvOsCacheIoSync();
+		mvPp2RxqDescNumUpdate(pp->port, rxq, rx_done, rx_done);
+	}
+}
+
+static void mv_eth_txq_done_force(struct eth_port *pp, struct tx_queue *txq_ctrl)
+{
+	int cpu, tx_done;
+	struct txq_cpu_ctrl *txq_cpu_ptr;
+
+	for_each_possible_cpu(cpu) {
+		txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
+		tx_done = txq_cpu_ptr->txq_count;
+		mv_eth_txq_bufs_free(pp, &txq_ctrl->txq_cpu[cpu], tx_done);
+		STAT_DBG(txq_ctrl->stats.txq_txdone += tx_done);
+		STAT_DBG(txq_cpu_ptr->stats.txq_txdone += tx_done);
+
+		/* reset txq */
+		txq_cpu_ptr->txq_count = 0;
+		txq_cpu_ptr->shadow_txq_put_i = 0;
+		txq_cpu_ptr->shadow_txq_get_i = 0;
+	}
+}
+
+inline u32 mv_eth_tx_done_pon(struct eth_port *pp, int *tx_todo)
+{
+	int txp, txq;
+	struct tx_queue *txq_ctrl;
+	struct txq_cpu_ctrl *txq_cpu_ptr;
+
+	u32 tx_done = 0;
+
+	*tx_todo = 0;
+
+	STAT_INFO(pp->stats.tx_done++);
+
+	/* simply go over all TX ports and TX queues */
+	txp = pp->txp_num;
+	while (txp--) {
+		txq = CONFIG_MV_ETH_TXQ;
+
+		while (txq--) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+			txq_cpu_ptr = &txq_ctrl->txq_cpu[smp_processor_id()];
+			if ((txq_ctrl) && (txq_cpu_ptr->txq_count)) {
+				tx_done += mv_eth_txq_done(pp, txq_ctrl);
+				*tx_todo += txq_cpu_ptr->txq_count;
+			}
+		}
+	}
+
+	STAT_DIST((tx_done < pp->dist_stats.tx_done_dist_size) ? pp->dist_stats.tx_done_dist[tx_done]++ : 0);
+
+	return tx_done;
+}
+
+
+inline u32 mv_eth_tx_done_gbe(struct eth_port *pp, u32 cause_tx_done, int *tx_todo)
+{
+	int txq;
+	struct tx_queue *txq_ctrl;
+	struct txq_cpu_ctrl *txq_cpu_ptr;
+	u32 tx_done = 0;
+
+	*tx_todo = 0;
+
+	STAT_INFO(pp->stats.tx_done++);
+
+	while (cause_tx_done != 0) {
+
+		/* For GbE ports we get TX Buffers Threshold Cross per queue in bits [7:0] */
+		txq = mv_eth_tx_done_policy(cause_tx_done);
+
+		if (txq == -1)
+			break;
+
+		txq_ctrl = &pp->txq_ctrl[txq];
+		txq_cpu_ptr = &txq_ctrl->txq_cpu[smp_processor_id()];
+
+		if (txq_ctrl == NULL) {
+			printk(KERN_ERR "%s: txq_ctrl = NULL, txq=%d\n", __func__, txq);
+			return -EINVAL;
+		}
+
+		if ((txq_ctrl) && (txq_cpu_ptr->txq_count)) {
+			tx_done += mv_eth_txq_done(pp, txq_ctrl);
+			*tx_todo += txq_cpu_ptr->txq_count;
+		}
+
+		cause_tx_done &= ~(1 << txq);
+	}
+
+	STAT_DIST((tx_done < pp->dist_stats.tx_done_dist_size) ? pp->dist_stats.tx_done_dist[tx_done]++ : 0);
+
+	return tx_done;
+}
+
+
+static void mv_eth_tx_frag_process(struct eth_port *pp, struct sk_buff *skb, struct aggr_tx_queue *aggr_txq_ctrl,
+					struct tx_queue *txq_ctrl, struct mv_eth_tx_spec *tx_spec)
+{
+	int i, cpu = smp_processor_id();
+	struct pp2_tx_desc *tx_desc;
+
+	for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {
+		skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
+
+		tx_desc = mvPp2AggrTxqNextDescGet(aggr_txq_ctrl->q);
+		tx_desc->physTxq = MV_PPV2_TXQ_PHYS(pp->port, tx_spec->txp, tx_spec->txq);
+
+		/* NETA_TX_BM_ENABLE_MASK = 0 */
+		/* NETA_TX_PKT_OFFSET_MASK = 0 */
+		tx_desc->dataSize = frag->size;
+		tx_desc->bufPhysAddr = mvOsCacheFlush(NULL, page_address(frag->page.p) + frag->page_offset,
+						      tx_desc->dataSize);
+
+		if (i == (skb_shinfo(skb)->nr_frags - 1)) {
+			/* Last descriptor */
+			if (tx_spec->flags & MV_ETH_F_NO_PAD)
+				tx_desc->command = (PP2_TX_L_DESC_MASK | PP2_TX_PADDING_DISABLE_MASK);
+			else
+				tx_desc->command = PP2_TX_L_DESC_MASK;
+
+			mv_eth_shadow_push(&txq_ctrl->txq_cpu[cpu], ((MV_ULONG) skb | MV_ETH_SHADOW_SKB));
+		} else {
+			/* Descriptor in the middle: Not First, Not Last */
+			tx_desc->command = 0;
+
+			mv_eth_shadow_push(&txq_ctrl->txq_cpu[cpu], 0);
+		}
+
+		mv_eth_tx_desc_flush(tx_desc);
+	}
+}
+
+
+/* Free "num" buffers from the pool */
+static int mv_eth_pool_free(int pool, int num)
+{
+	struct eth_pbuf *pkt;
+	int i = 0, buff_size;
+	struct bm_pool *ppool = &mv_eth_pool[pool];
+	unsigned long flags = 0;
+	bool free_all = false;
+
+	MV_ETH_LOCK(&ppool->lock, flags);
+
+	if (num >= ppool->buf_num) {
+		/* Free all buffers from the pool */
+		free_all = true;
+		num = ppool->buf_num;
+	}
+
+	buff_size = (ppool->is_hwf) ? RX_HWF_BUF_SIZE(ppool->pkt_size) : RX_BUF_SIZE(ppool->pkt_size);
+
+	if (mv_eth_pool_bm(ppool)) {
+		while (i < num) {
+			MV_U32 *va;
+			va = (MV_U32 *)mvBmPoolGet(pool);
+			if (va == 0)
+				break;
+
+			pkt = (struct eth_pbuf *)va;
+#if !defined(CONFIG_MV_ETH_BE_WA)
+			pkt = (struct eth_pbuf *)MV_32BIT_LE((MV_U32)pkt);
+#endif /* !CONFIG_MV_ETH_BE_WA */
+
+			if (!ppool->is_hwf) {
+				if (pkt)
+					mv_eth_pkt_free(pkt);
+			} else if (pkt) { /* HWF pool */
+				mvOsFree(pkt->pBuf);
+				mvOsFree(pkt);
+			}
+			i++;
+		}
+		printk(KERN_ERR "bm pool #%d: pkt_size=%4d, buf_size=%4d - %d of %d buffers free\n",
+			pool, ppool->pkt_size, buff_size, i, num);
+	}
+
+	ppool->buf_num -= num;
+
+	if (ppool->is_hwf)
+		return i;
+
+	/* Free buffers from the pool stack too */
+	if (free_all)
+		num = mvStackIndex(ppool->stack);
+	else if (mv_eth_pool_bm(ppool))
+		num = 0;
+
+	i = 0;
+	while (i < num) {
+		/* sanity check */
+		if (mvStackIndex(ppool->stack) == 0) {
+			printk(KERN_ERR "%s: No more buffers in the stack\n", __func__);
+			break;
+		}
+		pkt = (struct eth_pbuf *)mvStackPop(ppool->stack);
+		if (pkt) {
+			if (!ppool->is_hwf)
+				mv_eth_pkt_free(pkt);
+			else /* HWF packet - no skb */
+				mvOsFree(pkt);
+		}
+		i++;
+	}
+	if (i > 0)
+		printk(KERN_ERR "stack pool #%d: pkt_size=%4d, buf_size=%4d - %d of %d buffers free\n",
+			pool, ppool->pkt_size, buff_size, i, num);
+
+	MV_ETH_UNLOCK(&ppool->lock, flags);
+
+	return i;
+}
+
+
+static int mv_eth_pool_destroy(int pool)
+{
+	int num, status = 0;
+	struct bm_pool *ppool = &mv_eth_pool[pool];
+
+	num = mv_eth_pool_free(pool, ppool->buf_num);
+	if (num != ppool->buf_num) {
+		printk(KERN_ERR "Warning: could not free all buffers in pool %d while destroying pool\n", pool);
+		return MV_ERROR;
+	}
+
+	status = mvStackDelete(ppool->stack);
+
+/*	mvBmPoolDisable(pool);*/
+	mvBmPoolControl(pool, MV_STOP);
+
+	/* Note: we don't free the bm_pool here ! */
+	if (ppool->bm_pool)
+		mvOsFree(ppool->bm_pool);
+
+	memset(ppool, 0, sizeof(struct bm_pool));
+
+	return status;
+}
+
+
+static int mv_eth_pool_add(int pool, int buf_num)
+{
+	struct bm_pool *bm_pool;
+	struct sk_buff *skb;
+	struct eth_pbuf *pkt;
+	unsigned char *hwf_buff, *hwf_buff_phys;
+	int i, buff_size;
+	unsigned long flags = 0;
+
+	if ((pool < 0) || (pool >= MV_ETH_BM_POOLS)) {
+		printk(KERN_ERR "%s: invalid pool number %d\n", __func__, pool);
+		return 0;
+	}
+
+	bm_pool = &mv_eth_pool[pool];
+	buff_size = (bm_pool->is_hwf) ? RX_HWF_BUF_SIZE(bm_pool->pkt_size) : RX_BUF_SIZE(bm_pool->pkt_size);
+
+	/* Check buffer size */
+	if (bm_pool->pkt_size == 0) {
+		printk(KERN_ERR "%s: invalid pool #%d state: pkt_size=%d, buf_size=%d, buf_num=%d\n",
+		       __func__, pool, bm_pool->pkt_size, buff_size, bm_pool->buf_num);
+		return 0;
+	}
+
+	/* Insure buf_num is smaller than capacity */
+	if ((buf_num < 0) || ((buf_num + bm_pool->buf_num) > (bm_pool->capacity))) {
+
+		printk(KERN_ERR "%s: can't add %d buffers into bm_pool=%d: capacity=%d, buf_num=%d\n",
+		       __func__, buf_num, pool, bm_pool->capacity, bm_pool->buf_num);
+		return 0;
+	}
+
+	MV_ETH_LOCK(&bm_pool->lock, flags);
+
+	for (i = 0; i < buf_num; i++) {
+		pkt = mvOsMalloc(sizeof(struct eth_pbuf));
+		if (!pkt) {
+			printk(KERN_ERR "%s: can't allocate %d bytes\n", __func__, sizeof(struct eth_pbuf));
+			break;
+		}
+
+		if (!bm_pool->is_hwf) {
+			skb = mv_eth_skb_alloc(bm_pool, pkt);
+			if (!skb) {
+				kfree(pkt);
+				break;
+			}
+		} else {
+			hwf_buff = mv_eth_hwf_buff_alloc(bm_pool, pkt);
+			if (!hwf_buff) {
+				kfree(pkt);
+				break;
+			}
+			memset(hwf_buff, 0, sizeof(buff_size));
+		}
+		mvBmPoolPut(pool, pkt->physAddr, (MV_ULONG)pkt);
+		STAT_DBG(bm_pool->stats.bm_put++);
+	}
+	bm_pool->buf_num += i;
+
+	printk(KERN_ERR "bm pool #%d: pkt_size=%4d, buf_size=%4d - %d of %d buffers added\n",
+	       pool, bm_pool->pkt_size, buff_size, i, buf_num);
+
+	MV_ETH_UNLOCK(&bm_pool->lock, flags);
+
+	return i;
+}
+
+void	*mv_eth_bm_pool_create(int pool, int capacity, MV_ULONG *pPhysAddr)
+{
+		MV_ULONG			physAddr;
+		void				*pVirt;
+		MV_STATUS			status;
+
+		pVirt = mvOsIoUncachedMalloc(NULL, sizeof(MV_U32) * capacity, &physAddr, NULL);
+		if (pVirt == NULL) {
+			mvOsPrintf("%s: Can't allocate %d bytes for Long pool #%d\n",
+					__func__, MV_BM_POOL_CAP_MAX * sizeof(MV_U32), pool);
+			return NULL;
+		}
+
+		/* Pool address must be MV_BM_POOL_PTR_ALIGN bytes aligned */
+		if (MV_IS_NOT_ALIGN((unsigned)pVirt, MV_BM_POOL_PTR_ALIGN)) {
+			mvOsPrintf("memory allocated for BM pool #%d is not %d bytes aligned\n",
+						pool, MV_BM_POOL_PTR_ALIGN);
+			mvOsIoCachedFree(NULL, sizeof(MV_U32) * capacity, physAddr, pVirt, 0);
+			return NULL;
+		}
+		status = mvBmPoolInit(pool, physAddr, capacity);
+		if (status != MV_OK) {
+			mvOsPrintf("%s: Can't init #%d BM pool. status=%d\n", __func__, pool, status);
+			mvOsIoCachedFree(NULL, sizeof(MV_U32) * capacity, physAddr, pVirt, 0);
+			return NULL;
+		}
+
+		/*mvBmPoolEnable(pool);*/
+		mvBmPoolControl(pool, MV_START);
+
+		if (pPhysAddr != NULL)
+			*pPhysAddr = physAddr;
+
+		return pVirt;
+}
+
+static MV_STATUS mv_eth_pool_create(int pool, int capacity)
+{
+	struct bm_pool *bm_pool;
+
+	if ((pool < 0) || (pool >= MV_ETH_BM_POOLS)) {
+		printk(KERN_ERR "%s: pool=%d is out of range\n", __func__, pool);
+		return MV_BAD_VALUE;
+	}
+
+	bm_pool = &mv_eth_pool[pool];
+	memset(bm_pool, 0, sizeof(struct bm_pool));
+
+	bm_pool->bm_pool = mv_eth_bm_pool_create(pool, capacity, NULL);
+	if (bm_pool->bm_pool == NULL)
+		return MV_FAIL;
+
+	/* Create Stack as container of alloacted skbs for SKB_RECYCLE and for RXQs working without BM support */
+	bm_pool->stack = mvStackCreate(capacity);
+
+	if (bm_pool->stack == NULL) {
+		printk(KERN_ERR "Can't create MV_STACK structure for %d elements\n", capacity);
+		return MV_OUT_OF_CPU_MEM;
+	}
+
+	bm_pool->pool = pool;
+	bm_pool->capacity = capacity;
+	bm_pool->pkt_size = 0;
+	bm_pool->buf_num = 0;
+	spin_lock_init(&bm_pool->lock);
+
+	return MV_OK;
+}
+
+/* Interrupt handling */
+irqreturn_t mv_eth_isr(int irq, void *dev_id)
+{
+	struct eth_port *pp = (struct eth_port *)dev_id;
+	int cpu, group = pp->cpu_config[smp_processor_id()]->napi_group_id;
+	struct napi_group_ctrl *napi_group = pp->napi_group[group];
+	struct napi_struct *napi = napi_group->napi;
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if (pp->dbg_flags & MV_ETH_F_DBG_ISR) {
+		printk(KERN_ERR "%s: port=%d, cpu=%d, mask=0x%x, cause=0x%x\n",
+			__func__, pp->port, smp_processor_id(),
+			MV_REG_READ(MV_PP2_ISR_RX_TX_MASK_REG(MV_PPV2_PORT_PHYS(pp->port))),
+			mvPp2GbeIsrCauseRxTxGet(pp->port));
+	}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+	STAT_INFO(pp->stats.irq++);
+
+	/* Mask all interrupts for cpus in this group */
+	for_each_possible_cpu(cpu) {
+		if ((1 << cpu) & napi_group->cpu_mask)
+			mvPp2GbeCpuInterruptsDisable(pp->port, cpu);
+	}
+
+	/* Verify that the device not already on the polling list */
+	if (napi_schedule_prep(napi)) {
+		/* schedule the work (rx+txdone+link) out of interrupt contxet */
+		__napi_schedule(napi);
+	} else {
+		STAT_INFO(pp->stats.irq_err++);
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+		printk(KERN_ERR "mv_eth_isr ERROR: port=%d, cpu=%d\n", pp->port, smp_processor_id());
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+	}
+	return IRQ_HANDLED;
+}
+
+void mv_eth_link_event(struct eth_port *pp, int print)
+{
+	struct net_device *dev = pp->dev;
+	bool              link_is_up = false;
+
+	STAT_INFO(pp->stats.link++);
+
+	/* Check Link status on ethernet port */
+#ifdef CONFIG_MV_PON
+	if (MV_PON_PORT(pp->port))
+		link_is_up = mv_pon_link_status();
+	else
+#endif /* CONFIG_MV_PON */
+		link_is_up = mvEthPortIsLinkUp(pp->port);
+
+	if (link_is_up) {
+		mvPp2PortUp(pp->port);
+		set_bit(MV_ETH_F_LINK_UP_BIT, &(pp->flags));
+
+		if (mv_eth_ctrl_is_tx_enabled(pp)) {
+			if (dev) {
+				netif_carrier_on(dev);
+				netif_tx_wake_all_queues(dev);
+			}
+		}
+	} else {
+		if (dev) {
+			netif_carrier_off(dev);
+			netif_tx_stop_all_queues(dev);
+		}
+		mvPp2PortDown(pp->port);
+		clear_bit(MV_ETH_F_LINK_UP_BIT, &(pp->flags));
+	}
+
+	if (print) {
+		if (dev)
+			printk(KERN_ERR "%s: ", dev->name);
+		else
+			printk(KERN_ERR "%s: ", "none");
+
+		mv_eth_link_status_print(pp->port);
+	}
+}
+
+/***********************************************************************************************/
+int mv_eth_poll(struct napi_struct *napi, int budget)
+{
+	int rx_done = 0, group_id, cpu;
+	struct napi_group_ctrl *napi_group;
+	MV_U32 causeRxTx;
+	struct eth_port *pp = MV_ETH_PRIV(napi->dev);
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if (pp->dbg_flags & MV_ETH_F_DBG_POLL) {
+		printk(KERN_ERR "%s ENTER: port=%d, cpu=%d, mask=0x%x, cause=0x%x\n",
+			__func__, pp->port, smp_processor_id(),
+			MV_REG_READ(MV_PP2_ISR_RX_TX_MASK_REG(MV_PPV2_PORT_PHYS(pp->port))),
+			mvPp2GbeIsrCauseRxTxGet(pp->port));
+	}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
+		STAT_INFO(pp->stats.netdev_stop++);
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+		if (pp->dbg_flags & MV_ETH_F_DBG_RX)
+			printk(KERN_ERR "%s: STARTED_BIT = 0, poll completed.\n", __func__);
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+		napi_complete(napi);
+		STAT_INFO(pp->stats.poll_exit[smp_processor_id()]++);
+		return rx_done;
+	}
+
+	STAT_INFO(pp->stats.poll[smp_processor_id()]++);
+
+	/* Read cause register */
+	causeRxTx = mvPp2GbeIsrCauseRxTxGet(pp->port);
+
+	if (causeRxTx & MV_PP2_CAUSE_MISC_ERR_SUM_MASK) {
+		if (causeRxTx & MV_PP2_CAUSE_FCS_ERR_MASK)
+			printk(KERN_ERR "%s: FCS error\n", __func__);
+
+		if (causeRxTx & MV_PP2_CAUSE_RX_FIFO_OVERRUN_MASK)
+			printk(KERN_ERR "%s: RX fifo overrun error\n", __func__);
+
+		if (causeRxTx & MV_PP2_CAUSE_TX_FIFO_UNDERRUN_MASK)
+			printk(KERN_ERR "%s: TX fifo underrun error\n", __func__);
+
+		if (causeRxTx & MV_PP2_CAUSE_MISC_SUM_MASK) {
+			printk(KERN_ERR "%s: misc event\n", __func__);
+			MV_REG_WRITE(MV_PP2_ISR_MISC_CAUSE_REG, 0);
+		}
+
+		causeRxTx &= ~MV_PP2_CAUSE_MISC_ERR_SUM_MASK;
+		MV_REG_WRITE(MV_PP2_ISR_RX_TX_CAUSE_REG(MV_PPV2_PORT_PHYS(pp->port)), causeRxTx);
+	}
+	group_id = pp->cpu_config[smp_processor_id()]->napi_group_id;
+	napi_group = pp->napi_group[group_id];
+	causeRxTx |= napi_group->cause_rx_tx;
+
+#ifdef CONFIG_MV_ETH_TXDONE_ISR
+	if (mvPp2GbeIsrCauseTxDoneIsSet(pp->port, causeRxTx)) {
+		int tx_todo = 0, cause_tx_done;
+		/* TX_DONE process */
+		cause_tx_done = mvPp2GbeIsrCauseTxDoneOffset(pp->port, causeRxTx);
+		if (MV_PON_PORT(pp->port))
+			mv_eth_tx_done_pon(pp, &tx_todo);
+		else
+			mv_eth_tx_done_gbe(pp, cause_tx_done, &tx_todo);
+	}
+#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+	if (MV_PON_PORT(pp->port))
+		causeRxTx &= ~MV_PP2_PON_CAUSE_TXP_OCCUP_DESC_ALL_MASK;
+	else
+		causeRxTx &= ~MV_PP2_CAUSE_TXQ_OCCUP_DESC_ALL_MASK;
+
+	while ((causeRxTx != 0) && (budget > 0)) {
+		int count, rx_queue;
+
+		rx_queue = mv_eth_rx_policy(causeRxTx);
+		if (rx_queue == -1)
+			break;
+
+		count = mv_eth_rx(pp, budget, rx_queue);
+		rx_done += count;
+		budget -= count;
+		if (budget > 0)
+			causeRxTx &= ~((1 << rx_queue) << MV_PP2_CAUSE_RXQ_OCCUP_DESC_OFFS);
+	}
+
+	STAT_DIST((rx_done < pp->dist_stats.rx_dist_size) ? pp->dist_stats.rx_dist[rx_done]++ : 0);
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if (pp->dbg_flags & MV_ETH_F_DBG_POLL) {
+		printk(KERN_ERR "%s  EXIT: port=%d, cpu=%d, budget=%d, rx_done=%d\n",
+			__func__, pp->port, smp_processor_id(), budget, rx_done);
+	}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+	if (budget > 0) {
+		unsigned long flags;
+
+		causeRxTx = 0;
+
+		napi_complete(napi);
+
+		STAT_INFO(pp->stats.poll_exit[smp_processor_id()]++);
+
+		/* TODO: do we need irq_save */
+		local_irq_save(flags);
+		/* Enable interrupts for all cpus belong to this group */
+		for_each_possible_cpu(cpu) {
+			if (!((1 << cpu) & napi_group->cpu_mask))
+				continue;
+			mvPp2GbeCpuInterruptsEnable(pp->port, cpu);
+		}
+		local_irq_restore(flags);
+	}
+	napi_group->cause_rx_tx = causeRxTx;
+	return rx_done;
+}
+
+void mv_eth_port_promisc_set(int port, int queue)
+{
+	if (mv_eth_pnc_ctrl_en)
+		mvPrsMacPromiscousSet(port, 1);
+	else
+		printk(KERN_ERR "%s: PARSER and CLASSIFIER control is disabled\n", __func__);
+}
+
+void mv_eth_port_filtering_cleanup(int port)
+{
+	static bool is_first = true;
+
+	/* clean TCAM and SRAM only one, no need to do this per port. */
+	if (is_first) {
+		mvPp2PrsHwClearAll();
+		mvPp2PrsHwInvAll();
+		is_first = false;
+	}
+}
+
+
+static MV_STATUS mv_eth_bm_pools_init(void)
+{
+	int i, j, buff_size;
+	MV_STATUS status;
+
+	/* Get compile time configuration */
+	mv_eth_bm_config_get();
+
+	/* Create all pools with maximum capacity */
+	for (i = 0; i < MV_ETH_BM_POOLS; i++) {
+		status = mv_eth_pool_create(i, MV_BM_POOL_CAP_MAX);
+		if (status != MV_OK) {
+			printk(KERN_ERR "%s: can't create bm_pool=%d - capacity=%d\n", __func__, i, MV_BM_POOL_CAP_MAX);
+			for (j = 0; j < i; j++)
+				mv_eth_pool_destroy(j);
+			return status;
+		}
+		mv_eth_pool[i].pkt_size = mv_eth_bm_config_pkt_size_get(i);
+
+		if (mv_eth_bm_config_is_hwf_pool(i)) {
+			mv_eth_pool[i].is_hwf = 1;
+			buff_size = RX_HWF_BUF_SIZE(mv_eth_pool[i].pkt_size);
+		} else
+			buff_size = RX_BUF_SIZE(mv_eth_pool[i].pkt_size);
+
+		if (mv_eth_pool[i].pkt_size == 0)
+			mvPp2BmPoolBufSizeSet(i, 0);
+		else
+			mvPp2BmPoolBufSizeSet(i, buff_size);
+	}
+	return 0;
+}
+
+#ifdef CONFIG_MV_ETH_HWF
+int mv_eth_hwf_bm_pool_init(struct eth_port *pp, int mtu)
+{
+	int num = 0, pkt_size = RX_PKT_SIZE(mtu);
+
+	if (pp->hwf_pool_long == NULL) {
+		struct bm_pool *new_pool = &mv_eth_pool[mv_eth_bm_config_hwf_long_pool_get(pp->port)];
+
+		if (mv_eth_attach_long_pool(pp, new_pool, pp->hwf_pool_long_num, pkt_size)) {
+			printk(KERN_ERR "%s FAILED: pool=%d, pkt_size=%d, only %d of %d allocated\n",
+			       __func__, new_pool->pool, new_pool->pkt_size, num, pp->hwf_pool_long_num);
+			return -1;
+		}
+	}
+
+	if (pp->hwf_pool_short == NULL) {
+		pp->hwf_pool_short = &mv_eth_pool[mv_eth_bm_config_hwf_short_pool_get(pp->port)];
+		pp->hwf_pool_short->port_map |= (1 << pp->port);
+
+		mvPp2BmPoolBufSizeSet(pp->hwf_pool_short->pool, RX_HWF_BUF_SIZE(pp->hwf_pool_short->pkt_size));
+
+		num = mv_eth_pool_add(pp->hwf_pool_short->pool, pp->hwf_pool_short_num);
+		if (num != pp->hwf_pool_short_num) {
+			printk(KERN_ERR "%s FAILED: pool=%d, pkt_size=%d, only %d of %d allocated\n",
+			       __func__, pp->hwf_pool_short->pool, pp->hwf_pool_short->pkt_size, num, pp->hwf_pool_short_num);
+			return -ENOMEM;
+		}
+	}
+
+	mvPp2PortHwfBmPoolSet(pp->port, pp->hwf_pool_short->pool, pp->hwf_pool_long->pool);
+
+	return 0;
+}
+#endif /* CONFIG_MV_ETH_HWF */
+
+static int mv_eth_port_link_speed_fc(int port, MV_ETH_PORT_SPEED port_speed, int en_force)
+{
+	if (en_force) {
+		if (mvEthSpeedDuplexSet(port, port_speed, MV_ETH_DUPLEX_FULL)) {
+			printk(KERN_ERR "mvEthSpeedDuplexSet failed\n");
+			return -EIO;
+		}
+		if (mvEthFlowCtrlSet(port, MV_ETH_FC_ENABLE)) {
+			printk(KERN_ERR "mvEthFlowCtrlSet failed\n");
+			return -EIO;
+		}
+		if (mvEthForceLinkModeSet(port, 1, 0)) {
+			printk(KERN_ERR "mvEthForceLinkModeSet failed\n");
+			return -EIO;
+		}
+	} else {
+		if (mvEthForceLinkModeSet(port, 0, 0)) {
+			printk(KERN_ERR "mvEthForceLinkModeSet failed\n");
+			return -EIO;
+		}
+		if (mvEthSpeedDuplexSet(port, MV_ETH_SPEED_AN, MV_ETH_DUPLEX_AN)) {
+			printk(KERN_ERR "mvEthSpeedDuplexSet failed\n");
+			return -EIO;
+		}
+		if (mvEthFlowCtrlSet(port, MV_ETH_FC_AN_SYM)) {
+			printk(KERN_ERR "mvEthFlowCtrlSet failed\n");
+			return -EIO;
+		}
+	}
+
+	return 0;
+}
+
+static int mv_eth_load_network_interfaces(struct platform_device *pdev)
+{
+	u32 port, dev_i = 0;
+	struct eth_port *pp;
+	int mtu, err, txp, phys_port;
+	struct mv_pp2_pdata *plat_data = (struct mv_pp2_pdata *)pdev->dev.platform_data;
+	u8 mac[MV_MAC_ADDR_SIZE];
+
+	port = pdev->id;
+	phys_port = MV_PPV2_PORT_PHYS(port);
+	printk(KERN_ERR "  o Loading network interface(s) for port #%d: cpu_mask=0x%x, mtu=%d\n",
+			port, plat_data->cpu_mask, plat_data->mtu);
+
+	pp = mv_eth_ports[port] = mvOsMalloc(sizeof(struct eth_port));
+	if (!pp) {
+		printk(KERN_ERR "Error: failed to allocate memory for port %d\n", port);
+		return -ENOMEM;
+	}
+	memset(pp, 0, sizeof(struct eth_port));
+
+	err = mv_eth_priv_init(pp, port);
+	if (err)
+		return err;
+
+	pp->cpuMask = plat_data->cpu_mask;
+	/* set port's speed, duplex, fc */
+	if (!MV_PON_PORT(pp->port)) {
+		/* force link, speed and duplex if necessary (e.g. Switch is connected) based on board information */
+		switch (plat_data->speed) {
+		case SPEED_10:
+			err = mv_eth_port_link_speed_fc(pp->port, MV_ETH_SPEED_10, 1);
+			break;
+		case SPEED_100:
+			err = mv_eth_port_link_speed_fc(pp->port, MV_ETH_SPEED_100, 1);
+			break;
+		case SPEED_1000:
+			err = mv_eth_port_link_speed_fc(pp->port, MV_ETH_SPEED_1000, 1);
+			break;
+		case 0:
+			err = mv_eth_port_link_speed_fc(pp->port, MV_ETH_SPEED_AN, 0);
+			break;
+		default:
+			/* do nothing */
+			break;
+		}
+		if (err)
+			return err;
+	}
+
+#ifdef CONFIG_MV_ETH_SWITCH
+	if (pp->flags & (MV_ETH_F_SWITCH | MV_ETH_F_EXT_SWITCH)) {
+		int status = mv_eth_switch_config_get(mv_eth_initialized, port);
+
+		if (status < 0) {
+			printk(KERN_ERR "\nWarning: port %d - Invalid netconfig string\n", port);
+			mv_eth_priv_cleanup(pp);
+			return -EIO;
+		}
+		if (status == 0) {	/* User selected to work with Gateway driver    */
+			clear_bit(MV_ETH_F_EXT_SWITCH_BIT, &(pp->flags));
+		} else if (status == 1) {
+			/* User selected to work without Gateway driver */
+			clear_bit(MV_ETH_F_SWITCH_BIT, &(pp->flags));
+			printk(KERN_ERR "  o Working in External, plat_data->mtu Switch mode\n");
+			ext_switch_port_mask = mv_switch_link_detection_init();
+		}
+	}
+	if (pp->flags & MV_ETH_F_SWITCH) {
+		set_bit(MV_ETH_F_MH_BIT, &(pp->flags));
+		mtu = switch_net_config[port].mtu;
+		if (mv_switch_init(RX_PKT_SIZE(mtu), SWITCH_CONNECTED_PORTS_MASK)) {
+			printk(KERN_ERR "\nWarning: port %d - Switch initialization failed\n", port);
+			mv_eth_priv_cleanup(pp);
+			return -EIO;
+		}
+	} else
+#endif /* CONFIG_MV_ETH_SWITCH */
+		mtu = mv_eth_config_get(pdev, mac);
+
+	printk(KERN_ERR "\t%s p=%d: mtu=%d, mac=%p\n", MV_PON_PORT(port) ? "pon" : "giga", port, mtu, mac);
+
+	if (mv_eth_hal_init(pp)) {
+		printk(KERN_ERR "%s: can't init eth hal\n", __func__);
+		mv_eth_priv_cleanup(pp);
+		return -EIO;
+	}
+
+#ifdef CONFIG_MV_ETH_SWITCH
+	if (pp->flags & MV_ETH_F_SWITCH) {
+		int queue = CONFIG_MV_ETH_RXQ_DEF;
+
+		mv_eth_switch_netdev_first = dev_i;
+		dev_i = mv_eth_switch_netdev_init(pp, dev_i, pdev);
+		if (dev_i < (mv_eth_switch_netdev_first + switch_net_config[port].netdev_max)) {
+			printk(KERN_ERR "%s: can't create netdevice for switch\n", __func__);
+			mv_eth_priv_cleanup(pp);
+			return -EIO;
+		}
+		mv_eth_switch_netdev_last = dev_i - 1;
+
+		/* set this port to be in promiscuous mode. MAC filtering is performed by the Switch */
+		mv_eth_port_promisc_set(pp->port, queue);
+		handle_group_affinity(port);
+		return 0;
+	}
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+	mv_net_devs[dev_i] = mv_eth_netdev_init(pp, mtu, mac, pdev);
+	if (!mv_net_devs[dev_i]) {
+		printk(KERN_ERR "%s: can't create netdevice\n", __func__);
+		mv_eth_priv_cleanup(pp);
+		return -EIO;
+	}
+	pp->dev = mv_net_devs[dev_i];
+	/* Default NAPI initialization */
+	/* Create one group for this port, that contains all RXQs and all CPUs - every cpu can process all RXQs */
+	if (pp->flags & MV_ETH_F_CONNECT_LINUX) {
+		if (mv_eth_port_napi_group_create(pp->port, 0))
+			return -EIO;
+		if (mv_eth_napi_set_cpu_affinity(pp->port, 0, (1 << CONFIG_NR_CPUS) - 1) ||
+				mv_eth_napi_set_rxq_affinity(pp->port, 0, (1 << MV_ETH_MAX_RXQ) - 1))
+			return -EIO;
+	}
+	dev_i++;
+
+	mv_net_devs_num = dev_i;
+
+	if (mv_eth_pnc_ctrl_en) {
+		/* Init classifer MTU */
+		for (txp = 0; txp < pp->txp_num; txp++)
+			mvPp2ClsHwMtuSet(MV_PPV2_PORT_PHYS(pp->port), txp, mtu/*TODO fix size*/);
+
+		mvPp2ClsHwOversizeRxqSet(MV_PPV2_PORT_PHYS(pp->port), pp->first_rxq);
+
+		/* classifier port default config */
+		mvPp2ClsHwPortDefConfig(phys_port, 0, FLOWID_DEF(phys_port), pp->first_rxq);
+	}
+
+	/* Call mv_eth_open specifically for ports not connected to Linux netdevice */
+	if (!(pp->flags & MV_ETH_F_CONNECT_LINUX)) {
+		if (pp->flags & MV_ETH_F_SWITCH)
+			printk(KERN_ERR "%s: a GbE port using the Gateway driver cannot be disconnected from Linux\n", __func__);
+		else
+			mv_eth_open(pp->dev);
+	}
+
+	return 0;
+}
+
+
+
+int mv_eth_resume_network_interfaces(struct eth_port *pp)
+{
+/* TBD */
+	return 0;
+}
+
+/***********************************************************
+ * mv_eth_port_resume                                      *
+ ***********************************************************/
+
+int mv_eth_port_resume(int port)
+{
+/* TBD */
+	return 0;
+}
+
+/***********************************************************
+ * mv_eth_win_init --                                      *
+ *   Win initilization                                     *
+ ***********************************************************/
+void 	mv_eth_win_init()
+{
+
+	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+	MV_STATUS status;
+	int i;
+
+	status = mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1);
+	if (status != MV_OK)
+		return;
+
+	for (i = 0; i < MAX_TARGETS; i++) {
+		if (addrWinMap[i].enable == MV_FALSE)
+			continue;
+
+#ifdef CONFIG_MV_SUPPORT_L2_DEPOSIT
+		/* Setting DRAM windows attribute to :
+		   0x3 - Shared transaction + L2 write allocate (L2 Deposit) */
+		if (MV_TARGET_IS_DRAM(i)) {
+			addrWinMap[i].attrib &= ~(0x30);
+			addrWinMap[i].attrib |= 0x30;
+		}
+#endif
+	}
+	mvPp2WinInit(0, addrWinMap);
+	return;
+}
+
+/***********************************************************
+ * mv_eth_port_suspend                                     *
+ *   main driver initialization. loading the interfaces.   *
+ ***********************************************************/
+int mv_eth_port_suspend(int port)
+{
+/* TBD */
+	return 0;
+}
+
+/***********************************************************
+ * mv_eth_pm_mode_set --                                   *
+ *   set pm_mode. (power menegment mod)			   *
+ ***********************************************************/
+int	mv_eth_pm_mode_set(int port, int mode)
+{
+/* TBD */
+	return 0;
+}
+
+static int	mv_eth_shared_probe(void)
+{
+	int size, cpu;
+
+	/* init MAC Unit */
+	mvSysPp2Init();
+	mv_eth_config_show();
+
+	size = mv_eth_ports_num * sizeof(struct eth_port *);
+	mv_eth_ports = mvOsMalloc(size);
+	if (!mv_eth_ports)
+		goto oom;
+
+	memset(mv_eth_ports, 0, size);
+
+	/* Allocate array of pointers to struct net_device */
+	size = mv_net_devs_max * sizeof(struct net_device *);
+	mv_net_devs = mvOsMalloc(size);
+	if (!mv_net_devs)
+		goto oom;
+
+	memset(mv_net_devs, 0, size);
+
+	/* Allocate aggregated TXQs control */
+	size = CONFIG_NR_CPUS * sizeof(struct aggr_tx_queue);
+	aggr_txqs = mvOsMalloc(size);
+	if (!aggr_txqs)
+		goto oom;
+
+	memset(aggr_txqs, 0, size);
+	for_each_possible_cpu(cpu) {
+		aggr_txqs[cpu].txq_size = CONFIG_MV_ETH_AGGR_TXQ_SIZE;
+		aggr_txqs[cpu].q = mvPp2AggrTxqInit(cpu, CONFIG_MV_ETH_AGGR_TXQ_SIZE);
+	}
+
+	if (mv_eth_bm_pools_init())
+		goto oom;
+
+	/* Parser default initialization */
+	if (mv_eth_pnc_ctrl_en) {
+
+		if (mvPrsDefaultInit())
+			printk(KERN_ERR "%s: Warning PARSER default init failed\n", __func__);
+
+		if (mvPp2ClassifierDefInit())
+			printk(KERN_ERR "%s: Warning Classifier defauld init failed\n", __func__);
+	}
+
+#ifdef CONFIG_MV_INCLUDE_SWITCH
+	if (mv_switch_load(SWITCH_CONNECTED_PORTS_MASK))
+		printk(KERN_ERR "\nWarning: Switch load failed\n");
+#endif /* CONFIG_MV_INCLUDE_SWITCH */
+
+	mv_eth_initialized = 1;
+	return 0;
+
+oom:
+	if (mv_eth_ports)
+		mvOsFree(mv_eth_ports);
+
+	if (mv_net_devs)
+		mvOsFree(mv_net_devs);
+
+	if (aggr_txqs)
+		mvOsFree(aggr_txqs);
+
+	printk(KERN_ERR "%s: out of memory\n", __func__);
+	return -ENOMEM;
+}
+
+/***********************************************************
+ * mv_eth_probe --                                         *
+ *   main driver initialization. loading the interfaces.   *
+ ***********************************************************/
+static int mv_eth_probe(struct platform_device *pdev)
+{
+	struct mv_pp2_pdata *plat_data = (struct mv_pp2_pdata *)pdev->dev.platform_data;
+	int phyAddr, port = pdev->id;
+
+	if (!mv_eth_initialized) {
+
+		mv_eth_ports_num = mvCtrlEthMaxPortGet();
+		mv_net_devs_max = mv_eth_ports_num;
+
+#ifdef CONFIG_MV_ETH_SWITCH
+		mv_net_devs_max += (CONFIG_MV_ETH_SWITCH_NETDEV_NUM - 1);
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+		if (mv_eth_shared_probe())
+			return -ENODEV;
+	}
+
+	if (!MV_PON_PORT(pdev->id)) {
+		if (!plat_data->lb_enable) {
+			/* Set the board information regarding PHY address */
+			phyAddr = mvBoardPhyAddrGet(pdev->id);
+			mvEthPhyAddrSet(pdev->id, phyAddr);
+		}
+
+		if (plat_data->lb_enable)
+			mvEthPortLbSet(port, (plat_data->speed == SPEED_1000), plat_data->is_sgmii);
+		mvEthPortPowerUp(port, plat_data->is_sgmii, plat_data->is_rgmii);
+	}
+
+	if (mv_eth_load_network_interfaces(pdev))
+		return -ENODEV;
+
+	printk(KERN_ERR "\n");
+
+	return 0;
+}
+
+
+static int mv_eth_config_get(struct platform_device *pdev, MV_U8 *mac_addr)
+{
+	struct mv_pp2_pdata *plat_data = (struct mv_pp2_pdata *)pdev->dev.platform_data;
+
+	if (mac_addr)
+		memcpy(mac_addr, plat_data->mac_addr, MV_MAC_ADDR_SIZE);
+
+	return plat_data->mtu;
+}
+
+/***********************************************************
+ * mv_eth_tx_timeout --                                    *
+ *   nothing to be done (?)                                *
+ ***********************************************************/
+static void mv_eth_tx_timeout(struct net_device *dev)
+{
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	struct eth_port *pp = MV_ETH_PRIV(dev);
+
+	pp->stats.tx_timeout++;
+#endif /* #ifdef CONFIG_MV_ETH_STAT_ERR */
+
+	printk(KERN_INFO "%s: tx timeout\n", dev->name);
+}
+
+/***************************************************************
+ * mv_eth_netdev_init -- Allocate and initialize net_device    *
+ *                   structure                                 *
+ ***************************************************************/
+struct net_device *mv_eth_netdev_init(struct eth_port *pp, int mtu, u8 *mac,
+				struct platform_device *pdev)
+{
+	int cpu;
+	struct net_device *dev;
+	struct eth_dev_priv *dev_priv;
+	struct cpu_ctrl	*cpuCtrl;
+
+	dev = alloc_etherdev_mq(sizeof(struct eth_dev_priv), CONFIG_MV_ETH_TXQ);
+	if (!dev)
+		return NULL;
+
+	dev_priv = (struct eth_dev_priv *)netdev_priv(dev);
+	if (!dev_priv)
+		return NULL;
+
+	memset(dev_priv, 0, sizeof(struct eth_dev_priv));
+	dev_priv->port_p = pp;
+/*
+TODO:change
+	dev->irq = NET_TH_RXTX_IRQ_NUM(pp->port);
+*/
+	dev->irq = 101 + pp->port;
+
+	dev->mtu = mtu;
+	memcpy(dev->dev_addr, mac, MV_MAC_ADDR_SIZE);
+	dev->tx_queue_len = CONFIG_MV_ETH_TXQ_DESC;
+	dev->watchdog_timeo = 5 * HZ;
+
+#ifdef CONFIG_MV_ETH_SWITCH
+	if (pp->flags & (MV_ETH_F_SWITCH | MV_ETH_F_EXT_SWITCH)) {
+
+		if (pp->flags & MV_ETH_F_SWITCH)
+			dev->netdev_ops = &mv_switch_netdev_ops;
+		else
+			dev->netdev_ops = &mv_eth_netdev_ops;
+
+		dev_priv->netdev_p = mvOsMalloc(sizeof(struct eth_netdev));
+		if (!dev_priv->netdev_p) {
+			printk(KERN_ERR "failed to allocate eth_netdev\n");
+			free_netdev(dev);
+			return NULL;
+		}
+		memset(dev_priv->netdev_p, 0, sizeof(struct eth_netdev));
+		/* For correct link information of Linux interface: */
+		if (pp->flags & MV_ETH_F_EXT_SWITCH) {
+			dev_priv->netdev_p->port_map = ext_switch_port_mask;
+			dev_priv->netdev_p->link_map = 0;
+		}
+	} else
+#endif /* CONFIG_MV_ETH_SWITCH */
+		dev->netdev_ops = &mv_eth_netdev_ops;
+
+#ifdef CONFIG_MV_ETH_TOOL
+	SET_ETHTOOL_OPS(dev, &mv_eth_tool_ops);
+#endif
+
+	for_each_possible_cpu(cpu) {
+		cpuCtrl = pp->cpu_config[cpu];
+		cpuCtrl->napi_group_id = -1;
+		cpuCtrl->tx_done_timer.data = (unsigned long)dev;
+		cpuCtrl->cleanup_timer.data = (unsigned long)dev;
+	}
+
+	SET_NETDEV_DEV(dev, &pdev->dev);
+
+	if (pp->flags & MV_ETH_F_CONNECT_LINUX) {
+		mv_eth_netdev_set_features(dev);
+		if (register_netdev(dev)) {
+			printk(KERN_ERR "failed to register %s\n", dev->name);
+			free_netdev(dev);
+			return NULL;
+		} else {
+			printk(KERN_ERR "    o %s, ifindex = %d, GbE port = %d", dev->name, dev->ifindex, pp->port);
+#ifdef CONFIG_MV_ETH_SWITCH
+			if (!(pp->flags & MV_ETH_F_SWITCH))
+				printk(KERN_CONT "\n");
+#else
+			printk(KERN_CONT "\n");
+#endif
+		}
+	}
+	return dev;
+}
+
+bool mv_eth_netdev_find(unsigned int dev_idx)
+{
+	int i;
+
+	for (i = 0; i < mv_net_devs_num; i++) {
+		if (mv_net_devs && mv_net_devs[i] && (mv_net_devs[i]->ifindex == dev_idx))
+			return true;
+	}
+	return false;
+}
+EXPORT_SYMBOL(mv_eth_netdev_find);
+
+
+int mv_eth_hal_init(struct eth_port *pp)
+{
+	int rxq, txp, txq, size, cpu;
+	struct tx_queue *txq_ctrl;
+	struct txq_cpu_ctrl *txq_cpu_ptr;
+	struct rx_queue *rxq_ctrl;
+
+	/* Init port */
+	pp->port_ctrl = mvPp2PortInit(pp->port, pp->first_rxq, pp->rxq_num, NULL);
+	if (!pp->port_ctrl) {
+		printk(KERN_ERR "%s: failed to load port=%d\n", __func__, pp->port);
+		return -ENODEV;
+	}
+
+	size = pp->txp_num * CONFIG_MV_ETH_TXQ * sizeof(struct tx_queue);
+	pp->txq_ctrl = mvOsMalloc(size);
+	if (!pp->txq_ctrl)
+		goto oom;
+
+	memset(pp->txq_ctrl, 0, size);
+
+	/* Create TX descriptor rings */
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+
+			txq_ctrl->q = NULL;
+			txq_ctrl->txp = txp;
+			txq_ctrl->txq = txq;
+			txq_ctrl->txq_size = CONFIG_MV_ETH_TXQ_DESC;
+			txq_ctrl->hwf_size = CONFIG_MV_ETH_TXQ_HWF_DESC;
+
+			for_each_possible_cpu(cpu) {
+				txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
+				txq_cpu_ptr->shadow_txq = NULL;
+				txq_cpu_ptr->txq_size =
+					(CONFIG_MV_ETH_TXQ_DESC - CONFIG_MV_ETH_TXQ_HWF_DESC) / MV_ETH_MAX_CPU;
+				txq_cpu_ptr->txq_count = 0;
+				txq_cpu_ptr->shadow_txq_put_i = 0;
+				txq_cpu_ptr->shadow_txq_get_i = 0;
+			}
+
+			txq_ctrl->txq_done_pkts_coal = mv_ctrl_txdone;
+		}
+	}
+
+	pp->rxq_ctrl = mvOsMalloc(pp->rxq_num * sizeof(struct rx_queue));
+	if (!pp->rxq_ctrl)
+		goto oom;
+
+	memset(pp->rxq_ctrl, 0, pp->rxq_num * sizeof(struct rx_queue));
+
+	/* Create Rx descriptor rings */
+	for (rxq = 0; rxq < pp->rxq_num; rxq++) {
+		rxq_ctrl = &pp->rxq_ctrl[rxq];
+		rxq_ctrl->rxq_size = CONFIG_MV_ETH_RXQ_DESC;
+		rxq_ctrl->rxq_pkts_coal = CONFIG_MV_ETH_RX_COAL_PKTS;
+		rxq_ctrl->rxq_time_coal = CONFIG_MV_ETH_RX_COAL_USEC;
+	}
+
+	if (pp->flags & MV_ETH_F_MH)
+		mvPp2MhSet(pp->port, MV_PP2_MH);
+
+#ifdef CONFIG_MV_ETH_TOOL
+	/* Configure defaults */
+	pp->autoneg_cfg  = AUTONEG_ENABLE;
+	pp->speed_cfg    = SPEED_1000;
+	pp->duplex_cfg  = DUPLEX_FULL;
+	pp->advertise_cfg = 0x2f;
+#endif /* CONFIG_MV_ETH_TOOL */
+
+	return 0;
+oom:
+	printk(KERN_ERR "%s: port=%d: out of memory\n", __func__, pp->port);
+	return -ENODEV;
+}
+
+/* Show network driver configuration */
+void mv_eth_config_show(void)
+{
+	/* Check restrictions */
+#if defined(CONFIG_MV_ETH_TSO) && !defined(CONFIG_MV_ETH_TX_CSUM_OFFLOAD)
+#   error "If GSO enabled - TX checksum offload must be enabled too"
+#endif
+
+	printk(KERN_ERR "  o %d Giga ports supported\n", mv_eth_ports_num);
+
+#ifdef CONFIG_MV_PON
+	printk(KERN_ERR "  o Giga PON port is #%d: - %d TCONTs supported\n", MV_PON_LOGIC_PORT_GET(), MV_ETH_MAX_TCONT);
+#endif
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+	printk(KERN_ERR "  o SKB recycle supported (%s)\n", mv_ctrl_recycle ? "Enabled" : "Disabled");
+#endif
+
+#ifdef CONFIG_MV_ETH_NETA
+	printk(KERN_ERR "  o NETA acceleration mode %d\n", mvNetaAccMode());
+#endif
+
+	printk(KERN_ERR "  o BM supported for CPU: %d BM pools\n", MV_ETH_BM_POOLS);
+
+#ifdef CONFIG_MV_ETH_HWF
+	printk(KERN_ERR "  o HWF supported\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_PMT
+	printk(KERN_ERR "  o PME supported\n");
+#endif
+
+	printk(KERN_ERR "  o RX Queue support: %d Queues * %d Descriptors\n", CONFIG_MV_ETH_RXQ, CONFIG_MV_ETH_RXQ_DESC);
+
+	printk(KERN_ERR "  o TX Queue support: %d Queues * %d Descriptors\n", CONFIG_MV_ETH_TXQ, CONFIG_MV_ETH_TXQ_DESC);
+
+#if defined(CONFIG_MV_ETH_TSO)
+	printk(KERN_ERR "  o GSO supported\n");
+#endif /* CONFIG_MV_ETH_TSO */
+
+#if defined(CONFIG_MV_ETH_RX_CSUM_OFFLOAD)
+	printk(KERN_ERR "  o Receive checksum offload supported\n");
+#endif
+#if defined(CONFIG_MV_ETH_TX_CSUM_OFFLOAD)
+	printk(KERN_ERR "  o Transmit checksum offload supported\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	printk(KERN_ERR "  o Driver ERROR statistics enabled\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_STAT_INF
+	printk(KERN_ERR "  o Driver INFO statistics enabled\n");
+#endif
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+	printk(KERN_ERR "  o Driver DEBUG statistics enabled\n");
+#endif
+
+#ifdef ETH_DEBUG
+	printk(KERN_ERR "  o Driver debug messages enabled\n");
+#endif
+
+#if defined(CONFIG_MV_ETH_SWITCH)
+	printk(KERN_ERR "  o Switch support enabled\n");
+
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+	printk(KERN_ERR "\n");
+}
+
+/* Set network device features on initialization. Take into account default compile time configuration. */
+static void mv_eth_netdev_set_features(struct net_device *dev)
+{
+	dev->features = NETIF_F_SG | NETIF_F_LLTX;
+
+#ifdef CONFIG_MV_ETH_TX_CSUM_OFFLOAD_DEF
+	if (dev->mtu <= MV_ETH_TX_CSUM_MAX_SIZE)
+		dev->features |= NETIF_F_IP_CSUM;
+#endif /* CONFIG_MV_ETH_TX_CSUM_OFFLOAD_DEF */
+
+#ifdef CONFIG_MV_ETH_TSO_DEF
+	if (dev->features & NETIF_F_IP_CSUM)
+		dev->features |= NETIF_F_TSO;
+#endif /* CONFIG_MV_ETH_TSO_DEF */
+}
+
+/* Update network device features after changing MTU.	*/
+static void mv_eth_netdev_update_features(struct net_device *dev)
+{
+#ifdef CONFIG_MV_ETH_TX_CSUM_OFFLOAD
+	if (dev->mtu > MV_ETH_TX_CSUM_MAX_SIZE) {
+		dev->features &= ~NETIF_F_IP_CSUM;
+		printk(KERN_ERR "Removing NETIF_F_IP_CSUM in device %s features\n", dev->name);
+	}
+#endif /* CONFIG_MV_ETH_TX_CSUM_OFFLOAD */
+
+#ifdef CONFIG_MV_ETH_TSO
+	if (!(dev->features & NETIF_F_IP_CSUM)) {
+		dev->features &= ~NETIF_F_TSO;
+		printk(KERN_ERR "Removing NETIF_F_TSO in device %s features\n", dev->name);
+	}
+#endif /* CONFIG_MV_ETH_TSO */
+}
+
+void mv_eth_priv_cleanup(struct eth_port *pp)
+{
+	/* TODO */
+}
+
+static struct bm_pool *mv_eth_long_pool_get(struct eth_port *pp, int pkt_size)
+{
+	int             pool, i;
+	struct bm_pool	*bm_pool, *temp_pool = NULL;
+	unsigned long   flags = 0;
+
+	/* look for free pool pkt_size == 0. First check pool == pp->port */
+	/* if no free pool choose larger than required */
+	for (i = 0; i < MV_ETH_BM_POOLS; i++) {
+		pool = (pp->port + i) % MV_ETH_BM_POOLS;
+		bm_pool = &mv_eth_pool[pool];
+
+		MV_ETH_LOCK(&bm_pool->lock, flags);
+
+		if (bm_pool->pkt_size == 0) {
+			/* found free pool */
+
+			MV_ETH_UNLOCK(&bm_pool->lock, flags);
+			return bm_pool;
+		}
+		if (bm_pool->pkt_size >= pkt_size && !bm_pool->is_hwf) {
+			if (temp_pool == NULL)
+				temp_pool = bm_pool;
+			else if (bm_pool->pkt_size < temp_pool->pkt_size)
+				temp_pool = bm_pool;
+		}
+		MV_ETH_UNLOCK(&bm_pool->lock, flags);
+	}
+	return temp_pool;
+}
+
+static int mv_eth_rxq_fill(struct eth_port *pp, int rxq, int num)
+{
+	mvPp2RxqNonOccupDescAdd(pp->port, rxq, num);
+	return num;
+}
+
+static int mv_eth_txq_create(struct eth_port *pp, struct tx_queue *txq_ctrl)
+{
+	int cpu;
+	struct txq_cpu_ctrl *txq_cpu_ptr;
+
+	txq_ctrl->q = mvPp2TxqInit(pp->port, txq_ctrl->txp, txq_ctrl->txq, txq_ctrl->txq_size, txq_ctrl->hwf_size);
+	if (txq_ctrl->q == NULL) {
+		printk(KERN_ERR "%s: can't create TxQ - port=%d, txp=%d, txq=%d, desc=%d, hwf desc=%d\n",
+		       __func__, pp->port, txq_ctrl->txp, txq_ctrl->txp, txq_ctrl->txq_size, txq_ctrl->hwf_size);
+		return -ENODEV;
+	}
+
+	for_each_possible_cpu(cpu) {
+		txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
+		txq_cpu_ptr->shadow_txq = mvOsMalloc(txq_cpu_ptr->txq_size * sizeof(MV_U32));
+		if (txq_cpu_ptr->shadow_txq == NULL)
+			goto no_mem;
+		/* reset txq */
+		txq_cpu_ptr->txq_count = 0;
+		txq_cpu_ptr->shadow_txq_put_i = 0;
+		txq_cpu_ptr->shadow_txq_get_i = 0;
+	}
+
+#ifdef CONFIG_MV_ETH_HWF
+/*
+	TBD
+	mvNetaHwfTxqInit(pp->port, txq_ctrl->txp, txq_ctrl->txq);
+*/
+#endif /* CONFIG_MV_ETH_HWF */
+
+	return 0;
+
+no_mem:
+	mv_eth_txq_delete(pp, txq_ctrl);
+	return -ENOMEM;
+}
+
+
+static void mv_eth_txq_delete(struct eth_port *pp, struct tx_queue *txq_ctrl)
+{
+	int cpu;
+	struct txq_cpu_ctrl *txq_cpu_ptr;
+	for_each_possible_cpu(cpu) {
+		txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
+		if (txq_cpu_ptr->shadow_txq) {
+			mvOsFree(txq_cpu_ptr->shadow_txq);
+			txq_cpu_ptr->shadow_txq = NULL;
+		}
+	}
+
+	if (txq_ctrl->q) {
+		mvPp2TxqDelete(pp->port, txq_ctrl->txp, txq_ctrl->txq);
+		txq_ctrl->q = NULL;
+	}
+}
+
+/* Free all packets pending transmit from all TXQs and reset TX port */
+int mv_eth_txp_clean(int port, int txp)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	int queue, msec, pending;
+
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "Port %d must be stopped before\n", port);
+		return -EINVAL;
+	}
+
+	/* free the skb's in the hal tx ring */
+	for (queue = 0; queue < CONFIG_MV_ETH_TXQ; queue++) {
+		struct tx_queue *txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + queue];
+
+		if (txq_ctrl->q) {
+			/* Wait for all packets to be transmitted */
+			msec = 0;
+			do {
+				if (msec >= MV_ETH_TX_PENDING_TIMEOUT_MSEC) {
+					mvOsPrintf("port=%d, txp=%d txq=%d: timeout for transmit pending descriptors\n",
+						   port, txp, queue);
+					break;
+				}
+				mdelay(1);
+				msec++;
+
+				pending = mvPp2TxqPendDescNumGet(pp->port,  txp, queue);
+			} while (pending);
+			/* release all transmitted packets */
+			mv_eth_txq_done_force(pp, txq_ctrl);
+		}
+	}
+
+	mvPp2TxpReset(port, txp);
+
+	return 0;
+}
+
+/* Free received packets from all RXQs and reset RX of the port */
+int mv_eth_rx_reset(int port)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "Port %d must be stopped before\n", port);
+		return -EINVAL;
+	}
+
+	mvPp2RxReset(port);
+	return 0;
+}
+
+/***********************************************************
+ * coal set functions		                           *
+ ***********************************************************/
+MV_STATUS mv_eth_rx_ptks_coal_set(int port, int rxq, MV_U32 value)
+{
+	MV_STATUS status = mvPp2RxqPktsCoalSet(port, rxq, value);
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	if (status == MV_OK)
+		pp->rxq_ctrl[rxq].rxq_pkts_coal = value;
+	return status;
+}
+
+MV_STATUS mv_eth_rx_time_coal_set(int port, int rxq, MV_U32 value)
+{
+
+	MV_STATUS status = mvPp2RxqTimeCoalSet(port, rxq, value);
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	if (status == MV_OK)
+		pp->rxq_ctrl[rxq].rxq_time_coal = value;
+	return status;
+
+	return  MV_OK;
+}
+
+MV_STATUS mv_eth_tx_done_ptks_coal_set(int port, int txp, int txq, MV_U32 value)
+{
+	MV_STATUS status = mvPp2TxDonePktsCoalSet(port, txp, txq, value);
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	if (status == MV_OK)
+		pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq].txq_done_pkts_coal = value;
+	return status;
+}
+
+/***********************************************************
+ * mv_eth_start_internals --                               *
+ *   fill rx buffers. start rx/tx activity. set coalesing. *
+ *   clear and unmask interrupt bits                       *
+ ***********************************************************/
+int mv_eth_start_internals(struct eth_port *pp, int mtu)
+{
+	unsigned int status;
+	int rxq, txp, txq, num, err = 0;
+	int pkt_size = RX_PKT_SIZE(mtu);
+
+	if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
+		STAT_ERR(pp->stats.state_err++);
+		printk(KERN_ERR "%s: port %d, wrong state: STARTED_BIT = 1\n", __func__, pp->port);
+		err = -EINVAL;
+		goto out;
+	}
+
+	mvEthMaxRxSizeSet(pp->port, RX_PKT_SIZE(mtu));
+
+#ifdef CONFIG_MV_ETH_HWF
+	mv_eth_hwf_bm_pool_init(pp, mtu);
+#endif /* CONFIG_MV_ETH_HWF */
+
+	/* Allocate buffers for Long buffers pool */
+	if (pp->pool_long == NULL) {
+		struct bm_pool *new_pool;
+		int long_pool = mv_eth_bm_config_long_pool_get(pp->port);
+
+		/* check if config pool is good */
+		if ((long_pool != -1) &&
+				((mv_eth_pool[long_pool].pkt_size == 0) ||
+				(mv_eth_pool[long_pool].pkt_size >= pkt_size)))
+			new_pool = &mv_eth_pool[long_pool];
+		else
+			new_pool = mv_eth_long_pool_get(pp, pkt_size);
+
+		if (new_pool == NULL) {
+			printk(KERN_ERR "%s FAILED: port=%d, Can't find pool for pkt_size=%d\n",
+			       __func__, pp->port, pkt_size);
+			err = -ENOMEM;
+			goto out;
+		}
+		if (new_pool->is_hwf) {
+			printk(KERN_ERR "%s FAILED: port=%d, pool#%d is already used by HWF\n",
+			       __func__, pp->port, new_pool->pool);
+			err = -EINVAL;
+			goto out;
+		}
+
+		if (mv_eth_attach_long_pool(pp, new_pool, pp->pool_long_num, pkt_size))
+			goto out;
+	}
+
+	if (pp->pool_short == NULL) {
+		int short_pool = mv_eth_bm_config_short_pool_get(pp->port);
+
+		/* Allocate packets for short pool */
+		if (short_pool < 0) {
+			err = -EINVAL;
+			goto out;
+		}
+		pp->pool_short = &mv_eth_pool[short_pool];
+		if (pp->pool_short->is_hwf) {
+			printk(KERN_ERR "%s FAILED: port=%d, pool#%d is already used by HWF\n",
+			       __func__, pp->port, pp->pool_short->pool);
+			err = -EINVAL;
+			goto out;
+		}
+		pp->pool_short->port_map |= (1 << pp->port);
+		if (pp->pool_short->pool != pp->pool_long->pool) {
+			num = mv_eth_pool_add(pp->pool_short->pool, pp->pool_short_num);
+			if (num != pp->pool_short_num) {
+				printk(KERN_ERR "%s FAILED: pool=%d, pkt_size=%d - %d of %d buffers added\n",
+					   __func__, short_pool, pp->pool_short->pkt_size, num, pp->pool_short_num);
+				err = -ENOMEM;
+				goto out;
+			}
+			mvPp2BmPoolBufSizeSet(pp->pool_short->pool, RX_BUF_SIZE(pp->pool_short->pkt_size));
+		} else {
+			int dummy_short_pool = (pp->pool_short->pool + 1) % MV_BM_POOLS;
+
+			/* To disable short pool we choose unused pool and set pkt size to 0 (buffer size = pkt offset) */
+			mvPp2BmPoolBufSizeSet(dummy_short_pool, NET_SKB_PAD);
+		}
+	}
+
+	for (rxq = 0; rxq < pp->rxq_num; rxq++) {
+		if (pp->rxq_ctrl[rxq].q == NULL) {
+			/* allocate descriptors and initialize RXQ */
+			pp->rxq_ctrl[rxq].q = mvPp2RxqInit(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_size);
+			if (!pp->rxq_ctrl[rxq].q) {
+				printk(KERN_ERR "%s: can't create RxQ port=%d, rxq=%d, desc=%d\n",
+				       __func__, pp->port, rxq, pp->rxq_ctrl[rxq].rxq_size);
+				err = -ENODEV;
+				goto out;
+			}
+			/* Set Offset  - at this point logical RXQs are already mappedto physical RXQs */
+			mvPp2RxqOffsetSet(pp->port, rxq, NET_SKB_PAD);
+		}
+
+		/* Set coalescing pkts and time */
+		mv_eth_rx_ptks_coal_set(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_pkts_coal);
+		mv_eth_rx_time_coal_set(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_time_coal);
+
+		if (pp->pool_short->pool == pp->pool_long->pool) {
+			int dummy_short_pool = (pp->pool_short->pool + 1) % MV_BM_POOLS;
+
+			/* To disable short pool we choose unused pool and set pkt size to 0 (buffer size = pkt offset) */
+			mvPp2RxqBmPoolSet(pp->port, rxq, dummy_short_pool, pp->pool_long->pool);
+		} else
+			mvPp2RxqBmPoolSet(pp->port, rxq, pp->pool_short->pool, pp->pool_long->pool);
+
+		if (mvPp2RxqFreeDescNumGet(pp->port, rxq) == 0)
+			mv_eth_rxq_fill(pp, rxq, pp->rxq_ctrl[rxq].rxq_size);
+	}
+
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++) {
+			struct tx_queue *txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+
+			if ((txq_ctrl->q == NULL) && (txq_ctrl->txq_size > 0)) {
+				err = mv_eth_txq_create(pp, txq_ctrl);
+				if (err)
+					goto out;
+				spin_lock_init(&txq_ctrl->queue_lock);
+			}
+#ifdef CONFIG_MV_ETH_TXDONE_ISR
+			mv_eth_tx_done_ptks_coal_set(pp->port, txp, txq, txq_ctrl->txq_done_pkts_coal);
+#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+		}
+		mvPp2TxpMaxTxSizeSet(pp->port, txp, RX_PKT_SIZE(mtu));
+	}
+	/* TODO: set speed, duplex, fc with ethtool parameres (speed_cfg, etc..) */
+
+	/* start the hal - rx/tx activity */
+	status = mvPp2PortEnable(pp->port);
+	if (status == MV_OK)
+		set_bit(MV_ETH_F_LINK_UP_BIT, &(pp->flags));
+#ifdef CONFIG_MV_PON
+	else if (MV_PON_PORT(pp->port) && (mv_pon_link_status() == MV_TRUE)) {
+		mvPp2PortUp(pp->port);
+		set_bit(MV_ETH_F_LINK_UP_BIT, &(pp->flags));
+	}
+#endif /* CONFIG_MV_PON */
+	set_bit(MV_ETH_F_STARTED_BIT, &(pp->flags));
+ out:
+	return err;
+}
+
+
+
+int mv_eth_resume_internals(struct eth_port *pp, int mtu)
+{
+/* TBD */
+	return 0;
+
+}
+
+
+int mv_eth_restore_registers(struct eth_port *pp, int mtu)
+{
+/* TBD */
+	return 0;
+}
+
+
+/***********************************************************
+ * mv_eth_suspend_internals --                                *
+ *   stop port rx/tx activity. free skb's from rx/tx rings.*
+ ***********************************************************/
+int mv_eth_suspend_internals(struct eth_port *pp)
+{
+/* TBD */
+	return 0;
+}
+
+
+/***********************************************************
+ * mv_eth_stop_internals --                                *
+ *   stop port rx/tx activity. free skb's from rx/tx rings.*
+ ***********************************************************/
+int mv_eth_stop_internals(struct eth_port *pp)
+{
+
+	int queue, txp;
+
+	if (!test_and_clear_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
+		STAT_ERR(pp->stats.state_err++);
+		printk(KERN_ERR "%s: port %d, wrong state: STARTED_BIT = 0.\n", __func__, pp->port);
+		goto error;
+	}
+
+	mdelay(10);
+
+	/* Transmit and free all packets */
+	for (txp = 0; txp < pp->txp_num; txp++)
+		mv_eth_txp_clean(pp->port, txp);
+
+	/* stop the port activity, mask all interrupts */
+	if (mvPp2PortDisable(pp->port) != MV_OK) {
+		printk(KERN_ERR "GbE port %d: ethPortDisable failed\n", pp->port);
+		goto error;
+	}
+
+	/* free the skb's in the hal rx ring */
+	for (queue = 0; queue < pp->rxq_num; queue++)
+		mv_eth_rxq_drop_pkts(pp, queue);
+
+	return 0;
+
+error:
+	printk(KERN_ERR "GbE port %d: stop internals failed\n", pp->port);
+	return -1;
+}
+
+/* return positive if MTU is valid */
+int mv_eth_check_mtu_valid(struct net_device *dev, int mtu)
+{
+	if (mtu < 68) {
+		printk(KERN_INFO "MTU must be at least 68, change mtu failed\n");
+		return -EINVAL;
+	}
+	if (mtu > 9676 /* 9700 - 20 and rounding to 8 */) {
+		printk(KERN_ERR "%s: Illegal MTU value %d, ", dev->name, mtu);
+		mtu = 9676;
+		printk(KERN_CONT " rounding MTU to: %d \n", mtu);
+	}
+
+	if (MV_IS_NOT_ALIGN(RX_PKT_SIZE(mtu), 8)) {
+		printk(KERN_ERR "%s: Illegal MTU value %d, ", dev->name, mtu);
+		mtu = MV_ALIGN_UP(RX_PKT_SIZE(mtu), 8);
+		printk(KERN_CONT " rounding MTU to: %d \n", mtu);
+	}
+	return mtu;
+}
+
+/* Check if MTU can be changed */
+int mv_eth_check_mtu_internals(struct net_device *dev, int mtu)
+{
+	int i, pkt_size = RX_PKT_SIZE(mtu);
+	struct eth_port *pp = MV_ETH_PRIV(dev);
+	struct bm_pool	*new_pool = NULL, *port_pool;
+
+	if (!pp)
+		return -EPERM;
+
+	port_pool = pp->pool_long;
+
+	/* long pool is not shared with other ports */
+	if ((port_pool) && (port_pool->port_map == (1 << pp->port)))
+		return 0;
+
+	new_pool = mv_eth_long_pool_get(pp, pkt_size);
+
+	/* there is a pool suitable for new port's mtu */
+	if (new_pool)
+		return 0;
+
+	/* we must use the current long pool - need to check that all other ports using this pool are stopped */
+	if (!port_pool)
+		return -EPERM;
+
+	for (i = 0; i < mv_eth_ports_num; i++) {
+		/* Check that all ports using this pool are stopped */
+		if (port_pool->port_map & (1 << i)) {
+			pp = mv_eth_port_by_id(i);
+			if ((pp == NULL) || (pp->port == i))
+				continue;
+
+			if (pp->flags & MV_ETH_F_STARTED) {
+				printk(KERN_ERR "Port %d use pool #%d and must be stopped before changing mtu\n",
+					pp->port, port_pool->pool);
+				return -EPERM;
+			}
+		}
+	}
+
+	return 0;
+}
+
+/***********************************************************
+ * mv_eth_change_mtu_internals --                          *
+ *   stop port activity. release skb from rings. set new   *
+ *   mtu in device and hw. restart port activity and       *
+ *   and fill rx-buiffers with size according to new mtu.  *
+ ***********************************************************/
+int mv_eth_change_mtu_internals(struct net_device *dev, int mtu)
+{
+	struct bm_pool *new_pool = NULL, *port_pool;
+	struct eth_port *pp = MV_ETH_PRIV(dev);
+	int pkt_size = RX_PKT_SIZE(mtu), pkts_num = pp->pool_long_num;
+
+	if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
+		STAT_ERR(pp->stats.state_err++);
+		if (pp->dbg_flags & MV_ETH_F_DBG_RX)
+			printk(KERN_ERR "%s: port %d, STARTED_BIT = 0, Invalid value.\n", __func__, pp->port);
+		return -1;
+	}
+
+	if (mtu == dev->mtu)
+		goto mtu_out;
+
+#ifdef CONFIG_MV_ETH_HWF
+	port_pool = pp->hwf_pool_long;
+
+	/* for now, hwf long pool must not be shared with other ports */
+	if (port_pool) {
+		if (port_pool->port_map == (1 << pp->port)) {
+			/* refill pool with updated buffer size */
+			mv_eth_pool_free(port_pool->pool, pkts_num);
+			port_pool->pkt_size = 0;
+			if (mv_eth_attach_long_pool(pp, port_pool, pkts_num, pkt_size))
+				return -1;
+		} else {
+			printk(KERN_ERR "%s: port %d, HWF long pool is shared with other ports.\n", __func__, pp->port);
+			return -1;
+		}
+	}
+#endif /* CONFIG_MV_ETH_HWF */
+
+	port_pool = pp->pool_long;
+
+	/* long pool is not shared with other ports */
+	if ((port_pool) && (port_pool->port_map == (1 << pp->port))) {
+		/* refill pool with updated buffer size */
+		mv_eth_pool_free(port_pool->pool, pkts_num);
+		port_pool->pkt_size = 0;
+		if (mv_eth_attach_long_pool(pp, port_pool, pkts_num, pkt_size))
+			return -1;
+
+		goto mtu_out;
+	}
+
+	/* find new pool according to new mtu */
+	new_pool = mv_eth_long_pool_get(pp, pkt_size);
+	if (new_pool && (new_pool != port_pool)) {
+		/* dettach old pool, attach new pool */
+		mv_eth_pool_free(port_pool->pool, pkts_num);
+		port_pool->port_map &= ~(1 << pp->port);
+
+		if (mv_eth_attach_long_pool(pp, new_pool, pkts_num, pkt_size))
+			return -1;
+		goto mtu_out;
+	}
+
+	printk(KERN_ERR "%s: port %d, couldn't find any suitable BM pool got mtu=%d.\n", __func__, pp->port, mtu);
+	return -1;
+
+	/* TODO for now, skip code below for handling shared pools - we will support it later */
+	/* must use current pool */
+/*	if (!port_pool) {
+		printk(KERN_ERR "%s: port %d, couldn't find any suitable BM pool got mtu=%d.\n", __func__, pp->port, mtu);
+		return -1;
+	}
+	for (i = 0; i < mv_eth_ports_num; i++) {
+*/
+		/* Check that all ports using this pool are stopped */
+/*		if (port_pool->port_map & (1 << i)) {
+			tmp = mv_eth_port_by_id(i);
+			if ((tmp == NULL) || (pp->port == i))
+				continue;
+
+			if (tmp->flags & MV_ETH_F_STARTED) {
+				printk(KERN_ERR "Port %d use pool #%d and must be stopped before changing mtu\n",
+					tmp->port, port_pool->pool);
+				return -EPERM;
+			}
+		}
+	}
+*/
+	/* refill pool with updated buffer size */
+/*	mv_eth_pool_free(port_pool->pool, pkts_num);
+	port_pool->pkt_size = 0;
+	if (mv_eth_attach_long_pool(pp, port_pool, pkts_num, pkt_size))
+		return -1;
+*/
+mtu_out:
+	dev->mtu = mtu;
+	mv_eth_netdev_update_features(dev);
+
+	return 0;
+}
+
+/***********************************************************
+ * mv_eth_tx_done_timer_callback --			   *
+ *   N msec periodic callback for tx_done                  *
+ ***********************************************************/
+static void mv_eth_tx_done_timer_callback(unsigned long data)
+{
+	struct cpu_ctrl *cpuCtrl;
+	struct net_device *dev = (struct net_device *)data;
+	struct eth_port *pp = MV_ETH_PRIV(dev);
+	int tx_done = 0, tx_todo = 0;
+	unsigned int txq_mask;
+
+	STAT_INFO(pp->stats.tx_done_timer++);
+
+	cpuCtrl = pp->cpu_config[smp_processor_id()];
+
+	clear_bit(MV_ETH_F_TX_DONE_TIMER_BIT, &(cpuCtrl->flags));
+
+
+	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
+		STAT_INFO(pp->stats.netdev_stop++);
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+		if (pp->dbg_flags & MV_ETH_F_DBG_TX)
+			printk(KERN_ERR "%s: port #%d is stopped, STARTED_BIT = 0, exit timer.\n", __func__, pp->port);
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+		return;
+	}
+
+	if (MV_PON_PORT(pp->port))
+		tx_done = mv_eth_tx_done_pon(pp, &tx_todo);
+	else {
+		/* check all possible queues, as there is no indication from interrupt */
+		txq_mask = (1 << CONFIG_MV_ETH_TXQ) - 1;
+		tx_done = mv_eth_tx_done_gbe(pp, txq_mask, &tx_todo);
+	}
+
+	if (tx_todo > 0)
+		mv_eth_add_tx_done_timer(cpuCtrl);
+}
+
+/***********************************************************
+ * mv_eth_cleanup_timer_callback --			   *
+ *   N msec periodic callback for error cleanup            *
+ ***********************************************************/
+static void mv_eth_cleanup_timer_callback(unsigned long data)
+{
+	struct cpu_ctrl *cpuCtrl;
+	struct net_device *dev = (struct net_device *)data;
+	struct eth_port *pp = MV_ETH_PRIV(dev);
+
+	STAT_INFO(pp->stats.cleanup_timer++);
+
+	cpuCtrl = pp->cpu_config[smp_processor_id()];
+	clear_bit(MV_ETH_F_CLEANUP_TIMER_BIT, &(cpuCtrl->flags));
+
+	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
+		return;
+
+	/* FIXME: check bm_pool->missed and pp->rxq_ctrl[rxq].missed counters and allocate */
+	/* re-add timer if necessary (check bm_pool->missed and pp->rxq_ctrl[rxq].missed   */
+}
+
+void mv_eth_mac_show(int port)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (pp == NULL) {
+		printk(KERN_ERR "%s: port %d entry is null \n", __func__, port);
+		return;
+	}
+
+	/* TODO - example in NETA */
+}
+
+/********************************************/
+/*		DSCP API		    */
+/********************************************/
+void mv_eth_dscp_map_show(int port)
+{
+	int dscp, txq;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (pp == NULL) {
+		printk(KERN_ERR "%s: port %d entry is null \n", __func__, port);
+		return;
+	}
+
+	/* TODO - call pnc_ipv4_dscp_show() example in NETA */
+
+	printk(KERN_ERR "\n");
+	printk(KERN_ERR " DSCP <=> TXQ map for port #%d\n\n", port);
+	for (dscp = 0; dscp < sizeof(pp->txq_dscp_map); dscp++) {
+		txq = pp->txq_dscp_map[dscp];
+		if (txq != MV_ETH_TXQ_INVALID)
+			printk(KERN_ERR "0x%02x <=> %d\n", dscp, txq);
+	}
+}
+
+int mv_eth_rxq_dscp_map_set(int port, int rxq, unsigned char dscp)
+{
+	/* TBD */
+	printk(KERN_ERR "Not supported\n");
+
+	return MV_FAIL;
+}
+
+/* Set TXQ for special DSCP value. txq=-1 - use default TXQ for this port */
+int mv_eth_txq_dscp_map_set(int port, int txq, unsigned char dscp)
+{
+	MV_U8 old_txq;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (mvPp2PortCheck(port))
+		return -EINVAL;
+
+	if ((pp == NULL) || (pp->txq_ctrl == NULL))
+		return -ENODEV;
+
+	if ((dscp < 0) || (dscp >= 64))
+		return -EINVAL;
+
+	old_txq = pp->txq_dscp_map[dscp];
+
+	/* The same txq - do nothing */
+	if (old_txq == (MV_U8) txq)
+		return 0;
+
+	if (txq == -1) {
+		pp->txq_dscp_map[dscp] = MV_ETH_TXQ_INVALID;
+		return 0;
+	}
+
+	if ((txq < 0) || (txq >= CONFIG_MV_ETH_TXQ))
+		return -EINVAL;
+
+	pp->txq_dscp_map[dscp] = (MV_U8) txq;
+
+	return 0;
+}
+
+/********************************************/
+
+void mv_eth_vlan_prio_show(int port)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	if (pp == NULL) {
+		printk(KERN_ERR "%s: port %d entry is null \n", __func__, port);
+		return;
+	}
+
+	/* TODO - example in NETA */
+}
+
+int mv_eth_rxq_vlan_prio_set(int port, int rxq, unsigned char prio)
+{
+	int status = -1;
+	/*
+	TODO - example in NETA
+	status = pnc_vlan_prio_set(port, prio, rxq);
+	*/
+
+	if (status == 0)
+		printk(KERN_ERR "Succeeded\n");
+	else if (status == -1)
+		printk(KERN_ERR "Not supported\n");
+	else
+		printk(KERN_ERR "Failed\n");
+
+	return status;
+}
+
+
+static int mv_eth_priv_init(struct eth_port *pp, int port)
+{
+	static int first_rxq = 0;
+	int cpu, i;
+	struct cpu_ctrl	*cpuCtrl;
+	u8	*ext_buf;
+
+	memset(pp, 0, sizeof(struct eth_port));
+
+	/* Default field per cpu initialization */
+	for (i = 0; i < CONFIG_NR_CPUS; i++) {
+		pp->cpu_config[i] = kmalloc(sizeof(struct cpu_ctrl), GFP_KERNEL);
+		memset(pp->cpu_config[i], 0, sizeof(struct cpu_ctrl));
+	}
+
+	pp->port = port;
+	pp->first_rxq = first_rxq;
+	pp->rxq_num = CONFIG_MV_ETH_RXQ;
+	first_rxq += pp->rxq_num;
+	pp->txp_num = 1;
+	pp->txp = 0;
+	for_each_possible_cpu(cpu) {
+		cpuCtrl = pp->cpu_config[cpu];
+		cpuCtrl->txq = CONFIG_MV_ETH_TXQ_DEF;
+	}
+
+	pp->flags = 0;
+
+	pp->pool_long_num = mv_eth_bm_config_long_buf_num_get(port);
+	if (pp->pool_long_num > MV_BM_POOL_CAP_MAX)
+		pp->pool_long_num = MV_BM_POOL_CAP_MAX;
+
+	pp->pool_short_num = mv_eth_bm_config_short_buf_num_get(port);
+	if (pp->pool_short_num > MV_BM_POOL_CAP_MAX)
+		pp->pool_short_num = MV_BM_POOL_CAP_MAX;
+#ifdef CONFIG_MV_ETH_HWF
+	pp->hwf_pool_long_num = mv_eth_bm_config_hwf_long_buf_num_get(pp->port);
+	if (pp->hwf_pool_long_num > MV_BM_POOL_CAP_MAX)
+		pp->hwf_pool_long_num = MV_BM_POOL_CAP_MAX;
+
+	pp->hwf_pool_short_num = mv_eth_bm_config_hwf_short_buf_num_get(pp->port);
+	if (pp->hwf_pool_short_num > MV_BM_POOL_CAP_MAX)
+		pp->hwf_pool_short_num = MV_BM_POOL_CAP_MAX;
+#endif /* CONFIG_MV_ETH_HWF */
+
+
+	for (i = 0; i < 64; i++)
+		pp->txq_dscp_map[i] = MV_ETH_TXQ_INVALID;
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+	pp->tx_special_check = NULL;
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+
+	mv_eth_port_config_parse(pp);
+
+#ifdef CONFIG_MV_PON
+	if (MV_PON_PORT(port)) {
+		set_bit(MV_ETH_F_MH_BIT, &(pp->flags));
+		pp->txp_num = CONFIG_MV_PON_TCONTS;
+		pp->txp = CONFIG_MV_PON_TXP_DEF;
+		for_each_possible_cpu(i)
+			pp->cpu_config[i]->txq = CONFIG_MV_PON_TXQ_DEF;
+	}
+#endif /* CONFIG_MV_PON */
+
+#if defined(CONFIG_MV_ETH_RX_CSUM_OFFLOAD_DEF)
+	pp->rx_csum_offload = 1;
+#endif /* CONFIG_MV_ETH_RX_CSUM_OFFLOAD_DEF */
+
+#ifdef CONFIG_MV_INCLUDE_SWITCH
+	if (mvBoardSwitchConnectedPortGet(port) != -1) {
+		set_bit(MV_ETH_F_SWITCH_BIT, &(pp->flags));
+		set_bit(MV_ETH_F_EXT_SWITCH_BIT, &(pp->flags));
+	}
+#endif /* CONFIG_MV_INCLUDE_SWITCH */
+	for_each_possible_cpu(cpu) {
+		cpuCtrl = pp->cpu_config[cpu];
+		memset(&cpuCtrl->tx_done_timer, 0, sizeof(struct timer_list));
+		cpuCtrl->tx_done_timer.function = mv_eth_tx_done_timer_callback;
+		init_timer(&cpuCtrl->tx_done_timer);
+		clear_bit(MV_ETH_F_TX_DONE_TIMER_BIT, &(cpuCtrl->flags));
+		memset(&cpuCtrl->cleanup_timer, 0, sizeof(struct timer_list));
+		cpuCtrl->cleanup_timer.function = mv_eth_cleanup_timer_callback;
+		init_timer(&cpuCtrl->cleanup_timer);
+		clear_bit(MV_ETH_F_CLEANUP_TIMER_BIT, &(cpuCtrl->flags));
+	}
+
+	pp->weight = CONFIG_MV_ETH_RX_POLL_WEIGHT;
+
+	/* Init pool of external buffers for TSO, fragmentation, etc */
+	spin_lock_init(&pp->extLock);
+	pp->extBufSize = CONFIG_MV_ETH_EXTRA_BUF_SIZE;
+	pp->extArrStack = mvStackCreate(CONFIG_MV_ETH_EXTRA_BUF_NUM);
+	if (pp->extArrStack == NULL) {
+		printk(KERN_ERR "Error: failed create  extArrStack for port #%d\n", port);
+		return -ENOMEM;
+	}
+	for (i = 0; i < CONFIG_MV_ETH_EXTRA_BUF_NUM; i++) {
+		ext_buf = mvOsMalloc(CONFIG_MV_ETH_EXTRA_BUF_SIZE);
+		if (ext_buf == NULL) {
+			printk(KERN_WARNING "%s Warning: %d of %d extra buffers allocated\n",
+				__func__, i, CONFIG_MV_ETH_EXTRA_BUF_NUM);
+			break;
+		}
+		mvStackPush(pp->extArrStack, (MV_U32)ext_buf);
+	}
+
+#ifdef CONFIG_MV_ETH_STAT_DIST
+	pp->dist_stats.rx_dist = mvOsMalloc(sizeof(u32) * (pp->rxq_num * CONFIG_MV_ETH_RXQ_DESC + 1));
+	if (pp->dist_stats.rx_dist != NULL) {
+		pp->dist_stats.rx_dist_size = pp->rxq_num * CONFIG_MV_ETH_RXQ_DESC + 1;
+		memset(pp->dist_stats.rx_dist, 0, sizeof(u32) * pp->dist_stats.rx_dist_size);
+	} else
+		printk(KERN_ERR "ethPort #%d: Can't allocate %d bytes for rx_dist\n",
+		       pp->port, sizeof(u32) * (pp->rxq_num * CONFIG_MV_ETH_RXQ_DESC + 1));
+
+	pp->dist_stats.tx_done_dist =
+	    mvOsMalloc(sizeof(u32) * (pp->txp_num * CONFIG_MV_ETH_TXQ * CONFIG_MV_ETH_TXQ_DESC + 1));
+	if (pp->dist_stats.tx_done_dist != NULL) {
+		pp->dist_stats.tx_done_dist_size = pp->txp_num * CONFIG_MV_ETH_TXQ * CONFIG_MV_ETH_TXQ_DESC + 1;
+		memset(pp->dist_stats.tx_done_dist, 0, sizeof(u32) * pp->dist_stats.tx_done_dist_size);
+	} else
+		printk(KERN_ERR "ethPort #%d: Can't allocate %d bytes for tx_done_dist\n",
+		       pp->port, sizeof(u32) * (pp->txp_num * CONFIG_MV_ETH_TXQ * CONFIG_MV_ETH_TXQ_DESC + 1));
+#endif /* CONFIG_MV_ETH_STAT_DIST */
+
+	return 0;
+}
+
+/***********************************************************************************
+ ***  print RX bm_pool status
+ ***********************************************************************************/
+void mv_eth_napi_groups_print(int port)
+{
+	int i;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+
+	printk(KERN_CONT "NAPI groups:   cpu_mask   rxq_mask   napi_state\n");
+	for (i = 0; i < MV_ETH_MAX_NAPI_GROUPS; i++) {
+		if (!pp->napi_group[i])
+			continue;
+		printk(KERN_ERR "          %d:      0x%02x     0x%04x             %d\n",
+			i, pp->napi_group[i]->cpu_mask, pp->napi_group[i]->rxq_mask,
+			test_bit(NAPI_STATE_SCHED, &pp->napi_group[i]->napi->state));
+	}
+
+	printk(KERN_CONT "\n");
+}
+
+/***********************************************************************************
+ ***  print RX bm_pool status
+ ***********************************************************************************/
+void mv_eth_pool_status_print(int pool)
+{
+	struct bm_pool *bm_pool = &mv_eth_pool[pool];
+
+	printk(KERN_ERR "\nRX Pool #%d: pkt_size=%d, owned by: %s, BM-HW support - %s\n",
+	       pool, bm_pool->pkt_size, bm_pool->is_hwf ? "HWF" : "SW", mv_eth_pool_bm(bm_pool) ? "Yes" : "No");
+
+	printk(KERN_ERR "bm_pool=%p, stack=%p, capacity=%d, buf_num=%d, port_map=0x%x missed=%d\n",
+	       bm_pool->bm_pool, bm_pool->stack, bm_pool->capacity, bm_pool->buf_num,
+		   bm_pool->port_map, bm_pool->missed);
+
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	printk(KERN_ERR "Errors: skb_alloc_oom=%u, stack_empty=%u, stack_full=%u\n",
+	       bm_pool->stats.skb_alloc_oom, bm_pool->stats.stack_empty, bm_pool->stats.stack_full);
+#endif /* #ifdef CONFIG_MV_ETH_STAT_ERR */
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+	printk(KERN_ERR "skb_alloc_ok=%u, bm_put=%u, stack_put=%u, stack_get=%u\n",
+	       bm_pool->stats.skb_alloc_ok, bm_pool->stats.bm_put, bm_pool->stats.stack_put, bm_pool->stats.stack_get);
+
+	printk(KERN_ERR "skb_recycled_ok=%u, skb_recycled_err=%u\n",
+	       bm_pool->stats.skb_recycled_ok, bm_pool->stats.skb_recycled_err);
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+
+	if (bm_pool->stack)
+		mvStackStatus(bm_pool->stack, 0);
+
+	memset(&bm_pool->stats, 0, sizeof(bm_pool->stats));
+}
+
+
+/***********************************************************************************
+ ***  print ext pool status
+ ***********************************************************************************/
+void mv_eth_ext_pool_print(struct eth_port *pp)
+{
+	printk(KERN_ERR "\nExt Pool Stack: bufSize = %u bytes\n", pp->extBufSize);
+	mvStackStatus(pp->extArrStack, 0);
+}
+
+/***********************************************************************************
+ ***  print net device status
+ ***********************************************************************************/
+void mv_eth_netdev_print(struct net_device *dev)
+{
+	struct eth_netdev *dev_priv = MV_DEV_PRIV(dev);
+
+	printk(KERN_ERR "%s net_device status: dev=%p, pp=%p\n\n", dev->name, dev, MV_ETH_PRIV(dev));
+	printk(KERN_ERR "ifIdx=%d, features=0x%x, flags=0x%x, mtu=%u, size=%d, MAC=" MV_MACQUAD_FMT "\n",
+	       dev->ifindex, (unsigned int)(dev->features), (unsigned int)(dev->flags),
+	       dev->mtu, RX_PKT_SIZE(dev->mtu), MV_MACQUAD(dev->dev_addr));
+
+	if (dev_priv)
+		printk(KERN_ERR "group=%d, tx_vlan_mh=0x%04x, switch_port_map=0x%x, switch_port_link_map=0x%x\n",
+		       dev_priv->group, dev_priv->tx_vlan_mh, dev_priv->port_map, dev_priv->link_map);
+}
+
+void mv_eth_status_print(void)
+{
+	printk(KERN_ERR "totals: ports=%d, devs=%d\n", mv_eth_ports_num, mv_net_devs_num);
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+	printk(KERN_ERR "SKB recycle = %s\n", mv_ctrl_recycle ? "Enabled" : "Disabled");
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+}
+
+/***********************************************************************************
+ ***  print Ethernet port status
+ ***********************************************************************************/
+void mv_eth_port_status_print(unsigned int port)
+{
+	int txp, q;
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct tx_queue *txq_ctrl;
+	struct cpu_ctrl	*cpuCtrl;
+
+	if (!pp)
+		return;
+
+	printk(KERN_ERR "\n");
+	printk(KERN_ERR "port=%d, flags=0x%lx, rx_weight=%d\n", port, pp->flags, pp->weight);
+	if ((!(pp->flags & MV_ETH_F_SWITCH)) && (pp->flags & MV_ETH_F_CONNECT_LINUX))
+		printk(KERN_ERR "%s: ", pp->dev->name);
+	else
+		printk(KERN_ERR "port %d: ", port);
+
+	mv_eth_link_status_print(port);
+
+	printk(KERN_ERR "rxq_coal(pkts)[ q]      = ");
+	for (q = 0; q < pp->rxq_num; q++)
+		printk(KERN_CONT "%4d ", mvPp2RxqPktsCoalGet(port, q));
+
+	printk(KERN_CONT "\n");
+	printk(KERN_ERR "rxq_coal(usec)[ q]      = ");
+	for (q = 0; q < pp->rxq_num; q++)
+		printk(KERN_CONT "%4d ", mvPp2RxqTimeCoalGet(port, q));
+
+	printk(KERN_CONT "\n");
+	printk(KERN_ERR "rxq_desc(num)[ q]       = ");
+	for (q = 0; q < pp->rxq_num; q++)
+		printk(KERN_CONT "%4d ", pp->rxq_ctrl[q].rxq_size);
+
+	printk(KERN_CONT "\n");
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		printk(KERN_ERR "txq_coal(pkts)[%2d.q]    = ", txp);
+		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++)
+			printk(KERN_CONT "%4d ", mvPp2TxDonePktsCoalGet(port, txp, q));
+		printk(KERN_CONT "\n");
+
+		printk(KERN_ERR "txq_desc(num) [%2d.q]    = ", txp);
+		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + q];
+			printk(KERN_CONT "%4d ", txq_ctrl->txq_size);
+		}
+		printk(KERN_CONT "\n");
+
+		printk(KERN_ERR "txq_sw_desc(num) [%2d.q] = ", txp);
+		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + q];
+			printk(KERN_CONT "%4d ", txq_ctrl->txq_cpu[0].txq_size); /*TODO: for every cpu?*/
+		}
+		printk(KERN_CONT "\n");
+	}
+	printk(KERN_ERR "\n");
+
+#ifdef CONFIG_MV_ETH_TXDONE_ISR
+	printk(KERN_ERR "Do tx_done in NAPI context triggered by ISR\n");
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		printk(KERN_ERR "txcoal(pkts)[%2d.q] = ", txp);
+		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++)
+			printk(KERN_CONT "%3d ", mvPp2TxDonePktsCoalGet(port, txp, q));
+		printk(KERN_CONT "\n");
+	}
+	printk(KERN_ERR "\n");
+#else
+	printk(KERN_ERR "Do tx_done in TX or Timer context: tx_done_threshold=%d\n", mv_ctrl_txdone);
+#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+
+	printk(KERN_ERR "txp=%d, zero_pad=%s, mh_en=%s (0x%04x), tx_cmd=0x%04x 0x%04x 0x%04x 0x%04x\n",
+		pp->txp, (pp->flags & MV_ETH_F_NO_PAD) ? "Disabled" : "Enabled",
+		(pp->flags & MV_ETH_F_MH) ? "Enabled" : "Disabled",
+		pp->tx_mh, pp->hw_cmd[0], pp->hw_cmd[1], pp->hw_cmd[2], pp->hw_cmd[3]);
+
+	printk(KERN_CONT "\n");
+	printk(KERN_CONT "CPU:   txq_def   napi_group_id\n");
+	{
+		int cpu;
+		for_each_possible_cpu(cpu) {
+			cpuCtrl = pp->cpu_config[cpu];
+			if (MV_BIT_CHECK(pp->cpuMask, cpu))
+				printk(KERN_ERR "  %d:      %d      %d\n",
+					cpu, cpuCtrl->txq, cpuCtrl->napi_group_id);
+		}
+	}
+
+	printk(KERN_CONT "\n");
+
+	mv_eth_napi_groups_print(port);
+#ifdef CONFIG_MV_ETH_SWITCH
+	if (pp->flags & MV_ETH_F_SWITCH)
+		mv_eth_switch_status_print(port);
+#endif /* CONFIG_MV_ETH_SWITCH */
+}
+
+/***********************************************************************************
+ ***  print port statistics
+ ***********************************************************************************/
+
+void mv_eth_port_stats_print(unsigned int port)
+{
+	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct port_stats *stat = NULL;
+	struct tx_queue *txq_ctrl;
+	struct txq_cpu_ctrl *txq_cpu_ptr;
+	int txp, queue, cpu;
+	u32 total_rx_ok, total_rx_fill_ok;
+#ifdef CONFIG_MV_ETH_STAT_INF
+	int i;
+#endif
+
+
+	if (pp == NULL) {
+		printk(KERN_ERR "eth_stats_print: wrong port number %d\n", port);
+		return;
+	}
+	stat = &(pp->stats);
+
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	printk(KERN_ERR "\n====================================================\n");
+	printk(KERN_ERR "ethPort_%d: Errors", port);
+	printk(KERN_CONT "\n-------------------------------\n");
+	printk(KERN_ERR "rx_error......................%10u\n", stat->rx_error);
+	printk(KERN_ERR "tx_timeout....................%10u\n", stat->tx_timeout);
+	printk(KERN_ERR "tx_netif_stop.................%10u\n", stat->netif_stop);
+	printk(KERN_ERR "netif_wake....................%10u\n", stat->netif_wake);
+	printk(KERN_ERR "ext_stack_empty...............%10u\n", stat->ext_stack_empty);
+	printk(KERN_ERR "ext_stack_full ...............%10u\n", stat->ext_stack_full);
+	printk(KERN_ERR "state_err.....................%10u\n", stat->state_err);
+#endif /* CONFIG_MV_ETH_STAT_ERR */
+
+#ifdef CONFIG_MV_ETH_STAT_INF
+	printk(KERN_ERR "\n====================================================\n");
+	printk(KERN_ERR "ethPort_%d: interrupt statistics", port);
+	printk(KERN_CONT "\n-------------------------------\n");
+	printk(KERN_ERR "irq...........................%10u\n", stat->irq);
+	printk(KERN_ERR "irq_err.......................%10u\n", stat->irq_err);
+
+	printk(KERN_ERR "\n====================================================\n");
+	printk(KERN_ERR "ethPort_%d: Events", port);
+	printk(KERN_CONT "\n-------------------------------\n");
+	for (i = 0; i < CONFIG_NR_CPUS; i++) {
+		printk(KERN_ERR "poll[%d]......................%10u\n", i, stat->poll[i]);
+		printk(KERN_ERR "poll_exit[%d].................%10u\n", i, stat->poll_exit[i]);
+	}
+	printk(KERN_ERR "tx_fragmentation..............%10u\n", stat->tx_fragment);
+	printk(KERN_ERR "tx_done_event.................%10u\n", stat->tx_done);
+	printk(KERN_ERR "tx_done_timer_event...........%10u\n", stat->tx_done_timer);
+	printk(KERN_ERR "cleanup_timer_event...........%10u\n", stat->cleanup_timer);
+	printk(KERN_ERR "link..........................%10u\n", stat->link);
+	printk(KERN_ERR "netdev_stop...................%10u\n", stat->netdev_stop);
+#ifdef CONFIG_MV_ETH_RX_SPECIAL
+	printk(KERN_ERR "rx_special....................%10u\n", stat->rx_special);
+#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+	printk(KERN_ERR "tx_special....................%10u\n", stat->tx_special);
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+#endif /* CONFIG_MV_ETH_STAT_INF */
+
+	printk(KERN_ERR "\n");
+	total_rx_ok = total_rx_fill_ok = 0;
+	printk(KERN_ERR "RXQ:       rx_ok      rx_fill_ok     missed\n\n");
+	for (queue = 0; queue < pp->rxq_num; queue++) {
+		u32 rxq_ok = 0, rxq_fill = 0;
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+		rxq_ok = stat->rxq[queue];
+		rxq_fill = stat->rxq_fill[queue];
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+
+		printk(KERN_ERR "%3d:  %10u    %10u          %d\n",
+			queue, rxq_ok, rxq_fill,
+			pp->rxq_ctrl[queue].missed);
+		total_rx_ok += rxq_ok;
+		total_rx_fill_ok += rxq_fill;
+	}
+	printk(KERN_ERR "SUM:  %10u    %10u\n", total_rx_ok, total_rx_fill_ok);
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+	{
+		printk(KERN_ERR "\n====================================================\n");
+		printk(KERN_ERR "ethPort_%d: Debug statistics", port);
+		printk(KERN_CONT "\n-------------------------------\n");
+
+		printk(KERN_ERR "\n");
+		printk(KERN_ERR "rx_gro....................%10u\n", stat->rx_gro);
+		printk(KERN_ERR "rx_gro_bytes .............%10u\n", stat->rx_gro_bytes);
+
+		printk(KERN_ERR "tx_tso....................%10u\n", stat->tx_tso);
+		printk(KERN_ERR "tx_tso_bytes .............%10u\n", stat->tx_tso_bytes);
+
+		printk(KERN_ERR "rx_netif..................%10u\n", stat->rx_netif);
+		printk(KERN_ERR "rx_drop_sw................%10u\n", stat->rx_drop_sw);
+		printk(KERN_ERR "rx_csum_hw................%10u\n", stat->rx_csum_hw);
+		printk(KERN_ERR "rx_csum_sw................%10u\n", stat->rx_csum_sw);
+
+
+		printk(KERN_ERR "tx_skb_free...............%10u\n", stat->tx_skb_free);
+		printk(KERN_ERR "tx_sg.....................%10u\n", stat->tx_sg);
+		printk(KERN_ERR "tx_csum_hw................%10u\n", stat->tx_csum_hw);
+		printk(KERN_ERR "tx_csum_sw................%10u\n", stat->tx_csum_sw);
+
+		printk(KERN_ERR "ext_stack_get.............%10u\n", stat->ext_stack_get);
+		printk(KERN_ERR "ext_stack_put ............%10u\n", stat->ext_stack_put);
+
+		printk(KERN_ERR "\n");
+	}
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+
+	printk(KERN_ERR "\n");
+	printk(KERN_ERR "TXP-TXQ:  count        send          done      no_resource\n\n");
+
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		for (queue = 0; queue < CONFIG_MV_ETH_TXQ; queue++)
+			for_each_possible_cpu(cpu) {
+				u32 txq_tx = 0, txq_txdone = 0, txq_err = 0;
+
+				txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + queue];
+				txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
+#ifdef CONFIG_MV_ETH_STAT_DBG
+				txq_tx = txq_ctrl->stats.txq_tx;
+				txq_txdone =  txq_ctrl->stats.txq_txdone;
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+#ifdef CONFIG_MV_ETH_STAT_ERR
+				txq_err = txq_ctrl->stats.txq_err;
+#endif /* CONFIG_MV_ETH_STAT_ERR */
+
+				printk(KERN_ERR "%d-%d-cpu#%d:      %3d    %10u    %10u    %10u\n",
+				       txp, queue, cpu, txq_cpu_ptr->txq_count, txq_tx,
+				       txq_txdone, txq_err);
+
+				memset(&txq_ctrl->stats, 0, sizeof(txq_ctrl->stats));
+			}
+	}
+	printk(KERN_ERR "\n\n");
+
+	memset(stat, 0, sizeof(struct port_stats));
+
+	/* RX pool statistics */
+	if (pp->pool_short)
+		mv_eth_pool_status_print(pp->pool_short->pool);
+
+	if (pp->pool_long)
+		mv_eth_pool_status_print(pp->pool_long->pool);
+
+		mv_eth_ext_pool_print(pp);
+
+#ifdef CONFIG_MV_ETH_STAT_DIST
+	{
+		int i;
+		struct dist_stats *dist_stats = &(pp->dist_stats);
+
+		if (dist_stats->rx_dist) {
+			printk(KERN_ERR "\n      Linux Path RX distribution\n");
+			for (i = 0; i < dist_stats->rx_dist_size; i++) {
+				if (dist_stats->rx_dist[i] != 0) {
+					printk(KERN_ERR "%3d RxPkts - %u times\n", i, dist_stats->rx_dist[i]);
+					dist_stats->rx_dist[i] = 0;
+				}
+			}
+		}
+
+		if (dist_stats->tx_done_dist) {
+			printk(KERN_ERR "\n      tx-done distribution\n");
+			for (i = 0; i < dist_stats->tx_done_dist_size; i++) {
+				if (dist_stats->tx_done_dist[i] != 0) {
+					printk(KERN_ERR "%3d TxDoneDesc - %u times\n", i, dist_stats->tx_done_dist[i]);
+					dist_stats->tx_done_dist[i] = 0;
+				}
+			}
+		}
+#ifdef CONFIG_MV_ETH_TSO
+		if (dist_stats->tx_tso_dist) {
+			printk(KERN_ERR "\n      TSO stats\n");
+			for (i = 0; i < dist_stats->tx_tso_dist_size; i++) {
+				if (dist_stats->tx_tso_dist[i] != 0) {
+					printk(KERN_ERR "%3d KBytes - %u times\n", i, dist_stats->tx_tso_dist[i]);
+					dist_stats->tx_tso_dist[i] = 0;
+				}
+			}
+		}
+#endif /* CONFIG_MV_ETH_TSO */
+	}
+#endif /* CONFIG_MV_ETH_STAT_DIST */
+}
+
+
+static int mv_eth_port_cleanup(int port)
+{
+	int txp, txq, rxq, i;
+	struct eth_port *pp;
+	struct tx_queue *txq_ctrl;
+	struct rx_queue *rxq_ctrl;
+
+	pp = mv_eth_port_by_id(port);
+
+	if (pp == NULL)
+		return -1;
+
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "%s: port %d is started, cannot cleanup\n", __func__, port);
+		return -1;
+	}
+
+	/* Reset Tx ports */
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		if (mv_eth_txp_clean(port, txp))
+			printk(KERN_ERR "Warning: Port %d Tx port %d reset failed\n", port, txp);
+	}
+
+	/* Delete Tx queues */
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+			mv_eth_txq_delete(pp, txq_ctrl);
+		}
+	}
+
+	mvOsFree(pp->txq_ctrl);
+	pp->txq_ctrl = NULL;
+
+#ifdef CONFIG_MV_ETH_STAT_DIST
+	/* Free Tx Done distribution statistics */
+	mvOsFree(pp->dist_stats.tx_done_dist);
+#endif
+
+	/* Reset RX ports */
+	if (mv_eth_rx_reset(port))
+		printk(KERN_ERR "Warning: Rx port %d reset failed\n", port);
+
+	/* Delete Rx queues */
+	for (rxq = 0; rxq < pp->rxq_num; rxq++) {
+		rxq_ctrl = &pp->rxq_ctrl[rxq];
+		mvPp2RxqDelete(pp->port, rxq);
+		rxq_ctrl->q = NULL;
+	}
+
+	mvOsFree(pp->rxq_ctrl);
+	pp->rxq_ctrl = NULL;
+
+#ifdef CONFIG_MV_ETH_STAT_DIST
+	/* Free Rx distribution statistics */
+	mvOsFree(pp->dist_stats.rx_dist);
+#endif
+
+	/* Free buffer pools */
+	if (pp->pool_long) {
+		mv_eth_pool_free(pp->pool_long->pool, pp->pool_long_num);
+		pp->pool_long->port_map &= ~(1 << pp->port);
+		if (!pp->pool_long->port_map)
+			pp->pool_long->is_hwf = 0;
+		pp->pool_long = NULL;
+	}
+	if (pp->pool_short) {
+		mv_eth_pool_free(pp->pool_short->pool, pp->pool_short_num);
+		pp->pool_short->port_map &= ~(1 << pp->port);
+		if (!pp->pool_short->port_map)
+			pp->pool_short->is_hwf = 0;
+		pp->pool_short = NULL;
+	}
+
+	/* Clear Marvell Header related modes - will be set again if needed on re-init */
+	mvPp2MhSet(port, MV_PP2_MH_NONE);
+
+	/* Clear any forced link, speed and duplex */
+	mv_eth_port_link_speed_fc(port, MV_ETH_SPEED_AN, 0);
+
+	mvPp2PortDestroy(port);
+
+	if (pp->flags & MV_ETH_F_CONNECT_LINUX)
+		for (i = 0; i < MV_ETH_MAX_NAPI_GROUPS; i++)
+			mv_eth_port_napi_group_delete(pp->port, i);
+
+	return 0;
+}
+
+
+int mv_eth_all_ports_cleanup(void)
+{
+	int port, pool, status = 0;
+
+	for (port = 0; port < mv_eth_ports_num; port++) {
+		status = mv_eth_port_cleanup(port);
+		if (status != 0) {
+			printk(KERN_ERR "Error: mv_eth_port_cleanup failed on port %d, stopping all ports cleanup\n", port);
+			return status;
+		}
+	}
+
+	for (pool = 0; pool < MV_ETH_BM_POOLS; pool++)
+		mv_eth_pool_destroy(pool);
+
+	for (port = 0; port < mv_eth_ports_num; port++) {
+		if (mv_eth_ports[port])
+			mvOsFree(mv_eth_ports[port]);
+	}
+
+	memset(mv_eth_ports, 0, (mv_eth_ports_num * sizeof(struct eth_port *)));
+	/* Note: not freeing mv_eth_ports - we will reuse them */
+
+	return 0;
+}
+
+
+#ifdef CONFIG_MV_PON
+/* PON link status api */
+PONLINKSTATUSPOLLFUNC pon_link_status_polling_func;
+
+void pon_link_status_notify_func(MV_BOOL link_state)
+{
+	struct eth_port *pon_port = mv_eth_port_by_id(MV_PON_LOGIC_PORT_GET());
+	mv_eth_link_event(pon_port, 1);
+}
+
+/* called by PON module */
+void mv_pon_link_state_register(PONLINKSTATUSPOLLFUNC poll_func, PONLINKSTATUSNOTIFYFUNC *notify_func)
+{
+	pon_link_status_polling_func = poll_func;
+	*notify_func = pon_link_status_notify_func;
+}
+
+MV_BOOL mv_pon_link_status(void)
+{
+	/*TODO*/
+	return MV_TRUE;
+
+	if (pon_link_status_polling_func != NULL)
+		return pon_link_status_polling_func();
+	printk(KERN_ERR "pon_link_status_polling_func is uninitialized\n");
+	return MV_FALSE;
+}
+#endif /* CONFIG_MV_PON */
+
+/* Support for platform driver */
+
+#ifdef CONFIG_CPU_IDLE
+
+
+int mv_eth_suspend_clock(int port)
+{
+/* TBD */
+	return 0;
+}
+
+
+int mv_eth_suspend(struct platform_device *pdev, pm_message_t state)
+{
+/* TBD */
+	return 0;
+}
+
+
+int mv_eth_resume_clock(int port)
+{
+/* TBD */
+	return 0;
+}
+
+
+int mv_eth_resume(struct platform_device *pdev)
+{
+/* TBD */
+	return 0;
+
+}
+
+#endif	/* CONFIG_CPU_IDLE */
+
+static int mv_eth_remove(struct platform_device *pdev)
+{
+    printk(KERN_INFO "Removing Marvell Ethernet Driver\n");
+    return 0;
+}
+
+static void mv_eth_shutdown(struct platform_device *pdev)
+{
+    printk(KERN_INFO "Shutting Down Marvell Ethernet Driver\n");
+}
+
+static struct platform_driver mv_eth_driver = {
+	.probe = mv_eth_probe,
+	.remove = mv_eth_remove,
+	.shutdown = mv_eth_shutdown,
+#ifdef CONFIG_CPU_IDLE
+	.suspend = mv_eth_suspend,
+	.resume = mv_eth_resume,
+#endif /* CONFIG_CPU_IDLE */
+	.driver = {
+		.name = MV_PP2_PORT_NAME,
+	},
+};
+
+static int __init mv_eth_init_module(void)
+{
+	return platform_driver_register(&mv_eth_driver);
+}
+module_init(mv_eth_init_module);
+
+static void __exit mv_eth_cleanup_module(void)
+{
+	platform_driver_unregister(&mv_eth_driver);
+}
+module_exit(mv_eth_cleanup_module);
+
+
+MODULE_DESCRIPTION("Marvell Ethernet Driver - www.marvell.com");
+MODULE_AUTHOR("Dmitri Epshtein <dima@marvell.com>");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
new file mode 100644
index 0000000..9675cf9
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
@@ -0,0 +1,859 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#ifndef __mv_netdev_h__
+#define __mv_netdev_h__
+
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <net/ip.h>
+
+#include "mvCommon.h"
+#include "mvOs.h"
+#include "mv802_3.h"
+#include "mvStack.h"
+
+#include "gbe/mvPp2Gbe.h"
+#include "bm/mvBmRegs.h"
+#include "bm/mvBm.h"
+
+#ifdef CONFIG_SMP
+# define MV_ETH_MAX_CPU CONFIG_NR_CPUS
+#else
+# define MV_ETH_MAX_CPU 1
+#endif
+
+/******************************************************
+ * driver statistics control --                       *
+ ******************************************************/
+#ifdef CONFIG_MV_ETH_STAT_ERR
+#define STAT_ERR(c) c
+#else
+#define STAT_ERR(c)
+#endif
+
+#ifdef CONFIG_MV_ETH_STAT_INF
+#define STAT_INFO(c) c
+#else
+#define STAT_INFO(c)
+#endif
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+#define STAT_DBG(c) c
+#else
+#define STAT_DBG(c)
+#endif
+
+#ifdef CONFIG_MV_ETH_STAT_DIST
+#define STAT_DIST(c) c
+#else
+#define STAT_DIST(c)
+#endif
+
+extern int mv_ctrl_txdone;
+
+/****************************************************************************
+ * Rx buffer size: MTU + 2(Marvell Header) + 4(VLAN) + 14(MAC hdr) + 4(CRC) *
+ ****************************************************************************/
+#define RX_PKT_SIZE(mtu) \
+		MV_ALIGN_UP((mtu) + 2 + 4 + ETH_HLEN + 4, CPU_D_CACHE_LINE_SIZE)
+
+#define RX_BUF_SIZE(pkt_size)   	((pkt_size) + NET_SKB_PAD)
+#define RX_HWF_PKT_OFFS			32
+#define RX_HWF_BUF_SIZE(pkt_size)   	((pkt_size) + RX_HWF_PKT_OFFS)
+
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+extern int mv_ctrl_recycle;
+
+#define mv_eth_is_recycle()     (mv_ctrl_recycle)
+int mv_eth_skb_recycle(struct sk_buff *skb);
+#else
+#define mv_eth_is_recycle()     0
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+
+
+/******************************************************
+ * interrupt control --                               *
+ ******************************************************/
+#define MV_ETH_TRYLOCK(lock, flags)                           \
+	(in_interrupt() ? spin_trylock((lock)) :              \
+		spin_trylock_irqsave((lock), (flags)))
+
+#define MV_ETH_LOCK(lock, flags)                              \
+{                                                             \
+	if (in_interrupt())                                   \
+		spin_lock((lock));                            \
+	else                                                  \
+		spin_lock_irqsave((lock), (flags));           \
+}
+
+#define MV_ETH_UNLOCK(lock, flags)                            \
+{                                                             \
+	if (in_interrupt())                                   \
+		spin_unlock((lock));                          \
+	else                                                  \
+		spin_unlock_irqrestore((lock), (flags));      \
+}
+
+#define MV_ETH_LIGHT_LOCK(flags)                              \
+	if (!in_interrupt())                                  \
+		local_irq_save(flags);
+
+#define MV_ETH_LIGHT_UNLOCK(flags)	                      \
+	if (!in_interrupt())                                  \
+		local_irq_restore(flags);
+
+/******************************************************
+ * rx / tx queues --                                  *
+ ******************************************************/
+/*
+ * Debug statistics
+ */
+
+struct txq_stats {
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	u32 txq_err;
+#endif /* CONFIG_MV_ETH_STAT_ERR */
+#ifdef CONFIG_MV_ETH_STAT_DBG
+	u32 txq_tx;
+	u32 txq_txdone;
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+};
+
+struct port_stats {
+
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	u32 rx_error;
+	u32 tx_timeout;
+	u32 netif_stop;
+	u32 ext_stack_empty;
+	u32 ext_stack_full;
+	u32 netif_wake;
+	u32 state_err;
+#endif /* CONFIG_MV_ETH_STAT_ERR */
+
+#ifdef CONFIG_MV_ETH_STAT_INF
+	u32 irq;
+	u32 irq_err;
+	u32 poll[CONFIG_NR_CPUS];
+	u32 poll_exit[CONFIG_NR_CPUS];
+	u32 tx_fragment;
+	u32 tx_done;
+	u32 tx_done_timer;
+	u32 cleanup_timer;
+	u32 link;
+	u32 netdev_stop;
+
+#ifdef CONFIG_MV_ETH_RX_SPECIAL
+	u32 rx_special;
+#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+	u32	tx_special;
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+
+#endif /* CONFIG_MV_ETH_STAT_INF */
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+	u32 rxq[CONFIG_MV_ETH_RXQ];
+	u32 rxq_fill[CONFIG_MV_ETH_RXQ];
+	u32 rx_netif;
+	u32 rx_gro;
+	u32 rx_gro_bytes;
+	u32 rx_drop_sw;
+	u32 rx_csum_hw;
+	u32 rx_csum_sw;
+	u32 tx_csum_hw;
+	u32 tx_csum_sw;
+	u32 tx_skb_free;
+	u32 tx_sg;
+	u32 tx_tso;
+	u32 tx_tso_bytes;
+	u32 ext_stack_put;
+	u32 ext_stack_get;
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+};
+
+/* Used for define type of data saved in shadow: SKB or eth_pbuf or nothing */
+#define MV_ETH_SHADOW_SKB		0x1
+#define MV_ETH_SHADOW_EXT		0x2
+
+/* Masks used for pp->flags */
+#define MV_ETH_F_STARTED_BIT        0
+#define MV_ETH_F_SWITCH_BIT         1	/* port is connected to the Switch using the Gateway driver */
+#define MV_ETH_F_MH_BIT             2
+#define MV_ETH_F_NO_PAD_BIT         3
+#define MV_ETH_F_EXT_SWITCH_BIT	    4	/* port is connected to the Switch without the Gateway driver */
+#define MV_ETH_F_CONNECT_LINUX_BIT  5	/* port is connected to Linux netdevice */
+#define MV_ETH_F_LINK_UP_BIT        6
+#define MV_ETH_F_SUSPEND_BIT        7
+#define MV_ETH_F_STARTED_OLD_BIT    8 /*STARTED_BIT value before suspend */
+
+#define MV_ETH_F_STARTED           (1 << MV_ETH_F_STARTED_BIT)
+#define MV_ETH_F_SWITCH            (1 << MV_ETH_F_SWITCH_BIT)
+#define MV_ETH_F_MH                (1 << MV_ETH_F_MH_BIT)
+#define MV_ETH_F_NO_PAD            (1 << MV_ETH_F_NO_PAD_BIT)
+#define MV_ETH_F_EXT_SWITCH        (1 << MV_ETH_F_EXT_SWITCH_BIT)
+#define MV_ETH_F_CONNECT_LINUX     (1 << MV_ETH_F_CONNECT_LINUX_BIT)
+#define MV_ETH_F_LINK_UP           (1 << MV_ETH_F_LINK_UP_BIT)
+#define MV_ETH_F_SUSPEND           (1 << MV_ETH_F_SUSPEND_BIT)
+#define MV_ETH_F_STARTED_OLD       (1 << MV_ETH_F_STARTED_OLD_BIT)
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+/* Masks used for pp->dbg_flags */
+#define MV_ETH_F_DBG_RX_BIT         0
+#define MV_ETH_F_DBG_TX_BIT         1
+#define MV_ETH_F_DBG_DUMP_BIT       2
+#define MV_ETH_F_DBG_ISR_BIT        3
+#define MV_ETH_F_DBG_POLL_BIT       4
+
+#define MV_ETH_F_DBG_RX            (1 << MV_ETH_F_DBG_RX_BIT)
+#define MV_ETH_F_DBG_TX            (1 << MV_ETH_F_DBG_TX_BIT)
+#define MV_ETH_F_DBG_DUMP          (1 << MV_ETH_F_DBG_DUMP_BIT)
+#define MV_ETH_F_DBG_ISR           (1 << MV_ETH_F_DBG_ISR_BIT)
+#define MV_ETH_F_DBG_POLL          (1 << MV_ETH_F_DBG_POLL_BIT)
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+/* Masks used for cpu_ctrl->flags */
+#define MV_ETH_F_TX_DONE_TIMER_BIT  0
+#define MV_ETH_F_CLEANUP_TIMER_BIT  1
+
+#define MV_ETH_F_TX_DONE_TIMER		(1 << MV_ETH_F_TX_DONE_TIMER_BIT)	/* 0x01 */
+#define MV_ETH_F_CLEANUP_TIMER		(1 << MV_ETH_F_CLEANUP_TIMER_BIT)	/* 0x02 */
+
+
+#define MV_ETH_TXQ_INVALID	0xFF
+
+#define TOS_TO_DSCP(tos)	((tos >> 2) & 0x3F)
+
+struct mv_eth_tx_spec {
+	u16		hw_cmd[4];	/* tx_desc offset = 0x10 */
+	u16		flags;
+	u8		txp;
+	u8		txq;
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+	void		(*tx_func) (u8 *data, int size, struct mv_eth_tx_spec *tx_spec);
+#endif
+};
+
+struct txq_cpu_ctrl {
+	int 			txq_size;
+	int			txq_count;
+	u32			*shadow_txq; /* can be MV_ETH_PKT* or struct skbuf* */
+	int			shadow_txq_put_i;
+	int			shadow_txq_get_i;
+	struct txq_stats    	stats;
+};
+
+struct tx_queue {
+	MV_PP2_PHYS_TXQ_CTRL	*q;
+	u8                  	txp;
+	u8                  	txq;
+	int                 	txq_size;
+	int                 	hwf_size;
+	struct txq_cpu_ctrl	txq_cpu[CONFIG_NR_CPUS];
+	struct txq_stats    	stats;
+	spinlock_t          	queue_lock;
+	MV_U32              	txq_done_pkts_coal;
+	unsigned long       flags;
+};
+
+struct aggr_tx_queue {
+	MV_PP2_AGGR_TXQ_CTRL	*q;
+	int                 	txq_size;
+	int                 	txq_count;
+	struct txq_stats    	stats;
+	MV_U32              	txq_done_pkts_coal;
+};
+
+struct rx_queue {
+	MV_PP2_PHYS_RXQ_CTRL	*q;
+	int                 	rxq_size;
+	int                 	missed;
+	MV_U32	            	rxq_pkts_coal;
+	MV_U32	            	rxq_time_coal;
+};
+
+struct dist_stats {
+	u32     *rx_dist;
+	int     rx_dist_size;
+	u32     *tx_done_dist;
+	int     tx_done_dist_size;
+	u32     *tx_tso_dist;
+	int     tx_tso_dist_size;
+};
+
+struct cpu_ctrl {
+	int			napi_group_id;
+	int             	txq;
+	struct timer_list   	tx_done_timer;
+	struct timer_list   	cleanup_timer;
+	unsigned long       	flags;
+};
+
+struct napi_group_ctrl {
+	MV_U8			cpu_mask;
+	MV_U16			rxq_mask;
+	MV_U32			cause_rx_tx;
+	struct napi_struct	*napi;
+};
+
+struct eth_port {
+	int                 port;
+	MV_PP2_PORT_CTRL   *port_ctrl;
+	struct rx_queue     *rxq_ctrl;
+	struct tx_queue     *txq_ctrl;
+	int                 txp_num;
+	int		    first_rxq;
+	int 		    rxq_num;
+	struct net_device   *dev;
+	rwlock_t            rwlock;
+	struct bm_pool      *pool_long;
+	int                 pool_long_num;
+	struct bm_pool      *pool_short;
+	int                 pool_short_num;
+#ifdef CONFIG_MV_ETH_HWF
+	struct bm_pool      *hwf_pool_long;
+	int                 hwf_pool_long_num;
+	struct bm_pool      *hwf_pool_short;
+	int                 hwf_pool_short_num;
+#endif /* CONFIG_MV_ETH_HWF */
+	struct napi_group_ctrl *napi_group[MV_ETH_MAX_RXQ];
+	unsigned long       flags;	/* MH, TIMER, etc. */
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	u8		    dbg_flags;
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+	u16                 hw_cmd[4];	/* offset 0x10 in TX descriptor */
+	int                 txp;
+	u16                 tx_mh;	/* 2B MH */
+	struct port_stats   stats;
+	struct dist_stats   dist_stats;
+	int                 weight;
+	MV_STACK            *extArrStack;
+	int                 extBufSize;
+	spinlock_t          extLock;
+	MV_U8  		    txq_dscp_map[64];
+
+#ifdef CONFIG_MV_ETH_TOOL
+	__u16               speed_cfg;
+	__u8                duplex_cfg;
+	__u8                autoneg_cfg;
+	__u16		    advertise_cfg;
+#endif/* CONFIG_MV_ETH_TOOL */
+#ifdef CONFIG_MV_ETH_RX_CSUM_OFFLOAD
+	MV_U32              rx_csum_offload;
+#endif /* CONFIG_MV_ETH_RX_CSUM_OFFLOAD */
+#ifdef CONFIG_MV_ETH_RX_SPECIAL
+	void    (*rx_special_proc)(int port, int rxq, struct net_device *dev,
+					struct sk_buff *skb, struct pp2_rx_desc *rx_desc);
+#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+	int     (*tx_special_check)(int port, struct net_device *dev, struct sk_buff *skb,
+					struct mv_eth_tx_spec *tx_spec_out);
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+	MV_U32 cpuMask;
+	MV_U32 rx_indir_table[256];
+	struct cpu_ctrl	*cpu_config[CONFIG_NR_CPUS];
+	MV_U32  sgmii_serdes;
+	int	pm_mode;
+};
+
+enum eth_pm_mode {
+	MV_ETH_PM_WOL = 0,
+	MV_ETH_PM_CLOCK,
+	MV_ETH_PM_DISABLE,
+	MV_ETH_PM_LAST
+};
+
+struct eth_netdev {
+	u16     tx_vlan_mh;		/* 2B MH */
+	u16     vlan_grp_id;		/* vlan group ID */
+	u16     port_map;		/* switch port map */
+	u16     link_map;		/* switch port link map */
+	u16     cpu_port;		/* switch CPU port */
+	u16     group;
+};
+
+struct eth_dev_priv {
+	struct eth_port     *port_p;
+	struct eth_netdev   *netdev_p;
+};
+
+#define MV_ETH_PRIV(dev)        (((struct eth_dev_priv *)(netdev_priv(dev)))->port_p)
+#define MV_DEV_PRIV(dev)        (((struct eth_dev_priv *)(netdev_priv(dev)))->netdev_p)
+#define MV_DEV_STAT(dev)        (&((dev)->stats))
+
+/* define which Switch ports are relevant */
+#define SWITCH_CONNECTED_PORTS_MASK	0x7F
+
+#define MV_SWITCH_ID_0			0
+#define MV_ETH_PORT_0			0
+#define MV_ETH_PORT_1			1
+
+struct pool_stats {
+#ifdef CONFIG_MV_ETH_STAT_ERR
+	u32 skb_alloc_oom;
+	u32 stack_empty;
+	u32 stack_full;
+#endif /* CONFIG_MV_ETH_STAT_ERR */
+
+#ifdef CONFIG_MV_ETH_STAT_DBG
+	u32 bm_put;
+	u32 stack_put;
+	u32 stack_get;
+	u32 skb_alloc_ok;
+	u32 skb_recycled_ok;
+	u32 skb_recycled_err;
+#endif /* CONFIG_MV_ETH_STAT_DBG */
+};
+
+struct bm_pool {
+	int         pool;
+	int 	    is_hwf;
+	int         capacity;
+	int         buf_num;
+	int         pkt_size;
+	u32         *bm_pool;
+	MV_STACK    *stack;
+	spinlock_t  lock;
+	u32         port_map;
+	int         missed;		/* FIXME: move to stats */
+	struct pool_stats  stats;
+};
+
+#define MV_ETH_BM_POOLS	        MV_BM_POOLS
+#define mv_eth_pool_bm(p)       (p->bm_pool)
+
+MV_STATUS mv_eth_bm_config_get(void);
+int mv_eth_bm_config_is_hwf_pool(int pool);
+int mv_eth_bm_config_pkt_size_get(int pool);
+int mv_eth_bm_config_pkt_size_set(int pool, int pkt_size);
+int mv_eth_bm_config_short_pool_get(int port);
+int mv_eth_bm_config_short_buf_num_get(int port);
+int mv_eth_bm_config_long_pool_get(int port);
+int mv_eth_bm_config_long_buf_num_get(int port);
+int mv_eth_bm_config_hwf_short_pool_get(int port);
+int mv_eth_bm_config_hwf_short_buf_num_get(int port);
+int mv_eth_bm_config_hwf_long_pool_get(int port);
+int mv_eth_bm_config_hwf_long_buf_num_get(int port);
+void mv_eth_bm_config_print(void);
+
+extern struct bm_pool mv_eth_pool[MV_ETH_BM_POOLS];
+extern struct eth_port **mv_eth_ports;
+
+static inline void mv_eth_interrupts_unmask(struct eth_port *pp)
+{
+	int cpu = smp_processor_id(), group_id;
+	struct napi_group_ctrl *napi_group;
+
+	group_id = pp->cpu_config[cpu]->napi_group_id;
+	if (group_id < 0)
+		return;
+	napi_group = pp->napi_group[group_id];
+
+	/* unmask interrupts - for RX unmask only RXQs that are in the same napi group */
+#ifdef CONFIG_MV_ETH_TXDONE_ISR
+	mvPp2GbeIsrRxTxUnmask(pp->port, napi_group->rxq_mask, 1 /* unmask TxDone interrupts */);
+#else
+	mvPp2GbeIsrRxTxUnmask(pp->port, napi_group->rxq_mask, 0 /* mask TxDone interrupts */);
+#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+}
+
+static inline void mv_eth_interrupts_mask(struct eth_port *pp)
+{
+	mvPp2GbeIsrRxTxMask(pp->port);
+}
+
+static inline int mv_eth_ctrl_is_tx_enabled(struct eth_port *pp)
+{
+	if (!pp)
+		return -ENODEV;
+
+	if (pp->flags & MV_ETH_F_CONNECT_LINUX)
+		return 1;
+
+	return 0;
+}
+
+/*
+	Check if there are enough descriptors in physical TXQ.
+
+	return: 0 - not enough descriptors,  1 - enough descriptors
+*/
+static inline int mv_eth_phys_desc_num_check(struct txq_cpu_ctrl *txq_ctrl, int num)
+{
+	if ((txq_ctrl->txq_count + num) >= txq_ctrl->txq_size) {
+		/*
+		printk(KERN_ERR "eth_tx: txq_ctrl->txq=%d - no_resource: txq_count=%d, txq_size=%d, num=%d\n",
+			txq_ctrl->txq, txq_ctrl->txq_count, txq_ctrl->txq_size, num);
+		*/
+		STAT_ERR(txq_ctrl->stats.txq_err++);
+		return 0;
+	}
+	return 1;
+}
+
+/*
+	Check if there are enough descriptors in aggregated TXQ.
+	If not enough, then try to update number of occupied aggr descriptors and check again.
+
+	return: 0 - not enough descriptors,  1 - enough descriptors
+*/
+static inline int mv_eth_aggr_desc_num_check(struct aggr_tx_queue *aggr_txq_ctrl, int num)
+{
+	/* Is enough aggregated TX descriptors to send packet */
+	if ((aggr_txq_ctrl->txq_count + num) >= aggr_txq_ctrl->txq_size) {
+		/* update number of available aggregated TX descriptors */
+		aggr_txq_ctrl->txq_count = mvPp2AggrTxqPendDescNumGet(smp_processor_id());
+	}
+	/* Is enough aggregated descriptors */
+	if ((aggr_txq_ctrl->txq_count + num) >= aggr_txq_ctrl->txq_size) {
+		/*
+		printk(KERN_ERR "eth_tx: txq_ctrl->txq=%d - no_resource: txq_count=%d, txq_size=%d, num=%d\n",
+			txq_ctrl->txq, txq_ctrl->txq_count, txq_ctrl->txq_size, num);
+		*/
+		STAT_ERR(aggr_txq_ctrl->stats.txq_err++);
+		return 0;
+	}
+
+	return 1;
+}
+
+static inline void mv_eth_tx_desc_flush(struct pp2_tx_desc *tx_desc)
+{
+#if defined(MV_CPU_BE)
+	/*mvNetaTxqDescSwap(tx_desc);*/
+#endif /* MV_CPU_BE */
+
+	mvOsCacheLineFlush(NULL, tx_desc);
+}
+
+static inline void *mv_eth_extra_pool_get(struct eth_port *pp)
+{
+	void *ext_buf;
+
+	spin_lock(&pp->extLock);
+	if (mvStackIndex(pp->extArrStack) == 0) {
+		STAT_ERR(pp->stats.ext_stack_empty++);
+		ext_buf = mvOsMalloc(CONFIG_MV_ETH_EXTRA_BUF_SIZE);
+	} else {
+		STAT_DBG(pp->stats.ext_stack_get++);
+		ext_buf = (void *)mvStackPop(pp->extArrStack);
+	}
+	spin_unlock(&pp->extLock);
+
+	return ext_buf;
+}
+
+static inline int mv_eth_extra_pool_put(struct eth_port *pp, void *ext_buf)
+{
+	spin_lock(&pp->extLock);
+	if (mvStackIsFull(pp->extArrStack)) {
+		STAT_ERR(pp->stats.ext_stack_full++);
+		spin_unlock(&pp->extLock);
+		mvOsFree(ext_buf);
+		return 1;
+	}
+	mvStackPush(pp->extArrStack, (MV_U32)ext_buf);
+	STAT_DBG(pp->stats.ext_stack_put++);
+	spin_unlock(&pp->extLock);
+	return 0;
+}
+
+static inline void mv_eth_add_cleanup_timer(struct cpu_ctrl *cpuCtrl)
+{
+	if (test_and_set_bit(MV_ETH_F_CLEANUP_TIMER_BIT, &(cpuCtrl->flags)) == 0) {
+		cpuCtrl->cleanup_timer.expires = jiffies + ((HZ * CONFIG_MV_ETH_CLEANUP_TIMER_PERIOD) / 1000); /* ms */
+		add_timer(&cpuCtrl->cleanup_timer);
+	}
+}
+
+static inline void mv_eth_add_tx_done_timer(struct cpu_ctrl *cpuCtrl)
+{
+	if (test_and_set_bit(MV_ETH_F_TX_DONE_TIMER_BIT, &(cpuCtrl->flags)) == 0) {
+
+		cpuCtrl->tx_done_timer.expires = jiffies + ((HZ * CONFIG_MV_ETH_TX_DONE_TIMER_PERIOD) / 1000); /* ms */
+		add_timer(&cpuCtrl->tx_done_timer);
+	}
+}
+
+static inline void mv_eth_shadow_inc_get(struct txq_cpu_ctrl *txq_cpu)
+{
+	txq_cpu->shadow_txq_get_i++;
+	if (txq_cpu->shadow_txq_get_i == txq_cpu->txq_size)
+		txq_cpu->shadow_txq_get_i = 0;
+}
+
+static inline void mv_eth_shadow_inc_put(struct txq_cpu_ctrl *txq_cpu)
+{
+	txq_cpu->shadow_txq_put_i++;
+	if (txq_cpu->shadow_txq_put_i == txq_cpu->txq_size)
+		txq_cpu->shadow_txq_put_i = 0;
+}
+
+static inline void mv_eth_shadow_dec_put(struct txq_cpu_ctrl *txq_cpu)
+{
+	if (txq_cpu->shadow_txq_put_i == 0)
+		txq_cpu->shadow_txq_put_i = txq_cpu->txq_size - 1;
+	else
+		txq_cpu->shadow_txq_put_i--;
+}
+
+static inline u32 mv_eth_shadow_get_pop(struct txq_cpu_ctrl *txq_cpu)
+{
+	u32 res = txq_cpu->shadow_txq[txq_cpu->shadow_txq_get_i];
+
+	txq_cpu->shadow_txq_get_i++;
+	if (txq_cpu->shadow_txq_get_i == txq_cpu->txq_size)
+		txq_cpu->shadow_txq_get_i = 0;
+	return res;
+}
+
+static inline void mv_eth_shadow_push(struct txq_cpu_ctrl *txq_cpu, int val)
+{
+	txq_cpu->shadow_txq[txq_cpu->shadow_txq_put_i] = val;
+	txq_cpu->shadow_txq_put_i++;
+	if (txq_cpu->shadow_txq_put_i == txq_cpu->txq_size)
+		txq_cpu->shadow_txq_put_i = 0;
+}
+
+/* Free pkt + skb pair */
+static inline void mv_eth_pkt_free(struct eth_pbuf *pkt)
+{
+	struct sk_buff *skb = (struct sk_buff *)pkt->osInfo;
+
+#ifdef CONFIG_NET_SKB_RECYCLE
+	skb->skb_recycle = NULL;
+	skb->hw_cookie = NULL;
+#endif /* CONFIG_NET_SKB_RECYCLE */
+
+	dev_kfree_skb_any(skb);
+	mvOsFree(pkt);
+}
+
+static inline int mv_eth_pool_put(struct bm_pool *pool, struct eth_pbuf *pkt)
+{
+	unsigned long flags = 0;
+
+	MV_ETH_LOCK(&pool->lock, flags);
+	if (mvStackIsFull(pool->stack)) {
+		STAT_ERR(pool->stats.stack_full++);
+		MV_ETH_UNLOCK(&pool->lock, flags);
+
+		/* free pkt+skb */
+		mv_eth_pkt_free(pkt);
+		return 1;
+	}
+	mvStackPush(pool->stack, (MV_U32) pkt);
+	STAT_DBG(pool->stats.stack_put++);
+	MV_ETH_UNLOCK(&pool->lock, flags);
+	return 0;
+}
+
+
+/* Pass pkt to BM Pool or RXQ ring */
+static inline void mv_eth_rxq_refill(struct eth_port *pp, int rxq,
+				     struct eth_pbuf *pkt, struct bm_pool *pool, struct pp2_rx_desc *rx_desc)
+{
+	unsigned long flags = 0;
+
+	/* Refill BM pool */
+	STAT_DBG(pool->stats.bm_put++);
+	MV_ETH_LIGHT_LOCK(flags);
+	mvBmPoolPut(pkt->pool, (MV_ULONG) pkt->physAddr, (MV_ULONG) pkt);
+	MV_ETH_LIGHT_UNLOCK(flags);
+	mvOsCacheLineInv(NULL, rx_desc);
+}
+
+
+#ifdef CONFIG_MV_ETH_SWITCH
+struct mv_eth_switch_config {
+	int             mtu;
+	int             netdev_max;
+	int             netdev_cfg;
+	unsigned char   mac_addr[CONFIG_MV_ETH_SWITCH_NETDEV_NUM][MV_MAC_ADDR_SIZE];
+	u16             board_port_map[CONFIG_MV_ETH_SWITCH_NETDEV_NUM];
+};
+
+extern int  mv_eth_switch_netdev_first, mv_eth_switch_netdev_last;
+extern struct mv_eth_switch_config      switch_net_config[CONFIG_MV_ETH_PORTS_NUM];
+extern struct net_device **mv_net_devs;
+
+int     mv_eth_switch_config_get(int use_existing_config, int port);
+int     mv_eth_switch_set_mac_addr(struct net_device *dev, void *mac);
+void    mv_eth_switch_set_multicast_list(struct net_device *dev);
+int     mv_eth_switch_change_mtu(struct net_device *dev, int mtu);
+int     mv_eth_switch_start(struct net_device *dev);
+int     mv_eth_switch_stop(struct net_device *dev);
+void    mv_eth_switch_status_print(int port);
+int     mv_eth_switch_port_add(struct net_device *dev, int port);
+int     mv_eth_switch_port_del(struct net_device *dev, int port);
+
+#endif /* CONFIG_MV_ETH_SWITCH */
+
+/******************************************************
+ * Function prototypes --                             *
+ ******************************************************/
+int         mv_eth_stop(struct net_device *dev);
+int         mv_eth_change_mtu(struct net_device *dev, int mtu);
+int         mv_eth_check_mtu_internals(struct net_device *dev, int mtu);
+int         mv_eth_check_mtu_valid(struct net_device *dev, int mtu);
+
+int         mv_eth_set_mac_addr(struct net_device *dev, void *mac);
+void        mv_eth_set_multicast_list(struct net_device *dev, int flags);
+int         mv_eth_open(struct net_device *dev);
+int         mv_eth_port_suspend(int port);
+int         mv_eth_port_resume(int port);
+int         mv_eth_resume_clock(int port);
+int         mv_eth_suspend_clock(int port);
+int         mv_eth_suspend_internals(struct eth_port *pp);
+int         mv_eth_resume_internals(struct eth_port *pp, int mtu);
+int         mv_eth_restore_registers(struct eth_port *pp, int mtu);
+
+void        mv_eth_win_init(void);
+int         mv_eth_resume_network_interfaces(struct eth_port *pp);
+int         mv_eth_pm_mode_set(int port, int mode);
+
+irqreturn_t mv_eth_isr(int irq, void *dev_id);
+int         mv_eth_start_internals(struct eth_port *pp, int mtu);
+int         mv_eth_stop_internals(struct eth_port *pp);
+int         mv_eth_change_mtu_internals(struct net_device *netdev, int mtu);
+
+int         mv_eth_rx_reset(int port);
+int         mv_eth_txp_clean(int port, int txp);
+
+MV_STATUS   mv_eth_rx_ptks_coal_set(int port, int rxq, MV_U32 value);
+MV_STATUS   mv_eth_rx_time_coal_set(int port, int rxq, MV_U32 value);
+MV_STATUS   mv_eth_tx_done_ptks_coal_set(int port, int txp, int txq, MV_U32 value);
+
+struct eth_port     *mv_eth_port_by_id(unsigned int port);
+struct net_device   *mv_eth_netdev_by_id(unsigned int idx);
+bool                 mv_eth_netdev_find(unsigned int if_index);
+
+void        mv_eth_mac_show(int port);
+void        mv_eth_dscp_map_show(int port);
+int         mv_eth_rxq_dscp_map_set(int port, int rxq, unsigned char dscp);
+int         mv_eth_txq_dscp_map_set(int port, int txq, unsigned char dscp);
+
+int         mv_eth_rxq_vlan_prio_set(int port, int rxq, unsigned char prio);
+void        mv_eth_vlan_prio_show(int port);
+
+void        mv_eth_netdev_print(struct net_device *netdev);
+void        mv_eth_status_print(void);
+void        mv_eth_port_status_print(unsigned int port);
+void        mv_eth_port_stats_print(unsigned int port);
+void 	    mv_eth_pool_status_print(int pool);
+
+void        mv_eth_set_noqueue(struct net_device *dev, int enable);
+void	    mv_eth_ctrl_pnc(int en);
+void        mv_eth_ctrl_hwf(int en);
+int         mv_eth_ctrl_recycle(int en);
+void        mv_eth_ctrl_txdone(int num);
+int         mv_eth_ctrl_tx_mh(int port, u16 mh);
+
+int         mv_eth_ctrl_tx_cmd_dsa(int port, u16 dsa);
+int         mv_eth_ctrl_tx_cmd_color(int port, u16 color);
+int         mv_eth_ctrl_tx_cmd_gem_id(int port, u16 gem_id);
+int         mv_eth_ctrl_tx_cmd_pon_fec(int port, u16 pon_fec);
+int         mv_eth_ctrl_tx_cmd_gem_oem(int port, u16 gem_oem);
+int         mv_eth_ctrl_tx_cmd_mod(int port, u16 mod);
+int         mv_eth_ctrl_tx_cmd_pme_dptr(int port, u16 pme_dptr);
+int         mv_eth_ctrl_tx_cmd_pme_prog(int port, u16 pme_prog);
+
+int         mv_eth_ctrl_txq_cpu_def(int port, int txp, int txq, int cpu);
+int         mv_eth_ctrl_flag(int port, u32 flag, u32 val);
+int	    mv_eth_ctrl_dbg_flag(int port, u32 flag, u32 val);
+int	    mv_eth_ctrl_txq_size_set(int port, int txp, int txq, int txq_size, int hwf_size);
+int         mv_eth_ctrl_rxq_size_set(int port, int rxq, int value);
+int         mv_eth_ctrl_port_buf_num_set(int port, int long_num, int short_num);
+int         mv_eth_ctrl_pool_size_set(int pool, int pkt_size);
+int         mv_eth_ctrl_set_poll_rx_weight(int port, u32 weight);
+void        mv_eth_tx_desc_print(struct pp2_tx_desc *desc);
+void        mv_eth_pkt_print(struct eth_pbuf *pkt);
+void        mv_eth_rx_desc_print(struct pp2_rx_desc *desc);
+void        mv_eth_skb_print(struct sk_buff *skb);
+void        mv_eth_link_status_print(int port);
+
+#ifdef CONFIG_MV_PON
+typedef MV_BOOL(*PONLINKSTATUSPOLLFUNC)(void);		  /* prototype for PON link status polling function */
+typedef void   (*PONLINKSTATUSNOTIFYFUNC)(MV_BOOL state); /* prototype for PON link status notification function */
+
+MV_BOOL mv_pon_link_status(void);
+void mv_pon_link_state_register(PONLINKSTATUSPOLLFUNC poll_func, PONLINKSTATUSNOTIFYFUNC *notify_func);
+void mv_pon_ctrl_omci_type(MV_U16 type);
+void mv_pon_ctrl_omci_rx_gh(int en);
+void mv_pon_omci_print(void);
+
+#endif /* CONFIG_MV_PON */
+
+#ifdef CONFIG_MV_ETH_TX_SPECIAL
+void        mv_eth_tx_special_check_func(int port, int (*func)(int port, struct net_device *dev,
+				  struct sk_buff *skb, struct mv_eth_tx_spec *tx_spec_out));
+#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+
+#ifdef CONFIG_MV_ETH_RX_SPECIAL
+void        mv_eth_rx_special_proc_func(int port, void (*func)(int port, int rxq, struct net_device *dev,
+							struct sk_buff *skb, struct pp2_rx_desc *rx_desc));
+#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+
+int  mv_eth_poll(struct napi_struct *napi, int budget);
+void mv_eth_link_event(struct eth_port *pp, int print);
+
+int mv_eth_rx_policy(u32 cause);
+int mv_eth_refill(struct eth_port *pp, int rxq,
+				struct eth_pbuf *pkt, struct bm_pool *pool, struct pp2_rx_desc *rx_desc);
+u32 mv_eth_txq_done(struct eth_port *pp, struct tx_queue *txq_ctrl);
+u32 mv_eth_tx_done_gbe(struct eth_port *pp, u32 cause_tx_done, int *tx_todo);
+u32 mv_eth_tx_done_pon(struct eth_port *pp, int *tx_todo);
+
+
+/*****************************************
+ *            NAPI Group API             *
+ *****************************************/
+int  mv_eth_port_napi_group_create(int port, int group);
+int  mv_eth_port_napi_group_delete(int port, int group);
+int  mv_eth_napi_set_cpu_affinity(int port, int group, int cpu_mask);
+int  mv_eth_napi_set_rxq_affinity(int port, int group, int rxq_mask);
+void mv_eth_napi_groups_print(int port);
+
+#ifdef CONFIG_MV_ETH_RX_DESC_PREFETCH
+struct pp2_rx_desc *mv_eth_rx_prefetch(struct eth_port *pp,
+						MV_PP2_PHYS_RXQ_CTRL *rx_ctrl, int rx_done, int rx_todo);
+#endif /* CONFIG_MV_ETH_RX_DESC_PREFETCH */
+
+void	*mv_eth_bm_pool_create(int pool, int capacity, MV_ULONG *physAddr);
+
+#if defined(CONFIG_MV_ETH_HWF) && !defined(CONFIG_MV_ETH_BM_CPU)
+MV_STATUS mv_eth_hwf_bm_create(int port, int mtuPktSize);
+void      mv_hwf_bm_dump(void);
+#endif /* CONFIG_MV_ETH_HWF && !CONFIG_MV_ETH_BM_CPU */
+
+#endif /* __mv_netdev_h__ */
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/plcr/plcr_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/plcr/plcr_sysfs.c
new file mode 100644
index 0000000..8d7b634
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/plcr/plcr_sysfs.c
@@ -0,0 +1,213 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+
+#include "mvCommon.h"
+#include "mvTypes.h"
+#include "plcr/mvPp2PlcrHw.h"
+
+
+static ssize_t plcr_help(char *buf)
+{
+	int off = 0;
+
+	off += scnprintf(buf + off, PAGE_SIZE - off, "all arguments are decimal numbers\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE - off, "cat             help      - Show this help\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "cat             regs      - Show PLCR hardware registers\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "cat             dump      - Dump all policers configuration and status\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo p        > dump      - Dump policer <p> configuration and status\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo period   > period    - Set token update base period\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo 0|1      > rate      - Enable <1> or Disable <0> addition of tokens to token buckets\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo bytes    > min_pkt   - Set minimal packet length\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo 0|1      > edrop     - Enable <1> or Disable <0> early packets drop\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo p 0|1    > enable    - Enable <1> or Disable <0> policer <p>\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo p u t    > config    - Set token units <u> and update type <t> for policer <p>\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo p num    > tokens    - Set number of tokens for each update for policer <p>\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo p c e    > bucket    - Set commit <c> and exceed <e> bucket sizes for policer <p>\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo i tr     > cpu_tr    - Set value <tr> to CPU (SWF) threshold <i>\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo i tr     > hwf_tr    - Set value <tr> to HWF threshold <i>\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo rxq i    > rxq_tr    - Set thershold <i> to be used for RXQ <rxq>\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo txq i    > txq_tr    - Set thershold <i> to be used for TXQ <txq>\n");
+
+	return off;
+}
+
+static ssize_t plcr_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	const char  *name = attr->attr.name;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help"))
+		return plcr_help(buf);
+
+	if (!strcmp(name, "regs")) {
+		mvPp2PlcrHwRegs();
+	} else	if (!strcmp(name, "dump")) {
+		mvPp2PlcrHwDumpAll();
+	} else {
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+		return -EINVAL;
+	}
+	return 0;
+}
+
+static ssize_t plcr_dec_store(struct device *dev,
+			struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  err = 0, p = 0, i = 0, v = 0;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%d %d %d", &p, &i, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "dump")) {
+		mvPp2PlcrHwDumpSingle(p);
+	} else	if (!strcmp(name, "period")) {
+		mvPp2PlcrHwBasePeriodSet(p);
+	} else	if (!strcmp(name, "rate")) {
+		mvPp2PlcrHwBaseRateGenEnable(p);
+	} else	if (!strcmp(name, "min_pkt")) {
+		mvPp2PlcrHwMinPktLen(p);
+	} else	if (!strcmp(name, "edrop")) {
+		mvPp2PlcrHwEarlyDropSet(p);
+	} else	if (!strcmp(name, "enable")) {
+		mvPp2PlcrHwEnable(p, i);
+	} else	if (!strcmp(name, "config")) {
+		mvPp2PlcrHwTokenConfig(p, i, v);
+	} else	if (!strcmp(name, "tokens")) {
+		mvPp2PlcrHwTokenValue(p, i);
+	} else	if (!strcmp(name, "bucket")) {
+		mvPp2PlcrHwBucketSizeSet(p, i, v);
+	} else	if (!strcmp(name, "cpu_tr")) {
+		mvPp2PlcrHwCpuThreshSet(p, i);
+	} else	if (!strcmp(name, "hwf_tr")) {
+		mvPp2PlcrHwHwfThreshSet(p, i);
+	} else	if (!strcmp(name, "rxq_tr")) {
+		mvPp2PlcrHwRxqThreshSet(p, i);
+	} else	if (!strcmp(name, "txq_tr")) {
+		mvPp2PlcrHwTxqThreshSet(p, i);
+	} else
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, name);
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+
+static DEVICE_ATTR(help,          S_IRUSR, plcr_show, NULL);
+static DEVICE_ATTR(regs,	      S_IRUSR, plcr_show, NULL);
+static DEVICE_ATTR(dump,          S_IRUSR | S_IWUSR, plcr_show, plcr_dec_store);
+static DEVICE_ATTR(period,	      S_IWUSR, NULL,     plcr_dec_store);
+static DEVICE_ATTR(rate,	      S_IWUSR, NULL,     plcr_dec_store);
+static DEVICE_ATTR(min_pkt,       S_IWUSR, NULL,     plcr_dec_store);
+static DEVICE_ATTR(edrop,         S_IWUSR, NULL,     plcr_dec_store);
+static DEVICE_ATTR(enable,        S_IWUSR, NULL,     plcr_dec_store);
+static DEVICE_ATTR(config,        S_IWUSR, NULL,     plcr_dec_store);
+static DEVICE_ATTR(tokens,        S_IWUSR, NULL,     plcr_dec_store);
+static DEVICE_ATTR(bucket,        S_IWUSR, NULL,     plcr_dec_store);
+static DEVICE_ATTR(cpu_tr,        S_IWUSR, NULL,     plcr_dec_store);
+static DEVICE_ATTR(hwf_tr,        S_IWUSR, NULL,     plcr_dec_store);
+static DEVICE_ATTR(rxq_tr,        S_IWUSR, NULL,     plcr_dec_store);
+static DEVICE_ATTR(txq_tr,        S_IWUSR, NULL,     plcr_dec_store);
+
+
+static struct attribute *plcr_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_regs.attr,
+	&dev_attr_dump.attr,
+	&dev_attr_period.attr,
+	&dev_attr_rate.attr,
+	&dev_attr_min_pkt.attr,
+	&dev_attr_edrop.attr,
+	&dev_attr_enable.attr,
+	&dev_attr_config.attr,
+	&dev_attr_tokens.attr,
+	&dev_attr_bucket.attr,
+	&dev_attr_cpu_tr.attr,
+	&dev_attr_hwf_tr.attr,
+	&dev_attr_rxq_tr.attr,
+	&dev_attr_txq_tr.attr,
+
+	NULL
+};
+
+static struct attribute_group plcr_group = {
+	.name = "plcr",
+	.attrs = plcr_attrs,
+};
+
+int __devinit plcr_sysfs_init(void)
+{
+		int err;
+		struct device *pd;
+
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+		if (!pd) {
+			platform_device_register_simple("pp2", -1, NULL, 0);
+			pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+		}
+
+		if (!pd) {
+			printk(KERN_ERR"%s: cannot find pp2 device\n", __func__);
+			pd = &platform_bus;
+		}
+
+		err = sysfs_create_group(&pd->kobj, &plcr_group);
+		if (err) {
+			printk(KERN_INFO "sysfs group failed %d\n", err);
+			goto out;
+		}
+out:
+		return err;
+}
+
+module_init(plcr_sysfs_init);
+
+MODULE_AUTHOR("Dima Epshtein");
+MODULE_DESCRIPTION("PLCR sysfs for Marvell PPv2");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/pme/pme_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/pme/pme_sysfs.c
new file mode 100644
index 0000000..bdb121c
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/pme/pme_sysfs.c
@@ -0,0 +1,334 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+
+#include "mvCommon.h"
+#include "mvTypes.h"
+#include "pme/mvPp2PmeHw.h"
+
+static MV_PP2_PME_ENTRY  mv_pp2_pme_e;
+
+static ssize_t pme_help(char *buf)
+{
+	int off = 0;
+
+	off += scnprintf(buf + off, PAGE_SIZE - off, "t, i, a, b, c, l, s - are dec numbers\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "v, m, e             - are hex numbers\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE - off, "cat              help          - Show this help\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "cat              hw_regs       - Show PME hardware registers\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "cat              sw_dump       - Show PME sw etry\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "cat              hw_i_dump     - Dump valid PME hw entries of the instruction table\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "cat              hw_i_dump_all - Dump all PME hw entries of the instruction table\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "cat              hw_i_inv      - Invalidate all PME hw entries in the table <t>\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo 1         > sw_clear      - Clear PME sw etry\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo i         > hw_i_read     - Read PME hw entry <i> from instruction table into sw entry\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo i         > hw_i_write    - Write sw entry to PME hw entry <i> in the instruction table\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v         > sw_word       - Set 4 bytes value <v> to sw entry\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v         > sw_cmd        - Set modification command to instruction table sw entry\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v         > sw_data       - Set modification data (2 bytes) to to instruction table sw entry\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo a         > sw_type       - Set type of modification command <a> to instruction table sw entry\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo 0|1       > sw_last       - Set/Clear last bit in instruction table sw entry\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo a b c     > sw_flags      - Set/Clear flags: <a>-last, <b>-ipv4csum, <c>-l4csum\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo t         > hw_d_dump     - Dump non zero PME hw entries from the data table <t>\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo t         > hw_d_clear    - Clear all PME hw entries in the data table <t>\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo t i v     > hw_d_write    - Write 2b modification data <v> to entry <i> of data table <t>\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo t i       > hw_d_read     - Read and print 2b modification data from entry <i> of data table <t>\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo i v       > vlan_etype    - Set 2 bytes value <v> of VLAN ethertype <i>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v         > vlan_def      - Set 2 bytes value <v> of default VLAN ethertype.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo i v       > dsa_etype     - Set 2 bytes value <v> of DSA ethertype <i>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v         > dsa_src_dev   - Set source device value to be set in DSA tag.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo 0|1       > ttl_zero      - Action for packet with zero TTL: 0-drop, 1-forward.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v         > pppoe_etype   - Set 2 bytes value <v> of PPPoE ethertype\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v         > pppoe_len     - Set 2 bytes value <v> of PPPoE length configuration\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo i v       > pppoe_proto   - Set 2 bytes value <v> of PPPoE protocol <i>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo a t v     > pppoe_set     - Set PPPoE header fields: version <a>, type <t> and code <v>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo s i       > max_config    - Set max header size <s bytes> and max instructions <i>.\n");
+
+	return off;
+}
+
+static ssize_t pme_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	const char  *name = attr->attr.name;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help"))
+		return pme_help(buf);
+
+	if (!strcmp(name, "sw_dump")) {
+		mvPp2PmeSwDump(&mv_pp2_pme_e);
+	} else if (!strcmp(name, "hw_regs")) {
+		mvPp2PmeHwRegs();
+	} else	if (!strcmp(name, "hw_i_dump")) {
+		mvPp2PmeHwDump(0);
+	} else if (!strcmp(name, "hw_i_dump_all")) {
+		mvPp2PmeHwDump(1);
+	} else if (!strcmp(name, "hw_i_inv")) {
+		mvPp2PmeHwInvAll();
+	} else {
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+		return -EINVAL;
+	}
+	return 0;
+}
+
+static ssize_t pme_dec_store(struct device *dev,
+			struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  err = 0, t = 0, i = 0, v = 0;
+	unsigned long flags;
+	unsigned short data;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%d %d %x", &t, &i, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "hw_i_write")) {
+		err = mvPp2PmeHwWrite(t, &mv_pp2_pme_e);
+	} else if (!strcmp(name, "sw_clear")) {
+		err = mvPp2PmeSwClear(&mv_pp2_pme_e);
+	} else if (!strcmp(name, "hw_i_read")) {
+		err = mvPp2PmeHwRead(t, &mv_pp2_pme_e);
+	} else if (!strcmp(name, "sw_flags")) {
+		err = mvPp2PmeSwCmdFlagsSet(&mv_pp2_pme_e, t, i, v);
+	} else if (!strcmp(name, "sw_last")) {
+		err = mvPp2PmeSwCmdLastSet(&mv_pp2_pme_e, t);
+	} else if (!strcmp(name, "hw_d_dump")) {
+		err = mvPp2PmeHwDataTblDump(t);
+	} else if (!strcmp(name, "hw_d_clear")) {
+		err = mvPp2PmeHwDataTblClear(t);
+	} else if (!strcmp(name, "hw_d_read")) {
+		err = mvPp2PmeHwDataTblRead(t, i, &data);
+		printk(KERN_INFO "Data%d table entry #%d: 0x%04x\n", t, i, data);
+	} else if (!strcmp(name, "hw_d_write")) {
+		data = (unsigned short)v;
+		err = mvPp2PmeHwDataTblWrite(t, i, data);
+	} else if (!strcmp(name, "ttl_zero")) {
+		err = mvPp2PmeTtlZeroSet(t);
+	} else if (!strcmp(name, "max_config")) {
+		err = mvPp2PmeMaxConfig(t, i, v);
+	} else if (!strcmp(name, "pppoe_set")) {
+		err = mvPp2PmeMaxConfig(t, i, v);
+	} else
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, name);
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t pme_dec_hex_store(struct device *dev,
+				struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char	*name = attr->attr.name;
+	unsigned int    err = 0, i = 0, v = 0;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%d %x", &i, &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "vlan_etype")) {
+		mvPp2PmeVlanEtherTypeSet(i, v);
+	} else if (!strcmp(name, "dsa_etype")) {
+		mvPp2PmeDsaDefaultSet(i, v);
+	} else if (!strcmp(name, "pppoe_proto")) {
+		mvPp2PmePppoeProtoSet(i, v);
+	} else
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t pme_hex_store(struct device *dev,
+				struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char	*name = attr->attr.name;
+	unsigned int    err = 0, v = 0;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%x", &v);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "sw_word")) {
+		mvPp2PmeSwWordSet(&mv_pp2_pme_e, v);
+	} else if (!strcmp(name, "sw_cmd")) {
+		mvPp2PmeSwCmdSet(&mv_pp2_pme_e, v);
+	} else if (!strcmp(name, "sw_type")) {
+		mvPp2PmeSwCmdTypeSet(&mv_pp2_pme_e, v);
+	} else if (!strcmp(name, "sw_data")) {
+		mvPp2PmeSwCmdDataSet(&mv_pp2_pme_e, v);
+	} else if (!strcmp(name, "vlan_def")) {
+		mvPp2PmeVlanDefaultSet(v);
+	} else if (!strcmp(name, "dsa_src_dev")) {
+		mvPp2PmeDsaSrcDevSet(v);
+	} else if (!strcmp(name, "pppoe_etype")) {
+		mvPp2PmePppoeEtypeSet(v);
+	} else if (!strcmp(name, "pppoe_len")) {
+		mvPp2PmePppoeLengthSet(v);
+	} else
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(help,          S_IRUSR, pme_show, NULL);
+static DEVICE_ATTR(sw_dump,       S_IRUSR, pme_show, NULL);
+static DEVICE_ATTR(hw_regs,       S_IRUSR, pme_show, NULL);
+static DEVICE_ATTR(hw_i_dump,     S_IRUSR, pme_show, NULL);
+static DEVICE_ATTR(hw_i_dump_all, S_IRUSR, pme_show, NULL);
+static DEVICE_ATTR(hw_i_inv,      S_IRUSR, pme_show, NULL);
+static DEVICE_ATTR(sw_clear,      S_IWUSR, NULL,     pme_dec_store);
+static DEVICE_ATTR(hw_i_write,    S_IWUSR, NULL,     pme_dec_store);
+static DEVICE_ATTR(hw_i_read,     S_IWUSR, NULL,     pme_dec_store);
+static DEVICE_ATTR(sw_flags,      S_IWUSR, NULL,     pme_dec_store);
+static DEVICE_ATTR(sw_last,       S_IWUSR, NULL,     pme_dec_store);
+static DEVICE_ATTR(sw_word,       S_IWUSR, NULL,     pme_hex_store);
+static DEVICE_ATTR(sw_cmd,        S_IWUSR, NULL,     pme_hex_store);
+static DEVICE_ATTR(sw_type,       S_IWUSR, NULL,     pme_hex_store);
+static DEVICE_ATTR(sw_data,       S_IWUSR, NULL,     pme_hex_store);
+static DEVICE_ATTR(hw_d_dump,     S_IWUSR, NULL,     pme_dec_store);
+static DEVICE_ATTR(hw_d_clear,    S_IWUSR, NULL,     pme_dec_store);
+static DEVICE_ATTR(hw_d_write,    S_IWUSR, NULL,     pme_dec_store);
+static DEVICE_ATTR(hw_d_read,     S_IWUSR, NULL,     pme_dec_store);
+static DEVICE_ATTR(vlan_etype,    S_IWUSR, NULL,     pme_dec_hex_store);
+static DEVICE_ATTR(vlan_def,      S_IWUSR, NULL,     pme_hex_store);
+static DEVICE_ATTR(dsa_etype,     S_IWUSR, NULL,     pme_dec_hex_store);
+static DEVICE_ATTR(dsa_src_dev,   S_IWUSR, NULL,     pme_hex_store);
+static DEVICE_ATTR(ttl_zero,      S_IWUSR, NULL,     pme_dec_store);
+static DEVICE_ATTR(pppoe_set,     S_IWUSR, NULL,     pme_dec_store);
+static DEVICE_ATTR(pppoe_etype,   S_IWUSR, NULL,     pme_hex_store);
+static DEVICE_ATTR(pppoe_len,     S_IWUSR, NULL,     pme_hex_store);
+static DEVICE_ATTR(pppoe_proto,   S_IWUSR, NULL,     pme_dec_hex_store);
+static DEVICE_ATTR(max_config,    S_IWUSR, NULL,     pme_dec_store);
+
+
+static struct attribute *pme_attrs[] = {
+	&dev_attr_help.attr,
+	&dev_attr_sw_dump.attr,
+	&dev_attr_sw_clear.attr,
+	&dev_attr_hw_regs.attr,
+	&dev_attr_hw_i_write.attr,
+	&dev_attr_hw_i_read.attr,
+	&dev_attr_hw_i_dump.attr,
+	&dev_attr_hw_i_dump_all.attr,
+	&dev_attr_hw_i_inv.attr,
+	&dev_attr_sw_word.attr,
+	&dev_attr_sw_cmd.attr,
+	&dev_attr_sw_data.attr,
+	&dev_attr_sw_type.attr,
+	&dev_attr_sw_flags.attr,
+	&dev_attr_sw_last.attr,
+	&dev_attr_hw_d_read.attr,
+	&dev_attr_hw_d_write.attr,
+	&dev_attr_hw_d_dump.attr,
+	&dev_attr_hw_d_clear.attr,
+	&dev_attr_vlan_etype.attr,
+	&dev_attr_vlan_def.attr,
+	&dev_attr_dsa_etype.attr,
+	&dev_attr_dsa_src_dev.attr,
+	&dev_attr_ttl_zero.attr,
+	&dev_attr_pppoe_set.attr,
+	&dev_attr_pppoe_etype.attr,
+	&dev_attr_pppoe_len.attr,
+	&dev_attr_pppoe_proto.attr,
+	&dev_attr_max_config.attr,
+
+	NULL
+};
+
+static struct attribute_group pme_group = {
+	.name = "pme",
+	.attrs = pme_attrs,
+};
+
+int __devinit pme_sysfs_init(void)
+{
+		int err;
+		struct device *pd;
+
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+		if (!pd) {
+			platform_device_register_simple("pp2", -1, NULL, 0);
+			pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+		}
+
+		if (!pd) {
+			printk(KERN_ERR"%s: cannot find pp2 device\n", __func__);
+			pd = &platform_bus;
+		}
+
+		err = sysfs_create_group(&pd->kobj, &pme_group);
+		if (err) {
+			printk(KERN_INFO "sysfs group failed %d\n", err);
+			goto out;
+		}
+out:
+		return err;
+}
+
+module_init(pme_sysfs_init);
+
+MODULE_AUTHOR("Dima Epshtein");
+MODULE_DESCRIPTION("PME for Marvell PPv2");
+MODULE_LICENSE("GPL");
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/prs/prs_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/prs/prs_sysfs.c
new file mode 100644
index 0000000..aee312d
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/prs/prs_sysfs.c
@@ -0,0 +1,289 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include "mvOs.h"
+#include "mvCommon.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "pp2/prs/mvPp2PrsHw.h"
+#include "pp2/prs/mvPp2Prs.h"
+
+
+static  MV_PP2_PRS_ENTRY pe;
+
+
+static ssize_t mv_prs_help(char *buf)
+{
+	int off = 0;
+
+	off += scnprintf(buf + off, PAGE_SIZE - off, "cat          sw_dump       - dump parser SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "cat          hw_dump       - dump all valid HW entries\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "cat          hw_regs       - dump parser registers.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo id      > hw_write    - write parser SW entry into HW place <id>.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo id      > hw_read     - read parser entry <id> into SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo 1       > sw_clear    - clear parser SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo id      > hw_inv      - invalidate parser entry <id> in hw.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo         > hw_inv_all  - invalidate all parser entries in HW.\n");
+
+	/* TODO- remove next command, only for debug */
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo a b c d e > hw_flow    - write flow entry to HW\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "                             flowId <a>, result <b>, result mask <c>, port <d>, tcam index <e>.\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE - off, "\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo p m     > t_port      - add<m=1> or delete<m=0> port<p> in SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo pmap    > t_port_map  - set port map <pmap> to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v m     > t_ai        - update ainfo value <v> with mask <m> in SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo o d m   > t_byte      - set byte of data <d> with mask <m> and offset <o> to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v       > t_lu        - set lookup id <v> to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v m     > s_ri        - set result info value <v> with mask <m> to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v m     > s_ai        - set ainfo value <v> with mask <m> to sw entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v       > s_next_lu   - set next lookup id value <v> to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v       > s_shift     - set packet shift value <v> for next lookup to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo t v     > s_offs      - set offset value <v> for type <t> to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v       > s_lu_done   - set (v=1) or clear (v=0) lookup done bit to SW entry.\n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo v       > s_fid_gen   - set (v=1) or clear (v=0) flowid generate bit in SW entry.\n");
+
+	off += scnprintf(buf + off, PAGE_SIZE - off, "echo p l m o > hw_frst_itr - set values for first iteration port <p>, lookupid <l>, \n");
+	off += scnprintf(buf + off, PAGE_SIZE - off, "				  max loops <m>, init offs <o>.\n");
+
+	return off;
+}
+
+
+static ssize_t mv_prs_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+	if (!strcmp(name, "hw_dump"))
+		mvPp2PrsHwDump();
+	else if (!strcmp(name, "sw_dump"))
+		mvPp2PrsSwDump(&pe);
+	else if (!strcmp(name, "hw_regs"))
+		mvPp2PrsHwRegsDump();
+	else
+		off += mv_prs_help(buf);
+
+	return off;
+}
+
+static ssize_t mv_prs_store_signed(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	int  err = 0, a = 0, b = 0, c = 0, d = 0;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%d %d %d %d", &a, &b, &c, &d);
+	local_irq_save(flags);
+
+	if (!strcmp(name, "s_shift"))
+		mvPp2PrsSwSramShiftSet(&pe, a, SRAM_OP_SEL_SHIFT_ADD);
+	else if (!strcmp(name, "s_offs"))
+		mvPp2PrsSwSramOffsetSet(&pe, a, b, SRAM_OP_SEL_SHIFT_ADD);
+	else if (!strcmp(name, "hw_frst_itr"))
+		mvPp2PrsHwPortInit(a, b, c, d);
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+
+static ssize_t mv_prs_store_unsigned(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char    *name = attr->attr.name;
+	unsigned int  err = 0, a = 0, b = 0, c = 0, d = 0, e = 0;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%x %x %x %x %x", &a, &b, &c, &d, &e);
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "hw_write")) {
+		pe.index = a;
+		mvPp2PrsHwWrite(&pe);
+	} else if (!strcmp(name, "hw_read")) {
+		pe.index = a;
+		mvPp2PrsHwRead(&pe);
+	} else if (!strcmp(name, "sw_clear"))
+		mvPp2PrsSwClear(&pe);
+	else if (!strcmp(name, "hw_inv"))
+		mvPp2PrsHwInv(a);
+	else if (!strcmp(name, "hw_inv_all"))
+		mvPp2PrsHwInvAll();
+	else if (!strcmp(name, "t_port"))
+		mvPp2PrsSwTcamPortSet(&pe, a, b);
+	else if (!strcmp(name, "t_port_map"))
+		mvPp2PrsSwTcamPortMapSet(&pe, a);
+	else if (!strcmp(name, "t_lu"))
+		mvPp2PrsSwTcamLuSet(&pe, a);
+	else if (!strcmp(name, "t_ai"))
+		mvPp2PrsSwTcamAiUpdate(&pe, a, b);
+	else if (!strcmp(name, "t_byte"))
+		mvPp2PrsSwTcamByteSet(&pe, a, b, c);
+	else if (!strcmp(name, "s_ri"))
+		mvPp2PrsSwSramRiUpdate(&pe, a, b);
+	else if (!strcmp(name, "s_ai"))
+		mvPp2PrsSwSramAiUpdate(&pe, a, b);
+	else if (!strcmp(name, "s_next_lu"))
+		mvPp2PrsSwSramNextLuSet(&pe, a);
+	else if (!strcmp(name, "s_lu_done"))
+		(a == 1) ? 	mvPp2PrsSwSramLuDoneSet(&pe) :
+				mvPp2PrsSwSramLuDoneClear(&pe);
+	else if (!strcmp(name, "s_fid_gen"))
+		(a == 1) ?	mvPp2PrsSwSramFlowidGenSet(&pe) :
+				mvPp2PrsSwSramFlowidGenClear(&pe);
+	else if (!strcmp(name, "hw_flow"))
+		mvPrsFlowIdGen(e, a, b, c, d);
+
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+static DEVICE_ATTR(hw_dump,		S_IRUSR, mv_prs_show, NULL);
+static DEVICE_ATTR(sw_dump,		S_IRUSR, mv_prs_show, NULL);
+static DEVICE_ATTR(help,		S_IRUSR, mv_prs_show, NULL);
+static DEVICE_ATTR(hw_regs,		S_IRUSR, mv_prs_show, NULL);
+static DEVICE_ATTR(sw_clear,    	S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(hw_write,    	S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(hw_read,     	S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(hw_inv,      	S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(hw_inv_all, 		S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(t_byte,		S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(t_port,      	S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(t_port_map,		S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(t_ai,		S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(t_lu,		S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(s_ri,		S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(s_ai,		S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(s_next_lu,		S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(s_shift,		S_IWUSR, mv_prs_show, mv_prs_store_signed);
+static DEVICE_ATTR(s_offs,		S_IWUSR, mv_prs_show, mv_prs_store_signed);
+static DEVICE_ATTR(s_lu_done,		S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(s_fid_gen,		S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+static DEVICE_ATTR(hw_frst_itr,		S_IWUSR, mv_prs_show, mv_prs_store_signed);
+static DEVICE_ATTR(hw_flow,		S_IWUSR, mv_prs_show, mv_prs_store_unsigned);
+
+
+
+
+static struct attribute *prs_attrs[] = {
+    &dev_attr_hw_dump.attr,
+    &dev_attr_sw_dump.attr,
+    &dev_attr_hw_regs.attr,
+    &dev_attr_hw_write.attr,
+    &dev_attr_hw_read.attr,
+    &dev_attr_hw_inv.attr,
+    &dev_attr_hw_inv_all.attr,
+    &dev_attr_sw_clear.attr,
+    &dev_attr_t_byte.attr,
+    &dev_attr_t_port.attr,
+    &dev_attr_t_port_map.attr,
+    &dev_attr_t_ai.attr,
+    &dev_attr_t_lu.attr,
+    &dev_attr_s_ri.attr,
+    &dev_attr_s_ai.attr,
+    &dev_attr_s_next_lu.attr,
+    &dev_attr_s_shift.attr,
+    &dev_attr_s_offs.attr,
+    &dev_attr_s_lu_done.attr,
+    &dev_attr_s_fid_gen.attr,
+    &dev_attr_hw_frst_itr.attr,
+    &dev_attr_help.attr,
+    &dev_attr_hw_flow.attr,
+    NULL
+};
+
+static struct attribute_group prs_group = {
+	.name = "prs",
+	.attrs = prs_attrs,
+};
+
+int __devinit prs_sysfs_init(void)
+{
+	int err;
+	struct device *pd;
+
+	pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	if (!pd) {
+		platform_device_register_simple("pp2", -1, NULL, 0);
+		pd = bus_find_device_by_name(&platform_bus_type, NULL, "pp2");
+	}
+
+	if (!pd) {
+		printk(KERN_ERR "%s: cannot find neta device\n", __func__);
+		pd = &platform_bus;
+	}
+
+	err = sysfs_create_group(&pd->kobj, &prs_group);
+	if (err) {
+		printk(KERN_INFO "sysfs group failed %d\n", err);
+		goto out;
+	}
+out:
+	return err;
+}
+
+module_init(prs_sysfs_init);
+
+MODULE_AUTHOR("Uri Eliyahu");
+MODULE_DESCRIPTION("prs for Marvell NetA2");
+MODULE_LICENSE("GPL");
+
diff --git a/include/linux/mv_pp2.h b/include/linux/mv_pp2.h
new file mode 100644
index 0000000..151273f
--- /dev/null
+++ b/include/linux/mv_pp2.h
@@ -0,0 +1,109 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+/*  mv_pp2.h */
+
+#ifndef LINUX_MV_PP2_H
+#define LINUX_MV_PP2_H
+
+#define MV_PP2_PORT_NAME	"mv_pp2_port"
+
+struct mv_pp2_pdata {
+	unsigned int  cpu_mask;
+	int           mtu;
+
+
+	/* Whether a PHY is present, and if yes, at which address. */
+	int      phy_addr;
+
+	/* Use this MAC address if it is valid */
+	u8       mac_addr[6];
+
+	/*
+	* If speed is 0, autonegotiation is enabled.
+	*   Valid values for speed: 0, SPEED_10, SPEED_100, SPEED_1000.
+	*   Valid values for duplex: DUPLEX_HALF, DUPLEX_FULL.
+	*/
+	int      speed;
+	int      duplex;
+
+	/* Port configuration: indicates if this port is LB, and if PCS block is active */
+	int	lb_enable;
+	int	is_sgmii;
+	int	is_rgmii;
+
+	/*
+	* How many RX/TX queues to use.
+	*/
+	int      rx_queue_count;
+	int      tx_queue_count;
+
+	/*
+	* Override default RX/TX queue sizes if nonzero.
+	*/
+	int      rx_queue_size;
+	int      tx_queue_size;
+};
+
+
+#endif  /* LINUX_MV_PP2_H */
-- 
1.7.5.4

