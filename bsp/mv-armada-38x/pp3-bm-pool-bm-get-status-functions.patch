From 041371872270be1e5f20938b79789c2259b63cbf Mon Sep 17 00:00:00 2001
From: Dovrat <dovrat@marvell.com>
Date: Wed, 23 Apr 2014 22:08:15 +0300
Subject: [PATCH 1583/1825] pp3: bm: pool & bm get status functions

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit 22701ba05177ce382c830d32c6e5f4428dd1df9e

Change-Id: I27cab0ca4ed7e382fc13bad36d2586783c15a8dc
Signed-off-by: Dovrat <dovrat@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/7177
Tested-by: Star_Automation <star@marvell.com>
Reviewed-by: Uri Eliyahu <uriel@marvell.com>
Reviewed-by: Dmitri Epshtein <dima@marvell.com>
Tested-by: Dmitri Epshtein <dima@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 drivers/net/ethernet/marvell/pp3/bm/mv_bm.c |  241 ++++++++++++++++++++-------
 drivers/net/ethernet/marvell/pp3/bm/mv_bm.h |   49 +++---
 2 files changed, 207 insertions(+), 83 deletions(-)

diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
index 4ca025d..8c16401 100644
--- a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
@@ -203,6 +203,8 @@ int bm_attr_gp_pool_set(u32 arDomain, u32 awDomain, u32 arCache, u32 awCache, u3
 	struct bm_dram_cache_conf  reg_dram_cache_conf;
 	struct bm_dram_qos_conf    reg_dram_qos_conf;
 
+	pr_info("bm_attr_gp_pool_set %d %d %d %d %d %d\n", arDomain, awDomain, arCache, awCache, arQOS, awQOS);
+
 	if ((arDomain < BM_ADOMAIN_MIN) || (arDomain > BM_ADOMAIN_MAX)) {
 		pr_err("arDomain is not in range\n");
 		return rc;
@@ -348,12 +350,15 @@ int bm_qm_gpm_pools_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base_addr
 
 	pr_info("%s:\n", __func__);
 	pr_info("  num_of_buffers    %d\n", num_of_buffers);
-	pr_info(" qece_base_address 0x%02X%08X pl_base_address 0x%02X%08X\n",
-		qece_base_address->dma_msb, qece_base_address->dma_lsb,
+	pr_info("  qece_base_address(1) virtual 0x%02X%08X	physical 0x%02X%08X\n",
+		qece_base_address->virt_msb, qece_base_address->virt_lsb,
+		qece_base_address->dma_msb,   qece_base_address->dma_lsb);
+	pr_info("  pl_base_address(0) virtual 0x%02X%08X	physical 0x%02X%08X\n",
+		pl_base_address->virt_msb, pl_base_address->virt_lsb,
 		pl_base_address->dma_msb,   pl_base_address->dma_lsb);
-	pr_info("  ae_thr            %d af_thr          %d\n", ae_thr, af_thr);
-	pr_info("  cache_vmid        %d cache_attr      %d\n", cache_vmid, cache_attr);
-	pr_info("  cache_so_thr      %d cache_si_thr    %d  cache_num_of_buffers %d\n",
+	pr_info("  ae_thr            %d		af_thr          %d\n", ae_thr, af_thr);
+	pr_info("  cache_vmid        %d		cache_attr      %d\n", cache_vmid, cache_attr);
+	pr_info("  cache_so_thr      %d		cache_si_thr    %d		cache_num_of_buffers %d\n",
 		cache_so_thr, cache_si_thr, cache_num_of_buffers);
 
 	granularity_of_pe_in_dram  = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_DRAM;		/* 64/4 */
@@ -496,8 +501,8 @@ int bm_qm_gpm_pools_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base_addr
 	pool = 1;
 	base_address.dma_msb = qece_base_address->dma_msb;
 	base_address.dma_lsb = qece_base_address->dma_lsb;
-	base_address.virt_msb = pl_base_address->virt_msb;
-	base_address.virt_lsb = pl_base_address->virt_lsb;
+	base_address.virt_msb = qece_base_address->virt_msb;
+	base_address.virt_lsb = qece_base_address->virt_lsb;
 	quick_init = 1;
 	pe_size = 1;
 	rc = bm_pool_dram_set(pool, num_of_buffers, pe_size, &base_address, ae_thr, af_thr);
@@ -623,7 +628,7 @@ int bm_qm_dram_pools_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base_add
 	/*	for pools 2&3 it allocates the buffer memory before filling the pool	*/
 	rc = ENOMEM;
 	pl_buf_address_allocate.virt_lsb =
-			(u32)dma_alloc_coherent(NULL, num_of_buffers*4, &pl_buf_address_allocate.dma_lsb, GFP_KERNEL);
+			(u32)dma_alloc_coherent(NULL, num_of_buffers*4, &(pl_buf_address_allocate.dma_lsb), GFP_KERNEL);
 	if (pl_buf_address_allocate.virt_lsb == (u32)NULL)
 		return rc;
 		/*base_address_hi need to be resolved - ???*/
@@ -658,7 +663,7 @@ int bm_qm_dram_pools_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base_add
 	/*	for pools 2&3 it allocates the buffer memory before filling the pool	*/
 	rc = ENOMEM;
 	qece_buf_address_allocate.virt_lsb =
-			(u32)dma_alloc_coherent(NULL, num_of_buffers*4, &qece_buf_address_allocate.dma_lsb, GFP_KERNEL);
+		(u32)dma_alloc_coherent(NULL, num_of_buffers*4, &(qece_buf_address_allocate.dma_lsb), GFP_KERNEL);
 	if (qece_buf_address_allocate.virt_lsb == (u32)NULL)
 		return rc;
 		/*base_address_hi need to be resolved - ???*/
@@ -684,6 +689,7 @@ int bm_pool_quick_init_status_get(u32 pool, u32 *completed)
 	int rc = -BM_INPUT_NOT_IN_RANGE;
 	u32 pid, bid, pid_local;
 	struct bm_pool_st   reg_pool_st;
+	u32 enabled, quick_init;
 
 	if ((pool           <     BM_POOL_MIN) || (pool           >     BM_POOL_MAX)) {
 		pr_err("wrong pool number %d\n", pool);
@@ -697,6 +703,17 @@ int bm_pool_quick_init_status_get(u32 pool, u32 *completed)
 		pr_err("something is wrong\n");
 		return rc;
 	}
+	bm_pool_enabled_get(pool, &enabled, &quick_init);
+	if (enabled != BM_POOL_IS_ENABLED) {
+		pr_err("pool is not enabled\n");
+		return rc;
+	}
+	if (quick_init != BM_QUICK_INIT_IS_ON) {
+		pr_err("pool is not in quick init mode\n");
+		*completed = BM_POOL_INIT_COMPLETED;
+		return 0;
+	}
+
 
 	pid       = (int)pool;
 	bid       = BM_PID_TO_BANK(pid);
@@ -2567,11 +2584,6 @@ int bm_pool_memory_fill(u32 pool, u32 num_of_buffers, struct mv_a40 *base_addres
 	int rc = -BM_INPUT_NOT_IN_RANGE;
 	u32 granularity_of_pe_in_dram;
 	u32 i, *p;
-/*
-	u64 p_long;
-	uint64_t p_long;
-	uintptr_t p_long;
-*/
 	granularity_of_pe_in_dram = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_DRAM;	/* 64/4 */
 
 	if ((num_of_buffers % granularity_of_pe_in_dram) != 0) /* UNIT_OF__1_BYTES = 1 */
@@ -2586,32 +2598,33 @@ int bm_pool_memory_fill(u32 pool, u32 num_of_buffers, struct mv_a40 *base_addres
 		if ((num_of_buffers < BM_NUM_OF_BUFFERS_QM_MIN) || (num_of_buffers > BM_NUM_OF_BUFFERS_QM_DRAM_MAX))
 			return rc;
 	}
-/*	if ((base_address_hi < BM_DRAM_ADDRESS_HI_MIN) || (base_address_hi > BM_DRAM_ADDRESS_HI_MAX)) */
 	if ((base_address->dma_msb < BM_DRAM_ADDRESS_MIN_MSB) ||
 		(base_address->dma_msb > BM_DRAM_ADDRESS_MAX_MSB))
 		return rc;
-/*	if (base_address_lo < BM_DRAM_ADDRESS_LO_MIN) */
 	if ((base_address->dma_msb == BM_DRAM_ADDRESS_MIN_MSB) &&
 		(base_address->dma_lsb <  BM_DRAM_ADDRESS_MIN_LSB))
 		return rc;
-/*	if (base_address_lo > BM_DRAM_ADDRESS_LO_MAX) */
 	if ((base_address->dma_msb == BM_DRAM_ADDRESS_MAX_MSB) &&
 		(base_address->dma_lsb >  BM_DRAM_ADDRESS_MAX_LSB))
 		return rc;
 
-/*
-	action
-	Takes pool_base_address and use it as a pointer to fill all PE's with incrementing value (starting with 1)
-	Write in Dram in BM pool section an incrementing index */
+    /*
+	 * Takes pool_base_address and use it as a pointer
+	 * to fill all PE's with incrementing value (starting with 1)
+	 * Write in Dram in BM pool section an incrementing index
+	 */
 
 	p = (u32 *)(base_address->virt_lsb);
-/*
-	base_address->dma_msb - ???
-	p = (u32 *)((base_address->dma_msb << 32) + base_address->dma_lsb);
-	p = (u32 *)temp;
-	p++;*/
-	for (i = 0; i < num_of_buffers; i++)
-		*p++ = i + 1;
+	pr_info("%s:\n", __func__);
+	pr_info("  num_of_buffers    %d\n", num_of_buffers);
+	pr_info("  base_address virtual 0x%02X%08X	physical 0x%02X%08X\n",
+		base_address->virt_msb, base_address->virt_lsb,
+		base_address->dma_msb, base_address->dma_lsb);
+
+	for (i = 0; i < num_of_buffers; i++) {
+		*p = i + 1;
+		p++;
+	}
 
 	rc = OK;
 	return rc;
@@ -2671,15 +2684,12 @@ int bm_pool_dram_set(u32 pool, u32 num_of_buffers, u32 pe_size, struct mv_a40 *b
 	if ((pe_size         <         BM_PE_SIZE_MIN) || (pe_size         >         BM_PE_SIZE_MAX))
 		return rc;
 
-/*	if ((base_address_hi < BM_DRAM_ADDRESS_HI_MIN) || (base_address_hi > BM_DRAM_ADDRESS_HI_MAX)) */
 	if ((base_address->dma_msb < BM_DRAM_ADDRESS_MIN_MSB) ||
 		(base_address->dma_msb > BM_DRAM_ADDRESS_MAX_MSB))
 		return rc;
-/*	if (base_address_lo < BM_DRAM_ADDRESS_LO_MIN) */
 	if ((base_address->dma_msb == BM_DRAM_ADDRESS_MIN_MSB) &&
 		(base_address->dma_lsb <  BM_DRAM_ADDRESS_MIN_LSB))
 		return rc;
-/*	if (base_address_lo > BM_DRAM_ADDRESS_LO_MAX) */
 	if ((base_address->dma_msb == BM_DRAM_ADDRESS_MAX_MSB) &&
 		(base_address->dma_lsb >  BM_DRAM_ADDRESS_MAX_LSB))
 		return rc;
@@ -2900,14 +2910,13 @@ int bm_gp_pool_pair_set(u32 pool, u32 pool_pair)
 	return rc;
 }
 
-/*int bm_pool_cache_set(u32 pool, u32 vmid, u32 attr, u32 so_thr, u32 si_thr, u32 end, u32 start)*/
 int bm_pool_cache_set(u32 pool, u32 cache_vmid, u32 cache_attr, u32 cache_so_thr, u32 cache_si_thr,
 						u32 cache_num_of_buffers)
 {
 	u32 reg_base_address, reg_size, reg_offset;
 	int rc = -BM_INPUT_NOT_IN_RANGE;
-	u32 pid, bid, pid_local, pid_temp, bid_temp, pid_local_temp;
-	u32 granularity_of_pe_in_cache, cache_start, cache_end, cache_end_max[BM_BANK_MAX], pool_enable;
+	u32 pid, bid, pid_local, pid_temp, pid_local_temp;
+	u32 granularity_of_pe_in_cache, cache_start, cache_end, cache_end_max, pool_enable;
 	struct bm_pool_conf_b0    reg_b0_pool_conf;
 	struct bm_pool_conf_bgp   reg_bgp_pool_conf;
 	struct bm_c_mng_stat_data tab_dpr_c_mng_stat;
@@ -2951,26 +2960,30 @@ int bm_pool_cache_set(u32 pool, u32 cache_vmid, u32 cache_attr, u32 cache_so_thr
 	} else
 		return rc;
 
-	for (bid_temp = BM_BANK_MIN; bid_temp < BM_BANK_MAX; bid_temp++)
-		cache_end_max[bid_temp] = 0;
+	pid = pool;
+	bid = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
 
-	for (pid_temp = BM_POOL_MIN; pid_temp < BM_POOL_MAX; pid_temp++) {
-		bid_temp = BM_PID_TO_BANK(pid_temp);
-		pid_local_temp = BM_PID_TO_PID_LOCAL(pid_temp);
+	cache_end_max = 0;
 
+	for (pid_temp = BM_POOL_MIN; pid_temp < BM_POOL_MAX; pid_temp++) {
+		if (BM_PID_TO_BANK(pid_temp) != bid)
+			continue; /* run only on pools that are in bank */
 		if ((pid_temp > BM_POOL_QM_MAX) && (pid_temp < BM_POOL_GP_MIN))
 			continue; /* pools 4, 5, 6, 7 don't exist */
 
-		reg_base_address =      bm.b_pool_n_conf[bid_temp];
-		reg_size   =   bm_reg_size.b_pool_n_conf[bid_temp];
-		reg_offset = bm_reg_offset.b_pool_n_conf[bid_temp] * pid_local_temp;
+		pid_local_temp = BM_PID_TO_PID_LOCAL(pid_temp);
+
+		reg_base_address =      bm.b_pool_n_conf[bid];
+		reg_size   =   bm_reg_size.b_pool_n_conf[bid];
+		reg_offset = bm_reg_offset.b_pool_n_conf[bid] * pid_local_temp;
 
-		if  (bid_temp == 0) { /* QM pools */
+		if  (bid == 0) { /* QM pools */
 			rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b0_pool_conf);
 			if (rc != OK)
 				return rc;
 			pool_enable = reg_b0_pool_conf.pool_enable;
-		} else if ((bid_temp == 1) || (bid_temp == 2) || (bid_temp == 3) || (bid_temp == 4)) { /* QP pools */
+		} else if ((bid == 1) || (bid == 2) || (bid == 3) || (bid == 4)) { /* GP pools */
 			rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_pool_conf);
 			if (rc != OK)
 				return rc;
@@ -2983,22 +2996,18 @@ int bm_pool_cache_set(u32 pool, u32 cache_vmid, u32 cache_attr, u32 cache_so_thr
 		if (pool_enable == OFF)
 			continue;	/* pool pid_local_temp is not enabled */
 
-		reg_base_address =      bm.dpr_c_mng_stat[bid_temp];
-		reg_size   =   bm_reg_size.dpr_c_mng_stat[bid_temp];
-		reg_offset = bm_reg_offset.dpr_c_mng_stat[bid_temp] * pid_local_temp;
+		reg_base_address =      bm.dpr_c_mng_stat[bid];
+		reg_size   =   bm_reg_size.dpr_c_mng_stat[bid];
+		reg_offset = bm_reg_offset.dpr_c_mng_stat[bid] * pid_local_temp;
 
 		rc = bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_dpr_c_mng_stat);
 		if (rc != OK)
 			return rc;
-		cache_end_max[bid_temp] = MV_MAX(cache_end_max[bid_temp],
-						tab_dpr_c_mng_stat.cache_end * UNIT_OF_64_BYTES);
+		cache_end_max = MV_MAX(cache_end_max, tab_dpr_c_mng_stat.cache_end * UNIT_OF_64_BYTES);
 	}
 
-	pid = pool;
-	bid = BM_PID_TO_BANK(pid);
-	pid_local = BM_PID_TO_PID_LOCAL(pid);
 
-	if ((cache_end_max[bid]   < BM_CACHE_END_MIN) || (cache_end_max[bid]    >      BM_CACHE_END_MAX))
+	if ((cache_end_max   < BM_CACHE_END_MIN) || (cache_end_max    >      BM_CACHE_END_MAX))
 		return rc;
 
 	reg_base_address =      bm.dpr_c_mng_stat[bid];
@@ -3008,7 +3017,7 @@ int bm_pool_cache_set(u32 pool, u32 cache_vmid, u32 cache_attr, u32 cache_so_thr
 	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_dpr_c_mng_stat);
 	if (rc != OK)
 		return rc;
-	cache_start  = cache_end_max[bid] + 1;
+	cache_start  = cache_end_max + 1;
 	cache_end    = cache_start + (cache_num_of_buffers / granularity_of_pe_in_cache) - 1;
 
 	if ((cache_start < BM_CACHE_START_MIN) || (cache_start  > BM_CACHE_START_MAX))
@@ -3072,19 +3081,131 @@ int bm_pool_disable(u32 pool)
 	rc = OK;
 	return rc;
 }
+/* Get if pool is enabled */
+int bm_pool_enabled_get(u32 pool, u32 *enabled, u32 *quick_init)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pid, bid, pid_local;
+	struct bm_pool_conf_b0  reg_b0_pool_conf;
+	struct bm_pool_conf_bgp reg_bgp_pool_conf;
+
+	if ((pool       <       BM_POOL_MIN) || (pool       >       BM_POOL_MAX))
+		return rc;
+	if ((pool       >    BM_POOL_QM_MAX) && (pool       <    BM_POOL_GP_MIN))
+		return rc; /* pools 4, 5, 6, 7 don't exist */
+
+	pid = (int)pool;
+	bid = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	reg_base_address =      bm.b_pool_n_conf[bid];
+	reg_size   =   bm_reg_size.b_pool_n_conf[bid];
+	reg_offset = bm_reg_offset.b_pool_n_conf[bid] * pid_local;
+
+	if  (bid == 0) { /* QM pools */
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_b0_pool_conf);
+		if (rc != OK)
+			return rc;
+		*enabled = reg_b0_pool_conf.pool_enable;
+		*quick_init = reg_b0_pool_conf.pool_quick_init;
+	} else if ((bid == 1) || (bid == 2) || (bid == 3) || (bid == 4)) { /* QP pools */
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_pool_conf);
+		if (rc != OK)
+			return rc;
+
+		*enabled = reg_bgp_pool_conf.pool_enable;
+		*quick_init = reg_bgp_pool_conf.pool_quick_init;
+	} else {
+		rc = -BM_INPUT_NOT_IN_RANGE;
+		return rc;
+	}
+
+	rc = OK;
+	return rc;
+}
+
+/* Get pool pointers - internal registers */
+int bm_pool_pointer_get(u32 pool, u32 *rd_ptr, u32 *wr_ptr)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	u32 pid;
+	struct bm_tpr_dro_mng_ball_dyn_data tab_tpr_dro_mng_ball_dyn_data;
+
+	if ((pool            <     BM_POOL_MIN) || (pool            >    BM_POOL_MAX))
+		return rc;
+	if ((pool            >  BM_POOL_QM_MAX) && (pool            < BM_POOL_GP_MIN))
+		return rc; /* pools 4, 5, 6, 7 don't exist */
+
+	pid       = (int)pool;
+
+	reg_base_address =      bm.tpr_dro_mng_ball_dyn;
+	reg_size   =   bm_reg_size.tpr_dro_mng_ball_dyn;
+	reg_offset = bm_reg_offset.tpr_dro_mng_ball_dyn * BM_PID_TO_GLOBAL_POOL_IDX(pid);
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_tpr_dro_mng_ball_dyn_data);
+	if (rc != OK)
+		return rc;
+
+	/* r/w pointer of BM to pool is given in 64 bits unit. starting from 0 */
+	*rd_ptr = tab_tpr_dro_mng_ball_dyn_data.dram_rd_ptr * 2;
+	*wr_ptr = tab_tpr_dro_mng_ball_dyn_data.dram_wr_ptr * 2;
+
+
+	rc = OK;
+	return rc;
+}
+/* Get interupt cause */
+int bm_bank_inter_get(u32 bank, u32 *ne, u32 *ae, u32 *af)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = OK;
+	u32 bid;
+
+	bid = bank;
+	reg_base_address =      bm.pool_nempty_intr_cause[bid];
+	reg_size   =   bm_reg_size.pool_nempty_intr_cause[bid];
+	reg_offset = bm_reg_offset.pool_nempty_intr_cause[bid] * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, ne);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      bm.dpool_ae_intr_cause[bid];
+	reg_size   =   bm_reg_size.dpool_ae_intr_cause[bid];
+	reg_offset = bm_reg_offset.dpool_ae_intr_cause[bid] * 0;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, ae);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      bm.dpool_af_intr_cause[bid];
+	reg_size   =   bm_reg_size.dpool_af_intr_cause[bid];
+	reg_offset = bm_reg_offset.dpool_af_intr_cause[bid];
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, af);
+	if (rc != OK)
+		return rc;
+
+	return rc;
+}
+
+/* Register Read Write */
 
 int bm_register_read(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr)
 {
 	int rc = -BM_INPUT_NOT_IN_RANGE;
 	char reg_name[255];
-	u32 *temp;
-	u32 i;
+	/*u32 *temp;
+	u32 i;*/
 
 	if (((u32)dataPtr <  BM_DATA_PTR_MIN) || ((u32)dataPtr >  BM_DATA_PTR_MAX))
 		return rc;
 
 	bm_register_name_get(base_address, offset, reg_name);
 	mv_pp3_hw_read(base_address+offset, wordsNumber, dataPtr);
+	/*
 	pr_info("[QM-BM] READ_REG add = 0x%08X : name = %s : value =", base_address, reg_name);
 	temp = dataPtr;
 	for (i = 0; i < wordsNumber; i++) {
@@ -3092,7 +3213,7 @@ int bm_register_read(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr
 		temp++;
 	}
 	pr_info("\n");
-
+	*/
 	rc = OK;
 	return rc;
 }
@@ -3101,13 +3222,14 @@ int bm_register_write(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPt
 {
 	int rc = -BM_INPUT_NOT_IN_RANGE;
 	char reg_name[255];
-	int i;
-	u32 *temp;
+	/*int i;
+	u32 *temp;*/
 
 	if (((u32)dataPtr <  BM_DATA_PTR_MIN) || ((u32)dataPtr >  BM_DATA_PTR_MAX))
 		return rc;
 
 	bm_register_name_get(base_address, offset, reg_name);
+	/*
 	pr_info("[QM-BM] WROTE_REG add = 0x%08X : name = %s : value =", base_address, reg_name);
 	temp = dataPtr;
 	for (i = 0; i < wordsNumber; i++) {
@@ -3115,6 +3237,7 @@ int bm_register_write(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPt
 		temp++;
 	}
 	pr_info("\n");
+	*/
 	mv_pp3_hw_write(base_address+offset, wordsNumber, dataPtr);
 
 	rc = OK;
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h
index d25dc6b..b7d0eca 100644
--- a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h
@@ -240,6 +240,9 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 /* Register status */
 #define BM_STATUS_IS_IDLE			1
+#define BM_POOL_IS_ENABLED			1
+#define BM_QUICK_INIT_IS_ON			1
+#define BM_POOL_INIT_COMPLETED		1
 
 #define BM_PID_TO_BANK(_pid)                \
 	((((_pid) >= 0) && ((_pid)   <=  3)) ?	0 :	\
@@ -627,19 +630,31 @@ int bm_pool_cache_set(
 int bm_pool_disable(u32 pool);
 
 /**
- * access_addr - absolute address: Silicon base + unit base + register offset
- * return register value
+ *  Per pool returns if pool is enabled and if in quick init mode
+ *
+ *  Return values:
+ *		0 - success
  */
-/*static INLINE
-int mv_pp3_hw_reg_read(u32 access_addr);
-*/
+int bm_pool_enabled_get(u32 pool, u32 *enabled, u32 *quick_init);
+
 /**
- * access_addr - absolute address: Silicon base + unit base + register offset
- * write data to register
+ *  Per pool returns BM read and write pointer to pool
+ *
+ *  Return values:
+ *		0 - success
  */
-/*static INLINE
-int mv_pp3_hw_reg_write(u32 access_addr, u32 data);
-*/
+int bm_pool_pointer_get(u32 pool, u32 *rd_ptr, u32 *wr_ptr);
+
+/**
+ *  Per Bank return interupt cause indicating if there was
+ *  not empty interupt, almost empty interupt and almost full interupt
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_bank_inter_get(u32 bank, u32 *ne, u32 *ae, u32 *af);
+
+
 /**
  *  Read register from BM units
  *
@@ -667,21 +682,7 @@ int bm_register_write(
 									that dataPtr points to wordsNumber words */
 
 
-/**
- *  Print per pool several registers which are helpful for advanced debugging
- *
- *  Return values:
- *		0 - success
-int bm_per_pool_advanced_debug(u32 pool, u32 line);
- */
 
-/**
- *  Print TBD
- *
- *  Return values:
- *		0 - success
-int bm_debug(void);
- */
 /*
  BM sysFS function
 */
-- 
1.7.5.4

