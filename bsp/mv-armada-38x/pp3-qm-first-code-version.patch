From 36a40ba25813b3eaa950e9bb436eba057c73c0b9 Mon Sep 17 00:00:00 2001
From: Yelena <yelena@marvell.com>
Date: Sun, 30 Mar 2014 12:02:09 +0300
Subject: [PATCH 1530/1825] pp3: qm: first code version

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit 5402ecd0610abbcefb815c8ef6bc2bbe1ed5a23c

Change-Id: I698fa54ac63a852e18e761e6803ed6ba771aa4ba
Signed-off-by: Yelena <yelena@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/6718
Reviewed-by: Eliezer Ben Zeev <eliezerb@marvell.com>
Reviewed-by: Dmitri Epshtein <dima@marvell.com>
Tested-by: Star_Automation <star@marvell.com>
Tested-by: Dmitri Epshtein <dima@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 drivers/net/ethernet/marvell/pp3/Makefile        |    3 +-
 drivers/net/ethernet/marvell/pp3/bm/mv_bm.c      |   92 -
 drivers/net/ethernet/marvell/pp3/qm/mv_qm.c      | 1914 ++++++++++++++++++++++
 drivers/net/ethernet/marvell/pp3/qm/mv_qm.h      |  706 ++++++++
 drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.c |  498 ++++++
 drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.h | 1124 +++++++++++++
 6 files changed, 4244 insertions(+), 93 deletions(-)
 create mode 100644 drivers/net/ethernet/marvell/pp3/qm/mv_qm.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/qm/mv_qm.h
 create mode 100644 drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.c
 create mode 100644 drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.h

diff --git a/drivers/net/ethernet/marvell/pp3/Makefile b/drivers/net/ethernet/marvell/pp3/Makefile
index c4f4b92..0e082cf 100644
--- a/drivers/net/ethernet/marvell/pp3/Makefile
+++ b/drivers/net/ethernet/marvell/pp3/Makefile
@@ -10,4 +10,5 @@ mv_pp3-objs := net_dev/mv_netdev.o hmac/mv_hmac.o emac/mv_emac.o
 mv_pp3-objs += emac/mv_emac_sysfs.o hmac/mv_hmac_sysfs.o net_dev/mv_dev_sysfs.o
 mv_pp3-objs += gmac/mv_gmac.o fw/mv_channel_if.o common/mv_stack.o
 mv_pp3-objs += fw/mv_fw.o fw/mv_fw_sysfs.o
-mv_pp3-objs += bm/mv_bm.o bm/mv_bm_sysfs.o bm/mv_bm_regs.o
\ No newline at end of file
+mv_pp3-objs += bm/mv_bm.o bm/mv_bm_sysfs.o bm/mv_bm_regs.o
+mv_pp3-objs += qm/mv_qm.o qm/mv_qm_regs.o
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
index e2ca576..fda771b 100644
--- a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
@@ -2932,98 +2932,6 @@ int bm_pool_disable(u32 pool)
 	return rc;
 }
 
-#ifdef __linux__
-/*
-	DUMMY
-	See QM project in mv_qm.c
-*/
-int qm_pfe_base_address_pool_set(u32 *pl_base_address, u32 *qece_base_address)
-{
-	int rc = -BM_INPUT_NOT_IN_RANGE;
-
-	rc = OK;
-	return rc;
-}
-/*
-int qm_pfe_base_address_pool_set(u32 *qece_base_address, u32 *pyld_base_address)
-{
-	int rc = -QM_INPUT_NOT_IN_RANGE;
-	struct pfe_qece_dram_base_address_hi         reg_qece_dram_base_address_hi;
-	struct pfe_qece_dram_base_address_lo         reg_qece_dram_base_address_lo;
-	struct pfe_pyld_dram_base_address_hi         reg_pyld_dram_base_address_hi;
-	struct pfe_pyld_dram_base_address_lo         reg_pyld_dram_base_address_lo;
-	u32 reg_base_address, reg_size, reg_offset;
-
-	if ((((struct mv_word40 *)qece_base_address)->hi < BM_DRAM_ADDRESS_HI_MIN) ||
-		(((struct mv_word40 *)qece_base_address)->hi > BM_DRAM_ADDRESS_HI_MAX))
-		return rc;
-	if ((((struct mv_word40 *)qece_base_address)->lo < BM_DRAM_ADDRESS_LO_MIN) ||
-		(((struct mv_word40 *)qece_base_address)->lo > BM_DRAM_ADDRESS_LO_MAX))
-		return rc;
-	if ((((struct mv_word40 *)pyld_base_address)->hi < BM_DRAM_ADDRESS_HI_MIN) ||
-		(((struct mv_word40 *)pyld_base_address)->hi > BM_DRAM_ADDRESS_HI_MAX))
-		return rc;
-	if ((((struct mv_word40 *)pyld_base_address)->lo < BM_DRAM_ADDRESS_LO_MIN) ||
-		(((struct mv_word40 *)pyld_base_address)->lo > BM_DRAM_ADDRESS_LO_MAX))
-		return rc;
-
-	reg_base_address =      qm.pfe.qece_dram_base_address_hi;
-	reg_size   =   qm_reg_size.pfe.qece_dram_base_address_hi;
-	reg_offset = qm_reg_offset.pfe.qece_dram_base_address_hi * 0;
-
-	rc = bm_register_read( reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_hi);
-	if (rc != OK)
-		return rc;
-
-	reg_qece_dram_base_address_hi.qece_dram_base_address_hi	= ((struct mv_word40 *)qece_base_address)->hi;
-	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_hi);
-	if (rc != OK)
-		return rc;
-
-	reg_base_address =      qm.pfe.qece_dram_base_address_lo;
-	reg_size   =   qm_reg_size.pfe.qece_dram_base_address_lo;
-	reg_offset = qm_reg_offset.pfe.qece_dram_base_address_lo * 0;
-
-	rc = bm_register_read( reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_lo);
-	if (rc != OK)
-		return rc;
-	reg_qece_dram_base_address_lo.qece_dram_base_address_low = ((struct mv_word40 *)qece_base_address)->lo;
-	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_lo);
-	if (rc != OK)
-		return rc;
-
-	reg_base_address =      qm.pfe.pyld_dram_base_address_hi;
-	reg_size   =   qm_reg_size.pfe.pyld_dram_base_address_hi;
-	reg_offset = qm_reg_offset.pfe.pyld_dram_base_address_hi * 0;
-
-	rc = bm_register_read( reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_hi);
-	if (rc != OK)
-		return rc;
-	reg_pyld_dram_base_address_hi.pyld_dram_base_address_hi	 = ((struct mv_word40 *)pyld_base_address)->hi;
-	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_hi);
-	if (rc != OK)
-		return rc;
-
-	reg_base_address =      qm.pfe.pyld_dram_base_address_lo;
-	reg_size   =   qm_reg_size.pfe.pyld_dram_base_address_lo;
-	reg_offset = qm_reg_offset.pfe.pyld_dram_base_address_lo * 0;
-
-	rc = bm_register_read( reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_lo);
-	if (rc != OK)
-		return rc;
-	reg_pyld_dram_base_address_lo.pyld_dram_base_address_low = ((struct mv_word40 *)pyld_base_address)->lo;
-	rc = bm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_lo);
-	if (rc != OK)
-		return rc;
-
-	rc = OK;
-	return rc;
-}
-*/
-
-#else /* __linux__ */
-#endif /* __linux__ */
-
 #define	COMPLETE_HW_WRITE
 
 #define	my_RW_DEBUG_UNITEST	/* for unitest */
diff --git a/drivers/net/ethernet/marvell/pp3/qm/mv_qm.c b/drivers/net/ethernet/marvell/pp3/qm/mv_qm.c
new file mode 100644
index 0000000..f09bba7
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/qm/mv_qm.c
@@ -0,0 +1,1914 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+/* includes */
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+#include "qm/mv_qm.h"
+#include "qm/mv_qm_regs.h"
+
+/**
+ */
+int qm_open(void)
+{
+	int rc;
+
+	rc = qm_reg_address_alias_init();
+	if (rc != OK)
+		return rc;
+	rc = qm_reg_size_alias_init();
+	if (rc != OK)
+		return rc;
+	rc = qm_reg_offset_alias_init();
+/*
+	if (rc != OK)
+		return rc;
+	rc = qm_pid_bid_init();
+*/
+	return rc;
+}
+
+/**
+ */
+int qm_close(void)
+{
+	int rc = OK;
+
+	return rc;
+}
+
+/**
+ */
+int qm_restart(void)
+{
+	int rc = OK;
+
+	return rc;
+}
+
+int qm_pfe_base_address_pool_set(u32 *qece_base_address, u32 *pyld_base_address)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	struct pfe_qece_dram_base_address_hi         reg_qece_dram_base_address_hi;
+	struct pfe_qece_dram_base_address_lo         reg_qece_dram_base_address_lo;
+	struct pfe_pyld_dram_base_address_hi         reg_pyld_dram_base_address_hi;
+	struct pfe_pyld_dram_base_address_lo         reg_pyld_dram_base_address_lo;
+
+	reg_base_address =      qm.pfe.qece_dram_base_address_hi;
+	reg_size   =   qm_reg_size.pfe.qece_dram_base_address_hi;
+	reg_offset = qm_reg_offset.pfe.qece_dram_base_address_hi * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_hi);
+	if (rc != OK)
+		return rc;
+
+	reg_qece_dram_base_address_hi.qece_dram_base_address_hi	 = ((struct mv_word40 *)qece_base_address)->hi;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_hi);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.qece_dram_base_address_lo;
+	reg_size   =   qm_reg_size.pfe.qece_dram_base_address_lo;
+	reg_offset = qm_reg_offset.pfe.qece_dram_base_address_lo * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_lo);
+	if (rc != OK)
+		return rc;
+
+	reg_qece_dram_base_address_lo.qece_dram_base_address_low = ((struct mv_word40 *)qece_base_address)->lo;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qece_dram_base_address_lo);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.pyld_dram_base_address_hi;
+	reg_size   =   qm_reg_size.pfe.pyld_dram_base_address_hi;
+	reg_offset = qm_reg_offset.pfe.pyld_dram_base_address_hi * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_hi);
+	if (rc != OK)
+		return rc;
+	reg_pyld_dram_base_address_hi.pyld_dram_base_address_hi	 = ((struct mv_word40 *)pyld_base_address)->hi;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_hi);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.pyld_dram_base_address_lo;
+	reg_size   =   qm_reg_size.pfe.pyld_dram_base_address_lo;
+	reg_offset = qm_reg_offset.pfe.pyld_dram_base_address_lo * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_lo);
+	if (rc != OK)
+		return rc;
+
+	reg_pyld_dram_base_address_lo.pyld_dram_base_address_low = ((struct mv_word40 *)pyld_base_address)->lo;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pyld_dram_base_address_lo);
+
+	return rc;
+}
+
+/*int qm_enable(u32 qe_thr_hi, u32 qe_thr_lo, u32 pl_thr_hi, u32 pl_thr_lo)
+int qm_enable(u32 gpm_qe_thr_hi, u32 gpm_qe_thr_lo, u32 gpm_pl_thr_hi, u32 gpm_pl_thr_lo,
+			u32 dram_qe_thr_hi, u32 dram_qe_thr_lo, u32 dram_pl_thr_hi, u32 dram_pl_thr_lo)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((gpm_qe_thr_hi  <  QM_GPM_QE_THR_HI_MIN) || (gpm_qe_thr_hi  >  QM_GPM_QE_THR_HI_MAX)) return rc;
+	if ((gpm_qe_thr_lo  <  QM_GPM_QE_THR_LO_MIN) || (gpm_qe_thr_lo  >  QM_GPM_QE_THR_LO_MAX)) return rc;
+	if ((gpm_pl_thr_hi  <  QM_GPM_PL_THR_HI_MIN) || (gpm_pl_thr_hi  >  QM_GPM_PL_THR_HI_MAX)) return rc;
+	if ((gpm_pl_thr_lo  <  QM_GPM_PL_THR_LO_MIN) || (gpm_pl_thr_lo  >  QM_GPM_PL_THR_LO_MAX)) return rc;
+	if ((dram_qe_thr_hi < QM_DRAM_QE_THR_HI_MIN) || (dram_qe_thr_hi > QM_DRAM_QE_THR_HI_MAX)) return rc;
+	if ((dram_qe_thr_lo < QM_DRAM_QE_THR_LO_MIN) || (dram_qe_thr_lo > QM_DRAM_QE_THR_LO_MAX)) return rc;
+	if ((dram_pl_thr_hi < QM_DRAM_PL_THR_HI_MIN) || (dram_pl_thr_hi > QM_DRAM_PL_THR_HI_MAX)) return rc;
+	if ((dram_pl_thr_lo < QM_DRAM_PL_THR_LO_MIN) || (dram_pl_thr_lo > QM_DRAM_PL_THR_LO_MAX)) return rc;
+
+	rc =  qm_gpm_pool_thr_set(gpm_qe_thr_hi,  gpm_qe_thr_lo,  gpm_pl_thr_hi,  gpm_pl_thr_lo); if (rc) return rc;
+	rc = qm_dram_pool_thr_set(dram_qe_thr_hi, dram_qe_thr_lo, dram_pl_thr_hi, dram_pl_thr_lo); if (rc) return rc;
+
+	return rc;
+}
+*/
+
+int qm_dma_gpm_pools_def_enable(void)
+{
+	int rc = OK;
+	u32 qece_thr_hi, qece_thr_lo, pl_thr_hi, pl_thr_lo;
+
+	qece_thr_hi = QM_GPM_QE_THR_HI_DEF;
+	qece_thr_lo = QM_GPM_QE_THR_LO_DEF;
+	pl_thr_hi   = QM_GPM_PL_THR_HI_DEF;
+	pl_thr_lo   = QM_GPM_PL_THR_LO_DEF;
+
+	rc = qm_dma_gpm_pools_enable(qece_thr_hi, qece_thr_lo, pl_thr_hi, pl_thr_lo);
+	return rc;
+}
+
+int qm_dma_gpm_pools_enable(u32 qece_thr_hi, u32 qece_thr_lo, u32 pl_thr_hi, u32 pl_thr_lo)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct dma_gpm_thresholds reg_gpm_thresholds;	/* RW */
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((qece_thr_hi < QM_GPM_QE_THR_HI_MIN) || (qece_thr_hi > QM_GPM_QE_THR_HI_MAX))
+		return rc;
+	if ((qece_thr_lo < QM_GPM_QE_THR_LO_MIN) || (qece_thr_lo > QM_GPM_QE_THR_LO_MAX))
+		return rc;
+	if ((pl_thr_hi   < QM_GPM_PL_THR_HI_MIN) || (pl_thr_hi   > QM_GPM_PL_THR_HI_MAX))
+		return rc;
+	if ((pl_thr_lo   < QM_GPM_PL_THR_LO_MIN) || (pl_thr_lo   > QM_GPM_PL_THR_LO_MAX))
+		return rc;
+
+	reg_base_address =      qm.dma.gpm_thresholds;
+	reg_size   =   qm_reg_size.dma.gpm_thresholds;
+	reg_offset = qm_reg_offset.dma.gpm_thresholds * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_gpm_thresholds);
+	if (rc != OK)
+		return rc;
+	reg_gpm_thresholds.gpm_qe_pool_low_bp  = qece_thr_lo;	/* qe_thr & 0x00FFFFFFFF; */
+	reg_gpm_thresholds.gpm_qe_pool_high_bp = qece_thr_hi;	/* qe_thr >> 32; */
+	reg_gpm_thresholds.gpm_pl_pool_low_bp  =   pl_thr_lo;	/* pl_thr & 0x00FFFFFFFF; */
+	reg_gpm_thresholds.gpm_pl_pool_high_bp =   pl_thr_hi;	/* pl_thr >> 32; */
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_gpm_thresholds);
+
+	return rc;
+}
+
+int qm_dma_dram_pools_def_enable(void)
+{
+	int rc = OK;
+	u32 qece_thr_hi, qece_thr_lo, pl_thr_hi, pl_thr_lo;
+
+	qece_thr_hi = QM_DRAM_QE_THR_HI_DEF;
+	qece_thr_lo = QM_DRAM_QE_THR_LO_DEF;
+	pl_thr_hi   = QM_DRAM_PL_THR_HI_DEF;
+	pl_thr_lo   = QM_DRAM_PL_THR_LO_DEF;
+
+	rc = qm_dma_dram_pools_enable(qece_thr_hi, qece_thr_lo, pl_thr_hi, pl_thr_lo);
+	return rc;
+}
+
+int qm_dma_dram_pools_enable(u32 qece_thr_hi, u32 qece_thr_lo, u32 pl_thr_hi, u32 pl_thr_lo)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct dma_dram_thresholds reg_dram_thresholds;	/* RW */
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((qece_thr_hi < QM_GPM_QE_THR_HI_MIN) || (qece_thr_hi > QM_GPM_QE_THR_HI_MAX))
+		return rc;
+	if ((qece_thr_lo < QM_GPM_QE_THR_LO_MIN) || (qece_thr_lo > QM_GPM_QE_THR_LO_MAX))
+		return rc;
+	if ((pl_thr_hi   < QM_GPM_PL_THR_HI_MIN) || (pl_thr_hi   > QM_GPM_PL_THR_HI_MAX))
+		return rc;
+	if ((pl_thr_lo   < QM_GPM_PL_THR_LO_MIN) || (pl_thr_lo   > QM_GPM_PL_THR_LO_MAX))
+		return rc;
+
+	reg_base_address =      qm.dma.dram_thresholds;
+	reg_size   =   qm_reg_size.dma.dram_thresholds;
+	reg_offset = qm_reg_offset.dma.dram_thresholds * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_thresholds);
+	if (rc != OK)
+		return rc;
+	reg_dram_thresholds.dram_qe_pool_low_bp  = qece_thr_lo;	/* qe_thr & 0x00FFFFFFFF; */
+	reg_dram_thresholds.dram_qe_pool_high_bp = qece_thr_hi;	/* qe_thr >> 32; */
+	reg_dram_thresholds.dram_pl_pool_low_bp  =   pl_thr_lo;	/* pl_thr & 0x00FFFFFFFF; */
+	reg_dram_thresholds.dram_pl_pool_high_bp =   pl_thr_hi;	/* pl_thr >> 32; */
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_dram_thresholds);
+	return rc;
+}
+
+int qm_dma_queue_memory_type_set(u32 queue, u32 memory_type)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct dma_q_memory_allocation        reg_q_memory_allocation;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((queue       <       QM_QUEUE_MIN) || (queue       >       QM_QUEUE_MAX))
+		return rc;
+	if ((memory_type < QM_MEMORY_TYPE_MIN) || (memory_type > QM_MEMORY_TYPE_MAX))
+		return rc;
+
+	reg_base_address =      qm.dma.Q_memory_allocation;
+	reg_size   =   qm_reg_size.dma.Q_memory_allocation;
+	reg_offset = qm_reg_offset.dma.Q_memory_allocation * (queue/32);
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_q_memory_allocation);
+	if (rc != OK)
+		return rc;
+
+	switch (memory_type) {
+	case GPM_MEMORY_TYPE:
+		reg_q_memory_allocation.q_memory &= ~(0x00000001 << (queue%32));
+		break;
+	case DRAM_MEMORY_TYPE:
+		reg_q_memory_allocation.q_memory |=  (0x00000001 << (queue%32));
+		break;
+	default:
+		rc = -QM_WRONG_MEMORY_TYPE;
+		return rc;
+	}
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_q_memory_allocation);
+	return rc;
+}
+
+/*
+int qm_disable(void)
+TBD Â– ask yuval peleg defined bits to stops and bit to check if it is stopped{
+	int rc = !OK;
+	int reg_size;
+
+	if (rc = dma_gpm_pool_thr_set(0, 0, 0, 0))
+		return rc;
+	if (rc = dma_dram_pool_thr_set(0, 0, 0, 0))
+
+	return rc;
+}
+*/
+
+int qm_packets_in_queues(u32 *status)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	int queue;
+	struct ql_qlen reg_qlen;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	*status = 0;
+
+	for (queue = 0; queue < QM_QUEUE_MAX; queue++) {
+		reg_base_address =      qm.ql.qlen;
+		reg_size   =   qm_reg_size.ql.qlen;
+		reg_offset = qm_reg_offset.ql.qlen * queue;
+
+		rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qlen);
+		if (rc != OK)
+			return rc;
+		if (reg_qlen.reg_ql_entry.ql > 0)
+			*status = 1;
+	}
+
+	rc = OK;
+	return rc;
+}
+
+int qm_default_set(void)
+{
+	int rc = !OK;
+
+	rc = qm_ru_port_to_class_def_set();
+	if (rc != OK)
+		return rc;
+	rc = qm_ru_pool_sid_number_def_set();
+	if (rc != OK)
+		return rc;
+	rc = qm_dqf_port_data_fifo_def_set();
+	if (rc != OK)
+		return rc;
+	rc = qm_dqf_port_credit_thr_def_set();
+	if (rc != OK)
+		return rc;
+	rc = qm_dqf_port_ppc_map_def_set();
+	if (rc != OK)
+		return rc;
+	rc = qm_dma_qos_attr_def_set();
+	if (rc != OK)
+		return rc;
+	rc = qm_dma_domain_attr_def_set();
+	if (rc != OK)
+		return rc;
+	rc = qm_dma_cache_attr_def_set();
+	if (rc != OK)
+		return rc;
+	rc = qm_pfe_qos_attr_def_set();
+	if (rc != OK)
+		return rc;
+	rc = qm_pfe_domain_attr_def_set();
+	if (rc != OK)
+		return rc;
+	rc = qm_pfe_cache_attr_def_set();
+	if (rc != OK)
+		return rc;
+	rc = qm_ql_thr_def_set();
+	if (rc != OK)
+		return rc;
+	rc = qm_ql_q_profile_def_set();
+	if (rc != OK)
+		return rc;
+
+	return rc;
+}
+
+int qm_ru_pool_sid_number_def_set(void)
+{
+	int rc = !OK;
+	u32 pool0_sid_num, pool1_sid_num;
+
+	pool0_sid_num = QM_POOL0_SID_NUM_DEF;
+	pool1_sid_num = QM_POOL1_SID_NUM_DEF;
+
+	rc = qm_ru_pool_sid_number_set(pool0_sid_num, pool1_sid_num);
+	return rc;
+}
+
+int qm_ru_pool_sid_number_set(u32 pool0_sid_num, u32 pool1_sid_num)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct reorder_ru_pool         reg_ru_pool;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((pool0_sid_num < QM_POOL0_SID_NUM_MIN) || (pool0_sid_num > QM_POOL0_SID_NUM_MAX))
+		return rc;
+	if ((pool1_sid_num < QM_POOL1_SID_NUM_MIN) || (pool1_sid_num > QM_POOL1_SID_NUM_MAX))
+		return rc;
+
+	reg_base_address =      qm.reorder.ru_pool;
+	reg_size   =   qm_reg_size.reorder.ru_pool;
+	reg_offset = qm_reg_offset.reorder.ru_pool * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_ru_pool);
+	if (rc != OK)
+		return rc;
+	reg_ru_pool.sid_limit   = pool0_sid_num;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_ru_pool);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.reorder.ru_pool;
+	reg_size   =   qm_reg_size.reorder.ru_pool;
+	reg_offset = qm_reg_offset.reorder.ru_pool * 1;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_ru_pool);
+	if (rc != OK)
+		return rc;
+	reg_ru_pool.sid_limit   = pool1_sid_num;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_ru_pool);
+	return rc;
+}
+
+int qm_ru_port_to_class_def_set(void)
+{
+	int rc = !OK;
+	u32 port_class_arr, port_pool_arr, arrays_size, input_port;
+
+	port_pool_arr  = QM_PORT_ARR_DEF;
+	arrays_size    = QM_ARRAYS_SIZE_DEF;
+
+	/* cMac and eMac */
+	for (input_port = QM_INPUT_PORT_CMAC_EMAC_MIN; input_port <= QM_INPUT_PORT_CMAC_EMAC_MAX; input_port++) {
+		port_class_arr = QM_CLASS_ARR_CMAC_EMAC_DEF;
+		rc = qm_ru_port_to_class_set(&port_class_arr, &port_pool_arr, input_port);
+		if (rc != OK)
+			return rc;
+	}
+
+	/* hMac */
+	for (input_port = QM_INPUT_PORT_HMAC_MIN; input_port <= QM_INPUT_PORT_HMAC_MAX; input_port++) {
+		port_class_arr = QM_CLASS_ARR_HMAC_DEF;
+		rc = qm_ru_port_to_class_set(&port_class_arr, &port_pool_arr, input_port);
+		if (rc != OK)
+			return rc;
+	}
+
+	/* PPC */
+	for (input_port = QM_INPUT_PORT_PPC_MIN; input_port <= QM_INPUT_PORT_PPC_MAX; input_port++) {
+		port_class_arr = QM_CLASS_ARR_PPC_DEF;
+		rc = qm_ru_port_to_class_set(&port_class_arr, &port_pool_arr, input_port);
+		if (rc != OK)
+			return rc;
+	}
+
+	rc = OK;
+	return rc;
+}
+/*
+port_class_arr holds class values which are in the range 0 to 63.
+Default values are:
+for input port  0 to  7 (cMac and eMac) class is 0 to 7 (respectively).
+For input port  8 to 71 (hMac) class is 8.
+For Input port 72 to 89  (PPC) class is 9.
+Port input 90 to 287 are not used so disregard their value.
+Classes 10 to 63 are left unused for future use.
+
+port_pool_arr holds pool  values which are either 0 or 1 (default values are pool 0 for all input ports)
+
+arrays_size holds the size of each array. Size can be a value from 90
+(current implementation to 288 (since input port is 0 to 287)
+*/
+
+int qm_ru_port_to_class_set(u32 *port_class_arr, u32 *port_pool_arr, u32 input_port)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+/*	struct reorder_ru_pool       reg_ru_pool;*/
+	u32 reg_base_address, reg_size, reg_offset;
+	struct reorder_ru_port2class reg_ru_port2class;
+
+	if ((*port_class_arr < QM_CLASS_ARR_MIN)   || (*port_class_arr >   QM_CLASS_ARR_MAX))
+		return rc;
+	if ((*port_pool_arr  < QM_PORT_ARR_MIN)    || (*port_pool_arr  >    QM_PORT_ARR_MAX))
+		return rc;
+	if ((input_port      < QM_ARRAYS_SIZE_MIN) || (input_port      > QM_ARRAYS_SIZE_MAX))
+		return rc;
+
+	reg_base_address =      qm.reorder.ru_port2class;
+	reg_size   =   qm_reg_size.reorder.ru_port2class;
+	reg_offset = qm_reg_offset.reorder.ru_port2class * input_port; /* ??? */
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_ru_port2class);
+	if (rc != OK)
+		return rc;
+	reg_ru_port2class.ru_class = *port_class_arr;
+	reg_ru_port2class.ru_pool  = *port_pool_arr;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_ru_port2class);
+	return rc;
+}
+
+int qm_dqf_port_data_fifo_def_set(void)
+{
+	int rc = !OK;
+	u32 port_depth_arr[QM_PORT_MAX + 1];
+
+	port_depth_arr[0]  = QM_PORT_DEPTH_ARR_PPC0_DEF;	/* 2*144B for PPC0		*/
+	port_depth_arr[1]  = QM_PORT_DEPTH_ARR_PPC1_DEF;	/* 1*144B for PPC1-mnt0	*/
+	port_depth_arr[2]  = QM_PORT_DEPTH_ARR_PPC1_DEF;	/* 1*144B for PPC1-mnt1	*/
+	port_depth_arr[3]  = QM_PORT_DEPTH_ARR_EMAC_DEF;	/*  2560B for eMac0		*/
+	port_depth_arr[4]  = QM_PORT_DEPTH_ARR_EMAC_DEF;	/*  2560B for eMac1		*/
+	port_depth_arr[5]  = QM_PORT_DEPTH_ARR_EMAC_DEF;	/*  2560B for eMac2		*/
+	port_depth_arr[6]  = QM_PORT_DEPTH_ARR_EMAC_DEF;	/*  2560B for eMac3		*/
+	port_depth_arr[7]  = QM_PORT_DEPTH_ARR_EMAC_DEF;	/*  2560B for eMac4		*/
+	port_depth_arr[8]  = QM_PORT_DEPTH_ARR_CMAC0_DEF;	/*  2560B for cMac0		*/
+	port_depth_arr[9]  = QM_PORT_DEPTH_ARR_CMAC1_DEF;	/*   512B for cMac1		*/
+	port_depth_arr[10] = QM_PORT_DEPTH_ARR_HMAC_DEF;	/*   512B for hMac		*/
+	port_depth_arr[11] = 0;
+	port_depth_arr[12] = 0;
+	port_depth_arr[13] = 0;
+	port_depth_arr[14] = 0;
+	port_depth_arr[15] = 0;
+
+	rc = qm_dqf_port_data_fifo_set(port_depth_arr);
+	return rc;
+}
+
+int qm_dqf_port_data_fifo_set(u32 *port_depth_arr)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct dqf_Data_FIFO_params_p          reg_Data_FIFO_params_p;
+	u32 reg_base_address, reg_size, reg_offset;
+	u32 port, port_depth_arr_sum = 0, data_fifo_ppc_counter = 0, data_fifo_mac_counter = 0;
+
+	for (port = QM_PORT_MIN; port <= QM_PORT_MAX; port++) {
+		if ((port_depth_arr[port] % GRANULARITY_OF_16_BYTES) != 0)
+			return rc;
+		port_depth_arr_sum = port_depth_arr_sum + port_depth_arr[port];
+		if ((port_depth_arr[port] < QM_PORT_DEPTH_ARR_MIN) || (port_depth_arr_sum > QM_PORT_DEPTH_ARR_SUM_MAX))
+			return rc;
+	}
+
+	for (port = QM_PORT_MIN; port <= QM_PORT_MAX; port++) {
+		reg_base_address =      qm.dqf.Data_FIFO_params_p;
+		reg_size   =   qm_reg_size.dqf.Data_FIFO_params_p;
+		reg_offset = qm_reg_offset.dqf.Data_FIFO_params_p * port;
+
+		rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_Data_FIFO_params_p);
+		if (rc != OK)
+			return rc;
+
+		switch (port) {
+		case 0:
+			reg_Data_FIFO_params_p.data_fifo_base_p   = data_fifo_ppc_counter;	/*      0 */
+			data_fifo_ppc_counter += (port_depth_arr[port] / QM_SIZE_OF_PORT_DEPTH_ARR_PPC_IN_BYTES);
+			reg_Data_FIFO_params_p.data_fifo_depth_p  = data_fifo_ppc_counter;	/*      2 */
+			break;
+		case 1:
+			reg_Data_FIFO_params_p.data_fifo_base_p   = data_fifo_ppc_counter;	/*      2 */
+			data_fifo_ppc_counter += (port_depth_arr[port] / QM_SIZE_OF_PORT_DEPTH_ARR_PPC_IN_BYTES);
+			reg_Data_FIFO_params_p.data_fifo_depth_p  = data_fifo_ppc_counter;	/*      1 */
+			break;
+		case 2:
+			reg_Data_FIFO_params_p.data_fifo_base_p   = data_fifo_ppc_counter;	/*      3 */
+			data_fifo_ppc_counter += (port_depth_arr[port] / QM_SIZE_OF_PORT_DEPTH_ARR_PPC_IN_BYTES);
+			reg_Data_FIFO_params_p.data_fifo_depth_p  = data_fifo_ppc_counter;	/*      1 */
+			break;
+		case 3:
+			reg_Data_FIFO_params_p.data_fifo_base_p   = data_fifo_mac_counter;	/*      0 */
+			data_fifo_mac_counter += (port_depth_arr[port] / QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES);
+			reg_Data_FIFO_params_p.data_fifo_depth_p  = data_fifo_mac_counter;	/* 0x00A0 */
+			break;
+		case 4:
+			reg_Data_FIFO_params_p.data_fifo_base_p   = data_fifo_mac_counter;	/* 0x00A0 */
+			data_fifo_mac_counter += (port_depth_arr[port] / QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES);
+			reg_Data_FIFO_params_p.data_fifo_depth_p  = data_fifo_mac_counter;	/* 0x0140 */
+			break;
+		case 5:
+			reg_Data_FIFO_params_p.data_fifo_base_p   = data_fifo_mac_counter;	/* 0x0140 */
+			data_fifo_mac_counter += (port_depth_arr[port] / QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES);
+			reg_Data_FIFO_params_p.data_fifo_depth_p  = data_fifo_mac_counter;	/* 0x01E0 */
+			break;
+		case 6:
+			reg_Data_FIFO_params_p.data_fifo_base_p   = data_fifo_mac_counter;	/* 0x01E0 */
+			data_fifo_mac_counter += (port_depth_arr[port] / QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES);
+			reg_Data_FIFO_params_p.data_fifo_depth_p  = data_fifo_mac_counter;	/* 0x0280 */
+			break;
+		case 7:
+			reg_Data_FIFO_params_p.data_fifo_base_p   = data_fifo_mac_counter;	/* 0x0280 */
+			data_fifo_mac_counter += (port_depth_arr[port] / QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES);
+			reg_Data_FIFO_params_p.data_fifo_depth_p  = data_fifo_mac_counter;	/* 0x0320 */
+			break;
+		case 8:
+			reg_Data_FIFO_params_p.data_fifo_base_p   = data_fifo_mac_counter;	/* 0x0320 */
+			data_fifo_mac_counter += (port_depth_arr[port] / QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES);
+			reg_Data_FIFO_params_p.data_fifo_depth_p  = data_fifo_mac_counter;	/* 0x03C0 */
+			break;
+		case 9:
+			reg_Data_FIFO_params_p.data_fifo_base_p   = data_fifo_mac_counter;	/* 0x03C0 */
+			data_fifo_mac_counter += (port_depth_arr[port] / QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES);
+			reg_Data_FIFO_params_p.data_fifo_depth_p  = data_fifo_mac_counter;	/* 0x03E0 */
+			break;
+		case 10:
+			reg_Data_FIFO_params_p.data_fifo_base_p   = data_fifo_mac_counter;	/* 0x03E0 */
+			data_fifo_mac_counter += (port_depth_arr[port] / QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES);
+			reg_Data_FIFO_params_p.data_fifo_depth_p  = data_fifo_mac_counter;	/* 0x0400 */
+			break;
+		default:
+			return rc;
+		}
+		rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_Data_FIFO_params_p);
+		if (rc != OK)
+			return rc;
+	}
+
+	rc = OK;
+	return rc;
+}
+
+int qm_dqf_port_credit_thr_def_set(void)
+/*int qm_ru_port_to_class_def_set()*/
+{
+	int rc = !OK;
+	u32 port_credit_thr_arr[QM_PORT_MAX + 1];
+
+	port_credit_thr_arr[0]  = 0;
+	port_credit_thr_arr[1]  = 0;
+	port_credit_thr_arr[2]  = 0;
+	port_credit_thr_arr[3]  = QM_PORT_CREDIT_THR_ARR_EMAC_DEF;	/*  2432B for eMac0		*/
+	port_credit_thr_arr[4]  = QM_PORT_CREDIT_THR_ARR_EMAC_DEF;	/*  2432B for eMac1		*/
+	port_credit_thr_arr[5]  = QM_PORT_CREDIT_THR_ARR_EMAC_DEF;	/*  2432B for eMac2		*/
+	port_credit_thr_arr[6]  = QM_PORT_CREDIT_THR_ARR_EMAC_DEF;	/*  2432B for eMac3		*/
+	port_credit_thr_arr[7]  = QM_PORT_CREDIT_THR_ARR_EMAC_DEF;	/*  2432B for eMac4		*/
+	port_credit_thr_arr[8]  = QM_PORT_CREDIT_THR_ARR_CMAC0_DEF;	/*  2432B for cMac0		*/
+	port_credit_thr_arr[9]  = QM_PORT_CREDIT_THR_ARR_CMAC1_DEF;	/*   384B for cMac1		*/
+	port_credit_thr_arr[10] = QM_PORT_CREDIT_THR_ARR_HMAC_DEF;	/*   384B for hMac		*/
+	port_credit_thr_arr[11] = 0;
+	port_credit_thr_arr[12] = 0;
+	port_credit_thr_arr[13] = 0;
+	port_credit_thr_arr[14] = 0;
+	port_credit_thr_arr[15] = 0;
+
+	rc = qm_dqf_port_credit_thr_set(port_credit_thr_arr);
+	return rc;
+}
+
+int qm_dqf_port_credit_thr_set(u32 *port_credit_thr_arr)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct dqf_Data_FIFO_params_p          reg_Data_FIFO_params_p;
+	struct dqf_Credit_Threshold_p          reg_Credit_Threshold_p;
+	u32 reg_base_address, reg_size, reg_offset;
+	u32 port, data_fifo_depth_p;
+
+	for (port = QM_PORT_MAC_MIN; port <= QM_PORT_MAC_MAX; port++) {
+		reg_base_address =      qm.dqf.Data_FIFO_params_p;
+		reg_size   =   qm_reg_size.dqf.Data_FIFO_params_p;
+		reg_offset = qm_reg_offset.dqf.Data_FIFO_params_p * port;
+
+		rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_Data_FIFO_params_p);
+		if (rc != OK)
+			return rc;
+		data_fifo_depth_p = reg_Data_FIFO_params_p.data_fifo_depth_p;
+
+		if ((port_credit_thr_arr[port] % GRANULARITY_OF_16_BYTES) != 0)
+			return rc;
+		if ((port_credit_thr_arr[port] < QM_PORT_CREDIT_THR_ARR_MIN) ||
+			(port_credit_thr_arr[port] > QM_PORT_CREDIT_THR_ARR_MAX))
+			return rc;
+	}
+
+	for (port = QM_PORT_MAC_MIN; port <= QM_PORT_MAC_MAX; port++) {
+		reg_base_address =      qm.dqf.Credit_Threshold_p;
+		reg_size   =   qm_reg_size.dqf.Credit_Threshold_p;
+		reg_offset = qm_reg_offset.dqf.Credit_Threshold_p * port;
+
+		rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_Credit_Threshold_p);
+		if (rc != OK)
+			return rc;
+
+		reg_Credit_Threshold_p.Credit_Threshold_p   = port_credit_thr_arr[port];
+
+		rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_Credit_Threshold_p);
+		if (rc != OK)
+			return rc;
+	}
+
+	rc = OK;
+	return rc;
+}
+
+int qm_dqf_port_ppc_map_def_set(void)
+{
+	int rc = !OK;
+	u32 port_ppc_arr[QM_PORT_MAX + 1];
+	u32 port;
+
+	port_ppc_arr[0]  = QM_PORT_PPC_ARR_PPC0_DEF;	/* 1 for PPC0      */
+	port_ppc_arr[1]  = QM_PORT_PPC_ARR_PPC1_DEF;	/* 2 for PPC1-mnt0 */
+	port_ppc_arr[2]  = QM_PORT_PPC_ARR_PPC1_DEF;	/* 2 for PPC1-mnt1 */
+	port_ppc_arr[3]  = 0;
+	port_ppc_arr[4]  = 0;
+	port_ppc_arr[5]  = 0;
+	port_ppc_arr[6]  = 0;
+	port_ppc_arr[7]  = 0;
+	port_ppc_arr[8]  = 0;
+	port_ppc_arr[9]  = 0;
+	port_ppc_arr[10] = 0;
+	port_ppc_arr[11] = 0;
+	port_ppc_arr[12] = 0;
+	port_ppc_arr[13] = 0;
+	port_ppc_arr[14] = 0;
+	port_ppc_arr[15] = 0;
+
+	/* PPC */
+	for (port = QM_PORT_PPC_MIN; port <= QM_PORT_PPC_MAX; port++) {
+		rc = qm_dqf_port_ppc_map_set(&port_ppc_arr[port], port);
+		if (rc != OK)
+			return rc;
+	}
+
+	rc = OK;
+	return rc;
+}
+
+int qm_dqf_port_ppc_map_set(u32 *port_ppc, u32 port)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct dqf_PPC_port_map_p              reg_PPC_port_map_p;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((port          < QM_PORT_PPC_MIN) || (port          >  QM_PORT_PPC_MAX))
+		return rc;
+
+	reg_base_address =      qm.dqf.PPC_port_map_p;
+	reg_size   =   qm_reg_size.dqf.PPC_port_map_p;
+	reg_offset = qm_reg_offset.dqf.PPC_port_map_p * port;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_PPC_port_map_p);
+	if (rc != OK)
+		return rc;
+	reg_PPC_port_map_p.ppc_port_map_p = *port_ppc;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_PPC_port_map_p);
+	return rc;
+}
+
+int qm_dma_qos_attr_def_set(void)
+{
+	int rc = !OK;
+	u32 swf_awqos, rdma_awqos, hwf_qe_ce_awqos, hwf_sfh_pl_awqos;
+
+	swf_awqos        = QM_SWF_AWQOS_DEF;		/* 1 for QM_SWF_AWQOS_DEF        */
+	rdma_awqos       = QM_RDMA_AWQOS_DEF;		/* 1 for QM_RDMA_AWQOS_DEF       */
+	hwf_qe_ce_awqos  = QM_HWF_QE_CE_AWQOS_DEF;	/* 1 for QM_HWF_QE_CE_AWQOS_DEF  */
+	hwf_sfh_pl_awqos = QM_HWF_SFH_PL_AWQOS_DEF;	/* 1 for QM_HWF_SFH_PL_AWQOS_DEF */
+
+	rc = qm_dma_qos_attr_set(swf_awqos, rdma_awqos, hwf_qe_ce_awqos, hwf_sfh_pl_awqos);
+	return rc;
+}
+
+/*
+int qm_axi_swf_write_attr_set(u32 qos,  u32 cache, u32 domain)
+int qm_axi_rdma_write_attr_set(u32 qos, u32 cache, u32 domain)
+int qm_axi_hwf_qece_write_attr_set(u32 qos, u32 cache, u32 domain)
+int qm_axi_hwf_pyl_write_attr_set(u32 qos, u32 cache, u32 domain)
+*/
+int qm_dma_qos_attr_set(u32 swf_awqos, u32 rdma_awqos, u32 hwf_qe_ce_awqos, u32 hwf_sfh_pl_awqos)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct dma_AXI_write_attributes_for_swf_mode  reg_AXI_write_attributes_for_swf_mode;
+	struct dma_AXI_write_attributes_for_rdma_mode reg_AXI_write_attributes_for_rdma_mode;
+	struct dma_AXI_write_attributes_for_hwf_qece  reg_AXI_write_attributes_for_hwf_qece;
+	struct dma_AXI_write_attributes_for_hwf_pyld  reg_AXI_write_attributes_for_hwf_pyld;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((swf_awqos       <         QM_SWF_AWQOS_MIN) || (swf_awqos        >        QM_SWF_AWQOS_MAX))
+		return rc;
+	if ((rdma_awqos      <        QM_RDMA_AWQOS_MIN) || (rdma_awqos       >       QM_RDMA_AWQOS_MAX))
+		return rc;
+	if ((hwf_qe_ce_awqos <   QM_HWF_QE_CE_AWQOS_MIN) || (hwf_qe_ce_awqos  >  QM_HWF_QE_CE_AWQOS_MAX))
+		return rc;
+	if ((hwf_sfh_pl_awqos < QM_HWF_SFH_PL_AWQOS_MIN) || (hwf_sfh_pl_awqos > QM_HWF_SFH_PL_AWQOS_MAX))
+		return rc;
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_swf_mode;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_swf_mode;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_swf_mode * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_swf_mode);
+	if (rc != OK)
+		return rc;
+	reg_AXI_write_attributes_for_swf_mode.swf_awqos    = swf_awqos;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_swf_mode);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_rdma_mode;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_rdma_mode;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_rdma_mode * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_rdma_mode);
+	if (rc != OK)
+		return rc;
+	reg_AXI_write_attributes_for_rdma_mode.rdma_awqos    = rdma_awqos;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_rdma_mode);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_hwf_qece;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_hwf_qece;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_hwf_qece * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_hwf_qece);
+	if (rc != OK)
+		return rc;
+	reg_AXI_write_attributes_for_hwf_qece.qece_awqos    = hwf_qe_ce_awqos;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_hwf_qece);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_hwf_pyld;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_hwf_pyld;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_hwf_pyld * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_hwf_pyld);
+	if (rc != OK)
+		return rc;
+	reg_AXI_write_attributes_for_hwf_pyld.pyld_awqos    = hwf_sfh_pl_awqos;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_hwf_pyld);
+	return rc;
+}
+
+int qm_dma_cache_attr_def_set(void)
+{
+	int rc = !OK;
+	u32 swf_awcache, rdma_awcache, hwf_qe_ce_awcache, hwf_sfh_pl_awcache;
+
+	swf_awcache        = QM_SWF_AWCACHE_DEF;		/* 11 for QM_SWF_AWQOS_DEF        */
+	rdma_awcache       = QM_RDMA_AWCACHE_DEF;		/* 11 for QM_RDMA_AWQOS_DEF       */
+	hwf_qe_ce_awcache  = QM_HWF_QE_CE_AWCACHE_DEF;	/*  3 for QM_HWF_QE_CE_AWQOS_DEF  */
+	hwf_sfh_pl_awcache = QM_HWF_SFH_PL_AWCACHE_DEF;	/*  3 for QM_HWF_SFH_PL_AWQOS_DEF */
+
+	rc = qm_dma_qos_attr_set(swf_awcache, rdma_awcache, hwf_qe_ce_awcache, hwf_sfh_pl_awcache);
+	return rc;
+}
+
+int qm_dma_cache_attr_set(u32 swf_awcache, u32 rdma_awcache, u32 hwf_qe_ce_awcache, u32 hwf_sfh_pl_awcache)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct dma_AXI_write_attributes_for_swf_mode  reg_AXI_write_attributes_for_swf_mode;
+	struct dma_AXI_write_attributes_for_rdma_mode reg_AXI_write_attributes_for_rdma_mode;
+	struct dma_AXI_write_attributes_for_hwf_qece  reg_AXI_write_attributes_for_hwf_qece;
+	struct dma_AXI_write_attributes_for_hwf_pyld  reg_AXI_write_attributes_for_hwf_pyld;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((swf_awcache       <         QM_SWF_AWCACHE_MIN) || (swf_awcache        >        QM_SWF_AWCACHE_MAX))
+		return rc;
+	if ((rdma_awcache      <        QM_RDMA_AWCACHE_MIN) || (rdma_awcache       >       QM_RDMA_AWCACHE_MAX))
+		return rc;
+	if ((hwf_qe_ce_awcache <   QM_HWF_QE_CE_AWCACHE_MIN) || (hwf_qe_ce_awcache  >  QM_HWF_QE_CE_AWCACHE_MAX))
+		return rc;
+	if ((hwf_sfh_pl_awcache < QM_HWF_SFH_PL_AWCACHE_MIN) || (hwf_sfh_pl_awcache > QM_HWF_SFH_PL_AWCACHE_MAX))
+		return rc;
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_swf_mode;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_swf_mode;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_swf_mode * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_swf_mode);
+	if (rc != OK)
+		return rc;
+	reg_AXI_write_attributes_for_swf_mode.swf_awcache  = swf_awcache;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_swf_mode);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_rdma_mode;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_rdma_mode;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_rdma_mode * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_rdma_mode);
+	if (rc != OK)
+		return rc;
+	reg_AXI_write_attributes_for_rdma_mode.rdma_awcache  = rdma_awcache;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_rdma_mode);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_hwf_qece;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_hwf_qece;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_hwf_qece * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_hwf_qece);
+	if (rc != OK)
+		return rc;
+	reg_AXI_write_attributes_for_hwf_qece.qece_awcache  = hwf_qe_ce_awcache;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_hwf_qece);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_hwf_pyld;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_hwf_pyld;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_hwf_pyld * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_hwf_pyld);
+	if (rc != OK)
+		return rc;
+	reg_AXI_write_attributes_for_hwf_pyld.pyld_awcache  = hwf_sfh_pl_awcache;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_hwf_pyld);
+	return rc;
+}
+
+int qm_dma_domain_attr_def_set(void)
+{
+	int rc = !OK;
+	u32 swf_awdomain, rdma_awdomain, hwf_qe_ce_awdomain, hwf_sfh_pl_awdomain;
+
+	swf_awdomain        = QM_SWF_AWDOMAIN_DEF;			/* 2 for QM_SWF_AWDOMAIN_DEF        */
+	rdma_awdomain       = QM_RDMA_AWDOMAIN_DEF;			/* 2 for QM_RDMA_AWDOMAIN_DEF       */
+	hwf_qe_ce_awdomain  = QM_HWF_QE_CE_AWDOMAIN_DEF;	/* 0 for QM_HWF_QE_CE_AWDOMAIN_DEF  */
+	hwf_sfh_pl_awdomain = QM_HWF_SFH_PL_AWDOMAIN_DEF;	/* 0 for QM_HWF_SFH_PL_AWDOMAIN_DEF */
+
+	rc = qm_dma_qos_attr_set(swf_awdomain, rdma_awdomain, hwf_qe_ce_awdomain, hwf_sfh_pl_awdomain);
+	return rc;
+}
+
+int qm_dma_domain_attr_set(u32 swf_awdomain, u32 rdma_awdomain, u32 hwf_qe_ce_awdomain, u32 hwf_sfh_pl_awdomain)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct dma_AXI_write_attributes_for_swf_mode  reg_AXI_write_attributes_for_swf_mode;
+	struct dma_AXI_write_attributes_for_rdma_mode reg_AXI_write_attributes_for_rdma_mode;
+	struct dma_AXI_write_attributes_for_hwf_qece  reg_AXI_write_attributes_for_hwf_qece;
+	struct dma_AXI_write_attributes_for_hwf_pyld  reg_AXI_write_attributes_for_hwf_pyld;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((swf_awdomain       <         QM_SWF_AWDOMAIN_MIN) || (swf_awdomain        >        QM_SWF_AWDOMAIN_MAX))
+		return rc;
+	if ((rdma_awdomain      <        QM_RDMA_AWDOMAIN_MIN) || (rdma_awdomain       >       QM_RDMA_AWDOMAIN_MAX))
+		return rc;
+	if ((hwf_qe_ce_awdomain <   QM_HWF_QE_CE_AWDOMAIN_MIN) || (hwf_qe_ce_awdomain  >  QM_HWF_QE_CE_AWDOMAIN_MAX))
+		return rc;
+	if ((hwf_sfh_pl_awdomain < QM_HWF_SFH_PL_AWDOMAIN_MIN) || (hwf_sfh_pl_awdomain > QM_HWF_SFH_PL_AWDOMAIN_MAX))
+		return rc;
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_swf_mode;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_swf_mode;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_swf_mode * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_swf_mode);
+	if (rc != OK)
+		return rc;
+	reg_AXI_write_attributes_for_swf_mode.swf_awdomain = swf_awdomain;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_swf_mode);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_rdma_mode;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_rdma_mode;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_rdma_mode * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_rdma_mode);
+	if (rc != OK)
+		return rc;
+	reg_AXI_write_attributes_for_rdma_mode.rdma_awdomain = rdma_awdomain;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_rdma_mode);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_hwf_qece;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_hwf_qece;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_hwf_qece * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_hwf_qece);
+	if (rc != OK)
+		return rc;
+	reg_AXI_write_attributes_for_hwf_qece.qece_awdomain = hwf_qe_ce_awdomain;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_hwf_qece);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.dma.AXI_write_attributes_for_hwf_pyld;
+	reg_size   =   qm_reg_size.dma.AXI_write_attributes_for_hwf_pyld;
+	reg_offset = qm_reg_offset.dma.AXI_write_attributes_for_hwf_pyld * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_hwf_pyld);
+	if (rc != OK)
+		return rc;
+	reg_AXI_write_attributes_for_hwf_pyld.pyld_awdomain = hwf_sfh_pl_awdomain;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_write_attributes_for_hwf_pyld);
+	return rc;
+}
+
+int qm_pfe_qos_attr_def_set(void)
+{
+	int rc = !OK;
+	u32 swf_arqos, rdma_arqos, hwf_qe_ce_arqos, hwf_sfh_pl_arqos;
+
+	swf_arqos        = QM_SWF_ARQOS_DEF;		/* 1 for QM_SWF_ARQOS_DEF        */
+	rdma_arqos       = QM_RDMA_ARQOS_DEF;		/* 1 for QM_RDMA_ARQOS_DEF       */
+	hwf_qe_ce_arqos  = QM_HWF_QE_CE_ARQOS_DEF;	/* 1 for QM_HWF_QE_CE_ARQOS_DEF  */
+	hwf_sfh_pl_arqos = QM_HWF_SFH_PL_ARQOS_DEF;	/* 1 for QM_HWF_SFH_PL_ARQOS_DEF */
+
+	rc = qm_dma_qos_attr_set(swf_arqos, rdma_arqos, hwf_qe_ce_arqos, hwf_sfh_pl_arqos);
+	return rc;
+}
+
+/*
+int qm_axi_swf_read_attr_set(u32 qos, u32 cache, u32 domain)
+int qm_axi_rdma_read_attr_set(u32 qos, u32 cache, u32 domain)
+int qm_axi_hwf_qece_read_attr_set(u32 qos, u32 cache, u32 domain)
+int qm_axi_hwf_pyld_read_attr_set(u32 qos, u32 cache, u32 domain)
+*/
+int qm_pfe_qos_attr_set(u32 swf_arqos, u32 rdma_arqos, u32 hwf_qe_ce_arqos, u32 hwf_sfh_pl_arqos)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct pfe_AXI_read_attributes_for_swf_mode  reg_AXI_read_attributes_for_swf_mode;
+	struct pfe_AXI_read_attributes_for_rdma_mode reg_AXI_read_attributes_for_rdma_mode;
+	struct pfe_AXI_read_attributes_for_hwf_qece  reg_AXI_read_attributes_for_hwf_qece;
+	struct pfe_AXI_read_attributes_for_hwf_pyld  reg_AXI_read_attributes_for_hwf_pyld;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((swf_arqos       <         QM_SWF_ARQOS_MIN) || (swf_arqos        >        QM_SWF_ARQOS_MAX))
+		return rc;
+	if ((rdma_arqos      <        QM_RDMA_ARQOS_MIN) || (rdma_arqos       >       QM_RDMA_ARQOS_MAX))
+		return rc;
+	if ((hwf_qe_ce_arqos <   QM_HWF_QE_CE_ARQOS_MIN) || (hwf_qe_ce_arqos  >  QM_HWF_QE_CE_ARQOS_MAX))
+		return rc;
+	if ((hwf_sfh_pl_arqos < QM_HWF_SFH_PL_ARQOS_MIN) || (hwf_sfh_pl_arqos > QM_HWF_SFH_PL_ARQOS_MAX))
+		return rc;
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_swf_mode;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_swf_mode;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_swf_mode * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_swf_mode);
+	if (rc != OK)
+		return rc;
+	reg_AXI_read_attributes_for_swf_mode.swf_arqos    = swf_arqos;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_swf_mode);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_rdma_mode;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_rdma_mode;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_rdma_mode * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_rdma_mode);
+	if (rc != OK)
+		return rc;
+	reg_AXI_read_attributes_for_rdma_mode.rdma_arqos    = rdma_arqos;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_rdma_mode);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_hwf_qece;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_hwf_qece;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_hwf_qece * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_hwf_qece);
+	if (rc != OK)
+		return rc;
+	reg_AXI_read_attributes_for_hwf_qece.qece_arqos    = hwf_qe_ce_arqos;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_hwf_qece);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_hwf_pyld;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_hwf_pyld;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_hwf_pyld * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_hwf_pyld);
+	if (rc != OK)
+		return rc;
+	reg_AXI_read_attributes_for_hwf_pyld.pyld_arqos    = hwf_sfh_pl_arqos;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_hwf_pyld);
+	return rc;
+}
+
+int qm_pfe_cache_attr_def_set(void)
+{
+	int rc = !OK;
+	u32 swf_arcache, rdma_arcache, hwf_qe_ce_arcache, hwf_sfh_pl_arcache;
+
+	swf_arcache        = QM_SWF_ARCACHE_DEF;		/* 1 for QM_SWF_ARCACHE_DEF	       */
+	rdma_arcache       = QM_RDMA_ARCACHE_DEF;		/* 1 for QM_RDMA_ARCACHE_DEF       */
+	hwf_qe_ce_arcache  = QM_HWF_QE_CE_ARCACHE_DEF;	/* 1 for QM_HWF_QE_CE_ARCACHE_DEF  */
+	hwf_sfh_pl_arcache = QM_HWF_SFH_PL_ARCACHE_DEF;	/* 1 for QM_HWF_SFH_PL_ARCACHE_DEF */
+
+	rc = qm_pfe_cache_attr_set(swf_arcache, rdma_arcache, hwf_qe_ce_arcache, hwf_sfh_pl_arcache);
+	return rc;
+}
+
+int qm_pfe_cache_attr_set(u32 swf_arcache, u32 rdma_arcache, u32 hwf_qe_ce_arcache, u32 hwf_sfh_pl_arcache)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct pfe_AXI_read_attributes_for_swf_mode  reg_AXI_read_attributes_for_swf_mode;
+	struct pfe_AXI_read_attributes_for_rdma_mode reg_AXI_read_attributes_for_rdma_mode;
+	struct pfe_AXI_read_attributes_for_hwf_qece  reg_AXI_read_attributes_for_hwf_qece;
+	struct pfe_AXI_read_attributes_for_hwf_pyld  reg_AXI_read_attributes_for_hwf_pyld;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((swf_arcache       <         QM_SWF_ARCACHE_MIN) || (swf_arcache        >        QM_SWF_ARCACHE_MAX))
+		return rc;
+	if ((rdma_arcache      <        QM_RDMA_ARCACHE_MIN) || (rdma_arcache       >       QM_RDMA_ARCACHE_MAX))
+		return rc;
+	if ((hwf_qe_ce_arcache <   QM_HWF_QE_CE_ARCACHE_MIN) || (hwf_qe_ce_arcache  >  QM_HWF_QE_CE_ARCACHE_MAX))
+		return rc;
+	if ((hwf_sfh_pl_arcache < QM_HWF_SFH_PL_ARCACHE_MIN) || (hwf_sfh_pl_arcache > QM_HWF_SFH_PL_ARCACHE_MAX))
+		return rc;
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_swf_mode;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_swf_mode;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_swf_mode * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_swf_mode);
+	if (rc != OK)
+		return rc;
+	reg_AXI_read_attributes_for_swf_mode.swf_arcache    = swf_arcache;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_swf_mode);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_rdma_mode;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_rdma_mode;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_rdma_mode * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_rdma_mode);
+	if (rc != OK)
+		return rc;
+	reg_AXI_read_attributes_for_rdma_mode.rdma_arcache    = rdma_arcache;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_rdma_mode);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_hwf_qece;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_hwf_qece;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_hwf_qece * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_hwf_qece);
+	if (rc != OK)
+		return rc;
+	reg_AXI_read_attributes_for_hwf_qece.qece_arcache    = hwf_qe_ce_arcache;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_hwf_qece);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_hwf_pyld;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_hwf_pyld;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_hwf_pyld * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_hwf_pyld);
+	if (rc != OK)
+		return rc;
+	reg_AXI_read_attributes_for_hwf_pyld.pyld_arcache    = hwf_sfh_pl_arcache;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_hwf_pyld);
+	return rc;
+}
+
+int qm_pfe_domain_attr_def_set(void)
+{
+	int rc = !OK;
+	u32 swf_ardomain, rdma_ardomain, hwf_qe_ce_ardomain, hwf_sfh_pl_ardomain;
+
+	swf_ardomain        = QM_SWF_ARDOMAIN_DEF;			/* 1 for QM_SWF_ARDOMAIN_DEF        */
+	rdma_ardomain       = QM_RDMA_ARDOMAIN_DEF;			/* 1 for QM_RDMA_ARDOMAIN_DEF       */
+	hwf_qe_ce_ardomain  = QM_HWF_QE_CE_ARDOMAIN_DEF;	/* 1 for QM_HWF_QE_CE_ARDOMAIN_DEF  */
+	hwf_sfh_pl_ardomain = QM_HWF_SFH_PL_ARDOMAIN_DEF;	/* 1 for QM_HWF_SFH_PL_ARDOMAIN_DEF */
+
+	rc = qm_pfe_domain_attr_set(swf_ardomain, rdma_ardomain, hwf_qe_ce_ardomain, hwf_sfh_pl_ardomain);
+	return rc;
+}
+
+int qm_pfe_domain_attr_set(u32 swf_ardomain, u32 rdma_ardomain, u32 hwf_qe_ce_ardomain, u32 hwf_sfh_pl_ardomain)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct pfe_AXI_read_attributes_for_swf_mode  reg_AXI_read_attributes_for_swf_mode;
+	struct pfe_AXI_read_attributes_for_rdma_mode reg_AXI_read_attributes_for_rdma_mode;
+	struct pfe_AXI_read_attributes_for_hwf_qece  reg_AXI_read_attributes_for_hwf_qece;
+	struct pfe_AXI_read_attributes_for_hwf_pyld  reg_AXI_read_attributes_for_hwf_pyld;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((swf_ardomain       <         QM_SWF_ARDOMAIN_MIN) || (swf_ardomain        >        QM_SWF_ARDOMAIN_MAX))
+		return rc;
+	if ((rdma_ardomain      <        QM_RDMA_ARDOMAIN_MIN) || (rdma_ardomain       >       QM_RDMA_ARDOMAIN_MAX))
+		return rc;
+	if ((hwf_qe_ce_ardomain <   QM_HWF_QE_CE_ARDOMAIN_MIN) || (hwf_qe_ce_ardomain  >  QM_HWF_QE_CE_ARDOMAIN_MAX))
+		return rc;
+	if ((hwf_sfh_pl_ardomain < QM_HWF_SFH_PL_ARDOMAIN_MIN) || (hwf_sfh_pl_ardomain > QM_HWF_SFH_PL_ARDOMAIN_MAX))
+		return rc;
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_swf_mode;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_swf_mode;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_swf_mode * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_swf_mode);
+	if (rc != OK)
+		return rc;
+	reg_AXI_read_attributes_for_swf_mode.swf_ardomain    = swf_ardomain;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_swf_mode);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_rdma_mode;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_rdma_mode;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_rdma_mode * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_rdma_mode);
+	if (rc != OK)
+		return rc;
+	reg_AXI_read_attributes_for_rdma_mode.rdma_ardomain    = rdma_ardomain;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_rdma_mode);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_hwf_qece;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_hwf_qece;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_hwf_qece * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_hwf_qece);
+	if (rc != OK)
+		return rc;
+	reg_AXI_read_attributes_for_hwf_qece.qece_ardomain    = hwf_qe_ce_ardomain;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_hwf_qece);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.pfe.AXI_read_attributes_for_hwf_pyld;
+	reg_size   =   qm_reg_size.pfe.AXI_read_attributes_for_hwf_pyld;
+	reg_offset = qm_reg_offset.pfe.AXI_read_attributes_for_hwf_pyld * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_hwf_pyld);
+	if (rc != OK)
+		return rc;
+	reg_AXI_read_attributes_for_hwf_pyld.pyld_ardomain    = hwf_sfh_pl_ardomain;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_AXI_read_attributes_for_hwf_pyld);
+	return rc;
+}
+
+int qm_ql_q_profile_def_set(void)
+{
+	int rc = !OK;
+	u32 queue_profile, queue;
+
+	for (queue = 0; queue <= 191; queue++) {
+		queue_profile = QM_QUEUE_PROFILE_0;
+		rc = qm_ql_q_profile_set(queue_profile, queue);
+		if (rc != OK)
+			return rc;
+	}
+	for (queue = 192; queue <= 223; queue++) {
+		queue_profile = QM_QUEUE_PROFILE_1;
+		rc = qm_ql_q_profile_set(queue_profile, queue);
+		if (rc != OK)
+			return rc;
+	}
+	for (queue = 224; queue <= 255; queue++) {
+		queue_profile = QM_QUEUE_PROFILE_3;
+		rc = qm_ql_q_profile_set(queue_profile, queue);
+		if (rc != OK)
+			return rc;
+	}
+	for (queue = 256; queue <= 287; queue++) {
+		queue_profile = QM_QUEUE_PROFILE_4;
+		rc = qm_ql_q_profile_set(queue_profile, queue);
+		if (rc != OK)
+			return rc;
+	}
+	for (queue = 288; queue <= 319; queue++) {
+		queue_profile = QM_QUEUE_PROFILE_5;
+		rc = qm_ql_q_profile_set(queue_profile, queue);
+		if (rc != OK)
+			return rc;
+	}
+	for (queue = 320; queue <= 415; queue++) {
+		queue_profile = QM_QUEUE_PROFILE_0;
+		rc = qm_ql_q_profile_set(queue_profile, queue);
+		if (rc != OK)
+			return rc;
+	}
+	for (queue = 416; queue <= 447; queue++) {
+		queue_profile = QM_QUEUE_PROFILE_6;
+		rc = qm_ql_q_profile_set(queue_profile, queue);
+		if (rc != OK)
+			return rc;
+	}
+	for (queue = 448; queue <= 511; queue++) {
+		queue_profile = QM_QUEUE_PROFILE_0;
+		rc = qm_ql_q_profile_set(queue_profile, queue);
+		if (rc != OK)
+			return rc;
+	}
+
+	rc = OK;
+	return rc;
+}
+
+int qm_ql_q_profile_set(u32 queue_profile, u32 queue)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct ql_qptr_entry reg_qptr_entry;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((queue_profile < QM_QUEUE_PROFILE_MIN) || (queue_profile >  QM_QUEUE_PROFILE_MAX))
+		return rc;
+	if ((queue         <         QM_QUEUE_MIN) || (queue         >          QM_QUEUE_MAX))
+		return rc;
+
+	reg_base_address =      qm.ql.qptr;
+	reg_size   =   qm_reg_size.ql.qptr;
+	reg_offset = qm_reg_offset.ql.qptr * queue/8;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qptr_entry);
+	if (rc != OK)
+		return rc;
+
+	switch (queue % 8) {
+	case 0:
+		reg_qptr_entry.qptr0 = queue_profile;
+		break;
+	case 1:
+		reg_qptr_entry.qptr1 = queue_profile;
+		break;
+	case 2:
+		reg_qptr_entry.qptr2 = queue_profile;
+		break;
+	case 3:
+		reg_qptr_entry.qptr3 = queue_profile;
+		break;
+	case 4:
+		reg_qptr_entry.qptr4 = queue_profile;
+		break;
+	case 5:
+		reg_qptr_entry.qptr5 = queue_profile;
+		break;
+	case 6:
+		reg_qptr_entry.qptr6 = queue_profile;
+		break;
+	case 7:
+		reg_qptr_entry.qptr7 = queue_profile;
+		break;
+	default:
+		return rc;
+	}
+
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qptr_entry);
+	return rc;
+}
+
+int qm_ql_thr_def_set(void)
+{
+	int rc = !OK;
+	u32 low_threshold, pause_threshold, high_threshold, traffic_source;
+
+/*
+#define QM_LOW_THRESHOLD_DEF	QM_THR_HI_DEF
+#define QM_QUEUE_PROFILE_INVALID			0x00000000	/ *    0 * /
+*/
+#define QM_QUEUE_PROFILE_0_LOW_THRESHOLD_DEF					0x0004B000	/* 300.0KB */
+#define QM_QUEUE_PROFILE_1_LOW_THRESHOLD_DEF					0x00007800	/*  30.0KB */
+#define QM_QUEUE_PROFILE_2_LOW_THRESHOLD_DEF					0x00007800	/*  30.0KB */
+#define QM_QUEUE_PROFILE_3_LOW_THRESHOLD_DEF					0x00003C00	/*  15.0KB */
+#define QM_QUEUE_PROFILE_4_LOW_THRESHOLD_DEF					0x00003C00	/*  15.0KB */
+#define QM_QUEUE_PROFILE_5_LOW_THRESHOLD_DEF					0x00000200	/*   0.5KB */
+#define QM_QUEUE_PROFILE_6_LOW_THRESHOLD_DEF					0x00000600	/*   1.5KB */
+
+#define QM_QUEUE_PROFILE_0_PAUSE_THRESHOLD_DEF					0xFFFFFF	/* -1 */
+#define QM_QUEUE_PROFILE_1_PAUSE_THRESHOLD_DEF					0xFFFFFF	/* 0xFFFFFF */
+#define QM_QUEUE_PROFILE_2_PAUSE_THRESHOLD_DEF					0xFFFFFF	/* 0xFFFFFF */
+#define QM_QUEUE_PROFILE_3_PAUSE_THRESHOLD_DEF					0xFFFFFF	/* 0xFFFFFF */
+#define QM_QUEUE_PROFILE_4_PAUSE_THRESHOLD_DEF					0xFFFFFF	/* 0xFFFFFF */
+#define QM_QUEUE_PROFILE_5_PAUSE_THRESHOLD_DEF					0xFFFFFF	/* 0xFFFFFF */
+#define QM_QUEUE_PROFILE_6_PAUSE_THRESHOLD_DEF					0xFFFFFF	/* 0xFFFFFF */
+
+#define QM_QUEUE_PROFILE_0_HIGH_THRESHOLD_DEF					0x00064000	/* 400.0KB */
+#define QM_QUEUE_PROFILE_1_HIGH_THRESHOLD_DEF					0x0000A000	/*  40.0KB */
+#define QM_QUEUE_PROFILE_2_HIGH_THRESHOLD_DEF					0x0000A000	/*  40.0KB */
+#define QM_QUEUE_PROFILE_3_HIGH_THRESHOLD_DEF					0x00005000	/*  20.0KB */
+#define QM_QUEUE_PROFILE_4_HIGH_THRESHOLD_DEF					0x00005000	/*  20.0KB */
+#define QM_QUEUE_PROFILE_5_HIGH_THRESHOLD_DEF					0x00000400	/*   1.0KB */
+#define QM_QUEUE_PROFILE_6_HIGH_THRESHOLD_DEF					0x00000800	/*   2.0KB */
+
+#define QM_QUEUE_PROFILE_0_TRAFFIC_SOURCE_DEF					         0	/*    0 */
+#define QM_QUEUE_PROFILE_1_TRAFFIC_SOURCE_DEF					         0	/*    0 */
+#define QM_QUEUE_PROFILE_2_TRAFFIC_SOURCE_DEF					0x00000001	/*    1 */
+#define QM_QUEUE_PROFILE_3_TRAFFIC_SOURCE_DEF					0x00000002	/*    2 */
+#define QM_QUEUE_PROFILE_4_TRAFFIC_SOURCE_DEF					0x00000003	/*    3 */
+#define QM_QUEUE_PROFILE_5_TRAFFIC_SOURCE_DEF					0x00000004	/*    4 */
+#define QM_QUEUE_PROFILE_6_TRAFFIC_SOURCE_DEF					0x00000004	/*    4 */
+
+	/* Profile 0 high 400KB low 300KB pause 0xFFFFFF source 0 (emac0-10G) */
+	low_threshold	= QM_QUEUE_PROFILE_0_LOW_THRESHOLD_DEF;
+	pause_threshold	= QM_QUEUE_PROFILE_0_PAUSE_THRESHOLD_DEF;
+	high_threshold	= QM_QUEUE_PROFILE_0_HIGH_THRESHOLD_DEF;
+	traffic_source	= QM_QUEUE_PROFILE_0_TRAFFIC_SOURCE_DEF;
+	rc = qm_ql_thr_set(low_threshold, pause_threshold, high_threshold, traffic_source, QM_QUEUE_PROFILE_0);
+	if (rc != OK)
+		return rc;
+
+	/* Profile 1 high 40KB low 30KB pause 0xFFFFFF source 0 (emac0-1G) */
+	low_threshold	= QM_QUEUE_PROFILE_1_LOW_THRESHOLD_DEF;
+	pause_threshold	= QM_QUEUE_PROFILE_1_PAUSE_THRESHOLD_DEF;
+	high_threshold	= QM_QUEUE_PROFILE_1_HIGH_THRESHOLD_DEF;
+	traffic_source	= QM_QUEUE_PROFILE_1_TRAFFIC_SOURCE_DEF;
+	rc = qm_ql_thr_set(low_threshold, pause_threshold, high_threshold, traffic_source, QM_QUEUE_PROFILE_1);
+	if (rc != OK)
+		return rc;
+
+	/* Profile 2 high 40KB low 30KB pause 0xFFFFFF source 1 (emac1-1G) */
+	low_threshold	= QM_QUEUE_PROFILE_2_LOW_THRESHOLD_DEF;
+	pause_threshold	= QM_QUEUE_PROFILE_2_PAUSE_THRESHOLD_DEF;
+	high_threshold	= QM_QUEUE_PROFILE_2_HIGH_THRESHOLD_DEF;
+	traffic_source	= QM_QUEUE_PROFILE_2_TRAFFIC_SOURCE_DEF;
+	rc = qm_ql_thr_set(low_threshold, pause_threshold, high_threshold, traffic_source, QM_QUEUE_PROFILE_2);
+	if (rc != OK)
+		return rc;
+
+	/* Profile 3 high 20KB low 15KB pause 0xFFFFFF source 2 (emac2-1G) */
+	low_threshold	= QM_QUEUE_PROFILE_3_LOW_THRESHOLD_DEF;
+	pause_threshold	= QM_QUEUE_PROFILE_3_PAUSE_THRESHOLD_DEF;
+	high_threshold	= QM_QUEUE_PROFILE_3_HIGH_THRESHOLD_DEF;
+	traffic_source	= QM_QUEUE_PROFILE_3_TRAFFIC_SOURCE_DEF;
+	rc = qm_ql_thr_set(low_threshold, pause_threshold, high_threshold, traffic_source, QM_QUEUE_PROFILE_3);
+	if (rc != OK)
+		return rc;
+
+	/* Profile 4 high 20KB low 15KB pause 0xFFFFFF source 3 (emac3-1G) */
+	low_threshold	= QM_QUEUE_PROFILE_4_LOW_THRESHOLD_DEF;
+	pause_threshold	= QM_QUEUE_PROFILE_4_PAUSE_THRESHOLD_DEF;
+	high_threshold	= QM_QUEUE_PROFILE_4_HIGH_THRESHOLD_DEF;
+	traffic_source	= QM_QUEUE_PROFILE_4_TRAFFIC_SOURCE_DEF;
+	rc = qm_ql_thr_set(low_threshold, pause_threshold, high_threshold, traffic_source, QM_QUEUE_PROFILE_4);
+	if (rc != OK)
+		return rc;
+
+	/* Profile 5 high  1KB low 0.5KB pause 0xFFFFFF source 4 (hmac-1K) */
+	low_threshold	= QM_QUEUE_PROFILE_5_LOW_THRESHOLD_DEF;
+	pause_threshold	= QM_QUEUE_PROFILE_5_PAUSE_THRESHOLD_DEF;
+	high_threshold	= QM_QUEUE_PROFILE_5_HIGH_THRESHOLD_DEF;
+	traffic_source	= QM_QUEUE_PROFILE_5_TRAFFIC_SOURCE_DEF;
+	rc = qm_ql_thr_set(low_threshold, pause_threshold, high_threshold, traffic_source, QM_QUEUE_PROFILE_5);
+	if (rc != OK)
+		return rc;
+
+	/* Profile 6 Â– high  2KB low 1.5KB pause 0xFFFFFF source 4 (hmac-2K) */
+	low_threshold	= QM_QUEUE_PROFILE_6_LOW_THRESHOLD_DEF;
+	pause_threshold	= QM_QUEUE_PROFILE_6_PAUSE_THRESHOLD_DEF;
+	high_threshold	= QM_QUEUE_PROFILE_6_HIGH_THRESHOLD_DEF;
+	traffic_source	= QM_QUEUE_PROFILE_6_TRAFFIC_SOURCE_DEF;
+	rc = qm_ql_thr_set(low_threshold, pause_threshold, high_threshold, traffic_source, QM_QUEUE_PROFILE_6);
+	return rc;
+}
+
+int qm_ql_thr_set(u32 low_threshold, u32 pause_threshold, u32 high_threshold, u32 traffic_source, u32 queue_profile)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct ql_low_threshold		reg_low_threshold;
+	struct ql_pause_threshold	reg_pause_threshold;
+	struct ql_high_threshold	reg_high_threshold;
+	struct ql_traffic_source	reg_traffic_source;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((queue_profile   <   QM_QUEUE_PROFILE_MIN) || (queue_profile   >   QM_QUEUE_PROFILE_MAX))
+		return rc;
+	if ((low_threshold   <   QM_LOW_THRESHOLD_MIN) || (low_threshold   >   QM_LOW_THRESHOLD_MAX))
+		return rc;
+	if ((pause_threshold < QM_PAUSE_THRESHOLD_MIN) || (pause_threshold > QM_PAUSE_THRESHOLD_MAX))
+		return rc;
+	if ((high_threshold  <  QM_HIGH_THRESHOLD_MIN) || (high_threshold  >  QM_HIGH_THRESHOLD_MAX))
+		return rc;
+	if ((traffic_source  <  QM_TRAFFIC_SOURCE_MIN) || (traffic_source  >  QM_TRAFFIC_SOURCE_MAX))
+		return rc;
+
+	reg_base_address =      qm.ql.low_threshold;
+	reg_size   =   qm_reg_size.ql.low_threshold;
+	reg_offset = qm_reg_offset.ql.low_threshold * (queue_profile - 1);
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_low_threshold);
+	if (rc != OK)
+		return rc;
+	reg_low_threshold.low_threshold   = low_threshold;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_low_threshold);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.ql.pause_threshold;
+	reg_size   =   qm_reg_size.ql.pause_threshold;
+	reg_offset = qm_reg_offset.ql.pause_threshold * (queue_profile - 1);
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pause_threshold);
+	if (rc != OK)
+		return rc;
+	reg_pause_threshold.pause_threshold = pause_threshold;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_pause_threshold);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.ql.high_threshold;
+	reg_size   =   qm_reg_size.ql.high_threshold;
+	reg_offset = qm_reg_offset.ql.high_threshold * (queue_profile - 1);
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_high_threshold);
+	if (rc != OK)
+		return rc;
+	reg_high_threshold.high_threshold = high_threshold;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_high_threshold);
+	if (rc != OK)
+		return rc;
+
+	reg_base_address =      qm.ql.traffic_source;
+	reg_size   =   qm_reg_size.ql.traffic_source;
+	reg_offset = qm_reg_offset.ql.traffic_source * (queue_profile - 1);
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_traffic_source);
+	if (rc != OK)
+		return rc;
+	reg_traffic_source.traffic_source = traffic_source;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_traffic_source);
+	if (rc != OK)
+		return rc;
+
+	return rc;
+}
+
+int qm_vmid_set(u32 qm_vmid)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+
+	if ((qm_vmid < QM_VMID_MIN) || (qm_vmid > QM_VMID_MAX))
+		return rc;
+
+	/*rc = bm_vmid_set( &ctl, bm_vmid); if (rc) return rc; */
+	rc = dma_vmid_set(qm_vmid);
+	if (rc != OK)
+		return rc;
+
+	rc = pfe_vmid_set(qm_vmid);
+	if (rc != OK)
+		return rc;
+
+	return rc;
+}
+
+int dma_vmid_set(u32 qm_vmid)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct dma_DRAM_VMID				  reg_DRAM_VMID;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((qm_vmid < QM_VMID_MIN) || (qm_vmid > QM_VMID_MAX))
+		return rc;
+
+	reg_base_address =      qm.dma.DRAM_VMID;
+	reg_size   =   qm_reg_size.dma.DRAM_VMID;
+	reg_offset = qm_reg_offset.dma.DRAM_VMID * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_DRAM_VMID);
+	if (rc != OK)
+		return rc;
+	reg_DRAM_VMID.dram_vmid = qm_vmid;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_DRAM_VMID);
+	if (rc != OK)
+		return rc;
+
+	return rc;
+}
+
+int pfe_vmid_set(u32 qm_vmid)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct pfe_QM_VMID     reg_QM_VMID;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((qm_vmid < QM_VMID_MIN) || (qm_vmid > QM_VMID_MAX))
+		return rc;
+
+	reg_base_address =      qm.pfe.QM_VMID;
+	reg_size   =   qm_reg_size.pfe.QM_VMID;
+	reg_offset = qm_reg_offset.pfe.QM_VMID * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_QM_VMID);
+	if (rc != OK)
+		return rc;
+	reg_QM_VMID.VMID = qm_vmid;
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_QM_VMID);
+	if (rc != OK)
+		return rc;
+
+	return rc;
+}
+
+int qm_queue_flush_start(u32 queue)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct pfe_queue_flush reg_queue_flush;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((queue   <   QM_QUEUE_MIN) || (queue   >   QM_QUEUE_MAX))
+		return rc;
+
+	reg_base_address =      qm.pfe.queue_flush;
+	reg_size   =   qm_reg_size.pfe.queue_flush;
+	reg_offset = qm_reg_offset.pfe.queue_flush * (queue/32);
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_queue_flush);
+	if (rc != OK)
+		return rc;
+	reg_queue_flush.queue_flush_bit_per_q |=  (0x00000001 << ((reg_queue_flush.queue_flush_bit_per_q)%32));
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_queue_flush);
+	if (rc != OK)
+		return rc;
+
+	return rc;
+}
+
+int qm_port_flush_start(u32 port)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	int pid;
+	struct pfe_port_flush reg_port_flush;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((port            <    QM_PORT_MIN) || (port            >    QM_PORT_MAX))
+		return rc;
+
+	pid = port;
+
+	reg_base_address =      qm.pfe.port_flush;
+	reg_size   =   qm_reg_size.pfe.port_flush;
+	reg_offset = qm_reg_offset.pfe.port_flush * 0;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_port_flush);
+	if (rc != OK)
+		return rc;
+	reg_port_flush.port_flush |=  (0x00000001 << pid);
+	rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_port_flush);
+	if (rc != OK)
+		return rc;
+
+	return rc;
+}
+
+int ql_queue_length_get(u32 queue, u32 *length, u32 *status)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	u32 reg_base_address, reg_size, reg_offset;
+	struct ql_qlen     reg_qlen;
+
+	if ((queue   <   QM_QUEUE_MIN) || (queue   >   QM_QUEUE_MAX))
+		return rc;
+
+	reg_base_address =      qm.ql.qlen;
+	reg_size   =   qm_reg_size.ql.qlen;
+	reg_offset = qm_reg_offset.ql.qlen * queue;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_qlen);
+	if (rc != OK)
+		return rc;
+	*length = reg_qlen.reg_ql_entry.ql;
+	*status = reg_qlen.reg_ql_entry.qstatus;
+
+	return rc;
+}
+
+int qm_idle_status_get(u32 *status)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct dma_idle_status reg_idle_status;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	reg_base_address =      qm.dma.idle_status;
+	reg_size   =   qm_reg_size.dma.idle_status;
+	reg_offset = qm_reg_offset.dma.idle_status * 0;
+
+	pr_info("\n-------------- Read DMA idle status -----------");
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_idle_status);
+	if (rc != OK)
+		return rc;
+	*status = *(u32 *)&reg_idle_status;
+
+	pr_info("\n");
+
+	pr_info("\t idle_status.gpm_pl_cache_is_empty  = 0x%08X\n",
+				reg_idle_status.gpm_pl_cache_is_empty);
+	pr_info("\t idle_status.gpm_pl_cache_is_full  = 0x%08X\n",
+				reg_idle_status.gpm_pl_cache_is_full);
+	pr_info("\t idle_status.gpm_qe_cache_is_empty  = 0x%08X\n",
+				reg_idle_status.gpm_qe_cache_is_empty);
+	pr_info("\t idle_status.gpm_qe_cache_is_full  = 0x%08X\n",
+				reg_idle_status.gpm_qe_cache_is_full);
+	pr_info("\t idle_status.dram_pl_cache_is_empty  = 0x%08X\n",
+				reg_idle_status.dram_pl_cache_is_empty);
+	pr_info("\t idle_status.dram_pl_cache_is_full  = 0x%08X\n",
+				reg_idle_status.dram_pl_cache_is_full);
+	pr_info("\t idle_status.dram_qe_cache_is_empty  = 0x%08X\n",
+				reg_idle_status.dram_qe_cache_is_empty);
+	pr_info("\t idle_status.dram_qe_cache_is_full  = 0x%08X\n",
+				reg_idle_status.dram_qe_cache_is_full);
+	pr_info("\t idle_status.dram_fifo_is_empty  = 0x%08X\n",
+				reg_idle_status.dram_fifo_is_empty);
+	pr_info("\t idle_status.mac_axi_enq_channel_is_empty  = 0x%08X\n",
+				reg_idle_status.mac_axi_enq_channel_is_empty);
+	pr_info("\t idle_status.NSS_axi_enq_channel_is_empty  = 0x%08X\n",
+				reg_idle_status.NSS_axi_enq_channel_is_empty);
+	pr_info("\t idle_status.gpm_ppe_read_fifo_is_empty  = 0x%08X\n",
+				reg_idle_status.gpm_ppe_read_fifo_is_empty);
+	pr_info("\t idle_status.ppe_gpm_pl_write_fifo_is_empty  = 0x%08X\n",
+				reg_idle_status.ppe_gpm_pl_write_fifo_is_empty);
+	pr_info("\t idle_status.ppe_gpm_qe_write_fifo_is_empty  = 0x%08X\n",
+				reg_idle_status.ppe_gpm_qe_write_fifo_is_empty);
+	pr_info("\t idle_status.ppe_ru_read_fifo_is_empty  = 0x%08X\n",
+				reg_idle_status.ppe_ru_read_fifo_is_empty);
+	pr_info("\t idle_status.ppe_ru_write_fifo_is_empty  = 0x%08X\n",
+				reg_idle_status.ppe_ru_write_fifo_is_empty);
+	pr_info("\t idle_status.ru_ppe_read_fifo_is_empty  = 0x%08X\n",
+				reg_idle_status.ru_ppe_read_fifo_is_empty);
+	pr_info("\t idle_status.dram_fifo_fsm_state_is_idle  = 0x%08X\n",
+				reg_idle_status.dram_fifo_fsm_state_is_idle);
+	pr_info("\t idle_status.qeram_init_fsm_state_is_idle  = 0x%08X\n",
+				reg_idle_status.qeram_init_fsm_state_is_idle);
+
+/*
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)status);
+	if (rc != OK)
+		return rc;
+*/
+	return rc;
+}
+
+/*
+int reorder_class_cmd_set(u32 host, u32 class, u32 sid, u32 cmd)
+int	qm_ru_class_cmd_set(u32 host, u32 class, , u32 sid, u32 cmd)
+ TBD (Alon Eldar)
+int qm_class_cmd_set(u32 host, u32 reorder_class, u32 sid, u32 cmd)
+*/
+int	qm_ru_class_cmd_set(u32 host, u32 host_class, u32 host_sid, u32 cmd)
+{
+	int rc = -QM_INPUT_NOT_IN_RANGE;
+	struct reorder_ru_host_cmd        reg_ru_host_cmd;
+	struct reorder_ru_task_permission reg_ru_task_permission;
+	u32 reg_base_address, reg_size, reg_offset;
+
+	if ((host       <          QM_HOST_MIN) || (host       >          QM_HOST_MAX))
+		return rc; /* Host: cpu 0 or cpu 1 (how does neta knows who It is Â– ask DIma?) */
+	if ((host_class < QM_REORDER_CLASS_MIN) || (host_class > QM_REORDER_CLASS_MAX))
+		return rc;
+	if ((host_sid   <           QM_SID_MIN) || (host_sid   >           QM_SID_MAX))
+		return rc;
+	if ((cmd        <           QM_CMD_MIN) || (cmd        >           QM_CMD_MAX))
+		return rc;
+
+	reg_base_address =      qm.reorder.ru_task_permission;
+	reg_size   =   qm_reg_size.reorder.ru_task_permission;
+	reg_offset = qm_reg_offset.reorder.ru_task_permission * host;
+
+	rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_ru_task_permission);
+	if (rc != OK)
+		return rc;
+
+	if (reg_ru_task_permission.ru_host_permitted == 1) {
+		reg_base_address =      qm.reorder.ru_host_cmd;
+		reg_size   =   qm_reg_size.reorder.ru_host_cmd;
+		reg_offset = qm_reg_offset.reorder.ru_host_cmd * host;
+
+		rc = qm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_ru_host_cmd);
+		if (rc != OK)
+			return rc;
+		reg_ru_host_cmd.ru_host_sid   = host_sid;
+		reg_ru_host_cmd.ru_host_class = host_class;
+/*		reg_ru_host_cmd.ru_host_task  = XXX;
+		reg_ru_host_cmd.ru_host_exec  = XXX;
+*/
+		rc = qm_register_write(reg_base_address, reg_offset, reg_size, (u32 *)&reg_ru_host_cmd);
+		if (rc != OK)
+			return rc;
+	} else {
+		pr_info("\t reg_ru_task_permission.ru_host_permitted = 0x%08X\n",
+				reg_ru_task_permission.ru_host_permitted);
+
+	}
+
+	return rc;
+}
+
+
+
+/*	rc = qm_register_read(qm.ql.mem2mg_resp_data_ll, (u32 *)&reg_mem2mg_resp_data_ll); if (rc) return rc;*/
+
+
+#define	COMPLETE_HW_WRITE
+
+#ifdef my_RW_DEBUG_UNITEST
+int qm_register_read(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr)
+{
+	int rc = OK;
+	u32 *temp;
+	u32 i;
+
+/*	In the future we can also add printing of the fields of the register */
+/*	pr_info(" DUMMY_PRINT  read by function <%s>,  result = 0x%08X\n", __func__, *(u32 *)dataPtr);
+
+	bm_register_name_get(base_address, offset, reg_name);
+	pr_info("[QM]  READ_REG add = 0x%08X : name = %s : value =", base_address, reg_name);
+*/
+	temp = dataPtr;
+	for (i = 0; i < wordsNumber; i++) {
+		/*
+		pr_info(" 0x%08X", *(u32 *)temp);*/
+		*(u32 *)temp = 0;
+		temp++;
+	}
+	pr_info("\n");
+/*	return OK;	 */
+/*
+	rc = mv_pp3_hw_read(base_address+offset, wordsNumber, dataPtr);
+	if (rc != OK) {
+		pr_info(" Not Available\n");
+		return rc;
+	}
+*/
+/*	if (rc != OK)
+		return rc;*/
+
+	COMPLETE_HW_WRITE
+	rc = OK;
+	return rc;
+}
+
+int qm_register_write(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr)
+{
+	char reg_name[50];
+	int rc = OK;
+	u32 *temp;
+	u32 i;
+
+	bm_register_name_get(base_address, offset, reg_name);
+	pr_info("[QM] WROTE_REG add = 0x%08X : name = %s : value =", base_address, reg_name);
+	temp = dataPtr;
+	for (i = 0; i < wordsNumber; i++) {
+		pr_info(" 0x%08X", *(u32 *)temp);
+		temp++;
+	}
+	pr_info("\n");
+
+/*	pr_info(" DUMMY_PRINT, result=%d\n", *(u32 *)dataPtr);*/
+/*	pr_info(" DUMMY_PRINT, result = 0x%08X\n", *(u32 *)dataPtr);*/
+/*	pr_info(" DUMMY_PRINT write by function <%s>, result = 0x%08X\n", __func__, *(u32 *)dataPtr);*/
+
+/*	return OK;	 */
+/*
+	rc = mv_pp3_hw_write(base_address+offset, wordsNumber, dataPtr);
+	if (rc != OK)
+		return rc;
+*/
+
+	COMPLETE_HW_WRITE
+	return rc;
+}
+#else
+int qm_register_read(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr)
+{
+	int rc = OK;
+
+	mv_pp3_hw_read(base_address+offset, wordsNumber, dataPtr);
+	if (rc != OK)
+		return rc;
+
+	COMPLETE_HW_WRITE
+	return rc;
+}
+
+int qm_register_write(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr)
+{
+	int rc = OK;
+
+	mv_pp3_hw_write(base_address+offset, wordsNumber, dataPtr);
+	if (rc != OK)
+		return rc;
+
+	COMPLETE_HW_WRITE
+	return rc;
+}
+#endif
+
+void qm_register_register_fields_print(u32 base_address, u32 value)
+{
+
+}
diff --git a/drivers/net/ethernet/marvell/pp3/qm/mv_qm.h b/drivers/net/ethernet/marvell/pp3/qm/mv_qm.h
new file mode 100644
index 0000000..248c895
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/qm/mv_qm.h
@@ -0,0 +1,706 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef	__MV_QM_H__
+#define	__MV_QM_H__
+
+#include "common/mv_sw_if.h"
+#include "common/mv_hw_if.h"
+
+/* Error Codes */
+#define QM_WRONG_MEMORY_TYPE           -EINVAL
+#define QM_ALIAS_ERROR                 -EINVAL
+#define QM_INPUT_NOT_IN_RANGE          -EINVAL
+
+/* Input definitions*/
+#define GPM_MEMORY_TYPE				 0
+#define DRAM_MEMORY_TYPE			 1
+#define GRANULARITY_OF_16_BYTES		16
+
+#define QM_QUEUE_PROFILE_INVALID			0x00000000	/*    0 */
+#define QM_QUEUE_PROFILE_0					0x00000001	/*    1 */
+#define QM_QUEUE_PROFILE_1					0x00000002	/*    2 */
+#define QM_QUEUE_PROFILE_2					0x00000003	/*    3 */
+#define QM_QUEUE_PROFILE_3					0x00000004	/*    4 */
+#define QM_QUEUE_PROFILE_4					0x00000005	/*    5 */
+#define QM_QUEUE_PROFILE_5					0x00000006	/*    6 */
+#define QM_QUEUE_PROFILE_6					0x00000007	/*    7 */
+
+
+/* Default values */
+#define QM_THR_HI_DEF			0x0000000C	/*  12 */
+#define QM_THR_LO_DEF			0x00000018	/*  24 */
+#define QM_GPM_QE_THR_HI_DEF	QM_THR_HI_DEF
+#define QM_GPM_QE_THR_LO_DEF	QM_THR_LO_DEF
+#define QM_GPM_PL_THR_HI_DEF	QM_THR_HI_DEF
+#define QM_GPM_PL_THR_LO_DEF	QM_THR_LO_DEF
+#define QM_DRAM_QE_THR_HI_DEF	QM_THR_HI_DEF
+#define QM_DRAM_QE_THR_LO_DEF	QM_THR_LO_DEF
+#define QM_DRAM_PL_THR_HI_DEF	QM_THR_HI_DEF
+#define QM_DRAM_PL_THR_LO_DEF	QM_THR_LO_DEF
+
+#define QM_POOL0_SID_NUM_DEF	QM_POOL0_SID_NUM_MAX
+#define QM_POOL1_SID_NUM_DEF	QM_POOL1_SID_NUM_MIN
+
+#define QM_CLASS_ARR_CMAC_EMAC_DEF	input_port	/*    0 */
+#define QM_CLASS_ARR_HMAC_DEF		0x00000008	/*    8 */
+#define QM_CLASS_ARR_PPC_DEF		0x00000009	/*    9 */
+#define QM_PORT_ARR_DEF				         0	/*    0 */
+#define QM_ARRAYS_SIZE_DEF			0x0000005A	/*   90 */
+
+#define QM_PORT_DEPTH_ARR_PPC0_DEF		    (2 * QM_SIZE_OF_PORT_DEPTH_ARR_PPC_IN_BYTES)	/* 2*144B */
+#define QM_PORT_DEPTH_ARR_PPC1_DEF		    (1 * QM_SIZE_OF_PORT_DEPTH_ARR_PPC_IN_BYTES)	/* 1*144B */
+#define QM_PORT_DEPTH_ARR_EMAC_DEF		  (160 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*  2560B */
+#define QM_PORT_DEPTH_ARR_CMAC0_DEF		  (160 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*  2560B */
+#define QM_PORT_DEPTH_ARR_CMAC1_DEF		   (32 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*   512B */
+#define QM_PORT_DEPTH_ARR_HMAC_DEF		   (32 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*   512B */
+
+#define QM_PORT_CREDIT_THR_ARR_EMAC_DEF		  (152 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*  2432B */
+#define QM_PORT_CREDIT_THR_ARR_CMAC0_DEF	  (152 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*  2432B */
+#define QM_PORT_CREDIT_THR_ARR_CMAC1_DEF	   (24 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*   384B */
+#define QM_PORT_CREDIT_THR_ARR_HMAC_DEF		   (24 * QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES)	/*   384B */
+
+#define QM_PORT_PPC_ARR_PPC0_DEF	    1	/* packets are processed by data        PPC */
+#define QM_PORT_PPC_ARR_PPC1_DEF	    2	/* packets are processed by maintenance PPC */
+
+#define QM_SWF_AWQOS_DEF			0x00000001	/*    1 */
+#define QM_RDMA_AWQOS_DEF			0x00000001	/*    1 */
+#define QM_HWF_QE_CE_AWQOS_DEF		0x00000001	/*    1 */
+#define QM_HWF_SFH_PL_AWQOS_DEF		0x00000001	/*    1 */
+
+#define QM_SWF_AWCACHE_DEF			0x0000000B	/*   11 */
+#define QM_RDMA_AWCACHE_DEF			0x0000000B	/*   11 */
+#define QM_HWF_QE_CE_AWCACHE_DEF	0x00000003	/*    3 */
+#define QM_HWF_SFH_PL_AWCACHE_DEF	0x00000003	/*    3 */
+
+#define QM_SWF_AWDOMAIN_DEF			0x00000002	/*    2 */
+#define QM_RDMA_AWDOMAIN_DEF		0x00000002	/*    2 */
+#define QM_HWF_QE_CE_AWDOMAIN_DEF	         0	/*    0 */
+#define QM_HWF_SFH_PL_AWDOMAIN_DEF	         0	/*    0 */
+
+#define QM_SWF_ARQOS_DEF			0x00000001	/*    1 */
+#define QM_RDMA_ARQOS_DEF			0x00000001	/*    1 */
+#define QM_HWF_QE_CE_ARQOS_DEF		0x00000001	/*    1 */
+#define QM_HWF_SFH_PL_ARQOS_DEF		0x00000001	/*    1 */
+
+#define QM_SWF_ARCACHE_DEF			0x0000000B	/*   11 */
+#define QM_RDMA_ARCACHE_DEF			0x0000000B	/*   11 */
+#define QM_HWF_QE_CE_ARCACHE_DEF	0x00000003	/*    3 */
+#define QM_HWF_SFH_PL_ARCACHE_DEF	0x00000003	/*    3 */
+
+#define QM_SWF_ARDOMAIN_DEF			0x00000002	/*    2 */
+#define QM_RDMA_ARDOMAIN_DEF		0x00000002	/*    2 */
+#define QM_HWF_QE_CE_ARDOMAIN_DEF	         0	/*    0 */
+#define QM_HWF_SFH_PL_ARDOMAIN_DEF	         0	/*    0 */
+
+/* Range Definitions */
+#define QM_QUEUE_MIN			         0	/*    0 */
+#define QM_QUEUE_MAX			0x00000200	/*  512 */
+#define QM_PORT_MIN				         0	/*    0 */
+#define QM_PORT_MAX				0x0000000F	/*   15 */
+#define QM_PORT_PPC_MIN			QM_PORT_MIN
+#define QM_PORT_PPC_MAX			0x00000002	/*    2 */
+#define QM_PORT_MAC_MIN			0x00000003	/*    3 */
+#define QM_PORT_MAC_MAX			0x0000000A	/*   10 */
+#define QM_QUEUE_PROFILE_MIN	         1	/*    1 */
+#define QM_QUEUE_PROFILE_MAX	0x00000007	/*    7 */
+
+#define QM_PPC_MIN				         0
+#define QM_PPC_MAX				0x7FFFFFFF
+#define QM_BASE_MIN				         0
+#define QM_BASE_MAX				0x7FFFFFFF
+#define QM_SIZE_MIN				         0
+#define QM_SIZE_MAX				0x7FFFFFFF
+
+#define QM_VMID_MIN				         0	/*   0 */
+#define QM_VMID_MAX				0x0000003F	/*  63 */
+#define QM_THR_MIN				         0	/*   0 */
+#define QM_THR_MAX				0x00000020	/*  32 */
+#define QM_GPM_QE_THR_HI_MIN	QM_THR_MIN
+#define QM_GPM_QE_THR_HI_MAX	QM_THR_MAX
+#define QM_GPM_QE_THR_LO_MIN	QM_THR_MIN
+#define QM_GPM_QE_THR_LO_MAX	QM_THR_MAX
+#define QM_GPM_PL_THR_HI_MIN	QM_THR_MIN
+#define QM_GPM_PL_THR_HI_MAX	QM_THR_MAX
+#define QM_GPM_PL_THR_LO_MIN	QM_THR_MIN
+#define QM_GPM_PL_THR_LO_MAX	QM_THR_MAX
+#define QM_DRAM_QE_THR_HI_MIN	QM_THR_MIN
+#define QM_DRAM_QE_THR_HI_MAX	QM_THR_MAX
+#define QM_DRAM_QE_THR_LO_MIN	QM_THR_MIN
+#define QM_DRAM_QE_THR_LO_MAX	QM_THR_MAX
+#define QM_DRAM_PL_THR_HI_MIN	QM_THR_MIN
+#define QM_DRAM_PL_THR_HI_MAX	QM_THR_MAX
+#define QM_DRAM_PL_THR_LO_MIN	QM_THR_MIN
+#define QM_DRAM_PL_THR_LO_MAX	QM_THR_MAX
+#define QM_POOL_SID_NUM_MIN		         0
+#define QM_POOL_SID_NUM_MAX		0x00001000	/* 4096 */
+
+#define QM_POOL0_SID_NUM_MIN	QM_POOL_SID_NUM_MIN
+#define QM_POOL0_SID_NUM_MAX	QM_POOL_SID_NUM_MAX
+#define QM_POOL1_SID_NUM_MIN	QM_POOL_SID_NUM_MIN
+#define QM_POOL1_SID_NUM_MAX	QM_POOL_SID_NUM_MAX
+
+#define QM_CLASS_ARR_MIN		         0	/*    0 */
+#define QM_CLASS_ARR_MAX		0x00000009	/*    9 */
+#define QM_PORT_ARR_MIN			         0	/*    0 */
+#define QM_PORT_ARR_MAX			0x00000001	/*    1 */
+#define QM_ARRAYS_SIZE_MIN		0x0000005A	/*   90 */
+#define QM_ARRAYS_SIZE_MAX		0x00000120	/*  288 */
+
+#define QM_INPUT_PORT_CMAC_EMAC_MIN	         0	/*    0 */
+#define QM_INPUT_PORT_CMAC_EMAC_MAX	0x00000007	/*    7 */
+#define QM_INPUT_PORT_HMAC_MIN		0x00000008	/*    8 */
+#define QM_INPUT_PORT_HMAC_MAX		0x00000047	/*   71 */
+#define QM_INPUT_PORT_PPC_MIN		0x00000048	/*   72 */
+#define QM_INPUT_PORT_PPC_MAX		0x00000059	/*   89 */
+
+#define QM_MEMORY_TYPE_MIN		         0
+#define QM_MEMORY_TYPE_MAX		         1
+
+#define QM_SIZE_OF_PORT_DEPTH_ARR_PPC_IN_BYTES		0x00000090	/*  144 */
+#define QM_SIZE_OF_PORT_DEPTH_ARR_MAC_IN_BYTES		0x00000010	/*   16 */
+#define QM_SIZE_OF_PORT_CREDIT_THR_ARR_MAC_IN_BYTES	0x00000010	/*   16 */
+
+#define QM_PORT_DEPTH_ARR_MIN			     0	/*     0 */
+#define QM_PORT_DEPTH_ARR_SUM_MAX	0x00004000	/* 16384 */
+
+#define QM_PORT_CREDIT_THR_ARR_MIN	GRANULARITY_OF_16_BYTES	/*     16 */
+#define QM_PORT_CREDIT_THR_ARR_MAX	(data_fifo_depth_p - 8 * GRANULARITY_OF_16_BYTES)	/* 8 * 16 */
+
+#define QM_SWF_ARDOMAIN_MIN				         0	/*    0 */
+#define QM_SWF_ARDOMAIN_MAX				0x00000003	/*    3 */
+#define QM_SWF_ARCACHE_MIN				         0	/*    0 */
+#define QM_SWF_ARCACHE_MAX				0x0000000F	/*   15 */
+#define QM_SWF_ARQOS_MIN					     0	/*    0 */
+#define QM_SWF_ARQOS_MAX				0x00000003	/*    3 */
+
+#define QM_RDMA_ARDOMAIN_MIN			         0	/*    0 */
+#define QM_RDMA_ARDOMAIN_MAX			0x00000003	/*    3 */
+#define QM_RDMA_ARCACHE_MIN				         0	/*    0 */
+#define QM_RDMA_ARCACHE_MAX				0x0000000F	/*   15 */
+#define QM_RDMA_ARQOS_MIN					     0	/*    0 */
+#define QM_RDMA_ARQOS_MAX				0x00000003	/*    3 */
+
+#define QM_HWF_QE_CE_ARDOMAIN_MIN		         0	/*    0 */
+#define QM_HWF_QE_CE_ARDOMAIN_MAX		0x00000003	/*    3 */
+#define QM_HWF_QE_CE_ARCACHE_MIN		         0	/*    0 */
+#define QM_HWF_QE_CE_ARCACHE_MAX		0x0000000F	/*   15 */
+#define QM_HWF_QE_CE_ARQOS_MIN				     0	/*    0 */
+#define QM_HWF_QE_CE_ARQOS_MAX			0x00000003	/*    3 */
+
+#define QM_HWF_SFH_PL_ARQOS_MIN			         0	/*    0 */
+#define QM_HWF_SFH_PL_ARQOS_MAX			0x00000003	/*    3 */
+#define QM_HWF_SFH_PL_ARCACHE_MIN		         0	/*    0 */
+#define QM_HWF_SFH_PL_ARCACHE_MAX		0x0000000F	/*   15 */
+#define QM_HWF_SFH_PL_ARDOMAIN_MIN			     0	/*    0 */
+#define QM_HWF_SFH_PL_ARDOMAIN_MAX		0x00000003	/*    3 */
+
+#define QM_SWF_AWDOMAIN_MIN				         0	/*    0 */
+#define QM_SWF_AWDOMAIN_MAX				0x00000003	/*    3 */
+#define QM_SWF_AWCACHE_MIN				         0	/*    0 */
+#define QM_SWF_AWCACHE_MAX				0x0000000F	/*   15 */
+#define QM_SWF_AWQOS_MIN					     0	/*    0 */
+#define QM_SWF_AWQOS_MAX				0x00000003	/*    3 */
+
+#define QM_RDMA_AWDOMAIN_MIN			         0	/*    0 */
+#define QM_RDMA_AWDOMAIN_MAX			0x00000003	/*    3 */
+#define QM_RDMA_AWCACHE_MIN				         0	/*    0 */
+#define QM_RDMA_AWCACHE_MAX				0x0000000F	/*   15 */
+#define QM_RDMA_AWQOS_MIN					     0	/*    0 */
+#define QM_RDMA_AWQOS_MAX				0x00000003	/*    3 */
+
+#define QM_HWF_QE_CE_AWDOMAIN_MIN		         0	/*    0 */
+#define QM_HWF_QE_CE_AWDOMAIN_MAX		0x00000003	/*    3 */
+#define QM_HWF_QE_CE_AWCACHE_MIN		         0	/*    0 */
+#define QM_HWF_QE_CE_AWCACHE_MAX		0x0000000F	/*   15 */
+#define QM_HWF_QE_CE_AWQOS_MIN				     0	/*    0 */
+#define QM_HWF_QE_CE_AWQOS_MAX			0x00000003	/*    3 */
+
+#define QM_HWF_SFH_PL_AWQOS_MIN			         0	/*    0 */
+#define QM_HWF_SFH_PL_AWQOS_MAX			0x00000003	/*    3 */
+#define QM_HWF_SFH_PL_AWCACHE_MIN		         0	/*    0 */
+#define QM_HWF_SFH_PL_AWCACHE_MAX		0x0000000F	/*   15 */
+#define QM_HWF_SFH_PL_AWDOMAIN_MIN			     0	/*    0 */
+#define QM_HWF_SFH_PL_AWDOMAIN_MAX		0x00000003	/*    3 */
+
+#define QM_LOW_THRESHOLD_MIN				     0
+#define QM_LOW_THRESHOLD_MAX			0x7FFFFFFF
+#define QM_PAUSE_THRESHOLD_MIN			         0
+#define QM_PAUSE_THRESHOLD_MAX			0x7FFFFFFF
+#define QM_HIGH_THRESHOLD_MIN			         0
+#define QM_HIGH_THRESHOLD_MAX			0x7FFFFFFF
+#define QM_TRAFFIC_SOURCE_MIN			         0
+#define QM_TRAFFIC_SOURCE_MAX			0x7FFFFFFF
+#define QM_HOST_MIN				         0
+#define QM_HOST_MAX				         1
+#define QM_REORDER_CLASS_MIN	         0
+#define QM_REORDER_CLASS_MAX	        63
+#define QM_SID_MIN				         0
+#define QM_SID_MAX				0x00001000
+#define QM_CMD_MIN				         0
+#define QM_CMD_MAX				0x7FFFFFFF
+
+/* typedef void *      qm_handle; */
+
+/**
+ *
+ *  Return values:
+ *		0 - success
+ */
+int qm_open(void);
+
+/**
+ *
+ *  Return values:
+ *		0 - success
+ */
+int qm_close(void);
+
+/**
+ *
+ *  Return values:
+ *		0 - success
+ */
+int qm_restart(void);
+
+/**
+ *  Set base address in Dram for pool
+ *
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_base_address_pool_set(
+							u32 *pl_base_address, /* Payload DRAM base address */
+							u32 *qece_base_address); /* QE/CE DRAM base address */
+
+/**
+ *  Enables QM,
+ *  Configure DMA with GPM pool thresholds with default values
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_gpm_pools_def_enable(void);
+
+/**
+ *  Enables QM,
+ *  Configure DMA with GPM pool thresholds
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_gpm_pools_enable(
+				u32 qece_thr_hi, /* GPM qe pool (pool 0) high 32bits threshold */
+				u32 qece_thr_lo, /* GPM qe pool (pool 0) low 32bits threshold */
+				u32 pl_thr_hi, /* GPM payload pool (pool 1) hi 32bits threshold */
+				u32 pl_thr_lo); /* GPM payload pool (pool 1) low 32bits threshold */
+
+/**
+ *  Configure DMA with DRAM pool thresholds with default values
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_dram_pools_def_enable(void);
+
+/**
+ *  Configure DMA with DRAM pool thresholds
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_dram_pools_enable(
+				u32 qece_thr_hi, /* DRAM qe pool (pool 2) high 32bits threshold */
+				u32 qece_thr_lo, /* DRAM qe pool (pool 2) low 32bits threshold */
+				u32 pl_thr_hi, /* DRAM payload pool (pool 3) hi 32bits threshold */
+				u32 pl_thr_lo); /* DRAM payload pool (pool 3) low 32bits threshold */
+
+/**
+ *  Configures for each queue in DMA if the queue resides in GPM or in DRAM
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_queue_memory_type_set(
+				u32 queue, /* Queue number 0 to 511 */
+				u32 memory_type); /* Memory type 0 - for DRAM 1 - for GPM */
+
+/**
+ *  Disable prefetching of BM from DMA and PFE - TBD
+ *  Return values:
+ *		0 - success
+int qm_disable(void);
+TBD Â– ask yuval peleg defined bits to stops and bit to check if it is stopped
+*/
+
+/**
+ *  verify if there is any Queue (0 to 511),
+ *  that has a queue length larger than 0
+ *  Return values:
+ *		0 - success
+ */
+int qm_packets_in_queues(
+				u32 *status);
+
+/**
+ *  Set default for QM units for mandatory parameters
+ *  Return values:
+ *		0 - success
+ */
+int qm_default_set(void);
+
+/**
+ *  Set SID number for each pool (0 and 1) in REORDER unit with default values
+ *  Return values:
+ *		0 - success
+ */
+int qm_ru_pool_sid_number_def_set(void);
+
+/**
+ *  Set SID number for each pool (0 and 1) in REORDER unit
+ *  Return values:
+ *		0 - success
+ */
+int qm_ru_pool_sid_number_set(
+				u32 pool0_sid_num, /* SID number fo pool 0. Total number of SID is 4k */
+				u32 pool1_sid_num); /* SID number fo pool 1. Total number of SID is 4k */
+
+/**
+ * Configure REORDER with class command when permission is granted with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_ru_port_to_class_def_set(void);
+
+/**
+ * Configure REORDER with class command when permission is granted.
+ *  Return values:
+ *		0 - success
+ */
+int qm_ru_port_to_class_set(
+				u32 *port_class_arr, /* class number in reorder unit. 0 to 63 */
+				u32 *port_pool_arr, /* holds pool  values which are either 0 or 1 */
+				u32 input_port); /* input port that arrive with the packet. 0 to 287 */
+/*
+				u32 reorder_class, / * class number in reorder unit. 0 to 63 * /
+				u32 input_port, / * input port that arrive with the packet. 0 to 287 * /
+*/
+
+/**
+ *  Configure DQF fifo base and depth thresholds with default values
+ *  Return values:
+ *		0 - success
+ */
+int qm_dqf_port_data_fifo_def_set(void);
+
+/**
+ *  Configure DQF fifo base and depth thresholds
+ *  Return values:
+ *		0 - success
+ */
+int qm_dqf_port_data_fifo_set(
+				u32 *port_depth_arr); /* holds depth in Bytes for ports 0 to 15 */
+
+/**
+ *  Configure DQF fifo credit thresholds with default values
+ *  Return values:
+ *		0 - success
+ */
+int qm_dqf_port_credit_thr_def_set(void);
+
+/**
+ *  Configure DQF fifo credit thresholds
+ *  Return values:
+ *		0 - success
+ */
+int qm_dqf_port_credit_thr_set(
+				u32 *port_credit_thr_arr); /* Configures credits thresholds for xMac input ports */
+
+/**
+ *  Configure DQF for each port which PPC (data or maintenance) handles the packet,
+ *  relevant only for PPC port with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dqf_port_ppc_map_def_set(void);
+
+/**
+ *  Configure DQF for each port which PPC (data or maintenance) handles the packet,
+ *  relevant only for PPC port.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dqf_port_ppc_map_set(
+				u32 *port_ppc_arr, /* holds indication which PPC process packets from this port */
+				u32 port); /* input ports */
+
+/**
+ *  Configure DMA QOS write attributes with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_qos_attr_def_set(void);
+
+/**
+ *  Configure DMA QOS write attributes.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_qos_attr_set(
+				u32 swf_awqos,
+				u32 rdma_awqos,
+				u32 hwf_qe_ce_awqos,
+				u32 hwf_sfh_pl_awqos);
+
+/**
+ *  Configure DMA CACHE write attributes with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_cache_attr_def_set(void);
+
+/**
+ *  Configure DMA CACHE write attributes.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_cache_attr_set(
+				u32 swf_awcache,
+				u32 rdma_awcache,
+				u32 hwf_qe_ce_awcache,
+				u32 hwf_sfh_pl_awcache);
+
+/**
+ *  Configure DMA DOMAIN write attributes with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_domain_attr_def_set(void);
+
+/**
+ *  Configure DMA DOMAIN write attributes.
+ *  Return values:
+ *		0 - success
+ */
+int qm_dma_domain_attr_set(
+				u32 swf_awdomain,
+				u32 rdma_awdomain,
+				u32 hwf_qe_ce_awdomain,
+				u32 hwf_sfh_pl_awdomain);
+
+/**
+ *  Configure PFE QOS read attributes with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_qos_attr_def_set(void);
+
+/**
+ *  Configure PFE QOS read attributes.
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_qos_attr_set(
+				u32 swf_arqos,
+				u32 rdma_arqos,
+				u32 hwf_qe_ce_arqos,
+				u32 hwf_sfh_pl_arqos);
+
+/**
+ *  Configure PFE CACHE read attributes with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_cache_attr_def_set(void);
+
+/**
+ *  Configure PFE CACHE read attributes.
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_cache_attr_set(
+				u32 swf_arcache,
+				u32 rdma_arcache,
+				u32 hwf_qe_ce_arcache,
+				u32 hwf_sfh_pl_arcache);
+
+/**
+ *  Configure PFE DOMAIN read attributes with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_domain_attr_def_set(void);
+
+/**
+ *  Configure PFE DOMAIN read attributes.
+ *  Return values:
+ *		0 - success
+ */
+int qm_pfe_domain_attr_set(
+				u32 swf_ardomain,
+				u32 rdma_ardomain,
+				u32 hwf_qe_ce_ardomain,
+				u32 hwf_sfh_pl_ardomain);
+
+/**
+ *  Configures per queue threshold profile with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_ql_q_profile_def_set(void);
+
+/**
+ *  Configures per queue threshold profile.
+ *  Return values:
+ *		0 - success
+ */
+int qm_ql_q_profile_set(
+				u32 queue_profile,
+				u32 queue);
+
+/**
+ *  Configures QL threshold for pause, on (low) and off (high)
+ *  and the to whom to send it (source) with default values.
+ *  Return values:
+ *		0 - success
+ */
+int qm_ql_thr_def_set(void);
+
+/**
+ *  Configures QL threshold for pause, on (low) and off (high)
+ *  and the to whom to send it (source).
+ *  Return values:
+ *		0 - success
+ */
+int qm_ql_thr_set(
+				u32 low_threshold,
+				u32 pause_threshold,
+				u32 high_threshold,
+				u32 traffic_source,
+				u32 queue_profile);
+
+/**
+ *  Set VMID in DMA and PFE
+ *  Return values:
+ *		0 - success
+ */
+int qm_vmid_set(u32 qm_vmid); /* VMID value for DAM and PFE */
+int dma_vmid_set(u32 qm_vmid); /* VMID value for DAM */
+int pfe_vmid_set(u32 qm_vmid); /* VMID value for PFE */
+
+/**
+ *  Configre PFE to start Flushing Queue. This process takes a while.
+ *  Indication for its completion is when Queue is empty
+ *  Return values:
+ *		0 - success
+ */
+int qm_queue_flush_start(u32 queue); /* queue number from 0 to 511 */
+
+/**
+ *  Configre PFE to start Flushing Port. This process takes a while.
+ *  Indication for its completion is when Port is empty
+ *  Return values:
+ *		0 - success
+ */
+int qm_port_flush_start(u32 port); /* port number from 0 to 15 */
+
+/**
+ *  Gives queue length and status
+ *  Return values:
+ *		0 - success
+ */
+int	qm_queue_len_get(
+			u32 queue, /* queue number from 0 to 511 */
+			u32 *length,
+			u32 *status);
+
+/**
+ *  Get Idle status from DMA
+ *  Return values:
+ *		0 - success
+ */
+int qm_idle_status_get(
+			u32 *status); /* DMA status is output to the called */
+
+/**
+ * Configure REORDER with class command when permission is granted.
+ *  Return values:
+ *		0 - success
+ */
+int	qm_ru_class_cmd_set(
+				u32 host,
+				u32 host_class, /* class number in reorder unit. 0 to 63 */
+				u32 host_sid, /* sid is in the range 0 to 4k */
+				u32 cmd); /* cmd is either update or release */
+
+/**
+ *  Write QM register
+ *  Return values:
+ *		0 - success
+ */
+int qm_register_write(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr);
+
+/**
+ *  Read QM register
+ *  Return values:
+ *		0 - success
+ */
+int qm_register_read(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr);
+
+#endif /* MV_QM_H */
diff --git a/drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.c b/drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.c
new file mode 100644
index 0000000..73fd65b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.c
@@ -0,0 +1,498 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+/* includes */
+/*#include "common/platform_definitions.h" */
+#include "common/mv_hw_if.h"
+#include "common/mv_sw_if.h"
+#include "qm/mv_qm_regs.h"
+
+struct qm_alias qm;
+struct qm_alias qm_reg_size;
+struct qm_alias qm_reg_offset;
+
+int qm_reg_address_alias_init(void)
+{
+	int rc = -QM_ALIAS_ERROR;
+	u32 siliconBase;
+
+	/*u32 bid, i;*/
+/*	u32      siliconBase    = SILICON_BASE; */
+	u32      qm_unit_offset =      QM_UNIT_OFFSET;
+	u32      ql_unit_offset =      QL_UNIT_OFFSET;
+	u32     pfe_unit_offset =     PFE_UNIT_OFFSET;
+	u32     dqf_unit_offset =     DQF_UNIT_OFFSET;
+	u32     dma_unit_offset =     DMA_UNIT_OFFSET;
+	u32   sched_unit_offset =   SCHED_UNIT_OFFSET;
+	u32    drop_unit_offset =    DROP_UNIT_OFFSET;
+	u32 reorder_unit_offset = REORDER_UNIT_OFFSET;
+	u32     gpm_unit_offset =     GPM_UNIT_OFFSET;
+
+	siliconBase = mv_hw_silicon_base_addr_get();
+
+	qm.base         = siliconBase +  qm_unit_offset;    /*0x00400000*/
+	qm.ql.base      = qm.base +      ql_unit_offset;	/*0x00400000*/
+	qm.pfe.base     = qm.base +     pfe_unit_offset;	/*0x00410000*/
+	qm.dqf.base     = qm.base +     dqf_unit_offset;	/*0x00420000*/
+	qm.dma.base     = qm.base +     dma_unit_offset;	/*0x00430000*/
+	qm.sched.base   = qm.base +   sched_unit_offset;	/*0x00440000*/
+	qm.drop.base    = qm.base +    drop_unit_offset;	/*0x00480000*/
+	qm.reorder.base = qm.base + reorder_unit_offset;	/*0x00500000*/
+	qm.gpm.base     = qm.base +     gpm_unit_offset;	/*0x00600000*/
+
+	/* QL registers addresses */
+	qm.ql.qptr                 = qm.ql.base + 0x00000000;
+	qm.ql.low_threshold        = qm.ql.base + 0x00000400;
+	qm.ql.pause_threshold      = qm.ql.base + 0x00000404;
+	qm.ql.high_threshold       = qm.ql.base + 0x00000408;
+	qm.ql.traffic_source       = qm.ql.base + 0x0000040C;
+	qm.ql.ECC_error_cause      = qm.ql.base + 0x00000500;
+	qm.ql.ECC_error_mask       = qm.ql.base + 0x00000504;
+	qm.ql.Internal_error_cause = qm.ql.base + 0x00000508;
+	qm.ql.internal_error_mask  = qm.ql.base + 0x0000050C;
+	qm.ql.nss_general_purpose  = qm.ql.base + 0x00001000;
+	qm.ql.qlen                 = qm.ql.base + 0x00002000;
+
+	/* PFE registers addresses */
+	qm.pfe.qece_dram_base_address_hi         = qm.pfe.base + 0x00000000;
+	qm.pfe.pyld_dram_base_address_hi         = qm.pfe.base + 0x00000004;
+	qm.pfe.qece_dram_base_address_lo         = qm.pfe.base + 0x00000008;
+	qm.pfe.pyld_dram_base_address_lo         = qm.pfe.base + 0x0000000C;
+	qm.pfe.QM_VMID                           = qm.pfe.base + 0x00000010;
+	qm.pfe.port_flush                        = qm.pfe.base + 0x0000001C;
+	qm.pfe.AXI_read_attributes_for_swf_mode  = qm.pfe.base + 0x00000030;
+	qm.pfe.AXI_read_attributes_for_rdma_mode = qm.pfe.base + 0x00000034;
+	qm.pfe.AXI_read_attributes_for_hwf_qece  = qm.pfe.base + 0x00000038;
+	qm.pfe.AXI_read_attributes_for_hwf_pyld  = qm.pfe.base + 0x0000003C;
+	qm.pfe.ecc_error_cause                   = qm.pfe.base + 0x00000100;
+	qm.pfe.ecc_error_mask                    = qm.pfe.base + 0x00000104;
+	qm.pfe.internal_error_cause              = qm.pfe.base + 0x00000108;
+	qm.pfe.internal_error_mask               = qm.pfe.base + 0x0000010C;
+	qm.pfe.idle_status                       = qm.pfe.base + 0x00000110;
+	qm.pfe.queue_flush                       = qm.pfe.base + 0x00000400;
+	qm.pfe.queue_qece                        = qm.pfe.base + 0x00008000;
+
+	/* DQF registers addresses */
+	qm.dqf.Data_FIFO_params_p               = qm.dqf.base + 0x00000000;
+	qm.dqf.Credit_Threshold_p               = qm.dqf.base + 0x00000040;
+	qm.dqf.PPC_port_map_p                   = qm.dqf.base + 0x00000080;
+	qm.dqf.data_fifo_pointers_p             = qm.dqf.base + 0x000000C0;
+	qm.dqf.dqf_itnr_cause                   = qm.dqf.base + 0x00000100;
+	qm.dqf.dqf_itnr_mask                    = qm.dqf.base + 0x00000104;
+	qm.dqf.misc_error_intr_cause            = qm.dqf.base + 0x00000108;
+	qm.dqf.misc_error_intr_mask             = qm.dqf.base + 0x00000104;
+	qm.dqf.dqf_ser_summary_intr_cause       = qm.dqf.base + 0x00000110;
+	qm.dqf.dqf_ser_summary_intr_mask        = qm.dqf.base + 0x00000114;
+	qm.dqf.write_to_full_error_intr_cause   = qm.dqf.base + 0x00000118;
+	qm.dqf.write_to_full_error_intr_mask    = qm.dqf.base + 0x0000011C;
+	qm.dqf.read_from_empty_error_intr_cause = qm.dqf.base + 0x00000120;
+	qm.dqf.read_from_empty_error_intr_mask  = qm.dqf.base + 0x00000124;
+	qm.dqf.wrong_axi_rd_error_intr_cause    = qm.dqf.base + 0x00000128;
+	qm.dqf.wrong_axi_rd_error_intr_mask     = qm.dqf.base + 0x0000012C;
+	qm.dqf.mg2mem_req_addr_ctrl             = qm.dqf.base + 0x00000130;
+	qm.dqf.mem2mg_resp_status               = qm.dqf.base + 0x00000134;
+	qm.dqf.mem2mg_resp_data_hh              = qm.dqf.base + 0x00000138;
+	qm.dqf.mem2mg_resp_data_hl              = qm.dqf.base + 0x0000013C;
+	qm.dqf.mem2mg_resp_data_lh              = qm.dqf.base + 0x00000140;
+	qm.dqf.mem2mg_resp_data_ll              = qm.dqf.base + 0x00000144;
+	qm.dqf.dqf_macs_l3_res                  = qm.dqf.base + 0x00001000;
+	qm.dqf.dqf_macs_l4_res                  = qm.dqf.base + 0x00001400;
+	qm.dqf.dqf_macs_l3_ptr                  = qm.dqf.base + 0x00001800;
+	qm.dqf.dqf_macs_l4_ptr                  = qm.dqf.base + 0x00001C00;
+	qm.dqf.dqf_macs_desc                    = qm.dqf.base + 0x00002000;
+
+	/* DMA registers addresses */
+	qm.dma.Q_memory_allocation                = qm.dma.base + 0x00000000;
+	qm.dma.gpm_thresholds                     = qm.dma.base + 0x00000050;
+	qm.dma.dram_thresholds                    = qm.dma.base + 0x00000054;
+	qm.dma.AXI_write_attributes_for_swf_mode  = qm.dma.base + 0x00000060;
+	qm.dma.AXI_write_attributes_for_rdma_mode = qm.dma.base + 0x00000064;
+	qm.dma.AXI_write_attributes_for_hwf_qece  = qm.dma.base + 0x00000068;
+	qm.dma.AXI_write_attributes_for_hwf_pyld  = qm.dma.base + 0x0000006C;
+	qm.dma.DRAM_VMID                          = qm.dma.base + 0x00000070;
+	qm.dma.idle_status                        = qm.dma.base + 0x00000080;
+	qm.dma.ecc_error_cause                    = qm.dma.base + 0x00000100;
+	qm.dma.ecc_error_mask                     = qm.dma.base + 0x00000104;
+	qm.dma.internal_error_cause               = qm.dma.base + 0x00000108;
+	qm.dma.internal_error_mask                = qm.dma.base + 0x0000010C;
+	qm.dma.ceram_mac                          = qm.dma.base + 0x00000800;
+	qm.dma.ceram_ppe                          = qm.dma.base + 0x00001000;
+	qm.dma.qeram                              = qm.dma.base + 0x00001800;
+	qm.dma.dram_fifo                          = qm.dma.base + 0x00002000;
+
+	/* SCHED registers addresses */
+	qm.sched.ErrStus                = qm.sched.base + 0x00000000;
+
+	/* DROP registers addresses */
+	qm.drop.DrpErrStus                            = qm.drop.base + 0x00000000;
+	qm.drop.DrpFirstExc                           = qm.drop.base + 0x00000008;
+	qm.drop.DrpErrCnt                             = qm.drop.base + 0x00000010;
+	qm.drop.DrpExcCnt                             = qm.drop.base + 0x00000018;
+	qm.drop.DrpExcMask                            = qm.drop.base + 0x00000020;
+	qm.drop.DrpId                                 = qm.drop.base + 0x00000028;
+	qm.drop.DrpForceErr                           = qm.drop.base + 0x00000030;
+	qm.drop.WREDDropProbMode                      = qm.drop.base + 0x00000038;
+	qm.drop.WREDMaxProbModePerColor               = qm.drop.base + 0x00000040;
+	qm.drop.DPSource                              = qm.drop.base + 0x00000048;
+	qm.drop.RespLocalDPSel                        = qm.drop.base + 0x00000050;
+	qm.drop.Drp_Decision_to_Query_debug           = qm.drop.base + 0x00000058;
+	qm.drop.Drp_Decision_hierarchy_to_Query_debug = qm.drop.base + 0x00000060;
+	qm.drop.TMtoTMPktGenQuantum                   = qm.drop.base + 0x00000068;
+	qm.drop.TMtoTMDPCoSSel                        = qm.drop.base + 0x00000070;
+	qm.drop.AgingUpdEnable                        = qm.drop.base + 0x00000078;
+	qm.drop.PortInstAndAvgQueueLength             = qm.drop.base + 0x0001A000;
+	qm.drop.DrpEccConfig                          = qm.drop.base + 0x0001E000;
+	qm.drop.DrpEccMemParams                       = qm.drop.base + 0x0001E008;
+
+	/* REORDER registers addresses */
+	qm.reorder.ru_qe              = qm.reorder.base + 0x00000000;
+	qm.reorder.ru_class           = qm.reorder.base + 0x00020000;
+	qm.reorder.ru_tasks           = qm.reorder.base + 0x00028000;
+	qm.reorder.ru_ptr2next        = qm.reorder.base + 0x00030000;
+	qm.reorder.ru_sid_fifo        = qm.reorder.base + 0x00038000;
+	qm.reorder.ru_port2class      = qm.reorder.base + 0x00040000;
+	qm.reorder.ru_pool            = qm.reorder.base + 0x00090000;
+	qm.reorder.ru_class_head      = qm.reorder.base + 0x00090100;
+	qm.reorder.ru_ser_error_cause = qm.reorder.base + 0x00090500;
+	qm.reorder.ru_ser_error_mask  = qm.reorder.base + 0x00090504;
+	qm.reorder.ru_host_cmd        = qm.reorder.base + 0x00090580;
+	qm.reorder.ru_task_permission = qm.reorder.base + 0x00090584;
+
+	/* GPM registers addresses */
+	qm.gpm.gpm_pl = qm.gpm.base + 0x00000000;
+	qm.gpm.gpm_qe = qm.gpm.base + 0x000A0000;
+
+	rc = OK;
+	return rc;
+}
+
+int qm_reg_size_alias_init(void)
+{
+	int rc = -QM_ALIAS_ERROR;
+	u32 word_size_in_bits, byte_size_in_bits = 8;
+
+	word_size_in_bits = 32/byte_size_in_bits;	/* word_size_in_bits = 4 */
+
+	/* QL registers sizes */
+	qm_reg_size.ql.qptr                 = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.low_threshold        = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.pause_threshold      = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.high_threshold       = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.traffic_source       = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.ECC_error_cause      = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.ECC_error_mask       = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.Internal_error_cause = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.internal_error_mask  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.nss_general_purpose  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.ql.qlen                 = 32/byte_size_in_bits/word_size_in_bits;
+
+	/* PFE registers sizes */
+	qm_reg_size.pfe.qece_dram_base_address_hi         =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.pyld_dram_base_address_hi         =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.qece_dram_base_address_lo         =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.pyld_dram_base_address_lo         =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.QM_VMID                           =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.port_flush                        =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.AXI_read_attributes_for_swf_mode  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.AXI_read_attributes_for_rdma_mode =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.AXI_read_attributes_for_hwf_qece  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.AXI_read_attributes_for_hwf_pyld  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.ecc_error_cause                   =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.ecc_error_mask                    =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.internal_error_cause              =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.internal_error_mask               =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.idle_status                       =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.queue_flush                       =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.pfe.queue_qece                        = 128/byte_size_in_bits/word_size_in_bits;
+
+	/* DQF registers sizes */
+	qm_reg_size.dqf.Data_FIFO_params_p               = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.Credit_Threshold_p               = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.PPC_port_map_p                   = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.data_fifo_pointers_p             = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_itnr_cause                   = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_itnr_mask                    = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.misc_error_intr_cause            = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.misc_error_intr_mask             = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_ser_summary_intr_cause       = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_ser_summary_intr_mask        = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.write_to_full_error_intr_cause   = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.write_to_full_error_intr_mask    = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.read_from_empty_error_intr_cause = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.read_from_empty_error_intr_mask  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.wrong_axi_rd_error_intr_cause    = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.wrong_axi_rd_error_intr_mask     = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.mg2mem_req_addr_ctrl             = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.mem2mg_resp_status               = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.mem2mg_resp_data_hh              = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.mem2mg_resp_data_hl              = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.mem2mg_resp_data_lh              = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.mem2mg_resp_data_ll              = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_macs_l3_res                  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_macs_l4_res                  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_macs_l3_ptr                  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_macs_l4_ptr                  = 32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dqf.dqf_macs_desc                    = 64/byte_size_in_bits/word_size_in_bits;
+
+	/* DMA registers addresses */
+	qm_reg_size.dma.Q_memory_allocation                =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.gpm_thresholds                     =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.dram_thresholds                    =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.AXI_write_attributes_for_swf_mode  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.AXI_write_attributes_for_rdma_mode =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.AXI_write_attributes_for_hwf_qece  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.AXI_write_attributes_for_hwf_pyld  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.DRAM_VMID                          =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.idle_status                        =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.ecc_error_cause                    =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.ecc_error_mask                     =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.internal_error_cause               =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.internal_error_mask                =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.ceram_mac                          =  96/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.ceram_ppe                          = 160/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.qeram                              =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.dma.dram_fifo                          = 160/byte_size_in_bits/word_size_in_bits;
+
+	/* SCHED registers addresses */
+	qm_reg_size.sched.ErrStus			               = 64/byte_size_in_bits/word_size_in_bits;
+
+	/* DROP registers addresses */
+	qm_reg_size.drop.DrpErrStus                            = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpFirstExc                           = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpErrCnt                             = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpExcCnt                             = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpExcMask                            = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpId                                 = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpForceErr                           = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.WREDDropProbMode                      = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.WREDMaxProbModePerColor               = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DPSource                              = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.RespLocalDPSel                        = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.Drp_Decision_to_Query_debug           = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.Drp_Decision_hierarchy_to_Query_debug = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.TMtoTMPktGenQuantum                   = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.TMtoTMDPCoSSel                        = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.AgingUpdEnable                        = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.PortInstAndAvgQueueLength             = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpEccConfig                          = 64/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.drop.DrpEccMemParams                       = 64/byte_size_in_bits/word_size_in_bits;
+
+	/* REORDER registers addresses */
+	qm_reg_size.reorder.ru_qe              = 256/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_class           =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_tasks           =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_ptr2next        =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_sid_fifo        =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_port2class      =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_pool            =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_class_head      =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_ser_error_cause =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_ser_error_mask  =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_host_cmd        =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.reorder.ru_task_permission =  32/byte_size_in_bits/word_size_in_bits;
+
+	/* GPM registers addresses */
+	qm_reg_size.gpm.gpm_pl =  32/byte_size_in_bits/word_size_in_bits;
+	qm_reg_size.gpm.gpm_qe = 128/byte_size_in_bits/word_size_in_bits;
+
+	rc = OK;
+	return rc;
+}
+
+int qm_reg_offset_alias_init(void)
+{
+	int rc = -QM_ALIAS_ERROR;
+
+	/*memset(qm_reg_offset,0,sizeof(*qm_reg_offset));*/
+	/* QL registers sizes */
+	qm_reg_offset.ql.qptr                 =  4;
+	qm_reg_offset.ql.low_threshold        = 16;
+	qm_reg_offset.ql.pause_threshold      = 16;
+	qm_reg_offset.ql.high_threshold       = 16;
+	qm_reg_offset.ql.traffic_source       = 16;
+	qm_reg_offset.ql.ECC_error_cause      =  4;
+	qm_reg_offset.ql.ECC_error_mask       =  4;
+	qm_reg_offset.ql.Internal_error_cause =  4;
+	qm_reg_offset.ql.internal_error_mask  =  4;
+	qm_reg_offset.ql.nss_general_purpose  =  4;
+	qm_reg_offset.ql.qlen                 =  4;
+
+	/* PFE registers sizes */
+	qm_reg_offset.pfe.qece_dram_base_address_hi         =   4;
+	qm_reg_offset.pfe.pyld_dram_base_address_hi         =   4;
+	qm_reg_offset.pfe.qece_dram_base_address_lo         =   4;
+	qm_reg_offset.pfe.pyld_dram_base_address_lo         =   4;
+	qm_reg_offset.pfe.QM_VMID                           =   4;
+	qm_reg_offset.pfe.port_flush                        =   4;
+	qm_reg_offset.pfe.AXI_read_attributes_for_swf_mode  =   4;
+	qm_reg_offset.pfe.AXI_read_attributes_for_rdma_mode =   4;
+	qm_reg_offset.pfe.AXI_read_attributes_for_hwf_qece  =   4;
+	qm_reg_offset.pfe.AXI_read_attributes_for_hwf_pyld  =   4;
+	qm_reg_offset.pfe.ecc_error_cause                   =   4;
+	qm_reg_offset.pfe.ecc_error_mask                    =   4;
+	qm_reg_offset.pfe.internal_error_cause              =   4;
+	qm_reg_offset.pfe.internal_error_mask               =   4;
+	qm_reg_offset.pfe.idle_status                       =   4;
+	qm_reg_offset.pfe.queue_flush                       =   4;
+	qm_reg_offset.pfe.queue_qece                        =  16;
+
+	/* DQF registers sizes */
+	qm_reg_offset.dqf.Data_FIFO_params_p               = 4;
+	qm_reg_offset.dqf.Credit_Threshold_p	           = 4;
+	qm_reg_offset.dqf.PPC_port_map_p                   = 4;
+	qm_reg_offset.dqf.data_fifo_pointers_p             = 4;
+	qm_reg_offset.dqf.dqf_itnr_cause                   = 4;
+	qm_reg_offset.dqf.dqf_itnr_mask                    = 4;
+	qm_reg_offset.dqf.misc_error_intr_cause            = 4;
+	qm_reg_offset.dqf.misc_error_intr_mask             = 4;
+	qm_reg_offset.dqf.dqf_ser_summary_intr_cause       = 4;
+	qm_reg_offset.dqf.dqf_ser_summary_intr_mask        = 4;
+	qm_reg_offset.dqf.write_to_full_error_intr_cause   = 4;
+	qm_reg_offset.dqf.write_to_full_error_intr_mask    = 4;
+	qm_reg_offset.dqf.read_from_empty_error_intr_cause = 4;
+	qm_reg_offset.dqf.read_from_empty_error_intr_mask  = 4;
+	qm_reg_offset.dqf.wrong_axi_rd_error_intr_cause    = 4;
+	qm_reg_offset.dqf.wrong_axi_rd_error_intr_mask     = 4;
+	qm_reg_offset.dqf.mg2mem_req_addr_ctrl             = 4;
+	qm_reg_offset.dqf.mem2mg_resp_status               = 4;
+	qm_reg_offset.dqf.mem2mg_resp_data_hh              = 4;
+	qm_reg_offset.dqf.mem2mg_resp_data_hl              = 4;
+	qm_reg_offset.dqf.mem2mg_resp_data_lh              = 4;
+	qm_reg_offset.dqf.mem2mg_resp_data_ll              = 4;
+	qm_reg_offset.dqf.dqf_macs_l3_res                  = 4;
+	qm_reg_offset.dqf.dqf_macs_l4_res                  = 4;
+	qm_reg_offset.dqf.dqf_macs_l3_ptr                  = 4;
+	qm_reg_offset.dqf.dqf_macs_l4_ptr                  = 4;
+	qm_reg_offset.dqf.dqf_macs_desc                    = 4;
+
+	/* DMA registers addresses */
+	qm_reg_offset.dma.Q_memory_allocation                =  4;
+	qm_reg_offset.dma.gpm_thresholds                     =  4;
+	qm_reg_offset.dma.dram_thresholds                    =  4;
+	qm_reg_offset.dma.AXI_write_attributes_for_swf_mode  =  4;
+	qm_reg_offset.dma.AXI_write_attributes_for_rdma_mode =  4;
+	qm_reg_offset.dma.AXI_write_attributes_for_hwf_qece  =  4;
+	qm_reg_offset.dma.AXI_write_attributes_for_hwf_pyld  =  4;
+	qm_reg_offset.dma.DRAM_VMID                          =  4;
+	qm_reg_offset.dma.idle_status                        =  4;
+	qm_reg_offset.dma.ecc_error_cause                    =  4;
+	qm_reg_offset.dma.ecc_error_mask                     =  4;
+	qm_reg_offset.dma.internal_error_cause               =  4;
+	qm_reg_offset.dma.internal_error_mask                =  4;
+	qm_reg_offset.dma.ceram_mac                          = 16;
+	qm_reg_offset.dma.ceram_ppe                          = 32;
+	qm_reg_offset.dma.qeram                              =  4;
+/*#warning MY_WARNING: Register qm_reg_offset.dma.dram_fifo is not defined in CIDER properly.*/
+	qm_reg_offset.dma.dram_fifo                          = 32;
+
+	/* SCHED registers addresses */
+	qm_reg_offset.sched.ErrStus                = 8;
+
+	/* DROP registers addresses */
+	qm_reg_offset.drop.DrpErrStus                            = 8;
+	qm_reg_offset.drop.DrpFirstExc                           = 8;
+	qm_reg_offset.drop.DrpErrCnt                             = 8;
+	qm_reg_offset.drop.DrpExcCnt                             = 8;
+	qm_reg_offset.drop.DrpExcMask                            = 8;
+	qm_reg_offset.drop.DrpId                                 = 8;
+	qm_reg_offset.drop.DrpForceErr                           = 8;
+	qm_reg_offset.drop.WREDDropProbMode                      = 8;
+	qm_reg_offset.drop.WREDMaxProbModePerColor               = 8;
+	qm_reg_offset.drop.DPSource                              = 8;
+	qm_reg_offset.drop.RespLocalDPSel                        = 8;
+	qm_reg_offset.drop.Drp_Decision_to_Query_debug           = 8;
+
+	qm_reg_offset.drop.Drp_Decision_hierarchy_to_Query_debug = 8;
+	qm_reg_offset.drop.TMtoTMPktGenQuantum                   = 8;
+	qm_reg_offset.drop.TMtoTMDPCoSSel                        = 8;
+	qm_reg_offset.drop.AgingUpdEnable                        = 8;
+	qm_reg_offset.drop.PortInstAndAvgQueueLength             = 8;
+	qm_reg_offset.drop.DrpEccConfig                          = 8;
+	qm_reg_offset.drop.DrpEccMemParams                       = 8;
+
+	/* REORDER registers addresses */
+	qm_reg_offset.reorder.ru_qe              = 32;
+	qm_reg_offset.reorder.ru_class           =  4;
+	qm_reg_offset.reorder.ru_tasks           =  4;
+	qm_reg_offset.reorder.ru_ptr2next        =  4;
+	qm_reg_offset.reorder.ru_sid_fifo        =  4;
+	qm_reg_offset.reorder.ru_port2class      =  4;
+	qm_reg_offset.reorder.ru_pool            =  4;
+	qm_reg_offset.reorder.ru_class_head      =  4;
+	qm_reg_offset.reorder.ru_ser_error_cause =  4;
+	qm_reg_offset.reorder.ru_ser_error_mask  =  4;
+	qm_reg_offset.reorder.ru_host_cmd        =  8;
+	qm_reg_offset.reorder.ru_task_permission =  8;
+
+	/* GPM registers addresses */
+	qm_reg_offset.gpm.gpm_pl =  8;
+	qm_reg_offset.gpm.gpm_qe = 16;
+
+	rc = OK;
+	return rc;
+}
+
+
+#ifdef MY_HIDE
+#endif /* MY_HIDE */
diff --git a/drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.h b/drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.h
new file mode 100644
index 0000000..9d7503b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/pp3/qm/mv_qm_regs.h
@@ -0,0 +1,1124 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+********************************************************************************
+Marvell Commercial License Option
+
+If you received this File from Marvell and you have entered into a commercial
+license agreement (a "Commercial License") with Marvell, the File is licensed
+to you under the terms of the applicable Commercial License.
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+********************************************************************************
+Marvell BSD License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File under the following licensing terms.
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+    *   Redistributions of source code must retain the above copyright notice,
+	this list of conditions and the following disclaimer.
+
+    *   Redistributions in binary form must reproduce the above copyright
+	notice, this list of conditions and the following disclaimer in the
+	documentation and/or other materials provided with the distribution.
+
+    *   Neither the name of Marvell nor the names of its contributors may be
+	used to endorse or promote products derived from this software without
+	specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*******************************************************************************/
+
+#ifndef	__MV_QM_REGS_H__
+#define	__MV_QM_REGS_H__
+
+#include "qm/mv_qm.h"
+
+#define      QM_UNIT_OFFSET 0x00400000
+#define      QL_UNIT_OFFSET 0x00000000
+#define     PFE_UNIT_OFFSET 0x00010000
+#define     DQF_UNIT_OFFSET 0x00020000
+#define     DMA_UNIT_OFFSET 0x00030000
+#define   SCHED_UNIT_OFFSET 0x00040000
+#define    DROP_UNIT_OFFSET 0x00080000
+#define      BM_UNIT_OFFSET 0x000D0000
+#define REORDER_UNIT_OFFSET 0x00100000
+#define     GPM_UNIT_OFFSET 0x00200000
+
+
+/* DMA */
+struct dma_q_memory_allocation {
+	int q_memory:32;					/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_gpm_thresholds {
+	int gpm_pl_pool_low_bp:6;			/* byte[ 0- 3] ,bit[ 0- 5] */
+	int _reserved_1:2;					/* byte[ 0- 3] ,bit[ 6- 7] */
+	int gpm_pl_pool_high_bp:6;			/* byte[ 0- 3] ,bit[ 8-13] */
+	int _reserved_2:2;					/* byte[ 0- 3] ,bit[14-15] */
+	int gpm_qe_pool_low_bp:6;			/* byte[ 0- 3] ,bit[16-21] */
+	int _reserved_3:2;					/* byte[ 0- 3] ,bit[22-23] */
+	int gpm_qe_pool_high_bp:6;			/* byte[ 0- 3] ,bit[24-29] */
+	int _reserved_4:2;					/* byte[ 0- 3] ,bit[30-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_dram_thresholds {
+	int dram_pl_pool_low_bp:6;			/* byte[ 0- 3] ,bit[ 0- 5] */
+	int _reserved_1:2;					/* byte[ 0- 3] ,bit[ 6- 7] */
+	int dram_pl_pool_high_bp:6;			/* byte[ 0- 3] ,bit[ 8-13] */
+	int _reserved_2:2;					/* byte[ 0- 3] ,bit[14-15] */
+	int dram_qe_pool_low_bp:6;			/* byte[ 0- 3] ,bit[16-21] */
+	int _reserved_3:2;					/* byte[ 0- 3] ,bit[22-23] */
+	int dram_qe_pool_high_bp:6;			/* byte[ 0- 3] ,bit[24-29] */
+	int _reserved_4:2;					/* byte[ 0- 3] ,bit[30-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_AXI_write_attributes_for_swf_mode {
+	int swf_awdomain:2;					/* byte[ 0- 3] ,bit[ 0- 1] */
+	int swf_awcache:4;					/* byte[ 0- 3] ,bit[ 2- 5] */
+	int swf_awqos:2;					/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_AXI_write_attributes_for_rdma_mode {
+	int rdma_awdomain:2;				/* byte[ 0- 3] ,bit[ 0- 1] */
+	int rdma_awcache:4;					/* byte[ 0- 3] ,bit[ 2- 5] */
+	int rdma_awqos:2;					/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_AXI_write_attributes_for_hwf_qece {
+	int qece_awdomain:2;				/* byte[ 0- 3] ,bit[ 0- 1] */
+	int qece_awcache:4;					/* byte[ 0- 3] ,bit[ 2- 5] */
+	int qece_awqos:2;					/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_AXI_write_attributes_for_hwf_pyld {
+	int pyld_awdomain:2;				/* byte[ 0- 3] ,bit[ 0- 1] */
+	int pyld_awcache:4;					/* byte[ 0- 3] ,bit[ 2- 5] */
+	int pyld_awqos:2;					/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_DRAM_VMID {
+	int dram_vmid:8;					/* byte[ 0- 3] ,bit[ 0- 7] */
+	int _reserved:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_idle_status {
+	int gpm_pl_cache_is_empty:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int gpm_pl_cache_is_full:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int gpm_qe_cache_is_empty:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int gpm_qe_cache_is_full:1;				/* byte[ 0- 3] ,bit[ 3- 3] */
+	int dram_pl_cache_is_empty:1;			/* byte[ 0- 3] ,bit[ 4- 4] */
+	int dram_pl_cache_is_full:1;			/* byte[ 0- 3] ,bit[ 5- 5] */
+	int dram_qe_cache_is_empty:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int dram_qe_cache_is_full:1;			/* byte[ 0- 3] ,bit[ 7- 7] */
+	int dram_fifo_is_empty:1;				/* byte[ 0- 3] ,bit[ 8- 8] */
+	int mac_axi_enq_channel_is_empty:1;		/* byte[ 0- 3] ,bit[ 9- 9] */
+	int NSS_axi_enq_channel_is_empty:1;		/* byte[ 0- 3] ,bit[10-10] */
+	int gpm_ppe_read_fifo_is_empty:1;		/* byte[ 0- 3] ,bit[11-11] */
+	int ppe_gpm_pl_write_fifo_is_empty:1;	/* byte[ 0- 3] ,bit[12-12] */
+	int ppe_gpm_qe_write_fifo_is_empty:1;	/* byte[ 0- 3] ,bit[13-13] */
+	int ppe_ru_read_fifo_is_empty:1;		/* byte[ 0- 3] ,bit[14-14] */
+	int ppe_ru_write_fifo_is_empty:1;		/* byte[ 0- 3] ,bit[15-15] */
+	int ru_ppe_read_fifo_is_empty:1;		/* byte[ 0- 3] ,bit[16-16] */
+	int dram_fifo_fsm_state_is_idle:1;		/* byte[ 0- 3] ,bit[17-17] */
+	int qeram_init_fsm_state_is_idle:1;		/* byte[ 0- 3] ,bit[18-18] */
+	int _reserved:13;						/* byte[ 0- 3] ,bit[19-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_ecc_error_cause {
+	int qm_dma_ecc_interrupt:1;				/* byte[ 0- 3] ,bit[ 0- 0] */
+	int ceram_mac_ecc_error:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int ceram_ppe_ecc_error:1;				/* byte[ 0- 3] ,bit[ 2- 2] */
+	int gpm_pl_ecc_error:1;					/* byte[ 0- 3] ,bit[ 3- 3] */
+	int gpm_qe_ecc_error:1;					/* byte[ 0- 3] ,bit[ 4- 4] */
+	int qeram_ecc_error:1;					/* byte[ 0- 3] ,bit[ 5- 5] */
+	int dram_fifo_ecc_error:1;				/* byte[ 0- 3] ,bit[ 6- 6] */
+	int _reserved:25;						/* byte[ 0- 3] ,bit[ 7-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_ecc_error_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int ceram_mac_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 1- 1] */
+	int ceram_ppe_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int gpm_pl_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int gpm_qe_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 4- 4] */
+	int qeram_ecc_error_mask:1;				/* byte[ 0- 3] ,bit[ 5- 5] */
+	int dram_fifo_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int _reserved_2:25;						/* byte[ 0- 3] ,bit[ 7-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_internal_error_cause {
+	int qm_dma_internal_error_interrupt:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int reg_file_error:1;							/* byte[ 0- 3] ,bit[ 1- 1] */
+	int dram_response_error:1;						/* byte[ 0- 3] ,bit[ 2- 2] */
+	int mac_enq_with_wrong_source_id_error:1;		/* byte[ 0- 3] ,bit[ 3- 3] */
+	int ppe_enq_with_wrong_source_id_error:1;		/* byte[ 0- 3] ,bit[ 4- 4] */
+	int _reserved:27;								/* byte[ 0- 3] ,bit[ 5-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_internal_error_mask {
+	int _reserved_1:1;								/* byte[ 0- 3] ,bit[ 0- 0] */
+	int reg_file_error_mask:1;						/* byte[ 0- 3] ,bit[ 1- 1] */
+	int dram_response_error_mask:1;					/* byte[ 0- 3] ,bit[ 2- 2] */
+	int mac_enq_with_wrong_source_id_error_mask:1;	/* byte[ 0- 3] ,bit[ 3- 3] */
+	int ppe_enq_with_wrong_source_id_error_mask:1;	/* byte[ 0- 3] ,bit[ 4- 4] */
+	int _reserved_2:27;								/* byte[ 0- 3] ,bit[ 5-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_ceram_mac {
+/*	uint128_t qece:89;							byte[ 0-11] ,bit[ 0-88] */
+	int ceram_mac_1:32;							/* byte[ 0-11] ,bit[ 0-31] */
+	int ceram_mac_2:32;							/* byte[ 0-11] ,bit[32-63] */
+	int ceram_mac_3:25;							/* byte[ 0-11] ,bit[64-88] */
+	int _reserved:7;							/* byte[ 0-11] ,bit[89-96] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_ceram_ppe {
+/*	uint128_t qece:131;							byte[ 0-11] ,bit[  0-130] */
+	int ceram_ppe_1:32;							/* byte[ 0-11] ,bit[  0- 31] */
+	int ceram_ppe_2:32;							/* byte[ 0-11] ,bit[ 32- 63] */
+	int ceram_ppe_3:32;							/* byte[ 0-11] ,bit[ 64- 95] */
+	int ceram_ppe_4:32;							/* byte[ 0-11] ,bit[ 96-128] */
+	int ceram_ppe_5:3;							/* byte[ 0-11] ,bit[128-130] */
+	int _reserved:29;							/* byte[ 0-11] ,bit[131-160] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_qeram {
+	int qeram:23;								/* byte[ 0- 3] ,bit[ 0-22] */
+	int _reserved:9;							/* byte[ 0- 3] ,bit[23-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dma_dram_fifo {
+/*	uint128_t dram_fifo:157;					byte[ 0-11] ,bit[  0-156] */
+	int dram_fifo_1:32;							/* byte[ 0-11] ,bit[  0- 31] */
+	int dram_fifo_2:32;							/* byte[ 0-11] ,bit[ 32- 63] */
+	int dram_fifo_3:32;							/* byte[ 0-11] ,bit[ 64- 95] */
+	int dram_fifo_4:32;							/* byte[ 0-11] ,bit[ 96-128] */
+	int dram_fifo_5:29;							/* byte[ 0-11] ,bit[128-156] */
+	int _reserved:3;							/* byte[ 0-11] ,bit[157-159] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+#define dma_ctl qm_dma_profile
+struct qm_dma_profile {
+	int                                           dma_address_base;
+	struct dma_Q_memory_allocation                tab_Q_memory_allocation[512/32];
+	struct dma_gpm_thresholds			          reg_gpm_thresholds;
+	struct dma_dram_thresholds			          reg_dram_thresholds;
+	struct dma_AXI_write_attributes_for_swf_mode  reg_AXI_write_attributes_for_swf_mode;
+	struct dma_AXI_write_attributes_for_rdma_mode reg_AXI_write_attributes_for_rdma_mode;
+	struct dma_AXI_write_attributes_for_hwf_qece  reg_AXI_write_attributes_for_hwf_qece;
+	struct dma_AXI_write_attributes_for_hwf_pyld  reg_AXI_write_attributes_for_hwf_pyld;
+	struct dma_DRAM_VMID				          reg_DRAM_VMID;
+	struct dma_idle_status                        reg_idle_status;
+	struct dma_ecc_error_cause                    reg_ecc_error_cause;
+	struct dma_ecc_error_mask                     reg_ecc_error_mask;
+	struct dma_internal_error_cause               reg_internal_error_cause;
+	struct dma_internal_error_mask                reg_internal_error_mask;
+	struct dma_ceram_mac                          tab_ceram_mac[72];
+	struct dma_ceram_ppe                          tab_ceram_ppe[18];
+	struct dma_qeram                              tab_qeram[512];
+	struct dma_dram_fifo                          tab_dram_fifo[128];
+	/ * environment * /
+	dma_handle hEnv;
+	int    magic;
+} __ATTRIBUTE_PACKED__;
+*/
+
+/* HW structures*/
+/* QL */
+struct ql_low_threshold {
+	int low_threshold:24;					/* byte[ 0- 3] ,bit[ 0-23] */
+	int _reserved:8;						/* byte[ 0- 3] ,bit[24-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_pause_threshold {
+	int pause_threshold:24;					/* byte[ 0- 3] ,bit[ 0-23] */
+	int _reserved:8;						/* byte[ 0- 3] ,bit[24-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_high_threshold {
+	int high_threshold:24;					/* byte[ 0- 3] ,bit[ 0-23] */
+	int _reserved:8;						/* byte[ 0- 3] ,bit[24-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_traffic_source {
+	int traffic_source:3;					/* byte[ 0- 3] ,bit[ 0- 2] */
+	int _reserved:29;						/* byte[ 0- 3] ,bit[ 3-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_ecc_error_cause {
+	int qm_ql_ecc_interrupt:1;				/* byte[ 0- 3] ,bit[ 0- 0] */
+	int qptr_ecc_error:1;					/* byte[ 0- 3] ,bit[ 1- 1] */
+	int qlen_ecc_error:1;					/* byte[ 0- 3] ,bit[ 2- 2] */
+	int _reserved:29;						/* byte[ 0- 3] ,bit[ 3-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_ecc_error_mask {
+	int _reserved_0:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int qptr_ecc_error_mask:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int qlen_ecc_error_mask:1;				/* byte[ 0- 3] ,bit[ 2- 2] */
+	int _reserved_1:29;						/* byte[ 0- 3] ,bit[ 3-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_internal_error_cause {
+	int qm_ql_internal_error_interrupt:1;	/* byte[ 0- 3] ,bit[ 0- 0] */
+	int reg_file_error:1;					/* byte[ 0- 3] ,bit[ 1- 1] */
+	int _reserved:30;						/* byte[ 0- 3] ,bit[ 2-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_internal_error_mask {
+	int _reserved_0:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int reg_file_error_mask:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int _reserved:30;						/* byte[ 0- 3] ,bit[ 2-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_nss_general_purpose {
+	int nss_general_purpose:32;				/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_qptr_entry {
+	int qptr0:3;							/* byte[ 0- 3] ,bit[ 0- 2] */
+	int qptr1:3;							/* byte[ 0- 3] ,bit[ 3- 5] */
+	int qptr2:3;							/* byte[ 0- 3] ,bit[ 6- 8] */
+	int qptr3:3;							/* byte[ 0- 3] ,bit[ 9-11] */
+	int qptr4:3;							/* byte[ 0- 3] ,bit[12-14] */
+	int qptr5:3;							/* byte[ 0- 3] ,bit[15-17] */
+	int qptr6:3;							/* byte[ 0- 3] ,bit[18-20] */
+	int qptr7:3;							/* byte[ 0- 3] ,bit[21-23] */
+	int _reserved:8;						/* byte[ 0- 3] ,bit[24-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_qptr {
+	struct ql_qptr_entry reg_qptr_entry;
+} __ATTRIBUTE_PACKED__;
+
+struct ql_ql_entry {
+	int ql:24;								/* byte[ 0- 3] ,bit[ 0-23] */
+	int qstatus:2;							/* byte[ 0- 3] ,bit[24-25] */
+	int _reserved:6;						/* byte[ 0- 3] ,bit[26-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct ql_qlen {
+	struct ql_ql_entry reg_ql_entry;
+} __ATTRIBUTE_PACKED__;
+
+/*
+#define ql_ctl qm_ql_profile
+struct qm_ql_profile {
+	int                            ql_address_base;
+	struct ql_low_threshold        reg_low_threshold;
+	struct ql_pause_threshold      reg_pause_threshold;
+	struct ql_high_threshold       reg_high_threshold;
+	struct ql_traffic_source       reg_traffic_source;
+	struct ql_ecc_error_cause      reg_ecc_error_cause;
+	struct ql_ecc_error_mask       reg_ecc_error_mask;
+	struct ql_internal_error_cause reg_internal_error_cause;
+	struct ql_internal_error_mask  reg_internal_error_mask;
+	struct ql_nss_general_purpose  reg_nss_general_purpose[8];
+	struct ql_qptr                 tab_qptr[256];
+	struct ql_qlen                 tab_qlen[512];
+	/ * environment * /
+	ql_handle hEnv;
+	int    magic;
+} __ATTRIBUTE_PACKED__;
+*/
+
+/* PFE */
+struct pfe_qece_dram_base_address_hi {
+	int qece_dram_base_address_hi:8;		/* byte[ 0- 3] ,bit[ 0- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_pyld_dram_base_address_hi {
+	int pyld_dram_base_address_hi:8;		/* byte[ 0- 3] ,bit[ 0- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_qece_dram_base_address_lo {
+	int qece_dram_base_address_low:32;		/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_pyld_dram_base_address_lo {
+	int pyld_dram_base_address_low:32;		/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_QM_VMID {
+	int VMID:8;								/* byte[ 0- 3] ,bit[ 0- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+struct pfe_port_ppe {
+	int port_ppe:16;						*//* byte[ 0- 3] ,bit[ 0-15] *//*
+	int _reserved:16;						*//* byte[ 0- 3] ,bit[16-31] *//*
+} __ATTRIBUTE_PACKED__;
+*/
+struct pfe_port_flush {
+	int port_flush:16;						/* byte[ 0- 3] ,bit[ 0-15] */
+	int _reserved:16;						/* byte[ 0- 3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_AXI_read_attributes_for_swf_mode {
+	int swf_ardomain:2;						/* byte[ 0- 3] ,bit[ 0- 1] */
+	int swf_arcache:4;						/* byte[ 0- 3] ,bit[ 2- 5] */
+	int swf_arqos:2;						/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_AXI_read_attributes_for_rdma_mode {
+	int rdma_ardomain:2;					/* byte[ 0- 3] ,bit[ 0- 1] */
+	int rdma_arcache:4;						/* byte[ 0- 3] ,bit[ 2- 5] */
+	int rdma_arqos:2;						/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_AXI_read_attributes_for_hwf_qece {
+	int qece_ardomain:2;					/* byte[ 0- 3] ,bit[ 0- 1] */
+	int qece_arcache:4;						/* byte[ 0- 3] ,bit[ 2- 5] */
+	int qece_arqos:2;						/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_AXI_read_attributes_for_hwf_pyld {
+	int pyld_ardomain:2;					/* byte[ 0- 3] ,bit[ 0- 1] */
+	int pyld_arcache:4;						/* byte[ 0- 3] ,bit[ 2- 5] */
+	int pyld_arqos:2;						/* byte[ 0- 3] ,bit[ 6- 7] */
+	int _reserved:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_ecc_error_cause {
+	int qm_pfe_ecc_interrupt:1;				/* byte[ 0- 3] ,bit[ 0- 0] */
+	int qflush_ecc_error:1;					/* byte[ 0- 3] ,bit[ 1- 1] */
+	int qece_ecc_error:1;					/* byte[ 0- 3] ,bit[ 2- 2] */
+	int macsdata_ecc_error:1;				/* byte[ 0- 3] ,bit[ 3- 3] */
+	int _reserved:28;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_ecc_error_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int qflush_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 1- 1] */
+	int qece_ecc_error_mask:1;				/* byte[ 0- 3] ,bit[ 2- 2] */
+	int macsdata_ecc_error_mask:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int _reserved_2:28;						/* byte[ 0- 3] ,bit[ 4-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_internal_error_cause {
+	int qm_pfe_internal_error_interrupt:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int reg_file_error:1;							/* byte[ 0- 3] ,bit[ 1- 1] */
+	int dram_response_error:1;						/* byte[ 0- 3] ,bit[ 2- 2] */
+	int last_port_not_last_queue_error:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int gpm_cl_error:1;								/* byte[ 0- 3] ,bit[ 4- 4] */
+	int deq_mode_error:1;							/* byte[ 0- 3] ,bit[ 5- 5] */
+	int no_descriptor_mode_for_dram_q_error:1;		/* byte[ 0- 3] ,bit[ 6- 6] */
+	int pckt_len_grtr_cfh_len_plus_descr_error:1;	/* byte[ 0- 3] ,bit[ 7- 7] */
+	int _reserved:24;								/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_internal_error_mask {
+	int _reserved_1:1;                                  /* byte[ 0- 3] ,bit[ 0- 0] */
+	int reg_file_error_mask:1;							/* byte[ 0- 3] ,bit[ 1- 1] */
+	int dram_response_error_mask:1;						/* byte[ 0- 3] ,bit[ 2- 2] */
+	int last_port_not_last_queue_error_mask:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int gpm_cl_error_mask:1;							/* byte[ 0- 3] ,bit[ 4- 4] */
+	int deq_mode_error_mask:1;							/* byte[ 0- 3] ,bit[ 5- 5] */
+	int no_descriptor_mode_for_dram_q_error_mask:1;		/* byte[ 0- 3] ,bit[ 6- 6] */
+	int pckt_len_grtr_cfh_len_plus_descr_error_mask:1;	/* byte[ 0- 3] ,bit[ 7- 7] */
+	int _reserved_2:24;                                 /* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_idle_status {
+	int axi_outstanding_fifo_empty:1;		/* byte[ 0- 3] ,bit[ 0-31] */
+	int dram_to_macs_fifo_empty:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int bm_release_fifo_empty:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int _reserved:29;						/* byte[ 0- 3] ,bit[ 4-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_queue_flush {
+	int queue_flush_bit_per_q:32;			/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct pfe_queue_qece {
+/*	uint128_t qece:128;						 byte[ 0-15] ,bit[ 0-127] */
+	uint32_t qece_1:32;						/* byte[ 0-15] ,bit[ 0-31] */
+	uint32_t qece_2:32;						/* byte[ 0-15] ,bit[32-63] */
+	uint32_t qece_3:32;						/* byte[ 0-15] ,bit[64-95] */
+	uint32_t qece_4:32;						/* byte[ 0-15] ,bit[96-127] */
+/*	int _reserved:32;						 byte[ 0- 3] ,bit[ 0-31]  DUMMY*/
+} __ATTRIBUTE_PACKED__;
+
+/*
+#define pfe_ctl qm_pfe_profile
+struct qm_pfe_profile {
+	int                                          pfe_address_base;
+	struct pfe_qece_dram_base_address_hi         reg_qece_dram_base_address_hi;
+	struct pfe_pyld_dram_base_address_hi         reg_pyld_dram_base_address_hi;
+	struct pfe_qece_dram_base_address_lo         reg_qece_dram_base_address_lo;
+	struct pfe_pyld_dram_base_address_lo         reg_pyld_dram_base_address_lo;
+	struct pfe_QM_VMID                           reg_QM_VMID;
+/ *	struct pfe_port_ppe                          reg_port_ppe; * /
+	struct pfe_port_flush                        reg_port_flush;
+	struct pfe_AXI_read_attributes_for_swf_mode  reg_AXI_read_attributes_for_swf_mode;
+	struct pfe_AXI_read_attributes_for_rdma_mode reg_AXI_read_attributes_for_rdma_mode;
+	struct pfe_AXI_read_attributes_for_hwf_qece  reg_AXI_read_attributes_for_hwf_qece;
+	struct pfe_AXI_read_attributes_for_hwf_pyld  reg_AXI_read_attributes_for_hwf_pyld;
+	struct pfe_ecc_error_cause                   reg_ecc_error_cause;
+	struct pfe_ecc_error_mask                    reg_ecc_error_mask;
+	struct pfe_internal_error_cause              reg_internal_error_cause;
+	struct pfe_internal_error_mask               reg_internal_error_mask;
+	struct pfe_idle_status                       reg_idle_status;
+	struct pfe_queue_flush                       tab_queue_flush[64];
+	struct pfe_queue_qece                        tab_queue_qece[2048];
+	/ * environment * /
+	pfe_handle hEnv;
+	int    magic;
+} __ATTRIBUTE_PACKED__;
+*/
+
+/* REORDER */
+struct reorder_ru_pool {
+	int sid_limit:32;					/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct reorder_ru_class_head {
+	int ru_class_head:12;				/* byte[ 0- 3] ,bit[ 0-11] */
+	int _reserved:20;					/* byte[ 0- 3] ,bit[12-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct reorder_ru_host_cmd {
+	int ru_host_sid:12;					/* byte[ 0- 3] ,bit[ 0-11] */
+	int _reserved_1:4;					/* byte[ 0- 3] ,bit[12-15] */
+	int ru_host_class:7;				/* byte[ 0- 3] ,bit[16-22] */
+	int _reserved_2:1;					/* byte[ 0- 3] ,bit[23-23] */
+	int ru_host_task:3;					/* byte[ 0- 3] ,bit[24-26] */
+	int _reserved_3:4;					/* byte[ 0- 3] ,bit[27-30] */
+	int ru_host_exec:1;					/* byte[ 0- 3] ,bit[31-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct reorder_ru_task_permission {
+	int _reserved_1:31;					/* byte[ 0- 3] ,bit[ 0-30] */
+	int ru_host_permitted:1;			/* byte[ 0- 3] ,bit[31-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct reorder_ru_port2class {
+	int ru_class:6;						/* byte[ 0- 3] ,bit[ 0- 5] */
+	int ru_pool:1;						/* byte[ 0- 3] ,bit[ 6- 6] */
+	int _reserved_1:25;					/* byte[ 0- 3] ,bit[ 7-31] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+#define reorder_ctl qm_reorder_profile
+struct qm_reorder_profile {
+	int                               reorder_address_base;
+	struct reorder_ru_pool            reg_ru_pool;
+	struct reorder_ru_class_head      reg_ru_class_head;
+/ *	struct reorder_qlen               tab_qlen[512]; * /
+	struct reorder_ru_host_cmd        reg_ru_host_cmd;
+	struct reorder_ru_task_permission reg_ru_task_permission;
+	struct reorder_ru_port2class      reg_ru_port2class;
+	/ * environment* /
+	ql_handle hEnv;
+	int    magic;
+} __ATTRIBUTE_PACKED__;
+*/
+
+/* GPM */
+struct gpm_gpm_pl {
+/*	int gpm_pl:512;						 byte[ 0-63] ,bit[  0-511] */
+	int gpm_pl_00:32;					/* byte[ 0-63] ,bit[  0- 31] */
+	int gpm_pl_01:32;					/* byte[ 0-63] ,bit[ 32- 63] */
+	int gpm_pl_02:32;					/* byte[ 0-63] ,bit[ 64- 95] */
+	int gpm_pl_03:32;					/* byte[ 0-63] ,bit[ 96-127] */
+	int gpm_pl_04:32;					/* byte[ 0-63] ,bit[128-159] */
+	int gpm_pl_05:32;					/* byte[ 0-63] ,bit[160-191] */
+	int gpm_pl_06:32;					/* byte[ 0-63] ,bit[192-223] */
+	int gpm_pl_07:32;					/* byte[ 0-63] ,bit[224-255] */
+	int gpm_pl_08:32;					/* byte[ 0-63] ,bit[256-287] */
+	int gpm_pl_09:32;					/* byte[ 0-63] ,bit[288-319] */
+	int gpm_pl_10:32;					/* byte[ 0-63] ,bit[320-351] */
+	int gpm_pl_11:32;					/* byte[ 0-63] ,bit[352-383] */
+	int gpm_pl_12:32;					/* byte[ 0-63] ,bit[384-415] */
+	int gpm_pl_13:32;					/* byte[ 0-63] ,bit[416-447] */
+	int gpm_pl_14:32;					/* byte[ 0-63] ,bit[448-479] */
+	int gpm_pl_15:32;					/* byte[ 0-63] ,bit[480-511] */
+} __ATTRIBUTE_PACKED__;
+
+struct gpm_gpm_qe {
+/*	int gpm_qe:128;						 byte[ 0- 7] ,bit[  0-128] */
+	int gpm_qe_00:32;					/* byte[ 0- 7] ,bit[  0- 31] */
+	int gpm_qe_01:32;					/* byte[ 0- 7] ,bit[ 32- 63] */
+	int gpm_qe_02:32;					/* byte[ 0- 7] ,bit[ 64- 95] */
+	int gpm_qe_03:32;					/* byte[ 0- 7] ,bit[ 96-127] */
+} __ATTRIBUTE_PACKED__;
+
+/*
+#define gpm_ctl qm_gpm_profile
+struct qm_gpm_profile {
+	int                                   gpm_address_base;
+	struct gpm_gpm_pl                     tab_gpm_pl[10240];
+	struct gpm_gpm_qe                     tab_gpm_qe[5120];
+	/ * environment * /
+	gpm_handle hEnv;
+	int    magic;
+} __ATTRIBUTE_PACKED__;
+*/
+
+/* DQF */
+struct dqf_Data_FIFO_params_p {
+	int data_fifo_base_p:10;			/* byte[ 0- 3] ,bit[ 0- 9] */
+	int _reserved_1:6;					/* byte[ 0- 3] ,bit[10-15] */
+	int data_fifo_depth_p:10;			/* byte[ 0- 3] ,bit[16-25] */
+	int _reserved_2:6;					/* byte[ 0- 3] ,bit[26-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_Credit_Threshold_p {
+	int Credit_Threshold_p:10;			/* byte[ 0- 3] ,bit[ 0- 9] */
+	int _reserved_1:22;					/* byte[ 0- 3] ,bit[10-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_PPC_port_map_p {
+	int ppc_port_map_p:2;				/* byte[ 0- 3] ,bit[ 0- 1] */
+	int _reserved_1:30;					/* byte[ 0- 3] ,bit[ 2-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_intr_cause {
+	int dqf_intr_sum:1;					/* byte[ 0- 3] ,bit[ 0- 0] */
+	int dqf_ser_sum:1;					/* byte[ 0- 3] ,bit[ 1- 1] */
+	int write_to_full_err_sum:1;		/* byte[ 0- 3] ,bit[ 2- 2] */
+	int read_from_empty_err_sum:1;		/* byte[ 0- 3] ,bit[ 3- 3] */
+	int wrong_axi_rd_err_sum:1;			/* byte[ 0- 3] ,bit[ 4- 4] */
+	int dqf_cs_calc_err:1;				/* byte[ 0- 3] ,bit[ 5- 5] */
+	int dqf_cs_inp_ctrl_err:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int dqf_rf_error:1;					/* byte[ 0- 3] ,bit[ 7- 7] */
+	int _reserved_1:24;					/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_intr_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int dqf_ser_sum_mask:1;					/* byte[ 0- 3] ,bit[ 1- 1] */
+	int write_to_full_error_sum_mask:1;		/* byte[ 0- 3] ,bit[ 2- 2] */
+	int read_from_empty_error_sum_mask:1;	/* byte[ 0- 3] ,bit[ 3- 3] */
+	int wrong_axi_rd_error_sum_mask:1;		/* byte[ 0- 3] ,bit[ 4- 4] */
+	int dqf_cs_calc_err_mask:1;				/* byte[ 0- 3] ,bit[ 5- 5] */
+	int dqf_cs_inp_ctrl_err_mask:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int dqf_rf_error_mask:1;				/* byte[ 0- 3] ,bit[ 7- 7] */
+	int _reserved_2:24;						/* byte[ 0- 3] ,bit[ 8-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_misc_error_intr_cause {
+	int misc_intr_sum:1;					/* byte[ 0- 3] ,bit[ 0- 0] */
+	int dqf_cs_calc_err:1;					/* byte[ 0- 3] ,bit[ 1- 1] */
+	int dqf_cs_inp_ctrl_err:1;				/* byte[ 0- 3] ,bit[ 2- 2] */
+	int dqf_rf_error:1;						/* byte[ 0- 3] ,bit[ 3- 3] */
+	int _reserved_1:28;						/* byte[ 0- 3] ,bit[ 4-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_misc_error_intr_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int dqf_cs_calc_err_mask:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int dqf_cs_inp_ctrl_err_mask:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int dqf_rf_error_mask:1;				/* byte[ 0- 3] ,bit[ 3- 3] */
+	int _reserved_2:28;						/* byte[ 0- 3] ,bit[ 4-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_ser_summary_intr_cause {
+	int ser_summary_intr_sum:1;				/* byte[ 0- 3] ,bit[ 0- 0] */
+	int ppe_data_ser_error_0:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int ppe_data_ser_error_1:1;				/* byte[ 0- 3] ,bit[ 2- 2] */
+	int ppe_data_ser_error_2:1;				/* byte[ 0- 3] ,bit[ 3- 3] */
+	int ppe_data_ser_error_3:1;				/* byte[ 0- 3] ,bit[ 4- 4] */
+	int ppe_data_ser_error_4:1;				/* byte[ 0- 3] ,bit[ 5- 5] */
+	int ppe_data_ser_error_5:1;				/* byte[ 0- 3] ,bit[ 6- 6] */
+	int ppe_data_ser_error_6:1;				/* byte[ 0- 3] ,bit[ 7- 7] */
+	int ppe_data_ser_error_7:1;				/* byte[ 0- 3] ,bit[ 8- 8] */
+	int ppe_data_ser_error_8:1;				/* byte[ 0- 3] ,bit[ 9- 9] */
+	int macs_csptr_ser_error_0:1;			/* byte[ 0- 3] ,bit[10-10] */
+	int macs_csptr_ser_error_1:1;			/* byte[ 0- 3] ,bit[11-11] */
+	int macs_csres_ser_error_0:1;			/* byte[ 0- 3] ,bit[12-12] */
+	int macs_csres_ser_error_1:1;			/* byte[ 0- 3] ,bit[13-13] */
+	int macs_data_ser_error:1;				/* byte[ 0- 3] ,bit[14-14] */
+	int macs_desc_ser_error:1;				/* byte[ 0- 3] ,bit[15-15] */
+	int macs_d2cs_ser_error:1;				/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_1:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_ser_summary_intr_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int ppe_data_ser_error_0_mask:1;		/* byte[ 0- 3] ,bit[ 1- 1] */
+	int ppe_data_ser_error_1_mask:1;		/* byte[ 0- 3] ,bit[ 2- 2] */
+	int ppe_data_ser_error_2_mask:1;		/* byte[ 0- 3] ,bit[ 3- 3] */
+	int ppe_data_ser_error_3_mask:1;		/* byte[ 0- 3] ,bit[ 4- 4] */
+	int ppe_data_ser_error_4_mask:1;		/* byte[ 0- 3] ,bit[ 5- 5] */
+	int ppe_data_ser_error_5_mask:1;		/* byte[ 0- 3] ,bit[ 6- 6] */
+	int ppe_data_ser_error_6_mask:1;		/* byte[ 0- 3] ,bit[ 7- 7] */
+	int ppe_data_ser_error_7_mask:1;		/* byte[ 0- 3] ,bit[ 8- 8] */
+	int ppe_data_ser_error_8_mask:1;		/* byte[ 0- 3] ,bit[ 9- 9] */
+	int macs_csptr_ser_error_0_mask:1;		/* byte[ 0- 3] ,bit[10-10] */
+	int macs_csptr_ser_error_1_mask:1;		/* byte[ 0- 3] ,bit[11-11] */
+	int macs_csres_ser_error_0_mask:1;		/* byte[ 0- 3] ,bit[12-12] */
+	int macs_csres_ser_error_1_mask:1;		/* byte[ 0- 3] ,bit[13-13] */
+	int macs_data_ser_error_mask:1;			/* byte[ 0- 3] ,bit[14-14] */
+	int macs_desc_ser_error_mask:1;			/* byte[ 0- 3] ,bit[15-15] */
+	int macs_d2cs_ser_error_mask:1;			/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_2:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_write_to_full_error_intr_cause {
+	int write_to_full_intr_sum:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int write_to_full_error_p0:1;			/* byte[ 0- 3] ,bit[ 1- 1] */
+	int write_to_full_error_p1:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int write_to_full_error_p2:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int write_to_full_error_p3:1;			/* byte[ 0- 3] ,bit[ 4- 4] */
+	int write_to_full_error_p4:1;			/* byte[ 0- 3] ,bit[ 5- 5] */
+	int write_to_full_error_p5:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int write_to_full_error_p6:1;			/* byte[ 0- 3] ,bit[ 7- 7] */
+	int write_to_full_error_p7:1;			/* byte[ 0- 3] ,bit[ 8- 8] */
+	int write_to_full_error_p8:1;			/* byte[ 0- 3] ,bit[ 9- 9] */
+	int write_to_full_error_p9:1;			/* byte[ 0- 3] ,bit[10-10] */
+	int write_to_full_error_p10:1;			/* byte[ 0- 3] ,bit[11-11] */
+	int write_to_full_error_p11:1;			/* byte[ 0- 3] ,bit[12-12] */
+	int write_to_full_error_p12:1;			/* byte[ 0- 3] ,bit[13-13] */
+	int write_to_full_error_p13:1;			/* byte[ 0- 3] ,bit[14-14] */
+	int write_to_full_error_p14:1;			/* byte[ 0- 3] ,bit[15-15] */
+	int write_to_full_error_p15:1;			/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_1:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_write_to_full_error_intr_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int write_to_full_error_mask_p0:1;		/* byte[ 0- 3] ,bit[ 1- 1] */
+	int write_to_full_error_mask_p1:1;		/* byte[ 0- 3] ,bit[ 2- 2] */
+	int write_to_full_error_mask_p2:1;		/* byte[ 0- 3] ,bit[ 3- 3] */
+	int write_to_full_error_mask_p3:1;		/* byte[ 0- 3] ,bit[ 4- 4] */
+	int write_to_full_error_mask_p4:1;		/* byte[ 0- 3] ,bit[ 5- 5] */
+	int write_to_full_error_mask_p5:1;		/* byte[ 0- 3] ,bit[ 6- 6] */
+	int write_to_full_error_mask_p6:1;		/* byte[ 0- 3] ,bit[ 7- 7] */
+	int write_to_full_error_mask_p7:1;		/* byte[ 0- 3] ,bit[ 8- 8] */
+	int write_to_full_error_mask_p8:1;		/* byte[ 0- 3] ,bit[ 9- 9] */
+	int write_to_full_error_mask_p9:1;		/* byte[ 0- 3] ,bit[10-10] */
+	int write_to_full_error_mask_p10:1;		/* byte[ 0- 3] ,bit[11-11] */
+	int write_to_full_error_mask_p11:1;		/* byte[ 0- 3] ,bit[12-12] */
+	int write_to_full_error_mask_p12:1;		/* byte[ 0- 3] ,bit[13-13] */
+	int write_to_full_error_mask_p13:1;		/* byte[ 0- 3] ,bit[14-14] */
+	int write_to_full_error_mask_p14:1;		/* byte[ 0- 3] ,bit[15-15] */
+	int write_to_full_error_mask_p15:1;		/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_2:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_read_from_empty_error_intr_cause {
+	int read_from_empty_intr_sum:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int read_from_empty_error_p0:1;			/* byte[ 0- 3] ,bit[ 1- 1] */
+	int read_from_empty_error_p1:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int read_from_empty_error_p2:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int read_from_empty_error_p3:1;			/* byte[ 0- 3] ,bit[ 4- 4] */
+	int read_from_empty_error_p4:1;			/* byte[ 0- 3] ,bit[ 5- 5] */
+	int read_from_empty_error_p5:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int read_from_empty_error_p6:1;			/* byte[ 0- 3] ,bit[ 7- 7] */
+	int read_from_empty_error_p7:1;			/* byte[ 0- 3] ,bit[ 8- 8] */
+	int read_from_empty_error_p8:1;			/* byte[ 0- 3] ,bit[ 9- 9] */
+	int read_from_empty_error_p9:1;			/* byte[ 0- 3] ,bit[10-10] */
+	int read_from_empty_error_p10:1;		/* byte[ 0- 3] ,bit[11-11] */
+	int read_from_empty_error_p11:1;		/* byte[ 0- 3] ,bit[12-12] */
+	int read_from_empty_error_p12:1;		/* byte[ 0- 3] ,bit[13-13] */
+	int read_from_empty_error_p13:1;		/* byte[ 0- 3] ,bit[14-14] */
+	int read_from_empty_error_p14:1;		/* byte[ 0- 3] ,bit[15-15] */
+	int read_from_empty_error_p15:1;		/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_1:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_read_from_empty_error_intr_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int read_from_empty_error_mask_p0:1;	/* byte[ 0- 3] ,bit[ 1- 1] */
+	int read_from_empty_error_mask_p1:1;	/* byte[ 0- 3] ,bit[ 2- 2] */
+	int read_from_empty_error_mask_p2:1;	/* byte[ 0- 3] ,bit[ 3- 3] */
+	int read_from_empty_error_mask_p3:1;	/* byte[ 0- 3] ,bit[ 4- 4] */
+	int read_from_empty_error_mask_p4:1;	/* byte[ 0- 3] ,bit[ 5- 5] */
+	int read_from_empty_error_mask_p5:1;	/* byte[ 0- 3] ,bit[ 6- 6] */
+	int read_from_empty_error_mask_p6:1;	/* byte[ 0- 3] ,bit[ 7- 7] */
+	int read_from_empty_error_mask_p7:1;	/* byte[ 0- 3] ,bit[ 8- 8] */
+	int read_from_empty_error_mask_p8:1;	/* byte[ 0- 3] ,bit[ 9- 9] */
+	int read_from_empty_error_mask_p9:1;	/* byte[ 0- 3] ,bit[10-10] */
+	int read_from_empty_error_mask_p10:1;	/* byte[ 0- 3] ,bit[11-11] */
+	int read_from_empty_error_mask_p11:1;	/* byte[ 0- 3] ,bit[12-12] */
+	int read_from_empty_error_mask_p12:1;	/* byte[ 0- 3] ,bit[13-13] */
+	int read_from_empty_error_mask_p13:1;	/* byte[ 0- 3] ,bit[14-14] */
+	int read_from_empty_error_mask_p14:1;	/* byte[ 0- 3] ,bit[15-15] */
+	int read_from_empty_error_mask_p15:1;	/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_2:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_wrong_axi_rd_error_intr_cause {
+	int wrong_axi_rd_intr_sum:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int wrong_axi_rd_error_p0:1;			/* byte[ 0- 3] ,bit[ 1- 1] */
+	int wrong_axi_rd_error_p1:1;			/* byte[ 0- 3] ,bit[ 2- 2] */
+	int wrong_axi_rd_error_p2:1;			/* byte[ 0- 3] ,bit[ 3- 3] */
+	int wrong_axi_rd_error_p3:1;			/* byte[ 0- 3] ,bit[ 4- 4] */
+	int wrong_axi_rd_error_p4:1;			/* byte[ 0- 3] ,bit[ 5- 5] */
+	int wrong_axi_rd_error_p5:1;			/* byte[ 0- 3] ,bit[ 6- 6] */
+	int wrong_axi_rd_error_p6:1;			/* byte[ 0- 3] ,bit[ 7- 7] */
+	int wrong_axi_rd_error_p7:1;			/* byte[ 0- 3] ,bit[ 8- 8] */
+	int wrong_axi_rd_error_p8:1;			/* byte[ 0- 3] ,bit[ 9- 9] */
+	int wrong_axi_rd_error_p9:1;			/* byte[ 0- 3] ,bit[10-10] */
+	int wrong_axi_rd_error_p10:1;			/* byte[ 0- 3] ,bit[11-11] */
+	int wrong_axi_rd_error_p11:1;			/* byte[ 0- 3] ,bit[12-12] */
+	int wrong_axi_rd_error_p12:1;			/* byte[ 0- 3] ,bit[13-13] */
+	int wrong_axi_rd_error_p13:1;			/* byte[ 0- 3] ,bit[14-14] */
+	int wrong_axi_rd_error_p14:1;			/* byte[ 0- 3] ,bit[15-15] */
+	int wrong_axi_rd_error_p15:1;			/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_1:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_wrong_axi_rd_error_intr_mask {
+	int _reserved_1:1;						/* byte[ 0- 3] ,bit[ 0- 0] */
+	int wrong_axi_rd_error_mask_p0:1;		/* byte[ 0- 3] ,bit[ 1- 1] */
+	int wrong_axi_rd_error_mask_p1:1;		/* byte[ 0- 3] ,bit[ 2- 2] */
+	int wrong_axi_rd_error_mask_p2:1;		/* byte[ 0- 3] ,bit[ 3- 3] */
+	int wrong_axi_rd_error_mask_p3:1;		/* byte[ 0- 3] ,bit[ 4- 4] */
+	int wrong_axi_rd_error_mask_p4:1;		/* byte[ 0- 3] ,bit[ 5- 5] */
+	int wrong_axi_rd_error_mask_p5:1;		/* byte[ 0- 3] ,bit[ 6- 6] */
+	int wrong_axi_rd_error_mask_p6:1;		/* byte[ 0- 3] ,bit[ 7- 7] */
+	int wrong_axi_rd_error_mask_p7:1;		/* byte[ 0- 3] ,bit[ 8- 8] */
+	int wrong_axi_rd_error_mask_p8:1;		/* byte[ 0- 3] ,bit[ 9- 9] */
+	int wrong_axi_rd_error_mask_p9:1;		/* byte[ 0- 3] ,bit[10-10] */
+	int wrong_axi_rd_error_mask_p10:1;		/* byte[ 0- 3] ,bit[11-11] */
+	int wrong_axi_rd_error_mask_p11:1;		/* byte[ 0- 3] ,bit[12-12] */
+	int wrong_axi_rd_error_mask_p12:1;		/* byte[ 0- 3] ,bit[13-13] */
+	int wrong_axi_rd_error_mask_p13:1;		/* byte[ 0- 3] ,bit[14-14] */
+	int wrong_axi_rd_error_mask_p14:1;		/* byte[ 0- 3] ,bit[15-15] */
+	int wrong_axi_rd_error_mask_p15:1;		/* byte[ 0- 3] ,bit[16-16] */
+	int _reserved_2:15;						/* byte[ 0- 3] ,bit[17-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_mg2mem_req_addr_ctrl {
+	int mg2mem_req_addr:10;				/* byte[ 0- 3] ,bit[ 0- 9] */
+	int mg2mem_req_mem_sel:1;			/* byte[ 0- 3] ,bit[10-10] */
+	int _reserved_1:21;					/* byte[ 0- 3] ,bit[21-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_mem2mg_resp_status {
+	int mem2mg_resp_ready:1;			/* byte[ 0- 3] ,bit[ 0- 0] */
+	int mem2mg_resp_sop:1;				/* byte[ 0- 3] ,bit[ 1- 1] */
+	int mem2mg_resp_eop:1;				/* byte[ 0- 3] ,bit[ 2- 2] */
+	int _reserved_1:29;					/* byte[ 0- 3] ,bit[ 3-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_mem2mg_resp_data_hh {
+	int mem2mg_resp_data_hh:32;			/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_mem2mg_resp_data_hl {
+	int mem2mg_resp_data_hl:32;			/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_mem2mg_resp_data_lh {
+	int mem2mg_resp_data_lh:32;			/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_mem2mg_resp_data_ll {
+	int mem2mg_resp_data_ll:32;			/* byte[ 0- 3] ,bit[ 0-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_data_fifo_pointers_p {
+	int data_fifo_wr_ptr_p:11;			/* byte[ 0- 3] ,bit[ 0-10] */
+	int _reserved_1:5;					/* byte[ 0- 3] ,bit[11-15] */
+	int data_fifo_rd_ptr_p:11;			/* byte[ 0- 3] ,bit[16-26] */
+	int _reserved_2:5;					/* byte[ 0- 3] ,bit[27-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct l3_result {
+	int l3_res:16;						/* byte[ 0- 3] ,bit[ 0-15] */
+	int _reserved_1:16;					/* byte[ 0- 3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_macs_l3_res {
+	struct l3_result reg_l3_result;
+} __ATTRIBUTE_PACKED__;
+
+struct l4_result {
+	int l3_res:16;						/* byte[ 0- 3] ,bit[ 0-15] */
+	int _reserved_1:16;					/* byte[ 0- 3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_macs_l4_res {
+	struct l4_result reg_l4_result;
+} __ATTRIBUTE_PACKED__;
+
+struct l3_pointer {
+	int l3_ptr:16;						/* byte[ 0- 3] ,bit[ 0-15] */
+	int _reserved_1:16;					/* byte[ 0- 3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_macs_l3_ptr {
+	struct l3_pointer reg_l3_pointer;
+} __ATTRIBUTE_PACKED__;
+
+struct l4_pointer {
+	int l4_ptr:16;						/* byte[ 0- 3] ,bit[ 0-15] */
+	int _reserved_1:16;					/* byte[ 0- 3] ,bit[16-31] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_macs_l4_ptr {
+	struct l4_pointer reg_l4_pointer;
+} __ATTRIBUTE_PACKED__;
+
+struct desc {
+	int macs_desc_1:32;					/* byte[ 0- 7] ,bit[ 0-31] */
+	int macs_desc_2:2;					/* byte[ 0- 7] ,bit[32-33] */
+	int _reserved_1:30;					/* byte[ 0- 7] ,bit[34-63] */
+} __ATTRIBUTE_PACKED__;
+
+struct dqf_dqf_macs_desc {
+	struct desc reg_desc;
+} __ATTRIBUTE_PACKED__;
+
+/*
+#define dqf_ctl qm_dqf_profile
+struct qm_dqf_profile {
+	int                                         dqf_address_base;
+	struct dqf_Data_FIFO_params_p               vec_Data_FIFO_params_p[16];
+	struct dqf_Credit_Threshold_p               vec_Credit_Threshold_p[16];
+	struct dqf_PPC_port_map_p                   vec_PPC_port_map_p[16];
+	struct dqf_data_fifo_pointers_p             vec_data_fifo_pointers_p[16];
+	struct dqf_dqf_intr_cause                   reg_dqf_intr_cause;
+	struct dqf_dqf_intr_mask                    reg_dqf_intr_mask;
+	struct dqf_misc_error_intr_cause            reg_misc_error_intr_cause;
+	struct dqf_misc_error_intr_mask             reg_misc_error_intr_mask;
+	struct dqf_dqf_ser_summary_intr_cause       reg_dqf_ser_summary_intr_cause;
+	struct dqf_dqf_ser_summary_intr_mask        reg_dqf_ser_summary_intr_mask;
+	struct dqf_write_to_full_error_intr_cause   reg_write_to_full_error_intr_cause;
+	struct dqf_write_to_full_error_intr_mask    reg_write_to_full_error_intr_mask;
+	struct dqf_read_from_empty_error_intr_cause reg_read_from_empty_error_intr_cause;
+	struct dqf_read_from_empty_error_intr_mask  reg_read_from_empty_error_intr_mask;
+	struct dqf_wrong_axi_rd_error_intr_cause    reg_wrong_axi_rd_error_intr_cause;
+	struct dqf_wrong_axi_rd_error_intr_mask     reg_wrong_axi_rd_error_intr_mask;
+	struct dqf_mg2mem_req_addr_ctrl             reg_mg2mem_req_addr_ctrl;
+	struct dqf_mem2mg_resp_status               reg_mem2mg_resp_status;
+	struct dqf_mem2mg_resp_data_hh              reg_mem2mg_resp_data_hh;
+	struct dqf_mem2mg_resp_data_hl              reg_mem2mg_resp_data_hl;
+	struct dqf_mem2mg_resp_data_lh              reg_mem2mg_resp_data_lh;
+	struct dqf_mem2mg_resp_data_ll              reg_mem2mg_resp_data_ll;
+	struct dqf_dqf_macs_l3_res                  tab_dqf_macs_l3_res[256];
+	struct dqf_dqf_macs_l4_res                  tab_dqf_macs_l4_res[256];
+	struct dqf_dqf_macs_l3_ptr                  tab_dqf_macs_l3_ptr[256];
+	struct dqf_dqf_macs_l4_ptr                  tab_dqf_macs_l4_ptr[256];
+	struct dqf_dqf_macs_desc                    tab_dqf_macs_desc[16];
+	/ * environment* /
+	dqf_handle hEnv;
+	int    magic;
+} __ATTRIBUTE_PACKED__;
+*/
+
+/* QM General */
+
+/*#define qm_register_write_new */
+/*#define qm_register_read_new */
+/*
+#define bm_register_write     qm_register_write
+#define bm_register_read      qm_register_read
+*/
+#define pfe_register_write    qm_register_write
+#define pfe_register_read     qm_register_read
+
+#define dma_register_write    qm_register_write
+#define dma_register_read     qm_register_read
+
+
+/*#define      qm_alias qm_alias*/
+#define      ql_alias qm_alias
+#define     pfe_alias qm_alias
+#define     dqf_alias qm_alias
+#define     dma_alias qm_alias
+/*#define      bm_alias qm_alias*/
+#define   sched_alias qm_alias
+#define    drop_alias qm_alias
+#define reorder_alias qm_alias
+#define     gpm_alias qm_alias
+
+struct qm_alias {
+	int base;
+
+	struct {
+		int base;
+		int qptr;
+		int low_threshold;
+		int pause_threshold;
+		int high_threshold;
+		int traffic_source;
+		int ECC_error_cause;
+		int ECC_error_mask;
+		int Internal_error_cause;
+		int internal_error_mask;
+		int nss_general_purpose;
+		int qlen;
+	} ql;
+
+	struct {
+		int base;
+		int qece_dram_base_address_hi;
+		int pyld_dram_base_address_hi;
+		int qece_dram_base_address_lo;
+		int pyld_dram_base_address_lo;
+		int QM_VMID;
+		int port_flush;
+		int AXI_read_attributes_for_swf_mode;
+		int AXI_read_attributes_for_rdma_mode;
+		int AXI_read_attributes_for_hwf_qece;
+		int AXI_read_attributes_for_hwf_pyld;
+		int ecc_error_cause;
+		int ecc_error_mask;
+		int internal_error_cause;
+		int internal_error_mask;
+		int idle_status;
+		int queue_flush;
+		int queue_qece;
+	} pfe;
+
+	struct {
+		int base;
+		int Data_FIFO_params_p;
+		int Credit_Threshold_p;
+		int PPC_port_map_p;
+		int data_fifo_pointers_p;
+		int dqf_itnr_cause;
+		int dqf_itnr_mask;
+		int misc_error_intr_cause;
+		int misc_error_intr_mask;
+		int dqf_ser_summary_intr_cause;
+		int dqf_ser_summary_intr_mask;
+		int write_to_full_error_intr_cause;
+		int write_to_full_error_intr_mask;
+		int read_from_empty_error_intr_cause;
+		int read_from_empty_error_intr_mask;
+		int wrong_axi_rd_error_intr_cause;
+		int wrong_axi_rd_error_intr_mask;
+		int mg2mem_req_addr_ctrl;
+		int mem2mg_resp_status;
+		int mem2mg_resp_data_hh;
+		int mem2mg_resp_data_hl;
+		int mem2mg_resp_data_lh;
+		int mem2mg_resp_data_ll;
+		int dqf_macs_l3_res;
+		int dqf_macs_l4_res;
+		int dqf_macs_l3_ptr;
+		int dqf_macs_l4_ptr;
+		int dqf_macs_desc;
+	} dqf;
+
+	struct {
+		int base;
+		int Q_memory_allocation;
+		int gpm_thresholds;
+		int dram_thresholds;
+		int AXI_write_attributes_for_swf_mode;
+		int AXI_write_attributes_for_rdma_mode;
+		int AXI_write_attributes_for_hwf_qece;
+		int AXI_write_attributes_for_hwf_pyld;
+		int DRAM_VMID;
+		int idle_status;
+		int ecc_error_cause;
+		int ecc_error_mask;
+		int internal_error_cause;
+		int internal_error_mask;
+		int ceram_mac;
+		int ceram_ppe;
+		int qeram;
+		int dram_fifo;
+	} dma;
+
+	struct {
+		int base;
+		int ErrStus;
+	} sched;
+
+	struct {
+		int base;
+		int DrpErrStus;
+		int DrpFirstExc;
+		int DrpErrCnt;
+		int DrpExcCnt;
+		int DrpExcMask;
+		int DrpId;
+		int DrpForceErr;
+		int WREDDropProbMode;
+		int WREDMaxProbModePerColor;
+		int DPSource;
+		int RespLocalDPSel;
+		int Drp_Decision_to_Query_debug;
+		int Drp_Decision_hierarchy_to_Query_debug;
+		int TMtoTMPktGenQuantum;
+		int TMtoTMDPCoSSel;
+		int AgingUpdEnable;
+		int PortInstAndAvgQueueLength;
+		int DrpEccConfig;
+		int DrpEccMemParams;
+	} drop;
+
+	struct {
+		int base;
+		int ru_qe;
+		int ru_class;
+		int ru_tasks;
+		int ru_ptr2next;
+		int ru_sid_fifo;
+		int ru_port2class;
+		int ru_pool;
+		int ru_class_head;
+		int ru_ser_error_cause;
+		int ru_ser_error_mask;
+		int ru_host_cmd;
+		int ru_task_permission;
+	} reorder;
+
+	struct {
+		int base;
+		int gpm_pl;	/*[10240] */
+		int gpm_qe;	/*[5120] */
+	} gpm;
+};	/* QM; */
+
+extern struct qm_alias qm;
+extern struct qm_alias qm_reg_size;
+extern struct qm_alias qm_reg_offset;
+
+int qm_reg_address_alias_init(void);
+int qm_reg_size_alias_init(void);
+int qm_reg_offset_alias_init(void);
+
+#endif   /* __MV_QM_REGS_H__ */
-- 
1.7.5.4

