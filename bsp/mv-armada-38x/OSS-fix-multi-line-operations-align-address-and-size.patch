From 96f01f4ccd8ba5874568ba11f935f348606a360c Mon Sep 17 00:00:00 2001
From: Tawfik Bayouk <tawfik@marvell.com>
Date: Tue, 21 Aug 2012 17:35:04 +0300
Subject: [PATCH 0152/1825] OSS: fix multi-line operations align address and
 size from KW2

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit 483e52d61919d7d6bb85d7041cd0c7cd6d39a14c

Change-Id: Ie72df598fd89ff5fb522b40ff8312460f9a74c36
Signed-off-by: Tawfik Bayouk <tawfik@marvell.com>
Signed-off-by: Kosta Zertsekel <konszert@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 arch/arm/plat-armada/linux_oss/mvOs.h |   30 +++++++++++++++++++++++++++++-
 1 files changed, 29 insertions(+), 1 deletions(-)

diff --git a/arch/arm/plat-armada/linux_oss/mvOs.h b/arch/arm/plat-armada/linux_oss/mvOs.h
index 46c7ac1..f61b516 100644
--- a/arch/arm/plat-armada/linux_oss/mvOs.h
+++ b/arch/arm/plat-armada/linux_oss/mvOs.h
@@ -380,13 +380,22 @@ static inline void mvOsBridgeReorderWA(void)
 	__asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 1" : : "r" (addr));\
 #endif
 	__asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 4" : : "r" (addr)); \
- }
+}
 #endif
 
 #define MV_OS_CACHE_MULTI_THRESH	256
+
+/* Flush multiple cache lines using mvOsCacheLineFlush to improve performance.              */
+/* addr is the pointer to start the flush operation from. It will be aligned to             */
+/* the beginning of the cache line automatically and the size will be adjusted accordingly. */
 static inline void mvOsCacheMultiLineFlush(void *handle, void *addr, int size)
 {
 	if (size <= MV_OS_CACHE_MULTI_THRESH) {
+		int shift = ((MV_ULONG)(addr) & (CPU_D_CACHE_LINE_SIZE - 1));
+		if (shift) {
+			addr -= shift; /* align address back to the beginning of a cache line */
+			size += shift;
+		}
 #if defined(CONFIG_CACHE_AURORA_L2)
 		DSBWA_4611(addr);
 		while (size > 0) {
@@ -412,9 +421,20 @@ static inline void mvOsCacheMultiLineFlush(void *handle, void *addr, int size)
 		pci_map_single(handle, addr, size, PCI_DMA_TODEVICE);
 }
 
+/* Invalidate multiple cache lines using mvOsCacheLineInv to improve performance.           */
+/* addr is the pointer to start the invalidate operation from. It will be aligned to        */
+/* the beginning of the cache line automatically and the size will be adjusted accordingly. */
+/* IMPORTANT: this function assumes the invalidate operation on partial lines does not      */
+/* interfere with the data written there.                                                   */
+/* DO NOT USE this function unless you are certain of this!                                 */
 static inline void mvOsCacheMultiLineInv(void *handle, void *addr, int size)
 {
 	if (size <= MV_OS_CACHE_MULTI_THRESH) {
+		int shift = ((MV_ULONG)(addr) & (CPU_D_CACHE_LINE_SIZE - 1));
+		if (shift) {
+			addr -= shift; /* align address back to the beginning of a cache line */
+			size += shift;
+		}
 #if defined(CONFIG_CACHE_AURORA_L2)
 		DSBWA_4413(addr);
 		while (size > 0) {
@@ -436,9 +456,17 @@ static inline void mvOsCacheMultiLineInv(void *handle, void *addr, int size)
 		pci_map_single(handle, addr, size, PCI_DMA_FROMDEVICE);
 }
 
+/* Flush and invalidate multiple cache lines using mvOsCacheLineFlushInv to improve performance. */
+/* addr is the pointer to start the flush and invalidate operation from. It will be aligned to   */
+/* the beginning of the cache line automatically and the size will be adjusted accordingly.      */
 static inline void mvOsCacheMultiLineFlushInv(void *handle, void *addr, int size)
 {
 	if (size <= MV_OS_CACHE_MULTI_THRESH) {
+		int shift = ((MV_ULONG)(addr) & (CPU_D_CACHE_LINE_SIZE - 1));
+		if (shift) {
+			addr -= shift; /* align address back to the beginning of a cache line */
+			size += shift;
+		}
 #if defined(CONFIG_CACHE_AURORA_L2)
 		DSBWA_4611(addr);
 		while (size > 0) {
-- 
1.7.5.4

