From 5ce4da542b8aa1543afd900856fc1a4fb9bee519 Mon Sep 17 00:00:00 2001
From: Evan <xswang@marvell.com>
Date: Wed, 9 Jul 2014 17:47:54 +0800
Subject: [PATCH 1788/1825] fix: pp2,neta: Fix compile issue that pp2 and neta
 driver can not work together

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit 7d367e6d55af8dcd7030bf7ec194e0e9b88aeb76

	1. Update define for shared macros by pp2 and neta driver
	2. Update pp2 functions define have same with neta driver
	3. Update pp2 and neta Kconfig for shared compile macros
	4. Update related Kconfig file for LK2.6, 3.2, 3.4
	5. Update file of mvebu_lsp_defconfig
	6. Update uboot related macro define

Signed-off-by: Evan <xswang@marvell.com>

Change-Id: I2d0db9e3eceb78e54b2ee6d0e19c04b5785797d3
Reviewed-on: http://vgitil04.il.marvell.com:8080/9091
Tested-by: Star_Automation <star@marvell.com>
Reviewed-by: Yelena Krivosheev <yelena@marvell.com>
Reviewed-by: Nadav Haklai <nadavh@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 arch/arm/configs/avanta_lp_defconfig               |   14 +-
 .../avanta_lp_family/ctrlEnv/mvCtrlEnvSpec.h       |   14 +-
 arch/arm/plat-armada/Kconfig                       |   34 +
 .../arm/plat-armada/mv_drivers_lsp/mv_neta/Kconfig |   36 +-
 .../mv_drivers_lsp/mv_neta/net_dev/mv_eth_nfp.c    |   16 +-
 .../mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c     |   80 +-
 .../mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h     |    8 +-
 .../plat-armada/mv_drivers_lsp/mv_network/Kconfig  |   22 +-
 .../mv_network/mv_ethernet/mv_eth_proc.c           |    4 +-
 .../mv_network/mv_ethernet/mv_netdev.c             |   38 +-
 .../mv_network/mv_ethernet/mv_netdev.h             |   12 +-
 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig |  281 ++--
 .../arm/plat-armada/mv_drivers_lsp/mv_pp2/Makefile |    4 +-
 .../mv_drivers_lsp/mv_pp2/cph/mv_cph_app.c         |    8 +-
 .../mv_drivers_lsp/mv_pp2/cph/mv_cph_app.h         |    4 +-
 .../mv_drivers_lsp/mv_pp2/cph/mv_cph_flow.c        |   48 +-
 .../mv_drivers_lsp/mv_pp2/cph/mv_cph_flow.h        |    4 +-
 .../mv_drivers_lsp/mv_pp2/cph/mv_cph_header.h      |    2 +-
 .../mv_drivers_lsp/mv_pp2/cph/mv_cph_netdev.c      |   42 +-
 .../mv_drivers_lsp/mv_pp2/cph/mv_cph_netdev.h      |    4 +-
 .../mv_drivers_lsp/mv_pp2/l2fw/l2fw_sysfs.c        |   10 +-
 .../mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c       |  226 ++--
 .../mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h       |    2 +-
 .../mv_pp2/net_dev/mv_eth_bm_sysfs.c               |   76 +-
 .../mv_pp2/net_dev/mv_eth_dbg_sysfs.c              |   36 +-
 .../mv_pp2/net_dev/mv_eth_hwf_sysfs.c              |    8 +-
 .../mv_pp2/net_dev/mv_eth_napi_sysfs.c             |    2 +-
 .../mv_pp2/net_dev/mv_eth_pme_sysfs.c              |   26 +-
 .../mv_pp2/net_dev/mv_eth_pon_sysfs.c              |   40 +-
 .../mv_pp2/net_dev/mv_eth_qos_sysfs.c              |   32 +-
 .../mv_pp2/net_dev/mv_eth_rx_sysfs.c               |   54 +-
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.c   |  104 +-
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h   |    6 +-
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.c    |  247 ++--
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.h    |    2 +-
 .../mv_pp2/net_dev/mv_eth_tx_sysfs.c               |   68 +-
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_ethernet.c    |   74 +-
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c      | 1661 ++++++++++----------
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h      |  413 +++---
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_pp2_netmap.h  |   32 +-
 .../mv_drivers_lsp/mv_tpm/src/core/tpm_cls.c       |    2 +-
 .../mv_drivers_lsp/mv_tpm/src/core/tpm_policer.c   |   12 +-
 arch/arm/plat-armada/mv_hal/neta/gbe/mvNeta.h      |    4 +-
 arch/arm/plat-armada/mv_hal/pp2/cls/mvPp2ClsHw.c   |    8 +-
 arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2Gbe.c     |   83 +-
 arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2Gbe.h     |   48 +-
 .../arm/plat-armada/mv_hal/pp2/gbe/mvPp2GbeDebug.c |   38 +-
 .../arm/plat-armada/mv_hal/pp2/gmac/mvEthGmacApi.c |   10 +-
 arch/arm/plat-armada/mv_hal/pp2/plcr/mvPp2PlcrHw.c |    2 +-
 49 files changed, 2048 insertions(+), 1953 deletions(-)

diff --git a/arch/arm/configs/avanta_lp_defconfig b/arch/arm/configs/avanta_lp_defconfig
index 168076e..11a4726 100644
--- a/arch/arm/configs/avanta_lp_defconfig
+++ b/arch/arm/configs/avanta_lp_defconfig
@@ -14,7 +14,7 @@ CONFIG_MODULE_UNLOAD=y
 # CONFIG_BLK_DEV_BSG is not set
 CONFIG_PARTITION_ADVANCED=y
 CONFIG_ARCH_AVANTA_LP=y
-CONFIG_MV_ETH_TXQ=8
+CONFIG_MV_PP2_TXQ=8
 CONFIG_MV_TDM_PCM_CLK_8MHZ=y
 # CONFIG_MV_INCLUDE_LEGACY_NAND is not set
 CONFIG_MV_INCLUDE_TPM=y
@@ -22,15 +22,19 @@ CONFIG_MV_INCLUDE_WIRELESS_APPLICATION=y
 CONFIG_MV_IPC_FREERTOS_DRIVER=y
 CONFIG_MTD_NAND_NFC_INIT_RESET=y
 CONFIG_MV_ETH_DEBUG_CODE=y
-CONFIG_MV_ETH_STAT_DBG=y
-CONFIG_MV_ETH_RX_SPECIAL=y
-CONFIG_MV_ETH_TX_SPECIAL=y
+CONFIG_MV_PP2_DEBUG_CODE=y
+CONFIG_MV_PP2_STAT_DBG=y
+CONFIG_MV_PP2_RX_SPECIAL=y
+CONFIG_MV_PP2_TX_SPECIAL=y
 CONFIG_MV_ETH_PP2_1=y
-CONFIG_MV_ETH_BM_PER_PORT_MODE=y
+CONFIG_MV_PP2_BM_PER_PORT_MODE=y
 CONFIG_MV_CPH=y
 CONFIG_MV_CPH_IGMP_HANDLE=y
 CONFIG_MV_CPH_MLD_HANDLE=y
 CONFIG_MV_CPH_FLOW_MAP_HANDLE=y
+CONFIG_MV_PP2_PON=y
+CONFIG_MV_PP2_PON_TXP_DEF=0
+CONFIG_MV_PP2_PON_TXQ_DEF=0
 # CONFIG_SWP_EMULATE is not set
 CONFIG_PL310_ERRATA_588369=y
 CONFIG_PL310_ERRATA_727915=y
diff --git a/arch/arm/mach-avantalp/avanta_lp_family/ctrlEnv/mvCtrlEnvSpec.h b/arch/arm/mach-avantalp/avanta_lp_family/ctrlEnv/mvCtrlEnvSpec.h
index e4ee0e1..1a4b268 100644
--- a/arch/arm/mach-avantalp/avanta_lp_family/ctrlEnv/mvCtrlEnvSpec.h
+++ b/arch/arm/mach-avantalp/avanta_lp_family/ctrlEnv/mvCtrlEnvSpec.h
@@ -122,16 +122,16 @@ extern "C" {
 #define GOP_REG_BASE(port)                      (MV_ETH_BASE_ADDR + 0x4000 + ((port) / 2) * 0x3000 + ((port) % 2) * 0x1000)
 #define MV_PON_REGS_OFFSET                      (MV_ETH_BASE_ADDR + 0x8000)
 
-#define MV_PON_EXIST
-#define MV_ETH_MAX_TCONT                        16
-#define MV_PON_PORT_ID                          7
-#define MV_ETH_RXQ_TOTAL_NUM                    32
+#define MV_PP2_PON_EXIST
+#define MV_PP2_MAX_TCONT                        16
+#define MV_PP2_PON_PORT_ID                      7
+#define MV_PP2_RXQ_TOTAL_NUM                    32
 #define MV_VLAN_1_TYPE                          0x88A8
 
 #define MV_ETH_MAX_PORTS                        4
-#define MV_ETH_MAX_RXQ                          16      /* Maximum number of RXQs can be mapped to each port */
-#define MV_ETH_MAX_TXQ                          8
-#define MV_ETH_TX_CSUM_MAX_SIZE                 1790
+#define MV_PP2_MAX_RXQ                          16      /* Maximum number of RXQs can be mapped to each port */
+#define MV_PP2_MAX_TXQ                          8
+#define MV_PP2_TX_CSUM_MAX_SIZE                 1790
 
 #define MV_ETH_REGS_OFFSET(port)                (MV_ETH_BASE_ADDR - ((port) / 2) * 0x40000 + ((port) % 2) * 0x4000)
 
diff --git a/arch/arm/plat-armada/Kconfig b/arch/arm/plat-armada/Kconfig
index ff9fe4a..0f7c89e 100644
--- a/arch/arm/plat-armada/Kconfig
+++ b/arch/arm/plat-armada/Kconfig
@@ -558,6 +558,31 @@ source arch/arm/plat-armada/mv_drivers_lsp/mv_xor/Kconfig
 source arch/arm/plat-armada/mv_drivers_lsp/mv_dma/Kconfig
 endmenu
 
+menu "SoC Network SKB Features"
+
+config NET_SKB_HEADROOM
+	int "SKB headroom size"
+	default 64
+	---help---
+	Customize SKB headroom size. Must be power of 2.
+
+config NET_SKB_RECYCLE
+	bool "Skb recycle"
+	default y
+	---help---
+	Work-in-progress and experimental.
+
+	This option enables skb's to be returned via a callback at kfree to
+	the allocator to make a fastpath for very skb consuming network
+	applications.
+
+config NET_SKB_RECYCLE_DEF
+	depends on NET_SKB_RECYCLE
+	int "Default value for SKB recycle:  0 - disable, 1 - enable"
+	default 1
+	---help---
+
+endmenu
 
 menu "SoC Networking support"
 depends on MV_INCLUDE_GIG_ETH
@@ -568,6 +593,15 @@ config MV_ETHERNET
 	help
 	  Obsolete
 
+config MV_ETH_DEBUG_CODE
+	bool "Add run-time debug code"
+	default n
+	---help---
+	Enable run-time enable/disable enter debug code blocks
+	It is share by NETA and PP2 driver module.
+	It is also control debug code in mux module.
+	Note the patch depends on it.
+
 config MV_ETH_LEGACY
 	bool "Legacy driver"
 	depends on ARCH_FEROCEON_KW
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/Kconfig
index 8066885..a7c37fa 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/Kconfig
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/Kconfig
@@ -493,7 +493,8 @@ endmenu
 
 menu "Control and Statistics"
 
-config  MV_ETH_DEBUG_CODE
+config  MV_NETA_DEBUG_CODE
+	depends on MV_ETH_DEBUG_CODE
 	bool "Add run-time debug code"
 	default n
 	---help---
@@ -538,27 +539,22 @@ endmenu
 
 menu "Advanced Features"
 
-config  NET_SKB_HEADROOM
-        int "SKB headroom size"
-        default 64
-        ---help---
-          Customize SKB headroom size. Must be power of 2.
-
-config NET_SKB_RECYCLE
-        bool "Skb recycle"
-        default y
-        ---help---
-          Work-in-progress and experimental.
+config MV_NETA_SKB_RECYCLE
+	depends on NET_SKB_RECYCLE
+	bool "NETA Skb recycle"
+	default y
+	---help---
+	Work-in-progress and experimental.
 
-          This option enables skb's to be returned via a callback at kfree to
-          the allocator to make a fastpath for very skb consuming network
-          applications.
+	This option enables skb's to be returned via a callback at kfree to
+	the allocator to make a fastpath for very skb consuming network
+	applications.
 
-config NET_SKB_RECYCLE_DEF
-        depends on NET_SKB_RECYCLE
-        int "Default value for SKB recycle:  0 - disable, 1 - enable"
-        default 1
-        ---help---
+config MV_NETA_SKB_RECYCLE_DEF
+	depends on MV_NETA_SKB_RECYCLE
+	int "Default value for SKB recycle:  0 - disable, 1 - enable"
+	default 1
+	---help---
 
 config  MV_ETH_TX_DONE_TIMER_PERIOD
         int "Periodical Tx Done timer period"
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_nfp.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_nfp.c
index 97b1908..e65dfc3 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_nfp.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_nfp.c
@@ -352,10 +352,10 @@ static MV_STATUS mv_eth_nfp_tx(struct eth_pbuf *pkt, MV_NFP_RESULT *res)
 
 	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
 		STAT_INFO(pp->stats.netdev_stop++);
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 		if (pp->flags & MV_ETH_F_DBG_TX)
 			printk(KERN_ERR "%s: STARTED_BIT = 0 , packet is dropped.\n", __func__);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 		return MV_DROPPED;
 	}
 
@@ -455,14 +455,14 @@ static MV_STATUS mv_eth_nfp_tx(struct eth_pbuf *pkt, MV_NFP_RESULT *res)
 	/* FIXME: PON only? --BK */
 	tx_desc->hw_cmd = pp->hw_cmd;
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 	if (pp->flags & MV_ETH_F_DBG_TX) {
 		printk(KERN_ERR "%s - nfp_tx_%lu: port=%d, txp=%d, txq=%d\n",
 		       dev->name, dev->stats.tx_packets, pp->port, res->txp, res->txq);
 		mv_eth_tx_desc_print(tx_desc);
 		mv_eth_pkt_print(pkt);
 	}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 
 	mv_eth_tx_desc_flush(tx_desc);
 
@@ -510,12 +510,12 @@ MV_STATUS mv_eth_nfp(struct eth_port *pp, int rxq, struct neta_rx_desc *rx_desc,
 	MV_NFP_RESULT   res;
 	bool            tx_external = false;
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 	if (pp->flags & MV_ETH_F_DBG_RX) {
 		mv_eth_rx_desc_print(rx_desc);
 		mv_eth_pkt_print(pkt);
 	}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 
 	status = nfp_core_p->nfp_rx(pp->port, rx_desc, pkt, &res);
 	tx_external = (res.flags & MV_NFP_RES_NETDEV_EXT);
@@ -718,12 +718,12 @@ static int mv_eth_nfp_ext_tx(struct eth_port *pp, struct eth_pbuf *pkt, MV_NFP_R
 		mv_eth_skb_check(skb);
 #endif /* ETH_SKB_DEBUG */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NETA_SKB_RECYCLE
 		if (mv_eth_is_recycle()) {
 			skb->skb_recycle = mv_eth_skb_recycle;
 			skb->hw_cookie = (__u32)pkt;
 		}
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NETA_SKB_RECYCLE */
 	}
 	return dev->netdev_ops->ndo_start_xmit(skb, dev);
 }
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c
index 5ca4416..651ab5c 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c
@@ -113,8 +113,8 @@ int mv_eth_ctrl_pnc(int en)
 }
 #endif /* CONFIG_MV_ETH_PNC */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
-int mv_ctrl_recycle = CONFIG_NET_SKB_RECYCLE_DEF;
+#ifdef CONFIG_MV_NETA_SKB_RECYCLE
+int mv_ctrl_recycle = CONFIG_MV_NETA_SKB_RECYCLE_DEF;
 EXPORT_SYMBOL(mv_ctrl_recycle);
 
 int mv_eth_ctrl_recycle(int en)
@@ -128,7 +128,7 @@ int mv_eth_ctrl_recycle(int en)
 	printk(KERN_ERR "SKB recycle is not supported\n");
 	return 1;
 }
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NETA_SKB_RECYCLE */
 
 extern u8 mvMacAddr[CONFIG_MV_ETH_PORTS_NUM][MV_MAC_ADDR_SIZE];
 extern u16 mvMtu[CONFIG_MV_ETH_PORTS_NUM];
@@ -1148,7 +1148,7 @@ static void mv_eth_rx_error(struct eth_port *pp, struct neta_rx_desc *rx_desc)
 	if (pp->dev)
 		pp->dev->stats.rx_errors++;
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 	if ((pp->flags & MV_ETH_F_DBG_RX) == 0)
 		return;
 
@@ -1180,7 +1180,7 @@ static void mv_eth_rx_error(struct eth_port *pp, struct neta_rx_desc *rx_desc)
 		break;
 	}
 	mv_eth_rx_desc_print(rx_desc);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 }
 
 void mv_eth_skb_print(struct sk_buff *skb)
@@ -1194,9 +1194,9 @@ void mv_eth_skb_print(struct sk_buff *skb)
 	       atomic_read(&skb->users), atomic_read(&skb_shinfo(skb)->dataref),
 	       skb_shinfo(skb)->nr_frags, skb_shinfo(skb)->gso_size, skb_shinfo(skb)->gso_segs);
 	printk(KERN_ERR "\t proto=%d, ip_summed=%d, priority=%d\n", ntohs(skb->protocol), skb->ip_summed, skb->priority);
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NETA_SKB_RECYCLE
 	printk(KERN_ERR "\t skb_recycle=%p, hw_cookie=0x%x\n", skb->skb_recycle, skb->hw_cookie);
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NETA_SKB_RECYCLE */
 }
 
 void mv_eth_rx_desc_print(struct neta_rx_desc *desc)
@@ -1333,7 +1333,7 @@ static inline int mv_eth_tx_policy(struct eth_port *pp, struct sk_buff *skb)
 	return txq;
 }
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NETA_SKB_RECYCLE
 int mv_eth_skb_recycle(struct sk_buff *skb)
 {
 	struct eth_pbuf *pkt = (struct eth_pbuf *)(skb->hw_cookie & ~BIT(0));
@@ -1381,14 +1381,14 @@ int mv_eth_skb_recycle(struct sk_buff *skb)
 		atomic_set(&skb->users, 1);
 
 	if (skb_recycle_check(skb, pool->pkt_size)) {
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 		/* Sanity check */
 		if (SKB_TRUESIZE(skb->end - skb->head) != skb->truesize) {
 			printk(KERN_ERR "%s: skb=%p, Wrong SKB_TRUESIZE(end - head)=%d\n",
 				__func__, skb, SKB_TRUESIZE(skb->end - skb->head));
 			mv_eth_skb_print(skb);
 		}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 
 		STAT_DBG(pool->stats.skb_recycled_ok++);
 		mvOsCacheInvalidate(pp->dev->dev.parent, skb->head, RX_BUF_SIZE(pool->pkt_size));
@@ -1414,7 +1414,7 @@ err:
 }
 EXPORT_SYMBOL(mv_eth_skb_recycle);
 
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NETA_SKB_RECYCLE */
 
 static struct sk_buff *mv_eth_skb_alloc(struct eth_port *pp, struct bm_pool *pool,
 					struct eth_pbuf *pkt, gfp_t gfp_mask)
@@ -1769,12 +1769,12 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 		mvNetaRxqDescSwap(rx_desc);
 #endif /* MV_CPU_BE */
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 		if (pp->flags & MV_ETH_F_DBG_RX) {
 			printk(KERN_ERR "\n%s: port=%d, cpu=%d\n", __func__, pp->port, smp_processor_id());
 			mv_eth_rx_desc_print(rx_desc);
 		}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 
 		rx_status = rx_desc->status;
 		pkt = (struct eth_pbuf *)rx_desc->bufCookie;
@@ -1820,12 +1820,12 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 	}
 #endif /* !CONFIG_MV_ETH_PNC */
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 		if (pp->flags & MV_ETH_F_DBG_RX) {
 			printk(KERN_ERR "pkt=%p, pBuf=%p, ksize=%d\n", pkt, pkt->pBuf, ksize(pkt->pBuf));
 			mvDebugMemDump(pkt->pBuf + pkt->offset, 64, 1);
 		}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 
 #if defined(CONFIG_MV_ETH_PNC) && defined(CONFIG_MV_ETH_RX_SPECIAL)
 		/* Special RX processing */
@@ -1874,13 +1874,13 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 		mv_eth_skb_check(skb);
 #endif /* ETH_SKB_DEBUG */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NETA_SKB_RECYCLE
 		if (mv_eth_is_recycle()) {
 			skb->skb_recycle = mv_eth_skb_recycle;
 			skb->hw_cookie = (__u32)pkt;
 			pkt = NULL;
 		}
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NETA_SKB_RECYCLE */
 
 		mv_eth_rx_csum(pp, rx_desc, skb);
 
@@ -1942,10 +1942,10 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
 		STAT_INFO(pp->stats.netdev_stop++);
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 		if (pp->flags & MV_ETH_F_DBG_TX)
 			printk(KERN_ERR "%s: STARTED_BIT = 0, packet is dropped.\n", __func__);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 		goto out;
 	}
 
@@ -1972,11 +1972,11 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 
 	/* In case this port is tagged, check if SKB is tagged - i.e. SKB's source is MUX interface */
 	if (pp->tagged && (!MV_MUX_SKB_IS_TAGGED(skb))) {
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 		if (pp->flags & MV_ETH_F_DBG_TX)
 			pr_err("%s: port %d is tagged, skb not from MUX interface - packet is dropped.\n",
 				__func__, pp->port);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 
 		goto out;
 	}
@@ -2068,7 +2068,7 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 */
 	txq_ctrl->txq_count += frags;
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 	if (pp->flags & MV_ETH_F_DBG_TX) {
 		printk(KERN_ERR "\n");
 		printk(KERN_ERR "%s - eth_tx_%lu: cpu=%d, in_intr=0x%lx, port=%d, txp=%d, txq=%d\n",
@@ -2079,7 +2079,7 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 		/*mv_eth_skb_print(skb);*/
 		mvDebugMemDump(skb->data, 64, 1);
 	}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 
 #ifdef CONFIG_MV_PON
 	if (MV_PON_PORT(pp->port))
@@ -2866,13 +2866,13 @@ irqreturn_t mv_eth_isr(int irq, void *dev_id)
 	int cpu = smp_processor_id();
 	struct napi_struct *napi = pp->cpu_config[cpu]->napi;
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 	if (pp->flags & MV_ETH_F_DBG_ISR) {
 		printk(KERN_ERR "%s: port=%d, cpu=%d, mask=0x%x, cause=0x%x\n",
 			__func__, pp->port, cpu,
 			MV_REG_READ(NETA_INTR_NEW_MASK_REG(pp->port)), MV_REG_READ(NETA_INTR_NEW_CAUSE_REG(pp->port)));
 	}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 
 	STAT_INFO(pp->stats.irq[cpu]++);
 
@@ -2887,10 +2887,10 @@ irqreturn_t mv_eth_isr(int irq, void *dev_id)
 		__napi_schedule(napi);
 	} else {
 		STAT_INFO(pp->stats.irq_err[cpu]++);
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 		pr_warning("%s: IRQ=%d, port=%d, cpu=%d - NAPI already scheduled\n",
 			__func__, irq, pp->port, cpu);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 	}
 	return IRQ_HANDLED;
 }
@@ -2975,21 +2975,21 @@ int mv_eth_poll(struct napi_struct *napi, int budget)
 	struct eth_port *pp = MV_ETH_PRIV(napi->dev);
 	struct cpu_ctrl *cpuCtrl = pp->cpu_config[smp_processor_id()];
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 	if (pp->flags & MV_ETH_F_DBG_POLL) {
 		printk(KERN_ERR "%s ENTER: port=%d, cpu=%d, mask=0x%x, cause=0x%x\n",
 			__func__, pp->port, smp_processor_id(),
 			MV_REG_READ(NETA_INTR_NEW_MASK_REG(pp->port)), MV_REG_READ(NETA_INTR_NEW_CAUSE_REG(pp->port)));
 	}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 
 	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
 		STAT_INFO(pp->stats.netdev_stop++);
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 		if (pp->flags & MV_ETH_F_DBG_RX)
 			printk(KERN_ERR "%s: STARTED_BIT = 0, poll completed.\n", __func__);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 
 		napi_complete(napi);
 		STAT_INFO(pp->stats.poll_exit[smp_processor_id()]++);
@@ -3055,12 +3055,12 @@ int mv_eth_poll(struct napi_struct *napi, int budget)
 
 	STAT_DIST((rx_done < pp->dist_stats.rx_dist_size) ? pp->dist_stats.rx_dist[rx_done]++ : 0);
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 	if (pp->flags & MV_ETH_F_DBG_POLL) {
 		printk(KERN_ERR "%s  EXIT: port=%d, cpu=%d, budget=%d, rx_done=%d\n",
 			__func__, pp->port, smp_processor_id(), budget, rx_done);
 	}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 
 	if (budget > 0) {
 		unsigned long flags;
@@ -4418,7 +4418,7 @@ void mv_eth_config_show(void)
 	pr_info("  o Giga PON port is #%d: - %d TCONTs supported\n", MV_PON_PORT_ID, MV_ETH_MAX_TCONT());
 #endif
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NETA_SKB_RECYCLE
 	pr_info("  o SKB recycle supported (%s)\n", mv_ctrl_recycle ? "Enabled" : "Disabled");
 #endif
 
@@ -5422,10 +5422,10 @@ static void mv_eth_tx_done_timer_callback(unsigned long data)
 	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
 		STAT_INFO(pp->stats.netdev_stop++);
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 		if (pp->flags & MV_ETH_F_DBG_TX)
 			printk(KERN_ERR "%s: port #%d is stopped, STARTED_BIT = 0, exit timer.\n", __func__, pp->port);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 
 		return;
 	}
@@ -5894,9 +5894,9 @@ void mv_eth_status_print(void)
 {
 	printk(KERN_ERR "totals: ports=%d\n", mv_eth_ports_num);
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NETA_SKB_RECYCLE
 	printk(KERN_ERR "SKB recycle = %s\n", mv_ctrl_recycle ? "Enabled" : "Disabled");
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NETA_SKB_RECYCLE */
 
 #ifdef CONFIG_MV_ETH_PNC
 	printk(KERN_ERR "PnC control = %s\n", mv_eth_pnc_ctrl_en ? "Enabled" : "Disabled");
@@ -6502,10 +6502,10 @@ void pon_link_status_notify_func(MV_BOOL link_state)
 
 	if ((pon_port->flags & MV_ETH_F_STARTED) == 0) {
 		/* Ignore link event if port is down - link status will be updated on start */
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 		pr_info("PON port: Link event (%s) when port is down\n",
 			link_state ? "Up" : "Down");
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 		return;
 	}
 	mv_eth_link_event(pon_port, 1);
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h
index 835a810..01453ce 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h
@@ -88,14 +88,14 @@ extern int mv_ctrl_txdone;
 #define RX_BUF_SIZE(pkt_size)   ((pkt_size) + NET_SKB_PAD)
 
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NETA_SKB_RECYCLE
 extern int mv_ctrl_recycle;
 
 #define mv_eth_is_recycle()     (mv_ctrl_recycle)
 int mv_eth_skb_recycle(struct sk_buff *skb);
 #else
 #define mv_eth_is_recycle()     0
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NETA_SKB_RECYCLE */
 
 /******************************************************
  * interrupt control --                               *
@@ -672,10 +672,10 @@ static inline void mv_eth_pkt_free(struct eth_pbuf *pkt)
 {
 	struct sk_buff *skb = (struct sk_buff *)pkt->osInfo;
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NETA_SKB_RECYCLE
 	skb->skb_recycle = NULL;
 	skb->hw_cookie = 0;
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NETA_SKB_RECYCLE */
 
 	dev_kfree_skb_any(skb);
 	mvOsFree(pkt);
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/Kconfig
index 102412b..6e960e8 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/Kconfig
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/Kconfig
@@ -177,23 +177,25 @@ config MV_ETH_SKB_REUSE_DEF
         default 0
         ---help---
 
-config  NET_SKB_HEADROOM
-        int "SKB headroom size"
-        default 64
-        ---help---
-          Customize SKB headroom size. Must be power of 2.
-
-config  NET_SKB_RECYCLE
+config MV_NET_SKB_RECYCLE
+        depends on NET_SKB_RECYCLE
         bool "Try to recycle SKB"
         default y
         ---help---
-          Recycle SKB via callback in 'struct sk_buff'
+        Recycle SKB via callback in 'struct sk_buff'
+        The oprtion is only valid in legacy driver module.
+        PP2 and NETA have their own macros.
+        Note the oprtion depends on it.
 
-config NET_SKB_RECYCLE_DEF
-        depends on NET_SKB_RECYCLE
+config MV_NET_SKB_RECYCLE_DEF
+        depends on MV_NET_SKB_RECYCLE
         int "Default value for SKB recycle:  0 - disable, 1 - enable"
         default 0
         ---help---
+        Default value for SKB recycle
+        The oprtion is only valid in legacy driver module.
+        PP2 and NETA have their own macros.
+        Note the oprtion depends on it.
 
 config  MV_ETH_NFP
         bool "Use Network Fast Processing (NFP)"
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_proc.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_proc.c
index 5838b50..7ed7a12 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_proc.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_eth_proc.c
@@ -225,11 +225,11 @@ int run_eth_com(const char *buffer) {
             break;
 #endif /* CONFIG_MV_ETH_SKB_REUSE */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
         case COM_SKB_RECYCLE:
             eth_skb_recycle_enable = value;
 	    break;
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NET_SKB_RECYCLE */
 
 #ifdef CONFIG_MV_ETH_NFP
         case COM_NFP:
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.c
index fabf96a..9a58793 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.c
@@ -294,8 +294,8 @@ static inline int mv_eth_skb_check(struct sk_buff *skb, int skb_size)
 }
 #endif /* LINUX_VERSION_CODE < 2.6.24 */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
-int eth_skb_recycle_enable = CONFIG_NET_SKB_RECYCLE_DEF;
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
+int eth_skb_recycle_enable = CONFIG_MV_NET_SKB_RECYCLE_DEF;
 static void eth_skb_recycle_clear(mv_eth_priv* priv)
 {
 	struct sk_buff *skb;
@@ -389,14 +389,14 @@ static INLINE struct sk_buff* eth_skb_alloc(mv_eth_priv *priv, MV_PKT_INFO* pPkt
     /* allocate new skb */
     /* 32(extra for cache prefetch) + 8 to align on 8B */
     buf_size = MV_RX_BUF_SIZE(mtu) + CPU_D_CACHE_LINE_SIZE  + 8;
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
 	if (!mvStackIsEmpty(priv->skbRecyclePool)) {
 		skb = (struct sk_buff*)mvStackPop(priv->skbRecyclePool);
 		ETH_STAT_DBG(priv->eth_stat.skb_recycle_get++);
 		/* FIXME: check size */
 	}
 	else
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NET_SKB_RECYCLE */
 		skb = dev_alloc_skb( buf_size ); 
 
     if (!skb) {
@@ -404,10 +404,10 @@ static INLINE struct sk_buff* eth_skb_alloc(mv_eth_priv *priv, MV_PKT_INFO* pPkt
         ETH_STAT_ERR(priv->eth_stat.skb_alloc_fail++);
         return NULL;
     }
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
     skb->skb_recycle = eth_skb_recycle;
     skb->hw_cookie = priv;
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NET_SKB_RECYCLE */
 
     ETH_STAT_DBG(priv->eth_stat.skb_alloc_ok++);
 
@@ -1557,10 +1557,10 @@ void	mv_eth_config_show(void)
                     eth_skb_reuse_enable ? "Enabled" : "Disabled");
 #endif /* CONFIG_MV_ETH_SKB_REUSE */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
 	printk("  o SKB Recycle supported - (%s)\n", 
                     eth_skb_recycle_enable ? "Enabled" : "Disabled");
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NET_SKB_RECYCLE */
 
 #if defined(CONFIG_MV_GATEWAY)
     printk("  o Gateway support enabled\n");
@@ -1711,9 +1711,9 @@ int     mv_eth_stop_internals(mv_eth_priv *priv)
     }
 #endif /* CONFIG_MV_ETH_NFP || CONFIG_MV_ETH_SKB_REUSE */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
 	eth_skb_recycle_clear(priv);
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NET_SKB_RECYCLE */
 
     /* Reset Rx descriptors ring */
     for(queue=0; queue<MV_ETH_RX_Q_NUM; queue++)
@@ -1764,7 +1764,7 @@ int     mv_eth_change_mtu_internals( struct net_device *dev, int mtu )
 
     dev->mtu = mtu;
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
 	eth_skb_recycle_clear(priv);
 #endif
 
@@ -2008,14 +2008,14 @@ int __init mv_eth_priv_init(mv_eth_priv *priv, int port)
     }
 #endif /* CONFIG_MV_ETH_SKB_REUSE */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
     priv->skbRecycleMTU = 0;
     priv->skbRecyclePool = mvStackCreate(1024);
     if (!priv->skbRecyclePool) {
         printk("%s: port %d, failed to allocate pool\n", __FUNCTION__, port);
         return -ENOMEM;
     }	
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NET_SKB_RECYCLE */
 
 #ifdef ETH_MV_TX_EN
     priv->tx_en = priv->tx_en_bk = MV_ETH_TX_EN_DEFAULT;
@@ -2053,13 +2053,13 @@ void    mv_eth_priv_cleanup(mv_eth_priv *priv)
     }
 #endif /* CONFIG_MV_ETH_SKB_REUSE */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
     if (priv->skbRecyclePool) 
 	{
 		mvStackDelete(priv->skbRecyclePool);
 		priv->skbRecyclePool = NULL;
     }
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NET_SKB_RECYCLE */
 
 #ifdef CONFIG_MV_ETH_NFP
 #else
@@ -3058,13 +3058,13 @@ void    mv_eth_status_print( unsigned int port )
     printk("\n");
 #endif /* CONFIG_MV_ETH_SKB_REUSE */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
     printk("SKB Recycle - %s, min skb size=%d, skbRecyclePool status:\n", 
             eth_skb_recycle_enable ? "Enabled" : "Disabled",
             priv->skbRecycleMTU);
     mvStackStatus(priv->skbRecyclePool, 0);
     printk("\n");
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NET_SKB_RECYCLE */
 
 #ifdef ETH_LRO
 	{
@@ -3176,14 +3176,14 @@ void mv_eth_stats_print( unsigned int port )
         printk( "skb_reuse_alloc...............%10u\n", stat->skb_reuse_alloc);
 #endif /* CONFIG_MV_ETH_SKB_REUSE */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
 	printk("\n");
         printk( "skb_recycle_put...............%10u\n", stat->skb_recycle_put);
         printk( "skb_recycle_get...............%10u\n", stat->skb_recycle_get);
 	printk( "skb_recycle_full..............%10u\n", stat->skb_recycle_full);
 	printk( "skb_recycle_del...............%10u\n", stat->skb_recycle_del);
 	printk( "skb_recycle_rej...............%10u\n", stat->skb_recycle_rej);
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NET_SKB_RECYCLE */
 
         printk("\n");
 
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.h
index 01240f9..f03337f 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_network/mv_ethernet/mv_netdev.h
@@ -225,9 +225,9 @@ typedef struct _eth_statistics
     u32 skb_reuse_rx, skb_reuse_tx, skb_reuse_alloc;
 #endif /* CONFIG_MV_ETH_SKB_REUSE */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
 	u32 skb_recycle_put, skb_recycle_get, skb_recycle_full, skb_recycle_del, skb_recycle_rej;
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NET_SKB_RECYCLE */
 
 #endif /* CONFIG_MV_ETH_STATS_DEBUG */
 
@@ -269,10 +269,10 @@ typedef struct _mv_eth_priv
     MV_STACK*       skbReusePool;
 #endif /* CONFIG_MV_ETH_SKB_REUSE */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
 	 MV_STACK*		skbRecyclePool;
 	 unsigned int	skbRecycleMTU;
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NET_SKB_RECYCLE */
 
 #ifdef CONFIG_MV_ETH_NFP
     MV_FP_STATS     fpStats;
@@ -344,9 +344,9 @@ extern int                  mv_eth_ports_num;
 extern int eth_skb_reuse_enable;
 #endif /* CONFIG_MV_ETH_SKB_REUSE */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_NET_SKB_RECYCLE
 extern int eth_skb_recycle_enable;
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_NET_SKB_RECYCLE */
 
 static INLINE int  mv_eth_tos_to_q_map(unsigned char tos, unsigned char num_of_queues)
 {
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig
index 7cd583c..485748d 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Kconfig
@@ -8,6 +8,16 @@ config MV_ETH_PP2_1
 	* TX descriptors chunks mechanism
 	* See PPv2.1 MAS for more info
 
+config MV_PP2_HWF
+	bool "Enable PPv2 Harware Forwarding"
+	default y
+	---help---
+	HWF are not shared between PP2 and NETA
+	PP2 and NETA can enable or disable HWF depdently
+	The default status is enable
+	Please note other options depend on it
+	Configuration is changable in Run-Time
+
 config MV_ETH_PP2_CLS2
 	bool
 	default y
@@ -28,20 +38,15 @@ config MV_ETH_PP2_CLS_MC
 	default y
 	---help---
 
-config MV_ETH_HWF
-	bool "Enable Harware Forwarding"
-	default y
-	---help---
-
-menu "BM configuration"
+menu "PP2 BM configuration"
 
 choice
-	prompt "BM pool assignment mode"
-	default MV_ETH_BM_SWF_HWF_MODE
+	prompt "PP2 BM pool assignment mode"
+	default MV_PP2_BM_SWF_HWF_MODE
 	---help---
 	Determines how BM pools are divided among GBE ports
 
-config MV_ETH_BM_SWF_HWF_MODE
+config MV_PP2_BM_SWF_HWF_MODE
 	bool "SWF / HWF seperation"
 	---help---
 	BM pools are not shared between SWF and HWF.
@@ -49,7 +54,7 @@ config MV_ETH_BM_SWF_HWF_MODE
 	When BM pool is used only by HWF, then SW can allocate smaller buffers for same packet size
 	Configuration is changable in Run-Time
 
-config MV_ETH_BM_PER_PORT_MODE
+config MV_PP2_BM_PER_PORT_MODE
 	bool "Per Port"
 	---help---
 	BM pools are shared beteen HWF and SWF.
@@ -59,112 +64,130 @@ config MV_ETH_BM_PER_PORT_MODE
 
 endchoice
 
-config MV_ETH_BM_LONG_BUF_NUM
-	int "number of buffers for BM long pool"
+config MV_PP2_BM_LONG_BUF_NUM
+	int "number of buffers for PP2 BM long pool"
 	default 1024
 	---help---
 	The number of long buffers is relevant for all long BM pools
 
-config MV_ETH_BM_SHORT_BUF_NUM
-	int "number of buffers for BM short pool"
+config MV_PP2_BM_SHORT_BUF_NUM
+	int "number of buffers for PP2 BM short pool"
 	default 2048
 	---help---
 	The number of short buffers is relevant for all short BM pools
 
 endmenu
 
-menu "Rx/Tx Queue configuration"
-
-config  MV_ETH_RXQ
-        int "Number of RX queues per port"
-        default 8
-        ---help---
-          Multiple RX queue support.
+menu "PP2 Rx/Tx Queue configuration"
 
-config  MV_ETH_TXQ
-        int "Number of TX queues"
-        default 1
-        ---help---
-          Multiple TX queue support.
+config MV_PP2_RXQ
+	int "Number of RX queues per port"
+	default 8
+	---help---
+	Multiple RX queue support.
+	PP2 module exvlusive.
+	Neta module has its own macro.
+	Note the option depends on it.
+
+config  MV_PP2_TXQ
+	int "Number of TX queues"
+	default 1
+	---help---
+	Multiple TX queue support.
+	PP2 module exvlusive.
+	Neta module has its own macro.
+	Note the option depends on it.
 
-config MV_ETH_RXQ_DESC
+config MV_PP2_RXQ_DESC
 	int "Number of Rx descriptors"
 	depends on MV_ETH_PP2
 	default 128
-        ---help---
+	---help---
 	The number of Rx descriptors in each Rx queue.
+	PP2 driver excludsive, NETA driver has its own option.
+	It depends on definetion of MV_ETH_PP2.
+	Please note other options depend on it.
 
-config MV_ETH_RXQ_DEF
+config MV_PP2_RXQ_DEF
         int "Default RXQ to recieve packets"
         default 0
         ---help---
 
-config MV_ETH_TXQ_DESC
+config MV_PP2_TXQ_DESC
 	int "Number of Tx descriptors"
 	depends on MV_ETH_PP2
 	default 532
         ---help---
 	The number of Tx descriptors in each Tx queue.
 
-config MV_ETH_TXQ_DEF
+config MV_PP2_TXQ_DEF
         int "Default TXQ to send local generated packets"
         default 0
         ---help---
 
-config MV_ETH_TXQ_HWF_DESC
+config MV_PP2_TXQ_HWF_DESC
 	int "Number of HWF Tx descriptors"
 	depends on (MV_ETH_PP2 && !MV_ETH_PP2_1)
 	default 16
         ---help---
 	The number of HWF dedicated Tx descriptors in each Tx queue.
 
-config MV_ETH_AGGR_TXQ_SIZE
+config MV_PP2_AGGR_TXQ_SIZE
 	int "Number of aggregated Tx descriptors"
 	depends on MV_ETH_PP2
 	default 256
         ---help---
 	The number of Tx descriptors in each aggregated Tx queue.
 
-config MV_ETH_TEMP_TXQ_SIZE
+config MV_PP2_TEMP_TXQ_SIZE
 	int "Number of temporary Txq descriptors (for switching between HWF and SWF)"
-	depends on (MV_ETH_PP2 && MV_ETH_HWF)
+	depends on (MV_ETH_PP2 && MV_PP2_HWF)
 	default 512
         ---help---
 
-config MV_ETH_TEMP_TXQ_HWF_SIZE
+config MV_PP2_TEMP_TXQ_HWF_SIZE
 	int "Number of temporary Txq HWF descriptors (for switching between HWF and SWF)"
-	depends on (MV_ETH_PP2 && MV_ETH_HWF)
+	depends on (MV_ETH_PP2 && MV_PP2_HWF)
 	default 256
         ---help---
 
 endmenu
 
-menu "IP/TCP/UDP Offloading"
+menu "PP2 IP/TCP/UDP Offloading"
 
-config  MV_ETH_TSO
-        bool "TSO Support for Marvell network interface"
+config  MV_PP2_TSO
+	bool "TSO Support for Marvell network interface"
 	default y
-        ---help---
-        Marvell network driver compiled with TSO (TCP Segmentation Offload) support.
+	---help---
+	Marvell network driver compiled with TSO (TCP Segmentation Offload) support.
+	The default status is enable
+	Please note other options depend on it
+	Configuration is changable in Run-Time
 
 endmenu
 
-menu "Control and Statistics"
+menu "PP2 Control and Statistics"
 
-config  MV_ETH_DEBUG_CODE
+config  MV_PP2_DEBUG_CODE
+	depends on MV_ETH_DEBUG_CODE
 	bool "Add run-time debug code"
 	default n
 	---help---
-	Enable run-time enable/disable enter debug code blocks
+	Enable run-time enable/disable enter debug code blocks.
+	PP2 driver excluded.
+	NETA driver have their own HWF option.
+	Please note other options depend on it.
 
-config  MV_ETH_STAT_ERR
+config  MV_PP2_STAT_ERR
         bool "Collect error statistics"
         default y
 	---help---
 	Marvell network interface driver collect minimal number of statistics.
 	Only for error conditions. Can be displayed using mv_eth_tool.
+	PP2 driver excluded.
+	Please note other options depend on it.
 
-config  MV_ETH_STAT_INF
+config  MV_PP2_STAT_INF
         bool "Collect event statistics"
         default y
         ---help---
@@ -172,14 +195,14 @@ config  MV_ETH_STAT_INF
 	Provide more information about driver functionality and almost doesn't
 	effect performance. Can be displayed using mv_eth_tool.
 
-config  MV_ETH_STAT_DBG
+config  MV_PP2_STAT_DBG
         bool "Collect debug statistics"
         default n
         ---help---
 	Marvell network interface driver collect a lot of statistics.
 	Used for Debug mode. Decrease performance. Can be displayed using mv_eth_tool.
 
-config  MV_ETH_STAT_DIST
+config  MV_PP2_STAT_DIST
         bool "Collect debug distribution statistics"
         default n
         ---help---
@@ -190,102 +213,112 @@ endmenu
 
 menu "Advanced Features"
 
-config  NET_SKB_HEADROOM
-        int "SKB headroom size"
-        default 64
-        ---help---
-          Customize SKB headroom size. Must be power of 2.
-
-config NET_SKB_RECYCLE
-        bool "Skb recycle"
-        default y
-        ---help---
-          Work-in-progress and experimental.
+config MV_PP2_SKB_RECYCLE
+	depends on NET_SKB_RECYCLE
+	bool "PP2 Skb recycle"
+	default y
+	---help---
+	Work-in-progress and experimental.
 
-          This option enables skb's to be returned via a callback at kfree to
-          the allocator to make a fastpath for very skb consuming network
-          applications.
+	This option enables skb's to be returned via a callback at kfree to
+	the allocator to make a fastpath for very skb consuming network
+	applications.
 
-config NET_SKB_RECYCLE_DEF
-        depends on NET_SKB_RECYCLE
-        int "Default value for SKB recycle:  0 - disable, 1 - enable"
-        default 1
-        ---help---
+config MV_PP2_SKB_RECYCLE_DEF
+	depends on MV_PP2_SKB_RECYCLE
+	int "Default value for SKB recycle:  0 - disable, 1 - enable"
+	default 1
+	---help---
 
-config  MV_ETH_TX_DONE_TIMER_PERIOD
+config MV_PP2_TX_DONE_TIMER_PERIOD
         int "Periodical Tx Done timer period"
         default 10
         ---help---
           Periodical timer period for Tx Done operation in [msec].
 
-config  MV_ETH_CLEANUP_TIMER_PERIOD
+config MV_PP2_CLEANUP_TIMER_PERIOD
         int "Periodical Cleanup timer period"
         default 10
         ---help---
           Periodical timer period for cleanup operation in [msec].
 
-config  MV_ETH_TXDONE_ISR
+config MV_PP2_TXDONE_ISR
 	bool "Use interrupt to process TX_DONE event"
 	default n
 	---help---
 	When chosen TX_DONE event will be process in interrupt mode
 	When unchosen TX_DONE event will be processed in polling mode
+	The default status is disable
+	Please note other options depend on it
 
-config  MV_ETH_TXDONE_COAL_PKTS
+config MV_PP2_TXDONE_COAL_PKTS
 	int "Threshold for TX_DONE event trigger"
 	default 16
 	---help---
 	Number of packets will be sent before TX_DONE event will be triggered
 	by interrupt or polling.
 
-config  MV_ETH_RX_COAL_PKTS
+config MV_PP2_RX_COAL_PKTS
         int "Threshold [number of packets] for RX interrupt"
         default 32
         ---help---
         Number of packets will be received before RX interrupt will be generated by HW.
 
-config  MV_ETH_RX_COAL_USEC
+config MV_PP2_RX_COAL_USEC
         int "Threshold [usec] for RX interrupt"
         default 100
         ---help---
         Time delay in usec before RX interrupt will be generated by HW if number of
 	received packets larger than 0 but smaller than MV_ETH_RX_COAL_PKTS
 
-config  MV_ETH_RX_DESC_PREFETCH
+config MV_PP2_RX_DESC_PREFETCH
 	bool "Enable RX descriptor prefetch"
 	default n
 	---help---
 	Use pld instruction to prefetch one RX descriptor ahead
+	The default status is disable
+	Please note other options depend on it
+	Configuration is changable in Run-Time
 
-config  MV_ETH_RX_PKT_PREFETCH
-        bool "Enable RX packet prefetch"
-        default n
-        ---help---
-        Use pld instruction to prefetch first two cache lines of received packet data
+config MV_PP2_RX_PKT_PREFETCH
+	bool "Enable RX packet prefetch"
+	default n
+	---help---
+	Use pld instruction to prefetch first two cache lines of received packet data
+	The default status is disable
+	Please note other options depend on it
+	Configuration is changable in Run-Time
 
-config MV_ETH_RX_SPECIAL
-        bool "Enable special RX processing"
-        default n
-        ---help---
-        Enable special RX processing for packets with RI_RX_SEPCIAL PNC result info bit set
+config MV_PP2_RX_SPECIAL
+	bool "Enable special RX processing"
+	default n
+	---help---
+	Enable special RX processing for packets with RI_RX_SEPCIAL PNC result info bit set
+	The default status is disable
+	Please note other options depend on it
+	Configuration is changable in Run-Time
 
-config MV_ETH_TX_SPECIAL
+config MV_PP2_TX_SPECIAL
 	bool "Enable special TX processing"
 	default n
 	---help---
 	Enable special TX processing for packets with signal header (SH)
+	The default status is disable
+	Please note other options depend on it
+	Configuration is changable in Run-Time
 
-config MV_ETH_L2FW
+config MV_PP2_L2FW
 	bool "L2 Forwarding support"
 	default n
 	---help---
 	Enable L2 Forwarding support for received packets.
 	Three modes are supported: Send packet without change, Swap MAC DA<->SA,
 	Copy the whole packet and swap MAC
+	The default status is disable
 
-config MV_ETH_L2FW_XOR
+config MV_PP2_L2FW_XOR
         bool "L2 Forwarding XOR support"
-        depends on MV_ETH_L2FW && MV_INCLUDE_XOR
+        depends on MV_PP2_L2FW && MV_INCLUDE_XOR
         default n
         ---help---
         Enable using XOR engine to copy ingress packets during L2FW processing.
@@ -293,28 +326,34 @@ config MV_ETH_L2FW_XOR
 	larger than XOR threshold (default value is 2000 bytes).
 	XOR threshold can be changes using sysfs command.
 
-config MV_ETH_L2SEC
+config MV_PP2_L2SEC
 	bool "L2 Forwarding IPSec support"
-	depends on MV_ETH_L2FW
+	depends on MV_PP2_L2FW
 	default n
 	---help---
 	Handle encrypted packets with CESA.
+	PP2 driver excluded.
+	NETA driver have their own HWF option.
+	Please note other options depend on it.
 
-config MV_ETH_L2FW_DEBUG
-	depends on MV_ETH_L2FW
+config MV_PP2_L2FW_DEBUG
+	depends on (MV_PP2_L2FW && MV_PP2_DEBUG_CODE)
 	bool "Add run-time L2FW debug code"
 	default n
 	---help---
 	Enable L2FW run-time enable/disable enter debug code blocks
+	PP2 driver excluded.
+	NETA driver have their own HWF option.
+	Please note other options depend on it.
 
-config MV_ETH_RX_POLL_WEIGHT
+config MV_PP2_RX_POLL_WEIGHT
 	int "poll weight for the RX poll() function"
 	default 64
 	range 1 255
 	---help---
 	poll weight for the RX poll() function; must be less or equal to 255
 
-config MV_ETH_EXTRA_BUF_SIZE
+config MV_PP2_EXTRA_BUF_SIZE
 	int "Extra buffer size in bytes"
 	default 120
 	range 120 16384
@@ -322,35 +361,51 @@ config MV_ETH_EXTRA_BUF_SIZE
 	Size of buffers allocated for extra pool and used in special cases like TSO,
 	fragmentattion and others
 
-config MV_ETH_EXTRA_BUF_NUM
+config MV_PP2_EXTRA_BUF_NUM
         int "Number of extra buffers allocated for each port"
-        default MV_ETH_TXQ_DESC
+        default MV_PP2_TXQ_DESC
 	---help---
 	Number of extra buffers allocated for each port
 endmenu
 
 menu "PON support for Network driver"
-	depends on MV_INCLUDE_PON
-
-config MV_PON_TXP_DEF
-        int "Default T-CONT to send local generated packets"
-        depends on MV_INCLUDE_PON
-        default 0
-        ---help---
 
-config MV_PON_TXQ_DEF
-        int "Default TXQ to send local generated packets"
-        depends on MV_INCLUDE_PON
-        default 0
-        ---help---
+config MV_PP2_PON
+	bool "PP2 PON support"
+	depends on MV_ETH_PP2 && MV_INCLUDE_PON
+	---help---
+	Choose this option to support PON port in Marvell network driver.
+	PP2 driver excluded.
+	NETA driver have their own HWF option.
+	Please note other options depend on it.
+
+config MV_PP2_PON_TXP_DEF
+	int "Default T-CONT to send local generated packets"
+	depends on MV_PP2_PON
+	default 0
+	---help---
+	Define T-CONT to send local generated packets
+	PP2 module exvlusive.
+	Neta module has its own macro.
+	Note the option depends on it.
+
+config MV_PP2_PON_TXQ_DEF
+	int "Default TXQ to send local generated packets"
+	depends on MV_PP2_PON
+	default 0
+	---help---
+	Define TXQ to send local generated packets
+	PP2 module exvlusive.
+	Neta module has its own macro.
+	Note the option depends on it.
 
 endmenu
 
-menu "ERRATA / WA"
+menu "PP2 ERRATA / WA"
 
-config MV_ETH_SWF_HWF_CORRUPTION_WA
+config MV_PP2_SWF_HWF_CORRUPTION_WA
         bool "Prevent data corruption in IOCC mode"
-        depends on (AURORA_IO_CACHE_COHERENCY && MV_ETH_HWF)
+        depends on (AURORA_IO_CACHE_COHERENCY && MV_PP2_HWF)
         default y
         ---help---
 	Enable this feature to avoid data corruption in IOCC mode
@@ -362,7 +417,7 @@ menu "SoC CPH support"
 
 config  MV_CPH
         tristate "Support for Marvell CPU Packet Handler Driver"
-        depends on MV_ETH_TX_SPECIAL
+        depends on MV_PP2_TX_SPECIAL
         default n
         ---help---
         CPH is designed mainly for PON product (GPON/EPON),
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Makefile
index df3a570..7d98b78 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Makefile
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Makefile
@@ -40,7 +40,7 @@ mv_pp2-objs += net_dev/mv_eth_rx_sysfs.o net_dev/mv_eth_tx_sysfs.o net_dev/mv_et
 mv_pp2-objs += net_dev/mv_eth_pme_sysfs.o net_dev/mv_eth_pon_sysfs.o
 mv_pp2-objs += net_dev/mv_eth_bm_sysfs.o net_dev/mv_eth_qos_sysfs.o net_dev/mv_eth_dbg_sysfs.o
 
-ifeq ($(CONFIG_MV_ETH_HWF),y)
+ifeq ($(CONFIG_MV_PP2_HWF),y)
 mv_pp2-objs += net_dev/mv_eth_hwf_sysfs.o
 endif
 
@@ -51,7 +51,7 @@ mv_pp2-objs += plcr/plcr_sysfs.o
 mv_pp2-objs += wol/wol_sysfs.o
 mv_pp2-objs += dpi/dpi_sysfs.o
 
-ifeq ($(CONFIG_MV_ETH_L2FW),y)
+ifeq ($(CONFIG_MV_PP2_L2FW),y)
 mv_pp2-objs += l2fw/l2fw_sysfs.o l2fw/mv_eth_l2fw.o
 endif
 
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_app.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_app.c
index da20466..5074423 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_app.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_app.c
@@ -1140,7 +1140,7 @@ MV_STATUS cph_app_mod_rx_packet(
 *******************************************************************************/
 MV_STATUS cph_app_mod_tx_packet(
 	struct sk_buff        *skb,
-	struct mv_eth_tx_spec *tx_spec_out,
+	struct mv_pp2_tx_spec *tx_spec_out,
 	enum CPH_APP_MOD_FIELD_E    mod_bm,
 	struct CPH_APP_MOD_T         *mod_value)
 {
@@ -1178,7 +1178,7 @@ MV_STATUS cph_app_mod_tx_packet(
 *******************************************************************************/
 MV_STATUS cph_app_set_frwd(
 	struct sk_buff        *skb,
-	struct mv_eth_tx_spec *tx_spec_out,
+	struct mv_pp2_tx_spec *tx_spec_out,
 	enum CPH_APP_FRWD_FIELD_E   frwd_bm,
 	struct CPH_APP_FRWD_T        *frwd_value)
 {
@@ -1252,7 +1252,7 @@ int cph_app_rx_bc(int port, struct net_device *dev, struct sk_buff *skb, struct
 		}
 
 		/* Forward packet */
-		if (netif_running(mv_eth_ports[peer_port]->dev)) {
+		if (netif_running(mv_pp2_ports[peer_port]->dev)) {
 			/* Copy a new SKB */
 			skb_old->tail += rx_desc->dataSize;
 			skb_old->len   = rx_desc->dataSize;
@@ -1261,7 +1261,7 @@ int cph_app_rx_bc(int port, struct net_device *dev, struct sk_buff *skb, struct
 				skb_new = skb_old;
 				goto out;
 			}
-			mv_eth_ports[peer_port]->dev->netdev_ops->ndo_start_xmit(skb_old, mv_eth_ports[peer_port]->dev);
+			mv_pp2_ports[peer_port]->dev->netdev_ops->ndo_start_xmit(skb_old, mv_pp2_ports[peer_port]->dev);
 		}
 	}
 out:
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_app.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_app.h
index dbce709..d4dca2b 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_app.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_app.h
@@ -591,7 +591,7 @@ MV_STATUS cph_app_mod_rx_packet(
 *******************************************************************************/
 MV_STATUS cph_app_mod_tx_packet(
 	struct sk_buff        *skb,
-	struct mv_eth_tx_spec *tx_spec_out,
+	struct mv_pp2_tx_spec *tx_spec_out,
 	enum CPH_APP_MOD_FIELD_E    mod_bm,
 	struct CPH_APP_MOD_T         *mod_value);
 
@@ -616,7 +616,7 @@ MV_STATUS cph_app_mod_tx_packet(
 *******************************************************************************/
 MV_STATUS cph_app_set_frwd(
 	struct sk_buff        *skb,
-	struct mv_eth_tx_spec *tx_spec_out,
+	struct mv_pp2_tx_spec *tx_spec_out,
 	enum CPH_APP_FRWD_FIELD_E   frwd_bm,
 	struct CPH_APP_FRWD_T        *frwd_value);
 
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_flow.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_flow.c
index 30f139a..87f1e82 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_flow.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_flow.c
@@ -2449,7 +2449,7 @@ MV_STATUS cph_flow_mod_packet(struct sk_buff *skb,  bool mh, struct CPH_FLOW_ENT
 *       On success, the function returns MV_OK.
 *       On error returns error code accordingly.
 *******************************************************************************/
-MV_STATUS cph_flow_mod_frwd(struct CPH_FLOW_ENTRY_T *flow, struct mv_eth_tx_spec *tx_spec_out)
+MV_STATUS cph_flow_mod_frwd(struct CPH_FLOW_ENTRY_T *flow, struct mv_pp2_tx_spec *tx_spec_out)
 {
 	MV_STATUS rc = MV_OK;
 
@@ -2488,13 +2488,13 @@ MV_STATUS cph_flow_mod_frwd(struct CPH_FLOW_ENTRY_T *flow, struct mv_eth_tx_spec
 *       On error returns 0.
 *******************************************************************************/
 MV_STATUS cph_flow_send_packet(struct net_device *dev_out, struct eth_pbuf *pkt,
-	struct mv_eth_tx_spec *tx_spec_out)
+	struct mv_pp2_tx_spec *tx_spec_out)
 {
 #if 0
 	struct eth_port *pp = MV_ETH_PRIV(dev_out);
 	int frags = 0;
 	bool tx_spec_ready = false;
-	struct mv_eth_tx_spec tx_spec;
+	struct mv_pp2_tx_spec tx_spec;
 	u32 tx_cmd;
 	struct tx_queue *txq_ctrl = NULL;
 	struct pp2_tx_desc *tx_desc;
@@ -2518,7 +2518,7 @@ MV_STATUS cph_flow_send_packet(struct net_device *dev_out, struct eth_pbuf *pkt,
 		tx_spec.flags  = tx_spec_out->flags;
 	}
 
-	txq_ctrl = &pp->txq_ctrl[tx_spec.txp * CONFIG_MV_ETH_TXQ + tx_spec.txq];
+	txq_ctrl = &pp->txq_ctrl[tx_spec.txp * CONFIG_MV_PP2_TXQ + tx_spec.txq];
 	if (txq_ctrl == NULL) {
 		pr_err("%s: invalidate txp/txq (%d/%d)\n", __func__, tx_spec.txp, tx_spec.txq);
 		goto out;
@@ -2526,13 +2526,13 @@ MV_STATUS cph_flow_send_packet(struct net_device *dev_out, struct eth_pbuf *pkt,
 	spin_lock_irqsave(&txq_ctrl->queue_lock);
 
 #if 0
-#ifdef CONFIG_MV_ETH_TSO
+#ifdef CONFIG_MV_PP2_TSO
 	/* GSO/TSO */
 	if (skb_is_gso(skb)) {
-		frags = mv_eth_tx_tso(skb, dev_out, &tx_spec, txq_ctrl);
+		frags = mv_pp2_tx_tso(skb, dev_out, &tx_spec, txq_ctrl);
 		goto out;
 	}
-#endif /* CONFIG_MV_ETH_TSO */
+#endif /* CONFIG_MV_PP2_TSO */
 #endif
 
 	frags = 1;
@@ -2544,13 +2544,13 @@ MV_STATUS cph_flow_send_packet(struct net_device *dev_out, struct eth_pbuf *pkt,
 		else
 			mh = pp->tx_mh;
 
-		if (mv_eth_skb_mh_add(skb, mh)) {
+		if (mv_pp2_skb_mh_add(skb, mh)) {
 			frags = 0;
 			goto out;
 		}
 	}
 #endif
-	tx_desc = mv_eth_tx_desc_get(txq_ctrl, frags);
+	tx_desc = mv_pp2_tx_desc_get(txq_ctrl, frags);
 	if (tx_desc == NULL) {
 		frags = 0;
 		goto out;
@@ -2558,7 +2558,7 @@ MV_STATUS cph_flow_send_packet(struct net_device *dev_out, struct eth_pbuf *pkt,
 
 	tx_cmd = PP2_TX_L4_CSUM_NOT;
 
-#ifdef CONFIG_MV_PON
+#ifdef CONFIG_MV_PP2_PON
 	tx_desc->hw_cmd[0] = tx_spec.hw_cmd[0];
 #endif
 
@@ -2577,28 +2577,28 @@ MV_STATUS cph_flow_send_packet(struct net_device *dev_out, struct eth_pbuf *pkt,
 			tx_cmd |= PP2_TX_FLZ_DESC_MASK;
 
 		tx_desc->command = tx_cmd;
-		mv_eth_tx_desc_flush(tx_desc);
+		mv_pp2_tx_desc_flush(tx_desc);
 
 		txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = ((MV_ULONG) skb | MV_ETH_SHADOW_SKB);
-		mv_eth_shadow_inc_put(txq_ctrl);
+		mv_pp2_shadow_inc_put(txq_ctrl);
 	}
 
 	txq_ctrl->txq_count += frags;
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 	if (pp->flags & MV_ETH_F_DBG_TX) {
 		pr_err("\n");
 		pr_err("%s - eth_tx_%lu: port=%d, txp=%d, txq=%d, skb=%p, head=%p, data=%p, size=%d\n",
 			dev_out->name, dev_out->stats.tx_packets, pp->port, tx_spec.txp, tx_spec.txq, skb,
 			skb->head, skb->data, skb->len);
-		mv_eth_tx_desc_print(tx_desc);
+		mv_pp2_tx_desc_print(tx_desc);
 	}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
-#ifdef CONFIG_MV_PON
-	if (MV_PON_PORT(pp->port))
+#ifdef CONFIG_MV_PP2_PON
+	if (MV_PP2_IS_PON_PORT(pp->port))
 		mvNetaPonTxqBytesAdd(pp->port, tx_spec.txp, tx_spec.txq, skb->len);
-#endif /* CONFIG_MV_PON */
+#endif /* CONFIG_MV_PP2_PON */
 
 	/* Enable transmit */
 	mvPp2AggrTxqPendDescAdd(pp->port, tx_spec.txp, tx_spec.txq, frags);
@@ -2614,18 +2614,18 @@ out:
 		dev_kfree_skb_any(skb);
 	}
 
-#ifndef CONFIG_MV_ETH_TXDONE_ISR
+#ifndef CONFIG_MV_PP2_TXDONE_ISR
 	if (txq_ctrl) {
-		if (txq_ctrl->txq_count >= mv_ctrl_txdone) {
-			u32 tx_done = mv_eth_txq_done(pp, txq_ctrl);
+		if (txq_ctrl->txq_count >= mv_ctrl_pp2_txdone) {
+			u32 tx_done = mv_pp2_txq_done(pp, txq_ctrl);
 			STAT_DIST((tx_done < pp->dist_stats.tx_done_dist_size) ?
 				pp->dist_stats.tx_done_dist[tx_done]++ : 0);
 		}
-		/* If after calling mv_eth_txq_done, txq_ctrl->txq_count equals frags, we need to set the timer */
+		/* If after calling mv_pp2_txq_done, txq_ctrl->txq_count equals frags, we need to set the timer */
 		if ((txq_ctrl->txq_count == frags) && (frags > 0))
-			mv_eth_add_tx_done_timer(pp);
+			mv_pp2_add_tx_done_timer(pp);
 	}
-#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+#endif /* CONFIG_MV_PP2_TXDONE_ISR */
 
 	if (txq_ctrl)
 		spin_unlock_irqrestore(&txq_ctrl->queue_lock);
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_flow.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_flow.h
index a7b8e6f..c14ff07 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_flow.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_flow.h
@@ -584,7 +584,7 @@ MV_STATUS cph_flow_mod_packet(struct sk_buff *skb,  bool mh, struct CPH_FLOW_ENT
 *       On success, the function returns MV_OK.
 *       On error returns error code accordingly.
 *******************************************************************************/
-MV_STATUS cph_flow_mod_frwd(struct CPH_FLOW_ENTRY_T *flow, struct mv_eth_tx_spec *tx_spec_out);
+MV_STATUS cph_flow_mod_frwd(struct CPH_FLOW_ENTRY_T *flow, struct mv_pp2_tx_spec *tx_spec_out);
 
 /******************************************************************************
 * cph_flow_send_packet()
@@ -605,7 +605,7 @@ MV_STATUS cph_flow_mod_frwd(struct CPH_FLOW_ENTRY_T *flow, struct mv_eth_tx_spec
 *       On error returns 0.
 *******************************************************************************/
 MV_STATUS cph_flow_send_packet(struct net_device *dev_out,  struct eth_pbuf *pkt,
-	struct mv_eth_tx_spec *tx_spec_out);
+	struct mv_pp2_tx_spec *tx_spec_out);
 
 /******************************************************************************
 * cph_flow_db_get_rule()
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_header.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_header.h
index 7fee81f..8414213 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_header.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_header.h
@@ -82,7 +82,7 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 /* Include Files
 ------------------------------------------------------------------------------*/
 #include <mvCommon.h>
-#include <mv_pp2/net_dev/mv_netdev.h>
+#include <../net_dev/mv_netdev.h>
 
 #include "mv_cph_infra.h"
 #include "mv_cph_app.h"
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_netdev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_netdev.c
index 2d7b41b..ef349ab 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_netdev.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_netdev.c
@@ -86,8 +86,6 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #include <net/ipv6.h>
 #include <linux/icmpv6.h>
 
-#include <ctrlEnv/mvCtrlEnvLib.h>
-
 #include "mvDebug.h"
 #include "mv_cph_header.h"
 
@@ -134,13 +132,13 @@ void cph_rec_skb(int port, struct sk_buff *skb)
 	struct eth_port *pp = NULL;
 
 	rx_status = netif_receive_skb(skb);
-	pp        = mv_eth_port_by_id(port);
+	pp        = mv_pp2_port_by_id(port);
 	if (rx_status)
 		STAT_DBG(pp->stats.rx_drop_sw++);
 }
 
 #ifdef CONFIG_MV_CPH_UDP_SAMPLE_HANDLE
-static inline void cph_copy_tx_spec(struct mv_eth_tx_spec *tx_spec,
+static inline void cph_copy_tx_spec(struct mv_pp2_tx_spec *tx_spec,
 					uint8_t txp, uint8_t txq,
 					uint16_t flags, uint32_t hw_cmd)
 {
@@ -153,7 +151,7 @@ static inline void cph_copy_tx_spec(struct mv_eth_tx_spec *tx_spec,
 int cph_udp_spec_print(int port)
 {
 	int i;
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	struct mv_udp_port_tx_spec *udp_spec;
 
 	if (!pp)
@@ -230,7 +228,7 @@ MV_STATUS  cph_udp_int_spec_set(struct mv_udp_port_tx_spec *udp_spec, uint16_t u
 MV_STATUS  cph_udp_src_spec_set(int tx_port, uint16_t udp_src_port, uint8_t txp,
 	uint8_t txq, uint16_t flags, uint32_t hw_cmd)
 {
-	struct eth_port *pp = mv_eth_port_by_id(tx_port);
+	struct eth_port *pp = mv_pp2_port_by_id(tx_port);
 	struct mv_udp_port_tx_spec *udp_src_spec = udp_port_spec_cfg[tx_port].udp_src;
 	MV_STATUS mv_status;
 
@@ -252,7 +250,7 @@ EXPORT_SYMBOL(cph_udp_src_spec_set);
 MV_STATUS  cph_udp_dest_spec_set(int tx_port, uint16_t udp_dest_port, uint8_t txp,
 	uint8_t txq, uint16_t flags, uint32_t hw_cmd)
 {
-	struct eth_port *pp = mv_eth_port_by_id(tx_port);
+	struct eth_port *pp = mv_pp2_port_by_id(tx_port);
 	struct mv_udp_port_tx_spec *udp_dst_spec = udp_port_spec_cfg[tx_port].udp_dst;
 	MV_STATUS mv_status;
 
@@ -297,7 +295,7 @@ void cph_udp_table_init(void)
 }
 
 int cph_udp_port_tx(int port, struct net_device *dev, struct sk_buff *skb,
-		struct mv_eth_tx_spec *tx_spec_out)
+		struct mv_pp2_tx_spec *tx_spec_out)
 {
 	struct iphdr  *iphdrp   = NULL;
 	struct udphdr *udphdrp  = NULL;
@@ -330,7 +328,7 @@ int cph_udp_port_tx(int port, struct net_device *dev, struct sk_buff *skb,
 					if ((udphdrp->source == udp_port_spec_cfg[port].udp_src[i].udp_port) &&
 					(udp_port_spec_cfg[port].udp_src[i].tx_spec.txq != MV_ETH_TXQ_INVALID)) {
 						memcpy(tx_spec_out, &(udp_port_spec_cfg[port].udp_src[i].tx_spec),
-							sizeof(struct mv_eth_tx_spec));
+							sizeof(struct mv_pp2_tx_spec));
 						MV_CPH_PRINT(CPH_DEBUG_LEVEL, "found udp_src 0x(%04x)\n",
 							ntohs(udphdrp->source));
 						return 1;
@@ -341,7 +339,7 @@ int cph_udp_port_tx(int port, struct net_device *dev, struct sk_buff *skb,
 					if ((udphdrp->dest == udp_port_spec_cfg[port].udp_dst[i].udp_port) &&
 					(udp_port_spec_cfg[port].udp_src[i].tx_spec.txq != MV_ETH_TXQ_INVALID)) {
 						memcpy(tx_spec_out, &(udp_port_spec_cfg[port].udp_dst[i].tx_spec),
-							sizeof(struct mv_eth_tx_spec));
+							sizeof(struct mv_pp2_tx_spec));
 						MV_CPH_PRINT(CPH_DEBUG_LEVEL, "found udp_dst 0x(%04x)\n",
 							ntohs(udphdrp->dest));
 						return 1;
@@ -449,7 +447,7 @@ static int cph_data_flow_rx(int port, struct net_device *dev, struct sk_buff *sk
 *       On error returns 0.
 *******************************************************************************/
 int cph_data_flow_tx(int port, struct net_device *dev, struct sk_buff *skb,
-			bool mh, struct mv_eth_tx_spec *tx_spec_out)
+			bool mh, struct mv_pp2_tx_spec *tx_spec_out)
 {
 	struct CPH_FLOW_ENTRY_T flow_rule;
 	int            offset = 0;
@@ -630,7 +628,7 @@ static int cph_app_packet_rx(int port, struct net_device *dev, struct sk_buff *s
 *       On error returns 0.
 *******************************************************************************/
 int cph_app_packet_tx(int port, struct net_device *dev, struct sk_buff *skb,
-			struct mv_eth_tx_spec *tx_spec_out)
+			struct mv_pp2_tx_spec *tx_spec_out)
 {
 	enum CPH_DIR_E             dir;
 	unsigned short                proto_type = 0;
@@ -728,7 +726,7 @@ int cph_app_packet_tx(int port, struct net_device *dev, struct sk_buff *skb,
 *
 * RETURNS:
 *       1: the packet will be handled and forwarded to linux stack in CPH
-*       0: the packet will not be forwarded to linux stack and mv_eth_rx() needs to continue to handle it
+*       0: the packet will not be forwarded to linux stack and mv_pp2_rx() needs to continue to handle it
 *******************************************************************************/
 int cph_rx_func(int port, int rxq, struct net_device *dev,
 		struct sk_buff *skb, struct pp2_rx_desc *rx_desc)
@@ -787,7 +785,7 @@ int cph_rx_func(int port, int rxq, struct net_device *dev,
 *       None.
 *******************************************************************************/
 int cph_tx_func(int port, struct net_device *dev, struct sk_buff *skb,
-		struct mv_eth_tx_spec *tx_spec_out)
+		struct mv_pp2_tx_spec *tx_spec_out)
 {
 	/* Transmit application packets */
 	if (cph_app_packet_tx(port, dev, skb, tx_spec_out))
@@ -828,8 +826,8 @@ int cph_netdev_init(void)
 {
 	unsigned int idx;
 
-	/* Retrieve Eth port number, as in mv_eth_init_module */
-	gs_mv_eth_port_num = mvCtrlEthMaxPortGet();
+	/* Retrieve Eth port number, TODO list */
+	gs_mv_eth_port_num = MV_ETH_MAX_PORTS;
 
 	if (gs_mv_eth_port_num > MV_ETH_MAX_PORTS)
 		gs_mv_eth_port_num = MV_ETH_MAX_PORTS;
@@ -848,16 +846,16 @@ int cph_netdev_init(void)
 #endif
 
 	/* Register special receive check function */
-#ifdef CONFIG_MV_ETH_RX_SPECIAL
+#ifdef CONFIG_MV_PP2_RX_SPECIAL
 	for (idx = 0; idx < gs_mv_eth_port_num; idx++)
-		mv_eth_rx_special_proc_func(idx, cph_rx_func);
-#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+		mv_pp2_rx_special_proc_func(idx, cph_rx_func);
+#endif /* CONFIG_MV_PP2_RX_SPECIAL */
 
 	/* Register special transmit check function */
-#ifdef CONFIG_MV_ETH_TX_SPECIAL
+#ifdef CONFIG_MV_PP2_TX_SPECIAL
 	for (idx = 0; idx < gs_mv_eth_port_num; idx++)
-		mv_eth_tx_special_check_func(idx, cph_tx_func);
-#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+		mv_pp2_tx_special_check_func(idx, cph_tx_func);
+#endif /* CONFIG_MV_PP2_TX_SPECIAL */
 
 	/* enable all T-CONT by default, whill remove it once callback implmented*/
 	for (idx = 0; idx < MV_TCONT_LLID_NUM; idx++)
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_netdev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_netdev.h
index 80b82a4..8dfa722 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_netdev.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/cph/mv_cph_netdev.h
@@ -91,7 +91,7 @@ extern "C" {
 
 #include <mvCommon.h>
 #include <mvOs.h>
-#include <mv_pp2/net_dev/mv_netdev.h>
+#include <../net_dev/mv_netdev.h>
 
 
 #define MV_CPH_MAS_UDP_SRC_PORT          8
@@ -102,7 +102,7 @@ extern "C" {
 #ifdef CONFIG_MV_CPH_UDP_SAMPLE_HANDLE
 struct mv_udp_port_tx_spec {
 	__be16    udp_port;
-	struct mv_eth_tx_spec tx_spec;
+	struct mv_pp2_tx_spec tx_spec;
 };
 
 struct mv_port_tx_spec {
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/l2fw_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/l2fw_sysfs.c
index faa049e..3711b5b 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/l2fw_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/l2fw_sysfs.c
@@ -34,7 +34,7 @@ disclaimer.
 
 #include "mvTypes.h"
 #include "mv_eth_l2fw.h"
-#ifdef CONFIG_MV_ETH_L2SEC
+#ifdef CONFIG_MV_PP2_L2SEC
 #include "mv_eth_l2sec.h"
 #endif
 #include "linux/inet.h"
@@ -56,7 +56,7 @@ static ssize_t mv_l2fw_help(char *buf)
 #ifdef CONFIG_MV_L2FW_XOR
 	off += sprintf(buf+off, "echo rxp thresh   > xor      - Set XOR threshold for port <rxp>\n");
 #endif
-#ifdef CONFIG_MV_ETH_L2SEC
+#ifdef CONFIG_MV_PP2_L2SEC
 	off += sprintf(buf+off, "echo p chan       > cesa     - Set cesa channel <chan> for port <p>.\n");
 #endif
 	return off;
@@ -182,7 +182,7 @@ static ssize_t mv_l2fw_store(struct device *dev,
 	else if (!strcmp(name, "bind"))
 		err = mv_l2fw_port(a, b, c);
 
-#ifdef CONFIG_MV_ETH_L2SEC
+#ifdef CONFIG_MV_PP2_L2SEC
 	else if (!strcmp(name, "cesa_chan"))
 		err = mv_l2sec_set_cesa_chan(a, b);
 #endif
@@ -206,7 +206,7 @@ static DEVICE_ATTR(ports_dump,		S_IRUSR, mv_l2fw_show, NULL);
 static DEVICE_ATTR(stats,		S_IRUSR, mv_l2fw_show, NULL);
 static DEVICE_ATTR(flush,		S_IWUSR, NULL,	mv_l2fw_hex_store);
 
-#ifdef CONFIG_MV_ETH_L2SEC
+#ifdef CONFIG_MV_PP2_L2SEC
 static DEVICE_ATTR(cesa_chan,		S_IWUSR, NULL,  mv_l2fw_store);
 #endif
 #ifdef CONFIG_MV_L2FW_XOR
@@ -228,7 +228,7 @@ static struct attribute *mv_l2fw_attrs[] = {
 	&dev_attr_ports_dump.attr,
 	&dev_attr_flush.attr,
 	&dev_attr_stats.attr,
-#ifdef CONFIG_MV_ETH_L2SEC
+#ifdef CONFIG_MV_PP2_L2SEC
 	&dev_attr_cesa_chan.attr,
 #endif
 	NULL
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c
index b95bd27..c553fed 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c
@@ -28,18 +28,18 @@ disclaimer.
 
 #include <linux/version.h>
 
-#ifdef CONFIG_MV_ETH_L2FW_XOR
+#ifdef CONFIG_MV_PP2_L2FW_XOR
 #include "xor/mvXor.h"
 #include "xor/mvXorRegs.h"
 #include "mv_hal_if/mvSysXorApi.h"
-#endif /* CONFIG_MV_ETH_L2FW_XOR */
+#endif /* CONFIG_MV_PP2_L2FW_XOR */
 
 #include "mv_eth_l2fw.h"
-#include "mv_pp2/net_dev/mv_netdev.h"
+#include "../net_dev/mv_netdev.h"
 #include "gbe/mvPp2Gbe.h"
 #include "mvDebug.h"
 
-#ifdef CONFIG_MV_ETH_L2SEC
+#ifdef CONFIG_MV_PP2_L2SEC
 #include "mv_eth_l2sec.h"
 #endif
 
@@ -47,12 +47,12 @@ static int numHashEntries;
 static int shared;
 
 static struct l2fw_rule **l2fw_hash;
-static struct eth_port_l2fw **mv_eth_ports_l2fw;
+static struct eth_port_l2fw **mv_pp2_ports_l2fw;
 static int eth_ports_l2fw_num;
 
 static MV_U32 l2fw_jhash_iv;
 
-#ifdef CONFIG_MV_ETH_L2FW_XOR
+#ifdef CONFIG_MV_PP2_L2FW_XOR
 static MV_XOR_DESC *eth_xor_desc;
 static MV_LONG      eth_xor_desc_phys_addr;
 #endif
@@ -64,7 +64,7 @@ static int mv_l2fw_port_init(int port);
 static void mv_l2fw_port_free(int port);
 
 static const struct net_device_ops mv_l2fw_netdev_ops;
-static const struct net_device_ops *mv_eth_netdev_ops_ptr;
+static const struct net_device_ops *mv_pp2_netdev_ops_ptr;
 
 static struct l2fw_rule *l2fw_lookup(MV_U32 srcIP, MV_U32 dstIP)
 {
@@ -77,7 +77,7 @@ static struct l2fw_rule *l2fw_lookup(MV_U32 srcIP, MV_U32 dstIP)
 
 	while (rule) {
 		if ((rule->srcIP == srcIP) && (rule->dstIP == dstIP)) {
-#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+#ifdef CONFIG_MV_PP2_L2FW_DEBUG
 			printk(KERN_INFO "rule is not NULL in %s\n", __func__);
 #endif
 			return rule;
@@ -86,7 +86,7 @@ static struct l2fw_rule *l2fw_lookup(MV_U32 srcIP, MV_U32 dstIP)
 		rule = rule->next;
 	}
 
-#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+#ifdef CONFIG_MV_PP2_L2FW_DEBUG
 	printk(KERN_INFO "rule is NULL in %s\n", __func__);
 #endif
 
@@ -146,11 +146,11 @@ void mv_l2fw_ports_dump(void)
 	mvOsPrintf("\nPrinting L2fw ports Database:\n");
 	mvOsPrintf("*******************************\n");
 
-	if (!mv_eth_ports_l2fw)
+	if (!mv_pp2_ports_l2fw)
 		return;
 
 	for (rx_port = 0; rx_port < eth_ports_l2fw_num; rx_port++) {
-		ppl2fw = mv_eth_ports_l2fw[rx_port];
+		ppl2fw = mv_pp2_ports_l2fw[rx_port];
 		if (ppl2fw)
 			mvOsPrintf("rx_port=%d cmd = %d tx_port=%d lookup=%d xor_threshold = %d\n",
 					rx_port, ppl2fw->cmd, ppl2fw->txPort, ppl2fw->lookupEn, ppl2fw->xorThreshold);
@@ -174,7 +174,7 @@ int mv_l2fw_add(MV_U32 srcIP, MV_U32 dstIP, int port)
 	srcIPchr = (MV_U8 *)&(srcIP);
 	dstIPchr = (MV_U8 *)&(dstIP);
 
-#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+#ifdef CONFIG_MV_PP2_L2FW_DEBUG
 	mvOsPrintf("srcIP=%x dstIP=%x in %s\n", srcIP, dstIP, __func__);
 	mvOsPrintf("srcIp = %u.%u.%u.%u in %s\n", MV_IPQUAD(srcIPchr), __func__);
 	mvOsPrintf("dstIp = %u.%u.%u.%u in %s\n", MV_IPQUAD(dstIPchr), __func__);
@@ -192,7 +192,7 @@ int mv_l2fw_add(MV_U32 srcIP, MV_U32 dstIP, int port)
 		mvOsPrintf("%s: OOM\n", __func__);
 		return MV_FAIL;
 	}
-#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+#ifdef CONFIG_MV_PP2_L2FW_DEBUG
 	mvOsPrintf("adding a rule to l2fw hash in %s\n", __func__);
 #endif
 	rule->srcIP = srcIP;
@@ -205,7 +205,7 @@ int mv_l2fw_add(MV_U32 srcIP, MV_U32 dstIP, int port)
 	return MV_OK;
 }
 
-static int mv_eth_poll_l2fw(struct napi_struct *napi, int budget)
+static int mv_pp2_poll_l2fw(struct napi_struct *napi, int budget)
 {
 	int rx_done = 0;
 	MV_U32 causeRxTx;
@@ -238,7 +238,7 @@ static int mv_eth_poll_l2fw(struct napi_struct *napi, int budget)
 	napi_group = pp->cpu_config[smp_processor_id()]->napi_group;
 	causeRxTx |= napi_group->cause_rx_tx;
 
-#ifdef CONFIG_MV_ETH_TXDONE_ISR
+#ifdef CONFIG_MV_PP2_TXDONE_ISR
 
 	/* TODO check this mode */
 
@@ -247,14 +247,14 @@ static int mv_eth_poll_l2fw(struct napi_struct *napi, int budget)
 
 		/* TX_DONE process */
 		cause_tx_done = mvPp2GbeIsrCauseTxDoneOffset(pp->port, causeRxTx);
-		if (MV_PON_PORT(pp->port)) {
-			mv_eth_tx_done_pon(pp, &tx_todo);
-			printk(KERN_ERR "enter to mv_eth_tx_done_pon\n", __func__);
+		if (MV_PP2_IS_PON_PORT(pp->port)) {
+			mv_pp2_tx_done_pon(pp, &tx_todo);
+			mvOsPrintf("enter to mv_pp2_tx_done_pon\n");
 		} else
-			mv_eth_tx_done_gbe(pp, cause_tx_done, &tx_todo);
+			mv_pp2_tx_done_gbe(pp, cause_tx_done, &tx_todo);
 	}
-#endif /* CONFIG_MV_ETH_TXDONE_ISR */
-	if (MV_PON_PORT(pp->port))
+#endif /* CONFIG_MV_PP2_TXDONE_ISR */
+	if (MV_PP2_IS_PON_PORT(pp->port))
 		causeRxTx &= ~MV_PP2_PON_CAUSE_TXP_OCCUP_DESC_ALL_MASK;
 	else
 		causeRxTx &= ~MV_PP2_CAUSE_TXQ_OCCUP_DESC_ALL_MASK;
@@ -262,7 +262,7 @@ static int mv_eth_poll_l2fw(struct napi_struct *napi, int budget)
 	while ((causeRxTx != 0) && (budget > 0)) {
 		int count, rx_queue;
 
-		rx_queue = mv_eth_rx_policy(causeRxTx);
+		rx_queue = mv_pp2_rx_policy(causeRxTx);
 		if (rx_queue == -1)
 			break;
 
@@ -275,12 +275,12 @@ static int mv_eth_poll_l2fw(struct napi_struct *napi, int budget)
 
 	STAT_DIST((rx_done < pp->dist_stats.rx_dist_size) ? pp->dist_stats.rx_dist[rx_done]++ : 0);
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 	if (pp->dbg_flags & MV_ETH_F_DBG_POLL) {
 		printk(KERN_ERR "%s  EXIT: port=%d, cpu=%d, budget=%d, rx_done=%d\n",
 			__func__, pp->port, cpu, budget, rx_done);
 	}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 	if (budget > 0) {
 		unsigned long flags;
@@ -316,9 +316,9 @@ static int mv_l2fw_update_napi(struct eth_port *pp, bool l2fw)
 		netif_napi_del(napi_group->napi);
 
 		if (l2fw)
-			netif_napi_add(pp->dev, napi_group->napi, mv_eth_poll_l2fw, pp->weight);
+			netif_napi_add(pp->dev, napi_group->napi, mv_pp2_poll_l2fw, pp->weight);
 		else
-			netif_napi_add(pp->dev, napi_group->napi, mv_eth_poll, pp->weight);
+			netif_napi_add(pp->dev, napi_group->napi, mv_pp2_poll, pp->weight);
 /*
 		if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
 			napi_enable(napi_group->napi);
@@ -331,18 +331,18 @@ static int mv_l2fw_check(int port, bool l2fw)
 {
 	if (!l2fw) {
 		/* user try to exit form l2fw */
-		if (!mv_eth_ports_l2fw) {
+		if (!mv_pp2_ports_l2fw) {
 			mvOsPrintf("port #%d l2fw already disabled\n", port);
 			return MV_ERROR;
 		}
 
-		if (!mv_eth_ports_l2fw[port]) {
+		if (!mv_pp2_ports_l2fw[port]) {
 			mvOsPrintf("port #%d l2fw already disabled\n", port);
 			return MV_ERROR;
 		}
 
 	/* user try to enter into l2fw */
-	} else if (mv_eth_ports_l2fw && mv_eth_ports_l2fw[port]) {
+	} else if (mv_pp2_ports_l2fw && mv_pp2_ports_l2fw[port]) {
 			mvOsPrintf("port #%d l2fw already enabled\n", port);
 			return MV_ERROR;
 	}
@@ -352,7 +352,7 @@ static int mv_l2fw_check(int port, bool l2fw)
 
 int mv_l2fw_set(int port, bool l2fw)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	int status = MV_OK;
 
 	if (mv_l2fw_check(port, l2fw))
@@ -371,9 +371,9 @@ int mv_l2fw_set(int port, bool l2fw)
 	/* for multiBuffer validation */
 	/*mvGmacMaxRxSizeSet(port, 9000);*/
 
-	if (!mv_eth_netdev_ops_ptr) {
+	if (!mv_pp2_netdev_ops_ptr) {
 		/* enter only once - save eth ops */
-		mv_eth_netdev_ops_ptr = pp->dev->netdev_ops;
+		mv_pp2_netdev_ops_ptr = pp->dev->netdev_ops;
 		/* set maximum number of ports */
 		eth_ports_l2fw_num = pp->plat_data->max_port;
 	}
@@ -386,7 +386,7 @@ int mv_l2fw_set(int port, bool l2fw)
 		pp->dev->netdev_ops  = &mv_l2fw_netdev_ops;
 
 	} else {
-		pp->dev->netdev_ops = mv_eth_netdev_ops_ptr;
+		pp->dev->netdev_ops = mv_pp2_netdev_ops_ptr;
 		mv_l2fw_port_free(port);
 	}
 
@@ -397,7 +397,7 @@ int mv_l2fw_port(int rx_port, int tx_port, int cmd)
 {
 	struct eth_port_l2fw *ppl2fw;
 
-	if (!mv_eth_ports_l2fw) {
+	if (!mv_pp2_ports_l2fw) {
 		mvOsPrintf("%s: ports are not in l2fw mode\n", __func__);
 		return MV_ERROR;
 	}
@@ -407,12 +407,12 @@ int mv_l2fw_port(int rx_port, int tx_port, int cmd)
 	if (mvPp2MaxCheck(tx_port, eth_ports_l2fw_num, "tx_port"))
 		return MV_ERROR;
 
-	if (!mv_eth_ports_l2fw[rx_port]) {
+	if (!mv_pp2_ports_l2fw[rx_port]) {
 		mvOsPrintf("%s: port #%d is not in l2fw mode\n", __func__, rx_port);
 		return MV_ERROR;
 	}
 
-	if (!mv_eth_ports_l2fw[tx_port]) {
+	if (!mv_pp2_ports_l2fw[tx_port]) {
 		mvOsPrintf("%s: port #%d is not in l2fw mode\n", __func__, tx_port);
 		return MV_ERROR;
 	}
@@ -422,7 +422,7 @@ int mv_l2fw_port(int rx_port, int tx_port, int cmd)
 		return MV_ERROR;
 	}
 
-	ppl2fw = mv_eth_ports_l2fw[rx_port];
+	ppl2fw = mv_pp2_ports_l2fw[rx_port];
 	ppl2fw->cmd = cmd;
 	ppl2fw->txPort = tx_port;
 
@@ -494,7 +494,7 @@ inline struct sk_buff *eth_l2fw_copy_packet_withOutXor(struct sk_buff *skb, stru
 
 	poolId = mvPp2RxBmPoolId(rx_desc);
 
-	skb_new = (struct sk_buff *)mv_eth_pool_get(poolId);
+	skb_new = (struct sk_buff *)mv_pp2_pool_get(poolId);
 
 	if (!skb_new) {
 		mvOsPrintf("skb == NULL in %s\n", __func__);
@@ -511,7 +511,7 @@ inline struct sk_buff *eth_l2fw_copy_packet_withOutXor(struct sk_buff *skb, stru
 	return skb_new;
 }
 
-#ifdef CONFIG_MV_ETH_L2FW_XOR
+#ifdef CONFIG_MV_PP2_L2FW_XOR
 inline struct sk_buff *eth_l2fw_copy_packet_withXor(struct sk_buff *skb, struct pp2_rx_desc *rx_desc)
 {
 	struct sk_buff *skb_new = NULL;
@@ -523,7 +523,7 @@ inline struct sk_buff *eth_l2fw_copy_packet_withXor(struct sk_buff *skb, struct
 
 	poolId = mvPp2RxBmPoolId(rx_desc);
 
-	skb_new = (struct sk_buff *)mv_eth_pool_get(poolId);
+	skb_new = (struct sk_buff *)mv_pp2_pool_get(poolId);
 
 	if (!skb_new) {
 		mvOsPrintf("skb == NULL in %s\n", __func__);
@@ -604,9 +604,9 @@ void mv_l2fw_xor(int rx_port, int threshold)
 		return;
 
 	mvOsPrintf("setting port %d threshold to %d in %s\n", rx_port, threshold, __func__);
-	mv_eth_ports_l2fw[rx_port]->xorThreshold = threshold;
+	mv_pp2_ports_l2fw[rx_port]->xorThreshold = threshold;
 }
-#endif /* CONFIG_MV_ETH_L2FW_XOR */
+#endif /* CONFIG_MV_PP2_L2FW_XOR */
 
 void mv_l2fw_lookupEn(int rx_port, int enable)
 {
@@ -614,24 +614,24 @@ void mv_l2fw_lookupEn(int rx_port, int enable)
 		return;
 
 	mvOsPrintf("setting port %d lookup mode to %s\n", rx_port, (enable == 1) ? "enable" : "disable");
-	mv_eth_ports_l2fw[rx_port]->lookupEn = enable;
+	mv_pp2_ports_l2fw[rx_port]->lookupEn = enable;
 }
 
 void mv_l2fw_stats(void)
 {
 	int i;
 
-	if (!mv_eth_ports_l2fw)
+	if (!mv_pp2_ports_l2fw)
 		return;
 
 	for (i = 0; i < eth_ports_l2fw_num; i++) {
-		if (mv_eth_ports_l2fw[i]) {
-			mvOsPrintf("number of errors in port[%d]=%d\n", i, mv_eth_ports_l2fw[i]->statErr);
-			mvOsPrintf("number of drops  in port[%d]=%d\n", i, mv_eth_ports_l2fw[i]->statDrop);
+		if (mv_pp2_ports_l2fw[i]) {
+			mvOsPrintf("number of errors in port[%d]=%d\n", i, mv_pp2_ports_l2fw[i]->statErr);
+			mvOsPrintf("number of drops  in port[%d]=%d\n", i, mv_pp2_ports_l2fw[i]->statDrop);
 		}
 	}
 
-#ifdef CONFIG_MV_ETH_L2SEC
+#ifdef CONFIG_MV_PP2_L2SEC
 	mv_l2sec_stats();
 #endif
 
@@ -641,7 +641,7 @@ inline int mv_l2fw_tx(struct sk_buff *skb, struct eth_port *pp, struct pp2_rx_de
 {
 	struct pp2_tx_desc *tx_desc;
 	u32 tx_cmd = 0;
-	struct mv_eth_tx_spec *tx_spec_ptr = NULL;
+	struct mv_pp2_tx_spec *tx_spec_ptr = NULL;
 	struct tx_queue *txq_ctrl;
 	struct aggr_tx_queue *aggr_txq_ctrl = NULL;
 	struct txq_cpu_ctrl *txq_cpu_ptr;
@@ -651,17 +651,17 @@ inline int mv_l2fw_tx(struct sk_buff *skb, struct eth_port *pp, struct pp2_rx_de
 	tx_spec_ptr->txq = pp->cpu_config[cpu]->txq;
 	aggr_txq_ctrl = &aggr_txqs[cpu];
 
-	txq_ctrl = &pp->txq_ctrl[tx_spec_ptr->txp * CONFIG_MV_ETH_TXQ + tx_spec_ptr->txq];
+	txq_ctrl = &pp->txq_ctrl[tx_spec_ptr->txp * CONFIG_MV_PP2_TXQ + tx_spec_ptr->txq];
 	txq_cpu_ptr = &(txq_ctrl->txq_cpu[cpu]);
 
 #ifdef CONFIG_MV_ETH_PP2_1
-	if (mv_eth_reserved_desc_num_proc(pp, tx_spec_ptr->txp, tx_spec_ptr->txq, frags) ||
-		mv_eth_aggr_desc_num_check(aggr_txq_ctrl, frags)) {
+	if (mv_pp2_reserved_desc_num_proc(pp, tx_spec_ptr->txp, tx_spec_ptr->txq, frags) ||
+		mv_pp2_aggr_desc_num_check(aggr_txq_ctrl, frags)) {
 		frags = 0;
 		goto out;
 	}
 #else
-	if (mv_eth_aggr_desc_num_check(aggr_txq_ctrl, frags))
+	if (mv_pp2_aggr_desc_num_check(aggr_txq_ctrl, frags))
 		goto out;
 #endif /*CONFIG_MV_ETH_PP2_1*/
 
@@ -698,7 +698,7 @@ inline int mv_l2fw_tx(struct sk_buff *skb, struct eth_port *pp, struct pp2_rx_de
 
 	tx_desc->physTxq = MV_PPV2_TXQ_PHYS(pp->port, tx_spec_ptr->txp, tx_spec_ptr->txq);
 
-	txq_ctrl = &pp->txq_ctrl[tx_spec_ptr->txp * CONFIG_MV_ETH_TXQ + tx_spec_ptr->txq];
+	txq_ctrl = &pp->txq_ctrl[tx_spec_ptr->txp * CONFIG_MV_PP2_TXQ + tx_spec_ptr->txq];
 
 	if (txq_ctrl == NULL) {
 		printk(KERN_ERR "%s: invalidate txp/txq (%d/%d)\n",
@@ -709,10 +709,10 @@ inline int mv_l2fw_tx(struct sk_buff *skb, struct eth_port *pp, struct pp2_rx_de
 
 	txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
 
-	if (txq_cpu_ptr->txq_count >= mv_ctrl_txdone)
+	if (txq_cpu_ptr->txq_count >= mv_ctrl_pp2_txdone)
 		mv_l2fw_txq_done(pp, txq_ctrl);
 
-	if (MV_PON_PORT(pp->port)) {
+	if (MV_PP2_IS_PON_PORT(pp->port)) {
 		tx_desc->dataSize  = rx_desc->dataSize;
 		tx_desc->pktOffset = skb_headroom(skb);
 	} else {
@@ -722,7 +722,7 @@ inline int mv_l2fw_tx(struct sk_buff *skb, struct eth_port *pp, struct pp2_rx_de
 
 	tx_desc->bufCookie = (MV_U32)skb;
 	tx_desc->bufPhysAddr = mvOsCacheFlush(NULL, skb->head, tx_desc->dataSize);
-	mv_eth_tx_desc_flush(tx_desc);
+	mv_pp2_tx_desc_flush(tx_desc);
 
 	/* TODO - XOR ready check */
 
@@ -732,17 +732,17 @@ inline int mv_l2fw_tx(struct sk_buff *skb, struct eth_port *pp, struct pp2_rx_de
 	txq_cpu_ptr->txq_count++;
 	aggr_txq_ctrl->txq_count++;
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 	if (pp->dbg_flags & MV_ETH_F_DBG_TX) {
 		printk(KERN_ERR "\n");
 		printk(KERN_ERR "%s - eth_l2fw_tx_%lu: cpu=%d, in_intr=0x%lx, port=%d, txp=%d, txq=%d\n",
 			pp->dev->name, pp->dev->stats.tx_packets, smp_processor_id(), in_interrupt(),
 			pp->port, tx_spec_ptr->txp, tx_spec_ptr->txq);
 
-		mv_eth_tx_desc_print(tx_desc);
+		mv_pp2_tx_desc_print(tx_desc);
 		mvDebugMemDump(skb->data, 64, 1);
 	}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 	/* Enable transmit */
 	wmb();
@@ -755,10 +755,10 @@ inline int mv_l2fw_tx(struct sk_buff *skb, struct eth_port *pp, struct pp2_rx_de
 	pp->dev->stats.tx_bytes += rx_desc->dataSize - MV_ETH_MH_SIZE;
 
 out:
-#ifndef CONFIG_MV_ETH_TXDONE_ISR
-	if (txq_cpu_ptr->txq_count >= mv_ctrl_txdone)
+#ifndef CONFIG_MV_PP2_TXDONE_ISR
+	if (txq_cpu_ptr->txq_count >= mv_ctrl_pp2_txdone)
 		mv_l2fw_txq_done(pp, txq_ctrl);
-#endif /* CONFIG_MV_ETH_STAT_DIST */
+#endif /* CONFIG_MV_PP2_STAT_DIST */
 
 	return NETDEV_TX_OK;
 }
@@ -799,14 +799,14 @@ static int mv_l2fw_txq_clean(int port, int txp, int txq)
 	if (mvPp2TxpCheck(port, txp))
 		return -EINVAL;
 
-	pp = mv_eth_port_by_id(port);
+	pp = mv_pp2_port_by_id(port);
 	if ((pp == NULL) || (pp->txq_ctrl == NULL))
 		return -ENODEV;
 
-	if (mvPp2MaxCheck(txq, CONFIG_MV_ETH_TXQ, "txq"))
+	if (mvPp2MaxCheck(txq, CONFIG_MV_PP2_TXQ, "txq"))
 		return -EINVAL;
 
-	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + txq];
 	if (txq_ctrl->q) {
 		/* Enable TXQ drain */
 		mvPp2TxqDrainSet(port, txp, txq, MV_TRUE);
@@ -851,7 +851,7 @@ static int mv_l2fw_txp_clean(int port, int txp)
 	if (mvPp2TxpCheck(port, txp))
 		return -EINVAL;
 
-	pp = mv_eth_port_by_id(port);
+	pp = mv_pp2_port_by_id(port);
 	if ((pp == NULL) || (pp->txq_ctrl == NULL))
 		return -ENODEV;
 
@@ -864,7 +864,7 @@ static int mv_l2fw_txp_clean(int port, int txp)
 	mvPp2TxPortFifoFlush(port, MV_TRUE);
 
 	/* free the skb's in the hal tx ring */
-	for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++)
+	for (txq = 0; txq < CONFIG_MV_PP2_TXQ; txq++)
 		mv_l2fw_txq_clean(port, txp, txq);
 
 	mvPp2TxPortFifoFlush(port, MV_FALSE);
@@ -881,11 +881,11 @@ inline void mv_l2fw_pool_refill(struct eth_port *pp,
 				     struct bm_pool *pool, struct pp2_rx_desc *rx_desc)
 {
 	if ((rx_desc->status & PP2_RX_BUF_HDR_MASK) == MV_FALSE) {
-		__u32 bm = mv_eth_bm_cookie_build(rx_desc);
-		mv_eth_pool_refill(pool, bm, rx_desc->bufPhysAddr, rx_desc->bufCookie);
+		__u32 bm = mv_pp2_bm_cookie_build(rx_desc);
+		mv_pp2_pool_refill(pool, bm, rx_desc->bufPhysAddr, rx_desc->bufCookie);
 	} else
 		/* multiBuffer mode */
-		mv_eth_buff_hdr_rx(pp, rx_desc);
+		mv_pp2_buff_hdr_rx(pp, rx_desc);
 }
 
 inline int mv_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
@@ -898,7 +898,7 @@ inline int mv_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
 	struct pp2_rx_desc *rx_desc;
 	struct bm_pool *pool;
 	MV_STATUS status = MV_OK;
-	struct eth_port_l2fw *ppl2fw = mv_eth_ports_l2fw[pp->port];
+	struct eth_port_l2fw *ppl2fw = mv_pp2_ports_l2fw[pp->port];
 	MV_IP_HEADER *pIph = NULL;
 	int ipOffset;
 	struct sk_buff *skb, *skb_new = NULL;
@@ -918,13 +918,13 @@ inline int mv_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
 
 	/* Fairness NAPI loop */
 	while (rx_done < rx_todo) {
-#ifdef CONFIG_MV_ETH_RX_DESC_PREFETCH
-		rx_desc = mv_eth_rx_prefetch(pp, rx_ctrl, rx_done, rx_todo);
+#ifdef CONFIG_MV_PP2_RX_DESC_PREFETCH
+		rx_desc = mv_pp2_rx_prefetch(pp, rx_ctrl, rx_done, rx_todo);
 #else
 		rx_desc = mvPp2RxqNextDescGet(rx_ctrl);
 		mvOsCacheLineInv(NULL, rx_desc);
 		prefetch(rx_desc);
-#endif /* CONFIG_MV_ETH_RX_DESC_PREFETCH */
+#endif /* CONFIG_MV_PP2_RX_DESC_PREFETCH */
 
 		if (!rx_desc)
 			printk(KERN_INFO "rx_desc is NULL in %s\n", __func__);
@@ -934,16 +934,16 @@ inline int mv_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
 
 		rx_status = rx_desc->status;
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 		/* check if buffer header is in used */
 		if (pp->dbg_flags & MV_ETH_F_DBG_BUFF_HDR)
 			if (rx_status & PP2_RX_BUF_HDR_MASK)
-				mv_eth_buff_hdr_rx_dump(pp, rx_desc);
+				mv_pp2_buff_hdr_rx_dump(pp, rx_desc);
 
 		/* print RX descriptor */
 		if (pp->dbg_flags & MV_ETH_F_DBG_RX)
-			mv_eth_rx_desc_print(rx_desc);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+			mv_pp2_rx_desc_print(rx_desc);
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 		skb = (struct sk_buff *)rx_desc->bufCookie;
 
@@ -953,7 +953,7 @@ inline int mv_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
 		}
 
 		poolId = mvPp2RxBmPoolId(rx_desc);
-		pool = &mv_eth_pool[poolId];
+		pool = &mv_pp2_pool[poolId];
 
 		if (rx_status & PP2_RX_ES_MASK) {
 			printk(KERN_ERR "giga #%d: bad rx status 0x%08x\n", pp->port, rx_status);
@@ -969,7 +969,7 @@ inline int mv_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
 			printk(KERN_INFO "pIph==NULL in %s\n", __func__);
 			continue;
 		}
-#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+#ifdef CONFIG_MV_PP2_L2FW_DEBUG
 		if (pp->dbg_flags & MV_ETH_F_DBG_RX) {
 
 			mvDebugMemDump(skb->data, 64, 1);
@@ -988,10 +988,10 @@ inline int mv_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
 		if (ppl2fw->lookupEn) {
 			rule = l2fw_lookup(pIph->srcIP, pIph->dstIP);
 
-			new_pp = rule ? mv_eth_ports[rule->port] : mv_eth_ports[ppl2fw->txPort];
+			new_pp = rule ? mv_pp2_ports[rule->port] : mv_pp2_ports[ppl2fw->txPort];
 
 		} else
-			new_pp  = mv_eth_ports[ppl2fw->txPort];
+			new_pp  = mv_pp2_ports[ppl2fw->txPort];
 
 		bytes = rx_desc->dataSize - MV_ETH_MH_SIZE;
 
@@ -1013,12 +1013,12 @@ inline int mv_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
 				status = MV_ERROR;
 				break;
 			}
-#ifdef CONFIG_MV_ETH_L2FW_XOR
+#ifdef CONFIG_MV_PP2_L2FW_XOR
 			if (bytes >= ppl2fw->xorThreshold) {
 				skb_new = eth_l2fw_copy_packet_withXor(skb, rx_desc);
 				pr_error("%s: xor is not supported\n", __func__);
 			}
-#endif /* CONFIG_MV_ETH_L2FW_XOR */
+#endif /* CONFIG_MV_PP2_L2FW_XOR */
 
 			if (skb_new == NULL)
 				skb_new = eth_l2fw_copy_packet_withOutXor(skb, rx_desc);
@@ -1026,17 +1026,17 @@ inline int mv_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
 			if (skb_new) {
 				bufPhysAddr = rx_desc->bufPhysAddr;
 
-				bm = mv_eth_bm_cookie_build(rx_desc);
+				bm = mv_pp2_bm_cookie_build(rx_desc);
 				status = mv_l2fw_tx(skb_new, new_pp, rx_desc);
 
-				mv_eth_pool_refill(pool, bm, bufPhysAddr, (MV_ULONG)skb);
+				mv_pp2_pool_refill(pool, bm, bufPhysAddr, (MV_ULONG)skb);
 
 				/* for refill function */
 				skb = skb_new;
 			} else
 				status = MV_ERROR;
 			break;
-#ifdef CONFIG_MV_ETH_L2SEC
+#ifdef CONFIG_MV_PP2_L2SEC
 		case CMD_L2FW_CESA:
 			if (rx_status & PP2_RX_BUF_HDR_MASK) {
 				printk(KERN_INFO "%s: not support cesa with multibuffer packets.\n", __func__);
@@ -1078,15 +1078,15 @@ inline int mv_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
 
 static void mv_l2fw_shared_cleanup(void)
 {
-	if (mv_eth_ports_l2fw)
-		mvOsFree(mv_eth_ports_l2fw);
+	if (mv_pp2_ports_l2fw)
+		mvOsFree(mv_pp2_ports_l2fw);
 
 	if (l2fw_hash) {
 		mv_l2fw_flush();
 		mvOsFree(l2fw_hash);
 	}
 
-	mv_eth_ports_l2fw = NULL;
+	mv_pp2_ports_l2fw = NULL;
 	l2fw_hash = NULL;
 }
 
@@ -1096,12 +1096,12 @@ static int mv_l2fw_shared_init(void)
 	int size, bytes;
 
 	size = eth_ports_l2fw_num * sizeof(struct eth_port_l2fw *);
-	mv_eth_ports_l2fw = mvOsMalloc(size);
+	mv_pp2_ports_l2fw = mvOsMalloc(size);
 
-	if (!mv_eth_ports_l2fw)
+	if (!mv_pp2_ports_l2fw)
 		goto oom;
 
-	memset(mv_eth_ports_l2fw, 0, size);
+	memset(mv_pp2_ports_l2fw, 0, size);
 
 	bytes = sizeof(struct l2fw_rule *) * L2FW_HASH_SIZE;
 	get_random_bytes(&l2fw_jhash_iv, sizeof(l2fw_jhash_iv));
@@ -1116,11 +1116,11 @@ static int mv_l2fw_shared_init(void)
 
 	mvOsPrintf("L2FW hash init %d entries, %d bytes\n", L2FW_HASH_SIZE, bytes);
 
-#ifdef CONFIG_MV_ETH_L2SEC
+#ifdef CONFIG_MV_PP2_L2SEC
 	mv_l2sec_cesa_init();
 #endif
 
-#ifdef CONFIG_MV_ETH_L2FW_XOR
+#ifdef CONFIG_MV_PP2_L2FW_XOR
 	setXorDesc();
 #endif
 
@@ -1143,16 +1143,16 @@ static int mv_l2fw_port_init(int port)
 			return status;
 	}
 
-	mv_eth_ports_l2fw[port] = mvOsMalloc(sizeof(struct eth_port_l2fw));
-	if (!mv_eth_ports_l2fw[port])
+	mv_pp2_ports_l2fw[port] = mvOsMalloc(sizeof(struct eth_port_l2fw));
+	if (!mv_pp2_ports_l2fw[port])
 		goto oom;
 
-	mv_eth_ports_l2fw[port]->cmd    = CMD_L2FW_AS_IS;
-	mv_eth_ports_l2fw[port]->txPort = port;
-	mv_eth_ports_l2fw[port]->lookupEn = 0;
-	mv_eth_ports_l2fw[port]->xorThreshold = XOR_THRESHOLD_DEF;
-	mv_eth_ports_l2fw[port]->statErr = 0;
-	mv_eth_ports_l2fw[port]->statDrop = 0;
+	mv_pp2_ports_l2fw[port]->cmd    = CMD_L2FW_AS_IS;
+	mv_pp2_ports_l2fw[port]->txPort = port;
+	mv_pp2_ports_l2fw[port]->lookupEn = 0;
+	mv_pp2_ports_l2fw[port]->xorThreshold = XOR_THRESHOLD_DEF;
+	mv_pp2_ports_l2fw[port]->statErr = 0;
+	mv_pp2_ports_l2fw[port]->statDrop = 0;
 
 	shared++;
 
@@ -1168,18 +1168,18 @@ oom:
 
 static void mv_l2fw_port_free(int port)
 {
-	if (!mv_eth_ports_l2fw) {
+	if (!mv_pp2_ports_l2fw) {
 		mvOsPrintf("in %s: l2fw database is NULL\n", __func__);
 		return;
 	}
 
-	if (!mv_eth_ports_l2fw[port]) {
+	if (!mv_pp2_ports_l2fw[port]) {
 		mvOsPrintf("in %s: l2fw port #%d database is NULL\n", __func__, port);
 		return;
 	}
 
-	mvOsFree(mv_eth_ports_l2fw[port]);
-	mv_eth_ports_l2fw[port] = NULL;
+	mvOsFree(mv_pp2_ports_l2fw[port]);
+	mv_pp2_ports_l2fw[port] = NULL;
 
 	shared--;
 
@@ -1196,7 +1196,7 @@ int mv_l2fw_stop(struct net_device *dev)
 		if (mv_l2fw_txp_clean(pp->port, txp))
 			return MV_ERROR;
 
-	return mv_eth_stop(dev);
+	return mv_pp2_eth_stop(dev);
 }
 
 static netdev_tx_t mv_l2fw_xmit(struct sk_buff *skb, struct net_device *dev)
@@ -1205,10 +1205,10 @@ static netdev_tx_t mv_l2fw_xmit(struct sk_buff *skb, struct net_device *dev)
 }
 
 static const struct net_device_ops mv_l2fw_netdev_ops = {
-	.ndo_open = mv_eth_open,
+	.ndo_open = mv_pp2_eth_open,
 	.ndo_stop = mv_l2fw_stop,
 	.ndo_start_xmit = mv_l2fw_xmit,
-	.ndo_set_rx_mode = mv_eth_rx_set_rx_mode,
-	.ndo_set_mac_address = mv_eth_set_mac_addr,
-	.ndo_change_mtu = mv_eth_change_mtu,
+	.ndo_set_rx_mode = mv_pp2_rx_set_rx_mode,
+	.ndo_set_mac_address = mv_pp2_eth_set_mac_addr,
+	.ndo_change_mtu = mv_pp2_eth_change_mtu,
 };
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h
index 4f1cebe..46075e3 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h
@@ -30,7 +30,7 @@ disclaimer.
 #define L2FW_MV_ETH_L2FW_H
 
 #include "mvOs.h"
-#include "mv_pp2/net_dev/mv_netdev.h"
+#include "../net_dev/mv_netdev.h"
 
 #define	L2FW_HASH_SIZE   (1 << 17)
 #define	L2FW_HASH_MASK   (L2FW_HASH_SIZE - 1)
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_bm_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_bm_sysfs.c
index 8b0c40d..2648aac 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_bm_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_bm_sysfs.c
@@ -36,7 +36,7 @@ disclaimer.
 #include "gbe/mvPp2Gbe.h"
 #include "mv_netdev.h"
 
-static ssize_t mv_eth_help(char *buf)
+static ssize_t mv_pp2_help(char *buf)
 {
 	int off = 0;
 
@@ -67,7 +67,7 @@ static ssize_t mv_eth_help(char *buf)
 	return off;
 }
 
-static ssize_t mv_eth_show(struct device *dev,
+static ssize_t mv_pp2_show(struct device *dev,
 				  struct device_attribute *attr, char *buf)
 {
 	const char	*name = attr->attr.name;
@@ -82,12 +82,12 @@ static ssize_t mv_eth_show(struct device *dev,
 		mvBmQsetConfigDumpAll();
 
 	else
-		off = mv_eth_help(buf);
+		off = mv_pp2_help(buf);
 
 	return off;
 }
 
-static ssize_t mv_eth_port_store(struct device *dev,
+static ssize_t mv_pp2_port_store(struct device *dev,
 				   struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
@@ -109,19 +109,19 @@ static ssize_t mv_eth_port_store(struct device *dev,
 	} else if (!strcmp(name, "poolDropCnt")) {
 		mvBmV1PoolDropCntDump(a);
 	} else if (!strcmp(name, "poolStatus")) {
-		mv_eth_pool_status_print(a);
+		mv_pp2_pool_status_print(a);
 	} else if (!strcmp(name, "poolSize")) {
-		err = mv_eth_ctrl_pool_size_set(a, b);
+		err = mv_pp2_ctrl_pool_size_set(a, b);
 	} else if (!strcmp(name, "poolBufNum")) {
-		err = mv_eth_ctrl_pool_buf_num_set(a, b);
+		err = mv_pp2_ctrl_pool_buf_num_set(a, b);
 	} else if (!strcmp(name, "longPool")) {
-		err = mv_eth_ctrl_long_pool_set(a, b);
+		err = mv_pp2_ctrl_long_pool_set(a, b);
 	} else if (!strcmp(name, "shortPool")) {
-		err = mv_eth_ctrl_short_pool_set(a, b);
+		err = mv_pp2_ctrl_short_pool_set(a, b);
 	} else if (!strcmp(name, "hwfLongPool")) {
-		err = mv_eth_ctrl_hwf_long_pool_set(a, b);
+		err = mv_pp2_ctrl_hwf_long_pool_set(a, b);
 	} else if (!strcmp(name, "hwfShortPool")) {
-		err = mv_eth_ctrl_hwf_short_pool_set(a, b);
+		err = mv_pp2_ctrl_hwf_short_pool_set(a, b);
 	} else if (!strcmp(name, "qsetCreate")) {
 		mvBmQsetCreate(a, b);
 	} else if (!strcmp(name, "qsetDelete")) {
@@ -151,29 +151,29 @@ static ssize_t mv_eth_port_store(struct device *dev,
 	return err ? -EINVAL : len;
 }
 
-static DEVICE_ATTR(help,		S_IRUSR, mv_eth_show, NULL);
-static DEVICE_ATTR(queueMappDump,	S_IRUSR, mv_eth_show, NULL);
-static DEVICE_ATTR(qsetConfigDump,	S_IRUSR, mv_eth_show, NULL);
-static DEVICE_ATTR(poolRegs,		S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(poolDropCnt,		S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(poolStatus,		S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(poolSize,		S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(poolBufNum,		S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(longPool,		S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(shortPool,		S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(hwfLongPool,		S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(hwfShortPool,	S_IWUSR, NULL, mv_eth_port_store);
-
-static DEVICE_ATTR(qsetCreate,		S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(qsetDelete,		S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(rxqQsetLong,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(rxqQsetShort,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(txqQsetLong,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(txqQsetShort,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(qsetMaxSet,		S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(qsetShow,		S_IWUSR, NULL, mv_eth_port_store);
-
-static struct attribute *mv_eth_attrs[] = {
+static DEVICE_ATTR(help,		S_IRUSR, mv_pp2_show, NULL);
+static DEVICE_ATTR(queueMappDump,	S_IRUSR, mv_pp2_show, NULL);
+static DEVICE_ATTR(qsetConfigDump,	S_IRUSR, mv_pp2_show, NULL);
+static DEVICE_ATTR(poolRegs,		S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(poolDropCnt,		S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(poolStatus,		S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(poolSize,		S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(poolBufNum,		S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(longPool,		S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(shortPool,		S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(hwfLongPool,		S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(hwfShortPool,	S_IWUSR, NULL, mv_pp2_port_store);
+
+static DEVICE_ATTR(qsetCreate,		S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(qsetDelete,		S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(rxqQsetLong,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(rxqQsetShort,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(txqQsetLong,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(txqQsetShort,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(qsetMaxSet,		S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(qsetShow,		S_IWUSR, NULL, mv_pp2_port_store);
+
+static struct attribute *mv_pp2_attrs[] = {
 	&dev_attr_help.attr,
 	&dev_attr_queueMappDump.attr,
 	&dev_attr_qsetConfigDump.attr,
@@ -197,16 +197,16 @@ static struct attribute *mv_eth_attrs[] = {
 	NULL
 };
 
-static struct attribute_group mv_eth_bm_group = {
+static struct attribute_group mv_pp2_bm_group = {
 	.name = "bm",
-	.attrs = mv_eth_attrs,
+	.attrs = mv_pp2_attrs,
 };
 
 int mv_pp2_bm_sysfs_init(struct kobject *pp2_kobj)
 {
 	int err;
 
-	err = sysfs_create_group(pp2_kobj, &mv_eth_bm_group);
+	err = sysfs_create_group(pp2_kobj, &mv_pp2_bm_group);
 	if (err)
 		printk(KERN_INFO "sysfs group failed %d\n", err);
 
@@ -215,7 +215,7 @@ int mv_pp2_bm_sysfs_init(struct kobject *pp2_kobj)
 
 int mv_pp2_bm_sysfs_exit(struct kobject *pp2_kobj)
 {
-	sysfs_remove_group(pp2_kobj, &mv_eth_bm_group);
+	sysfs_remove_group(pp2_kobj, &mv_pp2_bm_group);
 
 	return 0;
 }
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_dbg_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_dbg_sysfs.c
index 70c0ee4..05a2e4b 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_dbg_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_dbg_sysfs.c
@@ -36,7 +36,7 @@ disclaimer.
 #include "mv_eth_sysfs.h"
 
 
-static ssize_t mv_eth_dbg_help(char *buf)
+static ssize_t mv_pp2_dbg_help(char *buf)
 {
 	int off = 0;
 
@@ -48,7 +48,7 @@ static ssize_t mv_eth_dbg_help(char *buf)
 	return off;
 }
 
-static ssize_t mv_eth_dbg_show(struct device *dev,
+static ssize_t mv_pp2_dbg_show(struct device *dev,
 				  struct device_attribute *attr, char *buf)
 {
 	const char      *name = attr->attr.name;
@@ -58,18 +58,18 @@ static ssize_t mv_eth_dbg_show(struct device *dev,
 		return -EPERM;
 
 	if (!strcmp(name, "clean"))
-		mv_eth_all_ports_cleanup();
+		mv_pp2_all_ports_cleanup();
 	else if (!strcmp(name, "init")) {
-		if (mv_eth_all_ports_cleanup() == 0)
+		if (mv_pp2_all_ports_cleanup() == 0)
 			/* probe only if all ports are clean */
-			mv_eth_all_ports_probe();
+			mv_pp2_all_ports_probe();
 	} else
-		off = mv_eth_dbg_help(buf);
+		off = mv_pp2_dbg_help(buf);
 
 	return off;
 }
 
-static ssize_t mv_eth_dbg_reg_store(struct device *dev,
+static ssize_t mv_pp2_dbg_reg_store(struct device *dev,
 				   struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
@@ -105,14 +105,14 @@ static ssize_t mv_eth_dbg_reg_store(struct device *dev,
 }
 
 
-static DEVICE_ATTR(help,          S_IRUSR, mv_eth_dbg_show, NULL);
-static DEVICE_ATTR(clean,         S_IRUSR, mv_eth_dbg_show, NULL);
-static DEVICE_ATTR(init,          S_IRUSR, mv_eth_dbg_show, NULL);
-static DEVICE_ATTR(regRead,       S_IWUSR, NULL, mv_eth_dbg_reg_store);
-static DEVICE_ATTR(regWrite,      S_IWUSR, NULL, mv_eth_dbg_reg_store);
+static DEVICE_ATTR(help,          S_IRUSR, mv_pp2_dbg_show, NULL);
+static DEVICE_ATTR(clean,         S_IRUSR, mv_pp2_dbg_show, NULL);
+static DEVICE_ATTR(init,          S_IRUSR, mv_pp2_dbg_show, NULL);
+static DEVICE_ATTR(regRead,       S_IWUSR, NULL, mv_pp2_dbg_reg_store);
+static DEVICE_ATTR(regWrite,      S_IWUSR, NULL, mv_pp2_dbg_reg_store);
 
 
-static struct attribute *mv_eth_dbg_attrs[] = {
+static struct attribute *mv_pp2_dbg_attrs[] = {
 	&dev_attr_clean.attr,
 	&dev_attr_init.attr,
 	&dev_attr_help.attr,
@@ -122,25 +122,25 @@ static struct attribute *mv_eth_dbg_attrs[] = {
 };
 
 
-static struct attribute_group mv_eth_dbg_group = {
+static struct attribute_group mv_pp2_dbg_group = {
 	.name = "dbg",
-	.attrs = mv_eth_dbg_attrs,
+	.attrs = mv_pp2_dbg_attrs,
 };
 
 int mv_pp2_dbg_sysfs_init(struct kobject *pp2_kobj)
 {
 	int err;
 
-	err = sysfs_create_group(pp2_kobj, &mv_eth_dbg_group);
+	err = sysfs_create_group(pp2_kobj, &mv_pp2_dbg_group);
 	if (err)
-		pr_err("sysfs group i%s failed %d\n", mv_eth_dbg_group.name, err);
+		pr_err("sysfs group i%s failed %d\n", mv_pp2_dbg_group.name, err);
 
 	return err;
 }
 
 int mv_pp2_dbg_sysfs_exit(struct kobject *pp2_kobj)
 {
-	sysfs_remove_group(pp2_kobj, &mv_eth_dbg_group);
+	sysfs_remove_group(pp2_kobj, &mv_pp2_dbg_group);
 
 	return 0;
 }
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_hwf_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_hwf_sysfs.c
index 8f6dbe5..6e7bebb 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_hwf_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_hwf_sysfs.c
@@ -47,7 +47,7 @@ static ssize_t mv_pp2_hwf_help(char *buf)
 	o += scnprintf(buf+o, PAGE_SIZE-o, "cat                    status  - show SWF to HWF switching status\n");
 	o += scnprintf(buf+o, PAGE_SIZE-o, "echo msec            > timeout - set SWF to HWF switching timeout\n");
 	o += scnprintf(buf+o, PAGE_SIZE-o, "echo id txq rxq msec > switch  - start SWF to HWF switching process\n");
-#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+#ifdef CONFIG_MV_PP2_SWF_HWF_CORRUPTION_WA
 	o += scnprintf(buf+o, PAGE_SIZE-o, "echo en              > c_inv   - on/off L1 and L2 cache invalidation\n");
 #endif
 	return o;
@@ -131,7 +131,7 @@ static ssize_t mv_pp2_hwf_dec_store(struct device *dev,
 
 	if (!strcmp(name, "timeout")) {
 		fwd_switch_msec = val;
-#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+#ifdef CONFIG_MV_PP2_SWF_HWF_CORRUPTION_WA
 	} else if (!strcmp(name, "c_inv")) {
 		mv_pp2_cache_inv_wa_ctrl(val);
 #endif
@@ -153,7 +153,7 @@ static DEVICE_ATTR(regs,		S_IRUSR, mv_pp2_hwf_show, NULL);
 static DEVICE_ATTR(status,		S_IRUSR, mv_pp2_hwf_show, NULL);
 static DEVICE_ATTR(switch,		S_IWUSR, NULL, mv_pp2_hwf_store);
 static DEVICE_ATTR(timeout,		S_IWUSR, NULL, mv_pp2_hwf_dec_store);
-#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+#ifdef CONFIG_MV_PP2_SWF_HWF_CORRUPTION_WA
 static DEVICE_ATTR(c_inv,		S_IWUSR, NULL, mv_pp2_hwf_dec_store);
 #endif
 
@@ -163,7 +163,7 @@ static struct attribute *mv_pp2_hwf_attrs[] = {
 	&dev_attr_status.attr,
 	&dev_attr_switch.attr,
 	&dev_attr_timeout.attr,
-#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+#ifdef CONFIG_MV_PP2_SWF_HWF_CORRUPTION_WA
 	&dev_attr_c_inv.attr,
 #endif
 	NULL
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_napi_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_napi_sysfs.c
index 2125295..93217e8 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_napi_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_napi_sysfs.c
@@ -117,7 +117,7 @@ static ssize_t mv_eth_3_hex_store(struct device *dev,
 	if (!strcmp(name, "cpuGroup")) {
 		err = mv_eth_napi_set_cpu_affinity(p, i, v);
 	} else if (!strcmp(name, "rxqGroup")) {
-		err = mv_eth_napi_set_rxq_affinity(p, i, v);
+		err = mv_pp2_eth_napi_set_rxq_affinity(p, i, v);
 	} else {
 		err = 1;
 		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pme_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pme_sysfs.c
index a63faad..aac36d6 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pme_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pme_sysfs.c
@@ -36,7 +36,7 @@ disclaimer.
 #include "gbe/mvPp2Gbe.h"
 #include "mv_netdev.h"
 
-static ssize_t mv_eth_help(char *buf)
+static ssize_t mv_pp2_help(char *buf)
 {
 	int off = 0;
 
@@ -47,7 +47,7 @@ static ssize_t mv_eth_help(char *buf)
 	return off;
 }
 
-static ssize_t mv_eth_show(struct device *dev,
+static ssize_t mv_pp2_show(struct device *dev,
 				  struct device_attribute *attr, char *buf)
 {
 	int             off = 0;
@@ -55,12 +55,12 @@ static ssize_t mv_eth_show(struct device *dev,
 	if (!capable(CAP_NET_ADMIN))
 		return -EPERM;
 
-	off = mv_eth_help(buf);
+	off = mv_pp2_help(buf);
 
 	return off;
 }
 
-static ssize_t mv_eth_port_store(struct device *dev,
+static ssize_t mv_pp2_port_store(struct device *dev,
 				   struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
@@ -78,11 +78,11 @@ static ssize_t mv_eth_port_store(struct device *dev,
 	local_irq_save(flags);
 
 	if (!strcmp(name, "modCmd")) {
-		err = mv_eth_ctrl_tx_cmd_mod(p, v);
+		err = mv_pp2_ctrl_tx_cmd_mod(p, v);
 	} else if (!strcmp(name, "pmeDptr")) {
-		err = mv_eth_ctrl_tx_cmd_pme_dptr(p, v);
+		err = mv_pp2_ctrl_tx_cmd_pme_dptr(p, v);
 	} else if (!strcmp(name, "pmeProgram")) {
-		err = mv_eth_ctrl_tx_cmd_pme_prog(p, v);
+		err = mv_pp2_ctrl_tx_cmd_pme_prog(p, v);
 	} else {
 		err = 1;
 		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
@@ -96,12 +96,12 @@ static ssize_t mv_eth_port_store(struct device *dev,
 	return err ? -EINVAL : len;
 }
 
-static DEVICE_ATTR(help,        S_IRUSR, mv_eth_show, NULL);
-static DEVICE_ATTR(modCmd,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(pmeDptr,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(pmeProgram,	S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(help,        S_IRUSR, mv_pp2_show, NULL);
+static DEVICE_ATTR(modCmd,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(pmeDptr,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(pmeProgram,	S_IWUSR, NULL, mv_pp2_port_store);
 
-static struct attribute *mv_eth_attrs[] = {
+static struct attribute *mv_pp2_attrs[] = {
 	&dev_attr_help.attr,
 	&dev_attr_modCmd.attr,
 	&dev_attr_pmeDptr.attr,
@@ -111,7 +111,7 @@ static struct attribute *mv_eth_attrs[] = {
 
 static struct attribute_group gbe_pme_group = {
 	.name = "pme",
-	.attrs = mv_eth_attrs,
+	.attrs = mv_pp2_attrs,
 };
 
 int mv_pp2_gbe_pme_sysfs_init(struct kobject *gbe_kobj)
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pon_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pon_sysfs.c
index a3d4beb..cfc5517 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pon_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_pon_sysfs.c
@@ -36,7 +36,7 @@ disclaimer.
 #include "gbe/mvPp2Gbe.h"
 #include "mv_netdev.h"
 
-static ssize_t mv_eth_help(char *buf)
+static ssize_t mv_pp2_help(char *buf)
 {
 	int off = 0;
 
@@ -49,7 +49,7 @@ static ssize_t mv_eth_help(char *buf)
 	return off;
 }
 
-static ssize_t mv_eth_show(struct device *dev,
+static ssize_t mv_pp2_show(struct device *dev,
 				  struct device_attribute *attr, char *buf)
 {
 	int             off = 0;
@@ -57,12 +57,12 @@ static ssize_t mv_eth_show(struct device *dev,
 	if (!capable(CAP_NET_ADMIN))
 		return -EPERM;
 
-	off = mv_eth_help(buf);
+	off = mv_pp2_help(buf);
 
 	return off;
 }
 
-static ssize_t mv_eth_port_store(struct device *dev,
+static ssize_t mv_pp2_port_store(struct device *dev,
 				   struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
@@ -80,13 +80,13 @@ static ssize_t mv_eth_port_store(struct device *dev,
 	local_irq_save(flags);
 
 	if (!strcmp(name, "dsaTag")) {
-		err = mv_eth_ctrl_tx_cmd_dsa(p, v);
+		err = mv_pp2_ctrl_tx_cmd_dsa(p, v);
 	} else if (!strcmp(name, "pktColor")) {
-		err = mv_eth_ctrl_tx_cmd_color(p, v);
+		err = mv_pp2_ctrl_tx_cmd_color(p, v);
 	} else if (!strcmp(name, "gemPortId")) {
-		err = mv_eth_ctrl_tx_cmd_gem_id(p, v);
+		err = mv_pp2_ctrl_tx_cmd_gem_id(p, v);
 	} else if (!strcmp(name, "ponFec")) {
-		err = mv_eth_ctrl_tx_cmd_pon_fec(p, v);
+		err = mv_pp2_ctrl_tx_cmd_pon_fec(p, v);
 	} else if (!strcmp(name, "gemOem")) {
 		err = mv_eth_ctrl_tx_cmd_gem_oem(p, v);
 	} else {
@@ -102,14 +102,14 @@ static ssize_t mv_eth_port_store(struct device *dev,
 	return err ? -EINVAL : len;
 }
 
-static DEVICE_ATTR(help,        S_IRUSR, mv_eth_show, NULL);
-static DEVICE_ATTR(dsaTag,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(pktColor,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(gemPortId,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(ponFec,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(gemOem,	S_IWUSR, NULL, mv_eth_port_store);
+static DEVICE_ATTR(help,        S_IRUSR, mv_pp2_show, NULL);
+static DEVICE_ATTR(dsaTag,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(pktColor,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(gemPortId,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(ponFec,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(gemOem,	S_IWUSR, NULL, mv_pp2_port_store);
 
-static struct attribute *mv_eth_attrs[] = {
+static struct attribute *mv_pp2_attrs[] = {
 	&dev_attr_help.attr,
 	&dev_attr_dsaTag.attr,
 	&dev_attr_pktColor.attr,
@@ -119,24 +119,24 @@ static struct attribute *mv_eth_attrs[] = {
 	NULL
 };
 
-static struct attribute_group mv_eth_pon_group = {
+static struct attribute_group mv_pp2_pon_group = {
 	.name = "pon",
-	.attrs = mv_eth_attrs,
+	.attrs = mv_pp2_attrs,
 };
 
 int mv_pp2_pon_sysfs_init(struct kobject *gbe_kobj)
 {
 	int err;
 
-	err = sysfs_create_group(gbe_kobj, &mv_eth_pon_group);
+	err = sysfs_create_group(gbe_kobj, &mv_pp2_pon_group);
 	if (err)
-		pr_err("sysfs group %s failed %d\n", mv_eth_pon_group.name, err);
+		pr_err("sysfs group %s failed %d\n", mv_pp2_pon_group.name, err);
 
 	return err;
 }
 
 int mv_pp2_pon_sysfs_exit(struct kobject *gbe_kobj)
 {
-	sysfs_remove_group(gbe_kobj, &mv_eth_pon_group);
+	sysfs_remove_group(gbe_kobj, &mv_pp2_pon_group);
 	return 0;
 }
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_qos_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_qos_sysfs.c
index 361746e..9a07b64 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_qos_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_qos_sysfs.c
@@ -36,7 +36,7 @@ disclaimer.
 #include "gbe/mvPp2Gbe.h"
 #include "mv_netdev.h"
 
-static ssize_t mv_eth_help(char *buf)
+static ssize_t mv_pp2_help(char *buf)
 {
 	int off = 0;
 
@@ -46,7 +46,7 @@ static ssize_t mv_eth_help(char *buf)
 	return off;
 }
 
-static ssize_t mv_eth_show(struct device *dev,
+static ssize_t mv_pp2_show(struct device *dev,
 				  struct device_attribute *attr, char *buf)
 {
 	int             off = 0;
@@ -54,12 +54,12 @@ static ssize_t mv_eth_show(struct device *dev,
 	if (!capable(CAP_NET_ADMIN))
 		return -EPERM;
 
-	off = mv_eth_help(buf);
+	off = mv_pp2_help(buf);
 
 	return off;
 }
 
-static ssize_t mv_eth_port_store(struct device *dev,
+static ssize_t mv_pp2_port_store(struct device *dev,
 				   struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
@@ -77,7 +77,7 @@ static ssize_t mv_eth_port_store(struct device *dev,
 	local_irq_save(flags);
 
 	if (!strcmp(name, "dscp")) {
-		mv_eth_dscp_map_show(p);
+		mv_pp2_dscp_map_show(p);
 	} else {
 		err = 1;
 		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
@@ -91,7 +91,7 @@ static ssize_t mv_eth_port_store(struct device *dev,
 	return err ? -EINVAL : len;
 }
 
-static ssize_t mv_eth_3_hex_store(struct device *dev,
+static ssize_t mv_pp2_3_hex_store(struct device *dev,
 				   struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
@@ -108,7 +108,7 @@ static ssize_t mv_eth_3_hex_store(struct device *dev,
 	local_irq_save(flags);
 
 	if (!strcmp(name, "txqDscp")) {
-		err = mv_eth_txq_dscp_map_set(p, i, v);
+		err = mv_pp2_txq_dscp_map_set(p, i, v);
 	} else {
 		err = 1;
 		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
@@ -120,36 +120,36 @@ static ssize_t mv_eth_3_hex_store(struct device *dev,
 }
 
 
-static DEVICE_ATTR(help,         S_IRUSR, mv_eth_show, NULL);
-static DEVICE_ATTR(dscp,         S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(txqDscp,      S_IWUSR, NULL, mv_eth_3_hex_store);
+static DEVICE_ATTR(help,         S_IRUSR, mv_pp2_show, NULL);
+static DEVICE_ATTR(dscp,         S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(txqDscp,      S_IWUSR, NULL, mv_pp2_3_hex_store);
 
 
-static struct attribute *mv_eth_attrs[] = {
+static struct attribute *mv_pp2_attrs[] = {
 	&dev_attr_dscp.attr,
 	&dev_attr_txqDscp.attr,
 	&dev_attr_help.attr,
 	NULL
 };
 
-static struct attribute_group mv_eth_qos_group = {
+static struct attribute_group mv_pp2_qos_group = {
 	.name = "qos",
-	.attrs = mv_eth_attrs,
+	.attrs = mv_pp2_attrs,
 };
 
 int mv_pp2_qos_sysfs_init(struct kobject *gbe_kobj)
 {
 	int err;
 
-	err = sysfs_create_group(gbe_kobj, &mv_eth_qos_group);
+	err = sysfs_create_group(gbe_kobj, &mv_pp2_qos_group);
 	if (err)
-		pr_err("sysfs group %s failed %d\n", mv_eth_qos_group.name, err);
+		pr_err("sysfs group %s failed %d\n", mv_pp2_qos_group.name, err);
 
 	return err;
 }
 
 int mv_pp2_qos_sysfs_exit(struct kobject *gbe_kobj)
 {
-	sysfs_remove_group(gbe_kobj, &mv_eth_qos_group);
+	sysfs_remove_group(gbe_kobj, &mv_pp2_qos_group);
 	return 0;
 }
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_rx_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_rx_sysfs.c
index 892bb93..b077b66 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_rx_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_rx_sysfs.c
@@ -37,7 +37,7 @@ disclaimer.
 #include "prs/mvPp2Prs.h"
 #include "mv_netdev.h"
 
-static ssize_t mv_eth_help(char *b)
+static ssize_t mv_pp2_help(char *b)
 {
 	int o = 0;
 
@@ -58,7 +58,7 @@ static ssize_t mv_eth_help(char *b)
 	return o;
 }
 
-static ssize_t mv_eth_show(struct device *dev,
+static ssize_t mv_pp2_show(struct device *dev,
 				  struct device_attribute *attr, char *buf)
 {
 	const char      *name = attr->attr.name;
@@ -70,12 +70,12 @@ static ssize_t mv_eth_show(struct device *dev,
 	if (!strcmp(name, "rxDmaRegs"))
 		mvPp2RxDmaRegsPrint();
 	else
-		off = mv_eth_help(buf);
+		off = mv_pp2_help(buf);
 
 	return off;
 }
 
-static ssize_t mv_eth_port_store(struct device *dev,
+static ssize_t mv_pp2_port_store(struct device *dev,
 				   struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
@@ -101,14 +101,14 @@ static ssize_t mv_eth_port_store(struct device *dev,
 	} else if (!strcmp(name, "rxFifoRegs")) {
 		mvPp2RxFifoRegs(p);
 	} else if (!strcmp(name, "rxWeight")) {
-		mv_eth_ctrl_set_poll_rx_weight(p, v);
+		mv_pp2_ctrl_set_poll_rx_weight(p, v);
 	} else if (!strcmp(name, "rxqSize")) {
-		mv_eth_ctrl_rxq_size_set(p, v, a);
+		mv_pp2_ctrl_rxq_size_set(p, v, a);
 	} else if (!strcmp(name, "rxqCounters")) {
 		mvPp2V1RxqDbgCntrs(p, v);
 	} else if (!strcmp(name, "prefetch")) {
-		err |= mv_eth_ctrl_flag(p, MV_ETH_F_RX_DESC_PREFETCH, v & 0x1);
-		err |= mv_eth_ctrl_flag(p, MV_ETH_F_RX_PKT_PREFETCH, v & 0x2);
+		err |= mv_pp2_ctrl_flag(p, MV_ETH_F_RX_DESC_PREFETCH, v & 0x1);
+		err |= mv_pp2_ctrl_flag(p, MV_ETH_F_RX_PKT_PREFETCH, v & 0x2);
 	} else {
 		err = 1;
 		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
@@ -122,7 +122,7 @@ static ssize_t mv_eth_port_store(struct device *dev,
 	return err ? -EINVAL : len;
 }
 
-static ssize_t mv_eth_rx_hex_store(struct device *dev,
+static ssize_t mv_pp2_rx_hex_store(struct device *dev,
 				struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
@@ -154,19 +154,19 @@ static ssize_t mv_eth_rx_hex_store(struct device *dev,
 	return err ? -EINVAL : len;
 }
 
-static DEVICE_ATTR(help,        S_IRUSR, mv_eth_show, NULL);
-static DEVICE_ATTR(rxDmaRegs,  	S_IRUSR, mv_eth_show, NULL);
-static DEVICE_ATTR(rxqCounters, S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(rxqShow,     S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(gRxqRegs,    S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(pRxqRegs,    S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(rxFifoRegs,  S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(rxWeight,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(rxqSize,   	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(mhRxSpec,	S_IWUSR, NULL, mv_eth_rx_hex_store);
-static DEVICE_ATTR(prefetch,	S_IWUSR, NULL, mv_eth_port_store);
-
-static struct attribute *mv_eth_attrs[] = {
+static DEVICE_ATTR(help,        S_IRUSR, mv_pp2_show, NULL);
+static DEVICE_ATTR(rxDmaRegs,	S_IRUSR, mv_pp2_show, NULL);
+static DEVICE_ATTR(rxqCounters, S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(rxqShow,     S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(gRxqRegs,    S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(pRxqRegs,    S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(rxFifoRegs,  S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(rxWeight,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(rxqSize,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(mhRxSpec,	S_IWUSR, NULL, mv_pp2_rx_hex_store);
+static DEVICE_ATTR(prefetch,	S_IWUSR, NULL, mv_pp2_port_store);
+
+static struct attribute *mv_pp2_attrs[] = {
 	&dev_attr_help.attr,
 	&dev_attr_rxDmaRegs.attr,
 	&dev_attr_rxqShow.attr,
@@ -181,25 +181,25 @@ static struct attribute *mv_eth_attrs[] = {
 	NULL
 };
 
-static struct attribute_group mv_eth_rx_group = {
+static struct attribute_group mv_pp2_rx_group = {
 	.name = "rx",
-	.attrs = mv_eth_attrs,
+	.attrs = mv_pp2_attrs,
 };
 
 int mv_pp2_rx_sysfs_init(struct kobject *gbe_kobj)
 {
 	int err;
 
-	err = sysfs_create_group(gbe_kobj, &mv_eth_rx_group);
+	err = sysfs_create_group(gbe_kobj, &mv_pp2_rx_group);
 	if (err)
-		pr_err("sysfs group %s failed %d\n", mv_eth_rx_group.name, err);
+		pr_err("sysfs group %s failed %d\n", mv_pp2_rx_group.name, err);
 
 	return err;
 }
 
 int mv_pp2_rx_sysfs_exit(struct kobject *gbe_kobj)
 {
-	sysfs_remove_group(gbe_kobj, &mv_eth_rx_group);
+	sysfs_remove_group(gbe_kobj, &mv_pp2_rx_group);
 
 	return 0;
 }
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.c
index 3f4af3d..126c732 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.c
@@ -39,7 +39,7 @@ disclaimer.
 #include "mv_eth_sysfs.h"
 
 
-static ssize_t mv_eth_help(char *buf)
+static ssize_t mv_pp2_help(char *buf)
 {
 	int off = 0;
 
@@ -51,7 +51,7 @@ static ssize_t mv_eth_help(char *buf)
 	off += sprintf(buf+off, "cd                 pme         - move to PME sysfs directory\n");
 	off += sprintf(buf+off, "cd                 qos         - move to QoS sysfs directory\n\n");
 
-#ifdef CONFIG_MV_ETH_HWF
+#ifdef CONFIG_MV_PP2_HWF
 	off += sprintf(buf+off, "cd                 qos         - move to QoS sysfs directory\n\n");
 #endif
 	off += sprintf(buf+off, "cat                addrDec     - show address decode registers\n");
@@ -67,7 +67,7 @@ static ssize_t mv_eth_help(char *buf)
 	off += sprintf(buf+off, "echo [0|1]       > pnc         - enable / disable Parser and Classifier access\n");
 	off += sprintf(buf+off, "echo [0|1]       > skb         - enable / disable skb recycle\n");
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 	off += sprintf(buf+off, "echo [p] [hex]   > debug       - b0:rx, b1:tx, b2:isr, b3:poll, b4:dump, b5:b_hdr\n");
 #endif
 #ifdef CONFIG_CPU_IDLE
@@ -77,7 +77,7 @@ static ssize_t mv_eth_help(char *buf)
 	return off;
 }
 
-static ssize_t mv_eth_show(struct device *dev,
+static ssize_t mv_pp2_show(struct device *dev,
 				  struct device_attribute *attr, char *buf)
 {
 	const char      *name = attr->attr.name;
@@ -90,12 +90,12 @@ static ssize_t mv_eth_show(struct device *dev,
 		/*mvPp2AddressDecodeRegsPrint();*/
 		mvPp2AddrDecodeRegs();
 	else
-		off = mv_eth_help(buf);
+		off = mv_pp2_help(buf);
 
 	return off;
 }
 
-static ssize_t mv_eth_port_store(struct device *dev,
+static ssize_t mv_pp2_port_store(struct device *dev,
 				   struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
@@ -113,11 +113,11 @@ static ssize_t mv_eth_port_store(struct device *dev,
 	local_irq_save(flags);
 
 	if (!strcmp(name, "port")) {
-		mv_eth_status_print();
-		mv_eth_port_status_print(p);
+		mv_pp2_status_print();
+		mv_pp2_eth_port_status_print(p);
 		mvPp2PortStatus(p);
 	} else if (!strcmp(name, "cntrs")) {
-		if (!MV_PON_PORT(p))
+		if (!MV_PP2_IS_PON_PORT(p))
 			mvGmacMibCountersShow(p);
 		else
 			printk(KERN_ERR "sysfs command %s is not supported for xPON port %d\n",
@@ -134,13 +134,13 @@ static ssize_t mv_eth_port_store(struct device *dev,
 		mvPp2V0DropCntrs(p);
 #endif
 	} else if (!strcmp(name, "stats")) {
-		mv_eth_port_stats_print(p);
+		mv_pp2_port_stats_print(p);
 	} else if (!strcmp(name, "mac")) {
-		mv_eth_mac_show(p);
+		mv_pp2_mac_show(p);
 	} else if (!strcmp(name, "pnc")) {
-		mv_eth_ctrl_pnc(p);
+		mv_pp2_ctrl_pnc(p);
 	} else if (!strcmp(name, "skb")) {
-		mv_eth_ctrl_recycle(p);
+		mv_pp2_eth_ctrl_recycle(p);
 	} else {
 		err = 1;
 		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
@@ -154,7 +154,7 @@ static ssize_t mv_eth_port_store(struct device *dev,
 	return err ? -EINVAL : len;
 }
 
-static ssize_t mv_eth_2_hex_store(struct device *dev,
+static ssize_t mv_pp2_2_hex_store(struct device *dev,
 				   struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
@@ -172,24 +172,24 @@ static ssize_t mv_eth_2_hex_store(struct device *dev,
 	local_irq_save(flags);
 
 	if (!strcmp(name, "debug")) {
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
-		err = mv_eth_ctrl_dbg_flag(p, MV_ETH_F_DBG_RX,   v & 0x1);
-		err = mv_eth_ctrl_dbg_flag(p, MV_ETH_F_DBG_TX,   v & 0x2);
-		err = mv_eth_ctrl_dbg_flag(p, MV_ETH_F_DBG_ISR,  v & 0x4);
-		err = mv_eth_ctrl_dbg_flag(p, MV_ETH_F_DBG_POLL, v & 0x8);
-		err = mv_eth_ctrl_dbg_flag(p, MV_ETH_F_DBG_DUMP, v & 0x10);
-		err = mv_eth_ctrl_dbg_flag(p, MV_ETH_F_DBG_BUFF_HDR, v & 0x20);
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
+		err = mv_pp2_ctrl_dbg_flag(p, MV_ETH_F_DBG_RX,   v & 0x1);
+		err = mv_pp2_ctrl_dbg_flag(p, MV_ETH_F_DBG_TX,   v & 0x2);
+		err = mv_pp2_ctrl_dbg_flag(p, MV_ETH_F_DBG_ISR,  v & 0x4);
+		err = mv_pp2_ctrl_dbg_flag(p, MV_ETH_F_DBG_POLL, v & 0x8);
+		err = mv_pp2_ctrl_dbg_flag(p, MV_ETH_F_DBG_DUMP, v & 0x10);
+		err = mv_pp2_ctrl_dbg_flag(p, MV_ETH_F_DBG_BUFF_HDR, v & 0x20);
 #endif
 	} else if (!strcmp(name, "pm_mode")) {
 #ifdef CONFIG_CPU_IDLE
-		err = mv_eth_pm_mode_set(p, v);
+		err = mv_pp2_pm_mode_set(p, v);
 #endif
 	}
 
 	return err ? -EINVAL : len;
 }
 
-static ssize_t mv_eth_netdev_store(struct device *dev,
+static ssize_t mv_pp2_netdev_store(struct device *dev,
 		struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char *name = attr->attr.name;
@@ -207,7 +207,7 @@ static ssize_t mv_eth_netdev_store(struct device *dev,
 		err = 1;
 	} else {
 		if (!strcmp(name, "netdev"))
-			mv_eth_netdev_print(netdev);
+			mv_pp2_eth_netdev_print(netdev);
 		else {
 			err = 1;
 			printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
@@ -220,7 +220,7 @@ static ssize_t mv_eth_netdev_store(struct device *dev,
 	return err ? -EINVAL : len;
 }
 
-static ssize_t mv_eth_reg_store(struct device *dev,
+static ssize_t mv_pp2_reg_store(struct device *dev,
 				   struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
@@ -255,33 +255,33 @@ static ssize_t mv_eth_reg_store(struct device *dev,
 	return err ? -EINVAL : len;
 }
 
-static DEVICE_ATTR(addrDec,	S_IRUSR, mv_eth_show, NULL);
-static DEVICE_ATTR(help,	S_IRUSR, mv_eth_show, NULL);
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
-static DEVICE_ATTR(debug,	S_IWUSR, NULL, mv_eth_2_hex_store);
+static DEVICE_ATTR(addrDec,	S_IRUSR, mv_pp2_show, NULL);
+static DEVICE_ATTR(help,	S_IRUSR, mv_pp2_show, NULL);
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
+static DEVICE_ATTR(debug,	S_IWUSR, NULL, mv_pp2_2_hex_store);
 #endif
-static DEVICE_ATTR(isrRegs,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(gmacRegs,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(dropCntrs,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(stats,       S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(mac,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(pnc,		S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(skb,         S_IWUSR, NULL, mv_eth_port_store);
-
-static DEVICE_ATTR(port,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(cntrs,	S_IWUSR, NULL, mv_eth_port_store);
-static DEVICE_ATTR(netdev,	S_IWUSR, NULL, mv_eth_netdev_store);
-
-static DEVICE_ATTR(regRead,       S_IWUSR, NULL, mv_eth_reg_store);
-static DEVICE_ATTR(regWrite,      S_IWUSR, NULL, mv_eth_reg_store);
+static DEVICE_ATTR(isrRegs,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(gmacRegs,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(dropCntrs,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(stats,       S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(mac,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(pnc,		S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(skb,         S_IWUSR, NULL, mv_pp2_port_store);
+
+static DEVICE_ATTR(port,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(cntrs,	S_IWUSR, NULL, mv_pp2_port_store);
+static DEVICE_ATTR(netdev,	S_IWUSR, NULL, mv_pp2_netdev_store);
+
+static DEVICE_ATTR(regRead,       S_IWUSR, NULL, mv_pp2_reg_store);
+static DEVICE_ATTR(regWrite,      S_IWUSR, NULL, mv_pp2_reg_store);
 #ifdef CONFIG_CPU_IDLE
-static DEVICE_ATTR(pm_mode,	S_IWUSR, NULL, mv_eth_2_hex_store);
+static DEVICE_ATTR(pm_mode,	S_IWUSR, NULL, mv_pp2_2_hex_store);
 #endif
 
-static struct attribute *mv_eth_attrs[] = {
+static struct attribute *mv_pp2_attrs[] = {
 	&dev_attr_addrDec.attr,
 	&dev_attr_help.attr,
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 	&dev_attr_debug.attr,
 #endif
 	&dev_attr_port.attr,
@@ -302,8 +302,8 @@ static struct attribute *mv_eth_attrs[] = {
 	NULL
 };
 
-static struct attribute_group mv_eth_group = {
-	.attrs = mv_eth_attrs,
+static struct attribute_group mv_pp2_group = {
+	.attrs = mv_pp2_attrs,
 };
 
 static struct kobject *gbe_kobj;
@@ -318,7 +318,7 @@ int mv_pp2_gbe_sysfs_init(struct kobject *pp2_kobj)
 		return -ENOMEM;
 	}
 
-	err = sysfs_create_group(gbe_kobj, &mv_eth_group);
+	err = sysfs_create_group(gbe_kobj, &mv_pp2_group);
 	if (err) {
 		printk(KERN_INFO "sysfs group failed %d\n", err);
 		return err;
@@ -331,7 +331,7 @@ int mv_pp2_gbe_sysfs_init(struct kobject *pp2_kobj)
 	mv_pp2_qos_sysfs_init(gbe_kobj);
 	mv_pp2_pon_sysfs_init(gbe_kobj);
 	mv_pp2_gbe_pme_sysfs_init(gbe_kobj);
-#ifdef CONFIG_MV_ETH_HWF
+#ifdef CONFIG_MV_PP2_HWF
 	mv_pp2_gbe_hwf_sysfs_init(gbe_kobj);
 #endif
 	return err;
@@ -346,10 +346,10 @@ int mv_pp2_gbe_sysfs_exit(struct kobject *pp2_kobj)
 	mv_pp2_tx_sysfs_exit(gbe_kobj);
 	mv_pp2_rx_sysfs_exit(gbe_kobj);
 	mv_pp2_bm_sysfs_exit(gbe_kobj);
-#ifdef CONFIG_MV_ETH_HWF
+#ifdef CONFIG_MV_PP2_HWF
 	mv_pp2_gbe_hwf_sysfs_exit(gbe_kobj);
 #endif
-	sysfs_remove_group(pp2_kobj, &mv_eth_group);
+	sysfs_remove_group(pp2_kobj, &mv_pp2_group);
 
 	return 0;
 }
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h
index 5789bf9..b2e121c2 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h
@@ -86,10 +86,10 @@ int mv_pp2_pon_sysfs_exit(struct kobject *pp2_kobj);
 int mv_pp2_gbe_pme_sysfs_init(struct kobject *gbe_kobj);
 int mv_pp2_gbe_pme_sysfs_exit(struct kobject *gbe_kobj);
 
-#ifdef CONFIG_MV_ETH_HWF
+#ifdef CONFIG_MV_PP2_HWF
 int mv_pp2_gbe_hwf_sysfs_init(struct kobject *gbe_kobj);
 int mv_pp2_gbe_hwf_sysfs_exit(struct kobject *gbe_kobj);
-#endif /* CONFIG_MV_ETH_HWF */
+#endif /* CONFIG_MV_PP2_HWF */
 
 int mv_pp2_dbg_sysfs_init(struct kobject *pp2_kobj);
 int mv_pp2_dbg_sysfs_exit(struct kobject *pp2_kobj);
@@ -100,7 +100,7 @@ int mv_pp2_wol_sysfs_exit(struct kobject *pp2_kobj);
 int mv_pp2_dpi_sysfs_init(struct kobject *pp2_kobj);
 int mv_pp2_dpi_sysfs_exit(struct kobject *pp2_kobj);
 
-#ifdef CONFIG_MV_ETH_L2FW
+#ifdef CONFIG_MV_PP2_L2FW
 int mv_pp2_l2fw_sysfs_init(struct kobject *pp2_kobj);
 int mv_pp2_l2fw_sysfs_exit(struct kobject *pp2_kobj);
 #endif
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.c
index 11944cd..7d73867 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.c
@@ -58,34 +58,34 @@ disclaimer.
 
 #define MV_ETH_TOOL_AN_TIMEOUT	5000
 
-struct mv_eth_tool_stats {
+struct mv_pp2_tool_stats {
 	char stat_string[ETH_GSTRING_LEN];
 	int stat_offset;
 };
 
 #define MV_ETH_TOOL_STAT(m)	offsetof(struct eth_port, m)
 
-static const struct mv_eth_tool_stats mv_eth_tool_global_strings_stats[] = {
-#ifdef CONFIG_MV_ETH_STAT_ERR
+static const struct mv_pp2_tool_stats mv_pp2_tool_global_strings_stats[] = {
+#ifdef CONFIG_MV_PP2_STAT_ERR
 	{"rx_error", MV_ETH_TOOL_STAT(stats.rx_error)},
 	{"tx_timeout", MV_ETH_TOOL_STAT(stats.tx_timeout)},
 	{"ext_stack_empty", MV_ETH_TOOL_STAT(stats.ext_stack_empty)},
 	{"ext_stack_full", MV_ETH_TOOL_STAT(stats.ext_stack_full)},
 	{"state_err", MV_ETH_TOOL_STAT(stats.state_err)},
 #endif
-#ifdef CONFIG_MV_ETH_STAT_INF
+#ifdef CONFIG_MV_PP2_STAT_INF
 	{"tx_done", MV_ETH_TOOL_STAT(stats.tx_done)},
 	{"link", MV_ETH_TOOL_STAT(stats.link)},
 	{"netdev_stop", MV_ETH_TOOL_STAT(stats.netdev_stop)},
 	{"rx_buf_hdr", MV_ETH_TOOL_STAT(stats.rx_buf_hdr)},
-#ifdef CONFIG_MV_ETH_RX_SPECIAL
+#ifdef CONFIG_MV_PP2_RX_SPECIAL
 	{"rx_special", MV_ETH_TOOL_STAT(stats.rx_special)},
 #endif
-#ifdef CONFIG_MV_ETH_TX_SPECIAL
+#ifdef CONFIG_MV_PP2_TX_SPECIAL
 	{"tx_special", MV_ETH_TOOL_STAT(stats.tx_special)},
 #endif
 #endif
-#ifdef CONFIG_MV_ETH_STAT_DBG
+#ifdef CONFIG_MV_PP2_STAT_DBG
 	{"rx_tagged", MV_ETH_TOOL_STAT(stats.rx_tagged)},
 	{"rx_netif", MV_ETH_TOOL_STAT(stats.rx_netif)},
 	{"rx_gro", MV_ETH_TOOL_STAT(stats.rx_gro)},
@@ -106,7 +106,7 @@ static const struct mv_eth_tool_stats mv_eth_tool_global_strings_stats[] = {
 	{"rate_current", MV_ETH_TOOL_STAT(rate_current)},
 };
 
-static const struct mv_eth_tool_stats mv_eth_tool_cpu_strings_stats[] = {
+static const struct mv_pp2_tool_stats mv_pp2_tool_cpu_strings_stats[] = {
 #ifdef CONFIG_MV_ETH_STATS_DEBUG
 	{"irq", MV_ETH_TOOL_STAT(stats.irq)},
 	{"irq_err", MV_ETH_TOOL_STAT(stats.irq_err)},
@@ -117,36 +117,36 @@ static const struct mv_eth_tool_stats mv_eth_tool_cpu_strings_stats[] = {
 #endif /* CONFIG_MV_ETH_STATS_DEBUG */
 };
 
-static const struct mv_eth_tool_stats mv_eth_tool_rx_queue_strings_stats[] = {
-#ifdef CONFIG_MV_ETH_STAT_DBG
+static const struct mv_pp2_tool_stats mv_pp2_tool_rx_queue_strings_stats[] = {
+#ifdef CONFIG_MV_PP2_STAT_DBG
 	{"rxq", MV_ETH_TOOL_STAT(stats.rxq)},
-#endif /* CONFIG_MV_ETH_STAT_DBG */
+#endif /* CONFIG_MV_PP2_STAT_DBG */
 };
 
-static const struct mv_eth_tool_stats mv_eth_tool_tx_queue_strings_stats[] = {
+static const struct mv_pp2_tool_stats mv_pp2_tool_tx_queue_strings_stats[] = {
 };
 
 #define MV_ETH_TOOL_CPU_STATS_LEN	\
-	(sizeof(mv_eth_tool_cpu_strings_stats) / sizeof(struct mv_eth_tool_stats))
+	(sizeof(mv_pp2_tool_cpu_strings_stats) / sizeof(struct mv_pp2_tool_stats))
 
 #define MV_ETH_TOOL_RX_QUEUE_STATS_LEN	\
-	(sizeof(mv_eth_tool_rx_queue_strings_stats) / sizeof(struct mv_eth_tool_stats))
+	(sizeof(mv_pp2_tool_rx_queue_strings_stats) / sizeof(struct mv_pp2_tool_stats))
 
 #define MV_ETH_TOOL_TX_QUEUE_STATS_LEN	\
-	(sizeof(mv_eth_tool_tx_queue_strings_stats) / sizeof(struct mv_eth_tool_stats))
+	(sizeof(mv_pp2_tool_tx_queue_strings_stats) / sizeof(struct mv_pp2_tool_stats))
 
 #define MV_ETH_TOOL_QUEUE_STATS_LEN	\
-	((MV_ETH_TOOL_RX_QUEUE_STATS_LEN * CONFIG_MV_ETH_RXQ) + \
-	(MV_ETH_TOOL_TX_QUEUE_STATS_LEN * CONFIG_MV_ETH_TXQ))
+	((MV_ETH_TOOL_RX_QUEUE_STATS_LEN * CONFIG_MV_PP2_RXQ) + \
+	(MV_ETH_TOOL_TX_QUEUE_STATS_LEN * CONFIG_MV_PP2_TXQ))
 
 #define MV_ETH_TOOL_GLOBAL_STATS_LEN	\
-	(sizeof(mv_eth_tool_global_strings_stats) / sizeof(struct mv_eth_tool_stats))
+	(sizeof(mv_pp2_tool_global_strings_stats) / sizeof(struct mv_pp2_tool_stats))
 
 #define MV_ETH_TOOL_STATS_LEN		\
 	(MV_ETH_TOOL_GLOBAL_STATS_LEN + MV_ETH_TOOL_CPU_STATS_LEN + MV_ETH_TOOL_QUEUE_STATS_LEN)
 
 /******************************************************************************
-* mv_eth_tool_get_settings
+* mv_pp2_eth_tool_get_settings
 * Description:
 *	ethtool get standard port settings
 * INPUT:
@@ -157,7 +157,7 @@ static const struct mv_eth_tool_stats mv_eth_tool_tx_queue_strings_stats[] = {
 *	0 for success
 *
 *******************************************************************************/
-int mv_eth_tool_get_settings(struct net_device *netdev, struct ethtool_cmd *cmd)
+int mv_pp2_eth_tool_get_settings(struct net_device *netdev, struct ethtool_cmd *cmd)
 {
 	struct eth_port 	*priv = MV_ETH_PRIV(netdev);
 	u16			lp_ad, stat1000;
@@ -166,7 +166,7 @@ int mv_eth_tool_get_settings(struct net_device *netdev, struct ethtool_cmd *cmd)
 	MV_ETH_PORT_DUPLEX 	duplex;
 	MV_ETH_PORT_STATUS      status;
 
-	if ((priv == NULL) || (MV_PON_PORT(priv->port))) {
+	if ((priv == NULL) || (MV_PP2_IS_PON_PORT(priv->port))) {
 		printk(KERN_ERR "%s is not supported on %s\n", __func__, netdev->name);
 		return -EOPNOTSUPP;
 	}
@@ -238,7 +238,7 @@ int mv_eth_tool_get_settings(struct net_device *netdev, struct ethtool_cmd *cmd)
 
 
 /******************************************************************************
-* mv_eth_tool_restore_settings
+* mv_pp2_eth_tool_restore_settings
 * Description:
 *	restore saved speed/dublex/an settings
 * INPUT:
@@ -249,7 +249,7 @@ int mv_eth_tool_get_settings(struct net_device *netdev, struct ethtool_cmd *cmd)
 *	0 for success
 *
 *******************************************************************************/
-int mv_eth_tool_restore_settings(struct net_device *netdev)
+int mv_pp2_eth_tool_restore_settings(struct net_device *netdev)
 {
 	struct eth_port 	*priv = MV_ETH_PRIV(netdev);
 	int			phy_speed, phy_duplex;
@@ -321,7 +321,7 @@ int mv_eth_tool_restore_settings(struct net_device *netdev)
 
 
 /******************************************************************************
-* mv_eth_tool_set_settings
+* mv_pp2_eth_tool_set_settings
 * Description:
 *	ethtool set standard port settings
 * INPUT:
@@ -333,12 +333,12 @@ int mv_eth_tool_restore_settings(struct net_device *netdev)
 *	0 for success
 *
 *******************************************************************************/
-int mv_eth_tool_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+int mv_pp2_eth_tool_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
 {
 	struct eth_port *priv = MV_ETH_PRIV(dev);
 	int _speed, _duplex, _autoneg, _advertise, err;
 
-	if ((priv == NULL) || (MV_PON_PORT(priv->port))) {
+	if ((priv == NULL) || (MV_PP2_IS_PON_PORT(priv->port))) {
 		printk(KERN_ERR "%s is not supported on %s\n", __func__, dev->name);
 		return -EOPNOTSUPP;
 	}
@@ -352,7 +352,7 @@ int mv_eth_tool_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
 	priv->speed_cfg = cmd->speed;
 	priv->autoneg_cfg = cmd->autoneg;
 	priv->advertise_cfg = cmd->advertising;
-	err = mv_eth_tool_restore_settings(dev);
+	err = mv_pp2_eth_tool_restore_settings(dev);
 
 	if (err) {
 		priv->duplex_cfg = _duplex;
@@ -364,7 +364,7 @@ int mv_eth_tool_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
 }
 
 /******************************************************************************
-* mv_eth_tool_get_regs_len
+* mv_pp2_eth_tool_get_regs_len
 * Description:
 *	ethtool get registers array length
 * INPUT:
@@ -375,7 +375,7 @@ int mv_eth_tool_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
 *	registers array length
 *
 *******************************************************************************/
-int mv_eth_tool_get_regs_len(struct net_device *netdev)
+int mv_pp2_eth_tool_get_regs_len(struct net_device *netdev)
 {
 #define MV_ETH_TOOL_REGS_LEN 42
 
@@ -383,7 +383,7 @@ int mv_eth_tool_get_regs_len(struct net_device *netdev)
 }
 
 /******************************************************************************
-* mv_eth_tool_get_wol
+* mv_pp2_eth_tool_get_wol
 * Description:
 *	ethtool get WOL information
 * INPUT:
@@ -394,7 +394,7 @@ int mv_eth_tool_get_regs_len(struct net_device *netdev)
 *	0 on success
 *
 *******************************************************************************/
-void mv_eth_tool_get_wol(struct net_device *netdev,
+void mv_pp2_eth_tool_get_wol(struct net_device *netdev,
 			 struct ethtool_wolinfo *wolinfo)
 {
 	struct eth_port	*priv = MV_ETH_PRIV(netdev);
@@ -417,7 +417,7 @@ void mv_eth_tool_get_wol(struct net_device *netdev,
 }
 
 /******************************************************************************
-* mv_eth_tool_set_wol
+* mv_pp2_eth_tool_set_wol
 * Description:
 *	ethtool set WOL
 * INPUT:
@@ -429,7 +429,7 @@ void mv_eth_tool_get_wol(struct net_device *netdev,
 *	None
 *
 *******************************************************************************/
-int mv_eth_tool_set_wol(struct net_device *netdev,
+int mv_pp2_eth_tool_set_wol(struct net_device *netdev,
 			 struct ethtool_wolinfo *wolinfo)
 {
 	int ret;
@@ -484,7 +484,7 @@ int mv_eth_tool_set_wol(struct net_device *netdev,
 }
 
 /******************************************************************************
-* mv_eth_tool_get_drvinfo
+* mv_pp2_eth_tool_get_drvinfo
 * Description:
 *	ethtool get driver information
 * INPUT:
@@ -496,7 +496,7 @@ int mv_eth_tool_set_wol(struct net_device *netdev,
 *	None
 *
 *******************************************************************************/
-void mv_eth_tool_get_drvinfo(struct net_device *netdev,
+void mv_pp2_eth_tool_get_drvinfo(struct net_device *netdev,
 			     struct ethtool_drvinfo *info)
 {
 	strcpy(info->driver, "mv_eth");
@@ -504,13 +504,13 @@ void mv_eth_tool_get_drvinfo(struct net_device *netdev,
 	strcpy(info->bus_info, "Mbus");
 	info->n_stats = MV_ETH_TOOL_STATS_LEN;
 	info->testinfo_len = 0;
-	info->regdump_len = mv_eth_tool_get_regs_len(netdev);
+	info->regdump_len = mv_pp2_eth_tool_get_regs_len(netdev);
 	info->eedump_len = 0;
 }
 
 
 /******************************************************************************
-* mv_eth_tool_get_regs
+* mv_pp2_eth_tool_get_regs
 * Description:
 *	ethtool get registers array
 * INPUT:
@@ -522,13 +522,13 @@ void mv_eth_tool_get_drvinfo(struct net_device *netdev,
 *	None
 *
 *******************************************************************************/
-void mv_eth_tool_get_regs(struct net_device *netdev,
+void mv_pp2_eth_tool_get_regs(struct net_device *netdev,
 			  struct ethtool_regs *regs, void *p)
 {
 	struct eth_port *priv = MV_ETH_PRIV(netdev);
 	uint32_t	*regs_buff = p;
 
-	if ((priv == NULL) || MV_PON_PORT(priv->port)) {
+	if ((priv == NULL) || MV_PP2_IS_PON_PORT(priv->port)) {
 		printk(KERN_ERR "%s is not supported on %s\n", __func__, netdev->name);
 		return;
 	}
@@ -558,7 +558,7 @@ void mv_eth_tool_get_regs(struct net_device *netdev,
 
 
 /******************************************************************************
-* mv_eth_tool_nway_reset
+* mv_pp2_eth_tool_nway_reset
 * Description:
 *	ethtool restart auto negotiation
 * INPUT:
@@ -569,12 +569,12 @@ void mv_eth_tool_get_regs(struct net_device *netdev,
 *	0 on success
 *
 *******************************************************************************/
-int mv_eth_tool_nway_reset(struct net_device *netdev)
+int mv_pp2_eth_tool_nway_reset(struct net_device *netdev)
 {
 	struct eth_port *priv = MV_ETH_PRIV(netdev);
 	MV_U32	        phy_addr;
 
-	if ((priv == NULL) || (MV_PON_PORT(priv->port))) {
+	if ((priv == NULL) || (MV_PP2_IS_PON_PORT(priv->port))) {
 		printk(KERN_ERR "interface %s is not supported\n", netdev->name);
 		return -EOPNOTSUPP;
 	}
@@ -588,7 +588,7 @@ int mv_eth_tool_nway_reset(struct net_device *netdev)
 
 
 /******************************************************************************
-* mv_eth_tool_get_link
+* mv_pp2_eth_tool_get_link
 * Description:
 *	ethtool get link status
 * INPUT:
@@ -599,7 +599,7 @@ int mv_eth_tool_nway_reset(struct net_device *netdev)
 *	0 if link is down, 1 if link is up
 *
 *******************************************************************************/
-u32 mv_eth_tool_get_link(struct net_device *netdev)
+u32 mv_pp2_eth_tool_get_link(struct net_device *netdev)
 {
 	struct eth_port     *pp = MV_ETH_PRIV(netdev);
 
@@ -609,7 +609,7 @@ u32 mv_eth_tool_get_link(struct net_device *netdev)
 	}
 
 #ifdef CONFIG_MV_INCLUDE_PON
-	if (MV_PON_PORT(pp->port))
+	if (MV_PP2_IS_PON_PORT(pp->port))
 		return mv_pon_link_status(NULL);
 #endif /* CONFIG_MV_PON */
 
@@ -618,7 +618,7 @@ u32 mv_eth_tool_get_link(struct net_device *netdev)
 
 
 /******************************************************************************
-* mv_eth_tool_get_coalesce
+* mv_pp2_eth_tool_get_coalesce
 * Description:
 *	ethtool get RX/TX coalesce parameters
 * INPUT:
@@ -629,7 +629,7 @@ u32 mv_eth_tool_get_link(struct net_device *netdev)
 *	0 on success
 *
 *******************************************************************************/
-int mv_eth_tool_get_coalesce(struct net_device *netdev,
+int mv_pp2_eth_tool_get_coalesce(struct net_device *netdev,
 			     struct ethtool_coalesce *cmd)
 {
 	struct eth_port *pp = MV_ETH_PRIV(netdev);
@@ -637,7 +637,7 @@ int mv_eth_tool_get_coalesce(struct net_device *netdev,
 	   notice that if you use ethtool to set coal, then all queues have the same value */
 	cmd->rx_coalesce_usecs = pp->rx_time_coal_cfg;
 	cmd->rx_max_coalesced_frames = pp->rx_pkts_coal_cfg;
-#ifdef CONFIG_MV_ETH_TXDONE_ISR
+#ifdef CONFIG_MV_PP2_TXDONE_ISR
 	cmd->tx_max_coalesced_frames = pp->tx_pkts_coal_cfg;
 #endif
 
@@ -655,7 +655,7 @@ int mv_eth_tool_get_coalesce(struct net_device *netdev,
 }
 
 /******************************************************************************
-* mv_eth_tool_set_coalesce
+* mv_pp2_eth_tool_set_coalesce
 * Description:
 *	ethtool set RX/TX coalesce parameters
 * INPUT:
@@ -667,7 +667,7 @@ int mv_eth_tool_get_coalesce(struct net_device *netdev,
 *	0 on success
 *
 *******************************************************************************/
-int mv_eth_tool_set_coalesce(struct net_device *netdev,
+int mv_pp2_eth_tool_set_coalesce(struct net_device *netdev,
 			     struct ethtool_coalesce *cmd)
 {
 	struct eth_port *pp = MV_ETH_PRIV(netdev);
@@ -676,26 +676,26 @@ int mv_eth_tool_set_coalesce(struct net_device *netdev,
 	/* can't set rx coalesce with both 0 pkts and 0 usecs,  tx coalesce supports only pkts */
 	if (!cmd->rx_coalesce_usecs && !cmd->rx_max_coalesced_frames)
 		return -EPERM;
-#ifdef CONFIG_MV_ETH_TXDONE_ISR
+#ifdef CONFIG_MV_PP2_TXDONE_ISR
 	if (!cmd->tx_max_coalesced_frames)
 		return -EPERM;
 #endif
 
 	if (!cmd->use_adaptive_rx_coalesce)
-		for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++) {
-			mv_eth_rx_ptks_coal_set(pp->port, rxq, cmd->rx_max_coalesced_frames);
-			mv_eth_rx_time_coal_set(pp->port, rxq, cmd->rx_coalesce_usecs);
+		for (rxq = 0; rxq < CONFIG_MV_PP2_RXQ; rxq++) {
+			mv_pp2_rx_ptks_coal_set(pp->port, rxq, cmd->rx_max_coalesced_frames);
+			mv_pp2_rx_time_coal_set(pp->port, rxq, cmd->rx_coalesce_usecs);
 		}
 
 	pp->rx_time_coal_cfg = cmd->rx_coalesce_usecs;
 	pp->rx_pkts_coal_cfg = cmd->rx_max_coalesced_frames;
-#ifdef CONFIG_MV_ETH_TXDONE_ISR
+#ifdef CONFIG_MV_PP2_TXDONE_ISR
 	{
 		int txp, txq;
 
 		for (txp = 0; txp < pp->txp_num; txp++)
-			for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++)
-				mv_eth_tx_done_ptks_coal_set(pp->port, txp, txq, cmd->tx_max_coalesced_frames);
+			for (txq = 0; txq < CONFIG_MV_PP2_TXQ; txq++)
+				mv_pp2_tx_done_ptks_coal_set(pp->port, txp, txq, cmd->tx_max_coalesced_frames);
 	}
 #endif
 	pp->tx_pkts_coal_cfg = cmd->tx_max_coalesced_frames;
@@ -723,7 +723,7 @@ int mv_eth_tool_set_coalesce(struct net_device *netdev,
 
 
 /******************************************************************************
-* mv_eth_tool_get_ringparam
+* mv_pp2_eth_tool_get_ringparam
 * Description:
 *	ethtool get ring parameters
 * INPUT:
@@ -734,7 +734,7 @@ int mv_eth_tool_set_coalesce(struct net_device *netdev,
 *	None
 *
 *******************************************************************************/
-void mv_eth_tool_get_ringparam(struct net_device *netdev,
+void mv_pp2_eth_tool_get_ringparam(struct net_device *netdev,
 				struct ethtool_ringparam *ring)
 {
 	struct eth_port *priv = MV_ETH_PRIV(netdev);
@@ -745,7 +745,7 @@ void mv_eth_tool_get_ringparam(struct net_device *netdev,
 }
 
 /******************************************************************************
-* mv_eth_tool_set_ringparam
+* mv_pp2_eth_tool_set_ringparam
 * Description:
 *	ethtool set ring parameters
 * INPUT:
@@ -756,7 +756,7 @@ void mv_eth_tool_get_ringparam(struct net_device *netdev,
 *	None
 *
 *******************************************************************************/
-int mv_eth_tool_set_ringparam(struct net_device *netdev,
+int mv_pp2_eth_tool_set_ringparam(struct net_device *netdev,
 				 struct ethtool_ringparam *ring)
 {
 	struct eth_port *priv = MV_ETH_PRIV(netdev);
@@ -775,11 +775,11 @@ int mv_eth_tool_set_ringparam(struct net_device *netdev,
 		netdev_running = 1;
 
 	if (netdev_running)
-		mv_eth_stop(netdev);
+		mv_pp2_eth_stop(netdev);
 
 	if (rxq_size != priv->rxq_ctrl[0].rxq_size)
 		for (rxq = 0; rxq < priv->rxq_num; rxq++)
-			mv_eth_ctrl_rxq_size_set(priv->port, rxq, rxq_size);
+			mv_pp2_ctrl_rxq_size_set(priv->port, rxq, rxq_size);
 
 #ifdef CONFIG_MV_ETH_PP2_1
 	hwf_size = txq_size - (nr_cpu_ids * priv->txq_ctrl[0].rsvd_chunk);
@@ -791,20 +791,20 @@ int mv_eth_tool_set_ringparam(struct net_device *netdev,
 
 	if (txq_size != priv->txq_ctrl[0].txq_size)
 		for (txp = 0; txp < priv->txp_num; txp++)
-			for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++) {
-				mv_eth_ctrl_txq_size_set(priv->port, txp, txq, txq_size);
+			for (txq = 0; txq < CONFIG_MV_PP2_TXQ; txq++) {
+				mv_pp2_ctrl_txq_size_set(priv->port, txp, txq, txq_size);
 				/* swf_size is ignored if ppv2.0 */
-				mv_eth_ctrl_txq_limits_set(priv->port, txp, txq, hwf_size, swf_size);
+				mv_pp2_ctrl_txq_limits_set(priv->port, txp, txq, hwf_size, swf_size);
 			}
 
 	if (netdev_running)
-		mv_eth_open(netdev);
+		mv_pp2_eth_open(netdev);
 
 	return 0;
 }
 
 /******************************************************************************
-* mv_eth_tool_get_pauseparam
+* mv_pp2_eth_tool_get_pauseparam
 * Description:
 *	ethtool get pause parameters
 * INPUT:
@@ -815,7 +815,7 @@ int mv_eth_tool_set_ringparam(struct net_device *netdev,
 *	None
 *
 *******************************************************************************/
-void mv_eth_tool_get_pauseparam(struct net_device *netdev,
+void mv_pp2_eth_tool_get_pauseparam(struct net_device *netdev,
 				struct ethtool_pauseparam *pause)
 {
 	struct eth_port      *priv = MV_ETH_PRIV(netdev);
@@ -823,7 +823,7 @@ void mv_eth_tool_get_pauseparam(struct net_device *netdev,
 	MV_ETH_PORT_STATUS   portStatus;
 	MV_ETH_PORT_FC       flowCtrl;
 
-	if ((priv == NULL) || (MV_PON_PORT(priv->port))) {
+	if ((priv == NULL) || (MV_PP2_IS_PON_PORT(priv->port))) {
 		printk(KERN_ERR "%s is not supported on %s\n", __func__, netdev->name);
 		return;
 	}
@@ -850,7 +850,7 @@ void mv_eth_tool_get_pauseparam(struct net_device *netdev,
 
 
 /******************************************************************************
-* mv_eth_tool_set_pauseparam
+* mv_pp2_eth_tool_set_pauseparam
 * Description:
 *	ethtool configure pause parameters
 * INPUT:
@@ -862,7 +862,7 @@ void mv_eth_tool_get_pauseparam(struct net_device *netdev,
 *	0 on success
 *
 *******************************************************************************/
-int mv_eth_tool_set_pauseparam(struct net_device *netdev,
+int mv_pp2_eth_tool_set_pauseparam(struct net_device *netdev,
 				struct ethtool_pauseparam *pause)
 {
 	struct eth_port *priv = MV_ETH_PRIV(netdev);
@@ -870,7 +870,7 @@ int mv_eth_tool_set_pauseparam(struct net_device *netdev,
 	MV_U32			phy_addr;
 	MV_STATUS		status = MV_FAIL;
 
-	if ((priv == NULL) || (MV_PON_PORT(priv->port))) {
+	if ((priv == NULL) || (MV_PP2_IS_PON_PORT(priv->port))) {
 		printk(KERN_ERR "%s is not supported on %s\n", __func__, netdev->name);
 		return -EOPNOTSUPP;
 	}
@@ -900,7 +900,7 @@ int mv_eth_tool_set_pauseparam(struct net_device *netdev,
 }
 
 /******************************************************************************
-* mv_eth_tool_get_strings
+* mv_pp2_eth_tool_get_strings
 * Description:
 *	ethtool get strings (used for statistics and self-test descriptions)
 * INPUT:
@@ -912,7 +912,7 @@ int mv_eth_tool_set_pauseparam(struct net_device *netdev,
 *	None
 *
 *******************************************************************************/
-void mv_eth_tool_get_strings(struct net_device *netdev,
+void mv_pp2_eth_tool_get_strings(struct net_device *netdev,
 			     uint32_t stringset, uint8_t *data)
 {
 	uint8_t *p = data;
@@ -922,26 +922,26 @@ void mv_eth_tool_get_strings(struct net_device *netdev,
 	switch (stringset) {
 	case ETH_SS_TEST:
 		/*
-		memcpy(data, *mv_eth_tool_gstrings_test,
+		memcpy(data, *mv_pp2_tool_gstrings_test,
 		       MV_ETH_TOOL_TEST_LEN*ETH_GSTRING_LEN); */
 		break;
 	case ETH_SS_STATS:
 		for (i = 0; i < MV_ETH_TOOL_GLOBAL_STATS_LEN; i++) {
-			memcpy(p, mv_eth_tool_global_strings_stats[i].stat_string,
+			memcpy(p, mv_pp2_tool_global_strings_stats[i].stat_string,
 			       ETH_GSTRING_LEN);
 			p += ETH_GSTRING_LEN;
 		}
-		for (q = 0; q < CONFIG_MV_ETH_RXQ; q++) {
+		for (q = 0; q < CONFIG_MV_PP2_RXQ; q++) {
 			for (i = 0; i < MV_ETH_TOOL_RX_QUEUE_STATS_LEN; i++) {
-				const char *str = mv_eth_tool_rx_queue_strings_stats[i].stat_string;
+				const char *str = mv_pp2_tool_rx_queue_strings_stats[i].stat_string;
 				memcpy(p, str, ETH_GSTRING_LEN);
 				strcat(p, qnum[q]);
 				p += ETH_GSTRING_LEN;
 			}
 		}
-		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
+		for (q = 0; q < CONFIG_MV_PP2_TXQ; q++) {
 			for (i = 0; i < MV_ETH_TOOL_TX_QUEUE_STATS_LEN; i++) {
-				const char *str = mv_eth_tool_tx_queue_strings_stats[i].stat_string;
+				const char *str = mv_pp2_tool_tx_queue_strings_stats[i].stat_string;
 				memcpy(p, str, ETH_GSTRING_LEN);
 				strcat(p, qnum[q]);
 				p += ETH_GSTRING_LEN;
@@ -953,7 +953,7 @@ void mv_eth_tool_get_strings(struct net_device *netdev,
 
 
 /******************************************************************************
-* mv_eth_tool_get_stats_count
+* mv_pp2_eth_tool_get_stats_count
 * Description:
 *	ethtool get statistics count (number of stat. array entries)
 * INPUT:
@@ -964,13 +964,12 @@ void mv_eth_tool_get_strings(struct net_device *netdev,
 *	statistics count
 *
 *******************************************************************************/
-int mv_eth_tool_get_stats_count(struct net_device *netdev)
+int mv_pp2_eth_tool_get_stats_count(struct net_device *netdev)
 {
-/*	printk("in %s \n",__FUNCTION__);*/
 	return 0;
 }
 
-static int mv_eth_tool_get_rxnfc(struct net_device *dev, struct ethtool_rxnfc *info,
+static int mv_pp2_eth_tool_get_rxnfc(struct net_device *dev, struct ethtool_rxnfc *info,
 									 u32 *rules)
 {
 	if (info->cmd == ETHTOOL_GRXRINGS) {
@@ -982,7 +981,7 @@ static int mv_eth_tool_get_rxnfc(struct net_device *dev, struct ethtool_rxnfc *i
 }
 
 /******************************************************************************
-* mv_eth_tool_get_ethtool_stats
+* mv_pp2_eth_tool_get_ethtool_stats
 * Description:
 *	ethtool get statistics
 * INPUT:
@@ -994,7 +993,7 @@ static int mv_eth_tool_get_rxnfc(struct net_device *dev, struct ethtool_rxnfc *i
 *	None
 *
 *******************************************************************************/
-void mv_eth_tool_get_ethtool_stats(struct net_device *netdev,
+void mv_pp2_eth_tool_get_ethtool_stats(struct net_device *netdev,
 				   struct ethtool_stats *stats, uint64_t *data)
 {
 	struct eth_port	*priv = MV_ETH_PRIV(netdev);
@@ -1004,31 +1003,31 @@ void mv_eth_tool_get_ethtool_stats(struct net_device *netdev,
 
 	for (i = 0; i < MV_ETH_TOOL_GLOBAL_STATS_LEN; i++) {
 		char *p = (char *)priv +
-			mv_eth_tool_global_strings_stats[i].stat_offset;
+			mv_pp2_tool_global_strings_stats[i].stat_offset;
 		pdest[i] =  *(uint32_t *)p;
 	}
 	pdest += MV_ETH_TOOL_GLOBAL_STATS_LEN;
 
 	for (i = 0; i < MV_ETH_TOOL_CPU_STATS_LEN; i++) {
 		char *p = (char *)priv +
-			mv_eth_tool_cpu_strings_stats[i].stat_offset;
+			mv_pp2_tool_cpu_strings_stats[i].stat_offset;
 		pdest[i] =  *((uint32_t *)p + cpu);
 	}
 	pdest += MV_ETH_TOOL_CPU_STATS_LEN;
 
-	for (q = 0; q < CONFIG_MV_ETH_RXQ; q++) {
+	for (q = 0; q < CONFIG_MV_PP2_RXQ; q++) {
 		for (i = 0; i < MV_ETH_TOOL_RX_QUEUE_STATS_LEN; i++) {
 			char *p = (char *)priv +
-				mv_eth_tool_rx_queue_strings_stats[i].stat_offset;
+				mv_pp2_tool_rx_queue_strings_stats[i].stat_offset;
 			pdest[i] =  *((uint32_t *)p + q);
 		}
 		pdest += MV_ETH_TOOL_RX_QUEUE_STATS_LEN;
 	}
 
-	for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
+	for (q = 0; q < CONFIG_MV_PP2_TXQ; q++) {
 		for (i = 0; i < MV_ETH_TOOL_TX_QUEUE_STATS_LEN; i++) {
 			char *p = (char *)priv +
-				mv_eth_tool_tx_queue_strings_stats[i].stat_offset;
+				mv_pp2_tool_tx_queue_strings_stats[i].stat_offset;
 			pdest[i] =  *((uint32_t *)p + q);
 		}
 		pdest += MV_ETH_TOOL_TX_QUEUE_STATS_LEN;
@@ -1037,7 +1036,7 @@ void mv_eth_tool_get_ethtool_stats(struct net_device *netdev,
 
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 0, 0)
 /******************************************************************************
-* mv_eth_tool_set_phys_id
+* mv_pp2_eth_tool_set_phys_id
 * Description:
 *	ethtool set indicator state for physical identification
 * INPUT:
@@ -1049,7 +1048,7 @@ void mv_eth_tool_get_ethtool_stats(struct net_device *netdev,
 *	Set results
 *
 *******************************************************************************/
-static int mv_eth_tool_set_phys_id(struct net_device *netdev,
+static int mv_pp2_eth_tool_set_phys_id(struct net_device *netdev,
 			     enum ethtool_phys_id_state state)
 {
 	/* we can only set Blink Duty Cycle and Blink Duration for Blink1 and Blink0
@@ -1085,7 +1084,7 @@ static int mv_eth_tool_set_phys_id(struct net_device *netdev,
 }
 #else
 /******************************************************************************
-* mv_eth_tool_phys_id
+* mv_pp2_eth_tool_phys_id
 * Description:
 *	ethtool set indicator state for physical identification
 * INPUT:
@@ -1097,7 +1096,7 @@ static int mv_eth_tool_set_phys_id(struct net_device *netdev,
 *	Set results
 *
 *******************************************************************************/
-static int mv_eth_tool_phys_id(struct net_device *netdev,
+static int mv_pp2_eth_tool_phys_id(struct net_device *netdev,
 			     uint32_t data)
 {
 	/* we can only set Blink Duty Cycle and Blink Duration for Blink1 and Blink0
@@ -1121,7 +1120,7 @@ static int mv_eth_tool_phys_id(struct net_device *netdev,
 #endif
 
 /******************************************************************************
-* mv_eth_tool_get_sset_count
+* mv_pp2_eth_tool_get_sset_count
 * Description:
 *	ethtool get stringset count
 * INPUT:
@@ -1133,7 +1132,7 @@ static int mv_eth_tool_phys_id(struct net_device *netdev,
 *	stringset length
 *
 *******************************************************************************/
-static int mv_eth_tool_get_sset_count(struct net_device *netdev, int sset)
+static int mv_pp2_eth_tool_get_sset_count(struct net_device *netdev, int sset)
 {
 	switch (sset) {
 	case ETH_SS_STATS:
@@ -1143,36 +1142,36 @@ static int mv_eth_tool_get_sset_count(struct net_device *netdev, int sset)
 	}
 }
 
-const struct ethtool_ops mv_eth_tool_ops = {
-	.get_settings				= mv_eth_tool_get_settings,
-	.set_settings				= mv_eth_tool_set_settings,
-	.get_drvinfo				= mv_eth_tool_get_drvinfo,
-	.get_regs_len				= mv_eth_tool_get_regs_len,
-	.get_regs				= mv_eth_tool_get_regs,
-	.get_wol				= mv_eth_tool_get_wol,
-	.set_wol				= mv_eth_tool_set_wol,
-	.nway_reset				= mv_eth_tool_nway_reset,
-	.get_link				= mv_eth_tool_get_link,
-	.get_coalesce				= mv_eth_tool_get_coalesce,
-	.set_coalesce				= mv_eth_tool_set_coalesce,
-	.get_ringparam  			= mv_eth_tool_get_ringparam,
-	.set_ringparam 				= mv_eth_tool_set_ringparam,
-	.get_pauseparam				= mv_eth_tool_get_pauseparam,
-	.set_pauseparam				= mv_eth_tool_set_pauseparam,
-	.get_strings				= mv_eth_tool_get_strings,
+const struct ethtool_ops mv_pp2_eth_tool_ops = {
+	.get_settings				= mv_pp2_eth_tool_get_settings,
+	.set_settings				= mv_pp2_eth_tool_set_settings,
+	.get_drvinfo				= mv_pp2_eth_tool_get_drvinfo,
+	.get_regs_len				= mv_pp2_eth_tool_get_regs_len,
+	.get_regs				= mv_pp2_eth_tool_get_regs,
+	.get_wol				= mv_pp2_eth_tool_get_wol,
+	.set_wol				= mv_pp2_eth_tool_set_wol,
+	.nway_reset				= mv_pp2_eth_tool_nway_reset,
+	.get_link				= mv_pp2_eth_tool_get_link,
+	.get_coalesce				= mv_pp2_eth_tool_get_coalesce,
+	.set_coalesce				= mv_pp2_eth_tool_set_coalesce,
+	.get_ringparam				= mv_pp2_eth_tool_get_ringparam,
+	.set_ringparam				= mv_pp2_eth_tool_set_ringparam,
+	.get_pauseparam				= mv_pp2_eth_tool_get_pauseparam,
+	.set_pauseparam				= mv_pp2_eth_tool_set_pauseparam,
+	.get_strings				= mv_pp2_eth_tool_get_strings,
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 32)
-	.get_stats_count			= mv_eth_tool_get_stats_count,/*TODO: complete implementation */
+	.get_stats_count			= mv_pp2_eth_tool_get_stats_count,/*TODO: complete implementation */
 #endif
-	.get_ethtool_stats			= mv_eth_tool_get_ethtool_stats,/*TODO: complete implementation */
-	/*.get_rxfh_indir			= mv_eth_tool_get_rxfh_indir,
-	.set_rxfh_indir				= mv_eth_tool_set_rxfh_indir, */
-	.get_rxnfc                  		= mv_eth_tool_get_rxnfc,/*TODO new implementation*/
+	.get_ethtool_stats			= mv_pp2_eth_tool_get_ethtool_stats,/*TODO: complete implementation */
+	/*.get_rxfh_indir			= mv_pp2_eth_tool_get_rxfh_indir,
+	.set_rxfh_indir				= mv_pp2_eth_tool_set_rxfh_indir, */
+	.get_rxnfc				= mv_pp2_eth_tool_get_rxnfc,/*TODO new implementation*/
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 0, 0)
-	.set_phys_id				= mv_eth_tool_set_phys_id,
+	.set_phys_id				= mv_pp2_eth_tool_set_phys_id,
 #else
-	.phys_id				= mv_eth_tool_phys_id,
+	.phys_id				= mv_pp2_eth_tool_phys_id,
 #endif
-	.get_sset_count				= mv_eth_tool_get_sset_count,
+	.get_sset_count				= mv_pp2_eth_tool_get_sset_count,
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 5, 0)
 	.get_ts_info				= ethtool_op_get_ts_info,
 #endif
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.h
index a2c600c..61c6be0 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tool.h
@@ -30,6 +30,6 @@ disclaimer.
 
 #include <linux/ethtool.h>
 
-extern const struct ethtool_ops mv_eth_tool_ops;
+extern const struct ethtool_ops mv_pp2_eth_tool_ops;
 
 #endif
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tx_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tx_sysfs.c
index 358da87..636221a 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tx_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_tx_sysfs.c
@@ -37,7 +37,7 @@ disclaimer.
 #include "mv_netdev.h"
 
 
-static ssize_t mv_eth_help(char *buf)
+static ssize_t mv_pp2_help(char *buf)
 {
 	int off = 0;
 
@@ -64,7 +64,7 @@ static ssize_t mv_eth_help(char *buf)
 	return off;
 }
 
-static ssize_t mv_eth_show(struct device *dev,
+static ssize_t mv_pp2_show(struct device *dev,
 				  struct device_attribute *attr, char *buf)
 {
 	const char      *name = attr->attr.name;
@@ -76,12 +76,12 @@ static ssize_t mv_eth_show(struct device *dev,
 	if (!strcmp(name, "txRegs"))
 		mvPp2TxRegs();
 	else
-		off = mv_eth_help(buf);
+		off = mv_pp2_help(buf);
 
 	return off;
 }
 
-static ssize_t mv_eth_tx_hex_store(struct device *dev,
+static ssize_t mv_pp2_tx_hex_store(struct device *dev,
 				struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
@@ -99,11 +99,11 @@ static ssize_t mv_eth_tx_hex_store(struct device *dev,
 	local_irq_save(flags);
 
 	if (!strcmp(name, "txFlags")) {
-		err = mv_eth_ctrl_tx_flag(p, MV_ETH_TX_F_NO_PAD, v & 0x1);
-		err = mv_eth_ctrl_tx_flag(p, MV_ETH_TX_F_MH, v & 0x2);
-		err = mv_eth_ctrl_tx_flag(p, MV_ETH_TX_F_HW_CMD, v & 0x4);
+		err = mv_pp2_ctrl_tx_flag(p, MV_ETH_TX_F_NO_PAD, v & 0x1);
+		err = mv_pp2_ctrl_tx_flag(p, MV_ETH_TX_F_MH, v & 0x2);
+		err = mv_pp2_ctrl_tx_flag(p, MV_ETH_TX_F_HW_CMD, v & 0x4);
 	} else if (!strcmp(name, "txMH")) {
-		err = mv_eth_ctrl_tx_mh(p, MV_16BIT_BE((u16)v));
+		err = mv_pp2_eth_ctrl_tx_mh(p, MV_16BIT_BE((u16)v));
 	} else {
 		err = 1;
 		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
@@ -116,7 +116,7 @@ static ssize_t mv_eth_tx_hex_store(struct device *dev,
 	return err ? -EINVAL : len;
 }
 
-static ssize_t mv_eth_txq_store(struct device *dev,
+static ssize_t mv_pp2_txq_store(struct device *dev,
 				   struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char      *name = attr->attr.name;
@@ -134,7 +134,7 @@ static ssize_t mv_eth_txq_store(struct device *dev,
 	local_irq_save(flags);
 
 	if (!strcmp(name, "txqDef")) {
-		err = mv_eth_ctrl_txq_cpu_def(p, v, a, b);
+		err = mv_pp2_ctrl_txq_cpu_def(p, v, a, b);
 	} else if (!strcmp(name, "txqShow")) {
 		mvPp2TxqShow(p, v, a, b);
 	}  else if (!strcmp(name, "aggrTxqShow")) {
@@ -148,12 +148,12 @@ static ssize_t mv_eth_txq_store(struct device *dev,
 	} else if (!strcmp(name, "aggrTxqRegs")) {
 		mvPp2AggrTxqRegs(p);
 	} else if (!strcmp(name, "txqSize")) {
-		mv_eth_ctrl_txq_size_set(p, v, a, b);
+		mv_pp2_ctrl_txq_size_set(p, v, a, b);
 	} else if (!strcmp(name, "txqLimit")) {
 		/* last param is ignored in ppv2.0 */
-		mv_eth_ctrl_txq_limits_set(p, v, a, b, c);
+		mv_pp2_ctrl_txq_limits_set(p, v, a, b, c);
 	} else if (!strcmp(name, "txqChunk")) {
-		mv_eth_ctrl_txq_chunk_set(p, v, a, b);
+		mv_pp2_ctrl_txq_chunk_set(p, v, a, b);
 	} else {
 		err = 1;
 		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
@@ -167,22 +167,22 @@ static ssize_t mv_eth_txq_store(struct device *dev,
 	return err ? -EINVAL : len;
 }
 
-static DEVICE_ATTR(help,         S_IRUSR, mv_eth_show, NULL);
-static DEVICE_ATTR(txRegs,       S_IRUSR, mv_eth_show, NULL);
-static DEVICE_ATTR(aggrTxqRegs,  S_IWUSR, NULL, mv_eth_txq_store);
-static DEVICE_ATTR(pTxqCounters, S_IWUSR, NULL, mv_eth_txq_store);
-static DEVICE_ATTR(txqShow,      S_IWUSR, NULL, mv_eth_txq_store);
-static DEVICE_ATTR(gTxqRegs,     S_IWUSR, NULL, mv_eth_txq_store);
-static DEVICE_ATTR(pTxqRegs,     S_IWUSR, NULL, mv_eth_txq_store);
-static DEVICE_ATTR(aggrTxqShow,  S_IWUSR, NULL, mv_eth_txq_store);
-static DEVICE_ATTR(txqDef,       S_IWUSR, NULL, mv_eth_txq_store);
-static DEVICE_ATTR(txqSize,      S_IWUSR, NULL, mv_eth_txq_store);
-static DEVICE_ATTR(txqLimit,     S_IWUSR, NULL, mv_eth_txq_store);
-static DEVICE_ATTR(txqChunk,     S_IWUSR, NULL, mv_eth_txq_store);
-static DEVICE_ATTR(txFlags,      S_IWUSR, NULL, mv_eth_tx_hex_store);
-static DEVICE_ATTR(txMH,         S_IWUSR, NULL, mv_eth_tx_hex_store);
-
-static struct attribute *mv_eth_tx_attrs[] = {
+static DEVICE_ATTR(help,         S_IRUSR, mv_pp2_show, NULL);
+static DEVICE_ATTR(txRegs,       S_IRUSR, mv_pp2_show, NULL);
+static DEVICE_ATTR(aggrTxqRegs,  S_IWUSR, NULL, mv_pp2_txq_store);
+static DEVICE_ATTR(pTxqCounters, S_IWUSR, NULL, mv_pp2_txq_store);
+static DEVICE_ATTR(txqShow,      S_IWUSR, NULL, mv_pp2_txq_store);
+static DEVICE_ATTR(gTxqRegs,     S_IWUSR, NULL, mv_pp2_txq_store);
+static DEVICE_ATTR(pTxqRegs,     S_IWUSR, NULL, mv_pp2_txq_store);
+static DEVICE_ATTR(aggrTxqShow,  S_IWUSR, NULL, mv_pp2_txq_store);
+static DEVICE_ATTR(txqDef,       S_IWUSR, NULL, mv_pp2_txq_store);
+static DEVICE_ATTR(txqSize,      S_IWUSR, NULL, mv_pp2_txq_store);
+static DEVICE_ATTR(txqLimit,     S_IWUSR, NULL, mv_pp2_txq_store);
+static DEVICE_ATTR(txqChunk,     S_IWUSR, NULL, mv_pp2_txq_store);
+static DEVICE_ATTR(txFlags,      S_IWUSR, NULL, mv_pp2_tx_hex_store);
+static DEVICE_ATTR(txMH,         S_IWUSR, NULL, mv_pp2_tx_hex_store);
+
+static struct attribute *mv_pp2_tx_attrs[] = {
 	&dev_attr_txqDef.attr,
 	&dev_attr_pTxqCounters.attr,
 	&dev_attr_aggrTxqRegs.attr,
@@ -200,25 +200,25 @@ static struct attribute *mv_eth_tx_attrs[] = {
 	NULL
 };
 
-static struct attribute_group mv_eth_tx_group = {
+static struct attribute_group mv_pp2_tx_group = {
 	.name = "tx",
-	.attrs = mv_eth_tx_attrs,
+	.attrs = mv_pp2_tx_attrs,
 };
 
 int mv_pp2_tx_sysfs_init(struct kobject *gbe_kobj)
 {
 	int err;
 
-	err = sysfs_create_group(gbe_kobj, &mv_eth_tx_group);
+	err = sysfs_create_group(gbe_kobj, &mv_pp2_tx_group);
 	if (err)
-		pr_err("sysfs group %s failed %d\n", mv_eth_tx_group.name, err);
+		pr_err("sysfs group %s failed %d\n", mv_pp2_tx_group.name, err);
 
 	return err;
 }
 
 int mv_pp2_tx_sysfs_exit(struct kobject *gbe_kobj)
 {
-	sysfs_remove_group(gbe_kobj, &mv_eth_tx_group);
+	sysfs_remove_group(gbe_kobj, &mv_pp2_tx_group);
 
 	return 0;
 }
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_ethernet.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_ethernet.c
index 6fec0c3..665175a 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_ethernet.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_ethernet.c
@@ -43,17 +43,15 @@ disclaimer.
 
 #include "mv_netdev.h"
 
-extern unsigned int mv_eth_pnc_ctrl_en;
-
-static int mv_eth_set_mac_addr_internals(struct net_device *dev, void *addr);
+static int mv_pp2_set_mac_addr_internals(struct net_device *dev, void *addr);
 
 /***********************************************************
- * mv_eth_start --                                         *
+ * mv_pp2_start --                                         *
  *   start a network device. connect and enable interrupts *
  *   set hw defaults. fill rx buffers. restart phy link    *
  *   auto neg. set device link flags. report status.       *
  ***********************************************************/
-int mv_eth_start(struct net_device *dev)
+int mv_pp2_start(struct net_device *dev)
 {
 	struct eth_port *priv = MV_ETH_PRIV(dev);
 	int group;
@@ -65,19 +63,19 @@ int mv_eth_start(struct net_device *dev)
 	netif_tx_stop_all_queues(dev);
 
 	/* fill rx buffers, start rx/tx activity, set coalescing */
-	if (mv_eth_start_internals(priv, dev->mtu) != 0) {
+	if (mv_pp2_start_internals(priv, dev->mtu) != 0) {
 		printk(KERN_ERR "%s: start internals failed\n", dev->name);
 		goto error;
 	}
 	/* enable polling on the port, must be used after netif_poll_disable */
 	if (priv->flags & MV_ETH_F_CONNECT_LINUX) {
-		for (group = 0; group < MV_ETH_MAX_RXQ; group++)
+		for (group = 0; group < MV_PP2_MAX_RXQ; group++)
 			if (priv->napi_group[group] && priv->napi_group[group]->napi)
 				napi_enable(priv->napi_group[group]->napi);
 	}
 	if (priv->flags & MV_ETH_F_LINK_UP) {
 
-		if (mv_eth_ctrl_is_tx_enabled(priv)) {
+		if (mv_pp2_ctrl_is_tx_enabled(priv)) {
 			netif_carrier_on(dev);
 			netif_tx_wake_all_queues(dev);
 		}
@@ -86,16 +84,16 @@ int mv_eth_start(struct net_device *dev)
 
 	if (priv->flags & MV_ETH_F_CONNECT_LINUX) {
 		/* connect to port interrupt line */
-		if (request_irq(dev->irq, mv_eth_isr, (IRQF_DISABLED), dev->name, priv)) {
+		if (request_irq(dev->irq, mv_pp2_isr, (IRQF_DISABLED), dev->name, priv)) {
 			printk(KERN_ERR "cannot request irq %d for %s port %d\n", dev->irq, dev->name, priv->port);
-			for (group = 0; group < MV_ETH_MAX_RXQ; group++)
+			for (group = 0; group < MV_PP2_MAX_RXQ; group++)
 				if (priv->napi_group[group] && priv->napi_group[group]->napi)
 					napi_disable(priv->napi_group[group]->napi);
 			goto error;
 		}
 
 		/* unmask interrupts */
-		on_each_cpu(mv_eth_interrupts_unmask, (void *)priv, 1);
+		on_each_cpu(mv_pp2_interrupts_unmask, (void *)priv, 1);
 
 		/* Enable interrupts for all CPUs */
 		mvPp2GbeCpuInterruptsEnable(priv->port, priv->cpuMask);
@@ -107,10 +105,10 @@ int mv_eth_start(struct net_device *dev)
 	}
 
 	/* Enable GMAC */
-	if (!MV_PON_PORT(priv->port))
+	if (!MV_PP2_IS_PON_PORT(priv->port))
 		mvGmacPortEnable(priv->port);
 
-	mv_eth_link_event(priv, 1);
+	mv_pp2_link_event(priv, 1);
 
 	return 0;
 
@@ -120,11 +118,11 @@ error:
 }
 
 /***********************************************************
- * mv_eth_stop --                                          *
+ * mv_pp2_eth_stop --                                          *
  *   stop interface with linux core. stop port activity.   *
  *   free skb's from rings.                                *
  ***********************************************************/
-int mv_eth_stop(struct net_device *dev)
+int mv_pp2_eth_stop(struct net_device *dev)
 {
 	struct eth_port *priv = MV_ETH_PRIV(dev);
 	struct cpu_ctrl *cpuCtrl;
@@ -138,10 +136,10 @@ int mv_eth_stop(struct net_device *dev)
 	/* Disable interrupts for all CPUs */
 	mvPp2GbeCpuInterruptsDisable(priv->port, priv->cpuMask);
 
-	on_each_cpu(mv_eth_interrupts_mask, priv, 1);
+	on_each_cpu(mv_pp2_interrupts_mask, priv, 1);
 
 	/* make sure that the port finished its Rx polling */
-	for (group = 0; group < MV_ETH_MAX_RXQ; group++)
+	for (group = 0; group < MV_PP2_MAX_RXQ; group++)
 		if (priv->napi_group[group] && priv->napi_group[group]->napi)
 			napi_disable(priv->napi_group[group]->napi);
 
@@ -150,7 +148,7 @@ int mv_eth_stop(struct net_device *dev)
 	netif_tx_stop_all_queues(dev);
 
 	/* stop tx/rx activity, mask all interrupts, relese skb in rings,*/
-	mv_eth_stop_internals(priv);
+	mv_pp2_stop_internals(priv);
 	for_each_possible_cpu(cpu) {
 		cpuCtrl = priv->cpu_config[cpu];
 		del_timer(&cpuCtrl->tx_done_timer);
@@ -161,7 +159,7 @@ int mv_eth_stop(struct net_device *dev)
 
 	mvPp2PortEgressEnable(priv->port, MV_FALSE);
 
-	if (!MV_PON_PORT(priv->port))
+	if (!MV_PP2_IS_PON_PORT(priv->port))
 		mvGmacPortDisable(priv->port);
 
 	printk(KERN_NOTICE "%s: stopped\n", dev->name);
@@ -170,16 +168,16 @@ int mv_eth_stop(struct net_device *dev)
 }
 
 
-int mv_eth_change_mtu(struct net_device *dev, int mtu)
+int mv_pp2_eth_change_mtu(struct net_device *dev, int mtu)
 {
 	int old_mtu = dev->mtu;
 
-	mtu = mv_eth_check_mtu_valid(dev, mtu);
+	mtu = mv_pp2_eth_check_mtu_valid(dev, mtu);
 	if (mtu < 0)
 		return -EINVAL;
 
 	if (!netif_running(dev)) {
-		if (mv_eth_change_mtu_internals(dev, mtu) == -1)
+		if (mv_pp2_eth_change_mtu_internals(dev, mtu) == -1)
 			goto error;
 
 		printk(KERN_NOTICE "%s: change mtu %d (packet-size %d) to %d (packet-size %d)\n",
@@ -188,7 +186,7 @@ int mv_eth_change_mtu(struct net_device *dev, int mtu)
 		return 0;
 	}
 
-	if (mv_eth_check_mtu_internals(dev, mtu))
+	if (mv_pp2_check_mtu_internals(dev, mtu))
 		goto error;
 
 	if (dev->netdev_ops->ndo_stop(dev)) {
@@ -196,7 +194,7 @@ int mv_eth_change_mtu(struct net_device *dev, int mtu)
 		goto error;
 	}
 
-	if (mv_eth_change_mtu_internals(dev, mtu) == -1) {
+	if (mv_pp2_eth_change_mtu_internals(dev, mtu) == -1) {
 		printk(KERN_ERR "%s change mtu internals failed\n", dev->name);
 		goto error;
 	}
@@ -220,18 +218,18 @@ error:
  *   stop port activity. set new addr in device and hw.    *
  *   restart port activity.                                *
  ***********************************************************/
-static int mv_eth_set_mac_addr_internals(struct net_device *dev, void *addr)
+static int mv_pp2_set_mac_addr_internals(struct net_device *dev, void *addr)
 {
 	u8              *mac = &(((u8 *)addr)[2]);  /* skip on first 2B (ether HW addr type) */
 	int             i;
 
 	struct eth_port *priv = MV_ETH_PRIV(dev);
 
-	if (!mv_eth_pnc_ctrl_en) {
+	if (!mv_pp2_pnc_ctrl_en) {
 		printk(KERN_ERR "%s Error: PARSER and CLASSIFIER control is disabled\n", __func__);
 
 		/* linux stop the port */
-		mv_eth_open(dev);
+		mv_pp2_eth_open(dev);
 		return -1;
 	}
 
@@ -247,7 +245,7 @@ static int mv_eth_set_mac_addr_internals(struct net_device *dev, void *addr)
 
 #ifdef CONFIG_MV_INCLUDE_PON
 	/* Update PON module */
-	if (MV_PON_PORT(priv->port))
+	if (MV_PP2_IS_PON_PORT(priv->port))
 		mv_pon_set_mac_addr(addr);
 #endif
 
@@ -256,12 +254,12 @@ static int mv_eth_set_mac_addr_internals(struct net_device *dev, void *addr)
 	return 0;
 }
 
-void mv_eth_rx_set_rx_mode(struct net_device *dev)
+void mv_pp2_rx_set_rx_mode(struct net_device *dev)
 {
 	struct eth_port     *priv = MV_ETH_PRIV(dev);
 	int                 phyPort = MV_PPV2_PORT_PHYS(priv->port);
 
-	if (!mv_eth_pnc_ctrl_en) {
+	if (!mv_pp2_pnc_ctrl_en) {
 		pr_err("%s Error: PARSER and CLASSIFIER control is disabled\n", __func__);
 		return;
 	}
@@ -308,10 +306,10 @@ void mv_eth_rx_set_rx_mode(struct net_device *dev)
 }
 
 
-int     mv_eth_set_mac_addr(struct net_device *dev, void *addr)
+int     mv_pp2_eth_set_mac_addr(struct net_device *dev, void *addr)
 {
 	if (!netif_running(dev)) {
-		if (mv_eth_set_mac_addr_internals(dev, addr) == -1)
+		if (mv_pp2_set_mac_addr_internals(dev, addr) == -1)
 			goto error;
 		return 0;
 	}
@@ -321,7 +319,7 @@ int     mv_eth_set_mac_addr(struct net_device *dev, void *addr)
 		goto error;
 	}
 
-	if (mv_eth_set_mac_addr_internals(dev, addr) == -1)
+	if (mv_pp2_set_mac_addr_internals(dev, addr) == -1)
 		goto error;
 
 	if (dev->netdev_ops->ndo_open(dev)) {
@@ -338,17 +336,17 @@ error:
 
 
 /************************************************************
- * mv_eth_open -- Restore MAC address and call to   *
- *                mv_eth_start                               *
+ * mv_pp2_eth_open -- Restore MAC address and call to   *
+ *                    mv_pp2_start                      *
  ************************************************************/
-int mv_eth_open(struct net_device *dev)
+int mv_pp2_eth_open(struct net_device *dev)
 {
 
 	struct	eth_port *priv = MV_ETH_PRIV(dev);
 	int	phyPort = MV_PPV2_PORT_PHYS(priv->port);
 	static  u8 mac_bcast[MV_MAC_ADDR_SIZE] = { 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF };
 
-	if (mv_eth_pnc_ctrl_en) {
+	if (mv_pp2_pnc_ctrl_en) {
 
 		if (mvPrsMacDaAccept(phyPort, mac_bcast, 1 /*add*/)) {
 			printk(KERN_ERR "%s:mvPrsMacDaAccept\n", dev->name);
@@ -367,7 +365,7 @@ int mv_eth_open(struct net_device *dev)
 				return -1;
 		}
 	}
-	if (mv_eth_start(dev)) {
+	if (mv_pp2_start(dev)) {
 		printk(KERN_ERR "%s: start interface failed\n", dev->name);
 		return -1;
 	}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
index 4be5512..0f549e6 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
@@ -58,17 +58,17 @@ disclaimer.
 #include "mv_eth_tool.h"
 #include "mv_eth_sysfs.h"
 
-#define MV_ETH_MAX_NAPI_GROUPS	MV_ETH_MAX_RXQ
+#define MV_ETH_MAX_NAPI_GROUPS	MV_PP2_MAX_RXQ
 
 #define MV_ETH_TX_PENDING_TIMEOUT_MSEC     1000
 
-#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+#ifdef CONFIG_MV_PP2_SWF_HWF_CORRUPTION_WA
 static unsigned int mv_pp2_swf_hwf_wa_en;
 void mv_pp2_cache_inv_wa_ctrl(int en)
 {
 	mv_pp2_swf_hwf_wa_en = en;
 }
-void mv_eth_iocc_l1_l2_cache_inv(unsigned char *v_start, int size)
+void mv_pp2_iocc_l1_l2_cache_inv(unsigned char *v_start, int size)
 {
 	if (mv_pp2_swf_hwf_wa_en)
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 34)
@@ -77,14 +77,14 @@ void mv_eth_iocc_l1_l2_cache_inv(unsigned char *v_start, int size)
 		dma_cache_maint(v_start, size, DMA_FROM_DEVICE);
 #endif
 }
-#endif /* CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA */
+#endif /* CONFIG_MV_PP2_SWF_HWF_CORRUPTION_WA */
 
 static struct mv_mux_eth_ops mux_eth_ops;
 
 static struct  platform_device *pp2_sysfs;
 
 /*
-platform_device used in mv_eth_all_ports_probe only for debug
+platform_device used in mv_pp2_all_ports_probe only for debug
 */
 
 struct platform_device *plats[MV_ETH_MAX_PORTS];
@@ -93,77 +93,77 @@ struct platform_device *plats[MV_ETH_MAX_PORTS];
 static void *sync_head;
 static u32   sync_rx_desc;
 
-static inline int mv_eth_tx_policy(struct eth_port *pp, struct sk_buff *skb);
+static inline int mv_pp2_tx_policy(struct eth_port *pp, struct sk_buff *skb);
 
-#ifdef CONFIG_NET_SKB_RECYCLE
-int mv_ctrl_recycle = CONFIG_NET_SKB_RECYCLE_DEF;
-EXPORT_SYMBOL(mv_ctrl_recycle);
+#ifdef CONFIG_MV_PP2_SKB_RECYCLE
+int mv_ctrl_pp2_recycle = CONFIG_MV_PP2_SKB_RECYCLE_DEF;
+EXPORT_SYMBOL(mv_ctrl_pp2_recycle);
 
-int mv_eth_ctrl_recycle(int en)
+int mv_pp2_eth_ctrl_recycle(int en)
 {
-	mv_ctrl_recycle = en;
+	mv_ctrl_pp2_recycle = en;
 	return 0;
 }
 #else
-int mv_eth_ctrl_recycle(int en)
+int mv_pp2_eth_ctrl_recycle(int en)
 {
 	printk(KERN_ERR "SKB recycle is not supported\n");
 	return 1;
 }
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_PP2_SKB_RECYCLE */
 
-struct bm_pool mv_eth_pool[MV_ETH_BM_POOLS];
-struct eth_port **mv_eth_ports;
+struct bm_pool mv_pp2_pool[MV_ETH_BM_POOLS];
+struct eth_port **mv_pp2_ports;
 struct aggr_tx_queue *aggr_txqs;
 EXPORT_SYMBOL(aggr_txqs);
 
-int mv_ctrl_txdone = CONFIG_MV_ETH_TXDONE_COAL_PKTS;
-EXPORT_SYMBOL(mv_ctrl_txdone);
+int mv_ctrl_pp2_txdone = CONFIG_MV_PP2_TXDONE_COAL_PKTS;
+EXPORT_SYMBOL(mv_ctrl_pp2_txdone);
 
-unsigned int mv_eth_pnc_ctrl_en = 1;
+unsigned int mv_pp2_pnc_ctrl_en = 1;
 
 /*
  * Static declarations
  */
-static int mv_eth_ports_num = 0;
+static int mv_pp2_ports_num;
 
-static int mv_eth_initialized = 0;
+static int mv_pp2_initialized;
 
 static struct tasklet_struct link_tasklet;
 
 /*
  * Local functions
  */
-static void mv_eth_txq_delete(struct eth_port *pp, struct tx_queue *txq_ctrl);
-static void mv_eth_tx_timeout(struct net_device *dev);
-static int  mv_eth_tx(struct sk_buff *skb, struct net_device *dev);
-static void mv_eth_tx_frag_process(struct eth_port *pp, struct sk_buff *skb, struct aggr_tx_queue *aggr_txq_ctrl,
-		struct tx_queue *txq_ctrl, struct mv_eth_tx_spec *tx_spec);
-
-static void mv_eth_config_show(void);
-static int  mv_eth_priv_init(struct eth_port *pp, int port);
-static void mv_eth_priv_cleanup(struct eth_port *pp);
-static int  mv_eth_config_get(struct platform_device *pdev, u8 *mac);
-static int  mv_eth_hal_init(struct eth_port *pp);
-struct net_device *mv_eth_netdev_init(int mtu, u8 *mac, struct platform_device *pdev);
-static int mv_eth_netdev_connect(struct eth_port *pp);
-static void mv_eth_netdev_init_features(struct net_device *dev);
+static void mv_pp2_txq_delete(struct eth_port *pp, struct tx_queue *txq_ctrl);
+static void mv_pp2_tx_timeout(struct net_device *dev);
+static int  mv_pp2_tx(struct sk_buff *skb, struct net_device *dev);
+static void mv_pp2_tx_frag_process(struct eth_port *pp, struct sk_buff *skb, struct aggr_tx_queue *aggr_txq_ctrl,
+		struct tx_queue *txq_ctrl, struct mv_pp2_tx_spec *tx_spec);
+
+static void mv_pp2_config_show(void);
+static int  mv_pp2_priv_init(struct eth_port *pp, int port);
+static void mv_pp2_priv_cleanup(struct eth_port *pp);
+static int  mv_pp2_config_get(struct platform_device *pdev, u8 *mac);
+static int  mv_pp2_hal_init(struct eth_port *pp);
+struct net_device *mv_pp2_netdev_init(int mtu, u8 *mac, struct platform_device *pdev);
+static int mv_pp2_netdev_connect(struct eth_port *pp);
+static void mv_pp2_netdev_init_features(struct net_device *dev);
 #if LINUX_VERSION_CODE < KERNEL_VERSION(3, 4, 25)
-static u32 mv_eth_netdev_fix_features(struct net_device *dev, u32 features);
+static u32 mv_pp2_netdev_fix_features(struct net_device *dev, u32 features);
 #else
-static netdev_features_t mv_eth_netdev_fix_features(struct net_device *dev, netdev_features_t features);
+static netdev_features_t mv_pp2_netdev_fix_features(struct net_device *dev, netdev_features_t features);
 #endif
 
-static struct sk_buff *mv_eth_skb_alloc(struct bm_pool *pool, phys_addr_t *phys_addr, gfp_t gfp_mask);
-static MV_STATUS mv_eth_pool_create(int pool, int capacity);
-static int mv_eth_pool_add(int pool, int buf_num);
-static int mv_eth_pool_free(int pool, int num);
-static int mv_eth_pool_destroy(int pool);
-static struct bm_pool *mv_eth_pool_use(int pool, enum mv_eth_bm_type type, int pkt_size);
+static struct sk_buff *mv_pp2_skb_alloc(struct bm_pool *pool, phys_addr_t *phys_addr, gfp_t gfp_mask);
+static MV_STATUS mv_pp2_pool_create(int pool, int capacity);
+static int mv_pp2_pool_add(int pool, int buf_num);
+static int mv_pp2_pool_free(int pool, int num);
+static int mv_pp2_pool_destroy(int pool);
+static struct bm_pool *mv_pp2_pool_use(int pool, enum mv_pp2_bm_type type, int pkt_size);
 
-#ifdef CONFIG_MV_ETH_TSO
-int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_eth_tx_spec *tx_spec,
-			struct tx_queue *txq_ctrl, struct aggr_tx_queue *aggr_txq_ctrl);
+#ifdef CONFIG_MV_PP2_TSO
+static int mv_pp2_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_pp2_tx_spec *tx_spec,
+			 struct tx_queue *txq_ctrl, struct aggr_tx_queue *aggr_txq_ctrl);
 #endif
 
 #if defined(CONFIG_NETMAP) || defined(CONFIG_NETMAP_MODULE)
@@ -171,15 +171,15 @@ int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_eth_tx_
 #endif
 
 
-void mv_eth_ctrl_pnc(int en)
+void mv_pp2_ctrl_pnc(int en)
 {
-	mv_eth_pnc_ctrl_en = en;
+	mv_pp2_pnc_ctrl_en = en;
 }
 
 /*****************************************
  *          Adaptive coalescing          *
  *****************************************/
-static void mv_eth_adaptive_rx_update(struct eth_port *pp)
+static void mv_pp2_adaptive_rx_update(struct eth_port *pp)
 {
 	unsigned long period = jiffies - pp->rx_timestamp;
 
@@ -190,25 +190,25 @@ static void mv_eth_adaptive_rx_update(struct eth_port *pp)
 		if (rate < pp->pkt_rate_low_cfg) {
 			if (pp->rate_current != 1) {
 				pp->rate_current = 1;
-				for (i = 0; i < CONFIG_MV_ETH_RXQ; i++) {
-					mv_eth_rx_time_coal_set(pp->port, i, pp->rx_time_low_coal_cfg);
-					mv_eth_rx_ptks_coal_set(pp->port, i, pp->rx_pkts_low_coal_cfg);
+				for (i = 0; i < CONFIG_MV_PP2_RXQ; i++) {
+					mv_pp2_rx_time_coal_set(pp->port, i, pp->rx_time_low_coal_cfg);
+					mv_pp2_rx_ptks_coal_set(pp->port, i, pp->rx_pkts_low_coal_cfg);
 				}
 			}
 		} else if (rate > pp->pkt_rate_high_cfg) {
 			if (pp->rate_current != 3) {
 				pp->rate_current = 3;
-				for (i = 0; i < CONFIG_MV_ETH_RXQ; i++) {
-					mv_eth_rx_time_coal_set(pp->port, i, pp->rx_time_high_coal_cfg);
-					mv_eth_rx_ptks_coal_set(pp->port, i, pp->rx_pkts_high_coal_cfg);
+				for (i = 0; i < CONFIG_MV_PP2_RXQ; i++) {
+					mv_pp2_rx_time_coal_set(pp->port, i, pp->rx_time_high_coal_cfg);
+					mv_pp2_rx_ptks_coal_set(pp->port, i, pp->rx_pkts_high_coal_cfg);
 				}
 			}
 		} else {
 			if (pp->rate_current != 2) {
 				pp->rate_current = 2;
-				for (i = 0; i < CONFIG_MV_ETH_RXQ; i++) {
-					mv_eth_rx_time_coal_set(pp->port, i, pp->rx_time_coal_cfg);
-					mv_eth_rx_ptks_coal_set(pp->port, i, pp->rx_pkts_coal_cfg);
+				for (i = 0; i < CONFIG_MV_PP2_RXQ; i++) {
+					mv_pp2_rx_time_coal_set(pp->port, i, pp->rx_time_coal_cfg);
+					mv_pp2_rx_ptks_coal_set(pp->port, i, pp->rx_pkts_coal_cfg);
 				}
 			}
 		}
@@ -221,9 +221,9 @@ static void mv_eth_adaptive_rx_update(struct eth_port *pp)
 /*****************************************
  *            MUX function                *
  *****************************************/
-static int mv_eth_tag_type_set(int port, int type)
+static int mv_pp2_tag_type_set(int port, int type)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if ((type == MV_TAG_TYPE_MH) || (type == MV_TAG_TYPE_DSA) || (type == MV_TAG_TYPE_EDSA))
 		mvPp2MhSet(port, type);
@@ -236,9 +236,9 @@ static int mv_eth_tag_type_set(int port, int type)
  *            NAPI Group API             *
  *****************************************/
 /* Add/update a new empty napi_group */
-int mv_eth_port_napi_group_create(int port, int group)
+int mv_pp2_port_napi_group_create(int port, int group)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	struct napi_group_ctrl *napi_group;
 
 	if ((group < 0) || (group >= MV_ETH_MAX_NAPI_GROUPS)) {
@@ -263,7 +263,7 @@ int mv_eth_port_napi_group_create(int port, int group)
 	}
 
 	memset(napi_group->napi, 0, sizeof(struct napi_struct));
-	netif_napi_add(pp->dev, napi_group->napi, mv_eth_poll, pp->weight);
+	netif_napi_add(pp->dev, napi_group->napi, mv_pp2_poll, pp->weight);
 	pp->napi_group[group] = napi_group;
 	napi_group->id = group;
 
@@ -271,9 +271,9 @@ int mv_eth_port_napi_group_create(int port, int group)
 }
 
 /* Delete napi_group */
-int mv_eth_port_napi_group_delete(int port, int group)
+int mv_pp2_port_napi_group_delete(int port, int group)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	struct napi_group_ctrl *napi_group;
 
 	if ((group < 0) || (group >= MV_ETH_MAX_NAPI_GROUPS)) {
@@ -299,9 +299,9 @@ int mv_eth_port_napi_group_delete(int port, int group)
 	return 0;
 }
 
-int mv_eth_napi_set_cpu_affinity(int port, int group, int cpu_mask)
+int mv_pp2_napi_set_cpu_affinity(int port, int group, int cpu_mask)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	struct napi_group_ctrl *napi_group;
 	int i, cpu;
 
@@ -352,9 +352,9 @@ int mv_eth_napi_set_cpu_affinity(int port, int group, int cpu_mask)
 	return 0;
 }
 
-int mv_eth_napi_set_rxq_affinity(int port, int group, int rxq_mask)
+int mv_pp2_eth_napi_set_rxq_affinity(int port, int group, int rxq_mask)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	struct napi_group_ctrl *napi_group;
 	int i;
 
@@ -398,25 +398,25 @@ int mv_eth_napi_set_rxq_affinity(int port, int group, int rxq_mask)
 
 /**********************************************************/
 
-struct eth_port *mv_eth_port_by_id(unsigned int port)
+struct eth_port *mv_pp2_port_by_id(unsigned int port)
 {
-	if (mv_eth_ports && (port < mv_eth_ports_num))
-		return mv_eth_ports[port];
+	if (mv_pp2_ports && (port < mv_pp2_ports_num))
+		return mv_pp2_ports[port];
 
 	return NULL;
 }
 
 /* return the first port in port_mask that is up, or -1 if all ports are down */
-static int mv_eth_port_up_get(unsigned int port_mask)
+static int mv_pp2_port_up_get(unsigned int port_mask)
 {
 	int port;
 	struct eth_port *pp;
 
-	for (port = 0; port < mv_eth_ports_num; port++) {
+	for (port = 0; port < mv_pp2_ports_num; port++) {
 		if (!((1 << port) & port_mask))
 			continue;
 
-		pp = mv_eth_port_by_id(port);
+		pp = mv_pp2_port_by_id(port);
 		if (pp == NULL)
 			continue;
 
@@ -427,7 +427,7 @@ static int mv_eth_port_up_get(unsigned int port_mask)
 	return -1;
 }
 
-static inline int mv_eth_skb_mh_add(struct sk_buff *skb, u16 mh)
+static inline int mv_pp2_skb_mh_add(struct sk_buff *skb, u16 mh)
 {
        /* sanity: Check that there is place for MH in the buffer */
        if (skb_headroom(skb) < MV_ETH_MH_SIZE) {
@@ -444,20 +444,20 @@ static inline int mv_eth_skb_mh_add(struct sk_buff *skb, u16 mh)
 	return 0;
 }
 
-static inline int mv_eth_mh_skb_skip(struct sk_buff *skb)
+static inline int mv_pp2_mh_skb_skip(struct sk_buff *skb)
 {
 	__skb_pull(skb, MV_ETH_MH_SIZE);
 	return MV_ETH_MH_SIZE;
 }
 
-void mv_eth_ctrl_txdone(int num)
+void mv_pp2_ctrl_txdone(int num)
 {
-	mv_ctrl_txdone = num;
+	mv_ctrl_pp2_txdone = num;
 }
 
-int mv_eth_ctrl_tx_flag(int port, u32 flag, u32 val)
+int mv_pp2_ctrl_tx_flag(int port, u32 flag, u32 val)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	u32 bit_flag = (fls(flag) - 1);
 
 	if (!pp)
@@ -471,9 +471,9 @@ int mv_eth_ctrl_tx_flag(int port, u32 flag, u32 val)
 	return 0;
 }
 
-int mv_eth_ctrl_flag(int port, u32 flag, u32 val)
+int mv_pp2_ctrl_flag(int port, u32 flag, u32 val)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	u32 bit_flag = (fls(flag) - 1);
 
 	if (!pp)
@@ -487,10 +487,10 @@ int mv_eth_ctrl_flag(int port, u32 flag, u32 val)
 	return 0;
 }
 
-int mv_eth_ctrl_dbg_flag(int port, u32 flag, u32 val)
+int mv_pp2_ctrl_dbg_flag(int port, u32 flag, u32 val)
 {
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
-	struct eth_port *pp = mv_eth_port_by_id(port);
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	u32 bit_flag = (fls(flag) - 1);
 
 	if (!pp)
@@ -500,14 +500,14 @@ int mv_eth_ctrl_dbg_flag(int port, u32 flag, u32 val)
 		pp->dbg_flags |= (1 << bit_flag);
 	else
 		pp->dbg_flags &= ~(1 << bit_flag);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 	return 0;
 }
 
-/* mv_eth_ctrl_pool_port_map_get					*
+/* mv_pp2_ctrl_pool_port_map_get					*
  *     - Return ports map use this BM pool			*/
-int mv_eth_ctrl_pool_port_map_get(int pool)
+int mv_pp2_ctrl_pool_port_map_get(int pool)
 {
 	struct bm_pool *ppool;
 
@@ -516,7 +516,7 @@ int mv_eth_ctrl_pool_port_map_get(int pool)
 		return -1;
 	}
 
-	ppool = &mv_eth_pool[pool];
+	ppool = &mv_pp2_pool[pool];
 	if (ppool == NULL) {
 		pr_err("%s: BM pool %d is not initialized\n", __func__, pool);
 		return -1;
@@ -524,10 +524,10 @@ int mv_eth_ctrl_pool_port_map_get(int pool)
 	return ppool->port_map;
 }
 
-/* mv_eth_ctrl_pool_buf_num_set					*
+/* mv_pp2_ctrl_pool_buf_num_set					*
  *     - Set number of buffers for BM pool			*
  *     - Add or remove buffers to this pool accordingly		*/
-int mv_eth_ctrl_pool_buf_num_set(int pool, int buf_num)
+int mv_pp2_ctrl_pool_buf_num_set(int pool, int buf_num)
 {
 	unsigned long flags = 0;
 	struct bm_pool *ppool;
@@ -537,7 +537,7 @@ int mv_eth_ctrl_pool_buf_num_set(int pool, int buf_num)
 		return -1;
 	}
 
-	ppool = &mv_eth_pool[pool];
+	ppool = &mv_pp2_pool[pool];
 	if (ppool == NULL) {
 		pr_err("%s: BM pool %d is not initialized\n", __func__, pool);
 		return -1;
@@ -545,26 +545,26 @@ int mv_eth_ctrl_pool_buf_num_set(int pool, int buf_num)
 
 	MV_ETH_LOCK(&ppool->lock, flags);
 	if (ppool->buf_num > buf_num)
-		mv_eth_pool_free(pool, ppool->buf_num - buf_num);
+		mv_pp2_pool_free(pool, ppool->buf_num - buf_num);
 	else
-		mv_eth_pool_add(pool, buf_num - ppool->buf_num);
+		mv_pp2_pool_add(pool, buf_num - ppool->buf_num);
 	MV_ETH_UNLOCK(&ppool->lock, flags);
 
 	return 0;
 }
 
-/* mv_eth_ctrl_pool_size_set				*
+/* mv_pp2_ctrl_pool_size_set				*
  *     - Set buffer size for BM pool			*
  *     - All ports using this pool must be stopped	*
  *     - Re-allocate all buffers			*/
-int mv_eth_ctrl_pool_size_set(int pool, int total_size)
+int mv_pp2_ctrl_pool_size_set(int pool, int total_size)
 {
 	unsigned long flags = 0;
 	struct eth_port *pp;
-	struct bm_pool *ppool = &mv_eth_pool[pool];
+	struct bm_pool *ppool = &mv_pp2_pool[pool];
 	int port, pkt_size, buf_size, pkts_num;
 
-	port = mv_eth_port_up_get(ppool->port_map);
+	port = mv_pp2_port_up_get(ppool->port_map);
 	if (port != -1) {
 		pr_err("%s: Can't change pool %d buffer size, while port %d is up\n",
 			__func__, pool, port);
@@ -580,11 +580,11 @@ int mv_eth_ctrl_pool_size_set(int pool, int total_size)
 	}
 
 
-	for (port = 0; port < mv_eth_ports_num; port++) {
+	for (port = 0; port < mv_pp2_ports_num; port++) {
 		if (!((1 << port) & ppool->port_map))
 			continue;
 
-		pp = mv_eth_port_by_id(port);
+		pp = mv_pp2_port_by_id(port);
 		if (pp == NULL)
 			continue;
 
@@ -596,9 +596,9 @@ int mv_eth_ctrl_pool_size_set(int pool, int total_size)
 
 	MV_ETH_LOCK(&ppool->lock, flags);
 	pkts_num = ppool->buf_num;
-	mv_eth_pool_free(pool, pkts_num);
+	mv_pp2_pool_free(pool, pkts_num);
 	ppool->pkt_size = pkt_size;
-	mv_eth_pool_add(pool, pkts_num);
+	mv_pp2_pool_add(pool, pkts_num);
 
 	mvBmPoolBufSizeSet(pool, buf_size);
 	MV_ETH_UNLOCK(&ppool->lock, flags);
@@ -611,11 +611,11 @@ int mv_eth_ctrl_pool_size_set(int pool, int total_size)
 }
 
 /* detach port from old pool */
-int mv_eth_ctrl_pool_detach(int port, struct bm_pool *pool)
+int mv_pp2_ctrl_pool_detach(int port, struct bm_pool *pool)
 {
 	unsigned long flags = 0;
 	/*TODO remove struct bm_pool *pool;*/
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (pp == NULL) {
 		pr_err("%s: port %d does not exist\n" , __func__, port);
@@ -637,7 +637,7 @@ int mv_eth_ctrl_pool_detach(int port, struct bm_pool *pool)
 
 	if (!pool->port_map) {
 		MV_ETH_LOCK(&pool->lock, flags);
-		mv_eth_pool_free(pool->pool, pool->buf_num);
+		mv_pp2_pool_free(pool->pool, pool->buf_num);
 
 		pool->type = MV_ETH_BM_FREE;
 		pool->pkt_size = 0;
@@ -650,10 +650,10 @@ int mv_eth_ctrl_pool_detach(int port, struct bm_pool *pool)
 }
 
 #ifdef CONFIG_MV_ETH_PP2_1
-static int mv_eth_hwf_long_pool_attach(int port, int pool)
+static int mv_pp2_hwf_long_pool_attach(int port, int pool)
 {
 	int txp, txq;
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (pp == NULL) {
 		pr_err("%s: port %d does not exist\n" , __func__, port);
@@ -661,16 +661,16 @@ static int mv_eth_hwf_long_pool_attach(int port, int pool)
 	}
 
 	for (txp = 0; txp < pp->txp_num; txp++)
-		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++)
+		for (txq = 0; txq < CONFIG_MV_PP2_TXQ; txq++)
 			mvPp2TxqBmLongPoolSet(port, txp, txq, pool);
 
 	return MV_OK;
 }
 
-static int mv_eth_hwf_short_pool_attach(int port, int pool)
+static int mv_pp2_hwf_short_pool_attach(int port, int pool)
 {
 	int txp, txq;
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (pp == NULL) {
 		pr_err("%s: port %d does not exist\n" , __func__, port);
@@ -678,7 +678,7 @@ static int mv_eth_hwf_short_pool_attach(int port, int pool)
 	}
 
 	for (txp = 0; txp < pp->txp_num; txp++)
-		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++)
+		for (txq = 0; txq < CONFIG_MV_PP2_TXQ; txq++)
 			mvPp2TxqBmShortPoolSet(port, txp, txq, pool);
 
 	return MV_OK;
@@ -688,11 +688,11 @@ static int mv_eth_hwf_short_pool_attach(int port, int pool)
 
 /* Init classifer MTU */
 /* the same MTU for all Ports/Queues */
-static int mv_eth_tx_mtu_set(int port, int mtu)
+static int mv_pp2_tx_mtu_set(int port, int mtu)
 {
 	int txp;
 
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (pp == NULL) {
 		pr_err("%s: port %d does not exist\n" , __func__, port);
@@ -708,10 +708,10 @@ static int mv_eth_tx_mtu_set(int port, int mtu)
 
 #endif /* CONFIG_MV_ETH_PP2_1 */
 
-int mv_eth_ctrl_long_pool_set(int port, int pool)
+int mv_pp2_ctrl_long_pool_set(int port, int pool)
 {
 	unsigned long flags = 0;
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	struct bm_pool *old_pool;
 	int rxq, pkt_size = RX_PKT_SIZE(pp->dev->mtu);
 
@@ -731,11 +731,11 @@ int mv_eth_ctrl_long_pool_set(int port, int pool)
 			return 0;
 
 		if (pp->hwf_pool_long != pp->pool_long)
-			if (mv_eth_ctrl_pool_detach(port, old_pool))
+			if (mv_pp2_ctrl_pool_detach(port, old_pool))
 				return -EINVAL;
 	}
 
-	pp->pool_long = mv_eth_pool_use(pool, MV_ETH_BM_SWF_LONG, pkt_size);
+	pp->pool_long = mv_pp2_pool_use(pool, MV_ETH_BM_SWF_LONG, pkt_size);
 	if (!pp->pool_long)
 		return -EINVAL;
 	MV_ETH_LOCK(&pp->pool_long->lock, flags);
@@ -748,10 +748,10 @@ int mv_eth_ctrl_long_pool_set(int port, int pool)
 	return 0;
 }
 
-int mv_eth_ctrl_short_pool_set(int port, int pool)
+int mv_pp2_ctrl_short_pool_set(int port, int pool)
 {
 	unsigned long flags = 0;
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	struct bm_pool *old_pool;
 	int rxq;
 
@@ -771,11 +771,11 @@ int mv_eth_ctrl_short_pool_set(int port, int pool)
 			return 0;
 
 		if (pp->hwf_pool_short != pp->pool_short)
-			if (mv_eth_ctrl_pool_detach(port, old_pool))
+			if (mv_pp2_ctrl_pool_detach(port, old_pool))
 				return -EINVAL;
 	}
 
-	pp->pool_short = mv_eth_pool_use(pool, MV_ETH_BM_SWF_SHORT, MV_ETH_BM_SHORT_PKT_SIZE);
+	pp->pool_short = mv_pp2_pool_use(pool, MV_ETH_BM_SWF_SHORT, MV_ETH_BM_SHORT_PKT_SIZE);
 	if (!pp->pool_short)
 		return -EINVAL;
 	MV_ETH_LOCK(&pp->pool_short->lock, flags);
@@ -788,10 +788,10 @@ int mv_eth_ctrl_short_pool_set(int port, int pool)
 	return 0;
 }
 
-int mv_eth_ctrl_hwf_long_pool_set(int port, int pool)
+int mv_pp2_ctrl_hwf_long_pool_set(int port, int pool)
 {
 	unsigned long flags = 0;
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	struct bm_pool *old_pool;
 	int pkt_size = RX_PKT_SIZE(pp->dev->mtu);
 
@@ -811,11 +811,11 @@ int mv_eth_ctrl_hwf_long_pool_set(int port, int pool)
 			return 0;
 
 		if (pp->hwf_pool_long != pp->pool_long)
-			if (mv_eth_ctrl_pool_detach(port, old_pool))
+			if (mv_pp2_ctrl_pool_detach(port, old_pool))
 				return -EINVAL;
 	}
 
-	pp->hwf_pool_long = mv_eth_pool_use(pool, MV_ETH_BM_HWF_LONG, pkt_size);
+	pp->hwf_pool_long = mv_pp2_pool_use(pool, MV_ETH_BM_HWF_LONG, pkt_size);
 	if (!pp->hwf_pool_long)
 		return -EINVAL;
 	MV_ETH_LOCK(&pp->hwf_pool_long->lock, flags);
@@ -823,7 +823,7 @@ int mv_eth_ctrl_hwf_long_pool_set(int port, int pool)
 	MV_ETH_UNLOCK(&pp->hwf_pool_long->lock, flags);
 
 #ifdef CONFIG_MV_ETH_PP2_1
-	mv_eth_hwf_long_pool_attach(pp->port, pp->hwf_pool_long->pool);
+	mv_pp2_hwf_long_pool_attach(pp->port, pp->hwf_pool_long->pool);
 #else
 	mvPp2PortHwfBmPoolSet(pp->port, pp->hwf_pool_short->pool, pp->hwf_pool_long->pool);
 #endif
@@ -831,10 +831,10 @@ int mv_eth_ctrl_hwf_long_pool_set(int port, int pool)
 	return 0;
 }
 
-int mv_eth_ctrl_hwf_short_pool_set(int port, int pool)
+int mv_pp2_ctrl_hwf_short_pool_set(int port, int pool)
 {
 	unsigned long flags = 0;
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	struct bm_pool *old_pool;
 
 	if (pp == NULL) {
@@ -853,10 +853,10 @@ int mv_eth_ctrl_hwf_short_pool_set(int port, int pool)
 			return 0;
 
 		if (pp->hwf_pool_short != pp->pool_short)
-			if (mv_eth_ctrl_pool_detach(port, old_pool))
+			if (mv_pp2_ctrl_pool_detach(port, old_pool))
 				return -EINVAL;
 	}
-	pp->hwf_pool_short = mv_eth_pool_use(pool, MV_ETH_BM_HWF_SHORT, MV_ETH_BM_SHORT_HWF_PKT_SIZE);
+	pp->hwf_pool_short = mv_pp2_pool_use(pool, MV_ETH_BM_HWF_SHORT, MV_ETH_BM_SHORT_HWF_PKT_SIZE);
 	if (!pp->hwf_pool_short)
 		return -EINVAL;
 	MV_ETH_LOCK(&pp->hwf_pool_short->lock, flags);
@@ -864,7 +864,7 @@ int mv_eth_ctrl_hwf_short_pool_set(int port, int pool)
 	MV_ETH_UNLOCK(&pp->hwf_pool_short->lock, flags);
 
 #ifdef CONFIG_MV_ETH_PP2_1
-	mv_eth_hwf_short_pool_attach(pp->port, pp->hwf_pool_short->pool);
+	mv_pp2_hwf_short_pool_attach(pp->port, pp->hwf_pool_short->pool);
 #else
 	mvPp2PortHwfBmPoolSet(pp->port, pp->hwf_pool_short->pool, pp->hwf_pool_long->pool);
 #endif
@@ -872,9 +872,9 @@ int mv_eth_ctrl_hwf_short_pool_set(int port, int pool)
 	return 0;
 }
 
-int mv_eth_ctrl_set_poll_rx_weight(int port, u32 weight)
+int mv_pp2_ctrl_set_poll_rx_weight(int port, u32 weight)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	int i;
 
 	if (pp == NULL) {
@@ -900,7 +900,7 @@ int mv_eth_ctrl_set_poll_rx_weight(int port, u32 weight)
 	return 0;
 }
 
-int mv_eth_ctrl_rxq_size_set(int port, int rxq, int value)
+int mv_pp2_ctrl_rxq_size_set(int port, int rxq, int value)
 {
 	struct eth_port *pp;
 	struct rx_queue	*rxq_ctrl;
@@ -908,7 +908,7 @@ int mv_eth_ctrl_rxq_size_set(int port, int rxq, int value)
 	if (mvPp2PortCheck(port))
 		return -EINVAL;
 
-	if (mvPp2MaxCheck(rxq, CONFIG_MV_ETH_RXQ, "rxq"))
+	if (mvPp2MaxCheck(rxq, CONFIG_MV_PP2_RXQ, "rxq"))
 		return -EINVAL;
 
 	if ((value <= 0) || (value > 0x3FFF) || (value % 16)) {
@@ -916,7 +916,7 @@ int mv_eth_ctrl_rxq_size_set(int port, int rxq, int value)
 		return -EINVAL;
 	}
 
-	pp = mv_eth_port_by_id(port);
+	pp = mv_pp2_port_by_id(port);
 	if (pp == NULL) {
 		pr_err("Port %d does not exist\n", port);
 		return -EINVAL;
@@ -941,7 +941,7 @@ int mv_eth_ctrl_rxq_size_set(int port, int rxq, int value)
 	}
 	pp->rxq_ctrl[rxq].rxq_size = value;
 
-	/* New RXQ will be created during mv_eth_start_internals */
+	/* New RXQ will be created during mv_pp2_start_internals */
 	return 0;
 }
 
@@ -974,17 +974,19 @@ static void mv_pp2_txq_size_set(struct tx_queue *txq_ctrl, int txq_size)
 }
 
 /* set <txp/txq> SWF request chunk size */
-int mv_eth_ctrl_txq_chunk_set(int port, int txp, int txq, int chunk_size)
+int mv_pp2_ctrl_txq_chunk_set(int port, int txp, int txq, int chunk_size)
 {
 	struct tx_queue *txq_ctrl;
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
+
 
 	if (pp == NULL) {
 		printk(KERN_INFO "port does not exist (%d) in %s\n" , port, __func__);
 		return -EINVAL;
 	}
 
-	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + txq];
+
 	if (!txq_ctrl) {
 		printk(KERN_INFO "queue does not exist (%d) in %s\n" , port, __func__);
 		return -EINVAL;
@@ -1001,7 +1003,7 @@ int mv_eth_ctrl_txq_chunk_set(int port, int txp, int txq, int chunk_size)
 }
 
 /* swf_size is in use only in ppv2.1, ignored in ppv2.0 */
-int mv_eth_ctrl_txq_limits_set(int port, int txp, int txq, int hwf_size, int swf_size)
+int mv_pp2_ctrl_txq_limits_set(int port, int txp, int txq, int hwf_size, int swf_size)
 {
 	int txq_size;
 	struct tx_queue *txq_ctrl;
@@ -1010,16 +1012,16 @@ int mv_eth_ctrl_txq_limits_set(int port, int txp, int txq, int hwf_size, int swf
 	if (mvPp2TxpCheck(port, txp))
 		return -EINVAL;
 
-	if (mvPp2MaxCheck(txq, CONFIG_MV_ETH_TXQ, "txq"))
+	if (mvPp2MaxCheck(txq, CONFIG_MV_PP2_TXQ, "txq"))
 		return -EINVAL;
 
-	pp = mv_eth_port_by_id(port);
+	pp = mv_pp2_port_by_id(port);
 	if (pp == NULL) {
 		pr_err("port does not exist (%d) in %s\n" , port, __func__);
 		return -EINVAL;
 	}
 
-	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + txq];
 
 	if (!txq_ctrl) {
 		pr_err("queue is null %s\n", __func__);
@@ -1053,7 +1055,7 @@ int mv_eth_ctrl_txq_limits_set(int port, int txp, int txq, int hwf_size, int swf
 	return 0;
 }
 
-int mv_eth_ctrl_txq_size_set(int port, int txp, int txq, int txq_size)
+int mv_pp2_ctrl_txq_size_set(int port, int txp, int txq, int txq_size)
 {
 	struct tx_queue *txq_ctrl;
 	struct eth_port *pp;
@@ -1061,7 +1063,7 @@ int mv_eth_ctrl_txq_size_set(int port, int txp, int txq, int txq_size)
 	if (mvPp2TxpCheck(port, txp))
 		return -EINVAL;
 
-	if (mvPp2MaxCheck(txq, CONFIG_MV_ETH_TXQ, "txq"))
+	if (mvPp2MaxCheck(txq, CONFIG_MV_PP2_TXQ, "txq"))
 		return -EINVAL;
 
 	if ((txq_size <= 0) || (txq_size > 0x3FFF) || (txq_size % 16)) {
@@ -1069,7 +1071,7 @@ int mv_eth_ctrl_txq_size_set(int port, int txp, int txq, int txq_size)
 		return -EINVAL;
 	}
 
-	pp = mv_eth_port_by_id(port);
+	pp = mv_pp2_port_by_id(port);
 	if (pp == NULL) {
 		pr_err("Port %d does not exist\n", port);
 		return -EINVAL;
@@ -1080,7 +1082,8 @@ int mv_eth_ctrl_txq_size_set(int port, int txp, int txq, int txq_size)
 		return -EINVAL;
 	}
 
-	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + txq];
+
 	if (!txq_ctrl) {
 		pr_err("TXQ is not exist\n");
 		return -EINVAL;
@@ -1088,24 +1091,24 @@ int mv_eth_ctrl_txq_size_set(int port, int txp, int txq, int txq_size)
 
 	if ((txq_ctrl->q) && (txq_ctrl->txq_size != txq_size)) {
 		/* Clean and Reset of txq is required when TXQ ring size is changed */
-		mv_eth_txq_clean(port, txp, txq);
+		mv_pp2_txq_clean(port, txp, txq);
 
 		/* TBD: If needed to send dummy packets to reset number of descriptors reserved by all CPUs */
 
 		mvPp2TxqReset(port, txp, txq);
-		mv_eth_txq_delete(pp, txq_ctrl);
+		mv_pp2_txq_delete(pp, txq_ctrl);
 	}
 	mv_pp2_txq_size_set(txq_ctrl, txq_size);
 
-	/* New TXQ will be created during mv_eth_start_internals */
+	/* New TXQ will be created during mv_pp2_start_internals */
 	return 0;
 }
 
 
 /* Set TXQ for CPU originated packets */
-int mv_eth_ctrl_txq_cpu_def(int port, int txp, int txq, int cpu)
+int mv_pp2_ctrl_txq_cpu_def(int port, int txp, int txq, int cpu)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if ((cpu >= CONFIG_NR_CPUS) || (cpu < 0)) {
 		printk(KERN_ERR "cpu #%d is out of range: from 0 to %d\n",
@@ -1113,8 +1116,8 @@ int mv_eth_ctrl_txq_cpu_def(int port, int txp, int txq, int cpu)
 		return -EINVAL;
 	}
 
-	if (txq >= CONFIG_MV_ETH_TXQ) {
-		pr_err("txq #%d is out of range: from 0 to %d\n", txq, CONFIG_MV_ETH_TXQ - 1);
+	if (txq >= CONFIG_MV_PP2_TXQ) {
+		pr_err("txq #%d is out of range: from 0 to %d\n", txq, CONFIG_MV_PP2_TXQ - 1);
 		return -EINVAL;
 	}
 
@@ -1130,9 +1133,9 @@ int mv_eth_ctrl_txq_cpu_def(int port, int txp, int txq, int cpu)
 	return 0;
 }
 
-int mv_eth_ctrl_tx_mh(int port, u16 mh)
+int mv_pp2_eth_ctrl_tx_mh(int port, u16 mh)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (!pp)
 		return -ENODEV;
@@ -1142,9 +1145,9 @@ int mv_eth_ctrl_tx_mh(int port, u16 mh)
 	return 0;
 }
 
-int mv_eth_ctrl_tx_cmd_dsa(int port, u16 dsa_tag)
+int mv_pp2_ctrl_tx_cmd_dsa(int port, u16 dsa_tag)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (!pp)
 		return -ENODEV;
@@ -1155,9 +1158,9 @@ int mv_eth_ctrl_tx_cmd_dsa(int port, u16 dsa_tag)
 	return 0;
 }
 
-int mv_eth_ctrl_tx_cmd_color(int port, u16 color)
+int mv_pp2_ctrl_tx_cmd_color(int port, u16 color)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (!pp)
 		return -ENODEV;
@@ -1168,9 +1171,9 @@ int mv_eth_ctrl_tx_cmd_color(int port, u16 color)
 	return 0;
 }
 
-int mv_eth_ctrl_tx_cmd_gem_id(int port, u16 gem_port_id)
+int mv_pp2_ctrl_tx_cmd_gem_id(int port, u16 gem_port_id)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (!pp)
 		return -ENODEV;
@@ -1181,9 +1184,9 @@ int mv_eth_ctrl_tx_cmd_gem_id(int port, u16 gem_port_id)
 	return 0;
 }
 
-int mv_eth_ctrl_tx_cmd_pon_fec(int port, u16 pon_fec)
+int mv_pp2_ctrl_tx_cmd_pon_fec(int port, u16 pon_fec)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (!pp)
 		return -ENODEV;
@@ -1198,7 +1201,7 @@ int mv_eth_ctrl_tx_cmd_pon_fec(int port, u16 pon_fec)
 
 int mv_eth_ctrl_tx_cmd_gem_oem(int port, u16 gem_oem)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (!pp)
 		return -ENODEV;
@@ -1211,9 +1214,9 @@ int mv_eth_ctrl_tx_cmd_gem_oem(int port, u16 gem_oem)
 	return 0;
 }
 
-int mv_eth_ctrl_tx_cmd_mod(int port, u16 mod)
+int mv_pp2_ctrl_tx_cmd_mod(int port, u16 mod)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	u32 mask = (PP2_TX_MOD_DSCP_MASK | PP2_TX_MOD_PRIO_MASK | PP2_TX_MOD_DSCP_EN_MASK
 			| PP2_TX_MOD_PRIO_EN_MASK | PP2_TX_MOD_GEMPID_EN_MASK);
 
@@ -1228,9 +1231,9 @@ int mv_eth_ctrl_tx_cmd_mod(int port, u16 mod)
 	return 0;
 }
 
-int mv_eth_ctrl_tx_cmd_pme_dptr(int port, u16 pme_dptr)
+int mv_pp2_ctrl_tx_cmd_pme_dptr(int port, u16 pme_dptr)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (!pp)
 		return -ENODEV;
@@ -1241,9 +1244,9 @@ int mv_eth_ctrl_tx_cmd_pme_dptr(int port, u16 pme_dptr)
 	return 0;
 }
 
-int mv_eth_ctrl_tx_cmd_pme_prog(int port, u16 pme_prog)
+int mv_pp2_ctrl_tx_cmd_pme_prog(int port, u16 pme_prog)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (!pp)
 		return -ENODEV;
@@ -1255,61 +1258,61 @@ int mv_eth_ctrl_tx_cmd_pme_prog(int port, u16 pme_prog)
 }
 
 
-#ifdef CONFIG_MV_ETH_TX_SPECIAL
+#ifdef CONFIG_MV_PP2_TX_SPECIAL
 /* Register special transmit check function */
-void mv_eth_tx_special_check_func(int port,
+void mv_pp2_tx_special_check_func(int port,
 					int (*func)(int port, struct net_device *dev, struct sk_buff *skb,
-								struct mv_eth_tx_spec *tx_spec_out))
+								struct mv_pp2_tx_spec *tx_spec_out))
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (pp)
 		pp->tx_special_check = func;
 }
-#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+#endif /* CONFIG_MV_PP2_TX_SPECIAL */
 
-#ifdef CONFIG_MV_ETH_RX_SPECIAL
+#ifdef CONFIG_MV_PP2_RX_SPECIAL
 /* Register special transmit check function */
-void mv_eth_rx_special_proc_func(int port, int (*func)(int port, int rxq, struct net_device *dev,
+void mv_pp2_rx_special_proc_func(int port, int (*func)(int port, int rxq, struct net_device *dev,
 							struct sk_buff *skb, struct pp2_rx_desc *rx_desc))
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (pp)
 		pp->rx_special_proc = func;
 }
-#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+#endif /* CONFIG_MV_PP2_RX_SPECIAL */
 
-static inline u16 mv_eth_select_txq(struct net_device *dev, struct sk_buff *skb)
+static inline u16 mv_pp2_select_txq(struct net_device *dev, struct sk_buff *skb)
 {
 	struct eth_port *pp = MV_ETH_PRIV(dev);
-	return mv_eth_tx_policy(pp, skb);
-}
-
-static const struct net_device_ops mv_eth_netdev_ops = {
-	.ndo_open = mv_eth_open,
-	.ndo_stop = mv_eth_stop,
-	.ndo_start_xmit = mv_eth_tx,
-	.ndo_set_rx_mode = mv_eth_rx_set_rx_mode,
-	.ndo_set_mac_address = mv_eth_set_mac_addr,
-	.ndo_change_mtu = mv_eth_change_mtu,
-	.ndo_tx_timeout = mv_eth_tx_timeout,
-	.ndo_select_queue = mv_eth_select_txq,
+	return mv_pp2_tx_policy(pp, skb);
+}
+
+static const struct net_device_ops mv_pp2_netdev_ops = {
+	.ndo_open = mv_pp2_eth_open,
+	.ndo_stop = mv_pp2_eth_stop,
+	.ndo_start_xmit = mv_pp2_tx,
+	.ndo_set_rx_mode = mv_pp2_rx_set_rx_mode,
+	.ndo_set_mac_address = mv_pp2_eth_set_mac_addr,
+	.ndo_change_mtu = mv_pp2_eth_change_mtu,
+	.ndo_tx_timeout = mv_pp2_tx_timeout,
+	.ndo_select_queue = mv_pp2_select_txq,
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 39)
-	.ndo_fix_features = mv_eth_netdev_fix_features,
+	.ndo_fix_features = mv_pp2_netdev_fix_features,
 #endif
 };
 
 
-void mv_eth_link_status_print(int port)
+void mv_pp2_eth_link_status_print(int port)
 {
 	MV_ETH_PORT_STATUS link;
 
-#ifdef CONFIG_MV_PON
-	if (MV_PON_PORT(port))
+#ifdef CONFIG_MV_PP2_PON
+	if (MV_PP2_IS_PON_PORT(port))
 		mv_pon_link_status(&link);
 	else
-#endif /* CONFIG_MV_PON */
+#endif /* CONFIG_MV_PP2_PON */
 		mvGmacLinkStatus(port, &link);
 
 	if (link.linkup) {
@@ -1323,14 +1326,14 @@ void mv_eth_link_status_print(int port)
 
 }
 
-static void mv_eth_rx_error(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
+static void mv_pp2_rx_error(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
 {
 	STAT_ERR(pp->stats.rx_error++);
 
 	if (pp->dev)
 		pp->dev->stats.rx_errors++;
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 	if ((pp->dbg_flags & MV_ETH_F_DBG_RX) == 0)
 		return;
 
@@ -1352,11 +1355,11 @@ static void mv_eth_rx_error(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
 				pp->port, rx_desc->status, rx_desc->dataSize);
 		break;
 	}
-	mv_eth_rx_desc_print(rx_desc);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+	mv_pp2_rx_desc_print(rx_desc);
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 }
 
-void mv_eth_skb_print(struct sk_buff *skb)
+void mv_pp2_skb_print(struct sk_buff *skb)
 {
 	printk(KERN_ERR "skb=%p: head=%p, data=%p, tail=%p, end=%p\n", skb, skb->head, skb->data, skb->tail, skb->end);
 	printk(KERN_ERR "\t mac=%p, network=%p, transport=%p\n",
@@ -1367,12 +1370,12 @@ void mv_eth_skb_print(struct sk_buff *skb)
 	       atomic_read(&skb->users), atomic_read(&skb_shinfo(skb)->dataref),
 	       skb_shinfo(skb)->nr_frags, skb_shinfo(skb)->gso_size, skb_shinfo(skb)->gso_segs);
 	printk(KERN_ERR "\t proto=%d, ip_summed=%d, priority=%d\n", ntohs(skb->protocol), skb->ip_summed, skb->priority);
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_PP2_SKB_RECYCLE
 	printk(KERN_ERR "\t skb_recycle=%p, hw_cookie=0x%x\n", skb->skb_recycle, skb->hw_cookie);
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_PP2_SKB_RECYCLE */
 }
 
-void mv_eth_rx_desc_print(struct pp2_rx_desc *desc)
+void mv_pp2_rx_desc_print(struct pp2_rx_desc *desc)
 {
 	int i;
 	u32 *words = (u32 *) desc;
@@ -1425,9 +1428,9 @@ void mv_eth_rx_desc_print(struct pp2_rx_desc *desc)
 		(desc->parserInfo & PP2_RX_LKP_ID_MASK) >> PP2_RX_LKP_ID_OFFS,
 		(desc->parserInfo & PP2_RX_CPU_CODE_MASK) >> PP2_RX_CPU_CODE_OFFS);
 }
-EXPORT_SYMBOL(mv_eth_rx_desc_print);
+EXPORT_SYMBOL(mv_pp2_rx_desc_print);
 
-void mv_eth_tx_desc_print(struct pp2_tx_desc *desc)
+void mv_pp2_tx_desc_print(struct pp2_tx_desc *desc)
 {
 	int i;
 	u32 *words = (u32 *) desc;
@@ -1437,9 +1440,9 @@ void mv_eth_tx_desc_print(struct pp2_tx_desc *desc)
 		printk(KERN_CONT "%8.8x ", *words++);
 	printk(KERN_CONT "\n");
 }
-EXPORT_SYMBOL(mv_eth_tx_desc_print);
+EXPORT_SYMBOL(mv_pp2_tx_desc_print);
 
-void mv_eth_pkt_print(struct eth_pbuf *pkt)
+void mv_pp2_pkt_print(struct eth_pbuf *pkt)
 {
 	printk(KERN_ERR "pkt: len=%d off=%d pool=%d "
 	       "skb=%p pa=%lx buf=%p\n",
@@ -1449,19 +1452,19 @@ void mv_eth_pkt_print(struct eth_pbuf *pkt)
 	mvDebugMemDump(pkt->pBuf + pkt->offset, 64, 1);
 	mvOsCacheInvalidate(NULL, pkt->pBuf + pkt->offset, 64);
 }
-EXPORT_SYMBOL(mv_eth_pkt_print);
+EXPORT_SYMBOL(mv_pp2_pkt_print);
 
-static inline int mv_eth_tx_done_policy(u32 cause)
+static inline int mv_pp2_tx_done_policy(u32 cause)
 {
 	return fls(cause) - 1;
 }
 
-inline int mv_eth_rx_policy(u32 cause)
+inline int mv_pp2_rx_policy(u32 cause)
 {
 	return fls(cause) - 1;
 }
 
-static inline int mv_eth_txq_dscp_map_get(struct eth_port *pp, MV_U8 dscp)
+static inline int mv_pp2_txq_dscp_map_get(struct eth_port *pp, MV_U8 dscp)
 {
 	MV_U8 q = pp->txq_dscp_map[dscp];
 
@@ -1471,20 +1474,20 @@ static inline int mv_eth_txq_dscp_map_get(struct eth_port *pp, MV_U8 dscp)
 	return q;
 }
 
-static inline int mv_eth_tx_policy(struct eth_port *pp, struct sk_buff *skb)
+static inline int mv_pp2_tx_policy(struct eth_port *pp, struct sk_buff *skb)
 {
 	int txq = pp->cpu_config[smp_processor_id()]->txq;
 
 	if (skb->protocol == htons(ETH_P_IP)) {
 		struct iphdr *iph = ip_hdr(skb);
 
-		txq = mv_eth_txq_dscp_map_get(pp, TOS_TO_DSCP(iph->tos));
+		txq = mv_pp2_txq_dscp_map_get(pp, TOS_TO_DSCP(iph->tos));
 	}
 	return txq;
 }
 
-#ifdef CONFIG_NET_SKB_RECYCLE
-int mv_eth_skb_recycle(struct sk_buff *skb)
+#ifdef CONFIG_MV_PP2_SKB_RECYCLE
+int mv_pp2_skb_recycle(struct sk_buff *skb)
 {
 	int pool, cpu;
 	__u32 bm = skb->hw_cookie;
@@ -1495,13 +1498,13 @@ int mv_eth_skb_recycle(struct sk_buff *skb)
 	skb->hw_cookie = 0;
 	skb->skb_recycle = NULL;
 
-	cpu = mv_eth_bm_cookie_cpu_get(bm);
+	cpu = mv_pp2_bm_cookie_cpu_get(bm);
 
-	pool = mv_eth_bm_cookie_pool_get(bm);
+	pool = mv_pp2_bm_cookie_pool_get(bm);
 	if (mvPp2MaxCheck(pool, MV_ETH_BM_POOLS, "bm_pool"))
 		return 1;
 
-	ppool = &mv_eth_pool[pool];
+	ppool = &mv_pp2_pool[pool];
 
 	/*
 	WA for Linux network stack issue that prevent skb recycle.
@@ -1523,56 +1526,56 @@ int mv_eth_skb_recycle(struct sk_buff *skb)
 		is_recyclable = true;
 
 	if (is_recyclable) {
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 		/* Sanity check */
 		if (SKB_TRUESIZE(skb->end - skb->head) != skb->truesize) {
 			pr_err("%s: skb=%p, Wrong SKB_TRUESIZE(end - head)=%d\n",
 				__func__, skb, SKB_TRUESIZE(skb->end - skb->head));
-			mv_eth_skb_print(skb);
+			mv_pp2_skb_print(skb);
 		}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 		STAT_DBG(ppool->stats.skb_recycled_ok++);
 
 		phys_addr = dma_map_single(NULL, skb->head, RX_BUF_SIZE(ppool->pkt_size), DMA_FROM_DEVICE);
 		/*phys_addr = virt_to_phys(skb->head);*/
-#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+#ifdef CONFIG_MV_PP2_SWF_HWF_CORRUPTION_WA
 		/* Invalidate only part of the buffer used by CPU */
 		if ((ppool->type == MV_ETH_BM_MIXED_LONG) || (ppool->type == MV_ETH_BM_MIXED_SHORT))
-			mv_eth_iocc_l1_l2_cache_inv(skb->head, skb->len + skb_headroom(skb));
-#endif /* CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA */
+			mv_pp2_iocc_l1_l2_cache_inv(skb->head, skb->len + skb_headroom(skb));
+#endif /* CONFIG_MV_PP2_SWF_HWF_CORRUPTION_WA */
 	} else {
 /*
 		pr_err("%s: Failed - skb=%p, pool=%d, bm_cookie=0x%x\n",
 			__func__, skb, MV_ETH_BM_COOKIE_POOL(bm), bm.word);
 
-		mv_eth_skb_print(skb);
+		mv_pp2_skb_print(skb);
 */
-		skb = mv_eth_skb_alloc(ppool, &phys_addr,  GFP_ATOMIC);
+		skb = mv_pp2_skb_alloc(ppool, &phys_addr,  GFP_ATOMIC);
 		if (!skb) {
 			pr_err("Linux processing - Can't refill\n");
 			return 1;
 		}
 	}
-	mv_eth_pool_refill(ppool, bm, phys_addr, (unsigned long) skb);
+	mv_pp2_pool_refill(ppool, bm, phys_addr, (unsigned long) skb);
 	atomic_dec(&ppool->in_use);
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 /*
 	if (cpu != smp_processor_id()) {
 		pr_warning("%s on CPU=%d other than RX=%d\n", __func__,
 			smp_processor_id(), cpu);
 	}
 */
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 	return !is_recyclable;
 }
-EXPORT_SYMBOL(mv_eth_skb_recycle);
+EXPORT_SYMBOL(mv_pp2_skb_recycle);
 
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_PP2_SKB_RECYCLE */
 
-static struct sk_buff *mv_eth_skb_alloc(struct bm_pool *pool, phys_addr_t *phys_addr, gfp_t gfp_mask)
+static struct sk_buff *mv_pp2_skb_alloc(struct bm_pool *pool, phys_addr_t *phys_addr, gfp_t gfp_mask)
 {
 	struct sk_buff *skb;
 	phys_addr_t pa;
@@ -1587,9 +1590,9 @@ static struct sk_buff *mv_eth_skb_alloc(struct bm_pool *pool, phys_addr_t *phys_
 		pa = dma_map_single(NULL, skb->head, RX_BUF_SIZE(pool->pkt_size), DMA_FROM_DEVICE);
 		*phys_addr = pa;
 
-#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+#ifdef CONFIG_MV_PP2_SWF_HWF_CORRUPTION_WA
 		if ((pool->type == MV_ETH_BM_MIXED_LONG) || (pool->type == MV_ETH_BM_MIXED_SHORT))
-			mv_eth_iocc_l1_l2_cache_inv(skb->head, RX_BUF_SIZE(pool->pkt_size));
+			mv_pp2_iocc_l1_l2_cache_inv(skb->head, RX_BUF_SIZE(pool->pkt_size));
 #endif
 	}
 
@@ -1598,7 +1601,7 @@ static struct sk_buff *mv_eth_skb_alloc(struct bm_pool *pool, phys_addr_t *phys_
 	return skb;
 }
 
-static unsigned char *mv_eth_hwf_buff_alloc(struct bm_pool *pool, phys_addr_t *phys_addr)
+static unsigned char *mv_pp2_hwf_buff_alloc(struct bm_pool *pool, phys_addr_t *phys_addr)
 {
 	unsigned char *buff;
 	int size = RX_HWF_BUF_SIZE(pool->pkt_size);
@@ -1613,7 +1616,7 @@ static unsigned char *mv_eth_hwf_buff_alloc(struct bm_pool *pool, phys_addr_t *p
 	return buff;
 }
 
-static inline void mv_eth_txq_buf_free(struct eth_port *pp, u32 shadow)
+static inline void mv_pp2_txq_buf_free(struct eth_port *pp, u32 shadow)
 {
 	if (!shadow)
 		return;
@@ -1624,7 +1627,7 @@ static inline void mv_eth_txq_buf_free(struct eth_port *pp, u32 shadow)
 		STAT_DBG(pp->stats.tx_skb_free++);
 	} else if (shadow & MV_ETH_SHADOW_EXT) {
 		shadow &= ~MV_ETH_SHADOW_EXT;
-		mv_eth_extra_pool_put(pp, (void *)shadow);
+		mv_pp2_extra_pool_put(pp, (void *)shadow);
 	} else {
 		/* TBD - return buffer back to BM */
 		printk(KERN_ERR "%s: unexpected buffer - not skb and not ext\n", __func__);
@@ -1632,19 +1635,19 @@ static inline void mv_eth_txq_buf_free(struct eth_port *pp, u32 shadow)
 }
 
 
-static inline void mv_eth_txq_bufs_free(struct eth_port *pp, struct txq_cpu_ctrl *txq_cpu, int num)
+static inline void mv_pp2_txq_bufs_free(struct eth_port *pp, struct txq_cpu_ctrl *txq_cpu, int num)
 {
 	u32 shadow;
 	int i;
 
 	/* Free buffers that was not freed automatically by BM */
 	for (i = 0; i < num; i++) {
-		shadow = mv_eth_shadow_get_pop(txq_cpu);
-		mv_eth_txq_buf_free(pp, shadow);
+		shadow = mv_pp2_shadow_get_pop(txq_cpu);
+		mv_pp2_txq_buf_free(pp, shadow);
 	}
 }
 
-inline u32 mv_eth_txq_done(struct eth_port *pp, struct tx_queue *txq_ctrl)
+inline u32 mv_pp2_txq_done(struct eth_port *pp, struct tx_queue *txq_ctrl)
 {
 	int tx_done;
 	struct txq_cpu_ctrl *txq_cpu_ptr = &txq_ctrl->txq_cpu[smp_processor_id()];
@@ -1661,40 +1664,40 @@ inline u32 mv_eth_txq_done(struct eth_port *pp, struct tx_queue *txq_ctrl)
 	if (txq_cpu_ptr->txq_count < tx_done)
 		return tx_done;
 
-	mv_eth_txq_bufs_free(pp, txq_cpu_ptr, tx_done);
+	mv_pp2_txq_bufs_free(pp, txq_cpu_ptr, tx_done);
 
 	txq_cpu_ptr->txq_count -= tx_done;
 	STAT_DBG(txq_cpu_ptr->stats.txq_txdone += tx_done);
 
 	return tx_done;
 }
-EXPORT_SYMBOL(mv_eth_txq_done);
+EXPORT_SYMBOL(mv_pp2_txq_done);
 
 /* Reuse skb if possible, allocate new skb and move to BM pool */
-inline int mv_eth_refill(struct bm_pool *ppool, __u32 bm, int is_recycle)
+inline int mv_pp2_refill(struct bm_pool *ppool, __u32 bm, int is_recycle)
 {
 	struct sk_buff *skb;
 	phys_addr_t phys_addr;
 
-	if (is_recycle && (mv_eth_bm_in_use_read(ppool) < ppool->in_use_thresh))
+	if (is_recycle && (mv_pp2_bm_in_use_read(ppool) < ppool->in_use_thresh))
 		return 0;
 
 	/* No recycle or too many buffers are in use - alloc new skb */
-	skb = mv_eth_skb_alloc(ppool, &phys_addr, GFP_ATOMIC);
+	skb = mv_pp2_skb_alloc(ppool, &phys_addr, GFP_ATOMIC);
 	if (!skb) {
 		pr_err("Linux processing - Can't refill\n");
 		return 1;
 	}
 	STAT_DBG(ppool->stats.no_recycle++);
 
-	mv_eth_pool_refill(ppool, bm, phys_addr, (unsigned long) skb);
+	mv_pp2_pool_refill(ppool, bm, phys_addr, (unsigned long) skb);
 	atomic_dec(&ppool->in_use);
 
 	return 0;
 }
-EXPORT_SYMBOL(mv_eth_refill);
+EXPORT_SYMBOL(mv_pp2_refill);
 
-static inline MV_U32 mv_eth_skb_tx_csum(struct eth_port *pp, struct sk_buff *skb)
+static inline MV_U32 mv_pp2_skb_tx_csum(struct eth_port *pp, struct sk_buff *skb)
 {
 	if (skb->ip_summed == CHECKSUM_PARTIAL) {
 		int   ip_hdr_len = 0;
@@ -1727,7 +1730,7 @@ static inline MV_U32 mv_eth_skb_tx_csum(struct eth_port *pp, struct sk_buff *skb
 	return PP2_TX_L4_CSUM_NOT | PP2_TX_IP_CSUM_DISABLE_MASK;
 }
 
-inline struct pp2_rx_desc *mv_eth_rx_prefetch(struct eth_port *pp, MV_PP2_PHYS_RXQ_CTRL *rx_ctrl,
+inline struct pp2_rx_desc *mv_pp2_rx_prefetch(struct eth_port *pp, MV_PP2_PHYS_RXQ_CTRL *rx_ctrl,
 									  int rx_done, int rx_todo)
 {
 	struct pp2_rx_desc	*rx_desc, *next_desc;
@@ -1750,7 +1753,7 @@ inline struct pp2_rx_desc *mv_eth_rx_prefetch(struct eth_port *pp, MV_PP2_PHYS_R
 	return rx_desc;
 }
 
-void mv_eth_buff_hdr_rx(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
+void mv_pp2_buff_hdr_rx(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
 {
 	u32 rx_status = rx_desc->status;
 	int mc_id, pool_id;
@@ -1773,7 +1776,7 @@ void mv_eth_buff_hdr_rx(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
 		buff_hdr = (PP2_BUFF_HDR *)(((struct sk_buff *)buff_virt_addr)->head);
 		mc_id = PP2_BUFF_HDR_INFO_MC_ID(buff_hdr->info);
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 		if (pp->dbg_flags & MV_ETH_F_DBG_BUFF_HDR) {
 			printk(KERN_ERR "buff header #%d:\n", count);
 			mvDebugMemDump(buff_hdr, 32, 1);
@@ -1801,17 +1804,17 @@ void mv_eth_buff_hdr_rx(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
 		buff_phys_addr = buff_phys_addr_next;
 		buff_virt_addr = buff_virt_addr_next;
 
-		STAT_DBG((&mv_eth_pool[pool_id])->stats.bm_put++);
+		STAT_DBG((&mv_pp2_pool[pool_id])->stats.bm_put++);
 
 	} while (!PP2_BUFF_HDR_INFO_IS_LAST(buff_hdr->info));
 
 	mvOsCacheLineInv(NULL, rx_desc);
 	STAT_INFO(pp->stats.rx_buf_hdr++);
 }
-EXPORT_SYMBOL(mv_eth_buff_hdr_rx);
+EXPORT_SYMBOL(mv_pp2_buff_hdr_rx);
 
 
-void mv_eth_buff_hdr_rx_dump(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
+void mv_pp2_buff_hdr_rx_dump(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
 {
 	int mc_id;
 	PP2_BUFF_HDR *buff_hdr;
@@ -1843,7 +1846,7 @@ void mv_eth_buff_hdr_rx_dump(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
 
 }
 
-static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct napi_struct *napi)
+static inline int mv_pp2_rx(struct eth_port *pp, int rx_todo, int rxq, struct napi_struct *napi)
 {
 	struct net_device *dev = pp->dev;
 	MV_PP2_PHYS_RXQ_CTRL *rx_ctrl = pp->rxq_ctrl[rxq].q;
@@ -1877,7 +1880,7 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 	while (rx_done < rx_todo) {
 
 		if (pp->flags & MV_ETH_F_RX_DESC_PREFETCH)
-			rx_desc = mv_eth_rx_prefetch(pp, rx_ctrl, rx_done, rx_todo);
+			rx_desc = mv_pp2_rx_prefetch(pp, rx_ctrl, rx_done, rx_todo);
 		else {
 			rx_desc = mvPp2RxqNextDescGet(rx_ctrl);
 			mvOsCacheLineInv(NULL, rx_desc);
@@ -1889,28 +1892,28 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 		mvPPv2RxqDescSwap(rx_desc);
 #endif /* MV_CPU_BE */
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 		if (pp->dbg_flags & MV_ETH_F_DBG_RX) {
 			printk(KERN_ERR "\n%s: port=%d, cpu=%d\n", __func__, pp->port, smp_processor_id());
-			mv_eth_rx_desc_print(rx_desc);
+			mv_pp2_rx_desc_print(rx_desc);
 		}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 		rx_status = rx_desc->status;
-		bm = mv_eth_bm_cookie_build(rx_desc);
-		pool = mv_eth_bm_cookie_pool_get(bm);
-		ppool = &mv_eth_pool[pool];
+		bm = mv_pp2_bm_cookie_build(rx_desc);
+		pool = mv_pp2_bm_cookie_pool_get(bm);
+		ppool = &mv_pp2_pool[pool];
 
 		/* check if buffer header is used */
 		if ((rx_status & (PP2_RX_HWF_SYNC_MASK | PP2_RX_BUF_HDR_MASK)) == PP2_RX_BUF_HDR_MASK) {
-			mv_eth_buff_hdr_rx(pp, rx_desc);
+			mv_pp2_buff_hdr_rx(pp, rx_desc);
 			continue;
 		}
 
 		if (rx_status & PP2_RX_ES_MASK) {
-			mv_eth_rx_error(pp, rx_desc);
+			mv_pp2_rx_error(pp, rx_desc);
 
-			mv_eth_pool_refill(ppool, bm, rx_desc->bufPhysAddr, rx_desc->bufCookie);
+			mv_pp2_pool_refill(ppool, bm, rx_desc->bufPhysAddr, rx_desc->bufCookie);
 			mvOsCacheLineInv(NULL, rx_desc);
 			continue;
 		}
@@ -1920,7 +1923,7 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 			/* Remember sync bit for TX */
 			pr_info("\n%s: port=%d, rxq=%d, cpu=%d, skb=%p - Sync packet received\n",
 			__func__, pp->port, rxq, smp_processor_id(), skb);
-			mv_eth_rx_desc_print(rx_desc);
+			mv_pp2_rx_desc_print(rx_desc);
 			sync_head = skb->head;
 			sync_rx_desc = rx_status;
 		}
@@ -1940,17 +1943,17 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 		rx_bytes = rx_desc->dataSize;
 		dev->stats.rx_bytes += rx_bytes;
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 		if (pp->dbg_flags & MV_ETH_F_DBG_RX) {
 			printk(KERN_ERR "skb=%p, buf=%p, ksize=%d\n", skb, skb->head, ksize(skb->head));
 			mvDebugMemDump(skb->head + NET_SKB_PAD, 64, 1);
 		}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 		/* Linux processing */
 		__skb_put(skb, rx_bytes);
 
-#if defined(CONFIG_MV_ETH_RX_SPECIAL)
+#if defined(CONFIG_MV_PP2_RX_SPECIAL)
 		/* Special RX processing */
 		if (mvPp2IsRxSpecial(rx_desc->parserInfo)) {
 			if (pp->rx_special_proc) {
@@ -1958,29 +1961,29 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 					STAT_INFO(pp->stats.rx_special++);
 
 					/* Refill processing */
-					mv_eth_refill(ppool, bm, 0);
+					mv_pp2_refill(ppool, bm, 0);
 					mvOsCacheLineInv(NULL, rx_desc);
 					continue;
 				}
 			}
 		}
-#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+#endif /* CONFIG_MV_PP2_RX_SPECIAL */
 
-#ifdef CONFIG_NET_SKB_RECYCLE
-		if (mv_eth_is_recycle()) {
-			skb->skb_recycle = mv_eth_skb_recycle;
+#ifdef CONFIG_MV_PP2_SKB_RECYCLE
+		if (mv_pp2_is_recycle()) {
+			skb->skb_recycle = mv_pp2_skb_recycle;
 			skb->hw_cookie = bm;
 		}
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_PP2_SKB_RECYCLE */
 
-		mv_eth_rx_csum(pp, rx_desc, skb);
+		mv_pp2_rx_csum(pp, rx_desc, skb);
 
 		if (pp->tagged) {
 			mv_mux_rx(skb, pp->port, napi);
 			STAT_DBG(pp->stats.rx_tagged++);
 			skb = NULL;
 		} else {
-			dev->stats.rx_bytes -= mv_eth_mh_skb_skip(skb);
+			dev->stats.rx_bytes -= mv_pp2_mh_skb_skip(skb);
 			skb->protocol = eth_type_trans(skb, dev);
 		}
 
@@ -1999,7 +2002,7 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 		}
 
 		/* Refill processing: */
-		mv_eth_refill(ppool, bm, mv_eth_is_recycle());
+		mv_pp2_refill(ppool, bm, mv_pp2_is_recycle());
 		mvOsCacheLineInv(NULL, rx_desc);
 	}
 
@@ -2010,12 +2013,12 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 	return rx_done;
 }
 
-static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
+static int mv_pp2_tx(struct sk_buff *skb, struct net_device *dev)
 {
 	struct eth_port *pp = MV_ETH_PRIV(dev);
 	int frags = 0, cpu = smp_processor_id();
 	u32 tx_cmd, bufPhysAddr;
-	struct mv_eth_tx_spec tx_spec, *tx_spec_ptr = NULL;
+	struct mv_pp2_tx_spec tx_spec, *tx_spec_ptr = NULL;
 	struct tx_queue *txq_ctrl = NULL;
 	struct txq_cpu_ctrl *txq_cpu_ptr = NULL;
 	struct aggr_tx_queue *aggr_txq_ctrl = NULL;
@@ -2024,10 +2027,10 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 
 	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
 		STAT_INFO(pp->stats.netdev_stop++);
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 		if (pp->dbg_flags & MV_ETH_F_DBG_TX)
 			printk(KERN_ERR "%s: STARTED_BIT = 0, packet is dropped.\n", __func__);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 		goto out;
 	}
 
@@ -2036,7 +2039,7 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 		goto out;
 	}
 
-#if defined(CONFIG_MV_ETH_TX_SPECIAL)
+#if defined(CONFIG_MV_PP2_TX_SPECIAL)
 	if (pp->tx_special_check) {
 
 		if (pp->tx_special_check(pp->port, dev, skb, &tx_spec)) {
@@ -2050,15 +2053,15 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 			}
 		}
 	}
-#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+#endif /* CONFIG_MV_PP2_TX_SPECIAL */
 
 	/* In case this port is tagged, check if SKB is tagged - i.e. SKB's source is MUX interface */
 	if (pp->tagged && (!MV_MUX_SKB_IS_TAGGED(skb))) {
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 		if (pp->dbg_flags & MV_ETH_F_DBG_TX)
 			pr_err("%s: port %d is tagged, skb not from MUX interface - packet is dropped.\n",
 				__func__, pp->port);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 		goto out;
 	}
@@ -2066,11 +2069,11 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 	/* Get TXQ (without BM) to send packet generated by Linux */
 	if (tx_spec_ptr == NULL) {
 		tx_spec_ptr = &pp->tx_spec;
-		tx_spec_ptr->txq = mv_eth_select_txq(dev, skb);
+		tx_spec_ptr->txq = mv_pp2_select_txq(dev, skb);
 	}
 
 	aggr_txq_ctrl = &aggr_txqs[smp_processor_id()];
-	txq_ctrl = &pp->txq_ctrl[tx_spec_ptr->txp * CONFIG_MV_ETH_TXQ + tx_spec_ptr->txq];
+	txq_ctrl = &pp->txq_ctrl[tx_spec_ptr->txp * CONFIG_MV_PP2_TXQ + tx_spec_ptr->txq];
 	if (txq_ctrl == NULL) {
 		printk(KERN_ERR "%s: invalidate txp/txq (%d/%d)\n",
 			__func__, tx_spec_ptr->txp, tx_spec_ptr->txq);
@@ -2080,18 +2083,18 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 
 	MV_ETH_LIGHT_LOCK(flags);
 
-#ifdef CONFIG_MV_ETH_TSO
+#ifdef CONFIG_MV_PP2_TSO
 	/* GSO/TSO */
 	if (skb_is_gso(skb)) {
-		frags = mv_eth_tx_tso(skb, dev, tx_spec_ptr, txq_ctrl, aggr_txq_ctrl);
+		frags = mv_pp2_tx_tso(skb, dev, tx_spec_ptr, txq_ctrl, aggr_txq_ctrl);
 		goto out;
 	}
-#endif /* CONFIG_MV_ETH_TSO */
+#endif /* CONFIG_MV_PP2_TSO */
 
 	frags = skb_shinfo(skb)->nr_frags + 1;
 
 	if (tx_spec_ptr->flags & MV_ETH_TX_F_MH) {
-		if (mv_eth_skb_mh_add(skb, tx_spec_ptr->tx_mh)) {
+		if (mv_pp2_skb_mh_add(skb, tx_spec_ptr->tx_mh)) {
 			frags = 0;
 			goto out;
 		}
@@ -2099,11 +2102,11 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 
 	/* is enough descriptors? */
 #ifdef CONFIG_MV_ETH_PP2_1
-	if (mv_eth_reserved_desc_num_proc(pp, tx_spec_ptr->txp, tx_spec_ptr->txq, frags) ||
-		mv_eth_aggr_desc_num_check(aggr_txq_ctrl, frags)) {
+	if (mv_pp2_reserved_desc_num_proc(pp, tx_spec_ptr->txp, tx_spec_ptr->txq, frags) ||
+		mv_pp2_aggr_desc_num_check(aggr_txq_ctrl, frags)) {
 #else
-	if (mv_eth_phys_desc_num_check(txq_cpu_ptr, frags) ||
-		mv_eth_aggr_desc_num_check(aggr_txq_ctrl, frags)) {
+	if (mv_pp2_phys_desc_num_check(txq_cpu_ptr, frags) ||
+		mv_pp2_aggr_desc_num_check(aggr_txq_ctrl, frags)) {
 
 #endif
 
@@ -2117,7 +2120,7 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 
 	/* Don't use BM for Linux packets: NETA_TX_BM_ENABLE_MASK = 0 */
 	/* NETA_TX_PKT_OFFSET_MASK = 0 - for all descriptors */
-	tx_cmd = mv_eth_skb_tx_csum(pp, skb);
+	tx_cmd = mv_pp2_skb_tx_csum(pp, skb);
 
 	if (tx_spec_ptr->flags & MV_ETH_TX_F_HW_CMD) {
 		tx_desc->hwCmd[0] = tx_spec_ptr->hw_cmd[0];
@@ -2144,20 +2147,20 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 			tx_cmd |= PP2_TX_F_DESC_MASK | PP2_TX_L_DESC_MASK;
 
 		tx_desc->command = tx_cmd;
-		mv_eth_tx_desc_flush(tx_desc);
+		mv_pp2_tx_desc_flush(tx_desc);
 
-		mv_eth_shadow_push(txq_cpu_ptr, ((MV_ULONG) skb | MV_ETH_SHADOW_SKB));
+		mv_pp2_shadow_push(txq_cpu_ptr, ((MV_ULONG) skb | MV_ETH_SHADOW_SKB));
 	} else {
 		/* First but not Last */
 		tx_cmd |= PP2_TX_F_DESC_MASK | PP2_TX_PADDING_DISABLE_MASK;
 
-		mv_eth_shadow_push(txq_cpu_ptr, 0);
+		mv_pp2_shadow_push(txq_cpu_ptr, 0);
 
 		tx_desc->command = tx_cmd;
-		mv_eth_tx_desc_flush(tx_desc);
+		mv_pp2_tx_desc_flush(tx_desc);
 
 		/* Continue with other skb fragments */
-		mv_eth_tx_frag_process(pp, skb, aggr_txq_ctrl, txq_ctrl, tx_spec_ptr);
+		mv_pp2_tx_frag_process(pp, skb, aggr_txq_ctrl, txq_ctrl, tx_spec_ptr);
 		STAT_DBG(pp->stats.tx_sg++);
 	}
 
@@ -2173,12 +2176,12 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 		pr_info("%s: port=%d, txp=%d, txq=%d, cpu=%d, skb=%p, rx_desc=0x%08x - Sync packet transmitted\n",
 			__func__, pp->port, tx_spec_ptr->txp, tx_spec_ptr->txq, smp_processor_id(),
 			skb, sync_rx_desc);
-		mv_eth_tx_desc_print(tx_desc);
+		mv_pp2_tx_desc_print(tx_desc);
 		mvDebugMemDump(skb->data, 64, 1);
 		sync_head = NULL;
 		sync_rx_desc = 0;
 	}
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 	if (pp->dbg_flags & MV_ETH_F_DBG_TX) {
 		printk(KERN_ERR "\n");
 		printk(KERN_ERR "%s - eth_tx_%lu: cpu=%d, in_intr=0x%lx, port=%d, txp=%d, txq=%d\n",
@@ -2186,11 +2189,11 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 			pp->port, tx_spec_ptr->txp, tx_spec_ptr->txq);
 		printk(KERN_ERR "\t skb=%p, head=%p, data=%p, size=%d\n", skb, skb->head, skb->data, skb->len);
 		pr_info("\t sync_head=%p, sync_rx_desc=0x%08x\n", sync_head, sync_rx_desc);
-		mv_eth_tx_desc_print(tx_desc);
-		/*mv_eth_skb_print(skb);*/
+		mv_pp2_tx_desc_print(tx_desc);
+		/*mv_pp2_skb_print(skb);*/
 		mvDebugMemDump(skb->data, 64, 1);
 	}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 	/* Enable transmit */
 	wmb();
 	mvPp2AggrTxqPendDescAdd(frags);
@@ -2207,23 +2210,23 @@ out:
 		dev_kfree_skb_any(skb);
 	}
 
-#ifndef CONFIG_MV_ETH_TXDONE_ISR
+#ifndef CONFIG_MV_PP2_TXDONE_ISR
 	if (txq_ctrl) {
-		if (txq_cpu_ptr->txq_count >= mv_ctrl_txdone) {
-#ifdef CONFIG_MV_ETH_STAT_DIST
-			u32 tx_done = mv_eth_txq_done(pp, txq_ctrl);
+		if (txq_cpu_ptr->txq_count >= mv_ctrl_pp2_txdone) {
+#ifdef CONFIG_MV_PP2_STAT_DIST
+			u32 tx_done = mv_pp2_txq_done(pp, txq_ctrl);
 
 			if (tx_done < pp->dist_stats.tx_done_dist_size)
 				pp->dist_stats.tx_done_dist[tx_done]++;
 #else
-			mv_eth_txq_done(pp, txq_ctrl);
-#endif /* CONFIG_MV_ETH_STAT_DIST */
+			mv_pp2_txq_done(pp, txq_ctrl);
+#endif /* CONFIG_MV_PP2_STAT_DIST */
 		}
-		/* If after calling mv_eth_txq_done, txq_ctrl->txq_count equals frags, we need to set the timer */
+		/* If after calling mv_pp2_txq_done, txq_ctrl->txq_count equals frags, we need to set the timer */
 		if ((txq_cpu_ptr->txq_count == frags) && (frags > 0))
-			mv_eth_add_tx_done_timer(pp->cpu_config[smp_processor_id()]);
+			mv_pp2_add_tx_done_timer(pp->cpu_config[smp_processor_id()]);
 	}
-#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+#endif /* CONFIG_MV_PP2_TXDONE_ISR */
 
 	if (txq_ctrl)
 		MV_ETH_LIGHT_UNLOCK(flags);
@@ -2231,9 +2234,9 @@ out:
 	return NETDEV_TX_OK;
 }
 
-#ifdef CONFIG_MV_ETH_TSO
+#ifdef CONFIG_MV_PP2_TSO
 /* Validate TSO */
-static inline int mv_eth_tso_validate(struct sk_buff *skb, struct net_device *dev)
+static inline int mv_pp2_tso_validate(struct sk_buff *skb, struct net_device *dev)
 {
 	if (!(dev->features & NETIF_F_TSO)) {
 		pr_err("error: (skb_is_gso(skb) returns true but features is not NETIF_F_TSO\n");
@@ -2259,7 +2262,7 @@ static inline int mv_eth_tso_validate(struct sk_buff *skb, struct net_device *de
 	return 0;
 }
 
-static inline int mv_eth_tso_build_hdr_desc(struct pp2_tx_desc *tx_desc, struct eth_port *priv, struct sk_buff *skb,
+static inline int mv_pp2_tso_build_hdr_desc(struct pp2_tx_desc *tx_desc, struct eth_port *priv, struct sk_buff *skb,
 					     struct txq_cpu_ctrl *txq_ctrl, u16 *mh, int hdr_len, int size,
 					     MV_U32 tcp_seq, MV_U16 ip_id, int left_len)
 {
@@ -2269,12 +2272,12 @@ static inline int mv_eth_tso_build_hdr_desc(struct pp2_tx_desc *tx_desc, struct
 	MV_U32 bufPhysAddr;
 	int mac_hdr_len = skb_network_offset(skb);
 
-	data = mv_eth_extra_pool_get(priv);
+	data = mv_pp2_extra_pool_get(priv);
 	if (!data) {
 		pr_err("Can't allocate extra buffer for TSO\n");
 		return 0;
 	}
-	mv_eth_shadow_push(txq_ctrl, ((MV_ULONG)data | MV_ETH_SHADOW_EXT));
+	mv_pp2_shadow_push(txq_ctrl, ((MV_ULONG)data | MV_ETH_SHADOW_EXT));
 
 	/* Reserve 2 bytes for IP header alignment */
 	mac = data + MV_ETH_MH_SIZE;
@@ -2316,12 +2319,12 @@ static inline int mv_eth_tso_build_hdr_desc(struct pp2_tx_desc *tx_desc, struct
 	tx_desc->pktOffset = bufPhysAddr & MV_ETH_TX_DESC_ALIGN;
 	tx_desc->bufPhysAddr = bufPhysAddr & (~MV_ETH_TX_DESC_ALIGN);
 
-	mv_eth_tx_desc_flush(tx_desc);
+	mv_pp2_tx_desc_flush(tx_desc);
 
 	return hdr_len;
 }
 
-static inline int mv_eth_tso_build_data_desc(struct pp2_tx_desc *tx_desc, struct sk_buff *skb,
+static inline int mv_pp2_tso_build_data_desc(struct pp2_tx_desc *tx_desc, struct sk_buff *skb,
 					     struct txq_cpu_ctrl *txq_ctrl, char *frag_ptr,
 					     int frag_size, int data_left, int total_left)
 {
@@ -2347,18 +2350,18 @@ static inline int mv_eth_tso_build_data_desc(struct pp2_tx_desc *tx_desc, struct
 			val = ((MV_ULONG) skb | MV_ETH_SHADOW_SKB);
 		}
 	}
-	mv_eth_shadow_push(txq_ctrl, val);
-	mv_eth_tx_desc_flush(tx_desc);
+	mv_pp2_shadow_push(txq_ctrl, val);
+	mv_pp2_tx_desc_flush(tx_desc);
 
 	return size;
 }
 
 /***********************************************************
- * mv_eth_tx_tso --                                        *
+ * mv_pp2_tx_tso --                                        *
  *   send a packet.                                        *
  ***********************************************************/
-int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_eth_tx_spec *tx_spec,
-			struct tx_queue *txq_ctrl, struct aggr_tx_queue *aggr_txq_ctrl)
+static int mv_pp2_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_pp2_tx_spec *tx_spec,
+			 struct tx_queue *txq_ctrl, struct aggr_tx_queue *aggr_txq_ctrl)
 {
 	int ptxq, frag = 0;
 	int total_len, hdr_len, size, frag_size, data_left;
@@ -2374,7 +2377,7 @@ int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_eth_tx_
 
 	STAT_DBG(priv->stats.tx_tso++);
 
-	if (mv_eth_tso_validate(skb, dev))
+	if (mv_pp2_tso_validate(skb, dev))
 		return 0;
 
 	txq_cpu_ptr = &txq_ctrl->txq_cpu[smp_processor_id()];
@@ -2423,16 +2426,16 @@ int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_eth_tx_
 		 * We also need one descriptor for packet header						  */
 		seg_desc_num = skb_shinfo(skb)->nr_frags - frag + 2;
 
-		if (mv_eth_aggr_desc_num_check(aggr_txq_ctrl, seg_desc_num)) {
+		if (mv_pp2_aggr_desc_num_check(aggr_txq_ctrl, seg_desc_num)) {
 			STAT_DBG(priv->stats.tx_tso_no_resource++);
 			return 0;
 		}
 
 		/* Check if there are enough descriptors in physical TXQ */
 #ifdef CONFIG_MV_ETH_PP2_1
-		if (mv_eth_reserved_desc_num_proc(priv, tx_spec->txp, tx_spec->txq, seg_desc_num)) {
+		if (mv_pp2_reserved_desc_num_proc(priv, tx_spec->txp, tx_spec->txq, seg_desc_num)) {
 #else
-		if (mv_eth_phys_desc_num_check(txq_cpu_ptr, seg_desc_num)) {
+		if (mv_pp2_phys_desc_num_check(txq_cpu_ptr, seg_desc_num)) {
 #endif
 			STAT_DBG(priv->stats.tx_tso_no_resource++);
 			return 0;
@@ -2454,12 +2457,12 @@ int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_eth_tx_
 			mh = &tx_spec->tx_mh;
 
 		/* prepare packet headers: MAC + IP + TCP */
-		size = mv_eth_tso_build_hdr_desc(tx_desc, priv, skb, txq_cpu_ptr, mh,
+		size = mv_pp2_tso_build_hdr_desc(tx_desc, priv, skb, txq_cpu_ptr, mh,
 					hdr_len, data_left, tcp_seq, ip_id, total_len);
 		if (size == 0) {
 			aggr_txq_ctrl->txq_count--;
 			txq_cpu_ptr->txq_count--;
-			mv_eth_shadow_dec_put(txq_cpu_ptr);
+			mv_pp2_shadow_dec_put(txq_cpu_ptr);
 			mvPp2AggrTxqPrevDescGet(aggr_txq_ctrl->q);
 
 			STAT_DBG(priv->stats.tx_tso_no_resource++);
@@ -2479,7 +2482,7 @@ int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_eth_tx_
 			aggr_txq_ctrl->txq_count++;
 			txq_cpu_ptr->txq_count++;
 
-			size = mv_eth_tso_build_data_desc(tx_desc, skb, txq_cpu_ptr,
+			size = mv_pp2_tso_build_data_desc(tx_desc, skb, txq_cpu_ptr,
 							  frag_ptr, frag_size, data_left, total_len);
 			total_bytes += size;
 			data_left -= size;
@@ -2523,10 +2526,10 @@ int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev, struct mv_eth_tx_
 	return total_desc_num;
 }
 
-#endif /* CONFIG_MV_ETH_TSO */
+#endif /* CONFIG_MV_PP2_TSO */
 
 /* Push packets received by the RXQ to BM pool */
-static void mv_eth_rxq_drop_pkts(struct eth_port *pp, int rxq)
+static void mv_pp2_rxq_drop_pkts(struct eth_port *pp, int rxq)
 {
 	struct pp2_rx_desc   *rx_desc;
 	int	                 rx_done, i;
@@ -2549,11 +2552,11 @@ static void mv_eth_rxq_drop_pkts(struct eth_port *pp, int rxq)
 		mvPPv2RxqDescSwap(rx_desc);
 #endif /* MV_CPU_BE */
 
-		bm = mv_eth_bm_cookie_build(rx_desc);
-		pool = mv_eth_bm_cookie_pool_get(bm);
-		ppool = &mv_eth_pool[pool];
+		bm = mv_pp2_bm_cookie_build(rx_desc);
+		pool = mv_pp2_bm_cookie_pool_get(bm);
+		ppool = &mv_pp2_pool[pool];
 
-		mv_eth_pool_refill(ppool, bm, rx_desc->bufPhysAddr, rx_desc->bufCookie);
+		mv_pp2_pool_refill(ppool, bm, rx_desc->bufPhysAddr, rx_desc->bufCookie);
 		mvOsCacheLineInv(NULL, rx_desc);
 	}
 	if (rx_done) {
@@ -2562,7 +2565,7 @@ static void mv_eth_rxq_drop_pkts(struct eth_port *pp, int rxq)
 	}
 }
 
-static int mv_eth_txq_done_force(struct eth_port *pp, struct tx_queue *txq_ctrl)
+static int mv_pp2_txq_done_force(struct eth_port *pp, struct tx_queue *txq_ctrl)
 {
 	int cpu, tx_done = 0;
 	struct txq_cpu_ctrl *txq_cpu_ptr;
@@ -2570,7 +2573,7 @@ static int mv_eth_txq_done_force(struct eth_port *pp, struct tx_queue *txq_ctrl)
 	for_each_possible_cpu(cpu) {
 		txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
 		tx_done = txq_cpu_ptr->txq_count;
-		mv_eth_txq_bufs_free(pp, &txq_ctrl->txq_cpu[cpu], tx_done);
+		mv_pp2_txq_bufs_free(pp, &txq_ctrl->txq_cpu[cpu], tx_done);
 		STAT_DBG(txq_cpu_ptr->stats.txq_txdone += tx_done);
 
 		/* reset txq */
@@ -2581,7 +2584,7 @@ static int mv_eth_txq_done_force(struct eth_port *pp, struct tx_queue *txq_ctrl)
 	return tx_done;
 }
 
-inline u32 mv_eth_tx_done_pon(struct eth_port *pp, int *tx_todo)
+inline u32 mv_pp2_tx_done_pon(struct eth_port *pp, int *tx_todo)
 {
 	int txp, txq;
 	struct tx_queue *txq_ctrl;
@@ -2595,13 +2598,13 @@ inline u32 mv_eth_tx_done_pon(struct eth_port *pp, int *tx_todo)
 	/* simply go over all TX ports and TX queues */
 	txp = pp->txp_num;
 	while (txp--) {
-		txq = CONFIG_MV_ETH_TXQ;
+		txq = CONFIG_MV_PP2_TXQ;
 
 		while (txq--) {
-			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + txq];
 			txq_cpu_ptr = &txq_ctrl->txq_cpu[smp_processor_id()];
 			if ((txq_ctrl) && (txq_cpu_ptr->txq_count)) {
-				tx_done += mv_eth_txq_done(pp, txq_ctrl);
+				tx_done += mv_pp2_txq_done(pp, txq_ctrl);
 				*tx_todo += txq_cpu_ptr->txq_count;
 			}
 		}
@@ -2613,7 +2616,7 @@ inline u32 mv_eth_tx_done_pon(struct eth_port *pp, int *tx_todo)
 }
 
 
-inline u32 mv_eth_tx_done_gbe(struct eth_port *pp, u32 cause_tx_done, int *tx_todo)
+inline u32 mv_pp2_tx_done_gbe(struct eth_port *pp, u32 cause_tx_done, int *tx_todo)
 {
 	int txq;
 	struct tx_queue *txq_ctrl;
@@ -2627,7 +2630,7 @@ inline u32 mv_eth_tx_done_gbe(struct eth_port *pp, u32 cause_tx_done, int *tx_to
 	while (cause_tx_done != 0) {
 
 		/* For GbE ports we get TX Buffers Threshold Cross per queue in bits [7:0] */
-		txq = mv_eth_tx_done_policy(cause_tx_done);
+		txq = mv_pp2_tx_done_policy(cause_tx_done);
 
 		if (txq == -1)
 			break;
@@ -2641,7 +2644,7 @@ inline u32 mv_eth_tx_done_gbe(struct eth_port *pp, u32 cause_tx_done, int *tx_to
 		}
 
 		if ((txq_ctrl) && (txq_cpu_ptr->txq_count)) {
-			tx_done += mv_eth_txq_done(pp, txq_ctrl);
+			tx_done += mv_pp2_txq_done(pp, txq_ctrl);
 			*tx_todo += txq_cpu_ptr->txq_count;
 		}
 
@@ -2654,8 +2657,8 @@ inline u32 mv_eth_tx_done_gbe(struct eth_port *pp, u32 cause_tx_done, int *tx_to
 }
 
 
-static void mv_eth_tx_frag_process(struct eth_port *pp, struct sk_buff *skb, struct aggr_tx_queue *aggr_txq_ctrl,
-					struct tx_queue *txq_ctrl, struct mv_eth_tx_spec *tx_spec)
+static void mv_pp2_tx_frag_process(struct eth_port *pp, struct sk_buff *skb, struct aggr_tx_queue *aggr_txq_ctrl,
+					struct tx_queue *txq_ctrl, struct mv_pp2_tx_spec *tx_spec)
 {
 	int i, cpu = smp_processor_id();
 	struct pp2_tx_desc *tx_desc;
@@ -2689,25 +2692,25 @@ static void mv_eth_tx_frag_process(struct eth_port *pp, struct sk_buff *skb, str
 			else
 				tx_desc->command = PP2_TX_L_DESC_MASK;
 
-			mv_eth_shadow_push(&txq_ctrl->txq_cpu[cpu], ((MV_ULONG) skb | MV_ETH_SHADOW_SKB));
+			mv_pp2_shadow_push(&txq_ctrl->txq_cpu[cpu], ((MV_ULONG) skb | MV_ETH_SHADOW_SKB));
 		} else {
 			/* Descriptor in the middle: Not First, Not Last */
 			tx_desc->command = 0;
 
-			mv_eth_shadow_push(&txq_ctrl->txq_cpu[cpu], 0);
+			mv_pp2_shadow_push(&txq_ctrl->txq_cpu[cpu], 0);
 		}
 
-		mv_eth_tx_desc_flush(tx_desc);
+		mv_pp2_tx_desc_flush(tx_desc);
 	}
 }
 
 
 /* Free "num" buffers from the pool */
-static int mv_eth_pool_free(int pool, int num)
+static int mv_pp2_pool_free(int pool, int num)
 {
 	int i = 0, buf_size, total_size;
 	u32 pa;
-	struct bm_pool *ppool = &mv_eth_pool[pool];
+	struct bm_pool *ppool = &mv_pp2_pool[pool];
 	bool free_all = false;
 
 	if (num >= ppool->buf_num) {
@@ -2733,7 +2736,7 @@ static int mv_eth_pool_free(int pool, int num)
 		/*pr_info("%4d: phys_addr=0x%x, virt_addr=%p\n", i, pa, va);*/
 
 		if (!MV_ETH_BM_POOL_IS_HWF(ppool->type)) {
-			mv_eth_skb_free((struct sk_buff *)va);
+			mv_pp2_skb_free((struct sk_buff *)va);
 		} else { /* HWF pool */
 			mvOsFree((char *)va);
 		}
@@ -2751,12 +2754,12 @@ static int mv_eth_pool_free(int pool, int num)
 }
 
 
-static int mv_eth_pool_destroy(int pool)
+static int mv_pp2_pool_destroy(int pool)
 {
 	int num, status = 0;
-	struct bm_pool *ppool = &mv_eth_pool[pool];
+	struct bm_pool *ppool = &mv_pp2_pool[pool];
 
-	num = mv_eth_pool_free(pool, ppool->buf_num);
+	num = mv_pp2_pool_free(pool, ppool->buf_num);
 	if (num != ppool->buf_num) {
 		printk(KERN_ERR "Warning: could not free all buffers in pool %d while destroying pool\n", pool);
 		return MV_ERROR;
@@ -2774,7 +2777,7 @@ static int mv_eth_pool_destroy(int pool)
 }
 
 
-static int mv_eth_pool_add(int pool, int buf_num)
+static int mv_pp2_pool_add(int pool, int buf_num)
 {
 	struct bm_pool *bm_pool;
 	struct sk_buff *skb;
@@ -2786,7 +2789,7 @@ static int mv_eth_pool_add(int pool, int buf_num)
 	if (mvPp2MaxCheck(pool, MV_ETH_BM_POOLS, "bm_pool"))
 		return 0;
 
-	bm_pool = &mv_eth_pool[pool];
+	bm_pool = &mv_pp2_pool[pool];
 
 	if (MV_ETH_BM_POOL_IS_HWF(bm_pool->type)) {
 		buf_size = RX_HWF_BUF_SIZE(bm_pool->pkt_size);
@@ -2810,23 +2813,23 @@ static int mv_eth_pool_add(int pool, int buf_num)
 		return 0;
 	}
 
-	bm = mv_eth_bm_cookie_pool_set(bm, pool);
+	bm = mv_pp2_bm_cookie_pool_set(bm, pool);
 	for (i = 0; i < buf_num; i++) {
 		if (!MV_ETH_BM_POOL_IS_HWF(bm_pool->type)) {
 			/* Allocate skb for pool used for SWF */
-			skb = mv_eth_skb_alloc(bm_pool, &phys_addr, GFP_KERNEL);
+			skb = mv_pp2_skb_alloc(bm_pool, &phys_addr, GFP_KERNEL);
 			if (!skb)
 				break;
 
-			mv_eth_pool_refill(bm_pool, bm, phys_addr, (unsigned long) skb);
+			mv_pp2_pool_refill(bm_pool, bm, phys_addr, (unsigned long) skb);
 		} else {
 			/* Allocate pkt + buffer for pool used for HWF */
-			hwf_buff = mv_eth_hwf_buff_alloc(bm_pool, &phys_addr);
+			hwf_buff = mv_pp2_hwf_buff_alloc(bm_pool, &phys_addr);
 			if (!hwf_buff)
 				break;
 
 			memset(hwf_buff, 0, buf_size);
-			mv_eth_pool_refill(bm_pool, bm, phys_addr, (MV_ULONG) hwf_buff);
+			mv_pp2_pool_refill(bm_pool, bm, phys_addr, (MV_ULONG) hwf_buff);
 		}
 	}
 
@@ -2844,7 +2847,7 @@ static int mv_eth_pool_add(int pool, int buf_num)
 	return i;
 }
 
-void	*mv_eth_bm_pool_create(int pool, int capacity, MV_ULONG *pPhysAddr)
+void	*mv_pp2_bm_pool_create(int pool, int capacity, MV_ULONG *pPhysAddr)
 {
 	MV_ULONG physAddr;
 	void *pVirt;
@@ -2880,7 +2883,7 @@ void	*mv_eth_bm_pool_create(int pool, int capacity, MV_ULONG *pPhysAddr)
 	return pVirt;
 }
 
-static MV_STATUS mv_eth_pool_create(int pool, int capacity)
+static MV_STATUS mv_pp2_pool_create(int pool, int capacity)
 {
 	struct bm_pool *bm_pool;
 	MV_ULONG    physAddr;
@@ -2890,10 +2893,10 @@ static MV_STATUS mv_eth_pool_create(int pool, int capacity)
 		return MV_BAD_VALUE;
 	}
 
-	bm_pool = &mv_eth_pool[pool];
+	bm_pool = &mv_pp2_pool[pool];
 	memset(bm_pool, 0, sizeof(struct bm_pool));
 
-	bm_pool->bm_pool = mv_eth_bm_pool_create(pool, capacity, &physAddr);
+	bm_pool->bm_pool = mv_pp2_bm_pool_create(pool, capacity, &physAddr);
 	if (bm_pool->bm_pool == NULL)
 		return MV_FAIL;
 
@@ -2909,7 +2912,7 @@ static MV_STATUS mv_eth_pool_create(int pool, int capacity)
 	return MV_OK;
 }
 
-/* mv_eth_pool_use:							*
+/* mv_pp2_pool_use:							*
  *	- notify the driver that BM pool is being used as specific type	*
  *	- Allocate / Free buffers if necessary				*
  *	- Returns the used pool pointer in case of success		*
@@ -2917,13 +2920,13 @@ static MV_STATUS mv_eth_pool_create(int pool, int capacity)
  *		- pool: BM pool that is being used			*
  *		- type: type of usage (SWF/HWF/MIXED long/short)	*
  *		- pkt_size: number of bytes per packet			*/
-static struct bm_pool *mv_eth_pool_use(int pool, enum mv_eth_bm_type type, int pkt_size)
+static struct bm_pool *mv_pp2_pool_use(int pool, enum mv_pp2_bm_type type, int pkt_size)
 {
 	unsigned long flags = 0;
 	struct bm_pool *new_pool;
 	int num;
 
-	new_pool = &mv_eth_pool[pool];
+	new_pool = &mv_pp2_pool[pool];
 
 	if ((MV_ETH_BM_POOL_IS_SHORT(new_pool->type) && MV_ETH_BM_POOL_IS_LONG(type))
 		|| (MV_ETH_BM_POOL_IS_SHORT(type) && MV_ETH_BM_POOL_IS_LONG(new_pool->type))) {
@@ -2948,7 +2951,7 @@ static struct bm_pool *mv_eth_pool_use(int pool, enum mv_eth_bm_type type, int p
 		int port, pkts_num;
 
 		/* If there are ports using this pool, they must be stopped before allocation */
-		port = mv_eth_port_up_get(new_pool->port_map);
+		port = mv_pp2_port_up_get(new_pool->port_map);
 		if (port != -1) {
 			pr_err("%s: port %d use pool %d and must be stopped before buffer re-allocation\n",
 				__func__, port, new_pool->pool);
@@ -2961,9 +2964,9 @@ static struct bm_pool *mv_eth_pool_use(int pool, enum mv_eth_bm_type type, int p
 		pkts_num = new_pool->buf_num;
 		if (pkts_num == 0)
 			pkts_num = (MV_ETH_BM_POOL_IS_LONG(type)) ?
-				CONFIG_MV_ETH_BM_LONG_BUF_NUM : CONFIG_MV_ETH_BM_SHORT_BUF_NUM;
+				CONFIG_MV_PP2_BM_LONG_BUF_NUM : CONFIG_MV_PP2_BM_SHORT_BUF_NUM;
 		else
-			mv_eth_pool_free(new_pool->pool, pkts_num);
+			mv_pp2_pool_free(new_pool->pool, pkts_num);
 
 		/* Check if pool has moved to SWF and HWF shared mode */
 		if ((MV_ETH_BM_POOL_IS_HWF(new_pool->type) && !MV_ETH_BM_POOL_IS_HWF(type))
@@ -2976,7 +2979,7 @@ static struct bm_pool *mv_eth_pool_use(int pool, enum mv_eth_bm_type type, int p
 			new_pool->pkt_size = pkt_size;
 
 		/* Allocate buffers for this pool */
-		num = mv_eth_pool_add(new_pool->pool, pkts_num);
+		num = mv_pp2_pool_add(new_pool->pool, pkts_num);
 		if (num != pkts_num) {
 			pr_err("%s FAILED: pool=%d, pkt_size=%d, only %d of %d allocated\n",
 				__func__, new_pool->pool, new_pool->pkt_size, num, pkts_num);
@@ -2997,7 +3000,7 @@ static struct bm_pool *mv_eth_pool_use(int pool, enum mv_eth_bm_type type, int p
 }
 
 /* Interrupt handling */
-irqreturn_t mv_eth_isr(int irq, void *dev_id)
+irqreturn_t mv_pp2_isr(int irq, void *dev_id)
 {
 	struct eth_port *pp = (struct eth_port *)dev_id;
 	int cpu = smp_processor_id();
@@ -3005,14 +3008,14 @@ irqreturn_t mv_eth_isr(int irq, void *dev_id)
 	struct napi_struct *napi = napi_group->napi;
 	u32 imr;
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 	if (pp->dbg_flags & MV_ETH_F_DBG_ISR) {
 		pr_info("%s: port=%d, cpu=%d, mask=0x%x, cause=0x%x\n",
 			__func__, pp->port, cpu,
 			mvPp2RdReg(MV_PP2_ISR_RX_TX_MASK_REG(MV_PPV2_PORT_PHYS(pp->port))),
 			mvPp2GbeIsrCauseRxTxGet(pp->port));
 	}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 	STAT_INFO(pp->stats.irq[cpu]++);
 
@@ -3025,10 +3028,10 @@ irqreturn_t mv_eth_isr(int irq, void *dev_id)
 		__napi_schedule(napi);
 	} else {
 		STAT_INFO(pp->stats.irq_err[cpu]++);
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 		pr_warning("%s: IRQ=%d, port=%d, cpu=%d, cpu_mask=0x%x - NAPI already scheduled\n",
 			__func__, irq, pp->port, cpu, napi_group->cpu_mask);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 	}
 
 	/*
@@ -3041,7 +3044,7 @@ irqreturn_t mv_eth_isr(int irq, void *dev_id)
 	return IRQ_HANDLED;
 }
 
-irqreturn_t mv_eth_link_isr(int irq, void *dev_id)
+irqreturn_t mv_pp2_link_isr(int irq, void *dev_id)
 {
 	mvGmacIsrSummaryMask();
 
@@ -3063,7 +3066,7 @@ irqreturn_t mv_wol_isr(int irq, void *dev_id)
 }
 #endif
 
-void mv_eth_link_tasklet(unsigned long data)
+void mv_pp2_link_tasklet(unsigned long data)
 {
 	int port;
 	MV_U32 regVal, regVal1;
@@ -3074,7 +3077,7 @@ void mv_eth_link_tasklet(unsigned long data)
 	/* check only relevant interrupts - ports0 and 1 */
 	regVal &= (ETH_ISR_SUM_PORT0_MASK | ETH_ISR_SUM_PORT1_MASK);
 
-	for (port = 0; port < mv_eth_ports_num; port++) {
+	for (port = 0; port < mv_pp2_ports_num; port++) {
 		/* check if interrupt was caused by this port */
 		if (!(ETH_ISR_SUM_PORT_MASK(port) & regVal))
 			continue;
@@ -3087,25 +3090,25 @@ void mv_eth_link_tasklet(unsigned long data)
 			continue;
 		}
 
-		pp = mv_eth_port_by_id(port);
+		pp = mv_pp2_port_by_id(port);
 		if (pp)
-			mv_eth_link_event(pp, 1);
+			mv_pp2_link_event(pp, 1);
 	}
 
 	mvGmacIsrSummaryUnmask();
 }
 
-static bool mv_eth_link_status(struct eth_port *pp)
+static bool mv_pp2_link_status(struct eth_port *pp)
 {
 #ifdef CONFIG_MV_INCLUDE_PON
-	if (MV_PON_PORT(pp->port))
+	if (MV_PP2_IS_PON_PORT(pp->port))
 		return mv_pon_link_status(NULL);
 	else
 #endif /* CONFIG_MV_PON */
 		return mvGmacPortIsLinkUp(pp->port);
 }
 
-void mv_eth_link_event(struct eth_port *pp, int print)
+void mv_pp2_link_event(struct eth_port *pp, int print)
 {
 	struct net_device *dev = pp->dev;
 	bool              link_is_up = false;
@@ -3113,14 +3116,14 @@ void mv_eth_link_event(struct eth_port *pp, int print)
 	STAT_INFO(pp->stats.link++);
 
 	/* Check Link status on ethernet port */
-	link_is_up = mv_eth_link_status(pp);
+	link_is_up = mv_pp2_link_status(pp);
 
 	if (link_is_up) {
 		/* Link Up event */
 		mvPp2PortEgressEnable(pp->port, MV_TRUE);
 		set_bit(MV_ETH_F_LINK_UP_BIT, &(pp->flags));
 
-		if (mv_eth_ctrl_is_tx_enabled(pp)) {
+		if (mv_pp2_ctrl_is_tx_enabled(pp)) {
 			if (dev) {
 				netif_carrier_on(dev);
 				netif_tx_wake_all_queues(dev);
@@ -3144,34 +3147,34 @@ void mv_eth_link_event(struct eth_port *pp, int print)
 		else
 			printk(KERN_ERR "%s: ", "none");
 
-		mv_eth_link_status_print(pp->port);
+		mv_pp2_eth_link_status_print(pp->port);
 	}
 }
 
 /***********************************************************************************************/
-int mv_eth_poll(struct napi_struct *napi, int budget)
+int mv_pp2_poll(struct napi_struct *napi, int budget)
 {
 	int rx_done = 0;
 	struct napi_group_ctrl *napi_group;
 	MV_U32 causeRxTx;
 	struct eth_port *pp = MV_ETH_PRIV(napi->dev);
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 	if (pp->dbg_flags & MV_ETH_F_DBG_POLL) {
 		printk(KERN_ERR "%s ENTER: port=%d, cpu=%d, mask=0x%x, cause=0x%x\n",
 			__func__, pp->port, smp_processor_id(),
 			mvPp2RdReg(MV_PP2_ISR_RX_TX_MASK_REG(MV_PPV2_PORT_PHYS(pp->port))),
 			mvPp2GbeIsrCauseRxTxGet(pp->port));
 	}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
 		STAT_INFO(pp->stats.netdev_stop++);
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 		if (pp->dbg_flags & MV_ETH_F_DBG_RX)
 			printk(KERN_ERR "%s: STARTED_BIT = 0, poll completed.\n", __func__);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 		napi_complete(napi);
 		STAT_INFO(pp->stats.poll_exit[smp_processor_id()]++);
@@ -3204,18 +3207,18 @@ int mv_eth_poll(struct napi_struct *napi, int budget)
 	napi_group = pp->cpu_config[smp_processor_id()]->napi_group;
 	causeRxTx |= napi_group->cause_rx_tx;
 
-#ifdef CONFIG_MV_ETH_TXDONE_ISR
+#ifdef CONFIG_MV_PP2_TXDONE_ISR
 	if (mvPp2GbeIsrCauseTxDoneIsSet(pp->port, causeRxTx)) {
 		int tx_todo = 0, cause_tx_done;
 		/* TX_DONE process */
 		cause_tx_done = mvPp2GbeIsrCauseTxDoneOffset(pp->port, causeRxTx);
-		if (MV_PON_PORT(pp->port))
-			mv_eth_tx_done_pon(pp, &tx_todo);
+		if (MV_PP2_IS_PON_PORT(pp->port))
+			mv_pp2_tx_done_pon(pp, &tx_todo);
 		else
-			mv_eth_tx_done_gbe(pp, cause_tx_done, &tx_todo);
+			mv_pp2_tx_done_gbe(pp, cause_tx_done, &tx_todo);
 	}
-#endif /* CONFIG_MV_ETH_TXDONE_ISR */
-	if (MV_PON_PORT(pp->port))
+#endif /* CONFIG_MV_PP2_TXDONE_ISR */
+	if (MV_PP2_IS_PON_PORT(pp->port))
 		causeRxTx &= ~MV_PP2_PON_CAUSE_TXP_OCCUP_DESC_ALL_MASK;
 	else
 		causeRxTx &= ~MV_PP2_CAUSE_TXQ_OCCUP_DESC_ALL_MASK;
@@ -3223,11 +3226,11 @@ int mv_eth_poll(struct napi_struct *napi, int budget)
 	while ((causeRxTx != 0) && (budget > 0)) {
 		int count, rx_queue;
 
-		rx_queue = mv_eth_rx_policy(causeRxTx);
+		rx_queue = mv_pp2_rx_policy(causeRxTx);
 		if (rx_queue == -1)
 			break;
 
-		count = mv_eth_rx(pp, budget, rx_queue, napi);
+		count = mv_pp2_rx(pp, budget, rx_queue, napi);
 		rx_done += count;
 		budget -= count;
 		if (budget > 0)
@@ -3240,12 +3243,12 @@ int mv_eth_poll(struct napi_struct *napi, int budget)
 
 	STAT_DIST((rx_done < pp->dist_stats.rx_dist_size) ? pp->dist_stats.rx_dist[rx_done]++ : 0);
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 	if (pp->dbg_flags & MV_ETH_F_DBG_POLL) {
 		printk(KERN_ERR "%s  EXIT: port=%d, cpu=%d, budget=%d, rx_done=%d\n",
 			__func__, pp->port, smp_processor_id(), budget, rx_done);
 	}
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 	if (budget > 0) {
 		causeRxTx = 0;
@@ -3256,7 +3259,7 @@ int mv_eth_poll(struct napi_struct *napi, int budget)
 
 		/* adapt RX coalescing according to packets rate */
 		if (pp->rx_adaptive_coal_cfg)
-			mv_eth_adaptive_rx_update(pp);
+			mv_pp2_adaptive_rx_update(pp);
 
 		/* Enable interrupts for all cpus belong to this group */
 		if (!(pp->flags & MV_ETH_F_IFCAP_NETMAP)) {
@@ -3269,7 +3272,7 @@ int mv_eth_poll(struct napi_struct *napi, int budget)
 	return rx_done;
 }
 
-void mv_eth_port_filtering_cleanup(int port)
+void mv_pp2_port_filtering_cleanup(int port)
 {
 	static bool is_first = true;
 
@@ -3282,36 +3285,36 @@ void mv_eth_port_filtering_cleanup(int port)
 }
 
 
-static MV_STATUS mv_eth_bm_pools_init(void)
+static MV_STATUS mv_pp2_bm_pools_init(void)
 {
 	int i, j;
 	MV_STATUS status;
 
 	/* Create all pools with maximum capacity */
 	for (i = 0; i < MV_ETH_BM_POOLS; i++) {
-		status = mv_eth_pool_create(i, MV_BM_POOL_CAP_MAX);
+		status = mv_pp2_pool_create(i, MV_BM_POOL_CAP_MAX);
 		if (status != MV_OK) {
 			printk(KERN_ERR "%s: can't create bm_pool=%d - capacity=%d\n", __func__, i, MV_BM_POOL_CAP_MAX);
 			for (j = 0; j < i; j++)
-				mv_eth_pool_destroy(j);
+				mv_pp2_pool_destroy(j);
 			return status;
 		}
 
-		mv_eth_pool[i].pkt_size = 0;
-		mv_eth_pool[i].type = MV_ETH_BM_FREE;
+		mv_pp2_pool[i].pkt_size = 0;
+		mv_pp2_pool[i].type = MV_ETH_BM_FREE;
 
 		mvPp2BmPoolBufSizeSet(i, 0);
 	}
 	return 0;
 }
 
-int mv_eth_swf_bm_pool_init(struct eth_port *pp, int mtu)
+int mv_pp2_swf_bm_pool_init(struct eth_port *pp, int mtu)
 {
 	unsigned long flags = 0;
 	int rxq, pkt_size = RX_PKT_SIZE(mtu);
 
 	if (pp->pool_long == NULL) {
-		pp->pool_long = mv_eth_pool_use(MV_ETH_BM_SWF_LONG_POOL(pp->port),
+		pp->pool_long = mv_pp2_pool_use(MV_ETH_BM_SWF_LONG_POOL(pp->port),
 							MV_ETH_BM_SWF_LONG, pkt_size);
 		if (pp->pool_long == NULL)
 			return -1;
@@ -3325,7 +3328,7 @@ int mv_eth_swf_bm_pool_init(struct eth_port *pp, int mtu)
 	}
 
 	if (pp->pool_short == NULL) {
-		pp->pool_short = mv_eth_pool_use(MV_ETH_BM_SWF_SHORT_POOL(pp->port),
+		pp->pool_short = mv_pp2_pool_use(MV_ETH_BM_SWF_SHORT_POOL(pp->port),
 							MV_ETH_BM_SWF_SHORT, MV_ETH_BM_SHORT_PKT_SIZE);
 		if (pp->pool_short == NULL)
 			return -1;
@@ -3341,14 +3344,14 @@ int mv_eth_swf_bm_pool_init(struct eth_port *pp, int mtu)
 	return 0;
 }
 
-#ifdef CONFIG_MV_ETH_HWF
-int mv_eth_hwf_bm_pool_init(struct eth_port *pp, int mtu)
+#ifdef CONFIG_MV_PP2_HWF
+int mv_pp2_hwf_bm_pool_init(struct eth_port *pp, int mtu)
 {
 	unsigned long flags = 0;
 	int pkt_size = RX_PKT_SIZE(mtu);
 
 	if (pp->hwf_pool_long == NULL) {
-		pp->hwf_pool_long = mv_eth_pool_use(MV_ETH_BM_HWF_LONG_POOL(pp->port),
+		pp->hwf_pool_long = mv_pp2_pool_use(MV_ETH_BM_HWF_LONG_POOL(pp->port),
 							MV_ETH_BM_HWF_LONG, pkt_size);
 		if (pp->hwf_pool_long == NULL)
 			return -1;
@@ -3358,12 +3361,12 @@ int mv_eth_hwf_bm_pool_init(struct eth_port *pp, int mtu)
 		MV_ETH_UNLOCK(&pp->hwf_pool_long->lock, flags);
 
 #ifdef CONFIG_MV_ETH_PP2_1
-		mv_eth_hwf_long_pool_attach(pp->port, pp->hwf_pool_long->pool);
+		mv_pp2_hwf_long_pool_attach(pp->port, pp->hwf_pool_long->pool);
 #endif
 	}
 
 	if (pp->hwf_pool_short == NULL) {
-		pp->hwf_pool_short = mv_eth_pool_use(MV_ETH_BM_HWF_SHORT_POOL(pp->port),
+		pp->hwf_pool_short = mv_pp2_pool_use(MV_ETH_BM_HWF_SHORT_POOL(pp->port),
 							MV_ETH_BM_HWF_SHORT, MV_ETH_BM_SHORT_HWF_PKT_SIZE);
 		if (pp->hwf_pool_short == NULL)
 			return -1;
@@ -3373,7 +3376,7 @@ int mv_eth_hwf_bm_pool_init(struct eth_port *pp, int mtu)
 		MV_ETH_UNLOCK(&pp->hwf_pool_short->lock, flags);
 
 #ifdef CONFIG_MV_ETH_PP2_1
-		mv_eth_hwf_short_pool_attach(pp->port, pp->hwf_pool_short->pool);
+		mv_pp2_hwf_short_pool_attach(pp->port, pp->hwf_pool_short->pool);
 #endif
 	}
 
@@ -3383,9 +3386,9 @@ int mv_eth_hwf_bm_pool_init(struct eth_port *pp, int mtu)
 
 	return 0;
 }
-#endif /* CONFIG_MV_ETH_HWF */
+#endif /* CONFIG_MV_PP2_HWF */
 
-static int mv_eth_port_link_speed_fc(int port, MV_ETH_PORT_SPEED port_speed, int en_force)
+static int mv_pp2_port_link_speed_fc(int port, MV_ETH_PORT_SPEED port_speed, int en_force)
 {
 	if (en_force) {
 		if (mvGmacSpeedDuplexSet(port, port_speed, MV_ETH_DUPLEX_FULL)) {
@@ -3417,7 +3420,7 @@ static int mv_eth_port_link_speed_fc(int port, MV_ETH_PORT_SPEED port_speed, int
 	return 0;
 }
 
-static int mv_eth_load_network_interfaces(struct platform_device *pdev)
+static int mv_pp2_load_network_interfaces(struct platform_device *pdev)
 {
 	u32 port;
 	struct eth_port *pp;
@@ -3431,9 +3434,9 @@ static int mv_eth_load_network_interfaces(struct platform_device *pdev)
 	pr_info("  o Loading network interface(s) for port #%d: cpu_mask=0x%x, mtu=%d\n",
 			port, plat_data->cpu_mask, plat_data->mtu);
 
-	mtu = mv_eth_config_get(pdev, mac);
+	mtu = mv_pp2_config_get(pdev, mac);
 
-	dev = mv_eth_netdev_init(mtu, mac, pdev);
+	dev = mv_pp2_netdev_init(mtu, mac, pdev);
 
 	if (dev == NULL) {
 		pr_err("\to %s: can't create netdevice\n", __func__);
@@ -3443,11 +3446,11 @@ static int mv_eth_load_network_interfaces(struct platform_device *pdev)
 	pp = (struct eth_port *)netdev_priv(dev);
 	pp->plat_data = plat_data;
 
-	mv_eth_ports[port] = pp;
+	mv_pp2_ports[port] = pp;
 
-	err = mv_eth_priv_init(pp, port);
+	err = mv_pp2_priv_init(pp, port);
 	if (err) {
-		mv_eth_priv_cleanup(pp);
+		mv_pp2_priv_cleanup(pp);
 		return err;
 	}
 
@@ -3485,44 +3488,44 @@ static int mv_eth_load_network_interfaces(struct platform_device *pdev)
 	}
 
 	/* set port's speed, duplex, fc */
-	if (!MV_PON_PORT(pp->port)) {
+	if (!MV_PP2_IS_PON_PORT(pp->port)) {
 		/* force link, speed and duplex if necessary based on board information */
-		err = mv_eth_port_link_speed_fc(pp->port, speed, force_link);
+		err = mv_pp2_port_link_speed_fc(pp->port, speed, force_link);
 		if (err) {
-			mv_eth_priv_cleanup(pp);
+			mv_pp2_priv_cleanup(pp);
 			return err;
 		}
 	}
 
 	pr_info("\to %s p=%d: phy=%d,  mtu=%d, mac="MV_MACQUAD_FMT", speed=%s %s\n",
-		MV_PON_PORT(port) ? "pon" : "giga", port, plat_data->phy_addr, mtu,
+		MV_PP2_IS_PON_PORT(port) ? "pon" : "giga", port, plat_data->phy_addr, mtu,
 		MV_MACQUAD(mac), mvGmacSpeedStrGet(speed), force_link ? "(force)" : "");
 
-	if (mv_eth_hal_init(pp)) {
+	if (mv_pp2_hal_init(pp)) {
 		pr_err("\to %s: can't init eth hal\n", __func__);
-		mv_eth_priv_cleanup(pp);
+		mv_pp2_priv_cleanup(pp);
 		return -EIO;
 	}
 
-	if (mv_eth_netdev_connect(pp) < 0) {
+	if (mv_pp2_netdev_connect(pp) < 0) {
 		pr_err("\to %s: can't connect to linux\n", __func__);
-		mv_eth_priv_cleanup(pp);
+		mv_pp2_priv_cleanup(pp);
 		return -EIO;
 	}
 
 	/* Default NAPI initialization */
 	/* Create one group for this port, that contains all RXQs and all CPUs - every cpu can process all RXQs */
 	if (pp->flags & MV_ETH_F_CONNECT_LINUX) {
-		if (mv_eth_port_napi_group_create(pp->port, 0))
+		if (mv_pp2_port_napi_group_create(pp->port, 0))
 			return -EIO;
-		if (mv_eth_napi_set_cpu_affinity(pp->port, 0, (1 << CONFIG_NR_CPUS) - 1) ||
-				mv_eth_napi_set_rxq_affinity(pp->port, 0, (1 << MV_ETH_MAX_RXQ) - 1))
+		if (mv_pp2_napi_set_cpu_affinity(pp->port, 0, (1 << CONFIG_NR_CPUS) - 1) ||
+				mv_pp2_eth_napi_set_rxq_affinity(pp->port, 0, (1 << MV_PP2_MAX_RXQ) - 1))
 			return -EIO;
 	}
 
-	if (mv_eth_pnc_ctrl_en) {
+	if (mv_pp2_pnc_ctrl_en) {
 #ifndef CONFIG_MV_ETH_PP2_1
-		mv_eth_tx_mtu_set(port, mtu);
+		mv_pp2_tx_mtu_set(port, mtu);
 #endif /* CONFIG_MV_ETH_PP2_1 */
 
 #ifndef CONFIG_MV_ETH_PP2_1
@@ -3543,11 +3546,11 @@ static int mv_eth_load_network_interfaces(struct platform_device *pdev)
 	mv_pp2_netmap_attach(pp);
 #endif /* CONFIG_NETMAP */
 
-	/* Call mv_eth_open specifically for ports not connected to Linux netdevice */
+	/* Call mv_pp2_open specifically for ports not connected to Linux netdevice */
 	if (!(pp->flags & MV_ETH_F_CONNECT_LINUX))
-		mv_eth_open(pp->dev);
+		mv_pp2_eth_open(pp->dev);
 
-	mux_eth_ops.set_tag_type = mv_eth_tag_type_set;
+	mux_eth_ops.set_tag_type = mv_pp2_tag_type_set;
 	mv_mux_eth_attach(pp->port, pp->dev, &mux_eth_ops);
 
 	pr_info("\n");
@@ -3557,21 +3560,21 @@ static int mv_eth_load_network_interfaces(struct platform_device *pdev)
 
 
 
-int mv_eth_resume_network_interfaces(struct eth_port *pp)
+int mv_pp2_resume_network_interfaces(struct eth_port *pp)
 {
 /* TBD */
 	return 0;
 }
 
 /***********************************************************
- * mv_eth_port_resume                                      *
+ * mv_pp2_port_resume                                      *
  ***********************************************************/
 
-int mv_eth_port_resume(int port)
+int mv_pp2_port_resume(int port)
 {
 	struct eth_port *pp;
 
-	pp = mv_eth_port_by_id(port);
+	pp = mv_pp2_port_by_id(port);
 
 	if (pp == NULL) {
 		pr_err("%s: pp == NULL, port=%d\n", __func__, port);
@@ -3583,7 +3586,7 @@ int mv_eth_port_resume(int port)
 		return MV_ERROR;
 	}
 	if (pp->pm_mode == MV_ETH_PM_WOL) {
-		mv_eth_start_internals(pp, pp->dev->mtu);
+		mv_pp2_start_internals(pp, pp->dev->mtu);
 		mvGmacPortIsrUnmask(port);
 		mvGmacPortSumIsrUnmask(port);
 	}
@@ -3596,7 +3599,7 @@ int mv_eth_port_resume(int port)
 	return MV_OK;
 }
 
-void    mv_eth_hal_shared_init(struct mv_pp2_pdata *plat_data)
+void    mv_pp2_hal_shared_init(struct mv_pp2_pdata *plat_data)
 {
 	MV_PP2_HAL_DATA halData;
 
@@ -3608,7 +3611,7 @@ void    mv_eth_hal_shared_init(struct mv_pp2_pdata *plat_data)
 	halData.iocc = arch_is_coherent();
 	halData.ctrlModel = plat_data->ctrl_model;
 	halData.ctrlRev = plat_data->ctrl_rev;
-	halData.aggrTxqSize = CONFIG_MV_ETH_AGGR_TXQ_SIZE;
+	halData.aggrTxqSize = CONFIG_MV_PP2_AGGR_TXQ_SIZE;
 
 #ifdef CONFIG_MV_INCLUDE_PON
 	halData.maxTcont = CONFIG_MV_PON_TCONTS;
@@ -3621,10 +3624,10 @@ void    mv_eth_hal_shared_init(struct mv_pp2_pdata *plat_data)
 
 
 /***********************************************************
- * mv_eth_win_init --                                      *
+ * mv_pp2_win_init --                                      *
  *   Win initilization                                     *
  ***********************************************************/
-void mv_eth_win_init(void)
+void mv_pp2_win_init(void)
 {
 	const struct mbus_dram_target_info *dram;
 	int i;
@@ -3696,14 +3699,14 @@ void mv_eth_win_init(void)
 
 
 /***********************************************************
- * mv_eth_port_suspend                                     *
+ * mv_pp2_eth_port_suspend                                 *
  *   main driver initialization. loading the interfaces.   *
  ***********************************************************/
-int mv_eth_port_suspend(int port)
+int mv_pp2_eth_port_suspend(int port)
 {
 	struct eth_port *pp;
 
-	pp = mv_eth_port_by_id(port);
+	pp = mv_pp2_port_by_id(port);
 	if (!pp)
 		return MV_OK;
 
@@ -3715,7 +3718,7 @@ int mv_eth_port_suspend(int port)
 	if (pp->flags & MV_ETH_F_STARTED) {
 		if (pp->pm_mode == MV_ETH_PM_WOL) {
 			/* Clean up and disable all interrupts */
-			mv_eth_stop_internals(pp);
+			mv_pp2_stop_internals(pp);
 			mvGmacPortIsrMask(port);
 			mvGmacPortSumIsrMask(port);
 		}
@@ -3730,12 +3733,12 @@ int mv_eth_port_suspend(int port)
 }
 
 /***********************************************************
- * mv_eth_pm_mode_set --                                   *
+ * mv_pp2_pm_mode_set --                                   *
  *   set pm_mode. (power menegment mod)			   *
  ***********************************************************/
-int mv_eth_pm_mode_set(int port, int mode)
+int	mv_pp2_pm_mode_set(int port, int mode)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (pp == NULL) {
 		pr_err("%s: pp == NULL, port=%d\n", __func__, port);
@@ -3752,7 +3755,7 @@ int mv_eth_pm_mode_set(int port, int mode)
 	return MV_OK;
 }
 
-static void mv_eth_sysfs_exit(void)
+static void mv_pp2_sysfs_exit(void)
 {
 	struct device *pd;
 
@@ -3761,7 +3764,7 @@ static void mv_eth_sysfs_exit(void)
 		printk(KERN_ERR"%s: cannot find pp2 device\n", __func__);
 		return;
 	}
-#ifdef CONFIG_MV_ETH_L2FW
+#ifdef CONFIG_MV_PP2_L2FW
 	mv_pp2_l2fw_sysfs_exit(&pd->kobj);
 #endif
 
@@ -3785,7 +3788,7 @@ static void mv_eth_sysfs_exit(void)
 	platform_device_unregister(pp2_sysfs);
 }
 
-static int mv_eth_sysfs_init(void)
+static int mv_pp2_sysfs_init(void)
 {
 	struct device *pd;
 
@@ -3816,33 +3819,33 @@ static int mv_eth_sysfs_init(void)
 	mv_pp2_dpi_sysfs_init(&pd->kobj);
 #endif
 
-#ifdef CONFIG_MV_ETH_L2FW
+#ifdef CONFIG_MV_PP2_L2FW
 	mv_pp2_l2fw_sysfs_init(&pd->kobj);
 #endif
 
 
 	return 0;
 }
-static int	mv_eth_shared_probe(struct mv_pp2_pdata *plat_data)
+static int	mv_pp2_shared_probe(struct mv_pp2_pdata *plat_data)
 {
 	int size, cpu;
 
-	mv_eth_sysfs_init();
+	mv_pp2_sysfs_init();
 
 	/* init MAC Unit */
-	mv_eth_win_init();
+	mv_pp2_win_init();
 
 	/* init MAC Unit */
-	mv_eth_hal_shared_init(plat_data);
+	mv_pp2_hal_shared_init(plat_data);
 
-	mv_eth_config_show();
+	mv_pp2_config_show();
 
-	size = mv_eth_ports_num * sizeof(struct eth_port *);
-	mv_eth_ports = mvOsMalloc(size);
-	if (!mv_eth_ports)
+	size = mv_pp2_ports_num * sizeof(struct eth_port *);
+	mv_pp2_ports = mvOsMalloc(size);
+	if (!mv_pp2_ports)
 		goto oom;
 
-	memset(mv_eth_ports, 0, size);
+	memset(mv_pp2_ports, 0, size);
 
 	/* Allocate aggregated TXQs control */
 	size = CONFIG_NR_CPUS * sizeof(struct aggr_tx_queue);
@@ -3852,23 +3855,23 @@ static int	mv_eth_shared_probe(struct mv_pp2_pdata *plat_data)
 
 	memset(aggr_txqs, 0, size);
 	for_each_possible_cpu(cpu) {
-		aggr_txqs[cpu].txq_size = CONFIG_MV_ETH_AGGR_TXQ_SIZE;
-		aggr_txqs[cpu].q = mvPp2AggrTxqInit(cpu, CONFIG_MV_ETH_AGGR_TXQ_SIZE);
+		aggr_txqs[cpu].txq_size = CONFIG_MV_PP2_AGGR_TXQ_SIZE;
+		aggr_txqs[cpu].q = mvPp2AggrTxqInit(cpu, CONFIG_MV_PP2_AGGR_TXQ_SIZE);
 		if (!aggr_txqs[cpu].q)
 			goto oom;
 	}
 
-#ifdef CONFIG_MV_ETH_HWF
+#ifdef CONFIG_MV_PP2_HWF
 	/* Create temporary TXQ for switching between HWF and SWF */
-	if (mvPp2TxqTempInit(CONFIG_MV_ETH_TEMP_TXQ_SIZE, CONFIG_MV_ETH_TEMP_TXQ_HWF_SIZE) != MV_OK)
+	if (mvPp2TxqTempInit(CONFIG_MV_PP2_TEMP_TXQ_SIZE, CONFIG_MV_PP2_TEMP_TXQ_HWF_SIZE) != MV_OK)
 		goto oom;
 #endif
 
-	if (mv_eth_bm_pools_init())
+	if (mv_pp2_bm_pools_init())
 		goto oom;
 
 	/* Parser default initialization */
-	if (mv_eth_pnc_ctrl_en) {
+	if (mv_pp2_pnc_ctrl_en) {
 		if (mvPrsDefaultInit())
 			printk(KERN_ERR "%s: Warning PARSER default init failed\n", __func__);
 
@@ -3881,20 +3884,20 @@ static int	mv_eth_shared_probe(struct mv_pp2_pdata *plat_data)
 #endif
 
 	/* Initialize tasklet for handle link events */
-	tasklet_init(&link_tasklet, mv_eth_link_tasklet, 0);
+	tasklet_init(&link_tasklet, mv_pp2_link_tasklet, 0);
 
 	/* request IRQ for link interrupts from GOP */
-	if (request_irq(IRQ_GLOBAL_GOP, mv_eth_link_isr, (IRQF_DISABLED), "mv_eth_link", NULL))
+	if (request_irq(IRQ_GLOBAL_GOP, mv_pp2_link_isr, (IRQF_DISABLED), "mv_pp2_link", NULL))
 		printk(KERN_ERR "%s: Could not request IRQ for GOP interrupts\n", __func__);
 
 	mvGmacIsrSummaryUnmask();
 
-	mv_eth_initialized = 1;
+	mv_pp2_initialized = 1;
 	return 0;
 
 oom:
-	if (mv_eth_ports)
-		mvOsFree(mv_eth_ports);
+	if (mv_pp2_ports)
+		mvOsFree(mv_pp2_ports);
 
 	if (aggr_txqs)
 		mvOsFree(aggr_txqs);
@@ -3903,7 +3906,7 @@ oom:
 	return -ENOMEM;
 }
 
-static void mv_eth_shared_cleanup(void)
+static void mv_pp2_shared_cleanup(void)
 {
 	int pool, cpu;
 
@@ -3913,9 +3916,9 @@ static void mv_eth_shared_cleanup(void)
 	*/
 
 	for (pool = 0; pool < MV_ETH_BM_POOLS; pool++)
-		mv_eth_pool_destroy(pool);
+		mv_pp2_pool_destroy(pool);
 
-#ifdef CONFIG_MV_ETH_HWF
+#ifdef CONFIG_MV_PP2_HWF
 	/* Delete temporary TXQ (switching between HWF and SWF)*/
 	mvPp2TxqTempDelete();
 #endif
@@ -3925,36 +3928,36 @@ static void mv_eth_shared_cleanup(void)
 
 	mvOsFree(aggr_txqs);
 
-	mvOsFree(mv_eth_ports);
+	mvOsFree(mv_pp2_ports);
 
-	/* Hal init by mv_eth_hal_shared_init*/
+	/* Hal init by mv_pp2_hal_shared_init*/
 	mvPp2HalDestroy();
 
-	/*mv_eth_win_cleanup();*/
+	/*mv_pp2_win_cleanup();*/
 
-	mv_eth_sysfs_exit();
+	mv_pp2_sysfs_exit();
 
-	mv_eth_initialized = 0;
+	mv_pp2_initialized = 0;
 }
 
 /***********************************************************
- * mv_eth_probe --                                         *
+ * mv_pp2_eth_probe --                                         *
  *   main driver initialization. loading the interfaces.   *
  ***********************************************************/
-static int mv_eth_probe(struct platform_device *pdev)
+static int mv_pp2_eth_probe(struct platform_device *pdev)
 {
 	struct mv_pp2_pdata *plat_data = (struct mv_pp2_pdata *)pdev->dev.platform_data;
 	int phyAddr, is_sgmii, is_rgmii, port = pdev->id;
 
-	if (!mv_eth_initialized) {
+	if (!mv_pp2_initialized) {
 
-		mv_eth_ports_num = plat_data->max_port;
+		mv_pp2_ports_num = plat_data->max_port;
 
-		if (mv_eth_shared_probe(plat_data))
+		if (mv_pp2_shared_probe(plat_data))
 			return -ENODEV;
 	}
 
-	if (!MV_PON_PORT(port)) {
+	if (!MV_PP2_IS_PON_PORT(port)) {
 		/* First: Disable Gmac */
 		mvGmacPortDisable(port);
 
@@ -3976,7 +3979,7 @@ static int mv_eth_probe(struct platform_device *pdev)
 		mvGmacPortSumIsrUnmask(port);
 	}
 
-	if (mv_eth_load_network_interfaces(pdev))
+	if (mv_pp2_load_network_interfaces(pdev))
 		return -ENODEV;
 
 #ifdef CONFIG_CPU_IDLE
@@ -3988,14 +3991,14 @@ static int mv_eth_probe(struct platform_device *pdev)
 			wol_isr_register++;
 	}
 #endif
-	/* used in mv_eth_all_ports_probe */
+	/* used in mv_pp2_all_ports_probe */
 	plats[port] = pdev;
 
 	return 0;
 }
 
 
-static int mv_eth_config_get(struct platform_device *pdev, MV_U8 *mac_addr)
+static int mv_pp2_config_get(struct platform_device *pdev, MV_U8 *mac_addr)
 {
 	struct mv_pp2_pdata *plat_data = (struct mv_pp2_pdata *)pdev->dev.platform_data;
 
@@ -4006,16 +4009,16 @@ static int mv_eth_config_get(struct platform_device *pdev, MV_U8 *mac_addr)
 }
 
 /***********************************************************
- * mv_eth_tx_timeout --                                    *
+ * mv_pp2_tx_timeout --                                    *
  *   nothing to be done (?)                                *
  ***********************************************************/
-static void mv_eth_tx_timeout(struct net_device *dev)
+static void mv_pp2_tx_timeout(struct net_device *dev)
 {
-#ifdef CONFIG_MV_ETH_STAT_ERR
+#ifdef CONFIG_MV_PP2_STAT_ERR
 	struct eth_port *pp = MV_ETH_PRIV(dev);
 
 	pp->stats.tx_timeout++;
-#endif /* #ifdef CONFIG_MV_ETH_STAT_ERR */
+#endif /* #ifdef CONFIG_MV_PP2_STAT_ERR */
 
 	printk(KERN_INFO "%s: tx timeout\n", dev->name);
 }
@@ -4024,13 +4027,13 @@ static void mv_eth_tx_timeout(struct net_device *dev)
  * mv_eth_netdev_init -- Allocate and initialize net_device    *
  *                   structure                                 *
  ***************************************************************/
-struct net_device *mv_eth_netdev_init(int mtu, u8 *mac, struct platform_device *pdev)
+struct net_device *mv_pp2_netdev_init(int mtu, u8 *mac, struct platform_device *pdev)
 {
 	struct net_device *dev;
 	struct eth_port *dev_priv;
 	struct resource *res;
 
-	dev = alloc_etherdev_mq(sizeof(struct eth_port), CONFIG_MV_ETH_TXQ);
+	dev = alloc_etherdev_mq(sizeof(struct eth_port), CONFIG_MV_PP2_TXQ);
 	if (!dev)
 		return NULL;
 
@@ -4049,15 +4052,15 @@ struct net_device *mv_eth_netdev_init(int mtu, u8 *mac, struct platform_device *
 	dev->mtu = mtu;
 	memcpy(dev->dev_addr, mac, MV_MAC_ADDR_SIZE);
 	memcpy(dev->perm_addr, mac, MV_MAC_ADDR_SIZE);
-	dev->tx_queue_len = CONFIG_MV_ETH_TXQ_DESC;
+	dev->tx_queue_len = CONFIG_MV_PP2_TXQ_DESC;
 	dev->watchdog_timeo = 5 * HZ;
 
-	if (MV_PON_PORT(dev_priv->port))
+	if (MV_PP2_IS_PON_PORT(dev_priv->port))
 		dev->hard_header_len += MV_ETH_MH_SIZE;
 
-	dev->netdev_ops = &mv_eth_netdev_ops;
+	dev->netdev_ops = &mv_pp2_netdev_ops;
 
-	SET_ETHTOOL_OPS(dev, &mv_eth_tool_ops);
+	SET_ETHTOOL_OPS(dev, &mv_pp2_eth_tool_ops);
 
 	SET_NETDEV_DEV(dev, &pdev->dev);
 
@@ -4066,9 +4069,9 @@ struct net_device *mv_eth_netdev_init(int mtu, u8 *mac, struct platform_device *
 }
 
 /***************************************************************
- * mv_eth_netdev_connect -- Connect device to linux            *
+ * mv_pp2_netdev_connect -- Connect device to linux            *
 ***************************************************************/
-static int mv_eth_netdev_connect(struct eth_port *pp)
+static int mv_pp2_netdev_connect(struct eth_port *pp)
 {
 	struct net_device *dev;
 	struct cpu_ctrl	*cpuCtrl;
@@ -4087,7 +4090,7 @@ static int mv_eth_netdev_connect(struct eth_port *pp)
 	}
 
 	if (pp->flags & MV_ETH_F_CONNECT_LINUX) {
-		mv_eth_netdev_init_features(pp->dev);
+		mv_pp2_netdev_init_features(pp->dev);
 		if (register_netdev(dev)) {
 			pr_err("\to failed to register %s\n", dev->name);
 			free_netdev(dev);
@@ -4099,24 +4102,24 @@ static int mv_eth_netdev_connect(struct eth_port *pp)
 	return MV_OK;
 }
 
-bool mv_eth_netdev_find(unsigned int dev_idx)
+bool mv_pp2_eth_netdev_find(unsigned int dev_idx)
 {
 	int port;
 
-	for (port = 0; port < mv_eth_ports_num; port++) {
-		struct eth_port *pp = mv_eth_port_by_id(port);
+	for (port = 0; port < mv_pp2_ports_num; port++) {
+		struct eth_port *pp = mv_pp2_port_by_id(port);
 
 		if (pp && pp->dev && (pp->dev->ifindex == dev_idx))
 			return true;
 	}
 	return false;
 }
-EXPORT_SYMBOL(mv_eth_netdev_find);
+EXPORT_SYMBOL(mv_pp2_eth_netdev_find);
 
 
-int mv_eth_hal_init(struct eth_port *pp)
+int mv_pp2_hal_init(struct eth_port *pp)
 {
-	int rxq, txp, txq, size;
+	int rxq, txp, txq, size, cpu;
 	struct tx_queue *txq_ctrl;
 	struct rx_queue *rxq_ctrl;
 
@@ -4127,7 +4130,7 @@ int mv_eth_hal_init(struct eth_port *pp)
 		return -ENODEV;
 	}
 
-	size = pp->txp_num * CONFIG_MV_ETH_TXQ * sizeof(struct tx_queue);
+	size = pp->txp_num * CONFIG_MV_PP2_TXQ * sizeof(struct tx_queue);
 	pp->txq_ctrl = mvOsMalloc(size);
 	if (!pp->txq_ctrl)
 		goto oom;
@@ -4136,14 +4139,14 @@ int mv_eth_hal_init(struct eth_port *pp)
 
 	/* Create TX descriptor rings */
 	for (txp = 0; txp < pp->txp_num; txp++) {
-		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++) {
-			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+		for (txq = 0; txq < CONFIG_MV_PP2_TXQ; txq++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + txq];
 
 			txq_ctrl->txp = txp;
 			txq_ctrl->txq = txq;
-			txq_ctrl->txq_done_pkts_coal = mv_ctrl_txdone;
+			txq_ctrl->txq_done_pkts_coal = mv_ctrl_pp2_txdone;
 
-			mv_pp2_txq_size_set(txq_ctrl, CONFIG_MV_ETH_TXQ_DESC);
+			mv_pp2_txq_size_set(txq_ctrl, CONFIG_MV_PP2_TXQ_DESC);
 		}
 	}
 
@@ -4156,9 +4159,9 @@ int mv_eth_hal_init(struct eth_port *pp)
 	/* Create Rx descriptor rings */
 	for (rxq = 0; rxq < pp->rxq_num; rxq++) {
 		rxq_ctrl = &pp->rxq_ctrl[rxq];
-		rxq_ctrl->rxq_size = CONFIG_MV_ETH_RXQ_DESC;
-		rxq_ctrl->rxq_pkts_coal = CONFIG_MV_ETH_RX_COAL_PKTS;
-		rxq_ctrl->rxq_time_coal = CONFIG_MV_ETH_RX_COAL_USEC;
+		rxq_ctrl->rxq_size = CONFIG_MV_PP2_RXQ_DESC;
+		rxq_ctrl->rxq_pkts_coal = CONFIG_MV_PP2_RX_COAL_PKTS;
+		rxq_ctrl->rxq_time_coal = CONFIG_MV_PP2_RX_COAL_USEC;
 	}
 
 	if (pp->tx_spec.flags & MV_ETH_TX_F_MH)
@@ -4169,13 +4172,13 @@ int mv_eth_hal_init(struct eth_port *pp)
 	pp->speed_cfg = SPEED_1000;
 	pp->duplex_cfg = DUPLEX_FULL;
 	pp->advertise_cfg = 0x2f;
-	pp->rx_time_coal_cfg = CONFIG_MV_ETH_RX_COAL_USEC;
-	pp->rx_pkts_coal_cfg = CONFIG_MV_ETH_RX_COAL_PKTS;
-	pp->tx_pkts_coal_cfg = mv_ctrl_txdone;
-	pp->rx_time_low_coal_cfg = CONFIG_MV_ETH_RX_COAL_USEC >> 2;
-	pp->rx_time_high_coal_cfg = CONFIG_MV_ETH_RX_COAL_USEC << 2;
-	pp->rx_pkts_low_coal_cfg = CONFIG_MV_ETH_RX_COAL_PKTS;
-	pp->rx_pkts_high_coal_cfg = CONFIG_MV_ETH_RX_COAL_PKTS;
+	pp->rx_time_coal_cfg = CONFIG_MV_PP2_RX_COAL_USEC;
+	pp->rx_pkts_coal_cfg = CONFIG_MV_PP2_RX_COAL_PKTS;
+	pp->tx_pkts_coal_cfg = mv_ctrl_pp2_txdone;
+	pp->rx_time_low_coal_cfg = CONFIG_MV_PP2_RX_COAL_USEC >> 2;
+	pp->rx_time_high_coal_cfg = CONFIG_MV_PP2_RX_COAL_USEC << 2;
+	pp->rx_pkts_low_coal_cfg = CONFIG_MV_PP2_RX_COAL_PKTS;
+	pp->rx_pkts_high_coal_cfg = CONFIG_MV_PP2_RX_COAL_PKTS;
 	pp->pkt_rate_low_cfg = 1000;
 	pp->pkt_rate_high_cfg = 50000;
 	pp->rate_sample_cfg = 5;
@@ -4188,7 +4191,7 @@ oom:
 }
 
 /* Show network driver configuration */
-void mv_eth_config_show(void)
+void mv_pp2_config_show(void)
 {
 #ifdef CONFIG_MV_ETH_PP2_1
 	pr_info("  o	PPv2.1 Giga driver\n");
@@ -4196,67 +4199,67 @@ void mv_eth_config_show(void)
 	pr_info("  o	PPv2.0 Giga driver\n");
 #endif
 
-	printk(KERN_ERR "  o %d Giga ports supported\n", mv_eth_ports_num);
+	pr_info("  o %d Giga ports supported\n", mv_pp2_ports_num);
 
 #ifdef CONFIG_MV_INCLUDE_PON
-	printk(KERN_ERR "  o xPON port is #%d: - %d of %d TCONTs supported\n",
-		MV_PON_LOGIC_PORT_GET(), CONFIG_MV_PON_TCONTS, MV_ETH_MAX_TCONT);
+	pr_info("  o xPON port is #%d: - %d of %d TCONTs supported\n",
+		MV_PON_LOGIC_PORT_GET(), CONFIG_MV_PON_TCONTS, MV_PP2_MAX_TCONT);
 #endif
 
-#ifdef CONFIG_NET_SKB_RECYCLE
-	printk(KERN_ERR "  o SKB recycle supported (%s)\n", mv_ctrl_recycle ? "Enabled" : "Disabled");
+#ifdef CONFIG_MV_PP2_SKB_RECYCLE
+	pr_info("  o SKB recycle supported (%s)\n", mv_ctrl_pp2_recycle ? "Enabled" : "Disabled");
 #endif
 
-	printk(KERN_ERR "  o BM supported for CPU: %d BM pools\n", MV_ETH_BM_POOLS);
+	pr_info("  o BM supported for CPU: %d BM pools\n", MV_ETH_BM_POOLS);
 
-#ifdef CONFIG_MV_ETH_HWF
-	printk(KERN_ERR "  o HWF supported\n");
+#ifdef CONFIG_MV_PP2_HWF
+	pr_info("  o HWF supported\n");
 #endif
 
 #ifdef CONFIG_MV_ETH_PMT
-	printk(KERN_ERR "  o PME supported\n");
+	pr_info("  o PME supported\n");
 #endif
 
-	printk(KERN_ERR "  o RX Queue support: %d Queues * %d Descriptors\n", CONFIG_MV_ETH_RXQ, CONFIG_MV_ETH_RXQ_DESC);
+	pr_info("  o RX Queue support: %d Queues * %d Descriptors\n", CONFIG_MV_PP2_RXQ, CONFIG_MV_PP2_RXQ_DESC);
 
-	printk(KERN_ERR "  o TX Queue support: %d Queues * %d Descriptors\n", CONFIG_MV_ETH_TXQ, CONFIG_MV_ETH_TXQ_DESC);
+	pr_info("  o TX Queue support: %d Queues * %d Descriptors\n", CONFIG_MV_PP2_TXQ, CONFIG_MV_PP2_TXQ_DESC);
 
-#if defined(CONFIG_MV_ETH_TSO)
-	printk(KERN_ERR "  o GSO supported\n");
-#endif /* CONFIG_MV_ETH_TSO */
+#if defined(CONFIG_MV_PP2_TSO)
+	pr_info("  o GSO supported\n");
+#endif /* CONFIG_MV_PP2_TSO */
 
 #if defined(CONFIG_MV_ETH_RX_CSUM_OFFLOAD)
-	printk(KERN_ERR "  o Receive checksum offload supported\n");
+	pr_info("  o Receive checksum offload supported\n");
 #endif
 #if defined(CONFIG_MV_ETH_TX_CSUM_OFFLOAD)
-	printk(KERN_ERR "  o Transmit checksum offload supported\n");
+	pr_info("  o Transmit checksum offload supported\n");
 #endif
 
-#ifdef CONFIG_MV_ETH_STAT_ERR
-	printk(KERN_ERR "  o Driver ERROR statistics enabled\n");
+#ifdef CONFIG_MV_PP2_STAT_ERR
+	pr_info("  o Driver ERROR statistics enabled\n");
 #endif
 
-#ifdef CONFIG_MV_ETH_STAT_INF
-	printk(KERN_ERR "  o Driver INFO statistics enabled\n");
+#ifdef CONFIG_MV_PP2_STAT_INF
+	pr_info("  o Driver INFO statistics enabled\n");
 #endif
 
-#ifdef CONFIG_MV_ETH_STAT_DBG
-	printk(KERN_ERR "  o Driver DEBUG statistics enabled\n");
+#ifdef CONFIG_MV_PP2_STAT_DBG
+	pr_info("  o Driver DEBUG statistics enabled\n");
 #endif
 
 #ifdef ETH_DEBUG
-	printk(KERN_ERR "  o Driver debug messages enabled\n");
+	pr_info("  o Driver debug messages enabled\n");
 #endif
 
 #if defined(CONFIG_MV_INCLUDE_SWITCH)
-	printk(KERN_ERR "  o Switch support enabled\n");
+	pr_info("  o Switch support enabled\n");
 #endif /* CONFIG_MV_INCLUDE_SWITCH */
 
-	printk(KERN_ERR "\n");
+	pr_info("\n");
 }
 
 /* Set network device features on initialization. Take into account default compile time configuration. */
-void mv_eth_netdev_init_features(struct net_device *dev)
+void mv_pp2_netdev_init_features(struct net_device *dev)
 {
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 39)
 	dev->features = NETIF_F_RXCSUM | NETIF_F_IP_CSUM | NETIF_F_SG | NETIF_F_LLTX;
@@ -4267,7 +4270,7 @@ void mv_eth_netdev_init_features(struct net_device *dev)
 	dev->hw_features = NETIF_F_GRO | NETIF_F_RXCSUM | NETIF_F_IP_CSUM | NETIF_F_SG;
 #endif
 
-#ifdef CONFIG_MV_ETH_TSO
+#ifdef CONFIG_MV_PP2_TSO
 	dev->features |= NETIF_F_TSO;
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 39)
 	dev->hw_features |= NETIF_F_TSO;
@@ -4276,38 +4279,38 @@ void mv_eth_netdev_init_features(struct net_device *dev)
 }
 
 #if LINUX_VERSION_CODE < KERNEL_VERSION(3, 4, 25)
-static u32 mv_eth_netdev_fix_features(struct net_device *dev, u32 features)
+static u32 mv_pp2_netdev_fix_features(struct net_device *dev, u32 features)
 {
-	if (dev->mtu > MV_ETH_TX_CSUM_MAX_SIZE)
+	if (dev->mtu > MV_PP2_TX_CSUM_MAX_SIZE)
 		if (features & (NETIF_F_IP_CSUM | NETIF_F_TSO)) {
 			features &= ~(NETIF_F_IP_CSUM | NETIF_F_TSO);
 			printk(KERN_ERR "%s: NETIF_F_IP_CSUM and NETIF_F_TSO not supported for mtu larger %d bytes\n",
-				dev->name, MV_ETH_TX_CSUM_MAX_SIZE);
+				dev->name, MV_PP2_TX_CSUM_MAX_SIZE);
 		}
 
 	return features;
 }
 #else
-static netdev_features_t mv_eth_netdev_fix_features(struct net_device *dev, netdev_features_t features)
+static netdev_features_t mv_pp2_netdev_fix_features(struct net_device *dev, netdev_features_t features)
 {
-	if (dev->mtu > MV_ETH_TX_CSUM_MAX_SIZE)
+	if (dev->mtu > MV_PP2_TX_CSUM_MAX_SIZE)
 		if (features & (NETIF_F_IP_CSUM | NETIF_F_TSO)) {
 			features &= ~(NETIF_F_IP_CSUM | NETIF_F_TSO);
 			printk(KERN_ERR "%s: NETIF_F_IP_CSUM and NETIF_F_TSO not supported for mtu larger %d bytes\n",
-				dev->name, MV_ETH_TX_CSUM_MAX_SIZE);
+				dev->name, MV_PP2_TX_CSUM_MAX_SIZE);
 		}
 
 	return features;
 }
 #endif
 
-static int mv_eth_rxq_fill(struct eth_port *pp, int rxq, int num)
+static int mv_pp2_rxq_fill(struct eth_port *pp, int rxq, int num)
 {
 	mvPp2RxqNonOccupDescAdd(pp->port, rxq, num);
 	return num;
 }
 
-static int mv_eth_txq_create(struct eth_port *pp, struct tx_queue *txq_ctrl)
+static int mv_pp2_txq_create(struct eth_port *pp, struct tx_queue *txq_ctrl)
 {
 	int cpu;
 	struct txq_cpu_ctrl *txq_cpu_ptr;
@@ -4338,12 +4341,12 @@ static int mv_eth_txq_create(struct eth_port *pp, struct tx_queue *txq_ctrl)
 	return 0;
 
 no_mem:
-	mv_eth_txq_delete(pp, txq_ctrl);
+	mv_pp2_txq_delete(pp, txq_ctrl);
 	return -ENOMEM;
 }
 
 
-static void mv_eth_txq_delete(struct eth_port *pp, struct tx_queue *txq_ctrl)
+static void mv_pp2_txq_delete(struct eth_port *pp, struct tx_queue *txq_ctrl)
 {
 	int cpu;
 	struct txq_cpu_ctrl *txq_cpu_ptr;
@@ -4362,7 +4365,7 @@ static void mv_eth_txq_delete(struct eth_port *pp, struct tx_queue *txq_ctrl)
 	}
 }
 
-int mv_eth_txq_clean(int port, int txp, int txq)
+int mv_pp2_txq_clean(int port, int txp, int txq)
 {
 	struct eth_port *pp;
 	struct tx_queue *txq_ctrl;
@@ -4372,14 +4375,14 @@ int mv_eth_txq_clean(int port, int txp, int txq)
 	if (mvPp2TxpCheck(port, txp))
 		return -EINVAL;
 
-	pp = mv_eth_port_by_id(port);
+	pp = mv_pp2_port_by_id(port);
 	if ((pp == NULL) || (pp->txq_ctrl == NULL))
 		return -ENODEV;
 
-	if (mvPp2MaxCheck(txq, CONFIG_MV_ETH_TXQ, "txq"))
+	if (mvPp2MaxCheck(txq, CONFIG_MV_PP2_TXQ, "txq"))
 		return -EINVAL;
 
-	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + txq];
 	if (txq_ctrl->q) {
 		/* Enable TXQ drain */
 		mvPp2TxqDrainSet(port, txp, txq, MV_TRUE);
@@ -4403,13 +4406,13 @@ int mv_eth_txq_clean(int port, int txp, int txq)
 
 		/* release all transmitted packets */
 
-		tx_done = mv_eth_txq_done(pp, txq_ctrl);
+		tx_done = mv_pp2_txq_done(pp, txq_ctrl);
 		if (tx_done > 0)
 			mvOsPrintf(KERN_INFO "%s: port=%d, txp=%d txq=%d: Free %d transmitted descriptors\n",
 				__func__, port, txp, txq, tx_done);
 
 		/* release all untransmitted packets */
-		tx_done = mv_eth_txq_done_force(pp, txq_ctrl);
+		tx_done = mv_pp2_txq_done_force(pp, txq_ctrl);
 		if (tx_done > 0)
 			mvOsPrintf(KERN_INFO "%s: port=%d, txp=%d txq=%d: Free %d untransmitted descriptors\n",
 				__func__, port, txp, txq, tx_done);
@@ -4426,7 +4429,7 @@ int mv_eth_txq_clean(int port, int txp, int txq)
 }
 
 /* Free all packets pending transmit from all TXQs and reset TX port */
-int mv_eth_txp_clean(int port, int txp)
+int mv_pp2_txp_clean(int port, int txp)
 {
 	struct eth_port *pp;
 	int txq;
@@ -4434,7 +4437,7 @@ int mv_eth_txp_clean(int port, int txp)
 	if (mvPp2TxpCheck(port, txp))
 		return -EINVAL;
 
-	pp = mv_eth_port_by_id(port);
+	pp = mv_pp2_port_by_id(port);
 	if ((pp == NULL) || (pp->txq_ctrl == NULL))
 		return -ENODEV;
 
@@ -4447,8 +4450,8 @@ int mv_eth_txp_clean(int port, int txp)
 	mvPp2TxPortFifoFlush(port, MV_TRUE);
 
 	/* free the skb's in the hal tx ring */
-	for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++)
-		mv_eth_txq_clean(port, txp, txq);
+	for (txq = 0; txq < CONFIG_MV_PP2_TXQ; txq++)
+		mv_pp2_txq_clean(port, txp, txq);
 
 	mvPp2TxPortFifoFlush(port, MV_FALSE);
 
@@ -4456,9 +4459,9 @@ int mv_eth_txp_clean(int port, int txp)
 }
 
 /* Free received packets from all RXQs and reset RX of the port */
-int mv_eth_rx_reset(int port)
+int mv_pp2_rx_reset(int port)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (pp->flags & MV_ETH_F_STARTED) {
 		printk(KERN_ERR "Port %d must be stopped before\n", port);
@@ -4472,20 +4475,20 @@ int mv_eth_rx_reset(int port)
 /***********************************************************
  * coal set functions		                           *
  ***********************************************************/
-MV_STATUS mv_eth_rx_ptks_coal_set(int port, int rxq, MV_U32 value)
+MV_STATUS mv_pp2_rx_ptks_coal_set(int port, int rxq, MV_U32 value)
 {
 	MV_STATUS status = mvPp2RxqPktsCoalSet(port, rxq, value);
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	if (status == MV_OK)
 		pp->rxq_ctrl[rxq].rxq_pkts_coal = value;
 	return status;
 }
 
-MV_STATUS mv_eth_rx_time_coal_set(int port, int rxq, MV_U32 value)
+MV_STATUS mv_pp2_rx_time_coal_set(int port, int rxq, MV_U32 value)
 {
 
 	MV_STATUS status = mvPp2RxqTimeCoalSet(port, rxq, value);
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	if (status == MV_OK)
 		pp->rxq_ctrl[rxq].rxq_time_coal = value;
 	return status;
@@ -4493,17 +4496,17 @@ MV_STATUS mv_eth_rx_time_coal_set(int port, int rxq, MV_U32 value)
 	return  MV_OK;
 }
 
-MV_STATUS mv_eth_tx_done_ptks_coal_set(int port, int txp, int txq, MV_U32 value)
+MV_STATUS mv_pp2_tx_done_ptks_coal_set(int port, int txp, int txq, MV_U32 value)
 {
 	MV_STATUS status = mvPp2TxDonePktsCoalSet(port, txp, txq, value);
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	if (status == MV_OK)
-		pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq].txq_done_pkts_coal = value;
+		pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + txq].txq_done_pkts_coal = value;
 	return status;
 }
 
 /***********************************************************
-* mv_eth_start_internals --                               *
+* mv_pp2_start_internals --                               *
 *   fill rx buffers. start rx/tx activity. set coalesing. *
 *   clear and unmask interrupt bits                       *
 *   -   RX and TX init
@@ -4514,7 +4517,7 @@ MV_STATUS mv_eth_tx_done_ptks_coal_set(int port, int txp, int txq, MV_U32 value)
 *   -   SW start tx (wake_up _all_queues)
 *   -   HW start rx
 ***********************************************************/
-int mv_eth_start_internals(struct eth_port *pp, int mtu)
+int mv_pp2_start_internals(struct eth_port *pp, int mtu)
 {
 	int rxq, txp, txq, err = 0;
 
@@ -4525,21 +4528,21 @@ int mv_eth_start_internals(struct eth_port *pp, int mtu)
 		goto out;
 	}
 
-	if (!MV_PON_PORT(pp->port))
+	if (!MV_PP2_IS_PON_PORT(pp->port))
 		mvGmacMaxRxSizeSet(pp->port, RX_PKT_SIZE(mtu));
 #ifdef CONFIG_MV_INCLUDE_PON
 	else
 		mv_pon_mtu_config(RX_PKT_SIZE(mtu));
 #endif
 
-	err = mv_eth_swf_bm_pool_init(pp, mtu);
+	err = mv_pp2_swf_bm_pool_init(pp, mtu);
 	if (err)
 		goto out;
-#ifdef CONFIG_MV_ETH_HWF
-	err = mv_eth_hwf_bm_pool_init(pp, mtu);
+#ifdef CONFIG_MV_PP2_HWF
+	err = mv_pp2_hwf_bm_pool_init(pp, mtu);
 	if (err)
 		goto out;
-#endif /* CONFIG_MV_ETH_HWF */
+#endif /* CONFIG_MV_PP2_HWF */
 
 
 	for (rxq = 0; rxq < pp->rxq_num; rxq++) {
@@ -4557,12 +4560,12 @@ int mv_eth_start_internals(struct eth_port *pp, int mtu)
 		}
 
 		/* Set coalescing pkts and time */
-		mv_eth_rx_ptks_coal_set(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_pkts_coal);
-		mv_eth_rx_time_coal_set(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_time_coal);
+		mv_pp2_rx_ptks_coal_set(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_pkts_coal);
+		mv_pp2_rx_time_coal_set(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_time_coal);
 
 		if (!(pp->flags & MV_ETH_F_IFCAP_NETMAP)) {
 			if (mvPp2RxqFreeDescNumGet(pp->port, rxq) == 0)
-				mv_eth_rxq_fill(pp, rxq, pp->rxq_ctrl[rxq].rxq_size);
+				mv_pp2_rxq_fill(pp, rxq, pp->rxq_ctrl[rxq].rxq_size);
 		} else {
 			/*printk(KERN_ERR "%s :: run with netmap enable", __func__);*/
 			mvPp2RxqNonOccupDescAdd(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_size);
@@ -4574,18 +4577,18 @@ int mv_eth_start_internals(struct eth_port *pp, int mtu)
 	}
 
 	for (txp = 0; txp < pp->txp_num; txp++) {
-		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++) {
-			struct tx_queue *txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+		for (txq = 0; txq < CONFIG_MV_PP2_TXQ; txq++) {
+			struct tx_queue *txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + txq];
 
 			if ((txq_ctrl->q == NULL) && (txq_ctrl->txq_size > 0)) {
-				err = mv_eth_txq_create(pp, txq_ctrl);
+				err = mv_pp2_txq_create(pp, txq_ctrl);
 				if (err)
 					goto out;
 				spin_lock_init(&txq_ctrl->queue_lock);
 			}
-#ifdef CONFIG_MV_ETH_TXDONE_ISR
-			mv_eth_tx_done_ptks_coal_set(pp->port, txp, txq, txq_ctrl->txq_done_pkts_coal);
-#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+#ifdef CONFIG_MV_PP2_TXDONE_ISR
+			mv_pp2_tx_done_ptks_coal_set(pp->port, txp, txq, txq_ctrl->txq_done_pkts_coal);
+#endif /* CONFIG_MV_PP2_TXDONE_ISR */
 #ifdef CONFIG_NETMAP
 		if (pp->flags & MV_ETH_F_IFCAP_NETMAP) {
 			if (pp2_netmap_txq_init_buffers(pp, txp, txq))
@@ -4604,14 +4607,14 @@ int mv_eth_start_internals(struct eth_port *pp, int mtu)
 
 
 
-int mv_eth_resume_internals(struct eth_port *pp, int mtu)
+int mv_pp2_eth_resume_internals(struct eth_port *pp, int mtu)
 {
 /* TBD */
 	return 0;
 }
 
 
-int mv_eth_restore_registers(struct eth_port *pp, int mtu)
+int mv_pp2_restore_registers(struct eth_port *pp, int mtu)
 {
 /* TBD */
 	return 0;
@@ -4619,10 +4622,10 @@ int mv_eth_restore_registers(struct eth_port *pp, int mtu)
 
 
 /***********************************************************
- * mv_eth_suspend_internals --                                *
+ * mv_pp2_eth_suspend_internals --                                *
  *   stop port rx/tx activity. free skb's from rx/tx rings.*
  ***********************************************************/
-int mv_eth_suspend_internals(struct eth_port *pp)
+int mv_pp2_eth_suspend_internals(struct eth_port *pp)
 {
 /* TBD */
 	return 0;
@@ -4630,7 +4633,7 @@ int mv_eth_suspend_internals(struct eth_port *pp)
 
 
 /***********************************************************
-* mv_eth_stop_internals --                                *
+* mv_pp2_stop_internals --                                *
 *   -   HW stop rx
 *   -   SW stop tx (tx_stop_all_queues)
 *   -   Disable interrupts
@@ -4639,7 +4642,7 @@ int mv_eth_suspend_internals(struct eth_port *pp)
 *   -   HW disable port
 *   -   RX and TX cleanups
 ***********************************************************/
-int mv_eth_stop_internals(struct eth_port *pp)
+int mv_pp2_stop_internals(struct eth_port *pp)
 {
 	int queue, txp;
 
@@ -4653,12 +4656,12 @@ int mv_eth_stop_internals(struct eth_port *pp)
 
 	/* Transmit and free all packets */
 	for (txp = 0; txp < pp->txp_num; txp++)
-		mv_eth_txp_clean(pp->port, txp);
+		mv_pp2_txp_clean(pp->port, txp);
 
 
 	/* free the skb's in the hal rx ring */
 	for (queue = 0; queue < pp->rxq_num; queue++)
-		mv_eth_rxq_drop_pkts(pp, queue);
+		mv_pp2_rxq_drop_pkts(pp, queue);
 
 	return 0;
 
@@ -4668,7 +4671,7 @@ error:
 }
 
 /* return positive if MTU is valid */
-int mv_eth_check_mtu_valid(struct net_device *dev, int mtu)
+int mv_pp2_eth_check_mtu_valid(struct net_device *dev, int mtu)
 {
 	if (mtu < 68) {
 		printk(KERN_INFO "MTU must be at least 68, change mtu failed\n");
@@ -4689,7 +4692,7 @@ int mv_eth_check_mtu_valid(struct net_device *dev, int mtu)
 }
 
 /* Check if MTU can be changed */
-int mv_eth_check_mtu_internals(struct net_device *dev, int mtu)
+int mv_pp2_check_mtu_internals(struct net_device *dev, int mtu)
 {
 	struct eth_port *pp = MV_ETH_PRIV(dev);
 	struct bm_pool *port_pool;
@@ -4710,12 +4713,12 @@ int mv_eth_check_mtu_internals(struct net_device *dev, int mtu)
 }
 
 /***********************************************************
- * mv_eth_change_mtu_internals --                          *
+ * mv_pp2_eth_change_mtu_internals --                      *
  *   stop port activity. release skb from rings. set new   *
  *   mtu in device and hw. restart port activity and       *
  *   and fill rx-buiffers with size according to new mtu.  *
  ***********************************************************/
-int mv_eth_change_mtu_internals(struct net_device *dev, int mtu)
+int mv_pp2_eth_change_mtu_internals(struct net_device *dev, int mtu)
 {
 	struct bm_pool *port_pool;
 	struct eth_port *pp = MV_ETH_PRIV(dev);
@@ -4724,7 +4727,7 @@ int mv_eth_change_mtu_internals(struct net_device *dev, int mtu)
 
 	if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
 		STAT_ERR(pp->stats.state_err++);
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 		if (pp->dbg_flags & MV_ETH_F_DBG_RX)
 			printk(KERN_ERR "%s: port %d, STARTED_BIT = 0, Invalid value.\n", __func__, pp->port);
 #endif
@@ -4742,9 +4745,9 @@ int mv_eth_change_mtu_internals(struct net_device *dev, int mtu)
 		/* for now, swf long pool must not be shared with other ports */
 		if (port_pool->port_map == (1 << pp->port)) {
 			/* refill pool with updated buffer size */
-			mv_eth_pool_free(port_pool->pool, pkts_num);
+			mv_pp2_pool_free(port_pool->pool, pkts_num);
 			port_pool->pkt_size = pkt_size;
-			mv_eth_pool_add(port_pool->pool, pkts_num);
+			mv_pp2_pool_add(port_pool->pool, pkts_num);
 		} else {
 			printk(KERN_ERR "%s: port %d, SWF long pool is shared with other ports.\n", __func__, pp->port);
 			MV_ETH_UNLOCK(&port_pool->lock, flags);
@@ -4754,7 +4757,7 @@ int mv_eth_change_mtu_internals(struct net_device *dev, int mtu)
 		MV_ETH_UNLOCK(&port_pool->lock, flags);
 	}
 
-#ifdef CONFIG_MV_ETH_HWF
+#ifdef CONFIG_MV_PP2_HWF
 	port_pool = pp->hwf_pool_long;
 
 	if (port_pool && (pp->hwf_pool_long != pp->pool_long)) {
@@ -4763,9 +4766,9 @@ int mv_eth_change_mtu_internals(struct net_device *dev, int mtu)
 		/* for now, hwf long pool must not be shared with other ports */
 		if (port_pool->port_map == (1 << pp->port)) {
 			/* refill pool with updated buffer size */
-			mv_eth_pool_free(port_pool->pool, pkts_num);
+			mv_pp2_pool_free(port_pool->pool, pkts_num);
 			port_pool->pkt_size = pkt_size;
-			mv_eth_pool_add(port_pool->pool, pkts_num);
+			mv_pp2_pool_add(port_pool->pool, pkts_num);
 		} else {
 			printk(KERN_ERR "%s: port %d, HWF long pool is shared with other ports.\n", __func__, pp->port);
 			MV_ETH_UNLOCK(&port_pool->lock, flags);
@@ -4774,9 +4777,9 @@ int mv_eth_change_mtu_internals(struct net_device *dev, int mtu)
 		mvPp2BmPoolBufSizeSet(port_pool->pool, RX_HWF_BUF_SIZE(port_pool->pkt_size));
 		MV_ETH_UNLOCK(&port_pool->lock, flags);
 	}
-#endif /* CONFIG_MV_ETH_HWF */
+#endif /* CONFIG_MV_PP2_HWF */
 
-	if (!MV_PON_PORT(pp->port))
+	if (!MV_PP2_IS_PON_PORT(pp->port))
 		mvGmacMaxRxSizeSet(pp->port, pkt_size);
 #ifdef CONFIG_MV_INCLUDE_PON
 	else
@@ -4784,7 +4787,7 @@ int mv_eth_change_mtu_internals(struct net_device *dev, int mtu)
 #endif
 
 #ifndef CONFIG_MV_ETH_PP2_1
-	mv_eth_tx_mtu_set(pp->port, pkt_size);
+	mv_pp2_tx_mtu_set(pp->port, pkt_size);
 #endif
 
 mtu_out:
@@ -4798,10 +4801,10 @@ mtu_out:
 }
 
 /***********************************************************
- * mv_eth_tx_done_timer_callback --			   *
+ * mv_pp2_tx_done_timer_callback --			   *
  *   N msec periodic callback for tx_done                  *
  ***********************************************************/
-static void mv_eth_tx_done_timer_callback(unsigned long data)
+static void mv_pp2_tx_done_timer_callback(unsigned long data)
 {
 	struct cpu_ctrl *cpuCtrl = (struct cpu_ctrl *)data;
 	struct eth_port *pp = cpuCtrl->pp;
@@ -4814,20 +4817,20 @@ static void mv_eth_tx_done_timer_callback(unsigned long data)
 
 	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
 		STAT_INFO(pp->stats.netdev_stop++);
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 		if (pp->dbg_flags & MV_ETH_F_DBG_TX)
 			printk(KERN_ERR "%s: port #%d is stopped, STARTED_BIT = 0, exit timer.\n", __func__, pp->port);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 		return;
 	}
 
-	if (MV_PON_PORT(pp->port))
-		tx_done = mv_eth_tx_done_pon(pp, &tx_todo);
+	if (MV_PP2_IS_PON_PORT(pp->port))
+		tx_done = mv_pp2_tx_done_pon(pp, &tx_todo);
 	else {
 		/* check all possible queues, as there is no indication from interrupt */
-		txq_mask = (1 << CONFIG_MV_ETH_TXQ) - 1;
-		tx_done = mv_eth_tx_done_gbe(pp, txq_mask, &tx_todo);
+		txq_mask = (1 << CONFIG_MV_PP2_TXQ) - 1;
+		tx_done = mv_pp2_tx_done_gbe(pp, txq_mask, &tx_todo);
 	}
 
 	if (cpuCtrl->cpu != smp_processor_id()) {
@@ -4835,22 +4838,22 @@ static void mv_eth_tx_done_timer_callback(unsigned long data)
 		cpuCtrl = pp->cpu_config[smp_processor_id()];
 	}
 	if (tx_todo > 0)
-		mv_eth_add_tx_done_timer(cpuCtrl);
+		mv_pp2_add_tx_done_timer(cpuCtrl);
 }
 
-void mv_eth_mac_show(int port)
+void mv_pp2_mac_show(int port)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (pp == NULL) {
-		printk(KERN_ERR "%s: port %d entry is null \n", __func__, port);
+		pr_err("%s: port %d entry is null\n", __func__, port);
 		return;
 	}
 
 	mvOsPrintf("port %d RXQ %d~%d\n", port, pp->first_rxq, pp->first_rxq + pp->rxq_num);
-	mvEthPortUcastShow(port);
-	mvEthPortMcastShow(port);
-	mvEthPortBcastShow(port);
+	mvPp2PortUcastShow(port);
+	mvPp2PortMcastShow(port);
+	mvPp2PortBcastShow(port);
 
 	return;
 }
@@ -4858,13 +4861,13 @@ void mv_eth_mac_show(int port)
 /********************************************/
 /*		DSCP API		    */
 /********************************************/
-void mv_eth_dscp_map_show(int port)
+void mv_pp2_dscp_map_show(int port)
 {
 	int dscp, txq;
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (pp == NULL) {
-		printk(KERN_ERR "%s: port %d entry is null \n", __func__, port);
+		pr_err("%s: port %d entry is null\n", __func__, port);
 		return;
 	}
 
@@ -4879,7 +4882,7 @@ void mv_eth_dscp_map_show(int port)
 	}
 }
 
-int mv_eth_rxq_dscp_map_set(int port, int rxq, unsigned char dscp)
+int mv_pp2_rxq_dscp_map_set(int port, int rxq, unsigned char dscp)
 {
 	/* TBD */
 	printk(KERN_ERR "Not supported\n");
@@ -4888,10 +4891,10 @@ int mv_eth_rxq_dscp_map_set(int port, int rxq, unsigned char dscp)
 }
 
 /* Set TXQ for special DSCP value. txq=-1 - use default TXQ for this port */
-int mv_eth_txq_dscp_map_set(int port, int txq, unsigned char dscp)
+int mv_pp2_txq_dscp_map_set(int port, int txq, unsigned char dscp)
 {
 	MV_U8 old_txq;
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (mvPp2PortCheck(port))
 		return -EINVAL;
@@ -4913,7 +4916,7 @@ int mv_eth_txq_dscp_map_set(int port, int txq, unsigned char dscp)
 		return 0;
 	}
 
-	if ((txq < 0) || (txq >= CONFIG_MV_ETH_TXQ))
+	if ((txq < 0) || (txq >= CONFIG_MV_PP2_TXQ))
 		return -EINVAL;
 
 	pp->txq_dscp_map[dscp] = (MV_U8) txq;
@@ -4923,19 +4926,19 @@ int mv_eth_txq_dscp_map_set(int port, int txq, unsigned char dscp)
 
 /********************************************/
 
-void mv_eth_vlan_prio_show(int port)
+void mv_pp2_eth_vlan_prio_show(int port)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (pp == NULL) {
-		printk(KERN_ERR "%s: port %d entry is null \n", __func__, port);
+		pr_err("%s: port %d entry is null\n", __func__, port);
 		return;
 	}
 
 	/* TODO - example in NETA */
 }
 
-int mv_eth_rxq_vlan_prio_set(int port, int rxq, unsigned char prio)
+int mv_pp2_eth_rxq_vlan_prio_set(int port, int rxq, unsigned char prio)
 {
 	int status = -1;
 	/*
@@ -4954,7 +4957,7 @@ int mv_eth_rxq_vlan_prio_set(int port, int rxq, unsigned char prio)
 }
 
 
-static int mv_eth_priv_init(struct eth_port *pp, int port)
+static int mv_pp2_priv_init(struct eth_port *pp, int port)
 {
 	static int first_rxq = 0;
 	static int first_rx_q[MV_ETH_MAX_PORTS];
@@ -4973,7 +4976,7 @@ static int mv_eth_priv_init(struct eth_port *pp, int port)
 			first_rx_q[i] = -1;
 
 	pp->port = port;
-	pp->rxq_num = CONFIG_MV_ETH_RXQ;
+	pp->rxq_num = CONFIG_MV_PP2_RXQ;
 	pp->txp_num = 1;
 	pp->tx_spec.flags = 0;
 	pp->tx_spec.txp = 0;
@@ -4987,96 +4990,96 @@ static int mv_eth_priv_init(struct eth_port *pp, int port)
 
 	for_each_possible_cpu(cpu) {
 		cpuCtrl = pp->cpu_config[cpu];
-		cpuCtrl->txq = CONFIG_MV_ETH_TXQ_DEF;
+		cpuCtrl->txq = CONFIG_MV_PP2_TXQ_DEF;
 		cpuCtrl->pp = pp;
 		cpuCtrl->cpu = cpu;
 	}
 
 	pp->flags = 0;
 
-#ifdef CONFIG_MV_ETH_RX_DESC_PREFETCH
+#ifdef CONFIG_MV_PP2_RX_DESC_PREFETCH
 	pp->flags |= MV_ETH_F_RX_DESC_PREFETCH;
 #endif
 
-#ifdef CONFIG_MV_ETH_RX_PKT_PREFETCH
+#ifdef CONFIG_MV_PP2_RX_PKT_PREFETCH
 	pp->flags |= MV_ETH_F_RX_PKT_PREFETCH;
 #endif
 
 	for (i = 0; i < 64; i++)
 		pp->txq_dscp_map[i] = MV_ETH_TXQ_INVALID;
-#ifdef CONFIG_MV_ETH_TX_SPECIAL
+#ifdef CONFIG_MV_PP2_TX_SPECIAL
 	pp->tx_special_check = NULL;
-#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+#endif /* CONFIG_MV_PP2_TX_SPECIAL */
 
 #ifdef CONFIG_MV_INCLUDE_PON
-	if (MV_PON_PORT(port)) {
+	if (MV_PP2_IS_PON_PORT(port)) {
 		pp->tx_spec.flags |= MV_ETH_TX_F_MH;
 		pp->txp_num = CONFIG_MV_PON_TCONTS;
-		pp->tx_spec.txp = CONFIG_MV_PON_TXP_DEF;
+		pp->tx_spec.txp = CONFIG_MV_PP2_PON_TXP_DEF;
 		for_each_possible_cpu(i)
-			pp->cpu_config[i]->txq = CONFIG_MV_PON_TXQ_DEF;
+			pp->cpu_config[i]->txq = CONFIG_MV_PP2_PON_TXQ_DEF;
 	}
 #endif
 
 	for_each_possible_cpu(cpu) {
 		cpuCtrl = pp->cpu_config[cpu];
 		memset(&cpuCtrl->tx_done_timer, 0, sizeof(struct timer_list));
-		cpuCtrl->tx_done_timer.function = mv_eth_tx_done_timer_callback;
+		cpuCtrl->tx_done_timer.function = mv_pp2_tx_done_timer_callback;
 		cpuCtrl->tx_done_timer.data = (unsigned long)cpuCtrl;
 		init_timer(&cpuCtrl->tx_done_timer);
 		clear_bit(MV_ETH_F_TX_DONE_TIMER_BIT, &(cpuCtrl->flags));
 	}
 
-	pp->weight = CONFIG_MV_ETH_RX_POLL_WEIGHT;
+	pp->weight = CONFIG_MV_PP2_RX_POLL_WEIGHT;
 
 	/* Init pool of external buffers for TSO, fragmentation, etc */
 	spin_lock_init(&pp->extLock);
-	pp->extBufSize = CONFIG_MV_ETH_EXTRA_BUF_SIZE;
-	pp->extArrStack = mvStackCreate(CONFIG_MV_ETH_EXTRA_BUF_NUM);
+	pp->extBufSize = CONFIG_MV_PP2_EXTRA_BUF_SIZE;
+	pp->extArrStack = mvStackCreate(CONFIG_MV_PP2_EXTRA_BUF_NUM);
 	if (pp->extArrStack == NULL) {
 		pr_err("\to %s: Error: failed create  extArrStack for port #%d\n", __func__, port);
 		return -ENOMEM;
 	}
 
-	for (i = 0; i < CONFIG_MV_ETH_EXTRA_BUF_NUM; i++) {
-		ext_buf = mvOsMalloc(CONFIG_MV_ETH_EXTRA_BUF_SIZE);
+	for (i = 0; i < CONFIG_MV_PP2_EXTRA_BUF_NUM; i++) {
+		ext_buf = mvOsMalloc(CONFIG_MV_PP2_EXTRA_BUF_SIZE);
 		if (ext_buf == NULL) {
 			pr_warn("\to %s Warning: %d of %d extra buffers allocated\n",
-				__func__, i, CONFIG_MV_ETH_EXTRA_BUF_NUM);
+				__func__, i, CONFIG_MV_PP2_EXTRA_BUF_NUM);
 			break;
 		}
 		mvStackPush(pp->extArrStack, (MV_U32)ext_buf);
 	}
 
-#ifdef CONFIG_MV_ETH_STAT_DIST
-	pp->dist_stats.rx_dist = mvOsMalloc(sizeof(u32) * (pp->rxq_num * CONFIG_MV_ETH_RXQ_DESC + 1));
+#ifdef CONFIG_MV_PP2_STAT_DIST
+	pp->dist_stats.rx_dist = mvOsMalloc(sizeof(u32) * (pp->rxq_num * CONFIG_MV_PP2_RXQ_DESC + 1));
 	if (pp->dist_stats.rx_dist != NULL) {
-		pp->dist_stats.rx_dist_size = pp->rxq_num * CONFIG_MV_ETH_RXQ_DESC + 1;
+		pp->dist_stats.rx_dist_size = pp->rxq_num * CONFIG_MV_PP2_RXQ_DESC + 1;
 		memset(pp->dist_stats.rx_dist, 0, sizeof(u32) * pp->dist_stats.rx_dist_size);
 	} else
 		pr_err("\to ethPort #%d: Can't allocate %d bytes for rx_dist\n",
-		       pp->port, sizeof(u32) * (pp->rxq_num * CONFIG_MV_ETH_RXQ_DESC + 1));
+		       pp->port, sizeof(u32) * (pp->rxq_num * CONFIG_MV_PP2_RXQ_DESC + 1));
 
 	pp->dist_stats.tx_done_dist =
-	    mvOsMalloc(sizeof(u32) * (pp->txp_num * CONFIG_MV_ETH_TXQ * CONFIG_MV_ETH_TXQ_DESC + 1));
+	    mvOsMalloc(sizeof(u32) * (pp->txp_num * CONFIG_MV_PP2_TXQ * CONFIG_MV_PP2_TXQ_DESC + 1));
 	if (pp->dist_stats.tx_done_dist != NULL) {
-		pp->dist_stats.tx_done_dist_size = pp->txp_num * CONFIG_MV_ETH_TXQ * CONFIG_MV_ETH_TXQ_DESC + 1;
+		pp->dist_stats.tx_done_dist_size = pp->txp_num * CONFIG_MV_PP2_TXQ * CONFIG_MV_PP2_TXQ_DESC + 1;
 		memset(pp->dist_stats.tx_done_dist, 0, sizeof(u32) * pp->dist_stats.tx_done_dist_size);
 	} else
 		pr_err("\to ethPort #%d: Can't allocate %d bytes for tx_done_dist\n",
-		       pp->port, sizeof(u32) * (pp->txp_num * CONFIG_MV_ETH_TXQ * CONFIG_MV_ETH_TXQ_DESC + 1));
-#endif /* CONFIG_MV_ETH_STAT_DIST */
+		       pp->port, sizeof(u32) * (pp->txp_num * CONFIG_MV_PP2_TXQ * CONFIG_MV_PP2_TXQ_DESC + 1));
+#endif /* CONFIG_MV_PP2_STAT_DIST */
 
 	return 0;
 }
 
 /*
 free the memory that allocate by
-mv_eth_netdev_init
-mv_eth_priv_init
-mv_eth_hal_init
+mv_pp2_netdev_init
+mv_pp2_priv_init
+mv_pp2_hal_init
 */
-static void mv_eth_priv_cleanup(struct eth_port *pp)
+static void mv_pp2_priv_cleanup(struct eth_port *pp)
 {
 	int i, port;
 
@@ -5100,18 +5103,18 @@ static void mv_eth_priv_cleanup(struct eth_port *pp)
 	if (mvStackDelete(pp->extArrStack))
 		printk(KERN_ERR "Error: failed delete extArrStack for port #%d\n", port);
 
-#ifdef CONFIG_MV_ETH_STAT_DIST
+#ifdef CONFIG_MV_PP2_STAT_DIST
 	mvOsFree(pp->dist_stats.rx_dist);
 	mvOsFree(pp->dist_stats.tx_done_dist);
 	mvOsFree(pp->dist_stats.tx_tso_dist);
-#endif /* CONFIG_MV_ETH_STAT_DIST */
+#endif /* CONFIG_MV_PP2_STAT_DIST */
 
-	/* allocate by mv_eth_netdev_init */
+	/* allocate by mv_pp2_netdev_init */
 	/* free dev and pp*/
 	synchronize_net();
 	unregister_netdev(pp->dev);
 	free_netdev(pp->dev);
-	mv_eth_ports[port] = NULL;
+	mv_pp2_ports[port] = NULL;
 }
 
 
@@ -5119,10 +5122,10 @@ static void mv_eth_priv_cleanup(struct eth_port *pp)
 /***********************************************************************************
  ***  print RX bm_pool status
  ***********************************************************************************/
-void mv_eth_napi_groups_print(int port)
+void mv_pp2_napi_groups_print(int port)
 {
 	int i;
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	printk(KERN_CONT "NAPI groups:   cpu_mask   rxq_mask   napi_state\n");
 	for (i = 0; i < MV_ETH_MAX_NAPI_GROUPS; i++) {
@@ -5139,10 +5142,10 @@ void mv_eth_napi_groups_print(int port)
 /***********************************************************************************
  ***  print RX bm_pool status
  ***********************************************************************************/
-void mv_eth_pool_status_print(int pool)
+void mv_pp2_pool_status_print(int pool)
 {
 	const char *type;
-	struct bm_pool *bm_pool = &mv_eth_pool[pool];
+	struct bm_pool *bm_pool = &mv_pp2_pool[pool];
 	int buf_size, total_size, true_size;
 
 	if (MV_ETH_BM_POOL_IS_HWF(bm_pool->type)) {
@@ -5185,20 +5188,20 @@ void mv_eth_pool_status_print(int pool)
 		bm_pool->pkt_size, buf_size, total_size, true_size);
 	pr_info("     capacity=%d, buf_num=%d, port_map=0x%x, in_use=%u, in_use_thresh=%u\n",
 		bm_pool->capacity, bm_pool->buf_num, bm_pool->port_map,
-		mv_eth_bm_in_use_read(bm_pool), bm_pool->in_use_thresh);
+		mv_pp2_bm_in_use_read(bm_pool), bm_pool->in_use_thresh);
 
-#ifdef CONFIG_MV_ETH_STAT_ERR
+#ifdef CONFIG_MV_PP2_STAT_ERR
 	pr_cont("     skb_alloc_oom=%u", bm_pool->stats.skb_alloc_oom);
-#endif /* #ifdef CONFIG_MV_ETH_STAT_ERR */
+#endif /* #ifdef CONFIG_MV_PP2_STAT_ERR */
 
-#ifdef CONFIG_MV_ETH_STAT_DBG
+#ifdef CONFIG_MV_PP2_STAT_DBG
 	pr_cont(", skb_alloc_ok=%u, bm_put=%u\n",
 	       bm_pool->stats.skb_alloc_ok, bm_pool->stats.bm_put);
 
 	pr_info("     no_recycle=%u, skb_recycled_ok=%u, skb_recycled_err=%u, bm_cookie_err=%u\n",
 		bm_pool->stats.no_recycle, bm_pool->stats.skb_recycled_ok,
 		bm_pool->stats.skb_recycled_err, bm_pool->stats.bm_cookie_err);
-#endif /* CONFIG_MV_ETH_STAT_DBG */
+#endif /* CONFIG_MV_PP2_STAT_DBG */
 
 	memset(&bm_pool->stats, 0, sizeof(bm_pool->stats));
 }
@@ -5207,7 +5210,7 @@ void mv_eth_pool_status_print(int pool)
 /***********************************************************************************
  ***  print ext pool status
  ***********************************************************************************/
-void mv_eth_ext_pool_print(struct eth_port *pp)
+void mv_pp2_ext_pool_print(struct eth_port *pp)
 {
 	printk(KERN_ERR "\nExt Pool Stack: bufSize = %u bytes\n", pp->extBufSize);
 	mvStackStatus(pp->extArrStack, 0);
@@ -5216,7 +5219,7 @@ void mv_eth_ext_pool_print(struct eth_port *pp)
 /***********************************************************************************
  ***  print net device status
  ***********************************************************************************/
-void mv_eth_netdev_print(struct net_device *dev)
+void mv_pp2_eth_netdev_print(struct net_device *dev)
 {
 	printk(KERN_ERR "%s net_device status:\n\n", dev->name);
 	printk(KERN_ERR "ifIdx=%d, mtu=%u, pkt_size=%d, buf_size=%d, MAC=" MV_MACQUAD_FMT "\n",
@@ -5237,7 +5240,7 @@ void mv_eth_netdev_print(struct net_device *dev)
 		netif_running(dev), netif_oper_up(dev));
 	pr_info("uc_promisc=%d, promiscuity=%d, allmulti=%d\n", dev->uc_promisc, dev->promiscuity, dev->allmulti);
 
-	if (mv_eth_netdev_find(dev->ifindex)) {
+	if (mv_pp2_eth_netdev_find(dev->ifindex)) {
 		struct eth_port *pp = MV_ETH_PRIV(dev);
 		if (pp->tagged)
 			mv_mux_netdev_print_all(pp->port);
@@ -5248,15 +5251,15 @@ void mv_eth_netdev_print(struct net_device *dev)
 	}
 }
 
-void mv_eth_status_print(void)
+void mv_pp2_status_print(void)
 {
-	printk(KERN_ERR "totals: ports=%d\n", mv_eth_ports_num);
+	pr_info("totals: ports=%d\n", mv_pp2_ports_num);
 
-#ifdef CONFIG_NET_SKB_RECYCLE
-	pr_info("SKB recycle                  : %s\n", mv_ctrl_recycle ? "Enabled" : "Disabled");
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#ifdef CONFIG_MV_PP2_SKB_RECYCLE
+	pr_info("SKB recycle                  : %s\n", mv_ctrl_pp2_recycle ? "Enabled" : "Disabled");
+#endif /* CONFIG_MV_PP2_SKB_RECYCLE */
 
-#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+#ifdef CONFIG_MV_PP2_SWF_HWF_CORRUPTION_WA
 	pr_info("HWF + SWF data corruption WA : %s\n", mv_pp2_swf_hwf_wa_en ? "Enabled" : "Disabled");
 #endif /* CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA */
 }
@@ -5264,11 +5267,11 @@ void mv_eth_status_print(void)
 /***********************************************************************************
  ***  print Ethernet port status
  ***********************************************************************************/
-void mv_eth_port_status_print(unsigned int port)
+void mv_pp2_eth_port_status_print(unsigned int port)
 {
 	int txp, q;
 
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	struct tx_queue *txq_ctrl;
 	struct cpu_ctrl	*cpuCtrl;
 
@@ -5289,7 +5292,7 @@ void mv_eth_port_status_print(unsigned int port)
 	else
 		pr_info("port %d: ", port);
 
-	mv_eth_link_status_print(port);
+	mv_pp2_eth_link_status_print(port);
 
 	pr_cont("\n");
 	pr_info("rxq_coal(pkts)[ q]         = ");
@@ -5309,39 +5312,39 @@ void mv_eth_port_status_print(unsigned int port)
 	pr_cont("\n");
 	for (txp = 0; txp < pp->txp_num; txp++) {
 		pr_info("txq_coal(pkts)[%2d.q]       = ", txp);
-		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++)
+		for (q = 0; q < CONFIG_MV_PP2_TXQ; q++)
 			pr_cont("%4d ", mvPp2TxDonePktsCoalGet(port, txp, q));
 		pr_cont("\n");
 
 		pr_info("txq_desc(num) [%2d.q]       = ", txp);
-		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
-			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + q];
+		for (q = 0; q < CONFIG_MV_PP2_TXQ; q++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + q];
 			pr_cont("%4d ", txq_ctrl->txq_size);
 		}
 		pr_cont("\n");
 
 		pr_info("txq_hwf_desc(num) [%2d.q]   = ", txp);
-		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
-			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + q];
+		for (q = 0; q < CONFIG_MV_PP2_TXQ; q++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + q];
 			pr_cont("%4d ", txq_ctrl->hwf_size);
 		}
 		pr_cont("\n");
 
 #ifdef CONFIG_MV_ETH_PP2_1
 		pr_info("txq_swf_desc(num) [%2d.q]   = ", txp);
-		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
-			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + q];
-			pr_cont("%4d ", txq_ctrl->swf_size);
+		for (q = 0; q < CONFIG_MV_PP2_TXQ; q++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + q];
+			pr_cont("%4d ", txq_ctrl->txq_cpu[0].txq_size);
 		}
 		pr_info("txq_rsvd_chunk(num) [%2d.q] = ", txp);
-		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
-			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + q];
+		for (q = 0; q < CONFIG_MV_PP2_TXQ; q++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + q];
 			pr_cont("%4d ", txq_ctrl->rsvd_chunk);
 		}
 #else
 		pr_info("txq_swf_desc(num) [%2d.q]   = ", txp);
-		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++) {
-			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + q];
+		for (q = 0; q < CONFIG_MV_PP2_TXQ; q++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + q];
 			pr_cont("%4d ", txq_ctrl->txq_cpu[0].txq_size);
 		}
 #endif /* CONFIG_MV_ETH_PP2_1 */
@@ -5350,18 +5353,18 @@ void mv_eth_port_status_print(unsigned int port)
 	}
 	pr_info("\n");
 
-#ifdef CONFIG_MV_ETH_TXDONE_ISR
+#ifdef CONFIG_MV_PP2_TXDONE_ISR
 	printk(KERN_ERR "Do tx_done in NAPI context triggered by ISR\n");
 	for (txp = 0; txp < pp->txp_num; txp++) {
 		printk(KERN_ERR "txcoal(pkts)[%2d.q] = ", txp);
-		for (q = 0; q < CONFIG_MV_ETH_TXQ; q++)
+		for (q = 0; q < CONFIG_MV_PP2_TXQ; q++)
 			printk(KERN_CONT "%3d ", mvPp2TxDonePktsCoalGet(port, txp, q));
 		printk(KERN_CONT "\n");
 	}
 	printk(KERN_ERR "\n");
 #else
-	printk(KERN_ERR "Do tx_done in TX or Timer context: tx_done_threshold=%d\n", mv_ctrl_txdone);
-#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+	pr_err("Do tx_done in TX or Timer context: tx_done_threshold=%d\n", mv_ctrl_pp2_txdone);
+#endif /* CONFIG_MV_PP2_TXDONE_ISR */
 
 	printk(KERN_ERR "txp=%d, zero_pad=%s, mh_en=%s (0x%04x), hw_cmd: 0x%08x 0x%08x 0x%08x\n",
 		pp->tx_spec.txp, (pp->tx_spec.flags & MV_ETH_TX_F_NO_PAD) ? "Disabled" : "Enabled",
@@ -5384,7 +5387,7 @@ void mv_eth_port_status_print(unsigned int port)
 
 	printk(KERN_CONT "\n");
 
-	mv_eth_napi_groups_print(port);
+	mv_pp2_napi_groups_print(port);
 
 	/* Print status of all mux_dev for this port */
 	if (pp->tagged) {
@@ -5399,9 +5402,9 @@ void mv_eth_port_status_print(unsigned int port)
  ***  print port statistics
  ***********************************************************************************/
 
-void mv_eth_port_stats_print(unsigned int port)
+void mv_pp2_port_stats_print(unsigned int port)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 	struct port_stats *stat = NULL;
 	struct tx_queue *txq_ctrl;
 	struct txq_cpu_ctrl *txq_cpu_ptr;
@@ -5417,16 +5420,16 @@ void mv_eth_port_stats_print(unsigned int port)
 	}
 	stat = &(pp->stats);
 
-#ifdef CONFIG_MV_ETH_STAT_ERR
+#ifdef CONFIG_MV_PP2_STAT_ERR
 	pr_info("Errors:\n");
 	pr_info("rx_error..................%10u\n", stat->rx_error);
 	pr_info("tx_timeout................%10u\n", stat->tx_timeout);
 	pr_info("ext_stack_empty...........%10u\n", stat->ext_stack_empty);
 	pr_info("ext_stack_full............%10u\n", stat->ext_stack_full);
 	pr_info("state_err.................%10u\n", stat->state_err);
-#endif /* CONFIG_MV_ETH_STAT_ERR */
+#endif /* CONFIG_MV_PP2_STAT_ERR */
 
-#ifdef CONFIG_MV_ETH_STAT_INF
+#ifdef CONFIG_MV_PP2_STAT_INF
 	pr_info("\nEvents:\n");
 
 	pr_info("irq[cpu]            = ");
@@ -5459,16 +5462,16 @@ void mv_eth_port_stats_print(unsigned int port)
 	pr_info("netdev_stop...............%10u\n", stat->netdev_stop);
 	pr_info("rx_buf_hdr................%10u\n", stat->rx_buf_hdr);
 
-#ifdef CONFIG_MV_ETH_RX_SPECIAL
+#ifdef CONFIG_MV_PP2_RX_SPECIAL
 	pr_info("rx_special................%10u\n", stat->rx_special);
-#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+#endif /* CONFIG_MV_PP2_RX_SPECIAL */
 
-#ifdef CONFIG_MV_ETH_TX_SPECIAL
+#ifdef CONFIG_MV_PP2_TX_SPECIAL
 	pr_info("tx_special................%10u\n", stat->tx_special);
-#endif /* CONFIG_MV_ETH_TX_SPECIAL */
-#endif /* CONFIG_MV_ETH_STAT_INF */
+#endif /* CONFIG_MV_PP2_TX_SPECIAL */
+#endif /* CONFIG_MV_PP2_STAT_INF */
 
-#ifdef CONFIG_MV_ETH_STAT_DBG
+#ifdef CONFIG_MV_PP2_STAT_DBG
 	{
 		__u32 total_rx_ok = 0;
 
@@ -5508,7 +5511,7 @@ void mv_eth_port_stats_print(unsigned int port)
 		}
 		printk(KERN_ERR "SUM:  %10u\n", total_rx_ok);
 	}
-#endif /* CONFIG_MV_ETH_STAT_DBG */
+#endif /* CONFIG_MV_PP2_STAT_DBG */
 
 	pr_info("\nAggregated TXQs statistics\n");
 	pr_info("CPU:  count        send       no_resource\n\n");
@@ -5516,12 +5519,12 @@ void mv_eth_port_stats_print(unsigned int port)
 		struct aggr_tx_queue *aggr_txq_ctrl = &aggr_txqs[cpu];
 		u32 txq_tx = 0, txq_err = 0;
 
-#ifdef CONFIG_MV_ETH_STAT_DBG
+#ifdef CONFIG_MV_PP2_STAT_DBG
 		txq_tx = aggr_txq_ctrl->stats.txq_tx;
-#endif /* CONFIG_MV_ETH_STAT_DBG */
-#ifdef CONFIG_MV_ETH_STAT_ERR
+#endif /* CONFIG_MV_PP2_STAT_DBG */
+#ifdef CONFIG_MV_PP2_STAT_ERR
 		txq_err = aggr_txq_ctrl->stats.txq_err;
-#endif /* CONFIG_MV_ETH_STAT_ERR */
+#endif /* CONFIG_MV_PP2_STAT_ERR */
 
 		pr_info(" %d:    %3d   %10u    %10u\n",
 		       cpu, aggr_txq_ctrl->txq_count, txq_tx, txq_err);
@@ -5533,22 +5536,22 @@ void mv_eth_port_stats_print(unsigned int port)
 	pr_info("TXP-TXQ:  count  res_num      send          done     no_resource      res_req      res_total\n\n");
 
 	for (txp = 0; txp < pp->txp_num; txp++) {
-		for (queue = 0; queue < CONFIG_MV_ETH_TXQ; queue++)
+		for (queue = 0; queue < CONFIG_MV_PP2_TXQ; queue++)
 			for_each_possible_cpu(cpu) {
 				u32 txq_tx = 0, txq_done = 0, txq_reserved_req = 0, txq_reserved_total = 0, txq_err = 0;
 
-				txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + queue];
+				txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + queue];
 				txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
-#ifdef CONFIG_MV_ETH_STAT_DBG
+#ifdef CONFIG_MV_PP2_STAT_DBG
 				txq_tx = txq_cpu_ptr->stats.txq_tx;
 				txq_done = txq_cpu_ptr->stats.txq_txdone;
 				txq_reserved_req = txq_cpu_ptr->stats.txq_reserved_req;
 				txq_reserved_total = txq_cpu_ptr->stats.txq_reserved_total;
 
-#endif /* CONFIG_MV_ETH_STAT_DBG */
-#ifdef CONFIG_MV_ETH_STAT_ERR
+#endif /* CONFIG_MV_PP2_STAT_DBG */
+#ifdef CONFIG_MV_PP2_STAT_ERR
 				txq_err = txq_cpu_ptr->stats.txq_err;
-#endif /* CONFIG_MV_ETH_STAT_ERR */
+#endif /* CONFIG_MV_PP2_STAT_ERR */
 
 				pr_info("%d-%d-cpu#%d: %3d    %3d   %10u    %10u    %10u    %10u    %10u\n",
 				       txp, queue, cpu, txq_cpu_ptr->txq_count, txq_cpu_ptr->reserved_num,
@@ -5559,16 +5562,16 @@ void mv_eth_port_stats_print(unsigned int port)
 	}
 	memset(stat, 0, sizeof(struct port_stats));
 
-	mv_eth_ext_pool_print(pp);
+	mv_pp2_ext_pool_print(pp);
 
 	/* RX pool statistics */
 	if (pp->pool_short)
-		mv_eth_pool_status_print(pp->pool_short->pool);
+		mv_pp2_pool_status_print(pp->pool_short->pool);
 
 	if (pp->pool_long)
-		mv_eth_pool_status_print(pp->pool_long->pool);
+		mv_pp2_pool_status_print(pp->pool_long->pool);
 
-#ifdef CONFIG_MV_ETH_STAT_DIST
+#ifdef CONFIG_MV_PP2_STAT_DIST
 	{
 		int i;
 		struct dist_stats *dist_stats = &(pp->dist_stats);
@@ -5592,7 +5595,7 @@ void mv_eth_port_stats_print(unsigned int port)
 				}
 			}
 		}
-#ifdef CONFIG_MV_ETH_TSO
+#ifdef CONFIG_MV_PP2_TSO
 		if (dist_stats->tx_tso_dist) {
 			printk(KERN_ERR "\n      TSO stats\n");
 			for (i = 0; i < dist_stats->tx_tso_dist_size; i++) {
@@ -5602,12 +5605,12 @@ void mv_eth_port_stats_print(unsigned int port)
 				}
 			}
 		}
-#endif /* CONFIG_MV_ETH_TSO */
+#endif /* CONFIG_MV_PP2_TSO */
 	}
-#endif /* CONFIG_MV_ETH_STAT_DIST */
+#endif /* CONFIG_MV_PP2_STAT_DIST */
 }
-/* mv_eth_tx_cleanup - reset and delete all tx queues */
-static void mv_eth_tx_cleanup(struct eth_port *pp)
+/* mv_pp2_tx_cleanup - reset and delete all tx queues */
+static void mv_pp2_tx_cleanup(struct eth_port *pp)
 {
 	int txp, txq;
 	struct tx_queue *txq_ctrl;
@@ -5617,22 +5620,22 @@ static void mv_eth_tx_cleanup(struct eth_port *pp)
 
 	/* Reset Tx ports */
 	for (txp = 0; txp < pp->txp_num; txp++) {
-		if (mv_eth_txp_clean(pp->port, txp))
+		if (mv_pp2_txp_clean(pp->port, txp))
 			printk(KERN_ERR "Warning: Port %d Tx port %d reset failed\n", pp->port, txp);
 	}
 
 	/* Delete Tx queues */
 	for (txp = 0; txp < pp->txp_num; txp++) {
-		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++) {
-			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+		for (txq = 0; txq < CONFIG_MV_PP2_TXQ; txq++) {
+			txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + txq];
 			if (txq_ctrl->q)
-				mv_eth_txq_delete(pp, txq_ctrl);
+				mv_pp2_txq_delete(pp, txq_ctrl);
 		}
 	}
 }
 
-/* mv_eth_rx_cleanup - reset and delete all rx queues */
-static void mv_eth_rx_cleanup(struct eth_port *pp)
+/* mv_pp2_rx_cleanup - reset and delete all rx queues */
+static void mv_pp2_rx_cleanup(struct eth_port *pp)
 {
 	int rxq, prxq;
 	struct rx_queue *rxq_ctrl;
@@ -5641,7 +5644,7 @@ static void mv_eth_rx_cleanup(struct eth_port *pp)
 		return;
 
 	/* Reset RX ports */
-	if (mv_eth_rx_reset(pp->port))
+	if (mv_pp2_rx_reset(pp->port))
 		printk(KERN_ERR "%s Warning: Rx port %d reset failed\n", __func__, pp->port);
 
 	/* Delete Rx queues */
@@ -5661,8 +5664,8 @@ static void mv_eth_rx_cleanup(struct eth_port *pp)
 }
 
 
-/* mv_eth_pool_cleanup - delete all ports buffers from pool */
-static void mv_eth_pool_cleanup(int port, struct bm_pool *ppool)
+/* mv_pp2_pool_cleanup - delete all ports buffers from pool */
+static void mv_pp2_pool_cleanup(int port, struct bm_pool *ppool)
 {
 	if (!ppool)
 		return;
@@ -5670,12 +5673,12 @@ static void mv_eth_pool_cleanup(int port, struct bm_pool *ppool)
 	ppool->port_map &= ~(1 << port);
 
 	if (ppool->port_map == 0) {
-		mv_eth_pool_free(ppool->pool, ppool->buf_num);
+		mv_pp2_pool_free(ppool->pool, ppool->buf_num);
 		ppool->type = MV_ETH_BM_FREE;
 	}
 }
 
-static void mv_eth_napi_cleanup(struct eth_port *pp)
+static void mv_pp2_napi_cleanup(struct eth_port *pp)
 {
 	int i;
 	struct napi_group_ctrl *napi_group;
@@ -5697,10 +5700,10 @@ static void mv_eth_napi_cleanup(struct eth_port *pp)
 	}
 }
 
-static int mv_eth_port_cleanup(int port)
+static int mv_pp2_port_cleanup(int port)
 {
 	struct eth_port *pp;
-	pp = mv_eth_port_by_id(port);
+	pp = mv_pp2_port_by_id(port);
 
 	if (pp == NULL) {
 		printk(KERN_ERR "port %d already clean\n", port);
@@ -5712,58 +5715,58 @@ static int mv_eth_port_cleanup(int port)
 		return -1;
 	}
 
-	mv_eth_tx_cleanup(pp);
-	mv_eth_rx_cleanup(pp);
+	mv_pp2_tx_cleanup(pp);
+	mv_pp2_rx_cleanup(pp);
 
 	/*pools cleanup*/
-	mv_eth_pool_cleanup(port, pp->pool_long);
-	mv_eth_pool_cleanup(port, pp->pool_short);
-	mv_eth_pool_cleanup(port, pp->hwf_pool_long);
-	mv_eth_pool_cleanup(port, pp->hwf_pool_short);
+	mv_pp2_pool_cleanup(port, pp->pool_long);
+	mv_pp2_pool_cleanup(port, pp->pool_short);
+	mv_pp2_pool_cleanup(port, pp->hwf_pool_long);
+	mv_pp2_pool_cleanup(port, pp->hwf_pool_short);
 
 	/* Clear Marvell Header related modes - will be set again if needed on re-init */
 	mvPp2MhSet(port, MV_TAG_TYPE_NONE);
 
 	/* Clear any forced link, speed and duplex */
-	mv_eth_port_link_speed_fc(port, MV_ETH_SPEED_AN, 0);
+	mv_pp2_port_link_speed_fc(port, MV_ETH_SPEED_AN, 0);
 
-	mv_eth_napi_cleanup(pp);
+	mv_pp2_napi_cleanup(pp);
 
 	if (pp->tagged)
 		mv_mux_eth_detach(pp->port);
 
-	mv_eth_priv_cleanup(pp);
+	mv_pp2_priv_cleanup(pp);
 
 	printk(KERN_ERR "port %d cleanup done\n", port);
 
 	return 0;
 }
 
-int mv_eth_all_ports_cleanup(void)
+int mv_pp2_all_ports_cleanup(void)
 {
 	int port, status;
 
-	for (port = 0; port < mv_eth_ports_num; port++) {
-		status = mv_eth_port_cleanup(port);
+	for (port = 0; port < mv_pp2_ports_num; port++) {
+		status = mv_pp2_port_cleanup(port);
 		if (status != 0) {
 			printk(KERN_ERR "%s :port %d, cleanup failed, stopping all ports cleanup\n", __func__, port);
 			return status;
 		}
 	}
 
-	if (mv_eth_initialized)
-		mv_eth_shared_cleanup();
+	if (mv_pp2_initialized)
+		mv_pp2_shared_cleanup();
 
 	return MV_OK;
 
 }
 
-int mv_eth_all_ports_probe(void)
+int mv_pp2_all_ports_probe(void)
 {
 	int port = 0;
 
-	for (port = 0; port < mv_eth_ports_num; port++)
-		if (mv_eth_probe(plats[port]))
+	for (port = 0; port < mv_pp2_ports_num; port++)
+		if (mv_pp2_eth_probe(plats[port]))
 			return 1;
 	return 0;
 }
@@ -5777,8 +5780,8 @@ struct mv_eth_ext_mac_ops *mv_pon_callbacks;
 
 void pon_link_status_notify(int port_id, MV_BOOL link_state)
 {
-	struct eth_port *pon_port = mv_eth_port_by_id(MV_PON_LOGIC_PORT_GET());
-	mv_eth_link_event(pon_port, 1);
+	struct eth_port *pon_port = mv_pp2_port_by_id(MV_PON_LOGIC_PORT_GET());
+	mv_pp2_link_event(pon_port, 1);
 }
 
 /* called by PON module */
@@ -5883,22 +5886,22 @@ MV_STATUS mv_pon_disable(void)
 #ifdef CONFIG_CPU_IDLE
 
 
-int mv_eth_suspend_clock(int port)
+int mv_pp2_suspend_clock(int port)
 {
 /* TBD */
 	return 0;
 }
 
-/* mv_eth_suspend_common - common port suspend, can be called anyplace */
-int mv_eth_suspend_common(int port)
+/* mv_pp2_suspend_common - common port suspend, can be called anyplace */
+int mv_pp2_suspend_common(int port)
 {
 	struct eth_port *pp;
 
-	pp = mv_eth_port_by_id(port);
+	pp = mv_pp2_port_by_id(port);
 	if (!pp)
 		return MV_OK;
 
-	if (mv_eth_port_suspend(port)) {
+	if (mv_pp2_eth_port_suspend(port)) {
 		pr_err("%s: port #%d suspend failed.\n", __func__, port);
 		return MV_ERROR;
 	}
@@ -5916,11 +5919,11 @@ int mv_eth_suspend_common(int port)
 	return MV_OK;
 }
 
-int mv_eth_suspend(struct platform_device *pdev, pm_message_t state)
+int mv_pp2_eth_suspend(struct platform_device *pdev, pm_message_t state)
 {
 	int port = pdev->id;
 
-	if (mv_eth_suspend_common(port)) {
+	if (mv_pp2_suspend_common(port)) {
 		pr_err("%s: port #%d suspend failed.\n", __func__, port);
 		return MV_ERROR;
 	}
@@ -5928,25 +5931,25 @@ int mv_eth_suspend(struct platform_device *pdev, pm_message_t state)
 	return MV_OK;
 }
 
-int mv_eth_resume_clock(int port)
+int mv_pp2_resume_clock(int port)
 {
 /* TBD */
 	return 0;
 }
 
 
-int mv_eth_resume(struct platform_device *pdev)
+int mv_pp2_eth_resume(struct platform_device *pdev)
 {
 	struct eth_port *pp;
 	int port = pdev->id;
 
-	pp = mv_eth_port_by_id(port);
+	pp = mv_pp2_port_by_id(port);
 	if (!pp)
 		return MV_OK;
 
 	/* PM mode: WoL Mode*/
 	if (pp->pm_mode == 0) {
-		if (mv_eth_port_resume(port)) {
+		if (mv_pp2_port_resume(port)) {
 			pr_err("%s: port #%d resume failed.\n", __func__, port);
 			return MV_ERROR;
 		}
@@ -5957,14 +5960,14 @@ int mv_eth_resume(struct platform_device *pdev)
 
 #endif	/* CONFIG_CPU_IDLE */
 
-static int mv_eth_remove(struct platform_device *pdev)
+static int mv_pp2_eth_remove(struct platform_device *pdev)
 {
 #ifdef CONFIG_NETMAP
 	int port = pdev->id;
-	struct eth_port *pp = mv_eth_port_by_id(port);
+	struct eth_port *pp = mv_pp2_port_by_id(port);
 #endif
 	printk(KERN_INFO "Removing Marvell Ethernet Driver\n");
-	mv_eth_sysfs_exit();
+	mv_pp2_sysfs_exit();
 #ifdef CONFIG_NETMAP
 	if (pp->flags & MV_ETH_F_IFCAP_NETMAP)
 		netmap_detach(pp->dev);
@@ -5972,44 +5975,44 @@ static int mv_eth_remove(struct platform_device *pdev)
 	return 0;
 }
 
-static void mv_eth_shutdown(struct platform_device *pdev)
+static void mv_pp2_eth_shutdown(struct platform_device *pdev)
 {
 
 #ifdef CONFIG_CPU_IDLE
 	int port = pdev->id;
-		struct eth_port *pp = mv_eth_port_by_id(port);
+		struct eth_port *pp = mv_pp2_port_by_id(port);
 
 	if (pp->flags & MV_ETH_F_STARTED)
-		mv_eth_suspend_common(port);
+		mv_pp2_suspend_common(port);
 #endif
 
 	printk(KERN_INFO "Shutting Down Marvell Ethernet Driver\n");
 }
 
-static struct platform_driver mv_eth_driver = {
-	.probe = mv_eth_probe,
-	.remove = mv_eth_remove,
-	.shutdown = mv_eth_shutdown,
+static struct platform_driver mv_pp2_eth_driver = {
+	.probe = mv_pp2_eth_probe,
+	.remove = mv_pp2_eth_remove,
+	.shutdown = mv_pp2_eth_shutdown,
 #ifdef CONFIG_CPU_IDLE
-	.suspend = mv_eth_suspend,
-	.resume = mv_eth_resume,
+	.suspend = mv_pp2_eth_suspend,
+	.resume = mv_pp2_eth_resume,
 #endif /* CONFIG_CPU_IDLE */
 	.driver = {
 		.name = MV_PP2_PORT_NAME,
 	},
 };
 
-static int __init mv_eth_init_module(void)
+static int __init mv_pp2_init_module(void)
 {
-	return platform_driver_register(&mv_eth_driver);
+	return platform_driver_register(&mv_pp2_eth_driver);
 }
-module_init(mv_eth_init_module);
+module_init(mv_pp2_init_module);
 
-static void __exit mv_eth_cleanup_module(void)
+static void __exit mv_pp2_cleanup_module(void)
 {
-	platform_driver_unregister(&mv_eth_driver);
+	platform_driver_unregister(&mv_pp2_eth_driver);
 }
-module_exit(mv_eth_cleanup_module);
+module_exit(mv_pp2_cleanup_module);
 
 
 MODULE_DESCRIPTION("Marvell Ethernet Driver - www.marvell.com");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
index 8e5ebed..bedc692 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
@@ -50,31 +50,32 @@ disclaimer.
 /******************************************************
  * driver statistics control --                       *
  ******************************************************/
-#ifdef CONFIG_MV_ETH_STAT_ERR
+#ifdef CONFIG_MV_PP2_STAT_ERR
 #define STAT_ERR(c) c
 #else
 #define STAT_ERR(c)
 #endif
 
-#ifdef CONFIG_MV_ETH_STAT_INF
+#ifdef CONFIG_MV_PP2_STAT_INF
 #define STAT_INFO(c) c
 #else
 #define STAT_INFO(c)
 #endif
 
-#ifdef CONFIG_MV_ETH_STAT_DBG
+#ifdef CONFIG_MV_PP2_STAT_DBG
 #define STAT_DBG(c) c
 #else
 #define STAT_DBG(c)
 #endif
 
-#ifdef CONFIG_MV_ETH_STAT_DIST
+#ifdef CONFIG_MV_PP2_STAT_DIST
 #define STAT_DIST(c) c
 #else
 #define STAT_DIST(c)
 #endif
 
-extern int mv_ctrl_txdone;
+extern int mv_ctrl_pp2_txdone;
+extern unsigned int mv_pp2_pnc_ctrl_en;
 
 /****************************************************************************
  * Rx buffer size: MTU + 2(Marvell Header) + 4(VLAN) + 14(MAC hdr) + 4(CRC) *
@@ -95,14 +96,14 @@ extern int mv_ctrl_txdone;
 
 #define RX_TRUE_SIZE(total_size)	roundup_pow_of_two(total_size)
 
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_PP2_SKB_RECYCLE
 extern int mv_ctrl_recycle;
 
-#define mv_eth_is_recycle()     (mv_ctrl_recycle)
-int mv_eth_skb_recycle(struct sk_buff *skb);
+#define mv_pp2_is_recycle()     (mv_ctrl_pp2_recycle)
+int mv_pp2_skb_recycle(struct sk_buff *skb);
 #else
-#define mv_eth_is_recycle()     0
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#define mv_pp2_is_recycle()     0
+#endif /* CONFIG_MV_PP2_SKB_RECYCLE */
 
 
 
@@ -145,28 +146,28 @@ int mv_eth_skb_recycle(struct sk_buff *skb);
  */
 
 struct txq_stats {
-#ifdef CONFIG_MV_ETH_STAT_ERR
+#ifdef CONFIG_MV_PP2_STAT_ERR
 	u32 txq_err;
-#endif /* CONFIG_MV_ETH_STAT_ERR */
-#ifdef CONFIG_MV_ETH_STAT_DBG
+#endif /* CONFIG_MV_PP2_STAT_ERR */
+#ifdef CONFIG_MV_PP2_STAT_DBG
 	u32 txq_tx;
 	u32 txq_reserved_req;   /* Number of requests to reserve TX descriptors */
 	u32 txq_reserved_total; /* Accumulated number of reserved TX descriptors */
 	u32 txq_txdone;
-#endif /* CONFIG_MV_ETH_STAT_DBG */
+#endif /* CONFIG_MV_PP2_STAT_DBG */
 };
 
 struct port_stats {
 
-#ifdef CONFIG_MV_ETH_STAT_ERR
+#ifdef CONFIG_MV_PP2_STAT_ERR
 	u32 rx_error;
 	u32 tx_timeout;
 	u32 ext_stack_empty;
 	u32 ext_stack_full;
 	u32 state_err;
-#endif /* CONFIG_MV_ETH_STAT_ERR */
+#endif /* CONFIG_MV_PP2_STAT_ERR */
 
-#ifdef CONFIG_MV_ETH_STAT_INF
+#ifdef CONFIG_MV_PP2_STAT_INF
 	u32 irq[CONFIG_NR_CPUS];
 	u32 irq_err[CONFIG_NR_CPUS];
 	u32 poll[CONFIG_NR_CPUS];
@@ -178,18 +179,18 @@ struct port_stats {
 	u32 netdev_stop;
 	u32 rx_buf_hdr;
 
-#ifdef CONFIG_MV_ETH_RX_SPECIAL
+#ifdef CONFIG_MV_PP2_RX_SPECIAL
 	u32 rx_special;
-#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+#endif /* CONFIG_MV_PP2_RX_SPECIAL */
 
-#ifdef CONFIG_MV_ETH_TX_SPECIAL
+#ifdef CONFIG_MV_PP2_TX_SPECIAL
 	u32 tx_special;
-#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+#endif /* CONFIG_MV_PP2_TX_SPECIAL */
 
-#endif /* CONFIG_MV_ETH_STAT_INF */
+#endif /* CONFIG_MV_PP2_STAT_INF */
 
-#ifdef CONFIG_MV_ETH_STAT_DBG
-	u32 rxq[CONFIG_MV_ETH_RXQ];
+#ifdef CONFIG_MV_PP2_STAT_DBG
+	u32 rxq[CONFIG_MV_PP2_RXQ];
 	u32 rx_tagged;
 	u32 rx_netif;
 	u32 rx_gro;
@@ -206,7 +207,7 @@ struct port_stats {
 	u32 tx_tso_bytes;
 	u32 ext_stack_put;
 	u32 ext_stack_get;
-#endif /* CONFIG_MV_ETH_STAT_DBG */
+#endif /* CONFIG_MV_PP2_STAT_DBG */
 };
 
 #define MV_ETH_TX_DESC_ALIGN		0x1f
@@ -234,7 +235,7 @@ struct port_stats {
 #define MV_ETH_F_STARTED_OLD            (1 << MV_ETH_F_STARTED_OLD_BIT)
 #define MV_ETH_F_IFCAP_NETMAP           (1 << MV_ETH_F_IFCAP_NETMAP_BIT)
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_PP2_DEBUG_CODE
 /* Masks used for pp->dbg_flags */
 #define MV_ETH_F_DBG_RX_BIT         0
 #define MV_ETH_F_DBG_TX_BIT         1
@@ -249,7 +250,7 @@ struct port_stats {
 #define MV_ETH_F_DBG_ISR           (1 << MV_ETH_F_DBG_ISR_BIT)
 #define MV_ETH_F_DBG_POLL          (1 << MV_ETH_F_DBG_POLL_BIT)
 #define MV_ETH_F_DBG_BUFF_HDR      (1 << MV_ETH_F_DBG_BUFF_HDR_BIT)
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_PP2_DEBUG_CODE */
 
 /* Masks used for cpu_ctrl->flags */
 #define MV_ETH_F_TX_DONE_TIMER_BIT  0
@@ -269,14 +270,14 @@ struct port_stats {
 #define MV_ETH_TX_F_MH		0x0002
 #define MV_ETH_TX_F_HW_CMD	0x0004
 
-struct mv_eth_tx_spec {
+struct mv_pp2_tx_spec {
 	unsigned long	flags;
 	u32		hw_cmd[3];     /* tx_desc offset = 0x10, 0x14, 0x18 */
 	u16		tx_mh;
 	u8		txp;
 	u8		txq;
-#ifdef CONFIG_MV_ETH_TX_SPECIAL
-	void		(*tx_func) (u8 *data, int size, struct mv_eth_tx_spec *tx_spec);
+#ifdef CONFIG_MV_PP2_TX_SPECIAL
+	void		(*tx_func) (u8 *data, int size, struct mv_pp2_tx_spec *tx_spec);
 #endif
 };
 
@@ -360,10 +361,10 @@ struct eth_port {
 	struct bm_pool		*pool_short;
 	struct bm_pool		*hwf_pool_long;
 	struct bm_pool		*hwf_pool_short;
-	struct napi_group_ctrl	*napi_group[MV_ETH_MAX_RXQ];
+	struct napi_group_ctrl	*napi_group[MV_PP2_MAX_RXQ];
 	unsigned long		flags; /* MH, TIMER, etc. */
 	u8			dbg_flags;
-	struct mv_eth_tx_spec	tx_spec;
+	struct mv_pp2_tx_spec	tx_spec;
 	struct port_stats	stats;
 	struct dist_stats	dist_stats;
 	int			weight;
@@ -392,14 +393,14 @@ struct eth_port {
 	/* Rate calculate */
 	unsigned long		rx_rate_pkts;
 	unsigned long		rx_timestamp;
-#ifdef CONFIG_MV_ETH_RX_SPECIAL
+#ifdef CONFIG_MV_PP2_RX_SPECIAL
 	int			(*rx_special_proc)(int port, int rxq, struct net_device *dev,
 						struct sk_buff *skb, struct pp2_rx_desc *rx_desc);
-#endif /* CONFIG_MV_ETH_RX_SPECIAL */
-#ifdef CONFIG_MV_ETH_TX_SPECIAL
+#endif /* CONFIG_MV_PP2_RX_SPECIAL */
+#ifdef CONFIG_MV_PP2_TX_SPECIAL
 	int			(*tx_special_check)(int port, struct net_device *dev, struct sk_buff *skb,
-						struct mv_eth_tx_spec *tx_spec_out);
-#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+						struct mv_pp2_tx_spec *tx_spec_out);
+#endif /* CONFIG_MV_PP2_TX_SPECIAL */
 	MV_U32			cpuMask;
 	MV_U32			rx_indir_table[256];
 	struct cpu_ctrl		*cpu_config[CONFIG_NR_CPUS];
@@ -420,13 +421,13 @@ enum eth_pm_mode {
 
 /* BM specific defines */
 struct pool_stats {
-#ifdef CONFIG_MV_ETH_STAT_ERR
+#ifdef CONFIG_MV_PP2_STAT_ERR
 	u32 skb_alloc_oom;
 	u32 stack_empty;
 	u32 stack_full;
-#endif /* CONFIG_MV_ETH_STAT_ERR */
+#endif /* CONFIG_MV_PP2_STAT_ERR */
 
-#ifdef CONFIG_MV_ETH_STAT_DBG
+#ifdef CONFIG_MV_PP2_STAT_DBG
 	u32 no_recycle;
 	u32 bm_put;
 	u32 stack_put;
@@ -435,11 +436,11 @@ struct pool_stats {
 	u32 skb_recycled_ok;
 	u32 skb_recycled_err;
 	u32 bm_cookie_err;
-#endif /* CONFIG_MV_ETH_STAT_DBG */
+#endif /* CONFIG_MV_PP2_STAT_DBG */
 };
 
 /* BM pool assignment */
-#ifdef CONFIG_MV_ETH_BM_PER_PORT_MODE
+#ifdef CONFIG_MV_PP2_BM_PER_PORT_MODE
 /* #port   SWF long   SWF short   HWF long   HWF short *
  *   0         0          1           0           1    *
  *   1         2          3           2           3    *
@@ -449,7 +450,7 @@ struct pool_stats {
 #define MV_ETH_BM_SWF_SHORT_POOL(port)		((port << 1) + 1)
 #define MV_ETH_BM_HWF_LONG_POOL(port)		(MV_ETH_BM_SWF_LONG_POOL(port))
 #define MV_ETH_BM_HWF_SHORT_POOL(port)		(MV_ETH_BM_SWF_SHORT_POOL(port))
-#else /* CONFIG_MV_ETH_BM_SWF_HWF_MODE */
+#else /* CONFIG_MV_PP2_BM_SWF_HWF_MODE */
 /* #port   SWF long   SWF short   HWF long   HWF short *
  *   0         0          3           4           7    *
  *   1         1          3           5           7    *
@@ -462,9 +463,9 @@ struct pool_stats {
 #endif
 
 #define MV_ETH_BM_POOLS		MV_BM_POOLS
-#define mv_eth_pool_bm(p)	(p->bm_pool)
+#define mv_pp2_pool_bm(p)	(p->bm_pool)
 
-enum mv_eth_bm_type {
+enum mv_pp2_bm_type {
 	MV_ETH_BM_FREE,		/* BM pool is not being used by any port		   */
 	MV_ETH_BM_SWF_LONG,	/* BM pool is being used by SWF as long pool		   */
 	MV_ETH_BM_SWF_SHORT,	/* BM pool is being used by SWF as short pool		   */
@@ -474,7 +475,7 @@ enum mv_eth_bm_type {
 	MV_ETH_BM_MIXED_SHORT	/* BM pool is being used by both HWF and SWF as short pool */
 };
 
-/* Macros for using mv_eth_bm_type */
+/* Macros for using mv_pp2_bm_type */
 #define MV_ETH_BM_POOL_IS_HWF(type)	((type == MV_ETH_BM_HWF_LONG) || (type == MV_ETH_BM_HWF_SHORT))
 #define MV_ETH_BM_POOL_IS_SWF(type)	((type == MV_ETH_BM_SWF_LONG) || (type == MV_ETH_BM_SWF_SHORT))
 #define MV_ETH_BM_POOL_IS_MIXED(type)	((type == MV_ETH_BM_MIXED_LONG) || (type == MV_ETH_BM_MIXED_SHORT))
@@ -491,7 +492,7 @@ enum mv_eth_bm_type {
 
 struct bm_pool {
 	int			pool;
-	enum mv_eth_bm_type	type;
+	enum mv_pp2_bm_type	type;
 	int			capacity;
 	int			buf_num;
 	int			pkt_size;
@@ -521,22 +522,22 @@ struct bm_pool {
 /* bits[24-31] - Cpu    */
 #define MV_ETH_BM_COOKIE_CPU_OFFS		24
 
-static inline int mv_eth_bm_cookie_grntd_get(__u32 cookie)
+static inline int mv_pp2_bm_cookie_grntd_get(__u32 cookie)
 {
 	return (cookie & MV_ETH_BM_COOKIE_F_GRNTD) >> MV_ETH_BM_COOKIE_F_GRNTD_BIT;
 }
 
-static inline int mv_eth_bm_cookie_qset_get(__u32 cookie)
+static inline int mv_pp2_bm_cookie_qset_get(__u32 cookie)
 {
 	return (cookie >> 16) & 0xFF;
 }
 
-static inline int mv_eth_bm_cookie_pool_get(__u32 cookie)
+static inline int mv_pp2_bm_cookie_pool_get(__u32 cookie)
 {
 	return (cookie >> 8) & 0xFF;
 }
 
-static inline __u32 mv_eth_bm_cookie_pool_set(__u32 cookie, int pool)
+static inline __u32 mv_pp2_bm_cookie_pool_set(__u32 cookie, int pool)
 {
 	__u32 bm;
 
@@ -545,14 +546,14 @@ static inline __u32 mv_eth_bm_cookie_pool_set(__u32 cookie, int pool)
 
 	return bm;
 }
-static inline int mv_eth_bm_cookie_cpu_get(__u32 cookie)
+static inline int mv_pp2_bm_cookie_cpu_get(__u32 cookie)
 {
 	return (cookie >> MV_ETH_BM_COOKIE_CPU_OFFS) & 0xFF;
 }
 
 /* Build bm cookie from rx_desc */
 /* Cookie includes information needed to return buffer to bm pool: poolid, qset, etc */
-static inline __u32 mv_eth_bm_cookie_build(struct pp2_rx_desc *rx_desc)
+static inline __u32 mv_pp2_bm_cookie_build(struct pp2_rx_desc *rx_desc)
 {
 	int pool = mvPp2RxBmPoolId(rx_desc);
 	int cpu = smp_processor_id();
@@ -566,15 +567,15 @@ static inline __u32 mv_eth_bm_cookie_build(struct pp2_rx_desc *rx_desc)
 
 }
 
-static inline int mv_eth_bm_in_use_read(struct bm_pool *bm)
+static inline int mv_pp2_bm_in_use_read(struct bm_pool *bm)
 {
 	return atomic_read(&bm->in_use);
 }
 
-extern struct bm_pool mv_eth_pool[MV_ETH_BM_POOLS];
-extern struct eth_port **mv_eth_ports;
+extern struct bm_pool mv_pp2_pool[MV_ETH_BM_POOLS];
+extern struct eth_port **mv_pp2_ports;
 
-static inline void mv_eth_rx_csum(struct eth_port *pp, struct pp2_rx_desc *rx_desc, struct sk_buff *skb)
+static inline void mv_pp2_rx_csum(struct eth_port *pp, struct pp2_rx_desc *rx_desc, struct sk_buff *skb)
 {
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 39)
 	if (pp->dev->features & NETIF_F_RXCSUM) {
@@ -594,7 +595,7 @@ static inline void mv_eth_rx_csum(struct eth_port *pp, struct pp2_rx_desc *rx_de
 	STAT_DBG(pp->stats.rx_csum_sw++);
 }
 
-static inline void mv_eth_interrupts_unmask(struct eth_port *pp)
+static inline void mv_pp2_interrupts_unmask(struct eth_port *pp)
 {
 	int cpu = smp_processor_id();
 	struct napi_group_ctrl *napi_group;
@@ -606,19 +607,19 @@ static inline void mv_eth_interrupts_unmask(struct eth_port *pp)
 
 
 	/* unmask interrupts - for RX unmask only RXQs that are in the same napi group */
-#ifdef CONFIG_MV_ETH_TXDONE_ISR
+#ifdef CONFIG_MV_PP2_TXDONE_ISR
 	mvPp2GbeIsrRxTxUnmask(pp->port, napi_group->rxq_mask, 1 /* unmask TxDone interrupts */);
 #else
 	mvPp2GbeIsrRxTxUnmask(pp->port, napi_group->rxq_mask, 0 /* mask TxDone interrupts */);
-#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+#endif /* CONFIG_MV_PP2_TXDONE_ISR */
 }
 
-static inline void mv_eth_interrupts_mask(struct eth_port *pp)
+static inline void mv_pp2_interrupts_mask(struct eth_port *pp)
 {
 	mvPp2GbeIsrRxTxMask(pp->port);
 }
 
-static inline int mv_eth_ctrl_is_tx_enabled(struct eth_port *pp)
+static inline int mv_pp2_ctrl_is_tx_enabled(struct eth_port *pp)
 {
 	if (!pp)
 		return -ENODEV;
@@ -634,7 +635,7 @@ static inline int mv_eth_ctrl_is_tx_enabled(struct eth_port *pp)
 
 	return: 1 - not enough descriptors,  0 - enough descriptors
 */
-static inline int mv_eth_phys_desc_num_check(struct txq_cpu_ctrl *txq_ctrl, int num)
+static inline int mv_pp2_phys_desc_num_check(struct txq_cpu_ctrl *txq_ctrl, int num)
 {
 
 	if ((txq_ctrl->txq_count + num) > txq_ctrl->txq_size) {
@@ -654,9 +655,9 @@ static inline int mv_eth_phys_desc_num_check(struct txq_cpu_ctrl *txq_ctrl, int
 
 	return: 1 - not enough descriptors,  0 - enough descriptors
 */
-static inline int mv_eth_reserved_desc_num_proc(struct eth_port *pp, int txp, int txq, int num)
+static inline int mv_pp2_reserved_desc_num_proc(struct eth_port *pp, int txp, int txq, int num)
 {
-	struct tx_queue *txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+	struct tx_queue *txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_PP2_TXQ + txq];
 	struct txq_cpu_ctrl *txq_cpu_p;
 	struct txq_cpu_ctrl *txq_cpu_ptr =  &txq_ctrl->txq_cpu[smp_processor_id()];
 
@@ -702,7 +703,7 @@ static inline int mv_eth_reserved_desc_num_proc(struct eth_port *pp, int txp, in
 
 	return: 1 - not enough descriptors,  0 - enough descriptors
 */
-static inline int mv_eth_aggr_desc_num_check(struct aggr_tx_queue *aggr_txq_ctrl, int num)
+static inline int mv_pp2_aggr_desc_num_check(struct aggr_tx_queue *aggr_txq_ctrl, int num)
 {
 	/* Is enough aggregated TX descriptors to send packet */
 	if ((aggr_txq_ctrl->txq_count + num) > aggr_txq_ctrl->txq_size) {
@@ -722,7 +723,7 @@ static inline int mv_eth_aggr_desc_num_check(struct aggr_tx_queue *aggr_txq_ctrl
 	return 0;
 }
 
-static inline void mv_eth_tx_desc_flush(struct pp2_tx_desc *tx_desc)
+static inline void mv_pp2_tx_desc_flush(struct pp2_tx_desc *tx_desc)
 {
 #if defined(MV_CPU_BE)
 	mvPPv2TxqDescSwap(tx_desc);
@@ -731,14 +732,14 @@ static inline void mv_eth_tx_desc_flush(struct pp2_tx_desc *tx_desc)
 	mvOsCacheLineFlush(NULL, tx_desc);
 }
 
-static inline void *mv_eth_extra_pool_get(struct eth_port *pp)
+static inline void *mv_pp2_extra_pool_get(struct eth_port *pp)
 {
 	void *ext_buf;
 
 	spin_lock(&pp->extLock);
 	if (mvStackIndex(pp->extArrStack) == 0) {
 		STAT_ERR(pp->stats.ext_stack_empty++);
-		ext_buf = mvOsMalloc(CONFIG_MV_ETH_EXTRA_BUF_SIZE);
+		ext_buf = mvOsMalloc(CONFIG_MV_PP2_EXTRA_BUF_SIZE);
 	} else {
 		STAT_DBG(pp->stats.ext_stack_get++);
 		ext_buf = (void *)mvStackPop(pp->extArrStack);
@@ -748,7 +749,7 @@ static inline void *mv_eth_extra_pool_get(struct eth_port *pp)
 	return ext_buf;
 }
 
-static inline int mv_eth_extra_pool_put(struct eth_port *pp, void *ext_buf)
+static inline int mv_pp2_extra_pool_put(struct eth_port *pp, void *ext_buf)
 {
 	spin_lock(&pp->extLock);
 	if (mvStackIsFull(pp->extArrStack)) {
@@ -763,31 +764,31 @@ static inline int mv_eth_extra_pool_put(struct eth_port *pp, void *ext_buf)
 	return 0;
 }
 
-static inline void mv_eth_add_tx_done_timer(struct cpu_ctrl *cpuCtrl)
+static inline void mv_pp2_add_tx_done_timer(struct cpu_ctrl *cpuCtrl)
 {
 	if (test_and_set_bit(MV_ETH_F_TX_DONE_TIMER_BIT, &(cpuCtrl->flags)) == 0) {
 
-		cpuCtrl->tx_done_timer.expires = jiffies + ((HZ * CONFIG_MV_ETH_TX_DONE_TIMER_PERIOD) / 1000); /* ms */
+		cpuCtrl->tx_done_timer.expires = jiffies + ((HZ * CONFIG_MV_PP2_TX_DONE_TIMER_PERIOD) / 1000); /* ms */
 		STAT_INFO(cpuCtrl->pp->stats.tx_done_timer_add[smp_processor_id()]++);
 		add_timer_on(&cpuCtrl->tx_done_timer, smp_processor_id());
 	}
 }
 
-static inline void mv_eth_shadow_inc_get(struct txq_cpu_ctrl *txq_cpu)
+static inline void mv_pp2_shadow_inc_get(struct txq_cpu_ctrl *txq_cpu)
 {
 	txq_cpu->shadow_txq_get_i++;
 	if (txq_cpu->shadow_txq_get_i == txq_cpu->txq_size)
 		txq_cpu->shadow_txq_get_i = 0;
 }
 
-static inline void mv_eth_shadow_inc_put(struct txq_cpu_ctrl *txq_cpu)
+static inline void mv_pp2_shadow_inc_put(struct txq_cpu_ctrl *txq_cpu)
 {
 	txq_cpu->shadow_txq_put_i++;
 	if (txq_cpu->shadow_txq_put_i == txq_cpu->txq_size)
 		txq_cpu->shadow_txq_put_i = 0;
 }
 
-static inline void mv_eth_shadow_dec_put(struct txq_cpu_ctrl *txq_cpu)
+static inline void mv_pp2_shadow_dec_put(struct txq_cpu_ctrl *txq_cpu)
 {
 	if (txq_cpu->shadow_txq_put_i == 0)
 		txq_cpu->shadow_txq_put_i = txq_cpu->txq_size - 1;
@@ -795,7 +796,7 @@ static inline void mv_eth_shadow_dec_put(struct txq_cpu_ctrl *txq_cpu)
 		txq_cpu->shadow_txq_put_i--;
 }
 
-static inline u32 mv_eth_shadow_get_pop(struct txq_cpu_ctrl *txq_cpu)
+static inline u32 mv_pp2_shadow_get_pop(struct txq_cpu_ctrl *txq_cpu)
 {
 	u32 res = txq_cpu->shadow_txq[txq_cpu->shadow_txq_get_i];
 
@@ -805,7 +806,7 @@ static inline u32 mv_eth_shadow_get_pop(struct txq_cpu_ctrl *txq_cpu)
 	return res;
 }
 
-static inline void mv_eth_shadow_push(struct txq_cpu_ctrl *txq_cpu, int val)
+static inline void mv_pp2_shadow_push(struct txq_cpu_ctrl *txq_cpu, int val)
 {
 	txq_cpu->shadow_txq[txq_cpu->shadow_txq_put_i] = val;
 	txq_cpu->shadow_txq_put_i++;
@@ -814,19 +815,19 @@ static inline void mv_eth_shadow_push(struct txq_cpu_ctrl *txq_cpu, int val)
 }
 
 /* Free skb pair */
-static inline void mv_eth_skb_free(struct sk_buff *skb)
+static inline void mv_pp2_skb_free(struct sk_buff *skb)
 {
-#ifdef CONFIG_NET_SKB_RECYCLE
+#ifdef CONFIG_MV_PP2_SKB_RECYCLE
 	skb->skb_recycle = NULL;
 	skb->hw_cookie = 0;
-#endif /* CONFIG_NET_SKB_RECYCLE */
+#endif /* CONFIG_MV_PP2_SKB_RECYCLE */
 
 	dev_kfree_skb_any(skb);
 }
 
 /* PPv2.1 new API - pass packet to Qset */
 /*
-static inline void mv_eth_pool_qset_put(int pool, MV_ULONG phys_addr, MV_ULONG cookie, struct pp2_rx_desc *rx_desc)
+static inline void mv_pp2_pool_qset_put(int pool, MV_ULONG phys_addr, MV_ULONG cookie, struct pp2_rx_desc *rx_desc)
 {
 	int qset, is_grntd;
 
@@ -838,10 +839,10 @@ static inline void mv_eth_pool_qset_put(int pool, MV_ULONG phys_addr, MV_ULONG c
 */
 
 /* Pass pkt to BM Pool or RXQ ring */
-static inline void mv_eth_pool_refill(struct bm_pool *ppool, __u32 bm,
+static inline void mv_pp2_pool_refill(struct bm_pool *ppool, __u32 bm,
 				MV_ULONG phys_addr, MV_ULONG cookie)
 {
-	int pool = mv_eth_bm_cookie_pool_get(bm);
+	int pool = mv_pp2_bm_cookie_pool_get(bm);
 	unsigned long flags = 0;
 	int grntd, qset;
 
@@ -849,8 +850,8 @@ static inline void mv_eth_pool_refill(struct bm_pool *ppool, __u32 bm,
 	STAT_DBG(ppool->stats.bm_put++);
 	MV_ETH_LIGHT_LOCK(flags);
 
-	grntd =  mv_eth_bm_cookie_grntd_get(bm);
-	qset = mv_eth_bm_cookie_qset_get(bm);
+	grntd =  mv_pp2_bm_cookie_grntd_get(bm);
+	qset = mv_pp2_bm_cookie_qset_get(bm);
 
 	/* if PPV2.0 HW ignore qset and grntd */
 	mvBmPoolQsetPut(pool, (MV_ULONG) phys_addr, (MV_ULONG) cookie, qset, grntd);
@@ -858,7 +859,7 @@ static inline void mv_eth_pool_refill(struct bm_pool *ppool, __u32 bm,
 	MV_ETH_LIGHT_UNLOCK(flags);
 }
 
-static inline MV_U32 mv_eth_pool_get(int pool)
+static inline MV_U32 mv_pp2_pool_get(int pool)
 {
 	MV_U32 bufCookie;
 	unsigned long flags = 0;
@@ -873,102 +874,102 @@ static inline MV_U32 mv_eth_pool_get(int pool)
 /******************************************************
  * Function prototypes --                             *
  ******************************************************/
-int         mv_eth_start(struct net_device *dev);
-int         mv_eth_stop(struct net_device *dev);
-int         mv_eth_change_mtu(struct net_device *dev, int mtu);
-int         mv_eth_check_mtu_internals(struct net_device *dev, int mtu);
-int         mv_eth_check_mtu_valid(struct net_device *dev, int mtu);
-
-int         mv_eth_set_mac_addr(struct net_device *dev, void *mac);
-void	    mv_eth_rx_set_rx_mode(struct net_device *dev);
-int         mv_eth_open(struct net_device *dev);
-int         mv_eth_port_suspend(int port);
-int         mv_eth_port_resume(int port);
-int         mv_eth_resume_clock(int port);
-int         mv_eth_suspend_clock(int port);
-int         mv_eth_suspend_internals(struct eth_port *pp);
-int         mv_eth_resume_internals(struct eth_port *pp, int mtu);
-int         mv_eth_restore_registers(struct eth_port *pp, int mtu);
-
-void	    mv_eth_port_promisc_set(int port);
-
-void        mv_eth_win_init(void);
-int         mv_eth_resume_network_interfaces(struct eth_port *pp);
-int         mv_eth_pm_mode_set(int port, int mode);
-
-irqreturn_t mv_eth_isr(int irq, void *dev_id);
-irqreturn_t mv_eth_link_isr(int irq, void *dev_id);
-int         mv_eth_start_internals(struct eth_port *pp, int mtu);
-int         mv_eth_stop_internals(struct eth_port *pp);
-int         mv_eth_change_mtu_internals(struct net_device *netdev, int mtu);
-
-int         mv_eth_rx_reset(int port);
-int         mv_eth_txq_clean(int port, int txp, int txq);
-int         mv_eth_txp_clean(int port, int txp);
-int         mv_eth_all_ports_cleanup(void);
-int         mv_eth_all_ports_probe(void);
-
-MV_STATUS   mv_eth_rx_ptks_coal_set(int port, int rxq, MV_U32 value);
-MV_STATUS   mv_eth_rx_time_coal_set(int port, int rxq, MV_U32 value);
-MV_STATUS   mv_eth_tx_done_ptks_coal_set(int port, int txp, int txq, MV_U32 value);
-
-struct eth_port     *mv_eth_port_by_id(unsigned int port);
-bool                 mv_eth_netdev_find(unsigned int if_index);
-
-void        mv_eth_mac_show(int port);
-void        mv_eth_dscp_map_show(int port);
-int         mv_eth_rxq_dscp_map_set(int port, int rxq, unsigned char dscp);
-int         mv_eth_txq_dscp_map_set(int port, int txq, unsigned char dscp);
-
-int         mv_eth_rxq_vlan_prio_set(int port, int rxq, unsigned char prio);
-void        mv_eth_vlan_prio_show(int port);
-
-void        mv_eth_netdev_print(struct net_device *netdev);
-void        mv_eth_status_print(void);
-void        mv_eth_port_status_print(unsigned int port);
-void        mv_eth_port_stats_print(unsigned int port);
-void 	    mv_eth_pool_status_print(int pool);
-
-void        mv_eth_set_noqueue(struct net_device *dev, int enable);
-void	    mv_eth_ctrl_pnc(int en);
-void        mv_eth_ctrl_hwf(int en);
-int         mv_eth_ctrl_recycle(int en);
-void        mv_eth_ctrl_txdone(int num);
-int         mv_eth_ctrl_tx_mh(int port, u16 mh);
-
-int         mv_eth_ctrl_tx_cmd_dsa(int port, u16 dsa);
-int         mv_eth_ctrl_tx_cmd_color(int port, u16 color);
-int         mv_eth_ctrl_tx_cmd_gem_id(int port, u16 gem_id);
-int         mv_eth_ctrl_tx_cmd_pon_fec(int port, u16 pon_fec);
+int         mv_pp2_start(struct net_device *dev);
+int         mv_pp2_eth_stop(struct net_device *dev);
+int         mv_pp2_eth_change_mtu(struct net_device *dev, int mtu);
+int         mv_pp2_check_mtu_internals(struct net_device *dev, int mtu);
+int         mv_pp2_eth_check_mtu_valid(struct net_device *dev, int mtu);
+
+int         mv_pp2_eth_set_mac_addr(struct net_device *dev, void *mac);
+void	    mv_pp2_rx_set_rx_mode(struct net_device *dev);
+int         mv_pp2_eth_open(struct net_device *dev);
+int         mv_pp2_eth_port_suspend(int port);
+int         mv_pp2_port_resume(int port);
+int         mv_pp2_resume_clock(int port);
+int         mv_pp2_suspend_clock(int port);
+int         mv_pp2_eth_suspend_internals(struct eth_port *pp);
+int         mv_pp2_eth_resume_internals(struct eth_port *pp, int mtu);
+int         mv_pp2_restore_registers(struct eth_port *pp, int mtu);
+
+void	    mv_pp2_port_promisc_set(int port);
+
+void        mv_pp2_win_init(void);
+int         mv_pp2_resume_network_interfaces(struct eth_port *pp);
+int         mv_pp2_pm_mode_set(int port, int mode);
+
+irqreturn_t mv_pp2_isr(int irq, void *dev_id);
+irqreturn_t mv_pp2_link_isr(int irq, void *dev_id);
+int         mv_pp2_start_internals(struct eth_port *pp, int mtu);
+int         mv_pp2_stop_internals(struct eth_port *pp);
+int         mv_pp2_eth_change_mtu_internals(struct net_device *netdev, int mtu);
+
+int         mv_pp2_rx_reset(int port);
+int         mv_pp2_txq_clean(int port, int txp, int txq);
+int         mv_pp2_txp_clean(int port, int txp);
+int         mv_pp2_all_ports_cleanup(void);
+int         mv_pp2_all_ports_probe(void);
+
+MV_STATUS   mv_pp2_rx_ptks_coal_set(int port, int rxq, MV_U32 value);
+MV_STATUS   mv_pp2_rx_time_coal_set(int port, int rxq, MV_U32 value);
+MV_STATUS   mv_pp2_tx_done_ptks_coal_set(int port, int txp, int txq, MV_U32 value);
+
+struct eth_port     *mv_pp2_port_by_id(unsigned int port);
+bool                 mv_pp2_eth_netdev_find(unsigned int if_index);
+
+void        mv_pp2_mac_show(int port);
+void        mv_pp2_dscp_map_show(int port);
+int         mv_pp2_rxq_dscp_map_set(int port, int rxq, unsigned char dscp);
+int         mv_pp2_txq_dscp_map_set(int port, int txq, unsigned char dscp);
+
+int         mv_pp2_eth_rxq_vlan_prio_set(int port, int rxq, unsigned char prio);
+void        mv_pp2_eth_vlan_prio_show(int port);
+
+void        mv_pp2_eth_netdev_print(struct net_device *netdev);
+void        mv_pp2_status_print(void);
+void        mv_pp2_eth_port_status_print(unsigned int port);
+void        mv_pp2_port_stats_print(unsigned int port);
+void        mv_pp2_pool_status_print(int pool);
+
+void        mv_pp2_set_noqueue(struct net_device *dev, int enable);
+void	    mv_pp2_ctrl_pnc(int en);
+void        mv_pp2_ctrl_hwf(int en);
+int         mv_pp2_eth_ctrl_recycle(int en);
+void        mv_pp2_ctrl_txdone(int num);
+int         mv_pp2_eth_ctrl_tx_mh(int port, u16 mh);
+
+int         mv_pp2_ctrl_tx_cmd_dsa(int port, u16 dsa);
+int         mv_pp2_ctrl_tx_cmd_color(int port, u16 color);
+int         mv_pp2_ctrl_tx_cmd_gem_id(int port, u16 gem_id);
+int         mv_pp2_ctrl_tx_cmd_pon_fec(int port, u16 pon_fec);
 int         mv_eth_ctrl_tx_cmd_gem_oem(int port, u16 gem_oem);
-int         mv_eth_ctrl_tx_cmd_mod(int port, u16 mod);
-int         mv_eth_ctrl_tx_cmd_pme_dptr(int port, u16 pme_dptr);
-int         mv_eth_ctrl_tx_cmd_pme_prog(int port, u16 pme_prog);
-
-int         mv_eth_ctrl_txq_cpu_def(int port, int txp, int txq, int cpu);
-int         mv_eth_ctrl_flag(int port, u32 flag, u32 val);
-int         mv_eth_ctrl_tx_flag(int port, u32 flag, u32 val);
-int	    mv_eth_ctrl_dbg_flag(int port, u32 flag, u32 val);
-int	    mv_eth_ctrl_txq_size_set(int port, int txp, int txq, int txq_size);
-int         mv_eth_ctrl_txq_limits_set(int port, int txp, int txq, int hwf_size, int swf_size);
-int         mv_eth_ctrl_txq_chunk_set(int port, int txp, int txq, int chunk_size);
-int         mv_eth_ctrl_rxq_size_set(int port, int rxq, int value);
-int	    mv_eth_ctrl_pool_buf_num_set(int pool, int buf_num);
-int         mv_eth_ctrl_pool_detach(int port, struct bm_pool *ppool);
-int         mv_eth_ctrl_pool_size_set(int pool, int pkt_size);
-int	    mv_eth_ctrl_long_pool_set(int port, int pool);
-int	    mv_eth_ctrl_short_pool_set(int port, int pool);
-int	    mv_eth_ctrl_hwf_long_pool_set(int port, int pool);
-int	    mv_eth_ctrl_hwf_short_pool_set(int port, int pool);
-int     mv_eth_ctrl_set_poll_rx_weight(int port, u32 weight);
-int     mv_eth_ctrl_pool_port_map_get(int pool);
-void        mv_eth_tx_desc_print(struct pp2_tx_desc *desc);
-void        mv_eth_pkt_print(struct eth_pbuf *pkt);
-void        mv_eth_rx_desc_print(struct pp2_rx_desc *desc);
-void        mv_eth_skb_print(struct sk_buff *skb);
-void        mv_eth_link_status_print(int port);
-void        mv_eth_buff_hdr_rx_dump(struct eth_port *pp, struct pp2_rx_desc *rx_desc);
-void        mv_eth_buff_hdr_rx(struct eth_port *pp, struct pp2_rx_desc *rx_desc);
+int         mv_pp2_ctrl_tx_cmd_mod(int port, u16 mod);
+int         mv_pp2_ctrl_tx_cmd_pme_dptr(int port, u16 pme_dptr);
+int         mv_pp2_ctrl_tx_cmd_pme_prog(int port, u16 pme_prog);
+
+int         mv_pp2_ctrl_txq_cpu_def(int port, int txp, int txq, int cpu);
+int         mv_pp2_ctrl_flag(int port, u32 flag, u32 val);
+int         mv_pp2_ctrl_tx_flag(int port, u32 flag, u32 val);
+int	    mv_pp2_ctrl_dbg_flag(int port, u32 flag, u32 val);
+int	    mv_pp2_ctrl_txq_size_set(int port, int txp, int txq, int txq_size);
+int         mv_pp2_ctrl_txq_limits_set(int port, int txp, int txq, int hwf_size, int swf_size);
+int         mv_pp2_ctrl_txq_chunk_set(int port, int txp, int txq, int chunk_size);
+int         mv_pp2_ctrl_rxq_size_set(int port, int rxq, int value);
+int	    mv_pp2_ctrl_pool_buf_num_set(int pool, int buf_num);
+int         mv_pp2_ctrl_pool_detach(int port, struct bm_pool *ppool);
+int         mv_pp2_ctrl_pool_size_set(int pool, int pkt_size);
+int	    mv_pp2_ctrl_long_pool_set(int port, int pool);
+int	    mv_pp2_ctrl_short_pool_set(int port, int pool);
+int	    mv_pp2_ctrl_hwf_long_pool_set(int port, int pool);
+int	    mv_pp2_ctrl_hwf_short_pool_set(int port, int pool);
+int     mv_pp2_ctrl_set_poll_rx_weight(int port, u32 weight);
+int     mv_pp2_ctrl_pool_port_map_get(int pool);
+void        mv_pp2_tx_desc_print(struct pp2_tx_desc *desc);
+void        mv_pp2_pkt_print(struct eth_pbuf *pkt);
+void        mv_pp2_rx_desc_print(struct pp2_rx_desc *desc);
+void        mv_pp2_skb_print(struct sk_buff *skb);
+void        mv_pp2_eth_link_status_print(int port);
+void        mv_pp2_buff_hdr_rx_dump(struct eth_port *pp, struct pp2_rx_desc *rx_desc);
+void        mv_pp2_buff_hdr_rx(struct eth_port *pp, struct pp2_rx_desc *rx_desc);
 
 /* External MAC support (i.e. PON) */
 /* callback functions to be called by netdev (implemented in external MAC module) */
@@ -998,46 +999,46 @@ MV_STATUS mv_pon_enable(void);
 MV_STATUS mv_pon_disable(void);
 #endif
 
-#ifdef CONFIG_MV_ETH_TX_SPECIAL
-void        mv_eth_tx_special_check_func(int port, int (*func)(int port, struct net_device *dev,
-				  struct sk_buff *skb, struct mv_eth_tx_spec *tx_spec_out));
-#endif /* CONFIG_MV_ETH_TX_SPECIAL */
+#ifdef CONFIG_MV_PP2_TX_SPECIAL
+void        mv_pp2_tx_special_check_func(int port, int (*func)(int port, struct net_device *dev,
+				  struct sk_buff *skb, struct mv_pp2_tx_spec *tx_spec_out));
+#endif /* CONFIG_MV_PP2_TX_SPECIAL */
 
-#ifdef CONFIG_MV_ETH_RX_SPECIAL
-void        mv_eth_rx_special_proc_func(int port, int (*func)(int port, int rxq, struct net_device *dev,
+#ifdef CONFIG_MV_PP2_RX_SPECIAL
+void        mv_pp2_rx_special_proc_func(int port, int (*func)(int port, int rxq, struct net_device *dev,
 							struct sk_buff *skb, struct pp2_rx_desc *rx_desc));
-#endif /* CONFIG_MV_ETH_RX_SPECIAL */
+#endif /* CONFIG_MV_PP2_RX_SPECIAL */
 
-int  mv_eth_poll(struct napi_struct *napi, int budget);
-void mv_eth_link_event(struct eth_port *pp, int print);
+int  mv_pp2_poll(struct napi_struct *napi, int budget);
+void mv_pp2_link_event(struct eth_port *pp, int print);
 
-int mv_eth_rx_policy(u32 cause);
-int mv_eth_refill(struct bm_pool *ppool, __u32 bm, int is_recycle);
-u32 mv_eth_txq_done(struct eth_port *pp, struct tx_queue *txq_ctrl);
-u32 mv_eth_tx_done_gbe(struct eth_port *pp, u32 cause_tx_done, int *tx_todo);
-u32 mv_eth_tx_done_pon(struct eth_port *pp, int *tx_todo);
+int mv_pp2_rx_policy(u32 cause);
+int mv_pp2_refill(struct bm_pool *ppool, __u32 bm, int is_recycle);
+u32 mv_pp2_txq_done(struct eth_port *pp, struct tx_queue *txq_ctrl);
+u32 mv_pp2_tx_done_gbe(struct eth_port *pp, u32 cause_tx_done, int *tx_todo);
+u32 mv_pp2_tx_done_pon(struct eth_port *pp, int *tx_todo);
 
 
 /*****************************************
  *            NAPI Group API             *
  *****************************************/
-int  mv_eth_port_napi_group_create(int port, int group);
-int  mv_eth_port_napi_group_delete(int port, int group);
-int  mv_eth_napi_set_cpu_affinity(int port, int group, int cpu_mask);
-int  mv_eth_napi_set_rxq_affinity(int port, int group, int rxq_mask);
-void mv_eth_napi_groups_print(int port);
+int  mv_pp2_port_napi_group_create(int port, int group);
+int  mv_pp2_port_napi_group_delete(int port, int group);
+int  mv_pp2_napi_set_cpu_affinity(int port, int group, int cpu_mask);
+int  mv_pp2_eth_napi_set_rxq_affinity(int port, int group, int rxq_mask);
+void mv_pp2_napi_groups_print(int port);
 
-struct pp2_rx_desc *mv_eth_rx_prefetch(struct eth_port *pp,
+struct pp2_rx_desc *mv_pp2_rx_prefetch(struct eth_port *pp,
 					MV_PP2_PHYS_RXQ_CTRL *rx_ctrl, int rx_done, int rx_todo);
 
-void		*mv_eth_bm_pool_create(int pool, int capacity, MV_ULONG *physAddr);
+void		*mv_pp2_bm_pool_create(int pool, int capacity, MV_ULONG *physAddr);
 
-#if defined(CONFIG_MV_ETH_HWF) && !defined(CONFIG_MV_ETH_BM_CPU)
-MV_STATUS mv_eth_hwf_bm_create(int port, int mtuPktSize);
+#if defined(CONFIG_MV_PP2_HWF) && !defined(CONFIG_MV_ETH_BM_CPU)
+MV_STATUS mv_pp2_hwf_bm_create(int port, int mtuPktSize);
 void      mv_hwf_bm_dump(void);
-#endif /* CONFIG_MV_ETH_HWF && !CONFIG_MV_ETH_BM_CPU */
+#endif /* CONFIG_MV_PP2_HWF && !CONFIG_MV_ETH_BM_CPU */
 
-#ifdef CONFIG_MV_ETH_SWF_HWF_CORRUPTION_WA
+#ifdef CONFIG_MV_PP2_SWF_HWF_CORRUPTION_WA
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 34)
 extern void ___dma_single_dev_to_cpu(const void *, size_t, enum dma_data_direction);
 #else
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_pp2_netmap.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_pp2_netmap.h
index 37b68af..e23b5e5 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_pp2_netmap.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_pp2_netmap.h
@@ -51,14 +51,14 @@ static int mv_pp2_netmap_reg(struct ifnet *ifp, int onoff)
 		return -EINVAL;
 
 	if (!(ifp->flags & IFF_UP)) {
-		/* mv_eth_open has not been called yet, so resources
+		/* mv_pp2_eth_open has not been called yet, so resources
 		 * are not allocated */
 		printk(KERN_ERR "Interface is down!");
 		return -EINVAL;
 	}
 
 	/* stop current interface */
-	if (mv_eth_stop(ifp)) {
+	if (mv_pp2_eth_stop(ifp)) {
 		printk(KERN_ERR "%s: stop interface failed\n", ifp->name);
 		return -EINVAL;
 	}
@@ -66,13 +66,13 @@ static int mv_pp2_netmap_reg(struct ifnet *ifp, int onoff)
 	if (onoff) { /* enable netmap mode */
 		u32 port_map;
 
-		mv_eth_rx_reset(adapter->port);
+		mv_pp2_rx_reset(adapter->port);
 		ifp->if_capenable |= IFCAP_NETMAP;
 		na->if_transmit = (void *)ifp->netdev_ops;
 		ifp->netdev_ops = &na->nm_ndo;
 
 		/* check that long pool is not shared with other ports */
-		port_map =  mv_eth_ctrl_pool_port_map_get(adapter->pool_long->pool);
+		port_map =  mv_pp2_ctrl_pool_port_map_get(adapter->pool_long->pool);
 		if (port_map != (1 << adapter->port)) {
 			printk(KERN_ERR "%s: BM pool %d not initialized or shared with other ports.\n",
 			__func__, adapter->pool_long->pool);
@@ -81,10 +81,10 @@ static int mv_pp2_netmap_reg(struct ifnet *ifp, int onoff)
 
 		/* Keep old number of long pool buffers */
 		pool_buf_num[adapter->pool_long->pool] = adapter->pool_long->buf_num;
-		mv_eth_pool_free(adapter->pool_long->pool, adapter->pool_long->buf_num);
+		mv_pp2_pool_free(adapter->pool_long->pool, adapter->pool_long->buf_num);
 
 		/* set same pool number for short and long packets */
-		for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++)
+		for (rxq = 0; rxq < CONFIG_MV_PP2_RXQ; rxq++)
 			mvPp2RxqBmShortPoolSet(adapter->port, rxq, adapter->pool_long->pool);
 
 		/* update short pool in software */
@@ -99,11 +99,11 @@ static int mv_pp2_netmap_reg(struct ifnet *ifp, int onoff)
 
 		ifp->if_capenable &= ~IFCAP_NETMAP;
 		ifp->netdev_ops = (void *)na->if_transmit;
-		mv_eth_rx_reset(adapter->port);
+		mv_pp2_rx_reset(adapter->port);
 
 		/* TODO: handle SMP - each CPU must call this loop */
 		/*
-		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++)
+		for (txq = 0; txq < CONFIG_MV_PP2_TXQ; txq++)
 			mvPp2TxqSentDescProc(adapter->port, 0, txq);
 		*/
 
@@ -116,10 +116,10 @@ static int mv_pp2_netmap_reg(struct ifnet *ifp, int onoff)
 
 		MV_ETH_UNLOCK(&adapter->pool_long->lock, flags);
 		printk(KERN_ERR "NETMAP: free %d buffers from pool %d\n", i, adapter->pool_long->pool);
-		mv_eth_pool_add(adapter->pool_long->pool, pool_buf_num[adapter->pool_long->pool]);
+		mv_pp2_pool_add(adapter->pool_long->pool, pool_buf_num[adapter->pool_long->pool]);
 
 		/* set port's short pool for Linux driver */
-		for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++)
+		for (rxq = 0; rxq < CONFIG_MV_PP2_RXQ; rxq++)
 			mvPp2RxqBmShortPoolSet(adapter->port, rxq, adapter->pool_short->pool);
 
 		/* update short pool in software */
@@ -128,7 +128,7 @@ static int mv_pp2_netmap_reg(struct ifnet *ifp, int onoff)
 		clear_bit(MV_ETH_F_IFCAP_NETMAP_BIT, &(adapter->flags));
 	}
 
-	if (mv_eth_start(ifp)) {
+	if (mv_pp2_start(ifp)) {
 		printk(KERN_ERR "%s: start interface failed\n", ifp->name);
 		return -EINVAL;
 	}
@@ -187,7 +187,7 @@ mv_pp2_netmap_txsync(struct ifnet *ifp, u_int ring_nr, int do_lock)
 			slot->flags &= ~NS_REPORT;
 
 			/* check aggregated TXQ resource */
-			if (mv_eth_aggr_desc_num_check(aggr_txq_ctrl, 1)) {
+			if (mv_pp2_aggr_desc_num_check(aggr_txq_ctrl, 1)) {
 				if (do_lock)
 					mtx_unlock(&kring->q_lock);
 				return netmap_ring_reinit(kring);
@@ -199,7 +199,7 @@ mv_pp2_netmap_txsync(struct ifnet *ifp, u_int ring_nr, int do_lock)
 			tx_desc->dataSize = len;
 			tx_desc->pktOffset = slot->data_offs;
 			tx_desc->command = PP2_TX_L4_CSUM_NOT | PP2_TX_F_DESC_MASK | PP2_TX_L_DESC_MASK;
-			mv_eth_tx_desc_flush(tx_desc);
+			mv_pp2_tx_desc_flush(tx_desc);
 			aggr_txq_ctrl->txq_count++;
 
 			if (slot->flags & NS_BUF_CHANGED)
@@ -437,7 +437,7 @@ static int pp2_netmap_txq_init_buffers(struct SOFTC_T *adapter, int txp, int txq
 	if (!(adapter->flags & MV_ETH_F_IFCAP_NETMAP))
 		return 0;
 
-	q = txp * CONFIG_MV_ETH_TXQ + txq;
+	q = txp * CONFIG_MV_PP2_TXQ + txq;
 
 	/* initialize the tx ring */
 	slot = netmap_reset(na, NR_TX, q, 0);
@@ -465,8 +465,8 @@ mv_pp2_netmap_attach(struct SOFTC_T *adapter)
 	na.nm_register = mv_pp2_netmap_reg;
 	na.nm_txsync = mv_pp2_netmap_txsync;
 	na.nm_rxsync = mv_pp2_netmap_rxsync;
-	na.num_tx_rings = CONFIG_MV_ETH_TXQ;
-	netmap_attach(&na, CONFIG_MV_ETH_RXQ);
+	na.num_tx_rings = CONFIG_MV_PP2_TXQ;
+	netmap_attach(&na, CONFIG_MV_PP2_RXQ);
 }
 /* end of file */
 
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_tpm/src/core/tpm_cls.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_tpm/src/core/tpm_cls.c
index 851e3e1..cde59c4 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_tpm/src/core/tpm_cls.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_tpm/src/core/tpm_cls.c
@@ -1596,7 +1596,7 @@ static int tpm_cls_rx_qh_init(void)
 	/* Set queue high of different port, GMAC0, GMAC1, and PON */
 	for (eth_port = 0; eth_port <= TPM_NUM_MAX_GMAC_PORTS; eth_port++) {
 
-		eth_pp = mv_eth_port_by_id(eth_port);
+		eth_pp = mv_pp2_port_by_id(eth_port);
 		phy_port = MV_PPV2_PORT_PHYS(eth_port);
 		if (eth_pp == NULL) {
 			TPM_OS_INFO(TPM_CLS_MOD, "port #%d, phy #%d is not initialized\n", eth_port, phy_port);
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_tpm/src/core/tpm_policer.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_tpm/src/core/tpm_policer.c
index 11d3ada..9a8a064 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_tpm/src/core/tpm_policer.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_tpm/src/core/tpm_policer.c
@@ -747,7 +747,7 @@ int tpm_sched_egr_mtu_set(enum tpm_gmac_idx_t gmac_idx,
 		TPM_OS_ERROR(TPM_PLCR_MOD, "Invalid GMAC index %d\n", gmac_idx);
 		return TPM_BAD_PARAM;
 	}
-	if (tcont_id >= MV_ETH_MAX_TCONT) {
+	if (tcont_id >= MV_PP2_MAX_TCONT) {
 		TPM_OS_ERROR(TPM_PLCR_MOD, "Invalid tcont %d\n", tcont_id);
 		return TPM_BAD_PARAM;
 	}
@@ -797,7 +797,7 @@ int tpm_sched_egr_queue_mode_set(enum tpm_gmac_idx_t gmac_idx,
 		TPM_OS_ERROR(TPM_PLCR_MOD, "Invalid GMAC index %d\n", gmac_idx);
 		return TPM_BAD_PARAM;
 	}
-	if (tcont_id >= MV_ETH_MAX_TCONT) {
+	if (tcont_id >= MV_PP2_MAX_TCONT) {
 		TPM_OS_ERROR(TPM_PLCR_MOD, "Invalid tcont %d\n", tcont_id);
 		return TPM_BAD_PARAM;
 	}
@@ -805,7 +805,7 @@ int tpm_sched_egr_queue_mode_set(enum tpm_gmac_idx_t gmac_idx,
 		TPM_OS_ERROR(TPM_PLCR_MOD, "Invalid WRR weight %d\n", wrr_weight);
 		return TPM_BAD_PARAM;
 	}
-	if (queue_id >= MV_ETH_MAX_TXQ) {
+	if (queue_id >= MV_PP2_MAX_TXQ) {
 		TPM_OS_ERROR(TPM_PLCR_MOD, "Invalid queue %d\n", queue_id);
 		return TPM_BAD_PARAM;
 	}
@@ -878,11 +878,11 @@ int tpm_sched_egr_queue_rate_lim_set(enum tpm_gmac_idx_t gmac_idx,
 		TPM_OS_ERROR(TPM_PLCR_MOD, "Invalid GMAC index %d\n", gmac_idx);
 		return TPM_BAD_PARAM;
 	}
-	if (tcont_id >= MV_ETH_MAX_TCONT) {
+	if (tcont_id >= MV_PP2_MAX_TCONT) {
 		TPM_OS_ERROR(TPM_PLCR_MOD, "Invalid tcont %d\n", tcont_id);
 		return TPM_BAD_PARAM;
 	}
-	if (queue_id >= MV_ETH_MAX_TXQ) {
+	if (queue_id >= MV_PP2_MAX_TXQ) {
 		TPM_OS_ERROR(TPM_PLCR_MOD, "Invalid queue %d\n", queue_id);
 		return TPM_BAD_PARAM;
 	}
@@ -942,7 +942,7 @@ int tpm_sched_egr_port_rate_lim_set(enum tpm_gmac_idx_t gmac_idx,
 		TPM_OS_ERROR(TPM_PLCR_MOD, "Invalid GMAC index %d\n", gmac_idx);
 		return TPM_BAD_PARAM;
 	}
-	if (tcont_id >= MV_ETH_MAX_TCONT) {
+	if (tcont_id >= MV_PP2_MAX_TCONT) {
 		TPM_OS_ERROR(TPM_PLCR_MOD, "Invalid tcont %d\n", tcont_id);
 		return TPM_BAD_PARAM;
 	}
diff --git a/arch/arm/plat-armada/mv_hal/neta/gbe/mvNeta.h b/arch/arm/plat-armada/mv_hal/neta/gbe/mvNeta.h
index 9e158c3..f928ffc 100644
--- a/arch/arm/plat-armada/mv_hal/neta/gbe/mvNeta.h
+++ b/arch/arm/plat-armada/mv_hal/neta/gbe/mvNeta.h
@@ -79,11 +79,11 @@ extern "C" {
 # include "pnc/mvPnc.h"
 #endif /* CONFIG_MV_ETH_PNC */
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
+#ifdef CONFIG_MV_NETA_DEBUG_CODE
 # define mvNetaDebugPrintf      mvOsPrintf
 #else
 # define mvNetaDebugPrintf(msg, ...)
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+#endif /* CONFIG_MV_NETA_DEBUG_CODE */
 
 #ifndef MV_ETH_MAX_TCONT
 # define MV_ETH_MAX_TCONT 1
diff --git a/arch/arm/plat-armada/mv_hal/pp2/cls/mvPp2ClsHw.c b/arch/arm/plat-armada/mv_hal/pp2/cls/mvPp2ClsHw.c
index 5076857..ddd078d 100644
--- a/arch/arm/plat-armada/mv_hal/pp2/cls/mvPp2ClsHw.c
+++ b/arch/arm/plat-armada/mv_hal/pp2/cls/mvPp2ClsHw.c
@@ -259,8 +259,8 @@ int mvPp2V0ClsHwMtuSet(int port, int txp, int mtu)
 
 	POS_RANGE_VALIDATE(mtu, MV_PP2_CLS_MTU_MAX);
 
-	if (port == MV_PON_PORT_ID)  {/*pon*/
-		POS_RANGE_VALIDATE(txp, MV_ETH_MAX_TCONT - 1); /*txq num in pon*/
+	if (port == MV_PP2_PON_PORT_ID)  {/*pon*/
+		POS_RANGE_VALIDATE(txp, MV_PP2_MAX_TCONT - 1); /*txq num in pon*/
 		eport = txp; /* regs 0 - 15 for pon txq */
 	} else {
 		POS_RANGE_VALIDATE(port, ETH_PORTS_NUM - 1);
@@ -336,7 +336,7 @@ int mvPp2ClsHwMhSet(int port, int virtEn, int uniEn, unsigned short mh)
 	BIT_RANGE_VALIDATE(virtEn);
 	POS_RANGE_VALIDATE(mh, MV_PP2_CLS_PCTRL_MH_MASK);
 
-	if (MV_PON_PORT(port))
+	if (MV_PP2_IS_PON_PORT(port))
 		regVal = uniDisable << MV_PP2_CLS_PCTRL_UNI_EN_OFFS;
 	else
 		regVal = (uniDisable << MV_PP2_CLS_PCTRL_UNI_EN_OFFS) |
@@ -1075,7 +1075,7 @@ int mvPp2ClsHwRegsDump()
 		mvPp2PrintReg(MV_PP2_CLS_PCTRL_REG(i), reg_name);
 	}
 #else
-	for (i = 0; i < (MV_ETH_MAX_TCONT + MV_PP2_MAX_PORTS - 1); i++) {
+	for (i = 0; i < (MV_PP2_MAX_TCONT + MV_PP2_MAX_PORTS - 1); i++) {
 		mvOsSPrintf(reg_name, "MV_PP2_CLS_MTU_%d_REG", i);
 		mvPp2PrintReg(MV_PP2_CLS_MTU_REG(i), reg_name);
 	}
diff --git a/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2Gbe.c b/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2Gbe.c
index 0fd9c9b..b794cfa 100644
--- a/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2Gbe.c
+++ b/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2Gbe.c
@@ -118,7 +118,7 @@ int mvPp2TxpCheck(int port, int txp)
 	if (mvPp2PortCheck(port))
 		return 1;
 
-	if (MV_PON_PORT(port))
+	if (MV_PP2_IS_PON_PORT(port))
 		txpMax = mvPp2HalData.maxTcont;
 
 	return mvPp2MaxCheck(txp, txpMax, "txp");
@@ -131,9 +131,14 @@ int mvPp2CpuCheck(int cpu)
 
 int mvPp2EgressPort(int port, int txp)
 {
-	if (!MV_PON_PORT(port))
-		return (MV_ETH_MAX_TCONT + port + txp);
-	return txp;
+	int egress_port;
+
+	if (!MV_PP2_IS_PON_PORT(port))
+		egress_port = MV_PP2_MAX_TCONT + port + txp;
+	else
+		egress_port = txp;
+
+	return egress_port;
 }
 /*-------------------------------------------------------------------------------*/
 MV_STATUS mvPp2HalInit(MV_PP2_HAL_DATA *halData)
@@ -181,7 +186,7 @@ MV_STATUS mvPp2HalInit(MV_PP2_HAL_DATA *halData)
 	mvPp2RxFifoInit(mvPp2HalData.maxPort);
 
 	/* Init all interrupt rxqs groups - each port has 0 rxqs */
-	for (i = 0; i <= MV_PON_PORT_ID; i++)
+	for (i = 0; i <= MV_PP2_PON_PORT_ID; i++)
 		mvPp2GbeIsrRxqGroup(i, 0);
 
 	MV_REG_WRITE(ETH_MNG_EXTENDED_GLOBAL_CTRL_REG, 0x27);
@@ -232,7 +237,7 @@ MV_STATUS mvPp2DefaultsSet(int port)
 	int txp, queue, txPortNum, i;
 	MV_PP2_PORT_CTRL *pPortCtrl = mvPp2PortHndlGet(port);
 
-	if (!MV_PON_PORT(port))
+	if (!MV_PP2_IS_PON_PORT(port))
 		mvGmacDefaultsSet(port);
 
 	/* avoid unused variable compilation warninig */
@@ -246,7 +251,7 @@ MV_STATUS mvPp2DefaultsSet(int port)
 
 		mvPp2WrReg(MV_PP2_TXP_SCHED_CMD_1_REG, 0);
 		/* Close bandwidth for all queues */
-		for (queue = 0; queue < MV_ETH_MAX_TXQ; queue++)
+		for (queue = 0; queue < MV_PP2_MAX_TXQ; queue++)
 			mvPp2WrReg(MV_PP2_TXQ_SCHED_TOKEN_CNTR_REG(MV_PPV2_TXQ_PHYS(port, txp, queue)), 0);
 
 		/* Set refill period to 1 usec, refill tokens and bucket size to maximum */
@@ -290,13 +295,13 @@ MV_STATUS mvPp2PhysRxqMapAdd(int prxq, int port, int lrxq)
 		mvOsPrintf("Bad port number: %d\n", port);
 		return MV_BAD_PARAM;
 	}
-	if (lrxq < 0 || lrxq > MV_ETH_MAX_RXQ) {
+	if (lrxq < 0 || lrxq > MV_PP2_MAX_RXQ) {
 		mvOsPrintf("Bad logical RXQ number: %d\n", lrxq);
 		return MV_BAD_PARAM;
 	}
 	if (mvPp2PhysRxqs == NULL)
 		return MV_ERROR;
-	if (prxq < 0 || prxq >= MV_ETH_RXQ_TOTAL_NUM)
+	if (prxq < 0 || prxq >= MV_PP2_RXQ_TOTAL_NUM)
 		return MV_BAD_PARAM;
 	if (mvPp2PhysRxqs[prxq].port != MV_PP2_RXQ_FREE || mvPp2PhysRxqs[prxq].logicRxq != MV_PP2_RXQ_FREE)
 		return MV_BAD_PARAM;
@@ -305,9 +310,9 @@ MV_STATUS mvPp2PhysRxqMapAdd(int prxq, int port, int lrxq)
 	/* map prxq <- (port, lrxq) */
 	if (pCtrl == NULL || pCtrl->pRxQueue == NULL)
 		return MV_BAD_PARAM;
-	if (lrxq < 0 || lrxq >= MV_ETH_MAX_RXQ)
+	if (lrxq < 0 || lrxq >= MV_PP2_MAX_RXQ)
 		return MV_BAD_PARAM;
-	if (pCtrl->rxqNum >= MV_ETH_MAX_RXQ)
+	if (pCtrl->rxqNum >= MV_PP2_MAX_RXQ)
 		return MV_FAIL;
 
 	pCtrl->pRxQueue[lrxq] = &mvPp2PhysRxqs[prxq];
@@ -327,7 +332,7 @@ MV_STATUS mvPp2PhysRxqMapDel(int prxq)
 
 	if (mvPp2PhysRxqs == NULL)
 		return MV_ERROR;
-	if (prxq < 0 || prxq >= MV_ETH_RXQ_TOTAL_NUM)
+	if (prxq < 0 || prxq >= MV_PP2_RXQ_TOTAL_NUM)
 		return MV_BAD_PARAM;
 
 	port = mvPp2PhysRxqs[prxq].port;
@@ -352,7 +357,7 @@ MV_STATUS mvPp2PortLogicRxqMapDel(int port, int lrxq)
 		mvOsPrintf("Bad port number: %d\n", port);
 		return MV_BAD_PARAM;
 	}
-	if (lrxq < 0 || lrxq > MV_ETH_MAX_RXQ) {
+	if (lrxq < 0 || lrxq > MV_PP2_MAX_RXQ) {
 		mvOsPrintf("Bad logical RXQ number: %d\n", lrxq);
 		return MV_BAD_PARAM;
 	}
@@ -512,18 +517,18 @@ MV_STATUS mvPp2PhysRxqsAlloc(MV_VOID)
 {
 	int i, bytes;
 
-	bytes = MV_ETH_RXQ_TOTAL_NUM * sizeof(MV_PP2_PHYS_RXQ_CTRL);
+	bytes = MV_PP2_RXQ_TOTAL_NUM * sizeof(MV_PP2_PHYS_RXQ_CTRL);
 	mvPp2PhysRxqs = mvOsMalloc(bytes);
 
 	if (!mvPp2PhysRxqs) {
 		mvOsPrintf("mvPp2 Can't allocate %d Bytes for %d RXQs controls\n",
-			   bytes, MV_ETH_RXQ_TOTAL_NUM);
+			   bytes, MV_PP2_RXQ_TOTAL_NUM);
 		return MV_OUT_OF_CPU_MEM;
 	}
 
 	memset(mvPp2PhysRxqs, 0, bytes);
 
-	for (i = 0; i < MV_ETH_RXQ_TOTAL_NUM; i++) {
+	for (i = 0; i < MV_PP2_RXQ_TOTAL_NUM; i++) {
 		mvPp2PhysRxqs[i].port = MV_PP2_RXQ_FREE;
 		mvPp2PhysRxqs[i].logicRxq = MV_PP2_RXQ_FREE;
 		mvPp2PhysRxqs[i].rxq = i;
@@ -546,7 +551,7 @@ MV_STATUS mvPp2PortRxqsInit(int port, int firstRxq, int numRxqs)
 	int i;
 	MV_PP2_PORT_CTRL *pCtrl = mvPp2PortCtrl[port];
 
-	if (firstRxq < 0 || firstRxq + numRxqs > MV_ETH_RXQ_TOTAL_NUM) {
+	if (firstRxq < 0 || firstRxq + numRxqs > MV_PP2_RXQ_TOTAL_NUM) {
 		mvOsPrintf("%s: Bad RXQ parameters. first RXQ = %d,  num of RXQS = %d\n", __func__, firstRxq, numRxqs);
 		return MV_BAD_PARAM;
 	}
@@ -560,11 +565,11 @@ MV_STATUS mvPp2PortRxqsInit(int port, int firstRxq, int numRxqs)
 
 	/* Allocate logical RXQs */
 	if (!pCtrl->pRxQueue)
-		pCtrl->pRxQueue = mvOsMalloc(MV_ETH_MAX_RXQ * sizeof(MV_PP2_PHYS_RXQ_CTRL *));
+		pCtrl->pRxQueue = mvOsMalloc(MV_PP2_MAX_RXQ * sizeof(MV_PP2_PHYS_RXQ_CTRL *));
 	if (!pCtrl->pRxQueue)
 		return MV_OUT_OF_CPU_MEM;
 
-	mvOsMemset(pCtrl->pRxQueue, 0, (MV_ETH_MAX_RXQ * sizeof(MV_PP2_PHYS_RXQ_CTRL *)));
+	mvOsMemset(pCtrl->pRxQueue, 0, (MV_PP2_MAX_RXQ * sizeof(MV_PP2_PHYS_RXQ_CTRL *)));
 
 	/* Associate requested RXQs with port */
 	for (i = firstRxq; i < firstRxq + numRxqs; i++)
@@ -677,11 +682,11 @@ MV_PP2_PHYS_TXQ_CTRL *mvPp2TxqInit(int port, int txp, int txq, int descNum, int
 	/* TCONTS for PON port must be continious from 0 to mvPp2HalData.maxTcont */
 	/* GBE ports assumed to be continious from 0 to (mvPp2HalData.maxPort - 1) */
 	descPerTxq = 16;
-	if (MV_PON_PORT(port))
+	if (MV_PP2_IS_PON_PORT(port))
 		desc = ptxq * descPerTxq;
 	else
-		desc = (mvPp2HalData.maxTcont * MV_ETH_MAX_TXQ * descPerTxq) +
-			(port * MV_ETH_MAX_TXQ * descPerTxq) + (txq * descPerTxq);
+		desc = (mvPp2HalData.maxTcont * MV_PP2_MAX_TXQ * descPerTxq) +
+			(port * MV_PP2_MAX_TXQ * descPerTxq) + (txq * descPerTxq);
 
 	mvPp2WrReg(MV_PP2_TXQ_PREF_BUF_REG, MV_PP2_PREF_BUF_PTR(desc) | MV_PP2_PREF_BUF_SIZE_16 |
 				MV_PP2_PREF_BUF_THRESH(descPerTxq/2));
@@ -762,7 +767,7 @@ MV_STATUS mvPp2PortTxqsInit(int port)
 	for (txp = 0; txp < pCtrl->txpNum; txp++) {
 		for (txq = 0; txq < pCtrl->txqNum; txq++) {
 			ptxq = MV_PPV2_TXQ_PHYS(port, txp, txq);
-			pCtrl->pTxQueue[txp * CONFIG_MV_ETH_TXQ + txq] = &mvPp2PhysTxqs[ptxq];
+			pCtrl->pTxQueue[txp * CONFIG_MV_PP2_TXQ + txq] = &mvPp2PhysTxqs[ptxq];
 		}
 	}
 
@@ -976,11 +981,11 @@ void *mvPp2PortInit(int port, int firstRxq, int numRxqs, void *osHandle)
 
 	/* associate TXQs to this port */
 #ifdef CONFIG_MV_INCLUDE_PON
-	pCtrl->txpNum = MV_PON_PORT(port) ? mvPp2HalData.maxTcont : 1;
+	pCtrl->txpNum = MV_PP2_IS_PON_PORT(port) ? mvPp2HalData.maxTcont : 1;
 #else
 	pCtrl->txpNum = 1;
 #endif
-	pCtrl->txqNum = CONFIG_MV_ETH_TXQ;
+	pCtrl->txqNum = CONFIG_MV_PP2_TXQ;
 	status = mvPp2PortTxqsInit(port);
 	if (status != MV_OK)
 		return NULL;
@@ -1055,7 +1060,7 @@ MV_STATUS mvPp2PortEgressEnable(int port, MV_BOOL en)
 
 MV_STATUS mvPp2PortEnable(int port, MV_BOOL en)
 {
-	if (!MV_PON_PORT(port)) {
+	if (!MV_PP2_IS_PON_PORT(port)) {
 		/* Enable port */
 		if (en)
 			mvGmacPortEnable(port);
@@ -1391,7 +1396,7 @@ unsigned int mvPp2RxqTimeCoalGet(int port, int rxq)
  *  - isTxDoneIsr: if 0 then Tx Done interruptare not unmasked */
 MV_STATUS mvPp2GbeIsrRxTxUnmask(int port, MV_U16 rxq_mask, int isTxDoneIsr)
 {
-	if (MV_PON_PORT(port)) {
+	if (MV_PP2_IS_PON_PORT(port)) {
 		mvPp2WrReg(MV_PP2_ISR_PON_RX_TX_MASK_REG,
 			(MV_PP2_PON_CAUSE_MISC_SUM_MASK |
 			((isTxDoneIsr) ? MV_PP2_PON_CAUSE_TXP_OCCUP_DESC_ALL_MASK : 0) |
@@ -1409,7 +1414,7 @@ MV_STATUS mvPp2GbeIsrRxTxUnmask(int port, MV_U16 rxq_mask, int isTxDoneIsr)
 /* mask the current CPU's rx/tx interrupts */
 MV_STATUS mvPp2GbeIsrRxTxMask(int port)
 {
-	if (MV_PON_PORT(port))
+	if (MV_PP2_IS_PON_PORT(port))
 		mvPp2WrReg(MV_PP2_ISR_PON_RX_TX_MASK_REG, 0);
 	else
 		mvPp2WrReg(MV_PP2_ISR_RX_TX_MASK_REG(MV_PPV2_PORT_PHYS(port)), 0);
@@ -1419,9 +1424,9 @@ MV_STATUS mvPp2GbeIsrRxTxMask(int port)
 
 MV_STATUS mvPp2GbeIsrRxqGroup(int port, int rxqNum)
 {
-	if ((rxqNum % 4 != 0) || (rxqNum > MV_ETH_MAX_RXQ)) {
+	if ((rxqNum % 4 != 0) || (rxqNum > MV_PP2_MAX_RXQ)) {
 		mvOsPrintf("%s: bad number of rxqs - %d.  Must be multiple of 4 and less than %d\n",
-			__func__, rxqNum, MV_ETH_MAX_RXQ);
+			__func__, rxqNum, MV_PP2_MAX_RXQ);
 		return MV_BAD_PARAM;
 	}
 
@@ -1600,7 +1605,7 @@ MV_STATUS   mvPp2TxqRateSet(int port, int txp, int txq, int rate)
 	if (mvPp2TxpCheck(port, txp))
 		return MV_BAD_PARAM;
 
-	if (txq >= MV_ETH_MAX_TXQ)
+	if (txq >= MV_PP2_MAX_TXQ)
 		return MV_BAD_PARAM;
 
 	status = mvPp2RateCalc(rate, accuracy, &period, &tokens);
@@ -1644,7 +1649,7 @@ MV_STATUS mvPp2TxqBurstSet(int port, int txp, int txq, int burst)
 	if (mvPp2TxpCheck(port, txp))
 		return MV_BAD_PARAM;
 
-	if (txq >= MV_ETH_MAX_TXQ)
+	if (txq >= MV_PP2_MAX_TXQ)
 		return MV_BAD_PARAM;
 
 	txPortNum = mvPp2EgressPort(port, txp);
@@ -1678,7 +1683,7 @@ MV_STATUS mvPp2TxqFixPrioSet(int port, int txp, int txq)
 	if (mvPp2TxpCheck(port, txp))
 		return MV_BAD_PARAM;
 
-	if (txq >= MV_ETH_MAX_TXQ)
+	if (txq >= MV_PP2_MAX_TXQ)
 		return MV_BAD_PARAM;
 
 	txPortNum = mvPp2EgressPort(port, txp);
@@ -1701,7 +1706,7 @@ MV_STATUS mvPp2TxqWrrPrioSet(int port, int txp, int txq, int weight)
 	if (mvPp2TxpCheck(port, txp))
 		return MV_BAD_PARAM;
 
-	if (txq >= MV_ETH_MAX_TXQ)
+	if (txq >= MV_PP2_MAX_TXQ)
 		return MV_BAD_PARAM;
 
 	txPortNum = mvPp2EgressPort(port, txp);
@@ -1773,7 +1778,7 @@ MV_STATUS   mvPp2TxpMaxTxSizeSet(int port, int txp, int maxTxSize)
 		regVal |= size;
 		mvPp2WrReg(MV_PP2_TXP_SCHED_TOKEN_SIZE_REG, regVal);
 	}
-	for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++) {
+	for (txq = 0; txq < CONFIG_MV_PP2_TXQ; txq++) {
 		regVal = mvPp2RdReg(MV_PP2_TXQ_SCHED_TOKEN_SIZE_REG(txq));
 		size = regVal & MV_PP2_TXQ_TOKEN_SIZE_MAX;
 		if (size < mtu) {
@@ -1827,7 +1832,7 @@ MV_STATUS mvPp2TxpEnable(int port, int txp)
 	/* Enable all initialized TXs. */
 	qMap = 0;
 	for (txq = 0; txq < pPortCtrl->txqNum; txq++) {
-		if (pPortCtrl->pTxQueue[txp * CONFIG_MV_ETH_TXQ + txq] != NULL)
+		if (pPortCtrl->pTxQueue[txp * CONFIG_MV_PP2_TXQ + txq] != NULL)
 			qMap |= (1 << txq);
 	}
 	/* Indirect access to register */
@@ -1906,7 +1911,7 @@ MV_STATUS mvPp2TxPortFifoFlush(int port, MV_BOOL en)
 	MV_U32 regVal;
 
 	/* valid only for ethernet ports (not for xPON) */
-	if (MV_PON_PORT(port))
+	if (MV_PP2_IS_PON_PORT(port))
 		return MV_NOT_SUPPORTED;
 
 	regVal = mvPp2RdReg(MV_PP2_TX_PORT_FLUSH_REG);
@@ -1936,7 +1941,7 @@ MV_STATUS mvPp2TxPortFifoFlush(int port, MV_BOOL en)
 
 /* Function for swithcing SWF to HWF */
 /* txq is physical (global) txq in range 0..MV_PP2_TXQ_TOTAL_NUM */
-/* txq is physical (global) rxq in range 0..MV_ETH_RXQ_TOTAL_NUM */
+/* txq is physical (global) rxq in range 0..MV_PP2_RXQ_TOTAL_NUM */
 
 MV_STATUS mvPp2FwdSwitchCtrl(MV_U32 flowId, int txq, int rxq, int msec)
 {
@@ -1947,7 +1952,7 @@ MV_STATUS mvPp2FwdSwitchCtrl(MV_U32 flowId, int txq, int rxq, int msec)
 	if (mvPp2MaxCheck(txq, MV_PP2_TXQ_TOTAL_NUM, "global txq"))
 		return MV_BAD_PARAM;
 
-	if (mvPp2MaxCheck(rxq, MV_ETH_RXQ_TOTAL_NUM, "global rxq"))
+	if (mvPp2MaxCheck(rxq, MV_PP2_RXQ_TOTAL_NUM, "global rxq"))
 		return MV_BAD_PARAM;
 
 	timeout = MV_PP2_FWD_SWITCH_TIMEOUT_MAX * 1024;
diff --git a/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2Gbe.h b/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2Gbe.h
index acb1c51..634252f 100644
--- a/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2Gbe.h
+++ b/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2Gbe.h
@@ -211,41 +211,41 @@ static INLINE int mvPp2LogicRxqToPhysRxq(int port, int rxq)
 
 
 /************************** TXQ: Physical - Logical Mapping ******************************/
-#ifdef MV_PON_EXIST
+#ifdef MV_PP2_PON_EXIST
 
 #define MV_PON_LOGIC_PORT_GET()			(mvPp2HalData.maxPort - 1)
-#define MV_PON_PORT(p)				((p) == MV_PON_LOGIC_PORT_GET())
-#define MV_PON_PHYS_PORT_GET()			MV_PON_PORT_ID
-#define MV_PON_PHYS_PORT(p)			((p) == MV_PON_PORT_ID)
-#define MV_PP2_TOTAL_TXP_NUM			(MV_ETH_MAX_TCONT + MV_ETH_MAX_PORTS - 1)
-#define MV_PP2_TOTAL_PON_TXQ_NUM		(MV_ETH_MAX_TCONT * MV_ETH_MAX_TXQ)
+#define MV_PP2_IS_PON_PORT(p)			((p) == MV_PON_LOGIC_PORT_GET())
+#define MV_PON_PHYS_PORT_GET()			MV_PP2_PON_PORT_ID
+#define MV_PON_PHYS_PORT(p)			((p) == MV_PP2_PON_PORT_ID)
+#define MV_PP2_TOTAL_TXP_NUM			(MV_PP2_MAX_TCONT + MV_ETH_MAX_PORTS - 1)
+#define MV_PP2_TOTAL_PON_TXQ_NUM		(MV_PP2_MAX_TCONT * MV_PP2_MAX_TXQ)
 
-#define MV_PPV2_PORT_PHYS(port)			((MV_PON_PORT(port)) ? MV_PON_PHYS_PORT_GET() : (port))
-#define MV_PPV2_TXP_PHYS(port, txp)		((MV_PON_PORT(port)) ? txp : (MV_ETH_MAX_TCONT + port))
-#define MV_PPV2_TXQ_PHYS(port, txp, txq)	((MV_PON_PORT(port)) ? txp * MV_ETH_MAX_TXQ + txq :\
-											MV_PP2_TOTAL_PON_TXQ_NUM + port * MV_ETH_MAX_TXQ + txq)
+#define MV_PPV2_PORT_PHYS(port)			((MV_PP2_IS_PON_PORT(port)) ? MV_PON_PHYS_PORT_GET() : (port))
+#define MV_PPV2_TXP_PHYS(port, txp)		((MV_PP2_IS_PON_PORT(port)) ? txp : (MV_PP2_MAX_TCONT + port))
+#define MV_PPV2_TXQ_PHYS(port, txp, txq)	((MV_PP2_IS_PON_PORT(port)) ? txp * MV_PP2_MAX_TXQ + txq :\
+							MV_PP2_TOTAL_PON_TXQ_NUM + port * MV_PP2_MAX_TXQ + txq)
 
 #define MV_PPV2_TXQ_LOGICAL_PORT(physTxq)	((physTxq < MV_PP2_TOTAL_PON_TXQ_NUM) ? MV_PON_LOGIC_PORT_ID_GET() :\
-							(physTxq - MV_PP2_TOTAL_PON_TXQ_NUM) / MV_ETH_MAX_TXQ)
+							(physTxq - MV_PP2_TOTAL_PON_TXQ_NUM) / MV_PP2_MAX_TXQ)
 
-#define MV_PPV2_TXQ_LOGICAL_TXP(physTxq)	((physTxq < MV_PP2_TOTAL_PON_TXQ_NUM) ? (physTxq / MV_ETH_MAX_TXQ) : 0)
+#define MV_PPV2_TXQ_LOGICAL_TXP(physTxq)	((physTxq < MV_PP2_TOTAL_PON_TXQ_NUM) ? (physTxq / MV_PP2_MAX_TXQ) : 0)
 
 #else /* Without PON */
 
-#define MV_PON_PORT(p)				MV_FALSE
+#define MV_PP2_IS_PON_PORT(p)				MV_FALSE
 #define MV_PON_PHYS_PORT(p)			MV_FALSE
 #define MV_PP2_TOTAL_TXP_NUM			(MV_ETH_MAX_PORTS)
 
 #define MV_PPV2_PORT_PHYS(port)                 (port)
 #define MV_PPV2_TXP_PHYS(port, txp)		(port)
-#define MV_PPV2_TXQ_PHYS(port, txp, txq)	(port * MV_ETH_MAX_TXQ + txq)
-#define MV_PPV2_TXQ_LOGICAL_PORT(physTxq)	(physTxq / MV_ETH_MAX_TXQ)
+#define MV_PPV2_TXQ_PHYS(port, txp, txq)	(port * MV_PP2_MAX_TXQ + txq)
+#define MV_PPV2_TXQ_LOGICAL_PORT(physTxq)	(physTxq / MV_PP2_MAX_TXQ)
 #define MV_PPV2_TXQ_LOGICAL_TXP(physTxq)	0
 
-#endif /* MV_PON_EXIST */
+#endif /* MV_PP2_PON_EXIST */
 
-#define MV_PPV2_TXQ_LOGICAL_TXQ(physTxq)	(physTxq % MV_ETH_MAX_TXQ)
-#define MV_PP2_TXQ_TOTAL_NUM			(MV_PP2_TOTAL_TXP_NUM * MV_ETH_MAX_TXQ)
+#define MV_PPV2_TXQ_LOGICAL_TXQ(physTxq)	(physTxq % MV_PP2_MAX_TXQ)
+#define MV_PP2_TXQ_TOTAL_NUM			(MV_PP2_TOTAL_TXP_NUM * MV_PP2_MAX_TXQ)
 
 /************************** Data Path functions ******************************/
 /* Set TXQ descriptors fields relevant for CSUM calculation */
@@ -558,7 +558,7 @@ static INLINE MV_U32 mvPp2GbeIsrCauseRxTxGet(int port)
 {
 	MV_U32 val;
 
-	if (MV_PON_PORT(port)) {
+	if (MV_PP2_IS_PON_PORT(port)) {
 		val = mvPp2RdReg(MV_PP2_ISR_PON_RX_TX_CAUSE_REG);
 		val &= (MV_PP2_PON_CAUSE_RXQ_OCCUP_DESC_ALL_MASK |
 			MV_PP2_PON_CAUSE_TXP_OCCUP_DESC_ALL_MASK | MV_PP2_PON_CAUSE_MISC_SUM_MASK);
@@ -573,7 +573,7 @@ static INLINE MV_U32 mvPp2GbeIsrCauseRxTxGet(int port)
 
 static INLINE MV_BOOL mvPp2GbeIsrCauseTxDoneIsSet(int port, MV_U32 causeRxTx)
 {
-	if (MV_PON_PORT(port))
+	if (MV_PP2_IS_PON_PORT(port))
 		return (causeRxTx & MV_PP2_PON_CAUSE_TXP_OCCUP_DESC_ALL_MASK);
 
 	return (causeRxTx & MV_PP2_CAUSE_TXQ_OCCUP_DESC_ALL_MASK);
@@ -581,7 +581,7 @@ static INLINE MV_BOOL mvPp2GbeIsrCauseTxDoneIsSet(int port, MV_U32 causeRxTx)
 
 static INLINE MV_U32 mvPp2GbeIsrCauseTxDoneOffset(int port, MV_U32 causeRxTx)
 {
-	if (MV_PON_PORT(port))
+	if (MV_PP2_IS_PON_PORT(port))
 		return (causeRxTx & MV_PP2_PON_CAUSE_TXP_OCCUP_DESC_ALL_MASK);
 
 	return (causeRxTx & MV_PP2_CAUSE_TXQ_OCCUP_DESC_ALL_MASK);
@@ -758,7 +758,7 @@ void mvPp2V1TxqDbgCntrs(int port, int txp, int txq);
 void mvPp2V1RxqDbgCntrs(int port, int rxq);
 void mvPp2RxFifoRegs(int port);
 void mvPp2PortStatus(int port);
-void mvEthPortUcastShow(int port);
-void mvEthPortMcastShow(int port);
-void mvEthPortBcastShow(int port);
+void mvPp2PortUcastShow(int port);
+void mvPp2PortMcastShow(int port);
+void mvPp2PortBcastShow(int port);
 #endif /* MV_PP2_GBE_H */
diff --git a/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2GbeDebug.c b/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2GbeDebug.c
index 8edbb24..100f1d0 100644
--- a/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2GbeDebug.c
+++ b/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2GbeDebug.c
@@ -80,8 +80,8 @@ MV_VOID mvPp2RxDmaRegsPrint(void)
 
 	mvOsPrintf("\n[RX DMA regs]\n");
 
-	mvOsPrintf("\nRXQs [0..%d] registers\n", MV_ETH_RXQ_TOTAL_NUM);
-	for (i = 0; i < MV_ETH_RXQ_TOTAL_NUM; i++) {
+	mvOsPrintf("\nRXQs [0..%d] registers\n", MV_PP2_RXQ_TOTAL_NUM);
+	for (i = 0; i < MV_PP2_RXQ_TOTAL_NUM; i++) {
 #ifdef CONFIG_MV_ETH_PP2_1
 		mvPp2PrintReg(MV_PP2_RX_STATUS, "MV_PP2_RX_STATUS");
 		mvPp2PrintReg2(MV_PP2_RXQ_CONFIG_REG(i), "MV_PP2_RXQ_CONFIG_REG", i);
@@ -153,7 +153,7 @@ MV_VOID mvPp2RxqShow(int port, int rxq, int mode)
 		return;
 	}
 
-	if (mvPp2MaxCheck(rxq, MV_ETH_MAX_RXQ, "logical rxq"))
+	if (mvPp2MaxCheck(rxq, MV_PP2_MAX_RXQ, "logical rxq"))
 		return;
 
 	if (pCtrl->pRxQueue[rxq] == NULL) {
@@ -196,7 +196,7 @@ MV_VOID mvPp2TxqShow(int port, int txp, int txq, int mode)
 	if (mvPp2TxpCheck(port, txp))
 		return;
 
-	if (mvPp2MaxCheck(txq, MV_ETH_MAX_TXQ, "logical txq"))
+	if (mvPp2MaxCheck(txq, MV_PP2_MAX_TXQ, "logical txq"))
 		return;
 
 	pTxq = MV_PPV2_TXQ_PHYS(port, txp, txq);
@@ -250,7 +250,7 @@ void mvPp2IsrRegs(int port)
 
 	physPort = MV_PPV2_PORT_PHYS(port);
 
-	mvOsPrintf("\n[PPv2 ISR registers: port=%d - %s]\n", port, MV_PON_PORT(port) ? "PON" : "GMAC");
+	mvOsPrintf("\n[PPv2 ISR registers: port=%d - %s]\n", port, MV_PP2_IS_PON_PORT(port) ? "PON" : "GMAC");
 	mvPp2PrintReg(MV_PP2_ISR_RXQ_GROUP_REG(port), "MV_PP2_ISR_RXQ_GROUP_REG");
 	mvPp2PrintReg(MV_PP2_ISR_ENABLE_REG(port), "MV_PP2_ISR_ENABLE_REG");
 	mvPp2PrintReg(MV_PP2_ISR_RX_TX_CAUSE_REG(physPort), "MV_PP2_ISR_RX_TX_CAUSE_REG");
@@ -259,7 +259,7 @@ void mvPp2IsrRegs(int port)
 	mvPp2PrintReg(MV_PP2_ISR_RX_ERR_CAUSE_REG(physPort), "MV_PP2_ISR_RX_ERR_CAUSE_REG");
 	mvPp2PrintReg(MV_PP2_ISR_RX_ERR_MASK_REG(physPort), "MV_PP2_ISR_RX_ERR_MASK_REG");
 
-	if (MV_PON_PORT(port)) {
+	if (MV_PP2_IS_PON_PORT(port)) {
 		mvPp2PrintReg(MV_PP2_ISR_PON_TX_UNDR_CAUSE_REG, "MV_PP2_ISR_PON_TX_UNDR_CAUSE_REG");
 		mvPp2PrintReg(MV_PP2_ISR_PON_TX_UNDR_MASK_REG, "MV_PP2_ISR_PON_TX_UNDR_MASK_REG");
 	} else {
@@ -274,7 +274,7 @@ void mvPp2PhysRxqRegs(int rxq)
 {
 	mvOsPrintf("\n[PPv2 RxQ registers: global rxq=%d]\n", rxq);
 
-	if (mvPp2MaxCheck(rxq, MV_ETH_RXQ_TOTAL_NUM, "global rxq"))
+	if (mvPp2MaxCheck(rxq, MV_PP2_RXQ_TOTAL_NUM, "global rxq"))
 		return;
 
 	mvPp2WrReg(MV_PP2_RXQ_NUM_REG, rxq);
@@ -302,7 +302,7 @@ void mvPp2PortRxqRegs(int port, int rxq)
 	if (mvPp2PortCheck(port))
 		return;
 
-	if (mvPp2MaxCheck(rxq, MV_ETH_MAX_RXQ, "local rxq"))
+	if (mvPp2MaxCheck(rxq, MV_PP2_MAX_RXQ, "local rxq"))
 		return;
 
 	mvPp2PhysRxqRegs(mvPp2LogicRxqToPhysRxq(port, rxq));
@@ -334,7 +334,7 @@ void mvPp2PortTxqRegs(int port, int txp, int txq)
 	if (mvPp2TxpCheck(port, txp))
 		return;
 
-	if (mvPp2MaxCheck(txq, MV_ETH_MAX_TXQ, "local txq"))
+	if (mvPp2MaxCheck(txq, MV_PP2_MAX_TXQ, "local txq"))
 		return;
 
 	mvPp2PhysTxqRegs(MV_PPV2_TXQ_PHYS(port, txp, txq));
@@ -397,7 +397,7 @@ void mvPp2TxSchedRegs(int port, int txp)
 	mvPp2PrintReg(MV_PP2_TXP_SCHED_TOKEN_SIZE_REG, "MV_PP2_TXP_SCHED_TOKEN_SIZE_REG");
 	mvPp2PrintReg(MV_PP2_TXP_SCHED_TOKEN_CNTR_REG, "MV_PP2_TXP_SCHED_TOKEN_CNTR_REG");
 
-	for (txq = 0; txq < MV_ETH_MAX_TXQ; txq++) {
+	for (txq = 0; txq < MV_PP2_MAX_TXQ; txq++) {
 		mvOsPrintf("\n[TxQ Scheduler registers: port=%d, txp=%d, txq=%d]\n", port, txp, txq);
 		mvPp2PrintReg(MV_PP2_TXQ_SCHED_REFILL_REG(txq), "MV_PP2_TXQ_SCHED_REFILL_REG");
 		mvPp2PrintReg(MV_PP2_TXQ_SCHED_TOKEN_SIZE_REG(txq), "MV_PP2_TXQ_SCHED_TOKEN_SIZE_REG");
@@ -439,17 +439,17 @@ void mvPp2V0DropCntrs(int port)
 	mvPp2PrintReg(MV_PP2_OVERRUN_DROP_REG(MV_PPV2_PORT_PHYS(port)), "MV_PP2_OVERRUN_DROP_REG");
 	mvPp2PrintReg(MV_PP2_CLS_DROP_REG(MV_PPV2_PORT_PHYS(port)), "MV_PP2_CLS_DROP_REG");
 
-	if (MV_PON_PORT(port)) {
+	if (MV_PP2_IS_PON_PORT(port)) {
 		for (i = 0; i < mvPp2HalData.maxTcont; i++) {
 			mvPp2PrintReg2(MV_PP2_V0_TX_EARLY_DROP_REG(i), "MV_PP2_TX_EARLY_DROP_REG", i);
 			mvPp2PrintReg2(MV_PP2_V0_TX_DESC_DROP_REG(i), "MV_PP2_TX_DESC_DROP_REG", i);
 		}
 	} else {
-		i = MV_ETH_MAX_TCONT + port;
+		i = MV_PP2_MAX_TCONT + port;
 		mvPp2PrintReg2(MV_PP2_V0_TX_EARLY_DROP_REG(i), "MV_PP2_TX_EARLY_DROP_REG", i);
 		mvPp2PrintReg2(MV_PP2_V0_TX_DESC_DROP_REG(i), "MV_PP2_TX_DESC_DROP_REG", i);
 	}
-	for (i = port * CONFIG_MV_ETH_RXQ; i < (port * CONFIG_MV_ETH_RXQ + CONFIG_MV_ETH_RXQ); i++) {
+	for (i = port * CONFIG_MV_PP2_RXQ; i < (port * CONFIG_MV_PP2_RXQ + CONFIG_MV_PP2_RXQ); i++) {
 		mvPp2PrintReg2(MV_PP2_V0_RX_EARLY_DROP_REG(i), "MV_PP2_RX_EARLY_DROP_REG", i);
 		mvPp2PrintReg2(MV_PP2_V0_RX_DESC_DROP_REG(i), "MV_PP2_RX_DESC_DROP_REG", i);
 	}
@@ -470,7 +470,7 @@ void mvPp2V1DropCntrs(int port)
 	mvPp2RegPrintNonZero(MV_PP2_CLS_DROP_REG(physPort), "MV_PP2_CLS_DROP_REG");
 
 	for (txp = 0; txp < pPortCtrl->txpNum; txp++) {
-		for (q = 0; q < MV_ETH_MAX_TXQ; q++) {
+		for (q = 0; q < MV_PP2_MAX_TXQ; q++) {
 			mvOsPrintf("\n------ [Port #%d txp #%d txq #%d counters] -----\n", port, txp, q);
 			mvPp2WrReg(MV_PP2_V1_CNT_IDX_REG, TX_CNT_IDX(port, txp, q));
 			mvPp2RegPrintNonZero(MV_PP2_V1_TX_PKT_FULLQ_DROP_REG, "MV_PP2_V1_TX_PKT_FULLQ_DROP_REG");
@@ -480,7 +480,7 @@ void mvPp2V1DropCntrs(int port)
 		}
 	}
 
-	for (q = 0; q < CONFIG_MV_ETH_RXQ; q++) {
+	for (q = 0; q < CONFIG_MV_PP2_RXQ; q++) {
 		mvOsPrintf("\n------ [Port #%d, rxq #%d counters] -----\n", port, q);
 		phyRxq = mvPp2LogicRxqToPhysRxq(port, q);
 		mvPp2WrReg(MV_PP2_V1_CNT_IDX_REG, phyRxq);
@@ -604,7 +604,7 @@ void mvPp2PortStatus(int port)
 
 	mvOsPrintf("\n[Link: port=%d, ctrl=%p]\n", port, pPortCtrl);
 
-	if (!MV_PON_PORT(port)) {
+	if (!MV_PP2_IS_PON_PORT(port)) {
 
 		mvGmacLinkStatus(port, &link);
 
@@ -628,7 +628,7 @@ void mvPp2PortStatus(int port)
 	}
 }
 
-void mvEthPortUcastShow(int port)
+void mvPp2PortUcastShow(int port)
 {
 	MV_PP2_PRS_ENTRY pe;
 	int phyPort = MV_PPV2_PORT_PHYS(port);
@@ -660,7 +660,7 @@ void mvEthPortUcastShow(int port)
 	return;
 }
 
-void mvEthPortMcastShow(int port)
+void mvPp2PortMcastShow(int port)
 {
 	MV_PP2_PRS_ENTRY pe;
 	int phyPort = MV_PPV2_PORT_PHYS(port);
@@ -692,7 +692,7 @@ void mvEthPortMcastShow(int port)
 	return;
 }
 
-void mvEthPortBcastShow(int port)
+void mvPp2PortBcastShow(int port)
 {
 	MV_PP2_PRS_ENTRY pe;
 	int phyPort = MV_PPV2_PORT_PHYS(port);
diff --git a/arch/arm/plat-armada/mv_hal/pp2/gmac/mvEthGmacApi.c b/arch/arm/plat-armada/mv_hal/pp2/gmac/mvEthGmacApi.c
index 8cc541b..85335a9 100644
--- a/arch/arm/plat-armada/mv_hal/pp2/gmac/mvEthGmacApi.c
+++ b/arch/arm/plat-armada/mv_hal/pp2/gmac/mvEthGmacApi.c
@@ -213,7 +213,7 @@ MV_STATUS mvGmacLinkStatus(int port, MV_ETH_PORT_STATUS *pStatus)
 {
 	MV_U32 regVal;
 
-	if (MV_PON_PORT(port)) {
+	if (MV_PP2_IS_PON_PORT(port)) {
 		pStatus->linkup = MV_TRUE;
 		pStatus->speed = MV_ETH_SPEED_1000;
 		pStatus->duplex = MV_ETH_DUPLEX_FULL;
@@ -303,7 +303,7 @@ MV_STATUS mvGmacMaxRxSizeSet(int port, int maxRxSize)
 {
 	MV_U32		regVal;
 
-	if (MV_PON_PORT(port))
+	if (MV_PP2_IS_PON_PORT(port))
 		return MV_ERROR;
 
 	regVal =  MV_REG_READ(ETH_GMAC_CTRL_0_REG(port));
@@ -649,7 +649,7 @@ void mvGmacPortRegs(int port)
 	if (mvPp2PortCheck(port))
 		return;
 
-	if (MV_PON_PORT(port)) {
+	if (MV_PP2_IS_PON_PORT(port)) {
 		mvOsPrintf("Not supported for PON port\n");
 		return;
 	}
@@ -738,7 +738,7 @@ void mvGmacMibCountersClear(int port)
 {
 	int i;
 
-	if (MV_PON_PORT(port))
+	if (MV_PP2_IS_PON_PORT(port))
 		return;
 
 	/* Perform dummy reads from MIB counters */
@@ -765,7 +765,7 @@ void mvGmacMibCountersShow(int port)
 	if (mvPp2PortCheck(port))
 		return;
 
-	if (MV_PON_PORT(port)) {
+	if (MV_PP2_IS_PON_PORT(port)) {
 		mvOsPrintf("%s: not supported for PON port\n", __func__);
 		return;
 	}
diff --git a/arch/arm/plat-armada/mv_hal/pp2/plcr/mvPp2PlcrHw.c b/arch/arm/plat-armada/mv_hal/pp2/plcr/mvPp2PlcrHw.c
index 9ff31f8..81d8651 100644
--- a/arch/arm/plat-armada/mv_hal/pp2/plcr/mvPp2PlcrHw.c
+++ b/arch/arm/plat-armada/mv_hal/pp2/plcr/mvPp2PlcrHw.c
@@ -112,7 +112,7 @@ void        mvPp2PlcrHwRegs(void)
 	}
 #endif
 	mvOsPrintf("\nPer RXQ: Non zero early drop thresholds\n");
-	for (i = 0; i < MV_ETH_RXQ_TOTAL_NUM; i++) {
+	for (i = 0; i < MV_PP2_RXQ_TOTAL_NUM; i++) {
 		mvPp2WrReg(MV_PP2_PLCR_EDROP_RXQ_REG, i);
 		regVal = mvPp2RdReg(MV_PP2_PLCR_EDROP_RXQ_TR_REG);
 		if (regVal != 0)
-- 
1.7.5.4

