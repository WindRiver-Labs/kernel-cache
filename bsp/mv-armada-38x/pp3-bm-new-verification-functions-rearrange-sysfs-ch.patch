From 40b0c6a1882057c33cc400b7eafcde30f7504750 Mon Sep 17 00:00:00 2001
From: Dovrat <dovrat@marvell.com>
Date: Sun, 27 Apr 2014 10:48:52 +0300
Subject: [PATCH 1590/1825] pp3: bm: new verification functions, rearrange
 sysfs check that bm was initialized

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit 51eee376c9036dac5b86bc8a95536eae8f479380

Change-Id: I65f8a559f8c4fd0e23cb898443711a3c9a64ea18
Signed-off-by: Dovrat <dovrat@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/7709
Tested-by: Star_Automation <star@marvell.com>
Reviewed-by: Yelena Krivosheev <yelena@marvell.com>
Reviewed-by: Uri Eliyahu <uriel@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 drivers/net/ethernet/marvell/pp3/bm/mv_bm.c       |  341 +++++++---
 drivers/net/ethernet/marvell/pp3/bm/mv_bm.h       |   41 +-
 drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c |  793 ++++++++++++---------
 3 files changed, 724 insertions(+), 451 deletions(-)

diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
index 8c16401..1cfc7a7 100644
--- a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.c
@@ -72,9 +72,18 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #include "qm/mv_qm.h"
 #include "bm/mv_bm_regs.h"
 
+static int bm_module_is_open_for_connection = -1;
+#define BM_AVAILABLE_CHECK() \
+{ \
+	if (bm_module_is_open_for_connection == -1) { \
+		pr_info("\nYou should first call bm_open!\n"); \
+		return -1; \
+	} \
+}
+
 int bm_open(void)
 {
-	int rc = !OK;
+	int rc = OK;
 
 	rc = bm_reg_address_alias_init();
 	if (rc != OK)
@@ -86,21 +95,26 @@ int bm_open(void)
 	if (rc != OK)
 		return rc;
 	rc = bm_pid_bid_init();
+	if (rc != OK)
+		return rc;
+	bm_module_is_open_for_connection = 1;
 	return rc;
 }
 
 /*BM User Application Interface*/
 int bm_attr_all_pools_def_set(void)
 {
-	int rc = !OK;
+	int rc = OK;
 	u32 arDomain, awDomain, arCache, awCache, arQOS, awQOS;
 
-	arDomain = 0;
-	awDomain = 0;
-	arCache  = 3;
-	awCache  = 3;
-	arQOS    = 1;
-	awQOS    = 0;
+	BM_AVAILABLE_CHECK();
+
+	arDomain = BM_ADOMAIN_DEF;
+	awDomain = BM_ADOMAIN_DEF;
+	arCache  = BM_ACACHE_DEF;
+	awCache  = BM_ACACHE_DEF;
+	arQOS    = BM_ARQOS_DEF;
+	awQOS    = BM_AWQOS_DEF;
 
 	rc = bm_attr_qm_pool_set(arDomain, awDomain, arCache, awCache, arQOS, awQOS);
 	if (rc != OK)
@@ -118,6 +132,8 @@ int bm_attr_qm_pool_set(u32 arDomain, u32 awDomain, u32 arCache, u32 awCache, u3
 	struct bm_dram_cache_conf  reg_dram_cache_conf;
 	struct bm_dram_qos_conf    reg_dram_qos_conf;
 
+	BM_AVAILABLE_CHECK();
+
 	pr_info("bm_attr_qm_pool_set %d %d %d %d %d %d\n", arDomain, awDomain, arCache, awCache, arQOS, awQOS);
 
 	if ((arDomain < BM_ADOMAIN_MIN) || (arDomain > BM_ADOMAIN_MAX)) {
@@ -147,7 +163,7 @@ int bm_attr_qm_pool_set(u32 arDomain, u32 awDomain, u32 arCache, u32 awCache, u3
 	rc = bm_enable_status_get(&bm_req_rcv_en);
 	if (rc != OK)
 		return rc;
-	if (bm_req_rcv_en == 1) {
+	if (bm_req_rcv_en == BM_UNIT_IS_ENABLED) {
 		rc = -BM_ATTR_CHANGE_AFTER_BM_ENABLE;
 		return rc;
 	}
@@ -203,6 +219,8 @@ int bm_attr_gp_pool_set(u32 arDomain, u32 awDomain, u32 arCache, u32 awCache, u3
 	struct bm_dram_cache_conf  reg_dram_cache_conf;
 	struct bm_dram_qos_conf    reg_dram_qos_conf;
 
+	BM_AVAILABLE_CHECK();
+
 	pr_info("bm_attr_gp_pool_set %d %d %d %d %d %d\n", arDomain, awDomain, arCache, awCache, arQOS, awQOS);
 
 	if ((arDomain < BM_ADOMAIN_MIN) || (arDomain > BM_ADOMAIN_MAX)) {
@@ -233,7 +251,7 @@ int bm_attr_gp_pool_set(u32 arDomain, u32 awDomain, u32 arCache, u32 awCache, u3
 	rc = bm_enable_status_get(&bm_req_rcv_en);
 	if (rc != OK)
 		return rc;
-	if (bm_req_rcv_en == 1) {
+	if (bm_req_rcv_en == BM_UNIT_IS_ENABLED) {
 		rc = -BM_ATTR_CHANGE_AFTER_BM_ENABLE;
 		return rc;
 	}
@@ -286,6 +304,8 @@ int bm_enable_status_get(u32 *bm_req_rcv_en)
 	int rc = -BM_INPUT_NOT_IN_RANGE;
 	struct bm_common_general_conf          reg_common_general_conf;
 
+	BM_AVAILABLE_CHECK();
+
 	reg_base_address =      bm.common_general_conf;
 	reg_size   =   bm_reg_size.common_general_conf;
 	reg_offset = bm_reg_offset.common_general_conf * 0;
@@ -305,6 +325,8 @@ int bm_qm_gpm_pools_def_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base_
 	int rc = -BM_INPUT_NOT_IN_RANGE;
 	u32 ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
 
+	BM_AVAILABLE_CHECK();
+
 	ae_thr               = BM_AE_THR_DEF(num_of_buffers);
 	af_thr               = BM_AF_THR_DEF(num_of_buffers);
 	cache_vmid           = BM_CACHE_VMID_DEF;
@@ -324,6 +346,8 @@ int bm_qm_dram_pools_def_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base
 	int rc = -BM_INPUT_NOT_IN_RANGE;
 	u32 ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
 
+	BM_AVAILABLE_CHECK();
+
 	ae_thr               = BM_AE_THR_DEF(num_of_buffers);
 	af_thr               = BM_AF_THR_DEF(num_of_buffers);
 	cache_vmid           = BM_CACHE_VMID_DEF;
@@ -348,17 +372,19 @@ int bm_qm_gpm_pools_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base_addr
 	struct mv_a40 base_address;
 	u32 granularity_of_pe_in_dram, granularity_of_pe_in_cache;
 
+	BM_AVAILABLE_CHECK();
+
 	pr_info("%s:\n", __func__);
 	pr_info("  num_of_buffers    %d\n", num_of_buffers);
-	pr_info("  qece_base_address(1) virtual 0x%02X%08X	physical 0x%02X%08X\n",
+	pr_info("  qece_base_address(1) virtual 0x%02X%08X   physical 0x%02X%08X\n",
 		qece_base_address->virt_msb, qece_base_address->virt_lsb,
 		qece_base_address->dma_msb,   qece_base_address->dma_lsb);
-	pr_info("  pl_base_address(0) virtual 0x%02X%08X	physical 0x%02X%08X\n",
+	pr_info("  pl_base_address(0)   virtual 0x%02X%08X   physical 0x%02X%08X\n",
 		pl_base_address->virt_msb, pl_base_address->virt_lsb,
 		pl_base_address->dma_msb,   pl_base_address->dma_lsb);
-	pr_info("  ae_thr            %d		af_thr          %d\n", ae_thr, af_thr);
-	pr_info("  cache_vmid        %d		cache_attr      %d\n", cache_vmid, cache_attr);
-	pr_info("  cache_so_thr      %d		cache_si_thr    %d		cache_num_of_buffers %d\n",
+	pr_info("  ae_thr %d af_thr %d\n", ae_thr, af_thr);
+	pr_info("  cache_vmid %d cache_attr %d\n", cache_vmid, cache_attr);
+	pr_info("  cache_so_thr %d cache_si_thr %d cache_num_of_buffers %d\n",
 		cache_so_thr, cache_si_thr, cache_num_of_buffers);
 
 	granularity_of_pe_in_dram  = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_DRAM;		/* 64/4 */
@@ -468,7 +494,7 @@ int bm_qm_gpm_pools_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base_addr
 	if (rc != OK)
 		return rc;
 
-	if (bm_req_rcv_en == 1) {
+	if (bm_req_rcv_en == BM_UNIT_IS_ENABLED) {
 		pr_err("qm gpm pool should be enabled before BM module is enabled\n");
 		rc = -BM_ATTR_CHANGE_AFTER_BM_ENABLE;
 		return rc;
@@ -479,8 +505,8 @@ int bm_qm_gpm_pools_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base_addr
 	base_address.dma_lsb = pl_base_address->dma_lsb;
 	base_address.virt_msb = pl_base_address->virt_msb;
 	base_address.virt_lsb = pl_base_address->virt_lsb;
-	quick_init = 1;
-	pe_size = 1;
+	quick_init = BM_QUICK_INIT_IS_ON;
+	pe_size = BM_PE_SIZE_IS_32_BITS;
 	rc = bm_pool_dram_set(pool, num_of_buffers, pe_size, &base_address, ae_thr, af_thr);
 	if (rc != OK)
 		return rc;
@@ -503,8 +529,8 @@ int bm_qm_gpm_pools_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base_addr
 	base_address.dma_lsb = qece_base_address->dma_lsb;
 	base_address.virt_msb = qece_base_address->virt_msb;
 	base_address.virt_lsb = qece_base_address->virt_lsb;
-	quick_init = 1;
-	pe_size = 1;
+	quick_init = BM_QUICK_INIT_IS_ON;
+	pe_size = BM_PE_SIZE_IS_32_BITS;
 	rc = bm_pool_dram_set(pool, num_of_buffers, pe_size, &base_address, ae_thr, af_thr);
 	if (rc != OK)
 		return rc;
@@ -533,6 +559,8 @@ int bm_qm_dram_pools_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base_add
 	struct mv_a40 base_address;
 	u32 granularity_of_pe_in_dram, granularity_of_pe_in_cache;
 
+	BM_AVAILABLE_CHECK();
+
 	granularity_of_pe_in_dram  = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_DRAM;		/* 64/4 */
 	granularity_of_pe_in_cache = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_CACHE;	/* 64/4 */
 
@@ -602,7 +630,7 @@ int bm_qm_dram_pools_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base_add
 	rc = bm_enable_status_get(&bm_req_rcv_en);
 	if (rc != OK)
 		return rc;
-	if (bm_req_rcv_en == 1) {
+	if (bm_req_rcv_en == BM_UNIT_IS_ENABLED) {
 		rc = -BM_ATTR_CHANGE_AFTER_BM_ENABLE;
 		return rc;
 	}
@@ -613,8 +641,8 @@ int bm_qm_dram_pools_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base_add
 	base_address.dma_lsb = pl_base_address->dma_lsb;
 	base_address.virt_msb = pl_base_address->virt_msb;
 	base_address.virt_lsb = pl_base_address->virt_lsb;
-	quick_init = 1;
-	pe_size = 1;
+	quick_init = BM_QUICK_INIT_IS_ON;
+	pe_size = BM_PE_SIZE_IS_32_BITS;
 	buffer_size = BM_BUFFER_SIZE_P2;
 	rc = bm_pool_dram_set(pool, num_of_buffers, pe_size, &base_address, ae_thr, af_thr);
 	if (rc != OK)
@@ -648,8 +676,8 @@ int bm_qm_dram_pools_quick_init(u32 num_of_buffers, struct mv_a40 *qece_base_add
 	base_address.dma_lsb = qece_base_address->dma_lsb;
 	base_address.virt_msb = qece_base_address->virt_msb;
 	base_address.virt_lsb = qece_base_address->virt_lsb;
-	quick_init = 1;
-	pe_size = 1;
+	quick_init = BM_QUICK_INIT_IS_ON;
+	pe_size = BM_PE_SIZE_IS_32_BITS;
 	buffer_size = BM_BUFFER_SIZE_P3;
 	rc = bm_pool_dram_set(pool, num_of_buffers, pe_size, &base_address, ae_thr, af_thr);
 	if (rc != OK)
@@ -691,6 +719,8 @@ int bm_pool_quick_init_status_get(u32 pool, u32 *completed)
 	struct bm_pool_st   reg_pool_st;
 	u32 enabled, quick_init;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((pool           <     BM_POOL_MIN) || (pool           >     BM_POOL_MAX)) {
 		pr_err("wrong pool number %d\n", pool);
 		return rc;
@@ -706,15 +736,14 @@ int bm_pool_quick_init_status_get(u32 pool, u32 *completed)
 	bm_pool_enabled_get(pool, &enabled, &quick_init);
 	if (enabled != BM_POOL_IS_ENABLED) {
 		pr_err("pool is not enabled\n");
-		return rc;
+		return -1;
 	}
 	if (quick_init != BM_QUICK_INIT_IS_ON) {
 		pr_err("pool is not in quick init mode\n");
 		*completed = BM_POOL_INIT_COMPLETED;
-		return 0;
+		return -1;
 	}
 
-
 	pid       = (int)pool;
 	bid       = BM_PID_TO_BANK(pid);
 	pid_local = BM_PID_TO_PID_LOCAL(pid);
@@ -739,18 +768,19 @@ int bm_gp_pool_def_basic_init(u32 pool, u32 num_of_buffers, struct mv_a40 *base_
 	u32 pe_size, ae_thr, af_thr, cache_vmid, cache_attr,
 			cache_so_thr, cache_si_thr, cache_num_of_buffers;
 
+	BM_AVAILABLE_CHECK();
+
 	pe_size              = BM_PE_SIZE_DEF;
-	/*pool_pair            = BM_POOL_PAIR_GP_DEF;*/
 	ae_thr               = BM_AE_THR_DEF(num_of_buffers);
 	af_thr               = BM_AF_THR_DEF(num_of_buffers);
 	cache_vmid           = BM_CACHE_VMID_DEF;
 	cache_attr           = BM_CACHE_ATTR_DEF;
 
-	if (partition_model == 0) {			/* large partition in cache */
+	if (partition_model == BM_BIG_PARTITION_IN_CACHE) {			/* large partition in cache */
 		cache_si_thr         = BM_CACHE_SI_THR_GP_BIG_DEF;
 		cache_so_thr         = BM_CACHE_SO_THR_GP_BIG_DEF;
 		cache_num_of_buffers = BM_CACHE_NUM_OF_BUFFERS_GP_BIG_DEF;
-	} else if (partition_model == 1) {	/* small partition in cache */
+	} else if (partition_model == BM_SMALL_PARTITION_IN_CACHE) {	/* small partition in cache */
 		cache_si_thr         = BM_CACHE_SI_THR_GP_SMALL_DEF;
 		cache_so_thr         = BM_CACHE_SO_THR_GP_SMALL_DEF;
 		cache_num_of_buffers = BM_CACHE_NUM_OF_BUFFERS_GP_SMALL_DEF;
@@ -771,9 +801,11 @@ int bm_gp_pool_basic_init(u32 pool, u32 num_of_buffers, struct mv_a40 *base_addr
 				u32 cache_num_of_buffers)
 {
 	int rc = -BM_INPUT_NOT_IN_RANGE;
-	u32 quick_init = 0;	/* quick_init is FALSE */
+	u32 quick_init = BM_QUICK_INIT_IS_OFF;	/* quick_init is FALSE */
 	u32 granularity_of_pe_in_dram, granularity_of_pe_in_cache;
 
+	BM_AVAILABLE_CHECK();
+
 	if (pe_size == BM_PE_SIZE_IS_40_BITS) {
 		granularity_of_pe_in_dram  =
 			GRANULARITY_OF_64_BYTES / GP_PE_SIZE_OF_40_BITS_IN_BYTES_IN_DRAM;	/* 64/8 */
@@ -846,12 +878,6 @@ int bm_gp_pool_basic_init(u32 pool, u32 num_of_buffers, struct mv_a40 *base_addr
 		pr_err("problem with base address\n");
 		return rc;
 	}
-	if ((pe_size              <          BM_PE_SIZE_MIN) ||
-		(pe_size              >          BM_PE_SIZE_MAX)) {
-		pr_err("wrong pe_size %d. should be in range %d..%d\n",
-			pe_size, BM_PE_SIZE_MIN, BM_PE_SIZE_MAX);
-		return rc;
-	}
 	if ((pool_pair            <        BM_POOL_PAIR_MIN) ||
 		(pool_pair            >        BM_POOL_PAIR_MAX)) {
 		pr_err("wrong pool_pair %d. should be in range %d..%d\n",
@@ -927,6 +953,8 @@ int bm_enable(void)
 	struct bm_common_general_conf          reg_common_general_conf;
 	u32 bm_req_rcv_en;
 
+	BM_AVAILABLE_CHECK();
+
 	reg_base_address =      bm.common_general_conf;
 	reg_size   =   bm_reg_size.common_general_conf;
 	reg_offset = bm_reg_offset.common_general_conf * 0;
@@ -934,7 +962,7 @@ int bm_enable(void)
 	rc = bm_enable_status_get(&bm_req_rcv_en);
 	if (rc != OK)
 		return rc;
-	if (bm_req_rcv_en == 1) {
+	if (bm_req_rcv_en == BM_UNIT_IS_ENABLED) {
 		rc = -BM_CHANGE_AFTER_BM_ENABLE;
 		return rc;
 	}
@@ -955,6 +983,8 @@ int bm_disable(void)
 	struct bm_common_general_conf          reg_common_general_conf;
 	u32 pool;
 
+	BM_AVAILABLE_CHECK();
+
 	for (pool = BM_POOL_GP_MIN; pool <= BM_POOL_GP_MAX; pool++) {
 		rc = bm_pool_disable(pool);
 		if (rc != OK)
@@ -992,6 +1022,9 @@ int bm_pool_fill_level_get(u32 pool, u32 *fill_level)
 	int rc = -BM_INPUT_NOT_IN_RANGE;
 	u32 pid, bid, pid_local;
 	struct bm_tpr_drw_mng_ball_dyn_data         tab_tpr_drw_mng_ball_dyn;
+	u32 pe_size;
+
+	BM_AVAILABLE_CHECK();
 
 	if ((pool            <     BM_POOL_MIN) || (pool            >     BM_POOL_MAX))
 		return rc;
@@ -1011,7 +1044,17 @@ int bm_pool_fill_level_get(u32 pool, u32 *fill_level)
 	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_tpr_drw_mng_ball_dyn);
 	if (rc != OK)
 		return rc;
-	*fill_level = tab_tpr_drw_mng_ball_dyn.dram_fill * UNIT_OF__8_BYTES;
+
+	rc = bm_pool_pe_size_get(pool, &pe_size);
+	if (rc != OK)
+		return rc;
+	/* Fill level is given in 8 Bytes unit. Here we translate it to number of PE's */
+	if (pe_size == BM_PE_SIZE_IS_32_BITS)
+		*fill_level = tab_tpr_drw_mng_ball_dyn.dram_fill * 2;
+	else if (pe_size == BM_PE_SIZE_IS_40_BITS)
+		*fill_level = tab_tpr_drw_mng_ball_dyn.dram_fill;
+	else
+		return rc;
 
 	rc = OK;
 	return rc;
@@ -1024,13 +1067,15 @@ int bm_vmid_set(u32 bm_vmid)
 	struct bm_common_general_conf          reg_common_general_conf;
 	u32 bm_req_rcv_en;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((bm_vmid < BM_VMID_MIN) || (bm_vmid > BM_VMID_MAX))
 		return rc;
 
 	rc = bm_enable_status_get(&bm_req_rcv_en);
 	if (rc != OK)
 		return rc;
-	if (bm_req_rcv_en == 1) {
+	if (bm_req_rcv_en == BM_UNIT_IS_ENABLED) {
 		rc = -BM_CHANGE_AFTER_BM_ENABLE;
 		return rc;
 	}
@@ -1054,22 +1099,21 @@ int bm_gp_pool_def_quick_init(u32 pool, u32 num_of_buffers, u32 fill_level,
 	int rc = -BM_INPUT_NOT_IN_RANGE;
 	u32 pe_size, ae_thr, af_thr, cache_vmid, cache_attr,
 					cache_so_thr, cache_si_thr, cache_num_of_buffers;
-/*	u32 large_cache;*/
+
+	BM_AVAILABLE_CHECK();
 
 	pe_size              = BM_PE_SIZE_IS_32_BITS;
-	/*pool_pair            = BM_POOL_PAIR_GP_DEF;*/
 	ae_thr               = BM_AE_THR_DEF(num_of_buffers);
 	af_thr               = BM_AF_THR_DEF(num_of_buffers);
 	cache_vmid           = BM_CACHE_VMID_DEF;
 	cache_attr           = BM_CACHE_ATTR_DEF;
 
-/*	large_cache = !(partition_model);	???*/
 
-	if (partition_model == 0) {			/* large partition in cache */
+	if (partition_model == BM_BIG_PARTITION_IN_CACHE) {			/* large partition in cache */
 		cache_si_thr         = BM_CACHE_SI_THR_GP_BIG_DEF;
 		cache_so_thr         = BM_CACHE_SO_THR_GP_BIG_DEF;
 		cache_num_of_buffers = BM_CACHE_NUM_OF_BUFFERS_GP_BIG_DEF;
-	} else if (partition_model == 1) {	/* small partition in cache */
+	} else if (partition_model == BM_SMALL_PARTITION_IN_CACHE) {	/* small partition in cache */
 		cache_si_thr         = BM_CACHE_SI_THR_GP_SMALL_DEF;
 		cache_so_thr         = BM_CACHE_SO_THR_GP_SMALL_DEF;
 		cache_num_of_buffers = BM_CACHE_NUM_OF_BUFFERS_GP_SMALL_DEF;
@@ -1091,7 +1135,9 @@ int bm_gp_pool_quick_init(u32 pool, u32 num_of_buffers, u32 fill_level, struct m
 	u32 quick_init/*, bm_req_rcv_en*/;
 	u32 granularity_of_pe_in_dram, granularity_of_pe_in_cache;
 
-	quick_init = 1;	/*quick_init is TRUE*/
+	BM_AVAILABLE_CHECK();
+
+	quick_init = BM_QUICK_INIT_IS_ON;	/*quick_init is TRUE*/
 
 	if (pe_size == BM_PE_SIZE_IS_40_BITS) {
 		granularity_of_pe_in_dram  =
@@ -1137,8 +1183,6 @@ int bm_gp_pool_quick_init(u32 pool, u32 num_of_buffers, u32 fill_level, struct m
 	if ((base_address->dma_msb == BM_DRAM_ADDRESS_MAX_MSB) &&
 		(base_address->dma_lsb >  BM_DRAM_ADDRESS_MAX_LSB))
 		return rc;
-	if ((pe_size      <      BM_PE_SIZE_MIN) || (pe_size      >      BM_PE_SIZE_MAX))
-		return rc;
 	if ((pool_pair    <    BM_POOL_PAIR_MIN) || (pool_pair    >    BM_POOL_PAIR_MAX))
 		return rc;
 	if ((ae_thr       < BM_AE_THR_MIN(num_of_buffers)) || (ae_thr       > BM_AE_THR_MAX(num_of_buffers)))
@@ -1176,7 +1220,7 @@ int bm_gp_pool_quick_init(u32 pool, u32 num_of_buffers, u32 fill_level, struct m
 	rc = bm_enable_status_get(&bm_req_rcv_en);
 	if (rc != OK)
 		return rc;
-	if (bm_req_rcv_en == ON) {
+	if (bm_req_rcv_en == BM_UNIT_IS_ENABLED) {
 		rc = -BM_ATTR_CHANGE_AFTER_BM_ENABLE;
 		return rc;
 	}
@@ -1192,7 +1236,6 @@ int bm_global_registers_dump(void)
 	u32 reg_base_address, reg_size, reg_offset;
 	int rc = !OK;
 	char reg_name[50];
-
 	struct bm_sys_nrec_common_d0_st  reg_sys_nrec_common_d0_st;
 	struct bm_sys_nrec_common_d1_st  reg_sys_nrec_common_d1_st;
 	struct bm_sys_nrec_common_d2_st  reg_sys_nrec_common_d2_st;
@@ -1206,6 +1249,8 @@ int bm_global_registers_dump(void)
 	struct bm_dm_axi_wr_pend_fifo_st reg_dm_axi_wr_pend_fifo_st;
 	struct bm_bm_idle_st             reg_bm_idle_st;
 
+	BM_AVAILABLE_CHECK();
+
 	reg_base_address =      bm.sys_nrec_common_d0_st;
 	reg_size   =   bm_reg_size.sys_nrec_common_d0_st;
 	reg_offset = bm_reg_offset.sys_nrec_common_d0_st * 0;
@@ -1487,6 +1532,8 @@ int bm_pool_registers_dump(u32 pool)
 	struct bm_tpr_drw_mng_ball_dyn_data tab_tpr_drw_mng_ball_dyn_data;
 	struct bm_tpr_ctrs_0_data           tab_tpr_ctrs_0_data;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((pool            <     BM_POOL_MIN) || (pool            >    BM_POOL_MAX))
 		return rc;
 	if ((pool            >  BM_POOL_QM_MAX) && (pool            < BM_POOL_GP_MIN))
@@ -1699,7 +1746,6 @@ int bm_bank_registers_dump(u32 bank)
 	int rc = -BM_INPUT_NOT_IN_RANGE;
 	u32 bid;
 	char reg_name[50];
-
 	struct bm_b_sys_rec_bank_d0_st       reg_b_sys_rec_bank_d0_st;
 	struct bm_b_sys_rec_bank_d1_st       reg_b_sys_rec_bank_d1_st;
 	struct bm_b_bank_req_fifos_st        reg_b_bank_req_fifos_st;
@@ -1707,6 +1753,8 @@ int bm_bank_registers_dump(u32 bank)
 	struct bm_bgp_past_alc_fifos_st      reg_bgp_past_alc_fifos_st;
 	struct bm_b0_rls_wrp_ppe_fifos_st    reg_b0_rls_wrp_ppe_fifos_st;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((bank            <     BM_BANK_MIN) || (bank            >     BM_BANK_MAX))
 		return rc;
 
@@ -1877,6 +1925,8 @@ int bm_cache_memory_dump(u32 bank)
 	struct bm_cache_b0_mem_data     reg_cache_b0_data;
 	struct bm_cache_bgp_data        reg_cache_bgp_data;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((bank            <     BM_BANK_MIN) || (bank            >     BM_BANK_MAX))
 		return rc;
 
@@ -1948,6 +1998,8 @@ int bm_idle_status_get(u32 *status)
 	int rc = -BM_INPUT_NOT_IN_RANGE;
 	struct bm_bm_idle_st reg_bm_idle_st;
 
+	BM_AVAILABLE_CHECK();
+
 	if (((u32)status < BM_DATA_PTR_MIN) || ((u32)status > BM_DATA_PTR_MAX))
 		return rc;
 
@@ -1956,7 +2008,6 @@ int bm_idle_status_get(u32 *status)
 	reg_offset = bm_reg_offset.bm_idle_st * 0;
 
 	rc =  bm_register_read(reg_base_address, reg_offset, reg_size,  (u32 *)&reg_bm_idle_st);
-/*	rc =  bm_register_read(reg_base_address, reg_offset, reg_size,  &status);  if (rc != 0) return rc; */
 	if (rc != OK)
 		return rc;
 	*status = reg_bm_idle_st.bm_idle_st;
@@ -1972,6 +2023,8 @@ int bm_pool_status_get(u32 pool, u32 *pool_nempty, u32 *dpool_ae, u32 *dpool_af)
 	u32 pid, bid, pid_local;
 	struct bm_pool_st   reg_pool_st;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((pool             <     BM_POOL_MIN) || (pool             >     BM_POOL_MAX))
 		return rc;
 	if ((pool             >  BM_POOL_QM_MAX) && (pool             <  BM_POOL_GP_MIN))
@@ -2017,6 +2070,8 @@ int bm_idle_debug(void)
 	struct bm_dm_axi_wr_pend_fifo_st       reg_dm_axi_wr_pend_fifo_st;
 	char reg_name[50];
 
+	BM_AVAILABLE_CHECK();
+
 	for (bid = 0; bid < BM_NUMBER_OF_BANKS; bid++) {
 		reg_base_address =      bm.b_bank_req_fifos_st;
 		reg_size   =   bm_reg_size.b_bank_req_fifos_st;
@@ -2173,27 +2228,6 @@ int bm_idle_debug(void)
 	return rc;
 }
 
-/*Errors and interrupts handling – TBD*/
-/*
-1.	bm_inter_read(u32 group, u32 *dataPtr)
-2.	bm_inter_clean(u32 group)
-3.	bm_inter_mask_set(u32 group, u32 mask)
-Note: it is recommended that interrupts mask will be set after BM is enabled and that the interrupted will be
-							unmasked with correlation to the specific configuration
-4.	bm_error_read(u32 group, u32 *dataPtr)
-5.	bm_error_clean(u32 group)
-6.	bm_error_mask_set (u32 group, u32 mask)
-7.	List of registers that are used for interrupt handling. API will be defined later with the interrupt
-							handling definition
-a.	bn_sys_rec_bank_d0_st: PID/VMID of last VMID-miss event for alloc/release:
-							Postponed till we handle interupts
-b.	bn_sys_rec_bank_d1_st: PID/source client of last release/alloc request to disabled pool:
-							Postponed till we handle interupts
-c.	sys_nrec_common_d0_st: PID of last alloc/release. Postponed till we handle interupts
-d.	sys_nrec_common_d1_st: PID of last DRAM read. Postponed till we handle interupts
-e.	common_general_conf: field drm_si_decide_extra_fill. According to Koby this is currently not in used
-*/
-
 int bm_error_dump(void)
 {
 	u32 reg_base_address, reg_size, reg_offset;
@@ -2210,6 +2244,8 @@ int bm_error_dump(void)
 	struct bm_b_dpool_af_intr_cause         reg_b_dpool_af_intr_cause;
 	char reg_name[50];
 
+	BM_AVAILABLE_CHECK();
+
 	for (bid = 0; bid < BM_NUMBER_OF_BANKS; bid++) {
 		reg_base_address =      bm.b_sys_rec_bank_intr_cause[bid];
 		reg_size   =   bm_reg_size.b_sys_rec_bank_intr_cause[bid];
@@ -2586,6 +2622,8 @@ int bm_pool_memory_fill(u32 pool, u32 num_of_buffers, struct mv_a40 *base_addres
 	u32 i, *p;
 	granularity_of_pe_in_dram = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_DRAM;	/* 64/4 */
 
+	BM_AVAILABLE_CHECK();
+
 	if ((num_of_buffers % granularity_of_pe_in_dram) != 0) /* UNIT_OF__1_BYTES = 1 */
 		return rc; /* PE_size is 22 bit */
 	if ((pool            <         BM_POOL_QM_MIN) || (pool            >         BM_POOL_QM_MAX))
@@ -2639,6 +2677,8 @@ int bm_pool_dram_set(u32 pool, u32 num_of_buffers, u32 pe_size, struct mv_a40 *b
 	struct bm_d_mng_ball_stat_data          tab_dpr_d_mng_ball_stat;
 	u32 granularity_of_pe_in_dram;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((pool >= BM_POOL_QM_MIN) && (pool <= BM_POOL_QM_MAX)) { /* QM pools */
 		granularity_of_pe_in_dram = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_DRAM;	/* 64/4 */
 	} else if ((pool >= BM_POOL_GP_MIN) && (pool <= BM_POOL_GP_MAX)) { /* GP pools */
@@ -2681,7 +2721,7 @@ int bm_pool_dram_set(u32 pool, u32 num_of_buffers, u32 pe_size, struct mv_a40 *b
 	} else
 		return rc;
 
-	if ((pe_size         <         BM_PE_SIZE_MIN) || (pe_size         >         BM_PE_SIZE_MAX))
+	if ((pe_size         != BM_PE_SIZE_IS_32_BITS) && (pe_size         != BM_PE_SIZE_IS_40_BITS))
 		return rc;
 
 	if ((base_address->dma_msb < BM_DRAM_ADDRESS_MIN_MSB) ||
@@ -2738,6 +2778,8 @@ int bm_pool_fill_level_set(u32 pool, u32 num_of_buffers, u32 pe_size, u32 quick_
 	struct bm_tpr_drw_mng_ball_dyn_data         tab_tpr_drw_mng_ball_dyn;
 	u32 granularity_of_pe_in_dram;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((pool >= BM_POOL_QM_MIN) && (pool <= BM_POOL_QM_MAX)) { /* QM pools */
 		granularity_of_pe_in_dram = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_DRAM;	/* 64/4 */
 	} else if ((pool >= BM_POOL_GP_MIN) && (pool <= BM_POOL_GP_MAX)) { /* GP pools */
@@ -2771,7 +2813,7 @@ int bm_pool_fill_level_set(u32 pool, u32 num_of_buffers, u32 pe_size, u32 quick_
 	} else
 		return rc;
 
-	if ((pe_size        <    BM_PE_SIZE_MIN) || (pe_size        >         BM_PE_SIZE_MAX))
+	if ((pe_size   != BM_PE_SIZE_IS_32_BITS) && (pe_size        != BM_PE_SIZE_IS_40_BITS))
 		return rc;
 	if ((quick_init     < BM_QUICK_INIT_MIN) || (quick_init     >      BM_QUICK_INIT_MAX))
 		return rc;
@@ -2808,6 +2850,8 @@ int bm_pool_enable(u32 pool, u32 quick_init)
 	struct bm_pool_conf_b0  reg_b0_pool_conf;
 	struct bm_pool_conf_bgp reg_bgp_pool_conf;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((pool       <       BM_POOL_MIN) || (pool       >       BM_POOL_MAX))
 		return rc;
 	if ((pool       >    BM_POOL_QM_MAX) && (pool       <    BM_POOL_GP_MIN))
@@ -2859,9 +2903,11 @@ int bm_gp_pool_pe_size_set(u32 pool, u32 pe_size)
 	u32 pid, bid, pid_local;
 	struct bm_pool_conf_bgp reg_bgp_pool_conf;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((pool    < BM_POOL_GP_MIN) || (pool    > BM_POOL_GP_MAX))
 		return rc;
-	if ((pe_size < BM_PE_SIZE_MIN) || (pe_size > BM_PE_SIZE_MAX))
+	if ((pe_size != BM_PE_SIZE_IS_32_BITS) && (pe_size != BM_PE_SIZE_IS_40_BITS))
 		return rc;
 
 	pid = (int)pool;
@@ -2888,6 +2934,8 @@ int bm_gp_pool_pair_set(u32 pool, u32 pool_pair)
 	u32 pid, bid, pid_local;
 	struct bm_pool_conf_bgp reg_bgp_pool_n_conf;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((pool      <   BM_POOL_GP_MIN) || (pool      >   BM_POOL_GP_MAX))
 		return rc;
 	if ((pool_pair < BM_POOL_PAIR_MIN) || (pool_pair > BM_POOL_PAIR_MAX))
@@ -2921,6 +2969,8 @@ int bm_pool_cache_set(u32 pool, u32 cache_vmid, u32 cache_attr, u32 cache_so_thr
 	struct bm_pool_conf_bgp   reg_bgp_pool_conf;
 	struct bm_c_mng_stat_data tab_dpr_c_mng_stat;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((pool >= BM_POOL_QM_MIN) || (pool <= BM_POOL_QM_MAX)) /* QM pools */
 		granularity_of_pe_in_cache = GRANULARITY_OF_64_BYTES / QM_PE_SIZE_IN_BYTES_IN_CACHE;	/* 64/4 */
 	else if ((pool >= BM_POOL_GP_MIN) || (pool <= BM_POOL_GP_MAX)) /* GM pools */
@@ -3043,6 +3093,8 @@ int bm_pool_disable(u32 pool)
 	struct bm_pool_conf_b0  reg_b0_pool_conf;
 	struct bm_pool_conf_bgp reg_bgp_pool_conf;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((pool  <    BM_POOL_MIN) || (pool  >     BM_POOL_MAX))
 		return rc;
 	if ((pool  > BM_POOL_QM_MAX) && (pool  < BM_POOL_GP_MIN))
@@ -3090,6 +3142,8 @@ int bm_pool_enabled_get(u32 pool, u32 *enabled, u32 *quick_init)
 	struct bm_pool_conf_b0  reg_b0_pool_conf;
 	struct bm_pool_conf_bgp reg_bgp_pool_conf;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((pool       <       BM_POOL_MIN) || (pool       >       BM_POOL_MAX))
 		return rc;
 	if ((pool       >    BM_POOL_QM_MAX) && (pool       <    BM_POOL_GP_MIN))
@@ -3124,21 +3178,62 @@ int bm_pool_enabled_get(u32 pool, u32 *enabled, u32 *quick_init)
 	rc = OK;
 	return rc;
 }
+/* Get pe_size */
+int bm_pool_pe_size_get(u32 pool, u32 *pe_size)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = OK;
+	u32 pid, bid, pid_local;
+	struct bm_pool_conf_bgp reg_bgp_pool_conf;
+
+	BM_AVAILABLE_CHECK();
+
+	if ((pool            <     BM_POOL_MIN) || (pool            >    BM_POOL_MAX))
+		return -BM_INPUT_NOT_IN_RANGE;
+	if ((pool            >  BM_POOL_QM_MAX) && (pool            < BM_POOL_GP_MIN))
+		return -BM_INPUT_NOT_IN_RANGE; /* pools 4, 5, 6, 7 don't exist */
+
+	pid = (int)pool;
+	bid = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	if ((pool >= BM_POOL_QM_MIN) || (pool <= BM_POOL_QM_MAX)) { /* QM pools */
+		*pe_size = BM_PE_SIZE_IS_32_BITS;
+	} else if ((pool >= BM_POOL_GP_MIN) || (pool <= BM_POOL_GP_MAX)) { /* GM pools */
+		reg_base_address =      bm.b_pool_n_conf[bid];
+		reg_size   =   bm_reg_size.b_pool_n_conf[bid];
+		reg_offset = bm_reg_offset.b_pool_n_conf[bid] * pid_local;
+
+		rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&reg_bgp_pool_conf);
+		if (rc != OK)
+			return rc;
+
+		*pe_size = reg_bgp_pool_conf.pe_size;
+	} else
+		return rc;
+
+	return rc;
+}
 
 /* Get pool pointers - internal registers */
 int bm_pool_pointer_get(u32 pool, u32 *rd_ptr, u32 *wr_ptr)
 {
 	u32 reg_base_address, reg_size, reg_offset;
-	int rc = -BM_INPUT_NOT_IN_RANGE;
-	u32 pid;
+	int rc = OK;
+	u32 pid, bid, pid_local;
+	u32 pe_size;
 	struct bm_tpr_dro_mng_ball_dyn_data tab_tpr_dro_mng_ball_dyn_data;
 
+	BM_AVAILABLE_CHECK();
+
 	if ((pool            <     BM_POOL_MIN) || (pool            >    BM_POOL_MAX))
-		return rc;
+		return -BM_INPUT_NOT_IN_RANGE;
 	if ((pool            >  BM_POOL_QM_MAX) && (pool            < BM_POOL_GP_MIN))
-		return rc; /* pools 4, 5, 6, 7 don't exist */
+		return -BM_INPUT_NOT_IN_RANGE; /* pools 4, 5, 6, 7 don't exist */
 
-	pid       = (int)pool;
+	pid = (int)pool;
+	bid = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
 
 	reg_base_address =      bm.tpr_dro_mng_ball_dyn;
 	reg_size   =   bm_reg_size.tpr_dro_mng_ball_dyn;
@@ -3148,21 +3243,34 @@ int bm_pool_pointer_get(u32 pool, u32 *rd_ptr, u32 *wr_ptr)
 	if (rc != OK)
 		return rc;
 
-	/* r/w pointer of BM to pool is given in 64 bits unit. starting from 0 */
-	*rd_ptr = tab_tpr_dro_mng_ball_dyn_data.dram_rd_ptr * 2;
-	*wr_ptr = tab_tpr_dro_mng_ball_dyn_data.dram_wr_ptr * 2;
-
+	/*
+	 * r/w pointer of BM to pool is given in 64 bits unit. starting from 0
+	 * QM PE's are in 32bits so we multiply by 2 to get number of PE's
+	 * GP PE's can either be in 32bits or in 40 bits
+	*/
+	rc = bm_pool_pe_size_get(pool, &pe_size);
+	if (rc != OK)
+		return rc;
+	if (pe_size == BM_PE_SIZE_IS_32_BITS) {
+		*rd_ptr = tab_tpr_dro_mng_ball_dyn_data.dram_rd_ptr * 2;
+		*wr_ptr = tab_tpr_dro_mng_ball_dyn_data.dram_wr_ptr * 2;
+	} else if (pe_size == BM_PE_SIZE_IS_40_BITS) {
+		*rd_ptr = tab_tpr_dro_mng_ball_dyn_data.dram_rd_ptr;
+		*wr_ptr = tab_tpr_dro_mng_ball_dyn_data.dram_wr_ptr;
+	} else
+		return rc;
 
-	rc = OK;
 	return rc;
 }
-/* Get interupt cause */
-int bm_bank_inter_get(u32 bank, u32 *ne, u32 *ae, u32 *af)
+/* Get interupt cause for pool capacity*/
+int bm_bank_intr_pool_fill_get(u32 bank, u32 *ne, u32 *ae, u32 *af)
 {
 	u32 reg_base_address, reg_size, reg_offset;
 	int rc = OK;
 	u32 bid;
 
+	BM_AVAILABLE_CHECK();
+
 	bid = bank;
 	reg_base_address =      bm.pool_nempty_intr_cause[bid];
 	reg_size   =   bm_reg_size.pool_nempty_intr_cause[bid];
@@ -3190,18 +3298,63 @@ int bm_bank_inter_get(u32 bank, u32 *ne, u32 *ae, u32 *af)
 
 	return rc;
 }
+/* Get cache fill */
+int bm_pool_cache_fill_get(u32 pool, u32 *rd_ptr, u32 *wr_ptr, u32 *fill_min, u32 *fill_max)
+{
+	u32 reg_base_address, reg_size, reg_offset;
+	int rc = OK;
+	u32 bid, pid, pid_local;
+	struct bm_c_mng_dyn_data            tab_tpr_c_mng_dyn;
+
+	BM_AVAILABLE_CHECK();
+
+	if ((pool            <     BM_POOL_MIN) || (pool            >    BM_POOL_MAX))
+		return -BM_INPUT_NOT_IN_RANGE;
+	if ((pool            >  BM_POOL_QM_MAX) && (pool            < BM_POOL_GP_MIN))
+		return -BM_INPUT_NOT_IN_RANGE; /* pools 4, 5, 6, 7 don't exist */
+
+	pid       = (int)pool;
+	bid       = BM_PID_TO_BANK(pid);
+	pid_local = BM_PID_TO_PID_LOCAL(pid);
+
+	reg_base_address =      bm.tpr_c_mng_b_dyn[bid];
+	reg_size   =   bm_reg_size.tpr_c_mng_b_dyn[bid];
+	reg_offset = bm_reg_offset.tpr_c_mng_b_dyn[bid] * pid_local;
+
+	rc =  bm_register_read(reg_base_address, reg_offset, reg_size, (u32 *)&tab_tpr_c_mng_dyn);
+	if (rc != OK)
+		return rc;
+	/*
+	 * QM pools in each cache line there are 4 PE's (4 Bytes)
+	 * GP pools in each cache line there is 1 PE's (8 Bytes)
+	 */
+	if ((pool >= BM_POOL_QM_MIN) || (pool <= BM_POOL_QM_MAX)) { /* QM pools */
+		*fill_min = tab_tpr_c_mng_dyn.cache_fill_min * 4;
+		*fill_max = tab_tpr_c_mng_dyn.cache_fill_max * 4;
+		*rd_ptr = tab_tpr_c_mng_dyn.cache_rd_ptr * 4;
+		*wr_ptr = tab_tpr_c_mng_dyn.cache_wr_ptr * 4;
+	} else if ((pool >= BM_POOL_GP_MIN) || (pool <= BM_POOL_GP_MAX)) { /* GM pools */
+		*fill_min = tab_tpr_c_mng_dyn.cache_fill_min;
+		*fill_max = tab_tpr_c_mng_dyn.cache_fill_max;
+		*rd_ptr = tab_tpr_c_mng_dyn.cache_rd_ptr;
+		*wr_ptr = tab_tpr_c_mng_dyn.cache_wr_ptr;
+	} else
+		return rc;
+
+	return rc;
+}
 
 /* Register Read Write */
 
 int bm_register_read(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr)
 {
-	int rc = -BM_INPUT_NOT_IN_RANGE;
+	int rc = OK;
 	char reg_name[255];
 	/*u32 *temp;
 	u32 i;*/
 
 	if (((u32)dataPtr <  BM_DATA_PTR_MIN) || ((u32)dataPtr >  BM_DATA_PTR_MAX))
-		return rc;
+		return -BM_INPUT_NOT_IN_RANGE;
 
 	bm_register_name_get(base_address, offset, reg_name);
 	mv_pp3_hw_read(base_address+offset, wordsNumber, dataPtr);
@@ -3214,19 +3367,18 @@ int bm_register_read(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr
 	}
 	pr_info("\n");
 	*/
-	rc = OK;
 	return rc;
 }
 
 int bm_register_write(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPtr)
 {
-	int rc = -BM_INPUT_NOT_IN_RANGE;
+	int rc = OK;
 	char reg_name[255];
 	/*int i;
 	u32 *temp;*/
 
 	if (((u32)dataPtr <  BM_DATA_PTR_MIN) || ((u32)dataPtr >  BM_DATA_PTR_MAX))
-		return rc;
+		return -BM_INPUT_NOT_IN_RANGE;
 
 	bm_register_name_get(base_address, offset, reg_name);
 	/*
@@ -3240,7 +3392,6 @@ int bm_register_write(u32 base_address, u32 offset, u32 wordsNumber, u32 *dataPt
 	*/
 	mv_pp3_hw_write(base_address+offset, wordsNumber, dataPtr);
 
-	rc = OK;
 	return rc;
 }
 
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h
index b7d0eca..2a161e3 100644
--- a/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm.h
@@ -170,7 +170,12 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  * QOS read/write for any pool in the range 0 to 3 (2 bits)
 */
 
-#define BM_ACACHE_MIN				0
+#define BM_ACACHE_DEF						3
+#define BM_ADOMAIN_DEF						0
+#define BM_ARQOS_DEF						1
+#define BM_AWQOS_DEF						0
+
+#define BM_ACACHE_MIN						0
 #define BM_ACACHE_MAX				0x0000000F	/* 15 */
 #define BM_ADOMAIN_MIN				         0
 #define BM_ADOMAIN_MAX				0x00000003	/*   3 */
@@ -202,8 +207,6 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #define BM_QUICK_INIT_MAX			0x00000001
 #define BM_POOL_PAIR_MIN			         0
 #define BM_POOL_PAIR_MAX			0x00000001
-#define BM_PE_SIZE_MIN				0x00000001
-#define BM_PE_SIZE_MAX				0x00000001
 #define BM_VMID_MIN					         0
 #define BM_VMID_MAX					0x0000003F	/*  63 */
 #define BM_CACHE_VMID_MIN			         0
@@ -242,7 +245,11 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #define BM_STATUS_IS_IDLE			1
 #define BM_POOL_IS_ENABLED			1
 #define BM_QUICK_INIT_IS_ON			1
+#define BM_QUICK_INIT_IS_OFF		0
 #define BM_POOL_INIT_COMPLETED		1
+#define BM_UNIT_IS_ENABLED			1
+#define BM_SMALL_PARTITION_IN_CACHE 1
+#define BM_BIG_PARTITION_IN_CACHE   0
 
 #define BM_PID_TO_BANK(_pid)                \
 	((((_pid) >= 0) && ((_pid)   <=  3)) ?	0 :	\
@@ -421,7 +428,7 @@ int bm_disable(void);
 
 
 /**
- *  gives fill level of pool in DRAM
+ *  gives fill level of pool in DRAM in PE's count
  *	Return values:
  *		0 - success
  */
@@ -630,6 +637,15 @@ int bm_pool_cache_set(
 int bm_pool_disable(u32 pool);
 
 /**
+ *  Per pool returns what is the PE size
+ *  1 - for 32bits, 0 for 40bits
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_pool_pe_size_get(u32 pool, u32 *pe_size);
+
+/**
  *  Per pool returns if pool is enabled and if in quick init mode
  *
  *  Return values:
@@ -639,6 +655,9 @@ int bm_pool_enabled_get(u32 pool, u32 *enabled, u32 *quick_init);
 
 /**
  *  Per pool returns BM read and write pointer to pool
+ *  the pointers goes on the pool as a FIFO.
+ *  when there is traffic pointers are less accurate
+ *  the pointers units are in PE's
  *
  *  Return values:
  *		0 - success
@@ -646,13 +665,23 @@ int bm_pool_enabled_get(u32 pool, u32 *enabled, u32 *quick_init);
 int bm_pool_pointer_get(u32 pool, u32 *rd_ptr, u32 *wr_ptr);
 
 /**
- *  Per Bank return interupt cause indicating if there was
+ *  Per Bank return interupt cause indicating per pool if there was
  *  not empty interupt, almost empty interupt and almost full interupt
  *
  *  Return values:
  *		0 - success
  */
-int bm_bank_inter_get(u32 bank, u32 *ne, u32 *ae, u32 *af);
+int bm_bank_intr_pool_fill_get(u32 bank, u32 *ne, u32 *ae, u32 *af);
+
+/**
+ *  Per pool return cache max and min fill level.
+ *  when there is no requests max and min should be identical.
+ *  read and write pointer of cache (which works as fifo)
+ *
+ *  Return values:
+ *		0 - success
+ */
+int bm_pool_cache_fill_get(u32 pool, u32 *rd_ptr, u32 *wr_ptr, u32 *fill_min, u32 *fill_max);
 
 
 /**
diff --git a/drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c
index 90344ea..4859332 100644
--- a/drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c
+++ b/drivers/net/ethernet/marvell/pp3/bm/mv_bm_sysfs.c
@@ -84,64 +84,51 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 	pr_err("%s: error code = 0x%08X on illegal operation at line %05d in function <%s> in file <%s>\n", _func, _rc, __LINE__, __func__, __FILE__);	\
 */
 
-#define PR_INFO_CALLED		\
-{							\
-	pr_info("%s is called\n", attr->attr.name);	\
-}
-
 static ssize_t mv_bm_help(char *b)
 {
 	int o = 0; /* buffer offset */
 	int s = PAGE_SIZE; /* buffer size */
 
 
-	o += scnprintf(b+o, s-o, "cat status                               - show BM status\n");
-	o += scnprintf(b+o, s-o, "echo      > open                         - Open session with BM\n");
-	o += scnprintf(b+o, s-o, "echo      > attr_all_pools_def_set       - Configures BM read/write def attr\n");
-	o += scnprintf(b+o, s-o, "echo      > enable_status_get            - Get BM enable status\n");
-	o += scnprintf(b+o, s-o, "echo      > enable                       - enable BM\n");
-	o += scnprintf(b+o, s-o, "echo      > disable                      - disable BM\n");
-	o += scnprintf(b+o, s-o, "echo      > idle_status_get              - Read BM idle status\n");
-	o += scnprintf(b+o, s-o, "echo nb   > qm_gpm_pools_def_quick_init  - Initiates GPM pools\n");
-	o += scnprintf(b+o, s-o, "echo nb   > qm_dram_pools_def_quick_init - Initiates DRAM pools\n");
-	o += scnprintf(b+o, s-o, "echo p    > pool_quick_init_status_get   - Get pool quick init status\n");
-	o += scnprintf(b+o, s-o, "echo p    > pool_fill_level_get          - Get pool fill level in DRAM\n");
-	o += scnprintf(b+o, s-o, "echo id   > vmid_set                     - Set BM VMID\n");
-	o += scnprintf(b+o, s-o, "echo pool > pool_disable                 - Set Pool to disable\n");
-	o += scnprintf(b+o, s-o, "echo p nb > pool_memory_fill             - Fill memory of pool with PE index\n");
-	o += scnprintf(b+o, s-o, "echo p qi > pool_enable                  - Enables BM pool\n");
-	o += scnprintf(b+o, s-o, "echo p ps > gp_pool_pe_size_set          - Set PE pointer size in GP pool\n");
-	o += scnprintf(b+o, s-o, "echo p pp > gp_pool_pair_set             - Configure pool works in pairs\n");
-	o += scnprintf(b+o, s-o, "echo nb p nb pm pp > test                   - Open&init mandatory registers\n");
-	o += scnprintf(b+o, s-o, "echo p nb pm pp    > gp_pool_def_basic_init - Default basic init of gp pools\n");
-	o += scnprintf(b+o, s-o, "echo p nb fl pm pp > gp_pool_def_quick_init - Default quick init of gp pools\n");
-	o += scnprintf(b+o, s-o, "echo p nb ps qi    > pool_fill_level_set    - Conf Fill level of pool in DRAM\n");
-	o += scnprintf(b+o, s-o, "echo p pn dpe dpf  > pool_status_get        - not empty almost full/empty\n");
-	o += scnprintf(b+o, s-o, "echo p nb ps et ft > pool_dram_set          - Conf Fill level of pool in DRAM\n");
-	o += scnprintf(b+o, s-o, "echo rD wD rC wC rQ wQ    > attr_qm_pool_set                     - rw att QM\n");
-	o += scnprintf(b+o, s-o, "echo rD wD rC wC rQ wQ    > attr_gp_pool_set                     - rw att GP\n");
-	o += scnprintf(b+o, s-o, "echo p cid ca cot cit cnb > pool_cache_set                       - Conf cache\n");
-	o += scnprintf(b+o, s-o, "echo nb et ft id ca cot cit, cnb  > qm_gpm_pools_quick_init      - Ini QM GPM\n");
-	o += scnprintf(b+o, s-o, "echo p nb ps pp et ft id ca cot cit cnb > gp_pool_basic_init     - B initi GP\n");
-	o += scnprintf(b+o, s-o, "echo p nb fl ps pp et at cid ca cot cit cnb > gp_pool_quick_init - GP ini\n");
-	o += scnprintf(b+o, s-o, "echo nb et ft id ca cot cit, cnb > qm_dram_pools_quick_init      - Ini QM DRAM\n");
-
+	o += scnprintf(b+o, s-o, "\n");
+	o += scnprintf(b+o, s-o, "cat                status                         - show BM status\n");
+	o += scnprintf(b+o, s-o, "echo               > open                         - Open session with BM\n");
+	o += scnprintf(b+o, s-o, "echo               > attr_all_pools_def_set       - Config read/write def attr\n");
+	o += scnprintf(b+o, s-o, "echo nb            > qm_gpm_pools_def_quick_init  - Initiates GPM pools\n");
+	o += scnprintf(b+o, s-o, "echo nb            > qm_dram_pools_def_quick_init - Initiates DRAM pools\n");
+	o += scnprintf(b+o, s-o, "echo               > enable                       - Enable BM\n");
+	o += scnprintf(b+o, s-o, "echo p nb pm pp    > gp_pool_def_basic_init       - Default basic init gp pools\n");
+	o += scnprintf(b+o, s-o, "echo p nb fl pm pp > gp_pool_def_quick_init       - Default quick init gp pools\n");
+	o += scnprintf(b+o, s-o, "echo p             > pool_quick_init_status_get   - Get pool quick init status\n");
+	o += scnprintf(b+o, s-o, "echo id            > vmid_set                     - Set BM VMID\n");
+	o += scnprintf(b+o, s-o, "echo nb p nb pm pp > test                         - Open&init mandatory regs\n");
+	o += scnprintf(b+o, s-o, "\n");
+	o += scnprintf(b+o, s-o, "echo rD wD rC wC rQ wQ                     > attr_qm_pool_set\n");
+	o += scnprintf(b+o, s-o, "echo rD wD rC wC rQ wQ                     > attr_gp_pool_set\n");
+	o += scnprintf(b+o, s-o, "echo nb qe pl ae af cv ca co ci cb         > qm_gpm_pools_quick_init\n");
+	o += scnprintf(b+o, s-o, "echo nb qe pl ae af cv ca co ci cb         > qm_dram_pools_quick_init\n");
+	o += scnprintf(b+o, s-o, "echo p nb ad ps pp ae af cv ca co ci cb    > gp_pool_basic_init\n");
+	o += scnprintf(b+o, s-o, "echo p nb ad fl ps pp ae af cv ca co ci cb > gp_pool_quick_init\n");
+	/* o += scnprintf(b+o, s-o, "echo      > disable                      - disable BM\n"); */
 
+	o += scnprintf(b+o, s-o, "\n");
 	o += scnprintf(b+o, s-o, "parameters: [p]    pool number\n");
 	o += scnprintf(b+o, s-o, "            [nb]   number of buffers\n");
 	o += scnprintf(b+o, s-o, "            [id]   vmid\n");
-	o += scnprintf(b+o, s-o, "            [pool] pool number\n");
-	o += scnprintf(b+o, s-o, "            [qi]   quick init mode: 1 - quick init, 0 - not quick init\n");
-	o += scnprintf(b+o, s-o, "            [ps]   PE size: 1 - 32bits, 0 - 40 bits\n");
-	o += scnprintf(b+o, s-o, "            [pp]   pool pair: 1 - alloc in pairs, 0 - alloc not in pairs\n");
+	o += scnprintf(b+o, s-o, "            [ps]   PE size: 1 is 32bits, 0 is 40 bits\n");
+	o += scnprintf(b+o, s-o, "            [pp]   pool pair: 1 is alloc in pairs, 0 is alloc not in pairs\n");
 	o += scnprintf(b+o, s-o, "            [fl]   fill level\n");
-	o += scnprintf(b+o, s-o, "            [pm]   partition model: 1 - small partition in cache, 0 - big\n");
-	o += scnprintf(b+o, s-o, "            [rD]   arDomain\n");
-	o += scnprintf(b+o, s-o, "            [wD]   awDomain\n");
-	o += scnprintf(b+o, s-o, "            [rC]   arCache\n");
-	o += scnprintf(b+o, s-o, "            [wC]   awCache\n");
-	o += scnprintf(b+o, s-o, "            [rQ]   arQOS\n");
-	o += scnprintf(b+o, s-o, "            [wQ]   awQOS\n");
+	o += scnprintf(b+o, s-o, "            [pm]   partition model: 1 is small partition in cache, 0 is big\n");
+	o += scnprintf(b+o, s-o, "            [ae]   almost empty threshold\n");
+	o += scnprintf(b+o, s-o, "            [af]   almost full threshold\n");
+	o += scnprintf(b+o, s-o, "            [qe]   qm qece pool base address\n");
+	o += scnprintf(b+o, s-o, "            [pl]   qm pl pool base address\n");
+	o += scnprintf(b+o, s-o, "            [ad]   pool base address\n");
+	o += scnprintf(b+o, s-o, "            [cb]   cache number of buffers\n");
+	o += scnprintf(b+o, s-o, "            [cv ca]   cache vmid, cache attributes\n");
+	o += scnprintf(b+o, s-o, "            [co ci]   cache swap out threshold, cache swap in threshold\n");
+	o += scnprintf(b+o, s-o, "            [rD wD rC wC rQ wQ] arDomain awDomain arCache awCache arQOS awQOS\n");
+
 	o += scnprintf(b+o, s-o, "\n");
 
 	return o;
@@ -156,7 +143,6 @@ static ssize_t mv_bm_show(struct device *dev,
 	if (!capable(CAP_NET_ADMIN))
 		return -EPERM;
 
-	pr_info("mv_bm_show is called\n");
 	if (!strcmp(name, "status")) {
 		u32 status = 0;
 		pr_info("bm_enable_status_get: ");
@@ -164,8 +150,6 @@ static ssize_t mv_bm_show(struct device *dev,
 		pr_info("status is %d\n", status);
 	} else if (!strcmp(name, "help")) {
 		off = mv_bm_help(buf);
-	} else if (!strcmp(name, "debug")) {
-		pr_info("debug\n");
 	} else {
 		off = 1;
 		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
@@ -180,9 +164,6 @@ static ssize_t mv_bm_config(struct device *dev,
 	const char      *name = attr->attr.name;
 	int rc = -BM_INPUT_NOT_IN_RANGE;
 	int             err = 0;
-/*
-	u32 flags;
-*/
 	unsigned long flags;
 
 	if (!capable(CAP_NET_ADMIN))
@@ -196,14 +177,14 @@ static ssize_t mv_bm_config(struct device *dev,
 		if (rc != OK)
 			PR_ERR_CODE(rc)
 	} else if (!strcmp(name, "test")) {
-		u32 qm_num_of_buffers;
+		u32 qm_num_of_buffers, gp_num_of_buffers;
 		struct mv_a40 qece_base_address, pl_base_address, base_address;
-		u32 pool, gp_num_of_buffers, partition_model, pool_pair;
+		u32 pool, gp_pool, partition_model, pool_pair;
 		u32 completed, fill_level, status = 0, temp, *temp_ptr, enabled, quick_init;
-		u32 ne, ae, af, rd_ptr, wr_ptr, i, pool_index;
+		u32 ne, ae, af, rd_ptr, wr_ptr, i, fill_level_max, fill_level_min;
 		struct bm_c_mng_stat_data cache;
-
-		sscanf(buf, "%d %d %d %d %d", &qm_num_of_buffers, &pool, &gp_num_of_buffers, &partition_model, &pool_pair);
+		/* Read input values */
+		sscanf(buf, "%d %d %d %d %d", &qm_num_of_buffers, &gp_pool, &gp_num_of_buffers, &partition_model, &pool_pair);
 		if ((qm_num_of_buffers == 0) || (gp_num_of_buffers == 0)) {
 			pr_err("wrong number of buffers. should be larger than 0\n");
 			return -1;
@@ -238,14 +219,14 @@ static ssize_t mv_bm_config(struct device *dev,
 			pr_err("qm gpm pool quick init failed\n");
 			return -1;
 		}
-		for (pool_index = 0; pool_index <= 1; pool_index++) {
+		for (pool = 0; pool <= 1; pool++) {
 			completed = fill_level = 0xFFFFFFFF;
-			rc = bm_pool_quick_init_status_get(pool_index, &completed);
+			rc = bm_pool_quick_init_status_get(pool, &completed);
 			if (completed != BM_POOL_INIT_COMPLETED) {
-				pr_err("qm gpm pool %d didn't complete quick init\n", pool_index);
+				pr_err("qm gpm pool %d didn't complete quick init\n", pool);
 				return -1;
 			}
-			if (pool_index == 0)
+			if (pool == 0)
 				temp_ptr = (u32 *)pl_base_address.virt_lsb;
 			else
 				temp_ptr = (u32 *)qece_base_address.virt_lsb;
@@ -257,17 +238,42 @@ static ssize_t mv_bm_config(struct device *dev,
 				temp_ptr++;
 			}
 
-			bm_pool_enabled_get(pool_index, &enabled, &quick_init);
-			pr_info("pool %d pool is enabled %d quick init mode %d\n", pool_index, enabled, quick_init);
-			bm_pool_status_get(pool_index, &ne, &ae, &af);
-			pr_info("pool %d cache nempty %d dram ae %d dram af %d\n", pool_index, ne, ae, af);
-			bm_pool_pointer_get(pool_index, &rd_ptr, &wr_ptr);
-			pr_info("pool %d read pointer %d write pointer %d\n", pool_index, rd_ptr, wr_ptr);
-			rc = bm_register_read(bm.dpr_c_mng_stat[0], bm_reg_offset.dpr_c_mng_stat[0] * pool_index, bm_reg_size.dpr_c_mng_stat[0], (u32 *)&cache);
-			pr_info("pool %d cache start %d end %d Bytes %d\n", pool_index, cache.cache_start, cache.cache_end,
+			bm_pool_enabled_get(pool, &enabled, &quick_init);
+			pr_info("pool %d pool is enabled %d quick init mode %d\n", pool, enabled, quick_init);
+			bm_pool_status_get(pool, &ne, &ae, &af);
+			pr_info("pool %d cache nempty %d dram ae %d dram af %d\n", pool, ne, ae, af);
+			bm_pool_pointer_get(pool, &rd_ptr, &wr_ptr);
+			pr_info("pool %d dram read pointer %d write pointer %d\n", pool, rd_ptr, wr_ptr);
+			rc = bm_register_read(bm.dpr_c_mng_stat[0], bm_reg_offset.dpr_c_mng_stat[0] * pool, bm_reg_size.dpr_c_mng_stat[0], (u32 *)&cache);
+			pr_info("pool %d cache start %d end %d Bytes %d\n", pool, cache.cache_start, cache.cache_end,
 				((cache.cache_end - cache.cache_start + 1) * 64));
-			rc = bm_pool_fill_level_get(pool_index, &fill_level);
-			pr_info("\t pool %d completed quick init = %d fill level %d Bytes\n", pool_index, completed, fill_level);
+			rc = bm_pool_fill_level_get(pool, &fill_level);
+			pr_info("\t pool %d dram fill level %d PE's\n", pool, fill_level);
+			if (qm_num_of_buffers  != rd_ptr + fill_level) {
+				pr_err("problem: since there are no traffic, read pointer + fill level should be equal to dram size\n");
+				return -1;
+			}
+			if (wr_ptr != 0) {
+				pr_err("problem: pool dram %d was full, write pointer should be 0\n", pool);
+				return -1;
+			}
+			bm_pool_cache_fill_get(pool, &rd_ptr, &wr_ptr, &fill_level_min, &fill_level_max);
+			pr_info("pool %d cache read pointer %d write pointer %d fill min %d fill max %d\n",
+				pool, rd_ptr, wr_ptr, fill_level_min, fill_level_max);
+			if (fill_level_min != fill_level_max) {
+				pr_err("problem: pool cache min&max fill level should be idenitcal\n");
+				return -1;
+			}
+			/* cache for pool 0 start in 0, for pool 1 starts after pool 1 */
+			if (((pool == 0) && (rd_ptr != 0)) || ((pool == 1) && (rd_ptr != 512))) {
+				pr_err("problem: pool cache was never read\n");
+				return -1;
+			}
+			if (((pool == 0) && (wr_ptr != fill_level_max)) || ((pool == 1) && (wr_ptr != fill_level_max + 512))) {
+				pr_err("problem: pool cache min&max fill level should be idenitcal to write pointer\n");
+				return -1;
+			}
+			pr_info("\t pool %d completed quick init = %d\n", pool, completed);
 		}
 		/* Enable BM unit */
 		rc = bm_enable();
@@ -279,70 +285,75 @@ static ssize_t mv_bm_config(struct device *dev,
 		pr_info("bm unit status is %d\n", status);
 		base_address.virt_lsb = (u32)dma_alloc_coherent(NULL, gp_num_of_buffers*4, &base_address.dma_lsb, GFP_KERNEL);
 		/* Init GP pool */
-		rc = bm_gp_pool_def_basic_init(pool, gp_num_of_buffers, &base_address, partition_model, pool_pair);
+		rc = bm_gp_pool_def_basic_init(gp_pool, gp_num_of_buffers, &base_address, partition_model, pool_pair);
 		if (rc != OK) {
-			pr_err("bm gp pool %d basic init failed\n", pool);
+			pr_err("bm gp pool %d basic init failed\n", gp_pool);
 			return -1;
 		}
-		rc = bm_pool_quick_init_status_get(pool, &completed);
-		rc = bm_pool_fill_level_get(pool, &fill_level);
-		pr_info("\t pool %d fill level %d Bytes\n", completed, fill_level);
+		rc = bm_pool_fill_level_get(gp_pool, &fill_level);
+		pr_info("\t pool %d fill level %d Bytes\n", gp_pool, fill_level);
 
 		bm_idle_status_get(&status);
 		pr_info("bm unit idle status is %s\n", ((status == BM_STATUS_IS_IDLE) ? "IDLE" : "BUSY"));
-		bm_pool_status_get(pool, &ne, &ae, &af);
-		pr_info("pool %d cache nempty %d dram ae %d dram af %d\n", pool, ne, ae, af);
-		bm_pool_pointer_get(pool, &rd_ptr, &wr_ptr);
-		pr_info("pool %d read pointer %d write pointer %d\n", pool, rd_ptr, wr_ptr);
+		bm_pool_status_get(gp_pool, &ne, &ae, &af);
+		pr_info("pool %d cache nempty %d dram ae %d dram af %d\n", gp_pool, ne, ae, af);
+		bm_pool_pointer_get(gp_pool, &rd_ptr, &wr_ptr);
+		pr_info("pool %d dram read pointer %d write pointer %d\n", gp_pool, rd_ptr, wr_ptr);
+		bm_pool_cache_fill_get(gp_pool, &rd_ptr, &wr_ptr, &fill_level_min, &fill_level_max);
+		pr_info("pool %d cache read pointer %d write pointer %d fill min %d fill max %d\n",
+				gp_pool, rd_ptr, wr_ptr, fill_level_min, fill_level_max);
+		if (fill_level_min != fill_level_max) {
+			pr_err("problem: pool cache min&max fill level should be idenitcal\n");
+			return -1;
+		}
+		if ((rd_ptr != 0) || (wr_ptr != 0) || (fill_level_min != 0) || (fill_level_max != 0)) {
+			pr_err("problem: pool cache was never read/write/filled\n");
+			return -1;
+		}
 
-		bm_bank_inter_get(0, &ne, &ae, &af);
+		bm_bank_intr_pool_fill_get(0, &ne, &ae, &af);
 		pr_info("bank 0 ne %x ae %x af %x\n", ne, ae, af);
-
-		bm_bank_inter_get(1, &ne, &ae, &af);
+		/*
+		 * pools 0 & 1 are not empty and almost full
+		 * no interupt was unmask
+		 */
+		if ((ae != 0) || (af != 6) || (ne != 6)) {
+			pr_err("wrong fill interupts for bank 0\n");
+			return -1;
+		}
+		bm_bank_intr_pool_fill_get(1, &ne, &ae, &af);
 		pr_info("bank 1 ne %x ae %x af %x\n", ne, ae, af);
+		/* GP pools were init with basic init - no filling was done */
+		if ((ae != 0) || (af != 0) || (ne != 0)) {
+			pr_err("wrong fill interupts for bank 1\n");
+			return -1;
+		}
 
 	} else if (!strcmp(name, "attr_all_pools_def_set")) {
-		PR_INFO_CALLED
 		rc = bm_attr_all_pools_def_set();
 		if (rc != OK)
 			PR_ERR_CODE(rc)
 	} else if (!strcmp(name, "attr_qm_pool_set")) {
 		u32 arDomain, awDomain, arCache, awCache, arQOS, awQOS;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		arDomain = awDomain = arCache = awCache = arQOS = awQOS = 0xFFFFFFFF;
+		/* Read input values */
 		sscanf(buf, "%d %d %d %d %d %d", &arDomain, &awDomain, &arCache, &awCache, &arQOS, &awQOS);
 		rc = bm_attr_qm_pool_set(arDomain, awDomain, arCache, awCache, arQOS, awQOS);
 		if (rc != OK)
 			PR_ERR_CODE(rc)
 	} else if (!strcmp(name, "attr_gp_pool_set")) {
 		u32 arDomain, awDomain, arCache, awCache, arQOS, awQOS;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		arDomain = awDomain = arCache = awCache = arQOS = awQOS = 0xFFFFFFFF;
+		/* Read input values */
 		sscanf(buf, "%d %d %d %d %d %d", &arDomain, &awDomain, &arCache, &awCache, &arQOS, &awQOS);
 		rc = bm_attr_gp_pool_set(arDomain, awDomain, arCache, awCache, arQOS, awQOS);
 		if (rc != OK)
 			PR_ERR_CODE(rc)
-	} else if (!strcmp(name, "enable_status_get"))	{
-		u32 bm_req_rcv_en;
-
-		/* Read input values */
-		PR_INFO_CALLED
-		bm_req_rcv_en = 0xFFFFFFFF;
-		rc = bm_enable_status_get(&bm_req_rcv_en);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
-		pr_info("\t bm_req_rcv_en = %d\n", bm_req_rcv_en);
 	} else if (!strcmp(name, "qm_gpm_pools_def_quick_init")) {
 		u32 num_of_buffers;
 		struct mv_a40 qece_base_address, pl_base_address;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		num_of_buffers = qece_base_address.dma_msb = qece_base_address.virt_msb = pl_base_address.dma_msb = pl_base_address.virt_msb = 0;
+		/* Read input values */
 		sscanf(buf, "%d", &num_of_buffers);
 		if (num_of_buffers == 0) {
 			pr_err("wrong number of buffers. should be larger than 0\n");
@@ -356,10 +367,8 @@ static ssize_t mv_bm_config(struct device *dev,
 	} else if (!strcmp(name, "qm_dram_pools_def_quick_init")) {
 		u32 num_of_buffers;
 		struct mv_a40 qece_base_address, pl_base_address;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		num_of_buffers = qece_base_address.dma_msb = qece_base_address.virt_msb = pl_base_address.dma_msb = pl_base_address.virt_msb = 0;
+		/* Read input values */
 		sscanf(buf, "%d", &num_of_buffers);
 		if (num_of_buffers == 0) {
 			pr_err("wrong number of buffers. should be larger than 0\n");
@@ -373,11 +382,9 @@ static ssize_t mv_bm_config(struct device *dev,
 	} else if (!strcmp(name, "qm_gpm_pools_quick_init")) {
 		u32 num_of_buffers, ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
 		struct mv_a40 qece_base_address, pl_base_address;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		num_of_buffers = qece_base_address.dma_msb = qece_base_address.virt_msb = pl_base_address.dma_msb = pl_base_address.virt_msb = 0;
 		ae_thr = af_thr = cache_vmid = cache_attr = cache_so_thr = cache_si_thr = cache_num_of_buffers = 0xFFFFFFFF;
+		/* Read input values */
 		sscanf(buf, "%d %d %d %d %d %d %d %d", &num_of_buffers, &ae_thr, &af_thr, &cache_vmid, &cache_attr, &cache_so_thr, &cache_si_thr, &cache_num_of_buffers);
 		if (num_of_buffers == 0) {
 			pr_err("wrong number of buffers. should be larger than 0\n");
@@ -391,11 +398,9 @@ static ssize_t mv_bm_config(struct device *dev,
 	} else if (!strcmp(name, "qm_dram_pools_quick_init")) {
 		u32 num_of_buffers, ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
 		struct mv_a40 qece_base_address, pl_base_address;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		num_of_buffers = qece_base_address.dma_msb = qece_base_address.virt_msb = pl_base_address.dma_msb = pl_base_address.virt_msb = 0;
 		ae_thr = af_thr = cache_vmid = cache_attr = cache_so_thr = cache_si_thr = cache_num_of_buffers = 0xFFFFFFFF;
+		/* Read input values */
 		sscanf(buf, "%d %d %d %d %d %d %d %d", &num_of_buffers, &ae_thr, &af_thr, &cache_vmid, &cache_attr, &cache_so_thr, &cache_si_thr, &cache_num_of_buffers);
 		if (num_of_buffers == 0) {
 			pr_err("wrong number of buffers. should be larger than 0\n");
@@ -408,10 +413,8 @@ static ssize_t mv_bm_config(struct device *dev,
 			PR_ERR_CODE(rc)
 	} else if (!strcmp(name, "pool_quick_init_status_get")) {
 		u32 pool, completed;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		pool = completed = 0xFFFFFFFF;
+		/* Read input values */
 		sscanf(buf, "%d", &pool);
 		rc = bm_pool_quick_init_status_get(pool, &completed);
 		if (rc != OK)
@@ -420,11 +423,9 @@ static ssize_t mv_bm_config(struct device *dev,
 	} else if (!strcmp(name, "gp_pool_def_basic_init")) {
 		u32 pool, num_of_buffers, partition_model, pool_pair;
 		struct mv_a40 base_address;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		num_of_buffers = base_address.dma_msb = base_address.virt_msb = 0;
 		pool = partition_model = pool_pair = 0xFFFFFFFF;
+		/* Read input values */
 		sscanf(buf, "%d %d %d %d", &pool, &num_of_buffers, &partition_model, &pool_pair);
 		if (num_of_buffers == 0) {
 			pr_err("wrong number of buffers. should be larger than 0\n");
@@ -437,11 +438,9 @@ static ssize_t mv_bm_config(struct device *dev,
 	} else if (!strcmp(name, "gp_pool_basic_init")) {
 		u32 pool, num_of_buffers, pe_size, pool_pair, ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
 		struct mv_a40 base_address;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		num_of_buffers = base_address.dma_msb = base_address.virt_msb = 0;
 		pool = pe_size = pool_pair = ae_thr = af_thr = cache_vmid = cache_attr = cache_so_thr = cache_si_thr = cache_num_of_buffers = 0xFFFFFFFF;
+		/* Read input values */
 		sscanf(buf, "%d %d %d %d %d %d %d %d %d %d %d", &pool, &num_of_buffers, &pe_size, &pool_pair, &ae_thr, &af_thr, &cache_vmid, &cache_attr, &cache_so_thr, &cache_si_thr, &cache_num_of_buffers);
 		if (num_of_buffers == 0) {
 			pr_err("wrong number of buffers. should be larger than 0\n");
@@ -452,31 +451,18 @@ static ssize_t mv_bm_config(struct device *dev,
 		if (rc != OK)
 			PR_ERR_CODE(rc)
 	} else if (!strcmp(name, "enable")) {
-		PR_INFO_CALLED
 		rc = bm_enable();
 		if (rc != OK)
 			PR_ERR_CODE(rc)
+/*
 	} else if (!strcmp(name, "disable")) {
 		PR_INFO_CALLED
 		rc = bm_disable();
 		if (rc != OK)
 			PR_ERR_CODE(rc)
-	} else if (!strcmp(name, "pool_fill_level_get")) {
-		u32 pool, fill_level;
-
-		/* Read input values */
-		PR_INFO_CALLED
-		pool = fill_level = 0xFFFFFFFF;
-		sscanf(buf, "%d", &pool);
-		rc = bm_pool_fill_level_get(pool, &fill_level);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
-		pr_info("\t fill_level = %d\n", fill_level);
+*/
 	} else if (!strcmp(name, "vmid_set")) {
 		u32 bm_vmid;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		bm_vmid = 0xFFFFFFFF;
 		sscanf(buf, "%d", &bm_vmid);
 		rc = bm_vmid_set(bm_vmid);
@@ -485,11 +471,9 @@ static ssize_t mv_bm_config(struct device *dev,
 	} else if (!strcmp(name, "gp_pool_def_quick_init")) {
 		u32 pool, num_of_buffers, fill_level, partition_model, pool_pair;
 		struct mv_a40 base_address;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		num_of_buffers = base_address.dma_msb = base_address.virt_msb = fill_level = 0;
 		pool = partition_model = pool_pair = 0xFFFFFFFF;
+		/* Read input values */
 		sscanf(buf, "%d %d %d %d %d", &pool, &num_of_buffers, &fill_level, &partition_model, &pool_pair);
 		if (num_of_buffers == 0) {
 			pr_err("wrong number of buffers. should be larger than 0\n");
@@ -502,11 +486,9 @@ static ssize_t mv_bm_config(struct device *dev,
 	} else if (!strcmp(name, "gp_pool_quick_init")) {
 		u32 pool, num_of_buffers, fill_level, pe_size, pool_pair, ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
 		struct mv_a40 base_address;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		num_of_buffers = base_address.dma_msb = base_address.virt_msb = fill_level = 0;
 		pool = pe_size = pool_pair = ae_thr = af_thr = cache_vmid = cache_attr = cache_so_thr = cache_si_thr = cache_num_of_buffers = 0xFFFFFFFF;
+		/* Read input values */
 		sscanf(buf, "%d %d %d %d %d %d %d %d %d %d %d %d", &pool, &num_of_buffers, &fill_level, &pe_size, &pool_pair, &ae_thr, &af_thr, &cache_vmid, &cache_attr, &cache_so_thr, &cache_si_thr, &cache_num_of_buffers);
 		if (num_of_buffers == 0) {
 			pr_err("wrong number of buffers. should be larger than 0\n");
@@ -516,146 +498,8 @@ static ssize_t mv_bm_config(struct device *dev,
 		rc = bm_gp_pool_quick_init(pool, num_of_buffers, fill_level, &base_address, pe_size, pool_pair, ae_thr, af_thr, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
 		if (rc != OK)
 			PR_ERR_CODE(rc)
-	} else if (!strcmp(name, "idle_status_get")) {
-		u32 status;
-
-		/* Read input values */
-		PR_INFO_CALLED
-		status = 0xFFFFFFFF;
-		rc = bm_idle_status_get(&status);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
-		pr_info("\t status = %d\n", status);
-	} else if (!strcmp(name, "pool_status_get")) {
-		u32 pool, pool_nempty, dpool_ae, dpool_af;
-
-		PR_INFO_CALLED
-		pool = pool_nempty = dpool_ae = dpool_af = 0xFFFFFFFF;
-		/* Read input values */
-		sscanf(buf, "%d", &pool);
-		rc = bm_pool_status_get(pool, &pool_nempty, &dpool_ae, &dpool_af);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
-		else
-			pr_info("pool %d nempty %d ae %d af %d\n", pool, pool_nempty, dpool_ae, dpool_af);
-	} else if (!strcmp(name, "pool_memory_fill")) {
-		u32 pool,  num_of_buffers;
-		struct mv_a40 base_address;
-
-		/* Read input values */
-		PR_INFO_CALLED
-		num_of_buffers = base_address.dma_msb = base_address.virt_msb = 0;
-		pool = 0xFFFFFFFF;
-		sscanf(buf, "%d %d", &pool, &num_of_buffers);
-		if (num_of_buffers == 0) {
-			pr_err("wrong number of buffers. should be larger than 0\n");
-			return -1;
-		}
-		base_address.virt_lsb = (u32)dma_alloc_coherent(NULL, num_of_buffers*4, &base_address.dma_lsb, GFP_KERNEL);
-		rc = bm_pool_memory_fill(pool, num_of_buffers, &base_address);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
-	} else if (!strcmp(name, "pool_dram_set"))	{
-		u32 pool,  num_of_buffers, pe_size, ae_thr, af_thr;
-		struct mv_a40 base_address;
-
-		/* Read input values */
-		PR_INFO_CALLED
-		num_of_buffers = base_address.dma_msb = base_address.virt_msb = 0;
-		pool = pe_size = ae_thr = af_thr = 0xFFFFFFFF;
-		sscanf(buf, "%d %d %d %d %d", &pool, &num_of_buffers, &pe_size, &ae_thr, &af_thr);
-		if (num_of_buffers == 0) {
-			pr_err("wrong number of buffers. should be larger than 0\n");
-			return -1;
-		}
-		base_address.virt_lsb = (u32)dma_alloc_coherent(NULL, num_of_buffers*4, &base_address.dma_lsb, GFP_KERNEL);
-		rc = bm_pool_dram_set(pool,  num_of_buffers, pe_size,  &base_address, ae_thr, af_thr);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
-	} else if (!strcmp(name, "pool_fill_level_set")) {
-		u32 pool,  num_of_buffers, pe_size,  quick_init;
-
-		/* Read input values */
-		PR_INFO_CALLED
-		pool = num_of_buffers = pe_size = quick_init = 0xFFFFFFFF;
-		sscanf(buf, "%d %d %d %d", &pool, &num_of_buffers, &pe_size, &quick_init);
-		rc = bm_pool_fill_level_set(pool, num_of_buffers, pe_size, quick_init);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
-	} else if (!strcmp(name, "pool_enable")) {
-		u32 pool, quick_init;
-
-		/* Read input values */
-		PR_INFO_CALLED
-		pool = quick_init = 0xFFFFFFFF;
-		sscanf(buf, "%d %d", &pool, &quick_init);
-		rc = bm_pool_enable(pool, quick_init);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
-	} else if (!strcmp(name, "gp_pool_pe_size_set")) {
-		u32 pool, pe_size;
-
-		/* Read input values */
-		PR_INFO_CALLED
-		pool = pe_size = 0xFFFFFFFF;
-		sscanf(buf, "%d %d", &pool, &pe_size);
-		rc = bm_gp_pool_pe_size_set(pool, pe_size);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
-	} else if (!strcmp(name, "gp_pool_pair_set")) {
-		u32 pool, pool_pair;
-
-		/* Read input values */
-		PR_INFO_CALLED
-		pool = pool_pair = 0xFFFFFFFF;
-		sscanf(buf, "%d %d", &pool, &pool_pair);
-		rc = bm_gp_pool_pair_set(pool, pool_pair);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
-	} else if (!strcmp(name, "pool_cache_set")) {
-		u32 pool, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
-
-		/* Read input values */
-		PR_INFO_CALLED
-		pool = cache_vmid = cache_attr = cache_so_thr = cache_si_thr = cache_num_of_buffers = 0xFFFFFFFF;
-		sscanf(buf, "%d %d %d %d %d %d", &pool, &cache_vmid, &cache_attr, &cache_so_thr, &cache_si_thr, &cache_num_of_buffers);
-		rc = bm_pool_cache_set(pool, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
-	} else if (!strcmp(name, "pool_disable")) {
-		u32 pool;
-
-		/* Read input values */
-		PR_INFO_CALLED
-		pool = 0xFFFFFFFF;
-		sscanf(buf, "%d", &pool);
-		rc = bm_pool_disable(pool);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
-/*not used*/
-	} else if (!strcmp(name, "register_read")) {
-		u32 base_address, offset, wordsNumber, dataPtr;
-
-		PR_INFO_CALLED
-		base_address = offset = wordsNumber = dataPtr = 0xFFFFFFFF;
-		/* Read input values */
-		sscanf(buf, "%x %x %x %x", &base_address, &offset, &wordsNumber, &dataPtr);
-		rc = bm_register_read(base_address, offset, wordsNumber, &dataPtr);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
-	} else if (!strcmp(name, "register_write")) {
-		u32 base_address, offset, wordsNumber, dataPtr;
-
-		PR_INFO_CALLED
-		base_address = offset = wordsNumber = dataPtr = 0xFFFFFFFF;
-		/* Read input values */
-		sscanf(buf, "%x %x %x %x", &base_address, &offset, &wordsNumber, &dataPtr);
-		rc = bm_register_write(base_address, offset, wordsNumber, &dataPtr);
-		if (rc != OK)
-			PR_ERR_CODE(rc)
 	} else {
 		err = 1;
-/*		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);*/
 		pr_err("%s: wrong name of BM function <%s>\n", __func__, attr->attr.name);
 	}
 
@@ -671,7 +515,6 @@ static DEVICE_ATTR(test,                         S_IWUSR, NULL,       mv_bm_conf
 static DEVICE_ATTR(attr_all_pools_def_set,       S_IWUSR, NULL,       mv_bm_config);
 static DEVICE_ATTR(attr_qm_pool_set,             S_IWUSR, NULL,       mv_bm_config);
 static DEVICE_ATTR(attr_gp_pool_set,             S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(enable_status_get,            S_IWUSR, NULL,       mv_bm_config);
 static DEVICE_ATTR(qm_gpm_pools_def_quick_init,  S_IWUSR, NULL,       mv_bm_config);
 static DEVICE_ATTR(qm_dram_pools_def_quick_init, S_IWUSR, NULL,       mv_bm_config);
 static DEVICE_ATTR(qm_gpm_pools_quick_init,      S_IWUSR, NULL,       mv_bm_config);
@@ -680,23 +523,10 @@ static DEVICE_ATTR(pool_quick_init_status_get,   S_IWUSR, NULL,       mv_bm_conf
 static DEVICE_ATTR(gp_pool_def_basic_init,       S_IWUSR, NULL,       mv_bm_config);
 static DEVICE_ATTR(gp_pool_basic_init,           S_IWUSR, NULL,       mv_bm_config);
 static DEVICE_ATTR(enable,                       S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(disable,                      S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(pool_fill_level_get,          S_IWUSR, NULL,       mv_bm_config);
 static DEVICE_ATTR(vmid_set,                     S_IWUSR, NULL,       mv_bm_config);
 static DEVICE_ATTR(gp_pool_def_quick_init,       S_IWUSR, NULL,       mv_bm_config);
 static DEVICE_ATTR(gp_pool_quick_init,           S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(idle_status_get,              S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(pool_status_get,              S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(pool_memory_fill,             S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(pool_dram_set,                S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(pool_fill_level_set,          S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(pool_enable,                  S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(gp_pool_pe_size_set,          S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(gp_pool_pair_set,             S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(pool_cache_set,               S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(pool_disable,                 S_IWUSR, NULL,       mv_bm_config);
-
-
+/*static DEVICE_ATTR(disable,                      S_IWUSR, NULL,       mv_bm_config);*/
 
 static struct attribute *mv_bm_attrs[] = {
 	&dev_attr_help.attr,
@@ -706,7 +536,6 @@ static struct attribute *mv_bm_attrs[] = {
 	&dev_attr_attr_all_pools_def_set.attr,
 	&dev_attr_attr_qm_pool_set.attr,
 	&dev_attr_attr_gp_pool_set.attr,
-	&dev_attr_enable_status_get.attr,
 	&dev_attr_qm_gpm_pools_def_quick_init.attr,
 	&dev_attr_qm_dram_pools_def_quick_init.attr,
 	&dev_attr_qm_gpm_pools_quick_init.attr,
@@ -715,21 +544,10 @@ static struct attribute *mv_bm_attrs[] = {
 	&dev_attr_gp_pool_def_basic_init.attr,
 	&dev_attr_gp_pool_basic_init.attr,
 	&dev_attr_enable.attr,
-	&dev_attr_disable.attr,
-	&dev_attr_pool_fill_level_get.attr,
 	&dev_attr_vmid_set.attr,
 	&dev_attr_gp_pool_def_quick_init.attr,
 	&dev_attr_gp_pool_quick_init.attr,
-	&dev_attr_idle_status_get.attr,
-	&dev_attr_pool_status_get.attr,
-	&dev_attr_pool_memory_fill.attr,
-	&dev_attr_pool_dram_set.attr,
-	&dev_attr_pool_fill_level_set.attr,
-	&dev_attr_pool_enable.attr,
-	&dev_attr_gp_pool_pe_size_set.attr,
-	&dev_attr_gp_pool_pair_set.attr,
-	&dev_attr_pool_cache_set.attr,
-	&dev_attr_pool_disable.attr,
+/*	&dev_attr_disable.attr, */
 
 	NULL
 };
@@ -743,17 +561,26 @@ static ssize_t mv_bm_debug_help(char *b)
 	int o = 0; /* buffer offset */
 	int s = PAGE_SIZE; /* buffer size */
 
-
-	o += scnprintf(b+o, s-o, "echo      > global_registers_dump        - Print global registers\n");
-	o += scnprintf(b+o, s-o, "echo  p   > pool_registers_dump          - Print all BM pool registers\n");
-	o += scnprintf(b+o, s-o, "echo  b   > bank_registers_dump          - Print all BM bank registers\n");
-	o += scnprintf(b+o, s-o, "echo  b   > cache_memory_dump            - Print 512 cache lines per in bank\n");
-	o += scnprintf(b+o, s-o, "echo      > idle_debug                   - Print busy indication registers\n");
-	o += scnprintf(b+o, s-o, "echo      > error_dump                   - Print busy reason registers\n");
-	o += scnprintf(b+o, s-o, "echo ba, ofs, wN > register_read   - Read register from BM units\n");
-	o += scnprintf(b+o, s-o, "echo ba, ofs, d  > register_write  - Write one word in BM units\n");
-
-
+	o += scnprintf(b+o, s-o, "\n");
+	o += scnprintf(b+o, s-o, "echo             > enable_status_get            - Get BM enable status\n");
+	o += scnprintf(b+o, s-o, "echo             > idle_status_get              - Read BM idle status\n");
+	o += scnprintf(b+o, s-o, "\n");
+	o += scnprintf(b+o, s-o, "echo p           > pool_fill_level_get          - Get pool fill level in DRAM\n");
+	o += scnprintf(b+o, s-o, "echo p           > pool_status_get              - not empty almost full/empty\n");
+	o += scnprintf(b+o, s-o, "echo p           > pool_enabled_get              - Is pool enabled\n");
+	o += scnprintf(b+o, s-o, "echo p           > pool_pointer_get              - Get pool Dram r/w pointers\n");
+	o += scnprintf(b+o, s-o, "echo p           > pool_cache_fill_get           - Get pool cache fill level\n");
+	o += scnprintf(b+o, s-o, "echo b           > bank_intr_pool_fill_get       - Get bank fill level\n");
+	o += scnprintf(b+o, s-o, "\n");
+	o += scnprintf(b+o, s-o, "echo             > global_registers_dump        - Print global registers\n");
+	o += scnprintf(b+o, s-o, "echo p           > pool_registers_dump          - Print all BM pool registers\n");
+	o += scnprintf(b+o, s-o, "echo b           > bank_registers_dump          - Print all BM bank registers\n");
+	o += scnprintf(b+o, s-o, "echo b           > cache_memory_dump            - Print 512 cache lines in bank\n");
+	o += scnprintf(b+o, s-o, "echo             > idle_debug                   - Print busy indication regs\n");
+	o += scnprintf(b+o, s-o, "echo             > error_dump                   - Print busy reason registers\n");
+	o += scnprintf(b+o, s-o, "echo ba, ofs, wN > register_read                - Read register from BM unit\n");
+	o += scnprintf(b+o, s-o, "echo ba, ofs, d  > register_write               - Write one word in BM unit\n");
+	o += scnprintf(b+o, s-o, "\n");
 	o += scnprintf(b+o, s-o, "parameters: [p]    pool\n");
 	o += scnprintf(b+o, s-o, "            [b]    bank\n");
 	o += scnprintf(b+o, s-o, "            [ba]   base address\n");
@@ -792,9 +619,7 @@ static ssize_t mv_bm_debug_config(struct device *dev,
 	const char      *name = attr->attr.name;
 	int rc = -BM_INPUT_NOT_IN_RANGE;
 	int             err = 0;
-/*
-	u32 flags;
-*/
+
 	unsigned long flags;
 
 	if (!capable(CAP_NET_ADMIN))
@@ -803,56 +628,124 @@ static ssize_t mv_bm_debug_config(struct device *dev,
 	local_irq_save(flags);
 
 	if (!strcmp(name, "global_registers_dump")) {
-		PR_INFO_CALLED
 		rc = bm_global_registers_dump();
 		if (rc != OK)
 			PR_ERR_CODE(rc)
 	} else if (!strcmp(name, "pool_registers_dump")) {
 		u32 pool;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		pool = 0xFFFFFFFF;
+		/* Read input values */
 		sscanf(buf, "%d", &pool);
 		rc = bm_pool_registers_dump(pool);
 		if (rc != OK)
 			PR_ERR_CODE(rc)
 	} else if (!strcmp(name, "bank_registers_dump")) {
 		u32 bank;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		bank = 0xFFFFFFFF;
+		/* Read input values */
 		sscanf(buf, "%d", &bank);
 		rc = bm_bank_registers_dump(bank);
 		if (rc != OK)
 			PR_ERR_CODE(rc)
 	} else if (!strcmp(name, "cache_memory_dump")) {
 		u32 bank;
-
-		/* Read input values */
-		PR_INFO_CALLED
 		bank = 0xFFFFFFFF;
+		/* Read input values */
 		sscanf(buf, "%d", &bank);
 		rc = bm_cache_memory_dump(bank);
 		if (rc != OK)
 			pr_err("%s: illegal operation in function <%s>, error code = 0x%08X\n", __func__, attr->attr.name, rc);
 	} else if (!strcmp(name, "idle_debug")) {
-		PR_INFO_CALLED
 		rc = bm_idle_debug();
 		if (rc != OK)
 			PR_ERR_CODE(rc)
 	} else if (!strcmp(name, "error_dump")) {
-		PR_INFO_CALLED
 		rc = bm_error_dump();
 		if (rc != OK)
 			PR_ERR_CODE(rc)
-/*not used*/
+	} else if (!strcmp(name, "enable_status_get"))	{
+		u32 bm_req_rcv_en;
+		bm_req_rcv_en = 0xFFFFFFFF;
+		rc = bm_enable_status_get(&bm_req_rcv_en);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+		pr_info("BM module is %s\n", ((bm_req_rcv_en == BM_UNIT_IS_ENABLED) ? "Enabled" : "Not enabled"));
+		pr_info("\t bm_req_rcv_en = %d\n", bm_req_rcv_en);
+	} else if (!strcmp(name, "pool_fill_level_get")) {
+		u32 pool, fill_level;
+		pool = fill_level = 0xFFFFFFFF;
+		/* Read input values */
+		sscanf(buf, "%d", &pool);
+		rc = bm_pool_fill_level_get(pool, &fill_level);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+		pr_info("\t pool %d fill_level in PE's = %d\n", pool, fill_level);
+	} else if (!strcmp(name, "idle_status_get")) {
+		u32 status;
+		status = 0xFFFFFFFF;
+		rc = bm_idle_status_get(&status);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+		pr_info("\t BM is %s: status = %d\n", ((status == BM_STATUS_IS_IDLE) ? "Idle" : "Busy"), status);
+	} else if (!strcmp(name, "pool_status_get")) {
+		u32 pool, pool_nempty, dpool_ae, dpool_af;
+		pool = pool_nempty = dpool_ae = dpool_af = 0xFFFFFFFF;
+		/* Read input values */
+		sscanf(buf, "%d", &pool);
+		rc = bm_pool_status_get(pool, &pool_nempty, &dpool_ae, &dpool_af);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+		else
+			pr_info("pool %d:  %s, %s, %s\n",
+			pool, ((pool_nempty == 1) ? "Not Empty" : "Empty"),
+			((dpool_ae == 1) ? "Almost Empty" : "Not almost Empty"),
+			((dpool_af == 1) ? "Almost Full" : "Not almost FUll"));
+	} else if (!strcmp(name, "pool_enabled_get")) {
+		u32 pool;
+		u32 enabled, quick_init;
+		/* Read input values */
+		sscanf(buf, "%d", &pool);
+		rc =  bm_pool_enabled_get(pool, &enabled, &quick_init);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+		else
+			pr_info("pool %d: %s, %s\n", pool,
+			((enabled == BM_POOL_IS_ENABLED) ? "Enabled" : "Not Enabled"),
+			((quick_init == BM_QUICK_INIT_IS_ON) ? "Quick Init Mode" : "Not Quick Init mode"));
+	} else if (!strcmp(name, "pool_pointer_get")) {
+		u32 pool;
+		u32 rd_ptr, wr_ptr;
+		/* Read input values */
+		sscanf(buf, "%d", &pool);
+		rc = bm_pool_pointer_get(pool, &rd_ptr, &wr_ptr);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+		else
+			pr_info("pool %d dram read pointer %d PE's. dram write pointer %d PE's\n", pool, rd_ptr, wr_ptr);
+	} else if (!strcmp(name, "bank_intr_pool_fill_get")) {
+		u32 bank, ne, ae, af;
+		/* Read input values */
+		sscanf(buf, "%d", &bank);
+		rc = bm_bank_intr_pool_fill_get(bank, &ne, &ae, &af);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+		else
+			pr_info("bank %d Interupts: not empty %x almost empty %x almost full %x\n", bank, ne, ae, af);
+	} else if (!strcmp(name, "pool_cache_fill_get")) {
+		u32 pool;
+		u32 rd_ptr, wr_ptr;
+		u32 fill_min, fill_max;
+		/* Read input values */
+		sscanf(buf, "%d", &pool);
+		rc =  bm_pool_cache_fill_get(pool, &rd_ptr, &wr_ptr, &fill_min, &fill_max);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+		else
+			pr_info("pool %d cache: read pointer %d PE's. write pointer %d PE's. fill min %d PE's, max %d PE's\n",
+			pool, rd_ptr, wr_ptr, fill_min, fill_max);
 	} else if (!strcmp(name, "register_read")) {
 		u32 base_address, offset, wordsNumber, dataPtr, i;
 		u32 sili_base = mv_hw_silicon_base_addr_get();
-
-		PR_INFO_CALLED
 		base_address = offset = wordsNumber = dataPtr = 0xFFFFFFFF;
 		/* Read input values */
 		sscanf(buf, "%x %x %x", &base_address, &offset, &wordsNumber);
@@ -865,8 +758,6 @@ static ssize_t mv_bm_debug_config(struct device *dev,
 	} else if (!strcmp(name, "register_write")) {
 		u32 base_address, offset, dataPtr;
 		u32 sili_base = mv_hw_silicon_base_addr_get();
-
-		PR_INFO_CALLED
 		base_address = offset = dataPtr = 0xFFFFFFFF;
 		/* Read input values */
 		sscanf(buf, "%x %x %x", &base_address, &offset, &dataPtr);
@@ -884,18 +775,33 @@ static ssize_t mv_bm_debug_config(struct device *dev,
 }
 
 static DEVICE_ATTR(help_debug,                   S_IRUSR, mv_bm_debug_show, NULL);
+static DEVICE_ATTR(idle_status_get,              S_IWUSR, NULL,       mv_bm_debug_config);
+static DEVICE_ATTR(pool_status_get,              S_IWUSR, NULL,       mv_bm_debug_config);
+static DEVICE_ATTR(pool_fill_level_get,          S_IWUSR, NULL,       mv_bm_debug_config);
+static DEVICE_ATTR(enable_status_get,            S_IWUSR, NULL,       mv_bm_debug_config);
+static DEVICE_ATTR(pool_enabled_get,        S_IWUSR, NULL,       mv_bm_debug_config);
+static DEVICE_ATTR(pool_pointer_get,        S_IWUSR, NULL,       mv_bm_debug_config);
+static DEVICE_ATTR(bank_intr_pool_fill_get,        S_IWUSR, NULL,       mv_bm_debug_config);
+static DEVICE_ATTR(pool_cache_fill_get,        S_IWUSR, NULL,       mv_bm_debug_config);
 static DEVICE_ATTR(global_registers_dump,        S_IWUSR, NULL,       mv_bm_debug_config);
-static DEVICE_ATTR(pool_registers_dump,          S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(bank_registers_dump,          S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(cache_memory_dump,            S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(idle_debug,                   S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(error_dump,                   S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(register_read,                S_IWUSR, NULL,       mv_bm_config);
-static DEVICE_ATTR(register_write,               S_IWUSR, NULL,       mv_bm_config);
-
+static DEVICE_ATTR(pool_registers_dump,          S_IWUSR, NULL,       mv_bm_debug_config);
+static DEVICE_ATTR(bank_registers_dump,          S_IWUSR, NULL,       mv_bm_debug_config);
+static DEVICE_ATTR(cache_memory_dump,            S_IWUSR, NULL,       mv_bm_debug_config);
+static DEVICE_ATTR(idle_debug,                   S_IWUSR, NULL,       mv_bm_debug_config);
+static DEVICE_ATTR(error_dump,                   S_IWUSR, NULL,       mv_bm_debug_config);
+static DEVICE_ATTR(register_read,                S_IWUSR, NULL,       mv_bm_debug_config);
+static DEVICE_ATTR(register_write,               S_IWUSR, NULL,       mv_bm_debug_config);
 
 static struct attribute *mv_bm_debug_attrs[] = {
 	&dev_attr_help_debug.attr,
+	&dev_attr_enable_status_get.attr,
+	&dev_attr_pool_fill_level_get.attr,
+	&dev_attr_idle_status_get.attr,
+	&dev_attr_pool_status_get.attr,
+	&dev_attr_pool_enabled_get.attr,
+	&dev_attr_pool_pointer_get.attr,
+	&dev_attr_bank_intr_pool_fill_get.attr,
+	&dev_attr_pool_cache_fill_get.attr,
 	&dev_attr_global_registers_dump.attr,
 	&dev_attr_pool_registers_dump.attr,
 	&dev_attr_bank_registers_dump.attr,
@@ -912,6 +818,189 @@ static struct attribute_group mv_bm_debug_group = {
 	.attrs = mv_bm_debug_attrs,
 };
 
+static ssize_t mv_bm_internals_help(char *b)
+{
+	int o = 0; /* buffer offset */
+	int s = PAGE_SIZE; /* buffer size */
+
+	o += scnprintf(b+o, s-o, "\n");
+	o += scnprintf(b+o, s-o, "echo p nb             > pool_memory_fill       - Fill pool memory with PE index\n");
+	o += scnprintf(b+o, s-o, "echo p qi             > pool_enable            - Enables BM pool\n");
+	o += scnprintf(b+o, s-o, "echo p                > pool_disable           - Set Pool to disable\n");
+	o += scnprintf(b+o, s-o, "echo p ps             > gp_pool_pe_size_set    - Set PE pointer size in GP pool\n");
+	o += scnprintf(b+o, s-o, "echo p pp             > gp_pool_pair_set       - Configure pool works in pairs\n");
+	o += scnprintf(b+o, s-o, "echo p nb ps qi       > pool_fill_level_set    - Conf pool Fill level in DRAM\n");
+	o += scnprintf(b+o, s-o, "echo p nb ps ae af    > pool_dram_set          - Conf pool Fill level in DRAM\n");
+	o += scnprintf(b+o, s-o, "echo p cv ca co ci cb > pool_cache_set         - Conf cache\n");
+	o += scnprintf(b+o, s-o, "\n");
+	o += scnprintf(b+o, s-o, "parameters: [p]    pool number\n");
+	o += scnprintf(b+o, s-o, "            [nb]   number of buffers\n");
+	o += scnprintf(b+o, s-o, "            [qi]   quick init mode: 1 is quick init, 0 is not quick init\n");
+	o += scnprintf(b+o, s-o, "            [ps]   PE size: 1 - 32bits, 0 - 40 bits\n");
+	o += scnprintf(b+o, s-o, "            [pp]   pool pair: 1 is alloc in pairs, 0 is alloc not in pairs\n");
+	o += scnprintf(b+o, s-o, "            [fl]   fill level\n");
+	o += scnprintf(b+o, s-o, "            [pm]   partition model: 1 is small partition in cache, 0 is big\n");
+	o += scnprintf(b+o, s-o, "            [ae]   almost empty threshold\n");
+	o += scnprintf(b+o, s-o, "            [af]   almost full threshold\n");
+	o += scnprintf(b+o, s-o, "            [cb]   cache number of buffers\n");
+	o += scnprintf(b+o, s-o, "            [cv ca]   cache vmid, cache attributes\n");
+	o += scnprintf(b+o, s-o, "            [co ci]   cache swap our threshold, cache swap in threshold\n");
+	o += scnprintf(b+o, s-o, "\n");
+
+	return o;
+}
+
+static ssize_t mv_bm_internals_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	const char      *name = attr->attr.name;
+	int             off = 0;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help")) {
+		off = mv_bm_internals_help(buf);
+	} else if (!strcmp(name, "help_internals")) {
+		off = mv_bm_internals_help(buf);
+	} else {
+		off = 1;
+		pr_err("%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	return off;
+}
+static ssize_t mv_bm_internals_config(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int rc = -BM_INPUT_NOT_IN_RANGE;
+	int             err = 0;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "pool_memory_fill")) {
+		u32 pool,  num_of_buffers;
+		struct mv_a40 base_address;
+		num_of_buffers = base_address.dma_msb = base_address.virt_msb = 0;
+		pool = 0xFFFFFFFF;
+		/* Read input values */
+		sscanf(buf, "%d %d", &pool, &num_of_buffers);
+		if (num_of_buffers == 0) {
+			pr_err("wrong number of buffers. should be larger than 0\n");
+			return -1;
+		}
+		base_address.virt_lsb = (u32)dma_alloc_coherent(NULL, num_of_buffers*4, &base_address.dma_lsb, GFP_KERNEL);
+		rc = bm_pool_memory_fill(pool, num_of_buffers, &base_address);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "pool_dram_set"))	{
+		u32 pool,  num_of_buffers, pe_size, ae_thr, af_thr;
+		struct mv_a40 base_address;
+		num_of_buffers = base_address.dma_msb = base_address.virt_msb = 0;
+		pool = pe_size = ae_thr = af_thr = 0xFFFFFFFF;
+		/* Read input values */
+		sscanf(buf, "%d %d %d %d %d", &pool, &num_of_buffers, &pe_size, &ae_thr, &af_thr);
+		if (num_of_buffers == 0) {
+			pr_err("wrong number of buffers. should be larger than 0\n");
+			return -1;
+		}
+		base_address.virt_lsb = (u32)dma_alloc_coherent(NULL, num_of_buffers*4, &base_address.dma_lsb, GFP_KERNEL);
+		rc = bm_pool_dram_set(pool,  num_of_buffers, pe_size,  &base_address, ae_thr, af_thr);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "pool_fill_level_set")) {
+		u32 pool,  num_of_buffers, pe_size,  quick_init;
+		pool = num_of_buffers = pe_size = quick_init = 0xFFFFFFFF;
+		/* Read input values */
+		sscanf(buf, "%d %d %d %d", &pool, &num_of_buffers, &pe_size, &quick_init);
+		rc = bm_pool_fill_level_set(pool, num_of_buffers, pe_size, quick_init);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "gp_pool_pe_size_set")) {
+		u32 pool, pe_size;
+		pool = pe_size = 0xFFFFFFFF;
+		/* Read input values */
+		sscanf(buf, "%d %d", &pool, &pe_size);
+		rc = bm_gp_pool_pe_size_set(pool, pe_size);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "gp_pool_pair_set")) {
+		u32 pool, pool_pair;
+		pool = pool_pair = 0xFFFFFFFF;
+		/* Read input values */
+		sscanf(buf, "%d %d", &pool, &pool_pair);
+		rc = bm_gp_pool_pair_set(pool, pool_pair);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "pool_cache_set")) {
+		u32 pool, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers;
+		pool = cache_vmid = cache_attr = cache_so_thr = cache_si_thr = cache_num_of_buffers = 0xFFFFFFFF;
+		/* Read input values */
+		sscanf(buf, "%d %d %d %d %d %d", &pool, &cache_vmid, &cache_attr, &cache_so_thr, &cache_si_thr, &cache_num_of_buffers);
+		rc = bm_pool_cache_set(pool, cache_vmid, cache_attr, cache_so_thr, cache_si_thr, cache_num_of_buffers);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "pool_enable")) {
+		u32 pool, quick_init;
+		pool = quick_init = 0xFFFFFFFF;
+		/* Read input values */
+		sscanf(buf, "%d %d", &pool, &quick_init);
+		rc = bm_pool_enable(pool, quick_init);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else if (!strcmp(name, "pool_disable")) {
+		u32 pool;
+		pool = 0xFFFFFFFF;
+		/* Read input values */
+		sscanf(buf, "%d", &pool);
+		rc = bm_pool_disable(pool);
+		if (rc != OK)
+			PR_ERR_CODE(rc)
+	} else {
+		err = 1;
+		pr_err("%s: wrong name of BM function <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+
+static DEVICE_ATTR(help_internals,             S_IRUSR, mv_bm_internals_show, NULL);
+static DEVICE_ATTR(pool_memory_fill,           S_IWUSR, NULL,       mv_bm_internals_config);
+static DEVICE_ATTR(pool_dram_set,              S_IWUSR, NULL,       mv_bm_internals_config);
+static DEVICE_ATTR(pool_fill_level_set,        S_IWUSR, NULL,       mv_bm_internals_config);
+static DEVICE_ATTR(pool_enable,                S_IWUSR, NULL,       mv_bm_internals_config);
+static DEVICE_ATTR(pool_disable,               S_IWUSR, NULL,       mv_bm_internals_config);
+static DEVICE_ATTR(gp_pool_pe_size_set,        S_IWUSR, NULL,       mv_bm_internals_config);
+static DEVICE_ATTR(gp_pool_pair_set,           S_IWUSR, NULL,       mv_bm_internals_config);
+static DEVICE_ATTR(pool_cache_set,             S_IWUSR, NULL,       mv_bm_internals_config);
+
+static struct attribute *mv_bm_internals_attrs[] = {
+	&dev_attr_help_internals.attr,
+	&dev_attr_pool_memory_fill.attr,
+	&dev_attr_pool_dram_set.attr,
+	&dev_attr_pool_fill_level_set.attr,
+	&dev_attr_gp_pool_pe_size_set.attr,
+	&dev_attr_gp_pool_pair_set.attr,
+	&dev_attr_pool_cache_set.attr,
+	&dev_attr_pool_enable.attr,
+	&dev_attr_pool_disable.attr,
+	NULL
+};
+
+static struct attribute_group mv_bm_internals_group = {
+	.name = "internals",
+	.attrs = mv_bm_internals_attrs,
+};
+
+
 int mv_pp3_bm_sysfs_init(struct kobject *neta_kobj)
 {
 	int err;
@@ -936,6 +1025,12 @@ int mv_pp3_bm_sysfs_init(struct kobject *neta_kobj)
 		return err;
 	}
 
+	err = sysfs_create_group(bm_kobj, &mv_bm_internals_group);
+	if (err) {
+		pr_err(KERN_INFO "sysfs group failed for bm internals%d\n", err);
+		return err;
+	}
+
 	return err;
 }
 
@@ -944,5 +1039,3 @@ int mv_pp3_bm_sysfs_exit(struct kobject *emac_kobj)
 	/*TODO*/
 	return 0;
 }
-
-
-- 
1.7.5.4

