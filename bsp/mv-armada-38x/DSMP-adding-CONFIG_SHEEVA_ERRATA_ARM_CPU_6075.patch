From 19c06de88dced83dbdd57bc30be20277c6d34f9c Mon Sep 17 00:00:00 2001
From: Tawfik Bayouk <tawfik@marvell.com>
Date: Tue, 21 Aug 2012 17:33:42 +0300
Subject: [PATCH 0067/1825] DSMP adding CONFIG_SHEEVA_ERRATA_ARM_CPU_6075

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit 34939d6cf33a2cb1448b4bc35958e634f57397ea

Change-Id: Idfd0679ef0b814fb8cc8523f92da138f7c330623
Signed-off-by: Tawfik Bayouk <tawfik@marvell.com>
Signed-off-by: Kosta Zertsekel <konszert@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 arch/arm/include/asm/assembler.h |    8 ++++++++
 arch/arm/include/asm/barrier.h   |    4 ++++
 arch/arm/mm/Kconfig              |   23 +++++++++++++++++++++++
 arch/arm/mm/cache-v7.S           |    8 ++++++++
 arch/arm/mm/proc-macros.S        |    4 ++++
 5 files changed, 47 insertions(+), 0 deletions(-)

diff --git a/arch/arm/include/asm/assembler.h b/arch/arm/include/asm/assembler.h
index 5c8b3bf4..486d2c8 100644
--- a/arch/arm/include/asm/assembler.h
+++ b/arch/arm/include/asm/assembler.h
@@ -211,9 +211,17 @@
 #ifdef CONFIG_SMP
 #if __LINUX_ARM_ARCH__ >= 7
 	.ifeqs "\mode","arm"
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_6075
+	ALT_SMP(dsb)
+#else
 	ALT_SMP(dmb)
+#endif
 	.else
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_6075
+	ALT_SMP(W(dsb))
+#else
 	ALT_SMP(W(dmb))
+#endif
 	.endif
 #elif __LINUX_ARM_ARCH__ == 6
 	ALT_SMP(mcr	p15, 0, r0, c7, c10, 5)	@ dmb
diff --git a/arch/arm/include/asm/barrier.h b/arch/arm/include/asm/barrier.h
index 0511238..cfab866 100644
--- a/arch/arm/include/asm/barrier.h
+++ b/arch/arm/include/asm/barrier.h
@@ -16,7 +16,11 @@
 #if __LINUX_ARM_ARCH__ >= 7
 #define isb() __asm__ __volatile__ ("isb" : : : "memory")
 #define dsb() __asm__ __volatile__ ("dsb" : : : "memory")
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_6075
+#define dmb() __asm__ __volatile__ ("dsb" : : : "memory")
+#else
 #define dmb() __asm__ __volatile__ ("dmb" : : : "memory")
+#endif
 #elif defined(CONFIG_CPU_XSC3) || __LINUX_ARM_ARCH__ == 6
 #define isb() __asm__ __volatile__ ("mcr p15, 0, %0, c7, c5, 4" \
 				    : : "r" (0) : "memory")
diff --git a/arch/arm/mm/Kconfig b/arch/arm/mm/Kconfig
index 266a476..25bfd95 100644
--- a/arch/arm/mm/Kconfig
+++ b/arch/arm/mm/Kconfig
@@ -1004,6 +1004,29 @@ config SHEEVA_ERRATA_ARM_CPU_6043
 		Alternatively, if a DMB or DSB instruction is issued after completing a group of clean operations (before executing any
 		stores to the cleaned lines), the issue also cannot occur.
 
+config SHEEVA_ERRATA_ARM_CPU_6075
+
+        bool "Sheeva Errata 6075: clean operations can cause victim data to be written out of order"
+        depends on  CPU_SHEEVA_PJ4B_V7 && ARMADA_XP_REV_A0
+        default y
+        help
+	When a DMB or DSB is used, the architecture requires that the barrier order explicit memory accesses from before the
+	barrier to ones after the barrier.  Because non-cacheable accesses are permitted to pend to the memory buffers, there
+	exists a rare scenario where the prescribed ordering is not honored.  Consider the following multiprocessor example:
+	Processor 0:
+	STR Data
+	DMB
+	STR Flag
+	Processor 1:
+	LDR Unrelated
+	LDR Flag
+	DMB
+	LDR Data ; Data & Unrelated in same non-cacheable chunk
+	In the above scenario, the LDR Data happens to pend and return the stale (prior to Flag update by Processor 0)
+	version of data.
+	Workaround
+	This issue can be avoided by replacing a DMB with a DSB SYS.
+
 config SHEEVA_ERRATA_ARM_CPU_PMU_RESET
 	bool "Sheeva Errata CPU Performance counters reset"
 	depends on CPU_SHEEVA_PJ4B_V6 || CPU_SHEEVA_PJ4B_V7
diff --git a/arch/arm/mm/cache-v7.S b/arch/arm/mm/cache-v7.S
index 24248be..cc74461 100644
--- a/arch/arm/mm/cache-v7.S
+++ b/arch/arm/mm/cache-v7.S
@@ -42,7 +42,11 @@ ENDPROC(v7_flush_icache_all)
  *	- mm    - mm_struct describing address space
  */
 ENTRY(v7_flush_dcache_all)
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_6075
+	dsb
+#else
 	dmb					@ ensure ordering with previous memory accesses
+#endif
 	mrc	p15, 1, r0, c0, c0, 1		@ read clidr
 	ands	r3, r0, #0x7000000		@ extract loc from clidr
 	mov	r3, r3, lsr #23			@ left align loc bit field
@@ -288,8 +292,12 @@ v7_dma_inv_range:
 	mcrne	p15, 0, r1, c7, c14, 1		@ clean & invalidate D / U line
 1:
 #if defined (CONFIG_SHEEVA_ERRATA_ARM_CPU_4413)
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_6075
+	dsb
+#else
 	dmb
 #endif
+#endif
 	mcr	p15, 0, r0, c7, c6, 1		@ invalidate D / U line
 	add	r0, r0, r2
 	cmp	r0, r1
diff --git a/arch/arm/mm/proc-macros.S b/arch/arm/mm/proc-macros.S
index 13a0ea4..c343997 100644
--- a/arch/arm/mm/proc-macros.S
+++ b/arch/arm/mm/proc-macros.S
@@ -207,7 +207,11 @@
         orr     r3, r2, #PSR_F_BIT | PSR_I_BIT
         msr     cpsr_c, r3                      @ Disable interrupts
 #if __LINUX_ARM_ARCH__ >= 7
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_6075
+	dsb
+#else
 	dmb					@ DMB for V7
+#endif
 #elif __LINUX_ARM_ARCH__ == 6
         mcr     p15, 0, r0, c7, c10, 5          @ DMB for V6
 #endif
-- 
1.7.5.4

