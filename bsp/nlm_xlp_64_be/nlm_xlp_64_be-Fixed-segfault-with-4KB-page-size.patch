From 8d772690d23f0df33a9ebd17b7bdc7ba1918e63d Mon Sep 17 00:00:00 2001
From: Yanjiang Jin <yanjiang.jin@windriver.com>
Date: Thu, 27 Dec 2012 10:31:28 +0800
Subject: [PATCH 2/9] nlm_xlp_64_be: Fixed segfault with 4KB page size

Using LSU debug registers on xlp8xx and xlp3xx for L1dcache flush.

This patch is for erratum E28_CPU: L1D Cache Incomplete Flush.

Signed-off-by: Jayanthi A <jayanthi.annadurai@broadcom.com>
Integrated-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 .../asm/mach-netlogic/cpu-feature-overrides.h      |    5 +-
 arch/mips/include/asm/mach-netlogic/xlp-mmu.h      |  142 +++++++++++-
 .../asm/netlogic/xlp8xx/cpu_control_macros.h       |   57 +++++
 arch/mips/include/asm/pgtable-32.h                 |    2 +-
 arch/mips/kernel/setup.c                           |    5 +
 arch/mips/mm/c-phoenix.c                           |  250 +++++++++++++++++++-
 arch/mips/netlogic/xlp/mmu.c                       |    2 -
 mm/memory.c                                        |   67 ++++++
 8 files changed, 510 insertions(+), 20 deletions(-)
 create mode 100644 arch/mips/include/asm/netlogic/xlp8xx/cpu_control_macros.h

diff --git a/arch/mips/include/asm/mach-netlogic/cpu-feature-overrides.h b/arch/mips/include/asm/mach-netlogic/cpu-feature-overrides.h
index 1562b3e..0ee47df 100644
--- a/arch/mips/include/asm/mach-netlogic/cpu-feature-overrides.h
+++ b/arch/mips/include/asm/mach-netlogic/cpu-feature-overrides.h
@@ -28,7 +28,6 @@
 #define cpu_has_cache_cdex_p    0
 #define cpu_has_cache_cdex_s    0
 #define cpu_has_counter 1
-#define cpu_has_dc_aliases      0
 #define cpu_has_divec   1
 #define cpu_has_dsp     0
 #define cpu_has_ejtag   1
@@ -57,4 +56,8 @@
 #define cpu_has_vtag_icache     0
 #define cpu_has_watch   1
 
+#ifdef CONFIG_NLM_XLP
+#define cpu_has_dc_aliases     (PAGE_SIZE < (cpu_data[0].dcache.sets * cpu_data[0].dcache.linesz))
+#endif
+
 #endif /* __ASM_MACH_NLM_CPU_FEATURE_OVERRIDES_H */
diff --git a/arch/mips/include/asm/mach-netlogic/xlp-mmu.h b/arch/mips/include/asm/mach-netlogic/xlp-mmu.h
index 5ec7054..85ac684 100644
--- a/arch/mips/include/asm/mach-netlogic/xlp-mmu.h
+++ b/arch/mips/include/asm/mach-netlogic/xlp-mmu.h
@@ -3,6 +3,8 @@
 
 #include <linux/percpu.h>
 #include <asm/mipsregs.h>
+#include <asm/netlogic/xlp8xx/cpu_control_macros.h>
+#include <asm/mach-netlogic/pgwalker.h>
 
 /* 
  * These numbers correspond to Cop0 Config6 reg 
@@ -25,6 +27,10 @@
 
 extern DEFINE_PER_CPU(unsigned long [NR_ADDR_SEGMENTS], pgd_bases);
 
+extern uint32_t nlm_l1_lock[NR_CPUS/4];
+
+extern int is_nlm_xlp2xx_compat;
+
 static inline void setup_user_pgd(pgd_t *pgd)
 {
 #ifdef CONFIG_PGWALKER
@@ -35,6 +41,108 @@ static inline void setup_user_pgd(pgd_t *pgd)
 #endif
 };
 
+
+static inline void nlm_lock_l1(uint32_t core)
+{
+        uint32_t temp;
+        __asm__ __volatile__(
+                "       .set    noreorder       \n"
+                "1:     ll      %1, %2          \n"
+                "       bgtz    %1, 2f          \n"
+                "       ori     %1, 1           \n"
+                "       sc      %1, %0          \n"
+#ifdef CONFIG_NLM_XLP
+                "       ehb                     \n"
+#endif
+                "       beqz    %1, 1b          \n"
+                "       nop                     \n"
+                "       .subsection 2           \n"
+                "2:     ll      %1, %2          \n"
+                "       bgtz    %1, 2b          \n"
+                "       nop                     \n"
+                "       b       1b              \n"
+                "        nop                    \n"
+                "       .previous               \n"
+                "       .set    reorder         \n"
+                : "=m" (nlm_l1_lock[core]), "=&r" (temp)
+                : "m" (nlm_l1_lock[core])
+                : "memory");
+}
+
+static inline void nlm_unlock_l1(uint32_t core)
+{
+        uint32_t temp;
+
+        __asm__ __volatile__(
+                "       .set    noreorder 	         \n"
+                "1:     ll      %1, %2          	 \n"
+                "       sub     %1, 1                    \n"
+                "       sc      %1, %0                   \n"
+#ifdef CONFIG_NLM_XLP
+                "       ehb                              \n"
+#endif
+                "       beqz    %1, 2f                   \n"
+                "        nop                             \n"
+                "       .subsection 2                    \n"
+                "2:     b       1b                       \n"
+                "        nop                             \n"
+                "       .previous                        \n"
+                "       .set    reorder                  \n"
+                : "=m" (nlm_l1_lock[core]), "=&r" (temp)
+                : "m" (nlm_l1_lock[core])
+                : "memory");
+
+}
+
+#define NLM_XLP_L1_MAXWAY       2
+#define NLM_XLP_L1_MAXINDX      128
+
+static inline void nlm_flush_l1_dcache_line(uint32_t line)
+{
+         __asm__ __volatile__ (
+                "       .set push                       \n"
+                "       .set noat                       \n"
+                "       .set noreorder                  \n"
+                "       li $8, "STR(LSU_DEBUG_DATA0)"   \n"
+                "       mtcr $0, $8                     \n"
+                "       li $9, "STR(LSU_DEBUG_ADDR)"    \n"
+                "       ori %0, %0, 0x1                 \n"
+                "       mtcr %0, $9                     \n"
+                "1:                                     \n"
+                "       mfcr $8, $9                     \n"
+                "       andi $8, $8, 0x1                \n"
+                "       bnez $8, 1b                     \n"
+                "       nop                             \n"
+                "       .set pop                        \n"
+                : : "r"(line) : "$8" , "$9");
+}
+
+static inline void nlm_flush_l1_dcache(void)
+{
+    uint32_t index, line, max;
+    uint32_t cpu = read_c0_ebase() & 0x7f;
+    uint32_t thread = cpu & 0x3;
+
+    nlm_lock_l1(cpu >> 2);
+    max = (thread + 1) * current_cpu_data.dcache.sets;
+    index = thread * current_cpu_data.dcache.sets;
+
+    for(; index < max; index++) {
+
+        line = (index << 5) | (1<<1);
+        nlm_flush_l1_dcache_line(line);
+        line = (1 << 2) | (index << 5) | (1<<1);
+        nlm_flush_l1_dcache_line(line);
+
+        line = (index << 5) | (1<<1) | (0x1 << 14);
+        nlm_flush_l1_dcache_line(line);
+        line = (1 << 2) | (index << 5) | (1<<1) | (0x1 << 14);
+        nlm_flush_l1_dcache_line(line);
+    }
+
+    nlm_unlock_l1(cpu >> 2);
+}
+
 static __inline__ void pipeline_flush(void)
 {
 	__asm__ __volatile__ (
@@ -51,16 +159,32 @@ static __inline__ void pipeline_flush(void)
 		);
 }
 
-#ifdef CONFIG_PGWALKER
+#ifdef CONFIG_32BIT
+#define disable_pgwalker(flags) (void)flags
+#define enable_pgwalker(flags) (void) flags
+#else
 #define disable_pgwalker(flags)						\
-	({ flags = read_c0_config6();					\
-		pipeline_flush(); write_c0_config6(read_c0_config6() & ~ENABLE_PGWALKER); pipeline_flush();})
+	({ if (!is_nlm_xlp2xx_compat) {				\
+	        flags = read_c0_config6();				\
+		pipeline_flush();					\
+		write_c0_config6(read_c0_config6() & ~ENABLE_PGWALKER);	\
+		pipeline_flush();					\
+	   } else { 							\
+	        flags = read_c0_pwctl();				\
+		pipeline_flush();					\
+		write_c0_pwctl(flags & ~(1 <<  PWCTL_PW_EN_O));		\
+		pipeline_flush();					\
+	   }								\
+	  })
 
-#define enable_pgwalker(flags)						\
-	({ write_c0_config6(read_c0_config6() | (flags & ENABLE_PGWALKER)); })
-#else
-#define disable_pgwalker(flags) do { } while (0)
-#define enable_pgwalker(flags)	do { } while (0)
-#endif
+#define enable_pgwalker(flags)								\
+	({ 										\
+	    if (!is_nlm_xlp2xx_compat) {						\
+		write_c0_config6(read_c0_config6() | (flags & ENABLE_PGWALKER));	\
+	    } else {									\
+		write_c0_pwctl(read_c0_pwctl() | (flags & (1 << PWCTL_PW_EN_O)));	\
+	    }										\
+	})
 
 #endif
+#endif
diff --git a/arch/mips/include/asm/netlogic/xlp8xx/cpu_control_macros.h b/arch/mips/include/asm/netlogic/xlp8xx/cpu_control_macros.h
new file mode 100644
index 0000000..0f73f69
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/xlp8xx/cpu_control_macros.h
@@ -0,0 +1,57 @@
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_2# */
+
+#ifndef __CPUCONTROL_MACROS_H__
+#define __CPUCONTROL_MACROS_H__
+#include <asm/netlogic/xlp8xx/cpu.h>
+#include <asm/netlogic/xlp8xx/xlp_sys.h>
+
+#define CP0_EBASE	$15
+#ifdef CONFIG_64BIT
+#define NMI_BASE    	0xffffffffbfc00000UL
+#else
+#define NMI_BASE        0xbfc00000UL	
+#endif
+#define NMI_BASE_ASM   	0xbfc00000
+
+#define LSU_DEFEATURE 0x304
+#define LSU_DEBUG_ADDR  0x305
+#define LSU_DEBUG_DATA0	0x306
+#define MMU_SETUP 0x400
+#define SCHED_DEFEATURE 0x700
+
+#ifndef __ASSEMBLY__
+#define	 XLP_THREADS_PER_CORE	4
+#define  XLP_CORES_PER_NODE	7
+void enable_cpus(unsigned int, unsigned int);
+u32 get_core_dfs(int);
+u32 change_cpu_freq(int, int);
+extern int xlp8xx_a01_workaround_needed;
+#endif	// __ASSEMBLY__
+#endif /* __CPUCONTROL_MACROS_H__ */
diff --git a/arch/mips/include/asm/pgtable-32.h b/arch/mips/include/asm/pgtable-32.h
index 208b158..6115405 100644
--- a/arch/mips/include/asm/pgtable-32.h
+++ b/arch/mips/include/asm/pgtable-32.h
@@ -133,7 +133,7 @@ pfn_pte(unsigned long pfn, pgprot_t prot)
 #define pfn_pte(pfn, prot)	__pte(((pfn) << (PAGE_SHIFT + 2)) | pgprot_val(prot))
 #else
 #ifdef CONFIG_NLM_XLP
-#define pte_pfn(x)     ((unsigned long)(((x).pte & ~((1ULL<<_PAGE_NO_READ_SHIFT)|(1ULL<<_PAGE_NO_EXEC_SHIFT))) >> _PFN_SHIFT))
+#define pte_pfn(x)     ((unsigned long)((x).pte >> PAGE_SHIFT))
 #else
 #define pte_pfn(x)     ((unsigned long)((x).pte >> _PFN_SHIFT))
 #endif
diff --git a/arch/mips/kernel/setup.c b/arch/mips/kernel/setup.c
index 1f75132..82141c2 100644
--- a/arch/mips/kernel/setup.c
+++ b/arch/mips/kernel/setup.c
@@ -74,6 +74,11 @@ static char __initdata builtin_cmdline[COMMAND_LINE_SIZE] = CONFIG_CMDLINE;
 const unsigned long mips_io_port_base __read_mostly = -1;
 EXPORT_SYMBOL(mips_io_port_base);
 
+/* A flag to indicate the chip is xlp2xx. A variable is used since later on
+ * it is used in macros.
+ */
+int is_nlm_xlp2xx_compat = 0;
+
 static struct resource code_resource = { .name = "Kernel code", };
 static struct resource data_resource = { .name = "Kernel data", };
 
diff --git a/arch/mips/mm/c-phoenix.c b/arch/mips/mm/c-phoenix.c
index 3700ef4..8120eba 100644
--- a/arch/mips/mm/c-phoenix.c
+++ b/arch/mips/mm/c-phoenix.c
@@ -165,11 +165,21 @@ static void nlm_common_local_flush_dcache(void)
 {
 	int i;
 	unsigned long base = CKSEG0;
+	unsigned int lines;
 
-	/* Index Invalidate all the lines and the ways */
-	for (i = 0; i < dcache_lines; i++) {
-		cacheop(Index_Writeback_Inv_D, base);
-		base += dcache_linesz;
+	if (is_nlm_xlp2xx_compat) {
+  		//dbg_msg("flushing the whole damn local D-cache\n");
+
+		lines = current_cpu_data.dcache.ways * current_cpu_data.dcache.sets;
+
+		 /* Index Invalidate all the lines and the ways */
+		for(i=0;i<lines;i++) {
+		  cacheop(Index_Writeback_Inv_D, base);
+		  base += current_cpu_data.dcache.linesz;
+  		}
+	}
+	else {
+		nlm_flush_l1_dcache();	
 	}
 
 	cacheop_hazard();
@@ -195,6 +205,81 @@ static void nlm_common_flush_l1_caches(void)
 	on_each_cpu(nlm_common_flush_l1_caches_ipi, (void *)NULL, 1);
 }
 
+#ifdef CONFIG_NLM_XLP
+
+struct flush_cache_page_args {
+	struct vm_area_struct *vma;
+	unsigned long addr;
+        unsigned long pfn;
+};
+
+static inline int has_valid_asid(const struct mm_struct *mm)
+{
+        return cpu_context(smp_processor_id(), mm);
+}
+
+static void local_nlm_flush_cache_mm(void * args)
+{
+       struct mm_struct *mm = args;
+
+       if (!has_valid_asid(mm))
+                return;
+
+	nlm_flush_l1_dcache();
+	nlm_common_local_flush_icache();
+	cacheop_hazard();
+
+}
+
+static void nlm_flush_cache_mm(struct mm_struct *mm)
+{
+       if (!cpu_has_dc_aliases)
+                return;
+
+       on_each_cpu(local_nlm_flush_cache_mm, mm, 1);
+}
+
+static inline void local_nlm_flush_cache_range(void * args)
+{
+        struct vm_area_struct *vma = args;
+
+        if (!(has_valid_asid(vma->vm_mm)))
+                return;
+
+        nlm_flush_l1_dcache();
+	nlm_common_local_flush_icache();
+        cacheop_hazard();
+}
+
+static void nlm_flush_cache_range(struct vm_area_struct *vma,
+        unsigned long start, unsigned long end)
+{
+       if (!cpu_has_dc_aliases)
+                return;
+
+       on_each_cpu(local_nlm_flush_cache_range, vma, 1);
+}
+
+static inline void local_nlm_flush_cache_page(void *args)
+{
+       nlm_flush_l1_dcache();
+	nlm_common_local_flush_icache();
+       cacheop_hazard();
+}
+
+static void nlm_flush_cache_page(struct vm_area_struct *vma,
+        unsigned long addr, unsigned long pfn)
+{
+        struct flush_cache_page_args args;
+
+        args.vma = vma;
+        args.addr = addr;
+        args.pfn = pfn;
+
+       on_each_cpu(local_nlm_flush_cache_page, &args, 1);
+}
+
+#endif
 static void nlm_common_noflush(void) { /* do nothing */ }
 
 static __init void probe_l1_cache(void)
@@ -299,9 +384,19 @@ void nlm_cache_init(void)
 	 * These get called when virtual->physical translation of a user address space is about
 	 * to be changed. These are closely related to TLB coherency (flush_tlb_{mm, range, page})
 	 */
-	flush_cache_mm = (void (*)(struct mm_struct *))nlm_common_noflush;
-	flush_cache_range = (void *) nlm_common_noflush;
-	flush_cache_page = (void *) nlm_common_flush_l1_caches;
+#ifdef CONFIG_NLM_XLP
+        if ((!is_nlm_xlp2xx_compat) && cpu_has_dc_aliases) {
+               flush_cache_mm = nlm_flush_cache_mm;
+               flush_cache_range = nlm_flush_cache_range;
+               flush_cache_page = nlm_flush_cache_page;
+        }
+	else 
+#endif
+	{
+		flush_cache_mm = (void (*)(struct mm_struct *))nlm_common_noflush;
+		flush_cache_range = (void *) nlm_common_noflush;
+		flush_cache_page = (void *) nlm_common_noflush;
+	}
 
 	/* flush_icache_page: flush_dcache_page + update_mmu_cache takes care of this
 	 *
@@ -331,3 +426,144 @@ void nlm_cache_init(void)
 
 	update_kseg0_coherency();
 }
+
+#ifdef CONFIG_64BIT
+#define cacheop_paddr(op, base) __asm__ __volatile__ ( \
+                         ".set push\n"           \
+                         ".set noreorder\n"      \
+                         ".set mips64\n"          \
+                         "dli $8, 0x9800000000000000\n"              \
+                         "daddu $8, $8, %1\n"       \
+                         "cache %0, 0($8)\n"     \
+                         ".set pop\n"            \
+                         : : "i"(op), "r"(base) : "$8")
+
+#else
+static inline void cacheop_paddr(const unsigned int op, phys_t base)
+{
+	uint64_t temp_msb, temp_lsb;
+	phys_t temp1;
+
+	temp_msb = (uint64_t)(base >> 32);
+	temp_lsb = (uint64_t)(base & 0xffffffff);
+
+	__asm__ volatile(
+		".set push\n"
+		".set noreorder\n"
+		".set mips64\n"
+		"dli $8,0x9800000000000000\n"
+		"dsll32 %0, %2,0\n"
+		"or %0,%0,%3\n"
+		"daddu $8, $8, %0\n"
+		"cache %1, 0($8)\n"
+		".set pop\n"
+		".set reorder\n"
+		: "=&r"(temp1)
+		: "i"(op), "r"(temp_msb) , "r"(temp_lsb)
+		:"$8"
+		);
+}
+#endif
+
+#define enable_KX(flags)   \
+ preempt_disable(); \
+ __asm__ __volatile__ (          \
+	".set push\n"              \
+	".set noat\n"               \
+	".set noreorder\n"     \
+	"mfc0 %0, $12\n\t"             \
+	"ori $1, %0, 0x81\n\t"   \
+	"xori $1, 1\n\t"      \
+	"mtc0 $1, $12\n"       \
+        ".set pop\n"          \
+        : "=r"(flags) ); \
+  preempt_enable();
+
+#define disable_KX(flags)   \
+ __asm__ __volatile__ (          \
+	".set push\n"              \
+	"mtc0 %0, $12\n"       \
+        ".set pop\n"          \
+        : : "r"(flags) )
+
+
+#define SETS_PER_WAY_SHIFT 22
+#define SETS_PER_WAY_MASK 0x7
+#define CACHELINE_SIZE_BITS 5
+
+static void nlm_common_local_flush_icache_range_paddr(phys_t start, phys_t end)
+{
+	phys_t addr;
+#ifdef CONFIG_32BIT
+	unsigned long flags;
+	phys_t temp;
+#endif
+#ifdef CONFIG_NLM_VMIPS
+	int tlbs = 0, tlbe = 0;
+	nlm_vmips_temp_xkphys_tlb_add(start, end, &tlbs, &tlbe);
+#endif
+
+#ifdef CONFIG_NLM_XLP
+	int sets_per_way, niter, i;
+	uint64_t mask;
+
+	sets_per_way = (read_c0_config1() >> SETS_PER_WAY_SHIFT) & SETS_PER_WAY_MASK;
+	niter = sets_per_way + 6 + CACHELINE_SIZE_BITS - PAGE_SHIFT;
+	if (niter < 0)
+		niter = 0;
+	niter = 1 << niter;
+	mask = niter - 1;
+#endif
+
+#ifdef CONFIG_32BIT
+	enable_KX(flags);
+#endif
+    for (addr = (start & ~(phys_t)(icache_linesz - 1)); addr < end;
+                    addr += icache_linesz) {
+		cacheop_paddr(Hit_Invalidate_I, addr);
+#ifdef CONFIG_NLM_XLP
+		for (i = 1; i < niter; ++i)
+			cacheop_paddr(Hit_Invalidate_I, (addr & ~(mask << PAGE_SHIFT)) | (i << PAGE_SHIFT));
+#endif
+    }
+
+#ifdef CONFIG_32BIT
+	disable_KX(flags);
+#endif
+
+#ifdef CONFIG_NLM_VMIPS
+	for(;tlbe >= tlbs; tlbe--)
+        nlm_vmips_wired_entry_remove(tlbe);
+
+#endif
+	cacheop_sync_istream();
+}
+
+static void nlm_common_flush_icache_range_paddr_ipi(void *info)
+{
+  struct flush_icache_range_args_paddr *args = info;
+
+  optimize_thread_flush();
+
+  nlm_common_local_flush_icache_range_paddr(args->start, args->end);
+}
+
+void nlm_common_flush_icache_range_paddr(phys_t start)
+{
+  struct flush_icache_range_args_paddr args;
+
+#ifdef CONFIG_NLMCOMMON_VM_DEBUG
+  dbg_msg("return address: ");
+  print_symbol("ra[0]=%s\n", (unsigned long) return_address());
+#endif
+
+  args.start = start;
+  args.end = start + PAGE_SIZE;
+  /* TODO: don't even send ipi to non-zero thread ids
+   * This may require some changes to smp_call_function interface, for now just avoid
+   * redundant cache ops
+   */
+  on_each_cpu(nlm_common_flush_icache_range_paddr_ipi, &args, 1);
+}
+
+
diff --git a/arch/mips/netlogic/xlp/mmu.c b/arch/mips/netlogic/xlp/mmu.c
index 0e69842..c8bcda2 100644
--- a/arch/mips/netlogic/xlp/mmu.c
+++ b/arch/mips/netlogic/xlp/mmu.c
@@ -53,8 +53,6 @@ static int __initdata tlb_config = (ENABLE_128_TLB);
 static int __initdata tlb_config = (ENABLE_ETLB | ENABLE_128_TLB);
 #endif
 
-int is_nlm_xlp2xx_compat = 0;
-
 int __init disable_etlb(char *str)
 {
 	tlb_config &= ~ENABLE_ETLB;
diff --git a/mm/memory.c b/mm/memory.c
index 9616738..decec12 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -3405,6 +3405,73 @@ int make_pages_present(unsigned long addr, unsigned long end)
 	return ret == len ? 0 : -EFAULT;
 }
 
+#if defined(CONFIG_NLMCOMMON_VM_DEBUG)
+
+static void print_pte_range(pte_t *pte, int pgd_index, int pmd_index)
+{
+	int i;
+	
+	for (i = 0; i < PTRS_PER_PTE; ++pte, ++i)
+	{
+		if (pte_none(*pte))
+			continue;
+		printk("\t\tpte[%d] = %llx, vpage = %lx\n", i, pte_val(*pte), 
+			  	((unsigned long)pgd_index << PGDIR_SHIFT)
+				| ((unsigned long)pmd_index << PAGE_SHIFT));
+	}
+}
+
+static void print_pmd_range(pmd_t *pmd, int pgd_index)
+{
+	int i;
+
+	for (i = 0; i < PTRS_PER_PMD; ++pmd, ++i)
+	{
+		if (pmd_none(*pmd))
+			continue;
+	 	print_pte_range((pte_t *) pmd_val(*pmd), pgd_index, i);
+	}
+}
+
+void dump_pgtable(pgd_t *pgd)
+{
+	int i = 0;
+
+	if (pgd == NULL) {
+		printk("NULL pgd ... bailing out\n");
+		return;
+	}
+
+	printk("dumping page table: pgd=%lx\n", (unsigned long)pgd);   
+	for (i = 0; i < PTRS_PER_PGD; ++pgd, ++i) 
+    {    
+		if (pgd_none(*pgd))
+			continue;	
+		print_pmd_range((pmd_t *) pgd_val(*pgd), i);
+	}
+}
+	
+void dump_mm_pgtable(struct mm_struct *mm)
+{
+	if (!mm) {
+    	printk("[%s]: mm == NULL (Kernel Thread?)\n", __FUNCTION__);
+    	return;
+	}
+
+	return dump_pgtable(mm->pgd);
+}
+
+void dump_current_pgtable(void)
+{
+  printk("[%s]: current = %lx, current->mm=%lx, current->active_mm=%lx\n", 
+	 __FUNCTION__,
+	 (unsigned long)current, (unsigned long)current->mm,
+	 (unsigned long)current->active_mm);
+  dump_mm_pgtable(current->mm);
+}
+
+#endif
+
 #if !defined(__HAVE_ARCH_GATE_AREA)
 
 #if defined(AT_SYSINFO_EHDR)
-- 
1.7.0

