From 4aabcb54a5975b541d93fa128940978332ed6fcc Mon Sep 17 00:00:00 2001
From: Yanjiang Jin <yanjiang.jin@windriver.com>
Date: Mon, 23 Apr 2012 12:18:35 +0800
Subject: [PATCH 23/46] nlm_xlp_64_be: cpu-hotplug: Prevent softirq wakeup on wrong CPU

The problem: The serial will hang after cpu_online operation.

The reason: When an interrupt happens before the cpu_active bit is
set by the cpu which brought up the newly onlined cpu, then the
scheduler refuses to enqueue the woken thread which is bound to
that newly onlined cpu on that newly onlined cpu due to the not
yet set cpu_active bit and selects a fallback runqueue.
The function start_secondary() uses the following code to
guarantee it:

while (!cpumask_test_cpu(cpu, cpu_active_mask))
cpu_relax();
/* enable local interrupts */
local_irq_enable();

We can refer the git commit fb197cf9861b9520ca43556c0ecea84e3792c873
to get more details.
In other words, we should enable local interrupts after the
cpu_active bit is set. But the function nlm_smp_finish() is
in front of cpumask_test_cpu(), and nlm_smp_finish() enabled
local IRQs in the end of it.

So use a group of safer functions spin_lock_irqsave() and
spin_unlock_irqrestore() to avoid this.

Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/netlogic/xlp/smp.c |    7 +++----
 1 files changed, 3 insertions(+), 4 deletions(-)

diff --git a/arch/mips/netlogic/xlp/smp.c b/arch/mips/netlogic/xlp/smp.c
index f9f967a..8521b31 100644
--- a/arch/mips/netlogic/xlp/smp.c
+++ b/arch/mips/netlogic/xlp/smp.c
@@ -185,17 +185,16 @@ void nlm_smp_finish(void)
 #ifdef CONFIG_HOTPLUG_CPU
 	int cpu = hard_smp_processor_id();
 	uint32_t bitmask = 0;
+	unsigned long flags;
 
 	if (atomic_read(&cpu_hotplug_flag)) {
-		spin_lock(&smp_reserve_lock);
-		local_irq_disable();
+		spin_lock_irqsave(&smp_reserve_lock, flags);
 		/* Enable IRQs on the cpu */
 		fixup_irqs(smp_processor_id(), 1);
-		local_irq_enable();
 		bitmask = cpumask_to_uint32(&cpu_online_map);
 		bitmask = bitmask | (1 << cpu);
 		set_ite(bitmask);
-		spin_unlock(&smp_reserve_lock);
+		spin_unlock_irqrestore(&smp_reserve_lock, flags);
 	}
 #endif
 }
-- 
1.7.0

