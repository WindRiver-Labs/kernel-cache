From 73e50edb78d8d2c8e7bffcf909e82e75ac1e60bd Mon Sep 17 00:00:00 2001
From: Wu Zhangjin <zhangjin.wu@windriver.com>
Date: Thu, 7 Apr 2011 14:18:46 +0800
Subject: [PATCH 23/37] nlm_xlp_64_be: add NAE driver support

[ Based on netlogic SDK 20110720 ]

Add support for the on-board NAE ethernet ports.

Signed-off-by: Venu Vadapalli <vvadapalli@netlogicmicro.com>
Signed-off-by: Siva Pochiraju <sivap@netlogicmicro.com>
Signed-off-by: Zi Shen Lim <zlim@netlogicmicro.com>
Signed-off-by: henry shao <hshao@netlogicmicro.com>
[ Call initialize_nae() with cpu_online_map instead of cpu_present_map
to make maxcpus or the coming cpu hotplug support work for the online
cpus is important to nlm_hal_write_poe_pcim_reg(), with wrong config,
the NAE driver doesn't work. Accordingly, a new function
cpu_hotplug_fixup_poe() is added for the coming cpu hotplug support. ]
Signed-off-by: Wu Zhangjin <zhangjin.wu@windriver.com>
---
 drivers/net/Kconfig          |   24 +
 drivers/net/Makefile         |    2 +
 drivers/net/nae/Makefile     |    9 +
 drivers/net/nae/init_nae.c   |   55 ++
 drivers/net/nae/net_common.h |  189 +++++++
 drivers/net/nae/xlp_hw.c     |  479 ++++++++++++++++++
 drivers/net/nae/xlp_nae.c    | 1127 ++++++++++++++++++++++++++++++++++++++++++
 drivers/net/nae/xlp_nae.h    |   94 ++++
 8 files changed, 1979 insertions(+), 0 deletions(-)
 create mode 100644 drivers/net/nae/Makefile
 create mode 100644 drivers/net/nae/init_nae.c
 create mode 100644 drivers/net/nae/net_common.h
 create mode 100644 drivers/net/nae/xlp_hw.c
 create mode 100644 drivers/net/nae/xlp_nae.c
 create mode 100644 drivers/net/nae/xlp_nae.h

diff --git a/drivers/net/Kconfig b/drivers/net/Kconfig
index 485878a..4e20b34 100644
--- a/drivers/net/Kconfig
+++ b/drivers/net/Kconfig
@@ -3365,4 +3365,28 @@ config VMXNET3
          To compile this driver as a module, choose M here: the
          module will be called vmxnet3.
 
+config VBUS_ENET
+	tristate "VBUS Ethernet Driver"
+	default n
+	select VBUS_PROXY
+	help
+	   A virtualized 802.x network device based on the VBUS
+	   "virtual-ethernet" interface.  It can be used with any
+	   hypervisor/kernel that supports the vbus+venet protocol.
+
+config VBUS_ENET_DEBUG
+        bool "Enable Debugging"
+	depends on VBUS_ENET
+	default n
+
+config XLP_NAE
+	tristate "netlogic microsystems xlp nae mac driver"
+	default n
+	select NLM_ENABLE_COP2
+	help
+	  This driver supports netlogic xls/xlr/xlp soc network driver.
+	  For more information on xls/xlr/xlp mac driver, please visit
+
+	  <http://support.netlogicmicro.com/support>
+
 endif # NETDEVICES
diff --git a/drivers/net/Makefile b/drivers/net/Makefile
index c466634..932662f 100644
--- a/drivers/net/Makefile
+++ b/drivers/net/Makefile
@@ -297,3 +297,5 @@ obj-$(CONFIG_WIMAX) += wimax/
 
 obj-$(CONFIG_OCTEON_MGMT_ETHERNET) += octeon/
 obj-$(CONFIG_PCH_GBE) += pch_gbe/
+
+obj-$(CONFIG_XLP_NAE) += nae/
diff --git a/drivers/net/nae/Makefile b/drivers/net/nae/Makefile
new file mode 100644
index 0000000..7860498
--- /dev/null
+++ b/drivers/net/nae/Makefile
@@ -0,0 +1,9 @@
+#
+# Makefile for xlp_nae network driver
+#
+
+EXTRA_CFLAGS := -DNLM_HAL_LINUX_KERNEL -Iarch/mips/include/asm/netlogic/hal
+EXTRA_CFLAGS += -Iarch/mips/netlogic/boot
+
+obj-y 		+= nae.o
+nae-objs 	:= xlp_nae.o init_nae.o xlp_hw.o
diff --git a/drivers/net/nae/init_nae.c b/drivers/net/nae/init_nae.c
new file mode 100644
index 0000000..5305336
--- /dev/null
+++ b/drivers/net/nae/init_nae.c
@@ -0,0 +1,55 @@
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/delay.h>
+
+#include <asm/netlogic/cpumask.h>
+
+#include <asm/netlogic/hal/nlm_hal_fmn.h>
+#include <asm/netlogic/hal/nlm_hal_nae.h>
+#include <asm/netlogic/hal/nlm_hal_xlp_dev.h>
+#include <ops.h>
+
+#include <asm/netlogic/interrupt.h>
+
+#include "net_common.h"
+
+extern int rely_on_firmware_config;
+
+static void config_fmn(void)
+{
+	unsigned long mflags = 0;
+	struct cpumask cpumask;
+
+	/* bind cpu to n0c0t0 and drain all leftover firmware messages */
+	sched_bindto_save_affinity(0, &cpumask);
+
+	/* Configure FMN again but only cpu credits */
+	msgrng_access_enable(mflags);
+
+	nlm_xlp_msgring_int_handler(IRQ_MSGRING, NULL);
+
+	/* Configure credits to non-n0c0 cores */
+	nlm_hal_fmn_init(0x10000000, 0x02000000, 50);
+
+	msgrng_access_disable(mflags);
+
+	sched_bindto_restore_affinity(&cpumask);
+}
+
+int initialize_nae(uint32_t cm0, uint32_t cm1, uint32_t cm2, uint32_t cm3)
+{
+	int dom_id = 0;
+	unsigned long mflags;
+
+	config_fmn();
+
+	msgrng_access_enable(mflags);
+	nlm_hal_init_nae(fdt, dom_id);
+
+	printk("Overriding HAL POE configuration based on current active cpumask\n");
+	nlm_hal_init_poe_distvec(0, cm0, cm1, cm2, cm3, (1 << nae_cfg.rx_vc));
+
+	msgrng_access_disable(mflags);
+	return 0;
+}
diff --git a/drivers/net/nae/net_common.h b/drivers/net/nae/net_common.h
new file mode 100644
index 0000000..cdd3bf4
--- /dev/null
+++ b/drivers/net/nae/net_common.h
@@ -0,0 +1,189 @@
+#ifndef NET_COMMON_H
+#define NET_COMMON_H
+
+#include <nlm_hal_nae.h>
+
+#define MAX_FMN_CODE		-1
+#define FMN_CREDIT_DEFAULT	8
+#define FMN_POE_CREDIT_DEFAULT	9
+#define MAX_FMN_ARRAY		50
+#define SUCCESS			0
+#define FAIL			-1
+#define CPU0_VC			0
+
+#define CPU_Q_ID(cpu, vid) (((cpu) << 2) | (vid))
+
+#define MAX_DEST_QID		50
+
+typedef struct fmn_credit_struct {
+	unsigned int   s_qid;
+	unsigned int   d_qid;
+	unsigned int   flag;
+	#define SET_UP_QUEUE         0x1
+	#define SET_UP_CREDITS       0x2
+	#define SET_UP_MULTI_DEST    0x4
+	#define SET_UP_MULTI_SRC     0x8
+	unsigned int   q_len;
+	unsigned int   credit;
+} fmn_credit_type;
+
+extern int init_gmac(unsigned int inf);
+extern int init_tx_if_credit(__u32 credit_val, unsigned int if_bmask);
+extern int init_ucore(uint32_t ucore_mask, int if_num);
+extern void init_ingress(void);
+extern void init_egress(void);
+extern int fmn_init(const fmn_credit_type *credit);
+extern void *xlp_init_buffer(size_t size,
+			size_t pbase,
+			uint64_t *vaddr_base);
+
+extern void *init_nae_free_pool(int num_queue,
+	unsigned char *pktmem,
+	int num_bytes,
+	int num_desc);
+extern void print_netreg(void);
+
+#ifdef DBG
+	#define log_dbg     printk
+	#define log_pkt     printk
+#else
+	#define log_dbg(...)
+	#define log_pkt(...)
+#endif
+#define log_err
+#define log_info	printk
+
+#ifdef DBG
+static inline void press_key_to_continue(void)
+{
+	log_dbg("press <enter> to continue...\n");
+}
+#else
+#define press_key_to_continue()
+#endif
+
+enum NAE_REG_CMD {
+	CMD_READ = 0,
+	CMD_WRITE
+};
+
+#define NAE_RX_ENABLE 0x1
+#define NAE_TX_ENABLE 0x1
+
+struct xlp_msg {
+	uint64_t entry[4];
+};
+
+static inline void msg_print(uint32_t size, uint32_t code, uint32_t dest, struct xlp_msg *msg)
+{
+	int i;
+	log_dbg("  size = %u\n"
+		"  code = %u (0x%x)\n"
+		"  dest = %u (0x%x)\n",
+		size, code, code, dest, dest);
+	for (i = 0; i < size && size <= 4; ++i) {
+		log_dbg("  msg.entry%d = 0x%016llx\n",
+			i, msg->entry[i]);
+	}
+}
+
+static inline void poe_print(uint64_t msg0)
+{
+	log_dbg("POE nextfid = %llu (0x%llx)\n"
+		"    nextdist = %llu (0x%llx)\n"
+		"    nextdest = %llu (0x%llx)\n"
+		"    msgaddr = 0x%llx\n"
+		"    fid = %llu (0x%llx)\n",
+		(msg0 >> 48) & 0xffff, (msg0 >> 48) & 0xffff,
+		(msg0 >> 44) & 0xf, (msg0 >> 44) & 0xf,
+		(msg0 >> 32) & 0xfff, (msg0 >> 32) & 0xfff,
+		(msg0 >> 16) & 0xffff,
+		(msg0) & 0xffff, (msg0) & 0xffff);
+}
+
+static inline void rx_print(uint64_t msg0)
+{
+	log_dbg("RX  context = %llu\n"
+		"    length = %llu (0x%llx)\n"
+		"    address = 0x%010llx\n"
+		"    unclass = %llu\n"
+		"    err = %llu\n"
+		"    IPcksm = %llu\n"
+		"    TCPcksm = %llu\n"
+		"    prepad = %llu\n"
+		"    p2p = %llu\n",
+		(msg0 >> 54) & 0x3ff,
+		(msg0 >> 40) & 0x3fff, (msg0 >> 40) & 0x3fff,
+		(msg0) & 0xffffffffc0ULL,
+		(msg0 >> 5) & 0x1,
+		(msg0 >> 4) & 0x1,
+		(msg0 >> 3) & 0x1,
+		(msg0 >> 2) & 0x1,
+		(msg0 >> 1) & 0x1,
+		(msg0) & 0x1);
+}
+
+static inline void buf_print(unsigned char *buf, unsigned long len)
+{
+	unsigned long i;
+	for (i = 0; i < len; ++i) {
+		log_dbg(" %02x", buf[i]);
+		if (i % 8 == 7)
+			log_dbg(" ");
+		if (i % 32 == 31)
+			log_dbg("\n");
+	}
+	log_dbg("\n");
+}
+
+#define CRC_LEN 4
+#define BYTE_OFFSET 2
+
+#define NULL_VFBID 127
+
+static inline uint64_t nae_tx_desc(unsigned int type,
+	unsigned int rdex, unsigned int fbid, unsigned int len, uint64_t addr)
+{
+	return ((uint64_t)(type & 0x3) << 62) |
+		((uint64_t)(rdex & 0x1) << 61) |
+		((uint64_t)(fbid & 0x7f) << 54) |
+		((uint64_t)(len & 0x3fff) << 40) |
+		(addr&0xffffffffffULL);
+}
+
+static inline void tx_print(uint64_t msg0)
+{
+	log_dbg("TX  type = %llu\n"
+		"    rdex = %llu\n"
+		"    vfbid = %llu\n"
+		"    length = %llu (0x%llx)\n"
+		"    address = 0x%010llx\n",
+		((msg0 >> 62) & 0x3),
+		((msg0 >> 61) & 0x1),
+		((msg0 >> 54) & 0x7f),
+		((msg0 >> 40) & 0x3fff), ((msg0 >> 40) & 0x3fff),
+		(msg0) & 0xffffffffffULL);
+}
+
+extern void *fdt;
+
+struct nae_port {
+	int  valid;
+	int  mgmt;
+	int  num_free_desc;
+	int  txq_range[2];
+	int  rxq;
+	int  hw_port_id;
+};
+
+struct nae_config {
+	int fb_vc;
+	int rx_vc;
+	int num_ports;
+	struct nae_port ports[18];
+};
+
+extern int initialize_nae(uint32_t cm0, uint32_t cm1, uint32_t cm2, uint32_t cm3);
+extern void nlm_xlp_msgring_int_handler(unsigned int irq, struct pt_regs *regs);
+
+#endif
diff --git a/drivers/net/nae/xlp_hw.c b/drivers/net/nae/xlp_hw.c
new file mode 100644
index 0000000..e3cea43
--- /dev/null
+++ b/drivers/net/nae/xlp_hw.c
@@ -0,0 +1,479 @@
+/*
+ * Copyright 2003-2010 Netlogic Microsystem, Inc. ("Netlogic"). All rights
+ * reserved.
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ *****************************#NLM_2#**********************************/
+
+#include <linux/types.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/mii.h>
+
+#include <asm/netlogic/xlp_mac.h>
+#include <asm/netlogic/hal/nlm_hal_nae.h>
+#include "xlp_nae.h"
+
+
+#define NLM_NUM_REG_DUMP 9 /* Register 0xa0 to 0xa8 */
+#define NLM_ETHTOOL_REG_LEN (NLM_NUM_REG_DUMP * 4)
+#define PHY_STATUS_RETRIES 25000
+
+#define DRV_NAME	"xlp_nae"
+#define DRV_VERSION	"0.1"
+
+static void nlm_xlp_mac_mii_write(struct dev_data *priv, int regidx, uint16_t regval);
+static unsigned int nlm_xlp_mac_mii_read(struct dev_data *priv, int regidx);
+void nlm_xlp_mac_set_enable(struct dev_data *priv, int flag);
+static int xlp_enable_autoneg(struct net_device *dev, u32 adv);
+static int xlp_set_link_speed(struct net_device *dev, int speed, int duplex);
+static u32 mac_debug;
+
+static int xlp_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	int mii_status;
+
+	if (priv->type != SGMII_IF) {
+		cmd->supported = SUPPORTED_FIBRE|SUPPORTED_10000baseT_Full;
+		cmd->advertising = SUPPORTED_FIBRE|SUPPORTED_10000baseT_Full;
+		cmd->speed = SPEED_10000;
+		cmd->port = PORT_FIBRE;
+		cmd->duplex = DUPLEX_FULL;
+		cmd->phy_address = priv->port;
+		cmd->autoneg = AUTONEG_DISABLE;
+		cmd->maxtxpkt = 0;
+		cmd->maxrxpkt = 0;
+	} else {
+		cmd->supported = SUPPORTED_10baseT_Full |
+			SUPPORTED_10baseT_Half |
+			SUPPORTED_100baseT_Full | SUPPORTED_100baseT_Half |
+			SUPPORTED_1000baseT_Full | SUPPORTED_MII |
+			SUPPORTED_Autoneg | SUPPORTED_TP;
+
+		cmd->advertising = priv->advertising;
+
+		mii_status = nlm_xlp_mac_mii_read(priv, MII_NCONFIG);
+		priv->speed = (mii_status >> 3) & 0x03;
+
+		cmd->speed = (priv->speed == xlp_mac_speed_1000) ? SPEED_1000 :
+			(priv->speed == xlp_mac_speed_100) ? SPEED_100 : SPEED_10;
+
+		cmd->duplex = (mii_status >> 5) & 0x1;
+		cmd->port = PORT_TP;
+		cmd->phy_address = priv->port;
+		cmd->transceiver = XCVR_INTERNAL;
+		cmd->autoneg = (~(mii_status >> 14)) & 0x1;
+		cmd->maxtxpkt = 0;
+		cmd->maxrxpkt = 0;
+	}
+
+	return 0;
+}
+static int xlp_enable_autoneg(struct net_device *dev, u32 adv)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	int mii_status;
+	u32 adv1, adv2;
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	nlm_xlp_mac_set_enable(priv, 0);
+	/* advertising for 10/100 Mbps */
+	adv1 = nlm_xlp_mac_mii_read(priv, MII_ADVERTISE);
+	adv1 &= ~(ADVERTISE_ALL | ADVERTISE_100BASE4);
+	/* advertising for 1000 Mbps */
+	adv2 = nlm_xlp_mac_mii_read(priv, 0x9);
+	adv2 &= ~(0x300);
+
+	if (adv & ADVERTISED_10baseT_Half)
+		adv1 |= ADVERTISE_10HALF;
+	if (adv & ADVERTISED_10baseT_Full)
+		adv1 |= ADVERTISE_10FULL;
+	if (adv & ADVERTISED_100baseT_Full)
+		adv1 |= ADVERTISE_100FULL;
+	if (adv & ADVERTISED_100baseT_Half)
+		adv1 |= ADVERTISE_100HALF;
+
+	if (adv & ADVERTISED_1000baseT_Full)
+		adv2 |= 0x200;
+	if (adv & ADVERTISED_1000baseT_Half)
+		adv2 |= 0x100;
+
+	/* Set the advertising parameters */
+	nlm_xlp_mac_mii_write(priv, MII_ADVERTISE, adv1);
+	nlm_xlp_mac_mii_write(priv, 0x9, adv2);
+
+	priv->advertising = adv1 | adv2;
+
+	mii_status = nlm_xlp_mac_mii_read(priv, MII_BMCR);
+	/* enable autoneg and force restart autoneg */
+	mii_status |= (BMCR_ANENABLE | BMCR_ANRESTART);
+	nlm_xlp_mac_mii_write(priv, MII_BMCR, mii_status);
+
+	nlm_xlp_mac_set_enable(priv, 1);
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return 0;
+}
+
+static int xlp_set_link_speed(struct net_device *dev, int speed, int duplex)
+{
+	u32 adv;
+
+	switch (speed) {
+	case SPEED_10:
+		if (duplex == DUPLEX_FULL)
+			adv = ADVERTISED_10baseT_Full;
+		else
+			adv = ADVERTISED_10baseT_Half;
+		break;
+	case SPEED_100:
+		if (duplex == DUPLEX_FULL)
+			adv = ADVERTISED_100baseT_Full;
+		else
+			adv = ADVERTISED_100baseT_Half;
+		break;
+	case SPEED_1000:
+		if (duplex == DUPLEX_FULL)
+			adv = ADVERTISED_1000baseT_Full;
+		else
+			adv = ADVERTISED_1000baseT_Half;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return xlp_enable_autoneg(dev, adv);
+}
+
+static int xlp_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	int ret;
+	struct dev_data *priv = netdev_priv(dev);
+
+	if (priv->type != SGMII_IF)
+		return -EIO;
+
+	if (cmd->autoneg == AUTONEG_ENABLE)
+		ret = xlp_enable_autoneg(dev, cmd->advertising);
+	else
+		ret = xlp_set_link_speed(dev, cmd->speed, cmd->duplex);
+	return ret;
+}
+
+static void xlp_get_drvinfo(struct net_device *dev,
+	struct ethtool_drvinfo *info)
+{
+	strcpy(info->driver, DRV_NAME);
+	strcpy(info->version, DRV_VERSION);
+}
+
+static int xlp_get_regs_len(struct net_device *dev)
+{
+	return NLM_ETHTOOL_REG_LEN;
+}
+static void xlp_get_regs(struct net_device *dev,
+	struct ethtool_regs *regs, void *p)
+{
+	u32 *data = (u32 *)p;
+	int i;
+	struct dev_data *priv = netdev_priv(dev);
+	unsigned long flags;
+
+	memset((void *)data, 0, NLM_ETHTOOL_REG_LEN);
+
+	spin_lock_irqsave(&priv->lock, flags);
+	for (i = 0; i <= NLM_NUM_REG_DUMP; i++)
+		*(data + i) = nlm_hal_read_mac_reg(priv->block, priv->index, R_TX_CONTROL + i);
+	spin_unlock_irqrestore(&priv->lock, flags);
+}
+static u32 xlp_get_msglevel(struct net_device *dev)
+{
+	return mac_debug;
+}
+static void xlp_set_msglevel(struct net_device *dev, u32 value)
+{
+	mac_debug = value;
+}
+
+static int xlp_nway_reset(struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	int mii_status;
+	unsigned long flags;
+	int ret = -EINVAL;
+
+	if (priv->type != SGMII_IF)
+		return -EIO;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	mii_status = nlm_xlp_mac_mii_read(priv, MII_BMCR);
+	if (mii_status & BMCR_ANENABLE) {
+		nlm_xlp_mac_mii_write(priv,
+				MII_BMCR, BMCR_ANRESTART | mii_status);
+		ret = 0;
+	}
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return ret;
+}
+
+static u32 xlp_get_link(struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	int mii_status;
+	unsigned long flags;
+	if (priv->type != SGMII_IF)
+		return -EIO;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	mii_status = nlm_xlp_mac_mii_read(priv, MII_BMSR);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return mii_status & BMSR_LSTATUS;
+}
+#define NLM_STATS_KEY_LEN	\
+	(sizeof(struct net_device_stats) / sizeof(unsigned long))
+static struct {
+	const char string[ETH_GSTRING_LEN];
+} xlp_ethtool_stats_keys[NLM_STATS_KEY_LEN] = {
+	{ "rx_packets" },
+	{ "tx_packets" },
+	{ "rx_bytes" },
+	{ "tx_bytes" },
+	{ "rx_errors" },
+	{ "tx_errors" },
+	{ "rx_dropped" },
+	{ "tx_dropped" },
+	{ "multicast" },
+	{ "collisions" },
+	{ "rx_length_errors" },
+	{ "rx_over_errors" },
+	{ "rx_crc_errors" },
+	{ "rx_frame_errors" },
+	{ "rx_fifo_errors" },
+	{ "rx_missed_errors" },
+	{ "tx_aborted_errors" },
+	{ "tx_carrier_errors" },
+	{ "tx_fifo_errors" },
+	{ "tx_heartbeat_errors" },
+	{ "tx_window_errors" },
+	{ "rx_compressed" },
+	{ "tx_compressed" }
+};
+
+static int xlp_get_sset_count (struct net_device *netdev,
+	int string_set)
+{
+	switch (string_set) {
+	case ETH_SS_STATS:
+		return NLM_STATS_KEY_LEN;
+	default:
+		return -EINVAL;
+	}
+}
+
+static void xlp_get_strings (struct net_device *dev, u32 stringset, u8 *buf)
+{
+	switch (stringset) {
+	case ETH_SS_STATS:
+		memcpy(buf, &xlp_ethtool_stats_keys,
+			sizeof(xlp_ethtool_stats_keys));
+		break;
+	default:
+		pr_warning("%s: Invalid stringset %d\n",
+			__func__, stringset);
+		break;
+	}
+}
+
+
+/*
+ * xlp_get_mac_stats -  collect stats info from Mac stats register
+ * @dev   -  this is per device based function
+ * @stats -  net device stats structure
+ */
+void xlp_get_mac_stats(struct net_device *dev, struct net_device_stats *stats)
+{
+	struct dev_data *priv = netdev_priv(dev);
+
+	if (priv->type != SGMII_IF)
+		return;
+
+	stats->tx_errors = nlm_hal_read_mac_reg(priv->block, priv->index, TX_FCS_ERROR_COUNTER);
+	stats->rx_dropped = nlm_hal_read_mac_reg(priv->block, priv->index, RX_DROP_PACKET_COUNTER);
+	stats->tx_dropped = nlm_hal_read_mac_reg(priv->block, priv->index, TX_DROP_FRAME_COUNTER);
+	stats->multicast = nlm_hal_read_mac_reg(priv->block, priv->index, RX_MULTICAST_PACKET_COUNTER);
+	stats->collisions = nlm_hal_read_mac_reg(priv->block, priv->index, TX_TOTAL_COLLISION_COUNTER);
+	stats->rx_length_errors = nlm_hal_read_mac_reg(priv->block, priv->index, RX_FRAME_LENGTH_ERROR_COUNTER);
+	stats->rx_over_errors = nlm_hal_read_mac_reg(priv->block, priv->index, RX_DROP_PACKET_COUNTER);
+	stats->rx_crc_errors = nlm_hal_read_mac_reg(priv->block, priv->index, RX_FCS_ERROR_COUNTER);
+	stats->rx_frame_errors = nlm_hal_read_mac_reg(priv->block, priv->index, RX_ALIGNMENT_ERROR_COUNTER);
+	stats->rx_fifo_errors = nlm_hal_read_mac_reg(priv->block, priv->index, RX_DROP_PACKET_COUNTER);
+	stats->rx_missed_errors = nlm_hal_read_mac_reg(priv->block, priv->index, RX_CARRIER_SENSE_ERROR_COUNTER);
+	stats->rx_errors = (stats->rx_over_errors + stats->rx_crc_errors + stats->rx_frame_errors + stats->rx_fifo_errors + stats->rx_missed_errors);
+	stats->tx_aborted_errors = nlm_hal_read_mac_reg(priv->block, priv->index, TX_EXCESSIVE_COLLISION_PACKET_COUNTER);
+	/*
+	stats->tx_carrier_errors = nlm_hal_read_mac_reg( priv->block, priv->index, TX_DROP_FRAME_COUNTER);
+	stats->tx_fifo_errors = nlm_hal_read_mac_reg( priv->block, priv->index, TX_DROP_FRAME_COUNTER);
+	*/
+	return;
+}
+
+/*
+ * xlp_get_ethtool_stats -  part of ethtool_ops member function
+ * @dev   -  this is per device based function
+ * @stats -  net device stats structure
+*/
+static void xlp_get_ethtool_stats (struct net_device *dev,
+	struct ethtool_stats *estats, u64 *stats)
+{
+	int i;
+	struct dev_data *priv = netdev_priv(dev);
+	unsigned long flags;
+	unsigned long *tmp_stats;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	xlp_get_mac_stats(dev, &priv->stats);
+
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	tmp_stats = (unsigned long *)&priv->stats;
+	for (i = 0; i < NLM_STATS_KEY_LEN; i++) {
+		*stats = (u64)*tmp_stats;
+		stats++;
+		tmp_stats++;
+	}
+}
+
+/*
+ *  nlm_xlp_mac_mii_read - Read mac mii phy register
+ *
+ *  Input parameters:
+ *  	   priv - priv structure
+ *  	   phyaddr - PHY's address
+ *  	   regidx = index of register to read
+ *
+ *  Return value:
+ *  	   value read (16 bits), or 0xffffffff if an error occurred.
+ */
+static unsigned int nlm_xlp_mac_mii_read(struct dev_data *priv, int regidx)
+{
+	return nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, priv->phy.addr, regidx);
+}
+
+/*
+ *  nlm_xlp_mac_mii_write -Write mac mii PHY register.
+ *
+ *  Input parameters:
+ *  	   priv - priv structure
+ *  	   regidx - register within the PHY
+ *  	   regval - data to write to register
+ *
+ *  Return value:
+ *  	   nothing
+ */
+static void nlm_xlp_mac_mii_write(struct dev_data *priv, int regidx, uint16_t regval)
+{
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, priv->phy.addr, regidx, regval);
+	return;
+}
+
+static struct ethtool_ops xlp_ethtool_ops = {
+	.get_settings = xlp_get_settings,
+	.set_settings = xlp_set_settings,
+	.get_drvinfo = xlp_get_drvinfo,
+	.get_regs_len = xlp_get_regs_len,
+	.get_regs = xlp_get_regs,
+	.get_msglevel = xlp_get_msglevel,
+	.set_msglevel = xlp_set_msglevel,
+	.nway_reset = xlp_nway_reset,
+	.get_link = xlp_get_link,
+	.get_strings = xlp_get_strings,
+	.get_sset_count = xlp_get_sset_count,
+	.get_ethtool_stats = xlp_get_ethtool_stats,
+};
+
+void xlp_set_ethtool_ops(struct net_device *netdev)
+{
+	SET_ETHTOOL_OPS(netdev, &xlp_ethtool_ops);
+}
+
+
+void nlm_xlp_mac_set_enable(struct dev_data *priv, int flag)
+{
+	int inf;
+	uint32_t speed = 0, duplex = 0, ifmode = 0;
+	uint32_t netwk_inf = 0, mac_cfg2 = 0;
+
+	if ((priv->type != SGMII_IF) && (priv->type != XAUI_IF))
+		return;
+	switch (priv->type) {
+	case SGMII_IF:
+		inf = (priv->block * 4) + priv->index;
+		break;
+	case XAUI_IF:
+	case INTERLAKEN_IF:
+		inf = priv->block;
+		break;
+	default:
+		return;
+	}
+
+	if (flag) {
+		if (priv->type == SGMII_IF) {
+			if (nlm_hal_get_phy_status(inf, &speed, &duplex)) {
+				/* nlm_print("mac set enable speed %d duplex %d\n",speed, duplex); */
+				ifmode = ((speed == 2) ? 2 : 1);
+				nlm_hal_mac_disable(inf, priv->type);
+				netwk_inf = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
+				netwk_inf &= (~(0x3));
+				write_gmac_reg(inf , NETWK_INF_CTRL_REG, netwk_inf | speed);
+				mac_cfg2 = read_gmac_reg(inf, MAC_CONF2);
+				mac_cfg2 &= (~((0x3 << 8) | 1));
+				write_gmac_reg(inf , MAC_CONF2,
+					      mac_cfg2 | (ifmode << 8) | duplex);
+			}
+		}
+		nlm_hal_mac_enable(inf, priv->type);
+	} else {
+		nlm_hal_mac_disable(inf, priv->type);
+	}
+}
+
+int nlm_xlp_link_up(struct dev_data *priv, int phy)
+{
+	uint16_t extstatus;
+
+	if (priv->type != SGMII_IF)
+		return -EIO;
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, priv->phy.addr, 22, 0);
+	extstatus = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, priv->phy.addr, 17);
+
+	return (extstatus & 0x0400) ? 1 : 0;
+}
diff --git a/drivers/net/nae/xlp_nae.c b/drivers/net/nae/xlp_nae.c
new file mode 100644
index 0000000..a52947d
--- /dev/null
+++ b/drivers/net/nae/xlp_nae.c
@@ -0,0 +1,1127 @@
+/*
+ * Copyright 2003-2010 Netlogic Microsystem, Inc. ("Netlogic"). All rights
+ * reserved.
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ ****************************#NLM_2#**********************************/
+
+#include <linux/types.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/fs.h>
+#include <linux/errno.h>
+#include <linux/proc_fs.h>
+#include <linux/fcntl.h>
+#include <linux/mman.h>
+#include <linux/mm.h>
+#include <linux/pci.h>
+
+#include <net/ip.h>
+
+#include <asm/current.h>
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/netlogic/cpumask.h>
+
+#include <asm/netlogic/hal/nlm_hal_fmn.h>
+#include <asm/netlogic/hal/nlm_hal_nae.h>
+#include <asm/netlogic/hal/nlm_hal_pic.h>
+
+#include <asm/netlogic/hal/nlm_hal_macros.h>
+
+#include <asm/netlogic/mips-exts.h>
+
+#include "net_common.h"
+#include "xlp_nae.h"
+
+#if 1
+#include <asm/atomic.h>
+
+#define STATS_SET(x, v)	atomic64_set((atomic64_t *)&(x), (v))
+#define STATS_ADD(x, v)	atomic64_add((long)(v), (atomic64_t *)&(x))
+#define STATS_INC(x)	atomic64_inc((atomic64_t *)&(x))
+#define STATS_READ(x)	atomic64_read((atomic64_t *)&(x))
+#else
+#define STATS_SET(x, v)	do { (x) = (v); } while (0)
+#define STATS_ADD(x, v)	do { (x) += (v); } while (0)
+#define STATS_INC(x)	do { (x) += 1; } while (0)
+#define STATS_READ(x)	(x)
+#endif
+
+#define XLP_SOC_MAC_DRIVER "XLP Mac Driver"
+
+/* On-Chip NAE PCI Header */
+#define PCI_NETL_VENDOR			0xfecc
+#define PCI_DEVID_BASE			0
+#define PCI_DEVID_OFF_NET		0
+
+#define MAX_NET_INF			1
+#define MAX_GMAC_PORT			18
+#define XLP_SGMII_RCV_CONTEXT_NUM	8
+
+/* FMN send failure errors */
+#define MSG_DST_FC_FAIL			0x01
+#define MSG_INFLIGHT_MSG_EX		0x02
+#define MSG_TXQ_FULL			0x04
+
+#define ETH_MTU_SIZE			1536
+#define MIN_ETH_FRAME_SIZE		64
+
+#define DUMP_PKT(str, x, y) if (debug == 2) { \
+	int i;					\
+	pr_info(" %s \n", str);                 \
+	for (i = 0; i < y; i++)	{		\
+		pr_info("%02x ", (x)[i]);	\
+		if (i % 16 == 15)		\
+			pr_info("\n");		\
+	}					\
+	pr_info("\n"); }
+
+/* Module Parameters */
+static int debug;
+module_param(debug, int, 0);
+
+static int drop_uboot_pkt = 1;
+module_param(drop_uboot_pkt, int, 0);
+static unsigned long stats_uboot_pkts;
+
+extern int naecfg_hack;
+module_param(naecfg_hack, int, 0);
+
+/*
+ *
+ * Below parameters are set during FDT file parsing
+ */
+int frin_desc_thres = 24;
+module_param(frin_desc_thres, int, 0);
+
+static uint32_t nae_rx_vc;
+static uint32_t nae_fb_vc;
+
+unsigned char eth_hw_addr[18][6] = {
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x05},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x06},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x07},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x08},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x09},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x0A},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x0B},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x0C},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x0D},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x0E},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x0F},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x10},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x11},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x12},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x13},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x14},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x15},
+	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x16}
+};
+
+#define ETHER_FRAME_MIN_LEN	64
+static struct pci_device_id soc_pci_table[] __devinitdata = {
+	{ PCI_NETL_VENDOR, PCI_DEVID_BASE + PCI_DEVID_OFF_NET,
+	PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0},
+	{ 0, }
+};
+
+extern void xlp_set_ethtool_ops(struct net_device *netdev);
+extern void xlp_get_mac_stats(struct net_device *dev, struct net_device_stats *stats);
+spinlock_t  nlm_xlp_nae_lock;
+static void nlm_xlp_nae_init(void);
+static int xlp_mac_proc_read(char *page, char * *start, off_t off, int count, int *eof, void *data);
+static int  nlm_xlp_nae_open (struct net_device *dev);
+static int  nlm_xlp_nae_stop (struct net_device *dev);
+static int  nlm_xlp_nae_start_xmit (struct sk_buff *skb, struct net_device *dev);
+static void  nlm_xlp_set_multicast_list (struct net_device *dev);
+static int  nlm_xlp_nae_ioctl (struct net_device *dev, struct ifreq *rq, int cmd);
+static int  nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu);
+static void  nlm_xlp_nae_tx_timeout (struct net_device *dev);
+static void xlp_mac_setup_hwaddr(struct dev_data *priv);
+
+#ifdef	ENABLE_NAE_PIC_INT
+static irqreturn_t nlm_xlp_nae_int_handler(int irq, void *dev_id);
+#endif
+
+static void nlm_xlp_nae_msgring_handler(uint32_t vc, uint32_t src_id,
+					uint32_t size, uint32_t code,
+					uint64_t msg0, uint64_t msg1,
+					uint64_t msg2, uint64_t msg3, void *data);
+
+static void nlm_xlp_mac_timer(unsigned long data);
+static struct net_device_stats *nlm_xlp_mac_get_stats(struct net_device *dev);
+
+static struct net_device *dev_mac[MAX_GMAC_PORT];
+
+extern struct proc_dir_entry *nlm_root_proc;
+static struct tasklet_struct mac_refill_task[MAX_GMAC_PORT];
+static int mac_refill_frin_desc(unsigned long dev);
+
+extern void nlm_xlp_mac_set_enable(struct dev_data *priv, int flag);
+
+static const struct net_device_ops nlm_xlp_nae_ops = {
+	.ndo_open = nlm_xlp_nae_open,
+	.ndo_stop = nlm_xlp_nae_stop,
+	.ndo_start_xmit = nlm_xlp_nae_start_xmit,
+	.ndo_set_multicast_list = nlm_xlp_set_multicast_list,
+	.ndo_do_ioctl = nlm_xlp_nae_ioctl,
+	.ndo_tx_timeout = nlm_xlp_nae_tx_timeout,
+	.ndo_change_mtu = nlm_xlp_nae_change_mtu,
+	.ndo_set_mac_address = eth_mac_addr,
+	.ndo_get_stats = nlm_xlp_mac_get_stats,
+};
+
+static inline void cpu_halt(void)
+{
+	__asm__ volatile (".set push\n"
+			".set noreorder\n"
+			"   wait\n"
+			"1: b    1b\n"
+			"   nop\n"
+			".set pop\n"
+		);
+}
+
+static inline void print_fmn_send_error(const char *str, uint32_t send_result)
+{
+	if (send_result & MSG_DST_FC_FAIL)
+		pr_info("[%s] Msg Destination flow control credit fail(send_result = %08x)\n",
+			str, send_result);
+	else if (send_result & MSG_INFLIGHT_MSG_EX)
+		pr_info("[%s] MSG_INFLIGHT_MSG_EX(send_result = %08x)\n", __func__, send_result);
+	else if (send_result & MSG_TXQ_FULL)
+		pr_info("[%s] TX message Q full(send_result = %08x)\n", __func__, send_result);
+	else
+		pr_info("[%s] Unknown send error type(send_result = %08x)\n", __func__, send_result);
+}
+
+static inline struct sk_buff *mac_get_skb_back_ptr(uint64_t addr)
+{
+	uint64_t *back_ptr = (uint64_t *)(addr - CACHELINE_SIZE);
+	/* this function should be used only for newly allocated packets. It assumes
+	 * the first cacheline is for the back pointer related book keeping info
+	 */
+	return (struct sk_buff *)(*back_ptr);
+}
+
+static inline void mac_put_skb_back_ptr(struct sk_buff *skb)
+{
+	uint64_t *back_ptr = (uint64_t *)skb->data;
+
+	/* this function should be used only for newly allocated packets. It assumes
+	 * the first cacheline is for the back pointer related book keeping info
+	 */
+	skb_reserve(skb, CACHELINE_SIZE);
+	*back_ptr = (uint64_t)skb;
+}
+
+#define CACHELINE_ALIGNED_ADDR(addr) (((unsigned long)(addr)) & ~(CACHELINE_SIZE-1))
+
+/*
+ * cacheline_aligned_kmalloc - 64 bits cache aligned kmalloc
+ * return - buffer address
+ */
+static inline void *cacheline_aligned_kmalloc(int size, int gfp_mask)
+{
+	void *buf = kmalloc(size + CACHELINE_SIZE, gfp_mask);
+	if (buf)
+	buf = (void *)(CACHELINE_ALIGNED_ADDR((unsigned long)buf +
+							CACHELINE_SIZE));
+	return buf;
+}
+
+/*
+ * nlm_xlp_alloc_skb - 64 bits cache aligned skb buffer allocate
+ * return - skb buffer address
+ */
+static inline struct sk_buff *nlm_xlp_alloc_skb(void)
+{
+	int offset = 0;
+	struct sk_buff *skb = __dev_alloc_skb(NLM_RX_BUF_SIZE, GFP_KERNEL);
+
+	if (!skb)
+		return NULL;
+	/* align the data to the next cache line */
+	offset = ((unsigned long)skb->data + CACHELINE_SIZE) &
+			~(CACHELINE_SIZE - 1);
+	skb_reserve(skb, (offset - (unsigned long)skb->data));
+
+	return skb;
+}
+
+
+/*
+ * nlm_xlp_free_skb - change msg into skb buffer address, free it
+ * @msg - freeback msg that sent to cpu vc
+ */
+static inline void nlm_xlp_free_skb(struct xlp_msg *msg)
+{
+	struct sk_buff *skb;
+	struct dev_data *priv;
+	int cpu = hard_smp_processor_id();
+	unsigned long tmp;
+
+	tmp = (unsigned long)(msg->entry[0] & 0xffffffffffULL);
+	skb = (struct sk_buff *)bus_to_virt(tmp);
+
+	if (!skb)
+		return;
+	/* Tx Complete */
+
+	/* release the skb and update statistics outside the spinlock */
+	priv = netdev_priv(skb->dev);
+	STATS_INC(priv->stats.tx_packets);
+	STATS_ADD(priv->stats.tx_bytes, skb->len);
+	priv->cpu_stats[cpu].txc_packets++;
+
+
+	netif_tx_wake_all_queues(skb->dev);
+	/* nlm_netif_queue_tx_complete(skb->dev); */
+
+	dev_kfree_skb_any(skb);
+}
+
+/*
+ * mac_refill_frin_desc - refill rx freein buffer for a device
+ * @dev - this is per device based function
+ */
+static int mac_refill_frin_desc(unsigned long dev)
+{
+	struct dev_data *priv;
+	struct net_device *ndev;
+	int ret, mflags, i, code, limit;
+	struct xlp_msg msg;
+	struct sk_buff *skb;
+	uint64_t *idx_ptr;
+
+	ndev = (struct net_device *) dev;
+	priv = netdev_priv(ndev);
+	ret = 0;
+
+	atomic64_inc(&priv->num_replenishes);
+
+	limit = atomic64_read(&priv->frin_to_be_sent);
+
+	for (i = 0; i < limit; i++) {
+		skb = nlm_xlp_alloc_skb();
+		if (!skb) {
+			pr_info("[%s] alloc skb failed\n", __func__);
+
+			ret = -ENOMEM;
+			break;
+		}
+
+		skb->dev = ndev;
+
+		/* Send the free Rx desc to the MAC */
+		mac_put_skb_back_ptr(skb);
+		code = 0;
+		idx_ptr = (uint64_t *)((unsigned long)skb->data-20);
+		*idx_ptr = i;
+
+		msgrng_access_enable(mflags);
+		msg.entry[0] = (unsigned long long)virt_to_bus(skb->data) & 0xffffffffffULL;
+		msg.entry[1] = msg.entry[2] = msg.entry[3] = 0;
+		/* Send the packet to nae rx */
+		__sync();
+
+		ret = nlm_hal_send_msg1(priv->nae_rx_qid, code, msg.entry[0]);
+		if (ret) {
+			print_fmn_send_error(__func__, ret);
+			pr_info("Unable to send configured free desc, check freein carving (qid = %d)\n", priv->nae_rx_qid);
+
+			/* free the buffer and return! */
+			dev_kfree_skb_any(skb);
+
+			msgrng_access_disable(mflags);
+
+			/* ignore "send message destination flow control credit fail" error,
+			 * because mac_refill_frin_desc can be executed at the same time.
+			 */
+			if (ret == 0x1)
+				ret = 0;
+			else
+				ret = -EBUSY;
+
+			break;
+		}
+		msgrng_access_disable(mflags);
+
+		atomic64_dec(&priv->frin_to_be_sent);
+
+		atomic64_inc(&priv->total_frin_sent);
+	}
+
+	return ret;
+}
+
+/*
+ * nlm_xlp_nae_init - xlp_nae device driver init function
+ * @dev - this is per device based function
+ */
+
+static void nlm_xlp_nae_init(void)
+{
+	struct net_device *dev = NULL;
+	struct dev_data *priv = NULL;
+	int i;
+	struct proc_dir_entry *entry;
+
+	pr_info("======= Module Parameters =========\n");
+	pr_info("debug = %d, frin_desc_thres = %d naecfg_hack = %d drop_uboot_pkt = %d\n",
+	debug, frin_desc_thres, naecfg_hack, drop_uboot_pkt);
+
+	if (initialize_nae(cpumask_to_uint32(&cpu_online_map), 0, 0, 0))
+		return;
+
+	nae_fb_vc = nae_cfg.fb_vc;
+	nae_rx_vc = nae_cfg.rx_vc;
+
+	for (i = 0; i < nae_cfg.num_ports; i++) {
+		/* Register only valid ports which are management */
+		if (!nae_cfg.ports[i].valid)
+			continue;
+
+		dev = alloc_etherdev(sizeof(struct dev_data));
+		if (!dev) {
+			pr_err("%s: Failed to alloc dev, port = %d\n", __func__, i);
+			return;
+		}
+
+		ether_setup(dev);
+
+		priv = netdev_priv(dev);
+		spin_lock_init(&priv->lock);
+		priv->dev = dev;
+		dev->netdev_ops = &nlm_xlp_nae_ops;
+
+		/* set ethtool_ops which is inside xlp_ethtool.c file */
+		xlp_set_ethtool_ops(dev);
+
+		/*netif_napi_add(dev, &priv->napi, nlm_xlp_napi_poll, 16); */
+
+		dev->dev_addr = eth_hw_addr[i];
+		priv->port = i;
+
+		atomic64_set(&priv->frin_to_be_sent, nae_cfg.ports[i].num_free_desc);
+		atomic64_set(&priv->num_replenishes, 0);
+		atomic64_set(&priv->total_frin_sent, 0);
+
+		priv->inited = 0;
+		priv->block = nae_cfg.ports[i].hw_port_id / 4;
+		priv->type = nae_cfg.ports[i].iftype;
+		switch (nae_cfg.ports[i].iftype) {
+		case SGMII_IF:
+			priv->index = nae_cfg.ports[i].hw_port_id & 0x3;
+			priv->phy.addr = nae_cfg.ports[i].hw_port_id;
+			break;
+		case XAUI_IF:
+			priv->index = XGMAC;
+			break;
+		case INTERLAKEN_IF:
+			priv->index = INTERLAKEN;
+			break;
+		default:
+			priv->index = 0;
+			break;
+		}
+		if (debug)
+			nlm_print("port%d hw %d block %d index %d type %d \n", i, nae_cfg.ports[i].hw_port_id,
+				priv->block, priv->index, priv->type);
+
+		priv->nae_tx_qid = nae_cfg.ports[i].txq_range[0];
+		priv->nae_rx_qid = nae_cfg.ports[i].rxq;
+
+		register_netdev(dev);
+
+		dev_mac[i] = dev;
+		xlp_mac_setup_hwaddr(priv);
+
+		tasklet_init(&mac_refill_task[priv->port],
+				(void (*)(long unsigned int))mac_refill_frin_desc,
+				(unsigned long)dev);
+	}
+
+	entry = create_proc_read_entry("mac_stats", 0 /* def mode */,
+					nlm_root_proc /* parent */,
+					xlp_mac_proc_read /* proc read function */,
+					0	/* no client data */
+				);
+	if (!entry) {
+		pr_info("[%s]: Unable to create proc read entry for xlp_mac!\n",
+			__func__);
+	}
+}
+
+/*
+ * nlm_xlp_nae_open - called when bring up a device interface
+ * @dev - this is per device based function
+ */
+static int  nlm_xlp_nae_open (struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	int i;
+	int ret = 0;
+
+	if (priv->inited)
+		return 0;
+
+	if (register_xlp_msgring_handler(XLP_MSG_HANDLE_NAE_0, nlm_xlp_nae_msgring_handler, dev)) {
+		pr_info("Fatal error! Can't register msgring handler for TX_STN_GMAC0");
+		ret = -1;
+		goto out;
+	}
+
+	ret = mac_refill_frin_desc((unsigned long)dev);
+	if (ret)
+		goto out;
+
+#ifdef ENABLE_NAE_PIC_INT
+	{
+		int port = priv->port;
+		irq = irt_irq_table[PIC_IRT_NA_INDEX(port)][0];
+		if (request_irq(irq, nlm_xlp_nae_int_handler, IRQF_SHARED, dev->name, dev)) {
+			ret = -EBUSY;
+			pr_info("can't get mac interrupt line (%d)\n", dev->irq);
+		}
+		dump_irt_entry(PIC_IRT_NA_INDEX(port));
+	}
+#endif
+
+	/* set timer to test rx routine */
+	init_timer(&priv->link_timer);
+	/* priv->link_timer.expires = jiffies + HZ; First timer after 1 sec */
+	priv->link_timer.expires = jiffies + HZ; /* First timer after 1s */
+	priv->link_timer.data = (unsigned long) priv->port;
+	priv->link_timer.function = &nlm_xlp_mac_timer;
+	priv->phy_oldlinkstat = -1;
+
+	netif_tx_start_all_queues(dev);
+	add_timer(&priv->link_timer);
+
+	/* napi_enable(&priv->napi); */
+
+	STATS_SET(priv->stats.tx_packets, 0);
+	STATS_SET(priv->stats.tx_errors, 0);
+	STATS_SET(priv->stats.tx_bytes, 0);
+	STATS_SET(priv->stats.tx_dropped, 0);
+	STATS_SET(priv->stats.rx_packets, 0);
+	STATS_SET(priv->stats.rx_errors, 0);
+	STATS_SET(priv->stats.rx_bytes, 0);
+	STATS_SET(priv->stats.rx_dropped, 0);
+	STATS_SET(priv->stats.multicast, 0);
+	STATS_SET(priv->stats.collisions, 0);
+
+	for (i = 0; i < NR_CPUS; i++) {
+		priv->cpu_stats[i].tx_packets = 0;
+		priv->cpu_stats[i].txc_packets = 0;
+		priv->cpu_stats[i].rx_packets = 0;
+		priv->cpu_stats[i].interrupts = 0;
+
+	}
+	priv->inited = 1;
+	nlm_xlp_mac_set_enable(priv, 1);
+out:
+	return ret;
+}
+
+/*
+ * nlm_xlp_nae_stop - called when bring down the interface
+ * @dev - this is per device based function
+ */
+static int  nlm_xlp_nae_stop (struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+
+	spin_lock_irq(&priv->lock);
+	nlm_xlp_mac_set_enable(priv, 0);
+	priv->inited = 0;
+	del_timer_sync(&priv->link_timer);
+
+	netif_tx_stop_all_queues(dev);
+
+	/* napi_disable(&priv->napi); */
+	spin_unlock_irq(&priv->lock);
+	return 0;
+}
+
+
+/*
+ * nlm_xlp_nae_start_xmit - transmit a packet from buffer
+ * @dev - this is per device based function
+ * @skb - data buffer to send
+ */
+static int nlm_xlp_nae_start_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	unsigned long mflags = 0;
+	int cpu = hard_smp_processor_id(), ret = 0;
+	struct xlp_msg msg = { { 0, 0, 0, 0} };
+
+	if (!skb) {
+		pr_info("[%s] skb is NULL\n", __func__);
+		return -1;
+	}
+	if (skb->len == 0) {
+		pr_info("[%s] skb empty packet\n", __func__);
+		return -1;
+	}
+
+	msg.entry[0] = nae_tx_desc(P2D_NEOP, 0, cpu, 0, virt_to_bus(skb));
+	msg.entry[1] = nae_tx_desc(P2D_EOP,
+					0,
+					NULL_VFBID,
+					skb->len,
+					virt_to_bus(skb->data));
+
+	msg.entry[2] = msg.entry[3] = 0;
+
+	DUMP_PKT(__func__, skb->data, skb->len);
+
+	__sync();
+
+	if (debug) {
+		pr_info("[%s]: tx_qid = %d, entry0 = %llx, entry1 = %llx\n", __func__,
+			priv->nae_tx_qid, msg.entry[0], msg.entry[1]);
+	}
+
+	msgrng_access_enable(mflags);
+/* retry_send: */
+	ret = nlm_hal_send_msg2(priv->nae_tx_qid,
+					0,
+					msg.entry[0],
+					msg.entry[1]);
+	if (ret) {
+		print_fmn_send_error(__func__, ret);
+		pr_info("[%s] HACK ALERT! dropping packet(skb = %p)!\n", __func__, skb);
+		dev_kfree_skb_any(skb);
+		/* goto retry_send; */
+	}
+
+	msgrng_access_disable(mflags);
+	dev->trans_start = jiffies;
+
+	STATS_ADD(priv->stats.tx_bytes, skb->len);
+	STATS_INC(priv->stats.tx_packets);
+	priv->cpu_stats[cpu].tx_packets++;
+
+	return NETDEV_TX_OK;
+}
+
+/*
+ * nlm_xlp_set_multicast_list
+ */
+static void  nlm_xlp_set_multicast_list (struct net_device *dev)
+{
+	if (dev->flags & IFF_ALLMULTI) {
+		/*
+		 * Enable ALL multicasts.  Do this by inverting the
+		 * multicast enable bit.
+		 */
+		return;
+	}
+	return;
+}
+
+static void xlp_mac_setup_hwaddr(struct dev_data *priv)
+{
+	struct net_device *dev = priv->dev;
+
+	nlm_hal_write_mac_reg(priv->block, priv->index, MAC_ADDR0_LO, (dev->dev_addr[5] << 24) |
+				(dev->dev_addr[4] << 16) | (dev->dev_addr[3] << 8) | (dev->dev_addr[2]));
+
+	nlm_hal_write_mac_reg(priv->block, priv->index, MAC_ADDR0_HI, (dev->dev_addr[1] << 24) |
+				(dev->dev_addr[0] << 16));
+
+	nlm_hal_write_mac_reg(priv->block, priv->index, MAC_ADDR0_MASK_LO, 0xFFFFFFFF);
+	nlm_hal_write_mac_reg(priv->block, priv->index, MAC_ADDR0_MASK_HI, 0xFFFFFFFF);
+
+	nlm_hal_write_mac_reg(priv->block, priv->index, MAC_FILTER_CONFIG, (1 << MAC_FILTER_BCAST_EN_POS) |
+				(1 << MAC_FILTER_MCAST_EN_POS) | (1 << MAC_FILTER_ADDR0_VALID_POS));
+}
+
+
+/*
+ * nlm_xlp_nae_ioctl
+ */
+static int  nlm_xlp_nae_ioctl (struct net_device *dev, struct ifreq *rq, int cmd)
+{
+	int rc = 0;
+	switch (cmd) {
+	default:
+		rc = -EOPNOTSUPP;
+		break;
+	}
+
+	return rc;
+}
+
+/*
+ * nlm_xlp_nae_change_mtu
+ */
+static int nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	unsigned long flags;
+
+	if ((new_mtu > ETH_MTU_SIZE) || (new_mtu < MIN_ETH_FRAME_SIZE)) {
+		pr_err("%s: (new_mtu > ETH_MTU_SIZE) || (new_mtu < MIN_ETH_FRAME_SIZE)\n", __func__);
+		return -EINVAL;
+	}
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	dev->mtu = new_mtu;
+
+	if (netif_running(dev)) {
+		/* Disable MAC TX/RX */
+		nlm_xlp_mac_set_enable(priv, 0);
+
+		/* Flush RX FR IN */
+		/* Flush TX IN */
+		nlm_xlp_mac_set_enable(priv, 1);
+	}
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return 0;
+}
+
+/*
+ * nlm_xlp_mac_get_stats - wrap function for xlp_get_mac_stats
+ * @dev - this is per device based function
+ */
+static struct net_device_stats *nlm_xlp_mac_get_stats(struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	xlp_get_mac_stats(dev, &priv->stats);
+
+	/* XXX update other stats here */
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return &priv->stats;
+}
+
+/*
+ * nlm_xlp_nae_tx_timeout - called when transmiter timeout
+ * @dev - this is per device based function
+ */
+static void  nlm_xlp_nae_tx_timeout (struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+
+	spin_lock_irq(&priv->lock);
+
+	priv->stats.tx_errors++;
+
+	spin_unlock_irq(&priv->lock);
+
+	netif_tx_wake_all_queues(dev);
+
+	pr_warning("%s: Transmit timed out\n", dev->name);
+	return;
+}
+
+#ifdef ENABLE_NAE_PIC_INT
+/*
+ * nlm_xlp_nae_int_handler - interrupt handler
+ * @irq - irq number
+ * @dev_id - this device
+ */
+static irqreturn_t nlm_xlp_nae_int_handler(int irq, void *dev_id)
+{
+	struct net_device *dev;
+	struct dev_data *priv;
+	int i;
+	int cpu = 0;
+
+	cpu = hard_smp_processor_id();
+	priv->cpu_stats[cpu].interrupts++;
+
+	if (!dev_id) {
+		pr_info("[%s]: NULL dev_id \n", __func__);
+		return IRQ_HANDLED;
+	}
+	dev = (struct net_device *)dev_id;
+	priv = netdev_priv(dev);
+
+	i = find_irt_from_irq(irq);
+
+
+	return IRQ_HANDLED;
+}
+#endif
+
+/*
+ * nlm_xlp_nae_msgring_handler - message ring interrupt handler
+ * @vc-  virtual channel number
+ * @dev_id - this device
+ */
+static void nlm_xlp_nae_msgring_handler(uint32_t vc, uint32_t src_id,
+					uint32_t size, uint32_t code,
+					uint64_t msg0, uint64_t msg1,
+					uint64_t msg2, uint64_t msg3, void *data)
+{
+	struct net_device *pdev;
+	struct dev_data *priv;
+	unsigned int len, port = 0, context;
+	uint64_t addr, vaddr;
+	struct sk_buff *skb;
+	int cpu = 0;
+
+	cpu = hard_smp_processor_id();
+	vc &= 0x03;
+
+	if (debug) {
+		pr_info("[%s] src_id = %d vc = %d, size = %d, entry0 = %llx entry1 = %llx\n", __func__,
+			src_id, vc, size, msg0, msg1);
+	}
+
+	if (vc == nae_fb_vc && size == 1) {
+		/* Process Transmit Complete, addr is the skb pointer */
+		addr = msg0 & 0xffffffffffULL;
+
+		if (drop_uboot_pkt) {
+			if ((addr >= (192<<20)) && (addr < (256 << 20))) {
+				pr_info("%s: Dropping firmware TXC packet (addr = %llx, vc = %d, size = %d)!\n", __func__, addr, vc, size);
+				stats_uboot_pkts++;
+				return;
+			}
+		}
+
+		/* context field is currently unused */
+		context = (msg0 >> 40) & 0x3fff;
+		port = cntx2port[context];
+#ifdef DEBUG_CONTEXT_PORT_MAPPING
+		if (port == 0)
+			pr_info("FB context %d port %d\n", context, port);
+#endif
+		skb = (struct sk_buff *)bus_to_virt(addr);
+		if (skb) {
+			priv = netdev_priv(skb->dev);
+
+			if (debug) {
+				pr_info("[%s][TXC] addr = %llx, skb = %p, context = %d, port = %d\n",
+					__func__, addr, skb, context, port);
+			}
+			dev_kfree_skb_any(skb);
+
+			priv->cpu_stats[cpu].txc_packets++;
+		} else {
+			pr_info("[%s]: [txc] Null skb? paddr = %llx (halting cpu!)\n", __func__, addr);
+			cpu_halt();
+		}
+	} else if (vc == nae_rx_vc && size == 2) {
+		int bad_pkt = 0;
+		int err = (msg1 >> 4) & 0x1;
+		int ip_csum_valid = (msg1 >> 3) & 0x1;
+		int tcp_csum_valid = (msg1 >> 2) & 0x1;
+
+		/* Rx packet */
+		addr = msg1 & 0xffffffffc0ULL;
+		len = (msg1 >> 40) & 0x3fff;
+		context = (msg1 >> 54) & 0x3ff;
+
+#ifdef DEBUG_RXPKT_ADDR_NULL
+		if (addr == 0) {
+			pr_err("Rcvd pkt address NULL !!!\n");
+			pr_err("[%s] src_id=%d vc = %d, size = %d, entry0=%llx entry1=%llx\n", __func__,
+				src_id, vc, size, msg0, msg1);
+			return;
+		}
+#endif
+
+		if (err)
+			bad_pkt = 1;
+
+		if (drop_uboot_pkt) {
+			if ((addr >= (192<<20)) && (addr < (256 << 20))) {
+				pr_info("%s: Dropping firmware RX packet (addr = %llx, vc = %d, size = %d)!\n", __func__, addr, vc, size);
+				stats_uboot_pkts++;
+				return;
+			}
+		}
+
+		port = cntx2port[context];
+#ifdef DEBUG_CONTEXT_PORT_MAPPING
+		if (port == 0)
+			pr_info("Rx context %d port %d \n", context, port);
+#endif
+		if (port >= MAX_GMAC_PORT) {
+			pr_info("[%s]: bad port = %d, context = %d\n", __func__, port, context);
+			return;
+		}
+
+		pdev = (struct net_device *)dev_mac[port];
+		if (!pdev) {
+			pr_info("[%s]: [RX] wrong port = %d(context = %d)? pdev = NULL!\n", __func__, port, context);
+			return;
+		}
+		priv = netdev_priv(pdev);
+
+		vaddr = (uint64_t)bus_to_virt(addr);
+
+		if (debug) {
+			pr_info("[%s][RX] addr = %llx, len = %d, context = %d, port = %d, vaddr = %llx\n",
+				__func__, addr, len, context, port, vaddr);
+		}
+
+		DUMP_PKT("RX Packet: ", (unsigned char *)vaddr, len);
+
+		len = len - MAC_CRC_LEN;
+
+		skb = mac_get_skb_back_ptr(vaddr);
+		if (!skb) {
+			STATS_INC(priv->stats.rx_errors);
+			STATS_INC(priv->stats.rx_dropped);
+			pr_info("[%s] Null skb? addr = %llx, vaddr = %llx, drop it!\n",
+				__func__, addr, vaddr);
+			cpu_halt();
+			return;
+		}
+
+		if (debug) {
+			struct iphdr *iph = (struct iphdr *)(vaddr + 14);
+			int net_pkt_len = iph->tot_len + 14;
+			int eth_proto = *(unsigned short *)(vaddr + 12);
+
+			if ((eth_proto == 0x800) && (net_pkt_len != len))
+				bad_pkt = 1;
+
+			if (bad_pkt) {
+				pr_info("[%s]: vaddr = %llx (len:%d/%d) (ip:proto = %d) (%d/%d/%d))\n",
+					__func__, vaddr, net_pkt_len, len, iph->protocol,
+					err, ip_csum_valid, tcp_csum_valid);
+			}
+		}
+
+		if (bad_pkt) {
+			STATS_INC(priv->stats.rx_errors);
+			STATS_INC(priv->stats.rx_dropped);
+
+			dev_kfree_skb_any(skb);
+			goto out;
+		}
+
+		skb_put(skb, len);
+		skb->dev = dev_mac[port];
+		skb->protocol = eth_type_trans(skb, dev_mac[port]);
+		skb->dev->last_rx = jiffies;
+
+		/* Pass the packet to Network stack */
+		netif_rx (skb);
+
+		/* Update Stats */
+		STATS_ADD(priv->stats.rx_bytes, len);
+		STATS_INC(priv->stats.rx_packets);
+		priv->cpu_stats[cpu].rx_packets++;
+
+out:
+		if (atomic64_inc_return(&priv->frin_to_be_sent) > frin_desc_thres) {
+			tasklet_schedule(&mac_refill_task[port]);
+			/* mac_refill_frin_desc((unsigned long) skb->dev); */
+		}
+	} else {
+		pr_info("[%s]: wrong vc = %d or size = %d?\n", __func__, vc, size);
+	}
+
+	return;
+}
+
+/*
+ * xlp_mac_proc_read - proc file system read routine
+ * @page - buffer address
+ * @dev_id - this device
+ */
+static int xlp_mac_proc_read(char *page, char * *start, off_t off,
+				int count, int *eof, void *data)
+{
+	int len = 0;
+	off_t begin = 0;
+	int i = 0, cpu = 0;
+	struct net_device *dev = 0;
+	struct dev_data *priv = 0;
+
+	len += sprintf(page + len, "uboot_pkts = %ld\n", stats_uboot_pkts);
+
+	for (i = 0; i < MAX_GMAC_PORT; i++) {
+
+		dev = dev_mac[i];
+
+		if (dev == 0)
+			continue;
+
+		priv = netdev_priv(dev);
+
+		len += sprintf(page + len, "=============== port@%d ==================\n", i);
+
+		len += sprintf(page + len, "per port@%d: frin_to_be_sent = %ld num_replenishes = %ld frin_sent = %ld\n",
+				i, atomic64_read(&priv->frin_to_be_sent),
+				atomic64_read(&priv->num_replenishes),
+				atomic64_read(&priv->total_frin_sent));
+
+		len += sprintf(page + len,
+				"per port@%d: %lu(rxp) %lu(rxb) %lu(txp) %lu(txb)\n",
+				i,
+				STATS_READ(priv->stats.rx_packets),
+				STATS_READ(priv->stats.rx_bytes),
+				STATS_READ(priv->stats.tx_packets),
+				STATS_READ(priv->stats.tx_bytes));
+
+		for (cpu = 0; cpu < NR_CPUS; cpu++) {
+			unsigned long tx = priv->cpu_stats[cpu].tx_packets;
+			unsigned long txc = priv->cpu_stats[cpu].txc_packets;
+			unsigned long rx = priv->cpu_stats[cpu].rx_packets;
+			unsigned long ints = priv->cpu_stats[cpu].interrupts;
+
+			if (!tx && !txc && !rx && !ints)
+				continue;
+
+			len += sprintf(page + len, "per cpu@%d: %lu(txp) %lu(txcp) %lu(rxp) %lu(int)\n",
+					cpu, tx, txc, rx, ints);
+		}
+	}
+
+	*eof = 1;
+
+	*start = page + (off - begin);
+	len -= (off - begin);
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+
+	return len;
+}
+
+/*
+ * nlm_xlp_mac_timer - interrupt handler routine
+ * @data - parameter passed in when timer interrupt handler is called.
+ */
+static void nlm_xlp_mac_timer(unsigned long data)
+{
+	unsigned port = data;
+	struct net_device *dev = (struct net_device *)dev_mac[port];
+	struct dev_data *priv = netdev_priv(dev);
+	int next_tick = HZ / 1000; /* 1ms */
+
+	/* printk("[%s] A0 Workaround, forcing FMN int handling \n",__func__); */
+	if (priv->inited) {
+		uint32_t cpumask = cpumask_to_uint32(&cpu_present_map); /* doesn't handle non-n0 nodes */
+		uint32_t cpumask_lo;
+		uint32_t cpumask_hi;
+
+		pic_reg_t *mmio = nlm_hal_pic_offset();
+		int cpu = hard_smp_processor_id();
+
+		cpumask = cpumask & ~(1 << cpu);
+		cpumask_hi = cpumask >> 16;;
+		cpumask_lo = cpumask & 0xffff;
+
+		/* Send IRQ_MSGRING vector in an IPI to all cpus but the current one */
+		if (cpumask_lo)
+			nlm_hal_write_pic_reg(mmio, PIC_IPI_CTL, (IRQ_MSGRING << 20) | cpumask_lo);
+
+		if (cpumask_hi)
+			nlm_hal_write_pic_reg(mmio, PIC_IPI_CTL, (IRQ_MSGRING << 20) | (1 << 16)
+					      | (cpumask_hi));
+
+		/* Run IPI handler on this cpu too */
+		nlm_xlp_msgring_int_handler(IRQ_MSGRING, NULL);
+	}
+
+	priv->link_timer.expires = jiffies + next_tick;
+	add_timer(&priv->link_timer);
+}
+
+static int __devinit nlm_xlp_nae_pci_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
+{
+	int result = 0;
+
+	result = pci_enable_device(pdev);
+	return result;
+}
+
+/*
+ * nlm_xlp_nae_remove - driver remove routine
+ * @pdev - pci device.
+ */
+static void nlm_xlp_nae_remove(struct pci_dev *pdev)
+{
+	int i;
+	struct net_device *dev = 0;
+	struct dev_data *priv = 0;
+
+	for (i = 0; i < MAX_GMAC_PORT; i++) {
+		dev = dev_mac[i];
+
+		/* skip non-existant ports */
+		if (dev == 0)
+			continue;
+
+		priv = netdev_priv(dev);
+		/* netif_napi_del(&priv->napi); */
+		unregister_netdev(dev);
+		free_netdev(dev);
+	}
+
+	remove_proc_entry("mac_stats", nlm_root_proc /* parent dir */);
+}
+
+static struct pci_driver soc_driver = {
+	.name = XLP_SOC_MAC_DRIVER,
+	.id_table = soc_pci_table,
+	.probe = nlm_xlp_nae_pci_probe,
+	.remove = nlm_xlp_nae_remove,
+};
+
+static int __init nlm_xlp_mac_init(void)
+{
+	nlm_xlp_nae_init();
+
+	return pci_register_driver(&soc_driver);
+}
+
+static void __exit nlm_xlp_mac_exit(void)
+{
+	/* unregister mac driver */
+	pci_unregister_driver(&soc_driver);
+}
+
+module_init(nlm_xlp_mac_init);
+module_exit(nlm_xlp_mac_exit);
+
+MODULE_AUTHOR("Netlogic Microsystems");
+MODULE_DESCRIPTION("Netlogic XLP SoC Network driver ");
+MODULE_LICENSE("GPL");
+MODULE_VERSION("0.1");
diff --git a/drivers/net/nae/xlp_nae.h b/drivers/net/nae/xlp_nae.h
new file mode 100644
index 0000000..c62e197
--- /dev/null
+++ b/drivers/net/nae/xlp_nae.h
@@ -0,0 +1,94 @@
+#ifndef _XLP_NAE_H
+#define _XLP_NAE_H
+
+#define MAC_MAX_FRAME_SIZE	1600
+#define MAC_SKB_BACK_PTR_SIZE	SMP_CACHE_BYTES
+
+#define MAC_PREPAD		0
+#define BYTE_OFFSET		2
+#define NLM_RX_BUF_SIZE (MAC_MAX_FRAME_SIZE+BYTE_OFFSET+MAC_PREPAD+MAC_SKB_BACK_PTR_SIZE+SMP_CACHE_BYTES)
+#define MAC_CRC_LEN		4
+#define CACHELINE_SIZE		(1ULL << 6)
+#define CACHELINE_ALIGNED(addr) (((addr) + (CACHELINE_SIZE-1)) & ~(CACHELINE_SIZE-1))
+#define PHYS_TO_VIRT(paddr) (uint64_t)((paddr) - (netlib_paddrb) + (netlib_vaddrb))
+#define VIRT_TO_PHYS(vaddr) (uint64_t)((vaddr) - (netlib_vaddrb) + (netlib_paddrb))
+extern unsigned long long netlib_vaddrb;
+extern unsigned long long netlib_paddrb;
+#define PADDR_BASE 0x100000ULL
+#define PADDR_SIZE 0x200000
+#define INIT_VBASE(vbase, pbase) { etlib_vaddrb = vbase; netlib_paddrb = pbase; }
+
+struct cpu_stat {
+	unsigned long tx_packets;
+	unsigned long txc_packets;
+	unsigned long rx_packets;
+	unsigned long interrupts;
+};
+
+
+typedef enum xlp_net_types {
+	TYPE_XLP_GMAC = 0,
+	TYPE_XLP_XGMAC,
+	TYPE_XLP_XAUI,
+	TYPE_XLP_INTERLAKEN,
+	MAX_XLP_NET_TYPES
+} xlp_interface_t;
+
+typedef enum {
+	xlp_mac_speed_10,
+	xlp_mac_speed_100,
+	xlp_mac_speed_1000,
+	xlp_mac_speed_rsvd
+} xlp_mac_speed_t;
+
+typedef enum {
+	xlp_mac_duplex_auto,
+	xlp_mac_duplex_half,
+	xlp_mac_duplex_full
+} xlp_mac_duplex_t;
+
+typedef enum {
+	xlp_mac_fc_auto,
+	xlp_mac_fc_disabled,
+	xlp_mac_fc_frame,
+	xlp_mac_fc_collision,
+	xlp_mac_fc_carrier
+} xlp_mac_fc_t;
+
+struct phy_info {
+	int addr;
+	int mode;
+	uint32_t *mii_addr;
+	uint32_t *pcs_addr;
+	uint32_t *serdes_addr;
+};
+
+struct dev_data {
+	struct net_device *dev;
+	struct net_device_stats stats;
+	struct cpu_stat cpu_stats[NR_CPUS];
+	struct timer_list link_timer;
+	struct napi_struct napi;
+	spinlock_t lock;
+	unsigned short port;
+	unsigned short inited;
+	unsigned short block;
+	unsigned short index;
+	unsigned short type;
+	struct sk_buff *skb;
+	int phy_oldlinkstat;
+	atomic64_t frin_to_be_sent;
+	atomic64_t num_replenishes;
+	atomic64_t total_frin_sent;
+	__u8 hwaddr[6];
+
+	xlp_mac_speed_t speed; /* current speed */
+	xlp_mac_duplex_t duplex; /* current duplex */
+	xlp_mac_fc_t flow_ctrl; /* current flow control setting */
+	int advertising;
+	struct phy_info phy;
+	uint32_t nae_rx_qid;
+	uint32_t nae_tx_qid;
+};
+
+#endif
-- 
1.7.0.2

