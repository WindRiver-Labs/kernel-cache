From c5e97277e7957ce87d33156e229022d751dbe032 Mon Sep 17 00:00:00 2001
From: Wu Zhangjin <zhangjin.wu@windriver.com>
Date: Thu, 7 Apr 2011 15:00:40 +0800
Subject: [PATCH 18/37] nlm_xlp_64_be: add board support for NetLogic XLP8xx EVB

[ Based on netlogic SDK 20110720 ]

Add basic board support for NetLogic XLP8xx EVB, includes irq, reset,
smp, hal and on chip devices and board setup.

Signed-off-by: henry shao <hshao@netlogicmicro.com>
Signed-off-by: Krishnamurthy D V <kmurthy@netlogicmicro.com>
Signed-off-by: Zi Shen Lim <zlim@netlogicmicro.com>
[ Clean up irq support and fdt process related functions; Fix
hard-coded NR_CPUS issue, NR_CPUS can be set to non hard-coded 128
value, such as 32/64 ...; Support 3 memory segmentations. ]
Signed-off-by: Wu Zhangjin <zhangjin.wu@windriver.com>
---
 arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h   |   24 +-
 .../mips/include/asm/netlogic/hal/nlm_hal_macros.h |  126 +-
 arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h   |   46 +-
 arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h   |    6 +-
 arch/mips/include/asm/netlogic/hal/nlm_hal_sae.h   |    2 +
 .../include/asm/netlogic/hal/nlm_hal_xlp_dev.h     |  173 ++-
 arch/mips/include/asm/netlogic/xlp.h               |    2 +-
 arch/mips/mm/cerr-nlm.c                            |    1 +
 arch/mips/netlogic/common/Makefile                 |    8 +
 arch/mips/netlogic/common/bootinfo.c               |   24 +
 arch/mips/netlogic/common/cpu_proc.c               |  223 ++
 arch/mips/netlogic/common/dma.c                    |  601 +++++
 arch/mips/netlogic/common/fdt_helper.c             |  158 ++
 arch/mips/netlogic/common/memory.c                 |  218 ++
 arch/mips/netlogic/common/nlm_hal.c                | 2296 ++++++++++++++++++++
 arch/mips/netlogic/common/nlm_hal_fmn_config.c     |  343 +++
 arch/mips/netlogic/common/nlm_hal_nae.c            | 1679 ++++++++++++++
 arch/mips/netlogic/xlp/Makefile                    |    9 +
 arch/mips/netlogic/xlp/board.c                     |   48 +
 arch/mips/netlogic/xlp/bootinfo.c                  |   93 +
 arch/mips/netlogic/xlp/cpu_control.c               |  186 ++
 arch/mips/netlogic/xlp/cpu_control_asm.S           |  200 ++
 arch/mips/netlogic/xlp/cpu_control_macros.h        |  155 ++
 arch/mips/netlogic/xlp/irq.c                       |  415 ++++
 arch/mips/netlogic/xlp/nmi.S                       |   53 +
 arch/mips/netlogic/xlp/on_chip.c                   |  453 ++++
 arch/mips/netlogic/xlp/platform.c                  |  264 +++
 arch/mips/netlogic/xlp/setup.c                     |  685 ++++++
 arch/mips/netlogic/xlp/smp.c                       |  283 +++
 arch/mips/netlogic/xlp/time.c                      |  130 ++
 30 files changed, 8847 insertions(+), 57 deletions(-)
 create mode 100644 arch/mips/netlogic/common/Makefile
 create mode 100644 arch/mips/netlogic/common/bootinfo.c
 create mode 100644 arch/mips/netlogic/common/cpu_proc.c
 create mode 100644 arch/mips/netlogic/common/dma.c
 create mode 100644 arch/mips/netlogic/common/fdt_helper.c
 create mode 100644 arch/mips/netlogic/common/memory.c
 create mode 100644 arch/mips/netlogic/common/nlm_hal.c
 create mode 100644 arch/mips/netlogic/common/nlm_hal_fmn_config.c
 create mode 100644 arch/mips/netlogic/common/nlm_hal_nae.c
 create mode 100644 arch/mips/netlogic/xlp/Makefile
 create mode 100644 arch/mips/netlogic/xlp/board.c
 create mode 100644 arch/mips/netlogic/xlp/bootinfo.c
 create mode 100644 arch/mips/netlogic/xlp/cpu_control.c
 create mode 100644 arch/mips/netlogic/xlp/cpu_control_asm.S
 create mode 100644 arch/mips/netlogic/xlp/cpu_control_macros.h
 create mode 100644 arch/mips/netlogic/xlp/irq.c
 create mode 100644 arch/mips/netlogic/xlp/nmi.S
 create mode 100644 arch/mips/netlogic/xlp/on_chip.c
 create mode 100644 arch/mips/netlogic/xlp/platform.c
 create mode 100644 arch/mips/netlogic/xlp/setup.c
 create mode 100644 arch/mips/netlogic/xlp/smp.c
 create mode 100644 arch/mips/netlogic/xlp/time.c

diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h
index 0aa41ee..a3f14a4 100644
--- a/arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h
@@ -129,6 +129,7 @@ static inline int xlp_send(unsigned int dest)
         __asm__ volatile (".set push\n"
                           ".set noreorder\n"
                           ".set arch=xlp\n"
+                          "sync\n"
                           "msgsnds %0, %1\n"
                           ".set pop\n"
                           : "=&r" (success)
@@ -207,6 +208,7 @@ static inline int xlp_message_send_1(uint32_t dst,
 				     uint32_t  code, uint64_t data)
 {
   unsigned int dest = 0;
+  int retry = 16;
 
   xlp_load_tx_msg0(data);
 
@@ -216,13 +218,13 @@ static inline int xlp_message_send_1(uint32_t dst,
   nlm_hal_dbg_msg("Sending msg<%llx> to dest = %x\n", 
 	  data, dest);
 #endif
-	
-  if (!xlp_send(dest) ) {
-	  /* Check the status */
-	  return xlp_read_tx_status() ;
+
+  while(retry--){
+	if(xlp_send(dest))
+		return 0;
   }
+  return xlp_read_tx_status();
 
-  return 0;
 }
 /* message send API NON blocking for double entry message*/
 static inline int xlp_message_send_2(uint32_t dst, 
@@ -230,7 +232,7 @@ static inline int xlp_message_send_2(uint32_t dst,
 				     uint64_t data0, uint64_t data1)
 {
   unsigned int dest = 0;
-
+  int retry = 16;
 
   xlp_load_tx_msg0(data0);
   xlp_load_tx_msg1(data1);
@@ -241,13 +243,11 @@ static inline int xlp_message_send_2(uint32_t dst,
   nlm_hal_dbg_msg("Sending msg<%llx, %llx> to dest = %x\n", 
 	  data0, data1, dest);
 #endif
-	
-  if (!xlp_send(dest) ) {
-	  /* Check the status */
-	  return xlp_read_tx_status();
+  while(retry--){
+	if(xlp_send(dest))
+		return 0;
   }
-
-  return 0;
+  return xlp_read_tx_status();
 }
 
 /* message send API NON blocking for double entry message*/
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_macros.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_macros.h
index 45aa58a..9e2811b 100644
--- a/arch/mips/include/asm/netlogic/hal/nlm_hal_macros.h
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_macros.h
@@ -27,19 +27,15 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #define _NLM_HAL_MACROS_H
 
 #ifndef __ASSEMBLY__
-extern unsigned long long xlp_io_base;
-extern unsigned long long xlp_fmn_base;
-extern unsigned long long xlp_nae_base;
-extern unsigned long long xlp_mac_base;
-extern unsigned long long xlp_poe_base_pcie;
-extern unsigned long long xlp_poe_base_pcim;
-extern unsigned long long xlp_sys_base;
-#endif /* #ifndef __ASSEMBLY__ */
+extern unsigned long xlp_io_base;
+extern unsigned long xlp_fmn_base;
+extern unsigned long xlp_nae_base;
+extern unsigned long xlp_mac_base;
+extern unsigned long xlp_poe_base_pcie;
+extern unsigned long xlp_poe_base_pcim;
+extern unsigned long xlp_sys_base;
 
-#ifndef NLM_HAL_LINUX_KERNEL
-#define preempt_enable()
-#define preempt_disable()
-#endif
+#endif /* #ifndef __ASSEMBLY__ */
 
 #define msgrng_enable(flags)                \
 do {                                        \
@@ -75,6 +71,7 @@ do {                                        \
   preempt_enable();                          \
 } while(0)
 
+
 #if defined(NLM_HAL_LINUX_USER) /* Linux User mode */
 
 #include <stdio.h>
@@ -86,7 +83,25 @@ do {                                        \
 #define nlm_print printf
 #define nlm_malloc malloc
 #define nlm_free  free
-#define nlm_delay(x) usleep((x) * 1000)
+				       // Adding a new macro for mdelay. 
+#if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32) || \
+    (_MIPS_SZLONG == 32)
+#define KSEG0     0x80000000UL
+#define KSEG1     0xA0000000UL
+#define KSEG2     0xC0000000UL
+#define KSEG3     0xE0000000UL
+#define KSEG0_PHY_BOUNDARY 0x10000000UL    // 256 MB
+#else
+#define KSEG0     (0xffffffff80000000ULL)
+#define KSEG1     (0xffffffffA0000000ULL)
+#define KSEG2     (0xffffffffC0000000ULL)
+#define KSEG3     (0xffffffffE0000000ULL)
+#define KSEG0_PHY_BOUNDARY 0x10000000ULL    // 256 MB
+#endif
+
+#define nlm_udelay(n) 	usleep(n)
+#define nlm_mdelay(n) 	usleep(n * 1000) 
+				        
 
 #elif defined(NLM_HAL_LINUX_KERNEL) /* Linux Kenrel mode */
 
@@ -101,13 +116,30 @@ do {                                        \
 #define nlm_print printk
 #define nlm_malloc(size) kzalloc((size), GFP_KERNEL)
 #define nlm_free  kfree
-#define nlm_delay  mdelay
+
+#if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32) || \
+    (_MIPS_SZLONG == 32)
+#define KSEG0     0x80000000UL
+#define KSEG1     0xA0000000UL
+#define KSEG2     0xC0000000UL
+#define KSEG3     0xE0000000UL
+#define KSEG0_PHY_BOUNDARY 0x10000000UL    // 256 MB
+#else
+#define KSEG0     (0xffffffff80000000ULL)
+#define KSEG1     (0xffffffffA0000000ULL)
+#define KSEG2     (0xffffffffC0000000ULL)
+#define KSEG3     (0xffffffffE0000000ULL)
+#define KSEG0_PHY_BOUNDARY 0x10000000ULL    // 256 MB
+#endif
+#define nlm_mdelay(n) mdelay(n)
+
+#define nlm_udelay(n)	udelay(n)
+#define nlm_mdelay(n)  	mdelay(n)
 
 extern int register_xlp_msgring_handler(int major,
                              void (*action) (uint32_t, uint32_t, uint32_t, uint32_t,
                                              uint64_t, uint64_t, uint64_t, uint64_t, void *),
                              void *dev_id);
-
 #endif /* __ASSEMBLY__ */
 
 #elif defined(NLM_HAL_NETOS) /* Netos */
@@ -121,8 +153,9 @@ extern int register_xlp_msgring_handler(int major,
 #define nlm_print printf
 #define nlm_malloc malloc
 #define nlm_free  free
-#define nlm_delay(x)  _netos_delay(x) /* Temporary implementation for netos-hyperex */
-static __inline__ void _netos_delay(x)
+#define nlm_udelay(x)	_netos_delay(x) /* Temporary implementation for netos-hyperex */
+#define nlm_mdelay(n) 	nlm_udelay(n * 1000)
+static __inline__ void _netos_delay(unsigned int x)
 {
         unsigned long int i;
 
@@ -133,9 +166,23 @@ static __inline__ void _netos_delay(x)
         for (i = 0; i<(1000 * x) ; i++)
                 __asm__ __volatile__ ("");
 }
-
 #endif /* __ASSEMBLY__ */
 
+#if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32) || \
+    (_MIPS_SZLONG == 32)
+#define KSEG0     0x80000000
+#define KSEG1     0xA0000000
+#define KSEG2     0xC0000000
+#define KSEG3     0xE0000000
+#define KSEG0_PHY_BOUNDARY 0x10000000    // 256 MB
+#else
+#define KSEG0     (0xffffffff80000000)
+#define KSEG1     (0xffffffffA0000000)
+#define KSEG2     (0xffffffffC0000000)
+#define KSEG3     (0xffffffffE0000000)
+#define KSEG0_PHY_BOUNDARY 0x10000000    // 256 MB
+#endif
+
 #elif defined(NLM_HAL_UBOOT) /* u-boot */
 
 #include <common.h>
@@ -145,7 +192,23 @@ static __inline__ void _netos_delay(x)
 #define nlm_print printf
 #define nlm_malloc malloc
 #define nlm_free  free
-#define nlm_delay  udelay
+#define nlm_udelay(n)	udelay(n)
+#define nlm_mdelay(n) 	udelay(n * 1000)
+
+#if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32) || \
+    (_MIPS_SZLONG == 32)
+#define KSEG0     0x80000000UL
+#define KSEG1     0xA0000000UL
+#define KSEG2     0xC0000000UL
+#define KSEG3     0xE0000000UL
+#define KSEG0_PHY_BOUNDARY 0x10000000UL    // 256 MB
+#else
+#define KSEG0     (0xffffffff80000000ULL)
+#define KSEG1     (0xffffffffA0000000ULL)
+#define KSEG2     (0xffffffffC0000000ULL)
+#define KSEG3     (0xffffffffE0000000ULL)
+#define KSEG0_PHY_BOUNDARY 0x10000000ULL    // 256 MB
+#endif
 
 #elif defined(NLM_HAL_NETLBOOT) /* netlboot */
 #include <printk.h>
@@ -153,7 +216,8 @@ static __inline__ void _netos_delay(x)
 #define nlm_print printk
 #define nlm_malloc malloc
 #define nlm_free  free
-#define nlm_delay  mdelay
+#define nlm_udelay(n)	udelay(n)
+#define nlm_mdelay(n) 	mdelay(n)
 
 #else
 #error "Unsupported platform for NL HAL"
@@ -525,6 +589,12 @@ do {                                                                    \
 
 #endif /* _ABI64 */
 
+#ifdef NLM_HAL_LINUX_KERNEL 
+#define DFS_OUTPUT(DR, DF, DV)  ((400/((DR+1) * 3)) * (DF+1) * 2)/(DV+1)
+#else
+#define DFS_OUTPUT(DR, DF, DV)  ((133.33/(DR+1)) * (DF+1) * 2)/(DV+1)
+#endif
+
 typedef enum crc_type {
 	NLM_CRC_32 = 0,
 	NLM_CRC_16 = 16,
@@ -806,6 +876,8 @@ static __inline__ uint64_t xlp_get_field_dw(uint64_t dword, int lsb, int size)
 #define nlh_read_cfg_reg64(addr)       nlm_uaccess_mem_read64((NLH_XKPHYS_UNCACHED | (addr)))
 #define nlh_write_cfg_reg64(addr, val) nlm_uaccess_mem_write64((NLH_XKPHYS_UNCACHED | (addr)), (val))
 
+#define nlh_send_msg3(dst, code, data0, data1, data2) \
+  nlm_uaccess_msgsnd_3(code, dst, data0, data1, data2)
 
 #define nlh_send_msg2(dst, code, data0, data1) \
   nlm_uaccess_msgsnd_2(code, dst, data0, data1)
@@ -861,6 +933,20 @@ static __inline__ uint64_t xlp_get_field_dw(uint64_t dword, int lsb, int size)
 
 #endif
 
+#else  /* __ASSEMBLY__ */
+
+#if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32) || \
+    (_MIPS_SZLONG == 32)
+#define LW lw
+#define LA la
+#define SW sw
+#else
+#define LW ld
+#define LA dla
+#define SW sd
+#endif
+
+
 #endif /* __ASSEMBLY__ */
 
 
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h
index 8ee6c79..818bcc1 100644
--- a/arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h
@@ -36,18 +36,21 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #define MAX_NAE_CONTEXTS       524
 
 struct nlm_hal_nae_port {
-	uint32_t  valid;
-	uint32_t  mgmt;
-        uint32_t  num_free_desc;
-        uint32_t  txq_range[2];
-        uint32_t  rxq;
-        uint32_t  hw_port_id;
+	int  valid;
+	int  mgmt;
+        int  num_free_desc;
+        int  txq_range[2];
+        int  rxq;
+        int  hw_port_id;
+	int  vlan_pri_en;
+	int  iftype;
+	int  num_channels;
 };
 
 struct nlm_hal_nae_config {
-	uint32_t fb_vc;
-        uint32_t rx_vc;
-	uint32_t num_ports;
+	int fb_vc;
+        int rx_vc;
+	int num_ports;
 	struct nlm_hal_nae_port ports[18];
 };
 
@@ -102,6 +105,9 @@ static __inline__ uint32_t flow_base_mask_config(unsigned int interface, unsigne
 }
 
 extern int nlm_hal_init_poe_distvec(int vec, uint32_t cm0, uint32_t cm1, uint32_t cm2, uint32_t cm3, uint32_t vcmask);
+extern void nlm_hal_init_poe_ext_storage(uint64_t fbp_base_phys,
+					 uint64_t msg_base_phys,
+					 uint64_t msg_base_virt);
 
 extern int nlm_hal_load_ucore(int ucore_mask, unsigned int *opcodes, int num_opcodes);
 
@@ -110,13 +116,13 @@ extern int nlm_hal_open_if(int type, int  inf);
 extern int nlm_hal_close_if(int type, int  inf);
 
 /* Here regs are pairs of <index, val> of interface regs */
-extern int nlm_hal_init_if_regs(int type, int  inf, uint32_t *regs, uint32_t num_regs);
+extern int nlm_hal_init_if_regs(int type, int  inf, uint32_t *regs, int num_regs);
 
 /* Here regs are pairs of <index, val> of NAE regs */
-extern int nlm_hal_init_nae_regs(int type, uint32_t *regs, uint32_t num_regs);
+extern int nlm_hal_init_nae_regs(int type, uint32_t *regs, int num_regs);
 
 /* Here regs are pairs of <index, val> of POE regs */
-extern int nlm_hal_init_poe_regs(uint32_t *regs, uint32_t num_regs);
+extern int nlm_hal_init_poe_regs(uint32_t *regs, int num_regs);
 
 extern int nlm_hal_nae_send(int dest, int fbid, unsigned long long phys_addr, int len, unsigned int flags);
 extern int nlm_hal_nae_recv(int rx_vc, unsigned long long *phys_addr, unsigned int *flags);
@@ -139,12 +145,22 @@ extern void nae_lane_reset_txpll(int block, int lane_ctrl);
 
 /*  PCS initialization
  */
-extern void nlm_hal_sgmii_pcs_init(uint32_t sgmii_cplx_mask);
-extern void nlm_hal_xaui_pcs_init(uint32_t xaui_cplx_mask);
-
+extern void nlm_hal_sgmii_pcs_init(int sgmii_cplx_mask);
+extern void nlm_hal_xaui_pcs_init(int xaui_cplx_mask);
+extern void nlm_hal_ilk_pcs_init(int ilk_cplx_mask, int num_lanes);
 extern void nlm_hal_sgmii_phy_init(void);
 
 extern int nlm_hal_init_nae(void *fdt, int dom_id);
 
+extern int nlm_hal_write_ucore_shared_mem(unsigned int *data, int words);
+
+extern int nlm_hal_get_phy_status(int inf, uint32_t *speed, uint32_t *duplex);
+
+extern void nlm_hal_mac_disable(int inf, int type);
+
+extern void nlm_hal_mac_enable(int inf, int type);
+
+extern uint16_t nlm_hal_get_hwport(uint32_t context);
+
 #endif //__ASSEMBLY__
 #endif //#ifndef _NLM_HAL_NAE_H_
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h
index 1da3697..386b1de 100644
--- a/arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h
@@ -156,8 +156,8 @@ THE POSSIBILITY OF SUCH DAMAGE.
 
 #define PIC_INT_THR_ENABLE_0_N01   0x2a
 #define PIC_INT_THR_ENABLE_0_N23   0x2b
-#define PIC_INT_THR_ENABLE_N01(id) (PIC_INT_THR_ENABLE_0_N01 + ((id) * 2))
-#define PIC_INT_THR_ENABLE_N23(id) (PIC_INT_THR_ENABLE_0_N23 + ((id) * 2))
+#define PIC_INT_THR_ENABLE_N01(id) (PIC_INT_THR_ENABLE_0_N12 + ((id) * 2))
+#define PIC_INT_THR_ENABLE_N23(id) (PIC_INT_THR_ENABLE_0_N12 + ((id) * 2))
 
 #define PIC_IRT_0   0x3a
 #define PIC_IRT(id) (PIC_IRT_0 + (id))
@@ -231,7 +231,7 @@ static __inline__ int nlm_hal_is_shared_irt(int irt_num)
 #define PIC_UART_1_IRQ           18
 #define PIC_I2C_0_IRQ            nlm_hal_irt_to_irq(PIC_IRT_I2C_0_INDEX)
 #define PIC_I2C_1_IRQ            nlm_hal_irt_to_irq(PIC_IRT_I2C_1_INDEX)
-#define PIC_GPIO_IRQ             nlm_hal_irt_to_irq(PIC_IRT_GPIO_INDEX)
+#define PIC_GPIO_IRQ(num)        nlm_hal_irt_to_irq(PIC_IRT_GPIO_INDEX(num))
 #define PIC_IRT_LAST_IRQ_        (PIC_IRQ_BASE + PIC_NUM_IRTS - 1)
 #define PIC_IRT_LAST_IRQ()       PIC_IRT_LAST_IRQ_
 
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_sae.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_sae.h
index 998fbcf..9db2d5b 100644
--- a/arch/mips/include/asm/netlogic/hal/nlm_hal_sae.h
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_sae.h
@@ -107,6 +107,8 @@ struct nlm_crypto_param {
 					(XLP_CRYPTO_NODE, XLP_CRYPTO_BUS, XLP_CRYPTO_DEVICE, XLP_CRYPTO_FUNC), \
 					 (reg))
 
+extern void nlm_hal_set_sae_freq(int freq);
+
 /* Should return error of Alo - Mode combo is not supported*/
 extern int nlm_hal_crypto_preprocess_request(void *cntrl_desc_mem,
 					     struct nlm_crypto_cipher_init_param
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_xlp_dev.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_xlp_dev.h
index 2439e9d..58aa764 100644
--- a/arch/mips/include/asm/netlogic/hal/nlm_hal_xlp_dev.h
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_xlp_dev.h
@@ -234,10 +234,10 @@ enum net_cfg_regs {
  TX_IFACE_ENBL_STATUS               = 0x49,
  TX_PKTLEN_PMEM_CMD                 = 0x4a,
  TX_PKTLEN_PMEM_STATUS              = 0x4b,
- TX_SCHED_CTXTMAP_CMD0              = 0x4c,
- TX_SCHED_CTXTMAP_CMD1              = 0x4d,
- TX_SCHED_CTXTMAP_STATUS0           = 0x4e,
- TX_SCHED_CTXTMAP_STATUS1           = 0x4f,
+ TX_SCHED_MAP_CMD0                  = 0x4c,
+ TX_SCHED_MAP_CMD1                  = 0x4d,
+ TX_SCHED_MAP_STATUS0               = 0x387,
+ TX_SCHED_MAP_STATUS1               = 0x388,
  TX_PKT_PMEM_CMD0                   = 0x50,
  TX_PKT_PMEM_CMD1                   = 0x51,
  TX_PKT_PMEM_STATUS                 = 0x52,
@@ -261,6 +261,7 @@ enum net_cfg_regs {
 enum if_cfg_regs {
   MAC_CONF1 = 0,
   MAC_CONF2 = 1,
+  NETWK_INF_CTRL3_REG = 0x7c,
   NETWK_INF_CTRL_REG = 0x7f
 };
 //
@@ -365,7 +366,12 @@ enum poe_cfg_reg {
   ERROR_LOG_WORD0 = 462, // TBI
   ERROR_INJ_CTL = 465, // TBI
   DIST_VEC_0_15 = 466, // TBI
+  LOCAL_FBP_BASE = 0x400,
+  MSG_STORAGE_BASE_ADR_L = 0x60,
+  FBP_BASE_ADR_L = 0x62,
 };
+#define EXT_FBP_START_ADDR       0x1800
+#define MAX_POE_EXT_MSG_STORAGE  (58 << 10) /* 58K entries */
 
 enum POE_SW_CODE {
 	DROP_IN_NAE = 0,
@@ -524,10 +530,10 @@ enum sys_cfg_regs {
 };
 
 #define nlm_hal_read_sys_reg(index) \
-	nlm_hal_read_32bit_reg(xlp_sys_base + 0x100, (index))
+	nlm_hal_read_32bit_reg((xlp_sys_base + 0x100), (index))
 
 #define nlm_hal_write_sys_reg(index, val) \
-	nlm_hal_write_32bit_reg(xlp_sys_base + 0x100, (index), (val))
+	nlm_hal_write_32bit_reg((xlp_sys_base + 0x100), (index), (val))
 
 enum {
 	PHYMODE_NONE = 0,
@@ -544,6 +550,7 @@ enum {
 	LM_IL = 3,
 };	
 
+#define MAX_GMAC_PORT			18
 #define MAX_CPLX_BLOCK                  5
 #define MAX_LANE_PER_CPLX               4
 
@@ -582,6 +589,11 @@ enum {
 #define LANE_CFG_CPLX_0_1               0x0
 #define LANE_CFG_CPLX_2_3               0x1
 #define LANE_CFG_CPLX_4                 0x2
+    #define LANE_CFG_LANE_0_POS         0
+    #define LANE_CFG_LANE_1_POS         4
+    #define LANE_CFG_LANE_2_POS         8
+    #define LANE_CFG_LANE_3_POS         12
+
     #define LANE_CFG_DISCONNECT         0
     #define LANE_CFG_GMAC               1
     #define LANE_CFG_XGMAC              2
@@ -784,12 +796,161 @@ enum {
     #define NETIOR_XGMAC_PHYADDR_POS    23
     #define NETIOR_XGMAC_DEVID_POS      18
     #define NETIOR_XGMAC_STATS_EN_POS   17
+    #define NETIOR_XGMAC_STATS_CLR_POS	16	
     #define NETIOR_XGMAC_TX_PFC_EN_POS  14
+    #define NETIOR_XGMAC_RX_PFC_EN_POS  13
     #define NETIOR_XGMAC_SOFT_RST_POS   11
     #define NETIOR_XGMAC_TX_PAUSE_POS   10
 
+#define NETIOR_XGMAC_CTRL2		0x7E
 #define NETIOR_XGMAC_CTRL3		0x7D
 
+#define MAC_ADDR0_LO			0x50
+#define MAC_ADDR0_HI			0x51
+#define MAC_FILTER_CONFIG		0x5c
+	#define MAC_FILTER_BCAST_EN_POS 	10
+	#define MAC_FILTER_MCAST_EN_POS		8
+	#define MAC_FILTER_ADDR0_VALID_POS 	0
+#define MAC_ADDR0_MASK_LO		0x58
+#define MAC_ADDR0_MASK_HI		0x59
+	
+// Interlaken Registers
+
+#define ILK_TX_CONTROL			0x00
+    #define ILK_TX_CTRL_RST_INF		0x80000000
+    #define ILK_TX_CTRL_RST_CORE	0x40000000
+    #define ILK_TX_CTRL_TXO		0x20000000
+    #define ILK_TX_CTRL_TXU		0x10000000
+    #define ILK_TX_CTRL_TXBE		0x08000000
+    #define ILK_TX_CTRL_DSW		0x00000200
+    #define ILK_TX_CTRL_BAD_LANE	0x00000100
+    #define ILK_TX_CTRL_RATELIM_EN	0x00000002
+    #define ILK_TX_CTRL_TX_EN		0x00000001
+    
+    #define ILK_TX_CTRL_FIFO_THR_POS	19
+    #define ILK_TX_CTRL_CAL_LEN_POS	15
+    #define ILK_TX_CTRL_BS_POS		12
+    #define ILK_TX_CTRL_BMAX_POS	10
+    #define ILK_TX_CTRL_BLS_POS		5
+    #define ILK_TX_CTRL_LLS_POS		2
+
+#define ILK_TX_RATE_LIMIT		0x01
+    #define ILK_TX_RATE_LIM_UI_POS	24
+    #define ILK_TX_RATE_LIM_DELTA_POS	12
+    #define ILK_TX_RATE_LIM_MTC_POS	0
+
+#define ILK_TX_META_CTRL		0x02
+    #define ILK_TX_META_CTRL_TXLEN_POS	16
+    #define ILK_TX_META_CTRL_RXLEN_POS	0
+
+#define ILK_RX_CONTROL			0x03
+    #define ILK_RX_CTRL_RST_CORE	0x00800000
+    #define ILK_RX_CTRL_BAD_LANE	0x00000004
+    #define ILK_RX_CTRL_FORCE_RESYNC	0x00000002
+    #define ILK_RX_CTRL_PKT_MODE	0x00000001
+
+    #define ILK_RX_CTRL_RST_LANE_POS	24
+    #define ILK_RX_CTRL_BMAX_POS	9
+    #define ILK_RX_CTRL_LLS_POS		6
+    #define ILK_RX_CTRL_BLS_POS		3
+
+#define ILK_RX_STATUS1			0x04
+    // All fields are RWC
+    #define ILK_RX_STAT1_MFS_POS	24
+    #define ILK_RX_STAT1_MFSE_POS	16
+    #define ILK_RX_STAT1_MFLE_POS	8
+    #define ILK_RX_STAT1_MFRE_POS	0
+
+#define ILK_RX_STATUS2			0x05
+    // All fields are RWC	
+    #define ILK_RX_STAT2_RDCV_POS	24
+    #define ILK_RX_STAT2_RDCE_POS	16
+    #define ILK_RX_STAT2_RDIS_POS	8
+    #define ILK_RX_STAT2_RDLS_POS	0	
+ 	
+#define ILK_GENERAL_CTRL1		0x06
+    #define ILK_GEN_CTRL1_RXBTE_POS	16
+    #define ILK_GEN_CTRL1_RXMBITS_POS	12	// PRM bug
+    #define ILK_GEN_CTRL1_RXFC_POS	8	// Bits 8..11 RXFC (This is not included in PRM)
+    #define ILK_GEN_CTRL1_TXMBITS_POS	0
+
+#define ILK_RX_STATUS3			0x07
+    #define ILK_RX_STAT3_CC_MAP		0x00080000
+    #define ILK_RX_STAT3_TIME_STAMP	0x00040000  //RWC
+    #define ILK_RX_STAT3_RXL_ALIGN	0x00020000
+    // Bits 16-0 RWC
+    #define ILK_RX_STAT3_WCRC_ERR	0x00010000
+    #define ILK_RX_STAT3_CWCRC_ERR	0x00008000
+    #define ILK_RX_STAT3_SS_ERR		0x00004000
+    #define ILK_RX_STAT3_MFLEN_ERR	0x00002000
+    #define ILK_RX_STAT3_MFRPT_ERR	0x00001000
+    #define ILK_RX_STAT3_WRDSYNC_ERR	0x00000800
+    #define ILK_RX_STAT3_MF_ERR		0x00000400
+    #define ILK_RX_STAT3_FRM_ERR	0x00000200
+    #define ILK_RX_STAT3_BADTYPE_ERR	0x00000100
+    #define ILK_RX_STAT3_SOP_ERR	0x00000080
+    #define ILK_RX_STAT3_EOP_ERR	0x00000040
+    #define ILK_RX_STAT3_LA_ERR		0x00000020
+    #define ILK_RX_STAT3_LM_ERR		0x00000010
+    #define ILK_RX_STAT3_BMAX_ERR	0x00000008
+    #define ILK_RX_STAT3_BURST_ERR	0x00000004
+    #define ILK_RX_STAT3_FIFO_OVF_ERR	0x00000002
+    #define ILK_RX_STAT3_OTHER_ERR	0x00000001
+
+#define ILK_RX_FC_TMAP0			0x08
+#define ILK_RX_FC_TMAP1			0x09
+#define ILK_RX_FC_TMAP2			0x0A
+#define ILK_RX_FC_TMAP3			0x0B
+#define ILK_RX_FC_TMAP4			0x0C
+
+#define ILK_RX_FC_TADDR			0x0D
+    #define ILK_RX_FC_RXMTUDROP_EN	0x40000000
+    #define ILK_RX_FC_REQ_VALID		0x00000020
+    #define ILK_RX_FC_WRITE_REQ		0x00000010
+
+    #define ILK_RX_FC_RXMTU_SIZE_POS	17  // size in 16byte words
+    #define ILK_RX_FC_TABLE_IDX_POS	0	
+
+#define ILK_GENERAL_CTRL2		0x0E
+    #define ILK_GEN_CTRL2_STATS_COR	0x40000000
+
+    #define ILK_GEN_CTRL2_SCS5_POS	25		    
+    #define ILK_GEN_CTRL2_SCS4_POS	20
+    #define ILK_GEN_CTRL2_SCS3_POS	15
+    #define ILK_GEN_CTRL2_SCS2_POS	10
+    #define ILK_GEN_CTRL2_SCS1_POS	5
+    #define ILK_GEN_CTRL2_SCS0_POS	0
+
+#define ILK_GENERAL_CTRL3		0x0F
+    #define ILK_GEN_CTRL3_LCS1_POS	17
+    #define ILK_GEN_CTRL3_LCS0_POS	14
+    #define ILK_GEN_CTRL3_MCS1_POS	12
+    #define ILK_GEN_CTRL3_MCS0_POS      10
+    #define ILK_GEN_CTRL3_SCS7_POS	5
+    #define ILK_GEN_CTRL3_SCS6_POS	0
+
+#define ILK_SMALL_COUNT0		0x10
+#define ILK_SMALL_COUNT1                0x11
+#define ILK_SMALL_COUNT2                0x12
+#define ILK_SMALL_COUNT3                0x13
+#define ILK_SMALL_COUNT4                0x14
+#define ILK_SMALL_COUNT5                0x15
+#define ILK_SMALL_COUNT6                0x16
+#define ILK_SMALL_COUNT7                0x17
+#define ILK_MID_COUNT0			0x18
+#define ILK_MID_COUNT1			0x19
+#define ILK_LARGE_COUNT_L0		0x1A
+#define ILK_LARGE_COUNT_L1              0x1B
+#define ILK_LARGE_COUNT_H0		0x1C
+#define ILK_LARGE_COUNT_H1              0x1D
+
+// Serdes Register
+#define SERDES_PRBS_CTRL		0x64
+    #define SERDES_LOOPBACK_EN		0x02
+
+#define ILK_BURST_MAX           	3 // 256 bytes   
+
+// SPI 
 #define XLP_SPI_CONFIG			0x40
     #define XLP_SPI_CPHA		0x01
     #define XLP_SPI_CPOL		0x02
diff --git a/arch/mips/include/asm/netlogic/xlp.h b/arch/mips/include/asm/netlogic/xlp.h
index 991a086..69f9ae7 100644
--- a/arch/mips/include/asm/netlogic/xlp.h
+++ b/arch/mips/include/asm/netlogic/xlp.h
@@ -48,8 +48,8 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #define XLP_REVISION_A2 	0x02
 
 #define MAX_CPU_REV_LEN		100
-#define NLM_MAX_CPU_NODE		1
 #define NLM_MAX_CPU_PER_NODE	32
+#define NLM_MAX_CPU_NODE	(CONFIG_NR_CPUS / NLM_MAX_CPU_PER_NODE)
 #define NLM_MAX_THREADS_PER_CPU	4
 #define NLM_MAX_VC_PER_THREAD	4
 
diff --git a/arch/mips/mm/cerr-nlm.c b/arch/mips/mm/cerr-nlm.c
index 699b994..0f7526a 100644
--- a/arch/mips/mm/cerr-nlm.c
+++ b/arch/mips/mm/cerr-nlm.c
@@ -27,6 +27,7 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #include <asm/system.h>
 
 #include <asm/netlogic/iomap.h>
+#include <asm/netlogic/mips-exts.h>
 
 unsigned char nlm_cerr_stack[8192];
 volatile int nlm_cerr_lock;
diff --git a/arch/mips/netlogic/common/Makefile b/arch/mips/netlogic/common/Makefile
new file mode 100644
index 0000000..22511e6
--- /dev/null
+++ b/arch/mips/netlogic/common/Makefile
@@ -0,0 +1,8 @@
+#EXTRA_CFLAGS := -Werror
+EXTRA_CFLAGS := $(CFLAGS) -DNLM_HAL_LINUX_KERNEL -Iarch/mips/include/asm/netlogic/hal
+obj-y :=   cpu_proc.o memory.o bootinfo.o
+
+obj-$(CONFIG_NLM_XLP)			+= nlm_hal_fmn_config.o
+obj-$(CONFIG_NLM_XLP)			+= nlm_hal.o nlm_hal_nae.o fdt_helper.o
+
+EXTRA_AFLAGS := $(CFLAGS)
diff --git a/arch/mips/netlogic/common/bootinfo.c b/arch/mips/netlogic/common/bootinfo.c
new file mode 100644
index 0000000..0619ab1
--- /dev/null
+++ b/arch/mips/netlogic/common/bootinfo.c
@@ -0,0 +1,24 @@
+
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. ("Netlogic").
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
+
+*****************************#NETL_1#********************************/
+
+#include <linux/kernel.h>
+#include <asm/bootinfo.h>
+#include <asm/netlogic/bootinfo.h>
+
+void copy_mem_map(struct boot_mem_map *dst, struct nlm_boot_mem_map *src)
+{
+	int i;
+
+	dst->nr_map = src->nr_map;
+	for(i=0; i < dst->nr_map; i++) {
+		dst->map[i].addr = (phys_t)src->map[i].addr;
+		dst->map[i].size = (phys_t)src->map[i].size;
+		dst->map[i].type = (long)src->map[i].type;
+	}
+}
diff --git a/arch/mips/netlogic/common/cpu_proc.c b/arch/mips/netlogic/common/cpu_proc.c
new file mode 100644
index 0000000..60957b6
--- /dev/null
+++ b/arch/mips/netlogic/common/cpu_proc.c
@@ -0,0 +1,223 @@
+/***********************************************************************
+ * Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+ * reserved.
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ * *****************************#NETL_2#********************************/
+
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/poll.h>
+#include <linux/workqueue.h>
+#include <linux/proc_fs.h>
+#include <linux/cpumask.h>
+
+#include <asm/netlogic/proc.h>
+#include <asm/mach-netlogic/mmu.h>
+#include <asm/time.h>
+
+extern struct proc_dir_entry *nlm_root_proc;
+
+#ifndef CONFIG_BTLB_LOADER
+extern void nlm_update_tlb_stats(void *ignored);
+#endif
+
+struct nlm_cpu_stat {
+	unsigned long long msgring_pic_int;
+	unsigned long long msgring_int;
+	unsigned long long msgring_cycles;
+	unsigned long long fp_exp;
+	unsigned long long rdhwr_exp;
+};
+
+struct nlm_cpu_stat nlm_cpu_stats[NR_CPUS];
+__u64 nlm_cp2_exceptions[NR_CPUS];
+
+extern unsigned long long nlm_common_tlb_stats[];
+
+
+void nlm_cpu_stat_update_rdhwr(void)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	nlm_cpu_stats[cpu].rdhwr_exp++;
+
+	preempt_enable();
+}
+
+void nlm_cpu_stat_update_fp(void)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	nlm_cpu_stats[cpu].fp_exp++;
+
+	preempt_enable();
+}
+
+void nlm_cpu_stat_update_msgring_int(void)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	nlm_cpu_stats[cpu].msgring_int++;
+
+	preempt_enable();
+}
+
+void nlm_cpu_stat_update_msgring_cycles(__u32 cycles)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	nlm_cpu_stats[cpu].msgring_cycles += cycles;
+
+	preempt_enable();
+}
+
+void nlm_cpu_stat_update_msgring_pic_int(void)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	nlm_cpu_stats[cpu].msgring_pic_int++;
+
+	preempt_enable();
+}
+
+static int nlm_cpu_proc_read(char *page, char **start, off_t off,
+			     int count, int *eof, void *data)
+{
+	int i = 0;
+	int len = 0;
+	off_t begin = 0;
+
+#ifndef CONFIG_BTLB_LOADER
+	/* Update the TLB stats from other CPUs */
+	on_each_cpu(nlm_update_tlb_stats, NULL, 1);
+#endif
+
+	len += sprintf(page + len, "CPU Frequency: %u HZ\n", (unsigned int)mips_hpt_frequency);
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	for(i=0;i<32;i++) {
+
+		if (!nlm_cp2_exceptions[i]) continue;
+
+			len += sprintf(page + len,
+				       "cop2_exp: %03d 0x%016llx\n",
+				       i, (unsigned long long)nlm_cp2_exceptions[i]);
+			if (!proc_pos_check(&begin, &len, off, count))
+				goto out;
+	}
+
+	for(i=0;i<32;i++) {
+
+		if (!nlm_cpu_stats[i].msgring_pic_int && !nlm_cpu_stats[i].msgring_int)
+			continue;
+
+			len += sprintf(page + len,
+				       "msgring: %03d 0x%016llx 0x%016llx 0x%016llx\n",
+				       i, nlm_cpu_stats[i].msgring_pic_int,
+				       nlm_cpu_stats[i].msgring_int,
+				       nlm_cpu_stats[i].msgring_cycles);
+			if (!proc_pos_check(&begin, &len, off, count))
+				goto out;
+	}
+
+	for(i=0;i<32;i++) {
+
+		if (!nlm_cpu_stats[i].fp_exp && !nlm_cpu_stats[i].rdhwr_exp)
+			continue;
+
+			len += sprintf(page + len,
+				       "cpu_exp: %03d 0x%016llx 0x%016llx\n",
+				       i, nlm_cpu_stats[i].fp_exp,
+				       nlm_cpu_stats[i].rdhwr_exp);
+			if (!proc_pos_check(&begin, &len, off, count))
+				goto out;
+	}
+
+	for (i = 0; i < 32; i++) {
+
+		if (!nlm_common_tlb_stats[i])
+			continue;
+
+		len += sprintf(page + len,
+			       "tlb: %03d 0x%016llx \n",
+			       i, nlm_common_tlb_stats[i]);
+		if (!proc_pos_check(&begin, &len, off, count))
+			goto out;
+	}
+
+	*eof = 1;
+
+      out:
+	*start = page + (off - begin);
+	len -= (off - begin);
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+
+	return len;
+}
+
+static int nlm_cpu_proc_init(void)
+{
+	struct proc_dir_entry *entry;
+#ifdef CONFIG_NLM_XLP
+	entry = create_proc_read_entry("xlp_cpu", 0 /* def mode */ ,
+				       nlm_root_proc/* parent */ ,
+				       nlm_cpu_proc_read
+				       /* proc read function */ ,
+				       0	/* no client data */
+		);
+#endif
+	if (!entry) {
+		printk("[%s]: Unable to create proc read entry for cpu!\n",
+		       __FUNCTION__);
+	}
+
+	return 0;
+}
+
+static void nlm_cpu_proc_exit(void)
+{
+}
+
+module_init(nlm_cpu_proc_init);
+module_exit(nlm_cpu_proc_exit);
diff --git a/arch/mips/netlogic/common/dma.c b/arch/mips/netlogic/common/dma.c
new file mode 100644
index 0000000..e9ca364
--- /dev/null
+++ b/arch/mips/netlogic/common/dma.c
@@ -0,0 +1,601 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/delay.h>
+
+#include <asm/io.h>
+#include <asm/mipsregs.h>
+#include <asm/netlogic/msgring.h>
+#include <asm/netlogic/iomap.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/debug.h>
+
+#define CH0_CONTROL 8
+#define MSGRNG_CODE_DMA 8
+#define XLR_DMA_RESP_TIMEOUT 500
+#define MAX_DMA_QUEUE_LEN 256
+#define PCIX_ACK_TIMER_VAL 0x18
+
+#define MAX_DMA_TRANS_PER_CPU 256
+#define XLR_MAX_DMA_LEN_PER_DESC ((1 << 20) - 1)	/* 1 MB - 1 */
+
+#define NEXT_SEQ_NUM(x) ((x->sequence_number + 1) & (MAX_DMA_TRANS_PER_CPU - 1))
+#define INC_SEQ_NUM(x) x->sequence_number = \
+		((x->sequence_number + 1) & (MAX_DMA_TRANS_PER_CPU - 1))
+
+#define DMA_SLOT_BUSY(x) (x->trans[x->sequence_number].pending)
+
+#define DMA_RESP_PENDING(x, seq) (x->trans[seq].pending)
+
+#define DMA_SLOT_GET(x) (x->trans[x->sequence_number].pending = 1); \
+				INC_SEQ_NUM(ctrl);
+
+#define DMA_SLOT_PUT(x, seq) (x->trans[seq].pending = 0)
+
+#define DMA_GET_RESP(x, seq) (x->trans[seq].dma_resp)
+
+#define DMA_PUT_RESP(x, seq, msg) x->trans[seq].dma_resp = msg; \
+				x->trans[seq].pending = 0;
+
+#define DMA_DONE(x, seq) (x->trans[seq].pending == 0)
+
+#define Message(a,b...)		//printk("\n[%s] - "a"\n",__FUNCTION__,##b)
+#define ErrorMsg(a,b...) printk("\nError in [%s] - "a"\n",__FUNCTION__,##b)
+enum dma_msgring_bucket_config {
+
+	DMA_MSG_BUCKET0_SIZE = 0x320,
+	DMA_MSG_BUCKET1_SIZE,
+	DMA_MSG_BUCKET2_SIZE,
+	DMA_MSG_BUCKET3_SIZE,
+};
+
+enum dma_msgring_credit_config {
+
+	DMA_CC_CPU0_0 = 0x380,
+	DMA_CC_CPU1_0 = 0x388,
+	DMA_CC_CPU2_0 = 0x390,
+	DMA_CC_CPU3_0 = 0x398,
+	DMA_CC_CPU4_0 = 0x3a0,
+	DMA_CC_CPU5_0 = 0x3a8,
+	DMA_CC_CPU6_0 = 0x3b0,
+	DMA_CC_CPU7_0 = 0x3b8
+};
+
+/* We use 10 bit transaction id in the DMA message to uniquely identify a DMA
+   response.
+   0-7 indicate a sequence number (0 to 255)
+   8-9 bits encode the CPU thread id (0 to 3)
+   */
+typedef struct dma_trans {
+	volatile int pending;
+	uint64_t dma_resp;
+	void (*func) (void *, uint64_t);
+	void *data;
+} dma_trans_t;
+
+typedef struct xlr_dma_ctrl {
+	spinlock_t q_lock;
+	int sequence_number;
+	dma_trans_t trans[MAX_DMA_TRANS_PER_CPU];
+} xlr_dma_ctrl_t;
+
+volatile static int xlr_dma_producer = 0;
+volatile static int xlr_dma_consumer = 0;
+struct msgrng_msg xlr_dma_queue[MAX_DMA_QUEUE_LEN];
+static int xlr_dma_init_done = 0;
+xlr_dma_ctrl_t xlr_dma_ctrl[NR_CPUS];
+
+spinlock_t xlr_dma_lock = SPIN_LOCK_UNLOCKED;
+spinlock_t xlr_enqueue_dma_spin = SPIN_LOCK_UNLOCKED;
+uint32_t xlr_total_dma_reqs, xlr_total_dma_bytes;
+uint32_t xlr_dma_req_failed, xlr_dma_timeout_errors, xlr_dma_errors,
+    xlr_dma_stale_resp;
+uint32_t xlr_dma_msg_send_failed;
+
+void xlr_async_dma_task(unsigned long data);
+extern unsigned int nlm_common_get_shared_mem_base(void);
+#define CONFIG_PROC_FS 1
+#ifdef CONFIG_PROC_FS
+#include <linux/proc_fs.h>
+
+extern int xlr_loader_own_dma;
+extern struct proc_dir_entry *nlm_root_proc;
+
+static int xlr_dma_proc_read(char *page, char **start, off_t off,
+			     int count, int *eof, void *data)
+{
+	int len, total_len;
+	char *ptr = page;
+
+	if (count < 512)	/* Need minimum of this space */
+		return -EINVAL;
+
+	total_len = 0;
+	len = sprintf(ptr, "Total DMA Requests = %d\n", xlr_total_dma_reqs);
+	ptr += len;
+	total_len += len;
+
+	len = sprintf(ptr, "Total DMA Bytes = %d\n", xlr_total_dma_bytes);
+	ptr += len;
+	total_len += len;
+
+	len = sprintf(ptr, "DMA Requests failed = %d\n", xlr_dma_req_failed);
+	ptr += len;
+	total_len += len;
+
+	len = sprintf(ptr, "DMA Timeout errors = %d\n", xlr_dma_timeout_errors);
+	ptr += len;
+	total_len += len;
+
+	len = sprintf(ptr, "DMA errors = %d\n", xlr_dma_errors);
+	ptr += len;
+	total_len += len;
+
+	len = sprintf(ptr, "DMA Stale responses = %d\n", xlr_dma_stale_resp);
+	total_len += len;
+
+	len = sprintf(ptr, "DMA Message Send Failed = %d\n",
+		      xlr_dma_msg_send_failed);
+	total_len += len;
+
+	return total_len;
+}
+void xlr_init_dma_proc(void)
+{
+	struct proc_dir_entry *entry;
+
+	if (!(entry = create_proc_entry("xlr_dma_stats", 0444, nlm_root_proc))) {
+		printk("%s: create_proc_entry failed\n", __FUNCTION__);
+		return;
+	}
+	entry->read_proc = xlr_dma_proc_read;
+
+}
+void xlr_uninit_dma_proc(void)
+{
+	remove_proc_entry("xlr_dma_stat", nlm_root_proc);
+}
+#endif
+
+/* DMA message handler - Called from interrupt context */
+static void xlr_dma_msgring_handler(int bucket, int size, int code,
+				    int stid, struct msgrng_msg *msg,
+				    void *data /* ignored */ )
+{
+	int cpu, thr_id, tx_id, seq;
+	xlr_dma_ctrl_t *ctrl;
+
+	tx_id = (msg->msg0 >> 48) & 0x3ff;
+	thr_id = (tx_id >> 8) & 0x3;
+	seq = (tx_id & 0xff);
+
+	cpu = (netlogic_cpu_id() * 4) + thr_id;
+	ctrl = &xlr_dma_ctrl[cpu];
+
+	spin_lock(&ctrl->q_lock);
+	/* Check if there was a pending request. This can happen if the
+	   requestor times out and gives up the request. So in that case
+	   do not update the response
+	   NOTE: One corner case that is not handled here is that when seq no
+	   wraps around and request was pending for the new one and this response
+	   was for the old request. This ideally must not happen.
+	 */
+	if (DMA_RESP_PENDING(ctrl, seq)) {
+
+		DMA_PUT_RESP(ctrl, seq, msg->msg0);
+		if (ctrl->trans[seq].func) {
+			ctrl->trans[seq].func(ctrl->trans[seq].data, msg->msg0);
+		}
+		spin_unlock(&ctrl->q_lock);
+		return;
+	}
+	spin_unlock(&ctrl->q_lock);
+	printk("ERROR: Stale response from DMA engine for transaction id %d\n",
+	       seq);
+	spin_lock(&xlr_dma_lock);
+	xlr_dma_stale_resp++;
+	spin_unlock(&xlr_dma_lock);
+	return;
+}
+
+inline void xlr_build_xfer_msg(struct msgrng_msg *msg, uint64_t src,
+			       uint64_t dest, uint32_t len, int tx_id,
+			       int resp_bkt)
+{
+	msg->msg0 = (1ULL << 63) | ((uint64_t) len << 40) |
+	    (src & 0xffffffffffULL);
+	msg->msg1 = (1ULL << 58) | ((uint64_t) tx_id << 48) |
+	    ((uint64_t) resp_bkt << 40) | (dest & 0xffffffffffull);
+
+}
+
+int xlr_enqueue_dma_msg(struct msgrng_msg *msg)
+{
+	unsigned long mflags;
+	spin_lock_irqsave(&xlr_enqueue_dma_spin, mflags);
+	if (((xlr_dma_producer + 1) % (MAX_DMA_QUEUE_LEN)) == xlr_dma_consumer) {
+		//ErrorMsg("DMA Async Queue is full");
+		spin_unlock_irqrestore(&xlr_enqueue_dma_spin, mflags);
+		return -ENOMEM;
+	}
+	//Enqueue Msg 
+	xlr_dma_queue[xlr_dma_producer].msg0 = msg->msg0;
+	xlr_dma_queue[xlr_dma_producer].msg1 = msg->msg1;
+	xlr_dma_queue[xlr_dma_producer].msg2 = 0ULL;
+	xlr_dma_queue[xlr_dma_producer].msg3 = 0ULL;
+	xlr_dma_producer = (xlr_dma_producer + 1) % (MAX_DMA_QUEUE_LEN);
+	spin_unlock_irqrestore(&xlr_enqueue_dma_spin, mflags);
+	return 0;
+}
+
+DECLARE_TASKLET(xlr_dma_task, xlr_async_dma_task, 0);
+void xlr_async_dma_task(unsigned long data)
+{
+	unsigned long flags = 0;
+	int data_len;
+	uint64_t phys1, phys2;
+	struct msgrng_msg *msg;
+	static int last_msg_send_success = 1;
+	int msg_send_success = 0;
+
+	while ((xlr_dma_consumer != xlr_dma_producer)) {
+
+		msg = &xlr_dma_queue[xlr_dma_consumer];
+		phys1 = msg->msg0 & 0xffffffffffULL;	//DEST
+		phys2 = msg->msg1 & 0xffffffffffULL;	//SRC
+		data_len = (msg->msg0 >> 40) & 0xfffff;
+		msgrng_access_enable(flags);
+		if (xlr_dma_consumer == xlr_dma_producer) {
+			ErrorMsg("Shdnt Happen.");
+		}
+		if (message_send_retry(2, MSGRNG_CODE_DMA, MSGRNG_STNID_DMA_0,
+				       &xlr_dma_queue[xlr_dma_consumer])) {
+			xlr_dma_msg_send_failed++;
+			msgrng_access_disable(flags);
+			last_msg_send_success = 1;
+			msg_send_success = 0;
+			tasklet_schedule(&xlr_dma_task);
+			break;
+		}
+
+		msg_send_success = 1;
+		last_msg_send_success = 1;
+		xlr_dma_consumer = (xlr_dma_consumer + 1) % (MAX_DMA_QUEUE_LEN);
+		msgrng_access_disable(flags);
+	}
+
+}
+
+/* Returns 0 on success, -1 otherwise */
+int xlr_async_request_dma(uint64_t src, uint64_t dest, uint32_t len,
+			  void (*func) (void *, uint64_t), void *data)
+{
+	int thr_id, cpu;
+	xlr_dma_ctrl_t *ctrl;
+	int tx_id, resp_bkt, seq;
+	struct msgrng_msg msg;
+	unsigned long flags;
+
+	/* Driver does not support multiple descriptor DMA yet */
+	if (len > XLR_MAX_DMA_LEN_PER_DESC) {
+		ErrorMsg("%s: Cannot do DMA for more than %d bytes\n",
+			 __FUNCTION__, XLR_MAX_DMA_LEN_PER_DESC);
+		return -1;
+	}
+	if (xlr_dma_init_done == 0) {
+		ErrorMsg("%s: XLR DMA engine is not initialized\n",
+			 __FUNCTION__);
+		return -1;
+	}
+	Message("\nSrc Addr %#llx Dst Addr %#llx\n", src, dest);
+
+	preempt_disable();
+	thr_id = netlogic_thr_id();
+	cpu = (netlogic_cpu_id() * 4) + thr_id;
+	ctrl = &xlr_dma_ctrl[cpu];
+
+	spin_lock_irqsave(&ctrl->q_lock, flags);
+	preempt_enable();
+
+	if (DMA_SLOT_BUSY(ctrl)) {
+		//ErrorMsg("%s: No space to enqueue this request\n", __FUNCTION__);
+		spin_unlock_irqrestore(&ctrl->q_lock, flags);
+		return -1;
+	}
+	tx_id = (thr_id << 8) | ctrl->sequence_number;
+	seq = ctrl->sequence_number;
+	DMA_SLOT_GET(ctrl);
+
+	/* use bucket 0 of each core as the bucket where response will be 
+	   received
+	 */
+	resp_bkt = netlogic_cpu_id() * 8;
+
+	spin_unlock_irqrestore(&ctrl->q_lock, flags);
+
+	/*CallBack For Async Call. */
+	ctrl->trans[seq].func = func;
+	ctrl->trans[seq].data = data;
+
+	/* Form the DMA simple xfer request and send to Channel 0 */
+
+	xlr_build_xfer_msg(&msg, src, dest, len, tx_id, resp_bkt);
+
+	if (xlr_enqueue_dma_msg(&msg)) {
+		//ErrorMsg("Cant Enqueue Msg.");
+		spin_lock_irqsave(&ctrl->q_lock, flags);
+		DMA_SLOT_PUT(ctrl, seq);
+		spin_unlock_irqrestore(&ctrl->q_lock, flags);
+		tasklet_schedule(&xlr_dma_task);
+		return -1;
+	}
+	tasklet_schedule(&xlr_dma_task);
+	return 0;
+}
+
+/* Returns 0 on success, -1 otherwise */
+int xlr_request_dma(uint64_t src, uint64_t dest, uint32_t len)
+{
+	int thr_id, cpu, i;
+	xlr_dma_ctrl_t *ctrl;
+	int tx_id, resp_bkt, seq, ret, err;
+	struct msgrng_msg  msg = {0}, r_msg = {0};
+	unsigned long flags;
+
+	/* Driver does not support multiple descriptor DMA yet */
+	if (len > XLR_MAX_DMA_LEN_PER_DESC) {
+		printk("%s: Cannot do DMA for more than %d bytes\n",
+		       __FUNCTION__, XLR_MAX_DMA_LEN_PER_DESC);
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_req_failed++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+	if (xlr_dma_init_done == 0) {
+		printk("%s: XLR DMA engine is not initialized\n", __FUNCTION__);
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_req_failed++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+
+	preempt_disable();
+	thr_id = netlogic_thr_id();
+	cpu = (netlogic_cpu_id() * 4) + thr_id;
+	ctrl = &xlr_dma_ctrl[cpu];
+
+	spin_lock_irqsave(&ctrl->q_lock, flags);
+	preempt_enable();	/* will not enable actually */
+	if (DMA_SLOT_BUSY(ctrl)) {
+		printk("%s: No space to enqueue this request\n", __FUNCTION__);
+		spin_unlock_irqrestore(&ctrl->q_lock, flags);
+
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_req_failed++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+	tx_id = (thr_id << 8) | ctrl->sequence_number;
+	seq = ctrl->sequence_number;
+	DMA_SLOT_GET(ctrl);
+
+	/* use bucket 0 of each core as the bucket where response will be 
+	   received
+	 */
+	resp_bkt = netlogic_cpu_id() * 8;
+	spin_unlock_irqrestore(&ctrl->q_lock, flags);
+
+	/*Reset Callback - As this is not async call */
+	ctrl->trans[seq].func = NULL;
+	ctrl->trans[seq].data = NULL;
+
+	/* Form the DMA simple xfer request and send to Channel 0 */
+	xlr_build_xfer_msg(&msg, src, dest, len, tx_id, resp_bkt);
+	msgrng_access_enable(flags);
+	if (message_send_retry(2, MSGRNG_CODE_DMA, MSGRNG_STNID_DMA_0, &msg)) {
+		printk
+		    ("Message_send failed: Cannot submit DMA request to engine\n");
+		msgrng_access_disable(flags);
+		spin_lock_irqsave(&ctrl->q_lock, flags);
+		DMA_SLOT_PUT(ctrl, seq);
+		spin_unlock_irqrestore(&ctrl->q_lock, flags);
+
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_req_failed++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+	msgrng_access_disable(flags);
+	/* wait for the response here */
+	for (i = 0; i < XLR_DMA_RESP_TIMEOUT; i++) {
+		if (DMA_DONE(ctrl, seq))
+			break;
+		udelay(50);
+	}
+	if (i == XLR_DMA_RESP_TIMEOUT) {
+		printk("%s:Did not get response from DMA engine\n",
+		       __FUNCTION__);
+		spin_lock_irqsave(&ctrl->q_lock, flags);
+		DMA_SLOT_PUT(ctrl, seq);
+		spin_unlock_irqrestore(&ctrl->q_lock, flags);
+
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_timeout_errors++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+	/* Do some error checks */
+
+	r_msg.msg0 = DMA_GET_RESP(ctrl, seq);
+	ret = (r_msg.msg0 >> 62) & 0x3;
+	err = (r_msg.msg0 >> 60) & 0x3;
+	if (ret != 0x3) {
+		printk("%s: Bad return code %d from DMA engine\n", __FUNCTION__,
+		       ret);
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_errors++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+	if (err & 0x2) {
+		printk("%s:DMA engine reported Message format error\n",
+		       __FUNCTION__);
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_errors++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+	if (err & 0x1) {
+		printk("%s:DMA engine reported Bus error\n", __FUNCTION__);
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_errors++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+
+		return -1;
+	}
+	spin_lock_irqsave(&xlr_dma_lock, flags);
+	xlr_total_dma_reqs++;
+	xlr_total_dma_bytes += len;
+	spin_unlock_irqrestore(&xlr_dma_lock, flags);
+	return 0;
+}
+
+int xlr_init_dma(void)
+{
+	int i;
+	nlm_reg_t *mmio = netlogic_io_mmio(0x1A000);
+	xlr_dma_ctrl_t *ctrl;
+#ifdef NLM_BRIDGE_WKAROUND
+	unsigned int flags=0;
+#endif
+
+	for (i = 0; i < NR_CPUS; i++) {
+		ctrl = &xlr_dma_ctrl[i];
+		spin_lock_init(&ctrl->q_lock);
+		ctrl->sequence_number = 0;
+	}
+	/* Register for the Message ring handler */
+	if (register_msgring_handler(TX_STN_DMA, xlr_dma_msgring_handler, NULL)) {
+		printk("Couldn't register DMA msgring handler\n");
+		return -1;
+	}
+#ifdef NLM_BRIDGE_WKAROUND
+	if (nlm_enable_br_wrkaround) {
+		flags = nlm_write_lock_irq_save(nlm_bridge_lock);
+	}
+#endif
+	/* Use channel 0 for all DMA */
+	/* Pci Stream Hint En = 1, Report Error = 1, Section Size = 4, 
+	 * RMaxCr=4, WMaxCr =4, En=1; */
+	mmio[CH0_CONTROL] = (1 << 28) | (1 << 24) | (4 << 12) | (4 << 8) |
+	    (4 << 5) | (1 << 4);
+	mmio[PCIX_ACK_TIMER_VAL] = 100;
+	/* Configure the bucket sizes */
+	if (xlr_loader_own_dma) {
+		mmio[DMA_MSG_BUCKET0_SIZE] =
+		    shared_bucket_sizes.bucket[MSGRNG_STNID_DMA_0];
+		mmio[DMA_MSG_BUCKET1_SIZE] =
+		    shared_bucket_sizes.bucket[MSGRNG_STNID_DMA_1];
+		mmio[DMA_MSG_BUCKET2_SIZE] =
+		    shared_bucket_sizes.bucket[MSGRNG_STNID_DMA_2];
+		mmio[DMA_MSG_BUCKET3_SIZE] =
+		    shared_bucket_sizes.bucket[MSGRNG_STNID_DMA_3];
+
+		/* Configure the DMA credits */
+		for (i = 0; i < 128; i++) {
+			mmio[DMA_CC_CPU0_0 + i] =
+			    shared_cc_table_dma.counters[i >> 3][i & 0x07];
+		}
+	} else {
+		mmio[DMA_MSG_BUCKET0_SIZE] =
+		    bucket_sizes.bucket[MSGRNG_STNID_DMA_0];
+		mmio[DMA_MSG_BUCKET1_SIZE] =
+		    bucket_sizes.bucket[MSGRNG_STNID_DMA_1];
+		mmio[DMA_MSG_BUCKET2_SIZE] =
+		    bucket_sizes.bucket[MSGRNG_STNID_DMA_2];
+		mmio[DMA_MSG_BUCKET3_SIZE] =
+		    bucket_sizes.bucket[MSGRNG_STNID_DMA_3];
+
+		/* Configure the DMA credits */
+		for (i = 0; i < 128; i++) {
+			mmio[DMA_CC_CPU0_0 + i] =
+			    cc_table_dma.counters[i >> 3][i & 0x07];
+		}
+	}
+#ifdef NLM_BRIDGE_WKAROUND
+	if (nlm_enable_br_wrkaround) {
+		nlm_write_unlock_irq_restore(nlm_bridge_lock, flags);
+	}
+#endif
+#ifdef CONFIG_PROC_FS
+	xlr_init_dma_proc();
+#endif
+	xlr_dma_init_done = 1;
+	printk("Initialized XLR DMA Controller, Channel 0 \n");
+	tasklet_schedule(&xlr_dma_task);
+	return 0;
+}
+
+#ifdef TEST_DMA
+void xlr_dma_test(void)
+{
+	int i;
+	uint8_t *ptr1, *ptr2;
+	unsigned long s_jiffy, e_jiffy;
+
+	ptr1 = (uint8_t *) kmalloc(0x1000, GFP_KERNEL);
+	ptr2 = (uint8_t *) kmalloc(0x1000, GFP_KERNEL);
+	if (!ptr1 || !ptr2) {
+		if (ptr1)
+			kfree(ptr1);
+		if (ptr2)
+			kfree(ptr2);
+
+		printk("DMA test buffer alloc failed\n");
+		return;
+	}
+	memset(ptr1, 0xa5, 0x1000);
+	s_jiffy = read_c0_count();
+	for (i = 0; i < 512; i++) {
+		xlr_request_dma((uint64_t) virt_to_phys(ptr1),
+				(uint64_t) virt_to_phys(ptr2), 0x1000);
+	}
+	e_jiffy = read_c0_count();
+	if (memcmp(ptr1, ptr2, 0x1000)) {
+		printk("DMA Data does not match. Test failed\n");
+	} else
+		printk("DMA Data Matches. Test Successful\n");
+
+	printk("Start time = %lx end time = %lx\n", s_jiffy, e_jiffy);
+	kfree(ptr1);
+	kfree(ptr2);
+}
+#endif
+EXPORT_SYMBOL(xlr_request_dma);
diff --git a/arch/mips/netlogic/common/fdt_helper.c b/arch/mips/netlogic/common/fdt_helper.c
new file mode 100644
index 0000000..6bb929e
--- /dev/null
+++ b/arch/mips/netlogic/common/fdt_helper.c
@@ -0,0 +1,158 @@
+/*************************************************************************
+ Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+ reserved.
+ Redistribution and use in source and binary forms, with or without
+ modification, are permitted provided that the following conditions are
+ met:
+ 1. Redistributions of source code must retain the above copyright
+    notice, this list of conditions and the following disclaimer.
+ 2. Redistributions in binary form must reproduce the above copyright
+    notice, this list of conditions and the following disclaimer in
+    the documentation and/or other materials provided with the
+    distribution.
+ THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE
+ LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ THE POSSIBILITY OF SUCH DAMAGE.
+*******************************#NETL_2#**********************************/
+#if defined(__KERNEL__)
+#include <linux/kernel.h>
+
+#else
+#include <stdio.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <unistd.h>
+#if !defined(NLM_HAL_NETLBOOT) && !defined(NLM_HAL_NETOS)
+#include <sys/mman.h>
+#endif
+#endif
+
+#include "libfdt.h"
+#include "fdt_helper.h"
+
+static int fdt_helper_print  = 1;
+
+#if !defined(__KERNEL__)
+#define fdtprint(x...) do {   \
+	if (fdt_helper_print) \
+		printf(x);    \
+} while (0)
+#else
+#define fdtprint(x...) do {   \
+	if (fdt_helper_print) \
+		printk(x);    \
+} while (0)
+#endif
+
+int set_fdt_helper_print(int val)
+{
+	int old_val = fdt_helper_print;
+	fdt_helper_print = val;
+	return old_val;
+}
+
+#if !defined(__KERNEL__) && !defined(NLM_HAL_NETOS) && !defined(NLM_HAL_NETLBOOT)
+void *open_fdt(int fd)
+{
+	struct stat st;
+	if (fstat(fd, &st) < 0) {
+		perror("fstat");
+		return NULL;
+	}
+
+	void *fdt;
+	fdt = mmap(NULL, st.st_size, PROT_READ, MAP_PRIVATE, fd, 0);
+	if (fdt == MAP_FAILED) {
+		perror("mmap");
+		return NULL;
+	}
+	return fdt;
+}
+#else
+void *open_fdt(int fd) { return NULL; }
+#endif
+
+#define DEBUG
+
+static void print_fdt_prop(const char *path, const char *prop,
+	enum prop_type type, const void *buf, int len)
+{
+#ifdef DEBUG
+	fdtprint("FDT: parsed %s.%s: ", path, prop);
+	if (type == PROP_CELL) {
+		const uint32_t *dst = (const uint32_t *)buf;
+		int cells = len / sizeof(uint32_t);
+		int i;
+
+		fdtprint("cells=%d val=", cells);
+		for (i = 0; i < cells; i++) {
+			fdtprint("0x%x(%d),", dst[i], dst[i]);
+		}
+	}
+	else {
+		fdtprint("len=%d val=%s", len, (const char *)buf);
+	}
+	fdtprint("\n");
+#endif
+}
+
+int copy_fdt_prop(void *fdt, const char *path, const char *prop,
+	enum prop_type type, void *buf, int len)
+{
+	int nodeoffset;
+	const void *pval;
+	int plen;
+	int copylen;
+
+	if (len <= 0)  {
+		fdtprint("Warning: Len is 0 while copying %s/%s\n", path, prop);
+		return -1;
+	}
+
+	nodeoffset = fdt_path_offset(fdt, path);
+	if (nodeoffset < 0) {
+		fdtprint("%s: Failed to parse path %s\n",
+		         fdt_strerror(nodeoffset), path);
+		return nodeoffset;
+	}
+
+	pval = fdt_getprop(fdt, nodeoffset, prop, &plen);
+	if (pval == NULL) {
+		fdtprint("%s: Failed to parse property %s\n",
+		         fdt_strerror(plen), prop);
+		return plen;
+	}
+
+	if (plen > len) {
+		fdtprint("WARNING: buf of %d is insufficient to store %d (%s/%s)\n",
+		         len, plen, path, prop);
+		copylen = len;
+	}
+	else {
+		copylen = plen;
+	}
+
+	if (type == PROP_CELL) {
+		const uint32_t *src = (const uint32_t *)pval;
+		uint32_t *dst = (uint32_t *)buf;
+		int i;
+		for (i = 0; i < copylen / sizeof(uint32_t); i++) {
+			dst[i] = fdt32_to_cpu(src[i]);
+		}
+	}
+	else {
+		memcpy(buf, pval, copylen);
+	}
+
+ 	print_fdt_prop(path, prop, type, buf, copylen); 
+
+	return copylen;
+}
diff --git a/arch/mips/netlogic/common/memory.c b/arch/mips/netlogic/common/memory.c
new file mode 100644
index 0000000..f3d1b53
--- /dev/null
+++ b/arch/mips/netlogic/common/memory.c
@@ -0,0 +1,218 @@
+/***********************************************************************
+ * Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+ * reserved.
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ * *****************************#NETL_2#********************************/
+
+#include <linux/fs.h>
+#include <linux/fcntl.h>
+#include <linux/irqflags.h>
+#include <asm/mipsregs.h>
+#include <asm/page.h>
+#include <asm/mach-netlogic/mmu.h>
+
+/*
+ * the following structures and definitions are internal to this
+ * file and hence not defined in a header file
+ */
+typedef struct
+{
+	unsigned int size;
+	unsigned int mask;
+} tlbparam_t;
+
+tlbparam_t mipstlbs[] = 
+{ {  4 << 10,    0x0},
+  { 16 << 10,    0x3},
+  { 64 << 10,    0xf},
+  {256 << 10,   0x3f},
+  {  1 << 20,   0xff},
+  {  4 << 20,  0x3ff},
+  { 16 << 20,  0xfff},
+  { 64 << 20, 0x3fff},
+  {256 << 20, 0xffff},
+};
+
+#define NTLB (sizeof(mipstlbs)/sizeof(tlbparam_t))
+#define ULL unsigned long long
+#define PCIDEV_ADDRSPACE_START (0x3ULL << 30)
+
+static uint32_t align_size(uint32_t size)
+{
+	int i;
+
+	for (i = 0; (i < NTLB - 1) && (size > mipstlbs[i].size); ++i)
+		;
+	return mipstlbs[i].size;
+}
+
+static uint32_t tlb_mask(uint32_t size)
+{
+	int i;
+
+	size = align_size(size);
+
+	for (i = 0; i < NTLB && mipstlbs[i].size != size; ++i)
+		;
+	return mipstlbs[i].mask;
+}
+
+#define entrylo(paddr, attr) \
+	((((paddr & 0xffffffffffULL) >> 12) << 6) | (attr))
+
+
+/*
+ * External Function / APIs
+ */
+
+void setup_tlb(tlb_info_t *tlb)
+{
+	write_c0_pagemask(tlb_mask(tlb->pagesize) << 13);
+	write_c0_entryhi(tlb->vaddr & ~0x1fff);
+	write_c0_entrylo0(entrylo(tlb->paddr0, tlb->attr0));
+	write_c0_entrylo1(entrylo(tlb->paddr1, tlb->attr1));
+
+	if (tlb->wired) {
+		write_c0_index(read_c0_wired());
+		tlb_write_indexed();
+		write_c0_wired(read_c0_wired() + 1);
+	}
+	else {
+		tlb_write_random();
+	}
+}
+
+#ifdef CONFIG_MAPPED_KERNEL
+
+/*
+ * the following initialization is needed for 32-bit
+ * mapped kernels. It must be set 512 MB past the
+ * mapped start kseg2 address (0xc0000000).
+ * 0xc0000000 + 0x20000000(512MB) = 0xe0000000
+ */
+unsigned long __vmalloc_start = 0xe0000000;
+
+#endif
+
+#if defined(CONFIG_KSEG2_LOWMEM) && defined(CONFIG_KSEG2_LOWMEM)
+
+#include <asm/barrier.h>
+
+static volatile int max_low_pfn_set = 0;
+extern unsigned long max_low_pfn;
+
+void setup_mapped_kernel_tlbs(int firstpage, int primary_cpu)
+{
+	tlb_info_t tlb;
+
+    tlb.pagesize = LARGEST_TLBPAGE_SZ; /* we set up the largest pages */
+
+	/*
+	 * In NetLogic's Linux kernel, the second 256MB of physical
+	 * address space is reserved for device configuration and
+	 * is not mapped to DRAM (to imply memory as opposed to IO
+	 * device space). Hence the attribute of the second part of
+	 * the first wired entry is invalid, while the both part of
+	 * other wired entries are symmetric. We handle the above
+	 * difference through the following unseemly if condition
+	 */
+	if (firstpage) {
+		tlb.vaddr = XKSEG;
+		tlb.paddr1 = tlb.paddr0 = 0;
+		tlb.attr0 = ((_CACHE_CACHABLE_COW |_PAGE_DIRTY |  _PAGE_VALID | _PAGE_GLOBAL) >> ENTRYLO_PFN_SHIFT);
+		tlb.attr1 = _PAGE_GLOBAL >> ENTRYLO_PFN_SHIFT;
+		tlb.wired = TRUE;
+		setup_tlb(&tlb);
+	}
+	else {
+		/*
+		 * the primary cpu reads the memory map and records
+		 * the highest page frame number. Secondary cpus
+		 * must wait till the variable max_low_pfn is set
+		 */
+		if (!primary_cpu)
+			while (!max_low_pfn_set)
+				;
+
+		tlb.vaddr = XKSEG + 2 * LARGEST_TLBPAGE_SZ; 
+		tlb.paddr0 = 2 * LARGEST_TLBPAGE_SZ;
+		for (; tlb.paddr0 < (max_low_pfn << PAGE_SHIFT);
+			 tlb.paddr0 += 2 * tlb.pagesize, tlb.vaddr += 2 * tlb.pagesize) {
+			/*
+			 * Skip 3 - 3.5GB range (PCI device space)
+			 */
+			if (tlb.paddr0 == PCIDEV_ADDRSPACE_START)
+				continue;
+			tlb.paddr1 = tlb.paddr0 + tlb.pagesize;
+			tlb.attr1 = tlb.attr0 = ((_CACHE_CACHABLE_COW |_PAGE_DIRTY |  _PAGE_VALID | _PAGE_GLOBAL) >> ENTRYLO_PFN_SHIFT);
+			tlb.wired = TRUE;
+			setup_tlb(&tlb);
+		}
+		if (primary_cpu)
+			__vmalloc_start = tlb.vaddr;
+	}
+}
+
+unsigned long recalculate_max_low_pfn(unsigned long max_low_pfn)
+{
+	/* 
+	 * truncate max_low_pfn to 512MB boundary as largest tlb
+	 * pages are used to minimize the number of wired entries
+	 */
+	if ((max_low_pfn << PAGE_SHIFT) >= (2ULL * LARGEST_TLBPAGE_SZ))
+		max_low_pfn = PFN_DOWN((uint64_t)(max_low_pfn << PAGE_SHIFT) & ~((2ULL * LARGEST_TLBPAGE_SZ) - 1));
+	max_low_pfn_set = TRUE;
+	__sync();
+	
+	return max_low_pfn;
+}
+
+#else
+
+void setup_mapped_kernel_tlbs(int index, int secondary_cpu) { }
+unsigned long recalculate_max_low_pfn(unsigned long max_low_pfn) {return max_low_pfn;}
+
+#endif /* #if defined(CONFIG_KSEG2_LOWMEM) && defined(CONFIG_KSEG2_LOWMEM) */
+
+/* override of arch/mips/mm/cache.c: __uncached_access */
+extern int nlm_common_get_pgprot(unsigned long address);
+int __uncached_access(struct file *file, unsigned long addr)
+{
+	if (file->f_flags & O_SYNC)
+		return 1;
+
+	/* check the address region, return uncached pages for IO space and
+	   cached page for memory space. */
+	return nlm_common_get_pgprot(addr);
+}
+
+inline int valid_phys_addr_range(unsigned long addr, size_t count)
+{
+	/* for now return valid */
+	return 1;
+}
+
+inline int valid_mmap_phys_addr_range(unsigned long pfn, size_t size) 
+{
+	/* for now return valid */
+	return 1;
+}
diff --git a/arch/mips/netlogic/common/nlm_hal.c b/arch/mips/netlogic/common/nlm_hal.c
new file mode 100644
index 0000000..5b8fd93
--- /dev/null
+++ b/arch/mips/netlogic/common/nlm_hal.c
@@ -0,0 +1,2296 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include "nlm_hal_fmn.h"
+#include "nlm_hal_nae.h"
+#include "nlm_hal_sae.h"
+
+/* These addresses are computed by the nlm_hal_init() */
+unsigned long xlp_io_base;
+unsigned long xlp_fmn_base;
+unsigned long xlp_nae_base;
+unsigned long xlp_mac_base;
+unsigned long xlp_poe_base_pcie;
+unsigned long xlp_poe_base_pcim;
+unsigned long xlp_sys_base;
+
+int naecfg_hack = 1;
+
+void nlm_hal_init_ext_phy(int inf);
+void nlm_hal_config_sgmii_if(int inf);
+
+static __inline__ unsigned int power_on_reset_cfg(void)
+{
+	return nlh_read_cfg_reg32(0x18035104);
+}
+
+#define PCI_MEM_BAR_0 0x4
+#define PCIE_CONTROL_0 0x240
+__inline__ void nlm_hal_xlp_pcie_rc_init(void)
+{
+	int num_pcie = 4; /* Number of PCIe controllers */
+	unsigned long base = 0x18000000;
+	int dev = 1;
+	int pcie = 0;
+
+	unsigned int pciemode = (power_on_reset_cfg() >> 19) & 0xf;
+
+	for (pcie = 0; pcie < num_pcie; pcie++) {
+		unsigned long addr;
+		unsigned int val;
+
+		if (!(pciemode & (1 << pcie)))
+			continue;
+
+		addr = base + (dev << 15) + (pcie << 12);
+
+		val = nlm_hal_read_32bit_reg(addr, PCIE_CONTROL_0);
+		val |= (1 << 21); /* BAR mask enable */
+		nlm_hal_write_32bit_reg(addr, PCIE_CONTROL_0, val);
+
+		nlm_hal_write_32bit_reg(addr, PCI_MEM_BAR_0, 0x0);
+	}
+}
+
+/* PCI Enumeration */
+__inline__ void nlm_hal_enumerate_pci(void)
+{
+}
+
+/* Basic Reg access
+ */
+__inline__ uint32_t nlm_hal_read_32bit_reg(uint64_t base, int index)
+{
+	return nlh_read_cfg_reg32(base + (index << 2));
+}
+
+__inline__ void nlm_hal_write_32bit_reg(uint64_t base, int index, uint32_t val)
+{
+	nlh_write_cfg_reg32(base +  (index << 2) , val);
+}
+
+__inline__ uint64_t nlm_hal_read_64bit_reg(uint64_t base, int index)
+{
+	return nlh_read_cfg_reg64(base + (index << 3));
+}
+__inline__ void nlm_hal_write_64bit_reg(uint64_t base, int index, uint64_t val)
+{
+	nlh_write_cfg_reg64(base +  (index << 3) , val);
+}
+
+/*
+ *    Generic Devices
+ */
+__inline__ uint64_t nlm_hal_get_dev_base(int node, int bus, int dev, int func)
+{
+	uint64_t base = xlp_io_base & 0x1fffffff;
+
+	return (uint64_t)  (base +
+			    (bus << 20) +   
+			    (dev << 15) +   
+			    (node*8 << 15) +
+			    (func << 12));
+}
+
+/*
+ *     FMN
+ */
+__inline__ uint32_t nlm_hal_send_msg3(uint32_t dst, uint32_t code, uint64_t data0, uint64_t data1, uint64_t data2)
+{
+	return nlh_send_msg3(dst, code, data0, data1, data2);
+}
+__inline__ uint32_t nlm_hal_send_msg2(uint32_t dst, uint32_t code, uint64_t data0, uint64_t data1)
+{
+	return nlh_send_msg2(dst, code, data0, data1);
+}
+__inline__ uint32_t nlm_hal_send_msg1(uint32_t dst, uint32_t code, uint64_t data0)
+{
+	return nlh_send_msg1(dst, code, data0);
+}
+
+__inline__ uint32_t nlm_hal_recv_msg2(uint32_t dst, uint32_t *src, uint32_t *size, uint32_t *code, uint64_t *data0, uint64_t *data1)
+{
+	return nlh_recv_msg2(dst, src, size, code, data0, data1);
+}
+__inline__ uint32_t nlm_hal_recv_msg1(uint32_t dst, uint32_t *src, uint32_t *size, uint32_t *code, uint64_t *data0)
+{
+	return nlh_recv_msg1(dst, src, size, code, data0);
+}
+
+__inline__ uint32_t nlm_hal_pop_msg2(uint32_t dst, uint32_t src, uint32_t code, uint64_t data0, uint64_t data1)
+{
+	return nlh_pop_msg2(dst, src, code, data0, data1);
+}
+__inline__ uint32_t nlm_hal_pop_msg1(uint32_t dst, uint32_t src, uint32_t code, uint64_t data0)
+{
+	return nlh_pop_msg1(dst, src, code, data0);
+}
+
+__inline__ int nlm_hal_is_xlp_a0(void)
+{
+	/* XXX: read register to determine stepping */
+	return 1;
+}
+
+__inline__ int nlm_hal_is_xlp_le(void)
+{
+	unsigned int pwronrst = power_on_reset_cfg();
+	int little_endian = ((pwronrst & (1 << 5)) == 0);
+	return little_endian;
+}
+
+/* Main initialization */
+__inline__ void nlm_hal_init(void)
+{
+	unsigned long long mask = ~0xf;
+#if !defined(NLM_HAL_LINUX_USER) && (_MIPS_SZLONG == 64)
+	unsigned int flags = 0;
+	enable_KX(flags);
+#endif
+
+
+	nlm_hal_enumerate_pci();
+
+	xlp_io_base = KSEG1 + 0x18000000;
+
+        /* PCI enumeration of supported devices*/
+	xlp_fmn_base = mask & nlm_hal_read_32bit_reg(0x18020000, PCI_MEM_BAR_0);
+
+	xlp_mac_base = mask & nlm_hal_read_32bit_reg(0x18018000, PCI_MEM_BAR_0);
+	xlp_nae_base = xlp_mac_base + 0xe000;
+
+	xlp_poe_base_pcim = mask & nlm_hal_read_32bit_reg(0x18019000, PCI_MEM_BAR_0);
+	xlp_poe_base_pcie = (xlp_io_base + 0x19000) & 0x1fffffff; /* For now . Will be fixed soon.*/
+
+	xlp_sys_base = (xlp_io_base + 0x35000) & 0x1fffffff; /*For now . Will be fixed soon.*/
+
+#if !defined(NLM_HAL_LINUX_USER) && (_MIPS_SZLONG == 64)
+	disable_KX(flags);
+#endif
+}
+
+
+/*
+ * Naming convention: NLM_HAL_XXX for external API
+ *                    NLH_XXX for internal naming of NL HAL
+ */
+#ifdef NLM_HAL_LINUX_KERNEL
+#include <linux/types.h>
+#include <linux/module.h>
+
+EXPORT_SYMBOL(xlp_io_base);
+EXPORT_SYMBOL(xlp_fmn_base);
+EXPORT_SYMBOL(xlp_nae_base);
+EXPORT_SYMBOL(xlp_mac_base);
+EXPORT_SYMBOL(xlp_sys_base);
+EXPORT_SYMBOL(xlp_poe_base_pcie);
+EXPORT_SYMBOL(xlp_poe_base_pcim);
+
+EXPORT_SYMBOL(nlm_hal_init);
+EXPORT_SYMBOL(nlm_hal_read_32bit_reg);
+EXPORT_SYMBOL(nlm_hal_write_32bit_reg);
+EXPORT_SYMBOL(nlm_hal_send_msg1);
+EXPORT_SYMBOL(nlm_hal_recv_msg1);
+EXPORT_SYMBOL(nlm_hal_send_msg2);
+EXPORT_SYMBOL(nlm_hal_recv_msg2);
+EXPORT_SYMBOL(nlm_hal_send_msg3);
+#endif
+
+#include "nlm_hal_pic.h"
+/*
+   This is to map 160 irt entry to 64 interrupt vector
+   Each row has three elements
+   irq		shared     number of sharing
+   irq:  assigned irq number used in linux
+   shared:  0: this irq not shared,  1: this irq is shared
+   number of sharing:  if shared = 1,  this variable indicate number of irt line to shared the same irq
+   if shared = 0,  this should be 0.
+*/
+#define SHARED_IRQ	1
+#define NOT_SHARED	0
+
+int irt_irq_table[160][4]= {
+        {9,     1,      2,      0},     /*PICIRT_WD_0_INDEX         0	*/
+        {9,     1,      2,      0},     /*PICIRT_WD_1_INDEX         1	*/
+        {19,    1,      2,      0},     /*PICIRT_WD_NMI_0_INDEX     2	*/
+        {19,    1,      2,      0},     /*PICIRT_WD_NMI_1_INDEX     3	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_0_INDEX      4	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_1_INDEX      5	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_2_INDEX      6	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_3_INDEX      7	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_4_INDEX      8	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_5_INDEX      9	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_6_INDEX      10	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_7_INDEX      11	*/
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(0),    12	*/
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(1),    13  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(2),    14  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(3),    15  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(4),    16  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(5),    17  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(6),    18  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(7),    19  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(8),    20  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(9),    21  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(10),   22  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(11),   23  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(12),   24  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(13),   25  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(14),   26  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(15),   27  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(16),   28  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(17),   29  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(18),   30  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(19),   31  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(20),   32  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(21),   33  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(22),   34  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(23),   35  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(24),   36  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(25),   37  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(26),   38  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(27),   39  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(28),   40  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(29),   41  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(30),   42  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(31),   43  */
+        {49,    0,      0,      0},     /*PICIRT_MSG_0_INDEX,       44	*/
+        {48,    0,      0,      0},     /*PICIRT_MSG_1_INDEX,       45	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(0) 46  */
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(1) 47  */
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(2) 48	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(3) 49	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(4) 50	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(5) 51	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(6) 52	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(7) 53	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(8) 54	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(9) 55	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(10)56 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(11)57 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(12)58	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(13)59 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(14)60 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(15)61 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(16)62 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(17)63	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(18)64 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(19)65 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(20)66 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(21)67 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(22)68 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(23)69 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(24)70 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(25)71 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(26)72 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(27)73 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(28)74 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(29)75 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(30)76 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(31)77 	*/
+        {44,    0,      0,      0},     /*PICIRT_PCIE_LINK_INDEX(0) 78	*/
+        {43,    0,      0,      0},     /*PICIRT_PCIE_LINK_INDEX(1) 79	*/
+        {42,    0,      0,      0},     /*PICIRT_PCIE_LINK_INDEX(2) 80	*/
+        {41,    0,      0,      0},     /*PICIRT_PCIE_LINK_INDEX(3) 81	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(0)        82	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(1)        83	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(2)        84	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(3)        85	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(4)        86	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(5)        87	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(6)        88	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(7)        89	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(8)        90	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(9)        91	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(10)       92	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(11)       93	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(12)       94	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(13)       95	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(14)       96	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(15)       97	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(16)       98	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(17)       99	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(18)       100	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(19)       101	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(20)       102 */
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(21)       103	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(22)       104	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(23)       105	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(24)       106	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(25)       107	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(26)       108	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(27)       109	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(28)       110	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(29)       111	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(30)       112	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(31)       113	*/
+        {60,    0,      0,      0},     /*PICIRT_POE_INDEX          114	*/
+        {24,    1,      6,      0},     /*PICIRT_USB_INDEX(0)       115	*/
+        {25,    1,      6,      0},     /*PICIRT_USB_INDEX(1)       116	*/
+        {25,    1,      6,      0},     /*PICIRT_USB_INDEX(2)       117	*/
+        {24,    1,      6,      0},     /*PICIRT_USB_INDEX(3)       118	*/
+        {25,    1,      6,      0},     /*PICIRT_USB_INDEX(4)       119	*/
+        {25,    1,      6,      0},     /*PICIRT_USB_INDEX(5)       120	*/
+        {61,    0,      0,      0},     /*PICIRT_GDX_INDEX          121 */
+        {63,    0,      0,      0},     /*PICIRT_SEC_INDEX          122 */
+        {62,    0,      0,      0},     /*PICIRT_RSA_INDEX          123 */
+        {39,    1,      4,      0},     /*PICIRT_COMP_INDEX(0)      124 */
+        {39,    1,      4,      0},     /*PICIRT_COMP_INDEX(1)      125 */
+        {39,    1,      4,      0},     /*PICIRT_COMP_INDEX(2)      126 */
+        {39,    1,      4,      0},     /*PICIRT_COMP_INDEX(3)      127 */
+        {38,    0,      0,      0},     /*PICIRT_GBU_INDEX          128 */
+        {37,    1,      3,      0},     /*PICIRT_ICC_0_INDEX        129  ICC - Inter Chip Coherency*/
+        {37,    1,      3,      0},     /*PICIRT_ICC_1_INDEX        130 */
+        {37,    1,      3,      0},     /*PICIRT_ICC_2_INDEX        131 */
+        {36,    0,      0,      0},     /*PICIRT_CAM_INDEX          132 */
+        {17,    0,      0,      0},     /*PICIRT_UART_0_INDEX       133 */
+        {18,    0,      0,      0},     /*PICIRT_UART_1_INDEX       134 */
+        {11,    1,      2,      0},     /*PICIRT_I2C_0_INDEX        135	*/
+        {11,    1,      2,      0},     /*PICIRT_I2C_1_INDEX        136	*/
+        {12,    1,      2,      0},     /*PICIRT_SYS_0              137	*/
+        {12,    1,      2,      0},     /*PICIRT_SYS_1              138	*/
+        {55,    0,      0,      0},     /*PICIRT_JTAG_INDEX         139	*/
+        {50,    0,      0,      0},     /*PICIRT_PIC                140	*/
+        {54,    0,      0,      0},     /*PICIRT_NBU                141	*/
+        {53,    0,      0,      0},     /*PICIRT_TCU                142	*/
+        {52,    0,      0,      0},     /*PICIRT_GCU                143  GBC - Global Coherency*/
+        {36,    1,      2,      0},     /*PICIRT_DMC_0_INDEX        144	*/
+        {36,    1,      2,      0},     /*PICIRT_DMC_1_INDEX        145	*/
+        {13,    0,      0,      0},     /*PICIRT_GPIO_INDEX(0)      146	*/
+        {14,    0,      0,      0},     /*PICIRT_GPIO_INDEX(1)      147	*/
+        {15,    0,      0,      0},     /*PICIRT_GPIO_INDEX(2)      148	*/
+        {16,    0,      0,      0},     /*PICIRT_GPIO_INDEX(3)      149	*/
+        {20,    0,      0,      0},     /*PICIRT_NOR                150	*/
+        {21,    0,      0,      0},     /*PICIRT_NAND               151	*/
+        {22,    0,      0,      0},     /*PICIRT_SPI                152	*/
+        {23,    0,      0,      0},     /*PICIRT_MMC                153	*/
+        {0,     0,      0,      0},     /*			    154	*/
+        {0,     0,      0,      0},     /*                          155	*/
+        {0,     0,      0,      0},     /*                          156	*/
+        {0,     0,      0,      0},     /*                          157	*/
+        {0,     0,      0,      0},     /*                          158	*/
+        {0,     0,      0,      0},     /*                          159	*/
+};
+
+
+/*
+  short find_irt_from_irq( int irq)
+
+  find irt number from irq
+  irq: input irq number,
+  return:  irt number,  if it is -1, indicate can't find irt line for irq number.
+*/
+int find_irt_from_irq( int irq)
+{
+        unsigned long long irt_pending0, irt_pending1, irt_pending2;
+        int base_irt, num_shared = 0, i,j;
+        uint64_t val;
+        uint64_t shared_mask;
+
+        if(irq <0 || irq >63)
+        {
+                return -1;
+        }
+        if(irq < 8)
+                return irq;
+
+        /*from base irt_irq_table, find base irt number, for shared irq, need figure out which is the*/
+        for ( i = 0; i < PIC_NUM_IRTS; i++)
+        {
+                if(irq == irt_irq_table[i][0])
+                {
+                        /* unshared irq*/
+                        if(irt_irq_table[i][1] == NOT_SHARED)
+                        {
+                                /* this is irt number we needed;*/
+                                return  i;
+                        }
+                        else if(irt_irq_table[i][1] == SHARED_IRQ)
+                        {
+                                /*if shared bit is 1,  this irq is shared by a number of irt line*/
+                                num_shared = irt_irq_table[i][2];
+                                break;
+                        }
+                }
+
+        }
+        base_irt = i;
+        if(num_shared == NOT_SHARED || base_irt == 160)
+                return -1;
+        /* for shared irq, need figure out which irt line produce this irq*/
+        /* we can determine it by look at the interrupt pending register*/
+
+        /*first scan col 4 of enabled field to see whether any IRT is enabled,*/
+        /*it could be just first time to register*/
+        for(j = 0; j < num_shared; j++)
+        {
+		shared_mask = (1ULL << num_shared) - 1;
+                if( irt_irq_table[base_irt][0] != irt_irq_table[base_irt + j][0])
+                        continue;
+
+                if(irt_irq_table[base_irt + j][3] == 1)
+                {
+                        val = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_IRT(base_irt + j));
+                        if(!(val & (1 << 31)))
+                        {
+                                /*this irt entry not enable yet*/
+                                return base_irt + j;
+
+                        }
+                        else
+                        {
+                                /*check pending register*/
+                                if(base_irt+j < 64)
+                                {
+                                        irt_pending0 = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_INT_PENDING0);
+                                        shared_mask  = shared_mask << base_irt;
+                                        irt_pending0 = irt_pending0 & shared_mask;
+                                        if(irt_pending0 & (1ULL << (base_irt + j)))
+                                                return (j + base_irt);
+                                }
+                                else if(base_irt + j >= 64 && base_irt + j < 128)
+                                {
+                                        irt_pending1 = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_INT_PENDING1);
+                                        shared_mask  = shared_mask << (base_irt - 64);
+                                        irt_pending1 = irt_pending1 & shared_mask;
+                                        if(irt_pending1 & (1ULL << (base_irt + j - 64)))
+                                                return (j + base_irt);
+
+                                }
+                                else if(base_irt+j > 128)
+                                {
+                                        irt_pending2 = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_INT_PENDING2);
+                                        shared_mask  = shared_mask << (base_irt - 128);
+                                        irt_pending2 = irt_pending2 & shared_mask;
+                                        if(irt_pending2 & (1ULL << (base_irt + j - 128)))
+                                                return (j + base_irt);
+                                }
+                        }
+                }
+        }
+
+        /*if we get here, means penging register is not set for all */
+        for(j = 0; j < num_shared ; j++)
+        {
+
+                if(irt_irq_table[base_irt+j][3] == 1)
+                        return (base_irt+j);
+        }
+        return -1;
+}
+
+
+int nlm_hal_request_shared_irq(int irt)
+{
+        uint64_t  val;
+
+        if(irt < 0 || irt > PIC_NUM_IRTS)
+                return -1;
+        irt_irq_table[irt][3] = 1;
+        val = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt));
+        /* clear DB and DTE field */
+        val &= ~(0x3f << 20);
+        val |= (irt_irq_table[irt][0] << 20 | 1 << 31 | 1 << 28);
+        nlm_hal_write_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt),val);
+
+
+        return irt_irq_table[irt][0];
+}
+void nlm_hal_unrequest_shared_irq(int irt)
+{
+        if(irt < 0 || irt > PIC_NUM_IRTS)
+                return;
+        if(irt_irq_table[irt][3] == 1)
+                irt_irq_table[irt][3] = 0;
+        return;
+}
+
+void nlm_hal_set_irt_to_cpu(int irt, int cpu)
+{
+        int val;
+
+        val = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt));
+        /* clear DB and DTE field */
+        val &= ~( 0x7<<16 | 0xf);
+        val |= (1 << 19 |((cpu-1)/16)<<16 | cpu && 0xf );
+        nlm_hal_write_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt),val);
+}
+
+void nlm_hal_set_irq_to_cpu(int irq, int cpu)
+{
+        int val, irt, i, num_shared = 0, base_irt = 0;
+
+        irt = find_irt_from_irq(irq);
+
+        if(irt < 0 || irt > PIC_NUM_IRTS)
+                return;
+
+        if(irt_irq_table[irt][1] == NOT_SHARED)
+        {
+                val = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt));
+                val |= ( ((cpu-1)/16)<<16 | cpu && 0xf );
+                nlm_hal_write_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt),val);
+        }
+        else
+        {
+                for(i = 0; i < PIC_NUM_IRTS; i++)
+                {
+                        if( irq == irt_irq_table[i][0])
+                        {
+                                base_irt = i;
+                                num_shared = irt_irq_table[i][2];
+                                break;
+                        }
+                }
+                for(i = base_irt; i < base_irt+num_shared; i++)
+                {
+                        nlm_hal_set_irt_to_cpu( i, cpu);
+                }
+        }
+        return;
+}
+
+static const unsigned char dfs_values[4] =
+{ 2,4,8,16};
+
+unsigned long long nlm_hal_cpu_freq(void)
+{
+	unsigned long long mips_counter_frequency;
+	unsigned int pwron_rst_reg = nlm_hal_read_sys_reg(POWER_ON_RESET_CFG);
+
+	int pll_divf = (pwron_rst_reg >> 10) & 0x7f;
+	int pll_divr = (pwron_rst_reg >> 8)  & 0x3;
+	int dfs_div  = (pwron_rst_reg >> 17) & 0x3;
+
+        unsigned long long vco_fs         = (((7500 * 1000) * (pll_divr+1))/(4 * (pll_divf+1)));
+	unsigned long long pll_period_fs  = vco_fs * 2; /* pll output is divided by 2 */
+
+	dfs_div = dfs_values[dfs_div];
+
+	mips_counter_frequency = 1000000000000000ULL/pll_period_fs;
+	mips_counter_frequency = mips_counter_frequency / dfs_div;
+
+	return mips_counter_frequency;
+}
+
+unsigned long tlb_size_to_page_size(unsigned long size)
+{
+	if (size <= (4*1024)) return 4*1024;
+	if (size <= (16*1024)) return 16*1024;
+	if (size <= (64*1024)) return 64*1024;
+	if (size <= (256*1024)) return 256*1024;
+	if (size <= (1024*1024)) return 1024*1024;
+	if (size <= (4*1024*1024)) return 4*1024*1024;
+	if (size <= (16*1024*1024)) return 16*1024*1024;
+	if (size <= (64*1024*1024)) return 64*1024*1024;
+
+	return 256*1024*1024;
+}
+
+unsigned long tlb_size_to_mask(unsigned long size)
+{
+	if (size <= (4*1024)) return 0x0 << 13;
+	if (size <= (16*1024)) return 0x03 << 13;
+	if (size <= (64*1024)) return 0x0f << 13;
+	if (size <= (256*1024)) return 0x3f << 13;
+	if (size <= (1024*1024)) return 0xff << 13;
+	if (size <= (4*1024*1024)) return 0x3ff << 13;
+	if (size <= (16*1024*1024)) return 0xfff << 13;
+	if (size <= (64*1024*1024)) return 0x3fff << 13;
+
+	return 0xffff << 13;
+}
+
+/*
+ * NAE Support
+ */
+/* Currently Only Gmac is supported !! */
+/* NETWORK INF CTRL REG */
+#define SOFTRESET(x)                        ((x) << 11)
+#define STATS_EN(x)                         ((x) << 16)
+#define TX_EN(x)                            ((x) << 2)
+#define SPEED(x)                            ((x) & 0x3)
+
+/* MAC_CONF1 */
+#define INF_SOFTRESET(x)                    ((x) << 31)
+#define INF_LOOP_BACK(x)                    ((x) << 8)
+#define INF_RX_ENABLE(x)                    ((x) << 2)
+#define INF_TX_ENABLE(x)                    (0x1)
+
+/* MAC_CONF2 */
+#define INF_PREMBL_LEN(x)                   (((x) & 0xf) << 12)
+#define INF_IFMODE(x)                       (((x) & 0x3) << 8)
+#define INF_LENCHK(x)                       ((((x) & 0x1)) << 4)
+#define INF_PADCRCEN(x)                     (((x) & 0x1) << 2)
+#define INF_PADCRC(x)                       (((x) & 0x1) << 1)
+#define INF_FULLDUP(x)                      ((x) & 0x1)
+#define TXINITIORCR(x)                      ((x) & 0x7ffff) << 8
+
+#define NAE_RX_ENABLE 0x1
+#define NAE_TX_ENABLE 0x1
+#define NAE_TX_ACE 0x2
+
+#define INF_BYTE_MODE   0x2
+#define INF_NIBBLE_MODE 0x1
+
+enum NAE_REG_CMD {
+	CMD_READ = 0,
+	CMD_WRITE
+};
+
+enum if_speed {
+        SPEED_10M = 0,
+        SPEED_100M,
+        SPEED_1000M
+}; 
+
+
+int nlm_hal_init_if_regs(int type, int  inf, uint32_t *regs, int num_regs)
+{
+	int i;
+ 	if ((regs == NULL) || (num_regs == 0)) {
+		return -2;
+	}
+
+	if (type != INTERLAKEN_IF) {
+		for (i = 0; i < num_regs; i++) {
+			write_gmac_reg(inf, regs[2*i], regs[2*i + 1]);
+		}
+		return 0;
+	}
+	return -1;
+}
+int nlm_hal_init_nae_regs(int type, uint32_t *regs, int num_regs)
+{
+	int i;
+ 	if ((regs == NULL) || (num_regs == 0)) {
+		return -2;
+	}
+
+	if (type == INTERLAKEN_IF) {
+		return -1;
+	}
+
+	for (i = 0; i < num_regs; i++) {
+		nlm_hal_write_nae_reg(regs[2*i], regs[2*i + 1]);
+	}
+	return 0;
+}
+
+int nlm_hal_init_poe_regs(uint32_t *regs, int num_regs)
+{
+	int i;
+ 	if ((regs == NULL) || (num_regs == 0)) {
+		return -2;
+	}
+
+	for (i = 0; i < num_regs; i++) {
+		if (regs[3*i] == PCIE_MEM_POE_REG) {
+			/* PCIE MEM based regs */
+			nlm_hal_write_poe_pcim_reg(regs[3*i + 1], regs[3*i + 2]);
+
+		} else if (regs[3*i] == PCIE_CFG_POE_REG) {
+			/* PCIE  CFG header based regs */
+			nlm_hal_write_poe_pcie_reg(regs[3*i + 1], regs[3*i + 2]);
+		}
+	}
+	return 0;
+}
+
+void nlm_hal_init_poe_ext_storage(uint64_t fbp_base_phys,
+				  uint64_t msg_base_phys,
+	                          uint64_t msg_base_virt)
+{
+	uint32_t addr;
+	uint64_t ldata, a;
+	uint64_t *vaddr;
+	int i;
+	uint32_t mbase_hi, mbase_lo, fbp_hi, fbp_lo;
+	mbase_hi = (msg_base_phys >> 32) & 0xffffffff;
+	mbase_lo = msg_base_phys & 0xffffffff;
+	fbp_hi = (fbp_base_phys >> 32) & 0xffffffff;
+	fbp_lo = fbp_base_phys & 0xffffffff;
+
+	/* POE External Message Storage (upto 58K) */
+
+	nlm_print("POE ext msg storage: \n");
+	nlm_print("msg base: 0x%x%x\n", mbase_hi, mbase_lo);
+	nlm_print("fbp base: 0x%x%x\n", fbp_hi, fbp_lo);
+
+	/* Free Buffer Pool config */
+	nlm_print (" POE Free Buffer Pool config ...\n");
+
+	a = (uint64_t)EXT_FBP_START_ADDR;
+	vaddr = (uint64_t *) msg_base_virt;
+	for (i = 0; i < (MAX_POE_EXT_MSG_STORAGE / 4); i++) {
+		ldata = ((a+3) << 48) | ((a+2) << 32) | ((a+1) << 16) | a;
+		*vaddr = ldata;
+		vaddr++;
+		a += 4;
+	}
+
+	/* Configuring Message base pointer */
+	addr = MSG_STORAGE_BASE_ADR_L;
+	nlm_print ("POE Configuring Message base pointer ...\n");
+	nlm_hal_write_poe_pcie_reg(addr, mbase_lo);
+	addr++;
+	nlm_hal_write_poe_pcie_reg(addr, mbase_hi);
+
+	/* Configuring FBP base pointer */
+	addr = FBP_BASE_ADR_L;
+	nlm_print ("POE Configuring FBP base pointer ...\n");
+	nlm_hal_write_poe_pcie_reg(addr, fbp_lo);
+	addr++;
+	nlm_hal_write_poe_pcie_reg(addr, fbp_hi);
+}
+
+
+#define NUM_VCS_PER_CPU 4
+#define NUM_DISTVEC_CELLS 16
+#define NUM_DISTVEC_CPUMASKS 4
+
+#define MIN_DIST_VEC 0
+#define MAX_DIST_VEC 16
+
+#define POE_DIST_VEC0 0x100
+
+int nlm_hal_init_poe_distvec(int vec, uint32_t cm0, uint32_t cm1,
+	uint32_t cm2, uint32_t cm3, uint32_t vcmask)
+{
+	uint32_t cpumasks[NUM_DISTVEC_CPUMASKS];
+	uint32_t distvec[NUM_DISTVEC_CELLS];
+	int i;
+	int cpu;
+
+	if (vec < MIN_DIST_VEC || vec >= MAX_DIST_VEC)
+		return -1;
+
+	cpumasks[0] = cm0;
+	cpumasks[1] = cm1;
+	cpumasks[2] = cm2;
+	cpumasks[3] = cm3;
+
+	vcmask &= 0xf;
+	if (!vcmask)
+		return -1;
+
+	/* Initialize distribution vector cells */
+	for (i = 0; i < NUM_DISTVEC_CELLS; i++) {
+		distvec[i] = 0;
+	}
+
+	for (i = 0; i < NUM_DISTVEC_CPUMASKS; i++) {
+		uint32_t cpumask = cpumasks[i];
+
+		for (cpu = 0; cpu < 32; cpu++) {
+			int cell, offset;
+			uint32_t value;
+			int vc = 0;
+			int gcpu = 0;
+
+			if (((1 << cpu) & cpumask) == 0)
+				continue;
+
+			/* Use global cpu id */
+			gcpu = cpu + (i * 32);
+			vc = (gcpu * NUM_VCS_PER_CPU) % (NUM_DISTVEC_CELLS * 32);
+
+			cell = vc / 32;
+			offset = vc % 32;
+
+			value = vcmask << offset;
+
+			distvec[cell] |= value;
+		}
+	}
+
+	/* Write distribution vector cells */
+	for (i = 0; i < NUM_DISTVEC_CELLS; i++) {
+		int reg_index;
+		uint32_t value;
+
+		reg_index = POE_DIST_VEC0 + (vec * NUM_DISTVEC_CELLS)
+		            + (NUM_DISTVEC_CELLS - 1 - i);
+		value = distvec[i];
+
+		nlm_print("POE DistVec[%d]: reg=%d value=%08x\n",
+		          vec, (NUM_DISTVEC_CELLS - 1 - i), value);
+		nlm_hal_write_poe_pcim_reg(reg_index, value);
+	}
+
+	return 0;
+}
+
+extern struct nlm_hal_nae_config nae_cfg;
+
+void cpu_hotplug_fixup_poe(int cpu, int flag)
+{
+	unsigned long mflags = 0;
+	int reg_index;
+	uint32_t value, vcmask;
+	int cell, offset, vc = 0;
+	uint32_t distvec[NUM_DISTVEC_CELLS];
+
+	vcmask =  (1 << nae_cfg.rx_vc);
+	vc = (cpu * NUM_VCS_PER_CPU) % (NUM_DISTVEC_CELLS * 32);
+	cell = vc / 32;
+
+	reg_index = POE_DIST_VEC0 + (NUM_DISTVEC_CELLS - 1 - cell);
+
+	/* do we need to ensure nobody is operating on msgrng? */
+	msgrng_access_enable(mflags);
+	if (flag) {
+		/* online */
+		offset = vc % 32;
+		value = vcmask << offset;
+
+		distvec[cell] |= value;
+		nlm_hal_write_poe_pcim_reg(reg_index, value);
+	} else {
+		/* offline */
+		nlm_hal_write_poe_pcim_reg(reg_index, 0);
+	}
+	msgrng_access_disable(mflags);
+}
+
+
+int nlm_hal_init_if(int type, int  inf, uint32_t *regs, int num_regs)
+{
+	int i;
+	if (regs == NULL) {
+		return -1;
+	}
+	if (type == INTERLAKEN_IF) {
+		return -1;
+	}
+	/* Initialize the regs */
+	for (i = 0; i < num_regs; ++i) {
+		/*		nlm_hal_write_nae_reg(inf, regs[2*i], regs[2*i + 1]); */
+	}
+	return 0;
+}
+
+static int init_netior(int type)
+{
+	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_SOFTRESET, 0);
+	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_MISC_REG3_ADDR , (0x0 | (0x0007 << 18) ) );
+	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_MISC_REG2_ADDR , 0x07070707 );
+	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_MISC_REG1_ADDR , 0x00fffff );
+	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_MISC_REG1_ADDR , 0x0);
+	return 0;
+}
+
+/* Ingress Config
+ *      20 queue (1000 - 1019)
+ *      RxConfig : set the Free in desc default
+ *      Interface to context mapping(RX_IF_BASE_CONFIG0..8)
+ *      set valid active interface
+ *      parser configuration
+ *      Free-Fifo pool to context (FREE_IN_FIFO_CFG)
+ *      Parser se
+ *
+ *
+ * */
+static void init_ingress(void)
+{
+	unsigned int rx_cfg = 0;
+	unsigned int parser_threshold = 384 ;
+	int desc_size = 2048;
+
+	rx_cfg = nlm_hal_read_nae_reg(RX_CONFIG);
+
+	//log_dbg("nae rxcfg %x txcfg %x\n", rx_cfg, tx_cfg);
+#define NAE_MAX_MESSAGE_SIZE(x)                 (((x) & 0x3)<<1)
+#define RESET_MAX_MESSAGE_SIZE                   ~(0x3<<1)
+#define NAE_FRINDESCCLSIZE(x)                   (((x)  & 0xff)<< 4 )
+#define RESET_FRINDESCCLSIZE                   ~((0xff)<< 4)
+#define NAE_RX_STATUS_MASK(x)                   (((x) & 0x7f) << 24)
+#define RESET_RX_STATUS_MASK                   ~((0x3f) << 24)
+
+	nlm_hal_write_nae_reg( RX_CONFIG,(rx_cfg &
+					  RESET_MAX_MESSAGE_SIZE &
+					  RESET_FRINDESCCLSIZE &
+					  RESET_RX_STATUS_MASK
+				       ) |
+			       NAE_RX_ENABLE|
+			       NAE_MAX_MESSAGE_SIZE(0x0)|
+			       NAE_RX_STATUS_MASK(0x43)|
+			       NAE_FRINDESCCLSIZE(desc_size/64)
+		);
+
+#define PARSER_THRESHOLD(x) ((x)  & 0x3ff)
+#define PARSER_THRESHOLD_DIV_DESCSIZE(x) ( ((x) & 0xff) << 12)
+#define PARSER_THRESHOLD_MOD_DESCSIZE_CL(x) ( ((x) & 0xff) << 20)
+
+	nlm_hal_write_nae_reg( XLP_PARSER_CONFIG,
+			       PARSER_THRESHOLD(parser_threshold) |
+			       PARSER_THRESHOLD_DIV_DESCSIZE((parser_threshold/desc_size) + 1) |
+			       PARSER_THRESHOLD_MOD_DESCSIZE_CL( (parser_threshold/64)%desc_size) );
+}
+
+static void init_egress(void)
+{
+	uint32_t tx_cfg =  nlm_hal_read_nae_reg(TX_CONFIG);
+
+	nlm_hal_write_nae_reg( TX_CONFIG, tx_cfg | NAE_TX_ENABLE | NAE_TX_ACE );
+}
+
+static void init_ucore(int if_num)
+{
+
+	nlm_hal_write_nae_reg(UCORE_IFACE_MASK_CFG,
+			      ucore_spray_config(if_num, 0xffff, CMD_WRITE));
+
+}
+
+int nlm_hal_open_if(int type, int  inf)
+{
+	unsigned int netwk_inf  = 0;
+	unsigned int tx_config = 0;
+	int tx_ior_credit = 0;
+	uint32_t ifmask = 0;
+	unsigned int mac_cfg1 = 0;
+	unsigned int netior_ctrl3 = 0;
+
+	// Init Netior ... Need to fixed
+	init_netior(type);
+
+	switch(type) {
+		case XAUI_IF:
+			// inf is a complex number
+			netwk_inf = nlm_hal_read_mac_reg(inf, XGMAC, NETIOR_XGMAC_CTRL1);
+			netwk_inf |= (1 << NETIOR_XGMAC_STATS_CLR_POS);
+			nlm_hal_write_mac_reg(inf, XGMAC, NETIOR_XGMAC_CTRL1, netwk_inf);
+			ifmask = 0xf << (inf);
+			tx_ior_credit = nlm_hal_read_nae_reg(TX_IORCRDT_INIT);
+			nlm_hal_write_nae_reg(TX_IORCRDT_INIT, tx_ior_credit | ifmask);
+		        tx_config = nlm_hal_read_nae_reg(TX_CONFIG);
+			// need to toggle these bits for credits to be loaded
+		 	nlm_hal_write_nae_reg(TX_CONFIG, tx_config | ( TXINITIORCR(ifmask)));
+		        nlm_hal_write_nae_reg(TX_CONFIG, tx_config & ~( TXINITIORCR(ifmask)));
+			break;
+		case INTERLAKEN_IF:
+			// inf is a complex number
+			ifmask = 0xff << (inf);   //based on number of lanes
+			tx_ior_credit = nlm_hal_read_nae_reg(TX_IORCRDT_INIT);
+			nlm_hal_write_nae_reg(TX_IORCRDT_INIT, tx_ior_credit | (ifmask));
+                        tx_config = nlm_hal_read_nae_reg(TX_CONFIG);
+			// need to toggle these bits for credits to be loaded
+	                nlm_hal_write_nae_reg(TX_CONFIG, tx_config | ( TXINITIORCR(ifmask)));
+                        nlm_hal_write_nae_reg(TX_CONFIG, tx_config & ~( TXINITIORCR(ifmask)));
+			break;
+		case SGMII_IF:
+			tx_ior_credit = nlm_hal_read_nae_reg(TX_IORCRDT_INIT);
+			nlm_hal_write_nae_reg(TX_IORCRDT_INIT, tx_ior_credit & (~ (1<<inf)));
+			tx_config = nlm_hal_read_nae_reg(TX_CONFIG);
+			// need to toggle these bits for credits to be loaded
+			nlm_hal_write_nae_reg(TX_CONFIG, tx_config | ( TXINITIORCR(1<<inf)));
+			nlm_hal_write_nae_reg(TX_CONFIG, tx_config & ~( TXINITIORCR(1<<inf)));
+
+			/* init phy id to access internal PCS */
+		        netwk_inf = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
+        		netwk_inf &= 0x7ffffff;
+		        netwk_inf |= ((inf) << 27);
+        		write_gmac_reg(inf, NETWK_INF_CTRL_REG, netwk_inf);
+
+			/* Sofreset set bit 11 to 0  */
+
+			write_gmac_reg(inf , NETWK_INF_CTRL_REG,  netwk_inf & 0xfffff7ff);
+
+			// Reset GMAC
+			mac_cfg1 = read_gmac_reg(inf, MAC_CONF1);
+		        write_gmac_reg(inf , MAC_CONF1, mac_cfg1 | INF_SOFTRESET(1) |
+					           INF_RX_ENABLE(1) |
+						   INF_TX_ENABLE(1));
+
+			// Default 1G
+		        write_gmac_reg(inf , MAC_CONF2,  INF_PREMBL_LEN(0x7) |
+                        		     	INF_IFMODE(2)  |
+                	               		INF_FULLDUP(1) |
+		  			        INF_PADCRCEN(1));
+
+			// Clear GMAC reset
+			mac_cfg1 = read_gmac_reg(inf, MAC_CONF1);
+		        write_gmac_reg(inf , MAC_CONF1, mac_cfg1 & ~(INF_SOFTRESET(1)));
+
+			// Clear speed debug bit
+		        netior_ctrl3 = read_gmac_reg(inf, NETWK_INF_CTRL3_REG);
+		        write_gmac_reg(inf, NETWK_INF_CTRL3_REG, netior_ctrl3 & (~(1<<6)));
+
+#ifndef XLP_SIM
+			// init external phy, bypass SGMII auto negotiation
+			nlm_hal_init_ext_phy(inf);
+#endif
+			// Configure speed and mode
+			nlm_hal_config_sgmii_if(inf);
+			break;
+		default:
+			nlm_print("Unknown interface type\n");
+			return 0;
+	}
+
+	init_ingress();
+	init_egress();
+	init_ucore(inf);
+
+	return 0;
+}
+int nlm_hal_close_if(int type, int  inf)
+{
+	if (type != SGMII_IF) {
+		return -1;
+	}
+	/* Turn off TX, RX enables */
+	return 0;
+}
+/*
+ *  NAE Send
+ */
+static __inline__ uint64_t nae_tx_desc(unsigned int type,
+				       unsigned int rdex,
+				       unsigned int fbid,
+				       unsigned int len,
+				       uint64_t addr)
+{
+	return ((uint64_t)(type & 0x3) << 62) |
+		((uint64_t)(rdex & 0x1) << 61) |
+		((uint64_t)(fbid & 0x7f) << 54) |
+		((uint64_t)(len & 0x3fff) << 40) |
+		addr;
+}
+
+int nlm_hal_nae_send(int dest, int fbid, unsigned long long phys_addr, int len, unsigned int flags)
+{
+	/* TODO: Implement flags */
+	unsigned long long data[4];
+
+	data[0] = nae_tx_desc(P2D_NEOP, 0, fbid, 0, phys_addr);
+	data[1] = nae_tx_desc(P2D_EOP,
+			      0,
+			      NULL_VFBID,
+			      len ,
+			      phys_addr );
+
+	return nlm_hal_send_msg2(dest,
+				 0,
+				 data[0],
+				 data[1]);
+}
+/*
+ * Nae recv
+ */
+int nlm_hal_soc_recv(int dst_vc, unsigned int *intf, unsigned long long *phys_addr, unsigned int *flags)
+{
+	uint32_t size = 0, code = 0;
+	unsigned int rx_status = 0;
+	uint64_t data[4];
+	int len = 0;
+
+	*flags = NAE_RECV_NONE;
+
+	if(nlm_hal_recv_msg2(dst_vc, (uint32_t *) intf, &size, &code, &data[0], &data[1])) {
+
+		rx_status = xlp_read_rx_status();
+
+
+		if (!((rx_status >> 28) & (1 << dst_vc))) {
+			return -1;
+		}
+
+		return -2;
+	}
+
+	if (size == 2 && dst_vc == 0) {
+
+		/* Rx Packet
+		 */
+		*flags = NAE_RECV_RX;
+		*phys_addr = (data[1]) & 0xffffffffc0ULL;
+		len = (data[1] >> 40) & 0x3fff;
+	}
+	else if (size == 1 && dst_vc == 3) {
+
+		/* TxC Packet
+		 */
+
+		*flags = NAE_RECV_TXC;
+		*phys_addr = (data[0]);
+		len = 0;
+	}
+	else {
+
+		*flags = NAE_RECV_UNKNOWN;
+		*phys_addr = 0;
+		len = 0;
+	}
+
+	return len;
+}
+
+int nlm_hal_nae_recv(int rx_vc, unsigned long long *phys_addr, unsigned int *flags)
+{
+	unsigned int intf;
+	return nlm_hal_soc_recv(rx_vc, &intf, phys_addr, flags);
+}
+/*
+ *  Ucore support
+ */
+int nlm_hal_load_ucore(int ucore_mask, unsigned int *opcodes, int num_opcodes)
+{
+	int mask = ucore_mask & NAE_UCORE_MASK;
+	unsigned int id = 0;
+	int i;
+
+	while (id < MAX_NAE_UCORES) {
+
+		if ((mask & (1 << id)) == 0) {
+			id++;
+			continue;
+		}
+
+		for (i=0; i < num_opcodes; ++i) {
+			nlm_hal_write_ucode(id, (i * 4), opcodes[i]);
+		}
+		id++;
+	}
+	return 0;
+}
+
+/*
+ *      MDIO Support
+ */
+/* Internal MDIO READ/WRITE Routines
+ */
+static int nae_int_gmac_mdio_read(int bus,int block, int intf_type, int phyaddr, int regidx)
+{
+	uint32_t mdio_ld_cmd = nlm_hal_read_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4);
+
+	if (mdio_ld_cmd & INT_MDIO_CTRL_CMD_LOAD) {
+		nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
+				       (mdio_ld_cmd & ~INT_MDIO_CTRL_CMD_LOAD));
+	}
+
+	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_SMP
+			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
+			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
+			       | (2 << INT_MDIO_CTRL_OP_POS)
+			       | (1 << INT_MDIO_CTRL_ST_POS)
+			       | (7 << INT_MDIO_CTRL_XDIV_POS)
+			       | (2 << INT_MDIO_CTRL_TA_POS)
+			       | (2 << INT_MDIO_CTRL_MIIM_POS)
+			       | (0 << INT_MDIO_CTRL_LOAD_POS)
+			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	/* Toggle Load Cmd Bit */
+	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_SMP
+			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
+			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
+			       | (2 << INT_MDIO_CTRL_OP_POS)
+			       | (1 << INT_MDIO_CTRL_ST_POS)
+			       | (7 << INT_MDIO_CTRL_XDIV_POS)
+			       | (2 << INT_MDIO_CTRL_TA_POS)
+			       | (2 << INT_MDIO_CTRL_MIIM_POS)
+			       | (1 << INT_MDIO_CTRL_LOAD_POS) /* */
+			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	/* poll master busy bit until it is not busy
+	 */
+	while(nlm_hal_read_mac_reg( block, intf_type,
+				    INT_MDIO_RD_STAT + bus * 4) & INT_MDIO_STAT_MBSY) {
+	}
+
+	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_SMP
+			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
+			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
+			       | (2 << INT_MDIO_CTRL_OP_POS)
+			       | (1 << INT_MDIO_CTRL_ST_POS)
+			       | (7 << INT_MDIO_CTRL_XDIV_POS)
+			       | (2 << INT_MDIO_CTRL_TA_POS)
+			       | (2 << INT_MDIO_CTRL_MIIM_POS)
+			       | (0 << INT_MDIO_CTRL_LOAD_POS)
+			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	/* Read the data back
+	 */
+	return nlm_hal_read_mac_reg( block, intf_type, INT_MDIO_RD_STAT + bus * 4);
+}
+
+/* Internal MDIO WRITE Routines
+ */
+static int nae_int_gmac_mdio_write(int bus, int block, int intf_type, int phyaddr, int regidx, uint16_t val)
+{
+	uint32_t mdio_ld_cmd = nlm_hal_read_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4);
+
+	if (mdio_ld_cmd & INT_MDIO_CTRL_CMD_LOAD) {
+		nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
+				       (mdio_ld_cmd & ~INT_MDIO_CTRL_CMD_LOAD));
+	}
+
+	/* load data into ctrl data reg
+	 */
+	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL_DATA + bus * 4, val);
+
+	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_SMP
+			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
+			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
+			       | (1 << INT_MDIO_CTRL_OP_POS)
+			       | (1 << INT_MDIO_CTRL_ST_POS)
+			       | (7 << INT_MDIO_CTRL_XDIV_POS)
+			       | (2 << INT_MDIO_CTRL_TA_POS)
+			       | (1 << INT_MDIO_CTRL_MIIM_POS)
+			       | (0 << INT_MDIO_CTRL_LOAD_POS)
+			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_SMP
+			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
+			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
+			       | (1 << INT_MDIO_CTRL_OP_POS)
+			       | (1 << INT_MDIO_CTRL_ST_POS)
+			       | (7 << INT_MDIO_CTRL_XDIV_POS)
+			       | (2 << INT_MDIO_CTRL_TA_POS)
+			       | (1 << INT_MDIO_CTRL_MIIM_POS)
+			       | (1 << INT_MDIO_CTRL_LOAD_POS)
+			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	/* poll master busy bit until it is not busy
+	 */
+	while(nlm_hal_read_mac_reg( block, intf_type,
+				    INT_MDIO_RD_STAT + bus * 4) & INT_MDIO_STAT_MBSY) {
+	}
+
+	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_SMP
+			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
+			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
+			       | (1 << INT_MDIO_CTRL_OP_POS)
+			       | (1 << INT_MDIO_CTRL_ST_POS)
+			       | (7 << INT_MDIO_CTRL_XDIV_POS)
+			       | (2 << INT_MDIO_CTRL_TA_POS)
+			       | (1 << INT_MDIO_CTRL_MIIM_POS)
+			       | (0 << INT_MDIO_CTRL_LOAD_POS)
+			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	return 0;
+}
+
+static int int_nae_gmac_mdio_reset(int bus, int block, int intf_type)
+{
+	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_RST |
+			       (7 << INT_MDIO_CTRL_XDIV_POS) 	|
+			       (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       (7 << INT_MDIO_CTRL_XDIV_POS) 	|
+			       (1 << INT_MDIO_CTRL_MCDIV_POS));
+	return 0;
+}
+
+/**********************************************************************
+ *  nae_gmac_mdio_read - Read sgmii phy register
+ *
+ *  Input parameters:
+ *         bus          - bus number, nae has two external gmac bus: 0 and 1
+ *         phyaddr      - PHY's address
+ *         regidx       - index of register to read
+ *
+ *  Return value:
+ *         value read (16 bits), or 0xffffffff if an error occurred.
+ ********************************************************************* */
+static int nae_gmac_mdio_read(int bus,int block, int intf_type, int phyaddr, int regidx)
+{
+	uint32_t mdio_ld_cmd = nlm_hal_read_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4);
+
+	if (mdio_ld_cmd & EXT_G_MDIO_CMD_LCD) {
+		nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
+				       (mdio_ld_cmd & ~EXT_G_MDIO_CMD_LCD));
+		while(nlm_hal_read_mac_reg( block, intf_type,
+					    EXT_G0_MDIO_RD_STAT + bus * 4) & EXT_G_MDIO_STAT_MBSY);
+	}
+
+	//nlm_print("[%s/%d] SENDING READ COMMAND \n", __func__, __LINE__);
+
+	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
+			       EXT_G_MDIO_CMD_SP
+			       | (phyaddr << EXT_G_MDIO_PHYADDR_POS)
+			       | (regidx << EXT_G_MDIO_REGADDR_POS)
+			       | 0x00 | (0<<18) | (0x7<<2));
+
+	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
+			       EXT_G_MDIO_CMD_SP
+			       | (phyaddr << EXT_G_MDIO_PHYADDR_POS)
+			       | (regidx << EXT_G_MDIO_REGADDR_POS)
+			       | 0x00 | (1<<18) | (0x7<<2));
+
+	/* poll master busy bit until it is not busy */
+	while(nlm_hal_read_mac_reg( block, intf_type,
+				    EXT_G0_MDIO_RD_STAT + bus * 4) & EXT_G_MDIO_STAT_MBSY) {
+		//nlm_print("[%d] EXT_G_MDIO_STAT_MBSY is SET!\n", __LINE__);
+	}
+
+	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
+			       EXT_G_MDIO_CMD_SP
+			       | (phyaddr << EXT_G_MDIO_PHYADDR_POS)
+			       | (regidx << EXT_G_MDIO_REGADDR_POS)
+			       | 0x00 | (0<<18) | (0x7<<2));
+
+	//nlm_print("[%d] EXT_G_MDIO_STAT_MBSY CLEARED!\n", __LINE__);
+
+	/* Issue the read command */
+	//nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,(1));
+	//nlm_print("[%s/%d] READ RETURNING...\n", __func__, __LINE__);
+
+	/* Read the data back */
+	return nlm_hal_read_mac_reg( block, intf_type, EXT_G0_MDIO_RD_STAT + bus * 4);
+}
+
+/**********************************************************************
+ *  nae_gmac_mdio_write -Write sgmac mii PHY register.
+ *
+ *  Input parameters:
+ *         bus          - bus number, nae has two external gmac bus: 0 and 1
+ *         phyaddr      - PHY to use
+ *         regidx       - register within the PHY
+ *         val          - data to write to register
+ *
+ *  Return value:
+ *         0 - success
+ ********************************************************************* */
+static int nae_gmac_mdio_write(int bus, int block, int intf_type, int phyaddr, int regidx, uint16_t val)
+{
+	uint32_t mdio_ld_cmd = nlm_hal_read_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4);
+
+	if (mdio_ld_cmd & EXT_G_MDIO_CMD_LCD) {
+		nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
+				       (mdio_ld_cmd & ~EXT_G_MDIO_CMD_LCD));
+		while(nlm_hal_read_mac_reg( block, intf_type,
+					    EXT_G0_MDIO_RD_STAT + bus * 4) & EXT_G_MDIO_STAT_MBSY);
+	}
+
+	/* load data into ctrl data reg
+	 */
+	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL_DATA + bus * 4, val);
+
+	//nlm_print("[%s/%d] SENDING WRITE COMMAND \n", __func__, __LINE__);
+
+	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
+			       EXT_G_MDIO_CMD_SP 	|
+			       (phyaddr << EXT_G_MDIO_PHYADDR_POS) 	|
+			       (regidx << EXT_G_MDIO_REGADDR_POS)		|
+			       0x00 | (0<<18) | (0x7<<2));
+
+	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
+			       EXT_G_MDIO_CMD_LCD | EXT_G_MDIO_CMD_SP 	|
+			       (phyaddr << EXT_G_MDIO_PHYADDR_POS) 	|
+			       (regidx << EXT_G_MDIO_REGADDR_POS)		|
+			       0x00 | (0<<18) | (0x7<<2));
+
+	/* poll master busy bit until it is not busy */
+	while(nlm_hal_read_mac_reg( block, intf_type,
+				    EXT_G0_MDIO_RD_STAT + bus * 4) & EXT_G_MDIO_STAT_MBSY);
+
+	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
+			       EXT_G_MDIO_CMD_SP 	|
+			       (phyaddr << EXT_G_MDIO_PHYADDR_POS) 	|
+			       (regidx << EXT_G_MDIO_REGADDR_POS)		|
+			       0x00 | (0<<18) | (0x7<<2));
+
+	//nlm_print("[%s/%d] WRITE RETURNING...\n", __func__, __LINE__);
+	return 0;
+}
+
+/**********************************************************************
+ *  nae_gmac_mdio_reset -Reset sgmii mdio module.
+ *
+ *  Input parameters:
+ *         bus - bus number, nae has two external gmac bus: 0 and 1
+ *
+ *  Return value:
+ *        0 - success
+ ********************************************************************* */
+static int nae_gmac_mdio_reset(int bus, int block, int intf_type)
+{
+	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
+			       EXT_G_MDIO_MMRST);
+	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
+			       0);
+	return 0;
+}
+int nlm_hal_mdio_read(int type, int bus,int block, int intf_type,
+		      int phyaddr, int regidx)
+{
+	if (type == NLM_HAL_INT_MDIO) {
+		return nae_int_gmac_mdio_read(bus, block, intf_type,
+					      phyaddr, regidx);
+	} else if (type == NLM_HAL_EXT_MDIO) {
+		return nae_gmac_mdio_read(bus, block, intf_type,
+					  phyaddr, regidx);
+	} else {
+		nlm_print("NAE_ERROR: Invalid type for MDIO read !!\n");
+		return -1;
+	}
+}
+
+int nlm_hal_mdio_write(int type, int bus, int block, int intf_type,
+		       int phyaddr, int regidx, uint16_t val)
+{
+	if (type == NLM_HAL_INT_MDIO) {
+		return nae_int_gmac_mdio_write(bus, block, intf_type,
+					       phyaddr, regidx, val);
+	} else if (type == NLM_HAL_EXT_MDIO) {
+		return nae_gmac_mdio_write(bus, block, intf_type,
+					   phyaddr, regidx, val);
+	} else {
+		nlm_print("NAE_ERROR: Invalid type for MDIO write !!\n");
+		return -1;
+	}
+}
+
+int nlm_hal_mdio_reset(int type, int bus, int block, int intf_type)
+{
+	if (type == NLM_HAL_INT_MDIO) {
+		return int_nae_gmac_mdio_reset(bus, block, intf_type);
+
+	} else if (type == NLM_HAL_EXT_MDIO) {
+		return nae_gmac_mdio_reset(bus, block, intf_type);
+
+	} else {
+		nlm_print("NAE_ERROR: Invalid type for MDIO reset !!\n");
+		return -1;
+	}
+}
+#if 0
+/**********************************************************************
+ *  nae_xgmac_mdio_read - Read xgmac phy register
+ *
+ *  Input parameters:
+ *         bus          - bus number, nae has two external xgmac bus: 0 and 1
+ *         phyaddr      - PHY's address
+ *         regidx       - index of register to read
+ *
+ *  Return value:
+ *         value read (16 bits), or 0xffffffff if an error occurred.
+ ********************************************************************* */
+static int nae_xgmac_mdio_read(int bus,int block, int intf_type, int phyaddr, int regidx)
+{
+
+        nlm_hal_write_mac_reg( block, intf_type, EXT_XG0_MDIO_CTRL + bus * 4,
+			       phyaddr<<EXT_XG_MDIO_CTRL_PHYADDR_POS
+			       | 1<<EXT_XG_MDIO_CTRL_MCDIV_POS
+			       | EXT_XG_MDIO_CTRL_CMD_LOAD
+			       | 1<<EXT_XG_MDIO_CTRL_MIIM_POS
+			       | 0x2<<EXT_XG_MDIO_CTRL_TA_POS
+			       | MDIO_OP_CMD_READ<<2);
+
+        /* poll master busy bit until it is not busy */
+        while(nlm_hal_read_mac_reg( block, intf_type,
+				    EXT_XG0_MDIO_RD_STAT + bus * 4) & EXT_XG_MDIO_STAT_MBSY);
+
+        return nlm_hal_read_mac_reg( block, intf_type,
+				     EXT_XG0_MDIO_CTRL_DATA + bus * 4) & 0xFFFF;
+}
+/**********************************************************************
+ *  nae_xgmac_mdio_write -Write xgmac mii PHY register.
+ *
+ *  Input parameters:
+ *         bus          - bus number, nae has two external xgmac bus: 0 and 1
+ *         phyaddr      - PHY to use
+ *         regidx       - register within the PHY
+ *         val          - data to write to register
+ *
+ *  Return value:
+ *         0 - success
+ ********************************************************************* */
+static int nae_xgmac_mdio_write(int bus, int block, int intf_type, int phyaddr, int regidx, int16_t val)
+{
+        /* load data to INT_MDIO_CTRL_DATA register*/
+        nlm_hal_write_mac_reg( block, intf_type,
+			       EXT_XG0_MDIO_CTRL_DATA+ bus * 4, val);
+
+        nlm_hal_write_mac_reg( block, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+			       phyaddr<<EXT_XG_MDIO_CTRL_PHYADDR_POS
+			       | 1<<EXT_XG_MDIO_CTRL_MCDIV_POS
+			       | EXT_XG_MDIO_CTRL_CMD_LOAD
+			       | 1<<EXT_XG_MDIO_CTRL_MIIM_POS
+			       | 0x2<<EXT_XG_MDIO_CTRL_TA_POS
+			       | MDIO_OP_CMD_WRITE<<2);
+
+        /* poll master busy bit until it is not busy */
+        while(nlm_hal_read_mac_reg( block, intf_type,
+				    EXT_XG0_MDIO_RD_STAT + bus * 4 )& EXT_XG_MDIO_STAT_MBSY);
+
+        return 0;
+}
+
+/**********************************************************************
+ *  nae_xgmac_mdio_reset -Reset sgmii PHY.
+ *
+ *  Input parameters:
+ *         bus - bus number, nae has two external xgmac bus: 0 and 1
+ *
+ *  Return value:
+ *        0 - success
+ ********************************************************************* */
+static int nae_xgmac_mdio_reset(int bus, int block, int intf_type)
+{
+        nlm_hal_write_mac_reg( block, intf_type,
+			       EXT_XG0_MDIO_CTRL + bus * 4,
+			       EXT_XG_MDIO_CTRL_RST);
+        return 0;
+}
+
+/**********************************************************************
+ *  nae_gmac_internal_mdio_read - Read internal mdio phy bus
+ *
+ *  Input parameters:
+ *         phyaddr      - PHY's address
+ *         regidx       - index of register to read
+ *
+ *  Return value:
+ *         value read (16 bits), or 0xffffffff if an error occurred.
+ ********************************************************************* */
+static int nae_gmac_internal_mdio_read(int block, int intf_type, int phyaddr, int regidx)
+{
+
+        nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL,
+			       phyaddr<<INT_MDIO_CTRL_PHYADDR_POS
+			       | 1<<INT_MDIO_CTRL_MCDIV_POS
+			       |INT_MDIO_CTRL_CMD_LOAD
+			       | 1<<INT_MDIO_CTRL_MIIM_POS
+			       | 0x2<<INT_MDIO_CTRL_TA_POS
+			       | MDIO_OP_CMD_READ<<2);
+
+        /* poll master busy bit until it is not busy */
+        while(nlm_hal_read_mac_reg( block, intf_type,
+				    INT_MDIO_RD_STAT) & INT_MDIO_STAT_MBSY);
+
+        return nlm_hal_read_mac_reg( block, intf_type,INT_MDIO_CTRL_DATA) & 0xFFFF;
+}
+
+/**********************************************************************
+ *  nae_gmac_internal_mdio_write -Write internal gmac mii PHY register.
+ *
+ *  Input parameters:
+ *         phyaddr      - PHY to use
+ *         regidx       - register within the PHY
+ *         val          - data to write to register
+ *
+ *  Return value:
+ *         0 - success
+ ********************************************************************* */
+static int nae_gmac_internal_mdio_write(int block, int intf_type, int phyaddr, int regidx, int16_t val)
+{
+
+        /* load data to INT_MDIO_CTRL_DATA register*/
+        nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL_DATA, val);
+        nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL,
+			       phyaddr<<INT_MDIO_CTRL_PHYADDR_POS
+			       | 1<<INT_MDIO_CTRL_MCDIV_POS
+			       |INT_MDIO_CTRL_CMD_LOAD
+			       | 1<<INT_MDIO_CTRL_MIIM_POS
+			       | 0x2<<INT_MDIO_CTRL_TA_POS
+			       | MDIO_OP_CMD_WRITE<<2);
+
+        /* poll master busy bit until it is not busy */
+        while(nlm_hal_read_mac_reg( block, intf_type,
+				    INT_MDIO_RD_STAT) & INT_MDIO_STAT_MBSY);
+
+        return 0;
+}
+
+/**********************************************************************
+ *  nae_gmac_internal_mdio_reset -Reset internal gmac PHY register.
+ *
+ *  Input parameters:
+ *
+ *  Return value:
+ *        0 - success
+ ********************************************************************* */
+static int nae_gmac_internal_mdio_reset(int block, int intf_type)
+{
+        nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL, INT_MDIO_CTRL_RST);
+        return 0;
+}
+#endif
+
+/**********************************************************************
+ *  nae_lane_reset_txpll
+ *
+ ********************************************************************* */
+
+
+/* Some inputs from Kaushik */
+
+void nae_lane_reset_txpll(int block, int lane_ctrl)
+{
+	uint32_t val = 0, saved_data;
+	int rext_sel = 0;
+
+	if (lane_ctrl != 4) {
+		int i;
+		rext_sel = (1 << 23);
+
+		val = nlm_hal_read_mac_reg( block, PHY, lane_ctrl);
+		val &= ~PHY_LANE_CTRL_RST; /* Set the reset (inverse logic) */
+		val |= rext_sel;
+
+		/* Resetting PMA for non-zero lanes */
+		nlm_hal_write_mac_reg( block, PHY, lane_ctrl,val);
+
+		for (i=0; i< 0x100000; ++i)
+			; /* empty loop */
+
+		val |= PHY_LANE_CTRL_RST; /* Unset the reset (inverse logic) */
+		nlm_hal_write_mac_reg( block, PHY, lane_ctrl,val);
+
+		val = 0;
+	}
+
+	/* Come out of reset for TXPLL */
+#if 0
+	saved_data = nlm_hal_read_mac_reg( block, PHY, lane_ctrl) & 0xFFC00000;
+#else
+	saved_data = nlm_hal_read_mac_reg( block, PHY, lane_ctrl) & 0xFFC00000;
+#endif
+
+	nlm_hal_write_mac_reg( block, PHY, lane_ctrl,         (0x66 << PHY_LANE_CTRL_ADDR_POS)
+			       | PHY_LANE_CTRL_CMD_READ
+			       | PHY_LANE_CTRL_CMD_START
+			       | PHY_LANE_CTRL_RST
+			       | rext_sel
+			       | val );
+	while (((val = nlm_hal_read_mac_reg( block, PHY, lane_ctrl)) & PHY_LANE_CTRL_CMD_PENDING));
+	val &= 0xFF;
+
+	/* set bit[4] to 0
+	 */
+	val &= ~(1 << 4);
+	nlm_hal_write_mac_reg( block, PHY, lane_ctrl,   (0x66 << PHY_LANE_CTRL_ADDR_POS)
+			       | PHY_LANE_CTRL_CMD_WRITE
+			       | PHY_LANE_CTRL_CMD_START
+			       | (0x0 << 19) /* (0x4 << 19) */
+			       | rext_sel
+			       | saved_data
+			       | val );
+	/* re-do */
+	nlm_hal_write_mac_reg( block, PHY, lane_ctrl,   (0x66 << PHY_LANE_CTRL_ADDR_POS)
+			       | PHY_LANE_CTRL_CMD_WRITE
+			       | PHY_LANE_CTRL_CMD_START
+			       | (0x0 << 19) /* (0x4 << 19) */
+			       | rext_sel
+			       | saved_data
+			       | val );
+
+	while(!((val = nlm_hal_read_mac_reg( block, PHY, lane_ctrl-PHY_LANE_0_CTRL)) & PHY_LANE_STAT_PCR));
+
+	/* Clear the Power Down bit */
+	val = nlm_hal_read_mac_reg( block, PHY, lane_ctrl);
+	val &= ~( (1 << 29) | (0x7ffff));
+	nlm_hal_write_mac_reg( block, PHY, lane_ctrl, (rext_sel | val));
+
+
+}
+
+/*
+  cplx configuration needed to be parsed from fdt tree and set at the time
+  before xlp_nae_config_lane_gmac can be called
+*/
+/**********************************************************************
+ *  nae_config_lane_gmac
+ *
+ ********************************************************************* */
+static void xlp_nae_config_lane_gmac(int cplx_mask)
+{
+	int block, lane_ctrl;
+	int cplx_lane_enable = LM_SGMII | (LM_SGMII << 4) | (LM_SGMII << 8) | (LM_SGMII << 12);
+	int lane_enable = 0;
+
+	/*  Lane mode progamming
+	 */
+	block = 7;
+	/* Complexes 0, 1 */
+	if (cplx_mask & 0x1) {
+		lane_enable |= cplx_lane_enable;
+	}
+	if (cplx_mask & 0x2) {
+		lane_enable |= (cplx_lane_enable << 16);
+	}
+	if (lane_enable) {
+		nlm_hal_write_mac_reg( block, LANE_CFG, LANE_CFG_CPLX_0_1,  lane_enable);
+		lane_enable = 0;
+	}
+	/* Complexes 2 3 */
+	if (cplx_mask & 0x4) {
+		lane_enable |= cplx_lane_enable;
+	}
+	if (cplx_mask & 0x8) {
+		lane_enable |= (cplx_lane_enable << 16);
+	}
+	nlm_hal_write_mac_reg( block, LANE_CFG, LANE_CFG_CPLX_2_3,   lane_enable);
+
+	/* Always enable complex 4 */
+	nlm_hal_write_mac_reg( block, LANE_CFG, LANE_CFG_CPLX_4, LM_SGMII << 4
+			       |  LM_SGMII );
+
+	/* serdes lane progaming
+	 */
+	for( block = 0; block < 4; block++)
+	{
+		if ((cplx_mask & (1 << block)) == 0) {
+			continue;
+		}
+		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_0_CTRL,  PHY_LANE_CTRL_RST
+				       | PHY_LANE_CTRL_PWRDOWN
+				       | (2 << PHY_LANE_CTRL_PHYMODE_POS));
+
+		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_1_CTRL,  PHY_LANE_CTRL_RST
+				       | PHY_LANE_CTRL_PWRDOWN
+				       | (2 << PHY_LANE_CTRL_PHYMODE_POS));
+
+		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_2_CTRL,  PHY_LANE_CTRL_RST
+				       | PHY_LANE_CTRL_PWRDOWN
+				       | (2 << PHY_LANE_CTRL_PHYMODE_POS));
+
+		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_3_CTRL,  PHY_LANE_CTRL_RST
+				       | PHY_LANE_CTRL_PWRDOWN
+				       | (2 << PHY_LANE_CTRL_PHYMODE_POS));
+
+	}
+	/* Always config complex 4 */
+	block = 4;
+	nlm_hal_write_mac_reg( block, PHY, PHY_LANE_0_CTRL,  PHY_LANE_CTRL_RST
+			       | PHY_LANE_CTRL_PWRDOWN
+			       | (2 << PHY_LANE_CTRL_PHYMODE_POS));
+
+	nlm_hal_write_mac_reg( block, PHY, PHY_LANE_1_CTRL,  PHY_LANE_CTRL_RST
+			       | PHY_LANE_CTRL_PWRDOWN
+			       | (2 << PHY_LANE_CTRL_PHYMODE_POS));
+
+	for( block = 0; block < 4; block++)
+	{
+		if ((cplx_mask & (1 << block)) == 0) {
+			continue;
+		}
+
+		for( lane_ctrl = PHY_LANE_0_CTRL; lane_ctrl <= PHY_LANE_3_CTRL; lane_ctrl++)
+			nae_lane_reset_txpll( block, lane_ctrl);
+	}
+	/* Always do this for Complex 4*/
+	block = 4;
+	for( lane_ctrl = PHY_LANE_0_CTRL; lane_ctrl <= PHY_LANE_1_CTRL; lane_ctrl++)
+		nae_lane_reset_txpll( block, lane_ctrl);
+
+	return;
+}
+
+
+void nlm_hal_mac_disable(int inf, int type)
+{
+        unsigned int mac_cfg1 = 0, xaui_cfg = 0;
+        unsigned int netwk_inf = 0;
+
+	switch(type) {
+		case SGMII_IF:
+			mac_cfg1 = read_gmac_reg(inf, MAC_CONF1);
+		        write_gmac_reg(inf , MAC_CONF1, mac_cfg1 & ~(0x5));
+              		netwk_inf = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
+              		write_gmac_reg(inf ,NETWK_INF_CTRL_REG, netwk_inf &  (~(TX_EN(1))));
+			break;
+		case XAUI_IF:
+			xaui_cfg=nlm_hal_read_mac_reg(inf, XGMAC, XAUI_CONFIG_1);
+			nlm_hal_write_mac_reg(inf, XGMAC, XAUI_CONFIG_1, xaui_cfg &
+                                                        (~(XAUI_CONFIG_TFEN | XAUI_CONFIG_RFEN)));
+			break;
+		case INTERLAKEN_IF:
+			break;
+	}
+}
+
+void nlm_hal_mac_enable(int inf, int type)
+{
+        unsigned int mac_cfg1 = 0, xaui_cfg = 0;
+        unsigned int netwk_inf = 0;
+
+        switch(type) {
+                case SGMII_IF:
+			netwk_inf  = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
+		        write_gmac_reg(inf , NETWK_INF_CTRL_REG, netwk_inf | TX_EN(1));
+        		mac_cfg1 = read_gmac_reg(inf, MAC_CONF1);
+        		write_gmac_reg(inf , MAC_CONF1, mac_cfg1 | (0x5));
+                        break;
+                case XAUI_IF:
+			xaui_cfg=nlm_hal_read_mac_reg(inf, XGMAC, XAUI_CONFIG_1);
+	                nlm_hal_write_mac_reg(inf, XGMAC, XAUI_CONFIG_1, xaui_cfg |
+							XAUI_CONFIG_TFEN | XAUI_CONFIG_RFEN );                              
+
+                        break;
+                case INTERLAKEN_IF:
+                        break;
+        }
+}
+
+#ifdef MARVELL_PHY_DEBUG
+static void dump_phy_regs(int inf)
+{
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x0);
+	nlm_print("Page0 Control Reg %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0));
+	nlm_print("Page0 Status Reg %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 1));
+        nlm_print("Page0 ExtStatus Reg %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 17));
+
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x2);
+	nlm_print("Page %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22));
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x2);
+
+        nlm_print("Page2 Control Reg %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0));
+        nlm_print("Page2 media Reg %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 10));
+	nlm_print("Page2 Reg26 (Bypass) %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 26));
+	nlm_print("Page2 SGMII sync %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 17));
+
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x0);
+}
+#endif
+
+void nlm_hal_init_ext_phy(int inf)
+{
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x02);
+	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 16, 0x0288);
+
+	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x8000);
+	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0x00, 0x8000);
+	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0x04, 0x01);
+
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22,0x00);
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0, 0x1000);
+
+	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0x00, 0);
+
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x02);
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 26, 0x8000);
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0, 0);
+
+	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0x00, 0);
+
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x00);
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0, 0xb000);
+
+	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0x00, 0x8000);
+}
+
+void nlm_hal_ext_phy_an(int inf)
+{
+        uint32_t i=0;
+        volatile uint16_t val, status, extstatus;
+        uint16_t speed, duplex = 0;
+
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0);
+        val = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0);
+        val |= 0x1200;
+        nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0, val);
+
+	nlm_print("Starting auto-negotiation on port %d\n",inf);
+
+	i=0;
+        do {
+		nlm_mdelay(100);
+                status = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 1);
+                extstatus = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 17);
+		if (((status & 0x0024) == 0x0024) && (extstatus & 0x0400))
+			break;
+		i++;
+        }while(i<50);
+
+        extstatus = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 17);
+        speed = (extstatus >> 14) & 0x3;
+        duplex =  (extstatus >> 13) & 0x1;
+
+#ifdef MARVELL_PHY_DEBUG
+        switch(speed) {
+                case SPEED_10M:
+                        nlm_print("physpeed 10 Mbps\t");
+                        break;
+                case SPEED_100M:
+                        nlm_print("physpeed 100 Mbps\t");
+                        break;
+                case SPEED_1000M:
+                        nlm_print("physpeed 1000 Mbps\t");
+                        break;
+                default:
+                        nlm_print("unknown speed !!! \t");
+        }
+        ((duplex == 1) ? nlm_print("Full duplex\n"):nlm_print("Half duplex\n"));
+	dump_phy_regs(inf);
+#endif
+}
+
+int nlm_hal_get_phy_status(int inf, uint32_t *speed, uint32_t *duplex)
+{
+	uint16_t extstatus;
+
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0);
+        extstatus = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 17);
+        *speed = (extstatus >> 14) & 0x3;
+        *duplex =  (extstatus >> 13) & 0x1;
+	if (extstatus & 0x0400) {
+	//	nlm_print("Link is up : %x\n",extstatus);
+		return 1;
+	}
+	else {
+	//	nlm_print("Link is down : %x\n",extstatus);
+		return 0;
+	}
+
+}
+
+void nlm_hal_config_sgmii_if(int inf)
+{
+	unsigned int mac_cfg1 = 0, mac_cfg2 = 0;
+	unsigned int netwk_inf = 0;
+	unsigned int ifmode, speed, duplex;
+
+	// Disable TX , Rx for now
+	mac_cfg1 = read_gmac_reg(inf, MAC_CONF1);
+	write_gmac_reg(inf , MAC_CONF1, mac_cfg1 & ~(0x5));
+	netwk_inf = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
+	write_gmac_reg(inf ,NETWK_INF_CTRL_REG, netwk_inf &  (~(1<<2)));
+
+#ifndef XLP_SIM
+	// Enable auto negotiation on PHY side
+	nlm_hal_ext_phy_an(inf);
+
+	// Read PHY status from extended status
+	nlm_hal_get_phy_status(inf,&speed, &duplex);
+
+#else
+	speed = SPEED_1000M;
+	duplex = 1;
+#endif
+	ifmode = ((speed == SPEED_1000M) ? INF_BYTE_MODE : INF_NIBBLE_MODE);
+
+	// Configure negotiated speed and mode
+        netwk_inf  = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
+        netwk_inf &= (~(0x3));
+	write_gmac_reg(inf , NETWK_INF_CTRL_REG, netwk_inf | SPEED(speed));
+
+        mac_cfg2 = read_gmac_reg(inf, MAC_CONF2);
+        mac_cfg2 &= (~(0x3 << 8));
+	write_gmac_reg(inf , MAC_CONF2,
+			       mac_cfg2            |
+			       INF_IFMODE(ifmode)     |
+			       INF_FULLDUP(duplex));
+
+        netwk_inf  = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
+        write_gmac_reg(inf , NETWK_INF_CTRL_REG, netwk_inf | (1<<15));
+
+        mac_cfg1 = read_gmac_reg(inf, MAC_CONF1);
+        write_gmac_reg(inf , MAC_CONF1, mac_cfg1 | (0x3 << 4));
+}
+
+void nlm_hal_sgmii_pcs_init(int sgmii_cplx_mask)
+{
+        nlm_hal_mdio_reset(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG);
+        nlm_print("Net:   Reset Internal MDIO\n");
+        nlm_hal_mdio_reset(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG);
+        nlm_print("Net:   Reset External MDIO\n");
+	xlp_nae_config_lane_gmac(sgmii_cplx_mask);
+	nlm_print("Net:   Completed PCS Configuration\n");
+}
+
+void nlm_hal_dtr_init(void)
+{
+    uint64_t base = nlm_hal_get_dev_base (XLP_DTR_NODE, XLP_DTR_BUS, XLP_DTR_DEVICE, XLP_DTR_FUNC);
+    /* Enable Master Control register */
+    nlm_hal_write_32bit_reg (base, XLP_DTR_MASTER_CONTROL_REG, 0x1);
+    /* Channel control registers */
+    nlm_hal_write_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_0, 0x3fe);
+    nlm_hal_write_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_1, 0x3fe);
+    nlm_hal_write_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_2, 0x3fe);
+    nlm_hal_write_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_3, 0x3fe);
+#ifdef DUMP
+    printf ("Base Register 0x%llx\n", (unsigned long long)base);
+    printf ("Master control 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_MASTER_CONTROL_REG));
+    printf ("Channel control0 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_0));
+    printf ("Channel control1 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_1));
+    printf ("Channel control2 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_2));
+    printf ("Channel control3 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_3));
+#endif
+}
+
+/* SAE SUPPORT
+ */
+void nlm_hal_set_sae_freq(int freq)
+{
+	int cnt, data, i;
+	unsigned int spr, spf;
+
+	data = 0x2;   // sae dfs decrement
+	if(freq == 500)
+		cnt = 4; // Need to compute this properly
+	else
+		cnt = 2;
+
+	for(i=0;i<cnt;i++){
+		nlm_hal_write_sys_reg(SYS_DFS_DIV_DEC_CTRL, data);
+	}
+
+	data = nlm_hal_read_sys_reg(PLL_CTRL);
+	spf = data >> 3 & 0x7f;
+	spr = data >> 1  & 0x3;
+
+	data = (nlm_hal_read_sys_reg(SYS_DFS_DIV_VALUE0) >> 4)  & 0xf;
+	nlm_print("SAE Frequency set to %dMHz (2X frequency %dMHz) \n",
+		  (int) DFS_OUTPUT(spr, spf, data) ,
+		  (int) DFS_OUTPUT(spr, spf, data) * 2);
+}
+
+static __inline__ uint64_t
+gen_cntl_instr(struct nlm_crypto_cipher_init_param *cip,
+	       struct nlm_crypto_auth_init_param *aip)
+{
+	uint64_t cntl_desc = 0;
+	if (aip) {
+		cntl_desc |= (unsigned long long) aip->hmac << 61;
+		cntl_desc |= (unsigned long long) aip->auth_alg << 52;
+		cntl_desc |= (unsigned long long) aip->auth_mode << 43;
+	}
+	if (cip) {
+		cntl_desc |= (unsigned long long) cip->cipher_alg << 34;
+		cntl_desc |= (unsigned long long) cip->cipher_mode << 25;
+		cntl_desc |=
+		    (unsigned long long) cip->arc4_cipher_key_len << 18;
+		cntl_desc |= (unsigned long long) cip->arc4_key_init << 17;
+		cntl_desc |= (unsigned long long) cip->cfb_mask;
+	}
+	return cntl_desc;
+}
+
+int
+nlm_hal_crypto_preprocess_request(void *cntrl_desc,
+				  struct nlm_crypto_cipher_init_param *cip,
+				  struct nlm_crypto_auth_init_param *aip)
+{
+	uint64_t *ptr = (uint64_t *) cntrl_desc;
+	unsigned char *temp_ptr = (unsigned char *) cntrl_desc;
+
+	ptr[0] = gen_cntl_instr(cip, aip);
+
+	temp_ptr += 8;
+
+	if (cip) {
+		if (cip->cipher_key) {
+			memcpy(temp_ptr, cip->cipher_key->buf,
+			       cip->cipher_key->iov_len);
+			temp_ptr += cip->cipher_key->iov_len;
+		}
+	}
+	if (aip) {
+		if (aip->auth_key) {
+			memcpy(temp_ptr, aip->auth_key->buf,
+			       aip->auth_key->iov_len);
+
+		}
+	}
+	return 0;
+}
+
+uint64_t
+gen_pkt_desc_0(struct nlm_crypto_param * cprm)
+{
+	uint64_t pkt = 0;
+
+	cprm->iv_len = (cprm->iv_len) ? (cprm->iv_len - 1) : 0;
+	pkt |= (unsigned long long) cprm->tls_proto << 63;
+	pkt |= (unsigned long long) cprm->hash_source << 62;
+	pkt |= (unsigned long long) cprm->hash_output_l3_alloc << 60;
+	pkt |= (unsigned long long) cprm->enc << 59;
+	pkt |= (unsigned long long) cprm->iv_len << 41;
+	pkt |= (unsigned long long) cprm->hash_dst_address_phy;
+
+	return pkt;
+}
+
+uint64_t
+gen_pkt_desc_1(struct nlm_crypto_param * cprm)
+{
+	uint64_t pkt = 0;
+
+	cprm->cipher_len = (cprm->cipher_len) ? (cprm->cipher_len - 1) : 0;
+	cprm->auth_len = (cprm->auth_len) ? (cprm->auth_len - 1) : 0;
+
+	pkt |= (unsigned long long) cprm->cipher_len << 32;
+	pkt |= (unsigned long long) cprm->auth_len;
+
+	return pkt;
+}
+
+uint64_t
+gen_pkt_desc_2(struct nlm_crypto_param * cprm)
+{
+	uint64_t pkt = 0;
+
+	pkt |= (unsigned long long) cprm->iv_offset << 45;
+	pkt |= (unsigned long long) cprm->cipher_bit_count << 42;
+	pkt |= (unsigned long long) cprm->cipher_offset << 22;
+	pkt |= (unsigned long long) cprm->hash_bit_count << 19;
+	pkt |= (unsigned long long) cprm->hash_clobber << 18;
+	pkt |= (unsigned long long) cprm->auth_offset;
+
+	return pkt;
+}
+
+uint64_t
+gen_pkt_desc_3(struct nlm_crypto_param * cprm)
+{
+	uint64_t pkt = 0;
+
+	pkt |= (unsigned long long) cprm->designer_freeback_id << 48;
+	pkt |= (unsigned long long) cprm->tag_len << 11;
+	pkt |= (unsigned long long) cprm->arc4_save_l3_alloc << 8;
+	pkt |= (unsigned long long) cprm->arc4_save_state << 6;
+	pkt |= (unsigned long long) cprm->hmac_external_pad_key << 5;
+
+	return pkt;
+}
+
+uint64_t
+gen_pkt_desc_4(struct nlm_crypto_param * cprm, uint32_t index)
+{
+	uint64_t pkt = 0;
+
+	pkt |= (unsigned long long) (cprm->src_phy[index].iov_len - 1) << 48;
+	pkt |= (unsigned long) cprm->src_phy[index].buf;
+
+	return pkt;
+}
+
+uint64_t
+gen_pkt_desc_5(struct nlm_crypto_param * cprm, uint32_t index)
+{
+	uint64_t pkt = 0;
+
+	pkt |= (unsigned long long) (cprm->dst_phy[index].iov_len - 1) << 48;
+	pkt |= (unsigned long long) cprm->cipher_output_l3_alloc << 46;
+	pkt |= (unsigned long long) cprm->cipher_clobber << 41;
+	pkt |= (unsigned long) cprm->dst_phy[index].buf;
+
+	return pkt;
+}
+
+/* Return error when parameter are invalid */
+int
+nlm_hal_crypto_send_request(uint32_t dst_vc, uint32_t fb_id,
+			    void *cntrl_desc, uint64_t cntrl_desc_phy,
+			    void *pkt_desc, uint64_t pkt_desc_phy,
+			    struct nlm_crypto_param *cprm, uint64_t tx_id)
+{
+	uint32_t i = 0, j = 0, pkt_desc_len = 0;
+	uint64_t *ptr = (uint64_t *) pkt_desc, entry0 = 0, entry1 = 0;
+
+	ptr[0] = gen_pkt_desc_0(cprm);
+	ptr[1] = gen_pkt_desc_1(cprm);
+	ptr[2] = gen_pkt_desc_2(cprm);
+	ptr[3] = gen_pkt_desc_3(cprm);
+
+	while (i < cprm->nr_frags) {
+		ptr[4 + 2 * i] = gen_pkt_desc_4(cprm, i);
+		ptr[4 + 2 * i + 1] = gen_pkt_desc_5(cprm, i);
+		i++;
+	}
+	i = 4 + cprm->nr_frags * 2;
+
+	while (j < cprm->designer_freeback_len)
+		ptr[i++] = cprm->designer_fb[j];
+
+	entry0 |= (unsigned long long) fb_id << 48;
+	if (cprm->send_designer_fb) {
+		entry0 |=
+		    (unsigned long long) cprm->designer_freeback_len << 46;
+		entry0 |= (unsigned long long) cprm->send_designer_fb << 48;
+		pkt_desc_len = 4;	/* Initialize for pakt desc length */
+	}
+	entry0 |= (unsigned long long) (cprm->cipher_key_len >> 3) << 40;
+	entry0 |= (unsigned long long) (cntrl_desc_phy >> 6);
+
+	pkt_desc_len += (4 + 2 * cprm->nr_frags);
+	pkt_desc_len = (pkt_desc_len / 2) - 1;
+
+	entry1 |= (unsigned long long) cprm->arc4_load_state << 63;
+	entry1 |= (unsigned long long) (cprm->auth_key_len >> 3) << 56;
+	entry1 |= (unsigned long long) pkt_desc_len << 43;
+	entry1 |= (unsigned long long) (pkt_desc_phy >> 6);
+
+	nlm_hal_send_msg3(dst_vc, 0 /*code */ , entry0, entry1, tx_id);
+
+	return 0;
+}
+
+/* Returns 64 bit transaction ID */
+uint64_t
+nlm_hal_crypto_process_response(uint32_t rx_vc, uint32_t code,
+				uint32_t src, uint64_t entry0,
+				uint64_t entry1, uint64_t * err_msg)
+{
+	*err_msg = entry1;
+	return entry0;
+}
+
+uint64_t
+nlm_hal_crypto_receive_response(uint32_t rx_vc, uint64_t * err_msg)
+{
+	uint32_t size, code, src;
+	uint64_t entry0 = 0, entry1 = 0;
+
+	nlm_hal_recv_msg2(rx_vc, &src, &size, &code, &entry0, &entry1);
+
+	return nlm_hal_crypto_process_response(rx_vc, code, src, entry0, entry1,
+					       err_msg);
+}
+#ifdef NLM_HAL_LINUX_KERNEL
+#include <linux/types.h>
+#include <linux/module.h>
+EXPORT_SYMBOL(nlm_hal_open_if);
+EXPORT_SYMBOL(naecfg_hack);
+EXPORT_SYMBOL(nlm_hal_is_xlp_a0);
+EXPORT_SYMBOL(nlm_hal_is_xlp_le);
+EXPORT_SYMBOL(nlm_hal_init_if_regs);
+EXPORT_SYMBOL(nlm_hal_init_nae_regs);
+EXPORT_SYMBOL(nlm_hal_load_ucore);
+EXPORT_SYMBOL(nlm_hal_sgmii_pcs_init);
+EXPORT_SYMBOL(nlm_hal_init_poe_regs);
+EXPORT_SYMBOL(nlm_hal_init_poe_distvec);
+EXPORT_SYMBOL(nlm_hal_crypto_preprocess_request);
+EXPORT_SYMBOL(nlm_hal_crypto_send_request);
+EXPORT_SYMBOL(nlm_hal_crypto_process_response);
+EXPORT_SYMBOL(nlm_hal_crypto_receive_response);
+EXPORT_SYMBOL(nlm_hal_get_phy_status);
+EXPORT_SYMBOL(nlm_hal_mdio_read);
+EXPORT_SYMBOL(nlm_hal_mdio_write);
+EXPORT_SYMBOL(nlm_hal_mac_enable);
+EXPORT_SYMBOL(nlm_hal_mac_disable);
+#endif
diff --git a/arch/mips/netlogic/common/nlm_hal_fmn_config.c b/arch/mips/netlogic/common/nlm_hal_fmn_config.c
new file mode 100644
index 0000000..665a17a
--- /dev/null
+++ b/arch/mips/netlogic/common/nlm_hal_fmn_config.c
@@ -0,0 +1,343 @@
+/*********************************************************************
+
+  Copyright 2003-2010 Netlogic Microsystem, Inc. ( Netlogic ). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#NLM_2#**********************************/
+#ifdef NLM_HAL_LINUX_KERNEL
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <asm/netlogic/hal/nlm_hal_fmn.h>
+#else
+#include "nlm_hal_fmn.h"
+#endif
+
+#define CPU		1
+#define PCIE	2
+#define GDX		3
+#define CMP		4
+#define CRYPTO	5
+#define POE		6
+#define NAE		7
+#define RSA		8
+
+#define INT_EN 			0x0800000000000000ULL
+#define OUTQ_EN			0x8000000000000000ULL
+#define SPILL_EN 		0x4000000000000000ULL
+#define LOW40MASK       	0x000000ffffffffffULL
+#define UP46MASK        	0xfffffffffffc0000ULL
+#define UP52MASK        	0xfffffffffffff000ULL
+#define LOW18MASK       	0x000000000003ffffULL
+#define LOW4KMASK       	0x00000000000003ffULL
+#define OUTQ_SIZE		32
+#define NUM_SGMII_PORT		18
+#define MAX_TXVC		524
+#define FMN_OUTQ		1024
+#define NUM_CORES		8
+#define NUM_CPU_VC		128
+#define NUM_CPU_POPQ		256
+#define NUM_THREADS		4
+#define NUM_VC_PER_THREAD	4
+
+/* 1024-bit bitmask as 16 64-bit longs.
+ * '1' => station @ that bit position
+ * is disabled.
+ */
+unsigned long long stids[16];
+
+/*********************************************************************
+ * nlm_hal_enable_vc_intr
+ *
+ * In xlp, there are 4 VC per cpu. Each vc can be configured to generate
+ * an interrupt when message receive event happens.
+ ********************************************************************/
+void nlm_hal_enable_vc_intr(int vc)
+{
+	uint64_t val = 0;
+	val = nlm_hal_read_outq_config(vc);
+	val &= ~((0x7ULL<<56) | (0x3ULL<<54) | (0x7ULL<<51) | (0x3ULL<<49));
+	val |=  (0ULL<<56)|(0x2ULL<<54)|(0x0ULL<<51)|(0x1ULL<<49);
+	nlm_hal_write_outq_config(vc, val);
+}
+
+/*********************************************************************
+ * nlm_hal_disable_vc_intr
+*********************************************************************/
+void nlm_hal_disable_vc_intr(int vc)
+{
+	uint64_t val = 0;
+	val = nlm_hal_read_outq_config(vc);
+	val = val & ~((0x3ULL<<54) | (0x3ULL<<49));
+	nlm_hal_write_outq_config(vc, val);
+}
+
+/*********************************************************************
+ * nlm_hal_set_fmn_interrupt
+ *
+ * setup cp2 msgconfig register for fmn interrup vector as 6
+ *
+ ********************************************************************/
+void nlm_hal_set_fmn_interrupt(int irq)
+{
+	uint32_t val;
+	/* Need write interrupt vector to cp2 msgconfig register */
+
+	val =  _read_32bit_cp2_register(XLP_MSG_CONFIG_REG);
+	val &= ~(0x1f << 16);
+	val |= (irq << 16);
+	_write_32bit_cp2_register(XLP_MSG_CONFIG_REG, val);
+
+}
+
+static __inline__ void nlm_hal_write_credit(int src, int dst, uint32_t credits)
+{
+	uint64_t regaddr = nlh_qid_to_virt_addr(XLP_CREDIT_CONFIG_REG, 0);
+	uint64_t value = (((src) & 0x3ff) | (((dst) & 0xfff) << 12) | (((credits) & 0xffff) << 24));
+
+	nlh_write_cfg_reg64(regaddr, value);
+}
+
+/* Clear a particular bit within the
+ * 1024 bitmaks array stids.
+ * Note: not a generic routine.
+ */
+static void clearbit(int bitnum) {
+
+	int index = bitnum / 64;
+	stids[index] &= ~(1ULL << (bitnum % 64));
+}
+
+void enable_interface(int interface, short value) {
+
+	switch (interface) {
+		case CPU: {
+				int i;
+				for (i=0; i<8; i++) {
+					if ((value  & (1 << i)) == 0)
+						clearbit(i << 4);
+				}
+			} break;
+		case PCIE: {
+				int i;
+				for (i=0; i<4; i++) {
+					if ((value  & (1 << i)) == 0)
+						clearbit(XLP_STNID_PCIE0 + (i << 1));	
+				}
+			} break;
+		case GDX: {
+				if (value == 0)
+					clearbit(XLP_STNID_GDX);	
+			} break;
+		case CMP: {
+				int i;
+				for (i=0; i<4; i++) {
+					if ((value  & (1 << i)) == 0)
+						clearbit(XLP_STNID_CMP + i);	
+				}
+			} break;
+		case CRYPTO: {
+				int i;
+				for (i=0; i<12; i++) {
+					if ((value  & (1 << i)) == 0)
+						clearbit(XLP_STNID_CRYPTO + i);	
+				}
+			} break;
+		case POE: {
+				if (value == 0)
+					clearbit(XLP_STNID_POE);	
+			} break;
+		case NAE: {
+				if (value == 0)
+					clearbit(XLP_STNID_NAE_TX);	
+			} break;
+		case RSA: {
+				int i;
+				for (i=0; i<9; i++) {
+					if ((value  & (1 << i)) == 0)
+						clearbit(XLP_STNID_RSA_ECC + i);	
+				}
+			} break;
+		default:
+			nlm_print("Error! Configuring Credits for Unknown Interface.\n");
+			break;
+	}
+}
+
+/* Based on the (un)set bits from the EFUSE CFG Regs,
+ * create a bitmask representing 0-1023 station IDs
+ * which can then be used to check whether to send
+ * credits to or not. This is a one-time operation.
+ */
+void stids_toskip(void) {
+
+	int i;
+
+	for (i=0; i<16; i++)
+		stids[i] = ~0ULL;	/* init to all disabled */
+
+	enable_interface(CPU,     nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG0) & 0xff);
+	enable_interface(PCIE,   (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG1) >> 3) & 0xf);
+	enable_interface(GDX,    (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG1) >> 8) & 0x1);
+	enable_interface(CMP,    (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG1) >> 9) & 0xf);
+	enable_interface(CRYPTO, (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG1) >> 14) & 0xfff);
+	enable_interface(POE,    (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG1) >> 27) & 0x1);
+	enable_interface(NAE,    (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG1) >> 28) & 0x1);
+	enable_interface(RSA,    (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG2)) & 0x1ff);
+}
+
+static void nlm_hal_write_fmn_credit(uint32_t credits)
+{
+	int src, qid;
+
+	volatile int index;
+
+	/* this populates the global array 'stids'
+	 * with a '1' representing a disabled station ID.
+	 */
+	stids_toskip();
+
+	for (src = 0; src <= XLP_STNID_NAE_TX; src++) {
+		/* check if bitposition src == 1 in
+		 * the dst_skip_bitmask. if so, continue
+		 */
+		index = src / 64;
+
+		if ((stids[index] >> (src % 64)) & 0x1) {
+			continue;
+		}
+
+		/* only enabled stations will reach here
+		 */
+		for (qid = 0; qid < 1024; qid++)
+			nlm_hal_write_credit(src, qid, credits);
+	}
+}
+
+/*********************************************************************
+ * nlm_hal_fmn_init
+ *
+ * setup 1024 outq, set credit from cpu to io,  io to io, and io to
+ * cpu
+ ********************************************************************/
+#if defined(NLM_HAL_UBOOT) || defined(NLM_HAL_NETLBOOT)
+
+/*********************************************************************
+ * nlm_hal_setup_outq
+ *
+ * In xlp, there is 1024 receive message queues for fmn network. The
+ * queue, allocated to cpu and high speed IO device, identified by
+ * their vc number. When A send B a FMN message, receive VC is dest
+ * number A need addressing. This function is to config each queue with
+ * initial defaule value
+ *
+ * Total spill size for each Q is 16KB
+ * This allows for 1024 q entries with 16B of entry size
+ * This assumes credits across all sending agents to this queue is < 1024
+ ********************************************************************/
+static void nlm_hal_setup_outq(uint64_t tiny_spill_base, uint32_t tiny_size, uint32_t credits)
+{
+	uint32_t qid;
+	uint64_t val;
+
+	const uint64_t spill_base = 256 << 20;
+	uint64_t q_spill_base = 0;
+	uint64_t q_spill_start_page = 0;
+	const int q_spill_pages = 4;
+	const uint32_t q_spill_page_size = 4 << 10; /* 4KB */
+
+	const uint32_t ram_base = 0;
+	uint32_t q_ram_base = 0;
+	uint32_t q_ram_start_page = 0;
+	const int q_ram_pages = 1;
+	const uint32_t q_ram_page_entries = 32; /* entries, not bytes */
+
+	/* Configure all 1024 Queues! */
+	for( qid = 0; qid < 1024; qid++ )
+	{
+		/* Enable all output queues and spill on all queues */
+		val = OUTQ_EN|SPILL_EN;
+
+		/* Enable interrupts for cpu Queues */
+		if ( (qid >= 0) && (qid < 128))
+			val |= INT_EN|(0ULL<<56)|(0x2ULL<<54)|(0x0ULL<<51)|(0x1ULL<<49);
+
+		/***************************************************************
+		 * Configuration of on-chip RAM area
+		 **************************************************************
+		 */
+		q_ram_base = ram_base + (qid * q_ram_pages * q_ram_page_entries);
+
+		val |= ( ((q_ram_base >> 10) & 0x1f) << 10); /* [14:10] of q_ram_base */
+
+		q_ram_start_page = (q_ram_base >> 5) & 0x1f; /* [9:5] of q_ram_base */
+		val |= (q_ram_start_page << 0);
+		val |= ( (q_ram_start_page + q_ram_pages - 1) << 5) ;
+
+		/***************************************************************
+		 * Configuration of spill area
+		 **************************************************************
+		 */
+		q_spill_base = spill_base + (qid * q_spill_pages * q_spill_page_size);
+
+		val |= ( ((q_spill_base >> 18) & 0x3fffff) << 27); /* [39:18] of q_spill_base */
+
+		q_spill_start_page = (q_spill_base >> 12) & 0x3f; /* [17:12] of q_spill_base */
+		val |= (q_spill_start_page << 15);
+		val |= ( (q_spill_start_page + q_spill_pages - 1) << 21);
+
+		/* Write to the configuration register */
+		nlm_hal_write_outq_config(qid, val);
+	}
+}
+
+
+void nlm_hal_fmn_init(uint64_t spill_base, uint32_t size, uint32_t credits)
+{
+	nlm_print("*** Firmware Configuration of FMN ***\n");
+
+	/* verify out_q config
+	 */
+	nlm_hal_setup_outq(spill_base, size, credits);
+	nlm_hal_write_fmn_credit(credits);
+}
+
+#else /* !UBOOT,NETLBOOT */
+
+void nlm_hal_fmn_init(uint64_t spill_base, uint32_t size, uint32_t credits)
+{
+	nlm_print("***** OS Configuration of FMN ******\n");
+	nlm_hal_write_fmn_credit(credits);
+
+}
+#endif
+
+#ifdef NLM_HAL_LINUX_KERNEL
+#include <linux/types.h>
+#include <linux/module.h>
+EXPORT_SYMBOL(nlm_hal_disable_vc_intr);
+EXPORT_SYMBOL(nlm_hal_enable_vc_intr);
+EXPORT_SYMBOL(nlm_hal_fmn_init);
+#endif
diff --git a/arch/mips/netlogic/common/nlm_hal_nae.c b/arch/mips/netlogic/common/nlm_hal_nae.c
new file mode 100644
index 0000000..9649d9e
--- /dev/null
+++ b/arch/mips/netlogic/common/nlm_hal_nae.c
@@ -0,0 +1,1679 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include "nlm_hal_fmn.h"
+#include "nlm_hal_nae.h"
+#include "libfdt.h"
+#include "fdt_helper.h"
+
+#define VAL_UCORE_RESET(x) ( ( (x) &0xffff) << 8)
+
+struct nlm_hal_nae_config nae_cfg;
+int cntx2port[MAX_NAE_CONTEXTS];
+static int nae_reset_done = 0;
+static void xlp_nae_config_interlaken(int blk,int port, int num_lanes);
+static void xlp_nae_config_xaui(int block, int port);
+static unsigned int ucore_shared_scratch[128];
+static unsigned int ucore_shared_scratch_words;
+
+int nlm_hal_write_ucore_shared_mem(unsigned int *data, int words)
+{
+	int i = 0;
+	if(words>128)
+		return -1;
+	for (i=0; i<words; ++i) {
+		ucore_shared_scratch[i] = data[i];
+	}
+	ucore_shared_scratch_words = words;
+	return 0;
+}
+
+/*
+ * Temporary direct ucore configuration. HAL needs to support stop and restart
+ * of ucores before reloading code
+ */
+static int local_load_ucore(int ucore_mask, unsigned int *opcodes, int num_opcodes)
+{
+	int mask = ucore_mask & NAE_UCORE_MASK;
+	unsigned int id = 0;
+	int write_cmd = 1;
+	int i;
+	volatile uint32_t ucore_cfg = 0;
+
+	/* Stop all ucores */
+	if (nae_reset_done == 0) { /* Skip the Ucore reset if NAE reset is done */
+		nlm_print("Stopping and Resetting all ucore...\n");
+
+		ucore_cfg = nlm_hal_read_nae_reg(RX_UCORE_CFG);
+		nlm_hal_write_nae_reg(RX_UCORE_CFG, ucore_cfg | (1 << 24));
+
+		nlm_hal_write_nae_reg(UCORE_IFACE_MASK_CFG, ucore_spray_config(16, 0, write_cmd));
+
+		/* poll for ucore to get in to a wait state */
+		for(;;) {
+			ucore_cfg = nlm_hal_read_nae_reg(RX_UCORE_CFG);
+			if (ucore_cfg & (1 << 25)) break;
+		}
+		nlm_print("Ucore Reset Complete\n");
+	}
+
+	nlm_print("Loading ucores (mask = 0x%04x)\n", mask);
+
+	while (id < MAX_NAE_UCORES) {
+
+		if ((mask & (1 << id)) == 0) {
+			id++;
+			continue;
+		}
+
+		for (i=0; i < num_opcodes; ++i) {
+			nlm_hal_write_ucode(id, (i * 4), opcodes[i]);
+		}
+		if(num_opcodes & 0x1){
+			/* Add 'nop' if total number of instructions are odd */
+			nlm_hal_write_ucode(id, (i * 4), 0x0);
+		}
+		id++;
+	}
+	/* Download u-core shared memory data*/
+	if(ucore_shared_scratch_words){
+		ucore_cfg = nlm_hal_read_nae_reg(RX_UCORE_CFG);
+		/*set iram to 0*/
+		nlm_hal_write_nae_reg(RX_UCORE_CFG, ucore_cfg & ~(1<<7));
+		for (i=0; i<ucore_shared_scratch_words; ++i) {
+			nlm_hal_write_ucode(0, (i * 4), ucore_shared_scratch[i]);
+		}
+		/*restore ucore_cfg*/
+		nlm_hal_write_nae_reg(RX_UCORE_CFG, ucore_cfg);
+	}
+
+	/* Enable per-domain ucores */
+        ucore_cfg = nlm_hal_read_nae_reg(RX_UCORE_CFG);
+
+	/* write one to reset bits to put the ucores in reset */
+	ucore_cfg = ucore_cfg | (VAL_UCORE_RESET(ucore_mask));
+        nlm_hal_write_nae_reg(RX_UCORE_CFG, ucore_cfg);
+
+	/* write zero to reset bits to pull them out of reset */
+	ucore_cfg = ucore_cfg & (~VAL_UCORE_RESET(ucore_mask)) & ~(1 << 24);
+        nlm_hal_write_nae_reg(RX_UCORE_CFG, ucore_cfg);
+
+	nlm_hal_write_nae_reg(UCORE_IFACE_MASK_CFG, ucore_spray_config(16, 0xffff, write_cmd));
+	return 0;
+}
+
+#define UCORE_SRC_NODE(id) "/soc/nae-cfg/ucore/src@"#id
+
+/* Currently only one microcore cfile (given under src@1 node is supported */
+#define GET_UCORE_PROP(prop, buf, len)					\
+	copy_fdt_prop(fdt, UCORE_SRC_NODE(1), prop, PROP_CELL, buf, len)
+
+/* Currently only suports only one Ucore file across all ucores */
+static void parse_ucore_config(void *fdt)
+{
+	int size = 0;
+	unsigned int *uc_opcodes;
+	uint32_t uc_mask = 0, num_opcodes = 0;
+
+	/* Domain specific ucore mask */
+	GET_UCORE_PROP("mask", &uc_mask, sizeof(uint32_t));
+
+	GET_UCORE_PROP("num-opcodes", &num_opcodes, sizeof(uint32_t));
+
+	size = sizeof(uint32_t) * num_opcodes;
+	uc_opcodes = nlm_malloc(size);
+	if (!uc_opcodes) {
+		nlm_print("[%s] Unable to allocate temporary memory\n", __func__);
+		return;
+	}
+
+	GET_UCORE_PROP("opcodes", uc_opcodes, size);
+
+	local_load_ucore(uc_mask, (unsigned int *)uc_opcodes, num_opcodes);
+
+	nlm_free(uc_opcodes);
+}
+
+#define POE_NODE "/soc/nae-cfg/poe/regs"
+#define GET_POE_PROP(prop, buf, len)					\
+	copy_fdt_prop(fdt, POE_NODE, prop, PROP_CELL, buf, len)
+
+#define POE_MAX_LOC_32BIT_CHUNKS 192
+static void init_poe_loc_msg_storage(void)
+{
+	int i;
+	int reg_id = LOCAL_FBP_BASE;
+	for (i = 0; i < POE_MAX_LOC_32BIT_CHUNKS; ++i) {
+		/* Selects 32 entries via bit mask */
+		nlm_hal_write_poe_pcim_reg(reg_id, 0xffffffff);
+		reg_id++;
+	}
+}
+
+static void parse_poe_config(void *fdt)
+{
+	int size = 0;
+	uint32_t *poe_regs;
+	uint32_t num_regs;
+	int sz_32bit = sizeof(uint32_t);
+	char mode_str[20];
+
+	copy_fdt_prop(fdt, "/soc/nae-cfg/poe", "mode", PROP_STR, mode_str, 20);
+
+	
+	if (strcmp(mode_str, "bypass") != 0) { // Non bypass mode
+		/* Local Message Storage (6K): Always Enabled! */
+		init_poe_loc_msg_storage();
+		nlm_print("Finished POE mode %s memory  carving\n", mode_str);
+	} else {
+		nlm_print("Configuring POE in bypass mode\n");
+	}
+
+	GET_POE_PROP("num-regs", &num_regs, sz_32bit);
+
+	/* Each tuple has 3 elements. (type, index, val) hence the multiplication by 3 */
+	size = sizeof(uint32_t) * num_regs * 3;
+	poe_regs = nlm_malloc(size);
+	if (!poe_regs) {
+		nlm_print("[%s] Unable to allocate temporary memory\n", __func__);
+		return;
+	}
+
+	GET_POE_PROP("regs", poe_regs, size);
+
+	nlm_hal_init_poe_regs(poe_regs, num_regs);
+
+	nlm_free(poe_regs);
+}
+
+#define GET_CPU_PROP(node_str, prop, buf, len)				\
+	copy_fdt_prop(fdt, node_str, prop, PROP_CELL, buf, len)
+
+static void parse_fdt_cpu_config(void *fdt, int dom_id)
+{
+	char node_str[32];
+
+	snprintf(node_str, 32, "/doms/dom@%d/cpu", dom_id);
+
+	if (GET_CPU_PROP(node_str, "nae-rx-vc", &nae_cfg.rx_vc, sizeof(uint32_t)) < 0) {
+		nlm_print("Unable to parse nae_rx_vc, using defaults\n");
+		goto out;
+	}
+
+	if (GET_CPU_PROP(node_str, "nae-fb-vc", &nae_cfg.fb_vc, sizeof(uint32_t)) < 0) {
+		nlm_print("Unable to parse nae_rx_vc, using defaults\n");
+		goto out;
+	}
+
+ out:
+
+	return;
+}
+
+int rely_on_firmware_config = 0;
+
+#define NAE_NODE "/soc/nae-cfg"
+#define NAE_GLOBAL_NODE "/soc/nae-cfg/global-nae-regs"
+
+#define GET_NAE_PROP(prop, buf, len)					\
+	copy_fdt_prop(fdt, NAE_NODE, prop, PROP_CELL, buf, len)
+
+#define GET_NAE_STR_PROP(prop, buf, len)					\
+	copy_fdt_prop(fdt, NAE_NODE, prop, PROP_STR, buf, len)
+
+#define GET_NAE_GLOBAL_PROP(prop, buf, len)					\
+	copy_fdt_prop(fdt, NAE_GLOBAL_NODE, prop, PROP_CELL, buf, len)
+
+#define MAX_PROP_LEN 30
+/* Temporarily specifying these sizes here.
+   These will be moved to FDT soon
+*/
+#define NLM_STG2_FIFO_SZ   200
+#define NLM_EH_FIFO_SZ     200
+#define NLM_FROUT_FIFO_SZ  200
+#define NLM_MS_FIFO_SZ     200
+#define NLM_PKT_FIFO_SZ    200
+#define NLM_PKTLEN_FIFO_SZ 200
+
+#define MAX_STG2_OFFSET           0x7F
+#define MAX_EH_OFFSET             0x7F
+#define MAX_FREE_OUT_OFFSET       0x7F
+#define MAX_MS_OFFSET             0x1F
+#define MAX_PMEM_OFFSET           0x7FE
+
+static void config_egress_fifo_carvings(int start_ctxt, int num_ctxts)
+{
+	int i, limit = start_ctxt + num_ctxts;
+	uint32_t data = 0;
+	uint32_t start = 0, size, offset;
+	static uint32_t cur_start[6] = { 0, 0, 0, 0, 0, 0};
+
+	/* Stage 2 FIFO */
+	start = cur_start[0];
+	for(i=start_ctxt;i<limit;i++) {
+		size   = NLM_STG2_FIFO_SZ;
+		if(size) offset = size -1; else offset = size ;
+		if(offset > MAX_STG2_OFFSET)
+			offset = MAX_STG2_OFFSET ;
+		data =   offset << 23  |
+			start << 11 |
+			i << 1      |
+			1;
+		nlm_print("program_nae_stg2_pmem: ctxt_num:%d start:%d size:%d\n", i, start, size);
+		nlm_hal_write_nae_reg(STG2_PMEM_PROG, data);
+		start+= size;
+	}
+	cur_start[0] = start;
+
+	/* EH FIFO */
+	start  = cur_start[1];
+	for(i=start_ctxt;i<limit;i++){
+		size   = NLM_EH_FIFO_SZ;
+		if(size) offset = size -1; else offset = size ;
+		if(offset > MAX_EH_OFFSET)
+			offset = MAX_EH_OFFSET ;
+		data =   offset << 23  |
+			start << 11 |
+			i << 1      |
+			1;
+		nlm_print("program_nae_eh_pmem: ctxt_num:%d start:%d size:%d\n", i, start, size);
+		nlm_hal_write_nae_reg(EH_PMEM_PROG, data);
+		start+= size;
+	}
+	cur_start[1] = start;
+
+	/* FROUT FIFO */
+	start  = cur_start[2];
+	for(i=start_ctxt;i<limit;i++){
+		size   = NLM_FROUT_FIFO_SZ;
+		if(size) offset = size -1; else offset = size ;
+		if(offset > MAX_FREE_OUT_OFFSET)
+			offset = MAX_FREE_OUT_OFFSET ;
+		data =   offset << 23  |
+			start << 11 |
+			i << 1      |
+			1;
+		nlm_print("program_nae_frout_pmem: ctxt_num:%d start:%d size:%d\n", i, start, size);
+		nlm_hal_write_nae_reg(FREE_PMEM_PROG, data);
+		start+= size;
+	}
+	cur_start[2] = start;
+
+	/* MS FIFO */
+	start  = cur_start[3];
+	for(i=start_ctxt;i<limit;i++){
+		size   = NLM_MS_FIFO_SZ;
+		if(size) offset = size -1; else offset = size ;
+		if(offset > MAX_MS_OFFSET)
+			offset = MAX_MS_OFFSET ;
+		data =   offset << 22  | 		// FIXME in PRM
+			start << 11 |
+			i << 1      |
+			1;
+		nlm_print("program_nae_ms_pmem: ctxt_num:%d start:%d size:%d\n", i, start, size);
+		nlm_hal_write_nae_reg(STR_PMEM_CMD, data);
+		start+= size;
+	}
+	cur_start[3] = start;
+
+	/* PKT FIFO */
+	start  = cur_start[4];
+	for(i=start_ctxt;i<limit;i++){
+		size   = NLM_PKT_FIFO_SZ;
+		if(size) offset = size -1; else offset = size ;
+		if(offset > MAX_PMEM_OFFSET)
+			offset = MAX_PMEM_OFFSET ;
+		nlm_hal_write_nae_reg(TX_PKT_PMEM_CMD1, offset);
+
+		data =   start << 11 |
+			i << 1      |
+			1;
+		nlm_print("program_nae_pkt_pmem: ctxt_num:%d size:%d\n", i, size);
+		nlm_hal_write_nae_reg(TX_PKT_PMEM_CMD0, data);
+		start+= size;
+	}
+	cur_start[4] = start;
+
+	/* PKT LEN FIFO */
+	start  = cur_start[5];
+	for(i=start_ctxt;i<limit;i++){
+		size   = NLM_PKTLEN_FIFO_SZ;
+		if(size) offset = size -1; else offset = size ;
+		data =   offset  << 22 |
+			start << 11 |
+			i << 1      |
+			1;
+		nlm_print("program_nae_plen_pmem: ctxt_num:%d size:%d\n", i, size);
+		nlm_hal_write_nae_reg(TX_PKTLEN_PMEM_CMD, data);
+		start+= size;
+	}
+	cur_start[5] = start;
+}
+/* Temporarily specifying these credits here.
+   These will be moved to FDT soon
+*/
+#define NLM_STG1_2_CREDIT     200
+#define NLM_STG2_EH_CREDIT    200
+#define NLM_STG2_FROUT_CREDIT 200
+#define NLM_STG2_MS_CREDIT    200
+static void config_egress_fifo_credits(int start_ctxt, int num_ctxts)
+{
+	int i, limit = start_ctxt + num_ctxts;
+	uint32_t data, credit, max_credit;
+
+	/* Stage1 -> Stage2 */
+	max_credit = MAX_STG2_OFFSET + 1;
+	for(i=start_ctxt;i<limit;i++){
+		credit = NLM_STG1_2_CREDIT;
+		if (credit > max_credit)
+			credit = max_credit;
+
+		data =   credit << 16  |
+			i << 4      |
+			1;
+		nlm_print("program_nae_stg1_2_stg2_credit: ctxt_num:%d credit:%d\n", i, credit);
+		nlm_hal_write_nae_reg(STG1_STG2CRDT_CMD, data);
+	}
+
+	/* Stage2 -> EH */
+	max_credit = MAX_EH_OFFSET+1;
+	for(i=start_ctxt;i<limit;i++){
+		credit = NLM_STG2_EH_CREDIT;
+		if (credit > max_credit)
+			credit = max_credit;
+
+		data =   credit << 16  |
+			i << 4      |
+			1;
+		nlm_print("program_nae_stg2_2_eh_credit: ctxt_num:%d credit:%d\n", i, credit);
+		nlm_hal_write_nae_reg(STG2_EHCRDT_CMD, data);
+	}
+
+	/* Stage2 -> Frout */
+	max_credit = MAX_FREE_OUT_OFFSET+1;
+	for(i=start_ctxt;i<limit;i++){
+		credit = NLM_STG2_FROUT_CREDIT;
+		if (credit > max_credit)
+			credit = max_credit;
+
+		data =   credit << 16  |
+			i << 4      |
+			1;
+		nlm_print("program_nae_stg2_2_frout_credit: ctxt_num:%d credit:%d\n", i, credit);
+		nlm_hal_write_nae_reg(STG2_FREECRDT_CMD, data);
+	}
+
+	/* Stage2 -> MS */
+	max_credit = MAX_MS_OFFSET + 1;
+	for(i=start_ctxt;i<limit;i++){
+		credit = NLM_STG2_MS_CREDIT;
+		if (credit > max_credit)
+			credit = max_credit;
+
+		data =   credit << 16  |
+			i << 4      |
+			1;
+		nlm_print("program_nae_stg2_2_ms_credit: ctxt_num:%d credit:%d\n", i, credit);
+		nlm_hal_write_nae_reg(STG2_STRCRDT_CMD, data);
+	}
+}
+
+#define NUM_INGRESS_PORTS 19
+static uint32_t context_to_port_channel(uint32_t context)
+{
+	uint32_t data, i;
+	uint32_t rx_if_base_config, rx_if_base_config1, base, ctxt;
+
+	ctxt  = context - XLP_NET_TX_VC_BASE;
+
+        /* Set it to non-existent port */
+	data = 19 << 10 ;            
+	for(i=0;i<NUM_INGRESS_PORTS;i++){
+		base = nlm_hal_read_nae_reg(RX_IF_BASE_CONFIG_0 + i/2);
+
+		rx_if_base_config = base & 0xffff;
+		rx_if_base_config1 = (base >> 16) & 0xffff;
+
+		if( (i == 19) && (ctxt >= rx_if_base_config) ) {
+			data = (rx_if_base_config << 10) |
+				(ctxt - rx_if_base_config);
+		} else if( (ctxt >= rx_if_base_config) && (ctxt < rx_if_base_config1) ) {
+			data = (i << 10) |
+				(ctxt - rx_if_base_config);
+			break;
+		}
+	}
+	return data;
+}
+
+#define NUM_EGRESS_PORTS 18
+#define TX_IF_BURST_MAX  2048
+#define DRR_QUANTA       2048
+#define SP_EN            0
+#define SP_NUM           0
+
+void config_egress_drr(int start_ctxt, int end_ctxt)
+{
+	uint32_t data, context, port, channel;
+	uint32_t limit = end_ctxt + 1;
+
+	for (port=0; port<NUM_EGRESS_PORTS; port++) {
+		data  = (TX_IF_BURST_MAX << 12) |
+			(port    << 4) |
+			1;
+		nlm_hal_write_nae_reg(TX_IFACE_BURSTMAX_CMD, data);
+	}
+
+	for (context = start_ctxt; context<limit; context++){
+
+		data = DRR_QUANTA;
+		nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD1, data);
+
+		data = context_to_port_channel(context);
+		port = data >> 10;
+		channel   = data & 0xff;
+
+		data   = channel << 20 |
+			port    << 15 |
+			context << 5  |
+			SP_EN << 4        |
+			SP_NUM << 1    |
+			1;
+		nlm_print("context:%d port:%d channel:%d \n",
+			       context, port, channel);
+		nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD0, data);
+	}
+}
+
+static void config_egress(int context_base, int port)
+{
+	unsigned int offset =0, data = 0;
+
+	config_egress_fifo_carvings(context_base, nae_cfg.ports[port].num_channels);
+	config_egress_fifo_credits (context_base, nae_cfg.ports[port].num_channels);
+
+	switch (nae_cfg.ports[port].iftype)
+	{
+		case INTERLAKEN_IF:
+			for(offset = 0; offset < nae_cfg.ports[port].num_channels; offset++) {
+				nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD1, DRR_QUANTA);
+				data = (nae_cfg.ports[port].hw_port_id << 15) |
+					 (offset << 20) | ((context_base + offset) << 5) ;
+				nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD0, data | 1 );
+				nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD0, data);
+				nlm_print("txsched %x \n",nlm_hal_read_nae_reg(TX_SCHED_MAP_CMD0));	
+			}
+			break;
+		default:
+                        for (offset=0;offset < nae_cfg.ports[port].num_channels; offset++) {
+				nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD1, DRR_QUANTA);
+                                data =  (nae_cfg.ports[port].hw_port_id << 15) | ((context_base + offset) << 5) ;
+				nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD0 , data | 1 );
+                                nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD0 , data);
+				nlm_print("txsched %x \n",nlm_hal_read_nae_reg(TX_SCHED_MAP_CMD0));
+                        }
+			break;
+	}
+}
+
+#ifdef NLM_HAL_LINUX_KERNEL
+#define DFS_OUTPUT(DR, DF, DV)  ((400/((DR+1) * 3)) * (DF+1) * 2)/(DV+1)
+#else
+#define DFS_OUTPUT(DR, DF, DV)  ((133.33/(DR+1)) * (DF+1) * 2)/(DV+1)
+#endif
+
+static void set_nae_frequency(int frequency)
+{
+	int cnt, data, i;
+	unsigned int spr, spf;
+
+	data = 0x1;   // net dfs decr
+	if(frequency == 500)
+		cnt = 8;
+	else
+		cnt = 4;
+	for(i=0;i<cnt;i++){
+		nlm_hal_write_sys_reg(SYS_DFS_DIV_DEC_CTRL, data);
+	}
+
+	data = nlm_hal_read_sys_reg(PLL_CTRL);
+	spf = data >> 3 & 0x7f;
+	spr = data >> 1  & 0x3;
+
+	data = nlm_hal_read_sys_reg(SYS_DFS_DIV_VALUE0) & 0xf;
+	nlm_print("NAE Frequency set to %dMHz (2X frequency %dMHz) \n",
+		  (int) DFS_OUTPUT(spr, spf, data)/2 ,
+		  (int) DFS_OUTPUT(spr, spf, data));
+}
+
+static void parse_fdt_nae_config(void *fdt)
+{
+	int i = 0, port_node;
+	char port_type_str[MAX_PROP_LEN];
+	int size = 0;
+	int num_ports = 0;
+	uint32_t start_port, num_nae_regs, num_intf_regs;
+	char nae_port_str[1000];
+	uint32_t rx_config = 0;
+	int num_global_nae_regs;
+	uint32_t *global_nae_regs;
+	int frequency, context = 0;
+	int xaui_complex_map = 0, ilk_complex_map = 0, num_lanes = 0;
+
+	/* Parse Nae Config */
+	start_port = num_nae_regs = num_intf_regs = 0;
+
+	if(GET_NAE_PROP("frequency", &frequency, sizeof(uint32_t)) < 0)
+		nlm_print("fdt missing frequency\n");
+	set_nae_frequency(frequency);
+
+	/*******************************************************************************/
+	/* Read range of ports allocated per domain
+	 * start-port-id -> start-port-id + num-ports
+	 */
+
+	if(GET_NAE_PROP("start-port-id", &start_port, sizeof(uint32_t)) < 0)
+		nlm_print("fdt missing start-port-id\n");
+
+	if(GET_NAE_PROP("num-ports", &num_ports, sizeof(uint32_t)) < 0)
+		nlm_print("fdt missing num-ports\n");
+
+	/*******************************************************************************/
+
+	if(GET_NAE_PROP("num-intf-regs", &num_intf_regs, sizeof(uint32_t)) < 0)
+		nlm_print("fdt missing num-if-regs\n");
+
+	nlm_print("num-ports = %d, start-port-id = %d\n", num_ports, start_port);
+
+	/*
+	 *   PCS intialization
+	 */
+	if (!rely_on_firmware_config)
+	{
+		/* bitmask of complexes to initialize */
+		nlm_hal_sgmii_pcs_init(1<<4);
+	}
+
+        if(GET_NAE_PROP("xaui-complex-map", &xaui_complex_map, sizeof(uint32_t)) < 0)
+                nlm_print("fdt missing xaui-complex-map\n");
+        else  
+                nlm_hal_xaui_pcs_init(xaui_complex_map);
+
+        if(GET_NAE_PROP("ilk-complex-map", &ilk_complex_map, sizeof(uint32_t)) < 0)
+                nlm_print("fdt missing ilk-complex-map\n");
+        else {  
+		if(GET_NAE_PROP("num-lanes", &num_lanes, sizeof(uint32_t)) < 0) {
+			nlm_print("fdt missing num-lanes, default 4\n");
+			num_lanes = 4;
+		}
+                nlm_hal_ilk_pcs_init(ilk_complex_map, num_lanes);
+	}
+
+        /* Clear NETIOR soft reset */
+        nlm_hal_write_mac_reg(BLOCK_7, LANE_CFG, NETIOR_SOFTRESET, 0x0);
+        nlm_print("%s Completed NETIOR soft reset\n", __func__);
+
+
+	/* Disable RX enable bit in RX_CONFIG */
+	rx_config = nlm_hal_read_nae_reg(RX_CONFIG);
+	rx_config &= 0xfffffffe;
+	nlm_hal_write_nae_reg(RX_CONFIG, rx_config);
+
+
+	/*
+	 *    Global register configuration
+	 */
+	if(GET_NAE_GLOBAL_PROP("num-regs", &num_global_nae_regs, sizeof(uint32_t)) < 0)
+		nlm_print("fdt missing num-regs for global-nae-regs\n");
+
+	size = sizeof(uint32_t) * num_global_nae_regs * 2;
+	global_nae_regs = nlm_malloc(size);
+	if (!global_nae_regs) {
+		nlm_print("[%s] Unable to allocate memory for global nae-regs, aborting\n", __func__);
+		return;
+	}
+
+	GET_NAE_GLOBAL_PROP("regs", global_nae_regs, size);
+	nlm_hal_init_nae_regs(0, global_nae_regs, num_global_nae_regs);
+	nlm_print("Configured %x global NAE regs\n", num_global_nae_regs);
+
+	for(i = 0; i < num_ports; i++)
+	{
+		uint32_t *nae_regs = 0;
+		uint32_t *intf_regs = 0;
+		int mgmt_intf = 0;
+		int port = 0;
+
+		sprintf(nae_port_str, "/soc/nae-cfg/port@%d", i);
+
+#define GET_PORT_PROP(prop, buf, len)					\
+	copy_fdt_prop(fdt, nae_port_str, prop, PROP_CELL, buf, len)
+
+#define GET_PORT_STR_PROP(prop, buf, len)					\
+	copy_fdt_prop(fdt, nae_port_str, prop, PROP_STR, buf, len)
+
+		port_node = fdt_path_offset(fdt, nae_port_str);
+		if (!port_node) continue;
+
+		if (GET_PORT_PROP("mgmt", &mgmt_intf, sizeof(uint32_t)) < 0)
+			nlm_print("fdt missing mgmt\n");
+
+		port = nae_cfg.num_ports;
+		nae_cfg.num_ports++;
+
+		nae_cfg.ports[port].valid = 1;
+		nae_cfg.ports[port].mgmt = mgmt_intf;
+		nae_cfg.ports[port].vlan_pri_en = 0; /* For now. Will be added via sysconfig later */
+
+		if (GET_PORT_PROP("tx-que-range", &nae_cfg.ports[port].txq_range[0], sizeof(uint32_t) * 2) < 0)	{
+			nlm_print("fdt missing tx-que-range\n");
+		}
+		else {
+			nlm_print("tx-que-range[%d %d]\n", nae_cfg.ports[port].txq_range[0],
+			       nae_cfg.ports[port].txq_range[1]);
+		}
+
+		if (GET_PORT_PROP("rx-que", &nae_cfg.ports[port].rxq, sizeof(uint32_t)) < 0) {
+			nlm_print("fdt missing rx-que\n");
+		}
+		else {
+			nlm_print("rx-que[%d]\n", nae_cfg.ports[port].rxq);
+		}
+                if (GET_PORT_PROP("hw-port-id", &nae_cfg.ports[port].hw_port_id, sizeof(uint32_t)) < 0) {
+                        nlm_print("fdt missing hw-port-id\n");
+                }
+                else {
+                        nlm_print("hw-port-id[%d]\n", nae_cfg.ports[port].hw_port_id);
+		}
+
+		GET_PORT_PROP("num-channels", &nae_cfg.ports[port].num_channels, sizeof(uint32_t));
+	
+		GET_PORT_STR_PROP("type", port_type_str, MAX_PROP_LEN);
+		if (!strcmp(port_type_str, "SGMII_IF")) {
+			nae_cfg.ports[port].iftype = SGMII_IF;
+		}
+		else if (!strcmp(port_type_str, "XAUI_IF")) {
+			nae_cfg.ports[port].iftype = XAUI_IF;
+			xlp_nae_config_xaui((nae_cfg.ports[port].hw_port_id / 4), port);
+		}
+		else if (!strcmp(port_type_str, "INTERLAKEN_IF")) {
+			nae_cfg.ports[port].iftype = INTERLAKEN_IF;
+			xlp_nae_config_interlaken((nae_cfg.ports[port].hw_port_id / 4), port, num_lanes);
+		}
+		else  {
+			nae_cfg.ports[port].iftype = UNKNOWN_IF;
+			nlm_print("HW port %d with Unknown interface type !!!\n",nae_cfg.ports[port].hw_port_id);
+		}
+
+		GET_PORT_PROP("num-free-desc", &nae_cfg.ports[port].num_free_desc,
+			sizeof(uint32_t));
+
+		if(GET_PORT_PROP("num-nae-regs", &num_nae_regs, sizeof(uint32_t)) < 0)
+			nlm_print("fdt missing per port num-nae-regs\n");
+
+		size = sizeof(uint32_t) * num_nae_regs * 2;
+		nae_regs = nlm_malloc(size);
+		if (!nae_regs) {
+			nlm_print("[%s] Unable to allocate memory for nae-regs, aborting\n", __func__);
+			return;
+		}
+		GET_PORT_PROP("nae-regs", nae_regs, size);
+
+		size = sizeof(uint32_t) * num_intf_regs * 2;
+		intf_regs = nlm_malloc(size);
+		if (!intf_regs) {
+			nlm_print("[%s] Unable to allocate memory for if-regs, aborting\n", __func__);
+			return;
+		}
+		GET_PORT_PROP("intf-regs", intf_regs, size);
+
+		if (mgmt_intf && rely_on_firmware_config) {
+			int reg = 0;
+
+			/* don't rely on firmware for free-in desc carving */
+			for (reg = 0; reg < num_nae_regs; reg++) {
+				if (nae_regs[reg * 2] != FREE_IN_FIFO_CFG) continue;
+				nlm_hal_write_nae_reg(FREE_IN_FIFO_CFG, nae_regs[reg * 2 + 1]);
+			}
+		} else {
+			nlm_print("Configuring per-port interface registers for port@%d\n", i);
+			/* Configure per port interface registers */
+			nlm_hal_init_if_regs(nae_cfg.ports[port].iftype, nae_cfg.ports[port].hw_port_id, intf_regs, num_intf_regs);
+
+			nlm_print("Configuring per-port NAE registers for port@%d\n", i);
+			/* Configure per port NAE registers */
+			nlm_hal_init_nae_regs(nae_cfg.ports[port].iftype, nae_regs, num_nae_regs);
+		}
+
+		/* Egress Config */
+		config_egress(context, port);
+		context += nae_cfg.ports[port].num_channels;
+
+		nlm_free(nae_regs);
+		nlm_free(intf_regs);
+
+		if (!rely_on_firmware_config) {
+			if (nlm_hal_open_if(nae_cfg.ports[port].iftype, nae_cfg.ports[port].hw_port_id) < 0) {
+				nlm_print("[%s] Unable to open port %d\n", __func__, i);
+				continue;
+			}
+		}
+
+		nlm_print("Initialized port@%d\n", i);
+	}
+}
+
+#ifndef NLM_HAL_LINUX_KERNEL
+#define preempt_enable()
+#define preempt_disable()
+#endif
+
+#define msgrng_enable(flags)                \
+do {                                        \
+  preempt_disable(); \
+  __asm__ volatile (                        \
+		    ".set push\n\t"                 \
+		    ".set reorder\n\t"              \
+		    ".set noat\n\t"                 \
+		    "mfc0 %0, $12\n\t"              \
+		    "li  $8, 0x40000001\n\t"        \
+		    "or  $1, %0, $8\n\t"            \
+		    "xori $1, 1\n\t"                \
+		    ".set noreorder\n\t"            \
+		    "mtc0 $1, $12\n\t"              \
+		    ".set\tpop\n\t"                 \
+		    : "=r" (flags)                  \
+		    :                               \
+		    : "$8"                          \
+		    );                              \
+  preempt_enable(); \
+} while (0)
+
+#define msgrng_disable(flags) __asm__ volatile (    \
+                 "mtc0 %0, $12" : : "r" (flags))
+
+#define msgrng_access_enable(mflags) do {   \
+  preempt_disable();                        \
+  msgrng_enable(mflags);                \
+} while(0)
+
+#define msgrng_access_disable(mflags) do {   \
+  msgrng_disable(mflags);              \
+  preempt_enable();                          \
+} while(0)
+
+static void drain_nae_frin_fifo_descs(void)
+{
+	int i = 0;
+	uint32_t value = 0;
+
+	nlm_hal_write_nae_reg(RX_FREE_FIFO_POP, 0xfffff);
+	for (i = 0; i < 10; i++) {
+		nlm_mdelay(1);
+		value = nlm_hal_read_nae_reg(RX_FREE_FIFO_POP);
+		if (value == 0xfffff) break;
+	}
+	if (i == 10) {
+		nlm_print("Unable to zap free in fifo!(value=0x%08x)\n", value);
+	}
+	else {
+		nlm_print("Successfully zapped free in fifo!\n");
+	}
+	nlm_hal_write_nae_reg(RX_FREE_FIFO_POP, 0);
+}
+
+static int debug = 1;
+
+static void print_frin_desc_carving(void)
+{
+	int intf;
+
+	if (!debug) return;
+
+	for (intf = 0; intf < 20; intf++) {
+		uint32_t value = 0;
+		int start = 0, size = 0;
+
+		nlm_hal_write_nae_reg(FREE_IN_FIFO_CFG, (0x80000000 | intf));
+
+		value = nlm_hal_read_nae_reg(FREE_IN_FIFO_CFG);
+		size = 2 * ((value >> 20) & 0x3ff);
+		start = 2 * ((value >> 8) & 0x1ff);
+
+		nlm_print("intf@%02d=0x%08x, start=%d, size=%d\n", intf, value, start, size);
+	}
+}
+
+static void deflate_frin_fifo_carving(void)
+{
+	int intf = 0;
+	const int minimum_size = 8; /* this represents entries, each entry holds 2 descriptors */
+	int start = 0;
+	uint32_t value = 0;
+
+	for (intf = 0; intf < 20; intf++) {
+		start = minimum_size * intf;
+		value = (minimum_size << 20) | (start << 8) | (intf);
+		nlm_hal_write_nae_reg(FREE_IN_FIFO_CFG, value);
+	}
+}
+
+static int check_header(void *fdt)
+{
+        int fdt_err = fdt_check_header(fdt);
+        if (fdt_err < 0) {
+                nlm_print("FDT_ERROR: Invalid FDT Detected: %s\n",
+                                fdt_strerror(fdt_err));
+                return -1;
+        }
+
+	return 0;
+}
+
+void drain_nae_stray_packets(void)
+{
+	int i, j;
+	int mgmt_vc = 1016;
+	int desc_size = 2048;
+	uint64_t laddr = (255 << 20); /* 255 MB */
+
+
+	for (j = 0; j < 2; ++j) {
+
+		/* Turn off RX enable */
+		write_gmac_reg(16 + j , MAC_CONF1,0);
+
+
+		/* Send Free descriptors */
+		for (i = 0; i < 100; ++i) {
+			if (nlm_hal_send_msg1( mgmt_vc + j,
+					       0,
+					       laddr)) {
+
+				nlm_print("%s; Failed to send Free-in desc\n", __func__);
+				break;
+			}
+			laddr += desc_size;
+		}
+	}
+	nlm_mdelay(1);
+}
+
+static void reset_nae(void)
+{
+	uint32_t rx_config = nlm_hal_read_nae_reg(RX_CONFIG);
+
+	/* Reset NAE */
+	nlm_hal_write_sys_reg(SYS_RESET, (1 << 9));
+	nlm_mdelay(1);
+
+	nlm_hal_write_sys_reg(SYS_RESET, (0 << 9));
+	nlm_mdelay(1);
+
+	rx_config = nlm_hal_read_nae_reg(RX_CONFIG);
+	nae_reset_done = 1;
+}
+
+int nlm_hal_init_nae(void *fdt, int dom_id)
+{
+	int i = 0;
+	int context = 0, ctxsize = 0, offset=0;
+	uint32_t bar0;
+
+	if (check_header(fdt)) {
+		nlm_print("Sanity check on FDT blob failed! Aborting\n");
+		return -1;
+	}
+
+	bar0 = nlm_hal_read_32bit_reg(0x18018000, 0x4);
+
+	/* Initialize default configuration */
+	for (i = 0; i < 18; i++) {
+		nae_cfg.fb_vc = 1;
+		nae_cfg.rx_vc = 0;
+		nae_cfg.ports[i].valid = 0;
+		nae_cfg.ports[i].mgmt = 0;
+	}
+
+	for (i = 0; i < MAX_NAE_CONTEXTS; i++) {
+		/* 18 is an invalid port */
+		cntx2port[i] = 18;
+	}
+
+	/* frin_fifo represents the 20 pools of free-in descriptor fifos */
+	//drain_nae_stray_packets();
+	drain_nae_frin_fifo_descs();
+	deflate_frin_fifo_carving();
+
+	reset_nae();
+
+	nlm_hal_write_32bit_reg(0x18018000, 0x4, bar0);
+
+	nlm_print("Configuring ucore...\n");
+	parse_ucore_config(fdt);
+
+	nlm_print("Configuring NAE...\n");
+	parse_fdt_nae_config(fdt);
+
+	nlm_print("Configuring CPU-NAE...\n");
+	parse_fdt_cpu_config(fdt, dom_id);
+
+	nlm_print("Configuring PoE...\n");
+	parse_poe_config(fdt);
+
+	nlm_print("NAE configuration done!\n");
+
+	nlm_print("Digest of FDT based NAE config: \n");
+	nlm_print("fb_vc = %d, rx_vc = %d\n", nae_cfg.fb_vc, nae_cfg.rx_vc);
+	for (i = 0; i < 18; i++) {
+		struct nlm_hal_nae_port *port = &nae_cfg.ports[i];
+
+		if (!port->valid) continue;
+
+		ctxsize = nae_cfg.ports[i].num_channels;
+#if 0
+		/* Default NAE configuration uses hw_port_id as the context */
+		context = port->hw_port_id;
+		cntx2port[context] = i; /* logical port */
+#else
+		for(offset=0; offset < ctxsize; offset++)
+			cntx2port[context + offset] = i; /* logical port */
+
+#endif
+
+		nlm_print("port@%d: valid = %d, mgmt = %d, num_free_desc = %d ctxt = %d\n"
+		       "\t txq[0] = %d, txq[1] = %d, rxq = %d, hw_port_id = %d\n", i,
+			  port->valid, port->mgmt, port->num_free_desc, context,
+		       port->txq_range[0], port->txq_range[1], port->rxq, port->hw_port_id);
+
+		context += ctxsize;
+
+	}
+
+	nlm_print("FRIN desc carving after HAL initialization...\n");
+	print_frin_desc_carving();
+
+	return 0;
+}
+/*
+ *  Interface support
+ */
+
+#define PHY_STATUS_RETRIES 20000
+#define WAIT_XGMAC_MDIO_BSY_CLEAR   for (i = 0; i < PHY_STATUS_RETRIES; i++) {	\
+        if((nlm_hal_read_mac_reg( 7, intf_type,					\
+        	EXT_XG0_MDIO_RD_STAT + bus * 4 ) & EXT_XG_MDIO_STAT_MBSY) == 0)	\
+                        break;							\
+        }
+
+
+/*
+ *                   XAUI Support
+ *
+ */
+
+/**********************************************************************
+ *  nlm_hal_xgmac_mdio_indirect_addr -Write reg index for indirect read/write.
+ *
+ *  Input parameters:
+ *         bus          - bus number, nae has two external xgmac bus: 0 and 1
+ *         phyaddr      - PHY to use
+ *         regidx       - register within the PHY
+ *         val          - data to write to register
+ *
+ *  Return value:
+ *         0 - success
+ ********************************************************************* */
+static int nlm_hal_xgmac_mdio_indirect_addr(int bus,int block, int intf_type, int phyaddr, int regidx)
+{
+        int32_t i;
+        int16_t dev_type;
+
+
+        dev_type = 0x5;
+
+        /* load  XGMC_MDIO_CTRL_DATA register with indirect addr */
+        nlm_hal_write_mac_reg( 7 , intf_type,
+                                EXT_XG0_MDIO_CTRL_DATA + bus * 4, regidx);
+
+        nlm_hal_write_mac_reg( 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_type << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | EXT_XG_MDIO_CTRL_CMD_LOAD
+                                | MDIO_MIIM_CMD_10G_MMD << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | EXT_XG_MDIO_CTRL_TA << EXT_XG_MDIO_CTRL_TA_POS
+                                | MDIO_CTRL_OP_INDIRECT_ADDR << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+
+        /* poll master busy bit until it is not busy */
+	WAIT_XGMAC_MDIO_BSY_CLEAR
+
+        nlm_hal_write_mac_reg( 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_type << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | MDIO_MIIM_CMD_IDLE << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | 0x0 << EXT_XG_MDIO_CTRL_TA_POS
+                                | MDIO_CTRL_OP_INDIRECT_ADDR << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+
+        /* poll master busy bit until it is not busy */
+	WAIT_XGMAC_MDIO_BSY_CLEAR
+	return 0;
+}
+
+/**********************************************************************
+ *  nlm_hal_xgmac_mdio_indirect_write -Write xgmac mii PHY register.
+ *
+ *  Input parameters:
+ *         bus          - bus number, nae has two external xgmac bus: 0 and 1
+ *         phyaddr      - PHY to use
+ *         regidx       - register within the PHY
+ *         val          - data to write to register
+ *
+ *  Return value:
+ *         0 - success
+ ********************************************************************* */
+int nlm_hal_xgmac_mdio_indirect_write(int bus, int block, int intf_type, int phyaddr, int regidx, uint16_t val)
+{
+        int32_t  i;
+        int16_t dev_type;
+
+        dev_type = 0x5;
+
+         /* first is indirect address cycle */
+        nlm_hal_xgmac_mdio_indirect_addr(bus, block, intf_type, phyaddr, regidx);
+
+        nlm_hal_write_mac_reg( 7 , intf_type,
+                                EXT_XG0_MDIO_CTRL_DATA+ bus * 4, val);
+
+        nlm_hal_write_mac_reg( 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_type << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | EXT_XG_MDIO_CTRL_CMD_LOAD
+                                | MDIO_MIIM_CMD_10G_MMD << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | EXT_XG_MDIO_CTRL_TA << EXT_XG_MDIO_CTRL_TA_POS
+                                | MDIO_CTRL_OP_WRITE_10G_MMD << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+        /* poll master busy bit until it is not busy */
+	WAIT_XGMAC_MDIO_BSY_CLEAR
+
+
+        nlm_hal_write_mac_reg( 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_type << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | MDIO_MIIM_CMD_IDLE << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | 0x0 << EXT_XG_MDIO_CTRL_TA_POS
+                                | 0 << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+
+        /* poll master busy bit until it is not busy */
+	WAIT_XGMAC_MDIO_BSY_CLEAR
+	return 0;
+}
+
+/**********************************************************************
+ *  nlm_hal_xgmac_mdio_indirect_read - Read xgmac phy register
+ *
+ *  Input parameters:
+ *         bus          - bus number, nae has two external xgmac bus: 0 and 1
+ *         phyaddr      - PHY's address
+ *         regidx       - index of register to read
+ *
+ *  Return value:
+ *         value read (16 bits), or 0xffffffff if an error occurred.
+ ********************************************************************* */
+int nlm_hal_xgmac_mdio_indirect_read(int bus, int block, int intf_type, int phyaddr, int regidx)
+{
+        int32_t  i;
+        int16_t dev_type;
+
+        dev_type = 0x5;
+
+         /* first is indirect address cycle */
+        nlm_hal_xgmac_mdio_indirect_addr(bus, block, intf_type, phyaddr, regidx);
+
+        nlm_hal_write_mac_reg( 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_type << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | EXT_XG_MDIO_CTRL_CMD_LOAD
+                                | MDIO_MIIM_CMD_10G_MMD << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | EXT_XG_MDIO_CTRL_TA << EXT_XG_MDIO_CTRL_TA_POS
+                                | MDIO_CTRL_OP_READ_10G_MMD << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+        /* poll master busy bit until it is not busy */
+	WAIT_XGMAC_MDIO_BSY_CLEAR
+
+
+        nlm_hal_write_mac_reg( 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_type << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | MDIO_MIIM_CMD_IDLE << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | 0x0 << EXT_XG_MDIO_CTRL_TA_POS
+                                | 0 << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+
+        /* poll master busy bit until it is not busy */
+	WAIT_XGMAC_MDIO_BSY_CLEAR
+
+	return nlm_hal_read_mac_reg( 7, intf_type,
+                                EXT_XG0_MDIO_RD_STAT + bus * 4) & 0xFFFF;
+
+}
+
+/**********************************************************************
+ *  nlm_hal_xgmac_mdio_indirect_reset- reset xaui block.
+ *
+ *  Input parameters:
+ *         bus - bus number, nae has two external gmac bus: 0 and 1
+ *
+ *  Return value:
+ *       none
+ ********************************************************************* */
+void nlm_hal_xgmac_mdio_indirect_reset(int bus, int block, int intf_type)
+{
+        int16_t phyaddr, data;
+
+	phyaddr = 0x14 + block;
+        data = XAUI_PHY_RST;
+        nlm_hal_xgmac_mdio_indirect_write(bus, block, intf_type, phyaddr, XAUI_PHY_CTRL_1, data);
+
+	data &= ~XAUI_PHY_RST;
+        nlm_hal_xgmac_mdio_indirect_write(bus, block, intf_type, phyaddr, XAUI_PHY_CTRL_1, data);
+}
+
+/**********************************************************************
+ *  nae_config_lane_gmac
+ *
+ ********************************************************************* */
+void nlm_hal_xaui_pcs_init(int xaui_cplx_mask)
+{
+	int block, lane_ctrl;
+	int cplx_lane_enable = LM_XAUI | (LM_XAUI << 4) | (LM_XAUI << 8) | (LM_XAUI << 12);
+	int lane_enable = 0;
+
+	if (xaui_cplx_mask == 0) {
+		return;
+	}
+
+	/* write 0x2 to enable SGMII for all lane
+	 */
+	block = 7;
+
+	if (xaui_cplx_mask & 0x3) { /* Complexes 0, 1 */
+		if (xaui_cplx_mask & 0x1) { /* Complex 0 */
+			lane_enable |= cplx_lane_enable;
+		}
+		if (xaui_cplx_mask & 0x2) {/* Complex 1 */
+			lane_enable |= (cplx_lane_enable << 16);
+		}
+		nlm_hal_write_mac_reg( block, LANE_CFG, LANE_CFG_CPLX_0_1,   lane_enable);
+	}
+	lane_enable = 0;
+	if (xaui_cplx_mask & 0xc) { /* Complexes 2, 3 */
+		if (xaui_cplx_mask & 0x4) { /* Complex 2 */
+			lane_enable |= cplx_lane_enable;
+		}
+		if (xaui_cplx_mask & 0x8) {/* Complex 3 */
+			lane_enable |= (cplx_lane_enable << 16);
+		}
+		nlm_hal_write_mac_reg( block, LANE_CFG, LANE_CFG_CPLX_2_3,   lane_enable);
+	}
+
+	/* serdes lane progaming
+	 */
+	for( block = 0; block < 4; block++)
+	{
+		if ((xaui_cplx_mask & (1 << block)) == 0) {
+			continue;
+		}
+		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_0_CTRL,
+				       PHY_LANE_CTRL_RST_XAUI
+				       | PHY_LANE_CTRL_PWRDOWN
+				       | (PHYMODE_XAUI << PHY_LANE_CTRL_PHYMODE_POS));
+
+		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_1_CTRL,
+				       PHY_LANE_CTRL_RST_XAUI
+				       | PHY_LANE_CTRL_PWRDOWN
+				       | (PHYMODE_XAUI << PHY_LANE_CTRL_PHYMODE_POS));
+
+		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_2_CTRL,
+				       PHY_LANE_CTRL_RST_XAUI
+				       | PHY_LANE_CTRL_PWRDOWN
+				       | (PHYMODE_XAUI << PHY_LANE_CTRL_PHYMODE_POS));
+
+		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_3_CTRL,
+				       PHY_LANE_CTRL_RST_XAUI
+				       | PHY_LANE_CTRL_PWRDOWN
+				       | (PHYMODE_XAUI << PHY_LANE_CTRL_PHYMODE_POS));
+
+	}
+
+	/* Bring txpll out of reset */
+	for( block = 0; block < 4; block++)
+	{
+		if ((xaui_cplx_mask & (1 << block)) == 0) {
+			continue;
+		}
+
+		for( lane_ctrl = PHY_LANE_0_CTRL; lane_ctrl <= PHY_LANE_3_CTRL; lane_ctrl++) {
+			nae_lane_reset_txpll( block, lane_ctrl);
+		}
+	}
+	nlm_print("%s all blocks & lanes out of TXPLL\n", __func__);
+	/* Wait for Rx & TX clock stable */
+	for( block = 0; block < 4; block++)
+	{
+		if ((xaui_cplx_mask & (1 << block)) == 0) {
+			continue;
+		}
+
+		for( lane_ctrl = PHY_LANE_0_CTRL; lane_ctrl <= PHY_LANE_3_CTRL; lane_ctrl++) {
+			while ((nlm_hal_read_mac_reg(block, PHY, (lane_ctrl - 4)) & (LANE_TX_CLK)) != LANE_TX_CLK) {
+				/* Wait for TX and RX clock to be set */
+			}
+			nlm_print("%s Blk%d lane%d got TX clock stable\n", __func__, block, lane_ctrl);
+
+			while ((nlm_hal_read_mac_reg(block, PHY, (lane_ctrl - 4)) & (LANE_RX_CLK)) != LANE_RX_CLK) {
+				/* Wait for TX and RX clock to be set */
+			}
+			nlm_print("%s Blk%d lane%d got RX clock stable\n", __func__, block, lane_ctrl);
+
+			while ((nlm_hal_read_mac_reg(block, PHY, (lane_ctrl - 4)) & (XAUI_LANE_FAULT)) != 0) {
+				/* Wait for XAUI Lane fault to be cleared */
+			}
+			nlm_print("%s Blk%d lane%d got lane fault cleared\n", __func__, block, lane_ctrl);
+
+		}
+	}
+
+}
+
+//XAUI port initialization
+static void xlp_nae_config_xaui(int block, int port)
+{
+	uint32_t val = 0;
+
+	val = 	nlm_hal_read_mac_reg(block, XGMAC, XGMAC_CTL_REG1);
+	val &= ~(0x1 << 11); /* Reset xgmac soft reset(bit 11) xaui soft reset (bit 12) */
+	nlm_hal_write_mac_reg(block, XGMAC, XGMAC_CTL_REG1, val);
+	nlm_print("%s Cleared XGMAC soft reset\n", __func__);
+
+	val = 	nlm_hal_read_mac_reg(block, XGMAC, XGMAC_CTL_REG1);
+	val &= ~(0x3 << 11); /* Reset xgmac soft reset(bit 11) xaui soft reset (bit 12) */
+	nlm_hal_write_mac_reg(block, XGMAC, XGMAC_CTL_REG1, val);
+	nlm_print("%s Cleared XAUI reset\n", __func__);
+
+	nlm_hal_write_mac_reg( block, XGMAC, XAUI_CONFIG_0, 0xffffffff);
+	nlm_hal_write_mac_reg( block, XGMAC, XAUI_CONFIG_0, 0x0);
+
+	/* Enable tx/rx frame */
+	val = 0xF00010A8;
+	val |= (XAUI_CONFIG_LENCHK | XAUI_CONFIG_GENFCS | XAUI_CONFIG_PAD_64);
+	nlm_hal_write_mac_reg(  block, XGMAC, XAUI_CONFIG_1,    XAUI_CONFIG_TFEN
+				| XAUI_CONFIG_RFEN
+				| val );
+	/* write max frame len*/
+	nlm_hal_write_mac_reg(  block, XGMAC, XAUI_MAX_FRAME_LEN , 0x04002000);
+
+	/* set stats counter*/
+	val = nlm_hal_read_mac_reg( block, XGMAC, NETIOR_XGMAC_CTRL1);
+	val |= 1 << NETIOR_XGMAC_VLAN_DC_POS;
+	val |= 1 << NETIOR_XGMAC_STATS_EN_POS;
+
+	if (nae_cfg.ports[port].vlan_pri_en) {
+		val |= 1 << NETIOR_XGMAC_TX_PFC_EN_POS;
+		val |= 1 << NETIOR_XGMAC_RX_PFC_EN_POS;
+		val |= 1 << NETIOR_XGMAC_TX_PAUSE_POS;
+	} else {
+		val &= ~(1 << NETIOR_XGMAC_TX_PFC_EN_POS);
+		val &= ~(1 << NETIOR_XGMAC_TX_PAUSE_POS);
+	}
+	nlm_hal_write_mac_reg(block, XGMAC, NETIOR_XGMAC_CTRL1, val);
+
+		/*
+		 * Configuring the OFF/ON timer
+		 * 31:16  - In PFC mode is used as the Xoff value                                    
+		 * 15:0   - In PFC mode is used as the Xon value                                     
+		 *        - in Link level FC mode, is used as the Xoff value.                        
+		 */
+	if (nae_cfg.ports[port].vlan_pri_en) {
+		val = 0xF1230000;          // PFC mode:  OffTimer = 0xF123  OnTimer = 0x0000 
+	} else {
+		val = 0x0000F123;          // Link level FC: OffTimer = 0xF123   
+	}
+	nlm_hal_write_mac_reg(block, XGMAC, NETIOR_XGMAC_CTRL2, val);
+
+
+	/* set xaui tx threshold */
+	val = nlm_hal_read_mac_reg(block, XGMAC, NETIOR_XGMAC_CTRL3);
+
+	 /* val &= ~(0x1f << 10);  */
+	 /* val |= (15 << 10);  */
+
+	nlm_hal_write_mac_reg(block, XGMAC, NETIOR_XGMAC_CTRL3, val);
+	nlm_print("%s XAUI Config Complete block %d swport %d hwport %d!!\n", __func__,block, port, nae_cfg.ports[port].hw_port_id);
+	return;
+}
+
+/*
+ *                   Interlaken Support
+ *
+ */
+static void xlp_nae_config_lane_ilk(int ilk_block_base, int ilk_num_lanes)
+{
+	volatile uint32_t lane_mask = 0;
+	uint32_t ilk_lane_eable = 0;
+	volatile uint32_t lane_config = 0, lane_cfg_reg =  ((ilk_block_base < 2) ? LANE_CFG_CPLX_0_1 : LANE_CFG_CPLX_2_3);
+	volatile uint32_t phy_lane = PHY_LANE_CTRL_BPC_XAUI | PHY_LANE_CTRL_RST |
+				PHY_LANE_CTRL_PWRDOWN | (PHYMODE_IL << PHY_LANE_CTRL_PHYMODE_POS);
+	uint32_t block, lane, max_block;
+
+	nlm_print("xlp_nae_config_lane_ilk blk %d num_lanes %d\n",ilk_block_base, ilk_num_lanes);
+	if (!((ilk_block_base == 0) || (ilk_block_base == 2)))
+		return;
+	// Configure Lane mode for interlaken
+
+	nlm_print("Configure Lane mode \n");
+	block = max_block = ilk_block_base ;
+	max_block += ((ilk_num_lanes > MAX_LANE_PER_CPLX ) ? 2 : 1);
+
+	for(; block < max_block ; block++ ) {
+	        if (block % 2) {
+	                ilk_lane_eable <<= 16;
+        	        lane_mask <<= 16;
+		}
+		else {
+			ilk_lane_eable = (LM_IL << LANE_CFG_LANE_3_POS) |
+					(LM_IL << LANE_CFG_LANE_2_POS) |
+					(LM_IL << LANE_CFG_LANE_1_POS) | LM_IL;
+			lane_mask = 0xFFFF;
+		}
+		nlm_print("ilk_lane_eable 0x%x lane_mask 0x%x reg %d \n",ilk_lane_eable, lane_mask, lane_cfg_reg);
+		lane_config = nlm_hal_read_mac_reg( BLOCK_7, LANE_CFG, lane_cfg_reg);
+		nlm_hal_write_mac_reg(BLOCK_7, LANE_CFG, lane_cfg_reg, lane_config & (~lane_mask));
+	
+                lane_config = nlm_hal_read_mac_reg(BLOCK_7, LANE_CFG, lane_cfg_reg);
+		lane_config |= ilk_lane_eable;
+                nlm_hal_write_mac_reg(BLOCK_7, LANE_CFG, lane_cfg_reg, lane_config | ilk_lane_eable);
+		nlm_print("lanecfg %x \n",nlm_hal_read_mac_reg(BLOCK_7, LANE_CFG, lane_cfg_reg));
+        }
+
+	nlm_print("Configure PHY mode \n");
+
+	// Configure PHY mode
+
+	for(block = ilk_block_base; block < max_block ; block++) {
+		for (lane = 0; lane < MAX_LANE_PER_CPLX ; lane++) {
+			if (lane==0) {
+				nlm_hal_write_mac_reg(block, PHY, PHY_LANE_0_CTRL + lane, phy_lane);
+			}
+			else {
+				nlm_hal_write_mac_reg(block, PHY, PHY_LANE_0_CTRL + lane, phy_lane | (1<<PHY_LANE_CTRL_REXSEL_POS));
+			}
+		}
+	}
+
+	nlm_print("Reset pll \n");
+	// Check PID revision and do the following
+	for(block = ilk_block_base; block < max_block ; block++) {
+                for (lane = PHY_LANE_0_CTRL; lane <= PHY_LANE_3_CTRL; lane++) {
+			nae_lane_reset_txpll( block, lane);
+                }
+	}
+}
+
+#ifdef INTERLAKEN_DEBUG
+static void dump_interlaken_regs(int blk)
+{
+	nlm_print("Rxstats1 0x%x\n",nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS1));
+	nlm_print("Rxstats2 0x%x\n",nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS2));
+	nlm_print("Rxstats3 0x%x\n",nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS3));
+}
+
+static void xlp_debug_interlaken(int blk)
+{
+	uint32_t debug;
+
+	debug = (0 << ILK_GEN_CTRL2_SCS0_POS) | (1 << ILK_GEN_CTRL2_SCS1_POS ) |
+		(2 << ILK_GEN_CTRL2_SCS2_POS);
+
+        debug |= (3 << ILK_GEN_CTRL2_SCS4_POS) | (4 << ILK_GEN_CTRL2_SCS5_POS);
+	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_GENERAL_CTRL2, debug);
+
+	debug = (1 << ILK_GEN_CTRL3_LCS1_POS) | (3 << ILK_GEN_CTRL3_LCS0_POS) |
+		(1 << ILK_GEN_CTRL3_MCS1_POS) | (0 << ILK_GEN_CTRL3_MCS0_POS) |
+		(13 << ILK_GEN_CTRL3_SCS6_POS) | (11 << ILK_GEN_CTRL3_SCS7_POS);
+	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_GENERAL_CTRL3, debug);
+	dump_interlaken_regs(blk);
+}
+#endif
+
+#ifdef ILK_SERDES_LOOP
+static uint8_t nlm_hal_read_pma_reg(int block, int lane, uint8_t serdes_reg)
+{
+	volatile uint32_t lane_ctrl = 0;
+	volatile uint32_t serdes_val = 0;
+
+	lane += PHY_LANE_0_CTRL;
+
+	lane_ctrl = nlm_hal_read_mac_reg(block, PHY, lane);
+	lane_ctrl |= PHY_LANE_CTRL_CMD_READ | PHY_LANE_CTRL_CMD_START |
+			PHY_LANE_CTRL_RST | (serdes_reg << PHY_LANE_CTRL_ADDR_POS);
+
+	nlm_hal_write_mac_reg(block, PHY, lane, lane_ctrl);
+
+        while (((lane_ctrl = nlm_hal_read_mac_reg( block, PHY, lane)) & PHY_LANE_CTRL_CMD_PENDING));
+
+	serdes_val = lane_ctrl & 0xFF;
+	return serdes_val;
+}
+
+static void nlm_hal_write_pma_reg(int block, int lane, uint8_t serdes_reg, uint8_t serdes_val)
+{
+	volatile uint32_t lane_ctrl = 0;
+
+	lane += PHY_LANE_0_CTRL;
+
+	lane_ctrl = 0xFFFF0000 & nlm_hal_read_mac_reg(block, PHY, lane);
+	lane_ctrl = (lane_ctrl & (~PHY_LANE_CTRL_CMD_READ)) |
+				 PHY_LANE_CTRL_CMD_START | PHY_LANE_CTRL_RST |
+				 (serdes_reg << PHY_LANE_CTRL_ADDR_POS) |
+				 (serdes_val << PHY_LANE_CTRL_DATA_POS) ;
+
+	nlm_hal_write_mac_reg(block , PHY, lane, lane_ctrl);
+
+	nlm_hal_write_mac_reg(block , PHY, lane, lane_ctrl);
+
+        while((lane_ctrl = nlm_hal_read_mac_reg( block, PHY, lane)) & PHY_LANE_CTRL_CMD_PENDING);
+}
+#endif
+
+
+static void xlp_nae_config_interlaken(int blk,int port, int num_lanes)
+{
+	volatile uint32_t rxctrl = 0;
+	volatile uint32_t txctrl = 0, genctrl = 0;
+	volatile uint32_t status;
+	int i = 0;
+
+#ifdef ILK_SERDES_LOOP
+	int lane, lnsperblk = (num_lanes > MAX_LANE_PER_CPLX) ? MAX_LANE_PER_CPLX : num_lanes;
+	volatile uint8_t prbsctrl = 0;
+
+	// Enable loopback here if configured
+	do {
+		for(lane = 0; lane < lnsperblk; lane++) {
+			prbsctrl = nlm_hal_read_pma_reg(blk+i, lane, SERDES_PRBS_CTRL);
+			prbsctrl |= SERDES_LOOPBACK_EN;
+			nlm_hal_write_pma_reg(blk+i, lane, SERDES_PRBS_CTRL, prbsctrl);	
+		}
+		lnsperblk = num_lanes - lnsperblk;
+		if (!lnsperblk) 
+			break;
+		i++;				
+	}while(i<2);
+
+	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS1, 0xFFFFFFFF);
+	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS2, 0xFFFFFFFF);
+	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS3, 0x0004FFFF);
+#endif
+        if (!((blk == 0) || (blk == 2)))
+                return;
+
+	nlm_print("interlaken blk %d num_lanes %d \n",blk, num_lanes);
+
+	// Configure number of lanes , IL registers
+	if (num_lanes == 1) {
+		rxctrl = ILK_RX_CTRL_BAD_LANE | (num_lanes << ILK_RX_CTRL_BLS_POS )
+			 | (num_lanes << ILK_RX_CTRL_LLS_POS);
+                txctrl = ILK_TX_CTRL_BAD_LANE | (num_lanes << ILK_TX_CTRL_BLS_POS)
+			 | (num_lanes << ILK_TX_CTRL_LLS_POS);
+	}
+	else {
+		rxctrl = (num_lanes - 1) << ILK_RX_CTRL_LLS_POS;
+		txctrl = (num_lanes - 1) << ILK_TX_CTRL_LLS_POS;
+	}
+
+        rxctrl |= (ILK_BURST_MAX << ILK_RX_CTRL_BMAX_POS);
+        txctrl |= (ILK_BURST_MAX << ILK_TX_CTRL_BMAX_POS); 
+        nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_RX_CONTROL, rxctrl);
+        nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_TX_CONTROL, txctrl);
+
+	txctrl = nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_TX_CONTROL);
+	txctrl |= (ILK_BURST_MAX << ILK_TX_CTRL_BMAX_POS); 
+	txctrl |= (0x1 << ILK_TX_CTRL_CAL_LEN_POS); // 16:0 32:1 48:2 64:3
+	txctrl |= ILK_TX_CTRL_RST_INF |
+			 ILK_TX_CTRL_RST_CORE |
+			 ILK_TX_CTRL_TX_EN ;
+	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_TX_CONTROL, txctrl);
+	nlm_print("txctrl 0x%x\n",nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_TX_CONTROL));
+
+	genctrl = nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_GENERAL_CTRL1);
+	genctrl &= (~(0xF << 8));
+	genctrl |= (1<<8);    // 16:0 32:1 48:2 64:3
+	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_GENERAL_CTRL1, genctrl);
+
+	rxctrl = nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_RX_CONTROL);
+	rxctrl |= (ILK_BURST_MAX << ILK_RX_CTRL_BMAX_POS);
+	rxctrl |= (0xFF << ILK_RX_CTRL_RST_LANE_POS) | 
+				ILK_RX_CTRL_RST_CORE |
+				ILK_RX_CTRL_PKT_MODE;
+	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_RX_CONTROL, rxctrl);
+	nlm_print("rxctrl 0x%x\n",nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_RX_CONTROL));
+
+	// Configure calendar map table
+
+	nlm_print("Checking Lanes are aligned \n");
+	// check lanes are aligned
+	i=0;
+	do {
+		status = nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS3);
+		nlm_print("Lane status 0x%x\n",status);
+		if (++i > 10)
+			break;
+	}while(!(status & ILK_RX_STAT3_RXL_ALIGN));
+#ifdef INTERLAKEN_DEBUG
+	xlp_debug_interlaken(blk);
+#endif
+}
+
+
+void nlm_hal_ilk_pcs_init(int ilk_cplx_mask, int num_lanes)
+{
+	int block, lane_ctrl;
+
+	nlm_print("nlm_hal_ilk_pcs_init ilk_cplx_mask 0x%x\n",ilk_cplx_mask);
+	for (block = 0 ; block < (MAX_CPLX_BLOCK - 1); block+=2) {
+		if (ilk_cplx_mask & (1<<block))
+			xlp_nae_config_lane_ilk(block , num_lanes);
+	}
+
+	        /* Wait for Rx & TX clock stable */
+        for( block = 0; block < 4; block++)
+        {
+                if ((ilk_cplx_mask & (1 << block)) == 0) {
+                        continue;
+                }
+
+                for( lane_ctrl = PHY_LANE_0_CTRL; lane_ctrl <= PHY_LANE_3_CTRL; lane_ctrl++) {
+                        while ((nlm_hal_read_mac_reg(block, PHY, (lane_ctrl - 4)) & (LANE_TX_CLK)) != LANE_TX_CLK) {
+                                /* Wait for TX and RX clock to be set */
+                        }
+                        nlm_print("%s Blk%d lane%d got TX clock stable\n", __func__, block, lane_ctrl);
+
+                        while ((nlm_hal_read_mac_reg(block, PHY, (lane_ctrl - 4)) & (LANE_RX_CLK)) != LANE_RX_CLK) {
+                                /* Wait for TX and RX clock to be set */
+                        }
+                        nlm_print("%s Blk%d lane%d got RX clock stable\n", __func__, block, lane_ctrl);
+
+                }
+        }
+}
+
+uint16_t nlm_hal_get_hwport(uint32_t context)
+{
+	uint32_t rxbase = 0, rxbase1=0;
+	int i, port = 0;
+
+	for(i=0; i < 10; i++) {
+		rxbase = nlm_hal_read_nae_reg(RX_IF_BASE_CONFIG_0 + i);
+		if ((context >= (rxbase & 0x3FF)) && ( context < ((rxbase >> 16) & 0x3FF)))
+			return port;
+		port++;
+		rxbase1 = nlm_hal_read_nae_reg(RX_IF_BASE_CONFIG_0 + i + 1);
+		if ((context >= ((rxbase >> 16) & 0x3FF)) && ( context <  (rxbase1 & 0x3FF)))
+			return port;
+		port++;	
+	}
+	return MAX_GMAC_PORT;
+}
+
+#ifdef NLM_HAL_LINUX_KERNEL
+#include <linux/types.h>
+#include <linux/module.h>
+EXPORT_SYMBOL(nlm_hal_write_ucore_shared_mem);
+EXPORT_SYMBOL(nlm_hal_init_nae);
+EXPORT_SYMBOL(nae_cfg);
+EXPORT_SYMBOL(cntx2port);
+EXPORT_SYMBOL(rely_on_firmware_config);
+#endif /* #ifdef NLM_HAL_LINUX_KERNEL */
diff --git a/arch/mips/netlogic/xlp/Makefile b/arch/mips/netlogic/xlp/Makefile
new file mode 100644
index 0000000..3cc2115
--- /dev/null
+++ b/arch/mips/netlogic/xlp/Makefile
@@ -0,0 +1,9 @@
+EXTRA_CFLAGS := -Werror
+EXTRA_CFLAGS := $(CFLAGS) -DNLM_HAL_LINUX_KERNEL -Iarch/mips/include/asm/netlogic/hal
+
+obj-y                    	= setup.o
+obj-y 				+= irq.o time.o on_chip.o
+obj-$(CONFIG_NLM_XLP) 		+= platform.o board.o
+obj-$(CONFIG_SMP)       	+= smp.o
+
+obj-$(CONFIG_NLM_XLP) += cpu_control.o cpu_control_asm.o
diff --git a/arch/mips/netlogic/xlp/board.c b/arch/mips/netlogic/xlp/board.c
new file mode 100644
index 0000000..1c94bdf
--- /dev/null
+++ b/arch/mips/netlogic/xlp/board.c
@@ -0,0 +1,48 @@
+/***********************************************************************
+ * Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+ * reserved.
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ * *****************************#NETL_2#********************************/
+
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/platform_device.h>
+#include <linux/i2c.h>
+
+static struct i2c_board_info xlp_i2c_device_info[] __initdata = {
+	{
+		I2C_BOARD_INFO("ds1374", 0x68),
+	},
+	{
+		I2C_BOARD_INFO("lm90", 0x4c),
+	},
+	{
+		I2C_BOARD_INFO("at24c02", 0x57),
+	}
+};
+
+static int __init xlp_i2c_device_init(void)
+{
+	return i2c_register_board_info(1, xlp_i2c_device_info, ARRAY_SIZE(xlp_i2c_device_info));
+}
+
+arch_initcall(xlp_i2c_device_init);
diff --git a/arch/mips/netlogic/xlp/bootinfo.c b/arch/mips/netlogic/xlp/bootinfo.c
new file mode 100644
index 0000000..a9a034d
--- /dev/null
+++ b/arch/mips/netlogic/xlp/bootinfo.c
@@ -0,0 +1,93 @@
+#include <linux/stddef.h>
+#include <linux/string.h>
+
+#include <asm/bootinfo.h>
+#include <asm/netlogic/xlp.h>
+#include <asm/netlogic/bootinfo.h>
+#include <xen/interface/xen.h>
+
+static int is_valid_prominfo(struct psb_info *info)
+{
+	if (!prom_info) 
+		return -1;
+  
+	if ((prom_info->magic_dword & 0xffffffffULL) != 0x900dbeef) 
+		return -1;
+
+	if ((prom_info->magic_dword >> 32) != PSB_INFO_VERSION) 
+		return -1;
+
+	return 0;
+}
+
+int read_cmdline_args(int *argc, char *n_argv[], char *n_envp[])
+{
+	char **argv, **envp;
+	int i;
+	int32_t *t_argv;
+
+	*argc = (int)fw_arg0;
+	argv = (char **)(unsigned long)(int)fw_arg1;
+	envp = (char **)(unsigned long)(int)fw_arg2;
+
+		
+	for (i = 0, t_argv = (int32_t *)argv; i < *argc; i++, t_argv++)
+		n_argv[i] = (char *)(unsigned long)(*t_argv);
+
+		if (envp != NULL) {
+			int32_t *t_envp;
+
+			for (i = 0, t_envp = (int32_t *)envp; *t_envp; i++) {
+				n_envp[i] = (char *)(unsigned long)(*t_envp);
+				t_envp++;
+		}
+	}
+
+	return 0;
+}
+
+int read_prominfo(void)
+{
+	prom_info = &prom_info_copy;
+
+	memcpy((void *)prom_info, (void *)(unsigned long)(int)fw_arg3, 
+		   sizeof(struct psb_info));
+	
+	return is_valid_prominfo(prom_info);
+}
+
+/* TODO: Need to add right code here for XLP here */
+int read_dram_info(void)
+{
+	struct nlm_boot_mem_map *map;
+
+	if (!prom_info || (!prom_info->psb_mem_map && !prom_info->avail_mem_map)) 
+		return -1;
+
+	/* copy the mem_map from bootloader */
+	if (sizeof(*prom_info) <= prom_info->size && prom_info->avail_mem_map)
+		map = (struct nlm_boot_mem_map *) ((unsigned long)prom_info->avail_mem_map);	
+	else
+		map = (struct nlm_boot_mem_map *)((unsigned long)prom_info->psb_mem_map);
+	
+	if (!(map->nr_map > 0 && map->nr_map <= 32))
+		return -1;
+
+	copy_mem_map(&prom_map, map);
+	
+	return 0;
+}
+
+/* TODO: Is this valid for XLP ? */
+int read_physaddr_map(void)
+{
+	struct nlm_boot_mem_map *physaddr_map = (struct nlm_boot_mem_map *)
+		((unsigned long)prom_info->psb_physaddr_map);
+
+	if (physaddr_map == NULL)
+		return -1;
+
+	copy_mem_map(&boot_physaddr_info,  physaddr_map);
+
+	return 0;
+}
diff --git a/arch/mips/netlogic/xlp/cpu_control.c b/arch/mips/netlogic/xlp/cpu_control.c
new file mode 100644
index 0000000..444ab0b
--- /dev/null
+++ b/arch/mips/netlogic/xlp/cpu_control.c
@@ -0,0 +1,186 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/bootmem.h>
+#include <linux/init.h>
+#include <linux/pm.h>
+
+#include <asm/asm.h>
+#include <asm/irq.h>
+#include <asm/io.h>
+#include <asm/bootinfo.h>
+#include <asm/addrspace.h>
+#include <asm/reboot.h>
+#include <asm/time.h>
+#include <linux/interrupt.h>
+#include <asm/atomic.h>
+#include <asm/cacheflush.h>
+
+#include <asm/netlogic/xlp.h>
+#include <asm/netlogic/hal/nlm_hal.h>
+#include <asm/netlogic/mips-exts.h>
+
+#include "cpu_control_macros.h"
+
+#define XLP_ECFG_BASE           0x18000000
+#define XLP_SYS_DEV_BASE        0x35000
+
+/* temporary storage space for
+ * stack pointers
+ */
+unsigned long linuxsp[NR_CPUS];
+
+/* Externs
+ */
+extern unsigned char __stack[];
+extern char boot_siblings_start[], boot_siblings_end[];
+extern char reset_entry[], reset_entry_end[];
+
+static inline void jump_address(unsigned long entry)
+{
+	asm volatile (
+			".set push   	\n"
+			".set noreorder \n"
+			"jalr  %0     	\n"
+			"nop          	\n"
+			".set pop       \n"
+			:: "r"(entry));
+}
+
+/* Configure LSU */
+static inline void config_lsu(void)
+{
+	uint32_t tmp0, tmp1, tmp2;
+	__asm__ __volatile__ (
+		".set push\n"
+		".set noreorder\n"
+		"li      %0, "STR(LSU_DEFEATURE)"\n"
+		"mfcr    %1, %0\n"
+		"lui     %2, 0x4080\n"
+		"or      %1, %1, %2\n"
+		"li	 %2, ~0xe\n"
+		"and	 %1, %1, %2\n"
+		"mtcr    %1, %0\n"
+		"li      %0, "STR(SCHED_DEFEATURE)"\n"
+		"lui     %1, 0x0100\n"
+		"mtcr    %1, %0\n"
+		".set pop\n"
+		: "=r" (tmp0), "=r" (tmp1), "=r" (tmp2)
+	);
+}
+
+static void enable_cores(unsigned int node, unsigned int cores_bitmap)
+{
+	uint32_t core, value;
+	uint64_t sys_mmio;
+	uint32_t cbitmap = cores_bitmap;
+
+	/* if n0c0t0, don't pull yourself out of reset! */
+	if(node == 0) cbitmap = cbitmap & 0xfe;
+
+	printk("[%s] node@%d, cores_bitmap = 0x%08x cbitmap = 0x%08x\n",
+	       __func__, node, cores_bitmap, cbitmap);
+
+        sys_mmio = (uint64_t) (XLP_ECFG_BASE + XLP_SYS_DEV_BASE + 0x40000 * node );
+
+	for (core = 0x1; core != (0x1 << 8); core <<= 1) {
+
+		if ( (cbitmap & core) == 0) continue;
+
+		/* Enable CPU clock
+		 */
+		value = nlm_hal_read_32bit_reg(sys_mmio,0x4E) & ~core;
+		nlm_hal_write_32bit_reg(sys_mmio, 0x4E, value);
+
+		/* Remove CPU Reset */
+		value = nlm_hal_read_32bit_reg(sys_mmio, 0x4B) & ~core;
+		nlm_hal_write_32bit_reg(sys_mmio, 0x4B, value);
+
+		/* Poll for CPU to mark itself coherent */
+		for(;;) {
+			value = nlm_hal_read_32bit_reg(sys_mmio, 0x4D) & core;
+			if (!value) break;
+		}
+	}
+}
+
+int threads_to_enable = 1;
+/*
+ * This function is called once for each node. However, it is executed
+ * only on "master cpu", mostly on n0c0t0
+ */
+void enable_cpus(unsigned int node, unsigned int node_cpumask)
+{
+	uint32_t t0_bitmap = 0x0;
+	uint32_t t0_positions = 0, index = 0;
+	uint32_t cores_bitmap;
+
+	if (hard_smp_processor_id() != 0) {
+		printk("[%s]: Running on non n0c0t0 cpu??\n", __func__);
+		return;
+	}
+
+	/* Setup Exception vectors only the first time around */
+	if (!node) {
+
+		config_lsu();
+
+		/* Linux runs out of KSEG2. Setup TLBs
+		 * for other threads, by running from
+		 * KSEG0. Then, jump back into KSEG2.
+		 */
+		memcpy((void *)(NMI_BASE + (2<<10)),
+		       (void *)&boot_siblings_start,
+		       (boot_siblings_end - boot_siblings_start));
+
+		/* setup the reset vector */
+		memcpy((void *)(NMI_BASE), (void *)&reset_entry, (reset_entry_end - reset_entry));
+
+	}
+
+	/* bitmap of thread@0 of every core in this node */
+	t0_bitmap = node_cpumask & 0x11111111;
+
+	cores_bitmap = 0;
+	for (t0_positions = 0, index = 0; t0_positions < 32; t0_positions += 4, index++) {
+		if (t0_bitmap & (1 << t0_positions))
+			cores_bitmap |= (1 << index);
+	}
+
+	threads_to_enable = num_ones(node_cpumask & 0xf);
+
+	printk("node@%d: t0_bitmap = 0x%08x, cores_bitmap = 0x%08x\n", node, t0_bitmap, cores_bitmap);
+
+	enable_cores(node, cores_bitmap);
+
+	if (!node) {
+		/* Wakeup threads of n0c0 */
+		jump_address(NMI_BASE + (2<<10));
+	}
+
+	return;
+}
diff --git a/arch/mips/netlogic/xlp/cpu_control_asm.S b/arch/mips/netlogic/xlp/cpu_control_asm.S
new file mode 100644
index 0000000..eafdb54
--- /dev/null
+++ b/arch/mips/netlogic/xlp/cpu_control_asm.S
@@ -0,0 +1,200 @@
+#include <asm/asm.h>
+#include <asm/asm-offsets.h>
+#include <asm/regdef.h>
+#include <asm/mipsregs.h>
+#include <asm/stackframe.h>
+#include <asm/asmmacro.h>
+
+#include <asm/netlogic/mips-exts.h>
+#include <kernel-entry-init.h>
+#include "cpu_control_macros.h"
+
+	.macro  prog_c0_status set clr
+	.set 	push
+	mfc0    t0, CP0_STATUS
+	or  	t0, ST0_CU0|\set|0x1f|\clr
+	xor 	t0, 0x1f|\clr
+	mtc0    t0, CP0_STATUS
+	.set    noreorder
+	sll 	zero,3              # ehb
+	.set    pop
+	.endm
+
+	.macro 	__start_secondary
+	.set push
+	mtc0    zero, CP0_WIRED
+#ifdef CONFIG_64BIT
+	prog_c0_status ST0_KX ST0_BEV
+#else
+	prog_c0_status 0 ST0_BEV
+#endif
+	mfc0 		t0, CP0_EBASE, 1
+	andi 		t0, 0x7f
+	PTR_LA		t1, xlp_stack_pages_temp
+	li   		t2, _THREAD_SIZE
+	srl  		t2, 2
+	mul  		t3, t2, t0
+	PTR_ADDU  	gp, t1, t3
+	PTR_ADDU  	sp, gp, t2
+	PTR_ADDI  	sp, sp, -64
+	PTR_LA t0, 	prom_boot_cpus_secondary
+	jr 			t0
+	nop
+	.set pop
+    .endm
+
+.macro __config_lsu
+	.set push
+	.set noreorder
+	li      t0, LSU_DEFEATURE
+	mfcr    t1, t0
+
+	lui     t2, 0x4080  # Enable Unaligned Access, L2HPE
+	or      t1, t1, t2
+
+	li	t2, ~0xe    # S1RCM
+	and	t1, t1, t2
+
+	mtcr    t1, t0
+
+	li      t0, SCHED_DEFEATURE
+	lui     t1, 0x0100 # Experimental: Disable BRU accepting ALU ops
+	mtcr    t1, t0
+
+	.set pop
+.endm
+
+	/* T0 of Non-0 Cores jump
+	 * here, from enable_cores
+	 * This code sits in KSEG0
+	 * (@0xbfc00000)
+	 */
+EXPORT(reset_entry)
+	mfc0    t0, CP0_EBASE, 1
+	mfc0	t1, CP0_EBASE, 1
+	andi	t1, 0x60
+	srl	t1,  5
+	li	t2, 0x40000  #load 0x40000
+	mul	t3, t2, t1  #t3 = node * 0x40000
+	srl     t0, t0 , 2
+	and     t0, t0 , 0x7 # t0 contains the core number
+	li      t1, 0x1
+	sll     t0, t1, t0
+	nor     t0, t0, zero
+	dla     t2, CPU_MMIO_OFFSET(SYS)
+	add	t2, t2, t3  #get node based SYS offset
+	lw      t1, (SYS_CPUNONCOHERENTMODE_REG << 2)(t2)
+	and     t1, t1, t0
+	sw      t1, (SYS_CPUNONCOHERENTMODE_REG << 2)(t2)
+
+	/* read back to ensure complete */
+	lw      t1, (SYS_CPUNONCOHERENTMODE_REG << 2)(t2)
+	sync
+
+	/* Configure LSU on Non-0 Cores. */
+	__config_lsu
+
+	dla     t1, boot_siblings_start
+	dla     t2, __boot_siblings
+	subu	t2, t2, t1		/* t2 now has the jump offset */
+
+	/* Jump to KSEG0 addr of __boot_siblings
+	 * We cant use 'dla' here.
+	 */
+	dli 	k0,	NMI_BASE_ASM
+	ori 	k0,	k0, 2048
+	addu    k0, k0, t2
+	jr	    k0
+	nop
+EXPORT(reset_entry_end)
+
+	/* boot_siblings is copied into
+	 * NMI_BASE in KSEG0 space. This
+	 * sets up TLBs for other threads
+	 * so that non-0 threads can run
+	 * out of KSEG2
+	 */
+
+EXPORT(boot_siblings_start)			/* "Master" (n0c0t0) cpu starts from here */
+	.set 	noreorder
+	LONG_S  sp, linuxsp($0)
+	SAVE_ALL
+	sync
+
+EXPORT(__boot_siblings)				/* T0 of every core in every node starts from here */
+	lw      t1, threads_to_enable
+	beq     t1, 0x2, 2f
+	nop
+	addi    t1, -1
+2:
+	li      t0, ((CPU_BLOCKID_MAP << 8) | BLKID_MAP_THREADMODE)
+	mfcr    t2, t0
+	or  	t2, t2, t1
+	mtcr    t2, t0
+
+	/* threads (incl. T0) of this core
+	 * start fetching from this point
+	 */
+	mfc0    t0, CP0_EBASE, 1		/* EBASE, Select 1 	*/
+	andi    t0, 0x7f		        /* Linear CPU ID	*/
+	beqz    t0, 2f
+	nop
+1:
+    __start_secondary				/* "Slave" cpu (of every core on every node) go here */
+2:
+	LONG_L   sp, linuxsp($0)		/* "Master" (n0c0t0) cpu restores from here */
+	PTR_SUBU sp, PT_SIZE
+	RESTORE_ALL
+
+	jr   ra
+	nop
+EXPORT(boot_siblings_end)
+
+NESTED(ptr_smp_boot, 16, sp)
+
+        move    sp, a1
+        move    gp, a2
+        jal     a0
+        nop
+
+END(ptr_smp_boot)
+
+	.macro	setup_c0_status set clr
+	.set	push
+	mfc0	t0, CP0_STATUS
+	or	t0, ST0_CU0|\set|0x1f|\clr
+	xor	t0, 0x1f|\clr
+	mtc0	t0, CP0_STATUS
+	.set	noreorder
+	sll	zero,3				# ehb
+	.set	pop
+	.endm
+
+/* Don't jump to linux function from Bootloader stack. Change it
+ * here. Kernel might allocate bootloader memory before all the CPUs are
+ * brought up (eg: Inode cache region) and we better don't overwrite this
+ * memory
+ */
+NESTED(prom_pre_boot_secondary_cpus, 16, sp)
+        SET_MIPS64
+	mtc0    zero, CP0_WIRED
+
+	/* Don't trust the bootstrapper to set cp0_status to what you want */
+#ifdef CONFIG_64BIT
+	setup_c0_status ST0_KX ST0_BEV
+#else
+	setup_c0_status 0 ST0_BEV
+#endif
+	mfc0 t0, CP0_EBASE, 1 #read ebase
+        andi t0, 0x7f #t0 has the processor_id()
+        PTR_LA  t1, xlp_stack_pages_temp
+        li   t2, _THREAD_SIZE
+        srl  t2, 2
+        mul  t3, t2, t0
+        PTR_ADDU  gp, t1, t3
+        PTR_ADDU       sp, gp, t2
+        PTR_ADDI       sp, sp, -32
+        PTR_LA t0, prom_boot_cpus_secondary
+        jr t0
+        nop
+END(prom_pre_boot_secondary_cpus)
diff --git a/arch/mips/netlogic/xlp/cpu_control_macros.h b/arch/mips/netlogic/xlp/cpu_control_macros.h
new file mode 100644
index 0000000..69ac013
--- /dev/null
+++ b/arch/mips/netlogic/xlp/cpu_control_macros.h
@@ -0,0 +1,155 @@
+#ifndef __CPUCONTROL_MACROS_H__
+#define __CPUCONTROL_MACROS_H__
+
+#define CP0_EBASE	$15
+#define CHIP_PID_XLP    0x00
+#define NMI_BASE    	0xffffffffbfc00000UL
+#define NMI_BASE_ASM   	0xbfc00000
+
+/* CPU Internal Blocks specific to XLP .
+ * These are accessed using the mfcr/mtcr
+ * instructions. Blocks [0-5] are same for
+ * XLR and XLP
+ */
+#define CPU_BLOCKID_MAP                         0x0a
+/* Offsets of interest from the 'MAP' Block */
+#define BLKID_MAP_THREADMODE                    0x00 
+#define BLKID_MAP_EXT_EBASE_ENABLE              0x04 
+#define BLKID_MAP_CCDI_CONFIG                   0x08
+#define BLKID_MAP_THRD0_CCDI_STATUS             0x0c    
+#define BLKID_MAP_THRD1_CCDI_STATUS             0x10
+#define BLKID_MAP_THRD2_CCDI_STATUS             0x14    
+#define BLKID_MAP_THRD3_CCDI_STATUS             0x18
+#define BLKID_MAP_THRD0_DEBUG_MODE              0x1c
+#define BLKID_MAP_THRD1_DEBUG_MODE              0x20
+#define BLKID_MAP_THRD2_DEBUG_MODE              0x24
+#define BLKID_MAP_THRD3_DEBUG_MODE              0x28
+#define BLKID_MAP_MISC_STATE                    0x60
+#define BLKID_MAP_DEBUG_READ_CTL                0x64
+#define BLKID_MAP_DEBUG_READ_REG0               0x68
+#define BLKID_MAP_DEBUG_READ_REG1               0x6c
+
+#define CPU_BLOCKID_SCH                         7
+#define CPU_BLOCKID_SCU                         8
+#define CPU_BLOCKID_FPU                         9
+
+#define LSU_DEFEATURE 0x304
+#define MMU_SETUP 0x400
+#define SCHED_DEFEATURE 0x700
+
+/* ----------------------------------
+ *   XLP RESET Physical Address Map
+ * ----------------------------------
+ * PCI ECFG : 0x18000000 - 0x1bffffff 
+ * PCI CFG  : 0x1c000000 - 0x1cffffff 
+ * FLASH    : 0x1fc00000 - 0x1fffffff 
+ * ----------------------------------
+ */
+
+/* 
+ * The DEFAULT_XLP_IO_BASE value is what is
+ * programmed in the NBU's (NorthBridge Unit) 
+ * ECFG_BAR register. The NBU itself is 
+ * accessible as [BDF:0,0,0].
+ */
+#define DEFAULT_XLP_IO_BASE       0xffffffffb8000000ULL
+#define DEFAULT_XLP_IO_BASE_VIRT  0xffffffffb8000000      /* IO_BASE for Assembly macros */
+#define DEFAULT_CPU_IO_BASE       DEFAULT_XLP_IO_BASE
+#define DEFAULT_CPU_IO_BASE_VIRT  DEFAULT_XLP_IO_BASE_VIRT
+#define CPU_IO_SIZE               (64<<20)        /* Size of the ECFG Space      */
+#define HDR_OFFSET                0x100           /* Skip 256 bytes of cfg. hdrs */
+
+/* The On-Chip functional blocks for XLP */
+
+/* --------------------------------------------------------------*/
+/* Accesses Based on Enhanced Configuration Mechanism            */
+/* --------------------------------------------------------------*/
+/* Interface | Bus          | Dev       |  Func                  */
+/* --------------------------------------------------------------*/
+#define        BRIDGE        (0x00<<20) | (0x00<<15) | (0x00<<12)
+#define        PIC           (0x00<<20) | (0x00<<15) | (0x04<<12)
+#define        CMS           (0x00<<20) | (0x04<<15) | (0x00<<12)
+#define        UART0         (0x00<<20) | (0x06<<15) | (0x00<<12)
+#define        UART1         (0x00<<20) | (0x06<<15) | (0x01<<12)
+#define        I2C0          (0x00<<20) | (0x06<<15) | (0x02<<12)
+#define        I2C1          (0x00<<20) | (0x06<<15) | (0x03<<12)
+#define        GPIO          (0x00<<20) | (0x06<<15) | (0x04<<12)
+#define        SYS           (0x00<<20) | (0x06<<15) | (0x05<<12)
+#define        JTAG          (0x00<<20) | (0x06<<15) | (0x06<<12)
+#define        NOR           (0x00<<20) | (0x07<<15) | (0x00<<12)
+#define        NAND          (0x00<<20) | (0x07<<15) | (0x01<<12)
+#define        SPI           (0x00<<20) | (0x07<<15) | (0x02<<12)
+#define        MMC           (0x00<<20) | (0x07<<15) | (0x03<<12)
+
+#define CPU_MMIO_OFFSET(x) (DEFAULT_CPU_IO_BASE_VIRT + (x) + HDR_OFFSET)
+
+
+#define SYS_CHIPRST_REG                 0
+#define SYS_PWRONRSTCFG0_REG            1
+#define SYS_EFUSEDEV_CFG0_REG           2
+#define SYS_EFUSEDEV_CFG1_REG           3
+#define SYS_EFUSEDEV_CFG2_REG           4
+#define SYS_EFUSEDEV_CFG3_REG           5
+#define SYS_EFUSEDEV_CFG4_REG           6
+#define SYS_EFUSEDEV_CFG5_REG           7
+#define SYS_EFUSEDEV_CFG6_REG           8
+#define SYS_EFUSEDEV_CFG7_REG           9 
+#define SYS_PLLCTRL_REG                 10
+#define SYS_CPURST_REG                  11
+#define SYS_CPUTHREADEN_REG             12
+#define SYS_CPUNONCOHERENTMODE_REG      13
+#define SYS_COREDFSDISCTRL_REG          14
+#define SYS_COREDFSRSTCTRL_REG          15
+#define SYS_COREDFSBYPCTRL_REG          16
+#define SYS_COREDFSPHACTRL_REG          17
+#define SYS_COREDFSDIVCTRL_REG          18
+#define SYS_SYSRST_REG                  19
+#define SYS_SYSDFSDISCTRL_REG           20
+#define SYS_SYSDFSRSTCTRL_REG           21
+#define SYS_SYSDFSBYPCTRL_REG           22
+#define SYS_SYSDFSDIVCTRL_REG           23
+#define SYS_DMCDFSCTRL_REG              24
+
+#ifndef __ASSEMBLY__
+
+static inline int num_ones(unsigned long mask)
+{
+	int  nones;
+	for (nones = 0; mask; mask >>= 1) {
+		if (mask & 0x1)
+			++nones;
+	}
+	return nones;
+}
+
+enum processor_sys
+{
+	SYS_CHIPRST                     = 0,
+	SYS_PWRONRSTCFG0                = 1,
+	SYS_EFUSEDEV_CFG0               = 2,
+	SYS_EFUSEDEV_CFG1               = 3,
+	SYS_EFUSEDEV_CFG2               = 4,
+	SYS_EFUSEDEV_CFG3               = 5,
+	SYS_EFUSEDEV_CFG4               = 6,
+	SYS_EFUSEDEV_CFG5               = 7,
+	SYS_EFUSEDEV_CFG6               = 8,
+	SYS_EFUSEDEV_CFG7               = 9, 
+	SYS_PLLCTRL                     = 10,
+	SYS_CPURST                      = 11,
+	SYS_CPUTHREADEN                 = 12,
+	SYS_CPUNONCOHERENTMODE          = 13,
+	SYS_COREDFSDISCTRL              = 14,
+	SYS_COREDFSRSTCTRL              = 15,
+	SYS_COREDFSBYPCTRL              = 16,
+	SYS_COREDFSPHACTRL              = 17,
+	SYS_COREDFSDIVCTRL              = 18,
+	SYS_SYSRST                      = 19,
+	SYS_SYSDFSDISCTRL               = 20,
+	SYS_SYSDFSRSTCTRL               = 21,
+	SYS_SYSDFSBYPCTRL               = 22,
+	SYS_SYSDFSDIVCTRL               = 23,
+	SYS_DMCDFSCTRL                  = 24
+};
+
+#endif
+#endif /* __CPUCONTROL_MACROS_H__ */
diff --git a/arch/mips/netlogic/xlp/irq.c b/arch/mips/netlogic/xlp/irq.c
new file mode 100644
index 0000000..42b2295
--- /dev/null
+++ b/arch/mips/netlogic/xlp/irq.c
@@ -0,0 +1,415 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems ("Netlogic") All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/kernel_stat.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/linkage.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/slab.h>
+#include <linux/pci.h>
+#include <asm/errno.h>
+#include <asm/signal.h>
+#include <asm/system.h>
+#include <asm/ptrace.h>
+#include <asm/kgdb.h>
+#include <asm/mipsregs.h>
+#include <asm/time.h>
+
+#include <asm/netlogic/cpumask.h>
+#include <asm/netlogic/xlp.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/pic.h>
+#include <asm/netlogic/debug.h>
+#include <asm/thread_info.h>
+#include <linux/irq.h>
+#include <asm/netlogic/hal/nlm_hal_pic.h>
+/*
+ * These are the routines that handle all the low level interrupt stuff. 
+ * Actions handled here are: initialization of the interrupt map, requesting of
+ * interrupt lines by handlers, dispatching if interrupts to handlers, probing
+ * for interrupt lines 
+ */
+
+/* Externs */
+extern void nlm_xlp_msgring_int_handler(int irq, struct pt_regs *regs);
+
+uint64_t nlm_xlp_irq_mask;
+spinlock_t nlm_common_pic_lock = SPIN_LOCK_UNLOCKED;
+
+static void pic_unmask(unsigned int irq)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+	unsigned long flags;
+	nlm_reg_t reg;
+	unsigned long irt;
+
+	if(irq < 8) {
+		return;
+	}
+	irt = find_irt_from_irq(irq);
+	if(irt == -1)
+	{
+		printk("can't find irt for irq: %d\n",irq);
+		return;
+	}
+
+	spin_lock_irqsave(&nlm_common_pic_lock, flags);
+
+	/* What happens if this irq was previously not ack'ed? 
+	 * Assume, that doesn't happen?
+	 */
+	reg = nlm_hal_read_pic_reg(mmio, PIC_IRT(irt));
+	/* By default all the interrupts are initialized as level senstive - fix for the PCMCIA flash */
+	nlm_hal_write_pic_reg(mmio, PIC_IRT(nlm_hal_irq_to_irt(irq)),
+		      reg | (1 << 28) | (1 << 31));
+
+	spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+
+	return;
+}
+
+static void pic_ack(unsigned int irq)
+{
+	unsigned long flags;
+	unsigned long irt;
+	/*uint64_t val;*/
+
+
+	if(irq < 8) {
+		return;
+	}
+	irt = find_irt_from_irq(irq);
+	if(irt == -1)
+	{
+		printk("can't find irt for irq: %d\n",irq);
+		return;
+	}
+	/* If edge triggered IRQ, ack it immediately, else when the device
+	 * interrupt condition is cleared, we may lose interrupts 
+	 */
+	if (PIC_IRQ_IS_EDGE_TRIGGERED(irq)) {
+		spin_lock_irqsave(&nlm_common_pic_lock, flags);
+		nlm_hal_ack_pic(irt);
+		spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+	}
+}
+
+static void pic_end(unsigned int irq)
+{
+	unsigned long flags;
+	unsigned long irt;
+	/*uint64_t val;*/
+
+	if(irq < 8) {
+		return;
+	}
+	irt = find_irt_from_irq(irq);
+	if(irt == -1)
+	{
+		printk("can't find irt for irq: %d\n",irq);
+		return;
+	}
+	/* If level triggered, ack it after the device condition is cleared */
+	if (!PIC_IRQ_IS_EDGE_TRIGGERED(irq)) {
+		spin_lock_irqsave(&nlm_common_pic_lock, flags);
+		nlm_hal_ack_pic(nlm_hal_irq_to_irt(irq));
+		spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+	}
+}
+
+static void pic_shutdown(unsigned int irq)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+	unsigned long flags;
+	nlm_reg_t reg;
+	unsigned long irt;
+
+	if(irq < 8) {
+		return;
+	}
+	irt = find_irt_from_irq(irq);
+	if(irt == -1)
+	{
+		printk("can't find irt for irq: %d\n",irq);
+		return;
+	}
+
+	spin_lock_irqsave(&nlm_common_pic_lock, flags);
+
+	/* What happens if this irq is currently pending an ack? 
+	 * Assume, that doesn't happen?
+	 */
+	reg = nlm_hal_read_pic_reg(mmio, PIC_IRT(irt));
+	nlm_hal_write_pic_reg(mmio, PIC_IRT(irt), (reg & ~(1 << 31)));
+
+	spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+}
+
+/*
+ * Set affinity for the irq for chips
+ * 
+ */
+
+static int pic_set_affinity(unsigned int irq, const cpumask_t *mask)
+{
+	unsigned long flags;
+	int cpu;
+
+	spin_lock_irqsave(&nlm_common_pic_lock, flags);
+	for_each_online_cpu(cpu){
+		if(cpumask_test_cpu(cpu, mask))
+		{
+			nlm_hal_set_irq_to_cpu(irq, cpu);
+		}
+	}
+	spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+
+	return 0;
+}
+
+static struct irq_chip nlm_common_pic = {
+	.name = "XLP-PIC",
+	.unmask = pic_unmask,
+	.mask = pic_shutdown,
+	.ack = pic_ack,
+	.end = pic_end,
+	.set_affinity = pic_set_affinity
+};
+
+static void rsvd_pic_handler_1_1(unsigned int irq)
+{
+	if(irq < PIC_IRQ_BASE)
+		return;
+  dbg_msg("Requesting a reserved irq (%d)??", irq);
+  return;
+}
+
+static void rsvd_pic_handler_1(unsigned int irq)
+{
+	if(irq < PIC_IRQ_BASE)
+		return;
+  dbg_msg("handler called for a reserved irq (%d)\n", irq);
+}
+
+static int rsvd_pic_handler_2(unsigned int irq, const struct cpumask *mask)
+{
+	if(irq < PIC_IRQ_BASE)
+		return -1;
+
+	dbg_msg("handler called for a reserved irq (%d)\n", irq);
+	return 0;
+}
+
+struct irq_chip nlm_rsvd_pic_irq_timer = {
+        .name = "Count-Compare",
+        .unmask = rsvd_pic_handler_1_1,
+        .mask = rsvd_pic_handler_1,
+        .ack = rsvd_pic_handler_1,
+        .end = rsvd_pic_handler_1,
+        .set_affinity = rsvd_pic_handler_2
+};
+
+struct irq_chip nlm_rsvd_pic_irq_oprofile = {
+        .name = "Oprofile",
+        .unmask = rsvd_pic_handler_1_1,
+        .mask = rsvd_pic_handler_1,
+        .ack = rsvd_pic_handler_1,
+        .end = rsvd_pic_handler_1,
+        .set_affinity = rsvd_pic_handler_2
+};
+
+struct irq_chip nlm_common_rsvd_pic = {
+	.name = "Netlogic-RSVD-PIC",
+	.unmask = rsvd_pic_handler_1_1,
+	.mask = rsvd_pic_handler_1,
+	.ack = rsvd_pic_handler_1,
+	.end = rsvd_pic_handler_1,
+	.set_affinity = rsvd_pic_handler_2
+};
+
+static irqreturn_t nlm_common_rsvd_irq_handler(int irq, void *dev_id)
+{
+	if(irq == IRQ_TIMER) 
+		return IRQ_HANDLED;
+  dbg_msg("handler for reserved irq %d\n", irq);
+  return IRQ_NONE;
+}
+
+struct irqaction nlm_common_rsvd_action = {
+	.handler = nlm_common_rsvd_irq_handler,
+	.flags = 0,
+	.name = "nlm_common_rsvd_action",
+	.dev_id = 0,
+	.next = 0
+};
+
+struct irqaction msgring_action = {
+	.handler = nlm_common_rsvd_irq_handler,
+	.name = "msgring",
+};
+
+struct irqaction ipi_smp_func_action = {
+	.handler = nlm_common_rsvd_irq_handler,
+	.name = "ipi_smp_func",
+};
+
+struct irqaction ipi_smp_resched_action = {
+	.handler = nlm_common_rsvd_irq_handler,
+	.name = "ipi_smp_resched",
+};
+
+extern nlm_common_atomic_t msgring_registered;
+
+void    
+handle_msgring_irq(unsigned int irq, struct irq_desc *desc)
+{
+	kstat_incr_irqs_this_cpu(irq, desc);
+
+	nlm_xlp_msgring_int_handler(irq, NULL);
+}
+
+void handle_ipi_irq(unsigned int irq, struct irq_desc *desc)
+{
+	kstat_incr_irqs_this_cpu(irq, desc);
+
+	if (irq == IRQ_IPI_SMP_FUNCTION)
+		smp_call_function_interrupt();
+	else if (irq == IRQ_IPI_SMP_RESCHEDULE) /* for reschduling */
+		set_need_resched();
+}
+
+void __init init_nlm_common_irqs(void)
+{
+	int i;
+
+	for (i = 0; i < NR_IRQS; i++) {
+		set_irq_chip_and_handler(i, &nlm_common_pic, handle_level_irq);
+	}
+
+#ifdef CONFIG_REMOTE_DEBUG
+	irq_desc[IRQ_REMOTE_DEBUG].chip = &nlm_common_rsvd_pic;
+	irq_desc[IRQ_REMOTE_DEBUG].action = nlm_common_rsvd_action;
+	nlm_xlp_irq_mask |= (1ULL << IRQ_REMOTE_DEBUG);
+#endif
+
+#ifdef CONFIG_SMP
+	irq_desc[IRQ_IPI_SMP_FUNCTION].chip = &nlm_common_rsvd_pic;
+	irq_desc[IRQ_IPI_SMP_FUNCTION].action = &ipi_smp_func_action;
+	set_irq_handler(IRQ_IPI_SMP_FUNCTION, handle_ipi_irq);
+
+	irq_desc[IRQ_IPI_SMP_RESCHEDULE].chip = &nlm_common_rsvd_pic;
+	irq_desc[IRQ_IPI_SMP_RESCHEDULE].action = &ipi_smp_resched_action;
+	set_irq_handler(IRQ_IPI_SMP_RESCHEDULE, handle_ipi_irq);
+
+	nlm_xlp_irq_mask |=
+	    ((1ULL << IRQ_IPI_SMP_FUNCTION) | (1ULL << IRQ_IPI_SMP_RESCHEDULE));
+#endif
+
+	/* msgring interrupt */
+	irq_desc[IRQ_MSGRING].chip = &nlm_common_rsvd_pic;
+	irq_desc[IRQ_MSGRING].action = &msgring_action;
+	set_irq_handler(IRQ_MSGRING, handle_msgring_irq);
+	nlm_xlp_irq_mask |= (1ULL << IRQ_MSGRING);
+
+	/* unmask all PIC related interrupts. If no handler is installed by the 
+	 * drivers, it'll just ack the interrupt and return 
+	 */
+	for (i = PIC_IRT_FIRST_IRQ; i <= PIC_IRT_LAST_IRQ(); i++)
+		nlm_xlp_irq_mask |= (1ULL << i);
+
+#ifdef CONFIG_KGDB
+	nlm_xlp_irq_mask |= (1ULL << IRQ_IPI_SMP_KGDB);
+#endif
+
+	irq_desc[IRQ_TIMER].chip = &nlm_rsvd_pic_irq_timer;
+	irq_desc[IRQ_TIMER].action = NULL;
+	nlm_xlp_irq_mask |= (1ULL << IRQ_TIMER);
+}
+
+void __cpuinit nlm_smp_irq_init(void)
+{
+#ifdef XLP_MERGE_TODO
+	/* Set up kseg0 to be cachable coherent */
+	change_c0_config(CONF_CM_CMASK, CONF_CM_DEFAULT);
+#endif
+	/* set interrupt mask for non-zero cpus */
+	write_64bit_cp0_eimr(nlm_xlp_irq_mask | (1 << IRQ_TIMER));
+}
+
+void __init arch_init_irq(void)
+{
+#ifdef CONFIG_KGDB
+	if (kgdb_early_setup)
+		return;
+#endif
+
+	/* Initialize the irq descriptors */
+	init_nlm_common_irqs();
+
+	write_64bit_cp0_eimr(nlm_xlp_irq_mask);
+}
+
+asmlinkage void plat_irq_dispatch(void)
+{
+	uint64_t eirr, eimr, pending;
+	int irq = 0;
+
+	eirr = read_64bit_cp0_eirr();
+	eimr = read_64bit_cp0_eimr();
+
+	pending = eirr & eimr;
+	if (unlikely(!pending)) {
+		/* According to the datasheet eirr must be cleared manually */
+		if (eirr & ~eimr)
+			write_64bit_cp0_eirr(eirr & ~eimr);
+		return;
+	}
+
+	if (pending & (1 << IRQ_TIMER)) {
+		/* ack */
+		write_64bit_cp0_eirr(1ULL << IRQ_TIMER);
+		do_IRQ(IRQ_TIMER);
+		return;
+	}
+
+	for (irq = 63; irq != -1; irq--) {
+		if (pending & (1ULL << irq))
+			break;
+		else if (eirr & (1ULL << irq)) {	/* eirr also must be cleared */
+			write_64bit_cp0_eirr(1ULL << irq);
+			continue;
+		}
+	}
+	if (irq == -1)
+		return;
+
+	/* ack interrupts */
+	write_64bit_cp0_eirr(1ULL << irq);
+
+	do_IRQ(irq);
+}
diff --git a/arch/mips/netlogic/xlp/nmi.S b/arch/mips/netlogic/xlp/nmi.S
new file mode 100644
index 0000000..0a1d321
--- /dev/null
+++ b/arch/mips/netlogic/xlp/nmi.S
@@ -0,0 +1,53 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems ("Netlogic")~l rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/init.h>
+
+#include <asm/asm.h>
+#include <asm/asmmacro.h>
+#include <asm/cacheops.h>
+#include <asm/irqflags.h>
+#include <asm/regdef.h>
+#include <asm/fpregdef.h>
+#include <asm/mipsregs.h>
+#include <asm/stackframe.h>
+#include <asm/war.h>
+#include <asm/page.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/interrupt.h>
+
+
+NESTED(nlm_except_vec_nmi, 0, sp)
+	.set push
+	.set noat
+	.set mips64
+	.set noreorder
+1:	wait
+	b	1b
+	nop
+	.set pop
+END(nlm_except_vec_nmi)
+
+#endif
diff --git a/arch/mips/netlogic/xlp/on_chip.c b/arch/mips/netlogic/xlp/on_chip.c
new file mode 100644
index 0000000..39c6874
--- /dev/null
+++ b/arch/mips/netlogic/xlp/on_chip.c
@@ -0,0 +1,453 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/types.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/timer.h>
+
+#include <asm/netlogic/iomap.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/debug.h>
+#include <asm/netlogic/xlp.h>
+
+#include <asm/netlogic/hal/nlm_hal_fmn.h>
+#include <asm/netlogic/hal/nlm_hal_pic.h>
+
+#define MAX_VC	4096
+
+unsigned long netlogic_io_base = (unsigned long)(DEFAULT_NETLOGIC_IO_BASE);
+EXPORT_SYMBOL(netlogic_io_base);
+
+extern int hwemul;
+
+extern void nlm_cpu_stat_update_msgring_int(void);
+extern void nlm_cpu_stat_update_msgring_cycles(__u32 cycles);
+extern void nlm_cpu_stat_update_msgring_pic_int(void);
+
+uint32_t msgring_global_thread_mask = 0;
+uint32_t nlm_cpu_vc_mask[NLM_MAX_CPU_NODE*NLM_MAX_CPU_PER_NODE] = {0};
+
+/* make this a read/write spinlock */
+spinlock_t msgrng_lock;
+nlm_common_atomic_t msgring_registered;
+
+struct msgstn_handler {
+        void (*action)(uint32_t, uint32_t, uint32_t, uint32_t, uint64_t, uint64_t, uint64_t, uint64_t, void *);
+        void *dev_id;
+};
+
+static uint16_t vc_to_handle_map[MAX_VC] = {
+	[0 ... 15] = XLP_MSG_HANDLE_CPU0,
+	[16 ... 31] = XLP_MSG_HANDLE_CPU1,
+	[32 ... 47] = XLP_MSG_HANDLE_CPU2,
+	[48 ... 63] = XLP_MSG_HANDLE_CPU3,
+	[64 ... 79] = XLP_MSG_HANDLE_CPU4,
+	[80 ... 85] = XLP_MSG_HANDLE_CPU5,
+	[96 ... 111] = XLP_MSG_HANDLE_CPU6,
+	[112 ... 127] = XLP_MSG_HANDLE_CPU7,
+	[128 ... 143] = XLP_MSG_HANDLE_CPU0,
+	[144 ... 159] = XLP_MSG_HANDLE_CPU1,
+	[160 ... 175] = XLP_MSG_HANDLE_CPU2,
+	[176 ... 191] = XLP_MSG_HANDLE_CPU3,
+	[192 ... 207] = XLP_MSG_HANDLE_CPU4,
+	[208 ... 223] = XLP_MSG_HANDLE_CPU5,
+	[224 ... 239] = XLP_MSG_HANDLE_CPU6,
+	[240 ... 255] = XLP_MSG_HANDLE_CPU7,
+	[256 ... 257] = XLP_MSG_HANDLE_PCIE0,
+	[258 ... 259] = XLP_MSG_HANDLE_PCIE1,
+	[260 ... 261] = XLP_MSG_HANDLE_PCIE2,
+	[262 ... 263] = XLP_MSG_HANDLE_PCIE3,
+	[264 ... 271] = XLP_MSG_HANDLE_GDX,
+	[272 ... 280] = XLP_MSG_HANDLE_RSA_ECC,
+	[281 ... 296] = XLP_MSG_HANDLE_CRYPTO,
+	[297 ... 304] = XLP_MSG_HANDLE_CMP,
+	[305 ... 383] = XLP_MSG_HANDLE_INVALID,
+	[384 ... 391] = XLP_MSG_HANDLE_NAE_0,
+	[392 ... 475] = XLP_MSG_HANDLE_INVALID,
+	[476] 	      = XLP_MSG_HANDLE_NAE_0,
+	[477] 	      = XLP_MSG_HANDLE_NAE_0,
+	[478] 	      = XLP_MSG_HANDLE_NAE_0,
+	[479] 	      = XLP_MSG_HANDLE_NAE_0,
+	[480] 	      = XLP_MSG_HANDLE_NAE_0,
+	[481] 	      = XLP_MSG_HANDLE_NAE_0,
+	[482] 	      = XLP_MSG_HANDLE_NAE_0,
+	[483] 	      = XLP_MSG_HANDLE_NAE_0,
+	[484] 	      = XLP_MSG_HANDLE_NAE_0,
+	[485] 	      = XLP_MSG_HANDLE_NAE_0,
+	[486] 	      = XLP_MSG_HANDLE_NAE_0,
+	[487] 	      = XLP_MSG_HANDLE_NAE_0,
+	[488] 	      = XLP_MSG_HANDLE_NAE_0,
+	[489] 	      = XLP_MSG_HANDLE_NAE_0,
+	[490] 	      = XLP_MSG_HANDLE_NAE_0,
+	[491] 	      = XLP_MSG_HANDLE_NAE_0,
+	[492] 	      = XLP_MSG_HANDLE_NAE_0,
+	[493] 	      = XLP_MSG_HANDLE_NAE_0,
+	[494 ... 999] = XLP_MSG_HANDLE_NAE_0,
+	[1000] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1001] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1002] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1003] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1004] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1005] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1006] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1007] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1008] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1009] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1010] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1011] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1012] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1013] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1014] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1015] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1016] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1017] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1018 ... 1019] = XLP_MSG_HANDLE_NAE_0,
+	[1020 ... 4095] = XLP_MSG_HANDLE_INVALID
+};
+
+/******************************************************************************************
+ *  dummy_handler 
+ *
+ *  @vc		cpu vc number
+ *  @src_id	msg sender station vc
+ *  @size	msg_size-1
+ *  @code	software code nae or poe can put in
+ *  @msg0	64 bit msg0 structure 
+ *  @msg1	64 bit msg1 structure 
+ *  @msg2	64 bit msg2 structure 
+ *  @msg3	64 bit msg3 structure 
+ *  @dev_id	driver write can save a device id here
+ *
+ ******************************************************************************************/
+void dummy_handler(uint32_t vc, uint32_t src_id, uint32_t size, uint32_t code, 
+		   uint64_t msg0, uint64_t msg1, uint64_t msg2, uint64_t msg3, void *dev_id)
+{
+	printk("[%s]: No Handler for message from stn_id=%d, bucket=%d, "
+	       "size=%d, msg0=%llx, msg1=%llx dropping message\n",
+	       __FUNCTION__, src_id, vc, size,
+	       (unsigned long long)msg0, (unsigned long long)msg1);
+}
+
+/******************************************************************************************
+ *
+ * intial msg_hander_map with dummy_handler, when real driver msgring handler registered
+ * it will override the entry with hander driver writer provided
+ *
+ ******************************************************************************************/
+struct msgstn_handler msg_handler_map[XLP_MSG_HANDLE_MAX] = {
+	[0 ... (XLP_MSG_HANDLE_MAX-1)] = {dummy_handler, NULL},
+};
+
+/*********************************************************************
+ * nlm_xlp_msgring_int_handler 
+ *
+ *  @irq	msgring irq number
+ *  @regs	linux systems call back function provide struct pt_regs 
+ *  
+ ********************************************************************/
+void nlm_xlp_msgring_int_handler(unsigned int irq, struct pt_regs *regs)
+{
+	unsigned long mflags;
+	int vc = 0;
+	uint32_t size = 0, code = 0, src_id = 0, cycles = 0;
+	struct msgstn_handler *handler = 0;
+	unsigned int status = 0;
+	uint64_t msg0, msg1, msg2, msg3;
+	unsigned int msg_status1 = 0, vc_empty_status = 0;
+	int loop = 0;
+	int cpu = hard_smp_processor_id();
+	int pop_vc_mask = nlm_cpu_vc_mask[cpu];
+
+	msg0 = msg1 = msg2 = msg3 = 0;
+
+        if (irq == IRQ_MSGRING) {
+                /* normal message ring interrupt */
+                /* xlr_inc_counter(MSGRNG_INT);  */
+                nlm_cpu_stat_update_msgring_int();
+        } else {
+                nlm_cpu_stat_update_msgring_pic_int();
+        }
+
+
+//	irq_enter();
+
+        msgrng_access_enable(mflags);
+	cycles = read_c0_count();
+
+	/* Don't loop forever, it may increase interrupt latency */
+	for (loop = 0; loop < 16; loop++) {
+
+		/* Read latest VC empty mask */
+		msg_status1 = xlp_read_status1();
+
+		vc_empty_status = (msg_status1 >> 24) & pop_vc_mask;
+		if (vc_empty_status == pop_vc_mask)
+			break;
+
+		for( vc = 0; vc < 4; vc++)
+		{
+			if(!(pop_vc_mask & (1<<vc)))
+				continue;
+			status = xlp_message_receive( vc, &src_id, &size, &code, &msg0, &msg1, &msg2, &msg3);
+			if(status != 0)
+				continue;
+
+			handler = &msg_handler_map[vc_to_handle_map[src_id]];
+	
+			/* Execute device driver fmn handler */
+			(handler->action)(vc, src_id, size, code,
+					  msg0, msg1, msg2, msg3, handler->dev_id);
+
+		}
+
+		/* Simulator currently doesn't simulate vc_empty_status1 bits! */
+		//if (!hwemul) break;
+	}
+	nlm_cpu_stat_update_msgring_cycles(read_c0_count() - cycles);
+
+	/* Clear VC interrupt status by writing 1s */
+	xlp_write_status1( (msg_status1 | (pop_vc_mask << 16)) );
+
+        msgrng_access_disable(mflags);
+
+//	irq_exit();
+}
+
+EXPORT_SYMBOL(nlm_xlp_msgring_int_handler);
+
+/*******************************************************************************************
+ *  register_xlp_msgring_handler 
+ *
+ *  @major      handler id number, each type handler has an ID
+ *  @action     handler callback function (see dummy_handler above for detail)
+ *  @dev_id	optional dev_id paramter for driver write to save device id
+ *******************************************************************************************/
+int register_xlp_msgring_handler(int major,
+			     void (*action) (uint32_t, uint32_t, uint32_t, uint32_t,
+					     uint64_t, uint64_t, uint64_t, uint64_t, void *),
+			     void *dev_id)
+{
+	int ret = 1;
+	unsigned long flags = 0;
+
+	if (major >= XLP_MSG_HANDLE_MAX || action == NULL) {
+		printk(KERN_ALERT "%s:%d  Invalid parameter: major=%d, "
+		       "XLP_MAX_TX_STN=%d action=%p",
+		       __FUNCTION__, __LINE__, major, XLP_MAX_TX_STNS, action);
+		return ret;
+	}
+
+	/* Check if the message station is valid, if not return error */
+	spin_lock_irqsave(&msgrng_lock, flags);
+
+
+	msg_handler_map[major].action = action;
+	msg_handler_map[major].dev_id = dev_id;
+
+	ret = 0;
+	msgring_registered.value = 1;
+
+	spin_unlock_irqrestore(&msgrng_lock, flags);
+
+	return ret;
+}
+
+EXPORT_SYMBOL(register_xlp_msgring_handler);
+
+#include <asm/netlogic/cpumask.h>
+void nlm_nmi_cpus(unsigned int mask)
+{
+	uint32_t cpumask = cpumask_to_uint32(&cpu_present_map); /* doesn't handle non-n0 nodes */
+	uint32_t cpumask_lo;
+	uint32_t cpumask_hi;
+	const int nmi = 1;
+
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	cpumask = cpumask & mask;
+
+	cpumask_hi = cpumask >> 16;;
+	cpumask_lo = cpumask & 0xffff;
+
+	/* Send IRQ_MSGRING vector in an IPI to all cpus but the current one */
+	if (cpumask_lo)
+		nlm_hal_write_pic_reg(mmio, PIC_IPI_CTL, (nmi << 31) | cpumask_lo );
+
+	if (cpumask_hi)
+		nlm_hal_write_pic_reg(mmio, PIC_IPI_CTL, (nmi << 31) | (1 << 16) | (cpumask_hi));
+}
+
+void on_chip_shutoff_msgring(void)
+{
+	uint32_t flags;
+
+	/* Need write interrupt vector to cp2 msgconfig register */
+	msgrng_access_enable(flags);
+	_write_32bit_cp2_register(XLP_MSG_CONFIG_REG, 0);
+	msgrng_access_disable(flags);
+}
+
+/*********************************************************************
+ * enable_msgconfig_int 
+ *
+ ********************************************************************/
+void enable_msgconfig_int(void)
+{
+	uint32_t flags;
+
+	/* Need write interrupt vector to cp2 msgconfig register */
+	msgrng_access_enable(flags);
+	nlm_hal_set_fmn_interrupt(IRQ_MSGRING);
+	msgrng_access_disable(flags);
+}
+
+
+/*********************************************************************
+ *  pic_init
+ *  
+ ********************************************************************/
+static void pic_init(void)
+{
+	int i = 0;
+	int vcpu;
+	uint32_t thread_mask;
+
+	vcpu = hard_smp_processor_id() & 0x1F;
+
+	thread_mask = (1 << vcpu);
+
+	for (i = 0; i < PIC_NUM_IRTS; i++) {
+		/* Use local scheduling and high polarity for all IRTs
+		 * Invalidate all IRTs, by default
+		 */
+		nlm_hal_pic_write_irt(i, 0, 0, 1, nlm_hal_irt_to_irq(i), 1, 0, thread_mask);
+	}
+
+	/* On XLP, MSGRING config register is per hw-thread */
+	enable_msgconfig_int();
+}
+
+atomic_t nlm_common_counters[NR_CPUS][NLM_MAX_COUNTERS] __cacheline_aligned;
+
+/*********************************************************************
+ *  nlm_usb_init 
+ *
+ ********************************************************************/
+static void nlm_usb_init (void) __attribute__((unused));
+static void nlm_usb_init (void)
+{
+	volatile unsigned int value;
+
+        nlm_reg_t * gpio_mmio = netlogic_io_mmio(NETLOGIC_IO_GPIO_OFFSET);
+        nlm_reg_t * usb_mmio  = netlogic_io_mmio(NETLOGIC_IO_USB_1_OFFSET);
+
+	netlogic_write_reg(usb_mmio, 49, 0x10000000); //Clear Rogue Phy INTs
+	netlogic_write_reg(usb_mmio, 50, 0x1f000000);
+
+        netlogic_write_reg(usb_mmio,  1, 0x07000500);
+
+	value = gpio_mmio[21];
+	if ((value >> 22) & 0x01) {
+		printk("Detected USB Host mode..\n");
+		netlogic_write_reg(usb_mmio,  0, 0x02000000);
+	}
+	else {
+		printk("Detected USB Device mode..\n");
+		netlogic_write_reg(usb_mmio,  0, 0x01000000);
+	}
+}
+
+
+/*********************************************************************
+ * nlm_enable_vc_intr
+ *********************************************************************/
+void nlm_enable_vc_intr(void)
+{
+	int cpu = hard_smp_processor_id();
+	int vc_index = 0;
+	int i = 0;
+
+	for(i=0; i<NLM_MAX_VC_PER_THREAD; i++)
+	{
+		if(nlm_cpu_vc_mask[cpu] & (1<<i)){
+			vc_index = (i + cpu*NLM_MAX_VC_PER_THREAD) & 0x7f;
+			/*disable interrupts*/
+			nlm_hal_enable_vc_intr(vc_index);
+		}
+	}
+}
+
+/*********************************************************************
+ * nlm_disable_vc_intr
+ *********************************************************************/
+void nlm_disable_vc_intr(void)
+{
+	int cpu = hard_smp_processor_id();
+	int vc_index = 0;
+	int i = 0;
+
+	for(i=0; i<NLM_MAX_VC_PER_THREAD; i++)
+	{
+		if(nlm_cpu_vc_mask[cpu] & (1<<i)){
+			vc_index = (i + cpu*NLM_MAX_VC_PER_THREAD) & 0x7f;
+			/*enable interrupts*/
+			nlm_hal_disable_vc_intr(vc_index);
+		}
+	}
+}
+
+/*********************************************************************
+ * on_chip_init
+ *  
+ ********************************************************************/
+void on_chip_init(void)
+{
+	int i = 0, j = 0;
+
+	cpu_logical_map(0)  = hard_smp_processor_id();
+
+	/* Set netlogic_io_base to the run time value */
+	spin_lock_init(&msgrng_lock);
+
+	msgring_registered.value = 0;
+
+	on_chip_shutoff_msgring();
+
+	nlm_hal_init();
+
+	pic_init(); 
+
+	for (i = 0; i < NR_CPUS; i++)
+	for (j = 0; j < NLM_MAX_COUNTERS; j++)
+			atomic_set(&nlm_common_counters[i][j], 0);
+
+	/*enable vc interrupts*/
+	nlm_enable_vc_intr();
+}
diff --git a/arch/mips/netlogic/xlp/platform.c b/arch/mips/netlogic/xlp/platform.c
new file mode 100644
index 0000000..842fee9
--- /dev/null
+++ b/arch/mips/netlogic/xlp/platform.c
@@ -0,0 +1,264 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/dma-mapping.h>
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/platform_device.h>
+#include <linux/serial.h>
+#include <linux/serial_8250.h>
+#include <linux/pci.h>
+#include <linux/serial_reg.h>
+#include <linux/spinlock.h>
+
+#include <asm/time.h>
+#include <asm/netlogic/hal/nlm_hal_macros.h>
+#include <asm/netlogic/hal/nlm_hal_pic.h>
+#include <asm/netlogic/xlp.h>
+#include <asm/netlogic/xlp_usb.h>
+#include <asm/netlogic/iomap.h>
+
+#define XLP_SOC_PCI_DRIVER "XLP SoC Driver"
+#define DEV_IRT_INFO		0x3D
+
+#define XLP_MAX_DEVICE		8
+#define XLP_MAX_FUNC		8
+#define MAX_DEV2DRV		10
+#define MAX_NUM_UARTS		4
+#define UART_CLK 		133333333
+#define XLP_UART_PORTIO_OFFSET	0x1000
+
+static struct plat_serial8250_port xlp_uart_port[MAX_NUM_UARTS];
+
+static u64 xlp_dev_dmamask = DMA_BIT_MASK(32);
+
+enum driverType{
+	PLAT_DRV = 0,
+	PCI_DRV	 = 1
+};
+
+struct dev2drv {
+	uint32_t 	devid;
+	uint8_t 	drvname[16];
+	uint8_t 	len;
+	uint8_t 	id;
+	uint8_t		drivetype;
+};
+
+unsigned int xlp_uart_in(struct uart_port *p, int offset) {
+
+	nlm_reg_t *mmio;
+	unsigned int value;
+
+	/* XLP uart does not need any mapping of regs 
+	 */
+	offset = offset << p->regshift;
+	mmio = (nlm_reg_t *)(p->membase + offset);
+	value = netlogic_read_reg(mmio, 0);
+
+	return value;
+}
+
+void xlp_uart_out(struct uart_port *p, int offset, int value)
+{
+	nlm_reg_t *mmio;
+
+	offset = offset << p->regshift;
+	mmio = (nlm_reg_t *)(p->membase + offset);
+	netlogic_write_reg(mmio, 0, value);
+}
+
+static void xlp_init_uart(int port_id)
+{
+        xlp_uart_port[port_id].mapbase       = DEFAULT_NETLOGIC_IO_BASE 
+						+ NETLOGIC_IO_UART_0_OFFSET + port_id * XLP_UART_PORTIO_OFFSET;
+        xlp_uart_port[port_id].membase       = (void __iomem *)xlp_uart_port[port_id].mapbase;
+        xlp_uart_port[port_id].irq           = PIC_UART_0_IRQ + port_id;
+
+        xlp_uart_port[port_id].uartclk       = UART_CLK;
+        xlp_uart_port[port_id].iotype        = UPIO_NLM;
+        xlp_uart_port[port_id].flags         = UPF_SKIP_TEST|UPF_FIXED_TYPE|UPF_BOOT_AUTOCONF;
+        xlp_uart_port[port_id].type          = PORT_16550A;
+        xlp_uart_port[port_id].regshift      = 2;
+        xlp_uart_port[port_id].serial_in     = xlp_uart_in;
+        xlp_uart_port[port_id].serial_out    = xlp_uart_out;
+}
+
+static void xlp_usb_hw_start(int ctrl_no)
+{
+	int val;
+
+	/* reset USB phy 
+	 */
+	val = usb_reg_read( 0, ctrl_no, XLP_USB_PHY0);
+
+	if(ctrl_no == 0)
+		val &= ~(USBPHYRESET | USBPHYPORTRESET0 | USBPHYPORTRESET1);
+	else if(ctrl_no == 3)
+		val &= ~(USBPHYRESET | USBPHYPORTRESET0 | USBPHYPORTRESET1);
+
+	usb_reg_write(0, ctrl_no, XLP_USB_PHY0, val);
+
+	udelay(2000);
+
+	val = usb_reg_read( 0, ctrl_no, XLP_USB_CTL0);
+	val &= ~(USBCONTROLLERRESET );
+	val |= 0x4;
+	usb_reg_write(0, ctrl_no, XLP_USB_CTL0, val);
+
+	return;
+}
+
+struct dev2drv dev2drv_table[MAX_DEV2DRV] = {
+	{XLP_DEVID_UART, "serial8250",	sizeof("serial8250"),	0,	PLAT_DRV},
+	{XLP_DEVID_I2C,	 "i2c-xlp",	sizeof("i2c-xlp"),	0, 	PLAT_DRV},
+	{XLP_DEVID_NOR,	 "cfi_probe",	sizeof("cfi_probe"),	0, 	PLAT_DRV},
+	{0x0, 			 "",	0,	0,	PLAT_DRV},
+};
+
+static int get_dev2drv(uint32_t x) 
+{
+	int i;
+
+	for(i=0; i<MAX_DEV2DRV; i++) {	
+		if(x == dev2drv_table[i].devid)
+			return i;
+	}
+	return i;
+}
+
+static int xlp_find_pci_dev(void)
+{
+	uint16_t i, j, id, idx = 0;
+	volatile uint64_t mmio;
+	uint32_t val, devid, vid, irt, irq;
+	struct platform_device* pplatdev;
+	struct resource* pres;
+
+	pres = (struct resource*) kmalloc(sizeof(struct resource) * 2, 
+			GFP_KERNEL);
+	if(!pres) {
+		printk("kmalloc struct resource failedi!\n");
+		return -ENOMEM;
+	}
+
+	for (i=0; i<XLP_MAX_DEVICE; i++) {
+
+		for (j=0; j<XLP_MAX_FUNC; j++) {
+
+			mmio = nlm_hal_get_dev_base(0, 0, i, j);
+			val  = nlm_hal_read_32bit_reg(mmio, 0);
+
+			if(val != 0xFFFFFFFF) {
+
+				devid	= (val & 0xFFFF0000) >> 16;
+				vid 	= (val & 0xFFFF);
+				idx 	= get_dev2drv(devid);
+
+				if(idx >= 0 && idx < MAX_DEV2DRV) {
+
+					if(dev2drv_table[idx].drivetype == PLAT_DRV) {
+
+						id = dev2drv_table[idx].id;
+
+						if (devid == XLP_DEVID_EHCI) {
+							if(id == 1)
+								id = 3;
+						}
+
+						if( devid == XLP_DEVID_OHCI) {
+							if(id < 2)
+								id = id + 1;
+							else if (id >=2)
+								id = id + 2;
+						}
+
+						if (devid == XLP_DEVID_UART)
+							id += PLAT8250_DEV_PLATFORM;
+
+						pplatdev =  platform_device_alloc(
+								(const char*)dev2drv_table[idx].drvname, id);
+						if (!pplatdev) {
+							printk("platform_device_alloc  failed!\n");
+							continue;
+						}
+
+						if(devid == XLP_DEVID_UART) {
+							pplatdev->dev.platform_data = &xlp_uart_port[dev2drv_table[idx].id];
+							xlp_init_uart(dev2drv_table[idx].id);
+						}
+
+						dev2drv_table[idx].id = dev2drv_table[idx].id + 1;	
+
+						pres[0].start	= mmio;
+						pres[0].end		= mmio;
+						pres[0].flags	= IORESOURCE_MEM;
+
+						irt = (nlm_hal_read_32bit_reg(mmio, DEV_IRT_INFO) & 0xFFFF);
+					   	if(nlm_hal_is_shared_irt(irt))
+							irq = nlm_hal_request_shared_irq(irt);
+						else
+							irq = nlm_hal_irt_to_irq(irt);
+
+						pres[1].start	= irq;
+						pres[1].end		= irq;
+						pres[1].flags	= IORESOURCE_IRQ;
+
+						platform_device_add_resources(pplatdev, pres, 2);
+
+						pplatdev->dev.dma_mask	= &xlp_dev_dmamask;
+
+						pplatdev->dev.coherent_dma_mask = DMA_BIT_MASK(32);
+
+						platform_device_add( pplatdev);
+					}
+				}
+			}
+		}
+	}
+	kfree(pres);
+	return 0;	
+}
+
+
+
+static int __init platform_devinit(void)
+{
+	xlp_find_pci_dev();
+#ifdef CONFIG_USB
+	xlp_usb_hw_start(0);
+	xlp_usb_hw_start(3);
+#endif
+	return 0;
+}
+
+static void __init platform_devexit(void)
+{
+	return;
+}
+
+module_init(platform_devinit);
+module_exit(platform_devexit);
diff --git a/arch/mips/netlogic/xlp/setup.c b/arch/mips/netlogic/xlp/setup.c
new file mode 100644
index 0000000..4097507
--- /dev/null
+++ b/arch/mips/netlogic/xlp/setup.c
@@ -0,0 +1,685 @@
+/* **********************************************************************
+ * Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+ * reserved.
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ * ****************************#NETL_2#*******************************
+ */
+
+/*
+ * Setup code for Netlogic's XLP-based boards
+ */
+
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/bootmem.h>
+#include <linux/init.h>
+#include <linux/pm.h>
+
+#include <asm/irq.h>
+#include <asm/io.h>
+#include <asm/bootinfo.h>
+#include <asm/addrspace.h>
+#include <asm/reboot.h>
+#include <asm/time.h>
+#include <linux/interrupt.h>
+#include <asm/atomic.h>
+#include <asm/cacheflush.h>
+
+#include <asm/mipsregs.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/iomap.h>
+#include <asm/netlogic/debug.h>
+#include <asm/netlogic/xlp.h>
+#include <asm/netlogic/memory-exclusion.h>
+#include <linux/serial.h>
+#include <linux/serial_core.h>
+#include <linux/module.h>
+#include <linux/proc_fs.h>
+#include <asm/mach-netlogic/mmu.h>
+#include <asm/netlogic/bootinfo.h>
+#include <asm/netlogic/cpumask.h>
+#include <asm/netlogic/hal/nlm_hal_macros.h>
+#include <asm/netlogic/hal/nlm_hal_pic.h>
+
+#include "../boot/ops.h"
+
+/* Certain macros for this file
+ */
+
+#define TRUE 					1
+#define FALSE 					0
+
+#define DEFAULT_LINUX_CPU_MASK			0x1
+#define DEFAULT_LOADER_MASK 			~DEFAULT_LINUX_CPU_MASK
+
+#define PER_CPU_THREAD_SIZE 			(THREAD_SIZE >> 2)
+#define TOTAL_THREAD_SIZE       		(PER_CPU_THREAD_SIZE * (NR_CPUS - 1))
+
+#define BOOT_LOADER_REGION_SZ 			0x04000000
+#define LOADER_KSEG_END 			0x10000000
+
+#define PROCESSOR_ID_MAX_LEN 			6
+
+extern char _end;
+extern void *fdt;
+
+EXPORT_SYMBOL(fdt);
+
+extern void *fdt_init(void *blob);
+extern void *simple_alloc_init(char *base, unsigned long heap_size,
+		unsigned long granularity, unsigned long max_allocs);
+
+extern unsigned int xlp_uart_in(struct uart_port *p, int offset);
+extern void xlp_uart_out(struct uart_port *p, int offset, int value);
+
+extern void (*board_nmi_handler_setup)(void );
+extern cpumask_t fdt_cpumask;
+
+struct proc_dir_entry *nlm_root_proc;
+EXPORT_SYMBOL(nlm_root_proc);
+
+unsigned long nlm_common_ebase = 0x0;
+
+char cpu_model_info[MAX_CPU_REV_LEN] = {'X','L','P'};
+
+unsigned int xlp_uart_portid = 0;
+
+static char prop_buf[MAX_PROP_LEN];
+
+unsigned long long nlm_common_tlb_stats[NR_CPUS] __cacheline_aligned;
+
+/* Struct for temp. allocation
+ * of sp/gp for secondary CPUs
+ */
+struct xlp_stack_pages {
+	unsigned long stack[(TOTAL_THREAD_SIZE)/sizeof(long)];
+};
+struct xlp_stack_pages xlp_stack_pages_temp
+__attribute__((__section__(".data.init_task"),
+	       __aligned__(THREAD_SIZE)));
+
+struct boot_mem_map boot_physaddr_info = {
+	.nr_map = 5,
+	.map = {
+		[0] = {
+			.addr = 0ULL,
+			.size = 0x14000000ULL,
+			.type = BOOT_MEM_RAM
+		},
+		[1] = {
+			.addr = 0x14000000ULL,
+			.size = 0x09000000ULL,
+			.type = BOOT_MEM_RESERVED
+		},
+		[2] = {
+			.addr = 0x1D000000ULL,
+			.size = 0xA3000000ULL,
+			.type = BOOT_MEM_RAM
+		},
+		[3] = {
+			.addr = 0xC0000000ULL,
+			.size = 0x20000000ULL,
+			.type = BOOT_MEM_RESERVED
+		},
+		[4] = {
+			.addr = 0xE0000000ULL,
+			.size = 0x20000000ULL,
+			.type = BOOT_MEM_RAM
+		},
+	}
+};
+
+int nlm_common_get_pgprot(unsigned long address)
+{
+	int i = 0;
+
+	for (i = 0; i < boot_physaddr_info.nr_map; i++) {
+		__u64 start = 0, end = 0;
+		long type = 0;
+
+		start = boot_physaddr_info.map[i].addr;
+		end = start + boot_physaddr_info.map[i].size;
+		type = boot_physaddr_info.map[i].type;
+
+		if (address >= start && address < end) {
+			/* Uncached */
+			if (type == BOOT_MEM_RESERVED) return 1;
+			/* cached */
+			if (type == BOOT_MEM_RAM) return 0;
+		}
+	}
+
+	/* uncached */
+	return 1;
+}
+
+int valid_mmap_nlm_common_addr_range(unsigned long pfn)
+{
+	int i;
+	__u64 end=0;
+
+	for (i = 0; i < boot_physaddr_info.nr_map; i++) {
+		end = boot_physaddr_info.map[i].addr + boot_physaddr_info.map[i].size;
+		end = end >> PAGE_SHIFT;
+		if (pfn <= (unsigned long)end)
+			return 1;
+	}
+	return 0;
+}
+
+const char *get_system_type(void)
+{
+	return "Netlogic XLP SoC";
+}
+
+extern void reset_nae(void);
+extern void on_chip_shutoff_msgring(void);
+
+static void ptr_linux_exit(void)
+{
+	/* trigger a chip reset */
+	 nlm_hal_write_sys_reg(CHIP_RESET, 1);
+
+	 for ( ; ; )
+		  cpu_wait();
+}
+
+void __init bus_error_init(void)
+{
+}
+
+#ifdef CONFIG_NLM_XLP
+void prom_reconfigure_thr_resources(void) {}
+#else
+void prom_reconfigure_thr_resources(void)
+{
+	unsigned int mmu_setup = 0;
+	int i = 0, num_threads = 0, dis_contig = 0;
+	int value = 0;
+	int cpu = 0;
+
+	/* Configure thread resources only if it is thread_0 of that core */
+	if (netlogic_thr_id() != 0) return;
+
+	/* cpu has to be thread@0 */
+	cpu = hard_smp_processor_id();
+
+	for (i = 0; i < 4; i++) {
+
+		if (!cpumask_test_cpu(cpu + i, &fdt_cpumask)) continue;
+
+		if (i != num_threads)	dis_contig = 1;
+
+		num_threads++;
+	}
+
+	switch(num_threads) {
+	case 1: value = 0x00; break;
+	case 2: value = 0x02; break;
+	default:
+		value = 0x03; break;
+	}
+
+	if (dis_contig)	value = 0x3;
+
+	mmu_setup = read_32bit_nlm_ctrl_reg(CPU_BLOCKID_MMU, 0);
+	mmu_setup = mmu_setup & ~0x06;
+	mmu_setup |= (value << 1);
+	write_32bit_nlm_ctrl_reg(CPU_BLOCKID_MMU, 0, mmu_setup);
+}
+#endif
+
+unsigned int __cpuinit get_c0_compare_int(void)
+{
+    return IRQ_TIMER;
+}
+
+/* TODO: Get this from FDT */
+void plat_time_init(void)
+{
+	extern void nlm_common_timer_setup(void);
+	mips_hpt_frequency = (unsigned int) nlm_hal_cpu_freq();
+	printk("mips_hpt_frequency = %u\n", mips_hpt_frequency);
+	nlm_common_timer_setup();
+}
+
+void __init plat_mem_setup(void)
+{
+	extern int panic_timeout;
+
+	panic_timeout 	 = 5;
+	_machine_restart = (void (*)(char *))ptr_linux_exit;
+	_machine_halt    = ptr_linux_exit;
+	pm_power_off 	 = ptr_linux_exit;
+	return;
+}
+
+struct nlm_common_name_value_struct {
+	char *name;
+	uint32_t *val;
+};
+
+static void prom_add_memory(uint64_t start, uint64_t size) __attribute__((unused));
+static void prom_add_memory(uint64_t start, uint64_t size)
+{
+	__u64 pref_backup = 512;
+
+	add_memory_region(
+			start, size - pref_backup, /* CHECK! */
+			BOOT_MEM_RAM);
+	return;
+}
+
+
+/* setup early serial port driver */
+#ifdef CONFIG_SERIAL_8250
+#define UART_CLK 133333333
+
+static void nlm_early_serial_setup(int uart_id)
+{
+	struct uart_port s;
+	extern int __init early_serial_setup(struct uart_port *port);
+
+	memset(&s, 0, sizeof(s));
+	s.flags = ASYNC_BOOT_AUTOCONF | ASYNC_SKIP_TEST;
+	s.iotype = UPIO_NLM;
+	s.regshift = 2; /* registers are 4 bytes wide */
+	/* hardware int 4 - the serial int, is CPU int 6
+	 but poll for now */
+	s.uartclk = UART_CLK;
+	switch(uart_id){
+		default:
+		case 0:
+			s.irq =  PIC_UART_0_IRQ;
+			s.membase = (unsigned char __iomem *)
+			(DEFAULT_NETLOGIC_IO_BASE + NETLOGIC_IO_UART_0_OFFSET);
+			s.mapbase = (DEFAULT_NETLOGIC_IO_BASE +
+					NETLOGIC_IO_UART_0_OFFSET);
+			s.line = 0;
+			break;
+		case 1:
+			s.irq =  PIC_UART_1_IRQ;
+			s.membase = (unsigned char __iomem *)
+			(DEFAULT_NETLOGIC_IO_BASE + NETLOGIC_IO_UART_1_OFFSET);
+			s.mapbase = (DEFAULT_NETLOGIC_IO_BASE +
+					NETLOGIC_IO_UART_1_OFFSET);
+			s.line = 1;
+			break;
+	}
+	s.serial_in	= xlp_uart_in;
+	s.serial_out	= xlp_uart_out;
+	if (early_serial_setup(&s) != 0) {
+		printk(KERN_ERR "Serial setup failed!\n");
+	}
+}
+#else
+static void nlm_early_serial_setup(int uart_id) {}
+#endif /* CONFIG_SERIAL_8250 */
+
+extern struct plat_smp_ops nlm_smp_ops;
+
+#define MAX_CPUMASK_CELLS NLM_MAX_CPU_NODE
+#define fdt32_to_cpu(x) be32_to_cpu(x)
+
+static int fdt_process(void)
+{
+	int  domain=0;
+	char domstr[32] = "";
+	int  i, na, ns, regs[6], entries, cpu_cells;
+	uint32_t node_vc_mask[4] = {0};
+	extern uint32_t nlm_cpu_vc_mask[NLM_MAX_CPU_NODE*NLM_MAX_CPU_PER_NODE];
+	unsigned char buf[30];	
+	int j, id=0, k, tmp;
+	uint32_t onlinemask[MAX_CPUMASK_CELLS];
+
+	/* If booted using FDT and U-Boot, all
+	 * we get is a pointer to an FDT Blob
+	 */
+	void *blob = (void *)fw_arg0;
+	void *node;
+
+	cpumask_clear(&fdt_cpumask);
+
+	if(!blob)
+		return -1;
+	/* Create a region starting from
+	 * (_end + 64K) of size 8MB for
+	 * the FDT structures. The 64K is
+	 * the current page size for XEN
+	 */
+	simple_alloc_init((char *)((unsigned long)(&_end)+0x10000),
+			(8<<20), 32, 128);
+
+	/* Create a local copy of the FDT
+	 */
+	fdt = fdt_init(blob);
+	if(!fdt)
+		return -1;
+	printk("Cached handle for FDT @ %p\n", fdt);
+
+	/* extract cmdline params
+	 */
+	node = finddevice("/chosen");
+	if (node) {
+		if (getprop(node, "bootargs", prop_buf, MAX_PROP_LEN) < 0)
+			return -1;
+		strcat(arcs_cmdline, prop_buf);
+	}
+
+	/* extract memory ranges,
+	 * add to command line
+	 */
+	node = finddevice("/doms/dom@0");
+	if (node) {
+		if (getprop(node, "#address-cells", &na, sizeof(na)) < 0)
+			na = 1;
+		else
+			na = fdt32_to_cpu(na);
+		if (na < 1 || na > 2)
+			printk("Can't cope with #address-cells == %d.\n\r", na);
+
+		if (getprop(node, "#size-cells", &ns, sizeof(ns)) < 0)
+			ns = 1;
+		else
+			ns = fdt32_to_cpu(ns);
+		if (ns < 1 || ns > 2)
+			printk("Can't cope with #size-cells == %d.\n\r", ns);
+
+		if (getprop(node, "#cpumask-cells", &cpu_cells, sizeof(cpu_cells)) < 0)
+			cpu_cells = 1;
+		else
+			cpu_cells = fdt32_to_cpu(cpu_cells);
+
+		if (cpu_cells < 1 || cpu_cells > MAX_CPUMASK_CELLS)
+			printk("Can't cope with #cpumask-cells == %d\n\r", cpu_cells);
+	}
+
+	node = finddevice("/doms/dom@0/memory");
+	if (node) {
+		entries = (getprop(node, "reg", regs, sizeof(regs))) / sizeof(regs[0]);
+		if (!entries || (entries % (na+ns)))
+			printk("Invalid Memory Map Specified!\n");
+
+		for (i=0; i<entries; i+=2) {
+			unsigned long long addr, size;
+
+			addr = fdt32_to_cpu(regs[i]);
+			size = fdt32_to_cpu(regs[i + 1]);
+
+			if (size == 0)
+				continue;
+
+			sprintf(domstr, " mem=%lldm@%lldm ", (size >> 20), (addr >> 20));
+			strcat(arcs_cmdline, domstr);
+			memset((void *)&domstr, '\0', sizeof(domstr));
+		}
+	}
+
+	printk("FDT Cmdline: %s\n", arcs_cmdline);
+
+
+	/* 
+	 * extract CPU online mask for domain 0 (linux)
+	 */
+	for (i = 0; i < MAX_CPUMASK_CELLS; i++)
+		onlinemask[i] = 0;
+
+	sprintf(domstr, "/doms/dom@%d/cpu", domain);
+
+	node = finddevice(domstr);
+	if (node) {
+		uint32_t onlinemask_buf[MAX_CPUMASK_CELLS];
+
+		char buf[CPUMASK_BUF];
+
+		/* Initialize buffers */
+		for (i = 0; i < MAX_CPUMASK_CELLS; i++)
+			onlinemask_buf[i] = 0;
+
+		/* Parse cpumask from FDT and handle endianness */
+		getprop(node, "onlinemask", &onlinemask_buf[0], sizeof(uint32_t) * cpu_cells);
+
+		for (i = 0; i < cpu_cells; i++) {
+			onlinemask_buf[i] = fdt32_to_cpu(onlinemask_buf[i]);
+
+			printk("FDT: cpu_cells: %d onlinemask[%d]: %08x\n",
+			       cpu_cells, i, onlinemask_buf[i]);
+		}
+
+		/* Store cpumask in predefined order */
+		for (i = 0; i < cpu_cells; i++)
+			onlinemask[i] = onlinemask_buf[cpu_cells - 1 - i];
+
+		for (i = 0; i < MAX_CPUMASK_CELLS; i++) {
+			int j = 0;
+
+			for (j = 0; j < 32; j++) {
+				if ((onlinemask[i] & (1 << j)) == 0) 
+					continue;
+				cpumask_set_cpu((i * 32 + j), &fdt_cpumask);
+			}
+		}
+
+		cpumask_scnprintf(buf, CPUMASK_BUF, &fdt_cpumask);
+		printk("fdt_cpumask: %s\n", buf);
+	}
+
+	node = finddevice("/doms/dom@0/fmn");
+	if (node) {
+		for (i = 0; i < NLM_MAX_CPU_NODE; i++) {
+			sprintf(buf, "node_%d_vc_mask",i);
+			memset(&node_vc_mask, 0, sizeof(node_vc_mask));
+			if (getprop(node, buf, &node_vc_mask, sizeof(node_vc_mask)) < 0) {
+				/* If no mask is passed, derive it from cpu online mask */
+				if (onlinemask[i]) {
+					for (j = 0; j < NLM_MAX_CPU_PER_NODE; j++, id++) {
+						if (onlinemask[i] & (1 << j))
+							nlm_cpu_vc_mask[id] = 0xf;
+					}
+				}
+			}
+			else {	/* Get vc mask from the fdt */
+				for (j = 0; j < 4; j++) {
+					tmp = fdt32_to_cpu(node_vc_mask[j]);
+					for (k = 0; k < 8; k++) {
+						nlm_cpu_vc_mask[id++] = (tmp >> (k * 4)) & 0xf;
+					}
+				}
+			}
+		}
+	}
+	else {	/* Derive vc mask from cpu online map */
+		for (i = 0; i < NLM_MAX_CPU_NODE; i++) {
+			if (onlinemask[i]) {
+				for (j = 0; j < NLM_MAX_CPU_PER_NODE; j++, id++) {
+					if (onlinemask[i] & (1 << j))
+						nlm_cpu_vc_mask[id] = 0xf;
+				}
+			}
+		}
+	}
+
+	sprintf(domstr, "/doms/dom@%d/uart", domain);
+	node = finddevice(domstr);
+	if (node) {
+		if (getprop(node, "id", &xlp_uart_portid, sizeof(xlp_uart_portid)) < 0)
+			return -1;
+	}
+
+	return 0;
+}
+
+static int get_xlp_proc_name(void)
+{
+	int processor_id = ((read_c0_prid() & 0xff00) >> 8);
+
+	switch (processor_id) {
+	case CHIP_PROCESSOR_ID_XLP_8XX:
+	case CHIP_PROCESSOR_ID_XLP_832:
+		strcpy(cpu_model_info, "XLP832");
+		break;
+	case CHIP_PROCESSOR_ID_XLP_816:
+		strcpy(cpu_model_info, "XLP816");
+		break;
+	case CHIP_PROCESSOR_ID_XLP_432:
+		strcpy(cpu_model_info, "XLP432");
+		break;
+	case CHIP_PROCESSOR_ID_XLP_416:
+		strcpy(cpu_model_info, "XLP416");
+		break;
+	case CHIP_PROCESSOR_ID_XLP_408:
+		strcpy(cpu_model_info, "XLP408");
+		break;
+	case CHIP_PROCESSOR_ID_XLP_316:
+		strcpy(cpu_model_info, "XLP316");
+		break;
+	case CHIP_PROCESSOR_ID_XLP_308:
+		strcpy(cpu_model_info, "XLP308");
+		break;
+	case CHIP_PROCESSOR_ID_XLP_304:
+		strcpy(cpu_model_info, "XLP304");
+		break;
+	case CHIP_PROCESSOR_ID_XLP_208:
+		strcpy(cpu_model_info, "XLP208");
+		break;
+	case CHIP_PROCESSOR_ID_XLP_204:
+		strcpy(cpu_model_info, "XLP204");
+		break;
+	case CHIP_PROCESSOR_ID_XLP_104:
+		strcpy(cpu_model_info, "XLP104");
+		break;
+	default:
+		strcpy(cpu_model_info, "XLP???");
+		return -1;
+	}
+
+	return 0;
+}
+
+static int get_xlp_revision(void)
+{
+	int revision = read_c0_prid() & 0xff;
+
+	switch (revision) {
+	case XLP_REVISION_A0:
+		strcpy(cpu_model_info + PROCESSOR_ID_MAX_LEN, " Rev A0");
+		break;
+	case XLP_REVISION_A1:
+		strcpy(cpu_model_info + PROCESSOR_ID_MAX_LEN, " Rev A1");
+		break;
+	case XLP_REVISION_A2:
+		strcpy(cpu_model_info + PROCESSOR_ID_MAX_LEN, " Rev A2");
+		break;
+	default:
+		strcpy(cpu_model_info + PROCESSOR_ID_MAX_LEN, " Rev ??");
+		return -1;
+	}
+
+	return 0;
+}
+
+char* get_cpu_info(void)
+{
+	get_xlp_proc_name();
+	get_xlp_revision();
+
+	return cpu_model_info;
+}
+
+static void xen_init(void) {}
+
+void __init prom_init(void)
+{
+	setup_mapped_kernel_tlbs(TRUE, TRUE);
+
+	fdt_process();
+
+	xen_init();
+
+	nlm_common_ebase = read_c0_ebase() & (~((1 << 12) - 1));
+
+	cpumask_clear(&smp_boot.online_map);
+	cpumask_set_cpu(hard_smp_processor_id(), &smp_boot.online_map);
+
+	on_chip_init();
+
+	prom_reconfigure_thr_resources();
+
+	/* setup early serial port driver */
+	nlm_early_serial_setup(xlp_uart_portid);
+
+	register_smp_ops(&nlm_smp_ops);
+
+	wakeup_secondary_cpus();
+}
+
+void prom_free_prom_memory(void)
+{
+	/* nothing to free */
+}
+
+#define KSEG0 0xffffffff80000000
+#define RING_BUFFER_BASE (511 << 20)
+#define RING_BUFFER_SIZE (8 << 10)
+static void outbyte_ring_buffer(char c)
+{
+	unsigned long base = RING_BUFFER_BASE + (hard_smp_processor_id() * RING_BUFFER_SIZE);
+	char *buf = (char *)KSEG0 + base;
+	static int idx = 0;
+
+	buf[idx] = c;
+	idx = (idx + 1) % (RING_BUFFER_SIZE);
+}
+
+void nlm_early_printk(const char *fmt, ...)
+{
+	char buf[256];
+	va_list args;
+	int r;
+	char *str = buf;
+
+	va_start(args, fmt);
+	r = vsnprintf(buf, 256, fmt, args);
+	va_end(args);
+
+	while (*str) {
+		outbyte_ring_buffer(*str);
+		str++;
+	}
+}
+
+#ifdef CONFIG_EARLY_PRINTK
+void prom_putchar(char c)
+{
+	xlp_prom_putchar(c);
+}
+#endif
+
+static int __init nlm_proc_setup(void)
+{
+	nlm_root_proc = proc_mkdir("netlogic", 0);
+	if (!nlm_root_proc)
+		return -ENOMEM;
+
+	return 0;
+}
+rootfs_initcall(nlm_proc_setup);
diff --git a/arch/mips/netlogic/xlp/smp.c b/arch/mips/netlogic/xlp/smp.c
new file mode 100644
index 0000000..2092a6e
--- /dev/null
+++ b/arch/mips/netlogic/xlp/smp.c
@@ -0,0 +1,283 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems ( "Netlogic" ). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+#include <linux/cpu.h>
+
+#include <asm/mipsregs.h>
+#include <asm/mmu_context.h>
+#include <asm/atomic.h>
+
+#include <asm/netlogic/xlp.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/interrupt.h>
+#include <asm/netlogic/hal/nlm_hal_pic.h>
+
+#include <asm/asm.h>
+#include <asm/mipsregs.h>
+#include <asm/processor.h>
+
+#include <asm/netlogic/cpumask.h>
+
+#include <asm/mach-netlogic/mmu.h>
+
+#include "cpu_control_macros.h"
+
+struct smp_boot_info smp_boot;
+cpumask_t fdt_cpumask;
+
+void nlm_enable_vc_intr(void);
+extern void ptr_smp_boot(unsigned long, unsigned long, unsigned long);
+extern void prom_reconfigure_thr_resources(void);
+extern unsigned long nlm_common_ebase;
+extern void enable_cpus(unsigned int node, unsigned online_mask);
+extern void nlm_smp_irq_init(void);
+extern void asmlinkage smp_bootstrap(void);
+extern void enable_msgconfig_int(void);
+
+void nlm_send_ipi_single(int cpu, unsigned int action)
+{
+        __u32 node = cpu / 32;
+        __u32 ipi = 0;
+	__u8 nmi = 0;
+	cpu = cpu % 32;
+
+        if (action & SMP_CALL_FUNCTION) {
+                ipi |= IRQ_IPI_SMP_FUNCTION;
+	} else if (action & SMP_RESCHEDULE_YOURSELF) {
+                ipi |= IRQ_IPI_SMP_RESCHEDULE;
+	} else if (action & SMP_CALL_KGDB_HOOK) {
+                ipi |= IRQ_IPI_SMP_KGDB;
+		/* for KGDB enable NMI also */
+		nmi = 1;
+	} else if (action & SMP_OPROFILE_IPI) {
+                ipi |= IRQ_IPI_OPROFILE;
+        } else
+		return;
+
+	smp_mb();
+
+        nlm_hal_pic_send_ipi(nmi, (ipi & 0x3f), node, cpu);
+}
+
+void nlm_send_ipi_mask(const struct cpumask * mask, unsigned int action)
+{
+	int cpu;
+
+	for_each_cpu(cpu, mask){
+		nlm_send_ipi_single(cpu, action);
+	}
+}
+
+extern void nlm_common_timer_setup(void);
+/*
+ * Code to run on secondary just after probing the CPU
+ */
+static void __cpuinit nlm_init_secondary(void)
+{
+    /* Time init for this cpu is done in mips_clockevent_init() */
+    nlm_smp_irq_init();
+
+    enable_msgconfig_int();
+
+    /* Workaround for XLP A0 Multi-Node bug */
+    {
+	    int cpu = hard_smp_processor_id();
+
+	    if ( (cpu % 32) == 0) {
+		    /* If this cpu@0 of any of the nodes, initialize PIC */
+		    nlm_common_timer_setup();
+	    }
+    }
+
+    /* Enable vc interupts for this thread*/
+    nlm_enable_vc_intr();
+}
+
+void nlm_smp_finish(void)
+{
+}
+
+void nlm_cpus_done(void)
+{
+}
+
+/* Boot all other cpus in the system, initialize them, and
+   bring them into the boot fn */
+void nlm_boot_secondary(int cpu, struct task_struct *idle)
+{
+	unsigned long gp = (unsigned long)task_thread_info(idle);
+	unsigned long sp = (unsigned long)__KSTK_TOS(idle);
+
+
+	smp_boot.boot_info[cpu].sp = sp;
+	smp_boot.boot_info[cpu].gp = gp;
+	smp_boot.boot_info[cpu].fn = (unsigned long)&smp_bootstrap;
+
+	/* barrier */
+	__sync();
+	smp_boot.boot_info[cpu].ready = 1;
+
+/*  	printk("[%s]: (PROM): sent a wakeup message to cpu %d\n", __FUNCTION__, cpu);  */
+}
+
+void __init nlm_smp_setup(void)
+{
+	int num_cpus = 0;
+	int boot_cpu = hard_smp_processor_id();
+	int i = 0;
+	char buf[CPUMASK_BUF];
+
+	/* Initialize maps */
+	for (i = 0; i < NR_CPUS; i++) {
+		__cpu_number_map[i] = 0;
+		__cpu_logical_map[i] = boot_cpu;
+	}
+
+	/* Setup map for master cpu */
+	__cpu_number_map[boot_cpu] = 0;
+	__cpu_logical_map[0] = boot_cpu;
+	num_cpus = 1;
+
+	/* Setup map for other cpus */
+	for (i = 0; i < NR_CPUS; i++) {
+
+		if (i == boot_cpu) continue;
+
+		if (cpumask_test_cpu(i, &fdt_cpumask)) {
+
+			__cpu_number_map[i] = num_cpus;
+			__cpu_logical_map[num_cpus] = i;
+
+			num_cpus++;
+		}
+	}
+
+	cpu_present_map = cpu_possible_map = fdt_cpumask;
+
+	cpumask_scnprintf(buf, CPUMASK_BUF, &cpu_possible_map);
+	printk("Possible/Present/FDT CPU map %s\n", buf);
+
+	printk("Detected %d Slave CPU(s)\n", num_cpus);
+}
+
+#define hw_enable_cpus enable_cpus
+
+/* Config MMU */
+static inline void config_mmu(void)
+{
+	uint32_t tmp0;
+
+	/*
+	 * Dummy write for A0 bug in MMU
+	 */
+	__asm__ __volatile__ (
+		".set push\n"
+		".set noreorder\n"
+		"li      %0, "STR(MMU_SETUP)"\n"
+		"mtcr    $0, %0\n"
+		"ehb\n"
+		".set pop\n"
+		: "=r" (tmp0)
+	);
+}
+
+int wakeup_secondary_cpus(void)
+{
+	cpumask_t mask32;
+	int node;
+
+	cpumask_clear(&mask32);
+	uint32_to_cpumask(&mask32, 0xffffffff);
+
+	for (node = 0; node < NLM_MAX_CPU_NODE; node++) {
+		cpumask_t tmpmask, nodemask;
+		unsigned int onlinemask;
+
+		cpumask_clear(&tmpmask);
+		cpumask_clear(&nodemask);
+
+		cpumask_shift_right(&nodemask, &fdt_cpumask, 32 * node);
+		cpumask_and(&tmpmask, &nodemask, &mask32);
+
+		if (cpumask_empty(&tmpmask))
+			continue;
+
+		onlinemask = cpumask_to_uint32(&tmpmask);
+		hw_enable_cpus(node, onlinemask);
+
+		printk("Enabled cpus (0x%08x) on node@%d\n", onlinemask, node);
+	}
+
+	/* only n0c0t0 initializes MMU */
+	config_mmu();
+
+	return 0;
+}
+
+void nlm_prepare_cpus(unsigned int max_cpus)
+{
+}
+
+struct plat_smp_ops nlm_smp_ops = {
+    .send_ipi_single    = nlm_send_ipi_single,
+    .send_ipi_mask      = nlm_send_ipi_mask,
+    .init_secondary     = nlm_init_secondary,
+    .smp_finish     	= nlm_smp_finish,
+    .cpus_done      	= nlm_cpus_done,
+    .boot_secondary     = nlm_boot_secondary,
+    .smp_setup      	= nlm_smp_setup,
+    .prepare_cpus       = nlm_prepare_cpus,
+};
+
+void prom_boot_cpus_secondary(void *args)
+{
+	int cpu = hard_smp_processor_id();
+
+	write_c0_ebase((uint32_t)nlm_common_ebase);
+
+	/* Announce that this cpu is available */
+	cpumask_test_and_set_cpu(cpu, &smp_boot.online_map);
+
+	/* Wait for master to signal */
+	for (;;) {
+		if (smp_boot.boot_info[cpu].ready) break;
+	}
+	__sync();
+
+	prom_reconfigure_thr_resources();
+
+	if (netlogic_thr_id() == 0) config_mmu();
+
+        setup_mapped_kernel_tlbs(TRUE, FALSE);
+        setup_mapped_kernel_tlbs(FALSE, FALSE);
+
+	/* Entry into the kernel (smp_bootstrap) */
+	ptr_smp_boot(smp_boot.boot_info[cpu].fn, smp_boot.boot_info[cpu].sp,
+		     smp_boot.boot_info[cpu].gp);
+}
diff --git a/arch/mips/netlogic/xlp/time.c b/arch/mips/netlogic/xlp/time.c
new file mode 100644
index 0000000..9ed9a20
--- /dev/null
+++ b/arch/mips/netlogic/xlp/time.c
@@ -0,0 +1,130 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are peNLMtted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/interrupt.h>
+#include <linux/sched.h>
+#include <linux/spinlock.h>
+
+#include <asm/irq.h>
+#include <asm/ptrace.h>
+#include <asm/addrspace.h>
+#include <asm/time.h>
+#include <asm/cpu.h>
+#include <asm/cpu-features.h>
+#include <linux/oprofile.h>
+
+#include <linux/proc_fs.h>
+#include <asm/netlogic/hal/nlm_hal_pic.h>
+#include <asm/netlogic/mips-exts.h>
+
+extern spinlock_t nlm_common_pic_lock;
+
+/* PIC clock at 66Mhz takes more than 60 secs to come to 0 from max. So 32bit 
+   counter is sufficient
+   */
+#define PIC_FREE_RUNNING_TIMER_MAX_VAL 0xffffffff
+cycle_t xlr_hpt_read(void)
+{
+	uint32_t counter;
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+	counter = (uint32_t) nlm_hal_read_pic_reg(mmio, PIC_TIMER_6_COUNTER);
+	return (cycle_t)(PIC_FREE_RUNNING_TIMER_MAX_VAL - counter);
+}
+
+EXPORT_SYMBOL(xlr_hpt_read);
+
+int read_current_timer(unsigned long *timer_val)
+{
+	*timer_val = xlr_hpt_read();
+	return 0;
+}
+
+void nlm_common_timer_setup(void)
+{
+        pic_reg_t *mmio = nlm_hal_pic_offset();
+        unsigned long flags = 0;
+
+        spin_lock_irqsave(&nlm_common_pic_lock, flags);
+
+        /* Use PIC Timer 6 as a free running counter */
+        nlm_hal_write_pic_reg(mmio, PIC_TIMER_6_MAXVAL, 0xffffffffffffffffULL);
+
+	/* enable the timer */
+        nlm_hal_pic_update_control(1 << (10 + 6));
+
+        spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+
+}
+
+static int nlm_timer_proc_read(char *page, char **start, off_t off, int count,
+			       int *eof, void *data)
+{
+	int len = 0;
+
+	preempt_disable();
+	len += sprintf(page + len, "cpu = %d, eimr = 0x%016llx, status = 0x%x\n", 
+				   /*smp_processor_id(), */
+				   hard_smp_processor_id(), 
+                   (unsigned long long)read_64bit_cp0_eimr(), read_c0_status());
+	preempt_enable();
+	*eof = 1;
+
+	return len;
+}
+
+extern struct proc_dir_entry *nlm_root_proc;
+struct proc_dir_entry *main_entry;
+struct proc_dir_entry *sub_entry;
+
+static int init_pic_timer_procfs(void)
+{
+	main_entry = proc_mkdir("nlm_timer", nlm_root_proc);
+	if (!main_entry) {
+		printk(KERN_ERR "unable to create /proc/nlm_timer\n");
+		return -ENOMEM;
+	}
+
+	sub_entry = create_proc_entry("debug", 0644, main_entry);
+
+	if (!sub_entry) {
+		remove_proc_entry("nlm_timer", nlm_root_proc);
+		return -ENOMEM;
+	}
+
+	sub_entry->read_proc = nlm_timer_proc_read;
+
+	printk("created nlm_timer proc fs entry\n");
+
+	return 0;
+}
+
+static void exit_pic_timer_procfs(void)
+{
+	remove_proc_entry("debug", main_entry);
+	remove_proc_entry("nlm_timer", nlm_root_proc);
+}
+
+module_init(init_pic_timer_procfs);
+module_exit(exit_pic_timer_procfs);
-- 
1.7.0.2

