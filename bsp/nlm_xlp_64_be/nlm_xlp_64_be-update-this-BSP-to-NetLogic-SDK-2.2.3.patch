From 959f8f83fb8cc02e97027ddd4a71cfb713541315 Mon Sep 17 00:00:00 2001
From: Yanjiang Jin <yanjiang.jin@windriver.com>
Date: Tue, 27 Mar 2012 15:33:01 +0800
Subject: [PATCH 01/46] nlm_xlp_64_be: update this BSP to NetLogic SDK 2.2.3

Support NetLogic's XLP316 A0, XLP432 and XLP832 A2 and B0,
based on NetLogic SDK 20120215_2.2.3 tag.

Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/Kconfig                                  |   51 +-
 arch/mips/Makefile                                 |    7 +-
 arch/mips/boot/compressed/Makefile                 |    2 +-
 arch/mips/boot/dts/ucore-3xx.dts                   |   61 +
 arch/mips/boot/dts/ucore-8xx.dts                   |   61 +
 arch/mips/boot/dts/xlp316.dts                      |  823 +++
 arch/mips/boot/dts/xlp832.dts                      | 1486 +++---
 arch/mips/include/asm/mach-netlogic/mmzone.h       |   80 +
 arch/mips/include/asm/mach-netlogic/topology.h     |   44 +
 arch/mips/include/asm/netlogic/config_net.h        |  108 +
 arch/mips/include/asm/netlogic/hal/nlm_evp_cpld.h  |   39 +
 arch/mips/include/asm/netlogic/hal/nlm_hal.h       |   79 +-
 arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h   |  297 ++-
 .../mips/include/asm/netlogic/hal/nlm_hal_macros.h |  516 ++-
 arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h   |  482 ++-
 arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h   |  379 --
 arch/mips/include/asm/netlogic/hal/nlm_hal_sys.h   |   64 +
 .../include/asm/netlogic/hal/nlm_hal_xlp_dev.h     |  480 ++-
 arch/mips/include/asm/netlogic/hal/nlm_nae.h       |  126 +
 arch/mips/include/asm/netlogic/interrupt.h         |   20 +-
 arch/mips/include/asm/netlogic/mips-exts.h         |    5 +
 arch/mips/include/asm/netlogic/msgring.h           |  713 +++
 arch/mips/include/asm/netlogic/msidef.h            |   73 +
 arch/mips/include/asm/netlogic/pic.h               |   15 +-
 arch/mips/include/asm/netlogic/sim.h               |  449 ++
 arch/mips/include/asm/netlogic/xgmac_mdio.h        |  114 +
 arch/mips/include/asm/netlogic/xlp.h               |   23 +-
 arch/mips/include/asm/netlogic/xlp8xx/cpu.h        |  157 +
 arch/mips/include/asm/netlogic/xlp8xx/xlp_sys.h    |  206 +
 arch/mips/include/asm/netlogic/xlp_hal_pic.h       |  290 ++
 arch/mips/include/asm/netlogic/xlp_irq.h           |  281 ++
 arch/mips/include/asm/netlogic/xlp_mac.h           |  128 +-
 arch/mips/include/asm/ptrace.h                     |   10 +
 arch/mips/kernel/asm-offsets.c                     |    9 +
 arch/mips/kernel/cpu-probe.c                       |    7 +-
 arch/mips/kernel/nlm_fs_handler.S                  |   28 +-
 arch/mips/netlogic/boot/.gitignore                 |    9 -
 arch/mips/netlogic/boot/Makefile                   |   37 +-
 arch/mips/netlogic/boot/fdt.c                      |  202 +
 arch/mips/netlogic/boot/fdt.h                      |   60 +
 arch/mips/netlogic/boot/fdt_ro.c                   |  469 ++
 arch/mips/netlogic/boot/fdt_rw.c                   |  474 ++
 arch/mips/netlogic/boot/fdt_strerror.c             |   96 +
 arch/mips/netlogic/boot/fdt_sw.c                   |  257 +
 arch/mips/netlogic/boot/fdt_wip.c                  |  145 +
 arch/mips/netlogic/boot/libfdt-wrapper.c           |   28 +-
 arch/mips/netlogic/boot/libfdt.h                   | 1076 ++++
 arch/mips/netlogic/boot/libfdt_internal.h          |   95 +
 arch/mips/netlogic/common/Makefile                 |    7 +
 arch/mips/netlogic/common/nlm_evp_cpld.c           |  193 +
 arch/mips/netlogic/common/nlm_hal.c                | 2601 ++++------
 arch/mips/netlogic/common/nlm_hal_cpu_info.c       |  516 ++
 arch/mips/netlogic/common/nlm_hal_fmn_config.c     |  780 +++-
 arch/mips/netlogic/common/nlm_hal_nae.c            | 5253 +++++++++++++++++---
 arch/mips/netlogic/common/nlm_hal_sys.c            |  573 +++
 arch/mips/netlogic/xlp/Makefile                    |    1 +
 arch/mips/netlogic/xlp/board.c                     |  128 +-
 arch/mips/netlogic/xlp/cpu_control.c               |  174 +-
 arch/mips/netlogic/xlp/cpu_control_asm.S           |  145 +-
 arch/mips/netlogic/xlp/cpu_control_macros.h        |  163 +-
 arch/mips/netlogic/xlp/irq.c                       | 1720 ++++++-
 arch/mips/netlogic/xlp/on_chip.c                   |  702 +++-
 arch/mips/netlogic/xlp/platform.c                  |   87 +-
 arch/mips/netlogic/xlp/setup.c                     |  472 ++-
 arch/mips/netlogic/xlp/smp.c                       |  214 +-
 arch/mips/netlogic/xlp/time.c                      |   63 +-
 arch/mips/netlogic/xlp/xlp_hal_pic.c               |  137 +
 arch/mips/pci/pci-xlp.c                            |  886 +++-
 drivers/net/nae/init_nae.c                         |   22 +-
 drivers/net/nae/net_common.h                       |  198 +-
 drivers/net/nae/xlp_hw.c                           |  316 +-
 drivers/net/nae/xlp_nae.c                          |  368 ++-
 drivers/net/nae/xlp_nae.h                          |  115 +-
 drivers/usb/host/ehci-pci.c                        |    6 +-
 drivers/usb/host/ohci-pci.c                        |    5 +-
 75 files changed, 21410 insertions(+), 5096 deletions(-)
 create mode 100644 arch/mips/boot/dts/ucore-3xx.dts
 create mode 100644 arch/mips/boot/dts/ucore-8xx.dts
 create mode 100644 arch/mips/boot/dts/xlp316.dts
 create mode 100644 arch/mips/include/asm/mach-netlogic/mmzone.h
 create mode 100644 arch/mips/include/asm/mach-netlogic/topology.h
 create mode 100644 arch/mips/include/asm/netlogic/config_net.h
 create mode 100644 arch/mips/include/asm/netlogic/hal/nlm_evp_cpld.h
 delete mode 100644 arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h
 create mode 100644 arch/mips/include/asm/netlogic/hal/nlm_hal_sys.h
 create mode 100644 arch/mips/include/asm/netlogic/hal/nlm_nae.h
 create mode 100644 arch/mips/include/asm/netlogic/msgring.h
 create mode 100644 arch/mips/include/asm/netlogic/msidef.h
 create mode 100644 arch/mips/include/asm/netlogic/sim.h
 create mode 100644 arch/mips/include/asm/netlogic/xgmac_mdio.h
 create mode 100644 arch/mips/include/asm/netlogic/xlp8xx/cpu.h
 create mode 100644 arch/mips/include/asm/netlogic/xlp8xx/xlp_sys.h
 create mode 100644 arch/mips/include/asm/netlogic/xlp_hal_pic.h
 create mode 100644 arch/mips/include/asm/netlogic/xlp_irq.h
 delete mode 100644 arch/mips/netlogic/boot/.gitignore
 create mode 100644 arch/mips/netlogic/boot/fdt.c
 create mode 100644 arch/mips/netlogic/boot/fdt.h
 create mode 100644 arch/mips/netlogic/boot/fdt_ro.c
 create mode 100644 arch/mips/netlogic/boot/fdt_rw.c
 create mode 100644 arch/mips/netlogic/boot/fdt_strerror.c
 create mode 100644 arch/mips/netlogic/boot/fdt_sw.c
 create mode 100644 arch/mips/netlogic/boot/fdt_wip.c
 create mode 100644 arch/mips/netlogic/boot/libfdt.h
 create mode 100644 arch/mips/netlogic/boot/libfdt_internal.h
 create mode 100644 arch/mips/netlogic/common/nlm_evp_cpld.c
 create mode 100644 arch/mips/netlogic/common/nlm_hal_cpu_info.c
 create mode 100644 arch/mips/netlogic/common/nlm_hal_sys.c
 create mode 100644 arch/mips/netlogic/xlp/xlp_hal_pic.c

diff --git a/arch/mips/Kconfig b/arch/mips/Kconfig
index eb51191..1900108 100644
--- a/arch/mips/Kconfig
+++ b/arch/mips/Kconfig
@@ -687,6 +687,38 @@ config NLM_XLP_SIM
 	  This board is based on Netlogic XLP Processor.
 	  Say Y here to support this machine type
 
+config NLM_XLP_EVP_BOARD
+        bool "Support for Netlogic XLP EVP board"
+        depends on EXPERIMENTAL
+        select SMP
+        select BOOT_ELF32
+        select NLM_COMMON
+        select NLM_XLP
+        select SYS_HAS_CPU_XLP
+        select SYS_SUPPORTS_SMP
+        select HW_HAS_PCI
+	select ARCH_SUPPORTS_MSI
+        select SWAP_IO_SPACE
+        select SYS_SUPPORTS_32BIT_KERNEL
+        select SYS_SUPPORTS_64BIT_KERNEL
+        select 64BIT_PHYS_ADDR
+        select SYS_SUPPORTS_BIG_ENDIAN
+        select SYS_SUPPORTS_LITTLE_ENDIAN
+        select SYS_SUPPORTS_HIGHMEM
+	select SYS_SUPPORTS_HOTPLUG_CPU
+	select SYS_SUPPORTS_ZBOOT
+        select DMA_COHERENT
+        select CEVT_R4K
+        select CSRC_R4K
+        select IRQ_CPU
+        select ZONE_DMA if 64BIT
+        select SYNC_R4K
+        select SYS_HAS_EARLY_PRINTK
+	select SYS_SUPPORTS_NUMA
+        help
+          This board is based on Netlogic XLP Processor.
+          Say Y here to support this machine type
+
 config CAVIUM_OCTEON_REFERENCE_BOARD
 	bool "Cavium Networks Octeon reference board"
 	select CEVT_R4K
@@ -1941,6 +1973,13 @@ config NODES_SHIFT
 	default "6"
 	depends on NEED_MULTIPLE_NODES
 
+config FORCE_MAX_ZONEORDER
+	int "Maximum zone order"
+	range 11 64 if !64BIT
+	default "11" if !64BIT
+	range 13 64 if 64BIT
+	default "13" if 64BIT
+
 config HW_PERF_EVENTS
 	bool "Enable hardware performance counter support for perf events"
 	depends on PERF_EVENTS && !MIPS_MT_SMTC && OPROFILE=n && CPU_MIPS32
@@ -2133,6 +2172,7 @@ config KEXEC
 config CRASH_DUMP
     bool "kernel crash dumps (EXPERIMENTAL)"
     depends on EXPERIMENTAL
+    select PROC_VMCORE
     help
       Generate crash dump after being started by kexec.
           This should be normally only set in special crash dump kernels
@@ -2207,6 +2247,7 @@ config PCI
 config PCI_DOMAINS
 	bool
 
+source "drivers/pci/pcie/Kconfig"
 source "drivers/pci/Kconfig"
 
 #
@@ -2320,7 +2361,6 @@ config BINFMT_ELF32
 endmenu
 
 menu "Power management options"
-
 config ARCH_HIBERNATION_POSSIBLE
 	def_bool y
 	depends on SYS_SUPPORTS_HOTPLUG_CPU || !SMP
@@ -2339,9 +2379,14 @@ config ARCH_PM_SNAPSHOT_POSSIBLE
 
 source "kernel/power/Kconfig"
 
-endmenu
+config XLP_CPUFREQ
+	bool "XLP Cpu frequency scaling support"
+	depends on NLM_XLP
+	help
+		Enable Cpu frequency scaling on Netlogic XLP series of processors.
+	source "drivers/cpufreq/Kconfig"
 
-source "arch/mips/kernel/cpufreq/Kconfig"
+endmenu
 
 source "net/Kconfig"
 
diff --git a/arch/mips/Makefile b/arch/mips/Makefile
index c6592ac..ca5afad 100644
--- a/arch/mips/Makefile
+++ b/arch/mips/Makefile
@@ -657,13 +657,18 @@ cflags-$(CONFIG_NLM_COMMON)	+= -I$(objtree)/arch/mips/netlogic/boot
 cflags-$(CONFIG_NLM_COMMON)	+= -I$(srctree)/arch/mips/netlogic/boot
 cflags-$(CONFIG_NLM_COMMON)	+= -I$(srctree)/arch/mips/include/asm/netlogic
 
+# This address is now configured via kernel configuration file
+load-$(CONFIG_NLM_PTR)          	+= $(CONFIG_NLM_COMMON_LOAD_ADDRESS)
+
 #
 # NETLOGIC XLP Soc, Simulator and boards
 #
 core-$(CONFIG_NLM_XLP)		+= arch/mips/netlogic/xlp/
-cflags-$(CONFIG_NLM_XLP)	+= -I$(srctree)/arch/mips/include/asm/netlogic/hal
+cflags-$(CONFIG_NLM_XLP)	+= -I$(srctree)/arch/mips/include/asm/netlogic/hal -DNLM_HAL_LINUX_KERNEL
+cflags-$(CONFIG_NLM_XLP_SIM)        	+= -DXLP_SIM=1
 # This address is now configured via kernel configuration file
 load-$(CONFIG_NLM_XLP_SIM)	+= $(CONFIG_NLM_COMMON_LOAD_ADDRESS)
+load-$(CONFIG_NLM_XLP_EVP_BOARD) += $(CONFIG_NLM_COMMON_LOAD_ADDRESS)
 
 #
 # Cavium Octeon
diff --git a/arch/mips/boot/compressed/Makefile b/arch/mips/boot/compressed/Makefile
index 34328f9..fce92a8 100644
--- a/arch/mips/boot/compressed/Makefile
+++ b/arch/mips/boot/compressed/Makefile
@@ -48,7 +48,7 @@ endif
 obj-y := $(obj)/head.o $(obj)/decompress.o $(obj)/dbg.o
 
 ifdef CONFIG_DEBUG_ZBOOT
-obj-$(CONFIG_NLM_XLP_SIM)		   += $(obj)/uart-xlp.o
+obj-$(CONFIG_NLM_XLP)			+= $(obj)/uart-xlp.o
 obj-$(CONFIG_SYS_SUPPORTS_ZBOOT_UART16550) += $(obj)/uart-16550.o
 obj-$(CONFIG_MACH_ALCHEMY)		   += $(obj)/uart-alchemy.o
 endif
diff --git a/arch/mips/boot/dts/ucore-3xx.dts b/arch/mips/boot/dts/ucore-3xx.dts
new file mode 100644
index 0000000..0742d79
--- /dev/null
+++ b/arch/mips/boot/dts/ucore-3xx.dts
@@ -0,0 +1,61 @@
+			ucore {
+				src@1 {
+num-opcodes = <50>;
+					path = "/home/wrsadmin/build/43/mips32_xlp/build/linux/arch/mips/boot/dts/storm-linux-default.c";
+					timestamp = "Fri Dec  2 01:56:24 2011
+";
+					mask = <0xff>;
+					opcodes = <
+						0x3c1c0010 
+						0x279cf808 
+						0x3c020010 
+						0x2442f808 
+						0x3c030010 
+						0x2463f808 
+						0xac400000 
+						0x0043082b 
+						0x1420fffd 
+						0x24420004 
+						0x3c1d0010 
+						0x27bdf9c0 
+						0x27a50020 
+						0x27a60028 
+						0xaca00000 
+						0xacc00000 
+						0x0c000029 
+						0x00002021 
+						0x1000ffff 
+						0x00000000 
+						0x3c020000 
+						0x8c4200fc 
+						0x27bdffe0 
+						0x2403ffff 
+						0xafbf001c 
+						0xafb10018 
+						0x10430009 
+						0xafb00014 
+						0x3c100000 
+						0x261000fc 
+						0x2411ffff 
+						0x0040f809 
+						0x2610fffc 
+						0x8e020000 
+						0x1451fffc 
+						0x00000000 
+						0x8fbf001c 
+						0x8fb10018 
+						0x8fb00014 
+						0x03e00008 
+						0x27bd0020 
+						0x24030004 
+						0x3c020170 
+						0x34088004 
+						0x8d040000 
+						0x34088030 
+						0xad030000 
+						0x34088000 
+						0x0800002b 
+						0xad020000 
+					>;
+				};
+			};
diff --git a/arch/mips/boot/dts/ucore-8xx.dts b/arch/mips/boot/dts/ucore-8xx.dts
new file mode 100644
index 0000000..29d981e
--- /dev/null
+++ b/arch/mips/boot/dts/ucore-8xx.dts
@@ -0,0 +1,61 @@
+			ucore {
+				src@1 {
+num-opcodes = <50>;
+					path = "/home/wrsadmin/build/43/mips32_xlp/build/linux/arch/mips/boot/dts/storm-linux-default.c";
+					timestamp = "Fri Dec  2 01:56:24 2011
+";
+					mask = <0xffff>;
+					opcodes = <
+						0x3c1c0010 
+						0x279cf808 
+						0x3c020010 
+						0x2442f808 
+						0x3c030010 
+						0x2463f808 
+						0xac400000 
+						0x0043082b 
+						0x1420fffd 
+						0x24420004 
+						0x3c1d0010 
+						0x27bdf9c0 
+						0x27a50020 
+						0x27a60028 
+						0xaca00000 
+						0xacc00000 
+						0x0c000029 
+						0x00002021 
+						0x1000ffff 
+						0x00000000 
+						0x3c020000 
+						0x8c4200fc 
+						0x27bdffe0 
+						0x2403ffff 
+						0xafbf001c 
+						0xafb10018 
+						0x10430009 
+						0xafb00014 
+						0x3c100000 
+						0x261000fc 
+						0x2411ffff 
+						0x0040f809 
+						0x2610fffc 
+						0x8e020000 
+						0x1451fffc 
+						0x00000000 
+						0x8fbf001c 
+						0x8fb10018 
+						0x8fb00014 
+						0x03e00008 
+						0x27bd0020 
+						0x24030004 
+						0x3c020170 
+						0x34088004 
+						0x8d040000 
+						0x34088030 
+						0xad030000 
+						0x34088000 
+						0x0800002b 
+						0xad020000 
+					>;
+				};
+			};
diff --git a/arch/mips/boot/dts/xlp316.dts b/arch/mips/boot/dts/xlp316.dts
new file mode 100644
index 0000000..b16361c
--- /dev/null
+++ b/arch/mips/boot/dts/xlp316.dts
@@ -0,0 +1,823 @@
+/* XLP3XX Device Tree Source
+ *
+ */
+
+/dts-v1/;
+
+/ {
+	model = "MIPS,XLP3XX";
+	compatible = "NETL,XLP3XX_A0";
+	#address-cells = <0x1>;
+	#size-cells = <0x1>;
+
+	hypervisor {
+		hypervisor-name = "Xen";
+		alloc_dom0_memory = <0x0>;
+		bootargs = "ncores=4 dom0_loadaddr=0x72000000 dom0_size=0x1c000000 dom0_cpumask=0xffff-- ";
+		domain_heap = <0x80000000 0x20000000>;
+	};
+
+	doms {
+		#address-cells = <0x1>;
+		#size-cells = <0x1>;
+
+		dom@0 {
+			device_type = "domain";
+			os = "linux";
+			#address-cells = <0x1>;
+			#size-cells = <0x1>;
+
+			cpu {
+				onlinemask = <0xffff>;
+				nae-rx-vc = <0x0>;
+				nae-fb-vc = <0x1>;
+				napi-vc-mask = <0x3>;
+				sae-rx-vc = <0x0>;
+				sae-rx-sync-vc = <0x3>;
+				ipsec-async-vc = <0x0>;
+				ipsec-sync-vc = <0x2>;
+			};
+
+			uart {
+				id = <0x0>;
+				owner = <0x1>;
+				sharedcfg = <0x1f000000>;
+			};
+
+			memory {
+				/* <Start Size>, Unit: M */
+				reg = <0x00000000 0x14000000 // 320M@0M
+				       0x1d000000 0xa3000000 >; // 2608M@464M
+			};
+                        fmn {
+                                node_0_vc_mask = <0x33333333 0x33333333 0x33333333 0x33333333>;
+                                node_1_vc_mask = <0x33333333 0x33333333 0x33333333 0x33333333>;
+                                node_2_vc_mask = <0x33333333 0x33333333 0x33333333 0x33333333>;
+                                node_3_vc_mask = <0x33333333 0x33333333 0x33333333 0x33333333>;
+                       };
+			pic {
+			};
+		};
+	};
+
+	chosen {
+		/* For NFS root filesystem */
+		/*
+		bootargs = "root=/dev/nfs rw nfsroot=192.168.0.1:/opt/rootfs/xlp832-n32 ip=192.168.0.2:192.168.0.1:192.168.0.1:255.255.254.0:xlp:eth4:off console=ttyS0,115200";
+		*/
+		/* For NOR root filesystem */
+		/*
+		bootargs = "crashkernel=128M@63M root=/dev/nfs rw nfsroot=128.224.162.244:/export/nfsroot/xlp832/rootfs ip=128.224.162.7:128.224.162.244:128.224.162.1:255.255.254.0:xlp:eth0:off console=ttyS0,115200";
+		bootargs = "crashkernel=128M@63M root=/dev/nfs rw nfsroot=128.224.162.244:/export/nfsroot/xlp832/rootfs ip=128.224.162.7:128.224.162.244:128.224.162.1:255.255.254.0:xlp:eth0:off console=ttyS0,115200";
+		bootargs = "ubi.mtd=7 root=ubi0:root rw rootfstype=ubifs ip=128.224.162.7:128.224.162.244:128.224.162.1:255.255.254.0:xlp:eth0:off console=ttyS0,115200";
+		bootargs = "root=/dev/mtdblock4 rw rootfstype=jffs2 ip=192.168.0.2:192.168.0.1:192.168.0.1:255.255.254.0:xlp:eth4:off console=ttyS0,115200";
+		bootargs = "root=/dev/mtdblock7 rw rootfstype=cramfs ip=128.224.162.7:128.224.162.244:128.224.162.1:255.255.254.0:xlp:eth0:off console=ttyS0,115200";
+		bootargs = "root=/dev/mtdblock7 rw rootfstype=yaffs ip=128.224.162.7:128.224.162.244:128.224.162.1:255.255.254.0:xlp:eth0:off console=ttyS0,115200";
+		bootargs = "console=ttyS0,115200 root=/dev/mmcblk0p3 rw rootdelay=10";
+		bootargs = "console=ttyS0,115200 root=/dev/sda1 rw rootdelay=10";
+		bootargs = "console=ttyS0,115200 root=/dev/md0 rw rootdelay=10";
+		*/
+		/* For kdump,CONFIG_PHYSICAL_START=0xffffffff84000000
+		 * Only PCIe ethernet driver(eth0) survive after booting
+		 * by kexec.
+		 */
+		bootargs = "crashkernel=128M@63M root=/dev/nfs rw nfsroot=128.224.162.151:/export/nfsroot/xlp832/rootfs ip=128.224.165.151:128.224.165.1:128.224.165.1:255.255.254.0:xlp:eth0:off console=ttyS0,115200 oprofile.timer=1";
+	};
+
+	/* These binaries are downloaded at the resp physical memory locations
+	 * by their corresponding bootstrapping loaders. For example,
+	 * u-boot is loaded by x-load at 193M, sysconfig is loaded by u-boot
+	 * at 1M, hypervisor by u-boot hypervisor at 136M.
+	 * On simulator all these binaries are pre-loaded by using '-F' option
+	 * for convenience. On silicon, they will be loaded by their corresponding
+	 * temporary download locations the stage-1/stage-2 firmware
+	 */
+	firmware-download {
+		u-boot        = <0x0c100000 0x3f00000>;  /* 63M @ 193M */
+		sysconfig     = <0x00100000 0x00100000>; /* 1M @ 1M */
+		hypervisor    = <0x08800000 0x00800000>; /* 8M @ 136M */
+		dom0          = <0x09000000 0x03000000>; /* 48M @ 144M */
+		domU-ramdisk  = <0x60000000 0x60800000>; /* 8M @ 1536M */
+	};
+
+	soc {
+num-nodes = <1>;
+fmn@node-0{
+        default-credits = <50>;
+        default-queue-size = <16384>;
+        fmn-spill-mem-base = <0x00000000 0x10000000>; /*0 - dynamic allocation */
+        fmn-spill-mem-size = <0x00000000 0x02000000>;
+	q-config{
+
+	};
+};
+fmn@node-1{
+        default-credits = <50>;
+        default-queue-size = <16384>;
+        fmn-spill-mem-base = <0 0>; /*0 - dynamic allocation */
+        fmn-spill-mem-size = <0x00000000 0x02000000>;
+	q-config{
+
+	};
+};
+fmn@node-2{
+
+};
+fmn@node-3{
+
+};
+  nae@node-0 {
+	model = "MIPS,XLP8XX NAE CFG";
+	compatible = "NETL,XLP8XX_A0";
+	#address-cells = <1>;
+	#size-cells = <1>;
+	frequency = <500>;
+
+	/include/ "ucore-3xx.dts"
+
+        freein-fifo-config {
+                /* If shared is true,
+                        1. Ucore is going to use upto max queues(16 for XLP, 8 for storm) for buffer mgmt
+                        2. Onnchip desc size per queue, same value will be configured for all the queues.
+                   If shared is false,
+                        1. Onchip desc size per queue will be configured using num_free_desc specified at the port level.
+                   If spill descs per queue is specified,
+                        1. spill will be enabled for all the queues(except mgmt) using the spill memory specified in the OS config file.
+                */
+		freein-fifo-spill-mem-range = <0x00000000 0x0fe00000 0x00000000 0x00100000>; // 1MB @ 254MB
+                freein-fifo-shared = <0>;
+                freein-fifo-onchip-num-descs = <56>; 
+                freein-fifo-spill-num-descs = <1200>;
+        };
+
+	// VFBID MAP: Upto 127 entries
+	// (each entry is a pair of (vfbid , dest-vc)
+	// Legal range: (vfbid (0 - 126), dest-vc (0 - 4095))
+	vfbid-config {
+		vfbid-map = <
+		      0    1    1    5    2   9    3    13
+                      4    17   5    21   6   25   7    29
+                      8    33   9    37   10  41   11   45
+                      12   49   13   53   14  57   15   61
+                      16   65   17   69   18  73   19   77
+                      20   81   21   85   22  89   23   93
+                      24   97   25  101   26 105   27  109
+                      28  113   29  117   30 121   31  125
+                >;
+	};
+
+	// Packet Ordering Engine (POE)
+	poe {	
+	
+		mode = "bypass";
+
+                distribution-enable = <1>;
+                // 16 bit mask
+                dist-drop-enable = <0>;
+                // 8 bit mask
+                class-drop-enable = <0>;
+                drop-timer = <0>;
+                dest-threshold = <0xa>;
+                dist-threshold = <0xa 0xa 0xa 0xa>;
+                statistics-enable = <0>;
+
+		// Each vector is 512 bit with masb indicating vc 512 and lsb indicating vc 0
+		// Format : 512-bit-vector is specified as 16 32-bit words
+		// Left most word has the vc range 511-479 right most word has vc range 31 - 0
+		// Each word has the MSB select higer vc number and LSB select lower vc num
+                distribution_vectors {
+                                     dv0  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0x1>;
+                                     dv1  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv2  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv3  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv4  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv5  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv6  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv7  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv8  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv9  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv10 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv11 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv12 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv13 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv14 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv15 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                };
+	};
+
+	complex@0 {
+		device_type = "nae-complex";
+		mode = "xaui";
+		xaui {
+			loopback = <0>;
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <55>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			parser-sequence-fifo-size = <225>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels 
+			num-channels = <1>;
+			rx-buffer-size = <944>;
+
+			// Max available descriptors are 1024  (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <150>;
+			free-desc-size = <2048>;
+			// In xlp3xx number of ucores available is 8. so, ucore_mask for xlp3xx is (ucore-mask & 0xFF)
+			ucore-mask = <0xffff>;
+		};
+		sgmii {
+	                loopback = <0 0 0 0>;
+			mgmt-port = <0 0 0 0>;
+        	        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                	iface-fifo-size = <13 13 13 13>;
+
+	                ext-phy-addr = <4 7 6 5>;
+        	        ext-phy-bus = <1 1 1 1>;
+
+	                // Max parser sequence fifo size 1024 packets
+        	        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                	num-channels = <1 1 1 1>;
+	                parser-sequence-fifo-size = <62 62 62 62>;
+
+        	        rx-buffer-size = <128 128 128 128>;
+
+                	// Max available descriptors are 1024 (across all complexes).
+	                // Per port num_free_descriptors must be even number
+        	        num-free-descs = <52 52 52 52>;
+                	free-desc-size = <2048 2048 2048 2048>;
+	                ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+		};
+                interlaken {
+                        //select daughter board : cortina or loopback
+                        db = "cortina";
+
+                        loopback = <0>;
+
+                        // Maximum number of lanes per interface = 8 (from 2 complexes)
+                        num-lanes = <4>;
+                        // lanerate 0 = 3.125Gbps , 1 = 6.25Gbps
+                        lane-rate = <0>;
+
+                        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                        iface-fifo-size = <110>;
+
+                        // Max parser sequence fifo size 1024 packets
+                        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                        parser-sequence-fifo-size = <225>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+                        num-channels = <4>;
+                        rx-buffer-size = <1840>;
+
+                        // Max available descriptors are 1024  (across all complexes).
+                        // Per port num_free_descriptors must be even number
+                        num-free-descs = <300>;
+                        free-desc-size = <2048>;
+                        ucore-mask = <0xffff>;
+                };
+
+	};
+	complex@1 {
+		device_type = "nae-complex";
+		mode = "xaui";
+		xaui {
+			loopback = <0>;
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <55>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			parser-sequence-fifo-size = <225>;
+			
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			num-channels = <1>;
+			rx-buffer-size = <944>;
+	
+			// Max available descriptors are 1024  (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <150>;
+			free-desc-size = <2048>;
+			ucore-mask = <0xffff>;
+		};
+		sgmii {
+	                loopback = <0 0 0 0>;
+
+	                // Max ingress fifo size 256 units (size of one unit is 64 byte)
+        	        iface-fifo-size = <13 13 13 13>;
+
+                	ext-phy-addr = <8 11 10 9>;
+	                ext-phy-bus = <1 1 1 1>;
+
+        	        // Max parser sequence fifo size 1024 packets
+                	// (if 1588 Timestamp is not required, then max size increases to 2048)
+	                num-channels = <1 1 1 1>;
+        	        parser-sequence-fifo-size = <62 62 62 62>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+        	        rx-buffer-size = <128 128 128 128>;
+
+
+                	// Max available descriptors are 1024 (across all complexes).
+	                // Per port num_free_descriptors must be even number
+        	        num-free-descs = <52 52 52 52>;
+                	free-desc-size = <2048 2048 2048 2048>;
+	                ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+		};
+
+	};
+	complex@2 {
+		device_type = "nae-complex";
+		mode = "xaui";
+
+                xaui {
+                        loopback = <0>;
+
+                        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                        iface-fifo-size = <55>;
+
+                        // Max parser sequence fifo size 1024 packets
+                        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                        parser-sequence-fifo-size = <225>;
+			
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+                        num-channels = <1>;
+                        rx-buffer-size = <944>;
+
+                        // Max available descriptors are 1024  (across all complexes).
+                        // Per port num_free_descriptors must be even number
+                        num-free-descs = <150>;
+                        free-desc-size = <2048>;
+                        ucore-mask = <0xffff>;
+                };
+
+		interlaken {
+	                //select daughter board : cortina or loopback
+        	        db = "cortina";
+
+                	loopback = <0>;
+
+	                // Maximum number of lanes per interface = 8 (from 2 complexes)
+        	        num-lanes = <4>;
+                	// lanerate 0 = 3.125Gbps , 1 = 6.25Gbps
+	                lane-rate = <0>;
+	
+        	        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                	iface-fifo-size = <110>;
+
+	                // Max parser sequence fifo size 1024 packets
+        	        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                	parser-sequence-fifo-size = <225>;
+			
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+                	num-channels = <4>;
+	                rx-buffer-size = <1840>;
+
+	                // Max available descriptors are 1024  (across all complexes).
+        	        // Per port num_free_descriptors must be even number
+                	num-free-descs = <300>;
+	                free-desc-size = <2048>;
+        	        ucore-mask = <0xffff>;
+		};
+		sgmii {
+        	        loopback = <0 0 0 0>;
+
+                	// Max ingress fifo size 256 units (size of one unit is 64 byte)
+	                iface-fifo-size = <13 13 13 13>;
+
+        	        ext-phy-addr = <0 3 2 1>;
+                	ext-phy-bus = <1 1 1 1>;
+
+	                // Max parser sequence fifo size 1024 packets
+        	        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                	num-channels = <1 1 1 1>;
+	                parser-sequence-fifo-size = <62 62 62 62>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+	                rx-buffer-size = <128 128 128 128>;
+
+
+        	        // Max available descriptors are 1024 (across all complexes).
+                	// Per port num_free_descriptors must be even number
+	                num-free-descs = <52 52 52 52>;
+        	        free-desc-size = <2048 2048 2048 2048>;
+                	ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+		};
+	};
+	complex@3 {
+		device_type = "nae-complex";
+		mode = "xaui";
+		xaui {
+			loopback = <0>;
+
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <55>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			parser-sequence-fifo-size = <225>;
+	
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			num-channels = <1>;
+			rx-buffer-size = <944>;
+
+			// Max available descriptors are 1024  (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <150>;
+			free-desc-size = <2048>;
+			ucore-mask = <0xffff>;
+		};
+                sgmii {
+                        loopback = <0 0 0 0>;
+
+                        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                        iface-fifo-size = <13 13 13 13>;
+
+                        ext-phy-addr = <12 15 14 13>;
+                        ext-phy-bus = <1 1 1 1>;
+
+                        // Max parser sequence fifo size 1024 packets
+                        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                        num-channels = <1 1 1 1>;
+                        parser-sequence-fifo-size = <62 62 62 62>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+                        rx-buffer-size = <128 128 128 128>;
+
+
+                        // Max available descriptors are 1024 (across all complexes).
+                        // Per port num_free_descriptors must be even number
+                        num-free-descs = <52 52 52 52>;
+                        free-desc-size = <2048 2048 2048 2048>;
+                        ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+                };
+	};
+	complex@4 {
+		device_type = "nae-complex";
+		mode = "sgmii";
+
+		sgmii {
+			loopback = <0 0>;
+	
+			mgmt-port = <1 0>;
+
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <13 13>;
+                
+			ext-phy-addr = <16 17>;
+        	        ext-phy-bus = <0 0>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			num-channels = <1 1>;
+			parser-sequence-fifo-size = <62 62>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			rx-buffer-size = <128 128>;
+				   
+
+			// Max available descriptors are 1024 (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <52 52>;
+			free-desc-size = <2048 2048>;
+			ucore-mask = <0xffff 0xffff>;
+		};
+	};
+};
+   nae@node-1 {
+	model = "MIPS,XLP8XX NAE CFG";
+	compatible = "NETL,XLP8XX_A0";
+	#address-cells = <1>;
+	#size-cells = <1>;
+	frequency = <500>;
+
+	/include/ "ucore-3xx.dts"
+
+        freein-fifo-config {
+                /* If shared is true,
+                        1. Ucore is going to use upto max queues(16 for XLP, 8 for storm) for buffer mgmt
+                        2. Onnchip desc size per queue, same value will be configured for all the queues.
+                   If shared is false,
+                        1. Onchip desc size per queue will be configured using num_free_desc specified at the port level.
+                   If spill descs per queue is specified,
+                        1. spill will be enabled for all the queues(except mgmt) using the spill memory specified in the OS config file.
+                */
+
+                freein-fifo-shared = <0>;
+                freein-fifo-onchip-num-descs = <0>;
+                freein-fifo-spill-num-descs = <0>;
+        };
+
+	// VFBID MAP: Upto 127 entries
+	// (each entry is a pair of (vfbid , dest-vc)
+	// Legal range: (vfbid (0 - 126), dest-vc (0 - 4095))
+	vfbid-config {
+		hw-replenish = <0>;
+	};
+
+	// Packet Ordering Engine (POE)
+	poe {	
+	
+		mode = "bypass";
+
+		// Each vector is 512 bit with masb indicating vc 512 and lsb indicating vc 0
+		// Format : 512-bit-vector is specified as 16 32-bit words
+		// Left most word has the vc range 511-479 right most word has vc range 31 - 0
+		// Each word has the MSB select higer vc number and LSB select lower vc num
+		
+		distribution-enable = <1>;
+		// 16 bit mask
+		dist-drop-enable = <0>;	 
+		// 8 bit mask
+		class-drop-enable = <0>;
+		drop-timer = <0>;
+		dest-threshold = <0xa>;
+		dist-threshold = <0xa 0xa 0xa 0xa>;
+		statistics-enable = <0>;
+ 
+                distribution_vectors {
+                                     dv0  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0x1>;
+                                     dv1  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv2  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv3  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv4  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv5  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv6  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv7  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv8  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv9  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv10 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv11 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv12 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv13 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv14 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv15 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                };
+	};
+
+	complex@0 {
+		device_type = "nae-complex";
+		mode = "xaui";
+		xaui {
+			loopback = <0>;
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <55>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			parser-sequence-fifo-size = <225>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			num-channels = <1>;
+			rx-buffer-size = <944>;
+
+			// Max available descriptors are 1024  (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <150>;
+			free-desc-size = <2048>;
+			ucore-mask = <0xffff>;
+		};
+		sgmii {
+	                loopback = <0 0 0 0>;
+	
+        	        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                	iface-fifo-size = <13 13 13 13>;
+
+	                ext-phy-addr = <4 7 6 5>;
+        	        ext-phy-bus = <1 1 1 1>;
+
+	                // Max parser sequence fifo size 1024 packets
+        	        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                	num-channels = <1 1 1 1>;
+	                parser-sequence-fifo-size = <62 62 62 62>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+        	        rx-buffer-size = <128 128 128 128>;
+
+
+                	// Max available descriptors are 1024 (across all complexes).
+	                // Per port num_free_descriptors must be even number
+        	        num-free-descs = <52 52 52 52>;
+                	free-desc-size = <2048 2048 2048 2048>;
+	                ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+		};
+                interlaken {
+                        //select daughter board : cortina or loopback
+                        db = "cortina";
+
+                        loopback = <0>;
+
+                        // Maximum number of lanes per interface = 8 (from 2 complexes)
+                        num-lanes = <4>;
+                        // lanerate 0 = 3.125Gbps , 1 = 6.25Gbps
+                        lane-rate = <0>;
+
+                        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                        iface-fifo-size = <110>;
+
+                        // Max parser sequence fifo size 1024 packets
+                        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                        parser-sequence-fifo-size = <225>;
+
+                        // Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+                        num-channels = <4>;
+                        rx-buffer-size = <1840>;
+
+                        // Max available descriptors are 1024  (across all complexes).
+                        // Per port num_free_descriptors must be even number
+                        num-free-descs = <300>;
+                        free-desc-size = <2048>;
+                        ucore-mask = <0xffff>;
+                };
+	};
+	complex@1 {
+		device_type = "nae-complex";
+		mode = "xaui";
+		xaui {
+			loopback = <0>;
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <55>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			parser-sequence-fifo-size = <225>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			num-channels = <1>;
+			rx-buffer-size = <944>;
+	
+			// Max available descriptors are 1024  (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <150>;
+			free-desc-size = <2048>;
+			ucore-mask = <0xffff>;
+		};
+		sgmii {
+	                loopback = <0 0 0 0>;
+
+	                // Max ingress fifo size 256 units (size of one unit is 64 byte)
+        	        iface-fifo-size = <13 13 13 13>;
+
+                	ext-phy-addr = <8 11 10 9>;
+	                ext-phy-bus = <1 1 1 1>;
+
+        	        // Max parser sequence fifo size 1024 packets
+                	// (if 1588 Timestamp is not required, then max size increases to 2048)
+	                num-channels = <1 1 1 1>;
+        	        parser-sequence-fifo-size = <62 62 62 62>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+        	        rx-buffer-size = <128 128 128 128>;
+
+
+                	// Max available descriptors are 1024 (across all complexes).
+	                // Per port num_free_descriptors must be even number
+        	        num-free-descs = <52 52 52 52>;
+                	free-desc-size = <2048 2048 2048 2048>;
+	                ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+		};
+
+	};
+	complex@2 {
+		device_type = "nae-complex";
+		mode = "xaui";
+
+                xaui {
+                        loopback = <0>;
+
+                        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                        iface-fifo-size = <55>;
+
+                        // Max parser sequence fifo size 1024 packets
+                        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                        parser-sequence-fifo-size = <225>;
+
+                        num-channels = <1>;
+                        rx-buffer-size = <944>;
+
+                        // Max available descriptors are 1024  (across all complexes).
+                        // Per port num_free_descriptors must be even number
+                        num-free-descs = <150>;
+                        free-desc-size = <2048>;
+                        ucore-mask = <0xffff>;
+                };
+
+		interlaken {
+	                //select daughter board : cortina or loopback
+        	        db = "cortina";
+
+                	loopback = <0>;
+
+	                // Maximum number of lanes per interface = 8 (from 2 complexes)
+        	        num-lanes = <4>;
+                	// lanerate 0 = 3.125Gbps , 1 = 6.25Gbps
+	                lane-rate = <0>;
+	
+        	        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                	iface-fifo-size = <110>;
+
+	                // Max parser sequence fifo size 1024 packets
+        	        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                	parser-sequence-fifo-size = <225>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+                	num-channels = <4>;
+	                rx-buffer-size = <1840>;
+
+	                // Max available descriptors are 1024  (across all complexes).
+        	        // Per port num_free_descriptors must be even number
+                	num-free-descs = <300>;
+	                free-desc-size = <2048>;
+        	        ucore-mask = <0xffff>;
+		};
+		sgmii {
+        	        loopback = <0 0 0 0>;
+
+                	// Max ingress fifo size 256 units (size of one unit is 64 byte)
+	                iface-fifo-size = <13 13 13 13>;
+
+        	        ext-phy-addr = <0 3 2 1>;
+                	ext-phy-bus = <1 1 1 1>;
+
+	                // Max parser sequence fifo size 1024 packets
+        	        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                	num-channels = <1 1 1 1>;
+	                parser-sequence-fifo-size = <62 62 62 62>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+	                rx-buffer-size = <128 128 128 128>;
+
+
+        	        // Max available descriptors are 1024 (across all complexes).
+                	// Per port num_free_descriptors must be even number
+	                num-free-descs = <52 52 52 52>;
+        	        free-desc-size = <2048 2048 2048 2048>;
+                	ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+		};
+	};
+	complex@3 {
+		device_type = "nae-complex";
+		mode = "xaui";
+		xaui {
+			loopback = <0>;
+
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <55>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			parser-sequence-fifo-size = <225>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			num-channels = <1>;
+			rx-buffer-size = <944>;
+
+			// Max available descriptors are 1024  (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <150>;
+			free-desc-size = <2048>;
+			ucore-mask = <0xffff>;
+		};
+	};
+	complex@4 {
+		device_type = "nae-complex";
+		mode = "sgmii";
+
+		sgmii {
+			loopback = <0 0>;
+			mgmt-port = <1 0>;
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <13 13>;
+ 		               
+			ext-phy-addr = <16 17>;
+        	        ext-phy-bus = <0 0>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			num-channels = <1 1>;
+			parser-sequence-fifo-size = <62 62>;
+	
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			rx-buffer-size = <128 128>;
+				   
+
+			// Max available descriptors are 1024 (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <52 52>;
+			free-desc-size = <2048 2048>;
+			ucore-mask = <0xffff 0xffff>;
+		};
+	};
+};
+nae@node-2 {
+
+};
+nae@node-3 {
+
+};
+
+	};
+};
+
diff --git a/arch/mips/boot/dts/xlp832.dts b/arch/mips/boot/dts/xlp832.dts
index f922e7f..cc3aadd 100644
--- a/arch/mips/boot/dts/xlp832.dts
+++ b/arch/mips/boot/dts/xlp832.dts
@@ -3,51 +3,58 @@
  */
 
 /dts-v1/;
+
 / {
 	model = "MIPS,XLP8XX";
 	compatible = "NETL,XLP8XX_A0";
-
-	#address-cells = <1>;
-	#size-cells = <1>;
+	#address-cells = <0x1>;
+	#size-cells = <0x1>;
 
 	hypervisor {
 		hypervisor-name = "Xen";
-		alloc_dom0_memory = <0>;
-		bootargs = "ncores=8 dom0_loadaddr=0x72000000 dom0_size=0x1c000000 dom0_cpumask=0xffffffff -- ";
+		alloc_dom0_memory = <0x0>;
+		bootargs = "ncores=8 dom0_loadaddr=0x72000000 dom0_size=0x1c000000 dom0_cpumask=0xffffffff-- ";
 		domain_heap = <0x80000000 0x20000000>;
 	};
+
 	doms {
-		#address-cells = <1>;
-		#size-cells = <1>;
+		#address-cells = <0x1>;
+		#size-cells = <0x1>;
+
 		dom@0 {
 			device_type = "domain";
 			os = "linux";
-
-			#address-cells = <1>;
-			#size-cells = <1>;
+			#address-cells = <0x1>;
+			#size-cells = <0x1>;
 
 			cpu {
 				onlinemask = <0xffffffff>;
-                                nae-rx-vc = <0>;
-                                nae-fb-vc = <1>;
+				nae-rx-vc = <0x0>;
+				nae-fb-vc = <0x1>;
+				napi-vc-mask = <0x3>;
+				sae-rx-vc = <0x0>;
+				sae-rx-sync-vc = <0x3>;
+				ipsec-async-vc = <0x0>;
+				ipsec-sync-vc = <0x2>;
 			};
+
 			uart {
-				id = <0>;
-				owner = <1>;
+				id = <0x0>;
+				owner = <0x1>;
 				sharedcfg = <0x1f000000>;
 			};
+
 			memory {
 				/* <Start Size>, Unit: M */
-				reg = <0x00000000 0x00000140 /* 320M@0M */
-				       0x000001d0 0x00000a30 /* 2608M@464M */
-				       0x00000e00 0x00003490>; /* 13456M@3584M */
-			};
-			fmn {
-				node_0_vc_mask = <0xffffffff 0xffffffff 0xffffffff 0xffffffff>;
-				node_1_vc_mask = <0xffffffff 0xffffffff 0xffffffff 0xffffffff>;
-				node_2_vc_mask = <0xffffffff 0xffffffff 0xffffffff 0xffffffff>;
-				node_3_vc_mask = <0xffffffff 0xffffffff 0xffffffff 0xffffffff>;
+				reg = <0x00000000 0x14000000 // 320M@0M
+				       0x1d000000 0xa3000000 >; // 2608M@464M
 			};
+                        fmn {
+                                node_0_vc_mask = <0x33333333 0x33333333 0x33333333 0x33333333>;
+                                node_1_vc_mask = <0x33333333 0x33333333 0x33333333 0x33333333>;
+                                node_2_vc_mask = <0x33333333 0x33333333 0x33333333 0x33333333>;
+                                node_3_vc_mask = <0x33333333 0x33333333 0x33333333 0x33333333>;
+                       };
 			pic {
 			};
 		};
@@ -60,13 +67,21 @@
 		*/
 		/* For NOR root filesystem */
 		/*
+		bootargs = "crashkernel=128M@63M root=/dev/nfs rw nfsroot=128.224.162.244:/export/nfsroot/xlp832/rootfs ip=128.224.162.7:128.224.162.244:128.224.162.1:255.255.254.0:xlp:eth0:off console=ttyS0,115200";
+		bootargs = "crashkernel=128M@63M root=/dev/nfs rw nfsroot=128.224.162.244:/export/nfsroot/xlp832/rootfs ip=128.224.162.7:128.224.162.244:128.224.162.1:255.255.254.0:xlp:eth0:off console=ttyS0,115200";
+		bootargs = "ubi.mtd=7 root=ubi0:root rw rootfstype=ubifs ip=128.224.162.7:128.224.162.244:128.224.162.1:255.255.254.0:xlp:eth0:off console=ttyS0,115200";
 		bootargs = "root=/dev/mtdblock4 rw rootfstype=jffs2 ip=192.168.0.2:192.168.0.1:192.168.0.1:255.255.254.0:xlp:eth4:off console=ttyS0,115200";
+		bootargs = "root=/dev/mtdblock7 rw rootfstype=cramfs ip=128.224.162.7:128.224.162.244:128.224.162.1:255.255.254.0:xlp:eth0:off console=ttyS0,115200";
+		bootargs = "root=/dev/mtdblock7 rw rootfstype=yaffs ip=128.224.162.7:128.224.162.244:128.224.162.1:255.255.254.0:xlp:eth0:off console=ttyS0,115200";
+		bootargs = "console=ttyS0,115200 root=/dev/mmcblk0p3 rw rootdelay=10";
+		bootargs = "console=ttyS0,115200 root=/dev/sda1 rw rootdelay=10";
+		bootargs = "console=ttyS0,115200 root=/dev/md0 rw rootdelay=10";
 		*/
 		/* For kdump,CONFIG_PHYSICAL_START=0xffffffff84000000
 		 * Only PCIe ethernet driver(eth0) survive after booting
 		 * by kexec.
 		 */
-		bootargs = "crashkernel=128M@63M root=/dev/nfs rw nfsroot=192.168.0.1:/opt/rootfs/xlp832-n32,nfsvers=3 ip=192.168.0.2:192.168.0.1:192.168.0.1:255.255.254.0:xlp:eth0:off console=ttyS0,115200";
+		bootargs = "crashkernel=128M@63M root=/dev/nfs rw nfsroot=128.224.162.151:/export/nfsroot/xlp832/rootfs ip=128.224.165.248:128.224.165.1:128.224.165.1:255.255.254.0:xlp:eth0:off console=ttyS0,115200";
 	};
 
 	/* These binaries are downloaded at the resp physical memory locations
@@ -86,714 +101,723 @@
 	};
 
 	soc {
-		nae-cfg {
-			start-port-id = <0>;
-			num-intf-regs = <0>;
-			frequency = <500>;
-			ilk-complex-map = <0x0>;
-			xaui-complex-map = <0xf>;
-			sgmii-complex-map = <0x10>;
-			num-ports = <6>;
-			ucore {
-				src@1 {
-num-opcodes = <56>;
-					mask = <0xffff>;
-					opcodes = <
-						0x3c1c0010
-						0x279cf810
-						0x3c020010
-						0x2442f810
-						0x3c030010
-						0x2463f810
-						0xac400000
-						0x0043082b
-						0x1420fffd
-						0x24420004
-						0x3c1d0010
-						0x27bdf9c0
-						0x27a50020
-						0x27a60028
-						0xaca00000
-						0xacc00000
-						0x0c00002c
-						0x00002021
-						0x1000ffff
-						0x00000000
-						0x3c020000
-						0x27bdffd8
-						0x8c59013c
-						0xafbf0024
-						0x2402ffff
-						0xafb10020
-						0x13220009
-						0xafb0001c
-						0x3c100000
-						0x2411ffff
-						0x2610013c
-						0x0320f809
-						0x2610fffc
-						0x8e190000
-						0x1731fffc
-						0x00000000
-						0x8fbf0024
-						0x8fb10020
-						0x8fb0001c
-						0x03e00008
-						0x27bd0028
-						0x00000000
-						0x00000000
-						0x00000000
-						0x24030004
-						0x3c020170
-						0x34088004
-						0x8d040000
-						0x34088030
-						0xad030000
-						0x34088000
-						0x0800002e
-						0xad020000
-						0x00000000
-						0x80000000
-						0x00000000
-					>;
-				};
-			};
-			global-nae-regs {
-				 num-regs = <0xbb>;
-				 regs = <
-					0x81 0x00000000
-					0x81 0x00000001
-					0x81 0x00000002
-					0x81 0x00000003
-					0x81 0x00000004
-					0x81 0x00000005
-					0x81 0x00000006
-					0x81 0x00000007
-					0x81 0x24924908
-					0x81 0x24924909
-					0x81 0x2492490a
-					0x81 0x2492490b
-					0x81 0x2492490c
-					0x81 0x2492490d
-					0x81 0x2492490e
-					0x81 0x2492490f
-					0x81 0x49249210
-					0x81 0x49249211
-					0x81 0x49249212
-					0x81 0x49249213
-					0x81 0x49249214
-					0x81 0x49249215
-					0x81 0x49249216
-					0x81 0x49249217
-					0x81 0x6db6db18
-					0x81 0x6db6db19
-					0x81 0x6db6db1a
-					0x81 0x6db6db1b
-					0x81 0x6db6db1c
-					0x81 0x6db6db1d
-					0x81 0x6db6db1e
-					0x81 0x6db6db1f
-					0x81 0x92492420
-					0x81 0x92492421
-					0x81 0x92492422
-					0x81 0x92492423
-					0x81 0x92492424
-					0x81 0x92492425
-					0x81 0x92492426
-					0x81 0x92492427
-					0x81 0xb6db6d28
-					0x81 0xb6db6d29
-					0x81 0xb6db6d2a
-					0x81 0xb6db6d2b
-					0x81 0xb6db6d2c
-					0x81 0xb6db6d2d
-					0x81 0xb6db6d2e
-					0x81 0xb6db6d2f
-					0x81 0xdb6db630
-					0x81 0xdb6db631
-					0x81 0xdb6db632
-					0x81 0xdb6db633
-					0x81 0xdb6db634
-					0x81 0xdb6db635
-					0x81 0xdb6db636
-					0x81 0xdb6db637
-					0x81 0xffffff38
-					0x81 0xffffff39
-					0x81 0xffffff3a
-					0x81 0xffffff3b
-					0x81 0xffffff3c
-					0x81 0xffffff3d
-					0x81 0xffffff3e
-					0x81 0xffffff3f
-					0x81 0x00000040
-					0x81 0x00000041
-					0x3a 0x007d01f1
-					0x3a 0x007901e1
-					0x3a 0x007501d1
-					0x3a 0x007101c1
-					0x3a 0x006d01b1
-					0x3a 0x006901a1
-					0x3a 0x00650191
-					0x3a 0x00610181
-					0x3a 0x005d0171
-					0x3a 0x00590161
-					0x3a 0x00550151
-					0x3a 0x00510141
-					0x3a 0x004d0131
-					0x3a 0x00490121
-					0x3a 0x00450111
-					0x3a 0x00410101
-					0x3a 0x003d00f1
-					0x3a 0x003900e1
-					0x3a 0x003500d1
-					0x3a 0x003100c1
-					0x3a 0x002d00b1
-					0x3a 0x002900a1
-					0x3a 0x00250091
-					0x3a 0x00210081
-					0x3a 0x001d0071
-					0x3a 0x00190061
-					0x3a 0x00150051
-					0x3a 0x00110041
-					0x3a 0x000d0031
-					0x3a 0x00090021
-					0x3a 0x00050011
-					0x3a 0x00010001
-					0x2f 0x0000ffff
-					0x8a 0x18370000
-					0x8a 0x18003701
-					0x8a 0x18003702
-					0x8a 0x18003703
-					0x8a 0x18373704
-					0x8a 0x18006e05
-					0x8a 0x18006e06
-					0x8a 0x18006e07
-					0x8a 0x18376e08
-					0x8a 0x1800a509
-					0x8a 0x1800a50a
-					0x8a 0x1800a50b
-					0x8a 0x1837a50c
-					0x8a 0x1800dc0d
-					0x8a 0x1800dc0e
-					0x8a 0x1800dc0f
-					0x8a 0x180ddc10
-					0x8a 0x180de911
-					0x8a 0x1800f612
-					0x8a 0x1800f613
-					0x12 0x00010000
-					0x13 0x00010001
-					0x14 0x00020001
-					0x15 0x00020002
-					0x16 0x00030002
-					0x17 0x00030003
-					0x18 0x00040003
-					0x19 0x00040004
-					0x1a 0x00050004
-					0x1b 0x00060006
-					0x21 0x00000000
-					0x22 0x8ec00000
-					0x22 0x0ec00000
-					0x21 0x00000001
-					0x22 0x8ec00ec0
-					0x22 0x0ec00ec0
-					0x21 0x00000002
-					0x22 0x8ec01d80
-					0x22 0x0ec01d80
-					0x21 0x00000003
-					0x22 0x8ec02c40
-					0x22 0x0ec02c40
-					0x21 0x00000004
-					0x22 0x82003b00
-					0x22 0x02003b00
-					0x21 0x00000005
-					0x22 0x82003d00
-					0x22 0x02003d00
-					0x20 0x04b00000
-					0x20 0x00804b01
-					0x20 0x00805302
-					0x20 0x00805b03
-					0x20 0x04b06304
-					0x20 0x0080ae05
-					0x20 0x0080b606
-					0x20 0x0080be07
-					0x20 0x04b0c608
-					0x20 0x00811109
-					0x20 0x0081190a
-					0x20 0x0081210b
-					0x20 0x04b1290c
-					0x20 0x0081740d
-					0x20 0x00817c0e
-					0x20 0x0081840f
-					0x20 0x01a18c10
-					0x20 0x01a1a611
-					0x20 0x0081c012
-					0x20 0x0081c813
-					0x1f 0x01c20000
-					0x1f 0x00001c21
-					0x1f 0x00001c22
-					0x1f 0x00001c23
-					0x1f 0x01c21c24
-					0x1f 0x00003845
-					0x1f 0x00003846
-					0x1f 0x00003847
-					0x1f 0x01c23848
-					0x1f 0x00005469
-					0x1f 0x0000546a
-					0x1f 0x0000546b
-					0x1f 0x01c2546c
-					0x1f 0x0000708d
-					0x1f 0x0000708e
-					0x1f 0x0000708f
-					0x1f 0x007c7090
-					0x1f 0x007c7851
-					0x1f 0x00008012
-					0x1f 0x00008013
-				 >;
-			};
-			port@0 {
-				type = "XAUI_IF";
-				num-free-desc = <150>;
-				hw-port-id = <0>;
-				num-channels = <1>;
-				mgmt = <0>;
-				tx-que-range = <476 476>;
-				rx-que = <1000>;
-				num-nae-regs = <16>;
-				free-desc-size = <2048>;
-				nae-regs = <
-					0x28 0x00002000
-					0x82 0x80ffff00
-					0x1d 0x00370000
-					0x1d 0x00370004
-					0x1d 0x00370008
-					0x1d 0x0037000c
-					0x1d 0x00370010
-					0x1d 0x00370014
-					0x1d 0x00370018
-					0x1d 0x0037001c
-					0x1d 0x00370020
-					0x1d 0x00370024
-					0x1d 0x00370028
-					0x1d 0x0037002c
-					0x1d 0x00370030
-					0x80 0x00000300
-				>;
-				intf-regs = <
-				>;
-			};
-			port@1 {
-				type = "XAUI_IF";
-				num-free-desc = <150>;
-				hw-port-id = <4>;
-				num-channels = <1>;
-				mgmt = <0>;
-				tx-que-range = <477 477>;
-				rx-que = <1004>;
-				num-nae-regs = <16>;
-				free-desc-size = <2048>;
-				nae-regs = <
-					0x28 0x00002004
-					0x82 0x80ffff04
-					0x1d 0x00370401
-					0x1d 0x00370405
-					0x1d 0x00370409
-					0x1d 0x0037040d
-					0x1d 0x00370411
-					0x1d 0x00370415
-					0x1d 0x00370419
-					0x1d 0x0037041d
-					0x1d 0x00370421
-					0x1d 0x00370425
-					0x1d 0x00370429
-					0x1d 0x0037042d
-					0x1d 0x00370431
-					0x80 0x2aaa0304
-				>;
-				intf-regs = <
-				>;
-			};
-			port@2 {
-				type = "XAUI_IF";
-				num-free-desc = <150>;
-				hw-port-id = <8>;
-				num-channels = <1>;
-				mgmt = <0>;
-				tx-que-range = <478 478>;
-				rx-que = <1008>;
-				num-nae-regs = <16>;
-				free-desc-size = <2048>;
-				nae-regs = <
-					0x28 0x00002008
-					0x82 0x80ffff08
-					0x1d 0x00370802
-					0x1d 0x00370806
-					0x1d 0x0037080a
-					0x1d 0x0037080e
-					0x1d 0x00370812
-					0x1d 0x00370816
-					0x1d 0x0037081a
-					0x1d 0x0037081e
-					0x1d 0x00370822
-					0x1d 0x00370826
-					0x1d 0x0037082a
-					0x1d 0x0037082e
-					0x1d 0x00370832
-					0x80 0x55540308
-				>;
-				intf-regs = <
-				>;
-			};
-			port@3 {
-				type = "XAUI_IF";
-				num-free-desc = <150>;
-				hw-port-id = <12>;
-				num-channels = <1>;
-				mgmt = <0>;
-				tx-que-range = <479 479>;
-				rx-que = <1012>;
-				num-nae-regs = <16>;
-				free-desc-size = <2048>;
-				nae-regs = <
-					0x28 0x0000200c
-					0x82 0x80ffff0c
-					0x1d 0x00370c03
-					0x1d 0x00370c07
-					0x1d 0x00370c0b
-					0x1d 0x00370c0f
-					0x1d 0x00370c13
-					0x1d 0x00370c17
-					0x1d 0x00370c1b
-					0x1d 0x00370c1f
-					0x1d 0x00370c23
-					0x1d 0x00370c27
-					0x1d 0x00370c2b
-					0x1d 0x00370c2f
-					0x1d 0x00370c33
-					0x80 0x7ffe030c
-				>;
-				intf-regs = <
-				>;
-			};
-			port@4 {
-				type = "SGMII_IF";
-				num-free-desc = <52>;
-				hw-port-id = <16>;
-				num-channels = <1>;
-				mgmt = <1>;
-				tx-que-range = <480 480>;
-				rx-que = <1016>;
-				num-nae-regs = <5>;
-				free-desc-size = <2048>;
-				nae-regs = <
-					0x28 0x00002010
-					0x82 0x80ffff10
-					0x1d 0x00371034
-					0x1d 0x00371035
-					0x80 0xaaa80310
-				>;
-				intf-regs = <
-					0x0 0x80000005
-					0x1 0x00007201
-					0x0 0x00000005
-				>;
-			};
-			port@5 {
-				type = "SGMII_IF";
-				num-free-desc = <52>;
-				hw-port-id = <17>;
-				num-channels = <1>;
-				mgmt = <1>;
-				tx-que-range = <481 481>;
-				rx-que = <1017>;
-				num-nae-regs = <5>;
-				free-desc-size = <2048>;
-				nae-regs = <
-					0x28 0x00002011
-					0x82 0x80ffff11
-					0x1d 0x00371136
-					0x1d 0x00371137
-					0x80 0xd5520311
-				>;
-				intf-regs = <
-					0x0 0x80000005
-					0x1 0x00007201
-					0x0 0x00000005
-				>;
-			};
-			poe {
-				mode = "bypass";
-				regs {
-					num-regs = <267>;
-					regs = <
-					0 0x205 0x00000000
-					1 0x100 0x00000000
-					1 0x101 0x00000000
-					1 0x102 0x00000000
-					1 0x103 0x00000000
-					1 0x104 0x00000000
-					1 0x105 0x00000000
-					1 0x106 0x00000000
-					1 0x107 0x00000000
-					1 0x108 0x00000000
-					1 0x109 0x00000000
-					1 0x10a 0x00000000
-					1 0x10b 0x00000000
-					1 0x10c 0x00000000
-					1 0x10d 0x00000000
-					1 0x10e 0x00000000
-					1 0x10f 0x00000001
-					1 0x110 0x00000000
-					1 0x111 0x00000000
-					1 0x112 0x00000000
-					1 0x113 0x00000000
-					1 0x114 0x00000000
-					1 0x115 0x00000000
-					1 0x116 0x00000000
-					1 0x117 0x00000000
-					1 0x118 0x00000000
-					1 0x119 0x00000000
-					1 0x11a 0x00000000
-					1 0x11b 0x00000000
-					1 0x11c 0x00000000
-					1 0x11d 0x00000000
-					1 0x11e 0x00000000
-					1 0x11f 0x00000000
-					1 0x120 0x00000000
-					1 0x121 0x00000000
-					1 0x122 0x00000000
-					1 0x123 0x00000000
-					1 0x124 0x00000000
-					1 0x125 0x00000000
-					1 0x126 0x00000000
-					1 0x127 0x00000000
-					1 0x128 0x00000000
-					1 0x129 0x00000000
-					1 0x12a 0x00000000
-					1 0x12b 0x00000000
-					1 0x12c 0x00000000
-					1 0x12d 0x00000000
-					1 0x12e 0x00000000
-					1 0x12f 0x00000000
-					1 0x130 0x00000000
-					1 0x131 0x00000000
-					1 0x132 0x00000000
-					1 0x133 0x00000000
-					1 0x134 0x00000000
-					1 0x135 0x00000000
-					1 0x136 0x00000000
-					1 0x137 0x00000000
-					1 0x138 0x00000000
-					1 0x139 0x00000000
-					1 0x13a 0x00000000
-					1 0x13b 0x00000000
-					1 0x13c 0x00000000
-					1 0x13d 0x00000000
-					1 0x13e 0x00000000
-					1 0x13f 0x00000000
-					1 0x140 0x00000000
-					1 0x141 0x00000000
-					1 0x142 0x00000000
-					1 0x143 0x00000000
-					1 0x144 0x00000000
-					1 0x145 0x00000000
-					1 0x146 0x00000000
-					1 0x147 0x00000000
-					1 0x148 0x00000000
-					1 0x149 0x00000000
-					1 0x14a 0x00000000
-					1 0x14b 0x00000000
-					1 0x14c 0x00000000
-					1 0x14d 0x00000000
-					1 0x14e 0x00000000
-					1 0x14f 0x00000000
-					1 0x150 0x00000000
-					1 0x151 0x00000000
-					1 0x152 0x00000000
-					1 0x153 0x00000000
-					1 0x154 0x00000000
-					1 0x155 0x00000000
-					1 0x156 0x00000000
-					1 0x157 0x00000000
-					1 0x158 0x00000000
-					1 0x159 0x00000000
-					1 0x15a 0x00000000
-					1 0x15b 0x00000000
-					1 0x15c 0x00000000
-					1 0x15d 0x00000000
-					1 0x15e 0x00000000
-					1 0x15f 0x00000000
-					1 0x160 0x00000000
-					1 0x161 0x00000000
-					1 0x162 0x00000000
-					1 0x163 0x00000000
-					1 0x164 0x00000000
-					1 0x165 0x00000000
-					1 0x166 0x00000000
-					1 0x167 0x00000000
-					1 0x168 0x00000000
-					1 0x169 0x00000000
-					1 0x16a 0x00000000
-					1 0x16b 0x00000000
-					1 0x16c 0x00000000
-					1 0x16d 0x00000000
-					1 0x16e 0x00000000
-					1 0x16f 0x00000000
-					1 0x170 0x00000000
-					1 0x171 0x00000000
-					1 0x172 0x00000000
-					1 0x173 0x00000000
-					1 0x174 0x00000000
-					1 0x175 0x00000000
-					1 0x176 0x00000000
-					1 0x177 0x00000000
-					1 0x178 0x00000000
-					1 0x179 0x00000000
-					1 0x17a 0x00000000
-					1 0x17b 0x00000000
-					1 0x17c 0x00000000
-					1 0x17d 0x00000000
-					1 0x17e 0x00000000
-					1 0x17f 0x00000000
-					1 0x180 0x00000000
-					1 0x181 0x00000000
-					1 0x182 0x00000000
-					1 0x183 0x00000000
-					1 0x184 0x00000000
-					1 0x185 0x00000000
-					1 0x186 0x00000000
-					1 0x187 0x00000000
-					1 0x188 0x00000000
-					1 0x189 0x00000000
-					1 0x18a 0x00000000
-					1 0x18b 0x00000000
-					1 0x18c 0x00000000
-					1 0x18d 0x00000000
-					1 0x18e 0x00000000
-					1 0x18f 0x00000000
-					1 0x190 0x00000000
-					1 0x191 0x00000000
-					1 0x192 0x00000000
-					1 0x193 0x00000000
-					1 0x194 0x00000000
-					1 0x195 0x00000000
-					1 0x196 0x00000000
-					1 0x197 0x00000000
-					1 0x198 0x00000000
-					1 0x199 0x00000000
-					1 0x19a 0x00000000
-					1 0x19b 0x00000000
-					1 0x19c 0x00000000
-					1 0x19d 0x00000000
-					1 0x19e 0x00000000
-					1 0x19f 0x00000000
-					1 0x1a0 0x00000000
-					1 0x1a1 0x00000000
-					1 0x1a2 0x00000000
-					1 0x1a3 0x00000000
-					1 0x1a4 0x00000000
-					1 0x1a5 0x00000000
-					1 0x1a6 0x00000000
-					1 0x1a7 0x00000000
-					1 0x1a8 0x00000000
-					1 0x1a9 0x00000000
-					1 0x1aa 0x00000000
-					1 0x1ab 0x00000000
-					1 0x1ac 0x00000000
-					1 0x1ad 0x00000000
-					1 0x1ae 0x00000000
-					1 0x1af 0x00000000
-					1 0x1b0 0x00000000
-					1 0x1b1 0x00000000
-					1 0x1b2 0x00000000
-					1 0x1b3 0x00000000
-					1 0x1b4 0x00000000
-					1 0x1b5 0x00000000
-					1 0x1b6 0x00000000
-					1 0x1b7 0x00000000
-					1 0x1b8 0x00000000
-					1 0x1b9 0x00000000
-					1 0x1ba 0x00000000
-					1 0x1bb 0x00000000
-					1 0x1bc 0x00000000
-					1 0x1bd 0x00000000
-					1 0x1be 0x00000000
-					1 0x1bf 0x00000000
-					1 0x1c0 0x00000000
-					1 0x1c1 0x00000000
-					1 0x1c2 0x00000000
-					1 0x1c3 0x00000000
-					1 0x1c4 0x00000000
-					1 0x1c5 0x00000000
-					1 0x1c6 0x00000000
-					1 0x1c7 0x00000000
-					1 0x1c8 0x00000000
-					1 0x1c9 0x00000000
-					1 0x1ca 0x00000000
-					1 0x1cb 0x00000000
-					1 0x1cc 0x00000000
-					1 0x1cd 0x00000000
-					1 0x1ce 0x00000000
-					1 0x1cf 0x00000000
-					1 0x1d0 0x00000000
-					1 0x1d1 0x00000000
-					1 0x1d2 0x00000000
-					1 0x1d3 0x00000000
-					1 0x1d4 0x00000000
-					1 0x1d5 0x00000000
-					1 0x1d6 0x00000000
-					1 0x1d7 0x00000000
-					1 0x1d8 0x00000000
-					1 0x1d9 0x00000000
-					1 0x1da 0x00000000
-					1 0x1db 0x00000000
-					1 0x1dc 0x00000000
-					1 0x1dd 0x00000000
-					1 0x1de 0x00000000
-					1 0x1df 0x00000000
-					1 0x1e0 0x00000000
-					1 0x1e1 0x00000000
-					1 0x1e2 0x00000000
-					1 0x1e3 0x00000000
-					1 0x1e4 0x00000000
-					1 0x1e5 0x00000000
-					1 0x1e6 0x00000000
-					1 0x1e7 0x00000000
-					1 0x1e8 0x00000000
-					1 0x1e9 0x00000000
-					1 0x1ea 0x00000000
-					1 0x1eb 0x00000000
-					1 0x1ec 0x00000000
-					1 0x1ed 0x00000000
-					1 0x1ee 0x00000000
-					1 0x1ef 0x00000000
-					1 0x1f0 0x00000000
-					1 0x1f1 0x00000000
-					1 0x1f2 0x00000000
-					1 0x1f3 0x00000000
-					1 0x1f4 0x00000000
-					1 0x1f5 0x00000000
-					1 0x1f6 0x00000000
-					1 0x1f7 0x00000000
-					1 0x1f8 0x00000000
-					1 0x1f9 0x00000000
-					1 0x1fa 0x00000000
-					1 0x1fb 0x00000000
-					1 0x1fc 0x00000000
-					1 0x1fd 0x00000000
-					1 0x1fe 0x00000000
-					1 0x1ff 0x00000000
-					0 0x200 0x0000000a
-					0 0x201 0x0000000a
-					0 0x202 0x0000000a
-					0 0x203 0x0000000a
-					0 0x204 0x0000000a
-					0 0x205 0x00000001
-					0 0xba 0x00000001
-					0 0x214 0x00000007
-					>;
-				};
-			};
+num-nodes = <1>;
+fmn@node-0{
+        default-credits = <50>;
+        default-queue-size = <16384>;
+        fmn-spill-mem-base = <0x00000000 0x10000000>; /*0 - dynamic allocation */
+        fmn-spill-mem-size = <0x00000000 0x02000000>;
+	q-config{
+
+	};
+};
+fmn@node-1{
+        default-credits = <50>;
+        default-queue-size = <16384>;
+        fmn-spill-mem-base = <0 0>; /*0 - dynamic allocation */
+        fmn-spill-mem-size = <0x00000000 0x02000000>;
+	q-config{
+
+	};
+};
+fmn@node-2{
+
+};
+fmn@node-3{
+
+};
+  nae@node-0 {
+	model = "MIPS,XLP8XX NAE CFG";
+	compatible = "NETL,XLP8XX_A0";
+	#address-cells = <1>;
+	#size-cells = <1>;
+	frequency = <500>;
+
+	/include/ "ucore-8xx.dts"
+
+        freein-fifo-config {
+                /* If shared is true,
+                        1. Ucore is going to use upto max queues(16 for XLP, 8 for storm) for buffer mgmt
+                        2. Onnchip desc size per queue, same value will be configured for all the queues.
+                   If shared is false,
+                        1. Onchip desc size per queue will be configured using num_free_desc specified at the port level.
+                   If spill descs per queue is specified,
+                        1. spill will be enabled for all the queues(except mgmt) using the spill memory specified in the OS config file.
+                */
+		freein-fifo-spill-mem-range = <0x00000000 0x0fe00000 0x00000000 0x00100000>; // 1MB @ 254MB
+                freein-fifo-shared = <0>;
+                freein-fifo-onchip-num-descs = <56>; 
+                freein-fifo-spill-num-descs = <1200>;
+        };
+
+	// VFBID MAP: Upto 127 entries
+	// (each entry is a pair of (vfbid , dest-vc)
+	// Legal range: (vfbid (0 - 126), dest-vc (0 - 4095))
+	vfbid-config {
+		vfbid-map = <
+		      0    1    1    5    2   9    3    13
+                      4    17   5    21   6   25   7    29
+                      8    33   9    37   10  41   11   45
+                      12   49   13   53   14  57   15   61
+                      16   65   17   69   18  73   19   77
+                      20   81   21   85   22  89   23   93
+                      24   97   25  101   26 105   27  109
+                      28  113   29  117   30 121   31  125
+                >;
+	};
+
+	// Packet Ordering Engine (POE)
+	poe {	
+	
+		mode = "bypass";
+
+                distribution-enable = <1>;
+                // 16 bit mask
+                dist-drop-enable = <0>;
+                // 8 bit mask
+                class-drop-enable = <0>;
+                drop-timer = <0>;
+                dest-threshold = <0xa>;
+                dist-threshold = <0xa 0xa 0xa 0xa>;
+                statistics-enable = <0>;
+
+		// Each vector is 512 bit with masb indicating vc 512 and lsb indicating vc 0
+		// Format : 512-bit-vector is specified as 16 32-bit words
+		// Left most word has the vc range 511-479 right most word has vc range 31 - 0
+		// Each word has the MSB select higer vc number and LSB select lower vc num
+                distribution_vectors {
+                                     dv0  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0x1>;
+                                     dv1  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv2  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv3  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv4  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv5  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv6  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv7  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv8  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv9  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv10 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv11 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv12 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv13 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv14 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv15 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                };
+	};
+
+	complex@0 {
+		device_type = "nae-complex";
+		mode = "xaui";
+		xaui {
+			loopback = <0>;
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <55>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			parser-sequence-fifo-size = <225>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels 
+			num-channels = <1>;
+			rx-buffer-size = <944>;
+
+			// Max available descriptors are 1024  (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <150>;
+			free-desc-size = <2048>;
+			// In xlp3xx number of ucores available is 8. so, ucore_mask for xlp3xx is (ucore-mask & 0xFF)
+			ucore-mask = <0xffff>;
+		};
+		sgmii {
+	                loopback = <0 0 0 0>;
+			mgmt-port = <0 0 0 0>;
+        	        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                	iface-fifo-size = <13 13 13 13>;
+
+	                ext-phy-addr = <4 7 6 5>;
+        	        ext-phy-bus = <1 1 1 1>;
+
+	                // Max parser sequence fifo size 1024 packets
+        	        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                	num-channels = <1 1 1 1>;
+	                parser-sequence-fifo-size = <62 62 62 62>;
+
+        	        rx-buffer-size = <128 128 128 128>;
+
+                	// Max available descriptors are 1024 (across all complexes).
+	                // Per port num_free_descriptors must be even number
+        	        num-free-descs = <52 52 52 52>;
+                	free-desc-size = <2048 2048 2048 2048>;
+	                ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+		};
+                interlaken {
+                        //select daughter board : cortina or loopback
+                        db = "cortina";
+
+                        loopback = <0>;
+
+                        // Maximum number of lanes per interface = 8 (from 2 complexes)
+                        num-lanes = <4>;
+                        // lanerate 0 = 3.125Gbps , 1 = 6.25Gbps
+                        lane-rate = <0>;
+
+                        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                        iface-fifo-size = <110>;
+
+                        // Max parser sequence fifo size 1024 packets
+                        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                        parser-sequence-fifo-size = <225>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+                        num-channels = <4>;
+                        rx-buffer-size = <1840>;
+
+                        // Max available descriptors are 1024  (across all complexes).
+                        // Per port num_free_descriptors must be even number
+                        num-free-descs = <300>;
+                        free-desc-size = <2048>;
+                        ucore-mask = <0xffff>;
+                };
+
+	};
+	complex@1 {
+		device_type = "nae-complex";
+		mode = "xaui";
+		xaui {
+			loopback = <0>;
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <55>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			parser-sequence-fifo-size = <225>;
+			
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			num-channels = <1>;
+			rx-buffer-size = <944>;
+	
+			// Max available descriptors are 1024  (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <150>;
+			free-desc-size = <2048>;
+			ucore-mask = <0xffff>;
+		};
+		sgmii {
+	                loopback = <0 0 0 0>;
+
+	                // Max ingress fifo size 256 units (size of one unit is 64 byte)
+        	        iface-fifo-size = <13 13 13 13>;
+
+                	ext-phy-addr = <8 11 10 9>;
+	                ext-phy-bus = <1 1 1 1>;
+
+        	        // Max parser sequence fifo size 1024 packets
+                	// (if 1588 Timestamp is not required, then max size increases to 2048)
+	                num-channels = <1 1 1 1>;
+        	        parser-sequence-fifo-size = <62 62 62 62>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+        	        rx-buffer-size = <128 128 128 128>;
+
+
+                	// Max available descriptors are 1024 (across all complexes).
+	                // Per port num_free_descriptors must be even number
+        	        num-free-descs = <52 52 52 52>;
+                	free-desc-size = <2048 2048 2048 2048>;
+	                ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+		};
+
+	};
+	complex@2 {
+		device_type = "nae-complex";
+		mode = "xaui";
+
+                xaui {
+                        loopback = <0>;
+
+                        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                        iface-fifo-size = <55>;
+
+                        // Max parser sequence fifo size 1024 packets
+                        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                        parser-sequence-fifo-size = <225>;
+			
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+                        num-channels = <1>;
+                        rx-buffer-size = <944>;
+
+                        // Max available descriptors are 1024  (across all complexes).
+                        // Per port num_free_descriptors must be even number
+                        num-free-descs = <150>;
+                        free-desc-size = <2048>;
+                        ucore-mask = <0xffff>;
+                };
+
+		interlaken {
+	                //select daughter board : cortina or loopback
+        	        db = "cortina";
+
+                	loopback = <0>;
+
+	                // Maximum number of lanes per interface = 8 (from 2 complexes)
+        	        num-lanes = <4>;
+                	// lanerate 0 = 3.125Gbps , 1 = 6.25Gbps
+	                lane-rate = <0>;
+	
+        	        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                	iface-fifo-size = <110>;
+
+	                // Max parser sequence fifo size 1024 packets
+        	        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                	parser-sequence-fifo-size = <225>;
+			
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+                	num-channels = <4>;
+	                rx-buffer-size = <1840>;
+
+	                // Max available descriptors are 1024  (across all complexes).
+        	        // Per port num_free_descriptors must be even number
+                	num-free-descs = <300>;
+	                free-desc-size = <2048>;
+        	        ucore-mask = <0xffff>;
 		};
+		sgmii {
+        	        loopback = <0 0 0 0>;
+
+                	// Max ingress fifo size 256 units (size of one unit is 64 byte)
+	                iface-fifo-size = <13 13 13 13>;
+
+        	        ext-phy-addr = <0 3 2 1>;
+                	ext-phy-bus = <1 1 1 1>;
+
+	                // Max parser sequence fifo size 1024 packets
+        	        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                	num-channels = <1 1 1 1>;
+	                parser-sequence-fifo-size = <62 62 62 62>;
 
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+	                rx-buffer-size = <128 128 128 128>;
+
+
+        	        // Max available descriptors are 1024 (across all complexes).
+                	// Per port num_free_descriptors must be even number
+	                num-free-descs = <52 52 52 52>;
+        	        free-desc-size = <2048 2048 2048 2048>;
+                	ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+		};
+	};
+	complex@3 {
+		device_type = "nae-complex";
+		mode = "xaui";
+		xaui {
+			loopback = <0>;
+
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <55>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			parser-sequence-fifo-size = <225>;
+	
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			num-channels = <1>;
+			rx-buffer-size = <944>;
+
+			// Max available descriptors are 1024  (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <150>;
+			free-desc-size = <2048>;
+			ucore-mask = <0xffff>;
+		};
+                sgmii {
+                        loopback = <0 0 0 0>;
+
+                        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                        iface-fifo-size = <13 13 13 13>;
+
+                        ext-phy-addr = <12 15 14 13>;
+                        ext-phy-bus = <1 1 1 1>;
+
+                        // Max parser sequence fifo size 1024 packets
+                        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                        num-channels = <1 1 1 1>;
+                        parser-sequence-fifo-size = <62 62 62 62>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+                        rx-buffer-size = <128 128 128 128>;
+
+
+                        // Max available descriptors are 1024 (across all complexes).
+                        // Per port num_free_descriptors must be even number
+                        num-free-descs = <52 52 52 52>;
+                        free-desc-size = <2048 2048 2048 2048>;
+                        ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+                };
+	};
+	complex@4 {
+		device_type = "nae-complex";
+		mode = "sgmii";
+
+		sgmii {
+			loopback = <0 0>;
+	
+			mgmt-port = <1 0>;
+
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <13 13>;
+                
+			ext-phy-addr = <16 17>;
+        	        ext-phy-bus = <0 0>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			num-channels = <1 1>;
+			parser-sequence-fifo-size = <62 62>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			rx-buffer-size = <128 128>;
+				   
+
+			// Max available descriptors are 1024 (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <52 52>;
+			free-desc-size = <2048 2048>;
+			ucore-mask = <0xffff 0xffff>;
+		};
 	};
 };
+   nae@node-1 {
+	model = "MIPS,XLP8XX NAE CFG";
+	compatible = "NETL,XLP8XX_A0";
+	#address-cells = <1>;
+	#size-cells = <1>;
+	frequency = <500>;
+
+	/include/ "ucore-8xx.dts"
+
+        freein-fifo-config {
+                /* If shared is true,
+                        1. Ucore is going to use upto max queues(16 for XLP, 8 for storm) for buffer mgmt
+                        2. Onnchip desc size per queue, same value will be configured for all the queues.
+                   If shared is false,
+                        1. Onchip desc size per queue will be configured using num_free_desc specified at the port level.
+                   If spill descs per queue is specified,
+                        1. spill will be enabled for all the queues(except mgmt) using the spill memory specified in the OS config file.
+                */
+
+                freein-fifo-shared = <0>;
+                freein-fifo-onchip-num-descs = <0>;
+                freein-fifo-spill-num-descs = <0>;
+        };
+
+	// VFBID MAP: Upto 127 entries
+	// (each entry is a pair of (vfbid , dest-vc)
+	// Legal range: (vfbid (0 - 126), dest-vc (0 - 4095))
+	vfbid-config {
+		hw-replenish = <0>;
+	};
+
+	// Packet Ordering Engine (POE)
+	poe {	
+	
+		mode = "bypass";
+
+		// Each vector is 512 bit with masb indicating vc 512 and lsb indicating vc 0
+		// Format : 512-bit-vector is specified as 16 32-bit words
+		// Left most word has the vc range 511-479 right most word has vc range 31 - 0
+		// Each word has the MSB select higer vc number and LSB select lower vc num
+		
+		distribution-enable = <1>;
+		// 16 bit mask
+		dist-drop-enable = <0>;	 
+		// 8 bit mask
+		class-drop-enable = <0>;
+		drop-timer = <0>;
+		dest-threshold = <0xa>;
+		dist-threshold = <0xa 0xa 0xa 0xa>;
+		statistics-enable = <0>;
+ 
+                distribution_vectors {
+                                     dv0  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0x1>;
+                                     dv1  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv2  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv3  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv4  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv5  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv6  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv7  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv8  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv9  = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv10 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv11 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv12 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv13 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv14 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                                     dv15 = <0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0>;
+                };
+	};
+
+	complex@0 {
+		device_type = "nae-complex";
+		mode = "xaui";
+		xaui {
+			loopback = <0>;
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <55>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			parser-sequence-fifo-size = <225>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			num-channels = <1>;
+			rx-buffer-size = <944>;
+
+			// Max available descriptors are 1024  (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <150>;
+			free-desc-size = <2048>;
+			ucore-mask = <0xffff>;
+		};
+		sgmii {
+	                loopback = <0 0 0 0>;
+	
+        	        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                	iface-fifo-size = <13 13 13 13>;
+
+	                ext-phy-addr = <4 7 6 5>;
+        	        ext-phy-bus = <1 1 1 1>;
+
+	                // Max parser sequence fifo size 1024 packets
+        	        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                	num-channels = <1 1 1 1>;
+	                parser-sequence-fifo-size = <62 62 62 62>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+        	        rx-buffer-size = <128 128 128 128>;
+
+
+                	// Max available descriptors are 1024 (across all complexes).
+	                // Per port num_free_descriptors must be even number
+        	        num-free-descs = <52 52 52 52>;
+                	free-desc-size = <2048 2048 2048 2048>;
+	                ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+		};
+                interlaken {
+                        //select daughter board : cortina or loopback
+                        db = "cortina";
+
+                        loopback = <0>;
+
+                        // Maximum number of lanes per interface = 8 (from 2 complexes)
+                        num-lanes = <4>;
+                        // lanerate 0 = 3.125Gbps , 1 = 6.25Gbps
+                        lane-rate = <0>;
+
+                        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                        iface-fifo-size = <110>;
+
+                        // Max parser sequence fifo size 1024 packets
+                        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                        parser-sequence-fifo-size = <225>;
+
+                        // Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+                        num-channels = <4>;
+                        rx-buffer-size = <1840>;
+
+                        // Max available descriptors are 1024  (across all complexes).
+                        // Per port num_free_descriptors must be even number
+                        num-free-descs = <300>;
+                        free-desc-size = <2048>;
+                        ucore-mask = <0xffff>;
+                };
+	};
+	complex@1 {
+		device_type = "nae-complex";
+		mode = "xaui";
+		xaui {
+			loopback = <0>;
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <55>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			parser-sequence-fifo-size = <225>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			num-channels = <1>;
+			rx-buffer-size = <944>;
+	
+			// Max available descriptors are 1024  (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <150>;
+			free-desc-size = <2048>;
+			ucore-mask = <0xffff>;
+		};
+		sgmii {
+	                loopback = <0 0 0 0>;
+
+	                // Max ingress fifo size 256 units (size of one unit is 64 byte)
+        	        iface-fifo-size = <13 13 13 13>;
+
+                	ext-phy-addr = <8 11 10 9>;
+	                ext-phy-bus = <1 1 1 1>;
+
+        	        // Max parser sequence fifo size 1024 packets
+                	// (if 1588 Timestamp is not required, then max size increases to 2048)
+	                num-channels = <1 1 1 1>;
+        	        parser-sequence-fifo-size = <62 62 62 62>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+        	        rx-buffer-size = <128 128 128 128>;
+
+
+                	// Max available descriptors are 1024 (across all complexes).
+	                // Per port num_free_descriptors must be even number
+        	        num-free-descs = <52 52 52 52>;
+                	free-desc-size = <2048 2048 2048 2048>;
+	                ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+		};
+
+	};
+	complex@2 {
+		device_type = "nae-complex";
+		mode = "xaui";
+
+                xaui {
+                        loopback = <0>;
+
+                        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                        iface-fifo-size = <55>;
+
+                        // Max parser sequence fifo size 1024 packets
+                        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                        parser-sequence-fifo-size = <225>;
+
+                        num-channels = <1>;
+                        rx-buffer-size = <944>;
+
+                        // Max available descriptors are 1024  (across all complexes).
+                        // Per port num_free_descriptors must be even number
+                        num-free-descs = <150>;
+                        free-desc-size = <2048>;
+                        ucore-mask = <0xffff>;
+                };
+
+		interlaken {
+	                //select daughter board : cortina or loopback
+        	        db = "cortina";
+
+                	loopback = <0>;
+
+	                // Maximum number of lanes per interface = 8 (from 2 complexes)
+        	        num-lanes = <4>;
+                	// lanerate 0 = 3.125Gbps , 1 = 6.25Gbps
+	                lane-rate = <0>;
+	
+        	        // Max ingress fifo size 256 units (size of one unit is 64 byte)
+                	iface-fifo-size = <110>;
+
+	                // Max parser sequence fifo size 1024 packets
+        	        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                	parser-sequence-fifo-size = <225>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+                	num-channels = <4>;
+	                rx-buffer-size = <1840>;
+
+	                // Max available descriptors are 1024  (across all complexes).
+        	        // Per port num_free_descriptors must be even number
+                	num-free-descs = <300>;
+	                free-desc-size = <2048>;
+        	        ucore-mask = <0xffff>;
+		};
+		sgmii {
+        	        loopback = <0 0 0 0>;
+
+                	// Max ingress fifo size 256 units (size of one unit is 64 byte)
+	                iface-fifo-size = <13 13 13 13>;
+
+        	        ext-phy-addr = <0 3 2 1>;
+                	ext-phy-bus = <1 1 1 1>;
+
+	                // Max parser sequence fifo size 1024 packets
+        	        // (if 1588 Timestamp is not required, then max size increases to 2048)
+                	num-channels = <1 1 1 1>;
+	                parser-sequence-fifo-size = <62 62 62 62>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+	                rx-buffer-size = <128 128 128 128>;
+
+
+        	        // Max available descriptors are 1024 (across all complexes).
+                	// Per port num_free_descriptors must be even number
+	                num-free-descs = <52 52 52 52>;
+        	        free-desc-size = <2048 2048 2048 2048>;
+                	ucore-mask = <0xffff 0xffff 0xffff 0xffff>;
+		};
+	};
+	complex@3 {
+		device_type = "nae-complex";
+		mode = "xaui";
+		xaui {
+			loopback = <0>;
+
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <55>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			parser-sequence-fifo-size = <225>;
+
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			num-channels = <1>;
+			rx-buffer-size = <944>;
+
+			// Max available descriptors are 1024  (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <150>;
+			free-desc-size = <2048>;
+			ucore-mask = <0xffff>;
+		};
+	};
+	complex@4 {
+		device_type = "nae-complex";
+		mode = "sgmii";
+
+		sgmii {
+			loopback = <0 0>;
+			mgmt-port = <1 0>;
+			// Max ingress fifo size 256 units (size of one unit is 64 byte)
+			iface-fifo-size = <13 13>;
+ 		               
+			ext-phy-addr = <16 17>;
+        	        ext-phy-bus = <0 0>;
+
+			// Max parser sequence fifo size 1024 packets 
+			// (if 1588 Timestamp is not required, then max size increases to 2048)
+			num-channels = <1 1>;
+			parser-sequence-fifo-size = <62 62>;
+	
+			// Since rx_buffer is per context, the buffer size given here will be divided by num-channels
+			rx-buffer-size = <128 128>;
+				   
+
+			// Max available descriptors are 1024 (across all complexes).
+			// Per port num_free_descriptors must be even number
+			num-free-descs = <52 52>;
+			free-desc-size = <2048 2048>;
+			ucore-mask = <0xffff 0xffff>;
+		};
+	};
+};
+nae@node-2 {
+
+};
+nae@node-3 {
+
+};
+
+	};
+};
+
diff --git a/arch/mips/include/asm/mach-netlogic/mmzone.h b/arch/mips/include/asm/mach-netlogic/mmzone.h
new file mode 100644
index 0000000..c494729
--- /dev/null
+++ b/arch/mips/include/asm/mach-netlogic/mmzone.h
@@ -0,0 +1,80 @@
+#ifndef _ASM_MACH_MMZONE_H
+#define _ASM_MACH_MMZONE_H
+
+#if defined(CONFIG_NEED_MULTIPLE_NODES) && defined(CONFIG_NUMA)
+
+#include <linux/cpumask.h>
+
+#ifndef NLM_MAX_CPU_NODE
+#define NLM_MAX_CPU_NODE	4
+#endif
+
+struct nlm_mem_info {
+	unsigned long low_pfn;
+	unsigned long high_pfn;
+	unsigned long map_pfn;
+	unsigned long bootmem_size;
+};
+struct nlm_node_mem_frag {
+	unsigned long start_pfn;
+	unsigned long end_pfn;
+};
+
+#define NLM_MAX_MEM_FRAGS_PER_NODE 16
+struct nlm_node_mem_info {
+	struct nlm_node_mem_frag mem[NLM_MAX_MEM_FRAGS_PER_NODE];
+	unsigned long free_addr; /* for node_data */
+	int frags;
+};
+
+struct nlm_cpu_info {
+	struct cpumask mask;
+};
+
+extern struct nlm_mem_info __node_mem_data[];
+
+struct nlm_node_data {
+	struct pglist_data pg_data;
+	struct nlm_cpu_info cpu;
+};
+
+extern struct nlm_node_data *__node_data[];
+
+#define NODE_DATA(nid)		(&__node_data[nid]->pg_data)
+#define NODE_CPU_MASK(nid)	(&__node_data[nid]->cpu.mask)
+#define NODE_MEM_DATA(nid)	(&__node_mem_data[nid])
+
+extern int nlm_get_node(unsigned long pfn);
+
+static inline unsigned int pa_to_nid(unsigned long addr)
+{
+	unsigned int  i;
+	unsigned long pfn = addr >> PAGE_SHIFT;
+
+	/* TODO: Implement this using NODE_DATA */
+	for (i = 0; i < NLM_MAX_CPU_NODE; i++) {
+
+		if ((!node_online(i)) || ((NODE_MEM_DATA(i)->low_pfn == 0) && (NODE_MEM_DATA(i)->high_pfn == 0)))
+			continue;
+
+		if (pfn >= NODE_MEM_DATA(i)->low_pfn && pfn <= NODE_MEM_DATA(i)->high_pfn)
+			return i;
+	}
+
+	/* special case: get node ID from dram_map info */
+	if (addr == 0)
+	{
+		i = nlm_get_node(pfn);
+		// printk("** special case: returning node %d.\n", i);
+		return i;
+	}
+
+	/* it should not really reach here */
+	printk("Invalid address is %lx\n", addr);
+	panic("Invalid address in pa_to_nid\n");
+	return 0;
+}
+
+#endif
+
+#endif /* _ASM_MACH_MMZONE_H */
diff --git a/arch/mips/include/asm/mach-netlogic/topology.h b/arch/mips/include/asm/mach-netlogic/topology.h
new file mode 100644
index 0000000..56e66ab
--- /dev/null
+++ b/arch/mips/include/asm/mach-netlogic/topology.h
@@ -0,0 +1,44 @@
+#ifndef _ASM_MACH_TOPOLOGY_H
+#define _ASM_MACH_TOPOLOGY_H
+
+#ifdef CONFIG_NUMA
+
+#include <asm/mmzone.h>
+
+/* FIXME_XLP: only works for all cpus up */
+#define cpu_to_node(cpu)	(cpu >> 5)
+#define hardcpu_to_node(cpu)	(cpu >> 5)
+
+#define cpumask_of_node(node)	(NODE_CPU_MASK(node))
+
+#define parent_node(node)	(node)
+
+#ifdef CONFIG_PCI
+#define cpumask_of_pcibus(bus)  (cpu_online_mask)
+/* FIXME_XLP: to be implemented */
+#define pcibus_to_node(bus)     (0)
+#endif
+
+/* sched_domains SD_NODE_INIT for multi-node XLP machines */
+/* FIXME_XLP: the number needs to be fine tuned later */
+#define SD_NODE_INIT (struct sched_domain) {		\
+	.parent			= NULL,			\
+	.child			= NULL,			\
+	.groups			= NULL,			\
+	.min_interval		= 8,			\
+	.max_interval		= 32,			\
+	.busy_factor		= 32,			\
+	.imbalance_pct		= 125,			\
+	.cache_nice_tries	= 1,			\
+	.flags			= SD_LOAD_BALANCE |	\
+				  SD_BALANCE_EXEC,	\
+	.last_balance		= jiffies,		\
+	.balance_interval	= 1,			\
+	.nr_balance_failed	= 0,			\
+}
+
+#endif
+
+#include <asm-generic/topology.h>
+
+#endif /* _ASM_MACH_TOPOLOGY_H */
diff --git a/arch/mips/include/asm/netlogic/config_net.h b/arch/mips/include/asm/netlogic/config_net.h
new file mode 100644
index 0000000..ddced35
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/config_net.h
@@ -0,0 +1,108 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _ASM_NLM_NET_H
+#define _ASM_NLM_NET_H
+
+#include <asm/netlogic/msgring.h>
+
+#define NETLOGIC_MAX_GMACS 8
+#define NETLOGIC_MAX_XGMACS 2
+#define NETLOGIC_MAX_XAUIS 2
+
+#define NETLOGIC_GMAC_PORTS_PER_CTRL 4
+
+#define NETLOGIC_MAX_MACS (NETLOGIC_MAX_GMACS + NETLOGIC_MAX_XGMACS)
+
+enum config_flags { NLM_PORT_INIT = 1, 
+					NLM_PORT_ATTACH = 2, 
+					NLM_INT_ATTACH = 4, 
+					NLM_MSGRNG_OWN = 8, 
+					NLM_PORT_EN = 0x10 };
+
+#define PORT_OWN_LINUX  ( NLM_PORT_INIT | NLM_PORT_ATTACH | NLM_INT_ATTACH | NLM_MSGRNG_OWN | NLM_PORT_EN )
+
+/* 	PORT_INIT  : GMAC/XGMAC IP initialization will be done. 
+	Port will be disabled after the initialization. 
+	Glue logic(spill, packet descriptors will not be initialized 
+
+	PORT_ATTACH : Eth interface will be attached to Linux 
+
+	INT_ATTACH : GMAC/XGMAC MDIO interrupt will be attached to Linux
+
+	MSGRNG_OWN : Glue logic(spill, packet descriptors will be initialized by linux
+
+	PORT_EN : Option to enable the port
+*/
+
+
+struct port_cfg {
+	/* port number */
+	int instance;
+
+	/* See enum config_flags */
+	uint32_t cfg_flag;
+
+	/* Interrupt Request number */
+	int irqno; 
+
+	/* number of descriptors configured */
+	int num_desc; 
+
+	/* pointer to the bucket config */
+	bucket_t *bucket;
+
+	/* pointer to the credit config */
+	struct stn_cc *credit;
+
+	/* driver should configure the pde */
+	int config_pde;
+
+	unsigned long mmio_addr; /* config address */
+	uint32_t phy_addr; /* phy id */
+	int phy_mode; /* sgmii or rgmii */
+	unsigned long mii_addr; /* mdio addr */
+	unsigned long pcs_addr; /* only for sgmii ports */
+	unsigned long serdes_addr; /* only for sgmii ports */
+};
+
+struct net_device_cfg {
+	struct port_cfg gmac_port[NETLOGIC_MAX_GMACS];
+	int xgs_type[NETLOGIC_MAX_XGMACS];
+	struct port_cfg xgs_port[NETLOGIC_MAX_XGMACS];
+};
+
+
+enum net_types { TYPE_GMAC = 0, TYPE_XGMAC, TYPE_SPI4, MAX_NET_TYPES };
+enum phy_modes { PHY_MODE_SGMII	= 1, PHY_MODE_RGMII = 2, 
+    PHY_MODE_SELECTABLE = 4, PHY_MODE_XAUI=8};
+
+#define PORT_INIT(x) (x & NLM_PORT_INIT)
+#define PORT_ATTACH(x) (x & NLM_PORT_ATTACH)
+#define PORT_INT_ATTACH(x) (x & NLM_INT_ATTACH)
+#define MSGRNG_OWN(x) (x & NLM_MSGRNG_OWN)
+#define PORT_EN(x) (x & NLM_PORT_EN)
+
+#endif
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_evp_cpld.h b/arch/mips/include/asm/netlogic/hal/nlm_evp_cpld.h
new file mode 100644
index 0000000..74953bd
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/hal/nlm_evp_cpld.h
@@ -0,0 +1,39 @@
+#ifndef __NLM_CPLD_H__
+#define __NLM_CPLD_H__
+
+#ifdef NLM_HAL_LINUX_KERNEL
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <asm/netlogic/hal/nlm_hal.h>
+#else
+#include "nlm_hal.h"
+#endif
+
+#define CORTINA_ILK1_BASE	0x17100000
+#define CORTINA_ILK2_BASE       0x17200000
+	
+#define NLM_XLP_MAX_CS  7
+
+typedef struct {
+        uint32_t        base;
+        uint32_t        size;
+        uint32_t        swap;
+        uint32_t        devparam;
+}nlm_xlp_nor_t;
+
+#define SWAB16(x)       ((uint16_t)((((uint16_t)x & (uint16_t)0x00FFU) << 8) |  \
+                        (((uint16_t)x & (uint16_t)0xFF00U) >> 8)))
+
+#define SIZE_16MB       (0x1000000)
+#define SIZE_1MB        (0x100000)
+
+#define DC_ILK          0
+#define DC_SGMII        1
+#define DC_XAUI         2
+#define DC_NOT_PRSNT    3
+
+#define DC_TYPE(val,slot)       ((val >> (slot * 2)) & 0x3)
+#define EVP_VER(val)            (val & 0x8)
+
+#endif
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal.h b/arch/mips/include/asm/netlogic/hal/nlm_hal.h
index ac3b00e..6a395a4 100644
--- a/arch/mips/include/asm/netlogic/hal/nlm_hal.h
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal.h
@@ -1,5 +1,5 @@
 /***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
 reserved.
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are
@@ -28,9 +28,43 @@ THE POSSIBILITY OF SUCH DAMAGE.
 
 #include "nlm_hal_macros.h"
 #include "nlm_hal_xlp_dev.h"
-
+#include "nlm_nae.h"
 #ifndef __ASSEMBLY__
+
+struct nlm_netl_proc_info{
+	unsigned int proc_id;
+	int revision;
+	char cpu_info_str[32];
+};
+
+/**
+* @brief Used by function ::get_phy_info and various internal PHY manufacturer-specific functions. 
+* @ingroup hal
+*/
+struct nlm_hal_ext_phy{
+        char name[16];
+        uint32_t phy_idfer;
+        uint32_t ext_mdio_bus;
+        int inf;
+        int phy_addr;
+        int (*phy_get_status)(struct nlm_hal_ext_phy* ext_phy, uint32_t *speed, uint32_t *duplex, int node);
+        void (*start_phy_an)(struct nlm_hal_ext_phy* ext_phy, int node);
+        void (*ext_phy_init)(struct nlm_hal_ext_phy* ext_phy, int node);
+        //(void) (*dump_regs)(void);
+};
+
 extern void nlm_hal_init(void);
+extern int is_nlm_xlpxxx(void);
+extern int is_nlm_xlp8xx(void);
+extern int is_nlm_xlp8xx_b0(void);
+extern int is_nlm_xlp3xx(void);
+extern int is_nlm_xlp316(void);
+extern int is_nlm_xlp308(void);
+extern int is_nlm_xlp304(void);
+extern int is_nlm_xlp8xx_b0(void);
+extern int is_nlm_xlp832_ax(void);
+extern int is_nlm_xlp8xx_ax(void);
+
 extern unsigned long long nlm_hal_cpu_freq(void);
 extern int naecfg_hack;
 
@@ -38,20 +72,59 @@ extern int nlm_hal_is_xlp_a0(void);
 extern int nlm_hal_is_xlp_le(void);
 extern void nlm_hal_xlp_pcie_rc_init(void);
 
+extern void nlm_hal_cpld_init(int node);
+extern int nlm_get_interface_type(int node, int slot);
+extern int is_ilk_card_onslot(int);
+extern int is_xlp_evp1(void);
+extern int is_xlp_evp2(void);
+extern int nlm_xlp_boardver(void);
+extern int nlm_xlp_cpldver(void);
+extern void sgmii_scan_phys(int node);
+
 #ifndef NLM_HAL_LINUX_KERNEL
-extern void enable_cpus(unsigned long thread_bitmask, unsigned long park_func); 
+extern void enable_cpus(unsigned int node, unsigned long thread_bitmask, unsigned long park_func); 
 #endif /* #ifndef NLM_HAL_LINUX_KERNEL */
 
+#ifdef NLM_HAL_XLOADER
+#define nlm_hal_read_16bit_reg(base, index)	(uint16_t)(nlh_read_cfg_reg16(base + (index << 1)))
+#define nlm_hal_write_16bit_reg(base, index, val)	(nlh_write_cfg_reg16(base +  (index << 1) , val))
+#define nlm_hal_read_32bit_reg(base, index)	(uint32_t)(nlh_read_cfg_reg32(base + (index << 2)))
+#define nlm_hal_write_32bit_reg(base, index, val)	(nlh_write_cfg_reg32(base +  (index << 2) , val))
+#define nlm_hal_read_64bit_reg(base, index) (uint64_t)(nlh_read_cfg_reg64(base + (index << 3)))
+#define nlm_hal_write_64bit_reg(base, index, val) 	(nlh_write_cfg_reg64(base +  (index << 3) , val))
+
+#else
+
+extern uint16_t nlm_hal_read_16bit_reg(uint64_t base, uint32_t index);
+extern void nlm_hal_write_16bit_reg(uint64_t base, uint32_t index, uint16_t val);
 extern uint32_t nlm_hal_read_32bit_reg(uint64_t base, int index);
 extern void nlm_hal_write_32bit_reg(uint64_t base, int index, uint32_t val);
 extern uint64_t nlm_hal_read_64bit_reg(uint64_t base, int index);
 extern void nlm_hal_write_64bit_reg(uint64_t base, int index, uint64_t val);
 
+#endif /*NLM_HAL_XLOADER*/
+
+extern void nlm_hal_cpld_write_16(int cs, uint16_t val, uint16_t reg);
+extern uint16_t nlm_hal_cpld_read_16(int cs, uint16_t reg);
+
+extern uint32_t efuse_cfg0(void);
+extern uint32_t efuse_cfg1(void);
+extern uint32_t efuse_cfg6(void);
+extern uint32_t get_proc_id(void);
+
+extern void nlm_hal_set_sae_engine_sel(void);
+extern void nlm_hal_set_rsa_engine_sel(void);
+extern void nlm_hal_set_sae_freq(int node, int freq);
+extern void nlm_hal_get_crypto_vc_nums(int *vcbase, int *vclimit);
+extern void nlm_hal_get_rsa_vc_nums(int *vcbase, int *vclimit);
+
 #define nlh_read_dev_reg(dev, index) nlm_hal_read_32bit_reg(nlm_hal_get_dev_base(dev), index)
 #define nlh_write_dev_reg(dev, index, val) nlm_hal_write_32bit_reg(nlm_hal_get_dev_base(dev), index, val)
 
 extern uint64_t nlm_hal_get_dev_base(int node, int bus, int dev, int func);
 
+extern int nlm_hal_get_cpuinfo(struct nlm_netl_proc_info *);
+
 /* 
 TODO :
   1. support Debug flags
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h
index a3f14a4..602e1eb 100644
--- a/arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h
@@ -1,5 +1,5 @@
 /***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
 reserved.
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are
@@ -52,6 +52,33 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #define xlp_load_tx_msg2(value) _write_64bit_cp2_register_sel(XLP_TX_BUF_REG, value, 2)
 #define xlp_load_tx_msg3(value) _write_64bit_cp2_register_sel(XLP_TX_BUF_REG, value, 3)
 
+#define XLP_FMN_DEFAULT_QUEUE_SIZE 	16384 //16K
+#define XLP_FMN_DEFAULT_CREDITS    	50
+#define XLP_FMNQ_SPILL_DEFAULT_MEM_ADDR (256ULL << 20)
+#define XLP_FMNQ_SPILL_DEFAULT_MEM_SIZE (32ULL << 20)
+
+#define FMN_MAX_Q_SIZE (256ULL * 1024)
+#define FMN_Q_PAGE_SIZE (4ULL * 1024)
+
+enum FMN_MSG_BLKS {
+	XLP_MSG_BLK_CPU = 0, 
+	XLP_MSG_BLK_POPQ, 
+        XLP_MSG_BLK_PCIE0,
+        XLP_MSG_BLK_PCIE1,
+        XLP_MSG_BLK_PCIE2,
+        XLP_MSG_BLK_PCIE3,
+	XLP_MSG_BLK_GDX,
+	XLP_MSG_BLK_RSA_ECC,
+	XLP_MSG_BLK_CRYPTO,
+	XLP_MSG_BLK_CMP,
+	XLP_MSG_BLK_POE,
+	XLP_MSG_BLK_NAE,
+	XLP_MSG_BLK_REGX,
+	XLP_MSG_BLK_SRIO,
+	XLP_MSG_BLK_MAX
+};
+
+
 enum LVL_INT_TYPES {
 	LVL_INT_DISABLE,
 	LVL_INT_LOW_WM,
@@ -85,11 +112,39 @@ enum XLP_REGS{
   XLP_INTERCHIP_LINK_CONFIG_REG,
   XLP_ERROR_REG
 };
+
+struct fmn_qsize_credit_config
+{
+        char q_name[16]; /* fmn station type*/
+        int b_stid; /* base stations */
+        int e_stid; /* end stations */
+        int n_txstns; /* number of tranmit stations from this type, only used for credit warn */
+        int valid;
+        int q_size; /* queue size for this type */
+        unsigned int credits[NLM_MAX_NODES][XLP_MSG_BLK_MAX];
+};
+
+struct fmn_cfg {
+        uint64_t fmn_spill_base;
+        uint64_t fmn_spill_size;
+        uint32_t fmn_default_qsize;
+        uint32_t fmn_default_credits;
+        uint32_t max_msg_blk;
+        struct fmn_qsize_credit_config  fmn_q_config[XLP_MSG_BLK_MAX];
+        // onchi mem
+        uint64_t q_ram_base;
+        uint32_t q_ram_page_perq;
+        uint32_t q_ram_base_cur;
+
+        // spill mem
+        uint32_t spill_base_cur;
+};
+
 typedef volatile unsigned long long msg_reg_t;
 
-static inline unsigned long long nlh_qid_to_virt_addr(int reg, int sel)
+static inline unsigned long long nlh_qid_to_virt_addr(int node, int reg, int sel)
 {
-  unsigned long long base = xlp_fmn_base & 0xffffffc000ULL;
+  unsigned long long base = xlp_fmn_base[node] & 0xffffffc000ULL;
 
 #if 0 //defined(NLM_HAL_LINUX_USER)
   base |= NLH_XKPHYS_UNCACHED;
@@ -110,18 +165,30 @@ static inline unsigned long long nlh_qid_to_virt_addr(int reg, int sel)
   return 0;
 }
 //
-#define nlm_hal_read_outq_config(qid) \
-  nlh_read_cfg_reg64(nlh_qid_to_virt_addr(XLP_OUTQ_CONFIG_REG, qid))
 
-#define nlm_hal_write_outq_config(qid, val) \
-  nlh_write_cfg_reg64( nlh_qid_to_virt_addr(XLP_OUTQ_CONFIG_REG, qid), val)
+#define nlm_hal_read_outq_config(node, qid) \
+	nlh_read_cfg_reg64(nlh_qid_to_virt_addr(node, XLP_OUTQ_CONFIG_REG, qid))
 
-#define nlm_hal_read_credit(qid, src, dst) \
-    nlh_read_cfg_reg64(nlh_qid_to_virt_addr(XLP_CREDIT_CONFIG_REG, 0))
+#define nlm_hal_write_outq_config(node, qid, val) \
+	nlh_write_cfg_reg64(nlh_qid_to_virt_addr(node, XLP_OUTQ_CONFIG_REG, qid), val)
+
+#define nlm_hal_read_credit(node, qid, src, dst) \
+	nlh_read_cfg_reg64(nlh_qid_to_virt_addr(node, XLP_CREDIT_CONFIG_REG, 0))
 
 /*
  *  Messaging Operations 
  */
+/**
+* @brief xlp_send function is used to send any configured message to a destination, used by the HAL send message API's for different number of messages. Performs a sync before sending.
+*
+* @param [in]  dest 		:Destination Message Queue number
+*
+* @return
+*  - "1" on  send success, "0" on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline int xlp_send(unsigned int dest)
 {
         unsigned int success = 0;
@@ -149,6 +216,17 @@ static inline void xlp_receive(unsigned int pri)
 }
 #endif
 //
+/**
+* @brief xlp_message_wait function is a non-blocking API used to wait for the first message to come to a mailbox. 
+*
+* @param [in]  mask 		:bitmask of the 4 VC's of the CPU, for which queues to monitor for a message
+*
+* @return
+*  - none
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline void xlp_message_wait(unsigned int mask)
 {
     __asm__ volatile(".set push\n"
@@ -204,6 +282,19 @@ static __inline__ unsigned int xlp_cpu_to_bucket(int pid)
    RT[11 : 0]  - Message Destination ID
  */
 /* message send API NON blocking for single entry message*/
+/**
+* @brief xlp_message_send_1 function is a non-blocking API used to send a single entry message to a mailbox. Will retry the message send 16 times. Performs a sync before sending.
+*
+* @param [in]  dst		:Destination Message Queue number
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  data 		:64b data value for the single message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline int xlp_message_send_1(uint32_t dst, 
 				     uint32_t  code, uint64_t data)
 {
@@ -227,6 +318,20 @@ static inline int xlp_message_send_1(uint32_t dst,
 
 }
 /* message send API NON blocking for double entry message*/
+/**
+* @brief xlp_message_send_2 function is a non-blocking API used to send a two entry message to a mailbox. Will retry the message send 16 times. Performs a sync before sending.
+*
+* @param [in]  dst		:Destination Message Queue number
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  data0 		:64b data value for the first message
+* @param [in]  data1 		:64b data value for the second message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline int xlp_message_send_2(uint32_t dst, 
 				     uint32_t  code,
 				     uint64_t data0, uint64_t data1)
@@ -251,6 +356,21 @@ static inline int xlp_message_send_2(uint32_t dst,
 }
 
 /* message send API NON blocking for double entry message*/
+/**
+* @brief xlp_message_send_3 function is a non-blocking API used to send a three entry message to a mailbox. Does not retry the send message. Performs a sync before sending.
+*
+* @param [in]  dst		:Destination Message Queue number
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  data0 		:64b data value for the first message
+* @param [in]  data1 		:64b data value for the second message
+* @param [in]  data2 		:64b data value for the third message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline int xlp_message_send_3(uint32_t dst, 
 				     uint32_t  code,
 				     uint64_t data0, uint64_t data1,
@@ -279,7 +399,22 @@ static inline int xlp_message_send_3(uint32_t dst,
   return 0;
 }
 
+
 /* Generic message send API NON blocking */
+/**
+* @brief xlp_message_send function is a non-blocking API for sending a one to four entry message to a mailbox.  Does not retry the send message. Performs a sync before sending.
+*
+* @param [in]  dst		:Destination Message Queue number
+* @param [in]  size		:Number of messages to transmit (1 to 4)
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  *data 		:uint64_t array of data[0] to data[3] representing each 64b message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline int xlp_message_send(uint32_t dst, 
 				   uint32_t size,  uint32_t  code,
 				   uint64_t *data)
@@ -311,6 +446,19 @@ static inline int xlp_message_send(uint32_t dst,
   return 0;
 }
 /* API to send a 1 entry message to "stid" with given "code" */
+/**
+* @brief xlp_message_send_block_fast_1 function is a blocking API for sending a one entry message to a mailbox.  It will continuously retry the send message until successful. Performs a sync before sending.
+*
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  dest_vc		:Destination Message Queue number
+* @param [in]  msg0 		:64b data value for the first message
+*
+* @return
+*  - none
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline void xlp_message_send_block_fast_1(unsigned int code, 
 						 unsigned int dest_vc,
 						 unsigned long long msg0)
@@ -335,6 +483,20 @@ static inline void xlp_message_send_block_fast_1(unsigned int code,
 }
 //
 /* API to send a 2 entry message to "stid" with given "code" */
+/**
+* @brief xlp_message_send_block_fast_2 function is a blocking API for sending a two entry message to a mailbox.  It will continuously retry the send message until successful. Performs a sync before sending.
+*
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  dest_vc		:Destination Message Queue number
+* @param [in]  msg0 		:64b data value for the first message
+* @param [in]  msg1 		:64b data value for the second message
+*
+* @return
+*  - none
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline void xlp_message_send_block_fast_2(unsigned int code, 
 						 unsigned int dest_vc,
 						 unsigned long long msg0,
@@ -360,6 +522,21 @@ static inline void xlp_message_send_block_fast_2(unsigned int code,
 			);
 }
 /* API to send a 3 entry message to "stid" with given "code" */
+/**
+* @brief xlp_message_send_block_fast_3 function is a blocking API for sending a three entry message to a mailbox.  It will continuously retry the send message until successful. Performs a sync before sending.
+*
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  dest_vc		:Destination Message Queue number
+* @param [in]  msg0 		:64b data value for the first message
+* @param [in]  msg1 		:64b data value for the second message
+* @param [in]  msg2 		:64b data value for the third message
+*
+* @return
+*  - none
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline void xlp_message_send_block_fast_3(unsigned int code, 
 						 unsigned int dest_vc,
 						 unsigned long long msg0,
@@ -387,6 +564,22 @@ static inline void xlp_message_send_block_fast_3(unsigned int code,
 			);
 }
 //
+/**
+* @brief xlp_message_send_block_fast_3 function is a blocking API for sending a four entry message to a mailbox.  It will continuously retry the send message until successful. Performs a sync before sending.
+*
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  dest_vc		:Destination Message Queue number
+* @param [in]  msg0 		:64b data value for the first message
+* @param [in]  msg1 		:64b data value for the second message
+* @param [in]  msg2 		:64b data value for the third message
+* @param [in]  msg3 		:64b data value for the fourth message
+*
+* @return
+*  - none
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline void xlp_message_send_block_fast(int size, unsigned int code,
 					       unsigned int dest_vc,
 					       unsigned long long msg0,
@@ -415,6 +608,17 @@ static inline void xlp_message_send_block_fast(int size, unsigned int code,
 			:"$8");
 }
 //
+/**
+* @brief xlp_receive function is used to receive message from a mailbox vc, used by the HAL receive message API's for different number of messages
+*
+* @param [in]  vc 		:VC mailbox of the CPU (1 to 4)
+*
+* @return
+*  - "1" on load success, "0" on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline int xlp_receive(unsigned int vc)
 {
 	unsigned int success = 0;
@@ -430,6 +634,21 @@ static inline int xlp_receive(unsigned int vc)
 	return success;
 }
 //
+/**
+* @brief xlp_message_receive_1 function is used to receive a single entry message from a VC of the CPU. Size should be used to determine how other 64b messages were available with data.
+*
+* @param [in]  vc 		:VC mailbox of the CPU (1 to 4)
+* @param [out]  src_id		:Source Message Queue Number
+* @param [out]  size		:# of messages returned (1 to 4)
+* @param [out]  code		:8b SW code of the received message
+* @param [out]  msg0 		:64b data value for the received message
+*
+* @return
+*  - "0" on receive success, "-1" on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline int xlp_message_receive_1(uint32_t vc, uint32_t *src_id,
 	uint32_t *size, uint32_t *code,	uint64_t *msg0)
 {
@@ -445,6 +664,22 @@ static inline int xlp_message_receive_1(uint32_t vc, uint32_t *src_id,
 	*msg0 = xlp_load_rx_msg0();
 	return 0;
 }
+/**
+* @brief xlp_message_receive_2 function is used to receive a single entry message from a VC of the CPU. Size should be used to determine how many of msg0-msg1 have valid data and if there were more messages available.
+*
+* @param [in]  vc 		:VC mailbox of the CPU (1 to 4)
+* @param [out]  src_id		:Source Message Queue Number
+* @param [out]  size		:# of messages that were in this received message (1 to 4)
+* @param [out]  code		:8b SW code of the received message
+* @param [out]  msg0 		:64b data value for the first received message
+* @param [out]  msg1 		:64b data value for the second received message
+*
+* @return
+*  - "0" on receive success, "-1" on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline int xlp_message_receive_2(uint32_t vc, uint32_t *src_id,
 	uint32_t *size, uint32_t *code, uint64_t *msg0, uint64_t *msg1)
 {
@@ -462,6 +697,24 @@ static inline int xlp_message_receive_2(uint32_t vc, uint32_t *src_id,
 	return 0;
 }
 //
+/**
+* @brief xlp_message_receive function is used to receive a four entry message from a VC of the CPU.  Size should be used to determine how many of msg0-msg3 have valid data.
+*
+* @param [in]  vc 		:VC mailbox of the CPU (1 to 4)
+* @param [out]  src_id		:Source Message Queue Number
+* @param [out]  size		:# of messages that were in this received message (1 to 4)
+* @param [out]  code		:8b SW code of the received message
+* @param [out]  msg0 		:64b data value for the first received message
+* @param [out]  msg1 		:64b data value for the second received message
+* @param [out]  msg2 		:64b data value for the third received message
+* @param [out]  msg3 		:64b data value for the fourth received message
+*
+* @return
+*  - "0" on receive success, "-1" on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline int xlp_message_receive(uint32_t vc, uint32_t *src_id,
 	uint32_t *size, uint32_t *code, uint64_t *msg0, uint64_t *msg1,
 	uint64_t *msg2, uint64_t *msg3)
@@ -499,6 +752,23 @@ static inline int xlp_message_pop_1(uint32_t vc, uint32_t src_id,
 //
 // Generic Messaging API
 //
+/**
+* @brief xlp_message_send_block function is a blocking API for sending a one to four entry message to a mailbox.  It will continuously retry the send message until successful. Performs a sync before sending.
+*
+* @param [in]  size		:# of 64b messages to be sent (1 to 4)
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  stid		:Destination Message Queue number
+* @param [in]  data0 		:64b data value for the first message
+* @param [in]  data1 		:64b data value for the second message, if size < 2 can be any value
+* @param [in]  data2 		:64b data value for the third message, if size < 3 can be any value
+* @param [in]  data3 		:64b data value for the fourth message, if size < 4 can be any value
+*
+* @return
+*  - none
+* 
+* @ingroup hal_fmn
+*
+*/
 static inline int xlp_message_send_block(unsigned int size, unsigned int code,
 					 unsigned int stid, uint64_t data0, uint64_t data1,
 					 uint64_t data2, uint64_t data3)
@@ -510,7 +780,7 @@ static inline int xlp_message_send_block(unsigned int size, unsigned int code,
 
 #endif				/* __ASSEMBLY__ */
 
-/* Returns the TxStatus reg */
+/* Returns the TxStatus reg, if unsuccessful, 0 if success */
 extern uint32_t nlm_hal_send_msg3(uint32_t dst, uint32_t code, uint64_t data0, uint64_t data1, uint64_t data2);
 extern uint32_t nlm_hal_send_msg2(uint32_t dst, uint32_t code, uint64_t data0, uint64_t data1);
 extern uint32_t nlm_hal_send_msg1(uint32_t dst, uint32_t code, uint64_t data0);
@@ -532,11 +802,12 @@ static __inline__ int fmn_level_int_val(uint64_t outq_config)
 	return xlp_get_field_dw(outq_config, 56, 3);
 }
 
-extern void nlm_hal_fmn_init(uint64_t spill_base, uint32_t size, uint32_t credit);
+extern void nlm_hal_fmn_init(void *fdt);
 extern void nlm_hal_set_fmn_interrupt(int irq);
 
-extern void nlm_hal_disable_vc_intr(int vc);
-extern void nlm_hal_enable_vc_intr(int vc);
+extern void nlm_hal_disable_vc_intr(int node, int vc);
+extern void nlm_hal_enable_vc_intr(int node, int vc);
 
 #endif /* #ifndef _NLH_FMN_H */
 
+	
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_macros.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_macros.h
index 9e2811b..7f6add6 100644
--- a/arch/mips/include/asm/netlogic/hal/nlm_hal_macros.h
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_macros.h
@@ -1,5 +1,5 @@
 /***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
 reserved.
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are
@@ -28,49 +28,20 @@ THE POSSIBILITY OF SUCH DAMAGE.
 
 #ifndef __ASSEMBLY__
 extern unsigned long xlp_io_base;
-extern unsigned long xlp_fmn_base;
-extern unsigned long xlp_nae_base;
-extern unsigned long xlp_mac_base;
-extern unsigned long xlp_poe_base_pcie;
-extern unsigned long xlp_poe_base_pcim;
-extern unsigned long xlp_sys_base;
+extern unsigned long xlp_fmn_base[];
+extern unsigned long xlp_nae_base[];
+extern unsigned long xlp_mac_base[];
+extern unsigned long xlp_poe_base_pcie[];
+extern unsigned long xlp_poe_base_pcim[];
+extern unsigned long xlp_sys_base[];
+
+extern int nlm_chip_is_xlp3xx;
+extern int is_nlm_xlp8xx(void);
+extern unsigned long xlp_regex_base_pcie;
+extern unsigned long xlp_regex_base_pcim;
 
 #endif /* #ifndef __ASSEMBLY__ */
 
-#define msgrng_enable(flags)                \
-do {                                        \
-  preempt_disable(); \
-  __asm__ volatile (                        \
-		    ".set push\n\t"                 \
-		    ".set reorder\n\t"              \
-		    ".set noat\n\t"                 \
-		    "mfc0 %0, $12\n\t"              \
-		    "li  $8, 0x40000001\n\t"        \
-		    "or  $1, %0, $8\n\t"            \
-		    "xori $1, 1\n\t"                \
-		    ".set noreorder\n\t"            \
-		    "mtc0 $1, $12\n\t"              \
-		    ".set\tpop\n\t"                 \
-		    : "=r" (flags)                  \
-		    :                               \
-		    : "$8"                          \
-		    );                              \
-  preempt_enable(); \
-} while (0)
-
-#define msgrng_disable(flags) __asm__ volatile (    \
-                 "mtc0 %0, $12" : : "r" (flags))
-
-#define msgrng_access_enable(mflags) do {   \
-  preempt_disable();                        \
-  msgrng_enable(mflags);                \
-} while(0)
-
-#define msgrng_access_disable(mflags) do {   \
-  msgrng_disable(mflags);              \
-  preempt_enable();                          \
-} while(0)
-
 
 #if defined(NLM_HAL_LINUX_USER) /* Linux User mode */
 
@@ -114,15 +85,34 @@ do {                                        \
 #include <linux/slab.h>
 
 #define nlm_print printk
-#define nlm_malloc(size) kzalloc((size), GFP_KERNEL)
+#define nlm_malloc(size) kmalloc((size), GFP_KERNEL)
 #define nlm_free  kfree
 
+static inline unsigned long nlm_spill_alloc(int node, uint64_t size)
+{
+        struct page *pg;
+        pg = alloc_pages_exact_node(node, GFP_KERNEL, get_order(size));
+	if (pg == NULL) {
+		nlm_print("Spill Mem allocation on node %d failed \n", node);
+		return 0;
+	}
+        return page_to_phys(pg);
+}
+
 #if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32) || \
     (_MIPS_SZLONG == 32)
+#ifndef KSEG0
 #define KSEG0     0x80000000UL
+#endif
+#ifndef KSEG1
 #define KSEG1     0xA0000000UL
+#endif
+#ifndef KSEG2
 #define KSEG2     0xC0000000UL
+#endif
+#ifndef KSEG3
 #define KSEG3     0xE0000000UL
+#endif
 #define KSEG0_PHY_BOUNDARY 0x10000000UL    // 256 MB
 #else
 #define KSEG0     (0xffffffff80000000ULL)
@@ -136,10 +126,6 @@ do {                                        \
 #define nlm_udelay(n)	udelay(n)
 #define nlm_mdelay(n)  	mdelay(n)
 
-extern int register_xlp_msgring_handler(int major,
-                             void (*action) (uint32_t, uint32_t, uint32_t, uint32_t,
-                                             uint64_t, uint64_t, uint64_t, uint64_t, void *),
-                             void *dev_id);
 #endif /* __ASSEMBLY__ */
 
 #elif defined(NLM_HAL_NETOS) /* Netos */
@@ -210,6 +196,14 @@ static __inline__ void _netos_delay(unsigned int x)
 #define KSEG0_PHY_BOUNDARY 0x10000000ULL    // 256 MB
 #endif
 
+#elif defined(NLM_HAL_XLOADER) /* x-loader */
+#include <common.h>
+#define KSEG0     0x80000000UL
+#define KSEG1     0xA0000000UL
+#define KSEG2     0xC0000000UL
+#define KSEG3     0xE0000000UL
+#define KSEG0_PHY_BOUNDARY 0x10000000UL    // 256 MB
+
 #elif defined(NLM_HAL_NETLBOOT) /* netlboot */
 #include <printk.h>
 
@@ -244,7 +238,11 @@ static __inline__ void _netos_delay(unsigned int x)
 /* XLP_MERGE_TODO */
 #define NLH_XKUSEG			0x0000000000000000
 #define NLH_XKSSEG			0x4000000000000000
-#define NLH_XKPHYS			0x8000000000000000
+#ifdef CONFIG_64BIT
+#define NLH_XKPHYS                      0x8000000000000000
+#else
+#define NLH_XKPHYS			0x8000000000000000ULL
+#endif
 #define NLH_XKPHYS_UNCACHED             0x9000000000000000ULL
 #define NLH_XKSEG			0xc000000000000000
 #define NLH_CKSEG0			0xffffffff80000000
@@ -256,7 +254,7 @@ static __inline__ void _netos_delay(unsigned int x)
 #define NLM_HAL_THREAD_SIZE (8 << 10)
 
 /* For hal internal debug */
-#define nlm_hal_dbg_msg(fmt, args...) {} /*printk(fmt, ##args)*/
+#define nlm_hal_dbg_msg(fmt, args...) printk(fmt, ##args)
 
 #ifndef __STR
 #define __STR(x) #x
@@ -269,6 +267,26 @@ static __inline__ void _netos_delay(unsigned int x)
 #define XLP_BIT_MASK_W(size) ((1 << (size)) - 1)
 #define XLP_BIT_MASK_DW(size) (((unsigned long long) 1 << size) - 1)
 
+#define enable_KX(flags)       \
+ __asm__ __volatile__ (        \
+        ".set push\n"          \
+        ".set noat\n"          \
+        ".set noreorder\n"     \
+        "mfc0 %0, $12\n\t"     \
+        "ori $1, %0, 0x81\n\t" \
+        "xori $1, 1\n\t"       \
+        "mtc0 $1, $12\n"       \
+        ".set pop\n"           \
+        : "=r"(flags) );
+
+#define disable_KX(flags)   \
+ __asm__ __volatile__ (     \
+        ".set push\n"       \
+        "mtc0 %0, $12\n"    \
+        ".set pop\n"        \
+        : : "r"(flags) )
+
+#ifdef CONFIG_64BIT
 static __inline__ uint8_t lb_40bit_phys(uint64_t phys, int cca)
 {
         uint8_t value = 0;
@@ -279,7 +297,8 @@ static __inline__ uint8_t lb_40bit_phys(uint64_t phys, int cca)
                              "dli   $8, " STR(NLH_XKPHYS) "\n"
                              "or    $8, $8, %2\n"
                              "daddu $8, $8, %1\n"
-                             "lb    %0, 0($8) \n" ".set pop\n":"=r"(value)
+                             "lb    %0, 0($8) \n" 
+			     ".set pop\n":"=r"(value)
                              :"r"(phys & 0xffffffffffULL),
                              "r"((uint64_t) cca << 59)
                              :"$8");
@@ -342,6 +361,147 @@ static __inline__ uint64_t ld_40bit_phys(uint64_t phys, int cca)
 
 	return value;
 }
+#else
+
+static __inline__ uint8_t lb_40bit_phys(uint64_t phys, int cca)
+{
+        uint8_t value = 0;
+        uint32_t low, high;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xffffffffffULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "lb %0, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :"=r"(value)
+                        :"r"(low), "r"(high)
+                        :"$1");
+
+        disable_KX(flags);
+
+        return value;
+}
+
+static __inline__ uint16_t lh_40bit_phys(uint64_t phys, int cca)
+{
+        uint16_t value = 0;
+        uint32_t low, high;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xfffffffffeULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "lhu %0, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :"=r"(value)
+                        :"r"(low), "r"(high)
+                        :"$1");
+
+        disable_KX(flags);
+
+        return value;
+}
+
+static __inline__ uint32_t lw_40bit_phys(uint64_t phys, int cca)
+{
+        uint32_t value = 0;
+        uint32_t low, high;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xfffffffffcULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "lw %0, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :"=r"(value)
+                        :"r"(low), "r"(high)
+                        :"$1");
+
+        disable_KX(flags);
+
+        return value;
+}
+
+static __inline__ uint64_t ld_40bit_phys(uint64_t phys, int cca)
+{
+        uint32_t lsw, msw, high, low;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xfffffffff8ULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low  = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %3, 0\n"
+                        "dsll32 %2, 0    \n"
+                        "dsrl32 %2, 0    \n"
+                        "or $1, $1, %2   \n"
+                        "ld $1, 0($1)    \n"
+                        "dsrl32 %1, $1 ,0\n"
+                        "dsll32 $1, $1 ,0\n"
+                        "dsrl32 %0, $1 ,0\n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :"=r"(lsw), "=r"(msw)
+                        :"r"(low),  "r"(high)
+                        :"$1");
+
+        disable_KX(flags);
+        return (((unsigned long long)msw << 32) | lsw);
+}
+
+#endif // #ifdef CONFIG_64BIT
+
 static __inline__ uint8_t lb_40bit_phys_uncached(uint64_t phys)
 {
         return lb_40bit_phys(phys, CCA_UNCACHED);
@@ -351,6 +511,17 @@ static __inline__  uint8_t lb_40bit_phys_cached(uint64_t phys)
 {
         return lb_40bit_phys(phys, CCA_CACHED);
 }
+
+static __inline__ uint16_t lh_40bit_phys_uncached(uint64_t phys)
+{
+        return lh_40bit_phys(phys, CCA_UNCACHED);
+}
+
+static __inline__  uint16_t lh_40bit_phys_cached(uint64_t phys)
+{
+        return lh_40bit_phys(phys, CCA_CACHED);
+}
+
 static __inline__ uint32_t lw_40bit_phys_uncached(uint64_t phys)
 {
 	return lw_40bit_phys(phys, CCA_UNCACHED);
@@ -368,6 +539,7 @@ static __inline__ uint64_t ld_40bit_phys_cached(uint64_t phys)
 	return ld_40bit_phys(phys, CCA_CACHED);
 }
 
+#ifdef CONFIG_64BIT
 static __inline__ void sb_40bit_phys(uint64_t phys, int cca, uint8_t value)
 {
   __asm__ __volatile__(".set push\n"
@@ -428,6 +600,131 @@ static __inline__ void sd_40bit_phys(uint64_t phys, int cca, uint64_t value)
 			     :"$8"
 		);
 }
+
+#else
+
+static __inline__ void sb_40bit_phys(uint64_t phys, int cca, uint8_t value)
+{
+        uint32_t low, high;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xffffffffffULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "sb %0, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :
+                        :"r"(value), "r"(low), "r"(high)
+                        :"$1");
+        disable_KX(flags);
+}
+
+static __inline__ void sh_40bit_phys(uint64_t phys, int cca, uint16_t value)
+{
+        uint32_t low, high;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xfffffffffeULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "sh %0, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :
+                        :"r"(value), "r"(low), "r"(high)
+                        :"$1");
+        disable_KX(flags);
+}
+
+static __inline__ void sw_40bit_phys(uint64_t phys, int cca, uint32_t value)
+{
+        uint32_t low, high;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xfffffffffcULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "sw %0, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :
+                        :"r"(value), "r"(low), "r"(high)
+                        :"$1");
+        disable_KX(flags);
+}
+
+static __inline__ void sd_40bit_phys(uint64_t phys, int cca, uint64_t value)
+{
+        uint32_t lsw, msw, high, low;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+        phys &= 0xfffffffff8ULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low  = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+        lsw  = (uint32_t) value  & 0xffffffff;
+        msw  = (uint32_t)(value >>32);
+        enable_KX(flags);
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %3, 0\n"
+                        "dsll32 %2, 0    \n"
+                        "dsrl32 %2, 0    \n"
+                        "or $1, $1, %2   \n"
+                        "dsll32 $8, %1, 0\n"
+                        "dsll32 %0, 0   \n"
+                        "dsrl32 %0, 0   \n"
+                        "or $8, $8, %0   \n"
+                        "sd $8, 0($1)    \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :
+                        : "r"(lsw), "r"(msw), "r"(low), "r"(high)
+                        :"$1", "$8");
+        disable_KX(flags);
+}
+
+#endif // #ifdef CONFIG_64BIT
+
 static __inline__ void sb_40bit_phys_uncached(uint64_t phys, uint8_t value)
 {
       sb_40bit_phys(phys, CCA_UNCACHED, value);
@@ -436,6 +733,16 @@ static __inline__ void sb_40bit_phys_cached(uint64_t phys, uint8_t value)
 {
       sb_40bit_phys(phys, CCA_CACHED, value);
 }
+
+static __inline__ void sh_40bit_phys_uncached(uint64_t phys, uint16_t value)
+{
+      sh_40bit_phys(phys, CCA_UNCACHED, value);
+}
+static __inline__ void sh_40bit_phys_cached(uint64_t phys, uint16_t value)
+{
+      sh_40bit_phys(phys, CCA_CACHED, value);
+}
+
 static __inline__ void sw_40bit_phys_uncached(uint64_t phys, uint32_t value)
 {
 	sw_40bit_phys(phys, CCA_UNCACHED, value);
@@ -453,25 +760,19 @@ static __inline__ void sd_40bit_phys_cached(uint64_t phys, uint64_t value)
 	sd_40bit_phys(phys, CCA_CACHED, value);
 }
 
-#define enable_KX(flags)       \
- __asm__ __volatile__ (        \
-        ".set push\n"          \
-        ".set noat\n"          \
-        ".set noreorder\n"     \
-        "mfc0 %0, $12\n\t"     \
-        "ori $1, %0, 0x81\n\t" \
-        "xori $1, 1\n\t"       \
-        "mtc0 $1, $12\n"       \
-        ".set pop\n"           \
-        : "=r"(flags) ); 
-        
-#define disable_KX(flags)   \
- __asm__ __volatile__ (     \
-        ".set push\n"       \
-        "mtc0 %0, $12\n"    \
-        ".set pop\n"        \
-        : : "r"(flags) )
         
+#define enable_ELPA()           \
+ __asm__ __volatile__ (         \
+        ".set push\n"           \
+        ".set noat\n"           \
+        ".set noreorder\n"      \
+        "mfc0 $8, $5, 1\n"      \
+        "li $9, 0x20000000\n"   \
+        "or $8, $8, $9\n"       \
+        "mtc0 $8, $5, 1\n"      \
+        ".set pop\n"            \
+        :  :  :"$8", "$9")                      
+
 
 /*
  *  COP2 Reg access macros
@@ -589,12 +890,6 @@ do {                                                                    \
 
 #endif /* _ABI64 */
 
-#ifdef NLM_HAL_LINUX_KERNEL 
-#define DFS_OUTPUT(DR, DF, DV)  ((400/((DR+1) * 3)) * (DF+1) * 2)/(DV+1)
-#else
-#define DFS_OUTPUT(DR, DF, DV)  ((133.33/(DR+1)) * (DF+1) * 2)/(DV+1)
-#endif
-
 typedef enum crc_type {
 	NLM_CRC_32 = 0,
 	NLM_CRC_16 = 16,
@@ -624,6 +919,7 @@ typedef uint32_t u_data;
         ".set push\n"                                         \
         ".set noat\n"                                         \
 	"dmtur %0, " REG_STR(poly_reg) "\n"                   \
+	"ehb\n"                                               \
         ".set pop\n"                                          \
 	: : [poly] "r"((crc_poly << poly_type) & 0x00000000ffffffff)  \
     );                                                        \
@@ -752,7 +1048,7 @@ nlm_crc7_word(int crc_reg, u_data data, unsigned int len, unsigned short crc_ini
 	uint32_t i, rem = len, __ret = init, l;                              \
 	for(i = 0; rem > 0;) {                                               \
                 data = ((uint64_t *)buf)[i];                                 \
-      	        i += 8;                                                      \
+      	        i += 1;                                                      \
 	        if(rem >= 8) {                                               \
 		        rem -= 8;                                            \
 		        l = 7;                                               \
@@ -789,7 +1085,7 @@ nlm_crc7_word(int crc_reg, u_data data, unsigned int len, unsigned short crc_ini
 	uint32_t i, rem = len, __ret = init, l;                              \
 	for(i = 0; rem > 0;) {                                               \
 		data = ((uint32_t *)buf)[i];                                 \
-                i += 4;                                                      \
+                i += 1;                                                      \
 		if(rem >= 4) {                                               \
 			rem -= 4;                                            \
 			l = 3;                                               \
@@ -827,7 +1123,7 @@ static __inline__ unsigned char
 nlm_crc7(int crc_reg, const unsigned char *buf, unsigned int len, unsigned char crc)
 {
 	return (unsigned char)(LOOP_ON_DATA(crc_reg, crc, buf,
-					    len, nlm_crc7_word) & 0x3f);
+					    len, nlm_crc7_word) & 0x7f);
 }
 #if 0
 static __inline__ int num_ones(unsigned long mask)
@@ -868,14 +1164,57 @@ static __inline__ uint64_t xlp_get_field_dw(uint64_t dword, int lsb, int size)
 	return ((dword >> lsb) & XLP_BIT_MASK_DW(size));
 }
 
+
+#if !defined(NLM_HAL_LINUX_USER)
+static __inline__ int nlm_read_prid(void)
+{
+        int res = 0;
+
+        asm volatile(         \
+                ".set push\n"           \
+                ".set noat\n"           \
+                ".set noreorder\n"      \
+                "mfc0 %0, $15, 0\n"      \
+                ".set pop\n"            \
+                : "=r" (res));
+
+        return res;
+}
+
+#else
+#define nlm_read_prid 			nlm_uaccess_processor_id
+#endif
+
+static __inline__ uint32_t nlm_read_ebase(void)
+{
+        uint32_t res = 0;
+
+        asm volatile(         \
+                ".set push\n"           \
+                ".set noat\n"           \
+                ".set noreorder\n"      \
+                "mfc0 %0, $15, 1\n"      \
+                ".set pop\n"            \
+                : "=r" (res));
+
+        return res;
+}
+
+
 /* Linux User Mode */
 #if defined(NLM_HAL_LINUX_USER)
 #include <nlm_uaccess.h>
+#define nlh_read_cfg_reg16(addr)       nlm_uaccess_mem_read16((NLH_XKPHYS_UNCACHED | (addr)))
+#define nlh_write_cfg_reg16(addr, val) nlm_uaccess_mem_write16((NLH_XKPHYS_UNCACHED | (addr)), (val))
 #define nlh_read_cfg_reg32(addr)       nlm_uaccess_mem_read32((NLH_XKPHYS_UNCACHED | (addr)))
 #define nlh_write_cfg_reg32(addr, val) nlm_uaccess_mem_write32((NLH_XKPHYS_UNCACHED | (addr)), (val))
 #define nlh_read_cfg_reg64(addr)       nlm_uaccess_mem_read64((NLH_XKPHYS_UNCACHED | (addr)))
 #define nlh_write_cfg_reg64(addr, val) nlm_uaccess_mem_write64((NLH_XKPHYS_UNCACHED | (addr)), (val))
 
+/* For Accessing Regex Registers in PCI Memory space */
+#define WRITE_REGX_CFG_REG_PCIM(reg, val)       nlh_write_cfg_reg32((xlp_regex_base_pcim + reg), (val))
+#define READ_REGX_CFG_REG_PCIM(reg)             nlh_read_cfg_reg32((xlp_regex_base_pcim + reg))
+
 #define nlh_send_msg3(dst, code, data0, data1, data2) \
   nlm_uaccess_msgsnd_3(code, dst, data0, data1, data2)
 
@@ -900,8 +1239,10 @@ static __inline__ uint64_t xlp_get_field_dw(uint64_t dword, int lsb, int size)
 
 /* NETOS and Linux Kernel Mdoe */
 #elif defined(NLM_HAL_NETOS) || defined(NLM_HAL_LINUX_KERNEL) \
-	|| defined(NLM_HAL_UBOOT) || defined(NLM_HAL_NETLBOOT)
+	|| defined(NLM_HAL_UBOOT) || defined(NLM_HAL_NETLBOOT) || defined(NLM_HAL_XLOADER)
 
+#define nlh_read_cfg_reg16(addr)       lh_40bit_phys_uncached(addr)
+#define nlh_write_cfg_reg16(addr, val) sh_40bit_phys_uncached(addr, val)
 #define nlh_read_cfg_reg32(addr)       lw_40bit_phys_uncached(addr)
 #define nlh_write_cfg_reg32(addr, val) sw_40bit_phys_uncached(addr, val)
 #define nlh_read_cfg_reg64(addr)       ld_40bit_phys_uncached(addr)
@@ -933,6 +1274,27 @@ static __inline__ uint64_t xlp_get_field_dw(uint64_t dword, int lsb, int size)
 
 #endif
 
+#if !defined(NLM_HAL_LINUX_USER)
+static __inline__ uint32_t nlm_hard_cpuid(void)
+{
+	return nlm_read_ebase() & 0x3ff;
+}
+#else
+#define nlm_hard_cpuid			nlm_uaccess_hard_cpuid
+#endif
+
+static __inline__ uint32_t nlm_node_id(void)
+{
+	if (is_nlm_xlp8xx())
+		return (nlm_hard_cpuid() >> 5) & 0x3;
+	return 0;
+}
+
+static __inline__ uint32_t nlm_cpu_id(void)
+{
+	return nlm_hard_cpuid() & 0x1f;
+}
+
 #else  /* __ASSEMBLY__ */
 
 #if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32) || \
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h
index 818bcc1..4619abf 100644
--- a/arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h
@@ -1,5 +1,5 @@
 /***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
 reserved.
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are
@@ -28,65 +28,286 @@ THE POSSIBILITY OF SUCH DAMAGE.
 
 #include "nlm_hal.h"
 
-#define NAE_RECV_NONE          0x00000000
-#define NAE_RECV_RX            0x00000001
-#define NAE_RECV_TXC           0x00000002
-#define NAE_RECV_UNKNOWN       0x80000000
-#define NULL_VFBID             127
-#define MAX_NAE_CONTEXTS       524
-
-struct nlm_hal_nae_port {
-	int  valid;
-	int  mgmt;
-        int  num_free_desc;
-        int  txq_range[2];
-        int  rxq;
-        int  hw_port_id;
-	int  vlan_pri_en;
-	int  iftype;
-	int  num_channels;
+
+#define NUM_DIST_VEC 		16
+#define NUM_WORDS_PER_DV 	16
+#define MAX_DV_TBL_ENTRIES (NUM_DIST_VEC * NUM_WORDS_PER_DV)
+
+#define XLP_3XX_MAX_PORTS	8
+#define XLP_MAX_PORTS		18
+
+#define NAE_RECV_NONE          	0x00000000
+#define NAE_RECV_RX            	0x00000001
+#define NAE_RECV_TXC           	0x00000002
+#define NAE_RECV_UNKNOWN       	0x80000000
+#define NULL_VFBID             	127
+#define MAX_NAE_CONTEXTS       	524
+#define XLP8XX_MAX_NAE_COMPLEX 	5
+#define MAX_CAL_SLOTS	       	64
+#define MAX_VFBID_ENTRIES	128
+
+#define XLP_MAX_FLOWS       (64 << 10)
+
+#define SGMII_CAL_SLOTS         3
+#define XAUI_CAL_SLOTS          13
+#define ILK_CAL_SLOTS           26
+
+#define MAX_PORTS_PERBLOCK	4
+#define XLP_MAX_INTERLAKEN_IF	2
+
+#define XLP3XX_MAX_NAE_COMPLEX	2
+#define XLP3XX_MAX_NAE_CONTEXTS	64
+#define MAX_POE_CLASSES     	8
+#define MAX_POE_CLASS_CTXT_TBL_SZ ((MAX_NAE_CONTEXTS / MAX_POE_CLASSES) + 1)
+#define XLP3XX_MAX_POE_CLASS_CTXT_TBL_SZ ((XLP3XX_MAX_NAE_CONTEXTS / MAX_POE_CLASSES) + 1)
+#define XLP3XX_SGMII_PARSERSEQ_FIFO_MAX	30
+/*################################*/
+#define XLP3XX_STG2_FIFO_SZ   512
+#define XLP3XX_EH_FIFO_SZ     512
+#define XLP3XX_FROUT_FIFO_SZ  512
+#define XLP3XX_MS_FIFO_SZ     512
+#define XLP3XX_PKT_FIFO_SZ    8192
+#define XLP3XX_PKTLEN_FIFO_SZ 512
+
+#define XLP3XX_MAX_STG2_OFFSET           0x7F
+#define XLP3XX_MAX_EH_OFFSET             0x1f
+#define XLP3XX_MAX_FREE_OUT_OFFSET       0x1f
+#define XLP3XX_MAX_MS_OFFSET             0xF
+#define XLP3XX_MAX_PMEM_OFFSET           0x7FE
+
+
+#define XLP3XX_STG1_2_CREDIT     XLP3XX_STG2_FIFO_SZ
+#define XLP3XX_STG2_EH_CREDIT    XLP3XX_EH_FIFO_SZ
+#define XLP3XX_STG2_FROUT_CREDIT XLP3XX_FROUT_FIFO_SZ
+#define XLP3XX_STG2_MS_CREDIT    XLP3XX_MS_FIFO_SZ
+
+/*################################*/
+
+/*################################*/
+#define XLP8XX_STG2_FIFO_SZ   2048
+#define XLP8XX_EH_FIFO_SZ     4096
+#define XLP8XX_FROUT_FIFO_SZ  4096
+#define XLP8XX_MS_FIFO_SZ     2048
+#define XLP8XX_PKT_FIFO_SZ    16384
+#define XLP8XX_PKTLEN_FIFO_SZ 2048
+
+#define XLP8XX_MAX_STG2_OFFSET           0x7F
+#define XLP8XX_MAX_EH_OFFSET           	 0x7F
+#define XLP8XX_MAX_FREE_OUT_OFFSET       0x7F
+#define XLP8XX_MAX_MS_OFFSET             0x1F
+#define XLP8XX_MAX_PMEM_OFFSET           0x7FE
+
+#define XLP8XX_STG1_2_CREDIT     XLP8XX_STG2_FIFO_SZ
+#define XLP8XX_STG2_EH_CREDIT    XLP8XX_EH_FIFO_SZ
+#define XLP8XX_STG2_FROUT_CREDIT XLP8XX_FROUT_FIFO_SZ
+#define XLP8XX_STG2_MS_CREDIT    XLP8XX_MS_FIFO_SZ
+
+#define XLP_FREEIN_SPILL_DEFAULT_MEM_ADDR (252ULL << 20)
+#define XLP_FREEIN_SPILL_DEFAULT_MEM_SIZE (4ULL << 20)
+
+/*################################*/
+
+struct nae_complex_config {
+	uint32_t num_free_desc[MAX_PORTS_PERBLOCK];
+	uint32_t free_desc_size[MAX_PORTS_PERBLOCK];
+	uint32_t intf_fifo_size[MAX_PORTS_PERBLOCK];
+	uint32_t prsr_seq_fifo_size[MAX_PORTS_PERBLOCK];
+	uint32_t rx_buf_size[MAX_PORTS_PERBLOCK];
+	uint32_t ucore_mask[MAX_PORTS_PERBLOCK];	
+	uint32_t ext_phy_addr[MAX_PORTS_PERBLOCK];
+	uint32_t ext_phy_bus[MAX_PORTS_PERBLOCK];
+	uint32_t mgmt[MAX_PORTS_PERBLOCK];
+	uint32_t loopback[MAX_PORTS_PERBLOCK];
+	uint32_t num_channels[MAX_PORTS_PERBLOCK];
+	uint32_t num_lanes;
+	uint32_t lane_rate;
 };
 
-struct nlm_hal_nae_config {
-	int fb_vc;
-        int rx_vc;
-	int num_ports;
-	struct nlm_hal_nae_port ports[18];
+
+struct poe_statistics {
+	uint64_t ooo_msg_count;
+	uint64_t inorder_msg_count;
+	uint64_t loc_stor_access_count;
+	uint64_t ext_stor_access_count;
+	uint64_t loc_stor_alloc_count;
+	uint64_t ext_stor_alloc_count;
 };
 
-extern struct nlm_hal_nae_config nae_cfg;
-extern int cntx2port[];
+/* Temporarily specifying these sizes here. 
+   These will be moved to FDT soon 
+*/
+
+static inline uint32_t nlm_stg2_fifo_sz(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_STG2_FIFO_SZ;
+	}else{
+		return XLP8XX_STG2_FIFO_SZ;
+	}
+}
+
+static inline uint32_t nlm_eh_fifo_sz(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_EH_FIFO_SZ;
+	}else{
+		return XLP8XX_EH_FIFO_SZ;
+	}
+}
+
+static inline uint32_t nlm_frout_fifo_sz(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_FROUT_FIFO_SZ;
+	}else{
+		return XLP8XX_FROUT_FIFO_SZ;
+	}
+}
+
+static inline uint32_t nlm_ms_fifo_sz(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_MS_FIFO_SZ;
+	}else{
+		return XLP8XX_MS_FIFO_SZ;
+	}
+}
+
+static inline uint32_t nlm_pkt_fifo_sz(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_PKT_FIFO_SZ;
+	}else{
+		return XLP8XX_PKT_FIFO_SZ;
+	}
+}
+
+static inline uint32_t nlm_pktlen_fifo_sz(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_PKTLEN_FIFO_SZ;
+	}else{
+		return XLP8XX_PKTLEN_FIFO_SZ;
+	}
+}
+
+static inline uint32_t max_stg2_offset(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_MAX_STG2_OFFSET;
+	}else{
+		return XLP8XX_MAX_STG2_OFFSET;
+	}
+}
 
+static inline uint32_t max_eh_offset(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_MAX_EH_OFFSET;
+	}else{
+		return XLP8XX_MAX_EH_OFFSET;
+	}
+}
+
+static inline uint32_t max_free_out_offset(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_MAX_FREE_OUT_OFFSET;
+	}else{
+		return XLP8XX_MAX_FREE_OUT_OFFSET;
+	}
+}
+
+static inline uint32_t max_ms_offset(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_MAX_MS_OFFSET;
+	}else{
+		return XLP8XX_MAX_MS_OFFSET;
+	}
+}
+
+static inline uint32_t max_pmem_offset(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_MAX_PMEM_OFFSET;
+	}else{
+		return XLP8XX_MAX_PMEM_OFFSET;
+	}
+}
+
+static inline uint32_t stg1_2_credit(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_STG1_2_CREDIT;
+	}else{
+		return XLP8XX_STG1_2_CREDIT;
+	}
+}
+
+static inline uint32_t stg2_eh_credit(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_STG2_EH_CREDIT;
+	}else{
+		return XLP8XX_STG2_EH_CREDIT;
+	}
+}
+
+static inline uint32_t stg2_frout_credit(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_STG2_FROUT_CREDIT;
+	}else{
+		return XLP8XX_STG2_FROUT_CREDIT;
+	}
+}
+
+static inline uint32_t stg2_ms_credit(void)
+{
+	if(is_nlm_xlp3xx()){
+		return XLP3XX_STG2_MS_CREDIT;
+	}else{
+		return XLP8XX_STG2_MS_CREDIT;
+	}
+}
+
+
+/*###################################################*/
 /* To access Interface specific regs in NAE block */
-#define XLP_NAE_OFFSET(iface) (xlp_nae_base | (((iface) & 0xf) << 9))
+#define XLP_NAE_OFFSET(node, iface) \
+	(xlp_nae_base[node] | (((iface) & 0xf) << 9))
 
 /* To access individual gmac regs */
-#define XLP_MAC_OFFSET(blk, iface) \
-  (xlp_mac_base + (((blk) * XLP_NA_REG_BLOCK_SIZE)) + ((iface) * XLP_NA_REG_IFACE_SIZE))
+#define XLP_MAC_OFFSET(node, blk, iface) \
+	(xlp_mac_base[node] + (((blk) * XLP_NA_REG_BLOCK_SIZE)) + ((iface) * XLP_NA_REG_IFACE_SIZE))
 
 #ifndef __ASSEMBLY__
 /* To access POE regs based in PCI Memory */
-#define nlm_hal_write_poe_pcim_reg(reg, val) nlm_hal_write_32bit_reg(xlp_poe_base_pcim, (reg), (val))
-#define nlm_hal_read_poe_pcim_reg(reg)   nlm_hal_read_32bit_reg(xlp_poe_base_pcim, (reg))
+
+#define nlm_hal_write_poe_pcim_reg(node, reg, val) nlm_hal_write_32bit_reg(xlp_poe_base_pcim[node], (reg), (val))
+#define nlm_hal_read_poe_pcim_reg(node, reg)   nlm_hal_read_32bit_reg(xlp_poe_base_pcim[node], (reg))
 
 /* To access POE regs based in PCIE config space */
-#define nlm_hal_write_poe_pcie_reg(reg, val) nlm_hal_write_32bit_reg(xlp_poe_base_pcie, (reg), (val))
-#define nlm_hal_read_poe_pcie_reg(reg)   nlm_hal_read_32bit_reg(xlp_poe_base_pcie, (reg))
 
-#define nlm_hal_write_nae_reg(reg, val) nlm_hal_write_32bit_reg(xlp_nae_base, (reg), (val))
-#define nlm_hal_read_nae_reg(reg) nlm_hal_read_32bit_reg(xlp_nae_base, (reg))
+#define nlm_hal_write_poe_pcie_reg(node, reg, val) nlm_hal_write_32bit_reg(xlp_poe_base_pcie[node], (reg), (val))
+#define nlm_hal_read_poe_pcie_reg(node, reg)   nlm_hal_read_32bit_reg(xlp_poe_base_pcie[node], (reg))
 
-#define nlm_hal_write_nae_iface_reg(iface, reg, val) nlm_hal_write_32bit_reg(XLP_NAE_OFFSET(iface), (reg), (val))
-#define nlm_hal_read_nae_iface_reg(iface, reg) nlm_hal_read_32bit_reg(XLP_NAE_OFFSET(iface), (reg))
+// NAE
+#define nlm_hal_write_nae_reg(node, reg, val) nlm_hal_write_32bit_reg(xlp_nae_base[node], (reg), (val))
+#define nlm_hal_read_nae_reg(node, reg) nlm_hal_read_32bit_reg(xlp_nae_base[node], (reg))
 
-#define nlm_hal_write_ucode(ucore, offset, val) \
-  nlh_write_cfg_reg32((xlp_mac_base + 0x10000 + (ucore * CODE_SIZE_PER_UCORE) + offset), (val))
+#define nlm_hal_write_nae_iface_reg(node, iface, reg, val) nlm_hal_write_32bit_reg(XLP_NAE_OFFSET(node, iface), (reg), (val))
+#define nlm_hal_read_nae_iface_reg(node, iface, reg) nlm_hal_read_32bit_reg(XLP_NAE_OFFSET(node, iface), (reg))
 
-#define nlm_hal_write_mac_reg(blk, iface, reg, val) nlm_hal_write_32bit_reg(XLP_MAC_OFFSET(blk, iface), (reg), (val))
-#define nlm_hal_read_mac_reg(blk, iface, reg) nlm_hal_read_32bit_reg(XLP_MAC_OFFSET(blk, iface), (reg))
+#define nlm_hal_write_ucode(node, ucore, offset, val) \
+  nlh_write_cfg_reg32((xlp_mac_base[node] + 0x10000 + (ucore * CODE_SIZE_PER_UCORE) + offset), (val))
 
-#define read_gmac_reg(idx, reg) nlm_hal_read_mac_reg( (((idx) & 0xff)>>2), ((idx) & 0x3), reg)
-#define write_gmac_reg(idx, reg, val) nlm_hal_write_mac_reg( (((idx) & 0xff)>>2), ((idx) & 0x3), (reg), (val))
+#define nlm_hal_write_mac_reg(node, blk, iface, reg, val) nlm_hal_write_32bit_reg(XLP_MAC_OFFSET(node, blk, iface), (reg), (val))
+#define nlm_hal_read_mac_reg(node, blk, iface, reg) nlm_hal_read_32bit_reg(XLP_MAC_OFFSET(node, blk, iface), (reg))
+
+#define read_gmac_reg(node, idx, reg) nlm_hal_read_mac_reg(node, (((idx) & 0xff)>>2), ((idx) & 0x3), reg)
+#define write_gmac_reg(node, idx, reg, val) nlm_hal_write_mac_reg(node, (((idx) & 0xff)>>2), ((idx) & 0x3), (reg), (val))
 
 static __inline__ uint32_t vfbid_to_dest_map(unsigned int vfbid, unsigned int dest, int cmd) {
 	return ((dest & 0x3fff) << 16) | ((vfbid & 0x7f) << 4) | (cmd & 0x1);
@@ -104,63 +325,184 @@ static __inline__ uint32_t flow_base_mask_config(unsigned int interface, unsigne
 	return ((base & 0xffff) << 16) | ((cmd & 0x1) << 15) | ((mask & 0x1f) << 8) | (interface & 0x1f);
 }
 
-extern int nlm_hal_init_poe_distvec(int vec, uint32_t cm0, uint32_t cm1, uint32_t cm2, uint32_t cm3, uint32_t vcmask);
-extern void nlm_hal_init_poe_ext_storage(uint64_t fbp_base_phys,
+uint32_t nlm_hal_get_frin_total_queue(int node);
+uint32_t nlm_hal_get_frin_queue_base(int node);
+extern int nlm_hal_init_poe_distvec(int node, int vec, uint32_t cm0, uint32_t cm1, uint32_t cm2, uint32_t cm3, uint32_t vcmask);
+extern void nlm_hal_init_poe_ext_storage(int node, uint64_t fbp_base_phys,
 					 uint64_t msg_base_phys,
 					 uint64_t msg_base_virt);
 
-extern int nlm_hal_load_ucore(int ucore_mask, unsigned int *opcodes, int num_opcodes);
-
-extern int nlm_hal_init_if(int type, int  inf, uint32_t *regs, int num_regs);
-extern int nlm_hal_open_if(int type, int  inf);
-extern int nlm_hal_close_if(int type, int  inf);
+extern int nlm_hal_load_ucore(int node, int ucore_mask, unsigned int *opcodes, int num_opcodes);
 
-/* Here regs are pairs of <index, val> of interface regs */
-extern int nlm_hal_init_if_regs(int type, int  inf, uint32_t *regs, int num_regs);
-
-/* Here regs are pairs of <index, val> of NAE regs */
-extern int nlm_hal_init_nae_regs(int type, uint32_t *regs, int num_regs);
-
-/* Here regs are pairs of <index, val> of POE regs */
-extern int nlm_hal_init_poe_regs(uint32_t *regs, int num_regs);
+extern int nlm_hal_init_if(int node, int type, int  inf, uint32_t *regs, int num_regs);
+extern int nlm_hal_open_if(int node, int type, int  inf);
+extern int nlm_hal_close_if(int node, int type, int  inf);
+extern void nlm_hal_init_ingress(int node, int desc_size);
 
 extern int nlm_hal_nae_send(int dest, int fbid, unsigned long long phys_addr, int len, unsigned int flags);
 extern int nlm_hal_nae_recv(int rx_vc, unsigned long long *phys_addr, unsigned int *flags);
 
 extern int nlm_hal_soc_recv(int dst_vc, unsigned int *intf, unsigned long long *phys_addr, unsigned int *flags);
 
+extern int nlm_enable_poe_statistics(int node);
+extern int nlm_disable_poe_statistics(int node);
+extern int nlm_read_poe_statistics(int node, struct poe_statistics *stats);
+
+
+enum NAE_REG_CMD {
+        CMD_READ = 0,
+        CMD_WRITE
+};
+
+enum if_speed {
+        SPEED_10M = 0,
+        SPEED_100M,
+        SPEED_1000M
+};
+
+
+/* NETWORK INF CTRL REG */
+#define SOFTRESET(x)                        ((x) << 11)
+#define STATS_EN(x)                         ((x) << 16)
+#define TX_EN(x)                            ((x) << 2)
+#define SPEED(x)                            ((x) & 0x3)
+
+/* MAC_CONF1 */
+#define INF_SOFTRESET(x)                    ((x) << 31)
+#define INF_LOOP_BACK(x)                    ((x) << 8)
+#define INF_RX_ENABLE(x)                    ((x) << 2)
+#define INF_TX_ENABLE(x)                    (0x1)
+
+/* MAC_CONF2 */
+#define INF_PREMBL_LEN(x)                   (((x) & 0xf) << 12)
+#define INF_IFMODE(x)                       (((x) & 0x3) << 8)
+#define INF_LENCHK(x)                       ((((x) & 0x1)) << 4)
+#define INF_PADCRCEN(x)                     (((x) & 0x1) << 2)
+#define INF_PADCRC(x)                       (((x) & 0x1) << 1)
+#define INF_FULLDUP(x)                      ((x) & 0x1)
+#define TXINITIORCR(x)                      ((x) & 0x7ffff) << 8
+
+#define NAE_RX_ENABLE 0x1
+#define NAE_TX_ENABLE 0x1
+#define NAE_TX_ACE 0x2
+#define NAE_TX_COMPATIBLE 0x4
+
+#define INF_BYTE_MODE   0x2
+#define INF_NIBBLE_MODE 0x1
+
 /* PHY Access routines
  */
 enum {
 	NLM_HAL_INT_MDIO,
 	NLM_HAL_EXT_MDIO,
 };
-extern int nlm_hal_mdio_read(int type, int bus,int block, int intf_type,
+extern int nlm_hal_mdio_read(int node, int type, int bus,int block, int intf_type,
 			     int phyaddr, int regidx);
-extern int nlm_hal_mdio_write(int type, int bus, int block, int intf_type, int phyaddr,
+extern int nlm_hal_mdio_write(int node, int type, int bus, int block, int intf_type, int phyaddr,
 			      int regidx, uint16_t val);
-extern int nlm_hal_mdio_reset(int type, int bus, int block, int intf_type);
+extern int nlm_hal_mdio_reset(int node, int type, int bus, int block, int intf_type);
 
-extern void nae_lane_reset_txpll(int block, int lane_ctrl);
+extern void xlp3xx_8xxb0_nae_lane_reset_txpll(int node, int block, int lane_ctrl, int phymode);
+extern void xlp8xx_ax_nae_lane_reset_txpll(int node, int block, int lane_ctrl, int phymode);
 
 /*  PCS initialization
  */
-extern void nlm_hal_sgmii_pcs_init(int sgmii_cplx_mask);
-extern void nlm_hal_xaui_pcs_init(int xaui_cplx_mask);
-extern void nlm_hal_ilk_pcs_init(int ilk_cplx_mask, int num_lanes);
-extern void nlm_hal_sgmii_phy_init(void);
+extern void nlm_hal_sgmii_pcs_init(int node, int sgmii_cplx_mask);
+extern void nlm_hal_xaui_pcs_init(int node, int xaui_cplx_mask);
+extern int nlm_hal_ilk_pcs_init(int node, uint32_t ilk_complex_map);
+extern int nlm_hal_init_cs34x7(int hwport,int num_lanes, int lane_rate);
+extern int is_xlp_ilk_lanealigned(int node, int blk);
+extern void nlm_hal_sgmii_phy_init(int node);
 
 extern int nlm_hal_init_nae(void *fdt, int dom_id);
-
+extern void reset_nae_mgmt(int node);
 extern int nlm_hal_write_ucore_shared_mem(unsigned int *data, int words);
 
-extern int nlm_hal_get_phy_status(int inf, uint32_t *speed, uint32_t *duplex);
+extern int nlm_hal_get_phy_status(int node, int inf, uint32_t *speed, uint32_t *duplex);
 
-extern void nlm_hal_mac_disable(int inf, int type);
+extern void nlm_hal_mac_disable(int node, int inf, int type);
 
-extern void nlm_hal_mac_enable(int inf, int type);
+extern void nlm_hal_mac_enable(int node, int inf, int type);
 
-extern uint16_t nlm_hal_get_hwport(uint32_t context);
+extern uint16_t nlm_hal_get_hwport(int node, uint32_t context);
+extern int nlm_hal_set_xaui_framesize(int node, int block, uint32_t tx_size, uint32_t rx_size);
+extern int nlm_hal_set_sgmii_framesize(int node, int block, int index, uint32_t size);
 
+extern int nlm_config_vfbid_table(int node, uint32_t start, uint32_t num_entries, uint32_t *vfbid_tbl);
 #endif //__ASSEMBLY__
+
+
+// POE APIS
+
+static inline void nlm_write_enqspill_threshold(int node, uint32_t threshold)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_ENQ_SPILL_THOLD, (threshold & 0xFF));
+}
+
+static inline void nlm_write_deqspill_threshold(int node, uint32_t threshold)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_DEQ_SPILL_THOLD, (threshold & 0xFF));
+}
+
+static inline void nlm_write_deqspill_timer(int node, uint32_t timer)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_DEQ_SPILL_TIMER, (timer & 0x3FF));
+}
+
+static inline void nlm_enable_distribution_class_drop(int node, uint32_t class_mask)
+{
+        uint32_t val = nlm_hal_read_poe_pcie_reg(node, POE_DISTR_CLASS_DROP_EN);
+        val |= (class_mask & 0xFF);
+        nlm_hal_write_poe_pcie_reg(node, POE_DISTR_CLASS_DROP_EN, val);
+}
+
+static inline void nlm_enable_distribution_vector_drop(int node, uint32_t vector_mask)
+{
+        uint32_t val = nlm_hal_read_poe_pcie_reg(node, POE_DISTR_VEC_DROP_EN);
+        val |= (vector_mask & 0xFFFF);
+        nlm_hal_write_poe_pcie_reg(node, POE_DISTR_VEC_DROP_EN, val);
+}
+
+static inline void nlm_disable_distribution_class_drop(int node, uint32_t class_mask)
+{
+        uint32_t val = nlm_hal_read_poe_pcie_reg(node, POE_DISTR_CLASS_DROP_EN);
+        val &= ~(class_mask & 0xFF);
+        nlm_hal_write_poe_pcie_reg(node, POE_DISTR_CLASS_DROP_EN, val);
+}
+
+static inline void nlm_disable_distribution_vector_drop(int node, uint32_t vector_mask)
+{
+        uint32_t val = nlm_hal_read_poe_pcie_reg(node, POE_DISTR_VEC_DROP_EN);
+        val &= ~(vector_mask & 0xFFFF);
+        nlm_hal_write_poe_pcie_reg(node, POE_DISTR_VEC_DROP_EN, val);
+}
+
+static inline void nlm_write_distvec_drop_timer(int node, uint32_t timer)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_DISTRVEC_DROP_TIMER, (timer & 0xFFFF));
+}
+
+static inline void nlm_enable_distribution(int node)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_DIST_ENABLE, 1);
+}
+
+static inline void nlm_disable_distribution(int node)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_DIST_ENABLE, 0);
+}
+
+static inline void nlm_write_poe_dest_threshold(int node, uint32_t threshold)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_DEST_THRESHOLD, (threshold & 0xFFFF));
+}
+
+static inline void nlm_write_poe_distr_threshold(int node, uint32_t threshold0, uint32_t threshold1, uint32_t threshold2, uint32_t threshold3)
+{
+	nlm_hal_write_poe_pcie_reg(node, POE_DIST_THRESHOLD_0, threshold0);
+	nlm_hal_write_poe_pcie_reg(node, POE_DIST_THRESHOLD_0+1, threshold1);
+	nlm_hal_write_poe_pcie_reg(node, POE_DIST_THRESHOLD_0+2, threshold2);
+	nlm_hal_write_poe_pcie_reg(node, POE_DIST_THRESHOLD_0+3, threshold3);
+}
+
 #endif //#ifndef _NLM_HAL_NAE_H_
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h
deleted file mode 100644
index 386b1de..0000000
--- a/arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h
+++ /dev/null
@@ -1,379 +0,0 @@
-/***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
-reserved.
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are
-met:
-1. Redistributions of source code must retain the above copyright
-notice, this list of conditions and the following disclaimer.
-2. Redistributions in binary form must reproduce the above copyright
-notice, this list of conditions and the following disclaimer in
-the documentation and/or other materials provided with the
-distribution.
-THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
-ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
-PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
-FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
-CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
-SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
-INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
-CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
-ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
-THE POSSIBILITY OF SUCH DAMAGE.
-*****************************#NETL_2#********************************/
-
-#ifndef _NLM_HAL_PIC_H
-#define _NLM_HAL_PIC_H
-
-#include "nlm_hal.h"
-
-#define TIMER_CYCLES_MAXVAL        0xffffffffffffffffULL
-
-/*
- *    IRT Map
- */
-#define PIC_NUM_IRTS               160
-
-#define PIC_IRT_WD_0_INDEX         0
-#define PIC_IRT_WD_1_INDEX         1
-#define PIC_IRT_WD_NMI_0_INDEX     2
-#define PIC_IRT_WD_NMI_1_INDEX     3
-#define PIC_IRT_TIMER_0_INDEX      4
-#define PIC_IRT_TIMER_1_INDEX      5
-#define PIC_IRT_TIMER_2_INDEX      6
-#define PIC_IRT_TIMER_3_INDEX      7
-#define PIC_IRT_TIMER_4_INDEX      8
-#define PIC_IRT_TIMER_5_INDEX      9
-#define PIC_IRT_TIMER_6_INDEX      10
-#define PIC_IRT_TIMER_7_INDEX      11
-#define PIC_IRT_CLOCK_INDEX        PIC_IRT_TIMER_7_INDEX
-
-#define PIC_NUM_MSG_Q_IRTS         32
-#define PIC_IRT_MSG_Q0_INDEX       12
-#define PIC_IRT_MSG_Q_INDEX(qid)   ((qid) + PIC_IRT_MSG_Q0_INDEX) // 12 - 43
-
-#define PIC_IRT_MSG_0_INDEX        44
-#define PIC_IRT_MSG_1_INDEX        45
-
-#define PIC_NUM_PCIE_MSIX_IRTS     32
-#define PIC_IRT_PCIE_MSIX_0_INDEX  46
-#define PIC_IRT_PCIE_MSIX_INDEX(num) ((num) + PIC_IRT_PCIE_MSIX_0_INDEX) // 46 - 77
-
-#define PIC_NUM_PCIE_LINK_IRTS     4
-#define PIC_IRT_PCIE_LINK_0_INDEX  78
-#define PIC_IRT_PCIE_LINK_INDEX(num) ((num) + PIC_IRT_PCIE_LINK_0_INDEX) // 78 - 81
-
-#define PIC_NUM_NA_IRTS            32
-#define PIC_IRT_NA_0_INDEX         82
-#define PIC_IRT_NA_INDEX(num)      ((num) + PIC_IRT_NA_0_INDEX) // 82 - 113
-
-#define PIC_IRT_POE_INDEX          114
-
-#define PIC_NUM_USB_IRTS           6
-#define PIC_IRT_USB_0_INDEX        115
-#define PIC_IRT_USB_INDEX(num) ((num) + PIC_IRT_USB_0_INDEX) // 115 - 120
-
-#define PIC_IRT_GDX_INDEX          121
-#define PIC_IRT_SEC_INDEX          122
-#define PIC_IRT_RSA_INDEX          123
-
-#define PIC_NUM_COMP_IRTS          4
-#define PIC_IRT_COMP_0_INDEX       124
-#define PIC_IRT_COMP_INDEX(num)    ((num) + PIC_IRT_COMP_0_INDEX) // 124 - 127
-
-#define PIC_IRT_GBU_INDEX          128
-#define PIC_IRT_ICC_0_INDEX        129 // ICC - Inter Chip Coherency
-#define PIC_IRT_ICC_1_INDEX        130
-#define PIC_IRT_ICC_2_INDEX        131
-#define PIC_IRT_CAM_INDEX          132
-#define PIC_IRT_UART_0_INDEX       133
-#define PIC_IRT_UART_1_INDEX       134
-#define PIC_IRT_I2C_0_INDEX        135
-#define PIC_IRT_I2C_1_INDEX        136
-#define PIC_IRT_SYS_0              137
-#define PIC_IRT_SYS_1              138
-#define PIC_IRT_JTAG_INDEX         139
-#define PIC_IRT_PIC                140
-#define PIC_IRT_NBU                141
-#define PIC_IRT_TCU                142
-#define PIC_IRT_GCU                143 // GBC - Global Coherency
-#define PIC_IRT_DMC_0_INDEX        144
-#define PIC_IRT_DMC_1_INDEX        145
-
-#define PIC_NUM_GPIO_IRTS          4
-#define PIC_IRT_GPIO_0_INDEX       146
-#define PIC_IRT_GPIO_INDEX(num)    ((num) + PIC_IRT_GPIO_0_INDEX) // 146 - 149
-
-#define PIC_IRT_NOR                150
-#define PIC_IRT_NAND               151
-#define PIC_IRT_SPI                152
-#define PIC_IRT_MMC                153
-
-/*
- *     Register Offsets
- */
-#define PIC_CTRL             0x00
-#define PIC_BYTESWAP         0x01
-#define PIC_STATUS           0x02
-#define PIC_INT_TIMEOUT      0x03
-#define PIC_ICI0_INT_TIMEOUT 0x04
-#define PIC_ICI1_INT_TIMEOUT 0x05
-#define PIC_ICI2_INT_TIMEOUT 0x06
-#define PIC_IPI_CTL          0x07
-#define PIC_INT_ACK          0x08
-#define PIC_INT_PENDING0     0x09
-#define PIC_INT_PENDING1     0x0a
-#define PIC_INT_PENDING2     0x0b
-
-#define PIC_WD0_MAX_VAL      0x0c
-#define PIC_WD0_COUNT        0x0d
-#define PIC_WD0_MASK_0       0x0e
-#define PIC_WD0_MASK_1       0x0f
-#define PIC_WD0_HEARBEATCMD  0x10
-#define PIC_WD0_HEARBEAT_0   0x11
-#define PIC_WD0_HEARBEAT_1   0x12
-
-#define PIC_WD_MAX_VAL(id)    (PIC_WD0_MAX_VAL + ((id) ? 7 : 0))
-#define PIC_WD_COUNT(id)      (PIC_WD0_COUNT + ((id) ? 7 : 0))
-#define PIC_WD_MASK_0(id)     (PIC_WD0_MASK_0 + ((id) ? 7 : 0))
-#define PIC_WD_MASK_1(id)     (PIC_WD0_MASK_1 + ((id) ? 7 : 0))
-#define PIC_WD_HEARBEAT_0(id) (PIC_WD0_HEARTBEAT_0 + ((id) ? 7 : 0))
-#define PIC_WD_HEARBEAT_1(id) (PIC_WD0_HEARTBEAT_1 + ((id) ? 7 : 0))
-
-#define PIC_SYS_TIMER_0_MAX_VAL   0x1a
-#define PIC_SYS_TIMER_MAX_VAL(id) (PIC_SYS_TIMER_0_MAX_VAL + (id))
-
-#define PIC_SYS_TIMER_0_COUNTER   0x22
-#define PIC_SYS_TIMER_COUNTER(id) (PIC_SYS_TIMER_0_COUNTER + (id))
-
-#define PIC_TIMER_0_MAXVAL   PIC_SYS_TIMER_0_MAX_VAL
-#define PIC_TIMER_0_COUNTER  PIC_SYS_TIMER_0_COUNTER
-#define PIC_TIMER_7_MAXVAL   PIC_SYS_TIMER_MAX_VAL(7)
-#define PIC_TIMER_7_COUNTER  PIC_SYS_TIMER_COUNTER(7)
-#define PIC_TIMER_6_MAXVAL   PIC_SYS_TIMER_MAX_VAL(6)
-#define PIC_TIMER_6_COUNTER  PIC_SYS_TIMER_COUNTER(6)
-
-#define PIC_INT_THR_ENABLE_0_N01   0x2a
-#define PIC_INT_THR_ENABLE_0_N23   0x2b
-#define PIC_INT_THR_ENABLE_N01(id) (PIC_INT_THR_ENABLE_0_N12 + ((id) * 2))
-#define PIC_INT_THR_ENABLE_N23(id) (PIC_INT_THR_ENABLE_0_N12 + ((id) * 2))
-
-#define PIC_IRT_0   0x3a
-#define PIC_IRT(id) (PIC_IRT_0 + (id))
-
-#define PIC_IRT_WD_0        PIC_IRT(PIC_IRT_WD0_INDEX)
-#define PIC_IRT_WD_1        PIC_IRT(PIC_IRT_WD1_INDEX)
-#define PIC_IRT_TIMER_0     PIC_IRT(PIC_IRT_TIMER_0_INDEX)
-#define PIC_IRT_TIMER_1     PIC_IRT(PIC_IRT_TIMER_1_INDEX)
-#define PIC_IRT_TIMER_2     PIC_IRT(PIC_IRT_TIMER_2_INDEX)
-#define PIC_IRT_TIMER_3     PIC_IRT(PIC_IRT_TIMER_3_INDEX)
-#define PIC_IRT_TIMER_4     PIC_IRT(PIC_IRT_TIMER_4_INDEX)
-#define PIC_IRT_TIMER_5     PIC_IRT(PIC_IRT_TIMER_5_INDEX)
-#define PIC_IRT_TIMER_6     PIC_IRT(PIC_IRT_TIMER_6_INDEX)
-#define PIC_IRT_TIMER_7     PIC_IRT(PIC_IRT_TIMER_7_INDEX)
-#define PIC_IRT_CLOCK       PIC_IRT_TIMER_7
-#define PIC_IRT_UART_0      PIC_IRT(PIC_IRT_UART_0_INDEX)
-#define PIC_IRT_UART_1      PIC_IRT(PIC_IRT_UART_1_INDEX)
-#define PIC_IRT_I2C_0       PIC_IRT(PIC_IRT_I2C_0_INDEX)
-#define PIC_IRT_I2C_1       PIC_IRT(PIC_IRT_I2C_1_INDEX)
-
-#define PIC_CLOCK_TIMER     7
-#define PIC_IRQ_BASE        8
-
-#define ASM_XLP_IO_PIC_OFFSET        0xffffffffb8004100 /* TODO: This will change in to function */
-#define C_XLP_IO_PIC_OFFSET        0xffffffffb8004100ULL /* TODO: This will change in to function */
-
-#ifndef __ASSEMBLY__
-enum {
-	WD0 = 0,
-	WD1 = 1
-};
-extern int irt_irq_table[PIC_NUM_IRTS][4];
-extern int find_irt_from_irq(int irq_num);
-extern int nlm_hal_request_shared_irq(int irt);
-extern void nlm_hal_unrequest_shared_irq(int irt);
-extern void nlm_hal_set_irt_to_cpu(int irt,int cpu);
-extern void nlm_hal_set_irq_to_cpu(int irq,int cpu);
-
-static __inline__ int nlm_hal_irt_to_irq(int irt_num)
-{
-	if(irt_num < 0 || irt_num > PIC_NUM_IRTS)
-		return -1;
-
-	return irt_irq_table[irt_num][0];
-}
-
-static __inline__ int nlm_hal_irq_to_irt(int irq_num)
-{
-	int irt = find_irt_from_irq(irq_num);
-	return irt;
-}
-
-static __inline__ int nlm_hal_is_shared_irt(int irt_num)
-{
-	return irt_irq_table[irt_num][1];
-}
-
-#define PIC_IRT_FIRST_IRQ        (PIC_IRQ_BASE)
-#define PIC_WD_0_IRQ             nlm_hal_irt_to_irq(PIC_IRT_WD_0_INDEX)
-#define PIC_WD_1_IRQ             nlm_hal_irt_to_irq(PIC_IRT_WD_1_INDEX)
-#define PIC_TIMER_0_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_0_INDEX)
-#define PIC_TIMER_1_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_1_INDEX)
-#define PIC_TIMER_2_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_2_INDEX)
-#define PIC_TIMER_3_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_3_INDEX)
-#define PIC_TIMER_4_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_4_INDEX)
-#define PIC_TIMER_5_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_5_INDEX)
-#define PIC_TIMER_6_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_6_INDEX)
-#define PIC_TIMER_7_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_7_INDEX)
-#define PIC_CLOCK_IRQ            (PIC_TIMER_7_IRQ)
-#define PIC_UART_0_IRQ           17
-#define PIC_UART_1_IRQ           18
-#define PIC_I2C_0_IRQ            nlm_hal_irt_to_irq(PIC_IRT_I2C_0_INDEX)
-#define PIC_I2C_1_IRQ            nlm_hal_irt_to_irq(PIC_IRT_I2C_1_INDEX)
-#define PIC_GPIO_IRQ(num)        nlm_hal_irt_to_irq(PIC_IRT_GPIO_INDEX(num))
-#define PIC_IRT_LAST_IRQ_        (PIC_IRQ_BASE + PIC_NUM_IRTS - 1)
-#define PIC_IRT_LAST_IRQ()       PIC_IRT_LAST_IRQ_
-
-/*
- *   Misc
- */
-#define IRT_VALID       	1
-#define LOCAL_SCHEDULING    1
-#define GLOBAL_SCHEDULING   0
-#define PIC_IRQ_IS_IRT(irq) ((irq >= PIC_IRT_FIRST_IRQ) && (irq <= PIC_IRT_LAST_IRQ_))
-#define PIC_IRQ_IS_EDGE_TRIGGERED(irq) 0 // XLP interrupts are level triggered
-
-/*
- *
- */
-
-#define NODE_OFFSET(node) ((node) << 18)
-#define CPU_TO_NODE(cpu) ((cpu) >> 5)
-
-static __inline__ int nlm_hal_cpu_id(void)
-{
-	int cpu;
-
-	__asm__ __volatile__ (
-		".set push\n"
-		".set noreorder\n"
-		".set mips32\n"
-		"mfc0 %0, $15, 1\n"
-		"andi %0, %0, 0x3ff\n"
-		".set pop\n"
-		: "=r"(cpu)
-		);
-
-	return cpu;
-}
-
-#define XLP_IO_PIC_OFFSET        C_XLP_IO_PIC_OFFSET
-
-typedef volatile unsigned long long pic_reg_t;
-
-static __inline__ pic_reg_t* nlm_hal_pic_offset(void)
-{
-	uint32_t cpu = nlm_hal_cpu_id();
-
-	return ( (pic_reg_t *) (unsigned long) (XLP_IO_PIC_OFFSET + NODE_OFFSET( CPU_TO_NODE(cpu) )) );
-}
-
-static __inline__ void nlm_hal_write_pic_reg(pic_reg_t *base, unsigned int offset, unsigned long long value)
-{
-	base[offset] = value;
-}
-static __inline__ unsigned long long nlm_hal_read_pic_reg(pic_reg_t *base, unsigned int offset)
-{
-	return ((base)[offset]);
-}
-
-static __inline__ void nlm_hal_pic_send_ipi(int nmi, int vec, int node, int cpu)
-{
-	pic_reg_t *mmio = nlm_hal_pic_offset();
-
-	unsigned long long ipi = (nmi << 31) | (vec << 20) | (node << 17) | (1 << (cpu & 0xf));
-	if (cpu > 15) {
-		ipi |= 0x10000; // Setting bit 16 to select cpus 16-31
-	}
-
-	nlm_hal_write_pic_reg(mmio, PIC_IPI_CTL, ipi);
-}
-
-static __inline__ unsigned long long nlm_hal_pic_read_control(void)
-{
-	pic_reg_t *mmio = nlm_hal_pic_offset();
-
-	return nlm_hal_read_pic_reg(mmio, PIC_CTRL);
-}
-
-static __inline__ void nlm_hal_pic_write_control(unsigned long long control)
-{
-	pic_reg_t *mmio = nlm_hal_pic_offset();
-
-	nlm_hal_write_pic_reg(mmio, PIC_CTRL, control);
-}
-
-static __inline__ void nlm_hal_pic_update_control(unsigned long long control)
-{
-	pic_reg_t *mmio = nlm_hal_pic_offset();
-
-	nlm_hal_write_pic_reg(mmio, PIC_CTRL, (control | nlm_hal_read_pic_reg(mmio, PIC_CTRL)));
-}
-
-static __inline__ void nlm_hal_ack_pic(int irt_num)
-{
-	pic_reg_t *mmio = nlm_hal_pic_offset();
-
-	nlm_hal_write_pic_reg(mmio, PIC_INT_ACK, irt_num);
-
-	/* Ack the Status register for Watchdog & System timers */
-	if (irt_num < 12) {
-		nlm_hal_write_pic_reg(mmio, PIC_STATUS, (1 << irt_num));
-	}
-}
-
-static __inline__ unsigned long long nlm_hal_pic_read_irt(int irt_num)
-{
-	pic_reg_t *mmio = nlm_hal_pic_offset();
-
-	return nlm_hal_read_pic_reg(mmio, PIC_IRT(irt_num));
-}
-
-static __inline__ void nlm_hal_pic_write_irt(int irt_num, int en, int nmi, int sch, int vec, int dt, int db, int dte)
-{
-	pic_reg_t *mmio = nlm_hal_pic_offset();
-
-	unsigned long long val = (((en & 0x1) << 31) | ((nmi & 0x1) << 29) | ((sch & 0x1) << 28) |
-				  ((vec & 0x3f) << 20) | ((dt & 0x1 ) << 19) | ((db & 0x7) << 16) |
-				  (dte & 0xffff));
-
-	nlm_hal_write_pic_reg(mmio, PIC_IRT(irt_num), val);
-}
-
-#define CPUIDBITS01(X) ((X) & 0x3)
-#define CPUIDBIT2(X) ((X >> 2) & 0x1)
-
-static __inline__ void nlm_hal_pic_write_irt_direct(int irt_num, int en, int nmi, int sch, int vec, int cpu)
-{
-	nlm_hal_pic_write_irt(irt_num, en, nmi, sch, vec, 1, CPUIDBIT2(cpu), CPUIDBITS01(cpu));
-	/* Does not support multi node support yet */
-}
-
-static __inline__ unsigned long long nlm_hal_pic_read_timer(int timer)
-{
-	pic_reg_t *mmio = nlm_hal_pic_offset();
-
-	return nlm_hal_read_pic_reg(mmio, PIC_SYS_TIMER_COUNTER(timer));
-}
-
-static __inline__ void nlm_hal_pic_write_timer(int timer, pic_reg_t value)
-{
-	pic_reg_t *mmio = nlm_hal_pic_offset();
-
-	nlm_hal_write_pic_reg(mmio, PIC_SYS_TIMER_COUNTER(timer), value);
-}
-
-#endif /* __ASSEMBLY__ */
-
-#endif /* _NLM_HAL_PIC_H */
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_sys.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_sys.h
new file mode 100644
index 0000000..c780243
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_sys.h
@@ -0,0 +1,64 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (``Netlogic''). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+#ifndef _NLH_SYS_H
+#define _NLH_SYS_H
+#if !defined(__KERNEL__) && !defined(NLM_HAL_UBOOT)
+#include <stdint.h>
+#endif
+
+#define COUNT_OF(x) ((sizeof(x)/sizeof(0[x])) / ((size_t)(!(sizeof(x) % sizeof(0[x])))))
+
+/* TODO: Griffin support for different REFCLKs. */
+/* 133.333 MHz Reference Clock */
+#define REF_CLK_NUM 400000000ULL
+#define REF_CLK_DEN 3ULL
+
+/* 1 MHz resolution for frequency setting */
+#define FREQ_RESOLUTION 1000000ULL
+
+enum soc_dfs_device {
+	DFS_DEVICE_NAE_2X = 1,
+	DFS_DEVICE_SAE,
+	DFS_DEVICE_RSA,
+	DFS_DEVICE_DTRE,
+	DFS_DEVICE_CMP,
+	DFS_DEVICE_KBP,
+	DFS_DEVICE_DMC,
+	DFS_DEVICE_NAND,
+	DFS_DEVICE_MMC,
+	DFS_DEVICE_NOR,
+	DFS_DEVICE_CORE,
+	DFS_DEVICE_REGEX_SLOW,
+	DFS_DEVICE_REGEX_FAST,
+	DFS_DEVICE_SATA,
+	INVALID_DFS_DEVICE = 0xFF
+};
+
+extern uint64_t nlm_hal_get_soc_freq(int node, enum soc_dfs_device device);
+extern uint64_t nlm_hal_set_soc_freq(int node, enum soc_dfs_device device, uint64_t freq);
+extern uint64_t nlm_hal_get_core_freq(int node, uint8_t core);
+extern uint64_t nlm_hal_set_core_freq(int node, uint8_t core, uint64_t freq);
+extern unsigned long long nlm_hal_cpu_freq(void);
+#endif
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_xlp_dev.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_xlp_dev.h
index 58aa764..14cffa2 100644
--- a/arch/mips/include/asm/netlogic/hal/nlm_hal_xlp_dev.h
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_xlp_dev.h
@@ -25,6 +25,13 @@ THE POSSIBILITY OF SUCH DAMAGE.
 
 #ifndef NLM_HAL_XLP_DEV_H
 #define NLM_HAL_XLP_DEV_H
+
+#define NLM_MAX_NODES           4
+
+#define MAX_VC_PERTHREAD        4
+
+#define XLP_CACHELINE_SIZE	64
+
 /*
  * This File has all the XLP Device specific Defines
  */
@@ -32,6 +39,53 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #define XLP_PCIE_DEV_BLK_SIZE 0x8000 // 4k per function  and 8 function in a dev block
 #define XLP_PCIE_BUS_BLK_SIZE (256 * XLP_PCIE_DEV_BLK_SIZE)
 
+/*CPU ID information */
+#define EFUSE_CFG6_CPUID_MASK  0xff
+
+
+
+/*Revision no.*/
+#define XLP_REVISION_A0 	0x00
+#define XLP_REVISION_A1 	0x01
+#define XLP_REVISION_A2 	0x02
+#define XLP_REVISION_B0	 	0x03
+
+/*XLP8XX/4XX B0 and A2 supported apis*/
+#define CHIP_PROCESSOR_ID_XLP_8_4_XX 0x10
+
+/*XLP 8XX/4XX  A0,A1,A2 chip support*/
+#define CHIP_PROCESSOR_ID_XLP_8XX   0x00
+#define CHIP_PROCESSOR_ID_XLP_832   CHIP_PROCESSOR_ID_XLP_8_4_XX
+#define CHIP_PROCESSOR_ID_XLP_816   0x14
+#define CHIP_PROCESSOR_ID_XLP_432   0x90
+#define CHIP_PROCESSOR_ID_XLP_416   0x94
+#define CHIP_PROCESSOR_ID_XLP_408   0x95
+#define CHIP_PROCESSOR_ID_XLP_208   0xB5
+#define CHIP_PROCESSOR_ID_XLP_204   0xB7
+#define CHIP_PROCESSOR_ID_XLP_104   0xF7
+
+/*3XX series*/
+#define CHIP_PROCESSOR_ID_XLP_3XX   0x11
+		#define CPU_EXTPID_XLP_3XX_NONE     0x00    /* Default */
+		#define CPU_EXTPID_XLP_3XX_L        0x01    /* Lite */
+		#define CPU_EXTPID_XLP_3XX_LP       0x02    /* Lite Plus */
+		#define CPU_EXTPID_XLP_3XX_LP2      0x03    /* Lite Plus */
+
+/*2XX series */
+#define CHIP_PROCESSOR_ID_XLP_2XX   0x12
+
+/*1XX series */
+#define CHIP_PROCESSOR_ID_XLP_1XX   0x13
+
+/*9XX series */
+#define CHIP_PROCESSOR_ID_XLP_9XX   0x15
+
+/*Revision no.*/
+#define XLP_REVISION_A0 	0x00
+#define XLP_REVISION_A1 	0x01
+#define XLP_REVISION_A2 	0x02
+#define XLP_REVISION_B0	 	0x03
+
 /*
  *    FMN
  */
@@ -84,6 +138,47 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #define XLP_NET_VC_BASE         XLP_NET_TX_VC_BASE
 #define XLP_NET_VC_LIMIT        1023
 
+#define XLP_POPQ_VC_BASE	128
+#define XLP_POPQ_VC_LIMIT	255
+
+#define XLP_CPU0_VC_BASE	0
+#define XLP_CPU0_VC_LIMIT       15
+#define XLP_CPU1_VC_LIMIT       31
+#define XLP_CPU2_VC_LIMIT       47
+#define XLP_CPU3_VC_LIMIT       63
+#define XLP_CPU4_VC_LIMIT       79
+#define XLP_CPU5_VC_LIMIT       95
+#define XLP_CPU6_VC_LIMIT       111
+#define XLP_CPU7_VC_LIMIT       127
+
+// XLP_3XX
+
+#define XLP_3XX_MAX_NAE_UCORES	8
+
+#define XLP_3XX_REGEX_VC_BASE       268
+#define XLP_3XX_REGEX_VC_LIMIT      271
+
+#define XLP_3XX_RSA_ECC_VC_BASE     272
+#define XLP_3XX_RSA_ECC_VC_LIMIT    275
+
+#define XLP_3XX_CRYPTO_VC_BASE      276
+#define XLP_3XX_CRYPTO_VC_LIMIT     279
+
+#define XLP_3XX_SRIO_VC_BASE        280
+#define XLP_3XX_SRIO_VC_LIMIT       288
+
+
+#define XLP_3XX_POE_VC_BASE         384
+#define XLP_3XX_POE_VC_LIMIT        391
+#define XLP_3XX_NET_TX_VC_BASE      432
+#define XLP_3XX_NET_TX_VC_LIMIT     495
+#define XLP_3XX_NET_RX_VC_BASE      496
+#define XLP_3XX_NET_RX_VC_LIMIT     503 // 511
+#define XLP_3XX_NET_VC_BASE	      XLP_3XX_NET_TX_VC_BASE	
+#define XLP_3XX_NET_VC_LIMIT        511
+
+#define XLP_3XX_INVALID_STATION		512
+
 /*Sw Code */
 #define XLP_CODE_MAC		0
 #define XLP_CODE_SEC		1	
@@ -116,13 +211,72 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #define XLP_DTR_CHANNEL_CONTROL_REG_3   0x4B
 
 /* Crypto related */
-#define XLP_CRYPTO_NODE                    0x0
-#define XLP_CRYPTO_BUS                     0x0
-#define XLP_CRYPTO_DEVICE                  0x5
-#define XLP_CRYPTO_FUNC                    0x1
+#define XLP_CRYPTO_NODE                 0x0
+#define XLP_CRYPTO_BUS                  0x0
+#define XLP_CRYPTO_DEVICE               0x5
+#define XLP_CRYPTO_FUNC                 0x1
+ 
+/*RSA related */
+#define XLP_RSA_NODE                    0x0
+#define XLP_RSA_BUS                     0x0
+#define XLP_RSA_DEVICE                  0x5
+#define XLP_RSA_FUNC                    0x2
+ 
+/*CDE related */
+#define XLP_CDE_NODE                    0x0
+#define XLP_CDE_BUS                     0x0
+#define XLP_CDE_DEVICE                  0x5
+#define XLP_CDE_FUNC                    0x3
+
+/* XLP Storm Regex related */
+#define XLP_3XX_REGEX_NODE		0x0
+#define XLP_3XX_REGEX_BUS		0x0
+#define XLP_3XX_REGEX_DEVICE		0x5
+#define XLP_3XX_REGEX_FUNC		0x5
+
+#define XLP_IO_DEVICE			0x0
+#define XLP_IO_FUNC	                0x0
+
+#define XLP_FMN_DEVICE			0x4
+#define XLP_FMN_FUNC			0x0
+
+#define XLP_NAE_DEVICE			0x3
+#define XLP_NAE_FUNC			0x0
+
+#define XLP_POE_DEVICE			0x3
+#define XLP_POE_FUNC			0x1
+
+#define XLP_SAE_DEVICE			0x5
+#define XLP_SAE_FUNC			0x1
+
+#define XLP_RSA_DEVICE			0x5
+#define XLP_RSA_FUNC			0x2
+
+#define XLP_SYS_DEVICE			0x6
+#define XLP_SYS_FUNC			0x5
+
+#define XLP_MAXDEV_PERNODE		8
+
+#define XLP_CFG_BASE(node, SOC)		((((node * XLP_MAXDEV_PERNODE) + SOC##_DEVICE) << 15) | (SOC##_FUNC << 12))
+		
 
 #ifndef __ASSEMBLY__
 /* Device Id: Bus[8:6], Dev[5:3], func[2:0] */
+
+enum sae_cfg_regs {
+  SECCONENGSL0 = 0x41,
+  SECCONENGSL1 = 0x42,
+  SECCONENGSL2 = 0x43,
+  SECCONENGSL3 = 0x44,
+  SECCONENGSL4 = 0x45,
+  SECCONENGSL5 = 0x46,
+  SECCONENGSL6 = 0x47,
+  SECCONENGSL7 = 0x48,
+  SECCONENGSL8 = 0x49,
+  SECEMSGCTLLO = 0x82,
+  SECEMSGCTLL1 = 0x83,
+};
+
 enum NLH_DEV_ID {
   NLH_BRIDGE = 0, 
   NLH_PIC    = 4,
@@ -151,9 +305,12 @@ enum XLP_MSG_HANDLES  {
         XLP_MSG_HANDLE_PCIE1,
         XLP_MSG_HANDLE_PCIE2,
         XLP_MSG_HANDLE_PCIE3,
+	XLP_MSG_HANDLE_DTRE,
         XLP_MSG_HANDLE_GDX,
+        XLP_MSG_HANDLE_REGX,
         XLP_MSG_HANDLE_RSA_ECC,
         XLP_MSG_HANDLE_CRYPTO,
+        XLP_MSG_HANDLE_SRIO,
         XLP_MSG_HANDLE_CMP,
         XLP_MSG_HANDLE_POE,
         XLP_MSG_HANDLE_NAE_0,
@@ -167,13 +324,6 @@ enum XLP_MSG_HANDLES  {
 #define XLP_NA_REG_BLOCK_SIZE 0x2000 /* 8KB */
 #define XLP_NA_REG_IFACE_SIZE 0x200 /* 512B */
 
-enum if_type {
-	UNKNOWN_IF,
-	SGMII_IF,
-	XAUI_IF,
-	INTERLAKEN_IF
-};
-
 enum net_cfg_regs {
  RX_CONFIG                          = 0x10,
  TX_CONFIG                          = 0x11,
@@ -204,6 +354,7 @@ enum net_cfg_regs {
  CRC_POLY1_CFG                      = 0x2b,
  FREE_SPILL0_MEM_CFG                = 0x2c,
  FREE_SPILL1_MEM_CFG                = 0x2d,
+ FREE_FIFO_THRESHOLD_CFG    	    = 0x2e,
  FREE_FIFO_THRESHOLDS_CFG           = 0x87,
  FLOW_CRC16_POLY_CFG                = 0x2f,
  DMA_TX_CREDIT_TH                   = 0x29,
@@ -236,11 +387,13 @@ enum net_cfg_regs {
  TX_PKTLEN_PMEM_STATUS              = 0x4b,
  TX_SCHED_MAP_CMD0                  = 0x4c,
  TX_SCHED_MAP_CMD1                  = 0x4d,
+ EGR_NIOR_CAL_LEN_REG       	    = 0x4e,
+ EGR_NIOR_CRDT_CAL_PROG     	    = 0x52,
  TX_SCHED_MAP_STATUS0               = 0x387,
  TX_SCHED_MAP_STATUS1               = 0x388,
  TX_PKT_PMEM_CMD0                   = 0x50,
  TX_PKT_PMEM_CMD1                   = 0x51,
- TX_PKT_PMEM_STATUS                 = 0x52,
+ TX_PKT_PMEM_STATUS                 = 0x389,
  TX_SCHED_CTRL                      = 0x53,
  STR_PMEM_CMD                       = 0x58,
  TX_IORCRDT_INIT                    = 0x59,
@@ -249,6 +402,7 @@ enum net_cfg_regs {
  POE_CLASS_SETUP_CFG                = 0x81,
  UCORE_IFACE_MASK_CFG               = 0x82,
  FLOW_TABLE1_CFG                    = 0x84,
+ IFACE_FIFO_CFG             	    = 0x8a,
  L2_TYPE_0                          = 0x210,
  L3_CTABLE_MASK_0                   = 0x22c,
  L3_CTABLE_0_0                      = 0x230,
@@ -261,6 +415,7 @@ enum net_cfg_regs {
 enum if_cfg_regs {
   MAC_CONF1 = 0,
   MAC_CONF2 = 1,
+  SGMII_MAX_FRAME_LEN = 4,
   NETWK_INF_CTRL3_REG = 0x7c,
   NETWK_INF_CTRL_REG = 0x7f
 };
@@ -310,6 +465,11 @@ enum NAE_BLOCK_NR {
 	BLOCK_7,
 };      
 
+typedef struct {
+        unsigned int base_vc;
+        unsigned int vc_limit;
+}nlm_fmn_config_t;
+
 typedef enum PHY_LANE_INTF_TYPE {
 	LANE_DISCONNECTED,      
 	LANE_GMAC,      
@@ -343,10 +503,6 @@ enum poe_cfg_reg {
   HI_CNT_EXTBUF_ST = 113, // TBI
   HI_CNT_LOCBUF_ALLOC = 114, // TBI
   HI_CNT_EXTBUF_ALLOC = 115, // TBI
-  MODE_ERR_FLOW_ID = 116, // TBI
-  STATS_ENABLE = 117, // TBI
-  MAX_SIZE_FLOW = 118, // TBI 
-  MAX_SIZE = 119, // TBI
   DROP_CNT_DIST0 = 192, // TBI
   DROP_CNT_CLASS0 = 208, // TBI
   DROP_CNT_DIST_CLASS0 = 216, // TBI
@@ -370,9 +526,53 @@ enum poe_cfg_reg {
   MSG_STORAGE_BASE_ADR_L = 0x60,
   FBP_BASE_ADR_L = 0x62,
 };
+
+enum poe_stats_reg {
+	OO_MSG_CNT_LO = 0xa8,
+	IN_ORDER_MSG_CNT_LO,
+	LOC_BUF_STOR_CNT_LO,
+	EXT_BUF_STOR_CNT_LO,
+	LOC_BUF_ALLOC_CNT_LO,
+	EXT_BUF_ALLOC_CNT_LO,
+        OO_MSG_CNT_HI ,
+        IN_ORDER_MSG_CNT_HI,
+        LOC_BUF_STOR_CNT_HI,
+        EXT_BUF_STOR_CNT_HI,
+        LOC_BUF_ALLOC_CNT_HI,
+        EXT_BUF_ALLOC_CNT_HI,
+	MODE_ERR_FLOW_ID,
+	POE_STATISTICS_EN,
+	POE_MAX_SIZE_FLOW,
+	POE_MAX_SIZE	
+};
+
+#define POE_DIST_THRESHOLD_0 	0x200
+#define POE_DEST_THRESHOLD	0x204
+#define POE_DIST_ENABLE 0x205
+#define POE_DIST_VEC0	0x100
+#define POE_DIST_THRESHOLD_VAL 0xa
+#define POE_MAX_LOCAL_MSGS (6 << 10) // 6K
+#define POE_TX_TIMER     0x214
+#define POE_FBP_SP       0xb8
+#define POE_FBP_SP_EN    0xb9
+#define POE_LOC_ALLOC_EN 0xba
+#define POE_EXT_ALLOC_EN 0xbb
+#define POE_LOCAL_FBP_BASE 0x400
+
+#define POE_ENQ_SPILL_THOLD	0x208
+#define POE_DEQ_SPILL_THOLD	0x209
+#define POE_DEQ_SPILL_TIMER	0x20A
+#define POE_DISTR_CLASS_DROP_EN	0x20B	
+#define POE_DISTR_VEC_DROP_EN	0x20C
+#define POE_DISTRVEC_DROP_TIMER	0x20D
+
 #define EXT_FBP_START_ADDR       0x1800
 #define MAX_POE_EXT_MSG_STORAGE  (58 << 10) /* 58K entries */
 
+#define XLP3XX_EXT_FBP_START_ADDR	0x1000
+#define XLP3XX_POE_MAX_LOCAL_MSGS	(4 << 10)
+#define XLP3XX_MAX_POE_EXT_MSG_STORAGE 	(28 << 10)
+
 enum POE_SW_CODE {
 	DROP_IN_NAE = 0,
 	FWD_DEST,
@@ -384,32 +584,6 @@ enum POE_SW_CODE {
 	RENQ_DEST_SERIAL
 };
 
-
-enum NLM_SAE_REG_CODE
-{
-  NLM_SAE_DEVICE_INFO_REG_0 = 0x30,
-  NLM_SAE_DEVICE_INFO_REG_1 = 0x31,
-  NLM_SAE_DEVICE_INFO_REG_2 = 0x32,
-  NLM_SAE_DEVICE_INFO_REG_3 = 0x33,
-
-  NLM_SAE_ENGINE_SELECT_REG_0 = 0x41,
-  NLM_SAE_ENGINE_SELECT_REG_1 = 0x42,
-  NLM_SAE_ENGINE_SELECT_REG_2 = 0x43,
-  NLM_SAE_ENGINE_SELECT_REG_3 = 0x44,
-  NLM_SAE_ENGINE_SELECT_REG_4 = 0x45,
-  NLM_SAE_ENGINE_SELECT_REG_5 = 0x46,
-  NLM_SAE_ENGINE_SELECT_REG_6 = 0x47,
-  NLM_SAE_ENGINE_SELECT_REG_7 = 0x48,
-
-  NLM_SAE_INGRESS_MSG_CNTR_LOW = 0x87,
-  NLM_SAE_INGRESS_MSG_CNTR_HIGH = 0x88,
-  NLM_SAE_EGRESS_MSG_CNTR_LOW = 0x89,
-  NLM_SAE_EGRESS_MSG_CNTR_HIGH = 0x8A,
-
-  NLM_SAE_NUM_CIPHER_BYTE_BASE = 0x91,
-  NLM_SAE_NUM_HASH_BYTE_BASE = 0x93,
-  NLM_SAE_NUM_VC = 0x10,
-};
 /*
  *  UCORE
  */
@@ -506,35 +680,68 @@ enum sys_cfg_regs {
     SYS_INT_STATUS          = 53,
     SYS_INT_EN0             = 54,
     SYS_INT_EN1             = 55,
-    SYS_UCO_S_ECC           = 56,
-    SYS_UCO_M_ECC           = 57,
-    SYS_UCO_ADDR            = 58,
-    SYS_UCO_INST            = 59,
-    MEM_BIST0               = 60,
-    MEM_BIST1               = 61,
-    MEM_BIST2               = 62,
-    MEM_BIST3               = 63,
-    MEM_BIST4               = 64,
-    MEM_BIST5               = 65,
-    MEM_BIST6               = 66,
-    MEM_BIST7               = 67,
-    MEM_BIST8               = 68,
-    MEM_BIST9               = 69,
-    MEM_BIST10              = 70,
-    MEM_BIST11              = 71,
-    MEM_BIST12              = 72,
-    SCRATCH0                = 73,
-    SCRATCH1                = 74,
-    SCRATCH2                = 75,
-    SCRATCH3                = 76,
+    PLL_DFS_DIS_CTRL        = 56,
+    PLL_DFS_RST_CTRL        = 57,
+    PLL_DFS_BYP_CTRL        = 58,
+    PLL_DFS_DIV_INC_CTRL    = 59,
+    PLL_DFS_DIV_DEC_CTRL    = 60,
+    PLL_DFS_DIV_VALUE       = 61,
+    SYS_DISABLE             = 62,
+    SYS_UCO_S_ECC           = 63,
+    SYS_UCO_M_ECC           = 64,
+    SYS_UCO_ADDR            = 65,
+    SYS_UCO_INST            = 66,
+    MEM_BIST0               = 67,
+    MEM_BIST1               = 68,
+    MEM_BIST2               = 69,
+    MEM_BIST3               = 70,
+    MEM_BIST4               = 71,
+    MEM_BIST5               = 72,
+    MEM_BIST6               = 73,
+    MEM_BIST7               = 74,
+    MEM_BIST8               = 75,
+    MEM_BIST9               = 76,
+    MEM_BIST10              ,
+    MEM_BIST11              ,
+    MEM_BIST12              ,
+    SCRATCH0                ,
+    SCRATCH1                ,
+    SCRATCH2                ,
+    SCRATCH3
 };
 
-#define nlm_hal_read_sys_reg(index) \
-	nlm_hal_read_32bit_reg((xlp_sys_base + 0x100), (index))
+#define nlm_hal_read_sys_reg(node, index) \
+        nlm_hal_read_32bit_reg((xlp_sys_base[node] + 0x100), (index))
+
+#define nlm_hal_write_sys_reg(node, index, val) \
+        nlm_hal_write_32bit_reg((xlp_sys_base[node] + 0x100), (index), (val))
+
+#define nlm_hal_read_sae_reg(reg) \
+        nlm_hal_read_32bit_reg((xlp_sae_base), (reg))
+
+#define nlm_hal_write_sae_reg(reg, val) \
+        nlm_hal_write_32bit_reg ((xlp_sae_base), (reg), (val))
+
+#define nlm_hal_read_rsa_reg(reg) \
+        nlm_hal_read_32bit_reg((xlp_rsa_base), (reg))
+
+#define nlm_hal_write_rsa_reg(reg, val) \
+        nlm_hal_write_32bit_reg ((xlp_rsa_base), (reg), (val))
+
+#if 0
+#define nlm_hal_read_sae_reg(node, reg) \
+        nlm_hal_read_32bit_reg((xlp_sae_base[node]), (reg))
+
+#define nlm_hal_write_sae_reg(node, reg, val) \
+        nlm_hal_write_32bit_reg ((xlp_sae_base[node]), (reg), (val))
+
+#define nlm_hal_read_rsa_reg(node, reg) \
+        nlm_hal_read_32bit_reg((xlp_rsa_base[node]), (reg))
 
-#define nlm_hal_write_sys_reg(index, val) \
-	nlm_hal_write_32bit_reg((xlp_sys_base + 0x100), (index), (val))
+#define nlm_hal_write_rsa_reg(node, reg, val) \
+        nlm_hal_write_32bit_reg ((xlp_rsa_base[node]), (reg), (val))
 
+#endif
 enum {
 	PHYMODE_NONE = 0,
 	PHYMODE_HS_SGMII = 1,
@@ -664,6 +871,7 @@ enum {
     #define EXT_G_MDIO_CMD_RDS          0x00040000
     #define EXT_G_MDIO_CMD_SC           0x00080000
     #define EXT_G_MDIO_MMRST            0x00100000
+    #define EXT_G_MDIO_DIV              0x0000001E	
 
 #define EXT_G0_MDIO_CTRL_DATA           0x1E
 #define EXT_G1_MDIO_CTRL_DATA           0x22
@@ -950,6 +1158,17 @@ enum {
 
 #define ILK_BURST_MAX           	3 // 256 bytes   
 
+#define XLP_ILK_LANE_RATE_LOW           0       // 0, 19, 0
+#define XLP_ILK_LANE_RATE_HIDH          1       // 1, 19, 0
+
+#define XLP_ILK_PORT_0                  0
+#define XLP_ILK_PORT_1                  8
+
+#define XLP_ILK_PORT0_CS                3
+#define XLP_ILK_PORT1_CS                4
+
+#define XLP_ILK_MAX_LANES               8
+
 // SPI 
 #define XLP_SPI_CONFIG			0x40
     #define XLP_SPI_CPHA		0x01
@@ -1064,7 +1283,7 @@ enum {
     #define USB_OHCI_INTERRUPT1_EN  	0x04
     #define USB_OHCI_INTERRUPT12_EN 	0x08
     #define USB_CTRL_INTERRUPT_EN   	0x10
-
+#ifndef NLM_HAL_LINUX_KERNEL		// This is not applicable in Linux
 #define XLP_NOR_IRQ			20
 #define XLP_NAND_IRQ			21
 #define XLP_SPI_IRQ			22
@@ -1076,6 +1295,7 @@ enum {
 #define XLP_NAND_IRT			151
 #define XLP_SPI_IRT			152
 #define XLP_MMC_IRT			153
+#endif
 
 #define XLP_PCIE_SPI_NOR_FLASH_DEV	7
 #define XLP_PCIE_SPI_NOR		0
@@ -1123,5 +1343,129 @@ enum {
 #define XLP_GPIO_INT1_IRT       	147
 #define XLP_GPIO_INT2_IRT       	148
 #define XLP_GPIO_INT3_IRT       	149
+
+// NOR Flash memory interface
+
+#define NLM_NOR_BUS_NUM        0
+#define NLM_NOR_DEV_NUM        7
+#define NLM_NOR_FUN_NUM        0
+
+#define NLM_NOR_CFG_BASE        ( 0x18000000 | (NLM_NOR_DEV_NUM << 15) | (NLM_NOR_FUN_NUM << 12))
+
+#define XLP_NOR_CS_BASE         0x40
+#define XLP_NOR_CS_LIMIT        0x48
+#define XLP_NOR_DEVPARAM        0x50
+#define XLP_NOR_DEV_TIME0       0x58
+#define XLP_NOR_DEV_TIME1       0x59
+
+
+#define NAE_CLK_DIV		0x1
+#define SAE_CLK_DIV		0x2
+
+#ifdef NLM_HAL_LINUX_KERNEL
+#define DFS_OUTPUT(DR, DF, DV)  ((400/((DR+1) * 3)) * (DF+1) * 2)/(DV+1)
+#else
+#define DFS_OUTPUT(DR, DF, DV)  ((133.33/(DR+1)) * (DF+1) * 2)/(DV+1)
+#endif
+
 #endif /*__ASSEMBLY__*/
+
+/* SATA related */
+
+/* SATA CONTROLLER PORT REGISTERS */
+#define SataCLB           0x00
+#define SataCLBU          0x04
+#define SataFB            0x08
+#define SataFBU           0x0c
+#define SataIS            0x10
+#define SataIE            0x14
+#define SataCMD           0x18
+#define SataTFD           0x20
+#define SataSIG           0x24
+#define SataSSTS          0x28
+#define SataSCTL          0x2c
+#define SataSERR          0x30
+#define SataSACT          0x34
+#define SataCI            0x38
+#define SataSNTF          0x3c
+#define SataFBS           0x40
+#define SataDMACR         0x70
+#define SataPHYCR         0x78
+#define SataPHYSTS        0x7c
+
+#define ECFG_BASE               0xffffffffb8000000ULL
+#define SATA_DEV_NUM            3
+#define SATA_FUNC_NUM           2
+#define XLP_IO_SATA_BASE        (ECFG_BASE | (SATA_DEV_NUM << 15) | (SATA_FUNC_NUM << 12))
+
+// #define XLP_MEM_SATA_BASE       0xd0042000
+// #define wr_sata_mem_reg(offset, val)            sw_40bit_phys_uncached(((uint64_t)XLP_MEM_SATA_BASE) + (offset), val)
+// #define rd_sata_mem_reg(offset)                 lw_40bit_phys_uncached(((uint64_t)XLP_MEM_SATA_BASE) + (offset))
+
+#define wr_sata_glue_reg(offset, val)           write_32bit_cfg_reg((uint32_t *)(XLP_IO_SATA_BASE + 0x900), (offset >> 2), val)
+#define rd_sata_glue_reg(offset)                read_32bit_cfg_reg((uint32_t *)(XLP_IO_SATA_BASE + 0x900), (offset >> 2))
+
+#define set_sata_glue_reg(offset, bit)          wr_sata_glue_reg(offset, (rd_sata_glue_reg(offset) | bit))
+#define clear_sata_glue_reg(offset, bit)        wr_sata_glue_reg(offset, (rd_sata_glue_reg(offset) & ~bit))
+
+#define SATA_CTL                0x00    // 
+#define SATA_STATUS             0x04    // SATA Status register
+#define SATA_INT                0x08    // SATA Interrupt Register
+#define SATA_INT_MASK           0x0c    // SATA Interrupt Mask Register
+#define SATA_CR_REG_TIMER       0x10    // PHY Conrol Timer Register
+#define SATA_CORE_ID            0x14    // SATA Core ID Register
+#define SATA_AXI_SLAVE_OPT1     0x18    // SATA AXI Slave Options Register
+#define SATA_PHY_LOS_LEV        0x1c    // SATA PHY LOS Level Register 
+#define SATA_PHY_MULTI          0x20    // SATA PHY Multiplier Register         
+#define SATA_PHY_CLK_SEL        0x24    // SATA PHY Clock Select Register
+#define SATA_PHY_AMP1_GEN1      0x28    // SATA PHY Transmit Amplitude Register 1   
+#define SATA_PHY_AMP1_GEN2      0x2c    // SATA PHY Transmit Amplitude Register 2   
+#define SATA_PHY_AMP1_GEN3      0x30    // SATA PHY Transmit Amplitude Register 3   
+#define SATA_PHY_PRE1           0x34    // SATA PHY Transmit Preemphasis Register 1
+#define SATA_PHY_PRE2           0x38    // SATA PHY Transmit Preemphasis Register 2
+#define SATA_PHY_PRE3           0x3c    // SATA PHY Transmit Preemphasis Register 3
+#define SATA_SPDMODE            0x40    // SATA Speed Mode Register
+#define SATA_REFCLK             0x44    // SATA Reference Clock Control Register
+#define SATA_BYTE_SWAP_DIS	0x74    // SATA byte swap disable
+
+//SATA_CTL Bits
+#define SATA_RST_N      (1 << 0)
+#define PHY0_RESET_N    (1 << 16)
+#define PHY1_RESET_N    (1 << 17)
+#define PHY2_RESET_N    (1 << 18)
+#define PHY3_RESET_N    (1 << 19)
+#define M_CSYSREQ       (1 << 2)
+#define S_CSYSREQ       (1 << 3)
+
+//SATA_STATUS Bits
+#define P0_PHY_READY (1 << 4)
+#define P1_PHY_READY (1 << 5)
+#define P2_PHY_READY (1 << 6)
+#define P3_PHY_READY (1 << 7)
+
+//SATA CONTROLLER GENERIC HOST REGISTERS
+#define SATA_CAP                0x00
+#define SATA_GHC                0x04
+#define SATA_IS                 0x08
+#define SATA_PI                 0x0c
+#define SATA_AHCI               0x10
+#define SATA_CCC_CTL            0x14
+#define SATA_CCC_PORTS          0x18
+#define SATA_CAP2               0x24
+#define SATA_BISTAFR            0xa0
+#define SATA_BISTCR             0xa4
+#define SATA_BISTFCTR           0xa8
+#define SATA_BISTSR             0xac
+#define SATA_OOBR               0xbc
+#define SATA_TIMER1MS           0xe0
+#define Reserved5               0x0
+#define SATA_GPARAM1R           0xe8
+#define SATA_GPARAM2R           0xec
+#define SATA_PPARAMR            0xf0
+#define SATA_TESTR              0xf4
+#define SATA_VERSIONR           0xf8
+#define SATA_IDR                0xfc
+
+#define HBAReset (1 << 0)
+
 #endif /* #ifndef NLM_HAL_XLP_DEV_H */
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_nae.h b/arch/mips/include/asm/netlogic/hal/nlm_nae.h
new file mode 100644
index 0000000..ec8e9a8
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/hal/nlm_nae.h
@@ -0,0 +1,126 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef __NLM_NAE_H__
+#define __NLM_NAE_H__
+
+#ifndef __ASSEMBLY__
+#define MAX_NAE_CONTEXTS_PERNODE	524
+#define MAX_NAE_PORTS_PERNODE		18
+#define XLP_MAX_INTERLAKEN_IF		2
+
+#define NLM_MAX_NODES           4
+
+#define FREEBACK_TO_NAE		0x01
+#define VFBID_FROM_FDT		0x02
+#define FREEIN_SPILL_DYNAMIC	0x04
+#define POE_ENQSPILL_DYNAMIC	0x08
+#define POE_DEQSPILL_DYNAMIC	0x10
+#define NAE_RESET_DONE		0x20
+#define NAE_INIT_VALID		0x40
+
+struct nlm_hal_nae_port {
+        int  valid;
+        int  mgmt;
+        int  num_free_desc;
+        int  txq;
+        int  rxq;
+        int  hw_port_id;
+        int  vlan_pri_en;
+        int  iftype;
+        int  num_channels;
+	uint32_t  rx_buf_size;
+	uint32_t  intf_fifo_size;
+	uint32_t  free_desc_size;
+	uint32_t  prsr_seq_fifo_size;
+	uint32_t  rx_slots_reqd;
+	uint32_t  tx_slots_reqd;
+	uint32_t  ucore_mask;
+        int  ext_phy_addr;
+        int  ext_phy_bus;
+};
+
+struct nlm_hal_nae_config {
+        int fb_vc;
+        int rx_vc;
+        int frin_queue_base;
+        int frin_total_queue;
+        int num_ports;
+	uint32_t flags;
+	int rx_cal_slots;
+	int tx_cal_slots;
+	/* if shared is true, ucore is going to use upto 16 queues
+	 for buffer mgmt. */
+	int freein_fifo_shared;
+	/* onchip descs per queue, valid only if shared = 1 
+	 same value for all queues upto 0-15.  16 and 17 are used by mgmt port 
+	 if shared is false look at the port level num_free_desc for onchip size */
+	int freein_fifo_onchip_num_descs;
+	/* spill descs per queue, it will be added with the onchip size  */
+	int freein_fifo_spill_num_descs; 
+	uint64_t freein_spill_base;
+	uint64_t freein_spill_size;
+        struct nlm_hal_nae_port ports[MAX_NAE_PORTS_PERNODE];
+	uint32_t cntx2port[MAX_NAE_CONTEXTS_PERNODE];
+	uint32_t num_lanes[XLP_MAX_INTERLAKEN_IF];
+	uint32_t lane_rate[XLP_MAX_INTERLAKEN_IF];
+	//egress fifo 
+	uint32_t stg2fifo_base;
+	uint32_t ehfifo_base;
+	uint32_t froutfifo_base;
+	uint32_t msfifo_base;
+	uint32_t pktfifo_base;
+	uint32_t pktlenfifo_base;
+	// NAE complex map
+	uint32_t sgmii_complex_map;
+	uint32_t xaui_complex_map;
+	uint32_t ilk_complex_map;
+	// total queues used = num_contexts
+	uint32_t num_contexts;
+};
+
+typedef struct nlm_hal_nae_config * nlm_nae_config_ptr;
+
+struct nlm_node_config
+{
+        int valid;
+        int num_nodes;  // Number of nodes
+        struct nlm_hal_nae_config *nae_cfg[NLM_MAX_NODES];      // NAE configuration
+        struct fmn_cfg *fmn_cfg[NLM_MAX_NODES];
+};
+
+extern struct nlm_node_config nlm_node_cfg;
+
+enum if_type {
+        UNKNOWN_IF,
+        SGMII_IF,
+        XAUI_IF,
+        INTERLAKEN_IF
+};
+
+extern int nlm_config_vfbid_table(int node, uint32_t start, uint32_t num_entries, uint32_t *vfbid_tbl);
+extern uint32_t *cntx2port[];
+#endif
+#endif
diff --git a/arch/mips/include/asm/netlogic/interrupt.h b/arch/mips/include/asm/netlogic/interrupt.h
index 2647c16..5fa0d53 100644
--- a/arch/mips/include/asm/netlogic/interrupt.h
+++ b/arch/mips/include/asm/netlogic/interrupt.h
@@ -1,5 +1,5 @@
 /***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
 reserved.
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are
@@ -26,15 +26,18 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #ifndef _ASM_NLM_INTERRUPT_H
 #define _ASM_NLM_INTERRUPT_H
 
+#ifdef CONFIG_NLM_XLP
+#include <asm/netlogic/xlp_irq.h>
+#else
 #include <asm/netlogic/pic.h>
 
 /* Defines for the IRQ numbers */
-
-#define IRQ_MSGRING              6
+#define NR_IRQS			256
+#define IRQ_DUMMY_UART           2
 #define IRQ_IPI_SMP_FUNCTION     3
 #define IRQ_IPI_SMP_RESCHEDULE   4
 #define IRQ_REMOTE_DEBUG         5
-//#define IRQ_OPROFILE             6
+#define IRQ_MSGRING              6
 #define IRQ_TIMER                7
 #define IRQ_IPI_SMP_KGDB   		50
 #define IRQ_IPI_OPROFILE        51
@@ -42,7 +45,16 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #define IRQ_IPI_CRF_MGMT_IPI	NLM_MANAGEMENT_IPI /* */
 #define IRQ_IPI_CRF_EVENTQ_IPI  NLM_EVENTQ_IPI
 
+#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY
+
+#define IRQ_IPI_NETRX           49
+#define SMP_NETRX_IPI           32
+
+#endif /* CONFIG_NLMCOMMON_IP_FLOW_AFFINITY */
+
+
 #define SMP_CALL_KGDB_HOOK 	8
 #define SMP_OPROFILE_IPI        16
+#endif		// CONFIG_NLM_XLP
 
 #endif
diff --git a/arch/mips/include/asm/netlogic/mips-exts.h b/arch/mips/include/asm/netlogic/mips-exts.h
index c8f7164..247fe39 100644
--- a/arch/mips/include/asm/netlogic/mips-exts.h
+++ b/arch/mips/include/asm/netlogic/mips-exts.h
@@ -285,6 +285,11 @@ static __inline__ int hard_smp_processor_id(void)
 	return cpu;
 }
 
+static __inline__ int netlogic_node_id(void)
+{
+	return hard_smp_processor_id() >> 5;	
+}
+
 static __inline__ int netlogic_cpu_id(void)
 {
 	return hard_smp_processor_id() >> 2;
diff --git a/arch/mips/include/asm/netlogic/msgring.h b/arch/mips/include/asm/netlogic/msgring.h
new file mode 100644
index 0000000..5981436
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/msgring.h
@@ -0,0 +1,713 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _ASM_NLM_MSG_RING_H
+#define _ASM_NLM_MSG_RING_H
+
+#include <linux/types.h>
+
+#include <asm/asm.h>
+#include <asm/netlogic/debug.h>
+#include <asm/netlogic/mips-exts.h>
+
+#ifndef __STR
+#define __STR(x) #x
+#endif
+#ifndef STR
+#define STR(x) __STR(x)
+#endif
+
+#define find_msb_one_bit(source)                                \
+({ uint64_t __res;                                              \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\tnoreorder\n\t"					\
+        "dlco\t$8, %1\n\t"                                      \
+	".set\tpop"						\
+        : "=r" (__res): "r" (source): "$8"                      \
+        );                                                      \
+        __res;})
+
+#define read_32bit_cp2_register(source)                         \
+({ int __res;                                                   \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\treorder\n\t"					\
+        "mfc2\t%0,"STR(source)"\n\t"                            \
+	".set\tpop"						\
+        : "=r" (__res));                                        \
+        __res;})
+
+#define write_32bit_cp2_register(register,value)                \
+        __asm__ __volatile__(                                   \
+        "mtc2\t%0,"STR(register)"\n\t"				\
+	"nop"							\
+        : : "r" (value));
+
+#define read_32bit_cp2_register_sel(source, sel)                \
+({ int __res;                                                   \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips32\n\t"                                       \
+        "mfc2\t%0,"STR(source)", %1\n\t"                        \
+	".set\tpop"						\
+        : "=r" (__res) : "i" (sel) );                           \
+        __res;})
+
+#define write_32bit_cp2_register_sel(reg, value, sel)           \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips32\n\t"                                       \
+        "mtc2\t%0,"STR(reg)", %1\n\t"                           \
+	".set\tpop"						\
+        : : "r" (value), "i" (sel) );
+
+#define MSGRNG_TX_BUF_REG $0
+#define MSGRNG_RX_BUF_REG $1
+
+#define MSGRNG_MSG_STATUS_REG $2
+#define MSGRNG_MSG_CONFIG_REG $3
+
+#define MSGRNG_MSG_BUCKSIZE_REG $4
+
+#define MSGRNG_CC_0_REG  $16
+#define MSGRNG_CC_1_REG  $17
+#define MSGRNG_CC_2_REG  $18
+#define MSGRNG_CC_3_REG  $19
+#define MSGRNG_CC_4_REG  $20
+#define MSGRNG_CC_5_REG  $21
+#define MSGRNG_CC_6_REG  $22
+#define MSGRNG_CC_7_REG  $23
+#define MSGRNG_CC_8_REG  $24
+#define MSGRNG_CC_9_REG  $25
+#define MSGRNG_CC_10_REG $26
+#define MSGRNG_CC_11_REG $27
+#define MSGRNG_CC_12_REG $28
+#define MSGRNG_CC_13_REG $29
+#define MSGRNG_CC_14_REG $30
+#define MSGRNG_CC_15_REG $31
+
+#define msgrng_read_status() read_32bit_cp2_register(MSGRNG_MSG_STATUS_REG)
+
+#define msgrng_read_config() read_32bit_cp2_register(MSGRNG_MSG_CONFIG_REG)
+#define msgrng_write_config(value) write_32bit_cp2_register(MSGRNG_MSG_CONFIG_REG, value)
+
+#define msgrng_read_bucksize(bucket) read_32bit_cp2_register_sel(MSGRNG_MSG_BUCKSIZE_REG, bucket)
+#define msgrng_write_bucksize(bucket, value) write_32bit_cp2_register_sel(MSGRNG_MSG_BUCKSIZE_REG, value, bucket)
+
+#define msgrng_read_cc(reg, pri) read_32bit_cp2_register_sel(reg, pri)
+#define msgrng_write_cc(reg, value, pri) write_32bit_cp2_register_sel(reg, value, pri)
+
+#ifndef _ABI64
+#define read_64bit_cp2_register_sel(source, sel)			\
+({									\
+	unsigned int high, low;						\
+									\
+		__asm__ __volatile__(					\
+			".set\tmips64\n\t"				\
+			"dmfc2\t$8, "STR(source)","STR(sel)"\n\t"		\
+			"dsrl32\t%0, $8, 0\n\t"			        \
+                        "dsll32\t$8, $8, 0\n\t"                         \
+                        "dsrl32\t%1, $8, 0\n\t"                         \
+			".set\tmips0"					\
+			: "=r" (high), "=r"(low): "i"(sel) : "$8");	\
+	( (((unsigned long long)high)<<32) | low);					\
+})
+
+#define write_64bit_cp2_register_sel(source, val, sel)			\
+do {									\
+     unsigned int high = val>>32;                                       \
+     unsigned int low  = val & 0xffffffff;                              \
+		__asm__ __volatile__(					\
+			".set\tmips64\n\t"				\
+                        "dsll32 $8, %1, 0\n"                            \
+                        "dsll32 $9, %0, 0\n"                            \
+                        "dsrl32 $8, $8, 0\n"                            \
+                        "or     $8, $8, $9\n"				\
+			"dmtc2\t$8, "STR(source)", %2\n\t"		\
+			".set\tmips0"					\
+			: : "r" (high), "r" (low), "i"(sel): "$8", "$9");		\
+} while (0)
+
+#else
+#define read_64bit_cp2_register(source)                         \
+({ unsigned long long __res;                                    \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\treorder\n\t"					\
+        ".set\tmips64\n\t"                                      \
+        "dmfc2\t%0,"STR(source)"\n\t"                            \
+	".set\tpop"						\
+        : "=r" (__res));                                        \
+        __res;})
+
+#define write_64bit_cp2_register(register,value)                \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\treorder\n\t"					\
+        "dmtc2\t%0,"STR(register)"\n\t"				\
+	"nop"							\
+	".set\tpop"						\
+        : : "r" (value));
+
+#define read_64bit_cp2_register_sel(source, sel)                \
+({ unsigned long long __res;                                    \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips64\n\t"                                       \
+        "dmfc2\t%0,"STR(source)", %1\n\t"                        \
+	".set\tpop"						\
+        : "=r" (__res) : "i" (sel) );                           \
+        __res;})
+
+#define write_64bit_cp2_register_sel(reg, value, sel)           \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips64\n\t"                                       \
+        "dmtc2\t%0,"STR(reg)", %1\n\t"                           \
+	".set\tpop"						\
+        : : "r" (value), "i" (sel) );
+#endif
+
+#define msgrng_load_rx_msg0() read_64bit_cp2_register_sel(MSGRNG_RX_BUF_REG, 0)
+#define msgrng_load_rx_msg1() read_64bit_cp2_register_sel(MSGRNG_RX_BUF_REG, 1)
+#define msgrng_load_rx_msg2() read_64bit_cp2_register_sel(MSGRNG_RX_BUF_REG, 2)
+#define msgrng_load_rx_msg3() read_64bit_cp2_register_sel(MSGRNG_RX_BUF_REG, 3)
+
+#define msgrng_load_tx_msg0(value) write_64bit_cp2_register_sel(MSGRNG_TX_BUF_REG, value, 0)
+#define msgrng_load_tx_msg1(value) write_64bit_cp2_register_sel(MSGRNG_TX_BUF_REG, value, 1)
+#define msgrng_load_tx_msg2(value) write_64bit_cp2_register_sel(MSGRNG_TX_BUF_REG, value, 2)
+#define msgrng_load_tx_msg3(value) write_64bit_cp2_register_sel(MSGRNG_TX_BUF_REG, value, 3)
+
+/* Station IDs */
+#define MSGRNG_STNID_CPU0  0x00
+#define MSGRNG_STNID_CPU1  0x08
+#define MSGRNG_STNID_CPU2  0x10
+#define MSGRNG_STNID_CPU3  0x18
+#define MSGRNG_STNID_CPU4  0x20
+#define MSGRNG_STNID_CPU5  0x28
+#define MSGRNG_STNID_CPU6  0x30
+#define MSGRNG_STNID_CPU7  0x38
+
+#define MSGRING_STNID_DEVICES 64
+#define MSGRNG_STNID_XGS0_TX 64
+#define MSGRNG_STNID_XMAC0_00_TX 64
+#define MSGRNG_STNID_XMAC0_01_TX 65
+#define MSGRNG_STNID_XMAC0_02_TX 66
+#define MSGRNG_STNID_XMAC0_03_TX 67
+#define MSGRNG_STNID_XMAC0_04_TX 68
+#define MSGRNG_STNID_XMAC0_05_TX 69
+#define MSGRNG_STNID_XMAC0_06_TX 70
+#define MSGRNG_STNID_XMAC0_07_TX 71
+#define MSGRNG_STNID_XMAC0_08_TX 72
+#define MSGRNG_STNID_XMAC0_09_TX 73
+#define MSGRNG_STNID_XMAC0_10_TX 74
+#define MSGRNG_STNID_XMAC0_11_TX 75
+#define MSGRNG_STNID_XMAC0_12_TX 76
+#define MSGRNG_STNID_XMAC0_13_TX 77
+#define MSGRNG_STNID_XMAC0_14_TX 78
+#define MSGRNG_STNID_XMAC0_15_TX 79
+
+#define MSGRNG_STNID_XGS1_TX 80
+#define MSGRNG_STNID_XMAC1_00_TX 80
+#define MSGRNG_STNID_XMAC1_01_TX 81
+#define MSGRNG_STNID_XMAC1_02_TX 82
+#define MSGRNG_STNID_XMAC1_03_TX 83
+#define MSGRNG_STNID_XMAC1_04_TX 84
+#define MSGRNG_STNID_XMAC1_05_TX 85
+#define MSGRNG_STNID_XMAC1_06_TX 86
+#define MSGRNG_STNID_XMAC1_07_TX 87
+#define MSGRNG_STNID_XMAC1_08_TX 88
+#define MSGRNG_STNID_XMAC1_09_TX 89
+#define MSGRNG_STNID_XMAC1_10_TX 90
+#define MSGRNG_STNID_XMAC1_11_TX 91
+#define MSGRNG_STNID_XMAC1_12_TX 92
+#define MSGRNG_STNID_XMAC1_13_TX 93
+#define MSGRNG_STNID_XMAC1_14_TX 94
+#define MSGRNG_STNID_XMAC1_15_TX 95
+
+#define MSGRNG_STNID_GMAC 96
+#define MSGRNG_STNID_GMACRFR_0  97
+#define MSGRNG_STNID_GMACTX0  98
+#define MSGRNG_STNID_GMACTX1  99
+#define MSGRNG_STNID_GMACTX2  100
+#define MSGRNG_STNID_GMACTX3  101
+#define MSGRNG_STNID_GMACRFR_1  103
+
+#define MSGRNG_STNID_DMA      104
+#define MSGRNG_STNID_DMA_0    104
+#define MSGRNG_STNID_DMA_1    105
+#define MSGRNG_STNID_DMA_2    106
+#define MSGRNG_STNID_DMA_3    107
+
+#define MSGRNG_STNID_XGS0FR 112
+#define MSGRNG_STNID_XMAC0RFR 113
+
+#define MSGRNG_STNID_XGS1FR 114
+#define MSGRNG_STNID_XMAC1RFR 115
+
+#define MSGRNG_STNID_SEC 120
+#define MSGRNG_STNID_SEC0 120
+#define MSGRNG_STNID_SEC1 121
+#define MSGRNG_STNID_SEC2 122
+#define MSGRNG_STNID_SEC3 123
+#define MSGRNG_STNID_PK0  124
+
+#define MSGRNG_STNID_GMAC1      80
+#define MSGRNG_STNID_GMAC1_FR   81
+#define MSGRNG_STNID_GMAC1_TX0  82
+#define MSGRNG_STNID_GMAC1_TX1  83
+#define MSGRNG_STNID_GMAC1_TX2  84
+#define MSGRNG_STNID_GMAC1_TX3  85
+#define MSGRNG_STNID_GMAC0      96
+#define MSGRNG_STNID_GMAC0_FR   97
+#define MSGRNG_STNID_GMAC0_TX0  98
+#define MSGRNG_STNID_GMAC0_TX1  99
+#define MSGRNG_STNID_GMAC0_TX2  100
+#define MSGRNG_STNID_GMAC0_TX3  101
+#define MSGRNG_STNID_CMP_0      108
+#define MSGRNG_STNID_CMP_1      109
+#define MSGRNG_STNID_CMP_2      110
+#define MSGRNG_STNID_CMP_3      111
+#define MSGRNG_STNID_PCIE_0     116
+#define MSGRNG_STNID_PCIE_1     117
+#define MSGRNG_STNID_PCIE_2     118
+#define MSGRNG_STNID_PCIE_3     119
+#define MSGRNG_STNID_XLS_PK0    121
+
+#define MSGRNG_CODE_DEVICE         0
+#define MSGRNG_CODE_MAC            MSGRNG_CODE_DEVICE
+#define MSGRNG_CODE_XGMAC          MSGRNG_CODE_DEVICE
+#define MSGRNG_CODE_SPI4           MSGRNG_CODE_DEVICE
+#define MSGRNG_CODE_SEC            MSGRNG_CODE_DEVICE
+#define MSGRNG_CODE_BOOT_WAKEUP    200
+
+static inline int msgrng_xgmac_stid_rfr(int id)
+{
+  return !id ? MSGRNG_STNID_XMAC0RFR : MSGRNG_STNID_XMAC1RFR;
+}
+
+static inline int msgrng_xgmac_stid_tx(int id)
+{
+  return !id ? MSGRNG_STNID_XMAC0_00_TX : MSGRNG_STNID_XMAC1_00_TX;
+}
+
+static inline int msgrng_gmac_stid_rfr(int id)
+{
+  if (id & 0x4)
+      return (MSGRNG_STNID_GMAC1_FR);
+  return (MSGRNG_STNID_GMACRFR_0);
+}
+
+static inline int msgrng_gmac_stid_rfr_split_mode(int id)
+{
+  return ((id>>1)?MSGRNG_STNID_GMACRFR_1:MSGRNG_STNID_GMACRFR_0);
+}
+
+static inline int msgrng_gmac_stid_tx(int id)
+{
+  if (id & 0x4)
+      return (MSGRNG_STNID_GMAC1_TX0 + (id & 0x3));
+  return (MSGRNG_STNID_GMACTX0 + id);
+}
+
+static inline int msgrng_gmac0_stid_rfr(int id)
+{
+  return (MSGRNG_STNID_GMAC0_FR);
+}
+static inline int msgrng_gmac0_stid_tx(int id)
+{
+  return (MSGRNG_STNID_GMAC0_TX0 + id);
+}
+static inline int msgrng_gmac1_stid_rfr(int id)
+{
+  return (MSGRNG_STNID_GMAC1_FR);
+}
+static inline int msgrng_gmac1_stid_tx(int id)
+{
+  return (MSGRNG_STNID_GMAC1_TX0 + (id & 0x3));
+}
+
+static inline void msgrng_send(unsigned int stid)
+{
+  __asm__ volatile (
+		    ".set push\n"
+		    ".set noreorder\n"
+		    "sync\n"
+		    //		    "msgsnd %0\n"
+		    "move  $8, %0\n"
+		    "c2    0x80001\n"
+		    ".set pop\n"
+		    : : "r" (stid) : "$8"
+		    );
+}
+
+static inline void msgrng_receive(unsigned int pri)
+{
+  __asm__ volatile (
+		    ".set push\n"
+		    ".set noreorder\n"
+		    //		    "msgld %0\n"
+		    "move $8, %0\n"
+		    "c2   0x80002\n"
+		    ".set pop\n"
+		    : : "r" (pri) : "$8"
+		    );
+}
+
+static inline void msgrng_wait(unsigned int mask)
+{
+  __asm__ volatile (
+		    ".set push\n"
+		    ".set noreorder\n"
+		    //		    "msgwait %0\n"
+		    "move $8, %0\n"
+		    /*to ensure msgwait picks up the right bucket */
+		    ""STR(PTR_ADDU)" $8, $8, $0\n"
+		    "c2   0x80003\n"
+		    ".set pop\n"
+		    : :"r" (mask) : "$8"
+		    );
+}
+
+#ifdef CONFIG_NLM_ENABLE_COP2
+
+#define msgrng_enable(flags) 
+#define msgrng_disable(flags) 
+
+#else
+
+#define msgrng_enable(flags)                \
+do {                                        \
+  preempt_disable(); \
+  __asm__ volatile (                        \
+		    ".set push\n\t"                 \
+		    ".set reorder\n\t"              \
+		    ".set noat\n\t"                 \
+		    "mfc0 %0, $12\n\t"              \
+		    "li  $8, 0x40000001\n\t"        \
+		    "or  $1, %0, $8\n\t"            \
+		    "xori $1, 1\n\t"                \
+		    ".set noreorder\n\t"            \
+		    "mtc0 $1, $12\n\t"              \
+		    ".set\tpop\n\t"                 \
+		    : "=r" (flags)                  \
+		    :                               \
+		    : "$8"                          \
+		    );                              \
+  preempt_enable(); \
+} while (0)
+#define msgrng_disable(flags) __asm__ volatile (    \
+                 "mtc0 %0, $12" : : "r" (flags))
+
+#endif
+
+#define msgrng_flags_save(flags) msgrng_enable(flags)
+#define msgrng_flags_restore(flags) msgrng_disable(flags)
+
+struct msgrng_msg {
+  __u64 msg0;
+  __u64 msg1;
+  __u64 msg2;
+  __u64 msg3;
+};
+
+static inline void message_send_block_fast(int size, unsigned int code, unsigned int stid,
+                                         unsigned long long msg0, unsigned long long msg1,
+					 unsigned long long msg2, unsigned long long msg3)
+{
+  __asm__ __volatile__ (".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        "dmtc2 %1, "STR(MSGRNG_TX_BUF_REG)", 0\n"
+                        "dmtc2 %2, "STR(MSGRNG_TX_BUF_REG)", 1\n"
+                        "dmtc2 %3, "STR(MSGRNG_TX_BUF_REG)", 2\n"
+                        "dmtc2 %4, "STR(MSGRNG_TX_BUF_REG)", 3\n"
+		        "sync\n"
+                        "move $8, %0\n"
+                        "1: c2 0x80001\n"
+                        "mfc2 $8, "STR(MSGRNG_MSG_STATUS_REG)"\n"
+                        "andi $8, $8, 0x6\n"
+                        "bnez $8, 1b\n"
+                        "move $8, %0\n"
+                        ".set pop\n"
+                        :
+                        : "r"(((size-1)<<16)|(code<<8)|stid), "r" (msg0), "r" (msg1), "r"(msg2), "r"(msg3)
+                        : "$8"
+                        );
+}
+
+#define message_receive_fast(bucket, size, code, stid, msg0, msg1, msg2, msg3)      \
+        ( { unsigned int _status=0, _tmp=0;                     \
+           msgrng_receive(bucket);                              \
+           while ( (_status=msgrng_read_status()) & 0x08) ;     \
+           _tmp = _status & 0x30;                               \
+           if (likely(!_tmp)) {                                 \
+                 (size)=((_status & 0xc0)>>6)+1;                \
+                 (code)=(_status & 0xff00)>>8;                  \
+                 (stid)=(_status & 0x7f0000)>>16;               \
+                 (msg0)=msgrng_load_rx_msg0();                  \
+                 (msg1)=msgrng_load_rx_msg1();                  \
+                 (msg2)=msgrng_load_rx_msg2();                  \
+                 (msg3)=msgrng_load_rx_msg3();                  \
+                 _tmp=0;                                        \
+                }                                               \
+           _tmp;                                                \
+        } )
+
+static __inline__ int message_send(unsigned int size, unsigned int code,
+				   unsigned int stid, struct msgrng_msg *msg)
+{
+  unsigned int dest = 0;
+  unsigned long long status=0;
+  int i=0;
+
+  msgrng_load_tx_msg0(msg->msg0);
+  msgrng_load_tx_msg1(msg->msg1);
+  msgrng_load_tx_msg2(msg->msg2);
+  msgrng_load_tx_msg3(msg->msg3);
+
+  dest = ((size-1)<<16)|(code<<8)|(stid);
+
+  //dbg_msg("Sending msg<%Lx,%Lx,%Lx,%Lx> to dest = %x\n",
+    //msg->msg0, msg->msg1, msg->msg2, msg->msg3, dest);
+
+
+  for(i=0;i<16;i++) {
+  	msgrng_send(dest);
+	status = msgrng_read_status();
+//	dbg_msg("status = %Lx\n", status);
+
+	if (status & 0x6) {
+	  continue;
+	}
+	else break;
+	}
+    if (i==16) {
+	  if (dest == 0x61)
+		  //dbg_msg("Processor %x: Unable to send msg to %llx\n", processor_id(), dest);
+	  return status & 0x6;
+	}
+  return msgrng_read_status() & 0x06;
+}
+
+static __inline__ int message_send_retry(unsigned int size, unsigned int code,
+					 unsigned int stid,
+					 struct msgrng_msg *msg)
+{
+  int res = 0;
+  int retry = 0;
+
+  for(;;) {
+    res = message_send(size, code, stid, msg);
+    /* retry a pending fail */
+    if (res & 0x02) continue;
+    /* credit fail */
+    if (res & 0x04) retry++;
+    else break;
+    if (retry == 4) return res & 0x06;
+  }
+
+  return 0;
+}
+
+static __inline__ int message_receive(int pri, int *size, int *code, int *src_id,
+				      struct msgrng_msg *msg)
+{
+  int res = message_receive_fast(pri, *size, *code, *src_id, msg->msg0, msg->msg1, msg->msg2, msg->msg3);
+
+#ifdef MSGRING_DUMP_MESSAGES
+  if (!res) {
+    dbg_msg("Received msg <%llx, %llx, %llx, %llx> <%d,%d,%d>\n",
+	    msg->msg0, msg->msg1, msg->msg2, msg->msg3,
+	    *size, *code, *src_id);
+  }
+#endif
+
+  return res;
+}
+
+#define MSGRNG_STN_RX_QSIZE 256
+
+typedef unsigned short bucket_t;
+#define MAX_NUM_MSGRNG_STN_CC   128
+#define MAX_NUM_GMAC_STNS 8
+#define MAX_NUM_XGMAC_STNS 18
+#define NR_STNS_PER_CORE 8
+
+struct stn_cc {
+	bucket_t counters[16][8];
+};
+
+struct bucket_size {
+	bucket_t bucket[MAX_NUM_MSGRNG_STN_CC];
+};
+
+extern struct bucket_size bucket_sizes;
+
+extern struct stn_cc cc_table_cpu_0;
+extern struct stn_cc cc_table_cpu_1;
+extern struct stn_cc cc_table_cpu_2;
+extern struct stn_cc cc_table_cpu_3;
+extern struct stn_cc cc_table_cpu_4;
+extern struct stn_cc cc_table_cpu_5;
+extern struct stn_cc cc_table_cpu_6;
+extern struct stn_cc cc_table_cpu_7;
+extern struct stn_cc cc_table_xgs_0;
+extern struct stn_cc cc_table_xgs_1;
+extern struct stn_cc cc_table_gmac;
+extern struct stn_cc cc_table_dma;
+extern struct stn_cc cc_table_sec;
+
+extern struct bucket_size xls_bucket_sizes;
+extern struct stn_cc xls_cc_table_cpu_0;
+extern struct stn_cc xls_cc_table_cpu_1;
+extern struct stn_cc xls_cc_table_cpu_2;
+extern struct stn_cc xls_cc_table_cpu_3;
+extern struct stn_cc xls_cc_table_gmac0;
+extern struct stn_cc xls_cc_table_gmac1;
+extern struct stn_cc xls_cc_table_cmp;
+extern struct stn_cc xls_cc_table_pcie;
+extern struct stn_cc xls_cc_table_dma;
+extern struct stn_cc xls_cc_table_sec;
+
+extern struct bucket_size shared_bucket_sizes;
+
+extern struct stn_cc shared_cc_table_cpu_0;
+extern struct stn_cc shared_cc_table_cpu_1;
+extern struct stn_cc shared_cc_table_cpu_2;
+extern struct stn_cc shared_cc_table_cpu_3;
+extern struct stn_cc shared_cc_table_cpu_4;
+extern struct stn_cc shared_cc_table_cpu_5;
+extern struct stn_cc shared_cc_table_cpu_6;
+extern struct stn_cc shared_cc_table_cpu_7;
+extern struct stn_cc shared_cc_table_gmac;
+extern struct stn_cc shared_cc_table_dma;
+
+#ifdef CONFIG_NLM_ENABLE_COP2
+
+#define msgrng_access_save(lock, iflags, mflags)
+#define msgrng_access_restore(lock, iflags, mflags)
+
+#define msgrng_access_enable(mflags) 
+#define msgrng_access_disable(mflags) 
+
+#else
+
+#define msgrng_access_save(lock, iflags, mflags) do {        \
+  spin_lock_irqsave(lock, iflags);                           \
+  msgrng_flags_save(mflags);                                 \
+ }while(0)
+
+#define msgrng_access_restore(lock, iflags, mflags) do {     \
+  msgrng_flags_restore(mflags);                              \
+  spin_unlock_irqrestore(lock, iflags);                      \
+ }while(0)
+
+#define msgrng_access_enable(mflags) do {   \
+  preempt_disable();                        \
+  msgrng_flags_save(mflags);                \
+} while(0)
+#define msgrng_access_disable(mflags) do {   \
+  msgrng_flags_restore(mflags);              \
+  preempt_enable();                          \
+} while(0)
+
+#endif
+
+enum {
+  TX_STN_CPU_0,
+  TX_STN_CPU_1,
+  TX_STN_CPU_2,
+  TX_STN_CPU_3,
+  TX_STN_CPU_4,
+  TX_STN_CPU_5,
+  TX_STN_CPU_6,
+  TX_STN_CPU_7,
+  TX_STN_GMAC,
+  TX_STN_DMA,
+  TX_STN_XGS_0,
+  TX_STN_XGS_1,
+  TX_STN_SEC,
+  TX_STN_GMAC0,
+  TX_STN_GMAC1,
+  TX_STN_CMP,
+  TX_STN_PCIE,
+  TX_STN_INVALID,
+  MAX_TX_STNS
+};
+
+#ifdef CONFIG_NLM_XLP
+extern int register_xlp_msgring_handler(int major,
+                             void (*action) (uint32_t, uint32_t, uint32_t, uint32_t,
+                                             uint64_t, uint64_t, uint64_t, uint64_t, void *),
+                             void *dev_id);
+extern int unregister_xlp_msgring_handler(int, void *);
+#else
+extern int register_msgring_handler(int major,
+				    void (*action)(int, int,int,int,struct msgrng_msg *, void *),
+				    void *dev_ctx);
+
+#endif
+
+extern void nlm_common_msgring_cpu_init(void);
+
+extern void nlm_common_msgring_config(void);
+
+#define cpu_to_msgring_bucket(cpu) ((((cpu) >> 2)<<3)|((cpu) & 0x03))
+
+
+/* PR: We need to make the following entrities visible across the kernel */
+#define CPU_BASE_BUCKET(x)   (((x)>>2)<<3)
+
+#define THR_LO_BUCKETID (netlogic_thr_id() & 3)
+#define THR_HI_BUCKETID (THR_LO_BUCKETID + 4)
+
+#define THIS_THR_LO_BUCKET cpu_to_msgring_bucket(hard_smp_processor_id())
+#define THIS_THR_HI_BUCKET (THIS_THR_LO_BUCKET)
+
+#define THR_LO_BKT_STATUS_MASK (1U << THR_LO_BUCKETID)
+#define THR_HI_BKT_STATUS_MASK (1U << THR_HI_BUCKETID)
+
+struct msgrng_msg;
+
+struct tx_stn_handler {
+	void (*action)(int, int, int, int, struct msgrng_msg *, void *);
+	void *dev_id;
+};
+
+struct tx_stn {
+	struct tx_stn_handler handler;
+};
+
+extern struct tx_stn tx_stns[];
+extern int rxstn_to_txstn_map[];
+extern int xls_rxstn_to_txstn_map[];
+
+extern int rmik_queue_pkt_mem(uint32_t fbstid, uint64_t physaddr);
+extern void rmik_init_replenish_work(int);
+extern void nlm_nlm_common_drop_message_unowned(int fbid, uint64_t physaddr, int cop_en);
+
+#endif
diff --git a/arch/mips/include/asm/netlogic/msidef.h b/arch/mips/include/asm/netlogic/msidef.h
new file mode 100644
index 0000000..df92e36
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/msidef.h
@@ -0,0 +1,73 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef ASM_NLM_MSIDEF_H
+#define ASM_NLM_MSIDEF_H
+
+/*
+ * Constants for Intel APIC based MSI messages.
+ * Adapted for the RMI XLR using identical defines
+ */
+
+/*
+ * Shifts for MSI data
+ */
+
+#define MSI_DATA_VECTOR_SHIFT		0
+#define  MSI_DATA_VECTOR_MASK		0x000000ff
+#define	 MSI_DATA_VECTOR(v)		(((v) << MSI_DATA_VECTOR_SHIFT) & MSI_DATA_VECTOR_MASK)
+
+#define MSI_DATA_DELIVERY_MODE_SHIFT	8
+#define  MSI_DATA_DELIVERY_FIXED	(0 << MSI_DATA_DELIVERY_MODE_SHIFT)
+#define  MSI_DATA_DELIVERY_LOWPRI	(1 << MSI_DATA_DELIVERY_MODE_SHIFT)
+
+#define MSI_DATA_LEVEL_SHIFT		14
+#define	 MSI_DATA_LEVEL_DEASSERT	(0 << MSI_DATA_LEVEL_SHIFT)
+#define	 MSI_DATA_LEVEL_ASSERT		(1 << MSI_DATA_LEVEL_SHIFT)
+
+#define MSI_DATA_TRIGGER_SHIFT		15
+#define  MSI_DATA_TRIGGER_EDGE		(0 << MSI_DATA_TRIGGER_SHIFT)
+#define  MSI_DATA_TRIGGER_LEVEL		(1 << MSI_DATA_TRIGGER_SHIFT)
+
+/*
+ * Shift/mask fields for msi address
+ */
+
+#define MSI_ADDR_BASE_HI		0
+#define MSI_ADDR_BASE_LO		0xfee00000
+
+#define MSI_ADDR_DEST_MODE_SHIFT	2
+#define  MSI_ADDR_DEST_MODE_PHYSICAL	(0 << MSI_ADDR_DEST_MODE_SHIFT)
+#define	 MSI_ADDR_DEST_MODE_LOGICAL	(1 << MSI_ADDR_DEST_MODE_SHIFT)
+
+#define MSI_ADDR_REDIRECTION_SHIFT	3
+#define  MSI_ADDR_REDIRECTION_CPU	(0 << MSI_ADDR_REDIRECTION_SHIFT) /* dedicated cpu */
+#define  MSI_ADDR_REDIRECTION_LOWPRI	(1 << MSI_ADDR_REDIRECTION_SHIFT) /* lowest priority */
+
+#define MSI_ADDR_DEST_ID_SHIFT		12
+#define	 MSI_ADDR_DEST_ID_MASK		0x00ffff0
+#define  MSI_ADDR_DEST_ID(dest)		(((dest) << MSI_ADDR_DEST_ID_SHIFT) & MSI_ADDR_DEST_ID_MASK)
+
+#endif /* ASM_NLM_MSIDEF_H */
diff --git a/arch/mips/include/asm/netlogic/pic.h b/arch/mips/include/asm/netlogic/pic.h
index 711e71f..ba0e1ae 100644
--- a/arch/mips/include/asm/netlogic/pic.h
+++ b/arch/mips/include/asm/netlogic/pic.h
@@ -1,5 +1,5 @@
 /***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
 reserved.
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are
@@ -28,6 +28,19 @@ THE POSSIBILITY OF SUCH DAMAGE.
 
 #include <asm/netlogic/iomap.h>
 
+#ifndef __ASSEMBLY__
+struct pt_regs;
+extern void nlm_common_ipi_handler(int irq, struct pt_regs *regs);
+extern void nlm_common_msgring_int_handler(unsigned int irq, struct pt_regs *regs);
+
+struct pic_tmask { 
+	unsigned int mask; 
+	int set; 
+	int valid;
+};
+
+#endif
+
 #if defined(CONFIG_NLM_XLP)
 
 // can't do floating in the kernel, so use 64 as an approximation 
diff --git a/arch/mips/include/asm/netlogic/sim.h b/arch/mips/include/asm/netlogic/sim.h
new file mode 100644
index 0000000..6c56db9
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/sim.h
@@ -0,0 +1,449 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _ASM_SIM_H
+#define _ASM_SIM_H
+
+#include <linux/types.h>
+#include <asm/cpu.h>
+#include <asm/mipsregs.h>
+
+#define MAX_CPU_REV_LEN	 100
+#define PSB_INFO_VERSION 0x0001
+
+struct psb_info {
+	uint64_t boot_level;
+	uint64_t io_base;
+	uint64_t output_device;
+	uint64_t uart_print;
+	uint64_t led_output;
+	uint64_t init;
+	uint64_t exit;
+	uint64_t warm_reset;
+	uint64_t wakeup;
+	uint64_t nlm_cpu_online_map;
+	uint64_t master_reentry_sp;
+	uint64_t master_reentry_gp;
+	uint64_t master_reentry_fn;
+	uint64_t slave_reentry_fn;
+	uint64_t magic_dword;
+	uint64_t uart_putchar;
+	uint64_t size;
+	uint64_t uart_getchar;
+	uint64_t nmi_handler;
+	uint64_t psb_version;
+	uint64_t mac_addr;
+	uint64_t cpu_frequency;
+	uint64_t board_version;
+	uint64_t malloc;
+	uint64_t free;
+	uint64_t global_shmem_addr;
+	uint64_t global_shmem_size;
+	uint64_t psb_os_cpu_map;
+	uint64_t userapp_cpu_map;
+	uint64_t wakeup_os;
+	uint64_t psb_mem_map;
+	uint64_t board_major_version;
+	uint64_t board_minor_version;
+	uint64_t board_manf_revision;
+	uint64_t board_serial_number;
+	uint64_t psb_physaddr_map;
+	uint64_t xlr_loaderip_config;
+	uint64_t bldr_envp;
+	uint64_t avail_mem_map;
+};
+
+
+enum {
+        NETLOGIC_IO_SPACE = 0x10,
+        PCIX_IO_SPACE,
+        PCIX_CFG_SPACE,
+        PCIX_MEMORY_SPACE,
+        HT_IO_SPACE,
+        HT_CFG_SPACE,
+        HT_MEMORY_SPACE,
+        SRAM_SPACE,
+        FLASH_CONTROLLER_SPACE
+};
+
+#define MAX_ENV_BUF 0x00020000 // 128 KB = One sector of Intel flash.
+struct environment
+{
+        unsigned int crc;
+        unsigned char envbuf[MAX_ENV_BUF - 20]; // 4 bytes for CRC and 16 bytes reserved.
+        unsigned char reserved[16];
+};
+
+#define NLM_XLR_BOARD_ARIZONA_I   1
+#define NLM_XLR_BOARD_ARIZONA_II  2
+#define NLM_XLR_BOARD_ARIZONA_III 3
+#define NLM_XLR_BOARD_ARIZONA_IV  4
+#define NLM_XLR_BOARD_ARIZONA_V   5
+#define NLM_XLR_BOARD_ARIZONA_VI   6  /* XLS boards */
+#define NLM_XLR_BOARD_ARIZONA_VII 7 /*XLS 2xx boards*/
+#define NLM_XLR_BOARD_ARIZONA_VIII 8 /*XLS LTE boards*/
+#define NLM_XLR_BOARD_ARIZONA_XI 11
+#define NLM_XLR_BOARD_ARIZONA_XII  12
+
+struct smp_boot_info_percpu {
+  volatile unsigned long ready;
+  volatile unsigned long sp;
+  volatile unsigned long gp;
+  volatile unsigned long fn;
+};
+
+struct smp_boot_info {
+  struct smp_boot_info_percpu boot_info[NR_CPUS];
+  __u32 online_map;
+};
+
+extern struct smp_boot_info smp_boot;
+extern void prom_boot_cpus_secondary(void *);
+
+extern __u32 xlr_board_major_version;
+extern __u32 xlr_board_minor_version;
+
+#define XLR_REVISION_A0 0xc0000
+#define XLR_REVISION_A1 0xc0001
+#define XLR_REVISION_B0 0xc0002
+#define XLR_REVISION_B1 0xc0003
+#define XLR_REVISION_B2 0xc0004
+#define XLR_REVISION_C0 0xc0005
+#define XLR_REVISION_C1 0xc0006
+#define XLR_REVISION_C2 0xc0007
+#define XLR_REVISION_C3 0xc0008
+#define XLR_REVISION_C4 0xc0009
+
+static __inline__ unsigned int xlr_revision(void)
+{
+	return read_c0_prid() & 0xff00ff;
+}
+
+static __inline__ int xlr_revision_a0(void)
+{
+	return xlr_revision() == XLR_REVISION_A0;
+}
+
+static __inline__ int xlr_revision_b0(void)
+{
+	return xlr_revision() == XLR_REVISION_B0;
+}
+
+static __inline__ int xlr_revision_b1(void)
+{
+        return xlr_revision() == XLR_REVISION_B1;
+}
+
+static __inline__ int xlr_revision_c(void)
+{
+    uint32_t prid = read_c0_prid();
+    if(prid>=XLR_REVISION_C0 && prid<=XLR_REVISION_C4)
+        return 1;        
+    return 0; 
+}
+
+static __inline__ int xlr_board_atx_i(void)
+{
+	return xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_I;
+}
+
+static __inline__ int xlr_board_atx_ii(void)
+{
+	return xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_II;
+}
+
+static __inline__ int xlr_board_atx_ii_b(void)
+{
+	return (xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_II)
+		&& (xlr_board_minor_version == 1);
+}
+
+static __inline__ int xlr_board_atx_iii(void)
+{
+	return xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_III;
+}
+
+static __inline__ int xlr_board_atx_iv(void)
+{
+	return (xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_IV)
+		&& (xlr_board_minor_version == 0);
+}
+
+static __inline__ int xlr_board_atx_iv_b(void)
+{
+	return (xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_IV)
+		&& (xlr_board_minor_version == 1);
+}
+
+static __inline__ int xlr_board_atx_v(void)
+{
+	return xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_V;
+}
+
+static __inline__ int xlr_board_atx_iii_256(void)
+{
+	return (xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_III)
+		&& (xlr_board_minor_version == 0);
+}
+
+static __inline__ int xlr_board_atx_iii_512(void)
+{
+	return (xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_III)
+		&& (xlr_board_minor_version == 1);
+}
+
+static __inline__ int xlr_board_atx_v_512(void)
+{
+	return (xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_V)
+		&& (xlr_board_minor_version == 1);
+}
+
+static __inline__ int xlr_board_atx_vi(void)
+{
+	return (xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_VI);
+}
+
+static __inline__ int xlr_board_atx_vii(void)
+{
+	return (xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_VII);
+}
+
+static __inline__ int xlr_board_atx_viii(void)
+{
+	return (xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_VIII);
+}
+
+static __inline__ int xlr_board_atx_xi(void)
+{
+	return (xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_XI);
+}
+
+static __inline__ int xlr_board_atx_xii(void)
+{
+	return (xlr_board_major_version == NLM_XLR_BOARD_ARIZONA_XII);
+}
+
+static __inline__ int xlr_board_atx_xaui_rework(void)
+{
+	if ((xlr_board_atx_xi() || xlr_board_atx_xii()) &&
+			(xlr_board_minor_version == 4))
+		return 1;
+	else
+		return 0;
+}
+
+
+#define XLR_HYBRID_NONE              0
+#define XLR_HYBRID_USER_MAC          1
+#define XLR_HYBRID_RMIOS_IPSEC       2
+#define XLR_HYBRID_RMIOS_TCPIP_STACK 3
+#define XLR_HYBRID_USER_MAC_GMAC     4
+#define XLR_HYBRID_USER_MAC_XGMAC    5
+#define XLR_HYBRID_USER_MAC_SPI4     6
+#define XLR_HYBRID_USER_MAC_GMAC_XGMAC    7
+#define XLR_HYBRID_USER_MAC_GMAC_SPI4     8
+
+extern int xlr_hybrid;
+
+static __inline__ int xlr_hybrid_user_mac(void)
+{
+	return xlr_hybrid == XLR_HYBRID_USER_MAC;
+}
+
+static __inline__ int xlr_hybrid_user_mac_xgmac(void)
+{
+	return (xlr_hybrid == XLR_HYBRID_USER_MAC_XGMAC || 
+		xlr_hybrid == XLR_HYBRID_USER_MAC_SPI4);
+}
+
+static __inline__ int xlr_hybrid_rmios_tcpip_stack(void)
+{
+        return xlr_hybrid == XLR_HYBRID_RMIOS_TCPIP_STACK;
+}
+
+static __inline__ int xlr_hybrid_rmios_ipsec(void)
+{
+	return xlr_hybrid == XLR_HYBRID_RMIOS_IPSEC;
+}
+
+static __inline__ int xlr_hybrid_none(void)
+{
+	return xlr_hybrid == XLR_HYBRID_NONE;
+}
+
+struct boot_mem_map_entry *psb_get_physaddr_base_address(unsigned long type);
+
+
+#define CHIP_PROCESSOR_ID_XLS_608   0x80
+#define CHIP_PROCESSOR_ID_XLS_408   0x88
+#define CHIP_PROCESSOR_ID_XLS_404   0x8c
+#define CHIP_PROCESSOR_ID_XLS_208   0x8e
+#define CHIP_PROCESSOR_ID_XLS_204   0x8f
+#define CHIP_PROCESSOR_ID_XLS_108   0xce
+#define CHIP_PROCESSOR_ID_XLS_104   0xcf
+
+/* Defines for XLS B0*/
+#define CHIP_PROCESSOR_ID_XLS_616_B0   0x40
+#define CHIP_PROCESSOR_ID_XLS_608_B0   0x4a
+#define CHIP_PROCESSOR_ID_XLS_416_B0   0x44
+#define CHIP_PROCESSOR_ID_XLS_412_B0   0x4c
+#define CHIP_PROCESSOR_ID_XLS_408_B0   0x4e
+#define CHIP_PROCESSOR_ID_XLS_404_B0   0x4f
+
+#define CHIP_PROCESSOR_ID_XLR_B_308   0x06
+#define CHIP_PROCESSOR_ID_XLR_B_508   0x07
+#define CHIP_PROCESSOR_ID_XLR_B_516   0x08
+#define CHIP_PROCESSOR_ID_XLR_B_532   0x09
+#define CHIP_PROCESSOR_ID_XLR_B_716   0x0a
+#define CHIP_PROCESSOR_ID_XLR_B_732   0x0b
+
+#define CHIP_PROCESSOR_ID_XLR_C_308   0x0F
+#define CHIP_PROCESSOR_ID_XLR_C_508   0x0b
+#define CHIP_PROCESSOR_ID_XLR_C_516   0x0a
+#define CHIP_PROCESSOR_ID_XLR_C_532   0x08
+#define CHIP_PROCESSOR_ID_XLR_C_716   0x02
+
+#if defined(CONFIG_NLM_XLP)
+/* Fake Values for bring-up */
+#define CHIP_PROCESSOR_ID_XLP_A_832   0x00
+#define CHIP_PROCESSOR_ID_XLR_C_732   0xff
+#else
+/* Real Values */
+#define CHIP_PROCESSOR_ID_XLP_A_832   0x90
+#define CHIP_PROCESSOR_ID_XLR_C_732   0x00
+#endif
+
+/*  fill the xls chip family types 
+ */
+extern int chip_is_xls6xx;
+extern int chip_is_xls4xx;
+extern int chip_is_xls2xx;
+extern int chip_is_xls1xx;
+extern int chip_is_xls;
+extern int chip_is_xls_b0;
+extern int chip_is_xls6xx_b0;
+extern int chip_is_xls4xx_b0;
+
+static __inline__ void set_xls_chip_family_types(void)
+{
+	int processor_id = ((read_c0_prid() & 0xff00) >> 8);
+	chip_is_xls = 1;
+	switch (processor_id) {
+        case CHIP_PROCESSOR_ID_XLS_608: 
+		{
+			chip_is_xls6xx = 1;
+			break;
+		}
+        case CHIP_PROCESSOR_ID_XLS_408:
+        case CHIP_PROCESSOR_ID_XLS_404:
+		{
+			chip_is_xls4xx = 1;
+			break;
+		}
+        case CHIP_PROCESSOR_ID_XLS_208:
+        case CHIP_PROCESSOR_ID_XLS_204:
+		{
+			chip_is_xls2xx = 1;
+			break;
+		}
+        case CHIP_PROCESSOR_ID_XLS_108:
+        case CHIP_PROCESSOR_ID_XLS_104:
+		{
+			chip_is_xls1xx = 1;
+			break;
+		}
+        case CHIP_PROCESSOR_ID_XLS_616_B0:
+        case CHIP_PROCESSOR_ID_XLS_608_B0:
+		{
+			chip_is_xls_b0 = 1;
+			chip_is_xls6xx_b0 = 1;
+			break;
+		}
+        case CHIP_PROCESSOR_ID_XLS_416_B0:
+        case CHIP_PROCESSOR_ID_XLS_412_B0:
+        case CHIP_PROCESSOR_ID_XLS_408_B0:
+        case CHIP_PROCESSOR_ID_XLS_404_B0:
+		{
+			chip_is_xls_b0 = 1;
+			chip_is_xls4xx_b0 = 1;
+			break;
+		}
+        default:
+			chip_is_xls = 0;
+	}
+	return;
+}
+
+static __inline__ int is_xls(void)
+{
+	return chip_is_xls;
+}
+
+static __inline__ int is_xls2xx(void)
+{
+	return chip_is_xls2xx;
+}
+
+static __inline__ int is_xls1xx(void)
+{
+	return chip_is_xls1xx;
+}
+
+static __inline__ int is_xls4xx(void)
+{
+	return chip_is_xls4xx;
+}
+
+static __inline__ int is_xls6xx(void)
+{
+	return chip_is_xls6xx;
+}
+
+static __inline__ int is_xls_b0_4xx(void)
+{
+	return chip_is_xls4xx_b0;
+}
+
+static __inline__ int is_xls_b0_6xx(void)
+{
+	return chip_is_xls6xx_b0;
+}
+
+static __inline__ int is_xls_b0(void)
+{
+	return chip_is_xls_b0;
+}
+
+
+
+#define NR_CORES 8
+#define NR_CPUS_PER_CORE 4
+#define NLM_MAX_ARGS 64
+#define NLM_MAX_ENVS 32
+
+extern char cpu_model_info[MAX_CPU_REV_LEN];
+extern char* get_cpu_info(void);
+
+#endif /* _ASM_SIM_H */
diff --git a/arch/mips/include/asm/netlogic/xgmac_mdio.h b/arch/mips/include/asm/netlogic/xgmac_mdio.h
new file mode 100644
index 0000000..4ce8b30
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/xgmac_mdio.h
@@ -0,0 +1,114 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+// MDIO Low level Access routines
+// All Phy's accessed from GMAC0 base
+
+#ifndef _XGMAC_MDIO
+#define _XGMAC_MDIO
+
+static inline int xmdio_read  (volatile unsigned int *_mmio,
+		uint32_t phy_addr, uint32_t address) ;
+static inline void xmdio_write (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t address, uint32_t data) ;
+static inline void xmdio_address (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t dev_ad, uint32_t address) ;
+
+// function prototypes
+static inline int xmdio_read  (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t address) {
+	uint32_t st_field = 0x0 ;
+	uint32_t op_type  = 0x3 ; // read operation
+	uint32_t ta_field = 0x2 ; // ta field
+	uint32_t data = 0 ;
+
+        xmdio_address (_mmio, phy_addr, 5, address) ;
+	_mmio [0x11] =  ( ( st_field & 0x3    ) << 30 ) |
+		( ( op_type  & 0x3    ) << 28 ) | 
+		( ( phy_addr & 0x1F   ) << 23 ) | 
+		( ( 5  & 0x1F   ) << 18 ) | 
+		( ( ta_field & 0x3    ) << 16 ) | 
+		( ( data     & 0xffff ) <<  0 ) ;
+
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x1 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+
+	// wait for write cycle to complete
+	while (_mmio [0x14] & 0x1) {
+	} ; 
+
+	data = _mmio [0x11] & 0xffff ;
+	return (data);
+}
+ 
+static inline void xmdio_write (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t address, uint32_t data) {
+	uint32_t st_field = 0x0 ;
+	uint32_t op_type  = 0x1 ; // write operation
+	uint32_t ta_field = 0x2 ; // ta field
+
+        xmdio_address ( _mmio, phy_addr, 5, address) ;
+	_mmio [0x11] =  ( ( st_field & 0x3    ) << 30 ) |
+		( ( op_type  & 0x3    ) << 28 ) | 
+		( ( phy_addr & 0x1F   ) << 23 ) | 
+		( ( 5  & 0x1F   ) << 18 ) | 
+		( ( ta_field & 0x3    ) << 16 ) | 
+		( ( data     & 0xffff ) <<  0 ) ;
+
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x1 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+
+	// wait for write cycle to complete
+	while (_mmio [0x14] & 0x1) {
+	} ; 
+
+}
+
+static inline void xmdio_address (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t dev_ad, uint32_t address) {
+	uint32_t st_field = 0x0 ;
+	uint32_t op_type  = 0x0 ; // address operation
+	uint32_t ta_field = 0x2 ; // ta field
+
+	_mmio [0x11] =  ( ( st_field & 0x3    ) << 30 ) |
+		( ( op_type  & 0x3    ) << 28 ) | 
+		( ( phy_addr & 0x1F   ) << 23 ) | 
+		( ( dev_ad  & 0x1F   ) << 18 ) | 
+		( ( ta_field & 0x3    ) << 16 ) | 
+		( ( address  & 0xffff ) <<  0 ) ;
+
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x1 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+
+	// wait for dev_ad cycle to complete
+	while (_mmio [0x14] & 0x1) {
+	} ; 
+
+}
+ 
+#endif
diff --git a/arch/mips/include/asm/netlogic/xlp.h b/arch/mips/include/asm/netlogic/xlp.h
index 69f9ae7..227c694 100644
--- a/arch/mips/include/asm/netlogic/xlp.h
+++ b/arch/mips/include/asm/netlogic/xlp.h
@@ -29,27 +29,13 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #include <linux/types.h>
 #include <asm/cpu.h>
 #include <asm/mipsregs.h>
-
-#define CHIP_PROCESSOR_ID_XLP_8XX   0x00
-#define CHIP_PROCESSOR_ID_XLP_832   0x10
-#define CHIP_PROCESSOR_ID_XLP_816   0x14
-#define CHIP_PROCESSOR_ID_XLP_432   0x90
-#define CHIP_PROCESSOR_ID_XLP_416   0x94
-#define CHIP_PROCESSOR_ID_XLP_408   0x95
-#define CHIP_PROCESSOR_ID_XLP_316   0xD4
-#define CHIP_PROCESSOR_ID_XLP_308   0xD5
-#define CHIP_PROCESSOR_ID_XLP_304   0xD7
-#define CHIP_PROCESSOR_ID_XLP_208   0xB5
-#define CHIP_PROCESSOR_ID_XLP_204   0xB7
-#define CHIP_PROCESSOR_ID_XLP_104   0xF7
-
-#define XLP_REVISION_A0 	0x00
-#define XLP_REVISION_A1 	0x01
-#define XLP_REVISION_A2 	0x02
+#include <asm/netlogic/hal/nlm_hal.h>
+#include <asm/netlogic/hal/nlm_hal_xlp_dev.h>
 
 #define MAX_CPU_REV_LEN		100
+#define NLM_MAX_CPU_NODE	4
+#define NLM_MAX_DRAM_REGION	8
 #define NLM_MAX_CPU_PER_NODE	32
-#define NLM_MAX_CPU_NODE	(CONFIG_NR_CPUS / NLM_MAX_CPU_PER_NODE)
 #define NLM_MAX_THREADS_PER_CPU	4
 #define NLM_MAX_VC_PER_THREAD	4
 
@@ -91,6 +77,7 @@ struct smp_boot_info {
 
 extern struct smp_boot_info smp_boot;
 extern void prom_boot_cpus_secondary(void *);
+extern cpumask_t phys_cpu_present_map;
 
 extern char cpu_model_info[MAX_CPU_REV_LEN];
 extern char* get_cpu_info(void);
diff --git a/arch/mips/include/asm/netlogic/xlp8xx/cpu.h b/arch/mips/include/asm/netlogic/xlp8xx/cpu.h
new file mode 100644
index 0000000..ab1a881
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/xlp8xx/cpu.h
@@ -0,0 +1,157 @@
+/*
+ * Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+ * reserved. Redistribution and use in source and binary forms, with 
+ * or without modification, are permitted provided that the following 
+ * conditions are met:
+ *
+ *	1. 	Redistributions of source code must retain the above copyright
+ *		notice, this list of conditions and the following disclaimer.
+ *
+ *	2. 	Redistributions in binary form must reproduce the above copyright
+ *		notice, this list of conditions and the following disclaimer in
+ *		the documentation and/or other materials provided with the
+ *		distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ * --------------------------------#NETL_2#--------------------------------
+ */
+/* XLP CPU specific */
+
+#ifndef __XLP_CPU_H_
+#define __XLP_CPU_H_
+
+/* so that these need not 
+ * be included explicitly 
+
+#include "xlp_bridge.h"
+#include "xlp_i2c.h"
+#include "xlp_spi.h"
+#include "xlp_sys.h"
+#include "xlp_ddr.h"
+#include "xlp_gbu.h"
+#include "xlp_nand.h"
+#include "xlp_ici.h"
+ */
+
+#define CHIP_PID_XLP					0x00
+#define MAX_NODES						0x04
+
+/* CPU Internal Blocks specific to XLP .
+ * These are accessed using the mfcr/mtcr
+ * instructions. Blocks [0-5] are same for
+ * XLR and XLP
+ */
+#define CPU_BLOCKID_MAP					0x0a
+/* Offsets of interest from the 'MAP' Block */
+#define BLKID_MAP_THREADMODE			0x00 
+#define BLKID_MAP_EXT_EBASE_ENABLE		0x04 
+#define BLKID_MAP_CCDI_CONFIG			0x08
+#define BLKID_MAP_THRD0_CCDI_STATUS		0x0c	
+#define BLKID_MAP_THRD1_CCDI_STATUS		0x10
+#define BLKID_MAP_THRD2_CCDI_STATUS		0x14	
+#define BLKID_MAP_THRD3_CCDI_STATUS		0x18
+#define BLKID_MAP_THRD0_DEBUG_MODE		0x1c
+#define BLKID_MAP_THRD1_DEBUG_MODE		0x20
+#define BLKID_MAP_THRD2_DEBUG_MODE		0x24
+#define BLKID_MAP_THRD3_DEBUG_MODE		0x28
+#define BLKID_MAP_MISC_STATE			0x60
+#define BLKID_MAP_DEBUG_READ_CTL		0x64
+#define BLKID_MAP_DEBUG_READ_REG0		0x68
+#define BLKID_MAP_DEBUG_READ_REG1		0x6c
+
+#define CPU_BLOCKID_SCH				7
+#define CPU_BLOCKID_SCU				8
+#define CPU_BLOCKID_FPU				9
+
+/* ----------------------------------
+ *   XLP RESET Physical Address Map
+ * ----------------------------------
+ * PCI ECFG : 0x18000000 - 0x1bffffff 
+ * PCI CFG  : 0x1c000000 - 0x1cffffff 
+ * FLASH    : 0x1fc00000 - 0x1fffffff 
+ * ----------------------------------
+ */
+
+/* The DEFAULT_XLP_IO_BASE value is what is
+ * programmed in the NBU's (NorthBridge Unit) 
+ * ECFG_BAR register. The NBU itself is 
+ * accessible as [BDF:0,0,0].
+ */
+#ifdef __ASSEMBLY__
+#define DEFAULT_XLP_IO_BASE		0xffffffffb8000000ULL
+#define DEFAULT_XLP_IO_BASE_VIRT	0xb8000000	/* IO_BASE for Assembly macros */
+#else
+#define DEFAULT_XLP_IO_BASE		0xffffffffb8000000ULL
+#define DEFAULT_XLP_IO_BASE_VIRT	DEFAULT_XLP_IO_BASE
+#define DEFAULT_XLP_IO_BASE_PHYS	0x18000000
+#endif
+
+#ifdef NLM_HAL_LINUX_KERNEL		/* Hal requires phy add :-) */
+#define DEFAULT_XLP_IO_BASE_PHYS        0x18000000
+#define DEFAULT_CPU_IO_BASE		DEFAULT_XLP_IO_BASE_PHYS
+#else
+#define DEFAULT_CPU_IO_BASE		DEFAULT_XLP_IO_BASE_VIRT
+#endif
+
+#define CPU_IO_SIZE			(64<<20)/* Size of the ECFG Space */
+#define HDR_OFFSET			0x100 /* Skip 256 bytes of cfg. hdrs */
+
+#define NETL_VENDOR_ID			0x184e
+#define ICI_DEVICE_ID			0x1002
+
+/* The On-Chip functional blocks for XLP */
+
+/* ------------------------------------------------------------------------*/
+/* Accesses Based on Enhanced Configuration Mechanism					   */
+/* ------------------------------------------------------------------------*/
+/* Interface			|	Bus    |	Dev	|   Func   */
+/* ------------------------------------------------------------------------*/
+#define BRIDGE			(0x00<<20) | (0x00<<15) | (0x00<<12)
+#define ICI0			(0x00<<20) | (0x00<<15) | (0x01<<12)
+#define ICI1			(0x00<<20) | (0x00<<15) | (0x02<<12)
+#define ICI2			(0x00<<20) | (0x00<<15) | (0x03<<12)
+#define	PIC			(0x00<<20) | (0x00<<15) | (0x04<<12)
+#define UART0			(0x00<<20) | (0x06<<15) | (0x00<<12)
+#define UART1			(0x00<<20) | (0x06<<15) | (0x01<<12)
+#define I2C0			(0x00<<20) | (0x06<<15) | (0x02<<12)
+#define I2C1			(0x00<<20) | (0x06<<15) | (0x03<<12)
+#define	GPIO			(0x00<<20) | (0x06<<15) | (0x04<<12)
+#define SYS			(0x00<<20) | (0x06<<15) | (0x05<<12)
+#define	JTAG			(0x00<<20) | (0x06<<15) | (0x06<<12)
+#define	NOR			(0x00<<20) | (0x07<<15) | (0x00<<12)
+#define	NAND			(0x00<<20) | (0x07<<15) | (0x01<<12)
+#define	SPI			(0x00<<20) | (0x07<<15) | (0x02<<12)
+#define	MMC			(0x00<<20) | (0x07<<15) | (0x03<<12)
+/* same as NOR ? */
+#define GBU			(0x00<<20) | (0x07<<15) | (0x00<<12)
+/* ------------------------------------------------------------------------*/
+
+#define CPU_MMIO_OFFSET(y,x)	(DEFAULT_CPU_IO_BASE + (x) + \
+				HDR_OFFSET + (y<<18))
+
+#define DMC_MMIO_OFFSET(y,x)	(DEFAULT_CPU_IO_BASE + (0x200*x) \
+				HDR_OFFSET + (y<<18) + (BRIDGE) + 0x300)
+
+#ifndef __ASSEMBLY__
+#define cpu_io_mmio(node,offset)	((__u32 *)((u64)DEFAULT_CPU_IO_BASE + \
+					(node<<18) + (offset) + HDR_OFFSET))
+
+#define dmc_io_mmio(node,offset)\
+	((__u32 *)(DEFAULT_CPU_IO_BASE + \
+	(node<<18) + (0x200*offset) + (BRIDGE) + 0x300 + HDR_OFFSET))
+
+#define ici_io_mmio(node,link)\
+	((__u32 *)(DEFAULT_CPU_IO_BASE + (ICI0) + \
+	(node<<18) + HDR_OFFSET + (link << 12) ) )
+#endif	/* __ASSEMBLY__ */
+#endif	/* __XLP_CPU_H_ */
diff --git a/arch/mips/include/asm/netlogic/xlp8xx/xlp_sys.h b/arch/mips/include/asm/netlogic/xlp8xx/xlp_sys.h
new file mode 100644
index 0000000..a6453de
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/xlp8xx/xlp_sys.h
@@ -0,0 +1,206 @@
+/*
+ * Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+ * reserved. Redistribution and use in source and binary forms, with 
+ * or without modification, are permitted provided that the following 
+ * conditions are met:
+ *
+ *	1. 	Redistributions of source code must retain the above copyright
+ *		notice, this list of conditions and the following disclaimer.
+ *
+ *	2. 	Redistributions in binary form must reproduce the above copyright
+ *		notice, this list of conditions and the following disclaimer in
+ *		the documentation and/or other materials provided with the
+ *		distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ * --------------------------------#NETL_2#--------------------------------
+ */
+#ifndef __XLP_SYS_H__
+#define __XLP_SYS_H__
+
+#define SYS_CHIPRESET_REG  0
+#define SYS_POWERONRESETCFG_REG  1
+#define SYS_EFUSEDEVICECFG0_REG  2
+#define SYS_EFUSEDEVICECFG1_REG  3
+#define SYS_EFUSEDEVICECFG2_REG  4
+#define SYS_EFUSEDEVICECFG3_REG  5
+#define SYS_EFUSEDEVICECFG4_REG  6
+#define SYS_EFUSEDEVICECFG5_REG  7
+#define SYS_EFUSEDEVICECFG6_REG  8
+#define SYS_EFUSEDEVICECFG7_REG  9
+#define SYS_PLLCTRL_REG  10
+#define SYS_CPURESET_REG  11
+#define SYS_CPUTHREADEN_REG  12
+#define SYS_CPUNONCOHERENTMODE_REG  13
+#define SYS_COREDFSDISCTRL_REG  14
+#define SYS_COREDFSRSTCTRL_REG  15
+#define SYS_COREDFSBYPCTRL_REG  16
+#define SYS_COREDFSPHACTRL_REG  17
+#define SYS_COREDFSDIVINCCTRL_REG  18
+#define SYS_COREDFSDIVDECCTRL_REG  19
+#define SYS_COREDFSDIVCTRL_REG  20
+#define SYS_SYSRESET_REG  21
+#define SYS_SYSDFSDISCTRL_REG  22
+#define SYS_SYSDFSRSTCTRL_REG  23
+#define SYS_SYSDFSBYPCTRL_REG  24
+#define SYS_SYSDFSDIVINCCTRL_REG  25
+#define SYS_SYSDFSDIVDECCTRL_REG  26
+#define SYS_SYSDFSDIVCTRL0_REG  27
+#define SYS_SYSDFSDIVCTRL1_REG  28
+#define SYS_CPUSENSEAMPDLY_REG  29
+#define SYS_SOCSENSEAMPDLY_REG  30
+#define SYS_SYSCTRL0_REG  31
+#define SYS_SYSCTRL1_REG  32
+#define SYS_TIMEOUTBSI_REG  33
+#define SYS_BYTESWAP_REG  34
+#define SYS_SYSVRMVID_REG  35
+#define SYS_SYSPWRRAMCMD_REG  36
+#define SYS_SYSPWRRAMADDR_REG  37
+#define SYS_SYSPWRRAMDATA0_REG  38
+#define SYS_SYSPWRRAMDATA1_REG  39
+#define SYS_SYSPWRRAMDATA2_REG  40
+#define SYS_SYSPWRUCODE_REG  41
+#define SYS_SYSPWRSTATUS0_REG  42
+#define SYS_SYSPWRSTATUS1_REG  43
+#define SYS_SYSPWRSTATUS2_REG  44
+#define SYS_SYSPWRSTATUS3_REG  45
+#define SYS_SYSPWRSTATUS4_REG  46
+#define SYS_SYSPWRSTATUS5_REG  47
+#define SYS_SYSPWRSTATUS6_REG  48
+#define SYS_SYSPWRSTATUS7_REG  49
+#define SYS_SYSSTATUS_REG  50
+#define SYS_SYSINTPOL_REG  51
+#define SYS_SYSINTTYPE_REG  52
+#define SYS_SYSINTSTATUS_REG  53
+#define SYS_SYSINTENABLE0_REG  54
+#define SYS_SYSINTENABLE1_REG  55
+#define SYS_SYSUCOSECC_REG  56
+#define SYS_SYSUCOMECC_REG  57
+#define SYS_SYSUCOADDR_REG  58
+#define SYS_SYSUCOINST_REG  59
+#define SYS_SYSMEMBISTGO0_REG  60
+#define SYS_SYSMEMBISTGO1_REG  61
+#define SYS_SYSMEMBISTGO2_REG  62
+#define SYS_SYSMEMBISTGO3_REG  63
+#define SYS_SYSMEMBISTGO4_REG  64
+#define SYS_SYSMEMBISTGO5_REG  65
+#define SYS_SYSMEMBISTGO6_REG  66
+#define SYS_SYSMEMBISTGO7_REG  67
+#define SYS_SYSMEMBISTGO8_REG  68
+#define SYS_SYSSCRATCH0_REG  69
+#define SYS_SYSSCRATCH1_REG  70
+#define SYS_SYSSCRATCH2_REG  71
+#define SYS_SYSSCRATCH3_REG  72
+
+#define SYS_PWRON_DIVF(x) ( (x >> 10) & 0x7f)
+#define SYS_PWRON_DIVR(x) ( (x >> 8) & 0x3)
+#define SYS_CORE_DFS(x,y) ( (x >> (y*4) ) & 0xf)
+#define SYS_PWRON_EXTDIV(x) ( (x >> 30) & 0x3)
+
+#define SYS_DMC_DISABLE_MASK 0x40
+#define SYS_DMC_PLL_RESET(x) (x << 16)
+#define SYS_DMC_PLL_DIVR(x) (x << 17)
+#define SYS_DMC_PLL_DIVF(x) (x << 19)
+#define SYS_DMC_DIV(x) ( (x >> 24) & 0xf)
+#define SYS_DMC_PLL_RMW_MASK 0xffff
+
+#define RD_DMC_PLL_DIVR(x) ( (x >> 17) & 0x3)
+#define RD_DMC_PLL_DIVF(x) ( (x >> 19) & 0x7f)
+
+#define SYS_DMC_DIV_DEC_MASK 0x40
+#define SYS_DMC_DIV_INC_MASK 0x40
+
+#ifndef __ASSEMBLY__
+enum processor_sys
+{
+	SYS_CHIPRESET = 0,
+	SYS_POWERONRESETCFG = 1,
+	SYS_EFUSEDEVICECFG0 = 2,
+	SYS_EFUSEDEVICECFG1 = 3,
+	SYS_EFUSEDEVICECFG2 = 4,
+	SYS_EFUSEDEVICECFG3 = 5,
+	SYS_EFUSEDEVICECFG4 = 6,
+	SYS_EFUSEDEVICECFG5 = 7,
+	SYS_EFUSEDEVICECFG6 = 8,
+	SYS_EFUSEDEVICECFG7 = 9,
+	SYS_PLLCTRL = 10,
+	SYS_CPURESET = 11,
+	SYS_CPUTHREADEN = 12,
+	SYS_CPUNONCOHERENTMODE = 13,
+	SYS_COREDFSDISCTRL = 14,
+	SYS_COREDFSRSTCTRL = 15,
+	SYS_COREDFSBYPCTRL = 16,
+	SYS_COREDFSPHACTRL = 17,
+	SYS_COREDFSDIVINCCTRL = 18,
+	SYS_COREDFSDIVDECCTRL = 19,
+	SYS_COREDFSDIVCTRL = 20,
+	SYS_SYSRESET = 21,
+	SYS_SYSDFSDISCTRL = 22,
+	SYS_SYSDFSRSTCTRL = 23,
+	SYS_SYSDFSBYPCTRL = 24,
+	SYS_SYSDFSDIVINCCTRL = 25,
+	SYS_SYSDFSDIVDECCTRL = 26,
+	SYS_SYSDFSDIVCTRL0 = 27,
+	SYS_SYSDFSDIVCTRL1 = 28,
+	SYS_CPUSENSEAMPDLY = 29,
+	SYS_SOCSENSEAMPDLY = 30,
+	SYS_SYSCTRL0 = 31,
+	SYS_SYSCTRL1 = 32,
+	SYS_TIMEOUTBSI = 33,
+	SYS_BYTESWAP = 34,
+	SYS_SYSVRMVID = 35,
+	SYS_SYSPWRRAMCMD = 36,
+	SYS_SYSPWRRAMADDR = 37,
+	SYS_SYSPWRRAMDATA0 = 38,
+	SYS_SYSPWRRAMDATA1 = 39,
+	SYS_SYSPWRRAMDATA2 = 40,
+	SYS_SYSPWRUCODE = 41,
+	SYS_SYSPWRSTATUS0 = 42,
+	SYS_SYSPWRSTATUS1 = 43,
+	SYS_SYSPWRSTATUS2 = 44,
+	SYS_SYSPWRSTATUS3 = 45,
+	SYS_SYSPWRSTATUS4 = 46,
+	SYS_SYSPWRSTATUS5 = 47,
+	SYS_SYSPWRSTATUS6 = 48,
+	SYS_SYSPWRSTATUS7 = 49,
+	SYS_SYSSTATUS = 50,
+	SYS_SYSINTPOL = 51,
+	SYS_SYSINTTYPE = 52,
+	SYS_SYSINTSTATUS = 53,
+	SYS_SYSINTENABLE0 = 54,
+	SYS_SYSINTENABLE1 = 55,
+	SYS_SYSUCOSECC = 56,
+	SYS_SYSUCOMECC = 57,
+	SYS_SYSUCOADDR = 58,
+	SYS_SYSUCOINST = 59,
+	SYS_SYSMEMBISTGO0 = 60,
+	SYS_SYSMEMBISTGO1 = 61,
+	SYS_SYSMEMBISTGO2 = 62,
+	SYS_SYSMEMBISTGO3 = 63,
+	SYS_SYSMEMBISTGO4 = 64,
+	SYS_SYSMEMBISTGO5 = 65,
+	SYS_SYSMEMBISTGO6 = 66,
+	SYS_SYSMEMBISTGO7 = 67,
+	SYS_SYSMEMBISTGO8 = 68,
+	SYS_SYSMEMBISTGO9 = 69,
+	SYS_SYSMEMBISTGO10 = 70,
+	SYS_SYSMEMBISTGO11 = 71,
+	SYS_SYSMEMBISTGO12 = 72,
+	SYS_SYSSCRATCH0 = 73,
+	SYS_SYSSCRATCH1 = 74,
+	SYS_SYSSCRATCH2 = 75,
+	SYS_SYSSCRATCH3 = 76
+};
+#endif
+
+#endif /* __XLP_SYS_H__ */
diff --git a/arch/mips/include/asm/netlogic/xlp_hal_pic.h b/arch/mips/include/asm/netlogic/xlp_hal_pic.h
new file mode 100644
index 0000000..0534bd1
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/xlp_hal_pic.h
@@ -0,0 +1,290 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _NLM_HAL_PIC_H
+#define _NLM_HAL_PIC_H
+
+#include "nlm_hal.h"
+/*
+ *     Register Offsets
+ */
+#define PIC_CTRL             0x00
+#define PIC_BYTESWAP         0x01
+#define PIC_STATUS           0x02
+#define PIC_INT_TIMEOUT      0x03
+#define PIC_ICI0_INT_TIMEOUT 0x04
+#define PIC_ICI1_INT_TIMEOUT 0x05
+#define PIC_ICI2_INT_TIMEOUT 0x06
+#define PIC_IPI_CTL          0x07
+#define PIC_INT_ACK          0x08
+#define PIC_INT_PENDING0     0x09
+#define PIC_INT_PENDING1     0x0a
+#define PIC_INT_PENDING2     0x0b
+
+#define PIC_WD0_MAX_VAL      0x0c
+#define PIC_WD0_COUNT        0x0d
+#define PIC_WD0_MASK_0       0x0e
+#define PIC_WD0_MASK_1       0x0f
+#define PIC_WD0_HEARBEATCMD  0x10
+#define PIC_WD0_HEARBEAT_0   0x11
+#define PIC_WD0_HEARBEAT_1   0x12
+#define PIC_SYS_TIMER_0_COUNTER   0x22
+
+#define PIC_INT_THR_ENABLE_0_N01   0x2a
+#define PIC_INT_THR_ENABLE_0_N23   0x2b
+#define PIC_INT_THR_ENABLE_N01(id) (PIC_INT_THR_ENABLE_0_N12 + ((id) * 2))
+#define PIC_INT_THR_ENABLE_N23(id) (PIC_INT_THR_ENABLE_0_N12 + ((id) * 2))
+
+#define PIC_IRT_0   0x3a
+#define PIC_IRT(id) (PIC_IRT_0 + (id))
+#define PIC_CLOCK_TIMER     7
+#define ASM_XLP_IO_PIC_OFFSET        0xffffffffb8004100 /* TODO: This will change in to function */
+#define C_XLP_IO_PIC_OFFSET        0xffffffffb8004100ULL /* TODO: This will change in to function */
+#define XLP_IO_PIC_OFFSET        C_XLP_IO_PIC_OFFSET
+
+#ifndef __ASSEMBLY__
+#define __nlm_hal_set_irq_to_cpu	__nlm_hal_set_irt_to_cpu
+void __nlm_hal_set_irt_to_cpu(int, int);
+void __nlm_hal_release_irq(int);
+int __nlm_hal_request_irq(int, int);
+#define CPUIDBITS01(X) ((X) & 0x3)
+#define CPUIDBIT2(X) ((X >> 2) & 0x1)
+
+#if 0
+static inline int nlm_hal_irt_to_irq(int irt_num)
+{
+	return __nlm_hal_find_irt_from_irq(irt_num);
+}
+
+static inline int nlm_hal_irq_to_irt(int irq_num)
+{
+	int irt = __nlm_hal_find_irt_from_irq(irq_num); // same function
+	return irt;
+}
+#endif
+#define PIC_IRQ_IS_EDGE_TRIGGERED(irq) 0 // XLP interrupts are level triggered
+#define NODE_OFFSET(node) ((node) << 18)
+#define CPU_TO_NODE(cpu) ((cpu) >> 5)
+
+static __inline__ int nlm_hal_cpu_id(void)
+{
+	int cpu;
+
+	__asm__ __volatile__ (
+		".set push\n"
+		".set noreorder\n"
+		".set mips32\n"
+		"mfc0 %0, $15, 1\n"
+		"andi %0, %0, 0x3ff\n"
+		".set pop\n"
+		: "=r"(cpu)
+		);
+
+	return cpu;
+}
+
+typedef volatile unsigned long long pic_reg_t;
+
+static __inline__ pic_reg_t* nlm_hal_pic_offset(void)
+{
+	uint32_t cpu = nlm_hal_cpu_id();
+
+	return ((pic_reg_t *) (XLP_IO_PIC_OFFSET + NODE_OFFSET(CPU_TO_NODE(cpu))));
+}
+
+#ifdef CONFIG_64BIT
+
+static __inline__ void nlm_hal_write_pic_reg(pic_reg_t *base,
+		unsigned int offset, unsigned long long value)
+{
+	base[offset] = value;
+}
+
+static __inline__ unsigned long long nlm_hal_read_pic_reg(pic_reg_t *base,
+		unsigned int offset)
+{
+	return ((base)[offset]);
+}
+
+#else
+
+static __inline__ void nlm_hal_write_pic_reg(pic_reg_t *base, unsigned int offset, unsigned long long value)
+{
+        uint32_t lsw, msw;
+        uint64_t val;
+        uint32_t ls, ms;
+        unsigned long flags;
+
+        lsw = (uint32_t) (base+offset);
+        msw = (uint32_t) 0xffffffffUL;
+        val = (uint64_t)value;
+
+        ls = (uint32_t) (val & 0xffffffff);
+        ms = (uint32_t) (val >> 32);
+
+        enable_KX(flags);
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "dsll32 $8, %4, 0\n"
+                        "dsll32 %3, 0\n"
+                        "dsrl32 %3, 0\n"
+                        "or $8, $8, %3\n"
+                        "sd $8, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :
+                        :"r"(val), "r"(lsw), "r"(msw), "r"(ls), "r"(ms)
+                        :"$1", "$8");
+        disable_KX(flags);
+}
+ 
+static __inline__ unsigned long long nlm_hal_read_pic_reg(pic_reg_t *base, unsigned int offset)
+{
+        uint32_t lsw, msw;
+        uint64_t value = 0;
+        uint32_t lo, hi;
+        unsigned long flags;
+
+        lsw = (uint32_t) (base+offset);
+        msw = (uint32_t) 0xffffffffUL;
+
+        enable_KX(flags);
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %3, 0\n"
+                        "dsll32 %2, 0\n"
+                        "dsrl32 %2, 0\n"
+                        "or $1, $1, %2\n"
+                        "ld $8, 0($1) \n"
+                        "dsrl32 %1, $8, 0\n"
+                        "dsll32 $8, $8, 0\n"
+                        "dsrl32 %0, $8, 0\n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :"=r"(lo), "=r"(hi)
+                        :"r"(lsw), "r"(msw)
+                        :"$1", "$8");
+
+        disable_KX(flags);
+        value = hi;
+        value = (uint64_t) ((value<<32) | lo);
+        return (value);
+}
+#endif
+
+static __inline__ void nlm_hal_pic_send_ipi(int nmi, int vec, int node, int cpu)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	unsigned long long ipi = (nmi << 31) | (vec << 20) | (node << 17) | (1 << (cpu & 0xf));
+	if (cpu > 15) {
+		ipi |= 0x10000; // Setting bit 16 to select cpus 16-31
+	}
+	nlm_hal_write_pic_reg(mmio, PIC_IPI_CTL, ipi);
+}
+
+static __inline__ unsigned long long nlm_hal_pic_read_control(void)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	return nlm_hal_read_pic_reg(mmio, PIC_CTRL);
+}
+
+static __inline__ void nlm_hal_pic_write_control(unsigned long long control)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	nlm_hal_write_pic_reg(mmio, PIC_CTRL, control);
+}
+
+static __inline__ void nlm_hal_pic_update_control(unsigned long long control)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	nlm_hal_write_pic_reg(mmio, PIC_CTRL,
+			(control | nlm_hal_read_pic_reg(mmio, PIC_CTRL)));
+}
+
+static __inline__ void nlm_hal_ack_pic(int irt_num)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	nlm_hal_write_pic_reg(mmio, PIC_INT_ACK, irt_num);
+
+	/* Ack the Status register for Watchdog & System timers */
+	if (irt_num < 12) {
+		nlm_hal_write_pic_reg(mmio, PIC_STATUS, (1 << irt_num));
+	}
+}
+
+static __inline__ unsigned long long nlm_hal_pic_read_irt(int irt_num)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	return nlm_hal_read_pic_reg(mmio, PIC_IRT(irt_num));
+}
+
+static __inline__ void nlm_hal_pic_write_irt(int irt_num, int en, int nmi, int sch, int vec, int dt, int db, int dte)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	unsigned long long val = (((en & 0x1) << 31) | ((nmi & 0x1) << 29) | ((sch & 0x1) << 28) |
+				  ((vec & 0x3f) << 20) | ((dt & 0x1 ) << 19) | ((db & 0x7) << 16) |
+				  (dte & 0xffff));
+
+	nlm_hal_write_pic_reg(mmio, PIC_IRT(irt_num), val);
+}
+
+static __inline__ void nlm_hal_pic_write_irt_direct(int irt_num, int en, int nmi, int sch, int vec, int cpu)
+{
+	nlm_hal_pic_write_irt(irt_num, en, nmi, sch, vec, 1, CPUIDBIT2(cpu), CPUIDBITS01(cpu));
+	/* Does not support multi node support yet */
+}
+
+static __inline__ unsigned long long nlm_hal_pic_read_timer(int timer)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	return nlm_hal_read_pic_reg(mmio, PIC_SYS_TIMER_COUNTER(timer));
+}
+
+static __inline__ void nlm_hal_pic_write_timer(int timer, pic_reg_t value)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	nlm_hal_write_pic_reg(mmio, PIC_SYS_TIMER_COUNTER(timer), value);
+}
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* _NLM_HAL_PIC_H */
diff --git a/arch/mips/include/asm/netlogic/xlp_irq.h b/arch/mips/include/asm/netlogic/xlp_irq.h
new file mode 100644
index 0000000..cf8f0cd
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/xlp_irq.h
@@ -0,0 +1,281 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _ASM_NLM_XLP_IRQ_H
+#define _ASM_NLM_XLP_IRQ_H
+
+#include <asm/netlogic/pic.h>
+
+/* Defines for the IRQ numbers */
+/* We define NR_IRQs to be 254, but IRT entries are 160 in size
+ * Effectively, we cannot use anything more than 159 */
+#define NR_IRQS			384
+/* Maximum IRQ vector numbers supported by MIPS */
+#define XLP_EIRR_SIZE		64
+#define XLP_IRT_NUM	160
+#define XLP_IRQ_MAX	168	/* 0-7 are reserved + 160 IRT entries */
+
+/* The following interrupt assignments (0-7) are special.
+ * I need to find out what governs these assignments
+ * XXX
+ */
+#define fdebug(fmt,arg...)\
+	printk(KERN_DEBUG "%s:%d " fmt, __FILE__, __LINE__, ##arg)
+
+#define XLP_IRQ_DUMMY_UART           2
+#define XLP_IRQ_IPI_SMP_FUNCTION     3
+#define XLP_IRQ_IPI_SMP_RESCHEDULE   4
+// #define XLP_IRQ_REMOTE_DEBUG         5
+#define XLP_IRQ_MSGRING              5
+#define XLP_IRQ_OPROFILE             6
+#define XLP_IRQ_TIMER                7
+#define XLP_IRQ_RESERVED_MAX		8
+
+#define XLP_IRQ_IPI_SMP_KGDB	     50
+
+#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY
+#define XLP_IRQ_IPI_NETRX		49
+#define SMP_NETRX_IPI			32
+#endif /* CONFIG_NLMCOMMON_IP_FLOW_AFFINITY */
+
+/* if you want some common #defines, please do it here */
+#define NLM_IRQ_DUMMY_UART		XLP_IRQ_DUMMY_UART
+#define NLM_IRQ_IPI_SMP_FUNCTION	XLP_IRQ_IPI_SMP_FUNCTION
+#define NLM_IRQ_IPI_SMP_RESCHEDULE	XLP_IRQ_IPI_SMP_RESCHEDULE
+#define NLM_IRQ_REMOTE_DEBUG		XLP_IRQ_REMOTE_DEBUG
+#define NLM_IRQ_MSGRING			XLP_IRQ_MSGRING
+#define NLM_IRQ_TIMER			XLP_IRQ_TIMER
+#define NLM_IRQ_IPI_SMP_KGDB		XLP_IRQ_IPI_SMP_KGDB
+
+/* These are flags required for SMP
+ * Not XLP specifc -- possibly mips specific.
+ * Need to move out XXX
+ */
+#define SMP_CALL_KGDB_HOOK	8
+#define SMP_OPROFILE_IPI        16
+
+#define TIMER_CYCLES_MAXVAL        0xffffffffffffffffULL
+
+/*
+ *    IRT Map
+ */
+
+#define arch_setup_msi_irqs	arch_setup_msi_irqs /* defines arch. specific msi setup function */
+#define xlp_irq_to_irt(x)	((x) - XLP_IRQ_RESERVED_MAX)
+#define xlp_irt_to_irq(x)	((x) + XLP_IRQ_RESERVED_MAX)
+
+#define XLP_WD_BASE			(0 + XLP_IRQ_RESERVED_MAX)
+#define XLP_WD_IRQ_IRQ(x) (XLP_WD_BASE + (x))
+
+#define XLP_WD_NMI_IRT_OFFSET		(2 + XLP_IRQ_RESERVED_MAX)
+#define XLP_WD_NMI_IRQ(x) (XLP_WD_NMI_IRT_OFFSET + (x))
+
+#define XLP_TIMER_IRT_OFFSET		(4 + XLP_IRQ_RESERVED_MAX)
+#define XLP_TIMER_IRQ(x)	(XLP_TIMER_IRT_OFFSET + (x))
+
+#define XLP_MSGQ_IRT_OFFSET			(12 + XLP_IRQ_RESERVED_MAX)
+#define XLP_MSGQ_IRQ(x)	(XLP_MSGQ_IRT_OFFSET + (x))
+
+#define XLP_MSG_IRT_OFFSET			(44 + XLP_IRQ_RESERVED_MAX)
+#define XLP_MSG_IRQ(x)	(XLP_MSG_IRT_OFFSET + (x))
+
+#define XLP_PCIE_MSIX_IRT_OFFSET		(46 + XLP_IRQ_RESERVED_MAX)
+#define XLP_PCIE_MSIX_IRQ(x)	(XLP_PCIE_MSIX_IRT_OFFSET + (x))
+
+#define XLP_PCIE_LINK_IRT_OFFSET		(78 + XLP_IRQ_RESERVED_MAX)
+#define XLP_PCIE_LINK_IRQ(x)	(XLP_PCIE_LINK_IRT_OFFSET + (x))
+
+#define XLP_NAE_IRT_OFFSET			(82 + XLP_IRQ_RESERVED_MAX)
+#define XLP_XLP_NAE_IRQ(x)	(XLP_XLP_NAE_IRT_OFFSET + (x))
+
+#define XLP_POE_IRT_OFFSET			(114 + XLP_IRQ_RESERVED_MAX)
+#define XLP_POE_IRQ(x)	(XLP_POE_IRT_OFFSET + (x))
+
+#define XLP_USB_IRT_OFFSET			(115 + XLP_IRQ_RESERVED_MAX)
+#define XLP_USB_IRQ(x)	(XLP_USB_IRT_OFFSET + (x))
+
+#define XLP_DTR_IRT_OFFSET			(121 + XLP_IRQ_RESERVED_MAX)
+#define XLP_DTR_IRQ(x)	(XLP_DTR_IRT_OFFSET + (x))
+
+#define XLP_SAE_IRT_OFFSET			(122 + XLP_IRQ_RESERVED_MAX)
+#define XLP_SAE_IRQ(x)	(XLP_SAE_IRT_OFFSET + (x))
+
+#define XLP_RSA_IRT_OFFSET			(123 + XLP_IRQ_RESERVED_MAX)
+#define XLP_RSA_IRQ(x)	(XLP_RSA_IRT_OFFSET + (x))
+
+#define XLP_COMP_IRT_OFFSET			(124 + XLP_IRQ_RESERVED_MAX)
+#define XLP_COMP_IRQ(x)	(XLP_COMP_IRT_OFFSET + (x))
+
+#define XLP_FLASH_IRT_OFFSET		(128 + XLP_IRQ_RESERVED_MAX)
+#define XLP_FLASH_IRQ(x)	(XLP_FLASH_IRT_OFFSET + (x))
+
+#define	XLP_ICI_IRT_OFFSET			(131 + XLP_IRQ_RESERVED_MAX)
+#define XLP_ICI_IRQ(x)	(XLP_ICI_IRT_OFFSET + (x))
+
+#define	XLP_KBP_IRT_OFFSET			(132 + XLP_IRQ_RESERVED_MAX)
+#define XLP_KBP_IRQ(x)	(XLP_KBP_IRT_OFFSET + (x))
+
+#define XLP_UART_IRT_OFFSET			(133 + XLP_IRQ_RESERVED_MAX)
+#define XLP_UART_IRQ(x)	(XLP_UART_IRT_OFFSET + (x))
+
+#define XLP_I2C_IRT_OFFSET			(135 + XLP_IRQ_RESERVED_MAX)
+#define XLP_I2C_IRQ(x)	(XLP_I2C_IRT_OFFSET + (x))
+
+#define XLP_SM_IRT_OFFSET			(137 + XLP_IRQ_RESERVED_MAX)
+#define XLP_SM_IRQ(x)	(XLP_SM_IRT_OFFSET + (x))
+
+#define	XLP_JTAG_IRT_OFFSET			(139 + XLP_IRQ_RESERVED_MAX)
+#define XLP_JTAG_IRQ(x)	(XLP_JTAG_IRT_OFFSET + (x))
+
+#define XLP_PIC_IRT_OFFSET			(140 + XLP_IRQ_RESERVED_MAX)
+#define XLP_PIC_IRQ(x)	(XLP_PIC_IRT_OFFSET + (x))
+
+#define XLP_MIOCB_IRT_OFFSET		(141 + XLP_IRQ_RESERVED_MAX)
+#define XLP_MIOCB_IRQ(x)	(XLP_MIOCB_IRT_OFFSET + (x))
+
+#define XLP_TCU_IRT_OFFSET			(142 + XLP_IRQ_RESERVED_MAX)
+#define XLP_TCU_IRQ(x)	(XLP_TCU_IRT_OFFSET + (x))
+
+#define XLP_GCU_IRT_OFFSET			(143 + XLP_IRQ_RESERVED_MAX)
+#define XLP_GCU_IRQ(x)	(XLP_GCU_IRT_OFFSET + (x))
+
+#define XLP_DRAM_IRT_OFFSET			(144 + XLP_IRQ_RESERVED_MAX)
+#define XLP_DRAM_IRQ(x)	(XLP_DRAM_IRT_OFFSET + (x))
+
+#define XLP_GPIO_IRT_OFFSET			(146 + XLP_IRQ_RESERVED_MAX)
+#define XLP_GPIO_IRQ(x)	(XLP_GPIO_IRT_OFFSET + (x))
+
+#define XLP_NOR_IRT_OFFSET			(150 + XLP_IRQ_RESERVED_MAX)
+#define XLP_NOR_IRQ(x)	(XLP_NOR_IRT_OFFSET + (x))
+
+#define XLP_NAND_IRT_OFFSET			(151 + XLP_IRQ_RESERVED_MAX)
+#define XLP_NAND_IRQ(x)	(XLP_NAND_IRT_OFFSET + (x))
+
+#define XLP_SPI_IRT_OFFSET			(152 + XLP_IRQ_RESERVED_MAX)
+#define XLP_SPI_IRQ(x)	(XLP_SPI_IRT_OFFSET + (x))
+
+#define XLP_MMC_IRT_OFFSET			(153 + XLP_IRQ_RESERVED_MAX)
+#define XLP_MMC_IRQ(x)	(XLP_MMC_IRT_OFFSET + (x))
+
+/* The following are the values supported per slot. A slot can have a device or
+ * a bridge, but only this much MSI/MSI-X can be alloted on that slot
+ * This is a kludge to keep NR_IRQS == 256 and can be expanded later
+ * We are using IRQ 192 - 255 for MSI/MSI-X
+ * */
+
+#define XLP_PIC_IRTREG_START 0xB4
+#define XLP_ITE_ENTRIES		8
+#ifdef CONFIG_XLP_MSI_ADDRESSES
+#define XLP_MSI_ADDR		0xFEE00000
+#endif
+#define XLP_INTX_TO_CTRL_FN(irq) ((irq - XLP_PCIE_LINK_IRQ(0)) & 0x3)
+#define XLP_MSI_ADDR_SIZE	0x00002000
+#define XLP_MSIX_ADDR_SIZE	0x00008000
+#define XLP_BDF_BASE(b,d,f)	(0x18000000 + ((b) << 20) + ((d) << 15) + ((f) << 12))
+#define XLP_MAX_SLOTS		4	/* Only 4 slots now */
+#define XLP_PCIE_CTRL_DEVFN(node, ctr)	PCI_DEVFN((node + 1), ctr)
+
+#ifdef CONFIG_PCI_MSI
+#define XLP_MSI_MM_CAP		5	/* Multiple message capability */
+#define XLP_MSI_PER_SLOT	(1 << XLP_MSI_MM_CAP)
+#define XLP_MSI_IRQ_OFFSET	256	/* Note IRQ not IRT */
+#define XLP_MSI_IRQ_START(fn)	(XLP_MSI_IRQ_OFFSET + (fn) * XLP_MSI_PER_SLOT)
+#define XLP_MSI_INDEX_START	XLP_MSI_IRQ_START(0)
+#define XLP_MSI_INDEX_END	(XLP_MSI_IRQ_START(XLP_MAX_SLOTS) - 1) /* 128 Vectors */
+#define XLP_MSI_TO_CTRL_FN(msi) (((msi) >> (XLP_MSI_MM_CAP)) & 3)
+
+#define XLP_MSIX_PER_SLOT	8
+#define XLP_MSIX_IRQ_OFFSET	192
+#define XLP_MSIX_TO_CTRL_FN(msix) (((msix) >> 3) & 3)
+#define XLP_MSIX_IRQ_START(fn)	(XLP_MSIX_IRQ_OFFSET + (fn) * XLP_MSIX_PER_SLOT)
+#define XLP_MSIX_INDEX_START	XLP_MSIX_IRQ_START(0)
+#define XLP_MSIX_INDEX_END	(XLP_MSIX_IRQ_START(XLP_MAX_SLOTS) - 1)// 31 vectors
+
+#endif
+
+#define	XLP_INTMODE_NONE  0
+#define	XLP_INTMODE_INTX  1
+#define	XLP_INTMODE_MSI  2
+#define	XLP_INTMODE_MSIX  4
+
+#define xlp_incr_ctrl_intmode(fn, mode) xlp_ctrl_intmode_add(fn, mode, 1)
+#define xlp_decr_ctrl_intmode(fn, mode) xlp_ctrl_intmode_add(fn, mode, -1)
+/*
+ *     Register Offsets
+ */
+#define PIC_CTRL             0x00
+#define PIC_BYTESWAP         0x01
+#define PIC_STATUS           0x02
+#define PIC_INT_TIMEOUT      0x03
+#define PIC_ICI0_INT_TIMEOUT 0x04
+#define PIC_ICI1_INT_TIMEOUT 0x05
+#define PIC_ICI2_INT_TIMEOUT 0x06
+#define PIC_IPI_CTL          0x07
+#define PIC_INT_ACK          0x08
+#define PIC_INT_PENDING0     0x09
+#define PIC_INT_PENDING1     0x0a
+#define PIC_INT_PENDING2     0x0b
+
+#define PIC_WD0_MAX_VAL      0x0c
+#define PIC_WD0_COUNT        0x0d
+#define PIC_WD0_MASK_0       0x0e
+#define PIC_WD0_MASK_1       0x0f
+#define PIC_WD0_HEARBEATCMD  0x10
+#define PIC_WD0_HEARBEAT_0   0x11
+#define PIC_WD0_HEARBEAT_1   0x12
+
+#define PIC_WD_MAX_VAL(id)    (PIC_WD0_MAX_VAL + ((id) ? 7 : 0))
+#define PIC_WD_COUNT(id)      (PIC_WD0_COUNT + ((id) ? 7 : 0))
+#define PIC_WD_MASK_0(id)     (PIC_WD0_MASK_0 + ((id) ? 7 : 0))
+#define PIC_WD_MASK_1(id)     (PIC_WD0_MASK_1 + ((id) ? 7 : 0))
+#define PIC_WD_HEARBEAT_0(id) (PIC_WD0_HEARTBEAT_0 + ((id) ? 7 : 0))
+#define PIC_WD_HEARBEAT_1(id) (PIC_WD0_HEARTBEAT_1 + ((id) ? 7 : 0))
+
+#define PIC_SYS_TIMER_0_MAX_VAL   0x1a
+#define PIC_SYS_TIMER_MAX_VAL(id) (PIC_SYS_TIMER_0_MAX_VAL + (id))
+
+#define PIC_SYS_TIMER_0_COUNTER   0x22
+#define PIC_SYS_TIMER_COUNTER(id) (PIC_SYS_TIMER_0_COUNTER + (id))
+
+#define PIC_TIMER_0_MAXVAL   PIC_SYS_TIMER_0_MAX_VAL
+#define PIC_TIMER_0_COUNTER  PIC_SYS_TIMER_0_COUNTER
+#define PIC_TIMER_7_MAXVAL   PIC_SYS_TIMER_MAX_VAL(7)
+#define PIC_TIMER_7_COUNTER  PIC_SYS_TIMER_COUNTER(7)
+#define PIC_TIMER_6_MAXVAL   PIC_SYS_TIMER_MAX_VAL(6)
+#define PIC_TIMER_6_COUNTER  PIC_SYS_TIMER_COUNTER(6)
+
+#define PIC_INT_THR_ENABLE_0_N01   0x2a
+#define PIC_INT_THR_ENABLE_0_N23   0x2b
+#define PIC_INT_THR_ENABLE_N01(id) (PIC_INT_THR_ENABLE_0_N12 + ((id) * 2))
+#define PIC_INT_THR_ENABLE_N23(id) (PIC_INT_THR_ENABLE_0_N12 + ((id) * 2))
+
+#define PIC_IRT_0   0x3a
+#define PIC_IRT(id) (PIC_IRT_0 + (id))
+
+
+#define ASM_XLP_IO_PIC_OFFSET        0xffffffffb8004100 /* TODO: This will change in to function */
+#define C_XLP_IO_PIC_OFFSET        0xffffffffb8004100ULL /* TODO: This will change in to function */
+
+#endif
diff --git a/arch/mips/include/asm/netlogic/xlp_mac.h b/arch/mips/include/asm/netlogic/xlp_mac.h
index 23fe782..409d50c 100644
--- a/arch/mips/include/asm/netlogic/xlp_mac.h
+++ b/arch/mips/include/asm/netlogic/xlp_mac.h
@@ -1,5 +1,5 @@
 /***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
 reserved.
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are
@@ -27,8 +27,10 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #define _ASM_NLM_MAC_H
 
 #include <linux/types.h>
+#include <asm/netlogic/msgring.h>
 #include <asm/netlogic/iomap.h>
 #include <linux/skbuff.h>
+#include <asm/netlogic/config_net.h>
 
 #define IPSEC_PACKET_PAYLOAD_SIZE 1696
 #define PHXSEC_HMAC_LENGTH 64
@@ -957,6 +959,7 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #define NLM_RX_BUF_SIZE (MAC_MAX_FRAME_SIZE+BYTE_OFFSET+MAC_PREPAD+MAC_SKB_BACK_PTR_SIZE+SMP_CACHE_BYTES)
 #define MAC_CRC_LEN             4
 
+
 enum {
         SGMII_SPEED_10   = 0x00000000,
         SGMII_SPEED_100  = 0x02000000,
@@ -1015,9 +1018,126 @@ enum tsv_rsv_reg{
 	CARRY_REG_2 = 0x4d,
 };
 
-enum net_types { TYPE_GMAC = 0, TYPE_XGMAC, TYPE_SPI4, MAX_NET_TYPES };
+struct size_1_desc {
+	uint64_t entry0;
+};
+
+struct size_2_desc {
+	uint64_t entry0;
+	uint64_t entry1;
+};
+
+struct size_3_desc {
+	uint64_t entry0;
+	uint64_t entry1;
+	uint64_t entry2;
+};
+
+struct size_4_desc {
+	uint64_t entry0;
+	uint64_t entry1;
+	uint64_t entry2;
+	uint64_t entry3;
+};
+
+struct fr_desc {
+	struct size_1_desc d1;
+};
+
+union rx_tx_desc {
+	struct size_1_desc d1;
+};
+
+static inline int mac_make_desc_rfr(struct msgrng_msg *msg, int id, int type,
+				    unsigned long addr)
+{
+	int stid = 0;
+
+	if (type == TYPE_XGMAC) stid = msgrng_xgmac_stid_rfr(id);
+	else  {
+#ifdef MAC_SPLIT_MODE
+		stid =  msgrng_gmac_stid_rfr_split_mode(id);
+#else
+		stid = msgrng_gmac_stid_rfr(id);
+#endif
+	}
+	msg->msg0 = (((uint64_t)CTRL_REG_FREE << 61) |
+		     ((uint64_t)stid<<52) |
+		     (uint64_t)addr);
+	msg->msg1 = msg->msg2 = msg->msg3 = 0;
+	return stid;
+}
+
+
+
+static inline int
+msgrng_stid_rfr(int id, int type)
+{
+	int stid = 0;
+
+	if (type == TYPE_XGMAC)
+		stid = msgrng_xgmac_stid_rfr(id);
+	else  {
+		if (id < 4) {
+#ifdef MAC_SPLIT_MODE
+			stid =  msgrng_gmac_stid_rfr_split_mode(id);
+#else
+			stid = msgrng_gmac_stid_rfr(id);
+#endif
+		}
+		else
+			stid = msgrng_gmac1_stid_rfr(id);
+	}
+	return stid;
+}
+
+
+
+static inline int mac_make_desc_b0_rfr(struct msgrng_msg *msg, int id, int type,
+				       unsigned long addr)
+{
+	int stid = msgrng_stid_rfr(id, type);
+
+	msg->msg0 = (uint64_t)addr & 0xffffffffe0ULL;
+	msg->msg1 = msg->msg2 = msg->msg3 = 0;
+
+	return stid;
+}
+
+#define MAC_TX_DESC_ALIGNMENT (SMP_CACHE_BYTES - 1)
+static inline int mac_make_desc_tx(struct msgrng_msg *msg, int id, int type,
+				   unsigned long addr, int len)
+{
+	int tx_stid = 0;
+	int fr_stid = 0;
+	int desc_offset = addr & MAC_TX_DESC_ALIGNMENT;
+
+	if (type == TYPE_XGMAC) {
+		tx_stid = msgrng_xgmac_stid_tx(id);
+		fr_stid = 0;
+	}
+	else {
+		int cpu = hard_smp_processor_id() >> 2;
+		if (id < 4)
+			tx_stid = msgrng_gmac_stid_tx(id);
+		else
+			tx_stid = msgrng_gmac1_stid_tx(id);
+		fr_stid = (cpu << 3) + netlogic_thr_id();
+	}
+
+	msg->msg0 = ( ((uint64_t)CTRL_SNGL << 61) |
+		      ((uint64_t)desc_offset << 40) |
+		      ((uint64_t)tx_stid << 52) |
+		      ((uint64_t)addr & ~MAC_TX_DESC_ALIGNMENT)
+		);
+	msg->msg1 = ( ( (uint64_t)CTRL_EOP << 61) |
+		      ( ((uint64_t)fr_stid) << 54) |
+		      ( (uint64_t)len << 40)
+		);
+
+	msg->msg2 = msg->msg3 = 0;
 
-enum phy_modes { PHY_MODE_SGMII	= 1, PHY_MODE_RGMII = 2, 
-    PHY_MODE_SELECTABLE = 4, PHY_MODE_XAUI=8};
+	return tx_stid;
+}
 
 #endif
diff --git a/arch/mips/include/asm/ptrace.h b/arch/mips/include/asm/ptrace.h
index e11850f..96e6c18 100644
--- a/arch/mips/include/asm/ptrace.h
+++ b/arch/mips/include/asm/ptrace.h
@@ -52,6 +52,16 @@ struct pt_regs {
 	unsigned long long mpl[3];        /* MTM{0,1,2} */
 	unsigned long long mtp[3];        /* MTP{0,1,2} */
 #endif
+#ifdef CONFIG_NLM_ENABLE_COP2
+	unsigned long long tx_buf[4];
+	unsigned long long rx_buf[4];
+	unsigned int tx_msg_status;
+	unsigned int rx_msg_status;
+	unsigned int misc_status;
+	unsigned int msg_config;
+	unsigned int msg_err;
+#endif
+
 } __attribute__ ((aligned (8)));
 
 #ifdef __KERNEL__
diff --git a/arch/mips/kernel/asm-offsets.c b/arch/mips/kernel/asm-offsets.c
index ca6c832..d1d3236 100644
--- a/arch/mips/kernel/asm-offsets.c
+++ b/arch/mips/kernel/asm-offsets.c
@@ -69,6 +69,15 @@ void output_ptreg_defines(void)
 	OFFSET(PT_MPL, pt_regs, mpl);
 	OFFSET(PT_MTP, pt_regs, mtp);
 #endif /* CONFIG_CPU_CAVIUM_OCTEON */
+#ifdef CONFIG_NLM_ENABLE_COP2
+	OFFSET(NLM_COP2_TX_BUF, pt_regs, tx_buf);
+	OFFSET(NLM_COP2_RX_BUF, pt_regs, rx_buf);
+	OFFSET(NLM_COP2_TX_MSG_STATUS, pt_regs, tx_msg_status);
+	OFFSET(NLM_COP2_RX_MSG_STATUS, pt_regs, rx_msg_status);
+	OFFSET(NLM_COP2_MISC_STATUS, pt_regs, misc_status);
+	OFFSET(NLM_COP2_MSG_CONFIG, pt_regs, msg_config);
+	OFFSET(NLM_COP2_MSG_ERR, pt_regs, msg_err);
+#endif
 	DEFINE(PT_SIZE, sizeof(struct pt_regs));
 	BLANK();
 }
diff --git a/arch/mips/kernel/cpu-probe.c b/arch/mips/kernel/cpu-probe.c
index 08d8c53..3be15cf 100644
--- a/arch/mips/kernel/cpu-probe.c
+++ b/arch/mips/kernel/cpu-probe.c
@@ -963,9 +963,7 @@ static inline void cpu_probe_netlogic(struct cpuinfo_mips *c, int cpu)
 	case CHIP_PROCESSOR_ID_XLP_432:
 	case CHIP_PROCESSOR_ID_XLP_416:
 	case CHIP_PROCESSOR_ID_XLP_408:
-	case CHIP_PROCESSOR_ID_XLP_316:
-	case CHIP_PROCESSOR_ID_XLP_308:
-	case CHIP_PROCESSOR_ID_XLP_304:
+	case CHIP_PROCESSOR_ID_XLP_3XX:
 	case CHIP_PROCESSOR_ID_XLP_208:
 	case CHIP_PROCESSOR_ID_XLP_204:
 	case CHIP_PROCESSOR_ID_XLP_104:
@@ -980,7 +978,8 @@ static inline void cpu_probe_netlogic(struct cpuinfo_mips *c, int cpu)
 		c->tlbsize = ((read_c0_config6() >> 16) & 0xffff) + 1;
 		__cpu_name[cpu] = (const char *)get_cpu_info();
 
-		pr_info("Enabling XLP CPU (%s)\n", cpu_name_string());
+		printk("Enabling XLP CPU (%s): pr id 0x%x  smp id %d\n",
+		       cpu_name_string(), c->processor_id, cpu);
 	}
 	break;
 	default:
diff --git a/arch/mips/kernel/nlm_fs_handler.S b/arch/mips/kernel/nlm_fs_handler.S
index 1e7a1bb..33ed34d 100644
--- a/arch/mips/kernel/nlm_fs_handler.S
+++ b/arch/mips/kernel/nlm_fs_handler.S
@@ -223,6 +223,30 @@ NESTED(nlm_fs_mem_write32, PT_SIZE, sp)
 	fs_eret
 END(nlm_fs_mem_write32)
 
+NESTED(nlm_fs_mem_read16, PT_SIZE, sp)
+       /* address is in (t0-msb, t1-lsb) */
+       dsll32  k0, T0, 0
+       dsll32  k1, T1, 0
+       dsrl32  T1, k1, 0
+       or      T0, k0, T1
+
+       /* data is in t2 */
+       lh      T2, (T0)
+       fs_eret
+END(nlm_fs_mem_read16)
+
+NESTED(nlm_fs_mem_write16, PT_SIZE, sp)
+        /* address is in (t0-msb, t1-lsb) */
+        dsll32  k0, T0, 0
+        dsll32  k1, T1, 0
+        dsrl32  T1, k1, 0
+        or      T0, k0, T1
+
+        /* data is in t2 */
+        sh      T2, (T0)
+        fs_eret
+END(nlm_fs_mem_write16)
+
 NESTED(nlm_fs_c0_count, PT_SIZE, sp)
 
 	mfc0    T0, $9, 0
@@ -317,14 +341,14 @@ END(nlm_fs_perf_ctr_stop)
 
 NESTED(nlm_fs_processorId, PT_SIZE, sp)
 
-	mfc0    T1, $15, 0
+	mfc0    T0, $15, 0
 
 	fs_eret
 END(nlm_fs_processorId)
 
 NESTED(nlm_fs_read_timer, PT_SIZE, sp)
 
-#include <asm/netlogic/hal/nlm_hal_pic.h>
+#include <asm/netlogic/xlp_hal_pic.h>
         MFC0    k0, CP0_PRID, 1
         andi    k0, k0, 0x3ff
         srl     k0, k0, 5  /* grab node id */
diff --git a/arch/mips/netlogic/boot/.gitignore b/arch/mips/netlogic/boot/.gitignore
deleted file mode 100644
index 4e6faf1..0000000
--- a/arch/mips/netlogic/boot/.gitignore
+++ /dev/null
@@ -1,9 +0,0 @@
-fdt.c
-fdt.h
-fdt_ro.c
-fdt_rw.c
-fdt_strerror.c
-fdt_sw.c
-fdt_wip.c
-libfdt.h
-libfdt_internal.h
diff --git a/arch/mips/netlogic/boot/Makefile b/arch/mips/netlogic/boot/Makefile
index b9977ad..cd787ec 100644
--- a/arch/mips/netlogic/boot/Makefile
+++ b/arch/mips/netlogic/boot/Makefile
@@ -2,37 +2,6 @@
 # Makefile for the Flattened Device Tree for Netlogic XLP Kernels
 #
 
-obj-y	+= simple_alloc.o libfdt-wrapper.o
-libfdt	:= fdt.c fdt_ro.c fdt_wip.c fdt_sw.c fdt_rw.c fdt_strerror.c
-
-obj-y	+= $(addsuffix .o, $(basename $(libfdt)))
-libfdtheader := fdt.h libfdt.h libfdt_internal.h
-
-$(addprefix $(obj)/,$(libfdt) libfdt-wrapper.o): \
-	$(addprefix $(obj)/,$(libfdtheader))
-
-quiet_cmd_copy_libfdt = COPY    $@
-      cmd_copy_libfdt = cp $< $@
-
-$(addprefix $(obj)/,$(libfdt) $(libfdtheader)): $(obj)/%: $(srctree)/scripts/dtc/libfdt/%
-	$(call cmd,copy_libfdt)
-
-quiet_cmd_bootcc = BOOTCC  $@
-      cmd_bootcc = $(CROSS32CC) -Wp,-MD,$(depfile) $(BOOTCFLAGS) -c -o $@ $<
-
-quiet_cmd_bootas = BOOTAS  $@
-      cmd_bootas = $(CROSS32CC) -Wp,-MD,$(depfile) $(BOOTAFLAGS) -c -o $@ $<
-
-quiet_cmd_bootar = BOOTAR  $@
-      cmd_bootar = $(CROSS32AR) -cr $@.$$$$ $(filter-out FORCE,$^); mv $@.$$$$ $@
-
-$(obj-libfdt): $(obj)/%.o: $(srctree)/scripts/dtc/libfdt/%.c FORCE
-	$(call if_changed_dep,bootcc)
-$(patsubst %.c,%.o, $(filter %.c, $(src-boot))): %.o: %.c FORCE
-	$(Q)mkdir -p $(dir $@)
-	$(call if_changed_dep,bootcc)
-$(patsubst %.S,%.o, $(filter %.S, $(src-boot))): %.o: %.S FORCE
-	$(Q)mkdir -p $(dir $@)
-	$(call if_changed_dep,bootas)
-
-clean-files += $(libfdt) $(libfdtheader)
+obj-y  += simple_alloc.o
+obj-y  += libfdt-wrapper.o
+obj-y  += fdt.o fdt_ro.o fdt_wip.o fdt_sw.o fdt_rw.o fdt_strerror.o
diff --git a/arch/mips/netlogic/boot/fdt.c b/arch/mips/netlogic/boot/fdt.c
new file mode 100644
index 0000000..3d7dc7c
--- /dev/null
+++ b/arch/mips/netlogic/boot/fdt.c
@@ -0,0 +1,202 @@
+/*
+ * libfdt - Flat Device Tree manipulation
+ * Copyright (C) 2006 David Gibson, IBM Corporation.
+ *
+ * libfdt is dual licensed: you can use it either under the terms of
+ * the GPL, or the BSD license, at your option.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ *     You should have received a copy of the GNU General Public
+ *     License along with this library; if not, write to the Free
+ *     Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston,
+ *     MA 02110-1301 USA
+ *
+ * Alternatively,
+ *
+ *  b) Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *     1. Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *     2. Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ *     THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
+ *     CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
+ *     INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *     MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ *     DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ *     CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *     SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
+ *     NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ *     LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ *     HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ *     CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+ *     OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
+ *     EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include "libfdt_env.h"
+
+#include <fdt.h>
+#include <libfdt.h>
+
+#include "libfdt_internal.h"
+
+int fdt_check_header(const void *fdt)
+{
+	if (fdt_magic(fdt) == FDT_MAGIC) {
+		/* Complete tree */
+		if (fdt_version(fdt) < FDT_FIRST_SUPPORTED_VERSION)
+			return -FDT_ERR_BADVERSION;
+		if (fdt_last_comp_version(fdt) > FDT_LAST_SUPPORTED_VERSION)
+			return -FDT_ERR_BADVERSION;
+	} else if (fdt_magic(fdt) == FDT_SW_MAGIC) {
+		/* Unfinished sequential-write blob */
+		if (fdt_size_dt_struct(fdt) == 0)
+			return -FDT_ERR_BADSTATE;
+	} else {
+		return -FDT_ERR_BADMAGIC;
+	}
+
+	return 0;
+}
+
+const void *fdt_offset_ptr(const void *fdt, int offset, int len)
+{
+	const char *p;
+
+	if (fdt_version(fdt) >= 0x11)
+		if (((offset + len) < offset)
+		    || ((offset + len) > fdt_size_dt_struct(fdt)))
+			return NULL;
+
+	p = _fdt_offset_ptr(fdt, offset);
+
+	if (p + len < p)
+		return NULL;
+	return p;
+}
+
+uint32_t fdt_next_tag(const void *fdt, int offset, int *nextoffset)
+{
+	const uint32_t *tagp, *lenp;
+	uint32_t tag;
+	const char *p;
+
+	if (offset % FDT_TAGSIZE)
+		return -1;
+
+	tagp = fdt_offset_ptr(fdt, offset, FDT_TAGSIZE);
+	if (! tagp)
+		return FDT_END; /* premature end */
+	tag = fdt32_to_cpu(*tagp);
+	offset += FDT_TAGSIZE;
+
+	switch (tag) {
+	case FDT_BEGIN_NODE:
+		/* skip name */
+		do {
+			p = fdt_offset_ptr(fdt, offset++, 1);
+		} while (p && (*p != '\0'));
+		if (! p)
+			return FDT_END;
+		break;
+	case FDT_PROP:
+		lenp = fdt_offset_ptr(fdt, offset, sizeof(*lenp));
+		if (! lenp)
+			return FDT_END;
+		/* skip name offset, length and value */
+		offset += 2*FDT_TAGSIZE + fdt32_to_cpu(*lenp);
+		break;
+	}
+
+	if (nextoffset)
+		*nextoffset = FDT_TAGALIGN(offset);
+
+	return tag;
+}
+
+int _fdt_check_node_offset(const void *fdt, int offset)
+{
+	if ((offset < 0) || (offset % FDT_TAGSIZE)
+	    || (fdt_next_tag(fdt, offset, &offset) != FDT_BEGIN_NODE))
+		return -FDT_ERR_BADOFFSET;
+
+	return offset;
+}
+
+int fdt_next_node(const void *fdt, int offset, int *depth)
+{
+	int nextoffset = 0;
+	uint32_t tag;
+
+	if (offset >= 0)
+		if ((nextoffset = _fdt_check_node_offset(fdt, offset)) < 0)
+			return nextoffset;
+
+	do {
+		offset = nextoffset;
+		tag = fdt_next_tag(fdt, offset, &nextoffset);
+
+		switch (tag) {
+		case FDT_PROP:
+		case FDT_NOP:
+			break;
+
+		case FDT_BEGIN_NODE:
+			if (depth)
+				(*depth)++;
+			break;
+
+		case FDT_END_NODE:
+			if (depth)
+				(*depth)--;
+			break;
+
+		case FDT_END:
+			return -FDT_ERR_NOTFOUND;
+
+		default:
+			return -FDT_ERR_BADSTRUCTURE;
+		}
+	} while (tag != FDT_BEGIN_NODE);
+
+	return offset;
+}
+
+const char *_fdt_find_string(const char *strtab, int tabsize, const char *s)
+{
+	int len = strlen(s) + 1;
+	const char *last = strtab + tabsize - len;
+	const char *p;
+
+	for (p = strtab; p <= last; p++)
+		if (memcmp(p, s, len) == 0)
+			return p;
+	return NULL;
+}
+
+int fdt_move(const void *fdt, void *buf, int bufsize)
+{
+#if 0
+	FDT_CHECK_HEADER(fdt);
+
+	if (fdt_totalsize(fdt) > bufsize)
+		return -FDT_ERR_NOSPACE;
+#endif
+	memcpy(buf, fdt, fdt_totalsize(fdt));
+	return 0;
+}
diff --git a/arch/mips/netlogic/boot/fdt.h b/arch/mips/netlogic/boot/fdt.h
new file mode 100644
index 0000000..48ccfd9
--- /dev/null
+++ b/arch/mips/netlogic/boot/fdt.h
@@ -0,0 +1,60 @@
+#ifndef _FDT_H
+#define _FDT_H
+
+#ifndef __ASSEMBLY__
+
+struct fdt_header {
+	uint32_t magic;			 /* magic word FDT_MAGIC */
+	uint32_t totalsize;		 /* total size of DT block */
+	uint32_t off_dt_struct;		 /* offset to structure */
+	uint32_t off_dt_strings;	 /* offset to strings */
+	uint32_t off_mem_rsvmap;	 /* offset to memory reserve map */
+	uint32_t version;		 /* format version */
+	uint32_t last_comp_version;	 /* last compatible version */
+
+	/* version 2 fields below */
+	uint32_t boot_cpuid_phys;	 /* Which physical CPU id we're
+					    booting on */
+	/* version 3 fields below */
+	uint32_t size_dt_strings;	 /* size of the strings block */
+
+	/* version 17 fields below */
+	uint32_t size_dt_struct;	 /* size of the structure block */
+};
+
+struct fdt_reserve_entry {
+	uint64_t address;
+	uint64_t size;
+};
+
+struct fdt_node_header {
+	uint32_t tag;
+	char name[0];
+};
+
+struct fdt_property {
+	uint32_t tag;
+	uint32_t len;
+	uint32_t nameoff;
+	char data[0];
+};
+
+#endif /* !__ASSEMBLY */
+
+#define FDT_MAGIC	0xd00dfeed	/* 4: version, 4: total size */
+#define FDT_TAGSIZE	sizeof(uint32_t)
+
+#define FDT_BEGIN_NODE	0x1		/* Start node: full name */
+#define FDT_END_NODE	0x2		/* End node */
+#define FDT_PROP	0x3		/* Property: name off,
+					   size, content */
+#define FDT_NOP		0x4		/* nop */
+#define FDT_END		0x9
+
+#define FDT_V1_SIZE	(7*sizeof(uint32_t))
+#define FDT_V2_SIZE	(FDT_V1_SIZE + sizeof(uint32_t))
+#define FDT_V3_SIZE	(FDT_V2_SIZE + sizeof(uint32_t))
+#define FDT_V16_SIZE	FDT_V3_SIZE
+#define FDT_V17_SIZE	(FDT_V16_SIZE + sizeof(uint32_t))
+
+#endif /* _FDT_H */
diff --git a/arch/mips/netlogic/boot/fdt_ro.c b/arch/mips/netlogic/boot/fdt_ro.c
new file mode 100644
index 0000000..22e6929
--- /dev/null
+++ b/arch/mips/netlogic/boot/fdt_ro.c
@@ -0,0 +1,469 @@
+/*
+ * libfdt - Flat Device Tree manipulation
+ * Copyright (C) 2006 David Gibson, IBM Corporation.
+ *
+ * libfdt is dual licensed: you can use it either under the terms of
+ * the GPL, or the BSD license, at your option.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ *     You should have received a copy of the GNU General Public
+ *     License along with this library; if not, write to the Free
+ *     Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston,
+ *     MA 02110-1301 USA
+ *
+ * Alternatively,
+ *
+ *  b) Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *     1. Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *     2. Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ *     THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
+ *     CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
+ *     INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *     MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ *     DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ *     CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *     SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
+ *     NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ *     LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ *     HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ *     CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+ *     OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
+ *     EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include "libfdt_env.h"
+
+#include <fdt.h>
+#include <libfdt.h>
+
+#include "libfdt_internal.h"
+
+static int _fdt_nodename_eq(const void *fdt, int offset,
+			    const char *s, int len)
+{
+	const char *p = fdt_offset_ptr(fdt, offset + FDT_TAGSIZE, len+1);
+
+	if (! p)
+		/* short match */
+		return 0;
+
+	if (memcmp(p, s, len) != 0)
+		return 0;
+
+	if (p[len] == '\0')
+		return 1;
+	else if (!memchr(s, '@', len) && (p[len] == '@'))
+		return 1;
+	else
+		return 0;
+}
+
+const char *fdt_string(const void *fdt, int stroffset)
+{
+	return (const char *)fdt + fdt_off_dt_strings(fdt) + stroffset;
+}
+
+int fdt_get_mem_rsv(const void *fdt, int n, uint64_t *address, uint64_t *size)
+{
+	FDT_CHECK_HEADER(fdt);
+	*address = fdt64_to_cpu(_fdt_mem_rsv(fdt, n)->address);
+	*size = fdt64_to_cpu(_fdt_mem_rsv(fdt, n)->size);
+	return 0;
+}
+
+int fdt_num_mem_rsv(const void *fdt)
+{
+	int i = 0;
+
+	while (fdt64_to_cpu(_fdt_mem_rsv(fdt, i)->size) != 0)
+		i++;
+	return i;
+}
+
+int fdt_subnode_offset_namelen(const void *fdt, int offset,
+			       const char *name, int namelen)
+{
+	int depth;
+
+	FDT_CHECK_HEADER(fdt);
+
+	for (depth = 0, offset = fdt_next_node(fdt, offset, &depth);
+	     (offset >= 0) && (depth > 0);
+	     offset = fdt_next_node(fdt, offset, &depth)) {
+		if (depth < 0)
+			return -FDT_ERR_NOTFOUND;
+		else if ((depth == 1)
+			 && _fdt_nodename_eq(fdt, offset, name, namelen))
+			return offset;
+	}
+
+	if (offset < 0)
+		return offset; /* error */
+	else
+		return -FDT_ERR_NOTFOUND;
+}
+
+int fdt_subnode_offset(const void *fdt, int parentoffset,
+		       const char *name)
+{
+	return fdt_subnode_offset_namelen(fdt, parentoffset, name, strlen(name));
+}
+
+int fdt_path_offset(const void *fdt, const char *path)
+{
+	const char *end = path + strlen(path);
+	const char *p = path;
+	int offset = 0;
+
+	FDT_CHECK_HEADER(fdt);
+
+	if (*path != '/')
+		return -FDT_ERR_BADPATH;
+
+	while (*p) {
+		const char *q;
+
+		while (*p == '/')
+			p++;
+		if (! *p)
+			return offset;
+		q = strchr(p, '/');
+		if (! q)
+			q = end;
+
+		offset = fdt_subnode_offset_namelen(fdt, offset, p, q-p);
+		if (offset < 0)
+			return offset;
+
+		p = q;
+	}
+
+	return offset;
+}
+
+const char *fdt_get_name(const void *fdt, int nodeoffset, int *len)
+{
+	const struct fdt_node_header *nh = _fdt_offset_ptr(fdt, nodeoffset);
+	int err;
+
+	if (((err = fdt_check_header(fdt)) != 0)
+	    || ((err = _fdt_check_node_offset(fdt, nodeoffset)) < 0))
+			goto fail;
+
+	if (len)
+		*len = strlen(nh->name);
+
+	return nh->name;
+
+ fail:
+	if (len)
+		*len = err;
+	return NULL;
+}
+
+const struct fdt_property *fdt_get_property(const void *fdt,
+					    int nodeoffset,
+					    const char *name, int *lenp)
+{
+	uint32_t tag;
+	const struct fdt_property *prop;
+	int namestroff;
+	int offset, nextoffset;
+	int err;
+
+	if (((err = fdt_check_header(fdt)) != 0)
+	    || ((err = _fdt_check_node_offset(fdt, nodeoffset)) < 0))
+			goto fail;
+
+	nextoffset = err;
+	do {
+		offset = nextoffset;
+
+		tag = fdt_next_tag(fdt, offset, &nextoffset);
+		switch (tag) {
+		case FDT_END:
+			err = -FDT_ERR_TRUNCATED;
+			goto fail;
+
+		case FDT_BEGIN_NODE:
+		case FDT_END_NODE:
+		case FDT_NOP:
+			break;
+
+		case FDT_PROP:
+			err = -FDT_ERR_BADSTRUCTURE;
+			prop = fdt_offset_ptr(fdt, offset, sizeof(*prop));
+			if (! prop)
+				goto fail;
+			namestroff = fdt32_to_cpu(prop->nameoff);
+			if (strcmp(fdt_string(fdt, namestroff), name) == 0) {
+				/* Found it! */
+				int len = fdt32_to_cpu(prop->len);
+				prop = fdt_offset_ptr(fdt, offset,
+						      sizeof(*prop)+len);
+				if (! prop)
+					goto fail;
+
+				if (lenp)
+					*lenp = len;
+
+				return prop;
+			}
+			break;
+
+		default:
+			err = -FDT_ERR_BADSTRUCTURE;
+			goto fail;
+		}
+	} while ((tag != FDT_BEGIN_NODE) && (tag != FDT_END_NODE));
+
+	err = -FDT_ERR_NOTFOUND;
+ fail:
+	if (lenp)
+		*lenp = err;
+	return NULL;
+}
+
+const void *fdt_getprop(const void *fdt, int nodeoffset,
+		  const char *name, int *lenp)
+{
+	const struct fdt_property *prop;
+
+	prop = fdt_get_property(fdt, nodeoffset, name, lenp);
+	if (! prop)
+		return NULL;
+
+	return prop->data;
+}
+
+uint32_t fdt_get_phandle(const void *fdt, int nodeoffset)
+{
+	const uint32_t *php;
+	int len;
+
+	php = fdt_getprop(fdt, nodeoffset, "linux,phandle", &len);
+	if (!php || (len != sizeof(*php)))
+		return 0;
+
+	return fdt32_to_cpu(*php);
+}
+
+int fdt_get_path(const void *fdt, int nodeoffset, char *buf, int buflen)
+{
+	int pdepth = 0, p = 0;
+	int offset, depth, namelen;
+	const char *name;
+
+	FDT_CHECK_HEADER(fdt);
+
+	if (buflen < 2)
+		return -FDT_ERR_NOSPACE;
+
+	for (offset = 0, depth = 0;
+	     (offset >= 0) && (offset <= nodeoffset);
+	     offset = fdt_next_node(fdt, offset, &depth)) {
+		if (pdepth < depth)
+			continue; /* overflowed buffer */
+
+		while (pdepth > depth) {
+			do {
+				p--;
+			} while (buf[p-1] != '/');
+			pdepth--;
+		}
+
+		name = fdt_get_name(fdt, offset, &namelen);
+		if (!name)
+			return namelen;
+		if ((p + namelen + 1) <= buflen) {
+			memcpy(buf + p, name, namelen);
+			p += namelen;
+			buf[p++] = '/';
+			pdepth++;
+		}
+
+		if (offset == nodeoffset) {
+			if (pdepth < (depth + 1))
+				return -FDT_ERR_NOSPACE;
+
+			if (p > 1) /* special case so that root path is "/", not "" */
+				p--;
+			buf[p] = '\0';
+			return p;
+		}
+	}
+
+	if ((offset == -FDT_ERR_NOTFOUND) || (offset >= 0))
+		return -FDT_ERR_BADOFFSET;
+	else if (offset == -FDT_ERR_BADOFFSET)
+		return -FDT_ERR_BADSTRUCTURE;
+
+	return offset; /* error from fdt_next_node() */
+}
+
+int fdt_supernode_atdepth_offset(const void *fdt, int nodeoffset,
+				 int supernodedepth, int *nodedepth)
+{
+	int offset, depth;
+	int supernodeoffset = -FDT_ERR_INTERNAL;
+
+	FDT_CHECK_HEADER(fdt);
+
+	if (supernodedepth < 0)
+		return -FDT_ERR_NOTFOUND;
+
+	for (offset = 0, depth = 0;
+	     (offset >= 0) && (offset <= nodeoffset);
+	     offset = fdt_next_node(fdt, offset, &depth)) {
+		if (depth == supernodedepth)
+			supernodeoffset = offset;
+
+		if (offset == nodeoffset) {
+			if (nodedepth)
+				*nodedepth = depth;
+
+			if (supernodedepth > depth)
+				return -FDT_ERR_NOTFOUND;
+			else
+				return supernodeoffset;
+		}
+	}
+
+	if ((offset == -FDT_ERR_NOTFOUND) || (offset >= 0))
+		return -FDT_ERR_BADOFFSET;
+	else if (offset == -FDT_ERR_BADOFFSET)
+		return -FDT_ERR_BADSTRUCTURE;
+
+	return offset; /* error from fdt_next_node() */
+}
+
+int fdt_node_depth(const void *fdt, int nodeoffset)
+{
+	int nodedepth;
+	int err;
+
+	err = fdt_supernode_atdepth_offset(fdt, nodeoffset, 0, &nodedepth);
+	if (err)
+		return (err < 0) ? err : -FDT_ERR_INTERNAL;
+	return nodedepth;
+}
+
+int fdt_parent_offset(const void *fdt, int nodeoffset)
+{
+	int nodedepth = fdt_node_depth(fdt, nodeoffset);
+
+	if (nodedepth < 0)
+		return nodedepth;
+	return fdt_supernode_atdepth_offset(fdt, nodeoffset,
+					    nodedepth - 1, NULL);
+}
+
+int fdt_node_offset_by_prop_value(const void *fdt, int startoffset,
+				  const char *propname,
+				  const void *propval, int proplen)
+{
+	int offset;
+	const void *val;
+	int len;
+
+	FDT_CHECK_HEADER(fdt);
+
+	/* FIXME: The algorithm here is pretty horrible: we scan each
+	 * property of a node in fdt_getprop(), then if that didn't
+	 * find what we want, we scan over them again making our way
+	 * to the next node.  Still it's the easiest to implement
+	 * approach; performance can come later. */
+	for (offset = fdt_next_node(fdt, startoffset, NULL);
+	     offset >= 0;
+	     offset = fdt_next_node(fdt, offset, NULL)) {
+		val = fdt_getprop(fdt, offset, propname, &len);
+		if (val && (len == proplen)
+		    && (memcmp(val, propval, len) == 0))
+			return offset;
+	}
+
+	return offset; /* error from fdt_next_node() */
+}
+
+int fdt_node_offset_by_phandle(const void *fdt, uint32_t phandle)
+{
+	if ((phandle == 0) || (phandle == -1))
+		return -FDT_ERR_BADPHANDLE;
+	phandle = cpu_to_fdt32(phandle);
+	return fdt_node_offset_by_prop_value(fdt, -1, "linux,phandle",
+					     &phandle, sizeof(phandle));
+}
+
+static int _stringlist_contains(const char *strlist, int listlen, const char *str)
+{
+	int len = strlen(str);
+	const char *p;
+
+	while (listlen >= len) {
+		if (memcmp(str, strlist, len+1) == 0)
+			return 1;
+		p = memchr(strlist, '\0', listlen);
+		if (!p)
+			return 0; /* malformed strlist.. */
+		listlen -= (p-strlist) + 1;
+		strlist = p + 1;
+	}
+	return 0;
+}
+
+int fdt_node_check_compatible(const void *fdt, int nodeoffset,
+			      const char *compatible)
+{
+	const void *prop;
+	int len;
+
+	prop = fdt_getprop(fdt, nodeoffset, "compatible", &len);
+	if (!prop)
+		return len;
+	if (_stringlist_contains(prop, len, compatible))
+		return 0;
+	else
+		return 1;
+}
+
+int fdt_node_offset_by_compatible(const void *fdt, int startoffset,
+				  const char *compatible)
+{
+	int offset, err;
+
+	FDT_CHECK_HEADER(fdt);
+
+	/* FIXME: The algorithm here is pretty horrible: we scan each
+	 * property of a node in fdt_node_check_compatible(), then if
+	 * that didn't find what we want, we scan over them again
+	 * making our way to the next node.  Still it's the easiest to
+	 * implement approach; performance can come later. */
+	for (offset = fdt_next_node(fdt, startoffset, NULL);
+	     offset >= 0;
+	     offset = fdt_next_node(fdt, offset, NULL)) {
+		err = fdt_node_check_compatible(fdt, offset, compatible);
+		if ((err < 0) && (err != -FDT_ERR_NOTFOUND))
+			return err;
+		else if (err == 0)
+			return offset;
+	}
+
+	return offset; /* error from fdt_next_node() */
+}
diff --git a/arch/mips/netlogic/boot/fdt_rw.c b/arch/mips/netlogic/boot/fdt_rw.c
new file mode 100644
index 0000000..3b1b1c7
--- /dev/null
+++ b/arch/mips/netlogic/boot/fdt_rw.c
@@ -0,0 +1,474 @@
+/*
+ * libfdt - Flat Device Tree manipulation
+ * Copyright (C) 2006 David Gibson, IBM Corporation.
+ *
+ * libfdt is dual licensed: you can use it either under the terms of
+ * the GPL, or the BSD license, at your option.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ *     You should have received a copy of the GNU General Public
+ *     License along with this library; if not, write to the Free
+ *     Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston,
+ *     MA 02110-1301 USA
+ *
+ * Alternatively,
+ *
+ *  b) Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *     1. Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *     2. Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ *     THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
+ *     CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
+ *     INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *     MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ *     DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ *     CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *     SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
+ *     NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ *     LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ *     HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ *     CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+ *     OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
+ *     EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include "libfdt_env.h"
+
+#include <fdt.h>
+#include <libfdt.h>
+
+#include "libfdt_internal.h"
+
+static int _fdt_blocks_misordered(const void *fdt,
+			      int mem_rsv_size, int struct_size)
+{
+	return (fdt_off_mem_rsvmap(fdt) < FDT_ALIGN(sizeof(struct fdt_header), 8))
+		|| (fdt_off_dt_struct(fdt) <
+		    (fdt_off_mem_rsvmap(fdt) + mem_rsv_size))
+		|| (fdt_off_dt_strings(fdt) <
+		    (fdt_off_dt_struct(fdt) + struct_size))
+		|| (fdt_totalsize(fdt) <
+		    (fdt_off_dt_strings(fdt) + fdt_size_dt_strings(fdt)));
+}
+
+static int _fdt_rw_check_header(void *fdt)
+{
+	FDT_CHECK_HEADER(fdt);
+
+	if (fdt_version(fdt) < 17)
+		return -FDT_ERR_BADVERSION;
+	if (_fdt_blocks_misordered(fdt, sizeof(struct fdt_reserve_entry),
+				   fdt_size_dt_struct(fdt)))
+		return -FDT_ERR_BADLAYOUT;
+	if (fdt_version(fdt) > 17)
+		fdt_set_version(fdt, 17);
+
+	return 0;
+}
+
+#define FDT_RW_CHECK_HEADER(fdt) \
+	{ \
+		int err; \
+		if ((err = _fdt_rw_check_header(fdt)) != 0) \
+			return err; \
+	}
+
+static inline int _fdt_data_size(void *fdt)
+{
+	return fdt_off_dt_strings(fdt) + fdt_size_dt_strings(fdt);
+}
+
+static int _fdt_splice(void *fdt, void *splicepoint, int oldlen, int newlen)
+{
+	char *p = splicepoint;
+	char *end = (char *)fdt + _fdt_data_size(fdt);
+
+	if (((p + oldlen) < p) || ((p + oldlen) > end))
+		return -FDT_ERR_BADOFFSET;
+	if ((end - oldlen + newlen) > ((char *)fdt + fdt_totalsize(fdt)))
+		return -FDT_ERR_NOSPACE;
+	memmove(p + newlen, p + oldlen, end - p - oldlen);
+	return 0;
+}
+
+static int _fdt_splice_mem_rsv(void *fdt, struct fdt_reserve_entry *p,
+			       int oldn, int newn)
+{
+	int delta = (newn - oldn) * sizeof(*p);
+	int err;
+	err = _fdt_splice(fdt, p, oldn * sizeof(*p), newn * sizeof(*p));
+	if (err)
+		return err;
+	fdt_set_off_dt_struct(fdt, fdt_off_dt_struct(fdt) + delta);
+	fdt_set_off_dt_strings(fdt, fdt_off_dt_strings(fdt) + delta);
+	return 0;
+}
+
+static int _fdt_splice_struct(void *fdt, void *p,
+			      int oldlen, int newlen)
+{
+	int delta = newlen - oldlen;
+	int err;
+
+	if ((err = _fdt_splice(fdt, p, oldlen, newlen)))
+		return err;
+
+	fdt_set_size_dt_struct(fdt, fdt_size_dt_struct(fdt) + delta);
+	fdt_set_off_dt_strings(fdt, fdt_off_dt_strings(fdt) + delta);
+	return 0;
+}
+
+static int _fdt_splice_string(void *fdt, int newlen)
+{
+	void *p = (char *)fdt
+		+ fdt_off_dt_strings(fdt) + fdt_size_dt_strings(fdt);
+	int err;
+
+	if ((err = _fdt_splice(fdt, p, 0, newlen)))
+		return err;
+
+	fdt_set_size_dt_strings(fdt, fdt_size_dt_strings(fdt) + newlen);
+	return 0;
+}
+
+static int _fdt_find_add_string(void *fdt, const char *s)
+{
+	char *strtab = (char *)fdt + fdt_off_dt_strings(fdt);
+	const char *p;
+	char *new;
+	int len = strlen(s) + 1;
+	int err;
+
+	p = _fdt_find_string(strtab, fdt_size_dt_strings(fdt), s);
+	if (p)
+		/* found it */
+		return (p - strtab);
+
+	new = strtab + fdt_size_dt_strings(fdt);
+	err = _fdt_splice_string(fdt, len);
+	if (err)
+		return err;
+
+	memcpy(new, s, len);
+	return (new - strtab);
+}
+
+int fdt_add_mem_rsv(void *fdt, uint64_t address, uint64_t size)
+{
+	struct fdt_reserve_entry *re;
+	int err;
+
+	FDT_RW_CHECK_HEADER(fdt);
+
+	re = _fdt_mem_rsv_w(fdt, fdt_num_mem_rsv(fdt));
+	err = _fdt_splice_mem_rsv(fdt, re, 0, 1);
+	if (err)
+		return err;
+
+	re->address = cpu_to_fdt64(address);
+	re->size = cpu_to_fdt64(size);
+	return 0;
+}
+
+int fdt_del_mem_rsv(void *fdt, int n)
+{
+	struct fdt_reserve_entry *re = _fdt_mem_rsv_w(fdt, n);
+	int err;
+
+	FDT_RW_CHECK_HEADER(fdt);
+
+	if (n >= fdt_num_mem_rsv(fdt))
+		return -FDT_ERR_NOTFOUND;
+
+	err = _fdt_splice_mem_rsv(fdt, re, 1, 0);
+	if (err)
+		return err;
+	return 0;
+}
+
+static int _fdt_resize_property(void *fdt, int nodeoffset, const char *name,
+				int len, struct fdt_property **prop)
+{
+	int oldlen;
+	int err;
+
+	*prop = fdt_get_property_w(fdt, nodeoffset, name, &oldlen);
+	if (! (*prop))
+		return oldlen;
+
+	if ((err = _fdt_splice_struct(fdt, (*prop)->data, FDT_TAGALIGN(oldlen),
+				      FDT_TAGALIGN(len))))
+		return err;
+
+	(*prop)->len = cpu_to_fdt32(len);
+	return 0;
+}
+
+static int _fdt_add_property(void *fdt, int nodeoffset, const char *name,
+			     int len, struct fdt_property **prop)
+{
+	int proplen;
+	int nextoffset;
+	int namestroff;
+	int err;
+
+	if ((nextoffset = _fdt_check_node_offset(fdt, nodeoffset)) < 0)
+		return nextoffset;
+
+	namestroff = _fdt_find_add_string(fdt, name);
+	if (namestroff < 0)
+		return namestroff;
+
+	*prop = _fdt_offset_ptr_w(fdt, nextoffset);
+	proplen = sizeof(**prop) + FDT_TAGALIGN(len);
+
+	err = _fdt_splice_struct(fdt, *prop, 0, proplen);
+	if (err)
+		return err;
+
+	(*prop)->tag = cpu_to_fdt32(FDT_PROP);
+	(*prop)->nameoff = cpu_to_fdt32(namestroff);
+	(*prop)->len = cpu_to_fdt32(len);
+	return 0;
+}
+
+int fdt_set_name(void *fdt, int nodeoffset, const char *name)
+{
+	char *namep;
+	int oldlen, newlen;
+	int err;
+
+	FDT_RW_CHECK_HEADER(fdt);
+
+	namep = (char *)(uintptr_t)fdt_get_name(fdt, nodeoffset, &oldlen);
+	if (!namep)
+		return oldlen;
+
+	newlen = strlen(name);
+
+	err = _fdt_splice_struct(fdt, namep, FDT_TAGALIGN(oldlen+1),
+				 FDT_TAGALIGN(newlen+1));
+	if (err)
+		return err;
+
+	memcpy(namep, name, newlen+1);
+	return 0;
+}
+
+int fdt_setprop(void *fdt, int nodeoffset, const char *name,
+		const void *val, int len)
+{
+	struct fdt_property *prop;
+	int err;
+
+	FDT_RW_CHECK_HEADER(fdt);
+
+	err = _fdt_resize_property(fdt, nodeoffset, name, len, &prop);
+	if (err == -FDT_ERR_NOTFOUND)
+		err = _fdt_add_property(fdt, nodeoffset, name, len, &prop);
+	if (err)
+		return err;
+
+	memcpy(prop->data, val, len);
+	return 0;
+}
+
+int fdt_delprop(void *fdt, int nodeoffset, const char *name)
+{
+	struct fdt_property *prop;
+	int len, proplen;
+
+	FDT_RW_CHECK_HEADER(fdt);
+
+	prop = fdt_get_property_w(fdt, nodeoffset, name, &len);
+	if (! prop)
+		return len;
+
+	proplen = sizeof(*prop) + FDT_TAGALIGN(len);
+	return _fdt_splice_struct(fdt, prop, proplen, 0);
+}
+
+int fdt_add_subnode_namelen(void *fdt, int parentoffset,
+			    const char *name, int namelen)
+{
+	struct fdt_node_header *nh;
+	int offset, nextoffset;
+	int nodelen;
+	int err;
+	uint32_t tag;
+	uint32_t *endtag;
+
+	FDT_RW_CHECK_HEADER(fdt);
+
+	offset = fdt_subnode_offset_namelen(fdt, parentoffset, name, namelen);
+	if (offset >= 0)
+		return -FDT_ERR_EXISTS;
+	else if (offset != -FDT_ERR_NOTFOUND)
+		return offset;
+
+	/* Try to place the new node after the parent's properties */
+	fdt_next_tag(fdt, parentoffset, &nextoffset); /* skip the BEGIN_NODE */
+	do {
+		offset = nextoffset;
+		tag = fdt_next_tag(fdt, offset, &nextoffset);
+	} while ((tag == FDT_PROP) || (tag == FDT_NOP));
+
+	nh = _fdt_offset_ptr_w(fdt, offset);
+	nodelen = sizeof(*nh) + FDT_TAGALIGN(namelen+1) + FDT_TAGSIZE;
+
+	err = _fdt_splice_struct(fdt, nh, 0, nodelen);
+	if (err)
+		return err;
+
+	nh->tag = cpu_to_fdt32(FDT_BEGIN_NODE);
+	memset(nh->name, 0, FDT_TAGALIGN(namelen+1));
+	memcpy(nh->name, name, namelen);
+	endtag = (uint32_t *)((char *)nh + nodelen - FDT_TAGSIZE);
+	*endtag = cpu_to_fdt32(FDT_END_NODE);
+
+	return offset;
+}
+
+int fdt_add_subnode(void *fdt, int parentoffset, const char *name)
+{
+	return fdt_add_subnode_namelen(fdt, parentoffset, name, strlen(name));
+}
+
+int fdt_del_node(void *fdt, int nodeoffset)
+{
+	int endoffset;
+
+	FDT_RW_CHECK_HEADER(fdt);
+
+	endoffset = _fdt_node_end_offset(fdt, nodeoffset);
+	if (endoffset < 0)
+		return endoffset;
+
+	return _fdt_splice_struct(fdt, _fdt_offset_ptr_w(fdt, nodeoffset),
+				  endoffset - nodeoffset, 0);
+}
+
+static void _fdt_packblocks(const char *old, char *new,
+			    int mem_rsv_size, int struct_size)
+{
+	int mem_rsv_off, struct_off, strings_off;
+
+	mem_rsv_off = FDT_ALIGN(sizeof(struct fdt_header), 8);
+	struct_off = mem_rsv_off + mem_rsv_size;
+	strings_off = struct_off + struct_size;
+
+	memmove(new + mem_rsv_off, old + fdt_off_mem_rsvmap(old), mem_rsv_size);
+	fdt_set_off_mem_rsvmap(new, mem_rsv_off);
+
+	memmove(new + struct_off, old + fdt_off_dt_struct(old), struct_size);
+	fdt_set_off_dt_struct(new, struct_off);
+	fdt_set_size_dt_struct(new, struct_size);
+
+	memmove(new + strings_off, old + fdt_off_dt_strings(old),
+		fdt_size_dt_strings(old));
+	fdt_set_off_dt_strings(new, strings_off);
+	fdt_set_size_dt_strings(new, fdt_size_dt_strings(old));
+}
+
+int fdt_open_into(const void *fdt, void *buf, int bufsize)
+{
+	int err;
+	int mem_rsv_size, struct_size;
+	int newsize;
+	const char *fdtstart = fdt;
+	const char *fdtend = fdtstart + fdt_totalsize(fdt);
+	char *tmp;
+
+	FDT_CHECK_HEADER(fdt);
+
+	mem_rsv_size = (fdt_num_mem_rsv(fdt)+1)
+		* sizeof(struct fdt_reserve_entry);
+	
+	__asm__ __volatile__ (
+			"sync\n"
+			"nop\n"
+			"nop\n"
+			"nop\n"
+			"nop\n"
+			"nop\n"
+			"nop\n"
+			"nop\n"
+			"sync\n");
+
+	if (fdt_version(fdt) >= 17) {
+		struct_size = fdt_size_dt_struct(fdt);
+	} else {
+		struct_size = 0;
+		while (fdt_next_tag(fdt, struct_size, &struct_size) != FDT_END)
+			;
+	}
+
+	if (!_fdt_blocks_misordered(fdt, mem_rsv_size, struct_size)) {
+		/* no further work necessary */
+		err = fdt_move(fdt, buf, bufsize);
+		if (err)
+			return err;
+		fdt_set_version(buf, 17);
+		fdt_set_size_dt_struct(buf, struct_size);
+		fdt_set_totalsize(buf, bufsize);
+		return 0;
+	}
+
+	/* Need to reorder */
+	newsize = FDT_ALIGN(sizeof(struct fdt_header), 8) + mem_rsv_size
+		+ struct_size + fdt_size_dt_strings(fdt);
+
+	if (bufsize < newsize)
+		return -FDT_ERR_NOSPACE;
+
+	/* First attempt to build converted tree at beginning of buffer */
+	tmp = buf;
+	/* But if that overlaps with the old tree... */
+	if (((tmp + newsize) > fdtstart) && (tmp < fdtend)) {
+		/* Try right after the old tree instead */
+		tmp = (char *)(uintptr_t)fdtend;
+		if ((tmp + newsize) > ((char *)buf + bufsize))
+			return -FDT_ERR_NOSPACE;
+	}
+
+	_fdt_packblocks(fdt, tmp, mem_rsv_size, struct_size);
+	memmove(buf, tmp, newsize);
+
+	fdt_set_magic(buf, FDT_MAGIC);
+	fdt_set_totalsize(buf, bufsize);
+	fdt_set_version(buf, 17);
+	fdt_set_last_comp_version(buf, 16);
+	fdt_set_boot_cpuid_phys(buf, fdt_boot_cpuid_phys(fdt));
+
+	return 0;
+}
+
+int fdt_pack(void *fdt)
+{
+	int mem_rsv_size;
+
+	FDT_RW_CHECK_HEADER(fdt);
+
+	mem_rsv_size = (fdt_num_mem_rsv(fdt)+1)
+		* sizeof(struct fdt_reserve_entry);
+	_fdt_packblocks(fdt, fdt, mem_rsv_size, fdt_size_dt_struct(fdt));
+	fdt_set_totalsize(fdt, _fdt_data_size(fdt));
+
+	return 0;
+}
diff --git a/arch/mips/netlogic/boot/fdt_strerror.c b/arch/mips/netlogic/boot/fdt_strerror.c
new file mode 100644
index 0000000..e6c3cee
--- /dev/null
+++ b/arch/mips/netlogic/boot/fdt_strerror.c
@@ -0,0 +1,96 @@
+/*
+ * libfdt - Flat Device Tree manipulation
+ * Copyright (C) 2006 David Gibson, IBM Corporation.
+ *
+ * libfdt is dual licensed: you can use it either under the terms of
+ * the GPL, or the BSD license, at your option.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ *     You should have received a copy of the GNU General Public
+ *     License along with this library; if not, write to the Free
+ *     Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston,
+ *     MA 02110-1301 USA
+ *
+ * Alternatively,
+ *
+ *  b) Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *     1. Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *     2. Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ *     THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
+ *     CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
+ *     INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *     MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ *     DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ *     CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *     SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
+ *     NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ *     LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ *     HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ *     CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+ *     OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
+ *     EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include "libfdt_env.h"
+
+#include <fdt.h>
+#include <libfdt.h>
+
+#include "libfdt_internal.h"
+
+struct fdt_errtabent {
+	const char *str;
+};
+
+#define FDT_ERRTABENT(val) \
+	[(val)] = { .str = #val, }
+
+static struct fdt_errtabent fdt_errtable[] = {
+	FDT_ERRTABENT(FDT_ERR_NOTFOUND),
+	FDT_ERRTABENT(FDT_ERR_EXISTS),
+	FDT_ERRTABENT(FDT_ERR_NOSPACE),
+
+	FDT_ERRTABENT(FDT_ERR_BADOFFSET),
+	FDT_ERRTABENT(FDT_ERR_BADPATH),
+	FDT_ERRTABENT(FDT_ERR_BADSTATE),
+
+	FDT_ERRTABENT(FDT_ERR_TRUNCATED),
+	FDT_ERRTABENT(FDT_ERR_BADMAGIC),
+	FDT_ERRTABENT(FDT_ERR_BADVERSION),
+	FDT_ERRTABENT(FDT_ERR_BADSTRUCTURE),
+	FDT_ERRTABENT(FDT_ERR_BADLAYOUT),
+};
+#define FDT_ERRTABSIZE	(sizeof(fdt_errtable) / sizeof(fdt_errtable[0]))
+
+const char *fdt_strerror(int errval)
+{
+	if (errval > 0)
+		return "<valid offset/length>";
+	else if (errval == 0)
+		return "<no error>";
+	else if (errval > -FDT_ERRTABSIZE) {
+		const char *s = fdt_errtable[-errval].str;
+
+		if (s)
+			return s;
+	}
+
+	return "<unknown error>";
+}
diff --git a/arch/mips/netlogic/boot/fdt_sw.c b/arch/mips/netlogic/boot/fdt_sw.c
new file mode 100644
index 0000000..698329e
--- /dev/null
+++ b/arch/mips/netlogic/boot/fdt_sw.c
@@ -0,0 +1,257 @@
+/*
+ * libfdt - Flat Device Tree manipulation
+ * Copyright (C) 2006 David Gibson, IBM Corporation.
+ *
+ * libfdt is dual licensed: you can use it either under the terms of
+ * the GPL, or the BSD license, at your option.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ *     You should have received a copy of the GNU General Public
+ *     License along with this library; if not, write to the Free
+ *     Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston,
+ *     MA 02110-1301 USA
+ *
+ * Alternatively,
+ *
+ *  b) Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *     1. Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *     2. Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ *     THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
+ *     CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
+ *     INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *     MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ *     DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ *     CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *     SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
+ *     NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ *     LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ *     HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ *     CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+ *     OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
+ *     EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include "libfdt_env.h"
+
+#include <fdt.h>
+#include <libfdt.h>
+
+#include "libfdt_internal.h"
+
+static int _fdt_sw_check_header(void *fdt)
+{
+	if (fdt_magic(fdt) != FDT_SW_MAGIC)
+		return -FDT_ERR_BADMAGIC;
+	/* FIXME: should check more details about the header state */
+	return 0;
+}
+
+#define FDT_SW_CHECK_HEADER(fdt) \
+	{ \
+		int err; \
+		if ((err = _fdt_sw_check_header(fdt)) != 0) \
+			return err; \
+	}
+
+static void *_fdt_grab_space(void *fdt, int len)
+{
+	int offset = fdt_size_dt_struct(fdt);
+	int spaceleft;
+
+	spaceleft = fdt_totalsize(fdt) - fdt_off_dt_struct(fdt)
+		- fdt_size_dt_strings(fdt);
+
+	if ((offset + len < offset) || (offset + len > spaceleft))
+		return NULL;
+
+	fdt_set_size_dt_struct(fdt, offset + len);
+	return fdt_offset_ptr_w(fdt, offset, len);
+}
+
+int fdt_create(void *buf, int bufsize)
+{
+	void *fdt = buf;
+
+	if (bufsize < sizeof(struct fdt_header))
+		return -FDT_ERR_NOSPACE;
+
+	memset(buf, 0, bufsize);
+
+	fdt_set_magic(fdt, FDT_SW_MAGIC);
+	fdt_set_version(fdt, FDT_LAST_SUPPORTED_VERSION);
+	fdt_set_last_comp_version(fdt, FDT_FIRST_SUPPORTED_VERSION);
+	fdt_set_totalsize(fdt,  bufsize);
+
+	fdt_set_off_mem_rsvmap(fdt, FDT_ALIGN(sizeof(struct fdt_header),
+					      sizeof(struct fdt_reserve_entry)));
+	fdt_set_off_dt_struct(fdt, fdt_off_mem_rsvmap(fdt));
+	fdt_set_off_dt_strings(fdt, bufsize);
+
+	return 0;
+}
+
+int fdt_add_reservemap_entry(void *fdt, uint64_t addr, uint64_t size)
+{
+	struct fdt_reserve_entry *re;
+	int offset;
+
+	FDT_SW_CHECK_HEADER(fdt);
+
+	if (fdt_size_dt_struct(fdt))
+		return -FDT_ERR_BADSTATE;
+
+	offset = fdt_off_dt_struct(fdt);
+	if ((offset + sizeof(*re)) > fdt_totalsize(fdt))
+		return -FDT_ERR_NOSPACE;
+
+	re = (struct fdt_reserve_entry *)((char *)fdt + offset);
+	re->address = cpu_to_fdt64(addr);
+	re->size = cpu_to_fdt64(size);
+
+	fdt_set_off_dt_struct(fdt, offset + sizeof(*re));
+
+	return 0;
+}
+
+int fdt_finish_reservemap(void *fdt)
+{
+	return fdt_add_reservemap_entry(fdt, 0, 0);
+}
+
+int fdt_begin_node(void *fdt, const char *name)
+{
+	struct fdt_node_header *nh;
+	int namelen = strlen(name) + 1;
+
+	FDT_SW_CHECK_HEADER(fdt);
+
+	nh = _fdt_grab_space(fdt, sizeof(*nh) + FDT_TAGALIGN(namelen));
+	if (! nh)
+		return -FDT_ERR_NOSPACE;
+
+	nh->tag = cpu_to_fdt32(FDT_BEGIN_NODE);
+	memcpy(nh->name, name, namelen);
+	return 0;
+}
+
+int fdt_end_node(void *fdt)
+{
+	uint32_t *en;
+
+	FDT_SW_CHECK_HEADER(fdt);
+
+	en = _fdt_grab_space(fdt, FDT_TAGSIZE);
+	if (! en)
+		return -FDT_ERR_NOSPACE;
+
+	*en = cpu_to_fdt32(FDT_END_NODE);
+	return 0;
+}
+
+static int _fdt_find_add_string(void *fdt, const char *s)
+{
+	char *strtab = (char *)fdt + fdt_totalsize(fdt);
+	const char *p;
+	int strtabsize = fdt_size_dt_strings(fdt);
+	int len = strlen(s) + 1;
+	int struct_top, offset;
+
+	p = _fdt_find_string(strtab - strtabsize, strtabsize, s);
+	if (p)
+		return p - strtab;
+
+	/* Add it */
+	offset = -strtabsize - len;
+	struct_top = fdt_off_dt_struct(fdt) + fdt_size_dt_struct(fdt);
+	if (fdt_totalsize(fdt) + offset < struct_top)
+		return 0; /* no more room :( */
+
+	memcpy(strtab + offset, s, len);
+	fdt_set_size_dt_strings(fdt, strtabsize + len);
+	return offset;
+}
+
+int fdt_property(void *fdt, const char *name, const void *val, int len)
+{
+	struct fdt_property *prop;
+	int nameoff;
+
+	FDT_SW_CHECK_HEADER(fdt);
+
+	nameoff = _fdt_find_add_string(fdt, name);
+	if (nameoff == 0)
+		return -FDT_ERR_NOSPACE;
+
+	prop = _fdt_grab_space(fdt, sizeof(*prop) + FDT_TAGALIGN(len));
+	if (! prop)
+		return -FDT_ERR_NOSPACE;
+
+	prop->tag = cpu_to_fdt32(FDT_PROP);
+	prop->nameoff = cpu_to_fdt32(nameoff);
+	prop->len = cpu_to_fdt32(len);
+	memcpy(prop->data, val, len);
+	return 0;
+}
+
+int fdt_finish(void *fdt)
+{
+	char *p = (char *)fdt;
+	uint32_t *end;
+	int oldstroffset, newstroffset;
+	uint32_t tag;
+	int offset, nextoffset;
+
+	FDT_SW_CHECK_HEADER(fdt);
+
+	/* Add terminator */
+	end = _fdt_grab_space(fdt, sizeof(*end));
+	if (! end)
+		return -FDT_ERR_NOSPACE;
+	*end = cpu_to_fdt32(FDT_END);
+
+	/* Relocate the string table */
+	oldstroffset = fdt_totalsize(fdt) - fdt_size_dt_strings(fdt);
+	newstroffset = fdt_off_dt_struct(fdt) + fdt_size_dt_struct(fdt);
+	memmove(p + newstroffset, p + oldstroffset, fdt_size_dt_strings(fdt));
+	fdt_set_off_dt_strings(fdt, newstroffset);
+
+	/* Walk the structure, correcting string offsets */
+	offset = 0;
+	while ((tag = fdt_next_tag(fdt, offset, &nextoffset)) != FDT_END) {
+		if (tag == FDT_PROP) {
+			struct fdt_property *prop =
+				fdt_offset_ptr_w(fdt, offset, sizeof(*prop));
+			int nameoff;
+
+			if (! prop)
+				return -FDT_ERR_BADSTRUCTURE;
+
+			nameoff = fdt32_to_cpu(prop->nameoff);
+			nameoff += fdt_size_dt_strings(fdt);
+			prop->nameoff = cpu_to_fdt32(nameoff);
+		}
+		offset = nextoffset;
+	}
+
+	/* Finally, adjust the header */
+	fdt_set_totalsize(fdt, newstroffset + fdt_size_dt_strings(fdt));
+	fdt_set_magic(fdt, FDT_MAGIC);
+	return 0;
+}
diff --git a/arch/mips/netlogic/boot/fdt_wip.c b/arch/mips/netlogic/boot/fdt_wip.c
new file mode 100644
index 0000000..a4652c6
--- /dev/null
+++ b/arch/mips/netlogic/boot/fdt_wip.c
@@ -0,0 +1,145 @@
+/*
+ * libfdt - Flat Device Tree manipulation
+ * Copyright (C) 2006 David Gibson, IBM Corporation.
+ *
+ * libfdt is dual licensed: you can use it either under the terms of
+ * the GPL, or the BSD license, at your option.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ *     You should have received a copy of the GNU General Public
+ *     License along with this library; if not, write to the Free
+ *     Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston,
+ *     MA 02110-1301 USA
+ *
+ * Alternatively,
+ *
+ *  b) Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *     1. Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *     2. Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ *     THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
+ *     CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
+ *     INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *     MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ *     DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ *     CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *     SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
+ *     NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ *     LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ *     HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ *     CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+ *     OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
+ *     EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include "libfdt_env.h"
+
+#include <fdt.h>
+#include <libfdt.h>
+
+#include "libfdt_internal.h"
+
+int fdt_setprop_inplace(void *fdt, int nodeoffset, const char *name,
+			const void *val, int len)
+{
+	void *propval;
+	int proplen;
+
+	propval = fdt_getprop_w(fdt, nodeoffset, name, &proplen);
+	if (! propval)
+		return proplen;
+
+	if (proplen != len)
+		return -FDT_ERR_NOSPACE;
+
+	memcpy(propval, val, len);
+	return 0;
+}
+
+static void _fdt_nop_region(void *start, int len)
+{
+	uint32_t *p;
+
+	for (p = start; (char *)p < ((char *)start + len); p++)
+		*p = cpu_to_fdt32(FDT_NOP);
+}
+
+int fdt_nop_property(void *fdt, int nodeoffset, const char *name)
+{
+	struct fdt_property *prop;
+	int len;
+
+	prop = fdt_get_property_w(fdt, nodeoffset, name, &len);
+	if (! prop)
+		return len;
+
+	_fdt_nop_region(prop, len + sizeof(*prop));
+
+	return 0;
+}
+
+int _fdt_node_end_offset(void *fdt, int nodeoffset)
+{
+	int level = 0;
+	uint32_t tag;
+	int offset, nextoffset;
+
+	tag = fdt_next_tag(fdt, nodeoffset, &nextoffset);
+	if (tag != FDT_BEGIN_NODE)
+		return -FDT_ERR_BADOFFSET;
+	do {
+		offset = nextoffset;
+		tag = fdt_next_tag(fdt, offset, &nextoffset);
+
+		switch (tag) {
+		case FDT_END:
+			return offset;
+
+		case FDT_BEGIN_NODE:
+			level++;
+			break;
+
+		case FDT_END_NODE:
+			level--;
+			break;
+
+		case FDT_PROP:
+		case FDT_NOP:
+			break;
+
+		default:
+			return -FDT_ERR_BADSTRUCTURE;
+		}
+	} while (level >= 0);
+
+	return nextoffset;
+}
+
+int fdt_nop_node(void *fdt, int nodeoffset)
+{
+	int endoffset;
+
+	endoffset = _fdt_node_end_offset(fdt, nodeoffset);
+	if (endoffset < 0)
+		return endoffset;
+
+	_fdt_nop_region(fdt_offset_ptr_w(fdt, nodeoffset, 0),
+			endoffset - nodeoffset);
+	return 0;
+}
diff --git a/arch/mips/netlogic/boot/libfdt-wrapper.c b/arch/mips/netlogic/boot/libfdt-wrapper.c
index 3720879..0ed262a 100644
--- a/arch/mips/netlogic/boot/libfdt-wrapper.c
+++ b/arch/mips/netlogic/boot/libfdt-wrapper.c
@@ -27,7 +27,12 @@
 #include <libfdt.h>
 #include "ops.h"
 
-#define min(x, y) ({ \
+#if 0
+(BAD_ERROR(err) || ((err < 0) && DEBUG)) 
+	printf("%s():%d  %s\n\r", __func__, __LINE__, fdt_strerror(err)); 
+#endif
+
+#define min(x,y) ({ \
 		typeof(x) _x = (x); \
 		typeof(y) _y = (y); \
 		(void) (&_x == &_y);    \
@@ -136,7 +141,7 @@ static void *fdt_wrapper_find_node_by_prop_value(const void *prev,
 						 int len)
 {
 	int offset = fdt_node_offset_by_prop_value(fdt, devp_offset_find(prev),
-						name, val, len);
+	                                           name, val, len);
 	return offset_devp(offset);
 }
 
@@ -144,7 +149,7 @@ static void *fdt_wrapper_find_node_by_compatible(const void *prev,
 						 const char *val)
 {
 	int offset = fdt_node_offset_by_compatible(fdt, devp_offset_find(prev),
-							val);
+	                                           val);
 	return offset_devp(offset);
 }
 
@@ -163,16 +168,22 @@ static unsigned long fdt_wrapper_finalize(void)
 	int rc;
 
 	rc = fdt_pack(fdt);
+#if 0
+	if (rc != 0)
+		fatal("Couldn't pack flat tree: %s\n\r",
+		      fdt_strerror(rc));
+#endif
 	return (unsigned long)fdt;
 }
 
 static int fdt_wrapper_check_header(void)
 {
-	int err = 0;
+	int err;
 
-	err = fdt_check_header(fdt);
+	if ((err = fdt_check_header(fdt)) != 0)
+		return err;
 
-	return err;
+	return 0;
 }
 
 void *fdt_init(void *blob)
@@ -202,9 +213,14 @@ void *fdt_init(void *blob)
 
 		bufsize = fdt_totalsize(fdt) + EXPAND_GRANULARITY;
 		buf = malloc(bufsize);
+		//if(!buf)
+		//	fatal("malloc failed. can't relocate the device tree\n\r");
 
 		err = fdt_open_into(fdt, buf, bufsize);
 
+		//if (err != 0)
+		//	fatal("fdt_init(): %s\n\r", fdt_strerror(err));
+
 		fdt = buf;
 	}
 #endif
diff --git a/arch/mips/netlogic/boot/libfdt.h b/arch/mips/netlogic/boot/libfdt.h
new file mode 100644
index 0000000..ce80e4f
--- /dev/null
+++ b/arch/mips/netlogic/boot/libfdt.h
@@ -0,0 +1,1076 @@
+#ifndef _LIBFDT_H
+#define _LIBFDT_H
+/*
+ * libfdt - Flat Device Tree manipulation
+ * Copyright (C) 2006 David Gibson, IBM Corporation.
+ *
+ * libfdt is dual licensed: you can use it either under the terms of
+ * the GPL, or the BSD license, at your option.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ *     You should have received a copy of the GNU General Public
+ *     License along with this library; if not, write to the Free
+ *     Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston,
+ *     MA 02110-1301 USA
+ *
+ * Alternatively,
+ *
+ *  b) Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *     1. Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *     2. Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ *     THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
+ *     CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
+ *     INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *     MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ *     DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ *     CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *     SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
+ *     NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ *     LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ *     HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ *     CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+ *     OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
+ *     EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <libfdt_env.h>
+#include <fdt.h>
+
+#define FDT_FIRST_SUPPORTED_VERSION	0x10
+#define FDT_LAST_SUPPORTED_VERSION	0x11
+
+/* Error codes: informative error codes */
+#define FDT_ERR_NOTFOUND	1
+	/* FDT_ERR_NOTFOUND: The requested node or property does not exist */
+#define FDT_ERR_EXISTS		2
+	/* FDT_ERR_EXISTS: Attemped to create a node or property which
+	 * already exists */
+#define FDT_ERR_NOSPACE		3
+	/* FDT_ERR_NOSPACE: Operation needed to expand the device
+	 * tree, but its buffer did not have sufficient space to
+	 * contain the expanded tree. Use fdt_open_into() to move the
+	 * device tree to a buffer with more space. */
+
+/* Error codes: codes for bad parameters */
+#define FDT_ERR_BADOFFSET	4
+	/* FDT_ERR_BADOFFSET: Function was passed a structure block
+	 * offset which is out-of-bounds, or which points to an
+	 * unsuitable part of the structure for the operation. */
+#define FDT_ERR_BADPATH		5
+	/* FDT_ERR_BADPATH: Function was passed a badly formatted path
+	 * (e.g. missing a leading / for a function which requires an
+	 * absolute path) */
+#define FDT_ERR_BADPHANDLE	6
+	/* FDT_ERR_BADPHANDLE: Function was passed an invalid phandle
+	 * value.  phandle values of 0 and -1 are not permitted. */
+#define FDT_ERR_BADSTATE	7
+	/* FDT_ERR_BADSTATE: Function was passed an incomplete device
+	 * tree created by the sequential-write functions, which is
+	 * not sufficiently complete for the requested operation. */
+
+/* Error codes: codes for bad device tree blobs */
+#define FDT_ERR_TRUNCATED	8
+	/* FDT_ERR_TRUNCATED: Structure block of the given device tree
+	 * ends without an FDT_END tag. */
+#define FDT_ERR_BADMAGIC	9
+	/* FDT_ERR_BADMAGIC: Given "device tree" appears not to be a
+	 * device tree at all - it is missing the flattened device
+	 * tree magic number. */
+#define FDT_ERR_BADVERSION	10
+	/* FDT_ERR_BADVERSION: Given device tree has a version which
+	 * can't be handled by the requested operation.  For
+	 * read-write functions, this may mean that fdt_open_into() is
+	 * required to convert the tree to the expected version. */
+#define FDT_ERR_BADSTRUCTURE	11
+	/* FDT_ERR_BADSTRUCTURE: Given device tree has a corrupt
+	 * structure block or other serious error (e.g. misnested
+	 * nodes, or subnodes preceding properties). */
+#define FDT_ERR_BADLAYOUT	12
+	/* FDT_ERR_BADLAYOUT: For read-write functions, the given
+	 * device tree has it's sub-blocks in an order that the
+	 * function can't handle (memory reserve map, then structure,
+	 * then strings).  Use fdt_open_into() to reorganize the tree
+	 * into a form suitable for the read-write operations. */
+
+/* "Can't happen" error indicating a bug in libfdt */
+#define FDT_ERR_INTERNAL	13
+	/* FDT_ERR_INTERNAL: libfdt has failed an internal assertion.
+	 * Should never be returned, if it is, it indicates a bug in
+	 * libfdt itself. */
+
+#define FDT_ERR_MAX		13
+
+/**********************************************************************/
+/* Low-level functions (you probably don't need these)                */
+/**********************************************************************/
+
+const void *fdt_offset_ptr(const void *fdt, int offset, int checklen);
+static inline void *fdt_offset_ptr_w(void *fdt, int offset, int checklen)
+{
+	return (void *)(uintptr_t)fdt_offset_ptr(fdt, offset, checklen);
+}
+
+uint32_t fdt_next_tag(const void *fdt, int offset, int *nextoffset);
+
+/**********************************************************************/
+/* Traversal functions                                                */
+/**********************************************************************/
+
+int fdt_next_node(const void *fdt, int offset, int *depth);
+
+/**********************************************************************/
+/* General functions                                                  */
+/**********************************************************************/
+
+#define fdt_get_header(fdt, field) \
+	(fdt32_to_cpu(((const struct fdt_header *)(fdt))->field))
+#define fdt_magic(fdt) 			(fdt_get_header(fdt, magic))
+#define fdt_totalsize(fdt)		(fdt_get_header(fdt, totalsize))
+#define fdt_off_dt_struct(fdt)		(fdt_get_header(fdt, off_dt_struct))
+#define fdt_off_dt_strings(fdt)		(fdt_get_header(fdt, off_dt_strings))
+#define fdt_off_mem_rsvmap(fdt)		(fdt_get_header(fdt, off_mem_rsvmap))
+#define fdt_version(fdt)		(fdt_get_header(fdt, version))
+#define fdt_last_comp_version(fdt) 	(fdt_get_header(fdt, last_comp_version))
+#define fdt_boot_cpuid_phys(fdt) 	(fdt_get_header(fdt, boot_cpuid_phys))
+#define fdt_size_dt_strings(fdt) 	(fdt_get_header(fdt, size_dt_strings))
+#define fdt_size_dt_struct(fdt)		(fdt_get_header(fdt, size_dt_struct))
+
+#define __fdt_set_hdr(name) \
+	static inline void fdt_set_##name(void *fdt, uint32_t val) \
+	{ \
+		struct fdt_header *fdth = fdt; \
+		fdth->name = cpu_to_fdt32(val); \
+	}
+__fdt_set_hdr(magic);
+__fdt_set_hdr(totalsize);
+__fdt_set_hdr(off_dt_struct);
+__fdt_set_hdr(off_dt_strings);
+__fdt_set_hdr(off_mem_rsvmap);
+__fdt_set_hdr(version);
+__fdt_set_hdr(last_comp_version);
+__fdt_set_hdr(boot_cpuid_phys);
+__fdt_set_hdr(size_dt_strings);
+__fdt_set_hdr(size_dt_struct);
+#undef __fdt_set_hdr
+
+/**
+ * fdt_check_header - sanity check a device tree or possible device tree
+ * @fdt: pointer to data which might be a flattened device tree
+ *
+ * fdt_check_header() checks that the given buffer contains what
+ * appears to be a flattened device tree with sane information in its
+ * header.
+ *
+ * returns:
+ *     0, if the buffer appears to contain a valid device tree
+ *     -FDT_ERR_BADMAGIC,
+ *     -FDT_ERR_BADVERSION,
+ *     -FDT_ERR_BADSTATE, standard meanings, as above
+ */
+int fdt_check_header(const void *fdt);
+
+/**
+ * fdt_move - move a device tree around in memory
+ * @fdt: pointer to the device tree to move
+ * @buf: pointer to memory where the device is to be moved
+ * @bufsize: size of the memory space at buf
+ *
+ * fdt_move() relocates, if possible, the device tree blob located at
+ * fdt to the buffer at buf of size bufsize.  The buffer may overlap
+ * with the existing device tree blob at fdt.  Therefore,
+ *     fdt_move(fdt, fdt, fdt_totalsize(fdt))
+ * should always succeed.
+ *
+ * returns:
+ *     0, on success
+ *     -FDT_ERR_NOSPACE, bufsize is insufficient to contain the device tree
+ *     -FDT_ERR_BADMAGIC,
+ *     -FDT_ERR_BADVERSION,
+ *     -FDT_ERR_BADSTATE, standard meanings
+ */
+int fdt_move(const void *fdt, void *buf, int bufsize);
+
+/**********************************************************************/
+/* Read-only functions                                                */
+/**********************************************************************/
+
+/**
+ * fdt_string - retrieve a string from the strings block of a device tree
+ * @fdt: pointer to the device tree blob
+ * @stroffset: offset of the string within the strings block (native endian)
+ *
+ * fdt_string() retrieves a pointer to a single string from the
+ * strings block of the device tree blob at fdt.
+ *
+ * returns:
+ *     a pointer to the string, on success
+ *     NULL, if stroffset is out of bounds
+ */
+const char *fdt_string(const void *fdt, int stroffset);
+
+/**
+ * fdt_num_mem_rsv - retrieve the number of memory reserve map entries
+ * @fdt: pointer to the device tree blob
+ *
+ * Returns the number of entries in the device tree blob's memory
+ * reservation map.  This does not include the terminating 0,0 entry
+ * or any other (0,0) entries reserved for expansion.
+ *
+ * returns:
+ *     the number of entries
+ */
+int fdt_num_mem_rsv(const void *fdt);
+
+/**
+ * fdt_get_mem_rsv - retrieve one memory reserve map entry
+ * @fdt: pointer to the device tree blob
+ * @address, @size: pointers to 64-bit variables
+ *
+ * On success, *address and *size will contain the address and size of
+ * the n-th reserve map entry from the device tree blob, in
+ * native-endian format.
+ *
+ * returns:
+ *     0, on success
+ *     -FDT_ERR_BADMAGIC,
+ *     -FDT_ERR_BADVERSION,
+ *     -FDT_ERR_BADSTATE, standard meanings
+ */
+int fdt_get_mem_rsv(const void *fdt, int n, uint64_t *address, uint64_t *size);
+
+/**
+ * fdt_subnode_offset_namelen - find a subnode based on substring
+ * @fdt: pointer to the device tree blob
+ * @parentoffset: structure block offset of a node
+ * @name: name of the subnode to locate
+ * @namelen: number of characters of name to consider
+ *
+ * Identical to fdt_subnode_offset(), but only examine the first
+ * namelen characters of name for matching the subnode name.  This is
+ * useful for finding subnodes based on a portion of a larger string,
+ * such as a full path.
+ */
+int fdt_subnode_offset_namelen(const void *fdt, int parentoffset,
+			       const char *name, int namelen);
+/**
+ * fdt_subnode_offset - find a subnode of a given node
+ * @fdt: pointer to the device tree blob
+ * @parentoffset: structure block offset of a node
+ * @name: name of the subnode to locate
+ *
+ * fdt_subnode_offset() finds a subnode of the node at structure block
+ * offset parentoffset with the given name.  name may include a unit
+ * address, in which case fdt_subnode_offset() will find the subnode
+ * with that unit address, or the unit address may be omitted, in
+ * which case fdt_subnode_offset() will find an arbitrary subnode
+ * whose name excluding unit address matches the given name.
+ *
+ * returns:
+ *	structure block offset of the requested subnode (>=0), on success
+ *	-FDT_ERR_NOTFOUND, if the requested subnode does not exist
+ *	-FDT_ERR_BADOFFSET, if parentoffset did not point to an FDT_BEGIN_NODE tag
+ *      -FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_TRUNCATED, standard meanings.
+ */
+int fdt_subnode_offset(const void *fdt, int parentoffset, const char *name);
+
+/**
+ * fdt_path_offset - find a tree node by its full path
+ * @fdt: pointer to the device tree blob
+ * @path: full path of the node to locate
+ *
+ * fdt_path_offset() finds a node of a given path in the device tree.
+ * Each path component may omit the unit address portion, but the
+ * results of this are undefined if any such path component is
+ * ambiguous (that is if there are multiple nodes at the relevant
+ * level matching the given component, differentiated only by unit
+ * address).
+ *
+ * returns:
+ *	structure block offset of the node with the requested path (>=0), on success
+ *	-FDT_ERR_BADPATH, given path does not begin with '/' or is invalid
+ *	-FDT_ERR_NOTFOUND, if the requested node does not exist
+ *      -FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_TRUNCATED, standard meanings.
+ */
+int fdt_path_offset(const void *fdt, const char *path);
+
+/**
+ * fdt_get_name - retrieve the name of a given node
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: structure block offset of the starting node
+ * @lenp: pointer to an integer variable (will be overwritten) or NULL
+ *
+ * fdt_get_name() retrieves the name (including unit address) of the
+ * device tree node at structure block offset nodeoffset.  If lenp is
+ * non-NULL, the length of this name is also returned, in the integer
+ * pointed to by lenp.
+ *
+ * returns:
+ *	pointer to the node's name, on success
+ *		If lenp is non-NULL, *lenp contains the length of that name (>=0)
+ *	NULL, on error
+ *		if lenp is non-NULL *lenp contains an error code (<0):
+ *		-FDT_ERR_BADOFFSET, nodeoffset did not point to FDT_BEGIN_NODE tag
+ *		-FDT_ERR_BADMAGIC,
+ *		-FDT_ERR_BADVERSION,
+ *		-FDT_ERR_BADSTATE, standard meanings
+ */
+const char *fdt_get_name(const void *fdt, int nodeoffset, int *lenp);
+
+/**
+ * fdt_get_property - find a given property in a given node
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node whose property to find
+ * @name: name of the property to find
+ * @lenp: pointer to an integer variable (will be overwritten) or NULL
+ *
+ * fdt_get_property() retrieves a pointer to the fdt_property
+ * structure within the device tree blob corresponding to the property
+ * named 'name' of the node at offset nodeoffset.  If lenp is
+ * non-NULL, the length of the property value is also returned, in the
+ * integer pointed to by lenp.
+ *
+ * returns:
+ *	pointer to the structure representing the property
+ *		if lenp is non-NULL, *lenp contains the length of the property
+ *		value (>=0)
+ *	NULL, on error
+ *		if lenp is non-NULL, *lenp contains an error code (<0):
+ *		-FDT_ERR_NOTFOUND, node does not have named property
+ *		-FDT_ERR_BADOFFSET, nodeoffset did not point to FDT_BEGIN_NODE tag
+ *		-FDT_ERR_BADMAGIC,
+ *		-FDT_ERR_BADVERSION,
+ *		-FDT_ERR_BADSTATE,
+ *		-FDT_ERR_BADSTRUCTURE,
+ *		-FDT_ERR_TRUNCATED, standard meanings
+ */
+const struct fdt_property *fdt_get_property(const void *fdt, int nodeoffset,
+					    const char *name, int *lenp);
+static inline struct fdt_property *fdt_get_property_w(void *fdt, int nodeoffset,
+						      const char *name,
+						      int *lenp)
+{
+	return (struct fdt_property *)(uintptr_t)
+		fdt_get_property(fdt, nodeoffset, name, lenp);
+}
+
+/**
+ * fdt_getprop - retrieve the value of a given property
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node whose property to find
+ * @name: name of the property to find
+ * @lenp: pointer to an integer variable (will be overwritten) or NULL
+ *
+ * fdt_getprop() retrieves a pointer to the value of the property
+ * named 'name' of the node at offset nodeoffset (this will be a
+ * pointer to within the device blob itself, not a copy of the value).
+ * If lenp is non-NULL, the length of the property value is also
+ * returned, in the integer pointed to by lenp.
+ *
+ * returns:
+ *	pointer to the property's value
+ *		if lenp is non-NULL, *lenp contains the length of the property
+ *		value (>=0)
+ *	NULL, on error
+ *		if lenp is non-NULL, *lenp contains an error code (<0):
+ *		-FDT_ERR_NOTFOUND, node does not have named property
+ *		-FDT_ERR_BADOFFSET, nodeoffset did not point to FDT_BEGIN_NODE tag
+ *		-FDT_ERR_BADMAGIC,
+ *		-FDT_ERR_BADVERSION,
+ *		-FDT_ERR_BADSTATE,
+ *		-FDT_ERR_BADSTRUCTURE,
+ *		-FDT_ERR_TRUNCATED, standard meanings
+ */
+const void *fdt_getprop(const void *fdt, int nodeoffset,
+			const char *name, int *lenp);
+static inline void *fdt_getprop_w(void *fdt, int nodeoffset,
+				  const char *name, int *lenp)
+{
+	return (void *)(uintptr_t)fdt_getprop(fdt, nodeoffset, name, lenp);
+}
+
+/**
+ * fdt_get_phandle - retrieve the phandle of a given node
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: structure block offset of the node
+ *
+ * fdt_get_phandle() retrieves the phandle of the device tree node at
+ * structure block offset nodeoffset.
+ *
+ * returns:
+ *	the phandle of the node at nodeoffset, on success (!= 0, != -1)
+ *	0, if the node has no phandle, or another error occurs
+ */
+uint32_t fdt_get_phandle(const void *fdt, int nodeoffset);
+
+/**
+ * fdt_get_path - determine the full path of a node
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node whose path to find
+ * @buf: character buffer to contain the returned path (will be overwritten)
+ * @buflen: size of the character buffer at buf
+ *
+ * fdt_get_path() computes the full path of the node at offset
+ * nodeoffset, and records that path in the buffer at buf.
+ *
+ * NOTE: This function is expensive, as it must scan the device tree
+ * structure from the start to nodeoffset.
+ *
+ * returns:
+ *	0, on success
+ *		buf contains the absolute path of the node at
+ *		nodeoffset, as a NUL-terminated string.
+ * 	-FDT_ERR_BADOFFSET, nodeoffset does not refer to a BEGIN_NODE tag
+ *	-FDT_ERR_NOSPACE, the path of the given node is longer than (bufsize-1)
+ *		characters and will not fit in the given buffer.
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE, standard meanings
+ */
+int fdt_get_path(const void *fdt, int nodeoffset, char *buf, int buflen);
+
+/**
+ * fdt_supernode_atdepth_offset - find a specific ancestor of a node
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node whose parent to find
+ * @supernodedepth: depth of the ancestor to find
+ * @nodedepth: pointer to an integer variable (will be overwritten) or NULL
+ *
+ * fdt_supernode_atdepth_offset() finds an ancestor of the given node
+ * at a specific depth from the root (where the root itself has depth
+ * 0, its immediate subnodes depth 1 and so forth).  So
+ *	fdt_supernode_atdepth_offset(fdt, nodeoffset, 0, NULL);
+ * will always return 0, the offset of the root node.  If the node at
+ * nodeoffset has depth D, then:
+ *	fdt_supernode_atdepth_offset(fdt, nodeoffset, D, NULL);
+ * will return nodeoffset itself.
+ *
+ * NOTE: This function is expensive, as it must scan the device tree
+ * structure from the start to nodeoffset.
+ *
+ * returns:
+
+ *	structure block offset of the node at node offset's ancestor
+ *		of depth supernodedepth (>=0), on success
+ * 	-FDT_ERR_BADOFFSET, nodeoffset does not refer to a BEGIN_NODE tag
+*	-FDT_ERR_NOTFOUND, supernodedepth was greater than the depth of nodeoffset
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE, standard meanings
+ */
+int fdt_supernode_atdepth_offset(const void *fdt, int nodeoffset,
+				 int supernodedepth, int *nodedepth);
+
+/**
+ * fdt_node_depth - find the depth of a given node
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node whose parent to find
+ *
+ * fdt_node_depth() finds the depth of a given node.  The root node
+ * has depth 0, its immediate subnodes depth 1 and so forth.
+ *
+ * NOTE: This function is expensive, as it must scan the device tree
+ * structure from the start to nodeoffset.
+ *
+ * returns:
+ *	depth of the node at nodeoffset (>=0), on success
+ * 	-FDT_ERR_BADOFFSET, nodeoffset does not refer to a BEGIN_NODE tag
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE, standard meanings
+ */
+int fdt_node_depth(const void *fdt, int nodeoffset);
+
+/**
+ * fdt_parent_offset - find the parent of a given node
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node whose parent to find
+ *
+ * fdt_parent_offset() locates the parent node of a given node (that
+ * is, it finds the offset of the node which contains the node at
+ * nodeoffset as a subnode).
+ *
+ * NOTE: This function is expensive, as it must scan the device tree
+ * structure from the start to nodeoffset, *twice*.
+ *
+ * returns:
+ *	structure block offset of the parent of the node at nodeoffset
+ *		(>=0), on success
+ * 	-FDT_ERR_BADOFFSET, nodeoffset does not refer to a BEGIN_NODE tag
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE, standard meanings
+ */
+int fdt_parent_offset(const void *fdt, int nodeoffset);
+
+/**
+ * fdt_node_offset_by_prop_value - find nodes with a given property value
+ * @fdt: pointer to the device tree blob
+ * @startoffset: only find nodes after this offset
+ * @propname: property name to check
+ * @propval: property value to search for
+ * @proplen: length of the value in propval
+ *
+ * fdt_node_offset_by_prop_value() returns the offset of the first
+ * node after startoffset, which has a property named propname whose
+ * value is of length proplen and has value equal to propval; or if
+ * startoffset is -1, the very first such node in the tree.
+ *
+ * To iterate through all nodes matching the criterion, the following
+ * idiom can be used:
+ *	offset = fdt_node_offset_by_prop_value(fdt, -1, propname,
+ *					       propval, proplen);
+ *	while (offset != -FDT_ERR_NOTFOUND) {
+ *		// other code here
+ *		offset = fdt_node_offset_by_prop_value(fdt, offset, propname,
+ *						       propval, proplen);
+ *	}
+ *
+ * Note the -1 in the first call to the function, if 0 is used here
+ * instead, the function will never locate the root node, even if it
+ * matches the criterion.
+ *
+ * returns:
+ *	structure block offset of the located node (>= 0, >startoffset),
+ *		 on success
+ *	-FDT_ERR_NOTFOUND, no node matching the criterion exists in the
+ *		tree after startoffset
+ * 	-FDT_ERR_BADOFFSET, nodeoffset does not refer to a BEGIN_NODE tag
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE, standard meanings
+ */
+int fdt_node_offset_by_prop_value(const void *fdt, int startoffset,
+				  const char *propname,
+				  const void *propval, int proplen);
+
+/**
+ * fdt_node_offset_by_phandle - find the node with a given phandle
+ * @fdt: pointer to the device tree blob
+ * @phandle: phandle value
+ *
+ * fdt_node_offset_by_phandle() returns the offset of the node
+ * which has the given phandle value.  If there is more than one node
+ * in the tree with the given phandle (an invalid tree), results are
+ * undefined.
+ *
+ * returns:
+ *	structure block offset of the located node (>= 0), on success
+ *	-FDT_ERR_NOTFOUND, no node with that phandle exists
+ *	-FDT_ERR_BADPHANDLE, given phandle value was invalid (0 or -1)
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE, standard meanings
+ */
+int fdt_node_offset_by_phandle(const void *fdt, uint32_t phandle);
+
+/**
+ * fdt_node_check_compatible: check a node's compatible property
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of a tree node
+ * @compatible: string to match against
+ *
+ *
+ * fdt_node_check_compatible() returns 0 if the given node contains a
+ * 'compatible' property with the given string as one of its elements,
+ * it returns non-zero otherwise, or on error.
+ *
+ * returns:
+ *	0, if the node has a 'compatible' property listing the given string
+ *	1, if the node has a 'compatible' property, but it does not list
+ *		the given string
+ *	-FDT_ERR_NOTFOUND, if the given node has no 'compatible' property
+ * 	-FDT_ERR_BADOFFSET, if nodeoffset does not refer to a BEGIN_NODE tag
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE, standard meanings
+ */
+int fdt_node_check_compatible(const void *fdt, int nodeoffset,
+			      const char *compatible);
+
+/**
+ * fdt_node_offset_by_compatible - find nodes with a given 'compatible' value
+ * @fdt: pointer to the device tree blob
+ * @startoffset: only find nodes after this offset
+ * @compatible: 'compatible' string to match against
+ *
+ * fdt_node_offset_by_compatible() returns the offset of the first
+ * node after startoffset, which has a 'compatible' property which
+ * lists the given compatible string; or if startoffset is -1, the
+ * very first such node in the tree.
+ *
+ * To iterate through all nodes matching the criterion, the following
+ * idiom can be used:
+ *	offset = fdt_node_offset_by_compatible(fdt, -1, compatible);
+ *	while (offset != -FDT_ERR_NOTFOUND) {
+ *		// other code here
+ *		offset = fdt_node_offset_by_compatible(fdt, offset, compatible);
+ *	}
+ *
+ * Note the -1 in the first call to the function, if 0 is used here
+ * instead, the function will never locate the root node, even if it
+ * matches the criterion.
+ *
+ * returns:
+ *	structure block offset of the located node (>= 0, >startoffset),
+ *		 on success
+ *	-FDT_ERR_NOTFOUND, no node matching the criterion exists in the
+ *		tree after startoffset
+ * 	-FDT_ERR_BADOFFSET, nodeoffset does not refer to a BEGIN_NODE tag
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE, standard meanings
+ */
+int fdt_node_offset_by_compatible(const void *fdt, int startoffset,
+				  const char *compatible);
+
+/**********************************************************************/
+/* Write-in-place functions                                           */
+/**********************************************************************/
+
+/**
+ * fdt_setprop_inplace - change a property's value, but not its size
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node whose property to change
+ * @name: name of the property to change
+ * @val: pointer to data to replace the property value with
+ * @len: length of the property value
+ *
+ * fdt_setprop_inplace() replaces the value of a given property with
+ * the data in val, of length len.  This function cannot change the
+ * size of a property, and so will only work if len is equal to the
+ * current length of the property.
+ *
+ * This function will alter only the bytes in the blob which contain
+ * the given property value, and will not alter or move any other part
+ * of the tree.
+ *
+ * returns:
+ *	0, on success
+ *	-FDT_ERR_NOSPACE, if len is not equal to the property's current length
+ *	-FDT_ERR_NOTFOUND, node does not have the named property
+ *	-FDT_ERR_BADOFFSET, nodeoffset did not point to FDT_BEGIN_NODE tag
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_TRUNCATED, standard meanings
+ */
+int fdt_setprop_inplace(void *fdt, int nodeoffset, const char *name,
+			const void *val, int len);
+
+/**
+ * fdt_setprop_inplace_cell - change the value of a single-cell property
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node whose property to change
+ * @name: name of the property to change
+ * @val: cell (32-bit integer) value to replace the property with
+ *
+ * fdt_setprop_inplace_cell() replaces the value of a given property
+ * with the 32-bit integer cell value in val, converting val to
+ * big-endian if necessary.  This function cannot change the size of a
+ * property, and so will only work if the property already exists and
+ * has length 4.
+ *
+ * This function will alter only the bytes in the blob which contain
+ * the given property value, and will not alter or move any other part
+ * of the tree.
+ *
+ * returns:
+ *	0, on success
+ *	-FDT_ERR_NOSPACE, if the property's length is not equal to 4
+  *	-FDT_ERR_NOTFOUND, node does not have the named property
+ *	-FDT_ERR_BADOFFSET, nodeoffset did not point to FDT_BEGIN_NODE tag
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_TRUNCATED, standard meanings
+ */
+static inline int fdt_setprop_inplace_cell(void *fdt, int nodeoffset,
+					   const char *name, uint32_t val)
+{
+	val = cpu_to_fdt32(val);
+	return fdt_setprop_inplace(fdt, nodeoffset, name, &val, sizeof(val));
+}
+
+/**
+ * fdt_nop_property - replace a property with nop tags
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node whose property to nop
+ * @name: name of the property to nop
+ *
+ * fdt_nop_property() will replace a given property's representation
+ * in the blob with FDT_NOP tags, effectively removing it from the
+ * tree.
+ *
+ * This function will alter only the bytes in the blob which contain
+ * the property, and will not alter or move any other part of the
+ * tree.
+ *
+ * returns:
+ *	0, on success
+ *	-FDT_ERR_NOTFOUND, node does not have the named property
+ *	-FDT_ERR_BADOFFSET, nodeoffset did not point to FDT_BEGIN_NODE tag
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_TRUNCATED, standard meanings
+ */
+int fdt_nop_property(void *fdt, int nodeoffset, const char *name);
+
+/**
+ * fdt_nop_node - replace a node (subtree) with nop tags
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node to nop
+ *
+ * fdt_nop_node() will replace a given node's representation in the
+ * blob, including all its subnodes, if any, with FDT_NOP tags,
+ * effectively removing it from the tree.
+ *
+ * This function will alter only the bytes in the blob which contain
+ * the node and its properties and subnodes, and will not alter or
+ * move any other part of the tree.
+ *
+ * returns:
+ *	0, on success
+ *	-FDT_ERR_BADOFFSET, nodeoffset did not point to FDT_BEGIN_NODE tag
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_TRUNCATED, standard meanings
+ */
+int fdt_nop_node(void *fdt, int nodeoffset);
+
+/**********************************************************************/
+/* Sequential write functions                                         */
+/**********************************************************************/
+
+int fdt_create(void *buf, int bufsize);
+int fdt_add_reservemap_entry(void *fdt, uint64_t addr, uint64_t size);
+int fdt_finish_reservemap(void *fdt);
+int fdt_begin_node(void *fdt, const char *name);
+int fdt_property(void *fdt, const char *name, const void *val, int len);
+static inline int fdt_property_cell(void *fdt, const char *name, uint32_t val)
+{
+	val = cpu_to_fdt32(val);
+	return fdt_property(fdt, name, &val, sizeof(val));
+}
+#define fdt_property_string(fdt, name, str) \
+	fdt_property(fdt, name, str, strlen(str)+1)
+int fdt_end_node(void *fdt);
+int fdt_finish(void *fdt);
+
+/**********************************************************************/
+/* Read-write functions                                               */
+/**********************************************************************/
+
+int fdt_open_into(const void *fdt, void *buf, int bufsize);
+int fdt_pack(void *fdt);
+
+/**
+ * fdt_add_mem_rsv - add one memory reserve map entry
+ * @fdt: pointer to the device tree blob
+ * @address, @size: 64-bit values (native endian)
+ *
+ * Adds a reserve map entry to the given blob reserving a region at
+ * address address of length size.
+ *
+ * This function will insert data into the reserve map and will
+ * therefore change the indexes of some entries in the table.
+ *
+ * returns:
+ *	0, on success
+ *	-FDT_ERR_NOSPACE, there is insufficient free space in the blob to
+ *		contain the new reservation entry
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_BADLAYOUT,
+ *	-FDT_ERR_TRUNCATED, standard meanings
+ */
+int fdt_add_mem_rsv(void *fdt, uint64_t address, uint64_t size);
+
+/**
+ * fdt_del_mem_rsv - remove a memory reserve map entry
+ * @fdt: pointer to the device tree blob
+ * @n: entry to remove
+ *
+ * fdt_del_mem_rsv() removes the n-th memory reserve map entry from
+ * the blob.
+ *
+ * This function will delete data from the reservation table and will
+ * therefore change the indexes of some entries in the table.
+ *
+ * returns:
+ *	0, on success
+ *	-FDT_ERR_NOTFOUND, there is no entry of the given index (i.e. there
+ *		are less than n+1 reserve map entries)
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_BADLAYOUT,
+ *	-FDT_ERR_TRUNCATED, standard meanings
+ */
+int fdt_del_mem_rsv(void *fdt, int n);
+
+/**
+ * fdt_set_name - change the name of a given node
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: structure block offset of a node
+ * @name: name to give the node
+ *
+ * fdt_set_name() replaces the name (including unit address, if any)
+ * of the given node with the given string.  NOTE: this function can't
+ * efficiently check if the new name is unique amongst the given
+ * node's siblings; results are undefined if this function is invoked
+ * with a name equal to one of the given node's siblings.
+ *
+ * This function may insert or delete data from the blob, and will
+ * therefore change the offsets of some existing nodes.
+ *
+ * returns:
+ *	0, on success
+ *	-FDT_ERR_NOSPACE, there is insufficient free space in the blob
+ *		to contain the new name
+ *	-FDT_ERR_BADOFFSET, nodeoffset did not point to FDT_BEGIN_NODE tag
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE, standard meanings
+ */
+int fdt_set_name(void *fdt, int nodeoffset, const char *name);
+
+/**
+ * fdt_setprop - create or change a property
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node whose property to change
+ * @name: name of the property to change
+ * @val: pointer to data to set the property value to
+ * @len: length of the property value
+ *
+ * fdt_setprop() sets the value of the named property in the given
+ * node to the given value and length, creating the property if it
+ * does not already exist.
+ *
+ * This function may insert or delete data from the blob, and will
+ * therefore change the offsets of some existing nodes.
+ *
+ * returns:
+ *	0, on success
+ *	-FDT_ERR_NOSPACE, there is insufficient free space in the blob to
+ *		contain the new property value
+ *	-FDT_ERR_BADOFFSET, nodeoffset did not point to FDT_BEGIN_NODE tag
+ *	-FDT_ERR_BADLAYOUT,
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_BADLAYOUT,
+ *	-FDT_ERR_TRUNCATED, standard meanings
+ */
+int fdt_setprop(void *fdt, int nodeoffset, const char *name,
+		const void *val, int len);
+
+/**
+ * fdt_setprop_cell - set a property to a single cell value
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node whose property to change
+ * @name: name of the property to change
+ * @val: 32-bit integer value for the property (native endian)
+ *
+ * fdt_setprop_cell() sets the value of the named property in the
+ * given node to the given cell value (converting to big-endian if
+ * necessary), or creates a new property with that value if it does
+ * not already exist.
+ *
+ * This function may insert or delete data from the blob, and will
+ * therefore change the offsets of some existing nodes.
+ *
+ * returns:
+ *	0, on success
+ *	-FDT_ERR_NOSPACE, there is insufficient free space in the blob to
+ *		contain the new property value
+ *	-FDT_ERR_BADOFFSET, nodeoffset did not point to FDT_BEGIN_NODE tag
+ *	-FDT_ERR_BADLAYOUT,
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_BADLAYOUT,
+ *	-FDT_ERR_TRUNCATED, standard meanings
+ */
+static inline int fdt_setprop_cell(void *fdt, int nodeoffset, const char *name,
+				   uint32_t val)
+{
+	val = cpu_to_fdt32(val);
+	return fdt_setprop(fdt, nodeoffset, name, &val, sizeof(val));
+}
+
+/**
+ * fdt_setprop_string - set a property to a string value
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node whose property to change
+ * @name: name of the property to change
+ * @str: string value for the property
+ *
+ * fdt_setprop_string() sets the value of the named property in the
+ * given node to the given string value (using the length of the
+ * string to determine the new length of the property), or creates a
+ * new property with that value if it does not already exist.
+ *
+ * This function may insert or delete data from the blob, and will
+ * therefore change the offsets of some existing nodes.
+ *
+ * returns:
+ *	0, on success
+ *	-FDT_ERR_NOSPACE, there is insufficient free space in the blob to
+ *		contain the new property value
+ *	-FDT_ERR_BADOFFSET, nodeoffset did not point to FDT_BEGIN_NODE tag
+ *	-FDT_ERR_BADLAYOUT,
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_BADLAYOUT,
+ *	-FDT_ERR_TRUNCATED, standard meanings
+ */
+#define fdt_setprop_string(fdt, nodeoffset, name, str) \
+	fdt_setprop((fdt), (nodeoffset), (name), (str), strlen(str)+1)
+
+/**
+ * fdt_delprop - delete a property
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node whose property to nop
+ * @name: name of the property to nop
+ *
+ * fdt_del_property() will delete the given property.
+ *
+ * This function will delete data from the blob, and will therefore
+ * change the offsets of some existing nodes.
+ *
+ * returns:
+ *	0, on success
+ *	-FDT_ERR_NOTFOUND, node does not have the named property
+ *	-FDT_ERR_BADOFFSET, nodeoffset did not point to FDT_BEGIN_NODE tag
+ *	-FDT_ERR_BADLAYOUT,
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_TRUNCATED, standard meanings
+ */
+int fdt_delprop(void *fdt, int nodeoffset, const char *name);
+
+/**
+ * fdt_add_subnode_namelen - creates a new node based on substring
+ * @fdt: pointer to the device tree blob
+ * @parentoffset: structure block offset of a node
+ * @name: name of the subnode to locate
+ * @namelen: number of characters of name to consider
+ *
+ * Identical to fdt_add_subnode(), but use only the first namelen
+ * characters of name as the name of the new node.  This is useful for
+ * creating subnodes based on a portion of a larger string, such as a
+ * full path.
+ */
+int fdt_add_subnode_namelen(void *fdt, int parentoffset,
+			    const char *name, int namelen);
+
+/**
+ * fdt_add_subnode - creates a new node
+ * @fdt: pointer to the device tree blob
+ * @parentoffset: structure block offset of a node
+ * @name: name of the subnode to locate
+ *
+ * fdt_add_subnode() creates a new node as a subnode of the node at
+ * structure block offset parentoffset, with the given name (which
+ * should include the unit address, if any).
+ *
+ * This function will insert data into the blob, and will therefore
+ * change the offsets of some existing nodes.
+
+ * returns:
+ *	structure block offset of the created nodeequested subnode (>=0), on success
+ *	-FDT_ERR_NOTFOUND, if the requested subnode does not exist
+ *	-FDT_ERR_BADOFFSET, if parentoffset did not point to an FDT_BEGIN_NODE tag
+ *	-FDT_ERR_EXISTS, if the node at parentoffset already has a subnode of
+ *		the given name
+ *	-FDT_ERR_NOSPACE, if there is insufficient free space in the
+ *		blob to contain the new node
+ *	-FDT_ERR_NOSPACE
+ *	-FDT_ERR_BADLAYOUT
+ *      -FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_TRUNCATED, standard meanings.
+ */
+int fdt_add_subnode(void *fdt, int parentoffset, const char *name);
+
+/**
+ * fdt_del_node - delete a node (subtree)
+ * @fdt: pointer to the device tree blob
+ * @nodeoffset: offset of the node to nop
+ *
+ * fdt_del_node() will remove the given node, including all its
+ * subnodes if any, from the blob.
+ *
+ * This function will delete data from the blob, and will therefore
+ * change the offsets of some existing nodes.
+ *
+ * returns:
+ *	0, on success
+ *	-FDT_ERR_BADOFFSET, nodeoffset did not point to FDT_BEGIN_NODE tag
+ *	-FDT_ERR_BADLAYOUT,
+ *	-FDT_ERR_BADMAGIC,
+ *	-FDT_ERR_BADVERSION,
+ *	-FDT_ERR_BADSTATE,
+ *	-FDT_ERR_BADSTRUCTURE,
+ *	-FDT_ERR_TRUNCATED, standard meanings
+ */
+int fdt_del_node(void *fdt, int nodeoffset);
+
+/**********************************************************************/
+/* Debugging / informational functions                                */
+/**********************************************************************/
+
+const char *fdt_strerror(int errval);
+
+#endif /* _LIBFDT_H */
diff --git a/arch/mips/netlogic/boot/libfdt_internal.h b/arch/mips/netlogic/boot/libfdt_internal.h
new file mode 100644
index 0000000..46eb93e
--- /dev/null
+++ b/arch/mips/netlogic/boot/libfdt_internal.h
@@ -0,0 +1,95 @@
+#ifndef _LIBFDT_INTERNAL_H
+#define _LIBFDT_INTERNAL_H
+/*
+ * libfdt - Flat Device Tree manipulation
+ * Copyright (C) 2006 David Gibson, IBM Corporation.
+ *
+ * libfdt is dual licensed: you can use it either under the terms of
+ * the GPL, or the BSD license, at your option.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ *     You should have received a copy of the GNU General Public
+ *     License along with this library; if not, write to the Free
+ *     Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston,
+ *     MA 02110-1301 USA
+ *
+ * Alternatively,
+ *
+ *  b) Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *     1. Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *     2. Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ *     THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
+ *     CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
+ *     INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *     MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ *     DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ *     CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *     SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
+ *     NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ *     LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ *     HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ *     CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+ *     OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
+ *     EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include <fdt.h>
+
+#define FDT_ALIGN(x, a)		(((x) + (a) - 1) & ~((a) - 1))
+#define FDT_TAGALIGN(x)		(FDT_ALIGN((x), FDT_TAGSIZE))
+
+#define FDT_CHECK_HEADER(fdt) \
+	{ \
+		int err; \
+		if ((err = fdt_check_header(fdt)) != 0) \
+			return err; \
+	}
+
+uint32_t _fdt_next_tag(const void *fdt, int startoffset, int *nextoffset);
+int _fdt_check_node_offset(const void *fdt, int offset);
+const char *_fdt_find_string(const char *strtab, int tabsize, const char *s);
+int _fdt_node_end_offset(void *fdt, int nodeoffset);
+
+static inline const void *_fdt_offset_ptr(const void *fdt, int offset)
+{
+	return (const char *)fdt + fdt_off_dt_struct(fdt) + offset;
+}
+
+static inline void *_fdt_offset_ptr_w(void *fdt, int offset)
+{
+	return (void *)(uintptr_t)_fdt_offset_ptr(fdt, offset);
+}
+
+static inline const struct fdt_reserve_entry *_fdt_mem_rsv(const void *fdt, int n)
+{
+	const struct fdt_reserve_entry *rsv_table =
+		(const struct fdt_reserve_entry *)
+		((const char *)fdt + fdt_off_mem_rsvmap(fdt));
+
+	return rsv_table + n;
+}
+static inline struct fdt_reserve_entry *_fdt_mem_rsv_w(void *fdt, int n)
+{
+	return (void *)(uintptr_t)_fdt_mem_rsv(fdt, n);
+}
+
+#define FDT_SW_MAGIC		(~FDT_MAGIC)
+
+#endif /* _LIBFDT_INTERNAL_H */
diff --git a/arch/mips/netlogic/common/Makefile b/arch/mips/netlogic/common/Makefile
index 9d5d197..d65ff9e 100644
--- a/arch/mips/netlogic/common/Makefile
+++ b/arch/mips/netlogic/common/Makefile
@@ -3,7 +3,14 @@ EXTRA_CFLAGS := $(CFLAGS) -DNLM_HAL_LINUX_KERNEL -Iarch/mips/include/asm/netlogi
 obj-y :=   cpu_proc.o memory.o bootinfo.o
 
 obj-$(CONFIG_NLM_XLP)			+= nlm_hal_fmn_config.o
+obj-$(CONFIG_NLM_XLP)			+= nlm_hal_cpu_info.o nlm_hal_sys.o nlm_evp_cpld.o
 obj-$(CONFIG_NLM_XLP)			+= nlm_hal.o nlm_hal_nae.o fdt_helper.o
 obj-$(CONFIG_KEXEC)			+= nlm_kexec.o
 
 EXTRA_AFLAGS := $(CFLAGS)
+
+clean-files += msgring.o msgring_xls.o msgring_shared.o nlm_hal_fmn_config.o nlm_hal_cpu_info.o
+clean-files += nlm_hal_sys.o nlm_hal.o
+clean-files += srio.o dma.o cpu_proc.o
+clean-files += msgring.c msgring_xls.c msgring_shared.c nlm_hal.c
+
diff --git a/arch/mips/netlogic/common/nlm_evp_cpld.c b/arch/mips/netlogic/common/nlm_evp_cpld.c
new file mode 100644
index 0000000..6b8f9f1
--- /dev/null
+++ b/arch/mips/netlogic/common/nlm_evp_cpld.c
@@ -0,0 +1,193 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+****************************#NETL_2#********************************/
+
+#ifdef NLM_HAL_LINUX_KERNEL
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <asm/netlogic/hal/nlm_evp_cpld.h>
+#include <asm/netlogic/hal/nlm_hal_sys.h>
+#else
+#include <byteorder.h>
+#include "nlm_evp_cpld.h"
+#include "nlm_hal_sys.h"
+#endif
+
+
+static nlm_xlp_nor_t xlp_nor_dev[8] = {
+{ 0x16000000, SIZE_16MB, 0, 0x2e00 },
+{ 0xffffffff, 0, 0, 0 },
+{ 0x17000000, SIZE_1MB , 1, 0x2C00 },
+{ 0x17100000, SIZE_1MB , 0, 0x2f84 },
+{ 0x17200000, SIZE_1MB , 0, 0x2f84 },
+{ 0xffffffff, 0, 0, 0 },
+{ 0xffffffff, 0, 0, 0 },
+{ 0xffffffff, 0, 0, 0 },
+};
+
+static inline uint32_t nlm_hal_nor_read(uint32_t reg)
+{
+        return nlm_hal_read_32bit_reg(NLM_NOR_CFG_BASE, reg);
+}
+
+static inline void nlm_hal_nor_write(uint32_t reg, uint32_t val)
+{
+        nlm_hal_write_32bit_reg(NLM_NOR_CFG_BASE, reg, val);
+}
+
+uint16_t nlm_hal_cpld_read_16(int cs, uint16_t reg)
+{
+        uint16_t val;
+	if ((cs == 3) || (cs ==4))
+	        nlm_hal_nor_write(XLP_NOR_DEVPARAM + cs , 0x2f84);
+	
+	val = nlm_hal_read_16bit_reg(xlp_nor_dev[cs].base, reg);
+        return (xlp_nor_dev[cs].swap ? le16_to_cpu(val): be16_to_cpu(val));
+}
+
+void nlm_hal_cpld_write_16(int cs, uint16_t val, uint16_t reg)
+{
+        uint16_t data = xlp_nor_dev[cs].swap ? cpu_to_le16(val): cpu_to_be16(val);
+	
+	if ((cs == 3) || (cs ==4))
+	        nlm_hal_nor_write(XLP_NOR_DEVPARAM + cs , 0x2d84);
+
+        nlm_hal_write_16bit_reg(xlp_nor_dev[cs].base, reg, data);
+}
+
+int nlm_xlp_boardver(void)
+{
+	uint16_t data = nlm_hal_cpld_read_16(2, 5);
+	return ((EVP_VER(data) >> 3) + 1);
+}
+
+int nlm_xlp_cpldver(void)
+{
+	return nlm_hal_cpld_read_16(2, 0);
+}
+
+int is_xlp_evp1(void)
+{
+        uint16_t data = nlm_hal_cpld_read_16(2, 5);
+
+        if (EVP_VER(data) == 0)
+                return 1;
+        else
+                return 0;
+}
+
+int is_xlp_evp2(void)
+{
+        uint16_t data = nlm_hal_cpld_read_16(2, 5);
+
+        if (EVP_VER(data))
+                return 1;
+        else
+                return 0;
+}
+
+int is_ilk_card_onslot(int slot)
+{
+	uint16_t data = nlm_hal_cpld_read_16(2, 6);
+
+	slot >>= 1;
+
+	if (DC_TYPE(data, slot) == DC_ILK) 
+		return 1;
+	else
+		return 0;
+}
+
+int nlm_get_interface_type(int node, int slot)
+{
+#ifdef SKIP_INTERFACE_TYPE_FROMCPLD
+	return DC_NOT_PRSNT;
+#else
+	uint16_t data = nlm_hal_cpld_read_16(2, 6);
+
+	nlm_print("Slot present status 0x%x\n", (data & 0xFF));
+        if (slot == 4)
+                return DC_SGMII;
+
+        if (nlm_xlp_cpldver() == 0)
+                return DC_NOT_PRSNT;
+
+	if (slot == 2)
+		slot >>= 1;
+	else if (slot == 1)
+		slot <<= 1;
+	return DC_TYPE(data, slot);
+#endif
+}
+
+int xlp_cpld_init(uint32_t cs)
+{
+	unsigned long base = xlp_nor_dev[cs].base;
+	unsigned long limit = base + xlp_nor_dev[cs].size - 1;
+
+	if (cs > NLM_XLP_MAX_CS)
+		return -1;
+
+	nlm_hal_nor_write(XLP_NOR_CS_BASE + cs , (base >> 8));
+	nlm_hal_nor_write(XLP_NOR_CS_LIMIT + cs , (limit >> 8));
+
+	nlm_hal_nor_write(XLP_NOR_DEVPARAM + cs , xlp_nor_dev[cs].devparam); 
+
+	nlm_hal_nor_write(XLP_NOR_DEV_TIME0 + (cs * 2), 0x4F646EC2 );
+	nlm_hal_nor_write(XLP_NOR_DEV_TIME1 + (cs * 2), 0x8CF3);
+
+	return 0;
+}
+
+void set_gbu_frequency(int node, int frequency)
+{
+	const uint64_t mhz = 1000000;
+	uint64_t set_freq = nlm_hal_set_soc_freq(node, DFS_DEVICE_NOR, frequency * mhz);
+
+#ifdef NLM_HAL_LINUX_KERNEL
+    do_div(set_freq, mhz);
+#else
+    set_freq /= mhz;
+#endif
+	nlm_print("GBU Frequency set to %lluMHz\n", set_freq);
+}
+
+void nlm_hal_cpld_init(int node)
+{
+#if !defined(XLP_SIM) || defined(NLM_BOARD)
+	int i;
+
+	set_gbu_frequency(node, 16);
+	
+	for(i=2; i<5; i++)
+        	xlp_cpld_init(i);
+#endif
+}
+
+#ifdef NLM_HAL_LINUX_KERNEL
+EXPORT_SYMBOL(nlm_hal_cpld_init);
+EXPORT_SYMBOL(nlm_get_interface_type);
+#endif
+
diff --git a/arch/mips/netlogic/common/nlm_hal.c b/arch/mips/netlogic/common/nlm_hal.c
index 5b8fd93..671d195 100644
--- a/arch/mips/netlogic/common/nlm_hal.c
+++ b/arch/mips/netlogic/common/nlm_hal.c
@@ -1,5 +1,5 @@
 /***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
 reserved.
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are
@@ -23,23 +23,86 @@ ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 THE POSSIBILITY OF SUCH DAMAGE.
 *****************************#NETL_2#********************************/
 
+
+/**
+* @defgroup hal Hardware Abstraction Layer APIs
+* @brief This section describes the generic and miscellaneous HAL APIs. <br>
+*
+* <b>Source:</b> libraries/hal/nlm_hal.c <br>
+* <b>Header:</b> hyperexec/srcs/drivers/hal/nlm_hal_fmn.h
+*/
+
+/**
+* @defgroup hal_nae NAE Hardware Abstraction Layer APIs
+* @brief This section describes the NAE(Network Acceleration Engine) HAL APIs.<br>
+*
+* <b>Source:</b> libraries/hal/nlm_hal.c <br>
+* <b>Header:</b> hyperexec/srcs/drivers/hal/nlm_hal.h
+*/
+
+/**
+* @defgroup hal_sae SAE Hardware Abstraction Layer APIs
+* @brief This section describes the SAE(Security Acceleration Engine) HAL APIs <br>
+*
+* <b>Source:</b> libraries/hal/nlm_hal.c <br>
+* <b>Header:</b> hyperexec/srcs/drivers/hal/nlm_hal_sae.h
+*/
+
+/**
+* @defgroup hal_fmn FMN Hardware Abstraction Layer APIs
+* @brief This section describes the FMN(Fast Messaging Network) HAL APIs <br>
+* 
+* <b>Source:</b> libraries/hal/nlm_hal.c <br>
+* <b>Header:</b> hyperexec/srcs/drivers/hal/nlm_hal_fmn.h
+*/
+#include <asm/netlogic/msgring.h>
+#include "nlm_hal.h"
 #include "nlm_hal_fmn.h"
 #include "nlm_hal_nae.h"
-#include "nlm_hal_sae.h"
+#include "nlm_hal_xlp_dev.h"
+#include "nlm_hal_sys.h"
 
 /* These addresses are computed by the nlm_hal_init() */
 unsigned long xlp_io_base;
-unsigned long xlp_fmn_base;
-unsigned long xlp_nae_base;
-unsigned long xlp_mac_base;
-unsigned long xlp_poe_base_pcie;
-unsigned long xlp_poe_base_pcim;
-unsigned long xlp_sys_base;
-
-int naecfg_hack = 1;
-
-void nlm_hal_init_ext_phy(int inf);
-void nlm_hal_config_sgmii_if(int inf);
+unsigned long xlp_fmn_base[NLM_MAX_NODES];
+unsigned long xlp_nae_base[NLM_MAX_NODES];
+unsigned long xlp_sae_base;
+unsigned long xlp_rsa_base;
+unsigned long xlp_mac_base[NLM_MAX_NODES];
+unsigned long xlp_poe_base_pcie[NLM_MAX_NODES];
+unsigned long xlp_poe_base_pcim[NLM_MAX_NODES];
+unsigned long xlp_sys_base[NLM_MAX_NODES];
+unsigned long xlp_regex_base_pcie;
+unsigned long xlp_regex_base_pcim;
+
+struct nlm_node_config  nlm_node_cfg;
+
+static int reg_num_phys;
+void sgmii_scan_phys(int node);
+void  nlm_hal_sata_firmware_init(void);
+void register_phy(int node, int inf, int* hw_portid);
+
+static int mvl_get_phy_status(struct nlm_hal_ext_phy *phy, uint32_t *speed, uint32_t *duplex, int node);
+static void mvl_start_an(struct nlm_hal_ext_phy *phy, int node);
+static void mvl_init_phy(struct nlm_hal_ext_phy *phy, int node);
+
+static int  bcm_get_phy_status(struct nlm_hal_ext_phy *phy, uint32_t *speed, uint32_t *duplex, int node);
+static void bcm_start_an(struct nlm_hal_ext_phy *phy, int node);
+static void bcm_init_phy(struct nlm_hal_ext_phy *phy, int node);
+
+
+void nlm_hal_init_ext_phy(int node, int inf);
+void nlm_hal_config_sgmii_if(int node, int inf);
+
+struct nlm_hal_ext_phy * get_phy_info(int inf);
+#define MAX_PHYS 18
+/*PHYs */
+static struct nlm_hal_ext_phy  known_ext_phys[] = {
+		{"mvs103656", 0xc97, 0, 0, 0, mvl_get_phy_status, mvl_start_an, mvl_init_phy},
+		{"bcm5461s", 0x60c1, 0, 0, 0, bcm_get_phy_status, bcm_start_an, bcm_init_phy}, 
+		{"", 0, 0, 0, 0, NULL, NULL, NULL}
+};
+static struct nlm_hal_ext_phy regs_ext_phys[MAX_PHYS];
 
 static __inline__ unsigned int power_on_reset_cfg(void)
 {
@@ -48,6 +111,16 @@ static __inline__ unsigned int power_on_reset_cfg(void)
 
 #define PCI_MEM_BAR_0 0x4
 #define PCIE_CONTROL_0 0x240
+
+/**
+* @brief nlm_hal_xlp_pcie_rc_init function is used to initialize the XLP PCIE controllers configured in RC mode.
+*
+* @return
+*  - Returns no value.
+*
+* @ingroup hal
+*
+*/
 __inline__ void nlm_hal_xlp_pcie_rc_init(void)
 {
 	int num_pcie = 4; /* Number of PCIe controllers */
@@ -79,61 +152,238 @@ __inline__ void nlm_hal_enumerate_pci(void)
 {
 }
 
+#ifndef NLM_HAL_XLOADER
 /* Basic Reg access
  */
+
+/**
+* @brief nlm_hal_read_16bit_reg function is used to read 16-bit registers (e.g. CPLD)
+*
+* @param [in] base Physical address where the register space starts
+* @param [in] index Register Index
+*
+* @return
+*  - 16bit register value
+*
+* @sa nlm_hal_write_16bit_reg, nlm_hal_read_32bit_reg, nlm_hal_write_32bit_reg, nlm_hal_read_64bit_reg, nlm_hal_write_64bit_reg??
+* @ingroup hal
+*
+*/
+__inline__ uint16_t nlm_hal_read_16bit_reg(uint64_t base, uint32_t index){
+    return nlh_read_cfg_reg16(base + (index << 1));
+} 
+/**
+* @brief nlm_hal_write_16bit_reg function is used to write 16-bit registers (e.g. CPLD)
+*
+* @param [in] base Physical address where the register space starts
+* @param [in] index Register Index
+* @param [in] val Register value
+*
+* @return
+*  - none
+*
+* @sa nlm_hal_read_16bit_reg, nlm_hal_read_32bit_reg, nlm_hal_write_32bit_reg, nlm_hal_read_64bit_reg, nlm_hal_write_64bit_reg??
+* @ingroup hal
+*
+*/
+__inline__ void nlm_hal_write_16bit_reg(uint64_t base, uint32_t index, uint16_t val){
+    nlh_write_cfg_reg16(base +  (index << 1) , val);
+} 
+
+/**
+* @brief nlm_hal_read_32bit_reg function is used to read 32bit registers
+*
+* @param [in] base Physical address where the register space starts
+* @param [in] index Register Index
+*
+* @return
+*  - 32bit register value
+* 
+* @sa nlm_hal_write_32bit_reg, nlm_hal_read_64bit_reg, nlm_hal_write_64bit_reg
+* @ingroup hal
+*
+*/
 __inline__ uint32_t nlm_hal_read_32bit_reg(uint64_t base, int index)
 {
 	return nlh_read_cfg_reg32(base + (index << 2));
 }
 
+/**
+* @brief nlm_hal_write_32bit_reg function is used to write 32bit registers
+*
+* @param [in] base Physical address where the register space starts
+* @param [in] index Register Index
+* @param [in] val Register value
+*
+* @return
+*  - none
+* 
+* @sa nlm_hal_read_32bit_reg, nlm_hal_read_64bit_reg, nlm_hal_write_64bit_reg
+* @ingroup hal
+*
+*/
 __inline__ void nlm_hal_write_32bit_reg(uint64_t base, int index, uint32_t val)
 {
 	nlh_write_cfg_reg32(base +  (index << 2) , val);
 }
 
+/**
+* @brief nlm_hal_read_64bit_reg function is used to read 64bit registers
+*
+* @param [in] base Physical address where the register space starts
+* @param [in] index Register Index
+*
+* @return
+*  - 64bit register value
+* 
+* @sa nlm_hal_write_32bit_reg, nlm_hal_read_32bit_reg, nlm_hal_write_64bit_reg
+* @ingroup hal
+*
+*/
 __inline__ uint64_t nlm_hal_read_64bit_reg(uint64_t base, int index)
 {
 	return nlh_read_cfg_reg64(base + (index << 3));
 }
+/**
+* @brief nlm_hal_read_64bit_reg function is used to write 64bit registers
+*
+* @param [in] base Physical address where the register space starts
+* @param [in] index Register Index
+* @param [in] val Register value
+*
+* @return
+*  - none
+* 
+* @sa nlm_hal_write_32bit_reg, nlm_hal_read_32bit_reg, nlm_hal_read_64bit_reg
+* @ingroup hal
+*
+*/
 __inline__ void nlm_hal_write_64bit_reg(uint64_t base, int index, uint64_t val)
 {
 	nlh_write_cfg_reg64(base +  (index << 3) , val);
 }
-
+#endif /*NLM_HAL_XLOADER*/
 /*
  *    Generic Devices
  */
+/**
+* @brief nlm_hal_get_dev_base function is used to get device base address 
+*
+* @param [in] node Node ID
+* @param [in] bus Bus ID
+* @param [in] dev Device ID
+* @param [in] func Function ID
+*
+* @return
+*  - Physical address of the base address for a given (node, bus, device, function) combination
+* 
+* @ingroup hal
+*
+*/
 __inline__ uint64_t nlm_hal_get_dev_base(int node, int bus, int dev, int func)
 {
 	uint64_t base = xlp_io_base & 0x1fffffff;
 
 	return (uint64_t)  (base +
-			    (bus << 20) +   
-			    (dev << 15) +   
-			    (node*8 << 15) +
+			    (bus << 20) +    
+			    (dev << 15) +    
+			    (node*8 << 15) + 
 			    (func << 12));
 }
 
 /*
  *     FMN
  */
+/**
+* @brief nlm_hal_send_msg3 function is a non-blocking API used to send a three entry message to a mailbox. Does not retry the send message. Performs a sync before sending.
+*
+* @param [in] dst Destination Message Queue number
+* @param [in] code 8b SW code to send with the message
+* @param [in] data0 64b data value for the first message
+* @param [in] data1 64b data value for the second message
+* @param [in] data2 64b data value for the third message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 __inline__ uint32_t nlm_hal_send_msg3(uint32_t dst, uint32_t code, uint64_t data0, uint64_t data1, uint64_t data2)
 {
 	return nlh_send_msg3(dst, code, data0, data1, data2);
 }
+
+/**
+* @brief nlm_hal_send_msg2 function is a non-blocking API used to send a two entry message to a mailbox. Will retry the message send 16 times. Performs a sync before sending.
+*
+* @param [in] dst Destination Message Queue number
+* @param [in] code 8b SW code to send with the message
+* @param [in] data0 64b data value for the first message
+* @param [in] data1 64b data value for the second message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 __inline__ uint32_t nlm_hal_send_msg2(uint32_t dst, uint32_t code, uint64_t data0, uint64_t data1)
 {
 	return nlh_send_msg2(dst, code, data0, data1);
 }
+/**
+* @brief nlm_hal_send_msg1 function is a non-blocking API used to send a single entry message to a mailbox. Will retry the message send 16 times. Performs a sync before sending.
+*
+* @param [in] dst Destination Message Queue number
+* @param [in] code 8b SW code to send with the message
+* @param [in] data0 64b data value for the single message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 __inline__ uint32_t nlm_hal_send_msg1(uint32_t dst, uint32_t code, uint64_t data0)
 {
 	return nlh_send_msg1(dst, code, data0);
 }
-
+/**
+* @brief nlm_hal_recv_msg2 function is used to receive a two entry message from a VC of the CPU. Size should be used to determine how many of msg0-msg1 have valid data and if there were more messages available.
+*
+* @param [in] vc VC mailbox of the CPU (1 to 4)
+* @param [out] src_id Source Message Queue Number
+* @param [out] size # of messages that were in this received message (1 to 4)
+* @param [out] code 8b SW code of the received message
+* @param [out] msg0 64b data value for the first received message
+* @param [out] msg1 64b data value for the second received message
+*
+* @return
+*  - "0" on receive success, "-1" on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 __inline__ uint32_t nlm_hal_recv_msg2(uint32_t dst, uint32_t *src, uint32_t *size, uint32_t *code, uint64_t *data0, uint64_t *data1)
 {
 	return nlh_recv_msg2(dst, src, size, code, data0, data1);
 }
+/**
+* @brief nlm_hal_recv_msg1 function is used to receive a single entry message from a VC of the CPU. Size should be used to determine how other 64b messages were available with data.
+*
+* @param [in] dst VC mailbox of the CPU (1 to 4)
+* @param [out] src Source Message Queue Number
+* @param [out] size # of messages returned (1 to 4)
+* @param [out] code 8b SW code of the received message
+* @param [out] data0 64b data value for the received message
+*
+* @return
+*  - "0" on receive success, "-1" on failure
+* 
+* @ingroup hal_fmn
+*
+*/
 __inline__ uint32_t nlm_hal_recv_msg1(uint32_t dst, uint32_t *src, uint32_t *size, uint32_t *code, uint64_t *data0)
 {
 	return nlh_recv_msg1(dst, src, size, code, data0);
@@ -162,29 +412,67 @@ __inline__ int nlm_hal_is_xlp_le(void)
 }
 
 /* Main initialization */
+/**
+* @brief nlm_hal_init function is used to Initialize HAL
+*
+* @return
+*  - Returns no value.
+*
+* @note
+*    This function must be the first to be called before any other HAL API's
+* 
+* @ingroup hal
+*
+*/
+
 __inline__ void nlm_hal_init(void)
 {
 	unsigned long long mask = ~0xf;
-#if !defined(NLM_HAL_LINUX_USER) && (_MIPS_SZLONG == 64)
+	int node = 0;
+#if !defined(NLM_HAL_LINUX_USER)
 	unsigned int flags = 0;
 	enable_KX(flags);
 #endif
+	nlm_hal_enumerate_pci();
 
+	nlm_node_cfg.valid = 1;
+	nlm_node_cfg.num_nodes = 1;
 
-	nlm_hal_enumerate_pci();
+ 	for(node = 0; node < NLM_MAX_NODES; node++)
+	{
+		//nlm_node_cfg.nae_cfg[node] = NULL;
+		nlm_node_cfg.nae_cfg[node] = NULL;
+		nlm_node_cfg.fmn_cfg[node] = NULL;
+
+		xlp_io_base = KSEG1 + 0x18000000;
 
-	xlp_io_base = KSEG1 + 0x18000000;
+        	/* PCI enumeration of supported devices*/
+		xlp_fmn_base[node] = mask & nlm_hal_read_32bit_reg((0x18000000 + XLP_CFG_BASE(node, XLP_FMN)), PCI_MEM_BAR_0);
 
-        /* PCI enumeration of supported devices*/
-	xlp_fmn_base = mask & nlm_hal_read_32bit_reg(0x18020000, PCI_MEM_BAR_0);
+		xlp_mac_base[node] = mask & nlm_hal_read_32bit_reg((0x18000000 + XLP_CFG_BASE(node, XLP_NAE)), PCI_MEM_BAR_0); //0x18018000
+		xlp_nae_base[node] = xlp_mac_base[node] + 0xe000;
 
-	xlp_mac_base = mask & nlm_hal_read_32bit_reg(0x18018000, PCI_MEM_BAR_0);
-	xlp_nae_base = xlp_mac_base + 0xe000;
+		xlp_poe_base_pcim[node] = mask & nlm_hal_read_32bit_reg((0x18000000 + XLP_CFG_BASE(node, XLP_POE)), PCI_MEM_BAR_0);	//0x18019000
+		xlp_poe_base_pcie[node] = (xlp_io_base | XLP_CFG_BASE(node, XLP_POE)) & 0x1fffffff; /* For now . Will be fixed soon.*/
 
-	xlp_poe_base_pcim = mask & nlm_hal_read_32bit_reg(0x18019000, PCI_MEM_BAR_0);
-	xlp_poe_base_pcie = (xlp_io_base + 0x19000) & 0x1fffffff; /* For now . Will be fixed soon.*/
+		xlp_sys_base[node] = (xlp_io_base | XLP_CFG_BASE(node, XLP_SYS)) & 0x1fffffff; /*For now . Will be fixed soon.*/
+	}
+
+	xlp_sae_base = (xlp_io_base | XLP_CFG_BASE(0, XLP_SAE)) & 0x1fffffff; /* For now . Will be fixed soon.*/
+        xlp_rsa_base = (xlp_io_base | XLP_CFG_BASE(0, XLP_RSA)) & 0x1fffffff; /* For now . Will be fixed soon.*/
 
-	xlp_sys_base = (xlp_io_base + 0x35000) & 0x1fffffff; /*For now . Will be fixed soon.*/
+       	if (is_nlm_xlp3xx()) {
+		xlp_regex_base_pcie = (xlp_io_base | (XLP_CFG_BASE(0, XLP_3XX_REGEX))) & 0x1fffffff;
+	        xlp_regex_base_pcim = mask & nlm_hal_read_32bit_reg((0x18000000 + XLP_CFG_BASE(0, XLP_3XX_REGEX)), PCI_MEM_BAR_0);
+                nlm_print("Regex (netl7) vendor_device id: %#x xlp_regex_base_pcim %#lx xlp_regex_base_pcie %#lx\n",
+                               nlm_hal_read_32bit_reg(xlp_regex_base_pcie, 0), xlp_regex_base_pcim, xlp_regex_base_pcie);
+       	}
+
+#if !defined(NLM_HAL_UBOOT)
+#ifndef CONFIG_N511
+        	nlm_hal_cpld_init(0);	
+#endif
+#endif
 
 #if !defined(NLM_HAL_LINUX_USER) && (_MIPS_SZLONG == 64)
 	disable_KX(flags);
@@ -205,6 +493,8 @@ EXPORT_SYMBOL(xlp_fmn_base);
 EXPORT_SYMBOL(xlp_nae_base);
 EXPORT_SYMBOL(xlp_mac_base);
 EXPORT_SYMBOL(xlp_sys_base);
+EXPORT_SYMBOL(xlp_sae_base);
+EXPORT_SYMBOL(xlp_rsa_base);
 EXPORT_SYMBOL(xlp_poe_base_pcie);
 EXPORT_SYMBOL(xlp_poe_base_pcim);
 
@@ -216,8 +506,7 @@ EXPORT_SYMBOL(nlm_hal_recv_msg1);
 EXPORT_SYMBOL(nlm_hal_send_msg2);
 EXPORT_SYMBOL(nlm_hal_recv_msg2);
 EXPORT_SYMBOL(nlm_hal_send_msg3);
-#endif
-
+#else
 #include "nlm_hal_pic.h"
 /*
    This is to map 160 irt entry to 64 interrupt vector
@@ -360,7 +649,7 @@ int irt_irq_table[160][4]= {
         {39,    1,      4,      0},     /*PICIRT_COMP_INDEX(1)      125 */
         {39,    1,      4,      0},     /*PICIRT_COMP_INDEX(2)      126 */
         {39,    1,      4,      0},     /*PICIRT_COMP_INDEX(3)      127 */
-        {38,    0,      0,      0},     /*PICIRT_GBU_INDEX          128 */
+        {0,     0,      0,      0},     /*                          128 */
         {37,    1,      3,      0},     /*PICIRT_ICC_0_INDEX        129  ICC - Inter Chip Coherency*/
         {37,    1,      3,      0},     /*PICIRT_ICC_1_INDEX        130 */
         {37,    1,      3,      0},     /*PICIRT_ICC_2_INDEX        131 */
@@ -373,11 +662,11 @@ int irt_irq_table[160][4]= {
         {12,    1,      2,      0},     /*PICIRT_SYS_1              138	*/
         {55,    0,      0,      0},     /*PICIRT_JTAG_INDEX         139	*/
         {50,    0,      0,      0},     /*PICIRT_PIC                140	*/
-        {54,    0,      0,      0},     /*PICIRT_NBU                141	*/
-        {53,    0,      0,      0},     /*PICIRT_TCU                142	*/
-        {52,    0,      0,      0},     /*PICIRT_GCU                143  GBC - Global Coherency*/
-        {36,    1,      2,      0},     /*PICIRT_DMC_0_INDEX        144	*/
-        {36,    1,      2,      0},     /*PICIRT_DMC_1_INDEX        145	*/
+        {0,     0,      0,      0},     /*Reserved                  141	*/
+        {0,     0,      0,      0},     /*Reserved                  142	*/
+        {31,    0,      0,      0},     /*XLP_SATA		    143	*/
+        {0,     0,      0,      0},     /*Reserved        	    144	*/
+        {0,     0,      0,      0},     /*Reserved        	    145	*/
         {13,    0,      0,      0},     /*PICIRT_GPIO_INDEX(0)      146	*/
         {14,    0,      0,      0},     /*PICIRT_GPIO_INDEX(1)      147	*/
         {15,    0,      0,      0},     /*PICIRT_GPIO_INDEX(2)      148	*/
@@ -386,12 +675,12 @@ int irt_irq_table[160][4]= {
         {21,    0,      0,      0},     /*PICIRT_NAND               151	*/
         {22,    0,      0,      0},     /*PICIRT_SPI                152	*/
         {23,    0,      0,      0},     /*PICIRT_MMC                153	*/
-        {0,     0,      0,      0},     /*			    154	*/
-        {0,     0,      0,      0},     /*                          155	*/
-        {0,     0,      0,      0},     /*                          156	*/
-        {0,     0,      0,      0},     /*                          157	*/
-        {0,     0,      0,      0},     /*                          158	*/
-        {0,     0,      0,      0},     /*                          159	*/
+        {54,    0,      0,      0},     /*PICIRT_NBU		    154	*/
+        {53,    0,      0,      0},     /*PICIRT_TCU                155	*/
+        {52,    0,      0,      0},     /*PICIRT_GCU                156	*/
+        {36,    1,      2,      0},     /*DDR3 DMC                  157 */
+        {36,    1,      2,      0},     /*DDR3 DMC		    158 */
+        {57,    0,      0,      0},     /*Trace Buffer	TCB	    159 */
 };
 
 
@@ -572,29 +861,6 @@ void nlm_hal_set_irq_to_cpu(int irq, int cpu)
         return;
 }
 
-static const unsigned char dfs_values[4] =
-{ 2,4,8,16};
-
-unsigned long long nlm_hal_cpu_freq(void)
-{
-	unsigned long long mips_counter_frequency;
-	unsigned int pwron_rst_reg = nlm_hal_read_sys_reg(POWER_ON_RESET_CFG);
-
-	int pll_divf = (pwron_rst_reg >> 10) & 0x7f;
-	int pll_divr = (pwron_rst_reg >> 8)  & 0x3;
-	int dfs_div  = (pwron_rst_reg >> 17) & 0x3;
-
-        unsigned long long vco_fs         = (((7500 * 1000) * (pll_divr+1))/(4 * (pll_divf+1)));
-	unsigned long long pll_period_fs  = vco_fs * 2; /* pll output is divided by 2 */
-
-	dfs_div = dfs_values[dfs_div];
-
-	mips_counter_frequency = 1000000000000000ULL/pll_period_fs;
-	mips_counter_frequency = mips_counter_frequency / dfs_div;
-
-	return mips_counter_frequency;
-}
-
 unsigned long tlb_size_to_page_size(unsigned long size)
 {
 	if (size <= (4*1024)) return 4*1024;
@@ -622,1315 +888,272 @@ unsigned long tlb_size_to_mask(unsigned long size)
 
 	return 0xffff << 13;
 }
-
-/*
- * NAE Support
- */
-/* Currently Only Gmac is supported !! */
-/* NETWORK INF CTRL REG */
-#define SOFTRESET(x)                        ((x) << 11)
-#define STATS_EN(x)                         ((x) << 16)
-#define TX_EN(x)                            ((x) << 2)
-#define SPEED(x)                            ((x) & 0x3)
-
-/* MAC_CONF1 */
-#define INF_SOFTRESET(x)                    ((x) << 31)
-#define INF_LOOP_BACK(x)                    ((x) << 8)
-#define INF_RX_ENABLE(x)                    ((x) << 2)
-#define INF_TX_ENABLE(x)                    (0x1)
-
-/* MAC_CONF2 */
-#define INF_PREMBL_LEN(x)                   (((x) & 0xf) << 12)
-#define INF_IFMODE(x)                       (((x) & 0x3) << 8)
-#define INF_LENCHK(x)                       ((((x) & 0x1)) << 4)
-#define INF_PADCRCEN(x)                     (((x) & 0x1) << 2)
-#define INF_PADCRC(x)                       (((x) & 0x1) << 1)
-#define INF_FULLDUP(x)                      ((x) & 0x1)
-#define TXINITIORCR(x)                      ((x) & 0x7ffff) << 8
-
-#define NAE_RX_ENABLE 0x1
-#define NAE_TX_ENABLE 0x1
-#define NAE_TX_ACE 0x2
-
-#define INF_BYTE_MODE   0x2
-#define INF_NIBBLE_MODE 0x1
-
-enum NAE_REG_CMD {
-	CMD_READ = 0,
-	CMD_WRITE
-};
-
-enum if_speed {
-        SPEED_10M = 0,
-        SPEED_100M,
-        SPEED_1000M
-}; 
-
-
-int nlm_hal_init_if_regs(int type, int  inf, uint32_t *regs, int num_regs)
-{
-	int i;
- 	if ((regs == NULL) || (num_regs == 0)) {
-		return -2;
-	}
-
-	if (type != INTERLAKEN_IF) {
-		for (i = 0; i < num_regs; i++) {
-			write_gmac_reg(inf, regs[2*i], regs[2*i + 1]);
-		}
-		return 0;
-	}
-	return -1;
-}
-int nlm_hal_init_nae_regs(int type, uint32_t *regs, int num_regs)
-{
-	int i;
- 	if ((regs == NULL) || (num_regs == 0)) {
-		return -2;
-	}
-
-	if (type == INTERLAKEN_IF) {
-		return -1;
-	}
-
-	for (i = 0; i < num_regs; i++) {
-		nlm_hal_write_nae_reg(regs[2*i], regs[2*i + 1]);
-	}
-	return 0;
-}
-
-int nlm_hal_init_poe_regs(uint32_t *regs, int num_regs)
-{
-	int i;
- 	if ((regs == NULL) || (num_regs == 0)) {
-		return -2;
-	}
-
-	for (i = 0; i < num_regs; i++) {
-		if (regs[3*i] == PCIE_MEM_POE_REG) {
-			/* PCIE MEM based regs */
-			nlm_hal_write_poe_pcim_reg(regs[3*i + 1], regs[3*i + 2]);
-
-		} else if (regs[3*i] == PCIE_CFG_POE_REG) {
-			/* PCIE  CFG header based regs */
-			nlm_hal_write_poe_pcie_reg(regs[3*i + 1], regs[3*i + 2]);
-		}
-	}
-	return 0;
-}
-
-void nlm_hal_init_poe_ext_storage(uint64_t fbp_base_phys,
-				  uint64_t msg_base_phys,
-	                          uint64_t msg_base_virt)
-{
-	uint32_t addr;
-	uint64_t ldata, a;
-	uint64_t *vaddr;
-	int i;
-	uint32_t mbase_hi, mbase_lo, fbp_hi, fbp_lo;
-	mbase_hi = (msg_base_phys >> 32) & 0xffffffff;
-	mbase_lo = msg_base_phys & 0xffffffff;
-	fbp_hi = (fbp_base_phys >> 32) & 0xffffffff;
-	fbp_lo = fbp_base_phys & 0xffffffff;
-
-	/* POE External Message Storage (upto 58K) */
-
-	nlm_print("POE ext msg storage: \n");
-	nlm_print("msg base: 0x%x%x\n", mbase_hi, mbase_lo);
-	nlm_print("fbp base: 0x%x%x\n", fbp_hi, fbp_lo);
-
-	/* Free Buffer Pool config */
-	nlm_print (" POE Free Buffer Pool config ...\n");
-
-	a = (uint64_t)EXT_FBP_START_ADDR;
-	vaddr = (uint64_t *) msg_base_virt;
-	for (i = 0; i < (MAX_POE_EXT_MSG_STORAGE / 4); i++) {
-		ldata = ((a+3) << 48) | ((a+2) << 32) | ((a+1) << 16) | a;
-		*vaddr = ldata;
-		vaddr++;
-		a += 4;
-	}
-
-	/* Configuring Message base pointer */
-	addr = MSG_STORAGE_BASE_ADR_L;
-	nlm_print ("POE Configuring Message base pointer ...\n");
-	nlm_hal_write_poe_pcie_reg(addr, mbase_lo);
-	addr++;
-	nlm_hal_write_poe_pcie_reg(addr, mbase_hi);
-
-	/* Configuring FBP base pointer */
-	addr = FBP_BASE_ADR_L;
-	nlm_print ("POE Configuring FBP base pointer ...\n");
-	nlm_hal_write_poe_pcie_reg(addr, fbp_lo);
-	addr++;
-	nlm_hal_write_poe_pcie_reg(addr, fbp_hi);
-}
-
-
-#define NUM_VCS_PER_CPU 4
-#define NUM_DISTVEC_CELLS 16
-#define NUM_DISTVEC_CPUMASKS 4
-
-#define MIN_DIST_VEC 0
-#define MAX_DIST_VEC 16
-
-#define POE_DIST_VEC0 0x100
-
-int nlm_hal_init_poe_distvec(int vec, uint32_t cm0, uint32_t cm1,
-	uint32_t cm2, uint32_t cm3, uint32_t vcmask)
-{
-	uint32_t cpumasks[NUM_DISTVEC_CPUMASKS];
-	uint32_t distvec[NUM_DISTVEC_CELLS];
-	int i;
-	int cpu;
-
-	if (vec < MIN_DIST_VEC || vec >= MAX_DIST_VEC)
-		return -1;
-
-	cpumasks[0] = cm0;
-	cpumasks[1] = cm1;
-	cpumasks[2] = cm2;
-	cpumasks[3] = cm3;
-
-	vcmask &= 0xf;
-	if (!vcmask)
-		return -1;
-
-	/* Initialize distribution vector cells */
-	for (i = 0; i < NUM_DISTVEC_CELLS; i++) {
-		distvec[i] = 0;
-	}
-
-	for (i = 0; i < NUM_DISTVEC_CPUMASKS; i++) {
-		uint32_t cpumask = cpumasks[i];
-
-		for (cpu = 0; cpu < 32; cpu++) {
-			int cell, offset;
-			uint32_t value;
-			int vc = 0;
-			int gcpu = 0;
-
-			if (((1 << cpu) & cpumask) == 0)
-				continue;
-
-			/* Use global cpu id */
-			gcpu = cpu + (i * 32);
-			vc = (gcpu * NUM_VCS_PER_CPU) % (NUM_DISTVEC_CELLS * 32);
-
-			cell = vc / 32;
-			offset = vc % 32;
-
-			value = vcmask << offset;
-
-			distvec[cell] |= value;
-		}
-	}
-
-	/* Write distribution vector cells */
-	for (i = 0; i < NUM_DISTVEC_CELLS; i++) {
-		int reg_index;
-		uint32_t value;
-
-		reg_index = POE_DIST_VEC0 + (vec * NUM_DISTVEC_CELLS)
-		            + (NUM_DISTVEC_CELLS - 1 - i);
-		value = distvec[i];
-
-		nlm_print("POE DistVec[%d]: reg=%d value=%08x\n",
-		          vec, (NUM_DISTVEC_CELLS - 1 - i), value);
-		nlm_hal_write_poe_pcim_reg(reg_index, value);
-	}
-
-	return 0;
-}
-
-extern struct nlm_hal_nae_config nae_cfg;
-
-void cpu_hotplug_fixup_poe(int cpu, int flag)
-{
-	unsigned long mflags = 0;
-	int reg_index;
-	uint32_t value, vcmask;
-	int cell, offset, vc = 0;
-	uint32_t distvec[NUM_DISTVEC_CELLS];
-
-	vcmask =  (1 << nae_cfg.rx_vc);
-	vc = (cpu * NUM_VCS_PER_CPU) % (NUM_DISTVEC_CELLS * 32);
-	cell = vc / 32;
-
-	reg_index = POE_DIST_VEC0 + (NUM_DISTVEC_CELLS - 1 - cell);
-
-	/* do we need to ensure nobody is operating on msgrng? */
-	msgrng_access_enable(mflags);
-	if (flag) {
-		/* online */
-		offset = vc % 32;
-		value = vcmask << offset;
-
-		distvec[cell] |= value;
-		nlm_hal_write_poe_pcim_reg(reg_index, value);
-	} else {
-		/* offline */
-		nlm_hal_write_poe_pcim_reg(reg_index, 0);
-	}
-	msgrng_access_disable(mflags);
-}
-
-
-int nlm_hal_init_if(int type, int  inf, uint32_t *regs, int num_regs)
-{
-	int i;
-	if (regs == NULL) {
-		return -1;
-	}
-	if (type == INTERLAKEN_IF) {
-		return -1;
-	}
-	/* Initialize the regs */
-	for (i = 0; i < num_regs; ++i) {
-		/*		nlm_hal_write_nae_reg(inf, regs[2*i], regs[2*i + 1]); */
-	}
-	return 0;
-}
-
-static int init_netior(int type)
-{
-	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_SOFTRESET, 0);
-	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_MISC_REG3_ADDR , (0x0 | (0x0007 << 18) ) );
-	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_MISC_REG2_ADDR , 0x07070707 );
-	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_MISC_REG1_ADDR , 0x00fffff );
-	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_MISC_REG1_ADDR , 0x0);
-	return 0;
-}
-
-/* Ingress Config
- *      20 queue (1000 - 1019)
- *      RxConfig : set the Free in desc default
- *      Interface to context mapping(RX_IF_BASE_CONFIG0..8)
- *      set valid active interface
- *      parser configuration
- *      Free-Fifo pool to context (FREE_IN_FIFO_CFG)
- *      Parser se
- *
- *
- * */
-static void init_ingress(void)
-{
-	unsigned int rx_cfg = 0;
-	unsigned int parser_threshold = 384 ;
-	int desc_size = 2048;
-
-	rx_cfg = nlm_hal_read_nae_reg(RX_CONFIG);
-
-	//log_dbg("nae rxcfg %x txcfg %x\n", rx_cfg, tx_cfg);
-#define NAE_MAX_MESSAGE_SIZE(x)                 (((x) & 0x3)<<1)
-#define RESET_MAX_MESSAGE_SIZE                   ~(0x3<<1)
-#define NAE_FRINDESCCLSIZE(x)                   (((x)  & 0xff)<< 4 )
-#define RESET_FRINDESCCLSIZE                   ~((0xff)<< 4)
-#define NAE_RX_STATUS_MASK(x)                   (((x) & 0x7f) << 24)
-#define RESET_RX_STATUS_MASK                   ~((0x3f) << 24)
-
-	nlm_hal_write_nae_reg( RX_CONFIG,(rx_cfg &
-					  RESET_MAX_MESSAGE_SIZE &
-					  RESET_FRINDESCCLSIZE &
-					  RESET_RX_STATUS_MASK
-				       ) |
-			       NAE_RX_ENABLE|
-			       NAE_MAX_MESSAGE_SIZE(0x0)|
-			       NAE_RX_STATUS_MASK(0x43)|
-			       NAE_FRINDESCCLSIZE(desc_size/64)
-		);
-
-#define PARSER_THRESHOLD(x) ((x)  & 0x3ff)
-#define PARSER_THRESHOLD_DIV_DESCSIZE(x) ( ((x) & 0xff) << 12)
-#define PARSER_THRESHOLD_MOD_DESCSIZE_CL(x) ( ((x) & 0xff) << 20)
-
-	nlm_hal_write_nae_reg( XLP_PARSER_CONFIG,
-			       PARSER_THRESHOLD(parser_threshold) |
-			       PARSER_THRESHOLD_DIV_DESCSIZE((parser_threshold/desc_size) + 1) |
-			       PARSER_THRESHOLD_MOD_DESCSIZE_CL( (parser_threshold/64)%desc_size) );
-}
-
-static void init_egress(void)
-{
-	uint32_t tx_cfg =  nlm_hal_read_nae_reg(TX_CONFIG);
-
-	nlm_hal_write_nae_reg( TX_CONFIG, tx_cfg | NAE_TX_ENABLE | NAE_TX_ACE );
-}
-
-static void init_ucore(int if_num)
-{
-
-	nlm_hal_write_nae_reg(UCORE_IFACE_MASK_CFG,
-			      ucore_spray_config(if_num, 0xffff, CMD_WRITE));
-
-}
-
-int nlm_hal_open_if(int type, int  inf)
-{
-	unsigned int netwk_inf  = 0;
-	unsigned int tx_config = 0;
-	int tx_ior_credit = 0;
-	uint32_t ifmask = 0;
-	unsigned int mac_cfg1 = 0;
-	unsigned int netior_ctrl3 = 0;
-
-	// Init Netior ... Need to fixed
-	init_netior(type);
-
-	switch(type) {
-		case XAUI_IF:
-			// inf is a complex number
-			netwk_inf = nlm_hal_read_mac_reg(inf, XGMAC, NETIOR_XGMAC_CTRL1);
-			netwk_inf |= (1 << NETIOR_XGMAC_STATS_CLR_POS);
-			nlm_hal_write_mac_reg(inf, XGMAC, NETIOR_XGMAC_CTRL1, netwk_inf);
-			ifmask = 0xf << (inf);
-			tx_ior_credit = nlm_hal_read_nae_reg(TX_IORCRDT_INIT);
-			nlm_hal_write_nae_reg(TX_IORCRDT_INIT, tx_ior_credit | ifmask);
-		        tx_config = nlm_hal_read_nae_reg(TX_CONFIG);
-			// need to toggle these bits for credits to be loaded
-		 	nlm_hal_write_nae_reg(TX_CONFIG, tx_config | ( TXINITIORCR(ifmask)));
-		        nlm_hal_write_nae_reg(TX_CONFIG, tx_config & ~( TXINITIORCR(ifmask)));
-			break;
-		case INTERLAKEN_IF:
-			// inf is a complex number
-			ifmask = 0xff << (inf);   //based on number of lanes
-			tx_ior_credit = nlm_hal_read_nae_reg(TX_IORCRDT_INIT);
-			nlm_hal_write_nae_reg(TX_IORCRDT_INIT, tx_ior_credit | (ifmask));
-                        tx_config = nlm_hal_read_nae_reg(TX_CONFIG);
-			// need to toggle these bits for credits to be loaded
-	                nlm_hal_write_nae_reg(TX_CONFIG, tx_config | ( TXINITIORCR(ifmask)));
-                        nlm_hal_write_nae_reg(TX_CONFIG, tx_config & ~( TXINITIORCR(ifmask)));
-			break;
-		case SGMII_IF:
-			tx_ior_credit = nlm_hal_read_nae_reg(TX_IORCRDT_INIT);
-			nlm_hal_write_nae_reg(TX_IORCRDT_INIT, tx_ior_credit & (~ (1<<inf)));
-			tx_config = nlm_hal_read_nae_reg(TX_CONFIG);
-			// need to toggle these bits for credits to be loaded
-			nlm_hal_write_nae_reg(TX_CONFIG, tx_config | ( TXINITIORCR(1<<inf)));
-			nlm_hal_write_nae_reg(TX_CONFIG, tx_config & ~( TXINITIORCR(1<<inf)));
-
-			/* init phy id to access internal PCS */
-		        netwk_inf = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
-        		netwk_inf &= 0x7ffffff;
-		        netwk_inf |= ((inf) << 27);
-        		write_gmac_reg(inf, NETWK_INF_CTRL_REG, netwk_inf);
-
-			/* Sofreset set bit 11 to 0  */
-
-			write_gmac_reg(inf , NETWK_INF_CTRL_REG,  netwk_inf & 0xfffff7ff);
-
-			// Reset GMAC
-			mac_cfg1 = read_gmac_reg(inf, MAC_CONF1);
-		        write_gmac_reg(inf , MAC_CONF1, mac_cfg1 | INF_SOFTRESET(1) |
-					           INF_RX_ENABLE(1) |
-						   INF_TX_ENABLE(1));
-
-			// Default 1G
-		        write_gmac_reg(inf , MAC_CONF2,  INF_PREMBL_LEN(0x7) |
-                        		     	INF_IFMODE(2)  |
-                	               		INF_FULLDUP(1) |
-		  			        INF_PADCRCEN(1));
-
-			// Clear GMAC reset
-			mac_cfg1 = read_gmac_reg(inf, MAC_CONF1);
-		        write_gmac_reg(inf , MAC_CONF1, mac_cfg1 & ~(INF_SOFTRESET(1)));
-
-			// Clear speed debug bit
-		        netior_ctrl3 = read_gmac_reg(inf, NETWK_INF_CTRL3_REG);
-		        write_gmac_reg(inf, NETWK_INF_CTRL3_REG, netior_ctrl3 & (~(1<<6)));
-
-#ifndef XLP_SIM
-			// init external phy, bypass SGMII auto negotiation
-			nlm_hal_init_ext_phy(inf);
 #endif
-			// Configure speed and mode
-			nlm_hal_config_sgmii_if(inf);
-			break;
-		default:
-			nlm_print("Unknown interface type\n");
-			return 0;
-	}
-
-	init_ingress();
-	init_egress();
-	init_ucore(inf);
-
-	return 0;
-}
-int nlm_hal_close_if(int type, int  inf)
-{
-	if (type != SGMII_IF) {
-		return -1;
-	}
-	/* Turn off TX, RX enables */
-	return 0;
-}
-/*
- *  NAE Send
- */
-static __inline__ uint64_t nae_tx_desc(unsigned int type,
-				       unsigned int rdex,
-				       unsigned int fbid,
-				       unsigned int len,
-				       uint64_t addr)
-{
-	return ((uint64_t)(type & 0x3) << 62) |
-		((uint64_t)(rdex & 0x1) << 61) |
-		((uint64_t)(fbid & 0x7f) << 54) |
-		((uint64_t)(len & 0x3fff) << 40) |
-		addr;
-}
-
-int nlm_hal_nae_send(int dest, int fbid, unsigned long long phys_addr, int len, unsigned int flags)
-{
-	/* TODO: Implement flags */
-	unsigned long long data[4];
-
-	data[0] = nae_tx_desc(P2D_NEOP, 0, fbid, 0, phys_addr);
-	data[1] = nae_tx_desc(P2D_EOP,
-			      0,
-			      NULL_VFBID,
-			      len ,
-			      phys_addr );
-
-	return nlm_hal_send_msg2(dest,
-				 0,
-				 data[0],
-				 data[1]);
-}
-/*
- * Nae recv
- */
-int nlm_hal_soc_recv(int dst_vc, unsigned int *intf, unsigned long long *phys_addr, unsigned int *flags)
-{
-	uint32_t size = 0, code = 0;
-	unsigned int rx_status = 0;
-	uint64_t data[4];
-	int len = 0;
-
-	*flags = NAE_RECV_NONE;
-
-	if(nlm_hal_recv_msg2(dst_vc, (uint32_t *) intf, &size, &code, &data[0], &data[1])) {
-
-		rx_status = xlp_read_rx_status();
-
-
-		if (!((rx_status >> 28) & (1 << dst_vc))) {
-			return -1;
-		}
-
-		return -2;
-	}
-
-	if (size == 2 && dst_vc == 0) {
-
-		/* Rx Packet
-		 */
-		*flags = NAE_RECV_RX;
-		*phys_addr = (data[1]) & 0xffffffffc0ULL;
-		len = (data[1] >> 40) & 0x3fff;
-	}
-	else if (size == 1 && dst_vc == 3) {
-
-		/* TxC Packet
-		 */
-
-		*flags = NAE_RECV_TXC;
-		*phys_addr = (data[0]);
-		len = 0;
-	}
-	else {
-
-		*flags = NAE_RECV_UNKNOWN;
-		*phys_addr = 0;
-		len = 0;
-	}
-
-	return len;
-}
-
-int nlm_hal_nae_recv(int rx_vc, unsigned long long *phys_addr, unsigned int *flags)
-{
-	unsigned int intf;
-	return nlm_hal_soc_recv(rx_vc, &intf, phys_addr, flags);
-}
-/*
- *  Ucore support
- */
-int nlm_hal_load_ucore(int ucore_mask, unsigned int *opcodes, int num_opcodes)
-{
-	int mask = ucore_mask & NAE_UCORE_MASK;
-	unsigned int id = 0;
-	int i;
-
-	while (id < MAX_NAE_UCORES) {
-
-		if ((mask & (1 << id)) == 0) {
-			id++;
-			continue;
-		}
-
-		for (i=0; i < num_opcodes; ++i) {
-			nlm_hal_write_ucode(id, (i * 4), opcodes[i]);
-		}
-		id++;
-	}
-	return 0;
-}
-
-/*
- *      MDIO Support
- */
-/* Internal MDIO READ/WRITE Routines
- */
-static int nae_int_gmac_mdio_read(int bus,int block, int intf_type, int phyaddr, int regidx)
-{
-	uint32_t mdio_ld_cmd = nlm_hal_read_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4);
-
-	if (mdio_ld_cmd & INT_MDIO_CTRL_CMD_LOAD) {
-		nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
-				       (mdio_ld_cmd & ~INT_MDIO_CTRL_CMD_LOAD));
-	}
-
-	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
-			       INT_MDIO_CTRL_SMP
-			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
-			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
-			       | (2 << INT_MDIO_CTRL_OP_POS)
-			       | (1 << INT_MDIO_CTRL_ST_POS)
-			       | (7 << INT_MDIO_CTRL_XDIV_POS)
-			       | (2 << INT_MDIO_CTRL_TA_POS)
-			       | (2 << INT_MDIO_CTRL_MIIM_POS)
-			       | (0 << INT_MDIO_CTRL_LOAD_POS)
-			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
-
-	/* Toggle Load Cmd Bit */
-	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
-			       INT_MDIO_CTRL_SMP
-			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
-			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
-			       | (2 << INT_MDIO_CTRL_OP_POS)
-			       | (1 << INT_MDIO_CTRL_ST_POS)
-			       | (7 << INT_MDIO_CTRL_XDIV_POS)
-			       | (2 << INT_MDIO_CTRL_TA_POS)
-			       | (2 << INT_MDIO_CTRL_MIIM_POS)
-			       | (1 << INT_MDIO_CTRL_LOAD_POS) /* */
-			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
-
-	/* poll master busy bit until it is not busy
-	 */
-	while(nlm_hal_read_mac_reg( block, intf_type,
-				    INT_MDIO_RD_STAT + bus * 4) & INT_MDIO_STAT_MBSY) {
-	}
-
-	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
-			       INT_MDIO_CTRL_SMP
-			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
-			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
-			       | (2 << INT_MDIO_CTRL_OP_POS)
-			       | (1 << INT_MDIO_CTRL_ST_POS)
-			       | (7 << INT_MDIO_CTRL_XDIV_POS)
-			       | (2 << INT_MDIO_CTRL_TA_POS)
-			       | (2 << INT_MDIO_CTRL_MIIM_POS)
-			       | (0 << INT_MDIO_CTRL_LOAD_POS)
-			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
-
-	/* Read the data back
-	 */
-	return nlm_hal_read_mac_reg( block, intf_type, INT_MDIO_RD_STAT + bus * 4);
-}
-
-/* Internal MDIO WRITE Routines
- */
-static int nae_int_gmac_mdio_write(int bus, int block, int intf_type, int phyaddr, int regidx, uint16_t val)
-{
-	uint32_t mdio_ld_cmd = nlm_hal_read_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4);
-
-	if (mdio_ld_cmd & INT_MDIO_CTRL_CMD_LOAD) {
-		nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
-				       (mdio_ld_cmd & ~INT_MDIO_CTRL_CMD_LOAD));
-	}
-
-	/* load data into ctrl data reg
-	 */
-	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL_DATA + bus * 4, val);
-
-	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
-			       INT_MDIO_CTRL_SMP
-			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
-			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
-			       | (1 << INT_MDIO_CTRL_OP_POS)
-			       | (1 << INT_MDIO_CTRL_ST_POS)
-			       | (7 << INT_MDIO_CTRL_XDIV_POS)
-			       | (2 << INT_MDIO_CTRL_TA_POS)
-			       | (1 << INT_MDIO_CTRL_MIIM_POS)
-			       | (0 << INT_MDIO_CTRL_LOAD_POS)
-			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
-
-	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
-			       INT_MDIO_CTRL_SMP
-			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
-			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
-			       | (1 << INT_MDIO_CTRL_OP_POS)
-			       | (1 << INT_MDIO_CTRL_ST_POS)
-			       | (7 << INT_MDIO_CTRL_XDIV_POS)
-			       | (2 << INT_MDIO_CTRL_TA_POS)
-			       | (1 << INT_MDIO_CTRL_MIIM_POS)
-			       | (1 << INT_MDIO_CTRL_LOAD_POS)
-			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
-
-	/* poll master busy bit until it is not busy
-	 */
-	while(nlm_hal_read_mac_reg( block, intf_type,
-				    INT_MDIO_RD_STAT + bus * 4) & INT_MDIO_STAT_MBSY) {
-	}
-
-	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
-			       INT_MDIO_CTRL_SMP
-			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
-			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
-			       | (1 << INT_MDIO_CTRL_OP_POS)
-			       | (1 << INT_MDIO_CTRL_ST_POS)
-			       | (7 << INT_MDIO_CTRL_XDIV_POS)
-			       | (2 << INT_MDIO_CTRL_TA_POS)
-			       | (1 << INT_MDIO_CTRL_MIIM_POS)
-			       | (0 << INT_MDIO_CTRL_LOAD_POS)
-			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
-
-	return 0;
-}
-
-static int int_nae_gmac_mdio_reset(int bus, int block, int intf_type)
-{
-	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
-			       INT_MDIO_CTRL_RST |
-			       (7 << INT_MDIO_CTRL_XDIV_POS) 	|
-			       (1 << INT_MDIO_CTRL_MCDIV_POS));
-
-	nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL + bus * 4,
-			       (7 << INT_MDIO_CTRL_XDIV_POS) 	|
-			       (1 << INT_MDIO_CTRL_MCDIV_POS));
-	return 0;
-}
-
-/**********************************************************************
- *  nae_gmac_mdio_read - Read sgmii phy register
- *
- *  Input parameters:
- *         bus          - bus number, nae has two external gmac bus: 0 and 1
- *         phyaddr      - PHY's address
- *         regidx       - index of register to read
- *
- *  Return value:
- *         value read (16 bits), or 0xffffffff if an error occurred.
- ********************************************************************* */
-static int nae_gmac_mdio_read(int bus,int block, int intf_type, int phyaddr, int regidx)
-{
-	uint32_t mdio_ld_cmd = nlm_hal_read_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4);
-
-	if (mdio_ld_cmd & EXT_G_MDIO_CMD_LCD) {
-		nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
-				       (mdio_ld_cmd & ~EXT_G_MDIO_CMD_LCD));
-		while(nlm_hal_read_mac_reg( block, intf_type,
-					    EXT_G0_MDIO_RD_STAT + bus * 4) & EXT_G_MDIO_STAT_MBSY);
-	}
-
-	//nlm_print("[%s/%d] SENDING READ COMMAND \n", __func__, __LINE__);
-
-	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
-			       EXT_G_MDIO_CMD_SP
-			       | (phyaddr << EXT_G_MDIO_PHYADDR_POS)
-			       | (regidx << EXT_G_MDIO_REGADDR_POS)
-			       | 0x00 | (0<<18) | (0x7<<2));
 
-	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
-			       EXT_G_MDIO_CMD_SP
-			       | (phyaddr << EXT_G_MDIO_PHYADDR_POS)
-			       | (regidx << EXT_G_MDIO_REGADDR_POS)
-			       | 0x00 | (1<<18) | (0x7<<2));
-
-	/* poll master busy bit until it is not busy */
-	while(nlm_hal_read_mac_reg( block, intf_type,
-				    EXT_G0_MDIO_RD_STAT + bus * 4) & EXT_G_MDIO_STAT_MBSY) {
-		//nlm_print("[%d] EXT_G_MDIO_STAT_MBSY is SET!\n", __LINE__);
-	}
-
-	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
-			       EXT_G_MDIO_CMD_SP
-			       | (phyaddr << EXT_G_MDIO_PHYADDR_POS)
-			       | (regidx << EXT_G_MDIO_REGADDR_POS)
-			       | 0x00 | (0<<18) | (0x7<<2));
-
-	//nlm_print("[%d] EXT_G_MDIO_STAT_MBSY CLEARED!\n", __LINE__);
-
-	/* Issue the read command */
-	//nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,(1));
-	//nlm_print("[%s/%d] READ RETURNING...\n", __func__, __LINE__);
-
-	/* Read the data back */
-	return nlm_hal_read_mac_reg( block, intf_type, EXT_G0_MDIO_RD_STAT + bus * 4);
-}
-
-/**********************************************************************
- *  nae_gmac_mdio_write -Write sgmac mii PHY register.
- *
- *  Input parameters:
- *         bus          - bus number, nae has two external gmac bus: 0 and 1
- *         phyaddr      - PHY to use
- *         regidx       - register within the PHY
- *         val          - data to write to register
- *
- *  Return value:
- *         0 - success
- ********************************************************************* */
-static int nae_gmac_mdio_write(int bus, int block, int intf_type, int phyaddr, int regidx, uint16_t val)
-{
-	uint32_t mdio_ld_cmd = nlm_hal_read_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4);
-
-	if (mdio_ld_cmd & EXT_G_MDIO_CMD_LCD) {
-		nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
-				       (mdio_ld_cmd & ~EXT_G_MDIO_CMD_LCD));
-		while(nlm_hal_read_mac_reg( block, intf_type,
-					    EXT_G0_MDIO_RD_STAT + bus * 4) & EXT_G_MDIO_STAT_MBSY);
-	}
-
-	/* load data into ctrl data reg
-	 */
-	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL_DATA + bus * 4, val);
-
-	//nlm_print("[%s/%d] SENDING WRITE COMMAND \n", __func__, __LINE__);
-
-	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
-			       EXT_G_MDIO_CMD_SP 	|
-			       (phyaddr << EXT_G_MDIO_PHYADDR_POS) 	|
-			       (regidx << EXT_G_MDIO_REGADDR_POS)		|
-			       0x00 | (0<<18) | (0x7<<2));
-
-	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
-			       EXT_G_MDIO_CMD_LCD | EXT_G_MDIO_CMD_SP 	|
-			       (phyaddr << EXT_G_MDIO_PHYADDR_POS) 	|
-			       (regidx << EXT_G_MDIO_REGADDR_POS)		|
-			       0x00 | (0<<18) | (0x7<<2));
-
-	/* poll master busy bit until it is not busy */
-	while(nlm_hal_read_mac_reg( block, intf_type,
-				    EXT_G0_MDIO_RD_STAT + bus * 4) & EXT_G_MDIO_STAT_MBSY);
-
-	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
-			       EXT_G_MDIO_CMD_SP 	|
-			       (phyaddr << EXT_G_MDIO_PHYADDR_POS) 	|
-			       (regidx << EXT_G_MDIO_REGADDR_POS)		|
-			       0x00 | (0<<18) | (0x7<<2));
-
-	//nlm_print("[%s/%d] WRITE RETURNING...\n", __func__, __LINE__);
-	return 0;
-}
-
-/**********************************************************************
- *  nae_gmac_mdio_reset -Reset sgmii mdio module.
- *
- *  Input parameters:
- *         bus - bus number, nae has two external gmac bus: 0 and 1
- *
- *  Return value:
- *        0 - success
- ********************************************************************* */
-static int nae_gmac_mdio_reset(int bus, int block, int intf_type)
-{
-	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
-			       EXT_G_MDIO_MMRST);
-	nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
-			       0);
-	return 0;
-}
-int nlm_hal_mdio_read(int type, int bus,int block, int intf_type,
-		      int phyaddr, int regidx)
-{
-	if (type == NLM_HAL_INT_MDIO) {
-		return nae_int_gmac_mdio_read(bus, block, intf_type,
-					      phyaddr, regidx);
-	} else if (type == NLM_HAL_EXT_MDIO) {
-		return nae_gmac_mdio_read(bus, block, intf_type,
-					  phyaddr, regidx);
-	} else {
-		nlm_print("NAE_ERROR: Invalid type for MDIO read !!\n");
-		return -1;
-	}
-}
-
-int nlm_hal_mdio_write(int type, int bus, int block, int intf_type,
-		       int phyaddr, int regidx, uint16_t val)
-{
-	if (type == NLM_HAL_INT_MDIO) {
-		return nae_int_gmac_mdio_write(bus, block, intf_type,
-					       phyaddr, regidx, val);
-	} else if (type == NLM_HAL_EXT_MDIO) {
-		return nae_gmac_mdio_write(bus, block, intf_type,
-					   phyaddr, regidx, val);
-	} else {
-		nlm_print("NAE_ERROR: Invalid type for MDIO write !!\n");
-		return -1;
-	}
-}
-
-int nlm_hal_mdio_reset(int type, int bus, int block, int intf_type)
+#ifdef PHY_DEBUG
+static void dump_phy_regs(int node, int inf)
 {
-	if (type == NLM_HAL_INT_MDIO) {
-		return int_nae_gmac_mdio_reset(bus, block, intf_type);
-
-	} else if (type == NLM_HAL_EXT_MDIO) {
-		return nae_gmac_mdio_reset(bus, block, intf_type);
-
-	} else {
-		nlm_print("NAE_ERROR: Invalid type for MDIO reset !!\n");
-		return -1;
+	nlm_nae_config_ptr nae_cfg = nlm_node_cfg.nae_cfg[node];
+	int j = 0;
+	for(;j<nae_cfg->num_ports;j++){
+		if(nae_cfg->ports[j].hw_port_id == inf)
+			break;
 	}
-}
-#if 0
-/**********************************************************************
- *  nae_xgmac_mdio_read - Read xgmac phy register
- *
- *  Input parameters:
- *         bus          - bus number, nae has two external xgmac bus: 0 and 1
- *         phyaddr      - PHY's address
- *         regidx       - index of register to read
- *
- *  Return value:
- *         value read (16 bits), or 0xffffffff if an error occurred.
- ********************************************************************* */
-static int nae_xgmac_mdio_read(int bus,int block, int intf_type, int phyaddr, int regidx)
-{
-
-        nlm_hal_write_mac_reg( block, intf_type, EXT_XG0_MDIO_CTRL + bus * 4,
-			       phyaddr<<EXT_XG_MDIO_CTRL_PHYADDR_POS
-			       | 1<<EXT_XG_MDIO_CTRL_MCDIV_POS
-			       | EXT_XG_MDIO_CTRL_CMD_LOAD
-			       | 1<<EXT_XG_MDIO_CTRL_MIIM_POS
-			       | 0x2<<EXT_XG_MDIO_CTRL_TA_POS
-			       | MDIO_OP_CMD_READ<<2);
-
-        /* poll master busy bit until it is not busy */
-        while(nlm_hal_read_mac_reg( block, intf_type,
-				    EXT_XG0_MDIO_RD_STAT + bus * 4) & EXT_XG_MDIO_STAT_MBSY);
-
-        return nlm_hal_read_mac_reg( block, intf_type,
-				     EXT_XG0_MDIO_CTRL_DATA + bus * 4) & 0xFFFF;
-}
-/**********************************************************************
- *  nae_xgmac_mdio_write -Write xgmac mii PHY register.
- *
- *  Input parameters:
- *         bus          - bus number, nae has two external xgmac bus: 0 and 1
- *         phyaddr      - PHY to use
- *         regidx       - register within the PHY
- *         val          - data to write to register
- *
- *  Return value:
- *         0 - success
- ********************************************************************* */
-static int nae_xgmac_mdio_write(int bus, int block, int intf_type, int phyaddr, int regidx, int16_t val)
-{
-        /* load data to INT_MDIO_CTRL_DATA register*/
-        nlm_hal_write_mac_reg( block, intf_type,
-			       EXT_XG0_MDIO_CTRL_DATA+ bus * 4, val);
-
-        nlm_hal_write_mac_reg( block, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
-			       phyaddr<<EXT_XG_MDIO_CTRL_PHYADDR_POS
-			       | 1<<EXT_XG_MDIO_CTRL_MCDIV_POS
-			       | EXT_XG_MDIO_CTRL_CMD_LOAD
-			       | 1<<EXT_XG_MDIO_CTRL_MIIM_POS
-			       | 0x2<<EXT_XG_MDIO_CTRL_TA_POS
-			       | MDIO_OP_CMD_WRITE<<2);
-
-        /* poll master busy bit until it is not busy */
-        while(nlm_hal_read_mac_reg( block, intf_type,
-				    EXT_XG0_MDIO_RD_STAT + bus * 4 )& EXT_XG_MDIO_STAT_MBSY);
-
-        return 0;
-}
-
-/**********************************************************************
- *  nae_xgmac_mdio_reset -Reset sgmii PHY.
- *
- *  Input parameters:
- *         bus - bus number, nae has two external xgmac bus: 0 and 1
- *
- *  Return value:
- *        0 - success
- ********************************************************************* */
-static int nae_xgmac_mdio_reset(int bus, int block, int intf_type)
-{
-        nlm_hal_write_mac_reg( block, intf_type,
-			       EXT_XG0_MDIO_CTRL + bus * 4,
-			       EXT_XG_MDIO_CTRL_RST);
-        return 0;
-}
 
-/**********************************************************************
- *  nae_gmac_internal_mdio_read - Read internal mdio phy bus
- *
- *  Input parameters:
- *         phyaddr      - PHY's address
- *         regidx       - index of register to read
- *
- *  Return value:
- *         value read (16 bits), or 0xffffffff if an error occurred.
- ********************************************************************* */
-static int nae_gmac_internal_mdio_read(int block, int intf_type, int phyaddr, int regidx)
-{
-
-        nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL,
-			       phyaddr<<INT_MDIO_CTRL_PHYADDR_POS
-			       | 1<<INT_MDIO_CTRL_MCDIV_POS
-			       |INT_MDIO_CTRL_CMD_LOAD
-			       | 1<<INT_MDIO_CTRL_MIIM_POS
-			       | 0x2<<INT_MDIO_CTRL_TA_POS
-			       | MDIO_OP_CMD_READ<<2);
-
-        /* poll master busy bit until it is not busy */
-        while(nlm_hal_read_mac_reg( block, intf_type,
-				    INT_MDIO_RD_STAT) & INT_MDIO_STAT_MBSY);
-
-        return nlm_hal_read_mac_reg( block, intf_type,INT_MDIO_CTRL_DATA) & 0xFFFF;
-}
-
-/**********************************************************************
- *  nae_gmac_internal_mdio_write -Write internal gmac mii PHY register.
- *
- *  Input parameters:
- *         phyaddr      - PHY to use
- *         regidx       - register within the PHY
- *         val          - data to write to register
- *
- *  Return value:
- *         0 - success
- ********************************************************************* */
-static int nae_gmac_internal_mdio_write(int block, int intf_type, int phyaddr, int regidx, int16_t val)
-{
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, nae_cfg->ports[j].phy_bus, BLOCK_7, LANE_CFG, nae_cfg->ports[j].phy_addr, 22, 0x0);
+	nlm_print("Page0 Control Reg %x\n",nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, nae_cfg->ports[j].phy_bus, BLOCK_7, LANE_CFG, nae_cfg->ports[j].phy_addr, 0));
+	nlm_print("Page0 Status Reg %x\n",nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, nae_cfg->ports[j].phy_bus, BLOCK_7, LANE_CFG, nae_cfg->ports[j].phy_addr, 1));
+        nlm_print("Page0 ExtStatus Reg %x\n",nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, nae_cfg->ports[j].phy_bus, BLOCK_7, LANE_CFG, nae_cfg->ports[j].phy_addr, 17));
 
-        /* load data to INT_MDIO_CTRL_DATA register*/
-        nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL_DATA, val);
-        nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL,
-			       phyaddr<<INT_MDIO_CTRL_PHYADDR_POS
-			       | 1<<INT_MDIO_CTRL_MCDIV_POS
-			       |INT_MDIO_CTRL_CMD_LOAD
-			       | 1<<INT_MDIO_CTRL_MIIM_POS
-			       | 0x2<<INT_MDIO_CTRL_TA_POS
-			       | MDIO_OP_CMD_WRITE<<2);
-
-        /* poll master busy bit until it is not busy */
-        while(nlm_hal_read_mac_reg( block, intf_type,
-				    INT_MDIO_RD_STAT) & INT_MDIO_STAT_MBSY);
-
-        return 0;
-}
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, nae_cfg->ports[j].phy_bus, BLOCK_7, LANE_CFG, nae_cfg->ports[j].phy_addr, 22, 0x2);
+	nlm_print("Page %x\n",nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, nae_cfg->ports[j].phy_bus, BLOCK_7, LANE_CFG, nae_cfg->ports[j].phy_addr, 22));
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, nae_cfg->ports[j].phy_bus, BLOCK_7, LANE_CFG, nae_cfg->ports[j].phy_addr, 22, 0x2);
 
-/**********************************************************************
- *  nae_gmac_internal_mdio_reset -Reset internal gmac PHY register.
- *
- *  Input parameters:
- *
- *  Return value:
- *        0 - success
- ********************************************************************* */
-static int nae_gmac_internal_mdio_reset(int block, int intf_type)
-{
-        nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL, INT_MDIO_CTRL_RST);
-        return 0;
+        nlm_print("Page2 Control Reg %x\n",nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, nae_cfg->ports[j].phy_bus, BLOCK_7, LANE_CFG, nae_cfg->ports[j].phy_addr, 0));
+        nlm_print("Page2 media Reg %x\n",nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, nae_cfg->ports[j].phy_bus, BLOCK_7, LANE_CFG, nae_cfg->ports[j].phy_addr, 10));
+	nlm_print("Page2 Reg26 (Bypass) %x\n",nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, nae_cfg->ports[j].phy_bus, BLOCK_7, LANE_CFG, nae_cfg->ports[j].phy_addr, 26));
+	nlm_print("Page2 SGMII sync %x\n",nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, nae_cfg->ports[j].phy_bus, BLOCK_7, LANE_CFG, nae_cfg->ports[j].phy_addr, 17));
+	
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, nae_cfg->ports[j].phy_bus, BLOCK_7, LANE_CFG, nae_cfg->ports[j].phy_addr, 22, 0x0);
 }
 #endif
 
-/**********************************************************************
- *  nae_lane_reset_txpll
- *
- ********************************************************************* */
-
-
-/* Some inputs from Kaushik */
-
-void nae_lane_reset_txpll(int block, int lane_ctrl)
+/**
+* @brief nlm_hal_init_ext_phy function initializes the external PHY of an interface.
+*
+* @param [in] node Node number
+* @param [in] inf Interface number
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+void nlm_hal_init_ext_phy(int node, int inf)
 {
-	uint32_t val = 0, saved_data;
-	int rext_sel = 0;
-
-	if (lane_ctrl != 4) {
-		int i;
-		rext_sel = (1 << 23);
-
-		val = nlm_hal_read_mac_reg( block, PHY, lane_ctrl);
-		val &= ~PHY_LANE_CTRL_RST; /* Set the reset (inverse logic) */
-		val |= rext_sel;
-
-		/* Resetting PMA for non-zero lanes */
-		nlm_hal_write_mac_reg( block, PHY, lane_ctrl,val);
-
-		for (i=0; i< 0x100000; ++i)
-			; /* empty loop */
-
-		val |= PHY_LANE_CTRL_RST; /* Unset the reset (inverse logic) */
-		nlm_hal_write_mac_reg( block, PHY, lane_ctrl,val);
-
-		val = 0;
-	}
-
-	/* Come out of reset for TXPLL */
-#if 0
-	saved_data = nlm_hal_read_mac_reg( block, PHY, lane_ctrl) & 0xFFC00000;
-#else
-	saved_data = nlm_hal_read_mac_reg( block, PHY, lane_ctrl) & 0xFFC00000;
-#endif
-
-	nlm_hal_write_mac_reg( block, PHY, lane_ctrl,         (0x66 << PHY_LANE_CTRL_ADDR_POS)
-			       | PHY_LANE_CTRL_CMD_READ
-			       | PHY_LANE_CTRL_CMD_START
-			       | PHY_LANE_CTRL_RST
-			       | rext_sel
-			       | val );
-	while (((val = nlm_hal_read_mac_reg( block, PHY, lane_ctrl)) & PHY_LANE_CTRL_CMD_PENDING));
-	val &= 0xFF;
-
-	/* set bit[4] to 0
-	 */
-	val &= ~(1 << 4);
-	nlm_hal_write_mac_reg( block, PHY, lane_ctrl,   (0x66 << PHY_LANE_CTRL_ADDR_POS)
-			       | PHY_LANE_CTRL_CMD_WRITE
-			       | PHY_LANE_CTRL_CMD_START
-			       | (0x0 << 19) /* (0x4 << 19) */
-			       | rext_sel
-			       | saved_data
-			       | val );
-	/* re-do */
-	nlm_hal_write_mac_reg( block, PHY, lane_ctrl,   (0x66 << PHY_LANE_CTRL_ADDR_POS)
-			       | PHY_LANE_CTRL_CMD_WRITE
-			       | PHY_LANE_CTRL_CMD_START
-			       | (0x0 << 19) /* (0x4 << 19) */
-			       | rext_sel
-			       | saved_data
-			       | val );
-
-	while(!((val = nlm_hal_read_mac_reg( block, PHY, lane_ctrl-PHY_LANE_0_CTRL)) & PHY_LANE_STAT_PCR));
-
-	/* Clear the Power Down bit */
-	val = nlm_hal_read_mac_reg( block, PHY, lane_ctrl);
-	val &= ~( (1 << 29) | (0x7ffff));
-	nlm_hal_write_mac_reg( block, PHY, lane_ctrl, (rext_sel | val));
-
+	struct nlm_hal_ext_phy *this_phy=NULL;
+	this_phy = get_phy_info(inf);
+	if(!this_phy)
+		return;
+	this_phy->ext_phy_init(this_phy, node);
+	return;
+}
 
+/**
+* @brief bcm_init_phy function initializes an external BROADCOM PHY.
+*
+* @param [in] phy nlm_hal_ext_phy struct pointing to the BROADCOM PHY
+* @param [in] node Node number
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+static void bcm_init_phy(struct nlm_hal_ext_phy *phy, int node)
+{
+	int bus = phy->ext_mdio_bus;
+	int phyaddr = phy->phy_addr;
+	int int_inf = phy->inf;
+	int status=0;
+	nlm_print("BCM_INIT_PHY \n ");
+	
+	nlm_hal_mdio_write(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf, 0x04, 0x01); // selector field
+	nlm_hal_mdio_write(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf, 0x00, 0); // disable XLP AN
+	nlm_hal_mdio_write(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf, 0x00, 0x8000); // soft reset
+
+	/*switch to 1000Base-X registers mode*/
+	/*refer mode control register in broadcom datasheet*/
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr,  0x1c, 0x7c00);
+	status = nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x1C);
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr,  0x1c, (status | (1<<15)| (0x1)));
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr,  0x0, 0x100 ); /*Disable AN*/
+	
+	status = nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr,  0x0);	
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr,  0x0, status | (1<<12) ); /*Enable AN on SGMMII side of PHY*/
+	status = nlm_hal_mdio_read(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf,  0x0);	
+	nlm_hal_mdio_write(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf, 0x00, status|(1<<12)); // Enable XLP AN
+	return;
 }
 
-/*
-  cplx configuration needed to be parsed from fdt tree and set at the time
-  before xlp_nae_config_lane_gmac can be called
+/**
+* @brief mvl_init_phy function initializes an external MARVELL PHY.
+*
+* @param [in] phy nlm_hal_ext_phy struct pointing to the MARVELL PHY
+* @param [in] node Node number
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+static void mvl_init_phy(struct nlm_hal_ext_phy *phy, int node)
+{
+	int bus = phy->ext_mdio_bus;
+	int phyaddr = phy->phy_addr;
+	int int_inf = phy->inf;
+
+	// device initialization
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 22, 0x02);
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 16, 0x0288);
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 22, 0x8000);
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x00, 0x8000);
+
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 22, 0x02); // page 2
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 26, 0x8000); // AN bypass enable
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0, 0); // Disable MAC side AN
+
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 22, 0x00); // page 0
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0, 0xb000); // Enable AN, Soft reset
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0, 0x9140); // Enable AN, Soft reset
+
+	nlm_hal_mdio_write(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf, 0x04, 0x01); // selector field
+	nlm_hal_mdio_write(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf, 0x00, 0x4000); // disable XLP AN
+	nlm_hal_mdio_write(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf, 0x00, 0x8000); // soft reset
+}
+
+/**
+* @brief nlm_hal_ext_phy_an function enables auto-negotiation on an interface.
+*
+* @param [in] node Node number
+* @param [in] inf Interface on which to enable auto-negotiation
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
 */
-/**********************************************************************
- *  nae_config_lane_gmac
- *
- ********************************************************************* */
-static void xlp_nae_config_lane_gmac(int cplx_mask)
+void nlm_hal_ext_phy_an(int node, int inf)
+{
+	struct nlm_hal_ext_phy *this_phy=NULL;
+	this_phy = get_phy_info(inf);
+	if(!this_phy)
+		return;
+	this_phy->start_phy_an(this_phy, node);
+	return;	
+}
+
+/**
+* @brief bcm_start_an function enables auto-negotiation on an external BROADCOM PHY.
+*
+* @param [in] phy nlm_hal_ext_phy struct pointing to the BROADCOM PHY
+* @param [in] node Node number
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+static void bcm_start_an(struct nlm_hal_ext_phy *phy, int node)
 {
-	int block, lane_ctrl;
-	int cplx_lane_enable = LM_SGMII | (LM_SGMII << 4) | (LM_SGMII << 8) | (LM_SGMII << 12);
-	int lane_enable = 0;
-
-	/*  Lane mode progamming
-	 */
-	block = 7;
-	/* Complexes 0, 1 */
-	if (cplx_mask & 0x1) {
-		lane_enable |= cplx_lane_enable;
-	}
-	if (cplx_mask & 0x2) {
-		lane_enable |= (cplx_lane_enable << 16);
-	}
-	if (lane_enable) {
-		nlm_hal_write_mac_reg( block, LANE_CFG, LANE_CFG_CPLX_0_1,  lane_enable);
-		lane_enable = 0;
-	}
-	/* Complexes 2 3 */
-	if (cplx_mask & 0x4) {
-		lane_enable |= cplx_lane_enable;
-	}
-	if (cplx_mask & 0x8) {
-		lane_enable |= (cplx_lane_enable << 16);
-	}
-	nlm_hal_write_mac_reg( block, LANE_CFG, LANE_CFG_CPLX_2_3,   lane_enable);
+	int status, count;
+	int phyaddr = phy->phy_addr;
+	int bus = phy->ext_mdio_bus;
+	int int_inf = phy->inf;
 
-	/* Always enable complex 4 */
-	nlm_hal_write_mac_reg( block, LANE_CFG, LANE_CFG_CPLX_4, LM_SGMII << 4
-			       |  LM_SGMII );
-
-	/* serdes lane progaming
-	 */
-	for( block = 0; block < 4; block++)
-	{
-		if ((cplx_mask & (1 << block)) == 0) {
-			continue;
+	/*switch to Copper registers mode*/
+	/*refer mode control register in broadcom datasheet*/
+	nlm_print("Starting auto-negotiation on port %d, external mdio bus %d, phy address %d\n", phy->inf,  bus, phyaddr);
+#if 0
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x1C, 0x7c00);
+	status = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x1C);
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x1C, ((status | (1<<15)) & ~1) );
+	status = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x0);
+	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x0, status|(1<<9));
+	count=0;
+        do {
+		nlm_mdelay(100);
+		count++;
+		status = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x1);
+		if(status & (1<<5)){ /* check for autonegotiation to be completed */
+			nlm_print("Autonegotiation is OK for phyaddr=0x%x \n", phyaddr);
+			break;	
 		}
-		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_0_CTRL,  PHY_LANE_CTRL_RST
-				       | PHY_LANE_CTRL_PWRDOWN
-				       | (2 << PHY_LANE_CTRL_PHYMODE_POS));
-
-		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_1_CTRL,  PHY_LANE_CTRL_RST
-				       | PHY_LANE_CTRL_PWRDOWN
-				       | (2 << PHY_LANE_CTRL_PHYMODE_POS));
-
-		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_2_CTRL,  PHY_LANE_CTRL_RST
-				       | PHY_LANE_CTRL_PWRDOWN
-				       | (2 << PHY_LANE_CTRL_PHYMODE_POS));
-
-		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_3_CTRL,  PHY_LANE_CTRL_RST
-				       | PHY_LANE_CTRL_PWRDOWN
-				       | (2 << PHY_LANE_CTRL_PHYMODE_POS));
-
+		status = -1;
+        }while(count<50);
+	
+	if(status<0){
+		nlm_print("Autonegotiation is NOT OK for phyaddr=0x%x \n", phyaddr);
+		return;
 	}
-	/* Always config complex 4 */
-	block = 4;
-	nlm_hal_write_mac_reg( block, PHY, PHY_LANE_0_CTRL,  PHY_LANE_CTRL_RST
-			       | PHY_LANE_CTRL_PWRDOWN
-			       | (2 << PHY_LANE_CTRL_PHYMODE_POS));
+#endif
 
-	nlm_hal_write_mac_reg( block, PHY, PHY_LANE_1_CTRL,  PHY_LANE_CTRL_RST
-			       | PHY_LANE_CTRL_PWRDOWN
-			       | (2 << PHY_LANE_CTRL_PHYMODE_POS));
 
-	for( block = 0; block < 4; block++)
-	{
-		if ((cplx_mask & (1 << block)) == 0) {
-			continue;
+	/*switch to 1000Base-X registers mode*/
+	//nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr,  0x1c, 0x7c00);
+	//status = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x1C);
+	//nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr,  0x1c, (status | (1<<15)| (0x1)));
+	//status = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr,  0x0);	
+	//nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr,  0x0, status|(1<<9)); /*Restart AN on SGMMII side of PHY*/
+	//nlm_mdelay(1000);
+	status = nlm_hal_mdio_read(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf,  0x0);	
+	nlm_hal_mdio_write(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf, 0x00, status|(1<<9)); // Restart XLP AN
+	/*Wait for XLP<->SGMII-PHY AN to be OK*/
+	count=0;
+        do {
+		nlm_mdelay(100);
+		count++;
+		status = nlm_hal_mdio_read(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf, 0x1);
+		if(status & (1<<5)){ /* check for autonegotiation to be completed */
+			nlm_print("Autonegotiation is OK with PHY-SGMII =0x%x \n", int_inf);	
+			return;
 		}
+		status = nlm_hal_mdio_read(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf,  0x0);	
+		nlm_hal_mdio_write(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf, 0x00, status|(1<<9)); // Restart XLP AN
+        }while(count<100);
 
-		for( lane_ctrl = PHY_LANE_0_CTRL; lane_ctrl <= PHY_LANE_3_CTRL; lane_ctrl++)
-			nae_lane_reset_txpll( block, lane_ctrl);
-	}
-	/* Always do this for Complex 4*/
-	block = 4;
-	for( lane_ctrl = PHY_LANE_0_CTRL; lane_ctrl <= PHY_LANE_1_CTRL; lane_ctrl++)
-		nae_lane_reset_txpll( block, lane_ctrl);
-
+	nlm_print("Autonegotiation is NOT OK for PHY-SGMII inf=0x%x int_inf =0x%x\n", phyaddr, int_inf);
 	return;
 }
 
-
-void nlm_hal_mac_disable(int inf, int type)
-{
-        unsigned int mac_cfg1 = 0, xaui_cfg = 0;
-        unsigned int netwk_inf = 0;
-
-	switch(type) {
-		case SGMII_IF:
-			mac_cfg1 = read_gmac_reg(inf, MAC_CONF1);
-		        write_gmac_reg(inf , MAC_CONF1, mac_cfg1 & ~(0x5));
-              		netwk_inf = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
-              		write_gmac_reg(inf ,NETWK_INF_CTRL_REG, netwk_inf &  (~(TX_EN(1))));
-			break;
-		case XAUI_IF:
-			xaui_cfg=nlm_hal_read_mac_reg(inf, XGMAC, XAUI_CONFIG_1);
-			nlm_hal_write_mac_reg(inf, XGMAC, XAUI_CONFIG_1, xaui_cfg &
-                                                        (~(XAUI_CONFIG_TFEN | XAUI_CONFIG_RFEN)));
-			break;
-		case INTERLAKEN_IF:
-			break;
-	}
-}
-
-void nlm_hal_mac_enable(int inf, int type)
-{
-        unsigned int mac_cfg1 = 0, xaui_cfg = 0;
-        unsigned int netwk_inf = 0;
-
-        switch(type) {
-                case SGMII_IF:
-			netwk_inf  = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
-		        write_gmac_reg(inf , NETWK_INF_CTRL_REG, netwk_inf | TX_EN(1));
-        		mac_cfg1 = read_gmac_reg(inf, MAC_CONF1);
-        		write_gmac_reg(inf , MAC_CONF1, mac_cfg1 | (0x5));
-                        break;
-                case XAUI_IF:
-			xaui_cfg=nlm_hal_read_mac_reg(inf, XGMAC, XAUI_CONFIG_1);
-	                nlm_hal_write_mac_reg(inf, XGMAC, XAUI_CONFIG_1, xaui_cfg |
-							XAUI_CONFIG_TFEN | XAUI_CONFIG_RFEN );                              
-
-                        break;
-                case INTERLAKEN_IF:
-                        break;
-        }
-}
-
-#ifdef MARVELL_PHY_DEBUG
-static void dump_phy_regs(int inf)
-{
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x0);
-	nlm_print("Page0 Control Reg %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0));
-	nlm_print("Page0 Status Reg %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 1));
-        nlm_print("Page0 ExtStatus Reg %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 17));
-
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x2);
-	nlm_print("Page %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22));
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x2);
-
-        nlm_print("Page2 Control Reg %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0));
-        nlm_print("Page2 media Reg %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 10));
-	nlm_print("Page2 Reg26 (Bypass) %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 26));
-	nlm_print("Page2 SGMII sync %x\n",nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 17));
-
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x0);
-}
-#endif
-
-void nlm_hal_init_ext_phy(int inf)
-{
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x02);
-	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 16, 0x0288);
-
-	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x8000);
-	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0x00, 0x8000);
-	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0x04, 0x01);
-
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22,0x00);
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0, 0x1000);
-
-	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0x00, 0);
-
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x02);
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 26, 0x8000);
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0, 0);
-
-	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0x00, 0);
-
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0x00);
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0, 0xb000);
-
-	nlm_hal_mdio_write(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0x00, 0x8000);
-}
-
-void nlm_hal_ext_phy_an(int inf)
+/**
+* @brief mvl_start_an function enables auto-negotiation on an external MARVELL PHY.
+*
+* @param [in] phy nlm_hal_ext_phy struct pointing to the MARVELL PHY
+* @param [in] node Node number
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+static void mvl_start_an(struct nlm_hal_ext_phy *phy, int node)
 {
         uint32_t i=0;
         volatile uint16_t val, status, extstatus;
-        uint16_t speed, duplex = 0;
+#ifdef PHY_DEBUG
+        uint16_t speed, duplex = 0; 
+#endif
+	int phyaddr = phy->phy_addr;
+	int bus = phy->ext_mdio_bus;
 
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0);
-        val = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0);
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 22, 0);
+        val = nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0);
         val |= 0x1200;
-        nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 0, val);
-
-	nlm_print("Starting auto-negotiation on port %d\n",inf);
+        nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0, val);
 
+#ifdef PHY_DEBUG
+	nlm_print("Starting auto-negotiation on port %d, external mdio bus %d, phy address %d\n", phy->inf,  bus, phyaddr);
+#endif
 	i=0;
         do {
 		nlm_mdelay(100);
-                status = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 1);
-                extstatus = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 17);
+                status = nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 1);
+                extstatus = nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 17);
 		if (((status & 0x0024) == 0x0024) && (extstatus & 0x0400))
 			break;
 		i++;
         }while(i<50);
+		nlm_mdelay(1000);
 
-        extstatus = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 17);
-        speed = (extstatus >> 14) & 0x3;
-        duplex =  (extstatus >> 13) & 0x1;
 
-#ifdef MARVELL_PHY_DEBUG
+#ifdef PHY_DEBUG
         switch(speed) {
                 case SPEED_10M:
                         nlm_print("physpeed 10 Mbps\t");
@@ -1945,83 +1168,296 @@ void nlm_hal_ext_phy_an(int inf)
                         nlm_print("unknown speed !!! \t");
         }
         ((duplex == 1) ? nlm_print("Full duplex\n"):nlm_print("Half duplex\n"));
-	dump_phy_regs(inf);
+	//dump_phy_regs(inf);
 #endif
 }
 
-int nlm_hal_get_phy_status(int inf, uint32_t *speed, uint32_t *duplex)
+/**
+* @brief bcm_get_phy_status function returns the status of an interface from the external BROADCOM PHY.
+*
+* @param [in] phy nlm_hal_ext_phy struct pointing to the BROADCOM PHY
+* @param [out] speed Link speed
+* @param [out] duplex Link duplex status
+* @param [in] node Node number
+*
+* @return
+* 	- 1 - Link up, 0 - Link Down
+* 
+* @ingroup hal_nae
+*
+*/
+static int bcm_get_phy_status(struct nlm_hal_ext_phy *phy, uint32_t *speed, uint32_t *duplex, int node)
+{
+	int aux_status=0;
+	int status=0;
+	int phyaddr = phy->phy_addr;
+	int bus = phy->ext_mdio_bus;
+	//int int_inf = phy->inf;
+
+	bcm_start_an(phy, node);
+	
+	/*switch to Copper registers mode*/
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x1C, 0x7c00);
+	status = nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x1C);
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x1C, ((status | (1<<15)) & ~1) );
+	aux_status = nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x19);
+	switch ((aux_status>>8) & 0x7){
+		case 0x7:
+			*speed = SPEED_1000M;
+			*duplex = 1;
+		break;
+		
+		case 0x6: 		 
+			*speed = SPEED_1000M;
+			*duplex = 0;
+		break;
+		
+		case 0x5: 		 
+			*speed = SPEED_100M;
+			*duplex = 1;
+		break;
+		
+		case 0x3: 		 
+			*speed = SPEED_100M;
+			*duplex = 0;
+		break;
+		
+		case 0x2: 		 
+			*speed = SPEED_10M;
+			*duplex = 1;
+		break;
+		
+		case 0x1: 		 
+			*speed = SPEED_10M;
+			*duplex = 0;
+		break;
+		
+		default:
+			nlm_print("Unknown operating speed\n");	
+		break;
+	}	
+
+//#ifdef PHY_DEBUG
+	if(*speed==SPEED_1000M)	
+		nlm_print("Configured with Speed  1000M");
+	if(*speed==SPEED_100M)	
+		nlm_print("Configured with Speed 100M");
+	if(*speed==SPEED_10M)	
+		nlm_print("Configured with Speed 10M");
+        
+	((*duplex == 1) ? nlm_print("Full duplex\n"):nlm_print("Half duplex\n"));
+//#endif
+	status = nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 0x1);
+	if(status & (1<<2)){
+		//nlm_print("Link is up : %x\n", status);
+		return 1;
+	}else{
+		//nlm_print("Link is down : %x\n", status);
+		return 0;
+	}
+}
+
+/**
+* @brief mvl_get_phy_status function returns the status of an interface from the external MARVELL PHY.
+*
+* @param [in] phy nlm_hal_ext_phy struct pointing to the MARVELL PHY
+* @param [out] speed Link speed
+* @param [out] duplex Link duplex status
+* @param [in] node Node number
+*
+* @return
+* 	- 1 - Link up, 0 - Link Down
+* 
+* @ingroup hal_nae
+*
+*/
+static int mvl_get_phy_status(struct nlm_hal_ext_phy *phy, uint32_t *speed, uint32_t *duplex, int node)
 {
 	uint16_t extstatus;
-
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 22, 0);
-        extstatus = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 17);
+	int phyaddr = phy->phy_addr;
+	int bus = phy->ext_mdio_bus;
+	
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 22, 0);
+        extstatus = nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr, 17);
         *speed = (extstatus >> 14) & 0x3;
         *duplex =  (extstatus >> 13) & 0x1;
 	if (extstatus & 0x0400) {
-	//	nlm_print("Link is up : %x\n",extstatus);
+		nlm_print("Link is up : %x\n",extstatus);
 		return 1;
 	}
 	else {
-	//	nlm_print("Link is down : %x\n",extstatus);
+		nlm_print("Link is down : %x\n",extstatus);
 		return 0;
 	}
-
-}
-
-void nlm_hal_config_sgmii_if(int inf)
-{
-	unsigned int mac_cfg1 = 0, mac_cfg2 = 0;
-	unsigned int netwk_inf = 0;
-	unsigned int ifmode, speed, duplex;
-
-	// Disable TX , Rx for now
-	mac_cfg1 = read_gmac_reg(inf, MAC_CONF1);
-	write_gmac_reg(inf , MAC_CONF1, mac_cfg1 & ~(0x5));
-	netwk_inf = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
-	write_gmac_reg(inf ,NETWK_INF_CTRL_REG, netwk_inf &  (~(1<<2)));
-
-#ifndef XLP_SIM
-	// Enable auto negotiation on PHY side
-	nlm_hal_ext_phy_an(inf);
-
-	// Read PHY status from extended status
-	nlm_hal_get_phy_status(inf,&speed, &duplex);
-
+	
+}
+
+/**
+* @brief get_phy_info function returns PHY information from the external PHY of an interface.
+*
+* @param [in] inf Interface number
+*
+* @return
+* 	- Pointer to external phy information structure
+* 	- NULL if no registered external phy exists for inf
+* 
+* @ingroup hal_nae
+*
+*/
+struct nlm_hal_ext_phy* get_phy_info(int inf)
+{
+	struct nlm_hal_ext_phy *phy_info = NULL;
+	/*search through scanned and registered phys*/
+	int reg_idx=0;
+	for(; reg_idx<MAX_PHYS; reg_idx++){
+		if(regs_ext_phys[reg_idx].inf==inf){
+			phy_info = regs_ext_phys + reg_idx;
+			return phy_info;
+		}
+	}
+	nlm_print("Interface could not be initialised for inf=0x%x\n", inf);
+	return NULL;
+}
+
+/**
+* @brief register_phy function registers external PHY information for an interface.
+*
+* @param [in] node Node number
+* @param [in] inf Interface number
+* @param [out] hw_portid PHY address of the external PHY attached to inf
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+void register_phy(int node, int inf, int* hw_portid)
+{
+	nlm_nae_config_ptr nae_cfg = nlm_node_cfg.nae_cfg[node];
+	int i = 0;
+	int phy_addr, ext_mdio_bus;
+	for(i=0; nae_cfg->num_ports; i++){
+		if(nae_cfg->ports[i].hw_port_id == inf)
+		break;
+	}
+#ifdef CONFIG_N511
+        // Hardcode here for now, rather than generating a new dts/dtb
+        if (inf == 0x10) {
+          // override dtb
+          nae_cfg->ports[i].ext_phy_addr = 0x10;
+          nae_cfg->ports[i].ext_phy_bus = 0;
+        }
+        if (inf == 0x11) {
+          // override dtb
+          nae_cfg->ports[i].ext_phy_addr = 0x10;
+          nae_cfg->ports[i].ext_phy_bus = 1;
+        }
+#endif
+	phy_addr = nae_cfg->ports[i].ext_phy_addr;
+	ext_mdio_bus = nae_cfg->ports[i].ext_phy_bus;
+	nlm_print("register_phy with inf=0x%x phy_addr=0%x ext_mdio_bus=0x%x\n", inf, phy_addr, ext_mdio_bus);
+
+	*hw_portid = phy_addr;
+	/* make a inf and hw_port id pair*/
+	for(i=0; i<reg_num_phys; i++){
+		if((*hw_portid) == regs_ext_phys[i].phy_addr){
+#ifdef CONFIG_N511
+                    if (ext_mdio_bus ==  regs_ext_phys[i].ext_mdio_bus) {
+                        regs_ext_phys[i].inf = inf;
+                        return;
+                    }
 #else
-	speed = SPEED_1000M;
-	duplex = 1;
+			regs_ext_phys[i].inf = inf;
+			return;
 #endif
-	ifmode = ((speed == SPEED_1000M) ? INF_BYTE_MODE : INF_NIBBLE_MODE);
-
-	// Configure negotiated speed and mode
-        netwk_inf  = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
-        netwk_inf &= (~(0x3));
-	write_gmac_reg(inf , NETWK_INF_CTRL_REG, netwk_inf | SPEED(speed));
-
-        mac_cfg2 = read_gmac_reg(inf, MAC_CONF2);
-        mac_cfg2 &= (~(0x3 << 8));
-	write_gmac_reg(inf , MAC_CONF2,
-			       mac_cfg2            |
-			       INF_IFMODE(ifmode)     |
-			       INF_FULLDUP(duplex));
-
-        netwk_inf  = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
-        write_gmac_reg(inf , NETWK_INF_CTRL_REG, netwk_inf | (1<<15));
-
-        mac_cfg1 = read_gmac_reg(inf, MAC_CONF1);
-        write_gmac_reg(inf , MAC_CONF1, mac_cfg1 | (0x3 << 4));
+		}	
+	}
+	*hw_portid = -1;
+	nlm_print("Could not find the given interface\n");
+}
+
+/**
+* @brief sgmii_scan_phys function scans all possibel PHYs on the external MDIO busses and logs active ports.
+*
+* @param [in] node Node number
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+void sgmii_scan_phys(int node)
+{
+	int phyid, inf;
+	int j;
+	int reg_idx=0;
+	
+	/*init regs_ext_phys data*/
+	for (j=0; j<MAX_PHYS; j++){
+		regs_ext_phys[j].phy_get_status =  NULL;
+		regs_ext_phys[j].start_phy_an =  NULL;
+		regs_ext_phys[j].ext_phy_init =  NULL;
+		regs_ext_phys[j].phy_addr = 0xff;	
+		regs_ext_phys[j].inf = -1;
+	}
+	/* scan all PHYs available on both ext MDIOs */
+	/* check with phys IDs against registered phys */
+
+	/*BUS1*/
+	if(!is_nlm_xlp3xx()){ /*Only one mdio controller on Storm*/
+		nlm_print("Scanning MDIO external BUS1----\n");
+		for(inf=0; inf<31; inf++){
+			phyid = nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, 1, BLOCK_7, LANE_CFG, inf, 3);
+			for(j=0; j < sizeof(known_ext_phys)/ sizeof(struct nlm_hal_ext_phy); j++){
+				if(phyid == known_ext_phys[j].phy_idfer){
+					regs_ext_phys[reg_idx].ext_mdio_bus = 1;
+					regs_ext_phys[reg_idx].phy_get_status =  known_ext_phys[j].phy_get_status;
+					regs_ext_phys[reg_idx].start_phy_an =  known_ext_phys[j].start_phy_an;
+					regs_ext_phys[reg_idx].ext_phy_init =  known_ext_phys[j].ext_phy_init;
+					regs_ext_phys[reg_idx].phy_addr = inf;	
+					regs_ext_phys[reg_idx].inf = -1;	
+					nlm_print("Found port with 1st bus and phy_addr =0x%x phy-idfer =0x%x\n ", regs_ext_phys[reg_idx].phy_addr, phyid);
+					reg_idx++;
+				}
+			}
+		
+		}
+	}
+	nlm_print("Scanning MDIO external BUS0----\n");
+	/*BUS0*/
+	for(inf=0; inf<31; inf++){
+		phyid = nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, inf, 3);
+		for(j=0; j < sizeof(known_ext_phys)/ sizeof(struct nlm_hal_ext_phy); j++){
+			if(phyid == known_ext_phys[j].phy_idfer){
+				
+				regs_ext_phys[reg_idx].ext_mdio_bus = 0;
+				regs_ext_phys[reg_idx].phy_get_status =  known_ext_phys[j].phy_get_status;
+				regs_ext_phys[reg_idx].start_phy_an =  known_ext_phys[j].start_phy_an;
+				regs_ext_phys[reg_idx].ext_phy_init =  known_ext_phys[j].ext_phy_init;
+				regs_ext_phys[reg_idx].phy_addr = inf;	
+				regs_ext_phys[reg_idx].inf = -1;	
+				nlm_print("Found port with 0th bus and phy_addr =0x%x phy-idfer=0x%x\n ", regs_ext_phys[reg_idx].phy_addr, phyid);
+				reg_idx++;
+			}
+		}
+		
+	}
+	
+	reg_num_phys =  reg_idx;
+	nlm_print("Total PHYs found = %d\n", reg_idx);
 }
 
-void nlm_hal_sgmii_pcs_init(int sgmii_cplx_mask)
-{
-        nlm_hal_mdio_reset(NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG);
-        nlm_print("Net:   Reset Internal MDIO\n");
-        nlm_hal_mdio_reset(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG);
-        nlm_print("Net:   Reset External MDIO\n");
-	xlp_nae_config_lane_gmac(sgmii_cplx_mask);
-	nlm_print("Net:   Completed PCS Configuration\n");
-}
 
+/**
+* @brief nlm_hal_dtr_init function is used to enable DTR block on XLP.
+*
+* @return : none
+*
+* @ingroup hal
+*
+*/
 void nlm_hal_dtr_init(void)
 {
     uint64_t base = nlm_hal_get_dev_base (XLP_DTR_NODE, XLP_DTR_BUS, XLP_DTR_DEVICE, XLP_DTR_FUNC);
@@ -2033,264 +1469,251 @@ void nlm_hal_dtr_init(void)
     nlm_hal_write_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_2, 0x3fe);
     nlm_hal_write_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_3, 0x3fe);
 #ifdef DUMP
-    printf ("Base Register 0x%llx\n", (unsigned long long)base);
-    printf ("Master control 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_MASTER_CONTROL_REG));
-    printf ("Channel control0 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_0));
-    printf ("Channel control1 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_1));
-    printf ("Channel control2 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_2));
-    printf ("Channel control3 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_3));
+    nlm_print ("Base Register 0x%llx\n", (unsigned long long)base);
+    nlm_print ("Master control 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_MASTER_CONTROL_REG));
+    nlm_print ("Channel control0 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_0));
+    nlm_print ("Channel control1 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_1));
+    nlm_print ("Channel control2 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_2));
+    nlm_print ("Channel control3 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_3));
 #endif
 }
 
 /* SAE SUPPORT
  */
-void nlm_hal_set_sae_freq(int freq)
+/**
+* @brief nlm_hal_set_sae_freq function sets the frequency of the SAE block.
+*
+* @param [in] node Node number
+* @param [in] freq Frequency to set in MHz
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_sae
+*
+*/
+void nlm_hal_set_sae_freq(int node, int freq)
 {
-	int cnt, data, i;
-	unsigned int spr, spf;
+	const uint64_t mhz = 1000000;
+	uint64_t set_freq = nlm_hal_set_soc_freq(0, DFS_DEVICE_SAE, freq * mhz);
 
-	data = 0x2;   // sae dfs decrement
-	if(freq == 500)
-		cnt = 4; // Need to compute this properly
-	else
-		cnt = 2;
+#ifdef NLM_HAL_LINUX_KERNEL
+    do_div(set_freq, mhz);
+#else
+    set_freq /= mhz;
+#endif
+	nlm_print("SAE Frequency set to %lluMHz\n", set_freq);
+}
 
-	for(i=0;i<cnt;i++){
-		nlm_hal_write_sys_reg(SYS_DFS_DIV_DEC_CTRL, data);
-	}
+void nlm_hal_set_rsa_freq(int node, int freq)
+{
+	const uint64_t mhz = 1000000;
+	uint64_t set_freq = nlm_hal_set_soc_freq(0, DFS_DEVICE_RSA, freq * mhz);
 
-	data = nlm_hal_read_sys_reg(PLL_CTRL);
-	spf = data >> 3 & 0x7f;
-	spr = data >> 1  & 0x3;
+#ifdef NLM_HAL_LINUX_KERNEL
+    do_div(set_freq, mhz);
+#else
+    set_freq /= mhz;
+#endif
 
-	data = (nlm_hal_read_sys_reg(SYS_DFS_DIV_VALUE0) >> 4)  & 0xf;
-	nlm_print("SAE Frequency set to %dMHz (2X frequency %dMHz) \n",
-		  (int) DFS_OUTPUT(spr, spf, data) ,
-		  (int) DFS_OUTPUT(spr, spf, data) * 2);
+	nlm_print("RSA Frequency set to %lluMHz\n", set_freq);
 }
 
-static __inline__ uint64_t
-gen_cntl_instr(struct nlm_crypto_cipher_init_param *cip,
-	       struct nlm_crypto_auth_init_param *aip)
+
+void nlm_hal_set_sae_engine_sel(void ) 
 {
-	uint64_t cntl_desc = 0;
-	if (aip) {
-		cntl_desc |= (unsigned long long) aip->hmac << 61;
-		cntl_desc |= (unsigned long long) aip->auth_alg << 52;
-		cntl_desc |= (unsigned long long) aip->auth_mode << 43;
-	}
-	if (cip) {
-		cntl_desc |= (unsigned long long) cip->cipher_alg << 34;
-		cntl_desc |= (unsigned long long) cip->cipher_mode << 25;
-		cntl_desc |=
-		    (unsigned long long) cip->arc4_cipher_key_len << 18;
-		cntl_desc |= (unsigned long long) cip->arc4_key_init << 17;
-		cntl_desc |= (unsigned long long) cip->cfb_mask;
-	}
-	return cntl_desc;
+	int i, n;
+#define NLM_SAE_ENGINE_SELECT_REG_0 0x41
+	if(is_nlm_xlp3xx())
+		n = 1;
+	else
+		n = 8;
+    for (i = 0; i < n; i++) {
+        nlm_hal_write_sae_reg(NLM_SAE_ENGINE_SELECT_REG_0 + i, 0x00FFFFFF);	
+    }
 }
 
-int
-nlm_hal_crypto_preprocess_request(void *cntrl_desc,
-				  struct nlm_crypto_cipher_init_param *cip,
-				  struct nlm_crypto_auth_init_param *aip)
+void nlm_hal_set_rsa_engine_sel(void) 
 {
-	uint64_t *ptr = (uint64_t *) cntrl_desc;
-	unsigned char *temp_ptr = (unsigned char *) cntrl_desc;
-
-	ptr[0] = gen_cntl_instr(cip, aip);
-
-	temp_ptr += 8;
-
-	if (cip) {
-		if (cip->cipher_key) {
-			memcpy(temp_ptr, cip->cipher_key->buf,
-			       cip->cipher_key->iov_len);
-			temp_ptr += cip->cipher_key->iov_len;
-		}
+	int i, n;
+	unsigned int val;
+#define NLM_RSA_ENGINE_SELECT_REG_0 0x41
+	if(is_nlm_xlp3xx()) {
+		n = 1;
+		val = 0xffff;
+	} else {
+		n = 3;
+		val = 0x7ffffff;
 	}
-	if (aip) {
-		if (aip->auth_key) {
-			memcpy(temp_ptr, aip->auth_key->buf,
-			       aip->auth_key->iov_len);
+    for (i = 0; i < n; i++) {
+        nlm_hal_write_rsa_reg(NLM_RSA_ENGINE_SELECT_REG_0 + i, val);	
+    }
+}
 
-		}
+void nlm_hal_get_crypto_vc_nums(int *vcbase, int *vclimit)
+{
+
+	if(is_nlm_xlp3xx()) {
+		*vcbase = XLP_3XX_CRYPTO_VC_BASE;
+		*vclimit = XLP_3XX_CRYPTO_VC_LIMIT;
+	} else {
+		*vcbase = XLP_CRYPTO_VC_BASE;
+		*vclimit = XLP_CRYPTO_VC_LIMIT;
 	}
-	return 0;
 }
 
-uint64_t
-gen_pkt_desc_0(struct nlm_crypto_param * cprm)
+void nlm_hal_get_rsa_vc_nums(int *vcbase, int *vclimit)
 {
-	uint64_t pkt = 0;
-
-	cprm->iv_len = (cprm->iv_len) ? (cprm->iv_len - 1) : 0;
-	pkt |= (unsigned long long) cprm->tls_proto << 63;
-	pkt |= (unsigned long long) cprm->hash_source << 62;
-	pkt |= (unsigned long long) cprm->hash_output_l3_alloc << 60;
-	pkt |= (unsigned long long) cprm->enc << 59;
-	pkt |= (unsigned long long) cprm->iv_len << 41;
-	pkt |= (unsigned long long) cprm->hash_dst_address_phy;
+	if(is_nlm_xlp3xx()) {
+		*vcbase  = XLP_3XX_RSA_ECC_VC_BASE;
+		*vclimit = XLP_3XX_RSA_ECC_VC_LIMIT;
+	} else {
+		*vcbase = XLP_RSA_ECC_VC_BASE;
+		*vclimit = XLP_RSA_ECC_VC_LIMIT;
 
-	return pkt;
+	}
 }
 
-uint64_t
-gen_pkt_desc_1(struct nlm_crypto_param * cprm)
+void  nlm_hal_sata_firmware_init(void) 
 {
-	uint64_t pkt = 0;
+	volatile uint32_t readdata, i;
 
-	cprm->cipher_len = (cprm->cipher_len) ? (cprm->cipher_len - 1) : 0;
-	cprm->auth_len = (cprm->auth_len) ? (cprm->auth_len - 1) : 0;
+	nlm_print(" Started AHCI Firmware Initialization.\n");
 
-	pkt |= (unsigned long long) cprm->cipher_len << 32;
-	pkt |= (unsigned long long) cprm->auth_len;
+	nlm_mdelay(1000);
 
-	return pkt;
-}
+	readdata = rd_sata_glue_reg(SATA_CTL);
 
-uint64_t
-gen_pkt_desc_2(struct nlm_crypto_param * cprm)
-{
-	uint64_t pkt = 0;
+	nlm_print ("Reseting PHYs.\n");
+	clear_sata_glue_reg(SATA_CTL, SATA_RST_N);
+	clear_sata_glue_reg(SATA_CTL, PHY3_RESET_N);
+	clear_sata_glue_reg(SATA_CTL, PHY2_RESET_N);
+	clear_sata_glue_reg(SATA_CTL, PHY1_RESET_N);
+	clear_sata_glue_reg(SATA_CTL, PHY0_RESET_N);
+	readdata = rd_sata_glue_reg(SATA_CTL);
+	nlm_mdelay(10);
 
-	pkt |= (unsigned long long) cprm->iv_offset << 45;
-	pkt |= (unsigned long long) cprm->cipher_bit_count << 42;
-	pkt |= (unsigned long long) cprm->cipher_offset << 22;
-	pkt |= (unsigned long long) cprm->hash_bit_count << 19;
-	pkt |= (unsigned long long) cprm->hash_clobber << 18;
-	pkt |= (unsigned long long) cprm->auth_offset;
+	set_sata_glue_reg(SATA_CTL, SATA_RST_N);
+	set_sata_glue_reg(SATA_CTL, PHY3_RESET_N);
+	set_sata_glue_reg(SATA_CTL, PHY2_RESET_N);
+	set_sata_glue_reg(SATA_CTL, PHY1_RESET_N);
+	set_sata_glue_reg(SATA_CTL, PHY0_RESET_N);
 
-	return pkt;
-}
+	readdata = rd_sata_glue_reg(SATA_CTL);
+	wr_sata_glue_reg(SATA_CTL, readdata);
+	readdata = rd_sata_glue_reg(SATA_CTL);
 
-uint64_t
-gen_pkt_desc_3(struct nlm_crypto_param * cprm)
-{
-	uint64_t pkt = 0;
+	nlm_print ("Waiting for PHYs to come up.\n");
+
+	i=0;
+	readdata = rd_sata_glue_reg(SATA_STATUS);
+	while ( ((readdata & 0x00F0) != 0x00F0) && (i < 30))
+	{
+		readdata = rd_sata_glue_reg(SATA_STATUS);
+		nlm_mdelay(10);
+		i++;
+	}
+
+	if (readdata  & P0_PHY_READY) nlm_print(" PHY0 is up.\n");
+	else nlm_print(" PHY0 is down.\n");
+	if (readdata  & P1_PHY_READY) nlm_print(" PHY1 is up.\n");
+	else nlm_print(" PHY1 is down.\n");
+	if (readdata  & P2_PHY_READY) nlm_print(" PHY2 is up.\n");
+	else nlm_print(" PHY2 is down.\n");
+	if (readdata  & P3_PHY_READY) nlm_print(" PHY3 is up.\n");
+	else nlm_print(" PHY3 is down.\n");
 
-	pkt |= (unsigned long long) cprm->designer_freeback_id << 48;
-	pkt |= (unsigned long long) cprm->tag_len << 11;
-	pkt |= (unsigned long long) cprm->arc4_save_l3_alloc << 8;
-	pkt |= (unsigned long long) cprm->arc4_save_state << 6;
-	pkt |= (unsigned long long) cprm->hmac_external_pad_key << 5;
+	nlm_print(" AHCI Firmware Init  Done.\n");
 
-	return pkt;
 }
 
-uint64_t
-gen_pkt_desc_4(struct nlm_crypto_param * cprm, uint32_t index)
+void nlm_hal_sata_intr_setup(void)
 {
-	uint64_t pkt = 0;
+	uint32_t val;
 
-	pkt |= (unsigned long long) (cprm->src_phy[index].iov_len - 1) << 48;
-	pkt |= (unsigned long) cprm->src_phy[index].buf;
+	/* clear pending interrupts and then enable them */
+	val = rd_sata_glue_reg(SATA_INT);
+	nlm_mdelay(10);
+	wr_sata_glue_reg(SATA_INT, val);
+	nlm_mdelay(10);
 
-	return pkt;
+	val = rd_sata_glue_reg(SATA_INT_MASK);
+	nlm_mdelay(10);
+	wr_sata_glue_reg(SATA_INT_MASK, (val | 0xffffffff ));
 }
 
-uint64_t
-gen_pkt_desc_5(struct nlm_crypto_param * cprm, uint32_t index)
+void nlm_hal_sata_intr_ack(void)
 {
-	uint64_t pkt = 0;
+	uint32_t val = 0;
 
-	pkt |= (unsigned long long) (cprm->dst_phy[index].iov_len - 1) << 48;
-	pkt |= (unsigned long long) cprm->cipher_output_l3_alloc << 46;
-	pkt |= (unsigned long long) cprm->cipher_clobber << 41;
-	pkt |= (unsigned long) cprm->dst_phy[index].buf;
-
-	return pkt;
+	val = rd_sata_glue_reg(SATA_INT);
+	nlm_mdelay(10);
+	wr_sata_glue_reg(SATA_INT, val);
 }
 
-/* Return error when parameter are invalid */
-int
-nlm_hal_crypto_send_request(uint32_t dst_vc, uint32_t fb_id,
-			    void *cntrl_desc, uint64_t cntrl_desc_phy,
-			    void *pkt_desc, uint64_t pkt_desc_phy,
-			    struct nlm_crypto_param *cprm, uint64_t tx_id)
+void nlm_hal_sata_init(void)
 {
-	uint32_t i = 0, j = 0, pkt_desc_len = 0;
-	uint64_t *ptr = (uint64_t *) pkt_desc, entry0 = 0, entry1 = 0;
+	nlm_hal_sata_firmware_init();
+}
 
-	ptr[0] = gen_pkt_desc_0(cprm);
-	ptr[1] = gen_pkt_desc_1(cprm);
-	ptr[2] = gen_pkt_desc_2(cprm);
-	ptr[3] = gen_pkt_desc_3(cprm);
+#define NUM_VCS_PER_CPU 4
 
-	while (i < cprm->nr_frags) {
-		ptr[4 + 2 * i] = gen_pkt_desc_4(cprm, i);
-		ptr[4 + 2 * i + 1] = gen_pkt_desc_5(cprm, i);
-		i++;
-	}
-	i = 4 + cprm->nr_frags * 2;
+#define NUM_DISTVEC_CELLS 	16
+#define MIN_DIST_VEC 0
+#define MAX_DIST_VEC 16
 
-	while (j < cprm->designer_freeback_len)
-		ptr[i++] = cprm->designer_fb[j];
+#define NUM_DISTVEC_CPUMASKS 4
 
-	entry0 |= (unsigned long long) fb_id << 48;
-	if (cprm->send_designer_fb) {
-		entry0 |=
-		    (unsigned long long) cprm->designer_freeback_len << 46;
-		entry0 |= (unsigned long long) cprm->send_designer_fb << 48;
-		pkt_desc_len = 4;	/* Initialize for pakt desc length */
-	}
-	entry0 |= (unsigned long long) (cprm->cipher_key_len >> 3) << 40;
-	entry0 |= (unsigned long long) (cntrl_desc_phy >> 6);
+#define POE_DIST_VEC0 0x100
 
-	pkt_desc_len += (4 + 2 * cprm->nr_frags);
-	pkt_desc_len = (pkt_desc_len / 2) - 1;
+void cpu_hotplug_fixup_poe(int cpu, int flag)
+{
+	unsigned long mflags = 0;
+	int reg_index;
+	uint32_t value, vcmask;
+	int cell, offset, vc = 0;
+	uint32_t distvec[NUM_DISTVEC_CELLS];
+	int node = cpu/32;
+	nlm_nae_config_ptr nae_cfg = nlm_node_cfg.nae_cfg[node];
 
-	entry1 |= (unsigned long long) cprm->arc4_load_state << 63;
-	entry1 |= (unsigned long long) (cprm->auth_key_len >> 3) << 56;
-	entry1 |= (unsigned long long) pkt_desc_len << 43;
-	entry1 |= (unsigned long long) (pkt_desc_phy >> 6);
+	vcmask =  (1 << nae_cfg->rx_vc);
+	vc = (cpu * NUM_VCS_PER_CPU) % (NUM_DISTVEC_CELLS * 32);
+	cell = vc / 32;
 
-	nlm_hal_send_msg3(dst_vc, 0 /*code */ , entry0, entry1, tx_id);
+	reg_index = POE_DIST_VEC0 + (NUM_DISTVEC_CELLS - 1 - cell);
 
-	return 0;
-}
+	/* do we need to ensure nobody is operating on msgrng? */
+	msgrng_access_enable(mflags);
+	if (flag) {
+		/* online */
+		offset = vc % 32;
+		value = vcmask << offset;
 
-/* Returns 64 bit transaction ID */
-uint64_t
-nlm_hal_crypto_process_response(uint32_t rx_vc, uint32_t code,
-				uint32_t src, uint64_t entry0,
-				uint64_t entry1, uint64_t * err_msg)
-{
-	*err_msg = entry1;
-	return entry0;
+		distvec[cell] |= value;
+		nlm_hal_write_poe_pcim_reg(node,reg_index, value);
+	} else {
+		/* offline */
+		nlm_hal_write_poe_pcim_reg(node,reg_index, 0);
+	}
+	msgrng_access_disable(mflags);
 }
 
-uint64_t
-nlm_hal_crypto_receive_response(uint32_t rx_vc, uint64_t * err_msg)
-{
-	uint32_t size, code, src;
-	uint64_t entry0 = 0, entry1 = 0;
-
-	nlm_hal_recv_msg2(rx_vc, &src, &size, &code, &entry0, &entry1);
-
-	return nlm_hal_crypto_process_response(rx_vc, code, src, entry0, entry1,
-					       err_msg);
-}
 #ifdef NLM_HAL_LINUX_KERNEL
 #include <linux/types.h>
 #include <linux/module.h>
-EXPORT_SYMBOL(nlm_hal_open_if);
-EXPORT_SYMBOL(naecfg_hack);
 EXPORT_SYMBOL(nlm_hal_is_xlp_a0);
 EXPORT_SYMBOL(nlm_hal_is_xlp_le);
-EXPORT_SYMBOL(nlm_hal_init_if_regs);
-EXPORT_SYMBOL(nlm_hal_init_nae_regs);
-EXPORT_SYMBOL(nlm_hal_load_ucore);
-EXPORT_SYMBOL(nlm_hal_sgmii_pcs_init);
-EXPORT_SYMBOL(nlm_hal_init_poe_regs);
-EXPORT_SYMBOL(nlm_hal_init_poe_distvec);
-EXPORT_SYMBOL(nlm_hal_crypto_preprocess_request);
-EXPORT_SYMBOL(nlm_hal_crypto_send_request);
-EXPORT_SYMBOL(nlm_hal_crypto_process_response);
-EXPORT_SYMBOL(nlm_hal_crypto_receive_response);
-EXPORT_SYMBOL(nlm_hal_get_phy_status);
-EXPORT_SYMBOL(nlm_hal_mdio_read);
-EXPORT_SYMBOL(nlm_hal_mdio_write);
-EXPORT_SYMBOL(nlm_hal_mac_enable);
-EXPORT_SYMBOL(nlm_hal_mac_disable);
+EXPORT_SYMBOL(sgmii_scan_phys);
+EXPORT_SYMBOL(nlm_hal_get_dev_base);
+EXPORT_SYMBOL(nlm_hal_set_sae_freq);
+EXPORT_SYMBOL(nlm_hal_set_rsa_freq);
+EXPORT_SYMBOL(nlm_hal_set_sae_engine_sel);
+EXPORT_SYMBOL(nlm_hal_set_rsa_engine_sel);
+EXPORT_SYMBOL(nlm_hal_get_crypto_vc_nums);
+EXPORT_SYMBOL(nlm_hal_get_rsa_vc_nums);
+EXPORT_SYMBOL(nlm_node_cfg);
+
+EXPORT_SYMBOL(nlm_hal_init_ext_phy);
+EXPORT_SYMBOL(nlm_hal_ext_phy_an);
+EXPORT_SYMBOL(register_phy);
 #endif
diff --git a/arch/mips/netlogic/common/nlm_hal_cpu_info.c b/arch/mips/netlogic/common/nlm_hal_cpu_info.c
new file mode 100644
index 0000000..b0c855f
--- /dev/null
+++ b/arch/mips/netlogic/common/nlm_hal_cpu_info.c
@@ -0,0 +1,516 @@
+#include "nlm_hal.h"
+#include "nlm_hal_macros.h"
+#include "nlm_hal_xlp_dev.h"
+
+
+static inline int bitcount(unsigned int n)                          
+{
+  register unsigned int tmp;
+    
+  tmp = n - ((n >> 1) & 033333333333)
+            - ((n >> 2) & 011111111111);
+  return ((tmp + (tmp >> 3)) & 030707070707) % 63;
+}
+
+
+__inline__ uint32_t efuse_cfg0(void)
+{
+	return  nlm_hal_read_32bit_reg((((KSEG1 + 0x18000000 + 0x35000) & 0x1fffffff) + 0x100), (EFUSE_DEVICE_CFG0));
+}
+
+ __inline__ uint32_t efuse_cfg1(void)
+{
+	return nlm_hal_read_32bit_reg((((KSEG1 + 0x18000000 + 0x35000) & 0x1fffffff) + 0x100), (EFUSE_DEVICE_CFG1));
+}
+
+__inline__ uint32_t efuse_cfg6(void)
+{
+	return nlm_hal_read_32bit_reg((((KSEG1 + 0x18000000 + 0x35000) & 0x1fffffff) + 0x100), (EFUSE_DEVICE_CFG6));
+}
+
+__inline__ uint32_t get_proc_id(void)
+{
+	uint32_t cpuid= efuse_cfg6() & EFUSE_CFG6_CPUID_MASK;
+	if(!cpuid){ /*May be its Non fused part.*/
+		return CHIP_PROCESSOR_ID_XLP_8_4_XX; /*Default to CHIP_PROCESSOR_ID_XLP_8_4_XX */
+	}
+	return cpuid;
+}
+
+__inline__ int is_nlm_rev_a0(void)
+{
+	return ((nlm_read_prid() & 0xff) == XLP_REVISION_A0);
+}
+
+ __inline__ int is_nlm_rev_a1(void)
+{
+	return ((nlm_read_prid() & 0xff) == XLP_REVISION_A1);
+}
+
+__inline__ int is_nlm_rev_a2(void)
+{
+	return ((nlm_read_prid() & 0xff) == XLP_REVISION_A2);
+}
+
+__inline__ int is_nlm_rev_b0(void)
+{
+	return ((nlm_read_prid() & 0xff) == XLP_REVISION_B0);
+}
+
+extern char *strcat(char *dest, const char *src);
+static  void get_cpu_rev(int *revid, char *rev)
+{
+	if(is_nlm_rev_a0()){
+		*revid = XLP_REVISION_A0;
+		strcat(rev, " Rev A0");
+	} 
+	if(is_nlm_rev_a1()){
+		*revid = XLP_REVISION_A1;
+		strcat(rev, " Rev A1"); 
+	} 
+	if(is_nlm_rev_a2()){
+		*revid = XLP_REVISION_A2;
+		strcat(rev, " Rev A2"); 
+	} 
+	if(is_nlm_rev_b0()){
+		*revid = XLP_REVISION_B0;
+		strcat(rev, " Rev B0"); 
+	} 
+	return;
+}
+
+static __inline__ int is_nlm_xlp_8_4_x(void)
+{
+	return (get_proc_id() == CHIP_PROCESSOR_ID_XLP_8_4_XX);
+}
+
+__inline__ int is_nlm_xlp832_b0(void)
+{
+	if(is_nlm_xlp_8_4_x() && is_nlm_rev_b0()){
+		unsigned int cfg0 =  efuse_cfg0() & 0xff; /*last 8 bits*/
+		unsigned int cfg1 =  efuse_cfg1() & 0x7; /*last 3 bits*/
+		
+		if( (bitcount(cfg0)==0) && (cfg1!=0x7) ){
+			return 1;
+		}
+	}
+	return 0;
+}
+
+__inline__ int is_nlm_xlp432_b0(void)
+{
+	if(is_nlm_xlp_8_4_x() && is_nlm_rev_b0()){
+		unsigned int cfg0 =  efuse_cfg0() & 0xff; /*last 8 bits*/
+		unsigned int cfg1 =  efuse_cfg1() & 0x7; /*last 3 bits*/
+		
+		if( (bitcount(cfg0)==0) && (cfg1==0x7) ){
+			return 1;
+		}
+	}
+	return 0;
+}
+
+__inline__ int is_nlm_xlp824_b0(void)
+{
+	if(is_nlm_xlp_8_4_x() && is_nlm_rev_b0()){
+		unsigned int cfg0 =  efuse_cfg0() & 0xff; /*last 8 bits*/
+		unsigned int cfg1 =  efuse_cfg1() & 0x7; /*last 3 bits*/
+		
+		if( (bitcount(cfg0)==2) && (cfg1!=0x7) ){
+			return 1;
+		}
+	}
+	return 0;
+}
+
+__inline__ int is_nlm_xlp424_b0(void)
+{
+	if(is_nlm_xlp_8_4_x() && is_nlm_rev_b0()){
+		unsigned int cfg0 =  efuse_cfg0() & 0xff; /*last 8 bits*/
+		unsigned int cfg1 =  efuse_cfg1() & 0x7; /*last 3 bits*/
+		
+		if( (bitcount(cfg0)==2) && (cfg1==0x7) ){
+			return 1;
+		}
+	}
+	return 0;
+}
+
+__inline__ int is_nlm_xlp816_b0(void)
+{
+	if(is_nlm_xlp_8_4_x() && is_nlm_rev_b0()){
+		unsigned int cfg0 =  efuse_cfg0() & 0xff; /*last 8 bits*/
+		unsigned int cfg1 =  efuse_cfg1() & 0x7; /*last 3 bits*/
+		
+		if( (bitcount(cfg0)==4) && (cfg1!=0x7) ){
+			return 1;
+		}
+	}
+	return 0;
+}
+
+__inline__ int is_nlm_xlp416_b0(void)
+{
+	if(is_nlm_xlp_8_4_x() && is_nlm_rev_b0()){
+		unsigned int cfg0 =  efuse_cfg0() & 0xff; /*last 8 bits*/
+		unsigned int cfg1 =  efuse_cfg1() & 0x7; /*last 3 bits*/
+		
+		if( (bitcount(cfg0)==4) && (cfg1==0x7) ){
+			return 1;
+		}
+	}
+	return 0;
+}
+
+__inline__ int is_nlm_xlp832_ax(void)
+{
+	return ( ((get_proc_id() == CHIP_PROCESSOR_ID_XLP_8XX) || is_nlm_xlp_8_4_x()) 
+		); //XLP832 A2 has same cpu id as B0 /
+}
+
+
+__inline__ int is_nlm_xlp432_ax(void)
+{
+	return (get_proc_id() == CHIP_PROCESSOR_ID_XLP_432);
+}
+
+__inline__ int is_nlm_xlp816_ax(void)
+{
+	return (get_proc_id() == CHIP_PROCESSOR_ID_XLP_816);
+}
+
+__inline__ int is_nlm_xlp416_ax(void)
+{
+	return (get_proc_id() == CHIP_PROCESSOR_ID_XLP_416);
+}
+
+__inline__ int is_nlm_xlp408_ax(void)
+{
+	return (get_proc_id() == CHIP_PROCESSOR_ID_XLP_408);
+}
+
+__inline__ int is_nlm_xlp208_ax(void)
+{
+	return (get_proc_id() == CHIP_PROCESSOR_ID_XLP_208);
+}
+
+__inline__ int is_nlm_xlp204_ax(void)
+{
+	return (get_proc_id() == CHIP_PROCESSOR_ID_XLP_204);
+}
+
+__inline__ int is_nlm_xlp104_ax(void)
+{
+	return (get_proc_id() == CHIP_PROCESSOR_ID_XLP_104);
+}
+
+/*high level APIs*/
+__inline__ int is_nlm_xlp8xx(void)
+{
+	if(is_nlm_xlp_8_4_x()
+	        || is_nlm_xlp832_ax()
+		|| is_nlm_xlp432_ax()
+		|| is_nlm_xlp816_ax()
+		|| is_nlm_xlp416_ax()
+		|| is_nlm_xlp408_ax()
+		|| is_nlm_xlp208_ax()
+		|| is_nlm_xlp204_ax()
+		|| is_nlm_xlp104_ax() ){
+			return 1;
+		}
+	return 0;
+}
+
+__inline__ int is_nlm_xlp8xx_ax(void)
+{
+	if(is_nlm_xlp832_ax()
+		|| is_nlm_xlp432_ax()
+		|| is_nlm_xlp816_ax()
+		|| is_nlm_xlp416_ax()
+		|| is_nlm_xlp408_ax()
+		|| is_nlm_xlp208_ax()
+		|| is_nlm_xlp204_ax()
+		|| is_nlm_xlp104_ax() ){
+			return 1;
+		}
+	return 0;
+}
+
+__inline__ int is_nlm_xlp8xx_b0(void)
+{
+	return (is_nlm_xlp_8_4_x() && is_nlm_rev_b0());
+}
+
+__inline__ int is_nlm_xlp3xx(void)
+{
+	return (get_proc_id() == CHIP_PROCESSOR_ID_XLP_3XX);
+}
+
+__inline__ int is_nlm_xlp3xx_a1(void)
+{
+	return (is_nlm_xlp3xx() && is_nlm_rev_a1());
+}
+
+__inline__ int is_nlm_xlp3xx_a0(void)
+{
+	return (is_nlm_xlp3xx() && is_nlm_rev_a0());
+}
+
+__inline__ void get_xlp3xx_extpid(char *extpid)
+{
+	unsigned int cfg0_extpid= (efuse_cfg0()>> 4) & 0xf; /*4-7 bits*/
+	if(cfg0_extpid==CPU_EXTPID_XLP_3XX_NONE){
+		strcat(extpid, "");
+		return;
+	}
+	if(cfg0_extpid==CPU_EXTPID_XLP_3XX_L){
+		strcat(extpid, " Lite");
+		return;
+	}
+	if(cfg0_extpid==CPU_EXTPID_XLP_3XX_LP){
+		strcat(extpid, " Lite+");
+		return;
+	}
+	if(cfg0_extpid==CPU_EXTPID_XLP_3XX_LP2){
+		strcat(extpid, " Lite+2");
+		return;
+	}
+	strcat(extpid, " Unknown");
+	return;
+}
+
+__inline__ int is_nlm_xlp3xx_lite(void)
+{
+	unsigned int cfg0_extpid = (efuse_cfg0()>> 4) & 0xf; /*4-7 bits*/
+
+	return (is_nlm_xlp3xx() && (cfg0_extpid != 0));
+}
+
+__inline__ int is_nlm_xlp316_a0(void)
+{
+	if(is_nlm_xlp3xx_a0()){
+		unsigned int cfg0 =  efuse_cfg0() & 0xf; /*last 4 bits*/
+		if( (bitcount(cfg0)==0)){
+			return 1;
+		}
+	}
+	return 0;
+}
+
+__inline__ int is_nlm_xlp316_a1(void)
+{
+	if(is_nlm_xlp3xx_a1()){
+		unsigned int cfg0 =  efuse_cfg0() & 0xf; /*last 4 bits*/
+		if( (bitcount(cfg0)==0)){
+			return 1;
+		}
+	}
+	return 0;
+	return (is_nlm_xlp316_a0());
+}
+
+__inline__ int is_nlm_xlp316(void)
+{
+	return(is_nlm_xlp316_a0() | is_nlm_xlp316_a1());
+}
+
+__inline__ int is_nlm_xlp308_a0(void)
+{
+	if(is_nlm_xlp3xx_a0()){
+		unsigned int cfg0 =  efuse_cfg0() & 0xf; /*last 4 bits*/
+		if( (bitcount(cfg0)==2)){
+			return 1;
+		}
+	}
+	return 0;
+}
+
+__inline__ int is_nlm_xlp308_a1(void)
+{
+	if(is_nlm_xlp3xx_a1()){
+		unsigned int cfg0 =  efuse_cfg0() & 0xf; /*last 4 bits*/
+		if( (bitcount(cfg0)==2)){
+			return 1;
+		}
+	}
+	return 0;
+}
+
+__inline__ int is_nlm_xlp308(void)
+{
+	return(is_nlm_xlp308_a0() | is_nlm_xlp308_a1());
+}
+
+__inline__ int is_nlm_xlp304_a0(void)
+{
+	if(is_nlm_xlp3xx_a0()){
+		unsigned int cfg0 =  efuse_cfg0() & 0xf; /*last 4 bits*/
+		if( (bitcount(cfg0)==3)){
+			return 1;
+		}
+	}
+	return 0;
+}
+
+__inline__ int is_nlm_xlp304_a1(void)
+{
+	if(is_nlm_xlp3xx_a1()){
+		unsigned int cfg0 =  efuse_cfg0() & 0xf; /*last 4 bits*/
+		if( (bitcount(cfg0)==3)){
+			return 1;
+		}
+	}
+	return 0;
+}
+
+__inline__ int is_nlm_xlp304(void)
+{
+	return(is_nlm_xlp304_a0() | is_nlm_xlp304_a1());
+}
+
+/*Check for XLP-CPU */
+__inline__ int is_nlm_xlpxxx(void)
+{
+	return (is_nlm_xlp8xx()||is_nlm_xlp3xx());
+}
+
+/**
+ * Fill the nlm_netl_proc_info using nlm cpu apis.
+ *
+ * @param[in,out] prid		: ptr to nlm_netl_proc_info
+ * Do not call this function if just cpu type has to be validated use
+ * cpu id apis instead.
+ * @return
+ * 1 on success, 0 on failure
+ * @ingroup	hal
+ */
+int  nlm_hal_get_cpuinfo(struct nlm_netl_proc_info* cpu_info)
+{
+	if(is_nlm_xlp8xx()){
+		strcpy(cpu_info->cpu_info_str, "XLP");
+		if(is_nlm_xlp832_b0()){
+			strcat(cpu_info->cpu_info_str, "832 Rev B0");
+			cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_8_4_XX;
+			cpu_info->revision= XLP_REVISION_B0;
+			return 1;
+		}
+		if(is_nlm_xlp824_b0()){
+			strcat(cpu_info->cpu_info_str, "824 Rev B0");
+			cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_8_4_XX;
+			cpu_info->revision= XLP_REVISION_B0;
+			return 1;
+		}
+		if(is_nlm_xlp816_b0()){
+			strcat(cpu_info->cpu_info_str, "816 Rev B0");
+			cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_8_4_XX;
+			cpu_info->revision= XLP_REVISION_B0;
+			return 1;
+		}
+		if(is_nlm_xlp432_b0()){
+			strcat(cpu_info->cpu_info_str, "432 Rev B0");
+			cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_8_4_XX;
+			cpu_info->revision= XLP_REVISION_B0;
+			return 1;
+		}
+		if(is_nlm_xlp424_b0()){
+			strcat(cpu_info->cpu_info_str, "424 Rev B0");
+			cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_8_4_XX;
+			cpu_info->revision= XLP_REVISION_B0;
+			return 1;
+		}
+		if(is_nlm_xlp416_b0()){
+			strcat(cpu_info->cpu_info_str, "416 Rev B0");
+			cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_8_4_XX;
+			cpu_info->revision= XLP_REVISION_B0;
+			return 1;
+		}
+		if(is_nlm_xlp832_ax()){
+			strcat(cpu_info->cpu_info_str, "832");
+			get_cpu_rev(&cpu_info->revision, cpu_info->cpu_info_str);
+			return 1;
+		}
+		if(is_nlm_xlp816_ax()){
+			strcat(cpu_info->cpu_info_str, "816");
+			cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_816;
+			get_cpu_rev(&cpu_info->revision, cpu_info->cpu_info_str);
+			return 1;
+		}
+		if(is_nlm_xlp432_ax()){
+			strcat(cpu_info->cpu_info_str, "432");
+			cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_432;
+			get_cpu_rev(&cpu_info->revision, cpu_info->cpu_info_str);
+			return 1;
+		}
+		if(is_nlm_xlp416_ax()){
+			strcat(cpu_info->cpu_info_str, "416");
+			cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_416;
+			get_cpu_rev(&cpu_info->revision, cpu_info->cpu_info_str);
+			return 1;
+		}
+		if(is_nlm_xlp408_ax()){
+			strcat(cpu_info->cpu_info_str, "408");
+			cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_408;
+			get_cpu_rev(&cpu_info->revision, cpu_info->cpu_info_str);
+			return 1;
+		}
+		if(is_nlm_xlp208_ax()){
+			strcat(cpu_info->cpu_info_str, "208");
+			cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_208;
+			get_cpu_rev(&cpu_info->revision, cpu_info->cpu_info_str);
+			return 1;
+		}
+		if(is_nlm_xlp204_ax()){
+			strcat(cpu_info->cpu_info_str, "204");
+			cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_204;
+			get_cpu_rev(&cpu_info->revision, cpu_info->cpu_info_str);
+			return 1;
+		}
+		if(is_nlm_xlp104_ax()){
+			strcat(cpu_info->cpu_info_str, "104");
+			cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_104;
+			get_cpu_rev(&cpu_info->revision, cpu_info->cpu_info_str);
+			return 1;
+		}
+	}
+	if(is_nlm_xlp3xx()){
+		cpu_info->proc_id = CHIP_PROCESSOR_ID_XLP_3XX;
+		strcpy(cpu_info->cpu_info_str, "XLP");
+		if(is_nlm_xlp316()){
+			strcat(cpu_info->cpu_info_str, "316");
+		}	
+		if(is_nlm_xlp308()){
+			strcat(cpu_info->cpu_info_str, "308");
+		}	
+		if(is_nlm_xlp304()){
+			strcat(cpu_info->cpu_info_str, "304");
+		}	
+		get_xlp3xx_extpid(cpu_info->cpu_info_str);
+		get_cpu_rev(&cpu_info->revision, cpu_info->cpu_info_str);
+		return 1;
+	}
+
+	return 0; //NO success in CPU ID
+}
+
+
+#ifdef NLM_HAL_LINUX_KERNEL
+#include <linux/types.h>
+#include <linux/module.h>
+/*Add  API here if any API  from above is needed*/
+EXPORT_SYMBOL(efuse_cfg0);
+EXPORT_SYMBOL(efuse_cfg1);
+EXPORT_SYMBOL(efuse_cfg6);
+EXPORT_SYMBOL(get_proc_id);
+EXPORT_SYMBOL(is_nlm_xlp8xx);
+EXPORT_SYMBOL(is_nlm_xlp8xx_b0);
+EXPORT_SYMBOL(is_nlm_xlp832_ax);
+EXPORT_SYMBOL(is_nlm_xlp8xx_ax);
+EXPORT_SYMBOL(is_nlm_xlp3xx);
+EXPORT_SYMBOL(is_nlm_xlpxxx);
+EXPORT_SYMBOL(is_nlm_xlp316);
+EXPORT_SYMBOL(is_nlm_xlp308);
+EXPORT_SYMBOL(is_nlm_xlp304);
+EXPORT_SYMBOL(nlm_hal_get_cpuinfo);
+EXPORT_SYMBOL(is_nlm_xlp3xx_lite);
+#endif
+
diff --git a/arch/mips/netlogic/common/nlm_hal_fmn_config.c b/arch/mips/netlogic/common/nlm_hal_fmn_config.c
index 665a17a..b947350 100644
--- a/arch/mips/netlogic/common/nlm_hal_fmn_config.c
+++ b/arch/mips/netlogic/common/nlm_hal_fmn_config.c
@@ -34,6 +34,8 @@
 #else
 #include "nlm_hal_fmn.h"
 #endif
+#include "libfdt.h"
+#include "fdt_helper.h"
 
 #define CPU		1
 #define PCIE	2
@@ -62,6 +64,291 @@
 #define NUM_THREADS		4
 #define NUM_VC_PER_THREAD	4
 
+
+nlm_fmn_config_t xlp3xx_fmn_config[] = {
+[XLP_MSG_HANDLE_CPU0] = {XLP_STNID_CPU0, XLP_CPU0_VC_LIMIT},
+[XLP_MSG_HANDLE_CPU1] = {XLP_STNID_CPU1, XLP_CPU1_VC_LIMIT},
+[XLP_MSG_HANDLE_CPU2] = {XLP_STNID_CPU2, XLP_CPU2_VC_LIMIT},
+[XLP_MSG_HANDLE_CPU3] = {XLP_STNID_CPU3, XLP_CPU3_VC_LIMIT},
+
+[XLP_MSG_HANDLE_CPU4] = {XLP_3XX_INVALID_STATION, 0},
+[XLP_MSG_HANDLE_CPU5] = {XLP_3XX_INVALID_STATION, 0},
+[XLP_MSG_HANDLE_CPU6] = {XLP_3XX_INVALID_STATION, 0},
+[XLP_MSG_HANDLE_CPU7] = {XLP_3XX_INVALID_STATION, 0},
+
+[XLP_MSG_HANDLE_PCIE0] = {XLP_PCIE0_VC_BASE, XLP_PCIE0_VC_LIMIT},
+[XLP_MSG_HANDLE_PCIE1] = {XLP_PCIE1_VC_BASE, XLP_PCIE1_VC_LIMIT},
+[XLP_MSG_HANDLE_PCIE2] = {XLP_PCIE2_VC_BASE, XLP_PCIE2_VC_LIMIT},
+[XLP_MSG_HANDLE_PCIE3] = {XLP_PCIE3_VC_BASE, XLP_PCIE3_VC_LIMIT},
+
+[XLP_MSG_HANDLE_DTRE] = {XLP_GDX_VC_BASE, XLP_GDX_VC_LIMIT},
+
+[XLP_MSG_HANDLE_GDX]  = {XLP_GDX_VC_BASE, XLP_GDX_VC_LIMIT},
+[XLP_MSG_HANDLE_REGX] = {XLP_3XX_REGEX_VC_BASE, XLP_3XX_REGEX_VC_LIMIT},
+[XLP_MSG_HANDLE_RSA_ECC] = {XLP_3XX_RSA_ECC_VC_BASE, XLP_3XX_RSA_ECC_VC_LIMIT},
+[XLP_MSG_HANDLE_CRYPTO] = {XLP_3XX_CRYPTO_VC_BASE, XLP_3XX_CRYPTO_VC_LIMIT},
+
+[XLP_MSG_HANDLE_SRIO] = {XLP_3XX_SRIO_VC_BASE, XLP_3XX_SRIO_VC_LIMIT},
+
+[XLP_MSG_HANDLE_CMP] = {XLP_3XX_INVALID_STATION, 0},
+
+[XLP_MSG_HANDLE_POE] = {XLP_3XX_POE_VC_BASE, XLP_3XX_POE_VC_LIMIT},
+[XLP_MSG_HANDLE_NAE_0] = {XLP_3XX_NET_TX_VC_BASE, XLP_3XX_NET_TX_VC_LIMIT},
+
+[XLP_MSG_HANDLE_INVALID] = {XLP_3XX_INVALID_STATION, 0},
+[XLP_MSG_HANDLE_MAX] = {XLP_3XX_INVALID_STATION, 0},
+};
+
+extern struct nlm_node_config nlm_node_cfg;
+
+//#define FMN_DEBUG 1
+
+static unsigned int fmn_cfg_value[XLP_NET_VC_LIMIT + 1];
+static unsigned int fmn_default_credits = XLP_FMN_DEFAULT_CREDITS;
+static unsigned int fmn_default_qsize = XLP_FMN_DEFAULT_QUEUE_SIZE;
+static unsigned long long fmn_spill_mem_addr = XLP_FMNQ_SPILL_DEFAULT_MEM_ADDR;
+static unsigned long long fmn_spill_mem_size = XLP_FMNQ_SPILL_DEFAULT_MEM_SIZE;
+
+
+static struct fmn_qsize_credit_config fmn_qsize_credit_cfg[XLP_MSG_BLK_MAX] = {
+	[XLP_MSG_BLK_CPU] =     { "cpu",    XLP_CPU0_VC_BASE,      XLP_CPU7_VC_LIMIT,      8, 1 },
+	[XLP_MSG_BLK_POPQ] =    { "popq",   XLP_POPQ_VC_BASE,      XLP_POPQ_VC_LIMIT,      0, 1 },
+        [XLP_MSG_BLK_PCIE0] =    { "pcie0",   XLP_PCIE0_VC_BASE,     XLP_PCIE0_VC_LIMIT,     1, 1 },
+        [XLP_MSG_BLK_PCIE1] =    { "pcie1",   XLP_PCIE1_VC_BASE,     XLP_PCIE1_VC_LIMIT,     1, 1 },
+        [XLP_MSG_BLK_PCIE2] =    { "pcie2",   XLP_PCIE2_VC_BASE,     XLP_PCIE2_VC_LIMIT,     1, 1 },
+        [XLP_MSG_BLK_PCIE3] =    { "pcie3",   XLP_PCIE3_VC_BASE,     XLP_PCIE3_VC_LIMIT,     1, 1 },
+	[XLP_MSG_BLK_GDX]  =    { "gdx",    XLP_GDX_VC_BASE,       XLP_GDX_VC_LIMIT,       1, 1 },
+	[XLP_MSG_BLK_RSA_ECC] = { "rsa",    XLP_RSA_ECC_VC_BASE,   XLP_RSA_ECC_VC_LIMIT,   1, 1 },
+	[XLP_MSG_BLK_CRYPTO] =  { "crypto", XLP_CRYPTO_VC_BASE,    XLP_CRYPTO_VC_LIMIT,    1, 1 },
+	[XLP_MSG_BLK_CMP] =     { "cmp",    XLP_CMP_VC_BASE,       XLP_CMP_VC_LIMIT,       1, 1 },
+	[XLP_MSG_BLK_POE] =     { "poe",    XLP_POE_VC_BASE,       XLP_POE_VC_LIMIT,       1, 1 },
+	[XLP_MSG_BLK_NAE] =     { "nae",    XLP_NET_VC_BASE,       XLP_NET_VC_LIMIT,       1, 1 },
+	[XLP_MSG_BLK_REGX] =    { "regx",   XLP_3XX_REGEX_VC_BASE, XLP_3XX_REGEX_VC_LIMIT, 1, 1 },
+	[XLP_MSG_BLK_SRIO] =    { "srio",   XLP_3XX_SRIO_VC_BASE,  XLP_3XX_SRIO_VC_LIMIT,  1, 1 },
+};
+
+
+/* called based on the chip type */
+static void fmn_modify_qsize_credit_config(int node, int blk, int ntxstns, int b_stid, int e_stid)
+{
+	struct fmn_qsize_credit_config *fmn_q_config = nlm_node_cfg.fmn_cfg[node]->fmn_q_config;
+
+	if(ntxstns >= 0)
+		fmn_q_config[blk].n_txstns = ntxstns;
+	if(b_stid >= 0)
+		fmn_q_config[blk].b_stid = b_stid;
+	if(e_stid >= 0)
+		fmn_q_config[blk].e_stid = e_stid;
+}
+
+static void fmn_invalidate_blocks(int node, int blk)
+{
+	struct fmn_qsize_credit_config *fmn_q_config = nlm_node_cfg.fmn_cfg[node]->fmn_q_config;
+
+	fmn_q_config[blk].valid = 0;
+}
+
+#if 0
+static void fmn_qsize_credit_cfg_extract(void *fdt)
+{
+	char path[128];
+	const void *pval;
+	int s_stn = 0, d_stn = 0, nodeoffset, plen, len = 0;
+	unsigned int qsize = XLP_FMN_DEFAULT_QUEUE_SIZE;
+	unsigned int credits = XLP_FMN_DEFAULT_CREDITS;
+
+	/* initialize with the default values, given the config file */
+	if(fdt) {
+		strcpy(path, "/fmn-config");
+		nodeoffset = fdt_path_offset(fdt, path);
+		if(nodeoffset >= 0)  {
+			pval = fdt_getprop(fdt, nodeoffset, "default-queue-size", &plen);
+			if(pval != NULL) {
+				qsize = fdt32_to_cpu(*(unsigned int *)pval);
+				fmn_default_qsize = qsize;
+			}
+			pval = fdt_getprop(fdt, nodeoffset, "default-credits", &plen);
+			if(pval != NULL) {
+				credits = fdt32_to_cpu(*(unsigned int *)pval);
+				fmn_default_credits = credits;
+			}
+		}
+
+		strcpy(path, "/extra-mem-config");
+		nodeoffset = fdt_path_offset(fdt, path);
+		if(nodeoffset >= 0)  {
+			pval = fdt_getprop(fdt, nodeoffset, "fmn-spill-mem-range", &plen);
+			if(pval != NULL) {
+				fmn_spill_mem_addr = fdt64_to_cpu(*(unsigned long long *)pval);
+				fmn_spill_mem_size = fdt64_to_cpu(*((unsigned long long *)pval + 1));
+			}
+		}
+	}
+
+	nlm_print("FMN Default queuesize %d credtis %d\n", qsize, credits);
+	nlm_print("FMN Spill mem addr %lx mem size %lx\n", 
+					(long)fmn_spill_mem_addr, (long)fmn_spill_mem_size);
+
+	/* credits from this source station(s_stn) to the destination station(d_stn) */
+	for(s_stn = 0; s_stn < XLP_MSG_BLK_MAX; s_stn++) {
+		fmn_qsize_credit_cfg[s_stn].q_size = qsize;
+		for(d_stn = 0; d_stn < XLP_MSG_BLK_MAX; d_stn++)
+			fmn_qsize_credit_cfg[s_stn].credits[d_stn] = credits;
+	}
+
+	if(!fdt)
+		return;
+	
+	for(s_stn = 0; s_stn < XLP_MSG_BLK_MAX; s_stn++) {
+		len = sprintf(&path[0], "%s", "/fmn-config/");
+		sprintf(&path[len], "%s", fmn_qsize_credit_cfg[s_stn].q_name);
+		nodeoffset = fdt_path_offset(fdt, path);
+		if(nodeoffset < 0) 
+			continue;
+
+		/* get queue size for this station */
+		pval = fdt_getprop(fdt, nodeoffset, "queue-size", &plen);
+		if(pval != NULL) {
+			qsize = fdt32_to_cpu(*(unsigned int *)pval);
+			fmn_qsize_credit_cfg[s_stn].q_size = qsize;
+		}
+
+		/* get credits from this station to other stations */
+		for(d_stn = 0; d_stn < XLP_MSG_BLK_MAX; d_stn++) {
+			pval = fdt_getprop(fdt, nodeoffset, fmn_qsize_credit_cfg[d_stn].q_name, &plen);
+			if (pval != NULL) {
+				credits = fdt32_to_cpu(*(unsigned int *)pval);
+				fmn_qsize_credit_cfg[s_stn].credits[d_stn] = credits;
+				/*nlm_print(" dst stn name %s credits %d\n", 
+						fmn_qsize_credit_cfg[d_stn].q_name, credits);*/
+			}
+		}
+	}
+	
+#ifdef FMN_DEBUG
+	/* dump the table */
+	for(s_stn = 0; s_stn < XLP_MSG_BLK_MAX; s_stn++) {
+		len = 0;
+		nlm_print("name %s bstid %d estid %d ntxstns %d qsize %d\n",
+				fmn_qsize_credit_cfg[s_stn].q_name, fmn_qsize_credit_cfg[s_stn].b_stid,
+				fmn_qsize_credit_cfg[s_stn].e_stid, fmn_qsize_credit_cfg[s_stn].n_txstns,
+				fmn_qsize_credit_cfg[s_stn].q_size);
+		nlm_print("  credits ");
+		for(d_stn = 0; d_stn < XLP_MSG_BLK_MAX; d_stn++)
+			nlm_print("<%s:%d> ",   fmn_qsize_credit_cfg[d_stn].q_name,
+					 fmn_qsize_credit_cfg[s_stn].credits[d_stn]);
+		nlm_print("\n");
+	}
+#endif
+}
+#endif
+
+static void fmn_update_credit(int node, int b_stid, int dst_node)
+{
+	unsigned int *credits = NULL;
+	int s_stn, d_stn, sid;
+	struct fmn_qsize_credit_config *fmn_q_config = nlm_node_cfg.fmn_cfg[node]->fmn_q_config;
+
+	/* configure with the default */
+	for(sid = 0; sid <= XLP_NET_VC_LIMIT; sid++)
+		fmn_cfg_value[sid] = nlm_node_cfg.fmn_cfg[node]->fmn_default_credits;
+
+	/* Get credit config from the given source station to different destination station */
+	for(s_stn = 0; s_stn < XLP_MSG_BLK_MAX; s_stn++) {
+		if(!fmn_q_config[s_stn].valid)
+			continue;
+		if(b_stid >=  fmn_q_config[s_stn].b_stid && 
+				b_stid <= fmn_q_config[s_stn].e_stid) {
+			credits = fmn_q_config[s_stn].credits[dst_node];
+			break;
+		}
+	}
+	if(credits == NULL) {
+		nlm_print("ERROR in Credit config: Station id not found, configuring default credit\n");
+		return;
+	}
+
+	for(d_stn = 0; d_stn < XLP_MSG_BLK_MAX; d_stn++) {
+//		nlm_print("update credit s_stn %d d_stn %d credits %d\n",s_stn, d_stn, credits[d_stn]);
+		if(!fmn_q_config[d_stn].valid)
+			continue;
+		for(sid = fmn_q_config[d_stn].b_stid; sid <= fmn_q_config[d_stn].e_stid; sid++)
+			fmn_cfg_value[sid] = credits[d_stn];
+	}
+
+	return;
+}
+
+static int fmn_update_qsize(int node)
+{
+	int sid, s_stn;
+	unsigned long long qsize;
+	struct fmn_qsize_credit_config *fmn_q_config = nlm_node_cfg.fmn_cfg[node]->fmn_q_config;
+
+	
+	/* qsize cannot be more than 256KB and it should be aligned to 4K */
+	if((fmn_default_qsize % FMN_Q_PAGE_SIZE) != 0)
+		fmn_default_qsize = (fmn_default_qsize + FMN_Q_PAGE_SIZE - 1) & (~(FMN_Q_PAGE_SIZE - 1));
+
+	if(fmn_default_qsize > FMN_MAX_Q_SIZE) {
+		nlm_print("ERROR: Default FMN Q size exceeds the limit\n");
+		return -1;
+	}
+	
+	for(sid = 0; sid <= XLP_NET_VC_LIMIT; sid++)
+		fmn_cfg_value[sid] = fmn_default_qsize;
+
+	for(s_stn = 0; s_stn < XLP_MSG_BLK_MAX; s_stn++) {
+		if(!fmn_q_config[s_stn].valid)
+			continue;
+		for(sid = fmn_q_config[s_stn].b_stid; sid <= fmn_q_config[s_stn].e_stid; sid++) {
+			qsize = fmn_q_config[s_stn].q_size;
+			if(qsize > FMN_MAX_Q_SIZE) {
+				nlm_print("ERROR: FMN Q size for stn %d exceeds the limit\n", s_stn);
+				return -1;
+			}
+			if((qsize % FMN_Q_PAGE_SIZE) != 0)
+				qsize = (qsize + FMN_Q_PAGE_SIZE - 1) & (~(FMN_Q_PAGE_SIZE - 1));
+			fmn_cfg_value[sid] = qsize;
+		}
+	}
+	return 0;
+}
+
+
+static void fmn_validate_credit(int node, int max_nodes)
+{
+	unsigned int credits, qsize;
+	unsigned int s_stn, d_stn, src_node;
+	struct fmn_qsize_credit_config *fmn_q_config = nlm_node_cfg.fmn_cfg[node]->fmn_q_config;
+
+	
+	/* credits from all the source stations to this station */
+	for(d_stn = 0; d_stn < XLP_MSG_BLK_MAX; d_stn++) {
+		if(!fmn_q_config[d_stn].valid)
+			continue;
+		qsize = fmn_q_config[d_stn].q_size;
+		credits = 0;
+	        for(src_node = 0; src_node < max_nodes; src_node++) {
+  		    for(s_stn = 0; s_stn < XLP_MSG_BLK_MAX; s_stn++)  {
+		 	if(!fmn_q_config[s_stn].valid)
+				continue;
+			credits += (fmn_q_config[s_stn].credits[src_node][d_stn] * fmn_q_config[s_stn].n_txstns);
+                    }
+		}
+
+#ifdef FMN_DEBUG
+		nlm_print("Credits check dst stn %s, reqd %d cfgrd %d\n", 
+					fmn_q_config[d_stn].q_name, (credits * 12), qsize);
+#endif
+
+		/* considering single entry message only */
+		if((credits * 12) >= qsize) 
+			nlm_print("WARN ... Credits overflow.. dst stn %s, reqd %d cfgd %d\n", 
+					fmn_q_config[d_stn].q_name, (credits * 12), qsize);
+	}
+}
+
 /* 1024-bit bitmask as 16 64-bit longs.
  * '1' => station @ that bit position
  * is disabled.
@@ -74,24 +361,24 @@ unsigned long long stids[16];
  * In xlp, there are 4 VC per cpu. Each vc can be configured to generate
  * an interrupt when message receive event happens.
  ********************************************************************/
-void nlm_hal_enable_vc_intr(int vc)
+void nlm_hal_enable_vc_intr(int node, int vc)
 {
 	uint64_t val = 0;
-	val = nlm_hal_read_outq_config(vc);
+	val = nlm_hal_read_outq_config(node, vc);
 	val &= ~((0x7ULL<<56) | (0x3ULL<<54) | (0x7ULL<<51) | (0x3ULL<<49));
 	val |=  (0ULL<<56)|(0x2ULL<<54)|(0x0ULL<<51)|(0x1ULL<<49);
-	nlm_hal_write_outq_config(vc, val);
+	nlm_hal_write_outq_config(node, vc, val);
 }
 
 /*********************************************************************
  * nlm_hal_disable_vc_intr
 *********************************************************************/
-void nlm_hal_disable_vc_intr(int vc)
+void nlm_hal_disable_vc_intr(int node, int vc)
 {
 	uint64_t val = 0;
-	val = nlm_hal_read_outq_config(vc);
+	val = nlm_hal_read_outq_config(0, vc);
 	val = val & ~((0x3ULL<<54) | (0x3ULL<<49));
-	nlm_hal_write_outq_config(vc, val);
+	nlm_hal_write_outq_config(node, vc, val);
 }
 
 /*********************************************************************
@@ -112,9 +399,9 @@ void nlm_hal_set_fmn_interrupt(int irq)
 
 }
 
-static __inline__ void nlm_hal_write_credit(int src, int dst, uint32_t credits)
+static __inline__ void nlm_hal_write_credit(int node, uint64_t src, uint64_t dst, uint64_t credits)
 {
-	uint64_t regaddr = nlh_qid_to_virt_addr(XLP_CREDIT_CONFIG_REG, 0);
+	uint64_t regaddr = nlh_qid_to_virt_addr(node, XLP_CREDIT_CONFIG_REG, 0); 
 	uint64_t value = (((src) & 0x3ff) | (((dst) & 0xfff) << 12) | (((credits) & 0xffff) << 24));
 
 	nlh_write_cfg_reg64(regaddr, value);
@@ -144,40 +431,42 @@ void enable_interface(int interface, short value) {
 				int i;
 				for (i=0; i<4; i++) {
 					if ((value  & (1 << i)) == 0)
-						clearbit(XLP_STNID_PCIE0 + (i << 1));	
+						clearbit(XLP_STNID_PCIE0 + (i << 1));		
 				}
 			} break;
 		case GDX: {
 				if (value == 0)
-					clearbit(XLP_STNID_GDX);	
+					clearbit(XLP_STNID_GDX);		
 			} break;
 		case CMP: {
 				int i;
+#ifndef NLM_XLP_3XX
 				for (i=0; i<4; i++) {
 					if ((value  & (1 << i)) == 0)
-						clearbit(XLP_STNID_CMP + i);	
+						clearbit(XLP_STNID_CMP + i);		
 				}
+#endif
 			} break;
 		case CRYPTO: {
 				int i;
 				for (i=0; i<12; i++) {
 					if ((value  & (1 << i)) == 0)
-						clearbit(XLP_STNID_CRYPTO + i);	
+						clearbit(XLP_STNID_CRYPTO + i);		
 				}
 			} break;
 		case POE: {
 				if (value == 0)
-					clearbit(XLP_STNID_POE);	
+					clearbit(XLP_STNID_POE);		
 			} break;
 		case NAE: {
 				if (value == 0)
-					clearbit(XLP_STNID_NAE_TX);	
+					clearbit(XLP_STNID_NAE_TX);		
 			} break;
 		case RSA: {
 				int i;
 				for (i=0; i<9; i++) {
 					if ((value  & (1 << i)) == 0)
-						clearbit(XLP_STNID_RSA_ECC + i);	
+						clearbit(XLP_STNID_RSA_ECC + i);		
 				}
 			} break;
 		default:
@@ -185,65 +474,148 @@ void enable_interface(int interface, short value) {
 			break;
 	}
 }
-
+	
 /* Based on the (un)set bits from the EFUSE CFG Regs,
  * create a bitmask representing 0-1023 station IDs
  * which can then be used to check whether to send
  * credits to or not. This is a one-time operation.
  */
-void stids_toskip(void) {
+void stids_toskip(int node) {
 
 	int i;
 
 	for (i=0; i<16; i++)
 		stids[i] = ~0ULL;	/* init to all disabled */
-
-	enable_interface(CPU,     nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG0) & 0xff);
-	enable_interface(PCIE,   (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG1) >> 3) & 0xf);
-	enable_interface(GDX,    (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG1) >> 8) & 0x1);
-	enable_interface(CMP,    (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG1) >> 9) & 0xf);
-	enable_interface(CRYPTO, (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG1) >> 14) & 0xfff);
-	enable_interface(POE,    (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG1) >> 27) & 0x1);
-	enable_interface(NAE,    (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG1) >> 28) & 0x1);
-	enable_interface(RSA,    (nlm_hal_read_sys_reg(EFUSE_DEVICE_CFG2)) & 0x1ff);
+	
+	enable_interface(CPU,     nlm_hal_read_sys_reg(node, EFUSE_DEVICE_CFG0) & 0xff);
+	enable_interface(PCIE,   (nlm_hal_read_sys_reg(node, EFUSE_DEVICE_CFG1) >> 3) & 0xf);
+	enable_interface(GDX,    (nlm_hal_read_sys_reg(node, EFUSE_DEVICE_CFG1) >> 8) & 0x1);
+	enable_interface(CMP,    (nlm_hal_read_sys_reg(node, EFUSE_DEVICE_CFG1) >> 9) & 0xf);
+	enable_interface(CRYPTO, (nlm_hal_read_sys_reg(node, EFUSE_DEVICE_CFG1) >> 14) & 0xfff);
+	enable_interface(POE,    (nlm_hal_read_sys_reg(node, EFUSE_DEVICE_CFG1) >> 27) & 0x1);
+	enable_interface(NAE,    (nlm_hal_read_sys_reg(node, EFUSE_DEVICE_CFG1) >> 28) & 0x1);
+	enable_interface(RSA,    (nlm_hal_read_sys_reg(node, EFUSE_DEVICE_CFG2)) & 0x1ff);
 }
 
-static void nlm_hal_write_fmn_credit(uint32_t credits)
+static void nlm_hal_write_fmn_credit(int node, int max_nodes) 
 {
-	int src, qid;
-
+	int src, qid, hndl = 0, dst_node;
+	nlm_fmn_config_t *fmn_config = NULL;
 	volatile int index;
+	uint32_t credits;
+
+        if (is_nlm_xlp3xx()) {
+                nlm_print(" XLP3XX FMN configuration \n");
+		fmn_modify_qsize_credit_config(node, XLP_MSG_BLK_CPU, 4, XLP_CPU0_VC_BASE, XLP_CPU3_VC_LIMIT);
+		if(is_nlm_xlp308()){
+                	fmn_config = &xlp3xx_fmn_config[0];
+			fmn_config += XLP_MSG_HANDLE_CPU2;
+			for(hndl = 0; hndl<2; hndl++){
+				fmn_config->base_vc = XLP_3XX_INVALID_STATION,
+				fmn_config->vc_limit =0;
+				fmn_config++;
+			}
+			fmn_modify_qsize_credit_config(node, XLP_MSG_BLK_CPU, 2, XLP_CPU0_VC_BASE, XLP_CPU1_VC_LIMIT);
 
-	/* this populates the global array 'stids'
+		}
+		if(is_nlm_xlp304()){
+                	fmn_config = &xlp3xx_fmn_config[0];
+			fmn_config += XLP_MSG_HANDLE_CPU1;
+			for(hndl = 0; hndl<3; hndl++){
+				fmn_config->base_vc = XLP_3XX_INVALID_STATION,
+				fmn_config->vc_limit =0;
+				fmn_config++;
+			}
+
+			fmn_modify_qsize_credit_config(node, XLP_MSG_BLK_CPU, 1, XLP_CPU0_VC_BASE, XLP_CPU0_VC_LIMIT);
+		}
+
+		/* 3xx has diffrent vcs for rsa, crypto and nae */
+		fmn_modify_qsize_credit_config(node, XLP_MSG_BLK_RSA_ECC, 1, XLP_3XX_RSA_ECC_VC_BASE, XLP_3XX_RSA_ECC_VC_LIMIT);
+		fmn_modify_qsize_credit_config(node, XLP_MSG_BLK_CRYPTO, 1, XLP_3XX_CRYPTO_VC_BASE, XLP_3XX_CRYPTO_VC_LIMIT);
+		fmn_modify_qsize_credit_config(node, XLP_MSG_BLK_NAE, 1, XLP_3XX_NET_VC_BASE, XLP_3XX_NET_VC_LIMIT);
+			
+		/* 3xx does not have compression engine */
+		fmn_invalidate_blocks(node, XLP_MSG_BLK_CMP);
+
+                fmn_config = &xlp3xx_fmn_config[0];
+                for(hndl = 0; hndl < XLP_MSG_HANDLE_MAX; hndl++) {
+                        if (fmn_config->base_vc != XLP_3XX_INVALID_STATION) {
+				fmn_update_credit(node, fmn_config->base_vc, node);		
+				credits = 0;
+                                for (qid = 0; qid <= XLP_3XX_NET_VC_LIMIT; qid++) {
+#ifdef FMN_DEBUG
+					if(credits != fmn_cfg_value[qid]) {
+						nlm_print("base %d qid %d credits %d\n", 
+							fmn_config->base_vc, qid, fmn_cfg_value[qid]);
+					}
+#endif
+					credits = fmn_cfg_value[qid];
+	                                nlm_hal_write_credit(node, fmn_config->base_vc, qid, credits);	
+                                }
+                        }
+                        fmn_config++;
+                }
+        }
+	else {
+	/* this populates the global array 'stids' 
 	 * with a '1' representing a disabled station ID.
 	 */
-	stids_toskip();
-
-	for (src = 0; src <= XLP_STNID_NAE_TX; src++) {
-		/* check if bitposition src == 1 in
-		 * the dst_skip_bitmask. if so, continue
-		 */
-		index = src / 64;
-
-		if ((stids[index] >> (src % 64)) & 0x1) {
-			continue;
+		stids_toskip(node);
+
+		/* 8xx does not have regx and srio */
+		fmn_invalidate_blocks(node, XLP_MSG_BLK_REGX);
+		fmn_invalidate_blocks(node, XLP_MSG_BLK_SRIO);
+
+
+		for (src = 0; src <= XLP_STNID_NAE_TX; src++) {
+			/* check if bitposition src == 1 in 
+			 * the dst_skip_bitmask. if so, continue
+			 */
+			index = src / 64;
+
+			if ((stids[index] >> (src % 64)) & 0x1) {
+				continue;
+			}
+
+			/* only enabled stations will reach here
+			 */
+
+			for(dst_node = 0 ;dst_node < max_nodes; dst_node++) {
+				fmn_update_credit(node, src, dst_node);
+				credits = 0;
+				for (qid = 0; qid < 1024; qid++) {
+#ifdef FMN_DEBUG
+					if(credits != fmn_cfg_value[qid]) {
+						nlm_print("src%d@%d node %d qid %d credits %d\n", 
+							src, node, dst_node, qid, fmn_cfg_value[qid]);
+					}
+#endif
+					credits = fmn_cfg_value[qid];
+					nlm_hal_write_credit(node, src, ((dst_node << 10) | qid), credits);	
+				}
+			}
 		}
-
-		/* only enabled stations will reach here
-		 */
-		for (qid = 0; qid < 1024; qid++)
-			nlm_hal_write_credit(src, qid, credits);
 	}
-}
 
+	/* Validae the credit config */
+	fmn_validate_credit(node, max_nodes);
+}
 /*********************************************************************
  * nlm_hal_fmn_init
  *
  * setup 1024 outq, set credit from cpu to io,  io to io, and io to
  * cpu
  ********************************************************************/
-#if defined(NLM_HAL_UBOOT) || defined(NLM_HAL_NETLBOOT)
+#if defined(NLM_HAL_UBOOT) || defined(NLM_HAL_NETLBOOT) || defined(NLM_HAL_NETOS)
 
+#define OUT_Q_INIT	0
+
+#else
+
+#define OUT_Q_INIT	((0x2ULL<<54) | (0x1ULL<<49))
+
+#endif
 /*********************************************************************
  * nlm_hal_setup_outq
  *
@@ -257,16 +629,14 @@ static void nlm_hal_write_fmn_credit(uint32_t credits)
  * This allows for 1024 q entries with 16B of entry size
  * This assumes credits across all sending agents to this queue is < 1024
  ********************************************************************/
-static void nlm_hal_setup_outq(uint64_t tiny_spill_base, uint32_t tiny_size, uint32_t credits)
+int nlm_hal_setup_outq(int node, int max_nodes)
 {
-	uint32_t qid;
+	uint32_t qid, max_qs = 0;
 	uint64_t val;
 
-	const uint64_t spill_base = 256 << 20;
-	uint64_t q_spill_base = 0;
-	uint64_t q_spill_start_page = 0;
-	const int q_spill_pages = 4;
-	const uint32_t q_spill_page_size = 4 << 10; /* 4KB */
+	uint64_t spill_base = nlm_node_cfg.fmn_cfg[node]->fmn_spill_base; //fmn_spill_mem_addr;
+	uint32_t spill_size = nlm_node_cfg.fmn_cfg[node]->fmn_spill_size;
+	uint64_t q_spill_start_page = 0, q_spill_pages;
 
 	const uint32_t ram_base = 0;
 	uint32_t q_ram_base = 0;
@@ -274,15 +644,38 @@ static void nlm_hal_setup_outq(uint64_t tiny_spill_base, uint32_t tiny_size, uin
 	const int q_ram_pages = 1;
 	const uint32_t q_ram_page_entries = 32; /* entries, not bytes */
 
-	/* Configure all 1024 Queues! */
-	for( qid = 0; qid < 1024; qid++ )
+	if (is_nlm_xlp3xx()) {
+		max_qs = XLP_3XX_NET_VC_LIMIT;
+	}
+	else {
+		max_qs = XLP_NET_VC_LIMIT;
+	}
+
+        nlm_node_cfg.fmn_cfg[node]->spill_base_cur = spill_base;
+        nlm_node_cfg.fmn_cfg[node]->q_ram_base = nlm_node_cfg.fmn_cfg[node]->q_ram_base_cur = q_ram_base;
+        nlm_node_cfg.fmn_cfg[node]->q_ram_page_perq = 1;
+
+	if(fmn_update_qsize(node) < 0)
+		return -1;
+
+	for( qid = 0; qid <= max_qs; qid++ )
 	{
-		/* Enable all output queues and spill on all queues */
-		val = OUTQ_EN|SPILL_EN;
+		/* Enable all output queues and spill on all queues.
+		   Disable spill for u-boot as the spill memory will be enabled by the os 
+		   loading time with the specified address */
+#if defined(NLM_HAL_UBOOT) || defined(NLM_HAL_NETLBOOT)
+		val = OUTQ_EN;
+#else
+		val = OUTQ_EN;
+		if (nlm_node_cfg.fmn_cfg[node]->fmn_spill_base != 0ULL) 
+			val |= SPILL_EN;
+#endif
 
 		/* Enable interrupts for cpu Queues */
 		if ( (qid >= 0) && (qid < 128))
-			val |= INT_EN|(0ULL<<56)|(0x2ULL<<54)|(0x0ULL<<51)|(0x1ULL<<49);
+			val |= OUT_Q_INIT ;
+
+			//val |= INT_EN|(0ULL<<56)|(0x2ULL<<54)|(0x0ULL<<51)|(0x1ULL<<49);
 
 		/***************************************************************
 		 * Configuration of on-chip RAM area
@@ -300,41 +693,274 @@ static void nlm_hal_setup_outq(uint64_t tiny_spill_base, uint32_t tiny_size, uin
 		 * Configuration of spill area
 		 **************************************************************
 		 */
-		q_spill_base = spill_base + (qid * q_spill_pages * q_spill_page_size);
-
-		val |= ( ((q_spill_base >> 18) & 0x3fffff) << 27); /* [39:18] of q_spill_base */
-
-		q_spill_start_page = (q_spill_base >> 12) & 0x3f; /* [17:12] of q_spill_base */
+		/* pages in 4K units */
+		q_spill_pages = fmn_cfg_value[qid] / (FMN_Q_PAGE_SIZE);
+		
+		/* if spill_start + qsize crosses 256MB boundary, configuration will be wrong as 
+		 only 17-12 bits only considered for spill last */
+		if(((spill_base & (FMN_MAX_Q_SIZE - 1)) +  fmn_cfg_value[qid]) > FMN_MAX_Q_SIZE)
+			spill_base = (spill_base + FMN_MAX_Q_SIZE - 1) & (~(FMN_MAX_Q_SIZE - 1));
+		
+		val |= ( ((spill_base >> 18) & 0x3fffff) << 27); /* [39:18] of q_spill_base */
+
+		q_spill_start_page = (spill_base >> 12) & 0x3f; /* [17:12] of q_spill_base */
 		val |= (q_spill_start_page << 15);
 		val |= ( (q_spill_start_page + q_spill_pages - 1) << 21);
 
+#ifdef FMN_DEBUG
+		nlm_print("Fmn q config %d sqbase %lx sqsize %d sqpages %d\n", 
+				qid, (long)spill_base, fmn_cfg_value[qid], (int)q_spill_pages);
+#endif
+		
+		spill_base +=  fmn_cfg_value[qid];
+		
 		/* Write to the configuration register */
-		nlm_hal_write_outq_config(qid, val);
+		nlm_hal_write_outq_config(node, qid, val);
 	}
-}
 
+        nlm_node_cfg.fmn_cfg[node]->spill_base_cur = spill_base;
+        nlm_node_cfg.fmn_cfg[node]->q_ram_base_cur = q_ram_base;
+ 
+        nlm_print("spill_base_cur 0x%llx qram_base_cur 0x%llx \n",(unsigned long long)spill_base,(unsigned long long) q_ram_base);
 
-void nlm_hal_fmn_init(uint64_t spill_base, uint32_t size, uint32_t credits)
+//	if((spill_base - fmn_spill_mem_addr) > fmn_spill_mem_size) {
+	if ((spill_base - nlm_node_cfg.fmn_cfg[node]->fmn_spill_base) > spill_size) {
+		nlm_print("ERROR:  FMN Q total size exceeds the limit\n");
+		return -1;
+	}
+	return 0;
+}
+
+int parse_queue_config(void *fdt, int max_nodes)
 {
-	nlm_print("*** Firmware Configuration of FMN ***\n");
+        int node = 0, src_node, s_stn, d_stn;
+        char fmn_cfg_str[80];
+        char prop_str[10];
+        int plen, nodeoffset;
+        uint32_t *pval;
+	struct fmn_qsize_credit_config *fmn_q_config;
+	uint32_t credits, qsize;
+
+        for(node = 0 ;  node < max_nodes; node++) {
+                fmn_q_config = nlm_node_cfg.fmn_cfg[node]->fmn_q_config;
+                for(d_stn=0; d_stn < XLP_MSG_BLK_MAX; d_stn++) {
+
+                        sprintf(fmn_cfg_str, "/soc/fmn@node-%d/q-config/%s", node, fmn_q_config[d_stn].q_name);
+                        nodeoffset = fdt_path_offset(fdt, fmn_cfg_str);
+                        if(nodeoffset < 0)
+                                continue;
+	                /* get queue size for this station */
+        	        pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "queue-size", &plen);
+                	if(pval != NULL) {
+                        	qsize = fdt32_to_cpu(*(unsigned int *)pval);
+	                        fmn_q_config[d_stn].q_size = qsize;
+        	        }
+
+                        sprintf(fmn_cfg_str, "/soc/fmn@node-%d/q-config/%s/credits-from", node, fmn_q_config[d_stn].q_name);
+                        nodeoffset = fdt_path_offset(fdt, fmn_cfg_str);
+                        if(nodeoffset < 0)
+                                continue;
+
+                	/* get credits from this station to other stations */
+
+                        for(src_node = 0; src_node < max_nodes; src_node++) {
+                                sprintf(prop_str, "node-%d", src_node);
+                                pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, prop_str, &plen);
+                                if(pval != NULL) {
+                                        if ((plen / sizeof(uint32_t)) != XLP_MSG_BLK_MAX) {
+                                                nlm_print("Invalid credit configuration in fdt \n");
+                                                while(1); 
+                                        }
+                                        for(s_stn = 0; s_stn < XLP_MSG_BLK_MAX; s_stn++) {
+                                                credits = fdt32_to_cpu(*(unsigned int *)(pval + s_stn));
+						if (credits != 0)
+							nlm_node_cfg.fmn_cfg[src_node]->fmn_q_config[s_stn].credits[node][d_stn] = credits;
+#ifdef FMN_DEBUG
+                                                nlm_print("node %d station %s has %d credits to %d:Q %s\n", src_node, nlm_node_cfg.fmn_cfg[src_node]->fmn_q_config[s_stn].q_name, nlm_node_cfg.fmn_cfg[src_node]->fmn_q_config[s_stn].credits[node][d_stn], node, fmn_q_config[d_stn].q_name);
+#endif
+                                        }
 
-	/* verify out_q config
-	 */
-	nlm_hal_setup_outq(spill_base, size, credits);
-	nlm_hal_write_fmn_credit(credits);
+                                }
+                        }
+                }
+        }
+	return 0;
 }
 
-#else /* !UBOOT,NETLBOOT */
 
-void nlm_hal_fmn_init(uint64_t spill_base, uint32_t size, uint32_t credits)
+int parse_fdt_fmn_config(void *fdt)
 {
-	nlm_print("***** OS Configuration of FMN ******\n");
-	nlm_hal_write_fmn_credit(credits);
+	char fmn_cfg_str[50];
+	int nodeoffset = 0, plen, max_nodes = 1, node = 0;
+  	uint32_t *pval;
+	struct fmn_cfg *fmn_config;
+#if !defined(NLM_HAL_UBOOT) && !defined(NLM_HAL_NETLBOOT)
+	uint64_t spill_base = 0ULL;
+#endif
+	uint32_t qsize, credits, src_node, s_stn, d_stn;
 
-}
+	sprintf(fmn_cfg_str,"/soc");
+	nodeoffset = fdt_path_offset(fdt, fmn_cfg_str);
+
+        if(nodeoffset < 0) {
+		nlm_print("No 'soc' param in dtb \n");		
+	        return -1;  
+	}
+#ifdef NLM_HAL_LINUX_KERNEL
+        pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "num-nodes", &plen);
+        if(pval != NULL) {
+		max_nodes = fdt32_to_cpu(*(unsigned int *)pval);
+        }
+	else {
+		max_nodes = 1;
+	}
 #endif
 
+	nlm_print("Number of nodes %d \n",max_nodes);
+
+	nlm_node_cfg.num_nodes = max_nodes;
+	
+	for(node = 0; node < max_nodes; node++) {
+		nlm_node_cfg.fmn_cfg[node] = nlm_malloc(sizeof(struct fmn_cfg));
+		if (nlm_node_cfg.fmn_cfg[node] == NULL) {
+			nlm_print("nlm_malloc failed for node %d\n", node);
+			return -1;
+		}
+		memset(nlm_node_cfg.fmn_cfg[node], 0, sizeof(struct fmn_cfg));
+		nlm_node_cfg.fmn_cfg[node]->fmn_default_credits = fmn_default_credits/max_nodes;
+		nlm_node_cfg.fmn_cfg[node]->fmn_default_qsize = fmn_default_qsize;
+		if (node == 0) {
+			nlm_node_cfg.fmn_cfg[node]->fmn_spill_base = fmn_spill_mem_addr;
+			nlm_node_cfg.fmn_cfg[node]->fmn_spill_size = fmn_spill_mem_size;
+		}
+		else {
+			nlm_node_cfg.fmn_cfg[node]->fmn_spill_base = 0ULL;
+			nlm_node_cfg.fmn_cfg[node]->fmn_spill_size = 0ULL;
+		}
+		
+		sprintf(fmn_cfg_str,"/soc/fmn@node-%d",node);
+                nodeoffset = fdt_path_offset(fdt, fmn_cfg_str);
+                if(nodeoffset < 0) {
+                        nlm_print("No 'fmn@node-%d' param in dtb \n",node);
+			nlm_print("node %d default qsize %d credits %d\n",node, nlm_node_cfg.fmn_cfg[node]->fmn_default_qsize, nlm_node_cfg.fmn_cfg[node]->fmn_default_credits);
+	                memcpy(nlm_node_cfg.fmn_cfg[node]->fmn_q_config, fmn_qsize_credit_cfg, sizeof(fmn_qsize_credit_cfg));
+                        continue;
+                }
+
+#if !defined(NLM_HAL_UBOOT) && !defined(NLM_HAL_NETLBOOT)
+		pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "fmn-spill-mem-size", &plen);
+                if(pval != NULL) {
+                        nlm_node_cfg.fmn_cfg[node]->fmn_spill_size = fdt64_to_cpu(*(unsigned long long *)pval) ;
+		}
+
+		pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "fmn-spill-mem-base", &plen);
+		if(pval != NULL) {
+			spill_base = fdt64_to_cpu(*(unsigned long long *)pval);
+			if (spill_base != 0ULL) {
+				nlm_node_cfg.fmn_cfg[node]->fmn_spill_base = spill_base;
+			}
+		}
 #ifdef NLM_HAL_LINUX_KERNEL
+		if ((pval == NULL) || (nlm_node_cfg.fmn_cfg[node]->fmn_spill_base == 0ULL)){
+			spill_base = nlm_spill_alloc(node, (nlm_node_cfg.fmn_cfg[node]->fmn_spill_size));
+			if (spill_base == 0ULL) {
+				nlm_print("Node %d FMN spill_mem alloc failed \n", node);
+				nlm_node_cfg.fmn_cfg[node]->fmn_spill_size = 0;
+			}
+			else
+				nlm_node_cfg.fmn_cfg[node]->fmn_spill_base = spill_base;
+		}
+#endif
+#endif
+		nlm_print("spillsize 0x%llx @ 0x%016llx \n", (unsigned long long)nlm_node_cfg.fmn_cfg[node]->fmn_spill_size,(unsigned long long)nlm_node_cfg.fmn_cfg[node]->fmn_spill_base);
+
+
+                pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "default-queue-size", &plen);
+                if (pval != NULL) {
+                        qsize = fdt32_to_cpu(*(unsigned int *)pval);
+                        nlm_node_cfg.fmn_cfg[node]->fmn_default_qsize = qsize;
+                }
+
+                pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "default-credits", &plen);
+                if (pval != NULL) {
+                        credits = fdt32_to_cpu(*(unsigned int *)pval);
+                        nlm_node_cfg.fmn_cfg[node]->fmn_default_credits = credits / max_nodes;
+                }
+
+		nlm_print("node %d default qsize %d credits %d\n",node, nlm_node_cfg.fmn_cfg[node]->fmn_default_qsize, nlm_node_cfg.fmn_cfg[node]->fmn_default_credits);
+                memcpy(nlm_node_cfg.fmn_cfg[node]->fmn_q_config, fmn_qsize_credit_cfg, sizeof(fmn_qsize_credit_cfg));
+	}
+
+        for(node=0; node < max_nodes; node++) {
+                fmn_config = nlm_node_cfg.fmn_cfg[node];
+                for(d_stn = 0; d_stn < XLP_MSG_BLK_MAX; d_stn++) {
+                        fmn_config->fmn_q_config[d_stn].q_size = fmn_config->fmn_default_qsize;
+                        for(src_node=0; src_node < max_nodes; src_node++) {
+                                for(s_stn=0; s_stn < XLP_MSG_BLK_MAX; s_stn++) {
+                                        fmn_config->fmn_q_config[d_stn].credits[src_node][s_stn] = fmn_config->fmn_default_credits;
+#ifdef FMN_DEBUG
+                                        nlm_print("%d:%s Q, credits given to node %d stn %s : %d\n", node, fmn_config->fmn_q_config[d_stn].q_name, src_node, fmn_config->fmn_q_config[s_stn].q_name, fmn_config->fmn_q_config[d_stn].credits[src_node][s_stn]);
+#endif
+                                }
+                        }
+                }
+        }
+
+	parse_queue_config(fdt, max_nodes);
+
+	return max_nodes;
+}
+
+/**
+* @brief nlm_hal_fmn_init function Initializes FMN (outpu Queues and Credit registers)
+*
+* @param [in]  spill_base    :Physical address where the spill base starts
+* @param [in]  size          :Size of the spill/fill region in bytes
+* @param [in]  credits       :Number of credits from any src to any dst. 
+*
+* @return
+*  - Returns no value.
+*
+* @note
+*    1. This funysconfig/dts/fmn-temp.dtstion must be the first to be called before any FMN HAL API's.
+* @n
+*    2. This function is typically called twice (once from U-boot and once from OS). This is due to
+*       Netlogic's SDK convention that only 1 cpu is running while in U-boot and potentially more than 
+*       one cpu running while in OS and also the requirement that Credit configuration can only
+*       happen after the cpu is out of reset.
+* @n
+*    3. The credits between any source and any destination is chosen to be same for simplification.
+* 
+* @ingroup hal_fmn
+*
+*/
+void nlm_hal_fmn_init(void *fdt)
+{
+	int node = 0; 
+	int max_nodes;
+
+	nlm_print("*** Firmware Configuration of FMN ***\n");
+
+	max_nodes = parse_fdt_fmn_config(fdt);
+
+	if (max_nodes < 0) {
+		nlm_print("FMN Configuration failed\n");
+		while(1);
+	}
+
+	//fmn_qsize_credit_cfg_extract(fdt);
+	/* verify out_q config 
+	 */
+	for (node = 0; node < max_nodes; node++) {
+		if(nlm_hal_setup_outq(node, max_nodes) < 0)
+			while(1);
+	}
+	for (node = 0; node < max_nodes; node++) {
+		nlm_hal_write_fmn_credit(node, max_nodes);
+	}
+}
+
+#ifdef NLM_HAL_LINUX_KERNEL 
 #include <linux/types.h>
 #include <linux/module.h>
 EXPORT_SYMBOL(nlm_hal_disable_vc_intr);
diff --git a/arch/mips/netlogic/common/nlm_hal_nae.c b/arch/mips/netlogic/common/nlm_hal_nae.c
index 9649d9e..6c17ab4 100644
--- a/arch/mips/netlogic/common/nlm_hal_nae.c
+++ b/arch/mips/netlogic/common/nlm_hal_nae.c
@@ -25,19 +25,1063 @@ THE POSSIBILITY OF SUCH DAMAGE.
 
 #include "nlm_hal_fmn.h"
 #include "nlm_hal_nae.h"
+#include "nlm_hal_sys.h"
 #include "libfdt.h"
 #include "fdt_helper.h"
+#include "nlm_evp_cpld.h"
 
 #define VAL_UCORE_RESET(x) ( ( (x) &0xffff) << 8)
 
-struct nlm_hal_nae_config nae_cfg;
-int cntx2port[MAX_NAE_CONTEXTS];
+#define GET_PORT_PROP(prop, buf, len)                                   \
+        copy_fdt_prop(fdt, nae_port_str, prop, PROP_CELL, buf, len)
+
+#define GET_PORT_STR_PROP(prop, buf, len)                                       \
+        copy_fdt_prop(fdt, nae_port_str, prop, PROP_STR, buf, len)
+
+extern struct nlm_hal_ext_phy* get_phy_info(int inf);
+extern void nlm_hal_ext_phy_an(int node, int inf);
+extern void register_phy(int node, int inf, int* hw_portid);
+extern void nlm_hal_init_ext_phy(int node, int inf);
+
 static int nae_reset_done = 0;
-static void xlp_nae_config_interlaken(int blk,int port, int num_lanes);
-static void xlp_nae_config_xaui(int block, int port);
+static void xlp_nae_config_interlaken(int node, int blk,int port, int num_lanes);
+static void xlp_nae_config_xaui(int node, int block, int port, int vlan_pri_en);
 static unsigned int ucore_shared_scratch[128];
 static unsigned int ucore_shared_scratch_words;
+static void xlp_nae_config_lane_gmac(int node, int cplx_mask);
+
+uint32_t *cntx2port[NLM_MAX_NODES];
+
+#ifdef INCLUDE_NAE_DEBUG
+#define NAE_DEBUG	nlm_print
+#else
+#define NAE_DEBUG(...)
+#endif
+
+
+/*
+ *      MDIO Support
+ */
+/* Internal MDIO READ/WRITE Routines
+ */
+/**
+* @brief nae_int_gmac_mdio_read function is used to read an SGMII PCS register.
+* 
+* @param [in] node Node number
+* @param [in] bus Internal MDIO bus number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] intf_type GMAC_0, GMAC_1, GMAC_2, GMAC_3, XGMAC, INTERLAKEN, PHY, LANE_CFG (only valid for block 7)
+* @param [in] phyaddr Internal PHY's address
+* @param [in] regidx MDIO register index
+*
+* @return
+* 	- value of MDIO register
+* 
+* @ingroup hal_nae
+*
+*/
+static int nae_int_gmac_mdio_read(int node, int bus,int block, int intf_type, int phyaddr, int regidx)
+{
+	uint32_t mdio_ld_cmd = nlm_hal_read_mac_reg(node, block, intf_type, INT_MDIO_CTRL + bus * 4);
+
+	if (mdio_ld_cmd & INT_MDIO_CTRL_CMD_LOAD) {
+		nlm_hal_write_mac_reg(node, block, intf_type, INT_MDIO_CTRL + bus * 4,
+				       (mdio_ld_cmd & ~INT_MDIO_CTRL_CMD_LOAD));
+	}
+
+	nlm_hal_write_mac_reg(node, block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_SMP
+			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
+			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
+			       | (2 << INT_MDIO_CTRL_OP_POS)
+			       | (1 << INT_MDIO_CTRL_ST_POS)
+			       | (7 << INT_MDIO_CTRL_XDIV_POS)
+			       | (2 << INT_MDIO_CTRL_TA_POS)
+			       | (2 << INT_MDIO_CTRL_MIIM_POS)
+			       | (0 << INT_MDIO_CTRL_LOAD_POS)
+			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	/* Toggle Load Cmd Bit */
+	nlm_hal_write_mac_reg(node, block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_SMP
+			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
+			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
+			       | (2 << INT_MDIO_CTRL_OP_POS)
+			       | (1 << INT_MDIO_CTRL_ST_POS)
+			       | (7 << INT_MDIO_CTRL_XDIV_POS)
+			       | (2 << INT_MDIO_CTRL_TA_POS)
+			       | (2 << INT_MDIO_CTRL_MIIM_POS)
+			       | (1 << INT_MDIO_CTRL_LOAD_POS) /* */
+			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	/* poll master busy bit until it is not busy
+	 */
+	while(nlm_hal_read_mac_reg(node, block, intf_type,
+				    INT_MDIO_RD_STAT + bus * 4) & INT_MDIO_STAT_MBSY) {
+	}
+
+	nlm_hal_write_mac_reg(node, block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_SMP
+			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
+			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
+			       | (2 << INT_MDIO_CTRL_OP_POS)
+			       | (1 << INT_MDIO_CTRL_ST_POS)
+			       | (7 << INT_MDIO_CTRL_XDIV_POS)
+			       | (2 << INT_MDIO_CTRL_TA_POS)
+			       | (2 << INT_MDIO_CTRL_MIIM_POS)
+			       | (0 << INT_MDIO_CTRL_LOAD_POS)
+			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	/* Read the data back
+	 */
+	return nlm_hal_read_mac_reg(node, block, intf_type, INT_MDIO_RD_STAT + bus * 4);
+}
+
+/* Internal MDIO WRITE Routines
+ */
+/**
+* @brief nae_int_gmac_mdio_write function is used to write an SGMII PCS register.
+*
+* @param [in] node Node number
+* @param [in] bus Internal MDIO bus number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] intf_type GMAC_0, GMAC_1, GMAC_2, GMAC_3, XGMAC, INTERLAKEN, PHY, LANE_CFG (only valid for block 7)
+* @param [in] phyaddr Internal PHY's address
+* @param [in] regidx MDIO register index
+* @param [in] val Value to write
+*
+* @return
+* 	- 0 on success
+* 
+* @ingroup hal_nae
+*
+*/
+static int nae_int_gmac_mdio_write(int node, int bus, int block, int intf_type, int phyaddr, int regidx, uint16_t val)
+{
+	uint32_t mdio_ld_cmd = nlm_hal_read_mac_reg(node, block, intf_type, INT_MDIO_CTRL + bus * 4);
+
+	if (mdio_ld_cmd & INT_MDIO_CTRL_CMD_LOAD) {
+		nlm_hal_write_mac_reg(node, block, intf_type, INT_MDIO_CTRL + bus * 4,
+				       (mdio_ld_cmd & ~INT_MDIO_CTRL_CMD_LOAD));
+	}
+
+	/* load data into ctrl data reg
+	 */
+	nlm_hal_write_mac_reg(node, block, intf_type, INT_MDIO_CTRL_DATA + bus * 4, val);
+
+	nlm_hal_write_mac_reg(node, block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_SMP
+			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
+			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
+			       | (1 << INT_MDIO_CTRL_OP_POS)
+			       | (1 << INT_MDIO_CTRL_ST_POS)
+			       | (7 << INT_MDIO_CTRL_XDIV_POS)
+			       | (2 << INT_MDIO_CTRL_TA_POS)
+			       | (1 << INT_MDIO_CTRL_MIIM_POS)
+			       | (0 << INT_MDIO_CTRL_LOAD_POS)
+			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	nlm_hal_write_mac_reg(node, block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_SMP
+			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
+			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
+			       | (1 << INT_MDIO_CTRL_OP_POS)
+			       | (1 << INT_MDIO_CTRL_ST_POS)
+			       | (7 << INT_MDIO_CTRL_XDIV_POS)
+			       | (2 << INT_MDIO_CTRL_TA_POS)
+			       | (1 << INT_MDIO_CTRL_MIIM_POS)
+			       | (1 << INT_MDIO_CTRL_LOAD_POS)
+			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	/* poll master busy bit until it is not busy
+	 */
+	while(nlm_hal_read_mac_reg(node, block, intf_type,
+				    INT_MDIO_RD_STAT + bus * 4) & INT_MDIO_STAT_MBSY) {
+	}
+
+	nlm_hal_write_mac_reg(node, block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_SMP
+			       | (phyaddr << INT_MDIO_CTRL_PHYADDR_POS)
+			       | (regidx << INT_MDIO_CTRL_DEVTYPE_POS)
+			       | (1 << INT_MDIO_CTRL_OP_POS)
+			       | (1 << INT_MDIO_CTRL_ST_POS)
+			       | (7 << INT_MDIO_CTRL_XDIV_POS)
+			       | (2 << INT_MDIO_CTRL_TA_POS)
+			       | (1 << INT_MDIO_CTRL_MIIM_POS)
+			       | (0 << INT_MDIO_CTRL_LOAD_POS)
+			       | (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	return 0;
+}
+
+/**
+* @brief int_nae_gmac_mdio_reset function is used to reset an internal MDIO controller.
+*
+* @param [in] node Node number
+* @param [in] bus Internal MDIO bus number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] intf_type GMAC_0, GMAC_1, GMAC_2, GMAC_3, XGMAC, INTERLAKEN, PHY, LANE_CFG (only valid for block 7)
+*
+* @return
+* 	- 0 on success
+* 
+* @ingroup hal_nae
+*
+*/
+static int int_nae_gmac_mdio_reset(int node, int bus, int block, int intf_type)
+{
+	nlm_hal_write_mac_reg(node, block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       INT_MDIO_CTRL_RST |
+			       (7 << INT_MDIO_CTRL_XDIV_POS) 	|
+			       (1 << INT_MDIO_CTRL_MCDIV_POS));
+
+	nlm_hal_write_mac_reg(node, block, intf_type, INT_MDIO_CTRL + bus * 4,
+			       (7 << INT_MDIO_CTRL_XDIV_POS) 	|
+			       (1 << INT_MDIO_CTRL_MCDIV_POS));
+	return 0;
+}
+
+/**********************************************************************
+ *  nae_gmac_mdio_read - Read sgmii phy register
+ *
+ *  Input parameters:
+ *         bus          - bus number, nae has two external gmac bus: 0 and 1
+ *         phyaddr      - PHY's address
+ *         regidx       - index of register to read
+ *
+ *  Return value:
+ *         value read (16 bits), or 0xffffffff if an error occurred.
+ ********************************************************************* */
+/**
+* @brief nae_gmac_mdio_read function is used to read an SGMII PHY register.
+*
+* @param [in] node Node number
+* @param [in] bus External MDIO bus number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] intf_type GMAC_0, GMAC_1, GMAC_2, GMAC_3, XGMAC, INTERLAKEN, PHY, LANE_CFG (only valid for block 7)
+* @param [in] phyaddr External PHY's address
+* @param [in] regidx PHY register index to read
+*
+* @return
+*	- value read (16 bits), or 0xffffffff if an error occurred.
+* 
+* @ingroup hal_nae
+*
+*/
+static int nae_gmac_mdio_read(int node, int bus, int block, int intf_type, int phyaddr, int regidx)
+{
+	uint32_t mdio_ld_cmd = nlm_hal_read_mac_reg(node, block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4);
+
+	if (mdio_ld_cmd & EXT_G_MDIO_CMD_LCD) {
+		nlm_hal_write_mac_reg(node, block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
+				       (mdio_ld_cmd & ~EXT_G_MDIO_CMD_LCD));
+		while(nlm_hal_read_mac_reg(node, block, intf_type,
+					    EXT_G0_MDIO_RD_STAT + bus * 4) & EXT_G_MDIO_STAT_MBSY);
+	}
+
+	//nlm_print("[%s/%d] SENDING READ COMMAND \n", __func__, __LINE__);
+
+	nlm_hal_write_mac_reg(node, block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
+			       EXT_G_MDIO_CMD_SP
+			       | (phyaddr << EXT_G_MDIO_PHYADDR_POS)
+			       | (regidx << EXT_G_MDIO_REGADDR_POS)
+			       | (0<<18)
+				   | EXT_G_MDIO_DIV);
+
+	nlm_hal_write_mac_reg(node, block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
+			       EXT_G_MDIO_CMD_SP
+			       | (phyaddr << EXT_G_MDIO_PHYADDR_POS)
+			       | (regidx << EXT_G_MDIO_REGADDR_POS)
+			       | (1<<18)
+				   | EXT_G_MDIO_DIV);
+
+	/* poll master busy bit until it is not busy */
+	while(nlm_hal_read_mac_reg(node, block, intf_type,
+				    EXT_G0_MDIO_RD_STAT + bus * 4) & EXT_G_MDIO_STAT_MBSY) {
+		//nlm_print("[%d] EXT_G_MDIO_STAT_MBSY is SET!\n", __LINE__);
+	}
+
+	nlm_hal_write_mac_reg(node, block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
+			       EXT_G_MDIO_CMD_SP
+			       | (phyaddr << EXT_G_MDIO_PHYADDR_POS)
+			       | (regidx << EXT_G_MDIO_REGADDR_POS)
+			       | (0<<18)
+				   | EXT_G_MDIO_DIV);
+
+	//nlm_print("[%d] EXT_G_MDIO_STAT_MBSY CLEARED!\n", __LINE__);
+
+	/* Issue the read command */
+	//nlm_hal_write_mac_reg( block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,(1));
+	//nlm_print("[%s/%d] READ RETURNING...\n", __func__, __LINE__);
+
+	/* Read the data back */
+	return nlm_hal_read_mac_reg(node, block, intf_type, EXT_G0_MDIO_RD_STAT + bus * 4);
+}
+
+/**********************************************************************
+ *  nae_gmac_mdio_write -Write sgmac mii PHY register.
+ *
+ *  Input parameters:
+ *         bus          - bus number, nae has two external gmac bus: 0 and 1
+ *         phyaddr      - PHY to use
+ *         regidx       - register within the PHY
+ *         val          - data to write to register
+ *
+ *  Return value:
+ *         0 - success
+ ********************************************************************* */
+/**
+* @brief nae_gmac_mdio_write function is used to write an SGMII PHY register.
+*
+* @param [in] node Node number
+* @param [in] bus External MDIO bus number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] intf_type GMAC_0, GMAC_1, GMAC_2, GMAC_3, XGMAC, INTERLAKEN, PHY, LANE_CFG (only valid for block 7)
+* @param [in] phyaddr External PHY's address
+* @param [in] regidx PHY register index to read
+* @param [in] val Value to write
+*
+* @return
+* 	- 0 on success
+* 
+* @ingroup hal_nae
+*
+*/
+static int nae_gmac_mdio_write(int node, int bus, int block, int intf_type, int phyaddr, int regidx, uint16_t val)
+{
+	uint32_t mdio_ld_cmd = nlm_hal_read_mac_reg(node, block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4);
+
+	if (mdio_ld_cmd & EXT_G_MDIO_CMD_LCD) {
+		nlm_hal_write_mac_reg(node, block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
+				       (mdio_ld_cmd & ~EXT_G_MDIO_CMD_LCD));
+		while(nlm_hal_read_mac_reg(node, block, intf_type,
+					    EXT_G0_MDIO_RD_STAT + bus * 4) & EXT_G_MDIO_STAT_MBSY);
+	}
+
+	/* load data into ctrl data reg
+	 */
+	nlm_hal_write_mac_reg(node, block, intf_type, EXT_G0_MDIO_CTRL_DATA + bus * 4, val);
+
+	//nlm_print("[%s/%d] SENDING WRITE COMMAND \n", __func__, __LINE__);
+
+	nlm_hal_write_mac_reg(node, block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
+			       EXT_G_MDIO_CMD_SP 	|
+			       (phyaddr << EXT_G_MDIO_PHYADDR_POS) 	|
+			       (regidx << EXT_G_MDIO_REGADDR_POS)	|
+			       (0<<18)								|
+				   EXT_G_MDIO_DIV);
+
+	nlm_hal_write_mac_reg(node, block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
+			       EXT_G_MDIO_CMD_LCD | EXT_G_MDIO_CMD_SP 	|
+			       (phyaddr << EXT_G_MDIO_PHYADDR_POS) 	|
+			       (regidx << EXT_G_MDIO_REGADDR_POS)	|
+			       (0<<18)								|
+				   EXT_G_MDIO_DIV);
+
+	/* poll master busy bit until it is not busy */
+	while(nlm_hal_read_mac_reg(node, block, intf_type,
+				    EXT_G0_MDIO_RD_STAT + bus * 4) & EXT_G_MDIO_STAT_MBSY);
+
+	nlm_hal_write_mac_reg(node, block, intf_type, EXT_G0_MDIO_CTRL+ bus * 4,
+			       EXT_G_MDIO_CMD_SP 	|
+			       (phyaddr << EXT_G_MDIO_PHYADDR_POS) 	|
+			       (regidx << EXT_G_MDIO_REGADDR_POS)	|
+			       (0<<18)								|
+				   EXT_G_MDIO_DIV);
+
+	//nlm_print("[%s/%d] WRITE RETURNING...\n", __func__, __LINE__);
+	return 0;
+}
+
+/**********************************************************************
+ *  nae_gmac_mdio_reset -Reset sgmii mdio module.
+ *
+ *  Input parameters:
+ *         bus - bus number, nae has two external gmac bus: 0 and 1
+ *
+ *  Return value:
+ *        0 - success
+ ********************************************************************* */
+/**
+* @brief nae_gmac_mdio_reset function is used to reset an external MDIO controller.
+*
+* @param [in] node Node number
+* @param [in] bus External MDIO bus number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] intf_type GMAC_0, GMAC_1, GMAC_2, GMAC_3, XGMAC, INTERLAKEN, PHY, LANE_CFG (only valid for block 7)
+*
+* @return
+* 	- 0 on success
+* 
+* @ingroup hal_nae
+*
+*/
+static int nae_gmac_mdio_reset(int node, int bus, int block, int intf_type)
+{
+	nlm_hal_write_mac_reg(node, block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
+			       EXT_G_MDIO_MMRST | EXT_G_MDIO_DIV);
+	nlm_hal_write_mac_reg(node, block, intf_type, EXT_G0_MDIO_CTRL + bus * 4,
+			       EXT_G_MDIO_DIV);
+	return 0;
+}
+
+/**
+* @brief nlm_hal_mdio_read function is used to read a register through MDIO.
+*
+* @param [in] node Node number
+* @param [in] type NLM_HAL_INT_MDIO or NLM_HAL_EXT_MDIO
+* @param [in] bus MDIO bus number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] intf_type GMAC_0, GMAC_1, GMAC_2, GMAC_3, XGMAC, INTERLAKEN, PHY, LANE_CFG (only valid for block 7)
+* @param [in] phyaddr PHY's address
+* @param [in] regidx PHY register index to read
+*
+* @return
+*	- value read (16 bits), or 0xffffffff if an error occurred.
+*	- -1: Invalid type
+* 
+* @ingroup hal_nae
+*
+*/
+int nlm_hal_mdio_read(int node, int type, int bus,int block, int intf_type,
+		      int phyaddr, int regidx)
+{
+	if (type == NLM_HAL_INT_MDIO) {
+		return nae_int_gmac_mdio_read(node, bus, block, intf_type,
+					      phyaddr, regidx);
+	} else if (type == NLM_HAL_EXT_MDIO) {
+		return nae_gmac_mdio_read(node, bus, block, intf_type,
+					  phyaddr, regidx);
+	} else {
+		nlm_print("NAE_ERROR: Invalid type for MDIO read !!\n");
+		return -1;
+	}
+}
+
+/**
+* @brief nlm_hal_mdio_write function is used to write a register through MDIO.
+*
+* @param [in] node Node number
+* @param [in] type NLM_HAL_INT_MDIO or NLM_HAL_EXT_MDIO
+* @param [in] bus MDIO bus number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] intf_type GMAC_0, GMAC_1, GMAC_2, GMAC_3, XGMAC, INTERLAKEN, PHY, LANE_CFG (only valid for block 7)
+* @param [in] phyaddr PHY's address
+* @param [in] regidx PHY register index to read
+* @param [in] val Value to write
+*
+* @return
+*	- 0 on success
+*	- -1: Invalid type
+* 
+* @ingroup hal_nae
+*
+*/
+int nlm_hal_mdio_write(int node, int type, int bus, int block, int intf_type,
+		       int phyaddr, int regidx, uint16_t val)
+{
+	if (type == NLM_HAL_INT_MDIO) {
+		return nae_int_gmac_mdio_write(node, bus, block, intf_type,
+					       phyaddr, regidx, val);
+	} else if (type == NLM_HAL_EXT_MDIO) {
+		return nae_gmac_mdio_write(node, bus, block, intf_type,
+					   phyaddr, regidx, val);
+	} else {
+		nlm_print("NAE_ERROR: Invalid type for MDIO write !!\n");
+		return -1;
+	}
+}
+
+/**
+* @brief nlm_hal_mdio_reset function is used to reset an MDIO controller.
+*
+* @param [in] node Node number
+* @param [in] type NLM_HAL_INT_MDIO or NLM_HAL_EXT_MDIO
+* @param [in] bus MDIO bus number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] intf_type GMAC_0, GMAC_1, GMAC_2, GMAC_3, XGMAC, INTERLAKEN, PHY, LANE_CFG (only valid for block 7)
+*
+* @return
+*	- 0 on success
+*	- -1: Invalid type
+* 
+* @ingroup hal_nae
+*
+*/
+int nlm_hal_mdio_reset(int node, int type, int bus, int block, int intf_type)
+{
+	if (type == NLM_HAL_INT_MDIO) {
+		return int_nae_gmac_mdio_reset(node, bus, block, intf_type);
+
+	} else if (type == NLM_HAL_EXT_MDIO) {
+		return nae_gmac_mdio_reset(node, bus, block, intf_type);
+
+	} else {
+		nlm_print("NAE_ERROR: Invalid type for MDIO reset !!\n");
+		return -1;
+	}
+}
+
+#if 0
+/**********************************************************************
+ *  nae_xgmac_mdio_read - Read xgmac phy register
+ *
+ *  Input parameters:
+ *         bus          - bus number, nae has two external xgmac bus: 0 and 1
+ *         phyaddr      - PHY's address
+ *         regidx       - index of register to read
+ *
+ *  Return value:
+ *         value read (16 bits), or 0xffffffff if an error occurred.
+ ********************************************************************* */
+static int nae_xgmac_mdio_read(int bus,int block, int intf_type, int phyaddr, int regidx)
+{
+
+        nlm_hal_write_mac_reg( block, intf_type, EXT_XG0_MDIO_CTRL + bus * 4,
+			       phyaddr<<EXT_XG_MDIO_CTRL_PHYADDR_POS
+			       | 1<<EXT_XG_MDIO_CTRL_MCDIV_POS
+			       | EXT_XG_MDIO_CTRL_CMD_LOAD
+			       | 1<<EXT_XG_MDIO_CTRL_MIIM_POS
+			       | 0x2<<EXT_XG_MDIO_CTRL_TA_POS
+			       | MDIO_OP_CMD_READ<<2);
+
+        /* poll master busy bit until it is not busy */
+        while(nlm_hal_read_mac_reg( block, intf_type,
+				    EXT_XG0_MDIO_RD_STAT + bus * 4) & EXT_XG_MDIO_STAT_MBSY);
+
+        return nlm_hal_read_mac_reg( block, intf_type,
+				     EXT_XG0_MDIO_CTRL_DATA + bus * 4) & 0xFFFF;
+}
+/**********************************************************************
+ *  nae_xgmac_mdio_write -Write xgmac mii PHY register.
+ *
+ *  Input parameters:
+ *         bus          - bus number, nae has two external xgmac bus: 0 and 1
+ *         phyaddr      - PHY to use
+ *         regidx       - register within the PHY
+ *         val          - data to write to register
+ *
+ *  Return value:
+ *         0 - success
+ ********************************************************************* */
+static int nae_xgmac_mdio_write(int bus, int block, int intf_type, int phyaddr, int regidx, int16_t val)
+{
+        /* load data to INT_MDIO_CTRL_DATA register*/
+        nlm_hal_write_mac_reg( block, intf_type,
+			       EXT_XG0_MDIO_CTRL_DATA+ bus * 4, val);
+
+        nlm_hal_write_mac_reg( block, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+			       phyaddr<<EXT_XG_MDIO_CTRL_PHYADDR_POS
+			       | 1<<EXT_XG_MDIO_CTRL_MCDIV_POS
+			       | EXT_XG_MDIO_CTRL_CMD_LOAD
+			       | 1<<EXT_XG_MDIO_CTRL_MIIM_POS
+			       | 0x2<<EXT_XG_MDIO_CTRL_TA_POS
+			       | MDIO_OP_CMD_WRITE<<2);
+
+        /* poll master busy bit until it is not busy */
+        while(nlm_hal_read_mac_reg( block, intf_type,
+				    EXT_XG0_MDIO_RD_STAT + bus * 4 )& EXT_XG_MDIO_STAT_MBSY);
+
+        return 0;
+}
+
+/**********************************************************************
+ *  nae_xgmac_mdio_reset -Reset sgmii PHY.
+ *
+ *  Input parameters:
+ *         bus - bus number, nae has two external xgmac bus: 0 and 1
+ *
+ *  Return value:
+ *        0 - success
+ ********************************************************************* */
+static int nae_xgmac_mdio_reset(int bus, int block, int intf_type)
+{
+        nlm_hal_write_mac_reg( block, intf_type,
+			       EXT_XG0_MDIO_CTRL + bus * 4,
+			       EXT_XG_MDIO_CTRL_RST);
+        return 0;
+}
+
+/**********************************************************************
+ *  nae_gmac_internal_mdio_read - Read internal mdio phy bus
+ *
+ *  Input parameters:
+ *         phyaddr      - PHY's address
+ *         regidx       - index of register to read
+ *
+ *  Return value:
+ *         value read (16 bits), or 0xffffffff if an error occurred.
+ ********************************************************************* */
+static int nae_gmac_internal_mdio_read(int block, int intf_type, int phyaddr, int regidx)
+{
+
+        nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL,
+			       phyaddr<<INT_MDIO_CTRL_PHYADDR_POS
+			       | 1<<INT_MDIO_CTRL_MCDIV_POS
+			       |INT_MDIO_CTRL_CMD_LOAD
+			       | 1<<INT_MDIO_CTRL_MIIM_POS
+			       | 0x2<<INT_MDIO_CTRL_TA_POS
+			       | MDIO_OP_CMD_READ<<2);
+
+        /* poll master busy bit until it is not busy */
+        while(nlm_hal_read_mac_reg( block, intf_type,
+				    INT_MDIO_RD_STAT) & INT_MDIO_STAT_MBSY);
+
+        return nlm_hal_read_mac_reg( block, intf_type,INT_MDIO_CTRL_DATA) & 0xFFFF;
+}
+
+/**********************************************************************
+ *  nae_gmac_internal_mdio_write -Write internal gmac mii PHY register.
+ *
+ *  Input parameters:
+ *         phyaddr      - PHY to use
+ *         regidx       - register within the PHY
+ *         val          - data to write to register
+ *
+ *  Return value:
+ *         0 - success
+ ********************************************************************* */
+static int nae_gmac_internal_mdio_write(int block, int intf_type, int phyaddr, int regidx, int16_t val)
+{
+
+        /* load data to INT_MDIO_CTRL_DATA register*/
+        nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL_DATA, val);
+        nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL,
+			       phyaddr<<INT_MDIO_CTRL_PHYADDR_POS
+			       | 1<<INT_MDIO_CTRL_MCDIV_POS
+			       |INT_MDIO_CTRL_CMD_LOAD
+			       | 1<<INT_MDIO_CTRL_MIIM_POS
+			       | 0x2<<INT_MDIO_CTRL_TA_POS
+			       | MDIO_OP_CMD_WRITE<<2);
+
+        /* poll master busy bit until it is not busy */
+        while(nlm_hal_read_mac_reg( block, intf_type,
+				    INT_MDIO_RD_STAT) & INT_MDIO_STAT_MBSY);
+
+        return 0;
+}
+
+/**********************************************************************
+ *  nae_gmac_internal_mdio_reset -Reset internal gmac PHY register.
+ *
+ *  Input parameters:
+ *
+ *  Return value:
+ *        0 - success
+ ********************************************************************* */
+static int nae_gmac_internal_mdio_reset(int block, int intf_type)
+{
+        nlm_hal_write_mac_reg( block, intf_type, INT_MDIO_CTRL, INT_MDIO_CTRL_RST);
+        return 0;
+}
+#endif
+
+
+// PLL 
+
+
+/**********************************************************************
+ *  nae_lane_reset_txpll
+ * * serdes lane progaming 
+ ********************************************************************* */
+
+/**
+* @brief xlp3xx_8xxb0_nae_lane_reset_txpll function is used to reset the Tx PLL for XLP3XX and XLP8XX-B0 products.
+*
+* @param [in] node Node number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] lane_ctrl Lane to reset (0-3)
+* @param [in] mode 0-unused, 1-XAUI, 2-SGMII, 3-INTERLAKEN
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+void xlp3xx_8xxb0_nae_lane_reset_txpll(int node, int block, int lane_ctrl, int mode)
+{
+	uint32_t val = 0;
+	int rext_sel = 0;
+	NAE_DEBUG("%s: block %d lane_ctrl %x \n",__func__,block,lane_ctrl);
+
+	if(lane_ctrl != 4)
+		rext_sel = (1 << 23);
+		
+	NAE_DEBUG("Before register reset de-assertion PMA value=0x%x\n", nlm_hal_read_mac_reg( node, block, PHY, lane_ctrl));
+
+	val = nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl);
+	if(mode != PHYMODE_SGMII){
+		val |= PHY_LANE_CTRL_BPC_XAUI; /*Set comma bypass for XAUII*/
+	}
+	val |= 0x100000 | (mode << PHY_LANE_CTRL_PHYMODE_POS);  /* Bit20: serdes reg reset Storm & Eagle B0 */
+	val &= ~(0x20000);
+        nlm_hal_write_mac_reg(node, block, PHY, lane_ctrl,val);
+		
+	val = nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl);
+	val |= 0x40000000; /* Unset the reset (inverse logic) : Bit30: epcs reset */
+        nlm_hal_write_mac_reg(node, block, PHY, lane_ctrl,val);
+	NAE_DEBUG(" After serdes  de-assertion PMA value=0x%x\n", nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl));
+
+
+	/* Clear the Power Down bit */
+	val = nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl);
+	val &= ~( (1 << 29) | (0x7ffff));
+	nlm_hal_write_mac_reg(node, block, PHY, lane_ctrl, (rext_sel | val));
+
+	NAE_DEBUG("Reset PLL done \n");
+}
+
+
+/**
+* @brief xlp8xx_ax_nae_lane_reset_txpll function is used to reset the Tx PLL for XLP8XX-AX products.
+*
+* @param [in] node Node number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] lane_ctrl Lane to reset (0-3)
+* @param [in] mode 0-unused, 1-XAUI, 2-SGMII, 3-INTERLAKEN
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+void xlp8xx_ax_nae_lane_reset_txpll(int node, int block, int lane_ctrl, int mode)
+{
+        uint32_t val = 0, saved_data;
+        int rext_sel = 0;
+	
+	val = PHY_LANE_CTRL_RST | PHY_LANE_CTRL_PWRDOWN | (mode << PHY_LANE_CTRL_PHYMODE_POS);
+
+	if(mode != PHYMODE_SGMII){
+                val |= PHY_LANE_CTRL_BPC_XAUI; /*Set comma bypass for XAUII*/
+        }
+
+	nlm_hal_write_mac_reg(node, block, PHY, lane_ctrl,  val);
+
+	if (lane_ctrl != 4) {
+		int i;
+		rext_sel = (1 << 23);
+
+		if(mode != PHYMODE_SGMII){
+			rext_sel |= PHY_LANE_CTRL_BPC_XAUI;
+		}
+
+		val = nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl);
+		val &= ~PHY_LANE_CTRL_RST; /* Set the reset (inverse logic) */
+		val |= rext_sel;
+
+		/* Resetting PMA for non-zero lanes */
+		nlm_hal_write_mac_reg(node, block, PHY, lane_ctrl,val);
+
+		for (i=0; i< 0x100000; ++i)
+			; /* empty loop */
+
+		val |= PHY_LANE_CTRL_RST; /* Unset the reset (inverse logic) */
+		nlm_hal_write_mac_reg(node, block, PHY, lane_ctrl,val);
+
+		val = 0;
+	}
+
+	/* Come out of reset for TXPLL */
+#if 0
+	saved_data = nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl) & 0xFFC00000;
+#else
+	saved_data = nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl) & 0xFFC00000;
+#endif
+
+	nlm_hal_write_mac_reg(node, block, PHY, lane_ctrl,         (0x66 << PHY_LANE_CTRL_ADDR_POS)
+			       | PHY_LANE_CTRL_CMD_READ
+			       | PHY_LANE_CTRL_CMD_START
+			       | PHY_LANE_CTRL_RST
+			       | rext_sel
+			       | val );
+	while (((val = nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl)) & PHY_LANE_CTRL_CMD_PENDING));
+	val &= 0xFF;
+
+	/* set bit[4] to 0
+	 */
+	val &= ~(1 << 4);
+	nlm_hal_write_mac_reg(node, block, PHY, lane_ctrl,   (0x66 << PHY_LANE_CTRL_ADDR_POS)
+			       | PHY_LANE_CTRL_CMD_WRITE
+			       | PHY_LANE_CTRL_CMD_START
+			       | (0x0 << 19) /* (0x4 << 19) */
+			       | rext_sel
+			       | saved_data
+			       | val );
+	/* re-do */
+	nlm_hal_write_mac_reg(node, block, PHY, lane_ctrl,   (0x66 << PHY_LANE_CTRL_ADDR_POS)
+			       | PHY_LANE_CTRL_CMD_WRITE
+			       | PHY_LANE_CTRL_CMD_START
+			       | (0x0 << 19) /* (0x4 << 19) */
+			       | rext_sel
+			       | saved_data
+			       | val );
+
+	while(!((val = nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl-PHY_LANE_0_CTRL)) & PHY_LANE_STAT_PCR));
+
+	/* Clear the Power Down bit */
+	val = nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl);
+	val &= ~( (1 << 29) | (0x7ffff));
+	nlm_hal_write_mac_reg(node, block, PHY, lane_ctrl, (rext_sel | val));
+}
+
+
+/*
+  cplx configuration needed to be parsed from fdt tree and set at the time
+  before xlp_nae_config_lane_gmac can be called
+*/
+/**********************************************************************
+ *  nae_config_lane_gmac
+ *
+ ********************************************************************* */
+/**
+* @brief xlp_nae_config_lane_gmac function is used to configure lanes in SGMII mode.
+*
+* @param [in] node Node number
+* @param [in] cplx_mask Mask of complexes to configure (possible in XLP832: 0x1F)
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+static void xlp_nae_config_lane_gmac(int node, int cplx_mask)
+{
+	int block, lane_ctrl;
+	int cplx_lane_enable = LM_SGMII | (LM_SGMII << 4) | (LM_SGMII << 8) | (LM_SGMII << 12);
+	int lane_enable = 0;
 
+	/*  Lane mode progamming
+	 */
+	block = 7;
+	/* Complexes 0, 1 */
+	if (cplx_mask & 0x1) {
+		lane_enable |= cplx_lane_enable;
+	}
+	if (cplx_mask & 0x2) {
+		lane_enable |= (cplx_lane_enable << 16);
+	}
+	if (lane_enable) {
+		nlm_hal_write_mac_reg(node, block, LANE_CFG, LANE_CFG_CPLX_0_1,  lane_enable);
+		lane_enable = 0;
+	}
+	
+	NAE_DEBUG("xlp_nae_config_lane_gmac with cplx_mask=0x%x and config=0x%x\n",cplx_mask ,nlm_hal_read_mac_reg(node, block, LANE_CFG, LANE_CFG_CPLX_0_1));
+	/* Complexes 2 3 */
+	if (cplx_mask & 0x4) {
+		lane_enable |= cplx_lane_enable;
+	}
+	if (cplx_mask & 0x8) {
+		lane_enable |= (cplx_lane_enable << 16);
+	}
+	nlm_hal_write_mac_reg(node, block, LANE_CFG, LANE_CFG_CPLX_2_3, lane_enable);
+	
+	/*complex 4*/
+	if(cplx_mask & 0x10){
+		nlm_hal_write_mac_reg(node, block, LANE_CFG, LANE_CFG_CPLX_4, LM_SGMII << 4 | LM_SGMII);	
+		block = 4;
+		for( lane_ctrl = PHY_LANE_0_CTRL; lane_ctrl <= PHY_LANE_1_CTRL; lane_ctrl++)
+		{
+			if (is_nlm_xlp8xx_b0()) {
+				xlp3xx_8xxb0_nae_lane_reset_txpll(node, block, lane_ctrl, PHYMODE_SGMII);
+			} else {
+				xlp8xx_ax_nae_lane_reset_txpll(node, block, lane_ctrl, PHYMODE_SGMII);
+			}
+		}
+	}	
+
+	for( block = 0; block < 4; block++)
+	{
+		if ((cplx_mask & (1 << block)) == 0) {
+			continue;
+		}
+
+		for( lane_ctrl = PHY_LANE_0_CTRL; lane_ctrl <= PHY_LANE_3_CTRL; lane_ctrl++){
+			if ((is_nlm_xlp3xx()) || (is_nlm_xlp8xx_b0())) {
+				xlp3xx_8xxb0_nae_lane_reset_txpll(node, block, lane_ctrl, PHYMODE_SGMII);
+			}else{
+				xlp8xx_ax_nae_lane_reset_txpll(node, block, lane_ctrl, PHYMODE_SGMII);
+		}	}
+	}
+	return;
+}
+
+/**
+* @brief nlm_hal_sgmii_pcs_init function resets MDIOs, scans external PHYs, and configures lanes in SGMII mode.
+*
+* @param [in] node Node number
+* @param [in] sgmii_cplx_mask Complex mask to configure in SGMII mode (possible in XLP832: 0x1F)
+*
+* @return
+*       - none
+*
+* @ingroup hal_nae
+*
+*/
+void nlm_hal_sgmii_pcs_init(int node, int sgmii_cplx_mask)
+{
+        nlm_hal_mdio_reset(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG);
+        nlm_print("Net:   Reset Internal MDIO\n");
+        nlm_hal_mdio_reset(node, NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG);
+        nlm_hal_mdio_reset(node, NLM_HAL_EXT_MDIO, 1, BLOCK_7, LANE_CFG);
+        nlm_print("Net:   Reset External MDIO\n");
+        nlm_print("Net:   Reset External MDIO\n");
+#if !defined(XLP_SIM) || defined(NLM_BOARD)
+        sgmii_scan_phys(node);
+#endif
+        xlp_nae_config_lane_gmac(node, sgmii_cplx_mask);
+        nlm_print("Net:   Completed PCS Configuration\n");
+}
+
+
+
+/**
+* @brief nlm_hal_config_sgmii_if function configures an SGMII interface to the correct speed and mode.
+*
+* @param [in] node Node number
+* @param [in] inf Interface number
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+void nlm_hal_config_sgmii_if(int node, int inf)
+{
+	unsigned int mac_cfg1 = 0, mac_cfg2 = 0;
+	unsigned int netwk_inf = 0;
+	unsigned int ifmode, speed, duplex;
+	struct nlm_hal_ext_phy *this_phy=NULL;
+
+
+	// Disable TX , Rx for now
+	mac_cfg1 = read_gmac_reg(node, inf, MAC_CONF1);
+	write_gmac_reg(node, inf , MAC_CONF1, mac_cfg1 & ~(0x5));
+	netwk_inf = read_gmac_reg(node, inf, NETWK_INF_CTRL_REG);
+	write_gmac_reg(node, inf ,NETWK_INF_CTRL_REG, netwk_inf &  (~(1<<2)));
+
+	/*Verify whether inf is registered intf*/
+	this_phy = get_phy_info(inf);
+	if(!this_phy){
+		nlm_print("Interface is not registered. Interface PHY-addr mismatch\n");
+		return;
+	}
+#if !defined(XLP_SIM) || defined(NLM_BOARD)
+	// Enable auto negotiation on PHY side
+	nlm_hal_ext_phy_an(node, inf);
+
+	// Read PHY status from extended status
+	nlm_hal_get_phy_status(node, inf, &speed, &duplex);
+
+#else
+	speed = SPEED_1000M;
+	duplex = 1;
+#endif
+	ifmode = ((speed == SPEED_1000M) ? INF_BYTE_MODE : INF_NIBBLE_MODE);
+
+	// Configure negotiated speed and mode
+        netwk_inf  = read_gmac_reg(node, inf, NETWK_INF_CTRL_REG);
+        netwk_inf &= (~(0x3));
+	write_gmac_reg(node, inf , NETWK_INF_CTRL_REG, netwk_inf | SPEED(speed));
+
+        mac_cfg2 = read_gmac_reg(node, inf, MAC_CONF2);
+        mac_cfg2 &= (~(0x3 << 8));
+	write_gmac_reg(node, inf , MAC_CONF2,
+			       mac_cfg2            |
+			       INF_IFMODE(ifmode)     |
+			       INF_FULLDUP(duplex));
+
+	// Clear statistics counters
+        netwk_inf  = read_gmac_reg(node, inf, NETWK_INF_CTRL_REG);
+        write_gmac_reg(node, inf , NETWK_INF_CTRL_REG, netwk_inf | (1<<15));
+
+	// Enable statistics counters
+	netwk_inf  = read_gmac_reg(node, inf, NETWK_INF_CTRL_REG);
+	write_gmac_reg(node, inf , NETWK_INF_CTRL_REG, (netwk_inf & (~(1<<15))) | (1 << 16));
+
+        mac_cfg1 = read_gmac_reg(node, inf, MAC_CONF1);
+        write_gmac_reg(node, inf , MAC_CONF1, mac_cfg1 | (0x3 << 4));
+}
+
+/*
+ *  Ucore support
+ */
+/**
+* @brief nlm_hal_load_ucore function is used to program NAE uCores.
+*
+* @param [in] node Node number
+* @param [in] ucore_mask Mask of uCores to program
+* @param [in] opcodes Pointer to array of opcode values
+* @param [in] num_opcodes Number of opcodes
+*
+* @return
+* 	- 0 on success
+* 
+* @ingroup hal_nae
+*
+*/
+int nlm_hal_load_ucore(int node, int ucore_mask, unsigned int *opcodes, int num_opcodes)
+{
+	int mask = ucore_mask & NAE_UCORE_MASK;
+	unsigned int id = 0;
+	int i;
+
+	while (id < MAX_NAE_UCORES) {
+
+		if ((mask & (1 << id)) == 0) {
+			id++;
+			continue;
+		}
+
+		for (i=0; i < num_opcodes; ++i) {
+			nlm_hal_write_ucode(node, id, (i * 4), opcodes[i]);
+		}
+		id++;
+	}
+	return 0;
+}
+
+/**
+* @brief init_egress function is used to initialize the NAE uCore spray mask to the default value.
+*
+* @param [in] node Node number
+* @param [in] if_num Interface number
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+static void init_ucore(int node, int if_num)
+{
+
+	if(is_nlm_xlp3xx()){
+		nlm_hal_write_nae_reg(node, UCORE_IFACE_MASK_CFG,
+                              ucore_spray_config(if_num, 0xff, CMD_WRITE));
+	}
+	else {
+		nlm_hal_write_nae_reg(node, UCORE_IFACE_MASK_CFG,
+			      ucore_spray_config(if_num, 0xffff, CMD_WRITE));
+	}
+}
+
+/**
+* @brief nlm_hal_write_ucore_shared_mem function is used to write the shared memory of the NAE uCores.
+*
+* @param [in] data Pointer to the 32-bit data
+* @param [in] words Number of words of data to write
+*
+* @return
+*  - 0 on success
+* 
+* @ingroup hal_nae
+*
+*/
 int nlm_hal_write_ucore_shared_mem(unsigned int *data, int words)
 {
 	int i = 0;
@@ -54,26 +1098,47 @@ int nlm_hal_write_ucore_shared_mem(unsigned int *data, int words)
  * Temporary direct ucore configuration. HAL needs to support stop and restart
  * of ucores before reloading code
  */
-static int local_load_ucore(int ucore_mask, unsigned int *opcodes, int num_opcodes)
+/**
+* @brief local_load_ucore function is used to load the instruction memory of the NAE uCores.
+*
+* @param [in] node Node number
+* @param [in] ucore_mask Mask of uCores to load (possible in XLP832: 0xffff)
+* @param [in] opcodes Pointer to opcodes
+* @param [in] num_opcodes Number of opcodes to write
+*
+* @return
+*  - 0 on success
+* 
+* @ingroup hal_nae
+*
+*/
+static int local_load_ucore(int node, int ucore_mask, unsigned int *opcodes, int num_opcodes)
 {
 	int mask = ucore_mask & NAE_UCORE_MASK;
 	unsigned int id = 0;
-	int write_cmd = 1;
-	int i;
+	int i, max_ucore;
 	volatile uint32_t ucore_cfg = 0;
 
+	NAE_DEBUG("node %d: ucore_mask 0x%x num_opcodes %d\n",node, ucore_mask, num_opcodes);
 	/* Stop all ucores */
+#ifndef UCORE_POE_BYPASS
 	if (nae_reset_done == 0) { /* Skip the Ucore reset if NAE reset is done */
+#else
+	if (is_nlm_xlp8xx_b0()) {
+#endif
 		nlm_print("Stopping and Resetting all ucore...\n");
 
-		ucore_cfg = nlm_hal_read_nae_reg(RX_UCORE_CFG);
-		nlm_hal_write_nae_reg(RX_UCORE_CFG, ucore_cfg | (1 << 24));
-
-		nlm_hal_write_nae_reg(UCORE_IFACE_MASK_CFG, ucore_spray_config(16, 0, write_cmd));
+		ucore_cfg = nlm_hal_read_nae_reg(node, RX_UCORE_CFG);
+#ifndef	UCORE_POE_BYPASS
+		nlm_hal_write_nae_reg(node, RX_UCORE_CFG, ucore_cfg | (1 << 24));
+#else
+		ucore_cfg &= (~VAL_UCORE_RESET(ucore_mask));
+		nlm_hal_write_nae_reg(node, RX_UCORE_CFG, ucore_cfg | (1 << 24) | (1<<28));
+#endif
 
 		/* poll for ucore to get in to a wait state */
 		for(;;) {
-			ucore_cfg = nlm_hal_read_nae_reg(RX_UCORE_CFG);
+			ucore_cfg = nlm_hal_read_nae_reg(node, RX_UCORE_CFG);
 			if (ucore_cfg & (1 << 25)) break;
 		}
 		nlm_print("Ucore Reset Complete\n");
@@ -81,7 +1146,14 @@ static int local_load_ucore(int ucore_mask, unsigned int *opcodes, int num_opcod
 
 	nlm_print("Loading ucores (mask = 0x%04x)\n", mask);
 
-	while (id < MAX_NAE_UCORES) {
+	if (is_nlm_xlp3xx()) {
+                max_ucore = XLP_3XX_MAX_NAE_UCORES;
+        }
+        else {
+                max_ucore = MAX_NAE_UCORES;
+        }
+
+	while (id < max_ucore) {
 
 		if ((mask & (1 << id)) == 0) {
 			id++;
@@ -89,58 +1161,71 @@ static int local_load_ucore(int ucore_mask, unsigned int *opcodes, int num_opcod
 		}
 
 		for (i=0; i < num_opcodes; ++i) {
-			nlm_hal_write_ucode(id, (i * 4), opcodes[i]);
+			nlm_hal_write_ucode(node, id, (i * 4), opcodes[i]);
 		}
 		if(num_opcodes & 0x1){
 			/* Add 'nop' if total number of instructions are odd */
-			nlm_hal_write_ucode(id, (i * 4), 0x0);
+			nlm_hal_write_ucode(node, id, (i * 4), 0x0);	
 		}
 		id++;
 	}
 	/* Download u-core shared memory data*/
 	if(ucore_shared_scratch_words){
-		ucore_cfg = nlm_hal_read_nae_reg(RX_UCORE_CFG);
+		ucore_cfg = nlm_hal_read_nae_reg(node, RX_UCORE_CFG);	
 		/*set iram to 0*/
-		nlm_hal_write_nae_reg(RX_UCORE_CFG, ucore_cfg & ~(1<<7));
+		nlm_hal_write_nae_reg(node, RX_UCORE_CFG, ucore_cfg & ~(1<<7));
 		for (i=0; i<ucore_shared_scratch_words; ++i) {
-			nlm_hal_write_ucode(0, (i * 4), ucore_shared_scratch[i]);
+			nlm_hal_write_ucode(node, 0, (i * 4), ucore_shared_scratch[i]);
 		}
 		/*restore ucore_cfg*/
-		nlm_hal_write_nae_reg(RX_UCORE_CFG, ucore_cfg);
+		nlm_hal_write_nae_reg(node, RX_UCORE_CFG, ucore_cfg);
 	}
 
 	/* Enable per-domain ucores */
-        ucore_cfg = nlm_hal_read_nae_reg(RX_UCORE_CFG);
+        ucore_cfg = nlm_hal_read_nae_reg(node, RX_UCORE_CFG);
 
 	/* write one to reset bits to put the ucores in reset */
 	ucore_cfg = ucore_cfg | (VAL_UCORE_RESET(ucore_mask));
-        nlm_hal_write_nae_reg(RX_UCORE_CFG, ucore_cfg);
+        nlm_hal_write_nae_reg(node, RX_UCORE_CFG, ucore_cfg);
 
 	/* write zero to reset bits to pull them out of reset */
 	ucore_cfg = ucore_cfg & (~VAL_UCORE_RESET(ucore_mask)) & ~(1 << 24);
-        nlm_hal_write_nae_reg(RX_UCORE_CFG, ucore_cfg);
+        nlm_hal_write_nae_reg(node, RX_UCORE_CFG, ucore_cfg);
 
-	nlm_hal_write_nae_reg(UCORE_IFACE_MASK_CFG, ucore_spray_config(16, 0xffff, write_cmd));
 	return 0;
 }
 
 #define UCORE_SRC_NODE(id) "/soc/nae-cfg/ucore/src@"#id
 
 /* Currently only one microcore cfile (given under src@1 node is supported */
-#define GET_UCORE_PROP(prop, buf, len)					\
-	copy_fdt_prop(fdt, UCORE_SRC_NODE(1), prop, PROP_CELL, buf, len)
+#define GET_UCORE_PROP(path_str, prop, buf, len)					\
+	copy_fdt_prop(fdt, path_str, prop, PROP_CELL, buf, len)
 
 /* Currently only suports only one Ucore file across all ucores */
-static void parse_ucore_config(void *fdt)
+/**
+* @brief parse_ucore_config function is used to initailize and program the NAE uCores based on the configuration in FDT.
+*
+* @param [in] fdt Pointer to the FDT
+* @param [in] node Node number
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+static void parse_ucore_config(void *fdt, int node)
 {
 	int size = 0;
 	unsigned int *uc_opcodes;
 	uint32_t uc_mask = 0, num_opcodes = 0;
+	char path_str[50];
 
+	sprintf(path_str, "/soc/nae@node-%d/ucore/src@%d",node, 1);
 	/* Domain specific ucore mask */
-	GET_UCORE_PROP("mask", &uc_mask, sizeof(uint32_t));
-
-	GET_UCORE_PROP("num-opcodes", &num_opcodes, sizeof(uint32_t));
+	GET_UCORE_PROP(path_str, "mask", &uc_mask, sizeof(uint32_t));
+	nlm_print("UCORE MASK 0x%x\n",uc_mask);
+	GET_UCORE_PROP(path_str, "num-opcodes", &num_opcodes, sizeof(uint32_t));
 
 	size = sizeof(uint32_t) * num_opcodes;
 	uc_opcodes = nlm_malloc(size);
@@ -149,80 +1234,450 @@ static void parse_ucore_config(void *fdt)
 		return;
 	}
 
-	GET_UCORE_PROP("opcodes", uc_opcodes, size);
+	GET_UCORE_PROP(path_str, "opcodes", uc_opcodes, size);
 
-	local_load_ucore(uc_mask, (unsigned int *)uc_opcodes, num_opcodes);
+	local_load_ucore(node, uc_mask, (unsigned int *)uc_opcodes, num_opcodes);
 
 	nlm_free(uc_opcodes);
 }
 
 #define POE_NODE "/soc/nae-cfg/poe/regs"
-#define GET_POE_PROP(prop, buf, len)					\
-	copy_fdt_prop(fdt, POE_NODE, prop, PROP_CELL, buf, len)
+#define GET_POE_PROP(path_str, prop, buf, len)					\
+	copy_fdt_prop(fdt, path_str, prop, PROP_CELL, buf, len)
 
 #define POE_MAX_LOC_32BIT_CHUNKS 192
-static void init_poe_loc_msg_storage(void)
+
+/**
+* @brief nlm_hal_init_poe_ext_storage function is used to initialize the POE memory spaces for message and FreeBuffer storage.
+*
+* @param [in] node Node number
+* @param [in] fbp_base_phys Physical address of the start of FreeBuffer storage in DRAM
+* @param [in] msg_base_phys Physical address of the start of message storage in DRAM
+* @param [in] msg_base_virt Virtual address of the start of message storage in DRAM
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+void nlm_hal_init_poe_ext_storage(int node, uint64_t fbp_base_phys,
+				  uint64_t msg_base_phys,
+	                          uint64_t msg_base_virt)
+{
+	uint32_t addr, num_messages;
+	uint64_t ldata, a;
+	uint64_t *vaddr;
+	int i;
+	uint32_t mbase_hi, mbase_lo, fbp_hi, fbp_lo;
+	mbase_hi = (msg_base_phys >> 32) & 0xffffffff;
+	mbase_lo = msg_base_phys & 0xffffffff;
+	fbp_hi = (fbp_base_phys >> 32) & 0xffffffff;
+	fbp_lo = fbp_base_phys & 0xffffffff;
+
+	/* POE External Message Storage (upto 58K) */
+
+	nlm_print("POE ext msg storage: \n");
+	nlm_print("msg base: 0x%x%x\n", mbase_hi, mbase_lo);
+	nlm_print("fbp base: 0x%x%x\n", fbp_hi, fbp_lo);
+
+	/* Free Buffer Pool config */
+	nlm_print (" POE Free Buffer Pool config ...\n");
+
+	if (is_nlm_xlp3xx()) {
+		a = (uint64_t)XLP3XX_EXT_FBP_START_ADDR;
+		num_messages = XLP3XX_MAX_POE_EXT_MSG_STORAGE;
+	}
+	else {
+		a = (uint64_t)EXT_FBP_START_ADDR;
+		num_messages = MAX_POE_EXT_MSG_STORAGE;
+	}
+
+	vaddr = (uint64_t *) msg_base_virt;
+	for (i = 0; i < (num_messages / 4); i++) {
+		ldata = ((a+3) << 48) | ((a+2) << 32) | ((a+1) << 16) | a;
+		*vaddr = ldata;
+		vaddr++;
+		a += 4;
+	}
+
+	/* Configuring Message base pointer */
+	addr = MSG_STORAGE_BASE_ADR_L;
+	nlm_print ("POE Configuring Message base pointer ...\n");
+	nlm_hal_write_poe_pcie_reg(node, addr, mbase_lo);
+	addr++;
+	nlm_hal_write_poe_pcie_reg(node, addr, mbase_hi);
+
+	/* Configuring FBP base pointer */
+	addr = FBP_BASE_ADR_L;
+	nlm_print ("POE Configuring FBP base pointer ...\n");
+	nlm_hal_write_poe_pcie_reg(node, addr, fbp_lo);
+	addr++;
+	nlm_hal_write_poe_pcie_reg(node, addr, fbp_hi);
+}
+
+
+#define NUM_VCS_PER_CPU 4
+
+#define NUM_DISTVEC_CELLS 	16
+#define MIN_DIST_VEC 0
+#define MAX_DIST_VEC 16
+
+#define NUM_DISTVEC_CPUMASKS 4
+
+#define POE_DIST_VEC0 0x100
+
+/**
+* @brief nlm_hal_init_poe_distvec function can be used to set the POE distribution vectors.
+*
+* @param [in] node Node number
+* @param [in] vec Distribution vector number to program
+* @param [in] cm0 CPU mask for CPUs 0-7
+* @param [in] cm1 CPU mask for CPUs 8-15
+* @param [in] cm2 CPU mask for CPUs 16-23
+* @param [in] cm3 CPU mask for CPUs 24-31
+* @param [in] vcmask VC mask for all CPUs
+*
+* @return
+* 	- 0 on success
+* 	- -1 on invalid input
+* 
+* @ingroup hal_nae
+*
+*/
+int nlm_hal_init_poe_distvec(int node,int vec, uint32_t cm0, uint32_t cm1,
+	uint32_t cm2, uint32_t cm3, uint32_t vcmask)
+{
+	uint32_t cpumasks[NUM_DISTVEC_CPUMASKS];
+	uint32_t distvec[NUM_DISTVEC_CELLS];
+	int i;
+	int cpu;
+
+	if (vec < MIN_DIST_VEC || vec >= MAX_DIST_VEC)
+		return -1;
+
+	cpumasks[0] = cm0;
+	cpumasks[1] = cm1;
+	cpumasks[2] = cm2;
+	cpumasks[3] = cm3;
+
+	vcmask &= 0xf;
+	if (!vcmask)
+		return -1;
+
+	/* Initialize distribution vector cells */
+	for (i = 0; i < NUM_DISTVEC_CELLS; i++) {
+		distvec[i] = 0;
+	}
+
+	for (i = 0; i < NUM_DISTVEC_CPUMASKS; i++) {
+		uint32_t cpumask = cpumasks[i];
+
+		for (cpu = 0; cpu < 32; cpu++) {
+			int cell, offset;
+			uint32_t value;
+			int vc = 0;
+			int gcpu = 0;
+
+			if (((1 << cpu) & cpumask) == 0)
+				continue;
+
+			/* Use global cpu id */
+			gcpu = cpu + (i * 32);
+			vc = (gcpu * NUM_VCS_PER_CPU) % (NUM_DISTVEC_CELLS * 32);
+
+			cell = vc / 32;
+			offset = vc % 32;
+
+			value = vcmask << offset;
+
+			distvec[cell] |= value;
+		}
+	}
+
+	/* Write distribution vector cells */
+	for (i = 0; i < NUM_DISTVEC_CELLS; i++) {
+		int reg_index;
+		uint32_t value;
+
+		reg_index = POE_DIST_VEC0 + (vec * NUM_DISTVEC_CELLS)
+		            + (NUM_DISTVEC_CELLS - 1 - i);
+		value = distvec[i];
+
+		nlm_print("Node %d POE DistVec[%d]: reg=%d value=%08x\n",
+		          node, vec, (NUM_DISTVEC_CELLS - 1 - i), value);
+		nlm_hal_write_poe_pcim_reg(node, reg_index, value);
+	}
+
+	return 0;
+}
+
+/**
+* @brief init_poe_loc_msg_storage function is used to initailize the POE local message storage.
+*
+* @param [in] node Node number
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+static void init_poe_loc_msg_storage(int node)
 {
 	int i;
 	int reg_id = LOCAL_FBP_BASE;
 	for (i = 0; i < POE_MAX_LOC_32BIT_CHUNKS; ++i) {
 		/* Selects 32 entries via bit mask */
-		nlm_hal_write_poe_pcim_reg(reg_id, 0xffffffff);
+		nlm_hal_write_poe_pcim_reg(node, reg_id, 0xffffffff);
 		reg_id++;
 	}
 }
 
-static void parse_poe_config(void *fdt)
+int nlm_clear_poe_stats(int node)
 {
-	int size = 0;
-	uint32_t *poe_regs;
-	uint32_t num_regs;
-	int sz_32bit = sizeof(uint32_t);
+	nlm_hal_write_poe_pcie_reg(node, OO_MSG_CNT_LO, 0);
+	nlm_hal_write_poe_pcie_reg(node, IN_ORDER_MSG_CNT_LO, 0);
+	nlm_hal_write_poe_pcie_reg(node, LOC_BUF_STOR_CNT_LO, 0);
+	nlm_hal_write_poe_pcie_reg(node, EXT_BUF_STOR_CNT_LO, 0);
+	nlm_hal_write_poe_pcie_reg(node, LOC_BUF_ALLOC_CNT_LO, 0);
+	nlm_hal_write_poe_pcie_reg(node, EXT_BUF_ALLOC_CNT_LO, 0);
+	return 0;
+}
+
+int nlm_enable_poe_statistics(int node) 
+{
+	uint32_t val;
+	nlm_clear_poe_stats(node);
+	
+	val = nlm_hal_read_poe_pcie_reg(node, POE_STATISTICS_EN);
+	val |= (1 << 1);
+	nlm_hal_write_poe_pcie_reg(node, POE_STATISTICS_EN, val);
+	return 0;
+}
+
+int nlm_disable_poe_statistics(int node)
+{
+        uint32_t val;
+
+        val = nlm_hal_read_poe_pcie_reg(node, POE_STATISTICS_EN);
+        val &= ~(1 << 1);
+        nlm_hal_write_poe_pcie_reg(node, POE_STATISTICS_EN, val);
+        return 0;
+}
+
+int nlm_read_poe_statistics(int node, struct poe_statistics *stats)
+{
+	if (stats == NULL)
+		return -1;
+
+	stats->ooo_msg_count = nlm_hal_read_poe_pcie_reg(node, OO_MSG_CNT_LO) |
+				((uint64_t)nlm_hal_read_poe_pcie_reg(node, OO_MSG_CNT_HI) << 32ULL);
+	stats->inorder_msg_count = nlm_hal_read_poe_pcie_reg(node, IN_ORDER_MSG_CNT_LO ) |
+                                ((uint64_t)nlm_hal_read_poe_pcie_reg(node, IN_ORDER_MSG_CNT_HI) << 32ULL);
+	stats->loc_stor_access_count = nlm_hal_read_poe_pcie_reg(node, LOC_BUF_STOR_CNT_LO ) |
+                                ((uint64_t)nlm_hal_read_poe_pcie_reg(node, LOC_BUF_STOR_CNT_HI) << 32ULL);
+	stats->ext_stor_access_count = nlm_hal_read_poe_pcie_reg(node, EXT_BUF_STOR_CNT_LO) |
+                                ((uint64_t)nlm_hal_read_poe_pcie_reg(node, EXT_BUF_STOR_CNT_HI) << 32ULL);
+	stats->loc_stor_alloc_count = nlm_hal_read_poe_pcie_reg(node, LOC_BUF_ALLOC_CNT_LO) |
+                                ((uint64_t)nlm_hal_read_poe_pcie_reg(node, LOC_BUF_ALLOC_CNT_HI) << 32ULL);
+	stats->ext_stor_alloc_count = nlm_hal_read_poe_pcie_reg(node, EXT_BUF_ALLOC_CNT_LO) |
+                                ((uint64_t)nlm_hal_read_poe_pcie_reg(node, EXT_BUF_ALLOC_CNT_HI) << 32ULL);
+
+	return 0;
+}
+
+#define NUM_DIST_VEC 		16
+#define NUM_WORDS_PER_DV 	16
+#define MAX_DV_TBL_ENTRIES (NUM_DIST_VEC * NUM_WORDS_PER_DV)
+
+/**
+* @brief parse_poe_config function is used to initailize and program the POE based on the configuration in FDT.
+*
+* @param [in] fdt Pointer to the FDT
+* @param [in] node Node number
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+static void parse_poe_config(void *fdt,int node)
+{
+	int size = 0, nodeoffset, plen, bypass = 1, dist_en = 1, stats_en = 0;
+	uint32_t *dist_vec;
 	char mode_str[20];
+	char path_str[50];
+	char dv_str[10];
+	uint32_t *pval;
+	int reg_id, i, offset;
+	uint32_t drop_timer = 0, dist_drop_enable = 0, class_drop_enable = 0, dest_threshold = POE_DIST_THRESHOLD_VAL;
+	uint32_t dist_threshold[4] = {POE_DIST_THRESHOLD_VAL , POE_DIST_THRESHOLD_VAL, 
+					POE_DIST_THRESHOLD_VAL , POE_DIST_THRESHOLD_VAL};
+
+	size = sizeof(uint32_t) * MAX_DV_TBL_ENTRIES;
+
+	dist_vec = nlm_malloc(size);
+	if (dist_vec == NULL) {
+		nlm_print("nlm_alloc failed");
+		return;
+	}
 
-	copy_fdt_prop(fdt, "/soc/nae-cfg/poe", "mode", PROP_STR, mode_str, 20);
+	sprintf(path_str, "/soc/nae@node-%d/poe", node);
 
+	nodeoffset = fdt_path_offset(fdt, path_str);
+	if (nodeoffset >= 0) {
+		pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "distribution-enable", &plen);
+		if (pval != NULL) {
+			dist_en = fdt32_to_cpu(*(uint32_t *)(pval));
+		}
+		else {
+			dist_en = 1;
+		}
+
+                pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "dist-drop-enable", &plen);
+                if (pval != NULL) {
+                        dist_drop_enable = fdt32_to_cpu(*(uint32_t *)(pval)) & 0xFFFF;
+                }
+
+                pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "class-drop-enable", &plen);
+                if (pval != NULL) {
+                        class_drop_enable = fdt32_to_cpu(*(uint32_t *)(pval)) & 0xFF;
+                }
+
+                pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "drop-timer", &plen);
+                if (pval != NULL) {
+                        drop_timer = fdt32_to_cpu(*(uint32_t *)(pval)) & 0xFFFF;
+                }
+
+		pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "dest-threshold", &plen);
+                if (pval != NULL) {
+                        dest_threshold = fdt32_to_cpu(*(uint32_t *)(pval)) & 0xFFFF;
+                }
+
+                pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "statistics-enable", &plen);
+                if (pval != NULL) {
+                        stats_en = fdt32_to_cpu(*(uint32_t *)(pval));
+                }
+                else {
+                        stats_en = 0;
+                }
 	
-	if (strcmp(mode_str, "bypass") != 0) { // Non bypass mode
-		/* Local Message Storage (6K): Always Enabled! */
-		init_poe_loc_msg_storage();
-		nlm_print("Finished POE mode %s memory  carving\n", mode_str);
-	} else {
-		nlm_print("Configuring POE in bypass mode\n");
+		nlm_print("distribution %d dest_threshold 0x%x drop_timer 0x%x\n", dist_en, dest_threshold, drop_timer);	
+		copy_fdt_prop(fdt, path_str, "mode", PROP_STR, mode_str, 20);
+		if (strcmp(mode_str, "bypass") != 0) { // Non bypass mode
+			bypass = 0;
+			/* Local Message Storage (6K): Always Enabled! */
+			init_poe_loc_msg_storage(node);
+			NAE_DEBUG("Finished POE mode %s memory  carving\n", mode_str);
+		} else {
+			nlm_print("Configuring POE in bypass mode\n");
+		}
+
+		if (dist_en == 1) {
+
+			pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "dist-threshold", &plen);
+                        if (pval != NULL) {
+                                for(i = 0; i < 4; i++)
+                                        dist_threshold[i] = fdt32_to_cpu(*(uint32_t *)(pval + i)) & 0xFFFF;
+                        }
+
+			sprintf(path_str, "/soc/nae@node-%d/poe/distribution_vectors", node);
+			nodeoffset = fdt_path_offset(fdt, path_str);
+			if (nodeoffset >= 0) {
+				for(i = 0; i < NUM_DIST_VEC; i++) {
+					sprintf(dv_str,"dv%d",i);
+
+					pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, dv_str, &plen);
+					if (pval != NULL) {
+						if ((plen / sizeof(uint32_t)) != NUM_WORDS_PER_DV) {
+							nlm_print("Number of words in distribution vector%d is wrong\n",i);
+						}	
+						else {
+							for(offset = 0; offset < NUM_WORDS_PER_DV; offset++) {
+								*(dist_vec + (i * NUM_WORDS_PER_DV) + offset) = (fdt32_to_cpu(*(uint32_t *)(pval+ offset)));	
+							}
+						}
+					}	
+					else {
+						nlm_print("Distribution vector configuration is wrong\n");
+						while(1);
+					}
+				}		
+			}
+			else {
+				// set default DV
+			}
+		}	
 	}
+	
+	if (dist_en == 1) {
+		nlm_disable_distribution(node);
+		reg_id = POE_DIST_VEC0;
+		for(i=0; i < NUM_DIST_VEC; i++) {
+			for(offset = 0; offset < NUM_WORDS_PER_DV; offset++) {
+				nlm_hal_write_poe_pcim_reg(node, reg_id, *(dist_vec + (i * NUM_WORDS_PER_DV) + offset));
+				reg_id++;
+			}
+		}
 
-	GET_POE_PROP("num-regs", &num_regs, sz_32bit);
+        	for (i=0; i< 4; ++i) {
+                	nlm_hal_write_poe_pcie_reg(node, (i + POE_DIST_THRESHOLD_0), dist_threshold[i]);
+	        }
 
-	/* Each tuple has 3 elements. (type, index, val) hence the multiplication by 3 */
-	size = sizeof(uint32_t) * num_regs * 3;
-	poe_regs = nlm_malloc(size);
-	if (!poe_regs) {
-		nlm_print("[%s] Unable to allocate temporary memory\n", __func__);
-		return;
+		nlm_hal_write_poe_pcie_reg(node, POE_DEST_THRESHOLD, dest_threshold);
+		nlm_enable_distribution(node);
+
+		if (dist_drop_enable)
+			nlm_enable_distribution_vector_drop(node, dist_drop_enable);
+		if (class_drop_enable)
+			nlm_enable_distribution_class_drop(node, class_drop_enable);
+
+		nlm_write_distvec_drop_timer(node, drop_timer);
 	}
 
-	GET_POE_PROP("regs", poe_regs, size);
+	if (stats_en == 1)
+		nlm_enable_poe_statistics(node);
 
-	nlm_hal_init_poe_regs(poe_regs, num_regs);
+	nlm_hal_write_poe_pcie_reg(node, POE_LOC_ALLOC_EN, 1);
 
-	nlm_free(poe_regs);
+	if (!bypass) {
+		nlm_hal_write_poe_pcie_reg(node, POE_FBP_SP_EN, 0x1);
+		nlm_hal_write_poe_pcie_reg(node, POE_EXT_ALLOC_EN, 1);
+	}
+	nlm_hal_write_poe_pcie_reg(node, POE_TX_TIMER, 0x3);
+	
+	nlm_free(dist_vec);
 }
 
 #define GET_CPU_PROP(node_str, prop, buf, len)				\
 	copy_fdt_prop(fdt, node_str, prop, PROP_CELL, buf, len)
 
-static void parse_fdt_cpu_config(void *fdt, int dom_id)
+/**
+* @brief parse_fdt_cpu_config function is used to initailize local structures holding CPU-NAE related information.
+*
+* @param [in] fdt Pointer to the FDT
+* @param [in] dom_id Domain number to parse
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+static void parse_fdt_cpu_config(void *fdt, int dom_id, nlm_nae_config_ptr nae_cfg)
 {
 	char node_str[32];
 
-	snprintf(node_str, 32, "/doms/dom@%d/cpu", dom_id);
+	 sprintf(node_str, "/doms/dom@%d/cpu", dom_id);
 
-	if (GET_CPU_PROP(node_str, "nae-rx-vc", &nae_cfg.rx_vc, sizeof(uint32_t)) < 0) {
+	if (GET_CPU_PROP(node_str, "nae-rx-vc", &nae_cfg->rx_vc, sizeof(uint32_t)) < 0) {
 		nlm_print("Unable to parse nae_rx_vc, using defaults\n");
 		goto out;
 	}
 
-	if (GET_CPU_PROP(node_str, "nae-fb-vc", &nae_cfg.fb_vc, sizeof(uint32_t)) < 0) {
+	if (GET_CPU_PROP(node_str, "nae-fb-vc", &nae_cfg->fb_vc, sizeof(uint32_t)) < 0) {
 		nlm_print("Unable to parse nae_rx_vc, using defaults\n");
 		goto out;
 	}
@@ -237,221 +1692,244 @@ int rely_on_firmware_config = 0;
 #define NAE_NODE "/soc/nae-cfg"
 #define NAE_GLOBAL_NODE "/soc/nae-cfg/global-nae-regs"
 
-#define GET_NAE_PROP(prop, buf, len)					\
-	copy_fdt_prop(fdt, NAE_NODE, prop, PROP_CELL, buf, len)
+#define GET_NAE_PROP(path_str, prop, buf, len)					\
+	copy_fdt_prop(fdt, path_str, prop, PROP_CELL, buf, len)
 
-#define GET_NAE_STR_PROP(prop, buf, len)					\
-	copy_fdt_prop(fdt, NAE_NODE, prop, PROP_STR, buf, len)
+#define GET_NAE_STR_PROP(path_str, prop, buf, len)					\
+	copy_fdt_prop(fdt, path_str, prop, PROP_STR, buf, len)
 
-#define GET_NAE_GLOBAL_PROP(prop, buf, len)					\
+#define GET_NAE_GLOBAL_PROP(path_str, prop, buf, len)					\
 	copy_fdt_prop(fdt, NAE_GLOBAL_NODE, prop, PROP_CELL, buf, len)
 
-#define MAX_PROP_LEN 30
-/* Temporarily specifying these sizes here.
-   These will be moved to FDT soon
+#define NAE_MAX_PROP_LEN 30
+
+/**
+* @brief config_egress_fifo_carvings function is used to carve the various egress FIFOs for the active contexts.
+*
+* @param [in] node Node number
+* @param [in] start_ctxt Starting context number
+* @param [in] num_ctxts Number of contexts to carve for
+* @param [in] nae_cfg nlm_nae_config_ptr pointer to the internal HAL nae_cfg structure
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
 */
-#define NLM_STG2_FIFO_SZ   200
-#define NLM_EH_FIFO_SZ     200
-#define NLM_FROUT_FIFO_SZ  200
-#define NLM_MS_FIFO_SZ     200
-#define NLM_PKT_FIFO_SZ    200
-#define NLM_PKTLEN_FIFO_SZ 200
-
-#define MAX_STG2_OFFSET           0x7F
-#define MAX_EH_OFFSET             0x7F
-#define MAX_FREE_OUT_OFFSET       0x7F
-#define MAX_MS_OFFSET             0x1F
-#define MAX_PMEM_OFFSET           0x7FE
-
-static void config_egress_fifo_carvings(int start_ctxt, int num_ctxts)
+static void config_egress_fifo_carvings(int node, int start_ctxt, int num_ctxts, nlm_nae_config_ptr nae_cfg)
 {
 	int i, limit = start_ctxt + num_ctxts;
 	uint32_t data = 0;
 	uint32_t start = 0, size, offset;
-	static uint32_t cur_start[6] = { 0, 0, 0, 0, 0, 0};
 
 	/* Stage 2 FIFO */
-	start = cur_start[0];
+	start = nae_cfg->stg2fifo_base;
 	for(i=start_ctxt;i<limit;i++) {
-		size   = NLM_STG2_FIFO_SZ;
+		size   = nlm_stg2_fifo_sz() / nae_cfg->num_contexts;
 		if(size) offset = size -1; else offset = size ;
-		if(offset > MAX_STG2_OFFSET)
-			offset = MAX_STG2_OFFSET ;
-		data =   offset << 23  |
-			start << 11 |
+		if(offset > max_stg2_offset())
+			offset = max_stg2_offset();
+		data =   offset << 23  | 
+			start << 11 |	
 			i << 1      |
-			1;
-		nlm_print("program_nae_stg2_pmem: ctxt_num:%d start:%d size:%d\n", i, start, size);
-		nlm_hal_write_nae_reg(STG2_PMEM_PROG, data);
+			1;	
+		NAE_DEBUG("program_nae_stg2_pmem: ctxt_num:%d start:%d size:%d\n", i, start, size);
+		nlm_hal_write_nae_reg(node, STG2_PMEM_PROG, data);
 		start+= size;
 	}
-	cur_start[0] = start;
+	nae_cfg->stg2fifo_base = start;
 
 	/* EH FIFO */
-	start  = cur_start[1];
+	start  = nae_cfg->ehfifo_base;	
 	for(i=start_ctxt;i<limit;i++){
-		size   = NLM_EH_FIFO_SZ;
+		size   = nlm_eh_fifo_sz() / nae_cfg->num_contexts;
 		if(size) offset = size -1; else offset = size ;
-		if(offset > MAX_EH_OFFSET)
-			offset = MAX_EH_OFFSET ;
-		data =   offset << 23  |
-			start << 11 |
+		if(offset > max_eh_offset())
+			offset = max_eh_offset();
+		data =   offset << 23  | 
+			start << 11 |	
 			i << 1      |
-			1;
-		nlm_print("program_nae_eh_pmem: ctxt_num:%d start:%d size:%d\n", i, start, size);
-		nlm_hal_write_nae_reg(EH_PMEM_PROG, data);
+			1;	
+		NAE_DEBUG("program_nae_eh_pmem: ctxt_num:%d start:%d size:%d\n", i, start, size);
+		nlm_hal_write_nae_reg(node, EH_PMEM_PROG, data);
 		start+= size;
 	}
-	cur_start[1] = start;
+	nae_cfg->ehfifo_base = start;
 
 	/* FROUT FIFO */
-	start  = cur_start[2];
+	start  = nae_cfg->froutfifo_base;	
 	for(i=start_ctxt;i<limit;i++){
-		size   = NLM_FROUT_FIFO_SZ;
+		size   = nlm_frout_fifo_sz() / nae_cfg->num_contexts;
 		if(size) offset = size -1; else offset = size ;
-		if(offset > MAX_FREE_OUT_OFFSET)
-			offset = MAX_FREE_OUT_OFFSET ;
-		data =   offset << 23  |
-			start << 11 |
+		if(offset > max_free_out_offset())
+			offset = max_free_out_offset();
+		data =   offset << 23  | 
+			start << 11 |	
 			i << 1      |
-			1;
-		nlm_print("program_nae_frout_pmem: ctxt_num:%d start:%d size:%d\n", i, start, size);
-		nlm_hal_write_nae_reg(FREE_PMEM_PROG, data);
+			1;	
+		NAE_DEBUG("program_nae_frout_pmem: ctxt_num:%d start:%d size:%d\n", i, start, size);
+		nlm_hal_write_nae_reg(node, FREE_PMEM_PROG, data);
 		start+= size;
 	}
-	cur_start[2] = start;
+	nae_cfg->froutfifo_base = start;
 
 	/* MS FIFO */
-	start  = cur_start[3];
+	start  = nae_cfg->msfifo_base;	
 	for(i=start_ctxt;i<limit;i++){
-		size   = NLM_MS_FIFO_SZ;
+		size   = nlm_ms_fifo_sz() / nae_cfg->num_contexts;
 		if(size) offset = size -1; else offset = size ;
-		if(offset > MAX_MS_OFFSET)
-			offset = MAX_MS_OFFSET ;
-		data =   offset << 22  | 		// FIXME in PRM
-			start << 11 |
+		if(offset > max_ms_offset())
+			offset = max_ms_offset();
+		data =   offset << 22  | 	
+			start << 11 |	
 			i << 1      |
-			1;
-		nlm_print("program_nae_ms_pmem: ctxt_num:%d start:%d size:%d\n", i, start, size);
-		nlm_hal_write_nae_reg(STR_PMEM_CMD, data);
+			1;	
+		NAE_DEBUG("program_nae_ms_pmem: ctxt_num:%d start:%d size:%d\n", i, start, size);
+		nlm_hal_write_nae_reg(node, STR_PMEM_CMD, data);
 		start+= size;
 	}
-	cur_start[3] = start;
+	nae_cfg->msfifo_base = start;
 
 	/* PKT FIFO */
-	start  = cur_start[4];
+	start  = nae_cfg->pktfifo_base;	
 	for(i=start_ctxt;i<limit;i++){
-		size   = NLM_PKT_FIFO_SZ;
+		size   = nlm_pkt_fifo_sz() / nae_cfg->num_contexts;
 		if(size) offset = size -1; else offset = size ;
-		if(offset > MAX_PMEM_OFFSET)
-			offset = MAX_PMEM_OFFSET ;
-		nlm_hal_write_nae_reg(TX_PKT_PMEM_CMD1, offset);
+		if(offset > max_pmem_offset())
+			offset = max_pmem_offset();
+		nlm_hal_write_nae_reg(node, TX_PKT_PMEM_CMD1, offset);
 
-		data =   start << 11 |
+		data =   start << 11 |	
 			i << 1      |
-			1;
-		nlm_print("program_nae_pkt_pmem: ctxt_num:%d size:%d\n", i, size);
-		nlm_hal_write_nae_reg(TX_PKT_PMEM_CMD0, data);
+			1;	
+		NAE_DEBUG("program_nae_pkt_pmem: ctxt_num:%d size:%d\n", i, size);
+		nlm_hal_write_nae_reg(node, TX_PKT_PMEM_CMD0, data);
 		start+= size;
 	}
-	cur_start[4] = start;
+	nae_cfg->pktfifo_base = start;
 
 	/* PKT LEN FIFO */
-	start  = cur_start[5];
+	start  = nae_cfg->pktlenfifo_base;	
 	for(i=start_ctxt;i<limit;i++){
-		size   = NLM_PKTLEN_FIFO_SZ;
+		size   = nlm_pktlen_fifo_sz() / nae_cfg->num_contexts;
 		if(size) offset = size -1; else offset = size ;
-		data =   offset  << 22 |
-			start << 11 |
+		data =   offset  << 22 |	
+			start << 11 |	
 			i << 1      |
-			1;
-		nlm_print("program_nae_plen_pmem: ctxt_num:%d size:%d\n", i, size);
-		nlm_hal_write_nae_reg(TX_PKTLEN_PMEM_CMD, data);
+			1;	
+		NAE_DEBUG("program_nae_plen_pmem: ctxt_num:%d size:%d\n", i, size);
+		nlm_hal_write_nae_reg(node, TX_PKTLEN_PMEM_CMD, data);
 		start+= size;
 	}
-	cur_start[5] = start;
+	nae_cfg->pktlenfifo_base = start;
 }
-/* Temporarily specifying these credits here.
-   These will be moved to FDT soon
+
+/**
+* @brief config_egress_fifo_credits function is used to assign credits to the various stages in the egress path.
+*
+* @param [in] node Node number
+* @param [in] start_ctxt Starting context number
+* @param [in] num_ctxts Number of contexts to assign for
+* @param [in] max_context The maximum context number for the device
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
 */
-#define NLM_STG1_2_CREDIT     200
-#define NLM_STG2_EH_CREDIT    200
-#define NLM_STG2_FROUT_CREDIT 200
-#define NLM_STG2_MS_CREDIT    200
-static void config_egress_fifo_credits(int start_ctxt, int num_ctxts)
+static void config_egress_fifo_credits(int node, int start_ctxt, int num_ctxts, int max_context)
 {
 	int i, limit = start_ctxt + num_ctxts;
 	uint32_t data, credit, max_credit;
 
 	/* Stage1 -> Stage2 */
-	max_credit = MAX_STG2_OFFSET + 1;
+	max_credit = max_stg2_offset() + 1;
 	for(i=start_ctxt;i<limit;i++){
-		credit = NLM_STG1_2_CREDIT;
+		credit = stg1_2_credit() / max_context;
 		if (credit > max_credit)
 			credit = max_credit;
 
-		data =   credit << 16  |
+		data =   credit << 16  | 
 			i << 4      |
-			1;
-		nlm_print("program_nae_stg1_2_stg2_credit: ctxt_num:%d credit:%d\n", i, credit);
-		nlm_hal_write_nae_reg(STG1_STG2CRDT_CMD, data);
+			1;	
+		NAE_DEBUG("program_nae_stg1_2_stg2_credit: ctxt_num:%d credit:%d\n", i, credit);
+		nlm_hal_write_nae_reg(node, STG1_STG2CRDT_CMD, data);
 	}
 
 	/* Stage2 -> EH */
-	max_credit = MAX_EH_OFFSET+1;
+	max_credit = max_eh_offset() + 1;
 	for(i=start_ctxt;i<limit;i++){
-		credit = NLM_STG2_EH_CREDIT;
+		credit = stg2_eh_credit() / max_context;
 		if (credit > max_credit)
 			credit = max_credit;
 
-		data =   credit << 16  |
+		data =   credit << 16  | 
 			i << 4      |
-			1;
-		nlm_print("program_nae_stg2_2_eh_credit: ctxt_num:%d credit:%d\n", i, credit);
-		nlm_hal_write_nae_reg(STG2_EHCRDT_CMD, data);
+			1;	
+		NAE_DEBUG("program_nae_stg2_2_eh_credit: ctxt_num:%d credit:%d\n", i, credit);
+		nlm_hal_write_nae_reg(node, STG2_EHCRDT_CMD, data);
 	}
 
 	/* Stage2 -> Frout */
-	max_credit = MAX_FREE_OUT_OFFSET+1;
+	max_credit = max_free_out_offset() + 1;
 	for(i=start_ctxt;i<limit;i++){
-		credit = NLM_STG2_FROUT_CREDIT;
+		credit = stg2_frout_credit() / max_context;
 		if (credit > max_credit)
 			credit = max_credit;
 
-		data =   credit << 16  |
+		data =   credit << 16  | 
 			i << 4      |
-			1;
-		nlm_print("program_nae_stg2_2_frout_credit: ctxt_num:%d credit:%d\n", i, credit);
-		nlm_hal_write_nae_reg(STG2_FREECRDT_CMD, data);
+			1;	
+		NAE_DEBUG("program_nae_stg2_2_frout_credit: ctxt_num:%d credit:%d\n", i, credit);
+		nlm_hal_write_nae_reg(node, STG2_FREECRDT_CMD, data);
 	}
 
 	/* Stage2 -> MS */
-	max_credit = MAX_MS_OFFSET + 1;
+	max_credit = max_ms_offset() + 1;
 	for(i=start_ctxt;i<limit;i++){
-		credit = NLM_STG2_MS_CREDIT;
+		credit = stg2_ms_credit() / max_context;
 		if (credit > max_credit)
 			credit = max_credit;
 
-		data =   credit << 16  |
+		data =   credit << 16  | 
 			i << 4      |
-			1;
-		nlm_print("program_nae_stg2_2_ms_credit: ctxt_num:%d credit:%d\n", i, credit);
-		nlm_hal_write_nae_reg(STG2_STRCRDT_CMD, data);
+			1;	
+		NAE_DEBUG("program_nae_stg2_2_ms_credit: ctxt_num:%d credit:%d\n", i, credit);
+		nlm_hal_write_nae_reg(node, STG2_STRCRDT_CMD, data);
 	}
 }
 
 #define NUM_INGRESS_PORTS 19
-static uint32_t context_to_port_channel(uint32_t context)
+/**
+* @brief context_to_port_channel function finds the interface number for a given context.
+*
+* @param [in] node Node number
+* @param [in] context Context number
+*
+* @return
+*  - Interface number
+* 
+* @ingroup hal_nae
+*
+*/
+static uint32_t context_to_port_channel(int node, uint32_t context)
 {
 	uint32_t data, i;
 	uint32_t rx_if_base_config, rx_if_base_config1, base, ctxt;
 
-	ctxt  = context - XLP_NET_TX_VC_BASE;
+	if (is_nlm_xlp3xx()) {
+		ctxt  = context - XLP_3XX_NET_TX_VC_BASE;
+	}
+	else {
+		ctxt  = context - XLP_NET_TX_VC_BASE;
+	}
 
         /* Set it to non-existent port */
-	data = 19 << 10 ;            
+	data = 19 << 10 ;             
 	for(i=0;i<NUM_INGRESS_PORTS;i++){
-		base = nlm_hal_read_nae_reg(RX_IF_BASE_CONFIG_0 + i/2);
+		base = nlm_hal_read_nae_reg(node, RX_IF_BASE_CONFIG_0 + i/2);
 
 		rx_if_base_config = base & 0xffff;
 		rx_if_base_config1 = (base >> 16) & 0xffff;
@@ -474,7 +1952,20 @@ static uint32_t context_to_port_channel(uint32_t context)
 #define SP_EN            0
 #define SP_NUM           0
 
-void config_egress_drr(int start_ctxt, int end_ctxt)
+/**
+* @brief config_egress_drr function configures the egress DRR scheduler.
+*
+* @param [in] node Node number
+* @param [in] start_ctxt Starting context number
+* @param [in] end_ctxt Ending context number
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+void config_egress_drr(int node, int start_ctxt, int end_ctxt)
 {
 	uint32_t data, context, port, channel;
 	uint32_t limit = end_ctxt + 1;
@@ -483,15 +1974,15 @@ void config_egress_drr(int start_ctxt, int end_ctxt)
 		data  = (TX_IF_BURST_MAX << 12) |
 			(port    << 4) |
 			1;
-		nlm_hal_write_nae_reg(TX_IFACE_BURSTMAX_CMD, data);
+		nlm_hal_write_nae_reg(node, TX_IFACE_BURSTMAX_CMD, data);
 	}
 
 	for (context = start_ctxt; context<limit; context++){
 
 		data = DRR_QUANTA;
-		nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD1, data);
+		nlm_hal_write_nae_reg(node, TX_SCHED_MAP_CMD1, data);
 
-		data = context_to_port_channel(context);
+		data = context_to_port_channel(node, context);
 		port = data >> 10;
 		channel   = data & 0xff;
 
@@ -501,339 +1992,1108 @@ void config_egress_drr(int start_ctxt, int end_ctxt)
 			SP_EN << 4        |
 			SP_NUM << 1    |
 			1;
-		nlm_print("context:%d port:%d channel:%d \n",
+		NAE_DEBUG("context:%d port:%d channel:%d \n",
 			       context, port, channel);
-		nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD0, data);
+		nlm_hal_write_nae_reg(node, TX_SCHED_MAP_CMD0, data);
 	}
 }
 
-static void config_egress(int context_base, int port)
+/**
+* @brief config_egress function configures the egress NAE path (fifo carvings, fifo credits) per port
+*
+* @param [in] node Node number
+* @param [in] context_base Starting context number for port
+* @param [in] port Logical interface number (as opposed to hardware interface number)
+* @param [in] nae_cfg nlm_nae_config_ptr pointer to the internal HAL nae_cfg structure
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+
+static void config_egress(int node, int context_base, int port, nlm_nae_config_ptr nae_cfg)
 {
 	unsigned int offset =0, data = 0;
 
-	config_egress_fifo_carvings(context_base, nae_cfg.ports[port].num_channels);
-	config_egress_fifo_credits (context_base, nae_cfg.ports[port].num_channels);
+	data  = (TX_IF_BURST_MAX << 12) | (nae_cfg->ports[port].hw_port_id << 4) | 1;
+        nlm_hal_write_nae_reg(node, TX_IFACE_BURSTMAX_CMD, data);
+
+	data  = ((context_base + nae_cfg->ports[port].num_channels - 1) << 22) | (context_base << 12) |
+		 (nae_cfg->ports[port].hw_port_id << 4) | 1 ;
+	nlm_hal_write_nae_reg(node, TX_DRR_ACTVLIST_CMD, data);
+	
+	config_egress_fifo_carvings(node, context_base, nae_cfg->ports[port].num_channels, nae_cfg);
+	config_egress_fifo_credits (node, context_base, nae_cfg->ports[port].num_channels, nae_cfg->num_contexts);
+
+	data = nlm_hal_read_nae_reg(node, DMA_TX_CREDIT_TH);
+	data |= (1 << 25) | (1 << 24);
+	nlm_hal_write_nae_reg(node, DMA_TX_CREDIT_TH, data);
 
-	switch (nae_cfg.ports[port].iftype)
+	switch (nae_cfg->ports[port].iftype)
 	{
 		case INTERLAKEN_IF:
-			for(offset = 0; offset < nae_cfg.ports[port].num_channels; offset++) {
-				nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD1, DRR_QUANTA);
-				data = (nae_cfg.ports[port].hw_port_id << 15) |
+                        data  = (64 << 12) | (nae_cfg->ports[port].hw_port_id << 4) | 1;
+                        nlm_hal_write_nae_reg(node, TX_IFACE_BURSTMAX_CMD, data);
+
+			for(offset = 0; offset < nae_cfg->ports[port].num_channels; offset++) {
+				nlm_hal_write_nae_reg(node, TX_SCHED_MAP_CMD1, DRR_QUANTA);
+				data = (nae_cfg->ports[port].hw_port_id << 15) |
 					 (offset << 20) | ((context_base + offset) << 5) ;
-				nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD0, data | 1 );
-				nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD0, data);
-				nlm_print("txsched %x \n",nlm_hal_read_nae_reg(TX_SCHED_MAP_CMD0));	
+				nlm_hal_write_nae_reg(node, TX_SCHED_MAP_CMD0, data | 1 );
+				nlm_hal_write_nae_reg(node, TX_SCHED_MAP_CMD0, data);
+				NAE_DEBUG("txsched %x \n",nlm_hal_read_nae_reg(node, TX_SCHED_MAP_CMD0)); 
 			}
 			break;
 		default:
-                        for (offset=0;offset < nae_cfg.ports[port].num_channels; offset++) {
-				nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD1, DRR_QUANTA);
-                                data =  (nae_cfg.ports[port].hw_port_id << 15) | ((context_base + offset) << 5) ;
-				nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD0 , data | 1 );
-                                nlm_hal_write_nae_reg(TX_SCHED_MAP_CMD0 , data);
-				nlm_print("txsched %x \n",nlm_hal_read_nae_reg(TX_SCHED_MAP_CMD0));
+                        for (offset=0;offset < nae_cfg->ports[port].num_channels; offset++) {
+				NAE_DEBUG("txsched hwport %d ctxt %d \n",nae_cfg->ports[port].hw_port_id , (context_base + offset));
+				nlm_hal_write_nae_reg(node, TX_SCHED_MAP_CMD1, DRR_QUANTA);
+				data =  (nae_cfg->ports[port].hw_port_id << 15) | ((context_base + offset) << 5) ;
+				nlm_hal_write_nae_reg(node, TX_SCHED_MAP_CMD0 , data | 1 );
+				nlm_hal_write_nae_reg(node, TX_SCHED_MAP_CMD0 , data);
+			       NAE_DEBUG("txsched %x \n",nlm_hal_read_nae_reg(node, TX_SCHED_MAP_CMD0));
                         }
 			break;
 	}
 }
 
-#ifdef NLM_HAL_LINUX_KERNEL
-#define DFS_OUTPUT(DR, DF, DV)  ((400/((DR+1) * 3)) * (DF+1) * 2)/(DV+1)
-#else
-#define DFS_OUTPUT(DR, DF, DV)  ((133.33/(DR+1)) * (DF+1) * 2)/(DV+1)
-#endif
 
-static void set_nae_frequency(int frequency)
+static int get_flow_mask(int num_ports)
 {
-	int cnt, data, i;
-	unsigned int spr, spf;
+        int i;
+        int max_bits = 5; /* upto 32 ports */
+        /* Compute the number of bits to needed to
+         * represent all the ports */
+        for (i = 0; i < max_bits; ++i) {
+                if (num_ports <= (2 << i)) {
+                        return i + 1; /* num bits is non zero and 'i' starts from 0 */
+                }
+        }
+        return max_bits;
+}
 
-	data = 0x1;   // net dfs decr
-	if(frequency == 500)
-		cnt = 8;
-	else
-		cnt = 4;
-	for(i=0;i<cnt;i++){
-		nlm_hal_write_sys_reg(SYS_DFS_DIV_DEC_CTRL, data);
-	}
 
-	data = nlm_hal_read_sys_reg(PLL_CTRL);
-	spf = data >> 3 & 0x7f;
-	spr = data >> 1  & 0x3;
+/* Flow Config */
+static void nlm_config_flow_base(int node, nlm_nae_config_ptr nae_cfg)
+{
+        int port = 0, hw_port = 0;
+        int flow_mask = get_flow_mask(nae_cfg->num_ports);
+        uint32_t reg, cur_flow_base = 0, max_ports;
+	uint32_t per_port_num_flows = XLP_MAX_FLOWS / nae_cfg->num_ports;
+
+        if (is_nlm_xlp3xx()) {
+                max_ports = XLP_3XX_MAX_PORTS;
+        }
+        else {
+                max_ports = XLP_MAX_PORTS;
+        }
 
-	data = nlm_hal_read_sys_reg(SYS_DFS_DIV_VALUE0) & 0xf;
-	nlm_print("NAE Frequency set to %dMHz (2X frequency %dMHz) \n",
-		  (int) DFS_OUTPUT(spr, spf, data)/2 ,
-		  (int) DFS_OUTPUT(spr, spf, data));
+	for (port = 0, hw_port = 0 ; port < nae_cfg->num_ports; hw_port++) { 
+            if (hw_port == nae_cfg->ports[port].hw_port_id) {
+		reg = (cur_flow_base << 16) | hw_port;
+		reg |= ((flow_mask & 0x1f) << 8);
+	        nlm_hal_write_nae_reg(node, FLOW_BASE_MASK_CFG, reg);
+        	cur_flow_base += per_port_num_flows;
+		port++;
+	    }	   
+	}	
 }
 
-static void parse_fdt_nae_config(void *fdt)
+
+static void nlm_config_rx_calendar(int node, nlm_nae_config_ptr nae_cfg)
 {
-	int i = 0, port_node;
-	char port_type_str[MAX_PROP_LEN];
-	int size = 0;
-	int num_ports = 0;
-	uint32_t start_port, num_nae_regs, num_intf_regs;
-	char nae_port_str[1000];
-	uint32_t rx_config = 0;
-	int num_global_nae_regs;
-	uint32_t *global_nae_regs;
-	int frequency, context = 0;
-	int xaui_complex_map = 0, ilk_complex_map = 0, num_lanes = 0;
+        int cal = 0, cal_len = 0, last_free = 0, port = 0;
+        uint32_t val = 0, max_ports;
 
-	/* Parse Nae Config */
-	start_port = num_nae_regs = num_intf_regs = 0;
+        if (is_nlm_xlp3xx()) {
+                max_ports = XLP_3XX_MAX_PORTS;
+        }
+        else {
+                max_ports = XLP_MAX_PORTS;
+        }
 
-	if(GET_NAE_PROP("frequency", &frequency, sizeof(uint32_t)) < 0)
-		nlm_print("fdt missing frequency\n");
-	set_nae_frequency(frequency);
+        cal_len = nae_cfg->rx_cal_slots - 1;
+
+        NAE_DEBUG("Rx calendar length %d \n", cal_len);
+        do {
+                if (cal >= MAX_CAL_SLOTS)
+                        break;
+                last_free = cal;
+                for(port = 0; port < max_ports; port++) {
+                        if (nae_cfg->ports[port].rx_slots_reqd) {
+                                val = (cal_len << 16) | (nae_cfg->ports[port].hw_port_id << 8) | cal;
+                                nlm_hal_write_nae_reg(node, RX_IFACE_SLOT_CAL, val);
+                                NAE_DEBUG("Rx cal: hwport %d cal %d rx val 0x%x\n",nae_cfg->ports[port].hw_port_id, cal,  val);
+                                cal++;
+                                nae_cfg->ports[port].rx_slots_reqd--;
+                        }
+                }
+                if (last_free == cal)
+                        break;
+        } while(1);
+}
 
-	/*******************************************************************************/
-	/* Read range of ports allocated per domain
-	 * start-port-id -> start-port-id + num-ports
-	 */
+static void nlm_config_tx_calendar(int node, nlm_nae_config_ptr nae_cfg)
+{
+        int cal = 0, cal_len = 0, last_free = 0, port = 0;
+        uint32_t val = 0, max_ports;
 
-	if(GET_NAE_PROP("start-port-id", &start_port, sizeof(uint32_t)) < 0)
-		nlm_print("fdt missing start-port-id\n");
+        if (is_nlm_xlp3xx()) {
+                max_ports = XLP_3XX_MAX_PORTS;
+        }
+        else {
+                max_ports = XLP_MAX_PORTS;
+        }
 
-	if(GET_NAE_PROP("num-ports", &num_ports, sizeof(uint32_t)) < 0)
-		nlm_print("fdt missing num-ports\n");
+	cal_len = nae_cfg->tx_cal_slots - 1;
+
+	nlm_hal_write_nae_reg(node, EGR_NIOR_CAL_LEN_REG, cal_len - 1);
+        do {
+                if (cal >= MAX_CAL_SLOTS)
+                        break;
+                last_free = cal;
+                for(port = 0; port < max_ports; port++) {
+                        if (nae_cfg->ports[port].tx_slots_reqd) {
+                                val = (nae_cfg->ports[port].hw_port_id << 7) | (cal << 1) | 1;
+                                nlm_hal_write_nae_reg(node, EGR_NIOR_CRDT_CAL_PROG, val);     // map it to interface
+                                NAE_DEBUG("TX cal: hwport %d cal %d tx val 0x%x\n",nae_cfg->ports[port].hw_port_id, cal,  val);
+                                cal++;
+                                nae_cfg->ports[port].tx_slots_reqd--;
+                        }
+                }
+                if (last_free == cal)
+                        break;
+        } while(1);
 
-	/*******************************************************************************/
+}
 
-	if(GET_NAE_PROP("num-intf-regs", &num_intf_regs, sizeof(uint32_t)) < 0)
-		nlm_print("fdt missing num-if-regs\n");
+/*
+Input:
+node - nae node id 	
+start - vfbid table index. 
+num_entries - number of entries to be configured from start
+vfbid_tbl - array of destination VCs
+(Entries 126 and 127 can not be used by software)
+
+Returns:
+	0 on success
+*/
 
-	nlm_print("num-ports = %d, start-port-id = %d\n", num_ports, start_port);
+int nlm_config_vfbid_table(int node, uint32_t start, uint32_t num_entries, uint32_t *vfbid_tbl)
+{
+	int vfbid;		
+	volatile uint32_t val = 0;
+	if (vfbid_tbl == NULL)
+		return -1;
+	
+	if ((start + num_entries) > 128)
+		return -1;
 
-	/*
-	 *   PCS intialization
-	 */
-	if (!rely_on_firmware_config)
-	{
-		/* bitmask of complexes to initialize */
-		nlm_hal_sgmii_pcs_init(1<<4);
+	for(vfbid = start; vfbid < (start + num_entries); vfbid++, vfbid_tbl++) {
+		val = ((*vfbid_tbl) << 16) | (vfbid << 4) | 1;
+		nlm_hal_write_nae_reg(node, VFBID_TO_DEST_MAP_CMD, val);		
+	//	NAE_DEBUG("vfbid %d dest %d \n",vfbid, *vfbid_tbl);
 	}
+	return 0;	
+}
 
-        if(GET_NAE_PROP("xaui-complex-map", &xaui_complex_map, sizeof(uint32_t)) < 0)
-                nlm_print("fdt missing xaui-complex-map\n");
-        else  
-                nlm_hal_xaui_pcs_init(xaui_complex_map);
-
-        if(GET_NAE_PROP("ilk-complex-map", &ilk_complex_map, sizeof(uint32_t)) < 0)
-                nlm_print("fdt missing ilk-complex-map\n");
-        else {  
-		if(GET_NAE_PROP("num-lanes", &num_lanes, sizeof(uint32_t)) < 0) {
-			nlm_print("fdt missing num-lanes, default 4\n");
-			num_lanes = 4;
-		}
-                nlm_hal_ilk_pcs_init(ilk_complex_map, num_lanes);
+static void nlm_config_poe_class(int node)
+{
+        int i;
+        uint32_t val;
+        int poe_cl_tbl[MAX_POE_CLASSES] = {0x0, 0x249249, 0x492492,
+                                           0x6db6db, 0x924924, 0xb6db6d,
+                                           0xdb6db6, 0xffffff};
+        int max_poe_tbl_sz;
+
+	if (is_nlm_xlp3xx()) {
+        	max_poe_tbl_sz = XLP3XX_MAX_POE_CLASS_CTXT_TBL_SZ;
+        }
+        else {
+		max_poe_tbl_sz = MAX_POE_CLASS_CTXT_TBL_SZ;
 	}
 
-        /* Clear NETIOR soft reset */
-        nlm_hal_write_mac_reg(BLOCK_7, LANE_CFG, NETIOR_SOFTRESET, 0x0);
-        nlm_print("%s Completed NETIOR soft reset\n", __func__);
+        NAE_DEBUG("max_poe_tbl_sz %d\n",max_poe_tbl_sz);
+        for (i = 0; i <max_poe_tbl_sz; ++i) {
+                val = (0x00 | i); /* clear the read bit 0x80 */
+                val |= (poe_cl_tbl[(i/MAX_POE_CLASSES) & 0x7] << 8);
 
+       //         NAE_DEBUG("POE index %d val %x \n",i, val);
+                nlm_hal_write_nae_reg(node, POE_CLASS_SETUP_CFG, val);
+        }
+}
 
-	/* Disable RX enable bit in RX_CONFIG */
-	rx_config = nlm_hal_read_nae_reg(RX_CONFIG);
-	rx_config &= 0xfffffffe;
-	nlm_hal_write_nae_reg(RX_CONFIG, rx_config);
+static inline void nlm_write_ucore_sprayvec(int node, int hw_port_id, uint32_t spray_vec)
+{
+	nlm_hal_write_nae_reg(node, UCORE_IFACE_MASK_CFG, ( 0x1ULL << 31) | ((spray_vec & 0xffff)  << 8) |
+                                     (hw_port_id & 0x1f));
+}
 
+static inline void nlm_write_fifo_size(int node, int hw_port_id, uint32_t size)
+{
+	nlm_hal_write_nae_reg(node, FREE_IN_FIFO_UNIQ_SZ_CFG, ((size/XLP_CACHELINE_SIZE) << 8) | (hw_port_id & 0x1f) );
+}
 
-	/*
-	 *    Global register configuration
-	 */
-	if(GET_NAE_GLOBAL_PROP("num-regs", &num_global_nae_regs, sizeof(uint32_t)) < 0)
-		nlm_print("fdt missing num-regs for global-nae-regs\n");
+static inline void nlm_write_interface_fifo(int node, int hw_port_id, uint32_t start, uint32_t size, uint32_t xoff_thresh)
+{
+	volatile uint32_t val;
+	
+	val = ((xoff_thresh << 25) | ((size & 0x1ff) << 16) |
+                                       ((start & 0xff) << 8) | hw_port_id);
+        nlm_hal_write_nae_reg(node, IFACE_FIFO_CFG, val);
 
-	size = sizeof(uint32_t) * num_global_nae_regs * 2;
-	global_nae_regs = nlm_malloc(size);
-	if (!global_nae_regs) {
-		nlm_print("[%s] Unable to allocate memory for global nae-regs, aborting\n", __func__);
-		return;
+	NAE_DEBUG("iface_start %d port %d size %d\n",start, hw_port_id, size);
+	NAE_DEBUG("reg %x 0x%x\n",IFACE_FIFO_CFG, val);
+}
+ 
+static inline void nlm_write_rxbase(int node, int hw_port_id, uint32_t base)
+{
+	volatile uint32_t val;
+	int reg = RX_IF_BASE_CONFIG_0 + (hw_port_id / 2);
+	
+        if ((hw_port_id % 2) == 0) {
+		val = nlm_hal_read_nae_reg(node, reg) & (0x3FF << 16);
+                val |= base;
+                nlm_hal_write_nae_reg(node, reg, val);
+        }
+        else {
+                val = nlm_hal_read_nae_reg(node, reg) & 0x3FF;
+                val |= (base << 16);
+                nlm_hal_write_nae_reg(node, reg, val);
+		NAE_DEBUG("reg %x 0x%x\n",reg, val);
+        }
+}
+
+static inline void nlm_configure_rxbuffer(int node, int context_base, int num_channels, uint32_t base, uint32_t size)
+{
+	int offset;
+	volatile uint32_t val;
+
+	size /= num_channels;
+
+	for(offset = 0; offset < num_channels; offset++) {
+		nlm_hal_write_nae_reg(node, RX_BUFFER_BASE_DEPTH_ADDR_REG, context_base + offset);
+                NAE_DEBUG("context %d base %x size %d \n",context_base + offset, base, size);
+         	NAE_DEBUG("reg %x 0x%x\n",RX_BUFFER_BASE_DEPTH_ADDR_REG, context_base + offset);       
+		val = 0x80000000 | ((base << 2) & 0x3fff); /* base */
+                val |= (((size << 2)  & 0x3fff) << 16); /* size */
+                nlm_hal_write_nae_reg(node, RX_BUFFER_BASE_DEPTH_REG, val);
+		NAE_DEBUG("reg %x 0x%x\n",RX_BUFFER_BASE_DEPTH_REG, val);
+                nlm_hal_write_nae_reg(node, RX_BUFFER_BASE_DEPTH_REG, 0x7fffffff & val);
+		NAE_DEBUG("reg %x 0x%x\n",RX_BUFFER_BASE_DEPTH_REG, 0x7fffffff & val);
+		base += size;
 	}
+}
+
+static inline void nlm_configure_parserfifo(int node, int hw_port_id, uint32_t start, uint32_t size)
+{
+	volatile uint32_t val;
 
-	GET_NAE_GLOBAL_PROP("regs", global_nae_regs, size);
-	nlm_hal_init_nae_regs(0, global_nae_regs, num_global_nae_regs);
-	nlm_print("Configured %x global NAE regs\n", num_global_nae_regs);
+	val = ((size & 0x1fff) << 17) | ((start & 0xfff) << 5) | (hw_port_id & 0x1f);
+        nlm_hal_write_nae_reg(node, PARSER_SEQ_FIFO_CFG, val);
+	NAE_DEBUG("reg %x 0x%x\n",PARSER_SEQ_FIFO_CFG, val);
+}
 
-	for(i = 0; i < num_ports; i++)
-	{
-		uint32_t *nae_regs = 0;
-		uint32_t *intf_regs = 0;
-		int mgmt_intf = 0;
-		int port = 0;
+static void nlm_config_ingress_fifo(int node, nlm_nae_config_ptr nae_cfg)
+{
+        int fifo_xoff_thresh;
+        int port, lane = 0, hw_port = 0, max_lanes, offset = 0;
+	int cur_iface_start = 0, max_ports;
+	uint32_t cur_parser_base = 0, context_base = 0, rx_buf_base = 0, size = 0;
+
+        NAE_DEBUG("Interface FIFO carving \n");
+        if (is_nlm_xlp3xx()) {
+                max_ports = XLP_3XX_MAX_PORTS;
+        }
+        else {
+                max_ports = XLP_MAX_PORTS;
+        }
+
+        for (port = 0, hw_port = 0 ; hw_port < max_ports; ) { 
+	    if (hw_port == nae_cfg->ports[port].hw_port_id) {
+
+		nlm_configure_rxbuffer(node, context_base,nae_cfg->ports[port].num_channels,
+                                        rx_buf_base, nae_cfg->ports[port].rx_buf_size);  
+                rx_buf_base += nae_cfg->ports[port].rx_buf_size;
 
-		sprintf(nae_port_str, "/soc/nae-cfg/port@%d", i);
+		switch(nae_cfg->ports[port].iftype) {
+		   case XAUI_IF:
+			fifo_xoff_thresh = 12;	   	
+			max_lanes = 4;
+			offset = 4;
+			break;
+		   case SGMII_IF:
+			fifo_xoff_thresh = 6;
+			max_lanes = 1;
+			offset = 1;
+			break;
+		   case INTERLAKEN_IF:
+			fifo_xoff_thresh = 12;
+			max_lanes = 8;
+			offset = 8;
+ 			break;
+		    default:
+			fifo_xoff_thresh = 0;
+                        max_lanes = 0;
+                        offset = 0;
+			break;
+                }
 
-#define GET_PORT_PROP(prop, buf, len)					\
-	copy_fdt_prop(fdt, nae_port_str, prop, PROP_CELL, buf, len)
+		for (lane = 0 ; lane < max_lanes; lane++) {
+			// carving interface fifo
+			size = ((lane == 0) ? nae_cfg->ports[port].intf_fifo_size : 0);
+			nlm_write_interface_fifo(node, nae_cfg->ports[port].hw_port_id + lane,
+                                                         cur_iface_start, size, fifo_xoff_thresh );
+			cur_iface_start += size;
+			
+			// carving Rx base
+			nlm_write_rxbase(node, nae_cfg->ports[port].hw_port_id + lane, context_base);
+			if (lane == 0)
+                        	context_base += nae_cfg->ports[port].num_channels;
+			
+			size = ((lane == 0) ? nae_cfg->ports[port].prsr_seq_fifo_size : 0);
+			nlm_configure_parserfifo(node, nae_cfg->ports[port].hw_port_id + lane, cur_parser_base, size);
+			cur_parser_base += size;
+		}
+		hw_port += offset;
+		port++;
+	    }
+	    else {
+		nlm_write_interface_fifo(node, hw_port, cur_iface_start, 0, 0 );
+		nlm_write_rxbase(node, hw_port, context_base);
+		nlm_configure_parserfifo(node, hw_port, cur_parser_base, 0);
+		hw_port++;
+	    }		
+        }
+}
 
-#define GET_PORT_STR_PROP(prop, buf, len)					\
-	copy_fdt_prop(fdt, nae_port_str, prop, PROP_STR, buf, len)
+static void nlm_config_nae_global(int node, nlm_nae_config_ptr nae_cfg) 
+{
+	uint32_t vfbid = 0, i = 0;
+        volatile uint32_t val = 0;
+        uint32_t dest;
+
+	nlm_config_poe_class(node);
+
+        if (nae_cfg->flags & FREEBACK_TO_NAE) {
+                dest = nae_cfg->frin_queue_base;
+
+                for (i = 0, vfbid = 32; i < NLM_MAX_NODES; vfbid++) {
+                        val = (dest << 16) | (vfbid << 4) | 1;
+                        nlm_hal_write_nae_reg(node, VFBID_TO_DEST_MAP_CMD, val);
+          //              NAE_DEBUG("HW vfbid %d dest %d \n",vfbid, dest);
+                        dest++;
+                        if (dest == (nae_cfg->frin_queue_base + nae_cfg->frin_total_queue)) {
+                                i++;
+                                dest = (i<<10) | nae_cfg->frin_queue_base;
+                        }
+                }
+        }
+	else {
+		for (i = 0, vfbid = 0; i < NLM_MAX_NODES; i++) {
+                        dest = nae_cfg->fb_vc;
+                        for (;vfbid < ((i+1) * 32); vfbid++) { 
+                                val = (((i<<10) | dest) << 16) | (vfbid << 4) | 1;
+                                nlm_hal_write_nae_reg(node, VFBID_TO_DEST_MAP_CMD, val);
+        //                        NAE_DEBUG("vfbid %d dest %d \n",vfbid, ((i<<10) | dest));
+                                dest += MAX_VC_PERTHREAD;
+                        }
+                }
 
-		port_node = fdt_path_offset(fdt, nae_port_str);
-		if (!port_node) continue;
+	}
 
-		if (GET_PORT_PROP("mgmt", &mgmt_intf, sizeof(uint32_t)) < 0)
-			nlm_print("fdt missing mgmt\n");
+	if (nae_cfg->num_ports)
+		nlm_config_flow_base(node, nae_cfg);
+	nlm_hal_write_nae_reg(node, FLOW_CRC16_POLY_CFG, 0xFFFF);
+	nlm_config_ingress_fifo(node, nae_cfg);
+	nlm_config_rx_calendar(node, nae_cfg);
+	if (!is_nlm_xlp8xx_ax())
+		nlm_config_tx_calendar(node, nae_cfg);
+}
 
-		port = nae_cfg.num_ports;
-		nae_cfg.num_ports++;
+/**
+* @brief set_nae_frequency function sets the frequency of the NAE block
+*
+* @param [in] node Node number
+* @param [in] frequency Frequency in MHz
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+static void set_nae_frequency(int node, int frequency)
+{
+        const uint64_t mhz = 1000000;
+        /* Note that the DFS sets the NAE 2X frequency.
+         * To set the NAE frequency, multiply by 2
+         */
+        uint64_t set_freq, set_freq_d = nlm_hal_set_soc_freq(node, DFS_DEVICE_NAE_2X, frequency * 2 * mhz);
 
-		nae_cfg.ports[port].valid = 1;
-		nae_cfg.ports[port].mgmt = mgmt_intf;
-		nae_cfg.ports[port].vlan_pri_en = 0; /* For now. Will be added via sysconfig later */
+#ifdef NLM_HAL_LINUX_KERNEL
+        do_div(set_freq_d, mhz);
+        set_freq = set_freq_d;
+        do_div(set_freq, 2);
+#else
+        set_freq_d /= mhz;
+        set_freq = set_freq_d / 2;
+#endif
+        nlm_print("NAE 2X Frequency set to %lluMHz (NAE frequency %llu MHz)\n", set_freq_d, set_freq);
+}
 
-		if (GET_PORT_PROP("tx-que-range", &nae_cfg.ports[port].txq_range[0], sizeof(uint32_t) * 2) < 0)	{
-			nlm_print("fdt missing tx-que-range\n");
+static int nae_freein_fifo_cfg(void *fdt, int node, nlm_nae_config_ptr nae_cfg)
+{
+	uint64_t tmp[2];
+	uint64_t *pval;
+	uint32_t reg, size, spillsz, port = 0;
+	int start = 0, i,  th_hi, th_lo;
+	uint64_t spill_addr, spill_mem_addr, spill_mem_size; 
+	int freein_fifo_shared = 0;
+	uint32_t freein_fifo_onchip_num_descs = 0;
+	uint32_t freein_fifo_spill_num_descs = 0;
+	int freein_fifo_total_queues = nae_cfg->frin_total_queue;
+	char path_str[50];
+
+	//spill mem allocation is skipped if FREEIN_SPILL_DYNAMIC is set
+	
+	if ((nae_cfg->flags & FREEIN_SPILL_DYNAMIC) == 0) {
+	    sprintf(path_str,"/soc/nae@node-%d/freein-fifo-config", node);
+	    if (copy_fdt_prop(fdt, path_str, "freein-fifo-spill-mem-range", PROP_STR, 
+				tmp, sizeof(tmp)) == sizeof(tmp)) {
+		pval = &tmp[0];
+		spill_mem_addr = fdt64_to_cpu((*pval));
+		spill_mem_size = fdt64_to_cpu((*(pval + 1)));
+#ifdef NLM_HAL_LINUX_KERNEL
+		if (spill_mem_addr == 0ULL) {
+			if ((spill_mem_addr = nlm_spill_alloc(node, spill_mem_size)) == 0ULL) {
+				nlm_print("free in spill mem allocation failed \n");
+				spill_mem_size = 0ULL;
+			}
+			else {
+				nae_cfg->flags |= FREEIN_SPILL_DYNAMIC;
+			}
+		}	
+#endif	
+	    } else {
+		if (node == 0) {
+			spill_mem_addr = XLP_FREEIN_SPILL_DEFAULT_MEM_ADDR;
+			spill_mem_size = XLP_FREEIN_SPILL_DEFAULT_MEM_SIZE;
 		}
 		else {
-			nlm_print("tx-que-range[%d %d]\n", nae_cfg.ports[port].txq_range[0],
-			       nae_cfg.ports[port].txq_range[1]);
+			spill_mem_addr = 0ULL;
+			spill_mem_size = 0ULL;
+		}
+	   }
+	   nae_cfg->freein_spill_base = spill_mem_addr;
+	   nae_cfg->freein_spill_size = spill_mem_size;	
+	}
+	else {
+		spill_mem_addr = nae_cfg->freein_spill_base;
+		spill_mem_size = nae_cfg->freein_spill_size;
+	}
+
+	copy_fdt_prop(fdt, path_str, "freein-fifo-shared", PROP_CELL, 
+			&freein_fifo_shared, 4);
+	copy_fdt_prop(fdt, path_str, "freein-fifo-onchip-num-descs", PROP_CELL, 
+			&freein_fifo_onchip_num_descs, 4);
+	copy_fdt_prop(fdt, path_str, "freein-fifo-spill-num-descs", PROP_CELL,
+			&freein_fifo_spill_num_descs, 4);
+			
+	nlm_print("NAE Freein-fifo, memaddr %lx memsize %lx shared %d onnchip-descs %d spill-descs %d\n",
+			(long)spill_mem_addr, (long)spill_mem_size, freein_fifo_shared,
+			freein_fifo_onchip_num_descs,freein_fifo_spill_num_descs);
+
+	/* in cache addr */
+	spill_addr = spill_mem_addr >> 6; 
+
+	/* in cachelines, 1 cacheline can store 12 descs  and 
+	get the number of cacheline required */
+	if (spill_mem_size != 0) {
+		spillsz = freein_fifo_spill_num_descs / 12 ; 
+		if((freein_fifo_spill_num_descs % 12) != 0)
+			spillsz++;
+	}
+	else
+		spillsz = 0;	
+
+	if (freein_fifo_shared) {
+		for(i = 0; i < freein_fifo_total_queues; i++) {
+			if(i < 16 && (spillsz)) {
+
+				reg = spill_addr & 0xffffffff;
+				nlm_hal_write_nae_reg(node, FREE_SPILL0_MEM_CFG, reg);
+				nlm_print("Freein fifo cfg %d spl_addr %lx reg0 %x\n", i, (long)spill_addr, reg);
+	
+				reg = (((spill_addr >> 32) & 0x3) << 30) | spillsz;
+				nlm_hal_write_nae_reg(node, FREE_SPILL1_MEM_CFG, reg);
+
+				nlm_print("Freein fifo cfg %d spl_addr %lx reg1 %x\n", i, (long)spill_addr, reg);
+				spill_addr += spillsz;
+				/* align to 32k, already >> 6 is done above, so align to 1k */
+				spill_addr = (spill_addr + 1023) & (~1023);
+			} else {
+				nlm_hal_write_nae_reg(node, FREE_SPILL0_MEM_CFG, 0);
+				nlm_hal_write_nae_reg(node, FREE_SPILL1_MEM_CFG, 0);
+			}
+		
+			/* Onchip configuraton is based on locations. 1 location can store 2 descs */
+			if(i < 16) {
+				size = freein_fifo_onchip_num_descs / 2;
+				/* take num free desc for the mgmt ports from the complex config only */
+				if(size == 0) 
+					size = 8;
+
+				reg = ((size  & 0x3ff ) << 20) | /* fcSize */
+					((start & 0x1ff)  << 8) | /* fcStart */
+					(i  & 0x1f);
+
+				nlm_hal_write_nae_reg(node, FREE_IN_FIFO_CFG, reg);
+				nlm_print("Freein fifo cfg %d fcstart %d size %d\n", i, start, size);
+				start += size;
+			}
 		}
+	}
 
-		if (GET_PORT_PROP("rx-que", &nae_cfg.ports[port].rxq, sizeof(uint32_t)) < 0) {
-			nlm_print("fdt missing rx-que\n");
+	for(i = 0, port = 0; i < freein_fifo_total_queues;) {
+		if ((freein_fifo_shared) && (nae_cfg->ports[port].hw_port_id < 16)) {
+			port++;
+			if(port >= nae_cfg->num_ports)
+				break;
+			i = nae_cfg->ports[port].hw_port_id;
+			continue;
+		} 
+
+                if(i < 16 && (spillsz)) {
+                        reg = spill_addr & 0xffffffff;
+                        nlm_hal_write_nae_reg(node, FREE_SPILL0_MEM_CFG, reg);
+                        nlm_print("Freein fifo cfg %d spl_addr %lx reg0 %x\n", i, (long)spill_addr, reg);
+
+	                reg = (((spill_addr >> 32) & 0x3) << 30) | spillsz;
+                        nlm_hal_write_nae_reg(node, FREE_SPILL1_MEM_CFG, reg);
+
+                        nlm_print("Freein fifo cfg %d spl_addr %lx reg1 %x\n", i, (long)spill_addr, reg);
+                        spill_addr += spillsz;
+                        /* align to 32k, already >> 6 is done above, so align to 1k */
+                        spill_addr = (spill_addr + 1023) & (~1023);
+                } else {
+                        nlm_hal_write_nae_reg(node, FREE_SPILL0_MEM_CFG, 0);
+                        nlm_hal_write_nae_reg(node, FREE_SPILL1_MEM_CFG, 0);
+                }
+
+		if (i == nae_cfg->ports[port].hw_port_id){
+			size = nae_cfg->ports[port].num_free_desc / 2;
+			port++;	
 		}
-		else {
-			nlm_print("rx-que[%d]\n", nae_cfg.ports[port].rxq);
+		else
+			size = 8;
+
+		reg = ((size  & 0x3ff ) << 20) | /* fcSize */
+	                 ((start & 0x1ff)  << 8) | /* fcStart */
+                         (i  & 0x1f);
+
+		nlm_hal_write_nae_reg(node, FREE_IN_FIFO_CFG, reg);
+                nlm_print("Freein fifo cfg... %d fcstart %d size %d\n", i, start, size);
+                start += size;		
+		i++;
+	}
+
+	if(spillsz) {
+		th_hi = 6; /* Defualt value */
+		th_lo = 0xe; /* Default value */
+		/* spill credits [27:24] has to be 2 */
+		reg = (2 << 24) | th_lo | (th_hi << 12);
+		nlm_hal_write_nae_reg(node, FREE_FIFO_THRESHOLD_CFG, reg); 
+
+		if(spill_addr > (spill_mem_addr + spill_mem_size)) {
+			nlm_print("ERROR : Spill address range overflow\n");
+			return -1;
+		}
+	}
+	
+	nae_cfg->freein_fifo_shared = freein_fifo_shared;
+	nae_cfg->freein_fifo_onchip_num_descs = freein_fifo_onchip_num_descs;
+	nae_cfg->freein_fifo_spill_num_descs = freein_fifo_spill_num_descs;
+
+	return 0;
+}
+
+
+static int parse_vfbid_config(void *fdt, int node, uint32_t *vfbid_tbl)
+{
+	char vfbid_path[50];
+	int offset, dest, index;
+	nlm_nae_config_ptr nae_cfg = nlm_node_cfg.nae_cfg[node];
+	uint32_t *pval;
+	int plen = 0, nodeoffset = 0, hw_replenish;
+
+	sprintf(vfbid_path, "/soc/nae@node-%d/vfbid-config",node);
+
+	if(GET_NAE_PROP(vfbid_path, "hw-replenish", &hw_replenish, sizeof(uint32_t)) < 0){
+                nlm_print("fdt missing hw-replenish\n");
+	}
+	else {
+		if (hw_replenish != 0)
+			nae_cfg->flags |= FREEBACK_TO_NAE;
+		else
+			nae_cfg->flags &= ~FREEBACK_TO_NAE;
+	}
+
+	for(offset = 0; offset < MAX_VFBID_ENTRIES; offset++) {
+		*(vfbid_tbl + offset) = 0;
+	}
+		
+	nodeoffset = fdt_path_offset(fdt, vfbid_path);
+        if(nodeoffset >= 0)  {
+                pval = (uint32_t *)fdt_getprop(fdt, nodeoffset, "vfbid-map", &plen);
+               	if(pval != NULL) {
+			nae_cfg->flags |= VFBID_FROM_FDT;
+			for(offset = 0; offset < (plen / 4); offset+=2) {
+				index = fdt32_to_cpu(*(uint32_t *)(pval + offset));
+				dest = fdt32_to_cpu(*(uint32_t *)(pval + offset + 1));
+				*(vfbid_tbl + index) = dest;
+			}
 		}
-                if (GET_PORT_PROP("hw-port-id", &nae_cfg.ports[port].hw_port_id, sizeof(uint32_t)) < 0) {
-                        nlm_print("fdt missing hw-port-id\n");
+        }
+	
+	return 0;
+}
+
+static inline int get_num_ports(int block, int intf_type)
+{
+	if (intf_type == SGMII_IF) {
+		if (block < 4)
+			return 4;
+		else
+			return 2;
+	}
+	else
+		return 1;	
+}
+
+static inline int get_slots_required(int intf_type)
+{
+	if (intf_type == SGMII_IF)
+		return SGMII_CAL_SLOTS;
+	else if (intf_type == XAUI_IF)
+		return XAUI_CAL_SLOTS;
+	else if (intf_type == INTERLAKEN_IF)	
+		return ILK_CAL_SLOTS;
+	else
+		return 0;		
+}
+
+static inline int valid_context_number(uint32_t context)
+{
+	int max_context;
+
+	if (is_nlm_xlp3xx())
+		max_context = XLP3XX_MAX_NAE_CONTEXTS;
+	else
+		max_context = MAX_NAE_CONTEXTS;
+	return ((context > max_context) ? 0 : 1);
+}
+
+static inline int valid_calendar_slot(uint32_t slot)
+{
+        return ((slot > MAX_CAL_SLOTS) ? 0 : 1);
+}
+
+static int get_interface_type(void *fdt, char *nae_port_str, int block, int port, int node)
+{
+	int intf_type, offset;
+	char port_type_str[NAE_MAX_PROP_LEN];
+	nlm_nae_config_ptr nae_cfg = nlm_node_cfg.nae_cfg[node];
+
+	intf_type = nlm_get_interface_type(node, block);
+
+	if (intf_type == DC_NOT_PRSNT) {
+        	if (GET_PORT_STR_PROP("mode", port_type_str, NAE_MAX_PROP_LEN) < 0) {
+                	nlm_print("FDT missing mode param for complex %d\n", block);
+                        intf_type = UNKNOWN_IF;
+                }
+                if (!strcmp(port_type_str, "sgmii")) {
+                        intf_type = DC_SGMII;
+                }
+                else if (!strcmp(port_type_str, "xaui")) {
+                        intf_type = DC_XAUI;
+                }
+                else if (!strcmp(port_type_str, "interlaken")) {
+                        intf_type = DC_ILK;
                 }
                 else {
-                        nlm_print("hw-port-id[%d]\n", nae_cfg.ports[port].hw_port_id);
+                        intf_type = UNKNOWN_IF;
+                        return -1;
+                }
+        }
+
+        switch(intf_type) {
+        	case DC_ILK:
+			if ((is_nlm_xlp3xx()) || (node != 0)) { // FIXME interlaken supported only on node-0 nae
+				nlm_print("Interlaken not supported \n");
+				return -1;
+			}
+			nlm_print("Complex %d in interlaken mode\n", block);
+                	if (is_nlm_xlp8xx()) {
+                        	nae_cfg->ports[port].iftype = INTERLAKEN_IF;
+			//	nae_cfg->ilk_complex_map |= (1 << block);
+			}
+                        else {
+                                nae_cfg->ports[port].iftype = UNKNOWN_IF;
+                                nlm_print("Interlaken is not supported on this board \n");
+                        }
+			break;
+                case DC_SGMII:
+			nlm_print("Complex %d in SGMII mode\n", block);
+			// nae_cfg->sgmii_complex_map |= (1 << block);
+			for(offset = 0; offset < MAX_PORTS_PERBLOCK; offset++) {
+	                        nae_cfg->ports[port+offset].iftype = SGMII_IF;
+			}		
+                        break;
+                case DC_XAUI:
+			nlm_print("Complex %d in xaui mode\n", block);
+			// nae_cfg->xaui_complex_map |= (1 << block);
+                        nae_cfg->ports[port].iftype = XAUI_IF;
+                        break;
+                default:
+                        nae_cfg->ports[port].iftype = UNKNOWN_IF;
+	}
+	return nae_cfg->ports[port].iftype;
+}
+
+static void extract_complex_params(void *fdt, int intf_type, char *nae_port_str, struct nae_complex_config *cmplx)
+{
+	int i = 0;
+	memset(cmplx, 0, sizeof(struct nae_complex_config));
+
+	GET_PORT_PROP("num-channels", &cmplx->num_channels, sizeof(cmplx->num_channels));
+	GET_PORT_PROP("num-free-descs", &cmplx->num_free_desc, sizeof(cmplx->num_free_desc));		
+        GET_PORT_PROP("free-desc-size", &cmplx->free_desc_size, sizeof(cmplx->free_desc_size));
+        GET_PORT_PROP("iface-fifo-size", &cmplx->intf_fifo_size, sizeof(cmplx->intf_fifo_size));
+        GET_PORT_PROP("parser-sequence-fifo-size", &cmplx->prsr_seq_fifo_size, sizeof(cmplx->prsr_seq_fifo_size));
+        GET_PORT_PROP("rx-buffer-size", &cmplx->rx_buf_size, sizeof(cmplx->rx_buf_size));
+        GET_PORT_PROP("ucore-mask",&cmplx->ucore_mask, sizeof(cmplx->ucore_mask));
+	if (intf_type == SGMII_IF) {
+		if (is_nlm_xlp3xx()) {
+		     for (i = 0 ; i < 4; i++) {
+			if (cmplx->prsr_seq_fifo_size[i] > XLP3XX_SGMII_PARSERSEQ_FIFO_MAX)
+				cmplx->prsr_seq_fifo_size[i] = XLP3XX_SGMII_PARSERSEQ_FIFO_MAX;
+		     }	
 		}
+		GET_PORT_PROP("ext-phy-addr", &cmplx->ext_phy_addr, sizeof(cmplx->ext_phy_addr));
+        	GET_PORT_PROP("ext-phy-bus", &cmplx->ext_phy_bus, sizeof(cmplx->ext_phy_bus));
+	}
+	else if (intf_type == INTERLAKEN_IF) {
+		if(GET_PORT_PROP("num-lanes", &cmplx->num_lanes, sizeof(uint32_t)) < 0) {
+                	nlm_print("fdt missing num-lanes, default 4\n");
+                        cmplx->num_lanes = 8;
+                }
+                if(GET_PORT_PROP("lane-rate", &cmplx->lane_rate, sizeof(uint32_t)) < 0) {
+                        nlm_print("fdt missing lane-rate, default 0\n");
+                        cmplx->lane_rate = XLP_ILK_LANE_RATE_LOW;
+                }
+	}
+	GET_PORT_PROP("mgmt-port", &cmplx->mgmt, sizeof(cmplx->mgmt)); 
+        GET_PORT_PROP("loopback", &cmplx->loopback, sizeof(cmplx->loopback));
+}
+
+uint32_t nlm_hal_get_frin_total_queue(int node)
+{
+	uint32_t frin_total_queue = 0;
 
-		GET_PORT_PROP("num-channels", &nae_cfg.ports[port].num_channels, sizeof(uint32_t));
+	if (is_nlm_xlp3xx()) {
+		frin_total_queue = XLP_3XX_NET_RX_VC_LIMIT - XLP_3XX_NET_RX_VC_BASE + 1;
+	}else{
+		frin_total_queue = XLP_NET_RX_VC_LIMIT - XLP_NET_RX_VC_BASE - 1; //skip gdx port
+	}
+	return frin_total_queue;
+}
+
+uint32_t nlm_hal_get_frin_queue_base(int node)
+{
+	uint32_t frin_queue_base = 0;
+	if (is_nlm_xlp3xx()) {
+		frin_queue_base = (node <<10) | XLP_3XX_NET_RX_VC_BASE;
+	}else{
+		frin_queue_base = (node << 10) | XLP_NET_RX_VC_BASE;
+	}
+	return frin_queue_base;
+}
+
+
+
+static int parse_port_config(void *fdt, int node, nlm_nae_config_ptr nae_cfg)
+{
+	char nae_port_str[80];
+	struct nae_complex_config cmplx_cfg;
+	int max_complex, block, intf_type, fdt_cmplx_offset ;
+	int offset, port, num_ports;
+	struct nlm_hal_nae_port *nae_port;
+	uint32_t txq, max_context = 0, tx_slots = 0, rx_slots = 0;
+
+	if (is_nlm_xlp3xx()) {
+		max_complex = XLP3XX_MAX_NAE_COMPLEX;
+		nae_cfg->frin_queue_base = (node <<10) | XLP_3XX_NET_RX_VC_BASE;
+		nae_cfg->frin_total_queue = XLP_3XX_NET_RX_VC_LIMIT - XLP_3XX_NET_RX_VC_BASE + 1;
+		txq = (node <<10) | XLP_3XX_NET_TX_VC_BASE;
+	}
+	else {
+		max_complex = XLP8XX_MAX_NAE_COMPLEX;
+		nae_cfg->frin_queue_base = (node << 10) | XLP_NET_RX_VC_BASE;
+                nae_cfg->frin_total_queue = XLP_NET_RX_VC_LIMIT - XLP_NET_RX_VC_BASE - 1; //skik gdx port
+		txq = (node <<10) | XLP_NET_TX_VC_BASE;
+	}
 	
-		GET_PORT_STR_PROP("type", port_type_str, MAX_PROP_LEN);
-		if (!strcmp(port_type_str, "SGMII_IF")) {
-			nae_cfg.ports[port].iftype = SGMII_IF;
+	nlm_print("node %d frin_queue_base %d frin_total_queue %d \n", node, nae_cfg->frin_queue_base, nae_cfg->frin_total_queue);
+	for(block=0, port = 0; block < max_complex; block++) {
+#ifndef NLM_HAL_UBOOT
+		if (is_nlm_xlp8xx_ax() && is_xlp_evp1() && (block % 2))
+			continue;
+#endif
+		sprintf(nae_port_str, "/soc/nae@node-%d/complex@%d",node, block);
+		fdt_cmplx_offset = fdt_path_offset(fdt, nae_port_str);
+		if (fdt_cmplx_offset < 0) {
+			nlm_print("complex %d configuration is missing in FDT\n", block);
+			continue;
+		}
+
+		intf_type = get_interface_type(fdt, nae_port_str, block, port, node);
+
+		if (intf_type == SGMII_IF) {
+			sprintf(nae_port_str, "/soc/nae@node-%d/complex@%d/sgmii", node, block);
+			fdt_cmplx_offset = fdt_path_offset(fdt, nae_port_str); 
+	                if (fdt_cmplx_offset < 0) {
+				nlm_print("Complex %d SGMII configuration missing in FDT \n", block);
+				continue;
+			}
+			nae_cfg->sgmii_complex_map |= (1 << block);
+
 		}
-		else if (!strcmp(port_type_str, "XAUI_IF")) {
-			nae_cfg.ports[port].iftype = XAUI_IF;
-			xlp_nae_config_xaui((nae_cfg.ports[port].hw_port_id / 4), port);
+		else if (intf_type == XAUI_IF) {
+			sprintf(nae_port_str, "/soc/nae@node-%d/complex@%d/xaui", node, block);
+			fdt_cmplx_offset = fdt_path_offset(fdt, nae_port_str);
+                        if (fdt_cmplx_offset < 0) {
+                                nlm_print("Complex %d XAUI configuration missing in FDT \n", block); 
+                                continue;
+                        }
+			nae_cfg->xaui_complex_map |= (1 << block);
 		}
-		else if (!strcmp(port_type_str, "INTERLAKEN_IF")) {
-			nae_cfg.ports[port].iftype = INTERLAKEN_IF;
-			xlp_nae_config_interlaken((nae_cfg.ports[port].hw_port_id / 4), port, num_lanes);
+		else if (intf_type == INTERLAKEN_IF) {
+			sprintf(nae_port_str, "/soc/nae@node-%d/complex@%d/interlaken",node, block);
+			fdt_cmplx_offset = fdt_path_offset(fdt, nae_port_str);
+                        if (fdt_cmplx_offset < 0) {
+                                nlm_print("Complex %d interlaken configuration missing in FDT \n", block);  
+                                continue;
+                        }
+			nae_cfg->ilk_complex_map |= (1 << block);
 		}
-		else  {
-			nae_cfg.ports[port].iftype = UNKNOWN_IF;
-			nlm_print("HW port %d with Unknown interface type !!!\n",nae_cfg.ports[port].hw_port_id);
+		else {
+			nlm_print("Complex %d interface type is unknown\n", block);
+			continue;
 		}
 
-		GET_PORT_PROP("num-free-desc", &nae_cfg.ports[port].num_free_desc,
-			sizeof(uint32_t));
+		num_ports = get_num_ports(block, intf_type);
+		
+		extract_complex_params(fdt, intf_type, nae_port_str, &cmplx_cfg);
+
+		for(offset = 0; offset < num_ports; offset++, port++) {
+			nae_port = &nae_cfg->ports[port];
+			nae_port->hw_port_id = (block * MAX_PORTS_PERBLOCK) + offset;
+			nae_port->txq = txq;
+			nae_port->rxq = nae_cfg->frin_queue_base + nae_port->hw_port_id;
+			nae_port->num_free_desc = cmplx_cfg.num_free_desc[offset];
+			nae_port->free_desc_size = cmplx_cfg.free_desc_size[offset];
+			nae_port->intf_fifo_size = cmplx_cfg.intf_fifo_size[offset];
+			nae_port->prsr_seq_fifo_size = cmplx_cfg.prsr_seq_fifo_size[offset];
+			nae_port->num_channels = cmplx_cfg.num_channels[offset];
+			nae_port->rx_buf_size = cmplx_cfg.rx_buf_size[offset];	// RX buf size is per context. The value given in dts is for the interface. This should be divided by num_channels  
+			nae_port->ucore_mask = cmplx_cfg.ucore_mask[offset];
+			nae_port->ext_phy_addr = cmplx_cfg.ext_phy_addr[offset];
+			nae_port->ext_phy_bus = cmplx_cfg.ext_phy_bus[offset];
+			if (is_nlm_xlp3xx()) {
+				nae_port->ucore_mask &= 0xFF;
+				nae_port->ext_phy_bus = 0;
+			}
+			nae_port->rx_slots_reqd = get_slots_required(nae_port->iftype);
+			nae_port->tx_slots_reqd = nae_port->rx_slots_reqd; 						
+			nae_cfg->lane_rate[nae_port->hw_port_id / XLP_ILK_MAX_LANES] = cmplx_cfg.lane_rate;
+			nae_cfg->num_lanes[nae_port->hw_port_id / XLP_ILK_MAX_LANES] = cmplx_cfg.num_lanes;
+			nae_port->mgmt = cmplx_cfg.mgmt[offset];
+			nae_port->valid = 1;
+			max_context += nae_port->num_channels;
+			if (!valid_context_number(max_context)) 
+				return -1;
+			tx_slots += nae_port->tx_slots_reqd;
+			if (!valid_calendar_slot(tx_slots))
+				return -1;
+			rx_slots += nae_port->rx_slots_reqd;
+			txq += nae_port->num_channels;		
+			nlm_print("port %d hwport %d num_channel %d num_free_desc %d \n", port, nae_port->hw_port_id, nae_port->num_channels, nae_port->num_free_desc);
+		}		
+		if (intf_type == INTERLAKEN_IF)
+			block++;
+	}
+	nae_cfg->num_ports = port;
+	nae_cfg->rx_cal_slots = rx_slots;
+	nae_cfg->tx_cal_slots = tx_slots;
+	nae_cfg->num_contexts = max_context;
+	nlm_print("Node %d number of ports %d max_channels %d\n", node, nae_cfg->num_ports, nae_cfg->num_contexts);
+	return nae_cfg->num_ports;
+}
 
-		if(GET_PORT_PROP("num-nae-regs", &num_nae_regs, sizeof(uint32_t)) < 0)
-			nlm_print("fdt missing per port num-nae-regs\n");
 
-		size = sizeof(uint32_t) * num_nae_regs * 2;
-		nae_regs = nlm_malloc(size);
-		if (!nae_regs) {
-			nlm_print("[%s] Unable to allocate memory for nae-regs, aborting\n", __func__);
-			return;
-		}
-		GET_PORT_PROP("nae-regs", nae_regs, size);
+/**
+* @brief parse_fdt_nae_config function is used to initailize and program the NAE and all interfaces, based on the configuration in FDT.
+*
+* @param [in] fdt Pointer to the FDT
+* @param [in] node Node number
+* @param [in] nae_cfg nlm_nae_config_ptr pointer to the internal HAL nae_cfg structure
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+static void parse_fdt_nae_config(void *fdt, int node, nlm_nae_config_ptr nae_cfg)
+{
+	int hw_port;
+	int num_ports = 0, port = 0;
+	uint32_t start_port, num_nae_regs, num_intf_regs;
+	char path_str[50];
+	uint32_t vfbid_tbl[MAX_VFBID_ENTRIES];
+	uint32_t rx_config = 0, tx_config = 0;
+	int frequency, context = 0;
 
-		size = sizeof(uint32_t) * num_intf_regs * 2;
-		intf_regs = nlm_malloc(size);
-		if (!intf_regs) {
-			nlm_print("[%s] Unable to allocate memory for if-regs, aborting\n", __func__);
-			return;
-		}
-		GET_PORT_PROP("intf-regs", intf_regs, size);
+	/* Parse Nae Config */
+	start_port = num_nae_regs = num_intf_regs = 0;
 
-		if (mgmt_intf && rely_on_firmware_config) {
-			int reg = 0;
+	sprintf(path_str,"/soc/nae@node-%d",node);
 
-			/* don't rely on firmware for free-in desc carving */
-			for (reg = 0; reg < num_nae_regs; reg++) {
-				if (nae_regs[reg * 2] != FREE_IN_FIFO_CFG) continue;
-				nlm_hal_write_nae_reg(FREE_IN_FIFO_CFG, nae_regs[reg * 2 + 1]);
-			}
-		} else {
-			nlm_print("Configuring per-port interface registers for port@%d\n", i);
-			/* Configure per port interface registers */
-			nlm_hal_init_if_regs(nae_cfg.ports[port].iftype, nae_cfg.ports[port].hw_port_id, intf_regs, num_intf_regs);
+	if(GET_NAE_PROP(path_str, "frequency", &frequency, sizeof(uint32_t)) < 0)
+		nlm_print("fdt missing frequency\n");
 
-			nlm_print("Configuring per-port NAE registers for port@%d\n", i);
-			/* Configure per port NAE registers */
-			nlm_hal_init_nae_regs(nae_cfg.ports[port].iftype, nae_regs, num_nae_regs);
-		}
+	set_nae_frequency(node, frequency);
+
+	parse_vfbid_config(fdt, node, vfbid_tbl);
+
+	num_ports = parse_port_config(fdt, node, nae_cfg);  
+	if (num_ports < 0) {
+		nlm_print("Node %d NAE configuration failed. Check fdt params !!!", node);
+		while(1);
+	}
+
+
+	if (nae_cfg->sgmii_complex_map) {
+		NAE_DEBUG("node %d SGMII PCS init 0x%x\n", node, nae_cfg->sgmii_complex_map);
+	       	nlm_hal_sgmii_pcs_init(node, nae_cfg->sgmii_complex_map);
+	}
+	
+	if (nae_cfg->xaui_complex_map) {
+		NAE_DEBUG("node %d XAUI PCS init 0x%x\n", node, nae_cfg->xaui_complex_map);
+		nlm_hal_xaui_pcs_init(node, nae_cfg->xaui_complex_map);
+	}
+
+	if (nae_cfg->ilk_complex_map) {
+		NAE_DEBUG("node %d interlaken PCS init 0x%x\n", node, nae_cfg->ilk_complex_map);
+		nlm_hal_ilk_pcs_init(node, nae_cfg->ilk_complex_map);
+	}
+
+        /* Clear NETIOR soft reset */
+        nlm_hal_write_mac_reg(node, BLOCK_7, LANE_CFG, NETIOR_SOFTRESET, 0x0);
+        NAE_DEBUG("%s Completed NETIOR soft reset\n", __func__);
+
+
+	/* Disable RX enable bit in RX_CONFIG */
+	rx_config = nlm_hal_read_nae_reg(node, RX_CONFIG);
+	rx_config &= 0xfffffffe;
+	nlm_hal_write_nae_reg(node, RX_CONFIG, rx_config);
+
+	if (is_nlm_xlp8xx_ax() == 0) {
+		tx_config = nlm_hal_read_nae_reg(node, TX_CONFIG);
+		tx_config &= ~(1<<3);
+		nlm_hal_write_nae_reg(node, TX_CONFIG, tx_config);
+	}	
+	
+	nlm_config_nae_global(node, nae_cfg);
+
+	if (nae_cfg->flags & VFBID_FROM_FDT) {
+		nlm_config_vfbid_table(node, 0 , MAX_VFBID_ENTRIES, vfbid_tbl);	
+	}
+
+	if(nae_freein_fifo_cfg(fdt, node, nae_cfg) < 0)
+		return;
+	
+	for(port = 0; port < num_ports; port++)
+	{
+		hw_port = nae_cfg->ports[port].hw_port_id;
+                if (nae_cfg->ports[port].iftype == XAUI_IF) {
+                        xlp_nae_config_xaui(node, (hw_port / 4), port, nae_cfg->ports[port].vlan_pri_en);
+                }
+                else if (nae_cfg->ports[port].iftype == INTERLAKEN_IF) {
+                        xlp_nae_config_interlaken(node, (hw_port / 4), port, nae_cfg->num_lanes[hw_port / XLP_ILK_MAX_LANES]);
+                }
 
 		/* Egress Config */
-		config_egress(context, port);
-		context += nae_cfg.ports[port].num_channels;
+		NAE_DEBUG("Egress context %d port %d num_channels %d \n",context,port, nae_cfg->ports[port].num_channels);
+		config_egress(node, context, port, nae_cfg);
+
+#if !defined(NLM_HAL_UBOOT) && defined(NLM_CORTINA_SUPPORT)
+                if (nae_cfg->ports[port].iftype == INTERLAKEN_IF) {
+                        if ((nlm_hal_init_cs34x7(hw_port, nae_cfg->num_lanes[hw_port / XLP_ILK_MAX_LANES],
+			 nae_cfg->lane_rate[hw_port / XLP_ILK_MAX_LANES]) == 0) && 
+				(is_xlp_ilk_lanealigned(node, hw_port/4)))
+				NAE_DEBUG("Interlaken lanes on port %d are aligned\n", hw_port);
+			else
+				NAE_DEBUG("Interlaken initialization on port %d failed\n", hw_port);
+                }
+#endif
+		context += nae_cfg->ports[port].num_channels;
 
-		nlm_free(nae_regs);
-		nlm_free(intf_regs);
+		nlm_write_ucore_sprayvec(node, hw_port, nae_cfg->ports[port].ucore_mask);
+		nlm_write_fifo_size(node, hw_port, nae_cfg->ports[port].free_desc_size);
 
 		if (!rely_on_firmware_config) {
-			if (nlm_hal_open_if(nae_cfg.ports[port].iftype, nae_cfg.ports[port].hw_port_id) < 0) {
-				nlm_print("[%s] Unable to open port %d\n", __func__, i);
+			if (nlm_hal_open_if(node, nae_cfg->ports[port].iftype, hw_port) < 0) {
+				nlm_print("[%s] Unable to open port %d\n", __func__, port);
 				continue;
-			}
+			} 
 		}
 
-		nlm_print("Initialized port@%d\n", i);
+		nlm_print("Initialized port@%d\n", port);
 	}
 }
 
-#ifndef NLM_HAL_LINUX_KERNEL
-#define preempt_enable()
-#define preempt_disable()
-#endif
-
-#define msgrng_enable(flags)                \
-do {                                        \
-  preempt_disable(); \
-  __asm__ volatile (                        \
-		    ".set push\n\t"                 \
-		    ".set reorder\n\t"              \
-		    ".set noat\n\t"                 \
-		    "mfc0 %0, $12\n\t"              \
-		    "li  $8, 0x40000001\n\t"        \
-		    "or  $1, %0, $8\n\t"            \
-		    "xori $1, 1\n\t"                \
-		    ".set noreorder\n\t"            \
-		    "mtc0 $1, $12\n\t"              \
-		    ".set\tpop\n\t"                 \
-		    : "=r" (flags)                  \
-		    :                               \
-		    : "$8"                          \
-		    );                              \
-  preempt_enable(); \
-} while (0)
-
-#define msgrng_disable(flags) __asm__ volatile (    \
-                 "mtc0 %0, $12" : : "r" (flags))
-
-#define msgrng_access_enable(mflags) do {   \
-  preempt_disable();                        \
-  msgrng_enable(mflags);                \
-} while(0)
-
-#define msgrng_access_disable(mflags) do {   \
-  msgrng_disable(mflags);              \
-  preempt_enable();                          \
-} while(0)
-
-static void drain_nae_frin_fifo_descs(void)
+/**
+* @brief drain_nae_frin_fifo_descs function is used to clear all FreeIn FIFOs in the NAE Ingress path.
+*
+* @param [in] node Node number
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+static void drain_nae_frin_fifo_descs(int node)
 {
 	int i = 0;
-	uint32_t value = 0;
+        uint32_t value = 0, fifo_mask;
+
+        if (is_nlm_xlp3xx()) {
+                fifo_mask = 0xff;
+        }
+        else {
+                fifo_mask = 0xfffff;
+        }
 
-	nlm_hal_write_nae_reg(RX_FREE_FIFO_POP, 0xfffff);
+	nlm_hal_write_nae_reg(node, RX_FREE_FIFO_POP, fifo_mask);
 	for (i = 0; i < 10; i++) {
 		nlm_mdelay(1);
-		value = nlm_hal_read_nae_reg(RX_FREE_FIFO_POP);
-		if (value == 0xfffff) break;
+		value = nlm_hal_read_nae_reg(node, RX_FREE_FIFO_POP);
+		if (value == fifo_mask) break;
 	}
 	if (i == 10) {
 		nlm_print("Unable to zap free in fifo!(value=0x%08x)\n", value);
@@ -841,24 +3101,42 @@ static void drain_nae_frin_fifo_descs(void)
 	else {
 		nlm_print("Successfully zapped free in fifo!\n");
 	}
-	nlm_hal_write_nae_reg(RX_FREE_FIFO_POP, 0);
+	nlm_hal_write_nae_reg(node, RX_FREE_FIFO_POP, 0);
 }
 
 static int debug = 1;
 
-static void print_frin_desc_carving(void)
+/**
+* @brief print_frin_desc_carving function prints the carving of the FreeIn FIFOs for the available interfaces.
+*
+* @param [in] node Node number
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+static void print_frin_desc_carving(int node)
 {
-	int intf;
+	int intf, max;
 
 	if (!debug) return;
 
-	for (intf = 0; intf < 20; intf++) {
+	if (is_nlm_xlp3xx()) {
+		max = XLP_3XX_MAX_PORTS;
+	}
+	else {
+		max = XLP_MAX_PORTS;
+	}
+		
+	for (intf = 0; intf < max; intf++) {
 		uint32_t value = 0;
 		int start = 0, size = 0;
 
-		nlm_hal_write_nae_reg(FREE_IN_FIFO_CFG, (0x80000000 | intf));
+		nlm_hal_write_nae_reg(node, FREE_IN_FIFO_CFG, (0x80000000 | intf));
 
-		value = nlm_hal_read_nae_reg(FREE_IN_FIFO_CFG);
+		value = nlm_hal_read_nae_reg(node, FREE_IN_FIFO_CFG);
 		size = 2 * ((value >> 20) & 0x3ff);
 		start = 2 * ((value >> 8) & 0x1ff);
 
@@ -866,20 +3144,50 @@ static void print_frin_desc_carving(void)
 	}
 }
 
-static void deflate_frin_fifo_carving(void)
+/**
+* @brief deflate_frin_fifo_carving function initializes the FreeIn FIFO carvings with minimum default values.
+*
+* @param [in] node Node number
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+static void deflate_frin_fifo_carving(int node)
 {
-	int intf = 0;
+	int intf = 0, max;
 	const int minimum_size = 8; /* this represents entries, each entry holds 2 descriptors */
 	int start = 0;
 	uint32_t value = 0;
 
-	for (intf = 0; intf < 20; intf++) {
+        if (is_nlm_xlp3xx()) {
+                max = XLP_3XX_MAX_PORTS;
+        }
+        else {
+                max = XLP_MAX_PORTS;
+        }
+
+	for (intf = 0; intf < max; intf++) {
 		start = minimum_size * intf;
 		value = (minimum_size << 20) | (start << 8) | (intf);
-		nlm_hal_write_nae_reg(FREE_IN_FIFO_CFG, value);
+		nlm_hal_write_nae_reg(node, FREE_IN_FIFO_CFG, value);
 	}
 }
 
+/**
+* @brief check_header function is used to validate the FDT.
+*
+* @param [in] fdt Pointer to the FDT
+*
+* @return
+*  - 0 for valid FDT
+*  - -1 for invalid FDT
+* 
+* @ingroup hal_nae
+*
+*/
 static int check_header(void *fdt)
 {
         int fdt_err = fdt_check_header(fdt);
@@ -892,7 +3200,18 @@ static int check_header(void *fdt)
 	return 0;
 }
 
-void drain_nae_stray_packets(void)
+/**
+* @brief drain_nae_stray_packets function disables Rx for port 16 and 17, and sends 100 free descriptors to drain any packets in the ingress path.
+*
+* @param [in] node Node number
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+void drain_nae_stray_packets(int node)
 {
 	int i, j;
 	int mgmt_vc = 1016;
@@ -903,7 +3222,7 @@ void drain_nae_stray_packets(void)
 	for (j = 0; j < 2; ++j) {
 
 		/* Turn off RX enable */
-		write_gmac_reg(16 + j , MAC_CONF1,0);
+		write_gmac_reg(node, 16 + j , MAC_CONF1,0);
 
 
 		/* Send Free descriptors */
@@ -921,109 +3240,88 @@ void drain_nae_stray_packets(void)
 	nlm_mdelay(1);
 }
 
-static void reset_nae(void)
+/**
+* @brief reset_nae function resets the NAE.
+*
+* @param [in] node Node number
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+static void reset_nae(int node)
 {
-	uint32_t rx_config = nlm_hal_read_nae_reg(RX_CONFIG);
-
+	uint32_t rx_config = nlm_hal_read_nae_reg(node, RX_CONFIG);
+	int reset_bit = 9;  
 	/* Reset NAE */
-	nlm_hal_write_sys_reg(SYS_RESET, (1 << 9));
+
+	if (is_nlm_xlp3xx())
+		reset_bit = 6;
+	else
+		reset_bit = 9;
+	
+	nlm_hal_write_sys_reg(node, SYS_RESET, (1 << reset_bit));
 	nlm_mdelay(1);
 
-	nlm_hal_write_sys_reg(SYS_RESET, (0 << 9));
+	nlm_hal_write_sys_reg(node, SYS_RESET, (0 << reset_bit));
 	nlm_mdelay(1);
 
-	rx_config = nlm_hal_read_nae_reg(RX_CONFIG);
+	rx_config = nlm_hal_read_nae_reg(node, RX_CONFIG);
 	nae_reset_done = 1;
 }
 
-int nlm_hal_init_nae(void *fdt, int dom_id)
+#if defined(__MIPSEL__)
+static uint32_t membar_fixup(uint32_t l)
 {
-	int i = 0;
-	int context = 0, ctxsize = 0, offset=0;
-	uint32_t bar0;
-
-	if (check_header(fdt)) {
-		nlm_print("Sanity check on FDT blob failed! Aborting\n");
-		return -1;
-	}
-
-	bar0 = nlm_hal_read_32bit_reg(0x18018000, 0x4);
-
-	/* Initialize default configuration */
-	for (i = 0; i < 18; i++) {
-		nae_cfg.fb_vc = 1;
-		nae_cfg.rx_vc = 0;
-		nae_cfg.ports[i].valid = 0;
-		nae_cfg.ports[i].mgmt = 0;
-	}
-
-	for (i = 0; i < MAX_NAE_CONTEXTS; i++) {
-		/* 18 is an invalid port */
-		cntx2port[i] = 18;
-	}
-
-	/* frin_fifo represents the 20 pools of free-in descriptor fifos */
-	//drain_nae_stray_packets();
-	drain_nae_frin_fifo_descs();
-	deflate_frin_fifo_carving();
-
-	reset_nae();
-
-	nlm_hal_write_32bit_reg(0x18018000, 0x4, bar0);
-
-	nlm_print("Configuring ucore...\n");
-	parse_ucore_config(fdt);
-
-	nlm_print("Configuring NAE...\n");
-	parse_fdt_nae_config(fdt);
-
-	nlm_print("Configuring CPU-NAE...\n");
-	parse_fdt_cpu_config(fdt, dom_id);
-
-	nlm_print("Configuring PoE...\n");
-	parse_poe_config(fdt);
+	unsigned char b;
+	uint32_t fixup;
 
-	nlm_print("NAE configuration done!\n");
+	if (!is_nlm_xlp8xx_ax())
+		return l;
 
-	nlm_print("Digest of FDT based NAE config: \n");
-	nlm_print("fb_vc = %d, rx_vc = %d\n", nae_cfg.fb_vc, nae_cfg.rx_vc);
-	for (i = 0; i < 18; i++) {
-		struct nlm_hal_nae_port *port = &nae_cfg.ports[i];
+	b = (l >> 24) & 0xff;
+	fixup = ((b << 24) | (b << 16) | (b << 8) | (b));
 
-		if (!port->valid) continue;
-
-		ctxsize = nae_cfg.ports[i].num_channels;
-#if 0
-		/* Default NAE configuration uses hw_port_id as the context */
-		context = port->hw_port_id;
-		cntx2port[context] = i; /* logical port */
+	return fixup;
+}
 #else
-		for(offset=0; offset < ctxsize; offset++)
-			cntx2port[context + offset] = i; /* logical port */
-
+#define membar_fixup(x) (x)
 #endif
 
-		nlm_print("port@%d: valid = %d, mgmt = %d, num_free_desc = %d ctxt = %d\n"
-		       "\t txq[0] = %d, txq[1] = %d, rxq = %d, hw_port_id = %d\n", i,
-			  port->valid, port->mgmt, port->num_free_desc, context,
-		       port->txq_range[0], port->txq_range[1], port->rxq, port->hw_port_id);
 
-		context += ctxsize;
+/**
+* @brief reset_nae_mgmt function deain the frin fifo followed by the reset_nae .
+*
+* @param [in] node Node number
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
 
-	}
+void  reset_nae_mgmt(int node)
+{
+	uint32_t bar0;
+	nlm_print("Resetting NAE ..\n");
+	bar0 = nlm_hal_read_32bit_reg(nlm_hal_get_dev_base(node, 0, XLP_NAE_DEVICE, XLP_NAE_FUNC), 0x4);
+	bar0 = membar_fixup(bar0);
+	drain_nae_frin_fifo_descs(node);
+	reset_nae(node);
+	nlm_hal_write_32bit_reg(nlm_hal_get_dev_base(node, 0, XLP_NAE_DEVICE, XLP_NAE_FUNC), 0x4, bar0);
+}
 
-	nlm_print("FRIN desc carving after HAL initialization...\n");
-	print_frin_desc_carving();
 
-	return 0;
-}
 /*
  *  Interface support
  */
 
 #define PHY_STATUS_RETRIES 20000
-#define WAIT_XGMAC_MDIO_BSY_CLEAR   for (i = 0; i < PHY_STATUS_RETRIES; i++) {	\
-        if((nlm_hal_read_mac_reg( 7, intf_type,					\
+#define WAIT_XGMAC_MDIO_BSY_CLEAR(node)  for (i = 0; i < PHY_STATUS_RETRIES; i++) {	\
+        if((nlm_hal_read_mac_reg(node, 7, intf_type,					\
         	EXT_XG0_MDIO_RD_STAT + bus * 4 ) & EXT_XG_MDIO_STAT_MBSY) == 0)	\
                         break;							\
         }
@@ -1046,7 +3344,23 @@ int nlm_hal_init_nae(void *fdt, int dom_id)
  *  Return value:
  *         0 - success
  ********************************************************************* */
-static int nlm_hal_xgmac_mdio_indirect_addr(int bus,int block, int intf_type, int phyaddr, int regidx)
+/**
+* @brief nlm_hal_xgmac_mdio_indirect_addr writes the external PHY register index for a following indirect read/write.
+*
+* @param [in] node Node number
+* @param [in] bus External MDIO bus number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] intf_type GMAC_0, GMAC_1, GMAC_2, GMAC_3, XGMAC, INTERLAKEN, PHY, LANE_CFG (only valid for block 7)
+* @param [in] phyaddr External PHY's address
+* @param [in] regidx PHY register index to read
+*
+* @return
+* 	- 0 on success
+* 
+* @ingroup hal_nae
+*
+*/
+static int nlm_hal_xgmac_mdio_indirect_addr(int node, int bus,int block, int intf_type, int phyaddr, int regidx)
 {
         int32_t i;
         int16_t dev_type;
@@ -1055,10 +3369,10 @@ static int nlm_hal_xgmac_mdio_indirect_addr(int bus,int block, int intf_type, in
         dev_type = 0x5;
 
         /* load  XGMC_MDIO_CTRL_DATA register with indirect addr */
-        nlm_hal_write_mac_reg( 7 , intf_type,
+        nlm_hal_write_mac_reg(node, 7 , intf_type,
                                 EXT_XG0_MDIO_CTRL_DATA + bus * 4, regidx);
 
-        nlm_hal_write_mac_reg( 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+        nlm_hal_write_mac_reg(node, 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
                                  phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
                                 | dev_type << EXT_XG_MDIO_CTRL_REG_POS
                                 | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
@@ -1071,9 +3385,9 @@ static int nlm_hal_xgmac_mdio_indirect_addr(int bus,int block, int intf_type, in
 
 
         /* poll master busy bit until it is not busy */
-	WAIT_XGMAC_MDIO_BSY_CLEAR
+	WAIT_XGMAC_MDIO_BSY_CLEAR(node)
 
-        nlm_hal_write_mac_reg( 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+        nlm_hal_write_mac_reg(node, 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
                                  phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
                                 | dev_type << EXT_XG_MDIO_CTRL_REG_POS
                                 | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
@@ -1085,7 +3399,7 @@ static int nlm_hal_xgmac_mdio_indirect_addr(int bus,int block, int intf_type, in
 
 
         /* poll master busy bit until it is not busy */
-	WAIT_XGMAC_MDIO_BSY_CLEAR
+	WAIT_XGMAC_MDIO_BSY_CLEAR(node)
 	return 0;
 }
 
@@ -1101,7 +3415,24 @@ static int nlm_hal_xgmac_mdio_indirect_addr(int bus,int block, int intf_type, in
  *  Return value:
  *         0 - success
  ********************************************************************* */
-int nlm_hal_xgmac_mdio_indirect_write(int bus, int block, int intf_type, int phyaddr, int regidx, uint16_t val)
+/**
+* @brief nlm_hal_xgmac_mdio_indirect_write writes an external PHY register.
+*
+* @param [in] node Node number
+* @param [in] bus External MDIO bus number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] intf_type GMAC_0, GMAC_1, GMAC_2, GMAC_3, XGMAC, INTERLAKEN, PHY, LANE_CFG (only valid for block 7)
+* @param [in] phyaddr External PHY's address
+* @param [in] regidx PHY register index to read
+* @param [in] val Value to write
+*
+* @return
+* 	- 0 on success
+* 
+* @ingroup hal_nae
+*
+*/
+int nlm_hal_xgmac_mdio_indirect_write(int node, int bus, int block, int intf_type, int phyaddr, int regidx, uint16_t val)
 {
         int32_t  i;
         int16_t dev_type;
@@ -1109,12 +3440,12 @@ int nlm_hal_xgmac_mdio_indirect_write(int bus, int block, int intf_type, int phy
         dev_type = 0x5;
 
          /* first is indirect address cycle */
-        nlm_hal_xgmac_mdio_indirect_addr(bus, block, intf_type, phyaddr, regidx);
+        nlm_hal_xgmac_mdio_indirect_addr(node, bus, block, intf_type, phyaddr, regidx);
 
-        nlm_hal_write_mac_reg( 7 , intf_type,
+        nlm_hal_write_mac_reg(node, 7 , intf_type,
                                 EXT_XG0_MDIO_CTRL_DATA+ bus * 4, val);
 
-        nlm_hal_write_mac_reg( 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+        nlm_hal_write_mac_reg(node, 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
                                  phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
                                 | dev_type << EXT_XG_MDIO_CTRL_REG_POS
                                 | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
@@ -1126,10 +3457,10 @@ int nlm_hal_xgmac_mdio_indirect_write(int bus, int block, int intf_type, int phy
                                 | EXT_XG_MDIO_CTRL_ST);
 
         /* poll master busy bit until it is not busy */
-	WAIT_XGMAC_MDIO_BSY_CLEAR
+	WAIT_XGMAC_MDIO_BSY_CLEAR(node)
 
 
-        nlm_hal_write_mac_reg( 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+        nlm_hal_write_mac_reg(node, 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
                                  phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
                                 | dev_type << EXT_XG_MDIO_CTRL_REG_POS
                                 | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
@@ -1141,7 +3472,7 @@ int nlm_hal_xgmac_mdio_indirect_write(int bus, int block, int intf_type, int phy
 
 
         /* poll master busy bit until it is not busy */
-	WAIT_XGMAC_MDIO_BSY_CLEAR
+	WAIT_XGMAC_MDIO_BSY_CLEAR(node)
 	return 0;
 }
 
@@ -1156,7 +3487,23 @@ int nlm_hal_xgmac_mdio_indirect_write(int bus, int block, int intf_type, int phy
  *  Return value:
  *         value read (16 bits), or 0xffffffff if an error occurred.
  ********************************************************************* */
-int nlm_hal_xgmac_mdio_indirect_read(int bus, int block, int intf_type, int phyaddr, int regidx)
+/**
+* @brief nlm_hal_xgmac_mdio_indirect_read reads an external PHY register.
+*
+* @param [in] node Node number
+* @param [in] bus External MDIO bus number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] intf_type GMAC_0, GMAC_1, GMAC_2, GMAC_3, XGMAC, INTERLAKEN, PHY, LANE_CFG (only valid for block 7)
+* @param [in] phyaddr External PHY's address
+* @param [in] regidx PHY register index to read
+*
+* @return
+*	- value read (16 bits), or 0xffffffff if an error occurred.
+* 
+* @ingroup hal_nae
+*
+*/
+int nlm_hal_xgmac_mdio_indirect_read(int node, int bus, int block, int intf_type, int phyaddr, int regidx)
 {
         int32_t  i;
         int16_t dev_type;
@@ -1164,9 +3511,9 @@ int nlm_hal_xgmac_mdio_indirect_read(int bus, int block, int intf_type, int phya
         dev_type = 0x5;
 
          /* first is indirect address cycle */
-        nlm_hal_xgmac_mdio_indirect_addr(bus, block, intf_type, phyaddr, regidx);
+        nlm_hal_xgmac_mdio_indirect_addr(node, bus, block, intf_type, phyaddr, regidx);
 
-        nlm_hal_write_mac_reg( 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+        nlm_hal_write_mac_reg(node, 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
                                  phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
                                 | dev_type << EXT_XG_MDIO_CTRL_REG_POS
                                 | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
@@ -1178,10 +3525,10 @@ int nlm_hal_xgmac_mdio_indirect_read(int bus, int block, int intf_type, int phya
                                 | EXT_XG_MDIO_CTRL_ST);
 
         /* poll master busy bit until it is not busy */
-	WAIT_XGMAC_MDIO_BSY_CLEAR
+	WAIT_XGMAC_MDIO_BSY_CLEAR(node)
 
 
-        nlm_hal_write_mac_reg( 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+        nlm_hal_write_mac_reg(node, 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
                                  phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
                                 | dev_type << EXT_XG_MDIO_CTRL_REG_POS
                                 | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
@@ -1193,13 +3540,284 @@ int nlm_hal_xgmac_mdio_indirect_read(int bus, int block, int intf_type, int phya
 
 
         /* poll master busy bit until it is not busy */
-	WAIT_XGMAC_MDIO_BSY_CLEAR
+	WAIT_XGMAC_MDIO_BSY_CLEAR(node)
 
-	return nlm_hal_read_mac_reg( 7, intf_type,
+	return nlm_hal_read_mac_reg(node, 7, intf_type,
                                 EXT_XG0_MDIO_RD_STAT + bus * 4) & 0xFFFF;
 
 }
 
+#ifdef CONFIG_N511
+// MPS - Pete Create adequate 10ge phy utils from the above examples
+static int nlm_hal_xgmac_mdio_addr(int node, int bus,int block, int intf_type,
+        int phyaddr, int dev_addr, int regidx)
+{
+        int32_t i;
+
+        /* load  XGMC_MDIO_CTRL_DATA register with addr */
+        nlm_hal_write_mac_reg( node, 7 , intf_type,
+                                EXT_XG0_MDIO_CTRL_DATA + (bus * 4), regidx);
+
+        nlm_hal_write_mac_reg( node, 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_addr << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | EXT_XG_MDIO_CTRL_CMD_LOAD
+                                | MDIO_MIIM_CMD_10G_MMD << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | EXT_XG_MDIO_CTRL_TA << EXT_XG_MDIO_CTRL_TA_POS
+                                | MDIO_CTRL_OP_INDIRECT_ADDR << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+
+        /* poll master busy bit until it is not busy */
+        WAIT_XGMAC_MDIO_BSY_CLEAR(node)
+
+        nlm_hal_write_mac_reg( node, 7, intf_type, EXT_XG0_MDIO_CTRL + (bus * 4),
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_addr << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | MDIO_MIIM_CMD_IDLE << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | 0x0 << EXT_XG_MDIO_CTRL_TA_POS
+                                | MDIO_CTRL_OP_INDIRECT_ADDR << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+
+        /* poll master busy bit until it is not busy */
+        WAIT_XGMAC_MDIO_BSY_CLEAR(node)
+        return 0;
+}
+
+int nlm_hal_xgmac_mdio_write(int node, int bus, int block, int intf_type, int phyaddr,
+        int dev_addr, int regidx, uint16_t val)
+{
+        int32_t  i;
+
+         /* first is indirect address cycle */
+        nlm_hal_xgmac_mdio_addr(0, bus, block, intf_type, phyaddr, dev_addr,
+                regidx);
+
+        nlm_hal_write_mac_reg( node, 7 , intf_type,
+                                EXT_XG0_MDIO_CTRL_DATA + (bus * 4), val);
+
+        nlm_hal_write_mac_reg( node, 7, intf_type, EXT_XG0_MDIO_CTRL+ bus * 4,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_addr << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | EXT_XG_MDIO_CTRL_CMD_LOAD
+                                | MDIO_MIIM_CMD_10G_MMD << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | EXT_XG_MDIO_CTRL_TA << EXT_XG_MDIO_CTRL_TA_POS
+                                | MDIO_CTRL_OP_WRITE_10G_MMD << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+        /* poll master busy bit until it is not busy */
+        WAIT_XGMAC_MDIO_BSY_CLEAR(node)
+
+        nlm_hal_write_mac_reg( node, 7, intf_type, EXT_XG0_MDIO_CTRL + (bus * 4),
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_addr << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | MDIO_MIIM_CMD_IDLE << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | 0x0 << EXT_XG_MDIO_CTRL_TA_POS
+                                | 0 << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+
+        /* poll master busy bit until it is not busy */
+        WAIT_XGMAC_MDIO_BSY_CLEAR(node)
+        return 0;
+}
+
+int nlm_hal_xgmac_mdio_read(int node, int bus, int block, int intf_type, int phyaddr,
+        int dev_addr, int regidx)
+{
+        int32_t  i;
+        int rdval;
+
+         /* first is indirect address cycle */
+        nlm_hal_xgmac_mdio_addr( node, bus, block, intf_type, phyaddr, dev_addr,
+                regidx);
+
+        nlm_hal_write_mac_reg( node, 7, intf_type, EXT_XG0_MDIO_CTRL + (bus * 4),
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_addr << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | EXT_XG_MDIO_CTRL_CMD_LOAD
+                                | MDIO_MIIM_CMD_10G_MMD << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | EXT_XG_MDIO_CTRL_TA << EXT_XG_MDIO_CTRL_TA_POS
+                                | MDIO_CTRL_OP_READ_10G_MMD << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+        /* poll master busy bit until it is not busy */
+        WAIT_XGMAC_MDIO_BSY_CLEAR(node)
+
+        rdval =  nlm_hal_read_mac_reg(node, 7, intf_type, EXT_XG0_MDIO_RD_STAT +
+                (bus * 4)) & 0xFFFF;
+
+        nlm_hal_write_mac_reg( node, 7, intf_type, EXT_XG0_MDIO_CTRL + (bus * 4),
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_addr << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | MDIO_MIIM_CMD_IDLE << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | 0x0 << EXT_XG_MDIO_CTRL_TA_POS
+                                | 0 << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+
+        /* poll master busy bit until it is not busy */
+        WAIT_XGMAC_MDIO_BSY_CLEAR(node)
+
+        return rdval;
+
+}
+
+#define WAIT_XGMAC_IMDIO_BSY_CLEAR(node)   for (i = 0; i < PHY_STATUS_RETRIES; i++) { \
+        if((nlm_hal_read_mac_reg(node, 7, intf_type,                                 \
+                INT_MDIO_RD_STAT) & EXT_XG_MDIO_STAT_MBSY) == 0)        \
+                        break;                                                  \
+        }
+
+static int nlm_hal_xgmac_imdio_addr(int node, int block, int intf_type,
+        int phyaddr, int regidx)
+{
+        int32_t i;
+        // internal xgmac pcs is always 5
+        // phyadd 0x13,0x14, 0x15, 0x16
+        int dev_addr = 5;
+
+        /* load  XGMC_MDIO_CTRL_DATA register with addr */
+        nlm_hal_write_mac_reg( node, 7 , intf_type,
+                                INT_MDIO_CTRL_DATA, regidx);
+
+        nlm_hal_write_mac_reg( node, 7, intf_type, INT_MDIO_CTRL,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_addr << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | EXT_XG_MDIO_CTRL_CMD_LOAD
+                                | MDIO_MIIM_CMD_10G_MMD << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | EXT_XG_MDIO_CTRL_TA << EXT_XG_MDIO_CTRL_TA_POS
+                                | MDIO_CTRL_OP_INDIRECT_ADDR << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+
+        /* poll master busy bit until it is not busy */
+        WAIT_XGMAC_IMDIO_BSY_CLEAR(node);
+
+        nlm_hal_write_mac_reg( node, 7, intf_type, INT_MDIO_CTRL,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_addr << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | MDIO_MIIM_CMD_IDLE << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | 0x0 << EXT_XG_MDIO_CTRL_TA_POS
+                                | MDIO_CTRL_OP_INDIRECT_ADDR << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+
+        /* poll master busy bit until it is not busy */
+        WAIT_XGMAC_IMDIO_BSY_CLEAR(node)
+        return 0;
+}
+
+int nlm_hal_xgmac_imdio_write(int node, int block, int intf_type, int phyaddr,
+        int regidx, uint16_t val)
+{
+        int32_t  i;
+        // internal xgmac pcs is always 5
+        // phyadd 0x13,0x14, 0x15, 0x16
+        int dev_addr = 5;
+
+         /* first is indirect address cycle */
+        nlm_hal_xgmac_imdio_addr(node, block, intf_type, phyaddr, regidx);
+
+        nlm_hal_write_mac_reg( node, block , intf_type,
+                                INT_MDIO_CTRL_DATA, val);
+
+        nlm_hal_write_mac_reg( node, block, intf_type, INT_MDIO_CTRL,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_addr << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | EXT_XG_MDIO_CTRL_CMD_LOAD
+                                | MDIO_MIIM_CMD_10G_MMD << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | EXT_XG_MDIO_CTRL_TA << EXT_XG_MDIO_CTRL_TA_POS
+                                | MDIO_CTRL_OP_WRITE_10G_MMD << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+        /* poll master busy bit until it is not busy */
+        WAIT_XGMAC_IMDIO_BSY_CLEAR(node);
+
+        nlm_hal_write_mac_reg( node, block, intf_type, INT_MDIO_CTRL,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_addr << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | MDIO_MIIM_CMD_IDLE << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | 0x0 << EXT_XG_MDIO_CTRL_TA_POS
+                                | 0 << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+
+        /* poll master busy bit until it is not busy */
+        WAIT_XGMAC_IMDIO_BSY_CLEAR(node);
+        return 0;
+}
+
+int nlm_hal_xgmac_imdio_read(int node, int block, int intf_type, int phyaddr,
+        int regidx)
+{
+        int32_t  i;
+        int rdval;
+        // internal xgmac pcs is always 5
+        // phyadd 0x13,0x14, 0x15, 0x16
+        int dev_addr = 5;
+
+         /* first is indirect address cycle */
+        nlm_hal_xgmac_imdio_addr(node, block, intf_type, phyaddr, regidx);
+
+        nlm_hal_write_mac_reg( node, block, intf_type, INT_MDIO_CTRL,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_addr << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | EXT_XG_MDIO_CTRL_CMD_LOAD
+                                | MDIO_MIIM_CMD_10G_MMD << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | EXT_XG_MDIO_CTRL_TA << EXT_XG_MDIO_CTRL_TA_POS
+                                | MDIO_CTRL_OP_READ_10G_MMD << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+        /* poll master busy bit until it is not busy */
+        WAIT_XGMAC_IMDIO_BSY_CLEAR(node);
+
+        rdval =  nlm_hal_read_mac_reg(node, block, intf_type, INT_MDIO_RD_STAT) & 0xFFFF;
+
+        nlm_hal_write_mac_reg( node, block, intf_type, INT_MDIO_CTRL,
+                                 phyaddr << EXT_XG_MDIO_CTRL_PHYADDR_POS
+                                | dev_addr << EXT_XG_MDIO_CTRL_REG_POS
+                                | 0x9 << EXT_XG_MDIO_CTRL_XDIV_POS
+                                | 1 << EXT_XG_MDIO_CTRL_MCDIV_POS
+                                | MDIO_MIIM_CMD_IDLE << EXT_XG_MDIO_CTRL_MIIM_POS
+                                | 0x0 << EXT_XG_MDIO_CTRL_TA_POS
+                                | 0 << EXT_XG_MDIO_CTRL_OP_POS
+                                | EXT_XG_MDIO_CTRL_ST);
+
+
+        /* poll master busy bit until it is not busy */
+        WAIT_XGMAC_IMDIO_BSY_CLEAR(node);
+
+        return rdval;
+
+}
+
+#endif /*CONFIG_N511*/
+
+
 /**********************************************************************
  *  nlm_hal_xgmac_mdio_indirect_reset- reset xaui block.
  *
@@ -1207,25 +3825,219 @@ int nlm_hal_xgmac_mdio_indirect_read(int bus, int block, int intf_type, int phya
  *         bus - bus number, nae has two external gmac bus: 0 and 1
  *
  *  Return value:
- *       none
+ *       none 
  ********************************************************************* */
-void nlm_hal_xgmac_mdio_indirect_reset(int bus, int block, int intf_type)
+/**
+* @brief nlm_hal_xgmac_mdio_indirect_reset resets the XAUI block.
+*
+* @param [in] node Node number
+* @param [in] bus External MDIO bus number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] intf_type GMAC_0, GMAC_1, GMAC_2, GMAC_3, XGMAC, INTERLAKEN, PHY, LANE_CFG (only valid for block 7)
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+void nlm_hal_xgmac_mdio_indirect_reset(int node, int bus, int block, int intf_type)
 {
         int16_t phyaddr, data;
 
 	phyaddr = 0x14 + block;
         data = XAUI_PHY_RST;
-        nlm_hal_xgmac_mdio_indirect_write(bus, block, intf_type, phyaddr, XAUI_PHY_CTRL_1, data);
+        nlm_hal_xgmac_mdio_indirect_write(node, bus, block, intf_type, phyaddr, XAUI_PHY_CTRL_1, data);
 
 	data &= ~XAUI_PHY_RST;
-        nlm_hal_xgmac_mdio_indirect_write(bus, block, intf_type, phyaddr, XAUI_PHY_CTRL_1, data);
+        nlm_hal_xgmac_mdio_indirect_write(node, bus, block, intf_type, phyaddr, XAUI_PHY_CTRL_1, data);
+}
+
+#ifdef CONFIG_N511
+//PRM PCS MMD reg offsets are impossible and NetLogic can't advise
+// This attempt did not seem to work right - Pete/MPS
+void nlm_xaui_pcs_mmd_init(void)
+{
+  uint32_t wval, rval;
+
+  rval = nlm_hal_read_mac_reg(0, 0, 4, 0x7f);
+  nlm_print("PreRead PCS MDD 0 0x%x\n", rval);
+  wval = (0x5 << 23) | (0x13 << 18);
+  nlm_hal_write_mac_reg(0, 0, 4, 0x7f, wval);
+  nlm_print("Write PCS MDD 0 0x%x\n", wval);
+
+  rval = nlm_hal_read_mac_reg(0, 1, 4, 0x7f);
+  nlm_print("PreRead PCS MDD 1 0x%x\n", rval);
+  wval = (0x5 << 23) | (0x14 << 18);
+  nlm_hal_write_mac_reg(0, 1, 4, 0x7f, wval);
+  nlm_print("Write PCS MDD 1 0x%x\n", wval);
+
+  rval = nlm_hal_read_mac_reg(0, 2, 4, 0x7f);
+  nlm_print("PreRead PCS MDD 2 0x%x\n", rval);
+  wval = (0x5 << 23) | (0x15 << 18);
+  nlm_hal_write_mac_reg(0, 2, 4, 0x7f, wval);
+  nlm_print("Write PCS MDD 2 0x%x\n", wval);
+
+  rval = nlm_hal_read_mac_reg(0, 3, 4, 0x7f);
+  nlm_print("PreRead PCS MDD 3 0x%x\n", rval);
+  wval = (0x5 << 23) | (0x16 << 18);
+  nlm_hal_write_mac_reg(0, 3, 4, 0x7f, wval);
+  nlm_print("Write PCS MDD 3 0x%x\n", wval);
+
 }
 
+// call for phy/ports 0 - 3
+void nlm_xaui_phy_write(int phyaddr, int devaddr, int regidx, uint16_t val)
+{
+  int bus = 0;
+  int block = 7;
+  int intf_type = 0xf;
+
+  if ((phyaddr >= 0x13) && (phyaddr <= 0x16)) {
+    // Internal phy
+    nlm_hal_xgmac_imdio_write(0, block, intf_type, phyaddr, regidx, val);
+  } else if (phyaddr > 1) {
+    bus = 1;
+  }
+  nlm_hal_xgmac_mdio_write(0, bus, block, intf_type, phyaddr, devaddr,
+        regidx, val);
+}
+
+uint16_t nlm_xaui_phy_read(int phyaddr, int devaddr, int regidx)
+{
+  int bus = 0;
+  int block = 7;
+  int intf_type = 0xf;
+  uint16_t val;
+
+  if (phyaddr >= 0x13) {
+    // Internal phy
+
+#if 0 //PRM PCS MMD reg offsets are impossible and NetLogic can't advise
+// This attempt did not seem to work right - Pete/MPS
+    // check if PCS MMD regs have been set
+    uint32_t tval, wval;
+
+    tval = nlm_hal_read_mac_reg(0, 4, 0x7f);
+    if (tval != ((0x5 << 23) | (0x13 << 18))) {
+      nlm_print("ERROR: PCS MMD 0 not set for MDIO 0x%x\n", tval);
+      wval = (0x5 << 23) | (0x13 << 18);
+      nlm_hal_write_mac_reg(0, 4, 0x7f, wval);
+      nlm_print("Write PCS MDD 0 0x%x\n", wval);
+      nlm_xaui_pcs_mmd_init();
+    }
+    tval = nlm_hal_read_mac_reg(1, 4, 0x7f);
+    if (tval != ((0x5 << 23) | (0x14 << 18))) {
+      nlm_print("ERROR: PCS MMD 1 not set for MDIO 0x%x\n", tval);
+      wval = (0x5 << 23) | (0x14 << 18);
+      nlm_hal_write_mac_reg(1, 4, 0x7f, wval);
+      nlm_print("Write PCS MDD 1 0x%x\n", wval);
+    }
+    tval = nlm_hal_read_mac_reg(2, 4, 0x7f);
+    if (tval != ((0x5 << 23) | (0x15 << 18))) {
+      nlm_print("ERROR: PCS MMD 2 not set for MDIO 0x%x\n", tval);
+      wval = (0x5 << 23) | (0x15 << 18);
+      nlm_hal_write_mac_reg(2, 4, 0x7f, wval);
+      nlm_print("Write PCS MDD 2 0x%x\n", wval);
+    }
+    tval = nlm_hal_read_mac_reg(3, 4, 0x7f);
+    if (tval != ((0x5 << 23) | (0x16 << 18))) {
+      nlm_print("ERROR: PCS MMD 3 not set for MDIO 0x%x\n", tval);
+      wval = (0x5 << 23) | (0x16 << 18);
+      nlm_hal_write_mac_reg(3, 4, 0x7f, wval);
+      nlm_print("Write PCS MDD 3 0x%x\n", wval);
+    }
+#endif
+
+//#if 0 // Use ext x0 mdio
+    val = nlm_hal_xgmac_mdio_indirect_read(0, bus, block, intf_type, phyaddr,
+        regidx);
+    nlm_print("nlm_xaui_phy_read PCS phy with external mdio = 0x%x\n", val);
+//#else // use int mdio
+    val = nlm_hal_xgmac_imdio_read(0, block, intf_type, phyaddr, regidx);
+    nlm_print("nlm_xaui_phy_read PCS phy with internal mdio = 0x%x\n", val);
+//#endif
+    return val;
+
+  } else if (phyaddr > 1) {
+    bus = 1;
+  }
+  val = nlm_hal_xgmac_mdio_read(0, bus, block, intf_type, phyaddr, devaddr,
+        regidx);
+
+  return val;
+}
+
+#include "nlm_10ge_phy_nlp1042.h"
+
+// MPS add, scan 10ge Phys
+void nlm_xaui_phy_scan(void)
+{
+  //static int init_done = 0;
+  int bus, phyaddr, devid;
+  nlm_print("nlm_xaui_phy_scan, xlp_mac_base = 0x%llux\n", (u64)xlp_mac_base);
+
+  //nlm_xaui_pcs_mmd_init();
+
+  bus=0;
+  for (phyaddr=0; phyaddr<2; phyaddr++) {
+    devid = nlm_hal_xgmac_mdio_read(0, bus, 7, 0xf, phyaddr, 1, 0xC205);
+    nlm_print("\t%d:%x: 0x%02x\n", bus, phyaddr, devid);
+#if 1
+    nlm_nlp1042_init(phyaddr);
+#else
+    if (init_done == 0) {
+      nlm_nlp1042_init(phyaddr);
+    } else {
+      int regaddr;
+      for (regaddr=0; regaddr<0x10; regaddr++) {
+        devid = nlm_hal_xgmac_mdio_read(0, bus, 7, 0xf, phyaddr, 1, regaddr);
+        nlm_print("\t%d:%x: 1:%d 0x%02x\n", bus, phyaddr, regaddr, devid);
+      }
+    }
+#endif
+  }
+  bus=1;
+  for (phyaddr=2; phyaddr<4; phyaddr++) {
+    devid = nlm_hal_xgmac_mdio_read(0, bus, 7, 0xf, phyaddr, 1, 0xC205);
+    nlm_print("\t%d:%x: 0x%02x\n", bus, phyaddr, devid);
+#if 1
+    nlm_nlp1042_init(phyaddr);
+#else
+    if (init_done == 0) {
+      nlm_nlp1042_init(phyaddr);
+    } else {
+      int regaddr;
+      for (regaddr=0; regaddr<32; regaddr++) {
+        devid = nlm_hal_xgmac_mdio_read(0, bus, 7, 0xf, phyaddr, 1, regaddr);
+        nlm_print("\t%d:%d: 1:%d 0x%02x\n", bus, phyaddr, regaddr, devid);
+      }
+    }
+#endif
+  }
+  //init_done = 1;
+}
+
+#endif // CONFIG_N511
+
+
 /**********************************************************************
- *  nae_config_lane_gmac
+ *  nae_config_lane_gmac 
  *
  ********************************************************************* */
-void nlm_hal_xaui_pcs_init(int xaui_cplx_mask)
+/**
+* @brief nlm_hal_xaui_pcs_init initializes lane configuration and resets the Tx PLL for XAUI complexes.
+*
+* @param [in] node Node number
+* @param [in] xaui_cplx_mask XAUI complex mask (possible in XLP832: 0x0F)
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+void nlm_hal_xaui_pcs_init(int node, int xaui_cplx_mask)
 {
 	int block, lane_ctrl;
 	int cplx_lane_enable = LM_XAUI | (LM_XAUI << 4) | (LM_XAUI << 8) | (LM_XAUI << 12);
@@ -1240,53 +4052,31 @@ void nlm_hal_xaui_pcs_init(int xaui_cplx_mask)
 	block = 7;
 
 	if (xaui_cplx_mask & 0x3) { /* Complexes 0, 1 */
+		lane_enable = nlm_hal_read_mac_reg(node, block, LANE_CFG, LANE_CFG_CPLX_0_1);	
 		if (xaui_cplx_mask & 0x1) { /* Complex 0 */
+			lane_enable &= ~(0xFFFF);
 			lane_enable |= cplx_lane_enable;
 		}
 		if (xaui_cplx_mask & 0x2) {/* Complex 1 */
+			lane_enable &= ~(0xFFFF<<16);
 			lane_enable |= (cplx_lane_enable << 16);
 		}
-		nlm_hal_write_mac_reg( block, LANE_CFG, LANE_CFG_CPLX_0_1,   lane_enable);
+		nlm_hal_write_mac_reg(node, block, LANE_CFG, LANE_CFG_CPLX_0_1,   lane_enable);
 	}
 	lane_enable = 0;
 	if (xaui_cplx_mask & 0xc) { /* Complexes 2, 3 */
+		lane_enable = nlm_hal_read_mac_reg(node, block, LANE_CFG, LANE_CFG_CPLX_2_3);
 		if (xaui_cplx_mask & 0x4) { /* Complex 2 */
+			lane_enable &= ~(0xFFFF);
 			lane_enable |= cplx_lane_enable;
 		}
 		if (xaui_cplx_mask & 0x8) {/* Complex 3 */
+			lane_enable &= ~(0xFFFF<<16);
 			lane_enable |= (cplx_lane_enable << 16);
 		}
-		nlm_hal_write_mac_reg( block, LANE_CFG, LANE_CFG_CPLX_2_3,   lane_enable);
+		nlm_hal_write_mac_reg(node, block, LANE_CFG, LANE_CFG_CPLX_2_3,   lane_enable);
 	}
 
-	/* serdes lane progaming
-	 */
-	for( block = 0; block < 4; block++)
-	{
-		if ((xaui_cplx_mask & (1 << block)) == 0) {
-			continue;
-		}
-		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_0_CTRL,
-				       PHY_LANE_CTRL_RST_XAUI
-				       | PHY_LANE_CTRL_PWRDOWN
-				       | (PHYMODE_XAUI << PHY_LANE_CTRL_PHYMODE_POS));
-
-		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_1_CTRL,
-				       PHY_LANE_CTRL_RST_XAUI
-				       | PHY_LANE_CTRL_PWRDOWN
-				       | (PHYMODE_XAUI << PHY_LANE_CTRL_PHYMODE_POS));
-
-		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_2_CTRL,
-				       PHY_LANE_CTRL_RST_XAUI
-				       | PHY_LANE_CTRL_PWRDOWN
-				       | (PHYMODE_XAUI << PHY_LANE_CTRL_PHYMODE_POS));
-
-		nlm_hal_write_mac_reg( block, PHY, PHY_LANE_3_CTRL,
-				       PHY_LANE_CTRL_RST_XAUI
-				       | PHY_LANE_CTRL_PWRDOWN
-				       | (PHYMODE_XAUI << PHY_LANE_CTRL_PHYMODE_POS));
-
-	}
 
 	/* Bring txpll out of reset */
 	for( block = 0; block < 4; block++)
@@ -1296,10 +4086,15 @@ void nlm_hal_xaui_pcs_init(int xaui_cplx_mask)
 		}
 
 		for( lane_ctrl = PHY_LANE_0_CTRL; lane_ctrl <= PHY_LANE_3_CTRL; lane_ctrl++) {
-			nae_lane_reset_txpll( block, lane_ctrl);
+			if((is_nlm_xlp3xx()) || (is_nlm_xlp8xx_b0())){
+				xlp3xx_8xxb0_nae_lane_reset_txpll(node, block, lane_ctrl, PHYMODE_XAUI);
+			}
+			else{
+				xlp8xx_ax_nae_lane_reset_txpll(node, block, lane_ctrl, PHYMODE_XAUI);
+			}
 		}
 	}
-	nlm_print("%s all blocks & lanes out of TXPLL\n", __func__);
+	NAE_DEBUG("%s all blocks & lanes out of TXPLL\n", __func__);
 	/* Wait for Rx & TX clock stable */
 	for( block = 0; block < 4; block++)
 	{
@@ -1308,372 +4103,1230 @@ void nlm_hal_xaui_pcs_init(int xaui_cplx_mask)
 		}
 
 		for( lane_ctrl = PHY_LANE_0_CTRL; lane_ctrl <= PHY_LANE_3_CTRL; lane_ctrl++) {
-			while ((nlm_hal_read_mac_reg(block, PHY, (lane_ctrl - 4)) & (LANE_TX_CLK)) != LANE_TX_CLK) {
+			while ((nlm_hal_read_mac_reg(node, block, PHY, (lane_ctrl - 4)) & (LANE_TX_CLK)) != LANE_TX_CLK) {
 				/* Wait for TX and RX clock to be set */
 			}
-			nlm_print("%s Blk%d lane%d got TX clock stable\n", __func__, block, lane_ctrl);
+			NAE_DEBUG("%s Blk%d lane%d got TX clock stable\n", __func__, block, lane_ctrl);
 
-			while ((nlm_hal_read_mac_reg(block, PHY, (lane_ctrl - 4)) & (LANE_RX_CLK)) != LANE_RX_CLK) {
+			while ((nlm_hal_read_mac_reg(node, block, PHY, (lane_ctrl - 4)) & (LANE_RX_CLK)) != LANE_RX_CLK) {
 				/* Wait for TX and RX clock to be set */
 			}
-			nlm_print("%s Blk%d lane%d got RX clock stable\n", __func__, block, lane_ctrl);
+			NAE_DEBUG("%s Blk%d lane%d got RX clock stable\n", __func__, block, lane_ctrl);
 
-			while ((nlm_hal_read_mac_reg(block, PHY, (lane_ctrl - 4)) & (XAUI_LANE_FAULT)) != 0) {
+			while ((nlm_hal_read_mac_reg(node, block, PHY, (lane_ctrl - 4)) & (XAUI_LANE_FAULT)) != 0) {
 				/* Wait for XAUI Lane fault to be cleared */
 			}
-			nlm_print("%s Blk%d lane%d got lane fault cleared\n", __func__, block, lane_ctrl);
-
+			NAE_DEBUG("%s Blk%d lane%d got lane fault cleared\n", __func__, block, lane_ctrl);
 		}
+
 	}
 
+#ifdef CONFIG_N511
+        nlm_xaui_phy_scan();
+#endif /*CONFIG_N511*/
+
 }
 
 //XAUI port initialization
-static void xlp_nae_config_xaui(int block, int port)
+/**
+* @brief xlp_nae_config_xaui initializes a XAUI port at the MAC level.
+*
+* @param [in] node Node number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] port Logical interface number (not hardware interface number)
+* @param [in] vlan_pri_en MAC level filtering enable
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+static void xlp_nae_config_xaui(int node, int block, int port, int vlan_pri_en)
 {
 	uint32_t val = 0;
 
-	val = 	nlm_hal_read_mac_reg(block, XGMAC, XGMAC_CTL_REG1);
+	val = 	nlm_hal_read_mac_reg(node, block, XGMAC, XGMAC_CTL_REG1);
 	val &= ~(0x1 << 11); /* Reset xgmac soft reset(bit 11) xaui soft reset (bit 12) */
-	nlm_hal_write_mac_reg(block, XGMAC, XGMAC_CTL_REG1, val);
-	nlm_print("%s Cleared XGMAC soft reset\n", __func__);
+	nlm_hal_write_mac_reg(node, block, XGMAC, XGMAC_CTL_REG1, val);
+	NAE_DEBUG("%s Cleared XGMAC soft reset\n", __func__);
 
-	val = 	nlm_hal_read_mac_reg(block, XGMAC, XGMAC_CTL_REG1);
+	val = 	nlm_hal_read_mac_reg(node, block, XGMAC, XGMAC_CTL_REG1);
 	val &= ~(0x3 << 11); /* Reset xgmac soft reset(bit 11) xaui soft reset (bit 12) */
-	nlm_hal_write_mac_reg(block, XGMAC, XGMAC_CTL_REG1, val);
-	nlm_print("%s Cleared XAUI reset\n", __func__);
-
-	nlm_hal_write_mac_reg( block, XGMAC, XAUI_CONFIG_0, 0xffffffff);
-	nlm_hal_write_mac_reg( block, XGMAC, XAUI_CONFIG_0, 0x0);
+	nlm_hal_write_mac_reg(node, block, XGMAC, XGMAC_CTL_REG1, val);
+	NAE_DEBUG("%s Cleared XAUI reset\n", __func__);
+	
+	nlm_hal_write_mac_reg(node, block, XGMAC, XAUI_CONFIG_0, 0xffffffff);
+	nlm_hal_write_mac_reg(node, block, XGMAC, XAUI_CONFIG_0, 0x0);
 
 	/* Enable tx/rx frame */
-	val = 0xF00010A8;
+	val = 0xA00010A8;
 	val |= (XAUI_CONFIG_LENCHK | XAUI_CONFIG_GENFCS | XAUI_CONFIG_PAD_64);
-	nlm_hal_write_mac_reg(  block, XGMAC, XAUI_CONFIG_1,    XAUI_CONFIG_TFEN
-				| XAUI_CONFIG_RFEN
-				| val );
+	nlm_hal_write_mac_reg(node, block, XGMAC, XAUI_CONFIG_1, val );
 	/* write max frame len*/
-	nlm_hal_write_mac_reg(  block, XGMAC, XAUI_MAX_FRAME_LEN , 0x04002000);
+	nlm_hal_write_mac_reg(node, block, XGMAC, XAUI_MAX_FRAME_LEN , 0x01800600);
 
 	/* set stats counter*/
-	val = nlm_hal_read_mac_reg( block, XGMAC, NETIOR_XGMAC_CTRL1);
+	val = nlm_hal_read_mac_reg(node, block, XGMAC, NETIOR_XGMAC_CTRL1);
 	val |= 1 << NETIOR_XGMAC_VLAN_DC_POS;
 	val |= 1 << NETIOR_XGMAC_STATS_EN_POS;
 
-	if (nae_cfg.ports[port].vlan_pri_en) {
-		val |= 1 << NETIOR_XGMAC_TX_PFC_EN_POS;
-		val |= 1 << NETIOR_XGMAC_RX_PFC_EN_POS;
-		val |= 1 << NETIOR_XGMAC_TX_PAUSE_POS;
+	if (vlan_pri_en) {
+		val |= 1 << NETIOR_XGMAC_TX_PFC_EN_POS; 
+		val |= 1 << NETIOR_XGMAC_RX_PFC_EN_POS; 
+		val |= 1 << NETIOR_XGMAC_TX_PAUSE_POS; 
 	} else {
-		val &= ~(1 << NETIOR_XGMAC_TX_PFC_EN_POS);
-		val &= ~(1 << NETIOR_XGMAC_TX_PAUSE_POS);
+		val &= ~(1 << NETIOR_XGMAC_TX_PFC_EN_POS); 
+		val |= (1 << NETIOR_XGMAC_TX_PAUSE_POS); 
 	}
-	nlm_hal_write_mac_reg(block, XGMAC, NETIOR_XGMAC_CTRL1, val);
+	nlm_hal_write_mac_reg(node, block, XGMAC, NETIOR_XGMAC_CTRL1, val);
 
 		/*
 		 * Configuring the OFF/ON timer
-		 * 31:16  - In PFC mode is used as the Xoff value                                    
-		 * 15:0   - In PFC mode is used as the Xon value                                     
-		 *        - in Link level FC mode, is used as the Xoff value.                        
+		 * 31:16  - In PFC mode is used as the Xoff value                                     
+		 * 15:0   - In PFC mode is used as the Xon value                                      
+		 *        - in Link level FC mode, is used as the Xoff value.                         
 		 */
-	if (nae_cfg.ports[port].vlan_pri_en) {
-		val = 0xF1230000;          // PFC mode:  OffTimer = 0xF123  OnTimer = 0x0000 
+	if (vlan_pri_en) {
+		val = 0xF1230000;          // PFC mode:  OffTimer = 0xF123  OnTimer = 0x0000  
 	} else {
-		val = 0x0000F123;          // Link level FC: OffTimer = 0xF123   
+		val = 0x0000F123;          // Link level FC: OffTimer = 0xF123    
 	}
-	nlm_hal_write_mac_reg(block, XGMAC, NETIOR_XGMAC_CTRL2, val);
+	nlm_hal_write_mac_reg(node, block, XGMAC, NETIOR_XGMAC_CTRL2, val);
 
 
 	/* set xaui tx threshold */
-	val = nlm_hal_read_mac_reg(block, XGMAC, NETIOR_XGMAC_CTRL3);
+	val = nlm_hal_read_mac_reg(node, block, XGMAC, NETIOR_XGMAC_CTRL3);
 
-	 /* val &= ~(0x1f << 10);  */
-	 /* val |= (15 << 10);  */
+	val &= ~(0x1f << 10);  
+	val |= (15 << 10);  
 
-	nlm_hal_write_mac_reg(block, XGMAC, NETIOR_XGMAC_CTRL3, val);
-	nlm_print("%s XAUI Config Complete block %d swport %d hwport %d!!\n", __func__,block, port, nae_cfg.ports[port].hw_port_id);
+	nlm_hal_write_mac_reg(node, block, XGMAC, NETIOR_XGMAC_CTRL3, val);
+	NAE_DEBUG("%s XAUI Config Complete block %d swport %d \n", __func__,block, port);
 	return;
 }
 
+int nlm_hal_set_xaui_framesize(int node, int block, uint32_t tx_size, uint32_t rx_size)
+{
+       nlm_hal_write_mac_reg(node, block, XGMAC, XAUI_MAX_FRAME_LEN , ((tx_size/4) << 16) | rx_size);
+       NAE_DEBUG("Max frame len set for RX= %d bytes\n", nlm_hal_read_mac_reg(node, block, XGMAC, XAUI_MAX_FRAME_LEN) & (0xffff));
+       NAE_DEBUG("Max frame len set for TX= %d bytes\n",  4*((nlm_hal_read_mac_reg(node, block, XGMAC, XAUI_MAX_FRAME_LEN) >>16) & (0xffff)));
+       return 0;
+}
+
+int nlm_hal_set_sgmii_framesize(int node, int block, int index, uint32_t size)
+{
+       nlm_hal_write_mac_reg(node, block, index, SGMII_MAX_FRAME_LEN, size);
+       NAE_DEBUG("Max frame len set = %d bytes\n",  nlm_hal_read_mac_reg(node, block, index, SGMII_MAX_FRAME_LEN));
+       return 0;
+}
+
 /*
  *                   Interlaken Support
  *
  */
-static void xlp_nae_config_lane_ilk(int ilk_block_base, int ilk_num_lanes)
+
+static uint8_t nlm_hal_read_pma_reg(int node, int block, int lane_ctrl, uint8_t serdes_reg)
 {
-	volatile uint32_t lane_mask = 0;
-	uint32_t ilk_lane_eable = 0;
-	volatile uint32_t lane_config = 0, lane_cfg_reg =  ((ilk_block_base < 2) ? LANE_CFG_CPLX_0_1 : LANE_CFG_CPLX_2_3);
-	volatile uint32_t phy_lane = PHY_LANE_CTRL_BPC_XAUI | PHY_LANE_CTRL_RST |
-				PHY_LANE_CTRL_PWRDOWN | (PHYMODE_IL << PHY_LANE_CTRL_PHYMODE_POS);
-	uint32_t block, lane, max_block;
+        volatile uint32_t serdes_val, regval;
+
+        regval = nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl);
+        regval &= 0xFFC00000;
+        nlm_hal_write_mac_reg(node, block, PHY, lane_ctrl,  regval
+                               | (serdes_reg << PHY_LANE_CTRL_ADDR_POS)
+                               | PHY_LANE_CTRL_CMD_READ
+                               | PHY_LANE_CTRL_CMD_START
+                               | PHY_LANE_CTRL_RST );
+        while (((serdes_val = nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl)) & PHY_LANE_CTRL_CMD_PENDING));
+        return (serdes_val & 0xFF);
+}
 
-	nlm_print("xlp_nae_config_lane_ilk blk %d num_lanes %d\n",ilk_block_base, ilk_num_lanes);
-	if (!((ilk_block_base == 0) || (ilk_block_base == 2)))
-		return;
-	// Configure Lane mode for interlaken
+static void nlm_hal_write_pma_reg(int node, int block, int lane_ctrl, uint8_t serdes_reg, uint8_t serdes_val)
+{
+        volatile uint32_t regval = 0;
 
-	nlm_print("Configure Lane mode \n");
-	block = max_block = ilk_block_base ;
-	max_block += ((ilk_num_lanes > MAX_LANE_PER_CPLX ) ? 2 : 1);
 
-	for(; block < max_block ; block++ ) {
-	        if (block % 2) {
-	                ilk_lane_eable <<= 16;
-        	        lane_mask <<= 16;
-		}
-		else {
-			ilk_lane_eable = (LM_IL << LANE_CFG_LANE_3_POS) |
-					(LM_IL << LANE_CFG_LANE_2_POS) |
-					(LM_IL << LANE_CFG_LANE_1_POS) | LM_IL;
-			lane_mask = 0xFFFF;
-		}
-		nlm_print("ilk_lane_eable 0x%x lane_mask 0x%x reg %d \n",ilk_lane_eable, lane_mask, lane_cfg_reg);
-		lane_config = nlm_hal_read_mac_reg( BLOCK_7, LANE_CFG, lane_cfg_reg);
-		nlm_hal_write_mac_reg(BLOCK_7, LANE_CFG, lane_cfg_reg, lane_config & (~lane_mask));
-	
-                lane_config = nlm_hal_read_mac_reg(BLOCK_7, LANE_CFG, lane_cfg_reg);
-		lane_config |= ilk_lane_eable;
-                nlm_hal_write_mac_reg(BLOCK_7, LANE_CFG, lane_cfg_reg, lane_config | ilk_lane_eable);
-		nlm_print("lanecfg %x \n",nlm_hal_read_mac_reg(BLOCK_7, LANE_CFG, lane_cfg_reg));
-        }
+        regval = nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl);
+        regval &= 0xFFC00000;
+        nlm_hal_write_mac_reg(node, block , PHY, lane_ctrl, regval
+                                        | PHY_LANE_CTRL_CMD_START | PHY_LANE_CTRL_RST
+                                        | (serdes_reg << PHY_LANE_CTRL_ADDR_POS)
+                                        | (serdes_val << PHY_LANE_CTRL_DATA_POS));
 
-	nlm_print("Configure PHY mode \n");
+        nlm_hal_write_mac_reg(node, block , PHY, lane_ctrl, regval
+                                        | PHY_LANE_CTRL_CMD_START | PHY_LANE_CTRL_RST
+                                        | (serdes_reg << PHY_LANE_CTRL_ADDR_POS)
+                                        | (serdes_val << PHY_LANE_CTRL_DATA_POS) );
 
-	// Configure PHY mode
+        while((nlm_hal_read_mac_reg(node, block, PHY, lane_ctrl)) & PHY_LANE_CTRL_CMD_PENDING);
+}
 
-	for(block = ilk_block_base; block < max_block ; block++) {
-		for (lane = 0; lane < MAX_LANE_PER_CPLX ; lane++) {
-			if (lane==0) {
-				nlm_hal_write_mac_reg(block, PHY, PHY_LANE_0_CTRL + lane, phy_lane);
-			}
-			else {
-				nlm_hal_write_mac_reg(block, PHY, PHY_LANE_0_CTRL + lane, phy_lane | (1<<PHY_LANE_CTRL_REXSEL_POS));
-			}
-		}
-	}
+static void nlm_hal_set_PLL(int node, int block, int lane_ctrl, uint32_t F_val, uint32_t N_val, uint32_t M_val)
+{
+        uint32_t data;
 
-	nlm_print("Reset pll \n");
-	// Check PID revision and do the following
-	for(block = ilk_block_base; block < max_block ; block++) {
-                for (lane = PHY_LANE_0_CTRL; lane <= PHY_LANE_3_CTRL; lane++) {
-			nae_lane_reset_txpll( block, lane);
+        data = nlm_hal_read_pma_reg(node, block, lane_ctrl, 4);
+        data = data & 0xf0;
+        data = data | (F_val & 0xf);
+        nlm_hal_write_pma_reg(node, block, lane_ctrl, 4, data);
+
+        data = nlm_hal_read_pma_reg(node, block, lane_ctrl, 5);
+        data = data & 0x80;
+        data = data | (N_val & 0x1f) | ((M_val & 0x3) << 5);
+        nlm_hal_write_pma_reg(node, block, lane_ctrl, 5, data);
+}
+
+/**
+* @brief xlp8xx_ilk_reset_pll initializes lane configuration and resets the Tx PLL for INTERLAKEN.
+*
+* @param [in] node Node number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] ilk_num_lanes Number of INTERLAKEN lanes to configure
+* @param [in] ilk_rate PLL lane frequency
+* @return
+*       - none
+*
+* @ingroup hal_nae
+*
+*/
+static void xlp8xx_ilk_reset_pll(int node, int ilk_block_base, int ilk_num_lanes, int ilk_rate)
+{
+        volatile uint32_t lane_mask = 0, val = 0;
+        uint32_t ilk_lane_eable = 0;
+        volatile uint32_t lane_config = 0, lane_cfg_reg =  ((ilk_block_base < 2) ? LANE_CFG_CPLX_0_1 : LANE_CFG_CPLX_2_3);
+        volatile uint32_t phy_lane = PHY_LANE_CTRL_BPC_XAUI | PHY_LANE_CTRL_RST |
+                                PHY_LANE_CTRL_PWRDOWN | (PHYMODE_IL << PHY_LANE_CTRL_PHYMODE_POS);
+        uint32_t block, lane, max_block, rext_sel=0;
+
+        if (!((ilk_block_base == 0) || (ilk_block_base == 2)))
+                return;
+        // Configure Lane mode for interlaken
+
+        block = max_block = ilk_block_base ;
+        max_block += ((ilk_num_lanes > MAX_LANE_PER_CPLX ) ? 2 : 1);
+
+        for(; block < max_block ; block++ ) {
+                if (block % 2) {
+                        ilk_lane_eable <<= 16;
+                        lane_mask <<= 16;
+                }
+                else {
+                        ilk_lane_eable = (LM_IL << LANE_CFG_LANE_3_POS) |
+                                        (LM_IL << LANE_CFG_LANE_2_POS) |
+                                        (LM_IL << LANE_CFG_LANE_1_POS) | LM_IL;
+                        lane_mask = 0xFFFFFFFF;
                 }
+                lane_config = nlm_hal_read_mac_reg(node, BLOCK_7, LANE_CFG, lane_cfg_reg);
+                nlm_hal_write_mac_reg(node, BLOCK_7, LANE_CFG, lane_cfg_reg, lane_config & (~lane_mask));
+
+                lane_config = nlm_hal_read_mac_reg(node, BLOCK_7, LANE_CFG, lane_cfg_reg);
+                lane_config |= ilk_lane_eable;
+                nlm_hal_write_mac_reg(node, BLOCK_7, LANE_CFG, lane_cfg_reg, lane_config | ilk_lane_eable);
+        }
+ 
+        if (is_nlm_xlp8xx_b0()) {
+                for(block = ilk_block_base; block < max_block ; block++) {
+                        for (lane = PHY_LANE_0_CTRL; lane <= PHY_LANE_3_CTRL; lane++) {
+                                if (lane != 4)
+                                        rext_sel = (1 << 23);
+                                else
+                                        rext_sel = 0;
+                                val = nlm_hal_read_mac_reg(node, block, PHY, lane);
+                                val |= 0x100000 | (PHYMODE_IL << PHY_LANE_CTRL_PHYMODE_POS) | PHY_LANE_CTRL_BPC_XAUI;
+                                val &= ~(0x20000);
+                                nlm_hal_write_mac_reg(node, block, PHY, lane,val);
+
+                                val = nlm_hal_read_mac_reg(node, block, PHY, lane);
+                                val |= 0x40000000; /* Unset the reset (inverse logic) : Bit30: epcs reset */
+                                nlm_hal_write_mac_reg(node, block, PHY, lane,val);
+                                NAE_DEBUG(" After serdes  de-assertion PMA value=0x%x\n", nlm_hal_read_mac_reg(node, block, PHY, lane));
+         //                       nlm_hal_set_PLL(node, block, lane, 0, 19, 0);
+
+                                /* Clear the Power Down bit */
+                                val = nlm_hal_read_mac_reg(node, block, PHY, lane);
+                                val &= ~( (1 << 29) | (0x7ffff));
+                                nlm_hal_write_mac_reg(node, block, PHY, lane, (rext_sel | val));
+
+                                NAE_DEBUG("Reset PLL done \n");
+                        }
+                }
+        }
+	else {       
+		for(block = ilk_block_base; block < max_block ; block++) {
+        	        for (lane = PHY_LANE_0_CTRL; lane <= PHY_LANE_3_CTRL; lane++) {
+	        //              xlp8xx_ax_nae_lane_reset_txpll( block, lane, PHYMODE_IL);
+        	                nlm_hal_write_mac_reg(node, block, PHY, lane,  phy_lane);
+
+                        	if (lane != 4) {
+                	                int i;
+                                	rext_sel = (1 << 23);
+
+	                                val = nlm_hal_read_mac_reg(node, block, PHY, lane);
+        	                        val &= ~PHY_LANE_CTRL_RST; /* Set the reset (inverse logic) */
+                	                val |= rext_sel | PHY_LANE_CTRL_BPC_XAUI;
+	
+        	                        /* Resetting PMA for non-zero lanes */
+                	                nlm_hal_write_mac_reg(node, block, PHY, lane,val);
+
+                        	        for (i=0; i< 0x100000; ++i); /* empty loop */
+
+                                	val |= PHY_LANE_CTRL_RST; /* Unset the reset (inverse logic) */
+	                                nlm_hal_write_mac_reg(node, block, PHY, lane,val);
+        	                        val = 0;
+                	        }
+                        	else
+                                	rext_sel = 0;
+
+        	                val = nlm_hal_read_pma_reg(node, block, lane, 0x66) & 0xFF;		
+       	        	        nlm_hal_set_PLL(node, block, lane, 0, 19, 0);
+
+               	        	val &= ~(1 << 4);
+                        	nlm_hal_write_pma_reg(node, block, lane, 0x66, val);
+	                        nlm_hal_write_pma_reg(node, block, lane, 0x66, val);
+
+	                        val = nlm_hal_read_mac_reg(node, block, PHY, lane);
+        	                val &= ~( (1 << 29) | (0x7ffff));
+                	        nlm_hal_write_mac_reg(node, block, PHY, lane, (rext_sel | val));
+
+	        //                nlm_print("pll F %x \n", nlm_hal_read_pma_reg(block, lane, 4));
+        	//                nlm_print("pll M %x \n", nlm_hal_read_pma_reg(block, lane, 5));
+
+                	}
+        	}
 	}
 }
 
 #ifdef INTERLAKEN_DEBUG
-static void dump_interlaken_regs(int blk)
+static void dump_interlaken_regs(int node, int blk)
 {
-	nlm_print("Rxstats1 0x%x\n",nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS1));
-	nlm_print("Rxstats2 0x%x\n",nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS2));
-	nlm_print("Rxstats3 0x%x\n",nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS3));
+	nlm_print("Rxstats1 0x%x\n",nlm_hal_read_mac_reg(node, blk, INTERLAKEN, ILK_RX_STATUS1));
+	nlm_print("Rxstats2 0x%x\n",nlm_hal_read_mac_reg(node, blk, INTERLAKEN, ILK_RX_STATUS2));
+	nlm_print("Rxstats3 0x%x\n",nlm_hal_read_mac_reg(node, blk, INTERLAKEN, ILK_RX_STATUS3));
 }
 
 static void xlp_debug_interlaken(int blk)
 {
 	uint32_t debug;
-
-	debug = (0 << ILK_GEN_CTRL2_SCS0_POS) | (1 << ILK_GEN_CTRL2_SCS1_POS ) |
+	
+	debug = (0 << ILK_GEN_CTRL2_SCS0_POS) | (1 << ILK_GEN_CTRL2_SCS1_POS ) | 
 		(2 << ILK_GEN_CTRL2_SCS2_POS);
 
         debug |= (3 << ILK_GEN_CTRL2_SCS4_POS) | (4 << ILK_GEN_CTRL2_SCS5_POS);
-	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_GENERAL_CTRL2, debug);
+	nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_GENERAL_CTRL2, debug);
 
 	debug = (1 << ILK_GEN_CTRL3_LCS1_POS) | (3 << ILK_GEN_CTRL3_LCS0_POS) |
 		(1 << ILK_GEN_CTRL3_MCS1_POS) | (0 << ILK_GEN_CTRL3_MCS0_POS) |
 		(13 << ILK_GEN_CTRL3_SCS6_POS) | (11 << ILK_GEN_CTRL3_SCS7_POS);
-	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_GENERAL_CTRL3, debug);
-	dump_interlaken_regs(blk);
+	nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_GENERAL_CTRL3, debug);
+	dump_interlaken_regs(node, blk);
 }
 #endif
 
-#ifdef ILK_SERDES_LOOP
-static uint8_t nlm_hal_read_pma_reg(int block, int lane, uint8_t serdes_reg)
+/**
+* @brief xlp_nae_config_interlaken initializes an INTERLAKEN port at the MAC level.
+*
+* @param [in] node Node number
+* @param [in] block NAE Register Memory Map Block
+* @param [in] port Logical interface number (not hardware interface number)
+* @param [in] num_lanes Number of INTERLAKEN lanes enabled
+*
+* @return
+*       - none
+*
+* @ingroup hal_nae
+*
+*/
+static void xlp_nae_config_interlaken(int node, int blk,int port, int num_lanes)
 {
-	volatile uint32_t lane_ctrl = 0;
-	volatile uint32_t serdes_val = 0;
-
-	lane += PHY_LANE_0_CTRL;
-
-	lane_ctrl = nlm_hal_read_mac_reg(block, PHY, lane);
-	lane_ctrl |= PHY_LANE_CTRL_CMD_READ | PHY_LANE_CTRL_CMD_START |
-			PHY_LANE_CTRL_RST | (serdes_reg << PHY_LANE_CTRL_ADDR_POS);
+        volatile uint32_t rxctrl = 0;
+        volatile uint32_t txctrl = 0, genctrl = 0;
+        volatile uint32_t val = 0;
 
-	nlm_hal_write_mac_reg(block, PHY, lane, lane_ctrl);
-
-        while (((lane_ctrl = nlm_hal_read_mac_reg( block, PHY, lane)) & PHY_LANE_CTRL_CMD_PENDING));
+#ifdef ILK_SERDES_LOOP
+        int lane, lnsperblk = (num_lanes > MAX_LANE_PER_CPLX) ? MAX_LANE_PER_CPLX : num_lanes;
+        volatile uint8_t prbsctrl = 0;
+
+        // Enable loopback here if configured
+        do {
+                for(lane = 0; lane < lnsperblk; lane++) {
+                        prbsctrl = nlm_hal_read_pma_reg(blk+i, lane, SERDES_PRBS_CTRL);
+                        prbsctrl |= SERDES_LOOPBACK_EN;
+                        nlm_hal_write_pma_reg(blk+i, lane, SERDES_PRBS_CTRL, prbsctrl);
+                }
+                lnsperblk = num_lanes - lnsperblk;
+                if (!lnsperblk)
+                        break;
+                i++;
+        }while(i<2);
+
+        nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_RX_STATUS1, 0xFFFFFFFF);
+        nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_RX_STATUS2, 0xFFFFFFFF);
+        nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_RX_STATUS3, 0x0004FFFF);
+#endif
+        if (!((blk == 0) || (blk == 2)))
+                return;
 
-	serdes_val = lane_ctrl & 0xFF;
-	return serdes_val;
-}
+        NAE_DEBUG("interlaken blk %d num_lanes %d \n",blk, num_lanes);
 
-static void nlm_hal_write_pma_reg(int block, int lane, uint8_t serdes_reg, uint8_t serdes_val)
-{
-	volatile uint32_t lane_ctrl = 0;
+        nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_TX_META_CTRL, 0x00f700f7); //cortina
 
-	lane += PHY_LANE_0_CTRL;
+        // Configure number of lanes , IL registers
+        if (num_lanes == 1) {
+                rxctrl = ILK_RX_CTRL_BAD_LANE | (num_lanes << ILK_RX_CTRL_BLS_POS )
+                         | (num_lanes << ILK_RX_CTRL_LLS_POS);
+                txctrl = ILK_TX_CTRL_BAD_LANE | (num_lanes << ILK_TX_CTRL_BLS_POS)
+                         | (num_lanes << ILK_TX_CTRL_LLS_POS);
+        }
+        else {
+                rxctrl = (num_lanes - 1) << ILK_RX_CTRL_LLS_POS | ((num_lanes-1) << ILK_RX_CTRL_BLS_POS);
+                txctrl = (num_lanes - 1) << ILK_TX_CTRL_LLS_POS | ((num_lanes-1) << ILK_TX_CTRL_BLS_POS) | (3 << ILK_TX_CTRL_BS_POS);
+        }
 
-	lane_ctrl = 0xFFFF0000 & nlm_hal_read_mac_reg(block, PHY, lane);
-	lane_ctrl = (lane_ctrl & (~PHY_LANE_CTRL_CMD_READ)) |
-				 PHY_LANE_CTRL_CMD_START | PHY_LANE_CTRL_RST |
-				 (serdes_reg << PHY_LANE_CTRL_ADDR_POS) |
-				 (serdes_val << PHY_LANE_CTRL_DATA_POS) ;
+        rxctrl |= (ILK_BURST_MAX << ILK_RX_CTRL_BMAX_POS) ;
+        txctrl |= (ILK_BURST_MAX << ILK_TX_CTRL_BMAX_POS) | (0x1 << ILK_TX_CTRL_CAL_LEN_POS) | ILK_TX_CTRL_TX_EN ;
+        if (1) {        // cortina
+                rxctrl |= ILK_RX_CTRL_PKT_MODE;
+                txctrl |= ILK_TX_CTRL_RATELIM_EN;
+        }
+        nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_RX_CONTROL, rxctrl);
+        nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_TX_CONTROL, txctrl);
 
-	nlm_hal_write_mac_reg(block , PHY, lane, lane_ctrl);
+        genctrl = nlm_hal_read_mac_reg(node, blk, INTERLAKEN, ILK_GENERAL_CTRL1);
+        genctrl &= (~(0xF << 8)); // 16:0 32:1 48:2 64:3
+        nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_GENERAL_CTRL1, genctrl);
 
-	nlm_hal_write_mac_reg(block , PHY, lane, lane_ctrl);
+        txctrl = nlm_hal_read_mac_reg(node, blk, INTERLAKEN, ILK_TX_CONTROL);
+        txctrl |= ILK_TX_CTRL_RST_INF | ILK_TX_CTRL_RST_CORE;
+        nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_TX_CONTROL, txctrl);
 
-        while((lane_ctrl = nlm_hal_read_mac_reg( block, PHY, lane)) & PHY_LANE_CTRL_CMD_PENDING);
-}
-#endif
+        rxctrl = nlm_hal_read_mac_reg(node, blk, INTERLAKEN, ILK_RX_CONTROL);
+        rxctrl |= (ILK_BURST_MAX << ILK_RX_CTRL_BMAX_POS);
+        rxctrl |= (0xFF << ILK_RX_CTRL_RST_LANE_POS) |
+                                ILK_RX_CTRL_RST_CORE;
+        nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_RX_CONTROL, rxctrl);
 
+        if (1) {                //cortina
+                nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_TX_META_CTRL, 0x07ff07ff);
 
-static void xlp_nae_config_interlaken(int blk,int port, int num_lanes)
-{
-	volatile uint32_t rxctrl = 0;
-	volatile uint32_t txctrl = 0, genctrl = 0;
-	volatile uint32_t status;
-	int i = 0;
+                genctrl = nlm_hal_read_mac_reg(node, blk, INTERLAKEN, ILK_GENERAL_CTRL1);
+                genctrl &= ~(0xF << 8) | 0x0F;
+                nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_GENERAL_CTRL1, genctrl);
 
-#ifdef ILK_SERDES_LOOP
-	int lane, lnsperblk = (num_lanes > MAX_LANE_PER_CPLX) ? MAX_LANE_PER_CPLX : num_lanes;
-	volatile uint8_t prbsctrl = 0;
-
-	// Enable loopback here if configured
-	do {
-		for(lane = 0; lane < lnsperblk; lane++) {
-			prbsctrl = nlm_hal_read_pma_reg(blk+i, lane, SERDES_PRBS_CTRL);
-			prbsctrl |= SERDES_LOOPBACK_EN;
-			nlm_hal_write_pma_reg(blk+i, lane, SERDES_PRBS_CTRL, prbsctrl);	
-		}
-		lnsperblk = num_lanes - lnsperblk;
-		if (!lnsperblk) 
-			break;
-		i++;				
-	}while(i<2);
+                txctrl = nlm_hal_read_mac_reg(node, blk, INTERLAKEN, ILK_TX_CONTROL);
+                txctrl &= ~(0xf << ILK_TX_CTRL_CAL_LEN_POS);
+                nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_TX_CONTROL, txctrl);
 
-	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS1, 0xFFFFFFFF);
-	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS2, 0xFFFFFFFF);
-	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS3, 0x0004FFFF);
-#endif
-        if (!((blk == 0) || (blk == 2)))
-                return;
+                val = nlm_hal_read_mac_reg(node, blk, INTERLAKEN, ILK_TX_RATE_LIMIT);
+                val |= (0xfff << 12);
+                nlm_hal_write_mac_reg(node, blk, INTERLAKEN, ILK_TX_RATE_LIMIT, val);
+        }
 
-	nlm_print("interlaken blk %d num_lanes %d \n",blk, num_lanes);
+        val = nlm_hal_read_nae_reg(node, TX_SCHED_CTRL);
+        val |= 1;
+        nlm_hal_write_nae_reg(node, TX_SCHED_CTRL, val);
 
-	// Configure number of lanes , IL registers
-	if (num_lanes == 1) {
-		rxctrl = ILK_RX_CTRL_BAD_LANE | (num_lanes << ILK_RX_CTRL_BLS_POS )
-			 | (num_lanes << ILK_RX_CTRL_LLS_POS);
-                txctrl = ILK_TX_CTRL_BAD_LANE | (num_lanes << ILK_TX_CTRL_BLS_POS)
-			 | (num_lanes << ILK_TX_CTRL_LLS_POS);
-	}
-	else {
-		rxctrl = (num_lanes - 1) << ILK_RX_CTRL_LLS_POS;
-		txctrl = (num_lanes - 1) << ILK_TX_CTRL_LLS_POS;
-	}
+}
 
-        rxctrl |= (ILK_BURST_MAX << ILK_RX_CTRL_BMAX_POS);
-        txctrl |= (ILK_BURST_MAX << ILK_TX_CTRL_BMAX_POS); 
-        nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_RX_CONTROL, rxctrl);
-        nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_TX_CONTROL, txctrl);
-
-	txctrl = nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_TX_CONTROL);
-	txctrl |= (ILK_BURST_MAX << ILK_TX_CTRL_BMAX_POS); 
-	txctrl |= (0x1 << ILK_TX_CTRL_CAL_LEN_POS); // 16:0 32:1 48:2 64:3
-	txctrl |= ILK_TX_CTRL_RST_INF |
-			 ILK_TX_CTRL_RST_CORE |
-			 ILK_TX_CTRL_TX_EN ;
-	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_TX_CONTROL, txctrl);
-	nlm_print("txctrl 0x%x\n",nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_TX_CONTROL));
-
-	genctrl = nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_GENERAL_CTRL1);
-	genctrl &= (~(0xF << 8));
-	genctrl |= (1<<8);    // 16:0 32:1 48:2 64:3
-	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_GENERAL_CTRL1, genctrl);
-
-	rxctrl = nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_RX_CONTROL);
-	rxctrl |= (ILK_BURST_MAX << ILK_RX_CTRL_BMAX_POS);
-	rxctrl |= (0xFF << ILK_RX_CTRL_RST_LANE_POS) | 
-				ILK_RX_CTRL_RST_CORE |
-				ILK_RX_CTRL_PKT_MODE;
-	nlm_hal_write_mac_reg(blk, INTERLAKEN, ILK_RX_CONTROL, rxctrl);
-	nlm_print("rxctrl 0x%x\n",nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_RX_CONTROL));
-
-	// Configure calendar map table
-
-	nlm_print("Checking Lanes are aligned \n");
-	// check lanes are aligned
-	i=0;
-	do {
-		status = nlm_hal_read_mac_reg(blk, INTERLAKEN, ILK_RX_STATUS3);
-		nlm_print("Lane status 0x%x\n",status);
-		if (++i > 10)
-			break;
-	}while(!(status & ILK_RX_STAT3_RXL_ALIGN));
+int is_xlp_ilk_lanealigned(int node, int blk)
+{
+        int i = 0;
+        volatile uint32_t status = 0;
+
+        // check lanes are aligned
+        do {
+                status = nlm_hal_read_mac_reg(node, blk, INTERLAKEN, ILK_RX_STATUS3);
+                if (++i > 10)
+                        break;
+        }while(!(status & ILK_RX_STAT3_RXL_ALIGN));
 #ifdef INTERLAKEN_DEBUG
-	xlp_debug_interlaken(blk);
+        xlp_debug_interlaken(blk);
+        dump_interlaken_regs(blk);
 #endif
+        return 1;
 }
 
+/**
+* @brief nlm_hal_ilk_pcs_init configures the lanes of INTERLAKEN complexes and waits for Tx/Rx clock stable.
+*
+* @param [in] node Node number
+* @param [in] ilk_complex_map Bitmap of NAE complexes to configure for Interlaken PCS
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
 
-void nlm_hal_ilk_pcs_init(int ilk_cplx_mask, int num_lanes)
+int nlm_hal_ilk_pcs_init(int node, uint32_t ilk_complex_map)
 {
-	int block, lane_ctrl;
+        int lane_ctrl;
+	int block;
+	nlm_nae_config_ptr nae_cfg = nlm_node_cfg.nae_cfg[node];
+	
+        if (!is_nlm_xlp8xx()) {
+                nlm_print("Internlaken is not supported \n");
+                return -1;
+        }
 
-	nlm_print("nlm_hal_ilk_pcs_init ilk_cplx_mask 0x%x\n",ilk_cplx_mask);
-	for (block = 0 ; block < (MAX_CPLX_BLOCK - 1); block+=2) {
-		if (ilk_cplx_mask & (1<<block))
-			xlp_nae_config_lane_ilk(block , num_lanes);
+	if (nae_cfg == NULL) {
+		nlm_print("NAE configuration is invalid\n");
+		return -1;
 	}
 
-	        /* Wait for Rx & TX clock stable */
-        for( block = 0; block < 4; block++)
-        {
-                if ((ilk_cplx_mask & (1 << block)) == 0) {
-                        continue;
-                }
+	for(block=0; block < XLP8XX_MAX_NAE_COMPLEX; block+=2) {
+		if (ilk_complex_map & (1<<block)) {				
+	        	xlp8xx_ilk_reset_pll(node, block , nae_cfg->num_lanes[block/2], nae_cfg->lane_rate[block/2]);
+		}
+	}
 
+	for(block=0; block < XLP8XX_MAX_NAE_COMPLEX; block++) {
+		if (!(ilk_complex_map & (1<<block))) {
+			block++;
+			continue;
+		}
+                /* Wait for Rx & TX clock stable */
                 for( lane_ctrl = PHY_LANE_0_CTRL; lane_ctrl <= PHY_LANE_3_CTRL; lane_ctrl++) {
-                        while ((nlm_hal_read_mac_reg(block, PHY, (lane_ctrl - 4)) & (LANE_TX_CLK)) != LANE_TX_CLK) {
+                        while ((nlm_hal_read_mac_reg(node, block, PHY, (lane_ctrl - 4)) & (LANE_TX_CLK)) != LANE_TX_CLK) {
                                 /* Wait for TX and RX clock to be set */
                         }
                         nlm_print("%s Blk%d lane%d got TX clock stable\n", __func__, block, lane_ctrl);
 
-                        while ((nlm_hal_read_mac_reg(block, PHY, (lane_ctrl - 4)) & (LANE_RX_CLK)) != LANE_RX_CLK) {
+                        while ((nlm_hal_read_mac_reg(node, block, PHY, (lane_ctrl - 4)) & (LANE_RX_CLK)) != LANE_RX_CLK) {
                                 /* Wait for TX and RX clock to be set */
                         }
                         nlm_print("%s Blk%d lane%d got RX clock stable\n", __func__, block, lane_ctrl);
 
                 }
+		if (nae_cfg->num_lanes[block/2] <= 4)
+			block++;
         }
+
+        return 0;
 }
 
-uint16_t nlm_hal_get_hwport(uint32_t context)
+/**
+* @brief nlm_hal_get_hwport function finds the interface number for a given context.
+*
+* @param [in] node Node number
+* @param [in] context Context number
+*
+* @return
+*  - Interface number
+* 
+* @ingroup hal_nae
+*
+*/
+uint16_t nlm_hal_get_hwport(int node, uint32_t context)
 {
 	uint32_t rxbase = 0, rxbase1=0;
 	int i, port = 0;
 
 	for(i=0; i < 10; i++) {
-		rxbase = nlm_hal_read_nae_reg(RX_IF_BASE_CONFIG_0 + i);
+		rxbase = nlm_hal_read_nae_reg(node, RX_IF_BASE_CONFIG_0 + i);
 		if ((context >= (rxbase & 0x3FF)) && ( context < ((rxbase >> 16) & 0x3FF)))
 			return port;
 		port++;
-		rxbase1 = nlm_hal_read_nae_reg(RX_IF_BASE_CONFIG_0 + i + 1);
+		rxbase1 = nlm_hal_read_nae_reg(node, RX_IF_BASE_CONFIG_0 + i + 1);
 		if ((context >= ((rxbase >> 16) & 0x3FF)) && ( context <  (rxbase1 & 0x3FF)))
-			return port;
-		port++;	
+			return port;	
+		port++;		
 	}
 	return MAX_GMAC_PORT;
 }
 
+
+int nlm_hal_init_if(int node, int type, int  inf, uint32_t *regs, int num_regs)
+{
+	int i;
+	if (regs == NULL) {
+		return -1;
+	}
+	if (type == INTERLAKEN_IF) {
+		return -1;
+	}
+	/* Initialize the regs */
+	for (i = 0; i < num_regs; ++i) {
+		/*		nlm_hal_write_nae_reg(inf, regs[2*i], regs[2*i + 1]); */
+	}
+	return 0;
+}
+
+/**
+* @brief init_netior function is used to initialize the network IO ring.
+*
+* @param [in] node Node number
+* @param [in] type Interface type (SGMII, XAUI, Interlaken..)
+*
+* @return
+* 	- 0 on success
+* 
+* @ingroup hal_nae
+*
+*/
+static int init_netior(int node, int type)
+{
+	nlm_hal_write_nae_iface_reg(node, 0xf, NETIOR_SOFTRESET, 0);
+	if (is_nlm_xlp3xx()) {
+		nlm_hal_write_nae_iface_reg(node, 0xf, NETIOR_MISC_REG3_ADDR , 0x0 );
+                nlm_hal_write_nae_iface_reg(node, 0xf, NETIOR_MISC_REG2_ADDR , 0x0707 );
+                nlm_hal_write_nae_iface_reg(node, 0xf, NETIOR_MISC_REG1_ADDR , 0x00ff );
+	}
+	else {
+		nlm_hal_write_nae_iface_reg(node, 0xf, NETIOR_MISC_REG3_ADDR , (0x0 | (0x0007 << 18) ) );
+		nlm_hal_write_nae_iface_reg(node, 0xf, NETIOR_MISC_REG2_ADDR , 0x07070707 );
+		nlm_hal_write_nae_iface_reg(node, 0xf, NETIOR_MISC_REG1_ADDR , 0x00fffff );
+	}
+	nlm_hal_write_nae_iface_reg(node, 0xf, NETIOR_MISC_REG1_ADDR , 0x0);
+
+	return 0;
+}
+
+/* Ingress Config
+ *      20 queue (1000 - 1019)
+ *      RxConfig : set the Free in desc default
+ *      Interface to context mapping(RX_IF_BASE_CONFIG0..8)
+ *      set valid active interface
+ *      parser configuration
+ *      Free-Fifo pool to context (FREE_IN_FIFO_CFG)
+ *      Parser se
+ *	default value for desc_size is 5504 in 64-bit
+ *
+ *
+ * */
+/**
+* @brief init_ingress function is used to initialize the NAE ingress path to default values.
+*
+* @param [in] node Node number
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+void nlm_hal_init_ingress(int node, int desc_size)
+{
+	unsigned int rx_cfg = 0;
+	unsigned int parser_threshold = 384;
+
+	if (!desc_size)
+#ifdef CONFIG_64BIT
+		desc_size = 5504; /* to support 16384(mtu)/(max 3 P2Ds) and cacheline aligned */
+#else
+		desc_size = 3204; /* to support 16384(mtu)/(max 3 P2Ds) and cacheline aligned */
+#endif
+
+	rx_cfg = nlm_hal_read_nae_reg(node, RX_CONFIG);
+
+	//log_dbg("nae rxcfg %x txcfg %x\n", rx_cfg, tx_cfg);
+#define NAE_MAX_MESSAGE_SIZE(x)                 (((x) & 0x3)<<1)
+#define RESET_MAX_MESSAGE_SIZE                   ~(0x3<<1)
+#define NAE_FRINDESCCLSIZE(x)                   (((x)  & 0xff)<< 4 )
+#define RESET_FRINDESCCLSIZE                   ~((0xff)<< 4)
+#define NAE_RX_STATUS_MASK(x)                   (((x) & 0x7f) << 24)
+#define RESET_RX_STATUS_MASK                   ~((0x3f) << 24)
+
+	nlm_hal_write_nae_reg(node,  RX_CONFIG,(rx_cfg &
+					  RESET_MAX_MESSAGE_SIZE &
+					  RESET_FRINDESCCLSIZE &
+					  RESET_RX_STATUS_MASK
+				       ) |
+			       NAE_RX_ENABLE|
+			       NAE_MAX_MESSAGE_SIZE(0x0)|
+			       NAE_RX_STATUS_MASK(0x43)|
+			       NAE_FRINDESCCLSIZE(desc_size/64)
+		);
+
+#define PARSER_THRESHOLD(x) ((x)  & 0x3ff)
+#define PARSER_THRESHOLD_DIV_DESCSIZE(x) ( ((x) & 0xff) << 12)
+#define PARSER_THRESHOLD_MOD_DESCSIZE_CL(x) ( ((x) & 0xff) << 20)
+
+	nlm_hal_write_nae_reg(node, XLP_PARSER_CONFIG,
+			       PARSER_THRESHOLD(parser_threshold) |
+			       PARSER_THRESHOLD_DIV_DESCSIZE((parser_threshold/desc_size) + 1) |
+			       PARSER_THRESHOLD_MOD_DESCSIZE_CL( (parser_threshold/64)%desc_size) );
+}
+
+/**
+* @brief init_egress function is used to initialize the NAE egress path to default values.
+*
+* @param [in] node Node number
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+static void init_egress(int node)
+{
+	uint32_t tx_cfg =  nlm_hal_read_nae_reg(node, TX_CONFIG);
+
+	if ((is_nlm_xlp3xx()) || (is_nlm_xlp8xx_b0())) {
+		nlm_hal_write_nae_reg(node, TX_CONFIG, tx_cfg | NAE_TX_ENABLE | NAE_TX_ACE  | NAE_TX_COMPATIBLE | (1 << 3));
+	}
+	else {
+		nlm_hal_write_nae_reg(node, TX_CONFIG, tx_cfg | NAE_TX_ENABLE | NAE_TX_ACE);
+	}
+}
+
+
+/**
+* @brief nlm_hal_open_if function onfigures the internal PCS and MAC for an interface.
+*
+* @param [in] node Node number
+* @param [in] type Interface type (SGMII, XAUI, Interlaken..)
+* @param [in] inf Interface number
+*
+* @return
+* 	- 0 on success
+* 
+* @ingroup hal_nae
+*
+*/
+int nlm_hal_open_if(int node, int type, int inf)
+{
+	unsigned int netwk_inf  = 0;
+	unsigned int tx_config = 0;
+	int tx_ior_credit = 0;
+	uint32_t ifmask = 0;
+	unsigned int mac_cfg1 = 0;
+	unsigned int netior_ctrl3 = 0;
+
+#if !defined(XLP_SIM) || defined(NLM_BOARD)
+	int hw_portid ;
+#endif
+
+	nlm_print("%s: %d node %d ",__func__,inf, node);
+	// Init Netior ... Need to fixed
+	init_netior(node, type);
+
+	switch(type) {
+		case XAUI_IF:
+			// inf is a complex number
+			netwk_inf = nlm_hal_read_mac_reg(node, inf, XGMAC, NETIOR_XGMAC_CTRL1);
+			netwk_inf |= (1 << NETIOR_XGMAC_STATS_CLR_POS);
+			nlm_hal_write_mac_reg(node, inf, XGMAC, NETIOR_XGMAC_CTRL1, netwk_inf);
+			ifmask = 0xf << (inf);
+			tx_ior_credit = nlm_hal_read_nae_reg(node, TX_IORCRDT_INIT);
+			nlm_hal_write_nae_reg(node, TX_IORCRDT_INIT, tx_ior_credit | ifmask);
+		        tx_config = nlm_hal_read_nae_reg(node, TX_CONFIG);
+			// need to toggle these bits for credits to be loaded
+		 	nlm_hal_write_nae_reg(node, TX_CONFIG, tx_config | ( TXINITIORCR(ifmask)));
+		        nlm_hal_write_nae_reg(node, TX_CONFIG, tx_config & ~( TXINITIORCR(ifmask)));
+			break;
+		case INTERLAKEN_IF:
+			// inf is a complex number
+			ifmask = 0xff << (inf);   //based on number of lanes
+			tx_ior_credit = nlm_hal_read_nae_reg(node, TX_IORCRDT_INIT);
+			nlm_hal_write_nae_reg(node, TX_IORCRDT_INIT, tx_ior_credit | (ifmask));
+                        tx_config = nlm_hal_read_nae_reg(node, TX_CONFIG);
+			// need to toggle these bits for credits to be loaded
+	                nlm_hal_write_nae_reg(node, TX_CONFIG, tx_config | ( TXINITIORCR(ifmask)));
+                        nlm_hal_write_nae_reg(node, TX_CONFIG, tx_config & ~( TXINITIORCR(ifmask)));
+			break;
+		case SGMII_IF:
+			tx_ior_credit = nlm_hal_read_nae_reg(node, TX_IORCRDT_INIT);
+			nlm_hal_write_nae_reg(node, TX_IORCRDT_INIT, tx_ior_credit & (~ (1<<inf)));
+			tx_config = nlm_hal_read_nae_reg(node, TX_CONFIG);
+			// need to toggle these bits for credits to be loaded
+			nlm_hal_write_nae_reg(node, TX_CONFIG, tx_config | ( TXINITIORCR(1<<inf)));
+			nlm_hal_write_nae_reg(node, TX_CONFIG, tx_config & (~( TXINITIORCR(1<<inf))));
+	
+			/* init phy id to access internal PCS */
+		        netwk_inf = read_gmac_reg(node, inf, NETWK_INF_CTRL_REG);
+        		netwk_inf &= 0x7ffffff;
+		        netwk_inf |= ((inf) << 27);
+        		write_gmac_reg(node, inf, NETWK_INF_CTRL_REG, netwk_inf);
+
+			/* Sofreset set bit 11 to 0  */
+
+			write_gmac_reg(node, inf , NETWK_INF_CTRL_REG,  netwk_inf & 0xfffff7ff);
+
+			// Reset GMAC 
+			mac_cfg1 = read_gmac_reg(node, inf, MAC_CONF1);
+		        write_gmac_reg(node, inf , MAC_CONF1, mac_cfg1 | INF_SOFTRESET(1) |
+					           INF_RX_ENABLE(1) |
+						   INF_TX_ENABLE(1));
+
+			// Default 1G
+		        write_gmac_reg(node, inf , MAC_CONF2,  INF_PREMBL_LEN(0x7) |
+                        		     	INF_IFMODE(2)  |
+                	               		INF_FULLDUP(1) |
+		  			        INF_PADCRCEN(1));
+
+			// Clear GMAC reset
+			mac_cfg1 = read_gmac_reg(node, inf, MAC_CONF1);
+		        write_gmac_reg(node, inf , MAC_CONF1, mac_cfg1 & ~(INF_SOFTRESET(1)));
+
+			// Clear speed debug bit
+		        netior_ctrl3 = read_gmac_reg(node, inf, NETWK_INF_CTRL3_REG);
+		        write_gmac_reg(node, inf, NETWK_INF_CTRL3_REG, netior_ctrl3 & (~(1<<6)));
+			nlm_print("CLEARING speed bit =0x%x\n", read_gmac_reg(node, inf, NETWK_INF_CTRL3_REG));
+
+#if !defined(XLP_SIM) || defined(NLM_BOARD)
+			register_phy(node, inf, &hw_portid);
+			if(hw_portid<0)	
+				goto init_inf;
+			// init external phy, bypass SGMII auto negotiation
+			nlm_hal_init_ext_phy(node, inf);
+#endif
+			// Configure speed and mode
+			nlm_hal_config_sgmii_if(node, inf);
+			break;
+		default:
+			nlm_print("Unknown interface type\n");	
+			return 0;
+	}
+#if !defined(XLP_SIM) || defined(NLM_BOARD)
+init_inf:
+#endif
+
+	nlm_hal_init_ingress (node, 0);
+	init_egress(node);
+	init_ucore(node, inf);
+
+	return 0;
+}
+
+int nlm_hal_close_if(int node, int type, int  inf)
+{
+	if (type != SGMII_IF) {
+		return -1;
+	}
+	/* Turn off TX, RX enables */
+	return 0;
+}
+
+
+/**
+* @brief nlm_hal_mac_disable function is used to disable an interface at the MAC level.
+*
+* @param [in] node Node number
+* @param [in] inf Interface number
+* @param [in] type SGMII_IF, XAUI_IF, INTERLAKEN_IF
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+void nlm_hal_mac_disable(int node, int inf, int type)
+{
+        unsigned int mac_cfg1 = 0, xaui_cfg = 0;
+        unsigned int netwk_inf = 0;
+
+	switch(type) {
+		case SGMII_IF:
+			mac_cfg1 = read_gmac_reg(node, inf, MAC_CONF1);
+		        write_gmac_reg(node, inf , MAC_CONF1, mac_cfg1 & ~(0x5));
+              		netwk_inf = read_gmac_reg(node, inf, NETWK_INF_CTRL_REG);
+              		write_gmac_reg(node, inf ,NETWK_INF_CTRL_REG, netwk_inf &  (~(TX_EN(1))));
+			break;
+		case XAUI_IF:
+			xaui_cfg=nlm_hal_read_mac_reg(node, inf, XGMAC, XAUI_CONFIG_1);
+			nlm_hal_write_mac_reg(node, inf, XGMAC, XAUI_CONFIG_1, xaui_cfg &
+                                                        (~(XAUI_CONFIG_TFEN | XAUI_CONFIG_RFEN)));
+			break;
+		case INTERLAKEN_IF:
+			break;
+	}
+}
+
+/**
+* @brief nlm_hal_mac_enable function is used to enable an interface at the MAC level.
+*
+* @param [in] inf Interface number
+* @param [in] type SGMII_IF, XAUI_IF, INTERLAKEN_IF
+*
+* @return
+* 	- none
+* 
+* @ingroup hal_nae
+*
+*/
+void nlm_hal_mac_enable(int node, int inf, int type)
+{
+        unsigned int mac_cfg1 = 0, xaui_cfg = 0;
+        unsigned int netwk_inf = 0;
+
+        switch(type) {
+                case SGMII_IF:
+			netwk_inf  = read_gmac_reg(node, inf, NETWK_INF_CTRL_REG);
+		        write_gmac_reg(node, inf , NETWK_INF_CTRL_REG, netwk_inf | TX_EN(1));
+        		mac_cfg1 = read_gmac_reg(node, inf, MAC_CONF1);
+        		write_gmac_reg(node, inf , MAC_CONF1, mac_cfg1 | (0x5));
+                        break;
+                case XAUI_IF:
+			xaui_cfg=nlm_hal_read_mac_reg(node, inf, XGMAC, XAUI_CONFIG_1);
+	                nlm_hal_write_mac_reg(node, inf, XGMAC, XAUI_CONFIG_1, xaui_cfg |
+							XAUI_CONFIG_TFEN | XAUI_CONFIG_RFEN | XAUI_CONFIG_TCTLEN | XAUI_CONFIG_RCTLEN);                               
+
+                        break;
+                case INTERLAKEN_IF:
+                        break;
+        }
+}
+
+/**
+* @brief nlm_hal_get_phy_status function returns the status of an interface from the external PHY.
+*
+* @param [in] node Node number
+* @param [in] inf Interface number
+* @param [out] speed Link speed
+* @param [out] duplex Link duplex status
+*
+* @return
+* 	- 1 - Link up, 0 - Link Down
+* 
+* @ingroup hal_nae
+*
+*/
+int nlm_hal_get_phy_status(int node, int inf, uint32_t *speed, uint32_t *duplex)
+{
+	struct nlm_hal_ext_phy *this_phy=NULL;
+	this_phy = get_phy_info(inf);
+	if(!this_phy)
+		return 0;
+	return this_phy->phy_get_status(this_phy, speed, duplex, node);
+}
+
+
+/*
+ *  NAE Send
+ */
+/**
+* @brief nae_tx_desc function is used to create an NAE Tx FMN message.
+*
+* @param [in] type P2D/P2P, EOP/NEOP
+* @param [in] rdex Read Exclusive
+* @param [in] fbid Virtual FreeBack ID
+* @param [in] len P2D: number of bytes in packet; P2P: number of bytes in descriptor list
+* @param [in] addr Physical address of P2D/P2P
+*
+* @return
+* 	- 64-bit FMN message
+* 
+* @ingroup hal_nae
+*
+*/
+static __inline__ uint64_t nae_tx_desc(unsigned int type,
+				       unsigned int rdex,
+				       unsigned int fbid,
+				       unsigned int len,
+				       uint64_t addr)
+{
+	return ((uint64_t)(type & 0x3) << 62) |
+		((uint64_t)(rdex & 0x1) << 61) |
+		((uint64_t)(fbid & 0x7f) << 54) |
+		((uint64_t)(len & 0x3fff) << 40) |
+		addr;
+}
+
+/**
+* @brief nlm_hal_nae_send function is used to send a packet.
+*
+* @param [in] dest NAE egress FMN station ID to send to
+* @param [in] fbid Virtual FreeBack ID
+* @param [in] phys_addr Physical address of P2D/P2P
+* @param [in] len P2D: number of bytes in packet; P2P: number of bytes in descriptor list
+* @param [in] flags Flags. Not currently used
+*
+* @return
+* 	- 0 on success
+* 	- non-zero on send fail
+* 
+* @ingroup hal_nae
+*
+*/
+int nlm_hal_nae_send(int dest, int fbid, unsigned long long phys_addr, int len, unsigned int flags)
+{
+	/* TODO: Implement flags */
+	unsigned long long data[4];
+
+	data[0] = nae_tx_desc(P2D_NEOP, 0, fbid, 0, phys_addr);
+	data[1] = nae_tx_desc(P2D_EOP,
+			      0,
+			      NULL_VFBID,
+			      len ,
+			      phys_addr );
+
+	return nlm_hal_send_msg2(dest,
+				 0,
+				 data[0],
+				 data[1]);
+}
+
+/*
+ * Nae recv
+ */
+/**
+* @brief nlm_hal_soc_recv function is used to receive a packet.
+*
+* @param [in] dst_vc Local CPU VC to receive from
+* @param [out] intf Interface number packet was received on
+* @param [out] phys_addr Physical address of P2D/P2P
+* @param [out] flags Rx status flags
+*
+* @return
+* 	- 0 on success
+* 	- -1 no messages available
+* 	- -2 message available but load failed
+* 
+* @ingroup hal
+*
+*/
+int nlm_hal_soc_recv(int dst_vc, unsigned int *intf, unsigned long long *phys_addr, unsigned int *flags)
+{
+	uint32_t size = 0, code = 0;
+	unsigned int rx_status = 0;
+	uint64_t data[4];
+	int len = 0;
+
+	*flags = NAE_RECV_NONE;
+
+	if(nlm_hal_recv_msg2(dst_vc, (uint32_t *) intf, &size, &code, &data[0], &data[1])) {
+
+		rx_status = xlp_read_rx_status();
+
+
+		if (!((rx_status >> 28) & (1 << dst_vc))) {
+			return -1;
+		}
+
+		return -2;
+	}
+
+	if (size == 2 && dst_vc == 0) {
+
+		/* Rx Packet
+		 */
+		*flags = NAE_RECV_RX;
+		*phys_addr = (data[1]) & 0xffffffffc0ULL;
+		len = (data[1] >> 40) & 0x3fff;
+	}
+	else if (size == 1 && dst_vc == 3) {
+
+		/* TxC Packet
+		 */
+
+		*flags = NAE_RECV_TXC;
+		*phys_addr = (data[0]);
+		len = 0;
+	}
+	else {
+
+		*flags = NAE_RECV_UNKNOWN;
+		*phys_addr = 0;
+		len = 0;
+	}
+
+	return len;
+}
+
+/**
+* @brief nlm_hal_nae_recv function is used to receive a packet.
+*
+* @param [in] rx_vc Local CPU VC to receive from
+* @param [out] phys_addr Physical address of P2D/P2P
+* @param [out] flags Rx status flags
+*
+* @return
+* 	- 0 on success
+* 	- -1 no messages available
+* 	- -2 message available but load failed
+* 
+* @ingroup hal_nae
+*
+*/
+int nlm_hal_nae_recv(int rx_vc, unsigned long long *phys_addr, unsigned int *flags)
+{
+	unsigned int intf;
+	return nlm_hal_soc_recv(rx_vc, &intf, phys_addr, flags);
+}
+
+
+/**
+* @brief nlm_hal_init_nae function is the main function for initializing and configuring the NAE and POE, based on the configuration in FDT.
+*
+* @param [in] fdt Pointer to the FDT
+* @param [in] dom_id Domain number to parse
+*
+* @return
+*  - none
+* 
+* @ingroup hal_nae
+*
+*/
+int nlm_hal_init_nae(void *fdt, int dom_id)
+{
+	int i = 0, max_ports = 0;
+	int context = 0, ctxsize = 0, offset=0;
+	uint32_t bar0;
+	int node;
+	struct nlm_hal_nae_config *nae_cfg;
+
+	if (check_header(fdt)) {
+		nlm_print("Sanity check on FDT blob failed! Aborting\n");
+		return -1;
+	}
+
+	nlm_print("number of nodes %d \n", nlm_node_cfg.num_nodes);
+
+	for (node= 0; node<nlm_node_cfg.num_nodes; node++) {
+		if (nlm_node_cfg.nae_cfg[node] == NULL) {
+			nlm_node_cfg.nae_cfg[node] = nlm_malloc(sizeof(struct nlm_hal_nae_config));
+		
+			nae_cfg = nlm_node_cfg.nae_cfg[node];
+			if (nae_cfg == NULL) {
+				nlm_print("Memory allocation failed for nae_cfg \n");
+				return -1;
+			}
+		}
+		else {
+			nae_cfg = nlm_node_cfg.nae_cfg[node];
+		}
+
+		memset(nae_cfg, 0, sizeof(struct nlm_hal_nae_config));
+
+		cntx2port[node] = &nae_cfg->cntx2port[0];
+
+		bar0 = nlm_hal_read_32bit_reg(nlm_hal_get_dev_base(node, 0, XLP_NAE_DEVICE, XLP_NAE_FUNC), 0x4);
+		bar0 = membar_fixup(bar0);
+
+		/* Initialize default configuration */
+		for (i = 0; i < 18; i++) {
+			nae_cfg->fb_vc = 1;
+			nae_cfg->rx_vc = 0;
+			nae_cfg->ports[i].valid = 0;
+			nae_cfg->ports[i].mgmt = 0;
+		}
+
+		for (i = 0; i < MAX_NAE_CONTEXTS; i++) {
+			/* 18 is an invalid port */
+			nae_cfg->cntx2port[i] = 18;
+		}
+	
+		/* frin_fifo represents the 20 pools of free-in descriptor fifos */
+		//drain_nae_stray_packets(node);
+		drain_nae_frin_fifo_descs(node);
+		deflate_frin_fifo_carving(node);
+
+#if !defined(NLM_HAL_UBOOT)
+		/* For U-Boot, reset_nae clears all IO BARs
+		 * which messes up Flash/CPLD/GBU BARs etc
+		 */
+		reset_nae(node);
+		nae_cfg->flags |= NAE_RESET_DONE;
+#else
+		nae_reset_done = 1;
+#endif
+
+		nlm_hal_write_32bit_reg(nlm_hal_get_dev_base(node, 0, XLP_NAE_DEVICE, XLP_NAE_FUNC), 0x4, bar0);
+
+		nlm_print("Configuring ucore...\n");
+		parse_ucore_config(fdt, node);
+
+	        nlm_print("Configuring CPU-NAE...\n");
+        	parse_fdt_cpu_config(fdt, dom_id, nae_cfg);
+
+		nlm_print("Configuring NAE...\n");
+		parse_fdt_nae_config(fdt, node, nae_cfg);
+
+		nlm_print("Configuring PoE...\n");
+		parse_poe_config(fdt, node);
+
+		nlm_print("NAE configuration done!\n");
+
+		nlm_print("Digest of FDT based NAE config: \n");
+		nlm_print("fb_vc = %d, rx_vc = %d\n", nae_cfg->fb_vc, nae_cfg->rx_vc);
+
+		max_ports = nae_cfg->num_ports;
+
+		for (i = 0, context = 0; i < max_ports; i++) {
+			struct nlm_hal_nae_port *port = &nae_cfg->ports[i];
+#ifdef NLM_HAL_LINUX_KERNEL
+			int port_num, txq;
+#endif
+
+			if (!port->valid) continue;
+
+			ctxsize = nae_cfg->ports[i].num_channels;
+#if 0
+		/* Default NAE configuration uses hw_port_id as the context */
+		context = port->hw_port_id;
+		cntx2port[context] = i; /* logical port */
+#else
+#ifdef NLM_HAL_LINUX_KERNEL
+                	if (nae_cfg->ports[i].iftype == INTERLAKEN_IF) {
+                        	nae_cfg->cntx2port[context] = i;
+	                        nae_cfg->ports[i].num_free_desc /= ctxsize;
+        	                nae_cfg->ports[i].num_channels = 1;
+                	        txq = nae_cfg->ports[i].txq;
+                        	nlm_print("port %d freedesc %d txq %d rxq %d num_channel %d hw_port %d \n",
+                                        i, nae_cfg->ports[i].num_free_desc, nae_cfg->ports[i].txq, nae_cfg->ports[i].rxq, nae_cfg->ports[i].num_channels,
+                                        nae_cfg->ports[i].hw_port_id);
+
+	                        for(offset=1; offset < ctxsize; offset++) {
+        	                        port_num = nae_cfg->num_ports;
+                	                nae_cfg->cntx2port[context + offset] = port_num;
+                        	        memcpy(&nae_cfg->ports[port_num], &nae_cfg->ports[i], sizeof(struct nlm_hal_nae_port));
+                                	nae_cfg->ports[port_num].txq = ++txq;
+	                                nae_cfg->num_ports++;
+        	                        nlm_print("port %d freedesc %d txq %d rxq %d num_channel %d hw_port %d \n",
+                                        port_num, nae_cfg->ports[port_num].num_free_desc, nae_cfg->ports[port_num].txq, nae_cfg->ports[port_num].rxq,
+                                        nae_cfg->ports[port_num].num_channels, nae_cfg->ports[port_num].hw_port_id);
+                	        }
+	                }
+        	        else {
+#endif
+				for(offset=0; offset < ctxsize; offset++)
+				nae_cfg->cntx2port[context + offset] = i; /* logical port */
+#ifdef NLM_HAL_LINUX_KERNEL
+        	        }
+#endif
+#endif
+
+			nlm_print("port@%d: valid = %d, mgmt = %d, num_free_desc = %d ctxt = %d\n"
+			       "\t txq[0] = %d, txq[1] = %d, rxq = %d, hw_port_id = %d\n", i,
+				  port->valid, port->mgmt, port->num_free_desc, context,
+			       port->txq, (port->txq + port->num_channels - 1), port->rxq, port->hw_port_id);
+	
+			context += ctxsize;
+	
+		}
+
+		nlm_print("FRIN desc carving after HAL initialization...\n");
+		print_frin_desc_carving(node);
+	}
+	
+	return 0;
+}
+
+
 #ifdef NLM_HAL_LINUX_KERNEL
 #include <linux/types.h>
 #include <linux/module.h>
+EXPORT_SYMBOL(nlm_hal_set_xaui_framesize);
+EXPORT_SYMBOL(nlm_hal_set_sgmii_framesize);
 EXPORT_SYMBOL(nlm_hal_write_ucore_shared_mem);
 EXPORT_SYMBOL(nlm_hal_init_nae);
-EXPORT_SYMBOL(nae_cfg);
-EXPORT_SYMBOL(cntx2port);
 EXPORT_SYMBOL(rely_on_firmware_config);
+EXPORT_SYMBOL(nlm_config_vfbid_table);
+EXPORT_SYMBOL(cntx2port);
+EXPORT_SYMBOL(nlm_enable_poe_statistics);
+EXPORT_SYMBOL(nlm_read_poe_statistics);
+EXPORT_SYMBOL(nlm_clear_poe_stats);
+EXPORT_SYMBOL(nlm_disable_poe_statistics);
+
+EXPORT_SYMBOL(nlm_hal_open_if);
+EXPORT_SYMBOL(nlm_hal_init_ingress);
+EXPORT_SYMBOL(nlm_hal_load_ucore);
+EXPORT_SYMBOL(nlm_hal_init_poe_distvec);
+EXPORT_SYMBOL(nlm_hal_get_phy_status);
+EXPORT_SYMBOL(nlm_hal_mdio_read);
+EXPORT_SYMBOL(nlm_hal_mdio_write);
+EXPORT_SYMBOL(nlm_hal_mac_enable);
+EXPORT_SYMBOL(nlm_hal_mac_disable);
 #endif /* #ifdef NLM_HAL_LINUX_KERNEL */
diff --git a/arch/mips/netlogic/common/nlm_hal_sys.c b/arch/mips/netlogic/common/nlm_hal_sys.c
new file mode 100644
index 0000000..daf56d5
--- /dev/null
+++ b/arch/mips/netlogic/common/nlm_hal_sys.c
@@ -0,0 +1,573 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (``Netlogic''). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+#if !defined(__KERNEL__) && !defined(NLM_HAL_UBOOT)
+#include <stddef.h>
+#endif
+#ifdef NLM_HAL_LINUX_KERNEL
+#include <asm/div64.h>
+#endif
+#include "nlm_hal.h"
+#include "nlm_hal_sys.h"
+#include "nlm_hal_xlp_dev.h"
+
+/**
+ * SoC device indices for XLP8xx/4xx devices.
+ */
+static uint8_t soc_device_index_xlp8xx[] = {
+	DFS_DEVICE_NAE_2X,
+	DFS_DEVICE_SAE,
+	DFS_DEVICE_RSA,
+	DFS_DEVICE_DTRE,
+	DFS_DEVICE_CMP,
+	DFS_DEVICE_KBP,
+	DFS_DEVICE_DMC,
+	DFS_DEVICE_NAND,
+	DFS_DEVICE_MMC,
+	DFS_DEVICE_NOR,
+	DFS_DEVICE_CORE
+};
+
+/**
+ * SoC device indices for XLP3xx devices.
+ */
+static uint8_t soc_device_index_xlp3xx[] = {
+	DFS_DEVICE_NAE_2X,
+	DFS_DEVICE_SAE,
+	DFS_DEVICE_RSA,
+	DFS_DEVICE_DTRE,
+	INVALID_DFS_DEVICE,
+	INVALID_DFS_DEVICE,
+	DFS_DEVICE_DMC,
+	DFS_DEVICE_NAND,
+	DFS_DEVICE_MMC,
+	DFS_DEVICE_NOR,
+	DFS_DEVICE_CORE,
+	DFS_DEVICE_REGEX_SLOW,
+	DFS_DEVICE_REGEX_FAST,
+	DFS_DEVICE_SATA
+};
+
+
+/**
+ * Calculate the DFS divider value for the specified reference clock
+ * and target output frequency.
+ * @param [in] reference the reference clock frequency, in Hz.
+ * @param [in] target the target output frequency, in Hz.
+ * @returns the divider that produces the target frequency
+ * (if the target frequency is within FREQ_RESOLUTION of the actual output).
+ * Otherwise, it will round up to the nearest divider (rounding down to the
+ * the lower output frequency).
+ */
+static uint8_t fuzzy_divider(uint64_t reference, uint64_t target)
+{
+	uint64_t divider = reference;
+	uint64_t freq = reference;
+    uint64_t delta;
+    uint8_t result;
+
+#ifdef NLM_HAL_LINUX_KERNEL
+    do_div(divider, target);
+    do_div(freq, divider);
+#else
+    divider /= target;
+    freq /= divider;
+#endif
+	delta = freq - target;
+    result = (uint8_t)divider;
+
+	return (delta <= FREQ_RESOLUTION)? result : (result + 1);
+}
+
+/**
+ * Get the SoC device index for the specified soc_dfs_device.
+ * @param [in] device SoC DFS device.
+ * @returns device index if exists on current chip family.
+ * @returns -1 if the device is not available on the current chip family.
+ */
+static int8_t soc_device_index(enum soc_dfs_device device)
+{
+	uint8_t i;
+	if (device == INVALID_DFS_DEVICE)
+		return -1;
+
+	if (is_nlm_xlp8xx()) {
+		for (i=0; i < COUNT_OF(soc_device_index_xlp8xx); i++) {
+			if (soc_device_index_xlp8xx[i] == device)
+				return i;
+		}
+	} else if (is_nlm_xlp3xx()) {
+		for (i=0; i < COUNT_OF(soc_device_index_xlp3xx); i++) {
+			if (soc_device_index_xlp3xx[i] == device)
+				return i;
+		}
+	}
+	return -1;
+}
+
+/**
+ * @returns the numerator for the reference clock frequency.
+ */
+static inline uint64_t ref_clk_num(void)
+{
+	return REF_CLK_NUM;
+}
+/**
+ * @returns the denominator for the reference clock frequency.
+ */
+static inline uint64_t ref_clk_den(void)
+{
+	return REF_CLK_DEN;
+}
+/**
+ * @returns the current reference clock frequency, in Hz.
+ */
+static inline uint64_t ref_clk_freq(void)
+{
+	return ref_clk_num() / ref_clk_den();
+}
+
+/**
+ * Mapping of DFS indices to actual DFS divider values.
+ */
+static uint8_t DFS[] = {1, 2, 3, 4, 5, 6, 7, 9, 11, 13, 15};
+
+/**
+ * @returns the maximum DFS divider value.
+ */
+static inline uint8_t max_dfs_val(void)
+{
+	return DFS[COUNT_OF(DFS) - 1];
+}
+/**
+ * @returns the minimum DFS divider value.
+ */
+static inline uint8_t min_dfs_val(void)
+{
+	return DFS[0];
+}
+
+/**
+ * Get the output frequency for the PLL, based on the
+ * R-divider, F-divider, and PLL DFS divider.
+ * @param [in] divr R-divider for the PLL.
+ * @param [in] divf F-divider for the PLL.
+ * @param [in] pll_dfs PLL DFS divider.
+ * @return PLL frequency, in Hz.
+ */
+static inline uint64_t pll_freq(uint8_t divr, uint8_t divf, uint8_t pll_dfs)
+{
+#ifndef NLM_HAL_LINUX_KERNEL
+	return (ref_clk_num() * (divf + 1) * 4 / 2) / (ref_clk_den() * (divr + 1) * (pll_dfs + 1));
+#else
+    uint64_t num = ref_clk_num() * (divf + 1) * 4 / 2;
+    uint64_t den = ref_clk_den() * (divr + 1) * (pll_dfs + 1);
+    do_div(num, den);
+	return num;
+#endif
+}
+
+/**
+ * Get the DFS index for the DFS value (to be used with the stepping functions).
+ * The DFS value is rounded up (producing the lower output frequency) if
+ * the exact DFS value does not exist.
+ * @param [in] dfs DFS divider value.
+ * @return the DFS index greater than or equal to the specified DFS divider value.
+ */
+static inline int8_t closest_dfs_index(uint8_t dfs)
+{
+	int i;
+	if (dfs > max_dfs_val())
+		return COUNT_OF(DFS)-1;
+
+	for (i = (COUNT_OF(DFS) - 2); i >= 0; i--) {
+		if ((DFS[i+1] >= dfs) && (dfs > DFS[i]))
+			return i+1;
+	}
+
+	return 0;
+}
+
+/**
+ * Determine whether the Core PLL DFS is bypassed.
+ * In XLP8xx-4xx A-stepping, the Core PLL DFS does not exist.
+ * @returns 0 if the Core PLL is not bypassed.
+ * @returns 1 if the Core PLL is bypassed, or if the Core PLL does not exist.
+ */
+static inline uint8_t is_core_pll_dfs_bypassed(int node)
+{
+	/* no Core PLL DFS on XLP8XX/4XX A-stepping */
+	if (is_nlm_xlp8xx_ax())
+		return 1;
+	return nlm_hal_read_sys_reg(node, PLL_DFS_BYP_CTRL) & 0x1;
+}
+
+/**
+ * Determine whether the SoC PLL DFS is bypassed.
+ * In XLP8xx-4xx A-stepping, the SoC PLL DFS does not exist.
+ * @returns 0 if the SoC PLL is not bypassed.
+ * @returns 1 if the SoC PLL is bypassed, or if the SoC PLL does not exist.
+ */
+static inline uint8_t is_soc_pll_dfs_bypassed(int node)
+{
+	/* no Core PLL DFS on XLP8XX/4XX A-stepping */
+	if (is_nlm_xlp8xx_ax())
+		return 1;
+	return (nlm_hal_read_sys_reg(node, PLL_DFS_BYP_CTRL) >> 1) & 0x1;
+}
+
+/**
+ * @return the Core PLL DFS divider value, if the chip family supports it.
+ * @return 0 if the Core PLL DFS is not implemented.
+ */
+static inline uint64_t core_pll_dfs_val(int node)
+{
+	/* no Core PLL DFS on XLP8XX/4XX A-stepping */
+	if (is_nlm_xlp8xx_ax())
+		return 0;
+	if (is_core_pll_dfs_bypassed(node))
+		return 0;
+	return nlm_hal_read_sys_reg(node, PLL_DFS_DIV_VALUE) & 0xf;
+}
+
+/**
+ * @return the SoC PLL DFS divider value, if the chip family supports it.
+ * @return 0 if the SoC PLL DFS is not implemented.
+ */
+static inline uint64_t soc_pll_dfs_val(int node)
+{
+	/* no SoC PLL DFS on XLP8XX/4XX A-stepping */
+	if (is_nlm_xlp8xx_ax())
+		return 0;
+	if (is_soc_pll_dfs_bypassed(node))
+		return 0;
+	return (nlm_hal_read_sys_reg(node, PLL_DFS_DIV_VALUE) >> 4) & 0xf;
+}
+
+/**
+ * Get the Core PLL frequency post PLL DFS.
+ */
+static inline uint64_t core_pll_freq(int node)
+{
+	uint32_t reg = nlm_hal_read_sys_reg(node, POWER_ON_RESET_CFG);
+	uint8_t divr = (reg >> 8)  & 0x3;
+	uint8_t divf = (reg >> 10) & 0x7f;
+	return pll_freq(divr, divf, core_pll_dfs_val(node));
+}
+
+/**
+ * Get the SoC PLL frequency post PLL DFS.
+ */
+static inline uint64_t soc_pll_freq(int node)
+{
+	uint32_t reg = nlm_hal_read_sys_reg(node, PLL_CTRL);
+	uint8_t divf = (reg >> 3) & 0x7F;
+	uint8_t divr = (reg >> 1) & 0x3;
+	return pll_freq(divr, divf, soc_pll_dfs_val(node));
+}
+
+/**
+ * Get the DDR PLL frequency.
+ */
+static inline uint64_t ddr_pll_freq(int node)
+{
+	uint32_t reg = nlm_hal_read_sys_reg(node, PLL_CTRL);
+	uint8_t divf = (reg >> 19) & 0x7F;
+	uint8_t divr = (reg >> 17) & 0x3;
+	return pll_freq(divr, divf, 0);
+}
+
+/**
+ * Get the DFS divider value for the specified SoC device.
+ * @param [in] device the SoC device.
+ */
+static inline uint64_t soc_dfs_val(int node, enum soc_dfs_device device)
+{
+	uint8_t device_index = soc_device_index(device);
+	if (device_index == -1)
+		return 0;
+	if (device_index >= 8)
+	{
+		device_index -= 8;
+		return (nlm_hal_read_sys_reg(node, SYS_DFS_DIV_VALUE1) >> (device_index * 4)) & 0xF;
+	}
+	return (nlm_hal_read_sys_reg(node, SYS_DFS_DIV_VALUE0) >> (device_index * 4)) & 0xF;
+}
+
+/**
+ * Get the DFS divider value for the specified Core.
+ * @param [in] core CPU core index.
+ */
+static inline uint64_t core_dfs_val(int node, uint8_t core)
+{
+	return (nlm_hal_read_sys_reg(node, CORE_DFS_DIV_VALUE) >> (core * 4)) & 0xF; 
+}
+
+/**
+ * Determine whether the SoC device's DFS is bypassed.
+ * @param [in] device the SoC device.
+ * @returns 1 if the SoC device's DFS is bypassed.
+ * @returns 0 if the SoC device's DFS is not bypassed.
+ */
+static inline uint8_t is_soc_dfs_bypassed(int node, enum soc_dfs_device device)
+{
+	uint8_t device_index = soc_device_index(device);
+	if (device_index == -1)
+		return 0;
+	return (nlm_hal_read_sys_reg(node, SYS_DFS_BYP_CTRL) >> device_index) & 1;
+}
+
+/**
+ * Enable/disable the DFS bypass for the specified SoC device.
+ * @param [in] device the SoC device.
+ * @param [in] bypass 1: bypass the DFS. 0: do not bypass DFS.
+ */
+static inline void set_soc_dfs_bypass(int node, enum soc_dfs_device device, uint8_t bypass)
+{
+	uint8_t device_index = soc_device_index(device);
+	uint32_t val;
+
+	if (device_index == -1)
+		return;
+	val = nlm_hal_read_sys_reg(node, SYS_DFS_BYP_CTRL) & ~(1 << device_index);
+	nlm_hal_write_sys_reg(node, SYS_DFS_BYP_CTRL, val | ((bypass? 0x1 : 0x0) << device_index));
+}
+
+/**
+ * Determine whether the CPU core's DFS is bypassed.
+ * @param [in] core CPU core index.
+ * @returns 1 if the CPU core's DFS is bypassed.
+ * @returns 0 if the CPU core's DFS is not bypassed.
+ */
+static inline uint8_t is_core_dfs_bypassed(int node, uint8_t core)
+{
+	return (nlm_hal_read_sys_reg(node, CORE_DFS_BYP_CTRL) >> core) & 1;
+}
+
+/**
+ * Enable/disable the DFS bypass for the specified CPU core.
+ * @param [in] core CPU core index.
+ * @param [in] bypass 1: bypass the DFS. 0: do not bypass DFS.
+ */
+static inline void set_core_dfs_bypass(int node, uint8_t core, uint8_t bypass)
+{
+	uint32_t val = nlm_hal_read_sys_reg(node, CORE_DFS_BYP_CTRL) & ~(1 << core);
+	nlm_hal_write_sys_reg(node, CORE_DFS_BYP_CTRL, val | ((bypass? 0x1 : 0x0) << core));
+}
+
+/**
+ * Get the operating frequency for the specified CPU core.
+ * @param [in] device the SoC device.
+ * @returns The SoC device operating frequency, in Hz.
+ */
+uint64_t nlm_hal_get_soc_freq(int node, enum soc_dfs_device device)
+{
+	uint64_t reference, den;
+	if (soc_device_index(device) == -1)
+		return 0;
+
+	switch (device) {
+		case DFS_DEVICE_NAND:
+		case DFS_DEVICE_NOR:
+		case DFS_DEVICE_MMC:
+			/* NOR, NAND and MMC devices are derived from the reference clock. */
+			reference = ref_clk_freq();
+			break;
+		case DFS_DEVICE_DMC:
+			reference = ddr_pll_freq(node);
+			break;
+		case DFS_DEVICE_CORE:
+			/* The Core DFS is derived from the Core PLL */
+			reference = core_pll_freq(node);
+			break;
+		default:
+			reference = soc_pll_freq(node);
+			break;
+	}
+
+    den = soc_dfs_val(node, device) + 1;
+	if (!is_soc_dfs_bypassed(node, device))
+#ifdef NLM_HAL_LINUX_KERNEL
+        do_div(reference, den);
+#else
+        reference /= den;
+#endif
+
+	return reference;
+}
+
+/**
+ * Step the DFS of the specified SoC device to the target DFS index.
+ * @param [in] device the SoC device.
+ * @param [in] dfs_index DFS index (**not** the DFS value).
+ */
+static void step_soc_dfs(int node, enum soc_dfs_device device, uint8_t dfs_index)
+{
+	uint8_t device_index = soc_device_index(device);
+	uint8_t cur = closest_dfs_index(soc_dfs_val(node, device));
+	int8_t delta = cur - dfs_index;
+	int i;
+
+	if (device_index == -1)
+		return;
+
+	if (delta >= 0) {
+		/* positive delta, decrement dfs */
+		for (i=0; i < delta; i++)
+			nlm_hal_write_sys_reg(node, SYS_DFS_DIV_DEC_CTRL, 1 << device_index);
+	} else {
+		/* negative delta, increment dfs */
+		for (i=0; i > delta; i--)
+			nlm_hal_write_sys_reg(node, SYS_DFS_DIV_INC_CTRL, 1 << device_index);
+	}
+}
+
+/**
+ * Set the operating frequency for the specified SoC device.
+ * This is achieved only by stepping the SoC device DFS.
+ * @param [in] device the SoC device.
+ * @param [in] freq target SoC device frequency, in Hz.
+ * @returns the new SoC device operating frequency, in Hz.
+ */
+uint64_t nlm_hal_set_soc_freq(int node, enum soc_dfs_device device, uint64_t freq)
+{
+	uint64_t reference;
+	uint8_t  target;
+	switch (device) {
+		case DFS_DEVICE_NAND:
+		case DFS_DEVICE_NOR:
+		case DFS_DEVICE_MMC:
+			/* NOR, NAND and MMC devices are derived from the reference clock. */
+			reference = ref_clk_freq();
+			break;
+		case DFS_DEVICE_DMC:
+			reference = ddr_pll_freq(node);
+			break;
+		case DFS_DEVICE_CORE:
+			/* The Core DFS is derived from the Core PLL */
+			reference = core_pll_freq(node);
+			break;
+		default:
+			reference = soc_pll_freq(node);
+			break;
+	}
+
+	target = closest_dfs_index(fuzzy_divider(reference, freq) - 1);
+	if (freq >= (reference - FREQ_RESOLUTION)) {
+		/* bypass DFS if freq is reference freq */
+		set_soc_dfs_bypass(node, device, 1);
+	} else {
+		/* otherwise, step dfs and clear bypass */
+		step_soc_dfs(node, device, target);
+		set_soc_dfs_bypass(node, device, 0);
+	}
+
+	return nlm_hal_get_soc_freq(node, device);
+}
+
+/**
+ * Get the operating frequency for the specified CPU core.
+ * @param [in] core CPU core index.
+ * @returns The CPU core operating frequency, in Hz.
+ */
+uint64_t nlm_hal_get_core_freq(int node, uint8_t core)
+{
+	uint64_t den, reference = core_pll_freq(node);
+    
+    den = core_dfs_val(node, core) + 1;
+	if (!is_core_dfs_bypassed(node, core))
+#ifdef NLM_HAL_LINUX_KERNEL
+	    do_div(reference, den);
+#else
+        reference /= den;
+#endif
+
+	return reference;
+}
+
+/**
+ * Step the DFS of the specified CPU core to the target DFS index.
+ * @param [in] core CPU core index.
+ * @param [in] dfs_index DFS index (**not** the DFS value).
+ */
+static void step_core_dfs(int node, uint8_t core, uint8_t dfs_index)
+{
+	uint8_t cur = closest_dfs_index(core_dfs_val(node, core));
+	int8_t delta = cur - dfs_index;
+
+	int i;
+	if (delta >= 0) {
+		/* positive delta, decrement dfs */
+		for (i=0; i < delta; i++)
+			nlm_hal_write_sys_reg(node, CORE_DFS_DIV_DEC_CTRL, 1 << core);
+	} else {
+		/* negative delta, increment dfs */
+		for (i=0; i > delta; i--)
+			nlm_hal_write_sys_reg(node, CORE_DFS_DIV_INC_CTRL, 1 << core);
+	}
+}
+
+/**
+ * Set the operating frequency for the specified CPU core.
+ * This is achieved only by stepping the Core DFS.
+ * @param [in] core CPU core index.
+ * @param [in] freq target CPU core frequency, in Hz.
+ * @returns the new CPU core operating frequency, in Hz.
+ */
+uint64_t nlm_hal_set_core_freq(int node, uint8_t core, uint64_t freq)
+{
+	uint64_t reference = core_pll_freq(node);
+	uint8_t target = closest_dfs_index(fuzzy_divider(reference, freq) - 1);
+
+	if (freq >= (reference - FREQ_RESOLUTION)) {
+		/* bypass DFS if freq is reference freq */
+		set_core_dfs_bypass(node, core, 1);
+	} else {
+		/* otherwise, step dfs and clear bypass */
+		step_core_dfs(node, core, target);
+		set_core_dfs_bypass(node, core, 0);
+	}
+
+	return nlm_hal_get_core_freq(node, core);
+}
+
+/**
+ * Get the operating frequency for the current core.
+ * @returns The core operating frequency (in Hz).
+ */
+unsigned long long nlm_hal_cpu_freq(void)  
+{
+	uint8_t core = (nlm_cpu_id() >> 2) & 0x7;
+	return nlm_hal_get_core_freq(nlm_node_id(), core);
+}
+
+#ifdef NLM_HAL_LINUX_KERNEL
+#include <linux/types.h>
+#include <linux/module.h>
+EXPORT_SYMBOL(nlm_hal_get_soc_freq);
+EXPORT_SYMBOL(nlm_hal_set_soc_freq);
+EXPORT_SYMBOL(nlm_hal_get_core_freq);
+EXPORT_SYMBOL(nlm_hal_set_core_freq);
+EXPORT_SYMBOL(nlm_hal_cpu_freq);
+#endif
diff --git a/arch/mips/netlogic/xlp/Makefile b/arch/mips/netlogic/xlp/Makefile
index 8633c2c..be3a061 100644
--- a/arch/mips/netlogic/xlp/Makefile
+++ b/arch/mips/netlogic/xlp/Makefile
@@ -4,6 +4,7 @@ EXTRA_CFLAGS := $(CFLAGS) -DNLM_HAL_LINUX_KERNEL -Iarch/mips/include/asm/netlogi
 obj-y                    	= setup.o mmu.o
 obj-y 				+= irq.o time.o on_chip.o
 obj-$(CONFIG_NLM_XLP) 		+= platform.o board.o
+obj-$(CONFIG_NLM_XLP) 		+= xlp_hal_pic.o
 obj-$(CONFIG_SMP)       	+= smp.o
 
 obj-$(CONFIG_NLM_XLP) += cpu_control.o cpu_control_asm.o
diff --git a/arch/mips/netlogic/xlp/board.c b/arch/mips/netlogic/xlp/board.c
index b400628..31564c4 100644
--- a/arch/mips/netlogic/xlp/board.c
+++ b/arch/mips/netlogic/xlp/board.c
@@ -1,9 +1,5 @@
-/* Copyright (c) 2011 Windriver Systems, Inc.
- * Author: Wu Zhangjin <zhangjin.wu@windriver.com>
- */
-
 /***********************************************************************
- * Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+ * Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
  * reserved.
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are
@@ -31,101 +27,53 @@
 #include <linux/init.h>
 #include <linux/platform_device.h>
 #include <linux/i2c.h>
-#include <linux/mtd/partitions.h>
-#include <linux/mtd/physmap.h>
-#include <mtd/mtd-abi.h>
+#include <linux/spi/spi.h>
 
 static struct i2c_board_info xlp_i2c_device_info[] __initdata = {
-	{
-		I2C_BOARD_INFO("ds1374", 0x68),
-	},
-	{
-		I2C_BOARD_INFO("lm90", 0x4c),
-	},
-	{
-		I2C_BOARD_INFO("at24c02", 0x57),
-	}
+#ifdef CONFIG_N511
+        {"ds1374",          1, 0x68, 0, 0, 0},
+        // max6657 old driver style is only working when omitted here
+        /*{"max6657",         1, 0x4c, 0, 0, 0},*/
+#else
+        {"ds1374",          0, 0x68, 0, 0, 0},
+        {"max6657",         0, 0x4c, 0, 0, 0},
+#endif
 };
 
-static struct mtd_partition xlp_mtd_partitions[] = {
-	{
-		.name	= "X-Loader(RO)",
-		.offset	= 0,
-		.size	= 0x100000,	/* 1M */
-		.mask_flags = MTD_WRITEABLE,
-	},
-	{
-		.name	= "U-boot(RW)",
-		.offset	= 0x100000,
-		.size	= 0x60000,	/* 384k */
-	},
-	{
-		.name	= "DTB(RW)",
-		.offset	= 0x160000,
-		.size	= 0x20000,	/* 128K */
-	},
-	{
-		.name	= "Kernel(RW)",
-		.offset	= 0x180000,
-		.size	= 0x580000,	/* 5.5M */
-	},
+static int __init xlp_i2c_device_init(void)
+{
+	return i2c_register_board_info(1, xlp_i2c_device_info, ARRAY_SIZE(xlp_i2c_device_info));
+}
+
+arch_initcall(xlp_i2c_device_init);
+
+static struct spi_board_info spsn_spi_board_info[] __initdata = {
+#ifdef CONFIG_N511
+        {
+                .modalias = "m25p80",
+                .max_speed_hz = 40000000,
+                .bus_num = 0,
+                .chip_select = 0
+        },
+#else
 	{
-		.name	= "Rootfs(RW)",
-		.offset	= 0x700000,
-		.size	= 0x800000,	/* 8M */
+		.modalias = "m25p80",
+		.max_speed_hz = 40000000,
+		.bus_num = 0,
+		.chip_select = 1
 	},
 	{
-		.name	= "Env(RO)",
-		.offset	= 0xf00000,	/* 1M */
-		.size	= MTDPART_SIZ_FULL,
-		.mask_flags = MTD_WRITEABLE,
-	},
-};
-
-#define BOARD_FLASH_SIZE 0x01000000 /* 16MB */
-#define BOARD_FLASH_BASE 0x16000000
-#define BOARD_FLASH_WIDTH 2 /* 16-bits */
-
-static struct physmap_flash_data xlp_flash_data = {
-	.width		= BOARD_FLASH_WIDTH,
-	.nr_parts	= ARRAY_SIZE(xlp_mtd_partitions),
-	.parts		= xlp_mtd_partitions,
-};
-
-static struct resource xlp_mtd_resource = {
-	.start	= BOARD_FLASH_BASE,
-	.end	= BOARD_FLASH_BASE + BOARD_FLASH_SIZE - 1,
-	.flags	= IORESOURCE_MEM,
-};
-
-static struct platform_device xlp_mtd_device = {
-	.name		= "physmap-flash",
-	.dev		= {
-		.platform_data	= &xlp_flash_data,
+		.modalias = "mt29f",
+		.max_speed_hz = 50000000,
+		.bus_num = 0,
+		.chip_select = 2
 	},
-	.num_resources	= 1,
-	.resource	= &xlp_mtd_resource,
-};
-
-static struct platform_device *xlp_mtd_devices[] __initdata = {
-	&xlp_mtd_device,
+#endif
 };
 
-static int __init xlp_device_init(void)
+static int __init xlp_spi_device_init(void)
 {
-	int err;
-
-	err = i2c_register_board_info(1, xlp_i2c_device_info, ARRAY_SIZE(xlp_i2c_device_info));
-
-	if (err < 0)
-		pr_err("xlp-i2c: cannot register board I2C devices\n");
-
-	pr_info("Register xlp mtd devices\n");
-	err = platform_add_devices(xlp_mtd_devices, ARRAY_SIZE(xlp_mtd_devices));
-
-	if (err < 0)
-		pr_err("xlp-mtd: cannot register board mtd devices\n");
-	return err;
+	return spi_register_board_info(spsn_spi_board_info, ARRAY_SIZE(spsn_spi_board_info));
 }
 
-arch_initcall(xlp_device_init);
+arch_initcall(xlp_spi_device_init);
diff --git a/arch/mips/netlogic/xlp/cpu_control.c b/arch/mips/netlogic/xlp/cpu_control.c
index 444ab0b..874a9b4 100644
--- a/arch/mips/netlogic/xlp/cpu_control.c
+++ b/arch/mips/netlogic/xlp/cpu_control.c
@@ -42,12 +42,12 @@ THE POSSIBILITY OF SUCH DAMAGE.
 
 #include <asm/netlogic/xlp.h>
 #include <asm/netlogic/hal/nlm_hal.h>
-#include <asm/netlogic/mips-exts.h>
 
 #include "cpu_control_macros.h"
 
 #define XLP_ECFG_BASE           0x18000000
 #define XLP_SYS_DEV_BASE        0x35000
+#define PLL_REF_CLK_PS		7500
 
 /* temporary storage space for
  * stack pointers
@@ -75,22 +75,37 @@ static inline void jump_address(unsigned long entry)
 static inline void config_lsu(void)
 {
 	uint32_t tmp0, tmp1, tmp2;
-	__asm__ __volatile__ (
-		".set push\n"
-		".set noreorder\n"
-		"li      %0, "STR(LSU_DEFEATURE)"\n"
-		"mfcr    %1, %0\n"
-		"lui     %2, 0x4080\n"
-		"or      %1, %1, %2\n"
-		"li	 %2, ~0xe\n"
-		"and	 %1, %1, %2\n"
-		"mtcr    %1, %0\n"
-		"li      %0, "STR(SCHED_DEFEATURE)"\n"
-		"lui     %1, 0x0100\n"
-		"mtcr    %1, %0\n"
-		".set pop\n"
-		: "=r" (tmp0), "=r" (tmp1), "=r" (tmp2)
-	);
+
+	if (xlp8xx_a01_workaround_needed) {
+		__asm__ __volatile__ (
+			".set push\n"
+			".set noreorder\n"
+			"li      %0, "STR(LSU_DEFEATURE)"\n"
+			"mfcr    %1, %0\n"
+			"lui     %2, 0x4080\n"
+			"or      %1, %1, %2\n"
+			"li	 %2, ~0xe\n"
+			"and	 %1, %1, %2\n"
+			"mtcr    %1, %0\n"
+			"li      %0, "STR(SCHED_DEFEATURE)"\n"
+			"lui     %1, 0x0100\n"
+			"mtcr    %1, %0\n"
+			".set pop\n"
+			: "=r" (tmp0), "=r" (tmp1), "=r" (tmp2)
+		);
+	} else {
+		__asm__ __volatile__ (
+			".set push\n"
+			".set noreorder\n"
+			"li      %0, "STR(LSU_DEFEATURE)"\n"
+			"mfcr    %1, %0\n"
+			"lui     %2, 0x4080\n"
+			"or      %1, %1, %2\n"
+			"mtcr    %1, %0\n"
+			".set pop\n"
+			: "=r" (tmp0), "=r" (tmp1), "=r" (tmp2)
+		);
+	}
 }
 
 static void enable_cores(unsigned int node, unsigned int cores_bitmap)
@@ -128,10 +143,28 @@ static void enable_cores(unsigned int node, unsigned int cores_bitmap)
 	}
 }
 
-int threads_to_enable = 1;
+static inline int num_ones(unsigned long mask)
+{
+	int ret = 0;
+
+	if (!mask) return 0;
+	while ((mask &= (mask - 1))) ret++;
+	return (ret + 1);
+}
+
+int threads_to_enable = 0;
 /*
  * This function is called once for each node. However, it is executed
  * only on "master cpu", mostly on n0c0t0
+ *
+ * t0_bitmap: bitmap of thread@0 of those cores in the given node, which 
+ *            are enabled in node_cpumask
+ *
+ * cores_bitmap: bitmap of cores (core 0's) which have at least one thread
+ *               enabled (considering ALL nodes and cores)
+ *
+ * threads_to_enable: count bitmap of threads to enable in all enabled cores.
+ *
  */
 void enable_cpus(unsigned int node, unsigned int node_cpumask)
 {
@@ -167,13 +200,14 @@ void enable_cpus(unsigned int node, unsigned int node_cpumask)
 
 	cores_bitmap = 0;
 	for (t0_positions = 0, index = 0; t0_positions < 32; t0_positions += 4, index++) {
-		if (t0_bitmap & (1 << t0_positions))
+		 if (t0_bitmap & (1 << t0_positions)){
 			cores_bitmap |= (1 << index);
+			threads_to_enable |= (num_ones((node_cpumask >> t0_positions) & 0xf) << t0_positions);
+		 }
 	}
 
-	threads_to_enable = num_ones(node_cpumask & 0xf);
-
-	printk("node@%d: t0_bitmap = 0x%08x, cores_bitmap = 0x%08x\n", node, t0_bitmap, cores_bitmap);
+	printk("node@%d: t0_bitmap = 0x%08x, cores_bitmap = 0x%08x threads_to_enable 0x%x\n", 
+		node, t0_bitmap, cores_bitmap,threads_to_enable);
 
 	enable_cores(node, cores_bitmap);
 
@@ -184,3 +218,99 @@ void enable_cpus(unsigned int node, unsigned int node_cpumask)
 
 	return;
 }
+
+EXPORT_SYMBOL(enable_cpus);
+/* Return period in femto-seconds.(1e-15 s)
+ */
+static u32 get_pll_period(int divf,int divr) {
+
+	u32 vco_fs;		/* vco in femto-seconds */
+	u32 pll_period_fs;	/* pll output in femto-seconds */
+
+	if (divr == 2) {
+		printk (KERN_ERR "Error! Illegal divr value %d!\n", divr);
+		return 0;
+	}
+	if ((divf < 11) || (divf > 91)) {
+		printk (KERN_ERR "Error! Illegal divf value %d!\n", divf);
+		return 0;
+	}
+
+	vco_fs = (((PLL_REF_CLK_PS * 1000) * (divr+1))/(4 * (divf+1)));
+	pll_period_fs  = vco_fs * 2; /* pll output is divided by 2 */
+
+	return pll_period_fs;
+}
+
+/* Return frequency in Hz
+ */
+static uint64_t get_pll_freq(int divf,int divr)
+{
+	uint64_t hz_freq = 1000000000000000ULL; /* 1e15 */
+	u32 pll_period_fs = get_pll_period(divf,divr);
+
+	do_div(hz_freq, ((uint64_t) pll_period_fs));
+
+	return hz_freq;
+}
+
+/* Return frequency in Hz
+ */
+u32 get_cpu_freq(int cpu_num)
+{
+	volatile u32* mmio;
+	uint64_t pll_freq;
+	u32 pwron_rst_reg;
+	u32 core_dfs, divf, divr, dfs, core, ext_div;
+	mmio = (volatile u32 *) cpu_io_mmio(cpu_num/32,SYS);
+
+	pwron_rst_reg = nlm_hal_read_32bit_reg((uint64_t)mmio, SYS_POWERONRESETCFG);
+	core_dfs      = nlm_hal_read_32bit_reg((uint64_t)mmio, SYS_COREDFSDIVCTRL);
+	core          = cpu_num >> 2;
+
+	divf = SYS_PWRON_DIVF(pwron_rst_reg);
+	divr = SYS_PWRON_DIVR(pwron_rst_reg);
+	ext_div = SYS_PWRON_EXTDIV(pwron_rst_reg) + 1;
+	dfs  = SYS_CORE_DFS(core_dfs,core) + 1;
+
+	pll_freq = get_pll_freq(divf,divr);
+	do_div( pll_freq, ((uint64_t)(ext_div * dfs)));
+	return ((u32) pll_freq);
+}
+
+EXPORT_SYMBOL(get_cpu_freq);
+
+u32 get_core_dfs(int cpu_num)
+{
+	u32 core_dfs, dfs;
+	volatile u32 *mmio;
+
+	mmio = (volatile u32 *) cpu_io_mmio(cpu_num/32,SYS);
+	core_dfs = nlm_hal_read_32bit_reg((uint64_t)mmio, SYS_COREDFSDIVCTRL);
+	dfs  = SYS_CORE_DFS(core_dfs, (cpu_num >> 2));
+	return dfs;
+}
+
+EXPORT_SYMBOL(get_core_dfs);
+
+/*
+ * @cpu_num : # of the cpu
+ * @dec	: whether to decrement frequency
+ * NOTE: If frequency to be decremented, multiplier should be incremented
+ */
+u32 change_cpu_freq(int cpu_num, int dec)
+{
+	volatile u32 *mmio;
+	u32 val;
+	/* INC freq --> DEC multiplier */
+	u32 reg = (dec == 1) ? SYS_COREDFSDIVINCCTRL: SYS_COREDFSDIVDECCTRL;
+
+	mmio = (volatile u32 *) cpu_io_mmio(cpu_num/32,SYS);
+	val = (0x1 << (cpu_num >> 2));
+	nlm_hal_write_32bit_reg((uint64_t)mmio, reg, val);
+	//printk("NLM: %#x\n", nlm_hal_read_32bit_reg((uint64_t)mmio, SYS_COREDFSDIVCTRL));
+	return 0;
+}
+
+EXPORT_SYMBOL(change_cpu_freq);
+
diff --git a/arch/mips/netlogic/xlp/cpu_control_asm.S b/arch/mips/netlogic/xlp/cpu_control_asm.S
index ebd9ce4..b1660a0 100644
--- a/arch/mips/netlogic/xlp/cpu_control_asm.S
+++ b/arch/mips/netlogic/xlp/cpu_control_asm.S
@@ -22,16 +22,52 @@
 	.set    pop
 	.endm
 
+	/* setup TLBs for non-0
+	 * cpus for KSEG2 access
+	 */
+	.macro 	SETUP_PERTHREAD_TLB
+#ifdef CONFIG_64BIT
+	dli     t3, CKSSEG
+	dmtc0   t3, CP0_ENTRYHI
+#else
+	li      t3, CKSSEG
+	mtc0    t3, CP0_ENTRYHI
+#endif
+	li      t1, 0x1f
+	MTC0    t1, CP0_ENTRYLO0    # physaddr, VG, cach exlwr
+	li      t2, 0x1
+	MTC0    t2, CP0_ENTRYLO1    # physaddr, DVG, cach exlwr
+	li      t1, 0x1fffe000      # MAPPED_KERN_TLBMASK, TLBPGMASK_256M
+	mtc0    t1, CP0_PAGEMASK
+	mtc0    zero, CP0_INDEX
+	tlbwi
+	li      t0, 1
+	mtc0    t0, CP0_WIRED
+	EHB
+	.endm
+
 	.macro 	__start_secondary
 	.set push
-	mtc0    zero, CP0_WIRED
+#ifdef CONFIG_MAPPED_KERNEL
+	SETUP_PERTHREAD_TLB
+#endif
 #ifdef CONFIG_64BIT
 	prog_c0_status ST0_KX ST0_BEV
 #else
 	prog_c0_status 0 ST0_BEV
 #endif
 	mfc0 		t0, CP0_EBASE, 1
+	andi		t0, 0x3
+	bnez		t0, 20f
+
+	/* Do this after tlb is set up */
+	__config_lsu
+
+20:
+
+	mfc0 		t0, CP0_EBASE, 1
 	andi 		t0, 0x7f
+
 	PTR_LA		t1, xlp_stack_pages_temp
 	li   		t2, _THREAD_SIZE
 	srl  		t2, 2
@@ -49,11 +85,18 @@
 	.set push
 	.set noreorder
 	li      t0, LSU_DEFEATURE
+
 	mfcr    t1, t0
 
 	lui     t2, 0x4080  # Enable Unaligned Access, L2HPE
 	or      t1, t1, t2
+	mtcr    t1, t0
+
+        PTR_LA	t2, xlp8xx_a01_workaround_needed
+	lw	t2, 0(t2)
+	beqz	t2, 10f
 
+	mfcr    t1, t0
 	li	t2, ~0xe    # S1RCM
 	and	t1, t1, t2
 
@@ -63,6 +106,39 @@
 	lui     t1, 0x0100 # Experimental: Disable BRU accepting ALU ops
 	mtcr    t1, t0
 
+10:
+
+	.set pop
+.endm
+
+.macro	flush_l1_dcache
+	.set push
+	.set noreorder
+	li	t0, LSU_DEBUG_DATA0
+	li      t1, LSU_DEBUG_ADDR
+	li	t2, 0
+	li 	t3, 0x200
+1:
+	sll	v0, t2, 5	
+	mtcr	zero, t0
+	ori	v1, v0, 0x3
+	mtcr	v1, t1
+2:
+	mfcr	v1, t1
+	andi	v1, 0x1
+	bnez	v1, 2b
+	nop
+	mtcr    zero, t0
+	ori	v1, v0, 0x7
+	mtcr    v1, t1
+3:
+	mfcr    v1, t1
+	andi    v1, 0x1
+	bnez    v1, 3b
+	nop
+	addi	t2, 1
+	bne	t3, t2, 1b
+	nop
 	.set pop
 .endm
 
@@ -83,21 +159,27 @@ EXPORT(reset_entry)
 	li      t1, 0x1
 	sll     t0, t1, t0
 	nor     t0, t0, zero
-	dla     t2, CPU_MMIO_OFFSET(SYS)
+#ifdef CONFIG_64BIT
+	dla     t2, CPU_MMIO_OFFSET(0, SYS)
+#else
+	la      t2, CPU_MMIO_OFFSET(0, SYS)
+#endif
 	add	t2, t2, t3  #get node based SYS offset
 	lw      t1, (SYS_CPUNONCOHERENTMODE_REG << 2)(t2)
 	and     t1, t1, t0
-	sw      t1, (SYS_CPUNONCOHERENTMODE_REG << 2)(t2)
+	sw      t1, (SYS_CPUNONCOHERENTMODE_REG<< 2)(t2)
 
 	/* read back to ensure complete */
 	lw      t1, (SYS_CPUNONCOHERENTMODE_REG << 2)(t2)
 	sync
 
-	/* Configure LSU on Non-0 Cores. */
-	__config_lsu
-
+#ifdef CONFIG_64BIT
 	dla     t1, boot_siblings_start
 	dla     t2, __boot_siblings
+#else
+	la      t1, boot_siblings_start
+	la      t2, __boot_siblings
+#endif
 	subu	t2, t2, t1		/* t2 now has the jump offset */
 
 	/* Jump to KSEG0 addr of __boot_siblings
@@ -124,7 +206,24 @@ EXPORT(boot_siblings_start)			/* "Master" (n0c0t0) cpu starts from here */
 	sync
 
 EXPORT(__boot_siblings)				/* T0 of every core in every node starts from here */
-	lw      t1, threads_to_enable
+
+	flush_l1_dcache
+
+	mfc0    t3, CP0_EBASE, 1
+	srl     t3, t3 , 2
+	and     t3, t3 , 0x7  			/* t3 contains the core number */
+	mul	 t3, t3 , 4                        
+#ifdef CONFIG_64BIT
+	dla     t0, threads_to_enable
+#else
+	la      t0, threads_to_enable
+#endif
+#ifdef CONFIG_MAPPED_KERNEL
+	subu	 t0, t0, 0x40000000		/* t0 has the kseg0 address of threads_to_enable */
+#endif
+	lw  	 t1, 0(t0)			/* t1 now has the entire threads_to_enable */
+	srl	 t1, t3                     
+	and	 t1, t1, 0xf 			/* t1 has the threads to enable for this core. */
 	beq     t1, 0x2, 2f
 	nop
 	addi    t1, -1
@@ -182,24 +281,22 @@ END(ptr_smp_boot)
 NESTED(prom_pre_boot_secondary_cpus, 16, sp)
         SET_MIPS64
 
-	mtc0		zero, CP0_WIRED
-	/* Don't trust the bootstrapper to set cp0_status to
-	 * what you want */
+	/* Don't trust the bootstrapper to set cp0_status to what you want */
 #ifdef CONFIG_64BIT
-	prog_c0_status ST0_KX ST0_BEV
+	setup_c0_status ST0_KX ST0_BEV
 #else
-	prog_c0_status 0 ST0_BEV
+	setup_c0_status 0 ST0_BEV
 #endif
-	mfc0 		t0, CP0_EBASE, 1
-	andi 		t0, 0x7f	# t0 has the hard processor id
-	PTR_LA		t1, xlp_stack_pages_temp
-	li   		t2, _THREAD_SIZE
-	srl  		t2, 2
-	mul  		t3, t2, t0
-	PTR_ADDU  	gp, t1, t3
-	PTR_ADDU  	sp, gp, t2
-	PTR_ADDI  	sp, sp, -64
-	PTR_LA t0, 	prom_boot_cpus_secondary
-	jr 		t0
-	 nop
+	mfc0 t0, CP0_EBASE, 1 #read ebase
+        andi t0, 0x7f #t0 has the processor_id()
+        PTR_LA  t1, xlp_stack_pages_temp
+        li   t2, _THREAD_SIZE
+        srl  t2, 2
+        mul  t3, t2, t0
+        PTR_ADDU  gp, t1, t3
+        PTR_ADDU       sp, gp, t2
+        PTR_ADDI       sp, sp, -32
+        PTR_LA t0, prom_boot_cpus_secondary
+        jr t0
+        nop
 END(prom_pre_boot_secondary_cpus)
diff --git a/arch/mips/netlogic/xlp/cpu_control_macros.h b/arch/mips/netlogic/xlp/cpu_control_macros.h
index 69ac013..673775e 100644
--- a/arch/mips/netlogic/xlp/cpu_control_macros.h
+++ b/arch/mips/netlogic/xlp/cpu_control_macros.h
@@ -1,155 +1,32 @@
 #ifndef __CPUCONTROL_MACROS_H__
 #define __CPUCONTROL_MACROS_H__
-
+#include <asm/netlogic/xlp8xx/cpu.h>
+#include <asm/netlogic/xlp8xx/xlp_sys.h>
 #define CP0_EBASE	$15
-#define CHIP_PID_XLP    0x00
+#ifdef CONFIG_64BIT
 #define NMI_BASE    	0xffffffffbfc00000UL
+#else
+#define NMI_BASE        0xbfc00000UL	
+#endif
 #define NMI_BASE_ASM   	0xbfc00000
 
-/* CPU Internal Blocks specific to XLP .
- * These are accessed using the mfcr/mtcr
- * instructions. Blocks [0-5] are same for
- * XLR and XLP
- */
-#define CPU_BLOCKID_MAP                         0x0a
-/* Offsets of interest from the 'MAP' Block */
-#define BLKID_MAP_THREADMODE                    0x00 
-#define BLKID_MAP_EXT_EBASE_ENABLE              0x04 
-#define BLKID_MAP_CCDI_CONFIG                   0x08
-#define BLKID_MAP_THRD0_CCDI_STATUS             0x0c    
-#define BLKID_MAP_THRD1_CCDI_STATUS             0x10
-#define BLKID_MAP_THRD2_CCDI_STATUS             0x14    
-#define BLKID_MAP_THRD3_CCDI_STATUS             0x18
-#define BLKID_MAP_THRD0_DEBUG_MODE              0x1c
-#define BLKID_MAP_THRD1_DEBUG_MODE              0x20
-#define BLKID_MAP_THRD2_DEBUG_MODE              0x24
-#define BLKID_MAP_THRD3_DEBUG_MODE              0x28
-#define BLKID_MAP_MISC_STATE                    0x60
-#define BLKID_MAP_DEBUG_READ_CTL                0x64
-#define BLKID_MAP_DEBUG_READ_REG0               0x68
-#define BLKID_MAP_DEBUG_READ_REG1               0x6c
-
-#define CPU_BLOCKID_SCH                         7
-#define CPU_BLOCKID_SCU                         8
-#define CPU_BLOCKID_FPU                         9
-
 #define LSU_DEFEATURE 0x304
+#define LSU_DEBUG_ADDR  0x305
+#define LSU_DEBUG_DATA0	0x306
 #define MMU_SETUP 0x400
 #define SCHED_DEFEATURE 0x700
 
-/* ----------------------------------
- *   XLP RESET Physical Address Map
- * ----------------------------------
- * PCI ECFG : 0x18000000 - 0x1bffffff 
- * PCI CFG  : 0x1c000000 - 0x1cffffff 
- * FLASH    : 0x1fc00000 - 0x1fffffff 
- * ----------------------------------
- */
-
-/* 
- * The DEFAULT_XLP_IO_BASE value is what is
- * programmed in the NBU's (NorthBridge Unit) 
- * ECFG_BAR register. The NBU itself is 
- * accessible as [BDF:0,0,0].
- */
-#define DEFAULT_XLP_IO_BASE       0xffffffffb8000000ULL
-#define DEFAULT_XLP_IO_BASE_VIRT  0xffffffffb8000000      /* IO_BASE for Assembly macros */
-#define DEFAULT_CPU_IO_BASE       DEFAULT_XLP_IO_BASE
-#define DEFAULT_CPU_IO_BASE_VIRT  DEFAULT_XLP_IO_BASE_VIRT
-#define CPU_IO_SIZE               (64<<20)        /* Size of the ECFG Space      */
-#define HDR_OFFSET                0x100           /* Skip 256 bytes of cfg. hdrs */
-
-/* The On-Chip functional blocks for XLP */
-
-/* --------------------------------------------------------------*/
-/* Accesses Based on Enhanced Configuration Mechanism            */
-/* --------------------------------------------------------------*/
-/* Interface | Bus          | Dev       |  Func                  */
-/* --------------------------------------------------------------*/
-#define        BRIDGE        (0x00<<20) | (0x00<<15) | (0x00<<12)
-#define        PIC           (0x00<<20) | (0x00<<15) | (0x04<<12)
-#define        CMS           (0x00<<20) | (0x04<<15) | (0x00<<12)
-#define        UART0         (0x00<<20) | (0x06<<15) | (0x00<<12)
-#define        UART1         (0x00<<20) | (0x06<<15) | (0x01<<12)
-#define        I2C0          (0x00<<20) | (0x06<<15) | (0x02<<12)
-#define        I2C1          (0x00<<20) | (0x06<<15) | (0x03<<12)
-#define        GPIO          (0x00<<20) | (0x06<<15) | (0x04<<12)
-#define        SYS           (0x00<<20) | (0x06<<15) | (0x05<<12)
-#define        JTAG          (0x00<<20) | (0x06<<15) | (0x06<<12)
-#define        NOR           (0x00<<20) | (0x07<<15) | (0x00<<12)
-#define        NAND          (0x00<<20) | (0x07<<15) | (0x01<<12)
-#define        SPI           (0x00<<20) | (0x07<<15) | (0x02<<12)
-#define        MMC           (0x00<<20) | (0x07<<15) | (0x03<<12)
-
-#define CPU_MMIO_OFFSET(x) (DEFAULT_CPU_IO_BASE_VIRT + (x) + HDR_OFFSET)
-
-
-#define SYS_CHIPRST_REG                 0
-#define SYS_PWRONRSTCFG0_REG            1
-#define SYS_EFUSEDEV_CFG0_REG           2
-#define SYS_EFUSEDEV_CFG1_REG           3
-#define SYS_EFUSEDEV_CFG2_REG           4
-#define SYS_EFUSEDEV_CFG3_REG           5
-#define SYS_EFUSEDEV_CFG4_REG           6
-#define SYS_EFUSEDEV_CFG5_REG           7
-#define SYS_EFUSEDEV_CFG6_REG           8
-#define SYS_EFUSEDEV_CFG7_REG           9 
-#define SYS_PLLCTRL_REG                 10
-#define SYS_CPURST_REG                  11
-#define SYS_CPUTHREADEN_REG             12
-#define SYS_CPUNONCOHERENTMODE_REG      13
-#define SYS_COREDFSDISCTRL_REG          14
-#define SYS_COREDFSRSTCTRL_REG          15
-#define SYS_COREDFSBYPCTRL_REG          16
-#define SYS_COREDFSPHACTRL_REG          17
-#define SYS_COREDFSDIVCTRL_REG          18
-#define SYS_SYSRST_REG                  19
-#define SYS_SYSDFSDISCTRL_REG           20
-#define SYS_SYSDFSRSTCTRL_REG           21
-#define SYS_SYSDFSBYPCTRL_REG           22
-#define SYS_SYSDFSDIVCTRL_REG           23
-#define SYS_DMCDFSCTRL_REG              24
-
 #ifndef __ASSEMBLY__
-
-static inline int num_ones(unsigned long mask)
-{
-	int  nones;
-	for (nones = 0; mask; mask >>= 1) {
-		if (mask & 0x1)
-			++nones;
-	}
-	return nones;
-}
-
-enum processor_sys
-{
-	SYS_CHIPRST                     = 0,
-	SYS_PWRONRSTCFG0                = 1,
-	SYS_EFUSEDEV_CFG0               = 2,
-	SYS_EFUSEDEV_CFG1               = 3,
-	SYS_EFUSEDEV_CFG2               = 4,
-	SYS_EFUSEDEV_CFG3               = 5,
-	SYS_EFUSEDEV_CFG4               = 6,
-	SYS_EFUSEDEV_CFG5               = 7,
-	SYS_EFUSEDEV_CFG6               = 8,
-	SYS_EFUSEDEV_CFG7               = 9, 
-	SYS_PLLCTRL                     = 10,
-	SYS_CPURST                      = 11,
-	SYS_CPUTHREADEN                 = 12,
-	SYS_CPUNONCOHERENTMODE          = 13,
-	SYS_COREDFSDISCTRL              = 14,
-	SYS_COREDFSRSTCTRL              = 15,
-	SYS_COREDFSBYPCTRL              = 16,
-	SYS_COREDFSPHACTRL              = 17,
-	SYS_COREDFSDIVCTRL              = 18,
-	SYS_SYSRST                      = 19,
-	SYS_SYSDFSDISCTRL               = 20,
-	SYS_SYSDFSRSTCTRL               = 21,
-	SYS_SYSDFSBYPCTRL               = 22,
-	SYS_SYSDFSDIVCTRL               = 23,
-	SYS_DMCDFSCTRL                  = 24
-};
-
-#endif
+#define	 XLP_THREADS_PER_CORE	4
+#define  XLP_CORES_PER_NODE	7
+u32 get_cpu_freq(int);
+void enable_cpus(unsigned int, unsigned int);
+u32 get_core_dfs(int);
+u32 change_cpu_freq(int, int);
+extern int xlp8xx_a01_workaround_needed;
+#define get_cpu_freq_masked(cpu_num, mask)\
+	((get_cpu_freq(cpu_num)/1000ULL) & (mask))
+#define XLP_FREQ_MASK	(0xfffffff0)
+#define XLP_CPU0	0
+#endif	// __ASSEMBLY__
 #endif /* __CPUCONTROL_MACROS_H__ */
diff --git a/arch/mips/netlogic/xlp/irq.c b/arch/mips/netlogic/xlp/irq.c
index 4254fbc..fd35416 100644
--- a/arch/mips/netlogic/xlp/irq.c
+++ b/arch/mips/netlogic/xlp/irq.c
@@ -32,6 +32,7 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #include <linux/mm.h>
 #include <linux/slab.h>
 #include <linux/pci.h>
+#include <linux/msi.h>
 #include <asm/errno.h>
 #include <asm/signal.h>
 #include <asm/system.h>
@@ -41,211 +42,841 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #include <asm/time.h>
 
 #include <asm/netlogic/cpumask.h>
+#include <asm/netlogic/xlp_hal_pic.h>
 #include <asm/netlogic/xlp.h>
+#include <asm/netlogic/xlp_irq.h>
+#include <asm/netlogic/msidef.h>
 #include <asm/netlogic/mips-exts.h>
 #include <asm/netlogic/pic.h>
 #include <asm/netlogic/debug.h>
 #include <asm/thread_info.h>
-#include <linux/irq.h>
-#include <asm/netlogic/hal/nlm_hal_pic.h>
-/*
- * These are the routines that handle all the low level interrupt stuff. 
+
+/* About this file: irq.c
+ * This file contains routines that handle all the low level interrupt stuff.
+ * Some of the platform specific portions are moved to arch/mips/pci/pci-xlp.c
  * Actions handled here are: initialization of the interrupt map, requesting of
- * interrupt lines by handlers, dispatching if interrupts to handlers, probing
- * for interrupt lines 
+ * interrupt lines by handlers, dispatching interrupts to handlers, probing
+ * for interrupt lines..etc.
  */
 
 /* Externs */
-extern void nlm_xlp_msgring_int_handler(int irq, struct pt_regs *regs);
+extern void nlm_common_timer_interrupt(struct pt_regs *, int);
+extern void nlm_xlp_msgring_int_handler(int , struct pt_regs *);
+extern int xlp_ctrl_fn_from_dev(const struct pci_dev *);
+extern const struct cpumask *xlp_closest_match_cpumask(struct cpumask *);
+int xlp_intx_enable(int);
+int xlp_intx_disable(int);
+extern void xlp_set_cpumask(const struct cpumask *m, int irt);
+void xlp_ctrl_intmode_add(int , int, int);
+extern int xlp_get_ctrl_intmode(int);
+extern int xlp_set_ctrl_intmode(int fn, int mode);
+#if defined CONFIG_PCI_MSI
+extern int xlp_msi_status_clear(struct pci_dev *, int);
+int xlp_msi_enable(int, u32);
+extern int xlp_msi_base_vector(struct pci_dev *);
+extern int is_msi_set(int);
+extern int calc_msi_vector_offset(int);
+int xlp_msi_disable(int, int);
+extern u32 xlp_msi_set_mask(int, int, int);
+volatile const void *xlp_msix_addr_start(int);
+volatile const void *xlp_msi_addr_start(int);
+extern u32 xlp_msix_status_clear(int);
+extern u32 xlp_msix_set_mask(int, int, int);
+int xlp_msix_enable(int);
+int xlp_msix_disable(int);
+void mask_msi_irq(unsigned int);
+void unmask_msi_irq(unsigned int);
+#endif
 
-uint64_t nlm_xlp_irq_mask;
-spinlock_t nlm_common_pic_lock = SPIN_LOCK_UNLOCKED;
+#ifdef CONFIG_NUMA
+extern void xlp_numa_ack_pic(int);
+#endif
 
-extern void nlm_enable_vc_intr(void);
-extern void enable_msgconfig_int(void);
+/* own variables */
+
+/* xlp_irq_mask is retained for legacy. It can be removed at a later point of
+ * time. Initially it was meant to keep a copy of present interrupt mask; with
+ * multi cpus each having its own mask register, we might not need this variable
+ */
+static volatile uint64_t xlp_irq_mask;
+
+/* spin lock for all interrupt related data structures
+ * This variable is used in timer init, so we export it
+ */
+spinlock_t xlp_pic_lock = SPIN_LOCK_UNLOCKED;
+EXPORT_SYMBOL(xlp_pic_lock);
+#if defined CONFIG_PCI_MSI
+/*
+ * This bitmap keeps track of the MSI vectors allocated from
+ * XLP_MSIX_IRQ_START(x)
+ */
+struct msi_alloc_bitmap {
+	u64 bitmap;	/* Can be any data structure to keep bits */
+	u32 count;	/* #of bits set at any point of time */
+};
+static struct msi_alloc_bitmap msix_vec[XLP_MAX_SLOTS];
+static struct msi_alloc_bitmap msi_vec[XLP_MAX_SLOTS];
+#endif
+
+/*
+ * There are two data structures pivotal for interrupt delivery mechanism
+ * irq_map[] and rvec_map[]
+ * irq_map[] : An array of struct irq_map_elem.
+ * Number of elements in this array is equal to NR_IRQ => there should be an
+ * entry corresponding to each interrupt in the system.
+ * Initial 8 elements (0-XLP_IRQ_RESERVED_MAX) are unpopulated. They are
+ * reserved for system internal interrupts which are not explicitly handled
+ * by plat_irq_dispatch; the handlers for these interrupts are called
+ * differently.
+ *
+ * All other entries are handled by plat_irq_dispatch()
+ * An entry would contain the rvec entry for this interrupt. The offset of this
+ * entry would be presented as the interrupt number for any requests
+ * E.g, for UART1, index is 141. This is the value of uart1 interrupt.
+ * asm/netlogic/xlp_irq.h defines this value as XLP_UART_IRQ(1)
+ *
+ * Each irq_map_elem has two members : rvec -> the rvec entry for this entry,
+ * usage : the number of successful irq_request() called on this IRQ.
+ *
+ * rvec_map is meant to map rvec numbers back to Interrupts.
+ * RVEC is just a number for s/w; which is the bit offset that is set in EIRR
+ * Refer PRM : 9.3 for details.
+ *
+ * irq_map : {<IERR RVEC>, <#of s/w vector multiplexed on this RVEC> }
+ * Some RVECs are reserved : so use only 9 through 63
+ * Any irt index can be derived from irq using the macros
+ * xlp_irt_to_irq() or xlp_irq_to_irt()
+ * These macros are required because of the imposed 64 bits (if RVEC)
+ * to 160 entries (size of IRT table)
+ *
+ * It is further complicated by the fact that PCI LINK interrupts are
+ * multiplexed with MSI interrupts. In that mode, each PCI Link interrupts
+ * can be caused by 32 MSI interrupts. That means, we need a meachinsm to map
+ * 32 msi interrupts * 4 pci slots (128 interrupts) to 4 possible RVECs.
+ * the irq_map table serves this purpose as well as follows
+ *
+ * We limit the per pci slot interrupt (for the time being) to XLP_MSI_PER_SLOT
+ * (currently 8). This is done to keep total number of interrupts to NR_IRQ;
+ *
+ */
+struct irq_map_elem {
+	int rvec;
+	int usage;	/* This is the usage count of an rvec, not the number
+			   of times a vector is used in s/w */
+};
+
+static struct irq_map_elem irq_map[NR_IRQS] = {
+	{0, 0},	/* Dummy			:	0 */
+	{0, 0},	/* Dummy			:	1 */
+	{0, 0},	/* Dummy			:	2 */
+	{0, 0},	/* Dummy			:	3 */
+	{0, 0},	/* Dummy			:	4 */
+	{0, 0},	/* Dummy			:	5 */
+	{0, 0},	/* Dummy			:	6 */
+	{0, 0},	/* Dummy			:	7 */
+        {9, 0}, /*XLP_WD_IDX(0)			:	8 */
+        {9, 0}, /*XLP_WD_IDX(1)			:	9 */
+        {19, 0}, /*XLP_WD_NMI_IDX(0)		:	10 */
+        {19, 0}, /*XLP_WD_NMI_IDX(1)		:	11 */
+        {10, 0}, /*XLP_TIMER_IDX(0)		:	12 */
+        {10, 0}, /*XLP_TIMER_IDX(1)		:	13 */
+        {10, 0}, /*XLP_TIMER_IDX(2)		:	14 */
+        {10, 0}, /*XLP_TIMER_IDX(3)		:	15 */
+        {10, 0}, /*XLP_TIMER_IDX(4)		:	16 */
+        {10, 0}, /*XLP_TIMER_IDX(5)		:	17 */
+        {10, 0}, /*XLP_TIMER_IDX(6)		:	18 */
+        {10, 0}, /*XLP_TIMER_IDX(7)		:	19 */
+        {59, 0}, /*XLP_MSGQ_IDX(0)		:	20 */
+        {59, 0}, /*XLP_MSGQ_IDX(1)		:	21 */
+        {59, 0}, /*XLP_MSGQ_IDX(2)		:	22 */
+        {59, 0}, /*XLP_MSGQ_IDX(3)		:	23 */
+        {59, 0}, /*XLP_MSGQ_IDX(4)		:	24 */
+        {59, 0}, /*XLP_MSGQ_IDX(5)		:	25 */
+        {59, 0}, /*XLP_MSGQ_IDX(6)		:	26 */
+        {59, 0}, /*XLP_MSGQ_IDX(7)		:	27 */
+        {59, 0}, /*XLP_MSGQ_IDX(8)		:	28 */
+        {59, 0}, /*XLP_MSGQ_IDX(9)		:	29 */
+        {59, 0}, /*XLP_MSGQ_IDX(10)		:	30 */
+        {59, 0}, /*XLP_MSGQ_IDX(11)		:	31 */
+        {59, 0}, /*XLP_MSGQ_IDX(12)		:	32 */
+        {59, 0}, /*XLP_MSGQ_IDX(13)		:	33 */
+        {59, 0}, /*XLP_MSGQ_IDX(14)		:	34 */
+        {59, 0}, /*XLP_MSGQ_IDX(15)		:	35 */
+        {59, 0}, /*XLP_MSGQ_IDX(16)		:	36 */
+        {59, 0}, /*XLP_MSGQ_IDX(17)		:	37 */
+        {59, 0}, /*XLP_MSGQ_IDX(18)		:	38 */
+        {59, 0}, /*XLP_MSGQ_IDX(19)		:	39 */
+        {59, 0}, /*XLP_MSGQ_IDX(20)		:	40 */
+        {59, 0}, /*XLP_MSGQ_IDX(21)		:	41 */
+        {59, 0}, /*XLP_MSGQ_IDX(22)		:	42 */
+        {59, 0}, /*XLP_MSGQ_IDX(23)		:	43 */
+        {59, 0}, /*XLP_MSGQ_IDX(24)		:	44 */
+        {59, 0}, /*XLP_MSGQ_IDX(25)		:	45 */
+        {59, 0}, /*XLP_MSGQ_IDX(26)		:	46 */
+        {59, 0}, /*XLP_MSGQ_IDX(27)		:	47 */
+        {59, 0}, /*XLP_MSGQ_IDX(28)		:	48 */
+        {59, 0}, /*XLP_MSGQ_IDX(29)		:	49 */
+        {59, 0}, /*XLP_MSGQ_IDX(30)		:	50 */
+        {59, 0}, /*XLP_MSGQ_IDX(31)		:	51 */
+        {49, 0}, /*XLP_MSG_IDX(0)		:	52 */
+        {48, 0}, /*XLP_MSG_IDX(1)		:	53 */
+        {32, 0}, /*XLP_PCIE_MSIX_IDX(0)		:	54 */
+        {32, 0}, /*XLP_PCIE_MSIX_IDX(1)		:	55 */
+        {32, 0}, /*XLP_PCIE_MSIX_IDX(2)		:	56 */
+        {32, 0}, /*XLP_PCIE_MSIX_IDX(3)		:	57 */
+        {32, 0}, /*XLP_PCIE_MSIX_IDX(4)		:	58 */
+        {32, 0}, /*XLP_PCIE_MSIX_IDX(5)		:	59 */
+        {32, 0}, /*XLP_PCIE_MSIX_IDX(6)		:	60 */
+        {32, 0}, /*XLP_PCIE_MSIX_IDX(7)		:	61 */
+        {33, 0}, /*XLP_PCIE_MSIX_IDX(8)		:	62 */
+        {33, 0}, /*XLP_PCIE_MSIX_IDX(9)		:	63 */
+        {33, 0}, /*XLP_PCIE_MSIX_IDX(10)	:	64 */
+        {33, 0}, /*XLP_PCIE_MSIX_IDX(11)	:	65 */
+        {33, 0}, /*XLP_PCIE_MSIX_IDX(12)	:	66 */
+        {33, 0}, /*XLP_PCIE_MSIX_IDX(13)	:	67 */
+        {33, 0}, /*XLP_PCIE_MSIX_IDX(14)	:	68 */
+        {33, 0}, /*XLP_PCIE_MSIX_IDX(15)	:	69 */
+        {34, 0}, /*XLP_PCIE_MSIX_IDX(16)	:	70 */
+        {34, 0}, /*XLP_PCIE_MSIX_IDX(17)	:	71 */
+        {34, 0}, /*XLP_PCIE_MSIX_IDX(18)	:	72 */
+        {34, 0}, /*XLP_PCIE_MSIX_IDX(19)	:	73 */
+        {34, 0}, /*XLP_PCIE_MSIX_IDX(20)	:	74 */
+        {34, 0}, /*XLP_PCIE_MSIX_IDX(21)	:	75 */
+        {34, 0}, /*XLP_PCIE_MSIX_IDX(22)	:	76 */
+        {34, 0}, /*XLP_PCIE_MSIX_IDX(23)	:	77 */
+        {35, 0}, /*XLP_PCIE_MSIX_IDX(24)	:	78 */
+        {35, 0}, /*XLP_PCIE_MSIX_IDX(25)	:	79 */
+        {35, 0}, /*XLP_PCIE_MSIX_IDX(26)	:	80 */
+        {35, 0}, /*XLP_PCIE_MSIX_IDX(27)	:	81 */
+        {35, 0}, /*XLP_PCIE_MSIX_IDX(28)	:	82 */
+        {35, 0}, /*XLP_PCIE_MSIX_IDX(29)	:	83 */
+        {35, 0}, /*XLP_PCIE_MSIX_IDX(30)	:	84 */
+        {35, 0}, /*XLP_PCIE_MSIX_IDX(31)	:	85 */
+        {41, 0}, /*XLP_PCIE_LINK_IRQ(0)		:	86 */
+        {42, 0}, /*XLP_PCIE_LINK_IRQ(1)		:	87 */
+        {43, 0}, /*XLP_PCIE_LINK_IRQ(2)		:	88 */
+        {44, 0}, /*XLP_PCIE_LINK_IRQ(3)		:	89 */
+        {58, 0}, /*XLP_NAE_IDX(0)		:	90 */
+        {58, 0}, /*XLP_NAE_IDX(1)		:	91 */
+        {58, 0}, /*XLP_NAE_IDX(2)		:	92 */
+        {58, 0}, /*XLP_NAE_IDX(3)		:	93 */
+        {58, 0}, /*XLP_NAE_IDX(4)		:	94 */
+        {58, 0}, /*XLP_NAE_IDX(5)		:	95 */
+        {58, 0}, /*XLP_NAE_IDX(6)		:	96 */
+        {58, 0}, /*XLP_NAE_IDX(7)		:	97 */
+        {58, 0}, /*XLP_NAE_IDX(8)		:	98 */
+        {58, 0}, /*XLP_NAE_IDX(9)		:	99 */
+        {58, 0}, /*XLP_NAE_IDX(10)		:	100 */
+        {58, 0}, /*XLP_NAE_IDX(11)		:	101 */
+        {58, 0}, /*XLP_NAE_IDX(12)		:	102 */
+        {58, 0}, /*XLP_NAE_IDX(13)		:	103 */
+        {58, 0}, /*XLP_NAE_IDX(14)		:	104 */
+        {58, 0}, /*XLP_NAE_IDX(15)		:	105 */
+        {58, 0}, /*XLP_NAE_IDX(16)		:	106 */
+        {58, 0}, /*XLP_NAE_IDX(17)		:	107 */
+        {58, 0}, /*XLP_NAE_IDX(18)		:	108 */
+        {58, 0}, /*XLP_NAE_IDX(19)		:	109 */
+        {58, 0}, /*XLP_NAE_IDX(20)		:	110 */
+        {58, 0}, /*XLP_NAE_IDX(21)		:	111 */
+        {58, 0}, /*XLP_NAE_IDX(22)		:	112 */
+        {58, 0}, /*XLP_NAE_IDX(23)		:	113 */
+        {58, 0}, /*XLP_NAE_IDX(24)		:	114 */
+        {58, 0}, /*XLP_NAE_IDX(25)		:	115 */
+        {58, 0}, /*XLP_NAE_IDX(26)		:	116 */
+        {58, 0}, /*XLP_NAE_IDX(27)		:	117 */
+        {58, 0}, /*XLP_NAE_IDX(28)		:	118 */
+        {58, 0}, /*XLP_NAE_IDX(29)		:	119 */
+        {58, 0}, /*XLP_NAE_IDX(30)		:	120 */
+        {58, 0}, /*XLP_NAE_IDX(31)		:	121 */
+        {60, 0}, /*XLP_POE_IDX			:	122 */
+        {24, 0}, /*XLP_USB_IDX(0)		:	123 */
+        {24, 0}, /*XLP_USB_IDX(1)		:	124 */
+        {24, 0}, /*XLP_USB_IDX(2)		:	125 */
+        {25, 0}, /*XLP_USB_IDX(3)		:	126 */
+        {25, 0}, /*XLP_USB_IDX(4)		:	127 */
+        {25, 0}, /*XLP_USB_IDX(5)		:	128 */
+        {61, 0}, /*XLP_GDX_IDX			:	129 */
+        {63, 0}, /*XLP_SEC_IDX			:	130 */
+        {62, 0}, /*XLP_RSA_IDX			:	131 */
+        {39, 0}, /*XLP_COMP_IDX(0)		:	132 */
+        {39, 0}, /*XLP_COMP_IDX(1)		:	133 */
+        {39, 0}, /*XLP_COMP_IDX(2)		:	134 */
+        {39, 0}, /*XLP_COMP_IDX(3)		:	135 */
+        {0, 0}, /*RESERVED_IDX			:	136 */
+        {37, 0}, /*XLP_ICC_IDX(0)		:	137  ICC - Inter Chip Coherency*/
+        {37, 0}, /*XLP_ICC_IDX(1)		:	138 */
+        {37, 0}, /*XLP_ICC_IDX(2)		:	139 */
+        {36, 0}, /*XLP_CAM_IDX			:	140 */
+        {17, 0}, /*XLP_UART_IDX(0)		:	141 */
+        {18, 0}, /*XLP_UART_IDX(0)		:	142 */
+        {11, 0}, /*XLP_I2C_IDX(0)		:	143 */
+        {11, 0}, /*XLP_I2C_IDX(0)		:	144 */
+        {12, 0}, /*XLP_SYS_IDX(0)		:	145 */
+        {12, 0}, /*XLP_SYS_IDX(1)		:	146 */
+        {55, 0}, /*XLP_JTAG_IDX			:	147 */
+        {50, 0}, /*XLP_PIC_IDX			:	148 */
+        {54, 0}, /*XLP_NBU_IDX			:	149 */
+        {53, 0}, /*XLP_TCU_IDX			:	150 */
+        {31, 0}, /*XLP_SATA			:	151 */
+        {38, 0}, /*XLP_DMC_IDX			:	152 */	/* collision */
+        {38, 0}, /*XLP_DMC_IDX			:	153 */
+        {13, 0}, /*XLP_GPIO_IDX(0)		:	154 */
+        {14, 0}, /*XLP_GPIO_IDX(1)		:	155 */
+        {15, 0}, /*XLP_GPIO_IDX(2)		:	156 */
+        {16, 0}, /*XLP_GPIO_IDX(3)		:	157 */
+        {20, 0}, /*XLP_NOR_IDX			:	158 */
+        {21, 0}, /*XLP_NAND_IDX			:	159 */
+        {22, 0}, /*XLP_SPI_IDX			:	160 */
+        {23, 0}, /*XLP_MMC_IDX			:	161 */
+        {0, 0}, /*			    162 */
+        {0, 0}, /*                          163 */
+        {0, 0}, /*                          164 */
+        {0, 0}, /*                          165 */
+        {0, 0}, /*                          166 */
+        {0, 0}, /*                          167 */
+};
+
+/*
+ * When startup function is called on an IRQ, that IRT's rvec map's bitmap
+ * would be set. This serves as a quick reverse lookup at the time of dispatch
+ */
+struct rvec_map_elem {
+	/* irt = elem.irt + ffs(bitmap), where bitmap != 0 */
+	int irt;	/* The first IRT corresponding to this rvec */
+	volatile unsigned long bitmap;	/* bit set is the offset from irt */
+};
+static struct rvec_map_elem rvec_map[XLP_EIRR_SIZE] = {
+	{-1, 0},			/* 0 */
+	{-1, 0},			/* 1 */
+	{-1, 0},			/* 2 */
+	{-1, 0},			/* 3 */
+	{-1, 0},			/* 4 */
+	{-1, 0},			/* 5 */
+	{-1, 0},			/* 6 */
+	{-1, 0},			/* 7 */
+	{-1, 0},			/* 8 */
+	{0, 0},				/* 9  Watchdog timer */
+	{4, 0},				/* 10 PIC Timter */
+	{135, 0},			/* 11 */
+	{137, 0},			/* 12 */
+	{146, 0},			/* 13 */
+	{147, 0},			/* 14 */
+	{148, 0},			/* 15 */
+	{149, 0},			/* 16 */
+	{133, 0},			/* 17 */
+	{134, 0},			/* 18 */
+	{2, 0},				/* 19 , Watchdog NMI */
+	{150, 0},			/* 20 */
+	{151, 0},			/* 21 */
+	{152, 0},			/* 22 */
+	{153, 0},			/* 23 */
+	{115, 0},			/* 24 */
+	{118, 0},			/* 25 */
+	{-1, 0},			/* 26 */
+	{-1, 0},			/* 27 */
+	{-1, 0},			/* 28 */
+	{-1, 0},			/* 29 */
+	{-1, 0},			/* 30 */
+	{143, 0},			/* 31 */
+	{46, 0},			/* 32  MSIX - FN(0)*/
+	{54, 0},			/* 33  MSIX - FN(1)*/
+	{62, 0},			/* 34  MSIX - FN(2)*/
+	{70, 0},			/* 35  MSIX - FN(3)*/
+	{132, 0},			/* 36 */
+	{129, 0},			/* 37 */
+	{144, 0},			/* 38 */
+	{124, 0},			/* 39 */
+	{-1, 0},			/* 40 */
+	{78, 0},			/* 41 */
+	{79, 0},			/* 42 */
+	{80, 0},			/* 43 */
+	{81, 0},			/* 44 */
+	{-1, 0},			/* 45 */
+	{-1, 0},			/* 46 */
+	{-1, 0},			/* 47 */
+	{45, 0},			/* 48 */
+	{44, 0},			/* 49 XLP_MSG_IDX*/
+	{140, 0},			/* 50 */
+	{-1, 0},			/* 51 */
+	{143, 0},			/* 52 */
+	{142, 0},			/* 53 */
+	{141, 0},			/* 54 */
+	{139, 0},			/* 55 */
+	{-1, 0},			/* 56 */
+	{-1, 0},			/* 57 */
+	{82, 0},			/* 58 */
+	{12, 0},			/* 59 , MSGQ*/
+	{114, 0},			/* 60 */
+	{121, 0},			/* 61 */
+	{123, 0},			/* 62 */
+	{122, 0},			/* 63 */
+};
+
+/*
+ * Set some eimr bits on each cpu
+ * This function will be called on each cpu by on_each_cpu()
+ * @bitmask	: bitmask to set in EIMR
+ */
+void xlp_set_eimr(void *param)
+{
+	u64 bitmask = (u64) param;
+	u64 eimr;
+
+	eimr = read_64bit_cp0_eimr();
+	eimr |= bitmask;
+	write_64bit_cp0_eimr(eimr);
+	return;
+}
+
+/*
+ * Clear some eimr bits on each cpu
+ * This function will be called on each cpu by on_each_cpu()
+ * @bitmask	: bitmask to clear in EIMR
+ */
+void xlp_clear_eimr(void *param)
+{
+	u64 bitmask = (u64) param;
+	u64 eimr = read_64bit_cp0_eimr();
+	eimr &= ~bitmask;
+	write_64bit_cp0_eimr(eimr);
+	return;
+}
 
-static void pic_unmask(unsigned int irq)
+void __xlp_setup_one_irq(u64 irq)
+{
+	int cpu;
+	preempt_disable();
+	cpu = smp_processor_id();
+	__nlm_hal_set_irt_to_cpu(xlp_irq_to_irt(irq), cpu);
+	preempt_enable();
+}
+
+/*
+ * Returns the base IRQ (index of irq_map) from an rvec
+ */
+static inline int __irqbase_from_rvec(int rvec)
+{
+	int irt;
+
+	irt = rvec_map[rvec].irt;
+	if (irt < 0) {
+		return -EINVAL;
+	}
+	return(irt + XLP_IRQ_RESERVED_MAX);
+}
+
+
+/*
+ * Returns the base IRQ from an rvec
+ */
+static inline int irqbase_from_rvec(int rvec)
 {
-	pic_reg_t *mmio = nlm_hal_pic_offset();
+	int ret;
 	unsigned long flags;
-	nlm_reg_t reg;
-	unsigned long irt;
 
-	if(irq < 8) {
+	spin_lock_irqsave(&xlp_pic_lock, flags);
+	ret = __irqbase_from_rvec(rvec);
+	spin_unlock_irqrestore(&xlp_pic_lock, flags);
+	return ret;
+}
+
+/*
+ * returns rvec from an IRQ entry
+ * An IRQ entry is (irt table index + reserved max)
+ *
+ * @irq : irq number
+ */
+int xlp_rvec_from_irq(int irq)
+{
+	if ((irq < XLP_IRQ_RESERVED_MAX) || (irq >= XLP_IRQ_MAX)) {
+		return -EINVAL;
+	}
+	return(irq_map[irq].rvec);
+}
+EXPORT_SYMBOL(xlp_rvec_from_irq);
+
+/*
+ * Masks out one IRQ in the EIMR register
+ * Must NOT be called with xlp_pic_lock held
+ * @irq : IRQ number
+ */
+static void __nlm_irq_mask(unsigned int irq)
+{
+	int rvec;
+
+	rvec = xlp_rvec_from_irq(irq);
+	if (rvec < 0) {
 		return;
 	}
-	irt = find_irt_from_irq(irq);
-	if(irt == -1)
-	{
-		printk("can't find irt for irq: %d\n",irq);
+	if (read_64bit_cp0_eimr() & (1ULL << rvec)) {
+		/* We do not clear eimr, this is a TODO for later time */
+		//on_each_cpu(xlp_clear_eimr, (void *) (1ULL << rvec), 1);
+	}
+	return;
+}
+
+/*
+ * Interface function (unlocked version) to mask an IRQ
+ * Calls helper function after input tests and spin_lock holds
+ *
+ * @irq : IRQ number
+ */
+static void nlm_intx_mask(unsigned int irq)
+{
+	//unsigned long flags;
+
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
+		return;
+	} else if(irq >= XLP_IRQ_MAX) {
+		pr_err("irq = %d. Invalid irq requested\n", irq);
 		return;
 	}
+	// Once enabled, we don't mask it out
+	//spin_lock_irqsave(&xlp_pic_lock, flags);	// Remove XXX
+	__nlm_irq_mask(irq);				// XXX
+	//spin_unlock_irqrestore(&xlp_pic_lock, flags);	// XXX remove
+	return;
+}
+
+/*
+ * Changes eimr bit value corresponding to IRT
+ * @irq : IRQ number
+ */
+static int __nlm_irq_unmask(int irq)
+{
+	int ret = 0;
+	int rvec = xlp_rvec_from_irq(irq);
+
+	if (rvec < 0)
+		return ret;
+
+	ret = __nlm_hal_request_irq(xlp_irq_to_irt(irq) , rvec);
+	if (ret != 0) {
+		printk(KERN_WARNING "Failed to setup IRQ %d\n", irq);
+		return ret;
+	}
 
-	spin_lock_irqsave(&nlm_common_pic_lock, flags);
+	if (((1ULL << rvec) & read_64bit_cp0_eimr()) == 0) {
+		/* This is only for those interrupts which are not statically
+		 * set in EIMR. Could dump stack if spin lock held */
+		 on_each_cpu(xlp_set_eimr, (void *) (1ULL << rvec), 1);
+	}
+	return ret;
+}
 
-	/* What happens if this irq was previously not ack'ed? 
-	 * Assume, that doesn't happen?
-	 */
-	reg = nlm_hal_read_pic_reg(mmio, PIC_IRT(irt));
-	/* By default all the interrupts are initialized as level senstive - fix for the PCMCIA flash */
-	nlm_hal_write_pic_reg(mmio, PIC_IRT(nlm_hal_irq_to_irt(irq)),
-		      reg | (1 << 28) | (1 << 31));
+/*
+ * Interface function (unlocked version) to mask an IRQ
+ * Calls helper function after input tests and spin_lock holds
+ *
+ * @irq : IRQ number
+ */
+static void nlm_intx_unmask(unsigned int irq)
+{
+	unsigned long flags;
+
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
+		return;
+	} else if(irq >= XLP_IRQ_MAX) {
+		pr_err("irq = %d. Invalid irq requested\n", irq);
+		return;
+	}
 
-	spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+	spin_lock_irqsave(&xlp_pic_lock, flags);
+	__nlm_irq_unmask(irq);
+	spin_unlock_irqrestore(&xlp_pic_lock, flags);
 
 	return;
 }
 
-static void pic_ack(unsigned int irq)
+static void nlm_irq_ack(unsigned int irq)
 {
 	unsigned long flags;
-	unsigned long irt;
-	/*uint64_t val;*/
 
-
-	if(irq < 8) {
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
 		return;
-	}
-	irt = find_irt_from_irq(irq);
-	if(irt == -1)
-	{
-		printk("can't find irt for irq: %d\n",irq);
+	} else if(irq >= XLP_IRQ_MAX) {
+		pr_err("irq = %d. Invalid irq requested\n", irq);
 		return;
 	}
-	/* If edge triggered IRQ, ack it immediately, else when the device
-	 * interrupt condition is cleared, we may lose interrupts 
-	 */
-	if (PIC_IRQ_IS_EDGE_TRIGGERED(irq)) {
-		spin_lock_irqsave(&nlm_common_pic_lock, flags);
-		nlm_hal_ack_pic(irt);
-		spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+	/* If edge triggered, ack it ASAP. Handle the interrupt later */
+	if (PIC_IRQ_IS_EDGE_TRIGGERED(xlp_irq_to_irt(irq))) {
+		spin_lock_irqsave(&xlp_pic_lock, flags);
+#ifndef CONFIG_NUMA
+		nlm_hal_ack_pic(xlp_irq_to_irt(irq));
+#else
+		xlp_numa_ack_pic(xlp_irq_to_irt(irq));
+#endif
+		spin_unlock_irqrestore(&xlp_pic_lock, flags);
 	}
 }
 
-static void pic_end(unsigned int irq)
+static void nlm_irq_end(unsigned int irq)
 {
 	unsigned long flags;
-	unsigned long irt;
-	/*uint64_t val;*/
 
-	if(irq < 8) {
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
 		return;
-	}
-	irt = find_irt_from_irq(irq);
-	if(irt == -1)
-	{
-		printk("can't find irt for irq: %d\n",irq);
+	} else if(irq >= XLP_IRQ_MAX) {
+		pr_err("irq = %d. Invalid irq requested\n", irq);
 		return;
 	}
 	/* If level triggered, ack it after the device condition is cleared */
-	if (!PIC_IRQ_IS_EDGE_TRIGGERED(irq)) {
-		spin_lock_irqsave(&nlm_common_pic_lock, flags);
-		nlm_hal_ack_pic(nlm_hal_irq_to_irt(irq));
-		spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+	if (!PIC_IRQ_IS_EDGE_TRIGGERED(xlp_irq_to_irt(irq))) {
+		spin_lock_irqsave(&xlp_pic_lock, flags);
+#ifndef CONFIG_NUMA
+		nlm_hal_ack_pic(xlp_irq_to_irt(irq));
+#else
+		xlp_numa_ack_pic(xlp_irq_to_irt(irq));
+#endif
+		spin_unlock_irqrestore(&xlp_pic_lock, flags);
+	}
+	return;
+}
+
+/*
+ * Startup function for any IRQ
+ * @irq: irq number
+ *
+ * This function is called as chip->startup() for all IRQs.
+ * In case of XLP, all normal interrupts must fall below XLP_MSI_IRQ_OFFSET
+ * When an interrupt is started, we force it to be enabled only in cpu0, it can
+ * be changed later by calling nlm_irq_set_affinity()
+ */
+static unsigned int nlm_irq_startup(unsigned int irq)
+{
+	__label__ __failure;
+	int ret = 0;
+	unsigned long flags;
+	int idx, rvec;
+	struct cpumask m;
+	struct cpumask const *n;
+
+	cpumask_clear(&m);
+	cpumask_set_cpu(0, &m);
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
+		return 0;
+	} else if(irq >= XLP_IRQ_MAX) {
+		return 0;
+	}
+	n = xlp_closest_match_cpumask(&m);
+	spin_lock_irqsave(&xlp_pic_lock, flags);
+	rvec = xlp_rvec_from_irq(irq);
+	if (irq_map[irq].usage == 0) {
+		/* Currently unused => not enabled. So, setup and enable */
+		xlp_set_cpumask(n, xlp_irq_to_irt(irq));
+		idx = irq - __irqbase_from_rvec(rvec);
+		set_bit(idx, &(rvec_map[rvec].bitmap));
+		irq_map[irq].usage++;
+		/* At this point, make sure that each CPU has eimr bit
+		 * corresponding to this IRQ set. Later the driver can set
+		 * the cpu affinity of this interrupt. The rationale for
+		 * setting up EIMR here is that it can be moved to any CPUs
+		 * (well, a subset of any CPUs) later
+		 */
+		ret = __nlm_irq_unmask(irq);
+	} else if (irq_map[irq].usage > 0) {
+		/* already being used. No need to check mask
+		 * if masked, will be unmasked later
+		 */
+		irq_map[irq].usage++;
+		ret = 0;
+	} else {
+		pr_err("Error irq = %d, rvec = %d, usage count %d\n", irq,
+				irq_map[irq].rvec, irq_map[irq].usage);
+		ret = -EFAULT;
 	}
+__failure:
+	spin_unlock_irqrestore(&xlp_pic_lock, flags);
+	return ret;
 }
 
-static void pic_shutdown(unsigned int irq)
+/*
+ * Startup functionf or regular interrupts
+ */
+static unsigned int nlm_intx_startup(unsigned int irq)
+{
+	int fn, ret;
+	/* if this irq correspond to any of the pci slots, enable intx on
+	 * the controller */
+	if ((irq >= XLP_PCIE_LINK_IRQ(0)) && (irq <= XLP_PCIE_LINK_IRQ(3))) {
+		fn = XLP_INTX_TO_CTRL_FN(irq);
+		if ((ret = xlp_intx_enable(fn)) < 0) {
+			return (unsigned int)ret;
+		}
+	}
+	return nlm_irq_startup(irq);
+}
+
+/*
+ * IRQ shut down function
+ * Disables one IRQ
+ *
+ * @irq : irq to shut down
+ *
+ * This function is called whenever release_irq() is called by means of
+ * chip->shutdown(). In this function, the rvec bit in every EIMR is cleared if
+ * usage falls to zero (in case of shared interrupts)
+ */
+static void nlm_irq_shutdown(unsigned int irq)
 {
-	pic_reg_t *mmio = nlm_hal_pic_offset();
 	unsigned long flags;
-	nlm_reg_t reg;
-	unsigned long irt;
+	int idx, rvec;
 
-	if(irq < 8) {
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
+		return;
+	} else if(irq >= XLP_IRQ_MAX) {
+		pr_err("irq = %d. Invalid irq requested\n", irq);
 		return;
 	}
-	irt = find_irt_from_irq(irq);
-	if(irt == -1)
-	{
-		printk("can't find irt for irq: %d\n",irq);
+	spin_lock_irqsave(&xlp_pic_lock, flags);
+	if (irq_map[irq].usage == 0) {
+		//fdebug("irq = %d, usage = %d\n", irq, irq_map[irq].usage);
+		spin_unlock_irqrestore(&xlp_pic_lock, flags);
 		return;
+	} else if (irq_map[irq].usage > 0) {
+		irq_map[irq].usage--;
 	}
+	/* If the usage reaches zero as a result of above subtraction,
+	 * free up the rvec */
+	if (irq_map[irq].usage == 0) {
+		//fdebug("irq = %d, usage = %d\n", irq, irq_map[irq].usage);
+		rvec = xlp_rvec_from_irq(irq);
+		idx = irq - __irqbase_from_rvec(rvec);
+		clear_bit(idx, &(rvec_map[rvec].bitmap));
+		spin_unlock_irqrestore(&xlp_pic_lock, flags);
+		__nlm_irq_mask(irq); /* masks this IRQ */
+	} else {
+		spin_unlock_irqrestore(&xlp_pic_lock, flags);
+	}
+	return;
+}
 
-	spin_lock_irqsave(&nlm_common_pic_lock, flags);
-
-	/* What happens if this irq is currently pending an ack? 
-	 * Assume, that doesn't happen?
-	 */
-	reg = nlm_hal_read_pic_reg(mmio, PIC_IRT(irt));
-	nlm_hal_write_pic_reg(mmio, PIC_IRT(irt), (reg & ~(1 << 31)));
 
-	spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+/*
+ * Shutdown function for intx
+ */
+static void nlm_intx_shutdown(unsigned int irq)
+{
+	int fn, ret;
+	/* if this irq correspond to any of the pci slots, disable intx on
+	 * the controller  before shutting it down */
+	if ((irq >= XLP_PCIE_LINK_IRQ(0)) && (irq <= XLP_PCIE_LINK_IRQ(3))) {
+		fn = XLP_INTX_TO_CTRL_FN(irq);
+		if ((ret = xlp_intx_disable(fn)) < 0) {
+			return;
+		}
+	}
+	return nlm_irq_shutdown(irq);
 }
-
 /*
  * Set affinity for the irq for chips
- * 
+ *
+ * When an interrupt is setup, its EIMR bit is set in all online cpus. That is,
+ * any cpu _can_ receive that interrupt. But it is the IRT entry that decides
+ * whether to send that interrupt (i.e, whether to set EIRR bit or not) to any
+ * particular CPU.
+ *
+ * IRT has two modes to decide the target CPUs for one interrupt.
+ * Method 1 : Using IRT table entry bits DT and DTE
+ * If DT==1, this interrupt can be routed to a max of 16 CPUs (well, hw threads)
+ * If DT==1, there is one more level of indirection called DTE. Each DTE entry
+ * has 128 bits and there are a total of 8 DTE entries. Each DTE entry contains
+ * the bitmask of target CPU for an interrupt. One of them is chosen based
+ * on the specified cpumask.
+ *
+ * The actual bitmask can be different from the specified bitmask based
+ * on the logic of xlp_closest_match_cpumask()
  */
-
-static int pic_set_affinity(unsigned int irq, const cpumask_t *mask)
+extern cpumask_t fdt_cpumask;
+static int nlm_irq_set_affinity(unsigned int irq, const struct cpumask *mask)
 {
 	unsigned long flags;
-	int cpu;
-
-	spin_lock_irqsave(&nlm_common_pic_lock, flags);
-	for_each_online_cpu(cpu){
-		if(cpumask_test_cpu(cpu, mask))
-		{
-			nlm_hal_set_irq_to_cpu(irq, cpu);
-		}
+	const struct cpumask *m;
+	struct cpumask n;
+
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
+		return 0;
+	} else if(irq >= XLP_IRQ_MAX) {
+		pr_err("irq = %d. Invalid irq requested\n", irq);
+		return -EINVAL;
 	}
-	spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+	/* We need present physical cpu mask. cpu_online_mask is logical, so
+	 * we can't use that. In XLP, hot pluggable CPUs are not
+	 * supported on rel 2.2.2 timeframe. So, we can use fdt_cpumask till
+	 * CPU Hotplugging gets implemented TODO CPU_HOTPLUG */
+#ifdef CONFIG_NUMA
+{
+	int i;
 
+	/* Interrupts are to be delivered locally */
+	cpumask_clear(&n);
+        for (i = 0; i < 32; i++) {
+                cpumask_set_cpu(i, &n);
+        }
+	cpumask_and(&n, &n, &fdt_cpumask);
+	cpumask_and(&n, mask, &n);
+}
+#else
+	cpumask_and(&n, mask, &fdt_cpumask);
+#endif
+	m = xlp_closest_match_cpumask(&n);
+	if (m == NULL) {
+		printk(KERN_WARNING "Could not find a match for specified cpumask\n");
+		return -EINVAL;
+	}
+	spin_lock_irqsave(&xlp_pic_lock, flags);
+	xlp_set_cpumask(m, xlp_irq_to_irt(irq));
+	spin_unlock_irqrestore(&xlp_pic_lock, flags);
 	return 0;
 }
 
-static struct irq_chip nlm_common_pic = {
+static struct irq_chip nlm_irq_pic = {
 	.name = "XLP-PIC",
-	.unmask = pic_unmask,
-	.mask = pic_shutdown,
-	.ack = pic_ack,
-	.end = pic_end,
-	.set_affinity = pic_set_affinity
+	.mask = nlm_intx_mask,
+	.unmask = nlm_intx_unmask,
+	.startup = nlm_intx_startup,
+	.shutdown = nlm_intx_shutdown,
+	.ack = nlm_irq_ack,
+	.end = nlm_irq_end,
+	.set_affinity = nlm_irq_set_affinity
 };
 
 static void rsvd_pic_handler_1_1(unsigned int irq)
 {
-	if(irq < PIC_IRQ_BASE)
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
+		return;
+	} else if(irq >= XLP_IRQ_MAX) {
+		pr_err("irq = %d. Invalid irq requested\n", irq);
 		return;
-  dbg_msg("Requesting a reserved irq (%d)??", irq);
-  return;
+	}
+	pr_err("Requesting a reserved irq (%d)??", irq);
+	return;
 }
 
 static void rsvd_pic_handler_1(unsigned int irq)
 {
-	if(irq < PIC_IRQ_BASE)
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
+		return;
+	} else if(irq >= XLP_IRQ_MAX) {
+		pr_err("irq = %d. Invalid irq requested\n", irq);
 		return;
-  dbg_msg("handler called for a reserved irq (%d)\n", irq);
+	}
+	pr_err("Requesting a reserved irq (%d)??", irq);
+	return;
 }
 
 static int rsvd_pic_handler_2(unsigned int irq, const struct cpumask *mask)
 {
-	if(irq < PIC_IRQ_BASE)
-		return -1;
-
-	dbg_msg("handler called for a reserved irq (%d)\n", irq);
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
+		return 0;
+	} else if(irq >= XLP_IRQ_MAX) {
+		pr_err("irq = %d. Invalid irq requested\n", irq);
+		return -EINVAL;
+	}
+	pr_err("Requesting a reserved irq (%d)??", irq);
 	return 0;
 }
 
-struct irq_chip nlm_rsvd_pic_irq_timer = {
-        .name = "Count-Compare",
-        .unmask = rsvd_pic_handler_1_1,
-        .mask = rsvd_pic_handler_1,
-        .ack = rsvd_pic_handler_1,
-        .end = rsvd_pic_handler_1,
-        .set_affinity = rsvd_pic_handler_2
-};
-
-struct irq_chip nlm_rsvd_pic_irq_oprofile = {
-        .name = "Oprofile",
-        .unmask = rsvd_pic_handler_1_1,
-        .mask = rsvd_pic_handler_1,
-        .ack = rsvd_pic_handler_1,
-        .end = rsvd_pic_handler_1,
-        .set_affinity = rsvd_pic_handler_2
-};
-
 struct irq_chip nlm_common_rsvd_pic = {
 	.name = "Netlogic-RSVD-PIC",
 	.unmask = rsvd_pic_handler_1_1,
@@ -257,10 +888,17 @@ struct irq_chip nlm_common_rsvd_pic = {
 
 static irqreturn_t nlm_common_rsvd_irq_handler(int irq, void *dev_id)
 {
-	if(irq == IRQ_TIMER) 
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
+		return 0;
+	} else if(irq >= XLP_IRQ_MAX) {
+		pr_err("irq = %d. Invalid irq requested\n", irq);
+		return -EINVAL;
+	}
+	if(irq == XLP_IRQ_TIMER) {
 		return IRQ_HANDLED;
-  dbg_msg("handler for reserved irq %d\n", irq);
-  return IRQ_NONE;
+	}
+	pr_err("Requesting a reserved irq (%d)??", irq);
+	return IRQ_NONE;
 }
 
 struct irqaction nlm_common_rsvd_action = {
@@ -271,163 +909,793 @@ struct irqaction nlm_common_rsvd_action = {
 	.next = 0
 };
 
-struct irqaction msgring_action = {
-	.handler = nlm_common_rsvd_irq_handler,
-	.name = "msgring",
-};
+void do_nlm_common_IRQ(unsigned int irq, struct pt_regs *regs)
+{
+	if (irq == XLP_IRQ_IPI_SMP_FUNCTION || irq == XLP_IRQ_IPI_SMP_RESCHEDULE) {
+		nlm_common_ipi_handler(irq, regs);
+		return;
+	}
+	if (irq == XLP_IRQ_MSGRING) {
+		nlm_xlp_msgring_int_handler(irq, regs);
+	}
+	else if (irq == XLP_IRQ_IPI_SMP_KGDB) {
+		/* ignore now */
+	}
+	else {
+		do_IRQ(irq);
+	}
+}
 
-struct irqaction ipi_smp_func_action = {
-	.handler = nlm_common_rsvd_irq_handler,
-	.name = "ipi_smp_func",
-};
+/* Unused function? Remove later */
+void __cpuinit nlm_smp_irq_init(void)
+{
+#ifdef XLP_MERGE_TODO
+	/* Set up kseg0 to be cachable coherent */
+	change_c0_config(CONF_CM_CMASK, CONF_CM_DEFAULT);
+#endif
+	write_64bit_cp0_eimr(xlp_irq_mask);
+}
 
-struct irqaction ipi_smp_resched_action = {
-	.handler = nlm_common_rsvd_irq_handler,
-	.name = "ipi_smp_resched",
-};
+void destroy_irq(unsigned int irq)
+{
+    /* no-op */
+}
 
-extern nlm_common_atomic_t msgring_registered;
+#ifdef CONFIG_PCI_MSI
 
-void    
-handle_msgring_irq(unsigned int irq, struct irq_desc *desc)
+/*
+ * The MSI and MSI-X functionality is supported only by the PCIe Controller.
+ * Whenever there is a request for MSI/MSI-X, we need to find out the
+ * controller on which that request is made. But in the PCI structure, I could
+ * not find a place where that information can be kept. Moreover, a hack job
+ * is not justified for the reason that only a small subset of PCI devices
+ * (no onboard ones) require this. So, we have the file arch/mips/pci/pci-xlp.c
+ * for XLP specific functionality.
+ *
+ * In case of MSI, we have to share one interrupt (XLP_PCIE_LINK_IRQ(x)) for
+ * for 32 possible MSI on a slot.
+ * We work around this problem by limiting the #of MSI per slot to
+ * XLP_MSI_PER_SLOT. MSI IRQ vectors start from XLP_MSI_IRQ_OFFSET.
+ * plat_irq_dispatch checks the vector number and dispatch it correctly.
+ *
+ * These bunch of functions would find out the controller function using the
+ * passed parameter and use nlm_irq_* function to operate on that IRT
+ */
+static unsigned int nlm_msi_startup(unsigned int msi)
 {
-	kstat_incr_irqs_this_cpu(irq, desc);
+	int bit, irq, fn, base_msi, ret;
 
-	nlm_xlp_msgring_int_handler(irq, NULL);
+	if ((msi < XLP_MSI_INDEX_START) || (msi > XLP_MSI_INDEX_END)){
+		return -EINVAL;
+	}
+	fn = XLP_MSI_TO_CTRL_FN(msi);
+	irq = XLP_PCIE_LINK_IRQ(XLP_MSI_TO_CTRL_FN(msi));	/* actual irq line (irt + max reserved) */
+	base_msi = XLP_MSI_IRQ_START(fn);
+	bit = msi - base_msi;
+	if ((ret = xlp_msi_enable(fn, bit)) < 0) {
+		return ret;
+	}
+	/* unmask MSI in the device */
+	unmask_msi_irq(msi);
+	return nlm_irq_startup(irq);
 }
 
-void handle_ipi_irq(unsigned int irq, struct irq_desc *desc)
+static int nlm_msi_set_affinity(unsigned int msi, const struct cpumask *mask)
 {
-	kstat_incr_irqs_this_cpu(irq, desc);
+	struct cpumask m;
+	if ((msi < XLP_MSI_INDEX_START) || (msi > XLP_MSI_INDEX_END)){
+		return -EINVAL;
+	}
 
-	if (irq == IRQ_IPI_SMP_FUNCTION)
-		smp_call_function_interrupt();
-	else if (irq == IRQ_IPI_SMP_RESCHEDULE) /* for reschduling */
-		set_need_resched();
+	cpumask_and(&m, mask, cpu_online_mask);
+	if (cpumask_equal(&m, cpu_online_mask)){
+		return nlm_irq_set_affinity(XLP_PCIE_LINK_IRQ(XLP_MSI_TO_CTRL_FN(msi)), &m);
+	} else {
+		printk(KERN_WARNING "MSI cpu affinity change not supported\n");
+		return -EINVAL;
+	}
 }
 
-void __init init_nlm_common_irqs(void)
+static void nlm_msi_shutdown(unsigned int msi)
 {
-	int i;
+	int bit, irq, fn, base_msi;
+
+	/* mask MSI in the device */
+	mask_msi_irq(msi);
+	fn = XLP_MSI_TO_CTRL_FN(msi);
+	irq = XLP_PCIE_LINK_IRQ(XLP_MSI_TO_CTRL_FN(msi));	/* actual irq line (irt + max reserved) */
+	base_msi = XLP_MSI_IRQ_START(fn);
+	bit = msi - base_msi;
+	if ((msi < XLP_MSI_INDEX_START) || (msi > XLP_MSI_INDEX_END)){
+		return;
+	}
+	if (xlp_msi_disable(fn, bit) < 0) {
+		return;
+	}
+	return nlm_irq_shutdown(irq);
+}
 
-	for (i = 0; i < NR_IRQS; i++) {
-		set_irq_chip_and_handler(i, &nlm_common_pic, handle_level_irq);
+static void nlm_msi_end(unsigned int msi)
+{
+	if ((msi < XLP_MSI_INDEX_START) || (msi > XLP_MSI_INDEX_END)){
+		return;
 	}
+	return nlm_irq_end(XLP_PCIE_LINK_IRQ(XLP_MSI_TO_CTRL_FN(msi)));
+}
 
-#ifdef CONFIG_REMOTE_DEBUG
-	irq_desc[IRQ_REMOTE_DEBUG].chip = &nlm_common_rsvd_pic;
-	irq_desc[IRQ_REMOTE_DEBUG].action = nlm_common_rsvd_action;
-	nlm_xlp_irq_mask |= (1ULL << IRQ_REMOTE_DEBUG);
-#endif
 
-#ifdef CONFIG_SMP
-	irq_desc[IRQ_IPI_SMP_FUNCTION].chip = &nlm_common_rsvd_pic;
-	irq_desc[IRQ_IPI_SMP_FUNCTION].action = &ipi_smp_func_action;
-	set_irq_handler(IRQ_IPI_SMP_FUNCTION, handle_ipi_irq);
+static void nlm_msi_ack(unsigned int msi)
+{
+	if ((msi < XLP_MSI_INDEX_START) || (msi > XLP_MSI_INDEX_END)){
+		return;
+	}
+	return nlm_irq_ack(XLP_PCIE_LINK_IRQ(XLP_MSI_TO_CTRL_FN(msi)));
+}
 
-	irq_desc[IRQ_IPI_SMP_RESCHEDULE].chip = &nlm_common_rsvd_pic;
-	irq_desc[IRQ_IPI_SMP_RESCHEDULE].action = &ipi_smp_resched_action;
-	set_irq_handler(IRQ_IPI_SMP_RESCHEDULE, handle_ipi_irq);
+/*
+ * Masks just one MSI
+ * @msi : the MSI to mask
+ */
 
-	nlm_xlp_irq_mask |=
-	    ((1ULL << IRQ_IPI_SMP_FUNCTION) | (1ULL << IRQ_IPI_SMP_RESCHEDULE));
-#endif
+static u32 nlm_msi_change_mask(unsigned int msi, int val)
+{
+	unsigned long flags;
+	int bit, fn;
+	u32 mask;
+
+	fn = XLP_MSI_TO_CTRL_FN(msi);
+	bit = msi - XLP_MSI_IRQ_START(fn);
+	spin_lock_irqsave(&xlp_pic_lock, flags);
+	mask = xlp_msi_set_mask(fn, bit, val);
+	if (val == 0) {
+		if (mask == 0) { /* This was the last bit to clear */
+			__nlm_irq_mask(XLP_PCIE_LINK_IRQ(XLP_MSI_TO_CTRL_FN(msi)));
+		}
+		if ((mask & (mask - 1)) == 0) {	/* Just set the only bit*/
+			__nlm_irq_unmask(XLP_PCIE_LINK_IRQ(XLP_MSI_TO_CTRL_FN(msi)));
+		}
+	}
+	spin_unlock_irqrestore(&xlp_pic_lock, flags);
+	return mask;
+}
 
-	/* msgring interrupt */
-	irq_desc[IRQ_MSGRING].chip = &nlm_common_rsvd_pic;
-	irq_desc[IRQ_MSGRING].action = &msgring_action;
-	set_irq_handler(IRQ_MSGRING, handle_msgring_irq);
-	nlm_xlp_irq_mask |= (1ULL << IRQ_MSGRING);
+/*
+ * Mask just one MSI
+ * The corresponding IRT will also be masked
+ */
+static void nlm_msi_mask(unsigned int msi)
+{
+	if ((msi < XLP_MSI_INDEX_START) || (msi > XLP_MSI_INDEX_END)){
+		return ;
+	}
+	/* mask MSI in the device */
+	mask_msi_irq(msi);
+	/* This is the h/w specific per vector masking function
+	 * We can't use the standard function because we don't support
+	 * it in the capability structure */
+	nlm_msi_change_mask(msi, 0);
+	return;
+}
 
-	/* unmask all PIC related interrupts. If no handler is installed by the 
-	 * drivers, it'll just ack the interrupt and return 
-	 */
-	for (i = PIC_IRT_FIRST_IRQ; i <= PIC_IRT_LAST_IRQ(); i++)
-		nlm_xlp_irq_mask |= (1ULL << i);
+/*
+ * Unmask just one MSI
+ * The corresponding IRT will also be unmasked
+ */
+static void nlm_msi_unmask(unsigned int msi)
+{
+	if ((msi < XLP_MSI_INDEX_START) || (msi > XLP_MSI_INDEX_END)){
+		return ;
+	}
+	/* unmask MSI in the device */
+	unmask_msi_irq(msi);
+	nlm_msi_change_mask(msi, 1);
+	return;
+}
 
-#ifdef CONFIG_KGDB
-	nlm_xlp_irq_mask |= (1ULL << IRQ_IPI_SMP_KGDB);
-#endif
+/*
+ * MSI hook-up routines for Netlogic Boards;
+ * Arch-dependent implementation called
+ * from generic msi.c routines.
+ */
+
+struct irq_chip nlm_msi_pic = {
+	.name = "XLP-PIC-MSI",
+	.startup = nlm_msi_startup,
+	.shutdown = nlm_msi_shutdown,
+	.ack = nlm_msi_ack,
+	.end = nlm_msi_end,
+	.mask = nlm_msi_mask,
+	.unmask = nlm_msi_unmask,
+	.set_affinity = nlm_msi_set_affinity
+};
+
+/*
+ * These functions would find out the controller function using the
+ * passed parameter and use nlm_irq_* function to operate on that IRT
+ */
 
-	irq_desc[IRQ_TIMER].chip = &nlm_rsvd_pic_irq_timer;
-	irq_desc[IRQ_TIMER].action = NULL;
-	nlm_xlp_irq_mask |= (1ULL << IRQ_TIMER);
+static int nlm_msix_set_affinity(unsigned int msix, const struct cpumask *mask)
+{
+	if ((msix < XLP_MSIX_INDEX_START) || (msix > XLP_MSIX_INDEX_END)){
+		return -EINVAL;
+	}
+	return nlm_irq_set_affinity(XLP_PCIE_MSIX_IRQ(msix - XLP_MSIX_INDEX_START), mask);
 }
 
-void __cpuinit nlm_smp_irq_init(void)
+static void nlm_msix_end(unsigned int msix)
 {
-#ifdef XLP_MERGE_TODO
-	/* Set up kseg0 to be cachable coherent */
-	change_c0_config(CONF_CM_CMASK, CONF_CM_DEFAULT);
-#endif
-	/* clear all pending interrupts (don't touch timer and soft,
-	 * they're special) */
-	write_64bit_cp0_eirr(0xffffffffffffff7c);
+	if ((msix < XLP_MSIX_INDEX_START) || (msix > XLP_MSIX_INDEX_END)){
+		return;
+	}
+	return nlm_irq_end(XLP_PCIE_MSIX_IRQ(msix - XLP_MSIX_INDEX_START));
+}
 
-	/* set interrupt mask for non-zero cpus */
-	write_64bit_cp0_eimr(nlm_xlp_irq_mask | (1 << IRQ_TIMER));
+static void nlm_msix_ack(unsigned int msix)
+{
+	if ((msix < XLP_MSIX_INDEX_START) || (msix > XLP_MSIX_INDEX_END)){
+		return;
+	}
+	return nlm_irq_ack(XLP_PCIE_MSIX_IRQ(msix - XLP_MSIX_INDEX_START));
 }
 
-void __init arch_init_irq(void)
+/*
+ * Masks just one MSIX
+ * @msix : the MSIX to mask
+ *
+ * MSI-X masking is different from MSI masking (msi->temporarily disable
+ * in the h/w. That is an XLP oddity.
+ * MSI-X has masking as a standard feature
+ */
+static void nlm_msix_mask(unsigned int msix)
 {
-#ifdef CONFIG_KGDB
-	if (kgdb_early_setup)
+	unsigned long flags;
+	if ((msix < XLP_MSIX_INDEX_START) || (msix > XLP_MSIX_INDEX_END)){
+		return ;
+	}
+	spin_lock_irqsave(&xlp_pic_lock, flags);
+	mask_msi_irq(msix); /* This function masks MSI-X -- please note */
+	__nlm_irq_mask(XLP_PCIE_MSIX_IRQ(msix - XLP_MSIX_INDEX_START));
+	spin_unlock_irqrestore(&xlp_pic_lock, flags);
+	return;
+}
+
+/*
+ * Unmask just one MSIX
+ * If required, unmask the corresponding IRT as well
+ */
+static void nlm_msix_unmask(unsigned int msix)
+{
+	unsigned long flags;
+	if ((msix < XLP_MSIX_INDEX_START) || (msix > XLP_MSIX_INDEX_END)){
+		return ;
+	}
+	spin_lock_irqsave(&xlp_pic_lock, flags);
+	__nlm_irq_mask(XLP_PCIE_MSIX_IRQ(msix - XLP_MSIX_INDEX_START));
+	unmask_msi_irq(msix); /* Enable MSI-X -- please note */
+	spin_unlock_irqrestore(&xlp_pic_lock, flags);
+	return;
+}
+
+static unsigned int nlm_msix_startup(unsigned int msix)
+{
+	int fn = XLP_MSIX_TO_CTRL_FN(msix), ret;
+	if ((msix < XLP_MSIX_INDEX_START) || (msix > XLP_MSIX_INDEX_END)){
+		printk(KERN_WARNING "Invalid msix #%d\n", msix);
+		return -EINVAL;
+	}
+	if ((ret = xlp_msix_enable(fn)) < 0) {
+		return ret;
+	}
+	nlm_msix_unmask(msix);
+	return nlm_irq_startup(XLP_PCIE_MSIX_IRQ(msix - XLP_MSIX_INDEX_START));
+}
+
+static void nlm_msix_shutdown(unsigned int msix)
+{
+	int fn = XLP_MSIX_TO_CTRL_FN(msix), ret;
+	if ((msix < XLP_MSIX_INDEX_START) || (msix > XLP_MSIX_INDEX_END)){
 		return;
-#endif
+	}
+	nlm_msix_mask(msix);
+	if ((ret = xlp_msix_disable(fn)) < 0) {
+		return;
+	}
+	return nlm_irq_shutdown(XLP_PCIE_MSIX_IRQ(msix - XLP_MSIX_INDEX_START));
+}
+
+/*
+ * MSI-X hook-up routines for Netlogic Boards;
+ * Arch-dependent implementation called
+ * from generic msi.c routines.
+ */
 
-	/* clear all pending interrupts */
-	write_64bit_cp0_eirr(0xffffffffffffffff);
-	/* Mask out all interrupts */
-	write_64bit_cp0_eimr(0);
+struct irq_chip nlm_msix_pic = {
+	.name = "XLP-PIC-MSIX",
+	.startup = nlm_msix_startup,
+	.shutdown = nlm_msix_shutdown,
+	.ack = nlm_msix_ack,
+	.end = nlm_msix_end,
+	.mask = nlm_msix_mask,
+	.unmask = nlm_msix_unmask,
+	.set_affinity = nlm_msix_set_affinity
+};
 
-	/* Initialize the irq descriptors */
-	init_nlm_common_irqs();
 
-	write_64bit_cp0_eimr(nlm_xlp_irq_mask);
+/*
+ * Composes MSI/MSI-X messages
+ */
+static int xlp_msi_compose_msg(struct pci_dev *pdev, struct msi_desc *desc,
+		unsigned int irq, struct msi_msg *msg)
+{
+	u8 offset;
+	int fn = xlp_ctrl_fn_from_dev(pdev);
+
+	if (fn < 0) return -EINVAL;
+	if (desc->msi_attrib.is_msix) {
+		if (irq < XLP_MSIX_INDEX_START) {	/* enforce minimum */
+			dev_err(&pdev->dev, "Invalid irq %d", irq);
+			return -EINVAL;
+		}
+		offset = irq - XLP_MSIX_INDEX_START;
+		msg->address_hi = (virt_to_phys(xlp_msix_addr_start(fn)) >> 32);
+		msg->address_lo = (virt_to_phys(xlp_msix_addr_start(fn)) & 0xffffffff);
+		//dev_dbg(&pdev->dev, "MSI-X hi = %#x, lo = %#x, data = %#x\n", msg->address_hi, msg->address_lo, offset);
+	} else {
+		if (irq < XLP_MSI_IRQ_OFFSET) {	/* enforce minimum */
+			return -EINVAL;
+		}
+		offset = irq - (XLP_MSI_IRQ_START(xlp_ctrl_fn_from_dev(pdev)));
+		msg->address_hi = (virt_to_phys(xlp_msi_addr_start(fn)) >> 32) & 0xffffffff;
+		msg->address_lo = (virt_to_phys(xlp_msi_addr_start(fn)) & 0xffffffff);
+	}
+	msg->data = offset;
+	return 0;
+}
+
+/*
+ * Returns the bitmask of currently used MSI-X on controller fn
+ *
+ * Must call with lock held
+ * @fn : controller number
+ */
+u32 __xlp_msix_bitmask(int fn)
+{
+	int idx = 0, ret = 0;
+
+	while (idx < XLP_MSIX_PER_SLOT) {
+		if (irq_map[XLP_MSIX_IRQ_START(fn) + idx].usage > 0) {
+			ret |= (1ULL << idx);
+		}
+		idx++;
+	}
+	return ret;
+}
+
+/*
+ * Back end of disable_msi()/ disable_msix()
+ */
+void arch_teardown_msi_irq(unsigned int msi)
+{
+	unsigned long flags;
+	int bit, fn;
+
+	switch (msi) {
+	case XLP_MSI_INDEX_START ... XLP_MSI_INDEX_END:
+		spin_lock_irqsave(&xlp_pic_lock, flags);
+		fn = XLP_MSI_TO_CTRL_FN(msi);
+		bit = msi - XLP_MSI_IRQ_START(fn);
+		msi_vec[fn].count--;
+		msi_vec[fn].bitmap &= ~(1ULL << bit);
+		if (xlp_get_ctrl_intmode(fn) == XLP_INTMODE_MSI) {
+			if (xlp_set_ctrl_intmode(fn, XLP_INTMODE_NONE) < 0){
+			}
+		}
+		spin_unlock_irqrestore(&xlp_pic_lock, flags);
+		return;
+	case XLP_MSIX_INDEX_START ... XLP_MSIX_INDEX_END:
+		fn = XLP_MSIX_TO_CTRL_FN(msi);
+		bit = msi - XLP_MSIX_IRQ_START(fn);
+		spin_lock_irqsave(&xlp_pic_lock, flags);
+		msix_vec[fn].count--;
+		msix_vec[fn].bitmap &= ~(1ULL << bit);
+		if (xlp_get_ctrl_intmode(fn) == XLP_INTMODE_MSIX) {
+			if (xlp_set_ctrl_intmode(fn, XLP_INTMODE_NONE) < 0){
+			}
+		}
+		spin_unlock_irqrestore(&xlp_pic_lock, flags);
+		return;
+	default:
+		return;	/* Do not proceed if !(msi || msix) */
+	}
+}
+
+#endif		// CONFIG_PCI_MSI
+
+static int xlp_perf_irq(void)
+{
+	return IRQ_HANDLED;
 }
 
+/*
+ * Entry function for interrupts
+ */
 asmlinkage void plat_irq_dispatch(void)
 {
-	uint64_t eirr, eimr, pending;
-	int irq = 0;
+	volatile u64 eirr;
+	volatile u64 eimr;
+	volatile u64 bitmap;
+	struct pt_regs *pt_regs = current_thread_info()->regs;
+	int rvec = 0, idx = 0, base_irq, irq, fn;
+	unsigned long flags;
 
 	eirr = read_64bit_cp0_eirr();
 	eimr = read_64bit_cp0_eimr();
-
-	pending = eirr & eimr;
-	if (unlikely(!pending)) {
-		/* According to the datasheet eirr must be cleared manually */
-		if (eirr & ~eimr)
-			write_64bit_cp0_eirr(eirr & ~eimr);
+	eirr &= eimr;
+	if (eirr & (1ULL << XLP_IRQ_TIMER)) {
+		write_64bit_cp0_eirr(1ULL << XLP_IRQ_TIMER);
+		nlm_common_timer_interrupt(pt_regs, XLP_IRQ_TIMER);
 		return;
 	}
 
-	if (pending & (1 << IRQ_TIMER)) {
-		/* ack */
-		write_64bit_cp0_eirr(1ULL << IRQ_TIMER);
-		do_IRQ(IRQ_TIMER);
+	if (eirr & (1ULL << XLP_IRQ_OPROFILE)) {
 		return;
 	}
 
-	for (irq = 63; irq != -1; irq--) {
-		if (pending & (1ULL << irq))
+	/* Loop till all bits of eirr is cleared */
+	while (eirr) {
+
+	rvec = __ilog2_u64(eirr);
+	if (rvec == -1) {
+		return;
+	}
+	eirr &= ~(1ULL << rvec);
+	write_64bit_cp0_eirr(1ULL << rvec);
+	if (rvec < XLP_IRQ_RESERVED_MAX) {
+		irq = rvec;
+		do_nlm_common_IRQ(irq, pt_regs);
+		return;
+	} else {
+		/* We need to loop through all possible irqs for an rvec */
+		base_irq = irqbase_from_rvec(rvec);
+		if(base_irq < 0) {
+			return;
+		}
+		spin_lock_irqsave(&xlp_pic_lock, flags);
+		bitmap = rvec_map[rvec].bitmap;
+		spin_unlock_irqrestore(&xlp_pic_lock, flags);
+		switch(base_irq) {
+		/* For INTX, bitmap and base irq already set */
+#if defined CONFIG_PCI_MSI
+		/* These are not MSI vector numbers, but IRT #s */
+		case XLP_PCIE_LINK_IRQ(0) ... XLP_PCIE_LINK_IRQ(3):
+			/* Here fn # of controller is easily calculated
+			 * Check the IRT table : 0 -> 78, 1-> 79 ..etc */
+			fn = base_irq - XLP_PCIE_LINK_IRQ(0);
+			if (is_msi_set(fn) != 0) { /* this is an MSI */
+				/* find vectors set */
+				bitmap = calc_msi_vector_offset(fn);
+				/* recalculate base_irq for MSI */
+				base_irq = XLP_MSI_IRQ_START(fn);
+				/* now handle it as any other interrupt */
+			}
+			break;
+		case XLP_PCIE_MSIX_IRQ(0) ... XLP_PCIE_MSIX_IRQ(31):
+			fn = XLP_MSIX_TO_CTRL_FN(base_irq - XLP_PCIE_MSIX_IRQ(0));/* This _is_ correct because of((x >>3) &3) */
+			/* this is an MSI/MSI-X. Find vectors set */
+			bitmap = xlp_msix_status_clear(fn);
+			/* recalculate base_irq for MSI */
+			base_irq = XLP_MSIX_IRQ_START(fn);
+			/* now handle it as any other interrupt */
 			break;
-		else if (eirr & (1ULL << irq)) {	/* eirr also must be cleared */
-			write_64bit_cp0_eirr(1ULL << irq);
-			continue;
+#endif
+		default:
+			break;
+		}
+		while (bitmap) {
+			/* now that we have bitmap, serve all of them */
+			idx = ffs(bitmap) - 1;	/* man ffs */
+			bitmap &= ~(1 << idx);
+			irq = base_irq + idx;
+			do_nlm_common_IRQ(irq, pt_regs);
+		}
+	}
+
+	}	// End of while (eirr)...
+	return;
+}
+
+int nlm_xlp_request_irq(int irq)
+{
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
+		return -ENODEV;
+	} else if(irq >= XLP_IRQ_MAX) {
+		return -EFAULT;
+	}
+	return(irq + XLP_IRQ_RESERVED_MAX);
+}
+EXPORT_SYMBOL(nlm_xlp_request_irq);
+
+#if defined CONFIG_PCI_MSI
+#ifdef arch_setup_msi_irqs
+/*
+ * Arch specific setup functions and helpers
+ */
+/*
+ * Backend function that sets up MSI.
+ * Called from arch_setup_msi_irqs()
+ *
+ * On XLP, we can have more than one MSI per device. But no device requests it
+ * because of possible x86 influence (one MSI per device limitation).
+ * We enforce this limitation as well.
+ */
+int xlp_setup_msi_irq(struct pci_dev *dev, struct msi_desc *desc, int nvec)
+{
+	__label__ setup_end;
+	__label__ setup_fail;
+	struct msi_msg msg;
+	int ret, fn, bit, base_msi;
+	unsigned long flags;
+
+	fn = xlp_ctrl_fn_from_dev(dev);
+	if (fn < 0) {
+		return -EFAULT;
+	}
+	base_msi = XLP_MSI_IRQ_START(fn);
+	if (base_msi < XLP_MSI_IRQ_OFFSET) {
+		return -EFAULT;
+	}
+	if (nvec != 1) {
+		return -EINVAL;
+	}
+	spin_lock_irqsave(&xlp_pic_lock, flags);
+	ret = xlp_get_ctrl_intmode(fn);
+	if ((ret == XLP_INTMODE_MSIX ) || (ret == XLP_INTMODE_INTX)) {
+		ret = -EBUSY;
+		goto setup_end;
+	}
+	/* search for the first unused bit in the bitmap.
+	 * Please note that the usage is different from that of MSIX allocation
+	 * where we have the luxury of 1 irt entry per MSIX. Here we have to
+	 * multiplex in software */
+	if (msi_vec[fn].bitmap == 0) {
+		bit = 0;
+	} else {
+		bit = ffz(msi_vec[fn].bitmap);
+	}
+	if (bit > (XLP_MSI_PER_SLOT - 1)) {
+		ret = -ENOSPC;
+		goto setup_end;
+	}
+	msi_vec[fn].bitmap |= (1ULL << bit);
+	msi_vec[fn].count++;
+	base_msi += bit;
+	set_irq_msi(base_msi, desc);
+	ret = xlp_msi_compose_msg(dev, desc, base_msi, &msg);
+	if (ret < 0) {
+		goto setup_fail;
+	}
+	write_msi_msg(base_msi, &msg);
+	ret = xlp_set_ctrl_intmode(fn, XLP_INTMODE_MSI);
+	if (ret == 0) {
+		goto setup_end;	/* All done */
+	}
+setup_fail:
+	msi_vec[fn].bitmap &= ~(1ULL << bit);
+	msi_vec[fn].count--;
+setup_end:
+	spin_unlock_irqrestore(&xlp_pic_lock, flags);
+	return ret;
+}
+
+/*
+ * MSI-X setup functions
+ */
+
+/*
+ * Allocates a single MSI-X vector for msi_desc entry
+ * @dev		: pci device
+ * @desc	: msi_descriptor for this msi entry
+ * @nvec	: outstanding number of interrupts required for this device
+ */
+int xlp_setup_msix_irq(struct pci_dev *dev, int nvec)
+{
+	__label__ fail_loop;
+	__label__ setup_end;
+	struct msi_msg msg;
+	int old_mode, ret, idx, base_msix, fn, bit, old_count;
+	u32 old_bitmap;
+	unsigned long flags;
+	struct msi_desc *desc;
+
+	fn = xlp_ctrl_fn_from_dev(dev);
+	if (fn < 0) {
+		return -EFAULT;
+	}
+	base_msix = XLP_MSIX_IRQ_START(fn);
+	if (base_msix < XLP_MSIX_IRQ_OFFSET) {
+		return -EFAULT;
+	}
+	spin_lock_irqsave(&xlp_pic_lock, flags);
+	old_bitmap = msix_vec[fn].bitmap;
+	old_count = msix_vec[fn].count;
+	old_mode = xlp_get_ctrl_intmode(fn);
+	if ((old_mode == XLP_INTMODE_MSI ) || (old_mode == XLP_INTMODE_INTX)) {
+		ret = -EBUSY;
+		goto setup_end;
+	}
+	ret = xlp_set_ctrl_intmode(fn, XLP_INTMODE_MSIX);
+	if (ret < 0) {
+		goto setup_end;
+	}
+	bit = 0, idx = 0;
+	list_for_each_entry(desc, &dev->msi_list, list) {
+		/* this loops exactly nvec times */
+		if (msix_vec[fn].bitmap == 0) {
+			bit = 0;
+		} else {
+			bit = ffz(msix_vec[fn].bitmap);
+		}
+		if (bit > (XLP_MSIX_PER_SLOT - 1)) {
+			dev_err(&dev->dev, "No more vectors to allocate\n");
+			/* if we allocated at least one vector, we need to
+			 * return a positve value. Else return negative */
+			if (idx > 0) {
+				ret = idx;
+			} else {
+				ret = -ENOSPC;
+			}
+			goto setup_end;	/* could be a partial success */
+		}
+		/* We have allocated one bit, now get a vector for it */
+		msix_vec[fn].bitmap |= (1ULL << bit);
+		msix_vec[fn].count++;
+		set_irq_msi(base_msix + bit, desc);
+		ret = xlp_msi_compose_msg(dev, desc, base_msix + bit, &msg);
+		if (ret < 0) {
+			goto fail_loop;
 		}
+		write_msi_msg(base_msix + bit, &msg);
+		idx++;
 	}
-	if (irq == -1)
+	spin_unlock_irqrestore(&xlp_pic_lock, flags);
+	return 0;
+fail_loop:
+	msi_vec[fn].bitmap = old_bitmap;
+	msi_vec[fn].count = old_count;
+	xlp_set_ctrl_intmode(fn, old_mode);
+setup_end:
+	spin_unlock_irqrestore(&xlp_pic_lock, flags);
+	return ret;
+}
+
+int arch_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
+{
+	struct msi_desc *entry;
+	int ret;
+
+	if (nvec == 0) {
+		return -EINVAL;
+	}
+	/*
+	 * For MSI, nvec = 1 is not an architectural limitation
+	 * But at least in Linux 2.6.32, there is only one entry allocated
+	 * in dev->msi_list. That means, we cannot setup more than one
+	 * MSI, even if architecture allows it.  */
+	if (type == PCI_CAP_ID_MSI) {
+		if (nvec > 1) {
+			return -EINVAL;
+		}
+		entry = list_first_entry(&dev->msi_list, struct msi_desc, list);
+		ret = xlp_setup_msi_irq(dev, entry, nvec);
+	} else if (type == PCI_CAP_ID_MSIX) {
+	/* MSI-X has nvec entries allocated
+	 * if nvec is greater than max number vectors that can be allocated,
+	 * ret will be a positive value. For any failures, ret will be -ve */
+		ret = xlp_setup_msix_irq(dev, nvec);
+	} else {
+		ret = -EINVAL;	/* To suppress compiler "ret unused" warning */
+	}
+	return ret;
+}
+EXPORT_SYMBOL(arch_setup_msi_irqs);
+#endif
+#endif
+
+void __init init_nlm_common_irqs(void)
+{
+	int i;
+	u64	mask = 0;
+
+	for (i = 0; i < XLP_IRQ_MAX; i++) {	// IRQ : 0 - 167
+		set_irq_chip_and_handler(i, &nlm_irq_pic, handle_level_irq);
+	}
+#ifdef CONFIG_PCI_MSI
+	for (i = XLP_MSI_INDEX_START; i <= XLP_MSI_INDEX_END; i++) {
+		set_irq_chip_and_handler(i, &nlm_msi_pic, handle_level_irq);
+	}
+	for (i = XLP_MSIX_INDEX_START; i <= XLP_MSIX_INDEX_END; i++) {
+		set_irq_chip_and_handler(i, &nlm_msix_pic, handle_level_irq);
+	}
+#endif
+
+#ifdef CONFIG_REMOTE_DEBUG	/* REMOVE on XLP TODO */
+	irq_desc[XLP_IRQ_REMOTE_DEBUG].chip = &nlm_common_rsvd_pic;
+	irq_desc[XLP_IRQ_REMOTE_DEBUG].action = nlm_common_rsvd_action;
+	xlp_irq_mask |= (1ULL << XLP_IRQ_REMOTE_DEBUG);
+#endif
+#ifdef CONFIG_SMP
+	irq_desc[XLP_IRQ_IPI_SMP_FUNCTION].chip = &nlm_common_rsvd_pic;
+	irq_desc[XLP_IRQ_IPI_SMP_FUNCTION].action = &nlm_common_rsvd_action;
+
+	irq_desc[XLP_IRQ_IPI_SMP_RESCHEDULE].chip = &nlm_common_rsvd_pic;
+	irq_desc[XLP_IRQ_IPI_SMP_RESCHEDULE].action = &nlm_common_rsvd_action;
+
+#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY	/* REMOVE on XLP TODO */
+	/* PR: New IPI added here for netrx balancing */
+	irq_desc[XLP_IRQ_IPI_NETRX].chip = &nlm_common_rsvd_pic;
+	irq_desc[XLP_IRQ_IPI_NETRX].action = &nlm_common_rsvd_action;
+	//xlp_irq_mask |= (1ULL << XLP_IRQ_IPI_NETRX);
+#endif				/* CONFIG_NLMCOMMON_IP_FLOW_AFFINITY */
+
+#endif
+
+	/* msgring interrupt */
+	irq_desc[XLP_IRQ_MSGRING].chip = &nlm_common_rsvd_pic;
+	irq_desc[XLP_IRQ_MSGRING].action = &nlm_common_rsvd_action;
+
+	mask = (
+			(1ULL << XLP_IRQ_TIMER) |
+			(1ULL << 10) |	/* timer */
+			(1ULL << 49) |	/* msg_idx */
+			(0x3ULL << 48) |	/* msg_idx */
+			(0xfULL << 32) |	/* pci msix */
+			(0xfULL << 41) |	/* pci and msi */
+			(0x1ULL << 58) |	/* nae */
+			(0x3ULL << 24) |	/* usb */
+			(0x3ULL	<< 17) |	/* uart */
+			(0xfULL << 13) |	/* gpio */
+			(0x1ULL << 31) |	/* SATA on xlp3xx */
+#ifdef CONFIG_SMP
+			(1ULL << XLP_IRQ_IPI_SMP_FUNCTION) |
+			(1ULL << XLP_IRQ_IPI_SMP_RESCHEDULE) |
+#endif
+#ifdef CONFIG_OPROFILE
+			(1ULL << XLP_IRQ_OPROFILE) |
+#endif
+#ifdef CONFIG_KGDB
+			(1ULL << XLP_IRQ_IPI_SMP_KGDB) |
+#endif
+			(1ULL << XLP_IRQ_MSGRING) |
+			(0xfULL << 20)		/* nor, nand, spi and mmc */
+	       );
+	/* set interrupt mask for non-zero cpus */
+	mask |= read_64bit_cp0_eimr();
+	xlp_irq_mask = mask;
+}
+
+
+void __init arch_init_irq(void)
+{
+	extern int (*perf_irq)(void);
+
+	perf_irq = xlp_perf_irq;
+
+#ifdef CONFIG_KGDB
+	if (kgdb_early_setup)
 		return;
+#endif
+
+	/* Initialize the irq descriptors */
+	init_nlm_common_irqs();
 
-	/* ack interrupts */
-	write_64bit_cp0_eirr(1ULL << irq);
+	write_64bit_cp0_eimr(xlp_irq_mask);
 
-	do_IRQ(irq);
 }
 
 #if defined(CONFIG_HOTPLUG_CPU) || defined(CONFIG_KEXEC)
 
+extern void nlm_enable_vc_intr(void);
+extern void enable_msgconfig_int(void);
 extern void on_chip_shutoff_msgring(void);
 extern void nlm_disable_vc_intr(void);
 extern void cpu_hotplug_fixup_poe(int cpu, int flag);
@@ -454,7 +1722,7 @@ void fixup_irqs(unsigned int cpu, int flag)
 		/* clear all pending interrupts */
 		write_64bit_cp0_eirr(0xffffffffffffffff);
 		/* set interrupt mask for non-zero cpus */
-		write_64bit_cp0_eimr(nlm_xlp_irq_mask | (1 << IRQ_TIMER));
+		write_64bit_cp0_eimr(xlp_irq_mask | (1 << XLP_IRQ_TIMER));
 		enable_msgconfig_int();
 		nlm_enable_vc_intr();
 	}
diff --git a/arch/mips/netlogic/xlp/on_chip.c b/arch/mips/netlogic/xlp/on_chip.c
index 7a8280a..562e4e2 100644
--- a/arch/mips/netlogic/xlp/on_chip.c
+++ b/arch/mips/netlogic/xlp/on_chip.c
@@ -1,5 +1,5 @@
 /***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
 reserved.
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are
@@ -32,16 +32,21 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #include <linux/module.h>
 #include <linux/timer.h>
 
+#include <asm/netlogic/msgring.h>
 #include <asm/netlogic/iomap.h>
 #include <asm/netlogic/mips-exts.h>
 #include <asm/netlogic/debug.h>
 #include <asm/netlogic/xlp.h>
 
 #include <asm/netlogic/hal/nlm_hal_fmn.h>
-#include <asm/netlogic/hal/nlm_hal_pic.h>
+#include <asm/netlogic/xlp_hal_pic.h>
+
+#include <linux/netdevice.h>
 
 #define MAX_VC	4096
 
+extern int xlp_rvec_from_irt(int);
+extern int xlp_rvec_from_irq(int);
 unsigned long netlogic_io_base = (unsigned long)(DEFAULT_NETLOGIC_IO_BASE);
 EXPORT_SYMBOL(netlogic_io_base);
 
@@ -54,22 +59,34 @@ extern void nlm_cpu_stat_update_msgring_pic_int(void);
 uint32_t msgring_global_thread_mask = 0;
 uint32_t nlm_cpu_vc_mask[NLM_MAX_CPU_NODE*NLM_MAX_CPU_PER_NODE] = {0};
 
+uint32_t nlm_l1_lock[NR_CPUS/4] = {0};
+
+typedef void (*vchandler)(int vc);
+static vchandler xlp_vc_handlers[NLM_MAX_VC_PER_THREAD];
+
 /* make this a read/write spinlock */
 spinlock_t msgrng_lock;
-nlm_common_atomic_t msgring_registered;
+static nlm_common_atomic_t msgring_registered;
 
 struct msgstn_handler {
         void (*action)(uint32_t, uint32_t, uint32_t, uint32_t, uint64_t, uint64_t, uint64_t, uint64_t, void *);
         void *dev_id;
 };
 
+struct net_device xlp_napi_fmn_dummy_dev;
+DEFINE_PER_CPU(struct napi_struct, xlp_napi_fmn_poll_struct);
+DEFINE_PER_CPU(unsigned long long, xlp_napi_fmn_rx_count);
+static int xlp_napi_vc_count = 0;
+static int xlp_fmn_init_done = 0;
+extern unsigned int xlp_napi_vc_mask;
+
 static uint16_t vc_to_handle_map[MAX_VC] = {
 	[0 ... 15] = XLP_MSG_HANDLE_CPU0,
 	[16 ... 31] = XLP_MSG_HANDLE_CPU1,
 	[32 ... 47] = XLP_MSG_HANDLE_CPU2,
 	[48 ... 63] = XLP_MSG_HANDLE_CPU3,
 	[64 ... 79] = XLP_MSG_HANDLE_CPU4,
-	[80 ... 85] = XLP_MSG_HANDLE_CPU5,
+	[80 ... 95] = XLP_MSG_HANDLE_CPU5,
 	[96 ... 111] = XLP_MSG_HANDLE_CPU6,
 	[112 ... 127] = XLP_MSG_HANDLE_CPU7,
 	[128 ... 143] = XLP_MSG_HANDLE_CPU0,
@@ -84,52 +101,122 @@ static uint16_t vc_to_handle_map[MAX_VC] = {
 	[258 ... 259] = XLP_MSG_HANDLE_PCIE1,
 	[260 ... 261] = XLP_MSG_HANDLE_PCIE2,
 	[262 ... 263] = XLP_MSG_HANDLE_PCIE3,
-	[264 ... 271] = XLP_MSG_HANDLE_GDX,
+	[264 ... 267] = XLP_MSG_HANDLE_DTRE,
+	[268 ... 271] = XLP_MSG_HANDLE_GDX,
 	[272 ... 280] = XLP_MSG_HANDLE_RSA_ECC,
 	[281 ... 296] = XLP_MSG_HANDLE_CRYPTO,
 	[297 ... 304] = XLP_MSG_HANDLE_CMP,
 	[305 ... 383] = XLP_MSG_HANDLE_INVALID,
 	[384 ... 391] = XLP_MSG_HANDLE_NAE_0,
 	[392 ... 475] = XLP_MSG_HANDLE_INVALID,
-	[476] 	      = XLP_MSG_HANDLE_NAE_0,
-	[477] 	      = XLP_MSG_HANDLE_NAE_0,
-	[478] 	      = XLP_MSG_HANDLE_NAE_0,
-	[479] 	      = XLP_MSG_HANDLE_NAE_0,
-	[480] 	      = XLP_MSG_HANDLE_NAE_0,
-	[481] 	      = XLP_MSG_HANDLE_NAE_0,
-	[482] 	      = XLP_MSG_HANDLE_NAE_0,
-	[483] 	      = XLP_MSG_HANDLE_NAE_0,
-	[484] 	      = XLP_MSG_HANDLE_NAE_0,
-	[485] 	      = XLP_MSG_HANDLE_NAE_0,
-	[486] 	      = XLP_MSG_HANDLE_NAE_0,
-	[487] 	      = XLP_MSG_HANDLE_NAE_0,
-	[488] 	      = XLP_MSG_HANDLE_NAE_0,
-	[489] 	      = XLP_MSG_HANDLE_NAE_0,
-	[490] 	      = XLP_MSG_HANDLE_NAE_0,
-	[491] 	      = XLP_MSG_HANDLE_NAE_0,
-	[492] 	      = XLP_MSG_HANDLE_NAE_0,
-	[493] 	      = XLP_MSG_HANDLE_NAE_0,
-	[494 ... 999] = XLP_MSG_HANDLE_NAE_0,
-	[1000] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1001] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1002] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1003] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1004] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1005] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1006] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1007] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1008] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1009] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1010] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1011] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1012] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1013] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1014] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1015] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1016] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1017] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1018 ... 1019] = XLP_MSG_HANDLE_NAE_0,
-	[1020 ... 4095] = XLP_MSG_HANDLE_INVALID
+	[476 ... 1019] = XLP_MSG_HANDLE_NAE_0,
+	[1020 ... 1023] = XLP_MSG_HANDLE_INVALID,
+	//NODE-1
+	[1024 ... 1039] = XLP_MSG_HANDLE_CPU0,
+	[1040 ... 1055] = XLP_MSG_HANDLE_CPU1,
+	[1056 ... 1071] = XLP_MSG_HANDLE_CPU2,
+	[1072 ... 1087] = XLP_MSG_HANDLE_CPU3,
+	[1088 ... 1103] = XLP_MSG_HANDLE_CPU4,
+	[1104 ... 1119] = XLP_MSG_HANDLE_CPU5,
+	[1120 ... 1135] = XLP_MSG_HANDLE_CPU6,
+	[1136 ... 1151] = XLP_MSG_HANDLE_CPU7,
+	[1158 ... 1279] = XLP_MSG_HANDLE_INVALID,
+	[1280 ... 1281] = XLP_MSG_HANDLE_PCIE0,
+	[1282 ... 1283] = XLP_MSG_HANDLE_PCIE1,
+	[1284 ... 1285] = XLP_MSG_HANDLE_PCIE2,
+	[1286 ... 1287] = XLP_MSG_HANDLE_PCIE3,
+	[1288 ... 1291] = XLP_MSG_HANDLE_DTRE,
+	[1292 ... 1295] = XLP_MSG_HANDLE_GDX,
+	[1296 ... 1304] = XLP_MSG_HANDLE_RSA_ECC,
+	[1305 ... 1320] = XLP_MSG_HANDLE_CRYPTO,
+	[1321 ... 1328] = XLP_MSG_HANDLE_CMP,
+	[1329 ... 1407] = XLP_MSG_HANDLE_INVALID,
+	[1408 ... 1415] = XLP_MSG_HANDLE_NAE_0,
+	[1416 ... 1499] = XLP_MSG_HANDLE_INVALID,
+	[1500 ... 2043] = XLP_MSG_HANDLE_NAE_0,
+	[2044 ... 2047] = XLP_MSG_HANDLE_INVALID,
+	// NODE-2	
+	[2048 ... 2063] = XLP_MSG_HANDLE_CPU0,
+	[2064 ... 2079] = XLP_MSG_HANDLE_CPU1,
+	[2080 ... 2095] = XLP_MSG_HANDLE_CPU2,
+	[2096 ... 2111] = XLP_MSG_HANDLE_CPU3,
+	[2112 ... 2127] = XLP_MSG_HANDLE_CPU4,
+	[2128 ... 2143] = XLP_MSG_HANDLE_CPU5,
+	[2144 ... 2159] = XLP_MSG_HANDLE_CPU6,
+	[2160 ... 2175] = XLP_MSG_HANDLE_CPU7,
+	[2176 ... 2303] = XLP_MSG_HANDLE_INVALID,
+	[2304 ... 2305] = XLP_MSG_HANDLE_PCIE0,
+	[2306 ... 2307] = XLP_MSG_HANDLE_PCIE1,
+	[2308 ... 2309] = XLP_MSG_HANDLE_PCIE2,
+	[2310 ... 2311] = XLP_MSG_HANDLE_PCIE3,
+	[2312 ... 2315] = XLP_MSG_HANDLE_DTRE,
+	[2316 ... 2319] = XLP_MSG_HANDLE_GDX,
+	[2320 ... 2328] = XLP_MSG_HANDLE_RSA_ECC,
+	[2329 ... 2344] = XLP_MSG_HANDLE_CRYPTO,
+	[2345 ... 2352] = XLP_MSG_HANDLE_CMP, 
+	[2353 ... 2431] = XLP_MSG_HANDLE_INVALID,
+	[2432 ... 2439] = XLP_MSG_HANDLE_NAE_0,
+	[2440 ... 2523] = XLP_MSG_HANDLE_INVALID,
+	[2524 ... 3067] = XLP_MSG_HANDLE_NAE_0,
+	[3068 ... 3071] = XLP_MSG_HANDLE_INVALID,
+
+	// NODE-3
+	[3072 ... 3087] = XLP_MSG_HANDLE_CPU0,
+	[3088 ... 3103] = XLP_MSG_HANDLE_CPU1,
+	[3104 ... 3119] = XLP_MSG_HANDLE_CPU2,
+	[3120 ... 3135] = XLP_MSG_HANDLE_CPU3,
+	[3136 ... 3151] = XLP_MSG_HANDLE_CPU4,
+	[3152 ... 3167] = XLP_MSG_HANDLE_CPU5,
+	[3168 ... 3183] = XLP_MSG_HANDLE_CPU6,
+	[3184 ... 3199] = XLP_MSG_HANDLE_CPU7,
+	[3200 ... 3327] = XLP_MSG_HANDLE_INVALID,
+	[3328 ... 3329] = XLP_MSG_HANDLE_PCIE0,
+	[3330 ... 3331] = XLP_MSG_HANDLE_PCIE1,
+	[3332 ... 3333] = XLP_MSG_HANDLE_PCIE2,
+	[3334 ... 3335] = XLP_MSG_HANDLE_PCIE3,
+	[3336 ... 3339] = XLP_MSG_HANDLE_DTRE,
+	[3340 ... 3343] = XLP_MSG_HANDLE_GDX,
+	[3344 ... 3352] = XLP_MSG_HANDLE_RSA_ECC,
+	[3353 ... 3368] = XLP_MSG_HANDLE_CRYPTO,
+	[3369 ... 3376] = XLP_MSG_HANDLE_CMP,
+	[3377 ... 3455] = XLP_MSG_HANDLE_INVALID,
+	[3456 ... 3463] = XLP_MSG_HANDLE_NAE_0,
+	[3464 ... 3547] = XLP_MSG_HANDLE_INVALID,
+	[3548 ... 4091] = XLP_MSG_HANDLE_NAE_0,
+	[4092 ... 4095] = XLP_MSG_HANDLE_INVALID,
+};
+
+static uint16_t xlp3xx_vc_to_handle_map[MAX_VC] = {
+	[0 ... 15] = XLP_MSG_HANDLE_CPU0,
+	[16 ... 31] = XLP_MSG_HANDLE_CPU1,
+	[32 ... 47] = XLP_MSG_HANDLE_CPU2,
+	[48 ... 63] = XLP_MSG_HANDLE_CPU3,
+	[64 ... 79] = XLP_MSG_HANDLE_INVALID,
+	[80 ... 95] = XLP_MSG_HANDLE_INVALID,
+	[96 ... 111] = XLP_MSG_HANDLE_INVALID,
+	[112 ... 127] = XLP_MSG_HANDLE_INVALID,
+	[128 ... 143] = XLP_MSG_HANDLE_CPU0,
+	[144 ... 159] = XLP_MSG_HANDLE_CPU1,
+	[160 ... 175] = XLP_MSG_HANDLE_CPU2,
+	[176 ... 191] = XLP_MSG_HANDLE_CPU3,
+	[192 ... 207] = XLP_MSG_HANDLE_INVALID,
+	[208 ... 223] = XLP_MSG_HANDLE_INVALID,
+	[224 ... 239] = XLP_MSG_HANDLE_INVALID,
+	[240 ... 255] = XLP_MSG_HANDLE_INVALID,
+	[256 ... 257] = XLP_MSG_HANDLE_PCIE0,
+	[258 ... 259] = XLP_MSG_HANDLE_PCIE1,
+	[260 ... 261] = XLP_MSG_HANDLE_PCIE2,
+	[262 ... 263] = XLP_MSG_HANDLE_PCIE3,
+	[264 ... 267] = XLP_MSG_HANDLE_DTRE,
+	[268 ... 271] = XLP_MSG_HANDLE_REGX,
+	[272 ... 275] = XLP_MSG_HANDLE_RSA_ECC,
+	[276 ... 279] = XLP_MSG_HANDLE_CRYPTO,
+	[280 ... 288] = XLP_MSG_HANDLE_SRIO,
+	[289 ... 383] = XLP_MSG_HANDLE_INVALID,
+	[384 ... 391] = XLP_MSG_HANDLE_NAE_0,
+	[392 ... 431] = XLP_MSG_HANDLE_INVALID,
+	[432 ... 511] = XLP_MSG_HANDLE_NAE_0,
+	[512 ... 4095]= XLP_MSG_HANDLE_INVALID
 };
 
 /******************************************************************************************
@@ -149,10 +236,12 @@ static uint16_t vc_to_handle_map[MAX_VC] = {
 void dummy_handler(uint32_t vc, uint32_t src_id, uint32_t size, uint32_t code, 
 		   uint64_t msg0, uint64_t msg1, uint64_t msg2, uint64_t msg3, void *dev_id)
 {
+#if 0
 	printk("[%s]: No Handler for message from stn_id=%d, bucket=%d, "
 	       "size=%d, msg0=%llx, msg1=%llx dropping message\n",
 	       __FUNCTION__, src_id, vc, size,
 	       (unsigned long long)msg0, (unsigned long long)msg1);
+#endif
 }
 
 /******************************************************************************************
@@ -165,6 +254,28 @@ struct msgstn_handler msg_handler_map[XLP_MSG_HANDLE_MAX] = {
 	[0 ... (XLP_MSG_HANDLE_MAX-1)] = {dummy_handler, NULL},
 };
 
+
+int nlm_xlp_register_vc_handler(int vc, void (*handler)(int vc))
+{
+	int i, node = 0;
+	if(vc < 0 || vc >= NLM_MAX_VC_PER_THREAD) {
+		printk("Invalid VC Passed %d\n", vc);
+		return -1;
+	}
+	xlp_vc_handlers[vc] = handler;
+
+	for(i=0; i<NR_CPUS; i++){
+		if(!cpu_isset(i, cpu_present_map))
+			continue;
+		node = i / 32;
+		nlm_hal_enable_vc_intr(node, (i*NLM_MAX_VC_PER_THREAD + vc) & 0x7f);
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(nlm_xlp_register_vc_handler);
+
+
 /*********************************************************************
  * nlm_xlp_msgring_int_handler 
  *
@@ -184,10 +295,10 @@ void nlm_xlp_msgring_int_handler(unsigned int irq, struct pt_regs *regs)
 	int loop = 0;
 	int cpu = hard_smp_processor_id();
 	int pop_vc_mask = nlm_cpu_vc_mask[cpu];
-
 	msg0 = msg1 = msg2 = msg3 = 0;
-
-        if (irq == IRQ_MSGRING) {
+	uint32_t napi_vc_mask = xlp_napi_vc_mask & pop_vc_mask;
+	
+	if (irq == XLP_IRQ_MSGRING) {
                 /* normal message ring interrupt */
                 /* xlr_inc_counter(MSGRNG_INT);  */
                 nlm_cpu_stat_update_msgring_int();
@@ -196,20 +307,34 @@ void nlm_xlp_msgring_int_handler(unsigned int irq, struct pt_regs *regs)
         }
 
 
-//	irq_enter();
+	irq_enter();
 
         msgrng_access_enable(mflags);
 	cycles = read_c0_count();
 
-	/* Don't loop forever, it may increase interrupt latency */
-	for (loop = 0; loop < 16; loop++) {
+	for (;;) {
 
 		/* Read latest VC empty mask */
 		msg_status1 = xlp_read_status1();
 
+#ifdef CONFIG_NLM_EXCL_VC_NAPI_HANDLER_SUPPORT
+		for(vc = 0; vc < 4; vc++) {
+			if(xlp_vc_handlers[vc])
+				(xlp_vc_handlers)[vc](vc);
+		}
+#else
+		if((~(msg_status1>>24) & napi_vc_mask) && xlp_fmn_init_done) {
+			struct napi_struct *napi;
+
+			/*Schedule napi routine to process messages from napi vc*/
+		        napi = &__get_cpu_var(xlp_napi_fmn_poll_struct);
+		        napi_schedule(napi);
+			pop_vc_mask = pop_vc_mask & ~napi_vc_mask;
+		}
+#endif
+
 		vc_empty_status = (msg_status1 >> 24) & pop_vc_mask;
-		if (vc_empty_status == pop_vc_mask)
-			break;
+		if (vc_empty_status == pop_vc_mask) break;  
 
 		for( vc = 0; vc < 4; vc++)
 		{
@@ -219,8 +344,13 @@ void nlm_xlp_msgring_int_handler(unsigned int irq, struct pt_regs *regs)
 			if(status != 0)
 				continue;
 
-			handler = &msg_handler_map[vc_to_handle_map[src_id]];
-	
+			if (is_nlm_xlp3xx()) {
+				handler = &msg_handler_map[xlp3xx_vc_to_handle_map[src_id]];
+			}
+			else {
+				handler = &msg_handler_map[vc_to_handle_map[src_id]];
+			}
+
 			/* Execute device driver fmn handler */
 			(handler->action)(vc, src_id, size, code,
 					  msg0, msg1, msg2, msg3, handler->dev_id);
@@ -237,11 +367,74 @@ void nlm_xlp_msgring_int_handler(unsigned int irq, struct pt_regs *regs)
 
         msgrng_access_disable(mflags);
 
-//	irq_exit();
+	irq_exit();
 }
 
 EXPORT_SYMBOL(nlm_xlp_msgring_int_handler);
 
+static DEFINE_PER_CPU(struct timer_list, msg_int_bkup_timer);
+static int msg_handler_timer_enabled=0;
+static void msg_timer_handler(unsigned long data)
+{
+/*
+	int cpu = smp_processor_id();
+	struct timer_list *timer = &per_cpu(msg_int_bkup_timer, cpu);
+*/
+	nlm_xlp_msgring_int_handler(XLP_IRQ_MSGRING, NULL);
+/*
+	timer->expires = jiffies + (HZ/100);
+	add_timer(timer);
+*/
+}
+void init_msg_bkp_timer(void *data)
+{
+	int cpu = smp_processor_id();
+	struct timer_list *timer = &per_cpu(msg_int_bkup_timer, cpu);
+
+	init_timer(timer);
+	timer->expires = jiffies + (HZ/100);
+	timer->data = 0;
+	timer->function = msg_timer_handler;
+	add_timer(timer);
+}
+
+void xlp_poll_vc0_messages(void)
+{
+        int vc = 0;
+        uint32_t size = 0, code = 0, src_id = 0;
+        struct msgstn_handler *handler = 0;
+        unsigned int status = 0;
+        uint64_t msg0, msg1, msg2, msg3;
+        unsigned int msg_status1 = 0, vc_empty_status = 0;
+        int loop = 0;
+        int pop_vc_mask = 0x1;
+	unsigned long mflags;
+#if 0
+	if (hard_smp_processor_id() != 0)
+		printk("Called handler on cpu %d from %s msgstatus: 0x%x\n",
+			       hard_smp_processor_id(),
+			       __FUNCTION__,xlp_read_status1());
+#endif
+        msg0 = msg1 = msg2 = msg3 = 0;
+        msgrng_access_enable(mflags);
+        for (loop = 0; loop < 16; loop++) {
+                /* Read latest VC empty mask */
+                msg_status1 = xlp_read_status1();
+                vc_empty_status = (msg_status1 >> 24) & pop_vc_mask;
+                if (vc_empty_status == pop_vc_mask)
+                        break;
+                status = xlp_message_receive( vc, &src_id, &size, &code, &msg0, &msg1, &msg2, &msg3);
+                if(status != 0)
+                        continue;
+                handler = &msg_handler_map[vc_to_handle_map[src_id]];
+                /* Execute device driver fmn handler */
+                (handler->action)(vc, src_id, size, code,
+                                msg0, msg1, msg2, msg3, handler->dev_id);
+        }
+        msgrng_access_disable(mflags);
+}
+EXPORT_SYMBOL(xlp_poll_vc0_messages);
+
 /*******************************************************************************************
  *  register_xlp_msgring_handler 
  *
@@ -267,6 +460,16 @@ int register_xlp_msgring_handler(int major,
 	/* Check if the message station is valid, if not return error */
 	spin_lock_irqsave(&msgrng_lock, flags);
 
+	if(!xlp_fmn_init_done)
+		xlp_fmn_init_done = 1;
+
+	if(msg_handler_timer_enabled == 0) {
+		msg_handler_timer_enabled = 1;
+		spin_unlock_irqrestore(&msgrng_lock, flags);
+		// init_msg_bkp_timer(0);	Not required, taken care by on_each_cpu()
+		on_each_cpu(init_msg_bkp_timer, 0, 1);
+		spin_lock_irqsave(&msgrng_lock, flags);
+	}
 
 	msg_handler_map[major].action = action;
 	msg_handler_map[major].dev_id = dev_id;
@@ -281,6 +484,27 @@ int register_xlp_msgring_handler(int major,
 
 EXPORT_SYMBOL(register_xlp_msgring_handler);
 
+int unregister_xlp_msgring_handler(int major, void *dev_id)
+{
+	unsigned long flags;
+
+	if(major >= XLP_MSG_HANDLE_MAX){
+		printk(KERN_ALERT "%s:%d  Invalid parameter: major=%d, "
+		       "XLP_MAX_TX_STN=%d", __FUNCTION__, __LINE__, major,
+		       XLP_MAX_TX_STNS);
+		return -1;
+	}
+	spin_lock_irqsave(&msgrng_lock, flags);
+	if(msg_handler_map[major].dev_id == dev_id){
+		msg_handler_map[major].action = dummy_handler;
+		msg_handler_map[major].dev_id = NULL;
+	}
+	spin_unlock_irqrestore(&msgrng_lock, flags);
+	return 0;
+}
+
+EXPORT_SYMBOL(unregister_xlp_msgring_handler);
+
 #include <asm/netlogic/cpumask.h>
 void nlm_nmi_cpus(unsigned int mask)
 {
@@ -307,6 +531,7 @@ void nlm_nmi_cpus(unsigned int mask)
 /* need COP2 to be accessible */
 static void on_chip_msgring_drain_msgs(void)
 {
+	unsigned long mflags;
 	int vc = 0;
 	uint32_t size = 0, code = 0, src_id = 0;
 	uint64_t msg0, msg1, msg2, msg3;
@@ -350,14 +575,231 @@ void on_chip_shutoff_msgring(void)
  ********************************************************************/
 void enable_msgconfig_int(void)
 {
-	uint32_t flags;
+	unsigned long flags  = 0;
 
 	/* Need write interrupt vector to cp2 msgconfig register */
 	msgrng_access_enable(flags);
-	nlm_hal_set_fmn_interrupt(IRQ_MSGRING);
+	nlm_hal_set_fmn_interrupt(XLP_IRQ_MSGRING);
 	msgrng_access_disable(flags);
 }
 
+/*
+ * Initializes PIC ITE entries PRM 9.5.6.26
+ * XLP restricts CPU affinity to 8 groups. They are,
+ * 0 =>	Only cpu0/thread0; mask = 1
+ * 1 => All CPUs/threads and nodes; mask = (~0 & online_cpu_mask) on all nodes
+ * 2 => cpu0-1 on all nodes. mask = 0x000000ff& online_cpu_mask  on all nodes
+ * 3 => cpu2-3 on all nodes; mask = 0x0000ff00 & online_cpu_mask on all nodes
+ * 4 => cpu4-5 on all nodes; mask = 0x00ff0000 & online_cpu_mask on all nodes
+ * 5 => cpu6-7 on all nodes; mask = 0xff000000 & online_cpu_mask on all nodes
+ * 6 => cpu0-15 on all nodes; mask = 0x0000ffff & online_cpu_mask on all nodes
+ * 7 => cpu15-31 on all nodes; mask = 0xffff0000 & online_cpu_mask on all nodes
+ *
+ * These are programmer defined groups and can be changed as warranted.
+ *
+ * FIXME: for NUMA, we assume all nodes will have identical intra-node cpu
+ * online masks.
+ */
+static struct cpumask xlp_ite_cpumask[XLP_ITE_ENTRIES];
+void xlp_pic_ite_init(const struct cpumask *tgt_mask)
+{
+	int i;
+	struct cpumask m;
+	u64 xlp_pic_base = XLP_BDF_BASE(0,0,4);
+	char buf[140];
+	u64 bitmask = 0;
+#ifdef CONFIG_NUMA
+	struct cpumask m1, m2;
+#endif
+
+#ifndef CONFIG_NUMA
+	printk(KERN_WARNING "Setting ITE entries only for 0-31 (Node 0) CPUs!\n");
+#endif
+	cpumask_clear(&m);
+	/* We manipulate only NODE0 ITE entries here */
+	for (i = 0; i < XLP_ITE_ENTRIES; i++) {
+		cpumask_clear(&xlp_ite_cpumask[i]);
+	}
+	cpumask_set_cpu(cpumask_first(tgt_mask), &xlp_ite_cpumask[0]);
+
+	/* Set 0-31 cpus, if present in cpu_online mask */
+	for (i = cpumask_first(tgt_mask); i < 32; ) {
+		bitmask |= (1ULL << i);
+		i = cpumask_next(i, tgt_mask);
+	}
+
+	/* Set 0-7 cpus */
+	for (i = 0; i < 8; i++) {
+		cpumask_set_cpu(i, &m);
+	}
+
+	cpumask_scnprintf(buf, 140, tgt_mask); fdebug("Target cpumask -> %s\n", buf);
+#ifndef CONFIG_NUMA
+	cpumask_copy(&xlp_ite_cpumask[1], tgt_mask);
+#else
+	cpumask_shift_left(&m1, &m, 8);
+	cpumask_or(&m1, &m1, &m);
+	cpumask_shift_left(&m2, &m1, 16);
+	cpumask_or(&m2, &m2, &m1);
+	cpumask_and(&m2, &m2, tgt_mask);
+	cpumask_copy(&xlp_ite_cpumask[1], &m2);
+#endif
+
+	/* logical and with cpuonline mask to get the actual mask */
+	cpumask_and(&xlp_ite_cpumask[2], &m, tgt_mask);
+	cpumask_shift_left(&xlp_ite_cpumask[3], &m, 8);
+	cpumask_and(&xlp_ite_cpumask[3], &xlp_ite_cpumask[3], tgt_mask);
+	cpumask_shift_left(&xlp_ite_cpumask[4], &m, 16);
+	cpumask_and(&xlp_ite_cpumask[4], &xlp_ite_cpumask[4], tgt_mask);
+	cpumask_shift_left(&xlp_ite_cpumask[5], &m, 24);
+	cpumask_and(&xlp_ite_cpumask[5], &xlp_ite_cpumask[5], tgt_mask);
+
+	cpumask_shift_left(&xlp_ite_cpumask[6], &m, 8);
+	cpumask_or(&xlp_ite_cpumask[6], &xlp_ite_cpumask[6], &m);
+	cpumask_shift_left(&xlp_ite_cpumask[7], &xlp_ite_cpumask[6], 16);
+	cpumask_and(&xlp_ite_cpumask[6], &xlp_ite_cpumask[6], tgt_mask);
+	cpumask_and(&xlp_ite_cpumask[7], &xlp_ite_cpumask[7], tgt_mask);
+
+
+	for (i = 0; i < XLP_ITE_ENTRIES; i++) {
+		cpumask_scnprintf(buf, 140, &xlp_ite_cpumask[i]);
+		printk(KERN_DEBUG "Supported CPUMASK (%d) -> %s\n", i, buf);
+	}
+
+#ifndef CONFIG_NUMA
+	/* Right shift by 1 is required by HAL, _DO_NOT_REMOVE_ */
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0x94 >> 1, (0x00000001 & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0x98 >> 1, (0xffffffff & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0x9C >> 1, (0x000000ff & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0xA0 >> 1, (0x0000ff00 & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0xA4 >> 1, (0x00ff0000 & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0xA8 >> 1, (0xff000000 & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0xAC >> 1, (0x0000ffff & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0xB0 >> 1, (0xffff0000 & bitmask));
+	/* We don't populate redirection to other nodes now */
+#else
+	for_each_online_node (i) {
+		/* Interrupt delivered only to local node */
+		int node_offset = (i >= 2) * 2;
+		int mask_shift = ((i == 1) || (i == 3)) * 32;
+
+		fdebug("Programming ITEs for Node %d\n", i);
+
+		xlp_pic_base = XLP_BDF_BASE(0, 0 + 8 * i, 4);
+
+		nlm_hal_write_64bit_reg(
+			xlp_pic_base,
+			(0x94 + node_offset) >> 1,
+			((uint64_t)(0x00000001 & bitmask)) << mask_shift);
+		nlm_hal_write_64bit_reg(
+			xlp_pic_base,
+			(0x98 + node_offset) >> 1,
+			((uint64_t)(0xffffffff & bitmask)) << mask_shift);
+		nlm_hal_write_64bit_reg(
+			xlp_pic_base,
+			(0x9C + node_offset) >> 1,
+			((uint64_t)(0x000000ff & bitmask)) << mask_shift);
+		nlm_hal_write_64bit_reg(
+			xlp_pic_base,
+			(0xA0 + node_offset) >> 1,
+			((uint64_t)(0x0000ff00 & bitmask)) << mask_shift);
+		nlm_hal_write_64bit_reg(
+			xlp_pic_base,
+			(0xA4 + node_offset) >> 1,
+			((uint64_t)(0x00ff0000 & bitmask)) << mask_shift);
+		nlm_hal_write_64bit_reg(
+			xlp_pic_base,
+			(0xA8 + node_offset) >> 1,
+			((uint64_t)(0xff000000 & bitmask)) << mask_shift);
+		nlm_hal_write_64bit_reg(
+			xlp_pic_base,
+			(0xAC + node_offset) >> 1,
+			((uint64_t)(0x0000ffff & bitmask)) << mask_shift);
+		nlm_hal_write_64bit_reg(
+			xlp_pic_base,
+			(0xB0 + node_offset) >> 1,
+			((uint64_t)(0xffff0000 & bitmask)) << mask_shift);
+	}
+#endif
+}
+
+/*
+ * This function returns closest match cpumask among the supported bitmasks
+ * in XLP
+ * Logic is moot, need to improve it later.
+ * XXX
+ *
+ * @m	: user supplied cpumask
+ */
+const struct cpumask *xlp_closest_match_cpumask(struct cpumask *m)
+{
+	int i;
+
+	for (i = 0; i < XLP_ITE_ENTRIES; i++) {
+		if (cpumask_equal(m, &xlp_ite_cpumask[i])) {
+			return &xlp_ite_cpumask[i];
+		}
+	}
+	return NULL;
+}
+
+/*
+ * This function sets the cpumask for an interrupt vector
+ * @m	: CPU mask resulting from xlp_closest_match_cpumask() call
+ */
+void xlp_set_cpumask(const struct cpumask *m, int irt)
+{
+	int i;
+	u64 xlp_pic_base = XLP_BDF_BASE(0,0,4);
+	u64 val;
+	u32 offset = ((XLP_PIC_IRTREG_START + (irt << 1)) >> 1);	// Hal requires this nasty right shift
+#ifdef CONFIG_NUMA
+	int nid;
+#endif
+
+#ifndef CONFIG_NUMA
+	/* We set the following in IRT entry
+	 * 28 : clear to indicate global delivery
+	 * 19 : clear to indicate DB selects ITE
+	 * 16-18 : set to indicate ITE
+	 * 0-15 : Clear
+	 */
+	for (i = 0; i < XLP_ITE_ENTRIES; i++) {
+		if (m != &xlp_ite_cpumask[i]) {
+			continue;
+		}
+		val = nlm_hal_read_64bit_reg(xlp_pic_base, offset);
+		val &= ~((1 << 28) | (1 << 19) | (0x7 << 16) | 0xffff);
+		val |= (i << 16);
+		//fdebug("Writing val = %#llx\n", val);
+		nlm_hal_write_64bit_reg(xlp_pic_base, offset, val);
+		return;
+	}
+#else
+	/* We set the following in IRT entry
+	 * 28 : clear to indicate global delivery
+	 * 19 : clear to indicate DB selects ITE
+	 * 16-18 : set to indicate ITE
+	 * 0-15 : Clear
+	 */
+	for_each_online_node (nid) {
+		xlp_pic_base = XLP_BDF_BASE(0, 0 + 8 * nid, 4);
+		for (i = 0; i < XLP_ITE_ENTRIES; i++) {
+			if (m != &xlp_ite_cpumask[i]) {
+				continue;
+			}
+			val = nlm_hal_read_64bit_reg(xlp_pic_base, offset);
+			val &= ~((1 << 28) | (1 << 19) | (0x7 << 16) | 0xffff);
+			val |= (i << 16);
+			//fdebug("Writing val = %#llx\n", val);
+			nlm_hal_write_64bit_reg(xlp_pic_base, offset, val);
+			return;
+		}
+	}
+#endif
+	printk(KERN_WARNING "Failed to program IRT entry %d\n", irt);
+	return;
+}
 
 /*********************************************************************
  *  pic_init
@@ -366,19 +808,18 @@ void enable_msgconfig_int(void)
 static void pic_init(void)
 {
 	int i = 0;
-	int vcpu;
+	int level, vcpu;
 	uint32_t thread_mask;
 
 	vcpu = hard_smp_processor_id() & 0x1F;
 
 	thread_mask = (1 << vcpu);
 
-	pr_info("%s: Master cpu is %d\n", __func__, vcpu);
-	for (i = 0; i < PIC_NUM_IRTS; i++) {
+	for (i = XLP_IRQ_RESERVED_MAX; i < XLP_IRT_NUM; i++) {
+		level = PIC_IRQ_IS_EDGE_TRIGGERED(i);
 		/* Use local scheduling and high polarity for all IRTs
-		 * Invalidate all IRTs, by default
-		 */
-		nlm_hal_pic_write_irt(i, 0, 0, 1, nlm_hal_irt_to_irq(i), 1, 0, thread_mask);
+		 * Invalidate all IRTs, by default */
+		nlm_hal_pic_write_irt(xlp_irq_to_irt(i), 0, 0, 1, xlp_rvec_from_irq(i), 1, 0, thread_mask);
 	}
 
 	/* On XLP, MSGRING config register is per hw-thread */
@@ -421,16 +862,23 @@ static void nlm_usb_init (void)
  *********************************************************************/
 void nlm_enable_vc_intr(void)
 {
-	int cpu = hard_smp_processor_id();
+	int cpu, node;
 	int vc_index = 0;
 	int i = 0;
 
-	for(i=0; i<NLM_MAX_VC_PER_THREAD; i++)
-	{
-		if(nlm_cpu_vc_mask[cpu] & (1<<i)){
+	for(cpu=0; cpu<NR_CPUS; cpu++){
+                if(!cpu_isset(cpu, cpu_present_map))
+                        continue;
+		node = cpu / 32;
+		for(i=0; i<NLM_MAX_VC_PER_THREAD; i++)
+		{
 			vc_index = (i + cpu*NLM_MAX_VC_PER_THREAD) & 0x7f;
-			/*disable interrupts*/
-			nlm_hal_enable_vc_intr(vc_index);
+			if(nlm_cpu_vc_mask[cpu] & (1<<i)){
+				/*enable interrupts*/
+				nlm_hal_enable_vc_intr(node, vc_index);
+			}else{
+				nlm_hal_disable_vc_intr(node, vc_index);
+			}
 		}
 	}
 }
@@ -449,11 +897,118 @@ void nlm_disable_vc_intr(void)
 		if(nlm_cpu_vc_mask[cpu] & (1<<i)){
 			vc_index = (i + cpu*NLM_MAX_VC_PER_THREAD) & 0x7f;
 			/*enable interrupts*/
-			nlm_hal_disable_vc_intr(vc_index);
+			nlm_hal_disable_vc_intr(0,vc_index);
 		}
 	}
 }
 
+int xlp_fmn_poll(struct napi_struct *napi, int budget)
+{
+	int vc = 0;
+	uint32_t size = 0, code = 0, src_id = 0, cycles = 0;
+	struct msgstn_handler *handler = 0;
+	unsigned int status = 0;
+	uint64_t msg0, msg1, msg2, msg3;
+	int cpu = hard_smp_processor_id();
+	int count = 0;
+	int no_msg = 0;
+	uint32_t napi_vc_mask = xlp_napi_vc_mask & nlm_cpu_vc_mask[cpu];
+#ifdef CONFIG_32BIT
+	unsigned long mflags;
+#endif
+
+	while(count < budget){
+		for( no_msg = 0, vc = 0; vc < 4; vc++)
+		{
+			if(!(napi_vc_mask & (1<<vc)))
+				continue;
+#ifdef CONFIG_32BIT
+			msgrng_access_enable(mflags);
+#endif
+			status = xlp_message_receive( vc, &src_id, &size, &code, &msg0, &msg1, &msg2, &msg3);
+#ifdef CONFIG_32BIT
+			msgrng_access_disable(mflags);
+#endif
+			if(status != 0){
+				no_msg++;
+				continue;
+			}
+			count++;
+			if (is_nlm_xlp3xx()) {
+				handler = &msg_handler_map[xlp3xx_vc_to_handle_map[src_id]];
+			}
+			else {
+				handler = &msg_handler_map[vc_to_handle_map[src_id]];
+			}
+
+			/* Execute device driver fmn handler */
+			(handler->action)(vc, src_id, size, code,
+				  msg0, msg1, msg2, msg3, handler->dev_id);
+		}
+		if(no_msg == xlp_napi_vc_count)
+			break;
+	}
+
+	/*Ack fmn interrupts.*/
+	if(count < budget) {
+		uint32_t val;
+		unsigned long flags;
+		local_irq_save(flags);
+#ifdef CONFIG_32BIT
+		msgrng_access_enable(mflags);
+#endif
+                napi_complete(napi);
+		/* Need write vc into the register */
+		val =  _read_32bit_cp2_register(XLP_MSG_STATUS1_REG);
+		//val |= ((1 << vc) << 16);
+		val |= (napi_vc_mask << 16);
+		_write_32bit_cp2_register(XLP_MSG_STATUS1_REG, val);
+#ifdef CONFIG_32BIT
+		msgrng_access_disable(mflags);
+#endif
+		local_irq_restore(flags);
+		return count;
+	}
+	return budget;
+}
+
+static inline int num_ones(unsigned int mask)
+{
+	int ret = 0;
+
+	if (!mask) return 0;
+	while ((mask &= (mask - 1))) ret++;
+	return (ret + 1);
+}
+
+
+static int xlp_napi_fmn_setup(void)
+{
+	int i, cpu_count;
+	struct napi_struct *napi;
+	int weight_p = 300;
+
+	xlp_napi_vc_count = num_ones(xlp_napi_vc_mask);
+	printk("MSGRING_NAPI: Initializing NLM NAPI subsystem\n");
+
+	init_dummy_netdev(&xlp_napi_fmn_dummy_dev);
+
+	for (cpu_count = 0; cpu_count < NR_CPUS; cpu_count++)
+	{
+		napi = &per_cpu(xlp_napi_fmn_poll_struct, cpu_count);
+		memset(napi, 0, sizeof(*napi));
+		netif_napi_add(&xlp_napi_fmn_dummy_dev, napi, xlp_fmn_poll, weight_p);
+		napi_enable(napi);
+	}
+
+	for (i = 0; i < NR_CPUS; i++) {
+		per_cpu(xlp_napi_fmn_rx_count, i) = 0;
+	}
+	return 0;
+}
+
+
+
 /*********************************************************************
  * on_chip_init
  *  
@@ -469,8 +1024,6 @@ void on_chip_init(void)
 
 	msgring_registered.value = 0;
 
-	on_chip_shutoff_msgring();
-
 	nlm_hal_init();
 
 	pic_init(); 
@@ -479,6 +1032,7 @@ void on_chip_init(void)
 	for (j = 0; j < NLM_MAX_COUNTERS; j++)
 			atomic_set(&nlm_common_counters[i][j], 0);
 
-	/*enable vc interrupts*/
-	nlm_enable_vc_intr();
+	
+	if(xlp_napi_vc_mask)
+		xlp_napi_fmn_setup();
 }
diff --git a/arch/mips/netlogic/xlp/platform.c b/arch/mips/netlogic/xlp/platform.c
index 28ecd01..e0e7dbd 100644
--- a/arch/mips/netlogic/xlp/platform.c
+++ b/arch/mips/netlogic/xlp/platform.c
@@ -1,5 +1,5 @@
 /***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
 reserved.
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are
@@ -34,13 +34,11 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #include <linux/serial_reg.h>
 #include <linux/spinlock.h>
 
-#include <asm/bootinfo.h>
 #include <asm/time.h>
 #include <asm/netlogic/hal/nlm_hal_macros.h>
-#include <asm/netlogic/hal/nlm_hal_pic.h>
+#include <asm/netlogic/xlp_hal_pic.h>
 #include <asm/netlogic/xlp.h>
 #include <asm/netlogic/xlp_usb.h>
-#include <asm/netlogic/iomap.h>
 
 #define XLP_SOC_PCI_DRIVER "XLP SoC Driver"
 #define DEV_IRT_INFO		0x3D
@@ -97,7 +95,7 @@ static void xlp_init_uart(int port_id)
         xlp_uart_port[port_id].mapbase       = DEFAULT_NETLOGIC_IO_BASE 
 						+ NETLOGIC_IO_UART_0_OFFSET + port_id * XLP_UART_PORTIO_OFFSET;
         xlp_uart_port[port_id].membase       = (void __iomem *)xlp_uart_port[port_id].mapbase;
-        xlp_uart_port[port_id].irq           = PIC_UART_0_IRQ + port_id;
+        xlp_uart_port[port_id].irq           = XLP_UART_IRQ(port_id);
 
         xlp_uart_port[port_id].uartclk       = UART_CLK;
         xlp_uart_port[port_id].iotype        = UPIO_NLM;
@@ -108,35 +106,50 @@ static void xlp_init_uart(int port_id)
         xlp_uart_port[port_id].serial_out    = xlp_uart_out;
 }
 
-static void xlp_usb_hw_start(int ctrl_no)
+static void xlp_usb_hw_start_controller(int node, int ctrl_no)
 {
 	int val;
-
-	/* reset USB phy 
-	 */
-	val = usb_reg_read( 0, ctrl_no, XLP_USB_PHY0);
+	/* Reset USB phy */
+	val = usb_reg_read( node, ctrl_no, XLP_USB_PHY0);
 
 	if(ctrl_no == 0)
 		val &= ~(USBPHYRESET | USBPHYPORTRESET0 | USBPHYPORTRESET1);
 	else if(ctrl_no == 3)
-		val &= ~(USBPHYRESET | USBPHYPORTRESET0 | USBPHYPORTRESET1);
-
-	usb_reg_write(0, ctrl_no, XLP_USB_PHY0, val);
+		val &= ~(USBPHYPORTRESET0 | USBPHYPORTRESET1);
+	usb_reg_write(node, ctrl_no, XLP_USB_PHY0, val);
 
 	udelay(2000);
-
-	val = usb_reg_read( 0, ctrl_no, XLP_USB_CTL0);
+	/* Bring usb controller out of reset
+ *  	 */
+	val = usb_reg_read( node, ctrl_no, XLP_USB_CTL0);
 	val &= ~(USBCONTROLLERRESET );
 	val |= 0x4;
-	usb_reg_write(0, ctrl_no, XLP_USB_CTL0, val);
+	usb_reg_write(node, ctrl_no, XLP_USB_CTL0, val);
 
 	return;
 }
 
+static void xlp_usb_hw_start(void)
+{
+	int n, online;
+	int total=num_possible_nodes();
+
+	for(n=0; n<total; n++) {
+		online=node_online(n);
+		if(!online)	continue;
+
+		xlp_usb_hw_start_controller(n, 0);
+		xlp_usb_hw_start_controller(n, 3);
+	}
+}
+
 struct dev2drv dev2drv_table[MAX_DEV2DRV] = {
-	{XLP_DEVID_UART, "serial8250",	sizeof("serial8250"),	0,	PLAT_DRV},
-	{XLP_DEVID_I2C,	 "i2c-xlp",	sizeof("i2c-xlp"),	0, 	PLAT_DRV},
-	{XLP_DEVID_NOR,	 "cfi_probe",	sizeof("cfi_probe"),	0, 	PLAT_DRV},
+	{XLP_DEVID_UART, "serial8250",	11,	0,	PLAT_DRV},
+	{XLP_DEVID_I2C,	 "i2c-xlp",	8,	0, 	PLAT_DRV},
+	{XLP_DEVID_MMC,	 "mmc-xlp",	8,	0, 	PLAT_DRV},
+	{XLP_DEVID_SPI,	 "spi-xlp",	8,	0, 	PLAT_DRV},
+	{XLP_DEVID_NOR,	 "nor-xlp",	8,	0, 	PLAT_DRV},
+	{XLP_DEVID_NAND, "nand-xlp",	9,	0, 	PLAT_DRV},
 	{0x0, 			 "",	0,	0,	PLAT_DRV},
 };
 
@@ -159,10 +172,10 @@ static int xlp_find_pci_dev(void)
 	struct platform_device* pplatdev;
 	struct resource* pres;
 
-	pres = (struct resource*) kmalloc(sizeof(struct resource) * 2, 
-			GFP_KERNEL);
+	pres = (struct resource*) kzalloc(sizeof(struct resource) * 2, GFP_KERNEL);
+
 	if(!pres) {
-		printk("kmalloc struct resource failedi!\n");
+		printk("kzalloc struct resource failedi!\n");
 		return -ENOMEM;
 	}
 
@@ -212,46 +225,36 @@ static int xlp_find_pci_dev(void)
 							xlp_init_uart(dev2drv_table[idx].id);
 						}
 
-						dev2drv_table[idx].id = dev2drv_table[idx].id + 1;	
+						dev2drv_table[idx].id = dev2drv_table[idx].id + 1;
 
 						pres[0].start	= mmio;
-						pres[0].end		= mmio;
+						pres[0].end	= mmio;
 						pres[0].flags	= IORESOURCE_MEM;
-
 						irt = (nlm_hal_read_32bit_reg(mmio, DEV_IRT_INFO) & 0xFFFF);
-					   	if(nlm_hal_is_shared_irt(irt))
-							irq = nlm_hal_request_shared_irq(irt);
-						else
-							irq = nlm_hal_irt_to_irq(irt);
+						irq = xlp_irt_to_irq(irt);
 
-						pres[1].start	= irq;
-						pres[1].end		= irq;
-						pres[1].flags	= IORESOURCE_IRQ;
+						pres[1].start = irq;
+						pres[1].end = irq;
+						pres[1].flags = IORESOURCE_IRQ;
 
 						platform_device_add_resources(pplatdev, pres, 2);
-
 						pplatdev->dev.dma_mask	= &xlp_dev_dmamask;
-
 						pplatdev->dev.coherent_dma_mask = DMA_BIT_MASK(32);
-
-						platform_device_add( pplatdev);
+						platform_device_add(pplatdev);
 					}
 				}
 			}
 		}
 	}
 	kfree(pres);
-	return 0;	
+	return 0;
 }
-
-
-
 static int __init platform_devinit(void)
 {
 	xlp_find_pci_dev();
+
 #ifdef CONFIG_USB
-	xlp_usb_hw_start(0);
-	xlp_usb_hw_start(3);
+	xlp_usb_hw_start();
 #endif
 	return 0;
 }
diff --git a/arch/mips/netlogic/xlp/setup.c b/arch/mips/netlogic/xlp/setup.c
index 30c69eb..b0ca7db 100644
--- a/arch/mips/netlogic/xlp/setup.c
+++ b/arch/mips/netlogic/xlp/setup.c
@@ -49,6 +49,7 @@
 #include <asm/netlogic/iomap.h>
 #include <asm/netlogic/debug.h>
 #include <asm/netlogic/xlp.h>
+#include <asm/netlogic/msgring.h>
 #include <asm/netlogic/memory-exclusion.h>
 #include <linux/serial.h>
 #include <linux/serial_core.h>
@@ -58,11 +59,10 @@
 #include <asm/netlogic/bootinfo.h>
 #include <asm/netlogic/cpumask.h>
 #include <asm/netlogic/hal/nlm_hal_macros.h>
-#include <asm/netlogic/hal/nlm_hal_pic.h>
-#include <asm/netlogic/hal/nlm_hal_nae.h>
-
+#include <asm/netlogic/xlp_hal_pic.h>
 #include <asm/mach-netlogic/nlm_kexec.h>
 #include "../boot/ops.h"
+#include "cpu_control_macros.h"
 
 /* Certain macros for this file
  */
@@ -85,6 +85,7 @@ extern char _end;
 extern void *fdt;
 
 EXPORT_SYMBOL(fdt);
+EXPORT_SYMBOL(dt_ops);
 
 extern void *fdt_init(void *blob);
 extern void *simple_alloc_init(char *base, unsigned long heap_size,
@@ -94,8 +95,14 @@ extern unsigned int xlp_uart_in(struct uart_port *p, int offset);
 extern void xlp_uart_out(struct uart_port *p, int offset, int value);
 
 extern void (*board_nmi_handler_setup)(void );
+extern unsigned long _text[];
 extern cpumask_t fdt_cpumask;
-
+extern cpumask_t fdt_loadermask;
+int xlp_loader_support = 0;
+#ifdef CONFIG_NUMA
+int hcpu_to_lcpu[NR_CPUS];
+#endif
+unsigned int xlp_napi_vc_mask = 0;
 struct proc_dir_entry *nlm_root_proc;
 EXPORT_SYMBOL(nlm_root_proc);
 
@@ -107,7 +114,37 @@ unsigned int xlp_uart_portid = 0;
 
 static char prop_buf[MAX_PROP_LEN];
 
+void *nlm_common_psb_shm = 0;
+unsigned long nlm_common_psb_shm_size = 0;
+
+#ifdef CONFIG_NUMA
+struct nlm_node_mem_info node_mem_info[NLM_MAX_CPU_NODE];
+/* number of nodes */
+static int nlm_nodes=1;
+#endif
+
+#ifdef CONFIG_NLMCOMMON_GLOBAL_TLB_SPLIT_ASID
+unsigned long nlm_asid_mask = 0x3f;
+unsigned int nlm_shtlb = 1; /* by default shared TLB is enabled */
+#endif
+
+const char *DEFAULT_CONSOLE_BOOT_PARAMS = "boot_noi2c mem=255m@1m mem=512m@512m console=ttyS0,115200 ";
+const char *DEFAULT_INITRD_BOOT_PARAMS = "rdinit=/sbin/init ";
+
+#ifdef CONFIG_SMP
+atomic_t cpus_rebooted = ATOMIC_INIT(0);
+#endif
+
 unsigned long long nlm_common_tlb_stats[NR_CPUS] __cacheline_aligned;
+spinlock_t atomic_lock = SPIN_LOCK_UNLOCKED;
+
+int hwemul = 0;
+EXPORT_SYMBOL(hwemul);
+
+/* A flag to indicate whether certain xlp8xx/832/816/432/416/408/208/204/104 a0/a1 workaround
+ * is needed or not.
+ */
+int xlp8xx_a01_workaround_needed = 0;
 
 /* Struct for temp. allocation
  * of sp/gp for secondary CPUs
@@ -193,14 +230,10 @@ const char *get_system_type(void)
 	return "Netlogic XLP SoC";
 }
 
-extern void reset_nae(void);
-extern void on_chip_shutoff_msgring(void);
-
 static void ptr_linux_exit(void)
 {
-	/* trigger a chip reset */
-	 nlm_hal_write_sys_reg(CHIP_RESET, 1);
-
+	// trigger a chip reset
+	 nlm_hal_write_sys_reg(netlogic_node_id(), CHIP_RESET, 1);
 	 for ( ; ; )
 		  cpu_wait();
 }
@@ -222,6 +255,42 @@ void prom_reconfigure_thr_resources(void)
 	/* Configure thread resources only if it is thread_0 of that core */
 	if (netlogic_thr_id() != 0) return;
 
+#ifdef CONFIG_NLMCOMMON_GLOBAL_TLB_SPLIT_ASID
+	uint32_t map;
+
+	/* netlogic kernel configures this
+	 */
+	if (nlm_shtlb && (nlm_asid_mask == 0x3f)) {
+
+		uint32_t online_map = smp_node.onlinemask[0];    /* from fdt */
+
+		/* Global TLB will work only if all
+		 * the enabled cores have all their
+		 * threads owned by Linux.
+		 */
+		map = online_map;
+		for (i = 0; i < NR_CPUS; i += 4) {
+			if ((map & 0xf) && ((map & 0xf) != 0xf)) {
+				nlm_asid_mask = 0xff;
+				nlm_shtlb = 0;
+				printk("Disabling Shared TLB mode\n");
+				break;
+			}
+			map >>= 4;
+		}
+		if ((nlm_asid_mask == 0x3f) && (netlogic_thr_id() == 0)) {
+			mmu_setup = read_32bit_nlm_ctrl_reg(CPU_BLOCKID_MMU, 0);
+			mmu_setup = mmu_setup | 0x1;
+			write_32bit_nlm_ctrl_reg(CPU_BLOCKID_MMU, 0, mmu_setup);
+
+			printk("CPU %d: Enabled Shared TLB mode \n",
+					netlogic_cpu_id());
+			return;
+		}
+	}
+	return;
+#endif /* CONFIG_NLMCOMMON_GLOBAL_TLB_SPLIT_ASID */
+
 	/* cpu has to be thread@0 */
 	cpu = hard_smp_processor_id();
 
@@ -252,14 +321,14 @@ void prom_reconfigure_thr_resources(void)
 
 unsigned int __cpuinit get_c0_compare_int(void)
 {
-    return IRQ_TIMER;
+    return XLP_IRQ_TIMER;
 }
 
 /* TODO: Get this from FDT */
 void plat_time_init(void)
 {
 	extern void nlm_common_timer_setup(void);
-	mips_hpt_frequency = (unsigned int) nlm_hal_cpu_freq();
+	mips_hpt_frequency = (unsigned int) get_cpu_freq(XLP_CPU0);
 	printk("mips_hpt_frequency = %u\n", mips_hpt_frequency);
 	nlm_common_timer_setup();
 }
@@ -291,7 +360,6 @@ static void prom_add_memory(uint64_t start, uint64_t size)
 	return;
 }
 
-
 /* setup early serial port driver */
 #ifdef CONFIG_SERIAL_8250
 #define UART_CLK 133333333
@@ -311,7 +379,7 @@ static void nlm_early_serial_setup(int uart_id)
 	switch(uart_id){
 		default:
 		case 0:
-			s.irq =  PIC_UART_0_IRQ;
+			s.irq = XLP_UART_IRQ(0);
 			s.membase = (unsigned char __iomem *)
 			(DEFAULT_NETLOGIC_IO_BASE + NETLOGIC_IO_UART_0_OFFSET);
 			s.mapbase = (DEFAULT_NETLOGIC_IO_BASE +
@@ -319,7 +387,7 @@ static void nlm_early_serial_setup(int uart_id)
 			s.line = 0;
 			break;
 		case 1:
-			s.irq =  PIC_UART_1_IRQ;
+			s.irq =  XLP_UART_IRQ(1);
 			s.membase = (unsigned char __iomem *)
 			(DEFAULT_NETLOGIC_IO_BASE + NETLOGIC_IO_UART_1_OFFSET);
 			s.mapbase = (DEFAULT_NETLOGIC_IO_BASE +
@@ -339,21 +407,80 @@ static void nlm_early_serial_setup(int uart_id) {}
 
 extern struct plat_smp_ops nlm_smp_ops;
 
-#define MAX_CPUMASK_CELLS NLM_MAX_CPU_NODE
+#define MAX_CPUMASK_CELLS 4
 #define fdt32_to_cpu(x) be32_to_cpu(x)
 
+int nlm_get_fdt_app_param(const char *param, void *data, int size)
+{
+	void *node;
+	node = finddevice("/doms/dom@0/app-param");
+	if(node) {
+		if (getprop(node, param, data, size) > 0)
+			return 0;
+	}
+	return -1;
+}
+EXPORT_SYMBOL(nlm_get_fdt_app_param);
+
+int nae_rx_vc = -1, nae_fb_vc = -1;
+int sae_rx_vc = -1, sae_rx_sync_vc = -1;
+int ipsec_async_vc = -1, ipsec_sync_vc = -1;
+static void parse_fdt_sae_vc_config()
+{
+	void *node;
+	int i;
+	node = finddevice("/doms/dom@0/cpu");
+	extern uint32_t nlm_cpu_vc_mask[NLM_MAX_CPU_NODE*NLM_MAX_CPU_PER_NODE];
+	if(node) {
+		if (getprop(node, "nae-rx-vc", &nae_rx_vc, 4) > 0)
+                        nae_rx_vc = fdt32_to_cpu(nae_rx_vc);
+
+		if (getprop(node, "nae-fb-vc", &nae_fb_vc, 4) > 0)
+                        nae_fb_vc = fdt32_to_cpu(nae_fb_vc);
+
+		if (getprop(node, "sae-rx-vc", &sae_rx_vc, 4) > 0) 
+			sae_rx_vc = fdt32_to_cpu(sae_rx_vc);
+		
+		if (getprop(node, "sae-rx-sync-vc", &sae_rx_sync_vc, 4) > 0)
+			sae_rx_sync_vc = fdt32_to_cpu(sae_rx_sync_vc);
+
+		if (getprop(node, "ipsec-async-vc", &ipsec_async_vc, 4) > 0)
+			ipsec_async_vc = fdt32_to_cpu(ipsec_async_vc);
+
+		if (getprop(node, "ipsec-sync-vc", &ipsec_sync_vc, 4) > 0)
+			ipsec_sync_vc = fdt32_to_cpu(ipsec_sync_vc);
+		
+		for(i =0 ; i < NLM_MAX_CPU_NODE*NLM_MAX_CPU_PER_NODE; i++) {
+			if(nlm_cpu_vc_mask[i] & (1 << ipsec_sync_vc)) {
+				ipsec_sync_vc = -1;
+			}
+				 
+		}
+	}
+
+	return;
+}
+EXPORT_SYMBOL(nae_rx_vc);
+EXPORT_SYMBOL(nae_fb_vc);
+EXPORT_SYMBOL(sae_rx_vc);
+EXPORT_SYMBOL(sae_rx_sync_vc);
+EXPORT_SYMBOL(ipsec_async_vc);
+EXPORT_SYMBOL(ipsec_sync_vc);
+
+
 static int fdt_process(void)
 {
 	int  domain=0;
 	char domstr[32] = "";
-	int  i, na, ns, regs[6], entries, cpu_cells;
-	uint32_t node_vc_mask[4] = {0};
+	uint32_t  i, na, ns, regs[MAX_PROP_LEN / 4], entries, cpu_cells;
+	uint32_t node_vc_mask[NLM_MAX_CPU_NODE] = {0};
 	extern uint32_t nlm_cpu_vc_mask[NLM_MAX_CPU_NODE*NLM_MAX_CPU_PER_NODE];
 	unsigned char buf[30];
 	int j, id=0, k, tmp;
 	uint32_t onlinemask[MAX_CPUMASK_CELLS];
 	int have_kexec_cmdline = 0;
 	int boot_for_kdump = 0;
+ 	uint32_t linux_loader_mask[MAX_CPUMASK_CELLS] = {0};
 
 	/* If booted using FDT and U-Boot, all
 	 * we get is a pointer to an FDT Blob
@@ -379,7 +506,26 @@ static int fdt_process(void)
 		}
 	}
 
+	if (is_kexec_boot()) {
+		/* Copy out the cmdline from the kexec control page reserved by parent kernel */
+		memset(prop_buf, '\0', MAX_PROP_LEN);
+		pr_debug("%s: copy cmdline from %p\n", __func__, kexec_cmdline_addr(blob));
+		memcpy(prop_buf, kexec_cmdline_addr(blob), MAX_PROP_LEN);
+		pr_debug("%s: cmdline = \n%s\n", __func__, prop_buf);
+		if (strncmp(prop_buf, "kexec ", 6) == 0) {
+			have_kexec_cmdline = 1;
+			/* elfcorehdr= is passed by kexec-tools when
+			 * booting from kernel panic.
+			 */
+			if ((strstr(prop_buf, "elfcorehdr=")) != NULL) {
+				pr_debug("%s: Boot from kernel panic\n", __func__);
+				boot_for_kdump = 1;
+			}
+		}
+	}
+
 	cpumask_clear(&fdt_cpumask);
+	cpumask_clear(&fdt_loadermask);
 
 	if(!blob)
 		return -1;
@@ -419,6 +565,13 @@ static int fdt_process(void)
 	 */
 	node = finddevice("/doms/dom@0");
 	if (node) {
+#ifdef CONFIG_NUMA
+		if (getprop(node, "#nodes", &nlm_nodes, sizeof(nlm_nodes)) < 0)
+			nlm_nodes = 1;
+		else
+			nlm_nodes = fdt32_to_cpu(nlm_nodes);
+#endif
+
 		if (getprop(node, "#address-cells", &na, sizeof(na)) < 0)
 			na = 1;
 		else
@@ -451,20 +604,31 @@ static int fdt_process(void)
 		 */
 		node = finddevice("/doms/dom@0/memory");
 		if (node) {
-			entries = (getprop(node, "reg", regs, sizeof(regs))) / sizeof(regs[0]);
+			entries = (getprop(node, "reg", regs, MAX_PROP_LEN)) / sizeof(regs[0]);
 			if (!entries || (entries % (na+ns)))
 				printk("Invalid Memory Map Specified!\n");
 
-			for (i = 0; i < entries; i += 2) {
-				unsigned long long addr, size;
+			for (i=0; i<entries; i+=na+ns) {
+				int base = i;
+				uint64_t addr, size;
 
-				addr = fdt32_to_cpu(regs[i]);
-				size = fdt32_to_cpu(regs[i + 1]);
+				addr = fdt32_to_cpu(regs[base++]);
+				if (na == 2)
+				{
+					/* handle 2 address-cells (ie. 64-bits of address) */
+					addr <<= 32;
+					addr |= fdt32_to_cpu(regs[base++]);
+				}
 
-				if (size == 0)
-					continue;
+				size = fdt32_to_cpu(regs[base++]);
+				if (ns == 2)
+				{
+					/* handle 2 size-cells (ie. 64-bits of size) */
+					size <<= 32;
+					size |= fdt32_to_cpu(regs[base++]);
+				}
 
-				sprintf(domstr, " mem=%lldm@%lldm ", size, addr);
+				sprintf(domstr, " mem=%lldm@%lldm ", (size >> 20), (addr >> 20));
 				strcat(arcs_cmdline, domstr);
 				memset((void *)&domstr, '\0', sizeof(domstr));
 			}
@@ -516,10 +680,75 @@ static int fdt_process(void)
 			}
 		}
 
+		if(getprop(node, "napi-vc-mask", &xlp_napi_vc_mask, sizeof(uint32_t)) < 0){
+			xlp_napi_vc_mask = 0x0;
+		}else{
+			xlp_napi_vc_mask = fdt32_to_cpu(xlp_napi_vc_mask);
+		}
+		printk("xlp_napi_vc_mask %#x\n", xlp_napi_vc_mask);
+
 		cpumask_scnprintf(buf, CPUMASK_BUF, &fdt_cpumask);
 		printk("fdt_cpumask: %s\n", buf);
 	}
 
+	sprintf(domstr, "/doms/dom@%d/linuxloader", domain);
+	node = finddevice(domstr);
+	if (node) {
+		uint32_t loadermask_buf[MAX_CPUMASK_CELLS], index;
+		char buf[CPUMASK_BUF];
+
+		xlp_loader_support = 1;
+		/* Initialize buffers */
+		for (i = 0; i < MAX_CPUMASK_CELLS; i++)
+			loadermask_buf[i] = 0;
+
+		/* Parse cpumask from FDT and handle endianness */
+		if((getprop(node, "loadermask", &loadermask_buf[0], sizeof(uint32_t) * cpu_cells) < 0)){
+			xlp_loader_support = 0;
+			goto noloadermask;
+		}
+
+		for (i = 0; i < cpu_cells; i++) {
+			loadermask_buf[i] = fdt32_to_cpu(loadermask_buf[i]);
+
+			printk("FDT: cpu_cells: %d loadermask_buf[%d]: %#08x\n",
+			       cpu_cells, i, loadermask_buf[i]);
+		}
+
+		/* Store cpumask in predefined order */
+		for (i = 0; i < cpu_cells; i++){
+			linux_loader_mask[i] = loadermask_buf[cpu_cells - 1 - i];
+			printk("linux_loader_mask[%d] = %#x\n",i,linux_loader_mask[i]);
+		}
+
+		for (i = 0; i < MAX_CPUMASK_CELLS; i++) {
+			int j = 0;
+
+			for (j = 0; j < 32; j++) {
+				if ((linux_loader_mask[i] & (1 << j)) == 0)
+					continue;
+				cpumask_set_cpu((i * 32 + j), &fdt_loadermask);
+			}
+		}
+
+		entries = (getprop(node, "memory", regs, sizeof(regs))) / sizeof(regs[0]);
+		if (!entries || (entries % (na+ns))){
+			printk("Invalid Memory Map Specified!\n");
+			xlp_loader_support = 0;
+			goto noloadermask;
+		}
+		for (i=0,index=0; i<entries; i+=4, index++) {
+				unsigned long long lsb_addr, msb_addr, lsb_size, msb_size;
+				msb_addr = fdt32_to_cpu(regs[i]);
+				lsb_addr = fdt32_to_cpu(regs[i + 1]);
+				msb_size = fdt32_to_cpu(regs[i + 2]);
+				lsb_size = fdt32_to_cpu(regs[i + 3]);
+		}
+noloadermask:
+		cpumask_scnprintf(buf, CPUMASK_BUF, &fdt_loadermask);
+		printk("fdt_loadermask: %s\n", buf);
+	}
+
 	node = finddevice("/doms/dom@0/fmn");
 	if (node) {
 		for (i = 0; i < NLM_MAX_CPU_NODE; i++) {
@@ -535,7 +764,7 @@ static int fdt_process(void)
 				}
 			}
 			else {	/* Get vc mask from the fdt */
-				for (j = 0; j < 4; j++) {
+				for (j = 3; j >= 0; j--) {
 					tmp = fdt32_to_cpu(node_vc_mask[j]);
 					for (k = 0; k < 8; k++) {
 						nlm_cpu_vc_mask[id++] = (tmp >> (k * 4)) & 0xf;
@@ -561,88 +790,98 @@ static int fdt_process(void)
 		if (getprop(node, "id", &xlp_uart_portid, sizeof(xlp_uart_portid)) < 0)
 			return -1;
 	}
+	/* Parse the sae async/sync vcs for linux userspace model */
+	parse_fdt_sae_vc_config();
 
 	return 0;
 }
 
-static int get_xlp_proc_name(void)
+char* get_cpu_info(void)
 {
-	int processor_id = ((read_c0_prid() & 0xff00) >> 8);
-
-	switch (processor_id) {
-	case CHIP_PROCESSOR_ID_XLP_8XX:
-	case CHIP_PROCESSOR_ID_XLP_832:
-		strcpy(cpu_model_info, "XLP832");
-		break;
-	case CHIP_PROCESSOR_ID_XLP_816:
-		strcpy(cpu_model_info, "XLP816");
-		break;
-	case CHIP_PROCESSOR_ID_XLP_432:
-		strcpy(cpu_model_info, "XLP432");
-		break;
-	case CHIP_PROCESSOR_ID_XLP_416:
-		strcpy(cpu_model_info, "XLP416");
-		break;
-	case CHIP_PROCESSOR_ID_XLP_408:
-		strcpy(cpu_model_info, "XLP408");
-		break;
-	case CHIP_PROCESSOR_ID_XLP_316:
-		strcpy(cpu_model_info, "XLP316");
-		break;
-	case CHIP_PROCESSOR_ID_XLP_308:
-		strcpy(cpu_model_info, "XLP308");
-		break;
-	case CHIP_PROCESSOR_ID_XLP_304:
-		strcpy(cpu_model_info, "XLP304");
-		break;
-	case CHIP_PROCESSOR_ID_XLP_208:
-		strcpy(cpu_model_info, "XLP208");
-		break;
-	case CHIP_PROCESSOR_ID_XLP_204:
-		strcpy(cpu_model_info, "XLP204");
-		break;
-	case CHIP_PROCESSOR_ID_XLP_104:
-		strcpy(cpu_model_info, "XLP104");
-		break;
-	default:
-		strcpy(cpu_model_info, "XLP???");
-		return -1;
+	struct nlm_netl_proc_info cpu_info;
+	if(nlm_hal_get_cpuinfo(&cpu_info)){
+		strcpy(cpu_model_info, cpu_info.cpu_info_str);
+	}else{
+		strcpy(cpu_model_info, "Unknown CPU");
 	}
-
-	return 0;
+	return cpu_model_info;
 }
 
-static int get_xlp_revision(void)
+#ifdef CONFIG_XEN
+extern void xen_init(void);
+#else
+static void xen_init(void) {}
+#endif
+
+#ifdef CONFIG_NUMA
+static void sort_mem_info(struct nlm_node_mem_info *info, unsigned long *spfn,
+	unsigned long *epfn)
 {
-	int revision = read_c0_prid() & 0xff;
-
-	switch (revision) {
-	case XLP_REVISION_A0:
-		strcpy(cpu_model_info + PROCESSOR_ID_MAX_LEN, " Rev A0");
-		break;
-	case XLP_REVISION_A1:
-		strcpy(cpu_model_info + PROCESSOR_ID_MAX_LEN, " Rev A1");
-		break;
-	case XLP_REVISION_A2:
-		strcpy(cpu_model_info + PROCESSOR_ID_MAX_LEN, " Rev A2");
-		break;
-	default:
-		strcpy(cpu_model_info + PROCESSOR_ID_MAX_LEN, " Rev ??");
-		return -1;
+	struct nlm_node_mem_frag *list = info->mem;
+	int i,j;
+
+	uint64_t start_pfn = 0;
+	uint64_t end_pfn = 0;
+
+	*spfn = *epfn = 0;
+	if(info->frags == 0)
+		return;
+
+	for(i=0; i < info->frags; i++) {
+		for (j = i; j < info->frags; j++) {
+			if (list[i].start_pfn > list[j].start_pfn) {
+				start_pfn = list[i].start_pfn;
+				end_pfn = list[i].end_pfn;
+				list[i].start_pfn = list[j].start_pfn;
+				list[i].end_pfn = list[j].end_pfn;
+				list[j].start_pfn = start_pfn;
+				list[j].end_pfn = end_pfn;
+			}
+		}
 	}
+	*spfn = list[0].start_pfn;
+	*epfn = list[info->frags-1].end_pfn;
+}
 
-	return 0;
+void __init prom_meminit(void)
+{
+	int node=0;
+	unsigned long start_pfn, end_pfn;
+	struct nlm_mem_info *minfo;
+
+	/* sort the node_mem_map */
+	for(node=0; node < nlm_nodes; node++) {
+        	sort_mem_info(&node_mem_info[node], &start_pfn, &end_pfn);
+        	minfo = NODE_MEM_DATA(node);
+        	minfo->low_pfn = start_pfn;
+        	minfo->high_pfn = end_pfn;
+	}
 }
 
-char* get_cpu_info(void)
+extern struct nlm_node_data __node_data_holder[];
+void __init build_node_cpu_map(void)
 {
-	get_xlp_proc_name();
-	get_xlp_revision();
+	int cpu, node,i;
 
-	return cpu_model_info;
-}
+	/* kernel expects all node_data to initialized
+ 	 * If a node has its own memory, we will overwrite this pointer
+ 	 */
+	for(node=0; node < MAX_NUMNODES; node++) {
+		__node_data[node] = &__node_data_holder[node];
+	}
 
-static void xen_init(void) {}
+	i=0;
+	for_each_cpu(cpu, &fdt_cpumask) {
+		node = hardcpu_to_node(cpu);
+		hcpu_to_lcpu[cpu] = i;
+		if(!node_online(node)) {
+			node_set_online(num_online_nodes());
+		}
+		i++;
+	}
+	printk("Number of online nodes = %d\n", num_online_nodes());
+}
+#endif
 
 #ifdef CONFIG_KEXEC
 extern void nlm_kexec_init(void);
@@ -654,13 +893,34 @@ void __init prom_init(void)
 {
 	void (*wakeup)(void *);
 
+#ifdef CONFIG_NLM_ENABLE_COP2
+	unsigned int c0status;
+#endif
+
+#ifdef CONFIG_MAPPED_KERNEL
 	setup_mapped_kernel_tlbs(TRUE, TRUE);
+#endif
 
 	fdt_process();
+
+#ifdef CONFIG_NUMA
+	build_node_cpu_map();
+#endif
+
 	xen_init();
 
 	nlm_common_ebase = read_c0_ebase() & (~((1 << 12) - 1));
 
+	/* FIXME: we should also remove it for xlp8xx a2, but we do not have interface function
+	 * for it yet. Once A1 is phased out in the field, this workaround code should be removed.
+	 */
+	xlp8xx_a01_workaround_needed = is_nlm_xlp8xx_ax();
+
+#ifdef CONFIG_NLM_ENABLE_COP2
+	// workaround. trap_init enables cop2. But this function gets called before trap_init
+	c0status = read_c0_status() | ST0_CU2;
+	write_c0_status(c0status);
+#endif
 	cpumask_clear(&smp_boot.online_map);
 	cpumask_set_cpu(hard_smp_processor_id(), &smp_boot.online_map);
 
@@ -696,7 +956,10 @@ void prom_free_prom_memory(void)
 	/* nothing to free */
 }
 
-#define KSEG0 0xffffffff80000000
+#ifndef KSEG0
+#define KSEG0 0xffffffff80000000ULL
+#endif
+
 #define RING_BUFFER_BASE (511 << 20)
 #define RING_BUFFER_SIZE (8 << 10)
 static void outbyte_ring_buffer(char c)
@@ -727,9 +990,28 @@ void nlm_early_printk(const char *fmt, ...)
 }
 
 #ifdef CONFIG_EARLY_PRINTK
+static void NS16550_putc(char c)
+{
+	nlm_reg_t *mmio;
+	switch(xlp_uart_portid){
+		default:
+		case 0:
+			mmio = netlogic_io_mmio(NETLOGIC_IO_UART_0_OFFSET);
+			break;
+		case 1:
+			mmio = netlogic_io_mmio(NETLOGIC_IO_UART_1_OFFSET);
+			break;
+	}
+	while (netlogic_read_reg( mmio, 0x5) == 0);
+		netlogic_write_reg( mmio, 0x0, c);
+}
+
 void prom_putchar(char c)
 {
-	xlp_prom_putchar(c);
+	void (*putchar)(char);
+
+	putchar = ((void (*)(char c))(unsigned long)(&NS16550_putc));
+	putchar(c);
 }
 #endif
 
diff --git a/arch/mips/netlogic/xlp/smp.c b/arch/mips/netlogic/xlp/smp.c
index 5b1a0bd..f9f967a 100644
--- a/arch/mips/netlogic/xlp/smp.c
+++ b/arch/mips/netlogic/xlp/smp.c
@@ -24,6 +24,7 @@ THE POSSIBILITY OF SUCH DAMAGE.
 *****************************#NETL_2#********************************/
 
 #include <linux/kernel.h>
+#include <linux/module.h>
 #include <linux/delay.h>
 #include <linux/init.h>
 #include <linux/smp.h>
@@ -32,11 +33,14 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #include <asm/mipsregs.h>
 #include <asm/mmu_context.h>
 #include <asm/atomic.h>
+#include <asm/cacheops.h>
 
 #include <asm/netlogic/xlp.h>
 #include <asm/netlogic/mips-exts.h>
 #include <asm/netlogic/interrupt.h>
-#include <asm/netlogic/hal/nlm_hal_pic.h>
+#include <asm/netlogic/xlp_hal_pic.h>
+#include <asm/netlogic/hal/nlm_hal_fmn.h>
+#include <linux/module.h>
 
 #include <asm/asm.h>
 #include <asm/mipsregs.h>
@@ -49,7 +53,11 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #include "cpu_control_macros.h"
 
 struct smp_boot_info smp_boot;
+EXPORT_SYMBOL(smp_boot);
 cpumask_t fdt_cpumask;
+cpumask_t fdt_loadermask;
+cpumask_t phys_cpu_present_map;
+EXPORT_SYMBOL(phys_cpu_present_map);
 
 void nlm_enable_vc_intr(void);
 extern void ptr_smp_boot(unsigned long, unsigned long, unsigned long);
@@ -59,24 +67,26 @@ extern void enable_cpus(unsigned int node, unsigned online_mask);
 extern void nlm_smp_irq_init(void);
 extern void asmlinkage smp_bootstrap(void);
 extern void enable_msgconfig_int(void);
+extern void xlp_pic_ite_init(const struct cpumask *);
 
-void nlm_send_ipi_single(int cpu, unsigned int action)
+void nlm_send_ipi_single(int logical_cpu, unsigned int action)
 {
+	int cpu = cpu_logical_map(logical_cpu);
         __u32 node = cpu / 32;
         __u32 ipi = 0;
 	__u8 nmi = 0;
 	cpu = cpu % 32;
 
         if (action & SMP_CALL_FUNCTION) {
-                ipi |= IRQ_IPI_SMP_FUNCTION;
+                ipi |= XLP_IRQ_IPI_SMP_FUNCTION;
 	} else if (action & SMP_RESCHEDULE_YOURSELF) {
-                ipi |= IRQ_IPI_SMP_RESCHEDULE;
+                ipi |= XLP_IRQ_IPI_SMP_RESCHEDULE;
 	} else if (action & SMP_CALL_KGDB_HOOK) {
-                ipi |= IRQ_IPI_SMP_KGDB;
+                ipi |= XLP_IRQ_IPI_SMP_KGDB;
 		/* for KGDB enable NMI also */
 		nmi = 1;
 	} else if (action & SMP_OPROFILE_IPI) {
-                ipi |= IRQ_IPI_OPROFILE;
+                ipi |= 51;
         } else
 		return;
 
@@ -102,9 +112,8 @@ static void __cpuinit nlm_init_secondary(void)
 {
     /* Time init for this cpu is done in mips_clockevent_init() */
     nlm_smp_irq_init();
-
     enable_msgconfig_int();
-
+#ifdef CONFIG_NLM_XLP_A0_WORKAROUNDS
     /* Workaround for XLP A0 Multi-Node bug */
     {
 	    int cpu = hard_smp_processor_id();
@@ -114,7 +123,7 @@ static void __cpuinit nlm_init_secondary(void)
 		    nlm_common_timer_setup();
 	    }
     }
-
+#endif
     /* Enable vc interupts for this thread*/
     nlm_enable_vc_intr();
 }
@@ -124,6 +133,21 @@ extern void fixup_irqs(unsigned int cpu, int flag);
 static DEFINE_SPINLOCK(smp_reserve_lock);
 static atomic_t __cpuinitdata cpu_hotplug_flag = ATOMIC_INIT(0);
 
+void set_ite(uint32_t bitmask)
+{
+	u64 xlp_pic_base = XLP_BDF_BASE(0,0,4);
+	/* Right shift by 1 is required by HAL, _DO_NOT_REMOVE_ */
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0x94 >> 1, (0x00000001 & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0x98 >> 1, (0xffffffff & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0x9C >> 1, (0x000000ff & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0xA0 >> 1, (0x0000ff00 & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0xA4 >> 1, (0x00ff0000 & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0xA8 >> 1, (0xff000000 & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0xAC >> 1, (0x0000ffff & bitmask));
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0xB0 >> 1, (0xffff0000 & bitmask));
+	/* We don't populate redirection to other nodes now */
+}
+
 static int __cpuinit nlm_cpu_callback(struct notifier_block *nfb,
 	unsigned long action, void *hcpu)
 {
@@ -159,12 +183,18 @@ late_initcall(register_nlm_notifier);
 void nlm_smp_finish(void)
 {
 #ifdef CONFIG_HOTPLUG_CPU
+	int cpu = hard_smp_processor_id();
+	uint32_t bitmask = 0;
+
 	if (atomic_read(&cpu_hotplug_flag)) {
 		spin_lock(&smp_reserve_lock);
 		local_irq_disable();
 		/* Enable IRQs on the cpu */
 		fixup_irqs(smp_processor_id(), 1);
 		local_irq_enable();
+		bitmask = cpumask_to_uint32(&cpu_online_map);
+		bitmask = bitmask | (1 << cpu);
+		set_ite(bitmask);
 		spin_unlock(&smp_reserve_lock);
 	}
 #endif
@@ -172,14 +202,19 @@ void nlm_smp_finish(void)
 
 void nlm_cpus_done(void)
 {
+	extern void *fdt;
+	nlm_hal_fmn_init(fdt);
 }
 
 /* Boot all other cpus in the system, initialize them, and
    bring them into the boot fn */
-void nlm_boot_secondary(int cpu, struct task_struct *idle)
+void nlm_boot_secondary(int logical_cpu, struct task_struct *idle)
 {
 	unsigned long gp = (unsigned long)task_thread_info(idle);
 	unsigned long sp = (unsigned long)__KSTK_TOS(idle);
+	int cpu = cpu_logical_map(logical_cpu);
+	
+	printk("nlm_boot_secondary: logical cpu %d physical cpu %d\n", logical_cpu, cpu);
 
 
 	smp_boot.boot_info[cpu].sp = sp;
@@ -202,14 +237,19 @@ void __init nlm_smp_setup(void)
 
 	/* Initialize maps */
 	for (i = 0; i < NR_CPUS; i++) {
-		__cpu_number_map[i] = 0;
-		__cpu_logical_map[i] = boot_cpu;
+		__cpu_number_map[i] = NR_CPUS + 1; /* Set to invalid value */
+		__cpu_logical_map[i] = NR_CPUS + 1; /* Set to invalid value */
 	}
 
 	/* Setup map for master cpu */
 	__cpu_number_map[boot_cpu] = 0;
 	__cpu_logical_map[0] = boot_cpu;
 	num_cpus = 1;
+	cpumask_clear(&cpu_possible_map);
+	cpumask_clear(&cpu_present_map);
+	cpumask_clear(&phys_cpu_present_map);
+	cpu_set(0, cpu_possible_map);
+	cpu_set(boot_cpu, phys_cpu_present_map);
 
 	/* Setup map for other cpus */
 	for (i = 0; i < NR_CPUS; i++) {
@@ -217,20 +257,23 @@ void __init nlm_smp_setup(void)
 		if (i == boot_cpu) continue;
 
 		if (cpumask_test_cpu(i, &fdt_cpumask)) {
-
 			__cpu_number_map[i] = num_cpus;
 			__cpu_logical_map[num_cpus] = i;
-
+			cpu_data[i].core = (int) (i/XLP_THREADS_PER_CORE);
+			cpu_set(i, phys_cpu_present_map);
 			num_cpus++;
 		}
 	}
 
-	cpu_present_map = cpu_possible_map = fdt_cpumask;
-
+	cpumask_copy(&cpu_present_map, &fdt_cpumask);
+	cpumask_copy(&cpu_possible_map, &cpu_present_map);
+	cpumask_scnprintf(buf, CPUMASK_BUF, &fdt_cpumask);
 	cpumask_scnprintf(buf, CPUMASK_BUF, &cpu_possible_map);
-	printk("Possible/Present/FDT CPU map %s\n", buf);
+	printk("Possible/Present CPU map %s\n", buf);
 
 	printk("Detected %d Slave CPU(s)\n", num_cpus);
+	/* Setup PIC with cpu_present_mask */
+	xlp_pic_ite_init((const struct cpumask *)&cpu_present_map);
 }
 
 #define hw_enable_cpus enable_cpus
@@ -256,6 +299,9 @@ static inline void config_mmu(void)
 	);
 }
 
+/*
+ * this function requires cpu_present_map
+ */
 int wakeup_secondary_cpus(void)
 {
 	cpumask_t mask32;
@@ -264,20 +310,26 @@ int wakeup_secondary_cpus(void)
 	cpumask_clear(&mask32);
 	uint32_to_cpumask(&mask32, 0xffffffff);
 
-	for (node = 0; node < NLM_MAX_CPU_NODE; node++) {
+	for (node = 0; node < 1; node++) {
 		cpumask_t tmpmask, nodemask;
+		cpumask_t tmploader_mask, loadernode_mask;
 		unsigned int onlinemask;
 
 		cpumask_clear(&tmpmask);
 		cpumask_clear(&nodemask);
+		cpumask_clear(&tmploader_mask);
+		cpumask_clear(&loadernode_mask);
 
 		cpumask_shift_right(&nodemask, &fdt_cpumask, 32 * node);
 		cpumask_and(&tmpmask, &nodemask, &mask32);
 
-		if (cpumask_empty(&tmpmask))
+		cpumask_shift_right(&loadernode_mask, &fdt_loadermask, 32 * node);
+		cpumask_and(&tmploader_mask, &loadernode_mask, &mask32);
+
+		if (cpumask_empty(&tmpmask) && cpumask_empty(&tmploader_mask))
 			continue;
 
-		onlinemask = cpumask_to_uint32(&tmpmask);
+		onlinemask = cpumask_to_uint32(&tmpmask) | cpumask_to_uint32(&tmploader_mask);
 		hw_enable_cpus(node, onlinemask);
 
 		printk("Enabled cpus (0x%08x) on node@%d\n", onlinemask, node);
@@ -295,9 +347,11 @@ void nlm_prepare_cpus(unsigned int max_cpus)
 
 #ifdef CONFIG_HOTPLUG_CPU
 
+
 static int nlm_cpu_disable(void)
 {
-	unsigned int cpu = smp_processor_id();
+	int cpu = hard_smp_processor_id();
+	uint32_t bitmask = 0;
 	atomic_set(&cpu_hotplug_flag, 1);
 
 	if (cpu == 0)
@@ -305,6 +359,10 @@ static int nlm_cpu_disable(void)
 
 	spin_lock(&smp_reserve_lock);
 
+        bitmask = cpumask_to_uint32(&cpu_online_map);
+	bitmask = bitmask & ~(1 << cpu);
+	set_ite(bitmask);
+
 	cpu_clear(cpu, cpu_online_map);
 	cpu_clear(cpu, cpu_callin_map);
 
@@ -368,6 +426,7 @@ void prom_boot_cpus_secondary(void *args)
 	/* Announce that this cpu is available */
 	cpumask_test_and_set_cpu(cpu, &smp_boot.online_map);
 
+
 	/* Wait for master to signal */
 	for (;;) {
 		if (smp_boot.boot_info[cpu].ready) break;
@@ -381,7 +440,120 @@ void prom_boot_cpus_secondary(void *args)
         setup_mapped_kernel_tlbs(TRUE, FALSE);
         setup_mapped_kernel_tlbs(FALSE, FALSE);
 
+	if (cpumask_test_cpu(cpu, &fdt_loadermask)) {
+		/* TLBMISS_HANDLER_SETUP */
+		write_c0_context(cpu << 26);
+		back_to_back_c0_hazard();
+		pgd_current[cpu] = (unsigned long)(swapper_pg_dir);
+		write_c0_pagemask(PM_DEFAULT_MASK);
+	}
+
 	/* Entry into the kernel (smp_bootstrap) */
 	ptr_smp_boot(smp_boot.boot_info[cpu].fn, smp_boot.boot_info[cpu].sp,
 		     smp_boot.boot_info[cpu].gp);
 }
+
+extern void save_epc(unsigned long *epc);
+extern void smp_call_function_interrupt(void);
+static int nlm_common_ipi_stats[NR_CPUS];
+static unsigned long nlm_common_ipi_epc[NR_CPUS];
+
+#ifdef CONFIG_NLM_XLR
+#define SET_IPI_VECTOR(x, y) x |= y
+
+void core_send_ipi(int logical_cpu, unsigned int action)
+{
+	int cpu = cpu_logical_map(logical_cpu);
+	__u32 tid = cpu & 0x3;
+	__u32 pid = (cpu >> 2) & 0x07;
+	__u32 ipi = (tid << 16) | (pid << 20);
+
+	if (action & SMP_CALL_FUNCTION) {
+		SET_IPI_VECTOR(ipi, IRQ_IPI_SMP_FUNCTION);
+	} else if (action & SMP_RESCHEDULE_YOURSELF) {
+		SET_IPI_VECTOR(ipi, IRQ_IPI_SMP_RESCHEDULE);
+	} else if (action & SMP_CALL_KGDB_HOOK) {
+		SET_IPI_VECTOR(ipi, IRQ_IPI_SMP_KGDB);
+		/* set NMI also for KGDB */
+		SET_IPI_VECTOR(ipi, (1 << 8));
+	} else if (action & SMP_OPROFILE_IPI) {
+		SET_IPI_VECTOR(ipi, IRQ_IPI_OPROFILE);
+	}
+#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY
+	else if (action & SMP_NETRX_IPI) {
+		SET_IPI_VECTOR(ipi, IRQ_IPI_NETRX);
+	}
+#endif				/* CONFIG_NLMCOMMON_IP_FLOW_AFFINITY */
+	else
+		return;
+
+	pic_send_ipi(ipi);
+}
+#endif
+
+extern __u64 nlm_common_irq_mask;
+
+#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY
+extern void skb_transfer_finish(void);
+#endif				/* CONFIG_NLMCOMMON_IP_FLOW_AFFINITY */
+
+#ifdef CONFIG_SMP
+/* IRQ_IPI_SMP_FUNCTION Handler */
+void nlm_smp_function_ipi_handler(unsigned int irq, struct irq_desc *desc)
+{
+	nlm_common_ipi_stats[smp_processor_id()]++;
+	save_epc(&nlm_common_ipi_epc[smp_processor_id()]);
+	smp_call_function_interrupt();
+	nlm_common_ipi_stats[smp_processor_id()]--;
+}
+
+/* IRQ_IPI_SMP_RESCHEDULE  handler */
+void nlm_smp_resched_ipi_handler(unsigned int irq, struct irq_desc *desc)
+{
+	nlm_common_ipi_stats[smp_processor_id()]++;
+	save_epc(&nlm_common_ipi_epc[smp_processor_id()]);
+
+	/* Announce that we are for reschduling */
+	set_need_resched();
+	nlm_common_ipi_stats[smp_processor_id()]--;
+}
+
+#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY
+/* nlm_ip_flow_ipi_handler HANDLER */
+void nlm_ip_flow_ipi_handler(unsigned int irq, struct irq_desc *desc)
+{
+	nlm_common_ipi_stats[smp_processor_id()]++;
+	save_epc(&nlm_common_ipi_epc[smp_processor_id()]);
+
+	/* do_IRQ called irq_enter() before calling this desc->handler */
+	skb_transfer_finish();
+	nlm_common_ipi_stats[smp_processor_id()]--;
+
+}
+#endif /* CONFIG_NLMCOMMON_IP_FLOW_AFFINITY */
+#endif
+
+void nlm_common_ipi_handler(int irq, struct pt_regs *regs)
+{
+	nlm_common_ipi_stats[smp_processor_id()]++;
+	save_epc(&nlm_common_ipi_epc[smp_processor_id()]);
+
+	if (irq == NLM_IRQ_IPI_SMP_FUNCTION) {
+		smp_call_function_interrupt();
+	}
+#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY
+	else if (irq == IRQ_IPI_NETRX) {
+		irq_enter();
+
+		skb_transfer_finish();
+
+		/* run soft IRQ at the end */
+		irq_exit();
+	}
+#endif	/* CONFIG_NLMCOMMON_IP_FLOW_AFFINITY */
+	else {
+		/* Announce that we are for reschduling */
+		set_need_resched();
+	}
+	nlm_common_ipi_stats[smp_processor_id()]--;
+}
diff --git a/arch/mips/netlogic/xlp/time.c b/arch/mips/netlogic/xlp/time.c
index 9ed9a20..bbbcae8 100644
--- a/arch/mips/netlogic/xlp/time.c
+++ b/arch/mips/netlogic/xlp/time.c
@@ -1,5 +1,5 @@
 /***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
 reserved.
 Redistribution and use in source and binary forms, with or without
 modification, are peNLMtted provided that the following conditions are
@@ -36,10 +36,61 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #include <linux/oprofile.h>
 
 #include <linux/proc_fs.h>
-#include <asm/netlogic/hal/nlm_hal_pic.h>
-#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/xlp_hal_pic.h>
 
-extern spinlock_t nlm_common_pic_lock;
+extern spinlock_t xlp_pic_lock;
+
+#ifndef CONFIG_NLMCOMMON_MAC
+void nlm_common_user_mac_update_time(void)
+{
+}
+void nlm_common_user_mac_update_ktime(void)
+{
+}
+#else
+extern void nlm_common_user_mac_update_time(void);
+extern void nlm_common_user_mac_update_ktime(void);
+#endif
+ 
+void save_epc(unsigned long *epc)
+{
+	__asm__ __volatile__(".set push\n"
+			     ".set noreorder\n"
+			     "mfc0 %0, $14\n" ".set pop\n":"=r"(*epc));
+}
+
+void nlm_common_timer_interrupt(struct pt_regs *regs, int irq)
+{
+	int cpu = hard_smp_processor_id();
+
+#ifdef CONFIG_NLM_WATCHDOG
+        pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	/* ack the watchdog */
+	/* Need to choose (?) the right heartbeat reg (0/1) and right chunk */
+	nlm_hal_write_pic_reg(mmio, PIC_WD_HEARTBEAT_0(0), 1 << cpu_logical_map(cpu));
+#endif
+
+#ifdef CONFIG_NLM_WATCHDOG
+	/* ack the watchdog */
+	netlogic_write_reg(mmio, 0x0c, 1 << cpu_logical_map(cpu));
+#endif
+
+	if (irq != XLP_IRQ_TIMER) {
+		printk("[%s]:cpu_%d: bad timer irq = %x\n", __FUNCTION__, cpu, irq);
+		BUG();
+	}
+
+    {
+        do_IRQ(irq);
+
+        if (cpu == 0) {
+            nlm_common_user_mac_update_time();
+	    nlm_common_user_mac_update_ktime();
+        }
+    }
+
+}
 
 /* PIC clock at 66Mhz takes more than 60 secs to come to 0 from max. So 32bit 
    counter is sufficient
@@ -66,7 +117,7 @@ void nlm_common_timer_setup(void)
         pic_reg_t *mmio = nlm_hal_pic_offset();
         unsigned long flags = 0;
 
-        spin_lock_irqsave(&nlm_common_pic_lock, flags);
+        spin_lock_irqsave(&xlp_pic_lock, flags);
 
         /* Use PIC Timer 6 as a free running counter */
         nlm_hal_write_pic_reg(mmio, PIC_TIMER_6_MAXVAL, 0xffffffffffffffffULL);
@@ -74,7 +125,7 @@ void nlm_common_timer_setup(void)
 	/* enable the timer */
         nlm_hal_pic_update_control(1 << (10 + 6));
 
-        spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+        spin_unlock_irqrestore(&xlp_pic_lock, flags);
 
 }
 
diff --git a/arch/mips/netlogic/xlp/xlp_hal_pic.c b/arch/mips/netlogic/xlp/xlp_hal_pic.c
new file mode 100644
index 0000000..5e03194
--- /dev/null
+++ b/arch/mips/netlogic/xlp/xlp_hal_pic.c
@@ -0,0 +1,137 @@
+#include <asm/netlogic/xlp_hal_pic.h>
+#ifdef CONFIG_NUMA
+#include <asm/topology.h>
+#endif
+
+/*
+ * __nlm_hal_request_irq
+ * This function will return the irt index for any given irq.
+ * Note :
+ *	We don't care if the irt is enabled or not, if there are
+ *	multiple assignments of the same irq or not.
+ *	must be called with irt_irq lock taken
+ *
+ * @irq : irq whose irt entry should be returned
+ *
+ * return : irt entry index
+ */
+int __nlm_hal_request_irq(int irt, int rvec)
+{
+        uint64_t  val;
+
+#ifndef CONFIG_NUMA
+	val = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt));
+	/* clear DB and DTE field */
+	val &= ~(0x3f << 20);
+	val |= ((rvec << 20) | (1 << 31));
+	nlm_hal_write_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt), val);
+#else
+	uint8_t	nid;
+	
+	for_each_online_node (nid) {
+		uint64_t xlp_pic_base = XLP_BDF_BASE(0, 0 + 8 * nid, 4);
+
+		val = nlm_hal_read_64bit_reg(xlp_pic_base, (0xB4 >> 1) + irt);
+		val &= ~(0x3f << 20);
+		val |= ((rvec << 20) | (1 << 31));
+		nlm_hal_write_64bit_reg(xlp_pic_base, (0xB4 >> 1) + irt, val);
+	}
+#endif
+        return 0;
+}
+
+/*
+ * __nlm_hal_release_irq
+ * Note :
+ *	must be called with irt_irq lock taken
+ *
+ * @irq : irq whose irt entry should be returned
+ *
+ * return : irt entry index
+ */
+void __nlm_hal_release_irq(int irt)
+{
+        uint64_t  val;
+
+#ifndef CONFIG_NUMA
+	val = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt));
+	val &= ~(1 << 31);
+	nlm_hal_write_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt), val);
+#else
+	uint8_t	nid;
+	
+	for_each_online_node (nid) {
+		uint64_t xlp_pic_base = XLP_BDF_BASE(0, 0 + 8 * nid, 4);
+
+		val = nlm_hal_read_64bit_reg(xlp_pic_base, (0xB4 >> 1) + irt);
+		val &= ~(1 << 31);
+		nlm_hal_write_64bit_reg(xlp_pic_base, (0xB4 >> 1) + irt, val);
+	}
+#endif
+}
+
+/*
+ * __nlm_hal_set_irt_to_cpu
+ *
+ * Sets DT and DB in an IRT entry
+ */
+void __nlm_hal_set_irt_to_cpu(int irt, int cpu)
+{
+        uint64_t val;
+	uint cpuid, threadid;
+	uint nodeid;
+#ifdef CONFIG_NUMA
+	uint64_t xlp_pic_base;
+#endif
+
+	/* DT is set 1 ==> Destination thread is specificed in DB and
+	 * DTE fields.
+	 * DB : (18-17 : Node id)
+	 * DB : (16) : 1 ==> DTE selects cpu 0-15
+	 * DB : (16) : 0 ===> DTE selects cpu 16-31
+	 *
+	 * cpuid and thread id are found out from cpu# param as follows
+	 * threadid = (cpu & 0xf)
+	 * cpuid = (cpu >> 4)
+	 */
+#ifndef CONFIG_NUMA
+	nodeid = 0;
+	cpuid = (cpu >> 4) & 1;	/* DB group of CPU */
+	threadid = cpu & 0xf;	/* range 0 - 15 for threadid */
+	val = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt));
+	val &= ~(0xfffff);	/* Clear DT, DB and DTE */
+	val |= ((1 << 19) | (nodeid << 17) | (cpuid << 16) | ( 1 << threadid));
+	nlm_hal_write_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt), val);
+#else
+	nodeid = cpu_to_node(cpu);
+	cpuid = (cpu >> 4) & 1;
+	threadid = cpu & 0xf;
+	xlp_pic_base = XLP_BDF_BASE(0, 0 + 8 * nodeid, 4);
+	val = nlm_hal_read_64bit_reg(xlp_pic_base, (0xB4 >> 1) + irt);
+	val &= ~(0xfffff);
+	val |= ((1 << 19) | (nodeid << 17) | (cpuid << 16) | ( 1 << threadid));
+	nlm_hal_write_64bit_reg(xlp_pic_base, (0xB4 >> 1) + irt, val);
+#endif
+}
+
+#ifdef CONFIG_NUMA
+void xlp_numa_ack_pic(int irt)
+{
+	int 	 nid = cpu_to_node(smp_processor_id());
+	uint64_t xlp_pic_base = XLP_BDF_BASE(0, 0 + 8 * nid, 4);
+
+	nlm_hal_write_64bit_reg(xlp_pic_base, 0x50 >> 1, irt);
+
+	/* Ack the Status register for Watchdog & System timers */
+	if (irt < 12)
+		nlm_hal_write_64bit_reg(xlp_pic_base, 0x44 >> 1, 1 << irt);
+}
+#endif
+
+#ifdef NLM_HAL_LINUX_KERNEL
+#include <linux/kernel.h>
+#include <linux/module.h>
+EXPORT_SYMBOL(__nlm_hal_set_irt_to_cpu);
+EXPORT_SYMBOL(__nlm_hal_request_irq);
+EXPORT_SYMBOL(__nlm_hal_release_irq);
+#endif
diff --git a/arch/mips/pci/pci-xlp.c b/arch/mips/pci/pci-xlp.c
index 495ff69..a4bf246 100644
--- a/arch/mips/pci/pci-xlp.c
+++ b/arch/mips/pci/pci-xlp.c
@@ -1,8 +1,5 @@
 /***********************************************************************
-Copyright (C) 2011 Wind River Systems, Inc.
-Author: Wu Zhangjin <zhangjin.wu@windriver.com>
-
-Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
+Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
 reserved.
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are
@@ -26,8 +23,10 @@ ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 THE POSSIBILITY OF SUCH DAMAGE.
 *****************************#NETL_2#********************************/
 
-#define NLM_HAL_LINUX_KERNEL
-
+/*
+ * This file contains specific functions for XLP chipsets and
+ * EVP boards.
+ */
 #include <linux/types.h>
 #include <linux/pci.h>
 #include <linux/kernel.h>
@@ -38,17 +37,380 @@ THE POSSIBILITY OF SUCH DAMAGE.
 
 #include <asm/io.h>
 
-#include <asm/netlogic/interrupt.h>
+#include <asm/netlogic/xlp_irq.h>
 #include <asm/netlogic/pci.h>
 #include <asm/netlogic/io.h>
 #include <asm/netlogic/iomap.h>
-#include <asm/netlogic/hal/nlm_hal.h>
-#include <asm/netlogic/hal/nlm_hal_pic.h>
+#include <asm/netlogic/sim.h>
+#include <asm/netlogic/xlp_hal_pic.h>
 
 extern int pci_probe_only;
-
 static void *pci_config_base;
-static void *pci_io_base;
+static const volatile void *pci_io_base;
+
+int xlp_intx_enable(int);
+int xlp_intx_disable(int);
+int xlp_msi_enable(int, u32);
+int xlp_msix_enable(int);
+int xlp_msi_disable(int, u32);
+int xlp_msix_disable(int);
+u32 xlp_msi_set_mask(int, int, int);
+
+/*
+ * Possible values are no more hard coded.
+ * For mapping of these values to IRT, refer
+ * arch/mips/netlogic/xlp/irq.c
+ *
+ * Here a table is defined to figure out the interrupt assignments to different
+ * cards placed on any of the 4 PCI slots.
+ *
+ * We have some unique problems here.
+ * 1. Board could be configured in different lane widths. That means, the cards
+ * could be controlled by different functions of the controller on board
+ * Eg. 2x8 config can have two cards (fn 0 and fn 2)
+ *	4x4 config can also have two cards (under fn0 through fn 3)
+ * 2. Cards can be placed on any available slot
+ * 3. The card can have a switch built in, thus giving rise to multiple devices
+ * on the slot.
+ *
+ * So, it is important to figure out the lanes on which cards are placed.
+ * First we read the lane config from POWER_ON_RESET_CFG
+ * Then each line's LTSSM state would give the card presence
+ * Based on that we have to assign interrupt values; while keeping the
+ * possibility of same interrupt assigned to multiple devices open.
+ *
+ * So, we have a map: XLP irq map is as follows
+ *  \fn 0	1	2	3
+ *plc\
+ * 0	86	0	88	89
+ * 1	86	87	88	0
+ * 2	86	0	88	89
+ * 3	86	87	88	89
+ * This map changes from processor to processor. check PRM or RTL because
+ * the values are a function of XLP_PCIE_LINK_IRT_OFFSET. To make them
+ * somewhat independent, I have defined macros and used them here.
+ *
+ * This map is dynamically populated based on card presence in the slot.
+ * If a card is present, and is a switch, then the secondary and subordinate
+ * numbers would be different. Based on this fact, we can figure out from
+ * pci_dev structure the slot where a card is placed at run time.
+ */
+struct xlp_link_struct {
+	int intno;
+	int sec;
+	int sub;
+};
+
+struct xlp_plc_fn_struct {
+	int plc;
+	struct xlp_link_struct farray[4];
+};
+
+static struct xlp_plc_fn_struct xlp_irqmap[4] = {
+	{0, {{XLP_PCIE_LINK_IRQ(0), 0, 0}, {0, 0, 0},
+		{XLP_PCIE_LINK_IRQ(2), 0, 0}, {0, 0, 0}}},
+	{1, {{XLP_PCIE_LINK_IRQ(0), 0, 0}, {XLP_PCIE_LINK_IRQ(1), 0, 0},
+		{XLP_PCIE_LINK_IRQ(2), 0, 0}, {0, 0, 0}}},
+	{2, {{XLP_PCIE_LINK_IRQ(0), 0, 0}, {0, 0, 0},
+		{XLP_PCIE_LINK_IRQ(2), 0, 0}, {XLP_PCIE_LINK_IRQ(3), 0, 0}}},
+	{3, {{XLP_PCIE_LINK_IRQ(0), 0, 0}, {XLP_PCIE_LINK_IRQ(1), 0, 0},
+		{XLP_PCIE_LINK_IRQ(2), 0, 0}, {XLP_PCIE_LINK_IRQ(3), 0, 0}}},
+};
+
+/*
+static int xlp_irq_map[4][4][3] = {
+	{{XLP_PCIE_LINK_IRQ(0), 0, 0}, {0, 0, 0},
+		{XLP_PCIE_LINK_IRQ(2), 0, 0}, {0, 0, 0}},
+	{{XLP_PCIE_LINK_IRQ(0), 0, 0}, {XLP_PCIE_LINK_IRQ(1), 0, 0},
+		{XLP_PCIE_LINK_IRQ(2), 0, 0}, {0, 0, 0}},
+	{{XLP_PCIE_LINK_IRQ(0), 0, 0}, {0, 0, 0},
+		{XLP_PCIE_LINK_IRQ(2), 0, 0}, {XLP_PCIE_LINK_IRQ(3), 0, 0}},
+	{{XLP_PCIE_LINK_IRQ(0), 0, 0}, {XLP_PCIE_LINK_IRQ(1), 0, 0},
+		{XLP_PCIE_LINK_IRQ(2), 0, 0}, {XLP_PCIE_LINK_IRQ(3), 0, 0}},
+};
+*/
+/* The following is the table describing current interrupt modes of
+ * XLP controllers. When an external switch is present, different devices
+ * can request different interrupt mode on the same controller which might lead
+ * to controller changing previous interrupt mode. If this happens, interrupt
+ * delivery will not work correctly. So, we need a way to prevent different
+ * devices requesting different interrupt modes. This is kind of impossible
+ * because we can't control all device drivers, but we can
+ *	1. fail pci_enable_msi{x} if intX is set and at least one interrupt
+ *	is allocated
+ *	2. fail request_irq() for any interrupt outside current interrupt
+ *	distribution range
+ */
+struct xlp_intmode_struct {
+	u32 mode;
+	int usage;
+};
+static struct xlp_intmode_struct intmode[4];
+
+int xlp_ctrl_intmode_add(int fn, int mode, int i)
+{
+	if (intmode[fn].mode != mode) {
+		return -EBUSY;
+	}
+	intmode[fn].usage += i;
+	if ((intmode[fn].usage < 0) || (intmode[fn].usage == 0)) {
+		intmode[fn].usage = 0;
+	}
+	return intmode[fn].usage;
+}
+
+
+int xlp_get_ctrl_intmode(int fn)
+{
+	return intmode[fn].mode;
+}
+
+int xlp_set_ctrl_intmode(int fn, int mode)
+{
+	int ret = 0;
+	if (intmode[fn].mode == mode) {
+		/* do nothing */
+	} else if (intmode[fn].usage == 0) {
+		intmode[fn].mode = mode;
+	} else {
+		ret = -EBUSY;
+	}
+	return ret;
+}
+
+/* Just a helper function to fill up xlp_irq_map table's entries
+ * This function checks whether a PCIe slot is populated and if yes,
+ * fills up the table with subordinate and secondary bus numbers. These
+ * numbers would be different only if the PCIe device has a switch inside.
+ */
+static int xlp_map_helper(int row, int fn)
+{
+	u64 xlp_pci_base;
+	u32 reg6, ltssm;
+
+	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
+	ltssm = nlm_hal_read_32bit_reg(xlp_pci_base, 0x25E);
+	if (ltssm != 0x00446000) {
+		printk(KERN_WARNING "LTSSM state is %#x. Fn %x link not up\n",
+				ltssm, fn);
+		return -ENODEV;
+	}
+	reg6 = nlm_hal_read_32bit_reg(xlp_pci_base, 0x6);
+	xlp_irqmap[row].farray[fn].sec = (reg6 >> 8) & 0xff;
+	xlp_irqmap[row].farray[fn].sub = (reg6 >> 16) & 0xff;
+	return 0;
+}
+
+/*
+ * Iterates over buses to find out the slot (thus pci controller fn)
+ */
+int xlp_ctrl_fn_from_dev(const struct pci_dev *dev)
+{
+	__label__ out;
+	int row = 0, fn = 0;
+
+	while (row < 4) {
+		fn = 0;
+		while (fn < 4) {
+			if ((dev->bus->number >= xlp_irqmap[row].farray[fn].sec)
+			&&(dev->bus->number <= xlp_irqmap[row].farray[fn].sub)){
+				goto out; /* No `break', note two loops */;
+			}
+			fn++;
+		}
+		row++;
+	}
+out:
+	if (fn >= 4) {
+		return -ENODEV;
+	}
+	return fn;
+}
+
+/*
+ * We discard the idea of a fixed address for MSI. But if that is ever required,
+ * define CONFIG_XLP_MSI_ADDRESSES
+ */
+#ifndef CONFIG_XLP_MSI_ADDRESSES
+static u64 XLP_MSI_ADDR = 0;
+#endif
+
+volatile const void *xlp_msix_addr_start(int fn)
+{
+	if (XLP_MSI_ADDR == 0) {
+		return 0;
+	}
+	return (volatile const void *)(XLP_MSI_ADDR + (fn * XLP_MSIX_ADDR_SIZE));
+}
+
+volatile const void *xlp_msi_addr_start(int fn)
+{
+	if (XLP_MSI_ADDR == 0) {
+		return 0;
+	}
+	return (volatile const void *)(XLP_MSI_ADDR + (fn * XLP_MSI_ADDR_SIZE));
+}
+
+/* Irrespective of any device requesting MSI/MSI-X, we keep the controller
+ * ready by programming the corresponding registers. This action, per se,
+ * does not start MSI/MSI-X for they have to be enabled explicitly.
+ */
+static void xlp_msi_controller_init(int fn)
+{
+	u64 xlp_pci_base;
+	u8 mmc;
+	u32 msi;
+
+	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
+	if (XLP_MSI_ADDR == 0) {
+		printk(KERN_ERR "MSI/MSI-X CANNOT be programmed\n");
+		return;
+	}
+	msi = nlm_hal_read_32bit_reg(xlp_pci_base, 0x14);
+	mmc = (msi >> 17) & 0x7;
+	/* Initialize MSI Base register */
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x15,
+		virt_to_phys(xlp_msi_addr_start(fn)) & 0xffffffff);
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x16,
+		(virt_to_phys(xlp_msi_addr_start(fn)) >> 32) & 0xffffffff);
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x17, 0x0);
+	msi |= ((mmc << 20) | (1 << 16));
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x14, msi);
+	/* Initialize MSI-X Base and Address reg. Note >> 8 in the address.
+	 * This is how 40bit address goes in 32bit registers.*/
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x24F,
+		(virt_to_phys(xlp_msix_addr_start(fn)) >> 8));
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x250,
+		(virt_to_phys(xlp_msix_addr_start(fn) + XLP_MSIX_ADDR_SIZE) >> 8));
+}
+
+/*
+ * Controller is initialized and explicity disabled
+ *
+ * @fn : controller function no.
+ */
+void xlp_pcie_controller_setup(int fn)
+{
+	xlp_msi_controller_init(fn);
+	//xlp_msix_disable(fn);
+	//xlp_msi_disable(fn, 0xf);
+	/* By default, leave INTX enabled */
+	xlp_intx_enable(fn);
+}
+
+/*
+ * Utility function to get syscfg
+ *
+ * @node : node id in multi chip config
+ */
+u32 xlp_get_power_on_reset_cfg(int node)
+{
+	u64 xlp_syscfg_base = XLP_BDF_BASE(0,6,5);
+	return nlm_hal_read_32bit_reg(xlp_syscfg_base, 0x41);
+}
+EXPORT_SYMBOL(xlp_get_power_on_reset_cfg);
+
+
+/*
+ * Called from system startup routine
+ */
+static void pcie_controller_init_done(void)
+{
+	u32 plc, syscfg, mode, count = 0;
+
+#ifndef CONFIG_XLP_MSI_ADDRESSES
+#ifdef CONFIG_32BIT
+	XLP_MSI_ADDR = (u64)__get_free_pages(GFP_KERNEL, get_order(0x100000));
+#else
+	XLP_MSI_ADDR = (u64)__get_free_pages(GFP_KERNEL, get_order(0x1000000));
+#endif
+	if (XLP_MSI_ADDR == 0) {
+		printk(KERN_ERR "Failed to get memory for MSI/MSI-X tables\n");
+	}
+#endif
+	if (!pci_probe_only){
+		printk(KERN_WARNING "PCIe bus IRQs configured incorrectly\n");
+		return;
+	}
+	syscfg = xlp_get_power_on_reset_cfg(0);
+	/* We don't manipulate pci_address space.
+	 * Get the link status from pcie lane config from 34.9.7.2 XLP PRM */
+	mode = (syscfg >> 19) & 0xf;
+	while (count < 4) {
+		printk(KERN_DEBUG "Controller %d is in %s mode\n",
+				count, (mode & (1 << count)) ? "RC" : "EP");
+		count++;
+	}
+	plc = (syscfg >> 23) & 0x3;
+	printk(KERN_DEBUG "PLC = %#x, mode = %#x\n", plc, mode);
+	switch (plc) {
+	/* The correlation between plc and lane config is very specific to XLP
+	 * and not very clear in PRM
+	 */
+	case 0:
+		/* controller 0 and 2 are active with 8lanes each */
+		if (mode & 0x1){
+			xlp_map_helper(plc, 0);
+			xlp_pcie_controller_setup(0);
+		}
+		if (mode & 0x4) {
+			xlp_map_helper(plc, 2);
+			xlp_pcie_controller_setup(2);
+		}
+		break;
+	case 1:
+		/* controllers 0,1 and 2 are active */
+		if (mode & 0x1){
+			xlp_map_helper(plc, 0);
+			xlp_pcie_controller_setup(0);
+		}
+		if (mode & 0x2){
+			xlp_map_helper(plc, 1);
+			xlp_pcie_controller_setup(1);
+		}
+		if (mode & 0x4){
+			xlp_map_helper(plc, 2);
+			xlp_pcie_controller_setup(2);
+		}
+		break;
+	case 2:
+		/* controllers 0,2 and 3 are active */
+		if (mode & 0x1){
+			xlp_map_helper(plc, 0);
+			xlp_pcie_controller_setup(0);
+		}
+		if (mode & 0x4){
+			xlp_map_helper(plc, 2);
+			xlp_pcie_controller_setup(2);
+		}
+		if (mode & 0x8){
+			xlp_map_helper(plc, 3);
+			xlp_pcie_controller_setup(3);
+		}
+		break;
+	case 3:
+		/* All four controllers are active with 4 lanes each */
+		if (mode & 0x1){
+			xlp_map_helper(plc, 0);
+			xlp_pcie_controller_setup(0);
+		}
+		if (mode & 0x2){
+			xlp_map_helper(plc, 1);
+			xlp_pcie_controller_setup(1);
+		}
+		if (mode & 0x4){
+			xlp_map_helper(plc, 2);
+			xlp_pcie_controller_setup(2);
+		}
+		if (mode & 0x8){
+			xlp_map_helper(plc, 3);
+			xlp_pcie_controller_setup(3);
+		}
+		break;
+	}
+	printk(KERN_DEBUG "[%s]: PCIE Controller initialization done\n", __FUNCTION__);
+	return;
+}
 
 static inline __u32 pci_cfg_read_32bit(__u32 addr)
 {
@@ -62,19 +424,18 @@ static inline __u32 pci_cfg_read_32bit(__u32 addr)
 
 static inline void pci_cfg_write_32bit(__u32 addr, __u32 data)
 {
-	unsigned int *p = (unsigned int *)(pci_config_base + (addr & ~3));
+        unsigned int *p = (unsigned int *)(pci_config_base + (addr & ~3));
 
 	*p = data;
 }
 
-static int pci_bus_status;
-#define pci_cfg_offset(bus, devfn, where) \
-	(((bus) << 16) + ((devfn) << 8) + (where))
-#define pci_cfg_addr(bus, devfn, where) \
-	pci_cfg_offset((bus)->number, (devfn), where)
+static int pci_bus_status = 0;
+
+#define pci_cfg_offset(bus, devfn, where) (((bus)<<20)+((devfn)<<12)+(where))	//for PCIE config space
+#define pci_cfg_addr(bus, devfn, where) pci_cfg_offset((bus)->number,(devfn),where)
 
 static int xlp_pcibios_read(struct pci_bus *bus, unsigned int devfn,
-				int where, int size, u32 *val)
+				int where, int size, u32 * val)
 {
 	__u32 data = 0;
 
@@ -99,7 +460,7 @@ static int xlp_pcibios_read(struct pci_bus *bus, unsigned int devfn,
 }
 
 static int xlp_pcibios_write(struct pci_bus *bus, unsigned int devfn,
-				int where, int size, u32 val)
+				 int where, int size, u32 val)
 {
 	__u32 cfgaddr = pci_cfg_offset((bus->number), devfn, where);
 	__u32 data = 0;
@@ -134,23 +495,22 @@ static struct pci_ops xlp_pci_ops = {
 };
 
 /*
-* XLP PCIE Controller
-*/
-#define DEFAULT_XLP_PCI_CONFIG_BASE 0x1c000000UL
+ * XLP PCIE Controller
+ */
+#define DEFAULT_XLP_PCI_ECONFIG_BASE	(0x18000000ULL)
+#define DEFAULT_XLP_PCI_ECONFIG_SIZE	(32 << 20)
+#define DEFAULT_XLP_PCI_CONFIG_BASE	(0x1c000000ULL)
+#define DEFAULT_XLP_PCI_CONFIG_SIZE	(32 << 20)
 static struct resource xlp_mem_resource = {
 	.name           = "XLP PCI MEM",
-	.start          = 0xd0000000ULL,	/* 256MB PCI mem @ 0xd000_0000 */
+	.start          = 0xd0000000ULL,          /* 256MB PCI mem @ 0xd000_0000 */
 	.end            = 0xdfffffffULL,
 	.flags          = IORESOURCE_MEM,
 };
-
-#define DEFAULT_PCI_IO_BASE	0x14000000UL
-#define DEFAULT_PCI_IO_SIZE	0x2000000UL
-
 static struct resource xlp_io_resource = {
 	.name           = "XLP IO MEM",
-	.start          = 0,			/* 32MB PCI IO @ 0x1400_0000 */
-	.end            = DEFAULT_PCI_IO_SIZE-1,
+	.start          = 0x14000000UL,         /* 32MB PCI IO @ 0x1400_0000 */
+	.end            = 0x15ffffffUL,
 	.flags          = IORESOURCE_IO,
 };
 struct pci_controller xlp_controller = {
@@ -162,38 +522,347 @@ struct pci_controller xlp_controller = {
 	.mem_offset     = 0x00000000UL
 };
 
+/*
+ * Apparently this function is called for all pci controller functions
+ * viz. 0:1.0, 0:1.1, 0:1.2 and 0:1.3
+ * In fact, we need not assign them any interrupt.
+ * But for any devices connected on them, consult the populated table
+ * and return corresponding interrupt.
+ */
 int __init pcibios_map_irq(const struct pci_dev *dev, u8 slot, u8 pin)
 {
-	/* arch/mips/netlogic/common/nlm_hal.c:
-	 * PORT	IRT	IRQ
-	 * 0	78	44
-	 * 1	79	43
-	 * 2	80	42
-	 * 3	81	41
+	int row = 0, fn = 0;
+
+	switch (dev->devfn) {
+	case XLP_PCIE_CTRL_DEVFN(0, 0) ... XLP_PCIE_CTRL_DEVFN(0, 3):
+		return 0;
+	default:
+		break;
+	}
+	row = (xlp_get_power_on_reset_cfg(0) >> 23) & 0x3;
+	fn = xlp_ctrl_fn_from_dev(dev);
+	dev_printk(KERN_DEBUG, &dev->dev, "Assigning interrupt %#x\n", xlp_irqmap[row].farray[fn].intno);
+	return xlp_irqmap[row].farray[fn].intno;
+}
+
+/*
+ * Enables INTx on a controller
+ */
+static int __xlp_intx_enable(int fn)
+{
+	u64 xlp_pci_base;
+	u32 pci;
+
+	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
+	pci = nlm_hal_read_32bit_reg(xlp_pci_base, 0x1);
+	pci &= ~(1 << 10);	/* Enable IntX assertion */
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x1, pci);
+	pci = nlm_hal_read_32bit_reg(xlp_pci_base, 0x261);
+	pci |= 0xf;	/* Enable INT A,B,C,D */
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x261, pci);
+	return 0;
+}
+
+int xlp_intx_enable(int fn)
+{
+	int mode = xlp_get_ctrl_intmode(fn);
+
+	if ((mode & XLP_INTMODE_MSI) || (mode & XLP_INTMODE_MSIX)) {
+		return -EBUSY;
+	}
+	__xlp_intx_enable(fn);
+	xlp_incr_ctrl_intmode(fn, XLP_INTMODE_INTX);
+	return 0;
+}
+
+/*
+ * Disables INTx on a controller
+ */
+static int __xlp_intx_disable(int fn)
+{
+	u64 xlp_pci_base;
+	u32 pci;
+
+	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
+	pci = nlm_hal_read_32bit_reg(xlp_pci_base, 0x1);
+	pci |= (1 << 10);
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x1, pci);
+	pci = nlm_hal_read_32bit_reg(xlp_pci_base, 0x261);
+	pci &= ~(0xf);
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x261, pci);
+	return 0;
+}
+
+int xlp_intx_disable(int fn)
+{
+	int mode = xlp_get_ctrl_intmode(fn);
+
+	if (!(mode & XLP_INTMODE_INTX)) {
+		return -EBUSY;
+	}
+	__xlp_intx_disable(fn);
+	xlp_decr_ctrl_intmode(fn, XLP_INTMODE_INTX);
+	return 0;
+}
+
+/*
+ * Finds the slot on which this device is placed and enables corresponding
+ * MSI enable register on the _controller_ if not already enabled
+ * @dev : pci device corresponding to this device
+ */
+static int __xlp_msi_enable(int fn, u32 bit)
+{
+	u64 xlp_pci_base;
+	u32 msi_en;
+
+	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
+
+	/* First, set PCIe MSI Enable register. __KEEP_THIS_ORDER__ */
+	msi_en = nlm_hal_read_32bit_reg(xlp_pci_base, 0x261);
+	msi_en &= ~(0xf);
+	if ((msi_en & (1 << 9)) == 0) {
+		msi_en |= (1 << 9);	/* controls ONLY MSI, Not MSI-X */
+		nlm_hal_write_32bit_reg(xlp_pci_base, 0x261, msi_en);
+	}
+	/* Now, set the individual bit */
+	xlp_msi_set_mask(fn, bit, 1);
+	return 0;
+}
+
+int xlp_msi_enable(int fn, u32 bit)
+{
+	int tmp = xlp_get_ctrl_intmode(fn);
+
+	if ((tmp & XLP_INTMODE_INTX) || (tmp & XLP_INTMODE_MSIX)) {
+		return -EBUSY;
+	}
+
+	/* Enable MSI bis
+	 * Multiple MSI can get enabled at different point of time (especially
+	 * with a switch present. So, setting the bitmap should not depend on
+	 * present value of reg 0x25b or 0x261
 	 */
-	int irq = 0, hwslot, func;
+	__xlp_msi_enable(fn, bit);
+	xlp_incr_ctrl_intmode(fn, XLP_INTMODE_MSI);
+	return 0;
+}
 
-	if (dev->bus->number == 0) {
-		/* PCI Bridge */
-		func = PCI_FUNC(dev->devfn);
-		irq = irt_irq_table[PIC_IRT_PCIE_LINK_INDEX(func)][0];
-	} else {
-		/* PCI Device */
-		hwslot = dev->bus->number;
-		irq = irt_irq_table[PIC_IRT_PCIE_LINK_INDEX(hwslot - 1)][0];
+/*
+ * Finds the slot on which this device is placed and enables corresponding
+ * MSI-X enable register on the controller
+ */
+static int __xlp_msix_enable(int fn)
+{
+	u64 xlp_pci_base;
+	u32 msix_ctrl;
+
+	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
+	msix_ctrl = nlm_hal_read_32bit_reg(xlp_pci_base, 0x2C);
+	if (!(msix_ctrl & 0x80000000)) {
+		msix_ctrl |= 0x80000000;	/* MSI-X enable */
+		nlm_hal_write_32bit_reg(xlp_pci_base, 0x2C, msix_ctrl);
+	}
+	//nlm_hal_write_32bit_reg(xlp_pci_base, 0xf, 0xFF);
+	return 0;
+}
+
+int xlp_msix_enable(int fn)
+{
+	int mode = xlp_get_ctrl_intmode(fn);
+
+	if ((mode & XLP_INTMODE_MSI) || (mode & XLP_INTMODE_INTX)) {
+		return -EBUSY;
+	}
+	__xlp_msix_enable(fn);
+	xlp_incr_ctrl_intmode(fn, XLP_INTMODE_MSIX);
+	return 0;
+}
+
+/*
+ * Disables MSI on controller function
+ */
+static int __xlp_msi_disable(int fn)
+{
+	u64 xlp_pci_base;
+	u32 msi_en;
+
+	/* We dont call xlp_decr_ctrl.... here because it has already been 
+	 * called before xlp_msi_disable is called */
+	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
+	/*set PCIe Int Enable register */
+	msi_en = nlm_hal_read_32bit_reg(xlp_pci_base, 0x261);
+	if ((msi_en & (1 << 9)) != 0) {
+		msi_en &= ~(1 << 9);
+		msi_en |= 0xf;
+		nlm_hal_write_32bit_reg(xlp_pci_base, 0x261, msi_en);
+	}
+	return 0;
+}
+
+int xlp_msi_disable(int fn, u32 bit)
+{
+	int tmp = xlp_get_ctrl_intmode(fn);
+	u32 r25b;
+
+	if (!(tmp & XLP_INTMODE_MSI)) {
+		return -EBUSY;
+	}
+	r25b = xlp_msi_set_mask(fn, bit, 0);
+	if (r25b == 0) {
+		__xlp_msi_disable(fn);
+	}
+	xlp_decr_ctrl_intmode(fn, XLP_INTMODE_MSI);
+	return 0;
+}
+
+/*
+ * Disables MSI-X on a controller function
+ */
+static int __xlp_msix_disable(int fn)
+{
+	u64 xlp_pci_base;
+	u32 msix_ctrl;
+
+	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
+	msix_ctrl = nlm_hal_read_32bit_reg(xlp_pci_base, 0x2C);
+	msix_ctrl &= ~(0x80000000);	/* MSI-X disable */
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x2C, msix_ctrl);
+	//nlm_hal_write_32bit_reg(xlp_pci_base, 0xf, 0xFF);	/* TODO Get from dev */
+	return 0;
+}
+
+int xlp_msix_disable(int fn)
+{
+	int mode = xlp_get_ctrl_intmode(fn);
+
+	if (!(mode & XLP_INTMODE_MSIX)) {
+		return -EBUSY;
+	}
+	if (xlp_decr_ctrl_intmode(fn, XLP_INTMODE_MSIX) == 0) {
+		__xlp_msix_disable(fn);
+	}
+	return 0;
+}
+
+/*
+ * checks if msi is enabled for this controller
+ * @fn	: controller function number
+ */
+int is_msi_set(int fn)
+{
+	u64 xlp_pci_base;
+	u32 msi_en, status;
+
+	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
+	msi_en = nlm_hal_read_32bit_reg(xlp_pci_base, 0x261);
+	status = (msi_en >> 9) & 1 ;
+	return status;
+}
+
+
+u32 calc_msi_vector_offset(int fn)
+{
+	u64 xlp_pci_base;
+	u32 msi_en, msi_stat;
+
+	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
+	msi_en = nlm_hal_read_32bit_reg(xlp_pci_base, 0x25B);
+	msi_stat = nlm_hal_read_32bit_reg(xlp_pci_base, 0x25A);
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x25A, msi_stat);
+	msi_stat &= msi_en;
+	return msi_stat;
+}
+
+/*
+ * Clears MSI-X status bits for a controller
+ * @fn : controller number
+ *
+ * status register is Read, Write 1 to clear.
+ * Figure out the mask (the bits corresponding to fn), read register, clear
+ * them and return the bits corresponding to fn
+ */
+#ifndef XLP_MSIX_PER_SLOT
+#define XLP_MSIX_PER_SLOT	8
+#endif
+u32 xlp_msix_status_clear(int fn)
+{
+	u64 xlp_pci_base;
+	u32 msix_stat;
+	u32 mask = ((XLP_MSIX_PER_SLOT - 1) << (fn * XLP_MSIX_PER_SLOT));
+
+	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
+	msix_stat = nlm_hal_read_32bit_reg(xlp_pci_base, 0x25D);
+	//fdebug("mask = %#x, fn = %d, MSIX status = %#x\n", mask, fn, msix_stat);
+	msix_stat &= mask;
+	//fdebug("Masked MSIX status = %#x\n", msix_stat);
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x25D, msix_stat);
+	//fdebug("Stat cleared %#x\n", nlm_hal_read_32bit_reg(xlp_pci_base, 0x25D));
+	return (msix_stat >> (fn * XLP_MSIX_PER_SLOT));
+}
+
+#if 0
+/* required only if xlp_ctrl_fn_from_dev() is static */
+int xlp_msi_base_vector(struct pci_dev *dev)
+{
+	return(XLP_MSI_IRQ_START(xlp_ctrl_fn_from_dev(dev)));
+}
+
+
+int xlp_msix_base_vector(struct pci_dev *dev)
+{
+	return(XLP_MSIX_IRQ_START(xlp_ctrl_fn_from_dev(dev)));
+}
+
+#endif
+
+/*
+ * Masks the bit corresponding to an MSI and return the resulting bitmask
+ */
+u32 xlp_msi_set_mask(int fn, int bit, int val)
+{
+	u64 xlp_pci_base;
+	u32 bits;
+
+	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
+	bits = nlm_hal_read_32bit_reg(xlp_pci_base, 0x25B);
+	if (val == 0) {	/* Clear bit `bit` */
+		bits &= ~( 1 << bit);
+	} else {	/* Set bit `bit` */
+		bits |= ( 1 << bit);
 	}
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x25B, bits);
+	return bits;
+}
 
-	return irq;
+/*
+ * Finds the slot on which this device is placed and clears the MSI status
+ * register on the controller
+ * @dev : pci device corresponding to this device
+ */
+int xlp_msi_status_clear(struct pci_dev *dev, int bit)
+{
+	int fn = 0;
+	u64 xlp_pci_base;
+	u32 msi_en;
+
+	fn = xlp_ctrl_fn_from_dev(dev);
+	if ((fn >= 4) || (fn < 0)) {
+		return -ENODEV;
+	}
+	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
+	msi_en = 1 << bit;
+	nlm_hal_write_32bit_reg(xlp_pci_base, 0x25B, msi_en);
+	return 0;
 }
 
 /* Do platform specific device initialization at pci_enable_device() time */
 int pcibios_plat_dev_init(struct pci_dev *dev)
 {
-	return 0;
+        return 0;
 }
 
 /* Enabled by default */
-static int __initdata xlp_nopci;
+static int __initdata xlp_nopci = 0;
 
 static int __init xlp_nopci_setup(char *str)
 {
@@ -209,36 +878,42 @@ static int __init pcibios_init(void)
 	unsigned long phys = 0;
 	unsigned long size = 0;
 
+	if (xlp_nopci) return 0;
+
 	/* Bootloader assigns PCI resources */
 	pci_probe_only = 1;
 
 	/* Map the PCIX CFG space */
-	pci_config_base = ioremap(DEFAULT_XLP_PCI_CONFIG_BASE, (32<<20));
+	pci_config_base = ioremap(DEFAULT_XLP_PCI_ECONFIG_BASE, DEFAULT_XLP_PCI_CONFIG_SIZE);
 	if (!pci_config_base) {
-		pr_err("Unable to map PCI config space!\n");
+		printk(KERN_ERR "Unable to map PCI config space!\n");
 		return 1;
 	}
 
-	phys = DEFAULT_PCI_IO_BASE;
-	size = DEFAULT_PCI_IO_SIZE;
+	phys = xlp_io_resource.start;
+	size = xlp_io_resource.end - xlp_io_resource.start + 1;
 
 	pci_io_base = ioremap(phys, size);
-	if (!pci_io_base)
-		pr_err("[%s]: Unable to IO-Remap phys=%lx, size=%lx\n",
-		       __func__, phys, size);
-	else
-		pr_err("[%s]: IO-Remapped phys=%lx, size=%lx to vaddr=%p\n",
-		       __func__, phys, size, pci_io_base);
+	if (!pci_io_base) {
+		printk(KERN_WARNING "[%s]: Unable to IO-Remap phys=%lx, size=%lx\n",
+		       __FUNCTION__, phys, size);
+		/* Eventually this is going to panic() */
+	}
+	else {
+		printk(KERN_DEBUG "[%s]: IO-Remapped phys=%lx, size=%lx to vaddr=%p\n",
+		       __FUNCTION__, phys, size, pci_io_base);
+	}
+	set_io_port_base((unsigned long) pci_io_base);
+	xlp_controller.io_map_base = (unsigned long) pci_io_base;
+	xlp_controller.io_map_base -= xlp_controller.io_offset;
 
 	/* IO Range for 16MB from where the MEM Range Ends */
 	ioport_resource.start =  0;
 	ioport_resource.end   = ~0;
 
-	set_io_port_base((unsigned long)pci_io_base);
-	xlp_controller.io_map_base = mips_io_port_base;
-	pr_info("%s: mips_io_port_base = 0x%lx\n", __func__, mips_io_port_base);
-
-	pr_info("Registering XLP PCIE Controller. \n");
+	printk(KERN_DEBUG "Registering XLP PCIE Controller. \n");
+	/* Setting up controller specific data */
+	pcie_controller_init_done();
 	register_pci_controller(&xlp_controller);
 
 	pci_bus_status = 1;
@@ -248,5 +923,90 @@ static int __init pcibios_init(void)
 arch_initcall(pcibios_init);
 
 struct pci_fixup pcibios_fixups[] = {
-{0, }
+	{0}
 };
+
+
+/*
+ * some ide specific io routines on PCI
+ */
+#define pci_ide_phys_to_virt(x) (((x) - (xlp_io_resource.start)) + (unsigned long)pci_io_base )
+
+inline void nlm_ide_mm_insw(unsigned long port, void *addr, u32 count)
+{
+	unsigned long v_port = pci_ide_phys_to_virt(port);
+	while (count--) {
+		*(u16 *)addr = (readw((const volatile void *)v_port));
+		addr += 2;
+	}
+}
+
+EXPORT_SYMBOL(nlm_ide_mm_insw);
+
+inline void nlm_ide_mm_insl(unsigned long port, void *addr, unsigned int count)
+{
+	unsigned long v_port = pci_ide_phys_to_virt(port);
+	while (count--) {
+		*(u32 *)addr = readl((const volatile void *) v_port);
+		addr += 4;
+	}
+}
+EXPORT_SYMBOL(nlm_ide_mm_insl);
+
+inline void nlm_ide_mm_outsw(unsigned long port, void *addr, unsigned int count)
+{
+	unsigned long v_port = pci_ide_phys_to_virt(port);
+	while (count--) {
+		writew(*(u16 *)addr, (volatile void *)v_port);
+		addr += 2;
+	}
+}
+EXPORT_SYMBOL(nlm_ide_mm_outsw);
+
+inline void nlm_ide_mm_outsl(unsigned long port, void *addr, unsigned int count)
+{
+	unsigned long v_port = pci_ide_phys_to_virt(port);
+	while (count--) {
+		writel(*(u32 *)addr, (volatile void *)v_port);
+		addr += 4;
+	}
+}
+EXPORT_SYMBOL(nlm_ide_mm_outsl);
+
+u8 nlm_ide_mm_inb (unsigned long port)
+{
+	return((u8)readb((const volatile void *)pci_ide_phys_to_virt(port)));
+}
+
+EXPORT_SYMBOL(nlm_ide_mm_inb);
+u16 nlm_ide_mm_inw (unsigned long port)
+{
+	return ((u16) (readw((const volatile void *)pci_ide_phys_to_virt(port))));
+}
+
+EXPORT_SYMBOL(nlm_ide_mm_inw);
+/* Not part of hwif anymore; remove static declaration */
+u32 nlm_ide_mm_inl (unsigned long port)
+{
+	return ((u32)readl((const volatile void *)pci_ide_phys_to_virt(port)));
+}
+
+EXPORT_SYMBOL(nlm_ide_mm_inl);
+void nlm_ide_mm_outb (u8 value, unsigned long port)
+{
+	writeb(value, (volatile void *)pci_ide_phys_to_virt(port));
+}
+
+EXPORT_SYMBOL(nlm_ide_mm_outb);
+void nlm_ide_mm_outw (u16 value, unsigned long port)
+{
+	writew(value, (volatile void *)pci_ide_phys_to_virt((u64)port));
+}
+
+EXPORT_SYMBOL(nlm_ide_mm_outw);
+/* Not part of hwif anymore; remove static declaration */
+void nlm_ide_mm_outl (u32 value, unsigned long port)
+{
+	writel((value), (volatile void *)pci_ide_phys_to_virt(port));
+}
+EXPORT_SYMBOL(nlm_ide_mm_outl);
diff --git a/drivers/net/nae/init_nae.c b/drivers/net/nae/init_nae.c
index b5915cc..f9560ac 100644
--- a/drivers/net/nae/init_nae.c
+++ b/drivers/net/nae/init_nae.c
@@ -3,6 +3,7 @@
 #include <linux/mm.h>
 #include <linux/delay.h>
 
+#include <asm/netlogic/msgring.h>
 #include <asm/netlogic/cpumask.h>
 
 #include <asm/netlogic/hal/nlm_hal_fmn.h>
@@ -10,8 +11,6 @@
 #include <asm/netlogic/hal/nlm_hal_xlp_dev.h>
 #include <ops.h>
 
-#include <asm/netlogic/interrupt.h>
-
 #include "net_common.h"
 
 extern int rely_on_firmware_config;
@@ -21,23 +20,23 @@ static void config_fmn(void)
 	unsigned long mflags = 0;
 	struct cpumask cpumask;
 
-	/* bind cpu to n0c0t0 */
+	/* bind cpu to n0c0t0 and drain all leftover firmware messages */
 	sched_bindto_save_affinity(0, &cpumask);
 
 	/* Configure FMN again but only cpu credits */
 	msgrng_access_enable(mflags);
 
-	/* Configure credits to non-n0c0 cores */
-	nlm_hal_fmn_init(0x10000000, 0x02000000, 50);
+	nlm_xlp_msgring_int_handler(XLP_IRQ_MSGRING, NULL);
 
 	msgrng_access_disable(mflags);
 
 	sched_bindto_restore_affinity(&cpumask);
 }
 
+
 int initialize_nae(uint32_t cm0, uint32_t cm1, uint32_t cm2, uint32_t cm3)
 {
-	int dom_id = 0;
+	int dom_id = 0, node;
 	unsigned long mflags;
 
 	config_fmn();
@@ -46,7 +45,16 @@ int initialize_nae(uint32_t cm0, uint32_t cm1, uint32_t cm2, uint32_t cm3)
 	nlm_hal_init_nae(fdt, dom_id);
 
 	printk("Overriding HAL POE configuration based on current active cpumask\n");
-	nlm_hal_init_poe_distvec(0, cm0, cm1, cm2, cm3, (1 << nae_cfg.rx_vc));
+	for(node = 0; node < nlm_node_cfg.num_nodes; node++) {
+		nlm_hal_init_poe_distvec(node, 0, cm0, cm1, cm2, cm3, (1 << nlm_node_cfg.nae_cfg[node]->rx_vc)); 
+	}
+	/* 
+	 {
+		nlm_hal_init_poe_distvec(0, 0, cm0, 0, 0, 0, (1 << nlm_node_cfg.nae_cfg[0]->rx_vc));
+		nlm_hal_init_poe_distvec(1, 0, 0, cm1, 0, 0, (1 << nlm_node_cfg.nae_cfg[1]->rx_vc));
+	 }
+	*/
+	
 
 	msgrng_access_disable(mflags);
 	return 0;
diff --git a/drivers/net/nae/net_common.h b/drivers/net/nae/net_common.h
index cdd3bf4..9cecbcf 100644
--- a/drivers/net/nae/net_common.h
+++ b/drivers/net/nae/net_common.h
@@ -3,70 +3,68 @@
 
 #include <nlm_hal_nae.h>
 
-#define MAX_FMN_CODE		-1
-#define FMN_CREDIT_DEFAULT	8
-#define FMN_POE_CREDIT_DEFAULT	9
-#define MAX_FMN_ARRAY		50
-#define SUCCESS			0
-#define FAIL			-1
-#define CPU0_VC			0
+#define MAX_FMN_CODE            -1
+#define FMN_CREDIT_DEFAULT      8
+#define FMN_POE_CREDIT_DEFAULT      9
+#define MAX_FMN_ARRAY               50
+#define SUCCESS                 0
+#define FAIL                    -1
+#define CPU0_VC                 0
 
-#define CPU_Q_ID(cpu, vid) (((cpu) << 2) | (vid))
+#define CPU_Q_ID(cpu, vid) (cpu)
 
-#define MAX_DEST_QID		50
+#define MAX_DEST_QID            50
 
 typedef struct fmn_credit_struct {
-	unsigned int   s_qid;
-	unsigned int   d_qid;
-	unsigned int   flag;
-	#define SET_UP_QUEUE         0x1
-	#define SET_UP_CREDITS       0x2
-	#define SET_UP_MULTI_DEST    0x4
-	#define SET_UP_MULTI_SRC     0x8
-	unsigned int   q_len;
-	unsigned int   credit;
+   unsigned int   s_qid;
+   unsigned int   d_qid;
+   unsigned int   flag;
+   #define SET_UP_QUEUE         0x1
+   #define SET_UP_CREDITS       0x2
+   #define SET_UP_MULTI_DEST    0x4
+   #define SET_UP_MULTI_SRC     0x8
+   unsigned int   q_len;
+#define FMN_QLEN_USE_DEFAULT      0
+   unsigned int   credit;
 } fmn_credit_type;
 
 extern int init_gmac(unsigned int inf);
-extern int init_tx_if_credit(__u32 credit_val, unsigned int if_bmask);
+extern int init_tx_if_credit( /*uint32_t*/__u32 credit_val, unsigned int if_bmask);
 extern int init_ucore(uint32_t ucore_mask, int if_num);
 extern void init_ingress(void);
 extern void init_egress(void);
 extern int fmn_init(const fmn_credit_type *credit);
-extern void *xlp_init_buffer(size_t size,
-			size_t pbase,
-			uint64_t *vaddr_base);
+extern void *xlp_init_buffer( size_t size,
+			      size_t pbase ,
+			      uint64_t *vaddr_base);
 
 extern void *init_nae_free_pool(int num_queue,
-	unsigned char *pktmem,
-	int num_bytes,
-	int num_desc);
+				unsigned char *pktmem ,
+				int num_bytes,
+				int num_desc);
 extern void print_netreg(void);
 
+#define DBG        1
 #ifdef DBG
-	#define log_dbg     printk
-	#define log_pkt     printk
+    #define log_dbg     printk
+    #define log_pkt     printk
 #else
-	#define log_dbg(...)
-	#define log_pkt(...)
+    #define log_dbg(...)
+    #define log_pkt(...)
+//    #define log_err(...)
 #endif
 #define log_err
-#define log_info	printk
+#define log_info   printk
 
 #ifdef DBG
-static inline void press_key_to_continue(void)
-{
+static __inline__ void press_key_to_continue(void) {
 	log_dbg("press <enter> to continue...\n");
+/*	getchar();*/
 }
 #else
 #define press_key_to_continue()
 #endif
 
-enum NAE_REG_CMD {
-	CMD_READ = 0,
-	CMD_WRITE
-};
-
 #define NAE_RX_ENABLE 0x1
 #define NAE_TX_ENABLE 0x1
 
@@ -74,64 +72,58 @@ struct xlp_msg {
 	uint64_t entry[4];
 };
 
-static inline void msg_print(uint32_t size, uint32_t code, uint32_t dest, struct xlp_msg *msg)
-{
+static __inline__ void msg_print(uint32_t size, uint32_t code, uint32_t dest, struct xlp_msg *msg) {
 	int i;
 	log_dbg("  size = %u\n"
-		"  code = %u (0x%x)\n"
-		"  dest = %u (0x%x)\n",
-		size, code, code, dest, dest);
+	       "  code = %u (0x%x)\n"
+	       "  dest = %u (0x%x)\n",
+	       size, code, code, dest, dest);
 	for (i = 0; i < size && size <= 4; ++i) {
 		log_dbg("  msg.entry%d = 0x%016llx\n",
-			i, msg->entry[i]);
+		       i, msg->entry[i]);
 	}
 }
 
-static inline void poe_print(uint64_t msg0)
-{
-	log_dbg("POE nextfid = %llu (0x%llx)\n"
-		"    nextdist = %llu (0x%llx)\n"
-		"    nextdest = %llu (0x%llx)\n"
-		"    msgaddr = 0x%llx\n"
-		"    fid = %llu (0x%llx)\n",
-		(msg0 >> 48) & 0xffff, (msg0 >> 48) & 0xffff,
-		(msg0 >> 44) & 0xf, (msg0 >> 44) & 0xf,
-		(msg0 >> 32) & 0xfff, (msg0 >> 32) & 0xfff,
-		(msg0 >> 16) & 0xffff,
-		(msg0) & 0xffff, (msg0) & 0xffff);
+static __inline__ void poe_print(uint64_t msg0) {
+	log_dbg("POE nextfid  = %llu (0x%llx)\n"
+	       "    nextdist = %llu (0x%llx)\n"
+	       "    nextdest = %llu (0x%llx)\n"
+	       "    msgaddr  = 0x%llx\n"
+	       "    fid      = %llu (0x%llx)\n",
+	       (msg0 >> 48) & 0xffff, (msg0 >> 48) & 0xffff,
+	       (msg0 >> 44) & 0xf, (msg0 >> 44) & 0xf,
+	       (msg0 >> 32) & 0xfff, (msg0 >> 32) & 0xfff,
+	       (msg0 >> 16) & 0xffff,
+	       (msg0) & 0xffff, (msg0) & 0xffff);
 }
 
-static inline void rx_print(uint64_t msg0)
-{
+static __inline__ void rx_print(uint64_t msg0) {
 	log_dbg("RX  context = %llu\n"
-		"    length = %llu (0x%llx)\n"
-		"    address = 0x%010llx\n"
-		"    unclass = %llu\n"
-		"    err = %llu\n"
-		"    IPcksm = %llu\n"
-		"    TCPcksm = %llu\n"
-		"    prepad = %llu\n"
-		"    p2p = %llu\n",
-		(msg0 >> 54) & 0x3ff,
-		(msg0 >> 40) & 0x3fff, (msg0 >> 40) & 0x3fff,
-		(msg0) & 0xffffffffc0ULL,
-		(msg0 >> 5) & 0x1,
-		(msg0 >> 4) & 0x1,
-		(msg0 >> 3) & 0x1,
-		(msg0 >> 2) & 0x1,
-		(msg0 >> 1) & 0x1,
-		(msg0) & 0x1);
+	       "    length  = %llu (0x%llx)\n"
+	       "    address = 0x%010llx\n"
+	       "    unclass = %llu\n"
+	       "    err     = %llu\n"
+	       "    IPcksm  = %llu\n"
+	       "    TCPcksm = %llu\n"
+	       "    prepad  = %llu\n"
+	       "    p2p     = %llu\n",
+	       (msg0 >> 54) & 0x3ff,
+	       (msg0 >> 40) & 0x3fff, (msg0 >> 40) & 0x3fff,
+	       (msg0) & 0xffffffffc0ULL,
+	       (msg0 >> 5) & 0x1,
+	       (msg0 >> 4) & 0x1,
+	       (msg0 >> 3) & 0x1,
+	       (msg0 >> 2) & 0x1,
+	       (msg0 >> 1) & 0x1,
+	       (msg0) & 0x1);
 }
 
-static inline void buf_print(unsigned char *buf, unsigned long len)
-{
+static __inline__ void buf_print(unsigned char *buf, unsigned long len) {
 	unsigned long i;
 	for (i = 0; i < len; ++i) {
 		log_dbg(" %02x", buf[i]);
-		if (i % 8 == 7)
-			log_dbg(" ");
-		if (i % 32 == 31)
-			log_dbg("\n");
+		if (i % 8 == 7) log_dbg(" ");
+		if (i % 32 == 31) log_dbg("\n");
 	}
 	log_dbg("\n");
 }
@@ -141,28 +133,26 @@ static inline void buf_print(unsigned char *buf, unsigned long len)
 
 #define NULL_VFBID 127
 
-static inline uint64_t nae_tx_desc(unsigned int type,
-	unsigned int rdex, unsigned int fbid, unsigned int len, uint64_t addr)
-{
+static __inline__ uint64_t nae_tx_desc(unsigned int type,
+	unsigned int rdex, unsigned int fbid, unsigned int len, uint64_t addr) {
 	return ((uint64_t)(type & 0x3) << 62) |
-		((uint64_t)(rdex & 0x1) << 61) |
-		((uint64_t)(fbid & 0x7f) << 54) |
-		((uint64_t)(len & 0x3fff) << 40) |
-		(addr&0xffffffffffULL);
+	       ((uint64_t)(rdex & 0x1) << 61) |
+	       ((uint64_t)(fbid & 0x7f) << 54) |
+	       ((uint64_t)(len & 0x3fff) << 40) |
+	       (addr&0xffffffffffULL);
 }
 
-static inline void tx_print(uint64_t msg0)
-{
-	log_dbg("TX  type = %llu\n"
-		"    rdex = %llu\n"
-		"    vfbid = %llu\n"
-		"    length = %llu (0x%llx)\n"
-		"    address = 0x%010llx\n",
-		((msg0 >> 62) & 0x3),
-		((msg0 >> 61) & 0x1),
-		((msg0 >> 54) & 0x7f),
-		((msg0 >> 40) & 0x3fff), ((msg0 >> 40) & 0x3fff),
-		(msg0) & 0xffffffffffULL);
+static __inline__ void tx_print(uint64_t msg0) {
+	log_dbg("TX  type    = %llu\n"
+	       "    rdex    = %llu\n"
+	       "    vfbid   = %llu\n"
+	       "    length  = %llu (0x%llx)\n"
+	       "    address = 0x%010llx\n",
+	       ((msg0 >> 62) & 0x3),
+	       ((msg0 >> 61) & 0x1),
+	       ((msg0 >> 54) & 0x7f),
+	       ((msg0 >> 40) & 0x3fff), ((msg0 >> 40) & 0x3fff),
+	       (msg0) & 0xffffffffffULL);
 }
 
 extern void *fdt;
@@ -170,15 +160,15 @@ extern void *fdt;
 struct nae_port {
 	int  valid;
 	int  mgmt;
-	int  num_free_desc;
-	int  txq_range[2];
-	int  rxq;
-	int  hw_port_id;
+        int  num_free_desc;
+        int  txq_range[2];
+        int  rxq;
+        int  hw_port_id;
 };
 
 struct nae_config {
 	int fb_vc;
-	int rx_vc;
+        int rx_vc;
 	int num_ports;
 	struct nae_port ports[18];
 };
diff --git a/drivers/net/nae/xlp_hw.c b/drivers/net/nae/xlp_hw.c
index e3cea43..3fbd9d7 100644
--- a/drivers/net/nae/xlp_hw.c
+++ b/drivers/net/nae/xlp_hw.c
@@ -1,27 +1,32 @@
-/*
- * Copyright 2003-2010 Netlogic Microsystem, Inc. ("Netlogic"). All rights
- * reserved.
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- * 1. Redistributions of source code must retain the above copyright
- * notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- * notice, this list of conditions and the following disclaimer in
- * the documentation and/or other materials provided with the
- * distribution.
- * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems, Inc. ``AS IS'' AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
- * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
- * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
- * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
- * THE POSSIBILITY OF SUCH DAMAGE.
- *****************************#NLM_2#**********************************/
+/*********************************************************************
+
+  Copyright 2003-2010 Netlogic Microsystem, Inc. ("Netlogic"). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#NLM_2#**********************************/
 
 #include <linux/types.h>
 #include <linux/module.h>
@@ -42,14 +47,13 @@
 #define PHY_STATUS_RETRIES 25000
 
 #define DRV_NAME	"xlp_nae"
-#define DRV_VERSION	"0.1"
+#define DRV_VERSION     "0.1"
 
 static void nlm_xlp_mac_mii_write(struct dev_data *priv, int regidx, uint16_t regval);
 static unsigned int nlm_xlp_mac_mii_read(struct dev_data *priv, int regidx);
 void nlm_xlp_mac_set_enable(struct dev_data *priv, int flag);
 static int xlp_enable_autoneg(struct net_device *dev, u32 adv);
 static int xlp_set_link_speed(struct net_device *dev, int speed, int duplex);
-static u32 mac_debug;
 
 static int xlp_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
 {
@@ -66,7 +70,9 @@ static int xlp_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
 		cmd->autoneg = AUTONEG_DISABLE;
 		cmd->maxtxpkt = 0;
 		cmd->maxrxpkt = 0;
-	} else {
+
+	}else{
+
 		cmd->supported = SUPPORTED_10baseT_Full |
 			SUPPORTED_10baseT_Half |
 			SUPPORTED_100baseT_Full | SUPPORTED_100baseT_Half |
@@ -79,7 +85,7 @@ static int xlp_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
 		priv->speed = (mii_status >> 3) & 0x03;
 
 		cmd->speed = (priv->speed == xlp_mac_speed_1000) ? SPEED_1000 :
-			(priv->speed == xlp_mac_speed_100) ? SPEED_100 : SPEED_10;
+		(priv->speed == xlp_mac_speed_100) ? SPEED_100: SPEED_10;
 
 		cmd->duplex = (mii_status >> 5) & 0x1;
 		cmd->port = PORT_TP;
@@ -108,18 +114,18 @@ static int xlp_enable_autoneg(struct net_device *dev, u32 adv)
 	adv2 = nlm_xlp_mac_mii_read(priv, 0x9);
 	adv2 &= ~(0x300);
 
-	if (adv & ADVERTISED_10baseT_Half)
+	if(adv & ADVERTISED_10baseT_Half)
 		adv1 |= ADVERTISE_10HALF;
-	if (adv & ADVERTISED_10baseT_Full)
+	if(adv & ADVERTISED_10baseT_Full)
 		adv1 |= ADVERTISE_10FULL;
-	if (adv & ADVERTISED_100baseT_Full)
+	if(adv & ADVERTISED_100baseT_Full)
 		adv1 |= ADVERTISE_100FULL;
-	if (adv & ADVERTISED_100baseT_Half)
+	if(adv & ADVERTISED_100baseT_Half)
 		adv1 |= ADVERTISE_100HALF;
 
-	if (adv & ADVERTISED_1000baseT_Full)
+	if(adv & ADVERTISED_1000baseT_Full)
 		adv2 |= 0x200;
-	if (adv & ADVERTISED_1000baseT_Half)
+	if(adv & ADVERTISED_1000baseT_Half)
 		adv2 |= 0x100;
 
 	/* Set the advertising parameters */
@@ -142,31 +148,34 @@ static int xlp_enable_autoneg(struct net_device *dev, u32 adv)
 static int xlp_set_link_speed(struct net_device *dev, int speed, int duplex)
 {
 	u32 adv;
-
-	switch (speed) {
-	case SPEED_10:
-		if (duplex == DUPLEX_FULL)
-			adv = ADVERTISED_10baseT_Full;
-		else
-			adv = ADVERTISED_10baseT_Half;
-		break;
-	case SPEED_100:
-		if (duplex == DUPLEX_FULL)
-			adv = ADVERTISED_100baseT_Full;
-		else
-			adv = ADVERTISED_100baseT_Half;
-		break;
-	case SPEED_1000:
-		if (duplex == DUPLEX_FULL)
-			adv = ADVERTISED_1000baseT_Full;
-		else
-			adv = ADVERTISED_1000baseT_Half;
-		break;
-	default:
-		return -EINVAL;
+	int ret =0;
+
+	switch(speed) {
+		case SPEED_10:
+			if ( duplex == DUPLEX_FULL )
+				adv = ADVERTISED_10baseT_Full;
+			else
+				adv = ADVERTISED_10baseT_Half;
+			break;
+		case SPEED_100:
+			if ( duplex == DUPLEX_FULL )
+				adv = ADVERTISED_100baseT_Full;
+			else
+				adv = ADVERTISED_100baseT_Half;
+			break;
+		case SPEED_1000:
+			if ( duplex == DUPLEX_FULL )
+				adv = ADVERTISED_1000baseT_Full;
+			else
+				adv = ADVERTISED_1000baseT_Half;
+			break;
+		default:
+			ret = -EINVAL;
+			return ret;
 	}
+	ret = xlp_enable_autoneg( dev,adv);
+	return ret;
 
-	return xlp_enable_autoneg(dev, adv);
 }
 
 static int xlp_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
@@ -174,18 +183,19 @@ static int xlp_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
 	int ret;
 	struct dev_data *priv = netdev_priv(dev);
 
-	if (priv->type != SGMII_IF)
+	if (priv->type != SGMII_IF) {
 		return -EIO;
-
-	if (cmd->autoneg == AUTONEG_ENABLE)
+	}
+	if (cmd->autoneg == AUTONEG_ENABLE) {
 		ret = xlp_enable_autoneg(dev, cmd->advertising);
-	else
+	}else {
 		ret = xlp_set_link_speed(dev, cmd->speed, cmd->duplex);
+	}
 	return ret;
 }
 
 static void xlp_get_drvinfo(struct net_device *dev,
-	struct ethtool_drvinfo *info)
+				struct ethtool_drvinfo *info)
 {
 	strcpy(info->driver, DRV_NAME);
 	strcpy(info->version, DRV_VERSION);
@@ -196,7 +206,7 @@ static int xlp_get_regs_len(struct net_device *dev)
 	return NLM_ETHTOOL_REG_LEN;
 }
 static void xlp_get_regs(struct net_device *dev,
-	struct ethtool_regs *regs, void *p)
+				struct ethtool_regs *regs, void *p)
 {
 	u32 *data = (u32 *)p;
 	int i;
@@ -206,17 +216,17 @@ static void xlp_get_regs(struct net_device *dev,
 	memset((void *)data, 0, NLM_ETHTOOL_REG_LEN);
 
 	spin_lock_irqsave(&priv->lock, flags);
-	for (i = 0; i <= NLM_NUM_REG_DUMP; i++)
-		*(data + i) = nlm_hal_read_mac_reg(priv->block, priv->index, R_TX_CONTROL + i);
+	for(i=0; i <= NLM_NUM_REG_DUMP; i++)
+		*(data + i) = nlm_hal_read_mac_reg(priv->node, priv->block, priv->index,  R_TX_CONTROL + i);
 	spin_unlock_irqrestore(&priv->lock, flags);
 }
 static u32 xlp_get_msglevel(struct net_device *dev)
 {
-	return mac_debug;
+	return 0; //mac_debug;
 }
 static void xlp_set_msglevel(struct net_device *dev, u32 value)
 {
-	mac_debug = value;
+//	mac_debug = value;
 }
 
 static int xlp_nway_reset(struct net_device *dev)
@@ -231,7 +241,8 @@ static int xlp_nway_reset(struct net_device *dev)
 
 	spin_lock_irqsave(&priv->lock, flags);
 	mii_status = nlm_xlp_mac_mii_read(priv, MII_BMCR);
-	if (mii_status & BMCR_ANENABLE) {
+	if(mii_status & BMCR_ANENABLE)
+	{
 		nlm_xlp_mac_mii_write(priv,
 				MII_BMCR, BMCR_ANRESTART | mii_status);
 		ret = 0;
@@ -253,12 +264,14 @@ static u32 xlp_get_link(struct net_device *dev)
 
 	spin_unlock_irqrestore(&priv->lock, flags);
 
-	return mii_status & BMSR_LSTATUS;
+	if(mii_status & BMSR_LSTATUS)
+		return 1;
+	return 0;
 }
-#define NLM_STATS_KEY_LEN	\
-	(sizeof(struct net_device_stats) / sizeof(unsigned long))
+#define NLM_STATS_KEY_LEN  \
+		(sizeof(struct net_device_stats) / sizeof(unsigned long))
 static struct {
-	const char string[ETH_GSTRING_LEN];
+	        const char string[ETH_GSTRING_LEN];
 } xlp_ethtool_stats_keys[NLM_STATS_KEY_LEN] = {
 	{ "rx_packets" },
 	{ "tx_packets" },
@@ -284,16 +297,9 @@ static struct {
 	{ "rx_compressed" },
 	{ "tx_compressed" }
 };
-
-static int xlp_get_sset_count (struct net_device *netdev,
-	int string_set)
+static int xlp_get_stats_count (struct net_device *dev)
 {
-	switch (string_set) {
-	case ETH_SS_STATS:
-		return NLM_STATS_KEY_LEN;
-	default:
-		return -EINVAL;
-	}
+	return NLM_STATS_KEY_LEN;
 }
 
 static void xlp_get_strings (struct net_device *dev, u32 stringset, u8 *buf)
@@ -301,61 +307,60 @@ static void xlp_get_strings (struct net_device *dev, u32 stringset, u8 *buf)
 	switch (stringset) {
 	case ETH_SS_STATS:
 		memcpy(buf, &xlp_ethtool_stats_keys,
-			sizeof(xlp_ethtool_stats_keys));
+				sizeof(xlp_ethtool_stats_keys));
 		break;
 	default:
-		pr_warning("%s: Invalid stringset %d\n",
-			__func__, stringset);
+		printk(KERN_WARNING "%s: Invalid stringset %d\n",
+				__func__, stringset);
 		break;
 	}
 }
 
 
-/*
+/**********************************************************************
  * xlp_get_mac_stats -  collect stats info from Mac stats register
  * @dev   -  this is per device based function
  * @stats -  net device stats structure
- */
+ **********************************************************************/
 void xlp_get_mac_stats(struct net_device *dev, struct net_device_stats *stats)
 {
 	struct dev_data *priv = netdev_priv(dev);
 
-	if (priv->type != SGMII_IF)
+	if (priv->type == INTERLAKEN_IF)
 		return;
 
-	stats->tx_errors = nlm_hal_read_mac_reg(priv->block, priv->index, TX_FCS_ERROR_COUNTER);
-	stats->rx_dropped = nlm_hal_read_mac_reg(priv->block, priv->index, RX_DROP_PACKET_COUNTER);
-	stats->tx_dropped = nlm_hal_read_mac_reg(priv->block, priv->index, TX_DROP_FRAME_COUNTER);
-	stats->multicast = nlm_hal_read_mac_reg(priv->block, priv->index, RX_MULTICAST_PACKET_COUNTER);
-	stats->collisions = nlm_hal_read_mac_reg(priv->block, priv->index, TX_TOTAL_COLLISION_COUNTER);
-	stats->rx_length_errors = nlm_hal_read_mac_reg(priv->block, priv->index, RX_FRAME_LENGTH_ERROR_COUNTER);
-	stats->rx_over_errors = nlm_hal_read_mac_reg(priv->block, priv->index, RX_DROP_PACKET_COUNTER);
-	stats->rx_crc_errors = nlm_hal_read_mac_reg(priv->block, priv->index, RX_FCS_ERROR_COUNTER);
-	stats->rx_frame_errors = nlm_hal_read_mac_reg(priv->block, priv->index, RX_ALIGNMENT_ERROR_COUNTER);
-	stats->rx_fifo_errors = nlm_hal_read_mac_reg(priv->block, priv->index, RX_DROP_PACKET_COUNTER);
-	stats->rx_missed_errors = nlm_hal_read_mac_reg(priv->block, priv->index, RX_CARRIER_SENSE_ERROR_COUNTER);
-	stats->rx_errors = (stats->rx_over_errors + stats->rx_crc_errors + stats->rx_frame_errors + stats->rx_fifo_errors + stats->rx_missed_errors);
-	stats->tx_aborted_errors = nlm_hal_read_mac_reg(priv->block, priv->index, TX_EXCESSIVE_COLLISION_PACKET_COUNTER);
+	stats->tx_errors = nlm_hal_read_mac_reg( priv->node, priv->block, priv->index, TX_FCS_ERROR_COUNTER);
+	stats->tx_dropped = nlm_hal_read_mac_reg( priv->node, priv->block, priv->index, TX_DROP_FRAME_COUNTER);
+	stats->multicast = nlm_hal_read_mac_reg( priv->node, priv->block, priv->index, RX_MULTICAST_PACKET_COUNTER);
+	stats->collisions = nlm_hal_read_mac_reg( priv->node, priv->block, priv->index, TX_TOTAL_COLLISION_COUNTER);
+	stats->rx_length_errors = nlm_hal_read_mac_reg( priv->node, priv->block, priv->index, RX_FRAME_LENGTH_ERROR_COUNTER);
+	stats->rx_over_errors = nlm_hal_read_mac_reg( priv->node, priv->block, priv->index, RX_DROP_PACKET_COUNTER);
+	stats->rx_crc_errors = nlm_hal_read_mac_reg( priv->node, priv->block, priv->index, RX_FCS_ERROR_COUNTER);
+	stats->rx_frame_errors = nlm_hal_read_mac_reg( priv->node, priv->block, priv->index, RX_ALIGNMENT_ERROR_COUNTER);
+	stats->rx_fifo_errors = nlm_hal_read_mac_reg( priv->node, priv->block, priv->index,RX_DROP_PACKET_COUNTER);
+	stats->rx_missed_errors = nlm_hal_read_mac_reg( priv->node, priv->block, priv->index,RX_CARRIER_SENSE_ERROR_COUNTER);
+	stats->rx_errors = (stats->rx_over_errors + stats->rx_crc_errors + stats->rx_frame_errors + stats->rx_fifo_errors +stats->rx_missed_errors);
+	stats->tx_aborted_errors = nlm_hal_read_mac_reg( priv->node, priv->block, priv->index, TX_EXCESSIVE_COLLISION_PACKET_COUNTER);
 	/*
-	stats->tx_carrier_errors = nlm_hal_read_mac_reg( priv->block, priv->index, TX_DROP_FRAME_COUNTER);
-	stats->tx_fifo_errors = nlm_hal_read_mac_reg( priv->block, priv->index, TX_DROP_FRAME_COUNTER);
+	stats->tx_carrier_errors = nlm_hal_read_mac_reg( priv->node, priv->block, priv->index, TX_DROP_FRAME_COUNTER);
+	stats->tx_fifo_errors = nlm_hal_read_mac_reg( priv->node, priv->block, priv->index, TX_DROP_FRAME_COUNTER);
 	*/
 	return;
 }
 
-/*
+/**********************************************************************
  * xlp_get_ethtool_stats -  part of ethtool_ops member function
  * @dev   -  this is per device based function
  * @stats -  net device stats structure
-*/
+ **********************************************************************/
 static void xlp_get_ethtool_stats (struct net_device *dev,
-	struct ethtool_stats *estats, u64 *stats)
+			struct ethtool_stats *estats, u64 *stats)
 {
 	int i;
 	struct dev_data *priv = netdev_priv(dev);
 	unsigned long flags;
 	unsigned long *tmp_stats;
-
+	
 	spin_lock_irqsave(&priv->lock, flags);
 
 	xlp_get_mac_stats(dev, &priv->stats);
@@ -364,14 +369,14 @@ static void xlp_get_ethtool_stats (struct net_device *dev,
 	spin_unlock_irqrestore(&priv->lock, flags);
 
 	tmp_stats = (unsigned long *)&priv->stats;
-	for (i = 0; i < NLM_STATS_KEY_LEN; i++) {
+	for(i=0; i < NLM_STATS_KEY_LEN; i++) {
 		*stats = (u64)*tmp_stats;
 		stats++;
 		tmp_stats++;
 	}
 }
 
-/*
+/**********************************************************************
  *  nlm_xlp_mac_mii_read - Read mac mii phy register
  *
  *  Input parameters:
@@ -381,13 +386,13 @@ static void xlp_get_ethtool_stats (struct net_device *dev,
  *
  *  Return value:
  *  	   value read (16 bits), or 0xffffffff if an error occurred.
- */
+ ********************************************************************* */
 static unsigned int nlm_xlp_mac_mii_read(struct dev_data *priv, int regidx)
 {
-	return nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, priv->phy.addr, regidx);
+        return nlm_hal_mdio_read(priv->node, NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, priv->phy.addr, regidx);
 }
 
-/*
+/**********************************************************************
  *  nlm_xlp_mac_mii_write -Write mac mii PHY register.
  *
  *  Input parameters:
@@ -397,26 +402,25 @@ static unsigned int nlm_xlp_mac_mii_read(struct dev_data *priv, int regidx)
  *
  *  Return value:
  *  	   nothing
- */
+ ********************************************************************* */
 static void nlm_xlp_mac_mii_write(struct dev_data *priv, int regidx, uint16_t regval)
 {
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, priv->phy.addr, regidx, regval);
+	nlm_hal_mdio_write(priv->node, NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, priv->phy.addr, regidx, regval);
 	return;
 }
 
-static struct ethtool_ops xlp_ethtool_ops = {
-	.get_settings = xlp_get_settings,
-	.set_settings = xlp_set_settings,
-	.get_drvinfo = xlp_get_drvinfo,
-	.get_regs_len = xlp_get_regs_len,
-	.get_regs = xlp_get_regs,
-	.get_msglevel = xlp_get_msglevel,
-	.set_msglevel = xlp_set_msglevel,
-	.nway_reset = xlp_nway_reset,
-	.get_link = xlp_get_link,
-	.get_strings = xlp_get_strings,
-	.get_sset_count = xlp_get_sset_count,
-	.get_ethtool_stats = xlp_get_ethtool_stats,
+static struct ethtool_ops xlp_ethtool_ops= {
+        .get_settings           = xlp_get_settings,
+        .set_settings           = xlp_set_settings,
+        .get_drvinfo            = xlp_get_drvinfo,
+        .get_regs_len           = xlp_get_regs_len,
+        .get_regs               = xlp_get_regs,
+        .get_msglevel           = xlp_get_msglevel,
+        .set_msglevel           = xlp_set_msglevel,
+        .nway_reset             = xlp_nway_reset,
+        .get_link               = xlp_get_link,
+        .get_strings            = xlp_get_strings,
+        .get_ethtool_stats      = xlp_get_ethtool_stats,
 };
 
 void xlp_set_ethtool_ops(struct net_device *netdev)
@@ -425,55 +429,57 @@ void xlp_set_ethtool_ops(struct net_device *netdev)
 }
 
 
+/**********************************************************************
+ **********************************************************************/
 void nlm_xlp_mac_set_enable(struct dev_data *priv, int flag)
 {
 	int inf;
 	uint32_t speed = 0, duplex = 0, ifmode = 0;
 	uint32_t netwk_inf = 0, mac_cfg2 = 0;
+	
 
 	if ((priv->type != SGMII_IF) && (priv->type != XAUI_IF))
 		return;
-	switch (priv->type) {
-	case SGMII_IF:
-		inf = (priv->block * 4) + priv->index;
-		break;
-	case XAUI_IF:
-	case INTERLAKEN_IF:
-		inf = priv->block;
-		break;
-	default:
-		return;
+	switch(priv->type) {
+		case SGMII_IF:
+			inf = (priv->block * 4) + priv->index;
+			break;
+		case XAUI_IF:
+		case INTERLAKEN_IF:
+			inf = priv->block;
+			break;
+		default:
+			return;
 	}
 
 	if (flag) {
 		if (priv->type == SGMII_IF) {
-			if (nlm_hal_get_phy_status(inf, &speed, &duplex)) {
-				/* nlm_print("mac set enable speed %d duplex %d\n",speed, duplex); */
-				ifmode = ((speed == 2) ? 2 : 1);
-				nlm_hal_mac_disable(inf, priv->type);
-				netwk_inf = read_gmac_reg(inf, NETWK_INF_CTRL_REG);
-				netwk_inf &= (~(0x3));
-				write_gmac_reg(inf , NETWK_INF_CTRL_REG, netwk_inf | speed);
-				mac_cfg2 = read_gmac_reg(inf, MAC_CONF2);
-				mac_cfg2 &= (~((0x3 << 8) | 1));
-				write_gmac_reg(inf , MAC_CONF2,
-					      mac_cfg2 | (ifmode << 8) | duplex);
+			if (nlm_hal_get_phy_status(priv->node, inf, &speed, &duplex)) {
+				//nlm_print("mac set enable speed %d duplex %d\n",speed, duplex);
+				ifmode = ((speed == 2) ? 2: 1);
+				nlm_hal_mac_disable(priv->node, inf, priv->type);
+			        netwk_inf  = read_gmac_reg(priv->node, inf, NETWK_INF_CTRL_REG);
+		        	netwk_inf &= (~(0x3));
+	        		write_gmac_reg(priv->node, inf , NETWK_INF_CTRL_REG, netwk_inf | speed);
+		        	mac_cfg2 = read_gmac_reg(priv->node, inf, MAC_CONF2);
+	        		mac_cfg2 &= (~((0x3 << 8) | 1));
+		        	write_gmac_reg(priv->node, inf , MAC_CONF2,
+                			              mac_cfg2 | (ifmode << 8) | duplex);
 			}
 		}
-		nlm_hal_mac_enable(inf, priv->type);
+		nlm_hal_mac_enable(priv->node, inf, priv->type);
 	} else {
-		nlm_hal_mac_disable(inf, priv->type);
+		nlm_hal_mac_disable(priv->node, inf, priv->type);
 	}
 }
 
 int nlm_xlp_link_up(struct dev_data *priv, int phy)
 {
-	uint16_t extstatus;
+        uint16_t extstatus;
 
 	if (priv->type != SGMII_IF)
-		return -EIO;
-	nlm_hal_mdio_write(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, priv->phy.addr, 22, 0);
-	extstatus = nlm_hal_mdio_read(NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, priv->phy.addr, 17);
-
-	return (extstatus & 0x0400) ? 1 : 0;
+                return -EIO;
+        nlm_hal_mdio_write(priv->node, NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, priv->phy.addr, 22, 0);
+        extstatus = nlm_hal_mdio_read(priv->node, NLM_HAL_EXT_MDIO, 0, BLOCK_7, LANE_CFG, priv->phy.addr, 17);
+        return ((extstatus & 0x0400) ? 1 : 0 );
 }
diff --git a/drivers/net/nae/xlp_nae.c b/drivers/net/nae/xlp_nae.c
index d002ed0..899c754 100644
--- a/drivers/net/nae/xlp_nae.c
+++ b/drivers/net/nae/xlp_nae.c
@@ -47,14 +47,15 @@
 #include <asm/current.h>
 #include <asm/system.h>
 #include <asm/uaccess.h>
+#include <asm/netlogic/msgring.h>
 #include <asm/netlogic/cpumask.h>
+#include <asm/netlogic/xlp.h>
 
 #include <asm/netlogic/hal/nlm_hal_fmn.h>
 #include <asm/netlogic/hal/nlm_hal_nae.h>
-#include <asm/netlogic/hal/nlm_hal_pic.h>
+#include <asm/netlogic/xlp_hal_pic.h>
 
 #include <asm/netlogic/hal/nlm_hal_macros.h>
-#include <asm/mach-netlogic/nlm_kexec.h>
 
 #include <asm/netlogic/mips-exts.h>
 
@@ -64,10 +65,22 @@
 #if 1
 #include <asm/atomic.h>
 
-#define STATS_SET(x, v)	atomic64_set((atomic64_t *)&(x), (v))
-#define STATS_ADD(x, v)	atomic64_add((long)(v), (atomic64_t *)&(x))
-#define STATS_INC(x)	atomic64_inc((atomic64_t *)&(x))
-#define STATS_READ(x)	atomic64_read((atomic64_t *)&(x))
+#ifdef CONFIG_64BIT
+#define STATS_SET(x,v)         atomic64_set((atomic64_t *)&(x), (v))
+#define STATS_ADD(x,v)         atomic64_add((long)(v), (atomic64_t *)&(x))
+#define STATS_DEC(x)           atomic64_dec((atomic64_t *)&(x))
+#define STATS_INC(x)           atomic64_inc((atomic64_t *)&(x))
+#define STATS_READ(x)          atomic64_read((atomic64_t *)&(x))
+#define STATS_INC_RET(x)       atomic64_inc_return((atomic64_t *)&(x))
+#else
+#define STATS_SET(x,v)         atomic_set((atomic_t *)&(x), (v))
+#define STATS_ADD(x,v)         atomic_add((long)(v), (atomic_t *)&(x))
+#define STATS_INC(x)           atomic_inc((atomic_t *)&(x))
+#define STATS_DEC(x)           atomic_dec((atomic_t *)&(x))
+#define STATS_READ(x)          atomic_read((atomic_t *)&(x))
+#define STATS_INC_RET(x)       atomic_inc_return((atomic_t *)&(x))
+#endif
+
 #else
 #define STATS_SET(x, v)	do { (x) = (v); } while (0)
 #define STATS_ADD(x, v)	do { (x) += (v); } while (0)
@@ -94,36 +107,212 @@
 #define ETH_MTU_SIZE			1536
 #define MIN_ETH_FRAME_SIZE		64
 
-#define DUMP_PKT(str, x, y) if (debug == 2) { \
-	int i;					\
-	pr_info(" %s \n", str);                 \
-	for (i = 0; i < y; i++)	{		\
-		pr_info("%02x ", (x)[i]);	\
-		if (i % 16 == 15)		\
-			pr_info("\n");		\
-	}					\
-	pr_info("\n"); }
+#define  DUMP_PKT(str, x, y)	if (debug == 2)  {	\
+	int i;      				\
+        printk(" %s \n", str);                  \
+        for(i = 0; i < y; i++)			\
+        {					\
+                printk("%02x ", (x)[i]);		\
+                if( i % 16 == 15)		\
+                        printk("\n");		\
+        }					\
+	printk("\n"); }
+
+/* This includes extra space and so with 64K PAGE_SIZE, we can have upto 
+   7 buffers. We need 32 bytes for prepad and another cacheline for storing
+   s/w info
+ */
+#ifdef CONFIG_64BIT
+#define DEFAULT_JUMBO_MTU	5568  // for mtu 16384 : 5568
+#else
+#define DEFAULT_JUMBO_MTU       3268  // for mtu 16384 : 5568
+#endif
+#define JUMBO_RX_OFFSET		64
+#define PREPAD_LEN		0	
+/* THIS MUST be multiple of cache line size */
+#define DEFAULT_JUMBO_BUFFER_SIZE	\
+		(DEFAULT_JUMBO_MTU + PREPAD_LEN + JUMBO_RX_OFFSET) 
+
+#define NETL_JUMBO_SKB_HDR_LEN 64
+#define MAC_FRIN_WORK_NUM NR_CPUS
+#define PHOENIX_MAX_MACS 18
+#define MAX_TSO_SKB_PEND_REQS 50
+
+static uint32_t maxnae;
+/* THIS MUST be multiple of cache line size */
+static int jumbo_buffer_size = DEFAULT_JUMBO_BUFFER_SIZE; /*or set in set_mtu */
+static int jumbo_mtu = DEFAULT_JUMBO_MTU; /* or set in set_mtu */
+typedef struct jumbo_rx_info {
+	struct page *page;
+	unsigned int page_offset; 
+	unsigned int space;
+	atomic_t alloc_fails[NLM_MAX_NODES][PHOENIX_MAX_MACS];
+}jumbo_rx_info_t;
+
+/* This struct size MUST be at most 32 bytes */
+struct jumbo_rx_cookie {
+	struct page *page;
+	unsigned int page_offset;
+};
+
+jumbo_rx_info_t  jumbo_rx_buff[NR_CPUS];
+//static struct tasklet_struct mac_frin_replenish_task[MAC_FRIN_WORK_NUM];
+static struct work_struct mac_frin_replenish_work[MAC_FRIN_WORK_NUM];
+static void mac_frin_replenish(unsigned long arg /* ignored */);
+static void tx_free_buffer(unsigned long arg /* ignored */);
+
+#define MAX_PACKET_SZ_PER_MSG	16384
+#define P2P_EXTRA_DESCS	      	((PAGE_SIZE / MAX_PACKET_SZ_PER_MSG) + 4)
+#define P2P_SKB_OFF	      	(MAX_SKB_FRAGS + P2P_EXTRA_DESCS - 1)
+#define CPU_INDEX(x) (x * 8)
+
+
+struct p2p_desc_mem {
+	void *mem;
+	uint64_t dsize;
+	uint64_t pad[6];
+	spinlock_t lock;
+};
+struct p2p_desc_mem p2p_desc_mem[NR_CPUS] __cacheline_aligned;
+static uint64_t p2p_dynamic_alloc_cnt[NR_CPUS * 8] __cacheline_aligned;
+static int p2p_desc_mem_init(void);
+
+enum msc_opcodes { IP_CHKSUM = 1,
+	TCP_CHKSUM,
+	UDP_CHKSUM,
+	SCTP_CRC,
+	FCOE_CRC,
+	IP_TCP_CHKSUM,
+	TSO_IP_TCP_CHKSUM,
+	IP_UDP_CHKSUM,
+	IP_CHKSUM_SCTP_CRC
+};
+
+uint16_t tcp_pseuodo_chksum(uint16_t *ipsrc)
+{
+	uint32_t sum = 0;
+	//*ipsrc = cpu_to_be16p(ipsrc);
+	sum += cpu_to_be16(ipsrc[0]);
+	sum += cpu_to_be16(ipsrc[1]);
+	sum += cpu_to_be16(ipsrc[2]);
+	sum += cpu_to_be16(ipsrc[3]);
+	sum += 6;
+	while(sum >> 16)
+		sum = (sum & 0xffff)  + (sum >> 16);
+	//      sum = ~sum;
+	return (uint16_t)sum;
+}
+
+uint16_t udp_pseuodo_chksum(uint16_t *ipsrc)
+{
+	uint32_t sum = 0;
+	sum += cpu_to_be16(ipsrc[0]);
+	sum += cpu_to_be16(ipsrc[1]);
+	sum += cpu_to_be16(ipsrc[2]);
+	sum += cpu_to_be16(ipsrc[3]);
+	sum += 0x11;
+	while(sum >> 16)
+		sum = (sum & 0xffff)  + (sum >> 16);
+	//      sum = ~sum;
+	return (uint16_t)sum;
+}
+
+
+static __inline__ uint64_t nae_tso_desc0(
+		unsigned int type,
+		unsigned int subtype,
+		unsigned int opcode,
+		unsigned int l3hdroff,
+		unsigned int l4hdroff,
+		unsigned int l3chksumoff,
+		unsigned int pseudohdrchksum,
+		unsigned int l4chksumoff,
+		unsigned int pyldoff)
+{
+
+	return ((uint64_t)(type & 0x3) << 62) |
+		((uint64_t)(subtype & 3) << 60) |
+		((uint64_t)(opcode & 0xf) << 56) |
+		((uint64_t)(l3hdroff & 0x3f) << 43) |
+		((uint64_t)(l4hdroff & 0x7f) << 36) |
+		((uint64_t)(l3chksumoff & 0x1f) << 31) |
+		((uint64_t)(pseudohdrchksum & 0xffff) << 15) |
+		((uint64_t)(l4chksumoff & 0x7f) << 8) |
+		((uint64_t)(pyldoff & 0xff));
+}
+
+static __inline__ uint64_t nae_tso_desc1(
+		unsigned int type,
+		unsigned int subtype,
+		unsigned int poly,
+		unsigned int mss,
+		unsigned int crcstopoff,
+		unsigned int crcinsoff)
+{
+	return ((uint64_t)(type & 0x3) << 62) |
+		((uint64_t)(subtype & 3) << 60) |
+		((uint64_t)(poly & 0x3) << 48) |
+		((uint64_t)(mss & 0xffff) << 32) |
+		((uint64_t)(crcstopoff & 0xffff) << 16) |
+		((uint64_t)(crcinsoff & 0xffff));
+
+}
+
+static __inline__ int tso_enable(struct net_device *dev, u32 data)
+{
+	int rv;
+	rv = ethtool_op_set_tso(dev, data);
+	if(rv == 0)
+		rv = ethtool_op_set_tx_csum(dev, data);
+	if(rv == 0)
+		rv = ethtool_op_set_sg(dev, data);
+	dev->features |= NETIF_F_FRAGLIST | NETIF_F_HIGHDMA;
+	return rv;
+}
+
+
+
+#ifdef CONFIG_64BIT
+#define MY_XKPHYS 0xa800000000000000ULL
+#else
+#define MY_XKPHYS 0xc0000000
+#endif
+static inline struct jumbo_rx_cookie *get_rx_cookie(uint64_t phys)
+{
+	/* rx cookie is  stored one cacheline before the start of rxbuf */
+	unsigned long *ptr = (unsigned long *)(unsigned long)
+		 		(MY_XKPHYS | (phys - SMP_CACHE_BYTES));
+
+	return (struct jumbo_rx_cookie *)ptr;
+}
+
+/* Here 
+   length -> is the exact length of the data (excluding BYTE_OFFSET, CRClen,
+   prepad)
+   hlen -> is the length of the data to be copied to the skb 
+   */
 
 /* Module Parameters */
-static int debug;
+static int debug = 0;
 module_param(debug, int, 0);
 
 static int drop_uboot_pkt = 1;
 module_param(drop_uboot_pkt, int, 0);
 static unsigned long stats_uboot_pkts;
 
-extern int naecfg_hack;
+int naecfg_hack = 1;
 module_param(naecfg_hack, int, 0);
 
-/*
+/***************************************************************
  *
  * Below parameters are set during FDT file parsing
  */
-int frin_desc_thres = 24;
+static int frin_desc_thres = 24;
 module_param(frin_desc_thres, int, 0);
 
-static uint32_t nae_rx_vc;
-static uint32_t nae_fb_vc;
+extern uint32_t nae_rx_vc;
+extern uint32_t nae_fb_vc;
+/***************************************************************/
 
 unsigned char eth_hw_addr[18][6] = {
 	{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x05},
@@ -148,9 +337,9 @@ unsigned char eth_hw_addr[18][6] = {
 
 #define ETHER_FRAME_MIN_LEN	64
 static struct pci_device_id soc_pci_table[] __devinitdata = {
-	{ PCI_NETL_VENDOR, PCI_DEVID_BASE + PCI_DEVID_OFF_NET,
-	PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0},
-	{ 0, }
+        {PCI_NETL_VENDOR, PCI_DEVID_BASE + PCI_DEVID_OFF_NET,
+         PCI_ANY_ID, PCI_ANY_ID, 0},
+        {}
 };
 
 extern void xlp_set_ethtool_ops(struct net_device *netdev);
@@ -166,6 +355,7 @@ static int  nlm_xlp_nae_ioctl (struct net_device *dev, struct ifreq *rq, int cmd
 static int  nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu);
 static void  nlm_xlp_nae_tx_timeout (struct net_device *dev);
 static void xlp_mac_setup_hwaddr(struct dev_data *priv);
+static int nlm_xlp_nae_set_hwaddr(struct net_device *dev, void *p);
 
 #ifdef	ENABLE_NAE_PIC_INT
 static irqreturn_t nlm_xlp_nae_int_handler(int irq, void *dev_id);
@@ -326,7 +516,7 @@ static int mac_refill_frin_desc(unsigned long dev)
 	priv = netdev_priv(ndev);
 	ret = 0;
 
-	atomic64_inc(&priv->num_replenishes);
+	atomic_inc(&priv->num_replenishes);
 
 	limit = atomic64_read(&priv->frin_to_be_sent);
 
@@ -375,9 +565,9 @@ static int mac_refill_frin_desc(unsigned long dev)
 		}
 		msgrng_access_disable(mflags);
 
-		atomic64_dec(&priv->frin_to_be_sent);
+		atomic_dec(&priv->frin_to_be_sent);
 
-		atomic64_inc(&priv->total_frin_sent);
+		atomic_inc(&priv->total_frin_sent);
 	}
 
 	return ret;
@@ -387,13 +577,33 @@ static int mac_refill_frin_desc(unsigned long dev)
  * nlm_xlp_nae_init - xlp_nae device driver init function
  * @dev - this is per device based function
  */
-
+extern cpumask_t phys_cpu_present_map;
 static void nlm_xlp_nae_init(void)
 {
 	struct net_device *dev = NULL;
 	struct dev_data *priv = NULL;
-	int i;
+	int i, node = 0, cpu, maxnae;
 	struct proc_dir_entry *entry;
+	nlm_nae_config_ptr nae_cfg;
+	uint32_t cpu_mask[NLM_MAX_NODES];
+	char buf[CPUMASK_BUF];
+	
+	for(i=0; i < NLM_MAX_NODES; i++)
+		cpu_mask[i] = 0;
+        
+	cpumask_scnprintf(buf, CPUMASK_BUF, &phys_cpu_present_map);
+        printk("phys_cpu_present_map %s\n",buf);
+
+	for (cpu = 0, node = 0; cpu < NR_CPUS ; cpu++) {
+                if(!cpu_isset(cpu, phys_cpu_present_map))
+                        continue;
+		node = cpu / 32;
+		cpu_mask[node] |= (1 << (cpu % 32));
+	}
+
+	printk("======= Module Parameters =========\n");
+	printk("debug = %d, frin_desc_thres=%d drop_uboot_pkt=%d\n",
+	       debug, frin_desc_thres, drop_uboot_pkt);
 
 	pr_info("======= Module Parameters =========\n");
 	pr_info("debug = %d, frin_desc_thres = %d naecfg_hack = %d drop_uboot_pkt = %d\n",
@@ -402,12 +612,20 @@ static void nlm_xlp_nae_init(void)
 	if (initialize_nae(cpumask_to_uint32(&cpu_online_map), 0, 0, 0))
 		return;
 
-	nae_fb_vc = nae_cfg.fb_vc;
-	nae_rx_vc = nae_cfg.rx_vc;
-
-	for (i = 0; i < nae_cfg.num_ports; i++) {
+	maxnae = nlm_node_cfg.num_nodes;	
+	for(node = 0; node < maxnae; node++) {
+		nae_cfg = nlm_node_cfg.nae_cfg[node];
+		if (nae_cfg != NULL)
+			break;
+	}
+	if (nae_cfg == NULL)
+	{
+	printk(KERN_ERR "\nnc is NULL\n");
+	BUG();
+	}
+	for (i = 0; i < nae_cfg->num_ports; i++) {
 		/* Register only valid ports which are management */
-		if (!nae_cfg.ports[i].valid)
+		if (!nae_cfg->ports[i].valid)
 			continue;
 
 		dev = alloc_etherdev(sizeof(struct dev_data));
@@ -431,17 +649,17 @@ static void nlm_xlp_nae_init(void)
 		dev->dev_addr = eth_hw_addr[i];
 		priv->port = i;
 
-		atomic64_set(&priv->frin_to_be_sent, nae_cfg.ports[i].num_free_desc);
+		atomic64_set(&priv->frin_to_be_sent, nae_cfg->ports[i].num_free_desc);
 		atomic64_set(&priv->num_replenishes, 0);
 		atomic64_set(&priv->total_frin_sent, 0);
 
 		priv->inited = 0;
-		priv->block = nae_cfg.ports[i].hw_port_id / 4;
-		priv->type = nae_cfg.ports[i].iftype;
-		switch (nae_cfg.ports[i].iftype) {
+		priv->block = nae_cfg->ports[i].hw_port_id / 4;
+		priv->type = nae_cfg->ports[i].iftype;
+		switch (nae_cfg->ports[i].iftype) {
 		case SGMII_IF:
-			priv->index = nae_cfg.ports[i].hw_port_id & 0x3;
-			priv->phy.addr = nae_cfg.ports[i].hw_port_id;
+			priv->index = nae_cfg->ports[i].hw_port_id & 0x3;
+			priv->phy.addr = nae_cfg->ports[i].hw_port_id;
 			break;
 		case XAUI_IF:
 			priv->index = XGMAC;
@@ -454,11 +672,11 @@ static void nlm_xlp_nae_init(void)
 			break;
 		}
 		if (debug)
-			nlm_print("port%d hw %d block %d index %d type %d \n", i, nae_cfg.ports[i].hw_port_id,
+			nlm_print("port%d hw %d block %d index %d type %d \n", i, nae_cfg->ports[i].hw_port_id,
 				priv->block, priv->index, priv->type);
 
-		priv->nae_tx_qid = nae_cfg.ports[i].txq_range[0];
-		priv->nae_rx_qid = nae_cfg.ports[i].rxq;
+		priv->nae_tx_qid = nae_cfg->ports[i].txq;
+		priv->nae_rx_qid = nae_cfg->ports[i].rxq;
 
 		register_netdev(dev);
 
@@ -655,16 +873,16 @@ static void xlp_mac_setup_hwaddr(struct dev_data *priv)
 {
 	struct net_device *dev = priv->dev;
 
-	nlm_hal_write_mac_reg(priv->block, priv->index, MAC_ADDR0_LO, (dev->dev_addr[5] << 24) |
+	nlm_hal_write_mac_reg(0, priv->block, priv->index, MAC_ADDR0_LO, (dev->dev_addr[5] << 24) |
 				(dev->dev_addr[4] << 16) | (dev->dev_addr[3] << 8) | (dev->dev_addr[2]));
 
-	nlm_hal_write_mac_reg(priv->block, priv->index, MAC_ADDR0_HI, (dev->dev_addr[1] << 24) |
+	nlm_hal_write_mac_reg(0, priv->block, priv->index, MAC_ADDR0_HI, (dev->dev_addr[1] << 24) |
 				(dev->dev_addr[0] << 16));
 
-	nlm_hal_write_mac_reg(priv->block, priv->index, MAC_ADDR0_MASK_LO, 0xFFFFFFFF);
-	nlm_hal_write_mac_reg(priv->block, priv->index, MAC_ADDR0_MASK_HI, 0xFFFFFFFF);
+	nlm_hal_write_mac_reg(0, priv->block, priv->index, MAC_ADDR0_MASK_LO, 0xFFFFFFFF);
+	nlm_hal_write_mac_reg(0, priv->block, priv->index, MAC_ADDR0_MASK_HI, 0xFFFFFFFF);
 
-	nlm_hal_write_mac_reg(priv->block, priv->index, MAC_FILTER_CONFIG, (1 << MAC_FILTER_BCAST_EN_POS) |
+	nlm_hal_write_mac_reg(0, priv->block, priv->index, MAC_FILTER_CONFIG, (1 << MAC_FILTER_BCAST_EN_POS) |
 				(1 << MAC_FILTER_MCAST_EN_POS) | (1 << MAC_FILTER_ADDR0_VALID_POS));
 }
 
@@ -753,6 +971,34 @@ static void  nlm_xlp_nae_tx_timeout (struct net_device *dev)
 	return;
 }
 
+static int nlm_xlp_nae_set_hwaddr(struct net_device *dev, void *p)
+{
+	struct sockaddr *addr = (struct sockaddr *)p;
+	struct dev_data *priv = netdev_priv(dev);
+	int rc = 0;
+
+	rc = eth_mac_addr(dev, p);
+
+	if (rc)
+		return rc;
+
+	if (priv->type == SGMII_IF)
+	{
+	  nlm_hal_write_mac_reg(priv->node,priv->block, priv->index, MAC_ADDR0_LO, 
+				(addr->sa_data[5] << 24) | 
+				(addr->sa_data[4] << 16) | 
+				(addr->sa_data[3] << 8) | 
+				(addr->sa_data[2]));
+
+	  nlm_hal_write_mac_reg(priv->node,priv->block, priv->index, MAC_ADDR0_HI, 
+				(addr->sa_data[1] << 24) | 
+				(addr->sa_data[0] << 16));
+	}
+
+	return rc;
+}
+
+
 #ifdef ENABLE_NAE_PIC_INT
 /*
  * nlm_xlp_nae_int_handler - interrupt handler
@@ -798,7 +1044,7 @@ static void nlm_xlp_nae_msgring_handler(uint32_t vc, uint32_t src_id,
 	unsigned int len, port = 0, context;
 	uint64_t addr, vaddr;
 	struct sk_buff *skb;
-	int cpu = 0;
+	int cpu = 0, node = 0;
 
 	cpu = hard_smp_processor_id();
 	vc &= 0x03;
@@ -873,7 +1119,8 @@ static void nlm_xlp_nae_msgring_handler(uint32_t vc, uint32_t src_id,
 			}
 		}
 
-		port = cntx2port[context];
+		node = (src_id >> 10) & 0x3;
+		port = *(cntx2port[node] + context);
 #ifdef DEBUG_CONTEXT_PORT_MAPPING
 		if (port == 0)
 			pr_info("Rx context %d port %d \n", context, port);
@@ -948,7 +1195,7 @@ static void nlm_xlp_nae_msgring_handler(uint32_t vc, uint32_t src_id,
 		priv->cpu_stats[cpu].rx_packets++;
 
 out:
-		if (atomic64_inc_return(&priv->frin_to_be_sent) > frin_desc_thres) {
+		if (atomic_inc_return(&priv->frin_to_be_sent) > frin_desc_thres) {
 			tasklet_schedule(&mac_refill_task[port]);
 			/* mac_refill_frin_desc((unsigned long) skb->dev); */
 		}
@@ -1051,14 +1298,14 @@ static void nlm_xlp_mac_timer(unsigned long data)
 
 		/* Send IRQ_MSGRING vector in an IPI to all cpus but the current one */
 		if (cpumask_lo)
-			nlm_hal_write_pic_reg(mmio, PIC_IPI_CTL, (IRQ_MSGRING << 20) | cpumask_lo);
+			nlm_hal_write_pic_reg(mmio, PIC_IPI_CTL, (XLP_IRQ_MSGRING << 20) | cpumask_lo);
 
 		if (cpumask_hi)
-			nlm_hal_write_pic_reg(mmio, PIC_IPI_CTL, (IRQ_MSGRING << 20) | (1 << 16)
+			nlm_hal_write_pic_reg(mmio, PIC_IPI_CTL, (XLP_IRQ_MSGRING << 20) | (1 << 16)
 					      | (cpumask_hi));
 
 		/* Run IPI handler on this cpu too */
-		nlm_xlp_msgring_int_handler(IRQ_MSGRING, NULL);
+		nlm_xlp_msgring_int_handler(XLP_IRQ_MSGRING, NULL);
 	}
 
 	priv->link_timer.expires = jiffies + next_tick;
@@ -1100,19 +1347,14 @@ static void nlm_xlp_nae_remove(struct pci_dev *pdev)
 }
 
 static struct pci_driver soc_driver = {
-	.name = XLP_SOC_MAC_DRIVER,
-	.id_table = soc_pci_table,
-	.probe = nlm_xlp_nae_pci_probe,
-	.remove = nlm_xlp_nae_remove,
+	.name             = XLP_SOC_MAC_DRIVER,
+	.id_table         = soc_pci_table,
+	.probe            = nlm_xlp_nae_pci_probe,
+	.remove		  = nlm_xlp_nae_remove,
 };
 
 static int __init nlm_xlp_mac_init(void)
 {
-	if (is_kexec_boot()) {
-		pr_err("%s: NAE driver doesn't work when booting from kexec\n", __func__);
-		return -ENODEV;
-	}
-
 	nlm_xlp_nae_init();
 
 	return pci_register_driver(&soc_driver);
diff --git a/drivers/net/nae/xlp_nae.h b/drivers/net/nae/xlp_nae.h
index c62e197..e191842 100644
--- a/drivers/net/nae/xlp_nae.h
+++ b/drivers/net/nae/xlp_nae.h
@@ -1,94 +1,83 @@
 #ifndef _XLP_NAE_H
 #define _XLP_NAE_H
 
-#define MAC_MAX_FRAME_SIZE	1600
-#define MAC_SKB_BACK_PTR_SIZE	SMP_CACHE_BYTES
+#define MAC_MAX_FRAME_SIZE      9214
+#define MAC_SKB_BACK_PTR_SIZE   SMP_CACHE_BYTES
+
 
 #define MAC_PREPAD		0
-#define BYTE_OFFSET		2
+#define BYTE_OFFSET             2
 #define NLM_RX_BUF_SIZE (MAC_MAX_FRAME_SIZE+BYTE_OFFSET+MAC_PREPAD+MAC_SKB_BACK_PTR_SIZE+SMP_CACHE_BYTES)
-#define MAC_CRC_LEN		4
-#define CACHELINE_SIZE		(1ULL << 6)
-#define CACHELINE_ALIGNED(addr) (((addr) + (CACHELINE_SIZE-1)) & ~(CACHELINE_SIZE-1))
+#define MAC_CRC_LEN             4
+#define CACHELINE_SIZE          (1ULL << 6)
+#define CACHELINE_ALIGNED(addr) ( ((addr) + (CACHELINE_SIZE-1)) & ~(CACHELINE_SIZE-1) )
 #define PHYS_TO_VIRT(paddr) (uint64_t)((paddr) - (netlib_paddrb) + (netlib_vaddrb))
 #define VIRT_TO_PHYS(vaddr) (uint64_t)((vaddr) - (netlib_vaddrb) + (netlib_paddrb))
-extern unsigned long long netlib_vaddrb;
+extern  unsigned long long netlib_vaddrb;
 extern unsigned long long netlib_paddrb;
 #define PADDR_BASE 0x100000ULL
 #define PADDR_SIZE 0x200000
-#define INIT_VBASE(vbase, pbase) { etlib_vaddrb = vbase; netlib_paddrb = pbase; }
+#define INIT_VBASE( vbase, pbase) {netlib_vaddrb = vbase ; netlib_paddrb = pbase;}
 
 struct cpu_stat {
-	unsigned long tx_packets;
-	unsigned long txc_packets;
-	unsigned long rx_packets;
-	unsigned long interrupts;
+        unsigned long tx_packets;
+        unsigned long txc_packets;
+        unsigned long rx_packets;
+        unsigned long interrupts;
 };
 
 
-typedef enum xlp_net_types {
-	TYPE_XLP_GMAC = 0,
-	TYPE_XLP_XGMAC,
-	TYPE_XLP_XAUI,
-	TYPE_XLP_INTERLAKEN,
-	MAX_XLP_NET_TYPES
-} xlp_interface_t;
+typedef enum xlp_net_types { TYPE_XLP_GMAC = 0, TYPE_XLP_XGMAC, TYPE_XLP_XAUI, TYPE_XLP_INTERLAKEN, MAX_XLP_NET_TYPES }xlp_interface_t;
 
-typedef enum {
-	xlp_mac_speed_10,
-	xlp_mac_speed_100,
-	xlp_mac_speed_1000,
-	xlp_mac_speed_rsvd
+typedef enum { xlp_mac_speed_10, xlp_mac_speed_100,
+               xlp_mac_speed_1000, xlp_mac_speed_rsvd
 } xlp_mac_speed_t;
 
-typedef enum {
-	xlp_mac_duplex_auto,
-	xlp_mac_duplex_half,
-	xlp_mac_duplex_full
+typedef enum { xlp_mac_duplex_auto, xlp_mac_duplex_half,
+               xlp_mac_duplex_full
 } xlp_mac_duplex_t;
 
-typedef enum {
-	xlp_mac_fc_auto,
-	xlp_mac_fc_disabled,
-	xlp_mac_fc_frame,
-	xlp_mac_fc_collision,
-	xlp_mac_fc_carrier
+typedef enum { xlp_mac_fc_auto, xlp_mac_fc_disabled, xlp_mac_fc_frame,
+               xlp_mac_fc_collision, xlp_mac_fc_carrier
 } xlp_mac_fc_t;
 
 struct phy_info {
-	int addr;
-	int mode;
-	uint32_t *mii_addr;
-	uint32_t *pcs_addr;
-	uint32_t *serdes_addr;
+        int addr;
+        int mode;
+        uint32_t *mii_addr;
+        uint32_t *pcs_addr;
+        uint32_t *serdes_addr;
 };
 
-struct dev_data {
-	struct net_device *dev;
-	struct net_device_stats stats;
-	struct cpu_stat cpu_stats[NR_CPUS];
-	struct timer_list link_timer;
-	struct napi_struct napi;
-	spinlock_t lock;
-	unsigned short port;
+struct dev_data
+{
+        struct net_device *dev;
+        struct net_device_stats stats;
+        struct cpu_stat cpu_stats[NR_CPUS];
+        struct timer_list link_timer;
+        struct napi_struct napi;
+        spinlock_t lock;
+        unsigned short port;
 	unsigned short inited;
-	unsigned short block;
-	unsigned short index;
-	unsigned short type;
-	struct sk_buff *skb;
-	int phy_oldlinkstat;
-	atomic64_t frin_to_be_sent;
-	atomic64_t num_replenishes;
-	atomic64_t total_frin_sent;
-	__u8 hwaddr[6];
+	unsigned short node;
+        unsigned short block;
+        unsigned short index;
+        unsigned short type;
+        struct sk_buff* skb;
+        int phy_oldlinkstat;
+	uint32_t  frin_desc_thres;
+        atomic_t frin_to_be_sent;
+	atomic_t num_replenishes;
+	atomic_t total_frin_sent;
+        __u8 hwaddr[6];
 
-	xlp_mac_speed_t speed; /* current speed */
-	xlp_mac_duplex_t duplex; /* current duplex */
-	xlp_mac_fc_t flow_ctrl; /* current flow control setting */
-	int advertising;
-	struct phy_info phy;
-	uint32_t nae_rx_qid;
-	uint32_t nae_tx_qid;
+        xlp_mac_speed_t speed;  /* current speed */
+        xlp_mac_duplex_t duplex;        /* current duplex */
+        xlp_mac_fc_t flow_ctrl; /* current flow control setting */
+        int advertising;
+        struct phy_info phy;
+        int nae_rx_qid;
+        int nae_tx_qid;
 };
 
 #endif
diff --git a/drivers/usb/host/ehci-pci.c b/drivers/usb/host/ehci-pci.c
index 0b87394..c134b2c 100644
--- a/drivers/usb/host/ehci-pci.c
+++ b/drivers/usb/host/ehci-pci.c
@@ -26,10 +26,12 @@
 #ifdef CONFIG_NLM_XLP
 
 #include <asm/netlogic/hal/nlm_hal.h>
-#include <asm/netlogic/hal/nlm_hal_pic.h>
+#include <asm/netlogic/xlp_hal_pic.h>
 #include <asm/netlogic/xlp.h>
 #include <asm/netlogic/xlp_usb.h>
 
+extern int nlm_xlp_request_irq(int irq);
+
 volatile uint64_t *ehci_regs;
 
 static void xlp_usb_hw_start(int ctrl_no)
@@ -69,7 +71,7 @@ int xlp_ehci_hcd_pci_probe(struct pci_dev *dev, const struct pci_device_id *id)
 	ctrl_no = dev->devfn & 0xF;
 
 	irt = usb_reg_read(0, ctrl_no, 0x3D) & 0xFFFF;
-	irq = nlm_hal_request_shared_irq(irt);
+	irq = nlm_xlp_request_irq(irt);
 
 	if (!irq) {
 		pr_err("Found HC with no IRQ.  Check BIOS/PCI %s setup!\n",
diff --git a/drivers/usb/host/ohci-pci.c b/drivers/usb/host/ohci-pci.c
index b9473ab..f774256 100644
--- a/drivers/usb/host/ohci-pci.c
+++ b/drivers/usb/host/ohci-pci.c
@@ -44,10 +44,11 @@ static int amd_ohci_iso_count;
 #ifdef CONFIG_NLM_XLP
 
 #include <asm/netlogic/hal/nlm_hal.h>
-#include <asm/netlogic/hal/nlm_hal_pic.h>
 #include <asm/netlogic/xlp.h>
 #include <asm/netlogic/xlp_usb.h>
 
+extern int nlm_xlp_request_irq(int irq);
+
 static void xlp_usb_start_ohc(int ctrl_no)
 {
 	/* enable interrupts
@@ -82,7 +83,7 @@ int xlp_ohci_hcd_pci_probe(struct pci_dev *dev,
 	ctrl_no = dev->devfn & 0xF;
 
 	irt = usb_reg_read(0, ctrl_no, 0x3D) & 0xFFFF;
-	irq = nlm_hal_request_shared_irq(irt);
+	irq = nlm_xlp_request_irq(irt);
 
 	if (!irq) {
 		pr_err("Found HC with no IRQ.  Check BIOS/PCI %s setup!\n",
-- 
1.7.0

