From c55f22c63de9db39339b09ebedaa604dcc472cb4 Mon Sep 17 00:00:00 2001
From: Yanjiang Jin <yanjiang.jin@windriver.com>
Date: Thu, 22 Nov 2012 17:17:12 +0800
Subject: [PATCH] nlm_xlp_64_be_cgl: support for more than 16GB mem

Add support for more than 16GB memory.
In case of NUMA, for each node, the first few physical memory
page is used for numa bookkeeping. These memories must
be wired as in early booting, no TLB refill handling exists.

Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/Kconfig                                 |    6 +
 arch/mips/include/asm/dma.h                       |    4 +
 arch/mips/include/asm/mach-netlogic/mmu.h         |   28 +++++
 arch/mips/include/asm/mach-netlogic/mmzone.h      |    3 +
 arch/mips/include/asm/netlogic/nlm_pcix_gen_dev.h |  123 +++++++++++++++++++++
 arch/mips/include/asm/pgalloc.h                   |   18 +++
 arch/mips/include/asm/thread_info.h               |    8 ++
 arch/mips/kernel/setup.c                          |    2 +
 arch/mips/mm/fault.c                              |   52 +++++++++
 arch/mips/mm/init.c                               |   18 ++-
 arch/mips/netlogic/common/memory.c                |    5 +-
 arch/mips/netlogic/xlp/numa.c                     |   32 +++++-
 arch/mips/netlogic/xlp/setup.c                    |   79 +++++++-------
 fs/exec.c                                         |    5 +
 include/linux/gfp.h                               |    5 +
 kernel/fork.c                                     |   28 +++++
 mm/memory.c                                       |   44 ++++++++
 mm/mmap.c                                         |   21 ++++
 mm/page_alloc.c                                   |   20 ++++
 mm/percpu.c                                       |    5 +
 20 files changed, 455 insertions(+), 51 deletions(-)
 create mode 100644 arch/mips/include/asm/netlogic/nlm_pcix_gen_dev.h

diff --git a/arch/mips/Kconfig b/arch/mips/Kconfig
index bce3e1b..cd5025c 100644
--- a/arch/mips/Kconfig
+++ b/arch/mips/Kconfig
@@ -1610,6 +1610,12 @@ config 64BIT
 	help
 	  Select this option if you want to build a 64-bit kernel.
 
+config NLM_16G_MEM_SUPPORT
+	bool "more than 16GB memory support"
+	depends on 64BIT
+	help
+	  Support more than 16GB memory
+
 endchoice
 
 choice
diff --git a/arch/mips/include/asm/dma.h b/arch/mips/include/asm/dma.h
index 2ffad41..bc9f9ce 100644
--- a/arch/mips/include/asm/dma.h
+++ b/arch/mips/include/asm/dma.h
@@ -89,7 +89,11 @@
 #define MAX_DMA_ADDRESS		PAGE_OFFSET
 #else
 #if defined(CONFIG_NLM_COMMON) && defined(CONFIG_64BIT)
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+#define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0xc0000000)
+#else
 #define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0x80000000)
+#endif
 #else
 #define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0x01000000)
 #endif
diff --git a/arch/mips/include/asm/mach-netlogic/mmu.h b/arch/mips/include/asm/mach-netlogic/mmu.h
index c866b59..73a1398 100644
--- a/arch/mips/include/asm/mach-netlogic/mmu.h
+++ b/arch/mips/include/asm/mach-netlogic/mmu.h
@@ -17,9 +17,25 @@
 #define SMALLEST_TLBPAGE_SZ (4UL << 10)
 #define LARGEST_TLBPAGE_SZ  (256UL << 20)
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+#define MAX_WIRED_PFN PFN_UP(4UL << 30)
+#endif
+
 #define TRUE 1
 #define FALSE 0
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+extern unsigned long NONWIRED_START, NONWIRED_END;
+#endif
+
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+struct tlb_entry {
+	unsigned long entryHi;
+	unsigned long entrylo0;
+	unsigned long entrylo1;
+	int wired;
+};
+#else
 typedef struct
 {
 	unsigned long vaddr;
@@ -30,6 +46,7 @@ typedef struct
 	uint32_t attr1;
 	int wired;
 } tlb_info_t;
+#endif
 
 #ifdef CONFIG_MAPPED_KERNEL
 extern unsigned long __vmalloc_start;
@@ -37,7 +54,9 @@ extern unsigned long __vmalloc_start;
 extern unsigned long long nlm_common_tlb_stats[];
 
 extern void mmu_init(void);
+#ifndef CONFIG_NLM_16G_MEM_SUPPORT
 extern void setup_tlb(tlb_info_t *tlb);
+#endif
 
 /*
  * the following needs an used argument to confirm to the 
@@ -69,5 +88,14 @@ extern void __init nlm_numa_bootmem_init(unsigned long);
 #define enable_pgwalker(flags) (void) flags
 #endif
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+extern int map_kernel_addrspace(unsigned long vaddr, unsigned long paddr,
+				unsigned long max_pfn);
+extern void setup_mapped_kernel_pgtable(void);
+
+#define KERNEL_PAGE_ATTR \
+	(_CACHE_CACHABLE_COW | _PAGE_DIRTY |  _PAGE_VALID | _PAGE_GLOBAL)
+#endif
+
 #endif /* __ASSEMBLY__ */
 #endif
diff --git a/arch/mips/include/asm/mach-netlogic/mmzone.h b/arch/mips/include/asm/mach-netlogic/mmzone.h
index 33e1dbd..c4136c5 100644
--- a/arch/mips/include/asm/mach-netlogic/mmzone.h
+++ b/arch/mips/include/asm/mach-netlogic/mmzone.h
@@ -24,6 +24,9 @@ struct nlm_node_mem_frag {
 struct nlm_node_mem_info {
 	struct nlm_node_mem_frag mem[NLM_MAX_MEM_FRAGS_PER_NODE];
 	int frags;
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	int min_start_pfn;
+#endif
 };
 
 struct nlm_cpu_info {
diff --git a/arch/mips/include/asm/netlogic/nlm_pcix_gen_dev.h b/arch/mips/include/asm/netlogic/nlm_pcix_gen_dev.h
new file mode 100644
index 0000000..1e1b144
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/nlm_pcix_gen_dev.h
@@ -0,0 +1,123 @@
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_2# */
+
+
+#ifndef __NLM_PCIX_DEVICE_H__
+#define __NLM_PCIX_DEVICE_H__
+
+#include <asm/types.h>
+#include <linux/cache.h>
+
+#ifdef NETLOGIC_LITTLE_ENDIAN
+#define PCIX_REG_BASE 64
+#else
+#define PCIX_REG_BASE (512 + 64)
+#endif
+
+/*Define this macro if device supports MAILBOX interrupt.*/
+/*#define XLR_MAILBOX_IS_SUPPORTED 1 */
+
+/*Define this macro if host is MSI capable.*/
+/*#define XLR_MSI_IS_SUPPORTED 1 */
+
+#define XLR_PCI_HOST_MODE 0x1
+#define XLR_PCI_DEV_MODE 0x2
+#define PCIX_INTRPT_CONTROL_REG (PCIX_REG_BASE + 15)
+#define PCIX_NETLOGIC_CONTROL_REG (PCIX_REG_BASE + 14)
+#define PCIX_INTRPT_STATUS_REG (PCIX_REG_BASE + 16)
+#define PCIX_HOST_MODE_CTRL_STATUS_REG (PCIX_REG_BASE + 35)
+#define PCIX_DEVICE_MODE_ADDR_MAPPER (PCIX_REG_BASE + 36)
+#define PCIX_DEVMODE_TBL_BAR0_REG                   (PCIX_REG_BASE + 44)
+#define PCIX_DEVMODE_TBL_BAR1_REG                   (PCIX_REG_BASE + 45)
+#define PCIX_DEVMODE_TBL_BAR2_REG                   (PCIX_REG_BASE + 46)
+#define PCIX_DEVMODE_TBL_BAR3_REG                   (PCIX_REG_BASE + 47)
+
+#define NLM_MAX_IRQS_SUPPORTED 16
+
+#define nlm_common_host_to_pci(addr) ((uint64_t)(addr) | 0x8000000000UL)
+
+#define CACHELINE_ALIGNED_ADDR(addr) \
+			(((unsigned long)(addr)) & ~(SMP_CACHE_BYTES-1))
+
+
+int xlr_get_pci_mode(void);
+void nlm_common_interrupt_host(void);
+/* DEVICE SIDE */
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+typedef int (*mailbox_handler)(void *, struct pt_regs *);
+int nlm_common_request_mailbox_handler(mailbox_handler, void *, int *);
+int nlm_common_disable_mailbox_intr(int *);
+int nlm_common_enable_mailbox_intr(int *);
+int nlm_common_free_mailbox_handler(int *);
+#endif
+
+
+/*
+ *************SHARED    MEMORY*************
+*/
+/* DURING BOOT ONLY */
+
+#define NLM_BOOT_SHARED_MEM_BASE 0x1000
+#define NLM_BOOT_SHARED_MEM_SIZE (32 * 1024 * 1024)
+
+
+/* AFTER BOOTIN WHOLE SHARED MEMORY IS CLAIMED BY THE GENERIC PCI DRIVER */
+#define NLM_GENERIC_SHARED_MEM_BASE (20*1024*1024)
+#define NLM_GENERIC_SHARED_MEM_SIZE (10*1024*1024)
+
+#define NLM_PCIX_SHARED_MEM_START (0x8000000+NLM_GENERIC_SHARED_MEM_BASE)
+#define NLM_PCIX_SHARED_MEM_END (NLM_PCIX_SHARED_MEM_START +\
+				NLM_GENERIC_SHARED_MEM_SIZE)
+/* All The Shared Address must be unique for each driver.
+ * Confliction of Address Space can cause unpredictable result.
+ * Shared Space Must be in sync with that of host driver. */
+
+
+/* SHARED SPACE BETWEEN MAC DRIVERS */
+#define NLM_MAC_SHARED_MEM_BASE NLM_GENERIC_SHARED_MEM_BASE
+#define NLM_MAC_SHARED_MEM_SIZE (1 * 1024 * 1024)
+
+
+/* SHARED SPACE BETWEEN CONSOLE DRIVERS */
+#define NLM_CONSOLE_OVER_PCI_SHARED_MEM_BASE \
+	(NLM_MAC_SHARED_MEM_BASE + NLM_MAC_SHARED_MEM_SIZE)
+#define NLM_CONSOLE_OVER_PCI_SHARED_MEM_SIZE (9 * 1024)
+
+/* SHARED space for DMA */
+#define NLM_DMA_MEM_BASE \
+			(NLM_CONSOLE_OVER_PCI_SHARED_MEM_BASE + \
+			NLM_CONSOLE_OVER_PCI_SHARED_MEM_SIZE)
+#define NLM_DMA_MEM_SIZE 1024
+
+/* SHARED SPACE BETWEEN IP OVER PCI DRIVER... */
+#define NLM_IP_OVER_PCI_MEM_BASE \
+			(NLM_DMA_MEM_BASE + NLM_DMA_MEM_SIZE)
+#define NLM_IP_OVER_PCI_MEM_SIZE (8*512+8*512+1024)
+
+#endif
diff --git a/arch/mips/include/asm/pgalloc.h b/arch/mips/include/asm/pgalloc.h
index 3738f4b..1b476ab 100644
--- a/arch/mips/include/asm/pgalloc.h
+++ b/arch/mips/include/asm/pgalloc.h
@@ -48,7 +48,11 @@ static inline pgd_t *pgd_alloc(struct mm_struct *mm)
 {
 	pgd_t *ret, *init;
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	ret = (pgd_t *) __get_free_pages(GFP_DMA|GFP_KERNEL, PGD_ORDER);
+#else
 	ret = (pgd_t *) __get_free_pages(GFP_KERNEL, PGD_ORDER);
+#endif
 	if (ret) {
 		init = pgd_offset(&init_mm, 0UL);
 		pgd_init((unsigned long)ret);
@@ -69,7 +73,12 @@ static inline pte_t *pte_alloc_one_kernel(struct mm_struct *mm,
 {
 	pte_t *pte;
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	pte = (pte_t *) __get_free_pages(
+			GFP_DMA|GFP_KERNEL|__GFP_REPEAT|__GFP_ZERO, PTE_ORDER);
+#else
 	pte = (pte_t *) __get_free_pages(GFP_KERNEL|__GFP_REPEAT|__GFP_ZERO, PTE_ORDER);
+#endif
 
 	return pte;
 }
@@ -79,7 +88,11 @@ static inline struct page *pte_alloc_one(struct mm_struct *mm,
 {
 	struct page *pte;
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	pte = alloc_pages(GFP_DMA | GFP_KERNEL | __GFP_REPEAT, PTE_ORDER);
+#else
 	pte = alloc_pages(GFP_KERNEL | __GFP_REPEAT, PTE_ORDER);
+#endif
 	if (pte) {
 		clear_highpage(pte);
 		pgtable_page_ctor(pte);
@@ -110,7 +123,12 @@ static inline pmd_t *pmd_alloc_one(struct mm_struct *mm, unsigned long address)
 {
 	pmd_t *pmd;
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	pmd = (pmd_t *) __get_free_pages(
+			GFP_DMA|GFP_KERNEL|__GFP_REPEAT, PMD_ORDER);
+#else
 	pmd = (pmd_t *) __get_free_pages(GFP_KERNEL|__GFP_REPEAT, PMD_ORDER);
+#endif
 	if (pmd)
 		pmd_init((unsigned long)pmd, (unsigned long)invalid_pte_table);
 	return pmd;
diff --git a/arch/mips/include/asm/thread_info.h b/arch/mips/include/asm/thread_info.h
index 9f09f0a..f55bdeb 100644
--- a/arch/mips/include/asm/thread_info.h
+++ b/arch/mips/include/asm/thread_info.h
@@ -86,10 +86,18 @@ register struct thread_info *__current_thread_info __asm__("$28");
 #define __HAVE_ARCH_THREAD_INFO_ALLOCATOR
 
 #ifdef CONFIG_DEBUG_STACK_USAGE
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+#define alloc_thread_info(tsk) kzalloc(THREAD_SIZE, GFP_KERNEL|GFP_DMA)
+#else
 #define alloc_thread_info(tsk) kzalloc(THREAD_SIZE, GFP_KERNEL)
+#endif
+#else
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+#define alloc_thread_info(tsk) kmalloc(THREAD_SIZE, GFP_KERNEL|GFP_DMA)
 #else
 #define alloc_thread_info(tsk) kmalloc(THREAD_SIZE, GFP_KERNEL)
 #endif
+#endif
 
 #define free_thread_info(info) kfree(info)
 
diff --git a/arch/mips/kernel/setup.c b/arch/mips/kernel/setup.c
index 862cc6b..1f75132 100644
--- a/arch/mips/kernel/setup.c
+++ b/arch/mips/kernel/setup.c
@@ -567,11 +567,13 @@ static void __init arch_mem_init(char **cmdline_p)
 	}
 
 	bootmem_init();
+#ifndef CONFIG_NLM_16G_MEM_SUPPORT
 #if defined(CONFIG_NLM_XLP) && defined(CONFIG_MAPPED_KERNEL)
 #ifndef CONFIG_NUMA
 	setup_mapped_kernel_tlbs(FALSE, TRUE);
 #endif
 #endif
+#endif
 #ifdef CONFIG_KEXEC
 	pr_info("Kexeckernel info: start = %llu end = %llu\n",
 		kexeck_res.start, kexeck_res.end);
diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index d388c18..5a11bb6 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -28,6 +28,9 @@
 #include <asm/ptrace.h>
 #include <asm/highmem.h>		/* For VMALLOC_END */
 
+#include <asm/netlogic/sim.h>
+#include <asm/mach-netlogic/xlp-mmu.h>
+#include <asm/mach-netlogic/mmu.h>
 
 DEFINE_TRACE(page_fault_entry);
 DEFINE_TRACE(page_fault_exit);
@@ -55,6 +58,44 @@ void pax_report_insns(void *pc, void *sp)
  * and the problem, and then passes it off to one of the appropriate
  * routines.
  */
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+#define ENTER_CRITICAL(flags) local_irq_save(flags)
+#define EXIT_CRITICAL(flags) local_irq_restore(flags)
+
+static void update_kernel_tlb(unsigned long address)
+{
+	unsigned long flags;
+	pgd_t *pgdp;
+	pud_t *pudp;
+	pmd_t *pmdp;
+	pte_t *ptep;
+	int pid;
+	__maybe_unused unsigned long config6_flags;
+
+	ENTER_CRITICAL(flags);
+	disable_pgwalker(config6_flags);
+
+	pid = read_c0_entryhi() & ASID_MASK;
+	address &= (PAGE_MASK << 1);
+	write_c0_entryhi(address | pid);
+	pgdp = pgd_offset_k(address);
+	mtc0_tlbw_hazard();
+	pudp = pud_offset(pgdp, address);
+	pmdp = pmd_offset(pudp, address);
+	{
+		ptep = pte_offset_map(pmdp, address);
+
+		write_c0_entrylo0(pte_to_entrylo(pte_val(*ptep++)));
+		write_c0_entrylo1(pte_to_entrylo(pte_val(*ptep)));
+		mtc0_tlbw_hazard();
+		tlb_write_random();
+	}
+	tlbw_use_hazard();
+	enable_pgwalker(config6_flags);
+	EXIT_CRITICAL(flags);
+}
+#endif
+
 asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 			      unsigned long address)
 {
@@ -88,6 +129,11 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 # define VMALLOC_FAULT_TARGET vmalloc_fault
 #endif
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	if (unlikely(address >= NONWIRED_START && address < NONWIRED_END))
+		goto refill_kernel_tlb;
+#endif
+
 	if (unlikely(address >= VMALLOC_START && address <= VMALLOC_END))
 		goto VMALLOC_FAULT_TARGET;
 #ifdef MODULE_START
@@ -305,4 +351,10 @@ vmalloc_fault:
 		return;
 	}
 #endif
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+refill_kernel_tlb:
+	update_kernel_tlb(address);
+	current->thread.cp0_baduaddr = address;
+	return;
+#endif
 }
diff --git a/arch/mips/mm/init.c b/arch/mips/mm/init.c
index 2efcbd2..6f64ff9 100644
--- a/arch/mips/mm/init.c
+++ b/arch/mips/mm/init.c
@@ -90,7 +90,12 @@ unsigned long setup_zero_pages(void)
 	else
 		order = 0;
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	empty_zero_page = __get_free_pages(
+				GFP_DMA | GFP_KERNEL | __GFP_ZERO, order);
+#else
 	empty_zero_page = __get_free_pages(GFP_KERNEL | __GFP_ZERO, order);
+#endif
 	if (!empty_zero_page)
 		panic("Oh boy, that early out of memory?");
 
@@ -299,7 +304,7 @@ void __init fixrange_init(unsigned long start, unsigned long end,
 }
 
 #ifndef CONFIG_NEED_MULTIPLE_NODES
-int page_is_ram(unsigned long pagenr)
+static int __init page_is_ram(unsigned long pagenr)
 {
 	int i;
 
@@ -328,6 +333,11 @@ void __init paging_init(void)
 
 	pagetable_init();
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	setup_mapped_kernel_tlbs(FALSE, TRUE);
+	setup_mapped_kernel_pgtable();
+#endif
+
 #ifdef CONFIG_HIGHMEM
 	kmap_init();
 #endif
@@ -425,7 +435,7 @@ void __init mem_init(void)
 	       reservedpages << (PAGE_SHIFT-10),
 	       datasize >> 10,
 	       initsize >> 10,
-	       totalhigh_pages << (PAGE_SHIFT-10));
+	       (unsigned long) (totalhigh_pages << (PAGE_SHIFT-10)));
 }
 #endif /* !CONFIG_NEED_MULTIPLE_NODES */
 
@@ -463,9 +473,7 @@ void __init_refok free_initmem(void)
 			__pa_symbol(&__init_end));
 }
 
-#ifndef CONFIG_MIPS_PGD_C0_CONTEXT
 unsigned long pgd_current[NR_CPUS];
-#endif
 /*
  * On 64-bit we've got three-level pagetables with a slightly
  * different layout ...
@@ -478,7 +486,7 @@ unsigned long pgd_current[NR_CPUS];
  * will officially be retired.
  */
 pgd_t swapper_pg_dir[_PTRS_PER_PGD] __page_aligned(_PGD_ORDER);
-#ifndef __PAGETABLE_PMD_FOLDED
+#ifdef CONFIG_64BIT
 pmd_t invalid_pmd_table[PTRS_PER_PMD] __page_aligned(PMD_ORDER);
 #endif
 pte_t invalid_pte_table[PTRS_PER_PTE] __page_aligned(PTE_ORDER);
diff --git a/arch/mips/netlogic/common/memory.c b/arch/mips/netlogic/common/memory.c
index f0a145b..868e9be 100644
--- a/arch/mips/netlogic/common/memory.c
+++ b/arch/mips/netlogic/common/memory.c
@@ -32,6 +32,7 @@
 
 #ifdef CONFIG_NLM_16G_MEM_SUPPORT
 #include <linux/bootmem.h>
+#include <linux/gfp.h>
 #include <asm/pgtable.h>
 #endif
 
@@ -88,7 +89,7 @@ static uint32_t tlb_mask(uint32_t size)
  * External Function / APIs
  */
 
-static void setup_tlb(tlb_entry_t *tlb, unsigned long pagesize)
+static void setup_tlb(struct tlb_entry *tlb, unsigned long pagesize)
 {
 	write_c0_pagemask(tlb_mask(pagesize) << 13);
 	write_c0_entryhi(tlb->entryHi & ~0x1fff);
@@ -173,7 +174,7 @@ unsigned long NONWIRED_END = ~0x0;
 
 void setup_mapped_kernel_tlbs(int firstpage, int primary_cpu)
 {
-	tlb_entry_t tlb;
+	struct tlb_entry tlb;
 	unsigned long max_wired_size;
 	unsigned long pagesize;
 	unsigned long vaddr, paddr;
diff --git a/arch/mips/netlogic/xlp/numa.c b/arch/mips/netlogic/xlp/numa.c
index 63e15e0..b85b071 100644
--- a/arch/mips/netlogic/xlp/numa.c
+++ b/arch/mips/netlogic/xlp/numa.c
@@ -193,10 +193,30 @@ void __init nlm_numa_bootmem_init(unsigned long reserved_end)
 		node_mem_info[node].frags++;
 
 #ifdef CONFIG_NLM_16G_MEM_SUPPORT
-		if (seg == 0)
-			node_mem_info[node].min_start_pfn = start;
-		else if (start < node_mem_info[node].min_start_pfn)
-			node_mem_info[node].min_start_pfn = start;
+		if (node == 0) {
+			/* 40 bit physical address,
+			 * min_start_pfn is the minimum above dma region */
+			unsigned long max_dma_pfn =
+			(MAX_DMA_ADDRESS & 0xffffffffffULL) >> PAGE_SHIFT;
+			if (seg == 0) {
+				if (start >= max_dma_pfn)
+					node_mem_info[node].min_start_pfn
+						= start;
+			} else if (start > max_dma_pfn) {
+				if (node_mem_info[node].min_start_pfn == 0)
+					node_mem_info[node].min_start_pfn
+						= start;
+				else if (start <
+					node_mem_info[node].min_start_pfn)
+					node_mem_info[node].min_start_pfn
+						= start;
+			}
+		} else {
+			if (seg == 0)
+				node_mem_info[node].min_start_pfn = start;
+			else if (start < node_mem_info[node].min_start_pfn)
+				node_mem_info[node].min_start_pfn = start;
+		}
 #endif
 
 		if (end > max_low_pfn)
@@ -371,8 +391,8 @@ void __init mem_init(void)
 		/*
 		 * This will free up the bootmem, ie, slot 0 memory.
 		 */
-		totalram_pages += 
-			free_all_bootmem_node(NODE_DATA(node));
+		totalram_pages +=
+				free_all_bootmem_node(NODE_DATA(node));
 	}
 
 	totalram_pages -= setup_zero_pages();   /* This comes from node 0 */
diff --git a/arch/mips/netlogic/xlp/setup.c b/arch/mips/netlogic/xlp/setup.c
index 645c9b5..a9c541f 100644
--- a/arch/mips/netlogic/xlp/setup.c
+++ b/arch/mips/netlogic/xlp/setup.c
@@ -1,28 +1,31 @@
-/* **********************************************************************
- * Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
- * reserved.
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
  * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
  * 1. Redistributions of source code must retain the above copyright
- * notice, this list of conditions and the following disclaimer.
+ *    notice, this list of conditions and the following disclaimer.
  * 2. Redistributions in binary form must reproduce the above copyright
- * notice, this list of conditions and the following disclaimer in
- * the documentation and/or other materials provided with the
- * distribution.
- * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
- * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
- * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
- * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
- * THE POSSIBILITY OF SUCH DAMAGE.
- * ****************************#NETL_2#*******************************
- */
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_2# */
 
 /*
  * Setup code for Netlogic's XLP-based boards
@@ -51,6 +54,7 @@
 #include <asm/netlogic/debug.h>
 #include <asm/netlogic/xlp.h>
 #include <asm/netlogic/msgring.h>
+#include <asm/netlogic/nlm_pcix_gen_dev.h>
 #include <asm/netlogic/memory-exclusion.h>
 #include <linux/serial.h>
 #include <linux/serial_core.h>
@@ -380,7 +384,7 @@ void plat_time_init(void)
 #if !defined CONFIG_XLP_REPLACE_R4K_TIMER
 	extern void nlm_common_timer_setup(void);
 #endif
-	mips_hpt_frequency = (unsigned int) get_cpu_freq(XLP_CPU0);
+	mips_hpt_frequency = (unsigned int) nlm_hal_cpu_freq();
 	printk("mips_hpt_frequency = %u\n", mips_hpt_frequency);
 #if !defined CONFIG_XLP_REPLACE_R4K_TIMER
 	nlm_common_timer_setup();
@@ -442,7 +446,10 @@ static void nlm_early_serial_setup(int uart_id)
 	/* hardware int 4 - the serial int, is CPU int 6
 	 but poll for now */
 
-	s.uartclk = UART_CLK_133MHz;
+	if (nlm_hal_is_ref_clk_133MHz())
+		s.uartclk = UART_CLK_133MHz;
+	else
+		s.uartclk = UART_CLK_66MHz;
 
 	switch(uart_id){
 		default:
@@ -629,7 +636,6 @@ static void parse_ici_parameters(void)
 {
 	char domstr[32] = "";
 	void *node;
-	int temp;
 	int domain = 0;
 
 	sprintf(domstr, "/doms/dom@%d/ici-config", domain);
@@ -825,31 +831,32 @@ static int fdt_process(void)
 		 */
 		node = finddevice("/doms/dom@0/memory");
 		if (node) {
-			entries = (getprop(node, "reg", regs, MAX_PROP_LEN)) / sizeof(regs[0]);
+			entries = (getprop(node, "reg", regs, MAX_PROP_LEN))
+					/ sizeof(regs[0]);
 			if (!entries || (entries % (na+ns)))
-				printk("Invalid Memory Map Specified!\n");
+				pr_err("Invalid Memory Map Specified!\n");
 
-			for (i=0; i<entries; i+=na+ns) {
+			for (i = 0; i < entries; i += na+ns) {
 				int base = i;
 				uint64_t addr, size;
 
 				addr = fdt32_to_cpu(regs[base++]);
-				if (na == 2)
-				{
-					/* handle 2 address-cells (ie. 64-bits of address) */
+				if (na == 2) {
+					/* handle 2 address-cells
+					 * (ie. 64-bits of address) */
 					addr <<= 32;
 					addr |= fdt32_to_cpu(regs[base++]);
 				}
 
 				size = fdt32_to_cpu(regs[base++]);
-				if (ns == 2)
-				{
+				if (ns == 2) {
 					/* handle 2 size-cells (ie. 64-bits of size) */
 					size <<= 32;
 					size |= fdt32_to_cpu(regs[base++]);
 				}
 
-				sprintf(domstr, " mem=%lldm@%lldm ", (size >> 20), (addr >> 20));
+				sprintf(domstr, " mem=%lldm@%lldm ",
+					(size >> 20), (addr >> 20));
 				strcat(arcs_cmdline, domstr);
 				memset((void *)&domstr, '\0', sizeof(domstr));
 			}
@@ -1167,8 +1174,6 @@ int nlm_config_ici(void)
 	}
 }
 
-#endif
-
 #ifdef CONFIG_KEXEC
 extern void nlm_kexec_init(void);
 #endif
@@ -1196,10 +1201,6 @@ void __init prom_init(void)
 
 	xen_init();
 
-#ifndef CONFIG_MAPPED_KERNEL
-	write_c0_ebase(read_c0_ebase() | 0x10000);
-#endif
-
 	nlm_common_ebase = read_c0_ebase() & (~((1 << 12) - 1));
 
 	/* FIXME: we should also remove it for xlp8xx a2, but we do not have interface function
@@ -1242,6 +1243,8 @@ void __init prom_init(void)
 			wakeup(prom_pre_boot_secondary_cpus);
 	}
 
+#endif
+
 #ifdef CONFIG_KEXEC
 	nlm_kexec_init();
 #endif
diff --git a/fs/exec.c b/fs/exec.c
index f042d34..cb78771 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -257,7 +257,12 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	struct vm_area_struct *vma = NULL;
 	struct mm_struct *mm = bprm->mm;
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	bprm->vma = vma = kmem_cache_zalloc(
+				vm_area_cachep, GFP_KERNEL | GFP_DMA);
+#else
 	bprm->vma = vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+#endif
 	if (!vma)
 		return -ENOMEM;
 
diff --git a/include/linux/gfp.h b/include/linux/gfp.h
index 4c6d413..8a9ab25 100644
--- a/include/linux/gfp.h
+++ b/include/linux/gfp.h
@@ -313,7 +313,12 @@ extern struct page *alloc_page_vma(gfp_t gfp_mask,
 #endif
 #define alloc_page(gfp_mask) alloc_pages(gfp_mask, 0)
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+extern unsigned long (*__get_free_pages)(gfp_t gfp_mask, unsigned int order);
+extern unsigned long ____get_free_pages(gfp_t gfp_mask, unsigned int order);
+#else
 extern unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order);
+#endif
 extern unsigned long get_zeroed_page(gfp_t gfp_mask);
 
 void *alloc_pages_exact(size_t size, gfp_t gfp_mask);
diff --git a/kernel/fork.c b/kernel/fork.c
index 9124feb..b1a9c4b 100644
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -108,7 +108,12 @@ int nr_processes(void)
 }
 
 #ifndef __HAVE_ARCH_TASK_STRUCT_ALLOCATOR
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+# define alloc_task_struct()	kmem_cache_alloc( \
+				task_struct_cachep, GFP_KERNEL | GFP_DMA)
+#else
 # define alloc_task_struct()	kmem_cache_alloc(task_struct_cachep, GFP_KERNEL)
+#endif
 # define free_task_struct(tsk)	kmem_cache_free(task_struct_cachep, (tsk))
 static struct kmem_cache *task_struct_cachep;
 #endif
@@ -194,10 +199,17 @@ void __init fork_init(unsigned long mempages)
 #define ARCH_MIN_TASKALIGN	L1_CACHE_BYTES
 #endif
 	/* create a slab on which task_structs can be allocated */
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	task_struct_cachep =
+		kmem_cache_create("task_struct", sizeof(struct task_struct),
+			ARCH_MIN_TASKALIGN,
+			SLAB_PANIC | SLAB_NOTRACK | SLAB_CACHE_DMA, NULL);
+#else
 	task_struct_cachep =
 		kmem_cache_create("task_struct", sizeof(struct task_struct),
 			ARCH_MIN_TASKALIGN, SLAB_PANIC | SLAB_NOTRACK, NULL);
 #endif
+#endif
 
 	/* do the arch specific task caches init */
 	arch_task_cache_init();
@@ -334,7 +346,11 @@ static int dup_mmap(struct mm_struct *mm, struct mm_struct *oldmm)
 				goto fail_nomem;
 			charge = len;
 		}
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+		tmp = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL | GFP_DMA);
+#else
 		tmp = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);
+#endif
 		if (!tmp)
 			goto fail_nomem;
 		*tmp = *mpnt;
@@ -461,7 +477,11 @@ static inline void mm_free_pgd(struct mm_struct * mm)
 
 __cacheline_aligned_in_smp DEFINE_SPINLOCK(mmlist_lock);
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+#define allocate_mm()	(kmem_cache_alloc(mm_cachep, GFP_KERNEL | GFP_DMA))
+#else
 #define allocate_mm()	(kmem_cache_alloc(mm_cachep, GFP_KERNEL))
+#endif
 #define free_mm(mm)	(kmem_cache_free(mm_cachep, (mm)))
 
 static unsigned long default_dump_filter = MMF_DUMP_FILTER_DEFAULT;
@@ -1569,10 +1589,18 @@ void __init proc_caches_init(void)
 	fs_cachep = kmem_cache_create("fs_cache",
 			sizeof(struct fs_struct), 0,
 			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK, NULL);
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	mm_cachep = kmem_cache_create("mm_struct",
+		sizeof(struct mm_struct), ARCH_MIN_MMSTRUCT_ALIGN,
+		SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK|SLAB_CACHE_DMA,
+		NULL);
+	vm_area_cachep = KMEM_CACHE(vm_area_struct, SLAB_PANIC|SLAB_CACHE_DMA);
+#else
 	mm_cachep = kmem_cache_create("mm_struct",
 			sizeof(struct mm_struct), ARCH_MIN_MMSTRUCT_ALIGN,
 			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK, NULL);
 	vm_area_cachep = KMEM_CACHE(vm_area_struct, SLAB_PANIC);
+#endif
 	mmap_init();
 }
 
diff --git a/mm/memory.c b/mm/memory.c
index 75d7017..c229fe1 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -1859,9 +1859,19 @@ static int remap_pte_range(struct mm_struct *mm, pmd_t *pmd,
 			unsigned long pfn, pgprot_t prot)
 {
 	pte_t *pte;
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	spinlock_t *uninitialized_var(ptl);
+#else
 	spinlock_t *ptl;
+#endif
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	pte = (mm == &init_mm) ?
+		pte_alloc_kernel(pmd, addr) :
+		pte_alloc_map_lock(mm, pmd, addr, &ptl);
+#else
 	pte = pte_alloc_map_lock(mm, pmd, addr, &ptl);
+#endif
 	if (!pte)
 		return -ENOMEM;
 	arch_enter_lazy_mmu_mode();
@@ -1871,7 +1881,12 @@ static int remap_pte_range(struct mm_struct *mm, pmd_t *pmd,
 		pfn++;
 	} while (pte++, addr += PAGE_SIZE, addr != end);
 	arch_leave_lazy_mmu_mode();
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	if (mm != &init_mm)
+		pte_unmap_unlock(pte - 1, ptl);
+#else
 	pte_unmap_unlock(pte - 1, ptl);
+#endif
 	return 0;
 }
 
@@ -3977,3 +3992,32 @@ void might_fault(void)
 }
 EXPORT_SYMBOL(might_fault);
 #endif
+
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+#include <asm/mach-netlogic/mmu.h>
+
+int __init map_kernel_addrspace(unsigned long addr, unsigned long pfn,
+				unsigned long max_pfn)
+{
+	pgd_t *pgd;
+	unsigned long end;
+	unsigned long next;
+	pgprot_t prot;
+	int err;
+
+	end = addr + ((max_pfn - pfn) << PAGE_SHIFT);
+
+	prot = __pgprot(KERNEL_PAGE_ATTR);
+	pfn -= addr >> PAGE_SHIFT;
+	pgd = pgd_offset(&init_mm, addr);
+	do {
+		next = pgd_addr_end(addr, end);
+		err = remap_pud_range(&init_mm, pgd, addr, next,
+		pfn + (addr >> PAGE_SHIFT), prot);
+		if (err)
+			break;
+	} while (pgd++, addr = next, addr != end);
+
+	return err;
+}
+#endif
diff --git a/mm/mmap.c b/mm/mmap.c
index 25730af..717cf06 100644
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@ -1387,7 +1387,11 @@ unsigned long mmap_region(struct file *file, unsigned long addr,
 	 * specific mapper. the address has already been validated, but
 	 * not unmapped, but the maps are removed from the list.
 	 */
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL | GFP_DMA);
+#else
 	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+#endif
 	if (!vma) {
 		error = -ENOMEM;
 		goto unacct_error;
@@ -2219,7 +2223,11 @@ static int __split_vma(struct mm_struct * mm, struct vm_area_struct * vma,
 	vma_m = pax_find_mirror_vma(vma);
 #endif
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	new = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL | GFP_DMA);
+#else
 	new = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);
+#endif
 	if (!new)
 		goto out_err;
 
@@ -2579,7 +2587,11 @@ unsigned long do_brk(unsigned long addr, unsigned long len)
 	/*
 	 * create a vma struct for an anonymous mapping
 	 */
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL | GFP_DMA);
+#else
 	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+#endif
 	if (!vma) {
 		vm_unacct_memory(charged);
 		return -ENOMEM;
@@ -2753,7 +2765,12 @@ struct vm_area_struct *copy_vma(struct vm_area_struct **vmap,
 		    vma_start < new_vma->vm_end)
 			*vmap = new_vma;
 	} else {
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+		new_vma = kmem_cache_alloc(vm_area_cachep,
+				GFP_KERNEL | GFP_DMA);
+#else
 		new_vma = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);
+#endif
 		if (new_vma) {
 			*new_vma = *vma;
 			pol = mpol_dup(vma_policy(vma));
@@ -2886,7 +2903,11 @@ int install_special_mapping(struct mm_struct *mm,
 	int ret;
 	struct vm_area_struct *vma;
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL | GFP_DMA);
+#else
 	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+#endif
 	if (unlikely(vma == NULL))
 		return -ENOMEM;
 
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 4394123..bfb601d 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -2031,6 +2031,25 @@ EXPORT_SYMBOL(__alloc_pages_nodemask);
 /*
  * Common helper functions.
  */
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+unsigned long ____get_free_pages(gfp_t gfp_mask, unsigned int order)
+{
+	struct page *page;
+
+	/*
+	 * __get_free_pages() returns a 32-bit address, which cannot represent
+	 * a highmem page
+	 */
+	VM_BUG_ON((gfp_mask & __GFP_HIGHMEM) != 0);
+
+	page = alloc_pages(gfp_mask, order);
+	if (!page)
+		return 0;
+	return (unsigned long) page_address(page);
+}
+unsigned long (*__get_free_pages)(gfp_t gfp_mask, unsigned int order)
+	= ____get_free_pages;
+#else
 unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order)
 {
 	struct page *page;
@@ -2046,6 +2065,7 @@ unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order)
 		return 0;
 	return (unsigned long) page_address(page);
 }
+#endif
 EXPORT_SYMBOL(__get_free_pages);
 
 unsigned long get_zeroed_page(gfp_t gfp_mask)
diff --git a/mm/percpu.c b/mm/percpu.c
index 3a58647..9d037bc 100644
--- a/mm/percpu.c
+++ b/mm/percpu.c
@@ -720,7 +720,12 @@ static int pcpu_alloc_pages(struct pcpu_chunk *chunk,
 		for (i = page_start; i < page_end; i++) {
 			struct page **pagep = &pages[pcpu_page_idx(cpu, i)];
 
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+			*pagep = alloc_pages_node(cpu_to_node(cpu),
+					gfp | GFP_DMA, 0);
+#else
 			*pagep = alloc_pages_node(cpu_to_node(cpu), gfp, 0);
+#endif
 			if (!*pagep) {
 				pcpu_free_pages(chunk, pages, populated,
 						page_start, page_end);
-- 
1.7.0.2

