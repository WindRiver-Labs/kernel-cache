From 6e5da26ae7146a896c403e3a04c6d985fd62b790 Mon Sep 17 00:00:00 2001
From: Yanjiang Jin <yanjiang.jin@windriver.com>
Date: Thu, 22 Nov 2012 14:49:46 +0800
Subject: [PATCH 2/5] nlm_xlp_64_be: update HugeTlb

Update HugeTlb for 64K page_size.

Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/Kconfig                              |   38 +++-
 arch/mips/include/asm/hugetlb.h                |   51 +++---
 arch/mips/include/asm/mach-netlogic/pgwalker.h |    1 +
 arch/mips/include/asm/mipsregs.h               |   16 +-
 arch/mips/include/asm/page.h                   |   26 ++-
 arch/mips/mm/hugetlbpage.c                     |  105 ++++++++++-
 arch/mips/mm/tlb-r4k.c                         |   52 +++++-
 arch/mips/mm/tlbex-fault.S                     |   10 +
 arch/mips/mm/tlbex.c                           |  127 ++++++++------
 arch/mips/netlogic/xlp/mmu.c                   |  234 +++++++++++------------
 10 files changed, 420 insertions(+), 240 deletions(-)

diff --git a/arch/mips/Kconfig b/arch/mips/Kconfig
index 3b432c5..9116736 100644
--- a/arch/mips/Kconfig
+++ b/arch/mips/Kconfig
@@ -1662,27 +1662,43 @@ endchoice
 choice
 	prompt "Hugetlb Page Size"
 	depends on HUGETLB_PAGE
-	default HUGETLB_PAGE_SIZE_2MB
+	default HUGE_PAGE_SIZE_8M
 
-config HUGETLB_PAGE_SIZE_2MB
+config HUGE_PAGE_SIZE_128K
+	bool "128KB"
+	help
+	  Using 128KB as the hugetlb page size
+
+config HUGE_PAGE_SIZE_512K
+	bool "512KB"
+	help
+	  Using 512KB as the hugetlb page size
+
+config HUGE_PAGE_SIZE_2M
 	bool "2MB"
-	depends on !PAGE_SIZE_16KB || !PAGE_SIZE_64KB
+	help
+	  Using 2MB as the hugetlb page size
 
-config HUGETLB_PAGE_SIZE_8MB
+config HUGE_PAGE_SIZE_8M
 	bool "8MB"
-	depends on !PAGE_SIZE_16KB || !PAGE_SIZE_64KB
+	help
+	  Using 8MB as the hugetlb page size
 
-config HUGETLB_PAGE_SIZE_32MB
+config HUGE_PAGE_SIZE_32M
 	bool "32MB"
-	depends on !PAGE_SIZE_64KB
+	help
+	  Using 32MB as the hugetlb page size
 
-config HUGETLB_PAGE_SIZE_128MB
+config HUGE_PAGE_SIZE_128M
 	bool "128MB"
-	depends on !PAGE_SIZE_64KB
+	help
+	  Using 128MB as the hugetlb page size
 
-config HUGETLB_PAGE_SIZE_512MB
+config HUGE_PAGE_SIZE_512M
 	bool "512MB"
-    
+	help
+	  Using 512MB as the hugetlb page size
+
 endchoice
 
 config FORCE_MAX_ZONEORDER
diff --git a/arch/mips/include/asm/hugetlb.h b/arch/mips/include/asm/hugetlb.h
index c565b7c..85f0f99 100644
--- a/arch/mips/include/asm/hugetlb.h
+++ b/arch/mips/include/asm/hugetlb.h
@@ -1,3 +1,11 @@
+/*-
+ * Copyright 2009-2012 Broadcom Corporation
+ *
+ * This is a derived work from software originally provided by the entity or
+ * entities identified below. The licensing terms, warranty terms and other
+ * terms specified in the header of the original work apply to this derived work
+ *
+ * #BRCM_1# */
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -50,27 +58,24 @@ static inline void hugetlb_free_pgd_range(struct mmu_gather *tlb,
 	free_pgd_range(tlb, addr, end, floor, ceiling);
 }
 
-static inline void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,
-				   pte_t *ptep, pte_t pte)
-{
-	set_pte_at(mm, addr, ptep, pte);
-}
-
-static inline pte_t huge_ptep_get_and_clear(struct mm_struct *mm,
-					    unsigned long addr, pte_t *ptep)
-{
-	pte_t clear;
-	pte_t pte = *ptep;
+extern void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,
+				pte_t *ptep, pte_t pte);
 
-	pte_val(clear) = (unsigned long)invalid_pte_table;
-	set_pte_at(mm, addr, ptep, clear);
-	return pte;
-}
+extern pte_t huge_ptep_get_and_clear(struct mm_struct *mm,
+				unsigned long addr, pte_t *ptep);
 
 static inline void huge_ptep_clear_flush(struct vm_area_struct *vma,
 					 unsigned long addr, pte_t *ptep)
 {
-	flush_tlb_mm(vma->vm_mm);
+}
+
+static inline pte_t huge_ptep_get(pte_t *ptep)
+{
+	/* Get the pte value for the even entry */
+	unsigned long pte = pte_val(*ptep) & ~(HPAGE_SIZE >> 1);
+
+	/* for XLP hpw, clear bit 61 which is indicates hpw it is a hpage */
+	return __pte(pte & ~(1ULL << 61));
 }
 
 static inline int huge_pte_none(pte_t pte)
@@ -87,7 +92,7 @@ static inline pte_t huge_pte_wrprotect(pte_t pte)
 static inline void huge_ptep_set_wrprotect(struct mm_struct *mm,
 					   unsigned long addr, pte_t *ptep)
 {
-	ptep_set_wrprotect(mm, addr, ptep);
+	set_huge_pte_at(mm, addr, ptep, pte_wrprotect(huge_ptep_get(ptep)));
 }
 
 static inline int huge_ptep_set_access_flags(struct vm_area_struct *vma,
@@ -95,12 +100,12 @@ static inline int huge_ptep_set_access_flags(struct vm_area_struct *vma,
 					     pte_t *ptep, pte_t pte,
 					     int dirty)
 {
-	return ptep_set_access_flags(vma, addr, ptep, pte, dirty);
-}
-
-static inline pte_t huge_ptep_get(pte_t *ptep)
-{
-	return *ptep;
+	int changed = !pte_same(*ptep, pte);
+	if (changed) {
+		set_huge_pte_at(vma->vm_mm, addr, ptep, pte);
+		flush_tlb_page(vma, addr);
+	}
+	return changed;
 }
 
 static inline int arch_prepare_hugepage(struct page *page)
diff --git a/arch/mips/include/asm/mach-netlogic/pgwalker.h b/arch/mips/include/asm/mach-netlogic/pgwalker.h
index 29c5659..326a350 100644
--- a/arch/mips/include/asm/mach-netlogic/pgwalker.h
+++ b/arch/mips/include/asm/mach-netlogic/pgwalker.h
@@ -6,6 +6,7 @@
 #define PGW_REGS_BLOCK 4
 
 enum {
+	PGW_MMU_SETUP = 0x0,
 	PGW_MMU_INFO = 0x10,
 	PGW_PGD_BASES,
 	PGW_PGD_SHIFT,
diff --git a/arch/mips/include/asm/mipsregs.h b/arch/mips/include/asm/mipsregs.h
index ddfd3ce..e2c88b7 100644
--- a/arch/mips/include/asm/mipsregs.h
+++ b/arch/mips/include/asm/mipsregs.h
@@ -230,15 +230,19 @@
 /*
  * Default huge tlb size for a given kernel configuration
  */
-#if defined(CONFIG_HUGETLB_PAGE_SIZE_2MB)
+#ifdef CONFIG_HUGE_PAGE_SIZE_128K
+#define PM_HUGE_MASK	PM_64K
+#elif defined(CONFIG_HUGE_PAGE_SIZE_512K)
+#define PM_HUGE_MASK	PM_256K
+#elif defined(CONFIG_HUGE_PAGE_SIZE_2M)
 #define PM_HUGE_MASK	PM_1M
-#elif defined(CONFIG_HUGETLB_PAGE_SIZE_8MB)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_8M)
 #define PM_HUGE_MASK	PM_4M
-#elif defined(CONFIG_HUGETLB_PAGE_SIZE_32MB)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_32M)
 #define PM_HUGE_MASK	PM_16M
-#elif defined(CONFIG_HUGETLB_PAGE_SIZE_128MB)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_128M)
 #define PM_HUGE_MASK	PM_64M
-#elif defined(CONFIG_HUGETLB_PAGE_SIZE_512MB)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_512M)
 #define PM_HUGE_MASK	PM_256M
 #elif defined(CONFIG_HUGETLB_PAGE)
 #error Bad page size configuration for hugetlbfs!
@@ -1095,7 +1099,6 @@ do {									\
 #define read_octeon_c0_dcacheerr()	__read_64bit_c0_register($27, 1)
 #define write_octeon_c0_dcacheerr(val)	__write_64bit_c0_register($27, 1, val)
 
-#ifdef CONFIG_PGWALKER
 /*
  * xlp2xx pagewalker PW registers
  */
@@ -1110,7 +1113,6 @@ do {									\
 
 #define read_c0_pwctl()	__read_32bit_c0_register($6, 6)
 #define write_c0_pwctl(val)	__write_32bit_c0_register($6, 6, val)
-#endif
 
 /*
  * Macros to access the floating point coprocessor control registers
diff --git a/arch/mips/include/asm/page.h b/arch/mips/include/asm/page.h
index a83e34b..f5a8b25 100644
--- a/arch/mips/include/asm/page.h
+++ b/arch/mips/include/asm/page.h
@@ -36,16 +36,22 @@
 
 #ifdef CONFIG_HUGETLB_PAGE
 
-#if defined(CONFIG_HUGETLB_PAGE_SIZE_2MB)
-#define HPAGE_SHIFT     21
-#elif defined(CONFIG_HUGETLB_PAGE_SIZE_8MB)
-#define HPAGE_SHIFT     23
-#elif defined(CONFIG_HUGETLB_PAGE_SIZE_32MB)
-#define HPAGE_SHIFT     25
-#elif defined(CONFIG_HUGETLB_PAGE_SIZE_128MB)
-#define HPAGE_SHIFT     27
-#elif defined(CONFIG_HUGETLB_PAGE_SIZE_512MB)
-#define HPAGE_SHIFT     29
+#ifdef CONFIG_HUGE_PAGE_SIZE_128K
+#define HPAGE_SHIFT	(PL_64K + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_512K)
+#define HPAGE_SHIFT	(PL_256 + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_2M)
+#define HPAGE_SHIFT	(PL_1M + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_8M)
+#define HPAGE_SHIFT	(PL_4M + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_32M)
+#define HPAGE_SHIFT	(PL_16M + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_128M)
+#define HPAGE_SHIFT	(PL_64M + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_512M)
+#define HPAGE_SHIFT	(PL_256M + 1)
+#else
+#error no proper huge page size defined!
 #endif
 
 #define HPAGE_SIZE	(_AC(1,UL) << HPAGE_SHIFT)
diff --git a/arch/mips/mm/hugetlbpage.c b/arch/mips/mm/hugetlbpage.c
index a7fee0d..475dea6 100644
--- a/arch/mips/mm/hugetlbpage.c
+++ b/arch/mips/mm/hugetlbpage.c
@@ -1,3 +1,11 @@
+/*-
+ * Copyright 2009-2012 Broadcom Corporation
+ *
+ * This is a derived work from software originally provided by the entity or
+ * entities identified below. The licensing terms, warranty terms and other
+ * terms specified in the header of the original work apply to this derived work
+ *
+ * #BRCM_1# */
 /*
  * MIPS Huge TLB Page Support for Kernel.
  *
@@ -16,24 +24,54 @@
 #include <linux/mm.h>
 #include <linux/hugetlb.h>
 #include <linux/pagemap.h>
+#include <linux/slab.h>
 #include <linux/err.h>
 #include <linux/sysctl.h>
 #include <asm/mman.h>
 #include <asm/tlb.h>
 #include <asm/tlbflush.h>
 
-pte_t *huge_pte_alloc(struct mm_struct *mm, unsigned long addr,
-		      unsigned long sz)
+pte_t *huge_pte_alloc_single(struct mm_struct *mm, unsigned long addr)
 {
 	pgd_t *pgd;
 	pud_t *pud;
+	pmd_t *pmd = NULL;
 	pte_t *pte = NULL;
 
 	pgd = pgd_offset(mm, addr);
 	pud = pud_alloc(mm, pgd, addr);
-	if (pud)
-		pte = (pte_t *)pmd_alloc(mm, pud, addr);
+	if (pud) {
+		pmd = (pmd_t *)pmd_alloc(mm, pud, addr);
+		if (pmd)
+			pte = pte_alloc_map(mm, pmd, addr);
+	}
+
+	return pte;
+}
 
+/**
+ * Given any address, we need to allocate page table entries
+ * for all pte's covered by the same huge page. This is needed if
+ * any address referencing the huge page faults and the tlb refill handler
+ * can refill the tlb entry with correct value.
+ *
+ * Return any valid pte pointer is fine as later on we still have
+ * "addr" to identify the correct huge page.
+ */
+pte_t *huge_pte_alloc(struct mm_struct *mm, unsigned long addr,
+		      unsigned long sz)
+{
+	pte_t *pte = NULL;
+	unsigned long i = 0;
+	unsigned long htlb_entries = 1 << HUGETLB_PAGE_ORDER;
+
+	addr &= HPAGE_MASK;
+	for (i = 0; i < htlb_entries; i++) {
+		pte = huge_pte_alloc_single(mm, addr);
+		if (!pte)
+			return NULL;
+		addr += PAGE_SIZE;
+	}
 	return pte;
 }
 
@@ -41,15 +79,68 @@ pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)
 {
 	pgd_t *pgd;
 	pud_t *pud;
-	pmd_t *pmd = NULL;
+	pmd_t *pmd;
+	pte_t *pte = NULL;
 
 	pgd = pgd_offset(mm, addr);
 	if (pgd_present(*pgd)) {
 		pud = pud_offset(pgd, addr);
-		if (pud_present(*pud))
+		if (pud_present(*pud)) {
 			pmd = pmd_offset(pud, addr);
+			if (pmd_present(*pmd))
+				pte = pte_offset_map(pmd, addr);
+		}
+	}
+	return pte;
+}
+
+/**
+ * Fill the pte value to all pte's covered by the same huge page.
+ */
+void set_huge_pte_at(struct mm_struct *mm, unsigned long addr, pte_t *ptep,
+pte_t entry)
+{
+	unsigned long i;
+	unsigned long htlb_entries = 1 << HUGETLB_PAGE_ORDER;
+	pte_t entry2;
+
+	entry2 =  __pte(pte_val(entry) + (HPAGE_SIZE >> 1));
+
+	/* for hardware page walker, bit 61 tells hpw it is a hpage */
+	entry  = __pte(pte_val(entry)  | (1ULL << 61));
+	entry2 = __pte(pte_val(entry2) | (1ULL << 61));
+
+	addr &= HPAGE_MASK;
+	for (i = 0; i < htlb_entries; i += 2) {
+		ptep = huge_pte_offset(mm, addr);
+		set_pte_at(mm, addr, ptep, entry);
+		addr += PAGE_SIZE;
+
+		ptep = huge_pte_offset(mm, addr);
+		set_pte_at(mm, addr, ptep, entry2);
+		addr += PAGE_SIZE;
+	}
+}
+
+pte_t huge_ptep_get_and_clear(struct mm_struct *mm, unsigned long addr,
+				pte_t *ptep)
+{
+	pte_t entry;
+	unsigned long i;
+	unsigned long htlb_entries = 1 << HUGETLB_PAGE_ORDER;
+
+	entry = *ptep;
+
+	/* clear bit 61 before giving back to the upper level function */
+	entry = __pte(pte_val(entry) & ~(1ULL << 61));
+
+	addr &= HPAGE_MASK;
+	for (i = 0; i < htlb_entries; i++) {
+		ptep = huge_pte_offset(mm, addr);
+		pte_clear(mm, addr, ptep);
+		addr += PAGE_SIZE;
 	}
-	return (pte_t *) pmd;
+	return entry;
 }
 
 int huge_pmd_unshare(struct mm_struct *mm, unsigned long *addr, pte_t *ptep)
diff --git a/arch/mips/mm/tlb-r4k.c b/arch/mips/mm/tlb-r4k.c
index 7373d3e..4fbeaa5 100644
--- a/arch/mips/mm/tlb-r4k.c
+++ b/arch/mips/mm/tlb-r4k.c
@@ -26,6 +26,10 @@
 #include <asm/mach-netlogic/mmu.h>
 #endif
 
+#ifdef CONFIG_HUGETLB_PAGE
+/* To work around the RAM TLB issue */
+#define XLP_TLB_WORKAROUND
+#endif
 
 extern void build_tlb_refill_handler(void);
 
@@ -255,6 +259,32 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
 	}
 }
 
+#ifdef CONFIG_HUGETLB_PAGE
+asmlinkage void do_hugetlb_invalidate(void)
+{
+	int oldpid, idx;
+
+	oldpid = read_c0_entryhi();
+	tlb_probe();
+	tlb_probe_hazard();
+	idx = read_c0_index();
+	if (idx > 0) {
+		int ridx = idx & 0x1fff;
+
+		if (ridx > ((read_c0_config6() >> 6) & 0x3ff)) {
+			/* Make sure all entries differ. */
+			write_c0_entrylo0(0);
+			write_c0_entrylo1(0);
+			write_c0_entryhi(UNIQUE_ENTRYHI(idx & 0x1fff));
+			mtc0_tlbw_hazard();
+			tlb_write_indexed();
+			tlbw_use_hazard();
+			write_c0_entryhi(oldpid);
+		}
+	}
+}
+#endif
+
 /*
  * This one is only used for pages with the global bit set so we don't care
  * much about the ASID.
@@ -325,19 +355,27 @@ void __update_tlb(struct vm_area_struct * vma, unsigned long address, pte_t pte)
 	idx = read_c0_index();
 #ifdef CONFIG_HUGETLB_PAGE
 	/* this could be a huge page  */
-	if (pmd_huge(*pmdp)) {
-		unsigned long lo;
+	if (is_vm_hugetlb_page(vma)) {
 		write_c0_pagemask(PM_HUGE_MASK);
-		ptep = (pte_t *)pmdp;
-		lo = pte_to_entrylo(pte_val(*ptep));
-		write_c0_entrylo0(lo);
-		write_c0_entrylo1(lo + (HPAGE_SIZE >> 7));
+		ptep = pte_offset_map(pmdp, address);
+		write_c0_entrylo0(pte_to_entrylo(pte_val(*ptep++)));
+		write_c0_entrylo1(pte_to_entrylo(pte_val(*ptep)));
 
 		mtc0_tlbw_hazard();
 		if (idx < 0)
 			tlb_write_random();
-		else
+		else {
+#ifndef XLP_TLB_WORKAROUND
 			tlb_write_indexed();
+#else
+			int ridx = idx & 0x1fff;
+			if (ridx > ((read_c0_config6() >> 6) & 0x3ff)) {
+				tlb_write_random();
+			}
+			else
+				tlb_write_indexed();
+#endif
+		}
 		write_c0_pagemask(PM_DEFAULT_MASK);
 	} else
 #endif
diff --git a/arch/mips/mm/tlbex-fault.S b/arch/mips/mm/tlbex-fault.S
index e99eaa1..789e713 100644
--- a/arch/mips/mm/tlbex-fault.S
+++ b/arch/mips/mm/tlbex-fault.S
@@ -15,6 +15,13 @@
 	NESTED(tlb_do_page_fault_\write, PT_SIZE, sp)
 	SAVE_ALL
 	MFC0	a2, CP0_BADVADDR
+
+#ifdef CONFIG_HUGETLB_PAGE
+	/* invalidate the tlb entry in fixed tlb */
+	jal	do_hugetlb_invalidate
+	nop
+#endif
+
 	KMODE
 	move	a0, sp
 	REG_S	a2, PT_BVADDR(sp)
@@ -26,3 +33,6 @@
 
 	tlb_do_page_fault 0
 	tlb_do_page_fault 1
+#if defined(CONFIG_READ_INHIBIT) || defined(CONFIG_EXEC_INHIBIT)
+	tlb_do_page_fault 2
+#endif
diff --git a/arch/mips/mm/tlbex.c b/arch/mips/mm/tlbex.c
index 959fe63..0d7ee93 100644
--- a/arch/mips/mm/tlbex.c
+++ b/arch/mips/mm/tlbex.c
@@ -40,6 +40,22 @@
 extern void tlb_do_page_fault_0(void);
 extern void tlb_do_page_fault_1(void);
 
+#ifdef CONFIG_NLM_COMMON
+#include <asm/netlogic/mips-exts.h>
+#endif
+
+#ifdef CONFIG_HUGETLB_PAGE
+/**
+ * This is applied to XLP (xlp8xx/xlp3xx only) hugetlb support.
+ * Basically, if the RAM TLB is enabled, a tlbprobe may return a
+ * fake hit. The huge page should not be written into RAM TLB
+ * due to page size mismatch. The following checks are needed
+ * for hugetlb invalid(tlbl/tlbs/tlbm) exception:
+ *   . check tlbprobe result, if it is not in CAM TLB, change to
+ *     write random
+ */
+#define XLP_TLB_WORKAROUND
+#endif
 
 static inline int r45k_bvahwbug(void)
 {
@@ -103,6 +119,9 @@ enum label_id {
 	label_illegal_access_tlbl,
 	label_exl_refill_exception,
 	label_r4000_write_probe_fail,
+#ifdef CONFIG_HUGETLB_PAGE
+	label_r4000_write_huge_probe_fail,
+#endif
 };
 
 UASM_L_LA(_second_part)
@@ -128,6 +147,9 @@ UASM_L_LA(_read_entrylo1)
 UASM_L_LA(_illegal_access_tlbl)
 UASM_L_LA(_exl_refill_exception)
 UASM_L_LA(_r4000_write_probe_fail)
+#ifdef CONFIG_HUGETLB_PAGE
+UASM_L_LA(_r4000_write_huge_probe_fail)
+#endif
 
 /*
  * For debug purposes.
@@ -161,6 +183,8 @@ static inline void dump_handler(const u32 *handler, int count)
 #define C0_ENTRYHI	10, 0
 #define C0_EPC		14, 0
 #define C0_XCONTEXT	20, 0
+#define C0_CONFIG6     16, 6
+#define C0_WIRED	6, 0
 
 #ifdef CONFIG_64BIT
 # define GET_CONTEXT(buf, reg) UASM_i_MFC0(buf, reg, C0_XCONTEXT)
@@ -511,32 +535,14 @@ static __cpuinit void build_huge_update_entries(u32 **p,
 						unsigned int pte,
 						unsigned int tmp)
 {
-	int small_sequence;
-
-	/*
-	 * A huge PTE describes an area the size of the
-	 * configured huge page size. This is twice the
-	 * of the large TLB entry size we intend to use.
-	 * A TLB entry half the size of the configured
-	 * huge page size is configured into entrylo0
-	 * and entrylo1 to cover the contiguous huge PTE
-	 * address space.
-	 */
-	small_sequence = (HPAGE_SIZE >> 7) < 0x10000;
-
-	/* We can clobber tmp.  It isn't used after this.*/
-	if (!small_sequence)
-		uasm_i_lui(p, tmp, HPAGE_SIZE >> (7 + 16));
-
 	build_convert_pte_to_entrylo(p, pte);
 	UASM_i_MTC0(p, pte, C0_ENTRYLO0); /* load it */
-	/* convert to entrylo1 */
-	if (small_sequence)
-		UASM_i_ADDIU(p, pte, pte, HPAGE_SIZE >> 7);
-	else
-		UASM_i_ADDU(p, pte, pte, tmp);
 
+	uasm_i_ld(p, pte, sizeof(pte_t), tmp);
+	build_convert_pte_to_entrylo(p, pte);
 	UASM_i_MTC0(p, pte, C0_ENTRYLO1); /* load it */
+
+	uasm_i_ehb(p);
 }
 
 static __cpuinit void build_huge_handler_tail(u32 **p,
@@ -552,8 +558,45 @@ static __cpuinit void build_huge_handler_tail(u32 **p,
 #else
 	UASM_i_SW(p, pte, 0, ptr);
 #endif
+
+	/* adjust the ptep pointer to be at even entry boundary.
+	 * this is needed to write back entries to tlb.
+	 */
+	uasm_i_ori(p, ptr, ptr, sizeof(pte_t));
+	uasm_i_xori(p, ptr, ptr, sizeof(pte_t));
+	UASM_i_LW(p, pte, 0, ptr);
+
 	build_huge_update_entries(p, pte, ptr);
+
+#ifdef CONFIG_NLM_XLP
+	/* Similar to no hugetlb case, checking probe result.
+	 * FIXME: this should not happen really.
+	 */
+	uasm_i_mfc0(p, ptr, C0_INDEX);
+
+	uasm_il_bltz(p, r, ptr, label_r4000_write_huge_probe_fail);
+	uasm_i_nop(p);
+
+#ifdef XLP_TLB_WORKAROUND
+	/* if it is index, check the index range, if the index points to ram tlb, use random */
+	uasm_i_mtc0(p, pte, OS_SCRATCH_REG3);
+	uasm_i_mfc0(p, pte, C0_CONFIG6);
+	uasm_i_srl(p, pte, pte, 6);
+	uasm_i_andi(p, pte, pte, 0x3ff); /* get the num of variable tlb -1 */
+	uasm_i_andi(p, ptr, ptr, 0x1fff); /* the index value */
+	uasm_i_subu(p, ptr, pte, ptr); /* compute (num_cam_tlb - 1 - index) */
+	uasm_i_mfc0(p, pte, OS_SCRATCH_REG3);
+	uasm_il_bltz(p, r, ptr, label_r4000_write_huge_probe_fail);
+	uasm_i_nop(p);
+#endif
+
+	build_huge_tlb_write_entry(p, l, r, pte, tlb_indexed);
+	uasm_l_r4000_write_huge_probe_fail(l, *p);
+
+	build_huge_tlb_write_entry(p, l, r, pte, tlb_random);
+#else
 	build_huge_tlb_write_entry(p, l, r, pte, tlb_indexed);
+#endif
 }
 #endif /* CONFIG_HUGETLB_PAGE */
 
@@ -576,15 +619,7 @@ build_get_pmde64(u32 **p, struct uasm_label **l, struct uasm_reloc **r,
 	uasm_il_bltz(p, r, tmp, label_vmalloc);
 	/* No uasm_i_nop needed here, since the next insn doesn't touch TMP. */
 
-#ifdef CONFIG_MIPS_PGD_C0_CONTEXT
-	/*
-	 * &pgd << 11 stored in CONTEXT [23..63].
-	 */
-	UASM_i_MFC0(p, ptr, C0_CONTEXT);
-	uasm_i_dins(p, ptr, 0, 0, 23); /* Clear lower 23 bits of context. */
-	uasm_i_ori(p, ptr, ptr, 0x540); /* 1 0  1 0 1  << 6  xkphys cached */
-	uasm_i_drotr(p, ptr, ptr, 11);
-#elif defined(CONFIG_SMP)
+#ifdef CONFIG_SMP
 # ifdef  CONFIG_MIPS_MT_SMTC
 	/*
 	 * SMTC uses TCBind value as "CPU" index
@@ -633,8 +668,7 @@ enum vmalloc64_mode {not_refill, refill};
  */
 static void __cpuinit
 build_get_pgd_vmalloc64(u32 **p, struct uasm_label **l, struct uasm_reloc **r,
-			unsigned int bvaddr, unsigned int ptr,
-			enum vmalloc64_mode mode)
+			unsigned int bvaddr, unsigned int ptr)
 {
 	long swpd = (long)swapper_pg_dir;
 
@@ -875,11 +909,11 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 	build_get_pgde32(&p, K0, K1); /* get pgd in K1 */
 #endif
 
+	build_get_ptep(&p, K0, K1);
 #ifdef CONFIG_HUGETLB_PAGE
 	build_is_huge_pte(&p, &r, K0, K1, label_tlb_huge_update);
 #endif
 
-	build_get_ptep(&p, K0, K1);
 	build_update_entries(&p, K0, K1);
 	build_tlb_write_entry(&p, &l, &r, tlb_random);
 	uasm_l_leave(&l, p);
@@ -903,7 +937,7 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 #endif
 
 #ifdef CONFIG_64BIT
-	build_get_pgd_vmalloc64(&p, &l, &r, K0, K1, refill);
+	build_get_pgd_vmalloc64(&p, &l, &r, K0, K1);
 #endif
 
 #if !defined(CONFIG_MAPPED_KERNEL)
@@ -1369,21 +1403,16 @@ build_r4000_tlbchange_handler_head(u32 **p, struct uasm_label **l,
 	build_get_pgde32(p, pte, ptr); /* get pgd in ptr */
 #endif
 
-#ifdef CONFIG_HUGETLB_PAGE
-	/*
-	 * For huge tlb entries, pmd doesn't contain an address but
-	 * instead contains the tlb pte. Check the PAGE_HUGE bit and
-	 * see if we need to jump to huge tlb processing.
-	 */
-	build_is_huge_pte(p, r, pte, ptr, label_tlb_huge_update);
-#endif
-
 	UASM_i_MFC0(p, pte, C0_BADVADDR);
 	UASM_i_LW(p, ptr, 0, ptr);
 	UASM_i_SRL(p, pte, pte, PAGE_SHIFT + PTE_ORDER - PTE_T_LOG2);
 	uasm_i_andi(p, pte, pte, (PTRS_PER_PTE - 1) << PTE_T_LOG2);
 	UASM_i_ADDU(p, ptr, ptr, pte);
 
+#ifdef CONFIG_HUGETLB_PAGE
+	build_is_huge_pte(p, r, pte, ptr, label_tlb_huge_update);
+#endif
+
 #ifdef CONFIG_SMP
 	uasm_l_smp_pgtable_change(l, *p);
 #endif
@@ -1407,14 +1436,6 @@ build_r4000_tlbchange_handler_tail(u32 **p, struct uasm_label **l,
 	uasm_i_nop(p);
 
 	build_tlb_write_entry(p, l, r, tlb_indexed);
-
-#ifdef CONFIG_HUGETLBFS
-#ifdef CONFIG_PAGE_SIZE_4KB
-	uasm_i_mtc0(p, ZERO, C0_PAGEMASK);
-#else
-	uasm_i_mtc0(p, K0, C0_PAGEMASK);
-#endif
-#endif
 	uasm_i_eret(p);
 	uasm_l_r4000_write_probe_fail(l, *p);
 	build_tlb_write_entry(p, l, r, tlb_random);
@@ -1422,7 +1443,7 @@ build_r4000_tlbchange_handler_tail(u32 **p, struct uasm_label **l,
 	uasm_i_eret(p); /* return from trap */
 
 #ifdef CONFIG_64BIT
-	build_get_pgd_vmalloc64(p, l, r, tmp, ptr, not_refill);
+	build_get_pgd_vmalloc64(p, l, r, tmp, ptr);
 #endif
 }
 
diff --git a/arch/mips/netlogic/xlp/mmu.c b/arch/mips/netlogic/xlp/mmu.c
index 7a75813..0e69842 100644
--- a/arch/mips/netlogic/xlp/mmu.c
+++ b/arch/mips/netlogic/xlp/mmu.c
@@ -1,27 +1,32 @@
-/***********************************************************************
- * Copyright 2003-2010 Netlogic Microsystems ("Netlogic"). All rights
- * reserved.
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
  * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
  * 1. Redistributions of source code must retain the above copyright
- * notice, this list of conditions and the following disclaimer.
+ *    notice, this list of conditions and the following disclaimer.
  * 2. Redistributions in binary form must reproduce the above copyright
- * notice, this list of conditions and the following disclaimer in
- * the documentation and/or other materials provided with the
- * distribution.
- * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
- * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
- * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
- * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
- * THE POSSIBILITY OF SUCH DAMAGE.
- * *****************************#NETL_2#********************************/
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_2# */
+
 #include <asm/mipsregs.h>
 #include <asm/mach-netlogic/mmu.h>
 #include <asm/mach-netlogic/pgwalker.h>
@@ -35,8 +40,20 @@
 #define READ_INHIBIT (1 << 31)
 #define EXEC_INHIBIT (1 << 30)
 
-#ifdef CONFIG_PGWALKER
-static int __initdata tlb_config = (ENABLE_ETLB | ENABLE_128_TLB | ENABLE_PGWALKER);
+#ifndef CONFIG_HUGETLB_PAGE
+#ifdef CONFIG_64BIT
+static int __initdata tlb_config = (ENABLE_ETLB | ENABLE_128_TLB);
+#else
+static int __initdata tlb_config = (ENABLE_128_TLB);
+#endif
+#else
+/* For hugetlb which has two different page sizes,
+ * xlp8xx/xlp3xx hardware page walker seems having some issues.
+ */
+static int __initdata tlb_config = (ENABLE_ETLB | ENABLE_128_TLB);
+#endif
+
+int is_nlm_xlp2xx_compat = 0;
 
 int __init disable_etlb(char *str)
 {
@@ -53,13 +70,13 @@ int __init disable_128tlb(char *str)
 }
 __setup("disable_128tlb", disable_128tlb);
 
-int __init disable_pgwalker_cmdline(char *str)
+int __init enable_pgwalker_cmdline(char *str)
 {
-	tlb_config &= ~ENABLE_PGWALKER;
+	tlb_config |= ENABLE_PGWALKER;
 
 	return 1;
 }
-__setup("disable_pgwalker", disable_pgwalker_cmdline);
+__setup("enable_pgwalker", enable_pgwalker_cmdline);
 
 /*
  * Page Walker
@@ -67,30 +84,25 @@ __setup("disable_pgwalker", disable_pgwalker_cmdline);
 
 DEFINE_PER_CPU(unsigned long [NR_ADDR_SEGMENTS], pgd_bases);
 
-#ifndef __PAGETABLE_PMD_FOLDED
+#ifdef CONFIG_64BIT
 static int pgtable_levels = PGD | PMD | PTE;
 #else
 static int pgtable_levels = PGD | PTE;
 #endif
 
-static int is_hwpw_mips_compliant(uint32_t proc_id)
-{
-	return (proc_id == CHIP_PROCESSOR_ID_XLP_3XX) ||
-		(proc_id == CHIP_PROCESSOR_ID_XLP_2XX) ||
-		(proc_id == CHIP_PROCESSOR_ID_XLP_1XX) ||
-		(proc_id == CHIP_PROCESSOR_ID_XLP_9XX);
-}
-
 static void pgwalker_init(void)
 {
 	unsigned int value;
 	int i = 0;
 
-	if (!(tlb_config & ENABLE_PGWALKER))
+	if (!(tlb_config & ENABLE_PGWALKER)) {
+		/* Disable hardware page walker */
+		write_c0_config6(read_c0_config6() & (~ENABLE_PGWALKER));
 		return;
+	}
 
 	/* Initialize pgd_bases to default values */
-	for (i = 0; i < NR_ADDR_SEGMENTS; i++) {
+	for(i = 0; i < NR_ADDR_SEGMENTS; i++) {
 		get_cpu_var(pgd_bases)[i] = (unsigned long)swapper_pg_dir;
 		put_cpu_var(pgd_bases);
 	}
@@ -121,7 +133,7 @@ static void pgwalker_init(void)
 	/* PGD shift and mask information */
 	pgw_register_write_w(PGW_PGD_SHIFT, _PGDIR_SHIFT - _PGD_T_LOG2);
 	pgw_register_write_w(PGW_PGD_MASK, (_PTRS_PER_PGD - 1) << _PGD_T_LOG2);
-#ifndef __PAGETABLE_PMD_FOLDED
+#ifdef CONFIG_64BIT
 	/*
 	 * MIPS Linux currently does not use 4-level page tables
 	 * and hence it is not necessary to fill in pud information
@@ -150,7 +162,7 @@ static void pgwalker_init(void)
 	put_cpu_var(pgd_bases);
 
 	dump_pgwalker_config();
-	pr_info("Initialized Page Walker on cpu@%d\n", hard_smp_processor_id());
+	printk("Initialized Page Walker on cpu@%d\n", hard_smp_processor_id());
 }
 
 static void pgwalker_init_mips_compliant(void)
@@ -231,23 +243,26 @@ void dump_pgwalker_config(void)
 	int i = 0;
 	uint64_t pwbase_val = 0, pwfield_val = 0, pwsize_val = 0;
 	uint32_t pwctl_val = 0;
-	int hwpw_mips_compliant = is_hwpw_mips_compliant(get_proc_id());
-
-	pgw_print_w(PGW_MMU_INFO);
-	pgw_print_w(PGW_PGD_SHIFT);
-	pgw_print_w(PGW_PGD_MASK);
-	pgw_print_w(PGW_PMD_SHIFT);
-	pgw_print_w(PGW_PMD_MASK);
-	pgw_print_w(PGW_PTE_SHIFT);
-	pgw_print_w(PGW_PTE_MASK);
-	pgw_print_w(PGW_PUD_SHIFT);
-	pgw_print_w(PGW_PUD_MASK);
-
-	pr_info("swapper_pg_dir = %lx\n", (unsigned long)swapper_pg_dir);
-	for (i = 0; i < NR_ADDR_SEGMENTS; i++)
-		pr_info("pgd_bases[%d] = 0x%lx\n", i, __get_cpu_var(pgd_bases)[i]);
-
-	if (hwpw_mips_compliant) {
+
+	if (!is_nlm_xlp2xx_compat) {
+		pgw_print_w(PGW_MMU_INFO);
+		pgw_print_w(PGW_PGD_SHIFT);
+		pgw_print_w(PGW_PGD_MASK);
+		pgw_print_w(PGW_PMD_SHIFT);
+		pgw_print_w(PGW_PMD_MASK);
+		pgw_print_w(PGW_PTE_SHIFT);
+		pgw_print_w(PGW_PTE_MASK);
+		pgw_print_w(PGW_PUD_SHIFT);
+		pgw_print_w(PGW_PUD_MASK);
+	} else {
+		pgw_print_w(PGW_MMU_SETUP);
+	}
+
+	printk("swapper_pg_dir = %lx\n", (unsigned long)swapper_pg_dir);
+	for(i = 0; i < NR_ADDR_SEGMENTS; i++) {
+		printk("pgd_bases[%d] = 0x%lx\n", i, __get_cpu_var(pgd_bases)[i]);
+	}
+	if (is_nlm_xlp2xx_compat) {
 		pwbase_val = read_c0_pwbase();
 		pwfield_val = read_c0_pwfield();
 		pwsize_val = read_c0_pwsize();
@@ -263,22 +278,9 @@ void dump_pgwalker_config(void)
 #ifdef CONFIG_NLM_XLP
 static void pgwalker_workaround_setup(void)
 {
-	uint32_t prid, chip_id, rev_id;
-
-	prid = read_c0_prid();
-	chip_id = (prid >> 8) & 0xff;
-	rev_id  = prid & 0xff;
-
-	/* Disable hardware page walker for XLP A0/1/2 chips (832-408),
-	 * Revision A0/A1/A2 chips.
-	 */
-	if (chip_id == CHIP_PROCESSOR_ID_XLP_8XX || chip_id == CHIP_PROCESSOR_ID_XLP_832
-	|| chip_id == CHIP_PROCESSOR_ID_XLP_816 || chip_id == CHIP_PROCESSOR_ID_XLP_432
-	|| chip_id == CHIP_PROCESSOR_ID_XLP_416 || chip_id == CHIP_PROCESSOR_ID_XLP_408) {
-		if (rev_id == XLP_REVISION_A0 || rev_id == XLP_REVISION_A1
-			|| rev_id == XLP_REVISION_A2)
-			tlb_config &= ~ENABLE_PGWALKER;
-	}
+	/* Disable hardware page walker for XLP A0/1/2, revision A0/A1/A2 chips. */
+	if (is_nlm_xlp8xx_ax())
+		tlb_config &= ~ENABLE_PGWALKER;
 }
 #else
 static void pgwalker_workaround_setup(void) {}
@@ -286,82 +288,70 @@ static void pgwalker_workaround_setup(void) {}
 
 void mmu_init(void)
 {
-	uint32_t config4_val = 0;
-	uint32_t proc_id = get_proc_id();
-	int hwpw_mips_compliant = is_hwpw_mips_compliant(proc_id);
+	uint32_t config4_val = 0, value;
 
 	/* For XLP832 A0-A2 chips, the page walker needs to be shutdown to
 	 * prevent potential errors.
 	 */
 	pgwalker_workaround_setup();
 
-	/*
-	 * Read back TLB entries after configuration
-	 */
-	current_cpu_data.tlbsize = (read_c0_config6() >> 16 ) & 0xffff;
+	if (is_nlm_xlp2xx_compat) {
+		/* MMU_SETUP:
+		 * [3]: using fixed TLB or not.
+		 * [4]: PTE format compatible with XLP8XX/XLP4XX/XLP3XX, mostly useful for RI/XI support
+		 */
+		value = 0;
+		if (tlb_config & ENABLE_ETLB)
+			value |= 1 << 3;
+		value |= 1 << 4;
+		pgw_register_write_w(PGW_MMU_SETUP, value);
 
-	/*
-	 * shift right half the number of 1s in
-	 * the pagemask and populate that value
-	 */
-	write_c0_config7(PM_DEFAULT_MASK >> (13 + (ffz(PM_DEFAULT_MASK >> 13) / 2)));
-
-#ifdef DEBUG
-	printk(KERN_INFO "( %s ): write_c0_config7 = %d\n", __FUNCTION__,
-		   read_c0_config7());
-#endif
-
-	if (hwpw_mips_compliant) {
 		/* set config4 to use 64KB page */
 		config4_val = read_c0_config4();
 		config4_val &= ~(((uint32_t)0x1f) << CFG4_FTLBPAGESIZE_O); /*clear 5-bit width field*/
-		config4_val |= ((uint32_t)0x3) << CFG4_FTLBPAGESIZE_O; /* 64KB page */
+		config4_val |= ((PAGE_SHIFT - 10) >> 1) << CFG4_FTLBPAGESIZE_O;
 		write_c0_config4(config4_val);
+	} else {
+		/*
+	 	* shift right half the number of 1s in
+	 	* the pagemask and populate that value
+	 	*/
+#ifdef CONFIG_HUGETLB_PAGE
+		write_c0_config7(PM_DEFAULT_MASK >> (13 + (ffz(PM_DEFAULT_MASK >> 13) / 2))
+			| ((PM_HUGE_MASK >> (13 + (ffz(PM_HUGE_MASK >> 13) / 2))) << 8));
+#else
+		write_c0_config7(PM_DEFAULT_MASK >> (13 + (ffz(PM_DEFAULT_MASK >> 13) / 2)));
+#endif
+
+#ifdef DEBUG
+		printk(KERN_INFO "( %s ): write_c0_config7 = %d\n", __FUNCTION__,
+			read_c0_config7());
+#endif
+
 	}
 
+	/*
+	 * Read back TLB entries after configuration
+	 */
+	current_cpu_data.tlbsize = (read_c0_config6() >> 16 ) & 0xffff;
+
 #ifdef CONFIG_EXEC_INHIBIT
-	pagegrain_write(pagegrain_read() | EXEC_INHIBIT);
+	write_c0_pagegrain(read_c0_pagegrain() | EXEC_INHIBIT);
 #endif
 
 #ifdef CONFIG_READ_INHIBIT
-	pagegrain_write(pagegrain_read() | READ_INHIBIT);
+	write_c0_pagegrain(read_c0_pagegrain() | READ_INHIBIT);
 #endif
 
-	if (hwpw_mips_compliant) {
+	if (is_nlm_xlp2xx_compat) {
 		pgwalker_init_mips_compliant();
 	} else {
 		pgwalker_init();
+
+		/* Intialize after pgwalker and others are configured! */
+		write_c0_config6(read_c0_config6() | tlb_config);
 	}
 	tlbstats_init();
 	entrylo0_mask_init();
 
-	/* Intialize after pgwalker and others are configured! */
-	write_c0_config6(read_c0_config6() | tlb_config);
 }
-#else	/* !CONFIG_PGWALKER */
-
-#ifndef CONFIG_HUGETLB_PAGE
-static int __initdata tlb_config = (ENABLE_ETLB | ENABLE_128_TLB);
-#endif
-
-void mmu_init(void)
-{
-#ifndef CONFIG_HUGETLB_PAGE
-	/*
-	 * shift right half the number of 1s in
-	 * the pagemask and populate that value
-	 */
-	write_c0_config7(PM_DEFAULT_MASK >> (13 + (ffz(PM_DEFAULT_MASK >> 13) / 2)));
-
-	/* Intialize after pgwalker and others are configured! */
-	write_c0_config6(read_c0_config6() | tlb_config);
-#endif
-
-	/*
-	 * Read back TLB entries after configuration
-	 */
-	current_cpu_data.tlbsize = ((read_c0_config6() >> 16) & 0xffff) + 1;
-	pr_info("%s: cpu = %d, tlbsize = %d\n", __func__, smp_processor_id(), current_cpu_data.tlbsize);
-}
-
-#endif	/* CONFIG_PGWALKER */
-- 
1.7.0

