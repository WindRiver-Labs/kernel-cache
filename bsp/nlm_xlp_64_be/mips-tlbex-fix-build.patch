From dcde04bce47b01060726b2689320be5b00bfe866 Mon Sep 17 00:00:00 2001
From: Yong Zhang <yong.zhang@windriver.com>
Date: Thu, 17 Jul 2014 16:09:56 +0800
Subject: [PATCH 15/16] mips:tlbex: fix build

Signed-off-by: Yong Zhang <yong.zhang@windriver.com>
---
 arch/mips/include/asm/cpu.h |    2 +-
 arch/mips/mm/tlbex.c        |  148 ++++++++++++-------------------------------
 2 files changed, 43 insertions(+), 107 deletions(-)

diff --git a/arch/mips/include/asm/cpu.h b/arch/mips/include/asm/cpu.h
index 6a0a3d5..3dc30fd 100644
--- a/arch/mips/include/asm/cpu.h
+++ b/arch/mips/include/asm/cpu.h
@@ -225,7 +225,7 @@ enum cpu_type_enum {
 	 * MIPS64 class processors
 	 */
 	CPU_5KC, CPU_20KC, CPU_25KF, CPU_SB1, CPU_SB1A, CPU_LOONGSON2,
-	CPU_CAVIUM_OCTEON, CPU_CAVIUM_OCTEON_PLUS,
+	CPU_CAVIUM_OCTEON, CPU_CAVIUM_OCTEON_PLUS, CPU_CAVIUM_OCTEON2,
 	CPU_XLP,
 
 	CPU_LAST
diff --git a/arch/mips/mm/tlbex.c b/arch/mips/mm/tlbex.c
index cb361b4..cfa2020 100644
--- a/arch/mips/mm/tlbex.c
+++ b/arch/mips/mm/tlbex.c
@@ -104,6 +104,7 @@ static int use_lwx_insns(void)
 		return 0;
 	}
 }
+
 #if defined(CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE) && \
     CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE > 0
 static bool scratchpad_available(void)
@@ -522,7 +523,6 @@ static void __cpuinit build_tlb_write_entry(u32 **p, struct uasm_label **l,
 	case CPU_5KC:
 	case CPU_TX49XX:
 	case CPU_PR4450:
-	case CPU_XLR:
 	case CPU_XLP:
 		uasm_i_nop(p);
 		tlbw(p);
@@ -538,12 +538,13 @@ static void __cpuinit build_tlb_write_entry(u32 **p, struct uasm_label **l,
 	case CPU_4KSC:
 	case CPU_20KC:
 	case CPU_25KF:
-	case CPU_BMIPS32:
-	case CPU_BMIPS3300:
-	case CPU_BMIPS4350:
-	case CPU_BMIPS4380:
-	case CPU_BMIPS5000:
+	case CPU_BCM3302:
+	case CPU_BCM4710:
 	case CPU_LOONGSON2:
+	case CPU_BCM6338:
+	case CPU_BCM6345:
+	case CPU_BCM6348:
+	case CPU_BCM6358:
 	case CPU_R5500:
 		if (m4kc_tlbp_war())
 			uasm_i_nop(p);
@@ -608,11 +609,6 @@ static void __cpuinit build_tlb_write_entry(u32 **p, struct uasm_label **l,
 		tlbw(p);
 		break;
 
-	case CPU_JZRISC:
-		tlbw(p);
-		uasm_i_nop(p);
-		break;
-
 	default:
 		panic("No TLB refill handler yet (CPU type: %d)",
 		      current_cpu_data.cputype);
@@ -713,12 +709,8 @@ build_is_huge_pte(u32 **p, struct uasm_reloc **r, unsigned int tmp,
 		unsigned int pmd, int lid)
 {
 	UASM_i_LW(p, tmp, 0, pmd);
-	if (use_bbit_insns()) {
-		uasm_il_bbit1(p, r, tmp, ilog2(_PAGE_HUGE), lid);
-	} else {
-		uasm_i_andi(p, tmp, tmp, _PAGE_HUGE);
-		uasm_il_bnez(p, r, tmp, lid);
-	}
+	uasm_i_andi(p, tmp, tmp, _PAGE_HUGE);
+	uasm_il_bnez(p, r, tmp, lid);
 }
 
 static __cpuinit void build_huge_update_entries(u32 **p,
@@ -1201,12 +1193,8 @@ build_fast_tlb_refill_handler (u32 **p, struct uasm_label **l,
 #endif
 	uasm_i_andi(p, scratch, scratch, (PTRS_PER_PGD - 1) << 3);
 
-	if (use_lwx_insns()) {
-		UASM_i_LWX(p, LOC_PTEP, scratch, ptr);
-	} else {
-		uasm_i_daddu(p, ptr, ptr, scratch); /* add in pgd offset */
-		uasm_i_ld(p, LOC_PTEP, 0, ptr); /* get pmd pointer */
-	}
+	uasm_i_daddu(p, ptr, ptr, scratch); /* add in pgd offset */
+	uasm_i_ld(p, LOC_PTEP, 0, ptr); /* get pmd pointer */
 
 #ifndef __PAGETABLE_PMD_FOLDED
 	/* get pmd offset in bytes */
@@ -1214,12 +1202,8 @@ build_fast_tlb_refill_handler (u32 **p, struct uasm_label **l,
 	uasm_i_andi(p, scratch, scratch, (PTRS_PER_PMD - 1) << 3);
 	GET_CONTEXT(p, tmp); /* get context reg */
 
-	if (use_lwx_insns()) {
-		UASM_i_LWX(p, scratch, scratch, ptr);
-	} else {
-		uasm_i_daddu(p, ptr, ptr, scratch); /* add in pmd offset */
-		UASM_i_LW(p, scratch, 0, ptr);
-	}
+	uasm_i_daddu(p, ptr, ptr, scratch); /* add in pmd offset */
+	UASM_i_LW(p, scratch, 0, ptr);
 #endif
 	/* Adjust the context during the load latency. */
 	build_adjust_context(p, tmp);
@@ -1231,25 +1215,15 @@ build_fast_tlb_refill_handler (u32 **p, struct uasm_label **l,
 	 * delay slot.  It cannot issue in the same cycle and may be
 	 * speculative and unneeded.
 	 */
-	if (use_lwx_insns())
-		uasm_i_nop(p);
 #endif /* CONFIG_HUGETLB_PAGE */
 
 
 	/* build_update_entries */
-	if (use_lwx_insns()) {
-		even = ptr;
-		odd = tmp;
-		UASM_i_LWX(p, even, scratch, tmp);
-		UASM_i_ADDIU(p, tmp, tmp, sizeof(pte_t));
-		UASM_i_LWX(p, odd, scratch, tmp);
-	} else {
-		UASM_i_ADDU(p, ptr, scratch, tmp); /* add in offset */
-		even = tmp;
-		odd = ptr;
-		UASM_i_LW(p, even, 0, ptr); /* get even pte */
-		UASM_i_LW(p, odd, sizeof(pte_t), ptr); /* get odd pte */
-	}
+	UASM_i_ADDU(p, ptr, scratch, tmp); /* add in offset */
+	even = tmp;
+	odd = ptr;
+	UASM_i_LW(p, even, 0, ptr); /* get even pte */
+	UASM_i_LW(p, odd, sizeof(pte_t), ptr); /* get odd pte */
 	if (kernel_uses_smartmips_rixi) {
 		uasm_i_dsrl_safe(p, even, even, ilog2(_PAGE_NO_EXEC));
 		uasm_i_dsrl_safe(p, odd, odd, ilog2(_PAGE_NO_EXEC));
@@ -1665,16 +1639,11 @@ build_pte_present(u32 **p, struct uasm_reloc **r,
 	int t = scratch >= 0 ? scratch : pte;
 
 	if (kernel_uses_smartmips_rixi) {
-		if (use_bbit_insns()) {
-			uasm_il_bbit0(p, r, pte, ilog2(_PAGE_PRESENT), lid);
-			uasm_i_nop(p);
-		} else {
-			uasm_i_andi(p, t, pte, _PAGE_PRESENT);
-			uasm_il_beqz(p, r, t, lid);
-			if (pte == t)
-				/* You lose the SMP race :-(*/
-				iPTE_LW(p, pte, ptr);
-		}
+		uasm_i_andi(p, t, pte, _PAGE_PRESENT);
+		uasm_il_beqz(p, r, t, lid);
+		if (pte == t)
+			/* You lose the SMP race :-(*/
+			iPTE_LW(p, pte, ptr);
 	} else {
 		uasm_i_andi(p, t, pte, _PAGE_PRESENT | _PAGE_READ);
 		uasm_i_xori(p, t, t, _PAGE_PRESENT | _PAGE_READ);
@@ -1738,17 +1707,12 @@ build_pte_modifiable(u32 **p, struct uasm_reloc **r,
 		     unsigned int pte, unsigned int ptr, int scratch,
 		     enum label_id lid)
 {
-	if (use_bbit_insns()) {
-		uasm_il_bbit0(p, r, pte, ilog2(_PAGE_WRITE), lid);
-		uasm_i_nop(p);
-	} else {
-		int t = scratch >= 0 ? scratch : pte;
-		uasm_i_andi(p, t, pte, _PAGE_WRITE);
-		uasm_il_beqz(p, r, t, lid);
-		if (pte == t)
-			/* You lose the SMP race :-(*/
-			iPTE_LW(p, pte, ptr);
-	}
+	int t = scratch >= 0 ? scratch : pte;
+	uasm_i_andi(p, t, pte, _PAGE_WRITE);
+	uasm_il_beqz(p, r, t, lid);
+	if (pte == t)
+		/* You lose the SMP race :-(*/
+		iPTE_LW(p, pte, ptr);
 }
 
 #ifndef CONFIG_MIPS_PGD_C0_CONTEXT
@@ -2008,23 +1972,14 @@ static void __cpuinit build_r4000_tlb_load_handler(void)
 		 * If the page is not _PAGE_VALID, RI or XI could not
 		 * have triggered it.  Skip the expensive test..
 		 */
-		if (use_bbit_insns()) {
-			uasm_il_bbit0(&p, &r, wr.r1, ilog2(_PAGE_VALID),
-				      label_tlbl_goaround1);
-		} else {
-			uasm_i_andi(&p, wr.r3, wr.r1, _PAGE_VALID);
-			uasm_il_beqz(&p, &r, wr.r3, label_tlbl_goaround1);
-		}
+		uasm_i_andi(&p, wr.r3, wr.r1, _PAGE_VALID);
+		uasm_il_beqz(&p, &r, wr.r3, label_tlbl_goaround1);
 		uasm_i_nop(&p);
 
 		uasm_i_tlbr(&p);
 		/* Examine  entrylo 0 or 1 based on ptr. */
-		if (use_bbit_insns()) {
-			uasm_i_bbit0(&p, wr.r2, ilog2(sizeof(pte_t)), 8);
-		} else {
-			uasm_i_andi(&p, wr.r3, wr.r2, sizeof(pte_t));
-			uasm_i_beqz(&p, wr.r3, 8);
-		}
+		uasm_i_andi(&p, wr.r3, wr.r2, sizeof(pte_t));
+		uasm_i_beqz(&p, wr.r3, 8);
 		/* load it in the delay slot*/
 		UASM_i_MFC0(&p, wr.r3, C0_ENTRYLO0);
 		/* load it if ptr is odd */
@@ -2033,15 +1988,9 @@ static void __cpuinit build_r4000_tlb_load_handler(void)
 		 * If the entryLo (now in wr.r3) is valid (bit 1), RI or
 		 * XI must have triggered it.
 		 */
-		if (use_bbit_insns()) {
-			uasm_il_bbit1(&p, &r, wr.r3, 1, label_nopage_tlbl);
-			uasm_i_nop(&p);
-			uasm_l_tlbl_goaround1(&l, p);
-		} else {
-			uasm_i_andi(&p, wr.r3, wr.r3, 2);
-			uasm_il_bnez(&p, &r, wr.r3, label_nopage_tlbl);
-			uasm_i_nop(&p);
-		}
+		uasm_i_andi(&p, wr.r3, wr.r3, 2);
+		uasm_il_bnez(&p, &r, wr.r3, label_nopage_tlbl);
+		uasm_i_nop(&p);
 		uasm_l_tlbl_goaround1(&l, p);
 	}
 	build_make_valid(&p, &r, wr.r1, wr.r2);
@@ -2062,23 +2011,14 @@ static void __cpuinit build_r4000_tlb_load_handler(void)
 		 * If the page is not _PAGE_VALID, RI or XI could not
 		 * have triggered it.  Skip the expensive test..
 		 */
-		if (use_bbit_insns()) {
-			uasm_il_bbit0(&p, &r, wr.r1, ilog2(_PAGE_VALID),
-				      label_tlbl_goaround2);
-		} else {
-			uasm_i_andi(&p, wr.r3, wr.r1, _PAGE_VALID);
-			uasm_il_beqz(&p, &r, wr.r3, label_tlbl_goaround2);
-		}
+		uasm_i_andi(&p, wr.r3, wr.r1, _PAGE_VALID);
+		uasm_il_beqz(&p, &r, wr.r3, label_tlbl_goaround2);
 		uasm_i_nop(&p);
 
 		uasm_i_tlbr(&p);
 		/* Examine  entrylo 0 or 1 based on ptr. */
-		if (use_bbit_insns()) {
-			uasm_i_bbit0(&p, wr.r2, ilog2(sizeof(pte_t)), 8);
-		} else {
-			uasm_i_andi(&p, wr.r3, wr.r2, sizeof(pte_t));
-			uasm_i_beqz(&p, wr.r3, 8);
-		}
+		uasm_i_andi(&p, wr.r3, wr.r2, sizeof(pte_t));
+		uasm_i_beqz(&p, wr.r3, 8);
 		/* load it in the delay slot*/
 		UASM_i_MFC0(&p, wr.r3, C0_ENTRYLO0);
 		/* load it if ptr is odd */
@@ -2087,12 +2027,8 @@ static void __cpuinit build_r4000_tlb_load_handler(void)
 		 * If the entryLo (now in wr.r3) is valid (bit 1), RI or
 		 * XI must have triggered it.
 		 */
-		if (use_bbit_insns()) {
-			uasm_il_bbit0(&p, &r, wr.r3, 1, label_tlbl_goaround2);
-		} else {
-			uasm_i_andi(&p, wr.r3, wr.r3, 2);
-			uasm_il_beqz(&p, &r, wr.r3, label_tlbl_goaround2);
-		}
+		uasm_i_andi(&p, wr.r3, wr.r3, 2);
+		uasm_il_beqz(&p, &r, wr.r3, label_tlbl_goaround2);
 		if (PM_DEFAULT_MASK == 0)
 			uasm_i_nop(&p);
 		/*
-- 
1.7.0

