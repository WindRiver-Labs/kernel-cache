From 13d8cffe7c5ccfba00b69c83ab906264a1f82bcf Mon Sep 17 00:00:00 2001
From: Michael Gill <michael.gill@xilinx.com>
Date: Fri, 20 May 2016 12:40:21 -0700
Subject: [PATCH 109/188] staging: apf: Fixed buffer over run related to page
 pinning

This patch comes from:
  https://github.com/Xilinx/linux-xlnx.git

The data structure used for storing pinned user space page
structures was a constant size.  Now it is adjustable
to accommodate large transfers from malloc allocated buffers

Signed-off-by: Michael Gill <gill@xilinx.com>
Tested-by : Radhey Shyam Pandey <radheys@xilinx.com>
Signed-off-by: Michal Simek <michal.simek@xilinx.com>

(cherry picked from commit 62348dfbcd7d913236ee55c40719ca41c60c5625)
Signed-off-by: Zumeng Chen <zumeng.chen@windriver.com>
---
 drivers/staging/apf/xilinx-dma-apf.c | 21 +++++++++++++++++----
 1 file changed, 17 insertions(+), 4 deletions(-)

diff --git a/drivers/staging/apf/xilinx-dma-apf.c b/drivers/staging/apf/xilinx-dma-apf.c
index 740d970..98dfd69 100644
--- a/drivers/staging/apf/xilinx-dma-apf.c
+++ b/drivers/staging/apf/xilinx-dma-apf.c
@@ -196,7 +196,7 @@ static void xilinx_chan_desc_cleanup(struct xdma_chan *chan)
 	spin_lock_irqsave(&chan->lock, flags);
 #define XDMA_BD_STS_RXEOF_MASK 0x04000000
 	desc = chan->bds[chan->bd_cur];
-	while ((desc->status & XDMA_BD_STS_ALL_MASK)) {
+	while (desc->status & XDMA_BD_STS_ALL_MASK) {
 		if ((desc->status & XDMA_BD_STS_RXEOF_MASK) &&
 		    !(desc->dmahead)) {
 			pr_info("ERROR: premature EOF on DMA\n");
@@ -417,8 +417,10 @@ static int xdma_setup_hw_desc(struct xdma_chan *chan,
 	int status;
 	unsigned long flags;
 	unsigned int bd_used_saved;
-	if (!chan)
+	if (!chan) {
+		pr_err("Requested transfer on invalid channel\n");
 		return -ENODEV;
+	}
 
 	/* if we almost run out of bd, try to recycle some */
 	if ((chan->poll_mode) && (chan->bd_used >= XDMA_BD_CLEANUP_THRESHOLD))
@@ -625,7 +627,8 @@ static unsigned int sgl_merge(struct scatterlist *sgl, unsigned int sgl_len,
 	return sg_merged_num;
 }
 
-static struct page *mapped_pages[XDMA_MAX_BD_CNT];
+static int mapped_pages_count;
+static struct page **mapped_pages;
 static int pin_user_pages(unsigned long uaddr,
 			   unsigned int ulen,
 			   int write,
@@ -649,6 +652,16 @@ static int pin_user_pages(unsigned long uaddr,
 	first_page = uaddr / PAGE_SIZE;
 	last_page = (uaddr + ulen - 1) / PAGE_SIZE;
 	num_pages = last_page - first_page + 1;
+	if (mapped_pages_count < num_pages) {
+		if (mapped_pages)
+			vfree(mapped_pages);
+		mapped_pages_count = num_pages * 2;
+		mapped_pages = vmalloc(sizeof(*mapped_pages) *
+				       mapped_pages_count);
+		if (!mapped_pages)
+			return -ENOMEM;
+	}
+
 	down_read(&mm->mmap_sem);
 	status = get_user_pages(curr_task, mm, uaddr, num_pages, write, 1,
 				mapped_pages, NULL);
@@ -694,7 +707,7 @@ static int pin_user_pages(unsigned long uaddr,
 
 		return 0;
 	} else {
-
+		pr_err("Failed to pin user pages\n");
 		for (pgidx = 0; pgidx < status; pgidx++) {
 			page_cache_release(mapped_pages[pgidx]);
 		}
-- 
2.0.2

