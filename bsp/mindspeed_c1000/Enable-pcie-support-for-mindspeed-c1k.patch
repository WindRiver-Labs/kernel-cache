From 230278ba91ebc799a81c39aea050c57c68999e68 Mon Sep 17 00:00:00 2001
From: Haiqing Bai <Haiqing.Bai@windriver.com>
Date: Fri, 3 Jun 2011 15:19:29 +0800
Subject: [PATCH 1/2] Enable pcie support for mindspeed c1k.

Original source code came from sdk-comcerto-openwrt-6.0.

Add pcie controller support for mindspeed_c1000.

Signed-off-by: Haiqing Bai <Haiqing.Bai@windriver.com>
---
 arch/arm/Kconfig                                   |    3 +-
 arch/arm/include/asm/pci.h                         |    2 +
 arch/arm/mach-comcerto/Makefile                    |    4 +
 arch/arm/mach-comcerto/comcerto-1000.c             |   32 +
 .../arm/mach-comcerto/include/mach/comcerto-1000.h |    9 +
 .../mach-comcerto/include/mach/comcerto-1000/io.h  |   76 ++
 .../include/mach/comcerto-1000/pcie.h              |  260 ++++
 arch/arm/mach-comcerto/include/mach/io.h           |   13 +-
 arch/arm/mach-comcerto/pcie-c1000.c                | 1257 ++++++++++++++++++++
 arch/arm/mach-comcerto/pcie-c1000.h                |   73 ++
 10 files changed, 1718 insertions(+), 11 deletions(-)
 create mode 100644 arch/arm/mach-comcerto/include/mach/comcerto-1000/io.h
 create mode 100644 arch/arm/mach-comcerto/include/mach/comcerto-1000/pcie.h
 create mode 100644 arch/arm/mach-comcerto/pcie-c1000.c
 create mode 100644 arch/arm/mach-comcerto/pcie-c1000.h

diff --git a/arch/arm/Kconfig b/arch/arm/Kconfig
index 662ec2c..fa1fe44 100644
--- a/arch/arm/Kconfig
+++ b/arch/arm/Kconfig
@@ -362,6 +362,7 @@ config ARCH_COMCERTO
 	select CPU_V6
 	select ARCH_HAS_CPUFREQ
 	select CPU_FREQ
+	select ARCH_SUPPORTS_MSI
 	help
 	  This enables support for Mindspeed's Comcerto development boards.
 	  If you would like to build your kernel to run on one of these boards
@@ -1118,7 +1119,7 @@ config ISA_DMA_API
 	bool
 
 config PCI
-	bool "PCI support" if ARCH_INTEGRATOR_AP || ARCH_VERSATILE_PB || ARCH_IXP4XX || ARCH_KS8695 || MACH_ARMCORE || ARCH_CNS3XXX
+	bool "PCI support" if ARCH_INTEGRATOR_AP || ARCH_VERSATILE_PB || ARCH_IXP4XX || ARCH_KS8695 || MACH_ARMCORE || ARCH_CNS3XXX || ARCH_COMCERTO
 	help
 	  Find out whether you have a PCI motherboard. PCI is the name of a
 	  bus system, i.e. the way the CPU talks to the other stuff inside
diff --git a/arch/arm/include/asm/pci.h b/arch/arm/include/asm/pci.h
index 3eb2a45..71a73a9 100644
--- a/arch/arm/include/asm/pci.h
+++ b/arch/arm/include/asm/pci.h
@@ -25,6 +25,8 @@ static inline int pci_proc_domain(struct pci_bus *bus)
    termination by PIC bus mater devices
 */
 extern void pcibios_set_master(struct pci_dev *dev);
+#elif defined(CONFIG_ARCH_COMCERTO)
+void pcibios_set_master(struct pci_dev *dev);
 #else
 static inline void pcibios_set_master(struct pci_dev *dev)
 {
diff --git a/arch/arm/mach-comcerto/Makefile b/arch/arm/mach-comcerto/Makefile
index 7683715..6260c63 100644
--- a/arch/arm/mach-comcerto/Makefile
+++ b/arch/arm/mach-comcerto/Makefile
@@ -10,3 +10,7 @@ obj-$(CONFIG_ARCH_M83XXX)			+= comcerto-1000.o pwrmgmt_c1000.o
 obj-$(CONFIG_EVM_C1KMFCN_EVM)			+= board-c1kmfcn_evm.o
 
 obj-$(CONFIG_CPU_FREQ)                          += cpufreq.o cpufreq1.o
+
+ifeq ($(CONFIG_PCI),y)
+	obj-$(CONFIG_ARCH_M83XXX)               += pcie-c1000.o
+endif
diff --git a/arch/arm/mach-comcerto/comcerto-1000.c b/arch/arm/mach-comcerto/comcerto-1000.c
index 02b5a99..399311d 100644
--- a/arch/arm/mach-comcerto/comcerto-1000.c
+++ b/arch/arm/mach-comcerto/comcerto-1000.c
@@ -67,6 +67,38 @@ static struct map_desc comcerto_io_desc[] __initdata = {
 		.length     = SZ_64K,
 		.type       = MT_DEVICE
 	},
+#if defined(CONFIG_PCI)
+	{
+		.virtual    = APB_VADDR(COMCERTO_APB_PCIePHY_BASE),
+		.pfn        = __phys_to_pfn(COMCERTO_APB_PCIePHY_BASE),
+		.length     = SZ_64K,
+		.type       = MT_DEVICE
+	},
+	{
+		.virtual    = APB_VADDR(COMCERTO_APB_PCIe0_BASE),
+		.pfn        = __phys_to_pfn(COMCERTO_APB_PCIe0_BASE),
+		.length     = SZ_64K,
+		.type       = MT_DEVICE
+	},
+	{
+		.virtual    = APB_VADDR(COMCERTO_APB_PCIe1_BASE),
+		.pfn        = __phys_to_pfn(COMCERTO_APB_PCIe1_BASE),
+		.length     = SZ_64K,
+		.type       = MT_DEVICE
+	},
+	{
+		.virtual    = COMCERTO_PCIe0CMD_VADDR_BASE,
+		.pfn        = __phys_to_pfn(COMCERTO_AHB_PCIe0CMD_BASE),
+		.length     = SZ_64K,
+		.type       = MT_DEVICE
+	},
+	{
+		.virtual    = COMCERTO_PCIe1CMD_VADDR_BASE,
+		.pfn        = __phys_to_pfn(COMCERTO_AHB_PCIe1CMD_BASE),
+		.length     = SZ_64K,
+		.type       = MT_DEVICE
+	},
+#endif
 	{
 		.virtual    = APB_VADDR(COMCERTO_APB_GPIO_BASE),
 		.pfn        = __phys_to_pfn(COMCERTO_APB_GPIO_BASE),
diff --git a/arch/arm/mach-comcerto/include/mach/comcerto-1000.h b/arch/arm/mach-comcerto/include/mach/comcerto-1000.h
index 9e996c9..2f7169f 100644
--- a/arch/arm/mach-comcerto/include/mach/comcerto-1000.h
+++ b/arch/arm/mach-comcerto/include/mach/comcerto-1000.h
@@ -71,6 +71,12 @@
 #define COMCERTO_AHB_DDRCONFIG_BASE		0x0D000000
 #define COMCERTO_AHB_ARAM_BASE			0x0A000000
 
+#define COMCERTO_PCIe_MEM_SIZE 0x10000000
+
+#define IO_SPACE_LIMIT         0
+#define PCIBIOS_MIN_MEM                COMCERTO_AHB_PCIe0_BASE
+#define PCIBIOS_MIN_IO         0
+
 /* Physical addresses of memories */
 #define COMCERTO_SDRAM_BASE                     (COMCERTO_AHB_DDR_BASE + SZ_8M)
 #define ARAM_MEMORY_SIZE                        SZ_128K
@@ -97,6 +103,9 @@
 #include <mach/comcerto-1000/intr.h>
 #include <mach/comcerto-1000/gpio.h>
 #include <mach/comcerto-1000/exp-bus.h>
+#include <mach/comcerto-1000/pcie.h>
+
+#define pcibios_assign_all_busses()    1
 
 #ifndef __ASSEMBLY__
 typedef enum {
diff --git a/arch/arm/mach-comcerto/include/mach/comcerto-1000/io.h b/arch/arm/mach-comcerto/include/mach/comcerto-1000/io.h
new file mode 100644
index 0000000..25bccf7
--- /dev/null
+++ b/arch/arm/mach-comcerto/include/mach/comcerto-1000/io.h
@@ -0,0 +1,76 @@
+/*
+ *  arch/arm/mach-comcerto/include/mach/comcerto-1000/io.h
+ *
+ *  Copyright (C) 2004,2005 Mindspeed Technologies, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#ifndef __ASM_ARCH_COMCERTO1000_IO_H
+#define __ASM_ARCH_COMCERTO1000_IO_H
+
+#include <mach/hardware.h>
+
+#if !defined(CONFIG_PCI)
+
+#define __io(a)			((void __iomem *)(a))
+#define __mem_pci(a)	(a)
+
+#else
+
+#define __mem_pci(a)	(a)
+
+/* IO ports are not supported */
+#define outb(v, p)	__readwrite_bug("outb")
+#define outw(v, p)	__readwrite_bug("outw")
+#define outl(v, p)	__readwrite_bug("outl")
+
+#define inb(p)		(__readwrite_bug("inb"), 0)
+#define inw(p)		(__readwrite_bug("inw"), 0)
+#define inl(p)		(__readwrite_bug("inl"), 0)
+
+#define outsb(p, d, l)	__readwrite_bug("outsb")
+#define outsw(p, d, l)	__readwrite_bug("outsw")
+#define outsl(p, d, l)	__readwrite_bug("outsl")
+
+#define insb(p, d, l)	(__readwrite_bug("insb"), 0)
+#define insw(p, d, l)	(__readwrite_bug("insw"), 0)
+#define insl(p, d, l)	(__readwrite_bug("insl"), 0)
+
+/*
+ * io{read, write}{8, 16, 32} macros
+ */
+
+#define ioread8(p)	({ unsigned int __v = __raw_readb(p); __v; })
+#define ioread16(p)	({ unsigned int __v = le16_to_cpu(__raw_readw(p)); __v; })
+#define ioread32(p)	({ unsigned int __v = le32_to_cpu(__raw_readl(p)); __v; })
+
+#define iowrite8(v, p)	__raw_writeb(v, p)
+#define iowrite16(v, p)	__raw_writew(cpu_to_le16(v), p)
+#define iowrite32(v, p)	__raw_writel(cpu_to_le32(v), p)
+
+#define ioread8_rep(p, d, c)	__raw_readsb(p, d, c)
+#define ioread16_rep(p, d, c)	__raw_readsw(p, d, c)
+#define ioread32_rep(p, d, c)	__raw_readsl(p, d, c)
+
+#define iowrite8_rep(p, s, c)	__raw_writesb(p, s, c)
+#define iowrite16_rep(p, s, c)	__raw_writesw(p, s, c)
+#define iowrite32_rep(p, s, c)	__raw_writesl(p, s, c)
+
+#define ioport_map(c, s)		(__readwrite_bug("ioport_map"), NULL)
+#define ioport_unmap(addr)	__readwrite_bug("ioport_unmap")
+
+#endif /* !defined(CONFIG_PCI) */
+
+#endif /* __ASM_ARCH_COMCERTO1000_IO_H */
diff --git a/arch/arm/mach-comcerto/include/mach/comcerto-1000/pcie.h b/arch/arm/mach-comcerto/include/mach/comcerto-1000/pcie.h
new file mode 100644
index 0000000..8a20f0c
--- /dev/null
+++ b/arch/arm/mach-comcerto/include/mach/comcerto-1000/pcie.h
@@ -0,0 +1,260 @@
+/*
+ *  arch/arm/mach-comcerto/include/mach/comcerto-1000/pcie.h
+ *
+ *  Copyright (C) 2008 Mindspeed Technologies, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef __COMCERTO_PCIE_H__
+#define __COMCERTO_PCIE_H__
+
+/***** Registers address *****/
+
+#define PCIE_SUBSYS_CTRL		0x00	/* PCIE_CTL */
+#define PCIE_SUBSYS_CFG			0x04	/* PCIE_CFG */
+
+#define PCIE_INT_RAW_STATUS		0x08	/* PCIE_IRQ */
+
+#define PCIE_INT_ROUTING_CPU_ENABLE	0x0C	/* PCIE_IE0 */
+#define PCIE_INT_ROUTING_CPU_DISABLE	0x10	/* PCIE_ID0 */
+#define PCIE_INT_ROUTING_CPU_MASK	0x14	/* PCIE_IM0 */
+
+#define PCIE_INT_ROUTING_MSI1_ENABLE	0x18	/* PCIE_IE1 */
+#define PCIE_INT_ROUTING_MSI1_DISABLE	0x1C	/* PCIE_ID1 */
+#define PCIE_INT_ROUTING_MSI1_MASK	0x20	/* PCIE_IM1 */
+
+#define PCIE_INT_ROUTING_MSI2_ENABLE	0x24	/* PCIE_IE2 */
+#define PCIE_INT_ROUTING_MSI2_DISABLE	0x28	/* PCIE_ID2 */
+#define PCIE_INT_ROUTING_MSI2_MASK	0x2C	/* PCIE_IM2 */
+
+#define PCIE_INT_ROUTING_MSI3_ENABLE	0x30	/* PCIE_IE3 */
+#define PCIE_INT_ROUTING_MSI3_DISABLE	0x34	/* PCIE_ID3 */
+#define PCIE_INT_ROUTING_MSI3_MASK	0x38	/* PCIE_IM3 */
+
+#define PCIE_INT_ROUTING_MSI4_ENABLE	0x3C	/* PCIE_IE3 */
+#define PCIE_INT_ROUTING_MSI4_DISABLE	0x40	/* PCIE_ID4 */
+#define PCIE_INT_ROUTING_MSI4_MASK	0x44	/* PCIE_IM4 */
+
+#define PCIE_INT_TEST			0x48	/* PCIE_ITS */
+
+#define PCIE_UPST_INT_RAW_STATUS	0x4C	/* US_IRQ */
+#define PCIE_UPST_INT_ENABLE		0x50	/* US_IE */
+#define PCIE_UPST_INT_DISABLE		0x54	/* US_ID */
+#define PCIE_UPST_INT_MASK		0x58	/* US_IM */
+#define PCIE_UPST_INT_TEST		0x5C	/* US_ITS */
+
+#define PCIE_MSI_CH0_ADDR		0x60	/* MSI_CH0 */
+#define PCIE_MSI_CH1_ADDR		0x64	/* MSI_CH1 */
+#define PCIE_MSI_CH2_ADDR		0x68	/* MSI_CH2 */
+#define PCIE_MSI_CH3_ADDR		0x6C	/* MSI_CH3 */
+
+#define PCIE_POWER_MANAGEMENT_STATUS	0x70	/* PM_STS */
+
+#define PCIE_BAR0_ADDR_OFFSET		0x74	/* BAR0_LA */
+#define PCIE_BAR1_ADDR_OFFSET		0x78	/* BAR1_LA */
+#define PCIE_BAR2_ADDR_OFFSET		0x7C	/* BAR2_LA */
+
+#define PCIE_BAR0_SIZE			0x80	/* BAR0_MSK */
+#define PCIE_BAR1_SIZE			0x84	/* BAR1_MSK */
+#define PCIE_BAR2_SIZE			0x88	/* BAR2_MSK */
+
+#define PCIE_DMA_CTRL_CFG		0x8C	/* DMA_CTL */
+
+#define PCIE_CH0_DMA_CTRL_CFG		0x90	/* CH0_CTL */
+
+#define PCIE_CH0_DMA_INT_RAW_STATUS	0x94	/* CH0_IRQ */
+#define PCIE_CH0_DMA_INT_ENABLE		0x98	/* CH0_IE */
+#define PCIE_CH0_DMA_INT_DISABLE	0x9C	/* CH0_ID */
+#define PCIE_CH0_DMA_INT_MASK		0xA0	/* CH0_IM */
+#define PCIE_CH0_DMA_INT_TEST		0xA4	/* CH0_ITS */
+
+#define PCIE_CH0_MSG_STATUS		0xA8	/* CH0_MSG */
+#define PCIE_CH0_DESC_QUEUE_ADDR	0xAC	/* CH0_QAD */
+#define PCIE_CH0_DESC_QUEUE_SIZE	0xB0	/* CH0_QSZ */
+#define PCIE_CH0_DESC_QUEUE_NEW		0xB4	/* CH0_QNW */
+#define PCIE_CH0_DESC_QUEUE_COUNT	0xB8	/* CH0_QCN */
+#define PCIE_CH0_DESC_QUEUE_CURRENT	0xBC	/* CH0_QPT */
+
+#define PCIE_CH1_DMA_CTRL_CFG		0xC0	/* CH1_CTL */
+
+#define PCIE_CH1_DMA_INT_RAW_STATUS	0xC4	/* CH1_IRQ */
+#define PCIE_CH1_DMA_INT_ENABLE		0xC8	/* CH1_IE */
+#define PCIE_CH1_DMA_INT_DISABLE	0xCC	/* CH1_ID */
+#define PCIE_CH1_DMA_INT_MASK		0xD0	/* CH1_IM */
+#define PCIE_CH1_DMA_INT_TEST		0xD4	/* CH1_ITS */
+
+#define PCIE_PEX_CFG1			0xD8	/* PEX_CFG1 */
+#define PCIE_PEX_CFG2			0xDC	/* PEX_CFG2 */
+#define PCIE_PEX_CFG3			0xE0	/* PEX_CFG3 */
+
+#define PCIE_PEX_ERROR_STATUS		0xE4	/* PEX_ERR */
+#define PCIE_PEX_ERROR_MASK		0xE8	/* PEX_MSK */
+
+#define PCIE_BIST_CTRL_STATUS		0xEC	/* PCIE_BIST */
+
+#define PCIE_MEM_SENSE_AMP_ADJUST	0xF0	/* PCIE_SNS */
+
+/* PEX configuration registers */
+#define PCIE_PEX_IP_BASEADDR		0x1000
+
+#define PCIE_PEX_IP_COMMAND_STATUS	(PCIE_PEX_IP_BASEADDR + 0x04)
+#define PCIE_PEX_IP_BAR0		(PCIE_PEX_IP_BASEADDR + 0x10)
+#define PCIE_PEX_IP_BAR1		(PCIE_PEX_IP_BASEADDR + 0x14)
+#define PCIE_PEX_IP_BAR2		(PCIE_PEX_IP_BASEADDR + 0x18)
+#define PCIE_PEX_IP_BAR3		(PCIE_PEX_IP_BASEADDR + 0x1C)
+#define PCIE_PEX_IP_BAR4		(PCIE_PEX_IP_BASEADDR + 0x20)
+#define PCIE_PEX_IP_BAR5		(PCIE_PEX_IP_BASEADDR + 0x24)
+
+
+/* Indirect command registers */
+#define PCIE_CH0_DMA_REMOTE_ADDR_LOW	0x00	/* PCIE_CH0_ALO */
+#define PCIE_CH0_DMA_REMOTE_ADDR_HIGH	0x04	/* PCIE_CH0_AHI */
+#define PCIE_CH0_DMA_LOCAL_ADDR		0x08	/* PCIE_CH0_LA */
+#define PCIE_CH0_DMA_START		0x0C	/* PCIE_CH0_STR */
+#define PCIE_CH0_DMA_SIMPLE_WRITE	0x10	/* PCIE_CH0_SWD */
+#define PCIE_CH0_DMA_SIMPLE_READ	0x14	/* PCIE_CH0_SRD */
+#define PCIE_CH0_DMA_STATUS		0x18	/* PCIE_CH0_STS */
+
+#define PCIE_CH1_DMA_REMOTE_ADDR_LOW	0x20	/* PCIE_CH1_ALO */
+#define PCIE_CH1_DMA_REMOTE_ADDR_HIGH	0x24	/* PCIE_CH1_AHI */
+#define PCIE_CH1_DMA_LOCAL_ADDR		0x28	/* PCIE_CH1_LA */
+#define PCIE_CH1_DMA_START		0x2C	/* PCIE_CH1_STR */
+#define PCIE_CH1_DMA_SIMPLE_WRITE	0x30	/* PCIE_CH1_SWD */
+#define PCIE_CH1_DMA_SIMPLE_READ	0x34	/* PCIE_CH1_SRD */
+#define PCIE_CH1_DMA_STATUS		0x38	/* PCIE_CH1_STS */
+
+
+/* PCIe PHY registers */
+#define PCIE_PHY_PARALLEL_CR_CTRL_PORT_ADDR	0x00	/* CR_ADDR */
+#define PCIE_PHY_PARALLEL_CR_CTRL_PORT_DATA	0x04	/* CR_DATA */
+#define PCIE_PHY_POWER_GOOD_STATUS		0x08	/* PG_STS */
+#define PCIE_PHY_MPLL_CTRL			0x0C	/* MPLL_CTL */
+#define PCIE_PHY_TEST_CTRL			0x10	/* TEST_CTL */
+#define PCIE_PHY_TRANSMIT_LEVEL_CTRL		0x14	/* TX_LVL_CTL */
+#define PCIE_PHY_LANE0_TX_CTRL			0x18	/* TX0_CTL */
+#define PCIE_PHY_LANE1_TX_CTRL			0x1C	/* TX1_CTL */
+#define PCIE_PHY_LOS_LEVEL_CTRL			0x20	/* LOS_LVL_CTL */
+#define PCIE_PHY_LANE0_RX_CTRL			0x24	/* RX0_CTL */
+#define PCIE_PHY_LANE1_RX_CTRL			0x28	/* RX1_CTL */
+#define PCIE_PHY_TECHNOLOGY_CTRL		0x2C	/* TECH_CTL */
+#define PCIE_PHY_RESISTOR_TUNE_CTRL		0x30	/* RTUNE_CTL */
+#define PCIE_PHY_PCS_STATUS			0x34	/* PCS_STS */
+#define PCIE_PHY_PCS_CTRL			0x38	/* PCS_CTL */
+
+/***** Masks *****/
+
+/* PCIE_CTL bits */
+#define PCIE_CTL_ENDPOINT_MODE		(1 << 0)
+#define PCIE_CTL_RW1C			(1 << 1)
+#define PCIE_CTL_CFG_READY		(1 << 2)
+
+/* PCIE_IRQ bits */
+#define PCIE_IRQ_POWER_MANAGEMENT	(1 << 0)
+#define PCIE_IRQ_TL_ERROR		(1 << 1)
+#define PCIE_IRQ_PEX_REJECT		(1 << 2)
+#define PCIE_IRQ_TX_REQUEST_ERROR	(1 << 3)
+#define PCIE_IRQ_DMA_CH0		(1 << 6)
+#define PCIE_IRQ_DMA_CH1		(1 << 7)
+#define PCIE_IRQ_VC0_LINK_UP		(1 << 8)
+#define PCIE_IRQ_VC0_LINK_DOWN		(1 << 9)
+
+#define PCIE_IRQ_ALL			(PCIE_IRQ_POWER_MANAGEMENT | PCIE_IRQ_TL_ERROR | PCIE_IRQ_PEX_REJECT | \
+					PCIE_IRQ_TX_REQUEST_ERROR | PCIE_IRQ_DMA_CH0 | PCIE_IRQ_DMA_CH1 | \
+					PCIE_IRQ_VC0_LINK_UP | PCIE_IRQ_VC0_LINK_DOWN)
+
+
+/* US_IRQ bits */
+#define US_IRQ_MSI0			(1 << 0)
+#define US_IRQ_MSI1			(1 << 1)
+#define US_IRQ_MSI2			(1 << 2)
+#define US_IRQ_MSI3			(1 << 3)
+#define US_IRQ_INTA			(1 << 4)
+#define US_IRQ_INTB			(1 << 5)
+#define US_IRQ_INTC			(1 << 6)
+#define US_IRQ_INTD			(1 << 7)
+
+#define US_IRQ_ALL			(US_IRQ_MSI1 | US_IRQ_MSI2 | US_IRQ_MSI3 | US_IRQ_MSI4 | \
+					US_IRQ_INTA | US_IRQ_INTB | US_IRQ_INTC | US_IRQ_INTD)
+
+/* DMA_CTL bits */
+#define PCIE_DMA_CTL_REQUESTER_ENABLE	(1 << 0)
+#define PCIE_DMA_CTL_COMPLETER_ENABLE	(1 << 1)
+#define PCIE_DMA_CTL_AHB64BIT_OVERWRITE	(1 << 7)
+#define PCIE_DMA_CTL_AHB_EARLY_BURST_TERMINATION	(1 << 8)
+
+/* BARn_MSK bits */
+#define BAR_MSK_PREFETCHABLE		(1 << 4)
+
+/* PEX_CFG1 bits */
+#define PCIE_PEX_CFG1_BAR_MATCH_ENABLE	(1U << 31)
+
+/* PEX_ERR bits */
+#define PCIE_PEX_ERR_LTSSM_STATE(v)	(((v) >> 24) & 0xff)
+
+/* PCIE_CHx_STR bits */
+#define PCIE_CH_DW_LENTGH(v)		(((v) & 0x3f) << 22)
+#define PCIE_CH_STR_START		(1 << 20)
+#define PCIE_CH_STR_LAST_ADDR_BE(v)	(((v) & 0xf) << 16)
+#define PCIE_CH_STR_FIRST_ADDR_BE(v)	(((v) & 0xf) << 12)
+#define PCIE_CH_STR_ATTR(v)		(((v) & 0x2) << 10)
+#define PCIE_CH_STR_TYPE(v)		(((v) & 0xf) << 5)
+#define PCIE_CH_STR_CLASS(v)		(((v) & 0x7) << 1)
+#define TYPE_MEM32		0x0
+#define TYPE_MEM64		0x1
+#define TYPE_MSG		0x2
+#define TYPE_CFG0		0x3
+#define TYPE_CFG1		0x4
+#define PCIE_CH_STR_DIR_WRITE		(1 << 4)
+#define PCIE_CH_STR_SIMPLE_MODE		(1 << 0)
+
+/* PCIE_CHx_STS bits */
+#define PCIE_CH_STS_DMA_REQ_STATUS_GET(v)	(((v) >> 11) & 0x7)
+#define PCIE_CH_STS_SIMPLE_REQ_STATUS_GET(v)	(((v) >> 1) & 0x7)
+#define PCIE_CH_STS_SIMPLE_REQ_BUSY		(1 << 0)
+
+/* CHx_CTL bits */
+#define PCIE_CH_CTL_BULK_MODE_ENABLE		(1 << 12)
+#define PCIE_CH_CTL_WEIGHT(v)			(((v) & 0xF) << 8)
+#define PCIE_CH_CTL_CMD_QUEUE_THRESHLD(v)	(((v) & 0x7) << 1)
+#define PCIE_CH_CTL_CMD_QUEUE_FLUSH		(1 << 0)
+
+/* TECH_CTL bits */
+#define PCIE_TECH_CTL_FAST_TECH		(1 << 2)
+#define PCIE_TECH_CTL_VP_IS_1P2		(1 << 1)
+#define PCIE_TECH_CTL_VPH_IS_3P3	(1 << 0)
+
+#ifndef __ASSEMBLY__
+
+#include <linux/types.h>
+
+struct pcie_desc {
+	u32 ctrl_status;
+	u32 local_addr;
+	u32 remote_addr_low;
+	u32 remote_addr_high;
+};
+#endif
+
+#define PCIE_DESC_HOST_OWNED			(1 << 0)
+#define PCIE_DESC_PKT_TRAFFIC_CLASS(v)		(((v) & 0x7) << 1)
+#define PCIE_DESC_WRITE				(1 << 4)
+#define PCIE_DESC_64BIT				(1 << 5)
+#define PCIE_DESC_PKT_ATTRIBUTES(v)		(((v) & 0x7) << 10)
+#define PCIE_DESC_ERROR				(1 << 12)
+#define PCIE_DESC_STATUS_GET(v)			(((v) >> 13) & 0x7)
+#define PCIE_DESC_LENGTH(v)			(((v) & 0xFFF) << 20)
+
+#endif /* __COMCERTO_PCIE_H__ */
diff --git a/arch/arm/mach-comcerto/include/mach/io.h b/arch/arm/mach-comcerto/include/mach/io.h
index be3320f..3e010c8 100644
--- a/arch/arm/mach-comcerto/include/mach/io.h
+++ b/arch/arm/mach-comcerto/include/mach/io.h
@@ -17,16 +17,9 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
  */
-#ifndef __ASM_ARCH_COMCERTO1000_IO_H
-#define __ASM_ARCH_COMCERTO1000_IO_H
+#ifndef __ASM_ARCH_COMCERTO_IO_H
+#define __ASM_ARCH_COMCERTO_IO_H
 
-#include <asm/io.h>
-
-#if !defined(CONFIG_PCI)
-
-#define __io(a)		((void __iomem *)(a))
-#define __mem_pci(a)	(a)
-
-#endif
+#include <mach/comcerto-1000/io.h>
 
 #endif /* __ASM_ARCH_COMCERTO1000_IO_H */
diff --git a/arch/arm/mach-comcerto/pcie-c1000.c b/arch/arm/mach-comcerto/pcie-c1000.c
new file mode 100644
index 0000000..5b40537
--- /dev/null
+++ b/arch/arm/mach-comcerto/pcie-c1000.c
@@ -0,0 +1,1257 @@
+/*
+ *  linux/arch/arm/mach-comcerto/pci-comcerto100.c
+ *
+ *  Copyright (C) 2004,2005 Mindspeed Technologies, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/init.h>
+#include <linux/pci.h>
+#include <linux/spinlock.h>
+#include <linux/module.h>
+#include <linux/interrupt.h>
+#include <linux/slab.h>
+#include <linux/delay.h>
+#if defined(CONFIG_PCI_MSI)
+#include <linux/msi.h>
+#endif
+
+#include <asm/irq.h>
+#include <asm/delay.h>
+#include <asm/sizes.h>
+#include <asm/mach/pci.h>
+#include <mach/irq.h>
+
+#include "pcie-c1000.h"
+
+#include <linux/platform_device.h>
+
+static struct pcie pcie;
+
+/*
+ * If we set up a device for bus mastering, we need to check the latency
+ * timer as certain crappy BIOSes forget to set it properly.
+ */
+unsigned int pcibios_max_latency = 255;
+
+void pcibios_set_master(struct pci_dev *dev)
+{
+	u8 lat;
+	pci_read_config_byte(dev, PCI_LATENCY_TIMER, &lat);
+	if (lat < 16)
+		lat = (64 <= pcibios_max_latency) ? 64 : pcibios_max_latency;
+	else if (lat > pcibios_max_latency)
+		lat = pcibios_max_latency;
+	else
+		return;
+	printk(KERN_DEBUG "PCI: Setting latency timer of device %s to %d\n",
+		pci_name(dev), lat);
+	pci_write_config_byte(dev, PCI_LATENCY_TIMER, lat);
+}
+
+
+int pcie_bulk_mode_read(struct pcie_ctrl *ctrl, void *to, u64 from, int size)
+{
+	struct pcie_bulk_ctrl *bulk = &ctrl->bulk;
+	struct pcie_desc *desc;
+	int offset = 0, size_now;
+	dma_addr_t handle;
+	unsigned long flags;
+
+	spin_lock_irqsave(&ctrl->lock, flags);
+
+	/* FIXME we should check if there is enough space
+	 * to queue new requests */
+
+	while (size > 0) {
+		desc = ((struct pcie_desc *)bulk->qbaseaddr) + bulk->cur;
+
+		size_now = (size < SZ_4K) ? size : SZ_4K;
+
+		handle = dma_map_single(NULL, (u8 *)to + offset, size_now, \
+							DMA_FROM_DEVICE);
+
+		bulk->handles[bulk->cur] = handle;
+
+		desc->local_addr = cpu_to_le32(handle);
+		desc->remote_addr_low = (u32)(cpu_to_le64(from + offset) & 0xffffffff);
+		desc->remote_addr_high = (u32)(cpu_to_le64(from + offset) >> 32);
+		desc->ctrl_status = PCIE_DESC_LENGTH(size_now) | PCIE_DESC_64BIT;
+
+		bulk->cur++;
+		if (bulk->cur >= bulk->size)
+			bulk->cur = 0;
+
+		writel(1, ctrl->baseaddr + PCIE_CH0_DESC_QUEUE_NEW);
+		size -= SZ_4K;
+		offset += SZ_4K;
+	}
+
+	spin_unlock_irqrestore(&ctrl->lock, flags);
+
+	return 0;
+}
+
+int pcie_bulk_mode_write(struct pcie_ctrl *ctrl, void *from, u64 to, int size)
+{
+	struct pcie_bulk_ctrl *bulk = &ctrl->bulk;
+	struct pcie_desc *desc;
+	int offset = 0, size_now;
+	dma_addr_t handle;
+	unsigned long flags;
+
+	spin_lock_irqsave(&ctrl->lock, flags);
+
+	while (size > 0) {
+		desc = ((struct pcie_desc *)bulk->qbaseaddr) + bulk->cur;
+
+		size_now = (size < SZ_4K) ? size : SZ_4K;
+
+		handle = dma_map_single(NULL, from + offset, size_now, DMA_TO_DEVICE);
+
+		bulk->handles[bulk->cur] = handle;
+
+		desc->local_addr = cpu_to_le32(handle);
+		desc->remote_addr_low = (u32)(cpu_to_le64(to + offset) & 0xffffffff);
+		desc->remote_addr_high = (u32)(cpu_to_le64(to + offset) >> 32);
+		desc->ctrl_status = PCIE_DESC_LENGTH(size_now) | PCIE_DESC_WRITE | PCIE_DESC_64BIT;
+
+		bulk->cur++;
+		if (bulk->cur >= bulk->size)
+			bulk->cur = 0;
+
+		writel(1, ctrl->baseaddr + PCIE_CH0_DESC_QUEUE_NEW);
+		size -= SZ_4K;
+		offset += SZ_4K;
+	}
+
+	spin_unlock_irqrestore(&ctrl->lock, flags);
+
+	return 0;
+}
+
+static int pcie_bulk_mode_init(struct pcie_ctrl *ctrl, int size)
+{
+	struct pcie_bulk_ctrl *bulk = &ctrl->bulk;
+
+	bulk->qbaseaddr = dma_alloc_coherent(NULL, size * sizeof(struct pcie_desc), &bulk->qhandle, GFP_KERNEL);
+	if (!bulk->qbaseaddr) {
+		printk(KERN_ERR "PCIe(%d): failed to allocate bulk mode queue\n", ctrl->index);
+		goto err0;
+	}
+
+	bulk->handles = kmalloc(size * sizeof(dma_addr_t), GFP_KERNEL);
+	if (!bulk->handles) {
+		printk(KERN_ERR "PCIe(%d): failed to allocate bulk mode handle queue\n", ctrl->index);
+		goto err1;
+	}
+	memset(bulk->handles, 0, size * sizeof(dma_addr_t));
+
+	bulk->cur = 0;
+	bulk->first = 0;
+	bulk->size = size;
+
+	writel(bulk->qhandle, ctrl->baseaddr + PCIE_CH0_DESC_QUEUE_ADDR);
+	writel(size, ctrl->baseaddr + PCIE_CH0_DESC_QUEUE_SIZE);
+	writel(PCIE_CH_CTL_BULK_MODE_ENABLE | PCIE_CH_CTL_WEIGHT(4) | PCIE_CH_CTL_CMD_QUEUE_FLUSH, ctrl->baseaddr + PCIE_CH0_DMA_CTRL_CFG);
+
+	/* FIXME enable interrupts */
+
+	return 0;
+
+err1:
+	dma_free_coherent(NULL, size * sizeof(struct pcie_desc), bulk->qbaseaddr, bulk->qhandle);
+
+err0:
+	return -1;
+}
+
+static void pcie_bulk_mode_exit(struct pcie_ctrl *ctrl)
+{
+	struct pcie_bulk_ctrl *bulk = &ctrl->bulk;
+
+	/* FIXME disable interrupts */
+
+	writel(PCIE_CH_CTL_CMD_QUEUE_FLUSH, ctrl->baseaddr + PCIE_CH0_DMA_CTRL_CFG);
+
+	kfree(bulk->handles);
+
+	dma_free_coherent(NULL, bulk->size * sizeof(struct pcie_desc), bulk->qbaseaddr, bulk->qhandle);
+}
+
+static inline void pcie_direct_memory_mapped_cfg(struct pcie_ctrl *ctrl)
+{
+	/* PCIe mem offset */
+	writel(((u32) ctrl->remote_mem_baseaddr) & 0xf0000000, \
+			ctrl->indirect_baseaddr + PCIE_CH1_DMA_REMOTE_ADDR_LOW);
+	writel((u32) (ctrl->remote_mem_baseaddr >> 32), \
+			ctrl->indirect_baseaddr + PCIE_CH1_DMA_REMOTE_ADDR_HIGH);
+
+	/* FIXME - When should we use 32bit/64bit? */
+	/* FIXME - What traffic class, attributes should be used? */
+	writel(PCIE_CH_STR_START |
+		PCIE_CH_STR_ATTR(0) |
+		PCIE_CH_STR_TYPE(TYPE_MEM32) |
+		PCIE_CH_STR_CLASS(0),
+		ctrl->indirect_baseaddr + PCIE_CH1_DMA_START);
+}
+
+static int pcie_indirect_simple_read_cfg(struct pcie_root_port *root_port, \
+		int bus, unsigned int devfn, int where, int size, u32 *val)
+{
+	struct pcie_ctrl *ctrl = root_port->ctrl;
+	unsigned long flags;
+	u32 status;
+	u8 byte_enables;
+	u8 offset = where & 0x3;
+	int rc = -1;
+
+	if (!ctrl->link_state)
+		goto out_nolock;
+
+	BUG_ON ((offset + size) > 4);
+
+	/* Filter device numbers, unless it's a type1 access */
+	if ((bus == root_port->busnr) && (PCI_SLOT(devfn) > 0))
+		goto out_nolock;
+
+	spin_lock_irqsave(&ctrl->lock, flags);
+
+	writel(((bus & 0xff) << 24) | ((devfn & 0xff) << 16) | (where & 0xffc),
+			ctrl->indirect_baseaddr + PCIE_CH1_DMA_REMOTE_ADDR_LOW);
+
+	writel(0, ctrl->indirect_baseaddr + PCIE_CH1_DMA_REMOTE_ADDR_HIGH);
+
+	byte_enables = ((1 << size) - 1) << offset;
+
+	/* For single DW transfer last addressed location byte enables must be 0x0 */
+	if (bus != root_port->busnr) {
+		writel(PCIE_CH_STR_START |
+			PCIE_CH_STR_LAST_ADDR_BE(0x0) | PCIE_CH_STR_FIRST_ADDR_BE(byte_enables) |
+			PCIE_CH_STR_ATTR(0) | PCIE_CH_STR_TYPE(TYPE_CFG1) |
+			PCIE_CH_STR_CLASS(0) | PCIE_CH_STR_SIMPLE_MODE, ctrl->indirect_baseaddr + PCIE_CH1_DMA_START);
+	} else {
+		writel(PCIE_CH_STR_START |
+			PCIE_CH_STR_LAST_ADDR_BE(0x0) | PCIE_CH_STR_FIRST_ADDR_BE(byte_enables) |
+			PCIE_CH_STR_ATTR(0) | PCIE_CH_STR_TYPE(TYPE_CFG0) |
+			PCIE_CH_STR_CLASS(0) | PCIE_CH_STR_SIMPLE_MODE, ctrl->indirect_baseaddr + PCIE_CH1_DMA_START);
+	}
+
+	while ((status = readl(ctrl->indirect_baseaddr + PCIE_CH1_DMA_STATUS)) & PCIE_CH_STS_SIMPLE_REQ_BUSY)
+		;
+
+	if (PCIE_CH_STS_SIMPLE_REQ_STATUS_GET(status)) {
+		printk(KERN_ERR "PCIe(%d): read config failed(%x) %x\n",
+				ctrl->index, status, PCIE_CH_STS_SIMPLE_REQ_STATUS_GET(status));
+		rc = -1;
+		goto out;
+	}
+
+	rc = 0;
+	*val = (readl(ctrl->indirect_baseaddr + PCIE_CH1_DMA_SIMPLE_READ) >> (8 * offset)) & ((1 << (8 * size)) - 1);
+
+out:
+	/* Put back initial configuration */
+	pcie_direct_memory_mapped_cfg(ctrl);
+
+	spin_unlock_irqrestore(&ctrl->lock, flags);
+
+out_nolock:
+	return rc;
+}
+
+
+static int pcie_indirect_simple_write_cfg(struct pcie_root_port *root_port,
+		int bus, unsigned int devfn, int where, int size, u32 val)
+{
+	struct pcie_ctrl *ctrl = root_port->ctrl;
+	unsigned long flags;
+	u32 status;
+	u8 byte_enables;
+	u8 offset = where & 0x3;
+	int rc = 0;
+
+	if (!ctrl->link_state)
+		goto err;
+
+	/* Filter device numbers, unless it's a type1 access */
+	if ((bus == root_port->busnr) && (PCI_SLOT(devfn) > 0))
+		goto err;
+
+	BUG_ON ((offset + size) > 4);
+
+	spin_lock_irqsave(&ctrl->lock, flags);
+
+	writel(((bus & 0xff) << 24) | ((devfn & 0xff) << 16) | (where & 0xffc),
+			ctrl->indirect_baseaddr + PCIE_CH1_DMA_REMOTE_ADDR_LOW);
+	writel(0, ctrl->indirect_baseaddr + PCIE_CH1_DMA_REMOTE_ADDR_HIGH);
+
+	byte_enables = ((1 << size) - 1) << offset;
+
+	writel(val << (8 * offset), ctrl->indirect_baseaddr + PCIE_CH1_DMA_SIMPLE_WRITE);
+
+	/* For single DW transfer last addressed location byte enables must be 0x0 */
+	if (bus != root_port->busnr)
+		writel(PCIE_CH_STR_START |
+			PCIE_CH_STR_LAST_ADDR_BE(0x0) | PCIE_CH_STR_FIRST_ADDR_BE(byte_enables) |
+			PCIE_CH_STR_ATTR(0) | PCIE_CH_STR_TYPE(TYPE_CFG1) |
+			PCIE_CH_STR_DIR_WRITE | PCIE_CH_STR_CLASS(0) | PCIE_CH_STR_SIMPLE_MODE,
+			ctrl->indirect_baseaddr + PCIE_CH1_DMA_START);
+	else
+		writel(PCIE_CH_STR_START |
+			PCIE_CH_STR_LAST_ADDR_BE(0x0) | PCIE_CH_STR_FIRST_ADDR_BE(byte_enables) |
+			PCIE_CH_STR_ATTR(0) | PCIE_CH_STR_TYPE(TYPE_CFG0) |
+			PCIE_CH_STR_DIR_WRITE | PCIE_CH_STR_CLASS(0) | PCIE_CH_STR_SIMPLE_MODE,
+			ctrl->indirect_baseaddr + PCIE_CH1_DMA_START);
+
+	while ((status = readl(ctrl->indirect_baseaddr + PCIE_CH1_DMA_STATUS)) & PCIE_CH_STS_SIMPLE_REQ_BUSY)
+		;
+
+	if (PCIE_CH_STS_SIMPLE_REQ_STATUS_GET(status)) {
+		printk(KERN_ERR "PCIe(%d): write config failed(%x)\n", ctrl->index, status);
+		rc = -1;
+	}
+
+	/* Put back initial configuration */
+	pcie_direct_memory_mapped_cfg(ctrl);
+
+	spin_unlock_irqrestore(&ctrl->lock, flags);
+
+	return rc;
+
+err:
+	return -1;
+}
+
+/**
+ * pcie1_read_config -
+ *
+ */
+static int pcie1_read_config(struct pci_bus *bus, unsigned int devfn, int where, int size, u32 *value)
+{
+	int rc;
+
+	rc = pcie_indirect_simple_read_cfg(&pcie.root_port[1], bus->number, devfn, where, size, value);
+
+	if (rc)
+		return PCIBIOS_DEVICE_NOT_FOUND;
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+
+/**
+ * pcie1_write_config -
+ *
+ */
+static int pcie1_write_config(struct pci_bus *bus, unsigned int devfn, int where, int size, u32 value)
+{
+	int rc;
+
+	rc = pcie_indirect_simple_write_cfg(&pcie.root_port[1], bus->number, devfn, where, size, value);
+	if (rc)
+		return PCIBIOS_DEVICE_NOT_FOUND;
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+
+static struct pci_ops pcie1_ops = {
+	.read = pcie1_read_config,
+	.write = pcie1_write_config,
+};
+
+/**
+ * pcie0_read_config -
+ *
+ */
+static int pcie0_read_config(struct pci_bus *bus, unsigned int devfn, int where, int size, u32 *value)
+{
+	int rc;
+
+	rc = pcie_indirect_simple_read_cfg(&pcie.root_port[0], bus->number, devfn, where, size, value);
+
+	if (rc)
+		return PCIBIOS_DEVICE_NOT_FOUND;
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+
+/**
+ * pcie0_write_config -
+ *
+ */
+static int pcie0_write_config(struct pci_bus *bus, unsigned int devfn, int where, int size, u32 value)
+{
+	int rc;
+
+	rc = pcie_indirect_simple_write_cfg(&pcie.root_port[0], bus->number, devfn, where, size, value);
+	if (rc)
+		return PCIBIOS_DEVICE_NOT_FOUND;
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+static struct pci_ops pcie0_ops = {
+	.read = pcie0_read_config,
+	.write = pcie0_write_config,
+};
+
+
+static int pcie_direct_memory_mapped_init(struct pcie_ctrl *ctrl)
+{
+	writel(0x7ff, ctrl->baseaddr + PCIE_CH1_DMA_INT_DISABLE);
+	writel(PCIE_CH_CTL_WEIGHT(4) | PCIE_CH_CTL_CMD_QUEUE_FLUSH, ctrl->baseaddr + PCIE_CH1_DMA_CTRL_CFG);
+
+	pcie_direct_memory_mapped_cfg(ctrl);
+
+	return 0;
+}
+
+static int pcie_requester_dma_init(struct pcie_ctrl *ctrl)
+{
+	pcie_direct_memory_mapped_init(ctrl);
+
+	pcie_bulk_mode_init(ctrl, PCIE_BULK_MODE_QUEUE_SIZE);
+
+	writel(readl(ctrl->baseaddr + PCIE_DMA_CTRL_CFG) | PCIE_DMA_CTL_REQUESTER_ENABLE, ctrl->baseaddr + PCIE_DMA_CTRL_CFG);
+
+	return 0;
+}
+
+static int pcie_configuration_space_init(struct pcie_ctrl *ctrl)
+{
+	u32 tmp;
+	int i;
+
+	if (!ctrl->is_endpoint) {
+		/* Type 1 configuration header */
+
+		/* Enable memory IO and bus master */
+		tmp = readl(ctrl->baseaddr + PCIE_PEX_IP_COMMAND_STATUS);
+		tmp |= PCI_COMMAND_MASTER | PCI_COMMAND_MEMORY;
+		writel(tmp, ctrl->baseaddr + PCIE_PEX_IP_COMMAND_STATUS);
+
+		writel(COMCERTO_AHB_DDR_BASE, ctrl->baseaddr + PCIE_PEX_IP_BAR0);
+		writel(0x0, ctrl->baseaddr + PCIE_PEX_IP_BAR1);
+	} else {
+		/* Type 0 configuration header */
+
+		/* BARS are 64bit */
+		writel(COMCERTO_AHB_DDR_BASE, ctrl->baseaddr + PCIE_PEX_IP_BAR0);
+		writel(0x0, ctrl->baseaddr + PCIE_PEX_IP_BAR1);
+
+		writel(COMCERTO_AHB_ARAM_BASE, ctrl->baseaddr + PCIE_PEX_IP_BAR2);
+		writel(0x00000000, ctrl->baseaddr + PCIE_PEX_IP_BAR3);
+
+		writel(0x00000000, ctrl->baseaddr + PCIE_PEX_IP_BAR4);
+		writel(0x00000000, ctrl->baseaddr + PCIE_PEX_IP_BAR5);
+	}
+}
+
+static int pcie_completer_dma_init(struct pcie_ctrl *ctrl)
+{
+	u32 tmp;
+
+	if (!ctrl->is_endpoint) {
+		/* FIXME - only one BAR is setup in configuration space */
+		/* Use same addresses in AHB and PCIe domains */
+		writel(COMCERTO_AHB_DDR_BASE, ctrl->baseaddr + PCIE_BAR0_ADDR_OFFSET);
+		writel(COMCERTO_AHB_ARAM_BASE, ctrl->baseaddr + PCIE_BAR1_ADDR_OFFSET);
+		writel(0, ctrl->baseaddr + PCIE_BAR2_ADDR_OFFSET);
+
+		writel(BAR_MSK_PREFETCHABLE | 0xa, ctrl->baseaddr + PCIE_BAR0_SIZE);	/* DDR, 1GiB */
+		writel(BAR_MSK_PREFETCHABLE | 0x0, ctrl->baseaddr + PCIE_BAR1_SIZE);	/* ARAM, 1MiB */
+		writel(0, ctrl->baseaddr + PCIE_BAR2_SIZE);	/* Not used */
+
+		tmp = readl(ctrl->baseaddr + PCIE_PEX_CFG1);
+		writel(tmp | PCIE_PEX_CFG1_BAR_MATCH_ENABLE, ctrl->baseaddr + PCIE_PEX_CFG1);
+
+	} else {
+		/* FIXME - should match configuration space BAR's */
+		/* In simulation external host is expecting one 4GiB BAR to access DDR */
+		writel(0x00000000, ctrl->baseaddr + PCIE_BAR0_ADDR_OFFSET);
+		writel(BAR_MSK_PREFETCHABLE | 0xc, ctrl->baseaddr + PCIE_BAR0_SIZE); /* DDR, 4GiB */
+	}
+
+	tmp = readl(ctrl->baseaddr + PCIE_DMA_CTRL_CFG);
+	tmp &= ~PCIE_DMA_CTL_AHB64BIT_OVERWRITE;
+	tmp |= PCIE_DMA_CTL_COMPLETER_ENABLE | PCIE_DMA_CTL_AHB_EARLY_BURST_TERMINATION;
+	writel(tmp, ctrl->baseaddr + PCIE_DMA_CTRL_CFG);
+
+	return 0;
+}
+
+static struct pcie_root_port *pci_dev_to_root_port(struct pci_dev *dev)
+{
+	/* FIXME this assumes all buses in controller 0 and scanned
+		before those in controller 1 */
+	if ((pcie.max_root_ports > 1) && (dev->bus->number >= pcie.root_port[1].busnr))
+		return &pcie.root_port[1];
+
+	return &pcie.root_port[0];
+}
+
+static struct pcie_root_port *irq_to_root_port(unsigned int irq)
+{
+	struct irq_desc *desc = irq_desc + irq;
+
+	return desc->chip_data;
+}
+
+
+static inline int pcie_irqmask_to_irq(struct pcie_root_port *root_port, int irqmask)
+{
+	return root_port->soft_irq_base + irqmask;
+}
+
+
+static void pcie_irq_ext_hdlr(unsigned int irq, struct irq_desc *desc)
+{
+	struct pcie_root_port *root_port = desc->chip_data;
+	struct pcie_ctrl *ctrl = root_port->ctrl;
+	u32 status;
+	int i;
+
+	/* Interrupts from the PCIe block are all level interrupts, they should be acked in the INTC
+	 * only after handling the interrupt source (PCIe block and PCIe device) */
+
+	/* Virtual wire INTx interrupts, at the PCIe block level, follow the state of the interrupt source,
+	 * there is no need to ack/clear them */
+
+	/* MSI interrupts, at the PCIe block level, are event/edge interrupts that must be cleared/acked (PCIe block)
+	 before clearing/acking the source (PCIe device) */
+
+	comcerto_irq_mask_0(irq);
+
+	while ((status = (readl(ctrl->baseaddr + PCIE_UPST_INT_RAW_STATUS) & readl(ctrl->baseaddr + PCIE_UPST_INT_MASK)))) {
+
+		for (i = 0; i < 8; i++) {
+			if (status & (1UL << i)) {
+				desc = irq_desc + root_port->soft_irq_base + i;
+				desc->handle_irq(root_port->soft_irq_base + i, desc);
+			}
+		}
+	}
+
+	comcerto_irq_ack_0(irq);
+	comcerto_irq_unmask_0(irq);
+}
+
+#if defined(CONFIG_PCI_MSI)
+void arch_teardown_msi_irq(unsigned int irq)
+{
+	struct pcie_root_port *root_port = irq_to_root_port(irq);
+
+	dynamic_irq_cleanup(irq);
+
+	clear_bit(irq - root_port->soft_irq_base, root_port->msi_irq_in_use);
+}
+
+static void pcie_ack_msi_irq(unsigned int irq)
+{
+	struct pcie_root_port *root_port = irq_to_root_port(irq);
+	struct pcie_ctrl *ctrl = root_port->ctrl;
+
+	writel(1 << (irq - root_port->soft_irq_base), ctrl->baseaddr + PCIE_UPST_INT_RAW_STATUS);
+}
+
+static void pcie_unmask_msi_irq(unsigned int irq)
+{
+	struct pcie_root_port *root_port = irq_to_root_port(irq);
+	struct pcie_ctrl *ctrl = root_port->ctrl;
+
+	writel(1 << (irq - root_port->soft_irq_base), ctrl->baseaddr + PCIE_UPST_INT_ENABLE);
+}
+
+static void pcie_mask_msi_irq(unsigned int irq)
+{
+	struct pcie_root_port *root_port = irq_to_root_port(irq);
+	struct pcie_ctrl *ctrl = root_port->ctrl;
+
+	writel(1 << (irq - root_port->soft_irq_base), ctrl->baseaddr + PCIE_UPST_INT_DISABLE);
+}
+
+static struct irq_chip pcie_msi_chip = {
+	.name = "PCIe MSI",
+	.ack = pcie_ack_msi_irq,
+	.enable = pcie_unmask_msi_irq,
+	.disable = pcie_mask_msi_irq,
+	.mask = pcie_mask_msi_irq,
+	.unmask = pcie_unmask_msi_irq,
+};
+
+int arch_setup_msi_irq(struct pci_dev *dev, struct msi_desc *desc)
+{
+	struct pcie_root_port *root_port = pci_dev_to_root_port(dev);
+	struct msi_msg msg;
+	int pos, irq;
+
+	/* There are 4 possible interrupts, each mapped to a different MSIx channel */
+find:
+	pos = find_first_zero_bit(root_port->msi_irq_in_use, 4);
+	if (pos >= 4)
+		goto err;
+
+	if (test_and_set_bit(pos, root_port->msi_irq_in_use))
+		goto find;
+
+	irq = root_port->soft_irq_base + pos;
+
+	dynamic_irq_init(irq);
+
+	set_irq_msi(irq, desc);
+
+	msg.address_hi = 0x0;
+	msg.address_lo = root_port->msi_mbox_handle + (irq - root_port->soft_irq_base) * sizeof(u32);
+
+	msg.data = 0x0;
+
+	write_msi_msg(irq, &msg);
+	set_irq_chip_data(irq, root_port);
+	set_irq_chip_and_handler(irq, &pcie_msi_chip, handle_edge_irq);
+	set_irq_flags(irq, IRQF_VALID);
+
+	return irq;
+
+err:
+	return -1;
+}
+
+static int pcie_root_port_msi_init(struct pcie_root_port *root_port)
+{
+	struct pcie_ctrl *ctrl = root_port->ctrl;
+
+	root_port->msi_mbox_baseaddr = dma_alloc_coherent(NULL, 4 * sizeof(u32), &root_port->msi_mbox_handle, GFP_KERNEL);
+	if (!root_port->msi_mbox_baseaddr) {
+		printk(KERN_ERR "PCIe(%d): failed to allocate msi mailbox coherent memory\n", ctrl->index);
+		goto err;
+	}
+
+	writel(root_port->msi_mbox_handle, ctrl->baseaddr + PCIE_MSI_CH0_ADDR);
+	writel(root_port->msi_mbox_handle + sizeof(u32), ctrl->baseaddr + PCIE_MSI_CH1_ADDR);
+	writel(root_port->msi_mbox_handle + 2 * sizeof(u32), ctrl->baseaddr + PCIE_MSI_CH2_ADDR);
+	writel(root_port->msi_mbox_handle + 3 * sizeof(u32), ctrl->baseaddr + PCIE_MSI_CH3_ADDR);
+
+	writel(US_IRQ_MSI0 | US_IRQ_MSI1 | US_IRQ_MSI2 | US_IRQ_MSI3, ctrl->baseaddr + PCIE_UPST_INT_DISABLE);
+
+	return 0;
+
+err:
+	return -1;
+}
+#endif
+
+static void pcie_nop_intx_irq(unsigned int irq)
+{
+	return;
+}
+
+static void pcie_unmask_intx_irq(unsigned int irq)
+{
+	struct pcie_root_port *root_port = irq_to_root_port(irq);
+	struct pcie_ctrl *ctrl = root_port->ctrl;
+
+	writel(1 << (irq - root_port->soft_irq_base), ctrl->baseaddr + PCIE_UPST_INT_ENABLE);
+}
+
+static void pcie_mask_intx_irq(unsigned int irq)
+{
+	struct pcie_root_port *root_port = irq_to_root_port(irq);
+	struct pcie_ctrl *ctrl = root_port->ctrl;
+
+	writel(1 << (irq - root_port->soft_irq_base), ctrl->baseaddr + PCIE_UPST_INT_DISABLE);
+}
+
+
+static struct irq_chip pcie_intx_chip = {
+	.name = "PCIe INTx",
+	.ack = pcie_nop_intx_irq,
+	.enable = pcie_unmask_intx_irq,
+	.disable = pcie_mask_intx_irq,
+	.mask = pcie_mask_intx_irq,
+	.unmask = pcie_unmask_intx_irq,
+};
+
+static int pcie_root_port_intx_init(struct pcie_root_port *root_port)
+{
+	struct pcie_ctrl *ctrl = root_port->ctrl;
+
+	int i, irq;
+
+	writel(US_IRQ_INTA | US_IRQ_INTB | US_IRQ_INTC | US_IRQ_INTD, ctrl->baseaddr + PCIE_UPST_INT_DISABLE);
+
+	for (i = 0; i < 4; i++) {
+		irq = root_port->soft_irq_base + 4 + i;
+		set_irq_chip_data(irq, root_port);
+		set_irq_chip_and_handler(irq, &pcie_intx_chip, handle_level_irq);
+		set_irq_flags(irq, IRQF_VALID);
+	}
+
+	set_irq_chip_data(root_port->irq_ext, root_port);
+	set_irq_chained_handler(root_port->irq_ext, pcie_irq_ext_hdlr);
+
+	return 0;
+}
+
+static int pcie_root_port_irq_ext_init(struct pcie_root_port *root_port)
+{
+#if defined(CONFIG_PCI_MSI)
+	pcie_root_port_msi_init(root_port);
+#endif
+
+	pcie_root_port_intx_init(root_port);
+
+	return 0;
+}
+
+
+static void pcie_irq_int_hdlr(unsigned int irq, struct irq_desc *desc)
+{
+	struct pcie_ctrl *ctrl = desc->chip_data;
+	u32 status = readl(ctrl->baseaddr + PCIE_INT_RAW_STATUS) & readl(ctrl->baseaddr + PCIE_INT_ROUTING_CPU_MASK);
+
+	comcerto_irq_mask_0(irq);
+
+	if (status & PCIE_IRQ_VC0_LINK_DOWN)
+		ctrl->link_state = 0;
+
+	if (status & PCIE_IRQ_VC0_LINK_UP)
+		ctrl->link_state = 1;
+
+	if (status & PCIE_IRQ_TL_ERROR)
+		ctrl->tl_error++;
+
+	if (status & PCIE_IRQ_PEX_REJECT)
+		ctrl->pex_reject++;
+
+	if (status & PCIE_IRQ_TX_REQUEST_ERROR)
+		ctrl->tx_request_error++;
+
+	writel(status, ctrl->baseaddr + PCIE_INT_RAW_STATUS);
+
+	comcerto_irq_ack_0(irq);
+	comcerto_irq_unmask_0(irq);
+}
+
+static int pcie_irq_int_init(struct pcie_ctrl *ctrl)
+{
+	writel(PCIE_IRQ_TL_ERROR | PCIE_IRQ_PEX_REJECT |
+		PCIE_IRQ_TX_REQUEST_ERROR | PCIE_IRQ_VC0_LINK_UP | PCIE_IRQ_VC0_LINK_DOWN, ctrl->baseaddr + PCIE_INT_ROUTING_CPU_ENABLE);
+
+	writel(PCIE_IRQ_POWER_MANAGEMENT | PCIE_IRQ_DMA_CH1 | PCIE_IRQ_DMA_CH0, ctrl->baseaddr + PCIE_INT_ROUTING_CPU_DISABLE);
+
+	writel(PCIE_IRQ_ALL, ctrl->baseaddr + PCIE_INT_ROUTING_MSI1_DISABLE);
+	writel(PCIE_IRQ_ALL, ctrl->baseaddr + PCIE_INT_ROUTING_MSI2_DISABLE);
+	writel(PCIE_IRQ_ALL, ctrl->baseaddr + PCIE_INT_ROUTING_MSI3_DISABLE);
+	writel(PCIE_IRQ_ALL, ctrl->baseaddr + PCIE_INT_ROUTING_MSI4_DISABLE);
+
+	set_irq_chip_data(ctrl->irq_int, ctrl);
+	set_irq_chained_handler(ctrl->irq_int, pcie_irq_int_hdlr);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static struct platform_device pcie_pwr0 = {
+	.name = "pcie",
+	.id = 0,
+};
+
+static struct platform_device pcie_pwr1 = {
+	.name = "pcie",
+	.id = 1,
+};
+#endif
+
+static int pcie_ctrl_init(int n)
+{
+	struct pcie_ctrl *ctrl;
+	u32 tmp, ret;
+	volatile int timeout;
+
+	ctrl = &pcie.ctrl[n];
+
+	ctrl->index = n;
+
+	switch (n) {
+	default:
+	case 0:
+		ctrl->baseaddr = (void *)APB_VADDR(COMCERTO_APB_PCIe0_BASE);
+		ctrl->indirect_baseaddr = (void *)COMCERTO_PCIe0CMD_VADDR_BASE;
+		ctrl->remote_mem_baseaddr = COMCERTO_AHB_PCIe0_BASE;
+		ctrl->irq_int = IRQ_PCIe0_INT;
+		break;
+
+	case 1:
+		ctrl->baseaddr = (void *)APB_VADDR(COMCERTO_APB_PCIe1_BASE);
+		ctrl->indirect_baseaddr = (void *)COMCERTO_PCIe1CMD_VADDR_BASE;
+		ctrl->remote_mem_baseaddr = COMCERTO_AHB_PCIe1_BASE;
+		ctrl->irq_int = IRQ_PCIe1_INT;
+		break;
+	}
+
+	spin_lock_init(&ctrl->lock);
+
+	/* Retrieve mode and clear bits */
+	tmp = readl(ctrl->baseaddr + PCIE_SUBSYS_CTRL);
+	if (tmp & PCIE_CTL_ENDPOINT_MODE) {
+		ctrl->is_endpoint = 1;
+
+		ctrl->endpoint = &pcie.endpoint[pcie.max_endpoints];
+		ctrl->endpoint->ctrl = ctrl;
+
+		pcie.max_endpoints++;
+	} else {
+		ctrl->is_endpoint = 0;
+
+		ctrl->root_port = &pcie.root_port[pcie.max_root_ports];
+		ctrl->root_port->ctrl = ctrl;
+
+		pcie.max_root_ports++;
+
+		switch (n) {
+		default:
+		case 0:
+			ctrl->root_port->irq_ext = IRQ_PCIe0_EXT;
+			ctrl->root_port->soft_irq_base = IRQ_PCIE0_MSI0;
+#ifdef CONFIG_PM
+			ret = platform_device_register(&pcie_pwr0);
+#endif
+			break;
+		case 1:
+			ctrl->root_port->irq_ext = IRQ_PCIe1_EXT;
+			ctrl->root_port->soft_irq_base = IRQ_PCIE1_MSI0;
+#ifdef CONFIG_PM
+			ret = platform_device_register(&pcie_pwr1);
+#endif
+			break;
+		}
+	}
+
+	writel(tmp | PCIE_CTL_RW1C, ctrl->baseaddr + PCIE_SUBSYS_CTRL);
+
+	/* configure Root Port ID */
+	if (!ctrl->is_endpoint)
+		writel(0x0000, ctrl->baseaddr + PCIE_PEX_CFG3);
+
+	pcie_configuration_space_init(ctrl);
+	pcie_completer_dma_init(ctrl);
+	pcie_requester_dma_init(ctrl);
+
+	pcie_irq_int_init(ctrl);
+
+	if (!ctrl->is_endpoint)
+		pcie_root_port_irq_ext_init(ctrl->root_port);
+
+	if (ctrl->is_endpoint)
+		writel(readl(ctrl->baseaddr + PCIE_SUBSYS_CTRL) | PCIE_CTL_CFG_READY, ctrl->baseaddr + PCIE_SUBSYS_CTRL);
+
+	if (!ctrl->is_endpoint) {
+		/* Wait for VC0 up before continuing, otherwise probing of the bus will fail */
+		/* Also, it's possible that no device is present on the link */
+		/* Check if LTSSM state is at least in Polling.x, otherwise exit */
+		timeout = 12;
+		do {
+			mdelay(1);
+			if (--timeout <= 0) {
+				printk(KERN_INFO "PCIe%d: no device detected on link (%x)\n", ctrl->index, PCIE_PEX_ERR_LTSSM_STATE(readl(ctrl->baseaddr + PCIE_PEX_ERROR_STATUS)));
+				goto out;
+			}
+
+		} while (PCIE_PEX_ERR_LTSSM_STATE(readl(ctrl->baseaddr + PCIE_PEX_ERROR_STATUS)) < 0x11);
+
+		/* If so, wait for VC0 up interrupt */
+		timeout = 100;
+		do {
+			mdelay(1);
+			if (--timeout <= 0) {
+				printk(KERN_INFO "PCIe%d: timeout waiting for VC0 up\n", ctrl->index);
+				goto out;
+			}
+		} while (!(((volatile struct pcie_ctrl *)ctrl)->link_state));
+	}
+out:
+	return 0;
+}
+
+static inline u16 pcie_phy_reg_read(u16 addr)
+{
+	writel(addr, pcie.phy_baseaddr + PCIE_PHY_PARALLEL_CR_CTRL_PORT_ADDR);
+	return (u16)(readl(pcie.phy_baseaddr + PCIE_PHY_PARALLEL_CR_CTRL_PORT_DATA) & 0xffff);
+}
+
+static inline void pcie_phy_reg_write(u16 val, u16 addr)
+{
+	writel(addr, pcie.phy_baseaddr + PCIE_PHY_PARALLEL_CR_CTRL_PORT_ADDR);
+	writel(val, pcie.phy_baseaddr + PCIE_PHY_PARALLEL_CR_CTRL_PORT_DATA);
+}
+
+static void pcie_phy_set_loopback(u16 lane)
+{
+	u16 val;
+
+	lane &= 0x1;
+
+	/* Set Tx loopback */
+	val = pcie_phy_reg_read(0x2036 | (lane << 8));
+	val |= (1 << 0);
+	pcie_phy_reg_write(val, 0x2036 | (lane << 8));
+
+	printk("lane%d.tx_ana.atbsel2 %x\n", lane, pcie_phy_reg_read(0x2036 | (lane << 8)));
+
+	/* Set Rx loopback */
+	val = pcie_phy_reg_read(0x2030 | (lane << 8));
+	val |= (1 << 4);
+	pcie_phy_reg_write(val, 0x2030 | (lane << 8));
+
+	printk("lane%d.rx_ana.ctrl %x\n", lane, pcie_phy_reg_read(0x2030 | (lane << 8)));
+
+	/* Disable los */
+	val = pcie_phy_reg_read(0x2002 | (lane << 8));
+	val &= ~(0x3 << 12);
+	pcie_phy_reg_write(val | (1 << 14), 0x2005 | (lane << 8));
+
+	printk("lane%d.rx_ovrd %x\n", lane, pcie_phy_reg_read(0x2005 | (lane << 8)));
+}
+
+static void pcie_phy_reg_dump(void)
+{
+	u16 val;
+
+	printk("clock.rtune_ctl %x\n", pcie_phy_reg_read(0x9));
+
+	val = pcie_phy_reg_read(0xe);
+	printk("clock.freq_stat(%x) prop_ctl(%x) int_ctl(%x) ncy5(%x) ncy(%x) prescale(%x)\n",
+			val, (val & 0x7), (val >> 3) & 0x7, (val >> 6) & 0x3, (val >> 8) & 0x1f, (val >> 13) & 0x3);
+
+	val = pcie_phy_reg_read(0xf);
+	printk("clock.ctl_stat(%x) use_refclk_dat(%x) mpll_clk_off(%x) mpll_pwron(%x) mpll_ss_en(%x) cko_alive_con(%x) cko_word_con(%x) rtune_to_tune(%x) wide_xface(%x) vph_is_3p3(%x) vp_is_1p2(%x) fast_tech(%x)\n",
+			val, val & 0x1, (val >> 1) & 0x1, (val >> 2) & 0x1, (val >> 3) & 0x1, (val >> 4) & 0x3,
+			(val >> 6) & 0x7, (val >> 10) & 0x1, (val >> 11) & 0x1, (val >> 12) & 0x1, (val >> 13) & 0x1,
+			(val >> 14) & 0x1);
+
+	printk("clock.lvl_stat %x\n", pcie_phy_reg_read(0x10));
+	printk("clock.ctl_ovrd %x\n", pcie_phy_reg_read(0x13));
+	printk("clock.lvl_ovrd %x\n", pcie_phy_reg_read(0x14));
+	printk("clock.creg_ovrd %x\n", pcie_phy_reg_read(0x15));
+	printk("clock.mpll_ctl %x\n", pcie_phy_reg_read(0x16));
+	printk("clock.mpll_tst %x\n", pcie_phy_reg_read(0x17));
+
+	val = pcie_phy_reg_read(0x2001);
+	printk("lane0.tx_stat(%x) tx_cko_en(%x) tx_en(%x) tx_clk_align(%x) tx_boost(%x) tx_atten(%x) tx_edgerate(%x)\n",
+				val, val & 0x1, (val >> 1) & 0x7, (val >> 4) & 0x1,
+				(val >> 6) & 0xf, (val >> 10) & 0x7, (val >> 13) & 0x3);
+
+	val = pcie_phy_reg_read(0x2101);
+	printk("lane1.tx_stat(%x) tx_cko_en(%x) tx_en(%x) tx_clk_align(%x) tx_boost(%x) tx_atten(%x) tx_edgerate(%x)\n",
+				val, val & 0x1, (val >> 1) & 0x7, (val >> 4) & 0x1,
+				(val >> 6) & 0xf, (val >> 10) & 0x7, (val >> 13) & 0x3);
+
+	val = pcie_phy_reg_read(0x2002);
+	printk("lane0.rx_stat(%x) half_rate(%x) rx_pll_pwron(%x) rx_en(%x) rx_align_en(%x) rx_term_en(%x) rx_equal_val(%x) rx_dpll_mode(%x) dpll_reset(%x) los_ctl(%x)\n",
+			val, val & 0x1, (val >> 1) & 0x1, (val >> 2) & 0x1,
+			(val >> 3) & 0x1, (val >> 4) & 0x1, (val >> 5) & 0x7, (val >> 8) & 0x7, (val >> 11) & 0x1,
+			(val >> 12) & 0x3);
+
+	val = pcie_phy_reg_read(0x2102);
+	printk("lane1.rx_stat(%x) half_rate(%x) rx_pll_pwron(%x) rx_en(%x) rx_align_en(%x) rx_term_en(%x) rx_equal_val(%x) rx_dpll_mode(%x) dpll_reset(%x) los_ctl(%x)\n",
+			val, val & 0x1, (val >> 1) & 0x1, (val >> 2) & 0x1,
+			(val >> 3) & 0x1, (val >> 4) & 0x1, (val >> 5) & 0x7, (val >> 8) & 0x7, (val >> 11) & 0x1,
+			(val >> 12) & 0x3);
+
+	val = pcie_phy_reg_read(0x2003);
+	printk("lane0.out_stat(%x) rx_valid(%x) rx_pll_state(%x) los(%x) tx_done(%x) tx_rxpres(%x)\n",
+			val, val & 0x1, (val >> 1) & 0x1, (val >> 2) & 0x1,
+			(val >> 3) & 0x1, (val >> 4) & 0x1);
+
+	val = pcie_phy_reg_read(0x2103);
+	printk("lane1.out_stat(%x) rx_valid(%x) rx_pll_state(%x) los(%x) tx_done(%x) tx_rxpres(%x)\n",
+			val, val & 0x1, (val >> 1) & 0x1, (val >> 2) & 0x1,
+			(val >> 3) & 0x1, (val >> 4) & 0x1);
+}
+
+static int pcie_phy_init(int ext_clk)
+{
+	u32 ncy;
+	u32 ncy5;
+	u32 prescale;
+
+	/* Default values */
+	u32 tx_level = 0xa & 0x1f;
+	u32 tx_boost = 0xb & 0xf;
+	u32 tx_atten = 0x0 & 0x7;
+	u32 tx_edge_rate = 0x0 & 0x3;
+	u32 tx_clk_align = 0x0 & 0x1;
+
+	u32 los_lvl = 0x11 & 0x1f;
+
+	u32 rx_equal_val = 0x2 & 0x7;
+
+	pcie.phy_baseaddr = (void *) APB_VADDR(COMCERTO_APB_PCIePHY_BASE);
+
+	if (ext_clk) {
+		/* Baud rate = 100MHz / Prescale * MPLL_divisor / 0.5 = 100MHz / 2 * 25 / 0.5 = 2.5GHz */
+		ncy = 0x5 & 0x1f;
+		ncy5 = 0x1 & 0x3;
+		prescale = 0x2 & 0x3;
+	} else {
+		/* Baud rate = 62.5MHz * MPLL_divisor / 0.5 = 62.5MHz * 20 / 0.5 = 2.5GHz */
+		ncy = 0x4 & 0x1f;
+		ncy5 = 0x0 & 0x3;
+		prescale = 0x0 & 0x3;
+	}
+
+	writel((prescale << 1) | (ncy5 << 3) | (ncy << 5), pcie.phy_baseaddr + PCIE_PHY_MPLL_CTRL);
+
+	/* fast tech, low = 1.0, high = 2.5 */
+	writel(PCIE_TECH_CTL_FAST_TECH, pcie.phy_baseaddr + PCIE_PHY_TECHNOLOGY_CTRL);
+
+	writel(tx_level, pcie.phy_baseaddr + PCIE_PHY_TRANSMIT_LEVEL_CTRL);
+
+	writel(tx_edge_rate | (tx_boost << 2) | (tx_atten << 6) | (tx_clk_align << 9), pcie.phy_baseaddr + PCIE_PHY_LANE0_TX_CTRL);
+
+	writel(tx_edge_rate | (tx_boost << 2) | (tx_atten << 6) | (tx_clk_align << 9), pcie.phy_baseaddr + PCIE_PHY_LANE1_TX_CTRL);
+
+	writel(0x00000000, pcie.phy_baseaddr + PCIE_PHY_PCS_CTRL);
+
+	return 0;
+}
+
+
+static u8 __init pcie_swizzle(struct pci_dev *dev, u8 *pin)
+{
+	return PCI_SLOT(dev->devfn);
+}
+
+static int __init pcie_map_irq(struct pci_dev *dev, u8 slot, u8 pin)
+{
+	struct pcie_root_port *root_port = pci_dev_to_root_port(dev);
+	int irq;
+
+	/* FIXME this may be board dependent and in particular depend on the bus
+	hierarchy */
+	irq = root_port->soft_irq_base + 4 + (slot + (pin - 1)) % 4;
+
+	printk("slot %d, pin %d, irq %d\n", slot, pin, irq);
+
+	return irq;
+}
+
+static int __init pcie_setup(int nr, struct pci_sys_data *sys)
+{
+	struct pcie_root_port *root_port;
+	struct pcie_ctrl *ctrl;
+	struct resource *res;
+
+	printk(KERN_INFO "pcie_setup(%d)\n", nr);
+
+	if (nr >= pcie.max_root_ports)
+		return 0;
+
+	root_port = &pcie.root_port[nr];
+	ctrl = root_port->ctrl;
+
+	res = kzalloc(sizeof(struct resource), GFP_KERNEL);
+	if (!res)
+		panic("Comcerto PCIe: unable to allocate resources");
+
+	res[0].start = ctrl->remote_mem_baseaddr;
+	res[0].end = ctrl->remote_mem_baseaddr + COMCERTO_PCIe_MEM_SIZE - 1;
+	res[0].flags = IORESOURCE_MEM;
+
+	if (ctrl->index == 0)
+		res[0].name = "Comcerto PCIe0 Memory Space";
+	else
+		res[0].name = "Comcerto PCIe1 Memory Space";
+
+	if (request_resource(&iomem_resource, &res[0])) {
+		printk(KERN_ERR "PCIe%d: request_resource() failed\n", nr);
+		goto err;
+	}
+
+	sys->resource[0] = &res[0];
+	sys->resource[1] = NULL;
+
+	return 1;
+
+err:
+	kfree(res);
+	return 0;
+}
+
+static struct pci_bus *__init pcie_scan_bus(int nr, struct pci_sys_data *sys)
+{
+	printk(KERN_INFO "pcie_scan_bus(%d)\n", nr);
+
+	if (nr >= pcie.max_root_ports)
+		return NULL;
+
+	pcie.root_port[nr].busnr = sys->busnr;
+
+	if (nr) {
+		return pci_scan_bus(sys->busnr, &pcie1_ops, sys);
+	} else {
+		return pci_scan_bus(sys->busnr, &pcie0_ops, sys);
+	}
+}
+
+static void __init pcie_preinit(void)
+{
+
+}
+
+static void __init pcie_postinit(void)
+{
+
+}
+
+static struct hw_pci comcerto_pcie __initdata = {
+	.swizzle = pcie_swizzle,
+	.map_irq = pcie_map_irq,
+	.setup = pcie_setup,
+	.scan = pcie_scan_bus,
+	.preinit = pcie_preinit,
+	.postinit = pcie_postinit,
+};
+
+#ifdef CONFIG_PM
+static int comcerto_pcie_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	struct pci_dev *dev1 = NULL;
+	int ret = -1;
+
+	while ((dev1 = pci_get_subsys(PCI_ANY_ID, PCI_ANY_ID, PCI_ANY_ID, PCI_ANY_ID, dev1))) {
+		if (dev1->driver->suspend && (pcie.root_port[pdev->id].busnr == dev1->bus->number))
+			ret = dev1->driver->suspend(dev1, state);
+	}
+	if (dev1 == NULL || ret == 0) {
+		if (pdev->id == 0)
+			pwr_mgmt_clk_down(COMPONENT_PCIE0);
+		else
+			pwr_mgmt_clk_down(COMPONENT_PCIE1);
+	}
+
+	return 0;
+}
+
+static int comcerto_pcie_resume(struct platform_device *pdev)
+{
+	struct pci_dev *dev1 = NULL;
+	int ret = -1;
+
+	if (pdev->id == 0)
+		pwr_mgmt_clk_restore(COMPONENT_PCIE0);
+	else
+		pwr_mgmt_clk_restore(COMPONENT_PCIE1);
+
+	while ((dev1 = pci_get_subsys(PCI_ANY_ID, PCI_ANY_ID, PCI_ANY_ID, PCI_ANY_ID, dev1))) {
+		if (dev1->driver->resume && (pcie.root_port[pdev->id].busnr == dev1->bus->number))
+			ret = dev1->driver->resume(dev1);
+	}
+
+	if (ret != 0) {
+		if (pdev->id == 0)
+			pwr_mgmt_clk_down(COMPONENT_PCIE0);
+		else
+			pwr_mgmt_clk_down(COMPONENT_PCIE1);
+	}
+
+	return 0;
+}
+
+/* Structure for a device driver */
+static struct platform_driver comcerto_pcie_driver = {
+	.suspend = comcerto_pcie_suspend,
+	.resume = comcerto_pcie_resume,
+	.driver	= {
+		.name = "pcie",
+	},
+};
+#endif
+
+static int __init comcerto_pcie_init(void)
+{
+	int nr, ret;
+	u32 val;
+	int ext_clk;
+
+	if (readl(COMCERTO_GPIO_SYSTEM_CONFIG) & PCIE_REFCLK_SRC)
+		ext_clk = 1;
+	else
+		ext_clk = 0;
+
+	/* Put block into reset */
+	writel(readl(COMCERTO_BLOCK_RESET_REG) & ~(PCIE1_REF_RST | PCIE0_REF_RST | PCIE1_AHB_RST | PCIE0_AHB_RST), COMCERTO_BLOCK_RESET_REG);
+
+	if (ext_clk) {
+		/* Power down PCIe PHY clock */
+#ifdef CONFIG_PM
+		pwr_mgmt_clk_down(COMPONENT_PCIEPHY);
+
+		/* Power up PCIe block clocks */
+		pwr_mgmt_clk_restore(COMPONENT_PCIE0);
+		pwr_mgmt_clk_restore(COMPONENT_PCIE1);
+#else
+		writel(readl(COMCERTO_CLK_CLK_PWR_DWN) | PCIE_REFCLK_NP_PD, COMCERTO_CLK_CLK_PWR_DWN);
+		writel(readl(COMCERTO_CLK_CLK_PWR_DWN) & ~(PCIE0_AHBCLK_PD | PCIE1_AHBCLK_PD), COMCERTO_CLK_CLK_PWR_DWN);
+#endif
+	} else {
+		/* Power up clocks */
+#ifdef CONFIG_PM
+		pwr_mgmt_clk_restore(COMPONENT_PCIE0);
+		pwr_mgmt_clk_restore(COMPONENT_PCIE1);
+		pwr_mgmt_clk_restore(COMPONENT_PCIEPHY);
+#else
+		writel(readl(COMCERTO_CLK_CLK_PWR_DWN) & ~(PCIE_REFCLK_NP_PD | PCIE0_AHBCLK_PD | PCIE1_AHBCLK_PD), COMCERTO_CLK_CLK_PWR_DWN);
+#endif
+
+		/* Set reference clock to 250/4 = 62.5 MHz */
+		val = readl(COMCERTO_CLK_DDR_PCIE_CLK_CNTRL);
+
+		val &= ~(PCIE_DIV_VAL_MASK | PCIE_DIV_BYPASS);
+		val |= 4 << PCIE_DIV_VAL_OFFSET;
+
+		writel(val, COMCERTO_CLK_DDR_PCIE_CLK_CNTRL);
+
+		/* Switch to clock output */
+		writel(val & ~PCIE_MUX_SEL, COMCERTO_CLK_DDR_PCIE_CLK_CNTRL);
+	}
+
+	/* Take block out of reset */
+	writel(readl(COMCERTO_BLOCK_RESET_REG) | (PCIE1_REF_RST | PCIE0_REF_RST | PCIE1_AHB_RST | PCIE0_AHB_RST), COMCERTO_BLOCK_RESET_REG);
+
+	memset(&pcie, 0, sizeof(struct pcie));
+
+	pcie_phy_init(ext_clk);
+
+	for (nr = 0; nr < PCIE_MAX_CTRLS; nr++)
+		pcie_ctrl_init(nr);
+
+	comcerto_pcie.nr_controllers = pcie.max_root_ports;
+
+	pci_common_init(&comcerto_pcie);
+
+#ifdef CONFIG_PM
+	ret = platform_driver_register(&comcerto_pcie_driver);
+#endif
+
+	return 0;
+}
+
+subsys_initcall(comcerto_pcie_init);
diff --git a/arch/arm/mach-comcerto/pcie-c1000.h b/arch/arm/mach-comcerto/pcie-c1000.h
new file mode 100644
index 0000000..764235f
--- /dev/null
+++ b/arch/arm/mach-comcerto/pcie-c1000.h
@@ -0,0 +1,73 @@
+#ifndef __PCIE_C1000_H
+#define __PCIE_C1000_H
+
+#define PCIE_MAX_CTRLS			2
+
+#define PCIE_BULK_MODE_QUEUE_SIZE	128
+
+struct pcie_bulk_ctrl {
+	void *qbaseaddr;
+	dma_addr_t qhandle;
+	dma_addr_t *handles;
+	int size;
+	int cur;
+	int first;
+};
+
+struct pcie_endpoint {
+	struct pcie_ctrl *ctrl;
+};
+
+struct pcie_root_port {
+
+	struct pcie_ctrl *ctrl;
+
+	int busnr;
+
+	dma_addr_t msi_mbox_handle;
+	void *msi_mbox_baseaddr;
+
+	unsigned long msi_irq_in_use[1];
+
+	unsigned int irq_ext;
+
+	int soft_irq_base;
+};
+
+struct pcie_ctrl {
+	int index;
+
+	struct pcie_root_port *root_port;
+	struct pcie_endpoint *endpoint;
+
+	void *baseaddr;
+
+	void *indirect_baseaddr;
+
+	u64 remote_mem_baseaddr;
+
+	unsigned int irq_int;
+
+	spinlock_t lock;
+	u8 link_state;
+	u8 is_endpoint;
+
+	struct pcie_bulk_ctrl bulk;
+
+	unsigned long tl_error;
+	unsigned long pex_reject;
+	unsigned long tx_request_error;
+};
+
+struct pcie {
+	struct pcie_ctrl ctrl[PCIE_MAX_CTRLS];
+	struct pcie_root_port root_port[PCIE_MAX_CTRLS];
+	struct pcie_endpoint endpoint[PCIE_MAX_CTRLS];
+
+	int max_root_ports;
+	int max_endpoints;
+
+	void *phy_baseaddr;
+};
+
+#endif /* __PCIE_C1000_H */
-- 
1.7.0.4

