From 457068ed43ba1ecd3e0a37c8d7ec90578c858366 Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Tue, 16 Dec 2008 19:07:02 +0800
Subject: [PATCH] rmi xlr page operations support

Add XLR's page operation support.

Signed-off-by: Jack Tan <jack.tan@windriver.com>
---
 arch/mips/mm/page.c     |  107 +++++++++++++++++++++++++++++++++++++++++++++++
 include/asm-mips/page.h |   19 ++++++++
 2 files changed, 126 insertions(+), 0 deletions(-)

diff --git a/arch/mips/mm/page.c b/arch/mips/mm/page.c
index 1417c64..535e141 100644
--- a/arch/mips/mm/page.c
+++ b/arch/mips/mm/page.c
@@ -82,11 +82,13 @@ static struct uasm_reloc __cpuinitdata relocs[5];
 
 static u32 clear_page_array[0x120 / 4];
 
+#ifndef CONFIG_CPU_PHOENIX
 #ifdef CONFIG_SIBYTE_DMA_PAGEOPS
 void clear_page_cpu(void *page) __attribute__((alias("clear_page_array")));
 #else
 void clear_page(void *page) __attribute__((alias("clear_page_array")));
 #endif
+#endif
 
 EXPORT_SYMBOL(clear_page);
 
@@ -100,12 +102,14 @@ EXPORT_SYMBOL(clear_page);
  */
 static u32 copy_page_array[0x540 / 4];
 
+#ifndef CONFIG_CPU_PHOENIX
 #ifdef CONFIG_SIBYTE_DMA_PAGEOPS
 void
 copy_page_cpu(void *to, void *from) __attribute__((alias("copy_page_array")));
 #else
 void copy_page(void *to, void *from) __attribute__((alias("copy_page_array")));
 #endif
+#endif
 
 EXPORT_SYMBOL(copy_page);
 
@@ -687,3 +691,106 @@ void copy_page(void *to, void *from)
 }
 
 #endif /* CONFIG_SIBYTE_DMA_PAGEOPS */
+
+#ifdef CONFIG_CPU_PHOENIX
+
+#include <asm/asm.h>
+
+void clear_page(void *page)
+{
+#ifdef CONFIG_PHOENIX_VM_DEBUG
+  printk("[%s]: page = %lx\n", __func__, (unsigned long)page);
+#endif
+  __asm__ __volatile__(
+		       ".set push                  \n"
+		       ".set noreorder             \n"
+		       ".set noat                  \n"
+		       ".set mips4                 \n"
+
+		       STR(LONG_ADDIU) "\t$1, $0, 1		\n"
+		       STR(LONG_SLL)"\t$1, %1		\n"
+		       /* store the address of last cacheline in $1 */
+		       STR(LONG_ADDU) "\t$1, %0, $1  \n"  
+
+		       /* pref with prep_for_store and zero the cacheline */
+		       "1:   pref      30,  0(%0)  \n"
+
+		       "     sd        $0,  0(%0)  \n"  
+		       "     sd        $0,  8(%0)  \n"
+		       "     sd        $0, 16(%0)  \n"
+		       "     sd        $0, 24(%0)  \n"
+
+		       /* loop till the last cacheline */
+		       STR(LONG_ADDIU)"\t%0, %0, 32  \n"  
+		       "     bne       %0, $1, 1b  \n"
+		       "     nop                   \n"
+
+		       ".set pop                   \n"
+		       :
+		       :"r" (page), "I" (PAGE_SHIFT)
+		       :"$1","memory");
+}
+
+void copy_page(void *to, void *from)
+{
+  __asm__ __volatile__(
+		       ".set push                  \n"
+		       ".set noreorder             \n"
+		       ".set noat                  \n"
+		       ".set mips64                 \n"
+
+		       STR(LONG_ADDIU) "\t$1, $0, 1		\n"
+		       STR(PTR_SLL) "\t $1, %2		\n"
+		       /* store the address of last cacheline in $1 */
+		       STR(LONG_ADDU)"\t$1, %1, $1  \n"  
+
+		       /* pref with prep_for_store the current cacheline */
+		       /* the stores should merge into this pref cacheline */
+		       "1:   pref      30,   0(%0)  \n"
+
+		       /* pref the next cacheline "from" */
+		       "     pref      0,    32(%1)  \n"
+
+		       /* copy the cacheline */
+#ifdef CONFIG_32BIT
+ 		       "2:   lw        $8,   0(%1)  \n"
+		       "     lw        $9,   4(%1)  \n"
+		       "     lw        $10,  8(%1)  \n"
+		       "     lw        $11,  12(%1)  \n"
+		       "     sw        $8,   0(%0)  \n"
+		       "     sw        $9,   4(%0)  \n"
+		       "     sw        $10,  8(%0)  \n"
+		       "     sw        $11,  12(%0)  \n"
+ 		       "     lw        $8,   16(%1)  \n"
+		       "     lw        $9,   20(%1)  \n"
+		       "     lw        $10,  24(%1)  \n"
+		       "     lw        $11,  28(%1)  \n"
+		       "     sw        $8,   16(%0)  \n"
+		       "     sw        $9,   20(%0)  \n"
+		       "     sw        $10,  24(%0)  \n"
+		       "     sw        $11,  28(%0)  \n"
+#else
+ 		       "2:   ld        $8,   0(%1)  \n"
+		       "     ld        $9,   8(%1)  \n"
+		       "     ld        $10,  16(%1)  \n"
+		       "     ld        $11,  24(%1)  \n"
+		       "     sd        $8,   0(%0)  \n"
+		       "     sd        $9,   8(%0)  \n"
+		       "     sd        $10,  16(%0)  \n"
+		       "     sd        $11,  24(%0)  \n"
+#endif
+
+		       /* loop till the last cacheline */		       
+		       STR(LONG_ADDIU)"\t%1, %1, 32  \n"
+		       STR(LONG_ADDIU)"\t%0, %0, 32  \n"  
+		       "     bne       %1, $1, 1b  \n"
+		       "     nop                   \n"
+
+		       ".set pop                   \n"
+
+		       :
+		       :"r" (to), "r"(from), "I" (PAGE_SHIFT)
+		       :"$1","$8", "$9", "$10", "$11", "memory");
+}
+
+#endif
diff --git a/include/asm-mips/page.h b/include/asm-mips/page.h
index fe7a88e..abd5ef5 100644
--- a/include/asm-mips/page.h
+++ b/include/asm-mips/page.h
@@ -60,15 +60,34 @@ struct page;
 static inline void clear_user_page(void *addr, unsigned long vaddr,
 	struct page *page)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	extern void phoenix_flush_dcache_page(struct page *page);
+#else
 	extern void (*flush_data_cache_page)(unsigned long addr);
+#endif
 
 	clear_page(addr);
+#ifdef CONFIG_RMI_PHOENIX
+	phoenix_flush_dcache_page(page);
+#else
 	if (pages_do_alias((unsigned long) addr, vaddr & PAGE_MASK))
 		flush_data_cache_page((unsigned long)addr);
+#endif
 }
 
+#ifdef CONFIG_RMI_PHOENIX
+static inline void copy_user_page(void *vto, void *vfrom, unsigned long vaddr,
+		    struct page *to)
+{
+	extern void phoenix_flush_dcache_page(struct page *page);
+
+	copy_page(vto, vfrom);
+	phoenix_flush_dcache_page(to);
+}
+#else
 extern void copy_user_page(void *vto, void *vfrom, unsigned long vaddr,
 	struct page *to);
+#endif
 struct vm_area_struct;
 extern void copy_user_highpage(struct page *to, struct page *from,
 	unsigned long vaddr, struct vm_area_struct *vma);
-- 
1.6.0.4

