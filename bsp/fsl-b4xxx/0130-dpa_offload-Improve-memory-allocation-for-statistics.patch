From df9688abc8edd9849dab4da988932bb058d9d503 Mon Sep 17 00:00:00 2001
From: Marian Chereji <marian.chereji@freescale.com>
Date: Mon, 18 Nov 2013 18:09:46 +0200
Subject: [PATCH 130/130] dpa_offload: Improve memory allocation for
 statistics counters

The DPA Stats module is allocating a great deal of memory at initialization
time to be able to prepare for any counter or class counter the user
might create. As this was no longer acceptable with the addition of the
support for a maximum of 512 counters, the allocation was moved to counter
creation time. This allows the driver to allocate just enough memory for
each counter. As the counter type is known at creation time, the needed
memory space is greatly improved (reduced).

Change-Id: Ie13c5d1524cb68d0b3e61a21a8b1cea15f4397fa
Signed-off-by: Marian Chereji <marian.chereji@freescale.com>
Signed-off-by: Aurelian Zanoschi <Aurelian.Zanoschi@freescale.com>
Reviewed-on: http://git.am.freescale.net:8181/6708
Tested-by: Review Code-CDREVIEW <CDREVIEW@freescale.com>
Reviewed-by: Anca Jeanina Floarea <anca.floarea@freescale.com>
Reviewed-by: Thomas Trefny <Tom.Trefny@freescale.com>
[This is a patch delivered from Freescale against fsl-sdk-v1.4.5,
 rebase on current context.]
Signed-off-by: Tiejun Chen <tiejun.chen@windriver.com>
---
 drivers/staging/fsl_dpa_offload/dpa_stats.c |  758 ++++++++++++++++++---------
 drivers/staging/fsl_dpa_offload/dpa_stats.h |   28 +-
 2 files changed, 543 insertions(+), 243 deletions(-)

diff --git a/drivers/staging/fsl_dpa_offload/dpa_stats.c b/drivers/staging/fsl_dpa_offload/dpa_stats.c
index 5b533e5..4333dd8 100644
--- a/drivers/staging/fsl_dpa_offload/dpa_stats.c
+++ b/drivers/staging/fsl_dpa_offload/dpa_stats.c
@@ -53,9 +53,13 @@
 
 #define DPA_STATS_US_CNT 0x80000000
 
+
 /* Global dpa_stats component */
 struct dpa_stats *gbl_dpa_stats;
 
+static int alloc_cnt_stats(struct stats_info *stats_info,
+				unsigned int num_members);
+
 static void init_cnt_32bit_stats(struct stats_info *stats_info,
 				 void *stats, uint32_t idx);
 
@@ -171,37 +175,47 @@ static int get_classif_tbl_key_stats(struct dpa_stats_cnt_cb *cnt_cb,
 {
 	struct dpa_stats_lookup_key *entry = &cnt_cb->tbl_cb.keys[idx];
 	t_FmPcdCcKeyStatistics stats;
+	uint8_t *mask_data;
 	int err;
 
 	switch (cnt_cb->tbl_cb.type) {
 	case DPA_CLS_TBL_HASH:
 		err = FM_PCD_HashTableFindNGetKeyStatistics(entry->cc_node,
-				entry->key.size, entry->key.byte, &stats);
+				entry->key.data.size, entry->key.data.byte,
+				&stats);
 		if (err != 0) {
 			log_err("Check failed for Classifier Hash Table counter id %d due to incorrect parameters: handle=0x%p, keysize=%d, keybyte=\n",
-				cnt_cb->id, entry->cc_node, entry->key.size);
-			dump_lookup_key(&entry->key);
+				cnt_cb->id, entry->cc_node,
+				entry->key.data.size);
+			dump_lookup_key(&entry->key.data);
 			return -EIO;
 		}
 		break;
 	case DPA_CLS_TBL_INDEXED:
 		err = FM_PCD_MatchTableGetKeyStatistics(
-				entry->cc_node, entry->key.byte[0], &stats);
+				entry->cc_node, entry->key.data.byte[0],
+				&stats);
 		if (err != 0) {
 			log_err("Check failed for Classifier Indexed Table counter id %d due to incorrect parameters: handle=0x%p, keysize=%d keybyte=\n",
-				cnt_cb->id, entry->cc_node, entry->key.size);
-			dump_lookup_key(&entry->key);
+				cnt_cb->id, entry->cc_node,
+				entry->key.data.size);
+			dump_lookup_key(&entry->key.data);
 			return -EIO;
 		}
 		break;
 	case DPA_CLS_TBL_EXACT_MATCH:
+		if (entry->key.valid_mask)
+			mask_data = entry->key.data.mask;
+		else
+			mask_data = NULL;
 		err = FM_PCD_MatchTableFindNGetKeyStatistics(entry->cc_node,
-				entry->key.size, entry->key.byte,
-				entry->key.mask, &stats);
+				entry->key.data.size, entry->key.data.byte,
+				mask_data, &stats);
 		if (err != 0) {
 			log_err("Check failed for Classifier Exact Match Table counter id %d due to incorrect parameters: handle=0x%p, keysize=%d, keybyte=\n",
-				cnt_cb->id, entry->cc_node, entry->key.size);
-			dump_lookup_key(&entry->key);
+				cnt_cb->id, entry->cc_node,
+				entry->key.data.size);
+			dump_lookup_key(&entry->key.data);
 			return -EINVAL;
 		}
 		break;
@@ -220,44 +234,49 @@ static int get_ccnode_key_stats(struct dpa_stats_cnt_cb *cnt_cb,
 				enum dpa_stats_classif_node_type ccnode_type,
 				uint32_t idx)
 {
-	struct dpa_offload_lookup_key *key = &cnt_cb->ccnode_cb.keys[idx];
+	struct dpa_stats_allocated_lookup_key *key = &cnt_cb->ccnode_cb.keys[idx];
 	t_FmPcdCcKeyStatistics stats;
 	int err;
+	uint8_t *mask_data;
 
 	switch (ccnode_type) {
 	case DPA_STATS_CLASSIF_NODE_HASH:
 		err = FM_PCD_HashTableFindNGetKeyStatistics(
 				cnt_cb->ccnode_cb.cc_node,
-				key->size, key->byte, &stats);
+				key->data.size, key->data.byte, &stats);
 		if (err != 0) {
 			log_err("Check failed for Classification Node counter id %d due to incorrect parameters: handle=0x%p, keysize=%d, keybyte=\n",
 				cnt_cb->id, cnt_cb->ccnode_cb.cc_node,
-				key->size);
-			dump_lookup_key(key);
+				key->data.size);
+			dump_lookup_key(&key->data);
 			return -EINVAL;
 		}
 		break;
 	case DPA_STATS_CLASSIF_NODE_INDEXED:
 		err = FM_PCD_MatchTableGetKeyStatistics(
 				cnt_cb->ccnode_cb.cc_node,
-				key->byte[0], &stats);
+				key->data.byte[0], &stats);
 		if (err != 0) {
 			log_err("Check failed for Classification Node counter id %d due to incorrect parameters: handle=0x%p, keysize=%d, keybyte=\n",
 				cnt_cb->id, cnt_cb->ccnode_cb.cc_node,
-				key->size);
-			dump_lookup_key(key);
+				key->data.size);
+			dump_lookup_key(&key->data);
 			return -EINVAL;
 		}
 		break;
 	case DPA_STATS_CLASSIF_NODE_EXACT_MATCH:
+		if (key->valid_mask)
+			mask_data = key->data.mask;
+		else
+			mask_data = NULL;
 		err = FM_PCD_MatchTableFindNGetKeyStatistics(
-				cnt_cb->ccnode_cb.cc_node, key->size, key->byte,
-				key->mask, &stats);
+				cnt_cb->ccnode_cb.cc_node, key->data.size,
+				key->data.byte, mask_data, &stats);
 		if (err != 0) {
 			log_err("Check failed for Classification Node counter id %d due to incorrect parameters: handle=0x%p, keysize=%d, keybyte=\n",
 				cnt_cb->id, cnt_cb->ccnode_cb.cc_node,
-				key->size);
-			dump_lookup_key(key);
+				key->data.size);
+			dump_lookup_key(&key->data);
 			return -EINVAL;
 		}
 		break;
@@ -463,7 +482,7 @@ static int get_new_req(struct dpa_stats *dpa_stats,
 
 static int put_cnt(struct dpa_stats *dpa_stats, struct dpa_stats_cnt_cb *cnt_cb)
 {
-	int err = 0, i = 0;
+	int err = 0;
 
 	/* Acquire DPA Stats instance lock */
 	mutex_lock(&dpa_stats->lock);
@@ -504,16 +523,6 @@ static int put_cnt(struct dpa_stats *dpa_stats, struct dpa_stats_cnt_cb *cnt_cb)
 		break;
 	}
 
-	/* Reset all statistics information */
-	memset(cnt_cb->info.stats_off, 0,
-			MAX_NUM_OF_STATS * sizeof(*cnt_cb->info.stats_off));
-	for (i = 0; i < MAX_NUM_OF_MEMBERS; i++) {
-		memset(cnt_cb->info.stats[i], 0,
-				MAX_NUM_OF_STATS * sizeof(uint64_t));
-		memset(cnt_cb->info.last_stats[i], 0,
-				MAX_NUM_OF_STATS * sizeof(uint64_t));
-	}
-
 	/* Release DPA Stats instance lock */
 	mutex_unlock(&dpa_stats->lock);
 
@@ -552,66 +561,10 @@ static int put_req(struct dpa_stats *dpa_stats, struct dpa_stats_req_cb *req_cb)
 	return 0;
 }
 
-static int alloc_cnt_cb(struct dpa_stats *dpa_stats,
-			struct dpa_stats_cnt_cb *cnt_cb)
-{
-	int i = 0;
-
-	/* Initialize counter lock */
-	mutex_init(&cnt_cb->lock);
-	/* Store dpa_stats instance */
-	cnt_cb->dpa_stats = dpa_stats;
-	/* Counter is not initialized, set the index to invalid value */
-	cnt_cb->index = DPA_OFFLD_INVALID_OBJECT_ID;
-
-	/* Allocate array of statistics offsets */
-	cnt_cb->info.stats_off = kcalloc(MAX_NUM_OF_STATS,
-				sizeof(*cnt_cb->info.stats_off), GFP_KERNEL);
-	if (!cnt_cb->info.stats_off) {
-		log_err("Cannot allocate memory to store array of statistics offsets\n");
-		return -ENOMEM;
-	}
-
-	/* Allocate array of currently read statistics */
-	cnt_cb->info.stats = kcalloc(MAX_NUM_OF_MEMBERS,
-				sizeof(uint64_t *), GFP_KERNEL);
-	if (!cnt_cb->info.stats) {
-		log_err("Cannot allocate memory to store array of statistics for all members\n");
-		return -ENOMEM;
-	}
-	for (i = 0; i < MAX_NUM_OF_MEMBERS; i++) {
-		cnt_cb->info.stats[i] = kcalloc(MAX_NUM_OF_STATS,
-					sizeof(uint64_t), GFP_KERNEL);
-		if (!cnt_cb->info.stats[i]) {
-			log_err("Cannot allocate memory to store array of statistics for %d member\n",
-				i);
-			return -ENOMEM;
-		}
-	}
-
-	/* Allocate array of previously read statistics */
-	cnt_cb->info.last_stats = kcalloc(MAX_NUM_OF_MEMBERS,
-				sizeof(uint64_t *), GFP_KERNEL);
-	if (!cnt_cb->info.last_stats) {
-		log_err("Cannot allocate memory to store array of previous read statistics for all members\n");
-		return -ENOMEM;
-	}
-	for (i = 0; i < MAX_NUM_OF_MEMBERS; i++) {
-		cnt_cb->info.last_stats[i] = kcalloc(MAX_NUM_OF_STATS,
-					sizeof(uint64_t), GFP_KERNEL);
-		if (!cnt_cb->info.last_stats[i]) {
-			log_err("Cannot allocate memory to store array of previous read statistics for %d member\n",
-				i);
-			return -ENOMEM;
-		}
-	}
-	return 0;
-}
-
 static int init_cnts_resources(struct dpa_stats *dpa_stats)
 {
 	struct dpa_stats_params config = dpa_stats->config;
-	int i, err;
+	int i;
 
 	/* Create circular queue that holds free counter IDs */
 	dpa_stats->cnt_id_cq = cq_new(config.max_counters, sizeof(int));
@@ -656,19 +609,21 @@ static int init_cnts_resources(struct dpa_stats *dpa_stats)
 		return -ENOMEM;
 	}
 
-	/* Allocate memory for every counter control block */
+	/* Initialize every counter control block */
 	for (i = 0; i < config.max_counters; i++) {
-		err = alloc_cnt_cb(dpa_stats, &dpa_stats->cnts_cb[i]);
-		if (err < 0)
-			return err;
+		/* Initialize counter lock */
+		mutex_init(&dpa_stats->cnts_cb[i].lock);
+		/* Store dpa_stats instance */
+		dpa_stats->cnts_cb[i].dpa_stats = dpa_stats;
+		/* Counter is not initialized, set the index to invalid value */
+		dpa_stats->cnts_cb[i].index = DPA_OFFLD_INVALID_OBJECT_ID;
 	}
-
 	return 0;
 }
 
 static int free_cnts_resources(struct dpa_stats *dpa_stats)
 {
-	uint32_t id, i, j;
+	uint32_t id, i;
 	int err = 0;
 
 	for (i = 0; i < dpa_stats->config.max_counters; i++) {
@@ -678,16 +633,9 @@ static int free_cnts_resources(struct dpa_stats *dpa_stats)
 
 		if (id != DPA_OFFLD_INVALID_OBJECT_ID) {
 			/* Release the counter id in the Counter IDs cq */
-			err = put_cnt(dpa_stats, &dpa_stats->cnts_cb[id]);
+			err = dpa_stats_remove_counter(id);
 			BUG_ON(err < 0);
 		}
-		for (j = 0; j < MAX_NUM_OF_MEMBERS; j++) {
-			kfree(dpa_stats->cnts_cb[i].info.stats[j]);
-			kfree(dpa_stats->cnts_cb[i].info.last_stats[j]);
-		}
-		kfree(dpa_stats->cnts_cb[i].info.stats_off);
-		kfree(dpa_stats->cnts_cb[i].info.stats);
-		kfree(dpa_stats->cnts_cb[i].info.last_stats);
 	}
 
 	/* Release counters IDs circular queue */
@@ -1194,7 +1142,7 @@ static void create_cnt_traffic_mng_stats(struct dpa_stats *dpa_stats)
 }
 
 static int copy_key_descriptor(const struct dpa_offload_lookup_key *src,
-			       struct dpa_offload_lookup_key *dst)
+			       struct dpa_stats_allocated_lookup_key *dst)
 {
 	/* Check that key byte pointer is valid */
 	if (!src->byte) {
@@ -1209,29 +1157,20 @@ static int copy_key_descriptor(const struct dpa_offload_lookup_key *src,
 		return -EINVAL;
 	}
 
-	/* Allocate memory to store the key byte array */
-	dst->byte = kmalloc(src->size, GFP_KERNEL);
-	if (!dst->byte) {
-		log_err("No more memory for lookup key descriptor byte\n");
-		return -ENOMEM;
-	}
-	memcpy(dst->byte, src->byte, src->size);
+	BUG_ON(dst->data.byte == NULL);
+	memcpy(dst->data.byte, src->byte, src->size);
+	dst->valid_key = true;
 
 	/* If there is a valid key mask pointer */
 	if (src->mask) {
-		/* Allocate memory to store the key mask array */
-		dst->mask = kmalloc(src->size, GFP_KERNEL);
-		if (!dst->mask) {
-			log_err("No more memory for lookup key descriptor mask\n");
-			kfree(dst->byte);
-			return -ENOMEM;
-		}
-		memcpy(dst->mask, src->mask, src->size);
+		BUG_ON(dst->data.mask == NULL);
+		memcpy(dst->data.mask, src->mask, src->size);
+		dst->valid_mask = true;
 	} else
-		dst->mask = NULL;
+		dst->valid_mask = false;
 
 	/* Store the key size */
-	dst->size = src->size;
+	dst->data.size = src->size;
 
 	return 0;
 }
@@ -1333,39 +1272,58 @@ static int get_fm_mac(struct dpa_stats_cnt_eth_src src, void **mac)
 	return 0;
 }
 
-static void cnt_sel_to_stats(struct stats_info *stats_info,
+static int cnt_sel_to_stats(struct stats_info *stats_info,
 			     int *stats_sel,
 			     uint32_t cnt_sel)
 {
 	uint32_t bit_val = 0, bit_pos = 0, cnt_pos = 1;
+	int stats_off[MAX_NUM_OF_STATS];
+
+	memset(stats_off, 0, sizeof(int) * MAX_NUM_OF_STATS);
 
 	while (cnt_sel > 0) {
 		bit_val = cnt_sel & 0x00000001;
-		stats_info->stats_off[cnt_pos - bit_val] = stats_sel[bit_pos++];
+		stats_off[cnt_pos - bit_val] = stats_sel[bit_pos++];
 		cnt_pos += bit_val;
 		cnt_sel >>= 1;
 	}
 
 	stats_info->stats_num = cnt_pos - 1;
+
+	/*
+	 * Allocate the stats offsets array and copy the calculated offsets
+	 * into it
+	 */
+	stats_info->stats_off = kcalloc(stats_info->stats_num, sizeof(int),
+					GFP_KERNEL);
+	if (!stats_info->stats_off) {
+		log_err("Failed to allocate stats offsets for new counter\n");
+		return -ENOMEM;
+	}
+
+	memcpy(stats_info->stats_off, stats_off,
+				stats_info->stats_num * sizeof(int));
+	return 0;
 }
 
 static int cnt_gen_sel_to_stats(struct dpa_stats_cnt_cb *cnt_cb,
 				enum dpa_stats_cnt_sel cnt_sel)
 {
 	struct dpa_stats *dpa_stats = cnt_cb->dpa_stats;
+	int stats_off[MAX_NUM_OF_STATS];
 
 	if (cnt_sel == DPA_STATS_CNT_NUM_OF_BYTES) {
-		cnt_cb->info.stats_off[0] =
+		stats_off[0] =
 		dpa_stats->stats_sel[cnt_cb->type][DPA_STATS_CNT_NUM_OF_BYTES];
 		cnt_cb->info.stats_num = 1;
 	} else if (cnt_sel == DPA_STATS_CNT_NUM_OF_PACKETS) {
-		cnt_cb->info.stats_off[0] =
+		stats_off[0] =
 	dpa_stats->stats_sel[cnt_cb->type][DPA_STATS_CNT_NUM_OF_PACKETS];
 		cnt_cb->info.stats_num = 1;
 	} else if (cnt_sel == DPA_STATS_CNT_NUM_ALL) {
-		cnt_cb->info.stats_off[0] =
+		stats_off[0] =
 		dpa_stats->stats_sel[cnt_cb->type][DPA_STATS_CNT_NUM_OF_BYTES];
-		cnt_cb->info.stats_off[1] =
+		stats_off[1] =
 	dpa_stats->stats_sel[cnt_cb->type][DPA_STATS_CNT_NUM_OF_PACKETS];
 		cnt_cb->info.stats_num = 2;
 	} else {
@@ -1375,6 +1333,20 @@ static int cnt_gen_sel_to_stats(struct dpa_stats_cnt_cb *cnt_cb,
 		return -EINVAL;
 	}
 
+	/*
+	 * Allocate the stats offsets array and copy the calculated offsets
+	 * into it
+	 */
+	cnt_cb->info.stats_off = kcalloc(cnt_cb->info.stats_num,
+						sizeof(int), GFP_KERNEL);
+	if (!cnt_cb->info.stats_off) {
+		log_err("Failed to allocate stats offsets for new counter\n");
+		return -ENOMEM;
+	}
+
+	memcpy(cnt_cb->info.stats_off, stats_off,
+				cnt_cb->info.stats_num * sizeof(int));
+
 	/* Set number of bytes that will be written by this counter */
 	cnt_cb->bytes_num = cnt_cb->members_num *
 				STATS_VAL_SIZE * cnt_cb->info.stats_num;
@@ -1386,6 +1358,7 @@ static int set_frag_manip(int td, struct dpa_stats_lookup_key *entry)
 {
 	struct dpa_cls_tbl_action action;
 	struct t_FmPcdManipStats stats;
+	struct dpa_offload_lookup_key local_key;
 	int err = 0;
 
 	if (entry->miss_key) {
@@ -1396,7 +1369,14 @@ static int set_frag_manip(int td, struct dpa_stats_lookup_key *entry)
 			return -EINVAL;
 		}
 	} else {
-		err = dpa_classif_table_lookup_by_key(td, &entry->key, &action);
+		local_key.byte = entry->key.data.byte;
+		local_key.size = entry->key.data.size;
+		if (entry->key.valid_mask)
+			local_key.mask = entry->key.data.mask;
+		else
+			local_key.mask = NULL;
+
+		err = dpa_classif_table_lookup_by_key(td, &local_key, &action);
 		if (err != 0) {
 			log_err("Cannot retrieve next action parameters from table %d\n",
 				td);
@@ -1425,6 +1405,28 @@ static int set_frag_manip(int td, struct dpa_stats_lookup_key *entry)
 	return 0;
 }
 
+static int alloc_cnt_stats(struct stats_info *stats_info,
+						unsigned int num_members)
+{
+	/* Allocate array of currently read statistics */
+	stats_info->stats = kcalloc(num_members * stats_info->stats_num,
+						sizeof(uint64_t), GFP_KERNEL);
+	if (!stats_info->stats) {
+		log_err("Cannot allocate memory to store array of statistics\n");
+		return -ENOMEM;
+	}
+
+	/* Allocate array of previously read statistics */
+	stats_info->last_stats = kcalloc(num_members * stats_info->stats_num,
+						sizeof(uint64_t), GFP_KERNEL);
+	if (!stats_info->last_stats) {
+		log_err("Cannot allocate memory to store array of previous read statistics for all members\n");
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
 static int set_cnt_eth_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			  const struct dpa_stats_cnt_params *params)
 {
@@ -1461,8 +1463,10 @@ static int set_cnt_eth_cb(struct dpa_stats_cnt_cb *cnt_cb,
 	cnt_cb->members_num = 1;
 
 	/* Map Ethernet counter selection to FM MAC statistics */
-	cnt_sel_to_stats(&cnt_cb->info,
+	err = cnt_sel_to_stats(&cnt_cb->info,
 			 dpa_stats->stats_sel[DPA_STATS_CNT_ETH], cnt_sel);
+	if (err)
+		return err;
 
 	/* Set number of bytes that will be written by this counter */
 	cnt_cb->bytes_num = STATS_VAL_SIZE * cnt_cb->info.stats_num;
@@ -1474,6 +1478,11 @@ static int set_cnt_eth_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			cnt_cb->id);
 		return -EINVAL;
 	}
+	cnt_cb->gen_cb.objs = kzalloc(sizeof(t_Handle), GFP_KERNEL);
+	if (!cnt_cb->gen_cb.objs) {
+		log_err("No more memory for new Ethernet counter\n");
+		return -ENOMEM;
+	}
 	cnt_cb->gen_cb.objs[0] = fm_mac;
 
 	err = FM_MAC_GetStatistics(cnt_cb->gen_cb.objs[0], &stats);
@@ -1482,6 +1491,11 @@ static int set_cnt_eth_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			cnt_cb->id);
 		return -ENOENT;
 	}
+
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
 	init_cnt_64bit_stats(&cnt_cb->info, &stats, 0);
 
 	return 0;
@@ -1521,6 +1535,11 @@ static int set_cnt_reass_cb(struct dpa_stats_cnt_cb *cnt_cb,
 		return -EFAULT;
 	}
 
+	cnt_cb->gen_cb.objs = kzalloc(sizeof(t_Handle), GFP_KERNEL);
+	if (!cnt_cb->gen_cb.objs) {
+		log_err("No more memory for new IP reass counter\n");
+		return -ENOMEM;
+	}
 	cnt_cb->gen_cb.objs[0] = params->reass_params.reass;
 	cnt_cb->members_num = 1;
 
@@ -1535,8 +1554,10 @@ static int set_cnt_reass_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			~(DPA_STATS_CNT_REASS_IPv6_FRAMES - 1);
 
 	/* Map Reassembly counter selection to Manip statistics */
-	cnt_sel_to_stats(&cnt_cb->info,
+	err = cnt_sel_to_stats(&cnt_cb->info,
 			 dpa_stats->stats_sel[DPA_STATS_CNT_REASS], cnt_sel);
+	if (err)
+		return err;
 
 	/* Set number of bytes that will be written by this counter */
 	cnt_cb->bytes_num = STATS_VAL_SIZE * cnt_cb->info.stats_num;
@@ -1548,6 +1569,11 @@ static int set_cnt_reass_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			cnt_cb->id);
 		return -EINVAL;
 	}
+
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
 	init_cnt_32bit_stats(&cnt_cb->info, &stats, 0);
 
 	return 0;
@@ -1579,6 +1605,11 @@ static int set_cnt_frag_cb(struct dpa_stats_cnt_cb *cnt_cb,
 		return -EFAULT;
 	}
 
+	cnt_cb->gen_cb.objs = kzalloc(sizeof(t_Handle), GFP_KERNEL);
+	if (!cnt_cb->gen_cb.objs) {
+		log_err("No more memory for new IP frag counter\n");
+		return -ENOMEM;
+	}
 	cnt_cb->gen_cb.objs[0] = params->frag_params.frag;
 	cnt_cb->members_num = 1;
 
@@ -1587,8 +1618,10 @@ static int set_cnt_frag_cb(struct dpa_stats_cnt_cb *cnt_cb,
 		cnt_sel -= 1;
 
 	/* Map Fragmentation counter selection to Manip statistics */
-	cnt_sel_to_stats(&cnt_cb->info,
+	err = cnt_sel_to_stats(&cnt_cb->info,
 			 dpa_stats->stats_sel[DPA_STATS_CNT_FRAG], cnt_sel);
+	if (err)
+		return err;
 
 	/* Set number of bytes that will be written by this counter */
 	cnt_cb->bytes_num = STATS_VAL_SIZE * cnt_cb->info.stats_num;
@@ -1600,6 +1633,11 @@ static int set_cnt_frag_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			cnt_cb->id);
 		return -EINVAL;
 	}
+
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
 	init_cnt_32bit_stats(&cnt_cb->info, &stats, 0);
 
 	return 0;
@@ -1612,6 +1650,7 @@ static int set_cnt_plcr_cb(struct dpa_stats_cnt_cb *cnt_cb,
 	uint32_t cnt_sel = params->plcr_params.cnt_sel;
 	uint64_t stats_val;
 	uint32_t i;
+	int err;
 
 	if (!dpa_stats) {
 		log_err("DPA Stats component is not initialized\n");
@@ -1631,6 +1670,11 @@ static int set_cnt_plcr_cb(struct dpa_stats_cnt_cb *cnt_cb,
 		return -EFAULT;
 	}
 
+	cnt_cb->gen_cb.objs = kzalloc(sizeof(t_Handle), GFP_KERNEL);
+	if (!cnt_cb->gen_cb.objs) {
+		log_err("No more memory for new policer counter\n");
+		return -ENOMEM;
+	}
 	cnt_cb->gen_cb.objs[0] = params->plcr_params.plcr;
 	cnt_cb->members_num = 1;
 
@@ -1639,19 +1683,25 @@ static int set_cnt_plcr_cb(struct dpa_stats_cnt_cb *cnt_cb,
 		cnt_sel -= 1;
 
 	/* Map Policer counter selection to policer statistics */
-	cnt_sel_to_stats(&cnt_cb->info,
+	err = cnt_sel_to_stats(&cnt_cb->info,
 			 dpa_stats->stats_sel[DPA_STATS_CNT_POLICER], cnt_sel);
+	if (err)
+		return err;
 
 	/* Set number of bytes that will be written by this counter */
 	cnt_cb->bytes_num = STATS_VAL_SIZE * cnt_cb->info.stats_num;
 
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
 	for (i = 0; i < cnt_cb->info.stats_num; i++) {
 		stats_val = (uint64_t)FM_PCD_PlcrProfileGetCounter(
 			cnt_cb->gen_cb.objs[0], cnt_cb->info.stats_off[i]);
 
 		/* Store the current value as the last read value */
-		cnt_cb->info.stats[0][i] = 0;
-		cnt_cb->info.last_stats[0][i] = stats_val;
+		cnt_cb->info.stats[i] = 0;
+		cnt_cb->info.last_stats[i] = stats_val;
 	}
 	return 0;
 }
@@ -1680,9 +1730,11 @@ static int set_cnt_classif_tbl_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			cnt_sel -= 1;
 
 		/* Map Classifier Table counter selection to CcNode stats */
-		cnt_sel_to_stats(&cnt_cb->info,
+		err = cnt_sel_to_stats(&cnt_cb->info,
 			dpa_stats->stats_sel[DPA_STATS_CNT_CLASSIF_NODE],
 			cnt_sel >> CLASSIF_STATS_SHIFT);
+		if (err)
+			return err;
 
 		frag_stats = 0;
 
@@ -1694,8 +1746,10 @@ static int set_cnt_classif_tbl_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			cnt_sel -= 1;
 
 		/* Map Classifier Table counter selection to Frag stats */
-		cnt_sel_to_stats(&cnt_cb->info,
+		err = cnt_sel_to_stats(&cnt_cb->info,
 			dpa_stats->stats_sel[DPA_STATS_CNT_FRAG], cnt_sel);
+		if (err)
+			return err;
 
 		frag_stats = 1;
 
@@ -1735,6 +1789,10 @@ static int set_cnt_classif_tbl_cb(struct dpa_stats_cnt_cb *cnt_cb,
 	/* Set number of bytes that will be written by this counter */
 	cnt_cb->bytes_num = STATS_VAL_SIZE * cnt_cb->info.stats_num;
 
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
 	/* Store DPA Classifier Table type */
 	cnt_tbl_cb->type = cls_tbl.type;
 
@@ -1743,7 +1801,18 @@ static int set_cnt_classif_tbl_cb(struct dpa_stats_cnt_cb *cnt_cb,
 	if (err != 0)
 		return -EINVAL;
 
-	/* Determine if counter is for 'miss' entry or for a valid key */
+	/* Allocate the single key: */
+	cnt_tbl_cb->keys[0].key.data.byte = kzalloc(
+			DPA_OFFLD_MAXENTRYKEYSIZE, GFP_KERNEL);
+	if (!cnt_tbl_cb->keys[0].key.data.byte)
+		log_err("Cannot allocate memory for the key of for counter id %d\n",
+				cnt_cb->id);
+	cnt_tbl_cb->keys[0].key.data.mask = kzalloc(
+			DPA_OFFLD_MAXENTRYKEYSIZE, GFP_KERNEL);
+	if (!cnt_tbl_cb->keys[0].key.data.mask)
+		log_err("Cannot allocate memory for the mask of counter id %d\n",
+				cnt_cb->id);
+
 	if (!prm.key) {
 		cnt_tbl_cb->keys[0].miss_key = TRUE;
 	} else {
@@ -1816,21 +1885,47 @@ static int set_cnt_ccnode_cb(struct dpa_stats_cnt_cb *cnt_cb,
 	cnt_cb->members_num = 1;
 
 	/* Map Classif Node counter selection to CcNode statistics */
-	cnt_sel_to_stats(&cnt_cb->info,
+	err = cnt_sel_to_stats(&cnt_cb->info,
 		dpa_stats->stats_sel[DPA_STATS_CNT_CLASSIF_NODE],
 		prm.cnt_sel >> CLASSIF_STATS_SHIFT);
+	if (err)
+		return err;
 
 	/* Set number of bytes that will be written by this counter */
 	cnt_cb->bytes_num = STATS_VAL_SIZE * cnt_cb->info.stats_num;
 
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
+	/* Allocate memory for one key descriptor */
+	cnt_cb->ccnode_cb.keys = kzalloc(sizeof(*cnt_cb->ccnode_cb.keys),
+								GFP_KERNEL);
+	if (!cnt_cb->ccnode_cb.keys) {
+		log_err("Cannot allocate memory for key descriptor for counter id %d\n", cnt_cb->id);
+		return -ENOMEM;
+	}
+
 	/* Set retrieve function depending on counter type */
 	err = set_cnt_classif_node_retrieve_func(cnt_cb, prm.ccnode_type);
 	if (err != 0)
 		return -EINVAL;
 
+	/* Allocate memory for every key */
+	cnt_cb->ccnode_cb.keys[0].data.byte = kzalloc(
+			DPA_OFFLD_MAXENTRYKEYSIZE, GFP_KERNEL);
+	if (!cnt_cb->ccnode_cb.keys[0].data.byte)
+		log_err("Cannot allocate memory for the key of the counter id %d\n",
+				cnt_cb->id);
+	cnt_cb->ccnode_cb.keys[0].data.mask = kzalloc(
+			DPA_OFFLD_MAXENTRYKEYSIZE, GFP_KERNEL);
+	if (!cnt_cb->ccnode_cb.keys[0].data.mask)
+		log_err("Cannot allocate memory for the mask of the counter id %d\n",
+				cnt_cb->id);
+
 	if (!params->classif_node_params.key) {
 		/* Set the key byte to NULL, to mark it for 'miss' entry */
-		cnt_cb->ccnode_cb.keys[0].byte = NULL;
+		cnt_cb->ccnode_cb.keys[0].valid_key = false;
 
 		/* Retrieve Classifier Node counter statistics for 'miss' */
 		err = get_ccnode_miss_stats(cnt_cb, prm.ccnode_type, 0);
@@ -1891,6 +1986,11 @@ static int set_cnt_ipsec_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			cnt_cb->id, cnt_cb->ipsec_cb.sa_id[0]);
 		return -EINVAL;
 	}
+
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
 	init_cnt_32bit_stats(&cnt_cb->info, &stats, 0);
 
 	return 0;
@@ -1929,6 +2029,12 @@ static int set_cnt_traffic_mng_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			DPA_STATS_CNT_TRAFFIC_CG, cnt_cb->id);
 		return -EINVAL;
 	}
+
+	cnt_cb->gen_cb.objs = kzalloc(sizeof(t_Handle), GFP_KERNEL);
+	if (!cnt_cb->gen_cb.objs) {
+		log_err("No more memory for new policer counter\n");
+		return -ENOMEM;
+	}
 	cnt_cb->gen_cb.objs[0] = params->traffic_mng_params.traffic_mng;
 	cnt_cb->members_num = 1;
 
@@ -1968,6 +2074,11 @@ static int set_cnt_traffic_mng_cb(struct dpa_stats_cnt_cb *cnt_cb,
 		}
 		break;
 	}
+
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
 	init_cnt_64bit_stats(&cnt_cb->info, &stats, 0);
 
 	return 0;
@@ -2003,13 +2114,26 @@ static int set_cls_cnt_eth_cb(struct dpa_stats_cnt_cb *cnt_cb,
 	cnt_cb->members_num = params->class_members;
 
 	/* Map Ethernet counter selection to FM MAC statistics */
-	cnt_sel_to_stats(&cnt_cb->info,
+	err = cnt_sel_to_stats(&cnt_cb->info,
 			 dpa_stats->stats_sel[DPA_STATS_CNT_ETH], cnt_sel);
+	if (err)
+		return err;
 
 	/* Set number of bytes that will be written by this counter */
 	cnt_cb->bytes_num = cnt_cb->members_num *
 				STATS_VAL_SIZE * cnt_cb->info.stats_num;
 
+	cnt_cb->gen_cb.objs = kcalloc(cnt_cb->members_num, sizeof(t_Handle),
+								GFP_KERNEL);
+	if (!cnt_cb->gen_cb.objs) {
+		log_err("No more memory for new Ethernet class counter\n");
+		return -ENOMEM;
+	}
+
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
 	for (i = 0; i < params->class_members; i++) {
 		/* Get FM MAC handle */
 		err = get_fm_mac(params->eth_params.src[i], &fm_mac);
@@ -2074,13 +2198,26 @@ static int set_cls_cnt_reass_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			~(DPA_STATS_CNT_REASS_IPv6_FRAMES - 1);
 
 	/* Map Reassembly counter selection to Manip statistics */
-	cnt_sel_to_stats(&cnt_cb->info,
+	err = cnt_sel_to_stats(&cnt_cb->info,
 			 dpa_stats->stats_sel[DPA_STATS_CNT_REASS], cnt_sel);
+	if (err)
+		return err;
 
 	/* Set number of bytes that will be written by this counter */
 	cnt_cb->bytes_num = cnt_cb->members_num *
 				STATS_VAL_SIZE * cnt_cb->info.stats_num;
 
+	cnt_cb->gen_cb.objs = kcalloc(cnt_cb->members_num, sizeof(t_Handle),
+								GFP_KERNEL);
+	if (!cnt_cb->gen_cb.objs) {
+		log_err("No more memory for new IP reass class counter\n");
+		return -ENOMEM;
+	}
+
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
 	for (i = 0; i < params->class_members; i++) {
 		if (!params->reass_params.reass[i]) {
 			log_err("Parameter Reassembly handle cannot be NULL for member %d, counter id %d\n",
@@ -2129,13 +2266,26 @@ static int set_cls_cnt_frag_cb(struct dpa_stats_cnt_cb *cnt_cb,
 		cnt_sel -= 1;
 
 	/* Map Fragmentation counter selection to Manip statistics */
-	cnt_sel_to_stats(&cnt_cb->info,
+	err = cnt_sel_to_stats(&cnt_cb->info,
 			 dpa_stats->stats_sel[DPA_STATS_CNT_FRAG], cnt_sel);
+	if (err)
+		return err;
 
 	/* Set number of bytes that will be written by this counter */
 	cnt_cb->bytes_num = cnt_cb->members_num *
 				STATS_VAL_SIZE * cnt_cb->info.stats_num;
 
+	cnt_cb->gen_cb.objs = kcalloc(cnt_cb->members_num, sizeof(t_Handle),
+								GFP_KERNEL);
+	if (!cnt_cb->gen_cb.objs) {
+		log_err("No more memory for new IP frag class counter\n");
+		return -ENOMEM;
+	}
+
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
 	for (i = 0; i < params->class_members; i++) {
 		if (!params->frag_params.frag[i]) {
 			log_err("Parameter Fragmentation handle cannot be NULL for member %d, counter id %d\n",
@@ -2162,7 +2312,8 @@ static int set_cls_cnt_plcr_cb(struct dpa_stats_cnt_cb *cnt_cb,
 {
 	struct dpa_stats *dpa_stats = cnt_cb->dpa_stats;
 	uint32_t cnt_sel = params->plcr_params.cnt_sel;
-	uint32_t i, j, stats;
+	uint32_t i, j, stats, stats_idx, stats_base_idx;
+	int err;
 
 	if (!dpa_stats) {
 		log_err("DPA Stats component is not initialized\n");
@@ -2183,13 +2334,26 @@ static int set_cls_cnt_plcr_cb(struct dpa_stats_cnt_cb *cnt_cb,
 	cnt_cb->members_num = params->class_members;
 
 	/* Map Policer counter selection to policer statistics */
-	cnt_sel_to_stats(&cnt_cb->info,
+	err = cnt_sel_to_stats(&cnt_cb->info,
 			 dpa_stats->stats_sel[DPA_STATS_CNT_POLICER], cnt_sel);
+	if (err)
+		return err;
 
 	/* Set number of bytes that will be written by this counter */
 	cnt_cb->bytes_num = cnt_cb->members_num *
 				STATS_VAL_SIZE * cnt_cb->info.stats_num;
 
+	cnt_cb->gen_cb.objs = kcalloc(cnt_cb->members_num, sizeof(t_Handle),
+								GFP_KERNEL);
+	if (!cnt_cb->gen_cb.objs) {
+		log_err("No more memory for new policer class counter\n");
+		return -ENOMEM;
+	}
+
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
 	for (i = 0; i < params->class_members; i++) {
 		if (!params->plcr_params.plcr[i]) {
 			log_err("Parameter Policer handle cannot be NULL for member %d, counter id %d\n",
@@ -2198,14 +2362,16 @@ static int set_cls_cnt_plcr_cb(struct dpa_stats_cnt_cb *cnt_cb,
 		}
 		cnt_cb->gen_cb.objs[i] = params->plcr_params.plcr[i];
 
+		stats_base_idx = cnt_cb->info.stats_num * i;
 		for (j = 0; j < cnt_cb->info.stats_num; j++) {
 			stats = (uint64_t)FM_PCD_PlcrProfileGetCounter(
 				cnt_cb->gen_cb.objs[i],
 				cnt_cb->info.stats_off[j]);
 
 			/* Store the current value as the last read value */
-			cnt_cb->info.stats[i][j] = 0;
-			cnt_cb->info.last_stats[i][j] = stats;
+			stats_idx = stats_base_idx + j;
+			cnt_cb->info.stats[stats_idx] = 0;
+			cnt_cb->info.last_stats[stats_idx] = stats;
 		}
 	}
 
@@ -2220,7 +2386,6 @@ static int set_cls_cnt_classif_tbl_pair(
 	struct dpa_stats_cnt_classif_tbl_cb *cnt_tbl_cb = &cnt_cb->tbl_cb;
 	struct dpa_stats_lookup_key *lookup_key = &cnt_tbl_cb->keys[idx];
 	struct dpa_cls_tbl_params cls_tbl;
-	struct dpa_offload_lookup_key tbl_key;
 	struct dpa_cls_tbl_action action;
 	int err = 0;
 
@@ -2241,16 +2406,9 @@ static int set_cls_cnt_classif_tbl_pair(
 			return -EFAULT;
 		}
 
-		/* Copy first key descriptor parameters*/
-		err = copy_key_descriptor(pair->first_key, &tbl_key);
-		if (err != 0) {
-			log_err("Cannot copy second key descriptor of the user pair\n");
-			return -EINVAL;
-		}
-
 		/* Use the first key of the pair to lookup in the classifier
 		 * table the next table connected on a "next-action" */
-		err = dpa_classif_table_lookup_by_key(td, &tbl_key, &action);
+		err = dpa_classif_table_lookup_by_key(td, pair->first_key, &action);
 		if (err != 0) {
 			log_err("Cannot retrieve next action parameters for table descriptor %d\n",
 				td);
@@ -2287,7 +2445,8 @@ static int set_cls_cnt_classif_tbl_pair(
 		lookup_key->miss_key = FALSE;
 
 		/* Set as lookup key the second key descriptor from the pair */
-		err = copy_key_descriptor(pair->second_key, &lookup_key->key);
+		err = copy_key_descriptor(pair->second_key,
+							&lookup_key->key);
 		if (err != 0) {
 			log_err("Cannot copy second key descriptor of the user pair\n");
 			return -EINVAL;
@@ -2323,9 +2482,11 @@ static int set_cls_cnt_classif_tbl_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			cnt_sel -= 1;
 
 		/* Map Classif Node counter selection to CcNode statistics */
-		cnt_sel_to_stats(&cnt_cb->info,
+		err = cnt_sel_to_stats(&cnt_cb->info,
 			dpa_stats->stats_sel[DPA_STATS_CNT_CLASSIF_NODE],
 			cnt_sel >> CLASSIF_STATS_SHIFT);
+		if (err)
+			return err;
 
 		frag_stats = 0;
 
@@ -2337,8 +2498,10 @@ static int set_cls_cnt_classif_tbl_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			cnt_sel -= 1;
 
 		/* Map Classif Node counter selection to fragmentation stats */
-		cnt_sel_to_stats(&cnt_cb->info,
+		err = cnt_sel_to_stats(&cnt_cb->info,
 			dpa_stats->stats_sel[DPA_STATS_CNT_FRAG], cnt_sel);
+		if (err)
+			return err;
 
 		frag_stats = 1;
 
@@ -2359,14 +2522,28 @@ static int set_cls_cnt_classif_tbl_cb(struct dpa_stats_cnt_cb *cnt_cb,
 			STATS_VAL_SIZE * cnt_cb->info.stats_num;
 
 	/* Allocate memory for key descriptors */
-	tbl_cb->keys = kcalloc(params->class_members,
-			       sizeof(*tbl_cb->keys), GFP_KERNEL);
+	tbl_cb->keys = kcalloc(params->class_members, sizeof(*tbl_cb->keys),
+								GFP_KERNEL);
 	if (!tbl_cb->keys) {
 		log_err("Cannot allocate memory for array of key descriptors for counter id %d\n",
 			cnt_cb->id);
 		return -ENOMEM;
 	}
 
+	for (i = 0; i < cnt_cb->members_num; i++) {
+		/* Allocate memory for every key */
+		tbl_cb->keys[i].key.data.byte = kzalloc(
+				DPA_OFFLD_MAXENTRYKEYSIZE, GFP_KERNEL);
+		if (!tbl_cb->keys[i].key.data.byte)
+			log_err("Cannot allocate memory for key %d of counter id %d\n",
+					i, cnt_cb->id);
+		tbl_cb->keys[i].key.data.mask = kzalloc(
+				DPA_OFFLD_MAXENTRYKEYSIZE, GFP_KERNEL);
+		if (!tbl_cb->keys[i].key.data.mask)
+			log_err("Cannot allocate memory for mask %d of counter id %d\n",
+					i, cnt_cb->id);
+	}
+
 	switch (prm.key_type) {
 	case DPA_STATS_CLASSIF_SINGLE_KEY:
 		if (!prm.keys) {
@@ -2432,8 +2609,8 @@ static int set_cls_cnt_classif_tbl_cb(struct dpa_stats_cnt_cb *cnt_cb,
 				}
 			}
 
-			err = set_cls_cnt_classif_tbl_pair(
-					cnt_cb, prm.td, prm.pairs[i], i);
+			err = set_cls_cnt_classif_tbl_pair(cnt_cb, prm.td,
+							prm.pairs[i], i);
 			if (err != 0) {
 				log_err("Cannot set classifier table pair key for counter id %d\n",
 					cnt_cb->id);
@@ -2449,6 +2626,10 @@ static int set_cls_cnt_classif_tbl_cb(struct dpa_stats_cnt_cb *cnt_cb,
 		return -EINVAL;
 	}
 
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
 	if (!frag_stats) {
 		for (i = 0; i < params->class_members; i++) {
 			if (!tbl_cb->keys[i].valid)
@@ -2525,9 +2706,11 @@ static int set_cls_cnt_ccnode_cb(struct dpa_stats_cnt_cb *cnt_cb,
 	cnt_cb->members_num = params->class_members;
 
 	/* Map Classif Node counter selection to CcNode statistics */
-	cnt_sel_to_stats(&cnt_cb->info,
+	err = cnt_sel_to_stats(&cnt_cb->info,
 			 dpa_stats->stats_sel[DPA_STATS_CNT_CLASSIF_NODE],
 			 prm.cnt_sel >> CLASSIF_STATS_SHIFT);
+	if (err)
+		return err;
 
 	/* Set number of bytes that will be written by this counter */
 	cnt_cb->bytes_num = cnt_cb->members_num *
@@ -2538,10 +2721,37 @@ static int set_cls_cnt_ccnode_cb(struct dpa_stats_cnt_cb *cnt_cb,
 	if (err != 0)
 		return -EINVAL;
 
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
+	/* Allocate memory for one key descriptor */
+	cnt_cb->ccnode_cb.keys = kcalloc(cnt_cb->members_num,
+					sizeof(*cnt_cb->ccnode_cb.keys),
+								GFP_KERNEL);
+	if (!cnt_cb->ccnode_cb.keys) {
+		log_err("Cannot allocate memory for key descriptors for class counter id %d\n", cnt_cb->id);
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < cnt_cb->members_num; i++) {
+		/* Allocate memory for every key */
+		cnt_cb->ccnode_cb.keys[i].data.byte = kzalloc(
+				DPA_OFFLD_MAXENTRYKEYSIZE, GFP_KERNEL);
+		if (!cnt_cb->ccnode_cb.keys[i].data.byte)
+			log_err("Cannot allocate memory for key %d of counter id %d\n",
+					i, cnt_cb->id);
+		cnt_cb->ccnode_cb.keys[i].data.mask = kzalloc(
+				DPA_OFFLD_MAXENTRYKEYSIZE, GFP_KERNEL);
+		if (!cnt_cb->ccnode_cb.keys[i].data.mask)
+			log_err("Cannot allocate memory for mask %d of counter id %d\n",
+					i, cnt_cb->id);
+	}
+
 	for (i = 0; i < params->class_members; i++) {
 		if (!prm.keys[i]) {
-			/* Set the key byte to NULL, to mark it for 'miss' */
-			cnt_cb->ccnode_cb.keys[i].byte = NULL;
+			/* Invalidate key data, to mark it for 'miss' */
+			cnt_cb->ccnode_cb.keys[i].valid_key = false;
 
 			/* Retrieve Classif Node counter statistics for 'miss'*/
 			err = get_ccnode_miss_stats(cnt_cb, prm.ccnode_type, i);
@@ -2605,6 +2815,10 @@ static int set_cls_cnt_ipsec_cb(struct dpa_stats_cnt_cb *cnt_cb,
 	if (err < 0)
 		return err;
 
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
 	for (i = 0; i < prm->class_members; i++) {
 		if (prm->ipsec_params.sa_id[i] != DPA_OFFLD_INVALID_OBJECT_ID) {
 			cnt_ipsec_cb->sa_id[i] = prm->ipsec_params.sa_id[i];
@@ -2658,6 +2872,17 @@ static int set_cls_cnt_traffic_mng_cb(struct dpa_stats_cnt_cb *cnt_cb,
 		return 0;
 	}
 
+	err = alloc_cnt_stats(&cnt_cb->info, cnt_cb->members_num);
+	if (err)
+		return err;
+
+	cnt_cb->gen_cb.objs = kcalloc(cnt_cb->members_num, sizeof(t_Handle),
+								GFP_KERNEL);
+	if (!cnt_cb->gen_cb.objs) {
+		log_err("No more memory for new traffic manager class counter\n");
+		return -ENOMEM;
+	}
+
 	/* Check the counter source and the Traffic Manager object */
 	switch (prm.src) {
 	case DPA_STATS_CNT_TRAFFIC_CLASS:
@@ -2716,7 +2941,10 @@ int set_classif_tbl_member(const struct dpa_stats_cls_member_params *prm,
 			   int mbr_idx, struct dpa_stats_cnt_cb *cnt_cb)
 {
 	struct dpa_stats_cnt_classif_tbl_cb *tbl_cb = &cnt_cb->tbl_cb;
+	struct dpa_stats_lookup_key *lookup_key = &tbl_cb->keys[mbr_idx];
+	struct dpa_stats_allocated_lookup_key *key = &lookup_key->key;
 	uint32_t i = 0;
+	uint32_t stats_base_idx;
 	int err = 0;
 
 	/* Check that counter is of type Classifier table */
@@ -2733,13 +2961,6 @@ int set_classif_tbl_member(const struct dpa_stats_cls_member_params *prm,
 		return -EINVAL;
 	}
 
-	/* Release the old key memory */
-	kfree(tbl_cb->keys[mbr_idx].key.byte);
-	tbl_cb->keys[mbr_idx].key.byte = NULL;
-
-	kfree(tbl_cb->keys[mbr_idx].key.mask);
-	tbl_cb->keys[mbr_idx].key.mask = NULL;
-
 	if (prm->type == DPA_STATS_CLS_MEMBER_SINGLE_KEY) {
 		if (!prm->key) {
 			/* Mark the key as 'miss' entry */
@@ -2750,15 +2971,15 @@ int set_classif_tbl_member(const struct dpa_stats_cls_member_params *prm,
 			tbl_cb->keys[mbr_idx].valid = FALSE;
 			tbl_cb->keys[mbr_idx].miss_key = FALSE;
 			/* Reset the statistics */
+			stats_base_idx = cnt_cb->info.stats_num * mbr_idx;
 			for (i = 0; i < cnt_cb->info.stats_num; i++) {
-				cnt_cb->info.stats[mbr_idx][i] = 0;
-				cnt_cb->info.last_stats[mbr_idx][i] = 0;
+				cnt_cb->info.stats[stats_base_idx + i] = 0;
+				cnt_cb->info.last_stats[stats_base_idx + i] = 0;
 			}
 			return 0;
 		} else {
 			/* Copy the key descriptor */
-			err = copy_key_descriptor(prm->key,
-						  &tbl_cb->keys[mbr_idx].key);
+			err = copy_key_descriptor(prm->key, key);
 			if (err != 0) {
 				log_err("Cannot copy key descriptor from user parameters\n");
 				return -EINVAL;
@@ -2775,9 +2996,10 @@ int set_classif_tbl_member(const struct dpa_stats_cls_member_params *prm,
 					tbl_cb->keys[mbr_idx].miss_key = FALSE;
 
 					/* Reset the statistics */
+					stats_base_idx = cnt_cb->info.stats_num * mbr_idx;
 					for (i = 0; i < cnt_cb->info.stats_num; i++) {
-						cnt_cb->info.stats[mbr_idx][i] = 0;
-						cnt_cb->info.last_stats[mbr_idx][i] = 0;
+						cnt_cb->info.stats[stats_base_idx + i] = 0;
+						cnt_cb->info.last_stats[stats_base_idx + i] = 0;
 					}
 					return 0;
 				}
@@ -2816,6 +3038,7 @@ int set_ipsec_member(const struct dpa_stats_cls_member_params *params,
 	struct dpa_stats_cnt_ipsec_cb *ipsec_cb = &cnt_cb->ipsec_cb;
 	struct dpa_ipsec_sa_stats stats;
 	uint32_t i = 0;
+	uint32_t stats_base_idx;
 	int err = 0;
 
 	/* Check that counter is of type IPSec */
@@ -2836,9 +3059,10 @@ int set_ipsec_member(const struct dpa_stats_cls_member_params *params,
 		/* Mark that corresponding SA id as invalid */
 		ipsec_cb->valid[mbr_idx] = FALSE;
 		/* Reset the statistics */
+		stats_base_idx = cnt_cb->info.stats_num * mbr_idx;
 		for (i = 0; i < cnt_cb->info.stats_num; i++) {
-			cnt_cb->info.stats[mbr_idx][i] = 0;
-			cnt_cb->info.last_stats[mbr_idx][i] = 0;
+			cnt_cb->info.stats[stats_base_idx + i] = 0;
+			cnt_cb->info.last_stats[stats_base_idx + i] = 0;
 		}
 	} else {
 		/* Mark the corresponding SA id as valid */
@@ -2861,19 +3085,20 @@ static void init_cnt_32bit_stats(struct stats_info *stats_info,
 				 void *stats, uint32_t idx)
 {
 	uint32_t j = 0;
-	uint64_t stats_val;
+	uint32_t stats_val, stats_base_idx;
+
+	stats_base_idx = stats_info->stats_num * idx;
 
 	for (j = 0; j < stats_info->stats_num; j++) {
 		if (stats_info->stats_off[j] == UNSUPPORTED_CNT_SEL)
 			continue;
 
 		/* Get statistics value */
-		stats_val = (uint64_t)(*((uint32_t *)
-				(stats + stats_info->stats_off[j])));
+		stats_val = *((uint32_t *)(stats + stats_info->stats_off[j]));
 
 		/* Store the current value as the last read value */
-		stats_info->stats[idx][j] = 0;
-		stats_info->last_stats[idx][j] = stats_val;
+		stats_info->stats[stats_base_idx + j] = 0;
+		stats_info->last_stats[stats_base_idx + j] = stats_val;
 	}
 }
 
@@ -2881,15 +3106,18 @@ static void init_cnt_64bit_stats(struct stats_info *stats_info,
 				 void *stats, uint32_t idx)
 {
 	uint32_t j = 0;
+	uint32_t stats_base_idx;
 	uint64_t stats_val;
 
+	stats_base_idx = stats_info->stats_num * idx;
+
 	for (j = 0; j < stats_info->stats_num; j++) {
 		/* Get statistics value */
 		stats_val = *((uint64_t *)(stats + stats_info->stats_off[j]));
 
 		/* Store the current value as the last read value */
-		stats_info->stats[idx][j] = 0;
-		stats_info->last_stats[idx][j] = stats_val;
+		stats_info->stats[stats_base_idx + j] = 0;
+		stats_info->last_stats[stats_base_idx + j] = stats_val;
 	}
 }
 
@@ -2898,7 +3126,10 @@ static inline void get_cnt_32bit_stats(struct dpa_stats_req_cb *req_cb,
 				       void *stats, uint32_t idx)
 {
 	uint32_t j = 0;
-	uint64_t stats_val;
+	uint32_t stats_val;
+	uint32_t stats_base_idx, stats_index;
+
+	stats_base_idx = stats_info->stats_num * idx;
 
 	for (j = 0; j < stats_info->stats_num; j++) {
 		if (stats_info->stats_off[j] == UNSUPPORTED_CNT_SEL) {
@@ -2911,30 +3142,32 @@ static inline void get_cnt_32bit_stats(struct dpa_stats_req_cb *req_cb,
 		}
 
 		/* Get statistics value */
-		stats_val = (uint64_t)(*((uint32_t *)
-				(stats + stats_info->stats_off[j])));
+		stats_val = *((uint32_t *)(stats + stats_info->stats_off[j]));
+
+		stats_index = stats_base_idx + j;
 
 		/* Check for rollover */
-		if (stats_val < stats_info->last_stats[idx][j])
-			stats_info->stats[idx][j] +=
+		if (stats_val < stats_info->last_stats[stats_index])
+			stats_info->stats[stats_index] +=
 				((unsigned long int)0xffffffff -
-				stats_info->last_stats[idx][j]) + stats_val;
+				stats_info->last_stats[stats_index]) +
+								stats_val;
 		else
-			stats_info->stats[idx][j] += stats_val -
-				stats_info->last_stats[idx][j];
+			stats_info->stats[stats_index] += stats_val -
+				stats_info->last_stats[stats_index];
 
 		/* Store the current value as the last read value */
-		stats_info->last_stats[idx][j] = stats_val;
+		stats_info->last_stats[stats_index] = stats_val;
 
 		/* Write the memory location */
 		*(uint32_t *)(req_cb->request_area) =
-				(uint32_t)stats_info->stats[idx][j];
+					stats_info->stats[stats_index];
 
 		/* Update the memory pointer */
 		req_cb->request_area += STATS_VAL_SIZE;
 
 		if (stats_info->reset)
-			stats_info->stats[idx][j] = 0;
+			stats_info->stats[stats_index] = 0;
 	}
 }
 
@@ -2944,32 +3177,37 @@ static inline void get_cnt_64bit_stats(struct dpa_stats_req_cb *req_cb,
 {
 	uint32_t j = 0;
 	uint64_t stats_val;
+	uint32_t stats_base_idx, stats_index;
+
+	stats_base_idx = stats_info->stats_num * idx;
 
 	for (j = 0; j < stats_info->stats_num; j++) {
 		/* Get statistics value */
 		stats_val = *((uint64_t *)(stats + stats_info->stats_off[j]));
 
+		stats_index = stats_base_idx + j;
+
 		/* Check for rollover */
-		if (stats_val < stats_info->last_stats[idx][j])
-			stats_info->stats[idx][j] +=
+		if (stats_val < stats_info->last_stats[stats_index])
+			stats_info->stats[stats_index] +=
 				((unsigned long int)0xffffffff -
-				stats_info->last_stats[idx][j]) + stats_val;
+				stats_info->last_stats[stats_index]) + stats_val;
 		else
-			stats_info->stats[idx][j] += stats_val -
-				stats_info->last_stats[idx][j];
+			stats_info->stats[stats_index] += stats_val -
+				stats_info->last_stats[stats_index];
 
 		/* Store the current value as the last read value */
-		stats_info->last_stats[idx][j] = stats_val;
+		stats_info->last_stats[stats_index] = stats_val;
 
 		/* Write the memory location */
 		*(uint32_t *)(req_cb->request_area) =
-				(uint32_t)stats_info->stats[idx][j];
+					(uint32_t)stats_info->stats[stats_index];
 
 		/* Update the memory pointer */
 		req_cb->request_area += STATS_VAL_SIZE;
 
 		if (stats_info->reset)
-			stats_info->stats[idx][j] = 0;
+			stats_info->stats[stats_index] = 0;
 	}
 }
 
@@ -3044,33 +3282,39 @@ static int get_cnt_plcr_stats(struct dpa_stats_req_cb *req_cb,
 	struct stats_info *info = &cnt_cb->info;
 	uint64_t stats_val = 0;
 	uint32_t i = 0, j = 0;
+	uint32_t stats_index, stats_base_idx;
 
 	for (i = 0; i < cnt_cb->members_num; i++) {
+
+		stats_base_idx = info->stats_num * i;
+
 		for (j = 0; j < info->stats_num; j++) {
 			stats_val = (uint64_t)FM_PCD_PlcrProfileGetCounter(
 				cnt_cb->gen_cb.objs[i], info->stats_off[j]);
 
+			stats_index = stats_base_idx + j;
+
 			/* Check for rollover */
-			if (stats_val < info->last_stats[i][j])
-				info->stats[i][j] +=
+			if (stats_val < info->last_stats[stats_index])
+				info->stats[stats_index] +=
 					((unsigned long int)0xffffffff -
-					info->last_stats[i][j]) + stats_val;
+					info->last_stats[stats_index]) + stats_val;
 			else
-				info->stats[i][j] += stats_val -
-					info->last_stats[i][j];
+				info->stats[stats_index] += stats_val -
+					info->last_stats[stats_index];
 
 			/* Store the current value as the last read value */
-			info->last_stats[i][j] = stats_val;
+			info->last_stats[stats_index] = stats_val;
 
 			/* Write the memory location */
 			*(uint32_t *)(req_cb->request_area) =
-					(uint32_t)info->stats[i][j];
+					(uint32_t)info->stats[stats_index];
 
 			/* Update the memory pointer */
 			req_cb->request_area += STATS_VAL_SIZE;
 
 			if (info->reset)
-				info->stats[i][j] = 0;
+				info->stats[stats_index] = 0;
 		}
 	}
 
@@ -3100,11 +3344,18 @@ static int get_cnt_cls_tbl_match_stats(struct dpa_stats_req_cb *req_cb,
 			err = FM_PCD_MatchTableGetMissStatistics(
 					cnt_cb->tbl_cb.keys[i].cc_node, &stats);
 		} else {
+			uint8_t *mask_data;
+
+			if (cnt_cb->tbl_cb.keys[i].key.valid_mask)
+				mask_data = cnt_cb->tbl_cb.keys[i].key.data.mask;
+			else
+				mask_data = NULL;
+
 			err = FM_PCD_MatchTableFindNGetKeyStatistics(
 					cnt_cb->tbl_cb.keys[i].cc_node,
-					cnt_cb->tbl_cb.keys[i].key.size,
-					cnt_cb->tbl_cb.keys[i].key.byte,
-					cnt_cb->tbl_cb.keys[i].key.mask,
+					cnt_cb->tbl_cb.keys[i].key.data.size,
+					cnt_cb->tbl_cb.keys[i].key.data.byte,
+					mask_data,
 					&stats);
 		}
 
@@ -3144,8 +3395,8 @@ static int get_cnt_cls_tbl_hash_stats(struct dpa_stats_req_cb *req_cb,
 		} else {
 			err = FM_PCD_HashTableFindNGetKeyStatistics(
 					cnt_cb->tbl_cb.keys[i].cc_node,
-					cnt_cb->tbl_cb.keys[i].key.size,
-					cnt_cb->tbl_cb.keys[i].key.byte,
+					cnt_cb->tbl_cb.keys[i].key.data.size,
+					cnt_cb->tbl_cb.keys[i].key.data.byte,
 					&stats);
 		}
 		if (err != 0) {
@@ -3184,7 +3435,7 @@ static int get_cnt_cls_tbl_index_stats(struct dpa_stats_req_cb *req_cb,
 		} else {
 			err = FM_PCD_MatchTableGetKeyStatistics(
 					cnt_cb->tbl_cb.keys[i].cc_node,
-					cnt_cb->tbl_cb.keys[i].key.byte[0],
+					cnt_cb->tbl_cb.keys[i].key.data.byte[0],
 					&stats);
 		}
 
@@ -3240,15 +3491,22 @@ static int get_cnt_ccnode_match_stats(struct dpa_stats_req_cb *req_cb,
 	int err = 0;
 
 	for (i = 0; i < cnt_cb->members_num; i++) {
-		if (!cnt_cb->ccnode_cb.keys[i].byte) {
+		if (!cnt_cb->ccnode_cb.keys[i].valid_key) {
 			err = FM_PCD_MatchTableGetMissStatistics(
 					cnt_cb->ccnode_cb.cc_node, &stats);
 		} else {
+			uint8_t *mask_data;
+
+			if (cnt_cb->ccnode_cb.keys[i].valid_mask)
+				mask_data = cnt_cb->ccnode_cb.keys[i].data.mask;
+			else
+				mask_data = NULL;
+
 			err = FM_PCD_MatchTableFindNGetKeyStatistics(
 				cnt_cb->ccnode_cb.cc_node,
-				cnt_cb->ccnode_cb.keys[i].size,
-				cnt_cb->ccnode_cb.keys[i].byte,
-				cnt_cb->ccnode_cb.keys[i].mask, &stats);
+				cnt_cb->ccnode_cb.keys[i].data.size,
+				cnt_cb->ccnode_cb.keys[i].data.byte,
+				mask_data, &stats);
 		}
 		if (err != 0) {
 			log_err("Cannot retrieve Classification Cc Node Exact Match statistics for counter id %d\n",
@@ -3269,14 +3527,14 @@ static int get_cnt_ccnode_hash_stats(struct dpa_stats_req_cb *req_cb,
 	int err = 0;
 
 	for (i = 0; i < cnt_cb->members_num; i++) {
-		if (!cnt_cb->ccnode_cb.keys[i].byte) {
+		if (!cnt_cb->ccnode_cb.keys[i].valid_key) {
 			err = FM_PCD_HashTableGetMissStatistics(
 					cnt_cb->ccnode_cb.cc_node, &stats);
 		} else {
 			err = FM_PCD_HashTableFindNGetKeyStatistics(
 				cnt_cb->ccnode_cb.cc_node,
-				cnt_cb->ccnode_cb.keys[i].size,
-				cnt_cb->ccnode_cb.keys[i].byte, &stats);
+				cnt_cb->ccnode_cb.keys[i].data.size,
+				cnt_cb->ccnode_cb.keys[i].data.byte, &stats);
 		}
 
 		if (err != 0) {
@@ -3298,13 +3556,13 @@ static int get_cnt_ccnode_index_stats(struct dpa_stats_req_cb *req_cb,
 	int err = 0;
 
 	for (i = 0; i < cnt_cb->members_num; i++) {
-		if (!cnt_cb->ccnode_cb.keys[i].byte) {
+		if (!cnt_cb->ccnode_cb.keys[i].valid_key) {
 			err = FM_PCD_MatchTableGetMissStatistics(
 					cnt_cb->ccnode_cb.cc_node, &stats);
 		} else {
 			err = FM_PCD_MatchTableGetKeyStatistics(
 				cnt_cb->ccnode_cb.cc_node,
-				cnt_cb->ccnode_cb.keys[i].byte[0], &stats);
+				cnt_cb->ccnode_cb.keys[i].data.byte[0], &stats);
 		}
 		if (err != 0) {
 			log_err("Cannot retrieve Classification Cc Node Index statistics for counter id %d\n",
@@ -3965,18 +4223,26 @@ int dpa_stats_remove_counter(int dpa_stats_cnt_id)
 	}
 
 	switch (cnt_cb->type) {
+	case DPA_STATS_CNT_ETH:
+	case DPA_STATS_CNT_REASS:
+	case DPA_STATS_CNT_FRAG:
+	case DPA_STATS_CNT_POLICER:
+	case DPA_STATS_CNT_TRAFFIC_MNG:
+		kfree(cnt_cb->gen_cb.objs);
+		break;
 	case DPA_STATS_CNT_CLASSIF_NODE:
 		/* Remove the allocated memory for keys bytes and masks */
 		for (i = 0; i < cnt_cb->members_num; i++) {
-			kfree(cnt_cb->ccnode_cb.keys[i].byte);
-			kfree(cnt_cb->ccnode_cb.keys[i].mask);
+			kfree(cnt_cb->ccnode_cb.keys[i].data.byte);
+			kfree(cnt_cb->ccnode_cb.keys[i].data.mask);
 		}
+		kfree(cnt_cb->ccnode_cb.keys);
 		break;
 	case DPA_STATS_CNT_CLASSIF_TBL:
 		/* Remove the allocated memory for keys bytes, masks and keys */
 		for (i = 0; i < cnt_cb->members_num; i++) {
-			kfree(cnt_cb->tbl_cb.keys[i].key.byte);
-			kfree(cnt_cb->tbl_cb.keys[i].key.mask);
+			kfree(cnt_cb->tbl_cb.keys[i].key.data.byte);
+			kfree(cnt_cb->tbl_cb.keys[i].key.data.mask);
 		}
 		kfree(cnt_cb->tbl_cb.keys);
 		break;
@@ -3989,6 +4255,18 @@ int dpa_stats_remove_counter(int dpa_stats_cnt_id)
 		break;
 	}
 
+	/*
+	 * In case of user space counters, the [stats] and [last_stats] members
+	 * may not be initialized.
+	 */
+	if (cnt_cb->info.stats) {
+		kfree(cnt_cb->info.stats);
+		kfree(cnt_cb->info.last_stats);
+		cnt_cb->info.stats 	= NULL;
+		cnt_cb->info.last_stats	= NULL;
+	}
+	kfree(cnt_cb->info.stats_off);
+
 	/* Release the counter id in the Counter IDs circular queue */
 	err = put_cnt(dpa_stats, cnt_cb);
 	if (err < 0) {
@@ -4129,7 +4407,7 @@ int dpa_stats_reset_counters(int *cnts_ids, unsigned int cnts_ids_len)
 {
 	struct dpa_stats *dpa_stats = NULL;
 	struct dpa_stats_cnt_cb *cnt_cb = NULL;
-	uint32_t i = 0, j = 0;
+	uint32_t i = 0;
 	int err = 0;
 
 	if (!gbl_dpa_stats) {
@@ -4186,10 +4464,14 @@ int dpa_stats_reset_counters(int *cnts_ids, unsigned int cnts_ids_len)
 					   cnts_ids, cnts_ids_len);
 			return -EINVAL;
 		}
-		/* Reset stored statistics values */
-		for (j = 0; j < MAX_NUM_OF_MEMBERS; j++)
-			memset(cnt_cb->info.stats[j], 0,
-					MAX_NUM_OF_STATS * sizeof(uint64_t));
+
+		/* User space counters make no sense in being reset. */
+		if (cnt_cb->info.stats) {
+			/* Reset stored statistics values */
+			memset(cnt_cb->info.stats, 0,
+				(cnt_cb->members_num * cnt_cb->info.stats_num) *
+				sizeof(uint64_t));
+		}
 
 		mutex_unlock(&cnt_cb->lock);
 	}
diff --git a/drivers/staging/fsl_dpa_offload/dpa_stats.h b/drivers/staging/fsl_dpa_offload/dpa_stats.h
index eec099c..d79e6e7 100644
--- a/drivers/staging/fsl_dpa_offload/dpa_stats.h
+++ b/drivers/staging/fsl_dpa_offload/dpa_stats.h
@@ -95,21 +95,39 @@ struct stats_info {
 	  */
 	unsigned int *stats_off;
 	unsigned int stats_num; /* Number of statistics to retrieve */
-	uint64_t **stats; /* Array to store statistics values */
-	uint64_t **last_stats;/* Array to store previous statistics values */
+	uint64_t *stats; /* Array to store statistics values */
+	uint64_t *last_stats; /* Array to store previous statistics values */
 	bool reset; /* Reset counter's statistics */
 };
 
 /* DPA Stats General Counter control block */
 struct dpa_stats_cnt_gen_cb {
 	/* Array of objects for which to retrieve statistics */
-	void *objs[MAX_NUM_OF_MEMBERS];
+	void **objs;
+};
+
+/*
+ * DPA Stats allocated lookup key descriptor. This is used in the context of
+ * lookup keys being preallocated for the classification type counters. In this
+ * case, the pointers to key data or key mask will always exist, hence there
+ * is no more way to tell whether the key data or mask are valid except by using
+ * a set of individual indicators like "valid_mask" and "valid_key".
+ */
+struct dpa_stats_allocated_lookup_key {
+	/* The key data (preallocated key & mask). */
+	struct dpa_offload_lookup_key data;
+
+	/* Indicates whether the mask is present or not. */
+	bool valid_mask;
+
+	/* Indicates whether the key data is present or not. */
+	bool valid_key;
 };
 
 /* DPA Stats Classifier Table key descriptor */
 struct dpa_stats_lookup_key {
 	void *cc_node;  /* Handle of Cc Node the lookup key belongs to */
-	struct dpa_offload_lookup_key key; /* Key descriptor */
+	struct dpa_stats_allocated_lookup_key key; /* Key descriptor */
 	bool valid; /* Lookup key is valid */
 	void *frag; /* Fragmentation handle corresponding to this key */
 	bool miss_key; /* Provide statistics for miss entry */
@@ -126,7 +144,7 @@ struct dpa_stats_cnt_classif_tbl_cb {
 /* DPA Stats Classif Node control block */
 struct dpa_stats_cnt_classif_cb {
 	void *cc_node;  /* Handle of Cc Node the lookup keys belong to */
-	struct dpa_offload_lookup_key keys[MAX_NUM_OF_MEMBERS];
+	struct dpa_stats_allocated_lookup_key *keys;
 		 /* Array of key descriptors for which to provide statistics */
 };
 
-- 
1.7.5.4

