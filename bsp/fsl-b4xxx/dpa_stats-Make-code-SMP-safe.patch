From 7d8130560e4f91612f3417baea721eab1edcf98e Mon Sep 17 00:00:00 2001
From: Anca-Jeanina Floarea <anca.floarea@freescale.com>
Date: Fri, 7 Sep 2012 20:06:38 +0000
Subject: [PATCH 308/518] dpa_stats: Make code SMP safe

Added synchronization in the DPA Stats code in order to
prevent simultaneous access and update the clean-up functions
for counter control block and request control block. The
clean-up function needs to restore the initial state of the
control block.

Signed-off-by: Anca Jeanina FLOAREA <anca.floarea@freescale.com>
[Grabbed from the branch, LINUX_IR5.2.0, of
https://git.freescale.com/git-private/cgit.cgi/ppc/alu-b4860/linux.git.]
Signed-off-by: Tiejun Chen <tiejun.chen@windriver.com>
---
 drivers/staging/fsl_dpa_offload/dpa_stats.c |  202 ++++++++++++++++++++++++---
 drivers/staging/fsl_dpa_offload/dpa_stats.h |   37 +++++-
 2 files changed, 220 insertions(+), 19 deletions(-)

diff --git a/drivers/staging/fsl_dpa_offload/dpa_stats.c b/drivers/staging/fsl_dpa_offload/dpa_stats.c
index 8b37269..83caa2e 100644
--- a/drivers/staging/fsl_dpa_offload/dpa_stats.c
+++ b/drivers/staging/fsl_dpa_offload/dpa_stats.c
@@ -86,6 +86,9 @@ static int get_new_cnt(struct dpa_stats *dpa_stats,
 	uint32_t id;
 	int i;
 
+	/* Acquire DPA Stats instance lock */
+	mutex_lock(&dpa_stats->lock);
+
 	/* Get an id for new Counter */
 	if (cq_get_4bytes(dpa_stats->cnt_id_cq, &id) < 0) {
 		pr_err("No more unused counter ids\n");
@@ -112,6 +115,9 @@ static int get_new_cnt(struct dpa_stats *dpa_stats,
 	/* Store on the current position the counter id */
 	dpa_stats->used_cnt_ids[i] = id;
 
+	/* Release DPA Stats instance lock */
+	mutex_unlock(&dpa_stats->lock);
+
 	*dpa_stats_cnt_id = id;
 	*cnt_cb = new_cnt;
 
@@ -125,6 +131,9 @@ static int get_new_req(struct dpa_stats *dpa_stats,
 	uint32_t id;
 	int i;
 
+	/* Acquire DPA Stats instance lock */
+	mutex_lock(&dpa_stats->lock);
+
 	/* Get an id for a new request */
 	if (cq_get_4bytes(dpa_stats->req_id_cq, &id) < 0) {
 		pr_err("No more unused counter ids\n");
@@ -151,6 +160,9 @@ static int get_new_req(struct dpa_stats *dpa_stats,
 	/* Store on the current position the request id */
 	dpa_stats->used_req_ids[i] = id;
 
+	/* Release DPA Stats instance lock */
+	mutex_unlock(&dpa_stats->lock);
+
 	*req_cb = new_req;
 	*dpa_stats_req_id = id;
 
@@ -161,6 +173,9 @@ static int put_cnt(struct dpa_stats *dpa_stats, struct dpa_stats_cnt_cb *cnt_cb)
 {
 	int err = 0;
 
+	/* Acquire DPA Stats instance lock */
+	mutex_lock(&dpa_stats->lock);
+
 	/* Release the Counter id in the Counter IDs circular queue */
 	err = cq_put_4bytes(dpa_stats->cnt_id_cq, cnt_cb->cnt_id);
 	if (err < 0) {
@@ -172,9 +187,38 @@ static int put_cnt(struct dpa_stats *dpa_stats, struct dpa_stats_cnt_cb *cnt_cb)
 	dpa_stats->used_cnt_ids[cnt_cb->cnt_index] =
 						DPA_OFFLD_INVALID_OBJECT_ID;
 
-	/* Clear all 'cnt_cb' information by setting them to a maximum value */
-	cnt_cb->cnt_index = DPA_STATS_MAX_NUM_OF_COUNTERS;
+	/* Clear all 'cnt_cb' information  */
+	cnt_cb->cnt_index = DPA_OFFLD_INVALID_OBJECT_ID;
 	cnt_cb->cnt_id = DPA_STATS_MAX_NUM_OF_COUNTERS;
+	cnt_cb->bytes_num = 0;
+	cnt_cb->f_get_cnt_stats = NULL;
+
+	switch (cnt_cb->type) {
+	case DPA_STATS_CNT_ETH:
+	case DPA_STATS_CNT_REASS:
+	case DPA_STATS_CNT_FRAG:
+	case DPA_STATS_CNT_POLICER:
+		memset(&cnt_cb->gen_cb, 0,
+				sizeof(struct dpa_stats_cnt_gen_cb));
+		break;
+	case DPA_STATS_CNT_CLASSIF_TBL:
+		memset(&cnt_cb->tbl_cb, 0,
+				sizeof(struct dpa_stats_cnt_classif_tbl_cb));
+		break;
+	case DPA_STATS_CNT_CLASSIF_NODE:
+		memset(&cnt_cb->ccnode_cb, 0,
+				sizeof(struct dpa_stats_cnt_classif_cb));
+		break;
+	case DPA_STATS_CNT_IPSEC:
+		memset(&cnt_cb->ipsec_cb, 0,
+				sizeof(struct dpa_stats_cnt_ipsec_cb));
+		break;
+	default:
+		break;
+	}
+
+	/* Release DPA Stats instance lock */
+	mutex_unlock(&dpa_stats->lock);
 
 	return 0;
 }
@@ -183,6 +227,9 @@ static int put_req(struct dpa_stats *dpa_stats, struct dpa_stats_req_cb *req_cb)
 {
 	int err = 0;
 
+	/* Acquire DPA Stats instance lock */
+	mutex_lock(&dpa_stats->lock);
+
 	/* Release the Counter id in the Counter IDs circular queue */
 	err = cq_put_4bytes(dpa_stats->req_id_cq, req_cb->req_id);
 	if (err < 0) {
@@ -194,9 +241,18 @@ static int put_req(struct dpa_stats *dpa_stats, struct dpa_stats_req_cb *req_cb)
 	dpa_stats->used_req_ids[req_cb->req_index] =
 						DPA_OFFLD_INVALID_OBJECT_ID;
 
+	memset(req_cb, 0, sizeof(struct dpa_stats_req_cb));
+
 	/* Clear all 'req_cb' information by setting them to a maximum value */
-	req_cb->req_index = DPA_STATS_MAX_NUM_OF_REQUESTS;
+	req_cb->req_index = DPA_OFFLD_INVALID_OBJECT_ID;
 	req_cb->req_id = DPA_STATS_MAX_NUM_OF_REQUESTS;
+	req_cb->bytes_num = 0;
+	req_cb->cnts_num = 0;
+	req_cb->request_area = NULL;
+	req_cb->request_done = NULL;
+
+	/* Release DPA Stats instance lock */
+	mutex_unlock(&dpa_stats->lock);
 
 	return 0;
 }
@@ -239,8 +295,11 @@ static int init_cnts_cb(struct dpa_stats *dpa_stats)
 		return -ENOMEM;
 	}
 
-	for (i = 0; i < config.max_counters; i++)
+	for (i = 0; i < config.max_counters; i++) {
+		mutex_init(&dpa_stats->cnts_cb[i].lock);
 		dpa_stats->cnts_cb[i].dpa_stats = dpa_stats;
+		dpa_stats->cnts_cb[i].cnt_index = DPA_OFFLD_INVALID_OBJECT_ID;
+	}
 
 	return 0;
 }
@@ -252,7 +311,9 @@ static int free_cnts_cb(struct dpa_stats *dpa_stats)
 	int err = 0;
 
 	for (i = 0; i < dpa_stats->config.max_counters; i++) {
+		mutex_lock(&dpa_stats->lock);
 		id = dpa_stats->used_cnt_ids[i];
+		mutex_unlock(&dpa_stats->lock);
 
 		if (id != DPA_OFFLD_INVALID_OBJECT_ID) {
 			cnt_cb = &(dpa_stats->cnts_cb[id]);
@@ -331,7 +392,9 @@ static int free_reqs_cb(struct dpa_stats *dpa_stats)
 	int err = 0;
 
 	for (i = 0; i <  DPA_STATS_MAX_NUM_OF_REQUESTS; i++) {
+		mutex_lock(&dpa_stats->lock);
 		id = dpa_stats->used_req_ids[i];
+		mutex_unlock(&dpa_stats->lock);
 
 		if (id != DPA_OFFLD_INVALID_OBJECT_ID) {
 			req_cb = &(dpa_stats->reqs_cb[id]);
@@ -380,6 +443,8 @@ static void free_resources(void)
 	/* free requests control blocks related stuff */
 	free_reqs_cb(dpa_stats);
 
+	flush_work(&dpa_stats->req_async_work);
+
 	/* destroy asynchronous requests workqueue */
 	if (dpa_stats->async_req_workqueue) {
 		destroy_workqueue(dpa_stats->async_req_workqueue);
@@ -404,10 +469,16 @@ static int treat_cnts_request(struct dpa_stats *dpa_stats,
 		/* Get counter's control block */
 		cnt_cb = &(dpa_stats->cnts_cb[cnt_id]);
 
+		/* Acquire counter lock */
+		mutex_lock(&cnt_cb->lock);
+
 		/* Call counter's retrieve function */
 		err = cnt_cb->f_get_cnt_stats(req_cb, cnt_cb);
 		if (err < 0) {
 			pr_err("Failed to retrieve counter values\n");
+			mutex_unlock(&cnt_cb->lock);
+			unblock_sched_cnts(dpa_stats, params.cnts_ids,
+					params.cnts_ids_len, 0);
 			return err;
 		}
 
@@ -415,8 +486,12 @@ static int treat_cnts_request(struct dpa_stats *dpa_stats,
 		 * successfully written so far */
 		req_cb->bytes_num += cnt_cb->bytes_num;
 		req_cb->cnts_num += 1;
+
+		mutex_unlock(&cnt_cb->lock);
 	}
 
+	unblock_sched_cnts(dpa_stats, params.cnts_ids, params.cnts_ids_len, 0);
+
 	return 0;
 }
 
@@ -2034,18 +2109,13 @@ void async_req_work_func(struct work_struct *work)
 	mutex_unlock(&dpa_stats->async_req_hlist_lock);
 
 	while (req_cb) {
+
 		err = treat_cnts_request(dpa_stats, req_cb);
 		if (err < 0) {
 			pr_err("Failed to retrieve counter values\n");
 			req_cb->bytes_num = err;
 		}
 
-		err = put_req(dpa_stats, req_cb);
-		if (err < 0) {
-			pr_err("Failed to release request control block\n");
-			req_cb->bytes_num = -ENOEXEC;
-		}
-
 		/* Notify the application */
 		req_cb->request_done(0, req_cb->config.storage_area_offset,
 				req_cb->cnts_num, req_cb->bytes_num);
@@ -2063,6 +2133,11 @@ void async_req_work_func(struct work_struct *work)
 
 		list_del(&req_cb->async_req_node);
 
+		/* Release the request control block */
+		err = put_req(dpa_stats, req_cb);
+		if (err < 0)
+			pr_err("Failed to release request control block\n");
+
 		/* Release the list lock so other threads may use it */
 		mutex_unlock(&dpa_stats->async_req_hlist_lock);
 
@@ -2102,6 +2177,10 @@ int dpa_stats_init(const struct dpa_stats_params *params, int *dpa_stats_id)
 	/* Store parameters */
 	dpa_stats->config = *params;
 
+	/* Initialize DPA Stats instance lock */
+	mutex_init(&dpa_stats->lock);
+	mutex_init(&dpa_stats->sched_cnt_lock);
+
 	/* Allocate and initialize counters control block  */
 	err = init_cnts_cb(dpa_stats);
 	if (err < 0) {
@@ -2187,6 +2266,9 @@ int dpa_stats_create_counter(int dpa_stats_id,
 		return err;
 	}
 
+	/* Acquire the lock for the counter control block */
+	mutex_lock(&cnt_cb->lock);
+
 	switch (params->type) {
 	case DPA_STATS_CNT_ETH:
 		err = set_cnt_eth_cb(cnt_cb, params);
@@ -2253,15 +2335,20 @@ int dpa_stats_create_counter(int dpa_stats_id,
 		break;
 	case DPA_STATS_CNT_TRAFFIC_MNG:
 		pr_err("Counter type not supported\n");
+		mutex_unlock(&cnt_cb->lock);
 		return -EINVAL;
 	default:
 		pr_err("Invalid counter type\n");
+		mutex_unlock(&cnt_cb->lock);
 		return -EINVAL;
 	};
 
 	/* Counter was created. Return the counter id */
 	*dpa_stats_cnt_id = id;
 
+	/* Unlock the counter control block structure */
+	mutex_unlock(&cnt_cb->lock);
+
 	return 0;
 
 create_counter_err:
@@ -2273,6 +2360,9 @@ create_counter_err:
 	if (err_rb < 0)
 		*dpa_stats_cnt_id = id;
 
+	/* Unlock the counter control block structure */
+	mutex_unlock(&cnt_cb->lock);
+
 	return err;
 }
 EXPORT_SYMBOL(dpa_stats_create_counter);
@@ -2314,6 +2404,9 @@ int dpa_stats_create_class_counter(int dpa_stats_id,
 		return err;
 	}
 
+	/* Acquire the lock for the counter control block */
+	mutex_lock(&cnt_cb->lock);
+
 	switch (params->type) {
 	case DPA_STATS_CNT_ETH:
 		err = set_cls_cnt_eth_cb(cnt_cb, params);
@@ -2380,15 +2473,20 @@ int dpa_stats_create_class_counter(int dpa_stats_id,
 		break;
 	case DPA_STATS_CNT_TRAFFIC_MNG:
 		pr_err("Counter type not supported\n");
+		mutex_unlock(&cnt_cb->lock);
 		return -EINVAL;
 	default:
 		pr_err("Invalid counter type\n");
+		mutex_unlock(&cnt_cb->lock);
 		return -EINVAL;
 	};
 
 	/* Counter was created. Return the counter id */
 	*dpa_stats_cnt_id = id;
 
+	/* Unlock the counter control block */
+	mutex_unlock(&cnt_cb->lock);
+
 	return 0;
 
 create_counter_err:
@@ -2400,6 +2498,9 @@ create_counter_err:
 	if (err_rb < 0)
 		*dpa_stats_cnt_id = id;
 
+	/* Unlock the counter control block */
+	mutex_unlock(&cnt_cb->lock);
+
 	return err;
 }
 EXPORT_SYMBOL(dpa_stats_create_class_counter);
@@ -2425,13 +2526,24 @@ int dpa_stats_modify_class_counter(int dpa_stats_cnt_id,
 		return -EINVAL;
 	}
 
+	/* Counter scheduled for the retrieve mechanism can't be modified */
+	if (cnt_is_sched(dpa_stats, dpa_stats_cnt_id)) {
+		pr_err("Counter id %d is in use\n", dpa_stats_cnt_id);
+		return -EBUSY;
+	}
+
 	/* Get counter control block */
 	cnt_cb = &dpa_stats->cnts_cb[dpa_stats_cnt_id];
 
-	/* Validity check for this Counter */
-	if (dpa_stats->used_cnt_ids[cnt_cb->cnt_index] ==
-			DPA_OFFLD_INVALID_OBJECT_ID) {
+	/* Acquire counter control block lock */
+	err = mutex_trylock(&cnt_cb->lock);
+	if (err == 0)
+		return -EAGAIN;
+
+	/* Validity check for this counter */
+	if (cnt_cb->cnt_index == DPA_OFFLD_INVALID_OBJECT_ID) {
 		pr_err("Invalid Counter id %d provided\n", dpa_stats_cnt_id);
+		mutex_unlock(&cnt_cb->lock);
 		return -EINVAL;
 	}
 
@@ -2441,6 +2553,7 @@ int dpa_stats_modify_class_counter(int dpa_stats_cnt_id,
 		err = set_classif_tbl_member(params, member_index, cnt_cb);
 		if (err < 0) {
 			pr_err("Failed to modify class member\n");
+			mutex_unlock(&cnt_cb->lock);
 			return -EINVAL;
 		}
 
@@ -2449,13 +2562,18 @@ int dpa_stats_modify_class_counter(int dpa_stats_cnt_id,
 		err = set_ipsec_member(params, member_index, cnt_cb);
 		if (err < 0) {
 			pr_err("Failed to modify class member\n");
+			mutex_unlock(&cnt_cb->lock);
 			return -EINVAL;
 		}
 	} else {
 		pr_err("Invalid member type\n");
+		mutex_unlock(&cnt_cb->lock);
 		return -EINVAL;
 	}
 
+	/* Unlock the counter control block */
+	mutex_unlock(&cnt_cb->lock);
+
 	return 0;
 }
 EXPORT_SYMBOL(dpa_stats_modify_class_counter);
@@ -2480,13 +2598,24 @@ int dpa_stats_remove_counter(int dpa_stats_cnt_id)
 		return -EINVAL;
 	}
 
+	/* Counter scheduled for the retrieve mechanism can't be removed */
+	if (cnt_is_sched(dpa_stats, dpa_stats_cnt_id)) {
+		pr_err("Counter id %d is in use\n", dpa_stats_cnt_id);
+		return -EBUSY;
+	}
+
 	/* Get counter control block */
 	cnt_cb = &dpa_stats->cnts_cb[dpa_stats_cnt_id];
 
+	/* Acquire counter control block lock */
+	err = mutex_trylock(&cnt_cb->lock);
+	if (err == 0)
+		return -EAGAIN;
+
 	/* Validity check for this counter */
-	if (dpa_stats->used_cnt_ids[cnt_cb->cnt_index] ==
-			DPA_OFFLD_INVALID_OBJECT_ID) {
+	if (cnt_cb->cnt_index == DPA_OFFLD_INVALID_OBJECT_ID) {
 		pr_err("Invalid Counter id %d provided\n", dpa_stats_cnt_id);
+		mutex_unlock(&cnt_cb->lock);
 		return -EINVAL;
 	}
 
@@ -2510,9 +2639,13 @@ int dpa_stats_remove_counter(int dpa_stats_cnt_id)
 	err = put_cnt(dpa_stats, cnt_cb);
 	if (err < 0) {
 		pr_err("Failed to release a preallocated counter\n");
+		mutex_unlock(&cnt_cb->lock);
 		return -EINVAL;
 	}
 
+	/* Release counter lock */
+	mutex_unlock(&cnt_cb->lock);
+
 	return 0;
 }
 EXPORT_SYMBOL(dpa_stats_remove_counter);
@@ -2532,10 +2665,24 @@ int dpa_stats_get_counters(struct dpa_stats_cnt_request_params params,
 		return -EPERM;
 	}
 
+	/* Check user-provided cnts_len pointer */
+	if (!cnts_len) {
+		pr_err("Parameter cnts_len can't be NULL\n");
+		return -EINVAL;
+	}
+
+	/* Check user-provided params.cnts_ids pointer */
+	if (!params.cnts_ids) {
+		pr_err("Parameter params.cnts_ids can't be NULL\n");
+		return -EINVAL;
+	}
+
 	dpa_stats = gbl_dpa_stats;
 
 	*cnts_len = 0;
 
+	block_sched_cnts(dpa_stats, params.cnts_ids, params.cnts_ids_len, 0);
+
 	/* Calculate number of bytes occupied by the counters */
 	for (i = 0; i < params.cnts_ids_len; i++) {
 		cnt_id = params.cnts_ids[i];
@@ -2548,14 +2695,27 @@ int dpa_stats_get_counters(struct dpa_stats_cnt_request_params params,
 		/* Get counter's control block */
 		cnt_cb = &(dpa_stats->cnts_cb[cnt_id]);
 
+		/* Acquire counter lock */
+		err = mutex_trylock(&cnt_cb->lock);
+		if (err == 0) {
+			pr_err("Counter %d is being used\n", cnt_id);
+			mutex_unlock(&cnt_cb->lock);
+			unblock_sched_cnts(dpa_stats, params.cnts_ids,
+					params.cnts_ids_len, 0);
+			return -EBUSY;
+		}
+
 		/* Check if counter control block is initialized */
-		if (dpa_stats->used_cnt_ids[cnt_cb->cnt_index] ==
-				DPA_OFFLD_INVALID_OBJECT_ID) {
+		if (cnt_cb->cnt_index == DPA_OFFLD_INVALID_OBJECT_ID) {
 			pr_err("Invalid Counter id %d provided\n", cnt_id);
+			mutex_unlock(&cnt_cb->lock);
+			unblock_sched_cnts(dpa_stats, params.cnts_ids,
+					params.cnts_ids_len, 0);
 			return -EINVAL;
 		}
 
 		*cnts_len += cnt_cb->bytes_num;
+		mutex_unlock(&cnt_cb->lock);
 	}
 
 	/* Check user-provided parameters */
@@ -2563,6 +2723,8 @@ int dpa_stats_get_counters(struct dpa_stats_cnt_request_params params,
 		dpa_stats->config.storage_area_len) {
 		pr_err("Invalid offset %d provided\n",
 				params.storage_area_offset);
+		unblock_sched_cnts(dpa_stats, params.cnts_ids,
+				params.cnts_ids_len, 0);
 		return -EINVAL;
 	}
 
@@ -2570,8 +2732,12 @@ int dpa_stats_get_counters(struct dpa_stats_cnt_request_params params,
 	err = get_new_req(dpa_stats, &req_id, &req_cb);
 	if (err < 0) {
 		pr_err("Failed retrieving a preallocated request\n");
+		/* Release counters locks */
+		unblock_sched_cnts(dpa_stats, params.cnts_ids,
+				params.cnts_ids_len, 0);
 		return err;
 	}
+
 	req_cb->config = params;
 	req_cb->request_done = request_done;
 
@@ -2586,7 +2752,6 @@ int dpa_stats_get_counters(struct dpa_stats_cnt_request_params params,
 			pr_err("Failed to retrieve counter values\n");
 
 		err = put_req(dpa_stats, req_cb);
-
 		return err;
 	} else {
 		/* Call is asynchronous */
@@ -2597,6 +2762,7 @@ int dpa_stats_get_counters(struct dpa_stats_cnt_request_params params,
 		queue_work(dpa_stats->async_req_workqueue,
 				&dpa_stats->req_async_work);
 	}
+
 	return 0;
 }
 EXPORT_SYMBOL(dpa_stats_get_counters);
diff --git a/drivers/staging/fsl_dpa_offload/dpa_stats.h b/drivers/staging/fsl_dpa_offload/dpa_stats.h
index 598b822..610ed43 100644
--- a/drivers/staging/fsl_dpa_offload/dpa_stats.h
+++ b/drivers/staging/fsl_dpa_offload/dpa_stats.h
@@ -69,6 +69,10 @@ struct dpa_stats {
 	struct list_head async_req_hlist;  /* Head list with asynchronous
 				 counters requests currently being processed */
 	struct mutex async_req_hlist_lock; /* Lock for async requests list */
+	struct mutex lock; /* Lock for this dpa_stats instance */
+	bool sched_cnt_ids[DPA_STATS_MAX_NUM_OF_COUNTERS]; /* Counters that are
+				scheduled for a retrieve operation */
+	struct mutex sched_cnt_lock; /* Lock for array of scheduled counters */
 };
 
 /* DPA Stats  request control block */
@@ -76,7 +80,7 @@ struct dpa_stats_req_cb {
 	struct dpa_stats_cnt_request_params config;
 				/* Parameters provided to the request */
 	uint32_t req_id; /* Request id */
-	uint32_t req_index; /* Request index in the 'used_req_ids'*/
+	int req_index; /* Request index in the 'used_req_ids'*/
 	void *request_area; /* Address in the storage area
 				associated with this request */
 	uint32_t bytes_num; /* Number of bytes written by this request */
@@ -149,6 +153,8 @@ struct dpa_stats_cnt_cb {
 	uint32_t cnt_id;  /* Counter identifier */
 	uint32_t cnt_index; /* Counter index in the 'used_cnt_ids'*/
 	uint32_t bytes_num; /* Number of bytes occupied by this counter */
+	struct mutex lock; /* Lock for this counter control block */
+	bool used; /* Counter has been scheduled for retrieve */
 	enum dpa_stats_cnt_type type; /* Counter type */
 	union {
 		struct dpa_stats_cnt_gen_cb gen_cb;
@@ -160,4 +166,33 @@ struct dpa_stats_cnt_cb {
 				statistics for a specific counter */
 };
 
+static inline void block_sched_cnts(struct dpa_stats *dpa_stats,
+		int *cnts_ids, int cnts_ids_len, int idx)
+{
+	mutex_lock(&dpa_stats->sched_cnt_lock);
+	for (idx = 0; idx < cnts_ids_len; idx++)
+		dpa_stats->sched_cnt_ids[cnts_ids[idx]] = TRUE;
+	mutex_unlock(&dpa_stats->sched_cnt_lock);
+}
+
+static inline void unblock_sched_cnts(struct dpa_stats *dpa_stats,
+		int *cnts_ids, int cnts_ids_len, int idx)
+{
+	mutex_lock(&dpa_stats->sched_cnt_lock);
+	for (idx = 0; idx < cnts_ids_len; idx++)
+		dpa_stats->sched_cnt_ids[cnts_ids[idx]] = FALSE;
+	mutex_unlock(&dpa_stats->sched_cnt_lock);
+}
+
+static inline int cnt_is_sched(struct dpa_stats *dpa_stats, int cnt_id)
+{
+	int ret = 0;
+
+	mutex_lock(&dpa_stats->sched_cnt_lock);
+	ret = dpa_stats->sched_cnt_ids[cnt_id];
+	mutex_unlock(&dpa_stats->sched_cnt_lock);
+
+	return ret;
+}
+
 #endif /* __DPA_STATS_H */
-- 
1.7.5.4

