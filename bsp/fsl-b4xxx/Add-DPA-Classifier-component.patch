From a1938ddc86f0946a10c77013b938afcf62919eb9 Mon Sep 17 00:00:00 2001
From: Marian Chereji <marian.chereji@freescale.com>
Date: Fri, 10 Feb 2012 18:44:09 +0000
Subject: [PATCH 088/518] Add DPA Classifier component

The DPA Classifier component is one of the components available
in the DPA Offloading Driver. It allows software to accelerate
lookups and decisions based on frame content using DPAA.

Signed-off-by: Marian Chereji <marian.chereji@freescale.com>
[Grabbed from the branch, LINUX_IR5.2.0, of
https://git.freescale.com/git-private/cgit.cgi/ppc/alu-b4860/linux.git.]
Signed-off-by: Tiejun Chen <tiejun.chen@windriver.com>
---
 drivers/staging/Kconfig                          |    2 +
 drivers/staging/Makefile                         |    1 +
 drivers/staging/fsl_dpa_offload/Kconfig          |    5 +
 drivers/staging/fsl_dpa_offload/Makefile         |   13 +
 drivers/staging/fsl_dpa_offload/crc64.h          |  355 ++++
 drivers/staging/fsl_dpa_offload/crc8.c           |   85 +
 drivers/staging/fsl_dpa_offload/crc8.h           |   56 +
 drivers/staging/fsl_dpa_offload/dpa_classifier.c | 2225 ++++++++++++++++++++++
 drivers/staging/fsl_dpa_offload/dpa_classifier.h |  279 +++
 drivers/staging/fsl_dpa_offload/dpa_compat.c     |  319 ++++
 drivers/staging/fsl_dpa_offload/dpa_compat.h     |  249 +++
 include/linux/fsl_dpa_classifier.h               |  424 ++++
 include/linux/fsl_dpa_compat.h                   |   50 +
 13 files changed, 4063 insertions(+), 0 deletions(-)
 create mode 100644 drivers/staging/fsl_dpa_offload/Kconfig
 create mode 100644 drivers/staging/fsl_dpa_offload/Makefile
 create mode 100644 drivers/staging/fsl_dpa_offload/crc64.h
 create mode 100644 drivers/staging/fsl_dpa_offload/crc8.c
 create mode 100644 drivers/staging/fsl_dpa_offload/crc8.h
 create mode 100644 drivers/staging/fsl_dpa_offload/dpa_classifier.c
 create mode 100644 drivers/staging/fsl_dpa_offload/dpa_classifier.h
 create mode 100644 drivers/staging/fsl_dpa_offload/dpa_compat.c
 create mode 100644 drivers/staging/fsl_dpa_offload/dpa_compat.h
 create mode 100644 include/linux/fsl_dpa_classifier.h
 create mode 100644 include/linux/fsl_dpa_compat.h

diff --git a/drivers/staging/Kconfig b/drivers/staging/Kconfig
index f21b05d..ad6f54c 100644
--- a/drivers/staging/Kconfig
+++ b/drivers/staging/Kconfig
@@ -138,6 +138,8 @@ source "drivers/staging/lttng2/Kconfig"
 
 source "drivers/staging/fsl_qbman/Kconfig"
 
+source "drivers/staging/fsl_dpa_offload/Kconfig"
+
 source "drivers/staging/fsl_pme2/Kconfig"
 
 source "drivers/staging/fsl_rman/Kconfig"
diff --git a/drivers/staging/Makefile b/drivers/staging/Makefile
index f5bedc7..88053bb 100644
--- a/drivers/staging/Makefile
+++ b/drivers/staging/Makefile
@@ -59,6 +59,7 @@ obj-$(CONFIG_PHONE)		+= telephony/
 obj-$(CONFIG_RAMSTER)		+= ramster/
 obj-$(CONFIG_USB_WPAN_HCD)	+= ozwpan/
 obj-$(CONFIG_FSL_DPA)		+= fsl_qbman/
+obj-$(CONFIG_FSL_DPA_OFFLOAD)	+= fsl_dpa_offload/
 obj-$(CONFIG_FSL_PME2)		+= fsl_pme2/
 obj-$(CONFIG_FSL_RMAN_UIO)	+= fsl_rman/
 obj-$(CONFIG_LTTNG2)		+= lttng2/
diff --git a/drivers/staging/fsl_dpa_offload/Kconfig b/drivers/staging/fsl_dpa_offload/Kconfig
new file mode 100644
index 0000000..e17ee71
--- /dev/null
+++ b/drivers/staging/fsl_dpa_offload/Kconfig
@@ -0,0 +1,5 @@
+
+config FSL_DPA_OFFLOAD
+	bool "Freescale Datapath Offloading Driver"
+	depends on FSL_FMAN
+	default n
diff --git a/drivers/staging/fsl_dpa_offload/Makefile b/drivers/staging/fsl_dpa_offload/Makefile
new file mode 100644
index 0000000..5683163
--- /dev/null
+++ b/drivers/staging/fsl_dpa_offload/Makefile
@@ -0,0 +1,13 @@
+
+#Include NetComm SW specific definitions
+include $(srctree)/drivers/net/ethernet/freescale/dpa/NetCommSw/ncsw_config.mk
+
+
+EXTRA_CFLAGS += \
+	-Idrivers/staging/fsl_dpa_offload/integration
+
+
+obj-$(CONFIG_FSL_DPA_OFFLOAD) +=    \
+        crc8.o                      \
+        dpa_classifier.o            \
+        dpa_compat.o
diff --git a/drivers/staging/fsl_dpa_offload/crc64.h b/drivers/staging/fsl_dpa_offload/crc64.h
new file mode 100644
index 0000000..376eeda
--- /dev/null
+++ b/drivers/staging/fsl_dpa_offload/crc64.h
@@ -0,0 +1,355 @@
+
+/* Copyright 2008-2012 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * This file contains the CRC64 Table, and inline functions used for calculating
+ * crc
+ */
+
+#ifndef __CRC64_H
+#define __CRC64_H
+
+#define CRC64_EXPON_ECMA_182			0xC96C5795D7870F42ULL
+#define CRC64_DEFAULT_INITVAL			0xFFFFFFFFFFFFFFFFULL
+
+#define BITS_PER_BYTE				8
+#define CRC64_BYTE_MASK				0xFF
+#define CRC64_TABLE_ENTRIES			(1 << BITS_PER_BYTE)
+#define CRC64_ODD_MASK				1
+
+
+/*
+ * '64 bit crc' Table
+ */
+struct crc64_t {
+	uint64_t initial;			/* Initial seed*/
+	uint64_t table[CRC64_TABLE_ENTRIES];	/* crc table entries*/
+};
+
+static struct crc64_t CRC64_ECMA_182 = {
+	.initial = CRC64_DEFAULT_INITVAL,
+	.table = {0x0000000000000000,
+		  0xb32e4cbe03a75f6f,
+		  0xf4843657a840a05b,
+		  0x47aa7ae9abe7ff34,
+		  0x7bd0c384ff8f5e33,
+		  0xc8fe8f3afc28015c,
+		  0x8f54f5d357cffe68,
+		  0x3c7ab96d5468a107,
+		  0xf7a18709ff1ebc66,
+		  0x448fcbb7fcb9e309,
+		  0x0325b15e575e1c3d,
+		  0xb00bfde054f94352,
+		  0x8c71448d0091e255,
+		  0x3f5f08330336bd3a,
+		  0x78f572daa8d1420e,
+		  0xcbdb3e64ab761d61,
+		  0x7d9ba13851336649,
+		  0xceb5ed8652943926,
+		  0x891f976ff973c612,
+		  0x3a31dbd1fad4997d,
+		  0x064b62bcaebc387a,
+		  0xb5652e02ad1b6715,
+		  0xf2cf54eb06fc9821,
+		  0x41e11855055bc74e,
+		  0x8a3a2631ae2dda2f,
+		  0x39146a8fad8a8540,
+		  0x7ebe1066066d7a74,
+		  0xcd905cd805ca251b,
+		  0xf1eae5b551a2841c,
+		  0x42c4a90b5205db73,
+		  0x056ed3e2f9e22447,
+		  0xb6409f5cfa457b28,
+		  0xfb374270a266cc92,
+		  0x48190ecea1c193fd,
+		  0x0fb374270a266cc9,
+		  0xbc9d3899098133a6,
+		  0x80e781f45de992a1,
+		  0x33c9cd4a5e4ecdce,
+		  0x7463b7a3f5a932fa,
+		  0xc74dfb1df60e6d95,
+		  0x0c96c5795d7870f4,
+		  0xbfb889c75edf2f9b,
+		  0xf812f32ef538d0af,
+		  0x4b3cbf90f69f8fc0,
+		  0x774606fda2f72ec7,
+		  0xc4684a43a15071a8,
+		  0x83c230aa0ab78e9c,
+		  0x30ec7c140910d1f3,
+		  0x86ace348f355aadb,
+		  0x3582aff6f0f2f5b4,
+		  0x7228d51f5b150a80,
+		  0xc10699a158b255ef,
+		  0xfd7c20cc0cdaf4e8,
+		  0x4e526c720f7dab87,
+		  0x09f8169ba49a54b3,
+		  0xbad65a25a73d0bdc,
+		  0x710d64410c4b16bd,
+		  0xc22328ff0fec49d2,
+		  0x85895216a40bb6e6,
+		  0x36a71ea8a7ace989,
+		  0x0adda7c5f3c4488e,
+		  0xb9f3eb7bf06317e1,
+		  0xfe5991925b84e8d5,
+		  0x4d77dd2c5823b7ba,
+		  0x64b62bcaebc387a1,
+		  0xd7986774e864d8ce,
+		  0x90321d9d438327fa,
+		  0x231c512340247895,
+		  0x1f66e84e144cd992,
+		  0xac48a4f017eb86fd,
+		  0xebe2de19bc0c79c9,
+		  0x58cc92a7bfab26a6,
+		  0x9317acc314dd3bc7,
+		  0x2039e07d177a64a8,
+		  0x67939a94bc9d9b9c,
+		  0xd4bdd62abf3ac4f3,
+		  0xe8c76f47eb5265f4,
+		  0x5be923f9e8f53a9b,
+		  0x1c4359104312c5af,
+		  0xaf6d15ae40b59ac0,
+		  0x192d8af2baf0e1e8,
+		  0xaa03c64cb957be87,
+		  0xeda9bca512b041b3,
+		  0x5e87f01b11171edc,
+		  0x62fd4976457fbfdb,
+		  0xd1d305c846d8e0b4,
+		  0x96797f21ed3f1f80,
+		  0x2557339fee9840ef,
+		  0xee8c0dfb45ee5d8e,
+		  0x5da24145464902e1,
+		  0x1a083bacedaefdd5,
+		  0xa9267712ee09a2ba,
+		  0x955cce7fba6103bd,
+		  0x267282c1b9c65cd2,
+		  0x61d8f8281221a3e6,
+		  0xd2f6b4961186fc89,
+		  0x9f8169ba49a54b33,
+		  0x2caf25044a02145c,
+		  0x6b055fede1e5eb68,
+		  0xd82b1353e242b407,
+		  0xe451aa3eb62a1500,
+		  0x577fe680b58d4a6f,
+		  0x10d59c691e6ab55b,
+		  0xa3fbd0d71dcdea34,
+		  0x6820eeb3b6bbf755,
+		  0xdb0ea20db51ca83a,
+		  0x9ca4d8e41efb570e,
+		  0x2f8a945a1d5c0861,
+		  0x13f02d374934a966,
+		  0xa0de61894a93f609,
+		  0xe7741b60e174093d,
+		  0x545a57dee2d35652,
+		  0xe21ac88218962d7a,
+		  0x5134843c1b317215,
+		  0x169efed5b0d68d21,
+		  0xa5b0b26bb371d24e,
+		  0x99ca0b06e7197349,
+		  0x2ae447b8e4be2c26,
+		  0x6d4e3d514f59d312,
+		  0xde6071ef4cfe8c7d,
+		  0x15bb4f8be788911c,
+		  0xa6950335e42fce73,
+		  0xe13f79dc4fc83147,
+		  0x521135624c6f6e28,
+		  0x6e6b8c0f1807cf2f,
+		  0xdd45c0b11ba09040,
+		  0x9aefba58b0476f74,
+		  0x29c1f6e6b3e0301b,
+		  0xc96c5795d7870f42,
+		  0x7a421b2bd420502d,
+		  0x3de861c27fc7af19,
+		  0x8ec62d7c7c60f076,
+		  0xb2bc941128085171,
+		  0x0192d8af2baf0e1e,
+		  0x4638a2468048f12a,
+		  0xf516eef883efae45,
+		  0x3ecdd09c2899b324,
+		  0x8de39c222b3eec4b,
+		  0xca49e6cb80d9137f,
+		  0x7967aa75837e4c10,
+		  0x451d1318d716ed17,
+		  0xf6335fa6d4b1b278,
+		  0xb199254f7f564d4c,
+		  0x02b769f17cf11223,
+		  0xb4f7f6ad86b4690b,
+		  0x07d9ba1385133664,
+		  0x4073c0fa2ef4c950,
+		  0xf35d8c442d53963f,
+		  0xcf273529793b3738,
+		  0x7c0979977a9c6857,
+		  0x3ba3037ed17b9763,
+		  0x888d4fc0d2dcc80c,
+		  0x435671a479aad56d,
+		  0xf0783d1a7a0d8a02,
+		  0xb7d247f3d1ea7536,
+		  0x04fc0b4dd24d2a59,
+		  0x3886b22086258b5e,
+		  0x8ba8fe9e8582d431,
+		  0xcc0284772e652b05,
+		  0x7f2cc8c92dc2746a,
+		  0x325b15e575e1c3d0,
+		  0x8175595b76469cbf,
+		  0xc6df23b2dda1638b,
+		  0x75f16f0cde063ce4,
+		  0x498bd6618a6e9de3,
+		  0xfaa59adf89c9c28c,
+		  0xbd0fe036222e3db8,
+		  0x0e21ac88218962d7,
+		  0xc5fa92ec8aff7fb6,
+		  0x76d4de52895820d9,
+		  0x317ea4bb22bfdfed,
+		  0x8250e80521188082,
+		  0xbe2a516875702185,
+		  0x0d041dd676d77eea,
+		  0x4aae673fdd3081de,
+		  0xf9802b81de97deb1,
+		  0x4fc0b4dd24d2a599,
+		  0xfceef8632775faf6,
+		  0xbb44828a8c9205c2,
+		  0x086ace348f355aad,
+		  0x34107759db5dfbaa,
+		  0x873e3be7d8faa4c5,
+		  0xc094410e731d5bf1,
+		  0x73ba0db070ba049e,
+		  0xb86133d4dbcc19ff,
+		  0x0b4f7f6ad86b4690,
+		  0x4ce50583738cb9a4,
+		  0xffcb493d702be6cb,
+		  0xc3b1f050244347cc,
+		  0x709fbcee27e418a3,
+		  0x3735c6078c03e797,
+		  0x841b8ab98fa4b8f8,
+		  0xadda7c5f3c4488e3,
+		  0x1ef430e13fe3d78c,
+		  0x595e4a08940428b8,
+		  0xea7006b697a377d7,
+		  0xd60abfdbc3cbd6d0,
+		  0x6524f365c06c89bf,
+		  0x228e898c6b8b768b,
+		  0x91a0c532682c29e4,
+		  0x5a7bfb56c35a3485,
+		  0xe955b7e8c0fd6bea,
+		  0xaeffcd016b1a94de,
+		  0x1dd181bf68bdcbb1,
+		  0x21ab38d23cd56ab6,
+		  0x9285746c3f7235d9,
+		  0xd52f0e859495caed,
+		  0x6601423b97329582,
+		  0xd041dd676d77eeaa,
+		  0x636f91d96ed0b1c5,
+		  0x24c5eb30c5374ef1,
+		  0x97eba78ec690119e,
+		  0xab911ee392f8b099,
+		  0x18bf525d915feff6,
+		  0x5f1528b43ab810c2,
+		  0xec3b640a391f4fad,
+		  0x27e05a6e926952cc,
+		  0x94ce16d091ce0da3,
+		  0xd3646c393a29f297,
+		  0x604a2087398eadf8,
+		  0x5c3099ea6de60cff,
+		  0xef1ed5546e415390,
+		  0xa8b4afbdc5a6aca4,
+		  0x1b9ae303c601f3cb,
+		  0x56ed3e2f9e224471,
+		  0xe5c372919d851b1e,
+		  0xa26908783662e42a,
+		  0x114744c635c5bb45,
+		  0x2d3dfdab61ad1a42,
+		  0x9e13b115620a452d,
+		  0xd9b9cbfcc9edba19,
+		  0x6a978742ca4ae576,
+		  0xa14cb926613cf817,
+		  0x1262f598629ba778,
+		  0x55c88f71c97c584c,
+		  0xe6e6c3cfcadb0723,
+		  0xda9c7aa29eb3a624,
+		  0x69b2361c9d14f94b,
+		  0x2e184cf536f3067f,
+		  0x9d36004b35545910,
+		  0x2b769f17cf112238,
+		  0x9858d3a9ccb67d57,
+		  0xdff2a94067518263,
+		  0x6cdce5fe64f6dd0c,
+		  0x50a65c93309e7c0b,
+		  0xe388102d33392364,
+		  0xa4226ac498dedc50,
+		  0x170c267a9b79833f,
+		  0xdcd7181e300f9e5e,
+		  0x6ff954a033a8c131,
+		  0x28532e49984f3e05,
+		  0x9b7d62f79be8616a,
+		  0xa707db9acf80c06d,
+		  0x14299724cc279f02,
+		  0x5383edcd67c06036,
+		  0xe0ada17364673f59
+	}
+};
+
+
+/*
+ * Initializes the crc seed
+ */
+static inline uint64_t crc64_init(void)
+{
+	return CRC64_ECMA_182.initial;
+}
+
+/*
+ * Computes 64 bit the crc
+ */
+static inline uint64_t crc64_compute(void const *data,
+				     uint32_t len, uint64_t seed)
+{
+	uint32_t i;
+	uint64_t crc = seed;
+	uint8_t *bdata = (uint8_t *) data;
+
+	for (i = 0; i < len; i++)
+		crc =
+		    CRC64_ECMA_182.
+		    table[(crc ^ *bdata++) & CRC64_BYTE_MASK] ^ (crc >> 8);
+
+	return crc;
+}
+
+/*
+ * Returns the 2's complement for the input seed
+ */
+static inline uint64_t crc64_finish(uint64_t seed)
+{
+	return ~seed;
+}
+
+
+#endif /* ifndef __CRC64_H */
diff --git a/drivers/staging/fsl_dpa_offload/crc8.c b/drivers/staging/fsl_dpa_offload/crc8.c
new file mode 100644
index 0000000..fe67068
--- /dev/null
+++ b/drivers/staging/fsl_dpa_offload/crc8.c
@@ -0,0 +1,85 @@
+
+/* Copyright 2008-2012 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * Implementation of the public CRC8 checksum
+ */
+
+/* DPA offloading layer includes */
+#include "crc8.h"
+
+/* FMD includes */
+#include "dpa_compat.h"
+
+
+static uint8_t crc8_table[256];
+static bool crc8_initialized;
+
+
+void init_crc8_table(uint8_t polynomial)
+{
+	int i, j, curr;
+
+
+	if (crc8_initialized)
+		return;
+
+	for (i = 0; i < 256; i++) {
+		curr = i;
+
+		for (j = 0; j < 8; j++) {
+			if ((curr & 0x80) != 0)
+				curr = (curr << 1) ^ (int)polynomial;
+			else
+				curr <<= 1;
+		}
+
+		crc8_table[i] = (uint8_t)curr;
+	}
+
+	crc8_initialized = true;
+}
+
+uint8_t crc8(const uint8_t *buf, unsigned int len)
+{
+	uint8_t sum = 0;
+	int i;
+
+
+	xx_assert(crc8_initialized);
+
+
+	for (i = 0; i < len; i++)
+		sum = crc8_table[sum ^ buf[i]];
+
+	return sum;
+}
diff --git a/drivers/staging/fsl_dpa_offload/crc8.h b/drivers/staging/fsl_dpa_offload/crc8.h
new file mode 100644
index 0000000..65b024a
--- /dev/null
+++ b/drivers/staging/fsl_dpa_offload/crc8.h
@@ -0,0 +1,56 @@
+
+/* Copyright 2008-2012 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * Interface of the public CRC8 checksum
+ */
+
+#ifndef __CRC8_H
+#define __CRC8_H
+
+
+#include "linux/types.h"
+
+
+#define CRC8_STANDARD_POLY			0xd5
+#define CRC8_CCITT_POLY				0x07
+#define CRC8_DALLAS_MAXIM_POLY			0x31
+#define CRC8_SAE_J1850_POLY			0x1d
+#define CRC8_WCDMA_POLY				0x9b
+
+
+void	init_crc8_table(uint8_t polynomial);
+
+uint8_t	crc8(const uint8_t *buf, unsigned int len);
+
+
+#endif /* __CRC8_H */
diff --git a/drivers/staging/fsl_dpa_offload/dpa_classifier.c b/drivers/staging/fsl_dpa_offload/dpa_classifier.c
new file mode 100644
index 0000000..15bd321
--- /dev/null
+++ b/drivers/staging/fsl_dpa_offload/dpa_classifier.c
@@ -0,0 +1,2225 @@
+
+/* Copyright 2008-2012 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * DPA Classifier Application Programming Interface implementation
+ */
+
+/* DPA offloading layer includes */
+#include "dpa_compat.h"
+#include "dpa_classifier.h"
+#include "crc8.h"
+#include "crc64.h"
+
+/* FMD includes */
+#include "error_ext.h"
+#include "fm_pcd_ext.h"
+
+
+/*
+ * Granularity of the array mapping table descriptors to table
+ * control structures in number of elements
+ */
+#define DPA_CLS_TBL_ARRAYSIZEGRANULARITY			10
+
+#define DPA_CLS_TBL_ENTRYIDNODEMASK				0xff0000
+#define DPA_CLS_TBL_ENTRYIDINDEXMASK				0x00ffff
+#define DPA_CLS_TBL_ENTRYIDNODESHIFT				16
+
+#define ENTRY_ID_GET_NODE(entry_id)				\
+	(((entry_id) & DPA_CLS_TBL_ENTRYIDNODEMASK) >>		\
+	DPA_CLS_TBL_ENTRYIDNODESHIFT)
+
+#define ENTRY_ID_GET_INDEX(entry_id)				\
+	((entry_id) & DPA_CLS_TBL_ENTRYIDINDEXMASK)
+
+
+/* Array for mapping table descriptors to table control structures */
+static struct dpa_cls_table **table;
+/* Number of tables currently supported by the mapping array */
+static unsigned int num_tables;
+/* Number of entries currently in use in the mapping array */
+static unsigned int table_entries_in_use;
+
+
+int dpa_classif_table_create(const struct dpa_cls_tbl_params	*params,
+				int				*td)
+{
+	unsigned int i;
+	int err = 0;
+	struct dpa_cls_table *ptable;
+
+	xx_sanity_check_return_value(params, "params", -EINVAL);
+	xx_sanity_check_return_value(td, "td", -EINVAL);
+
+	err = verify_table_params(params);
+	if (err < 0)
+		return err;
+
+	if (get_new_table_descriptor(td) < 0) {
+		err = extend_table_array();
+		if (err < 0)
+			return err;
+
+		/*
+		 * If extending the table was successful it is impossible for
+		 * the following function to fail
+		 */
+		get_new_table_descriptor(td);
+	}
+
+	ptable = (struct dpa_cls_table *)
+			xx_zalloc(sizeof(struct dpa_cls_table));
+	if (!ptable) {
+		xx_pr_err(("No more memory for DPA classifier table."));
+		err = -ENOMEM;
+		goto dpa_classif_table_create_error;
+	}
+
+	/* Copy over the table params into the control block */
+	memcpy(&ptable->params, params, sizeof(struct dpa_cls_tbl_params));
+
+	switch (ptable->params.type) {
+	case DPA_CLS_TBL_INDEXED:
+		ptable->int_cc_nodes_count = 1;
+		if (ptable->params.entry_mgmt ==
+				DPA_CLS_TBL_MANAGE_BY_KEY) {
+			/*
+			 * Allocate shadow table depending on the type of
+			 * classifier table
+			 */
+			/*
+			 * Shadow table is directly indexed with the index in
+			 * the entry key
+			 */
+			ptable->num_shadow_tables = 1;
+			ptable->shadow_table =
+				(struct dpa_cls_tbl_shadow_table *)
+				xx_zalloc(sizeof(struct
+						dpa_cls_tbl_shadow_table));
+			if (!ptable->shadow_table) {
+				xx_pr_err(("No more memory for DPA classifier shadow table."));
+				err = -ENOMEM;
+				goto dpa_classif_table_create_error;
+			}
+
+			/* Set shadow table size */
+			ptable->shadow_table->size =
+				ptable->params.indexed_params.entries_cnt;
+		}
+		err = table_init_indexed(ptable);
+		if (err < 0)
+			goto dpa_classif_table_create_error;
+		break;
+
+	case DPA_CLS_TBL_EXACT_MATCH:
+		ptable->int_cc_nodes_count = (unsigned int)
+			ptable->params.exact_match_params.entries_cnt /
+			DPA_CLS_TBL_MAXSHADOWTABLESIZE + 1;
+		if (ptable->params.entry_mgmt ==
+				DPA_CLS_TBL_MANAGE_BY_KEY) {
+			/*
+			 * Allocate shadow table depending on the type of
+			 * classifier table
+			 */
+			/*
+			 * Calculate the number of shadow tables necessary for
+			 * the provided number of entries
+			 */
+			ptable->num_shadow_tables =
+				ptable->int_cc_nodes_count;
+			ptable->shadow_table =
+				(struct dpa_cls_tbl_shadow_table *)
+				xx_zalloc(ptable->num_shadow_tables *
+				sizeof(struct dpa_cls_tbl_shadow_table));
+			if (!ptable->shadow_table) {
+				xx_pr_err(("No more memory for DPA classifier shadow table."));
+				err = -ENOMEM;
+				goto dpa_classif_table_create_error;
+			}
+
+			/* Set shadow table sizes */
+			for (i = 0; i < ptable->num_shadow_tables; i++)
+				ptable->shadow_table[i].size =
+					DPA_CLS_TBL_MAXSHADOWTABLESIZE;
+		}
+		err = table_init_exact_match(ptable);
+		if (err < 0)
+			goto dpa_classif_table_create_error;
+		break;
+
+	case DPA_CLS_TBL_HASH:
+		ptable->int_cc_nodes_count =
+			ptable->params.hash_params.num_sets;
+		if (ptable->params.entry_mgmt ==
+				DPA_CLS_TBL_MANAGE_BY_KEY) {
+			/*
+			 * Allocate shadow table depending on the type of
+			 * classifier table
+			 */
+			/* Shadow table is indexed using a HASH on the key */
+			ptable->num_shadow_tables = 1;
+			ptable->shadow_table =
+				(struct dpa_cls_tbl_shadow_table *)
+				xx_zalloc(sizeof(struct
+						dpa_cls_tbl_shadow_table));
+			if (!ptable->shadow_table) {
+				xx_pr_err(("No more memory for DPA classifier shadow table."));
+				err = -ENOMEM;
+				goto dpa_classif_table_create_error;
+			}
+
+			/* Set shadow table size */
+			ptable->shadow_table->size =
+					DPA_CLS_TBL_MAXSHADOWTABLESIZE;
+		}
+		err = table_init_hash(ptable);
+		if (err < 0)
+			goto dpa_classif_table_create_error;
+		break;
+	}
+
+	/* Init shadow tables if necessary */
+	if (ptable->num_shadow_tables) {
+		err = init_shadow_tables(ptable);
+		if (err < 0)
+			goto dpa_classif_table_create_error;
+	}
+
+	/* Miss action is drop by default */
+	ptable->miss_next_engine_params.nextEngine = e_FM_PCD_DONE;
+	ptable->miss_next_engine_params.params.enqueueParams.action	=
+		e_FM_PCD_DROP_FRAME;
+	ptable->miss_next_engine_params.params.enqueueParams.statisticsEn =
+		TRUE;
+
+	table[*td] = ptable;
+	init_crc8_table(CRC8_WCDMA_POLY);
+
+	return err;
+
+dpa_classif_table_create_error:
+	/* Something went wrong. Release allocated memory and exit */
+	if (ptable) {
+		if (ptable->shadow_table)
+			xx_free(ptable->shadow_table);
+
+		xx_free(ptable);
+		put_table_descriptor(*td);
+	}
+
+	return err;
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_create);
+
+int dpa_classif_table_free(int td)
+{
+	int err;
+	struct dpa_cls_table *ptable;
+
+	xx_sanity_check_return_value((td < num_tables), "td", -EINVAL);
+	xx_sanity_check_return_value(table[td], "td", -EINVAL);
+
+	ptable = table[td];
+
+	/* Flush the entries in the table */
+	err = dpa_classif_table_flush(td);
+
+	/* Check shadow table if it exists */
+	if (ptable->shadow_table) {
+
+		/* Release shadow table */
+		free_shadow_tables(ptable);
+		xx_free(ptable->shadow_table);
+	}
+
+	switch (ptable->params.type) {
+	case DPA_CLS_TBL_EXACT_MATCH:
+		table_cleanup_exact_match(ptable);
+		break;
+	case DPA_CLS_TBL_INDEXED:
+		table_cleanup_indexed(ptable);
+		break;
+	case DPA_CLS_TBL_HASH:
+		table_cleanup_hash(ptable);
+		break;
+	}
+
+	free_table_management(ptable);
+
+	xx_free(table[td]);
+
+	put_table_descriptor(td);
+
+	return err;
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_free);
+
+int dpa_classif_table_modify_miss_action(int			td,
+				const struct dpa_cls_tbl_action	*miss_action)
+{
+	int errno;
+	t_Error err;
+	t_FmPcdCcNextEngineParams miss_engine_params;
+	unsigned int i;
+	struct dpa_cls_table *ptable;
+	t_Handle fm_pcd;
+
+	xx_sanity_check_return_value((td < num_tables), "td", -EINVAL);
+	xx_sanity_check_return_value(table[td], "td", -EINVAL);
+	xx_sanity_check_return_value(miss_action, "miss_action", -EINVAL);
+
+	ptable = table[td];
+
+	if (ptable->params.type == DPA_CLS_TBL_INDEXED) {
+		xx_pr_err(("Miss Action for DPA Classifier Indexed Tables is not supported."));
+		return -ENOSYS;
+	}
+
+	/* Fill the [miss_engine_params] structure w/ data */
+	errno = action_to_next_engine_params(miss_action, &miss_engine_params);
+	if (errno < 0)
+		return errno;
+
+	fm_pcd = (t_Handle)ptable->params.fm_pcd;
+	if (ptable->params.type == DPA_CLS_TBL_HASH) {
+		/*
+		 * Set the next engine params for all the sets of the HASH
+		 * table
+		 */
+		for (i = 0; i < ptable->params.hash_params.num_sets; i++) {
+			err = FM_PCD_CcNodeModifyMissNextEngine(fm_pcd,
+				(t_Handle)ptable->int_cc_node[i].cc_node,
+				&miss_engine_params);
+			if (err != E_OK) {
+				xx_pr_fmd_err(err,
+					"FM_PCD_CcNodeModifyMissNextEngine");
+				xx_pr_err(("FMan driver call failed."));
+				return -EBUSY;
+			}
+		}
+	} else {
+		/*
+		 * For exact match tables, the miss action is updated on the
+		 * last USED Cc node in the chain
+		 */
+		for (i = 0; i < ptable->int_cc_nodes_count; i++) {
+			if (!ptable->int_cc_node[i].used)
+				break;
+		}
+
+		/*
+		 * If none of the Cc nodes are used, adjust the index so that
+		 * the miss action is configured on the first table.
+		 */
+		if (i == 0)
+			i = 1;
+
+		err = FM_PCD_CcNodeModifyMissNextEngine(fm_pcd,
+			(t_Handle)ptable->int_cc_node[i-1].cc_node,
+			&miss_engine_params);
+		if (err != E_OK) {
+			xx_pr_fmd_err(err, "FM_PCD_CcNodeModifyMissNextEngine");
+			xx_pr_err(("FMan driver call failed."));
+			return -EBUSY;
+		}
+	}
+
+	/* Store the miss next engine params */
+	memcpy(&ptable->miss_next_engine_params, &miss_engine_params,
+		sizeof(t_FmPcdCcNextEngineParams));
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_modify_miss_action);
+
+int dpa_classif_table_insert_entry(int				td,
+				const struct dpa_cls_tbl_key	*key,
+				const struct dpa_cls_tbl_action *action,
+				int				priority,
+				int				*entry_id)
+{
+	int errno;
+
+	xx_sanity_check_return_value((td < num_tables), "td", -EINVAL);
+	xx_sanity_check_return_value(table[td], "td", -EINVAL);
+	xx_sanity_check_return_value(key, "key", -EINVAL);
+	xx_sanity_check_return_value(action, "action", -EINVAL);
+
+	/*
+	 * Verify if there is already an entry in the table which conflicts with
+	 * this one (this verification is only possible if a shadow table is
+	 * used)
+	 */
+	if ((table[td]->shadow_table) &&
+			(find_shadow_entry(table[td], key) != NULL)) {
+		xx_pr_err(("DPA Classifier table entry already exists."));
+		return -EEXIST;
+	}
+
+	switch (table[td]->params.type) {
+	case DPA_CLS_TBL_INDEXED:
+		errno = table_insert_entry_indexed(table[td],
+						key,
+						action,
+						entry_id);
+		if (errno < 0)
+			return errno;
+		break;
+	case DPA_CLS_TBL_HASH:
+		errno = table_insert_entry_hash(table[td],
+						key,
+						action,
+						entry_id);
+		if (errno < 0)
+			return errno;
+		break;
+	case DPA_CLS_TBL_EXACT_MATCH:
+		errno = table_insert_entry_exact_match(table[td],
+						key,
+						action,
+						entry_id);
+		if (errno < 0)
+			return errno;
+		break;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_insert_entry);
+
+int dpa_classif_table_modify_entry_by_key(int			td,
+		const struct dpa_cls_tbl_key			*key,
+		const struct dpa_cls_tbl_entry_mod_params	*mod_params)
+{
+	struct list_head *list_entry;
+	struct dpa_cls_tbl_shadow_entry *shadow_entry;
+	int entry_id;
+
+	xx_sanity_check_return_value((td < num_tables), "td", -EINVAL);
+	xx_sanity_check_return_value(table[td], "td", -EINVAL);
+	xx_sanity_check_return_value(key, "key", -EINVAL);
+	xx_sanity_check_return_value(mod_params, "mod_params", -EINVAL);
+
+	/* Check for shadow table */
+	if (!table[td]->shadow_table) {
+		xx_pr_err(("Cannot modify entry by key in a DPA_CLS_TBL_MANAGE_BY_REF table."));
+		return -ENOSYS;
+	}
+
+	/* Check for unsupported modifications */
+	if ((mod_params->type != DPA_CLS_TBL_MODIFY_ACTION) &&
+		(table[td]->params.type != DPA_CLS_TBL_EXACT_MATCH)) {
+		xx_pr_err(("Modify entry key is supported only on exact match tables."));
+		return -ENOSYS;
+	}
+
+	/* Find the shadow entry associated with this key */
+	list_entry = find_shadow_entry(table[td], key);
+	if (list_entry == NULL) {
+		xx_pr_err(("DPA Classifier table entry not found."));
+		return -ENODEV;
+	}
+
+	if (table[td]->params.type == DPA_CLS_TBL_INDEXED)
+		entry_id = key->byte[0];
+	else {
+		shadow_entry = list_entry(list_entry,
+				struct dpa_cls_tbl_shadow_entry,
+				list_node);
+		entry_id = shadow_entry->entry_id;
+	}
+
+	return dpa_classif_table_modify_entry_by_ref(td, entry_id, mod_params);
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_modify_entry_by_key);
+
+int dpa_classif_table_modify_entry_by_ref(int			td,
+		int						entry_id,
+		const struct dpa_cls_tbl_entry_mod_params	*mod_params)
+{
+	struct dpa_cls_tbl_shadow_entry *shadow_entry;
+	struct dpa_cls_tbl_shadow_entry_indexed *shadow_entry_indexed;
+	struct dpa_cls_tbl_action *action;
+	struct dpa_cls_tbl_key *key;
+	t_FmPcdCcNextEngineParams next_engine_params;
+	t_FmPcdCcKeyParams key_params;
+	uint8_t key_data[DPA_CLS_TBL_MAXENTRYKEYSIZE];
+	uint8_t mask_data[DPA_CLS_TBL_MAXENTRYKEYSIZE];
+	uint8_t entry_index;
+	unsigned int cc_node_index;
+	int errno;
+	t_Error err;
+	struct dpa_cls_table *ptable;
+	t_Handle fm_pcd, cc_node;
+	uint8_t index;
+	struct list_head *bucket_head;
+
+	xx_sanity_check_return_value((td < num_tables), "td", -EINVAL);
+	xx_sanity_check_return_value(table[td], "td", -EINVAL);
+	xx_sanity_check_return_value(mod_params, "mod_params", -EINVAL);
+
+	/* Check for unsupported modifications */
+	if ((mod_params->type != DPA_CLS_TBL_MODIFY_ACTION) &&
+			(table[td]->params.type != DPA_CLS_TBL_EXACT_MATCH)) {
+		xx_pr_err(("Modify entry key is supported only on exact match tables."));
+		return -ENOSYS;
+	}
+
+	ptable = table[td];
+	if (ptable->params.type == DPA_CLS_TBL_INDEXED) {
+		cc_node_index	= 0;
+		entry_index	= (uint8_t)entry_id;
+	} else {
+		cc_node_index	= ENTRY_ID_GET_NODE(entry_id);
+		entry_index	= (uint8_t)ENTRY_ID_GET_INDEX(entry_id);
+	}
+
+	xx_sanity_check_return_value((cc_node_index <
+				ptable->int_cc_nodes_count),
+			"entry_id",
+			-EINVAL);
+	xx_sanity_check_return_value((entry_index <
+				ptable->int_cc_node[cc_node_index].table_size),
+			"entry_id",
+			-EINVAL);
+
+	fm_pcd	= (t_Handle)ptable->params.fm_pcd;
+	cc_node	= (t_Handle)ptable->int_cc_node[cc_node_index].cc_node;
+	index	= ptable->int_cc_node[cc_node_index].entry[entry_index].
+								entry_index;
+	switch (mod_params->type) {
+	case DPA_CLS_TBL_MODIFY_ACTION:
+		errno = action_to_next_engine_params(mod_params->action,
+						&next_engine_params);
+		if (errno < 0)
+			return errno;
+
+		err = FM_PCD_CcNodeModifyNextEngine(fm_pcd,
+						cc_node,
+						index,
+						&next_engine_params);
+		if (err != E_OK) {
+			xx_pr_fmd_err(err, "FM_PCD_CcNodeModifyNextEngine");
+			xx_pr_err(("FMan driver call failed."));
+			return -EBUSY;
+		}
+
+		break;
+	case DPA_CLS_TBL_MODIFY_KEY:
+		/* Only exact match tables support this type of modification. */
+		/*
+		 * Have to copy the data from the key and mask because the FMD
+		 * is not using const pointers and we cannot provide it the
+		 * const pointers that the user provided.
+		 */
+		memset(key_data, 0, DPA_CLS_TBL_MAXENTRYKEYSIZE);
+		memset(mask_data, 0, DPA_CLS_TBL_MAXENTRYKEYSIZE);
+		memcpy(key_data,
+			mod_params->key->byte,
+			ptable->params.exact_match_params.key_size);
+		memcpy(mask_data,
+			mod_params->key->mask,
+			ptable->params.exact_match_params.key_size);
+
+		err = FM_PCD_CcNodeModifyKey(fm_pcd,
+				cc_node,
+				index,
+				ptable->params.exact_match_params.key_size,
+				key_data,
+				mask_data);
+		if (err != E_OK) {
+			xx_pr_fmd_err(err, "FM_PCD_CcNodeModifyNextEngine");
+			xx_pr_err(("FMan driver call failed."));
+			return -EBUSY;
+		}
+
+		break;
+	case DPA_CLS_TBL_MODIFY_KEY_AND_ACTION:
+		/* Only exact match tables support this type of modification. */
+
+		errno = action_to_next_engine_params(mod_params->action,
+						&key_params.ccNextEngineParams);
+		if (errno < 0)
+			return errno;
+
+		/*
+		 * Have to copy the data from the key and mask because the FMD
+		 * is not using const pointers and we cannot provide it the
+		 * const pointers that the user provided.
+		 */
+		memset(key_data, 0, DPA_CLS_TBL_MAXENTRYKEYSIZE);
+		memset(mask_data, 0, DPA_CLS_TBL_MAXENTRYKEYSIZE);
+		memcpy(key_data,
+			mod_params->key->byte,
+			ptable->params.exact_match_params.key_size);
+		memcpy(mask_data,
+			mod_params->key->mask,
+			ptable->params.exact_match_params.key_size);
+
+		key_params.p_Key	= key_data;
+		key_params.p_Mask	= mask_data;
+
+		err = FM_PCD_CcNodeModifyKeyAndNextEngine(fm_pcd,
+				cc_node,
+				index,
+				ptable->params.exact_match_params.key_size,
+				&key_params);
+		if (err != E_OK) {
+			xx_pr_fmd_err(err,
+				"FM_PCD_CcNodeModifyKeyAndNextEngine");
+			xx_pr_err(("FMan driver call failed."));
+			return -EBUSY;
+		}
+
+		break;
+	}
+
+	/* If a shadow table exists, update the data in the shadow table */
+	if (ptable->shadow_table) {
+		if (ptable->params.type == DPA_CLS_TBL_INDEXED) {
+
+			bucket_head =
+				ptable->shadow_table[0].
+					shadow_entry[entry_index].next;
+			shadow_entry_indexed = list_entry(bucket_head,
+				struct dpa_cls_tbl_shadow_entry_indexed,
+				list_node);
+
+			key	= NULL;
+			action	= &shadow_entry_indexed->action;
+		} else {
+
+			bucket_head =
+				ptable->int_cc_node[cc_node_index].
+					entry[entry_index].shadow_entry;
+			shadow_entry = list_entry(bucket_head,
+					struct dpa_cls_tbl_shadow_entry,
+					list_node);
+
+			key	= &shadow_entry->key;
+			action	= &shadow_entry->action;
+		}
+
+
+		if ((mod_params->type == DPA_CLS_TBL_MODIFY_KEY) ||
+			(mod_params->type == DPA_CLS_TBL_MODIFY_KEY_AND_ACTION))
+			memcpy(key->byte,
+				mod_params->key->byte,
+				ptable->params.exact_match_params.key_size);
+
+		if ((mod_params->type == DPA_CLS_TBL_MODIFY_ACTION) ||
+			(mod_params->type == DPA_CLS_TBL_MODIFY_KEY_AND_ACTION))
+			memcpy(action,
+				mod_params->action,
+				sizeof(struct dpa_cls_tbl_action));
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_modify_entry_by_ref);
+
+int dpa_classif_table_delete_entry_by_key(int				td,
+					const struct dpa_cls_tbl_key	*key)
+{
+	struct list_head *list_entry;
+	int entry_id;
+	struct dpa_cls_tbl_shadow_entry *shadow_entry;
+
+	xx_sanity_check_return_value((td < num_tables), "td", -EINVAL);
+	xx_sanity_check_return_value(table[td], "td", -EINVAL);
+	xx_sanity_check_return_value(key, "key", -EINVAL);
+
+	if (!table[td]->shadow_table) {
+		xx_pr_err(("Cannot delete entry by key in a DPA_CLS_TBL_MANAGE_BY_REF table."));
+		return -ENOSYS;
+	}
+
+	/* Find the shadow entry associated with this key */
+	list_entry = find_shadow_entry(table[td], key);
+	if (list_entry == NULL) {
+		xx_pr_err(("DPA Classifier table entry not found."));
+		return -ENODEV;
+	}
+
+	if (table[td]->params.type == DPA_CLS_TBL_INDEXED)
+		entry_id = key->byte[0];
+	else {
+		shadow_entry = list_entry(list_entry,
+					struct dpa_cls_tbl_shadow_entry,
+					list_node);
+		entry_id = shadow_entry->entry_id;
+	}
+
+	return dpa_classif_table_delete_entry_by_ref(td, entry_id);
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_delete_entry_by_key);
+
+int dpa_classif_table_delete_entry_by_ref(int td, int entry_id)
+{
+	t_Error err;
+	t_FmPcdCcNextEngineParams next_engine_params;
+	struct dpa_cls_tbl_shadow_entry *shadow_entry;
+	struct dpa_cls_tbl_shadow_entry_indexed *shadow_entry_indexed;
+	uint8_t entry_index;
+	unsigned int i, cc_node_index;
+	struct dpa_cls_table *ptable;
+	t_Handle fm_pcd, cc_node;
+	uint8_t index;
+	struct list_head *bucket_head;
+	struct dpa_cls_tbl_cc_node_info *int_cc_node;
+
+	xx_sanity_check_return_value((td < num_tables), "td", -EINVAL);
+	xx_sanity_check_return_value(table[td], "td", -EINVAL);
+
+	ptable = table[td];
+
+	if (ptable->params.type == DPA_CLS_TBL_INDEXED) {
+		cc_node_index	= 0;
+		entry_index	= (uint8_t)entry_id;
+	} else {
+		cc_node_index	= ENTRY_ID_GET_NODE(entry_id);
+		entry_index	= (uint8_t)ENTRY_ID_GET_INDEX(entry_id);
+	}
+
+	xx_sanity_check_return_value((cc_node_index <
+				ptable->int_cc_nodes_count),
+			"entry_id",
+			-EINVAL);
+
+	xx_sanity_check_return_value((entry_index <
+				ptable->int_cc_node[cc_node_index].table_size),
+			"entry_id",
+			-EINVAL);
+
+	fm_pcd	= (t_Handle)ptable->params.fm_pcd;
+	cc_node	= (t_Handle)ptable->int_cc_node[cc_node_index].cc_node;
+	int_cc_node = &ptable->int_cc_node[cc_node_index];
+	if (ptable->params.type == DPA_CLS_TBL_INDEXED) {
+		/*
+		 * Cannot remove an entry from an indexed table. We will
+		 * replace it with DROP
+		 */
+		memset(&next_engine_params, 0,
+			sizeof(t_FmPcdCcNextEngineParams));
+		next_engine_params.nextEngine = e_FM_PCD_DONE;
+		next_engine_params.params.enqueueParams.action =
+			e_FM_PCD_DROP_FRAME;
+		next_engine_params.params.enqueueParams.statisticsEn = FALSE;
+		err = FM_PCD_CcNodeModifyNextEngine(fm_pcd,
+						cc_node,
+						entry_index,
+						&next_engine_params);
+		if (err != E_OK) {
+			xx_pr_fmd_err(err, "FM_PCD_CcNodeModifyNextEngine");
+			xx_pr_err(("FMan driver call failed."));
+			return -EBUSY;
+		}
+
+		/* No indexes updates are necessary for the indexed table */
+	} else {
+		/* For all the other tables types we can remove the key */
+
+		index = int_cc_node->entry[entry_index].entry_index;
+		err = FM_PCD_CcNodeRemoveKey(fm_pcd,
+					cc_node,
+					index);
+		if (err != E_OK) {
+			xx_pr_fmd_err(err, "FM_PCD_CcNodeRemoveKey");
+			xx_pr_err(("FMan driver call failed."));
+			return -EBUSY;
+		}
+
+
+		/*
+		 * Update the index management for the Cc node that this entry
+		 * was removed from. The linked lists were allowing us to
+		 * process only the entries with higher indexes than the one
+		 * that was removed. Arrays are forcing us to process the
+		 * entire set of entries (because they are not sorted in any
+		 * way).
+		 */
+	for (i = 0; i < int_cc_node->table_size; i++) {
+		if ((int_cc_node->entry[i].valid) &&
+			(int_cc_node->entry[i].entry_index >
+				int_cc_node->entry[entry_index].entry_index))
+				int_cc_node->entry[i].entry_index--;
+	}
+
+		int_cc_node->entry[entry_index].valid = false;
+	}
+	int_cc_node->used--;
+
+	if (ptable->num_shadow_tables) {
+		if (ptable->params.type == DPA_CLS_TBL_INDEXED) {
+
+			bucket_head = ptable->shadow_table[0].
+					shadow_entry[entry_index].next;
+			shadow_entry_indexed = list_entry(bucket_head,
+					struct dpa_cls_tbl_shadow_entry_indexed,
+					list_node);
+
+			list_del(&shadow_entry_indexed->list_node);
+
+			xx_free(shadow_entry_indexed);
+		} else {
+
+			bucket_head = ptable->int_cc_node[cc_node_index].
+					entry[entry_index].shadow_entry,
+			shadow_entry = list_entry(bucket_head,
+						struct dpa_cls_tbl_shadow_entry,
+						list_node);
+
+			list_del(&shadow_entry->list_node);
+
+			xx_free(shadow_entry);
+		}
+
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_delete_entry_by_ref);
+
+int dpa_classif_table_lookup_by_key(int				td,
+				const struct dpa_cls_tbl_key	*key,
+				struct dpa_cls_tbl_action	*action)
+{
+	struct list_head *pos;
+	struct dpa_cls_tbl_shadow_entry *shadow_entry;
+	struct dpa_cls_tbl_shadow_entry_indexed *shadow_entry_indexed;
+
+	xx_sanity_check_return_value((td < num_tables), "td", -EINVAL);
+	xx_sanity_check_return_value(table[td], "td", -EINVAL);
+	xx_sanity_check_return_value(key, "key", -EINVAL);
+	xx_sanity_check_return_value(action, "action", -EINVAL);
+
+	if (!table[td]->shadow_table) {
+		xx_pr_err(("Cannot lookup in a DPA_CLS_TBL_MANAGE_BY_REF table."));
+		return -ENOSYS;
+	}
+
+	pos = find_shadow_entry(table[td], key);
+	if (!pos)
+		return -ENODEV;
+
+	if (table[td]->params.type == DPA_CLS_TBL_INDEXED) {
+		shadow_entry_indexed = list_entry(pos,
+					struct dpa_cls_tbl_shadow_entry_indexed,
+					list_node);
+		memcpy(action, &shadow_entry_indexed->action,
+			sizeof(struct dpa_cls_tbl_action));
+	} else {
+		shadow_entry = list_entry(pos,
+					struct dpa_cls_tbl_shadow_entry,
+					list_node);
+		memcpy(action, &shadow_entry->action,
+			sizeof(struct dpa_cls_tbl_action));
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_lookup_by_key);
+
+int dpa_classif_table_lookup_by_ref(int				td,
+				int				entry_id,
+				struct dpa_cls_tbl_action	*action)
+{
+	struct dpa_cls_tbl_shadow_entry *shadow_entry;
+	struct dpa_cls_tbl_shadow_entry_indexed *shadow_entry_indexed;
+	unsigned int cc_node_index;
+	uint8_t entry_index;
+	struct list_head *bucket_head;
+
+	xx_sanity_check_return_value((td < num_tables), "td", -EINVAL);
+	xx_sanity_check_return_value(table[td], "td", -EINVAL);
+	xx_sanity_check_return_value(action, "action", -EINVAL);
+
+	if (!table[td]->shadow_table) {
+		xx_pr_err(("Cannot lookup in a DPA_CLS_TBL_MANAGE_BY_REF table."));
+		return -ENOSYS;
+	}
+
+	if (table[td]->params.type == DPA_CLS_TBL_INDEXED) {
+		cc_node_index	= 0;
+		entry_index	= (uint8_t)entry_id;
+	} else {
+		cc_node_index	= ENTRY_ID_GET_NODE(entry_id);
+		entry_index	= (uint8_t)ENTRY_ID_GET_INDEX(entry_id);
+	}
+
+	xx_sanity_check_return_value((cc_node_index <
+			table[td]->int_cc_nodes_count),
+		"entry_id",
+		-EINVAL);
+
+	xx_sanity_check_return_value((entry_index <
+			table[td]->int_cc_node[cc_node_index].table_size),
+		"entry_id",
+		-EINVAL);
+
+	if (table[td]->params.type == DPA_CLS_TBL_INDEXED) {
+
+		bucket_head = table[td]->shadow_table[0].
+					shadow_entry[entry_index].next;
+		shadow_entry_indexed = list_entry(bucket_head,
+					struct dpa_cls_tbl_shadow_entry_indexed,
+					list_node);
+
+		memcpy(action, &shadow_entry_indexed->action,
+			sizeof(struct dpa_cls_tbl_action));
+	} else {
+
+		bucket_head = table[td]->int_cc_node[cc_node_index].
+					entry[entry_index].shadow_entry;
+		shadow_entry = list_entry(bucket_head,
+					struct dpa_cls_tbl_shadow_entry,
+					list_node);
+
+		memcpy(action, &shadow_entry->action,
+			sizeof(struct dpa_cls_tbl_action));
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_lookup_by_ref);
+
+int dpa_classif_table_flush(int td)
+{
+	struct dpa_cls_tbl_shadow_entry *shadow_entry;
+	struct dpa_cls_tbl_shadow_entry_indexed *shadow_entry_indexed;
+	t_FmPcdCcNextEngineParams next_engine_params;
+	unsigned int i, j, k;
+	t_Error err;
+	struct dpa_cls_table *ptable;
+	t_Handle fm_pcd, cc_node;
+	uint8_t index;
+	struct list_head *bucket_head;
+	struct dpa_cls_tbl_cc_node_info *int_cc_node;
+	struct dpa_cls_tbl_shadow_table *shadow_table;
+
+	xx_sanity_check_return_value((td < num_tables), "td", -EINVAL);
+	xx_sanity_check_return_value(table[td], "td", -EINVAL);
+
+	ptable = table[td];
+	fm_pcd = (t_Handle)ptable->params.fm_pcd;
+	if (ptable->params.type == DPA_CLS_TBL_INDEXED) {
+		memset(&next_engine_params, 0,
+			sizeof(t_FmPcdCcNextEngineParams));
+		next_engine_params.nextEngine = e_FM_PCD_DONE;
+		next_engine_params.params.enqueueParams.action =
+			e_FM_PCD_DROP_FRAME;
+		next_engine_params.params.enqueueParams.statisticsEn = FALSE;
+
+		cc_node = (t_Handle)ptable->int_cc_node[0].cc_node;
+		for (i = 0; i < ptable->int_cc_node[0].table_size; i++) {
+			err = FM_PCD_CcNodeModifyNextEngine(fm_pcd,
+							cc_node,
+							(uint8_t)i,
+							&next_engine_params);
+			if (err != E_OK) {
+				xx_pr_fmd_err(err,
+					"FM_PCD_CcNodeModifyNextEngine");
+				xx_pr_err(("FMan driver call failed."));
+				return -EBUSY;
+			}
+		}
+		ptable->int_cc_node[0].used = 0;
+
+	/* Clean up shadow table if it exists */
+	if (ptable->num_shadow_tables) {
+		for (i = 0; i < ptable->int_cc_node[0].table_size; i++) {
+			shadow_table = &ptable->shadow_table[0];
+			if (!list_empty(&shadow_table->shadow_entry[i])) {
+				shadow_entry_indexed =
+					list_entry(shadow_table->
+				shadow_entry[i].next,
+				struct dpa_cls_tbl_shadow_entry_indexed,
+				list_node);
+
+				list_del(&shadow_entry_indexed->list_node);
+				xx_free(shadow_entry_indexed);
+			}
+		}
+	}
+	} else {
+		for (i = 0; i < ptable->int_cc_nodes_count; i++) {
+			cc_node = (t_Handle)ptable->int_cc_node[i].cc_node;
+			int_cc_node = &ptable->int_cc_node[i];
+			for (j = 0; j < int_cc_node->table_size; j++) {
+				if (int_cc_node->entry[j].valid) {
+					if (int_cc_node->entry[j].
+						shadow_entry) {
+						/*
+						 * Clean up shadow
+						 * entry as well
+						 */
+						bucket_head =
+					int_cc_node->entry[j].shadow_entry;
+
+						shadow_entry =
+							list_entry(bucket_head,
+					struct dpa_cls_tbl_shadow_entry,
+					list_node);
+
+						list_del(&shadow_entry->
+								list_node);
+
+						xx_free(shadow_entry);
+					}
+
+				index = int_cc_node->entry[j].entry_index;
+				err = FM_PCD_CcNodeRemoveKey(fm_pcd,
+							cc_node,
+							index);
+				if (err != E_OK) {
+					xx_pr_fmd_err(err, "FM_PCD_CcNodeRemoveKey");
+					xx_pr_err(("FMan driver call failed."));
+					return -EBUSY;
+				}
+
+				int_cc_node->used--;
+				int_cc_node->entry[j].valid = false;
+
+		/*
+		 * Update the index management for the Cc node that this entry
+		 * was removed from. The linked lists were allowing us to
+		 * process only the entries with higher indexes than the one
+		 * that was removed. Arrays are forcing us to process the
+		 * entire set of entries (because they are not sorted in any
+		 * way).
+		 */
+		for (k = 0; k < int_cc_node->table_size; k++) {
+			if ((int_cc_node->entry[k].valid) &&
+				(int_cc_node->entry[k].entry_index >
+				int_cc_node->entry[j].entry_index))
+					int_cc_node->entry[k].entry_index--;
+		}
+		}
+		}
+
+		xx_assert(int_cc_node->used == 0);
+		}
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_flush);
+
+int dpa_classif_table_get_entry_stats_by_key(int			td,
+					const struct dpa_cls_tbl_key	*key,
+					struct dpa_cls_tbl_entry_stats	*stats)
+{
+	int entry_id;
+	struct list_head *list_entry;
+	struct dpa_cls_tbl_shadow_entry *shadow_entry;
+
+	xx_sanity_check_return_value((td < num_tables), "td", -EINVAL);
+	xx_sanity_check_return_value(table[td], "td", -EINVAL);
+	xx_sanity_check_return_value(key, "key", -EINVAL);
+	xx_sanity_check_return_value(stats, "stats", -EINVAL);
+
+	if (!table[td]->shadow_table) {
+		xx_pr_err(("Cannot get stats by key in a DPA_CLS_TBL_MANAGE_BY_REF table."));
+		return -ENOSYS;
+	}
+
+	/* Find the shadow entry associated with this key */
+	list_entry = find_shadow_entry(table[td], key);
+	if (list_entry == NULL) {
+		xx_pr_err(("DPA Classifier table entry not found."));
+		return -ENODEV;
+	}
+
+	if (table[td]->params.type == DPA_CLS_TBL_INDEXED)
+		entry_id = key->byte[0];
+	else {
+		shadow_entry = list_entry(list_entry,
+					struct dpa_cls_tbl_shadow_entry,
+					list_node);
+		entry_id = shadow_entry->entry_id;
+	}
+
+	return dpa_classif_table_get_entry_stats_by_ref(td, entry_id, stats);
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_get_entry_stats_by_key);
+
+int dpa_classif_table_get_entry_stats_by_ref(int		td,
+				int				entry_id,
+				struct dpa_cls_tbl_entry_stats	*stats)
+{
+	unsigned int cc_node_index;
+	uint8_t entry_index;
+	t_Handle fm_pcd, cc_node;
+
+	xx_sanity_check_return_value((td < num_tables), "td", -EINVAL);
+	xx_sanity_check_return_value(table[td], "td", -EINVAL);
+	xx_sanity_check_return_value(stats, "stats", -EINVAL);
+
+	if (table[td]->params.type == DPA_CLS_TBL_INDEXED) {
+		cc_node_index	= 0;
+		entry_index	= (uint8_t)entry_id;
+	} else {
+		cc_node_index	= ENTRY_ID_GET_NODE(entry_id);
+		entry_index	= (uint8_t)ENTRY_ID_GET_INDEX(entry_id);
+	}
+
+	xx_sanity_check_return_value((cc_node_index <
+			table[td]->int_cc_nodes_count),
+		"entry_id",
+		-EINVAL);
+	xx_sanity_check_return_value((entry_index <
+			table[td]->int_cc_node[cc_node_index].table_size),
+		"entry_id",
+		-EINVAL);
+
+	fm_pcd = (t_Handle)table[td]->params.fm_pcd;
+	cc_node = (t_Handle)table[td]->int_cc_node[cc_node_index].cc_node;
+	stats->total_pkts = (unsigned long) FM_PCD_CcNodeGetKeyCounter(fm_pcd,
+							cc_node,
+							entry_index);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_get_entry_stats_by_ref);
+
+int dpa_classif_table_get_params(int td, struct dpa_cls_tbl_params *params)
+{
+	xx_sanity_check_return_value((td < num_tables), "td", -EINVAL);
+	xx_sanity_check_return_value(table[td], "td", -EINVAL);
+	xx_sanity_check_return_value(params, "params", -EINVAL);
+
+	memcpy(params, &table[td]->params, sizeof(struct dpa_cls_tbl_params));
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(dpa_classif_table_get_params);
+
+static int alloc_table_management(struct dpa_cls_table *cls_table)
+{
+	int err = 0;
+
+	xx_assert(cls_table);
+
+	/* Allocate the necessary table management tools */
+	cls_table->int_cc_node = (struct dpa_cls_tbl_cc_node_info *)
+		xx_zalloc(cls_table->int_cc_nodes_count *
+			sizeof(struct dpa_cls_tbl_cc_node_info));
+	if (!cls_table->int_cc_node) {
+		xx_pr_err(("No more memory for DPA Classifier table management."));
+		err = -ENOMEM;
+		goto alloc_table_mgmt_error;
+	}
+
+	return err;
+
+alloc_table_mgmt_error:
+	free_table_management(cls_table);
+
+	return err;
+}
+
+static void free_table_management(struct dpa_cls_table *cls_table)
+{
+	unsigned int i;
+
+	xx_assert(cls_table);
+
+	if (cls_table->params.type != DPA_CLS_TBL_INDEXED)
+		/* Release index management */
+		for (i = 0; i < cls_table->int_cc_nodes_count; i++) {
+			if (cls_table->int_cc_node[i].entry)
+				xx_free(cls_table->int_cc_node[i].entry);
+		}
+
+	if (cls_table->int_cc_node)
+		xx_free(cls_table->int_cc_node);
+
+	cls_table->int_cc_nodes_count = 0;
+}
+
+static int table_init_indexed(struct dpa_cls_table *cls_table)
+{
+	t_Error err;
+	int errno;
+	uint8_t i;
+	t_FmPcdCcNextEngineParams next_engine_params;
+	t_Handle fm_pcd, cc_node;
+
+	xx_assert(cls_table);
+	xx_assert(cls_table->params.type == DPA_CLS_TBL_INDEXED);
+
+	errno = alloc_table_management(cls_table);
+	if (errno < 0)
+		return errno;
+
+	/* The only managed Cc node is the one provided by the application */
+	cls_table->int_cc_node[0].cc_node = cls_table->params.cc_node;
+	cls_table->int_cc_node[0].table_size =
+		cls_table->params.indexed_params.entries_cnt;
+
+	/* Initialize all the actions in the indexed table with DROP */
+	memset(&next_engine_params, 0, sizeof(t_FmPcdCcNextEngineParams));
+	next_engine_params.nextEngine = e_FM_PCD_DONE;
+	next_engine_params.params.enqueueParams.action = e_FM_PCD_DROP_FRAME;
+
+	fm_pcd	= (t_Handle)cls_table->params.fm_pcd;
+	cc_node	= (t_Handle)cls_table->params.cc_node;
+	for (i = 0; i < cls_table->params.indexed_params.entries_cnt; i++) {
+		err = FM_PCD_CcNodeModifyNextEngine(fm_pcd,
+						cc_node,
+						i,
+						&next_engine_params);
+		if (err != E_OK) {
+			xx_pr_fmd_err(err, "FM_PCD_CcNodeModifyNextEngine");
+			xx_pr_err(("FMan driver call failed."));
+			return -EBUSY;
+		}
+	}
+
+	return 0;
+}
+
+static int table_init_hash(struct dpa_cls_table *cls_table)
+{
+	t_FmPcdCcNodeParams *hash_set_params = NULL;
+	unsigned int i;
+	int err = 0;
+	t_FmPcdCcNextEngineParams next_engine_params;
+	t_Error err_code;
+	t_Handle fm_pcd, cc_node;
+
+	xx_assert(cls_table);
+	xx_assert(cls_table->params.type == DPA_CLS_TBL_HASH);
+
+	err = alloc_table_management(cls_table);
+	if (err < 0)
+		return err;
+
+	hash_set_params = (t_FmPcdCcNodeParams *)
+		xx_zalloc(sizeof(struct t_FmPcdCcNodeParams));
+	if (!hash_set_params) {
+		xx_pr_err(("No more memory for DPA Classifier hash table."));
+		err = -ENOMEM;
+		goto table_init_hash_error;
+	}
+
+	hash_set_params->extractCcParams.type =
+		e_FM_PCD_EXTRACT_NON_HDR;
+	hash_set_params->extractCcParams.extractNonHdr.src =
+		e_FM_PCD_EXTRACT_FROM_KEY;
+	hash_set_params->extractCcParams.extractNonHdr.action =
+		e_FM_PCD_ACTION_EXACT_MATCH;
+	hash_set_params->extractCcParams.extractNonHdr.offset = 0;
+	hash_set_params->extractCcParams.extractNonHdr.size =
+		cls_table->params.hash_params.key_size;
+
+	hash_set_params->keysParams.numOfKeys = 0;
+	hash_set_params->keysParams.keySize =
+		cls_table->params.hash_params.key_size;
+	hash_set_params->keysParams.ccNextEngineParamsForMiss.nextEngine =
+		e_FM_PCD_DONE;
+	hash_set_params->keysParams.ccNextEngineParamsForMiss.params.
+		enqueueParams.action = e_FM_PCD_DROP_FRAME;
+
+	memset(&next_engine_params, 0, sizeof(next_engine_params));
+	next_engine_params.nextEngine = e_FM_PCD_CC;
+
+	fm_pcd	= (t_Handle)cls_table->params.fm_pcd;
+	cc_node	= (t_Handle)cls_table->params.cc_node;
+	for (i = 0; i < cls_table->params.hash_params.num_sets; i++) {
+		/* Create the HASH set */
+		cls_table->int_cc_node[i].cc_node =
+			(void *)FM_PCD_CcSetNode(fm_pcd,
+					hash_set_params);
+		if (cls_table->int_cc_node[i].cc_node == NULL) {
+			xx_pr_fmd_err(E_NOT_AVAILABLE, "FM_PCD_CcSetNode");
+			xx_pr_err(("FMan driver call failed."));
+			err = -EBUSY;
+			goto table_init_hash_error;
+		}
+		cls_table->int_cc_node[i].table_size =
+			cls_table->params.hash_params.max_ways;
+
+		/* Link the HASH set into the initial Cc node */
+		next_engine_params.params.ccParams.h_CcNode =
+			(t_Handle)cls_table->int_cc_node[i].cc_node;
+		err_code = FM_PCD_CcNodeModifyNextEngine(fm_pcd,
+						cc_node,
+						(uint8_t)i,
+						&next_engine_params);
+		if (err_code != E_OK) {
+			xx_pr_fmd_err(err_code,
+				"FM_PCD_CcNodeModifyNextEngine");
+			xx_pr_err(("FMan driver call failed."));
+			err = -EBUSY;
+			goto table_init_hash_error;
+		}
+
+		/* Allocate the index management array */
+		cls_table->int_cc_node[i].entry = (struct dpa_cls_tbl_entry *)
+			xx_zalloc(cls_table->int_cc_node[i].table_size *
+				sizeof(struct dpa_cls_tbl_entry));
+		if (!cls_table->int_cc_node[i].entry) {
+			xx_pr_err(("No more memory for DPA Classifier table index management."));
+			err = -ENOMEM;
+			goto table_init_hash_error;
+		}
+	}
+
+	cls_table->hash_mask =
+		(uint64_t)(cls_table->params.hash_params.num_sets - 1) <<
+		(8 * (6 - cls_table->params.hash_params.hash_offs) + 4) ;
+
+	xx_free(hash_set_params);
+
+	return err;
+
+table_init_hash_error:
+	if (hash_set_params)
+		xx_free(hash_set_params);
+
+	table_cleanup_hash(cls_table);
+
+	free_table_management(cls_table);
+
+	return err;
+}
+
+static int table_init_exact_match(struct dpa_cls_table *cls_table)
+{
+	int err = 0;
+	t_FmPcdCcNodeParams *cc_node_params = NULL;
+	unsigned int i;
+	t_Handle fm_pcd;
+
+	xx_assert(cls_table);
+	xx_assert(cls_table->params.type == DPA_CLS_TBL_EXACT_MATCH);
+
+	err = alloc_table_management(cls_table);
+	if (err < 0)
+		return err;
+
+	/* First Cc node is the one that the user provided */
+	cls_table->int_cc_node[0].cc_node = cls_table->params.cc_node;
+
+	/* Create additional Cc nodes if necessary */
+	cc_node_params = (t_FmPcdCcNodeParams *)
+		xx_zalloc(sizeof(t_FmPcdCcNodeParams));
+	if (!cc_node_params) {
+		xx_pr_err(("No more memory for DPA Classifier exact match table."));
+		err = -ENOMEM;
+		goto table_init_exact_match_error;
+	}
+	cc_node_params->keysParams.numOfKeys = 0;
+	cc_node_params->keysParams.keySize =
+		cls_table->params.exact_match_params.key_size;
+	cc_node_params->keysParams.ccNextEngineParamsForMiss.nextEngine =
+		e_FM_PCD_DONE;
+	cc_node_params->keysParams.ccNextEngineParamsForMiss.params.
+		enqueueParams.action = e_FM_PCD_DROP_FRAME;
+
+	cc_node_params->extractCcParams.type =
+		e_FM_PCD_EXTRACT_NON_HDR;
+	cc_node_params->extractCcParams.extractNonHdr.src =
+		e_FM_PCD_EXTRACT_FROM_KEY;
+	cc_node_params->extractCcParams.extractNonHdr.action =
+		e_FM_PCD_ACTION_EXACT_MATCH;
+	cc_node_params->extractCcParams.extractNonHdr.offset = 0;
+	cc_node_params->extractCcParams.extractNonHdr.size =
+		cls_table->params.exact_match_params.key_size;
+
+	fm_pcd = (t_Handle)cls_table->params.fm_pcd;
+	for (i = 0; i < cls_table->int_cc_nodes_count; i++) {
+		if (i > 0) { /* First node provided by user. Doesn't need to be
+				* created */
+			/* Dynamically create Cc node */
+			cls_table->int_cc_node[i].cc_node =
+				(void *)FM_PCD_CcSetNode(fm_pcd,
+					cc_node_params);
+			if (!cls_table->int_cc_node[i].cc_node) {
+				xx_pr_fmd_err(E_NOT_AVAILABLE,
+					"FM_PCD_CcSetNode");
+				xx_pr_err(("FMan driver call failed."));
+				err = -EBUSY;
+				goto table_init_exact_match_error;
+			}
+		}
+
+		/* Set the table size */
+		if (i < (cls_table->int_cc_nodes_count - 1))
+			cls_table->int_cc_node[i].table_size =
+				FM_PCD_MAX_NUM_OF_KEYS;
+		else
+			cls_table->int_cc_node[i].table_size =
+			cls_table->params.exact_match_params.entries_cnt -
+			(i * FM_PCD_MAX_NUM_OF_KEYS);
+
+		/* Allocate the index management array */
+		cls_table->int_cc_node[i].entry = (struct dpa_cls_tbl_entry *)
+			xx_zalloc(cls_table->int_cc_node[i].table_size *
+			sizeof(struct dpa_cls_tbl_entry));
+		if (!cls_table->int_cc_node[i].entry) {
+			xx_pr_err(("No more memory for DPA Classifier table index management."));
+			err = -ENOMEM;
+			goto table_init_exact_match_error;
+		}
+	}
+
+	xx_free(cc_node_params);
+
+	return err;
+
+table_init_exact_match_error:
+	if (cc_node_params)
+		xx_free(cc_node_params);
+
+	table_cleanup_exact_match(cls_table);
+
+	free_table_management(cls_table);
+
+	return err;
+}
+
+static void table_cleanup_hash(struct dpa_cls_table *cls_table)
+{
+	t_FmPcdCcNextEngineParams next_engine_params;
+	unsigned int i;
+	t_Error err;
+	t_Handle fm_pcd;
+
+	xx_assert(cls_table);
+	xx_assert(cls_table->params.type == DPA_CLS_TBL_HASH);
+
+	fm_pcd = (t_Handle)cls_table->params.fm_pcd;
+	for (i = 0; (i < cls_table->int_cc_nodes_count) &&
+			(cls_table->int_cc_node[i].cc_node); i++) {
+		/*
+		 * Remove entry in the initial Cc node which points to the
+		 * current node
+		 */
+		memset(&next_engine_params, 0, sizeof(next_engine_params));
+		next_engine_params.nextEngine = e_FM_PCD_DONE;
+		next_engine_params.params.enqueueParams.action =
+			e_FM_PCD_DROP_FRAME;
+
+		/*
+		 * We can only delete nodes if the miss action of the initial
+		 * node doesn't point to the dynamic Cc node chain
+		 */
+		err = FM_PCD_CcNodeModifyNextEngine(fm_pcd,
+				(t_Handle)cls_table->params.cc_node,
+				(uint8_t)i,
+				&next_engine_params);
+		if (err == E_OK)
+			FM_PCD_CcDeleteNode(fm_pcd,
+				(t_Handle)cls_table->int_cc_node[i].cc_node);
+		else {
+			xx_pr_fmd_err(err, "FM_PCD_CcNodeModifyNextEngine");
+			xx_pr_err(("FMan driver call failed."));
+			xx_pr_warn(("DPA Classifier failed to clean up hash table."));
+		}
+	}
+}
+
+static void table_cleanup_indexed(struct dpa_cls_table *cls_table)
+{
+	/* Nothing to do in this case */
+	return;
+}
+
+static void table_cleanup_exact_match(struct dpa_cls_table *cls_table)
+{
+	t_FmPcdCcNextEngineParams cc_miss_engine_params;
+	unsigned int i;
+	t_Error err;
+	t_Handle fm_pcd;
+
+	xx_assert(cls_table);
+	xx_assert(cls_table->params.type == DPA_CLS_TBL_EXACT_MATCH);
+
+	/* Uncouple the first Cc node from the initial one */
+	memset(&cc_miss_engine_params, 0, sizeof(cc_miss_engine_params));
+	cc_miss_engine_params.nextEngine = e_FM_PCD_DONE;
+	cc_miss_engine_params.params.enqueueParams.action = e_FM_PCD_DROP_FRAME;
+
+	if (cls_table->int_cc_nodes_count > 1) {
+		fm_pcd = (t_Handle)cls_table->params.fm_pcd;
+		/*
+		 * We can only delete nodes if the miss action of the initial
+		 * node doesn't point to the dynamic Cc node chain
+		 */
+		err = FM_PCD_CcNodeModifyMissNextEngine(fm_pcd,
+				(t_Handle)cls_table->int_cc_node[0].cc_node,
+				&cc_miss_engine_params);
+		if (err == E_OK) {
+			for (i = 1; (i < cls_table->int_cc_nodes_count) &&
+				(cls_table->int_cc_node[i].cc_node); i++)
+				FM_PCD_CcDeleteNode(fm_pcd,
+				(t_Handle)cls_table->int_cc_node[i].cc_node);
+		} else {
+			xx_pr_fmd_err(err, "FM_PCD_CcNodeModifyNextEngine");
+			xx_pr_err(("FMan driver call failed."));
+			xx_pr_warn(("DPA Classifier failed to clean up exact match table."));
+		}
+	}
+}
+
+static int verify_table_params(const struct dpa_cls_tbl_params *params)
+{
+	int err = 0;
+	unsigned int num_sets;
+
+	xx_assert(params);
+
+	switch (params->type) {
+	case DPA_CLS_TBL_EXACT_MATCH:
+		/*
+		 * Warning of performance penalties if the exact match table is
+		 * implemented with more than 3 nested Cc nodes.
+		 */
+		if (params->exact_match_params.entries_cnt >
+				3 * FM_PCD_MAX_NUM_OF_KEYS) {
+			xx_pr_warn(("Large exact match tables might cause performance penalties."));
+			break;
+		}
+
+		if (params->exact_match_params.key_size >
+				FM_PCD_MAX_SIZE_OF_KEY) {
+			xx_pr_err(("DPA Classifier exact match table key size (%d bytes) exceeds maximum (%d bytes).",
+				params->exact_match_params.key_size,
+				FM_PCD_MAX_SIZE_OF_KEY));
+			err = -EINVAL;
+			break;
+		}
+
+		if (params->exact_match_params.use_priorities) {
+			xx_pr_err(("Entry priorities for exact match tables are not yet supported."));
+			err = -ENOSYS;
+			break;
+		}
+		break;
+	case DPA_CLS_TBL_HASH:
+		if (params->hash_params.num_sets > FM_PCD_MAX_NUM_OF_KEYS) {
+			xx_pr_err(("DPA Classifier hash table number of sets (%d) exceeds maximum (%d).",
+				params->hash_params.num_sets,
+				FM_PCD_MAX_NUM_OF_KEYS));
+			err = -EINVAL;
+			break;
+		}
+
+		/* Verify that the number of sets is a power of 2 */
+		num_sets = 0x02; /* 0b00000010  - the smallest acceptable
+					value */
+		while (num_sets < params->hash_params.num_sets)
+			num_sets <<= 1;
+		if (num_sets != params->hash_params.num_sets) {
+			xx_pr_err(("DPA Classifier hash table number of sets (%d) must be a power of 2.",
+				params->hash_params.num_sets));
+			err = -EINVAL;
+			break;
+		}
+
+		if (params->hash_params.max_ways > FM_PCD_MAX_NUM_OF_KEYS) {
+			xx_pr_err(("DPA Classifier hash table number of ways (%d) exceeds maximum (%d).",
+				params->hash_params.max_ways,
+				FM_PCD_MAX_NUM_OF_KEYS));
+			err = -EINVAL;
+			break;
+		}
+
+		if (params->hash_params.key_size > FM_PCD_MAX_SIZE_OF_KEY) {
+			xx_pr_err(("DPA Classifier hash table key size (%d bytes) exceeds maximum (%d bytes).",
+				params->hash_params.key_size,
+				FM_PCD_MAX_SIZE_OF_KEY));
+			err = -EINVAL;
+			break;
+		}
+		break;
+	case DPA_CLS_TBL_INDEXED:
+		if (params->indexed_params.entries_cnt >
+				FM_PCD_MAX_NUM_OF_KEYS) {
+			xx_pr_err(("DPA Classifier indexed table size (%d entries) exceeds maximum (%d entries).",
+				params->indexed_params.entries_cnt,
+				FM_PCD_MAX_NUM_OF_KEYS));
+			err = -EINVAL;
+			break;
+		}
+
+		if (params->indexed_params.entries_cnt == 0) {
+			xx_pr_err(("Indexed table size zero is invalid."));
+			err = -EINVAL;
+			break;
+		}
+		break;
+	default:
+		xx_pr_err(("Unsupported DPA Classifier table type (%d).",
+			params->type));
+		err = -EINVAL;
+	}
+
+	return err;
+}
+
+static struct list_head *find_shadow_entry(const struct dpa_cls_table
+				*cls_table, const struct dpa_cls_tbl_key *key)
+{
+	uint8_t shadow_table_index;
+	struct dpa_cls_tbl_shadow_entry *entry;
+	bool found = false;
+	struct list_head *pos, *bucket_list;
+	unsigned int i, j;
+	struct dpa_cls_tbl_shadow_table *shadow_table;
+
+	xx_assert(cls_table);
+	xx_assert(key);
+	xx_assert(cls_table->shadow_table);
+
+	if (cls_table->params.type == DPA_CLS_TBL_INDEXED) {
+		shadow_table = &cls_table->shadow_table[0];
+		if (list_empty(&shadow_table->shadow_entry[key->byte[0]]))
+			return NULL;
+		else
+			return shadow_table->shadow_entry[key->byte[0]].next;
+	} else {
+		if (cls_table->params.type == DPA_CLS_TBL_HASH) {
+			shadow_table = &cls_table->shadow_table[0];
+			shadow_table_index = crc8(key->byte,
+				cls_table->params.hash_params.key_size);
+			bucket_list =
+				&shadow_table->shadow_entry[shadow_table_index];
+
+			if (list_empty(bucket_list))
+				return NULL;
+
+			/*
+			 * Look into the HASH bucket to find the entry with the
+			 * specified key
+			 */
+	list_for_each(pos, bucket_list) {
+		entry = list_entry(pos, struct dpa_cls_tbl_shadow_entry,
+				list_node);
+		found = true;
+		/* Verify if the key and mask are identical */
+		for (i = 0; i < DPA_CLS_TBL_MAXENTRYKEYSIZE; i++) {
+			if ((entry->key.byte[i] != key->byte[i]) ||
+					(entry->key.mask[i] != key->mask[i])) {
+				found = false;
+				break;
+			}
+		}
+		if (found)
+			break;
+	}
+
+		} else {
+			/*
+			 * Exact match table (DPA_CLS_TBL_EXACT_MATCH). Search
+			 * in all Cc node shadow tables
+			 */
+			shadow_table_index = crc8(key->byte,
+				cls_table->params.exact_match_params.key_size);
+			for (i = 0; i < cls_table->num_shadow_tables; i++) {
+				shadow_table = &cls_table->shadow_table[i];
+				if (list_empty(&shadow_table->
+					shadow_entry[shadow_table_index]))
+					continue;
+
+	/* Search into this bucket */
+	bucket_list = &shadow_table->shadow_entry[shadow_table_index];
+	list_for_each(pos, bucket_list) {
+		entry = list_entry(pos, struct dpa_cls_tbl_shadow_entry,
+				list_node);
+		found = true;
+		/* Verify if the key and mask are identical */
+		for (j = 0; j < DPA_CLS_TBL_MAXENTRYKEYSIZE; j++) {
+			if ((entry->key.byte[j] != key->byte[j]) ||
+					(entry->key.mask[j] != key->mask[j])) {
+				found = false;
+				break;
+			}
+		}
+		if (found)
+			break;
+	}
+
+			if (found)
+				break;
+
+			}
+		}
+	}
+
+	if (found)
+		return pos;
+
+	return NULL;
+}
+
+static int init_shadow_tables(struct dpa_cls_table *cls_table)
+{
+	unsigned int i, j;
+	int err = 0;
+
+	xx_assert(cls_table);
+
+	for (i = 0; i < cls_table->num_shadow_tables; i++) {
+		/* Allocate entries in the shadow table */
+		cls_table->shadow_table[i].shadow_entry = (struct list_head *)
+			xx_malloc(cls_table->shadow_table[i].size *
+				sizeof(struct list_head));
+		if (!cls_table->shadow_table[i].shadow_entry) {
+			xx_pr_err(("No more memory for DPA Classifier shadow tables."));
+			err = -ENOMEM;
+			goto init_shadow_tables_error;
+		}
+
+		/* Initialize the entries in shadow table */
+		for (j = 0; j < cls_table->shadow_table[i].size; j++)
+			INIT_LIST_HEAD(&cls_table->shadow_table[i].
+							shadow_entry[j]);
+	}
+
+	return err;
+
+init_shadow_tables_error:
+	free_shadow_tables(cls_table);
+
+	return err;
+}
+
+static void free_shadow_tables(struct dpa_cls_table *cls_table)
+{
+	unsigned int i;
+
+	xx_assert(cls_table);
+
+	for (i = 0; i < cls_table->num_shadow_tables; i++)
+		if (cls_table->shadow_table[i].shadow_entry) {
+			xx_free(cls_table->shadow_table[i].shadow_entry);
+			memset(&(cls_table->shadow_table[i]), 0,
+				sizeof(struct dpa_cls_tbl_shadow_table));
+		}
+}
+
+static int table_insert_entry_indexed(struct dpa_cls_table	*cls_table,
+				const struct dpa_cls_tbl_key	*key,
+				const struct dpa_cls_tbl_action	*action,
+				int				*entry_id)
+{
+	t_Error err;
+	int errno = 0;
+	struct dpa_cls_tbl_shadow_entry_indexed *shadow_entry = NULL;
+	t_FmPcdCcNextEngineParams next_engine_params;
+	t_Handle fm_pcd, cc_node;
+
+	xx_assert(cls_table);
+	xx_assert(key);
+	xx_assert(action);
+	xx_assert(cls_table->params.type == DPA_CLS_TBL_INDEXED);
+
+	memset(&next_engine_params, 0 , sizeof(next_engine_params));
+	errno = action_to_next_engine_params(action, &next_engine_params);
+	if (errno < 0)
+		goto table_insert_entry_indexed_error;
+
+	fm_pcd	= (t_Handle)cls_table->params.fm_pcd;
+	cc_node	= (t_Handle)cls_table->int_cc_node[0].cc_node;
+	/* Considering the index as the first byte in the key... */
+	err = FM_PCD_CcNodeModifyNextEngine(fm_pcd,
+					cc_node,
+					key->byte[0],
+					&next_engine_params);
+	if (err != E_OK) {
+		xx_pr_fmd_err(err, "FM_PCD_CcNodeModifyNextEngine");
+		xx_pr_err(("FMan driver call failed."));
+		errno = -EBUSY;
+		goto table_insert_entry_indexed_error;
+	}
+
+	cls_table->int_cc_node[0].used++;
+
+	/* If a shadow table exists, add the action to it */
+	if (cls_table->num_shadow_tables) {
+		shadow_entry = (struct dpa_cls_tbl_shadow_entry_indexed *)
+			xx_zalloc(sizeof(*shadow_entry));
+		if (!shadow_entry) {
+			xx_pr_err(("No more memory for a new DPA Classifier table entry."));
+			errno = -ENOMEM;
+			goto table_insert_entry_indexed_error;
+		}
+
+		memcpy(&shadow_entry->action, action,
+			sizeof(struct dpa_cls_tbl_action));
+
+		/*
+		 * Add entry to the shadow table. Shadow table is actually
+		 * indexed with the first byte of the entry key
+		 */
+		list_add(&shadow_entry->list_node,
+			&cls_table->shadow_table[0].shadow_entry[key->byte[0]]);
+	}
+
+	if (entry_id)
+		*entry_id = key->byte[0];
+
+	return errno;
+
+table_insert_entry_indexed_error:
+	if (shadow_entry)
+		xx_free(shadow_entry);
+
+	return errno;
+}
+
+static int table_insert_entry_exact_match(struct dpa_cls_table	*cls_table,
+				const struct dpa_cls_tbl_key	*key,
+				const struct dpa_cls_tbl_action	*action,
+				int				*entry_id)
+{
+	t_Error err;
+	int errno = 0;
+	int id;
+	struct dpa_cls_tbl_shadow_entry *shadow_entry = NULL;
+	t_FmPcdCcKeyParams key_params;
+	t_FmPcdCcNextEngineParams cc_miss_engine_params;
+	unsigned int i, j;
+	uint8_t shadow_table_index;
+	uint8_t key_data[DPA_CLS_TBL_MAXENTRYKEYSIZE];
+	uint8_t mask_data[DPA_CLS_TBL_MAXENTRYKEYSIZE];
+	t_Handle fm_pcd;
+	struct dpa_cls_tbl_shadow_table *shadow_table;
+
+	xx_assert(cls_table);
+	xx_assert(key);
+	xx_assert(action);
+	xx_assert(cls_table->params.type == DPA_CLS_TBL_EXACT_MATCH);
+
+	memset(&key_params, 0, sizeof(t_FmPcdCcKeyParams));
+
+	/*
+	 * Have to copy the data from the key and mask because the FMD is not
+	 * using const pointers and we cannot provide it the const pointers that
+	 * the user provided.
+	 */
+	memset(key_data, 0, DPA_CLS_TBL_MAXENTRYKEYSIZE);
+	memset(mask_data, 0, DPA_CLS_TBL_MAXENTRYKEYSIZE);
+	memcpy(key_data, key->byte,
+		cls_table->params.exact_match_params.key_size);
+	memcpy(mask_data, key->mask,
+		cls_table->params.exact_match_params.key_size);
+	key_params.p_Key	= key_data;
+	key_params.p_Mask	= mask_data;
+
+	errno = action_to_next_engine_params(action,
+				&key_params.ccNextEngineParams);
+	if (errno < 0)
+		goto table_insert_entry_exact_match_error;
+
+	/* Find an empty spot for this entry, in the existing Cc nodes */
+	i = 0;
+	while ((i < cls_table->int_cc_nodes_count) &&
+			(cls_table->int_cc_node[i].used >=
+			cls_table->int_cc_node[i].table_size)) {
+		i++;
+	}
+
+	fm_pcd = (t_Handle)cls_table->params.fm_pcd;
+	if ((i > 0) && (!cls_table->int_cc_node[i].used)) {
+		/* Check whether this is the last used node */
+		for (j = i; j < cls_table->int_cc_nodes_count; j++) {
+			if (cls_table->int_cc_node[j].used)
+				break;
+		}
+
+		if (j >= cls_table->int_cc_nodes_count) {
+			/* Last used node */
+			/*
+			 * Make sure this node is properly connected on the
+			 * miss relationship with the previous node
+			 */
+			memset(&cc_miss_engine_params, 0,
+				sizeof(t_FmPcdCcNextEngineParams));
+			cc_miss_engine_params.nextEngine = e_FM_PCD_CC;
+			cc_miss_engine_params.params.ccParams.h_CcNode =
+				(t_Handle)cls_table->int_cc_node[i].cc_node;
+
+			err = FM_PCD_CcNodeModifyMissNextEngine(fm_pcd,
+				(t_Handle)cls_table->int_cc_node[i-1].cc_node,
+				&cc_miss_engine_params);
+			if (err != E_OK) {
+				xx_pr_fmd_err(err,
+					"FM_PCD_CcNodeModifyMissNextEngine");
+				xx_pr_err(("FMan driver call failed."));
+				errno = -EBUSY;
+				goto table_insert_entry_exact_match_error;
+			}
+
+			/* Set the table miss action on this node */
+			err = FM_PCD_CcNodeModifyMissNextEngine(fm_pcd,
+				(t_Handle)cls_table->int_cc_node[i].cc_node,
+				&cls_table->miss_next_engine_params);
+			if (err != E_OK) {
+				xx_pr_fmd_err(err,
+					"FM_PCD_CcNodeModifyMissNextEngine");
+				xx_pr_err(("FMan driver call failed."));
+				errno = -EBUSY;
+				goto table_insert_entry_exact_match_error;
+			}
+		}
+	}
+
+	if (i > cls_table->int_cc_nodes_count) {
+		/* No more space to add a new entry */
+		xx_pr_err(("DPA Classifier exact match table is full. Unable to add a new entry."));
+		errno = -ENOSPC;
+		goto table_insert_entry_exact_match_error;
+	}
+
+	/* Find an empty index entry */
+	for (j = 0; j < cls_table->int_cc_node[i].table_size; j++)
+		if (!cls_table->int_cc_node[i].entry[j].valid)
+			break;
+
+	xx_assert(j < cls_table->int_cc_node[i].table_size);
+
+	cls_table->int_cc_node[i].entry[j].valid = true;
+	cls_table->int_cc_node[i].entry[j].entry_index =
+		(uint8_t)cls_table->int_cc_node[i].used;
+
+	id = (i << DPA_CLS_TBL_ENTRYIDNODESHIFT) + j;
+
+	/* Add the key to the selected Cc node */
+	err = FM_PCD_CcNodeAddKey(fm_pcd,
+		(t_Handle)cls_table->int_cc_node[i].cc_node,
+		cls_table->int_cc_node[i].entry[j].entry_index,
+		cls_table->params.exact_match_params.key_size,
+		&key_params);
+	if (err != E_OK) {
+		xx_pr_fmd_err(err, "FM_PCD_CcNodeAddKey");
+		xx_pr_err(("FMan driver call failed."));
+		errno = -EBUSY;
+		goto table_insert_entry_exact_match_error;
+	}
+
+	cls_table->int_cc_node[i].used++;
+
+	/* If shadow tables exist, add the entry to them */
+	if (cls_table->num_shadow_tables) {
+		shadow_entry = (struct dpa_cls_tbl_shadow_entry *)
+			xx_zalloc(sizeof(struct dpa_cls_tbl_shadow_entry));
+		if (!shadow_entry) {
+			xx_pr_err(("No more memory to add a new DPA Classifier shadow table entry."));
+			errno = -ENOMEM;
+			goto table_insert_entry_exact_match_error;
+		}
+
+		memcpy(&shadow_entry->action, action,
+			sizeof(struct dpa_cls_tbl_action));
+		memcpy(&shadow_entry->key, key,
+			sizeof(struct dpa_cls_tbl_key));
+
+		/* Connect index management entry with the shadow table entry */
+		shadow_entry->entry_id = id;
+		cls_table->int_cc_node[i].entry[j].shadow_entry =
+			&shadow_entry->list_node;
+
+		/* Add entry to the proper shadow table. */
+		shadow_table_index = crc8(key->byte,
+				cls_table->params.exact_match_params.key_size);
+		shadow_table = &cls_table->shadow_table[i];
+		list_add_tail(&shadow_entry->list_node,
+			&shadow_table->shadow_entry[shadow_table_index]);
+	}
+
+	if (entry_id)
+		*entry_id = id;
+
+	return errno;
+
+table_insert_entry_exact_match_error:
+	if (shadow_entry)
+		xx_free(shadow_entry);
+
+	return errno;
+}
+
+static int table_insert_entry_hash(struct dpa_cls_table		*cls_table,
+			const struct dpa_cls_tbl_key		*key,
+			const struct dpa_cls_tbl_action		*action,
+			int					*entry_id)
+{
+	t_Error err;
+	int errno = 0;
+	int id;
+	struct dpa_cls_tbl_shadow_entry *shadow_entry = NULL;
+	t_FmPcdCcKeyParams key_params;
+	uint8_t shadow_table_index;
+	uint64_t hash_set_index;
+	uint8_t key_data[DPA_CLS_TBL_MAXENTRYKEYSIZE];
+	uint8_t mask_data[DPA_CLS_TBL_MAXENTRYKEYSIZE];
+	unsigned int j;
+	struct dpa_cls_tbl_shadow_table *shadow_table;
+
+	xx_assert(cls_table);
+	xx_assert(key);
+	xx_assert(action);
+	xx_assert(cls_table->params.type == DPA_CLS_TBL_HASH);
+
+	memset(&key_params, 0, sizeof(t_FmPcdCcKeyParams));
+
+	/*
+	 * Have to copy the data from the key and mask because the FMD is not
+	 * using const pointers and we cannot provide it the const pointers that
+	 * the user provided.
+	 */
+	memset(key_data, 0, DPA_CLS_TBL_MAXENTRYKEYSIZE);
+	memset(mask_data, 0, DPA_CLS_TBL_MAXENTRYKEYSIZE);
+	memcpy(key_data, key->byte, cls_table->params.hash_params.key_size);
+	memcpy(mask_data, key->mask, cls_table->params.hash_params.key_size);
+	key_params.p_Key	= key_data;
+	key_params.p_Mask	= mask_data;
+
+	errno = action_to_next_engine_params(action,
+				&key_params.ccNextEngineParams);
+	if (errno < 0)
+		goto table_insert_entry_hash_error;
+
+	hash_set_index = crc64_init();
+	hash_set_index = crc64_compute(key_data,
+				cls_table->params.hash_params.key_size,
+				hash_set_index);
+	hash_set_index = (uint64_t)(hash_set_index & cls_table->hash_mask) >>
+		(8 * (6 - cls_table->params.hash_params.hash_offs) + 4);
+
+	xx_assert(hash_set_index < cls_table->int_cc_nodes_count);
+
+	/* Check if there are entries still available in the selected set */
+	if (cls_table->int_cc_node[hash_set_index].used >=
+			cls_table->int_cc_node[hash_set_index].table_size) {
+		xx_pr_err(("DPA Classifier hash table is full. Unable to add a new entry."));
+		errno = -ENOSPC;
+		goto table_insert_entry_hash_error;
+	}
+
+	/* Find an empty index entry */
+	for (j = 0; j < cls_table->int_cc_node[hash_set_index].table_size; j++)
+		if (!cls_table->int_cc_node[hash_set_index].entry[j].valid)
+			break;
+
+	xx_assert(j < cls_table->int_cc_node[hash_set_index].table_size);
+
+	cls_table->int_cc_node[hash_set_index].entry[j].valid = true;
+	cls_table->int_cc_node[hash_set_index].entry[j].entry_index =
+			(uint8_t)cls_table->int_cc_node[hash_set_index].used;
+
+	id = ((int)hash_set_index << DPA_CLS_TBL_ENTRYIDNODESHIFT) + j;
+
+	/* Add the key to the selected Cc node */
+	err = FM_PCD_CcNodeAddKey((t_Handle)cls_table->params.fm_pcd,
+		(t_Handle)cls_table->int_cc_node[hash_set_index].cc_node,
+		cls_table->int_cc_node[hash_set_index].entry[j].entry_index,
+		cls_table->params.hash_params.key_size,
+		&key_params);
+	if (err != E_OK) {
+		xx_pr_fmd_err(err, "FM_PCD_CcNodeAddKey");
+		xx_pr_err(("FMan driver call failed."));
+		errno = -EBUSY;
+		goto table_insert_entry_hash_error;
+	}
+
+	cls_table->int_cc_node[hash_set_index].used++;
+
+	/* If shadow tables exist, add the entry to them */
+	if (cls_table->num_shadow_tables) {
+		shadow_entry = (struct dpa_cls_tbl_shadow_entry *)
+			xx_zalloc(sizeof(struct dpa_cls_tbl_shadow_entry));
+		if (!shadow_entry) {
+			xx_pr_err(("No more memory to add a new DPA Classifier shadow table entry."));
+			errno = -ENOMEM;
+			goto table_insert_entry_hash_error;
+		}
+
+		memcpy(&shadow_entry->action, action,
+			sizeof(struct dpa_cls_tbl_action));
+		memcpy(&shadow_entry->key, key,
+			sizeof(struct dpa_cls_tbl_key));
+
+		/* Connect index management entry with the shadow table entry */
+		shadow_entry->entry_id = id;
+		cls_table->int_cc_node[hash_set_index].entry[j].shadow_entry =
+			&shadow_entry->list_node;
+
+		/* Add entry to the proper shadow table. */
+		shadow_table_index = crc8(key->byte,
+				cls_table->params.hash_params.key_size);
+		shadow_table = &cls_table->shadow_table[0];
+		list_add_tail(&shadow_entry->list_node,
+			&shadow_table->shadow_entry[shadow_table_index]);
+	}
+
+	if (entry_id)
+		*entry_id = id;
+
+	return errno;
+
+table_insert_entry_hash_error:
+	if (shadow_entry)
+		xx_free(shadow_entry);
+
+	return errno;
+}
+
+static int action_to_next_engine_params(const struct dpa_cls_tbl_action *action,
+				t_FmPcdCcNextEngineParams *next_engine_params)
+{
+	struct dpa_cls_table *next_table;
+
+	xx_assert(action);
+	xx_assert(next_engine_params);
+
+	memset(next_engine_params, 0, sizeof(t_FmPcdCcNextEngineParams));
+
+	switch (action->type) {
+	case DPA_CLS_TBL_ACTION_DROP:
+		next_engine_params->nextEngine = e_FM_PCD_DONE;
+		next_engine_params->params.enqueueParams.action =
+			e_FM_PCD_DROP_FRAME;
+		if (action->enable_statistics)
+			next_engine_params->params.enqueueParams.statisticsEn =
+				TRUE;
+
+		break;
+	case DPA_CLS_TBL_ACTION_ENQ:
+		if (action->enq_params.policer_params != NULL) {
+			xx_pr_err(("Policing for DPA Classifier flows is not yet supported."));
+			return -ENOSYS;
+		}
+
+		next_engine_params->nextEngine = e_FM_PCD_DONE;
+		next_engine_params->params.enqueueParams.action =
+			e_FM_PCD_ENQ_FRAME;
+		next_engine_params->params.enqueueParams.newFqid =
+				action->enq_params.new_fqid;
+		next_engine_params->h_Manip = (t_Handle) action->enq_params.hm;
+		if (action->enq_params.override_fqid)
+			next_engine_params->params.enqueueParams.overrideFqid =
+				TRUE;
+		if (action->enable_statistics)
+			next_engine_params->params.enqueueParams.statisticsEn =
+				TRUE;
+
+		break;
+	case DPA_CLS_TBL_ACTION_NEXT_TABLE:
+		if ((action->next_table_params.next_td >= num_tables) ||
+			(!table[action->next_table_params.next_td])) {
+			xx_pr_err(("Invalid next table descriptor (0x%08x).",
+				(unsigned)action->next_table_params.next_td));
+			return -EINVAL;
+		}
+
+		next_engine_params->nextEngine = e_FM_PCD_CC;
+		next_table = table[action->next_table_params.next_td];
+		next_engine_params->params.ccParams.h_CcNode =
+			(t_Handle)next_table->params.cc_node;
+
+		break;
+	default:
+		xx_pr_err(("Unsupported DPA Classifier action type (%d).",
+			action->type));
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int extend_table_array(void)
+{
+	unsigned int new_table_size = 0;
+	struct dpa_cls_table **new_table_array;
+
+	if (table)
+		new_table_size = num_tables;
+
+	new_table_size += DPA_CLS_TBL_ARRAYSIZEGRANULARITY;
+
+	new_table_array = (struct dpa_cls_table **)
+		xx_zalloc(new_table_size * sizeof(struct dpa_cls_table *));
+	if (!new_table_array) {
+		xx_pr_err(("No more memory for DPA Classifier table management."));
+		return -ENOMEM;
+	}
+
+	if (num_tables)
+		/*
+		 * Transfer pointers to existing tables into the new table
+		 * array
+		 */
+		memcpy(new_table_array, table,
+			num_tables * sizeof(struct dpa_cls_table *));
+
+	table		= new_table_array;
+	num_tables	= new_table_size;
+
+	return 0;
+}
+
+static int get_new_table_descriptor(int *td)
+{
+	int i;
+
+	if (table_entries_in_use >= num_tables)
+		return -ENOSPC;
+
+	for (i = 0; i < num_tables; i++)
+		if (table[i] == NULL) {
+			*td = i;
+			break;
+		}
+
+	table_entries_in_use++;
+
+	return 0;
+}
+
+
+static inline void put_table_descriptor(int td)
+{
+	if (table[td] != NULL) {
+		if (--table_entries_in_use == 0) {
+			xx_free(table);
+			table = NULL;
+			num_tables = 0;
+		} else
+			table[td] = NULL;
+	}
+}
diff --git a/drivers/staging/fsl_dpa_offload/dpa_classifier.h b/drivers/staging/fsl_dpa_offload/dpa_classifier.h
new file mode 100644
index 0000000..4b67e4e
--- /dev/null
+++ b/drivers/staging/fsl_dpa_offload/dpa_classifier.h
@@ -0,0 +1,279 @@
+
+/* Copyright 2008-2012 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * Internal DPA Classifier Application Programming Interface
+ */
+
+#ifndef __DPA_CLASSIFIER_H
+#define __DPA_CLASSIFIER_H
+
+
+/* DPA offloading layer includes */
+#include "linux/fsl_dpa_classifier.h"
+
+/* FMD includes */
+#include "fm_pcd_ext.h"
+
+
+/* API functions, definitions and enums */
+
+/* Internal API functions, definitions and enums */
+
+
+/*
+ * The maximum possible size of a shadow table. A DPA Classifier
+ * table can have multiple shadow tables depending on its type
+ * and size.
+ */
+#define DPA_CLS_TBL_MAXSHADOWTABLESIZE				256
+
+
+/* Index management entry */
+struct dpa_cls_tbl_entry {
+
+	bool			valid;		/* true if this entry
+						 * is valid */
+	uint8_t			entry_index;	/* The index of this entry
+						 * in the Cc node table */
+	struct list_head	*shadow_entry;	/* Pointer to the shadow
+						 * entry (if there is
+						 * one) associated with
+						 * this index management
+						 * entry */
+};
+
+/*
+ * Shadow Table Entry (for all types of tables except indexed
+ * tables)
+ */
+struct dpa_cls_tbl_shadow_entry {
+
+	struct dpa_cls_tbl_key		key;		/* Lookup key info */
+	struct dpa_cls_tbl_action	action;		/* Action info */
+	int				entry_id;	/* Id of this entry
+							 * (helps find
+							 * the index
+							 * management
+							 * entry faster */
+	struct list_head		list_node;	/* Pointers to other
+							 * shadow entries
+							 * in the current
+							 * set (bucket) */
+};
+
+/* Shadow Table Entry for indexed tables */
+struct dpa_cls_tbl_shadow_entry_indexed {
+
+	struct dpa_cls_tbl_action	action;		/* Action info */
+	struct list_head		list_node;	/* Pointers to other
+							 * shadow entries
+							 * in the current
+							 * set (bucket) */
+};
+
+/* Shadow Table */
+struct dpa_cls_tbl_shadow_table {
+
+	struct list_head	*shadow_entry;	/* Shadow table sets
+						 * (buckets) */
+	unsigned int		size;		/* The size of the shadow
+						 * table in number of sets
+						 * (buckets) */
+};
+
+/* Internal FMan Cc Node Management Info */
+struct dpa_cls_tbl_cc_node_info {
+
+	void				*cc_node;	/* Low level driver
+							 * (FMD) handle of
+							 * the Cc node */
+	unsigned int			table_size;	/* The size of this
+							 * Cc node's lookup
+							 * table */
+	unsigned int			used;		/* Number of entries
+							 * in the lookup
+							 * table that are
+							 * currently in
+							 * use */
+	struct dpa_cls_tbl_entry	*entry;		/* Index management
+							 * array. The size
+							 * of this array is
+							 * table_size */
+};
+
+/* DPA Classifier Table Control Data Structure */
+struct dpa_cls_table {
+
+	/* Array of shadow tables. NULL if there are none. */
+	struct dpa_cls_tbl_shadow_table		*shadow_table;
+
+	/* Number of shadow tables in the shadow_table array */
+	unsigned int				num_shadow_tables;
+
+	/*
+	 * Array of internally managed FMan Cc nodes. NULL
+	 * if there are none beside the initial Cc node (provided
+	 * by the application).
+	 */
+	struct dpa_cls_tbl_cc_node_info		*int_cc_node;
+
+	/*
+	 * Number of internally managed FMan Cc nodes in the
+	 * int_cc_node array
+	 */
+	unsigned int				int_cc_nodes_count;
+
+	/*
+	 * The mask that is used on the CRC64 HASH result to find
+	 * the HASH set for DPA Classifier HASH tables. This is of
+	 * no use for types of DPA Classifier tables other than
+	 * HASH.
+	 */
+	uint64_t				hash_mask;
+
+	/* (Initial) parameters of the DPA Classifier table. */
+	struct dpa_cls_tbl_params		params;
+
+	/*
+	 * The current miss next engine paramas for this table (for
+	 * exact match and HASH tables).
+	 */
+	t_FmPcdCcNextEngineParams		miss_next_engine_params;
+};
+
+
+/*
+ * Allocates the array of internally managed Cc nodes based on
+ * their number. The number of internally managed Cc nodes must
+ * be set in the table control structure before calling this
+ * function.
+ */
+static int	alloc_table_management(struct dpa_cls_table *cls_table);
+
+/*
+ * Releases resources related to the array of internally managed
+ * Cc nodes.
+ */
+static void	free_table_management(struct dpa_cls_table *cls_table);
+
+/* Initialize an indexed table. */
+static int	table_init_indexed(struct dpa_cls_table *cls_table);
+
+/* Initialize a hash table. */
+static int	table_init_hash(struct dpa_cls_table *cls_table);
+
+/* Initialize an exact match table. */
+static int	table_init_exact_match(struct dpa_cls_table *cls_table);
+
+/* Clean up an exact match table */
+static void	table_cleanup_exact_match(struct dpa_cls_table *cls_table);
+
+/* Clean up an indexed table */
+static void	table_cleanup_indexed(struct dpa_cls_table *cls_table);
+
+/* Clean up a hash table */
+static void	table_cleanup_hash(struct dpa_cls_table *cls_table);
+
+/*
+ * Runs a verification of the table parameters against certain
+ * ranges and limitations.
+ */
+static int	verify_table_params(const struct dpa_cls_tbl_params *params);
+
+/*
+ * Initialize shadow tables according to their number and sizes.
+ * The number of sizes of the shadow tables must be set in the
+ * table control structure before calling this function.
+ */
+static int	init_shadow_tables(struct dpa_cls_table *cls_table);
+
+/* Release resources associated with shadow tables. */
+static void	free_shadow_tables(struct dpa_cls_table *cls_table);
+
+/*
+ * Finds a specified entry in the shadow tables. The entry is
+ * identified by its lookup key.
+ */
+static struct list_head *find_shadow_entry(const struct dpa_cls_table
+				*cls_table, const struct dpa_cls_tbl_key *key);
+
+/* Add a new entry in an indexed table. */
+static int table_insert_entry_indexed(struct dpa_cls_table	*cls_table,
+				const struct dpa_cls_tbl_key	*key,
+				const struct dpa_cls_tbl_action	*action,
+				int				*entry_id);
+
+/* Add a new entry in an exact match table. */
+static int table_insert_entry_exact_match(struct dpa_cls_table	*cls_table,
+				const struct dpa_cls_tbl_key	*key,
+				const struct dpa_cls_tbl_action	*action,
+				int				*entry_id);
+
+/* Add a new entry in a hash table. */
+static int table_insert_entry_hash(struct dpa_cls_table		*cls_table,
+				const struct dpa_cls_tbl_key	*key,
+				const struct dpa_cls_tbl_action	*action,
+				int				*entry_id);
+
+/*
+ * Translates action parameters into next engine
+ * parameters for use with the low level driver (FMD).
+ */
+static int action_to_next_engine_params(const struct dpa_cls_tbl_action *action,
+				t_FmPcdCcNextEngineParams *next_engine_params);
+
+/*
+ * Extends with one more step the array mapping the table
+ * descriptors to table control structures. The array is
+ * reallocated with a constant number of new elements which is
+ * defined by the DPA Classifier implementation.
+ */
+static int	extend_table_array(void);
+
+/*
+ * Gets the first free table descriptor in the array mapping
+ * table descriptors to table control structures. In case the
+ * mapping array is overflowed (or it doesn't exist at all), the
+ * function will attempt to extend it (or create it).
+ */
+static int	get_new_table_descriptor(int *td);
+
+/*
+ * Releases a table descriptor. In case the array mapping table
+ * table descriptors to table control structures is completely
+ * empty the function removes it.
+ */
+static inline void put_table_descriptor(int td);
+
+
+#endif /* __DPA_CLASSIFIER_H */
diff --git a/drivers/staging/fsl_dpa_offload/dpa_compat.c b/drivers/staging/fsl_dpa_offload/dpa_compat.c
new file mode 100644
index 0000000..5c39369
--- /dev/null
+++ b/drivers/staging/fsl_dpa_offload/dpa_compat.c
@@ -0,0 +1,319 @@
+
+/* Copyright 2008-2012 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * DPA Offloading Compatibility Layer.
+ */
+
+/* DPA offloading layer includes */
+#include "dpa_compat.h"
+
+
+#ifdef DPA_OFFLOAD_DEBUG_MEMORY
+
+#define DEBUG_MAX_FILE_NAME_SIZE				62
+#define DEBUG_MAX_FUNC_NAME_SIZE				56
+
+
+struct dpa_offld_memory_block_info {
+	void			*mem;
+	char			file_name[DEBUG_MAX_FILE_NAME_SIZE + 1];
+	char			func_name[DEBUG_MAX_FUNC_NAME_SIZE + 1];
+	unsigned int		file_line;
+	size_t			size;
+	void			(*free_func)(void *);
+	struct list_head	node;
+};
+
+
+static struct list_head mem_block_list = {&mem_block_list, &mem_block_list};
+#endif /* DPA_OFFLOAD_DEBUG_MEMORY */
+
+
+void *dpa_offld_malloc(size_t size, int zero)
+{
+	void *memory;
+	unsigned long flags;
+
+
+	local_irq_save(flags);
+
+	memory = (zero) ? kzalloc(size, GFP_KERNEL) : kmalloc(size, GFP_KERNEL);
+
+	local_irq_restore(flags);
+
+	return memory;
+}
+
+#ifdef DPA_OFFLOAD_DEBUG_MEMORY
+void dpa_offld_free(void *memory)
+{
+	kfree(memory);
+}
+#endif /* DPA_OFFLOAD_DEBUG_MEMORY */
+
+void *dpa_offld_malloc_smart(size_t	size,
+			int		mem_partition_id,
+			unsigned int	alignment,
+			int		zero)
+{
+	void *memory, *tmp;
+
+
+	if (alignment < sizeof(void *))
+		return NULL;
+	size += alignment + sizeof(void *);
+	tmp = dpa_offld_malloc(size, zero);
+	if (tmp == NULL)
+		return NULL;
+	memory = (void *)(((unsigned)tmp + alignment + sizeof(void *)) &
+			~(alignment - 1));
+	*(void **)((unsigned)memory - sizeof(void *)) = tmp;
+
+	return memory;
+}
+
+void dpa_offld_free_smart(void *memory)
+{
+	dpa_offld_free(*(void **)((unsigned)memory - sizeof(void*)));
+}
+
+#ifdef DPA_OFFLOAD_DEBUG_MEMORY
+void *xx_malloc_debug(size_t	size,
+		int		zero,
+		const char	*file_name,
+		const char	*func_name,
+		unsigned int	file_line)
+{
+	struct dpa_offld_memory_block_info *memblk;
+	int str_offs = 0;
+	size_t str_len;
+
+
+	memblk = (struct dpa_offld_memory_block_info *)
+		dpa_offld_malloc(sizeof(struct dpa_offld_memory_block_info), 0);
+	if (!memblk)
+		return NULL;
+
+	memblk->size	= size;
+	memblk->mem	= dpa_offld_malloc(size, zero);
+	if (!memblk->mem) {
+		dpa_offld_free(memblk);
+		return NULL;
+	}
+	memblk->free_func = dpa_offld_free;
+	memblk->file_line = file_line;
+
+	str_len = strlen(file_name);
+	if (str_len > DEBUG_MAX_FILE_NAME_SIZE) {
+		str_offs	= str_len - DEBUG_MAX_FILE_NAME_SIZE;
+		str_len		= DEBUG_MAX_FILE_NAME_SIZE;
+	}
+	memcpy(memblk->file_name, &file_name[str_offs], str_len + 1);
+
+	str_len		= strlen(func_name);
+	str_offs	= 0;
+	if (str_len > DEBUG_MAX_FUNC_NAME_SIZE) {
+		str_offs	= str_len - DEBUG_MAX_FUNC_NAME_SIZE;
+		str_len		= DEBUG_MAX_FUNC_NAME_SIZE;
+	}
+	memcpy(memblk->func_name, &func_name[str_offs], str_len + 1);
+
+	list_add_tail(&memblk->node, &mem_block_list);
+
+	return memblk->mem;
+}
+
+void xx_free_debug(void *memory)
+{
+	struct list_head *temp;
+	struct dpa_offld_memory_block_info *memblk;
+	int found = 0;
+
+
+	if (list_empty(&mem_block_list)) {
+		pr_err("\nERROR: dpa_compat.c (%d), %s: Attempt to free unallocated memory\n  (0x%08x).\n",
+			__LINE__, __func__, (unsigned)memory);
+		dump_stack();
+		return;
+	}
+
+	/* Find memory block in list */
+	list_for_each(temp, &mem_block_list) {
+		memblk = list_entry(temp, struct dpa_offld_memory_block_info,
+				node);
+		if (memblk->mem == memory) {
+			found = 1;
+			break;
+		}
+	}
+
+	if (!found) {
+		pr_err("\nERROR: dpa_compat.c (%d), %s: Attempt to free unallocated memory\n  (0x%08x).\n",
+			__LINE__, __func__, (unsigned)memory);
+		dump_stack();
+		return;
+	}
+
+	list_del(temp);
+	if (memblk->free_func != dpa_offld_free) {
+		pr_err("\nERROR: dpa_compat.c (%d), %s: Freeing memory with the wrong\n  \"free\" function.\n",
+			__LINE__, __func__);
+		pr_err("  Memory block @ 0x%08x\n", (unsigned)memblk->mem);
+		pr_err("  Allocated in: %s\n", memblk->file_name);
+		pr_err("  Line %d, function \"%s\"\n", memblk->file_line,
+			memblk->func_name);
+		memblk->free_func(memblk->mem);
+	} else
+		dpa_offld_free(memblk->mem);
+
+	dpa_offld_free(memblk);
+}
+
+void *xx_malloc_smart_debug(size_t	size,
+			int		mem_partition_id,
+			unsigned int	alignment,
+			int		zero,
+			const char	*file_name,
+			const char	*func_name,
+			unsigned int	file_line)
+{
+	struct dpa_offld_memory_block_info *memblk;
+	int str_offs = 0;
+	size_t str_len;
+
+
+	memblk = (struct dpa_offld_memory_block_info *)
+		dpa_offld_malloc(sizeof(struct dpa_offld_memory_block_info), 0);
+	if (!memblk)
+		return NULL;
+
+	memblk->size	= size;
+	memblk->mem	= dpa_offld_malloc(size, zero);
+	if (!memblk->mem) {
+		dpa_offld_free(memblk);
+		return NULL;
+	}
+	memblk->free_func = dpa_offld_free_smart;
+	memblk->file_line = file_line;
+
+	str_len = strlen(file_name);
+	if (str_len > DEBUG_MAX_FILE_NAME_SIZE) {
+		str_offs	= str_len - DEBUG_MAX_FILE_NAME_SIZE;
+		str_len		= DEBUG_MAX_FILE_NAME_SIZE;
+	}
+	memcpy(memblk->file_name, &file_name[str_offs], str_len + 1);
+
+	str_len		= strlen(func_name);
+	str_offs	= 0;
+	if (str_len > DEBUG_MAX_FUNC_NAME_SIZE) {
+		str_offs	= str_len - DEBUG_MAX_FUNC_NAME_SIZE;
+		str_len		= DEBUG_MAX_FUNC_NAME_SIZE;
+	}
+	memcpy(memblk->func_name, &func_name[str_offs], str_len + 1);
+
+	list_add_tail(&memblk->node, &mem_block_list);
+
+	return memblk->mem;
+}
+
+void xx_free_smart_debug(void *memory)
+{
+	struct list_head *temp;
+	struct dpa_offld_memory_block_info *memblk;
+	int found = 0;
+
+
+	if (list_empty(&mem_block_list)) {
+		pr_err("\nERROR: dpa_compat.c (%d), %s: Attempt to free unallocated\n  memory (0x%08x).\n",
+			__LINE__, __func__, (unsigned)memory);
+		dump_stack();
+		return;
+	}
+
+	/* Find memory block in list */
+	list_for_each(temp, &mem_block_list) {
+		memblk = list_entry(temp, struct dpa_offld_memory_block_info,
+				node);
+		if (memblk->mem == memory) {
+			found = 1;
+			break;
+		}
+	}
+
+	if (!found) {
+		pr_err("\nERROR: dpa_compat.c (%d), %s: Attempt to free unallocated\n  memory (0x%08x).\n",
+			__LINE__, __func__, (unsigned)memory);
+		dump_stack();
+		return;
+	}
+
+	list_del(temp);
+	if (memblk->free_func != dpa_offld_free_smart) {
+		pr_err("\nERROR: dpa_compat.c (%d), %s: Freeing memory with the wrong\n  \"free\" function.\n",
+			__LINE__, __func__);
+		pr_err("  Memory block @ 0x%08x\n", (unsigned)memblk->mem);
+		pr_err("  Allocated in: %s\n", memblk->file_name);
+		pr_err("  Line %d, function \"%s\"\n", memblk->file_line,
+			memblk->func_name);
+		memblk->free_func(memblk->mem);
+	} else
+		dpa_offld_free_smart(memblk->mem);
+
+	dpa_offld_free(memblk);
+}
+
+void dpa_offld_display_mem_leaks(void)
+{
+	struct list_head *temp;
+	struct dpa_offld_memory_block_info *memblk;
+
+
+	if (list_empty(&mem_block_list)) {
+		pr_info("\nDEBUG: No memory leaks detected.\n");
+		return;
+	} else {
+		pr_warn("\nWARNING: Listing MEMORY LEAKS.\n");
+		list_for_each(temp, &mem_block_list) {
+			memblk = list_entry(temp,
+					struct dpa_offld_memory_block_info,
+					node);
+			pr_warn("\nLeaking %d bytes @ 0x%08x\n", memblk->size,
+				(unsigned)memblk->mem);
+			pr_warn("  Allocated in: %s\n", memblk->file_name);
+			pr_warn("  Line %d, function \"%s\"\n",
+				memblk->file_line, memblk->func_name);
+		}
+		pr_warn("\nDEBUG: Done listing memory leaks.\n");
+	}
+}
+#endif /* DPA_OFFLOAD_DEBUG_MEMORY */
diff --git a/drivers/staging/fsl_dpa_offload/dpa_compat.h b/drivers/staging/fsl_dpa_offload/dpa_compat.h
new file mode 100644
index 0000000..32f5588
--- /dev/null
+++ b/drivers/staging/fsl_dpa_offload/dpa_compat.h
@@ -0,0 +1,249 @@
+
+/* Copyright 2008-2012 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * DPA Offloading Layer compatibility layer interface for kernel space/user
+ * space integration
+ */
+
+#ifndef __DPA_COMPAT_H
+#define __DPA_COMPAT_H
+
+
+/* Linux kernel includes: */
+#include "linux/types.h"
+#include "linux/slab.h"
+#include "linux/printk.h"
+
+/* FMan driver includes: */
+#include "error_ext.h" /* for translating FMan LLD errTypeStrings */
+
+
+/*
+ * Memory management
+ */
+
+#ifdef DPA_OFFLOAD_DEBUG_MEMORY
+
+#define xx_malloc(size) \
+	xx_malloc_debug(size, 0,  __FILE__, __func__, __LINE__)
+
+#define xx_zalloc(size) \
+	xx_malloc_debug(size, \
+			1, \
+			__FILE__, \
+			__func__, \
+			__LINE__)
+
+#define xx_free					xx_free_debug
+
+#define xx_malloc_smart(size, partition_id, alignment) \
+	xx_malloc_smart_debug(size, \
+			partition_id, \
+			alignment, \
+			0, \
+			__FILE__, \
+			__func__, \
+			__LINE__)
+
+#define xx_zalloc_smart(size, partition_id, alignment) \
+	xx_malloc_smart_debug(size, \
+			partition_id, \
+			alignment, \
+			1, \
+			__FILE__, \
+			__func__, \
+			__LINE__)
+
+#define xx_free_smart				xx_free_smart_debug
+
+#define xx_display_mem_leaks			dpa_offld_display_mem_leaks
+
+#else /* not in DEBUG_MEMORY mode */
+
+#define dpa_offld_free				kfree
+
+#define xx_malloc(size) \
+			dpa_offld_malloc(size, 0)
+#define xx_zalloc(size) \
+			dpa_offld_malloc(size, 1)
+#define xx_free					kfree
+#define xx_malloc_smart(size, \
+			mem_partition_id, \
+			alignment) \
+	dpa_offld_malloc_smart(size, 0, mem_partition_id, alignment)
+#define xx_zalloc_smart(size, \
+			mem_partition_id, \
+			alignment) \
+	dpa_offld_malloc_smart(size, \
+			1, \
+			mem_partition_id, \
+			alignment)
+#define xx_free_smart				dpa_offld_free_smart
+#define xx_display_mem_leaks()
+
+#endif /* DPA_OFFLOAD_DEBUG_MEMORY */
+
+
+void	*dpa_offld_malloc(size_t size, int zero);
+
+
+#ifdef DPA_OFFLOAD_DEBUG_MEMORY
+void	dpa_offld_free(void *memory);
+#endif /* DPA_OFFLOAD_DEBUG_MEMORY */
+
+void	*dpa_offld_malloc_smart(size_t		size,
+				int		mem_partition_id,
+				unsigned int	alignment,
+				int		zero);
+
+void	dpa_offld_free_smart(void *memory);
+
+#ifdef DPA_OFFLOAD_DEBUG_MEMORY
+void	*xx_malloc_debug(size_t		size,
+			int		zero,
+			const char	*file_name,
+			const char	*func_name,
+			unsigned int	file_line);
+
+void	xx_free_debug(void *memory);
+
+void	*xx_malloc_smart_debug(size_t		size,
+				int		mem_partition_id,
+				unsigned int	alignment,
+				int		zero,
+				const char	*file_name,
+				const char	*func_name,
+				unsigned int	file_line);
+
+void	xx_free_smart_debug(void *memory);
+
+void	dpa_offld_display_mem_leaks(void);
+#endif /* DPA_OFFLOAD_DEBUG_MEMORY */
+
+
+/*
+ * Error Reporting
+ */
+#ifdef DPA_OFFLOAD_VERBOSE_WARNINGS
+#define	xx_pr_warn(message) \
+	do { \
+		pr_warn("WARNING: %s (%d): %s:", __FILE__, __LINE__, \
+			__func__); \
+		pr_warn message; \
+	} while (0)
+#else
+#define xx_pr_warn(message)
+#endif /* DPA_OFFLOAD_VERBOSE_WARNINGS */
+
+#ifdef DPA_OFFLOAD_VERBOSE_ERRORS
+#define xx_pr_err(message) \
+	do { \
+		pr_err("ERROR: %s (%d): %s:", __FILE__, __LINE__, __func__); \
+		pr_err message; \
+	} while (0)
+#define xx_pr_crit(message) \
+	do { \
+		pr_crit("CRITICAL: %s (%d): %s:", __FILE__, __LINE__, \
+			__func__); \
+		pr_crit message; \
+	} while (0)
+
+#define xx_pr_fmd_err(err_code, fmd_api) \
+	pr_err( \
+		"\nERROR (FMan LLD): %s: %s\n", \
+		fmd_api, \
+		errTypeStrings[GET_ERROR_TYPE(err_code)-E_OK-1])
+#else
+#define xx_pr_err(message)
+#define xx_pr_crit(message)
+#define xx_pr_fmd_err(err_code, fmd_api)
+#endif /* DPA_OFFLOAD_VERBOSE_ERRORS */
+
+/*
+ * This is the main display macro. Info display is always on (you cannot
+ * disable it), so please use it with consideration.
+ */
+#define xx_pr_info(message)			pr_info message
+
+#ifdef DPA_OFFLOAD_VERBOSE_DEBUG
+#define xx_pr_debug(message) \
+	do { \
+		pr_info("DEBUG: %s (%d): %s:", __FILE__, __LINE__, __func__); \
+		pr_info message; \
+	} while (0)
+#else
+#define xx_pr_debug(message)
+#endif /* DPA_OFFLOAD_VERBOSE_DEBUG */
+
+
+/*
+ * Error Checking
+ */
+#ifdef DPA_OFFLOAD_DEBUG
+#define xx_assert(cond) \
+	if (!(cond)) { \
+		pr_err( \
+			"\nERROR: DEBUG assertion failed: %s, line %d\n", \
+			__FILE__, \
+			__LINE__); \
+		panic("DPA offloading layer"); \
+	}
+#else
+#define xx_assert(cond)
+#endif /* DPA_OFFLOAD_DEBUG */
+
+#ifdef DPA_OFFLOAD_SANITY_CHECKS
+#define xx_sanity_check_return_value(cond, var_desc, ret) \
+	if (!cond) { \
+		xx_pr_err(( \
+			"\nERROR: %s: Invalid value for %s.\n", \
+			__func__, \
+			var_desc)); \
+		return ret; \
+	}
+
+#define xx_sanity_check_return(cond, var_desc) \
+	if (!cond) { \
+		xx_pr_err(( \
+			"\nERROR: %s: Invalid value for %s.\n", \
+			__func__, \
+			var_desc)); \
+		return; \
+	}
+#else
+#define xx_sanity_check_return_value(cond, var_desc, ret)
+#define xx_sanity_check_return(cond, var_desc)
+#endif
+
+
+#endif /* __DPA_COMPAT_H */
diff --git a/include/linux/fsl_dpa_classifier.h b/include/linux/fsl_dpa_classifier.h
new file mode 100644
index 0000000..a7ceb06
--- /dev/null
+++ b/include/linux/fsl_dpa_classifier.h
@@ -0,0 +1,424 @@
+
+/* Copyright 2008-2012 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * DPA Classifier Application Programming Interface.
+ */
+
+#ifndef __FSL_DPA_CLASSIFIER_H
+#define __FSL_DPA_CLASSIFIER_H
+
+
+/* DPA offloading layer includes */
+#include "fsl_dpa_compat.h"
+
+/* Other includes */
+#include "linux/types.h"
+
+
+/* API functions, definitions and enums */
+
+
+/* DPA Classifier maximum size of a lookup key, in bytes */
+#define DPA_CLS_TBL_MAXENTRYKEYSIZE				56
+
+/* DPA Classifier invalid table descriptor */
+#define DPA_CLS_INVALID_TABLE_DESC				-1
+
+/* DPA Classifier Table Types */
+enum dpa_cls_tbl_type {
+	DPA_CLS_TBL_HASH = 0,		/* HASH table */
+	DPA_CLS_TBL_INDEXED,		/* Indexed table */
+	DPA_CLS_TBL_EXACT_MATCH		/* Exact match table */
+};
+
+/* DPA Classifier Table Action Types */
+enum dpa_cls_tbl_action_type {
+	DPA_CLS_TBL_ACTION_DROP = 0,	/* Drop frame */
+	DPA_CLS_TBL_ACTION_ENQ,		/* Send frame into a frame queue
+					* (enqueue) */
+	DPA_CLS_TBL_ACTION_NEXT_TABLE	/* Go to another table and
+					* re-classify the packet */
+};
+
+/* DPA Classifier Table Entry Modification Types */
+enum dpa_cls_tbl_modify_type {
+	DPA_CLS_TBL_MODIFY_KEY = 0,		/* Modify the entry key.
+						* This modification is
+						* supported only on exact match
+						* tables. */
+	DPA_CLS_TBL_MODIFY_ACTION,		/* Modify the entry action */
+	DPA_CLS_TBL_MODIFY_KEY_AND_ACTION	/* Modify the entry key and
+						* action. This modification is
+						* supported only on exact match
+						* tables. */
+};
+
+/* DPA Classifier Table Entry Management Types */
+enum dpa_cls_tbl_entry_mgmt {
+	DPA_CLS_TBL_MANAGE_BY_KEY = 0,	/* Manage entries by key (shadow
+					* table). The shadow table consumes more
+					* RAM, but allows the user to do
+					* software lookups and refer to the
+					* table entries by their key as well as
+					* by their reference (Id) */
+
+	DPA_CLS_TBL_MANAGE_BY_REF,	/* Manage entries by reference only
+					* (no shadow table). Saves memory and
+					* speeds up runtime operations, but the
+					* user cannot do software lookups and
+					* can only refer to the entries by
+					* their reference (Id) */
+};
+
+/* DPA Classifier HASH table parameters */
+struct dpa_cls_tbl_hash_params {
+
+	unsigned int	num_sets;	/* Number of sets (buckets) of the
+					* HASH table */
+	unsigned int	max_ways;	/* Number of ways of the HASH table
+					* (capability to resolve conflicts) */
+	unsigned int	hash_offs;	/* HASH offset */
+	uint8_t		key_size;	/* Key size in bytes */
+};
+
+/* DPA Classifier indexed table parameters */
+struct dpa_cls_tbl_indexed_params {
+
+	unsigned int	entries_cnt;	/* Number of entries in the table */
+};
+
+/* DPA Classifier exact match table parameters */
+struct dpa_cls_tbl_exact_match_params {
+
+	unsigned int	entries_cnt;	/* Number of entries in the table */
+	uint8_t		key_size;	/* Key size in bytes */
+	int		use_priorities;	/* Use priorities for each entry in
+					* table if nonzero (this mode is not
+					* supported yet) */
+};
+
+/* DPA Classifier table parameters */
+struct dpa_cls_tbl_params {
+
+	/*
+	 * Handle of the FM PCD that owns the Cc nodes that this
+	 * table was built on
+	 */
+	void					*fm_pcd;
+
+	/*
+	 * Handle of the initial FM Cc node for this table
+	 *
+	 * This Cc node must be connected to a Cc tree.
+	 */
+	void					*cc_node;
+
+	/* The type of the DPA Classifier table */
+	enum dpa_cls_tbl_type			type;
+
+	/* Table entry management mechanism for runtime */
+	enum dpa_cls_tbl_entry_mgmt		entry_mgmt;
+
+	union {
+		/* Parameters for HASH table */
+		struct dpa_cls_tbl_hash_params		hash_params;
+
+		/* Parameters for indexed table */
+		struct dpa_cls_tbl_indexed_params	indexed_params;
+
+		/* Parameters for exact match table */
+		struct dpa_cls_tbl_exact_match_params	exact_match_params;
+	};
+};
+
+/* Policer parameters */
+struct dpa_cls_tbl_policer_params {
+
+	int		modify_policer_params;	/* Nonzero if the default
+						* policer parameters will be
+						* overridden */
+	int		shared_profile;		/* Nonzero if this policer
+						* profile is shared between
+						* ports; relevant only if
+						* [modify_policer_params] is
+						* nonzero */
+	unsigned int	new_rel_profile_id;	/* this parameter should
+						* indicate the policer profile
+						* offset within the port's
+						* policer profiles or from the
+						* SHARED window; relevant only
+						* if [modify_policer_params]
+						* is nonzero */
+};
+
+struct dpa_cls_tbl_header_manip;
+
+/* Enqueue action parameters */
+struct dpa_cls_tbl_enq_action_desc {
+
+	/*
+	 * Override the frame queue Id from KeyGen and use the one
+	 * specified in this enqueue action descriptor if nonzero
+	 */
+	int					override_fqid;
+
+	/*
+	 * Id of the frame queue where to send the frames in case of
+	 * rule hit.
+	 */
+	uint32_t				new_fqid;
+
+	/*
+	 * Pointer to the policer parameters. If NULL, no policing is
+	 * applied during the enqueue.
+	 */
+	struct dpa_cls_tbl_policer_params	*policer_params;
+
+	/*
+	 * Pointer to the header manipulation. If NULL, no header
+	 * manipulation will be performed.
+	 */
+	struct dpa_cls_tbl_header_manip		*hm;
+};
+
+/* Action parameters to route to a new classifier table */
+struct dpa_cls_tbl_next_table_desc {
+
+	int		next_td; /* Descriptor of the next DPA Classifier
+				 * table to continue classification with */
+};
+
+/* Entry key descriptor */
+struct dpa_cls_tbl_key {
+
+	/*
+	 * The data (bytes) of the key. For indexed tables the index is
+	 * the first byte of this array
+	 */
+	uint8_t		byte[DPA_CLS_TBL_MAXENTRYKEYSIZE];
+
+	/*
+	 * The mask of the key. The the bits corresponding to zeros in
+	 * the mask are ignored
+	 */
+	uint8_t		mask[DPA_CLS_TBL_MAXENTRYKEYSIZE];
+};
+
+/* DPA Classifier action descriptor */
+struct dpa_cls_tbl_action {
+
+	/*
+	 * Action type specifier. Drop action doesn't require any
+	 * further parameters
+	 */
+	enum dpa_cls_tbl_action_type	type;
+
+	/* Enable statistics for this entry if nonzero */
+	int				enable_statistics;
+
+	union {
+
+		/* Specific parameters for enqueue action */
+		struct dpa_cls_tbl_enq_action_desc	enq_params;
+
+		/*
+		 * Specific parameters for sending the frames to a new
+		 * classifier table
+		 */
+		struct dpa_cls_tbl_next_table_desc	next_table_params;
+	};
+};
+
+/* DPA Classifier entry modification parameters */
+struct dpa_cls_tbl_entry_mod_params {
+
+	/* The type of modification */
+	enum dpa_cls_tbl_modify_type		type;
+
+	/*
+	 * The new key parameters to replace the existing key
+	 * parameters of the entry. Ignored for modify types which
+	 * do not refer to the key.
+	 */
+	struct dpa_cls_tbl_key			*key;
+
+	/*
+	 * The new action parameters to replace the existing action
+	 * parameters of the entry. Ignored for modify types which
+	 * do not refer to the action.
+	 */
+	struct dpa_cls_tbl_action		*action;
+};
+
+/* DPA Classifier table entry statistics */
+struct dpa_cls_tbl_entry_stats {
+
+	unsigned long int	total_pkts;	/* The total number of
+						* packets that have hit the
+						* entry */
+};
+
+
+/*
+ * Creates and initializes a DPA Classifier table using a FMan
+ * coarse classification node. Depending on the type of table,
+ * this call can result in MURAM allocation.
+ *
+ * Once the DPA Classifier takes control of a FMan Cc node, all
+ * its management must be performed through this API. If
+ * applications use different APIs to modify the Cc node's
+ * properties in the same time while the DPA Classifier has
+ * ownership of the node, unpredictable behavior and data
+ * inconsistency can occur.
+ */
+int	dpa_classif_table_create(const struct dpa_cls_tbl_params *params,
+				int *td);
+
+/*
+ * Releases all resources associated with a DPA Classifier table
+ * and destroys it.
+ */
+int dpa_classif_table_free(int td);
+
+/* Modifies the action taken in case of lookup miss condition. */
+int dpa_classif_table_modify_miss_action(int			td,
+				const struct dpa_cls_tbl_action	*miss_action);
+
+/*
+ * Adds an entry (classification rule) in the specified DPA
+ * Classifier table. If the MURAM for the table was pre-allocated,
+ * this operation doesn't consume MURAM.
+ *
+ * Entry priorities for exact match tables are not supported yet.
+ *
+ * The hardware currently doesn't support longest prefix match on
+ * the exact match tables. If there are more entries in the
+ * table that match the lookup (e.g. because of their mask) the
+ * first one will always be returned by the hardware lookup.
+ */
+int dpa_classif_table_insert_entry(int				td,
+				const struct dpa_cls_tbl_key	*key,
+				const struct dpa_cls_tbl_action *action,
+				int				priority,
+				int				*entry_id);
+
+/*
+ * Modifies an entry in the specified DPA Classifier table. The
+ * entry is identified by the lookup key. This function never
+ * allocates new MURAM space.
+ */
+int dpa_classif_table_modify_entry_by_key(int			td,
+		const struct dpa_cls_tbl_key			*key,
+		const struct dpa_cls_tbl_entry_mod_params	*mod_params);
+
+/*
+ * Modifies an entry in the specified DPA Classifier table. The
+ * entry is identified by its ref (Id). This function never
+ * allocates new MURAM space.
+ */
+int dpa_classif_table_modify_entry_by_ref(int			td,
+		int						entry_id,
+		const struct dpa_cls_tbl_entry_mod_params	*mod_params);
+
+/*
+ * Removes an entry in the specified DPA Classifier table. The
+ * entry is identified by the lookup key. If the MURAM for the
+ * table was pre-allocated, this function doesn't free up any
+ * MURAM space.
+ */
+int dpa_classif_table_delete_entry_by_key(int				td,
+					const struct dpa_cls_tbl_key	*key);
+
+/*
+ * Removes an entry in the specified DPA Classifier table. The
+ * entry is identified by its ref (Id). If the MURAM for the
+ * table was pre-allocated, this function doesn't free up any
+ * MURAM space.
+ */
+int dpa_classif_table_delete_entry_by_ref(int td, int entry_id);
+
+/*
+ * Performs a lookup in the specified table for an entry specified
+ * by a key. If successful (i.e. the entry exists in that table)
+ * the action descriptor for that entry is returned.
+ *
+ * Table lookup works only if entry management by key is selected
+ * for the DPA Classifier table.
+ *
+ * This is not a hardware accelerated lookup. This lookup is
+ * performed by the DPA Classifier in its internal shadow tables.
+ * It is recommended to use this function with consideration.
+ */
+int dpa_classif_table_lookup_by_key(int				td,
+				const struct dpa_cls_tbl_key	*key,
+				struct dpa_cls_tbl_action	*action);
+
+/*
+ * Performs a lookup in the specified table for an entry specified
+ * by its ref (Id). The action descriptor for that entry is
+ * returned.
+ *
+ * Table lookup works only if entry management by key is selected
+ * for the DPA Classifier table.
+ */
+int dpa_classif_table_lookup_by_ref(int				td,
+				int				entry_id,
+				struct dpa_cls_tbl_action	*action);
+
+/*
+ * Removes all the entries in a DPA Classifier Table. After this
+ * operation is completed the entries cannot be recovered.
+ */
+int dpa_classif_table_flush(int td);
+
+/*
+ * Returns the statistics for a specified entry in a specified
+ * table. The entry is identified by the lookup key.
+ */
+int dpa_classif_table_get_entry_stats_by_key(int			td,
+					const struct dpa_cls_tbl_key	*key,
+					struct dpa_cls_tbl_entry_stats	*stats);
+
+/*
+ * Returns the statistics for a specified entry in a specified
+ * table. The entry is identified by its ref (pointer).
+ */
+int dpa_classif_table_get_entry_stats_by_ref(int		td,
+				int				entry_id,
+				struct dpa_cls_tbl_entry_stats	*stats);
+
+/* Returns the parameters of a classifier table. */
+int dpa_classif_table_get_params(int td, struct dpa_cls_tbl_params *params);
+
+
+#endif /* __FSL_DPA_CLASSIFIER_H */
diff --git a/include/linux/fsl_dpa_compat.h b/include/linux/fsl_dpa_compat.h
new file mode 100644
index 0000000..3b417c1
--- /dev/null
+++ b/include/linux/fsl_dpa_compat.h
@@ -0,0 +1,50 @@
+
+/* Copyright 2008-2012 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * DPA Offloading Layer compatibility layer type definitions for kernel
+ * space/user space integration
+ */
+
+#ifndef __FSL_DPA_COMPAT_H
+#define __FSL_DPA_COMPAT_H
+
+
+#ifndef __KERNEL__
+	#include "usdpaa/compat.h"
+#endif
+
+
+#define unused(x)					(x = x)
+
+
+#endif /* __FSL_DPA_COMPAT_H */
-- 
1.7.5.4

