From 8bebc01def8f0d15ebe02392452bab608a543fc0 Mon Sep 17 00:00:00 2001
From: Hai-Ying Wang <Haiying.Wang@freescale.com>
Date: Fri, 15 Feb 2013 00:27:01 +0000
Subject: [PATCH 056/518] fsl_qman: some updates to CEETM

- Move the code to reset channel and lni shaping parameters to release APIs.
- Use pr_debug to show the resource allocation information for debug.
- Add oal parameter to LNI enable shaper.
- Initialize sub-portal and LNI objects with kzalloc.
- Use cqid and dcpid instead of cq object to query cq.
- Use correct cqid to peek/pop cq.
- Fix the wrong lnitcfcc setting.
- Fix the dcp_id with dcp_idx in one DPA_ASSERT().
- Fix some typos.

Signed-off-by: Haiying Wang <Haiying.Wang@freescale.com>
[Grabbed from the branch, LINUX_IR5.2.0, of
https://git.freescale.com/git-private/cgit.cgi/ppc/alu-b4860/linux.git.]
Signed-off-by: Tiejun Chen <tiejun.chen@windriver.com>
---
 drivers/staging/fsl_qbman/qman_driver.c |   12 ++--
 drivers/staging/fsl_qbman/qman_high.c   |  141 ++++++++++++++++--------------
 include/linux/fsl_qman.h                |    5 +-
 3 files changed, 85 insertions(+), 73 deletions(-)

diff --git a/drivers/staging/fsl_qbman/qman_driver.c b/drivers/staging/fsl_qbman/qman_driver.c
index 3315902..a9944e7 100644
--- a/drivers/staging/fsl_qbman/qman_driver.c
+++ b/drivers/staging/fsl_qbman/qman_driver.c
@@ -184,7 +184,7 @@ static __init int fsl_ceetm_init(struct device_node *node)
 		qman_release_ceetm0_lfqid_range(range[0], range[1]);
 	if (dcp_portal == qm_dc_portal_fman1)
 		qman_release_ceetm1_lfqid_range(range[0], range[1]);
-	pr_info("Qman: The lfqid allocator of CEETM %d includes range"
+	pr_debug("Qman: The lfqid allocator of CEETM %d includes range"
 			" 0x%x:0x%x\n", dcp_portal, range[0], range[1]);
 
 	qman_ceetms[dcp_portal].idx = dcp_portal;
@@ -204,7 +204,7 @@ static __init int fsl_ceetm_init(struct device_node *node)
 	}
 
 	for (i = 0; i < range[1]; i++) {
-		sp = kmalloc(sizeof(*sp), GFP_KERNEL);
+		sp = kzalloc(sizeof(*sp), GFP_KERNEL);
 		if (!sp) {
 			pr_err("Can't alloc memory for sub-portal %d\n",
 							range[0] + i);
@@ -216,7 +216,7 @@ static __init int fsl_ceetm_init(struct device_node *node)
 		list_add_tail(&sp->node, &qman_ceetms[dcp_portal].sub_portals);
 		sp++;
 	}
-	pr_info("Qman: Reserve sub-portal %d:%d for CEETM %d\n",
+	pr_debug("Qman: Reserve sub-portal %d:%d for CEETM %d\n",
 					range[0], range[1], dcp_portal);
 	qman_ceetms[dcp_portal].sp_range[0] = range[0];
 	qman_ceetms[dcp_portal].sp_range[1] = range[1];
@@ -234,7 +234,7 @@ static __init int fsl_ceetm_init(struct device_node *node)
 	}
 
 	for (i = 0; i < range[1]; i++) {
-		lni = kmalloc(sizeof(*lni), GFP_KERNEL);
+		lni = kzalloc(sizeof(*lni), GFP_KERNEL);
 		if (!lni) {
 			pr_err("Can't alloc memory for LNI %d\n",
 							range[0] + i);
@@ -247,7 +247,7 @@ static __init int fsl_ceetm_init(struct device_node *node)
 		list_add_tail(&lni->node, &qman_ceetms[dcp_portal].lnis);
 		lni++;
 	}
-	pr_info("Qman: Reserve LNI %d:%d for CEETM %d\n",
+	pr_debug("Qman: Reserve LNI %d:%d for CEETM %d\n",
 					range[0], range[1], dcp_portal);
 	qman_ceetms[dcp_portal].lni_range[0] = range[0];
 	qman_ceetms[dcp_portal].lni_range[1] = range[1];
@@ -269,7 +269,7 @@ static __init int fsl_ceetm_init(struct device_node *node)
 		qman_release_ceetm0_channel_range(range[0], range[1]);
 	if (dcp_portal == qm_dc_portal_fman1)
 		qman_release_ceetm1_channel_range(range[0], range[1]);
-	pr_info("Qman: The channel allocator of CEETM %d includes"
+	pr_debug("Qman: The channel allocator of CEETM %d includes"
 			" range %d:%d\n", dcp_portal, range[0], range[1]);
 
 	/* Set CEETM PRES register */
diff --git a/drivers/staging/fsl_qbman/qman_high.c b/drivers/staging/fsl_qbman/qman_high.c
index 900d5d7..fc0eb4b 100644
--- a/drivers/staging/fsl_qbman/qman_high.c
+++ b/drivers/staging/fsl_qbman/qman_high.c
@@ -2349,7 +2349,7 @@ int qman_ceetm_configure_cq(struct qm_mcc_ceetm_cq_config *opts)
 	return 0;
 }
 
-int qman_ceetm_query_cq(struct qm_ceetm_cq *cq, u32 dcp_idx,
+int qman_ceetm_query_cq(unsigned int cqid, unsigned int dcpid,
 				struct qm_mcr_ceetm_cq_query *cq_query)
 {
 	struct qm_mc_command *mcc;
@@ -2362,8 +2362,8 @@ int qman_ceetm_query_cq(struct qm_ceetm_cq *cq, u32 dcp_idx,
 	PORTAL_IRQ_LOCK(p, irqflags);
 
 	mcc = qm_mc_start(&p->p);
-	mcc->cq_query.cqid = cq->idx;
-	mcc->cq_query.dcpid = cq->parent->dcp_idx;
+	mcc->cq_query.cqid = cqid;
+	mcc->cq_query.dcpid = dcpid;
 	qm_mc_commit(&p->p, QM_CEETM_VERB_CQ_QUERY);
 	while (!(mcr = qm_mc_result(&p->p)))
 		cpu_relax();
@@ -2650,7 +2650,7 @@ int qman_ceetm_cq_peek_pop_xsfdrread(struct qm_ceetm_cq *cq,
 	switch (command_type) {
 	case 0:
 	case 1:
-		mcc->cq_ppxr.cqid = cq->idx;
+		mcc->cq_ppxr.cqid = (cq->parent->idx << 4) | cq->idx;
 		break;
 	case 2:
 		mcc->cq_ppxr.xsfdr = xsfdr;
@@ -2842,7 +2842,7 @@ int qman_ceetm_sp_claim(struct qm_ceetm_sp **sp, enum qm_dc_portal dcp_idx,
 {
 	struct qm_ceetm_sp *p;
 
-	DPA_ASSERT((dcp_id ==  qm_dc_portal_fman0) ||
+	DPA_ASSERT((dcp_idx ==  qm_dc_portal_fman0) ||
 			(dcp_idx == qm_dc_portal_fman1));
 
 	if ((sp_idx < qman_ceetms[dcp_idx].sp_range[0]) ||
@@ -2874,9 +2874,10 @@ int qman_ceetm_sp_release(struct qm_ceetm_sp *sp)
 	}
 
 	list_for_each_entry(p, &qman_ceetms[sp->dcp_idx].sub_portals, node) {
-		if (p->idx == sp->idx)
+		if (p->idx == sp->idx) {
 			p->is_claimed = 0;
 			p->lni = NULL;
+		}
 	}
 	/* Disable CEETM mode of this sub-portal */
 	qman_sp_disable_ceetm_mode(sp->idx, sp->dcp_idx);
@@ -2913,26 +2914,31 @@ EXPORT_SYMBOL(qman_ceetm_lni_claim);
 int qman_ceetm_lni_release(struct qm_ceetm_lni *lni)
 {
 	struct qm_ceetm_lni *p;
+	struct qm_mcc_ceetm_mapping_shaper_tcfc_config config_opts;
 
 	if (!list_empty(&lni->channels)) {
 		pr_err("The LNI dependencies are not released!\n");
 		return -EBUSY;
 	}
 
-	lni->shaper_enable = 0;
-	lni->shaper_couple = 0;
-	lni->cr_token_rate.whole = 0;
-	lni->cr_token_rate.fraction = 0;
-	lni->er_token_rate.whole = 0;
-	lni->er_token_rate.fraction = 0;
-	lni->cr_token_bucket_limit = 0;
-	lni->er_token_bucket_limit = 0;
-	lni->is_claimed = 0;
 	list_for_each_entry(p, &qman_ceetms[lni->dcp_idx].lnis, node) {
-		if (p->idx == lni->idx)
+		if (p->idx == lni->idx) {
+			p->shaper_enable = 0;
+			p->shaper_couple = 0;
+			p->cr_token_rate.whole = 0;
+			p->cr_token_rate.fraction = 0;
+			p->er_token_rate.whole = 0;
+			p->er_token_rate.fraction = 0;
+			p->cr_token_bucket_limit = 0;
+			p->er_token_bucket_limit = 0;
 			p->is_claimed = 0;
+		}
 	}
-	return 0;
+	config_opts.cid = CEETM_COMMAND_LNI_SHAPER | lni->idx;
+	config_opts.dcpid = lni->dcp_idx;
+	memset(&config_opts.shaper_config, 0,
+				sizeof(config_opts.shaper_config));
+	return	qman_ceetm_configure_mapping_shaper_tcfc(&config_opts);
 }
 EXPORT_SYMBOL(qman_ceetm_lni_release);
 
@@ -2940,11 +2946,6 @@ int qman_ceetm_sp_set_lni(struct qm_ceetm_sp *sp, struct qm_ceetm_lni *lni)
 {
 	struct qm_mcc_ceetm_mapping_shaper_tcfc_config config_opts;
 
-	/*if (sp->lni->idx == lni->idx) {
-		pr_err("This SP <-> LNI mapping has been set\n");
-		return -EINVAL;
-	}
-	*/
 	config_opts.cid = CEETM_COMMAND_SP_MAPPING | sp->idx;
 	config_opts.dcpid = sp->dcp_idx;
 	config_opts.sp_mapping.map_lni_id = lni->idx;
@@ -2954,8 +2955,7 @@ int qman_ceetm_sp_set_lni(struct qm_ceetm_sp *sp, struct qm_ceetm_lni *lni)
 		return -EINVAL;
 
 	/* Enable CEETM mode for this sub-portal */
-	qman_sp_enable_ceetm_mode(sp->dcp_idx, sp->idx);
-	return 0;
+	return qman_sp_enable_ceetm_mode(sp->dcp_idx, sp->idx);
 }
 EXPORT_SYMBOL(qman_ceetm_sp_set_lni);
 
@@ -2976,7 +2976,8 @@ int qman_ceetm_sp_get_lni(struct qm_ceetm_sp *sp, unsigned int *lni_idx)
 }
 EXPORT_SYMBOL(qman_ceetm_sp_get_lni);
 
-int qman_ceetm_lni_enable_shaper(struct qm_ceetm_lni *lni, int coupled)
+int qman_ceetm_lni_enable_shaper(struct qm_ceetm_lni *lni, int coupled,
+								int oal)
 {
 	struct qm_mcc_ceetm_mapping_shaper_tcfc_config config_opts;
 
@@ -2990,38 +2991,26 @@ int qman_ceetm_lni_enable_shaper(struct qm_ceetm_lni *lni, int coupled)
 
 	config_opts.cid = CEETM_COMMAND_LNI_SHAPER | lni->idx;
 	config_opts.dcpid = lni->dcp_idx;
-	config_opts.shaper_config.cpl = (coupled << 7);
-				 /* | oal_value;  TBD - oal_value */
+	config_opts.shaper_config.cpl = (coupled << 7) | oal;
 	config_opts.shaper_config.crtcr = (lni->cr_token_rate.whole << 13) |
 			 lni->cr_token_rate.fraction;
 	config_opts.shaper_config.ertcr = (lni->er_token_rate.whole << 13) |
-			 lni->cr_token_rate.fraction;
+			 lni->er_token_rate.fraction;
 	config_opts.shaper_config.crtbl = lni->cr_token_bucket_limit;
 	config_opts.shaper_config.ertbl = lni->er_token_bucket_limit;
-	return	qman_ceetm_configure_mapping_shaper_tcfc(&config_opts);
+	return qman_ceetm_configure_mapping_shaper_tcfc(&config_opts);
 }
 EXPORT_SYMBOL(qman_ceetm_lni_enable_shaper);
 
 int qman_ceetm_lni_disable_shaper(struct qm_ceetm_lni *lni)
 {
-	struct qm_mcc_ceetm_mapping_shaper_tcfc_config config_opts;
-
 	if (!lni->shaper_enable) {
 		pr_err("The shaper has been disabled\n");
 		return -EINVAL;
 	}
 
 	lni->shaper_enable = 0;
-	lni->shaper_couple = 0;
-
-	config_opts.cid = CEETM_COMMAND_LNI_SHAPER | lni->idx;
-	config_opts.dcpid = lni->dcp_idx;
-	config_opts.shaper_config.cpl = 0; /* | oal_value;  TBD - oal_value */
-	config_opts.shaper_config.crtcr = 0;
-	config_opts.shaper_config.ertcr = 0;
-	config_opts.shaper_config.ertbl = 0;
-	config_opts.shaper_config.crtbl = 0;
-	return	qman_ceetm_configure_mapping_shaper_tcfc(&config_opts);
+	return 0;
 }
 EXPORT_SYMBOL(qman_ceetm_lni_disable_shaper);
 
@@ -3121,7 +3110,8 @@ int qman_ceetm_lni_set_excess_rate(struct qm_ceetm_lni *lni,
 	config_opts.shaper_config.cpl = query_result.shaper_query.cpl;
 	config_opts.shaper_config.crtcr = query_result.shaper_query.crtcr;
 	config_opts.shaper_config.crtbl = query_result.shaper_query.crtbl;
-	return	qman_ceetm_configure_mapping_shaper_tcfc(&config_opts);
+
+	return qman_ceetm_configure_mapping_shaper_tcfc(&config_opts);
 }
 EXPORT_SYMBOL(qman_ceetm_lni_set_excess_rate);
 
@@ -3158,7 +3148,6 @@ int qman_ceetm_lni_set_tcfcc(struct qm_ceetm_lni *lni,
 	struct qm_mcc_ceetm_mapping_shaper_tcfc_query query_opts;
 	struct qm_mcr_ceetm_mapping_shaper_tcfc_query query_result;
 	u64 lnitcfcc;
-	int ret;
 
 	if ((cq_level > 15) | (traffic_class > 7)) {
 		pr_err("The CQ or traffic class id is out of range\n");
@@ -3167,15 +3156,23 @@ int qman_ceetm_lni_set_tcfcc(struct qm_ceetm_lni *lni,
 
 	query_opts.cid = CEETM_COMMAND_TCFC | lni->idx;
 	query_opts.dcpid = lni->dcp_idx;
-	ret = qman_ceetm_query_mapping_shaper_tcfc(&query_opts, &query_result);
+	if (qman_ceetm_query_mapping_shaper_tcfc(&query_opts, &query_result)) {
+		pr_err("Fail to query tcfcc\n");
+		return -EINVAL;
+	}
 
 	lnitcfcc = query_result.tcfc_query.lnitcfcc;
-	if (traffic_class == -1) /* disable tcfc for this CQ */
-		lnitcfcc &= ~(1 >> (cq_level * 4));
-	else
-		lnitcfcc |=
-			((QMAN_CEETM_LNITCFCC_ENABLE | traffic_class) & 0xF) <<
-			QMAN_CEETM_LNITCFCC_CQ_LEVEL_SHIFT(cq_level);
+	if (traffic_class == -1) {
+		/* disable tcfc for this CQ */
+		lnitcfcc &= ~((u64)QMAN_CEETM_LNITCFCC_ENABLE <<
+				QMAN_CEETM_LNITCFCC_CQ_LEVEL_SHIFT(cq_level));
+	} else {
+		lnitcfcc &= ~((u64)0xF <<
+				QMAN_CEETM_LNITCFCC_CQ_LEVEL_SHIFT(cq_level));
+		lnitcfcc |= ((u64)(QMAN_CEETM_LNITCFCC_ENABLE |
+				traffic_class)) <<
+				QMAN_CEETM_LNITCFCC_CQ_LEVEL_SHIFT(cq_level);
+	}
 	config_opts.tcfc_config.lnitcfcc = lnitcfcc;
 	config_opts.cid = CEETM_COMMAND_TCFC | lni->idx;
 	config_opts.dcpid = lni->dcp_idx;
@@ -3183,14 +3180,14 @@ int qman_ceetm_lni_set_tcfcc(struct qm_ceetm_lni *lni,
 }
 EXPORT_SYMBOL(qman_ceetm_lni_set_tcfcc);
 
-#define QMAN_CEETM_LNITCFCC_TC_MASK 0x00000007
+#define QMAN_CEETM_LNITCFCC_TC_MASK 0x7
 int qman_ceetm_lni_get_tcfcc(struct qm_ceetm_lni *lni, unsigned int cq_level,
 						int *traffic_class)
 {
 	struct qm_mcc_ceetm_mapping_shaper_tcfc_query query_opts;
 	struct qm_mcr_ceetm_mapping_shaper_tcfc_query query_result;
 	int ret;
-	int lnitcfcc;
+	u8 lnitcfcc;
 
 	if (cq_level > 15) {
 		pr_err("the CQ level is out of range\n");
@@ -3202,9 +3199,9 @@ int qman_ceetm_lni_get_tcfcc(struct qm_ceetm_lni *lni, unsigned int cq_level,
 	ret = qman_ceetm_query_mapping_shaper_tcfc(&query_opts, &query_result);
 	if (ret)
 		return ret;
-	lnitcfcc = query_result.tcfc_query.lnitcfcc >>
-		QMAN_CEETM_LNITCFCC_CQ_LEVEL_SHIFT(cq_level);
-	if ((lnitcfcc & QMAN_CEETM_LNITCFCC_ENABLE) > 1)
+	lnitcfcc = (u8)(query_result.tcfc_query.lnitcfcc >>
+				QMAN_CEETM_LNITCFCC_CQ_LEVEL_SHIFT(cq_level));
+	if (lnitcfcc & QMAN_CEETM_LNITCFCC_ENABLE)
 		*traffic_class = lnitcfcc & QMAN_CEETM_LNITCFCC_TC_MASK;
 	else
 		*traffic_class = -1;
@@ -3231,11 +3228,9 @@ int qman_ceetm_channel_claim(struct qm_ceetm_channel **channel,
 		return -ENODEV;
 	}
 
-	p = kmalloc(sizeof(*p), GFP_KERNEL);
+	p = kzalloc(sizeof(*p), GFP_KERNEL);
 	p->idx = channel_idx;
 	p->dcp_idx = lni->dcp_idx;
-	p->shaper_enable = 0;
-	p->shaper_couple = 0;
 	list_add_tail(&p->node, &lni->channels);
 	INIT_LIST_HEAD(&p->class_queues);
 	INIT_LIST_HEAD(&p->ccgs);
@@ -3256,6 +3251,7 @@ EXPORT_SYMBOL(qman_ceetm_channel_claim);
 
 int qman_ceetm_channel_release(struct qm_ceetm_channel *channel)
 {
+	struct qm_mcc_ceetm_mapping_shaper_tcfc_config config_opts;
 	if (!list_empty(&channel->class_queues)) {
 		pr_err("CEETM channel#%d has class queue unreleased!\n",
 						channel->idx);
@@ -3266,12 +3262,23 @@ int qman_ceetm_channel_release(struct qm_ceetm_channel *channel)
 						channel->idx);
 		return -EBUSY;
 	}
+
+	config_opts.cid = CEETM_COMMAND_CHANNEL_SHAPER | channel->idx;
+	config_opts.dcpid = channel->dcp_idx;
+	memset(&config_opts.shaper_config, 0,
+				sizeof(config_opts.shaper_config));
+	if (qman_ceetm_configure_mapping_shaper_tcfc(&config_opts)) {
+		pr_err("Can't reset channel shapping parameters\n");
+		return -EINVAL;
+	}
+
 	if (channel->dcp_idx == qm_dc_portal_fman0)
 		qman_release_ceetm0_channelid(channel->idx);
 	if (channel->dcp_idx == qm_dc_portal_fman1)
 		qman_release_ceetm1_channelid(channel->idx);
 	list_del(&channel->node);
 	kfree(channel);
+
 	return 0;
 }
 EXPORT_SYMBOL(qman_ceetm_channel_release);
@@ -3314,11 +3321,13 @@ int qman_ceetm_channel_enable_shaper(struct qm_ceetm_channel *channel,
 
 	config_opts.cid = CEETM_COMMAND_CHANNEL_SHAPER | channel->idx;
 	config_opts.shaper_config.cpl = coupled << 7;
-	if (qman_ceetm_configure_mapping_shaper_tcfc(&config_opts)) {
-		pr_err("Can't set coupled for channel #%d\n", channel->idx);
-		return -EINVAL;
-	}
-	return 0;
+	config_opts.shaper_config.crtcr = (channel->cr_token_rate.whole << 13) |
+					channel->cr_token_rate.fraction;
+	config_opts.shaper_config.ertcr = (channel->er_token_rate.whole << 13) |
+					channel->er_token_rate.fraction;
+	config_opts.shaper_config.crtbl = channel->cr_token_bucket_limit;
+	config_opts.shaper_config.ertbl = channel->er_token_bucket_limit;
+	return qman_ceetm_configure_mapping_shaper_tcfc(&config_opts);
 }
 EXPORT_SYMBOL(qman_ceetm_channel_enable_shaper);
 
@@ -3386,7 +3395,7 @@ int qman_ceetm_channel_set_commit_rate(struct qm_ceetm_channel *channel,
 	config_opts.shaper_config.cpl = query_result.shaper_query.cpl;
 	config_opts.shaper_config.ertcr = query_result.shaper_query.ertcr;
 	config_opts.shaper_config.ertbl = query_result.shaper_query.ertbl;
-	return	qman_ceetm_configure_mapping_shaper_tcfc(&config_opts);
+	return qman_ceetm_configure_mapping_shaper_tcfc(&config_opts);
 }
 EXPORT_SYMBOL(qman_ceetm_channel_set_commit_rate);
 
@@ -3447,7 +3456,7 @@ int qman_ceetm_channel_set_excess_rate(struct qm_ceetm_channel *channel,
 	config_opts.shaper_config.cpl = query_result.shaper_query.cpl;
 	config_opts.shaper_config.crtcr = query_result.shaper_query.crtcr;
 	config_opts.shaper_config.crtbl = query_result.shaper_query.crtbl;
-	return	qman_ceetm_configure_mapping_shaper_tcfc(&config_opts);
+	return qman_ceetm_configure_mapping_shaper_tcfc(&config_opts);
 }
 EXPORT_SYMBOL(qman_ceetm_channel_set_excess_rate);
 
@@ -3981,7 +3990,7 @@ int qman_ceetm_lfq_release(struct qm_ceetm_lfq *lfq)
 {
 	if (lfq->parent->dcp_idx == qm_dc_portal_fman0)
 		qman_release_ceetm0_lfqid(lfq->idx);
-	if (lfq->parent->dcp_idx == qm_dc_portal_fman0)
+	if (lfq->parent->dcp_idx == qm_dc_portal_fman1)
 		qman_release_ceetm1_lfqid(lfq->idx);
 	list_del(&lfq->node);
 	kfree(lfq);
diff --git a/include/linux/fsl_qman.h b/include/linux/fsl_qman.h
index ae7f6cc..f4a46af 100644
--- a/include/linux/fsl_qman.h
+++ b/include/linux/fsl_qman.h
@@ -2585,6 +2585,8 @@ int qman_ceetm_sp_get_lni(struct qm_ceetm_sp *sp,
  * qman_ceetm_lni_disable_shaper - Enables/disables shaping on the LNI.
  * @lni: the given LNI.
  * @coupled: indicates whether CR and ER are coupled.
+ * @oal: the overhead accounting length which is added to the actual length of
+ * each frame when performing shaper calculations.
  *
  * When the number of (unused) committed-rate tokens reach the committed-rate
  * token limit, 'coupled' indicates whether surplus tokens should be added to
@@ -2604,7 +2606,8 @@ int qman_ceetm_sp_get_lni(struct qm_ceetm_sp *sp,
  * a) -EINVAL if the shaper is has already disabled.
  * b) -EIO if calling configure shaper command returns error.
  */
-int qman_ceetm_lni_enable_shaper(struct qm_ceetm_lni *lni, int coupled);
+int qman_ceetm_lni_enable_shaper(struct qm_ceetm_lni *lni, int coupled,
+								int oal);
 int qman_ceetm_lni_disable_shaper(struct qm_ceetm_lni *lni);
 
 /**
-- 
1.7.5.4

