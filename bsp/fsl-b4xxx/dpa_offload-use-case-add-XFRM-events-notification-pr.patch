From c8b77561d0000153d85894457399f99ee185a287 Mon Sep 17 00:00:00 2001
From: Alexandru BADICIOIU <alexandru.badicioiu@freescale.com>
Date: Thu, 17 May 2012 15:56:22 +0000
Subject: [PATCH 188/518] dpa_offload use case : add XFRM events notification
 processing

Signed-off-by: Alexandru BADICIOIU <alexandru.badicioiu@freescale.com>
[Grabbed from the branch, LINUX_IR5.2.0, of
https://git.freescale.com/git-private/cgit.cgi/ppc/alu-b4860/linux.git.]
Signed-off-by: Tiejun Chen <tiejun.chen@windriver.com>
---
 drivers/staging/fsl_dpa_offload/usecases/xfrm_km.c |  656 ++++++++++++++++++++
 .../staging/fsl_dpa_offload/usecases/xfrm_utils.c  |  231 +++++++
 2 files changed, 887 insertions(+), 0 deletions(-)
 create mode 100644 drivers/staging/fsl_dpa_offload/usecases/xfrm_km.c
 create mode 100644 drivers/staging/fsl_dpa_offload/usecases/xfrm_utils.c

diff --git a/drivers/staging/fsl_dpa_offload/usecases/xfrm_km.c b/drivers/staging/fsl_dpa_offload/usecases/xfrm_km.c
new file mode 100644
index 0000000..a5ddd1b
--- /dev/null
+++ b/drivers/staging/fsl_dpa_offload/usecases/xfrm_km.c
@@ -0,0 +1,656 @@
+/* Copyright 2008-2012 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <linux/module.h>
+#include <linux/spinlock.h>
+#include <linux/netdevice.h>
+#include <linux/inetdevice.h>
+#include <linux/crypto.h>
+#include <linux/in.h>		/* for IP protocols, IPPROTO_ESP */
+#include <net/xfrm.h>
+#include <net/ipv6.h>
+
+#include <linux/fsl_dpa_ipsec.h>
+
+#include "ports_conf.h"
+
+#include "platform_defs.h"
+#include "genl_ctl.h"
+#include "common.h"
+
+#define HASH_SIZE 256
+static const u32 jhash_initval = 0xdeadbeef;
+/* offloaded SA hash entry */
+struct sa {
+	struct hlist_node h;
+	struct xfrm_state *state;
+	int dir;
+	int sa_id;
+};
+/* offloaded SA's hash table */
+static struct hlist_head sa_htable[HASH_SIZE];
+
+/* Core to run the offloading work.
+*/
+static int offld_work_cpu;
+module_param(offld_work_cpu, int, 0);
+MODULE_PARM_DESC(offld_work_cpu, "\tCPU to run offloading work");
+
+/* Algos lookup table */
+static struct alg_suite {
+	const char *aalg;
+	int icv_truncbits;
+	const char *ealg;
+	int dpa_alg;
+} algs[] = {
+	{
+		.aalg = "hmac(sha1)",
+		.icv_truncbits = 96,
+		.ealg = "cbc(des3_ede)",
+		.dpa_alg = DPA_IPSEC_CIPHER_ALG_3DES_CBC_HMAC_96_SHA_160
+	}
+};
+
+/* Parameters used by DPA IPsec runtime APIs */
+static struct xfrm_km_uparms usr_params;
+
+/* Policy walking workqueue */
+struct work_arg {
+	struct xfrm_state *x;
+	struct xfrm_policy_walk walk;
+	struct work_struct work;
+	int from_pol;
+};
+static void work_func(struct work_struct *work);
+static int policy_walk_func(struct xfrm_policy *pol, int dir, int count,
+			    void *ptr);
+
+/*
+  Returns core number where CAAM JR0 IRQ is routed.
+  This core is used to run offloading work as auth split key
+  generation enables local BHs to receive CAAM job termination
+  notification.
+*/
+#if defined(CONFIG_P4080_BUILD) || defined(CONFIG_P5020_BUILD)
+int get_offld_work_cpu(void)
+{
+	u32 *addr, iidr;
+	int i;
+	addr = ioremap(SOC_BASE + IIDR(JR0_INT_NUM), sizeof(u32));
+	if (!addr) {
+		pr_err("%s(%d) : Cannot remap IIDR%d\n", __func__,
+		       __LINE__, JR0_INT_NUM);
+		return -1;
+	}
+	iidr = in_be32(addr);
+	iounmap(addr);
+
+	for (i = 0; iidr != 1; iidr = (iidr >> 1), i++)
+		;
+	return i;
+}
+#else
+int get_offld_work_cpu(void)
+{
+	return -ENOTSUPP;
+}
+#endif
+
+/*
+ Stores a pair of xfrm_state and DPA IPsec SA on a hash table
+ Hash is computed on concatenated auth and crypto keys + 1 direction byte
+ */
+static struct sa *hash_sa(struct hlist_head *htable, struct xfrm_state *x,
+			  int dir, int sa_id)
+{
+	struct sa *psa;
+	unsigned int hash_val = 0;
+	unsigned char *hash_key;
+	unsigned int hash_key_size;
+	unsigned char _dir = 0;
+
+	if (!x || (sa_id == -1))
+		return NULL;
+	if (dir != XFRM_POLICY_IN && dir != XFRM_POLICY_OUT)
+		return NULL;
+
+	psa = kzalloc(sizeof(*psa), GFP_ATOMIC);
+	if (!psa) {
+		pr_err("%s(%d) : Cannot allocate hash entry\n",
+		       __func__, __LINE__);
+		return NULL;
+	}
+
+	INIT_HLIST_NODE(&psa->h);
+
+	/* 1 byte for direction */
+	hash_key_size = x->aalg->alg_key_len / 8 + x->ealg->alg_key_len / 8 + 1;
+	hash_key = kzalloc(hash_key_size, GFP_ATOMIC);
+	if (!hash_key) {
+		pr_err("%s(%d) : Cannot allocate hash key\n",
+		       __func__, __LINE__);
+		kfree(psa);
+		return NULL;
+	}
+
+	memcpy(hash_key, x->aalg->alg_key, x->aalg->alg_key_len / 8);
+	memcpy(hash_key + x->aalg->alg_key_len / 8, x->ealg->alg_key,
+	       x->ealg->alg_key_len / 8);
+	if (dir == XFRM_POLICY_OUT) _dir = 1;
+	memcpy(hash_key + x->aalg->alg_key_len / 8 + x->ealg->alg_key_len / 8,
+	       &_dir, 1);
+
+	hash_val =
+	    jhash((u32 *) hash_key, hash_key_size, jhash_initval) % HASH_SIZE;
+	hlist_add_head(&psa->h, sa_htable + hash_val);
+	psa->sa_id = sa_id;
+	psa->state = x;
+	psa->dir = dir;
+	kfree(hash_key);
+	return psa;
+}
+
+/*
+ Retrieves a pair of xfrm_state and DPA IPsec SA id
+*/
+static struct sa *find_sa(struct hlist_head *htable, struct xfrm_state *x,
+			  int dir)
+{
+	unsigned int hash_val = 0;
+	unsigned char *hash_key;
+	unsigned int hash_key_size = 0;
+	struct hlist_node *entry;
+	int sa_found = 0;
+	unsigned char _dir = 0;
+	struct sa *psa = NULL;
+
+	if (dir != XFRM_POLICY_IN && dir != XFRM_POLICY_OUT)
+		return NULL;
+	/* 1 byte for direction */
+	hash_key_size = x->aalg->alg_key_len / 8 + x->ealg->alg_key_len / 8 + 1;
+	hash_key = kzalloc(hash_key_size, GFP_ATOMIC);
+	if (!hash_key) {
+		pr_err("%s(%d): Cannot allocate hash key\n",
+		       __func__, __LINE__);
+		return NULL;
+	}
+
+	memcpy(hash_key, x->aalg->alg_key, x->aalg->alg_key_len / 8);
+	memcpy(hash_key + x->aalg->alg_key_len / 8, x->ealg->alg_key,
+	       x->ealg->alg_key_len / 8);
+	if (dir == XFRM_POLICY_OUT) _dir = 1;
+	memcpy(hash_key + x->aalg->alg_key_len / 8 + x->ealg->alg_key_len / 8,
+	       &_dir, 1);
+
+	hash_val =
+	    jhash((u32 *) hash_key, hash_key_size, jhash_initval) % HASH_SIZE;
+	hlist_for_each_entry(psa, entry, sa_htable + hash_val, h) {
+		if (psa && psa->state == x && psa->dir == dir) {
+			sa_found = 1;
+			break;
+		}
+	}
+	if (!sa_found)
+		psa = NULL;
+	kfree(hash_key);
+	return psa;
+}
+
+/* Algos suite lookup
+ */
+static inline int alg_suite(struct xfrm_state *x)
+{
+	int i;
+	struct xfrm_algo_desc *aalg_desc;
+	aalg_desc = xfrm_aalg_get_byname(x->aalg->alg_name, 0);
+	for (i = 0; i < ARRAY_SIZE(algs); i++) {
+		if (!strcmp(x->aalg->alg_name, algs[i].aalg) &&
+		    (aalg_desc->uinfo.auth.icv_truncbits ==
+		     algs[i].icv_truncbits)
+		    && !strcmp(x->ealg->alg_name, algs[i].ealg))
+			return algs[i].dpa_alg;
+	}
+	return -ENOTSUPP;
+}
+
+/* XFRM state notifications
+ */
+static int xfrm_km_state_notify(struct xfrm_state *x, const struct km_event *c)
+{
+	int ret = 0;
+	unsigned int hash_val;
+	struct hlist_node *entry;
+	struct sa *psa;
+	struct work_arg *work;
+
+	/* Only ESP supported */
+	if (!(x && (x->id.proto == IPPROTO_ESP)))
+		return 0;
+
+	switch (c->event) {
+	case XFRM_MSG_EXPIRE:
+		pr_info("%s: XFRM_MSG_EXPIRE event, SPI %x\n",
+			__func__, x->id.spi);
+		break;
+
+	case XFRM_MSG_NEWAE:
+		pr_info("%s: XFRM_MSG_NEWAE event, SPI %x\n",
+			__func__, x->id.spi);
+		break;
+
+	case XFRM_MSG_DELSA:
+		pr_info("%s: XFRM_MSG_DELSA event, SPI %x\n",
+			__func__, x->id.spi);
+		psa = find_sa(sa_htable, x, XFRM_POLICY_OUT);
+		if (psa) {
+			ret = dpa_ipsec_remove_sa(psa->sa_id);
+			if (ret < 0)
+				pr_err("%s(%d): Error removing out SA (%d)\n",
+				       __func__, __LINE__, ret);
+			hlist_del(&psa->h);
+			kfree(psa);
+		}
+		psa = find_sa(sa_htable, x, XFRM_POLICY_IN);
+		if (psa) {
+			ret = dpa_ipsec_remove_sa(psa->sa_id);
+			if (ret < 0)
+				pr_info("%s(%d): error removing in SA (%d)\n",
+					__func__, __LINE__, ret);
+			hlist_del(&psa->h);
+			kfree(psa);
+		}
+		break;
+
+	case XFRM_MSG_UPDSA:
+		pr_info("%s: XFRM_MSG_UPDSA event, SPI %x\n",
+			__func__, x->id.spi);
+	case XFRM_MSG_NEWSA:
+		if (c->event == XFRM_MSG_NEWSA)
+			pr_info("%s: XFRM_MSG_NEWSA event, SPI %x\n",
+				__func__, x->id.spi);
+		work = kzalloc(sizeof(*work), GFP_KERNEL);
+		if (!work) {
+			pr_err("%s: Cannot allocate offld work\n", __func__);
+			return -ENOMEM;
+		}
+		work->x = x;
+		INIT_WORK(&work->work, work_func);
+		schedule_work_on(offld_work_cpu, &work->work);
+		break;
+
+	case XFRM_MSG_FLUSHSA:
+		pr_info("%s: XFRM_MSG_FLUSHSA event\n", __func__);
+		for (hash_val = 0; hash_val < HASH_SIZE; hash_val++) {
+			hlist_for_each_entry(psa, entry,
+					     sa_htable + hash_val, h) {
+				ret = dpa_ipsec_remove_sa(psa->sa_id);
+				if (ret < 0) {
+					pr_info
+					("%s(%d) : Error removing SA (%d)\n",
+					 __func__, __LINE__, ret);
+				}
+				kfree(psa);
+			}
+		}
+		break;
+
+	default:
+		pr_info("%s: Unknown SA event %d\n", __func__, c->event);
+		break;
+	}
+
+	return ret;
+}
+
+/* Policy walking
+*/
+static void work_func(struct work_struct *work)
+{
+	struct work_arg *this_work = container_of(work, struct work_arg, work);
+	xfrm_policy_walk_init(&this_work->walk, XFRM_POLICY_TYPE_ANY);
+	xfrm_policy_walk(&init_net, &this_work->walk, policy_walk_func,
+			 this_work);
+	xfrm_policy_walk_done(&this_work->walk);
+	kfree(this_work);
+}
+
+static int offload_sa(int dpa_ipsec_id,
+		      struct dpa_ipsec_sa_params *sa_params,
+		      struct xfrm_state *x,
+		      int def_sa_act_fqid,
+		      int policy_miss_fqid, int dir, int *sa_id)
+{
+	struct iphdr outer_iphdr;
+	struct ipv6hdr outer_ip6hdr;
+	struct dpa_cls_tbl_action def_sa_action;
+	int ret = 0;
+
+	if (dir != XFRM_POLICY_OUT && dir != XFRM_POLICY_IN)
+		return -EINVAL;
+
+	sa_params->crypto_params.auth_key = x->aalg->alg_key;
+	sa_params->crypto_params.auth_key_len = x->aalg->alg_key_len / 8;
+	sa_params->crypto_params.cipher_key = x->ealg->alg_key;
+	sa_params->crypto_params.cipher_key_len = x->ealg->alg_key_len / 8;
+
+	sa_params->spi = x->id.spi;
+	sa_params->sa_bpid = usr_params.sa_bpid;
+	sa_params->crypto_params.alg_suite = alg_suite(x);
+	if (sa_params->crypto_params.alg_suite < 0)
+		return -ENOTSUPP;
+
+	if (dir == XFRM_POLICY_OUT) {
+		sa_params->sa_dir = DPA_IPSEC_OUTBOUND;
+		sa_params->start_seq_num = 1;
+		sa_params->l2_hdr_size = ETH_HLEN;
+		sa_params->sa_wqid = usr_params.sa_wqid;
+		if (x->props.family == AF_INET) {
+			memset(&outer_iphdr, 0, sizeof(outer_iphdr));
+			outer_iphdr.version = IPVERSION;
+			outer_iphdr.ihl = sizeof(outer_iphdr) / sizeof(u32);
+			outer_iphdr.tot_len = sizeof(outer_iphdr);
+			outer_iphdr.saddr = x->props.saddr.a4;
+			outer_iphdr.daddr = x->id.daddr.a4;
+			outer_iphdr.protocol = IPPROTO_ESP;
+			sa_params->sa_out_params.outer_ip_header = &outer_iphdr;
+			sa_params->sa_out_params.ip_hdr_size =
+			    sizeof(outer_iphdr);
+		} else if (x->props.family == AF_INET6) {
+			memset(&outer_ip6hdr, 0, sizeof(outer_ip6hdr));
+			memcpy(&outer_ip6hdr.saddr, x->props.saddr.a6,
+			       sizeof(x->props.saddr.a6));
+			memcpy(&outer_ip6hdr.daddr, x->id.daddr.a6,
+			       sizeof(x->id.daddr.a6));
+			outer_ip6hdr.version = 0x6;
+			outer_ip6hdr.nexthdr = IPPROTO_ESP;
+			outer_ip6hdr.hop_limit = IPDEFTTL;
+			sa_params->sa_out_params.outer_ip_header =
+			    &outer_ip6hdr;
+			sa_params->sa_out_params.ip_hdr_size =
+			    sizeof(outer_ip6hdr);
+			sa_params->sa_out_params.addr_type =
+			    DPA_IPSEC_ADDR_T_IPv6;
+		}
+		sa_params->sa_out_params.outer_udp_header = NULL;
+		sa_params->sa_out_params.post_sec_flow_id = 0;
+		sa_params->sa_out_params.init_vector = NULL;
+	} else if (dir == XFRM_POLICY_IN) {
+		sa_params->sa_dir = DPA_IPSEC_INBOUND;
+		sa_params->sa_in_params.use_udp_encap = 0;
+		if (x->props.family == AF_INET) {
+			sa_params->sa_in_params.src_addr.addr_type =
+			    DPA_IPSEC_ADDR_T_IPv4;
+			sa_params->sa_in_params.src_addr.ipv4.word =
+			    x->props.saddr.a4;
+			sa_params->sa_in_params.dest_addr.addr_type =
+			    DPA_IPSEC_ADDR_T_IPv4;
+			sa_params->sa_in_params.dest_addr.ipv4.word =
+			    x->id.daddr.a4;
+		} else if (x->props.family == AF_INET6) {
+			sa_params->sa_in_params.src_addr.addr_type =
+			    DPA_IPSEC_ADDR_T_IPv6;
+			memcpy(sa_params->sa_in_params.src_addr.ipv6.byte,
+			       x->props.saddr.a6, sizeof(x->props.saddr.a6));
+			sa_params->sa_in_params.dest_addr.addr_type =
+			    DPA_IPSEC_ADDR_T_IPv6;
+			memcpy(sa_params->sa_in_params.dest_addr.ipv6.byte,
+			       x->id.daddr.a6, sizeof(x->id.daddr.a6));
+		}
+		memset(&def_sa_action, 0, sizeof(def_sa_action));
+		def_sa_action.type = DPA_CLS_TBL_ACTION_ENQ;
+		def_sa_action.enable_statistics = 0;
+		def_sa_action.enq_params.new_fqid = def_sa_act_fqid;
+		def_sa_action.enq_params.override_fqid = 1;
+		sa_params->sa_in_params.post_ipsec_action = def_sa_action;
+		sa_params->sa_in_params.policy_miss_fqid = policy_miss_fqid;
+		sa_params->sa_in_params.arw = DPA_IPSEC_ARSNONE;
+	}
+	ret = dpa_ipsec_create_sa(dpa_ipsec_id, sa_params, sa_id);
+	return ret;
+}
+
+static inline int offload_policy(struct dpa_ipsec_policy_params *pol_params,
+				 struct xfrm_selector *sel, int sa_id)
+{
+	int ret = 0;
+
+	memset(pol_params, 0, sizeof(*pol_params));
+	pol_params->mtu = usr_params.mtu_pre_enc;
+	if (sel->family == AF_INET) {
+		pol_params->src_addr.addr_type = DPA_IPSEC_ADDR_T_IPv4;
+		pol_params->src_addr.ipv4.word = sel->saddr.a4;
+		pol_params->dest_addr.addr_type = DPA_IPSEC_ADDR_T_IPv4;
+		pol_params->dest_addr.ipv4.word = sel->daddr.a4;
+	} else if (sel->family == AF_INET6) {
+		pol_params->src_addr.addr_type = DPA_IPSEC_ADDR_T_IPv6;
+		memcpy(pol_params->src_addr.ipv6.byte,
+			sel->saddr.a6, sizeof(sel->saddr.a6));
+		pol_params->dest_addr.addr_type = DPA_IPSEC_ADDR_T_IPv6;
+		memcpy(pol_params->dest_addr.ipv6.byte,
+			sel->daddr.a6, sizeof(sel->daddr.a6));
+	}
+	pol_params->src_prefix_len = sel->prefixlen_s;
+	pol_params->dest_prefix_len = sel->prefixlen_d;
+	pol_params->protocol = sel->proto;
+	pol_params->src_port = sel->sport;
+	pol_params->src_port_mask = sel->sport_mask;
+	pol_params->dest_port = sel->dport;
+	pol_params->dest_port_mask = sel->dport_mask;
+
+	ret = dpa_ipsec_sa_add_policy(sa_id, pol_params);
+	return ret;
+}
+
+/*
+ Loops over all XFRM policies and matches the template with the given SA.
+ Creates DPA IPsec policies/SAs based on XFRM counterparts.
+ */
+static int policy_walk_func(struct xfrm_policy *pol, int dir, int count,
+			    void *ptr)
+{
+	int err = 0;
+	int sa_id = -1;
+	struct sa *sa;
+	struct xfrm_state *x = ((struct work_arg *)ptr)->x;
+	int from_pol = ((struct work_arg *)ptr)->from_pol;
+	struct dpa_ipsec_sa_params sa_params;
+	struct dpa_ipsec_policy_params pol_params;
+
+	/* we support only one template per policy so only the
+	   first transform is checked */
+	if (x->props.family == AF_INET) {
+		if (!((x->id.daddr.a4 == pol->xfrm_vec[0].id.daddr.a4) &&
+		      (x->props.saddr.a4 == pol->xfrm_vec[0].saddr.a4) &&
+		      (x->id.proto == pol->xfrm_vec[0].id.proto))) {
+			/* continue walking */
+			return 0;
+		}
+	} else if (x->props.family == AF_INET6) {
+		if ((ipv6_addr_cmp((struct in6_addr *)x->id.daddr.a6,
+				   (struct in6_addr *)pol->xfrm_vec[0].id.daddr.
+				   a6)
+		     || ipv6_addr_cmp((struct in6_addr *)x->props.saddr.a6,
+				      (struct in6_addr *)pol->xfrm_vec[0].saddr.
+				      a6)
+		     || (x->id.proto != pol->xfrm_vec[0].id.proto)))
+			return 0;
+	}
+
+	if (dir == XFRM_POLICY_OUT || dir == XFRM_POLICY_IN)
+		sa = find_sa(sa_htable, x, dir);
+	else
+		return 0;	/* continue walking */
+
+	if (!sa) {
+		memset(&sa_params, 0, sizeof(sa_params));
+		err = offload_sa(dpa_ipsec_id, &sa_params, x,
+				 usr_params.def_sa_fqid,
+				 usr_params.pol_miss_fqid, dir, &sa_id);
+
+		if (err < 0) {
+			pr_err("%s(%d) : Error offloading out SA SPI %d (%d)\n",
+			       __func__, __LINE__, x->id.spi, err);
+			return err;
+		}
+		pr_info("Created SA SPI %x sa_id %d dir %s\n", x->id.spi,
+			sa_id, (dir == XFRM_POLICY_OUT) ? "OUT" : "IN");
+		sa = hash_sa(sa_htable, x, sa_params.sa_dir, sa_id);
+		if (!sa) {
+			pr_err("%s(%d) : Cannot allocate hash entry\n",
+			       __func__, __LINE__);
+			return -ENOMEM;
+		}
+
+	}
+	err = offload_policy(&pol_params, &pol->selector, sa->sa_id);
+	if (err < 0) {
+		pr_err("%s(%d): Error offloading policy index %d (%d)\n",
+		       __func__, __LINE__, pol->index, err);
+		return err;
+	}
+	/* stop walking if notified by policy to avoid
+	offloading twice the same policy*/
+	if (from_pol)
+		return 1;
+
+	return 0;
+}
+
+/* XFRM policy notifications
+ */
+static int xfrm_km_policy_notify(struct xfrm_policy *x, int dir,
+				 const struct km_event *c)
+{
+	int ret = 0;
+	struct xfrm_state *state;
+	struct work_arg *work;
+
+	switch (c->event) {
+	case XFRM_MSG_UPDPOLICY:
+		pr_info("%s: XFRM_MSG_NEWPOLICY event, policy index %d\n",
+			__func__, x->index);
+	case XFRM_MSG_NEWPOLICY:
+		if (c->event == XFRM_MSG_NEWPOLICY)
+			pr_info
+			    ("%s: XFRM_MSG_NEWPOLICY event, policy index %d\n",
+			     __func__, x->index);
+		/* we support only one template per policy so only the
+		   first transform is checked */
+		state = xfrm_state_lookup_byaddr(&init_net, 0,
+						 &x->xfrm_vec[0].id.daddr,
+						 &x->xfrm_vec[0].saddr,
+						 x->xfrm_vec[0].id.proto,
+						 x->family);
+		if (!state)
+			return -ENOENT;
+
+		if ((dir == XFRM_POLICY_IN || dir == XFRM_POLICY_OUT)) {
+			work = kzalloc(sizeof(*work), GFP_KERNEL);
+			if (!work) {
+				pr_err("%s(%d): Cannot allocate offld work\n",
+				       __func__, __LINE__);
+				return -ENOMEM;
+			}
+			work->x = state;
+			work->from_pol = 1;
+			INIT_WORK(&work->work, work_func);
+			schedule_work_on(offld_work_cpu, &work->work);
+		}
+
+		break;
+	case XFRM_MSG_DELPOLICY:
+		pr_info("%s: XFRM_MSG_DELPOLICY event, policy index %d\n",
+			__func__, x->index);
+		break;
+	case XFRM_MSG_GETPOLICY:
+		pr_info("%s: XFRM_MSG_GETPOLICY event, policy index %d\n",
+			__func__, x->index);
+		break;
+	case XFRM_MSG_POLEXPIRE:
+		pr_info("%s: XFRM_MSG_POLEXPIRE event, policy index %d\n",
+			__func__, x->index);
+		break;
+	case XFRM_MSG_FLUSHPOLICY:
+		pr_info("%s: XFRM_MSG_FLUSHPOLICY event, policy index %d\n",
+			__func__, x->index);
+		break;
+	}
+
+	return ret;
+
+}
+
+int xfrm_km_acquire(struct xfrm_state *x, struct xfrm_tmpl *tmpl,
+		    struct xfrm_policy *xp, int dir)
+{
+	pr_info("%s:\n", __func__);
+	return 0;
+}
+
+static int xfrm_km_initialized;
+
+/* XFRM key manager interface */
+static struct xfrm_mgr xfrm_mgr = {
+	.id = "dpa_ipacc",
+	.notify = xfrm_km_state_notify,
+	.notify_policy = xfrm_km_policy_notify,
+	.acquire = xfrm_km_acquire,
+};
+
+int init_xfrm_km(struct xfrm_km_uparms *params)
+{
+	int err = 0;
+	int core;
+
+	/* store user params for DPA IPsec runtime API */
+	usr_params = *params;
+
+	/* register ourselves as a key manager */
+	err = xfrm_register_km(&xfrm_mgr);
+	if (unlikely(err < 0)) {
+		pr_err("%s(%d): Cannot register %s XFRM key manager (%d)\n",
+		       __func__, __LINE__, xfrm_mgr.id, err);
+		return err;
+	}
+	core = get_offld_work_cpu();
+	if (core != -1)
+		offld_work_cpu = core;
+
+	xfrm_km_initialized = 1;
+	return err;
+}
+
+void cleanup_xfrm_km(void)
+{
+	if (!xfrm_km_initialized)
+		return;
+	xfrm_unregister_km(&xfrm_mgr);
+}
diff --git a/drivers/staging/fsl_dpa_offload/usecases/xfrm_utils.c b/drivers/staging/fsl_dpa_offload/usecases/xfrm_utils.c
new file mode 100644
index 0000000..773373f
--- /dev/null
+++ b/drivers/staging/fsl_dpa_offload/usecases/xfrm_utils.c
@@ -0,0 +1,231 @@
+/* Copyright 2008-2012 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/inetdevice.h>
+#include <linux/crypto.h>
+#include <linux/in.h>		/* for IP protocols, IPPROTO_ESP */
+#include <net/xfrm.h>
+
+
+#if (defined DEBUG_XFRM)
+void dump_xfrm_sa(struct xfrm_state *x)
+{
+	char authenc_name[CRYPTO_MAX_ALG_NAME];
+	int len;
+	char *xfrm_km_states[] = {
+		[XFRM_STATE_VOID] = "void",
+		[XFRM_STATE_ACQ] = "acq",
+		[XFRM_STATE_VALID] = "valid",
+		[XFRM_STATE_ERROR] = "error",
+		[XFRM_STATE_EXPIRED] = "expired",
+		[XFRM_STATE_DEAD] = "dead",
+	};
+
+	/* SA general info */
+	pr_info("\tx = %p\n", x);
+	/* SPI */
+	pr_info("\tx->id.spi = 0x%x\n", htonl(x->id.spi));
+	/* ESP/AH */
+	pr_info("\tx->id.proto = 0x%x\n", htonl(x->id.proto));
+	/* tunnel destination */
+	pr_info("\tx->id.daddr.a4 = %pI4\n", &x->id.daddr.a4);
+	pr_info("\tx->props.saddr.a4 = %pI4\n", &x->props.saddr.a4);
+	pr_info("\tx->km.state = %s\n", xfrm_km_states[x->km.state]);
+	pr_info("\tx->km.dying = %d\n", x->km.dying);
+	pr_info("\tx->data = %p\n", x->data);
+
+	/* NAT-T: x->encap is non-NULL only with UDP Encapsulation */
+	if (x->encap) {
+		struct xfrm_encap_tmpl *encap = x->encap;
+		pr_info("\tNAT-T is enabled\n");
+		pr_info("\t\tx->encap->encap_type: %s\n",
+		       encap->encap_type ==
+		       UDP_ENCAP_ESPINUDP ? "UDP_ENCAP_ESPINUDP" :
+			(encap->encap_type == UDP_ENCAP_ESPINUDP_NON_IKE ?
+				"UDP_ENCAP_ESPINUDP_NON_IKE" : "Unsupported"));
+		pr_info("\t\tx->encap->encap_sport = %d\n",
+		       ntohs(encap->encap_sport));
+		pr_info("\t\tx->encap->encap_dport = %d\n",
+		       ntohs(encap->encap_dport));
+	}
+
+	pr_info("\tx->props.mode = %d\n", x->props.mode);
+	if (x->props.mode == XFRM_MODE_TUNNEL)
+		pr_info("\tSA is TUNNEL mode!\n");
+	else if (x->props.mode == XFRM_MODE_TRANSPORT)
+		pr_info("\tSA is TRANSPORT mode!\n");
+	else
+		pr_err("\tSA has unsupported mode!\n");
+
+	/* Authentication algorithm */
+	if (x->aalg) {
+		struct xfrm_algo_desc *aalg_desc;
+		int i;
+		pr_info("\tx->aalg->alg_name = %s\n",
+		       x->aalg->alg_name);
+		pr_info("\tx->aalg->alg_key_len = %d\n",
+		       x->aalg->alg_key_len);
+		pr_info("\tx->aalg->alg_key:");
+		for (i = 0; i < x->aalg->alg_key_len / 8; i++) {
+			if (i % 16 == 0)
+				pr_cont("\n\t\t");
+			pr_cont("%02x ",
+			       (unsigned char)x->aalg->alg_key[i]);
+		}
+		pr_cont("\n");
+		aalg_desc = xfrm_aalg_get_byname(x->aalg->alg_name, 0);
+		BUG_ON(!aalg_desc);
+		pr_info(
+		       "\taalg_desc->uinfo.auth.icv_fullbits = %d, "
+		       "aalg_desc->uinfo.auth.icv_truncbits = %d\n",
+		       aalg_desc->uinfo.auth.icv_fullbits,
+		       aalg_desc->uinfo.auth.icv_truncbits);
+		pr_info(
+		       "\taalg_desc->uinfo.auth.icv_fullbits/8 = %d, "
+		       "aalg_desc->uinfo.auth.icv_truncbits/8 = %d\n",
+		       aalg_desc->uinfo.auth.icv_fullbits / 8,
+		       aalg_desc->uinfo.auth.icv_truncbits / 8);
+	}
+	/* Encryption algorithm */
+	if (x->ealg) {
+		int i;
+		pr_info("\tx->ealg->alg_name = %s\n",
+		       x->ealg->alg_name);
+		pr_info("\tx->ealg->alg_key_len = %d\n",
+		       x->ealg->alg_key_len);
+		pr_info("\tx->ealg->alg_key:");
+		for (i = 0; i < x->ealg->alg_key_len / 8; i++) {
+			if (i % 16 == 0)
+				pr_cont("\n\t\t");
+			pr_cont("%02x ",
+			       (unsigned char)x->ealg->alg_key[i]);
+		}
+		pr_cont("\n");
+	}
+
+	if (x->aead) {
+		int i;
+		pr_info("\tx->aead->alg_name = %s\n",
+		       x->aead->alg_name);
+		pr_info("\tx->aead->alg_key_len = %d\n",
+		       x->aead->alg_key_len);
+		pr_info("\tx->aead->alg_icv_len = %d\n",
+		       x->aead->alg_icv_len);
+		pr_info("\tx->aead->alg_key:");
+		for (i = 0; i < x->aead->alg_key_len / 8; i++) {
+			if (i % 16 == 0)
+				pr_cont("\n\t\t");
+			pr_cont("%02x ",
+			       (unsigned char)x->aead->alg_key[i]);
+		}
+	}
+
+	len = snprintf(authenc_name, CRYPTO_MAX_ALG_NAME, "authenc(%s,%s)",
+		       x->aalg ? x->aalg->alg_name : "digest_null",
+		       x->ealg->alg_name);
+	BUG_ON(len > CRYPTO_MAX_ALG_NAME);
+
+	/*
+	   if (!in_atomic()) {
+	   aead = crypto_alloc_aead(authenc_name, 0, 0);
+	   BUG_ON(!aead);
+	   pr_info(
+		"\tcrypto_aead_ivsize() = %d\n", crypto_aead_ivsize(aead));
+	   crypto_free_aead(aead);
+	   }
+	 */
+	if (x->aead) {
+		pr_info("\tx->aead->alg_name = %s\n",
+		       x->aead->alg_name);
+		pr_info("\tx->aead->alg_key_len = %d\n",
+		       x->aead->alg_key_len);
+		pr_info("\tx->aead->alg_icv_len = %d\n",
+		       x->aead->alg_icv_len);
+	}
+	if (x->type) {
+		pr_info("\tx->type->description = %s\n",
+		       x->type->description);
+		pr_info("\tx->type->flags = 0x%x\n", x->type->flags);
+	}
+	/* Lifetime parameters */
+	pr_info("\tx->lft.soft_byte_limit = %lld\n",
+	       x->lft.soft_byte_limit);
+	pr_info("\tx->lft.hard_byte_limit = %lld\n",
+	       x->lft.hard_byte_limit);
+	pr_info("\tx->lft.soft_packet_limit = %lld\n",
+	       x->lft.soft_packet_limit);
+	pr_info("\tx->lft.hard_packet_limit = %lld\n",
+	       x->lft.hard_packet_limit);
+	pr_info("\tx->lft.soft_add_expires_seconds = %lld\n",
+	       x->lft.soft_add_expires_seconds);
+	pr_info("\tx->lft.hard_add_expires_seconds = %lld\n",
+	       x->lft.hard_add_expires_seconds);
+	pr_info("\tx->lft.soft_use_expires_seconds = %lld\n",
+	       x->lft.soft_use_expires_seconds);
+	pr_info("\tx->lft.hard_use_expires_seconds = %lld\n",
+	       x->lft.hard_use_expires_seconds);
+	pr_info("\n\n");
+}
+
+void dump_xfrm_selector(struct xfrm_selector *sel)
+{
+	pr_info("\tsaddr %pI4 daddr %pI4\n", &sel->saddr.a4,
+	       &sel->daddr.a4);
+	pr_info("\tprefixlen_s %d prefixlen_d %d\n", sel->prefixlen_s,
+	       sel->prefixlen_d);
+	pr_info("\tproto %d\n", sel->proto);
+	pr_info("\tsport %d dport %d\n", sel->sport, sel->dport);
+	pr_info("\tsport mask %04x dport mask %04x\n", sel->sport_mask,
+	       sel->dport_mask);
+}
+
+void dump_xfrm_template(struct xfrm_tmpl *tmpl)
+{
+	pr_info("\ttemplates:\n");
+	pr_info("\t\tdaddr %pI4 spi %x proto %d saddr %pI4 mode %d\n",
+	       &tmpl->id.daddr.a4, tmpl->id.spi, tmpl->id.proto,
+	       &tmpl->saddr.a4, tmpl->mode);
+}
+#else
+void dump_xfrm_sa(struct xfrm_state *x)
+{
+}
+
+void dump_xfrm_selector(struct xfrm_selector *sel)
+{
+}
+
+void dump_xfrm_template(struct xfrm_tmpl *tmpl)
+{
+}
+#endif
-- 
1.7.5.4

