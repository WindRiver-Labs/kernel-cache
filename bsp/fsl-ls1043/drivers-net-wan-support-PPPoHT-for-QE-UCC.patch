From 2db00a1bba2745f109a3a937781e563b5e0a474d Mon Sep 17 00:00:00 2001
From: Xu Hao <H.Xu@freescale.com>
Date: Tue, 21 Jul 2015 14:17:54 +0800
Subject: [PATCH 315/451] drivers/net/wan: support PPPoHT for QE-UCC

Below are contents this patch rectified or modified:
1.redesigned tx buffer archtecture.
2.modified rx logic to slove buffer deficiency problem.
3.code added to support PPP tx & rx with CRC checking.
4.modified interfaces with Generic HDLC Layer.
5.added traffic control for Tx, converted NAPI-like to NAPI for Rx.
6.rectified frame statistics.
7.modified debug code
8.modified TDM registers setting to make it more stable.

Signed-off-by: Xu Hao <H.Xu@freescale.com>
[Xulin: Original patch taken from
Linux-LS1043A-SDK-V0.4-SOURCE-20150826-yocto.iso]
Signed-off-by: Xulin Sun <xulin.sun@windriver.com>
---
 drivers/net/wan/fsl_ucc_hdlc.c |  337 ++++++++++++++++++++++++++++++----------
 drivers/net/wan/fsl_ucc_hdlc.h |   36 +++--
 include/linux/fsl/ucc_fast.h   |    1 +
 3 files changed, 282 insertions(+), 92 deletions(-)

diff --git a/drivers/net/wan/fsl_ucc_hdlc.c b/drivers/net/wan/fsl_ucc_hdlc.c
index 06f4b86..6834376 100644
--- a/drivers/net/wan/fsl_ucc_hdlc.c
+++ b/drivers/net/wan/fsl_ucc_hdlc.c
@@ -28,20 +28,23 @@
 #include <linux/of_irq.h>
 #include <linux/of_platform.h>
 #include <linux/slab.h>
+#include <uapi/linux/if_arp.h>
 #include "fsl_ucc_hdlc.h"
 
 #define DRV_DESC "Freescale QE UCC HDLC Driver"
 #define DRV_NAME "ucc_hdlc"
 
-#undef DEBUG
-#define QE_HDLC_TEST
+#define TDM_PPPOHT_SLIC_MAXIN
+/* #define DEBUG */
+/* #define QE_HDLC_TEST */
+#define BROKEN_FRAME_INFO
 
 static struct ucc_hdlc_info uhdlc_primary_info = {
 	.uf_info = {
-		.tsa = 0,
+		.tsa = 1,
 		.cdp = 0,
 		.cds = 1,
-		.ctsp = 0,
+		.ctsp = 1,
 		.ctss = 1,
 		.revd = 0,
 		.urfs = 256,
@@ -62,10 +65,16 @@ static struct ucc_hdlc_info uhdlc_primary_info = {
 	.si_info = {
 #ifdef CONFIG_FSL_PQ_MDS_T1
 		.simr_rfsd = 1,		/* TDM card need 1 bit delay */
+		.simr_tfsd = 0,
+#else
+#ifdef TDM_PPPOHT_SLIC_MAXIN
+		.simr_rfsd = 1,
+		.simr_tfsd = 2,
 #else
 		.simr_rfsd = 0,
-#endif
 		.simr_tfsd = 0,
+#endif
+#endif
 		.simr_crt = 0,
 		.simr_sl = 0,
 		.simr_ce = 1,
@@ -86,15 +95,15 @@ static void dump_siram(struct ucc_hdlc_private *priv)
 
 	dev_info(priv->dev, "Dump the SI RX RAM\n");
 	for (i = 0; i < priv->num_of_ts; i++) {
-		pr_info("%04x ", siram[priv->siram_entry_id * 32 + i]);
-		if ((i + 1) % 4)
+		pr_info("%04x ", be16_to_cpu(siram[priv->siram_entry_id * 32 + i]));
+		if (!((i + 1) & 3))
 			pr_info("\n");
 	}
 
 	dev_info(priv->dev, "Dump the SI TX RAM\n");
 	for (i = 0; i < priv->num_of_ts; i++) {
-		pr_info("%04x ", siram[priv->siram_entry_id * 32 + 0x200 + i]);
-		if ((i + 1) % 4)
+		pr_info("%04x ", be16_to_cpu(siram[priv->siram_entry_id * 32 + 0x200 + i]));
+		if (!((i + 1) & 3))
 			pr_info("\n");
 	}
 }
@@ -112,13 +121,14 @@ static void mem_disp(u8 *addr, int size)
 		u32 *i32 = i;
 
 		pr_info("0x%08p: %08x %08x %08x %08x\r\n",
-			i32, i32[0], i32[1], i32[2], i32[3]);
+			i32, be32_to_cpu(i32[0]), be32_to_cpu(i32[1]),
+			be32_to_cpu(i32[2]), be32_to_cpu(i32[3]));
 	}
 
 	if (not_align == 1)
 		pr_info("0x%08p: ", i);
 	for (; i < addr + size4_aling; i += 4)
-		pr_info("%08x ", *((u32 *) (i)));
+		pr_info("%08x ", be32_to_cpu(*((u32 *) (i))));
 	for (; i < addr + size; i++)
 		pr_info("%02x", *((u8 *) (i)));
 	if (not_align == 1)
@@ -163,13 +173,13 @@ static void dump_bds(struct ucc_hdlc_private *priv)
 	int length;
 
 	if (priv->tx_bd_base) {
-		length = sizeof(struct qe_bd) * NUM_OF_BUF;
+		length = sizeof(struct qe_bd) * TX_BD_RING_LEN;
 		dev_info(priv->dev, " Dump tx BDs\n");
 		mem_disp((u8 *)priv->tx_bd_base, length);
 	}
 
 	if (priv->rx_bd_base) {
-		length = sizeof(struct qe_bd) * NUM_OF_BUF;
+		length = sizeof(struct qe_bd) * RX_BD_RING_LEN;
 		dev_info(priv->dev, " Dump rx BDs\n");
 		mem_disp((u8 *)priv->rx_bd_base, length);
 	}
@@ -194,8 +204,8 @@ static void dump_priv(struct ucc_hdlc_private *priv)
 	dev_info(priv->dev, "dma_rx_addr; = 0x%x\n", (u32)priv->dma_rx_addr);
 	dev_info(priv->dev, "tx_bd; = 0x%x\n", (u32)priv->tx_bd_base);
 	dev_info(priv->dev, "rx_bd; = 0x%x\n", (u32)priv->rx_bd_base);
-	dev_info(priv->dev, "phase_rx = 0x%x\n", (u32)priv->phase_rx);
-	dev_info(priv->dev, "phase_tx = 0x%x\n", (u32)priv->phase_tx);
+	dev_info(priv->dev, "curtx_bd = 0x%x\n", (u32)priv->curtx_bd);
+	dev_info(priv->dev, "currx_bd = 0x%x\n", (u32)priv->currx_bd);
 	dev_info(priv->dev, "ucc_pram_offset = 0x%x\n", priv->ucc_pram_offset);
 
 }
@@ -336,6 +346,7 @@ static int uhdlc_init(struct ucc_hdlc_private *priv)
 
 	/* Loopback mode */
 	if (priv->loopback) {
+		pr_info("TDM Mode: Loopback Mode\n");
 		gumr = ioread32be(&priv->uf_regs->gumr);
 		gumr |= (0x40000000 | UCC_FAST_GUMR_CDS | UCC_FAST_GUMR_TCI);
 		gumr &= ~(UCC_FAST_GUMR_CTSP | UCC_FAST_GUMR_RSYN);
@@ -358,7 +369,7 @@ static int uhdlc_init(struct ucc_hdlc_private *priv)
 	priv->tx_ring_size = TX_BD_RING_LEN;
 	/* Alloc Rx BD */
 	priv->rx_bd_base = dma_alloc_coherent(priv->dev,
-			RX_BD_RING_LEN * sizeof(struct qe_bd),
+			RX_BD_RING_LEN * sizeof(struct qe_bd *),
 			&priv->dma_rx_bd, GFP_KERNEL);
 
 	if (IS_ERR_VALUE((unsigned long)priv->rx_bd_base)) {
@@ -369,7 +380,7 @@ static int uhdlc_init(struct ucc_hdlc_private *priv)
 
 	/* Alloc Tx BD */
 	priv->tx_bd_base = dma_alloc_coherent(priv->dev,
-			TX_BD_RING_LEN * sizeof(struct qe_bd),
+			TX_BD_RING_LEN * sizeof(struct qe_bd *),
 			&priv->dma_tx_bd, GFP_KERNEL);
 
 	if (IS_ERR_VALUE((unsigned long)priv->tx_bd_base)) {
@@ -388,10 +399,17 @@ static int uhdlc_init(struct ucc_hdlc_private *priv)
 		goto pram_alloc_error;
 	}
 
+	priv->rx_skbuff = kmalloc_array(priv->rx_ring_size,
+			sizeof(*priv->rx_skbuff), GFP_KERNEL);
+	if (!priv->rx_skbuff)
+		goto rx_skb_alloc_error;
+	for (i = 0; i < priv->rx_ring_size; i++)
+		priv->rx_skbuff[i] = NULL;
+
 	priv->tx_skbuff = kmalloc_array(priv->tx_ring_size,
 			sizeof(*priv->tx_skbuff), GFP_KERNEL);
 	if (!priv->tx_skbuff)
-		goto pram_alloc_error;
+		goto tx_skb_alloc_error;
 	for (i = 0; i < priv->tx_ring_size; i++)
 		priv->tx_skbuff[i] = NULL;
 
@@ -421,9 +439,9 @@ static int uhdlc_init(struct ucc_hdlc_private *priv)
 		goto riptr_alloc_error;
 	}
 
-	tiptr = qe_muram_alloc(64, 32);
+	tiptr = qe_muram_alloc(32, 32);
 	if (IS_ERR_VALUE(tiptr)) {
-		dev_err(priv->dev, "Cannot allocate MURAM mem for transmit internal temp data pointer\n");
+		dev_err(priv->dev, "Cannot allocate MURAM mem for Transmit internal temp data pointer\n");
 		ret = -ENOMEM;
 		goto tiptr_alloc_error;
 	}
@@ -451,14 +469,14 @@ static int uhdlc_init(struct ucc_hdlc_private *priv)
 	iowrite16be(1, &priv->ucc_pram->rfthr);
 	iowrite16be(1, &priv->ucc_pram->rfcnt);
 	iowrite16be(DEFAULT_ADDR_MASK, &priv->ucc_pram->hmask);
-	iowrite16be(DEFAULT_BROAD_ADDR, &priv->ucc_pram->haddr2);
 	iowrite16be(DEFAULT_HDLC_ADDR, &priv->ucc_pram->haddr1);
+	iowrite16be(DEFAULT_HDLC_ADDR, &priv->ucc_pram->haddr2);
 	iowrite16be(DEFAULT_HDLC_ADDR, &priv->ucc_pram->haddr3);
 	iowrite16be(DEFAULT_HDLC_ADDR, &priv->ucc_pram->haddr4);
 
 	/* Get BD buffer */
 	bd_buffer = dma_alloc_coherent(priv->dev,
-			RX_BD_RING_LEN * MAX_RX_BUF_LENGTH,
+			(RX_BD_RING_LEN + TX_BD_RING_LEN) * MAX_RX_BUF_LENGTH,
 			&bd_dma_addr, GFP_KERNEL);
 
 	if (!bd_buffer) {
@@ -466,11 +484,14 @@ static int uhdlc_init(struct ucc_hdlc_private *priv)
 		return -ENOMEM;
 	}
 
-	memset(bd_buffer, 0,  RX_BD_RING_LEN * MAX_RX_BUF_LENGTH);
+	memset(bd_buffer, 0, (RX_BD_RING_LEN + TX_BD_RING_LEN)
+			* MAX_RX_BUF_LENGTH);
 
 	priv->rx_buffer = bd_buffer;
+	priv->tx_buffer = bd_buffer + RX_BD_RING_LEN * MAX_RX_BUF_LENGTH;
 
 	priv->dma_rx_addr = bd_dma_addr;
+	priv->dma_tx_addr = bd_dma_addr + RX_BD_RING_LEN * MAX_RX_BUF_LENGTH;
 
 	for (i = 0; i < RX_BD_RING_LEN; i++) {
 		if (i < (RX_BD_RING_LEN - 1))
@@ -490,6 +511,8 @@ static int uhdlc_init(struct ucc_hdlc_private *priv)
 			bd_status =  T_I | T_TC | T_W;
 
 		iowrite32be(bd_status, (u32 *)(priv->tx_bd_base + i));
+		iowrite32be(priv->dma_tx_addr + i * MAX_RX_BUF_LENGTH,
+				&priv->tx_bd_base[i].buf);
 	}
 
 	return 0;
@@ -497,6 +520,10 @@ static int uhdlc_init(struct ucc_hdlc_private *priv)
 tiptr_alloc_error:
 	qe_muram_free(riptr);
 riptr_alloc_error:
+	kfree(priv->tx_skbuff);
+tx_skb_alloc_error:
+	kfree(priv->rx_skbuff);
+rx_skb_alloc_error:
 	qe_muram_free(priv->ucc_pram_offset);
 pram_alloc_error:
 	dma_free_coherent(priv->dev,
@@ -518,32 +545,64 @@ static netdev_tx_t ucc_hdlc_tx(struct sk_buff *skb, struct net_device *dev)
 	struct ucc_hdlc_private *priv = (struct ucc_hdlc_private *)hdlc->priv;
 	struct qe_bd __iomem *bd;
 	u32 bd_status;
+	unsigned long flags;
+#ifdef QE_HDLC_TEST
 	u8 *send_buf;
 	int i;
-	u32 *hdlc_head, tmp_head;
+#endif
+	u16 *proto_head, tmp_head;
+
+	switch (dev->type) {
+	case ARPHRD_RAWHDLC:
+		if (skb_headroom(skb) < HDLC_HEAD_LEN) {
+			dev->stats.tx_dropped++;
+			dev_kfree_skb(skb);
+			netdev_err(dev, "No enough space for hdlc head\n");
+			return -ENOMEM;
+		}
+
+		skb_push(skb, HDLC_HEAD_LEN);
+
+		proto_head = (u16 *)skb->data;
+		tmp_head = *proto_head;
+		tmp_head = (tmp_head & HDLC_HEAD_MASK) | htons(DEFAULT_HDLC_HEAD);
+		*proto_head = tmp_head;
+
+		dev->stats.tx_bytes += skb->len;
+		break;
+
+	case ARPHRD_PPP:
+		proto_head = (u16 *)skb->data;
+		if (*proto_head != ntohs(DEFAULT_PPP_HEAD)) {
+			dev->stats.tx_dropped++;
+			dev_kfree_skb(skb);
+			netdev_err(dev, "Wrong ppp header\n");
+			return -ENOMEM;
+		}
+
+		dev->stats.tx_bytes += skb->len;
+		break;
 
-	if (skb_headroom(skb) < HDLC_HEAD_LEN) {
+	default:
 		dev->stats.tx_dropped++;
 		dev_kfree_skb(skb);
-		netdev_err(dev, "No enough space for hdlc head\n");
+		netdev_err(dev, "Protocol not supported!\n");
 		return -ENOMEM;
-	}
-	skb_push(skb, HDLC_HEAD_LEN);
 
-	hdlc_head = (u32 *)skb->data;
-	tmp_head = *hdlc_head;
-	tmp_head = (tmp_head & HDLC_HEAD_MASK) | cpu_to_be32(DEFAULT_HDLC_HEAD);
-	*hdlc_head = tmp_head;
-
-	dev->stats.tx_bytes += skb->len;
-
-	send_buf = (u8 *)skb->data;
+	} /*switch right bracket*/
 
 #ifdef QE_HDLC_TEST
+	pr_info("Tx data skb->len:%d ", skb->len);
+	send_buf = (u8 *)skb->data;
 	pr_info("\nTransmitted data:\n");
-	for (i = 0; (i < 16); i++)
-		pr_info("%x ", send_buf[i]);
+	for (i = 0; (i < 1536); i++) {
+		if (i == skb->len)
+			pr_info("++++");
+		else
+		pr_info("%02x\n", send_buf[i]);
+	}
 #endif
+	spin_lock_irqsave(&priv->lock, flags);
 
 	/* Start from the next BD that should be filled */
 	bd = priv->curtx_bd;
@@ -551,18 +610,17 @@ static netdev_tx_t ucc_hdlc_tx(struct sk_buff *skb, struct net_device *dev)
 	/* Save the skb pointer so we can free it later */
 	priv->tx_skbuff[priv->skb_curtx] = skb;
 
-
 	/* Update the current skb pointer (wrapping if this was the last) */
 	priv->skb_curtx =
 	    (priv->skb_curtx + 1) & TX_RING_MOD_MASK(TX_BD_RING_LEN);
-	/* set up the buffer descriptor */
-	iowrite32be(dma_map_single(priv->dev, skb->data, skb->len,
-			DMA_TO_DEVICE),
-			&((struct qe_bd __iomem *)bd)->buf);
 
-	bd_status = (bd_status & T_W) | T_R | T_I | T_L | T_TC | skb->len;
+	/* copy skb data to tx buffer for sdma processing */
+	memcpy(priv->tx_buffer + (be32_to_cpu(bd->buf) - priv->dma_tx_addr),
+		   skb->data, skb->len);
 
 	/* set bd status and length */
+	bd_status = (bd_status & T_W) | T_R | T_I | T_L | T_TC | skb->len;
+
 	iowrite32be(bd_status, (u32 __iomem *)bd);
 
 	/* Move to next BD in the ring */
@@ -570,8 +628,16 @@ static netdev_tx_t ucc_hdlc_tx(struct sk_buff *skb, struct net_device *dev)
 		bd += 1;
 	else
 		bd = priv->tx_bd_base;
+
+	if (bd == priv->dirty_tx) {
+		if (!netif_queue_stopped(dev))
+			netif_stop_queue(dev);
+	}
+
 	priv->curtx_bd = bd;
 
+	spin_unlock_irqrestore(&priv->lock, flags);
+
 	return NETDEV_TX_OK;
 }
 
@@ -596,11 +662,12 @@ static int hdlc_tx_done(struct ucc_hdlc_private *priv)
 		skb = priv->tx_skbuff[priv->skb_dirtytx];
 		if (!skb)
 			break;
-
+#ifdef QE_HDLC_TEST
+		pr_info("TxBD: %x\n", bd_status);
+#endif
 		dev->stats.tx_packets++;
-		dma_unmap_single(priv->dev,
-				ioread32be(&((struct qe_bd __iomem *)bd)->buf),
-				skb->len, DMA_TO_DEVICE);
+		memset(priv->tx_buffer + (be32_to_cpu(bd->buf) - priv->dma_tx_addr),
+			   0, skb->len);
 		dev_kfree_skb_irq(skb);
 
 		priv->tx_skbuff[priv->skb_dirtytx] = NULL;
@@ -633,55 +700,98 @@ static int hdlc_rx_done(struct ucc_hdlc_private *priv, int rx_work_limit)
 	u32 bd_status;
 	u16 length, howmany = 0;
 	u8 *bdbuffer;
+#ifdef QE_HDLC_TEST
 	int i;
+	static int entry;
+#endif
 
 	bd = priv->currx_bd;
 	bd_status = ioread32be((u32 __iomem *)bd);
 
 	/* while there are received buffers and BD is full (~R_E) */
 	while (!((bd_status & (R_E)) || (--rx_work_limit < 0))) {
+		if (bd_status & R_CR) {
+#ifdef BROKEN_FRAME_INFO
+			pr_info("Broken Frame with RxBD: %x\n", bd_status);
+#endif
+			dev->stats.rx_dropped++;
+			goto recycle;
+		}
 		bdbuffer = priv->rx_buffer +
 			(priv->currx_bdnum * MAX_RX_BUF_LENGTH);
 		length = (u16) (bd_status & BD_LENGTH_MASK);
 
 #ifdef QE_HDLC_TEST
+		pr_info("Received data length:%d", length);
+		pr_info("while entry times:%d", entry++);
+
 		pr_info("\nReceived data:\n");
-		for (i = 0; (i < 16); i++)
-			pr_info("%x ", bdbuffer[i]);
+		for (i = 0; (i < 1536); i++) {
+			if (i == length)
+				pr_info("++++");
+			else
+			pr_info("%02x\n", bdbuffer[i]);
+		}
 #endif
 
-		bdbuffer += HDLC_HEAD_LEN;
-		length -= (HDLC_HEAD_LEN + HDLC_CRC_SIZE);
-		skb = dev_alloc_skb(length);
-		if (!skb) {
-			dev->stats.rx_dropped++;
-			return -ENOMEM;
-		}
+		switch (dev->type) {
+		case ARPHRD_RAWHDLC:
+			bdbuffer += HDLC_HEAD_LEN;
+			length -= (HDLC_HEAD_LEN + HDLC_CRC_SIZE);
+
+			skb = dev_alloc_skb(length);
+			if (!skb) {
+				dev->stats.rx_dropped++;
+				return -ENOMEM;
+			}
+
+			skb_put(skb, length);
+			skb->len = length;
+			skb->dev = dev;
+			memcpy(skb->data, bdbuffer, length);
+			break;
+
+		case ARPHRD_PPP:
+			length -= HDLC_CRC_SIZE;
 
-		skb_put(skb, length);
-		skb->len = length;
-		skb->dev = dev;
-		memcpy(skb->data, bdbuffer, length);
+			skb = dev_alloc_skb(length);
+			if (!skb) {
+				dev->stats.rx_dropped++;
+				return -ENOMEM;
+			}
+
+			skb_put(skb, length);
+			skb->len = length;
+			skb->dev = dev;
+			memcpy(skb->data, bdbuffer, length);
+			break;
+		}
 
 		dev->stats.rx_packets++;
 		dev->stats.rx_bytes += skb->len;
 		howmany++;
 		if (hdlc->proto)
 			skb->protocol = hdlc_type_trans(skb, dev);
-		else
-			skb->protocol = cpu_to_be16(ETH_P_IP);
-		netif_rx(skb);
+#ifdef QE_HDLC_TEST
+		pr_info("skb->protocol:%x\n", skb->protocol);
+#endif
+		netif_receive_skb(skb);
+
+recycle:
+		iowrite32be((bd_status & ~BD_LENGTH_MASK) | R_E | R_I, (u32 *)bd);
 
 		/* update to point at the next bd */
-		if (bd_status & R_W)
+		if (bd_status & R_W) {
+			priv->currx_bdnum = 0;
 			bd = priv->rx_bd_base;
-		else
-			bd += 1;
+		} else {
+			if (priv->currx_bdnum < (RX_BD_RING_LEN - 1))
+				priv->currx_bdnum += 1;
+			else
+				priv->currx_bdnum = RX_BD_RING_LEN - 1;
 
-		if (priv->currx_bdnum < (RX_BD_RING_LEN - 1))
-			priv->currx_bdnum += 1;
-		else
-			priv->currx_bdnum = RX_BD_RING_LEN - 1;
+			bd += 1;
+		}
 
 		bd_status = ioread32be((u32 __iomem *)bd);
 	}
@@ -690,9 +800,31 @@ static int hdlc_rx_done(struct ucc_hdlc_private *priv, int rx_work_limit)
 	return howmany;
 }
 
+static int ucc_hdlc_poll(struct napi_struct *napi, int budget)
+{
+	struct ucc_hdlc_private *priv = container_of(napi, struct ucc_hdlc_private, napi);
+	int howmany;
+
+	/* Tx event processing */
+	spin_lock(&priv->lock);
+		hdlc_tx_done(priv);
+	spin_unlock(&priv->lock);
+
+	howmany = 0;
+	howmany += hdlc_rx_done(priv, budget - howmany);
+
+	if (howmany < budget) {
+		napi_complete(napi);
+		setbits32(priv->uccf->p_uccm, (UCCE_HDLC_RX_EVENTS | UCCE_HDLC_TX_EVENTS) << 16);
+	}
+
+	return howmany;
+}
+
 static irqreturn_t ucc_hdlc_irq_handler(int irq, void *dev_id)
 {
 	struct ucc_hdlc_private *priv = (struct ucc_hdlc_private *)dev_id;
+	struct net_device *dev = priv->ndev;
 	struct ucc_fast_private *uccf;
 	struct ucc_hdlc_info *uh_info;
 	u32 ucce;
@@ -703,14 +835,25 @@ static irqreturn_t ucc_hdlc_irq_handler(int irq, void *dev_id)
 
 	ucce = ioread32be(uccf->p_ucce);
 	uccm = ioread32be(uccf->p_uccm);
+	ucce &= uccm;
+	iowrite32be(ucce, uccf->p_ucce);
+#ifdef QE_HDLC_TEST
+	pr_info("irq ucce:%x\n", ucce);
+#endif
 
-	if ((ucce >> 16) & (UCC_HDLC_UCCE_RXF | UCC_HDLC_UCCE_RXB))
-		hdlc_rx_done(priv, RX_CLEAN_MAX);
-
-	if ((ucce >> 16) & UCC_HDLC_UCCE_TXB)
-		hdlc_tx_done(priv);
+	if ((ucce >> 16) & (UCCE_HDLC_RX_EVENTS | UCCE_HDLC_TX_EVENTS)) {
+		if (napi_schedule_prep(&priv->napi)) {
+			uccm &= ~((UCCE_HDLC_RX_EVENTS | UCCE_HDLC_TX_EVENTS) << 16);
+			iowrite32be(uccm, uccf->p_uccm);
+			__napi_schedule(&priv->napi);
+		}
+	}
 
-	iowrite32be(ucce, uccf->p_ucce);
+	/* Errors and other events */
+	if (ucce >> 16 & UCC_HDLC_UCCE_BSY)
+		dev->stats.rx_errors++;
+	if (ucce >> 16 & UCC_HDLC_UCCE_TXE)
+		dev->stats.tx_errors++;
 
 	return IRQ_HANDLED;
 }
@@ -747,7 +890,8 @@ static int uhdlc_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
 static int uhdlc_open(struct net_device *dev)
 {
 	u32 cecr_subblock;
-	struct ucc_hdlc_private *priv = dev_to_hdlc(dev)->priv;
+	hdlc_device *hdlc = dev_to_hdlc(dev);
+	struct ucc_hdlc_private *priv = hdlc->priv;
 
 	if (priv->hdlc_busy != 1) {
 		if (request_irq(priv->uh_info->uf_info.irq,
@@ -769,6 +913,10 @@ static int uhdlc_open(struct net_device *dev)
 			priv->si_regs->siglmr1_h |= (0x1 << priv->tdm_port);
 
 		priv->hdlc_busy = 1;
+		netif_device_attach(priv->ndev);
+		napi_enable(&priv->napi);
+		netif_start_queue(dev);
+		hdlc_open(dev);
 	} else
 		dev_err(priv->dev, "HDLC IS RUNNING!\n");
 
@@ -810,6 +958,12 @@ static void uhdlc_memclean(struct ucc_hdlc_private *priv)
 		priv->ucc_pram_offset = 0;
 	 }
 
+	kfree(priv->rx_skbuff);
+	priv->rx_skbuff = NULL;
+
+	kfree(priv->tx_skbuff);
+	priv->tx_skbuff = NULL;
+
 	if (priv->uf_regs) {
 		iounmap(priv->uf_regs);
 		priv->uf_regs = NULL;
@@ -822,11 +976,19 @@ static void uhdlc_memclean(struct ucc_hdlc_private *priv)
 
 	if (priv->rx_buffer) {
 		dma_free_coherent(priv->dev,
-			2 * NUM_OF_BUF * MAX_RX_BUF_LENGTH,
+			RX_BD_RING_LEN * MAX_RX_BUF_LENGTH,
 			priv->rx_buffer, priv->dma_rx_addr);
 		priv->rx_buffer = NULL;
 		priv->dma_rx_addr = 0;
 	}
+
+	if (priv->tx_buffer) {
+		dma_free_coherent(priv->dev,
+			TX_BD_RING_LEN * MAX_RX_BUF_LENGTH,
+			priv->tx_buffer, priv->dma_tx_addr);
+		priv->tx_buffer = NULL;
+		priv->dma_tx_addr = 0;
+	}
 }
 
 static int uhdlc_close(struct net_device *dev)
@@ -834,6 +996,7 @@ static int uhdlc_close(struct net_device *dev)
 	struct ucc_hdlc_private *priv = dev_to_hdlc(dev)->priv;
 	u32 cecr_subblock;
 
+	napi_disable(&priv->napi);
 	cecr_subblock = ucc_fast_get_qe_cr_subblock(
 				priv->uh_info->uf_info.ucc_num);
 
@@ -848,6 +1011,7 @@ static int uhdlc_close(struct net_device *dev)
 	ucc_fast_disable(priv->uccf, COMM_DIR_RX | COMM_DIR_TX);
 
 	free_irq(priv->uh_info->uf_info.irq, priv);
+	netif_stop_queue(dev);
 	priv->hdlc_busy = 0;
 
 	return 0;
@@ -1025,6 +1189,12 @@ static int uhdlc_suspend(struct device *dev)
 	if (!priv)
 		return -EINVAL;
 
+	if (!netif_running(priv->ndev))
+		return 0;
+
+	netif_device_detach(priv->ndev);
+	napi_disable(&priv->napi);
+
 	uh_info = priv->uh_info;
 	uf_regs = priv->uf_regs;
 
@@ -1064,6 +1234,9 @@ static int uhdlc_resume(struct device *dev)
 	if (!priv)
 		return -EINVAL;
 
+	if (!netif_running(priv->ndev))
+		return 0;
+
 	uh_info = priv->uh_info;
 	uf_info = &uh_info->uf_info;
 	uf_regs = priv->uf_regs;
@@ -1136,6 +1309,8 @@ static int uhdlc_resume(struct device *dev)
 			bd_status =  T_I | T_TC | T_W;
 
 		iowrite32be(bd_status, (u32 *)(priv->tx_bd_base + i));
+		iowrite32be(priv->dma_tx_addr + i * MAX_RX_BUF_LENGTH,
+				&priv->tx_bd_base[i].buf);
 	}
 
 	/* if hdlc is busy enable TX and RX */
@@ -1153,6 +1328,9 @@ static int uhdlc_resume(struct device *dev)
 			priv->si_regs->siglmr1_h |= (0x1 << priv->tdm_port);
 	}
 
+	napi_enable(&priv->napi);
+	netif_device_attach(priv->ndev);
+
 	return 0;
 }
 
@@ -1315,6 +1493,7 @@ static int ucc_hdlc_probe(struct platform_device *pdev)
 	dev->netdev_ops = &uhdlc_ops;
 	hdlc->attach = ucc_hdlc_attach;
 	hdlc->xmit = ucc_hdlc_tx;
+	netif_napi_add(dev, &uhdlc_priv->napi, ucc_hdlc_poll, 32);
 	if (register_hdlc_device(dev)) {
 		ret = -ENOBUFS;
 		pr_err("ucc_hdlc: unable to register hdlc device\n");
diff --git a/drivers/net/wan/fsl_ucc_hdlc.h b/drivers/net/wan/fsl_ucc_hdlc.h
index 93cc20cc..f3bc105 100644
--- a/drivers/net/wan/fsl_ucc_hdlc.h
+++ b/drivers/net/wan/fsl_ucc_hdlc.h
@@ -43,6 +43,10 @@
 #define SIMR_TFSD(n)	(n)
 #define SIMR_RFSD(n)	((n) << 8)
 
+/* UCC HDLC event register */
+#define UCCE_HDLC_RX_EVENTS	(UCC_HDLC_UCCE_RXF | UCC_HDLC_UCCE_RXB | UCC_HDLC_UCCE_BSY)
+#define UCCE_HDLC_TX_EVENTS	(UCC_HDLC_UCCE_TXB | UCC_HDLC_UCCE_TXE)
+
 enum tdm_ts_t {
 	TDM_TX_TS,
 	TDM_RX_TS
@@ -120,6 +124,7 @@ struct ucc_hdlc_private {
 	struct ucc_fast_private *uccf;
 	struct device *dev;
 	struct net_device *ndev;
+	struct napi_struct napi;
 	struct ucc_fast __iomem *uf_regs;	/* UCC Fast registers */
 	struct si1 __iomem *si_regs;
 	struct ucc_hdlc_param __iomem *ucc_pram;
@@ -134,30 +139,35 @@ struct ucc_hdlc_private {
 	u8 num_of_ts;		/* the number of timeslots in this tdm frame */
 	u32 tx_ts_mask;		/* tx time slot mask */
 	u32 rx_ts_mask;		/* rx time slot mask */
-	u8 *rx_buffer;		/* buffer used for Rx by the HDLC */
+
 	u8 *tx_buffer;		/* buffer used for Tx by the HDLC */
-	dma_addr_t dma_rx_addr;	/* dma mapped buffer for HDLC Rx */
+	u8 *rx_buffer;		/* buffer used for Rx by the HDLC */
 	dma_addr_t dma_tx_addr;	/* dma mapped buffer for HDLC Tx */
+	dma_addr_t dma_rx_addr;	/* dma mapped buffer for HDLC Rx */
+
 	struct qe_bd *tx_bd_base;
 	struct qe_bd *rx_bd_base;
+	dma_addr_t dma_tx_bd;
+	dma_addr_t dma_rx_bd;
 	struct qe_bd *curtx_bd;
 	struct qe_bd *currx_bd;
 	struct qe_bd *dirty_tx;
+	u16 currx_bdnum;
+
 	struct sk_buff **tx_skbuff;
 	struct sk_buff **rx_skbuff;
-	u16 skb_currx;
 	u16 skb_curtx;
-	u16 currx_bdnum;
+	u16 skb_currx;
 	unsigned short skb_dirtytx;
+
 	unsigned short tx_ring_size;
 	unsigned short rx_ring_size;
 	u32 ucc_pram_offset;
-	dma_addr_t dma_rx_bd;
-	dma_addr_t dma_tx_bd;
 
 	unsigned short encoding;
 	unsigned short parity;
 	u32 clocking;
+	spinlock_t lock;
 #ifdef CONFIG_PM
 	struct ucc_hdlc_param *ucc_pram_bak;
 	u32 gumr;
@@ -176,16 +186,16 @@ struct ucc_hdlc_private {
 #define ALIGNMENT_OF_UCC_HDLC_PRAM	64
 #define SI_BANK_SIZE	128
 #define MAX_HDLC_NUM	4
-#define BD_LEN_MASK	0xffff
-#define HDLC_HEAD_LEN	3
+#define HDLC_HEAD_LEN	2
 #define HDLC_CRC_SIZE	2
 #define TX_RING_MOD_MASK(size) (size-1)
 #define RX_RING_MOD_MASK(size) (size-1)
 
-#define HDLC_HEAD_MASK		0x000000ff
-#define DEFAULT_HDLC_HEAD	0x68aa4400
-#define DEFAULT_ADDR_MASK	0xffff
-#define DEFAULT_HDLC_ADDR	0xaa68
-#define DEFAULT_BROAD_ADDR	0xffff
+#define HDLC_HEAD_MASK		0x0000
+#define DEFAULT_HDLC_HEAD	0xff44
+#define DEFAULT_ADDR_MASK	0x00ff
+#define DEFAULT_HDLC_ADDR	0x00ff
+
+#define DEFAULT_PPP_HEAD    0xff03
 
 #endif
diff --git a/include/linux/fsl/ucc_fast.h b/include/linux/fsl/ucc_fast.h
index ec24f28..7af6f71 100644
--- a/include/linux/fsl/ucc_fast.h
+++ b/include/linux/fsl/ucc_fast.h
@@ -28,6 +28,7 @@
 #define R_L	0x08000000	/* last */
 #define R_F	0x04000000	/* first */
 #define R_CM	0x02000000	/* CM */
+#define R_CR	0x00040000	/* CR */
 
 /* transmit BD's status */
 #define T_R	0x80000000	/* ready bit */
-- 
1.7.5.4

