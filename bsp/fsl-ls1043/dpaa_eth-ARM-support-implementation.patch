From 220984c1b0b41b798de8875343818d4cd6f59a4c Mon Sep 17 00:00:00 2001
From: Marian-Cristian Rotariu <marian.rotariu@freescale.com>
Date: Fri, 16 Jan 2015 18:07:36 +0200
Subject: [PATCH 147/451] dpaa_eth: ARM support implementation

This patch adds the necessary modification to make the DPAA Ethernet driver
independent of the architecture. Moreover, this patch adds the last Ethernet
driver modifications and optimizations as of SDK 1.7.

Another important addition is the FSL_DPAA_DBG_EMULATOR kconfig option that
guards the low level calls to hardware devices not emulated or simulated. With
this option, the Ethernet driver can be initialized and tested with traffic in
the FSL emulator or simulator.

Signed-off-by: Marian-Cristian Rotariu <marian.rotariu@freescale.com>
Change-Id: I975a6e41d70cdbb617328a983a1c8e2426751f60
Reviewed-on: http://git.am.freescale.net:8181/28639
Tested-by: Review Code-CDREVIEW <CDREVIEW@freescale.com>
Reviewed-by: Mandy Lavi <Mandy.Lavi@freescale.com>
Reviewed-by: Mingkai Hu <Mingkai.Hu@freescale.com>
Reviewed-by: Yang Li <LeoLi@freescale.com>
[Xulin: Original patch taken from
Linux-LS1043A-SDK-V0.4-SOURCE-20150826-yocto.iso]
Signed-off-by: Xulin Sun <xulin.sun@windriver.com>
---
 drivers/net/ethernet/freescale/dpa/Kconfig         |   13 +
 drivers/net/ethernet/freescale/dpa/dpaa_eth.c      |   10 +-
 drivers/net/ethernet/freescale/dpa/dpaa_eth.h      |   47 ++--
 drivers/net/ethernet/freescale/dpa/dpaa_eth_base.c |   46 ++--
 drivers/net/ethernet/freescale/dpa/dpaa_eth_base.h |    3 +
 .../net/ethernet/freescale/dpa/dpaa_eth_common.c   |  148 ++++-------
 .../net/ethernet/freescale/dpa/dpaa_eth_generic.c  |  279 ++++++++++----------
 .../net/ethernet/freescale/dpa/dpaa_eth_generic.h  |    2 +-
 .../net/ethernet/freescale/dpa/dpaa_eth_macless.c  |   19 +-
 .../net/ethernet/freescale/dpa/dpaa_eth_proxy.c    |    8 +-
 drivers/net/ethernet/freescale/dpa/dpaa_eth_sg.c   |   53 ++--
 .../net/ethernet/freescale/dpa/dpaa_eth_shared.c   |   46 ++--
 .../net/ethernet/freescale/dpa/dpaa_eth_sysfs.c    |    5 -
 drivers/net/ethernet/freescale/dpa/dpaa_ethtool.c  |   32 +--
 .../ethernet/freescale/dpa/dpaa_generic_debugfs.c  |    1 +
 drivers/net/ethernet/freescale/dpa/mac-api.c       |   53 ++--
 drivers/net/ethernet/freescale/dpa/mac.c           |  115 ++++-----
 drivers/net/ethernet/freescale/dpa/mac.h           |   12 +-
 drivers/net/ethernet/freescale/dpa/offline_port.c  |  150 +++++-------
 drivers/net/ethernet/freescale/dpa/offline_port.h  |    2 +-
 20 files changed, 490 insertions(+), 554 deletions(-)

diff --git a/drivers/net/ethernet/freescale/dpa/Kconfig b/drivers/net/ethernet/freescale/dpa/Kconfig
index 0f27792..7874b3a 100644
--- a/drivers/net/ethernet/freescale/dpa/Kconfig
+++ b/drivers/net/ethernet/freescale/dpa/Kconfig
@@ -149,4 +149,17 @@ config FSL_DPAA_DBG_LOOP
 		# echo 5 > /sys/kernel/debug/powerpc/fsl_dpa/eth4_loop
 		# cat /sys/kernel/debug/powerpc/fsl_dpa/eth4_loop
 			4->5
+
+config FSL_DPAA_DBG_EMULATOR
+	bool "DPAA Ethernet for FSL Networking Emulation"
+	depends on FSL_DPAA_ETH
+	default y
+	---help---
+	  The DPAA Ethernet driver can be used in one of the proprietary FSL
+	  emulator/simulator for debugging purposes. These tools do not emulate
+	  the PHY devices or do not fully emulate the MAC devices. Therefore,
+	  some of the low level calls should be properly masked. In this tool,
+	  the DPAA Ethernet driver should behave as close as possible to the
+	  DPAA Ethernet driver running on a hardware device.
+
 endif # FSL_DPAA_ETH
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth.c b/drivers/net/ethernet/freescale/dpa/dpaa_eth.c
index 1568e20..2f0dd32 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth.c
@@ -114,7 +114,7 @@ struct net_device *dpa_loop_netdevs[20];
 
 #ifdef CONFIG_PM
 
-static int dpaa_suspend_noirq(struct device *dev)
+static int dpaa_suspend(struct device *dev)
 {
 	struct net_device	*net_dev;
 	struct dpa_priv_s	*priv;
@@ -162,7 +162,7 @@ set_wol_failed:
 	return err;
 }
 
-static int dpaa_resume_noirq(struct device *dev)
+static int dpaa_resume(struct device *dev)
 {
 	struct net_device	*net_dev;
 	struct dpa_priv_s	*priv;
@@ -204,8 +204,8 @@ resume_failed:
 }
 
 static const struct dev_pm_ops dpaa_pm_ops = {
-	.suspend_noirq = dpaa_suspend_noirq,
-	.resume_noirq = dpaa_resume_noirq,
+	.suspend = dpaa_suspend,
+	.resume = dpaa_resume,
 };
 
 #define DPAA_PM_OPS (&dpaa_pm_ops)
@@ -1005,6 +1005,7 @@ dpaa_eth_priv_probe(struct platform_device *_of_dev)
 	 * Must be executed after probing the MAC, but before
 	 * assigning the egress FQs to the CGRs.
 	 */
+#ifndef CONFIG_FSL_DPAA_DBG_EMULATOR
 	err = dpaa_eth_cgr_init(priv);
 	if (err < 0) {
 		dev_err(dev, "Error initializing CGR\n");
@@ -1015,6 +1016,7 @@ dpaa_eth_priv_probe(struct platform_device *_of_dev)
 		dev_err(dev, "Error initializing ingress CGR\n");
 		goto rx_cgr_init_failed;
 	}
+#endif
 
 	/* Add the FQs to the interface, and make them active */
 	list_for_each_entry_safe(dpa_fq, tmp, &priv->dpa_fq_list, list) {
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth.h b/drivers/net/ethernet/freescale/dpa/dpaa_eth.h
index ca5ad85..35f2dda 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth.h
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth.h
@@ -48,10 +48,6 @@ extern int dpa_num_cpus;
 #define dpa_get_rx_extra_headroom() dpa_rx_extra_headroom
 #define dpa_get_max_frm() dpa_max_frm
 
-/* Currently we have the same max_frm on all interfaces, so these macros
- * don't get a net_device argument. This will change in the future.
- */
-#define dpa_get_min_mtu()	64
 #define dpa_get_max_mtu()	\
 	(dpa_get_max_frm() - (VLAN_ETH_HLEN + ETH_FCS_LEN))
 
@@ -215,9 +211,6 @@ enum dpa_fq_type {
 	FQ_TYPE_TX_CONFIRM,     /* Tx default Conf FQ (actually an Rx FQ) */
 	FQ_TYPE_TX_CONF_MQ,     /* Tx conf FQs (one for each Tx FQ) */
 	FQ_TYPE_TX_ERROR,       /* Tx Error FQs (these are actually Rx FQs) */
-#ifdef CONFIG_FMAN_T4240
-	FQ_TYPE_TX_RECYCLE,	/* Tx FQs for recycleable frames only */
-#endif
 };
 
 struct dpa_fq {
@@ -336,9 +329,6 @@ struct dpa_priv_s {
 
 	uint16_t		 channel;	/* "fsl,qman-channel-id" */
 	struct list_head	 dpa_fq_list;
-#ifdef CONFIG_FMAN_T4240
-	struct qman_fq		*recycle_fqs[DPAA_ETH_TX_QUEUES];
-#endif
 
 #ifdef CONFIG_FSL_DPAA_ETH_DEBUGFS
 	struct dentry		*debugfs_file;
@@ -481,7 +471,8 @@ dpa_fd_offset(const struct qm_fd *fd)
 static inline int dpa_check_rx_mtu(struct sk_buff *skb, int mtu)
 {
 	if (unlikely(skb->len > mtu))
-		if ((skb->protocol != ETH_P_8021Q) || (skb->len > mtu + 4))
+		if ((skb->protocol != htons(ETH_P_8021Q))
+				|| (skb->len > mtu + 4))
 			return -1;
 
 	return 0;
@@ -501,11 +492,11 @@ static inline uint16_t dpa_get_headroom(struct dpa_buffer_layout_s *bl)
 	 *
 	 * Also make sure the headroom is a multiple of data_align bytes
 	 */
-	headroom = bl->priv_data_size +
+	headroom = (uint16_t)(bl->priv_data_size +
 		   (bl->parse_results ? DPA_PARSE_RESULTS_SIZE : 0) +
 		   (bl->hash_results || bl->time_stamp ?
 		    DPA_TIME_STAMP_SIZE + DPA_HASH_RESULTS_SIZE : 0) +
-		   bl->manip_extra_space;
+		   bl->manip_extra_space);
 
 	return bl->data_align ? ALIGN(headroom, bl->data_align) : headroom;
 }
@@ -526,6 +517,19 @@ static inline void clear_fd(struct qm_fd *fd)
 	fd->cmd = 0;
 }
 
+static inline struct qman_fq *_dpa_get_tx_conf_queue(
+		const struct dpa_priv_s *priv,
+		struct qman_fq *tx_fq)
+{
+	int i;
+
+	for (i = 0; i < DPAA_ETH_TX_QUEUES; i++)
+		if (priv->egress_fqs[i] == tx_fq)
+			return priv->conf_fqs[i];
+
+	return NULL;
+}
+
 static inline int __hot dpa_xmit(struct dpa_priv_s *priv,
 			struct rtnl_link_stats64 *percpu_stats, int queue,
 			struct qm_fd *fd)
@@ -533,17 +537,11 @@ static inline int __hot dpa_xmit(struct dpa_priv_s *priv,
 	int err, i;
 	struct qman_fq *egress_fq;
 
-#ifdef CONFIG_FMAN_T4240
-	/* Choose egress fq based on whether we want
-	 * to recycle the frame or not
-	 */
-	if (fd->cmd & FM_FD_CMD_FCO)
-		egress_fq = priv->recycle_fqs[queue];
-	else
-		egress_fq = priv->egress_fqs[queue];
-#else
 	egress_fq = priv->egress_fqs[queue];
-#endif
+	if (fd->bpid == 0xff)
+		fd->cmd |= qman_fq_fqid(
+				_dpa_get_tx_conf_queue(priv, egress_fq)
+				);
 
 	/* Trace this Tx fd */
 	trace_dpa_tx_fd(priv->net_dev, egress_fq, fd);
@@ -587,9 +585,6 @@ static inline void _dpa_assign_wq(struct dpa_fq *fq)
 		break;
 	case FQ_TYPE_RX_DEFAULT:
 	case FQ_TYPE_TX:
-#ifdef CONFIG_FMAN_T4240
-	case FQ_TYPE_TX_RECYCLE:
-#endif
 	case FQ_TYPE_RX_PCD:
 		fq->wq = 3;
 		break;
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth_base.c b/drivers/net/ethernet/freescale/dpa/dpaa_eth_base.c
index 7920b4e..3a40cfb 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth_base.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth_base.c
@@ -52,33 +52,24 @@ static int dpa_bp_cmp(const void *dpa_bp0, const void *dpa_bp1)
 struct dpa_bp * __cold __must_check /* __attribute__((nonnull)) */
 dpa_bp_probe(struct platform_device *_of_dev, size_t *count)
 {
-	int			 i, lenp, na, ns;
+	int			 i, lenp, na, ns, err;
 	struct device		*dev;
 	struct device_node	*dev_node;
-	const phandle		*phandle_prop;
-	const uint32_t		*bpid;
-	const uint32_t		*bpool_cfg;
+	const __be32		*bpool_cfg;
 	struct dpa_bp		*dpa_bp;
+	u32			bpid;
 
 	dev = &_of_dev->dev;
 
-	/* The default is one, if there's no property */
-	*count = 1;
-
-	/* Get the buffer pools to be used */
-	phandle_prop = of_get_property(dev->of_node,
-					"fsl,bman-buffer-pools", &lenp);
-
-	if (phandle_prop)
-		*count = lenp / sizeof(phandle);
-	else {
-		dev_err(dev,
-			"missing fsl,bman-buffer-pools device tree entry\n");
+	*count = of_count_phandle_with_args(dev->of_node,
+			"fsl,bman-buffer-pools", NULL);
+	if (*count < 1) {
+		dev_err(dev, "missing fsl,bman-buffer-pools device tree entry\n");
 		return ERR_PTR(-EINVAL);
 	}
 
 	dpa_bp = devm_kzalloc(dev, *count * sizeof(*dpa_bp), GFP_KERNEL);
-	if (unlikely(dpa_bp == NULL)) {
+	if (dpa_bp == NULL) {
 		dev_err(dev, "devm_kzalloc() failed\n");
 		return ERR_PTR(-ENOMEM);
 	}
@@ -92,10 +83,12 @@ dpa_bp_probe(struct platform_device *_of_dev, size_t *count)
 	na = of_n_addr_cells(dev_node);
 	ns = of_n_size_cells(dev_node);
 
-	for (i = 0; i < *count && phandle_prop; i++) {
+	for (i = 0; i < *count; i++) {
 		of_node_put(dev_node);
-		dev_node = of_find_node_by_phandle(phandle_prop[i]);
-		if (unlikely(dev_node == NULL)) {
+
+		dev_node = of_parse_phandle(dev->of_node,
+				"fsl,bman-buffer-pools", i);
+		if (dev_node == NULL) {
 			dev_err(dev, "of_find_node_by_phandle() failed\n");
 			return ERR_PTR(-EFAULT);
 		}
@@ -108,13 +101,13 @@ dpa_bp_probe(struct platform_device *_of_dev, size_t *count)
 			goto _return_of_node_put;
 		}
 
-		bpid = of_get_property(dev_node, "fsl,bpid", &lenp);
-		if ((bpid == NULL) || (lenp != sizeof(*bpid))) {
-			dev_err(dev, "fsl,bpid property not found.\n");
+		err = of_property_read_u32(dev_node, "fsl,bpid", &bpid);
+		if (err) {
+			dev_err(dev, "Cannot find buffer pool ID in the device tree\n");
 			dpa_bp = ERR_PTR(-EINVAL);
 			goto _return_of_node_put;
 		}
-		dpa_bp[i].bpid = (uint8_t)*bpid;
+		dpa_bp[i].bpid = (uint8_t)bpid;
 
 		bpool_cfg = of_get_property(dev_node, "fsl,bpool-ethernet-cfg",
 					&lenp);
@@ -165,8 +158,13 @@ int dpa_bp_shared_port_seed(struct dpa_bp *bp)
 	/* allocate memory region for buffers */
 	devm_request_mem_region(bp->dev, bp->paddr,
 			bp->size * bp->config_count, KBUILD_MODNAME);
+#ifdef CONFIG_FSL_DPAA_DBG_EMULATOR
+	bp->vaddr = NULL;
+	/* TODO: there is a problem with devm_ioremap_prot() call */
+#else
 	bp->vaddr = devm_ioremap_prot(bp->dev, bp->paddr,
 			bp->size * bp->config_count, 0);
+#endif
 	if (bp->vaddr == NULL) {
 		pr_err("Could not map memory for pool %d\n", bp->bpid);
 		return -EIO;
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth_base.h b/drivers/net/ethernet/freescale/dpa/dpaa_eth_base.h
index 5b5ef1e..87a69ca 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth_base.h
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth_base.h
@@ -37,6 +37,9 @@
 #include <linux/of_platform.h> /* struct platform_device */
 #include <linux/net_tstamp.h>	/* struct hwtstamp_config */
 
+extern const struct dpa_fq_cbs_t shared_fq_cbs;
+extern int __hot dpa_shared_tx(struct sk_buff *skb, struct net_device *net_dev);
+
 struct dpa_bp * __cold __must_check /* __attribute__((nonnull)) */
 dpa_bp_probe(struct platform_device *_of_dev, size_t *count);
 int dpa_bp_create(struct net_device *net_dev, struct dpa_bp *dpa_bp,
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth_common.c b/drivers/net/ethernet/freescale/dpa/dpaa_eth_common.c
index 5a899b7..b4fbddc 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth_common.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth_common.c
@@ -53,9 +53,16 @@
 #ifdef CONFIG_AS_FASTPATH
 #define DPA_NETIF_FEATURES	(NETIF_F_HW_QDISC | NETIF_F_HW_ACCEL_MQ)
 #else
+
+#ifdef CONFIG_FSL_DPAA_DBG_EMULATOR
+/* TODO: find out why this feature is missing */
+#define DPA_NETIF_FEATURES	0
+#else
 #define DPA_NETIF_FEATURES	NETIF_F_HW_ACCEL_MQ
 #endif
 
+#endif
+
 /* Size in bytes of the FQ taildrop threshold */
 #define DPA_FQ_TD		0x200000
 
@@ -69,13 +76,7 @@ static const struct fqid_cell tx_confirm_fqids[] = {
 	{0, DPAA_ETH_TX_QUEUES}
 };
 
-#ifdef CONFIG_FMAN_T4240
-static const struct fqid_cell tx_recycle_fqids[] = {
-	{0, DPAA_ETH_TX_QUEUES}
-};
-#endif
-
-static const struct fqid_cell default_fqids[][3] = {
+static struct fqid_cell default_fqids[][3] = {
 	[RX] = { {0, 1}, {0, 1}, {0, DPAA_ETH_RX_QUEUES} },
 	[TX] = { {0, 1}, {0, 1}, {0, DPAA_ETH_TX_QUEUES} }
 };
@@ -151,12 +152,14 @@ int __cold dpa_start(struct net_device *net_dev)
 	priv = netdev_priv(net_dev);
 	mac_dev = priv->mac_dev;
 
+#ifndef CONFIG_FSL_DPAA_DBG_EMULATOR
 	err = mac_dev->init_phy(net_dev, priv->mac_dev);
 	if (err < 0) {
 		if (netif_msg_ifup(priv))
 			netdev_err(net_dev, "init_phy() = %d\n", err);
 		return err;
 	}
+#endif
 
 	for_each_port_device(i, mac_dev->port_dev) {
 		err = fm_port_enable(mac_dev->port_dev[i]);
@@ -164,13 +167,14 @@ int __cold dpa_start(struct net_device *net_dev)
 			goto mac_start_failed;
 	}
 
+#ifndef CONFIG_FSL_DPAA_DBG_EMULATOR
 	err = priv->mac_dev->start(mac_dev);
 	if (err < 0) {
 		if (netif_msg_ifup(priv))
 			netdev_err(net_dev, "mac_dev->start() = %d\n", err);
 		goto mac_start_failed;
 	}
-
+#endif
 	netif_tx_start_all_queues(net_dev);
 
 	return 0;
@@ -266,12 +270,11 @@ dpa_get_stats64(struct net_device *net_dev,
 int dpa_change_mtu(struct net_device *net_dev, int new_mtu)
 {
 	const int max_mtu = dpa_get_max_mtu();
-	const int min_mtu = dpa_get_min_mtu();
 
 	/* Make sure we don't exceed the Ethernet controller's MAXFRM */
-	if (new_mtu < min_mtu || new_mtu > max_mtu) {
+	if (new_mtu < 68 || new_mtu > max_mtu) {
 		netdev_err(net_dev, "Invalid L3 mtu %d (must be between %d and %d).\n",
-				new_mtu, min_mtu, max_mtu);
+				new_mtu, 68, max_mtu);
 		return -EINVAL;
 	}
 	net_dev->mtu = new_mtu;
@@ -541,16 +544,9 @@ dpa_mac_probe(struct platform_device *_of_dev)
 	struct device_node	*timer_node;
 #endif
 
-	phandle_prop = of_get_property(_of_dev->dev.of_node,
-					"fsl,fman-mac", &lenp);
-	if (phandle_prop == NULL)
-		return NULL;
-
-	BUG_ON(lenp != sizeof(phandle));
-
 	dpa_dev = &_of_dev->dev;
 
-	mac_node = of_find_node_by_phandle(*phandle_prop);
+	mac_node = of_parse_phandle(_of_dev->dev.of_node, "fsl,fman-mac", 0);
 	if (unlikely(mac_node == NULL)) {
 		dev_err(dpa_dev, "of_find_node_by_phandle() failed\n");
 		return ERR_PTR(-EFAULT);
@@ -643,10 +639,11 @@ void dpa_set_rx_mode(struct net_device *net_dev)
 					   "mac_dev->set_promisc() = %d\n",
 					   _errno);
 	}
-
+#ifndef CONFIG_FSL_DPAA_DBG_EMULATOR
 	_errno = priv->mac_dev->set_multi(net_dev, priv->mac_dev);
 	if (unlikely(_errno < 0) && netif_msg_drv(priv))
 		netdev_err(net_dev, "mac_dev->set_multi() = %d\n", _errno);
+#endif
 }
 
 void dpa_set_buffers_layout(struct mac_device *mac_dev,
@@ -722,12 +719,15 @@ dpa_bp_alloc(struct dpa_bp *dpa_bp)
 			dpa_bp->bpid, NULL, 0);
 	if (IS_ERR(pdev)) {
 		err = PTR_ERR(pdev);
+		pr_err("platform_device_register_simple() returned %d\n", err);
 		goto pdev_register_failed;
 	}
 
 	err = dma_set_mask(&pdev->dev, DMA_BIT_MASK(40));
-	if (err)
+	if (err) {
+		pr_err("dma_set_mask() returned %d\n", err);
 		goto pdev_mask_failed;
+	}
 
 	dpa_bp->dev = &pdev->dev;
 
@@ -765,6 +765,7 @@ void dpa_bp_drain(struct dpa_bp *bp)
 				 * drain them one by one
 				 */
 				num = 1;
+				ret = 1;
 				continue;
 			} else {
 				/* Pool is fully drained */
@@ -882,8 +883,9 @@ int dpa_fq_probe_mac(struct device *dev, struct list_head *list,
 			    bool alloc_tx_conf_fqs,
 			    enum port_type ptype)
 {
-	const struct fqid_cell *fqids;
-	struct dpa_fq *dpa_fq;
+	struct fqid_cell *fqids = NULL;
+	const void *fqids_off = NULL;
+	struct dpa_fq *dpa_fq = NULL;
 	struct device_node *np = dev->of_node;
 	int num_ranges;
 	int i, lenp;
@@ -892,22 +894,28 @@ int dpa_fq_probe_mac(struct device *dev, struct list_head *list,
 		if (!dpa_fq_alloc(dev, tx_confirm_fqids, list,
 				  FQ_TYPE_TX_CONF_MQ))
 			goto fq_alloc_failed;
-
-#ifdef CONFIG_FMAN_T4240
-		/* per-core Tx queues for recyclable frames (FManv3 only) */
-		if (!dpa_fq_alloc(dev, tx_recycle_fqids, list,
-				  FQ_TYPE_TX_RECYCLE))
-			goto fq_alloc_failed;
-#endif
 	}
 
-	fqids = of_get_property(np, fsl_qman_frame_queues[ptype], &lenp);
-	if (fqids == NULL) {
+	fqids_off = of_get_property(np, fsl_qman_frame_queues[ptype], &lenp);
+	if (fqids_off == NULL) {
 		/* No dts definition, so use the defaults. */
 		fqids = default_fqids[ptype];
 		num_ranges = 3;
 	} else {
 		num_ranges = lenp / sizeof(*fqids);
+
+		fqids = devm_kzalloc(dev, sizeof(*fqids) * num_ranges,
+				GFP_KERNEL);
+		if (fqids == NULL)
+			goto fqids_alloc_failed;
+
+		/* convert to CPU endianess */
+		for (i = 0; i < num_ranges; i++) {
+			fqids[i].start = be32_to_cpup(fqids_off +
+					i * sizeof(*fqids));
+			fqids[i].count = be32_to_cpup(fqids_off +
+					i * sizeof(*fqids) + sizeof(__be32));
+		}
 	}
 
 	for (i = 0; i < num_ranges; i++) {
@@ -958,7 +966,8 @@ int dpa_fq_probe_mac(struct device *dev, struct list_head *list,
 	return 0;
 
 fq_alloc_failed:
-	dev_err(dev, "dpa_fq_alloc() failed\n");
+fqids_alloc_failed:
+	dev_err(dev, "Cannot allocate memory for frame queues\n");
 	return -ENOMEM;
 
 invalid_default_queue:
@@ -1105,9 +1114,6 @@ void dpa_fq_setup(struct dpa_priv_s *priv, const struct dpa_fq_cbs_t *fq_cbs,
 	uint32_t pcd_fqid;
 	const cpumask_t *affine_cpus = qman_affine_cpus();
 	int egress_cnt = 0, conf_cnt = 0;
-#ifdef CONFIG_FMAN_T4240
-	int recycle_cnt = 0;
-#endif
 
 	/* Prepare for PCD FQs init */
 	for_each_cpu(cpu, affine_cpus)
@@ -1161,14 +1167,6 @@ void dpa_fq_setup(struct dpa_priv_s *priv, const struct dpa_fq_cbs_t *fq_cbs,
 			BUG_ON(!priv->mac_dev);
 			dpa_setup_ingress(priv, fq, &fq_cbs->tx_errq);
 			break;
-#ifdef CONFIG_FMAN_T4240
-		case FQ_TYPE_TX_RECYCLE:
-			BUG_ON(!priv->mac_dev);
-			dpa_setup_egress(priv, fq, tx_port,
-					 &fq_cbs->egress_ern);
-			priv->recycle_fqs[recycle_cnt++] = &fq->fq_base;
-			break;
-#endif
 		default:
 			dev_warn(priv->net_dev->dev.parent,
 				 "Unknown FQ type detected!\n");
@@ -1192,18 +1190,6 @@ void dpa_fq_setup(struct dpa_priv_s *priv, const struct dpa_fq_cbs_t *fq_cbs,
 	}
 }
 
-static struct qman_fq *_dpa_get_tx_conf_queue(const struct dpa_priv_s *priv,
-					       struct qman_fq *tx_fq)
-{
-	int i;
-
-	for (i = 0; i < DPAA_ETH_TX_QUEUES; i++)
-		if (priv->egress_fqs[i] == tx_fq)
-			return priv->conf_fqs[i];
-
-	return NULL;
-}
-
 int dpa_fq_init(struct dpa_fq *dpa_fq, bool td_enable)
 {
 	int			 _errno;
@@ -1256,7 +1242,7 @@ int dpa_fq_init(struct dpa_fq *dpa_fq, bool td_enable)
 				dpa_fq->fq_type == FQ_TYPE_TX_CONF_MQ) {
 			initfq.we_mask |= QM_INITFQ_WE_CGID;
 			initfq.fqd.fq_ctrl |= QM_FQCTRL_CGE;
-			initfq.fqd.cgid = priv->cgr_data.cgr.cgrid;
+			initfq.fqd.cgid = (uint8_t)priv->cgr_data.cgr.cgrid;
 			/* Set a fixed overhead accounting, in an attempt to
 			 * reduce the impact of fixed-size skb shells and the
 			 * driver's needed headroom on system memory. This is
@@ -1286,34 +1272,16 @@ int dpa_fq_init(struct dpa_fq *dpa_fq, bool td_enable)
 		if (dpa_fq->fq_type == FQ_TYPE_TX) {
 			confq = _dpa_get_tx_conf_queue(priv, &dpa_fq->fq_base);
 			if (confq) {
-				initfq.we_mask |= QM_INITFQ_WE_CONTEXTA |
-						  QM_INITFQ_WE_CONTEXTB;
-				/* CTXA[OVFQ] = 1 */
-				initfq.fqd.context_a.hi = 0x80000000;
-				initfq.fqd.context_a.lo = 0x0;
-				initfq.fqd.context_b = qman_fq_fqid(confq);
-			}
-		}
-
-#ifdef CONFIG_FMAN_T4240
-		/* Configure the Tx queues for recycled frames, such that the
-		 * buffers are released by FMan and no confirmation is sent
-		 */
-		if (dpa_fq->fq_type == FQ_TYPE_TX_RECYCLE) {
-			initfq.we_mask |= QM_INITFQ_WE_CONTEXTA |
-					  QM_INITFQ_WE_CONTEXTB;
-			/* ContextA: OVFQ=1 (use ContextB FQID for confirmation)
-			 *           OVOM=1 (use contextA2 bits instead of ICAD)
-			 *           A2V=1 (contextA A2 field is valid)
-			 *           B0V=1 (contextB field is valid)
+				initfq.we_mask |= QM_INITFQ_WE_CONTEXTA;
+			/* ContextA: OVOM=1 (use contextA2 bits instead of ICAD)
+			 *	     A2V=1 (contextA A2 field is valid)
+			 *           A0V=1 (contextA A0 field is valid)
 			 * ContextA A2: EBD=1 (deallocate buffers inside FMan)
-			 * ContextB: Confirmation FQID = 0
 			 */
-			initfq.fqd.context_a.hi = 0x96000000;
-			initfq.fqd.context_a.lo = 0x80000000;
-			initfq.fqd.context_b = 0;
+				initfq.fqd.context_a.hi = 0x1a000000;
+				initfq.fqd.context_a.lo = 0x80000000;
+			}
 		}
-#endif
 
 		/* Put all *private* ingress queues in our "ingress CGR". */
 		if (priv->use_ingress_cgr &&
@@ -1322,7 +1290,7 @@ int dpa_fq_init(struct dpa_fq *dpa_fq, bool td_enable)
 				 dpa_fq->fq_type == FQ_TYPE_RX_PCD)) {
 			initfq.we_mask |= QM_INITFQ_WE_CGID;
 			initfq.fqd.fq_ctrl |= QM_FQCTRL_CGE;
-			initfq.fqd.cgid = priv->ingress_cgr.cgrid;
+			initfq.fqd.cgid = (uint8_t)priv->ingress_cgr.cgrid;
 			/* Set a fixed overhead accounting, just like for the
 			 * egress CGR.
 			 */
@@ -1511,7 +1479,7 @@ void dpa_release_sgt(struct qm_sg_entry *sgt)
 			DPA_BUG_ON(sgt[i].extension);
 
 			bmb[j].hi       = sgt[i].addr_hi;
-			bmb[j].lo       = sgt[i].addr_lo;
+			bmb[j].lo       = be32_to_cpu(sgt[i].addr_lo);
 
 			j++; i++;
 		} while (j < ARRAY_SIZE(bmb) &&
@@ -1595,8 +1563,8 @@ int dpa_enable_tx_csum(struct dpa_priv_s *priv,
 	fm_prs_result_t *parse_result;
 	struct iphdr *iph;
 	struct ipv6hdr *ipv6h = NULL;
-	int l4_proto;
-	int ethertype = ntohs(skb->protocol);
+	u8 l4_proto;
+	u16 ethertype = ntohs(skb->protocol);
 	int retval = 0;
 
 	if (skb->ip_summed != CHECKSUM_PARTIAL)
@@ -1625,16 +1593,16 @@ int dpa_enable_tx_csum(struct dpa_priv_s *priv,
 	 */
 	switch (ethertype) {
 	case ETH_P_IP:
-		parse_result->l3r = FM_L3_PARSE_RESULT_IPV4;
+		parse_result->l3r = cpu_to_be16(FM_L3_PARSE_RESULT_IPV4);
 		iph = ip_hdr(skb);
 		DPA_BUG_ON(iph == NULL);
-		l4_proto = ntohs(iph->protocol);
+		l4_proto = iph->protocol;
 		break;
 	case ETH_P_IPV6:
-		parse_result->l3r = FM_L3_PARSE_RESULT_IPV6;
+		parse_result->l3r = cpu_to_be16(FM_L3_PARSE_RESULT_IPV6);
 		ipv6h = ipv6_hdr(skb);
 		DPA_BUG_ON(ipv6h == NULL);
-		l4_proto = ntohs(ipv6h->nexthdr);
+		l4_proto = ipv6h->nexthdr;
 		break;
 	default:
 		/* We shouldn't even be here */
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth_generic.c b/drivers/net/ethernet/freescale/dpa/dpaa_eth_generic.c
index 8f2ad0f..b6283da 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth_generic.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth_generic.c
@@ -101,11 +101,10 @@ static const struct net_device_ops dpa_generic_ops = {
 	.ndo_init = dpa_ndo_init,
 	.ndo_set_features = dpa_set_features,
 	.ndo_fix_features = dpa_fix_features,
-	.ndo_init = dpa_ndo_init,
 	.ndo_change_mtu = dpa_change_mtu,
 };
 
-void dpa_generic_draining_timer(unsigned long arg)
+static void dpa_generic_draining_timer(unsigned long arg)
 {
 	struct dpa_generic_priv_s *priv = (struct dpa_generic_priv_s *)arg;
 
@@ -174,31 +173,27 @@ static struct platform_driver dpa_generic_driver = {
 	.remove		= dpa_generic_remove
 };
 
-int get_port_ref(struct device_node dev_node,
+static int get_port_ref(struct device_node *dev_node,
 		  struct fm_port **port)
 {
-	const phandle *dpa_port_ref_node = NULL;
-	struct platform_device *dpa_port_of_dev = NULL;
+	struct platform_device *port_of_dev = NULL;
 	struct device *op_dev = NULL;
-	struct device_node *dpa_port_node = NULL;
-	int lenp = 0;
+	struct device_node *port_node = NULL;
 
-	dpa_port_ref_node = of_get_property(&dev_node,
-			"fsl,fman-oh-port", &lenp);
-	if (dpa_port_ref_node == NULL)
+	port_node = of_parse_phandle(dev_node, "fsl,fman-oh-port", 0);
+	if (port_node == NULL)
 		return -EINVAL;
 
-	dpa_port_node = of_find_node_by_phandle(*dpa_port_ref_node);
-	if (dpa_port_node == NULL)
-		return -EINVAL;
+	port_of_dev = of_find_device_by_node(port_node);
+	of_node_put(port_node);
 
-	dpa_port_of_dev = of_find_device_by_node(dpa_port_node);
-	of_node_put(dpa_port_node);
-	if (dpa_port_of_dev == NULL)
+	if (port_of_dev == NULL)
 		return -EINVAL;
 
-	op_dev = &dpa_port_of_dev->dev;
+	/* get the reference to oh port from FMD */
+	op_dev = &port_of_dev->dev;
 	*port = fm_port_bind(op_dev);
+
 	if (*port == NULL)
 		return -EINVAL;
 
@@ -234,31 +229,25 @@ static void dpaa_generic_napi_disable(struct dpa_generic_priv_s *priv)
 static struct device_node *get_rx_op_port_node(struct platform_device *_of_dev)
 {
 	struct device *dev = &_of_dev->dev;
-	struct device_node *dev_node = NULL;
-	const phandle *ports_handle = NULL;
+	struct device_node *port_node = NULL;
+	struct device_node *onic_node = NULL;
 	int num_ports = 0;
-	int lenp = 0;
 
-	ports_handle = of_get_property(dev->of_node,
-			"fsl,oh-ports", &lenp);
-	if (ports_handle == NULL) {
-		dev_err(dev, "Cannot find node fsl,oh-ports property in device tree\n");
-		return ERR_PTR(-EINVAL);
-	}
+	onic_node = dev->of_node;
 
-	num_ports = lenp / sizeof(*ports_handle);
-	if (num_ports < 1) {
-		dev_err(dev, "There should be at least one O/H port in device tree\n");
+	num_ports = of_count_phandle_with_args(onic_node, "fsl,oh-ports", NULL);
+	if (num_ports != 2) {
+		dev_err(dev, "There should be two O/H port handles in the device tree\n");
 		return ERR_PTR(-EINVAL);
 	}
 
-	dev_node = of_find_node_by_phandle(*ports_handle);
-	if (unlikely(dev_node == NULL)) {
-		dev_err(dev, "Cannot find node oh port node in device tree\n");
+	port_node = of_parse_phandle(onic_node, "fsl,oh-ports", 0);
+	if (port_node == NULL) {
+		dev_err(dev, "Cannot find O/H port node in the device tree\n");
 		return ERR_PTR(-EFAULT);
 	}
 
-	return dev_node;
+	return port_node;
 }
 
 static int __cold dpa_generic_start(struct net_device *netdev)
@@ -433,7 +422,8 @@ dpa_generic_rx_dqrr(struct qman_portal *portal,
 	/* The skb is currently pointed at head + headroom. The packet
 	 * starts at skb->head + pad + fd offset.
 	 */
-	data_start = pad + dpa_fd_offset(fd) - skb_headroom(skb);
+	data_start = (unsigned int)(pad + dpa_fd_offset(fd) -
+				    skb_headroom(skb));
 	skb_put(skb, dpa_fd_length(fd) + data_start);
 	skb_pull(skb, data_start);
 	skb->protocol = eth_type_trans(skb, netdev);
@@ -498,10 +488,10 @@ static void dpa_generic_drain_bp(struct dpa_bp *bp, u8 nbuf)
  * Note that this function may modify the fd->cmd field and the skb data buffer
  * (the Parse Results area).
  */
-int dpa_generic_tx_csum(struct dpa_generic_priv_s *priv,
-			struct sk_buff *skb,
-			struct qm_fd *fd,
-			char *parse_results)
+static int dpa_generic_tx_csum(struct dpa_generic_priv_s *priv,
+			       struct sk_buff *skb,
+			       struct qm_fd *fd,
+			       char *parse_results)
 {
 	fm_prs_result_t *parse_result;
 	struct iphdr *iph;
@@ -539,13 +529,13 @@ int dpa_generic_tx_csum(struct dpa_generic_priv_s *priv,
 		parse_result->l3r = FM_L3_PARSE_RESULT_IPV4;
 		iph = ip_hdr(skb);
 		BUG_ON(iph == NULL);
-		l4_proto = ntohs(iph->protocol);
+		l4_proto = iph->protocol;
 		break;
 	case ETH_P_IPV6:
 		parse_result->l3r = FM_L3_PARSE_RESULT_IPV6;
 		ipv6h = ipv6_hdr(skb);
 		BUG_ON(ipv6h == NULL);
-		l4_proto = ntohs(ipv6h->nexthdr);
+		l4_proto = ipv6h->nexthdr;
 		break;
 	default:
 		/* We shouldn't even be here */
@@ -576,8 +566,8 @@ int dpa_generic_tx_csum(struct dpa_generic_priv_s *priv,
 	}
 
 	/* At index 0 is IPOffset_1 as defined in the Parse Results */
-	parse_result->ip_off[0] = skb_network_offset(skb);
-	parse_result->l4_off = skb_transport_offset(skb);
+	parse_result->ip_off[0] = (uint8_t)skb_network_offset(skb);
+	parse_result->l4_off = (uint8_t)skb_transport_offset(skb);
 
 	/* Enable L3 (and L4, if TCP or UDP) HW checksum. */
 	fd->cmd |= FM_FD_CMD_RPD | FM_FD_CMD_DTC;
@@ -652,7 +642,7 @@ static int __hot dpa_generic_tx(struct sk_buff *skb, struct net_device *netdev)
 	fd.format = qm_fd_contig;
 	fd.length20 = skb->len;
 	fd.offset = priv->tx_headroom;
-	fd.addr_hi = upper_32_bits(addr);
+	fd.addr_hi = (uint8_t)upper_32_bits(addr);
 	fd.addr_lo = lower_32_bits(addr);
 	/* fd.cmd |= FM_FD_CMD_FCO; */
 	fd.bpid = bp->bpid;
@@ -717,7 +707,7 @@ static int dpa_generic_napi_add(struct net_device *net_dev)
 	return 0;
 }
 
-void dpa_generic_napi_del(struct net_device *net_dev)
+static void dpa_generic_napi_del(struct net_device *net_dev)
 {
 	struct dpa_generic_priv_s *priv = netdev_priv(net_dev);
 	struct dpa_percpu_priv_s *percpu_priv;
@@ -784,82 +774,112 @@ static int dpa_generic_netdev_init(struct device_node *dpa_node,
 	return 0;
 }
 
-struct dpa_fq_cbs_t generic_fq_cbs = {
+static struct dpa_fq_cbs_t generic_fq_cbs = {
 	.rx_defq = { .cb = { .dqrr = dpa_generic_rx_dqrr } },
 	.rx_errq = { .cb = { .dqrr = dpa_generic_rx_err_dqrr } },
 	.egress_ern = { .cb = { .ern = dpa_generic_ern } }
 };
 
-struct list_head *dpa_generic_fq_probe(struct platform_device *_of_dev,
-					struct fm_port *tx_port)
+static struct fqid_cell *__fq_alloc(struct device *dev,
+				   int num_ranges,
+				   const void *fqids_off)
+{
+	struct fqid_cell *fqids;
+	int i;
+
+	fqids = kzalloc(sizeof(*fqids) * num_ranges, GFP_KERNEL);
+	if (fqids == NULL)
+		return NULL;
+
+	/* convert to CPU endianess */
+	for (i = 0; i < num_ranges; i++) {
+		fqids[i].start = be32_to_cpup(fqids_off +
+				i * sizeof(*fqids));
+		fqids[i].count = be32_to_cpup(fqids_off +
+				i * sizeof(*fqids) + sizeof(__be32));
+	}
+
+	return fqids;
+}
+
+static struct list_head *dpa_generic_fq_probe(struct platform_device *_of_dev,
+					      struct fm_port *tx_port)
 {
 	struct device *dev = &_of_dev->dev;
-	struct device_node *dev_node = NULL;
-	const struct fqid_cell *fqids;
+	struct device_node *oh_node = NULL;
+	struct device_node *onic_node = NULL;
+	struct fqid_cell *fqids;
+	const void *fqids_off;
 	struct dpa_fq *fq, *tmp;
 	struct list_head *list;
 	int num_ranges;
 	int i, lenp;
 
-	/* RX queues (RX error, RX default) are specified in Rx O/H port node */
-	dev_node = get_rx_op_port_node(_of_dev);
+	onic_node = dev->of_node;
 
-	fqids = of_get_property(dev_node, "fsl,qman-frame-queues-oh", &lenp);
-	if (fqids == NULL) {
+	list = devm_kzalloc(dev, sizeof(*list), GFP_KERNEL);
+	if (!list) {
+		dev_err(dev, "Cannot allocate space for frame queues list\n");
+		return ERR_PTR(-ENOMEM);
+	}
+
+	INIT_LIST_HEAD(list);
+
+	/* RX queues (RX error, RX default) are specified in Rx O/H port node */
+	oh_node = get_rx_op_port_node(_of_dev);
+	fqids_off = of_get_property(oh_node, "fsl,qman-frame-queues-oh", &lenp);
+	if (fqids_off == NULL) {
 		dev_err(dev, "Need Rx FQ definition in dts for generic devices\n");
 		return ERR_PTR(-EINVAL);
 	}
+	of_node_put(oh_node);
 
-	of_node_put(dev_node);
 	num_ranges = lenp / sizeof(*fqids);
 	if (num_ranges != 2) {
 		dev_err(dev, "Need 2 Rx FQ definitions in dts for generic devices\n");
 		return ERR_PTR(-EINVAL);
 	}
 
-	list = devm_kzalloc(dev, sizeof(*list), GFP_KERNEL);
-	if (!list) {
-		dev_err(dev, "devm_kzalloc() failed\n");
-		return ERR_PTR(-ENOMEM);
-	}
-
-	INIT_LIST_HEAD(list);
-
+	fqids = __fq_alloc(dev, num_ranges, fqids_off);
 	if (!dpa_fq_alloc(dev, &fqids[0], list, FQ_TYPE_RX_ERROR) ||
 			!dpa_fq_alloc(dev, &fqids[1], list,
 				FQ_TYPE_RX_DEFAULT)) {
-		dev_err(dev, "_dpa_fq_alloc() failed\n");
+		dev_err(dev, "Cannot allocate space for default frame queues\n");
 		return ERR_PTR(-ENOMEM);
 	}
+	kfree(fqids);
 
 	/* TX queues */
-	fqids = of_get_property(dev->of_node,
-			"fsl,qman-frame-queues-tx", &lenp);
-	if (fqids == NULL) {
+	fqids_off = of_get_property(onic_node, "fsl,qman-frame-queues-tx",
+			&lenp);
+	if (fqids_off == NULL) {
 		dev_err(dev, "Need Tx FQ definition in dts for generic devices\n");
 		return ERR_PTR(-EINVAL);
 	}
 
 	num_ranges = lenp / sizeof(*fqids);
+	fqids = __fq_alloc(dev, num_ranges, fqids_off);
 	for (i = 0; i < num_ranges; i++) {
 		if (!dpa_fq_alloc(dev, &fqids[i], list, FQ_TYPE_TX)) {
 			dev_err(dev, "_dpa_fq_alloc() failed\n");
 			return ERR_PTR(-ENOMEM);
 		}
 	}
+	kfree(fqids);
 
 	/* optional RX PCD queues */
 	lenp = 0;
-	fqids = of_get_property(dev->of_node,
+	fqids_off = of_get_property(onic_node,
 			"fsl,qman-frame-queues-rx", &lenp);
-
 	num_ranges = lenp / sizeof(*fqids);
+	fqids = __fq_alloc(dev, num_ranges, fqids_off);
 	for (i = 0; i < num_ranges; i++) {
 		if (!dpa_fq_alloc(dev, &fqids[i], list, FQ_TYPE_RX_PCD)) {
 			dev_err(dev, "_dpa_fq_alloc() failed\n");
 			return ERR_PTR(-ENOMEM);
 		}
 	}
+	kfree(fqids);
 
 	list_for_each_entry_safe(fq, tmp, list, list) {
 		if (fq->fq_type == FQ_TYPE_TX)
@@ -897,36 +917,33 @@ static int dpa_generic_rx_bp_probe(struct platform_device *_of_dev,
 				   struct dpa_buffer_layout_s **rx_buf_layout)
 {
 	struct device *dev = &_of_dev->dev;
-	const phandle *phandle_prop = NULL;
 	struct fm_port_params params;
 	struct dpa_bp *bp = NULL;
 	int bp_count = 0;
-	const uint32_t *bpid = NULL;
-	const uint32_t *bpool_cfg = NULL;
+	int bpid;
+	const __be32 *bpool_cfg = NULL;
 	struct device_node *dev_node = NULL;
+	struct device_node *oh_node = NULL;
 	struct dpa_buffer_layout_s *buf_layout = NULL;
 	int lenp = 0;
 	int na = 0, ns = 0;
 	int err = 0, i = 0;
 
-	dev_node = get_rx_op_port_node(_of_dev);
+	oh_node = get_rx_op_port_node(_of_dev);
 
-	phandle_prop = of_get_property(dev_node,
-			"fsl,bman-buffer-pools", &lenp);
-	if (!phandle_prop) {
-		dev_err(dev, "missing fsl,bman-buffer-pools property from device tree\n");
+	bp_count = of_count_phandle_with_args(oh_node,
+			"fsl,bman-buffer-pools", NULL);
+	if (bp_count <= 0) {
+		dev_err(dev, "Missing buffer pool handles from onic node from device tree\n");
 		return -EINVAL;
 	}
 
-	bp_count = lenp / sizeof(*phandle_prop);
-
 	bp = devm_kzalloc(dev, bp_count * sizeof(*bp), GFP_KERNEL);
 	if (unlikely(bp == NULL)) {
 		dev_err(dev, "devm_kzalloc() failed\n");
 		return -ENOMEM;
 	}
 
-	of_node_put(dev_node);
 	dev_node = of_find_node_by_path("/");
 	if (unlikely(dev_node == NULL)) {
 		dev_err(dev, "of_find_node_by_path(/) failed\n");
@@ -939,27 +956,20 @@ static int dpa_generic_rx_bp_probe(struct platform_device *_of_dev,
 	of_node_put(dev_node);
 
 	for (i = 0; i < bp_count; i++) {
-		dev_node = of_find_node_by_phandle(phandle_prop[i]);
-		if (unlikely(dev_node == NULL)) {
-			dev_err(dev, "of_find_node_by_phandle() failed\n");
+		dev_node = of_parse_phandle(oh_node,
+				"fsl,bman-buffer-pools", i);
+		if (dev_node == NULL) {
+			dev_err(dev, "Cannot find buffer pool node in the device tree\n");
 			return -EFAULT;
 		}
 
-		if (unlikely(!of_device_is_compatible(dev_node, "fsl,bpool"))) {
-			dev_err(dev, "!of_device_is_compatible(%s, fsl,bpool)\n",
-					dev_node->full_name);
-			err = -EINVAL;
-			goto _return_of_node_put;
-		}
-
-		bpid = of_get_property(dev_node, "fsl,bpid", &lenp);
-		if ((bpid == NULL) || (lenp != sizeof(*bpid))) {
-			dev_err(dev, "fsl,bpid property not found.\n");
-			err = -EINVAL;
+		err = of_property_read_u32(dev_node, "fsl,bpid", &bpid);
+		if (err) {
+			dev_err(dev, "Cannot find buffer pool ID in the buffer pool node in the device tree\n");
 			goto _return_of_node_put;
 		}
 
-		bp[i].bpid = *bpid;
+		bp[i].bpid = (uint8_t)bpid;
 
 		bpool_cfg = of_get_property(dev_node, "fsl,bpool-ethernet-cfg",
 				&lenp);
@@ -978,6 +988,8 @@ static int dpa_generic_rx_bp_probe(struct platform_device *_of_dev,
 		bp[i].percpu_count = alloc_percpu(*(bp[i].percpu_count));
 	}
 
+	of_node_put(oh_node);
+
 	buf_layout = devm_kzalloc(dev, sizeof(*buf_layout), GFP_KERNEL);
 	if (!buf_layout) {
 		dev_err(dev, "devm_kzalloc() failed\n");
@@ -1009,10 +1021,10 @@ _return_of_node_put:
 	return err;
 }
 
-int dpa_generic_tx_bp_probe(struct platform_device *_of_dev,
-			    struct fm_port *tx_port,
-			    struct dpa_bp **draining_tx_bp,
-			    struct dpa_buffer_layout_s **tx_buf_layout)
+static int dpa_generic_tx_bp_probe(struct platform_device *_of_dev,
+				   struct fm_port *tx_port,
+				   struct dpa_bp **draining_tx_bp,
+				   struct dpa_buffer_layout_s **tx_buf_layout)
 {
 	struct device *dev = &_of_dev->dev;
 	struct fm_port_params params;
@@ -1050,8 +1062,8 @@ int dpa_generic_tx_bp_probe(struct platform_device *_of_dev,
 	return 0;
 }
 
-int dpa_generic_buff_dealloc_probe(struct platform_device *_of_dev,
-				   int *disable_buff_dealloc)
+static int dpa_generic_buff_dealloc_probe(struct platform_device *_of_dev,
+					  int *disable_buff_dealloc)
 {
 	struct device *dev = &_of_dev->dev;
 	const phandle *disable_handle = NULL;
@@ -1066,52 +1078,45 @@ int dpa_generic_buff_dealloc_probe(struct platform_device *_of_dev,
 	return err;
 }
 
-int dpa_generic_port_probe(struct platform_device *_of_dev,
-			   struct fm_port **rx_port,
-			   struct fm_port **tx_port)
+static int dpa_generic_port_probe(struct platform_device *_of_dev,
+				  struct fm_port **rx_port,
+				  struct fm_port **tx_port)
 {
 	struct device *dev = &_of_dev->dev;
 	struct device_node *dev_node = NULL;
-	const phandle *ports_handle = NULL;
+	struct device_node *onic_node = NULL;
 	int num_ports = 0;
-	int lenp = 0;
 	int err = 0;
 
-	ports_handle = of_get_property(dev->of_node,
-			"fsl,oh-ports", &lenp);
-	if (ports_handle == NULL) {
-		dev_err(dev, "Cannot find fsl,oh-ports property in device tree\n");
-		return -EINVAL;
-	}
+	onic_node = dev->of_node;
 
-	num_ports = lenp / sizeof(*ports_handle);
+	num_ports = of_count_phandle_with_args(onic_node, "fsl,oh-ports", NULL);
 	if (num_ports != 2) {
-		/* for the moment, only two ports are supported */
 		dev_err(dev, "There should be two OH ports in device tree (one for RX, one for TX\n");
 		return -EINVAL;
 	}
 
-	dev_node = of_find_node_by_phandle(ports_handle[RX]);
-	if (unlikely(dev_node == NULL)) {
-		dev_err(dev, "Cannot find OH port node in device tree\n");
-		return -EFAULT;
+	dev_node = of_parse_phandle(onic_node, "fsl,oh-ports", RX);
+	if (dev_node == NULL) {
+		dev_err(dev, "Cannot find Rx OH port node in device tree\n");
+		return err;
 	}
 
-	err = get_port_ref(*dev_node, rx_port);
-	if (err < 0) {
-		dev_err(dev, "Cannot read OH port node in device tree\n");
+	err = get_port_ref(dev_node, rx_port);
+	if (err) {
+		dev_err(dev, "Cannot read Rx OH port node in device tree\n");
 		return err;
 	}
 
-	dev_node = of_find_node_by_phandle(ports_handle[TX]);
-	if (unlikely(dev_node == NULL)) {
-		dev_err(dev, "Cannot find OH port node in device tree\n");
+	dev_node = of_parse_phandle(onic_node, "fsl,oh-ports", TX);
+	if (dev_node == NULL) {
+		dev_err(dev, "Cannot find Tx OH port node in device tree\n");
 		return -EFAULT;
 	}
 
-	err = get_port_ref(*dev_node, tx_port);
-	if (err < 0) {
-		dev_err(dev, "Cannot read OH port node in device tree\n");
+	err = get_port_ref(dev_node, tx_port);
+	if (err) {
+		dev_err(dev, "Cannot read Tx OH port node in device tree\n");
 		return err;
 	}
 
@@ -1275,16 +1280,16 @@ static int dpa_generic_fq_create(struct net_device *netdev,
 	struct dpa_fq *fqs = NULL, *tmp = NULL;
 	struct task_struct *kth;
 	int err = 0;
+	int channel;
 
 	INIT_LIST_HEAD(&priv->dpa_fq_list);
 
 	list_replace_init(dpa_fq_list, &priv->dpa_fq_list);
 
-	priv->channel = dpa_get_channel();
-	if (priv->channel < 0) {
-		err = priv->channel;
-		return err;
-	}
+	channel = dpa_get_channel();
+	if (channel < 0)
+		return channel;
+	priv->channel = (uint16_t)channel;
 
 	/* Start a thread that will walk the cpus with affine portals
 	 * and add this pool channel to each's dequeue mask.
@@ -1307,12 +1312,12 @@ static int dpa_generic_fq_create(struct net_device *netdev,
 	return 0;
 }
 
-int dpa_generic_bp_create(struct net_device *net_dev,
-			  int rx_bp_count,
-			  struct dpa_bp *rx_bp,
-			  struct dpa_buffer_layout_s *rx_buf_layout,
-			  struct dpa_bp *draining_tx_bp,
-			  struct dpa_buffer_layout_s *tx_buf_layout)
+static int dpa_generic_bp_create(struct net_device *net_dev,
+				 int rx_bp_count,
+				 struct dpa_bp *rx_bp,
+				 struct dpa_buffer_layout_s *rx_buf_layout,
+				 struct dpa_bp *draining_tx_bp,
+				 struct dpa_buffer_layout_s *tx_buf_layout)
 {
 	struct dpa_generic_priv_s *priv = netdev_priv(net_dev);
 	int err = 0;
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth_generic.h b/drivers/net/ethernet/freescale/dpa/dpaa_eth_generic.h
index 606812f..0998d80 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth_generic.h
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth_generic.h
@@ -38,7 +38,7 @@
 struct dpa_generic_priv_s {
 	struct net_device *net_dev;
 	/* use the same percpu_priv as other DPAA Ethernet drivers */
-	struct dpa_percpu_priv_s *percpu_priv;
+	struct dpa_percpu_priv_s __percpu *percpu_priv;
 
 	/* up to 4 bps supported for RX */
 	int rx_bp_count;
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth_macless.c b/drivers/net/ethernet/freescale/dpa/dpaa_eth_macless.c
index f27ce5c..0a40ca4 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth_macless.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth_macless.c
@@ -74,10 +74,6 @@ static uint16_t tx_timeout = 1000;
 module_param(tx_timeout, ushort, S_IRUGO);
 MODULE_PARM_DESC(tx_timeout, "The Tx timeout in ms");
 
-/* reused from the shared driver */
-extern const struct dpa_fq_cbs_t shared_fq_cbs;
-int __hot dpa_shared_tx(struct sk_buff *skb, struct net_device *net_dev);
-
 /* forward declarations */
 static int __cold dpa_macless_start(struct net_device *net_dev);
 static int __cold dpa_macless_stop(struct net_device *net_dev);
@@ -88,8 +84,6 @@ static void __cold dpa_macless_set_rx_mode(struct net_device *net_dev);
 static int dpaa_eth_macless_probe(struct platform_device *_of_dev);
 static netdev_features_t
 dpa_macless_fix_features(struct net_device *dev, netdev_features_t features);
-static int dpa_macless_netdev_init(struct device_node *dpa_node,
-				struct net_device *net_dev);
 
 static const struct net_device_ops dpa_macless_ops = {
 	.ndo_open = dpa_macless_start,
@@ -273,7 +267,8 @@ static int dpa_fq_probe_macless(struct device *dev, struct list_head *list,
 	return 0;
 }
 
-struct proxy_device *dpa_macless_proxy_probe(struct platform_device *_of_dev)
+	static struct proxy_device *
+dpa_macless_proxy_probe(struct platform_device *_of_dev)
 {
 	struct device		*dev;
 	const phandle		*proxy_prop;
@@ -310,7 +305,7 @@ struct proxy_device *dpa_macless_proxy_probe(struct platform_device *_of_dev)
 
 static int dpaa_eth_macless_probe(struct platform_device *_of_dev)
 {
-	int err = 0, i;
+	int err = 0, i, channel;
 	struct device *dev;
 	struct device_node *dpa_node;
 	struct dpa_bp *dpa_bp;
@@ -393,13 +388,15 @@ static int dpaa_eth_macless_probe(struct platform_device *_of_dev)
 	if (err < 0)
 		goto bp_create_failed;
 
-	priv->channel = dpa_get_channel();
+	channel = dpa_get_channel();
 
-	if (priv->channel < 0) {
-		err = priv->channel;
+	if (channel < 0) {
+		err = channel;
 		goto get_channel_failed;
 	}
 
+	priv->channel = (uint16_t)channel;
+
 	/* Start a thread that will walk the cpus with affine portals
 	 * and add this pool channel to each's dequeue mask.
 	 */
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth_proxy.c b/drivers/net/ethernet/freescale/dpa/dpaa_eth_proxy.c
index a06465a..57aacb9 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth_proxy.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth_proxy.c
@@ -60,7 +60,7 @@ MODULE_PARM_DESC(debug, "Module/Driver verbosity level");
 static int __cold dpa_eth_proxy_remove(struct platform_device *of_dev);
 #ifdef CONFIG_PM
 
-static int proxy_suspend_noirq(struct device *dev)
+static int proxy_suspend(struct device *dev)
 {
 	struct proxy_device *proxy_dev = dev_get_drvdata(dev);
 	struct mac_device *mac_dev = proxy_dev->mac_dev;
@@ -78,7 +78,7 @@ port_suspend_failed:
 	return err;
 }
 
-static int proxy_resume_noirq(struct device *dev)
+static int proxy_resume(struct device *dev)
 {
 	struct proxy_device *proxy_dev = dev_get_drvdata(dev);
 	struct mac_device	*mac_dev = proxy_dev->mac_dev;
@@ -97,8 +97,8 @@ port_resume_failed:
 }
 
 static const struct dev_pm_ops proxy_pm_ops = {
-	.suspend_noirq = proxy_suspend_noirq,
-	.resume_noirq = proxy_resume_noirq,
+	.suspend = proxy_suspend,
+	.resume = proxy_resume,
 };
 
 #define PROXY_PM_OPS (&proxy_pm_ops)
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth_sg.c b/drivers/net/ethernet/freescale/dpa/dpaa_eth_sg.c
index c0e93a7..1c56fb6 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth_sg.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth_sg.c
@@ -229,12 +229,12 @@ struct sk_buff *_dpa_cleanup_tx_fd(const struct dpa_priv_s *priv,
 	int i;
 	struct dpa_bp *dpa_bp = priv->dpa_bp;
 	dma_addr_t addr = qm_fd_addr(fd);
+	dma_addr_t sg_addr;
 	struct sk_buff **skbh;
 	struct sk_buff *skb = NULL;
 	const enum dma_data_direction dma_dir = DMA_TO_DEVICE;
 	int nr_frags;
 
-	DPA_BUG_ON(fd->cmd & FM_FD_CMD_FCO);
 	dma_unmap_single(dpa_bp->dev, addr, dpa_bp->size, dma_dir);
 
 	/* retrieve skb back pointer */
@@ -262,15 +262,18 @@ struct sk_buff *_dpa_cleanup_tx_fd(const struct dpa_priv_s *priv,
 #endif /* CONFIG_FSL_DPAA_TS */
 
 		/* sgt[0] is from lowmem, was dma_map_single()-ed */
-		dma_unmap_single(dpa_bp->dev, sgt[0].addr,
-				sgt[0].length, dma_dir);
+		/* TODO: sg_addr should be in CPU endianess */
+		sg_addr = qm_sg_addr(&sgt[0]);
+		dma_unmap_single(dpa_bp->dev, sg_addr,
+				be32_to_cpu(sgt[0].length), dma_dir);
 
 		/* remaining pages were mapped with dma_map_page() */
 		for (i = 1; i < nr_frags; i++) {
 			DPA_BUG_ON(sgt[i].extension);
-
-			dma_unmap_page(dpa_bp->dev, sgt[i].addr,
-					sgt[i].length, dma_dir);
+			/* TODO: sg_addr should be in CPU endianess */
+			sg_addr = qm_sg_addr(&sgt[i]);
+			dma_unmap_page(dpa_bp->dev, sg_addr,
+					be32_to_cpu(sgt[i].length), dma_dir);
 		}
 
 		/* Free the page frag that we allocated on Tx */
@@ -436,6 +439,7 @@ static struct sk_buff *__hot sg_fd_to_skb(const struct dpa_priv_s *priv,
 		/* We use a single global Rx pool */
 		DPA_BUG_ON(dpa_bp != dpa_bpid2pool(sgt[i].bpid));
 
+		/* TODO: sg_addr should be in CPU endianess */
 		sg_addr = qm_sg_addr(&sgt[i]);
 		sg_vaddr = phys_to_virt(sg_addr);
 		DPA_BUG_ON(!IS_ALIGNED((unsigned long)sg_vaddr,
@@ -470,7 +474,7 @@ static struct sk_buff *__hot sg_fd_to_skb(const struct dpa_priv_s *priv,
 			 */
 			DPA_BUG_ON(fd_off != priv->rx_headroom);
 			skb_reserve(skb, fd_off);
-			skb_put(skb, sgt[i].length);
+			skb_put(skb, be32_to_cpu(sgt[i].length));
 		} else {
 			/* Not the first S/G entry; all data from buffer will
 			 * be added in an skb fragment; fragment index is offset
@@ -496,8 +500,8 @@ static struct sk_buff *__hot sg_fd_to_skb(const struct dpa_priv_s *priv,
 			/* page_offset only refers to the beginning of sgt[i];
 			 * but the buffer itself may have an internal offset.
 			 */
-			frag_offset = sgt[i].offset + page_offset;
-			frag_len = sgt[i].length;
+			frag_offset = be16_to_cpu(sgt[i].offset) + page_offset;
+			frag_len = be32_to_cpu(sgt[i].length);
 			/* skb_add_rx_frag() does no checking on the page; if
 			 * we pass it a tail page, we'll end up with
 			 * bad page accounting and eventually with segafults.
@@ -664,7 +668,6 @@ static int __hot skb_to_contig_fd(struct dpa_priv_s *priv,
 		/* Buffer is recyclable; use the new start address
 		 * and set fd parameters and DMA mapping direction
 		 */
-		fd->cmd |= FM_FD_CMD_FCO;
 		fd->bpid = dpa_bp->bpid;
 		DPA_BUG_ON(skb->data - buffer_start > DPA_MAX_FD_OFFSET);
 		fd->offset = (uint16_t)(skb->data - buffer_start);
@@ -679,6 +682,7 @@ static int __hot skb_to_contig_fd(struct dpa_priv_s *priv,
 		 * We are guaranteed to have at least tx_headroom bytes
 		 * available, so just use that for offset.
 		 */
+		fd->bpid = 0xff;
 		buffer_start = skb->data - priv->tx_headroom;
 		fd->offset = priv->tx_headroom;
 		dma_dir = DMA_TO_DEVICE;
@@ -706,6 +710,7 @@ static int __hot skb_to_contig_fd(struct dpa_priv_s *priv,
 	/* Fill in the rest of the FD fields */
 	fd->format = qm_fd_contig;
 	fd->length20 = skb->len;
+	fd->cmd |= FM_FD_CMD_FCO;
 
 	/* Map the entire buffer size that may be seen by FMan, but no more */
 	addr = dma_map_single(dpa_bp->dev, skbh,
@@ -762,9 +767,9 @@ static int __hot skb_to_sg_fd(struct dpa_priv_s *priv,
 	}
 
 	sgt = (struct qm_sg_entry *)(sgt_buf + priv->tx_headroom);
-	sgt[0].bpid = dpa_bp->bpid;
+	sgt[0].bpid = 0xff;
 	sgt[0].offset = 0;
-	sgt[0].length = skb_headlen(skb);
+	sgt[0].length = cpu_to_be32(skb_headlen(skb));
 	sgt[0].extension = 0;
 	sgt[0].final = 0;
 	addr = dma_map_single(dpa_bp->dev, skb->data, sgt[0].length, dma_dir);
@@ -774,16 +779,15 @@ static int __hot skb_to_sg_fd(struct dpa_priv_s *priv,
 		goto sg0_map_failed;
 
 	}
-	sgt[0].addr_hi = upper_32_bits(addr);
-	sgt[0].addr_lo = lower_32_bits(addr);
+	sgt[0].addr_hi = (uint8_t)upper_32_bits(addr);
+	sgt[0].addr_lo = cpu_to_be32(lower_32_bits(addr));
 
 	/* populate the rest of SGT entries */
 	for (i = 1; i <= nr_frags; i++) {
 		frag = &skb_shinfo(skb)->frags[i - 1];
-		sgt[i].bpid = dpa_bp->bpid;
-
+		sgt[i].bpid = 0xff;
 		sgt[i].offset = 0;
-		sgt[i].length = frag->size;
+		sgt[i].length = cpu_to_be32(frag->size);
 		sgt[i].extension = 0;
 		sgt[i].final = 0;
 
@@ -797,8 +801,8 @@ static int __hot skb_to_sg_fd(struct dpa_priv_s *priv,
 		}
 
 		/* keep the offset in the address */
-		sgt[i].addr_hi = upper_32_bits(addr);
-		sgt[i].addr_lo = lower_32_bits(addr);
+		sgt[i].addr_hi = (uint8_t)upper_32_bits(addr);
+		sgt[i].addr_lo = cpu_to_be32(lower_32_bits(addr));
 	}
 	sgt[i - 1].final = 1;
 
@@ -819,7 +823,10 @@ static int __hot skb_to_sg_fd(struct dpa_priv_s *priv,
 		err = -EINVAL;
 		goto sgt_map_failed;
 	}
-	fd->addr_hi = upper_32_bits(addr);
+
+	fd->bpid = 0xff;
+	fd->cmd |= FM_FD_CMD_FCO;
+	fd->addr_hi = (uint8_t)upper_32_bits(addr);
 	fd->addr_lo = lower_32_bits(addr);
 
 	return 0;
@@ -828,7 +835,7 @@ sgt_map_failed:
 sg_map_failed:
 	for (j = 0; j < i; j++)
 		dma_unmap_page(dpa_bp->dev, qm_sg_addr(&sgt[j]),
-			sgt[j].length, dma_dir);
+			be32_to_cpu(sgt[j].length), dma_dir);
 sg0_map_failed:
 csum_failed:
 	put_page(virt_to_head_page(sgt_buf));
@@ -927,8 +934,8 @@ int __hot dpa_tx(struct sk_buff *skb, struct net_device *net_dev)
 	if (unlikely(err < 0))
 		goto skb_to_fd_failed;
 
-	if (fd.cmd & FM_FD_CMD_FCO) {
-		skb_recycle(skb);
+	if (fd.bpid != 0xff) {
+		/* skb_recycle(skb); */
 		/* skb_recycle() reserves NET_SKB_PAD as skb headroom,
 		 * but we need the skb to look as if returned by build_skb().
 		 * We need to manually adjust the tailptr as well.
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth_shared.c b/drivers/net/ethernet/freescale/dpa/dpaa_eth_shared.c
index 7b88592..3757765 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth_shared.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth_shared.c
@@ -67,7 +67,6 @@ shared_tx_error_dqrr(struct qman_portal                *portal,
 static void shared_ern(struct qman_portal	*portal,
 		       struct qman_fq		*fq,
 		       const struct qm_mr_entry	*msg);
-int __hot dpa_shared_tx(struct sk_buff *skb, struct net_device *net_dev);
 
 #define DPA_DESCRIPTION "FSL DPAA Shared Ethernet driver"
 
@@ -274,18 +273,19 @@ shared_rx_dqrr(struct qman_portal *portal, struct qman_fq *fq,
 
 	if (fd->format == qm_fd_sg) {
 		if (dpa_bp->vaddr) {
-			sgt = dpa_phys2virt(dpa_bp,
-					    qm_fd_addr(fd)) + dpa_fd_offset(fd);
+			sgt = dpa_phys2virt(dpa_bp, qm_fd_addr(fd)) +
+				dpa_fd_offset(fd);
 
 			for (i = 0; i < DPA_SGT_MAX_ENTRIES; i++) {
+				void *frag_addr = dpa_phys2virt(dpa_bp,
+						qm_sg_addr(&sgt[i]) +
+						be16_to_cpu(sgt[i].offset));
+				u32 frag_length = be32_to_cpu(sgt[i].length);
 				BUG_ON(sgt[i].extension);
 
 				/* copy from sgt[i] */
-				memcpy(skb_put(skb, sgt[i].length),
-					dpa_phys2virt(dpa_bp,
-							qm_sg_addr(&sgt[i]) +
-							sgt[i].offset),
-					sgt[i].length);
+				memcpy(skb_put(skb, frag_length), frag_addr,
+						frag_length);
 				if (sgt[i].final)
 					break;
 			}
@@ -305,12 +305,13 @@ shared_rx_dqrr(struct qman_portal *portal, struct qman_fq *fq,
 							dpa_bp->size));
 
 			for (i = 0; i < DPA_SGT_MAX_ENTRIES; i++) {
+				u32 frag_length = be32_to_cpu(sgt[i].length);
 				BUG_ON(sgt[i].extension);
-
 				copy_from_unmapped_area(
-					skb_put(skb, sgt[i].length),
-					qm_sg_addr(&sgt[i]) + sgt[i].offset,
-					sgt[i].length);
+						skb_put(skb, frag_length),
+						qm_sg_addr(&sgt[i]) +
+						be16_to_cpu(sgt[i].offset),
+						frag_length);
 
 				if (sgt[i].final)
 					break;
@@ -488,7 +489,7 @@ int __hot dpa_shared_tx(struct sk_buff *skb, struct net_device *net_dev)
 	fd.bpid = dpa_bp->bpid;
 
 	fd.length20 = skb_headlen(skb);
-	fd.addr_hi = bmb.hi;
+	fd.addr_hi = (uint8_t)bmb.hi;
 	fd.addr_lo = bmb.lo;
 	fd.offset = priv->tx_headroom;
 
@@ -580,6 +581,7 @@ buf_acquire_failed:
 	/* We're done with the skb */
 	dev_kfree_skb(skb);
 
+	/* err remains unused, NETDEV_TX_OK must be returned here */
 	return NETDEV_TX_OK;
 }
 
@@ -604,7 +606,7 @@ static int dpa_shared_netdev_init(struct device_node *dpa_node,
 
 #ifdef CONFIG_PM
 
-static int dpa_shared_suspend_noirq(struct device *dev)
+static int dpa_shared_suspend(struct device *dev)
 {
 	struct net_device	*net_dev;
 	struct dpa_priv_s	*priv;
@@ -629,7 +631,7 @@ port_suspend_failed:
 	return err;
 }
 
-static int dpa_shared_resume_noirq(struct device *dev)
+static int dpa_shared_resume(struct device *dev)
 {
 	struct net_device	*net_dev;
 	struct dpa_priv_s	*priv;
@@ -655,8 +657,8 @@ port_resume_failed:
 }
 
 static const struct dev_pm_ops shared_pm_ops = {
-	.suspend_noirq = dpa_shared_suspend_noirq,
-	.resume_noirq = dpa_shared_resume_noirq,
+	.suspend = dpa_shared_suspend,
+	.resume = dpa_shared_resume,
 };
 
 #define SHARED_PM_OPS (&shared_pm_ops)
@@ -670,7 +672,7 @@ static const struct dev_pm_ops shared_pm_ops = {
 static int
 dpaa_eth_shared_probe(struct platform_device *_of_dev)
 {
-	int err = 0, i;
+	int err = 0, i, channel;
 	struct device *dev;
 	struct device_node *dpa_node;
 	struct dpa_bp *dpa_bp;
@@ -755,13 +757,15 @@ dpaa_eth_shared_probe(struct platform_device *_of_dev)
 
 	priv->mac_dev = mac_dev;
 
-	priv->channel = dpa_get_channel();
+	channel = dpa_get_channel();
 
-	if (priv->channel < 0) {
-		err = priv->channel;
+	if (channel < 0) {
+		err = channel;
 		goto get_channel_failed;
 	}
 
+	priv->channel = (uint16_t)channel;
+
 	/* Start a thread that will walk the cpus with affine portals
 	 * and add this pool channel to each's dequeue mask.
 	 */
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth_sysfs.c b/drivers/net/ethernet/freescale/dpa/dpaa_eth_sysfs.c
index bf01677..cd8b7d1 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth_sysfs.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth_sysfs.c
@@ -102,11 +102,6 @@ static ssize_t dpaa_eth_show_fqids(struct device *dev,
 		case FQ_TYPE_TX:
 			str = "Tx";
 			break;
-#ifdef CONFIG_FMAN_T4240
-		case FQ_TYPE_TX_RECYCLE:
-			str = "Tx(recycling)";
-			break;
-#endif
 		default:
 			str = "Unknown";
 		}
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_ethtool.c b/drivers/net/ethernet/freescale/dpa/dpaa_ethtool.c
index d36930e..60a1b22 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_ethtool.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_ethtool.c
@@ -189,8 +189,8 @@ static void __cold dpa_get_pauseparam(struct net_device *net_dev,
 	}
 
 	epause->autoneg = mac_dev->autoneg_pause;
-	epause->rx_pause = mac_dev->rx_pause;
-	epause->tx_pause = mac_dev->tx_pause;
+	epause->rx_pause = mac_dev->rx_pause_active;
+	epause->tx_pause = mac_dev->tx_pause_active;
 }
 
 static int __cold dpa_set_pauseparam(struct net_device *net_dev,
@@ -201,6 +201,7 @@ static int __cold dpa_set_pauseparam(struct net_device *net_dev,
 	struct phy_device       *phy_dev;
 	int _errno;
 	u32 newadv, oldadv;
+	bool rx_pause, tx_pause;
 
 	priv = netdev_priv(net_dev);
 	mac_dev = priv->mac_dev;
@@ -225,7 +226,9 @@ static int __cold dpa_set_pauseparam(struct net_device *net_dev,
 	 * adjust_link is triggered by a forced renegotiation of sym/asym PAUSE
 	 * settings.
 	 */
-	mac_dev->autoneg_pause = epause->autoneg;
+	mac_dev->autoneg_pause = !!epause->autoneg;
+	mac_dev->rx_pause_req = !!epause->rx_pause;
+	mac_dev->tx_pause_req = !!epause->tx_pause;
 
 	/* Determine the sym/asym advertised PAUSE capabilities from the desired
 	 * rx/tx pause settings.
@@ -254,25 +257,12 @@ static int __cold dpa_set_pauseparam(struct net_device *net_dev,
 		}
 	}
 
-	if (epause->autoneg)
-		return 0;
-
-	/* If PAUSE frame autonegotiation is disabled,
-	 * ethtool rx/tx settings are enforced.
-	 */
-	_errno = set_mac_rx_pause(mac_dev, !!epause->rx_pause);
-	if (unlikely(_errno < 0)) {
-		netdev_err(net_dev, "set_mac_rx_pause() = %d\n", _errno);
-		return _errno;
-	}
-
-	_errno = set_mac_tx_pause(mac_dev, !!epause->tx_pause);
-	if (unlikely(_errno < 0)) {
-		netdev_err(net_dev, "set_mac_tx_pause() = %d\n", _errno);
-		return _errno;
-	}
+	get_pause_cfg(mac_dev, &rx_pause, &tx_pause);
+	_errno = set_mac_active_pause(mac_dev, rx_pause, tx_pause);
+	if (unlikely(_errno < 0))
+		netdev_err(net_dev, "set_mac_active_pause() = %d\n", _errno);
 
-	return 0;
+	return _errno;
 }
 
 #ifdef CONFIG_PM
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_generic_debugfs.c b/drivers/net/ethernet/freescale/dpa/dpaa_generic_debugfs.c
index 6ab1ade..46b02d9 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_generic_debugfs.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_generic_debugfs.c
@@ -35,6 +35,7 @@
 #include <asm/debug.h>
 
 #include "dpaa_eth_generic.h"
+#include "dpaa_generic_debugfs.h"
 
 #define DPA_DEBUGFS_DESCRIPTION "FSL DPAA Ethernet debugfs entries"
 #define DPA_GENERIC_ETH_DEBUGFS_ROOT "fsl_generic_dpa"
diff --git a/drivers/net/ethernet/freescale/dpa/mac-api.c b/drivers/net/ethernet/freescale/dpa/mac-api.c
index a8b4704..dcb6ff2 100644
--- a/drivers/net/ethernet/freescale/dpa/mac-api.c
+++ b/drivers/net/ethernet/freescale/dpa/mac-api.c
@@ -132,9 +132,11 @@ static int __cold init(struct mac_device *mac_dev)
 	uint32_t			version;
 
 	priv = macdev_priv(mac_dev);
-
+#ifndef CONFIG_FSL_DPAA_DBG_EMULATOR
+	/* TODO find out why devm_ioremap is failing */
 	param.baseAddr =  (typeof(param.baseAddr))(uintptr_t)devm_ioremap(
 		mac_dev->dev, mac_dev->res->start, 0x2000);
+#endif
 	param.enetMode	= macdev2enetinterface(mac_dev);
 	memcpy(&param.addr, mac_dev->addr, min(sizeof(param.addr),
 		sizeof(mac_dev->addr)));
@@ -224,8 +226,11 @@ static int __cold memac_init(struct mac_device *mac_dev)
 
 	priv = macdev_priv(mac_dev);
 
+#ifndef CONFIG_FSL_DPAA_DBG_EMULATOR
+	/* TODO find out why devm_ioremap is failing */
 	param.baseAddr =  (typeof(param.baseAddr))(uintptr_t)devm_ioremap(
 		mac_dev->dev, mac_dev->res->start, 0x2000);
+#endif
 	param.enetMode	= macdev2enetinterface(mac_dev);
 	memcpy(&param.addr, mac_dev->addr, sizeof(mac_dev->addr));
 	param.macId		= mac_dev->cell_index;
@@ -271,12 +276,14 @@ static int __cold start(struct mac_device *mac_dev)
 
 	_errno = fm_mac_enable(mac_dev->get_mac_handle(mac_dev));
 
+#ifndef CONFIG_FSL_DPAA_DBG_EMULATOR
 	if (!_errno && phy_dev) {
 		if (macdev2enetinterface(mac_dev) != e_ENET_MODE_XGMII_10000)
 			phy_start(phy_dev);
 		else if (phy_dev->drv->read_status)
 			phy_dev->drv->read_status(phy_dev);
 	}
+#endif
 
 	return _errno;
 }
@@ -330,33 +337,24 @@ static int __cold set_multi(struct net_device *net_dev,
 }
 
 /* Avoid redundant calls to FMD, if the MAC driver already contains the desired
- * settings. Otherwise, the new MAC settings should be reflected in FMan.
+ * active PAUSE settings. Otherwise, the new active settings should be reflected
+ * in FMan.
  */
-int set_mac_rx_pause(struct mac_device *mac_dev, bool en)
+int set_mac_active_pause(struct mac_device *mac_dev, bool rx, bool tx)
 {
-	struct fm_mac_dev *fm_mac_dev;
+	struct fm_mac_dev *fm_mac_dev = mac_dev->get_mac_handle(mac_dev);
 	int _errno = 0;
 
-	if (unlikely(en != mac_dev->rx_pause)) {
-		fm_mac_dev = mac_dev->get_mac_handle(mac_dev);
-		_errno = fm_mac_set_rx_pause_frames(fm_mac_dev, en);
+	if (unlikely(rx != mac_dev->rx_pause_active)) {
+		_errno = fm_mac_set_rx_pause_frames(fm_mac_dev, rx);
 		if (likely(_errno == 0))
-			mac_dev->rx_pause = en;
+			mac_dev->rx_pause_active = rx;
 	}
 
-	return _errno;
-}
-
-int set_mac_tx_pause(struct mac_device *mac_dev, bool en)
-{
-	int _errno = 0;
-	struct fm_mac_dev *fm_mac_dev;
-
-	if (unlikely(en != mac_dev->tx_pause)) {
-		fm_mac_dev = mac_dev->get_mac_handle(mac_dev);
-		_errno = fm_mac_set_tx_pause_frames(fm_mac_dev, en);
+	if (unlikely(tx != mac_dev->tx_pause_active)) {
+		_errno = fm_mac_set_tx_pause_frames(fm_mac_dev, tx);
 		if (likely(_errno == 0))
-			mac_dev->tx_pause = en;
+			mac_dev->tx_pause_active = tx;
 	}
 
 	return _errno;
@@ -365,8 +363,7 @@ int set_mac_tx_pause(struct mac_device *mac_dev, bool en)
 /* Determine the MAC RX/TX PAUSE frames settings based on PHY
  * autonegotiation or values set by eththool.
  */
-static void get_pause_cfg(struct mac_device *mac_dev,
-		bool *rx_pause, bool *tx_pause)
+void get_pause_cfg(struct mac_device *mac_dev, bool *rx_pause, bool *tx_pause)
 {
 	struct phy_device *phy_dev = mac_dev->phy_dev;
 	u16 lcl_adv, rmt_adv;
@@ -381,8 +378,8 @@ static void get_pause_cfg(struct mac_device *mac_dev,
 	 * are those set by ethtool.
 	 */
 	if (!mac_dev->autoneg_pause) {
-		*rx_pause = !!mac_dev->rx_pause;
-		*tx_pause = !!mac_dev->tx_pause;
+		*rx_pause = mac_dev->rx_pause_req;
+		*tx_pause = mac_dev->tx_pause_req;
 		return;
 	}
 
@@ -428,13 +425,9 @@ static void adjust_link(struct net_device *net_dev)
 			phy_dev->duplex);
 
 	get_pause_cfg(mac_dev, &rx_pause, &tx_pause);
-
-	_errno = set_mac_rx_pause(mac_dev, rx_pause);
-	if (unlikely(_errno < 0))
-		netdev_err(net_dev, "set_rx_pause() = %d\n", _errno);
-	_errno = set_mac_tx_pause(mac_dev, tx_pause);
+	_errno = set_mac_active_pause(mac_dev, rx_pause, tx_pause);
 	if (unlikely(_errno < 0))
-		netdev_err(net_dev, "set_tx_pause() = %d\n", _errno);
+		netdev_err(net_dev, "set_mac_active_pause() = %d\n", _errno);
 }
 
 /* Initializes driver's PHY state, and attaches to the PHY.
diff --git a/drivers/net/ethernet/freescale/dpa/mac.c b/drivers/net/ethernet/freescale/dpa/mac.c
index 20994d4..4c83a05 100644
--- a/drivers/net/ethernet/freescale/dpa/mac.c
+++ b/drivers/net/ethernet/freescale/dpa/mac.c
@@ -46,6 +46,8 @@
 #include <linux/device.h>
 #include <linux/phy.h>
 
+#include <dpaa_eth.h>
+
 #include "lnxwrp_fm_ext.h"
 
 #include "mac.h"
@@ -140,7 +142,7 @@ MODULE_DEVICE_TABLE(of, mac_match);
 
 static int __cold mac_probe(struct platform_device *_of_dev)
 {
-	int			 _errno, i, lenp;
+	int			 _errno, i;
 	struct device		*dev;
 	struct device_node	*mac_node, *dev_node;
 	struct mac_device	*mac_dev;
@@ -148,8 +150,8 @@ static int __cold mac_probe(struct platform_device *_of_dev)
 	struct resource		 res;
 	const uint8_t		*mac_addr;
 	const char		*char_prop;
-	const phandle		*phandle_prop;
-	const uint32_t		*uint32_prop;
+	int			nph;
+	u32			cell_index;
 	const struct of_device_id *match;
 
 	dev = &_of_dev->dev;
@@ -218,6 +220,8 @@ static int __cold mac_probe(struct platform_device *_of_dev)
 		goto _return_dev_set_drvdata;
 	}
 
+#ifndef CONFIG_FSL_DPAA_DBG_EMULATOR
+	/* TODO: find out why devm_ioremap() call is not working */
 	mac_dev->vaddr = devm_ioremap(dev, mac_dev->res->start,
 				      mac_dev->res->end + 1
 				      - mac_dev->res->start);
@@ -226,21 +230,26 @@ static int __cold mac_probe(struct platform_device *_of_dev)
 		_errno = -EIO;
 		goto _return_dev_set_drvdata;
 	}
+#endif
 
 #define TBIPA_OFFSET		0x1c
 #define TBIPA_DEFAULT_ADDR	5 /* override if used as external PHY addr. */
 	mac_dev->tbi_node = of_parse_phandle(mac_node, "tbi-handle", 0);
 	if (mac_dev->tbi_node) {
 		u32 tbiaddr = TBIPA_DEFAULT_ADDR;
-
-		uint32_prop = of_get_property(mac_dev->tbi_node, "reg", NULL);
-		if (uint32_prop)
-			tbiaddr = *uint32_prop;
-		out_be32(mac_dev->vaddr + TBIPA_OFFSET, tbiaddr);
+		const __be32 *tbi_reg;
+		void __iomem *addr;
+
+		tbi_reg = of_get_property(mac_dev->tbi_node, "reg", NULL);
+		if (tbi_reg)
+			tbiaddr = be32_to_cpup(tbi_reg);
+		addr = mac_dev->vaddr + TBIPA_OFFSET;
+		/* TODO: out_be32 does not exist on ARM */
+		out_be32(addr, tbiaddr);
 	}
 
 	if (!of_device_is_available(mac_node)) {
-		devm_iounmap(dev, mac_dev->vaddr);
+		/* devm_iounmap(dev, mac_dev->vaddr); */
 		__devm_release_region(dev, fm_get_mem_region(mac_dev->fm_dev),
 			res.start, res.end + 1 - res.start);
 		fm_unbind(mac_dev->fm_dev);
@@ -250,15 +259,13 @@ static int __cold mac_probe(struct platform_device *_of_dev)
 	}
 
 	/* Get the cell-index */
-	uint32_prop = of_get_property(mac_node, "cell-index", &lenp);
-	if (unlikely(uint32_prop == NULL)) {
-		dev_err(dev, "of_get_property(%s, cell-index) failed\n",
+	_errno = of_property_read_u32(mac_node, "cell-index", &cell_index);
+	if (unlikely(_errno)) {
+		dev_err(dev, "Cannot read cell-index of mac node %s from device tree\n",
 				mac_node->full_name);
-		_errno = -EINVAL;
 		goto _return_dev_set_drvdata;
 	}
-	BUG_ON(lenp != sizeof(uint32_t));
-	mac_dev->cell_index = *uint32_prop;
+	mac_dev->cell_index = (uint8_t)cell_index;
 
 	/* Get the MAC address */
 	mac_addr = of_get_mac_address(mac_node);
@@ -270,21 +277,27 @@ static int __cold mac_probe(struct platform_device *_of_dev)
 	}
 	memcpy(mac_dev->addr, mac_addr, sizeof(mac_dev->addr));
 
-	/* Get the port handles */
-	phandle_prop = of_get_property(mac_node, "fsl,port-handles", &lenp);
-	if (unlikely(phandle_prop == NULL)) {
-		dev_err(dev, "of_get_property(%s, port-handles) failed\n",
+	/* Verify the number of port handles */
+	nph = of_count_phandle_with_args(mac_node, "fsl,port-handles", NULL);
+	if (unlikely(nph < 0)) {
+		dev_err(dev, "Cannot read port handles of mac node %s from device tree\n",
+				mac_node->full_name);
+		_errno = nph;
+		goto _return_dev_set_drvdata;
+	}
+
+	if (nph != ARRAY_SIZE(mac_dev->port_dev)) {
+		dev_err(dev, "Not supported number of port handles of mac node %s from device tree\n",
 				mac_node->full_name);
 		_errno = -EINVAL;
 		goto _return_dev_set_drvdata;
 	}
-	BUG_ON(lenp != sizeof(phandle) * ARRAY_SIZE(mac_dev->port_dev));
 
 	for_each_port_device(i, mac_dev->port_dev) {
-		/* Find the port node */
-		dev_node = of_find_node_by_phandle(phandle_prop[i]);
+		dev_node = of_parse_phandle(mac_node, "fsl,port-handles", i);
 		if (unlikely(dev_node == NULL)) {
-			dev_err(dev, "of_find_node_by_phandle() failed\n");
+			dev_err(dev, "Cannot find port node referenced by mac node %s from device tree\n",
+					mac_node->full_name);
 			_errno = -EINVAL;
 			goto _return_of_node_put;
 		}
@@ -308,16 +321,20 @@ static int __cold mac_probe(struct platform_device *_of_dev)
 	}
 
 	/* Get the PHY connection type */
-	char_prop = (const char *)of_get_property(mac_node,
-						"phy-connection-type", NULL);
-	if (unlikely(char_prop == NULL)) {
+	_errno = of_property_read_string(mac_node, "phy-connection-type",
+			&char_prop);
+	if (unlikely(_errno)) {
 		dev_warn(dev,
-			 "of_get_property(%s, phy-connection-type) failed. Defaulting to MII\n",
+			 "Cannot read PHY connection type of mac node %s from device tree. Defaulting to MII\n",
 			 mac_node->full_name);
 		mac_dev->phy_if = PHY_INTERFACE_MODE_MII;
 	} else
 		mac_dev->phy_if = str2phy(char_prop);
 
+#ifdef CONFIG_FSL_DPAA_DBG_EMULATOR
+	_errno = 0; /* ignore the above error */
+#endif
+
 	mac_dev->link		= false;
 	mac_dev->half_duplex	= false;
 	mac_dev->speed		= phy2speed[mac_dev->phy_if];
@@ -336,27 +353,8 @@ static int __cold mac_probe(struct platform_device *_of_dev)
 	if (strstr(char_prop, "xgmii"))
 		mac_dev->if_support = SUPPORTED_10000baseT_Full;
 
-	/* Get the rest of the PHY information */
-	mac_dev->phy_node = of_parse_phandle(mac_node, "phy-handle", 0);
-	if (mac_dev->phy_node == NULL) {
-		int sz;
-		const u32 *phy_id = of_get_property(mac_node, "fixed-link",
-							&sz);
-		if (!phy_id || sz < sizeof(*phy_id)) {
-			dev_err(dev, "No PHY (or fixed link) found\n");
-			_errno = -EINVAL;
-			goto _return_dev_set_drvdata;
-		}
-
-		sprintf(mac_dev->fixed_bus_id, PHY_ID_FMT, "fixed-0",
-			phy_id[0]);
-	}
-
-	_errno = mac_dev->init(mac_dev);
-	if (unlikely(_errno < 0)) {
-		dev_err(dev, "mac_dev->init() = %d\n", _errno);
-		goto _return_dev_set_drvdata;
-	}
+	/* TODO: Parse the "phy-handle" */
+	/* TODO: Initialize the MAC device (call to mac_dev->init)  */
 
 	/* pause frame autonegotiation enabled*/
 	mac_dev->autoneg_pause = true;
@@ -364,19 +362,14 @@ static int __cold mac_probe(struct platform_device *_of_dev)
 	/* by intializing the values to false, force FMD to enable PAUSE frames
 	 * on RX and TX
 	 */
-	mac_dev->rx_pause = mac_dev->tx_pause = false;
-	/* does not ignore PAUSE frames */
-	_errno = set_mac_rx_pause(mac_dev, true);
-	if (unlikely(_errno < 0)) {
-		dev_err(dev, "set_mac_rx_pause() = %d\n", _errno);
-		return _errno;
-	}
-	/* transmits PAUSE frames when congested */
-	_errno = set_mac_tx_pause(mac_dev, true);
-	if (unlikely(_errno < 0)) {
-		dev_err(dev, "set_mac_tx_pause() = %d\n", _errno);
-		return _errno;
-	}
+	mac_dev->rx_pause_req = mac_dev->tx_pause_req = true;
+	mac_dev->rx_pause_active = mac_dev->tx_pause_active = false;
+
+#ifndef CONFIG_FSL_DPAA_DBG_EMULATOR
+	_errno = set_mac_active_pause(mac_dev, true, true);
+	if (unlikely(_errno < 0))
+		dev_err(dev, "set_mac_active_pause() = %d\n", _errno);
+#endif
 
 	dev_info(dev,
 		"FMan MAC address: %02hx:%02hx:%02hx:%02hx:%02hx:%02hx\n",
diff --git a/drivers/net/ethernet/freescale/dpa/mac.h b/drivers/net/ethernet/freescale/dpa/mac.h
index 785877f..f9e2db2 100644
--- a/drivers/net/ethernet/freescale/dpa/mac.h
+++ b/drivers/net/ethernet/freescale/dpa/mac.h
@@ -67,9 +67,11 @@ struct mac_device {
 	/* List of multicast addresses */
 	struct list_head	 mc_addr_list;
 
-	u32	autoneg_pause;
-	u32	rx_pause;
-	u32	tx_pause;
+	bool autoneg_pause;
+	bool rx_pause_req;
+	bool tx_pause_req;
+	bool rx_pause_active;
+	bool tx_pause_active;
 
 	struct fm_mac_dev *(*get_mac_handle)(struct mac_device *mac_dev);
 	int (*init_phy)(struct net_device *net_dev, struct mac_device *mac_dev);
@@ -121,7 +123,7 @@ extern const char	*mac_driver_description;
 extern const size_t	 mac_sizeof_priv[];
 extern void (*const mac_setup[])(struct mac_device *mac_dev);
 
-int set_mac_rx_pause(struct mac_device *mac_dev, bool en);
-int set_mac_tx_pause(struct mac_device *mac_dev, bool en);
+int set_mac_active_pause(struct mac_device *mac_dev, bool rx, bool tx);
+void get_pause_cfg(struct mac_device *mac_dev, bool *rx_pause, bool *tx_pause);
 
 #endif	/* __MAC_H */
diff --git a/drivers/net/ethernet/freescale/dpa/offline_port.c b/drivers/net/ethernet/freescale/dpa/offline_port.c
index 17ed9af..ddbfdce 100644
--- a/drivers/net/ethernet/freescale/dpa/offline_port.c
+++ b/drivers/net/ethernet/freescale/dpa/offline_port.c
@@ -76,7 +76,7 @@ MODULE_DEVICE_TABLE(of, oh_port_match_table);
 
 #ifdef CONFIG_PM
 
-static int oh_suspend_noirq(struct device *dev)
+static int oh_suspend(struct device *dev)
 {
 	struct dpa_oh_config_s	*oh_config;
 
@@ -84,7 +84,7 @@ static int oh_suspend_noirq(struct device *dev)
 	return fm_port_suspend(oh_config->oh_port);
 }
 
-static int oh_resume_noirq(struct device *dev)
+static int oh_resume(struct device *dev)
 {
 	struct dpa_oh_config_s	*oh_config;
 
@@ -93,8 +93,8 @@ static int oh_resume_noirq(struct device *dev)
 }
 
 static const struct dev_pm_ops oh_pm_ops = {
-	.suspend_noirq = oh_suspend_noirq,
-	.resume_noirq = oh_resume_noirq,
+	.suspend = oh_suspend,
+	.resume = oh_resume,
 };
 
 #define OH_PM_OPS (&oh_pm_ops)
@@ -143,7 +143,7 @@ static uint32_t oh_fq_create(struct qman_fq *fq,
 	return 0;
 }
 
-void dump_fq(struct device *dev, int fqid, int channel)
+static void dump_fq(struct device *dev, int fqid, uint16_t channel)
 {
 	if (channel) {
 		/* display fqs with a valid (!= 0) destination channel */
@@ -151,15 +151,15 @@ void dump_fq(struct device *dev, int fqid, int channel)
 	}
 }
 
-void dump_fq_duple(struct device *dev, struct qman_fq *fqs, int fqs_count,
-		int channel_id)
+static void dump_fq_duple(struct device *dev, struct qman_fq *fqs,
+		int fqs_count, uint16_t channel_id)
 {
 	int i;
 	for (i = 0; i < fqs_count; i++)
 		dump_fq(dev, (fqs + i)->fqid, channel_id);
 }
 
-void dump_oh_config(struct device *dev, struct dpa_oh_config_s *conf)
+static void dump_oh_config(struct device *dev, struct dpa_oh_config_s *conf)
 {
 	struct list_head *fq_list;
 	struct fq_duple *fqd;
@@ -250,14 +250,13 @@ oh_port_probe(struct platform_device *_of_dev)
 	struct device_node *dpa_oh_node;
 	int lenp, _errno = 0, fq_idx, duple_idx;
 	int n_size, i, j, ret, duples_count;
-	const phandle *oh_port_handle, *bpool_handle;
 	struct platform_device *oh_of_dev;
 	struct device_node *oh_node, *bpool_node = NULL, *root_node;
 	struct device *oh_dev;
 	struct dpa_oh_config_s *oh_config = NULL;
-	uint32_t *oh_all_queues;
-	uint32_t *channel_ids;
-	uint32_t *oh_tx_queues;
+	const __be32 *oh_all_queues;
+	const __be32 *channel_ids;
+	const __be32 *oh_tx_queues;
 	uint32_t queues_count;
 	uint32_t crt_fqid_base;
 	uint32_t crt_fq_count;
@@ -270,17 +269,18 @@ oh_port_probe(struct platform_device *_of_dev)
 	bool init_oh_port;
 
 	const struct of_device_id *match;
-	uint32_t crt_ext_pools_count, ext_pool_size;
-	const unsigned int *port_id;
-	const unsigned int *channel_id;
+	int crt_ext_pools_count;
+	u32 ext_pool_size;
+	u32 port_id;
+	u32 channel_id;
 
 	int channel_ids_count;
 	int channel_idx;
 	struct fq_duple *fqd;
 	struct list_head *fq_list, *fq_list_tmp;
 
-	const uint32_t *bpool_cfg;
-	const uint32_t *bpid;
+	const __be32 *bpool_cfg;
+	uint32_t bpid;
 
 	memset(&oh_port_tx_params, 0, sizeof(oh_port_tx_params));
 	dpa_oh_dev = &_of_dev->dev;
@@ -294,49 +294,28 @@ oh_port_probe(struct platform_device *_of_dev)
 	dev_dbg(dpa_oh_dev, "Probing OH port...\n");
 
 	/* Find the referenced OH node */
-
-	oh_port_handle = of_get_property(dpa_oh_node,
-		"fsl,fman-oh-port", &lenp);
-	if (oh_port_handle == NULL) {
-		dev_err(dpa_oh_dev, "No OH port handle found in node %s\n",
-			dpa_oh_node->full_name);
-		return -EINVAL;
-	}
-
-	BUG_ON(lenp % sizeof(*oh_port_handle));
-	if (lenp != sizeof(*oh_port_handle)) {
-		dev_err(dpa_oh_dev,
-			"Found %lu OH port bindings in node %s, only 1 phandle is allowed.\n",
-			(unsigned long int)(lenp / sizeof(*oh_port_handle)),
-			dpa_oh_node->full_name);
-		return -EINVAL;
-	}
-
-	/* Read configuration for the OH port */
-	oh_node = of_find_node_by_phandle(*oh_port_handle);
+	oh_node = of_parse_phandle(dpa_oh_node, "fsl,fman-oh-port", 0);
 	if (oh_node == NULL) {
 		dev_err(dpa_oh_dev,
 			"Can't find OH node referenced from node %s\n",
 			dpa_oh_node->full_name);
 		return -EINVAL;
 	}
-	dev_info(dpa_oh_dev, "Found OH node handle compatible with %s.\n",
+	dev_info(dpa_oh_dev, "Found OH node handle compatible with %s\n",
 		match->compatible);
 
-	port_id = of_get_property(oh_node, "cell-index", &lenp);
-	if (port_id == NULL) {
+	_errno = of_property_read_u32(oh_node, "cell-index", &port_id);
+	if (_errno) {
 		dev_err(dpa_oh_dev, "No port id found in node %s\n",
 			dpa_oh_node->full_name);
-		_errno = -EINVAL;
 		goto return_kfree;
 	}
-	BUG_ON(lenp % sizeof(*port_id));
 
-	channel_id = of_get_property(oh_node, "fsl,qman-channel-id", &lenp);
-	if (channel_id == NULL) {
+	_errno = of_property_read_u32(oh_node, "fsl,qman-channel-id",
+			&channel_id);
+	if (_errno) {
 		dev_err(dpa_oh_dev, "No channel id found in node %s\n",
 			dpa_oh_node->full_name);
-		_errno = -EINVAL;
 		goto return_kfree;
 	}
 
@@ -383,7 +362,7 @@ oh_port_probe(struct platform_device *_of_dev)
 
 	/* FQs that enter OH port */
 	lenp = 0;
-	oh_all_queues = (uint32_t *)of_get_property(dpa_oh_node,
+	oh_all_queues = of_get_property(dpa_oh_node,
 		"fsl,qman-frame-queues-ingress", &lenp);
 	if (lenp % (2 * sizeof(*oh_all_queues))) {
 		dev_warn(dpa_oh_dev,
@@ -396,8 +375,8 @@ oh_port_probe(struct platform_device *_of_dev)
 	dev_err(dpa_oh_dev, "Allocating %d ingress frame queues duples\n",
 			duples_count);
 	for (duple_idx = 0; duple_idx < duples_count; duple_idx++) {
-		crt_fqid_base = oh_all_queues[2 * duple_idx];
-		crt_fq_count = oh_all_queues[2 * duple_idx + 1];
+		crt_fqid_base = be32_to_cpu(oh_all_queues[2 * duple_idx]);
+		crt_fq_count = be32_to_cpu(oh_all_queues[2 * duple_idx + 1]);
 
 		fqd = devm_kzalloc(dpa_oh_dev,
 				sizeof(struct fq_duple), GFP_KERNEL);
@@ -423,7 +402,7 @@ oh_port_probe(struct platform_device *_of_dev)
 		for (j = 0; j < crt_fq_count; j++)
 			(fqd->fqs + j)->fqid = crt_fqid_base + j;
 		fqd->fqs_count = crt_fq_count;
-		fqd->channel_id = *channel_id;
+		fqd->channel_id = (uint16_t)channel_id;
 		list_add(&fqd->fq_list, &oh_config->fqs_ingress_list);
 	}
 
@@ -448,7 +427,7 @@ oh_port_probe(struct platform_device *_of_dev)
 
 	/* FQs that exit OH port */
 	lenp = 0;
-	oh_all_queues = (uint32_t *)of_get_property(dpa_oh_node,
+	oh_all_queues = of_get_property(dpa_oh_node,
 		"fsl,qman-frame-queues-egress", &lenp);
 	if (lenp % (2 * sizeof(*oh_all_queues))) {
 		dev_warn(dpa_oh_dev,
@@ -461,8 +440,8 @@ oh_port_probe(struct platform_device *_of_dev)
 	dev_dbg(dpa_oh_dev, "Allocating %d egress frame queues duples\n",
 			duples_count);
 	for (duple_idx = 0; duple_idx < duples_count; duple_idx++) {
-		crt_fqid_base = oh_all_queues[2 * duple_idx];
-		crt_fq_count = oh_all_queues[2 * duple_idx + 1];
+		crt_fqid_base = be32_to_cpu(oh_all_queues[2 * duple_idx]);
+		crt_fq_count = be32_to_cpu(oh_all_queues[2 * duple_idx + 1]);
 
 		fqd = devm_kzalloc(dpa_oh_dev,
 				sizeof(struct fq_duple), GFP_KERNEL);
@@ -491,7 +470,7 @@ oh_port_probe(struct platform_device *_of_dev)
 		fqd->fqs_count = crt_fq_count;
 		/* channel ID is specified in another attribute */
 		fqd->channel_id = 0;
-		list_add(&fqd->fq_list, &oh_config->fqs_egress_list);
+		list_add_tail(&fqd->fq_list, &oh_config->fqs_egress_list);
 
 		/* allocate the queue */
 
@@ -499,7 +478,7 @@ oh_port_probe(struct platform_device *_of_dev)
 
 	/* channel_ids for FQs that exit OH port */
 	lenp = 0;
-	channel_ids = (uint32_t *)of_get_property(dpa_oh_node,
+	channel_ids = of_get_property(dpa_oh_node,
 		"fsl,qman-channel-ids-egress", &lenp);
 
 	channel_ids_count = lenp / (sizeof(*channel_ids));
@@ -515,7 +494,8 @@ oh_port_probe(struct platform_device *_of_dev)
 		if (channel_idx + 1 > channel_ids_count)
 			break;
 		fqd = list_entry(fq_list, struct fq_duple, fq_list);
-		fqd->channel_id = channel_ids[channel_idx++];
+		fqd->channel_id =
+			(uint16_t)be32_to_cpu(channel_ids[channel_idx++]);
 	}
 
 	/* create egress queues */
@@ -543,7 +523,7 @@ oh_port_probe(struct platform_device *_of_dev)
 	}
 
 	/* Read FQ ids/nums for the DPA OH node */
-	oh_all_queues = (uint32_t *)of_get_property(dpa_oh_node,
+	oh_all_queues = of_get_property(dpa_oh_node,
 		"fsl,qman-frame-queues-oh", &lenp);
 	if (oh_all_queues == NULL) {
 		dev_err(dpa_oh_dev,
@@ -569,8 +549,8 @@ oh_port_probe(struct platform_device *_of_dev)
 	fq_idx = 0;
 
 	/* Error FQID - must be present */
-	crt_fqid_base = oh_all_queues[fq_idx++];
-	crt_fq_count = oh_all_queues[fq_idx++];
+	crt_fqid_base = be32_to_cpu(oh_all_queues[fq_idx++]);
+	crt_fq_count = be32_to_cpu(oh_all_queues[fq_idx++]);
 	if (crt_fq_count != 1) {
 		dev_err(dpa_oh_dev,
 			"Only 1 Error FQ allowed in OH node %s referenced from node %s (read: %d FQIDs).\n",
@@ -584,8 +564,8 @@ oh_port_probe(struct platform_device *_of_dev)
 		oh_config->error_fqid, oh_node->full_name);
 
 	/* Default FQID - must be present */
-	crt_fqid_base = oh_all_queues[fq_idx++];
-	crt_fq_count = oh_all_queues[fq_idx++];
+	crt_fqid_base = be32_to_cpu(oh_all_queues[fq_idx++]);
+	crt_fq_count = be32_to_cpu(oh_all_queues[fq_idx++]);
 	if (crt_fq_count != 1) {
 		dev_err(dpa_oh_dev,
 			"Only 1 Default FQ allowed in OH node %s referenced from %s (read: %d FQIDs).\n",
@@ -599,8 +579,8 @@ oh_port_probe(struct platform_device *_of_dev)
 		oh_config->default_fqid, oh_node->full_name);
 
 	/* TX FQID - presence is optional */
-	oh_tx_queues = (uint32_t *)of_get_property(dpa_oh_node,
-		"fsl,qman-frame-queues-tx", &lenp);
+	oh_tx_queues = of_get_property(dpa_oh_node, "fsl,qman-frame-queues-tx",
+			&lenp);
 	if (oh_tx_queues == NULL) {
 		dev_dbg(dpa_oh_dev,
 			"No tx queues have been defined for OH node %s referenced from node %s\n",
@@ -619,19 +599,9 @@ oh_port_probe(struct platform_device *_of_dev)
 		goto return_kfree;
 	}
 
-	/* Read channel id for the queues */
-	channel_id = of_get_property(oh_node, "fsl,qman-channel-id", &lenp);
-	if (channel_id == NULL) {
-		dev_err(dpa_oh_dev, "No channel id found in node %s\n",
-			dpa_oh_node->full_name);
-		_errno = -EINVAL;
-		goto return_kfree;
-	}
-	BUG_ON(lenp % sizeof(*channel_id));
-
 	fq_idx = 0;
-	crt_fqid_base = oh_tx_queues[fq_idx++];
-	crt_fq_count = oh_tx_queues[fq_idx++];
+	crt_fqid_base = be32_to_cpu(oh_tx_queues[fq_idx++]);
+	crt_fq_count = be32_to_cpu(oh_tx_queues[fq_idx++]);
 	oh_config->egress_cnt = crt_fq_count;
 
 	/* Allocate TX queues */
@@ -649,7 +619,7 @@ oh_port_probe(struct platform_device *_of_dev)
 	/* Create TX queues */
 	for (i = 0; i < crt_fq_count; i++) {
 		ret = oh_fq_create(oh_config->egress_fqs + i,
-			crt_fqid_base + i, *channel_id, 3);
+			crt_fqid_base + i, (uint16_t)channel_id, 3);
 		if (ret != 0) {
 			dev_err(dpa_oh_dev,
 				"Unable to create TX frame queue %d for OH node %s referenced from node %s!\n",
@@ -673,10 +643,11 @@ config_port:
 	}
 
 	oh_set_buffer_layout(oh_config->oh_port, &buf_layout);
-	bpool_handle = of_get_property(dpa_oh_node,
-			"fsl,bman-buffer-pools", &lenp);
 
-	if (bpool_handle == NULL) {
+	/* read the pool handlers */
+	crt_ext_pools_count = of_count_phandle_with_args(dpa_oh_node,
+			"fsl,bman-buffer-pools", NULL);
+	if (crt_ext_pools_count <= 0) {
 		dev_info(dpa_oh_dev,
 			 "OH port %s has no buffer pool. Fragmentation will not be enabled\n",
 			oh_node->full_name);
@@ -694,29 +665,29 @@ config_port:
 	n_size = of_n_size_cells(root_node);
 	of_node_put(root_node);
 
-	crt_ext_pools_count = lenp / sizeof(phandle);
-	dev_dbg(dpa_oh_dev, "OH port number of pools = %u\n",
+	dev_dbg(dpa_oh_dev, "OH port number of pools = %d\n",
 			crt_ext_pools_count);
 
-	oh_port_tx_params.num_pools = crt_ext_pools_count;
+	oh_port_tx_params.num_pools = (uint8_t)crt_ext_pools_count;
 
 	for (i = 0; i < crt_ext_pools_count; i++) {
-		bpool_node = of_find_node_by_phandle(bpool_handle[i]);
+		bpool_node = of_parse_phandle(dpa_oh_node,
+				"fsl,bman-buffer-pools", i);
 		if (bpool_node == NULL) {
 			dev_err(dpa_oh_dev, "Invalid Buffer pool node\n");
 			_errno = -EINVAL;
 			goto return_kfree;
 		}
 
-		bpid = of_get_property(bpool_node, "fsl,bpid", &lenp);
-		if ((bpid == NULL) || (lenp != sizeof(*bpid))) {
-			dev_err(dpa_oh_dev, "Invalid Buffer pool Id\n");
+		_errno = of_property_read_u32(bpool_node, "fsl,bpid", &bpid);
+		if (_errno) {
+			dev_err(dpa_oh_dev, "Invalid Buffer Pool ID\n");
 			_errno = -EINVAL;
 			goto return_kfree;
 		}
 
-		oh_port_tx_params.pool_param[i].id = *bpid;
-		dev_dbg(dpa_oh_dev, "OH port bpool id = %u\n", *bpid);
+		oh_port_tx_params.pool_param[i].id = (uint8_t)bpid;
+		dev_dbg(dpa_oh_dev, "OH port bpool id = %u\n", bpid);
 
 		bpool_cfg = of_get_property(bpool_node,
 				"fsl,bpool-ethernet-cfg", &lenp);
@@ -726,9 +697,8 @@ config_port:
 			goto return_kfree;
 		}
 
-		of_read_number(bpool_cfg, n_size);
 		ext_pool_size = of_read_number(bpool_cfg + n_size, n_size);
-		oh_port_tx_params.pool_param[i].size = ext_pool_size;
+		oh_port_tx_params.pool_param[i].size = (uint16_t)ext_pool_size;
 		dev_dbg(dpa_oh_dev, "OH port bpool size = %u\n",
 			ext_pool_size);
 		of_node_put(bpool_node);
@@ -741,7 +711,7 @@ config_port:
 
 	frag_enabled = true;
 	dev_info(dpa_oh_dev, "IP Fragmentation enabled for OH port %d",
-		     *port_id);
+			port_id);
 
 init_port:
 	of_node_put(oh_node);
diff --git a/drivers/net/ethernet/freescale/dpa/offline_port.h b/drivers/net/ethernet/freescale/dpa/offline_port.h
index 54b0fe4..432ee88 100644
--- a/drivers/net/ethernet/freescale/dpa/offline_port.h
+++ b/drivers/net/ethernet/freescale/dpa/offline_port.h
@@ -39,7 +39,7 @@ struct qman_fq;
 struct fq_duple {
 	struct qman_fq *fqs;
 	int fqs_count;
-	int channel_id;
+	uint16_t channel_id;
 	struct list_head fq_list;
 };
 
-- 
1.7.5.4

