From fdb7a9e2d434137a22e6fb76062ea16e1cc73ce6 Mon Sep 17 00:00:00 2001
From: Ajay Kumar Gupta <ajay.gupta@ti.com>
Date: Mon, 22 Nov 2010 17:44:10 +0530
Subject: [PATCH 378/609] cppi41: device fix from Ravi

Original commit: 1c352c8ed700886023835b5c3417bf5bb41b9450

  From git://arago-project.org/git/projects/linux-am33x.git
  And ti-sdk-am335x-evm-05.05.00.00-Linux-x86-Install image

Signed-off-by: Ajay Kumar Gupta <ajay.gupta@ti.com>
Signed-off-by: Vaibhav Hiremath <hvaibhav@ti.com>
---
 drivers/usb/musb/cppi41.c     |  124 ++++++++++++++++++++++++++++++++++++++
 drivers/usb/musb/cppi41.h     |   31 ++++++++++
 drivers/usb/musb/cppi41_dma.c |  131 +++++++++++++++++++++++++++-------------
 3 files changed, 243 insertions(+), 43 deletions(-)

diff --git a/drivers/usb/musb/cppi41.c b/drivers/usb/musb/cppi41.c
index 3b2ea3d..7499743 100644
--- a/drivers/usb/musb/cppi41.c
+++ b/drivers/usb/musb/cppi41.c
@@ -59,6 +59,25 @@ static struct {
 	u8 mem_rgn;
 } dma_teardown[CPPI41_NUM_DMA_BLOCK];
 
+struct cppi41_dma_sched_tbl_t {
+	u8      pos;
+	u8      dma_ch;
+	u8      is_tx;
+	u8      enb;
+};
+
+struct cppi41_dma_sched_tbl_t dma_sched_tbl[MAX_SCHED_TBL_ENTRY] = {
+	/*pos  dma_ch#  is_tx  enb/dis*/
+	{ 0,    0,      0,      1},
+	{ 1,    0,      1,      1},
+	{ 2,    1,      0,      1},
+	{ 3,    1,      1,      1},
+	{ 4,    2,      0,      1},
+	{ 5,    2,      1,      1},
+	{ 6,    3,      0,      1},
+	{ 7,    3,      1,      1}
+};
+
 /******************** CPPI 4.1 Functions (External Interface) *****************/
 
 int cppi41_queue_mgr_init(u8 q_mgr, dma_addr_t rgn0_base, u16 rgn0_size)
@@ -106,6 +125,111 @@ int cppi41_queue_mgr_init(u8 q_mgr, dma_addr_t rgn0_base, u16 rgn0_size)
 	return 0;
 }
 
+int cppi41_dma_sched_tbl_init(u8 dma_num, u8 q_mgr,
+			u32 *sched_tbl, u8 tbl_size)
+{
+	struct cppi41_dma_block *dma_block;
+	int num_reg, k, i, val = 0;
+
+	dma_block = &cppi41_dma_block[dma_num];
+
+	num_reg = (tbl_size + 3) / 4;
+	for (k = i = 0; i < num_reg; i++) {
+#if 0
+		for (val = j = 0; j < 4; j++, k++) {
+			val >>= 8;
+			if (k < tbl_size)
+				val |= sched_tbl[k] << 24;
+		}
+#endif
+		val = sched_tbl[i];
+		__raw_writel(val, dma_block->sched_table_base +
+			DMA_SCHED_TABLE_WORD_REG(i));
+		DBG("DMA scheduler table @ %p, value written: %x\n",
+		dma_block->sched_table_base + DMA_SCHED_TABLE_WORD_REG(i),
+			val);
+	}
+
+}
+EXPORT_SYMBOL(cppi41_dma_sched_tbl_init);
+
+int cppi41_schedtbl_add_dma_ch(u8 dmanum, u8 qmgr, u8 dma_ch, u8 is_tx)
+{
+	struct cppi41_dma_block *dma_block;
+	int num_ch, i, tbl_index = 0, j = 0, found = 0;
+	u32 val;
+
+	dma_block = (struct cppi41_dma_block *)&cppi41_dma_block[dmanum];
+
+	val = 0;
+	for (num_ch = 0, i = 0; i < MAX_SCHED_TBL_ENTRY; i++) {
+		if (!found && dma_sched_tbl[i].dma_ch == dma_ch &&
+			dma_sched_tbl[i].is_tx == is_tx &&
+			dma_sched_tbl[i].enb == 0) {
+			dma_sched_tbl[i].enb = 1;
+			found = 1;
+		}
+
+		if (dma_sched_tbl[i].enb) {
+			val |= ((dma_sched_tbl[i].dma_ch |
+				(dma_sched_tbl[i].is_tx ? 0 : (1<<7))) << j*8);
+			num_ch++;
+			j++;
+		}
+		if (num_ch % 4 == 0) {
+			__raw_writel(val, dma_block->sched_table_base +
+				DMA_SCHED_TABLE_WORD_REG(tbl_index));
+			tbl_index++;
+			val = j = 0;
+		}
+	}
+
+	if (num_ch % 4) {
+		__raw_writel(val, dma_block->sched_table_base +
+			DMA_SCHED_TABLE_WORD_REG(tbl_index));
+	}
+	return num_ch;
+}
+EXPORT_SYMBOL(cppi41_schedtbl_add_dma_ch);
+
+int cppi41_schedtbl_remove_dma_ch(u8 dmanum, u8 qmgr, u8 dma_ch, u8 is_tx)
+{
+	struct cppi41_dma_block *dma_block;
+	int num_ch, i, tbl_index = 0, j = 0, found = 0;
+	u32 val;
+
+	dma_block = (struct cppi41_dma_block *)&cppi41_dma_block[dmanum];
+
+	val = 0;
+	for (num_ch = 0, i = 0; i < MAX_SCHED_TBL_ENTRY; i++) {
+		if (!found && dma_sched_tbl[i].dma_ch == dma_ch &&
+			dma_sched_tbl[i].is_tx == is_tx &&
+			dma_sched_tbl[i].enb == 1) {
+			dma_sched_tbl[i].enb = 0;
+		}
+
+		if (dma_sched_tbl[i].enb) {
+			val |= ((dma_sched_tbl[i].dma_ch |
+				(dma_sched_tbl[i].is_tx ? 0 : (1<<7))) << j*8);
+			num_ch++;
+			j++;
+		}
+		if (num_ch % 4 == 0) {
+			__raw_writel(val, dma_block->sched_table_base +
+				DMA_SCHED_TABLE_WORD_REG(tbl_index));
+			tbl_index++;
+			val = j = 0;
+		}
+	}
+
+	if (num_ch % 4) {
+		__raw_writel(val, dma_block->sched_table_base +
+			DMA_SCHED_TABLE_WORD_REG(tbl_index));
+	}
+	return num_ch;
+}
+EXPORT_SYMBOL(cppi41_schedtbl_remove_dma_ch);
+
 int cppi41_dma_block_init(u8 dma_num, u8 q_mgr, u8 num_order,
 				 u32 *sched_tbl, u8 tbl_size)
 {
diff --git a/drivers/usb/musb/cppi41.h b/drivers/usb/musb/cppi41.h
index 8450baa..c19d49b 100644
--- a/drivers/usb/musb/cppi41.h
+++ b/drivers/usb/musb/cppi41.h
@@ -188,6 +188,7 @@
  * DMA Scheduler - Table Region
  */
 #define DMA_SCHED_TABLE_WORD_REG(n)	((n) << 2)
+#define MAX_SCHED_TBL_ENTRY     8
 
 /*
  * CPPI 4.1 Host Packet Descriptor
@@ -715,3 +716,33 @@ int cppi41_get_teardown_info(unsigned long addr, u32 *info);
  * cppi41_exit - delete the instance created via cppi41_init()
  */
 void cppi41_exit(void);
+
+/**
+ * cppi41_dma_sched_tbl_init
+ */
+int cppi41_dma_sched_tbl_init(u8 dma_num, u8 q_mgr,
+				u32 *sched_tbl, u8 tbl_size);
+
+/**
+ * cppi41_schedtbl_add_dma_ch - add a dma channel to schedular table
+ *
+ * @dmanum      Number of DMa block
+ * @qmgr        Queue Manager Number
+ * @dma_ch      dma channel number
+ * @is_tx       transmit (is_tx=1) or recieve(is_tx=0)
+ *
+ * returns      number of channel in schedular table
+ */
+int cppi41_schedtbl_add_dma_ch(u8 dmanum, u8 qmgr, u8 dma_ch, u8 is_tx);
+
+/**
+ * cppi41_schedtbl_remove_dma_ch - remove a dma channel from schedular table
+ *
+ * @dmanum      Number of DMa block
+ * @qmgr        Queue Manager Number
+ * @dma_ch      dma channel number
+ * @is_tx       transmit (is_tx=1) or recieve(is_tx=0)
+ *
+ * returns      number of channel in schedular table
+ */
+int cppi41_schedtbl_remove_dma_ch(u8 dmanum, u8 qmgr, u8 dma_ch, u8 is_tx);
diff --git a/drivers/usb/musb/cppi41_dma.c b/drivers/usb/musb/cppi41_dma.c
index 38e725d..0f0b268 100644
--- a/drivers/usb/musb/cppi41_dma.c
+++ b/drivers/usb/musb/cppi41_dma.c
@@ -61,6 +61,7 @@ struct usb_pkt_desc {
 	struct usb_pkt_desc *next_pd_ptr;
 	u8 ch_num;
 	u8 ep_num;
+	u8 eop;
 };
 
 /**
@@ -695,23 +696,47 @@ static unsigned cppi41_next_rx_segment(struct cppi41_channel *rx_ch)
 	struct cppi41_host_pkt_desc *hw_desc;
 	u32 length = rx_ch->length - rx_ch->curr_offset;
 	u32 pkt_size = rx_ch->pkt_size;
-
-	/*
-	 * Rx can use the generic RNDIS mode where we can probably fit this
-	 * transfer in one PD and one IRQ (or two with a short packet).
-	 */
-	if ((pkt_size & 0x3f) == 0 && length >= 2 * pkt_size) {
-		cppi41_mode_update(rx_ch, USB_GENERIC_RNDIS_MODE);
-		cppi41_autoreq_update(rx_ch, USB_AUTOREQ_ALL_BUT_EOP);
-
-		if (likely(length < 0x10000))
-			pkt_size = length - length % pkt_size;
-		else
-			pkt_size = 0x10000;
-		cppi41_set_ep_size(rx_ch, pkt_size);
+	u32 max_rx_transfer_size = 64 * 1024;
+	u32 i, n_bd , pkt_len;
+	struct usb_gadget_driver *gadget_driver;
+
+	if (is_peripheral_active(cppi->musb)) {
+		/* TODO: temporary fix for CDC/RNDIS which needs to be in
+		 * GENERIC_RNDIS mode. Without this RNDIS gadget taking
+		 * more then 2K ms for a 64 byte pings.
+		 */
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+		gadget_driver = cppi->musb->gadget_driver;
+#endif
+		if (!strcmp(gadget_driver->driver.name, "g_ether")) {
+			cppi41_mode_update(rx_ch, USB_GENERIC_RNDIS_MODE);
+		} else {
+			max_rx_transfer_size = 512;
+			cppi41_mode_update(rx_ch, USB_TRANSPARENT_MODE);
+		}
+		pkt_len = 0;
+		if (rx_ch->length < max_rx_transfer_size)
+			pkt_len = rx_ch->length;
+		cppi41_set_ep_size(rx_ch, pkt_len);
 	} else {
-		cppi41_mode_update(rx_ch, USB_TRANSPARENT_MODE);
-		cppi41_autoreq_update(rx_ch, USB_NO_AUTOREQ);
+		/*
+		 * Rx can use the generic RNDIS mode where we can
+		 * probably fit this transfer in one PD and one IRQ
+		 * (or two with a short packet).
+		 */
+		if ((pkt_size & 0x3f) == 0 && length >= 2 * pkt_size) {
+			cppi41_mode_update(rx_ch, USB_GENERIC_RNDIS_MODE);
+			cppi41_autoreq_update(rx_ch, USB_AUTOREQ_ALL_BUT_EOP);
+
+			if (likely(length < 0x10000))
+				pkt_size = length - length % pkt_size;
+			else
+				pkt_size = 0x10000;
+			cppi41_set_ep_size(rx_ch, pkt_size);
+		} else {
+			cppi41_mode_update(rx_ch, USB_TRANSPARENT_MODE);
+			cppi41_autoreq_update(rx_ch, USB_NO_AUTOREQ);
+		}
 	}
 
 	DBG(4, "RX DMA%u, %s, maxpkt %u, addr %#x, rec'd %u/%u\n",
@@ -719,14 +744,40 @@ static unsigned cppi41_next_rx_segment(struct cppi41_channel *rx_ch)
 	    pkt_size, rx_ch->start_addr + rx_ch->curr_offset,
 	    rx_ch->curr_offset, rx_ch->length);
 
-	/* Get Rx packet descriptor from the free pool */
-	curr_pd = usb_get_free_pd(cppi);
-	if (curr_pd == NULL) {
-		/* Shouldn't ever happen! */
-		DBG(4, "No Rx PDs\n");
-		return 0;
+	/* calculate number of bd required */
+	n_bd = (length + max_rx_transfer_size - 1)/max_rx_transfer_size;
+
+	for (i = 0; i < n_bd ; ++i) {
+		/* Get Rx packet descriptor from the free pool */
+		curr_pd = usb_get_free_pd(cppi);
+		if (curr_pd == NULL) {
+			/* Shouldn't ever happen! */
+			DBG(4, "No Rx PDs\n");
+			goto sched;
+		}
+
+		pkt_len =
+		(length > max_rx_transfer_size) ? max_rx_transfer_size : length;
+
+		hw_desc = &curr_pd->hw_desc;
+		hw_desc->orig_buf_ptr = rx_ch->start_addr + rx_ch->curr_offset;
+		hw_desc->orig_buf_len = pkt_len;
+
+		curr_pd->ch_num = rx_ch->ch_num;
+		curr_pd->ep_num = rx_ch->end_pt->epnum;
+
+		curr_pd->eop = (length -= pkt_len) ? 0 : 1;
+		rx_ch->curr_offset += pkt_len;
+
+		/*
+		 * Push the free Rx packet descriptor
+		 * to the free descriptor/buffer queue.
+		 */
+		cppi41_queue_push(&rx_ch->queue_obj, curr_pd->dma_addr,
+			USB_CPPI41_DESC_ALIGN, 0);
 	}
 
+sched:
 	/*
 	 * HCD arranged ReqPkt for the first packet.
 	 * We arrange it for all but the last one.
@@ -739,25 +790,9 @@ static unsigned cppi41_next_rx_segment(struct cppi41_channel *rx_ch)
 		musb_writew(epio, MUSB_RXCSR, csr);
 	}
 
-	if (length < pkt_size)
-		pkt_size = length;
-
-	hw_desc = &curr_pd->hw_desc;
-	hw_desc->orig_buf_ptr = rx_ch->start_addr + rx_ch->curr_offset;
-	hw_desc->orig_buf_len = pkt_size;
-
-	curr_pd->ch_num = rx_ch->ch_num;
-	curr_pd->ep_num = rx_ch->end_pt->epnum;
-
-	rx_ch->curr_offset += pkt_size;
-
-	/*
-	 * Push the free Rx packet descriptor
-	 * to the free descriptor/buffer queue.
-	 */
-	cppi41_queue_push(&rx_ch->queue_obj, curr_pd->dma_addr,
-		USB_CPPI41_DESC_ALIGN, 0);
-
+	/* enable schedular if not enabled */
+	if (is_peripheral_active(cppi->musb) && (n_bd > 0))
+		cppi41_schedtbl_add_dma_ch(0, 0, rx_ch->ch_num, 0);
 	return 1;
 }
 
@@ -1210,6 +1245,13 @@ static void usb_process_rx_queue(struct cppi41 *cppi, unsigned index)
 		rx_ch = &cppi->rx_cppi_ch[ch_num];
 		rx_ch->channel.actual_len += length;
 
+		if (curr_pd->eop) {
+			curr_pd->eop = 0;
+			/* disable the rx dma schedular */
+			if (is_peripheral_active(cppi->musb))
+				cppi41_schedtbl_remove_dma_ch(0, 0, ch_num, 0);
+		}
+
 		/*
 		 * Return Rx PD to the software list --
 		 * this is protected by critical section
@@ -1222,8 +1264,11 @@ static void usb_process_rx_queue(struct cppi41 *cppi, unsigned index)
 
 			/* Rx completion routine callback */
 			musb_dma_completion(cppi->musb, ep_num, 0);
-		} else
-			cppi41_next_rx_segment(rx_ch);
+		} else {
+			if (is_peripheral_active(cppi->musb) &&
+				((rx_ch->length - rx_ch->curr_offset) > 0))
+				cppi41_next_rx_segment(rx_ch);
+		}
 	}
 }
 
-- 
1.7.5.4

