From 020eb9f3bcacf54d279643c2668488300afa9983 Mon Sep 17 00:00:00 2001
From: "Edgar E. Iglesias" <edgar.iglesias@xilinx.com>
Date: Fri, 9 Oct 2015 16:00:55 -0500
Subject: [PATCH 596/800] virtio_ring: revise descriptor addition logic for
 virtio_rpmsg

The virtio core expects the vring buffers to be allocated from
linear address space in general, but this may not be true always
with virtio_rpmsg. The virtio_rpmsg bus allocates the vring buffers
using the dma_alloc_coherent() API, and this API can return virtual
addresses from the vmalloc range if the underlying memory is allocated
from a carveout (physical contiguous memory not mapped into kernel) or
a CMA pool in highmem. For more details, please see the discussion
thread, http://marc.info/?l=linux-arm-kernel&m=142738673019657&w=2.

This patch adds a 'rpmsg' flag to the internal virtqueue_add function
and leverages this flag to revise the descriptor preparation when
adding the buffers. The revised logic uses the sg_dma_address() and
sg_dma_len() helpers instead of relying on sg_phys() and sg->length
fields, so that the remote side sees the physical addresses of the
vring buffers properly. The virtio rpmsg core is expected to prepare
the scatterlist structures with the dma fields filled in properly, and
use a new API (will be added in following patch) to add the virtqueue
buffers.

Signed-off-by: Edgar E. Iglesias <edgar.iglesias@xilinx.com>
[s-anna@ti.com: rename dma variable to use rpmsg, add commit description]
Signed-off-by: Suman Anna <s-anna@ti.com>
[zou: Original patch taken from PROCESSOR-SDK-LINUX-AM335X 02_00_01_07]
Signed-off-by: zou cao <cao.zou@windriver.com>
---
 drivers/virtio/virtio_ring.c |   25 +++++++++++++++----------
 1 files changed, 15 insertions(+), 10 deletions(-)

diff --git a/drivers/virtio/virtio_ring.c b/drivers/virtio/virtio_ring.c
index d2eb095..9083f48 100644
--- a/drivers/virtio/virtio_ring.c
+++ b/drivers/virtio/virtio_ring.c
@@ -123,11 +123,13 @@ static struct vring_desc *alloc_indirect(struct virtqueue *_vq,
 static inline void vring_desc_set(struct virtio_device *vdev,
 				  struct vring_desc *desc,
 				  struct scatterlist *sg,
-				  u16 flags)
+				  u16 flags,
+				  bool rpmsg)
 {
 	desc->flags = cpu_to_virtio16(vdev, flags);
-	desc->addr = cpu_to_virtio64(vdev, sg_phys(sg));
-	desc->len = cpu_to_virtio32(vdev, sg->length);
+	desc->addr = cpu_to_virtio64(vdev,
+				     rpmsg ? sg_dma_address(sg) : sg_phys(sg));
+	desc->len = cpu_to_virtio32(vdev, rpmsg ? sg_dma_len(sg) : sg->length);
 }
 
 static inline int virtqueue_add(struct virtqueue *_vq,
@@ -136,7 +138,8 @@ static inline int virtqueue_add(struct virtqueue *_vq,
 				unsigned int out_sgs,
 				unsigned int in_sgs,
 				void *data,
-				gfp_t gfp)
+				gfp_t gfp,
+				bool rpmsg)
 {
 	struct vring_virtqueue *vq = to_vvq(_vq);
 	struct scatterlist *sg;
@@ -174,7 +177,7 @@ static inline int virtqueue_add(struct virtqueue *_vq,
 
 	/* If the host supports indirect descriptor tables, and we have multiple
 	 * buffers, then go indirect. FIXME: tune this threshold */
-	if (vq->indirect && total_sg > 1 && vq->vq.num_free)
+	if (!rpmsg && vq->indirect && total_sg > 1 && vq->vq.num_free)
 		desc = alloc_indirect(_vq, total_sg, gfp);
 	else
 		desc = NULL;
@@ -216,7 +219,7 @@ static inline int virtqueue_add(struct virtqueue *_vq,
 	for (n = 0; n < out_sgs; n++) {
 		for (sg = sgs[n]; sg; sg = sg_next(sg)) {
 			vring_desc_set(_vq->vdev, desc + i, sg,
-				       VRING_DESC_F_NEXT);
+				       VRING_DESC_F_NEXT, rpmsg);
 			prev = i;
 			i = virtio16_to_cpu(_vq->vdev, desc[i].next);
 		}
@@ -224,7 +227,8 @@ static inline int virtqueue_add(struct virtqueue *_vq,
 	for (; n < (out_sgs + in_sgs); n++) {
 		for (sg = sgs[n]; sg; sg = sg_next(sg)) {
 			vring_desc_set(_vq->vdev, desc + i, sg,
-				       VRING_DESC_F_NEXT | VRING_DESC_F_WRITE);
+				       VRING_DESC_F_NEXT | VRING_DESC_F_WRITE,
+				       rpmsg);
 			prev = i;
 			i = virtio16_to_cpu(_vq->vdev, desc[i].next);
 		}
@@ -292,7 +296,8 @@ int virtqueue_add_sgs(struct virtqueue *_vq,
 		for (sg = sgs[i]; sg; sg = sg_next(sg))
 			total_sg++;
 	}
-	return virtqueue_add(_vq, sgs, total_sg, out_sgs, in_sgs, data, gfp);
+	return virtqueue_add(_vq, sgs, total_sg, out_sgs, in_sgs, data, gfp,
+			     false);
 }
 EXPORT_SYMBOL_GPL(virtqueue_add_sgs);
 
@@ -314,7 +319,7 @@ int virtqueue_add_outbuf(struct virtqueue *vq,
 			 void *data,
 			 gfp_t gfp)
 {
-	return virtqueue_add(vq, &sg, num, 1, 0, data, gfp);
+	return virtqueue_add(vq, &sg, num, 1, 0, data, gfp, false);
 }
 EXPORT_SYMBOL_GPL(virtqueue_add_outbuf);
 
@@ -336,7 +341,7 @@ int virtqueue_add_inbuf(struct virtqueue *vq,
 			void *data,
 			gfp_t gfp)
 {
-	return virtqueue_add(vq, &sg, num, 0, 1, data, gfp);
+	return virtqueue_add(vq, &sg, num, 0, 1, data, gfp, false);
 }
 EXPORT_SYMBOL_GPL(virtqueue_add_inbuf);
 
-- 
1.7.5.4

