From 9be382eb6164b1cd1303e7b4a5f396aea4ec18e0 Mon Sep 17 00:00:00 2001
From: Peter Ujfalusi <peter.ujfalusi@ti.com>
Date: Fri, 7 Aug 2015 14:31:27 +0300
Subject: [PATCH 427/800] dmaengine: omap-dma: Support for polled memcpy
 transfers

When copying small chunks of data the client driver can decide to not use
callbacks and completion (or other means of handling the end of transfer),
but to simply poll the status of the transfer.
This is indicated by the missing DMA_PREP_INTERRUPT flag - so that the
client has no interest in the interrupt.
In such a case the driver will start the transfer without delay and in the
omap_dma_tx_status() callback we will check if the channel is still enabled
or not, if not enabled, DMA_COMPLETED status is returned.

Signed-off-by: Peter Ujfalusi <peter.ujfalusi@ti.com>
Tested-by: Tomi Valkeinen <tomi.valkeinen@ti.com>
Signed-off-by: Jyri Sarha <jsarha@ti.com>
[zou: Original patch taken from PROCESSOR-SDK-LINUX-AM335X 02_00_01_07]
Signed-off-by: zou cao <cao.zou@windriver.com>
---
 drivers/dma/omap-dma.c |   17 ++++++++++++++---
 1 files changed, 14 insertions(+), 3 deletions(-)

diff --git a/drivers/dma/omap-dma.c b/drivers/dma/omap-dma.c
index 8ed39ce2..5388870 100644
--- a/drivers/dma/omap-dma.c
+++ b/drivers/dma/omap-dma.c
@@ -50,6 +50,7 @@ struct omap_chan {
 	struct dma_slave_config	cfg;
 	unsigned dma_sig;
 	bool cyclic;
+	bool start_no_delay;
 	bool paused;
 
 	int dma_ch;
@@ -709,6 +710,12 @@ static enum dma_status omap_dma_tx_status(struct dma_chan *chan,
 	if (ret == DMA_COMPLETE || !txstate)
 		return ret;
 
+	if (c->start_no_delay) {
+		uint32_t val = omap_dma_chan_read(c, CCR);
+		if (!(val & CCR_ENABLE))
+			return DMA_COMPLETE;
+	}
+
 	spin_lock_irqsave(&c->vc.lock, flags);
 	vd = vchan_find_desc(&c->vc, cookie);
 	if (vd) {
@@ -744,15 +751,15 @@ static void omap_dma_issue_pending(struct dma_chan *chan)
 		 * c->cyclic is used only by audio and in this case the DMA need
 		 * to be started without delay.
 		 */
-		if (!c->cyclic) {
+		if (c->cyclic || c->start_no_delay) {
+			omap_dma_start_desc(c);
+		} else {
 			struct omap_dmadev *d = to_omap_dma_dev(chan->device);
 			spin_lock(&d->lock);
 			if (list_empty(&c->node))
 				list_add_tail(&c->node, &d->pending);
 			spin_unlock(&d->lock);
 			tasklet_schedule(&d->task);
-		} else {
-			omap_dma_start_desc(c);
 		}
 	}
 	spin_unlock_irqrestore(&c->vc.lock, flags);
@@ -987,6 +994,8 @@ static struct dma_async_tx_descriptor *omap_dma_prep_dma_memcpy(
 	d->cicr = CICR_DROP_IE;
 	if (tx_flags & DMA_PREP_INTERRUPT)
 		d->cicr |= CICR_FRAME_IE;
+	else
+		c->start_no_delay = true;
 
 	d->csdp = data_type;
 
@@ -1047,6 +1056,8 @@ static int omap_dma_terminate_all(struct dma_chan *chan)
 		c->paused = false;
 	}
 
+	c->start_no_delay = false;
+
 	vchan_get_all_descriptors(&c->vc, &head);
 	spin_unlock_irqrestore(&c->vc.lock, flags);
 	vchan_dma_desc_free_list(&c->vc, &head);
-- 
1.7.5.4

