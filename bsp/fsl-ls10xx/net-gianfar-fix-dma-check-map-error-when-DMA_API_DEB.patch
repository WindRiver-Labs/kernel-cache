From a3cf7ae0fc459bfda393a957192e8fa8c48db9d0 Mon Sep 17 00:00:00 2001
From: Kevin Hao <kexin.hao@windriver.com>
Date: Wed, 29 Oct 2014 17:00:45 +0800
Subject: [PATCH] net: gianfar: fix dma check map error when DMA_API_DEBUG is
 enabled

We need to use dma_mapping_error() to check the dma address returned
by dma_map_single/page(). Otherwise we would get warning like this:
WARNING: CPU: 1 PID: 128 at lib/dma-debug)
fsl-gianfar ethernet.4: DMA-API: device driver failed to check map error[device address=0x00000000bdb00080] [size=1536 bytes] [mapped as single]
Modules linked in:

CPU: 1 PID: 128 Comm: irq/177-eth0_g0 Not tainted 3.14.22-rt9-WR7.0.0.0_preempt-rt #18
[<80018f94>] (unwind_backtrace) from [<800136bc>] (show_stack+0x20/0x24)
[<800136bc>] (show_stack) from [<806cdd94>] (dump_stack+0x84/0xd0)
[<806cdd94>] (dump_stack) from [<80028b00>] (warn_slowpath_common+0x84/0xa0)
[<80028b00>] (warn_slowpath_common) from [<80028b5c>] (warn_slowpath_fmt+0x40/0x48)
[<80028b5c>] (warn_slowpath_fmt) from [<803ba80c>] (check_unmap+0x5f0/0xb48)
[<803ba80c>] (check_unmap) from [<803badd4>] (debug_dma_unmap_page+0x70/0x78)
[<803badd4>] (debug_dma_unmap_page) from [<80488b50>] (gfar_clean_rx_ring+0x120/0x62c)
[<80488b50>] (gfar_clean_rx_ring) from [<804892ec>] (gfar_poll_rx_sq+0x58/0xe8)
[<804892ec>] (gfar_poll_rx_sq) from [<805b7a5c>] (net_rx_action+0x1c4/0x30c)
[<805b7a5c>] (net_rx_action) from [<8002e49c>] (do_current_softirqs+0x1d4/0x390)
[<8002e49c>] (do_current_softirqs) from [<8002e6d4>] (__local_bh_enable+0x7c/0x94)
[<8002e6d4>] (__local_bh_enable) from [<8002e704>] (local_bh_enable+0x18/0x1c)
[<8002e704>] (local_bh_enable) from [<8007cdb0>] (irq_forced_thread_fn+0x50/0x74)
[<8007cdb0>] (irq_forced_thread_fn) from [<8007d0bc>] (irq_thread+0x158/0x1c4)
[<8007d0bc>] (irq_thread) from [<8004c3ac>] (kthread+0xcc/0xe4)
[<8004c3ac>] (kthread) from [<8000ee38>] (ret_from_fork+0x14/0x20)

For TX, we need to unmap the pages which has already been mapped and
free the skb before return. For RX, just let the rxbdp as unempty.
We can retry to initialize it to empty in next round.

Signed-off-by: Kevin Hao <kexin.hao@windriver.com>

diff --git a/drivers/net/ethernet/freescale/gianfar.c b/drivers/net/ethernet/freescale/gianfar.c
index 150f921f9fd5..fadfa2ac2c78 100644
--- a/drivers/net/ethernet/freescale/gianfar.c
+++ b/drivers/net/ethernet/freescale/gianfar.c
@@ -117,7 +117,7 @@ static void gfar_reset_task(struct work_struct *work);
 static void gfar_timeout(struct net_device *dev);
 static int gfar_close(struct net_device *dev);
 struct sk_buff *gfar_new_skb(struct net_device *dev);
-static void gfar_new_rxbdp(struct gfar_priv_rx_q *rx_queue, struct rxbd8 *bdp,
+static int gfar_new_rxbdp(struct gfar_priv_rx_q *rx_queue, struct rxbd8 *bdp,
 			   struct sk_buff *skb);
 static int gfar_set_mac_address(struct net_device *dev);
 static int gfar_change_mtu(struct net_device *dev, int new_mtu);
@@ -220,9 +220,13 @@ static int gfar_init_bds(struct net_device *ndev)
 					netdev_err(ndev, "Can't allocate RX buffers\n");
 					return -ENOMEM;
 				}
-				rx_queue->rx_skbuff[j] = skb;
 
-				gfar_new_rxbdp(rx_queue, rxbdp, skb);
+				if (gfar_new_rxbdp(rx_queue, rxbdp, skb)) {
+					dev_kfree_skb(skb);
+					skb = NULL;
+				}
+
+				rx_queue->rx_skbuff[j] = skb;
 			}
 
 			rxbdp++;
@@ -2308,6 +2312,8 @@ static int gfar_start_xmit(struct sk_buff *skb, struct net_device *dev)
 						   0,
 						   frag_len,
 						   DMA_TO_DEVICE);
+			if (unlikely(dma_mapping_error(priv->dev, bufaddr)))
+				goto dma_map_err;
 
 			/* set the TxBD length and buffer pointer */
 			txbdp->bufPtr = cpu_to_be32(bufaddr);
@@ -2359,6 +2365,9 @@ static int gfar_start_xmit(struct sk_buff *skb, struct net_device *dev)
 
 	bufaddr = dma_map_single(priv->dev, skb->data,
 				 skb_headlen(skb), DMA_TO_DEVICE);
+	if (unlikely(dma_mapping_error(priv->dev, bufaddr)))
+		goto dma_map_err;
+
 	txbdp_start->bufPtr = cpu_to_be32(bufaddr);
 
 	/* If time stamping is requested one additional TxBD must be set up. The
@@ -2429,6 +2438,25 @@ static int gfar_start_xmit(struct sk_buff *skb, struct net_device *dev)
 	spin_unlock_irqrestore(&tx_queue->txlock, flags);
 
 	return NETDEV_TX_OK;
+
+dma_map_err:
+	txbdp = next_txbd(txbdp_start, base, tx_queue->tx_ring_size);
+	if (do_tstamp)
+		txbdp = next_txbd(txbdp, base, tx_queue->tx_ring_size);
+	for (i = 0; i < nr_frags; i++) {
+		lstatus = be32_to_cpu(txbdp->lstatus);
+		if (!(lstatus & BD_LFLAG(TXBD_READY)))
+			break;
+
+		txbdp->lstatus = cpu_to_be32(lstatus & ~BD_LFLAG(TXBD_READY));
+		bufaddr = be32_to_cpu(txbdp->bufPtr);
+		dma_unmap_page(priv->dev, bufaddr, be16_to_cpu(txbdp->length),
+				DMA_TO_DEVICE);
+		txbdp = next_txbd(txbdp, base, tx_queue->tx_ring_size);
+	}
+	gfar_wmb();
+	kfree_skb(skb);
+	return NETDEV_TX_OK;
 }
 
 /* Stops the kernel queue, and halts the controller */
@@ -2627,7 +2655,7 @@ static void gfar_clean_tx_ring(struct gfar_priv_tx_q *tx_queue)
 	tx_queue->dirty_tx = bdp;
 }
 
-static void gfar_new_rxbdp(struct gfar_priv_rx_q *rx_queue, struct rxbd8 *bdp,
+static int gfar_new_rxbdp(struct gfar_priv_rx_q *rx_queue, struct rxbd8 *bdp,
 			   struct sk_buff *skb)
 {
 	struct net_device *dev = rx_queue->dev;
@@ -2636,7 +2664,11 @@ static void gfar_new_rxbdp(struct gfar_priv_rx_q *rx_queue, struct rxbd8 *bdp,
 
 	buf = dma_map_single(priv->dev, skb->data,
 			     priv->rx_buffer_size, DMA_FROM_DEVICE);
+	if (dma_mapping_error(priv->dev, buf))
+		return -1;
+
 	gfar_init_rxbdp(rx_queue, bdp, buf);
+	return 0;
 }
 
 static struct sk_buff *gfar_alloc_skb(struct net_device *dev)
@@ -2877,10 +2909,13 @@ int gfar_clean_rx_ring(struct gfar_priv_rx_q *rx_queue, int rx_work_limit)
 
 		}
 
-		rx_queue->rx_skbuff[rx_queue->skb_currx] = newskb;
-
 		/* Setup the new bdp */
-		gfar_new_rxbdp(rx_queue, bdp, newskb);
+		if (gfar_new_rxbdp(rx_queue, bdp, newskb)) {
+			dev_kfree_skb(newskb);
+			newskb = NULL;
+		}
+
+		rx_queue->rx_skbuff[rx_queue->skb_currx] = newskb;
 
 		/* Update to the next pointer */
 		bdp = next_bd(bdp, base, rx_queue->rx_ring_size);
-- 
1.9.1

