From e88bf02808251901e31202e1058b124e7fa0bcb7 Mon Sep 17 00:00:00 2001
From: Rik van Riel <riel@redhat.com>
Date: Mon, 9 Aug 2010 17:18:37 -0700
Subject: [PATCH 438/479] cgl mm: rename anon_vma_lock to vma_lock_anon_vma

commit bb4a340e075b7897ece109686bfa177f8518d2db upstream

Rename anon_vma_lock to vma_lock_anon_vma.  This matches the naming style
used in page_lock_anon_vma and will come in really handy further down in
this patch series.

Signed-off-by: Rik van Riel <riel@redhat.com>
Acked-by: Mel Gorman <mel@csn.ul.ie>
Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Tested-by: Larry Woodman <lwoodman@redhat.com>
Acked-by: Larry Woodman <lwoodman@redhat.com>
Reviewed-by: Minchan Kim <minchan.kim@gmail.com>
Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
[context adjustment]
Integrated-by: Weiwei Wang <weiwei.wang@windriver.com>
---
 include/linux/rmap.h |    4 ++--
 mm/mmap.c            |   20 ++++++++++----------
 2 files changed, 12 insertions(+), 12 deletions(-)

diff --git a/include/linux/rmap.h b/include/linux/rmap.h
index 3ee3885..369bdb4 100644
--- a/include/linux/rmap.h
+++ b/include/linux/rmap.h
@@ -115,14 +115,14 @@ static inline struct anon_vma *page_anon_vma(struct page *page)
 	return page_rmapping(page);
 }
 
-static inline void anon_vma_lock(struct vm_area_struct *vma)
+static inline void vma_lock_anon_vma(struct vm_area_struct *vma)
 {
 	struct anon_vma *anon_vma = vma->anon_vma;
 	if (anon_vma)
 		spin_lock(&anon_vma->root->lock);
 }
 
-static inline void anon_vma_unlock(struct vm_area_struct *vma)
+static inline void vma_unlock_anon_vma(struct vm_area_struct *vma)
 {
 	struct anon_vma *anon_vma = vma->anon_vma;
 	if (anon_vma)
diff --git a/mm/mmap.c b/mm/mmap.c
index bbdbf42..d422ecc 100644
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@ -490,12 +490,12 @@ static void vma_link(struct mm_struct *mm, struct vm_area_struct *vma,
 		spin_lock(&mapping->i_mmap_lock);
 		vma->vm_truncate_count = mapping->truncate_count;
 	}
-	anon_vma_lock(vma);
+	vma_lock_anon_vma(vma);
 
 	__vma_link(mm, vma, prev, rb_link, rb_parent);
 	__vma_link_file(vma);
 
-	anon_vma_unlock(vma);
+	vma_unlock_anon_vma(vma);
 	if (mapping)
 		spin_unlock(&mapping->i_mmap_lock);
 
@@ -1952,9 +1952,9 @@ int expand_upwards(struct vm_area_struct *vma, unsigned long address)
 	locknext = vma->vm_next && (vma->vm_next->vm_flags & VM_GROWSDOWN);
 	if (locknext && unlikely(anon_vma_prepare(vma->vm_next)))
 		return -ENOMEM;
-	anon_vma_lock(vma);
+	vma_lock_anon_vma(vma);
 	if (locknext)
-		anon_vma_lock(vma->vm_next);
+		vma_lock_anon_vma(vma->vm_next);
 
 	/*
 	 * vma->vm_start/vm_end cannot change under us because the caller
@@ -1976,8 +1976,8 @@ int expand_upwards(struct vm_area_struct *vma, unsigned long address)
 			vma->vm_end = address;
 	}
 	if (locknext)
-		anon_vma_unlock(vma->vm_next);
-	anon_vma_unlock(vma);
+		vma_unlock_anon_vma(vma->vm_next);
+	vma_unlock_anon_vma(vma);
 	return error;
 }
 #endif /* CONFIG_STACK_GROWSUP || CONFIG_IA64 */
@@ -2010,9 +2010,9 @@ static int expand_downwards(struct vm_area_struct *vma,
 	if (lockprev && unlikely(anon_vma_prepare(prev)))
 		return -ENOMEM;
 	if (lockprev)
-		anon_vma_lock(prev);
+		vma_lock_anon_vma(prev);
 
-	anon_vma_lock(vma);
+	vma_lock_anon_vma(vma);
 
 	/*
 	 * vma->vm_start/vm_end cannot change under us because the caller
@@ -2048,9 +2048,9 @@ static int expand_downwards(struct vm_area_struct *vma,
 
 		}
 	}
-	anon_vma_unlock(vma);
+	vma_unlock_anon_vma(vma);
 	if (lockprev)
-		anon_vma_unlock(prev);
+		vma_unlock_anon_vma(prev);
 	return error;
 }
 
-- 
1.7.0

