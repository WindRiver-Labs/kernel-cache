From a29e8a79ade2e0c6dd639f2abc3e09dab0ff98d1 Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Wed, 19 Oct 2011 18:52:28 +0800
Subject: [PATCH 191/479] igb: update to 3.1.16

Source: Intel DH89XX SDK 0.6.0-95

Integrated-by: Jack Tan <jack.tan@windriver.com>
---
 drivers/net/igb/e1000_82575.c   |  820 ++++++++++++++++++++++++--
 drivers/net/igb/e1000_82575.h   |   22 +-
 drivers/net/igb/e1000_api.c     |    1 +
 drivers/net/igb/e1000_defines.h |  144 +++++-
 drivers/net/igb/e1000_hw.h      |   37 +-
 drivers/net/igb/e1000_mac.c     |   13 +
 drivers/net/igb/e1000_mac.h     |    3 +-
 drivers/net/igb/e1000_manage.c  |   87 +++-
 drivers/net/igb/e1000_manage.h  |    2 +
 drivers/net/igb/e1000_mbx.c     |    8 +-
 drivers/net/igb/e1000_mbx.h     |    1 +
 drivers/net/igb/e1000_nvm.c     |   69 +++-
 drivers/net/igb/e1000_nvm.h     |    3 +-
 drivers/net/igb/e1000_osdep.h   |    2 +-
 drivers/net/igb/e1000_phy.c     |  574 ++++++++++++++++++--
 drivers/net/igb/e1000_phy.h     |   45 ++-
 drivers/net/igb/e1000_regs.h    |   39 ++-
 drivers/net/igb/igb.h           |  130 ++++-
 drivers/net/igb/igb_ethtool.c   |  100 +++-
 drivers/net/igb/igb_main.c      | 1199 +++++++++++++++++++++++++++++++--------
 drivers/net/igb/igb_param.c     |  191 ++++++-
 drivers/net/igb/igb_vmdq.c      |  437 ++++++++++++++
 drivers/net/igb/igb_vmdq.h      |   46 ++
 drivers/net/igb/kcompat.c       |   72 ++-
 drivers/net/igb/kcompat.h       |  252 ++++++++-
 25 files changed, 3842 insertions(+), 455 deletions(-)
 create mode 100644 drivers/net/igb/igb_vmdq.c
 create mode 100644 drivers/net/igb/igb_vmdq.h

diff --git a/drivers/net/igb/e1000_82575.c b/drivers/net/igb/e1000_82575.c
index b2aec98..5494d7b 100644
--- a/drivers/net/igb/e1000_82575.c
+++ b/drivers/net/igb/e1000_82575.c
@@ -36,7 +36,6 @@
 #include "e1000_api.h"
 
 static s32  e1000_init_phy_params_82575(struct e1000_hw *hw);
-static s32  e1000_init_nvm_params_82575(struct e1000_hw *hw);
 static s32  e1000_init_mac_params_82575(struct e1000_hw *hw);
 static s32  e1000_acquire_phy_82575(struct e1000_hw *hw);
 static void e1000_release_phy_82575(struct e1000_hw *hw);
@@ -52,14 +51,20 @@ static s32  e1000_read_phy_reg_sgmii_82575(struct e1000_hw *hw, u32 offset,
                                            u16 *data);
 static s32  e1000_reset_hw_82575(struct e1000_hw *hw);
 static s32  e1000_reset_hw_82580(struct e1000_hw *hw);
-static s32 e1000_read_phy_reg_82580(struct e1000_hw *hw,
+static s32  e1000_read_phy_reg_82580(struct e1000_hw *hw,
                                     u32 offset, u16 *data);
-static s32 e1000_write_phy_reg_82580(struct e1000_hw *hw,
+static s32  e1000_write_phy_reg_82580(struct e1000_hw *hw,
                                      u32 offset, u16 data);
+static s32  e1000_set_d0_lplu_state_82580(struct e1000_hw *hw,
+                                          bool active);
+static s32  e1000_set_d3_lplu_state_82580(struct e1000_hw *hw,
+                                          bool active);
 static s32  e1000_set_d0_lplu_state_82575(struct e1000_hw *hw,
                                           bool active);
 static s32  e1000_setup_copper_link_82575(struct e1000_hw *hw);
 static s32  e1000_setup_serdes_link_82575(struct e1000_hw *hw);
+static s32  e1000_get_media_type_82575(struct e1000_hw *hw);
+static s32  e1000_set_sfp_media_type_82575(struct e1000_hw *hw);
 static s32  e1000_valid_led_default_82575(struct e1000_hw *hw, u16 *data);
 static s32  e1000_write_phy_reg_sgmii_82575(struct e1000_hw *hw,
                                             u32 offset, u16 data);
@@ -78,6 +83,14 @@ static void e1000_shutdown_serdes_link_82575(struct e1000_hw *hw);
 static void e1000_power_up_serdes_link_82575(struct e1000_hw *hw);
 static s32 e1000_set_pcie_completion_timeout(struct e1000_hw *hw);
 static s32 e1000_reset_mdicnfg_82580(struct e1000_hw *hw);
+static s32 e1000_validate_nvm_checksum_82580(struct e1000_hw *hw);
+static s32 e1000_update_nvm_checksum_82580(struct e1000_hw *hw);
+static s32 e1000_update_nvm_checksum_with_offset(struct e1000_hw *hw,
+						u16 offset);
+static s32 e1000_validate_nvm_checksum_with_offset(struct e1000_hw *hw,
+						u16 offset);
+static s32 e1000_validate_nvm_checksum_i350(struct e1000_hw *hw);
+static s32 e1000_update_nvm_checksum_i350(struct e1000_hw *hw);
 
 static const u16 e1000_82580_rxpbs_table[] =
 	{ 36, 72, 144, 1, 2, 4, 8, 16,
@@ -177,11 +190,17 @@ static s32 e1000_init_phy_params_82575(struct e1000_hw *hw)
 	switch (phy->id) {
 	case I347AT4_E_PHY_ID:
 	case M88E1112_E_PHY_ID:
+ 	case M88E1340M_E_PHY_ID:
 	case M88E1111_I_PHY_ID:
 		phy->type                   = e1000_phy_m88;
 		phy->ops.check_polarity     = e1000_igb_check_polarity_m88;
 		phy->ops.get_info           = e1000_get_phy_info_m88;
-		phy->ops.get_cable_length   = e1000_get_cable_length_m88;
+ 		if (phy->id == I347AT4_E_PHY_ID ||
+ 		    phy->id == M88E1112_E_PHY_ID ||
+ 		    phy->id == M88E1340M_E_PHY_ID)
+ 			phy->ops.get_cable_length = e1000_get_cable_length_m88_gen2;
+ 		else
+ 			phy->ops.get_cable_length = e1000_get_cable_length_m88;
 		phy->ops.force_speed_duplex = e1000_phy_force_speed_duplex_m88;
 		break;
 	case IGP03E1000_E_PHY_ID:
@@ -190,7 +209,7 @@ static s32 e1000_init_phy_params_82575(struct e1000_hw *hw)
 		phy->ops.check_polarity     = e1000_igb_check_polarity_igp;
 		phy->ops.get_info           = e1000_get_phy_info_igp;
 		phy->ops.get_cable_length   = e1000_get_cable_length_igp_2;
-		phy->ops.force_speed_duplex = e1000_phy_force_speed_duplex_igp;
+		phy->ops.force_speed_duplex = e1000_igb_phy_force_speed_duplex_igp;
 		phy->ops.set_d0_lplu_state  = e1000_set_d0_lplu_state_82575;
 		phy->ops.set_d3_lplu_state  = e1000_set_d3_lplu_state_generic;
 		break;
@@ -201,6 +220,8 @@ static s32 e1000_init_phy_params_82575(struct e1000_hw *hw)
 		phy->ops.force_speed_duplex = e1000_igb_phy_force_speed_duplex_82577;
 		phy->ops.get_cable_length   = e1000_igb_get_cable_length_82577;
 		phy->ops.get_info           = e1000_igb_get_phy_info_82577;
+ 		phy->ops.set_d0_lplu_state  = e1000_set_d0_lplu_state_82580;
+ 		phy->ops.set_d3_lplu_state  = e1000_set_d3_lplu_state_82580;
 		break;
 	default:
 		ret_val = -E1000_ERR_PHY;
@@ -215,7 +236,7 @@ out:
  *  e1000_init_nvm_params_82575 - Init NVM func ptrs.
  *  @hw: pointer to the HW structure
  **/
-static s32 e1000_init_nvm_params_82575(struct e1000_hw *hw)
+s32 e1000_init_nvm_params_82575(struct e1000_hw *hw)
 {
 	struct e1000_nvm_info *nvm = &hw->nvm;
 	u32 eecd = E1000_READ_REG(hw, E1000_EECD);
@@ -223,6 +244,15 @@ static s32 e1000_init_nvm_params_82575(struct e1000_hw *hw)
 
 	DEBUGFUNC("e1000_init_nvm_params_82575");
 
+	size = (u16)((eecd & E1000_EECD_SIZE_EX_MASK) >>
+	             E1000_EECD_SIZE_EX_SHIFT);
+	/*
+	 * Added to a constant, "size" becomes the left-shift value
+	 * for setting word_size.
+	 */
+	size += NVM_WORD_SIZE_BASE_SHIFT;
+
+	nvm->word_size = 1 << size;
 	nvm->opcode_bits        = 8;
 	nvm->delay_usec         = 1;
 	switch (nvm->override) {
@@ -240,30 +270,37 @@ static s32 e1000_init_nvm_params_82575(struct e1000_hw *hw)
 		break;
 	}
 
-	nvm->type              = e1000_nvm_eeprom_spi;
+	nvm->type = e1000_nvm_eeprom_spi;
 
-	size = (u16)((eecd & E1000_EECD_SIZE_EX_MASK) >>
-	                  E1000_EECD_SIZE_EX_SHIFT);
+	if (nvm->word_size == (1 << 15))
+		nvm->page_size = 128;
 
-	/*
-	 * Added to a constant, "size" becomes the left-shift value
-	 * for setting word_size.
-	 */
-	size += NVM_WORD_SIZE_BASE_SHIFT;
+	/* Function Pointers */
+	nvm->ops.acquire    = e1000_acquire_nvm_82575;
+	nvm->ops.release    = e1000_release_nvm_82575;
+	if (nvm->word_size < (1 << 15))
+		nvm->ops.read    = e1000_read_nvm_eerd;
+	else
+		nvm->ops.read    = e1000_read_nvm_spi;
 
-	/* EEPROM access above 16k is unsupported */
-	if (size > 14)
-		size = 14;
-	nvm->word_size = 1 << size;
+	nvm->ops.write              = e1000_write_nvm_spi;
+	nvm->ops.validate           = e1000_validate_nvm_checksum_generic;
+	nvm->ops.update             = e1000_update_nvm_checksum_generic;
+	nvm->ops.valid_led_default  = e1000_valid_led_default_82575;
 
-	/* Function Pointers */
-	nvm->ops.acquire       = e1000_acquire_nvm_82575;
-	nvm->ops.read          = e1000_read_nvm_eerd;
-	nvm->ops.release       = e1000_release_nvm_82575;
-	nvm->ops.update        = e1000_update_nvm_checksum_generic;
-	nvm->ops.valid_led_default = e1000_valid_led_default_82575;
-	nvm->ops.validate      = e1000_validate_nvm_checksum_generic;
-	nvm->ops.write         = e1000_write_nvm_spi;
+	/* override genric family function pointers for specific descendants */
+	switch (hw->mac.type) {
+	case e1000_82580:
+		nvm->ops.validate = e1000_validate_nvm_checksum_82580;
+		nvm->ops.update = e1000_update_nvm_checksum_82580;
+		break;
+	case e1000_i350:
+		nvm->ops.validate = e1000_validate_nvm_checksum_i350;
+		nvm->ops.update = e1000_update_nvm_checksum_i350;
+		break;
+	default:
+		break;
+	}
 
 	return E1000_SUCCESS;
 }
@@ -276,34 +313,11 @@ static s32 e1000_init_mac_params_82575(struct e1000_hw *hw)
 {
 	struct e1000_mac_info *mac = &hw->mac;
 	struct e1000_dev_spec_82575 *dev_spec = &hw->dev_spec._82575;
-	u32 ctrl_ext = 0;
 
 	DEBUGFUNC("e1000_init_mac_params_82575");
 
-	/* Set media type */
-        /*
-	 * The 82575 uses bits 22:23 for link mode. The mode can be changed
-         * based on the EEPROM. We cannot rely upon device ID. There
-         * is no distinguishable difference between fiber and internal
-         * SerDes mode on the 82575. There can be an external PHY attached
-         * on the SGMII interface. For this, we'll set sgmii_active to true.
-         */
-	hw->phy.media_type = e1000_media_type_copper;
-	dev_spec->sgmii_active = false;
-
-	ctrl_ext = E1000_READ_REG(hw, E1000_CTRL_EXT);
-	switch (ctrl_ext & E1000_CTRL_EXT_LINK_MODE_MASK) {
-	case E1000_CTRL_EXT_LINK_MODE_SGMII:
-		dev_spec->sgmii_active = true;
-		break;
-	case E1000_CTRL_EXT_LINK_MODE_1000BASE_KX:
-	case E1000_CTRL_EXT_LINK_MODE_PCIE_SERDES:
-		hw->phy.media_type = e1000_media_type_internal_serdes;
-		break;
-	default:
-		break;
-	}
-
+	/* Derives media type */
+	e1000_get_media_type_82575(hw);
 	/* Set mta register count */
 	mac->mta_reg_count = 128;
 	/* Set uta register count */
@@ -316,6 +330,8 @@ static s32 e1000_init_mac_params_82575(struct e1000_hw *hw)
 		mac->rar_entry_count = E1000_RAR_ENTRIES_82580;
 	if (mac->type == e1000_i350) {
 		mac->rar_entry_count = E1000_RAR_ENTRIES_I350;
+		/* Enable EEE default settings for i350 */
+		dev_spec->eee_disable = false;
 	}
 
 	/* Set if part includes ASF firmware */
@@ -731,6 +747,103 @@ out:
 }
 
 /**
+ *  e1000_set_d0_lplu_state_82580 - Set Low Power Linkup D0 state
+ *  @hw: pointer to the HW structure
+ *  @active: true to enable LPLU, false to disable
+ *
+ *  Sets the LPLU D0 state according to the active flag.  When
+ *  activating LPLU this function also disables smart speed
+ *  and vice versa.  LPLU will not be activated unless the
+ *  device autonegotiation advertisement meets standards of
+ *  either 10 or 10/100 or 10/100/1000 at all duplexes.
+ *  This is a function pointer entry point only called by
+ *  PHY setup routines.
+ **/
+static s32 e1000_set_d0_lplu_state_82580(struct e1000_hw *hw, bool active)
+{
+	struct e1000_phy_info *phy = &hw->phy;
+	s32 ret_val = E1000_SUCCESS;
+	u16 data;
+
+	DEBUGFUNC("e1000_set_d0_lplu_state_82580");
+
+	data = E1000_READ_REG(hw, E1000_82580_PHY_POWER_MGMT);
+
+	if (active) {
+		data |= E1000_82580_PM_D0_LPLU;
+
+		/* When LPLU is enabled, we should disable SmartSpeed */
+		data &= ~E1000_82580_PM_SPD;
+	} else {
+		data &= ~E1000_82580_PM_D0_LPLU;
+
+		/*
+		 * LPLU and SmartSpeed are mutually exclusive.  LPLU is used
+		 * during Dx states where the power conservation is most
+		 * important.  During driver activity we should enable
+		 * SmartSpeed, so performance is maintained.
+		 */
+		if (phy->smart_speed == e1000_smart_speed_on) {
+			data |= E1000_82580_PM_SPD;
+		} else if (phy->smart_speed == e1000_smart_speed_off) {
+			data &= ~E1000_82580_PM_SPD;
+		}
+	}
+
+	E1000_WRITE_REG(hw, E1000_82580_PHY_POWER_MGMT, data);
+	return ret_val;
+}
+
+/**
+ *  e1000_set_d3_lplu_state_82580 - Sets low power link up state for D3
+ *  @hw: pointer to the HW structure
+ *  @active: boolean used to enable/disable lplu
+ *
+ *  Success returns 0, Failure returns 1
+ *
+ *  The low power link up (lplu) state is set to the power management level D3
+ *  and SmartSpeed is disabled when active is true, else clear lplu for D3
+ *  and enable Smartspeed.  LPLU and Smartspeed are mutually exclusive.  LPLU
+ *  is used during Dx states where the power conservation is most important.
+ *  During driver activity, SmartSpeed should be enabled so performance is
+ *  maintained.
+ **/
+s32 e1000_set_d3_lplu_state_82580(struct e1000_hw *hw, bool active)
+{
+	struct e1000_phy_info *phy = &hw->phy;
+	s32 ret_val = E1000_SUCCESS;
+	u16 data;
+
+	DEBUGFUNC("e1000_set_d3_lplu_state_82580");
+
+	data = E1000_READ_REG(hw, E1000_82580_PHY_POWER_MGMT);
+
+	if (!active) {
+		data &= ~E1000_82580_PM_D3_LPLU;
+		/*
+		 * LPLU and SmartSpeed are mutually exclusive.  LPLU is used
+		 * during Dx states where the power conservation is most
+		 * important.  During driver activity we should enable
+		 * SmartSpeed, so performance is maintained.
+		 */
+		if (phy->smart_speed == e1000_smart_speed_on) {
+			data |= E1000_82580_PM_SPD;
+		} else if (phy->smart_speed == e1000_smart_speed_off) {
+			data &= ~E1000_82580_PM_SPD;
+		}
+	} else if ((phy->autoneg_advertised == E1000_ALL_SPEED_DUPLEX) ||
+	           (phy->autoneg_advertised == E1000_ALL_NOT_GIG) ||
+	           (phy->autoneg_advertised == E1000_ALL_10_SPEED)) {
+		data |= E1000_82580_PM_D3_LPLU;
+		/* When LPLU is enabled, we should disable SmartSpeed */
+		data &= ~E1000_82580_PM_SPD;
+	}
+
+	E1000_WRITE_REG(hw, E1000_82580_PHY_POWER_MGMT, data);
+	return ret_val;
+}
+
+/**
  *  e1000_acquire_nvm_82575 - Request for access to EEPROM
  *  @hw: pointer to the HW structure
  *
@@ -749,7 +862,37 @@ static s32 e1000_acquire_nvm_82575(struct e1000_hw *hw)
 	if (ret_val)
 		goto out;
 
-	ret_val = e1000_acquire_nvm_generic(hw);
+	/*
+	 * Check if there is some access
+	 * error this access may hook on
+	 */
+	if (hw->mac.type == e1000_i350) {
+		u32 eecd = E1000_READ_REG(hw, E1000_EECD);
+		if (eecd & (E1000_EECD_BLOCKED | E1000_EECD_ABORT |
+		    E1000_EECD_TIMEOUT)) {
+			/* Clear all access error flags */
+			E1000_WRITE_REG(hw, E1000_EECD, eecd |
+					E1000_EECD_ERROR_CLR);
+			DEBUGOUT("Nvm bit banging access error"
+				" detected and cleared.\n");
+		}
+	}
+	if (hw->mac.type == e1000_82580) {
+		u32 eecd = E1000_READ_REG(hw, E1000_EECD);
+		if (eecd & E1000_EECD_BLOCKED) {
+			/* Clear access error flag */
+			E1000_WRITE_REG(hw, E1000_EECD, eecd |
+					E1000_EECD_BLOCKED);
+			DEBUGOUT("Nvm bit banging access"
+				" error detected and cleared.\n");
+		}
+	}
+
+
+	switch (hw->mac.type) {
+	default:
+		ret_val = e1000_acquire_nvm_generic(hw);
+	}
 
 	if (ret_val)
 		e1000_release_swfw_sync_82575(hw, E1000_SWFW_EEP_SM);
@@ -769,7 +912,10 @@ static void e1000_release_nvm_82575(struct e1000_hw *hw)
 {
 	DEBUGFUNC("e1000_release_nvm_82575");
 
-	e1000_release_nvm_generic(hw);
+	switch (hw->mac.type) {
+	default:
+		e1000_release_nvm_generic(hw);
+	}
 	e1000_release_swfw_sync_82575(hw, E1000_SWFW_EEP_SM);
 }
 
@@ -1077,7 +1223,7 @@ void e1000_shutdown_serdes_link_82575(struct e1000_hw *hw)
  **/
 static s32 e1000_reset_hw_82575(struct e1000_hw *hw)
 {
-	u32 ctrl, icr;
+	u32 ctrl;
 	s32 ret_val;
 
 	DEBUGFUNC("e1000_reset_hw_82575");
@@ -1127,7 +1273,7 @@ static s32 e1000_reset_hw_82575(struct e1000_hw *hw)
 
 	/* Clear any pending interrupt events. */
 	E1000_WRITE_REG(hw, E1000_IMC, 0xffffffff);
-	icr = E1000_READ_REG(hw, E1000_ICR);
+	E1000_READ_REG(hw, E1000_ICR);
 
 	/* Install any alternate MAC address into RAR0 */
 	ret_val = e1000_igb_check_alt_mac_addr_generic(hw);
@@ -1223,7 +1369,12 @@ static s32 e1000_setup_copper_link_82575(struct e1000_hw *hw)
 	}
 	switch (hw->phy.type) {
 	case e1000_phy_m88:
-		ret_val = e1000_copper_link_setup_m88(hw);
+		if (hw->phy.id == I347AT4_E_PHY_ID ||
+		    hw->phy.id == M88E1112_E_PHY_ID ||
+		    hw->phy.id == M88E1340M_E_PHY_ID)
+			ret_val = e1000_copper_link_setup_m88_gen2(hw);
+		else
+			ret_val = e1000_copper_link_setup_m88(hw);
 		break;
 	case e1000_phy_igp_3:
 		ret_val = e1000_copper_link_setup_igp(hw);
@@ -1257,12 +1408,14 @@ static s32 e1000_setup_serdes_link_82575(struct e1000_hw *hw)
 {
 	u32 ctrl_ext, ctrl_reg, reg;
 	bool pcs_autoneg;
+	s32 ret_val = E1000_SUCCESS;
+	u16 data;
 
 	DEBUGFUNC("e1000_setup_serdes_link_82575");
 
 	if ((hw->phy.media_type != e1000_media_type_internal_serdes) &&
 	    !e1000_sgmii_active_82575(hw))
-		return E1000_SUCCESS;
+		return ret_val;
 
 	/*
 	 * On the 82575, SerDes loopback mode persists until it is
@@ -1301,6 +1454,18 @@ static s32 e1000_setup_serdes_link_82575(struct e1000_hw *hw)
 		pcs_autoneg = false;
 		/* fall through to default case */
 	default:
+		if (hw->mac.type == e1000_82575 ||
+		    hw->mac.type == e1000_82576) {
+			ret_val = hw->nvm.ops.read(hw, NVM_COMPAT, 1, &data);
+			if (ret_val) {
+				DEBUGOUT("NVM Read Error\n");
+				return ret_val;
+			}
+
+			if (data & E1000_EEPROM_PCS_AUTONEG_DISABLE_BIT)
+				pcs_autoneg = false;
+		}
+
 		/*
 		 * non-SGMII modes only supports a speed of 1000/Full for the
 		 * link so it is best to just force the MAC and let the pcs
@@ -1347,7 +1512,217 @@ static s32 e1000_setup_serdes_link_82575(struct e1000_hw *hw)
 	if (!e1000_sgmii_active_82575(hw))
 		e1000_force_mac_fc_generic(hw);
 
-	return E1000_SUCCESS;
+	return ret_val;
+}
+
+/**
+ *  e1000_get_media_type_82575 - derives current media type.
+ *  @hw: pointer to the HW structure
+ *
+ *  The media type is chosen reflecting few settings.
+ *  The following are taken into account:
+ *  - link mode set in the current port Init Control Word #3
+ *  - current link mode settings in CSR register
+ *  - MDIO vs. I2C PHY control interface chosen
+ *  - SFP module media type
+ **/
+static s32 e1000_get_media_type_82575(struct e1000_hw *hw)
+{
+	u32 lan_id = 0;
+	s32 ret_val = E1000_ERR_CONFIG;
+	struct e1000_dev_spec_82575 *dev_spec = &hw->dev_spec._82575;
+	u32 ctrl_ext = 0;
+	u32 current_link_mode = 0;
+	u16 init_ctrl_wd_3 = 0;
+	u8 init_ctrl_wd_3_offset = 0;
+	u8 init_ctrl_wd_3_bit_offset = 0;
+
+	/* Set internal phy as default */
+	dev_spec->sgmii_active = false;
+	dev_spec->module_plugged = false;
+
+	/*
+	 * Check if NVM access method is attached already.
+	 * If it is then Init Control Word #3 is considered
+	 * otherwise runtime CSR register content is taken.
+	 */
+
+	/* Get CSR setting */
+	ctrl_ext = E1000_READ_REG(hw, E1000_CTRL_EXT);
+
+	/* Get link mode setting */
+	if (hw->nvm.ops.read) {
+		/* Take link mode from EEPROM */
+
+		/*
+		 * Get LAN port ID to derive its
+		 * adequate Init Control Word #3
+		 */
+		lan_id = ((E1000_READ_REG(hw, E1000_STATUS) &
+		      E1000_STATUS_LAN_ID_MASK) >> E1000_STATUS_LAN_ID_OFFSET);
+		/*
+		 * Derive Init Control Word #3 offset
+		 * and mask to pick up link mode setting.
+		 */
+		if (hw->mac.type < e1000_82580) {
+			init_ctrl_wd_3_offset = lan_id ?
+			   NVM_INIT_CONTROL3_PORT_A : NVM_INIT_CONTROL3_PORT_B;
+			init_ctrl_wd_3_bit_offset = NVM_WORD24_LNK_MODE_OFFSET;
+		} else {
+			init_ctrl_wd_3_offset =
+			                    NVM_82580_LAN_FUNC_OFFSET(lan_id) +
+			                    NVM_INIT_CONTROL3_PORT_A;
+			init_ctrl_wd_3_bit_offset =
+			                      NVM_WORD24_82580_LNK_MODE_OFFSET;
+		}
+		/* Read Init Control Word #3*/
+		hw->nvm.ops.read(hw, init_ctrl_wd_3_offset, 1, &init_ctrl_wd_3);
+		current_link_mode = init_ctrl_wd_3;
+		/*
+		 * Switch to CSR for all but internal PHY.
+		 */
+		if ((init_ctrl_wd_3 << (E1000_CTRL_EXT_LINK_MODE_OFFSET -
+		    init_ctrl_wd_3_bit_offset)) !=
+		    E1000_CTRL_EXT_LINK_MODE_GMII) {
+			current_link_mode = ctrl_ext;
+			init_ctrl_wd_3_bit_offset =
+			                      E1000_CTRL_EXT_LINK_MODE_OFFSET;
+		}
+	} else {
+		/* Take link mode from CSR */
+		current_link_mode = ctrl_ext;
+		init_ctrl_wd_3_bit_offset = E1000_CTRL_EXT_LINK_MODE_OFFSET;
+	}
+
+	/*
+	 * Align link mode bits to
+	 * their CTRL_EXT location.
+	 */
+	current_link_mode <<= (E1000_CTRL_EXT_LINK_MODE_OFFSET -
+	                       init_ctrl_wd_3_bit_offset);
+	current_link_mode &= E1000_CTRL_EXT_LINK_MODE_MASK;
+
+	switch (current_link_mode) {
+
+	case E1000_CTRL_EXT_LINK_MODE_1000BASE_KX:
+		hw->phy.media_type = e1000_media_type_internal_serdes;
+		current_link_mode = E1000_CTRL_EXT_LINK_MODE_1000BASE_KX;
+		break;
+	case E1000_CTRL_EXT_LINK_MODE_GMII:
+		hw->phy.media_type = e1000_media_type_copper;
+		current_link_mode = E1000_CTRL_EXT_LINK_MODE_GMII;
+		break;
+	case E1000_CTRL_EXT_LINK_MODE_SGMII:
+	case E1000_CTRL_EXT_LINK_MODE_PCIE_SERDES:
+		/* Get phy control interface type set (MDIO vs. I2C)*/
+		if (e1000_sgmii_uses_mdio_82575(hw)) {
+			hw->phy.media_type = e1000_media_type_copper;
+			dev_spec->sgmii_active = true;
+			current_link_mode = E1000_CTRL_EXT_LINK_MODE_SGMII;
+		} else {
+			ret_val = e1000_set_sfp_media_type_82575(hw);
+			if (ret_val != E1000_SUCCESS)
+				goto out;
+			if (hw->phy.media_type ==
+				e1000_media_type_internal_serdes) {
+				current_link_mode =
+				         E1000_CTRL_EXT_LINK_MODE_PCIE_SERDES;
+			} else if (hw->phy.media_type ==
+				e1000_media_type_copper) {
+				current_link_mode =
+				               E1000_CTRL_EXT_LINK_MODE_SGMII;
+			}
+		}
+		break;
+	default:
+		DEBUGOUT("Link mode mask doesn't fit bit field size");
+		goto out;
+	}
+	/*
+	 * Do not change current link mode setting
+	 * if media type is fibre or has not been
+	 * recognized.
+	 */
+	if ((hw->phy.media_type != e1000_media_type_unknown) &&
+	    (hw->phy.media_type != e1000_media_type_fiber)) {
+		/* Update link mode */
+		ctrl_ext &= ~E1000_CTRL_EXT_LINK_MODE_MASK;
+		E1000_WRITE_REG(hw, E1000_CTRL_EXT, ctrl_ext |
+		                current_link_mode);
+	}
+
+	ret_val = E1000_SUCCESS;
+out:
+	/*
+	 * If media type was not identified then return media type
+	 * defined by the CTRL_EXT settings.
+	 */
+	if (hw->phy.media_type == e1000_media_type_unknown) {
+		if (current_link_mode == E1000_CTRL_EXT_LINK_MODE_SGMII)
+			hw->phy.media_type = e1000_media_type_copper;
+		else
+			hw->phy.media_type = e1000_media_type_internal_serdes;
+	}
+
+	return ret_val;
+}
+
+/**
+ *  e1000_set_sfp_media_type_82575 - derives SFP module media type.
+ *  @hw: pointer to the HW structure
+ *
+ *  The media type is chosen based on SFP module.
+ *  compatibility flags retrieved from SFP ID EEPROM.
+ **/
+static s32 e1000_set_sfp_media_type_82575(struct e1000_hw *hw)
+{
+	s32 ret_val = E1000_ERR_CONFIG;
+	u32 ctrl_ext = 0;
+	struct e1000_dev_spec_82575 *dev_spec = &hw->dev_spec._82575;
+	struct sfp_e1000_flags eth_flags = {0};
+	u8 tranceiver_type = 0;
+
+	/* Turn I2C interface ON */
+	ctrl_ext = E1000_READ_REG(hw, E1000_CTRL_EXT);
+	E1000_WRITE_REG(hw, E1000_CTRL_EXT, ctrl_ext | E1000_CTRL_I2C_ENA);
+
+	/* Read SFP module data */
+	ret_val = e1000_read_sfp_data_byte(hw,
+	               E1000_I2CCMD_SFP_DATA_ADDR(E1000_SFF_IDENTIFIER_OFFSET),
+	                                          &tranceiver_type);
+	if (ret_val != E1000_SUCCESS)
+		goto out;
+	ret_val = e1000_read_sfp_data_byte(hw,
+	                E1000_I2CCMD_SFP_DATA_ADDR(E1000_SFF_ETH_FLAGS_OFFSET),
+	                                           (u8 *)&eth_flags);
+	if (ret_val != E1000_SUCCESS)
+		goto out;
+	/*
+	 * Check if there is some SFP
+	 * module plugged and powered
+	 */
+	if ((tranceiver_type == E1000_SFF_IDENTIFIER_SFP) ||
+	    (tranceiver_type == E1000_SFF_IDENTIFIER_SFF)) {
+		dev_spec->module_plugged = true;
+		if (eth_flags.e1000_base_lx || eth_flags.e1000_base_sx) {
+			hw->phy.media_type = e1000_media_type_internal_serdes;
+		} else if (eth_flags.e1000_base_t) {
+			dev_spec->sgmii_active = true;
+			hw->phy.media_type = e1000_media_type_copper;
+		} else {
+				hw->phy.media_type = e1000_media_type_unknown;
+				DEBUGOUT("PHY module has not been "
+					 "recognized");
+				goto out;
+		}
+	} else {
+		hw->phy.media_type = e1000_media_type_unknown;
+	}
+	ret_val = E1000_SUCCESS;
+out:
+	/* Restore I2C interface setting */
+	E1000_WRITE_REG(hw, E1000_CTRL_EXT, ctrl_ext);
+	return ret_val;
 }
 
 /**
@@ -1571,7 +1946,7 @@ static void e1000_clear_hw_cntrs_82575(struct e1000_hw *hw)
 }
 
 /**
- *  e1000_rx_fifo_flush_82575 - Clean rx fifo after RX enable
+ *  e1000_rx_fifo_flush_82575 - Clean rx fifo after Rx enable
  *  @hw: pointer to the HW structure
  *
  *  After rx enable if managability is enabled then there is likely some
@@ -1589,7 +1964,7 @@ void e1000_rx_fifo_flush_82575(struct e1000_hw *hw)
 	    !(E1000_READ_REG(hw, E1000_MANC) & E1000_MANC_RCV_TCO_EN))
 		return;
 
-	/* Disable all RX queues */
+	/* Disable all Rx queues */
 	for (i = 0; i < 4; i++) {
 		rxdctl[i] = E1000_READ_REG(hw, E1000_RXDCTL(i));
 		E1000_WRITE_REG(hw, E1000_RXDCTL(i),
@@ -1627,7 +2002,7 @@ void e1000_rx_fifo_flush_82575(struct e1000_hw *hw)
 	E1000_WRITE_FLUSH(hw);
 	msec_delay(2);
 
-	/* Enable RX queues that were previously enabled and restore our
+	/* Enable Rx queues that were previously enabled and restore our
 	 * previous state
 	 */
 	for (i = 0; i < 4; i++)
@@ -1696,6 +2071,54 @@ out:
 }
 
 /**
+ *  e1000_vmdq_set_anti_spoofing_pf - enable or disable anti-spoofing
+ *  @hw: pointer to the hardware struct
+ *  @enable: state to enter, either enabled or disabled
+ *  @pf: Physical Function pool - do not set anti-spoofing for the PF
+ *
+ *  enables/disables L2 switch anti-spoofing functionality.
+ **/
+void e1000_vmdq_set_anti_spoofing_pf(struct e1000_hw *hw, bool enable, int pf)
+{
+	u32 dtxswc;
+
+	switch (hw->mac.type) {
+	case e1000_82576:
+		dtxswc = E1000_READ_REG(hw, E1000_DTXSWC);
+		if (enable) {
+			dtxswc |= (E1000_DTXSWC_MAC_SPOOF_MASK |
+				   E1000_DTXSWC_VLAN_SPOOF_MASK);
+			/* The PF can spoof - it has to in order to
+			 * support emulation mode NICs */
+			dtxswc ^=
+			  (1 << pf | 1 << (pf + E1000_DTXSWC_VLAN_SPOOF_SHIFT));
+		} else {
+			dtxswc &= ~(E1000_DTXSWC_MAC_SPOOF_MASK |
+				    E1000_DTXSWC_VLAN_SPOOF_MASK);
+		}
+		E1000_WRITE_REG(hw, E1000_DTXSWC, dtxswc);
+		break;
+	case e1000_i350:
+		dtxswc = E1000_READ_REG(hw, E1000_TXSWC);
+		if (enable) {
+			dtxswc |= (E1000_DTXSWC_MAC_SPOOF_MASK |
+				   E1000_DTXSWC_VLAN_SPOOF_MASK);
+			/* The PF can spoof - it has to in order to
+			 * support emulation mode NICs
+			 */
+			dtxswc ^=
+			  (1 << pf | 1 << (pf + E1000_DTXSWC_VLAN_SPOOF_SHIFT));
+		} else {
+			dtxswc &= ~(E1000_DTXSWC_MAC_SPOOF_MASK |
+				    E1000_DTXSWC_VLAN_SPOOF_MASK);
+		}
+		E1000_WRITE_REG(hw, E1000_TXSWC, dtxswc);
+	default:
+		break;
+	}
+}
+
+/**
  *  e1000_vmdq_set_loopback_pf - enable or disable vmdq loopback
  *  @hw: pointer to the hardware struct
  *  @enable: state to enter, either enabled or disabled
@@ -1715,6 +2138,14 @@ void e1000_vmdq_set_loopback_pf(struct e1000_hw *hw, bool enable)
 			dtxswc &= ~E1000_DTXSWC_VMDQ_LOOPBACK_EN;
 		E1000_WRITE_REG(hw, E1000_DTXSWC, dtxswc);
 		break;
+	case e1000_i350:
+		dtxswc = E1000_READ_REG(hw, E1000_TXSWC);
+		if (enable)
+			dtxswc |= E1000_DTXSWC_VMDQ_LOOPBACK_EN;
+		else
+			dtxswc &= ~E1000_DTXSWC_VMDQ_LOOPBACK_EN;
+		E1000_WRITE_REG(hw, E1000_TXSWC, dtxswc);
+		break;
 	default:
 		/* Currently no other hardware supports loopback */
 		break;
@@ -1807,7 +2238,7 @@ static s32 e1000_reset_mdicnfg_82580(struct e1000_hw *hw)
 {
 	s32 ret_val = E1000_SUCCESS;
 	u32 mdicnfg;
-	u16 nvm_data;
+	u16 nvm_data = 0;
 
 	DEBUGFUNC("e1000_reset_mdicnfg_82580");
 
@@ -1846,7 +2277,7 @@ static s32 e1000_reset_hw_82580(struct e1000_hw *hw)
 	s32 ret_val = E1000_SUCCESS;
 	/* BH SW mailbox bit in SW_FW_SYNC */
 	u16 swmbsw_mask = E1000_SW_SYNCH_MB;
-	u32 ctrl, icr;
+	u32 ctrl;
 	bool global_device_reset = hw->dev_spec._82575.global_device_reset;
 
 	DEBUGFUNC("e1000_reset_hw_82580");
@@ -1884,6 +2315,7 @@ static s32 e1000_reset_hw_82580(struct e1000_hw *hw)
 		ctrl |= E1000_CTRL_RST;
 
 	E1000_WRITE_REG(hw, E1000_CTRL, ctrl);
+	E1000_WRITE_FLUSH(hw);
 
 	/* Add delay to insure DEV_RST has time to complete */
 	if (global_device_reset)
@@ -1908,7 +2340,7 @@ static s32 e1000_reset_hw_82580(struct e1000_hw *hw)
 
 	/* Clear any pending interrupt events. */
 	E1000_WRITE_REG(hw, E1000_IMC, 0xffffffff);
-	icr = E1000_READ_REG(hw, E1000_ICR);
+	E1000_READ_REG(hw, E1000_ICR);
 
 	ret_val = e1000_reset_mdicnfg_82580(hw);
 	if (ret_val)
@@ -1943,3 +2375,263 @@ u16 e1000_rxpbs_adjust_82580(u32 data)
 
 	return ret_val;
 }
+
+/**
+ *  e1000_validate_nvm_checksum_with_offset - Validate EEPROM
+ *  checksum
+ *  @hw: pointer to the HW structure
+ *  @offset: offset in words of the checksum protected region
+ *
+ *  Calculates the EEPROM checksum by reading/adding each word of the EEPROM
+ *  and then verifies that the sum of the EEPROM is equal to 0xBABA.
+ **/
+s32 e1000_validate_nvm_checksum_with_offset(struct e1000_hw *hw, u16 offset)
+{
+	s32 ret_val = E1000_SUCCESS;
+	u16 checksum = 0;
+	u16 i, nvm_data;
+
+	DEBUGFUNC("e1000_validate_nvm_checksum_with_offset");
+
+	for (i = offset; i < ((NVM_CHECKSUM_REG + offset) + 1); i++) {
+		ret_val = hw->nvm.ops.read(hw, i, 1, &nvm_data);
+		if (ret_val) {
+			DEBUGOUT("NVM Read Error\n");
+			goto out;
+		}
+		checksum += nvm_data;
+	}
+
+	if (checksum != (u16) NVM_SUM) {
+		DEBUGOUT("NVM Checksum Invalid\n");
+		ret_val = -E1000_ERR_NVM;
+		goto out;
+	}
+
+out:
+	return ret_val;
+}
+
+/**
+ *  e1000_update_nvm_checksum_with_offset - Update EEPROM
+ *  checksum
+ *  @hw: pointer to the HW structure
+ *  @offset: offset in words of the checksum protected region
+ *
+ *  Updates the EEPROM checksum by reading/adding each word of the EEPROM
+ *  up to the checksum.  Then calculates the EEPROM checksum and writes the
+ *  value to the EEPROM.
+ **/
+s32 e1000_update_nvm_checksum_with_offset(struct e1000_hw *hw, u16 offset)
+{
+	s32 ret_val;
+	u16 checksum = 0;
+	u16 i, nvm_data;
+
+	DEBUGFUNC("e1000_update_nvm_checksum_with_offset");
+
+	for (i = offset; i < (NVM_CHECKSUM_REG + offset); i++) {
+		ret_val = hw->nvm.ops.read(hw, i, 1, &nvm_data);
+		if (ret_val) {
+			DEBUGOUT("NVM Read Error while updating checksum.\n");
+			goto out;
+		}
+		checksum += nvm_data;
+	}
+	checksum = (u16) NVM_SUM - checksum;
+	ret_val = hw->nvm.ops.write(hw, (NVM_CHECKSUM_REG + offset), 1,
+				&checksum);
+	if (ret_val)
+		DEBUGOUT("NVM Write Error while updating checksum.\n");
+
+out:
+	return ret_val;
+}
+
+/**
+ *  e1000_validate_nvm_checksum_82580 - Validate EEPROM checksum
+ *  @hw: pointer to the HW structure
+ *
+ *  Calculates the EEPROM section checksum by reading/adding each word of
+ *  the EEPROM and then verifies that the sum of the EEPROM is
+ *  equal to 0xBABA.
+ **/
+static s32 e1000_validate_nvm_checksum_82580(struct e1000_hw *hw)
+{
+	s32 ret_val = E1000_SUCCESS;
+	u16 eeprom_regions_count = 1;
+	u16 j, nvm_data;
+	u16 nvm_offset;
+
+	DEBUGFUNC("e1000_validate_nvm_checksum_82580");
+
+	ret_val = hw->nvm.ops.read(hw, NVM_COMPATIBILITY_REG_3, 1, &nvm_data);
+	if (ret_val) {
+		DEBUGOUT("NVM Read Error\n");
+		goto out;
+	}
+
+	if (nvm_data & NVM_COMPATIBILITY_BIT_MASK) {
+		/* if chekcsums compatibility bit is set validate checksums
+		 * for all 4 ports. */
+		eeprom_regions_count = 4;
+	}
+
+	for (j = 0; j < eeprom_regions_count; j++) {
+		nvm_offset = NVM_82580_LAN_FUNC_OFFSET(j);
+		ret_val = e1000_validate_nvm_checksum_with_offset(hw,
+								nvm_offset);
+		if (ret_val != E1000_SUCCESS)
+			goto out;
+	}
+
+out:
+	return ret_val;
+}
+
+/**
+ *  e1000_update_nvm_checksum_82580 - Update EEPROM checksum
+ *  @hw: pointer to the HW structure
+ *
+ *  Updates the EEPROM section checksums for all 4 ports by reading/adding
+ *  each word of the EEPROM up to the checksum.  Then calculates the EEPROM
+ *  checksum and writes the value to the EEPROM.
+ **/
+static s32 e1000_update_nvm_checksum_82580(struct e1000_hw *hw)
+{
+	s32 ret_val;
+	u16 j, nvm_data;
+	u16 nvm_offset;
+
+	DEBUGFUNC("e1000_update_nvm_checksum_82580");
+
+	ret_val = hw->nvm.ops.read(hw, NVM_COMPATIBILITY_REG_3, 1, &nvm_data);
+	if (ret_val) {
+		DEBUGOUT("NVM Read Error while updating checksum"
+			" compatibility bit.\n");
+		goto out;
+	}
+
+	if ((nvm_data & NVM_COMPATIBILITY_BIT_MASK) == 0) {
+		/* set compatibility bit to validate checksums appropriately */
+		nvm_data = nvm_data | NVM_COMPATIBILITY_BIT_MASK;
+		ret_val = hw->nvm.ops.write(hw, NVM_COMPATIBILITY_REG_3, 1,
+					&nvm_data);
+		if (ret_val) {
+			DEBUGOUT("NVM Write Error while updating checksum"
+				" compatibility bit.\n");
+			goto out;
+		}
+	}
+
+	for (j = 0; j < 4; j++) {
+		nvm_offset = NVM_82580_LAN_FUNC_OFFSET(j);
+		ret_val = e1000_update_nvm_checksum_with_offset(hw, nvm_offset);
+		if (ret_val) {
+			goto out;
+		}
+	}
+
+out:
+	return ret_val;
+}
+
+/**
+ *  e1000_validate_nvm_checksum_i350 - Validate EEPROM checksum
+ *  @hw: pointer to the HW structure
+ *
+ *  Calculates the EEPROM section checksum by reading/adding each word of
+ *  the EEPROM and then verifies that the sum of the EEPROM is
+ *  equal to 0xBABA.
+ **/
+static s32 e1000_validate_nvm_checksum_i350(struct e1000_hw *hw)
+{
+	s32 ret_val = E1000_SUCCESS;
+	u16 j;
+	u16 nvm_offset;
+
+	DEBUGFUNC("e1000_validate_nvm_checksum_i350");
+
+	for (j = 0; j < 4; j++) {
+		nvm_offset = NVM_82580_LAN_FUNC_OFFSET(j);
+		ret_val = e1000_validate_nvm_checksum_with_offset(hw,
+								nvm_offset);
+		if (ret_val != E1000_SUCCESS)
+			goto out;
+	}
+
+out:
+	return ret_val;
+}
+
+/**
+ *  e1000_update_nvm_checksum_i350 - Update EEPROM checksum
+ *  @hw: pointer to the HW structure
+ *
+ *  Updates the EEPROM section checksums for all 4 ports by reading/adding
+ *  each word of the EEPROM up to the checksum.  Then calculates the EEPROM
+ *  checksum and writes the value to the EEPROM.
+ **/
+static s32 e1000_update_nvm_checksum_i350(struct e1000_hw *hw)
+{
+	s32 ret_val = E1000_SUCCESS;
+	u16 j;
+	u16 nvm_offset;
+
+	DEBUGFUNC("e1000_update_nvm_checksum_i350");
+
+	for (j = 0; j < 4; j++) {
+		nvm_offset = NVM_82580_LAN_FUNC_OFFSET(j);
+		ret_val = e1000_update_nvm_checksum_with_offset(hw, nvm_offset);
+		if (ret_val != E1000_SUCCESS)
+			goto out;
+	}
+
+out:
+	return ret_val;
+}
+
+/**
+ *  e1000_set_eee_i350 - Enable/disable EEE support
+ *  @hw: pointer to the HW structure
+ *
+ *  Enable/disable EEE based on setting in dev_spec structure.
+ *
+ **/
+s32 e1000_set_eee_i350(struct e1000_hw *hw)
+{
+	s32 ret_val = E1000_SUCCESS;
+	u32 ipcnfg, eeer, ctrl_ext;
+
+	DEBUGFUNC("e1000_set_eee_i350");
+
+	ctrl_ext = E1000_READ_REG(hw, E1000_CTRL_EXT);
+	if ((hw->mac.type != e1000_i350) ||
+	    (ctrl_ext & E1000_CTRL_EXT_LINK_MODE_MASK))
+		goto out;
+	ipcnfg = E1000_READ_REG(hw, E1000_IPCNFG);
+	eeer = E1000_READ_REG(hw, E1000_EEER);
+
+	/* enable or disable per user setting */
+	if (!(hw->dev_spec._82575.eee_disable)) {
+		ipcnfg |= (E1000_IPCNFG_EEE_1G_AN |
+		           E1000_IPCNFG_EEE_100M_AN);
+		eeer |= (E1000_EEER_TX_LPI_EN |
+		         E1000_EEER_RX_LPI_EN |
+		         E1000_EEER_LPI_FC);
+
+	} else {
+		ipcnfg &= ~(E1000_IPCNFG_EEE_1G_AN |
+		            E1000_IPCNFG_EEE_100M_AN);
+		eeer &= ~(E1000_EEER_TX_LPI_EN |
+		          E1000_EEER_RX_LPI_EN |
+		          E1000_EEER_LPI_FC);
+	}
+	E1000_WRITE_REG(hw, E1000_IPCNFG, ipcnfg);
+	E1000_WRITE_REG(hw, E1000_EEER, eeer);
+			E1000_READ_REG(hw, E1000_IPCNFG);
+			E1000_READ_REG(hw, E1000_EEER);
+out:
+
+	return ret_val;
+}
diff --git a/drivers/net/igb/e1000_82575.h b/drivers/net/igb/e1000_82575.h
index af93064..71f2a79 100644
--- a/drivers/net/igb/e1000_82575.h
+++ b/drivers/net/igb/e1000_82575.h
@@ -192,8 +192,8 @@ union e1000_adv_rx_desc {
 				__le32 data;
 				struct {
 					__le16 pkt_info; /*RSS type, Pkt type*/
-					__le16 hdr_info; /* Split Header,
-				        	          * header buffer len*/
+					/* Split Header, header buffer len */
+					__le16 hdr_info;
 				} hs_rss;
 			} lo_dword;
 			union {
@@ -387,7 +387,7 @@ struct e1000_adv_tx_context_desc {
 #define E1000_FTQF_MASK_SOURCE_PORT_BP 0x80000000
 
 #define E1000_NVM_APME_82575          0x0400
-#define MAX_NUM_VFS                   8
+#define MAX_NUM_VFS                   7
 
 #define E1000_DTXSWC_MAC_SPOOF_MASK   0x000000FF /* Per VF MAC spoof control */
 #define E1000_DTXSWC_VLAN_SPOOF_MASK  0x0000FF00 /* Per VF VLAN spoof control */
@@ -417,6 +417,14 @@ struct e1000_adv_tx_context_desc {
 #define E1000_VMOLR_STRVLAN    0x40000000 /* Vlan stripping enable */
 #define E1000_VMOLR_STRCRC     0x80000000 /* CRC stripping enable */
 
+#define E1000_VMOLR_VPE        0x00800000 /* VLAN promiscuous enable */
+#define E1000_VMOLR_UPE        0x20000000 /* Unicast promisuous enable */
+#define E1000_DVMOLR_HIDVLAN   0x20000000 /* Vlan hiding enable */
+#define E1000_DVMOLR_STRVLAN   0x40000000 /* Vlan stripping enable */
+#define E1000_DVMOLR_STRCRC    0x80000000 /* CRC stripping enable */
+
+#define E1000_PBRWAC_WALPB     0x00000007 /* Wrap around event on LAN Rx PB */
+#define E1000_PBRWAC_PBE       0x00000008 /* Rx packet buffer empty */
 
 #define E1000_VLVF_ARRAY_SIZE     32
 #define E1000_VLVF_VLANID_MASK    0x00000FFF
@@ -445,11 +453,17 @@ struct e1000_adv_tx_context_desc {
 #define E1000_DTXCTL_MDP_EN     0x0020
 #define E1000_DTXCTL_SPOOF_INT  0x0040
 
+#define E1000_EEPROM_PCS_AUTONEG_DISABLE_BIT    1 << 14
+
 #define ALL_QUEUES   0xFFFF
 
-/* RX packet buffer size defines */
+/* Rx packet buffer size defines */
 #define E1000_RXPBS_SIZE_MASK_82576  0x0000007F
 void e1000_vmdq_set_loopback_pf(struct e1000_hw *hw, bool enable);
+void e1000_vmdq_set_anti_spoofing_pf(struct e1000_hw *hw, bool enable, int pf);
 void e1000_vmdq_set_replication_pf(struct e1000_hw *hw, bool enable);
+s32 e1000_init_nvm_params_82575(struct e1000_hw *hw);
+
 u16 e1000_rxpbs_adjust_82580(u32 data);
+s32 e1000_set_eee_i350(struct e1000_hw *);
 #endif /* _E1000_82575_H_ */
diff --git a/drivers/net/igb/e1000_api.c b/drivers/net/igb/e1000_api.c
index 368562f..d4a5cc7 100644
--- a/drivers/net/igb/e1000_api.c
+++ b/drivers/net/igb/e1000_api.c
@@ -179,6 +179,7 @@ s32 e1000_set_mac_type(struct e1000_hw *hw)
 	case E1000_DEV_ID_I350_FIBER:
 	case E1000_DEV_ID_I350_SERDES:
 	case E1000_DEV_ID_I350_SGMII:
+	case E1000_DEV_ID_I350_DA4:
 		mac->type = e1000_i350;
 		break;
 	default:
diff --git a/drivers/net/igb/e1000_defines.h b/drivers/net/igb/e1000_defines.h
index 1d60233..c82658d 100644
--- a/drivers/net/igb/e1000_defines.h
+++ b/drivers/net/igb/e1000_defines.h
@@ -39,6 +39,7 @@
 #define E1000_WUC_PME_STATUS 0x00000004 /* PME Status */
 #define E1000_WUC_APMPME     0x00000008 /* Assert PME on APM Wakeup */
 #define E1000_WUC_LSCWE      0x00000010 /* Link Status wake up enable */
+#define E1000_WUC_PPROXYE    0x00000010 /* Protocol Proxy Enable */
 #define E1000_WUC_LSCWO      0x00000020 /* Link Status wake up override */
 #define E1000_WUC_SPM        0x80000000 /* Enable SPM */
 #define E1000_WUC_PHY_WAKE   0x00000100 /* if PHY supports wakeup */
@@ -57,8 +58,7 @@
 #define E1000_WUFC_FLX1 0x00020000 /* Flexible Filter 1 Enable */
 #define E1000_WUFC_FLX2 0x00040000 /* Flexible Filter 2 Enable */
 #define E1000_WUFC_FLX3 0x00080000 /* Flexible Filter 3 Enable */
-#define E1000_WUFC_FLX4 0x00100000 /* Flexible Filter 4 Enable */
-#define E1000_WUFC_FLX5 0x00200000 /* Flexible Filter 5 Enable */
+#define E1000_WUFC_FW_RST 0x80000000 /* Wake on FW Reset Enable */
 #define E1000_WUFC_ALL_FILTERS  0x000F00FF /* Mask for all wakeup filters */
 #define E1000_WUFC_FLX_OFFSET   16 /* Offset to the Flexible Filters bits */
 #define E1000_WUFC_FLX_FILTERS  0x000F0000 /*Mask for the 4 flexible filters */
@@ -126,6 +126,8 @@
 #define E1000_CTRL_EXT_RO_DIS    0x00020000 /* Relaxed Ordering disable */
 #define E1000_CTRL_EXT_DMA_DYN_CLK_EN 0x00080000 /* DMA Dynamic Clock Gating */
 #define E1000_CTRL_EXT_LINK_MODE_MASK 0x00C00000
+#define E1000_CTRL_EXT_LINK_MODE_OFFSET 22  /* Offset of the link mode field
+                                             * in Ctrl Ext register */
 #define E1000_CTRL_EXT_LINK_MODE_82580_MASK 0x01C00000 /*82580 bit 24:22*/
 #define E1000_CTRL_EXT_LINK_MODE_1000BASE_KX  0x00400000
 #define E1000_CTRL_EXT_LINK_MODE_GMII 0x00000000
@@ -161,6 +163,8 @@
 #define E1000_I2CCMD_READY            0x20000000
 #define E1000_I2CCMD_INTERRUPT_ENA    0x40000000
 #define E1000_I2CCMD_ERROR            0x80000000
+#define E1000_I2CCMD_SFP_DATA_ADDR(a) (0x0000 + (a))
+#define E1000_I2CCMD_SFP_DIAG_ADDR(a) (0x0100 + (a))
 #define E1000_MAX_SGMII_PHY_REG_ADDR  255
 #define E1000_I2CCMD_PHY_TIMEOUT      200
 #define E1000_IVAR_VALID        0x80
@@ -196,6 +200,7 @@
 #define E1000_RXD_SPC_CFI_MASK  0x1000  /* CFI is bit 12 */
 #define E1000_RXD_SPC_CFI_SHIFT 12
 
+#define E1000_RXDEXT_STATERR_LB    0x00040000
 #define E1000_RXDEXT_STATERR_CE    0x01000000
 #define E1000_RXDEXT_STATERR_SE    0x02000000
 #define E1000_RXDEXT_STATERR_SEQ   0x04000000
@@ -266,6 +271,8 @@
 #define E1000_MANC_SMB_DATA_IN   0x08000000 /* SMBus Data In */
 #define E1000_MANC_SMB_DATA_OUT  0x10000000 /* SMBus Data Out */
 #define E1000_MANC_SMB_CLK_OUT   0x20000000 /* SMBus Clock Out */
+#define E1000_MANC_MPROXYE       0x40000000 /* Mngment Proxy Enable */
+#define E1000_MANC_EN_BMC2OS     0x10000000 /* OS2BMC is enabled or not */
 
 #define E1000_MANC_SMB_DATA_OUT_SHIFT  28 /* SMBus Data Out Shift */
 #define E1000_MANC_SMB_CLK_OUT_SHIFT   29 /* SMBus Clock Out Shift */
@@ -351,6 +358,7 @@
 #define E1000_SWFW_CSR_SM   0x08
 #define E1000_SWFW_PHY2_SM  0x20
 #define E1000_SWFW_PHY3_SM  0x40
+#define E1000_SWFW_SW_MNG_SM 0x400
 
 /* FACTPS Definitions */
 #define E1000_FACTPS_LFS    0x40000000  /* LAN Function Select */
@@ -578,7 +586,7 @@
 
 /* Transmit Control */
 #define E1000_TCTL_RST    0x00000001    /* software reset */
-#define E1000_TCTL_EN     0x00000002    /* enable tx */
+#define E1000_TCTL_EN     0x00000002    /* enable Tx */
 #define E1000_TCTL_BCE    0x00000004    /* busy check enable */
 #define E1000_TCTL_PSP    0x00000008    /* pad short packets */
 #define E1000_TCTL_CT     0x00000ff0    /* collision threshold */
@@ -689,6 +697,8 @@
 #define E1000_PBA_48K 0x0030    /* 48KB */
 #define E1000_PBA_64K 0x0040    /* 64KB */
 
+#define E1000_PBA_RXA_MASK  0xFFFF;
+
 #define E1000_PBS_16K E1000_PBA_16K
 #define E1000_PBS_24K E1000_PBA_24K
 
@@ -744,6 +754,8 @@
 #define E1000_ICR_EPRST         0x00100000 /* ME hardware reset occurs */
 #define E1000_ICR_FER           0x00400000 /* Fatal Error */
 
+#define E1000_ICR_THS           0x00800000 /* ICR.THS: Thermal Sensor Event*/
+#define E1000_ICR_MDDET         0x10000000 /* Malicious Driver Detect */
 
 /* Extended Interrupt Cause Read */
 #define E1000_EICR_RX_QUEUE0    0x00000001 /* Rx Queue 0 Interrupt */
@@ -827,6 +839,8 @@
 #define E1000_IMS_EPRST     E1000_ICR_EPRST
 #define E1000_IMS_FER           E1000_ICR_FER /* Fatal Error */
 
+#define E1000_IMS_THS           E1000_ICR_THS /* ICR.TS: Thermal Sensor Event*/
+#define E1000_IMS_MDDET         E1000_ICR_MDDET /* Malicious Driver Detect */
 /* Extended Interrupt Mask Set */
 #define E1000_EIMS_RX_QUEUE0    E1000_EICR_RX_QUEUE0 /* Rx Queue 0 Interrupt */
 #define E1000_EIMS_RX_QUEUE1    E1000_EICR_RX_QUEUE1 /* Rx Queue 1 Interrupt */
@@ -924,8 +938,10 @@
 #define E1000_RAH_AV  0x80000000        /* Receive descriptor valid */
 #define E1000_RAL_MAC_ADDR_LEN 4
 #define E1000_RAH_MAC_ADDR_LEN 2
-#define E1000_RAH_POOL_MASK 0x03FC0000
-#define E1000_RAH_POOL_1 0x00040000
+#define E1000_RAH_QUEUE_MASK_82575 0x000C0000
+#define E1000_RAH_POOL_MASK     0x03FC0000
+#define E1000_RAH_POOL_SHIFT    18
+#define E1000_RAH_POOL_1        0x00040000
 
 /* Error Codes */
 #define E1000_SUCCESS      0
@@ -1043,6 +1059,23 @@
 #define E1000_MDICNFG_PHY_MASK    0x03E00000
 #define E1000_MDICNFG_PHY_SHIFT   21
 
+#define E1000_THSTAT_LOW_EVENT      0x20000000  /* Low thermal threshold */
+#define E1000_THSTAT_MID_EVENT      0x00200000  /* Mid thermal threshold */
+#define E1000_THSTAT_HIGH_EVENT     0x00002000  /* High thermal threshold */
+#define E1000_THSTAT_PWR_DOWN       0x00000001  /* Power Down Event */
+#define E1000_THSTAT_LINK_THROTTLE  0x00000002  /* Link Speed Throttle Event */
+
+/* I350 EEE defines */
+#define E1000_IPCNFG_EEE_1G_AN      0x00000008  /* IPCNFG EEE Enable 1G AN */
+#define E1000_IPCNFG_EEE_100M_AN    0x00000004  /* IPCNFG EEE Enable 100M AN */
+#define E1000_EEER_TX_LPI_EN        0x00010000  /* EEER Tx LPI Enable */
+#define E1000_EEER_RX_LPI_EN        0x00020000  /* EEER Rx LPI Enable */
+#define E1000_EEER_LPI_FC           0x00040000  /* EEER Enable on Flow Control*/
+/* EEE status */
+#define E1000_EEER_EEE_NEG          0x20000000  /* EEE capability negotiated */
+#define E1000_EEER_RX_LPI_STATUS    0x40000000  /* Rx in LPI state */
+#define E1000_EEER_TX_LPI_STATUS    0x80000000  /* Tx in LPI state */
+
 /* PCI Express Control */
 #define E1000_GCR_RXD_NO_SNOOP          0x00000001
 #define E1000_GCR_RXDSCW_NO_SNOOP       0x00000002
@@ -1184,6 +1217,10 @@
 #define E1000_EECD_GNT       0x00000080 /* NVM Access Grant */
 #define E1000_EECD_PRES      0x00000100 /* NVM Present */
 #define E1000_EECD_SIZE      0x00000200 /* NVM Size (0=64 word 1=256 word) */
+#define E1000_EECD_BLOCKED   0x00008000 /* Bit banging access blocked flag */
+#define E1000_EECD_ABORT     0x00010000 /* NVM operation aborted flag */
+#define E1000_EECD_TIMEOUT   0x00020000 /* NVM read operation timeout flag */
+#define E1000_EECD_ERROR_CLR 0x00040000 /* NVM error status clear bit */
 /* NVM Addressing bits based on type 0=small, 1=large */
 #define E1000_EECD_ADDR_BITS 0x00000400
 #define E1000_EECD_TYPE      0x00002000 /* NVM Type (1-SPI, 0-Microwire) */
@@ -1228,6 +1265,8 @@
 #define NVM_FLASH_VERSION          0x0032
 #define NVM_ALT_MAC_ADDR_PTR       0x0037
 #define NVM_CHECKSUM_REG           0x003F
+#define NVM_COMPATIBILITY_REG_3    0x0003
+#define NVM_COMPATIBILITY_BIT_MASK 0x8000
 
 #define E1000_NVM_CFG_DONE_PORT_0  0x040000 /* MNG config cycle done */
 #define E1000_NVM_CFG_DONE_PORT_1  0x080000 /* ...for second port */
@@ -1239,6 +1278,11 @@
 /* Mask bits for fields in Word 0x24 of the NVM */
 #define NVM_WORD24_COM_MDIO         0x0008 /* MDIO interface shared */
 #define NVM_WORD24_EXT_MDIO         0x0004 /* MDIO accesses routed external */
+#define NVM_WORD24_LNK_MODE_OFFSET         8 /* Offset of Link Mode bits
+                                              * for 82575 up to Kawela */
+#define NVM_WORD24_82580_LNK_MODE_OFFSET   4 /* Offset of Link Mode bits
+                                              * Link Mode bits for 82580 up */
+
 
 /* Mask bits for fields in Word 0x0f of the NVM */
 #define NVM_WORD0F_PAUSE_MASK       0x3000
@@ -1339,11 +1383,12 @@
 #define M88E1000_E_PHY_ID    0x01410C50
 #define M88E1000_I_PHY_ID    0x01410C30
 #define M88E1011_I_PHY_ID    0x01410C20
-#define M88E1112_E_PHY_ID    0x01410C90
-#define I347AT4_E_PHY_ID    0x01410DC0
 #define IGP01E1000_I_PHY_ID  0x02A80380
 #define M88E1011_I_REV_4     0x04
 #define M88E1111_I_PHY_ID    0x01410CC0
+#define M88E1112_E_PHY_ID    0x01410C90
+#define I347AT4_E_PHY_ID     0x01410DC0
+#define M88E1340M_E_PHY_ID   0x01410DF0
 #define GG82563_E_PHY_ID     0x01410CA0
 #define IGP03E1000_E_PHY_ID  0x02A80390
 #define IFE_E_PHY_ID         0x02A80330
@@ -1443,10 +1488,46 @@
 #define M88E1000_EPSCR_SLAVE_DOWNSHIFT_1X    0x0100
 #define M88E1000_EPSCR_SLAVE_DOWNSHIFT_2X    0x0200
 #define M88E1000_EPSCR_SLAVE_DOWNSHIFT_3X    0x0300
-#define M88E1000_EPSCR_TX_CLK_2_5     0x0060 /* 2.5 MHz TX_CLK */
-#define M88E1000_EPSCR_TX_CLK_25      0x0070 /* 25  MHz TX_CLK */
-#define M88E1000_EPSCR_TX_CLK_0       0x0000 /* NO  TX_CLK */
+#define M88E1000_EPSCR_TX_CLK_2_5       0x0060 /* 2.5 MHz TX_CLK */
+#define M88E1000_EPSCR_TX_CLK_25        0x0070 /* 25  MHz TX_CLK */
+#define M88E1000_EPSCR_TX_CLK_0         0x0000 /* NO  TX_CLK */
+
+/* M88E1111 Specific Registers */
+#define M88E1111_PHY_PAGE_SELECT1       0x16  /* for registers 0-28 */
+#define M88E1111_PHY_PAGE_SELECT2       0x1D  /* for registers 30-31 */
+
+/* M88E1111 page select register mask */
+#define M88E1111_PHY_PAGE_SELECT_MASK1  0xFF
+#define M88E1111_PHY_PAGE_SELECT_MASK2  0x3F
+
+/* Intel I347AT4 Registers */
 
+#define I347AT4_PCDL            0x10 /* PHY Cable Diagnostics Length */
+#define I347AT4_PCDC            0x15 /* PHY Cable Diagnostics Control */
+#define I347AT4_PAGE_SELECT     0x16
+
+/* I347AT4 Extended PHY Specific Control Register */
+
+/*
+ * Number of times we will attempt to autonegotiate before downshifting if we
+ * are the master
+ */
+#define I347AT4_PSCR_DOWNSHIFT_ENABLE 0x0800
+#define I347AT4_PSCR_DOWNSHIFT_MASK   0x7000
+#define I347AT4_PSCR_DOWNSHIFT_1X     0x0000
+#define I347AT4_PSCR_DOWNSHIFT_2X     0x1000
+#define I347AT4_PSCR_DOWNSHIFT_3X     0x2000
+#define I347AT4_PSCR_DOWNSHIFT_4X     0x3000
+#define I347AT4_PSCR_DOWNSHIFT_5X     0x4000
+#define I347AT4_PSCR_DOWNSHIFT_6X     0x5000
+#define I347AT4_PSCR_DOWNSHIFT_7X     0x6000
+#define I347AT4_PSCR_DOWNSHIFT_8X     0x7000
+
+/* I347AT4 PHY Cable Diagnostics Control */
+#define I347AT4_PCDC_CABLE_LENGTH_UNIT  0x0400 /* 0=cm 1=meters */
+
+/* M88E1112 only registers */
+#define M88E1112_VCT_DSP_DISTANCE       0x001A
 
 /* M88EC018 Rev 2 specific DownShift settings */
 #define M88EC018_EPSCR_DOWNSHIFT_COUNTER_MASK  0x0E00
@@ -1575,11 +1656,17 @@
 #define E1000_LSECRXCTRL_RP             0x00000080
 #define E1000_LSECRXCTRL_RSV_MASK       0xFFFFFF33
 
+/* Tx Rate-Scheduler Config fields */
+#define E1000_RTTBCNRC_RS_ENA		0x80000000
+#define E1000_RTTBCNRC_RF_DEC_MASK	0x00003FFF
+#define E1000_RTTBCNRC_RF_INT_SHIFT     14
+#define E1000_RTTBCNRC_RF_INT_MASK	\
+	(E1000_RTTBCNRC_RF_DEC_MASK << E1000_RTTBCNRC_RF_INT_SHIFT)
 
 /* DMA Coalescing register fields */
 #define E1000_DMACR_DMACWT_MASK         0x00003FFF /* DMA Coalescing
                                                     * Watchdog Timer */
-#define E1000_DMACR_DMACTHR_MASK        0x00FF0000 /* DMA Coalescing Receive
+#define E1000_DMACR_DMACTHR_MASK        0x00FF0000 /* DMA Coalescing Rx
                                                     * Threshold */
 #define E1000_DMACR_DMACTHR_SHIFT       16
 #define E1000_DMACR_DMAC_LX_MASK        0x30000000 /* Lx when no PCIe
@@ -1592,19 +1679,44 @@
 
 #define E1000_DMCTLX_TTLX_MASK          0x00000FFF /* Time to LX request */
 
-#define E1000_DMCRTRH_UTRESH_MASK       0x0007FFFF /* Receive Traffic Rate
+#define E1000_DMCRTRH_UTRESH_MASK       0x0007FFFF /* Rx Traffic Rate
                                                     * Threshold */
-#define E1000_DMCRTRH_LRPRCW            0x80000000 /* Rcv packet rate in
+#define E1000_DMCRTRH_LRPRCW            0x80000000 /* Rx packet rate in
                                                     * current window */
 
-#define E1000_DMCCNT_CCOUNT_MASK        0x01FFFFFF /* DMA Coal Rcv Traffic
+#define E1000_DMCCNT_CCOUNT_MASK        0x01FFFFFF /* DMA Coal Rx Traffic
                                                     * Current Cnt */
 
-#define E1000_FCRTC_RTH_COAL_MASK       0x0003FFF0 /* Flow ctrl Rcv Threshold
+#define E1000_FCRTC_RTH_COAL_MASK       0x0003FFF0 /* Flow ctrl Rx Threshold
                                                     * High val */
 #define E1000_FCRTC_RTH_COAL_SHIFT      4
 #define E1000_PCIEMISC_LX_DECISION      0x00000080 /* Lx power decision based
                                                       on DMA coal */
 
-
+/* Proxy Filer Control */
+#define E1000_PROXYFC_D0               0x00000001  /* Enable offload in D0 */
+#define E1000_PROXYFC_EX               0x00000004  /* Directed exact proxy */
+#define E1000_PROXYFC_MC               0x00000008  /* Directed Multicast
+                                                    * Proxy */
+#define E1000_PROXYFC_BC               0x00000010  /* Broadcast Proxy Enable */
+#define E1000_PROXYFC_ARP_DIRECTED     0x00000020  /* Directed ARP Proxy
+                                                    * Enable */
+#define E1000_PROXYFC_IPV4             0x00000040  /* Directed IPv4 Enable */
+#define E1000_PROXYFC_IPV6             0x00000080  /* Directed IPv6 Enable */
+#define E1000_PROXYFC_NS               0x00000200  /* IPv4 Neighborhood
+                                                    * Solicitation */
+#define E1000_PROXYFC_ARP              0x00000800  /* ARP Request Proxy
+                                                    * Enable */
+/* Proxy Status */
+#define E1000_PROXYS_CLEAR             0xFFFFFFFF  /* Clear */
+
+/* Firmware Status */
+#define E1000_FWSTS_FWRI               0x80000000 /* Firmware Reset
+                                                   * Indication */
+/* VF Control */
+#define E1000_VTCTRL_RST               0x04000000 /* Reset VF */
+
+#define E1000_STATUS_LAN_ID_MASK        0x00000000C /* Mask for Lan ID field */
+#define E1000_STATUS_LAN_ID_OFFSET      2           /* Lan ID bit field offset
+                                                     * in status register */
 #endif /* _E1000_DEFINES_H_ */
diff --git a/drivers/net/igb/e1000_hw.h b/drivers/net/igb/e1000_hw.h
index 00d201e..9b557eb 100644
--- a/drivers/net/igb/e1000_hw.h
+++ b/drivers/net/igb/e1000_hw.h
@@ -55,6 +55,7 @@ struct e1000_hw;
 #define E1000_DEV_ID_I350_FIBER               0x1522
 #define E1000_DEV_ID_I350_SERDES              0x1523
 #define E1000_DEV_ID_I350_SGMII               0x1524
+#define E1000_DEV_ID_I350_DA4                 0x1546
 #define E1000_DEV_ID_DH89XXCC_SGMII           0x0438
 #define E1000_DEV_ID_DH89XXCC_SERDES          0x043A
 #define E1000_DEV_ID_DH89XXCC_BACKPLANE       0x043C
@@ -414,6 +415,10 @@ struct e1000_hw_stats {
 	u64 scvpc;
 	u64 hrmpc;
 	u64 doosync;
+	u64 o2bgptc;
+	u64 o2bspc;
+	u64 b2ospc;
+	u64 b2ogprc;
 };
 
 
@@ -503,6 +508,21 @@ struct e1000_mac_operations {
 	s32  (*wait_autoneg)(struct e1000_hw *);
 };
 
+/*
+ * When to use various PHY register access functions:
+ *
+ *                 Func   Caller
+ *   Function      Does   Does    When to use
+ *   ~~~~~~~~~~~~  ~~~~~  ~~~~~~  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *   X_reg         L,P,A  n/a     for simple PHY reg accesses
+ *   X_reg_locked  P,A    L       for multiple accesses of different regs
+ *                                on different pages
+ *   X_reg_page    A      L,P     for multiple accesses of different regs
+ *                                on the same page
+ *
+ * Where X=[read|write], L=locking, P=sets page, A=register access
+ *
+ */
 struct e1000_phy_operations {
 	s32  (*init_params)(struct e1000_hw *);
 	s32  (*acquire)(struct e1000_hw *);
@@ -513,14 +533,17 @@ struct e1000_phy_operations {
 	s32  (*get_cfg_done)(struct e1000_hw *hw);
 	s32  (*get_cable_length)(struct e1000_hw *);
 	s32  (*get_info)(struct e1000_hw *);
+	s32  (*set_page)(struct e1000_hw *, u16);
 	s32  (*read_reg)(struct e1000_hw *, u32, u16 *);
 	s32  (*read_reg_locked)(struct e1000_hw *, u32, u16 *);
+	s32  (*read_reg_page)(struct e1000_hw *, u32, u16 *);
 	void (*release)(struct e1000_hw *);
 	s32  (*reset)(struct e1000_hw *);
 	s32  (*set_d0_lplu_state)(struct e1000_hw *, bool);
 	s32  (*set_d3_lplu_state)(struct e1000_hw *, bool);
 	s32  (*write_reg)(struct e1000_hw *, u32, u16);
 	s32  (*write_reg_locked)(struct e1000_hw *, u32, u16);
+	s32  (*write_reg_page)(struct e1000_hw *, u32, u16);
 	void (*power_up)(struct e1000_hw *);
 	void (*power_down)(struct e1000_hw *);
 };
@@ -539,8 +562,8 @@ struct e1000_nvm_operations {
 
 struct e1000_mac_info {
 	struct e1000_mac_operations ops;
-	u8 addr[6];
-	u8 perm_addr[6];
+	u8 addr[ETH_ADDR_LEN];
+	u8 perm_addr[ETH_ADDR_LEN];
 
 	enum e1000_mac_type type;
 
@@ -681,11 +704,13 @@ struct e1000_mbx_info {
 struct e1000_dev_spec_82575 {
 	bool sgmii_active;
 	bool global_device_reset;
+	bool eee_disable;
+	bool module_plugged;
 };
 
 struct e1000_dev_spec_vf {
-	u32	vf_number;
-	u32	v2p_mailbox;
+	u32 vf_number;
+	u32 v2p_mailbox;
 };
 
 struct e1000_hw {
@@ -704,8 +729,8 @@ struct e1000_hw {
 	struct e1000_host_mng_dhcp_cookie mng_cookie;
 
 	union {
-		struct e1000_dev_spec_82575	_82575;
-		struct e1000_dev_spec_vf	vf;
+		struct e1000_dev_spec_82575 _82575;
+		struct e1000_dev_spec_vf vf;
 	} dev_spec;
 
 	u16 device_id;
diff --git a/drivers/net/igb/e1000_mac.c b/drivers/net/igb/e1000_mac.c
index de44f05..f8bcf4e 100644
--- a/drivers/net/igb/e1000_mac.c
+++ b/drivers/net/igb/e1000_mac.c
@@ -129,6 +129,19 @@ static void e1000_set_lan_id_multi_port_pcie(struct e1000_hw *hw)
 }
 
 /**
+*  e1000_igb_set_lan_id_single_port - Set LAN id for a single port device
+*  @hw: pointer to the HW structure
+*
+*  Sets the LAN function id to zero for a single port device.
+**/
+void e1000_igb_set_lan_id_single_port(struct e1000_hw *hw)
+{
+	struct e1000_bus_info *bus = &hw->bus;
+
+	bus->func = 0;
+}
+
+/**
  *  e1000_igb_clear_vfta_generic - Clear VLAN filter table
  *  @hw: pointer to the HW structure
  *
diff --git a/drivers/net/igb/e1000_mac.h b/drivers/net/igb/e1000_mac.h
index c2f2c04..c483cbb 100644
--- a/drivers/net/igb/e1000_mac.h
+++ b/drivers/net/igb/e1000_mac.h
@@ -43,6 +43,7 @@ s32  e1000_disable_pcie_master_generic(struct e1000_hw *hw);
 s32  e1000_force_mac_fc_generic(struct e1000_hw *hw);
 s32  e1000_get_auto_rd_done_generic(struct e1000_hw *hw);
 s32  e1000_get_bus_info_pcie_generic(struct e1000_hw *hw);
+void e1000_igb_set_lan_id_single_port(struct e1000_hw *hw);
 s32  e1000_get_hw_semaphore_generic(struct e1000_hw *hw);
 s32  e1000_get_speed_and_duplex_copper_generic(struct e1000_hw *hw, u16 *speed,
                                                u16 *duplex);
@@ -52,7 +53,7 @@ s32  e1000_id_led_init_generic(struct e1000_hw *hw);
 s32  e1000_led_on_generic(struct e1000_hw *hw);
 s32  e1000_led_off_generic(struct e1000_hw *hw);
 void e1000_update_mc_addr_list_generic(struct e1000_hw *hw,
-	                               u8 *mc_addr_list, u32 mc_addr_count);
+                                       u8 *mc_addr_list, u32 mc_addr_count);
 s32  e1000_set_fc_watermarks_generic(struct e1000_hw *hw);
 s32  e1000_setup_fiber_serdes_link_generic(struct e1000_hw *hw);
 s32  e1000_setup_led_generic(struct e1000_hw *hw);
diff --git a/drivers/net/igb/e1000_manage.c b/drivers/net/igb/e1000_manage.c
index a86c6d6..57927ac 100644
--- a/drivers/net/igb/e1000_manage.c
+++ b/drivers/net/igb/e1000_manage.c
@@ -27,8 +27,6 @@
 
 #include "e1000_api.h"
 
-static u8 e1000_calculate_checksum(u8 *buffer, u32 length);
-
 /**
  *  e1000_calculate_checksum - Calculate checksum for buffer
  *  @buffer: pointer to EEPROM
@@ -37,10 +35,10 @@ static u8 e1000_calculate_checksum(u8 *buffer, u32 length);
  *  Calculates the checksum for some buffer on a specified length.  The
  *  checksum calculated is returned.
  **/
-static u8 e1000_calculate_checksum(u8 *buffer, u32 length)
+u8 e1000_calculate_checksum(u8 *buffer, u32 length)
 {
 	u32 i;
-	u8  sum = 0;
+	u8 sum = 0;
 
 	DEBUGFUNC("e1000_calculate_checksum");
 
@@ -384,3 +382,84 @@ out:
 	return ret_val;
 }
 
+/**
+ *  e1000_host_interface_command - Writes buffer to host interface
+ *  @hw: pointer to the HW structure
+ *  @buffer: contains a command to write
+ *  @length: the byte length of the buffer, must be multiple of 4 bytes
+ *
+ *  Writes a buffer to the Host Interface.  Upon success, returns E1000_SUCCESS
+ *  else returns E1000_ERR_HOST_INTERFACE_COMMAND.
+ **/
+s32 e1000_host_interface_command(struct e1000_hw *hw, u8 *buffer, u32 length)
+{
+	u32 hicr, i;
+	s32 ret_val = E1000_SUCCESS;
+
+	DEBUGFUNC("e1000_host_interface_command");
+
+	if (!(hw->mac.arc_subsystem_valid)) {
+		DEBUGOUT("Hardware doesn't support host interface command.\n");
+		goto out;
+	}
+
+	if (!hw->mac.asf_firmware_present) {
+		DEBUGOUT("Firmware is not present.\n");
+		goto out;
+	}
+
+	if (length == 0 || length & 0x3 ||
+	    length > E1000_HI_MAX_BLOCK_BYTE_LENGTH) {
+		DEBUGOUT("Buffer length failure.\n");
+		ret_val = -E1000_ERR_HOST_INTERFACE_COMMAND;
+		goto out;
+	}
+
+	/* Check that the host interface is enabled. */
+	hicr = E1000_READ_REG(hw, E1000_HICR);
+	if ((hicr & E1000_HICR_EN) == 0) {
+		DEBUGOUT("E1000_HOST_EN bit disabled.\n");
+		ret_val = -E1000_ERR_HOST_INTERFACE_COMMAND;
+		goto out;
+	}
+
+	/* Calculate length in DWORDs */
+	length >>= 2;
+
+	/*
+	 * The device driver writes the relevant command block
+	 * into the ram area.
+	 */
+	for (i = 0; i < length; i++)
+		E1000_WRITE_REG_ARRAY_DWORD(hw,
+		                            E1000_HOST_IF,
+		                            i,
+		                            *((u32 *)buffer + i));
+
+	/* Setting this bit tells the ARC that a new command is pending. */
+	E1000_WRITE_REG(hw, E1000_HICR, hicr | E1000_HICR_C);
+
+	for (i = 0; i < E1000_HI_COMMAND_TIMEOUT; i++) {
+		hicr = E1000_READ_REG(hw, E1000_HICR);
+		if (!(hicr & E1000_HICR_C))
+			break;
+		msec_delay(1);
+	}
+
+	/* Check command successful completion. */
+	if (i == E1000_HI_COMMAND_TIMEOUT ||
+	    (!(E1000_READ_REG(hw, E1000_HICR) & E1000_HICR_SV))) {
+		DEBUGOUT("Command has failed with no status valid.\n");
+		ret_val = -E1000_ERR_HOST_INTERFACE_COMMAND;
+		goto out;
+	}
+
+	for (i = 0; i < length; i++)
+		*((u32 *)buffer + i) = E1000_READ_REG_ARRAY_DWORD(hw,
+		                                                  E1000_HOST_IF,
+		                                                  i);
+
+out:
+	return ret_val;
+}
+
diff --git a/drivers/net/igb/e1000_manage.h b/drivers/net/igb/e1000_manage.h
index c5473b6..562451b 100644
--- a/drivers/net/igb/e1000_manage.h
+++ b/drivers/net/igb/e1000_manage.h
@@ -38,6 +38,8 @@ s32  e1000_mng_write_cmd_header_generic(struct e1000_hw *hw,
 s32  e1000_mng_write_dhcp_info_generic(struct e1000_hw *hw,
                                        u8 *buffer, u16 length);
 bool e1000_enable_mng_pass_thru(struct e1000_hw *hw);
+u8 e1000_calculate_checksum(u8 *buffer, u32 length);
+s32 e1000_host_interface_command(struct e1000_hw *hw, u8 *buffer, u32 length);
 
 enum e1000_mng_mode {
 	e1000_mng_mode_none = 0,
diff --git a/drivers/net/igb/e1000_mbx.c b/drivers/net/igb/e1000_mbx.c
index b85f175..885fda0 100644
--- a/drivers/net/igb/e1000_mbx.c
+++ b/drivers/net/igb/e1000_mbx.c
@@ -465,7 +465,9 @@ s32 e1000_init_mbx_params_pf(struct e1000_hw *hw)
 {
 	struct e1000_mbx_info *mbx = &hw->mbx;
 
-	if (hw->mac.type == e1000_82576) {
+	switch (hw->mac.type) {
+	case e1000_82576:
+	case e1000_i350:
 		mbx->timeout = 0;
 		mbx->usec_delay = 0;
 
@@ -484,8 +486,8 @@ s32 e1000_init_mbx_params_pf(struct e1000_hw *hw)
 		mbx->stats.reqs = 0;
 		mbx->stats.acks = 0;
 		mbx->stats.rsts = 0;
+	default:
+		return E1000_SUCCESS;
 	}
-
-	return E1000_SUCCESS;
 }
 
diff --git a/drivers/net/igb/e1000_mbx.h b/drivers/net/igb/e1000_mbx.h
index fce5f09..a54b850 100644
--- a/drivers/net/igb/e1000_mbx.h
+++ b/drivers/net/igb/e1000_mbx.h
@@ -71,6 +71,7 @@
 
 #define E1000_PF_CONTROL_MSG      0x0100 /* PF control message */
 
+
 #define E1000_VF_MBX_INIT_TIMEOUT 2000 /* number of retries on mailbox */
 #define E1000_VF_MBX_INIT_DELAY   500  /* microseconds between retries */
 
diff --git a/drivers/net/igb/e1000_nvm.c b/drivers/net/igb/e1000_nvm.c
index 9172525..7a62bae 100644
--- a/drivers/net/igb/e1000_nvm.c
+++ b/drivers/net/igb/e1000_nvm.c
@@ -304,17 +304,18 @@ static s32 e1000_ready_nvm_eeprom(struct e1000_hw *hw)
 	struct e1000_nvm_info *nvm = &hw->nvm;
 	u32 eecd = E1000_READ_REG(hw, E1000_EECD);
 	s32 ret_val = E1000_SUCCESS;
-	u16 timeout = 0;
 	u8 spi_stat_reg;
 
 	DEBUGFUNC("e1000_ready_nvm_eeprom");
 
 	if (nvm->type == e1000_nvm_eeprom_spi) {
+		u16 timeout = NVM_MAX_RETRY_SPI;
+
 		/* Clear SK and CS */
 		eecd &= ~(E1000_EECD_CS | E1000_EECD_SK);
 		E1000_WRITE_REG(hw, E1000_EECD, eecd);
+		E1000_WRITE_FLUSH(hw);
 		usec_delay(1);
-		timeout = NVM_MAX_RETRY_SPI;
 
 		/*
 		 * Read "Status Register" repeatedly until the LSB is cleared.
@@ -346,6 +347,70 @@ out:
 }
 
 /**
+ *  e1000_read_nvm_spi - Read EEPROM's using SPI
+ *  @hw: pointer to the HW structure
+ *  @offset: offset of word in the EEPROM to read
+ *  @words: number of words to read
+ *  @data: word read from the EEPROM
+ *
+ *  Reads a 16 bit word from the EEPROM.
+ **/
+s32 e1000_read_nvm_spi(struct e1000_hw *hw, u16 offset, u16 words, u16 *data)
+{
+	struct e1000_nvm_info *nvm = &hw->nvm;
+	u32 i = 0;
+	s32 ret_val;
+	u16 word_in;
+	u8 read_opcode = NVM_READ_OPCODE_SPI;
+
+	DEBUGFUNC("e1000_read_nvm_spi");
+
+	/*
+	 * A check for invalid values:  offset too large, too many words,
+	 * and not enough words.
+	 */
+	if ((offset >= nvm->word_size) || (words > (nvm->word_size - offset)) ||
+	    (words == 0)) {
+		DEBUGOUT("nvm parameter(s) out of bounds\n");
+		ret_val = -E1000_ERR_NVM;
+		goto out;
+	}
+
+	ret_val = nvm->ops.acquire(hw);
+	if (ret_val)
+		goto out;
+
+	ret_val = e1000_ready_nvm_eeprom(hw);
+	if (ret_val)
+		goto release;
+
+	e1000_standby_nvm(hw);
+
+	if ((nvm->address_bits == 8) && (offset >= 128))
+		read_opcode |= NVM_A8_OPCODE_SPI;
+
+	/* Send the READ command (opcode + addr) */
+	e1000_shift_out_eec_bits(hw, read_opcode, nvm->opcode_bits);
+	e1000_shift_out_eec_bits(hw, (u16)(offset*2), nvm->address_bits);
+
+	/*
+	 * Read the data.  SPI NVMs increment the address with each byte
+	 * read and will roll over if reading beyond the end.  This allows
+	 * us to read the whole NVM from any offset
+	 */
+	for (i = 0; i < words; i++) {
+		word_in = e1000_shift_in_eec_bits(hw, 16);
+		data[i] = (word_in >> 8) | (word_in << 8);
+	}
+
+release:
+	nvm->ops.release(hw);
+
+out:
+	return ret_val;
+}
+
+/**
  *  e1000_read_nvm_eerd - Reads EEPROM using EERD register
  *  @hw: pointer to the HW structure
  *  @offset: offset of word in the EEPROM to read
diff --git a/drivers/net/igb/e1000_nvm.h b/drivers/net/igb/e1000_nvm.h
index 1af5d55..9099afc 100644
--- a/drivers/net/igb/e1000_nvm.h
+++ b/drivers/net/igb/e1000_nvm.h
@@ -36,12 +36,11 @@ s32  e1000_igb_read_mac_addr_generic(struct e1000_hw *hw);
 s32  e1000_read_pba_string_generic(struct e1000_hw *hw, u8 *pba_num,
                                    u32 pba_num_size);
 s32  e1000_read_pba_length_generic(struct e1000_hw *hw, u32 *pba_num_size);
+s32  e1000_read_nvm_spi(struct e1000_hw *hw, u16 offset, u16 words, u16 *data);
 s32  e1000_read_nvm_eerd(struct e1000_hw *hw, u16 offset, u16 words,
                          u16 *data);
 s32  e1000_valid_led_default_generic(struct e1000_hw *hw, u16 *data);
 s32  e1000_validate_nvm_checksum_generic(struct e1000_hw *hw);
-s32  e1000_write_nvm_eewr(struct e1000_hw *hw, u16 offset,
-                          u16 words, u16 *data);
 s32  e1000_write_nvm_spi(struct e1000_hw *hw, u16 offset, u16 words,
                          u16 *data);
 s32  e1000_update_nvm_checksum_generic(struct e1000_hw *hw);
diff --git a/drivers/net/igb/e1000_osdep.h b/drivers/net/igb/e1000_osdep.h
index 215a3a7..5b25e54 100644
--- a/drivers/net/igb/e1000_osdep.h
+++ b/drivers/net/igb/e1000_osdep.h
@@ -70,7 +70,7 @@
 #define DEBUGOUT(S)
 #define DEBUGOUT1(S, A...)
 
-#define DEBUGFUNC(F) DEBUGOUT(F "\n")
+#define DEBUGFUNC(F)
 #define DEBUGOUT2 DEBUGOUT1
 #define DEBUGOUT3 DEBUGOUT2
 #define DEBUGOUT7 DEBUGOUT3
diff --git a/drivers/net/igb/e1000_phy.c b/drivers/net/igb/e1000_phy.c
index e48d6b4..8955fd0 100644
--- a/drivers/net/igb/e1000_phy.c
+++ b/drivers/net/igb/e1000_phy.c
@@ -30,21 +30,21 @@
 static s32 e1000_copper_link_autoneg(struct e1000_hw *hw);
 static s32 e1000_phy_setup_autoneg(struct e1000_hw *hw);
 /* Cable length tables */
-static const u16 e1000_m88_cable_length_table[] =
-	{ 0, 50, 80, 110, 140, 140, E1000_CABLE_LENGTH_UNDEFINED };
+static const u16 e1000_m88_cable_length_table[] = {
+	0, 50, 80, 110, 140, 140, E1000_CABLE_LENGTH_UNDEFINED };
 #define M88E1000_CABLE_LENGTH_TABLE_SIZE \
                 (sizeof(e1000_m88_cable_length_table) / \
                  sizeof(e1000_m88_cable_length_table[0]))
 
-static const u16 e1000_igp_2_cable_length_table[] =
-    { 0, 0, 0, 0, 0, 0, 0, 0, 3, 5, 8, 11, 13, 16, 18, 21,
-      0, 0, 0, 3, 6, 10, 13, 16, 19, 23, 26, 29, 32, 35, 38, 41,
-      6, 10, 14, 18, 22, 26, 30, 33, 37, 41, 44, 48, 51, 54, 58, 61,
-      21, 26, 31, 35, 40, 44, 49, 53, 57, 61, 65, 68, 72, 75, 79, 82,
-      40, 45, 51, 56, 61, 66, 70, 75, 79, 83, 87, 91, 94, 98, 101, 104,
-      60, 66, 72, 77, 82, 87, 92, 96, 100, 104, 108, 111, 114, 117, 119, 121,
-      83, 89, 95, 100, 105, 109, 113, 116, 119, 122, 124,
-      104, 109, 114, 118, 121, 124};
+static const u16 e1000_igp_2_cable_length_table[] = {
+	0, 0, 0, 0, 0, 0, 0, 0, 3, 5, 8, 11, 13, 16, 18, 21, 0, 0, 0, 3,
+	6, 10, 13, 16, 19, 23, 26, 29, 32, 35, 38, 41, 6, 10, 14, 18, 22,
+	26, 30, 33, 37, 41, 44, 48, 51, 54, 58, 61, 21, 26, 31, 35, 40,
+	44, 49, 53, 57, 61, 65, 68, 72, 75, 79, 82, 40, 45, 51, 56, 61,
+	66, 70, 75, 79, 83, 87, 91, 94, 98, 101, 104, 60, 66, 72, 77, 82,
+	87, 92, 96, 100, 104, 108, 111, 114, 117, 119, 121, 83, 89, 95,
+	100, 105, 109, 113, 116, 119, 122, 124, 104, 109, 114, 118, 121,
+	124};
 #define IGP02E1000_CABLE_LENGTH_TABLE_SIZE \
                 (sizeof(e1000_igp_2_cable_length_table) / \
                  sizeof(e1000_igp_2_cable_length_table[0]))
@@ -87,18 +87,18 @@ s32 e1000_get_phy_id(struct e1000_hw *hw)
 	if (!(phy->ops.read_reg))
 		goto out;
 
-		ret_val = phy->ops.read_reg(hw, PHY_ID1, &phy_id);
-		if (ret_val)
-			goto out;
+	ret_val = phy->ops.read_reg(hw, PHY_ID1, &phy_id);
+	if (ret_val)
+		goto out;
 
-		phy->id = (u32)(phy_id << 16);
-		usec_delay(20);
-		ret_val = phy->ops.read_reg(hw, PHY_ID2, &phy_id);
-		if (ret_val)
-			goto out;
+	phy->id = (u32)(phy_id << 16);
+	usec_delay(20);
+	ret_val = phy->ops.read_reg(hw, PHY_ID2, &phy_id);
+	if (ret_val)
+		goto out;
 
-		phy->id |= (u32)(phy_id & PHY_REVISION_MASK);
-		phy->revision = (u32)(phy_id & ~PHY_REVISION_MASK);
+	phy->id |= (u32)(phy_id & PHY_REVISION_MASK);
+	phy->revision = (u32)(phy_id & ~PHY_REVISION_MASK);
 
 out:
 	return ret_val;
@@ -310,6 +310,13 @@ s32 e1000_write_phy_reg_i2c(struct e1000_hw *hw, u32 offset, u16 data)
 
 	DEBUGFUNC("e1000_write_phy_reg_i2c");
 
+	/* Prevent overwritting SFP I2C EEPROM which is at A0 address.*/
+	if ((hw->phy.addr == 0) || (hw->phy.addr > 7)) {
+		DEBUGOUT1("PHY I2C Address %d is out of range.\n",
+			  hw->phy.addr);
+		return -E1000_ERR_CONFIG;
+	}
+
 	/* Swap the data bytes for the I2C interface */
 	phy_data_swapped = ((data >> 8) & 0x00FF) | ((data << 8) & 0xFF00);
 
@@ -345,6 +352,139 @@ s32 e1000_write_phy_reg_i2c(struct e1000_hw *hw, u32 offset, u16 data)
 }
 
 /**
+ *  e1000_read_sfp_data_byte - Reads SFP module data.
+ *  @hw: pointer to the HW structure
+ *  @offset: byte location offset to be read
+ *  @data: read data buffer pointer
+ *
+ *  Reads one byte from SFP module data stored
+ *  in SFP resided EEPROM memory or SFP diagnostic area.
+ *  Function should be called with
+ *  E1000_I2CCMD_SFP_DATA_ADDR(<byte offset>) for SFP module database access
+ *  E1000_I2CCMD_SFP_DIAG_ADDR(<byte offset>) for SFP diagnostics parameters
+ *  access
+ **/
+s32 e1000_read_sfp_data_byte(struct e1000_hw *hw, u16 offset, u8 *data)
+{
+	u32 i = 0;
+	u32 i2ccmd = 0;
+	u32 data_local = 0;
+
+	DEBUGFUNC("e1000_read_sfp_data_byte");
+
+	if (offset > E1000_I2CCMD_SFP_DIAG_ADDR(255)) {
+		DEBUGOUT("I2CCMD command address exceeds upper limit\n");
+		return -E1000_ERR_PHY;
+	}
+
+	/*
+	 * Set up Op-code, EEPROM Address,in the I2CCMD
+	 * register. The MAC will take care of interfacing with the
+	 * EEPROM to retrieve the desired data.
+	 */
+	i2ccmd = ((offset << E1000_I2CCMD_REG_ADDR_SHIFT) |
+	          E1000_I2CCMD_OPCODE_READ);
+
+	E1000_WRITE_REG(hw, E1000_I2CCMD, i2ccmd);
+
+	/* Poll the ready bit to see if the I2C read completed */
+	for (i = 0; i < E1000_I2CCMD_PHY_TIMEOUT; i++) {
+		usec_delay(50);
+		data_local = E1000_READ_REG(hw, E1000_I2CCMD);
+		if (data_local & E1000_I2CCMD_READY)
+			break;
+	}
+	if (!(data_local & E1000_I2CCMD_READY)) {
+		DEBUGOUT("I2CCMD Read did not complete\n");
+		return -E1000_ERR_PHY;
+	}
+	if (data_local & E1000_I2CCMD_ERROR) {
+		DEBUGOUT("I2CCMD Error bit set\n");
+		return -E1000_ERR_PHY;
+	}
+	*data = (u8) data_local & 0xFF;
+
+	return E1000_SUCCESS;
+}
+
+/**
+ *  e1000_write_sfp_data_byte - Writes SFP module data.
+ *  @hw: pointer to the HW structure
+ *  @offset: byte location offset to write to
+ *  @data: data to write
+ *
+ *  Writes one byte to SFP module data stored
+ *  in SFP resided EEPROM memory or SFP diagnostic area.
+ *  Function should be called with
+ *  E1000_I2CCMD_SFP_DATA_ADDR(<byte offset>) for SFP module database access
+ *  E1000_I2CCMD_SFP_DIAG_ADDR(<byte offset>) for SFP diagnostics parameters
+ *  access
+ **/
+s32 e1000_write_sfp_data_byte(struct e1000_hw *hw, u16 offset, u8 data)
+{
+	u32 i = 0;
+	u32 i2ccmd = 0;
+	u32 data_local = 0;
+
+	DEBUGFUNC("e1000_write_sfp_data_byte");
+
+	if (offset > E1000_I2CCMD_SFP_DIAG_ADDR(255)) {
+		DEBUGOUT("I2CCMD command address exceeds upper limit\n");
+		return -E1000_ERR_PHY;
+	}
+	/*
+	 * The programming interface is 16 bits wide
+	 * so we need to read the whole word first
+	 * then update appropriate byte lane and write
+	 * the updated word back.
+	 */
+	/*
+	 * Set up Op-code, EEPROM Address,in the I2CCMD
+	 * register. The MAC will take care of interfacing
+	 * with an EEPROM to write the data given.
+	 */
+	i2ccmd = ((offset << E1000_I2CCMD_REG_ADDR_SHIFT) |
+		  E1000_I2CCMD_OPCODE_READ);
+	/* Set a command to read single word */
+	E1000_WRITE_REG(hw, E1000_I2CCMD, i2ccmd);
+	for (i = 0; i < E1000_I2CCMD_PHY_TIMEOUT; i++) {
+		usec_delay(50);
+		/*
+		 * Poll the ready bit to see if lastly
+		 * launched I2C operation completed
+		 */
+		i2ccmd = E1000_READ_REG(hw, E1000_I2CCMD);
+		if (i2ccmd & E1000_I2CCMD_READY) {
+			/* Check if this is READ or WRITE phase */
+			if ((i2ccmd & E1000_I2CCMD_OPCODE_READ) ==
+			    E1000_I2CCMD_OPCODE_READ) {
+				/*
+				 * Write the selected byte
+				 * lane and update whole word
+				 */
+				data_local = i2ccmd & 0xFF00;
+				data_local |= data;
+				i2ccmd = ((offset <<
+				  E1000_I2CCMD_REG_ADDR_SHIFT) |
+				  E1000_I2CCMD_OPCODE_WRITE | data_local);
+				E1000_WRITE_REG(hw, E1000_I2CCMD, i2ccmd);
+			} else {
+				break;
+			}
+		}
+	}
+	if (!(i2ccmd & E1000_I2CCMD_READY)) {
+		DEBUGOUT("I2CCMD Write did not complete\n");
+		return -E1000_ERR_PHY;
+	}
+	if (i2ccmd & E1000_I2CCMD_ERROR) {
+		DEBUGOUT("I2CCMD Error bit set\n");
+		return -E1000_ERR_PHY;
+	}
+	return E1000_SUCCESS;
+}
+
+/**
  *  e1000_read_phy_reg_m88 - Read m88 PHY register
  *  @hw: pointer to the HW structure
  *  @offset: register offset to be read
@@ -402,6 +542,26 @@ out:
 }
 
 /**
+ *  e1000_set_page_igp - Set page as on IGP-like PHY(s)
+ *  @hw: pointer to the HW structure
+ *  @page: page to set (shifted left when necessary)
+ *
+ *  Sets PHY page required for PHY register access.  Assumes semaphore is
+ *  already acquired.  Note, this function sets phy.addr to 1 so the caller
+ *  must set it appropriately (if necessary) after this function returns.
+ **/
+s32 e1000_set_page_igp(struct e1000_hw *hw, u16 page)
+{
+	DEBUGFUNC("e1000_set_page_igp");
+
+	DEBUGOUT1("Setting page 0x%x\n", page);
+
+	hw->phy.addr = 1;
+
+	return e1000_write_phy_reg_mdic(hw, IGP01E1000_PHY_PAGE_SELECT, page);
+}
+
+/**
  *  __e1000_read_phy_reg_igp - Read igp PHY register
  *  @hw: pointer to the HW structure
  *  @offset: register offset to be read
@@ -579,6 +739,7 @@ static s32 __e1000_read_kmrn_reg(struct e1000_hw *hw, u32 offset, u16 *data,
 	kmrnctrlsta = ((offset << E1000_KMRNCTRLSTA_OFFSET_SHIFT) &
 	               E1000_KMRNCTRLSTA_OFFSET) | E1000_KMRNCTRLSTA_REN;
 	E1000_WRITE_REG(hw, E1000_KMRNCTRLSTA, kmrnctrlsta);
+	E1000_WRITE_FLUSH(hw);
 
 	usec_delay(2);
 
@@ -653,6 +814,7 @@ static s32 __e1000_write_kmrn_reg(struct e1000_hw *hw, u32 offset, u16 data,
 	kmrnctrlsta = ((offset << E1000_KMRNCTRLSTA_OFFSET_SHIFT) &
 	               E1000_KMRNCTRLSTA_OFFSET) | data;
 	E1000_WRITE_REG(hw, E1000_KMRNCTRLSTA, kmrnctrlsta);
+	E1000_WRITE_FLUSH(hw);
 
 	usec_delay(2);
 
@@ -717,7 +879,7 @@ s32 e1000_igb_copper_link_setup_82577(struct e1000_hw *hw)
 		}
 	}
 
-	/* Enable CRS on TX. This must be set for half-duplex operation. */
+	/* Enable CRS on Tx. This must be set for half-duplex operation. */
 	ret_val = hw->phy.ops.read_reg(hw, I82577_CFG_REG, &phy_data);
 	if (ret_val)
 		goto out;
@@ -843,6 +1005,91 @@ out:
 }
 
 /**
+ *  e1000_copper_link_setup_m88_gen2 - Setup m88 PHY's for copper link
+ *  @hw: pointer to the HW structure
+ *
+ *  Sets up MDI/MDI-X and polarity for i347-AT4, m88e1322 and m88e1112 PHY's.
+ *  Also enables and sets the downshift parameters.
+ **/
+s32 e1000_copper_link_setup_m88_gen2(struct e1000_hw *hw)
+{
+	struct e1000_phy_info *phy = &hw->phy;
+	s32 ret_val;
+	u16 phy_data;
+
+	DEBUGFUNC("e1000_copper_link_setup_m88_gen2");
+
+	if (phy->reset_disable) {
+		ret_val = E1000_SUCCESS;
+		goto out;
+	}
+
+	/* Enable CRS on Tx. This must be set for half-duplex operation. */
+	ret_val = phy->ops.read_reg(hw, M88E1000_PHY_SPEC_CTRL, &phy_data);
+	if (ret_val)
+		goto out;
+
+	/*
+	 * Options:
+	 *   MDI/MDI-X = 0 (default)
+	 *   0 - Auto for all speeds
+	 *   1 - MDI mode
+	 *   2 - MDI-X mode
+	 *   3 - Auto for 1000Base-T only (MDI-X for 10/100Base-T modes)
+	 */
+	phy_data &= ~M88E1000_PSCR_AUTO_X_MODE;
+
+	switch (phy->mdix) {
+	case 1:
+		phy_data |= M88E1000_PSCR_MDI_MANUAL_MODE;
+		break;
+	case 2:
+		phy_data |= M88E1000_PSCR_MDIX_MANUAL_MODE;
+		break;
+	case 3:
+		/* M88E1112 does not support this mode) */
+		if (phy->id != M88E1112_E_PHY_ID) {
+			phy_data |= M88E1000_PSCR_AUTO_X_1000T;
+			break;
+		}
+	case 0:
+	default:
+		phy_data |= M88E1000_PSCR_AUTO_X_MODE;
+		break;
+	}
+
+	/*
+	 * Options:
+	 *   disable_polarity_correction = 0 (default)
+	 *       Automatic Correction for Reversed Cable Polarity
+	 *   0 - Disabled
+	 *   1 - Enabled
+	 */
+	phy_data &= ~M88E1000_PSCR_POLARITY_REVERSAL;
+	if (phy->disable_polarity_correction == 1)
+		phy_data |= M88E1000_PSCR_POLARITY_REVERSAL;
+
+	/* Enable downshift and setting it to X6 */
+	phy_data &= ~I347AT4_PSCR_DOWNSHIFT_MASK;
+	phy_data |= I347AT4_PSCR_DOWNSHIFT_6X;
+	phy_data |= I347AT4_PSCR_DOWNSHIFT_ENABLE;
+
+	ret_val = phy->ops.write_reg(hw, M88E1000_PHY_SPEC_CTRL, phy_data);
+	if (ret_val)
+		goto out;
+
+	/* Commit the changes. */
+	ret_val = phy->ops.commit(hw);
+	if (ret_val) {
+		DEBUGOUT("Error committing the PHY changes\n");
+		goto out;
+	}
+
+out:
+	return ret_val;
+}
+
+/**
  *  e1000_copper_link_setup_igp - Setup igp PHY's for copper link
  *  @hw: pointer to the HW structure
  *
@@ -1268,21 +1515,21 @@ out:
 }
 
 /**
- *  e1000_phy_force_speed_duplex_igp - Force speed/duplex for igp PHY
+ *  e1000_igb_phy_force_speed_duplex_igp - Force speed/duplex for igp PHY
  *  @hw: pointer to the HW structure
  *
  *  Calls the PHY setup function to force speed and duplex.  Clears the
  *  auto-crossover to force MDI manually.  Waits for link and returns
  *  successful if link up is successful, else -E1000_ERR_PHY (-2).
  **/
-s32 e1000_phy_force_speed_duplex_igp(struct e1000_hw *hw)
+s32 e1000_igb_phy_force_speed_duplex_igp(struct e1000_hw *hw)
 {
 	struct e1000_phy_info *phy = &hw->phy;
 	s32 ret_val;
 	u16 phy_data;
 	bool link;
 
-	DEBUGFUNC("e1000_phy_force_speed_duplex_igp");
+	DEBUGFUNC("e1000_igb_phy_force_speed_duplex_igp");
 
 	ret_val = phy->ops.read_reg(hw, PHY_CONTROL, &phy_data);
 	if (ret_val)
@@ -1397,7 +1644,10 @@ s32 e1000_phy_force_speed_duplex_m88(struct e1000_hw *hw)
 			goto out;
 
 		if (!link) {
-			if (hw->phy.type != e1000_phy_m88) {
+			if (hw->phy.type != e1000_phy_m88 ||
+			    hw->phy.id == I347AT4_E_PHY_ID ||
+			    hw->phy.id == M88E1340M_E_PHY_ID ||
+			    hw->phy.id == M88E1112_E_PHY_ID) {
 				DEBUGOUT("Link taking longer than expected.\n");
 			} else {
 				/*
@@ -1422,7 +1672,10 @@ s32 e1000_phy_force_speed_duplex_m88(struct e1000_hw *hw)
 			goto out;
 	}
 
-	if (hw->phy.type != e1000_phy_m88)
+	if (hw->phy.type != e1000_phy_m88 ||
+	    hw->phy.id == I347AT4_E_PHY_ID ||
+	    hw->phy.id == M88E1340M_E_PHY_ID ||
+	    hw->phy.id == M88E1112_E_PHY_ID)
 		goto out;
 
 	ret_val = phy->ops.read_reg(hw, M88E1000_EXT_PHY_SPEC_CTRL, &phy_data);
@@ -1455,6 +1708,75 @@ out:
 }
 
 /**
+ *  e1000_igb_phy_force_speed_duplex_ife - Force PHY speed & duplex
+ *  @hw: pointer to the HW structure
+ *
+ *  Forces the speed and duplex settings of the PHY.
+ *  This is a function pointer entry point only called by
+ *  PHY setup routines.
+ **/
+s32 e1000_igb_phy_force_speed_duplex_ife(struct e1000_hw *hw)
+{
+	struct e1000_phy_info *phy = &hw->phy;
+	s32 ret_val;
+	u16 data;
+	bool link;
+
+	DEBUGFUNC("e1000_igb_phy_force_speed_duplex_ife");
+
+	ret_val = phy->ops.read_reg(hw, PHY_CONTROL, &data);
+	if (ret_val)
+		goto out;
+
+	e1000_phy_force_speed_duplex_setup(hw, &data);
+
+	ret_val = phy->ops.write_reg(hw, PHY_CONTROL, data);
+	if (ret_val)
+		goto out;
+
+	/* Disable MDI-X support for 10/100 */
+	ret_val = phy->ops.read_reg(hw, IFE_PHY_MDIX_CONTROL, &data);
+	if (ret_val)
+		goto out;
+
+	data &= ~IFE_PMC_AUTO_MDIX;
+	data &= ~IFE_PMC_FORCE_MDIX;
+
+	ret_val = phy->ops.write_reg(hw, IFE_PHY_MDIX_CONTROL, data);
+	if (ret_val)
+		goto out;
+
+	DEBUGOUT1("IFE PMC: %X\n", data);
+
+	usec_delay(1);
+
+	if (phy->autoneg_wait_to_complete) {
+		DEBUGOUT("Waiting for forced speed/duplex link on IFE phy.\n");
+
+		ret_val = e1000_phy_has_link_generic(hw,
+		                                     PHY_FORCE_LIMIT,
+		                                     100000,
+		                                     &link);
+		if (ret_val)
+			goto out;
+
+		if (!link)
+			DEBUGOUT("Link taking longer than expected.\n");
+
+		/* Try once more */
+		ret_val = e1000_phy_has_link_generic(hw,
+		                                     PHY_FORCE_LIMIT,
+		                                     100000,
+		                                     &link);
+		if (ret_val)
+			goto out;
+	}
+
+out:
+	return ret_val;
+}
+
+/**
  *  e1000_phy_force_speed_duplex_setup - Configure forced PHY speed/duplex
  *  @hw: pointer to the HW structure
  *  @phy_ctrl: pointer to current value of PHY_CONTROL
@@ -1724,6 +2046,41 @@ out:
 }
 
 /**
+ *  e1000_igb_check_polarity_ife - Check cable polarity for IFE PHY
+ *  @hw: pointer to the HW structure
+ *
+ *  Polarity is determined on the polarity reversal feature being enabled.
+ **/
+s32 e1000_igb_check_polarity_ife(struct e1000_hw *hw)
+{
+	struct e1000_phy_info *phy = &hw->phy;
+	s32 ret_val;
+	u16 phy_data, offset, mask;
+
+	DEBUGFUNC("e1000_igb_check_polarity_ife");
+
+	/*
+	 * Polarity is determined based on the reversal feature being enabled.
+	 */
+	if (phy->polarity_correction) {
+		offset = IFE_PHY_EXTENDED_STATUS_CONTROL;
+		mask = IFE_PESC_POLARITY_REVERSED;
+	} else {
+		offset = IFE_PHY_SPECIAL_CONTROL;
+		mask = IFE_PSC_FORCE_POLARITY;
+	}
+
+	ret_val = phy->ops.read_reg(hw, offset, &phy_data);
+
+	if (!ret_val)
+		phy->cable_polarity = (phy_data & mask)
+		                       ? e1000_rev_polarity_reversed
+		                       : e1000_rev_polarity_normal;
+
+	return ret_val;
+}
+
+/**
  *  e1000_wait_autoneg_generic - Wait for auto-neg completion
  *  @hw: pointer to the HW structure
  *
@@ -1847,6 +2204,96 @@ out:
 	return ret_val;
 }
 
+s32 e1000_get_cable_length_m88_gen2(struct e1000_hw *hw)
+{
+	struct e1000_phy_info *phy = &hw->phy;
+	s32 ret_val;
+	u16 phy_data, phy_data2, index, default_page, is_cm;
+
+	DEBUGFUNC("e1000_get_cable_length_m88_gen2");
+
+	switch (hw->phy.id) {
+	case M88E1340M_E_PHY_ID:
+	case I347AT4_E_PHY_ID:
+		/* Remember the original page select and set it to 7 */
+		ret_val = phy->ops.read_reg(hw, I347AT4_PAGE_SELECT,
+					    &default_page);
+		if (ret_val)
+			goto out;
+
+		ret_val = phy->ops.write_reg(hw, I347AT4_PAGE_SELECT, 0x07);
+		if (ret_val)
+			goto out;
+
+		/* Get cable length from PHY Cable Diagnostics Control Reg */
+		ret_val = phy->ops.read_reg(hw, (I347AT4_PCDL + phy->addr),
+					    &phy_data);
+		if (ret_val)
+			goto out;
+
+		/* Check if the unit of cable length is meters or cm */
+		ret_val = phy->ops.read_reg(hw, I347AT4_PCDC, &phy_data2);
+		if (ret_val)
+			goto out;
+
+		is_cm = !(phy_data & I347AT4_PCDC_CABLE_LENGTH_UNIT);
+
+		/* Populate the phy structure with cable length in meters */
+		phy->min_cable_length = phy_data / (is_cm ? 100 : 1);
+		phy->max_cable_length = phy_data / (is_cm ? 100 : 1);
+		phy->cable_length = phy_data / (is_cm ? 100 : 1);
+
+		/* Reset the page selec	to its original value */
+		ret_val = phy->ops.write_reg(hw, I347AT4_PAGE_SELECT,
+					     default_page);
+		if (ret_val)
+			goto out;
+		break;
+	case M88E1112_E_PHY_ID:
+		/* Remember the original page select and set it to 5 */
+		ret_val = phy->ops.read_reg(hw, I347AT4_PAGE_SELECT,
+					    &default_page);
+		if (ret_val)
+			goto out;
+
+		ret_val = phy->ops.write_reg(hw, I347AT4_PAGE_SELECT, 0x05);
+		if (ret_val)
+			goto out;
+
+		ret_val = phy->ops.read_reg(hw, M88E1112_VCT_DSP_DISTANCE,
+					    &phy_data);
+		if (ret_val)
+			goto out;
+
+		index = (phy_data & M88E1000_PSSR_CABLE_LENGTH) >>
+			M88E1000_PSSR_CABLE_LENGTH_SHIFT;
+		if (index >= M88E1000_CABLE_LENGTH_TABLE_SIZE - 1) {
+			ret_val = -E1000_ERR_PHY;
+			goto out;
+		}
+
+		phy->min_cable_length = e1000_m88_cable_length_table[index];
+		phy->max_cable_length = e1000_m88_cable_length_table[index + 1];
+
+		phy->cable_length = (phy->min_cable_length +
+				     phy->max_cable_length) / 2;
+
+		/* Reset the page select to its original value */
+		ret_val = phy->ops.write_reg(hw, I347AT4_PAGE_SELECT,
+					     default_page);
+		if (ret_val)
+			goto out;
+
+		break;
+	default:
+		ret_val = -E1000_ERR_PHY;
+		goto out;
+	}
+
+out:
+	return ret_val;
+}
+
 /**
  *  e1000_get_cable_length_igp_2 - Determine cable length for igp2 PHY
  *  @hw: pointer to the HW structure
@@ -1865,11 +2312,12 @@ s32 e1000_get_cable_length_igp_2(struct e1000_hw *hw)
 	u16 phy_data, i, agc_value = 0;
 	u16 cur_agc_index, max_agc_index = 0;
 	u16 min_agc_index = IGP02E1000_CABLE_LENGTH_TABLE_SIZE - 1;
-	u16 agc_reg_array[IGP02E1000_PHY_CHANNEL_NUM] =
-	                                                 {IGP02E1000_PHY_AGC_A,
-	                                                  IGP02E1000_PHY_AGC_B,
-	                                                  IGP02E1000_PHY_AGC_C,
-	                                                  IGP02E1000_PHY_AGC_D};
+	static const u16 agc_reg_array[IGP02E1000_PHY_CHANNEL_NUM] = {
+	       IGP02E1000_PHY_AGC_A,
+	       IGP02E1000_PHY_AGC_B,
+	       IGP02E1000_PHY_AGC_C,
+	       IGP02E1000_PHY_AGC_D
+	};
 
 	DEBUGFUNC("e1000_get_cable_length_igp_2");
 
@@ -2068,6 +2516,63 @@ out:
 }
 
 /**
+ *  e1000_igb_get_phy_info_ife - Retrieves various IFE PHY states
+ *  @hw: pointer to the HW structure
+ *
+ *  Populates "phy" structure with various feature states.
+ **/
+s32 e1000_igb_get_phy_info_ife(struct e1000_hw *hw)
+{
+	struct e1000_phy_info *phy = &hw->phy;
+	s32 ret_val;
+	u16 data;
+	bool link;
+
+	DEBUGFUNC("e1000_igb_get_phy_info_ife");
+
+	ret_val = e1000_phy_has_link_generic(hw, 1, 0, &link);
+	if (ret_val)
+		goto out;
+
+	if (!link) {
+		DEBUGOUT("Phy info is only valid if link is up\n");
+		ret_val = -E1000_ERR_CONFIG;
+		goto out;
+	}
+
+	ret_val = phy->ops.read_reg(hw, IFE_PHY_SPECIAL_CONTROL, &data);
+	if (ret_val)
+		goto out;
+	phy->polarity_correction = (data & IFE_PSC_AUTO_POLARITY_DISABLE)
+	                           ? false : true;
+
+	if (phy->polarity_correction) {
+		ret_val = e1000_igb_check_polarity_ife(hw);
+		if (ret_val)
+			goto out;
+	} else {
+		/* Polarity is forced */
+		phy->cable_polarity = (data & IFE_PSC_FORCE_POLARITY)
+		                      ? e1000_rev_polarity_reversed
+		                      : e1000_rev_polarity_normal;
+	}
+
+	ret_val = phy->ops.read_reg(hw, IFE_PHY_MDIX_CONTROL, &data);
+	if (ret_val)
+		goto out;
+
+	phy->is_mdix = (data & IFE_PMC_MDIX_STATUS) ? true : false;
+
+	/* The following parameters are undefined for 10/100 operation. */
+	phy->cable_length = E1000_CABLE_LENGTH_UNDEFINED;
+	phy->local_rx = e1000_1000t_rx_status_undefined;
+	phy->remote_rx = e1000_1000t_rx_status_undefined;
+
+out:
+	return ret_val;
+}
+
+/**
  *  e1000_phy_sw_reset_generic - PHY software reset
  *  @hw: pointer to the HW structure
  *
@@ -2258,6 +2763,9 @@ enum e1000_phy_type e1000_get_phy_type_from_id(u32 phy_id)
 	case M88E1000_E_PHY_ID:
 	case M88E1111_I_PHY_ID:
 	case M88E1011_I_PHY_ID:
+	case I347AT4_E_PHY_ID:
+	case M88E1112_E_PHY_ID:
+	case M88E1340M_E_PHY_ID:
 		phy_type = e1000_phy_m88;
 		break;
 	case IGP01E1000_I_PHY_ID: /* IGP 1 & 2 share this */
@@ -2313,7 +2821,7 @@ s32 e1000_determine_phy_address(struct e1000_hw *hw)
 			 * If phy_type is valid, break - we found our
 			 * PHY address
 			 */
-			if (phy_type  != e1000_phy_unknown) {
+			if (phy_type != e1000_phy_unknown) {
 				ret_val = E1000_SUCCESS;
 				goto out;
 			}
diff --git a/drivers/net/igb/e1000_phy.h b/drivers/net/igb/e1000_phy.h
index 0926855..3094c4e 100644
--- a/drivers/net/igb/e1000_phy.h
+++ b/drivers/net/igb/e1000_phy.h
@@ -32,23 +32,29 @@ void e1000_init_phy_ops_generic(struct e1000_hw *hw);
 s32  e1000_check_downshift_generic(struct e1000_hw *hw);
 s32  e1000_igb_check_polarity_m88(struct e1000_hw *hw);
 s32  e1000_igb_check_polarity_igp(struct e1000_hw *hw);
+s32  e1000_igb_check_polarity_ife(struct e1000_hw *hw);
 s32  e1000_check_reset_block_generic(struct e1000_hw *hw);
 s32  e1000_copper_link_setup_igp(struct e1000_hw *hw);
 s32  e1000_copper_link_setup_m88(struct e1000_hw *hw);
-s32  e1000_phy_force_speed_duplex_igp(struct e1000_hw *hw);
+s32  e1000_copper_link_setup_m88_gen2(struct e1000_hw *hw);
+s32  e1000_igb_phy_force_speed_duplex_igp(struct e1000_hw *hw);
 s32  e1000_phy_force_speed_duplex_m88(struct e1000_hw *hw);
+s32  e1000_igb_phy_force_speed_duplex_ife(struct e1000_hw *hw);
 s32  e1000_get_cable_length_m88(struct e1000_hw *hw);
+s32  e1000_get_cable_length_m88_gen2(struct e1000_hw *hw);
 s32  e1000_get_cable_length_igp_2(struct e1000_hw *hw);
 s32  e1000_get_cfg_done_generic(struct e1000_hw *hw);
 s32  e1000_get_phy_id(struct e1000_hw *hw);
 s32  e1000_get_phy_info_igp(struct e1000_hw *hw);
 s32  e1000_get_phy_info_m88(struct e1000_hw *hw);
+s32  e1000_igb_get_phy_info_ife(struct e1000_hw *hw);
 s32  e1000_phy_sw_reset_generic(struct e1000_hw *hw);
 void e1000_phy_force_speed_duplex_setup(struct e1000_hw *hw, u16 *phy_ctrl);
 s32  e1000_phy_hw_reset_generic(struct e1000_hw *hw);
 s32  e1000_phy_reset_dsp_generic(struct e1000_hw *hw);
 s32  e1000_read_kmrn_reg_generic(struct e1000_hw *hw, u32 offset, u16 *data);
 s32  e1000_read_kmrn_reg_locked(struct e1000_hw *hw, u32 offset, u16 *data);
+s32  e1000_set_page_igp(struct e1000_hw *hw, u16 page);
 s32  e1000_read_phy_reg_igp(struct e1000_hw *hw, u32 offset, u16 *data);
 s32  e1000_read_phy_reg_igp_locked(struct e1000_hw *hw, u32 offset, u16 *data);
 s32  e1000_read_phy_reg_m88(struct e1000_hw *hw, u32 offset, u16 *data);
@@ -68,6 +74,8 @@ enum e1000_phy_type e1000_get_phy_type_from_id(u32 phy_id);
 s32  e1000_determine_phy_address(struct e1000_hw *hw);
 void e1000_igb_power_up_phy_copper(struct e1000_hw *hw);
 void e1000_igb_power_down_phy_copper(struct e1000_hw *hw);
+s32  e1000_enable_phy_wakeup_reg_access_bm(struct e1000_hw *hw, u16 *phy_reg);
+s32  e1000_disable_phy_wakeup_reg_access_bm(struct e1000_hw *hw, u16 *phy_reg);
 s32  e1000_read_phy_reg_mdic(struct e1000_hw *hw, u32 offset, u16 *data);
 s32  e1000_write_phy_reg_mdic(struct e1000_hw *hw, u32 offset, u16 data);
 s32  e1000_read_phy_reg_i2c(struct e1000_hw *hw, u32 offset, u16 *data);
@@ -77,8 +85,10 @@ s32  e1000_igb_check_polarity_82577(struct e1000_hw *hw);
 s32  e1000_igb_get_phy_info_82577(struct e1000_hw *hw);
 s32  e1000_igb_phy_force_speed_duplex_82577(struct e1000_hw *hw);
 s32  e1000_igb_get_cable_length_82577(struct e1000_hw *hw);
+s32  e1000_phy_force_speed_duplex_82577(struct e1000_hw *hw);
+s32  e1000_read_sfp_data_byte(struct e1000_hw *hw, u16 offset, u8 *data);
 
-#define E1000_MAX_PHY_ADDR                4
+#define E1000_MAX_PHY_ADDR                8
 
 /* IGP01E1000 Specific Registers */
 #define IGP01E1000_PHY_PORT_CONFIG        0x10 /* Port Config */
@@ -122,6 +132,12 @@ s32  e1000_igb_get_cable_length_82577(struct e1000_hw *hw);
 #define I82577_DSTATUS_CABLE_LENGTH       0x03FC
 #define I82577_DSTATUS_CABLE_LENGTH_SHIFT 2
 
+/* 82580 PHY Power Management */
+#define E1000_82580_PHY_POWER_MGMT        0xE14
+#define E1000_82580_PM_SPD                0x0001 /* Smart Power Down */
+#define E1000_82580_PM_D0_LPLU            0x0002 /* For D0a states */
+#define E1000_82580_PM_D3_LPLU            0x0004 /* For all other states */
+
 #define IGP01E1000_PHY_PCS_INIT_REG       0x00B4
 #define IGP01E1000_PHY_POLARITY_MASK      0x0078
 
@@ -166,6 +182,7 @@ s32  e1000_igb_get_cable_length_82577(struct e1000_hw *hw);
 #define E1000_KMRNCTRLSTA_DIAG_OFFSET     0x3    /* Kumeran Diagnostic */
 #define E1000_KMRNCTRLSTA_TIMEOUTS        0x4    /* Kumeran Timeouts */
 #define E1000_KMRNCTRLSTA_INBAND_PARAM    0x9    /* Kumeran InBand Parameters */
+#define E1000_KMRNCTRLSTA_IBIST_DISABLE   0x0200 /* Kumeran IBIST Disable */
 #define E1000_KMRNCTRLSTA_DIAG_NELPBK     0x1000 /* Nearend Loopback mode */
 
 #define IFE_PHY_EXTENDED_STATUS_CONTROL 0x10
@@ -191,4 +208,28 @@ s32  e1000_igb_get_cable_length_82577(struct e1000_hw *hw);
 #define IFE_PMC_FORCE_MDIX       0x0040 /* 1=force MDI-X, 0=force MDI */
 #define IFE_PMC_AUTO_MDIX        0x0080 /* 1=enable auto MDI/MDI-X, 0=disable */
 
+/* SFP modules ID memory locations */
+#define E1000_SFF_IDENTIFIER_OFFSET 0x00
+#define E1000_SFF_IDENTIFIER_SFF    0x02
+#define E1000_SFF_IDENTIFIER_SFP    0x03
+
+#define E1000_SFF_ETH_FLAGS_OFFSET  0x06
+/* Flags for SFP modules compatible with ETH up to 1Gb */
+struct sfp_e1000_flags {
+	u8 e1000_base_sx:1;
+	u8 e1000_base_lx:1;
+	u8 e1000_base_cx:1;
+	u8 e1000_base_t:1;
+	u8 e100_base_lx:1;
+	u8 e100_base_fx:1;
+	u8 e10_base_bx10:1;
+	u8 e10_base_px:1;
+};
+
+/* Vendor OUIs: format of OUI is 0x[byte0][byte1][byte2][00] */
+#define E1000_SFF_VENDOR_OUI_TYCO     0x00407600
+#define E1000_SFF_VENDOR_OUI_FTL      0x00906500
+#define E1000_SFF_VENDOR_OUI_AVAGO    0x00176A00
+#define E1000_SFF_VENDOR_OUI_INTEL    0x001B2100
+
 #endif
diff --git a/drivers/net/igb/e1000_regs.h b/drivers/net/igb/e1000_regs.h
index d92c486..13b93c2 100644
--- a/drivers/net/igb/e1000_regs.h
+++ b/drivers/net/igb/e1000_regs.h
@@ -39,9 +39,11 @@
 #define E1000_MDICNFG  0x00E04  /* MDI Config - RW */
 #define E1000_REGISTER_SET_SIZE        0x20000 /* CSR Size */
 #define E1000_EEPROM_INIT_CTRL_WORD_2  0x0F /* EEPROM Init Ctrl Word 2 */
+#define E1000_EEPROM_PCIE_CTRL_WORD_2  0x28 /* EEPROM PCIe Ctrl Word 2 */
 #define E1000_BARCTRL                  0x5BBC /* BAR ctrl reg */
 #define E1000_BARCTRL_FLSIZE           0x0700 /* BAR ctrl Flsize */
 #define E1000_BARCTRL_CSRSIZE          0x2000 /* BAR ctrl CSR size */
+#define E1000_I350_BARCTRL             0x5BFC /* BAR ctrl reg */
 #define E1000_SCTL     0x00024  /* SerDes Control - RW */
 #define E1000_FCAL     0x00028  /* Flow Control Address Low - RW */
 #define E1000_FCAH     0x0002C  /* Flow Control Address High -RW */
@@ -118,6 +120,7 @@
 #define E1000_PBDIAG   0x02458  /* Packet Buffer Diagnostic - RW */
 #define E1000_RXPBS    0x02404  /* Rx Packet Buffer Size - RW */
 #define E1000_IRPBS 0x02404 /* Same as RXPBS, renamed for newer adapters - RW */
+#define E1000_PBRWAC   0x024E8 /* Rx packet buffer wrap around counter - RO */
 #define E1000_RDTR     0x02820  /* Rx Delay Timer - RW */
 #define E1000_RADV     0x0282C  /* Rx Interrupt Absolute Delay Timer - RW */
 /*
@@ -408,6 +411,7 @@
 #define E1000_UFUSE     0x05B78 /* UFUSE - RO */
 #define E1000_FFLT_DBG  0x05F04 /* Debug Register */
 #define E1000_HICR      0x08F00 /* Host Interface Control */
+#define E1000_FWSTS     0x08F0C /* FW Status */
 
 /* RSS registers */
 #define E1000_CPUVEC    0x02C10 /* CPU Vector Register - RW */
@@ -439,10 +443,19 @@
 #define E1000_VFTE      0x00C90 /* VF Transmit Enables */
 #define E1000_QDE       0x02408 /* Queue Drop Enable - RW */
 #define E1000_DTXSWC    0x03500 /* DMA Tx Switch Control - RW */
+#define E1000_WVBR      0x03554 /* VM Wrong Behavior - RWS */
 #define E1000_RPLOLR    0x05AF0 /* Replication Offload - RW */
 #define E1000_UTA       0x0A000 /* Unicast Table Array - RW */
 #define E1000_IOVTCL    0x05BBC /* IOV Control Register */
 #define E1000_VMRCTL    0X05D80 /* Virtual Mirror Rule Control */
+#define E1000_VMRVLAN   0x05D90 /* Virtual Mirror Rule VLAN */
+#define E1000_VMRVM     0x05DA0 /* Virtual Mirror Rule VM */
+#define E1000_MDFB      0x03558 /* Malicious Driver free block */
+#define E1000_LVMMC     0x03548 /* Last VM Misbehavior cause */
+#define E1000_TXSWC     0x05ACC /* Tx Switch Control */
+#define E1000_SCCRL     0x05DB0 /* Storm Control Control */
+#define E1000_BSCTRH    0x05DB8 /* Broadcast Storm Control Threshold */
+#define E1000_MSCTRH    0x05DBC /* Multicast Storm Control Threshold */
 /* These act per VF so an array friendly macro is used */
 #define E1000_V2PMAILBOX(_n)   (0x00C40 + (4 * (_n)))
 #define E1000_P2VMAILBOX(_n)   (0x00C00 + (4 * (_n)))
@@ -452,6 +465,8 @@
 #define E1000_VLVF(_n)         (0x05D00 + (4 * (_n))) /* VLAN Virtual Machine
                                                        * Filter - RW */
 #define E1000_VMVIR(_n)        (0x03700 + (4 * (_n)))
+#define E1000_DVMOLR(_n)       (0x0C038 + (0x40 * (_n))) /* DMA VM offload */
+#define E1000_VTCTRL(_n)       (0x10000 + (0x100 * (_n))) /* VT Control */
 /* Time Sync */
 #define E1000_TSYNCRXCTL 0x0B620 /* Rx Time Sync Control register - RW */
 #define E1000_TSYNCTXCTL 0x0B614 /* Tx Time Sync Control register - RW */
@@ -513,12 +528,34 @@
 #define E1000_DMCTXTH           0x03550 /* Transmit Threshold */
 #define E1000_DMCTLX            0x02514 /* Time to Lx Request */
 #define E1000_DMCRTRH           0x05DD0 /* Receive Packet Rate Threshold */
-#define E1000_DMCCNT            0x05DD4 /* Current RX Count */
+#define E1000_DMCCNT            0x05DD4 /* Current Rx Count */
 #define E1000_FCRTC             0x02170 /* Flow Control Rx high watermark */
 #define E1000_PCIEMISC          0x05BB8 /* PCIE misc config register */
 
 /* PCIe Parity Status Register */
 #define E1000_PCIEERRSTS        0x05BA8
 
+#define E1000_PROXYS            0x5F64 /* Proxying Status */
+#define E1000_PROXYFC           0x5F60 /* Proxying Filter Control */
+/* Thermal sensor configuration and status registers */
+#define E1000_THMJT             0x08100 /* Junction Temperature */
+#define E1000_THLOWTC           0x08104 /* Low Threshold Control */
+#define E1000_THMIDTC           0x08108 /* Mid Threshold Control */
+#define E1000_THHIGHTC          0x0810C /* High Threshold Control */
+#define E1000_THSTAT            0x08110 /* Thermal Sensor Status */
+
+/*Energy Efficient Ethernet "EEE" registers */
+#define E1000_IPCNFG            0x0E38 /* Internal PHY Configuration */
+#define E1000_LTRC              0x01A0 /* Latency Tolerance Reporting Control */
+#define E1000_EEER              0x0E30 /* Energy Efficient Ethernet "EEE"*/
+#define E1000_EEE_SU            0x0E34 /* EEE Setup */
+#define E1000_TLPIC             0x4148 /* EEE Tx LPI Count - TLPIC */
+#define E1000_RLPIC             0x414C /* EEE Rx LPI Count - RLPIC */
+
+/* OS2BMC Registers */
+#define E1000_B2OSPC            0x08FE0 /* BMC2OS packets sent by BMC */
+#define E1000_B2OGPRC           0x04158 /* BMC2OS packets received by host */
+#define E1000_O2BGPTC           0x08FE4 /* OS2BMC packets received by BMC */
+#define E1000_O2BSPC            0x0415C /* OS2BMC packets transmitted by host */
 
 #endif
diff --git a/drivers/net/igb/igb.h b/drivers/net/igb/igb.h
index 978a59b..26a1f80 100644
--- a/drivers/net/igb/igb.h
+++ b/drivers/net/igb/igb.h
@@ -25,7 +25,6 @@
 
 *******************************************************************************/
 
-
 /* Linux PRO/1000 Ethernet Driver main header file */
 
 #ifndef _IGB_H_
@@ -43,7 +42,7 @@
 #include <linux/ethtool.h>
 #endif
 
-#ifdef SIOCSHWTSTAMP
+#ifdef HAVE_HW_TIME_STAMP
 #include <linux/clocksource.h>
 #include <linux/timecompare.h>
 #include <linux/net_tstamp.h>
@@ -58,7 +57,7 @@ struct igb_adapter;
 #include <linux/dca.h>
 #endif
 
-#ifndef SIOCSHWTSTAMP
+#ifndef HAVE_HW_TIME_STAMP
 #undef IGB_PER_PKT_TIMESTAMP
 #endif
 
@@ -67,6 +66,7 @@ struct igb_adapter;
 
 #include "e1000_api.h"
 #include "e1000_82575.h"
+#include "e1000_manage.h"
 
 #define IGB_ERR(args...) printk(KERN_ERR "igb: " args)
 
@@ -112,6 +112,7 @@ struct igb_adapter;
 #define IGB_MAX_UTA_ENTRIES              128
 #define MAX_EMULATION_MAC_ADDRS           16
 #define OUI_LEN                            3
+#define IGB_MAX_VMDQ_QUEUES                8
 
 struct vf_data_storage {
 	unsigned char vf_mac_addresses[ETH_ALEN];
@@ -126,6 +127,7 @@ struct vf_data_storage {
 #ifdef IFLA_VF_MAX
 	u16 pf_vlan; /* When set, guest VLAN config not allowed. */
 	u16 pf_qos;
+	u16 tx_rate;
 #endif
 };
 
@@ -181,8 +183,10 @@ struct vf_data_storage {
 /* How many Rx Buffers do we bundle into one write to the hardware ? */
 #define IGB_RX_BUFFER_WRITE	16	/* Must be power of 2 */
 
-#define AUTO_ALL_MODES            0
 #define IGB_EEPROM_APME         0x0400
+#ifndef ETH_TP_MDI_X
+#define AUTO_ALL_MODES          0
+#endif
 
 #ifndef IGB_MASTER_SLAVE
 /* Switch to override PHY master/slave setting */
@@ -244,8 +248,8 @@ struct igb_buffer {
 #ifdef NETIF_F_TSO
 			u16 gso_segs;
 #endif
-#ifdef SIOCSHWTSTAMP
-			union skb_shared_tx shtx;
+#ifdef HAVE_HW_TIME_STAMP
+			u8 shtx;
 #endif
 			u8 mapped_as_page;
 		};
@@ -333,10 +337,14 @@ struct igb_ring {
 #endif
 		};
 	};
-
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+	struct net_device *vmdq_netdev;
+	int vqueue_index;		/* queue index for virtual netdev */
+#endif
 	/* Items past this point are only used during ring alloc / free */
 	dma_addr_t dma;                 /* phys address of the ring */
 	int numa_node;                  /* node to alloc ring memory on */
+
 } ____cacheline_internodealigned_in_smp;
 
 enum e1000_ring_flags_t {
@@ -345,9 +353,21 @@ enum e1000_ring_flags_t {
 #ifdef IGB_LRO
 	IGB_RING_FLAG_RX_LRO,
 #endif /* IGB_LRO */
+	IGB_RING_FLAG_RX_LB_VLAN_BSWAP,
 	IGB_RING_FLAG_TX_CTX_IDX,
-	IGB_RING_FLAG_TX_DETECT_HANG
+	IGB_RING_FLAG_TX_DETECT_HANG,
+#ifdef NETIF_F_RXHASH
+	IGB_RING_FLAG_RX_HASH
+#endif
+};
+struct igb_mac_addr {
+	u8 addr[ETH_ALEN];
+	u16 queue;
+	u16 state; /* bitmask */
 };
+#define IGB_MAC_STATE_DEFAULT	0x1
+#define IGB_MAC_STATE_MODIFIED	0x2
+#define IGB_MAC_STATE_IN_USE	0x4
 
 #define IGB_TXD_DCMD (E1000_ADVTXD_DCMD_EOP | E1000_ADVTXD_DCMD_RS)
 
@@ -358,6 +378,16 @@ enum e1000_ring_flags_t {
 #define IGB_TX_CTXTDESC(R, i)	    \
 	(&(((struct e1000_adv_tx_context_desc *)((R)->desc))[i]))
 
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+#define netdev_ring(ring) \
+	((ring->vmdq_netdev ? ring->vmdq_netdev : ring->netdev))
+#define ring_queue_index(ring) \
+	((ring->vmdq_netdev ? ring->vqueue_index : ring->queue_index))
+#else
+#define netdev_ring(ring) (ring->netdev)
+#define ring_queue_index(ring) (ring->queue_index)
+#endif /* CONFIG_IGB_VMDQ_NETDEV */
+
 /* igb_desc_unused - calculate if we have unused descriptors */
 static inline u16 igb_desc_unused(const struct igb_ring *ring)
 {
@@ -405,10 +435,6 @@ struct igb_adapter {
 	struct work_struct watchdog_task;
 	bool fc_autoneg;
 	u8  tx_timeout_factor;
-#ifdef ETHTOOL_PHYS_ID
-	struct timer_list blink_timer;
-	unsigned long led_status;
-#endif
 
 	u32 max_frame_size;
 
@@ -420,7 +446,7 @@ struct igb_adapter {
 #ifdef IGB_LRO
 	struct igb_lro_stats lro_stats;
 #endif
-#ifdef SIOCSHWTSTAMP
+#ifdef HAVE_HW_TIME_STAMP
 	struct cyclecounter cycles;
 	struct timecounter clock;
 	struct timecompare compare;
@@ -452,16 +478,37 @@ struct igb_adapter {
 	u16 tx_ring_count;
 	u16 rx_ring_count;
 	struct vf_data_storage *vf_data;
+#ifdef IFLA_VF_MAX
+	int vf_rate_link_speed;
+#endif
 	u32 lli_port;
 	u32 lli_size;
 	unsigned int vfs_allocated_count;
+	/* Malicious Driver Detection flag. Valid only when SR-IOV is enabled */
+	bool mdd;
 	int int_mode;
 	u32 rss_queues;
 	u32 vmdq_pools;
 	u16 fw_version;
 	int node;
 	u32 wvbr;
+	struct igb_mac_addr *mac_table;
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+	struct net_device *vmdq_netdev[IGB_MAX_VMDQ_QUEUES];
+#endif
+	int dmac;
+};
+
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+struct igb_vmdq_adapter {
+	struct igb_adapter *real_adapter;
+	struct net_device *vnetdev;
+	struct net_device_stats net_stats;
+	struct igb_ring *tx_ring;
+	struct igb_ring *rx_ring;
+	struct vlan_group *vlgrp;
 };
+#endif
 
 
 #define IGB_FLAG_HAS_MSI           (1 << 0)
@@ -472,9 +519,58 @@ struct igb_adapter {
 #define IGB_FLAG_QUEUE_PAIRS       (1 << 5)
 #define IGB_FLAG_EEE               (1 << 6)
 
+#define IGB_MIN_TXPBSIZE           20408
+#define IGB_TX_BUF_4096            4096
+
+#define IGB_DMCTLX_DCFLUSH_DIS     0x80000000  /* Disable DMA Coal Flush */
+
+/* DMA Coalescing defines */
+#define IGB_DMAC_DISABLE          0
+#define IGB_DMAC_MIN            250
+#define IGB_DMAC_500            500
+#define IGB_DMAC_EN_DEFAULT    1000
+#define IGB_DMAC_2000          2000
+#define IGB_DMAC_3000          3000
+#define IGB_DMAC_4000          4000
+#define IGB_DMAC_5000          5000
+#define IGB_DMAC_6000          6000
+#define IGB_DMAC_7000          7000
+#define IGB_DMAC_8000          8000
+#define IGB_DMAC_9000          9000
+#define IGB_DMAC_MAX          10000
+
+
 #define IGB_82576_TSYNC_SHIFT 19
 #define IGB_82580_TSYNC_SHIFT 24
 #define IGB_TS_HDR_LEN        16
+
+/* CEM Support */
+#define FW_HDR_LEN           0x4
+#define FW_CMD_DRV_INFO      0xDD
+#define FW_CMD_DRV_INFO_LEN  0x5
+#define FW_CMD_RESERVED      0X0
+#define FW_RESP_SUCCESS      0x1
+#define FW_UNUSED_VER        0x0
+#define FW_MAX_RETRIES       3
+#define FW_STATUS_SUCCESS    0x1
+
+struct e1000_fw_hdr {
+	u8 cmd;
+	u8 buf_len;
+	union
+	{
+		u8 cmd_resv;
+		u8 ret_status;
+	} cmd_or_resp;
+	u8 checksum;
+};
+struct e1000_fw_drv_info {
+	struct e1000_fw_hdr hdr;
+	u8 port_num;
+	u32 drv_version;
+	u16 pad; /* end spacing to ensure length is mult. of dword */
+	u8  pad2; /* end spacing to ensure length is mult. of dword2 */
+};
 enum e1000_state_t {
 	__IGB_TESTING,
 	__IGB_RESETTING,
@@ -497,10 +593,11 @@ extern void igb_configure_tx_ring(struct igb_adapter *, struct igb_ring *);
 extern void igb_configure_rx_ring(struct igb_adapter *, struct igb_ring *);
 extern void igb_setup_tctl(struct igb_adapter *);
 extern void igb_setup_rctl(struct igb_adapter *);
-extern netdev_tx_t igb_xmit_frame_ring(struct sk_buff *, struct igb_ring *, bool);
+extern netdev_tx_t igb_xmit_frame_ring(struct sk_buff *, struct igb_ring *);
 extern void igb_unmap_and_free_tx_resource(struct igb_ring *,
                                            struct igb_buffer *);
 extern void igb_alloc_rx_buffers(struct igb_ring *, u16);
+extern void igb_clean_rx_ring(struct igb_ring *);
 extern void igb_update_stats(struct igb_adapter *);
 extern bool igb_has_link(struct igb_adapter *adapter);
 extern void igb_set_ethtool_ops(struct net_device *);
@@ -509,7 +606,12 @@ extern void igb_power_up_link(struct igb_adapter *);
 #ifdef ETHTOOL_OPS_COMPAT
 extern int ethtool_ioctl(struct ifreq *);
 #endif
+extern int igb_write_mc_addr_list(struct net_device *netdev);
+extern int igb_add_mac_filter(struct igb_adapter *adapter, u8 *addr, u16 queue);
+extern int igb_del_mac_filter(struct igb_adapter *adapter, u8* addr, u16 queue);
+extern int igb_available_rars(struct igb_adapter *adapter);
 extern s32 igb_vlvf_set(struct igb_adapter *, u32, bool, u32);
 extern void igb_configure_vt_default_pool(struct igb_adapter *adapter);
+extern void igb_enable_vlan_tags(struct igb_adapter *adapter);
 
 #endif /* _IGB_H_ */
diff --git a/drivers/net/igb/igb_ethtool.c b/drivers/net/igb/igb_ethtool.c
index 5beaffd..582e9fe 100644
--- a/drivers/net/igb/igb_ethtool.c
+++ b/drivers/net/igb/igb_ethtool.c
@@ -94,6 +94,10 @@ static const struct igb_stats igb_gstrings_stats[] = {
 	IGB_STAT("tx_smbus", stats.mgptc),
 	IGB_STAT("rx_smbus", stats.mgprc),
 	IGB_STAT("dropped_smbus", stats.mgpdc),
+	IGB_STAT("os2bmc_rx_by_bmc", stats.o2bgptc),
+	IGB_STAT("os2bmc_tx_by_bmc", stats.b2ospc),
+	IGB_STAT("os2bmc_tx_by_host", stats.o2bspc),
+	IGB_STAT("os2bmc_rx_by_host", stats.b2ogprc),
 };
 
 #define IGB_NETDEV_STAT(_net_stat) { \
@@ -199,6 +203,17 @@ static int igb_get_settings(struct net_device *netdev, struct ethtool_cmd *ecmd)
 	}
 
 	ecmd->autoneg = hw->mac.autoneg ? AUTONEG_ENABLE : AUTONEG_DISABLE;
+#ifdef ETH_TP_MDI_X
+
+	/* MDI-X => 2; MDI =>1; Invalid =>0 */
+	if ((hw->phy.media_type == e1000_media_type_copper) &&
+	    netif_carrier_ok(netdev))
+	    	ecmd->eth_tp_mdix = hw->phy.is_mdix ? ETH_TP_MDI_X :
+		                                      ETH_TP_MDI;
+	else
+		ecmd->eth_tp_mdix = ETH_TP_MDI_INVALID;
+
+#endif /* ETH_TP_MDI_X */
 	return 0;
 }
 
@@ -233,6 +248,24 @@ static int igb_set_settings(struct net_device *netdev, struct ethtool_cmd *ecmd)
 		}
 	}
 
+#ifdef ETH_TP_MDI_X
+	/* MDI-X =>2; MDI=>1; Invalid =>0 */
+	if (hw->phy.media_type == e1000_media_type_copper) {
+		switch (ecmd->eth_tp_mdix) {
+		case ETH_TP_MDI_X:
+			hw->phy.mdix = 2;
+			break;
+		case ETH_TP_MDI:
+			hw->phy.mdix = 1;
+			break;
+		case ETH_TP_MDI_INVALID:
+		default:
+			hw->phy.mdix = 0;
+			break;
+		}
+	}
+
+#endif /* ETH_TP_MDI_X */
 	/* reset the link */
 	if (netif_running(adapter->netdev)) {
 		igb_down(adapter);
@@ -432,7 +465,7 @@ static void igb_set_msglevel(struct net_device *netdev, u32 data)
 
 static int igb_get_regs_len(struct net_device *netdev)
 {
-#define IGB_REGS_LEN 551
+#define IGB_REGS_LEN 555
 	return IGB_REGS_LEN * sizeof(u32);
 }
 
@@ -649,7 +682,12 @@ static void igb_get_regs(struct net_device *netdev,
 	regs_buff[548] = E1000_READ_REG(hw, E1000_TDFT);
 	regs_buff[549] = E1000_READ_REG(hw, E1000_TDFHS);
 	regs_buff[550] = E1000_READ_REG(hw, E1000_TDFPC);
-
+	if (hw->mac.type > e1000_82580) {
+		regs_buff[551] = adapter->stats.o2bgptc;
+		regs_buff[552] = adapter->stats.b2ospc;
+		regs_buff[553] = adapter->stats.o2bspc;
+		regs_buff[554] = adapter->stats.b2ogprc;
+	}
 }
 
 static int igb_get_eeprom_len(struct net_device *netdev)
@@ -771,8 +809,8 @@ static void igb_get_drvinfo(struct net_device *netdev,
 {
 	struct igb_adapter *adapter = netdev_priv(netdev);
 
-	strncpy(drvinfo->driver,  igb_driver_name, 32);
-	strncpy(drvinfo->version, igb_driver_version, 32);
+	strncpy(drvinfo->driver,  igb_driver_name, sizeof(drvinfo->driver) - 1);
+	strncpy(drvinfo->version, igb_driver_version, sizeof(drvinfo->version) - 1);
 
 	/* EEPROM image version # is reported as firmware version # for
 	 * 82575 controllers */
@@ -781,7 +819,7 @@ static void igb_get_drvinfo(struct net_device *netdev,
 		 (adapter->fw_version & 0x0FF0) >> 4,
 		 adapter->fw_version & 0x000F);
 
-	strncpy(drvinfo->bus_info, pci_name(adapter->pdev), 32);
+	strncpy(drvinfo->bus_info, pci_name(adapter->pdev), sizeof(drvinfo->bus_info) -1);
 	drvinfo->n_stats = IGB_STATS_LEN;
 	drvinfo->testinfo_len = IGB_TEST_LEN;
 	drvinfo->regdump_len = igb_get_regs_len(netdev);
@@ -1541,7 +1579,7 @@ static int igb_run_loopback_test(struct igb_adapter *adapter)
 		/* place 64 packets on the transmit queue*/
 		for (i = 0; i < 64; i++) {
 			skb_get(skb);
-			tx_ret_val = igb_xmit_frame_ring(skb, tx_ring, false);
+			tx_ret_val = igb_xmit_frame_ring(skb, tx_ring);
 			if (tx_ret_val == NETDEV_TX_OK)
 				good_cnt++;
 		}
@@ -1555,6 +1593,7 @@ static int igb_run_loopback_test(struct igb_adapter *adapter)
 		msleep(200);
 
 		good_cnt = igb_clean_test_rings(rx_ring, tx_ring, size);
+		printk("CWM: loopback_test:good_cnt=%x\n", good_cnt);
 		if (good_cnt != 64) {
 			ret_val = 13;
 			break;
@@ -1585,11 +1624,13 @@ static int igb_loopback_test(struct igb_adapter *adapter, u64 *data)
 	if (*data)
 		goto err_loopback;
 	*data = igb_run_loopback_test(adapter);
+
 	igb_loopback_cleanup(adapter);
 
 err_loopback:
 	igb_free_desc_rings(adapter);
 out:
+	printk("CMW:igb_loopback:*data=%x\n", (uint)*data);
 	return *data;
 }
 
@@ -1815,8 +1856,32 @@ static int igb_set_wol(struct net_device *netdev, struct ethtool_wolinfo *wol)
 }
 
 /* bit defines for adapter->led_status */
-#define IGB_LED_ON		0
-
+#ifdef HAVE_ETHTOOL_SET_PHYS_ID
+static int igb_set_phys_id(struct net_device *netdev,
+                           enum ethtool_phys_id_state state)
+{
+        struct igb_adapter *adapter = netdev_priv(netdev);
+        struct e1000_hw *hw = &adapter->hw;
+
+        switch (state) {
+        case ETHTOOL_ID_ACTIVE:
+		e1000_blink_led(hw);
+                return 2;
+        case ETHTOOL_ID_ON:
+                e1000_led_on(hw);
+                break;
+        case ETHTOOL_ID_OFF:
+                e1000_led_off(hw);
+                break;
+        case ETHTOOL_ID_INACTIVE:
+		e1000_led_off(hw);
+		e1000_cleanup_led(hw);
+                break;
+        }
+
+        return 0;
+}
+#else
 static int igb_phys_id(struct net_device *netdev, u32 data)
 {
 	struct igb_adapter *adapter = netdev_priv(netdev);
@@ -1836,11 +1901,11 @@ static int igb_phys_id(struct net_device *netdev, u32 data)
 	msleep_interruptible(timeout);
 
 	e1000_led_off(hw);
-	clear_bit(IGB_LED_ON, &adapter->led_status);
 	e1000_cleanup_led(hw);
 
 	return 0;
 }
+#endif /* HAVE_ETHTOOL_SET_PHYS_ID */
 
 static int igb_set_coalesce(struct net_device *netdev,
 			    struct ethtool_coalesce *ec)
@@ -1852,7 +1917,10 @@ static int igb_set_coalesce(struct net_device *netdev,
 	    ((ec->rx_coalesce_usecs > 3) &&
 	     (ec->rx_coalesce_usecs < IGB_MIN_ITR_USECS)) ||
 	    (ec->rx_coalesce_usecs == 2))
+	    {
+	    	printk("set_coalesce:invalid parameter..");
 		return -EINVAL;
+	}
 
 	if ((ec->tx_coalesce_usecs > IGB_MAX_ITR_USECS) ||
 	    ((ec->tx_coalesce_usecs > 3) &&
@@ -1863,6 +1931,11 @@ static int igb_set_coalesce(struct net_device *netdev,
 	if ((adapter->flags & IGB_FLAG_QUEUE_PAIRS) && ec->tx_coalesce_usecs)
 		return -EINVAL;
 
+	/* If ITR is disabled, disable DMAC */
+	if (ec->rx_coalesce_usecs == 0) {
+		adapter->dmac = IGB_DMAC_DISABLE;
+	}
+	
 	/* convert to rate of irq's per second */
 	if (ec->rx_coalesce_usecs && ec->rx_coalesce_usecs <= 3)
 		adapter->rx_itr_setting = ec->rx_coalesce_usecs;
@@ -2084,7 +2157,11 @@ static struct ethtool_ops igb_ethtool_ops = {
 #endif
 	.self_test              = igb_diag_test,
 	.get_strings            = igb_get_strings,
+#ifdef HAVE_ETHTOOL_SET_PHYS_ID
+	.set_phys_id            = igb_set_phys_id,
+#else
 	.phys_id                = igb_phys_id,
+#endif /* HAVE_ETHTOOL_SET_PHYS_ID */
 #ifdef HAVE_ETHTOOL_GET_SSET_COUNT
 	.get_sset_count         = igb_get_sset_count,
 #else
@@ -2097,16 +2174,17 @@ static struct ethtool_ops igb_ethtool_ops = {
 #endif
 	.get_coalesce           = igb_get_coalesce,
 	.set_coalesce           = igb_set_coalesce,
-#ifdef ETHTOOL_GFLAGS
 #ifdef IGB_LRO
+#ifdef ETHTOOL_GFLAGS
 	.get_flags              = ethtool_op_get_flags,
 	.set_flags              = igb_set_flags,
-#endif
 #endif /* ETHTOOL_GFLAGS */
+#endif /* IGB_LRO */
 };
 
 void igb_set_ethtool_ops(struct net_device *netdev)
 {
 	SET_ETHTOOL_OPS(netdev, &igb_ethtool_ops);
 }
+
 #endif	/* SIOCETHTOOL */
diff --git a/drivers/net/igb/igb_main.c b/drivers/net/igb/igb_main.c
index 423d22c..d7d4c8e 100644
--- a/drivers/net/igb/igb_main.c
+++ b/drivers/net/igb/igb_main.c
@@ -48,18 +48,22 @@
 #include <linux/if_vlan.h>
 
 #include "igb.h"
+#include "igb_vmdq.h"
 
 #define DRV_DEBUG
 #define DRV_HW_PERF
 #define VERSION_SUFFIX
 
-#define DRV_VERSION "2.4.12" VERSION_SUFFIX DRV_DEBUG DRV_HW_PERF
+#define MAJ 3
+#define MIN 1
+#define BUILD 16
+#define DRV_VERSION __stringify(MAJ) "." __stringify(MIN) "." __stringify(BUILD) VERSION_SUFFIX DRV_DEBUG DRV_HW_PERF
 
 char igb_driver_name[] = "igb";
 char igb_driver_version[] = DRV_VERSION;
 static const char igb_driver_string[] =
                                 "Intel(R) Gigabit Ethernet Network Driver";
-static const char igb_copyright[] = "Copyright (c) 2007-2010 Intel Corporation.";
+static const char igb_copyright[] = "Copyright (c) 2007-2011 Intel Corporation.";
 
 static struct pci_device_id igb_pci_tbl[] = {
 	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_I350_COPPER) },
@@ -72,6 +76,10 @@ static struct pci_device_id igb_pci_tbl[] = {
 	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_82580_SGMII) },
 	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_82580_COPPER_DUAL) },
 	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_82580_QUAD_FIBER) },
+	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_DH89XXCC_SGMII) },
+	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_DH89XXCC_SERDES) },
+	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_DH89XXCC_BACKPLANE) },
+	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_DH89XXCC_SFP) },
 	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_82576) },
 	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_82576_NS) },
 	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_82576_NS_SERDES) },
@@ -83,7 +91,6 @@ static struct pci_device_id igb_pci_tbl[] = {
 	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_82575EB_COPPER) },
 	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_82575EB_FIBER_SERDES) },
 	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_82575GB_QUAD_COPPER) },
-	{ PCI_VDEVICE(INTEL, E1000_DEV_ID_DH89XXCC_SGMII) },
 	/* required last entry */
 	{0, }
 };
@@ -107,7 +114,6 @@ static void igb_configure_rx(struct igb_adapter *);
 static void igb_clean_all_tx_rings(struct igb_adapter *);
 static void igb_clean_all_rx_rings(struct igb_adapter *);
 static void igb_clean_tx_ring(struct igb_ring *);
-static void igb_clean_rx_ring(struct igb_ring *);
 static void igb_set_rx_mode(struct net_device *);
 static void igb_update_phy_info(unsigned long);
 static void igb_watchdog(unsigned long);
@@ -115,6 +121,7 @@ static void igb_watchdog_task(struct work_struct *);
 static netdev_tx_t igb_xmit_frame(struct sk_buff *skb, struct net_device *);
 static struct net_device_stats *igb_get_stats(struct net_device *);
 static int igb_change_mtu(struct net_device *, int);
+void igb_full_sync_mac_table(struct igb_adapter *adapter);
 static int igb_set_mac(struct net_device *, void *);
 static void igb_set_uta(struct igb_adapter *adapter);
 static irqreturn_t igb_intr(int irq, void *);
@@ -135,12 +142,13 @@ static void igb_vlan_rx_register(struct net_device *, struct vlan_group *);
 static void igb_vlan_rx_add_vid(struct net_device *, u16);
 static void igb_vlan_rx_kill_vid(struct net_device *, u16);
 static void igb_restore_vlan(struct igb_adapter *);
-static void igb_rar_set_qsel(struct igb_adapter *, u8 *, u32 , u8);
+void igb_rar_set(struct igb_adapter *adapter, u32 index);
 static void igb_ping_all_vfs(struct igb_adapter *);
 static void igb_msg_task(struct igb_adapter *);
 static void igb_vmm_control(struct igb_adapter *);
 static int igb_set_vf_mac(struct igb_adapter *, int, unsigned char *);
 static void igb_restore_vf_multicasts(struct igb_adapter *adapter);
+static void igb_process_mdd_event(struct igb_adapter *);
 #ifdef IFLA_VF_MAX
 static int igb_ndo_set_vf_mac( struct net_device *netdev, int vf, u8 *mac);
 static int igb_ndo_set_vf_vlan(struct net_device *netdev,
@@ -148,6 +156,7 @@ static int igb_ndo_set_vf_vlan(struct net_device *netdev,
 static int igb_ndo_set_vf_bw(struct net_device *netdev, int vf, int tx_rate);
 static int igb_ndo_get_vf_config(struct net_device *netdev, int vf,
 				 struct ifla_vf_info *ivi);
+static void igb_check_vf_rate_limit(struct igb_adapter *);
 #endif
 #ifdef CONFIG_PM
 static int igb_suspend(struct pci_dev *, pm_message_t);
@@ -189,6 +198,8 @@ static struct pci_error_handlers igb_err_handler = {
 };
 #endif
 
+static void igb_init_fw(struct igb_adapter *adapter);
+static void igb_init_dmac(struct igb_adapter *adapter, u32 pba);
 
 static struct pci_driver igb_driver = {
 	.name     = igb_driver_name,
@@ -237,7 +248,7 @@ static void igb_vfta_set(struct e1000_hw *hw, u32 vid, bool add)
 	e1000_write_vfta(hw, index, vfta);
 }
 
-#ifdef SIOCSHWTSTAMP
+#ifdef HAVE_HW_TIME_STAMP
 /**
  * igb_read_clock - read raw cycle counter (to be used by time counter)
  */
@@ -260,6 +271,9 @@ static cycle_t igb_read_clock(const struct cyclecounter *tc)
 	}
 
 	stamp |= (u64)E1000_READ_REG(hw, E1000_SYSTIML) << shift;
+	stamp |= (u64)E1000_READ_REG(hw, E1000_SYSTIML) << shift;
+	stamp |= (u64)E1000_READ_REG(hw, E1000_SYSTIML) << shift;
+	stamp |= (u64)E1000_READ_REG(hw, E1000_SYSTIML) << shift;
 	stamp |= (u64)E1000_READ_REG(hw, E1000_SYSTIMH) << (shift + 32);
 	return stamp;
 }
@@ -278,6 +292,7 @@ MODULE_PARM_DESC(debug, "Debug level (0=none, ..., 16=all)");
 static int __init igb_init_module(void)
 {
 	int ret;
+
 	printk(KERN_INFO "%s - version %s\n",
 	       igb_driver_string, igb_driver_version);
 
@@ -384,7 +399,6 @@ static int igb_alloc_queues(struct igb_adapter *adapter)
 	int orig_node = adapter->node;
 #endif /* HAVE_DEVICE_NUMA_NODE */
 
-
 	for (i = 0; i < adapter->num_tx_queues; i++) {
 #ifdef HAVE_DEVICE_NUMA_NODE
 		if (orig_node == -1) {
@@ -448,6 +462,14 @@ static int igb_alloc_queues(struct igb_adapter *adapter)
 		if (i < adapter->rss_queues)
 			set_bit(IGB_RING_FLAG_RX_LRO, &ring->flags);
 #endif
+#ifdef NETIF_F_RXHASH
+		/* set rx_hash */
+		set_bit(IGB_RING_FLAG_RX_HASH, &ring->flags);
+#endif
+		/* On i350, loopback VLAN packets have the tag byte-swapped. */
+		if (adapter->hw.mac.type == e1000_i350)
+			set_bit(IGB_RING_FLAG_RX_LB_VLAN_BSWAP, &ring->flags);
+
 		adapter->rx_ring[i] = ring;
 	}
 #ifdef HAVE_DEVICE_NUMA_NODE
@@ -722,6 +744,7 @@ static int igb_request_msix(struct igb_adapter *adapter)
 	}
 
 	igb_configure_msix(adapter);
+	return 0;
 out:
 	return err;
 }
@@ -821,6 +844,88 @@ static void igb_clear_interrupt_scheme(struct igb_adapter *adapter)
 }
 
 /**
+ * igb_process_mdd_event
+ * @adapter - board private structure
+ *
+ * Identify a malicious VF, disable the VF TX/RX queues and log a message.
+ */
+static void igb_process_mdd_event(struct igb_adapter *adapter)
+{
+	struct e1000_hw *hw = &adapter->hw;
+	u32 lvmmc, vfte, vfre, mdfb;
+	u8 vf_queue;
+
+	lvmmc = E1000_READ_REG(hw, E1000_LVMMC);
+	vf_queue = lvmmc >> 29;
+
+	/* VF index cannot be bigger or equal to VFs allocated */
+	if (vf_queue >= adapter->vfs_allocated_count)
+		return;
+
+	netdev_info(adapter->netdev,
+	            "VF %d misbehaved. VF queues are disabled. "
+	            "VM misbehavior code is 0x%x\n", vf_queue, lvmmc);
+
+	/* Disable VFTE and VFRE related bits */
+	vfte = E1000_READ_REG(hw, E1000_VFTE);
+	vfte &= ~(1 << vf_queue);
+	E1000_WRITE_REG(hw, E1000_VFTE, vfte);
+
+	vfre = E1000_READ_REG(hw, E1000_VFRE);
+	vfre &= ~(1 << vf_queue);
+	E1000_WRITE_REG(hw, E1000_VFRE, vfre);
+
+	/* Disable MDFB related bit */
+	mdfb = E1000_READ_REG(hw, E1000_MDFB);
+	mdfb &= ~(1 << vf_queue);
+	E1000_WRITE_REG(hw, E1000_MDFB, mdfb);
+
+	/* Reset the specific VF */
+	E1000_WRITE_REG(hw, E1000_VTCTRL(vf_queue), E1000_VTCTRL_RST);
+}
+
+/**
+ * igb_disable_mdd
+ * @adapter - board private structure
+ *
+ * Disable MDD behavior in the HW
+ **/
+static void igb_disable_mdd(struct igb_adapter *adapter)
+{
+	struct e1000_hw *hw = &adapter->hw;
+	u32 reg;
+
+	if (hw->mac.type != e1000_i350)
+		return;
+
+	reg = E1000_READ_REG(hw, E1000_DTXCTL);
+	reg &= (~E1000_DTXCTL_MDP_EN);
+	E1000_WRITE_REG(hw, E1000_DTXCTL, reg);
+}
+
+/**
+ * igb_enable_mdd
+ * @adapter - board private structure
+ *
+ * Enable the HW to detect malicious driver and sends an interrupt to
+ * the driver. 
+ * 
+ * Only available on i350 device
+ **/
+static void igb_enable_mdd(struct igb_adapter *adapter)
+{
+	struct e1000_hw *hw = &adapter->hw;
+	u32 reg;
+
+	if (hw->mac.type != e1000_i350)
+		return;
+
+	reg = E1000_READ_REG(hw, E1000_DTXCTL);
+	reg |= E1000_DTXCTL_MDP_EN;
+	E1000_WRITE_REG(hw, E1000_DTXCTL, reg);
+}
+
+/**
  * igb_reset_sriov_capability - disable SR-IOV if enabled
  *
  * Attempt to disable single root IO virtualization capabilites present in the
@@ -837,6 +942,9 @@ static void igb_reset_sriov_capability(struct igb_adapter *adapter)
 		pci_disable_sriov(pdev);
 		msleep(500);
 
+		/* Disable Malicious Driver Detection */
+		igb_disable_mdd(adapter);
+
 		/* free vf data storage */
 		kfree(adapter->vf_data);
 		adapter->vf_data = NULL;
@@ -878,8 +986,12 @@ static void igb_set_sriov_capability(struct igb_adapter *adapter)
 			igb_set_vf_mac(adapter, i, mac_addr);
 		}
 
-		if (!pci_enable_sriov(pdev, adapter->vfs_allocated_count))
+		if (!pci_enable_sriov(pdev, adapter->vfs_allocated_count)) {
+			/* DMA Coalescing is not supported in IOV mode. */
+			if (adapter->hw.mac.type >= e1000_i350)
+				adapter->dmac = IGB_DMAC_DISABLE;
 			return;
+		}
 
 		kfree(adapter->vf_data);
 		adapter->vf_data = NULL;
@@ -972,9 +1084,10 @@ static void igb_set_interrupt_capability(struct igb_adapter *adapter)
 #ifdef CONFIG_NETDEVICES_MULTIQUEUE
 	adapter->netdev->egress_subqueue_count = adapter->num_tx_queues;
 #else
-	adapter->netdev->real_num_tx_queues = adapter->num_tx_queues;
-#endif
+	adapter->netdev->real_num_tx_queues =
+			(adapter->vmdq_pools ? 1 : adapter->num_tx_queues);
 #endif
+#endif /* HAVE_TX_MQ */
 }
 
 /**
@@ -1019,15 +1132,14 @@ static int igb_alloc_q_vectors(struct igb_adapter *adapter)
 #ifdef IGB_LRO
 		if (v_idx < adapter->num_rx_queues) {
 			int size = sizeof(struct igb_lro_list);
-			q_vector->lrolist = vmalloc_node(size, q_vector->numa_node);
+			q_vector->lrolist = vzalloc_node(size, q_vector->numa_node);
 			if (!q_vector->lrolist)
-				q_vector->lrolist = vmalloc(size);
+				q_vector->lrolist = vzalloc(size);
 			if (!q_vector->lrolist)
 				goto err_out;
-			memset(q_vector->lrolist, 0, size);
 			igb_lro_ring_init(q_vector->lrolist);
 		}
-#endif
+#endif /* IGB_LRO */
 	}
 #ifdef HAVE_DEVICE_NUMA_NODE
 	/* Restore the adapter's original node */
@@ -1275,6 +1387,10 @@ static void igb_irq_enable(struct igb_adapter *adapter)
 		if (adapter->vfs_allocated_count) {
 			E1000_WRITE_REG(hw, E1000_MBVFIMR, 0xFF);
 			ims |= E1000_IMS_VMMB;
+			/* For I350 device only enable MDD interrupts*/
+			if ((adapter->mdd) &&
+			    (adapter->hw.mac.type == e1000_i350))
+				ims |= E1000_IMS_MDDET;
 		}
 		E1000_WRITE_REG(hw, E1000_IMS, ims);
 	} else {
@@ -1426,6 +1542,7 @@ int igb_up(struct igb_adapter *adapter)
 
 	for (i = 0; i < adapter->num_q_vectors; i++)
 		napi_enable(&(adapter->q_vector[i]->napi));
+
 	if (adapter->msix_entries)
 		igb_configure_msix(adapter);
 	else
@@ -1609,8 +1726,12 @@ void igb_reset(struct igb_adapter *adapter)
 	/* disable receive for all VFs and wait one second */
 	if (adapter->vfs_allocated_count) {
 		int i;
+		/*
+		 * Clear all flags except indication that the PF has set
+		 * the VF MAC addresses administratively
+		 */
 		for (i = 0 ; i < adapter->vfs_allocated_count; i++)
-			adapter->vf_data[i].flags = 0;
+			adapter->vf_data[i].flags &= IGB_VF_FLAG_PF_SET_MAC;
 
 		/* ping all the active vfs to let them know we are going down */
 		igb_ping_all_vfs(adapter);
@@ -1627,11 +1748,7 @@ void igb_reset(struct igb_adapter *adapter)
 	if (e1000_init_hw(hw))
 		dev_err(pci_dev_to_dev(pdev), "Hardware Error\n");
 
-	if (hw->mac.type >= e1000_82580) {
-		u32 reg = E1000_READ_REG(hw, E1000_PCIEMISC);
-		E1000_WRITE_REG(hw, E1000_PCIEMISC,
-		                reg & ~E1000_PCIEMISC_LX_DECISION);
-	}
+	igb_init_dmac(adapter, pba);
 	if (!netif_running(adapter->netdev))
 		igb_power_down_link(adapter);
 
@@ -1669,8 +1786,103 @@ static const struct net_device_ops igb_netdev_ops = {
 	.ndo_poll_controller	= igb_netpoll,
 #endif
 };
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+static const struct net_device_ops igb_vmdq_ops = {
+	.ndo_open		= &igb_vmdq_open,
+	.ndo_stop		= &igb_vmdq_close,
+	.ndo_start_xmit		= &igb_vmdq_xmit_frame,
+	.ndo_get_stats		= &igb_vmdq_get_stats,
+	.ndo_set_rx_mode	= &igb_vmdq_set_rx_mode,
+	.ndo_set_multicast_list	= &igb_vmdq_set_rx_mode,
+	.ndo_validate_addr	= eth_validate_addr,
+	.ndo_set_mac_address	= &igb_vmdq_set_mac,
+	.ndo_change_mtu		= &igb_vmdq_change_mtu,
+	.ndo_tx_timeout		= &igb_vmdq_tx_timeout,
+	.ndo_vlan_rx_register	= &igb_vmdq_vlan_rx_register,
+	.ndo_vlan_rx_add_vid	= &igb_vmdq_vlan_rx_add_vid,
+	.ndo_vlan_rx_kill_vid	= &igb_vmdq_vlan_rx_kill_vid,
+};
+#endif /* CONFIG_IGB_VMDQ_NETDEV */
+
 #endif /* HAVE_NET_DEVICE_OPS */
 
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+void igb_assign_vmdq_netdev_ops(struct net_device *vnetdev)
+{
+#ifdef HAVE_NET_DEVICE_OPS
+	vnetdev->netdev_ops = &igb_vmdq_ops;
+#else
+	dev->open = &igb_vmdq_open;
+	dev->stop = &igb_vmdq_close;
+	dev->hard_start_xmit = &igb_vmdq_xmit_frame;
+	dev->get_stats = &igb_vmdq_get_stats;
+#ifdef HAVE_SET_RX_MODE
+	dev->set_rx_mode = &igb_vmdq_set_rx_mode;
+#endif
+	dev->set_multicast_list = &igb_vmdq_set_rx_mode;
+	dev->set_mac_address = &igb_vmdq_set_mac;
+	dev->change_mtu = &igb_vmdq_change_mtu;
+#ifdef HAVE_TX_TIMEOUT
+	dev->tx_timeout = &igb_vmdq_tx_timeout;
+#endif
+#ifdef NETIF_F_HW_VLAN_TX
+	dev->vlan_rx_register = &igb_vmdq_vlan_rx_register;
+	dev->vlan_rx_add_vid = &igb_vmdq_vlan_rx_add_vid;
+	dev->vlan_rx_kill_vid = &igb_vmdq_vlan_rx_kill_vid;
+#endif
+#endif
+	igb_vmdq_set_ethtool_ops(vnetdev);
+	vnetdev->watchdog_timeo = 5 * HZ;
+
+}
+
+int igb_init_vmdq_netdevs(struct igb_adapter *adapter)
+{
+	int pool, err = 0, base_queue;
+	struct net_device *vnetdev;
+	struct igb_vmdq_adapter *vmdq_adapter;
+
+	for (pool = 1; pool < adapter->vmdq_pools; pool++) {
+		int qpp = (!adapter->rss_queues ? 1 : adapter->rss_queues);
+		base_queue = pool * qpp;
+		vnetdev = alloc_etherdev(sizeof(struct igb_vmdq_adapter));
+		if (!vnetdev) {
+			err = -ENOMEM;
+			break;
+		}
+		vmdq_adapter = netdev_priv(vnetdev);
+		vmdq_adapter->vnetdev = vnetdev;
+		vmdq_adapter->real_adapter = adapter;
+		vmdq_adapter->rx_ring = adapter->rx_ring[base_queue];
+		vmdq_adapter->tx_ring = adapter->tx_ring[base_queue];
+		igb_assign_vmdq_netdev_ops(vnetdev);
+		snprintf(vnetdev->name, IFNAMSIZ, "%sv%d",
+			 adapter->netdev->name, pool);
+		vnetdev->features = adapter->netdev->features;
+#ifdef HAVE_NETDEV_VLAN_FEATURES
+		vnetdev->vlan_features = adapter->netdev->vlan_features;
+#endif
+		adapter->vmdq_netdev[pool-1] = vnetdev;
+		err = register_netdev(vnetdev);
+		if (err)
+			break;
+	}
+	return err;
+}
+
+int igb_remove_vmdq_netdevs(struct igb_adapter *adapter)
+{
+	int pool, err = 0;
+
+	for (pool = 1; pool < adapter->vmdq_pools; pool++) {
+		unregister_netdev(adapter->vmdq_netdev[pool-1]);
+		free_netdev(adapter->vmdq_netdev[pool-1]);
+		adapter->vmdq_netdev[pool-1] = NULL;
+	}
+	return err;
+}
+#endif /* CONFIG_IGB_VMDQ_NETDEV */
+
 /**
  * igb_probe - Device Initialization Routine
  * @pdev: PCI device information struct
@@ -1817,7 +2029,11 @@ static int __devinit igb_probe(struct pci_dev *pdev,
 
 	/* Copper options */
 	if (hw->phy.media_type == e1000_media_type_copper) {
+#ifdef ETH_TP_MDI_X
+		hw->phy.mdix = ETH_TP_MDI_INVALID;
+#else
 		hw->phy.mdix = AUTO_ALL_MODES;
+#endif /* ETH_TP_MDI_X */
 		hw->phy.disable_polarity_correction = FALSE;
 		hw->phy.ms_type = e1000_ms_hw_default;
 	}
@@ -1871,17 +2087,16 @@ static int __devinit igb_probe(struct pci_dev *pdev,
 
 	/* make sure the NVM is good */
 	if (e1000_validate_nvm_checksum(hw) < 0) {
-		dev_err(pci_dev_to_dev(pdev), "The NVM Checksum Is Not Valid\n");
+		dev_err(pci_dev_to_dev(pdev), "The NVM Checksum Is Not"
+		        " Valid\n");
 		err = -EIO;
 		goto err_eeprom;
 	}
 
-	/* copy the MAC address out of the NVM */
 	if (e1000_read_mac_addr(hw))
 		dev_err(pci_dev_to_dev(pdev), "NVM Read Error\n");
-
 	memcpy(netdev->dev_addr, hw->mac.addr, netdev->addr_len);
-#ifdef HAVE_ETHTOOL_GET_PERM_ADDR
+#ifdef ETHTOOL_GPERMADDR
 	memcpy(netdev->perm_addr, hw->mac.addr, netdev->addr_len);
 
 	if (!is_valid_ether_addr(netdev->perm_addr)) {
@@ -1893,9 +2108,13 @@ static int __devinit igb_probe(struct pci_dev *pdev,
 		goto err_eeprom;
 	}
 
+	memcpy(&adapter->mac_table[0].addr, hw->mac.addr, netdev->addr_len);
+	adapter->mac_table[0].queue = adapter->vfs_allocated_count;
+	adapter->mac_table[0].state = (IGB_MAC_STATE_DEFAULT | IGB_MAC_STATE_IN_USE);
+	igb_rar_set(adapter, 0);
+
 	/* get firmware version for ethtool -i */
 	e1000_read_nvm(&adapter->hw, 5, 1, &adapter->fw_version);
-
 	setup_timer(&adapter->watchdog_timer, &igb_watchdog,
 	            (unsigned long) adapter);
 	setup_timer(&adapter->phy_info_timer, &igb_update_phy_info,
@@ -1960,7 +2179,7 @@ static int __devinit igb_probe(struct pci_dev *pdev,
 
 	/* initialize the wol settings based on the eeprom settings */
 	adapter->wol = adapter->eeprom_wol;
-	device_set_wakeup_enable(&adapter->pdev->dev, adapter->wol);
+	device_set_wakeup_enable(pci_dev_to_dev(adapter->pdev), adapter->wol);
 
 	/* reset the hardware with the new settings */
 	igb_reset(adapter);
@@ -1969,13 +2188,16 @@ static int __devinit igb_probe(struct pci_dev *pdev,
 	 * driver. */
 	igb_get_hw_control(adapter);
 
-	netif_tx_stop_all_queues(netdev);
-
 	strncpy(netdev->name, "eth%d", IFNAMSIZ);
 	err = register_netdev(netdev);
 	if (err)
 		goto err_register;
 
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+	err = igb_init_vmdq_netdevs(adapter);
+	if (err)
+		goto err_register;
+#endif
 	/* carrier off reporting is important to ethtool even BEFORE open */
 	netif_carrier_off(netdev);
 
@@ -1987,7 +2209,7 @@ static int __devinit igb_probe(struct pci_dev *pdev,
 	}
 
 #endif
-#ifdef SIOCSHWTSTAMP
+#ifdef HAVE_HW_TIME_STAMP
 	switch (hw->mac.type) {
 	case e1000_i350:
 	case e1000_82580:
@@ -2086,14 +2308,14 @@ static int __devinit igb_probe(struct pci_dev *pdev,
 	/* print bus type/speed/width info */
 	dev_info(pci_dev_to_dev(pdev), "%s: (PCIe:%s:%s) ",
 	         netdev->name,
-	         ((hw->bus.speed == e1000_bus_speed_2500) ? "2.5Gb/s" :
-	          (hw->bus.speed == e1000_bus_speed_5000) ? "5.0Gb/s" :
+	         ((hw->bus.speed == e1000_bus_speed_2500) ? "2.5GT/s" :
+	          (hw->bus.speed == e1000_bus_speed_5000) ? "5.0GT/s" :
 	                                                    "unknown"),
-	         ((hw->bus.width == e1000_bus_width_pcie_x4) ? "Width x4" :
-	          (hw->bus.width == e1000_bus_width_pcie_x2) ? "Width x2" :
-	          (hw->bus.width == e1000_bus_width_pcie_x1) ? "Width x1" :
+	         ((hw->bus.width == e1000_bus_width_pcie_x4) ? "Width x4\n" :
+	          (hw->bus.width == e1000_bus_width_pcie_x2) ? "Width x2\n" :
+	          (hw->bus.width == e1000_bus_width_pcie_x1) ? "Width x1\n" :
 	           "unknown"));
-
+	dev_info(pci_dev_to_dev(pdev), "%s: MAC: ", netdev->name);
 	for (i = 0; i < 6; i++)
 		printk("%2.2x%c", netdev->dev_addr[i], i == 5 ? '\n' : ':');
 
@@ -2104,6 +2326,17 @@ static int __devinit igb_probe(struct pci_dev *pdev,
 		 pba_str);
 
 
+	switch (hw->mac.type) {
+	case e1000_i350:
+		/* Enable EEE */
+		e1000_set_eee_i350(hw);
+
+		/* send driver version info to firmware */
+		igb_init_fw(adapter);
+		break;
+	default:
+		break;
+	}
 #ifdef IGB_LRO
 	if (test_bit(IGB_RING_FLAG_RX_LRO, &adapter->rx_ring[0]->flags))
 		dev_info(pci_dev_to_dev(pdev), "Internal LRO is enabled \n");
@@ -2179,6 +2412,9 @@ static void __devexit igb_remove(struct pci_dev *pdev)
 	igb_release_hw_control(adapter);
 
 	unregister_netdev(netdev);
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+	igb_remove_vmdq_netdevs(adapter);
+#endif
 
 	igb_clear_interrupt_scheme(adapter);
 	igb_reset_sriov_capability(adapter);
@@ -2189,6 +2425,7 @@ static void __devexit igb_remove(struct pci_dev *pdev)
 	pci_release_selected_regions(pdev,
 	                             pci_select_bars(pdev, IORESOURCE_MEM));
 
+	kfree(adapter->mac_table);
 	free_netdev(netdev);
 
 	pci_disable_pcie_error_reporting(pdev);
@@ -2234,6 +2471,10 @@ static int __devinit igb_sw_init(struct igb_adapter *adapter)
 
 	igb_check_options(adapter);
 
+	adapter->mac_table = kzalloc(sizeof(struct igb_mac_addr) *
+				     hw->mac.rar_entry_count, 
+				     GFP_ATOMIC);
+
 	/* These calls may decrease the number of queues */
 	igb_set_sriov_capability(adapter);
 
@@ -2374,12 +2615,11 @@ int igb_setup_tx_resources(struct igb_ring *tx_ring)
 	int size;
 
 	size = sizeof(struct igb_buffer) * tx_ring->count;
-	tx_ring->buffer_info = vmalloc_node(size, tx_ring->numa_node);
+	tx_ring->buffer_info = vzalloc_node(size, tx_ring->numa_node);
 	if (!tx_ring->buffer_info)
-		tx_ring->buffer_info = vmalloc(size);
+		tx_ring->buffer_info = vzalloc(size);
 	if (!tx_ring->buffer_info)
 		goto err;
-	memset(tx_ring->buffer_info, 0, size);
 
 	/* round up to nearest 4K */
 	tx_ring->size = tx_ring->count * sizeof(union e1000_adv_tx_desc);
@@ -2529,12 +2769,11 @@ int igb_setup_rx_resources(struct igb_ring *rx_ring)
 	int size, desc_len;
 
 	size = sizeof(struct igb_buffer) * rx_ring->count;
-	rx_ring->buffer_info = vmalloc_node(size, rx_ring->numa_node);
+	rx_ring->buffer_info = vzalloc_node(size, rx_ring->numa_node);
 	if (!rx_ring->buffer_info)
-		rx_ring->buffer_info = vmalloc(size);
+		rx_ring->buffer_info = vzalloc(size);
 	if (!rx_ring->buffer_info)
 		goto err;
-	memset(rx_ring->buffer_info, 0, size);
 
 	desc_len = sizeof(union e1000_adv_rx_desc);
 
@@ -2770,6 +3009,16 @@ static inline int igb_set_vf_rlpml(struct igb_adapter *adapter, int size,
 	    adapter->vf_data[vfn].vlans_enabled)
 		size += VLAN_TAG_SIZE;
 
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+	if (vfn >= adapter->vfs_allocated_count) {
+		int queue = vfn - adapter->vfs_allocated_count;
+		struct igb_vmdq_adapter *vadapter;
+
+		vadapter = netdev_priv(adapter->vmdq_netdev[queue-1]);
+		if (vadapter->vlgrp)
+			size += VLAN_TAG_SIZE;
+	}
+#endif
 	vmolr = E1000_READ_REG(hw, E1000_VMOLR(vfn));
 	vmolr &= ~E1000_VMOLR_RLPML_MASK;
 	vmolr |= size | E1000_VMOLR_LPE;
@@ -2792,7 +3041,7 @@ static void igb_rlpml_set(struct igb_adapter *adapter)
 
 	if (adapter->vmdq_pools && hw->mac.type != e1000_82575) {
 		int i;
-		for (i = 0; i < adapter->vmdq_pools; i++)
+		for (i = 1; i < adapter->vmdq_pools; i++)
 			igb_set_vf_rlpml(adapter, max_frame_size, pf_id + i);
 		/*
 		 * If we're in VMDQ or SR-IOV mode, then set global RLPML
@@ -2803,10 +3052,35 @@ static void igb_rlpml_set(struct igb_adapter *adapter)
 		 */
 		max_frame_size = MAX_JUMBO_FRAME_SIZE;
 	}
+	/* Set VF RLPML for the PF device. */
+	if (adapter->vfs_allocated_count)
+		igb_set_vf_rlpml(adapter, max_frame_size, pf_id);
 
 	E1000_WRITE_REG(hw, E1000_RLPML, max_frame_size);
 }
 
+static inline void igb_set_vf_vlan_strip(struct igb_adapter *adapter,
+					int vfn, bool enable)
+{
+	struct e1000_hw *hw = &adapter->hw;
+	u32 val;
+	void __iomem *reg;
+
+	if (hw->mac.type < e1000_82576)
+		return;
+
+	if (hw->mac.type == e1000_i350)
+		reg = hw->hw_addr + E1000_DVMOLR(vfn);
+	else
+		reg = hw->hw_addr + E1000_VMOLR(vfn);
+
+	val = readl(reg);
+	if (enable)
+		val |= E1000_VMOLR_STRVLAN;
+	else
+		val &= ~(E1000_VMOLR_STRVLAN);
+	writel(val, reg);
+}
 static inline void igb_set_vmolr(struct igb_adapter *adapter,
 				 int vfn, bool aupe)
 {
@@ -2822,26 +3096,21 @@ static inline void igb_set_vmolr(struct igb_adapter *adapter,
 
 	vmolr = E1000_READ_REG(hw, E1000_VMOLR(vfn));
 
-	vmolr |= E1000_VMOLR_STRVLAN;      /* Strip vlan tags */
 	if (aupe)
 		vmolr |= E1000_VMOLR_AUPE;        /* Accept untagged packets */
 	else
 		vmolr &= ~(E1000_VMOLR_AUPE); /* Tagged packets ONLY */
 
 	/* clear all bits that might not be set */
-	vmolr &= ~(E1000_VMOLR_BAM | E1000_VMOLR_RSSE);
+	vmolr &= ~E1000_VMOLR_RSSE;
 
 	if (adapter->rss_queues > 1 && vfn == adapter->vfs_allocated_count)
 		vmolr |= E1000_VMOLR_RSSE; /* enable RSS */
-	/*
-	 * for VMDq only allow the VFs and pool 0 to accept broadcast and
-	 * multicast packets
-	 */
-	if (vfn <= adapter->vfs_allocated_count)
-		vmolr |= E1000_VMOLR_BAM;	   /* Accept broadcast */
 
-	E1000_WRITE_REG(hw, E1000_VMOLR(vfn), vmolr);
+	vmolr |= E1000_VMOLR_BAM;	   /* Accept broadcast */
+	vmolr |= E1000_VMOLR_LPE; 	   /* Accept long packets */
 
+	E1000_WRITE_REG(hw, E1000_VMOLR(vfn), vmolr);
 }
 
 /**
@@ -2892,8 +3161,8 @@ void igb_configure_rx_ring(struct igb_adapter *adapter,
 	if (hw->mac.type >= e1000_82580)
 		srrctl |= E1000_SRRCTL_TIMESTAMP;
 #endif
-	/* Only set Drop Enable if we are supporting multiple queues */
-	if (adapter->num_rx_queues > 1)
+	/* Set Drop Enable if we are supporting SR-IOV */
+	if (adapter->vfs_allocated_count)
 		srrctl |= E1000_SRRCTL_DROP_EN;
 
 	E1000_WRITE_REG(hw, E1000_SRRCTL(reg_idx), srrctl);
@@ -2923,10 +3192,7 @@ static void igb_configure_rx(struct igb_adapter *adapter)
 	/* set UTA to appropriate mode */
 	igb_set_uta(adapter);
 
-	/* set the correct pool for the PF default MAC address in entry 0 */
-	igb_rar_set_qsel(adapter, adapter->hw.mac.addr, 0,
-	                 adapter->vfs_allocated_count);
-
+	igb_full_sync_mac_table(adapter);
 	/* Setup the HW Rx Head and Tail Descriptor Pointers and
 	 * the Base and Length of the Rx Descriptor Ring */
 	for (i = 0; i < adapter->num_rx_queues; i++)
@@ -3073,7 +3339,7 @@ static void igb_free_all_rx_resources(struct igb_adapter *adapter)
  * igb_clean_rx_ring - Free Rx Buffers per Queue
  * @rx_ring: ring to free buffers from
  **/
-static void igb_clean_rx_ring(struct igb_ring *rx_ring)
+void igb_clean_rx_ring(struct igb_ring *rx_ring)
 {
 	unsigned long size;
 #ifdef CONFIG_IGB_DISABLE_PACKET_SPLIT
@@ -3155,14 +3421,14 @@ static int igb_set_mac(struct net_device *netdev, void *p)
 	if (!is_valid_ether_addr(addr->sa_data))
 		return -EADDRNOTAVAIL;
 
+	igb_del_mac_filter(adapter, hw->mac.addr,
+			   adapter->vfs_allocated_count);
 	memcpy(netdev->dev_addr, addr->sa_data, netdev->addr_len);
 	memcpy(hw->mac.addr, addr->sa_data, netdev->addr_len);
 
 	/* set the correct pool for the new PF MAC address in entry 0 */
-	igb_rar_set_qsel(adapter, hw->mac.addr, 0,
-	                 adapter->vfs_allocated_count);
-
-	return 0;
+	return igb_add_mac_filter(adapter, hw->mac.addr,
+	                   adapter->vfs_allocated_count);
 }
 
 /**
@@ -3174,7 +3440,7 @@ static int igb_set_mac(struct net_device *netdev, void *p)
  *                0 on no addresses written
  *                X on writing X addresses to MTA
  **/
-static int igb_write_mc_addr_list(struct net_device *netdev)
+int igb_write_mc_addr_list(struct net_device *netdev)
 {
 	struct igb_adapter *adapter = netdev_priv(netdev);
 	struct e1000_hw *hw = &adapter->hw;
@@ -3184,15 +3450,26 @@ static int igb_write_mc_addr_list(struct net_device *netdev)
 	struct dev_mc_list *ha;
 #endif
 	u8  *mta_list;
-	int i;
+	int i, count;
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+	int vm;
+#endif
+	count = netdev_mc_count(netdev);
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+	for (vm = 1; vm < adapter->vmdq_pools; vm++) {
+		if (!adapter->vmdq_netdev[vm])
+			break;
+		if (!netif_running(adapter->vmdq_netdev[vm]))
+			continue;
+		count += netdev_mc_count(adapter->vmdq_netdev[vm]);
+	}
+#endif
 
-	if (netdev_mc_empty(netdev)) {
-		/* nothing to program, so clear mc list */
+	if (!count) {
 		e1000_update_mc_addr_list(hw, NULL, 0);
 		return 0;
 	}
-
-	mta_list = kzalloc(netdev_mc_count(netdev) * 6, GFP_ATOMIC);
+	mta_list = kzalloc(count * 6, GFP_ATOMIC);
 	if (!mta_list)
 		return -ENOMEM;
 
@@ -3204,11 +3481,86 @@ static int igb_write_mc_addr_list(struct net_device *netdev)
 #else
 		memcpy(mta_list + (i++ * ETH_ALEN), ha->dmi_addr, ETH_ALEN);
 #endif
-
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+	for (vm = 1; vm < adapter->vmdq_pools; vm++) {
+		if (!adapter->vmdq_netdev[vm])
+			break;
+		if (!netif_running(adapter->vmdq_netdev[vm]) ||
+		    !netdev_mc_count(adapter->vmdq_netdev[vm]))
+			continue;
+		netdev_for_each_mc_addr(ha, adapter->vmdq_netdev[vm])
+#ifdef NETDEV_HW_ADDR_T_MULTICAST
+			memcpy(mta_list + (i++ * ETH_ALEN),
+			       ha->addr, ETH_ALEN);
+#else
+			memcpy(mta_list + (i++ * ETH_ALEN),
+			       ha->dmi_addr, ETH_ALEN);
+#endif
+	}
+#endif
 	e1000_update_mc_addr_list(hw, mta_list, i);
 	kfree(mta_list);
 
-	return netdev_mc_count(netdev);
+	return count;
+}
+
+void igb_rar_set(struct igb_adapter *adapter, u32 index)
+{
+	u32 rar_low, rar_high;
+	struct e1000_hw *hw = &adapter->hw;
+	u8 *addr = adapter->mac_table[index].addr;
+	/* HW expects these in little endian so we reverse the byte order
+	 * from network order (big endian) to little endian
+	 */
+	rar_low = ((u32) addr[0] | ((u32) addr[1] << 8) |
+	          ((u32) addr[2] << 16) | ((u32) addr[3] << 24));
+	rar_high = ((u32) addr[4] | ((u32) addr[5] << 8));
+
+	/* Indicate to hardware the Address is Valid. */
+	if (adapter->mac_table[index].state & IGB_MAC_STATE_IN_USE)
+		rar_high |= E1000_RAH_AV;
+
+	if (hw->mac.type == e1000_82575)
+		rar_high |= E1000_RAH_POOL_1 * adapter->mac_table[index].queue;
+	else
+		rar_high |= E1000_RAH_POOL_1 << adapter->mac_table[index].queue;
+
+	E1000_WRITE_REG(hw, E1000_RAL(index), rar_low);
+	E1000_WRITE_FLUSH(hw);
+	E1000_WRITE_REG(hw, E1000_RAH(index), rar_high);
+	E1000_WRITE_FLUSH(hw);
+}
+
+void igb_full_sync_mac_table(struct igb_adapter *adapter)
+{
+	struct e1000_hw *hw = &adapter->hw;
+	int i;
+	for (i = 0; i < hw->mac.rar_entry_count; i++) {
+			igb_rar_set(adapter, i);
+	}
+}
+
+void igb_sync_mac_table(struct igb_adapter *adapter)
+{
+	struct e1000_hw *hw = &adapter->hw;
+	int i;
+	for (i = 0; i < hw->mac.rar_entry_count; i++) {
+		if (adapter->mac_table[i].state & IGB_MAC_STATE_MODIFIED)
+			igb_rar_set(adapter, i);
+		adapter->mac_table[i].state &= ~(IGB_MAC_STATE_MODIFIED);
+	}
+}
+
+int igb_available_rars(struct igb_adapter *adapter)
+{
+	struct e1000_hw *hw = &adapter->hw;
+	int i, count = 0;
+
+	for (i = 0; i < hw->mac.rar_entry_count; i++) {
+		if (adapter->mac_table[i].state == 0)
+			count++;
+	}
+	return count;
 }
 
 #ifdef HAVE_SET_RX_MODE
@@ -3224,47 +3576,33 @@ static int igb_write_mc_addr_list(struct net_device *netdev)
 static int igb_write_uc_addr_list(struct net_device *netdev)
 {
 	struct igb_adapter *adapter = netdev_priv(netdev);
-	struct e1000_hw *hw = &adapter->hw;
 	unsigned int vfn = adapter->vfs_allocated_count;
-	unsigned int rar_entries = hw->mac.rar_entry_count - (vfn + 1);
 	int count = 0;
 
 	/* return ENOMEM indicating insufficient memory for addresses */
-	if (netdev_uc_count(netdev) > rar_entries)
+	if (netdev_uc_count(netdev) > igb_available_rars(adapter))
 		return -ENOMEM;
-
-	if (!netdev_uc_empty(netdev) && rar_entries) {
+	if (!netdev_uc_empty(netdev)) {
 #ifdef NETDEV_HW_ADDR_T_UNICAST
 		struct netdev_hw_addr *ha;
 #else
 		struct dev_mc_list *ha;
 #endif
 		netdev_for_each_uc_addr(ha, netdev) {
-			if (!rar_entries)
-				break;
 #ifdef NETDEV_HW_ADDR_T_UNICAST
-			igb_rar_set_qsel(adapter, ha->addr,
-			                 rar_entries--,
-			                 vfn);
+			igb_del_mac_filter(adapter, ha->addr, vfn);
+			igb_add_mac_filter(adapter, ha->addr, vfn);
 #else
-			igb_rar_set_qsel(adapter, ha->da_addr,
-			                 rar_entries--,
-			                 vfn);
+			igb_del_mac_filter(adapter, ha->da_addr, vfn);
+			igb_add_mac_filter(adapter, ha->da_addr, vfn);
 #endif
 			count++;
 		}
 	}
-	/* write the addresses in reverse order to avoid write combining */
-	for (; rar_entries > 0 ; rar_entries--) {
-		E1000_WRITE_REG(hw, E1000_RAH(rar_entries), 0);
-		E1000_WRITE_REG(hw, E1000_RAL(rar_entries), 0);
-	}
-	E1000_WRITE_FLUSH(hw);
-
 	return count;
 }
 
-#endif
+#endif /* HAVE_SET_RX_MODE */
 /**
  * igb_set_rx_mode - Secondary Unicast, Multicast and Promiscuous mode set
  * @netdev: network interface device structure
@@ -3320,7 +3658,7 @@ static void igb_set_rx_mode(struct net_device *netdev)
 			rctl |= E1000_RCTL_UPE;
 			vmolr |= E1000_VMOLR_ROPE;
 		}
-#endif
+#endif /* HAVE_SET_RX_MODE */
 		rctl |= E1000_RCTL_VFE;
 	}
 	E1000_WRITE_REG(hw, E1000_RCTL, rctl);
@@ -3340,6 +3678,45 @@ static void igb_set_rx_mode(struct net_device *netdev)
 	igb_restore_vf_multicasts(adapter);
 }
 
+static void igb_check_wvbr(struct igb_adapter *adapter)
+{
+	struct e1000_hw *hw = &adapter->hw;
+	u32 wvbr = 0;
+
+	switch (hw->mac.type) {
+	case e1000_82576:
+	case e1000_i350:
+		if (!(wvbr = E1000_READ_REG(hw, E1000_WVBR)))
+			return;
+		break;
+	default:
+		break;
+	}
+
+	adapter->wvbr |= wvbr;
+}
+
+#define IGB_STAGGERED_QUEUE_OFFSET 8
+
+static void igb_spoof_check(struct igb_adapter *adapter)
+{
+	int j;
+
+	if (!adapter->wvbr)
+		return;
+
+	for(j = 0; j < adapter->vfs_allocated_count; j++) {
+		if (adapter->wvbr & (1 << j) ||
+		    adapter->wvbr & (1 << (j + IGB_STAGGERED_QUEUE_OFFSET))) {
+			DPRINTK(DRV, WARNING,
+				"Spoof event(s) detected on VF %d\n", j);
+			adapter->wvbr &=
+				~((1 << j) |
+				  (1 << (j + IGB_STAGGERED_QUEUE_OFFSET)));
+		}
+	}
+}
+
 /* Need to wait a few seconds after link up to get diagnostic information from
  * the phy */
 static void igb_update_phy_info(unsigned long data)
@@ -3356,7 +3733,6 @@ bool igb_has_link(struct igb_adapter *adapter)
 {
 	struct e1000_hw *hw = &adapter->hw;
 	bool link_active = FALSE;
-	s32 ret_val = 0;
 
 	/* get_link_status is set on LSC (link status) interrupt or
 	 * rx sequence error interrupt.  get_link_status will stay
@@ -3365,16 +3741,11 @@ bool igb_has_link(struct igb_adapter *adapter)
 	 */
 	switch (hw->phy.media_type) {
 	case e1000_media_type_copper:
-		if (hw->mac.get_link_status) {
-			ret_val = e1000_check_for_link(hw);
-			link_active = !hw->mac.get_link_status;
-		} else {
-			link_active = TRUE;
-		}
-		break;
+		if (!hw->mac.get_link_status)
+			return true;
 	case e1000_media_type_internal_serdes:
-		ret_val = e1000_check_for_link(hw);
-		link_active = hw->mac.serdes_has_link;
+		e1000_check_for_link(hw);
+		link_active = !hw->mac.get_link_status;
 		break;
 	case e1000_media_type_unknown:
 	default:
@@ -3404,6 +3775,7 @@ static void igb_watchdog_task(struct work_struct *work)
 	struct net_device *netdev = adapter->netdev;
 	u32 link;
 	int i;
+	u32 thstat, ctrl_ext;
 
 
 	link = igb_has_link(adapter);
@@ -3423,7 +3795,7 @@ static void igb_watchdog_task(struct work_struct *work)
 			       adapter->link_duplex == FULL_DUPLEX ?
 				 "Full Duplex" : "Half Duplex",
 			       ((ctrl & E1000_CTRL_TFCE) &&
-			        (ctrl & E1000_CTRL_RFCE)) ? "RX/TX" :
+			        (ctrl & E1000_CTRL_RFCE)) ? "RX/TX":
 			       ((ctrl & E1000_CTRL_RFCE) ?  "RX" :
 			       ((ctrl & E1000_CTRL_TFCE) ?  "TX" : "None")));
 			/* adjust timeout factor according to speed/duplex */
@@ -3441,6 +3813,9 @@ static void igb_watchdog_task(struct work_struct *work)
 			netif_tx_wake_all_queues(netdev);
 
 			igb_ping_all_vfs(adapter);
+#ifdef IFLA_VF_MAX
+			igb_check_vf_rate_limit(adapter);
+#endif /* IFLA_VF_MAX */
 
 			/* link state has changed, schedule phy info update */
 			if (!test_bit(__IGB_DOWN, &adapter->state))
@@ -3451,6 +3826,33 @@ static void igb_watchdog_task(struct work_struct *work)
 		if (netif_carrier_ok(netdev)) {
 			adapter->link_speed = 0;
 			adapter->link_duplex = 0;
+			/* check for thermal sensor event on i350 */
+			if (hw->mac.type == e1000_i350) {
+				thstat = E1000_READ_REG(hw, E1000_THSTAT);
+				ctrl_ext = E1000_READ_REG(hw, E1000_CTRL_EXT);
+				if ((hw->phy.media_type ==
+					e1000_media_type_copper) &&
+					!(ctrl_ext &
+					E1000_CTRL_EXT_LINK_MODE_SGMII)) {
+					if (thstat & E1000_THSTAT_PWR_DOWN) {
+						printk(KERN_ERR "igb: %s The "
+						"network adapter was stopped "
+						"because it overheated.\n",
+						netdev->name);
+					}
+					if (thstat & E1000_THSTAT_LINK_THROTTLE) {
+						printk(KERN_INFO 
+							"igb: %s The network "
+							"adapter supported "
+							"link speed "
+							"was downshifted "
+							"because it "
+							"overheated.\n",
+							netdev->name);
+					}
+				}
+			}
+
 			/* Links status message must follow this format */
 			printk(KERN_INFO "igb: %s NIC Link is Down\n",
 			       netdev->name);
@@ -3497,6 +3899,8 @@ static void igb_watchdog_task(struct work_struct *work)
 		E1000_WRITE_REG(hw, E1000_ICS, E1000_ICS_RXDMT0);
 	}
 
+	igb_spoof_check(adapter);
+
 	/* Reset the timer */
 	if (!test_bit(__IGB_DOWN, &adapter->state))
 		mod_timer(&adapter->watchdog_timer,
@@ -3668,7 +4072,7 @@ static void igb_set_itr(struct igb_q_vector *q_vector)
 		goto set_itr_now;
 	}
 
-	if (q_vector->rx_ring)
+	if (q_vector->rx_ring) 
 		current_itr = igb_update_itr(q_vector->rx_ring);
 	if (q_vector->tx_ring) {
 		igb_update_itr(q_vector->tx_ring);
@@ -3938,9 +4342,13 @@ static inline int igb_tx_map(struct igb_ring *tx_ring, struct sk_buff *skb,
 	}
 
 	tx_ring->buffer_info[i].skb = skb;
-#ifdef SIOCSHWTSTAMP
+#ifdef HAVE_HW_TIME_STAMP
+#ifdef SKB_SHARED_TX_IS_UNION
+	tx_ring->buffer_info[i].shtx = skb_shinfo(skb)->tx_flags.flags;
+#else
 	tx_ring->buffer_info[i].shtx = skb_shinfo(skb)->tx_flags;
 #endif
+#endif
 #ifdef NETIF_F_TSO
 	/* multiply data chunks by size of headers */
 	tx_ring->buffer_info[i].bytecount = ((gso_segs - 1) * hlen) + skb->len;
@@ -4039,10 +4447,10 @@ static inline void igb_tx_queue(struct igb_ring *tx_ring,
 
 static int __igb_maybe_stop_tx(struct igb_ring *tx_ring, const u16 size)
 {
-	struct net_device *netdev = tx_ring->netdev;
+	struct net_device *netdev = netdev_ring(tx_ring);
 
 	if (netif_is_multiqueue(netdev))
-		netif_stop_subqueue(netdev, tx_ring->queue_index);
+		netif_stop_subqueue(netdev, ring_queue_index(tx_ring));
 	else
 		netif_stop_queue(netdev);
 
@@ -4058,7 +4466,7 @@ static int __igb_maybe_stop_tx(struct igb_ring *tx_ring, const u16 size)
 
 	/* A reprieve! */
 	if (netif_is_multiqueue(netdev))
-		netif_wake_subqueue(netdev, tx_ring->queue_index);
+		netif_wake_subqueue(netdev, ring_queue_index(tx_ring));
 	else
 		netif_wake_queue(netdev);
 
@@ -4075,16 +4483,12 @@ static inline int igb_maybe_stop_tx(struct igb_ring *tx_ring, const u16 size)
 }
 
 netdev_tx_t igb_xmit_frame_ring(struct sk_buff *skb,
-				struct igb_ring *tx_ring,
-				bool vlan_enable)
+				struct igb_ring *tx_ring)
 {
 	int tso = 0, count;
 	u32 tx_flags = 0;
 	u16 first;
 	u8 hdr_len = 0;
-#ifdef SIOCSHWTSTAMP
-	union skb_shared_tx *shtx = skb_tx(skb);
-#endif
 
 	/* need: 1 descriptor per page,
 	 *       + 2 desc gap to keep tail from touching head,
@@ -4096,14 +4500,21 @@ netdev_tx_t igb_xmit_frame_ring(struct sk_buff *skb,
 		return NETDEV_TX_BUSY;
 	}
 
-#ifdef SIOCSHWTSTAMP
-	if (unlikely(shtx->hardware)) {
-		shtx->in_progress = 1;
+#ifdef HAVE_HW_TIME_STAMP
+#ifdef SKB_SHARED_TX_IS_UNION
+	if (unlikely(skb_shinfo(skb)->tx_flags.flags & SKBTX_HW_TSTAMP)) {
+		skb_shinfo(skb)->tx_flags.flags |= SKBTX_IN_PROGRESS;
 		tx_flags |= IGB_TX_FLAGS_TSTAMP;
 	}
+#else
+	if (unlikely(skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP)) {
+		skb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;
+		tx_flags |= IGB_TX_FLAGS_TSTAMP;
+	}
+#endif
 
 #endif
-	if (vlan_enable && vlan_tx_tag_present(skb)) {
+	if (vlan_tx_tag_present(skb)) {
 		tx_flags |= IGB_TX_FLAGS_VLAN;
 		tx_flags |= (vlan_tx_tag_get(skb) << IGB_TX_FLAGS_VLAN_SHIFT);
 	}
@@ -4144,7 +4555,7 @@ netdev_tx_t igb_xmit_frame_ring(struct sk_buff *skb,
 	igb_tx_queue(tx_ring, tx_flags, count, skb->len, hdr_len);
 
 #ifndef HAVE_TRANS_START_IN_QUEUE
-	tx_ring->netdev->trans_start = jiffies;
+	netdev_ring(tx_ring)->trans_start = jiffies;
 
 #endif
 	/* Make sure there is space in the ring for the next send. */
@@ -4159,7 +4570,7 @@ static inline struct igb_ring *igb_tx_queue_mapping(struct igb_adapter *adapter,
 {
 	unsigned int r_idx = skb->queue_mapping & (IGB_MAX_TX_QUEUES - 1);
 
-	if (r_idx > adapter->num_tx_queues)
+	if (r_idx >= adapter->num_tx_queues)
 		r_idx = r_idx % adapter->num_tx_queues;
 
 	return adapter->tx_ring[r_idx];
@@ -4183,12 +4594,21 @@ static netdev_tx_t igb_xmit_frame(struct sk_buff *skb,
 		return NETDEV_TX_OK;
 	}
 
+	/*
+	 * The minimum packet size with TCTL.PSP set is 17 so pad the skb
+	 * in order to meet this minimum size requirement.
+	 */
+	if (skb->len < 17) {
+		if (skb_padto(skb, 17))
+			return NETDEV_TX_OK;
+		skb->len = 17;
+	}
+
 	/* This goes back to the question of how to logically map a tx queue
 	 * to a flow.  Right now, performance is impacted slightly negatively
 	 * if using multiple tx queues.  If the stack breaks away from a
 	 * single qdisc implementation, we can look at this again. */
-	return igb_xmit_frame_ring(skb, igb_tx_queue_mapping(adapter, skb),
-	                               !!adapter->vlgrp);
+	return igb_xmit_frame_ring(skb, igb_tx_queue_mapping(adapter, skb));
 }
 
 /**
@@ -4366,8 +4786,15 @@ void igb_update_stats(struct igb_adapter *adapter)
 		struct igb_ring *ring = adapter->rx_ring[i];
 		ring->rx_stats.drops += rqdpc_tmp;
 		net_stats->rx_fifo_errors += rqdpc_tmp;
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+		if (!ring->vmdq_netdev) {
+			bytes += ring->rx_stats.bytes;
+			packets += ring->rx_stats.packets;
+		}
+#else
 		bytes += ring->rx_stats.bytes;
 		packets += ring->rx_stats.packets;
+#endif
 	}
 
 	net_stats->rx_bytes = bytes;
@@ -4377,8 +4804,15 @@ void igb_update_stats(struct igb_adapter *adapter)
 	packets = 0;
 	for (i = 0; i < adapter->num_tx_queues; i++) {
 		struct igb_ring *ring = adapter->tx_ring[i];
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+		if (!ring->vmdq_netdev) {
+			bytes += ring->tx_stats.bytes;
+			packets += ring->tx_stats.packets;
+		}
+#else
 		bytes += ring->tx_stats.bytes;
 		packets += ring->tx_stats.packets;
+#endif
 	}
 	net_stats->tx_bytes = bytes;
 	net_stats->tx_packets = packets;
@@ -4499,7 +4933,12 @@ void igb_update_stats(struct igb_adapter *adapter)
 	/* Management Stats */
 	adapter->stats.mgptc += E1000_READ_REG(hw, E1000_MGTPTC);
 	adapter->stats.mgprc += E1000_READ_REG(hw, E1000_MGTPRC);
-	adapter->stats.mgpdc += E1000_READ_REG(hw, E1000_MGTPDC);
+	if (hw->mac.type > e1000_82580) {
+		adapter->stats.o2bgptc += E1000_READ_REG(hw, E1000_O2BGPTC);
+		adapter->stats.o2bspc += E1000_READ_REG(hw, E1000_O2BSPC);
+		adapter->stats.b2ospc += E1000_READ_REG(hw, E1000_B2OSPC);
+		adapter->stats.b2ogprc += E1000_READ_REG(hw, E1000_B2OGPRC);
+	}
 }
 
 static irqreturn_t igb_msix_other(int irq, void *data)
@@ -4515,6 +4954,10 @@ static irqreturn_t igb_msix_other(int irq, void *data)
 	if (icr & E1000_ICR_DOUTSYNC) {
 		/* HW is reporting DMA is out of sync */
 		adapter->stats.doosync++;
+		/* The DMA Out of Sync is also indication of a spoof event
+		 * in IOV mode. Check the Wrong VM Behavior register to
+		 * see if it is really a spoof event. */
+		igb_check_wvbr(adapter);
 	}
 
 	/* Check for a mailbox event */
@@ -4528,6 +4971,10 @@ static irqreturn_t igb_msix_other(int irq, void *data)
 			mod_timer(&adapter->watchdog_timer, jiffies + 1);
 	}
 
+	/* Check for MDD event */
+	if (icr & E1000_ICR_MDDET)
+		igb_process_mdd_event(adapter);
+
 	E1000_WRITE_REG(hw, E1000_EIMS, adapter->eims_other);
 
 	return IRQ_HANDLED;
@@ -4976,7 +5423,8 @@ static int igb_ndo_set_vf_vlan(struct net_device *netdev,
 	int err = 0;
 	struct igb_adapter *adapter = netdev_priv(netdev);
 
-	if ((vf >= adapter->vfs_allocated_count) || (vlan > 4095) || (qos > 7))
+	/* VLAN IDs accepted range 0-4094 */
+	if ((vf >= adapter->vfs_allocated_count) || (vlan > VLAN_VID_MASK-1) || (qos > 7))
 		return -EINVAL;
 	if (vlan || qos) {
 		err = igb_vlvf_set(adapter, vlan, !!vlan, vf);
@@ -4986,6 +5434,7 @@ static int igb_ndo_set_vf_vlan(struct net_device *netdev,
 		igb_set_vmolr(adapter, vf, !vlan);
 		adapter->vf_data[vf].pf_vlan = vlan;
 		adapter->vf_data[vf].pf_qos = qos;
+		igb_set_vf_vlan_strip(adapter, vf, true); 
 		dev_info(&adapter->pdev->dev,
 			 "Setting VLAN %d, QOS 0x%x on VF %d\n", vlan, qos, vf);
 		if (test_bit(__IGB_DOWN, &adapter->state)) {
@@ -5001,6 +5450,7 @@ static int igb_ndo_set_vf_vlan(struct net_device *netdev,
 				   false, vf);
 		igb_set_vmvir(adapter, vlan, vf);
 		igb_set_vmolr(adapter, vf, true);
+		igb_set_vf_vlan_strip(adapter, vf, false); 
 		adapter->vf_data[vf].pf_vlan = 0;
 		adapter->vf_data[vf].pf_qos = 0;
        }
@@ -5013,14 +5463,18 @@ static int igb_set_vf_vlan(struct igb_adapter *adapter, u32 *msgbuf, u32 vf)
 {
 	int add = (msgbuf[0] & E1000_VT_MSGINFO_MASK) >> E1000_VT_MSGINFO_SHIFT;
 	int vid = (msgbuf[1] & E1000_VLVF_VLANID_MASK);
-
+	
+	if (vid)
+		igb_set_vf_vlan_strip(adapter, vf, true); 
+	else
+		igb_set_vf_vlan_strip(adapter, vf, false); 
 	return igb_vlvf_set(adapter, vid, add, vf);
 }
 
 static inline void igb_vf_reset(struct igb_adapter *adapter, u32 vf)
 {
-	/* clear flags */
-	adapter->vf_data[vf].flags &= ~(IGB_VF_FLAG_PF_SET_MAC);
+	/* clear flags except flag that the PF has set the MAC */
+	adapter->vf_data[vf].flags &= IGB_VF_FLAG_PF_SET_MAC;
 	adapter->vf_data[vf].last_nack = jiffies;
 
 	/* reset offloads to defaults */
@@ -5060,7 +5514,6 @@ static void igb_vf_reset_msg(struct igb_adapter *adapter, u32 vf)
 {
 	struct e1000_hw *hw = &adapter->hw;
 	unsigned char *vf_mac = adapter->vf_data[vf].vf_mac_addresses;
-	int rar_entry = hw->mac.rar_entry_count - (vf + 1);
 	u32 reg, msgbuf[3];
 	u8 *addr = (u8 *)(&msgbuf[1]);
 
@@ -5068,7 +5521,8 @@ static void igb_vf_reset_msg(struct igb_adapter *adapter, u32 vf)
 	igb_vf_reset(adapter, vf);
 
 	/* set vf mac address */
-	igb_rar_set_qsel(adapter, vf_mac, rar_entry, vf);
+	igb_del_mac_filter(adapter, vf_mac, vf);
+	igb_add_mac_filter(adapter, vf_mac, vf);
 
 	/* enable transmit and receive for vf */
 	reg = E1000_READ_REG(hw, E1000_VFTE);
@@ -5076,7 +5530,7 @@ static void igb_vf_reset_msg(struct igb_adapter *adapter, u32 vf)
 	reg = E1000_READ_REG(hw, E1000_VFRE);
 	E1000_WRITE_REG(hw, E1000_VFRE, reg | (1 << vf));
 
-	adapter->vf_data[vf].flags = IGB_VF_FLAG_CTS;
+	adapter->vf_data[vf].flags |= IGB_VF_FLAG_CTS;
 
 	/* reply to reset with ack and vf mac address */
 	msgbuf[0] = E1000_VF_RESET | E1000_VT_MSGTYPE_ACK;
@@ -5153,10 +5607,15 @@ static void igb_rcv_msg_from_vf(struct igb_adapter *adapter, u32 vf)
 
 	switch ((msgbuf[0] & 0xFFFF)) {
 	case E1000_VF_SET_MAC_ADDR:
-#ifndef IGB_DISABLE_VF_MAC_SET
-		retval = igb_set_vf_mac_addr(adapter, msgbuf, vf);
-#else
 		retval = -EINVAL;
+#ifndef IGB_DISABLE_VF_MAC_SET
+		if (!(vf_data->flags & IGB_VF_FLAG_PF_SET_MAC))
+			retval = igb_set_vf_mac_addr(adapter, msgbuf, vf);
+		else
+			DPRINTK(DRV, INFO,
+				"VF %d attempted to override administratively "
+				"set MAC address\nReload the VF driver to "
+				"resume operations\n", vf);
 #endif
 		break;
 	case E1000_VF_SET_PROMISC:
@@ -5169,9 +5628,13 @@ static void igb_rcv_msg_from_vf(struct igb_adapter *adapter, u32 vf)
 		retval = igb_set_vf_rlpml(adapter, msgbuf[1], vf);
 		break;
 	case E1000_VF_SET_VLAN:
+		retval = -1;
 #ifdef IFLA_VF_MAX
-		if (adapter->vf_data[vf].pf_vlan)
-			retval = -1;
+		if (vf_data->pf_vlan)
+			DPRINTK(DRV, INFO,
+				"VF %d attempted to override administratively "
+				"set VLAN tag\nReload the VF driver to "
+				"resume operations\n", vf);
 		else
 #endif
 			retval = igb_set_vf_vlan(adapter, msgbuf, vf);
@@ -5315,7 +5778,7 @@ static irqreturn_t igb_intr(int irq, void *data)
 	return IRQ_HANDLED;
 }
 
-static inline void igb_ring_irq_enable(struct igb_q_vector *q_vector)
+void igb_ring_irq_enable(struct igb_q_vector *q_vector)
 {
 	struct igb_adapter *adapter = q_vector->adapter;
 	struct e1000_hw *hw = &adapter->hw;
@@ -5374,7 +5837,7 @@ static int igb_poll(struct napi_struct *napi, int budget)
 	return work_done;
 }
 
-#ifdef SIOCSHWTSTAMP
+#ifdef HAVE_HW_TIME_STAMP
 /**
  * igb_systim_to_hwtstamp - convert system time value to hw timestamp
  * @adapter: board private structure
@@ -5421,7 +5884,7 @@ static void igb_tx_hwtstamp(struct igb_q_vector *q_vector, struct igb_buffer *bu
 	u64 regval;
 
 	/* if skb does not support hw timestamp or TX stamp not valid exit */
-	if (likely(!buffer_info->shtx.hardware) ||
+	if (likely(!buffer_info->shtx & SKBTX_HW_TSTAMP) ||
 	    !(E1000_READ_REG(hw, E1000_TSYNCTXCTL) & E1000_TSYNCTXCTL_VALID))
 		return;
 
@@ -5471,7 +5934,7 @@ static bool igb_clean_tx_irq(struct igb_q_vector *q_vector, int budget)
 #else
 				total_packets++;
 #endif
-#ifdef SIOCSHWTSTAMP
+#ifdef HAVE_HW_TIME_STAMP
 				igb_tx_hwtstamp(q_vector, buffer_info);
 #endif
 			}
@@ -5488,22 +5951,22 @@ static bool igb_clean_tx_irq(struct igb_q_vector *q_vector, int budget)
 	tx_ring->next_to_clean = i;
 
 	if (unlikely(count &&
-		     netif_carrier_ok(tx_ring->netdev) &&
+		     netif_carrier_ok(netdev_ring(tx_ring)) &&
 		     igb_desc_unused(tx_ring) >= IGB_TX_QUEUE_WAKE)) {
 		/* Make sure that anybody stopping the queue after this
 		 * sees the new next_to_clean.
 		 */
 		smp_mb();
-		if (netif_is_multiqueue(tx_ring->netdev)) {
-			if (__netif_subqueue_stopped(tx_ring->netdev, tx_ring->queue_index) &&
+		if (netif_is_multiqueue(netdev_ring(tx_ring))) {
+			if (__netif_subqueue_stopped(netdev_ring(tx_ring), ring_queue_index(tx_ring)) &&
 			    !(test_bit(__IGB_DOWN, &adapter->state))) {
-				netif_wake_subqueue(tx_ring->netdev, tx_ring->queue_index);
+				netif_wake_subqueue(netdev_ring(tx_ring), ring_queue_index(tx_ring));
 				tx_ring->tx_stats.restart_queue++;
 			}
 		} else {
-			if (netif_queue_stopped(tx_ring->netdev) &&
+			if (netif_queue_stopped(netdev_ring(tx_ring)) &&
 			    !(test_bit(__IGB_DOWN, &adapter->state))) {
-				netif_wake_queue(tx_ring->netdev);
+				netif_wake_queue(netdev_ring(tx_ring));
 				tx_ring->tx_stats.restart_queue++;
 			}
 		}
@@ -5511,6 +5974,7 @@ static bool igb_clean_tx_irq(struct igb_q_vector *q_vector, int budget)
 
 	if (test_bit(IGB_RING_FLAG_TX_DETECT_HANG, &tx_ring->flags)) {
 		struct e1000_hw *hw = &adapter->hw;
+
 		/* Detect a transmit hang in hardware, this serializes the
 		 * check with the clearing of time_stamp and movement of i */
 		clear_bit(IGB_RING_FLAG_TX_DETECT_HANG, &tx_ring->flags);
@@ -5542,11 +6006,11 @@ static bool igb_clean_tx_irq(struct igb_q_vector *q_vector, int budget)
 				eop,
 				jiffies,
 				eop_desc->wb.status);
-			if (netif_is_multiqueue(tx_ring->netdev))
-				netif_stop_subqueue(tx_ring->netdev,
-				                    tx_ring->queue_index);
+			if (netif_is_multiqueue(netdev_ring(tx_ring)))
+				netif_stop_subqueue(netdev_ring(tx_ring),
+						    ring_queue_index(tx_ring));
 			else
-				netif_stop_queue(tx_ring->netdev);
+				netif_stop_queue(netdev_ring(tx_ring));
 		}
 	}
 	tx_ring->total_bytes += total_bytes;
@@ -5567,9 +6031,16 @@ static void igb_receive_skb(struct igb_q_vector *q_vector,
                             u16 vlan_tag)
 {
 	struct igb_adapter *adapter = q_vector->adapter;
-
-	if (vlan_tag && adapter->vlgrp)
-		vlan_gro_receive(&q_vector->napi, adapter->vlgrp,
+	struct vlan_group *vlgrp = adapter->vlgrp;
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+	if (q_vector->rx_ring->vmdq_netdev) {
+		struct igb_vmdq_adapter *vadapt;
+		vadapt = netdev_priv(q_vector->rx_ring->vmdq_netdev);
+		vlgrp = vadapt->vlgrp;
+	}
+#endif
+	if (vlan_tag && vlgrp)
+		vlan_gro_receive(&q_vector->napi, vlgrp,
 		                 vlan_tag, skb);
 	else
 		napi_gro_receive(&q_vector->napi, skb);
@@ -5602,8 +6073,15 @@ static inline void igb_rx_checksum(struct igb_ring *ring,
 	if (status_err & (E1000_RXD_STAT_TCPCS | E1000_RXD_STAT_UDPCS))
 		skb->ip_summed = CHECKSUM_UNNECESSARY;
 }
+#ifdef NETIF_F_RXHASH
+static inline void igb_rx_hash(union e1000_adv_rx_desc *rx_desc,
+			       struct sk_buff *skb)
+{
+	skb->rxhash = le32_to_cpu(rx_desc->wb.lower.hi_dword.rss);
+}
+#endif
 
-#ifdef SIOCSHWTSTAMP
+#ifdef HAVE_HW_TIME_STAMP
 static void igb_rx_hwtstamp(struct igb_q_vector *q_vector, u32 staterr,
                                    struct sk_buff *skb)
 {
@@ -6013,7 +6491,6 @@ static void igb_clean_rx_irq(struct igb_q_vector *q_vector,
 		struct igb_buffer *buffer_info = &rx_ring->buffer_info[i];
 		struct sk_buff *skb = buffer_info->skb;
 		union e1000_adv_rx_desc *next_rxd;
-		u16 length = le16_to_cpu(rx_desc->wb.upper.length);
 		u16 vlan_tag;
 
 		rx_desc->wb.upper.status_error = 0;
@@ -6029,40 +6506,42 @@ static void igb_clean_rx_irq(struct igb_q_vector *q_vector,
 		prefetch(next_rxd);
 
 #ifdef CONFIG_IGB_DISABLE_PACKET_SPLIT
+		__skb_put(skb, le16_to_cpu(rx_desc->wb.upper.length));
 		dma_unmap_single(rx_ring->dev, buffer_info->dma,
 				 rx_ring->rx_buffer_len,
 				 DMA_FROM_DEVICE);
 		buffer_info->dma = 0;
-		skb_put(skb, length);
 
 #else
-		if (buffer_info->dma) {
+		if (!skb_is_nonlinear(skb)) {
+			__skb_put(skb, igb_get_hlen(rx_desc));
 			dma_unmap_single(rx_ring->dev, buffer_info->dma,
 			                 IGB_RX_HDR_LEN,
 					 DMA_FROM_DEVICE);
 			buffer_info->dma = 0;
-			skb_put(skb, igb_get_hlen(rx_desc));
 		}
 
-		if (length) {
-			dma_unmap_page(rx_ring->dev, buffer_info->page_dma,
-				       PAGE_SIZE / 2, DMA_FROM_DEVICE);
-			buffer_info->page_dma = 0;
+		if (rx_desc->wb.upper.length) {
+			u16 length = le16_to_cpu(rx_desc->wb.upper.length);
 
 			skb_fill_page_desc(skb, skb_shinfo(skb)->nr_frags,
 					   buffer_info->page,
 					   buffer_info->page_offset,
 					   length);
 
+			skb->len += length;
+			skb->data_len += length;
+			skb->truesize += length;
+
 			if ((page_count(buffer_info->page) != 1) ||
 			    (page_to_nid(buffer_info->page) != current_node))
 				buffer_info->page = NULL;
 			else
 				get_page(buffer_info->page);
 
-			skb->len += length;
-			skb->data_len += length;
-			skb->truesize += length;
+			dma_unmap_page(rx_ring->dev, buffer_info->page_dma,
+				       PAGE_SIZE / 2, DMA_FROM_DEVICE);
+			buffer_info->page_dma = 0;
 		}
 
 		if (!(staterr & E1000_RXD_STAT_EOP)) {
@@ -6081,7 +6560,7 @@ static void igb_clean_rx_irq(struct igb_q_vector *q_vector,
 			goto next_desc;
 		}
 
-#ifdef SIOCSHWTSTAMP
+#ifdef HAVE_HW_TIME_STAMP
 		if (staterr & (E1000_RXDADV_STAT_TSIP | E1000_RXDADV_STAT_TS))
 			igb_rx_hwtstamp(q_vector, staterr, skb);
 #endif
@@ -6090,11 +6569,19 @@ static void igb_clean_rx_irq(struct igb_q_vector *q_vector,
 
 		igb_rx_checksum(rx_ring, staterr, skb);
 
-		skb->protocol = eth_type_trans(skb, rx_ring->netdev);
-
-		vlan_tag = ((staterr & E1000_RXD_STAT_VP) ?
-		            le16_to_cpu(rx_desc->wb.upper.vlan) : 0);
+#ifdef NETIF_F_RXHASH
+		igb_rx_hash(rx_desc, skb);
+#endif
+		skb->protocol = eth_type_trans(skb, netdev_ring(rx_ring));
 
+		if (staterr & E1000_RXD_STAT_VP) {
+			if (test_bit(IGB_RING_FLAG_RX_LB_VLAN_BSWAP, &rx_ring->flags) &&
+			    (staterr & E1000_RXDEXT_STATERR_LB))
+				vlan_tag = be16_to_cpu(rx_desc->wb.upper.vlan);
+			else
+				vlan_tag = le16_to_cpu(rx_desc->wb.upper.vlan);
+		} else
+			vlan_tag = 0;
 #ifdef IGB_LRO
 		if (igb_can_lro(rx_ring, rx_desc, skb))
 			buffer_info->skb = igb_lro_queue(q_vector, skb, vlan_tag);
@@ -6103,10 +6590,11 @@ static void igb_clean_rx_irq(struct igb_q_vector *q_vector,
 			igb_receive_skb(q_vector, skb, vlan_tag);
 
 #ifndef NETIF_F_GRO
-		rx_ring->netdev->last_rx = jiffies;
+		netdev_ring(rx_ring)->last_rx = jiffies;
 
 #endif
 		(*work_done)++;
+
 next_desc:
 		if (*work_done >= budget)
 			break;
@@ -6158,14 +6646,15 @@ void igb_alloc_rx_buffers(struct igb_ring *rx_ring, u16 cleaned_count)
 		struct sk_buff *skb = buffer_info->skb;
 
 		if (likely(!skb)) {
-			skb = netdev_alloc_skb_ip_align(rx_ring->netdev, bufsz);
+			skb = netdev_alloc_skb_ip_align(netdev_ring(rx_ring),
+							bufsz);
 			buffer_info->skb = skb;
 			if (!skb) {
 				rx_ring->rx_stats.alloc_failed++;
 				goto no_buffers;
 			}
 			/* initialize queue mapping */
-			skb_record_rx_queue(skb, rx_ring->queue_index);
+			skb_record_rx_queue(skb, ring_queue_index(rx_ring));
 		}
 
 		if (!buffer_info->dma) {
@@ -6185,7 +6674,8 @@ void igb_alloc_rx_buffers(struct igb_ring *rx_ring, u16 cleaned_count)
 
 #ifndef CONFIG_IGB_DISABLE_PACKET_SPLIT
 		if (!buffer_info->page) {
-			buffer_info->page = netdev_alloc_page(rx_ring->netdev);
+			buffer_info->page =
+				netdev_alloc_page(netdev_ring(rx_ring));
 			if (!buffer_info->page) {
 				rx_ring->rx_stats.alloc_failed++;
 				goto no_buffers;
@@ -6269,7 +6759,7 @@ static int igb_mii_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)
 }
 
 #endif
-#ifdef SIOCSHWTSTAMP
+#ifdef HAVE_HW_TIME_STAMP
 /**
  * igb_hwtstamp_ioctl - control hardware time stamping
  * @netdev:
@@ -6462,7 +6952,7 @@ static int igb_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)
 	case SIOCSMIIREG:
 		return igb_mii_ioctl(netdev, ifr, cmd);
 #endif
-#ifdef SIOCSHWTSTAMP
+#ifdef HAVE_HW_TIME_STAMP
 	case SIOCSHWTSTAMP:
 		return igb_hwtstamp_ioctl(netdev, ifr, cmd);
 #endif
@@ -6503,17 +6993,33 @@ s32 e1000_write_pcie_cap_reg(struct e1000_hw *hw, u32 reg, u16 *value)
 	return E1000_SUCCESS;
 }
 
-static void igb_vlan_rx_register(struct net_device *netdev,
-				 struct vlan_group *grp)
+void igb_enable_vlan_tags(struct igb_adapter *adapter)
 {
-	struct igb_adapter *adapter = netdev_priv(netdev);
 	struct e1000_hw *hw = &adapter->hw;
 	u32 ctrl, rctl;
+	int enable = false;
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+	struct igb_vmdq_adapter *vadapter;
+	int i;
 
-	igb_irq_disable(adapter);
-	adapter->vlgrp = grp;
+	for (i = 1; i < adapter->vmdq_pools; i++) {
+		vadapter = netdev_priv(adapter->vmdq_netdev[i-1]);
+		if (vadapter->vlgrp) {
+			enable = true;
+			igb_set_vf_vlan_strip(adapter, 
+					      adapter->vfs_allocated_count + i,
+					      true);
+		} else
+			igb_set_vf_vlan_strip(adapter, 
+					      adapter->vfs_allocated_count + i,
+					      false);
+	}
+
+#endif
+	if (adapter->vlgrp)
+		enable = true;
 
-	if (grp) {
+	if (enable) {
 		/* enable VLAN tag insert/strip */
 		ctrl = E1000_READ_REG(hw, E1000_CTRL);
 		ctrl |= E1000_CTRL_VME;
@@ -6529,8 +7035,17 @@ static void igb_vlan_rx_register(struct net_device *netdev,
 		ctrl &= ~E1000_CTRL_VME;
 		E1000_WRITE_REG(hw, E1000_CTRL, ctrl);
 	}
-
 	igb_rlpml_set(adapter);
+}
+static void igb_vlan_rx_register(struct net_device *netdev,
+				 struct vlan_group *grp)
+{
+	struct igb_adapter *adapter = netdev_priv(netdev);
+
+	igb_irq_disable(adapter);
+	adapter->vlgrp = grp;
+
+	igb_enable_vlan_tags(adapter);
 
 	if (!test_bit(__IGB_DOWN, &adapter->state))
 		igb_irq_enable(adapter);
@@ -6541,23 +7056,26 @@ static void igb_vlan_rx_add_vid(struct net_device *netdev, u16 vid)
 	struct igb_adapter *adapter = netdev_priv(netdev);
 	struct e1000_hw *hw = &adapter->hw;
 	int pf_id = adapter->vfs_allocated_count;
-#ifndef HAVE_NETDEV_VLAN_FEATURES
-	struct net_device *v_netdev;
-#endif
 
 	/* attempt to add filter to vlvf array */
 	igb_vlvf_set(adapter, vid, TRUE, pf_id);
-
 	/* add the filter since PF can receive vlans w/o entry in vlvf */
 	igb_vfta_set(hw, vid, TRUE);
 #ifndef HAVE_NETDEV_VLAN_FEATURES
 
 	/* Copy feature flags from netdev to the vlan netdev for this vid.
 	 * This allows things like TSO to bubble down to our vlan device.
+	 * There is no need to update netdev for vlan 0 (DCB), since it
+	 * wouldn't has v_netdev.
 	 */
-	v_netdev = vlan_group_get_device(adapter->vlgrp, vid);
-	v_netdev->features |= adapter->netdev->features;
-	vlan_group_set_device(adapter->vlgrp, vid, v_netdev);
+	if (adapter->vlgrp) {
+		struct vlan_group *vlgrp = adapter->vlgrp;
+		struct net_device *v_netdev = vlan_group_get_device(vlgrp, vid);
+		if (v_netdev) {
+			v_netdev->features |= netdev->features;
+			vlan_group_set_device(vlgrp, vid, v_netdev);
+		}
+	}
 #endif
 }
 
@@ -6588,7 +7106,7 @@ static void igb_restore_vlan(struct igb_adapter *adapter)
 
 	if (adapter->vlgrp) {
 		u16 vid;
-		for (vid = 0; vid < VLAN_GROUP_ARRAY_LEN; vid++) {
+		for (vid = 0; vid < VLAN_N_VID; vid++) {
 			if (!vlan_group_get_device(adapter->vlgrp, vid))
 				continue;
 			igb_vlan_rx_add_vid(adapter->netdev, vid);
@@ -6711,11 +7229,10 @@ static int igb_suspend(struct pci_dev *pdev, pm_message_t state)
 {
 #define E1000_PMCSR       0x0044
 #define E1000_PMCSR_PS_D3 0x00000003
-	struct net_device *netdev = NULL;
-	struct igb_adapter *adapter = NULL; 
-	struct e1000_hw *hw = NULL;
-	u32 pmcsr = 0;
-
+        struct net_device *netdev = NULL;
+        struct igb_adapter *adapter = NULL;
+        struct e1000_hw *hw = NULL;
+        u32 pmcsr = 0;
 	int retval;
 	bool wake;
 
@@ -6730,25 +7247,24 @@ static int igb_suspend(struct pci_dev *pdev, pm_message_t state)
 		pci_set_power_state(pdev, PCI_D3hot);
 	}
 
-	/* This is WoL workaround for DH89xxCC */
-	switch (pdev->device) {
-		case E1000_DEV_ID_DH89XXCC_SFP:
-		case E1000_DEV_ID_DH89XXCC_BACKPLANE:
-		case E1000_DEV_ID_DH89XXCC_SERDES:
-		case E1000_DEV_ID_DH89XXCC_SGMII:
-			netdev = pci_get_drvdata(pdev);
-			adapter = netdev_priv(netdev);
-			hw = &adapter->hw;
-			pmcsr = E1000_READ_REG(hw, E1000_PMCSR);
-			pmcsr |= E1000_PMCSR_PS_D3;
-			E1000_WRITE_REG(hw, E1000_PMCSR, pmcsr);
-			E1000_WRITE_REG(hw, E1000_PMCSR, pmcsr);
-			break;
-		default:
-			break;
+        /* This is WoL workaround for DH89xxCC */
+        switch (pdev->device) {
+        case E1000_DEV_ID_DH89XXCC_SFP:
+        case E1000_DEV_ID_DH89XXCC_BACKPLANE:
+        case E1000_DEV_ID_DH89XXCC_SERDES:
+        case E1000_DEV_ID_DH89XXCC_SGMII:
+                netdev = pci_get_drvdata(pdev);
+                adapter = netdev_priv(netdev);
+                hw = &adapter->hw;
+                pmcsr = E1000_READ_REG( hw, E1000_PMCSR );
+                pmcsr |= E1000_PMCSR_PS_D3;
+                E1000_WRITE_REG( hw, E1000_PMCSR, pmcsr );
+                E1000_WRITE_REG( hw, E1000_PMCSR, pmcsr );
+                break;
+        default:
+                break;
 	}
 
-
 	return 0;
 }
 
@@ -6953,44 +7469,54 @@ static void igb_io_resume(struct pci_dev *pdev)
 }
 
 #endif /* HAVE_PCI_ERS */
-static void igb_rar_set_qsel(struct igb_adapter *adapter, u8 *addr, u32 index,
-                             u8 qsel)
+
+int igb_add_mac_filter(struct igb_adapter *adapter, u8 *addr, u16 queue)
 {
-	u32 rar_low, rar_high;
 	struct e1000_hw *hw = &adapter->hw;
+	int i;
 
-	/* HW expects these in little endian so we reverse the byte order
-	 * from network order (big endian) to little endian
-	 */
-	rar_low = ((u32) addr[0] | ((u32) addr[1] << 8) |
-	          ((u32) addr[2] << 16) | ((u32) addr[3] << 24));
-	rar_high = ((u32) addr[4] | ((u32) addr[5] << 8));
-
-	/* Indicate to hardware the Address is Valid. */
-	rar_high |= E1000_RAH_AV;
-
-	if (hw->mac.type == e1000_82575)
-		rar_high |= E1000_RAH_POOL_1 * qsel;
-	else
-		rar_high |= E1000_RAH_POOL_1 << qsel;
+	if (is_zero_ether_addr(addr))
+		return 0;
 
-	E1000_WRITE_REG(hw, E1000_RAL(index), rar_low);
-	E1000_WRITE_FLUSH(hw);
-	E1000_WRITE_REG(hw, E1000_RAH(index), rar_high);
-	E1000_WRITE_FLUSH(hw);
+	for (i = 0; i < hw->mac.rar_entry_count; i++) {
+		if (adapter->mac_table[i].state & IGB_MAC_STATE_IN_USE)
+			continue;
+		adapter->mac_table[i].state = (IGB_MAC_STATE_MODIFIED |
+						   IGB_MAC_STATE_IN_USE);
+		memcpy(adapter->mac_table[i].addr, addr, ETH_ALEN);
+		adapter->mac_table[i].queue = queue;
+		igb_sync_mac_table(adapter);
+		return 0;
+	}
+	return -ENOMEM;
 }
+int igb_del_mac_filter(struct igb_adapter *adapter, u8* addr, u16 queue)
+{
+	/* search table for addr, if found, set to 0 and sync */
+	int i;
+	struct e1000_hw *hw = &adapter->hw;
 
+	if (is_zero_ether_addr(addr))
+		return 0;
+	for (i = 0; i < hw->mac.rar_entry_count; i++) {
+		if (!compare_ether_addr(addr, adapter->mac_table[i].addr) &&
+		    adapter->mac_table[i].queue == queue) {
+			adapter->mac_table[i].state = IGB_MAC_STATE_MODIFIED;
+			memset(adapter->mac_table[i].addr, 0, ETH_ALEN);
+			adapter->mac_table[i].queue = 0;
+			igb_sync_mac_table(adapter);
+			return 0;
+		}
+	}
+	return -ENOMEM;
+}
 static int igb_set_vf_mac(struct igb_adapter *adapter,
                           int vf, unsigned char *mac_addr)
 {
-	struct e1000_hw *hw = &adapter->hw;
-	/* VF MAC addresses start at end of receive addresses and moves
-	 * torwards the first, as a result a collision should not be possible */
-	int rar_entry = hw->mac.rar_entry_count - (vf + 1);
-
+	igb_del_mac_filter(adapter, adapter->vf_data[vf].vf_mac_addresses, vf);
 	memcpy(adapter->vf_data[vf].vf_mac_addresses, mac_addr, ETH_ALEN);
 
-	igb_rar_set_qsel(adapter, mac_addr, rar_entry, vf);
+	igb_add_mac_filter(adapter, mac_addr, vf);
 
 	return 0;
 }
@@ -7004,7 +7530,7 @@ static int igb_ndo_set_vf_mac(struct net_device *netdev, int vf, u8 *mac)
 	adapter->vf_data[vf].flags |= IGB_VF_FLAG_PF_SET_MAC;
 	dev_info(&adapter->pdev->dev, "setting MAC %pM on VF %d\n", mac, vf);
 	dev_info(&adapter->pdev->dev, "Reload the VF driver to make this"
-				      " change effective.");
+				      " change effective.\n");
 	if (test_bit(__IGB_DOWN, &adapter->state)) {
 		dev_warn(&adapter->pdev->dev, "The VF MAC address has been set,"
 			 " but the PF device is not up.\n");
@@ -7014,9 +7540,94 @@ static int igb_ndo_set_vf_mac(struct net_device *netdev, int vf, u8 *mac)
 	return igb_set_vf_mac(adapter, vf, mac);
 }
 
+static int igb_link_mbps(int internal_link_speed)
+{
+	switch (internal_link_speed) {
+	case SPEED_100:
+		return 100;
+	case SPEED_1000:
+		return 1000;
+	default:
+		return 0;
+	}
+}
+
+static void igb_set_vf_rate_limit(struct e1000_hw *hw, int vf, int tx_rate,
+			int link_speed)
+{
+	int rf_dec, rf_int;
+	u32 bcnrc_val;
+
+	if (tx_rate != 0) {
+		/* Calculate the rate factor values to set */
+		rf_int = link_speed / tx_rate;
+		rf_dec = (link_speed - (rf_int * tx_rate));
+		rf_dec = (rf_dec * (1<<E1000_RTTBCNRC_RF_INT_SHIFT)) / tx_rate;
+
+		bcnrc_val = E1000_RTTBCNRC_RS_ENA;
+		bcnrc_val |= ((rf_int<<E1000_RTTBCNRC_RF_INT_SHIFT) &
+				E1000_RTTBCNRC_RF_INT_MASK);
+		bcnrc_val |= (rf_dec & E1000_RTTBCNRC_RF_DEC_MASK);
+	} else {
+		bcnrc_val = 0;
+	}
+
+	E1000_WRITE_REG(hw, E1000_RTTDQSEL, vf); /* vf X uses queue X */
+	/*
+	 * Set global transmit compensation time to the MMW_SIZE in RTTBCNRM
+	 * register. MMW_SIZE=0x014 if 9728-byte jumbo is supported.
+	 */
+	E1000_WRITE_REG(hw, E1000_RTTBCNRM(0), 0x14);
+	E1000_WRITE_REG(hw, E1000_RTTBCNRC, bcnrc_val);
+}
+
+static void igb_check_vf_rate_limit(struct igb_adapter *adapter)
+{
+	int actual_link_speed, i;
+	bool reset_rate = false;
+
+	/* VF TX rate limit was not set */
+	if ((adapter->vf_rate_link_speed == 0) || 
+		(adapter->hw.mac.type != e1000_82576))
+		return;
+
+	actual_link_speed = igb_link_mbps(adapter->link_speed);
+	if (actual_link_speed != adapter->vf_rate_link_speed) {
+		reset_rate = true;
+		adapter->vf_rate_link_speed = 0;
+		dev_info(&adapter->pdev->dev,
+		"Link speed has been changed. VF Transmit rate is disabled\n");
+	}
+
+	for (i = 0; i < adapter->vfs_allocated_count; i++) {
+		if (reset_rate)
+			adapter->vf_data[i].tx_rate = 0;
+
+		igb_set_vf_rate_limit(&adapter->hw, i,
+			adapter->vf_data[i].tx_rate, actual_link_speed);
+	}
+}
+
 static int igb_ndo_set_vf_bw(struct net_device *netdev, int vf, int tx_rate)
 {
-	return -EOPNOTSUPP;
+	struct igb_adapter *adapter = netdev_priv(netdev);
+	struct e1000_hw *hw = &adapter->hw;
+	int actual_link_speed;
+	
+	if (hw->mac.type != e1000_82576)
+		return -EOPNOTSUPP;
+
+	actual_link_speed = igb_link_mbps(adapter->link_speed);
+	if ((vf >= adapter->vfs_allocated_count) ||
+		(!(E1000_READ_REG(hw, E1000_STATUS) & E1000_STATUS_LU)) ||
+		(tx_rate < 0) || (tx_rate > actual_link_speed))
+		return -EINVAL;
+
+	adapter->vf_rate_link_speed = actual_link_speed;
+	adapter->vf_data[vf].tx_rate = (u16)tx_rate;
+	igb_set_vf_rate_limit(hw, vf, tx_rate, actual_link_speed);
+
+	return 0;
 }
 
 static int igb_ndo_get_vf_config(struct net_device *netdev,
@@ -7027,7 +7638,7 @@ static int igb_ndo_get_vf_config(struct net_device *netdev,
 		return -EINVAL;
 	ivi->vf = vf;
 	memcpy(&ivi->mac, adapter->vf_data[vf].vf_mac_addresses, ETH_ALEN);
-	ivi->tx_rate = 0;
+	ivi->tx_rate = adapter->vf_data[vf].tx_rate;
 	ivi->vlan = adapter->vf_data[vf].pf_vlan;
 	ivi->qos = adapter->vf_data[vf].pf_qos;
 	return 0;
@@ -7054,14 +7665,116 @@ static void igb_vmm_control(struct igb_adapter *adapter)
 		reg = E1000_READ_REG(hw, E1000_RPLOLR);
 		reg |= E1000_RPLOLR_STRVLAN;
 		E1000_WRITE_REG(hw, E1000_RPLOLR, reg);
+	case e1000_i350:
+		/* none of the above registers are supported by i350 */
 		break;
 	}
 
+	/* Enable Malicious Driver Detection */
+	if ((hw->mac.type == e1000_i350) && (adapter->vfs_allocated_count) &&
+	    (adapter->mdd))
+		igb_enable_mdd(adapter);
+
 	/* enable replication and loopback support */
-	e1000_vmdq_set_loopback_pf(hw, adapter->vfs_allocated_count &&
-				   (adapter->vmdq_pools <= 1));
+	e1000_vmdq_set_loopback_pf(hw, adapter->vfs_allocated_count ||
+				   adapter->vmdq_pools);
+
+	e1000_vmdq_set_anti_spoofing_pf(hw, adapter->vfs_allocated_count ||
+					adapter->vmdq_pools,
+					adapter->vfs_allocated_count);
 	e1000_vmdq_set_replication_pf(hw, adapter->vfs_allocated_count ||
 				      adapter->vmdq_pools);
 }
 
+static void igb_init_fw(struct igb_adapter *adapter) 
+{
+	struct e1000_fw_drv_info fw_cmd;
+	struct e1000_hw *hw = &adapter->hw;
+	int maj = MAJ;
+	int min = MIN;
+	int build  = BUILD;
+	int i;
+	
+	if (!e1000_get_hw_semaphore_generic(hw)) { 
+		for (i = 0; i <= FW_MAX_RETRIES; i++) {
+			E1000_WRITE_REG(hw, E1000_FWSTS, E1000_FWSTS_FWRI);
+			fw_cmd.hdr.cmd = FW_CMD_DRV_INFO;
+			fw_cmd.hdr.buf_len = FW_CMD_DRV_INFO_LEN;
+			fw_cmd.hdr.cmd_or_resp.cmd_resv = FW_CMD_RESERVED;
+			fw_cmd.port_num = hw->bus.func;
+			fw_cmd.drv_version = (maj << 24) + (min << 16)
+			                      + (build << 8) + FW_UNUSED_VER;
+			fw_cmd.hdr.checksum = e1000_calculate_checksum((u8 *)&fw_cmd,
+			                                           (FW_HDR_LEN +
+			                                            fw_cmd.hdr.buf_len));
+			 e1000_host_interface_command(hw, (u8*)&fw_cmd,
+			                             sizeof(fw_cmd)); 
+			if (fw_cmd.hdr.cmd_or_resp.ret_status == FW_STATUS_SUCCESS)
+				break;
+		}
+	} else
+		dev_warn(pci_dev_to_dev(adapter->pdev),
+			 "Unable to get semaphore, firmware init failed.\n");
+	e1000_put_hw_semaphore_generic(hw);
+}
+static void igb_init_dmac(struct igb_adapter *adapter, u32 pba)
+{
+	struct e1000_hw *hw = &adapter->hw;
+	u32 dmac_thr;
+	u16 hwm;
+
+	if (hw->mac.type > e1000_82580) {
+		if (adapter->dmac != IGB_DMAC_DISABLE) {
+			u32 reg;
+
+			/* force threshold to 0.  */
+			E1000_WRITE_REG(hw, E1000_DMCTXTH, 0);
+
+			/*
+			 * DMA Coalescing high water mark needs to be higher than the
+			 * RX threshold. set hwm to PBA -  2 * max frame size
+			 * */
+			hwm = pba - (2 * adapter->max_frame_size);
+			reg = E1000_READ_REG(hw, E1000_DMACR);
+			reg &= ~E1000_DMACR_DMACTHR_MASK;
+			dmac_thr = pba - 4;
+			reg |= ((dmac_thr << E1000_DMACR_DMACTHR_SHIFT)
+				& E1000_DMACR_DMACTHR_MASK);
+
+			/* transition to L0x or L1 if available..*/
+			reg |= (E1000_DMACR_DMAC_EN | E1000_DMACR_DMAC_LX_MASK);
+
+			/* watchdog timer= usec values in 32usec intervals */
+			reg |= ((adapter->dmac) >> 5);
+			E1000_WRITE_REG(hw, E1000_DMACR, reg);
+
+			/* no lower threshold to disable coalescing(smart fifb)-UTRESH=0*/
+			E1000_WRITE_REG(hw, E1000_DMCRTRH, 0);
+			E1000_WRITE_REG(hw, E1000_FCRTC, hwm);
+
+			/*
+			 * This sets the time to wait before requesting transition to
+			 * low power state to number of usecs needed to receive 1 512
+			 * byte frame at gigabit line rate
+			 */
+			reg = (IGB_DMCTLX_DCFLUSH_DIS | 0x4);
+
+			E1000_WRITE_REG(hw, E1000_DMCTLX, reg);
+
+			/* free space in tx packet buffer to wake from DMA coal */
+			E1000_WRITE_REG(hw, E1000_DMCTXTH, (IGB_MIN_TXPBSIZE -
+				(IGB_TX_BUF_4096 + adapter->max_frame_size)) >> 6);
+
+			/* make low power state decision controlled by DMA coal */
+			reg = E1000_READ_REG(hw, E1000_PCIEMISC);
+			reg &= ~E1000_PCIEMISC_LX_DECISION;
+			E1000_WRITE_REG(hw, E1000_PCIEMISC, reg);
+		} /* endif adapter->dmac is not disabled */
+	} else {
+		u32 reg = E1000_READ_REG(hw, E1000_PCIEMISC);
+		E1000_WRITE_REG(hw, E1000_PCIEMISC,
+		                reg & ~E1000_PCIEMISC_LX_DECISION);
+		E1000_WRITE_REG(hw, E1000_DMACR, 0);
+	}
+}
 /* igb_main.c */
diff --git a/drivers/net/igb/igb_param.c b/drivers/net/igb/igb_param.c
index 7624474..e28f212 100644
--- a/drivers/net/igb/igb_param.c
+++ b/drivers/net/igb/igb_param.c
@@ -39,6 +39,7 @@
 #define OPTION_UNSET   -1
 #define OPTION_DISABLED 0
 #define OPTION_ENABLED  1
+#define MAX_NUM_LIST_OPTS 15
 
 /* All parameters are treated the same, as an integer array of values.
  * This macro just reduces the need to repeat the same declaration code
@@ -77,7 +78,8 @@ IGB_PARAM(InterruptThrottleRate,
 	  "Maximum interrupts per second, per vector, (max 100000), default 3=adaptive");
 #define DEFAULT_ITR                    3
 #define MAX_ITR                   100000
-#define MIN_ITR                      120
+/* #define MIN_ITR                      120 */
+#define MIN_ITR                      0
 /* IntMode (Interrupt Mode)
  *
  * Valid Range: 0 - 2
@@ -135,7 +137,7 @@ IGB_PARAM(LLISize, "Low Latency Interrupt on Packet Size (0-1500), default 0=off
 IGB_PARAM(RSS, "Number of Receive-Side Scaling Descriptor Queues (0-8), default 1=number of cpus");
 
 #define DEFAULT_RSS       1
-#define MAX_RSS          ((adapter->hw.mac.type == e1000_82575) ? 4 : 8)
+#define MAX_RSS           ((adapter->hw.mac.type == e1000_82575) ? 4 : 8)
 #define MIN_RSS           0
 
 /* VMDQ (Enable VMDq multiqueue receive)
@@ -162,6 +164,17 @@ IGB_PARAM(max_vfs, "Number of Virtual Functions: 0 = disable, 1-7 enable, defaul
 #define MAX_SRIOV         7
 #define MIN_SRIOV         0
 
+/* MDD (Enable Malicious Driver Detection)
+ *
+ * Only available when SR-IOV is enabled - max_vfs is greater than 0
+ * 
+ * Valid Range: 0, 1
+ *
+ * Default Value:  1
+ */
+IGB_PARAM(MDD, "Malicious Driver Detection (0/1), default 1 = enabled. "
+	  "Only available when max_vfs is greater than 0");
+
 
 /* QueuePairs (Enable TX/RX queue pairs for interrupt handling)
  *
@@ -175,6 +188,26 @@ IGB_PARAM(QueuePairs, "Enable TX/RX queue pairs for interrupt handling (0,1), de
 #define MAX_QUEUE_PAIRS               1
 #define MIN_QUEUE_PAIRS               0
 
+/* Enable/disable EEE (a.k.a. IEEE802.3az)
+ *
+ * Valid Range: 0, 1
+ *
+ * Default Value: 1
+ */
+ IGB_PARAM(EEE, "Enable/disable on parts that support the feature");
+
+/* Enable/disable DMA Coalescing
+ *
+ * Valid Values: 0(off), 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000,
+ * 9000, 10000(msec), 250(usec), 500(usec)
+ *
+ * Default Value: 0
+ */
+ IGB_PARAM(DMAC, "Disable or set latency for DMA Coalescing ((0=off, 1000-10000(msec), 250, 500 (usec))");
+struct igb_opt_list {
+	int i;
+	char *str;
+};
 struct igb_option {
 	enum { enable_option, range_option, list_option } type;
 	const char *name;
@@ -187,7 +220,7 @@ struct igb_option {
 		} r;
 		struct { /* list_option info */
 			int nr;
-			struct igb_opt_list { int i; char *str; } *p;
+			struct igb_opt_list *p;
 		} l;
 	} arg;
 };
@@ -286,6 +319,9 @@ void __devinit igb_check_options(struct igb_adapter *adapter)
 			case 0:
 				DPRINTK(PROBE, INFO, "%s turned off\n",
 				        opt.name);
+				if(hw->mac.type >= e1000_i350)
+					adapter->dmac = IGB_DMAC_DISABLE;
+				adapter->rx_itr_setting = itr;
 				break;
 			case 1:
 				DPRINTK(PROBE, INFO, "%s set to dynamic mode\n",
@@ -476,6 +512,12 @@ void __devinit igb_check_options(struct igb_adapter *adapter)
 				adapter->vmdq_pools = 1;
 		}
 #endif
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+		if (hw->mac.type == e1000_82575 && adapter->vmdq_pools) {
+			DPRINTK(PROBE, INFO, "VMDq not supported on this part.\n");
+			adapter->vmdq_pools = 0;
+		}
+#endif
 	}
 	{ /* RSS - Enable RSS multiqueue receives */
 		struct igb_option opt = {
@@ -489,6 +531,7 @@ void __devinit igb_check_options(struct igb_adapter *adapter)
 
 		if (adapter->vmdq_pools) {
 			switch (hw->mac.type) {
+#ifndef CONFIG_IGB_VMDQ_NETDEV
 			case e1000_82576:
 				opt.arg.r.max = 2;
 				break;
@@ -497,6 +540,7 @@ void __devinit igb_check_options(struct igb_adapter *adapter)
 					opt.arg.r.max = 3;
 				if (adapter->vmdq_pools <= 2)
 					break;
+#endif
 			default:
 				opt.arg.r.max = 1;
 				break;
@@ -559,6 +603,124 @@ void __devinit igb_check_options(struct igb_adapter *adapter)
 		}
 #endif
 	}
+	{ /* EEE -  Enable EEE for capable adapters */
+
+		if (hw->mac.type >= e1000_i350) {
+			struct igb_option opt = {
+				.type = enable_option,
+				.name = "EEE Support",
+				.err  = "defaulting to Enabled",
+				.def  = OPTION_ENABLED
+			};
+#ifdef module_param_array
+			if (num_EEE > bd) {
+#endif
+				unsigned int eee = EEE[bd];
+				igb_validate_option(&eee, &opt, adapter);
+				adapter->flags |= eee ? IGB_FLAG_EEE : 0;
+				if (eee)
+					hw->dev_spec._82575.eee_disable = false;
+				else
+					hw->dev_spec._82575.eee_disable = true;
+
+#ifdef module_param_array
+			} else {
+				adapter->flags |= opt.def ? IGB_FLAG_EEE : 0;
+				if (adapter->flags & IGB_FLAG_EEE)
+					hw->dev_spec._82575.eee_disable = false;
+				else
+					hw->dev_spec._82575.eee_disable = true;
+			}
+#endif
+		}
+	}
+	{ /* DMAC -  Enable DMA Coalescing for capable adapters */
+
+		if (hw->mac.type >= e1000_i350) {
+			struct igb_opt_list list [] = {
+				{ IGB_DMAC_DISABLE, "DMAC Disable"},
+				{ IGB_DMAC_MIN, "DMAC 250 usec"},
+				{ IGB_DMAC_500, "DMAC 500 usec"},
+				{ IGB_DMAC_EN_DEFAULT, "DMAC 1000 usec"},
+				{ IGB_DMAC_2000, "DMAC 2000 usec"},
+				{ IGB_DMAC_3000, "DMAC 3000 usec"},
+				{ IGB_DMAC_4000, "DMAC 4000 usec"},
+				{ IGB_DMAC_5000, "DMAC 5000 usec"},
+				{ IGB_DMAC_6000, "DMAC 6000 usec"},
+				{ IGB_DMAC_7000, "DMAC 7000 usec"},
+				{ IGB_DMAC_8000, "DMAC 8000 usec"},
+				{ IGB_DMAC_9000, "DMAC 9000 usec"},
+				{ IGB_DMAC_MAX, "DMAC 10000 usec"}
+			};
+			struct igb_option opt = {
+				.type = list_option,
+				.name = "DMA Coalescing",
+				.err  = "using default of "__MODULE_STRING(IGB_DMAC_DISABLE),
+				.def  = IGB_DMAC_DISABLE,
+				.arg = { .l = { .nr = 13,
+					 	.p = list
+					}
+				}
+			};
+#ifdef module_param_array
+			if (num_DMAC > bd) {
+#endif
+				unsigned int dmac = DMAC[bd];
+				if (adapter->rx_itr_setting == IGB_DMAC_DISABLE)
+					dmac = IGB_DMAC_DISABLE;
+				igb_validate_option(&dmac, &opt, adapter);
+				switch (dmac) {
+				case IGB_DMAC_DISABLE:
+					adapter->dmac = dmac;
+					break;
+				case IGB_DMAC_MIN:
+					adapter->dmac = dmac;
+					break;
+				case IGB_DMAC_500:
+					adapter->dmac = dmac;
+					break;
+				case IGB_DMAC_EN_DEFAULT:
+					adapter->dmac = dmac;
+					break;
+				case IGB_DMAC_2000:
+					adapter->dmac = dmac;
+					break;
+				case IGB_DMAC_3000:
+					adapter->dmac = dmac;
+					break;
+				case IGB_DMAC_4000:
+					adapter->dmac = dmac;
+					break;
+				case IGB_DMAC_5000:
+					adapter->dmac = dmac;
+					break;
+				case IGB_DMAC_6000:
+					adapter->dmac = dmac;
+					break;
+				case IGB_DMAC_7000:
+					adapter->dmac = dmac;
+					break;
+				case IGB_DMAC_8000:
+					adapter->dmac = dmac;
+					break;
+				case IGB_DMAC_9000:
+					adapter->dmac = dmac;
+					break;
+				case IGB_DMAC_MAX:
+					adapter->dmac = dmac;
+					break;
+				default:
+					adapter->dmac = opt.def;
+					DPRINTK(PROBE, INFO,
+					"Invalid DMAC setting, "
+					"resetting DMAC to %d\n", opt.def);
+				}
+#ifdef module_param_array
+			} else
+				adapter->dmac = opt.def;
+#endif
+		}
+	}
 	{ /* Node assignment */
 		static struct igb_option opt = {
 			.type = range_option,
@@ -605,5 +767,28 @@ void __devinit igb_check_options(struct igb_adapter *adapter)
 #endif
 		adapter->node = node_param;
 	}
+	{ /* MDD - Enable Malicious Driver Detection. Only available when
+	     SR-IOV is enabled. */
+		struct igb_option opt = {
+			.type = enable_option,
+			.name = "Malicious Driver Detection",
+			.err  = "defaulting to 1",
+			.def  = OPTION_ENABLED,
+			.arg  = { .r = { .min = OPTION_DISABLED,
+					 .max = OPTION_ENABLED } }
+		};
+
+#ifdef module_param_array
+		if (num_MDD > bd) {
+#endif
+			adapter->mdd = MDD[bd];
+			igb_validate_option((uint *)&adapter->mdd, &opt,
+					    adapter);
+#ifdef module_param_array
+		} else {
+			adapter->mdd = opt.def;
+		}
+#endif
+	}
 }
 
diff --git a/drivers/net/igb/igb_vmdq.c b/drivers/net/igb/igb_vmdq.c
new file mode 100644
index 0000000..3fcfc3a
--- /dev/null
+++ b/drivers/net/igb/igb_vmdq.c
@@ -0,0 +1,437 @@
+/*******************************************************************************
+
+  Intel(R) Gigabit Ethernet Linux driver
+  Copyright(c) 2007-2010 Intel Corporation.
+
+  This program is free software; you can redistribute it and/or modify it
+  under the terms and conditions of the GNU General Public License,
+  version 2, as published by the Free Software Foundation.
+
+  This program is distributed in the hope it will be useful, but WITHOUT
+  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+  more details.
+
+  You should have received a copy of the GNU General Public License along with
+  this program; if not, write to the Free Software Foundation, Inc.,
+  51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+
+  The full GNU General Public License is included in this distribution in
+  the file called "COPYING".
+
+  Contact Information:
+  e1000-devel Mailing List <e1000-devel@lists.sourceforge.net>
+  Intel Corporation, 5200 N.E. Elam Young Parkway, Hillsboro, OR 97124-6497
+
+*******************************************************************************/
+
+
+#include <linux/tcp.h>
+
+#include "igb.h"
+#include "igb_vmdq.h"
+#include <linux/if_vlan.h>
+
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+int igb_vmdq_open(struct net_device *dev)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(dev);
+	struct igb_adapter *adapter = vadapter->real_adapter;
+	struct net_device *main_netdev = adapter->netdev;
+	int hw_queue = vadapter->rx_ring->queue_index +
+		       adapter->vfs_allocated_count;
+
+	if (test_bit(__IGB_DOWN, &adapter->state)) {
+		DPRINTK(DRV, WARNING,
+			"Open %s before opening this device.\n",
+			main_netdev->name);
+		return -EAGAIN;
+	}
+	netif_carrier_off(dev);
+	vadapter->tx_ring->vmdq_netdev = dev;
+	vadapter->rx_ring->vmdq_netdev = dev;
+	if (is_valid_ether_addr(dev->dev_addr)) {
+		igb_del_mac_filter(adapter, dev->dev_addr, hw_queue);
+		igb_add_mac_filter(adapter, dev->dev_addr, hw_queue);
+	}
+	netif_carrier_on(dev);
+	return 0;
+}
+
+int igb_vmdq_close(struct net_device *dev)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(dev);
+	struct igb_adapter *adapter = vadapter->real_adapter;
+	int hw_queue = vadapter->rx_ring->queue_index +
+		       adapter->vfs_allocated_count;
+
+	netif_carrier_off(dev);
+	igb_del_mac_filter(adapter, dev->dev_addr, hw_queue);
+
+	vadapter->tx_ring->vmdq_netdev = NULL;
+	vadapter->rx_ring->vmdq_netdev = NULL;
+	return 0;
+}
+
+netdev_tx_t igb_vmdq_xmit_frame(struct sk_buff *skb, struct net_device *dev)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(dev);
+
+	return igb_xmit_frame_ring(skb, vadapter->tx_ring);
+}
+
+struct net_device_stats *igb_vmdq_get_stats(struct net_device *dev)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(dev);
+        struct igb_adapter *adapter = vadapter->real_adapter;
+        struct e1000_hw *hw = &adapter->hw;
+	int hw_queue = vadapter->rx_ring->queue_index +
+		       adapter->vfs_allocated_count;
+
+	vadapter->net_stats.rx_packets +=
+			E1000_READ_REG(hw, E1000_PFVFGPRC(hw_queue));
+	E1000_WRITE_REG(hw, E1000_PFVFGPRC(hw_queue), 0);
+        vadapter->net_stats.tx_packets +=
+			E1000_READ_REG(hw, E1000_PFVFGPTC(hw_queue));
+        E1000_WRITE_REG(hw, E1000_PFVFGPTC(hw_queue), 0);
+        vadapter->net_stats.rx_bytes +=
+			E1000_READ_REG(hw, E1000_PFVFGORC(hw_queue));
+        E1000_WRITE_REG(hw, E1000_PFVFGORC(hw_queue), 0);
+        vadapter->net_stats.tx_bytes +=
+			E1000_READ_REG(hw, E1000_PFVFGOTC(hw_queue));
+        E1000_WRITE_REG(hw, E1000_PFVFGOTC(hw_queue), 0);
+        vadapter->net_stats.multicast +=
+			E1000_READ_REG(hw, E1000_PFVFMPRC(hw_queue));
+        E1000_WRITE_REG(hw, E1000_PFVFMPRC(hw_queue), 0);
+	/* only return the current stats */
+	return &vadapter->net_stats;
+}
+
+/**
+ * igb_write_vm_addr_list - write unicast addresses to RAR table
+ * @netdev: network interface device structure
+ *
+ * Writes unicast address list to the RAR table.
+ * Returns: -ENOMEM on failure/insufficient address space
+ *                0 on no addresses written
+ *                X on writing X addresses to the RAR table
+ **/
+static int igb_write_vm_addr_list(struct net_device *netdev)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(netdev);
+        struct igb_adapter *adapter = vadapter->real_adapter;
+	int count = 0;
+	int hw_queue = vadapter->rx_ring->queue_index +
+		       adapter->vfs_allocated_count;
+
+	/* return ENOMEM indicating insufficient memory for addresses */
+	if (netdev_uc_count(netdev) > igb_available_rars(adapter))
+		return -ENOMEM;
+
+	if (!netdev_uc_empty(netdev)) {
+#ifdef NETDEV_HW_ADDR_T_UNICAST
+		struct netdev_hw_addr *ha;
+#else
+		struct dev_mc_list *ha;
+#endif
+		netdev_for_each_uc_addr(ha, netdev) {
+#ifdef NETDEV_HW_ADDR_T_UNICAST
+			igb_del_mac_filter(adapter, ha->addr, hw_queue);
+			igb_add_mac_filter(adapter, ha->addr, hw_queue);
+#else
+			igb_del_mac_filter(adapter, ha->da_addr, hw_queue);
+			igb_add_mac_filter(adapter, ha->da_addr, hw_queue);
+#endif
+			count++;
+		}
+	}
+	return count;
+}
+
+
+#define E1000_VMOLR_UPE		0x20000000 /* Unicast promiscuous mode */
+void igb_vmdq_set_rx_mode(struct net_device *dev)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(dev);
+        struct igb_adapter *adapter = vadapter->real_adapter;
+        struct e1000_hw *hw = &adapter->hw;
+	u32 vmolr, rctl;
+	int hw_queue = vadapter->rx_ring->queue_index +
+		       adapter->vfs_allocated_count;
+
+	/* Check for Promiscuous and All Multicast modes */
+	vmolr = E1000_READ_REG(hw, E1000_VMOLR(hw_queue));
+
+	/* clear the affected bits */
+	vmolr &= ~(E1000_VMOLR_UPE | E1000_VMOLR_MPME |
+		   E1000_VMOLR_ROPE | E1000_VMOLR_ROMPE);
+
+	if (dev->flags & IFF_PROMISC) {
+		vmolr |= E1000_VMOLR_UPE;
+		rctl = E1000_READ_REG(hw, E1000_RCTL);
+		rctl |= E1000_RCTL_UPE;
+		E1000_WRITE_REG(hw, E1000_RCTL, rctl);
+	} else {
+		rctl = E1000_READ_REG(hw, E1000_RCTL);
+		rctl &= ~E1000_RCTL_UPE;
+		E1000_WRITE_REG(hw, E1000_RCTL, rctl);
+		if (dev->flags & IFF_ALLMULTI) {
+			vmolr |= E1000_VMOLR_MPME;
+		} else {
+			/*
+			 * Write addresses to the MTA, if the attempt fails
+			 * then we should just turn on promiscous mode so
+			 * that we can at least receive multicast traffic
+			 */
+			if (igb_write_mc_addr_list(adapter->netdev) != 0)
+				vmolr |= E1000_VMOLR_ROMPE;
+		}
+#ifdef HAVE_SET_RX_MODE
+		/*
+		 * Write addresses to available RAR registers, if there is not
+		 * sufficient space to store all the addresses then enable
+		 * unicast promiscous mode
+		 */
+		if (igb_write_vm_addr_list(dev) < 0)
+			vmolr |= E1000_VMOLR_UPE;
+#endif
+	}
+	E1000_WRITE_REG(hw, E1000_VMOLR(hw_queue), vmolr);
+
+	return;
+}
+
+int igb_vmdq_set_mac(struct net_device *dev, void *p)
+{
+	struct sockaddr *addr = p;
+	struct igb_vmdq_adapter *vadapter = netdev_priv(dev);
+        struct igb_adapter *adapter = vadapter->real_adapter;
+	int hw_queue = vadapter->rx_ring->queue_index +
+		       adapter->vfs_allocated_count;
+
+	igb_del_mac_filter(adapter, dev->dev_addr, hw_queue);
+	memcpy(dev->dev_addr, addr->sa_data, dev->addr_len);
+	return igb_add_mac_filter(adapter, dev->dev_addr, hw_queue);
+}
+
+int igb_vmdq_change_mtu(struct net_device *dev, int new_mtu)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(dev);
+	struct igb_adapter *adapter = vadapter->real_adapter;
+
+	if (adapter->netdev->mtu < new_mtu) {
+		DPRINTK(PROBE, INFO,
+			"Set MTU on %s to >= %d "
+			"before changing MTU on %s\n",
+			adapter->netdev->name, new_mtu, dev->name);
+		return -EINVAL;
+	}
+	dev->mtu = new_mtu;
+	return 0;
+}
+
+void igb_vmdq_tx_timeout(struct net_device *dev)
+{
+	return;
+}
+
+void igb_vmdq_vlan_rx_register(struct net_device *dev, struct vlan_group *grp)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(dev);
+	struct igb_adapter *adapter = vadapter->real_adapter;
+	struct e1000_hw *hw = &adapter->hw;
+	int hw_queue = vadapter->rx_ring->queue_index +
+		       adapter->vfs_allocated_count;
+
+	vadapter->vlgrp = grp;
+
+	igb_enable_vlan_tags(adapter);
+	E1000_WRITE_REG(hw, E1000_VMVIR(hw_queue), 0);
+
+	return;
+}
+void igb_vmdq_vlan_rx_add_vid(struct net_device *dev, unsigned short vid)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(dev);
+	struct igb_adapter *adapter = vadapter->real_adapter;
+#ifndef HAVE_NETDEV_VLAN_FEATURES
+	struct net_device *v_netdev;
+#endif
+	int hw_queue = vadapter->rx_ring->queue_index +
+		       adapter->vfs_allocated_count;
+
+	/* attempt to add filter to vlvf array */
+	igb_vlvf_set(adapter, vid, TRUE, hw_queue);
+
+#ifndef HAVE_NETDEV_VLAN_FEATURES
+
+	/* Copy feature flags from netdev to the vlan netdev for this vid.
+	 * This allows things like TSO to bubble down to our vlan device.
+	 */
+	v_netdev = vlan_group_get_device(vadapter->vlgrp, vid);
+	v_netdev->features |= adapter->netdev->features;
+	vlan_group_set_device(vadapter->vlgrp, vid, v_netdev);
+#endif
+
+	return;
+}
+void igb_vmdq_vlan_rx_kill_vid(struct net_device *dev, unsigned short vid)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(dev);
+	struct igb_adapter *adapter = vadapter->real_adapter;
+	int hw_queue = vadapter->rx_ring->queue_index +
+		       adapter->vfs_allocated_count;
+
+	vlan_group_set_device(vadapter->vlgrp, vid, NULL);
+	/* remove vlan from VLVF table array */
+	igb_vlvf_set(adapter, vid, FALSE, hw_queue);
+
+
+	return;
+}
+
+static int igb_vmdq_get_settings(struct net_device *netdev,
+				   struct ethtool_cmd *ecmd)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(netdev);
+	struct igb_adapter *adapter = vadapter->real_adapter;
+	struct e1000_hw *hw = &adapter->hw;
+	u32 status;
+
+	if (hw->phy.media_type == e1000_media_type_copper) {
+
+		ecmd->supported = (SUPPORTED_10baseT_Half |
+				   SUPPORTED_10baseT_Full |
+				   SUPPORTED_100baseT_Half |
+				   SUPPORTED_100baseT_Full |
+				   SUPPORTED_1000baseT_Full|
+				   SUPPORTED_Autoneg |
+				   SUPPORTED_TP);
+		ecmd->advertising = ADVERTISED_TP;
+
+		if (hw->mac.autoneg == 1) {
+			ecmd->advertising |= ADVERTISED_Autoneg;
+			/* the e1000 autoneg seems to match ethtool nicely */
+			ecmd->advertising |= hw->phy.autoneg_advertised;
+		}
+
+		ecmd->port = PORT_TP;
+		ecmd->phy_address = hw->phy.addr;
+	} else {
+		ecmd->supported   = (SUPPORTED_1000baseT_Full |
+				     SUPPORTED_FIBRE |
+				     SUPPORTED_Autoneg);
+
+		ecmd->advertising = (ADVERTISED_1000baseT_Full |
+				     ADVERTISED_FIBRE |
+				     ADVERTISED_Autoneg);
+
+		ecmd->port = PORT_FIBRE;
+	}
+
+	ecmd->transceiver = XCVR_INTERNAL;
+
+	status = E1000_READ_REG(hw, E1000_STATUS);
+
+	if (status & E1000_STATUS_LU) {
+
+		if ((status & E1000_STATUS_SPEED_1000) ||
+		    hw->phy.media_type != e1000_media_type_copper)
+			ecmd->speed = SPEED_1000;
+		else if (status & E1000_STATUS_SPEED_100)
+			ecmd->speed = SPEED_100;
+		else
+			ecmd->speed = SPEED_10;
+
+		if ((status & E1000_STATUS_FD) ||
+		    hw->phy.media_type != e1000_media_type_copper)
+			ecmd->duplex = DUPLEX_FULL;
+		else
+			ecmd->duplex = DUPLEX_HALF;
+	} else {
+		ecmd->speed = -1;
+		ecmd->duplex = -1;
+	}
+
+	ecmd->autoneg = hw->mac.autoneg ? AUTONEG_ENABLE : AUTONEG_DISABLE;
+	return 0;
+}
+
+
+static u32 igb_vmdq_get_msglevel(struct net_device *netdev)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(netdev);
+	struct igb_adapter *adapter = vadapter->real_adapter;
+	return adapter->msg_enable;
+}
+
+static void igb_vmdq_get_drvinfo(struct net_device *netdev,
+				   struct ethtool_drvinfo *drvinfo)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(netdev);
+	struct igb_adapter *adapter = vadapter->real_adapter;
+	struct net_device *main_netdev = adapter->netdev;
+
+	strncpy(drvinfo->driver, igb_driver_name, 32);
+	strncpy(drvinfo->version, igb_driver_version, 32);
+
+	strncpy(drvinfo->fw_version, "N/A", 4);
+	snprintf(drvinfo->bus_info, 32, "%s VMDQ %d", main_netdev->name,
+		 vadapter->rx_ring->queue_index);
+	drvinfo->n_stats = 0;
+	drvinfo->testinfo_len = 0;
+	drvinfo->regdump_len = 0;
+}
+
+static void igb_vmdq_get_ringparam(struct net_device *netdev,
+				     struct ethtool_ringparam *ring)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(netdev);
+
+	struct igb_ring *tx_ring = vadapter->tx_ring;
+	struct igb_ring *rx_ring = vadapter->rx_ring;
+
+	ring->rx_max_pending = IGB_MAX_RXD;
+	ring->tx_max_pending = IGB_MAX_TXD;
+	ring->rx_mini_max_pending = 0;
+	ring->rx_jumbo_max_pending = 0;
+	ring->rx_pending = rx_ring->count;
+	ring->tx_pending = tx_ring->count;
+	ring->rx_mini_pending = 0;
+	ring->rx_jumbo_pending = 0;
+}
+static u32 igb_vmdq_get_rx_csum(struct net_device *netdev)
+{
+	struct igb_vmdq_adapter *vadapter = netdev_priv(netdev);
+	struct igb_adapter *adapter = vadapter->real_adapter;
+
+	return test_bit(IGB_RING_FLAG_RX_CSUM, &adapter->rx_ring[0]->flags);
+}
+
+
+static struct ethtool_ops igb_vmdq_ethtool_ops = {
+	.get_settings           = igb_vmdq_get_settings,
+	.get_drvinfo            = igb_vmdq_get_drvinfo,
+	.get_link               = ethtool_op_get_link,
+	.get_ringparam          = igb_vmdq_get_ringparam,
+	.get_rx_csum            = igb_vmdq_get_rx_csum,
+	.get_tx_csum            = ethtool_op_get_tx_csum,
+	.get_sg                 = ethtool_op_get_sg,
+	.set_sg                 = ethtool_op_set_sg,
+	.get_msglevel           = igb_vmdq_get_msglevel,
+#ifdef NETIF_F_TSO
+	.get_tso                = ethtool_op_get_tso,
+#endif
+#ifdef HAVE_ETHTOOL_GET_PERM_ADDR
+	.get_perm_addr          = ethtool_op_get_perm_addr,
+#endif
+};
+
+void igb_vmdq_set_ethtool_ops(struct net_device *netdev)
+{
+	SET_ETHTOOL_OPS(netdev, &igb_vmdq_ethtool_ops);
+}
+
+
+#endif /* CONFIG_IGB_VMDQ_NETDEV */
+
diff --git a/drivers/net/igb/igb_vmdq.h b/drivers/net/igb/igb_vmdq.h
new file mode 100644
index 0000000..2660c0b
--- /dev/null
+++ b/drivers/net/igb/igb_vmdq.h
@@ -0,0 +1,46 @@
+/*******************************************************************************
+
+  Intel(R) Gigabit Ethernet Linux driver
+  Copyright(c) 2007-2010 Intel Corporation.
+
+  This program is free software; you can redistribute it and/or modify it
+  under the terms and conditions of the GNU General Public License,
+  version 2, as published by the Free Software Foundation.
+
+  This program is distributed in the hope it will be useful, but WITHOUT
+  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+  more details.
+
+  You should have received a copy of the GNU General Public License along with
+  this program; if not, write to the Free Software Foundation, Inc.,
+  51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+
+  The full GNU General Public License is included in this distribution in
+  the file called "COPYING".
+
+  Contact Information:
+  e1000-devel Mailing List <e1000-devel@lists.sourceforge.net>
+  Intel Corporation, 5200 N.E. Elam Young Parkway, Hillsboro, OR 97124-6497
+
+*******************************************************************************/
+
+#ifndef _IGB_VMDQ_H_
+#define _IGB_VMDQ_H_
+
+#ifdef CONFIG_IGB_VMDQ_NETDEV
+int igb_vmdq_open(struct net_device *dev);
+int igb_vmdq_close(struct net_device *dev);
+netdev_tx_t igb_vmdq_xmit_frame(struct sk_buff *skb, struct net_device *dev);
+struct net_device_stats *igb_vmdq_get_stats(struct net_device *dev);
+void igb_vmdq_set_rx_mode(struct net_device *dev);
+int igb_vmdq_set_mac(struct net_device *dev, void *addr);
+int igb_vmdq_change_mtu(struct net_device *dev, int new_mtu);
+void igb_vmdq_tx_timeout(struct net_device *dev);
+void igb_vmdq_vlan_rx_register(struct net_device *dev,
+				 struct vlan_group *grp);
+void igb_vmdq_vlan_rx_add_vid(struct net_device *dev, unsigned short vid);
+void igb_vmdq_vlan_rx_kill_vid(struct net_device *dev, unsigned short vid);
+void igb_vmdq_set_ethtool_ops(struct net_device *netdev);
+#endif /* CONFIG_IGB_VMDQ_NETDEV */
+#endif /* _IGB_VMDQ_H_ */
diff --git a/drivers/net/igb/kcompat.c b/drivers/net/igb/kcompat.c
index 85ff52e..a17385f 100644
--- a/drivers/net/igb/kcompat.c
+++ b/drivers/net/igb/kcompat.c
@@ -379,28 +379,6 @@ int _kc_snprintf(char * buf, size_t size, const char *fmt, ...)
 #endif /* < 2.4.8 */
 
 /*****************************************************************************/
-#if ( LINUX_VERSION_CODE < KERNEL_VERSION(2,4,21) )
-struct sk_buff *
-_kc_skb_pad(struct sk_buff *skb, int pad)
-{
-        struct sk_buff *nskb;
-        
-        /* If the skbuff is non linear tailroom is always zero.. */
-        if(skb_tailroom(skb) >= pad)
-        {
-                memset(skb->data+skb->len, 0, pad);
-                return skb;
-        }
-        
-        nskb = skb_copy_expand(skb, skb_headroom(skb), skb_tailroom(skb) + pad, GFP_ATOMIC);
-        kfree_skb(skb);
-        if(nskb)
-                memset(nskb->data+nskb->len, 0, pad);
-        return nskb;
-} 
-#endif /* < 2.4.21 */
-
-/*****************************************************************************/
 #if ( LINUX_VERSION_CODE < KERNEL_VERSION(2,4,13) )
 
 /**************************************/
@@ -646,6 +624,37 @@ void *_kc_kzalloc(size_t size, int flags)
 
 /*****************************************************************************/
 #if ( LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19) )
+int _kc_skb_pad(struct sk_buff *skb, int pad)
+{
+	int ntail;
+        
+        /* If the skbuff is non linear tailroom is always zero.. */
+        if(!skb_cloned(skb) && skb_tailroom(skb) >= pad) {
+		memset(skb->data+skb->len, 0, pad);
+		return 0;
+        }
+        
+	ntail = skb->data_len + pad - (skb->end - skb->tail);
+	if (likely(skb_cloned(skb) || ntail > 0)) {
+		if (pskb_expand_head(skb, 0, ntail, GFP_ATOMIC));
+			goto free_skb;
+	}
+
+#ifdef MAX_SKB_FRAGS
+	if (skb_is_nonlinear(skb) &&
+	    !__pskb_pull_tail(skb, skb->data_len))
+		goto free_skb;
+
+#endif
+	memset(skb->data + skb->len, 0, pad);
+        return 0;
+
+free_skb:
+	kfree_skb(skb);
+	return -ENOMEM;
+} 
+
+#if (!(RHEL_RELEASE_CODE && RHEL_RELEASE_CODE >= RHEL_RELEASE_VERSION(5,4)))
 int _kc_pci_save_state(struct pci_dev *pdev)
 {
 	struct net_device *netdev = pci_get_drvdata(pdev);
@@ -705,6 +714,7 @@ void _kc_pci_restore_state(struct pci_dev *pdev)
 #endif
 	}
 }
+#endif /* !(RHEL_RELEASE_CODE >= RHEL 5.4) */
 
 #ifdef HAVE_PCI_ERS
 void _kc_free_netdev(struct net_device *netdev)
@@ -726,7 +736,17 @@ void _kc_free_netdev(struct net_device *netdev)
 #endif
 }
 #endif
-#endif /* <= 2.6.18 */
+
+void *_kc_kmemdup(const void *src, size_t len, unsigned gfp)
+{
+	void *p;
+
+	p = kzalloc(len, gfp);
+	if (p)
+		memcpy(p, src, len);
+	return p;
+}
+#endif /* <= 2.6.19 */
 
 /*****************************************************************************/
 #if ( LINUX_VERSION_CODE < KERNEL_VERSION(2,6,22) )
@@ -1083,3 +1103,9 @@ int _kc_ethtool_op_set_flags(struct net_device *dev, u32 data, u32 supported)
 	return 0;
 }
 #endif /* < 2.6.36 */
+
+/******************************************************************************/
+#if ( LINUX_VERSION_CODE < KERNEL_VERSION(2,6,39) )
+#if (!(RHEL_RELEASE_CODE && RHEL_RELEASE_CODE > RHEL_RELEASE_VERSION(6,0)))
+#endif /* !(RHEL_RELEASE_CODE > RHEL_RELEASE_VERSION(6,0)) */
+#endif /* < 2.6.39 */
diff --git a/drivers/net/igb/kcompat.h b/drivers/net/igb/kcompat.h
index a467d9b..ae53d9f 100644
--- a/drivers/net/igb/kcompat.h
+++ b/drivers/net/igb/kcompat.h
@@ -50,7 +50,9 @@
 #include <linux/ip.h>
 #include <linux/udp.h>
 #include <linux/mii.h>
+#include <linux/vmalloc.h>
 #include <asm/io.h>
+#include <linux/ethtool.h>
 
 /* NAPI enable/disable flags here */
 #define NAPI
@@ -172,18 +174,6 @@ struct msix_entry {
 #define CONFIG_NET_POLL_CONTROLLER
 #endif
 
-#ifndef NETDEV_TX_OK
-#define NETDEV_TX_OK 0
-#endif
-
-#ifndef NETDEV_TX_BUSY
-#define NETDEV_TX_BUSY 1
-#endif
-
-#ifndef NETDEV_TX_LOCKED
-#define NETDEV_TX_LOCKED -1
-#endif
-
 #ifndef SKB_DATAREF_SHIFT
 /* if we do not have the infrastructure to detect if skb_header is cloned
    just return false in all cases */
@@ -974,13 +964,6 @@ struct vlan_ethhdr {
 #endif /* 2.4.20 => 2.4.19 */
 
 /*****************************************************************************/
-/* < 2.4.21 */
-#if ( LINUX_VERSION_CODE < KERNEL_VERSION(2,4,21) )
-#define skb_pad(x,y) _kc_skb_pad(x, y)
-struct sk_buff * _kc_skb_pad(struct sk_buff *skb, int pad);
-#endif  /* < 2.4.21 */
-
-/*****************************************************************************/
 /* 2.4.22 => 2.4.17 */
 #if ( LINUX_VERSION_CODE < KERNEL_VERSION(2,4,22) )
 #define pci_name(x)	((x)->slot_name)
@@ -1467,6 +1450,16 @@ static inline void *_kc_skb_header_pointer(const struct sk_buff *skb,
 #else
 	return NULL;
 #endif
+
+#ifndef NETDEV_TX_OK
+#define NETDEV_TX_OK 0
+#endif
+#ifndef NETDEV_TX_BUSY
+#define NETDEV_TX_BUSY 1
+#endif
+#ifndef NETDEV_TX_LOCKED
+#define NETDEV_TX_LOCKED -1
+#endif
 }
 #endif /* < 2.6.9 */
 
@@ -1553,6 +1546,13 @@ static inline unsigned long _kc_usecs_to_jiffies(const unsigned int m)
 #define ADVERTISE_PAUSE_ASYM    0x0800  /* Try for asymmetric pause     */
 /* 1000BASE-T Control register */
 #define ADVERTISE_1000FULL      0x0200  /* Advertise 1000BASE-T full duplex */
+#ifndef is_zero_ether_addr
+#define is_zero_ether_addr _kc_is_zero_ether_addr
+static inline int _kc_is_zero_ether_addr(const u8 *addr)
+{
+	return !(addr[0] | addr[1] | addr[2] | addr[3] | addr[4] | addr[5]);
+}
+#endif
 #endif /* < 2.6.12 */
 
 /*****************************************************************************/
@@ -1593,6 +1593,15 @@ do { \
 #ifndef device_init_wakeup
 #define device_init_wakeup(dev,val) do {} while (0)
 #endif
+static inline unsigned _kc_compare_ether_addr(const u8 *addr1, const u8 *addr2)
+{
+	const u16 *a = (const u16 *) addr1;
+	const u16 *b = (const u16 *) addr2;
+
+	return ((a[0] ^ b[0]) | (a[1] ^ b[1]) | (a[2] ^ b[2])) != 0;
+}
+#undef compare_ether_addr
+#define compare_ether_addr(addr1, addr2) _kc_compare_ether_addr(addr1, addr2)
 #endif /* < 2.6.15 */
 
 /*****************************************************************************/
@@ -1670,6 +1679,23 @@ static inline int _kc_skb_is_gso(const struct sk_buff *skb)
 #define resource_size_t unsigned long
 #endif
 
+#ifdef skb_pad
+#undef skb_pad
+#endif
+#define skb_pad(x,y) _kc_skb_pad(x, y)
+int _kc_skb_pad(struct sk_buff *skb, int pad);
+#ifdef skb_padto
+#undef skb_padto
+#endif
+#define skb_padto(x,y) _kc_skb_padto(x, y)
+static inline int _kc_skb_padto(struct sk_buff *skb, unsigned int len)
+{
+	unsigned int size = skb->len;
+	if(likely(size >= len))
+		return 0;
+	return _kc_skb_pad(skb, len - size);
+}
+
 #endif /* < 2.6.18 */
 
 /*****************************************************************************/
@@ -1711,6 +1737,7 @@ static inline int _kc_request_irq(unsigned int irq, new_handler_t handler, unsig
 
 #define irq_handler_t new_handler_t
 /* pci_restore_state and pci_save_state handles MSI/PCIE from 2.6.19 */
+#if (!(RHEL_RELEASE_CODE && RHEL_RELEASE_CODE >= RHEL_RELEASE_VERSION(5,4)))
 #define PCIE_CONFIG_SPACE_LEN 256
 #define PCI_CONFIG_SPACE_LEN 64
 #define PCIE_LINK_STATUS 0x12
@@ -1721,6 +1748,8 @@ extern int _kc_pci_save_state(struct pci_dev *);
 #undef pci_restore_state
 extern void _kc_pci_restore_state(struct pci_dev *);
 #define pci_restore_state(pdev) _kc_pci_restore_state(pdev)
+#endif /* !(RHEL_RELEASE_CODE >= RHEL 5.4) */
+
 #ifdef HAVE_PCI_ERS
 #undef free_netdev
 extern void _kc_free_netdev(struct net_device *);
@@ -1732,8 +1761,12 @@ static inline int pci_enable_pcie_error_reporting(struct pci_dev *dev)
 }
 #define pci_disable_pcie_error_reporting(dev) do {} while (0)
 #define pci_cleanup_aer_uncorrect_error_status(dev) do {} while (0)
+
+extern void *_kc_kmemdup(const void *src, size_t len, unsigned gfp);
+#define kmemdup(src, len, gfp) _kc_kmemdup(src, len, gfp)
 #else /* 2.6.19 */
 #include <linux/aer.h>
+#include <linux/string.h>
 #endif /* < 2.6.19 */
 
 /*****************************************************************************/
@@ -2023,6 +2056,21 @@ extern void _kc_pci_disable_link_state(struct pci_dev *dev, int state);
 #endif /* < 2.6.26 */
 /*****************************************************************************/
 #if ( LINUX_VERSION_CODE < KERNEL_VERSION(2,6,27) )
+static inline void _kc_ethtool_cmd_speed_set(struct ethtool_cmd *ep,
+					     __u32 speed)
+{
+	ep->speed = (__u16)speed;
+	/* ep->speed_hi = (__u16)(speed >> 16); */
+}
+#define ethtool_cmd_speed_set _kc_ethtool_cmd_speed_set
+
+static inline __u32 _kc_ethtool_cmd_speed(struct ethtool_cmd *ep)
+{
+	/* no speed_hi before 2.6.27, and probably no need for it yet */
+	return (__u32)ep->speed;
+}
+#define ethtool_cmd_speed _kc_ethtool_cmd_speed
+
 #if ( LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,15) )
 #if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,23)) && defined(CONFIG_PM))
 #define ANCIENT_PM 1
@@ -2135,6 +2183,8 @@ extern int _kc_pci_prepare_to_sleep(struct pci_dev *dev);
 
 /*****************************************************************************/
 #if ( LINUX_VERSION_CODE < KERNEL_VERSION(2,6,30) )
+#define skb_rx_queue_recorded(a) false
+#define skb_get_rx_queue(a) 0
 #ifdef IXGBE_FCOE
 #undef CONFIG_FCOE
 #undef CONFIG_FCOE_MODULE
@@ -2237,6 +2287,12 @@ extern u16 _kc_skb_tx_hash(struct net_device *dev, struct sk_buff *skb);
 #ifndef pci_pcie_cap
 #define pci_pcie_cap(pdev) pci_find_capability(pdev, PCI_CAP_ID_EXP)
 #endif
+#ifndef IPV4_FLOW
+#define IPV4_FLOW 0x10
+#endif /* IPV4_FLOW */
+#ifndef IPV6_FLOW
+#define IPV6_FLOW 0x11
+#endif /* IPV6_FLOW */
 /* Features back-ported to RHEL6 or SLES11 SP1 after 2.6.32 */
 #if ( (RHEL_RELEASE_CODE && RHEL_RELEASE_CODE >= RHEL_RELEASE_VERSION(6,0)) || \
       (SLE_VERSION_CODE && SLE_VERSION_CODE >= SLE_VERSION(11,1,0)) )
@@ -2361,9 +2417,35 @@ do {								\
 })
 #endif /* DEBUG */
 
-#if !defined(CONFIG_PM_OPS) && defined(CONFIG_PM_SLEEP)
-#define CONFIG_PM_OPS
-#endif
+#undef netif_printk
+#define netif_printk(priv, type, level, dev, fmt, args...)	\
+do {								\
+	if (netif_msg_##type(priv))				\
+		netdev_printk(level, (dev), fmt, ##args);	\
+} while (0)
+
+#undef netif_emerg
+#define netif_emerg(priv, type, dev, fmt, args...)		\
+	netif_level(emerg, priv, type, dev, fmt, ##args)
+#undef netif_alert
+#define netif_alert(priv, type, dev, fmt, args...)		\
+	netif_level(alert, priv, type, dev, fmt, ##args)
+#undef netif_crit
+#define netif_crit(priv, type, dev, fmt, args...)		\
+	netif_level(crit, priv, type, dev, fmt, ##args)
+#undef netif_err
+#define netif_err(priv, type, dev, fmt, args...)		\
+	netif_level(err, priv, type, dev, fmt, ##args)
+#undef netif_warn
+#define netif_warn(priv, type, dev, fmt, args...)		\
+	netif_level(warn, priv, type, dev, fmt, ##args)
+#undef netif_notice
+#define netif_notice(priv, type, dev, fmt, args...)		\
+	netif_level(notice, priv, type, dev, fmt, ##args)
+#undef netif_info
+#define netif_info(priv, type, dev, fmt, args...)		\
+	netif_level(info, priv, type, dev, fmt, ##args)
+
 #ifdef SET_SYSTEM_SLEEP_PM_OPS
 #define HAVE_SYSTEM_SLEEP_PM_OPS
 #endif
@@ -2391,6 +2473,9 @@ void _kc_netif_set_real_num_tx_queues(struct net_device *, unsigned int);
 #else
 #define netif_set_real_num_tx_queues(_netdev, _count) do {} while(0)
 #endif /* HAVE_TX_MQ */
+#ifndef ETH_FLAG_RXHASH
+#define ETH_FLAG_RXHASH (1<<28)
+#endif /* ETH_FLAG_RXHASH */
 #else /* < 2.6.35 */
 #define HAVE_PM_QOS_REQUEST_LIST
 #define HAVE_IRQ_AFFINITY_HINT
@@ -2437,13 +2522,28 @@ static inline struct sk_buff *_kc_netdev_alloc_skb_ip_align(struct net_device *d
 #undef netdev_alloc_skb_ip_align
 #endif
 #define netdev_alloc_skb_ip_align(n, l) _kc_netdev_alloc_skb_ip_align(n, l)
+
+#undef netif_level
+#define netif_level(level, priv, type, dev, fmt, args...)	\
+do {								\
+	if (netif_msg_##type(priv))				\
+		netdev_##level(dev, fmt, ##args);		\
+} while (0)
+
+#undef usleep_range
+#define usleep_range(min, max)	msleep(DIV_ROUND_UP(min, 1000))	
+
 #else /* < 2.6.36 */
 #define HAVE_PM_QOS_REQUEST_ACTIVE
 #define HAVE_8021P_SUPPORT
+#define HAVE_NDO_GET_STATS64
 #endif /* < 2.6.36 */
 
 /*****************************************************************************/
 #if ( LINUX_VERSION_CODE < KERNEL_VERSION(2,6,37) )
+#ifndef ETHTOOL_RXNTUPLE_ACTION_CLEAR
+#define ETHTOOL_RXNTUPLE_ACTION_CLEAR (-2)
+#endif
 #ifndef VLAN_N_VID
 #define VLAN_N_VID	VLAN_GROUP_ARRAY_LEN
 #endif /* VLAN_N_VID */
@@ -2459,5 +2559,113 @@ static inline void _kc_skb_checksum_none_assert(struct sk_buff *skb)
 	WARN_ON(skb->ip_summed != CHECKSUM_NONE);
 }
 #define skb_checksum_none_assert(skb) _kc_skb_checksum_none_assert(skb)
+
+static inline void *_kc_vzalloc_node(unsigned long size, int node)
+{
+	void *addr = vmalloc_node(size, node);
+	if (addr)
+		memset(addr, 0, size);
+	return addr;
+}
+#define vzalloc_node(_size, _node) _kc_vzalloc_node(_size, _node)
+
+static inline void *_kc_vzalloc(unsigned long size)
+{
+	void *addr = vmalloc(size);
+	if (addr)
+		memset(addr, 0, size);
+	return addr;
+}
+#define vzalloc(_size) _kc_vzalloc(_size)
+
+#ifdef HAVE_HW_TIME_STAMP
+#define SKBTX_HW_TSTAMP (1 << 0)
+#define SKBTX_IN_PROGRESS (1 << 2)
+#define SKB_SHARED_TX_IS_UNION
+#endif
 #endif /* < 2.6.37 */
+
+/*****************************************************************************/
+#if ( LINUX_VERSION_CODE < KERNEL_VERSION(2,6,38) )
+#if ( LINUX_VERSION_CODE < KERNEL_VERSION(2,6,22) )
+#define skb_checksum_start_offset(skb) skb_transport_offset(skb)
+#else /* 2.6.22 -> 2.6.37 */
+static inline int _kc_skb_checksum_start_offset(const struct sk_buff *skb)
+{
+        return skb->csum_start - skb_headroom(skb);
+}
+#define skb_checksum_start_offset(skb) _kc_skb_checksum_start_offset(skb)
+#endif /* 2.6.22 -> 2.6.37 */
+#ifdef CONFIG_DCB
+#ifndef DCB_CAP_DCBX_HOST
+#define DCB_CAP_DCBX_HOST		0x01
+#endif
+#ifndef DCB_CAP_DCBX_LLD_MANAGED
+#define DCB_CAP_DCBX_LLD_MANAGED	0x02
+#endif
+#ifndef DCB_CAP_DCBX_VER_CEE
+#define DCB_CAP_DCBX_VER_CEE		0x04
+#endif
+#ifndef DCB_CAP_DCBX_VER_IEEE
+#define DCB_CAP_DCBX_VER_IEEE		0x08
+#endif
+#ifndef DCB_CAP_DCBX_STATIC
+#define DCB_CAP_DCBX_STATIC		0x10
+#endif
+#endif /* CONFIG_DCB */
+#else /* < 2.6.38 */
+#ifndef HAVE_DCBNL_IEEE
+#define HAVE_DCBNL_IEEE
+#endif
+#endif /* < 2.6.38 */
+
+/*****************************************************************************/
+#if ( LINUX_VERSION_CODE < KERNEL_VERSION(2,6,39) )
+#if (!(RHEL_RELEASE_CODE && RHEL_RELEASE_CODE > RHEL_RELEASE_VERSION(6,0)))
+#endif /* !(RHEL_RELEASE_CODE > RHEL_RELEASE_VERSION(6,0)) */
+#else /* < 2.6.39 */
+#if defined(CONFIG_FCOE) || defined(CONFIG_FCOE_MODULE)
+#ifndef HAVE_NETDEV_OPS_FCOE_DDP_TARGET
+#define HAVE_NETDEV_OPS_FCOE_DDP_TARGET
+#endif
+#endif /* CONFIG_FCOE || CONFIG_FCOE_MODULE */
+#ifndef HAVE_MQPRIO
+#define HAVE_MQPRIO
+#endif
+#endif /* < 2.6.39 */
+
+/*****************************************************************************/
+#if ( LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0) )
+#ifdef ETHTOOL_GRXRINGS
+#ifndef FLOW_EXT
+#define	FLOW_EXT	0x80000000
+union _kc_ethtool_flow_union {
+	struct ethtool_tcpip4_spec		tcp_ip4_spec;
+	struct ethtool_usrip4_spec		usr_ip4_spec;
+	__u8					hdata[60];
+};
+struct _kc_ethtool_flow_ext {
+	__be16	vlan_etype;
+	__be16	vlan_tci;
+	__be32	data[2];
+};
+struct _kc_ethtool_rx_flow_spec {
+	__u32		flow_type;
+	union _kc_ethtool_flow_union h_u;
+	struct _kc_ethtool_flow_ext h_ext;
+	union _kc_ethtool_flow_union m_u;
+	struct _kc_ethtool_flow_ext m_ext;
+	__u64		ring_cookie;
+	__u32		location;
+};
+#define ethtool_rx_flow_spec _kc_ethtool_rx_flow_spec
+#endif /* FLOW_EXT */
+#endif
+
+#define pci_disable_link_state_locked pci_disable_link_state
+
+#else /* < 3.0.0 */
+#define HAVE_ETHTOOL_SET_PHYS_ID
+#endif /* < 3.0.0 */
+
 #endif /* _KCOMPAT_H_ */
-- 
1.7.0

