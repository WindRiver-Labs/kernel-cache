From c26b8e1c53ce79e00add9947fb3cf34174307528 Mon Sep 17 00:00:00 2001
From: Thomas Tai <Thomas.Tai@windriver.com>
Date: Wed, 10 Sep 2008 10:41:58 -0400
Subject: [PATCH] Added netpoll support for IBM 440 onchip ethernet driver

Added netpoll tx and rx function in ibm_newemac for
IBM 440 onchip ethernet driver, because kgdboe requires ethernet
driver to support netpolling.  Original patch is from
http://patchwork.ozlabs.org/linuxppc/patch?filter=archived&id=3648

Signed-off-by: Thomas Tai <Thomas.Tai@windriver.com>
---
 drivers/net/ibm_newemac/core.c |   93 +++++++++++++++++++++++++++++++++++++++-
 drivers/net/ibm_newemac/mal.c  |   18 --------
 drivers/net/ibm_newemac/mal.h  |   14 ++++++
 include/linux/netdevice.h      |    7 +++
 include/linux/netpoll.h        |    4 +-
 5 files changed, 114 insertions(+), 22 deletions(-)

diff --git a/drivers/net/ibm_newemac/core.c b/drivers/net/ibm_newemac/core.c
index ccd9d90..90547f4 100644
--- a/drivers/net/ibm_newemac/core.c
+++ b/drivers/net/ibm_newemac/core.c
@@ -1327,10 +1327,16 @@ static int emac_start_xmit(struct sk_buff *skb, struct net_device *ndev)
 	struct emac_instance *dev = netdev_priv(ndev);
 	unsigned int len = skb->len;
 	int slot;
-
 	u16 ctrl = EMAC_TX_CTRL_GFCS | EMAC_TX_CTRL_GP | MAL_TX_CTRL_READY |
 	    MAL_TX_CTRL_LAST | emac_tx_csum(dev, skb);
 
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	if (unlikely(dev->tx_cnt == NUM_TX_BUFF)) {
+		netif_stop_queue(ndev);
+		return -EBUSY;
+	}
+#endif
+
 	slot = dev->tx_slot++;
 	if (dev->tx_slot == NUM_TX_BUFF) {
 		dev->tx_slot = 0;
@@ -1491,6 +1497,61 @@ static void emac_parse_tx_error(struct emac_instance *dev, u16 ctrl)
 		++st->tx_bd_sqe;
 }
 
+#ifdef CONFIG_NET_POLL_CONTROLLER
+/*
+ * emac_poll_tx_nobh() is called during netpolling, it is
+ * samiliar to emac_poll_tx except that it does not
+ * lock/unlock bottom half. Otherwise, kernel will panic.
+ *
+ */
+static void emac_poll_tx_nobh(void *param)
+{
+	struct emac_instance *dev = param;
+	u32 bad_mask;
+
+	DBG2(dev, "poll_tx, %d %d" NL, dev->tx_cnt, dev->ack_slot);
+
+	if (emac_has_feature(dev, EMAC_FTR_HAS_TAH))
+		bad_mask = EMAC_IS_BAD_TX_TAH;
+	else
+		bad_mask = EMAC_IS_BAD_TX;
+
+	/*	netif_tx_lock_bh(dev->ndev); */
+	if (dev->tx_cnt) {
+		u16 ctrl;
+		int slot = dev->ack_slot, n = 0;
+	again:
+		ctrl = dev->tx_desc[slot].ctrl;
+		if (!(ctrl & MAL_TX_CTRL_READY)) {
+			struct sk_buff *skb = dev->tx_skb[slot];
+			++n;
+
+			if (skb) {
+				dev_kfree_skb(skb);
+				dev->tx_skb[slot] = NULL;
+			}
+			slot = (slot + 1) % NUM_TX_BUFF;
+
+			if (unlikely(ctrl & bad_mask))
+				emac_parse_tx_error(dev, ctrl);
+
+			if (--dev->tx_cnt)
+				goto again;
+		}
+		if (n) {
+			dev->ack_slot = slot;
+			if (netif_queue_stopped(dev->ndev) &&
+			    dev->tx_cnt < EMAC_TX_WAKEUP_THRESH)
+				netif_wake_queue(dev->ndev);
+
+			DBG2(dev, "tx %d pkts" NL, n);
+		}
+	}
+	/* netif_tx_unlock_bh(dev->ndev); */
+}
+#endif
+
+
 static void emac_poll_tx(void *param)
 {
 	struct emac_instance *dev = param;
@@ -2638,6 +2699,31 @@ static int __devinit emac_init_config(struct emac_instance *dev)
 	return 0;
 }
 
+#ifdef CONFIG_NET_POLL_CONTROLLER
+void poll_ctrl(struct net_device *dev)
+{
+	int budget = 16;
+
+	/* struct ibm_ocp_mal *mal = ((struct ocp_enet_private*)(dev->priv))->mal; */
+	struct emac_instance *emac_dev = netdev_priv(dev);
+	struct mal_instance *mal = dev_get_drvdata(&emac_dev->mal_dev->dev);
+	/*	struct net_device *poll_dev = &(mal->poll_dev); */
+
+	/* disable  MAL interrupts */
+	mal_disable_eob_irq(mal);
+	napi_disable(&mal->napi);
+
+	emac_poll_rx(netdev_priv(dev), budget);
+	emac_poll_tx_nobh(netdev_priv(dev));
+
+	napi_enable(&mal->napi);
+	/* Enable mal interrupts */
+	mal_enable_eob_irq(mal);
+
+}
+#endif
+
+
 static int __devinit emac_probe(struct of_device *ofdev,
 				const struct of_device_id *match)
 {
@@ -2789,6 +2875,11 @@ static int __devinit emac_probe(struct of_device *ofdev,
 	ndev->get_stats = &emac_stats;
 	ndev->set_multicast_list = &emac_set_multicast_list;
 	ndev->do_ioctl = &emac_ioctl;
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	ndev->poll_controller = poll_ctrl;
+#endif
+
 	if (emac_phy_supports_gige(dev->phy_mode)) {
 		ndev->hard_start_xmit = &emac_start_xmit_sg;
 		ndev->change_mtu = &emac_change_mtu;
diff --git a/drivers/net/ibm_newemac/mal.c b/drivers/net/ibm_newemac/mal.c
index 10c267b..1bc5f7b 100644
--- a/drivers/net/ibm_newemac/mal.c
+++ b/drivers/net/ibm_newemac/mal.c
@@ -198,24 +198,6 @@ void mal_poll_del(struct mal_instance *mal, struct mal_commac *commac)
 	spin_unlock_irqrestore(&mal->lock, flags);
 }
 
-/* synchronized by mal_poll() */
-static inline void mal_enable_eob_irq(struct mal_instance *mal)
-{
-	MAL_DBG2(mal, "enable_irq" NL);
-
-	// XXX might want to cache MAL_CFG as the DCR read can be slooooow
-	set_mal_dcrn(mal, MAL_CFG, get_mal_dcrn(mal, MAL_CFG) | MAL_CFG_EOPIE);
-}
-
-/* synchronized by NAPI state */
-static inline void mal_disable_eob_irq(struct mal_instance *mal)
-{
-	// XXX might want to cache MAL_CFG as the DCR read can be slooooow
-	set_mal_dcrn(mal, MAL_CFG, get_mal_dcrn(mal, MAL_CFG) & ~MAL_CFG_EOPIE);
-
-	MAL_DBG2(mal, "disable_irq" NL);
-}
-
 static irqreturn_t mal_serr(int irq, void *dev_instance)
 {
 	struct mal_instance *mal = dev_instance;
diff --git a/drivers/net/ibm_newemac/mal.h b/drivers/net/ibm_newemac/mal.h
index eaa7262..5c18eb3 100644
--- a/drivers/net/ibm_newemac/mal.h
+++ b/drivers/net/ibm_newemac/mal.h
@@ -225,6 +225,20 @@ static inline void set_mal_dcrn(struct mal_instance *mal, int reg, u32 val)
 	dcr_write(mal->dcr_host, reg, val);
 }
 
+/* synchronized by mal_poll() */
+static inline void mal_enable_eob_irq(struct mal_instance *mal)
+{
+	// XXX might want to cache MAL_CFG as the DCR read can be slooooow
+	set_mal_dcrn(mal, MAL_CFG, get_mal_dcrn(mal, MAL_CFG) | MAL_CFG_EOPIE);
+}
+
+/* synchronized by NAPI state */
+static inline void mal_disable_eob_irq(struct mal_instance *mal)
+{
+	// XXX might want to cache MAL_CFG as the DCR read can be slooooow
+	set_mal_dcrn(mal, MAL_CFG, get_mal_dcrn(mal, MAL_CFG) & ~MAL_CFG_EOPIE);
+}
+
 /* Register MAL devices */
 int mal_init(void);
 void mal_exit(void);
diff --git a/include/linux/netdevice.h b/include/linux/netdevice.h
index 5650061..c048c6c 100644
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@ -837,12 +837,19 @@ static inline void netif_napi_add(struct net_device *dev,
 	INIT_LIST_HEAD(&napi->poll_list);
 	napi->poll = poll;
 	napi->weight = weight;
+/*
+ * ibm_newemac driver do not use NETPOLL and
+ * pass a NULL net_device to this function.
+ * A ifndef is used to avoid the kernel panic.
+ */
+#ifndef CONFIG_NET_POLL_CONTROLLER
 #ifdef CONFIG_NETPOLL
 	napi->dev = dev;
 	list_add(&napi->dev_list, &dev->napi_list);
 	spin_lock_init(&napi->poll_lock);
 	napi->poll_owner = -1;
 #endif
+#endif
 	set_bit(NAPI_STATE_SCHED, &napi->state);
 }
 
diff --git a/include/linux/netpoll.h b/include/linux/netpoll.h
index 80e166a..abcdb47 100644
--- a/include/linux/netpoll.h
+++ b/include/linux/netpoll.h
@@ -65,9 +65,7 @@ static inline int netpoll_rx(struct sk_buff *skb)
 
 static inline int netpoll_receive_skb(struct sk_buff *skb)
 {
-	if (!list_empty(&skb->dev->napi_list))
-		return netpoll_rx(skb);
-	return 0;
+	return netpoll_rx(skb);
 }
 
 static inline void *netpoll_poll_lock(struct napi_struct *napi)
-- 
1.6.0.4

