From 657b38d57d00569db9cba213b73b64ec7a743cda Mon Sep 17 00:00:00 2001
From: Bi Junxiao <Junxiao.Bi@windriver.com>
Date: Thu, 29 Apr 2010 14:57:55 +0800
Subject: [PATCH] add resource management for cppi41 dma

Memory region and desc number are resources used in cppi41 dma.
Next_desc_index and next_mem_rgn records the first free resource index.
Every time when requesting a new resource, just get values from the
two array and then increase them by request size.
In this simple management mechanism, we can never reuse the resources that
had been freed. Because musb controller uses cppi41 dma, when it is built to
a moudle, then insmod/rmmod many times, at last the resource index will
increase to the max values, the request will fail.

Signed-off-by: Bi Junxiao <junxiao.bi@windriver.com>
[minor codingstyle modifications]
Signed-off-by: Stanley.Miao <stanley.miao@windriver.com>
---
 drivers/usb/musb/cppi41.c |  132 +++++++++++++++++++++++++++++++++++++++++----
 1 files changed, 122 insertions(+), 10 deletions(-)

diff --git a/drivers/usb/musb/cppi41.c b/drivers/usb/musb/cppi41.c
index 771d7ac..0acf992 100644
--- a/drivers/usb/musb/cppi41.c
+++ b/drivers/usb/musb/cppi41.c
@@ -48,9 +48,111 @@ static struct {
 
 static u32 *allocated_queues[CPPI41_NUM_QUEUE_MGR];
 
-/* First 32 packet descriptors are reserved for unallocated memory regions. */
-static u32 next_desc_index[CPPI41_NUM_QUEUE_MGR] = { 1 << 5 };
-static u8  next_mem_rgn[CPPI41_NUM_QUEUE_MGR];
+static unsigned long mem_rgn_map[CPPI41_NUM_QUEUE_MGR][CPPI41_MAX_MEM_RGN / BITS_PER_LONG + 1];
+
+static unsigned long alloc_next_mem_rgn_idx(u8 mgr)
+{
+	unsigned long rgn;
+
+	rgn = find_next_zero_bit(&mem_rgn_map[mgr], CPPI41_MAX_MEM_RGN, 0);
+	if (rgn < CPPI41_MAX_MEM_RGN)
+		set_bit(rgn, (unsigned long *) &mem_rgn_map[mgr]);
+
+	return rgn;
+}
+
+static void free_mem_rgn_idx(u8 mgr, u8 rgn)
+{
+	if (rgn < CPPI41_MAX_MEM_RGN)
+		clear_bit(rgn, (unsigned long *) &mem_rgn_map[mgr]);
+}
+
+#define DESC_MAX_INDEX 0x4000
+struct desc_index {
+	struct list_head next;
+	u32 start;
+	u32 size;
+};
+static struct list_head desc_idx_list[CPPI41_NUM_QUEUE_MGR];
+static int desc_index_init_flag;
+
+static void desc_index_init(void)
+{
+	int mgr;
+	struct desc_index *desc_seg;
+
+	for (mgr = 0; mgr < CPPI41_NUM_QUEUE_MGR; mgr++) {
+		INIT_LIST_HEAD(&desc_idx_list[mgr]);
+		desc_seg = kmalloc(sizeof(struct desc_index), GFP_KERNEL);
+		if (!desc_seg) {
+			printk(KERN_ERR "ERROR: %s: Unable to allocate "
+					"desc RAM.\n", __func__);
+			return;
+		}
+		/* First 32 packet descriptors are reserved for
+		 * unallocated memory regions.
+		 */
+		desc_seg->start = 32;
+		desc_seg->size = DESC_MAX_INDEX - 32;
+		list_add(&desc_seg->next, &desc_idx_list[mgr]);
+	}
+}
+
+static u32 alloc_next_desc_idx(u8 mgr, u32 size)
+{
+	struct desc_index *desc_seg, *next;
+	u32 start;
+
+	if (!desc_index_init_flag) {
+		desc_index_init();
+		desc_index_init_flag = 1;
+	}
+	list_for_each_entry_safe(desc_seg, next, &desc_idx_list[mgr], next) {
+		if (desc_seg->size == size) {
+			list_del(&desc_seg->next);
+			start = desc_seg->start;
+			kfree(desc_seg);
+			return start;
+		} else if (desc_seg->size > size) {
+			start = desc_seg->start;
+			desc_seg->start += size;
+			desc_seg->size -= size;
+			return start;
+		}
+	}
+
+	return DESC_MAX_INDEX;
+}
+
+static void free_next_desc_idx(u8 mgr, u32 start, u32 size)
+{
+	struct desc_index *desc_seg, *desc_next;
+
+	/*find an empty slot to insert*/
+	list_for_each_entry(desc_seg, &desc_idx_list[mgr], next) {
+		if (start < desc_seg->start)
+			break;
+	}
+	desc_next = kmalloc(sizeof(struct desc_index), GFP_KERNEL);
+	if (!desc_next) {
+		printk(KERN_ERR "ERROR: %s: Unable to allocate "
+				"desc RAM.\n", __func__);
+		return;
+	}
+	desc_next->start = start;
+	desc_next->size = size;
+	list_add_tail(&desc_next->next, &desc_seg->next);
+
+	/*check if can merge*/
+	list_for_each_entry_safe(desc_seg, desc_next, &desc_idx_list[mgr], next) {
+		if (desc_seg->start + desc_seg->size == desc_next->start) {
+			desc_next->start = desc_seg->start;
+			desc_next->size += desc_seg->size;
+			list_del(&desc_seg->next);
+			kfree(desc_seg);
+		}
+	}
+}
 
 static struct {
 	size_t rgn_size;
@@ -372,6 +474,9 @@ void cppi41_dma_block_deinit(u8 dma_num, u8 q_mgr)
 	cppi41_free_teardown_queue(dma_num);
 	dma_teardown[dma_num].queue_obj.base_addr = NULL;
 
+	/*free mem rgn and desc index*/
+	cppi41_mem_rgn_free(q_mgr, dma_teardown[dma_num].mem_rgn);
+
 	/* free the teardown descripotr memory */
 	dma_free_coherent(NULL, dma_teardown[dma_num].rgn_size,
 		dma_teardown[dma_num].virt_addr,
@@ -390,7 +495,7 @@ int cppi41_mem_rgn_alloc(u8 q_mgr, dma_addr_t rgn_addr, u8 size_order,
 {
 	void __iomem *desc_mem_regs;
 	u32 num_desc = 1 << num_order, index, ctrl;
-	int rgn;
+	unsigned long rgn;
 
 	DBG("%s called with rgn_addr = %08x, size_order = %d, num_order = %d\n",
 	    __func__, rgn_addr, size_order, num_order);
@@ -401,14 +506,11 @@ int cppi41_mem_rgn_alloc(u8 q_mgr, dma_addr_t rgn_addr, u8 size_order,
 	    (rgn_addr & ((1 << size_order) - 1)))
 		return -EINVAL;
 
-	rgn = next_mem_rgn[q_mgr];
-	index = next_desc_index[q_mgr];
+	rgn = alloc_next_mem_rgn_idx(q_mgr);
+	index = alloc_next_desc_idx(q_mgr, num_desc);
 	if (rgn >= CPPI41_MAX_MEM_RGN || index + num_desc > 0x4000)
 		return -ENOSPC;
 
-	next_mem_rgn[q_mgr] = rgn + 1;
-	next_desc_index[q_mgr] = index + num_desc;
-
 	desc_mem_regs = cppi41_queue_mgr[q_mgr].desc_mem_rgn_base;
 
 	/* Write the base register */
@@ -440,10 +542,12 @@ EXPORT_SYMBOL(cppi41_mem_rgn_alloc);
 int cppi41_mem_rgn_free(u8 q_mgr, u8 mem_rgn)
 {
 	void __iomem *desc_mem_regs;
+	u32 start_desc, num_order, num_desc;
+	u32 ctrl;
 
 	DBG("%s called.\n", __func__);
 
-	if (q_mgr >= cppi41_num_queue_mgr || mem_rgn >= next_mem_rgn[q_mgr])
+	if (q_mgr >= cppi41_num_queue_mgr || mem_rgn >= CPPI41_MAX_MEM_RGN)
 		return -EINVAL;
 
 	desc_mem_regs = cppi41_queue_mgr[q_mgr].desc_mem_rgn_base;
@@ -451,9 +555,17 @@ int cppi41_mem_rgn_free(u8 q_mgr, u8 mem_rgn)
 	if (__raw_readl(desc_mem_regs + QMGR_MEM_RGN_BASE_REG(mem_rgn)) == 0)
 		return -ENOENT;
 
+	ctrl = __raw_readl(desc_mem_regs + QMGR_MEM_RGN_CTRL_REG(mem_rgn));
+	start_desc = (ctrl & QMGR_MEM_RGN_INDEX_MASK) >> QMGR_MEM_RGN_INDEX_SHIFT;
+	num_order = ((ctrl & QMGR_MEM_RGN_SIZE_MASK) >> QMGR_MEM_RGN_SIZE_SHIFT) + 5;
+	num_desc = 1 << num_order;
+
 	__raw_writel(0, desc_mem_regs + QMGR_MEM_RGN_BASE_REG(mem_rgn));
 	__raw_writel(0, desc_mem_regs + QMGR_MEM_RGN_CTRL_REG(mem_rgn));
 
+	free_mem_rgn_idx(q_mgr, mem_rgn);
+	free_next_desc_idx(q_mgr, start_desc, num_desc);
+
 	return 0;
 }
 EXPORT_SYMBOL(cppi41_mem_rgn_free);
-- 
1.6.0.3

