From 89df518056812cb822f7f432c62e12a56780e789 Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Wed, 19 May 2010 23:57:28 +0800
Subject: [PATCH 10/47] nlm_xlr_atx_64_be: add dma support

Extracted from RMI SDK 1.7.0.

Signed-off-by: Jack Tan <jack.tan@windriver.com>
[ Move the forced "gfp |= __GFP_DMA;" to the common functions to reduce
duplication ]
Signed-off-by: Wu Zhangjin <zhangjin.tan@windriver.com>
---
 arch/mips/include/asm/dma.h                    |    2 +
 arch/mips/include/asm/mach-rmi/dma-coherence.h |   84 ++++++++++++++++++++++++
 arch/mips/mm/dma-default.c                     |    6 ++
 net/core/skbuff.c                              |    4 +
 4 files changed, 96 insertions(+), 0 deletions(-)
 create mode 100644 arch/mips/include/asm/mach-rmi/dma-coherence.h

diff --git a/arch/mips/include/asm/dma.h b/arch/mips/include/asm/dma.h
index 1353c81..45b7b26 100644
--- a/arch/mips/include/asm/dma.h
+++ b/arch/mips/include/asm/dma.h
@@ -87,6 +87,8 @@
 #if defined(CONFIG_SGI_IP22) || defined(CONFIG_SGI_IP28)
 /* don't care; ISA bus master won't work, ISA slave DMA supports 32bit addr */
 #define MAX_DMA_ADDRESS		PAGE_OFFSET
+#elif defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_64BIT)
+#define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0x80000000)
 #else
 #define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0x01000000)
 #endif
diff --git a/arch/mips/include/asm/mach-rmi/dma-coherence.h b/arch/mips/include/asm/mach-rmi/dma-coherence.h
new file mode 100644
index 0000000..dd6f900
--- /dev/null
+++ b/arch/mips/include/asm/mach-rmi/dma-coherence.h
@@ -0,0 +1,84 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2006  Ralf Baechle <ralf@linux-mips.org>
+ *
+ */
+#ifndef __ASM_MACH_RMI_DMA_COHERENCE_H
+#define __ASM_MACH_RMI_DMA_COHERENCE_H
+
+struct device;
+
+static inline dma_addr_t plat_map_dma_mem(struct device *dev, void *addr,
+	size_t size)
+{
+	return virt_to_phys(addr);
+}
+
+static inline dma_addr_t plat_map_dma_mem_page(struct device *dev,
+	struct page *page)
+{
+	return page_to_phys(page);
+}
+
+static inline unsigned long plat_dma_addr_to_phys(struct device *dev,
+		dma_addr_t dma_addr)
+{
+	return dma_addr;
+}
+
+static inline void plat_unmap_dma_mem(struct device *dev, dma_addr_t dma_addr,
+	size_t size, enum dma_data_direction direction)
+{
+}
+
+static inline int plat_device_is_coherent(struct device *dev)
+{
+#ifdef CONFIG_DMA_COHERENT
+	return 1;
+#else /* CONFIG_DMA_NONCOHERENT */
+	return 0;
+#endif
+}
+
+int dma_map_sg(struct device *dev, struct scatterlist *sg, int nents,
+	enum dma_data_direction direction)
+{
+	int i;
+
+	BUG_ON(direction == DMA_NONE);
+
+	for (i = 0; i < nents; i++, sg++)
+		sg->dma_address = dma_map_page(dev, sg_page(sg), sg->offset,
+			sg->length, direction);
+
+	return nents;
+}
+
+static inline int plat_dma_supported(struct device *dev, u64 mask)
+{
+	/*
+	 * we fall back to GFP_DMA when the mask isn't all 1s,
+	 * so we can't guarantee allocations that must be
+	 * within a tighter range than GFP_DMA..
+	 */
+	if (mask < DMA_BIT_MASK(24))
+		return 0;
+
+	return 1;
+}
+
+static inline void plat_extra_sync_for_device(struct device *dev)
+{
+	return;
+}
+
+static inline int plat_dma_mapping_error(struct device *dev,
+					 dma_addr_t dma_addr)
+{
+	return 0;
+}
+
+#endif /* __ASM_MACH_GENERIC_DMA_COHERENCE_H */
diff --git a/arch/mips/mm/dma-default.c b/arch/mips/mm/dma-default.c
index 9547bc0..191b0d5 100644
--- a/arch/mips/mm/dma-default.c
+++ b/arch/mips/mm/dma-default.c
@@ -64,6 +64,10 @@ static gfp_t massage_gfp_flags(const struct device *dev, gfp_t gfp)
 	/* Don't invoke OOM killer */
 	gfp |= __GFP_NORETRY;
 
+#if defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_64BIT)
+	gfp |= __GFP_DMA;
+#endif
+
 	return gfp;
 }
 
@@ -187,6 +191,7 @@ void dma_unmap_single(struct device *dev, dma_addr_t dma_addr, size_t size,
 
 EXPORT_SYMBOL(dma_unmap_single);
 
+#ifndef CONFIG_RMI_PHOENIX
 int dma_map_sg(struct device *dev, struct scatterlist *sg, int nents,
 	enum dma_data_direction direction)
 {
@@ -206,6 +211,7 @@ int dma_map_sg(struct device *dev, struct scatterlist *sg, int nents,
 
 	return nents;
 }
+#endif
 
 EXPORT_SYMBOL(dma_map_sg);
 
diff --git a/net/core/skbuff.c b/net/core/skbuff.c
index 0706e7d..26d4b36 100644
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -177,6 +177,10 @@ struct sk_buff *__alloc_skb(unsigned int size, gfp_t gfp_mask,
 	struct sk_buff *skb;
 	u8 *data;
 
+#if defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_64BIT)
+	gfp_mask |= __GFP_DMA;
+#endif
+
 	cache = fclone ? skbuff_fclone_cache : skbuff_head_cache;
 
 	/* Get the HEAD */
-- 
1.7.0.4

