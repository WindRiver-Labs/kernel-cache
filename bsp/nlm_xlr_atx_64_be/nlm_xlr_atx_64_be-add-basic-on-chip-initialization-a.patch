From 55906f3d2a17095a600bfa4a5f18c78e9713dfa6 Mon Sep 17 00:00:00 2001
From: Wu Zhangjin <zhangjin.wu@windriver.com>
Date: Mon, 6 Dec 2010 18:59:26 +0800
Subject: [PATCH 17/47] nlm_xlr_atx_64_be: add basic on chip initialization and msgring support

Extracted from RMI SDK 1.7.0.

The current msgring.c is pre-generated by the default msgring
configration.

Signed-off-by: Wu Zhangjin <zhangjin.wu@windriver.com>
---
 arch/mips/rmi/phoenix/Makefile  |    3 +-
 arch/mips/rmi/phoenix/irq.c     |   10 +-
 arch/mips/rmi/phoenix/msgring.c |  348 ++++++++++++++++++++++
 arch/mips/rmi/phoenix/on_chip.c |  610 +++++++++++++++++++++++++++++++++++++++
 4 files changed, 969 insertions(+), 2 deletions(-)
 create mode 100644 arch/mips/rmi/phoenix/msgring.c
 create mode 100644 arch/mips/rmi/phoenix/on_chip.c

diff --git a/arch/mips/rmi/phoenix/Makefile b/arch/mips/rmi/phoenix/Makefile
index 6479364..e37ffaa 100644
--- a/arch/mips/rmi/phoenix/Makefile
+++ b/arch/mips/rmi/phoenix/Makefile
@@ -1,4 +1,5 @@
-obj-y := irq.o cpu.o time.o memory.o
+obj-y := irq.o cpu.o time.o memory.o on_chip.o msgring.o
+
 obj-$(CONFIG_SMP) += smp.o
 
 EXTRA_AFLAGS := $(CFLAGS)
diff --git a/arch/mips/rmi/phoenix/irq.c b/arch/mips/rmi/phoenix/irq.c
index dc6b2a6..cfff43c 100644
--- a/arch/mips/rmi/phoenix/irq.c
+++ b/arch/mips/rmi/phoenix/irq.c
@@ -300,6 +300,11 @@ void __init init_phoenix_irqs(void)
 	    ((1ULL << IRQ_IPI_SMP_FUNCTION) | (1ULL << IRQ_IPI_SMP_RESCHEDULE));
 #endif				/* CONFIG_SMP */
 
+	/* msgring interrupt */
+	irq_desc[IRQ_MSGRING].chip = &phnx_rsvd_pic;
+	irq_desc[IRQ_MSGRING].action = &phnx_rsvd_action;
+	phnx_irq_mask |= (1ULL << IRQ_MSGRING);
+
 	irq_desc[IRQ_TIMER].chip = &phnx_rsvd_pic_irq_timer;
 	irq_desc[IRQ_TIMER].action = NULL;
 	phnx_irq_mask |= (1ULL << IRQ_TIMER);
@@ -328,7 +333,10 @@ void do_phnx_IRQ(unsigned int irq, struct pt_regs *regs)
 		return;
 	}
 #endif				/* CONFIG_SMP */
-	do_IRQ(irq);
+	if (irq == IRQ_MSGRING)
+		phnx_msgring_int_handler(irq, regs);
+	else
+		do_IRQ(irq);
 }
 
 void __cpuinit rmi_smp_irq_init(void)
diff --git a/arch/mips/rmi/phoenix/msgring.c b/arch/mips/rmi/phoenix/msgring.c
new file mode 100644
index 0000000..deea8a3
--- /dev/null
+++ b/arch/mips/rmi/phoenix/msgring.c
@@ -0,0 +1,348 @@
+/*********************************************************************
+ *
+ * Copyright 2003-2010 Raza Microelectronics, Inc. (RMI). All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES, LOSS OF USE, DATA, OR PROFITS, OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * *****************************RMI_2**********************************/
+
+/**********************************************************
+ * -----------------DO NOT EDIT THIS FILE------------------
+ * This file has been autogenerated by the build process
+ * from "msgring.cfg"
+ **********************************************************/
+
+
+
+#include <asm/rmi/msgring.h>
+#include <linux/module.h>
+
+struct bucket_size bucket_sizes = {
+	{32, 32, 32, 32, 32, 32, 32, 32,
+	 32, 32, 32, 32, 32, 32, 32, 32,
+	 32, 32, 32, 32, 32, 32, 32, 32,
+	 32, 32, 32, 32, 32, 32, 32, 32,
+	 32, 32, 32, 32, 32, 32, 32, 32,
+	 32, 32, 32, 32, 32, 32, 32, 32,
+	 32, 32, 32, 32, 32, 32, 32, 32,
+	 32, 32, 32, 32, 32, 32, 32, 32,
+	 32, 16, 16, 16, 16, 16, 16, 16,
+	 16, 16, 16, 16, 16, 16, 16, 0,
+	 32, 16, 16, 16, 16, 16, 16, 16,
+	 16, 16, 16, 16, 16, 16, 16, 0,
+	 0, 32, 32, 32, 32, 32, 0, 32,
+	 64, 64, 64, 64, 0, 0, 0, 0,
+	 0, 32, 0, 32, 0, 0, 0, 0,
+	 128, 0, 0, 0, 128, 0, 0, 0,
+	 }
+};
+
+EXPORT_SYMBOL(bucket_sizes);
+
+struct stn_cc cc_table_cpu_0 = { {
+				  {1, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 4, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {0, 2, 4, 4, 4, 4, 0, 2},
+				  {8, 8, 8, 8, 0, 0, 0, 0},
+				  {0, 2, 0, 2, 0, 0, 0, 0},
+				  {16, 0, 0, 0, 16, 0, 0, 0},
+				  }
+};
+
+EXPORT_SYMBOL(cc_table_cpu_0);
+
+struct stn_cc cc_table_cpu_1 = { {
+				  {1, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {0, 2, 4, 4, 4, 4, 0, 2},
+				  {8, 8, 8, 8, 0, 0, 0, 0},
+				  {0, 2, 0, 2, 0, 0, 0, 0},
+				  {16, 0, 0, 0, 16, 0, 0, 0},
+				  }
+};
+
+EXPORT_SYMBOL(cc_table_cpu_1);
+
+struct stn_cc cc_table_cpu_2 = { {
+				  {1, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {0, 4, 4, 4, 4, 4, 0, 4},
+				  {8, 8, 8, 8, 0, 0, 0, 0},
+				  {0, 2, 0, 2, 0, 0, 0, 0},
+				  {16, 0, 0, 0, 16, 0, 0, 0},
+				  }
+};
+
+EXPORT_SYMBOL(cc_table_cpu_2);
+
+struct stn_cc cc_table_cpu_3 = { {
+				  {1, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {0, 4, 4, 4, 4, 4, 0, 4},
+				  {8, 8, 8, 8, 0, 0, 0, 0},
+				  {0, 2, 0, 2, 0, 0, 0, 0},
+				  {16, 0, 0, 0, 16, 0, 0, 0},
+				  }
+};
+
+EXPORT_SYMBOL(cc_table_cpu_3);
+
+struct stn_cc cc_table_cpu_4 = { {
+				  {1, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {0, 4, 4, 4, 4, 4, 0, 4},
+				  {8, 8, 8, 8, 0, 0, 0, 0},
+				  {0, 4, 0, 4, 0, 0, 0, 0},
+				  {16, 0, 0, 0, 16, 0, 0, 0},
+				  }
+};
+
+EXPORT_SYMBOL(cc_table_cpu_4);
+
+struct stn_cc cc_table_cpu_5 = { {
+				  {1, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {0, 4, 4, 4, 4, 4, 0, 4},
+				  {8, 8, 8, 8, 0, 0, 0, 0},
+				  {0, 4, 0, 4, 0, 0, 0, 0},
+				  {16, 0, 0, 0, 16, 0, 0, 0},
+				  }
+};
+
+EXPORT_SYMBOL(cc_table_cpu_5);
+
+struct stn_cc cc_table_cpu_6 = { {
+				  {1, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {0, 4, 4, 4, 4, 4, 0, 4},
+				  {8, 8, 8, 8, 0, 0, 0, 0},
+				  {0, 4, 0, 4, 0, 0, 0, 0},
+				  {16, 0, 0, 0, 16, 0, 0, 0},
+				  }
+};
+
+EXPORT_SYMBOL(cc_table_cpu_6);
+
+struct stn_cc cc_table_cpu_7 = { {
+				  {1, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {4, 2, 2, 2, 2, 2, 2, 2},
+				  {2, 2, 2, 2, 2, 2, 2, 0},
+				  {0, 4, 4, 4, 4, 4, 0, 4},
+				  {8, 8, 8, 8, 0, 0, 0, 0},
+				  {0, 4, 0, 4, 0, 0, 0, 0},
+				  {16, 0, 0, 0, 16, 0, 0, 0},
+				  }
+};
+
+EXPORT_SYMBOL(cc_table_cpu_7);
+
+struct stn_cc cc_table_xgs_0 = { {
+				  {4, 8, 8, 8, 8, 8, 8, 8},
+				  {6, 8, 8, 6, 8, 8, 8, 8},
+				  {6, 8, 8, 8, 8, 8, 8, 8},
+				  {6, 8, 8, 8, 8, 8, 8, 8},
+				  {6, 8, 8, 8, 8, 8, 8, 8},
+				  {6, 8, 8, 8, 8, 8, 8, 8},
+				  {6, 8, 8, 8, 8, 8, 8, 8},
+				  {6, 8, 8, 8, 8, 8, 8, 8},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 4, 0, 4, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  }
+};
+
+EXPORT_SYMBOL(cc_table_xgs_0);
+
+struct stn_cc cc_table_xgs_1 = { {
+				  {4, 8, 8, 8, 8, 8, 8, 8},
+				  {6, 8, 8, 6, 8, 8, 8, 8},
+				  {6, 8, 8, 8, 8, 8, 8, 8},
+				  {6, 8, 8, 8, 8, 8, 8, 8},
+				  {6, 8, 8, 8, 8, 8, 8, 8},
+				  {6, 8, 8, 8, 8, 8, 8, 8},
+				  {6, 8, 8, 8, 8, 8, 8, 8},
+				  {6, 8, 8, 8, 8, 8, 8, 8},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  {0, 4, 0, 4, 0, 0, 0, 0},
+				  {0, 0, 0, 0, 0, 0, 0, 0},
+				  }
+};
+
+EXPORT_SYMBOL(cc_table_xgs_1);
+
+struct stn_cc cc_table_gmac = { {
+				 {4, 8, 8, 8, 8, 8, 8, 8},
+				 {8, 8, 8, 8, 8, 8, 8, 8},
+				 {8, 8, 8, 8, 8, 8, 8, 8},
+				 {8, 8, 8, 8, 8, 8, 8, 8},
+				 {8, 8, 8, 8, 8, 8, 8, 8},
+				 {8, 8, 8, 8, 8, 8, 8, 8},
+				 {8, 8, 8, 8, 8, 8, 8, 8},
+				 {8, 8, 8, 8, 8, 8, 8, 8},
+				 {0, 0, 0, 0, 0, 0, 0, 0},
+				 {0, 0, 0, 0, 0, 0, 0, 0},
+				 {0, 0, 0, 0, 0, 0, 0, 0},
+				 {0, 0, 0, 0, 0, 0, 0, 0},
+				 {0, 4, 0, 0, 0, 0, 0, 4},
+				 {0, 0, 0, 0, 0, 0, 0, 0},
+				 {0, 0, 0, 0, 0, 0, 0, 0},
+				 {0, 0, 0, 0, 0, 0, 0, 0},
+				 }
+};
+
+EXPORT_SYMBOL(cc_table_gmac);
+
+struct stn_cc cc_table_dma = { {
+				{4, 0, 0, 0, 0, 0, 0, 0},
+				{4, 0, 0, 0, 0, 0, 0, 0},
+				{4, 0, 0, 0, 0, 0, 0, 0},
+				{4, 0, 0, 0, 0, 0, 0, 0},
+				{4, 0, 0, 0, 0, 0, 0, 0},
+				{4, 0, 0, 0, 0, 0, 0, 0},
+				{4, 0, 0, 0, 0, 0, 0, 0},
+				{4, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				}
+};
+
+EXPORT_SYMBOL(cc_table_dma);
+
+struct stn_cc cc_table_sec = { {
+				{8, 8, 8, 8, 8, 8, 8, 8},
+				{8, 8, 8, 8, 8, 8, 8, 8},
+				{8, 8, 8, 8, 8, 8, 8, 8},
+				{8, 8, 8, 8, 8, 8, 8, 8},
+				{8, 8, 8, 8, 8, 8, 8, 8},
+				{8, 8, 8, 8, 8, 8, 8, 8},
+				{8, 8, 8, 8, 8, 8, 8, 8},
+				{8, 8, 8, 8, 8, 8, 8, 8},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				{0, 0, 0, 0, 0, 0, 0, 0},
+				}
+};
+
+EXPORT_SYMBOL(cc_table_sec);
diff --git a/arch/mips/rmi/phoenix/on_chip.c b/arch/mips/rmi/phoenix/on_chip.c
new file mode 100644
index 0000000..67b9ac6
--- /dev/null
+++ b/arch/mips/rmi/phoenix/on_chip.c
@@ -0,0 +1,610 @@
+/*
+  Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <linux/init.h>
+#include <linux/smp.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/module.h>
+
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/phnx_user_mac.h>
+#include <asm/rmi/sim.h>
+#include <linux/timer.h>
+#include <linux/smp.h>
+#include <linux/slab.h>
+
+unsigned long phoenix_io_base = (unsigned long) (DEFAULT_PHOENIX_IO_BASE);
+EXPORT_SYMBOL(phoenix_io_base);
+
+#define MSGRNG_CC_INIT_CPU_DEST(conf, dest, cpu) \
+do { \
+	msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][0], 0); \
+	msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][1], 1); \
+	msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][2], 2); \
+	msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][3], 3); \
+	msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][4], 4); \
+	msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][5], 5); \
+	msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][6], 6); \
+	msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][7], 7); \
+} while (0)
+
+/* Initialized CC for cpu 0 to send to all buckets at 0-7 cpus */
+#define MSGRNG_CC_INIT_CPU(conf, cpu) \
+do { \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 0, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 1, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 2, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 3, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 4, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 5, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 6, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 7, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 8, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 9, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 10, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 11, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 12, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 13, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 14, cpu); \
+	MSGRNG_CC_INIT_CPU_DEST(conf, 15, cpu); \
+} while (0)
+
+#define MSGRNG_BUCKETSIZE_INIT_CPU(conf, base) \
+do { \
+	msgrng_write_bucksize(0, conf##bucket_sizes.bucket[base+0]);         \
+	msgrng_write_bucksize(1, conf##bucket_sizes.bucket[base+1]);         \
+	msgrng_write_bucksize(2, conf##bucket_sizes.bucket[base+2]);  \
+	msgrng_write_bucksize(3, conf##bucket_sizes.bucket[base+3]);  \
+	msgrng_write_bucksize(4, conf##bucket_sizes.bucket[base+4]);  \
+	msgrng_write_bucksize(5, conf##bucket_sizes.bucket[base+5]);  \
+	msgrng_write_bucksize(6, conf##bucket_sizes.bucket[base+6]);  \
+	msgrng_write_bucksize(7, conf##bucket_sizes.bucket[base+7]);  \
+} while (0)
+
+#define XLR_MSG_TBL
+
+#define X_MSGRNG_BUCKETSIZE_INIT_CPU(x, y) MSGRNG_BUCKETSIZE_INIT_CPU(x, y)
+
+__u32 pop_bucket_mask[NR_CORES];
+__u32 pop_bucket_start[NR_CORES];
+__u32 pop_bucket_end[NR_CORES];
+__u32 cpu_to_bktmask[NR_CPUS];
+__u32 cpu_to_frstid[NR_CPUS];
+
+uint32_t hard_cpu_online_map;
+uint32_t msgring_global_thread_mask;
+
+/* make this a read/write spinlock */
+spinlock_t msgrng_lock;
+static phnx_atomic_t msgring_registered;
+
+int msgring_int_type;
+EXPORT_SYMBOL(msgring_int_type);
+
+int msgring_watermark_count;
+static __u32 msgring_thread_mask;
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+extern int rmi_msgring_napi;
+extern int xlr_napi_ready;
+extern void xlr_napi_rx_schedule(void);
+#endif
+
+struct tx_stn tx_stns[MAX_TX_STNS];
+
+int rxstn_to_txstn_map[128] = {
+	[0 ... 7] = TX_STN_CPU_0,
+	[8 ... 15] = TX_STN_CPU_1,
+	[16 ... 23] = TX_STN_CPU_2,
+	[24 ... 31] = TX_STN_CPU_3,
+	[32 ... 39] = TX_STN_CPU_4,
+	[40 ... 47] = TX_STN_CPU_5,
+	[48 ... 55] = TX_STN_CPU_6,
+	[56 ... 63] = TX_STN_CPU_7,
+	[64 ... 95] = TX_STN_INVALID,
+	[96 ... 103] = TX_STN_GMAC,
+	[104 ... 107] = TX_STN_DMA,
+	[108 ... 111] = TX_STN_INVALID,
+	[112 ... 113] = TX_STN_XGS_0,
+	[114 ... 115] = TX_STN_XGS_1,
+	[116 ... 119] = TX_STN_INVALID,
+	[120 ... 127] = TX_STN_SEC
+};
+
+void dummy_handler(int bucket, int size, int code, int tx_stid,
+		   struct msgrng_msg *msg, void *dev_id)
+{
+	pr_info("[%s]: No Handler for message from stn_id=%d, bucket=%d, "
+	       "size=%d, msg0=%llx, dropping message\n",
+	       __func__, tx_stid, bucket, size,
+	       (unsigned long long) msg->msg0);
+}
+
+struct tx_stn_handler tx_stn_handler_map[128] = {
+	[0 ... 127] = {dummy_handler, NULL},
+};
+
+void phoenix_msgring_cpu_init(void)
+{
+	int id;
+	unsigned long flags;
+
+	id = cpu_logical_map(get_cpu());
+
+	if (xlr_hybrid_user_mac() || xlr_hybrid_user_mac_xgmac()) {
+		/* msgring interrupt should be disabled */
+		msgring_int_type = 0x0;
+
+		pop_bucket_start[id >> 2] = 0;
+		pop_bucket_end[id >> 2] = 4;
+		pop_bucket_mask[id >> 2] = 0xf;
+	} else {
+		/* all the stations are owned by linux */
+		pop_bucket_start[id >> 2] = 0;
+		pop_bucket_end[id >> 2] = 8;
+		pop_bucket_mask[id >> 2] = 0xff;
+	}
+
+	/* if not thead 0 */
+	if ((id & 0x03) != 0) {
+		put_cpu();
+		return;
+	}
+
+	pr_debug("Initializing message ring for cpu_%d\n", id);
+
+	msgrng_flags_save(flags);
+
+	if (id == 0) {
+		X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL,
+					     0);
+		MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 0);
+	} else if (id == 4) {
+		X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL,
+					     8);
+		MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 1);
+	} else if (id == 8) {
+		X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL,
+					     16);
+		MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 2);
+	} else if (id == 12) {
+		X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL,
+					     24);
+		MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 3);
+	} else if (id == 16) {
+		X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL,
+					     32);
+		MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 4);
+	} else if (id == 20) {
+		X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL,
+					     40);
+		MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 5);
+	} else if (id == 24) {
+		X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL,
+					     48);
+		MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 6);
+	} else if (id == 28) {
+		X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL,
+					     56);
+		MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 7);
+	}
+	msgrng_flags_restore(flags);
+	put_cpu();
+}
+
+void phnx_msgring_config(void)
+{
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	/* If we use NAPI then we enable queue non-empty interrupt */
+	msgring_int_type = rmi_msgring_napi ? 0x01 : 0x02;
+#else
+	msgring_int_type = 0x02;
+#endif
+
+	msgring_watermark_count = 1;
+	msgring_thread_mask = 0x0f;
+}
+
+void phnx_derive_cpu_to_bkt_map(void)
+{
+	int cpus_per_core[NR_CORES];
+	int stns_per_core[NR_CORES];
+	int num_cpus, cpus, cpu_off, from, i;
+	int bucket_mask[NR_CPUS_PER_CORE];
+	int fr_bucket[NR_CPUS_PER_CORE];
+	int core, bkt_idx, bkt_mask;
+
+#define GET_NEXT_SET_BIT_U8(val, rv) { \
+	if (val < (1 << rv)) \
+		rv = 0; \
+	for (i = rv; val != 0 && i <= 7; i++) { \
+		if (val & (1 << i)) { \
+			rv = i; \
+			break; \
+		} \
+	}  \
+	if (i >= 8) \
+		rv = 0; \
+}
+
+
+	memset(cpus_per_core, 0, sizeof(cpus_per_core));
+	memset(stns_per_core, 0, sizeof(stns_per_core));
+
+	for (i = 0; i < NR_CPUS; i++) {
+		if (!(hard_cpu_online_map & (1 << i)))
+			continue;
+		core = i / NR_CPUS_PER_CORE;
+		cpus_per_core[core]++;
+	}
+	for (core = 0; core < NR_CORES; core++) {
+		for (i = 0; i < NR_STNS_PER_CORE; i++) {
+			if (!(pop_bucket_mask[core] & (1 << i)))
+				continue;
+			stns_per_core[core]++;
+		}
+	}
+
+	for (core = 0; core < NR_CORES; core++) {
+		int filled_all = 0;
+		int rv = 0;
+		uint8_t fr_bucket_map = 0;
+		memset(bucket_mask, 0, sizeof(bucket_mask));
+		memset(fr_bucket, 0xff, sizeof(fr_bucket));
+		num_cpus = cpus_per_core[core];
+		if (num_cpus == 0)
+			continue;
+		for (cpus = 0, bkt_idx = 0, bkt_mask =
+		     pop_bucket_mask[core]; bkt_mask;
+		     bkt_mask = bkt_mask >> 1, bkt_idx++) {
+			if (!(bkt_mask & 0x01))
+				continue;
+			bucket_mask[cpus] |= (1 << bkt_idx);
+
+			if (((int) fr_bucket[cpus] != -1)
+			    && (fr_bucket[cpus] < NR_CPUS_PER_CORE))
+				fr_bucket_map &= (~(1 << fr_bucket[cpus]));
+			fr_bucket_map |= (1 << bkt_idx);
+			fr_bucket[cpus] = bkt_idx;
+
+			if ((cpus + 1) == num_cpus)
+				filled_all = 1;
+
+			cpus = (cpus + 1) % num_cpus;
+		}
+
+		/* fill the non filled cpus */
+		if (filled_all == 0) {
+			for (from = 0; cpus < num_cpus; cpus++, from++)
+				bucket_mask[cpus] = bucket_mask[from];
+		}
+		cpu_off = core * NR_CPUS_PER_CORE;
+		for (from = 0, cpus = cpu_off;
+		     cpus < cpu_off + NR_CPUS_PER_CORE; cpus++) {
+			if (!(hard_cpu_online_map & (1 << cpus)))
+				continue;
+			cpu_to_bktmask[cpus] = bucket_mask[from];
+			GET_NEXT_SET_BIT_U8(fr_bucket_map, rv);
+			cpu_to_frstid[cpus] =
+			    rv + (core * NR_STNS_PER_CORE);
+			from++;
+			rv++;
+		}
+	}
+	return;
+}
+
+static int __init xlr_msgring_watermark_setup(char *str)
+{
+	if (*str == '=')
+		str++;
+
+	msgring_watermark_count = (int) simple_strtoul(str, NULL, 10);
+
+	return 1;
+}
+
+static int __init xlr_msgring_thread_mask_setup(char *str)
+{
+	if (*str == '=')
+		str++;
+
+	msgring_thread_mask = simple_strtoul(str, NULL, 16);
+	msgring_thread_mask &= 0x0f;
+
+	return 1;
+}
+
+static int __init xlr_complete_msgring_thread_mask_setup(char *str)
+{
+	if (*str == '=')
+		str++;
+	msgring_global_thread_mask = simple_strtoul(str, NULL, 16);
+	msgring_global_thread_mask &= 0xffffffff;
+	return 1;
+}
+
+__setup("xlr_msgring_watermark=", xlr_msgring_watermark_setup);
+__setup("xlr_msgring_thread_mask=", xlr_msgring_thread_mask_setup);
+__setup("xlr_complete_msgring_thread_mask=",
+	xlr_complete_msgring_thread_mask_setup);
+
+extern void phoenix_cpu_stat_update_msgring_int(void);
+extern void phoenix_cpu_stat_update_msgring_cycles(__u32 cycles);
+extern void phoenix_cpu_stat_update_msgring_pic_int(void);
+
+void msgring_process_rx_msgs(int start_bucket, int end_bucket,
+			     __u32 pop_bucket_mask)
+{
+	unsigned int bucket_empty_bm = 0;
+	int bucket = 0;
+	int size = 0, code = 0, rx_stid = 0;
+	struct msgrng_msg msg;
+	struct tx_stn_handler *handler = 0;
+	unsigned int status = 0;
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	if (xlr_napi_ready && in_irq()) {
+		xlr_napi_rx_schedule();
+		return;
+	}
+#endif
+
+	/* First Drain all the high priority messages */
+	for (;;) {
+		bucket_empty_bm =
+		    (msgrng_read_status() >> 24) & pop_bucket_mask;
+
+		/* all buckets empty, break */
+		if (bucket_empty_bm == pop_bucket_mask)
+			break;
+
+		for (bucket = start_bucket; bucket < end_bucket; bucket++) {
+
+			if ((bucket_empty_bm & (1 << bucket)) || /* empty */
+			    !((1 << bucket) & pop_bucket_mask))	/* not in mask */
+				continue;
+
+			status =
+			    message_receive(bucket, &size, &code, &rx_stid,
+					    &msg);
+			if (status)
+				continue;
+
+			handler = &tx_stn_handler_map[rx_stid];
+			/*
+			 * Handler is always present. If not actual, atleast
+			 * dummy_handler
+			*/
+			(handler->action) (bucket, size, code, rx_stid,
+					   &msg, handler->dev_id);
+		}
+	}
+}
+
+#ifndef CONFIG_PHOENIX_MAC
+struct user_mac_data *user_mac;
+struct xlr_user_mac_config xlr_user_mac;
+void phoenix_cpu_stat_update_msgring_int(void) {}
+
+void phoenix_cpu_stat_update_msgring_cycles(__u32 cycles) {}
+
+void phoenix_cpu_stat_update_msgring_pic_int(void) {}
+#endif				/* CONFIG_PHOENIX_MAC */
+
+__u32 msgrng_msg_cycles;
+
+void phnx_msgring_int_handler(unsigned int irq, struct pt_regs *regs)
+{
+	unsigned long mflags;
+	int core;
+	__u32 cycles = 0;
+	if (irq == IRQ_MSGRING) {
+		/* normal message ring interrupt */
+		phnx_inc_counter(MSGRNG_INT);
+		phoenix_cpu_stat_update_msgring_int();
+	} else {
+		phoenix_cpu_stat_update_msgring_pic_int();
+	}
+
+	irq_enter();
+
+	/* TODO: not necessary to disable preemption */
+	msgrng_flags_save(mflags);
+
+	cycles = read_c0_count();
+
+	core = cpu_logical_map(smp_processor_id()) >> 2;
+	msgring_process_rx_msgs(pop_bucket_start[core],
+				pop_bucket_end[core],
+				pop_bucket_mask[core]);
+
+	phoenix_cpu_stat_update_msgring_cycles(read_c0_count() - cycles);
+
+	msgrng_flags_restore(mflags);
+
+	/* Call the msg callback */
+	irq_exit();
+}
+
+static void enable_msgring_int(void *info)
+{
+	unsigned long flags = 0, mflags = 0;
+	unsigned int th_mask;
+	unsigned int core;
+	msgrng_access_save(&msgrng_lock, flags, mflags);
+
+	core = hard_smp_processor_id() & ~(0x3);
+	th_mask = (msgring_global_thread_mask >> core) & 0x0f;
+
+	/* enable the message ring interrupts */
+	msgrng_write_config((msgring_watermark_count << 24) |
+			    (IRQ_MSGRING << 16)
+			    | (th_mask << 8) | msgring_int_type);
+	msgrng_access_restore(&msgrng_lock, flags, mflags);
+}
+
+static void msgring_bkp_timer(unsigned long data)
+{
+	unsigned long flags;
+	struct timer_list *timer = (struct timer_list *) data;
+	local_irq_save(flags);
+	phnx_msgring_int_handler(-1, NULL);
+	local_irq_restore(flags);
+	mod_timer(timer, timer->expires + 2);
+}
+
+static void enable_msgring_timer(void *data)
+{
+	struct timer_list *timer;
+	timer = kmalloc(sizeof(struct timer_list), GFP_KERNEL);
+	setup_timer(timer, msgring_bkp_timer, (unsigned long) timer);
+	timer->expires = jiffies + 2;
+	add_timer(timer);
+}
+
+extern spinlock_t phnx_pic_lock;
+int register_msgring_handler(int major,
+			     void (*action) (int, int, int, int,
+					     struct msgrng_msg *, void *),
+			     void *dev_id)
+{
+	struct tx_stn_handler *handler = 0;
+	int ret = 1, tx_stid, i, j;
+	unsigned long flags = 0;
+	cpumask_t timer_cpu_mask;
+
+
+	if (major >= MAX_TX_STNS || action == NULL) {
+		pr_info(KERN_ALERT "%s:%d  Invalid parameter: major=%d, "
+		       "MAX_TX_STN=%d action=%p",
+		       __func__, __LINE__, major, MAX_TX_STNS, action);
+		return ret;
+	}
+
+	/* Check if the message station is valid, if not return error */
+	spin_lock_irqsave(&msgrng_lock, flags);
+
+	for (i = 0; i < 128; i++) {
+		tx_stid = rxstn_to_txstn_map[i];
+		if (tx_stid == major) {
+			tx_stn_handler_map[i].action = action;
+			tx_stn_handler_map[i].dev_id = dev_id;
+		}
+	}
+
+	handler = &tx_stns[major].handler;
+
+	handler->action = action;
+	handler->dev_id = dev_id;
+
+	ret = 0;
+	spin_unlock_irqrestore(&msgrng_lock, flags);
+
+	if (!ret && phnx_test_and_set(&msgring_registered)) {
+		int i = 0;
+
+		hard_cpu_online_map = 0;
+		for (i = 0; i < NR_CPUS; i++) {
+			if (cpu_isset(i, cpu_online_map))
+				hard_cpu_online_map |=
+				    (1 << cpu_logical_map(i));
+		}
+
+		/* derive the cpu to bucket map */
+		phnx_derive_cpu_to_bkt_map();
+
+		/* Configure PIC to deliver msgring interrupt for timeouts */
+		if (msgring_global_thread_mask == 0) {
+			for (i = 0; i < NR_CORES; i++) {
+				msgring_global_thread_mask |=
+				    (msgring_thread_mask << (i << 2));
+			}
+		}
+
+		msgring_global_thread_mask &= hard_cpu_online_map;
+
+		/* configure the msgring interrupt on all cpus */
+		on_each_cpu(enable_msgring_int, 0, 1);
+
+		/*
+		 * Schedule a messagering backup timer at every 2 jiffies on one
+		 * therad per core
+		*/
+		cpus_clear(timer_cpu_mask);
+		for (i = 0; i < NR_CORES; i++) {
+			int core_mask;
+			int phys_id, logical_id;
+			if (hard_cpu_online_map &
+			    (0xf << (i * NR_CPUS_PER_CORE))) {
+				core_mask =
+				    (hard_cpu_online_map >>
+				     (i * NR_CPUS_PER_CORE)) & 0xf;
+				for (j = 0; j < NR_CPUS_PER_CORE; j++) {
+					if (core_mask & (1 << j))
+						break;
+				}
+				phys_id = (i * NR_CPUS_PER_CORE) + j;
+				logical_id = cpu_number_map(phys_id);
+				cpu_set(logical_id, timer_cpu_mask);
+			}
+		}
+		smp_call_function_many(&timer_cpu_mask,
+				       enable_msgring_timer, NULL, 1);
+		if (cpu_isset
+		    (cpu_number_map(hard_smp_processor_id()),
+		     timer_cpu_mask))
+			enable_msgring_timer(NULL);
+	}
+
+	return ret;
+}
+
+EXPORT_SYMBOL(register_msgring_handler);
+
+extern void pic_init(void);
+
+void on_chip_init(void)
+{
+	cpu_logical_map(0) = hard_smp_processor_id();
+
+	/* Set phoenix_io_base to the run time value */
+	spin_lock_init(&msgrng_lock);
+
+	msgring_registered.value = 0;
+
+	phnx_msgring_config();
+
+	pic_init();
+
+	phoenix_msgring_cpu_init();
+}
-- 
1.7.0.4

