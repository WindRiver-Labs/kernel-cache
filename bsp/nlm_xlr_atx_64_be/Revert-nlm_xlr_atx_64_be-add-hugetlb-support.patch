From 09987b071f31fc8ba096a51964711bdceb47643e Mon Sep 17 00:00:00 2001
From: Zhang Xiao <xiao.zhang@windriver.com>
Date: Fri, 30 Mar 2012 17:09:45 +0800
Subject: [PATCH 1/3] Revert "nlm_xlr_atx_64_be: add hugetlb support"

This reverts commit e5882041c2c41688ee745cf0426126bdf1e4ed0f.

The original patch was focused on old linux kernel and not fit for newer one.

Signed-off-by: Zhang Xiao <xiao.zhang@windriver.com>
---
 arch/mips/Kconfig               |    1 -
 arch/mips/include/asm/hugetlb.h |    8 ++-
 arch/mips/mm/hugetlbpage.c      |  130 ---------------------------------------
 arch/mips/mm/tlbex.c            |    2 +-
 4 files changed, 7 insertions(+), 134 deletions(-)

diff --git a/arch/mips/Kconfig b/arch/mips/Kconfig
index 3ac20b8..bd4bc24 100644
--- a/arch/mips/Kconfig
+++ b/arch/mips/Kconfig
@@ -1342,7 +1342,6 @@ config CPU_PHOENIX
 	select CPU_SUPPORTS_32BIT_KERNEL
 	select CPU_SUPPORTS_64BIT_KERNEL
 	select CPU_SUPPORTS_HIGHMEM
-	select CPU_SUPPORTS_HUGEPAGES
 	select CPU_HAS_LLSC
 	select WEAK_ORDERING
 	select WEAK_REORDERING_BEYOND_LLSC
diff --git a/arch/mips/include/asm/hugetlb.h b/arch/mips/include/asm/hugetlb.h
index 223c431..c565b7c 100644
--- a/arch/mips/include/asm/hugetlb.h
+++ b/arch/mips/include/asm/hugetlb.h
@@ -11,8 +11,6 @@
 
 #include <asm/page.h>
 
-extern void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,
-				pte_t *ptep, pte_t entry);
 
 static inline int is_hugepage_only_range(struct mm_struct *mm,
 					 unsigned long addr,
@@ -52,6 +50,12 @@ static inline void hugetlb_free_pgd_range(struct mmu_gather *tlb,
 	free_pgd_range(tlb, addr, end, floor, ceiling);
 }
 
+static inline void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,
+				   pte_t *ptep, pte_t pte)
+{
+	set_pte_at(mm, addr, ptep, pte);
+}
+
 static inline pte_t huge_ptep_get_and_clear(struct mm_struct *mm,
 					    unsigned long addr, pte_t *ptep)
 {
diff --git a/arch/mips/mm/hugetlbpage.c b/arch/mips/mm/hugetlbpage.c
index 1173826..a7fee0d 100644
--- a/arch/mips/mm/hugetlbpage.c
+++ b/arch/mips/mm/hugetlbpage.c
@@ -22,135 +22,6 @@
 #include <asm/tlb.h>
 #include <asm/tlbflush.h>
 
-#ifdef CONFIG_CPU_PHOENIX
-static pte_t *get_pte_offset(struct mm_struct *mm, unsigned long addr)
-{
-	pgd_t *pgd;
-	pud_t *pud;
-	pmd_t *pmd;
-	pte_t *pte = NULL;
-
-	pgd = pgd_offset(mm, addr);
-	if (!pgd_none(*pgd)) {
-		pud = pud_offset(pgd, addr);
-		if (!pud_none(*pud)) {
-			pmd = pmd_offset(pud, addr);
-			if (!pmd_none(*pmd))
-				pte = pte_offset_map(pmd, addr);
-		}
-	}
-	return pte;
-}
-
-void set_huge_pte_at(struct mm_struct *mm, unsigned long addr, pte_t *ptep,
-		pte_t entry)
-{
-	int i;
-	uint32_t htlb_entries = 1 << HUGETLB_PAGE_ORDER;
-	struct vm_area_struct *vma = NULL;
-	uint32_t len = htlb_entries*PAGE_SIZE;
-	pte_t first_entry = entry;
-	unsigned long orig_addr ;
-
-	/*
-	 * We must align the address, because our caller will run
-	 * set_huge_pte_at() on whatever we return, which writes out
-	 * all of the sub-ptes for the hugepage range.  So we have
-	 * to give it the first such sub-pte.
-	 */
-	addr &= HPAGE_MASK;
-	orig_addr = addr;
-	/*Fill each entry with its own physical address map*/
-	for (i = 0; i < htlb_entries; i++) {
-		/*Get the pte offset, we may cross the pte table*/
-		ptep = get_pte_offset(mm, addr);
-
-		set_pte_at(mm, addr, ptep, entry);
-		addr += PAGE_SIZE;
-		pte_val(entry) += PAGE_SIZE;
-	}
-	addr = orig_addr;
-	vma = find_vma(mm, addr);
-
-	/*addr must belong to this vma*/
-	if (!((addr >= vma->vm_start) && ((addr+len) <= vma->vm_end)))
-		panic("set_huge_pte_at: No vma found for hugtlb page!!");
-
-	/*Don't know below loop is required or not.*/
-	pte_val(entry) = pte_val(first_entry);
-	for (i = 0 ; i < htlb_entries; i++) {
-		__update_cache(vma, addr, entry);
-		addr += PAGE_SIZE;
-		pte_val(entry) += PAGE_SIZE;
-	}
-}
-
-static pte_t *huge_pte_alloc_single(struct mm_struct *mm, unsigned long addr)
-{
-	pgd_t *pgd;
-	pud_t *pud;
-	pmd_t *pmd;
-	pte_t *pte = NULL;
-
-	pgd = pgd_offset(mm, addr);
-	pud = pud_alloc(mm, pgd, addr);
-	if (pud) {
-		pmd = pmd_alloc(mm, pud, addr);
-		if (pmd)
-			pte = pte_alloc_map(mm, pmd, addr);
-	}
-	return pte;
-}
-
-pte_t *huge_pte_alloc(struct mm_struct *mm, unsigned long addr, unsigned long sz)
-{
-	pte_t *first_pte = NULL;
-	pte_t *pte = NULL;
-	int i = 0;
-	uint32_t htlb_entries = 1 << HUGETLB_PAGE_ORDER;
-	uint32_t total_pte_required = htlb_entries / PTRS_PER_PTE;
-
-	/*increment number of pte required if htlb_entries
-	  is not multiple of PTRS_PER_PTE
-	*/
-	if (htlb_entries % PTRS_PER_PTE)
-		total_pte_required++;
-
-	addr &= HPAGE_MASK;
-	for (i = 0; i < total_pte_required; i++) {
-		pte = huge_pte_alloc_single(mm, addr);
-		if (!pte)
-			return NULL;
-		if (!first_pte)
-			first_pte = pte;
-		addr = addr + (PTRS_PER_PTE*PAGE_SIZE);
-	}
-	return first_pte;
-}
-
-pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)
-{
-	pgd_t *pgd;
-	pud_t *pud;
-	pmd_t *pmd;
-	pte_t *pte = NULL;
-
-	addr &= HPAGE_MASK;
-
-	pgd = pgd_offset(mm, addr);
-	if (!pgd_none(*pgd)) {
-		pud = pud_offset(pgd, addr);
-		if (!pud_none(*pud)) {
-			pmd = pmd_offset(pud, addr);
-			if (!pmd_none(*pmd))
-				pte = pte_offset_map(pmd, addr);
-		}
-	}
-	return pte;
-}
-
-#else
-
 pte_t *huge_pte_alloc(struct mm_struct *mm, unsigned long addr,
 		      unsigned long sz)
 {
@@ -180,7 +51,6 @@ pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)
 	}
 	return (pte_t *) pmd;
 }
-#endif
 
 int huge_pmd_unshare(struct mm_struct *mm, unsigned long *addr, pte_t *ptep)
 {
diff --git a/arch/mips/mm/tlbex.c b/arch/mips/mm/tlbex.c
index c45b94f..518245b 100644
--- a/arch/mips/mm/tlbex.c
+++ b/arch/mips/mm/tlbex.c
@@ -326,7 +326,6 @@ static void __cpuinit build_tlb_write_entry(u32 **p, struct uasm_label **l,
 	case CPU_5KC:
 	case CPU_TX49XX:
 	case CPU_PR4450:
-	case CPU_PHOENIX:
 		uasm_i_nop(p);
 		tlbw(p);
 		break;
@@ -354,6 +353,7 @@ static void __cpuinit build_tlb_write_entry(u32 **p, struct uasm_label **l,
 		tlbw(p);
 		break;
 
+	case CPU_PHOENIX:
 	case CPU_NEVADA:
 		uasm_i_nop(p); /* QED specifies 2 nops hazard */
 		/*
-- 
1.7.0.4

