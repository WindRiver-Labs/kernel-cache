From 12023400ed720bbc679a5b65772b5d829d68202c Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Wed, 19 May 2010 23:57:28 +0800
Subject: [PATCH 05/47] nlm_xlr_atx_64_be: add smp support

Extracted from RMI SDK 1.7.0.

XLR732 has 8 cores and 4 hardware threads per core. Following is the smp
support for it.

Signed-off-by: Jack Tan <jack.tan@windriver.com>
Signed-off-by: Wu Zhangjin <zhangjin.wu@windriver.com>
---
 arch/mips/include/asm/smp.h    |    1 +
 arch/mips/kernel/smp.c         |    8 ++-
 arch/mips/rmi/phoenix/Makefile |    1 +
 arch/mips/rmi/phoenix/smp.c    |   74 +++++++++++++++
 arch/mips/rmi/ptr/Makefile     |    6 ++
 arch/mips/rmi/ptr/smp.c        |  194 ++++++++++++++++++++++++++++++++++++++++
 arch/mips/rmi/ptr/smpboot.S    |   68 ++++++++++++++
 7 files changed, 351 insertions(+), 1 deletions(-)
 create mode 100644 arch/mips/rmi/phoenix/smp.c
 create mode 100644 arch/mips/rmi/ptr/Makefile
 create mode 100644 arch/mips/rmi/ptr/smp.c
 create mode 100644 arch/mips/rmi/ptr/smpboot.S

diff --git a/arch/mips/include/asm/smp.h b/arch/mips/include/asm/smp.h
index af42385..4d82cff 100644
--- a/arch/mips/include/asm/smp.h
+++ b/arch/mips/include/asm/smp.h
@@ -44,6 +44,7 @@ extern int __cpu_logical_map[NR_CPUS];
 extern volatile cpumask_t cpu_callin_map;
 
 extern void asmlinkage smp_bootstrap(void);
+extern void core_send_ipi(int cpu, unsigned int action);
 
 /*
  * this function sends a 'reschedule' IPI to another CPU.
diff --git a/arch/mips/kernel/smp.c b/arch/mips/kernel/smp.c
index 0aaa22b..9f5d9d8 100644
--- a/arch/mips/kernel/smp.c
+++ b/arch/mips/kernel/smp.c
@@ -110,7 +110,13 @@ asmlinkage __cpuinit void start_secondary(void)
 	 * XXX parity protection should be folded in here when it's converted
 	 * to an option instead of something based on .cputype
 	 */
-
+#ifdef CONFIG_RMI_PHOENIX
+	/*
+	 * Since we use pic timer of the platform as the jiffie, we
+	 * need to enable interrupt here before calibrate_delay.
+	 */
+	local_irq_enable();
+#endif
 	calibrate_delay();
 	preempt_disable();
 	cpu = smp_processor_id();
diff --git a/arch/mips/rmi/phoenix/Makefile b/arch/mips/rmi/phoenix/Makefile
index 187cd6c..8a3b61e 100644
--- a/arch/mips/rmi/phoenix/Makefile
+++ b/arch/mips/rmi/phoenix/Makefile
@@ -1,3 +1,4 @@
 obj-y := irq.o cpu.o time.o
+obj-$(CONFIG_SMP) += smp.o
 
 EXTRA_AFLAGS := $(CFLAGS)
diff --git a/arch/mips/rmi/phoenix/smp.c b/arch/mips/rmi/phoenix/smp.c
new file mode 100644
index 0000000..669d39e
--- /dev/null
+++ b/arch/mips/rmi/phoenix/smp.c
@@ -0,0 +1,74 @@
+/*
+  Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+*/
+
+#include <linux/hardirq.h>
+#include <linux/module.h>
+
+#include <asm/addrspace.h>
+#include <asm/smp.h>
+#include <asm/rmi/interrupt.h>
+
+void core_send_ipi(int logical_cpu, unsigned int action)
+{
+	int cpu = cpu_logical_map(logical_cpu);
+	__u32 ipi = 0;
+	__u32 tid = cpu & 0x3;
+	__u32 pid = (cpu >> 2) & 0x07;
+
+	if (action & SMP_CALL_FUNCTION) {
+		ipi = (tid << 16) | (pid << 20) | IRQ_IPI_SMP_FUNCTION;
+		pr_debug("[%s]: cpu_%d sending ipi_3 to cpu_%d\n",
+			 __func__, smp_processor_id(), cpu);
+	} else if (action & SMP_RESCHEDULE_YOURSELF) {
+		ipi = (tid << 16) | (pid << 20) | IRQ_IPI_SMP_RESCHEDULE;
+		pr_debug("[%s]: cpu_%d sending ipi_4 to cpu_%d\n", __func__,
+			 smp_processor_id(), cpu);
+	} else if (action & SMP_CALL_KGDB_HOOK) {
+		ipi = (tid << 16) | (pid << 20) | (1 << 8) | IRQ_IPI_SMP_KGDB;
+		pr_debug("Sending KGDB IPI 0x%08x to tid %d pid %d\n", ipi, tid,
+			 pid);
+	} else
+		BUG();
+
+	pic_send_ipi(ipi);
+}
+
+extern __u64 phnx_irq_mask;
+
+void phoenix_ipi_handler(int irq, struct pt_regs *regs)
+{
+	if (irq == IRQ_IPI_SMP_FUNCTION) {
+		pr_debug("[%s]: cpu_%d processing ipi_%d\n", __func__,
+			 smp_processor_id(), irq);
+		smp_call_function_interrupt();
+	} else {
+		pr_debug("[%s]: cpu_%d processing ipi_%d\n", __func__, smp_processor_id(), irq);
+		/* Announce that we are for reschduling */
+		set_need_resched();
+	}
+}
diff --git a/arch/mips/rmi/ptr/Makefile b/arch/mips/rmi/ptr/Makefile
new file mode 100644
index 0000000..dec1234
--- /dev/null
+++ b/arch/mips/rmi/ptr/Makefile
@@ -0,0 +1,6 @@
+obj-$(CONFIG_SMP)      += smp.o smpboot.o
+
+EXTRA_AFLAGS := $(CFLAGS)
+EXTRA_CFLAGS += -I$(srctree)/include/asm/rmi
+
+
diff --git a/arch/mips/rmi/ptr/smp.c b/arch/mips/rmi/ptr/smp.c
new file mode 100644
index 0000000..44732b7
--- /dev/null
+++ b/arch/mips/rmi/ptr/smp.c
@@ -0,0 +1,194 @@
+/*
+  Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+*/
+
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+
+#include <asm/asm.h>
+#include <asm/mmu_context.h>
+#include <asm/atomic.h>
+#include <asm/smp.h>
+#include <asm/mipsregs.h>
+#include <asm/processor.h>
+
+#include <asm/rmi/sim.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/mips-exts.h>
+
+struct smp_boot_info smp_boot;
+extern void ptr_smp_boot(unsigned long, unsigned long, unsigned long);
+extern void prom_reconfigure_thr_resources(void);
+
+/* Don't need a really big stack here */
+#define PER_CPU_THREAD_SIZE (THREAD_SIZE >> 2)
+#define TOTAL_THREAD_SIZE       (PER_CPU_THREAD_SIZE * (NR_CPUS - 1))
+
+/*
+ * This structure is used for changing sp and gp of secondary CPUs from that
+ *  of the bootloader and used until Linux kernel allocates one for them
+ */
+struct xlr_stack_pages {
+	unsigned long stack[(TOTAL_THREAD_SIZE) / sizeof(long)];
+};
+
+struct xlr_stack_pages xlr_stack_pages_temp
+	__attribute__ ((__section__(".data.init_task"), __aligned__(THREAD_SIZE)));
+
+void rmi_send_ipi_single(int cpu, unsigned int action)
+{
+	core_send_ipi(cpu, action);
+}
+
+void rmi_send_ipi_mask(const struct cpumask *mask, unsigned int action)
+{
+	int cpu;
+
+	for_each_cpu(cpu, mask)
+		core_send_ipi(cpu, action);
+}
+
+/*
+ * Code to run on secondary just after probing the CPU
+ */
+static void __cpuinit rmi_init_secondary(void)
+{
+	extern void rmi_smp_irq_init(void);
+
+	rmi_smp_irq_init();
+	/* Time init for this cpu is done in mips_clockevent_init() */
+}
+
+void rmi_smp_finish(void)
+{
+	phoenix_msgring_cpu_init();
+}
+
+void rmi_cpus_done(void)
+{
+}
+
+/*
+ * Boot all other cpus in the system, initialize them, and
+ * bring them into the boot fn
+*/
+void rmi_boot_secondary(int logical_cpu, struct task_struct *idle)
+{
+	unsigned long gp = (unsigned long)task_thread_info(idle);
+	unsigned long sp = (unsigned long)__KSTK_TOS(idle);
+
+	int cpu = cpu_logical_map(logical_cpu);
+
+	pr_debug("(PROM): waking up phys cpu# %d, gp = %lx\n", cpu, gp);
+
+	smp_boot.boot_info[cpu].sp = sp;
+	smp_boot.boot_info[cpu].gp = gp;
+	smp_boot.boot_info[cpu].fn = (unsigned long)&smp_bootstrap;
+	/* barrier */
+	__sync();
+	smp_boot.boot_info[cpu].ready = 1;
+
+	pr_debug("(PROM): sent a wakeup message to cpu %d\n", cpu);
+}
+
+unsigned int fast_syscall_cpumask_phy = 0x1;
+
+void __init rmi_smp_setup(void)
+{
+	int num_cpus = 1, i;
+	__u32 boot_cpu_online_map = 0, boot_cpu = 0x0;
+
+	boot_cpu = hard_smp_processor_id();
+
+	cpus_clear(cpu_possible_map);
+
+	boot_cpu_online_map = smp_boot.online_map;
+	pr_info("(PROM) CPU present map: %x\n", boot_cpu_online_map);
+
+	/* Fill the entries for boot cpu */
+	boot_cpu_online_map &= (~(1 << boot_cpu));
+	cpu_set(boot_cpu, cpu_possible_map);
+	__cpu_number_map[boot_cpu] = 0;
+	__cpu_logical_map[0] = boot_cpu;
+	cpu_set(0, cpu_possible_map);
+
+	for (i = 0; i < NR_CPUS; i++) {
+		if (boot_cpu_online_map & (1 << i)) {
+			cpu_set(i, cpu_possible_map);
+			__cpu_number_map[i] = num_cpus;
+			__cpu_logical_map[num_cpus] = i;
+			cpu_set(num_cpus, cpu_possible_map);
+			++num_cpus;
+		}
+	}
+
+	fast_syscall_cpumask_phy = (unsigned int)cpu_possible_map.bits[0];
+
+	pr_info("Phys CPU present map: %lx, possible map %lx\n",
+		(unsigned long)cpu_possible_map.bits[0],
+		(unsigned long)cpu_possible_map.bits[0]);
+
+	pr_info("Detected %i Slave CPU(s)\n", num_cpus);
+}
+
+void rmi_prepare_cpus(unsigned int max_cpus)
+{
+}
+
+struct plat_smp_ops rmi_smp_ops = {
+	.send_ipi_single = rmi_send_ipi_single,
+	.send_ipi_mask = rmi_send_ipi_mask,
+	.init_secondary = rmi_init_secondary,
+	.smp_finish = rmi_smp_finish,
+	.cpus_done = rmi_cpus_done,
+	.boot_secondary = rmi_boot_secondary,
+	.smp_setup = rmi_smp_setup,
+	.prepare_cpus = rmi_prepare_cpus,
+};
+
+void prom_boot_cpus_secondary(void *args)
+{
+	int cpu = hard_smp_processor_id();
+
+	write_c0_ebase(ebase);
+	atomic_add((1 << cpu), (atomic_t *)&smp_boot.online_map);
+
+	do {
+		if (smp_boot.boot_info[cpu].ready)
+			break;
+	} while (1);
+
+	__sync();
+
+	prom_reconfigure_thr_resources();
+
+	ptr_smp_boot(smp_boot.boot_info[cpu].fn, smp_boot.boot_info[cpu].sp,
+		     smp_boot.boot_info[cpu].gp);
+}
diff --git a/arch/mips/rmi/ptr/smpboot.S b/arch/mips/rmi/ptr/smpboot.S
new file mode 100644
index 0000000..873a07c
--- /dev/null
+++ b/arch/mips/rmi/ptr/smpboot.S
@@ -0,0 +1,68 @@
+/*
+ * Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <asm/asm.h>
+#include <asm/asm-offsets.h>
+#include <asm/regdef.h>
+#include <asm/mipsregs.h>
+
+NESTED(ptr_smp_boot, 16, sp)
+
+	move	sp, a1
+	move	gp, a2
+	jal	a0
+	nop
+
+END(ptr_smp_boot)
+
+/* Don't jump to linux function from Bootloader stack. Change it
+ * here. Kernel might allocate bootloader memory before all the CPUs are
+ * brought up (eg: Inode cache region) and we better don't overwrite this
+ * memory
+ */
+NESTED(prom_pre_boot_secondary_cpus, 16, sp)
+	.set mips64
+	mfc0 t0, $15, 1 #read ebase
+	andi t0, 0x1f #t0 has the processor_id()
+	PTR_LA	t1, xlr_stack_pages_temp
+	li   t2, _THREAD_SIZE
+	srl  t2, 2
+	mul  t3, t2, t0
+	nop
+	nop
+	nop
+	nop
+	nop
+	nop
+	PTR_ADDU  gp, t1, t3
+	PTR_ADDU       sp, gp, t2
+	PTR_ADDI       sp, sp, -32
+	PTR_LA t0, prom_boot_cpus_secondary
+	jr t0
+	 nop
+END(prom_pre_boot_secondary_cpus)
-- 
1.7.0.4

