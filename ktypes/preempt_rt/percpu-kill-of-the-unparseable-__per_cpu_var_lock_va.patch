From ed942a5458eaf56bf32b2299a440df07075adba7 Mon Sep 17 00:00:00 2001
From: Paul Gortmaker <paul.gortmaker@windriver.com>
Date: Mon, 21 Feb 2011 11:39:57 -0500
Subject: [PATCH] percpu: kill of the unparseable __per_cpu_var_lock_var(var)

This macro and its slightly less incomprehensible sister
are a net loss in terms of readability.  One might be able
to argue that they made sense (doubtful) in the old world
where percpu vars had a per_cpu__ prefix, but they sure
don't help the comprehensibility now.

To me, it is easier to just see:

	var##_lock        --> CPP replacement of PCPU locked var.
	lock_##var##_lock --> spinlock protecting above PCPU var.

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
---
 include/asm-generic/percpu.h |   14 +++++---------
 include/linux/percpu-defs.h  |    4 ++--
 2 files changed, 7 insertions(+), 11 deletions(-)

diff --git a/include/asm-generic/percpu.h b/include/asm-generic/percpu.h
index 1227a56..0c3ffb7 100644
--- a/include/asm-generic/percpu.h
+++ b/include/asm-generic/percpu.h
@@ -5,9 +5,6 @@
 #include <linux/threads.h>
 #include <linux/percpu-defs.h>
 
-#define __per_cpu_var_lock(var)	lock_##var##_locked
-#define __per_cpu_var_lock_var(var) var##_locked
-
 #ifdef CONFIG_SMP
 
 /*
@@ -64,9 +61,9 @@ extern unsigned long __per_cpu_offset[NR_CPUS];
 	(*SHIFT_PERCPU_PTR(&(var), __my_cpu_offset))
 
 #define per_cpu_lock(var, cpu) \
-	(*SHIFT_PERCPU_PTR(&__per_cpu_var_lock(var), per_cpu_offset(cpu)))
+	(*SHIFT_PERCPU_PTR(&(lock_##var##_locked), per_cpu_offset(cpu)))
 #define per_cpu_var_locked(var, cpu) \
-	(*SHIFT_PERCPU_PTR(&__per_cpu_var_lock_var(var), per_cpu_offset(cpu)))
+	(*SHIFT_PERCPU_PTR(&(var##_locked), per_cpu_offset(cpu)))
 #define __get_cpu_lock(var, cpu) \
 		per_cpu_lock(var, cpu)
 #define __get_cpu_var_locked(var, cpu) \
@@ -82,12 +79,11 @@ extern void setup_per_cpu_areas(void);
 #else /* ! SMP */
 
 #define per_cpu(var, cpu)			(*((void)(cpu), &(var)))
-#define per_cpu_var_locked(var, cpu) \
-	(*((void)(cpu), &__per_cpu_var_lock_var(var)))
+#define per_cpu_var_locked(var, cpu)	(*((void)(cpu), &(var##_locked)))
 #define __get_cpu_var(var)			(var)
 #define __raw_get_cpu_var(var)			(var)
-#define __get_cpu_lock(var, cpu)		__per_cpu_var_lock(var)
-#define __get_cpu_var_locked(var, cpu)		__per_cpu_var_lock_var(var)
+#define __get_cpu_lock(var, cpu)		(lock_##var##_locked)
+#define __get_cpu_var_locked(var, cpu)		(var##_locked)
 #define this_cpu_ptr(ptr) per_cpu_ptr(ptr, 0)
 #define __this_cpu_ptr(ptr) this_cpu_ptr(ptr)
 
diff --git a/include/linux/percpu-defs.h b/include/linux/percpu-defs.h
index bdc249b..4f9c20d 100644
--- a/include/linux/percpu-defs.h
+++ b/include/linux/percpu-defs.h
@@ -99,8 +99,8 @@
 	__DEFINE_SPINLOCK(lock_##name##_locked)
 
 #define DECLARE_PER_CPU_LOCKED(type, name)				\
-	extern PER_CPU_ATTRIBUTES spinlock_t __per_cpu_var_lock(name);	\
-	extern PER_CPU_ATTRIBUTES __typeof__(type) __per_cpu_var_lock_var(name)
+	extern PER_CPU_ATTRIBUTES spinlock_t lock_##name##_locked;	\
+	extern PER_CPU_ATTRIBUTES __typeof__(type) name##_locked
 
 #define DEFINE_PER_CPU_LOCKED(type, name)				\
 	DEFINE_PER_CPU_SPINLOCK(name, "");				\
-- 
1.7.4

