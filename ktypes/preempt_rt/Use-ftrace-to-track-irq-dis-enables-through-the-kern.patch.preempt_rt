From 81a61db97317d0ce203bcdd85bd4c95f4973fa04 Mon Sep 17 00:00:00 2001
From: Matt Sherer <matt.sherer@windriver.com>
Date: Sat, 31 Jan 2009 07:41:06 -0800
Subject: [PATCH] Use ftrace to track irq dis/enables through the kernel.

This is done on top of ftrace/CONFIG_IRQSOFF_TRACER.
Track it in a normal ftrace buffer set, kept separately from the normal
CONFIG_IRQSOFF_TRACER buffer.  Also provide the ability to dump the stored
trace when an NMI occurs.

Usage:

Enable it with CONFIG_FTRACE and CONFIG_IRQSOFF_TRACER.
This adds a new tracer name, which can be activated with:

mount -t debugfs nodev /debug
echo 32 > /debug/tracing/trace_entries
echo irqtrack > /debug/tracing/current_tracer
echo 1 > /debug/tracing/tracing_enabled

cat /debug/tracing/trace # watch the current buffer sequence

The same contents of /debug/tracing/trace are dumped at the
beginning of an NMI event.
---
 arch/x86/kernel/traps_32.c   |    6 ++++
 kernel/trace/trace.c         |   22 ++++++++++++++++
 kernel/trace/trace_irqsoff.c |   56 ++++++++++++++++++++++++++++++++++++++---
 3 files changed, 79 insertions(+), 5 deletions(-)

diff --git a/arch/x86/kernel/traps_32.c b/arch/x86/kernel/traps_32.c
index 7a0c947..fc00175 100644
--- a/arch/x86/kernel/traps_32.c
+++ b/arch/x86/kernel/traps_32.c
@@ -765,6 +765,12 @@ static DEFINE_SPINLOCK(nmi_print_lock);
 
 void notrace __kprobes die_nmi(char *str, struct pt_regs *regs, int do_panic)
 {
+
+#ifdef CONFIG_IRQSOFF_TRACER
+extern void dump_irq_trace(void);
+	dump_irq_trace();
+#endif
+
 	if (notify_die(DIE_NMIWATCHDOG, str, regs, 0, 2, SIGINT) == NOTIFY_STOP)
 		return;
 
diff --git a/kernel/trace/trace.c b/kernel/trace/trace.c
index 67b4e9a..2b39f14 100644
--- a/kernel/trace/trace.c
+++ b/kernel/trace/trace.c
@@ -1510,6 +1510,28 @@ seq_print_sym_offset(struct trace_seq *s, const char *fmt,
 	return 1;
 }
 
+#ifdef CONFIG_IRQSOFF_TRACER
+extern struct trace_array *irqtrack_trace;
+static struct trace_iterator iter;
+void dump_irq_trace(void) {
+	int i = 0;
+	iter.tr = irqtrack_trace;
+	iter.trace = current_trace;
+	iter.pos = -1;
+	printk("#           TASK-PID    PPID CPU#    TIMESTAMP  FUNCTION\n");
+	printk("#              | |         |  |          |         |\n");
+	if (iter.trace && iter.trace->open) 
+		iter.trace->open(&iter); /* _really_ ensure tracing is off */
+	while (i < global_trace.entries) {
+		find_next_entry_inc(&iter);
+		print_trace_line(&iter);
+		printk("%s",iter.seq.buffer);
+		trace_seq_reset(&iter.seq);
+		i++;
+	}
+}
+#endif
+
 #ifndef CONFIG_64BIT
 # define IP_FMT "%08lx"
 #else
diff --git a/kernel/trace/trace_irqsoff.c b/kernel/trace/trace_irqsoff.c
index cb78bef..50a8df9 100644
--- a/kernel/trace/trace_irqsoff.c
+++ b/kernel/trace/trace_irqsoff.c
@@ -19,6 +19,7 @@
 #include "trace.h"
 #include "trace_hist.h"
 
+struct trace_array			*irqtrack_trace __read_mostly;
 static struct trace_array		*irqsoff_trace __read_mostly;
 static int				tracer_enabled __read_mostly;
 
@@ -29,6 +30,7 @@ static DEFINE_RAW_SPINLOCK(max_trace_lock);
 enum {
 	TRACER_IRQS_OFF		= (1 << 1),
 	TRACER_PREEMPT_OFF	= (1 << 2),
+	TRACER_IRQ_TRACK	= (1 << 3),
 };
 
 static int trace_type __read_mostly;
@@ -47,7 +49,7 @@ preempt_trace(void)
 static inline int
 irq_trace(void)
 {
-	return ((trace_type & TRACER_IRQS_OFF) &&
+	return ((trace_type & TRACER_IRQS_OFF || trace_type & TRACER_IRQ_TRACK) &&
 		irqs_disabled());
 }
 #else
@@ -179,22 +181,29 @@ out_unlock:
 out:
 	data->critical_sequence = max_sequence;
 	data->preempt_timestamp = ftrace_now(cpu);
-	tracing_reset(data);
+	if (!(trace_type & TRACER_IRQ_TRACK))
+		tracing_reset(data);
 	trace_function(tr, data, CALLER_ADDR0, parent_ip, flags,
 		       preempt_count());
 }
 
+extern void die_nmi(char *, struct pt_regs *, int);
 static inline void
 start_critical_timing(unsigned long ip, unsigned long parent_ip)
 {
 	int cpu;
-	struct trace_array *tr = irqsoff_trace;
+	struct trace_array *tr;
 	struct trace_array_cpu *data;
 	unsigned long flags;
 
 	if (likely(!tracer_enabled))
 		return;
 
+	if (trace_type & TRACER_IRQ_TRACK)
+		tr = irqtrack_trace;
+	else 
+		tr = irqsoff_trace;
+
 	cpu = raw_smp_processor_id();
 
 	if (per_cpu(tracing_cpu, cpu))
@@ -210,7 +219,8 @@ start_critical_timing(unsigned long ip, unsigned long parent_ip)
 	data->critical_sequence = max_sequence;
 	data->preempt_timestamp = ftrace_now(cpu);
 	data->critical_start = parent_ip ? : ip;
-	tracing_reset(data);
+	if (!(trace_type & TRACER_IRQ_TRACK))
+		tracing_reset(data);
 
 	local_save_flags(flags);
 
@@ -225,7 +235,7 @@ static inline void
 stop_critical_timing(unsigned long ip, unsigned long parent_ip)
 {
 	int cpu;
-	struct trace_array *tr = irqsoff_trace;
+	struct trace_array *tr;
 	struct trace_array_cpu *data;
 	unsigned long flags;
 
@@ -239,6 +249,11 @@ stop_critical_timing(unsigned long ip, unsigned long parent_ip)
 	if (!tracer_enabled)
 		return;
 
+	if (trace_type & TRACER_IRQ_TRACK)
+		tr = irqtrack_trace;
+	else 
+		tr = irqsoff_trace;
+
 	data = tr->data[cpu];
 
 	if (unlikely(!data) || unlikely(!head_page(data)) ||
@@ -387,6 +402,19 @@ static void stop_irqsoff_tracer(struct trace_array *tr)
 	unregister_ftrace_function(&trace_ops);
 }
 
+static void __irqtrack_tracer_init(struct trace_array *tr)
+{
+	int cpu;
+	irqtrack_trace = tr;
+	/* make sure that the tracer is visible */
+	smp_wmb();
+
+	for_each_online_cpu(cpu)
+		tracing_reset(tr->data[cpu]);
+	if (tr->ctrl)
+		start_irqsoff_tracer(tr);
+}
+
 static void __irqsoff_tracer_init(struct trace_array *tr)
 {
 	irqsoff_trace = tr;
@@ -431,6 +459,22 @@ static void irqsoff_tracer_init(struct trace_array *tr)
 
 	__irqsoff_tracer_init(tr);
 }
+static void irqtrack_tracer_init(struct trace_array *tr)
+{
+	trace_type = TRACER_IRQ_TRACK;
+
+	__irqtrack_tracer_init(tr);
+}
+static struct tracer irqtrack_tracer __read_mostly =
+{
+	.name		= "irqtrack",
+	.init		= irqtrack_tracer_init,
+	.reset		= irqsoff_tracer_reset,
+	.open		= irqsoff_tracer_open,
+	.close		= irqsoff_tracer_close,
+	.ctrl_update	= irqsoff_tracer_ctrl_update,
+};
+# define register_irqtrack(trace) register_tracer(&trace)
 static struct tracer irqsoff_tracer __read_mostly =
 {
 	.name		= "irqsoff",
@@ -447,6 +491,7 @@ static struct tracer irqsoff_tracer __read_mostly =
 # define register_irqsoff(trace) register_tracer(&trace)
 #else
 # define register_irqsoff(trace) do { } while (0)
+# define register_irqtrack(trace) do { } while (0)
 #endif
 
 #ifdef CONFIG_PREEMPT_TRACER
@@ -506,6 +551,7 @@ static struct tracer preemptirqsoff_tracer __read_mostly =
 
 __init static int init_irqsoff_tracer(void)
 {
+	register_irqsoff(irqtrack_tracer);
 	register_irqsoff(irqsoff_tracer);
 	register_preemptoff(preemptoff_tracer);
 	register_preemptirqsoff(preemptirqsoff_tracer);
