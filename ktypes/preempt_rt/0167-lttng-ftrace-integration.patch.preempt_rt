From 830d2b3c9f4871363660235cb6dec0dedeca4910 Mon Sep 17 00:00:00 2001
From: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
Date: Thu, 2 Oct 2008 01:44:19 -0400
Subject: [PATCH] lttng-ftrace-integration

LTTng ftrace integration

Mark LTTng probe functions as "notrace".
Use preempt_disable/enable_notrace().
Create rcu_read_(un)lock_sched_notrace().
Make sure the tracepoint probes are not traced by removing the -pg in makefiles.

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
CC: Andrew Morton <akpm@linux-foundation.org>
CC: Masami Hiramatsu <mhiramat@redhat.com>
CC: 'Peter Zijlstra' <peterz@infradead.org>
CC: "Frank Ch. Eigler" <fche@redhat.com>
CC: 'Ingo Molnar' <mingo@elte.hu>
CC: 'Hideo AOKI' <haoki@redhat.com>
CC: Takashi Nishiie <t-nishiie@np.css.fujitsu.com>
CC: 'Steven Rostedt' <rostedt@goodmis.org>
---
 include/linux/rcupdate.h   |    2 ++
 include/linux/tracepoint.h |    2 ++
 kernel/marker.c            |   16 +++++++++-------
 ltt/ltt-relay.c            |   16 +++++++++-------
 ltt/ltt-serialize.c        |   22 +++++++---------------
 ltt/ltt-timestamp.c        |    6 +++---
 ltt/ltt-tracer.c           |    4 ++--
 ltt/probes/Makefile        |    9 +++++++++
 8 files changed, 43 insertions(+), 34 deletions(-)

diff --git a/include/linux/rcupdate.h b/include/linux/rcupdate.h
index 0d67ebe..5ed8d57 100644
--- a/include/linux/rcupdate.h
+++ b/include/linux/rcupdate.h
@@ -142,6 +142,7 @@ struct rcu_head {
  * on the write-side to insure proper synchronization.
  */
 #define rcu_read_lock_sched() preempt_disable()
+#define rcu_read_lock_sched_notrace() preempt_disable_notrace()
 
 /*
  * rcu_read_unlock_sched - marks the end of a RCU-classic critical section
@@ -149,6 +150,7 @@ struct rcu_head {
  * See rcu_read_lock_sched for more information.
  */
 #define rcu_read_unlock_sched() preempt_enable()
+#define rcu_read_unlock_sched_notrace() preempt_enable_notrace()
 
 
 
diff --git a/include/linux/tracepoint.h b/include/linux/tracepoint.h
index eca7c91..b500341 100644
--- a/include/linux/tracepoint.h
+++ b/include/linux/tracepoint.h
@@ -42,6 +42,7 @@ struct tracepoint {
 		void **it_func;						\
 									\
 		preempt_disable();					\
+		rcu_read_lock_sched_notrace();				\
 		it_func = rcu_dereference((tp)->funcs);			\
 		if (it_func) {						\
 			do {						\
@@ -49,6 +50,7 @@ struct tracepoint {
 			} while (*(++it_func));				\
 		}							\
 		preempt_enable();				\
+		rcu_read_unlock_sched_notrace();			\
 	} while (0)
 
 #define __CHECK_TRACE(name, generic, proto, args)			\
diff --git a/kernel/marker.c b/kernel/marker.c
index 4966cc1..83ccfb2 100644
--- a/kernel/marker.c
+++ b/kernel/marker.c
@@ -93,7 +93,7 @@ static void marker_update_processes(void)
  * though the function pointer change and the marker enabling are two distinct
  * operations that modifies the execution flow of preemptible code.
  */
-void __mark_empty_function(void *probe_private, void *call_private,
+notrace void __mark_empty_function(void *probe_private, void *call_private,
 	const char *fmt, va_list *args)
 {
 }
@@ -109,7 +109,8 @@ EXPORT_SYMBOL_GPL(__mark_empty_function);
  * need to put a full smp_rmb() in this branch. This is why we do not use
  * rcu_dereference() for the pointer read.
  */
-void marker_probe_cb(const struct marker *mdata, void *call_private, ...)
+notrace void marker_probe_cb(const struct marker *mdata,
+		void *call_private, ...)
 {
 	va_list args;
 	char ptype;
@@ -119,7 +120,7 @@ void marker_probe_cb(const struct marker *mdata, void *call_private, ...)
 	 * sure the teardown of the callbacks can be done correctly when they
 	 * are in modules and they insure RCU read coherency.
 	 */
-	rcu_read_lock_sched();
+	rcu_read_lock_sched_notrace();
 	ptype = mdata->ptype;
 	if (likely(!ptype)) {
 		marker_probe_func *func;
@@ -157,7 +158,7 @@ void marker_probe_cb(const struct marker *mdata, void *call_private, ...)
 			va_end(args);
 		}
 	}
-	rcu_read_unlock_sched();
+	rcu_read_unlock_sched_notrace();
 }
 EXPORT_SYMBOL_GPL(marker_probe_cb);
 
@@ -169,12 +170,13 @@ EXPORT_SYMBOL_GPL(marker_probe_cb);
  *
  * Should be connected to markers "MARK_NOARGS".
  */
-void marker_probe_cb_noarg(const struct marker *mdata, void *call_private, ...)
+notrace void marker_probe_cb_noarg(const struct marker *mdata,
+		void *call_private, ...)
 {
 	va_list args;	/* not initialized */
 	char ptype;
 
-	rcu_read_lock_sched();
+	rcu_read_lock_sched_notrace();
 	ptype = mdata->ptype;
 	if (likely(!ptype)) {
 		marker_probe_func *func;
@@ -207,7 +209,7 @@ void marker_probe_cb_noarg(const struct marker *mdata, void *call_private, ...)
 			multi[i].func(multi[i].probe_private, call_private,
 				mdata->format, &args);
 	}
-	rcu_read_unlock_sched();
+	rcu_read_unlock_sched_notrace();
 }
 EXPORT_SYMBOL_GPL(marker_probe_cb_noarg);
 
diff --git a/ltt/ltt-relay.c b/ltt/ltt-relay.c
index 1b0b1ce..3319a59 100644
--- a/ltt/ltt-relay.c
+++ b/ltt/ltt-relay.c
@@ -106,7 +106,7 @@ static void ltt_buffer_begin_callback(struct rchan_buf *buf,
  * offset is assumed to never be 0 here : never deliver a completely empty
  * subbuffer. The lost size is between 0 and subbuf_size-1.
  */
-static void ltt_buffer_end_callback(struct rchan_buf *buf,
+static notrace void ltt_buffer_end_callback(struct rchan_buf *buf,
 		u64 tsc, unsigned int offset, unsigned int subbuf_idx)
 {
 	struct ltt_block_start_header *header =
@@ -120,7 +120,7 @@ static void ltt_buffer_end_callback(struct rchan_buf *buf,
 	header->end.freq = ltt_frequency();
 }
 
-static void ltt_deliver(struct rchan_buf *buf, unsigned subbuf_idx,
+static notrace void ltt_deliver(struct rchan_buf *buf, unsigned subbuf_idx,
 		void *subbuf)
 {
 	struct ltt_channel_struct *channel =
@@ -169,7 +169,7 @@ static int ltt_remove_buf_file_callback(struct dentry *dentry)
 /*
  * This function should not be called from NMI interrupt context
  */
-static void ltt_buf_unfull(struct rchan_buf *buf,
+static notrace void ltt_buf_unfull(struct rchan_buf *buf,
 		unsigned subbuf_idx,
 		long offset)
 {
@@ -711,7 +711,7 @@ static int ltt_relay_create_dirs(struct ltt_trace_struct *new_trace)
  * Must be called when no tracing is active in the channel, because of
  * accesses across CPUs.
  */
-static void ltt_relay_buffer_flush(struct rchan_buf *buf)
+static notrace void ltt_relay_buffer_flush(struct rchan_buf *buf)
 {
 	buf->finalized = 1;
 	ltt_force_switch(buf, FORCE_FLUSH);
@@ -1128,7 +1128,7 @@ static inline void ltt_reserve_end_switch_current(
  * 		event header.
  * It will take care of sub-buffer switching.
  */
-static ssize_t ltt_relay_reserve_slot(struct ltt_trace_struct *trace,
+static notrace ssize_t ltt_relay_reserve_slot(struct ltt_trace_struct *trace,
 		struct ltt_channel_struct *ltt_channel, void **transport_data,
 		size_t data_size, size_t *slot_size, u64 *tsc, int cpu)
 {
@@ -1194,7 +1194,8 @@ static ssize_t ltt_relay_reserve_slot(struct ltt_trace_struct *trace,
  * operations, this function must be called from the CPU which owns the buffer
  * for a ACTIVE flush.
  */
-static void ltt_force_switch(struct rchan_buf *buf, enum force_switch_mode mode)
+static notrace void ltt_force_switch(struct rchan_buf *buf,
+		enum force_switch_mode mode)
 {
 	struct ltt_channel_struct *ltt_channel =
 			(struct ltt_channel_struct *)buf->chan->private_data;
@@ -1248,7 +1249,8 @@ static void ltt_force_switch(struct rchan_buf *buf, enum force_switch_mode mode)
  * @reserved : address following the event header.
  * @slot_size : size of the reserved slot.
  */
-static void ltt_relay_commit_slot(struct ltt_channel_struct *ltt_channel,
+static notrace void ltt_relay_commit_slot(
+		struct ltt_channel_struct *ltt_channel,
 		void **transport_data, size_t reserved, size_t slot_size)
 {
 	struct rchan_buf *buf = *transport_data;
diff --git a/ltt/ltt-serialize.c b/ltt/ltt-serialize.c
index d9c99fa..f0e01bc 100644
--- a/ltt/ltt-serialize.c
+++ b/ltt/ltt-serialize.c
@@ -132,8 +132,6 @@ enum ltt_type {
  * %*.*:*v expects sizeof(*ptr), __alignof__(*ptr), elem_num, ptr
  *         where elem_num is the number of elements in the sequence
  */
-
-__attribute__((no_instrument_function))
 static inline const char *parse_trace_type(const char *fmt,
 		char *trace_size, enum ltt_type *trace_type,
 		unsigned long *attributes)
@@ -239,7 +237,6 @@ parse_end:
  * Field width and precision are *not* supported.
  * %n not supported.
  */
-__attribute__((no_instrument_function))
 static inline const char *parse_c_type(const char *fmt,
 		char *c_size, enum ltt_type *c_type)
 {
@@ -325,7 +322,6 @@ parse_end:
 	return fmt;
 }
 
-__attribute__((no_instrument_function))
 static inline size_t serialize_trace_data(struct rchan_buf *buf,
 		size_t buf_offset,
 		char trace_size, enum ltt_type trace_type,
@@ -474,8 +470,7 @@ copydone:
 	return buf_offset;
 }
 
-__attribute__((no_instrument_function))
-size_t ltt_serialize_data(struct rchan_buf *buf, size_t buf_offset,
+notrace size_t ltt_serialize_data(struct rchan_buf *buf, size_t buf_offset,
 			struct ltt_serialize_closure *closure,
 			void *serialize_private,
 			int align,
@@ -597,8 +592,7 @@ end:
  * Calculate data size
  * Assume that the padding for alignment starts at a sizeof(void *) address.
  */
-static __attribute__((no_instrument_function))
-size_t ltt_get_data_size(struct ltt_serialize_closure *closure,
+static notrace size_t ltt_get_data_size(struct ltt_serialize_closure *closure,
 				void *serialize_private,
 				int align,
 				const char *fmt, va_list *args)
@@ -609,7 +603,7 @@ size_t ltt_get_data_size(struct ltt_serialize_closure *closure,
 				fmt, args);
 }
 
-static __attribute__((no_instrument_function))
+static notrace
 void ltt_write_event_data(struct rchan_buf *buf, size_t buf_offset,
 				struct ltt_serialize_closure *closure,
 				void *serialize_private,
@@ -622,8 +616,7 @@ void ltt_write_event_data(struct rchan_buf *buf, size_t buf_offset,
 }
 
 
-__attribute__((no_instrument_function))
-void ltt_vtrace(void *probe_data, void *call_data,
+notrace void ltt_vtrace(void *probe_data, void *call_data,
 		const char *fmt, va_list *args)
 {
 	int align;
@@ -659,7 +652,7 @@ void ltt_vtrace(void *probe_data, void *call_data,
 		&& (!private_data || !private_data->force)))
 		return;
 
-	rcu_read_lock_sched();
+	rcu_read_lock_sched_notrace();
 	if (likely(!private_data || !private_data->force
 			|| private_data->cpu == -1))
 		cpu = smp_processor_id();
@@ -731,12 +724,11 @@ void ltt_vtrace(void *probe_data, void *call_data,
 				slot_size);
 	}
 	__get_cpu_var(ltt_nesting)--;
-	rcu_read_unlock_sched();
+	rcu_read_unlock_sched_notrace();
 }
 EXPORT_SYMBOL_GPL(ltt_vtrace);
 
-__attribute__((no_instrument_function))
-void ltt_trace(void *probe_data, void *call_data, const char *fmt, ...)
+notrace void ltt_trace(void *probe_data, void *call_data, const char *fmt, ...)
 {
 	va_list args;
 
diff --git a/ltt/ltt-timestamp.c b/ltt/ltt-timestamp.c
index 3dff03d..1b74fe1 100644
--- a/ltt/ltt-timestamp.c
+++ b/ltt/ltt-timestamp.c
@@ -96,14 +96,14 @@ static void ltt_update_synthetic_tsc(void)
 }
 
 /* Called from buffer switch : in _any_ context (even NMI) */
-u64 ltt_read_synthetic_tsc(void)
+u64 notrace ltt_read_synthetic_tsc(void)
 {
 	struct synthetic_tsc_struct *cpu_synth;
 	u64 ret;
 	unsigned int index;
 	u32 tsc;
 
-	preempt_disable();
+	preempt_disable_notrace();
 	cpu_synth = &synthetic_tsc[smp_processor_id()];
 	index = cpu_synth->index;		/* atomic read */
 	tsc = ltt_get_timestamp32();		/* Hardware clocksource read */
@@ -114,7 +114,7 @@ u64 ltt_read_synthetic_tsc(void)
 			+ (1ULL << HW_BITS);
 	else
 		ret = SW_MSB(cpu_synth->tsc[index].val) | (u64)tsc;
-	preempt_enable();
+	preempt_enable_notrace();
 	return ret;
 }
 EXPORT_SYMBOL_GPL(ltt_read_synthetic_tsc);
diff --git a/ltt/ltt-tracer.c b/ltt/ltt-tracer.c
index 3411d74..7594fc6 100644
--- a/ltt/ltt-tracer.c
+++ b/ltt/ltt-tracer.c
@@ -48,7 +48,7 @@ static void async_wakeup(unsigned long data);
 static DEFINE_TIMER(ltt_async_wakeup_timer, async_wakeup, 0, 0);
 
 /* Default callbacks for modules */
-int ltt_filter_control_default
+int notrace ltt_filter_control_default
 	(enum ltt_filter_control_msg msg, struct ltt_trace_struct *trace)
 {
 	return 0;
@@ -182,7 +182,7 @@ static inline int is_channel_overwrite(enum ltt_channels chan,
 }
 
 
-void ltt_write_trace_header(struct ltt_trace_struct *trace,
+void notrace ltt_write_trace_header(struct ltt_trace_struct *trace,
 		struct ltt_trace_header *header)
 {
 	header->magic_number = LTT_TRACER_MAGIC_NUMBER;
diff --git a/ltt/probes/Makefile b/ltt/probes/Makefile
index b721211..3e7694e 100644
--- a/ltt/probes/Makefile
+++ b/ltt/probes/Makefile
@@ -1,7 +1,16 @@
 # LTTng tracing probes
 
+ifdef CONFIG_FTRACE
+CFLAGS_REMOVE_kernel-trace.o = -pg
+CFLAGS_REMOVE_mm-trace.o = -pg
+CFLAGS_REMOVE_fs-trace.o = -pg
+CFLAGS_REMOVE_ipc-trace.o = -pg
+CFLAGS_REMOVE_lockdep-trace.o = -pg
+endif
+
 obj-$(CONFIG_LTT_TRACEPROBES)	+= kernel-trace.o mm-trace.o fs-trace.o \
 				ipc-trace.o lockdep-trace.o
 ifeq ($(CONFIG_NET),y)
+CFLAGS_REMOVE_net-trace.o = -pg
 obj-$(CONFIG_TRACEPROBES)	+= net-trace.o
 endif
-- 
1.5.5.1

