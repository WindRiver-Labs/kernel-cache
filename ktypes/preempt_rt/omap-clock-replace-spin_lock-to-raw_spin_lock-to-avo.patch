From 52826ccfa8bde8f56e7995878782ed782da14474 Mon Sep 17 00:00:00 2001
From: Hui Wang <Hui.Wang@windriver.com>
Date: Wed, 29 Dec 2010 16:51:38 +0800
Subject: [PATCH 3/4] omap clock: replace spin_lock to raw_spin_lock to avoid warnings

When we suspend and resume the whole system, the following warnings
will print out:
root@localhost:/root> echo mem > /sys/power/state
Freezing user space processes ... (elapsed 0.02 seconds) done.
Freezing remaining freezable tasks ... (elapsed 0.01 seconds) done.
Suspending console(s) (use no_console_suspend to debug)
Could not enter target state in pm_suspend
BUG: sleeping function called from invalid context at
/buildarea3/hwang4/work41/3530prt/build/linux/kernel/rtmutex.c:707
pcnt: 1 0 in_atomic(): 1, irqs_disabled(): 128, pid: 0, name: swapper
[<c003e7d4>] [<c04ad86c>] (rt_spin_lock+0x30/0x5c)
[<c04ad86c>] [<c004e1f0>] (clk_disable+0x20/0x78)
[<c004e1f0>] [<c004396c>] (omap_uart_prepare_idle+0x124/0x15c)
[<c004396c>] [<c00478c8>] (omap_sram_idle+0xbc/0x440)
[<c00478c8>] [<c00488b0>] (omap3_enter_idle+0xa4/0x134)
[<c00488b0>] [<c03d39f4>] (cpuidle_idle_call+0xa0/0x180)
[<c03d39f4>] [<c0039574>] (cpu_idle+0x48/0xa0)
[<c0039574>] [<c00089f8>] (start_kernel+0x29c/0x304)
[<c00089f8>] [<80008034>] (0x80008034)
Restarting tasks ...
done.

This is because the spin_lock is sleepable in the preempt_rt kernel,
but we call them in an atomic and irq_disabled context. To avoid this
issue, replace spin_lock with raw_spin_lock.

Signed-off-by: Hui Wang <Hui.Wang@windriver.com>
---
 arch/arm/plat-omap/clock.c |   34 +++++++++++++++++-----------------
 1 files changed, 17 insertions(+), 17 deletions(-)

diff --git a/arch/arm/plat-omap/clock.c b/arch/arm/plat-omap/clock.c
index 0af5402..2546695 100644
--- a/arch/arm/plat-omap/clock.c
+++ b/arch/arm/plat-omap/clock.c
@@ -28,7 +28,7 @@
 
 static LIST_HEAD(clocks);
 static DEFINE_MUTEX(clocks_mutex);
-static DEFINE_SPINLOCK(clockfw_lock);
+static DEFINE_RAW_SPINLOCK(clockfw_lock);
 
 static struct clk_functions *arch_clock;
 
@@ -44,10 +44,10 @@ int clk_enable(struct clk *clk)
 	if (clk == NULL || IS_ERR(clk))
 		return -EINVAL;
 
-	spin_lock_irqsave(&clockfw_lock, flags);
+	raw_spin_lock_irqsave(&clockfw_lock, flags);
 	if (arch_clock->clk_enable)
 		ret = arch_clock->clk_enable(clk);
-	spin_unlock_irqrestore(&clockfw_lock, flags);
+	raw_spin_unlock_irqrestore(&clockfw_lock, flags);
 
 	return ret;
 }
@@ -60,7 +60,7 @@ void clk_disable(struct clk *clk)
 	if (clk == NULL || IS_ERR(clk))
 		return;
 
-	spin_lock_irqsave(&clockfw_lock, flags);
+	raw_spin_lock_irqsave(&clockfw_lock, flags);
 	if (clk->usecount == 0) {
 		printk(KERN_ERR "Trying disable clock %s with 0 usecount\n",
 		       clk->name);
@@ -72,7 +72,7 @@ void clk_disable(struct clk *clk)
 		arch_clock->clk_disable(clk);
 
 out:
-	spin_unlock_irqrestore(&clockfw_lock, flags);
+	raw_spin_unlock_irqrestore(&clockfw_lock, flags);
 }
 EXPORT_SYMBOL(clk_disable);
 
@@ -101,10 +101,10 @@ long clk_round_rate(struct clk *clk, unsigned long rate)
 	if (clk == NULL || IS_ERR(clk))
 		return ret;
 
-	spin_lock_irqsave(&clockfw_lock, flags);
+	raw_spin_lock_irqsave(&clockfw_lock, flags);
 	if (arch_clock->clk_round_rate)
 		ret = arch_clock->clk_round_rate(clk, rate);
-	spin_unlock_irqrestore(&clockfw_lock, flags);
+	raw_spin_unlock_irqrestore(&clockfw_lock, flags);
 
 	return ret;
 }
@@ -118,7 +118,7 @@ int clk_set_rate(struct clk *clk, unsigned long rate)
 	if (clk == NULL || IS_ERR(clk))
 		return ret;
 
-	spin_lock_irqsave(&clockfw_lock, flags);
+	raw_spin_lock_irqsave(&clockfw_lock, flags);
 	if (arch_clock->clk_set_rate)
 		ret = arch_clock->clk_set_rate(clk, rate);
 	if (ret == 0) {
@@ -126,7 +126,7 @@ int clk_set_rate(struct clk *clk, unsigned long rate)
 			clk->rate = clk->recalc(clk);
 		propagate_rate(clk);
 	}
-	spin_unlock_irqrestore(&clockfw_lock, flags);
+	raw_spin_unlock_irqrestore(&clockfw_lock, flags);
 
 	return ret;
 }
@@ -143,7 +143,7 @@ int clk_set_parent(struct clk *clk, struct clk *parent)
 	if (clk == NULL || IS_ERR(clk) || parent == NULL || IS_ERR(parent))
 		return ret;
 
-	spin_lock_irqsave(&clockfw_lock, flags);
+	raw_spin_lock_irqsave(&clockfw_lock, flags);
 	if (clk->usecount == 0) {
 		if (arch_clock->clk_set_parent)
 			ret = arch_clock->clk_set_parent(clk, parent);
@@ -154,7 +154,7 @@ int clk_set_parent(struct clk *clk, struct clk *parent)
 		}
 	} else
 		ret = -EBUSY;
-	spin_unlock_irqrestore(&clockfw_lock, flags);
+	raw_spin_unlock_irqrestore(&clockfw_lock, flags);
 
 	return ret;
 }
@@ -369,20 +369,20 @@ void clk_init_cpufreq_table(struct cpufreq_frequency_table **table)
 {
 	unsigned long flags;
 
-	spin_lock_irqsave(&clockfw_lock, flags);
+	raw_spin_lock_irqsave(&clockfw_lock, flags);
 	if (arch_clock->clk_init_cpufreq_table)
 		arch_clock->clk_init_cpufreq_table(table);
-	spin_unlock_irqrestore(&clockfw_lock, flags);
+	raw_spin_unlock_irqrestore(&clockfw_lock, flags);
 }
 
 void clk_exit_cpufreq_table(struct cpufreq_frequency_table **table)
 {
 	unsigned long flags;
 
-	spin_lock_irqsave(&clockfw_lock, flags);
+	raw_spin_lock_irqsave(&clockfw_lock, flags);
 	if (arch_clock->clk_exit_cpufreq_table)
 		arch_clock->clk_exit_cpufreq_table(table);
-	spin_unlock_irqrestore(&clockfw_lock, flags);
+	raw_spin_unlock_irqrestore(&clockfw_lock, flags);
 }
 #endif
 
@@ -404,10 +404,10 @@ static int __init clk_disable_unused(void)
 		if (ck->usecount > 0 || ck->enable_reg == 0)
 			continue;
 
-		spin_lock_irqsave(&clockfw_lock, flags);
+		raw_spin_lock_irqsave(&clockfw_lock, flags);
 		if (arch_clock->clk_disable_unused)
 			arch_clock->clk_disable_unused(ck);
-		spin_unlock_irqrestore(&clockfw_lock, flags);
+		raw_spin_unlock_irqrestore(&clockfw_lock, flags);
 	}
 
 	return 0;
-- 
1.6.5.2

