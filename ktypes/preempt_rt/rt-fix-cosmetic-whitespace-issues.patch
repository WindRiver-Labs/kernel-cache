From e89e7dd3e17c6a671efe0581f18b63d9dd05036f Mon Sep 17 00:00:00 2001
From: Paul Gortmaker <paul.gortmaker@windriver.com>
Date: Sat, 19 Feb 2011 13:27:39 -0500
Subject: [PATCH] rt: fix cosmetic whitespace issues

Fix up some cosmetic whitespace issues that prevent clean
comparisons to the upstream RT branch.

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
---
 drivers/net/loopback.c              |    2 +-
 drivers/of/base.c                   |    3 +--
 include/linux/interrupt.h           |    2 +-
 include/linux/mm.h                  |    2 +-
 include/linux/percpu-defs.h         |    2 +-
 include/linux/rt_lock.h             |    1 -
 include/trace/events/latency_hist.h |    1 -
 kernel/fork.c                       |    7 +++----
 kernel/hrtimer.c                    |    1 -
 kernel/irq/manage.c                 |    2 +-
 kernel/perf_event.c                 |    2 +-
 kernel/sched.c                      |    6 +++---
 lib/rwsem-spinlock.c                |    2 +-
 mm/memcontrol.c                     |    4 ++--
 mm/page_alloc.c                     |    3 ++-
 net/ipv4/netfilter/ip_tables.c      |    2 +-
 net/ipv6/netfilter/ip6_tables.c     |    2 +-
 17 files changed, 20 insertions(+), 24 deletions(-)

diff --git a/drivers/net/loopback.c b/drivers/net/loopback.c
index 729261e..6ad108f 100644
--- a/drivers/net/loopback.c
+++ b/drivers/net/loopback.c
@@ -88,7 +88,7 @@ static netdev_tx_t loopback_xmit(struct sk_buff *skb,
 
 	skb->protocol = eth_type_trans(skb, dev);
 	len = skb->len;
-	res = netif_rx_ni(skb) ;
+	res = netif_rx_ni(skb);
 
 	pcpu_lstats = (void __percpu __force *)dev->ml_priv;
 	lb_stats = per_cpu_ptr(pcpu_lstats, xmit_get_cpu());
diff --git a/drivers/of/base.c b/drivers/of/base.c
index 28297ae..4e962a3 100644
--- a/drivers/of/base.c
+++ b/drivers/of/base.c
@@ -139,8 +139,7 @@ EXPORT_SYMBOL(of_node_put);
 #endif /* !CONFIG_SPARC */
 
 struct property *__of_find_property(const struct device_node *np,
-				  const char *name,
-				  int *lenp)
+					   const char *name, int *lenp)
 {
 	struct property *pp;
 
diff --git a/include/linux/interrupt.h b/include/linux/interrupt.h
index f2d29a8..76295bd 100644
--- a/include/linux/interrupt.h
+++ b/include/linux/interrupt.h
@@ -53,8 +53,8 @@
  *                Used by threaded interrupts which need to keep the
  *                irq line disabled until the threaded handler has been run.
  * IRQF_NO_SUSPEND - Do not disable this IRQ during suspend
- *
  * IRQF_NODELAY - Interrupt is not force threaded on -rt
+ *
  */
 #define IRQF_DISABLED		0x00000020
 #define IRQF_SAMPLE_RANDOM	0x00000040
diff --git a/include/linux/mm.h b/include/linux/mm.h
index cdb0a34..89b83bb 100644
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -6,8 +6,8 @@
 #ifdef __KERNEL__
 
 #include <linux/gfp.h>
-#include <linux/list.h>
 #include <linux/slab.h>
+#include <linux/list.h>
 #include <linux/mmzone.h>
 #include <linux/rbtree.h>
 #include <linux/prio_tree.h>
diff --git a/include/linux/percpu-defs.h b/include/linux/percpu-defs.h
index 5c01e34..bdc249b 100644
--- a/include/linux/percpu-defs.h
+++ b/include/linux/percpu-defs.h
@@ -91,7 +91,7 @@
 	DEFINE_PER_CPU_SECTION(type, name, "")
 
 /*
- * next two added for RT patch
+ * next three added for RT patch
  * (wonder if we need corresponding DECLARE_*'s?) (clrkwllms)
  */
 #define DEFINE_PER_CPU_SPINLOCK(name, sec)				\
diff --git a/include/linux/rt_lock.h b/include/linux/rt_lock.h
index 7dff59e4..07d98f5 100644
--- a/include/linux/rt_lock.h
+++ b/include/linux/rt_lock.h
@@ -181,4 +181,3 @@ static inline int preempt_rt(void) { return 0; }
 #endif /* CONFIG_PREEMPT_RT */
 
 #endif
-
diff --git a/include/trace/events/latency_hist.h b/include/trace/events/latency_hist.h
index d6b5d77..7f70794 100644
--- a/include/trace/events/latency_hist.h
+++ b/include/trace/events/latency_hist.h
@@ -27,4 +27,3 @@ static inline char *getaction(int action)
 }
 
 #endif /* _LATENCY_HIST_H */
-
diff --git a/kernel/fork.c b/kernel/fork.c
index e95adda..d20acf8 100644
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -1876,9 +1876,9 @@ static int desched_thread(void * __bind_cpu)
 		schedule();
 
 		/*
- 		 * This must be called from time to time on ia64, and is a
- 		 * no-op on other archs. Used to be in cpu_idle(), but with
- 		 * the new -rt semantics it can't stay there.
+		 * This must be called from time to time on ia64, and is a
+		 * no-op on other archs. Used to be in cpu_idle(), but with
+		 * the new -rt semantics it can't stay there.
 		 */
 		check_pgt_cache();
 
@@ -1943,4 +1943,3 @@ __init int spawn_desched_task(void)
 	register_cpu_notifier(&cpu_nfb);
 	return 0;
 }
-
diff --git a/kernel/hrtimer.c b/kernel/hrtimer.c
index f3ea6f9..9556345 100644
--- a/kernel/hrtimer.c
+++ b/kernel/hrtimer.c
@@ -1423,7 +1423,6 @@ static inline int hrtimer_rt_defer(struct hrtimer *timer) { return 0; }
 
 #endif
 
-
 #ifdef CONFIG_HIGH_RES_TIMERS
 
 static enum hrtimer_restart hrtimer_wakeup(struct hrtimer *timer);
diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0610ead..9d4c691 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -571,7 +571,7 @@ irq_wait_for_interrupt(struct irq_desc *desc, struct irqaction *action)
  * is marked MASKED.
  */
 static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc,
-				 struct irqaction *action)
+				struct irqaction *action)
 {
 again:
 	chip_bus_lock(irq, desc);
diff --git a/kernel/perf_event.c b/kernel/perf_event.c
index e093520..9502afd 100644
--- a/kernel/perf_event.c
+++ b/kernel/perf_event.c
@@ -4,7 +4,7 @@
  *  Copyright (C) 2008 Thomas Gleixner <tglx@linutronix.de>
  *  Copyright (C) 2008-2009 Red Hat, Inc., Ingo Molnar
  *  Copyright (C) 2008-2009 Red Hat, Inc., Peter Zijlstra <pzijlstr@redhat.com>
- *  Copyright  ï¿½  2009 Paul Mackerras, IBM Corp. <paulus@au1.ibm.com>
+ *  Copyright  ©  2009 Paul Mackerras, IBM Corp. <paulus@au1.ibm.com>
  *
  * For licensing details see kernel-base/COPYING
  */
diff --git a/kernel/sched.c b/kernel/sched.c
index 9a263a9..7c52333 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -1965,8 +1965,8 @@ static void dequeue_task(struct rq *rq, struct task_struct *p, int sleep)
 /*
  * activate_task - move a task to the runqueue.
  */
-static void activate_task(struct rq *rq, struct task_struct *p, int wakeup,
-	bool head)
+static void
+activate_task(struct rq *rq, struct task_struct *p, int wakeup, bool head)
 {
 	if (task_contributes_to_load(p))
 		rq->nr_uninterruptible--;
@@ -8236,7 +8236,7 @@ void __might_sleep(const char *file, int line, int preempt_offset)
 			file, line);
 	printk(KERN_ERR
 		"pcnt: %x %d in_atomic(): %d, irqs_disabled(): %d, pid: %d, name: %s\n",
-	       preempt_count(), preempt_offset,
+			preempt_count(), preempt_offset,
 			in_atomic(), irqs_disabled(),
 			current->pid, current->comm);
 
diff --git a/lib/rwsem-spinlock.c b/lib/rwsem-spinlock.c
index 902d7dd..0bd2892 100644
--- a/lib/rwsem-spinlock.c
+++ b/lib/rwsem-spinlock.c
@@ -150,7 +150,7 @@ void __sched __down_read(struct rw_anon_semaphore *sem)
 	if (sem->activity >= 0 && list_empty(&sem->wait_list)) {
 		/* granted */
 		sem->activity++;
-		raw_spin_unlock_irqrestore(&sem->wait_lock, flags );
+		raw_spin_unlock_irqrestore(&sem->wait_lock, flags);
 		goto out;
 	}
 
diff --git a/mm/memcontrol.c b/mm/memcontrol.c
index abd765e..af5ae1a 100644
--- a/mm/memcontrol.c
+++ b/mm/memcontrol.c
@@ -1369,7 +1369,7 @@ void mem_cgroup_update_file_mapped(struct page *page, int val)
 		goto done;
 
 	/*
-	 * Preemption is already disabled. We can use __this_cpu_xxx
+	 * Preemption is already disabled. We can use __this_cpu_xxx,
 	 * but that's not true for RT !
 	 */
 	preempt_disable();
@@ -1380,8 +1380,8 @@ void mem_cgroup_update_file_mapped(struct page *page, int val)
 		__this_cpu_dec(mem->stat->count[MEM_CGROUP_STAT_FILE_MAPPED]);
 		ClearPageCgroupFileMapped(pc);
 	}
-
 	preempt_enable();
+
 done:
 	unlock_page_cgroup(pc);
 }
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index b87a708..6b25fca 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -711,7 +711,7 @@ static void __free_pages_ok(struct page *page, unsigned int order)
 	count_vm_events(PGFREE, 1 << order);
 	unlock_cpu_pcp(flags, this_cpu);
 	free_one_page(page_zone(page), page, order,
-		      get_pageblock_migratetype(page));
+					get_pageblock_migratetype(page));
 }
 
 /*
@@ -1121,6 +1121,7 @@ static void drain_pages(unsigned int cpu)
 
 		__lock_cpu_pcp(&flags, cpu);
 		pset = per_cpu_ptr(zone->pageset, cpu);
+
 		if (!pset) {
 			unlock_cpu_pcp(flags, cpu);
 			WARN_ON(1);
diff --git a/net/ipv4/netfilter/ip_tables.c b/net/ipv4/netfilter/ip_tables.c
index 106fec6..5f6042e 100644
--- a/net/ipv4/netfilter/ip_tables.c
+++ b/net/ipv4/netfilter/ip_tables.c
@@ -920,7 +920,7 @@ get_counters(const struct xt_table_info *t,
 
 	i = 0;
 	xt_info_wrlock(curcpu);
-       xt_entry_foreach(iter, t->entries[curcpu], t->size) {
+	xt_entry_foreach(iter, t->entries[curcpu], t->size) {
 		SET_COUNTER(counters[i], iter->counters.bcnt,
 			    iter->counters.pcnt);
 		++i;
diff --git a/net/ipv6/netfilter/ip6_tables.c b/net/ipv6/netfilter/ip6_tables.c
index ab24f18..ff7ce7b 100644
--- a/net/ipv6/netfilter/ip6_tables.c
+++ b/net/ipv6/netfilter/ip6_tables.c
@@ -950,7 +950,7 @@ get_counters(const struct xt_table_info *t,
 
 	i = 0;
 	xt_info_wrlock(curcpu);
-        xt_entry_foreach(iter, t->entries[curcpu], t->size) {
+	xt_entry_foreach(iter, t->entries[curcpu], t->size) {
 		SET_COUNTER(counters[i], iter->counters.bcnt,
 			    iter->counters.pcnt);
 		++i;
-- 
1.7.4

