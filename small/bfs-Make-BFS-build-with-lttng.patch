From 05d59b472c4d1c4570b8c7f9a5fc44f170b04043 Mon Sep 17 00:00:00 2001
From: Yang Shi <yang.shi@windriver.com>
Date: Thu, 14 Jun 2012 10:41:10 -0700
Subject: [PATCH 02/14] bfs: Make BFS build with lttng

Fix lttng build failure with BFS.

Signed-off-by: Yang Shi <yang.shi@windriver.com>
---
 kernel/sched/bfs.c  |   57 +++++++++++++++++++++++++++++++++++++++++++++++++++
 ltt/ltt-statedump.c |    4 ++++
 2 files changed, 61 insertions(+)

diff --git a/kernel/sched/bfs.c b/kernel/sched/bfs.c
index d8faf6a..ac1fb72 100644
--- a/kernel/sched/bfs.c
+++ b/kernel/sched/bfs.c
@@ -7333,3 +7333,60 @@ unsigned long default_scale_smt_power(struct sched_domain *sd, int cpu)
 	return smt_gain;
 }
 #endif
+
+#ifdef CONFIG_LTT
+static DEFINE_MUTEX(kernel_trace_mutex);
+static int kernel_trace_refcount;
+
+/**
+ * clear_kernel_trace_flag_all_tasks - clears all TIF_KERNEL_TRACE thread flags.
+ *
+ * This function iterates on all threads in the system to clear their
+ * TIF_KERNEL_TRACE flag. Setting the TIF_KERNEL_TRACE flag with the
+ * tasklist_lock held in copy_process() makes sure that once we finish clearing
+ * the thread flags, all threads have their flags cleared.
+ */
+void clear_kernel_trace_flag_all_tasks(void)
+{
+	struct task_struct *p;
+	struct task_struct *t;
+
+	mutex_lock(&kernel_trace_mutex);
+	if (--kernel_trace_refcount)
+		goto end;
+	read_lock(&tasklist_lock);
+	do_each_thread(p, t) {
+		clear_tsk_thread_flag(t, TIF_KERNEL_TRACE);
+	} while_each_thread(p, t);
+	read_unlock(&tasklist_lock);
+end:
+	mutex_unlock(&kernel_trace_mutex);
+}
+EXPORT_SYMBOL_GPL(clear_kernel_trace_flag_all_tasks);
+
+/**
+ * set_kernel_trace_flag_all_tasks - sets all TIF_KERNEL_TRACE thread flags.
+ *
+ * This function iterates on all threads in the system to set their
+ * TIF_KERNEL_TRACE flag. Setting the TIF_KERNEL_TRACE flag with the
+ * tasklist_lock held in copy_process() makes sure that once we finish setting
+ * the thread flags, all threads have their flags set.
+ */
+void set_kernel_trace_flag_all_tasks(void)
+{
+	struct task_struct *p;
+	struct task_struct *t;
+
+	mutex_lock(&kernel_trace_mutex);
+	if (kernel_trace_refcount++)
+		goto end;
+	read_lock(&tasklist_lock);
+	do_each_thread(p, t) {
+		set_tsk_thread_flag(t, TIF_KERNEL_TRACE);
+	} while_each_thread(p, t);
+	read_unlock(&tasklist_lock);
+end:
+	mutex_unlock(&kernel_trace_mutex);
+}
+EXPORT_SYMBOL_GPL(set_kernel_trace_flag_all_tasks);
+#endif
diff --git a/ltt/ltt-statedump.c b/ltt/ltt-statedump.c
index 47a0232..96ef8d5 100644
--- a/ltt/ltt-statedump.c
+++ b/ltt/ltt-statedump.c
@@ -363,7 +363,11 @@ ltt_enumerate_process_states(struct ltt_probe_private_data *call_data)
 			status = LTTNG_DEAD;
 		else if (t->state == TASK_RUNNING) {
 			/* Is this a forked child that has not run yet? */
+#ifdef CONFIG_SCHED_BFS
+			if (list_empty(&t->run_list))
+#else
 			if (list_empty(&t->rt.run_list))
+#endif
 				status = LTTNG_WAIT_FORK;
 			else
 				/*
-- 
1.7.9.7

