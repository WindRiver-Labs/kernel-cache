From 867b0f6ae934b40ba6f78ec4411f5d108225be70 Mon Sep 17 00:00:00 2001
From: Wu Zhangjin <zhangjin.wu@windriver.com>
Date: Thu, 11 Aug 2011 14:59:20 +0800
Subject: [PATCH 7/7] ftrace/graph: MIPS: Trace function entry before updating index

[ Based on mainline commit 722b3c74695377d11d18a52f3da08114d37f3f37 ]

Currently the index to the ret_stack is updated and the real return address
is saved in the ret_stack. Then we call the trace function. The trace
function could decide that it doesn't want to trace this function
(ex. set_graph_function does not match) and it will return 0 which means
not to trace this call.

The normal function graph tracer has this code:

if (!(trace->depth || ftrace_graph_addr(trace->func)) ||
      ftrace_graph_ignore_irqs())
	return 0;

What this states is, if the trace depth (which is curr_ret_stack)
is zero (top of nested functions) then test if we want to trace this
function. If this function is not to be traced, then return  0 and
the rest of the function graph tracer logic will not trace this function.

The problem arises when an interrupt comes in after we updated the
curr_ret_stack. The next function that gets called will have a trace->depth
of 1. Which fools this trace code into thinking that we are in a nested
function, and that we should trace. This causes interrupts to be traced
when they should not be.

The solution is to trace the function first and then update the ret_stack.

Reported-by: zhiping zhong <xzhong86@163.com>
Reported-by: wu zhangjin <wuzhangjin@gmail.com>
Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
[ Apply for MIPS ]
Signed-off-by: Wu Zhangjin <zhangjin.wu@windriver.com>
---
 arch/mips/kernel/ftrace.c |   12 ++++++------
 1 files changed, 6 insertions(+), 6 deletions(-)

diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index 994826f..ed0f2d2 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -307,18 +307,18 @@ void prepare_ftrace_return(unsigned long *parent_ra_addr, unsigned long self_ra,
 
 	insns = in_kernel_space(self_ra) ? 2 : MCOUNT_OFFSET_INSNS + 1;
 	trace.func = self_ra - (MCOUNT_INSN_SIZE * insns);
+	trace.depth = current->curr_ret_stack + 1;
 
-	if (ftrace_push_return_trace(old_parent_ra, trace.func, &trace.depth, fp)
-	    == -EBUSY) {
+	/* Only trace if the calling function expects to */
+	if (!ftrace_graph_entry(&trace)) {
 		*parent_ra_addr = old_parent_ra;
 		return;
 	}
 
-	/* Only trace if the calling function expects to */
-	if (!ftrace_graph_entry(&trace)) {
-		current->curr_ret_stack--;
+	if (ftrace_push_return_trace(old_parent_ra, trace.func, &trace.depth, fp)
+		== -EBUSY)
 		*parent_ra_addr = old_parent_ra;
-	}
+
 	return;
 out:
 	ftrace_graph_stop();
-- 
1.7.0.2

