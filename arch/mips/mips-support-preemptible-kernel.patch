From 68feca2df43be3448b959f915e969d6ec49be5b2 Mon Sep 17 00:00:00 2001
From: Tiejun Chen <tiejun.chen@windriver.com>
Date: Mon, 12 Apr 2010 15:03:02 +0800
Subject: [PATCH 4/8] mips support preemptible kernel

Some warning message result from calling function, smp_processor_id(),
if enable preempt option. So we should do explicitly somewhere when running
preemptible kernel, especially for some cache operation.

Signed-off-by: Tiejun Chen <tiejun.chen@windriver.com>
diff --git a/arch/mips/kernel/proc.c b/arch/mips/kernel/proc.c
index 5542817..e0f6737 100644
--- a/arch/mips/kernel/proc.c
+++ b/arch/mips/kernel/proc.c
@@ -22,7 +22,7 @@ static int show_cpuinfo(struct seq_file *m, void *v)
 	unsigned int version = cpu_data[n].processor_id;
 	unsigned int fp_vers = cpu_data[n].fpu_id;
 	char fmt [64];
-	int i;
+	int cpu,i;
 
 #ifdef CONFIG_SMP
 	if (!cpu_online(n))
@@ -42,9 +42,11 @@ static int show_cpuinfo(struct seq_file *m, void *v)
 	seq_printf(m, "processor\t\t: %ld\n", n);
 	sprintf(fmt, "cpu model\t\t: %%s V%%d.%%d%s\n",
 		      cpu_data[n].options & MIPS_CPU_FPU ? "  FPU V%d.%d" : "");
-	seq_printf(m, fmt, __cpu_name[n],
+	cpu = get_cpu();
+	seq_printf(m, fmt, __cpu_name[cpu],
 		      (version >> 4) & 0x0f, version & 0x0f,
 		      (fp_vers >> 4) & 0x0f, fp_vers & 0x0f);
+	put_cpu();
 	seq_printf(m, "BogoMIPS\t\t: %u.%02u\n",
 		      cpu_data[n].udelay_val / (500000/HZ),
 		      (cpu_data[n].udelay_val / (5000/HZ)) % 100);
diff --git a/arch/mips/mm/c-r4k.c b/arch/mips/mm/c-r4k.c
index 5109be9..4e94f14 100644
--- a/arch/mips/mm/c-r4k.c
+++ b/arch/mips/mm/c-r4k.c
@@ -382,12 +382,12 @@ static inline int has_valid_asid(const struct mm_struct *mm)
 
 static void r4k__flush_cache_vmap(void)
 {
-	r4k_blast_dcache();
+	r4k_on_each_cpu((void *)r4k_blast_dcache, NULL);
 }
 
 static void r4k__flush_cache_vunmap(void)
 {
-	r4k_blast_dcache();
+	r4k_on_each_cpu((void *)r4k_blast_dcache, NULL);
 }
 
 static inline void local_r4k_flush_cache_range(void * args)
@@ -613,7 +613,7 @@ static void r4k_dma_cache_wback_inv(unsigned long addr, unsigned long size)
 	 * explicitly
 	 */
 	if (cpu_has_safe_index_cacheops && size >= dcache_size) {
-		r4k_blast_dcache();
+		r4k_on_each_cpu((void *)r4k_blast_dcache, NULL);
 	} else {
 		R4600_HIT_CACHEOP_WAR_IMPL;
 		blast_dcache_range(addr, addr + size);
@@ -653,7 +653,7 @@ static void r4k_dma_cache_inv(unsigned long addr, unsigned long size)
 	}
 
 	if (cpu_has_safe_index_cacheops && size >= dcache_size) {
-		r4k_blast_dcache();
+		r4k_on_each_cpu((void *)r4k_blast_dcache, NULL);
 	} else {
 		unsigned long lsize = cpu_dcache_line_size();
 		unsigned long almask = ~(lsize - 1);
