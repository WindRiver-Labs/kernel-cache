From ef5ed7d2d99c901d544a0ab122efc083bf7401f1 Mon Sep 17 00:00:00 2001
From: Tiejun Chen <tiejun.chen@windriver.com>
Date: Fri, 25 Nov 2011 10:37:15 +0800
Subject: [PATCH] powerpc/kretprobe: Fix missed preemptions

For preempt_rt kernel feature we always go here with preempt_count()
is 1. This is correct since we don't disable preempt again while
calling notify_xxx(). So the original preempt_enable_no_resched()
would check to generate a call trace afater preempt_count() is
decreased to 0 inside. This may  make kretprobe failed. So we have
to use preempt_enable() to avoid this scenario.

Signed-off-by: Tiejun Chen <tiejun.chen@windriver.com>
---
 arch/powerpc/kernel/kprobes.c |   11 +++++++++++
 1 files changed, 11 insertions(+), 0 deletions(-)

diff --git a/arch/powerpc/kernel/kprobes.c b/arch/powerpc/kernel/kprobes.c
index 6b884d9..c250239 100644
--- a/arch/powerpc/kernel/kprobes.c
+++ b/arch/powerpc/kernel/kprobes.c
@@ -353,7 +353,18 @@ static int __kprobes trampoline_probe_handler(struct kprobe *p,
 
 	reset_current_kprobe();
 	kretprobe_hash_unlock(current, &flags);
+#ifdef CONFIG_PREEMPT_RT
+	/*
+	 * For preempt_rt kernel feature we always go here with preempt_count()
+	 * is 1. So the original preempt_enable_no_resched() would check to
+	 * generate a call trace afater preempt_count() is decreased to 0 inside.
+	 * This will make kretprobe failed. So we have to use preempt_enable()
+	 * to avoid this scenario.
+	 */
+	preempt_enable();
+#else
 	preempt_enable_no_resched();
+#endif
 
 	hlist_for_each_entry_safe(ri, node, tmp, &empty_rp, hlist) {
 		hlist_del(&ri->hlist);
-- 
1.7.0.4

