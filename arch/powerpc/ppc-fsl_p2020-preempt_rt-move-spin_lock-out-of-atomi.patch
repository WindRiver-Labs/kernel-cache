From a078d42ec9a1e83fca6e2dbf741661f36f67575c Mon Sep 17 00:00:00 2001
From: Tiejun Chen <tiejun.chen@windriver.com>
Date: Tue, 23 Nov 2010 11:15:53 +0800
Subject: [PATCH 2/3] ppc/fsl_p2020-preempt_rt: move spin_lock out of atomic condition

When run preempt_rt the following call trace is issued.
------
BUG: sleeping function called from invalid context at
/buildarea/tchen0/workplace/fsl_p2020-bsp/build/linux/kernel/rtmutex.c:707
pcnt: 1 0 in_atomic(): 1, irqs_disabled(): 0, pid: 30720, name: aio01
Call Trace:
[ee909e00] [c0008284] show_stack+0x44/0x160 (unreliable)
[ee909e30] [c0035c9c] __might_sleep+0xe4/0x108
[ee909e40] [c048e06c] rt_spin_lock+0x38/0xb4
[ee909e50] [c014035c] aio_read_evt+0x54/0x12c
[ee909e80] [c01417c4] sys_io_getevents+0x104/0x49c
[ee909f40] [c001169c] ret_from_syscall+0x0/0x4

To do track this as the follows:
------
read_events() <-- sys_io_getevents
        |
        + aio_read_evt()
          {
                ......
                kmap_atomic();
                spin_lock(&info->ring_lock);
                ......
                spin_unlock(&info->ring_lock);
          }

And under preempt_rt, spin_lock
                        |
                        + rt_spin_lock
                                |
                                + rt_spin_lock_fastlock()
                                  {
                                        if (likely(!current->in_printk))
                                                might_sleep();
                                  }

So after kmap_atomic(), might_sleep() is called with (in_atomic() = 1).

Here its safe to move spin_lock/spinc_unlock out of
kmap_atomic()/kunmap_atomic() with #ifdef CONFIG_PREEMPT_RT.

Signed-off-by: Tiejun Chen <tiejun.chen@windriver.com>
---
 fs/aio.c |   11 +++++++++++
 1 files changed, 11 insertions(+), 0 deletions(-)

diff --git a/fs/aio.c b/fs/aio.c
index 7eb6f2e..b6c4169 100644
--- a/fs/aio.c
+++ b/fs/aio.c
@@ -1016,6 +1016,10 @@ static int aio_read_evt(struct kioctx *ioctx, struct io_event *ent)
 	unsigned long head;
 	int ret = 0;
 
+#ifdef CONFIG_PREEMPT_RT
+	spin_lock(&info->ring_lock);
+#endif
+
 	ring = kmap_atomic(info->ring_pages[0], KM_USER0);
 	dprintk("in aio_read_evt h%lu t%lu m%lu\n",
 		 (unsigned long)ring->head, (unsigned long)ring->tail,
@@ -1024,7 +1028,9 @@ static int aio_read_evt(struct kioctx *ioctx, struct io_event *ent)
 	if (ring->head == ring->tail)
 		goto out;
 
+#ifndef CONFIG_PREEMPT_RT
 	spin_lock(&info->ring_lock);
+#endif
 
 	head = ring->head % info->nr;
 	if (head != ring->tail) {
@@ -1036,10 +1042,15 @@ static int aio_read_evt(struct kioctx *ioctx, struct io_event *ent)
 		ret = 1;
 		put_aio_ring_event(evp, KM_USER1);
 	}
+#ifndef CONFIG_PREEMPT_RT
 	spin_unlock(&info->ring_lock);
+#endif
 
 out:
 	kunmap_atomic(ring, KM_USER0);
+#ifdef CONFIG_PREEMPT_RT
+	spin_unlock(&info->ring_lock);
+#endif
 	dprintk("leaving aio_read_evt: %d  h%lu t%lu\n", ret,
 		 (unsigned long)ring->head, (unsigned long)ring->tail);
 	return ret;
-- 
1.6.5.2

