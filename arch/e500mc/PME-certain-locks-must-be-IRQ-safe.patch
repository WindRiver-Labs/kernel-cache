From 87a03cd87ee647f7451e0ef9c3724db478bbaadf Mon Sep 17 00:00:00 2001
From: Weiwei Wang <weiwei.wang@windriver.com>
Date: Thu, 30 Jun 2011 10:45:32 +0800
Subject: [PATCH 229/233] PME: certain locks must be IRQ-safe

Fix a lockdep error incured by enabling CONFIG_PROVE_LOCKING

In hard-irq context, spin_lock/unlock_irq can't be used, must
use spin_lock_irqsave/spin_unlock_irqrestore to keep lock state
consistent.

Signed-off-by: Andrew Liu <shengping.liu@windriver.com>
[rebase it onto QorIQ-DPAA-SDK-V1-20110609-systembuilder.iso]
Integrated-by: Weiwei Wang <weiwei.wang@windriver.com>
---
 drivers/staging/fsl_pme2/pme2_high.c |   11 +++++++----
 1 files changed, 7 insertions(+), 4 deletions(-)

diff --git a/drivers/staging/fsl_pme2/pme2_high.c b/drivers/staging/fsl_pme2/pme2_high.c
index 8a38a93..f05f87d 100644
--- a/drivers/staging/fsl_pme2/pme2_high.c
+++ b/drivers/staging/fsl_pme2/pme2_high.c
@@ -500,7 +500,9 @@ static inline void release_exclusive(__maybe_unused struct pme_ctx *ctx)
 static int __try_exclusive(struct pme_ctx *ctx)
 {
 	int ret = 0;
-	spin_lock_irq(&exclusive_lock);
+	unsigned long flags;
+
+	spin_lock_irqsave(&exclusive_lock, flags);
 	if (exclusive_refs) {
 		/* exclusivity already held, continue if we're the owner */
 		if (exclusive_ctx != ctx)
@@ -513,7 +515,7 @@ static int __try_exclusive(struct pme_ctx *ctx)
 	}
 	if (!ret)
 		exclusive_refs++;
-	spin_unlock_irq(&exclusive_lock);
+	spin_unlock_irqrestore(&exclusive_lock, flags);
 	return ret;
 }
 /* Use this macro as the wait expression because we don't want to continue
@@ -777,6 +779,7 @@ static inline struct pme_ctx_token *pop_matching_token(struct pme_ctx *ctx,
 {
 	struct pme_ctx_token *token;
 	const struct qm_fd *t_fd;
+	unsigned long flags;
 
 	/* The fast-path case is that the for() loop actually degenerates into;
 	 *     token = list_first_entry();
@@ -785,7 +788,7 @@ static inline struct pme_ctx_token *pop_matching_token(struct pme_ctx *ctx,
 	 * The penalty of the slow-path case is the for() loop plus the fact
 	 * we're optimising for a "likely" match first time, which might hurt
 	 * when that assumption is wrong a few times in succession. */
-	spin_lock(&ctx->lock);
+	spin_lock_irqsave(&ctx->lock, flags);
 	list_for_each_entry(token, &ctx->tokens, node) {
 		t_fd = (const struct qm_fd *)&token->blob[0];
 		if (likely(MATCH(t_fd, fd))) {
@@ -797,7 +800,7 @@ static inline struct pme_ctx_token *pop_matching_token(struct pme_ctx *ctx,
 	pr_err("PME2 Could not find matching token!\n");
 	BUG();
 found:
-	spin_unlock(&ctx->lock);
+	spin_unlock_irqrestore(&ctx->lock, flags);
 	return token;
 }
 
-- 
1.7.0.4

