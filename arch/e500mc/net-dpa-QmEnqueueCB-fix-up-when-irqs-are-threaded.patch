From 555c11514ec3ced695cb7947e2c3acf96f725dc4 Mon Sep 17 00:00:00 2001
From: Weiwei Wang <weiwei.wang@windriver.com>
Date: Fri, 1 Jul 2011 14:28:15 +0800
Subject: [PATCH 224/233] net/dpa: QmEnqueueCB fix up when irqs are threaded

backport from wrlinux-4.1

When Q/B man irqs are threaded, actually QmEnqueueCB cannot relax CPU with
udelay() which is one busy-waiting, and cpu_realx which is really implemented
only as a barrier. So the apropriate interrupt route may not be waked up to
handle QmEnqueue then sync their flag since the irqs already threaded.

So here create one work queue to make QmEnqueueCB can sleep after its QmEnqueue.
Then the interrupt route can have a chance to be scheduled to do with QmEnqueue.

Signed-off-by: Tiejun Chen <tiejun.chen@windriver.com>
[rebase it onto QorIQ-DPAA-SDK-V1-20110609-systembuilder.iso]
Integrated-by: Weiwei Wang <weiwei.wang@windriver.com>
---
 .../src/wrappers/Peripherals/FM/lnxwrp_fm.c        |   28 +++++++++++++++++++-
 1 files changed, 27 insertions(+), 1 deletions(-)

diff --git a/drivers/net/dpa/NetCommSw/src/wrappers/Peripherals/FM/lnxwrp_fm.c b/drivers/net/dpa/NetCommSw/src/wrappers/Peripherals/FM/lnxwrp_fm.c
index dc9f6fc..48a4923 100644
--- a/drivers/net/dpa/NetCommSw/src/wrappers/Peripherals/FM/lnxwrp_fm.c
+++ b/drivers/net/dpa/NetCommSw/src/wrappers/Peripherals/FM/lnxwrp_fm.c
@@ -950,7 +950,16 @@ static irqreturn_t fm_err_irq(int irq, void *_dev)
     return IRQ_NONE;
 }
 
+#if defined(CONFIG_PREEMPT_HARDIRQS) || defined(CONFIG_PREEMPT_SOFTIRQS)
+enum {
+	HC_FRMRCV_COMPLETE,
+	HC_FRMRCV_READY,
+};
+static volatile int hcFrmRcv = HC_FRMRCV_READY;
+static DECLARE_WAIT_QUEUE_HEAD(wq);
+#else
 static volatile int   hcFrmRcv = 0;
+#endif
 static spinlock_t     lock;
 /* used to protect FMD/LLD from concurent calls in functions fm_mutex_lock / fm_mutex_unlock */
 static struct mutex   lnxwrp_mutex;
@@ -964,7 +973,12 @@ static enum qman_cb_dqrr_result qm_tx_conf_dqrr_cb(struct qman_portal          *
 
     FM_PCD_HcTxConf(p_LnxWrpFmDev->h_PcdDev, (t_DpaaFD *)&dq->fd);
     spin_lock_irqsave(&lock, flags);
+#if defined(CONFIG_PREEMPT_HARDIRQS) || defined(CONFIG_PREEMPT_SOFTIRQS)
+	hcFrmRcv = HC_FRMRCV_COMPLETE;
+	wake_up_interruptible(&wq);
+#else
     hcFrmRcv--;
+#endif
     spin_unlock_irqrestore(&lock, flags);
 
     return qman_cb_dqrr_consume;
@@ -1044,19 +1058,30 @@ static struct qman_fq * FqAlloc(t_LnxWrpFmDev   *p_LnxWrpFmDev,
 static t_Error QmEnqueueCB (t_Handle h_Arg, void *p_Fd)
 {
     t_LnxWrpFmDev   *p_LnxWrpFmDev = (t_LnxWrpFmDev*)h_Arg;
-    int             _errno, timeout=1000000;
     unsigned long flags;
+    int             _errno;
+#if !defined(CONFIG_PREEMPT_HARDIRQS) && !defined(CONFIG_PREEMPT_SOFTIRQS)
+    int             timeout=1000000;
+#endif
 
     ASSERT_COND(p_LnxWrpFmDev);
 
     spin_lock_irqsave(&lock, flags);
+#if defined(CONFIG_PREEMPT_HARDIRQS) || defined(CONFIG_PREEMPT_SOFTIRQS)
+    hcFrmRcv=HC_FRMRCV_READY;
+#else
     hcFrmRcv++;
+#endif
     spin_unlock_irqrestore(&lock, flags);
 //MemDisp((uint8_t*)p_Fd,sizeof(t_DpaaFD));
     _errno = qman_enqueue(p_LnxWrpFmDev->hc_tx_fq, (struct qm_fd*)p_Fd, 0);
     if (_errno)
         RETURN_ERROR(MINOR, E_INVALID_STATE, ("qman_enqueue() failed"));
 
+#if defined(CONFIG_PREEMPT_HARDIRQS) || defined(CONFIG_PREEMPT_SOFTIRQS)
+	wait_event_interruptible_timeout(wq, hcFrmRcv == HC_FRMRCV_COMPLETE,
+			msecs_to_jiffies(250));
+#else
     while (hcFrmRcv && --timeout)
     {
         udelay(1);
@@ -1068,6 +1093,7 @@ static t_Error QmEnqueueCB (t_Handle h_Arg, void *p_Fd)
         RETURN_ERROR(MINOR, E_WRITE_FAILED, ("timeout waiting for Tx confirmation"));
         return E_WRITE_FAILED;
     }
+#endif
 
     return E_OK;
 }
-- 
1.7.0.4

