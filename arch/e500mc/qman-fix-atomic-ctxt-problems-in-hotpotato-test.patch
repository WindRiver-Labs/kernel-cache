From 0bc9365a638fe229cf4a6fddd66648be40cc07d5 Mon Sep 17 00:00:00 2001
From: Andrew Liu <shengping.liu@windriver.com>
Date: Tue, 3 Aug 2010 15:46:46 +0800
Subject: [PATCH 166/252] qman: fix atomic-ctxt problems in hotpotato test.

It is from FSL vendor SDK 2.x.

The problems were two-fold, we were using on_each_cpu() which
runs functions using doorbell interupts, and we were using
get_cpu_var()/put_cpu_var() around all the code. The latter
is not necessary because the code is already running core-affine,
 and the former is replaced with a home-brewed mechanism.

Signed-off-by: Geoff Thorpe <Geoff.Thorpe@freescale.com>
Integrated-by: Andrew Liu <shengping.liu@windriver.com>
---
 drivers/hwqueue/qman_test_hotpotato.c |   61 ++++++++++++++++++++++++++++----
 1 files changed, 53 insertions(+), 8 deletions(-)

diff --git a/drivers/hwqueue/qman_test_hotpotato.c b/drivers/hwqueue/qman_test_hotpotato.c
index 874bdfc..205b57f 100644
--- a/drivers/hwqueue/qman_test_hotpotato.c
+++ b/drivers/hwqueue/qman_test_hotpotato.c
@@ -1,4 +1,4 @@
-/* Copyright (c) 2009, Freescale Semiconductor, Inc.
+/* Copyright (c) 2009-2010, Freescale Semiconductor, Inc.
  * All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -79,6 +79,49 @@
  *    initialisation targets the correct cpu.
  */
 
+/* helper to run something on all cpus (can't use on_each_cpu(), as that invokes
+ * the fn from irq context, which is too restrictive). */
+struct bstrap {
+	void (*fn)(void);
+	atomic_t started;
+};
+static int bstrap_fn(void *__bstrap)
+{
+	struct bstrap *bstrap = __bstrap;
+	atomic_inc(&bstrap->started);
+	bstrap->fn();
+	while (!kthread_should_stop())
+		msleep(1);
+	return 0;
+}
+static int on_all_cpus(void (*fn)(void))
+{
+	int cpu;
+	for_each_online_cpu(cpu) {
+		struct bstrap bstrap = {
+			.fn = fn,
+			.started = ATOMIC_INIT(0)
+		};
+		struct task_struct *k = kthread_create(bstrap_fn, &bstrap,
+			"hotpotato%d", cpu);
+		int ret;
+		if (IS_ERR(k))
+			return -ENOMEM;
+		kthread_bind(k, cpu);
+		wake_up_process(k);
+		/* If we call kthread_stop() before the "wake up" has had an
+		 * effect, then the thread may exit with -EINTR without ever
+		 * running the function. So poll until it's started before
+		 * requesting it to stop. */
+		while (!atomic_read(&bstrap.started))
+			msleep(10);
+		ret = kthread_stop(k);
+		if (ret)
+			return ret;
+	}
+	return 0;
+}
+
 struct hp_handler {
 
 	/* The following data is stashed when 'rx' is dequeued; */
@@ -226,11 +269,13 @@ static enum qman_cb_dqrr_result special_dqrr(struct qman_portal *portal,
 	return qman_cb_dqrr_consume;
 }
 
-static void create_per_cpu_handlers(void *ignore)
+static void create_per_cpu_handlers(void)
 {
 	struct hp_handler *handler;
-	struct hp_cpu *p = &get_cpu_var(hp_cpu);
 	int loop;
+	struct hp_cpu *p = &get_cpu_var(hp_cpu);
+	/* release atomicity (so alloc is ok), we're run core-affine anyway */
+	put_cpu_var(hp_cpu);
 
 	p->processor_id = smp_processor_id();
 	spin_lock(&hp_lock);
@@ -247,13 +292,13 @@ static void create_per_cpu_handlers(void *ignore)
 		handler->frame_ptr = frame_ptr;
 		list_add_tail(&handler->node, &p->handlers);
 	}
-	put_cpu_var(hp_cpu);
 }
 
-static void destroy_per_cpu_handlers(void *ignore)
+static void destroy_per_cpu_handlers(void)
 {
 	struct list_head *loop, *tmp;
 	struct hp_cpu *p = &get_cpu_var(hp_cpu);
+	put_cpu_var(hp_cpu);
 
 	spin_lock(&hp_lock);
 	list_del(&p->node);
@@ -273,7 +318,7 @@ static void destroy_per_cpu_handlers(void *ignore)
 		list_del(&handler->node);
 		kmem_cache_free(hp_handler_slab, handler);
 	}
-	put_cpu_var(hp_cpu);
+
 }
 
 static inline u8 num_cachelines(u32 offset)
@@ -428,7 +473,7 @@ void qman_test_hotpotato(void)
 
 	/* Init phase 1 */
 	pr_info("Creating %d handlers per cpu...\n", HP_PER_CPU);
-	if (on_each_cpu(create_per_cpu_handlers, NULL, 1))
+	if (on_all_cpus(create_per_cpu_handlers))
 		panic("on_each_cpu() failed");
 	pr_info("Number of cpus: %d, total of %d handlers\n",
 		hp_cpu_list_length, hp_cpu_list_length * HP_PER_CPU);
@@ -447,7 +492,7 @@ void qman_test_hotpotato(void)
 
 	wait_event(queue, loop_counter == HP_LOOPS);
 	deallocate_frame_data();
-	if (on_each_cpu(destroy_per_cpu_handlers, NULL, 1))
+	if (on_all_cpus(destroy_per_cpu_handlers))
 		panic("on_each_cpu() failed");
 	kmem_cache_destroy(hp_handler_slab);
 	pr_info("qman_test_hotpotato finished\n");
-- 
1.6.5.2

