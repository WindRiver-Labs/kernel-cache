From cdbf32ef22b59c8813d5f40bc8176fcd71732d26 Mon Sep 17 00:00:00 2001
From: Emil Medve <Emilian.Medve@freescale.com>
Date: Tue, 13 Oct 2009 14:31:51 -0500
Subject: [PATCH 046/252] P4080/DPA: Prepare to remove the back pointer to the net_device from the private data

This prepares a fix to a SMP driver issue

Signed-off-by: Emil Medve <Emilian.Medve@Freescale.com>
[Applied FSL SDK 2.0.3 patch
"kernel-2.6.30-P4080-DPA-Prepare-to-remove-the-back-pointer.patch"]
Integrated-by: Yuri Nedel <Yuri.Nedel@windriver.com>
---
 drivers/net/dpa/dpa.c |   33 ++++++++++++++++-----------------
 1 files changed, 16 insertions(+), 17 deletions(-)

diff --git a/drivers/net/dpa/dpa.c b/drivers/net/dpa/dpa.c
index d58ee0f..7bc7eb7 100644
--- a/drivers/net/dpa/dpa.c
+++ b/drivers/net/dpa/dpa.c
@@ -172,8 +172,8 @@ static void dpa_hash_page(struct dpa_bp *bp, struct page *page, dma_addr_t base)
 	BUG();
 }
 
-static void bmb_free(const struct dpa_priv_s *priv, struct dpa_bp *bp,
-		struct bm_buffer *bmb)
+static void bmb_free(const struct net_device *net_dev,
+		     struct dpa_bp *bp, struct bm_buffer *bmb)
 {
 	int i;
 	/*
@@ -198,19 +198,18 @@ static void bmb_free(const struct dpa_priv_s *priv, struct dpa_bp *bp,
 
 		spin_unlock_irqrestore(&bp->lock, flags);
 
-		dma_unmap_page(priv->net_dev->dev.parent, bmb[i].lo,
+		dma_unmap_page(net_dev->dev.parent, bmb[i].lo,
 				bp->size, DMA_FROM_DEVICE);
 
 		put_page(page);
 	}
 }
 
-static void dpa_bp_refill(const struct dpa_priv_s *priv, struct dpa_bp *bp,
+static void dpa_bp_refill(const struct net_device *net_dev, struct dpa_bp *bp,
 			gfp_t mask)
 {
 	struct bm_buffer bmb[8];
 	int err;
-	struct net_device *dev = priv->net_dev;
 	unsigned int blocks;
 	unsigned int blocks_per_page = bp->bp_blocks_per_page;
 	unsigned int block_size = bp->size;
@@ -243,7 +242,7 @@ static void dpa_bp_refill(const struct dpa_priv_s *priv, struct dpa_bp *bp,
 						&compound_head(page)->_count);
 		}
 
-		addr = dma_map_page(dev->dev.parent, page, off, block_size,
+		addr = dma_map_page(net_dev->dev.parent, page, off, block_size,
 					DMA_FROM_DEVICE);
 
 		spin_lock_irqsave(&bp->lock, flags);
@@ -265,7 +264,7 @@ static void dpa_bp_refill(const struct dpa_priv_s *priv, struct dpa_bp *bp,
 						BMAN_RELEASE_FLAG_WAIT_INT);
 
 			if (err < 0) {
-				bmb_free(priv, bp, bmb);
+				bmb_free(net_dev, bp, bmb);
 				return;
 			}
 		}
@@ -281,7 +280,7 @@ static void dpa_bp_refill(const struct dpa_priv_s *priv, struct dpa_bp *bp,
 
 			for (j = i % 8; j < 8; j++)
 				bmb[j].lo = 0;
-			bmb_free(priv, bp, bmb);
+			bmb_free(net_dev, bp, bmb);
 			return;
 		}
 	}
@@ -300,12 +299,11 @@ static void __cold dpa_bp_depletion(struct bman_portal	*portal,
 }
 
 static int __devinit __must_check __cold __attribute__((nonnull))
-_dpa_bp_alloc(struct net_device *dev, struct list_head *list,
+_dpa_bp_alloc(struct net_device *net_dev, struct list_head *list,
 		struct dpa_bp *dpa_bp)
 {
 	int			 _errno;
 	struct bman_pool_params	 bp_params;
-	struct dpa_priv_s *priv = netdev_priv(dev);
 
 	BUG_ON(dpa_bp->size == 0);
 	BUG_ON(dpa_bp->count == 0);
@@ -321,7 +319,7 @@ _dpa_bp_alloc(struct net_device *dev, struct list_head *list,
 
 	dpa_bp->pool = bman_new_pool(&bp_params);
 	if (unlikely(dpa_bp->pool == NULL)) {
-		cpu_dev_err(dev->dev.parent,
+		cpu_dev_err(net_dev->dev.parent,
 				"%s:%hu:%s(): bman_new_pool() failed\n",
 				__file__, __LINE__, __func__);
 		_errno = -ENOMEM;
@@ -345,18 +343,19 @@ _dpa_bp_alloc(struct net_device *dev, struct list_head *list,
 		dpa_bp->kernel_pool = 1;
 
 		spin_lock_init(&dpa_bp->lock);
-		dpa_bp_refill(priv, dpa_bp, GFP_KERNEL);
+		dpa_bp_refill(net_dev, dpa_bp, GFP_KERNEL);
 	} else {
 		/* This is a shared pool, which the kernel doesn't manage */
 		dpa_bp->kernel_pool = 0;
-		devm_request_mem_region(dev->dev.parent, dpa_bp->paddr,
+		devm_request_mem_region(net_dev->dev.parent, dpa_bp->paddr,
 					dpa_bp->size * dpa_bp->count,
 					KBUILD_MODNAME);
-		dpa_bp->vaddr = devm_ioremap_prot(dev->dev.parent,
+		dpa_bp->vaddr = devm_ioremap_prot(net_dev->dev.parent,
 					dpa_bp->paddr,
-					dpa_bp->size * dpa_bp->count, 0);
+						  dpa_bp->size * dpa_bp->count,
+						  0);
 		if (unlikely(dpa_bp->vaddr == NULL)) {
-			cpu_dev_err(dev->dev.parent,
+			cpu_dev_err(net_dev->dev.parent,
 					"%s:%hu:%s(): devm_ioremap() failed\n",
 					__file__, __LINE__, __func__);
 			_errno = -EIO;
@@ -1527,7 +1526,7 @@ static void __hot dpa_rx(struct work_struct *fd_work)
 
 #ifdef CONFIG_DPA_RX_0_COPY
 		if (dpa_bp->bp_refill_pending > dpa_bp->bp_kick_thresh)
-			dpa_bp_refill(priv, dpa_bp, GFP_KERNEL);
+			dpa_bp_refill(net_dev, dpa_bp, GFP_KERNEL);
 #endif
 
 		goto _continue;
-- 
1.6.5.2

