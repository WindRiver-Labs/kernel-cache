From 99e2ec6f1fbe62cec21fb8abf2a8de423afeb8c7 Mon Sep 17 00:00:00 2001
From: Weiwei Wang <weiwei.wang@windriver.com>
Date: Fri, 1 Jul 2011 11:55:59 +0800
Subject: [PATCH 195/233] net/dpa: fix smp_processor_id warning

When CONFIG_PREEMPT is enabled, call trace below is reported:
BUG: using smp_processor_id() in preemptible [00000000] code: swapper/1
caller is dpa_select_queue+0x10/0x24
Call Trace:
[ebca9580] [c0007c8c] show_stack+0x44/0x160 (unreliable)
[ebca95b0] [c0376938] debug_smp_processor_id+0xe0/0xf0
[ebca95d0] [c049b12c] dpa_select_queue+0x10/0x24
[ebca95e0] [c056d6f0] dev_pick_tx+0x88/0x130
[ebca9600] [c056e388] dev_queue_xmit+0x1d0/0x550
[ebca9630] [c0577934] neigh_resolve_output+0x108/0x36c
[ebca9670] [c059edc0] ip_finish_output+0x144/0x360
[ebca96a0] [c059f450] ip_local_out+0x34/0x48
[ebca96b0] [c059f6e4] ip_push_pending_frames+0x280/0x3b0
....
And
BUG: using smp_processor_id() in preemptible [00000000] code: mingetty/753
caller is dpa_tx+0x24/0x698
Call Trace:
[eaecb560] [c0007c8c] show_stack+0x44/0x160 (unreliable)
[eaecb590] [c037693c] debug_smp_processor_id+0xe0/0xf0
[eaecb5b0] [c049cca0] dpa_tx+0x24/0x698
[eaecb600] [c056dd4c] dev_hard_start_xmit+0x254/0x56c
[eaecb650] [c057794c] neigh_resolve_output+0x108/0x36c
[eaecb690] [c059edd8] ip_finish_output+0x144/0x360
[eaecb6c0] [c059f468] ip_local_out+0x34/0x48
[eaecb6d0] [c059f6fc] ip_push_pending_frames+0x280/0x3b0
[eaecb700] [c05c1644] udp_push_pending_frames+0x108/0x494
[eaecb730] [c05c3bfc] udp_sendmsg+0x3ec/0x6a8
.....

Here use raw_smp_processor_id instead of smp_processor_id to fix this issue.

Signed-off-by: Weiwei Wang <weiwei.wang@windriver.com>
---
 drivers/net/dpa/dpaa_eth.c |   30 +++++++++++++++---------------
 1 files changed, 15 insertions(+), 15 deletions(-)

diff --git a/drivers/net/dpa/dpaa_eth.c b/drivers/net/dpa/dpaa_eth.c
index 84079f9..f603168 100644
--- a/drivers/net/dpa/dpaa_eth.c
+++ b/drivers/net/dpa/dpaa_eth.c
@@ -69,8 +69,8 @@
 #define DPA_MAX_TX_BACKLOG	512
 #define DPA_NAPI_WEIGHT		64
 
-#define DPA_BP_REFILL (1 | (smp_processor_id() << 16))
-#define DPA_BP_FINE ((smp_processor_id() << 16))
+#define DPA_BP_REFILL (1 | (raw_smp_processor_id() << 16))
+#define DPA_BP_FINE ((raw_smp_processor_id() << 16))
 #define DPA_BP_REFILL_NEEDED 1
 
 /* Bootarg used to override the Kconfig DPA_MAX_FRM_SIZE value */
@@ -213,7 +213,7 @@ static void dpa_bp_add_8(struct dpa_bp *dpa_bp)
 	int err;
 	int *count_ptr;
 
-	count_ptr = per_cpu_ptr(dpa_bp->percpu_count, smp_processor_id());
+	count_ptr = per_cpu_ptr(dpa_bp->percpu_count, raw_smp_processor_id());
 
 	for (i = 0; i < 8; i++) {
 		/*
@@ -271,7 +271,7 @@ static void dpa_make_private_pool(struct dpa_bp *dpa_bp)
 		int *countptr;
 		int j;
 		thiscount = per_cpu_ptr(dpa_bp->percpu_count,
-				smp_processor_id());
+				raw_smp_processor_id());
 		countptr = per_cpu_ptr(dpa_bp->percpu_count, i);
 
 		for (j = 0; j < dpa_bp->count; j += 8)
@@ -1127,7 +1127,7 @@ static int __hot dpa_shared_tx(struct sk_buff *skb, struct net_device *net_dev)
 	void *dpa_bp_vaddr;
 
 	priv = netdev_priv(net_dev);
-	percpu_priv = per_cpu_ptr(priv->percpu_priv, smp_processor_id());
+	percpu_priv = per_cpu_ptr(priv->percpu_priv, raw_smp_processor_id());
 	dev = net_dev->dev.parent;
 
 	memset(&fd, 0, sizeof(fd));
@@ -1199,7 +1199,7 @@ static int __hot dpa_tx(struct sk_buff *skb, struct net_device *net_dev)
 	int needed_headroom;
 
 	priv = netdev_priv(net_dev);
-	percpu_priv = per_cpu_ptr(priv->percpu_priv, smp_processor_id());
+	percpu_priv = per_cpu_ptr(priv->percpu_priv, raw_smp_processor_id());
 	dev = net_dev->dev.parent;
 
 	memset(&fd, 0, sizeof(fd));
@@ -1311,7 +1311,7 @@ ingress_rx_error_dqrr(struct qman_portal		*portal,
 	net_dev = ((struct dpa_fq *)fq)->net_dev;
 	priv = netdev_priv(net_dev);
 
-	percpu_priv = per_cpu_ptr(priv->percpu_priv, smp_processor_id());
+	percpu_priv = per_cpu_ptr(priv->percpu_priv, raw_smp_processor_id());
 
 	if (dpaa_eth_napi_schedule(percpu_priv)) {
 		percpu_priv->in_interrupt++;
@@ -1339,7 +1339,7 @@ shared_rx_dqrr(struct qman_portal *portal, struct qman_fq *fq,
 	net_dev = ((struct dpa_fq *)fq)->net_dev;
 	priv = netdev_priv(net_dev);
 
-	percpu_priv = per_cpu_ptr(priv->percpu_priv, smp_processor_id());
+	percpu_priv = per_cpu_ptr(priv->percpu_priv, raw_smp_processor_id());
 
 	if (unlikely(fd->status & FM_FD_STAT_ERRORS) != 0) {
 		if (netif_msg_hw(priv) && net_ratelimit())
@@ -1426,7 +1426,7 @@ ingress_rx_default_dqrr(struct qman_portal		*portal,
 	net_dev = ((struct dpa_fq *)fq)->net_dev;
 	priv = netdev_priv(net_dev);
 
-	percpu_priv = per_cpu_ptr(priv->percpu_priv, smp_processor_id());
+	percpu_priv = per_cpu_ptr(priv->percpu_priv, raw_smp_processor_id());
 
 	if (unlikely(dpaa_eth_napi_schedule(percpu_priv))) {
 		percpu_priv->in_interrupt++;
@@ -1452,7 +1452,7 @@ ingress_tx_error_dqrr(struct qman_portal		*portal,
 	net_dev = ((struct dpa_fq *)fq)->net_dev;
 	priv = netdev_priv(net_dev);
 
-	percpu_priv = per_cpu_ptr(priv->percpu_priv, smp_processor_id());
+	percpu_priv = per_cpu_ptr(priv->percpu_priv, raw_smp_processor_id());
 
 	if (dpaa_eth_napi_schedule(percpu_priv)) {
 		percpu_priv->in_interrupt++;
@@ -1476,7 +1476,7 @@ ingress_tx_default_dqrr(struct qman_portal		*portal,
 	net_dev = ((struct dpa_fq *)fq)->net_dev;
 	priv = netdev_priv(net_dev);
 
-	percpu_priv = per_cpu_ptr(priv->percpu_priv, smp_processor_id());
+	percpu_priv = per_cpu_ptr(priv->percpu_priv, raw_smp_processor_id());
 
 	if (dpaa_eth_napi_schedule(percpu_priv)) {
 		percpu_priv->in_interrupt++;
@@ -1500,7 +1500,7 @@ static void shared_ern(struct qman_portal	*portal,
 
 	net_dev = dpa_fq->net_dev;
 	priv = netdev_priv(net_dev);
-	percpu_priv = per_cpu_ptr(priv->percpu_priv, smp_processor_id());
+	percpu_priv = per_cpu_ptr(priv->percpu_priv, raw_smp_processor_id());
 
 	err = dpa_fd_release(net_dev, &msg->ern.fd);
 	if (unlikely(err < 0)) {
@@ -1527,7 +1527,7 @@ static void egress_ern(struct qman_portal	*portal,
 	net_dev = ((struct dpa_fq *)fq)->net_dev;
 	priv = netdev_priv(net_dev);
 	bp = priv->dpa_bp;
-	percpu_priv = per_cpu_ptr(priv->percpu_priv, smp_processor_id());
+	percpu_priv = per_cpu_ptr(priv->percpu_priv, raw_smp_processor_id());
 
 	percpu_priv->stats.tx_dropped++;
 	percpu_priv->stats.tx_fifo_errors++;
@@ -1681,7 +1681,7 @@ static void __cold dpa_timeout(struct net_device *net_dev)
 	struct dpa_percpu_priv_s *percpu_priv;
 
 	priv = netdev_priv(net_dev);
-	percpu_priv = per_cpu_ptr(priv->percpu_priv, smp_processor_id());
+	percpu_priv = per_cpu_ptr(priv->percpu_priv, raw_smp_processor_id());
 
 	if (netif_msg_timer(priv))
 		cpu_netdev_crit(net_dev, "Transmit timeout latency: %lu ms\n",
@@ -1991,7 +1991,7 @@ static const struct file_operations dpa_debugfs_fops = {
 
 static u16 dpa_select_queue(struct net_device *net_dev, struct sk_buff *skb)
 {
-	return smp_processor_id();
+	return raw_smp_processor_id();
 }
 
 static const struct net_device_ops dpa_private_ops = {
-- 
1.7.0.4

