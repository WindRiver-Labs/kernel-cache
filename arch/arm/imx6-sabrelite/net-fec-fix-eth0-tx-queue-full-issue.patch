From 384681516831db43990a56d54c118c6ee5b50dc1 Mon Sep 17 00:00:00 2001
From: Zhong Hongbo <hongbo.zhong@windriver.com>
Date: Thu, 25 Oct 2012 09:31:41 +0800
Subject: [PATCH 57/62] net/fec : fix 'eth0: tx queue full!' issue.

Source: Extract from vendor-drop package, L3.0.15_12.04.01_ER_source.tar.gz
(May,2012).

The issue is hard to reproduce in normal envrionment. And
the reproduce rate is about 40% when doing VTE auto test.

while the driver did report being busy when the link is down
or no transmission buffers are available, it did not stop the
queue, causing instant retries. furthermore, transmission being
triggered with link down was caused by unconditional queue
wakes, especially on timeouts.

Now, wake queue only if link is up and transmission buffers
are available, and dont forget to wake queue when link has
been adjusted. next, add stop queue notification upon driver
induced transmission problems, so network stack has a chance
to handle the situation.

Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 drivers/net/ethernet/freescale/fec.c |   24 ++++++++++++++++++------
 1 file changed, 18 insertions(+), 6 deletions(-)

diff --git a/drivers/net/ethernet/freescale/fec.c b/drivers/net/ethernet/freescale/fec.c
index a12b3f5..28d605a 100644
--- a/drivers/net/ethernet/freescale/fec.c
+++ b/drivers/net/ethernet/freescale/fec.c
@@ -284,12 +284,14 @@ fec_enet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
 	unsigned short	status;
 	unsigned long flags;
 
+	spin_lock_irqsave(&fep->hw_lock, flags);
 	if (!fep->link) {
 		/* Link is down or autonegotiation is in progress. */
+		netif_stop_queue(ndev);
+		spin_unlock_irqrestore(&fep->hw_lock, flags);
 		return NETDEV_TX_BUSY;
 	}
 
-	spin_lock_irqsave(&fep->hw_lock, flags);
 	/* Fill in a Tx ring entry */
 	bdp = fep->cur_tx;
 
@@ -300,6 +302,7 @@ fec_enet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
 		 * This should not happen, since ndev->tbusy should be set.
 		 */
 		printk("%s: tx queue full!.\n", ndev->name);
+		netif_stop_queue(ndev);
 		spin_unlock_irqrestore(&fep->hw_lock, flags);
 		return NETDEV_TX_BUSY;
 	}
@@ -319,8 +322,8 @@ fec_enet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
 	if (((unsigned long) bufaddr) & FEC_ALIGNMENT) {
 		unsigned int index;
 		index = bdp - fep->tx_bd_base;
-		memcpy(fep->tx_bounce[index], skb->data, skb->len);
-		bufaddr = fep->tx_bounce[index];
+		bufaddr = PTR_ALIGN(fep->tx_bounce[index], FEC_ALIGNMENT + 1);
+		memcpy(bufaddr, (void *)skb->data, skb->len);
 	}
 
 	/*
@@ -553,7 +556,8 @@ fec_timeout(struct net_device *ndev)
 	ndev->stats.tx_errors++;
 
 	fec_restart(ndev, fep->full_duplex);
-	netif_wake_queue(ndev);
+	if (fep->link && !fep->tx_full)
+		netif_wake_queue(ndev);
 }
 
 static void
@@ -577,6 +581,8 @@ fec_enet_tx(struct net_device *ndev)
 		bdp->cbd_bufaddr = 0;
 
 		skb = fep->tx_skbuff[fep->skb_dirty];
+		if (!skb)
+			break;
 		/* Check for errors. */
 		if (status & (BD_ENET_TX_HB | BD_ENET_TX_LC |
 				   BD_ENET_TX_RL | BD_ENET_TX_UN |
@@ -883,9 +889,11 @@ static void fec_enet_adjust_link(struct net_device *ndev)
 	/* Link on or off change */
 	if (phy_dev->link != fep->link) {
 		fep->link = phy_dev->link;
-		if (phy_dev->link)
+		if (phy_dev->link) {
 			fec_restart(ndev, phy_dev->duplex);
-		else
+			if (!fep->tx_full)
+				netif_wake_queue(ndev);
+		} else
 			fec_stop(ndev);
 		status_change = 1;
 	}
@@ -1230,6 +1238,10 @@ static int fec_enet_alloc_buffers(struct net_device *ndev)
 	bdp = fep->tx_bd_base;
 	for (i = 0; i < TX_RING_SIZE; i++) {
 		fep->tx_bounce[i] = kmalloc(FEC_ENET_TX_FRSIZE, GFP_KERNEL);
+		if (!fep->tx_bounce[i]) {
+			fec_enet_free_buffers(ndev);
+			return -ENOMEM;
+		}
 
 		bdp->cbd_sc = 0;
 		bdp->cbd_bufaddr = 0;
-- 
1.7.9.7

