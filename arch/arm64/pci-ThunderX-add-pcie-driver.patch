From 6ed9a0b1c302a63b2d6cf387d662198ecbb590a5 Mon Sep 17 00:00:00 2001
From: Jiang Lu <lu.jiang@windriver.com>
Date: Wed, 24 Jun 2015 09:11:59 +0000
Subject: [PATCH 19/23] pci:ThunderX:add pcie driver

Adds pcie driver for ThunderX soc.
Extracted from ThunderX-SDK pre-release 0.4.

Signed-off-by: Jiang Lu <lu.jiang@windriver.com>
---
 drivers/pci/host/pcie-thunder.c | 1023 +++++++++++++++++++++++++++++++++++++--
 1 files changed, 994 insertions(+), 29 deletions(-)

diff --git a/drivers/pci/host/pcie-thunder.c b/drivers/pci/host/pcie-thunder.c
index 2769420..101d31e 100644
--- a/drivers/pci/host/pcie-thunder.c
+++ b/drivers/pci/host/pcie-thunder.c
@@ -1,13 +1,14 @@
 /*
  * PCIe host controller driver for Cavium Thunder SOC
  *
- * Copyright (C) 2013, Cavium Inc.
+ * Copyright (C) 2014, Cavium Inc.
  *
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License as
  * published by the Free Software Foundation; either version 2 of
  * the License, or (at your option) any later version.
  */
+#include <linux/delay.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/interrupt.h>
@@ -23,13 +24,110 @@
 #define THUNDER_PCIE_DEV_SHIFT		15
 #define THUNDER_PCIE_FUNC_SHIFT		12
 
+#define THUNDER_ECAM0_CFG_BASE		0x848000000000
+#define THUNDER_ECAM1_CFG_BASE		0x849000000000
+#define THUNDER_ECAM2_CFG_BASE		0x84a000000000
+#define THUNDER_ECAM3_CFG_BASE		0x84b000000000
+#define THUNDER_ECAM4_CFG_BASE		0x948000000000
+#define THUNDER_ECAM5_CFG_BASE		0x949000000000
+#define THUNDER_ECAM6_CFG_BASE		0x94a000000000
+#define THUNDER_ECAM7_CFG_BASE		0x94b000000000
+
+#define THUNDER_PEM0_REG_BASE		(0x87e0c0000000 | (0 << 24))
+#define THUNDER_PEM1_REG_BASE		(0x87e0c0000000 | (1 << 24))
+#define THUNDER_PEM2_REG_BASE		(0x87e0c0000000 | (2 << 24))
+#define THUNDER_PEM3_REG_BASE		(0x87e0c0000000 | (3 << 24))
+#define THUNDER_PEM4_REG_BASE		(0x87e0c0000000 | (4 << 24))
+#define THUNDER_PEM5_REG_BASE		(0x87e0c0000000 | (5 << 24))
+#define THUNDER_PEM6_REG_BASE		(0x97e0c0000000 | (0 << 24))
+#define THUNDER_PEM7_REG_BASE		(0x97e0c0000000 | (1 << 24))
+#define THUNDER_PEM8_REG_BASE		(0x97e0c0000000 | (2 << 24))
+#define THUNDER_PEM9_REG_BASE		(0x97e0c0000000 | (3 << 24))
+#define THUNDER_PEM10_REG_BASE		(0x97e0c0000000 | (4 << 24))
+#define THUNDER_PEM11_REG_BASE		(0x97e0c0000000 | (5 << 24))
+
+#define THUNDER_GSER_N0_BASE		0x87e090000000
+#define THUNDER_GSER_N1_BASE		0x97e090000000
+#define THUNDER_GSER_SIZE		0x00000d000000
+
+#define SLIX_S2M_REGX_ACC		0x874001000000
+#define N1_SLIX_S2M_REGX_ACC		0x974001000000
+#define SLIX_S2M_REGX_ACC_SIZE		0x1000
+
+#define THUNDER_GSER_PCIE_MASK		0x01
+#define THUNDER_GSER_BGX_MASK		0x04
+#define THUNDER_GSER_SATA_MASK		0x20
+
+void __iomem *gser_base0;
+void __iomem *gser_base1;
+void __iomem *sli0_s2m_regx_base;
+void __iomem *sli1_s2m_regx_base;
+void __iomem *sli2_s2m_regx_base;
+void __iomem *sli3_s2m_regx_base;
+
+enum thunder_pcie_device_type {
+	THUNDER_ECAM,
+	THUNDER_PEM,
+};
+
 struct thunder_pcie {
 	struct device_node	*node;
 	struct device		*dev;
 	void __iomem		*cfg_base;
+	void __iomem		*pem_base;
+	void __iomem		*pem_sli_base;
 	struct msi_chip		*msi;
+	int			device_type;
+	int			ecam;
+	int			pem;
+};
+
+struct sli_mem_addr {
+	uint64_t addr:32;
+	uint64_t region:8;
+	uint64_t did_hi:4;
+	uint64_t node:2;
+	uint64_t reserved_46_46:1;
+	uint64_t io:1;
+	uint64_t reserved_48_63:16;
 };
 
+int pci_requester_id(struct pci_dev *dev)
+{
+	struct thunder_pcie *pcie = dev->bus->sysdata;
+
+	if (pcie->device_type == THUNDER_ECAM) {
+		/* this is easy case */
+		return ((pci_domain_nr(dev->bus) >> 2) << 19) |
+				((pci_domain_nr(dev->bus) % 4) << 16) |
+				((dev)->bus->number << 8) | (dev)->devfn;
+	} else {
+		if (pcie->pem < 3)
+			return (1 << 16) |
+					((dev)->bus->number << 8) |
+					(dev)->devfn;
+		else if (pcie->pem < 6)
+			return (3 << 16) |
+					((dev)->bus->number << 8) |
+					(dev)->devfn;
+		else if (pcie->pem < 9)
+			return (1 << 19) | (1 << 16) |
+					((dev)->bus->number << 8) |
+					(dev)->devfn;
+		else if (pcie->pem < 12)
+			return (1 << 19) |
+					(3 << 16) |
+					((dev)->bus->number << 8) |
+					(dev)->devfn;
+		else {
+			WARN_ON("Not Valid PEM id");
+			return -ENODEV;
+		}
+	}
+}
+EXPORT_SYMBOL(pci_requester_id);
+
+
 /*
  * This bridge is just for the sake of supporting ARI for
  * downstream devices. No resources are attached to it.
@@ -54,7 +152,7 @@ static void pci_bridge_resource_fixup(struct pci_dev *dev)
 	}
 }
 DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_CAVIUM, PCI_DEVICE_ID_THUNDER_BRIDGE,
-						pci_bridge_resource_fixup);
+			pci_bridge_resource_fixup);
 
 /*
  * All PCIe devices in Thunder have fixed resources, shouldn't be reassigned.
@@ -76,7 +174,482 @@ static void pci_dev_resource_fixup(struct pci_dev *dev)
 	}
 }
 DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_CAVIUM, PCI_ANY_ID,
-						pci_dev_resource_fixup);
+			pci_dev_resource_fixup);
+
+static uint64_t thunder_get_gser_cfg_addr(int node, int qlm)
+{
+	if (node)
+		return ((uint64_t)gser_base1) + 0x80 + (0x1000000 * qlm);
+	else
+		return ((uint64_t)gser_base0) + 0x80 + (0x1000000 * qlm);
+}
+
+static uint64_t thunder_get_gser_cfg(int node, int qlm)
+{
+	return readq((uint64_t *)thunder_get_gser_cfg_addr(node, qlm));
+}
+
+static void __iomem *slix_s2m_regx_adr(int node, int sli, int regnum)
+{
+	void __iomem *address = NULL;
+	int sli_node;
+	sli_node = node << 1 | sli;
+
+	switch (sli_node) {
+	case 0:
+		address = (void *)((uint64_t)sli0_s2m_regx_base) +
+			(regnum & 255) * 0x10ull;
+		break;
+	case 1:
+		address = (void *)((uint64_t)sli1_s2m_regx_base) +
+			(regnum & 255) * 0x10ull;
+		break;
+	case 2:
+		address = (void *)((uint64_t)sli2_s2m_regx_base) +
+			(regnum & 255) * 0x10ull;
+		break;
+	case 3:
+		address = (void *)((uint64_t)sli3_s2m_regx_base) +
+			(regnum & 255) * 0x10ull;
+		break;
+	default:
+		WARN_ON("Sli/Node id are not correct");
+	}
+	return address;
+}
+enum slix_s2m_ctype {
+	CTYPE_MEMORY	= 0,
+	CTYPE_CONFIG	= 1,
+	CTYPE_IO	= 2
+};
+
+static u64 slix_s2m_reg_val(unsigned mac, enum slix_s2m_ctype ctype,
+			    bool merge, bool relaxed, bool snoop, u32 ba_msb)
+{
+	u64 v;
+
+	v = (u64)(mac % 3) << 49;
+	v |= (u64)ctype << 53;
+	if (!merge)
+		v |= 1ull << 48;
+	if (relaxed)
+		v |= 5ull << 40;
+	if (!snoop)
+		v |= 5ull << 41;
+	v |= (u64)ba_msb;
+
+	return v;
+}
+
+static int thunder_pcie_check_ecam_cfg_access(int ecam, unsigned int bus,
+					 unsigned int devfn)
+{
+	int supported = 0;
+	uint16_t bdf = (bus << 8) | devfn;
+	uint64_t gser_cfg;
+
+	if (ecam == 0) {
+		switch (bdf) {
+		case 0x008:   /* RSL bridge */
+		case 0x010:   /* SMMU */
+		case 0x030:   /* GPIO */
+		case 0x038:   /* MPI */
+		case 0x080:   /* USB0 */
+		case 0x088:   /* USB1 */
+		case 0x0A0:   /* RAD bridge */
+		case 0x0A8:   /* ZIP bridge */
+		case 0x0B0:   /* DFA bridge */
+		case 0x100:   /* MRML */
+		case 0x101:   /* RST */
+		case 0x103:   /* FUS */
+		case 0x104:   /* FUSF */
+		case 0x109:   /* L2C */
+		case 0x10A:   /* SGPIO */
+		case 0x10C:   /* EMM */
+		case 0x10D:   /* KEY */
+		case 0x10e:   /* MIO_BOOT */
+		case 0x148:   /* TWSI0 */
+		case 0x149:   /* TWSI1 */
+		case 0x14A:   /* TWSI2 */
+		case 0x14B:   /* TWSI3 */
+		case 0x14C:   /* TWSI4 */
+		case 0x14D:   /* TWSI5 */
+		case 0x200:   /* RAD */
+		case 0x300:   /* ZIP */
+		case 0x400:   /* HFA */
+			supported = 1;
+			break;
+		case 0x180:   /* BGX0 */
+			gser_cfg = thunder_get_gser_cfg(0, 0);
+			if (gser_cfg & THUNDER_GSER_BGX_MASK)
+				supported = 1;
+			break;
+		case 0x181:   /* BGX1 */
+			gser_cfg = thunder_get_gser_cfg(0, 1);
+			if (gser_cfg & THUNDER_GSER_BGX_MASK)
+				supported = 1;
+			break;
+		default:
+			supported = 0;
+		}
+	} else if (ecam == 1) {
+		switch (bdf) {
+		case 0x008:   /* SMMU */
+		case 0x020:   /* AHCI0*/
+		case 0x028:   /* AHCI1 */
+		case 0x030:   /* AHCI2 */
+		case 0x038:   /* AHCI3 */
+			gser_cfg = thunder_get_gser_cfg(0, 2);
+			if (gser_cfg & THUNDER_GSER_SATA_MASK)
+				supported = 1;
+			break;
+		case 0x040:   /* AHCI4 */
+		case 0x048:   /* AHCI5 */
+		case 0x050:   /* AHCI5 */
+		case 0x058:   /* AHCI7 */
+			gser_cfg = thunder_get_gser_cfg(0, 3);
+			if (gser_cfg & THUNDER_GSER_SATA_MASK)
+				supported = 1;
+			break;
+		case 0x080:   /* PCIRC0 */
+		case 0x098:   /* PCIRC1 */
+		case 0x0A8:   /* PCIRC2 */
+		default:
+			supported = 0;
+		}
+	} else if (ecam == 2) {
+		switch (bdf) {
+		case 0x008:   /* SMMU */
+		case 0x010:   /* NIC Bridge */
+		case 0x018:   /* TNS */
+		case 0x100:   /* NIC PF */
+		case 0x101:   /* NIC VF */
+		case 0x102:   /* NIC VF */
+		case 0x103:   /* NIC VF */
+		case 0x104:   /* NIC VF */
+		case 0x105:   /* NIC VF */
+		case 0x106:   /* NIC VF */
+		case 0x107:   /* NIC VF */
+		case 0x108:   /* NIC VF */
+		case 0x109:   /* NIC VF */
+		case 0x10A:   /* NIC VF */
+		case 0x10B:   /* NIC VF */
+		case 0x10C:   /* NIC VF */
+		case 0x10D:   /* NIC VF */
+		case 0x10E:   /* NIC VF */
+		case 0x110:   /* NIC VF */
+			supported = 1;
+			break;
+		default:
+			supported = 0;
+		}
+	} else if (ecam == 3) {
+		switch (bdf) {
+		case 0x008:   /* SMMU */
+			supported = 1;
+			break;
+		case 0x020:   /* AHCI8 */
+		case 0x028:   /* AHCI9*/
+		case 0x030:   /* AHCI10 */
+		case 0x038:   /* AHCI11 */
+			gser_cfg = thunder_get_gser_cfg(0, 6);
+			if (gser_cfg & THUNDER_GSER_SATA_MASK)
+				supported = 1;
+			break;
+		case 0x040:   /* AHCI12 */
+		case 0x048:   /* AHCI13 */
+		case 0x050:   /* AHCI14 */
+		case 0x058:   /* AHCI15 */
+			gser_cfg = thunder_get_gser_cfg(0, 7);
+			if (gser_cfg & THUNDER_GSER_SATA_MASK)
+				supported = 1;
+			break;
+		case 0x080:   /* PCIRC3 */
+		case 0x098:   /* PCIRC4 */
+		case 0x0A8:   /* PCIRC5 */
+		default:
+			supported = 0;
+		}
+	}
+
+	if (ecam == 4) {
+		switch (bdf) {
+		case 0x008:   /* RSL bridge */
+		case 0x010:   /* SMMU */
+		case 0x030:   /* GPIO */
+		case 0x038:   /* MPI */
+		case 0x080:   /* USB0 */
+		case 0x088:   /* USB1 */
+		case 0x0A0:   /* RAD bridge */
+		case 0x0A8:   /* ZIP bridge */
+		case 0x0B0:   /* DFA bridge */
+		case 0x100:   /* MRML */
+		case 0x101:   /* RST */
+		case 0x103:   /* FUS */
+		case 0x104:   /* FUSF */
+		case 0x109:   /* L2C */
+		case 0x10A:   /* SGPIO */
+		case 0x10C:   /* EMM */
+		case 0x10D:   /* KEY */
+		case 0x10e:   /* MIO_BOOT */
+		case 0x148:   /* TWSI0 */
+		case 0x149:   /* TWSI1 */
+		case 0x14A:   /* TWSI2 */
+		case 0x14B:   /* TWSI3 */
+		case 0x14C:   /* TWSI4 */
+		case 0x14D:   /* TWSI5 */
+
+			supported = 1;
+			break;
+		case 0x180:   /* BGX0 */
+			gser_cfg = thunder_get_gser_cfg(1, 0);
+			if (gser_cfg & THUNDER_GSER_BGX_MASK)
+				supported = 1;
+			break;
+		case 0x181:   /* BGX1 */
+			gser_cfg = thunder_get_gser_cfg(1, 1);
+			if (gser_cfg & THUNDER_GSER_BGX_MASK)
+				supported = 1;
+			break;
+		default:
+			supported = 0;
+		}
+	} else if (ecam == 5) {
+		switch (bdf) {
+		case 0x008:   /* SMMU */
+		case 0x020:   /* AHCI0*/
+		case 0x028:   /* AHCI1 */
+		case 0x030:   /* AHCI2 */
+		case 0x038:   /* AHCI3 */
+			gser_cfg = thunder_get_gser_cfg(1, 2);
+			if (gser_cfg & THUNDER_GSER_SATA_MASK)
+				supported = 1;
+			break;
+		case 0x040:   /* AHCI4 */
+		case 0x048:   /* AHCI5 */
+		case 0x050:   /* AHCI5 */
+		case 0x058:   /* AHCI7 */
+			gser_cfg = thunder_get_gser_cfg(1, 3);
+			if (gser_cfg & THUNDER_GSER_SATA_MASK)
+				supported = 1;
+			break;
+		case 0x080:   /* PCIRC0 */
+		case 0x098:   /* PCIRC1 */
+		case 0x0A8:   /* PCIRC2 */
+		default:
+			supported = 0;
+		}
+	} else if (ecam == 6) {
+		switch (bdf) {
+		case 0x008:   /* SMMU */
+		case 0x010:   /* NIC Bridge */
+		case 0x100:   /* NIC PF */
+		case 0x101:   /* NIC VF */
+		case 0x102:   /* NIC VF */
+		case 0x103:   /* NIC VF */
+		case 0x104:   /* NIC VF */
+		case 0x105:   /* NIC VF */
+		case 0x106:   /* NIC VF */
+		case 0x107:   /* NIC VF */
+		case 0x108:   /* NIC VF */
+		case 0x109:   /* NIC VF */
+		case 0x10A:   /* NIC VF */
+		case 0x10B:   /* NIC VF */
+		case 0x10C:   /* NIC VF */
+		case 0x10D:   /* NIC VF */
+		case 0x10E:   /* NIC VF */
+		case 0x110:   /* NIC VF */
+			supported = 1;
+			break;
+		default:
+			supported = 0;
+		}
+	} else if (ecam == 7) {
+		switch (bdf) {
+		case 0x008:   /* SMMU */
+			supported = 1;
+			break;
+		case 0x020:   /* AHCI8 */
+		case 0x028:   /* AHCI9*/
+		case 0x030:   /* AHCI10 */
+		case 0x038:   /* AHCI11 */
+			gser_cfg = thunder_get_gser_cfg(1, 6);
+			if (gser_cfg & THUNDER_GSER_SATA_MASK)
+				supported = 1;
+			break;
+		case 0x040:   /* AHCI12 */
+		case 0x048:   /* AHCI13 */
+		case 0x050:   /* AHCI14 */
+		case 0x058:   /* AHCI15 */
+			gser_cfg = thunder_get_gser_cfg(1, 7);
+			if (gser_cfg & THUNDER_GSER_SATA_MASK)
+				supported = 1;
+			break;
+		case 0x080:   /* PCIRC3 */
+		case 0x098:   /* PCIRC4 */
+		case 0x0A8:   /* PCIRC5 */
+		default:
+			supported = 0;
+		}
+	}
+
+	return supported;
+}
+
+
+static int thunder_pcie_check_pem_cfg_access(int pem, unsigned int bus,
+					 unsigned int devfn)
+{
+	int supported = 0;
+	uint64_t gser_cfg;
+
+	/*TODO: 8 lane config needs to be handled supperately.
+	 * Hoping it should work..
+	 */
+
+	if (PCI_SLOT(devfn))
+		return supported;
+
+	switch (pem) {
+	case 0:
+		gser_cfg = thunder_get_gser_cfg(0, 2);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 1:
+		gser_cfg = thunder_get_gser_cfg(0, 3);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 2:
+		gser_cfg = thunder_get_gser_cfg(0, 4);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 3:
+		gser_cfg = thunder_get_gser_cfg(0, 5);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 4:
+		gser_cfg = thunder_get_gser_cfg(0, 6);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 5:
+		gser_cfg = thunder_get_gser_cfg(0, 7);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 6:
+		gser_cfg = thunder_get_gser_cfg(1, 2);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 7:
+		gser_cfg = thunder_get_gser_cfg(1, 3);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 8:
+		gser_cfg = thunder_get_gser_cfg(1, 4);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 9:
+		gser_cfg = thunder_get_gser_cfg(1, 5);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 10:
+		gser_cfg = thunder_get_gser_cfg(1, 6);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 11:
+		gser_cfg = thunder_get_gser_cfg(1, 7);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	}
+
+	return supported;
+}
+
+int first_bar0_read = 0;
+int first_bar1_read = 0;
+
+static int thunder_pcierc_config_read(void __iomem *pem_base, int reg, int size)
+{
+	void __iomem *addr;
+	unsigned int val;
+
+	if (reg == 0x10) /* BAR 0 */ {
+		if (!first_bar0_read)
+			val = 0xC0000004;
+		else
+			val = 0xffff800f;
+		first_bar0_read = 1;
+		return val;
+	}
+
+	if (reg == 0x14) /* BAR 1 */ {
+		if (!first_bar1_read)
+			val = 0x87E0;
+		else
+			val = 0xffffffff;
+		first_bar1_read = 1;
+		return val;
+	}
+
+
+	if (reg == 0x38) /* ROM */
+		return 0x00;
+
+	addr = pem_base + 0x30; /* RD_CFG reg */
+	writeq(reg & ~3, addr);
+	val = readq(addr) >> 32;
+
+	if (size == 1)
+		val = (val >> (8 * (reg & 3))) & 0xff;
+	else if (size == 2)
+		val = (val >> (8 * (reg & 3))) & 0xffff;
+
+	return val;
+}
+
+static void thunder_pcierc_config_write(void __iomem *pem_base, int reg,
+					int size, u64 val)
+{
+	void __iomem *addr;
+	u32 mask = 0;
+	u64 tmp;
+
+	addr = pem_base + 0x28; /* WR_CFG reg */
+
+	if (size == 4) {
+		writeq(((val << 32) | reg), addr);
+		return;
+	}
+
+	if (size == 2)
+		mask = ~(0xffff << ((reg & 0x3) * 8));
+	else if (size == 1)
+		mask = ~(0xff << ((reg & 0x3) * 8));
+
+	tmp = thunder_pcierc_config_read(pem_base, reg, size) & mask;
+	tmp |= val << ((reg & 0x3) * 8);
+	writeq((tmp << 32) | reg, addr);
+}
+
+static void __iomem *thunder_pcie_external_addr(struct thunder_pcie *pcie,
+						unsigned int bus, unsigned int devfn, int reg)
+{
+	return pcie->pem_sli_base + ((bus << 24)  | (devfn << 16) | reg);
+}
+
+
+
 
 static void __iomem *thunder_pcie_cfg_base(struct thunder_pcie *pcie,
 				 unsigned int bus, unsigned int devfn)
@@ -92,21 +665,40 @@ static int thunder_pcie_read_config(struct pci_bus *bus, unsigned int devfn,
 	struct thunder_pcie *pcie = bus->sysdata;
 	void __iomem *addr;
 	unsigned int busnr = bus->number;
+	int supported;
 
 	if (busnr > 255 || devfn > 255 || reg > 4095)
 		return PCIBIOS_DEVICE_NOT_FOUND;
 
 	addr = thunder_pcie_cfg_base(pcie, busnr, devfn) + reg;
 
+	if (pcie->device_type == THUNDER_ECAM) {
+		supported = thunder_pcie_check_ecam_cfg_access(pcie->ecam, busnr, devfn);
+	} else if (pcie->device_type == THUNDER_PEM) {
+		supported = thunder_pcie_check_pem_cfg_access(pcie->pem, busnr, devfn);
+		addr = thunder_pcie_external_addr(pcie, busnr, devfn, reg);
+	} else {
+		supported = 0;
+	}
+
 	switch (size) {
 	case 1:
-		*val = readb(addr);
+		if (!supported)
+			*val = 0xff;
+		else
+			*val = readb(addr);
 		break;
 	case 2:
-		*val = readw(addr);
+		if (!supported)
+			*val = 0xffff;
+		else
+			*val = readw(addr);
 		break;
 	case 4:
-		*val = readl(addr);
+		if (!supported)
+			*val = 0xffffffff;
+		else
+			*val = readl(addr);
 		break;
 	default:
 		return PCIBIOS_BAD_REGISTER_NUMBER;
@@ -121,11 +713,23 @@ static int thunder_pcie_write_config(struct pci_bus *bus, unsigned int devfn,
 	struct thunder_pcie *pcie = bus->sysdata;
 	void __iomem *addr;
 	unsigned int busnr = bus->number;
+	int supported;
 
 	if (busnr > 255 || devfn > 255 || reg > 4095)
 		return PCIBIOS_DEVICE_NOT_FOUND;
 
-	addr = thunder_pcie_cfg_base(pcie, busnr, devfn) + reg;
+	if (pcie->device_type == THUNDER_ECAM) {
+		supported = thunder_pcie_check_ecam_cfg_access(pcie->ecam, busnr, devfn);
+		addr = thunder_pcie_cfg_base(pcie, busnr, devfn) + reg;
+	} else if (pcie->device_type == THUNDER_PEM) {
+		supported = thunder_pcie_check_pem_cfg_access(pcie->pem, busnr, devfn);
+		addr = thunder_pcie_external_addr(pcie, busnr, devfn, reg);
+	} else {
+		supported = 0;
+	}
+
+	if (!supported)
+		return PCIBIOS_SUCCESSFUL;
 
 	switch (size) {
 	case 1:
@@ -168,13 +772,200 @@ static int thunder_pcie_msi_enable(struct thunder_pcie *pcie,
 	return 0;
 }
 
+#define PCIERC_CFG002 0x08
+#define PCIERC_CFG006 0x18
+#define PCIERC_CFG032 0x80
+
+static int thunder_pcierc_link_init(struct thunder_pcie *pcie)
+{
+	uint64_t regval;
+	void __iomem *address;
+
+	address = pcie->pem_base;
+
+	/* check whether PEM is safe to access. */
+	regval = readq(pcie->pem_base+0x420); /*PEMx_ON*/
+	if ((regval & 0x3) != 0x3) {
+		pr_err("PEM%d is not ON\n", pcie->pem);
+		return -ENODEV;
+	}
+
+	regval = readq(pcie->pem_base);
+	regval |= 0x10; /* Set Link Enable bit */
+	writeq(regval, address);
+
+
+	udelay(1000);
+	regval = thunder_pcierc_config_read(pcie->pem_base, PCIERC_CFG032, 0x4);
+	if (((regval>>29 & 0x1) == 0x0) || ((regval>>27 & 0x1) == 0x1)) {
+		pr_err("PCIe RC: Port %d Link Timeout\n", pcie->pem);
+		return -ENODEV;
+	}
+
+	return 0;
+}
+
+static int thunder_pcierc_init(struct thunder_pcie *pcie)
+{
+	uint64_t pem_addr;
+	uint64_t region;
+	uint64_t sli_group;
+	uint64_t gser_cfg;
+	int ret = 0;
+	int64_t node = -1, sli = -1;
+	int supported = 0;
+	u64 val;
+	void __iomem *addr;
+
+	switch (pcie->pem) {
+	case 0:
+		sli =  0;
+		sli_group = 0;
+		node = 0;
+		gser_cfg = thunder_get_gser_cfg(node, 2);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		gser_cfg = thunder_get_gser_cfg(node, 3);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+
+	case 1:
+		sli =  0;
+		sli_group = 1;
+		node = 0;
+		gser_cfg = thunder_get_gser_cfg(node, 3);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 2:
+		sli =  0;
+		sli_group = 2;
+		node = 0;
+		gser_cfg = thunder_get_gser_cfg(node, 4);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		gser_cfg = thunder_get_gser_cfg(node, 5);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 3:
+		sli =  1;
+		sli_group = 0;
+		node = 0;
+		gser_cfg = thunder_get_gser_cfg(node, 5);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 4:
+		sli =  1;
+		sli_group = 1;
+		node = 0;
+		gser_cfg = thunder_get_gser_cfg(node, 6);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		gser_cfg = thunder_get_gser_cfg(node, 7);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 5:
+		sli =  1;
+		sli_group = 2;
+		node = 0;
+		gser_cfg = thunder_get_gser_cfg(node, 7);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 6:
+		sli =  0;
+		sli_group = 0;
+		node = 1;
+		gser_cfg = thunder_get_gser_cfg(node, 2);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		gser_cfg = thunder_get_gser_cfg(node, 3);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 7:
+		sli =  0;
+		sli_group = 1;
+		node = 1;
+		gser_cfg = thunder_get_gser_cfg(node, 3);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 8:
+		sli =  0;
+		sli_group = 2;
+		node = 1;
+		gser_cfg = thunder_get_gser_cfg(node, 4);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		gser_cfg = thunder_get_gser_cfg(node, 5);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 9:
+		sli =  1;
+		sli_group = 0;
+		node = 1;
+		gser_cfg = thunder_get_gser_cfg(node, 5);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 10:
+		sli =  1;
+		node = 1;
+		sli_group = 1;
+		gser_cfg = thunder_get_gser_cfg(node, 6);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		gser_cfg = thunder_get_gser_cfg(node, 7);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	case 11:
+		sli =  1;
+		sli_group = 2;
+		node = 1;
+		gser_cfg = thunder_get_gser_cfg(node, 7);
+		if (gser_cfg & THUNDER_GSER_PCIE_MASK)
+			supported = 1;
+		break;
+	default:
+		return -ENODEV;
+	}
+
+	if (!supported)
+		return -ENODEV;
+
+	ret = thunder_pcierc_link_init(pcie);
+	if (ret)
+		return ret;
+
+	/* 1 slot for config access. */
+	addr = slix_s2m_regx_adr(node, sli, (sli_group << 6));
+	val = slix_s2m_reg_val(sli_group, CTYPE_CONFIG, false, false, false, 0);
+	writeq(val, addr);
+
+	/* PEM number and access type */
+	region = ((sli_group << 6) | (0ULL << 4)) << 32;
+	pem_addr = (1ULL << 47) | (node << 44) | ((0x8 + sli) << 40) | region;
+	pcie->pem_sli_base = ioremap(pem_addr, (0xFFULL << 24) - 1);
+	return ret;
+}
+
 static int thunder_pcie_probe(struct platform_device *pdev)
 {
 	struct thunder_pcie *pcie;
 	struct resource *cfg_base;
-	struct pci_host_bridge *bridge;
-	resource_size_t lastbus;
-	int ret;
+	struct pci_bus *bus;
+	resource_size_t iobase = 0;
+	int ret = 0;
+	int primary_bus = 0;
+	unsigned int i;
+	LIST_HEAD(res);
 
 	pcie = devm_kzalloc(&pdev->dev, sizeof(*pcie), GFP_KERNEL);
 	if (!pcie)
@@ -185,39 +976,213 @@ static int thunder_pcie_probe(struct platform_device *pdev)
 
 	/* Get controller's configuration space range */
 	cfg_base = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-	pcie->cfg_base = devm_ioremap_resource(&pdev->dev, cfg_base);
-	if (IS_ERR(pcie->cfg_base)) {
-		ret = PTR_ERR(pcie->cfg_base);
-		goto err_ioremap;
+	switch (cfg_base->start) {
+	case THUNDER_ECAM0_CFG_BASE:
+		pcie->device_type = THUNDER_ECAM;
+		pcie->ecam = 0;
+		break;
+	case THUNDER_ECAM1_CFG_BASE:
+		pcie->device_type = THUNDER_ECAM;
+		pcie->ecam = 1;
+		break;
+	case THUNDER_ECAM2_CFG_BASE:
+		pcie->device_type = THUNDER_ECAM;
+		pcie->ecam = 2;
+		break;
+	case THUNDER_ECAM3_CFG_BASE:
+		pcie->device_type = THUNDER_ECAM;
+		pcie->ecam = 3;
+		break;
+	case THUNDER_ECAM4_CFG_BASE:
+		pcie->device_type = THUNDER_ECAM;
+		pcie->ecam = 4;
+		break;
+	case THUNDER_ECAM5_CFG_BASE:
+		pcie->device_type = THUNDER_ECAM;
+		pcie->ecam = 5;
+		break;
+	case THUNDER_ECAM6_CFG_BASE:
+		pcie->device_type = THUNDER_ECAM;
+		pcie->ecam = 6;
+		break;
+	case THUNDER_ECAM7_CFG_BASE:
+		pcie->device_type = THUNDER_ECAM;
+		pcie->ecam = 7;
+		break;
+	case THUNDER_PEM0_REG_BASE:
+		pcie->device_type = THUNDER_PEM;
+		pcie->pem = 0;
+		break;
+	case THUNDER_PEM1_REG_BASE:
+		pcie->device_type = THUNDER_PEM;
+		pcie->pem = 1;
+		break;
+	case THUNDER_PEM2_REG_BASE:
+		pcie->device_type = THUNDER_PEM;
+		pcie->pem = 2;
+		break;
+	case THUNDER_PEM3_REG_BASE:
+		pcie->device_type = THUNDER_PEM;
+		pcie->pem = 3;
+		break;
+	case THUNDER_PEM4_REG_BASE:
+		pcie->device_type = THUNDER_PEM;
+		pcie->pem = 4;
+		break;
+	case THUNDER_PEM5_REG_BASE:
+		pcie->device_type = THUNDER_PEM;
+		pcie->pem = 5;
+		break;
+	case THUNDER_PEM6_REG_BASE:
+		pcie->device_type = THUNDER_PEM;
+		pcie->pem = 6;
+		break;
+	case THUNDER_PEM7_REG_BASE:
+		pcie->device_type = THUNDER_PEM;
+		pcie->pem = 7;
+		break;
+	case THUNDER_PEM8_REG_BASE:
+		pcie->device_type = THUNDER_PEM;
+		pcie->pem = 8;
+		break;
+	case THUNDER_PEM9_REG_BASE:
+		pcie->device_type = THUNDER_PEM;
+		pcie->pem = 9;
+		break;
+	case THUNDER_PEM10_REG_BASE:
+		pcie->device_type = THUNDER_PEM;
+		pcie->pem = 10;
+		break;
+	case THUNDER_PEM11_REG_BASE:
+		pcie->device_type = THUNDER_PEM;
+		pcie->pem = 11;
+		break;
+	}
+
+	if (gser_base0 == NULL)
+		gser_base0 = devm_ioremap(&pdev->dev,
+					 THUNDER_GSER_N0_BASE,
+					 THUNDER_GSER_SIZE);
+
+	if (sli0_s2m_regx_base == NULL)
+		sli0_s2m_regx_base = devm_ioremap(&pdev->dev, SLIX_S2M_REGX_ACC,
+					 SLIX_S2M_REGX_ACC_SIZE);
+	if (sli1_s2m_regx_base == NULL)
+		sli1_s2m_regx_base = devm_ioremap(&pdev->dev, SLIX_S2M_REGX_ACC+(1ull<<36),
+					 SLIX_S2M_REGX_ACC_SIZE);
+#ifdef CONFIG_NUMA
+	if (gser_base1 == NULL)
+		gser_base1 = devm_ioremap(&pdev->dev,
+					 THUNDER_GSER_N1_BASE,
+					 THUNDER_GSER_SIZE);
+	if (sli2_s2m_regx_base == NULL)
+		sli2_s2m_regx_base = devm_ioremap(&pdev->dev, N1_SLIX_S2M_REGX_ACC,
+					 SLIX_S2M_REGX_ACC_SIZE);
+	if (sli3_s2m_regx_base == NULL)
+		sli3_s2m_regx_base = devm_ioremap(&pdev->dev, N1_SLIX_S2M_REGX_ACC+(1ull<<36),
+					 SLIX_S2M_REGX_ACC_SIZE);
+#endif
+
+	if (pcie->device_type == THUNDER_ECAM) {
+		pcie->cfg_base = devm_ioremap_resource(&pdev->dev, cfg_base);
+		if (IS_ERR(pcie->cfg_base) || IS_ERR(gser_base0)) {
+			ret = PTR_ERR(pcie->cfg_base);
+			goto err_ioremap;
+		}
+
+		pr_err("%s: ECAM%d CFG BASE 0x%llx gser_base0:%llx\n", __func__,
+				pcie->ecam, (uint64_t)cfg_base->start, (uint64_t)gser_base0);
+
+#ifdef CONFIG_NUMA
+		if (IS_ERR(gser_base1)) {
+			ret = PTR_ERR(pcie->cfg_base);
+			goto err_ioremap;
+		}
+		pr_err("%s: ECAM%d CFG BASE 0x%llx gser_base1:%llx\n", __func__,
+				pcie->ecam, (uint64_t)cfg_base->start, (uint64_t)gser_base1);
+#endif
+		ret = of_pci_get_host_bridge_resources(pdev->dev.of_node,
+				0, 255, &res, NULL);
+	} else {
+		u64 val;
+		unsigned sli_pem, node, sli;
+		void __iomem *addr;
+
+		pcie->pem_base = ioremap(cfg_base->start, 0x500);
+		if (!pcie->pem_base) {
+			pr_err("Unable to map PCIe RC CFG registers\n");
+			goto err_ioremap;
+		}
+
+		if (thunder_pcierc_init(pcie)) {
+			pr_err("%s: PCIe RC%d not found\n", __func__, pcie->pem);
+			iounmap(pcie->pem_base);
+			return -ENODEV;
+		}
+
+
+		primary_bus = thunder_pcierc_config_read(pcie->pem_base, PCIERC_CFG006, 0x4);
+		pr_err("%s: PEM%d CFG BASE 0x%llx gser_base0:%llx primary_bus:%x\n", __func__,
+				pcie->pem, (uint64_t)cfg_base->start, (uint64_t)gser_base0, primary_bus);
+		primary_bus = (primary_bus >>  0x8) & 0xff;
+		ret = of_pci_get_host_bridge_resources(pdev->dev.of_node,
+				primary_bus, 255, &res, &iobase);
+
+		sli_pem = pcie->pem % 3;
+		sli = (pcie->pem / 3) % 2;
+		node = pcie->pem / 6;
+		for (i = 0; i < 16; i++) {
+			addr = slix_s2m_regx_adr(node, sli, (sli_pem << 6) + i + 0x10);
+			val = slix_s2m_reg_val(sli_pem, CTYPE_MEMORY, false, false, false, i);
+			writeq(val, addr);
+
+			addr = slix_s2m_regx_adr(node, sli, (sli_pem << 6) + i + 0x20);
+			val = slix_s2m_reg_val(sli_pem, CTYPE_MEMORY, true, true, true, i + 0x10);
+			writeq(val, addr);
+
+			addr = slix_s2m_regx_adr(node, sli, (sli_pem << 6) + i + 0x30);
+			val = slix_s2m_reg_val(sli_pem, CTYPE_IO, true, true, true, i);
+			writeq(val, addr);
+		}
 	}
 
-	bridge = of_create_pci_host_bridge(&pdev->dev, &thunder_pcie_ops, pcie);
-	if (IS_ERR(bridge)) {
-		ret = PTR_ERR(bridge);
-		goto err_pci;
+	if (ret)
+		goto err_get_host;
+
+
+	bus = pci_create_root_bus(&pdev->dev, primary_bus,
+		&thunder_pcie_ops, pcie, &res);
+	if (!bus) {
+		ret = -ENODEV;
+		goto err_root_bus;
 	}
 
 	/* Set reference to MSI chip */
-	ret = thunder_pcie_msi_enable(pcie, bridge->bus);
-	if (ret)
+	ret = thunder_pcie_msi_enable(pcie, bus);
+	if (ret) {
+		pr_err("%s: Unable to set reference to MSI chip: ret=%d\n",
+			__func__, ret);
 		goto err_msi;
+	}
 
 	platform_set_drvdata(pdev, pcie);
 
-	lastbus = pci_scan_child_bus(bridge->bus);
-	pci_bus_add_devices(bridge->bus);
-	ret = pci_bus_update_busn_res_end(bridge->bus, lastbus);
-	if (ret)
-		goto err_msi;
+	pci_scan_child_bus(bus);
+	pci_bus_add_devices(bus);
+
+	if (pcie->device_type == THUNDER_PEM)
+		pci_assign_unassigned_root_bus_resources(bus);
 
 	return 0;
 err_msi:
-	pci_remove_root_bus(bridge->bus);
-err_pci:
+	pci_remove_root_bus(bus);
+err_root_bus:
+	pci_free_resource_list(&res);
+err_get_host:
 	devm_ioremap_release(pcie->dev, pcie->cfg_base);
 err_ioremap:
 	of_node_put(pcie->node);
-	kfree(pcie);
+	devm_kfree(&pdev->dev, pcie);
 	return ret;
 }
 
@@ -239,4 +1204,4 @@ module_platform_driver(thunder_pcie_driver);
 
 MODULE_AUTHOR("Sunil Goutham");
 MODULE_DESCRIPTION("Cavium Thunder PCIe host controller driver");
-MODULE_LICENSE("GPLv2");
+MODULE_LICENSE("GPL v2");
-- 
1.7.5.4

