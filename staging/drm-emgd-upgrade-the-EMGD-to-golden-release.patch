From b4ee3ebfbca5138c73e520b387e9dcc4a418dcf0 Mon Sep 17 00:00:00 2001
From: fupan li <fupan.li@windriver.com>
Date: Wed, 8 Jan 2014 17:54:24 -0800
Subject: [PATCH 1/3] drm/emgd: upgrade the EMGD to golden release

BayTrail incoperates E38xx embedded on-chip graphics, which needs
the Intel Embedded Media and Graphics Driver (EMGD) Driver.
This is a incremental patch generated from 0001-Intel-EMGD-Add-support-for-Baytrail-platform.patch
and 0002-drm-emgd-Intel-EMGD-RC-Version-36-40-21-3685.patch in YP golden release BayTrail BSP.

Signed-off-by: fupan li <fupan.li@windriver.com>
---
 drivers/gpu/drm/emgd/Makefile                      |    2 +-
 drivers/gpu/drm/emgd/include/igd_context.h         |    5 +
 drivers/gpu/drm/emgd/include/igd_version.h         |    2 +-
 drivers/gpu/drm/emgd/include/kernel-compat.h       |   47 ++
 drivers/gpu/drm/emgd/src/core/drm_emgd_private.h   |  141 +++--
 drivers/gpu/drm/emgd/src/core/emgd_crtc.c          |   93 +++-
 drivers/gpu/drm/emgd/src/core/emgd_drv.c           |   70 ++-
 drivers/gpu/drm/emgd/src/core/emgd_fb.c            |    4 +-
 drivers/gpu/drm/emgd/src/core/emgd_fbcon.c         |   56 ++-
 drivers/gpu/drm/emgd/src/core/emgd_ovl.c           |   84 +++-
 drivers/gpu/drm/emgd/src/core/emgd_sysfs.c         |   11 +-
 drivers/gpu/drm/emgd/src/core/i915/i915_debugfs.c  |  312 +++++++----
 .../gpu/drm/emgd/src/core/i915/i915_emgd_helper.c  |  582 +++++++++++++++++++-
 drivers/gpu/drm/emgd/src/core/i915/i915_gem.c      |   49 +-
 .../drm/emgd/src/core/i915/i915_gem_execbuffer.c   |   47 ++-
 drivers/gpu/drm/emgd/src/core/i915/i915_gem_gtt.c  |   92 ++--
 .../gpu/drm/emgd/src/core/i915/i915_gem_stolen.c   |    4 +-
 drivers/gpu/drm/emgd/src/core/i915/i915_reg.h      |   19 +-
 drivers/gpu/drm/emgd/src/core/i915/i915_trace.h    |   25 +
 drivers/gpu/drm/emgd/src/core/i915/intel_atomic.c  |    7 +-
 drivers/gpu/drm/emgd/src/core/i915/intel_pm.c      |    9 -
 .../gpu/drm/emgd/src/core/i915/intel_ringbuffer.h  |   29 +
 .../drm/emgd/src/core/init/gn7/micro_init_vlv.c    |    2 +-
 .../gpu/drm/emgd/src/display/mode/cmn/kms_mode.c   |    4 +
 .../drm/emgd/src/display/mode/gn7/kms_mode_vlv.c   |   15 +-
 drivers/gpu/drm/emgd/src/display/pi/cmn/pi.c       |   11 +
 drivers/gpu/drm/emgd/src/pal/dp/dp_port.c          |   33 +-
 drivers/gpu/drm/emgd/src/state/reg/gn7/reg_vlv.c   |   31 +-
 drivers/gpu/drm/emgd/tools/fw_tool/README          |  103 ++++
 drivers/gpu/drm/emgd/tools/fw_tool/make_blob.sh    |   11 +-
 30 files changed, 1592 insertions(+), 308 deletions(-)
 create mode 100644 drivers/gpu/drm/emgd/include/kernel-compat.h

diff --git a/drivers/gpu/drm/emgd/Makefile b/drivers/gpu/drm/emgd/Makefile
index 28ab6e7..d0606e8 100644
--- a/drivers/gpu/drm/emgd/Makefile
+++ b/drivers/gpu/drm/emgd/Makefile
@@ -236,7 +236,7 @@ modules::
 	@echo "$(MAKE) -C $(KERNELDIR) M=$(CURDIR) modules"
 	@$(MAKE) -C $(KERNELDIR) M=$(CURDIR) modules
 ifeq "$(EMGD_CHANGELOG)" "1"
-	git log --pretty=format:"%h - %an (%ae): %ci %n%s" --shortstat --since=2.weeks | awk 'sub("$$", "\r")' > docs/EMGD_CHANGES.txt
+	git log --pretty=format:"%h - %an (%ae): %ci %n%s" --shortstat --since=2.weeks | awk 'sub("$$", "\r")' >  ../patches/drm/EMGD_CHANGES.txt
 endif
 
 clean::
diff --git a/drivers/gpu/drm/emgd/include/igd_context.h b/drivers/gpu/drm/emgd/include/igd_context.h
index 76ab8d3..80a9b40 100644
--- a/drivers/gpu/drm/emgd/include/igd_context.h
+++ b/drivers/gpu/drm/emgd/include/igd_context.h
@@ -147,6 +147,7 @@ typedef struct _emgd_crtc {
 	bool lowfreq_avail;
 	struct intel_overlay *overlay;
 	struct intel_unpin_work *unpin_work;
+	atomic_t unpin_work_count;
 	int fdi_lanes;
 	struct drm_i915_gem_object *cursor_bo;
 	uint32_t cursor_addr;
@@ -187,6 +188,10 @@ typedef struct _emgd_crtc {
 	wait_queue_head_t vbl_wait;
 	bool vbl_received;
 	struct list_head pending_flips;
+
+	/* To save the current s3d_mode in CRTC */
+	unsigned long current_s3d_mode;
+
 } emgd_crtc_t, igd_display_context_t;
 typedef struct emgd_crtc_t * igd_display_h;
 
diff --git a/drivers/gpu/drm/emgd/include/igd_version.h b/drivers/gpu/drm/emgd/include/igd_version.h
index 10e0905..d05a58f 100644
--- a/drivers/gpu/drm/emgd/include/igd_version.h
+++ b/drivers/gpu/drm/emgd/include/igd_version.h
@@ -34,5 +34,5 @@
 
 #define IGD_MAJOR_NUM  2
 #define IGD_MINOR_NUM  0
-#define IGD_BUILD_NUM  3551
+#define IGD_BUILD_NUM  3685
 #endif
diff --git a/drivers/gpu/drm/emgd/include/kernel-compat.h b/drivers/gpu/drm/emgd/include/kernel-compat.h
new file mode 100644
index 0000000..c5c6a71
--- /dev/null
+++ b/drivers/gpu/drm/emgd/include/kernel-compat.h
@@ -0,0 +1,47 @@
+/*
+ *-----------------------------------------------------------------------------
+ * Filename: kernel-compat.h
+ **-----------------------------------------------------------------------------
+ ** Copyright (c) 2002-2013, Intel Corporation.
+ **
+ ** Permission is hereby granted, free of charge, to any person obtaining a copy
+ ** of this software and associated documentation files (the "Software"), to deal
+ ** in the Software without restriction, including without limitation the rights
+ ** to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ ** copies of the Software, and to permit persons to whom the Software is
+ ** furnished to do so, subject to the following conditions:
+ **
+ ** The above copyright notice and this permission notice shall be included in
+ ** all copies or substantial portions of the Software.
+ **
+ ** THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ ** IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ ** FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ ** AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ ** LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ ** OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ ** THE SOFTWARE.
+ *
+ *
+ *-----------------------------------------------------------------------------
+ * Description:
+ **  This file contains kernel version comapability macors information. 
+ **-----------------------------------------------------------------------------
+*/
+
+ 
+
+#if LINUX_VERSION_CODE >=KERNEL_VERSION(3,10,0)
+#define GTT(dev_priv) (dev_priv)
+#else
+#define GTT(dev_priv) (dev_priv->mm.gtt)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3,10,0)
+#define	ADD_GTT_MTRR(base,sz,type,inc)	mtrr_add(base,sz,type,inc)
+#define DEL_GTT_MTRR(mtrr,base,sz)	mtrr_del(mtrr,base,sz) 
+#else
+#define ADD_GTT_MTRR(base,sz,type,inc)	0
+#define DEL_GTT_MTRR(mtrr,base,sz)		 
+#endif
+	
diff --git a/drivers/gpu/drm/emgd/src/core/drm_emgd_private.h b/drivers/gpu/drm/emgd/src/core/drm_emgd_private.h
index 6da6ac4..afaa580 100644
--- a/drivers/gpu/drm/emgd/src/core/drm_emgd_private.h
+++ b/drivers/gpu/drm/emgd/src/core/drm_emgd_private.h
@@ -154,57 +154,71 @@ struct sdvo_device_mapping {
 struct intel_display_error_state;
 
 struct drm_i915_error_state {
-	u32 eir;
-	u32 pgtbl_er;
-	u32 ier;
-	bool waiting[I915_NUM_RINGS];
-	u32 pipestat[I915_MAX_PIPES];
-	u32 ipeir;
-	u32 ipehr;
-	u32 instdone;
-	u32 acthd;
-	u32 error; /* gen6+ */
-	u32 bcs_acthd; /* gen6+ blt engine */
-	u32 bcs_ipehr;
-	u32 bcs_ipeir;
-	u32 bcs_instdone;
-	u32 bcs_seqno;
-	u32 vcs_acthd; /* gen6+ bsd engine */
-	u32 vcs_ipehr;
-	u32 vcs_ipeir;
-	u32 vcs_instdone;
-	u32 vcs_seqno;
-	u32 rc_psmi[I915_NUM_RINGS]; /* sleep state */
-	u32 instpm;
-	u32 instps;
-	u32 extra_instdone[4];
-	u32 seqno;
-	u64 bbaddr;
-	u64 fence[16];
-	struct timeval time;
-	struct drm_i915_error_object {
-		int page_count;
-		u32 gtt_offset;
-		u32 *pages[0];
-	} *ringbuffer[I915_NUM_RINGS], *batchbuffer[I915_NUM_RINGS];
-	struct drm_i915_error_buffer {
-		u32 size;
-		u32 name;
-		u32 rseqno, wseqno;
-		u32 gtt_offset;
-		u32 read_domains;
-		u32 write_domain;
-		s32 fence_reg:5;
-		s32 pinned:2;
-		u32 tiling:2;
-		u32 dirty:1;
-		u32 purgeable:1;
-		u32 ring:4;
-		u32 cache_level:2;
-	} *active_bo, *pinned_bo;
-	u32 active_bo_count, pinned_bo_count;
-	struct intel_overlay_error_state *overlay;
-	struct intel_display_error_state *display;
+        struct kref ref;
+        u32 eir;
+        u32 pgtbl_er;
+        u32 ier;
+        u32 ccid;
+        u32 derrmr;
+        u32 forcewake;
+        bool waiting[I915_NUM_RINGS];
+        u32 pipestat[I915_MAX_PIPES];
+        u32 tail[I915_NUM_RINGS];
+        u32 head[I915_NUM_RINGS];
+        u32 ctl[I915_NUM_RINGS];
+        u32 ipeir[I915_NUM_RINGS];
+        u32 ipehr[I915_NUM_RINGS];
+        u32 instdone[I915_NUM_RINGS];
+        u32 acthd[I915_NUM_RINGS];
+        u32 semaphore_mboxes[I915_NUM_RINGS][I915_NUM_RINGS - 1];
+        u32 semaphore_seqno[I915_NUM_RINGS][I915_NUM_RINGS - 1];
+        u32 rc_psmi[I915_NUM_RINGS]; /* sleep state */
+        /* our own tracking of ring head and tail */
+        u32 cpu_ring_head[I915_NUM_RINGS];
+        u32 cpu_ring_tail[I915_NUM_RINGS];
+        u32 error; /* gen6+ */
+        u32 err_int; /* gen7 */
+        u32 instpm[I915_NUM_RINGS];
+        u32 instps[I915_NUM_RINGS];
+        u32 extra_instdone[I915_NUM_INSTDONE_REG];
+        u32 seqno[I915_NUM_RINGS];
+        u64 bbaddr;                        
+        u32 fault_reg[I915_NUM_RINGS];
+        u32 done_reg;
+        u32 faddr[I915_NUM_RINGS];
+        u64 fence[I915_MAX_NUM_FENCES];
+        struct timeval time;
+	struct drm_i915_error_ring {
+                struct drm_i915_error_object {
+                        int page_count;
+                        u32 gtt_offset;
+                        u32 *pages[0];
+                } *ringbuffer, *batchbuffer;
+                struct drm_i915_error_request {
+                        long jiffies;
+                        u32 seqno;
+                        u32 tail;
+                } *requests;
+                int num_requests;
+        } ring[I915_NUM_RINGS];
+        struct drm_i915_error_buffer {
+                u32 size;
+                u32 name;
+                u32 rseqno, wseqno;
+                u32 gtt_offset;
+                u32 read_domains;
+                u32 write_domain;
+                s32 fence_reg:I915_MAX_NUM_FENCE_BITS;
+                s32 pinned:2;
+                u32 tiling:2;
+                u32 dirty:1;
+                u32 purgeable:1;
+                s32 ring:4;
+                u32 cache_level:2;
+        } *active_bo, *pinned_bo;
+        u32 active_bo_count, pinned_bo_count;
+        struct intel_overlay_error_state *overlay;
+        struct intel_display_error_state *display;
 };
 
 struct intel_device_info {
@@ -343,6 +357,8 @@ struct intel_l3_parity {
 typedef struct {
 	u32 render_prev;
 	u32 render_cur;
+	u32 media_prev;
+	u32 media_cur;
 	u32 punit_timestamp_prev;
 	u32 punit_timestamp_cur;
 } turbobuzy_t;
@@ -432,7 +448,15 @@ typedef struct drm_i915_private {
 	struct drm_device *dev;
 
 	const struct intel_device_info *info;
-
+	unsigned int gtt_mappable_entries;
+	phys_addr_t gma_bus_addr;
+	unsigned int gtt_total_entries;
+	unsigned int needs_dmar : 1;
+	dma_addr_t scratch_page_dma;
+	bool do_idle_maps;
+	struct page *scratch_page;
+	u32 __iomem *gtt;
+	size_t stolen_size;             /* Total size of stolen memory */
 	int has_gem;
 	int relative_constants_mode;
 
@@ -533,6 +557,11 @@ typedef struct drm_i915_private {
 	int num_fence_regs; /* 8 on pre-965, 16 otherwise */
 
 	unsigned int fsb_freq, mem_freq, is_ddr3;
+	
+	spinlock_t error_lock;
+
+	/* Protected by dev->error_lock. */
+	struct drm_i915_error_state *first_error;
 
 	struct workqueue_struct *wq;
 
@@ -996,6 +1025,7 @@ typedef struct drm_i915_private {
 		/* Shared normal slot knobs */
 		int shared_period;  /* NOTE: this is usec, sysfs converts to / from msec */
 		int shared_capacity;/* NOTE: this is usec, sysfs converts to / from msec */
+		bool shared_aereserve;/* TRUE = use AE for budget reservation, else use PE */
 		/* Shared rogue slot and demotion trigger time knobs */
 		bool rogue_switch;
 		int rogue_trigger;  /* NOTE: this is usec, sysfs converts to / from msec */
@@ -1016,6 +1046,7 @@ typedef struct drm_i915_private {
 		unsigned long rogue_last_refresh_jiffs; /* is jiffies */
 		
 		int req_prty_cnts[MAX_SCHED_PRIORITIES+1];
+		struct drm_i915_file_private * req_prty_fp[MAX_SCHED_PRIORITIES+1];
 		
 		/* Sysfs objects that are used during driver life */
 		struct emgd_obj *gemsched_sysfs_obj;
@@ -1744,6 +1775,7 @@ extern inline void i915_gem_chipset_flush(struct drm_device *dev)
 	if (INTEL_INFO(dev)->gen < 6)
 		intel_gtt_chipset_flush();
 }
+extern void i915_check_and_clear_faults(struct drm_device *dev);
 
 /* i915_gem_evict.c */
 int __must_check i915_gem_evict_something(struct drm_device *dev, int min_size,
@@ -1777,6 +1809,7 @@ void notify_ring(struct drm_device *dev, struct intel_ring_buffer *ring);
 void i915_error_work_func(struct work_struct *work);
 void vlv_pm_rps_work(struct work_struct *work);
 void vlv_queue_rps_work(struct drm_i915_private *dev_priv,u32 pm_iir);
+extern int crtc_pageflip_handler(struct drm_device *dev, int crtcnum);
 
 /* intel_pm.c */
 extern unsigned long i915_chipset_val(struct drm_i915_private *dev_priv);
@@ -1800,6 +1833,7 @@ extern void valleyview_set_rps(struct drm_device *dev, u8 val);
 
 #ifdef CONFIG_DEBUG_FS
 extern void i915_destroy_error_state(struct drm_device *dev);
+void i915_error_state_free(struct kref *error_ref);
 #else
 #define i915_destroy_error_state(x)
 #endif
@@ -1870,6 +1904,9 @@ static bool IS_DISPLAYREG(u32 reg)
 	if(reg == RENDER_RC0_COUNTER)
 		return false;
 
+	if(reg == MEDIA_RC0_COUNTER)
+		return false;
+
 	if (reg == MI_MODE)
 		return false;
 
diff --git a/drivers/gpu/drm/emgd/src/core/emgd_crtc.c b/drivers/gpu/drm/emgd/src/core/emgd_crtc.c
index 6b77a70..eefdc79 100644
--- a/drivers/gpu/drm/emgd/src/core/emgd_crtc.c
+++ b/drivers/gpu/drm/emgd/src/core/emgd_crtc.c
@@ -99,6 +99,7 @@ extern int s3d_timings_fixup(igd_display_port_t *port,
 
 
 const struct drm_crtc_helper_funcs emgd_crtc_helper_funcs = {
+	.disable              = emgd_crtc_disable,
 	.dpms                 = emgd_crtc_dpms,
 	.mode_fixup           = emgd_crtc_mode_fixup,
 	.mode_set             = emgd_crtc_mode_set,
@@ -461,7 +462,7 @@ static int emgd_crtc_mode_set_base(struct drm_crtc *crtc, int x, int y,
 
 	/* Pin the framebuffer into the GTT. */
 	devpriv->mm.interruptible = false;
-	ret = i915_gem_object_pin_to_display_plane(bo, alignment, NULL);
+	ret = intel_pin_and_fence_fb_obj(dev, bo, NULL);
 	if (ret != 0) {
 		EMGD_ERROR("Failed to pin framebuffer to GTT");
 		devpriv->mm.interruptible = true;
@@ -598,7 +599,7 @@ void emgd_crtc_commit(struct drm_crtc *crtc)
 	 * dpms & plane programming are ignored.
 	*/
 	if(!emgd_crtc->freeze_state) {
-		context->mode_dispatch->kms_program_pipe(emgd_crtc);
+		/* context->mode_dispatch->kms_program_pipe(emgd_crtc); */
 		/* Turn on pipe and plane */
 		emgd_crtc_dpms(crtc, DRM_MODE_DPMS_ON);
 	}
@@ -970,11 +971,23 @@ static void emgd_crtc_destroy(struct drm_crtc *crtc)
 	emgd_crtc_t *emgd_crtc = NULL;
 	igd_context_t *context = NULL;
 	igd_display_pipe_t *igd_pipe = NULL;
+	emgd_page_flip_work_t * work = NULL;
+	unsigned long flags;
 	int i;
 
 	EMGD_TRACE_ENTER;
 
 	emgd_crtc = container_of(crtc, emgd_crtc_t, base);
+	spin_lock_irqsave(&emgd_crtc->crtc_lock, flags);
+	work = emgd_crtc->flip_pending;
+	emgd_crtc->flip_pending = NULL;
+	spin_unlock_irqrestore(&emgd_crtc->crtc_lock, flags);
+
+	if (work) {
+		cancel_work_sync(&work->work);
+		kfree(work);
+	}
+
 	igd_pipe = emgd_crtc->igd_pipe;
 	if (!igd_pipe) {
 		EMGD_ERROR("\t\tpipe %d is not available", emgd_crtc->crtc_id);
@@ -1128,7 +1141,9 @@ int crtc_pageflip_handler(struct drm_device *dev, int crtcnum)
 	atomic_clear_mask(1 << plane_select,
 			  &page_flip_work->old_fb_obj->pending_flip.counter);
 
-	schedule_work(&page_flip_work->work);
+	wake_up_all(&priv->pending_flip_queue);
+
+	queue_work(priv->wq, &page_flip_work->work);
 
 	EMGD_TRACE_EXIT;
 	return 1;
@@ -1193,8 +1208,9 @@ int sprite_pageflip_handler(struct drm_device *dev, int crtcnum)
  
         atomic_clear_mask(1 << plane_select,
         &page_flip_work->old_stereo_obj[i]->pending_flip.counter);
-        schedule_work(&page_flip_work->work);
  	}
+  	/* Use queue_work() as in crtc_pageflip_handler */
+  	queue_work(priv->wq, &page_flip_work->work);
  
   	EMGD_TRACE_EXIT;
    	return 1;
@@ -1204,6 +1220,7 @@ static void emgd_unpin_work(struct work_struct *__work)
 {
 	emgd_page_flip_work_t *page_flip_work =
 			container_of(__work, emgd_page_flip_work_t, work);
+	emgd_crtc_t * emgd_crtc = (emgd_crtc_t *)page_flip_work->emgd_crtc;
 
 	/* Update sysfs' view of the CRTC */
 	emgd_sysfs_switch_crtc_fb(page_flip_work->emgd_crtc);
@@ -1213,6 +1230,10 @@ static void emgd_unpin_work(struct work_struct *__work)
 	drm_gem_object_unreference(&page_flip_work->new_fb_obj->base);
 	drm_gem_object_unreference(&page_flip_work->old_fb_obj->base);
 	mutex_unlock(&page_flip_work->dev->struct_mutex);
+
+	BUG_ON(atomic_read(&emgd_crtc->unpin_work_count) == 0);
+	atomic_dec(&emgd_crtc->unpin_work_count);
+
 	kfree(page_flip_work);
 }
 
@@ -1265,6 +1286,7 @@ static int emgd_crtc_page_flip(struct drm_crtc *crtc,
 	int                    ret, plane_select = 0;
 	struct drm_device      *dev = crtc->dev;
 	igd_context_t * context = ((drm_emgd_private_t *)dev->dev_private)->context;
+	drm_emgd_private_t    *priv = dev->dev_private;
 
 
 	EMGD_TRACE_ENTER;
@@ -1272,9 +1294,16 @@ static int emgd_crtc_page_flip(struct drm_crtc *crtc,
    	emgd_old_fb = container_of(crtc->fb, emgd_framebuffer_t, base);
    	emgd_new_fb = container_of(fb, emgd_framebuffer_t, base);
 
-   	if (emgd_new_fb->igd_flags & IGD_HDMI_STEREO_3D_MODE) {
-		return emgd_stereo_crtc_page_flip(crtc, fb, event);
-	}
+   	if (emgd_crtc->current_s3d_mode != PD_S3D_MODE_OFF &&
+   		emgd_new_fb->other_bo[0] && emgd_new_fb->other_bo[1])
+   	{
+   		emgd_new_fb->igd_flags |= IGD_HDMI_STEREO_3D_MODE;
+		ret=emgd_stereo_crtc_page_flip(crtc, fb, event);
+		if (ret) {
+			EMGD_ERROR("emgd_stereo_crtc_page_flip failed![%d]", ret);
+			return ret;
+		}
+   	}
 
 	page_flip_work = kzalloc(sizeof(emgd_page_flip_work_t), GFP_KERNEL);
 	if (NULL == page_flip_work) {
@@ -1314,6 +1343,10 @@ static int emgd_crtc_page_flip(struct drm_crtc *crtc,
 
 	spin_unlock_irqrestore(&emgd_crtc->crtc_lock, flags);
 
+	if (atomic_read(&emgd_crtc->unpin_work_count) >= 2) {
+		flush_workqueue(priv->wq);
+	}
+
 	page_flip_work->new_fb_obj = emgd_new_fb->bo;
 
 
@@ -1330,12 +1363,14 @@ static int emgd_crtc_page_flip(struct drm_crtc *crtc,
 		plane_select = 1;
 	}
 
+	atomic_inc(&emgd_crtc->unpin_work_count);
 	atomic_add(1 << plane_select, &page_flip_work->old_fb_obj->pending_flip);
 
-  	ret = context->mode_dispatch->kms_queue_flip(emgd_crtc, emgd_new_fb, 
-    		emgd_new_fb->bo, plane_select);
+	ret = context->mode_dispatch->kms_queue_flip(emgd_crtc, emgd_new_fb,
+			emgd_new_fb->bo, plane_select);
 
 	if (ret) {
+		atomic_dec(&emgd_crtc->unpin_work_count);
 		atomic_sub(1 << plane_select,
 			&page_flip_work->old_fb_obj->pending_flip);
 		drm_gem_object_unreference(&page_flip_work->old_fb_obj->base);
@@ -1376,6 +1411,11 @@ static int emgd_stereo_crtc_page_flip(struct drm_crtc *crtc,
 
   	EMGD_TRACE_ENTER;
 
+  	if(!emgd_crtc->sprite1 || !emgd_crtc->sprite2) {
+  		EMGD_ERROR("Unable to flip, sprite plane in current CRTC is NULL!");
+		return -ENXIO;
+  	}
+
    	emgd_old_fb = container_of(crtc->fb, emgd_framebuffer_t, base);
 
     page_flip_work = kzalloc(sizeof(emgd_page_flip_work_t), GFP_KERNEL);
@@ -1386,7 +1426,8 @@ static int emgd_stereo_crtc_page_flip(struct drm_crtc *crtc,
 
   	mutex_lock(&crtc->dev->struct_mutex);
 
-   	page_flip_work->event      = event;
+  	/* The event will be handled by emgd_crtc_page_flip */
+   	page_flip_work->event      = NULL;
    	page_flip_work->dev        = crtc->dev;
    	page_flip_work->emgd_crtc = emgd_crtc;
    	INIT_WORK(&page_flip_work->work, emgd_unpin_stereo_work);
@@ -1420,14 +1461,18 @@ static int emgd_stereo_crtc_page_flip(struct drm_crtc *crtc,
    	for (i = 0; i < 2; i++) {
     	if (!emgd_crtc->pipe) {
         	/* Pipe A */
+    		/* Sprite A = 0x2
+    		 * Sprite B = 0x3
+    		 */
           	plane_select = 2 + i;
       	} else {
         	/* Pipe B */
-           	/* TODO:  Need to verify the sprite D
-            *        plane select is 0x5 or 0x6.
-            *        B-spec doesn't have this info.
-            */
-           	plane_select = 4 + i;
+      		/* The BSpec doesn't clearly specify the setting for Sprite C and D,
+      		 * but from experiment, this is the setting found
+    		 * Sprite C = 0x5
+    		 * Sprite D = 0x4
+             */
+           	plane_select = 5 - i;
      	}
 
       	page_flip_work->old_stereo_obj[i] = emgd_old_fb->other_bo[i];
@@ -1622,15 +1667,16 @@ static bool intel_crtc_has_pending_flip(struct drm_crtc *crtc)
 {
 	struct drm_device *dev = crtc->dev;
 	drm_emgd_private_t *dev_priv = dev->dev_private;
+	emgd_crtc_t *emgd_crtc = to_emgd_crtc(crtc);
 	unsigned long flags;
 	bool pending;
 
 	if (i915_reset_in_progress(&dev_priv->gpu_error))
 		return false;
 
-	spin_lock_irqsave(&dev->event_lock, flags);
-	pending = to_emgd_crtc(crtc)->flip_pending != NULL;
-	spin_unlock_irqrestore(&dev->event_lock, flags);
+	spin_lock_irqsave(&emgd_crtc->crtc_lock, flags);
+	pending = emgd_crtc->flip_pending != NULL;
+	spin_unlock_irqrestore(&emgd_crtc->crtc_lock, flags);
 
 	return pending;
 }
@@ -1661,7 +1707,9 @@ void emgd_crtc_disable(struct drm_crtc *crtc)
 
 	list_for_each_entry(encoder, &dev->mode_config.encoder_list, head) {
 		encoder_funcs = encoder->helper_private;
-		encoder_funcs->dpms(encoder, DRM_MODE_DPMS_OFF);
+		if(!drm_helper_encoder_in_use(encoder)){
+			encoder_funcs->dpms(encoder, DRM_MODE_DPMS_OFF);
+		}
 	}
 
 	intel_crtc_wait_for_pending_flips(crtc);
@@ -1670,6 +1718,13 @@ void emgd_crtc_disable(struct drm_crtc *crtc)
 	intel_atomic_clear_flips(crtc);
 #endif
 
+	if (crtc->fb) {
+		mutex_lock(&dev->struct_mutex);
+		intel_unpin_fb_obj(to_intel_framebuffer(crtc->fb)->bo);
+		mutex_unlock(&dev->struct_mutex);
+		crtc->fb = NULL;
+	}
+
 	drm_vblank_off(dev, pipe);
 
 	emgd_crtc_dpms(crtc, DRM_MODE_DPMS_OFF);
diff --git a/drivers/gpu/drm/emgd/src/core/emgd_drv.c b/drivers/gpu/drm/emgd/src/core/emgd_drv.c
index ac2d0ed..201ae11 100644
--- a/drivers/gpu/drm/emgd/src/core/emgd_drv.c
+++ b/drivers/gpu/drm/emgd/src/core/emgd_drv.c
@@ -61,7 +61,7 @@
 #endif
 
 #include <linux/backlight.h>
-
+#include "kernel-compat.h"
 /******************************************************************************
  * Formal Declarations
  *****************************************************************************/
@@ -1440,7 +1440,11 @@ int emgd_driver_load(struct drm_device *dev, unsigned long flags)
 		return ret;
 	}
 #else
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,10,0)
+	intel_gtt_get(gtt_total, stolen, mappable_base, mappable_end);
+#else
 	dev_priv->mm.gtt = intel_gtt_get();
+#endif
 	if (!dev_priv->mm.gtt) {
 		EMGD_ERROR("Failed to initialize GTT");
 		ret = -ENODEV;
@@ -1448,11 +1452,11 @@ int emgd_driver_load(struct drm_device *dev, unsigned long flags)
 	}
 #endif
 
-	agp_size = dev_priv->mm.gtt->gtt_mappable_entries << PAGE_SHIFT;
+	agp_size = GTT(dev_priv)->gtt_mappable_entries << PAGE_SHIFT;
 	temp_dev_ctx =  & (((igd_context_t *)drm_HAL_handle)->device_context);
 
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3,4,0)
-	dev_priv->mm.gtt_base_addr = dev_priv->mm.gtt->gma_bus_addr;
+	dev_priv->mm.gtt_base_addr = GTT(dev_priv)->gma_bus_addr;
 	dev_priv->mm.gtt_mapping =
 		io_mapping_create_wc(dev_priv->mm.gtt_base_addr, agp_size);
 #else
@@ -1471,11 +1475,8 @@ int emgd_driver_load(struct drm_device *dev, unsigned long flags)
 		 * generation Core chips because WC PAT gets overridden by a UC
 		 * MTRR if present.  Even if a UC MTRR isn't present.
 		 */
-		/* dev_priv->mm.gtt_mtrr = mtrr_add(temp_dev_ctx->fb_adr,
-				agp_size,
-				MTRR_TYPE_WRCOMB, 1); */
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,4,0)
-		dev_priv->mm.gtt_mtrr = mtrr_add(dev_priv->mm.gtt_base_addr,
+#if LINUX_VERSION_CODE > KERNEL_VERSION(3,4,0)
+		dev_priv->mm.gtt_mtrr = ADD_GTT_MTRR(dev_priv->mm.gtt_base_addr,
 				agp_size,
 				MTRR_TYPE_WRCOMB, 1);
 #else
@@ -1551,8 +1552,8 @@ int emgd_driver_load(struct drm_device *dev, unsigned long flags)
 		io_mapping_free(dev_priv->mm.gtt_mapping);
 		if (dev_priv->mm.gtt_mtrr >= 0) {
 			/* mtrr_del the GMM_ADDR aperture we allocated earlier */
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,4,0)
-			mtrr_del(dev_priv->mm.gtt_mtrr, dev_priv->mm.gtt_base_addr,
+#if LINUX_VERSION_CODE > KERNEL_VERSION(3,4,0)
+			DEL_GTT_MTRR(dev_priv->mm.gtt_mtrr, dev_priv->mm.gtt_base_addr,
 					agp_size);
 #else
 			mtrr_del(dev_priv->mm.gtt_mtrr, dev->agp->base,
@@ -1758,9 +1759,9 @@ int emgd_driver_unload(struct drm_device *dev)
 	/* Free the GTT mapping */
 	io_mapping_free(dev_priv->mm.gtt_mapping);
 	if (dev_priv->mm.gtt_mtrr >= 0) {
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,4,0)
-		mtrr_del(dev_priv->mm.gtt_mtrr, dev_priv->mm.gtt_base_addr,
-				dev_priv->mm.gtt->gtt_mappable_entries * PAGE_SIZE);
+#if LINUX_VERSION_CODE > KERNEL_VERSION(3,4,0)
+		DEL_GTT_MTRR(dev_priv->mm.gtt_mtrr, dev_priv->mm.gtt_base_addr,
+				GTT(dev_priv)->gtt_mappable_entries * PAGE_SIZE);
 #else
 		mtrr_del(dev_priv->mm.gtt_mtrr, dev->agp->base,
 				dev->agp->agp_info.aper_size * 1024 * 1024);
@@ -1976,6 +1977,7 @@ void emgd_driver_lastclose(struct drm_device *dev)
 
 	vga_switcheroo_process_delayed_switch();
 
+	i915_gem_lastclose(dev);
 	EMGD_TRACE_EXIT;
 
 } /* emgd_driver_lastclose() */
@@ -2458,6 +2460,34 @@ irqreturn_t emgd_driver_irq_handler(int irq, void *arg)
 	return ret;
 } /* emgd_driver_irq_handler() */
 
+void i915_check_and_clear_faults(struct drm_device *dev)
+{
+	struct drm_i915_private *dev_priv = dev->dev_private;
+	struct intel_ring_buffer *ring;
+	int i;
+
+	if (INTEL_INFO(dev)->gen < 6)
+		return;
+
+	for_each_ring(ring, dev_priv, i) {
+		u32 fault_reg;
+		fault_reg = I915_READ(RING_FAULT_REG(ring));
+		if (fault_reg & RING_FAULT_VALID) {
+					DRM_DEBUG_DRIVER("Unexpected fault\n"
+					"\tAddr: 0x%08lx\\n"
+					"\tAddress space: %s\n"
+					"\tSource ID: %d\n"
+					"\tType: %d\n",
+					fault_reg & PAGE_MASK,
+					fault_reg & RING_FAULT_GTTSEL_MASK ? "GGTT" : "PPGTT",
+					RING_FAULT_SRCID(fault_reg),
+					RING_FAULT_FAULT_TYPE(fault_reg));
+			I915_WRITE(RING_FAULT_REG(ring),
+				fault_reg & ~RING_FAULT_VALID);
+		}
+	}
+	POSTING_READ(RING_FAULT_REG(&dev_priv->ring[RCS]));
+}
 
 #if LINUX_VERSION_CODE < KERNEL_VERSION(3,4,0)
 static int __devinit emgd_pci_probe(struct pci_dev *pdev,
@@ -2542,6 +2572,13 @@ static int emgd_pm_thaw(struct device *dev)
 	struct pci_dev *pdev = to_pci_dev(dev);
 	struct drm_device *drm_dev= pci_get_drvdata(pdev);
 
+	if (drm_core_check_feature(drm_dev, DRIVER_MODESET)) {
+		mutex_lock(&drm_dev->struct_mutex);
+		i915_gem_restore_gtt_mappings(drm_dev);
+		mutex_unlock(&drm_dev->struct_mutex);
+	} else if (drm_core_check_feature(drm_dev, DRIVER_MODESET))
+		i915_check_and_clear_faults(drm_dev);
+
 	intel_gt_reset(drm_dev);
 
 	return emgd_drm_restore(drm_dev);
@@ -2575,6 +2612,12 @@ static int emgd_pm_restore(struct device *dev)
 
 	pci_set_master(pdev);
 
+	if (drm_core_check_feature(drm_dev, DRIVER_MODESET)) {
+		mutex_lock(&drm_dev->struct_mutex);
+		i915_gem_restore_gtt_mappings(drm_dev);
+		mutex_unlock(&drm_dev->struct_mutex);
+	}
+
 	ret = emgd_drm_restore(drm_dev);
 	if (ret) {
 		return ret;
@@ -2624,6 +2667,7 @@ int emgd_drm_freeze(struct drm_device *dev)
 	}
 
 	intel_disable_gt_powersave(dev);
+	i915_gem_restore_gtt_mappings(dev);
 
 	/* When the system is suspended, the X server does a VT switch, which saves
 	 * the register state of the X server, and restores the console's register
diff --git a/drivers/gpu/drm/emgd/src/core/emgd_fb.c b/drivers/gpu/drm/emgd/src/core/emgd_fb.c
index fe0b3e2..590d821 100644
--- a/drivers/gpu/drm/emgd/src/core/emgd_fb.c
+++ b/drivers/gpu/drm/emgd/src/core/emgd_fb.c
@@ -1391,8 +1391,8 @@ static void emgd_user_framebuffer_destroy (struct drm_framebuffer *fb)
 	drm_gem_object_unreference_unlocked(&emgd_fb->bo->base);
 
 	for (i=0; i < 3; i++){
-		if(emgd_fb->other_bo[i]) {
-			drm_gem_object_unreference_unlocked(&emgd_fb->other_bo[i]->base);
+		if(emgd_fb->other_bo[i] && !emgd_fb->other_bo[i]->pin_count) {
+				drm_gem_object_unreference_unlocked(&emgd_fb->other_bo[i]->base);
 		}
 	}
 
diff --git a/drivers/gpu/drm/emgd/src/core/emgd_fbcon.c b/drivers/gpu/drm/emgd/src/core/emgd_fbcon.c
index 434c2c8..a207d45 100644
--- a/drivers/gpu/drm/emgd/src/core/emgd_fbcon.c
+++ b/drivers/gpu/drm/emgd/src/core/emgd_fbcon.c
@@ -998,6 +998,11 @@ int emgd_fbcon_initial_config(emgd_fbdev_t *emgd_fbdev, int alloc_fb)
 	struct drm_device     *dev          = emgd_fbdev->priv->dev;
 	drm_emgd_private_t    *priv         = emgd_fbdev->priv;
 	struct drm_display_mode mode, new_mode;
+	int hdisplay = -1;
+	int vdisplay = -1;
+	int adjusted_hdisplay = -1;
+	int adjusted_vdisplay = -1;
+	bool get_mode_initial_fb = true;
 	struct drm_encoder_helper_funcs *encoder_funcs;
 	struct drm_crtc_helper_funcs *crtc_funcs = NULL;
 	bool                   new_mode_valid = false;
@@ -1072,8 +1077,16 @@ int emgd_fbcon_initial_config(emgd_fbdev_t *emgd_fbdev, int alloc_fb)
 
 			/* Capture currently attach fb so we can unpin it */
 			oldfb = crtc->fb;
+#if LINUX_VERSION_CODE > KERNEL_VERSION(3, 4, 0)
+			if (oldfb)
+				drm_framebuffer_unreference(oldfb);
+#endif
 
 			crtc->fb = &emgd_fbdev->emgd_fb->base;
+#if LINUX_VERSION_CODE > KERNEL_VERSION(3, 4, 0)
+			if (crtc->fb)
+				drm_framebuffer_reference(crtc->fb);
+#endif
 
 			/* Set the basic parameters to look up the mode */
 			memset(&new_mode, 0, sizeof(new_mode));
@@ -1141,6 +1154,8 @@ int emgd_fbcon_initial_config(emgd_fbdev_t *emgd_fbdev, int alloc_fb)
 				}
 			}
 
+			if (!crtc->fb)
+				return -ENOMEM;
 			if(mode.crtc_hdisplay <= crtc->fb->width) { /* CRTC <= FB */
                                 if(mode.crtc_hdisplay + x > crtc->fb->width) { /* Check if offset creates FB out of bounds */
                                         x = crtc->fb->width - mode.crtc_hdisplay; /* Truncate offset to max allowable */
@@ -1224,17 +1239,50 @@ int emgd_fbcon_initial_config(emgd_fbdev_t *emgd_fbdev, int alloc_fb)
 			if (mode_set_ret == FALSE) {
 				EMGD_ERROR("Failed to set mode on CRTC.");
 			}
+
+			/* save width/height of 1st crtc, to init fb console */
+			if (get_mode_initial_fb) {
+				get_mode_initial_fb = false;
+				hdisplay = mode.crtc_hdisplay;
+				vdisplay = mode.crtc_vdisplay;
+
+				/* if  we cannot get valid width/height, try to fall back to pipe timing. 
+				 * when no timing matched, assume there is a fall safe timing in pipe.
+				*/
+				if (!((new_mode.crtc_hdisplay > 0) && (new_mode.crtc_vdisplay > 0))) {
+					EMGD_ERROR("No valid timing, fall back to pipe timing.");
+					igd_timing_info_t * pipe_timing = PIPE(emgd_crtc)->timing;
+
+					if (pipe_timing) {
+						if ((pipe_timing->width > 0) && (pipe_timing->height > 0)) {
+							adjusted_hdisplay = pipe_timing->width;
+							adjusted_vdisplay = pipe_timing->height;
+						}
+					} else {
+						EMGD_ERROR("Pipe timing fall back failed.");
+						/* Try to go for built in defaults, instead leave it initialized -1. */
+						adjusted_hdisplay = CONFIG_DEFAULT_WIDTH;
+						adjusted_vdisplay = CONFIG_DEFAULT_HEIGHT;
+					}
+				} else {
+					adjusted_hdisplay = new_mode.crtc_hdisplay;
+					adjusted_vdisplay = new_mode.crtc_vdisplay;
+				}
+			}
 		}
 	}
 	EMGD_DEBUG("DONE Attaching FB with all CRTCs");
 
 	/* When doing centering, make sure the value var.xres and var.yres have to be
          * the same as the newly updated crtc before passing into register_framebuffer()*/
+	/* Pass info of first crtc to register_framebuffer(), fb console use width/height of first crtc.
+	   when there is more than 1 crtc, need to save timing for 1st crtc by hdisplay, vdisplay,
+	   adjusted_hdisplay, and adjusted_vdisplay */
         if(drm_emgd_display_width > drm_emgd_width || drm_emgd_display_height > drm_emgd_height){  /*Check for centering*/
-                if(mode.crtc_hdisplay != new_mode.crtc_hdisplay || mode.crtc_vdisplay != new_mode.crtc_vdisplay){
-                        emgd_fbdev->priv->fbdev->var.xres = new_mode.crtc_hdisplay;
-                        emgd_fbdev->priv->fbdev->var.yres = new_mode.crtc_vdisplay;
-                }
+			if (hdisplay != adjusted_hdisplay || vdisplay != adjusted_vdisplay) {
+	                    emgd_fbdev->priv->fbdev->var.xres = adjusted_hdisplay;
+	                    emgd_fbdev->priv->fbdev->var.yres = adjusted_vdisplay;
+			}
         }
 
 
diff --git a/drivers/gpu/drm/emgd/src/core/emgd_ovl.c b/drivers/gpu/drm/emgd/src/core/emgd_ovl.c
index b2a6715..3d71305 100644
--- a/drivers/gpu/drm/emgd/src/core/emgd_ovl.c
+++ b/drivers/gpu/drm/emgd/src/core/emgd_ovl.c
@@ -2035,10 +2035,91 @@ int emgd_overlay_planes_shutdown(struct drm_device *dev,
 	return 0;
 }
 
-#if 0
 #ifdef CONFIG_DEBUG_FS
 #include <linux/seq_file.h>
 
+
+/* polyphase filter coefficients */
+#define N_HORIZ_Y_TAPS          5
+#define N_VERT_Y_TAPS           3
+#define N_HORIZ_UV_TAPS         3
+#define N_VERT_UV_TAPS          3
+#define N_PHASES                17
+
+/* memory bufferd overlay registers */
+struct overlay_registers {
+        u32 OBUF_0Y;
+        u32 OBUF_1Y;
+        u32 OBUF_0U;
+        u32 OBUF_0V;
+        u32 OBUF_1U;
+        u32 OBUF_1V;
+        u32 OSTRIDE;
+        u32 YRGB_VPH;
+        u32 UV_VPH;
+        u32 HORZ_PH;
+        u32 INIT_PHS;
+        u32 DWINPOS;
+        u32 DWINSZ;
+        u32 SWIDTH;
+        u32 SWIDTHSW;
+        u32 SHEIGHT;
+        u32 YRGBSCALE;
+        u32 UVSCALE;
+        u32 OCLRC0;
+        u32 OCLRC1;
+        u32 DCLRKV;
+        u32 DCLRKM;
+        u32 SCLRKVH;
+        u32 SCLRKVL;
+        u32 SCLRKEN;
+        u32 OCONFIG;
+        u32 OCMD;
+        u32 RESERVED1; /* 0x6C */
+        u32 OSTART_0Y;
+        u32 OSTART_1Y;
+        u32 OSTART_0U;
+        u32 OSTART_0V;
+        u32 OSTART_1U;
+        u32 OSTART_1V;
+        u32 OTILEOFF_0Y;
+        u32 OTILEOFF_1Y;
+        u32 OTILEOFF_0U;
+        u32 OTILEOFF_0V;
+        u32 OTILEOFF_1U;
+        u32 OTILEOFF_1V;
+        u32 FASTHSCALE; /* 0xA0 */
+        u32 UVSCALEV; /* 0xA4 */
+        u32 RESERVEDC[(0x200 - 0xA8) / 4]; /* 0xA8 - 0x1FC */
+        u16 Y_VCOEFS[N_VERT_Y_TAPS * N_PHASES]; /* 0x200 */
+        u16 RESERVEDD[0x100 / 2 - N_VERT_Y_TAPS * N_PHASES];
+        u16 Y_HCOEFS[N_HORIZ_Y_TAPS * N_PHASES]; /* 0x300 */
+        u16 RESERVEDE[0x200 / 2 - N_HORIZ_Y_TAPS * N_PHASES];
+        u16 UV_VCOEFS[N_VERT_UV_TAPS * N_PHASES]; /* 0x500 */
+        u16 RESERVEDF[0x100 / 2 - N_VERT_UV_TAPS * N_PHASES];
+        u16 UV_HCOEFS[N_HORIZ_UV_TAPS * N_PHASES]; /* 0x600 */
+        u16 RESERVEDG[0x100 / 2 - N_HORIZ_UV_TAPS * N_PHASES];
+};
+
+struct intel_overlay {
+        struct drm_device *dev;
+        struct intel_crtc *crtc;
+        struct drm_i915_gem_object *vid_bo;
+        struct drm_i915_gem_object *old_vid_bo;
+        int active;
+        int pfit_active;
+        u32 pfit_vscale_ratio; /* shifted-point number, (1<<12) == 1.0 */
+        u32 color_key;
+        u32 brightness, contrast, saturation;
+        u32 old_xscale, old_yscale;
+        /* register access */
+        u32 flip_addr;
+        struct drm_i915_gem_object *reg_bo;
+        /* flip handling */
+        uint32_t last_flip_req;
+        void (*flip_tail)(struct intel_overlay *);
+};
+
 struct intel_overlay_error_state {
 	struct overlay_registers regs;
 	unsigned long base;
@@ -2158,4 +2239,3 @@ intel_overlay_print_error_state(struct seq_file *m, struct intel_overlay_error_s
 #undef P
 }
 #endif
-#endif
diff --git a/drivers/gpu/drm/emgd/src/core/emgd_sysfs.c b/drivers/gpu/drm/emgd/src/core/emgd_sysfs.c
index 5ce1b60..061296c 100644
--- a/drivers/gpu/drm/emgd/src/core/emgd_sysfs.c
+++ b/drivers/gpu/drm/emgd/src/core/emgd_sysfs.c
@@ -819,7 +819,7 @@ ssize_t emgd_lock_plane(struct drm_device *dev, emgd_crtc_t *emgd_crtc)
 	emgd_crtc->unfreeze_yoffset = emgd_crtc->igd_plane->yoffset;
 
 	/* Flip the plane to the static copy */
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,4,0)
 	/* For kernel >= 3.7, ioremap_wc is used to map the buffer through
 	 * the Gfx Aperture. For tiled and fenced buffer, it will be read out
 	 * as linear by memcpy because it was mapped through Gfx Aperture.
@@ -1337,6 +1337,9 @@ static ssize_t emgd_gemsched_shared_show(emgd_obj_t *emgd, emgd_attribute_t *att
 	if (strncmp(attr->attr.name, "period", 6) == 0) {
 		return scnprintf(buf, PAGE_SIZE, "%06dms\n",
 			(dev_priv->scheduler.shared_period/1000));
+	} else if(strncmp(attr->attr.name, "aereserve", 9) == 0) {
+		return scnprintf(buf, PAGE_SIZE, "%d\n",
+			(int)dev_priv->scheduler.shared_aereserve);
 	} else if(strncmp(attr->attr.name, "capacity", 8) == 0) {
 		return scnprintf(buf, PAGE_SIZE, "%06dms\n",
 			(dev_priv->scheduler.shared_capacity/1000));
@@ -1364,6 +1367,9 @@ static ssize_t emgd_gemsched_shared_store(emgd_obj_t *emgd,
 			dev_priv->scheduler.shared_period = (value*1000);
 			EMGD_DEBUG("New shared period = %d\n", value);
 		}
+	} else if(strncmp(attr->attr.name, "aereserve", 9) == 0) {
+		dev_priv->scheduler.shared_aereserve = value? true: false;
+		EMGD_DEBUG("New shared AE reservation = %d\n", (value? 1:0));
 	} else if(strncmp(attr->attr.name, "capacity", 8) == 0) {
 		if (dev_priv->scheduler.shared_capacity != (value*1000)) {
 			ret = i915_gpu_idle(dev_priv->dev);
@@ -1851,9 +1857,12 @@ static emgd_attribute_t emgd_gemsched_shared_period_attribute =
 	__ATTR(period,   0664, emgd_gemsched_shared_show, emgd_gemsched_shared_store);
 static emgd_attribute_t emgd_gemsched_shared_capacity_attribute =
 	__ATTR(capacity, 0664, emgd_gemsched_shared_show, emgd_gemsched_shared_store);
+static emgd_attribute_t emgd_gemsched_shared_aereserve_attribute =
+	__ATTR(aereserve, 0664, emgd_gemsched_shared_show, emgd_gemsched_shared_store);
 static struct attribute *emgd_gemsched_shared_attrs[] = {
 	&emgd_gemsched_shared_period_attribute.attr,
 	&emgd_gemsched_shared_capacity_attribute.attr,
+	&emgd_gemsched_shared_aereserve_attribute.attr,
 	NULL,
 };
 
diff --git a/drivers/gpu/drm/emgd/src/core/i915/i915_debugfs.c b/drivers/gpu/drm/emgd/src/core/i915/i915_debugfs.c
index d364937..331d368 100644
--- a/drivers/gpu/drm/emgd/src/core/i915/i915_debugfs.c
+++ b/drivers/gpu/drm/emgd/src/core/i915/i915_debugfs.c
@@ -31,6 +31,7 @@
 #include <linux/debugfs.h>
 #include <linux/slab.h>
 #include <linux/export.h>
+#include <generated/utsrelease.h>
 #include "drmP.h"
 #if LINUX_VERSION_CODE < KERNEL_VERSION(3,4,0)
 #include "drm.h"
@@ -766,127 +767,224 @@ static void print_error_buffers(struct seq_file *m,
 	}
 }
 
+
+static void i915_ring_error_state(struct seq_file *m,
+                                  struct drm_device *dev,
+                                  struct drm_i915_error_state *error,
+                                  unsigned ring)
+{
+        BUG_ON(ring >= I915_NUM_RINGS); /* shut up confused gcc */
+        seq_printf(m, "%s command stream:\n", ring_str(ring));
+        seq_printf(m, "  HEAD: 0x%08x\n", error->head[ring]);
+        seq_printf(m, "  TAIL: 0x%08x\n", error->tail[ring]);
+        seq_printf(m, "  CTL: 0x%08x\n", error->ctl[ring]);
+        seq_printf(m, "  ACTHD: 0x%08x\n", error->acthd[ring]);
+        seq_printf(m, "  IPEIR: 0x%08x\n", error->ipeir[ring]);
+        seq_printf(m, "  IPEHR: 0x%08x\n", error->ipehr[ring]);
+        seq_printf(m, "  INSTDONE: 0x%08x\n", error->instdone[ring]);
+        if (ring == RCS && INTEL_INFO(dev)->gen >= 4)
+                seq_printf(m, "  BBADDR: 0x%08llx\n", error->bbaddr);
+
+        if (INTEL_INFO(dev)->gen >= 4)
+                seq_printf(m, "  INSTPS: 0x%08x\n", error->instps[ring]);
+        seq_printf(m, "  INSTPM: 0x%08x\n", error->instpm[ring]);
+        seq_printf(m, "  FADDR: 0x%08x\n", error->faddr[ring]);
+        if (INTEL_INFO(dev)->gen >= 6) {
+                seq_printf(m, "  RC PSMI: 0x%08x\n", error->rc_psmi[ring]);
+                seq_printf(m, "  FAULT_REG: 0x%08x\n", error->fault_reg[ring]);
+                seq_printf(m, "  SYNC_0: 0x%08x [last synced 0x%08x]\n",
+                           error->semaphore_mboxes[ring][0],
+                           error->semaphore_seqno[ring][0]);
+                seq_printf(m, "  SYNC_1: 0x%08x [last synced 0x%08x]\n",
+                           error->semaphore_mboxes[ring][1],
+                           error->semaphore_seqno[ring][1]);
+        }
+        seq_printf(m, "  seqno: 0x%08x\n", error->seqno[ring]);
+        seq_printf(m, "  waiting: %s\n", yesno(error->waiting[ring]));
+        seq_printf(m, "  ring->head: 0x%08x\n", error->cpu_ring_head[ring]);
+        seq_printf(m, "  ring->tail: 0x%08x\n", error->cpu_ring_tail[ring]);
+}
+
+struct i915_error_state_file_priv {
+        struct drm_device *dev;
+        struct drm_i915_error_state *error;
+};
+
 static int i915_error_state(struct seq_file *m, void *unused)
 {
-	struct drm_info_node *node = (struct drm_info_node *) m->private;
-	struct drm_device *dev = node->minor->dev;
-	drm_i915_private_t *dev_priv = dev->dev_private;
-	struct drm_i915_error_state *error;
-	unsigned long flags;
-	int i, page, offset, elt;
+        struct i915_error_state_file_priv *error_priv = m->private;
+        struct drm_device *dev = error_priv->dev;
+        drm_i915_private_t *dev_priv = dev->dev_private;
+        struct drm_i915_error_state *error = error_priv->error;
+        struct intel_ring_buffer *ring;
+        int i, j, page, offset, elt;
 
-	spin_lock_irqsave(&dev_priv->gpu_error.lock, flags);
-	if (!dev_priv->gpu_error.first_error) {
-		seq_printf(m, "no error state collected\n");
-		goto out;
-	}
+        if (!error) {
+                seq_printf(m, "no error state collected\n");
+                return 0;
+        }
 
-	error = dev_priv->gpu_error.first_error;
-
-	seq_printf(m, "Time: %ld s %ld us\n", error->time.tv_sec,
-		   error->time.tv_usec);
-	seq_printf(m, "PCI ID: 0x%04x\n", dev->pci_device);
-	seq_printf(m, "EIR: 0x%08x\n", error->eir);
-	seq_printf(m, "IER: 0x%08x\n", error->ier);
-	seq_printf(m, "PGTBL_ER: 0x%08x\n", error->pgtbl_er);
-	if (INTEL_INFO(dev)->gen >= 6) {
-		seq_printf(m, "ERROR: 0x%08x\n", error->error);
-		seq_printf(m, "Blitter command stream:\n");
-		seq_printf(m, "  ACTHD:    0x%08x\n", error->bcs_acthd);
-		seq_printf(m, "  IPEIR:    0x%08x\n", error->bcs_ipeir);
-		seq_printf(m, "  IPEHR:    0x%08x\n", error->bcs_ipehr);
-		seq_printf(m, "  INSTDONE: 0x%08x\n", error->bcs_instdone);
-		seq_printf(m, "  seqno:    0x%08x\n", error->bcs_seqno);
-		seq_printf(m, "Video (BSD) command stream:\n");
-		seq_printf(m, "  ACTHD:    0x%08x\n", error->vcs_acthd);
-		seq_printf(m, "  IPEIR:    0x%08x\n", error->vcs_ipeir);
-		seq_printf(m, "  IPEHR:    0x%08x\n", error->vcs_ipehr);
-		seq_printf(m, "  INSTDONE: 0x%08x\n", error->vcs_instdone);
-		seq_printf(m, "  seqno:    0x%08x\n", error->vcs_seqno);
-	}
-	seq_printf(m, "Render command stream:\n");
-	seq_printf(m, "  ACTHD: 0x%08x\n", error->acthd);
-	seq_printf(m, "  IPEIR: 0x%08x\n", error->ipeir);
-	seq_printf(m, "  IPEHR: 0x%08x\n", error->ipehr);
-	seq_printf(m, "  INSTDONE: 0x%08x\n", error->instdone);
-	if (INTEL_INFO(dev)->gen >= 4) {
-		seq_printf(m, "  INSTPS: 0x%08x\n", error->instps);
+        seq_printf(m, "Time: %ld s %ld us\n", error->time.tv_sec,
+                   error->time.tv_usec);
+        seq_printf(m, "Kernel: " UTS_RELEASE);
+        seq_printf(m, "PCI ID: 0x%04x\n", dev->pci_device);
+        seq_printf(m, "EIR: 0x%08x\n", error->eir);
+        seq_printf(m, "IER: 0x%08x\n", error->ier);
+        seq_printf(m, "PGTBL_ER: 0x%08x\n", error->pgtbl_er);
+        seq_printf(m, "FORCEWAKE: 0x%08x\n", error->forcewake);
+        seq_printf(m, "DERRMR: 0x%08x\n", error->derrmr);
+        seq_printf(m, "CCID: 0x%08x\n", error->ccid);
+
+        for (i = 0; i < dev_priv->num_fence_regs; i++)
+                seq_printf(m, "  fence[%d] = %08llx\n", i, error->fence[i]);
+
+        for (i = 0; i < ARRAY_SIZE(error->extra_instdone); i++)
+                seq_printf(m, "  INSTDONE_%d: 0x%08x\n", i, error->extra_instdone[i]);
+
+        if (INTEL_INFO(dev)->gen >= 6) {
+                seq_printf(m, "ERROR: 0x%08x\n", error->error);
+                seq_printf(m, "DONE_REG: 0x%08x\n", error->done_reg);
+        }
+
+        if (INTEL_INFO(dev)->gen == 7)
+                seq_printf(m, "ERR_INT: 0x%08x\n", error->err_int);
+
+        for_each_ring(ring, dev_priv, i)
+                i915_ring_error_state(m, dev, error, i);
+
+        if (error->active_bo)
+                print_error_buffers(m, "Active",
+                                    error->active_bo,
+                                    error->active_bo_count);
+
+        if (error->pinned_bo)
+                print_error_buffers(m, "Pinned",
+                                    error->pinned_bo,
+                                    error->pinned_bo_count);
+
+        for (i = 0; i < ARRAY_SIZE(error->ring); i++) {
+                struct drm_i915_error_object *obj;
+
+                if ((obj = error->ring[i].batchbuffer)) {
+                        seq_printf(m, "%s --- gtt_offset = 0x%08x\n",
+                                   dev_priv->ring[i].name,
+                                   obj->gtt_offset);
+                        offset = 0;
+                        for (page = 0; page < obj->page_count; page++) {
+                                for (elt = 0; elt < PAGE_SIZE/4; elt++) {
+                                        seq_printf(m, "%08x :  %08x\n", offset, obj->pages[page][elt]);
+                                        offset += 4;
+                                }
+                        }
+                }
+
+                if (error->ring[i].num_requests) {
+                        seq_printf(m, "%s --- %d requests\n",
+                                   dev_priv->ring[i].name,
+                                   error->ring[i].num_requests);
+                        for (j = 0; j < error->ring[i].num_requests; j++) {
+                                seq_printf(m, "  seqno 0x%08x, emitted %ld, tail 0x%08x\n",
+                                           error->ring[i].requests[j].seqno,
+                                           error->ring[i].requests[j].jiffies,
+                                           error->ring[i].requests[j].tail);
+                        }
+                }
+
+                if ((obj = error->ring[i].ringbuffer)) {
+                        seq_printf(m, "%s --- ringbuffer = 0x%08x\n",
+                                   dev_priv->ring[i].name,
+                                   obj->gtt_offset);
+                        offset = 0;
+                        for (page = 0; page < obj->page_count; page++) {
+                                for (elt = 0; elt < PAGE_SIZE/4; elt++) {
+                                        seq_printf(m, "%08x :  %08x\n",
+                                                   offset,
+                                                   obj->pages[page][elt]);
+                                        offset += 4;
+                                }
+                        }
+                }
+        }
+
+	if (error->overlay) {
+                intel_overlay_print_error_state(m, error->overlay);
+	}              
+
+        if (error->display) {
+                intel_display_print_error_state(m, dev, error->display);
 	}
-	seq_printf(m, "  INSTPM: 0x%08x\n", error->instpm);
-	seq_printf(m, "  seqno: 0x%08x\n", error->seqno);
 
-	for (i = 0; i < dev_priv->num_fence_regs; i++)
-		seq_printf(m, "  fence[%d] = %08llx\n", i, error->fence[i]);
+        return 0;
+}
 
-	for (i = 0; i < ARRAY_SIZE(error->extra_instdone); i++)
-		seq_printf(m, "  INSTDONE_%d: 0x%08x\n", i, error->extra_instdone[i]);
+static ssize_t
+i915_error_state_write(struct file *filp,
+                       const char __user *ubuf,
+                       size_t cnt,
+                       loff_t *ppos)
+{
+        struct seq_file *m = filp->private_data;
+        struct i915_error_state_file_priv *error_priv = m->private;
+        struct drm_device *dev = error_priv->dev;
+        int ret;
 
-	if (error->active_bo)
-		print_error_buffers(m, "Active",
-				    error->active_bo,
-				    error->active_bo_count);
+        DRM_DEBUG_DRIVER("Resetting error state\n");
 
-	if (error->pinned_bo)
-		print_error_buffers(m, "Pinned",
-				    error->pinned_bo,
-				    error->pinned_bo_count);
+        ret = mutex_lock_interruptible(&dev->struct_mutex);
+        if (ret)
+                return ret;
 
-	for (i = 0; i < ARRAY_SIZE(error->batchbuffer); i++) {
-		if(!(i < I915_NUM_RINGS)){
-                        seq_printf(m,"Attempting to execute beyond ringbuffer array");
-                }
-		
-		if (error->batchbuffer[i]) {
-			struct drm_i915_error_object *obj = error->batchbuffer[i];
+        i915_destroy_error_state(dev);
+        mutex_unlock(&dev->struct_mutex);
 
-			seq_printf(m, "%s --- gtt_offset = 0x%08x\n",
-				   dev_priv->ring[i].name,
-				   obj->gtt_offset);
-			offset = 0;
-			for (page = 0; page < obj->page_count; page++) {
-				for (elt = 0; elt < PAGE_SIZE/4; elt++) {
-					seq_printf(m, "%08x :  %08x\n", offset, obj->pages[page][elt]);
-					offset += 4;
-				}
-			}
-		}
-	}
+        return cnt;
+}
 
-	for (i = 0; i < ARRAY_SIZE(error->ringbuffer); i++) {
-		if(!(i < I915_NUM_RINGS)){
-                        seq_printf(m,"Attempting to execute beyond ringbuffer array");
-                }
 
-		if (error->ringbuffer[i]) {
-			struct drm_i915_error_object *obj = error->ringbuffer[i];
-			seq_printf(m, "%s --- ringbuffer = 0x%08x\n",
-				   dev_priv->ring[i].name,
-				   obj->gtt_offset);
-			offset = 0;
-			for (page = 0; page < obj->page_count; page++) {
-				for (elt = 0; elt < PAGE_SIZE/4; elt++) {
-					seq_printf(m, "%08x :  %08x\n",
-						   offset,
-						   obj->pages[page][elt]);
-					offset += 4;
-				}
-			}
-		}
-	}
+static int i915_error_state_open(struct inode *inode, struct file *file)
+{
+        struct drm_device *dev = inode->i_private;
+        drm_i915_private_t *dev_priv = dev->dev_private;
+        struct i915_error_state_file_priv *error_priv;
+        unsigned long flags;
 
-	if (error->overlay) {
-		//intel_overlay_print_error_state(m, error->overlay);
-	}
+        error_priv = kzalloc(sizeof(*error_priv), GFP_KERNEL);
+        if (!error_priv)
+                return -ENOMEM;
 
-	if (error->display)
-		intel_display_print_error_state(m, dev, error->display);
+        error_priv->dev = dev;
 
-out:
-	spin_unlock_irqrestore(&dev_priv->gpu_error.lock, flags);
+        spin_lock_irqsave(&dev_priv->error_lock, flags);
+        error_priv->error = dev_priv->first_error;
+        if (error_priv->error)
+                kref_get(&error_priv->error->ref);
+        spin_unlock_irqrestore(&dev_priv->error_lock, flags);
 
-	return 0;
+        return single_open(file, i915_error_state, error_priv);
+}
+
+static int i915_error_state_release(struct inode *inode, struct file *file)
+{
+
+        struct seq_file *m = file->private_data;
+        struct i915_error_state_file_priv *error_priv = m->private;
+
+        if (error_priv->error)
+                kref_put(&error_priv->error->ref, i915_error_state_free);
+        kfree(error_priv);
+
+        return single_release(inode, file);
 }
 
+static const struct file_operations i915_error_state_fops = {
+        .owner = THIS_MODULE,
+        .open = i915_error_state_open,
+        .read = seq_read,
+        .write = i915_error_state_write,
+        .llseek = default_llseek,
+        .release = i915_error_state_release,
+};
+
 static int
 i915_debugfs_common_open(struct inode *inode,
 						 struct file *filp)
@@ -2197,7 +2295,6 @@ static struct drm_info_list i915_debugfs_list[] = {
 	{"i915_blt_ringbuffer_data", i915_ringbuffer_data, 0, (void *)BCS},
 	{"i915_blt_ringbuffer_info", i915_ringbuffer_info, 0, (void *)BCS},
 	{"i915_batchbuffers", i915_batchbuffer_info, 0},
-	{"i915_error_state", i915_error_state, 0},
 	{"i915_rstdby_delays", i915_rstdby_delays, 0},
 	{"i915_cur_delayinfo", i915_cur_delayinfo, 0},
 	{"i915_delayfreq_table", i915_delayfreq_table, 0},
@@ -2261,6 +2358,12 @@ int i915_debugfs_init(struct drm_minor *minor)
 	if (ret)
 		return ret;
 
+	ret = i915_debugfs_create(minor->debugfs_root, minor,
+                                  "i915_error_state",
+                                  &i915_error_state_fops);
+	if (ret)
+		return ret;
+
 	return drm_debugfs_create_files(i915_debugfs_list,
 					I915_DEBUGFS_ENTRIES,
 					minor->debugfs_root, minor);
@@ -2284,6 +2387,9 @@ void i915_debugfs_cleanup(struct drm_minor *minor)
 				 1, minor);
 	drm_debugfs_remove_files((struct drm_info_list *) &i915_next_seqno_fops,
 				 1, minor);
+
+	drm_debugfs_remove_files((struct drm_info_list *) &i915_error_state_fops,
+                                 1, minor);
 }
 
 #endif /* CONFIG_DEBUG_FS */
diff --git a/drivers/gpu/drm/emgd/src/core/i915/i915_emgd_helper.c b/drivers/gpu/drm/emgd/src/core/i915/i915_emgd_helper.c
index 69088b9..c766b64 100644
--- a/drivers/gpu/drm/emgd/src/core/i915/i915_emgd_helper.c
+++ b/drivers/gpu/drm/emgd/src/core/i915/i915_emgd_helper.c
@@ -149,6 +149,478 @@ static void i915_get_extra_instdone(struct drm_device *dev,
 	}
 }
 
+#ifdef CONFIG_DEBUG_FS
+static struct drm_i915_error_object *
+i915_error_object_create(struct drm_i915_private *dev_priv,
+                         struct drm_i915_gem_object *src)
+{
+        struct drm_i915_error_object *dst;
+        int i, count;
+        u32 reloc_offset;
+
+        if (src == NULL || src->pages == NULL)
+                return NULL;
+
+        count = src->base.size / PAGE_SIZE;
+
+        dst = kmalloc(sizeof(*dst) + count * sizeof(u32 *), GFP_ATOMIC);
+        if (dst == NULL)
+                return NULL;
+
+        reloc_offset = src->gtt_offset;
+        for (i = 0; i < count; i++) {
+                unsigned long flags;
+                void *d;
+
+                d = kmalloc(PAGE_SIZE, GFP_ATOMIC);
+                if (d == NULL)
+                        goto unwind;
+
+                local_irq_save(flags);
+                if (reloc_offset < dev_priv->mm.gtt_mappable_end &&
+                    src->has_global_gtt_mapping) {
+                        void __iomem *s;
+
+                        /* Simply ignore tiling or any overlapping fence.
+ 			 * It's part of the error state, and this hopefully
+                         * captures what the GPU read.
+			 */
+
+                        s = io_mapping_map_atomic_wc(dev_priv->mm.gtt_mapping,
+                                                     reloc_offset);
+                        memcpy_fromio(d, s, PAGE_SIZE);
+                        io_mapping_unmap_atomic(s);
+                } else {
+			void *s;
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,4,0))
+                        struct page *page;
+                        page = i915_gem_object_get_page(src, i);
+
+                        drm_clflush_pages(&page, 1);
+
+                        s = kmap_atomic(page);
+                        memcpy(d, s, PAGE_SIZE);
+                        kunmap_atomic(s);
+
+                        drm_clflush_pages(&page, 1);
+#else
+                        drm_clflush_pages(&src->pages[i], 1);
+
+                        s = kmap_atomic(src->pages[i]);
+                        memcpy(d, s, PAGE_SIZE);
+                        kunmap_atomic(s);
+
+                        drm_clflush_pages(&src->pages[i], 1);
+#endif
+                }
+                local_irq_restore(flags);
+
+                dst->pages[i] = d;
+
+                reloc_offset += PAGE_SIZE;
+        }
+        dst->page_count = count;
+        dst->gtt_offset = src->gtt_offset;
+
+        return dst;
+
+unwind:
+        while (i--)
+                kfree(dst->pages[i]);
+        kfree(dst);
+        return NULL;
+}
+
+static void
+i915_error_object_free(struct drm_i915_error_object *obj)
+{
+        int page;
+
+        if (obj == NULL)
+                return;
+
+        for (page = 0; page < obj->page_count; page++)
+                kfree(obj->pages[page]);
+
+        kfree(obj);
+}
+
+void
+i915_error_state_free(struct kref *error_ref)
+{
+        struct drm_i915_error_state *error = container_of(error_ref,
+                                                          typeof(*error), ref);
+        int i;
+
+        for (i = 0; i < ARRAY_SIZE(error->ring); i++) {
+                i915_error_object_free(error->ring[i].batchbuffer);
+                i915_error_object_free(error->ring[i].ringbuffer);
+                kfree(error->ring[i].requests);
+        }
+
+        kfree(error->active_bo);
+        kfree(error->overlay);
+        kfree(error->display);
+        kfree(error);
+}
+
+static void capture_bo(struct drm_i915_error_buffer *err,
+                       struct drm_i915_gem_object *obj)
+{
+        err->size = obj->base.size;
+        err->name = obj->base.name;
+        err->rseqno = obj->last_read_seqno;
+        err->wseqno = obj->last_write_seqno;
+        err->gtt_offset = obj->gtt_offset;
+        err->read_domains = obj->base.read_domains;
+        err->write_domain = obj->base.write_domain;
+        err->fence_reg = obj->fence_reg;
+        err->pinned = 0;
+        if (obj->pin_count > 0)
+                err->pinned = 1;
+        if (obj->user_pin_count > 0)
+                err->pinned = -1;
+        err->tiling = obj->tiling_mode;
+        err->dirty = obj->dirty;
+        err->purgeable = obj->madv != I915_MADV_WILLNEED;
+        err->ring = obj->ring ? obj->ring->id : -1;
+        err->cache_level = obj->cache_level;
+}
+
+static u32 capture_active_bo(struct drm_i915_error_buffer *err,
+                             int count, struct list_head *head)
+{
+        struct drm_i915_gem_object *obj;
+        int i = 0;
+
+        list_for_each_entry(obj, head, mm_list) {
+                capture_bo(err++, obj);
+                if (++i == count)
+                        break;
+        }
+
+        return i;
+}
+
+static u32 capture_pinned_bo(struct drm_i915_error_buffer *err,
+                             int count, struct list_head *head)
+{
+        struct drm_i915_gem_object *obj;
+        int i = 0;
+
+        list_for_each_entry(obj, head, gtt_list) {
+                if (obj->pin_count == 0)
+                        continue;
+
+                capture_bo(err++, obj);
+                if (++i == count)
+                        break;
+        }
+
+        return i;
+}
+
+static void i915_gem_record_fences(struct drm_device *dev,
+                                   struct drm_i915_error_state *error)
+{
+        struct drm_i915_private *dev_priv = dev->dev_private;
+        int i;
+
+        /* Fences */
+        switch (INTEL_INFO(dev)->gen) {
+        case 7:
+        case 6:
+                for (i = 0; i < 16; i++)
+                        error->fence[i] = I915_READ64(FENCE_REG_SANDYBRIDGE_0 + (i * 8));
+                break;
+        case 5:
+        case 4:
+                for (i = 0; i < 16; i++)
+                        error->fence[i] = I915_READ64(FENCE_REG_965_0 + (i * 8));
+                break;
+        case 3:
+                if (IS_I945G(dev) || IS_I945GM(dev) || IS_G33(dev))
+                        for (i = 0; i < 8; i++)
+                                error->fence[i+8] = I915_READ(FENCE_REG_945_8 + (i * 4));
+        case 2:
+                for (i = 0; i < 8; i++)
+                        error->fence[i] = I915_READ(FENCE_REG_830_0 + (i * 4));
+                break;
+
+        }
+}
+
+static struct drm_i915_error_object *
+i915_error_first_batchbuffer(struct drm_i915_private *dev_priv,
+                             struct intel_ring_buffer *ring)
+{
+        struct drm_i915_gem_object *obj;
+        u32 seqno;
+
+        if (!ring->get_seqno)
+                return NULL;
+
+        if (HAS_BROKEN_CS_TLB(dev_priv->dev)) {
+                u32 acthd = I915_READ(ACTHD);
+
+                if (WARN_ON(ring->id != RCS))
+                        return NULL;
+
+                obj = ring->private;
+                if (acthd >= obj->gtt_offset &&
+                    acthd < obj->gtt_offset + obj->base.size)
+                        return i915_error_object_create(dev_priv, obj);
+        }
+
+        seqno = ring->get_seqno(ring, false);
+        list_for_each_entry(obj, &dev_priv->mm.active_list, mm_list) {
+                if (obj->ring != ring)
+                        continue;
+
+                if (i915_seqno_passed(seqno, obj->last_read_seqno))
+                        continue;
+
+                if ((obj->base.read_domains & I915_GEM_DOMAIN_COMMAND) == 0)
+                        continue;
+
+                /* We need to copy these to an anonymous buffer as the simplest
+                 * method to avoid being overwritten by userspace.
+                 */
+                return i915_error_object_create(dev_priv, obj);
+        }
+
+        return NULL;
+}
+
+static void i915_record_ring_state(struct drm_device *dev,
+                                   struct drm_i915_error_state *error,
+                                   struct intel_ring_buffer *ring)
+{
+        struct drm_i915_private *dev_priv = dev->dev_private;
+
+        if (INTEL_INFO(dev)->gen >= 6) {
+                error->rc_psmi[ring->id] = I915_READ(ring->mmio_base + 0x50);
+                error->fault_reg[ring->id] = I915_READ(RING_FAULT_REG(ring));
+                error->semaphore_mboxes[ring->id][0]
+                        = I915_READ(RING_SYNC_0(ring->mmio_base));
+                error->semaphore_mboxes[ring->id][1]
+                        = I915_READ(RING_SYNC_1(ring->mmio_base));
+                error->semaphore_seqno[ring->id][0] = ring->sync_seqno[0];
+                error->semaphore_seqno[ring->id][1] = ring->sync_seqno[1];
+        }
+
+        if (INTEL_INFO(dev)->gen >= 4) {
+                error->faddr[ring->id] = I915_READ(RING_DMA_FADD(ring->mmio_base));
+                error->ipeir[ring->id] = I915_READ(RING_IPEIR(ring->mmio_base));
+                error->ipehr[ring->id] = I915_READ(RING_IPEHR(ring->mmio_base));
+                error->instdone[ring->id] = I915_READ(RING_INSTDONE(ring->mmio_base));
+                error->instps[ring->id] = I915_READ(RING_INSTPS(ring->mmio_base));
+                if (ring->id == RCS)
+                        error->bbaddr = I915_READ64(BB_ADDR);
+        } else {
+                error->faddr[ring->id] = I915_READ(DMA_FADD_I8XX);
+                error->ipeir[ring->id] = I915_READ(IPEIR);
+                error->ipehr[ring->id] = I915_READ(IPEHR);
+                error->instdone[ring->id] = I915_READ(INSTDONE);
+        }
+
+        error->waiting[ring->id] = waitqueue_active(&ring->irq_queue);
+        error->instpm[ring->id] = I915_READ(RING_INSTPM(ring->mmio_base));
+        error->seqno[ring->id] = ring->get_seqno(ring, false);
+        error->acthd[ring->id] = intel_ring_get_active_head(ring);
+        error->head[ring->id] = I915_READ_HEAD(ring);
+        error->tail[ring->id] = I915_READ_TAIL(ring);
+        error->ctl[ring->id] = I915_READ_CTL(ring);
+
+        error->cpu_ring_head[ring->id] = ring->head;
+        error->cpu_ring_tail[ring->id] = ring->tail;
+}
+
+static void i915_gem_record_rings(struct drm_device *dev,
+                                  struct drm_i915_error_state *error)
+{
+        struct drm_i915_private *dev_priv = dev->dev_private;
+        struct intel_ring_buffer *ring;
+        struct drm_i915_gem_request *request;
+        int i, count;
+
+        for_each_ring(ring, dev_priv, i) {
+                i915_record_ring_state(dev, error, ring);
+
+                error->ring[i].batchbuffer =
+                        i915_error_first_batchbuffer(dev_priv, ring);
+
+                error->ring[i].ringbuffer =
+                        i915_error_object_create(dev_priv, ring->obj);
+
+                count = 0;
+                list_for_each_entry(request, &ring->request_list, list)
+                        count++;
+
+                error->ring[i].num_requests = count;
+                error->ring[i].requests =
+                        kmalloc(count*sizeof(struct drm_i915_error_request),
+                                GFP_ATOMIC);
+                if (error->ring[i].requests == NULL) {
+                        error->ring[i].num_requests = 0;
+                        continue;
+                }
+
+                count = 0;
+                list_for_each_entry(request, &ring->request_list, list) {
+                        struct drm_i915_error_request *erq;
+
+                        erq = &error->ring[i].requests[count++];
+                        erq->seqno = request->seqno;
+                        erq->jiffies = request->emitted_jiffies;
+                        erq->tail = request->tail;
+                }
+        }
+}
+
+/**
+ * i915_capture_error_state - capture an error record for later analysis
+ * @dev: drm device
+ *
+ * Should be called when an error is detected (either a hang or an error
+ * interrupt) to capture error state from the time of the error.  Fills
+ * out a structure which becomes available in debugfs for user level tools
+ * to pick up.
+ */
+
+static void i915_capture_error_state(struct drm_device *dev)
+{
+        struct drm_i915_private *dev_priv = dev->dev_private;
+        struct drm_i915_gem_object *obj;
+        struct drm_i915_error_state *error;
+        unsigned long flags;
+        int i, pipe;
+
+        spin_lock_irqsave(&dev_priv->error_lock, flags);
+        error = dev_priv->first_error;
+        spin_unlock_irqrestore(&dev_priv->error_lock, flags);
+        if (error)
+                return;
+
+        /* Account for pipe specific data like PIPE*STAT */
+        error = kzalloc(sizeof(*error), GFP_ATOMIC);
+        if (!error) {
+                DRM_DEBUG_DRIVER("out of memory, not capturing error state\n");
+                return;
+        }
+
+        DRM_INFO("capturing error event; look for more information in /debug/dri/%d/i915_error_state\n",
+                 dev->primary->index);
+
+        kref_init(&error->ref);
+        error->eir = I915_READ(EIR);
+        error->pgtbl_er = I915_READ(PGTBL_ER);
+        error->ccid = I915_READ(CCID);
+
+        if (HAS_PCH_SPLIT(dev))
+                error->ier = I915_READ(DEIER) | I915_READ(GTIER);
+        else if (IS_VALLEYVIEW(dev))
+                error->ier = I915_READ(GTIER) | I915_READ(VLV_IER);
+        else if (IS_GEN2(dev))
+                error->ier = I915_READ16(IER);
+        else
+                error->ier = I915_READ(IER);
+
+        if (INTEL_INFO(dev)->gen >= 6)
+                error->derrmr = I915_READ(DERRMR);
+
+        if (IS_VALLEYVIEW(dev))
+                error->forcewake = I915_READ(FORCEWAKE_VLV);
+        else if (INTEL_INFO(dev)->gen >= 7)
+                error->forcewake = I915_READ(FORCEWAKE_MT);
+        else if (INTEL_INFO(dev)->gen == 6)
+                error->forcewake = I915_READ(FORCEWAKE);
+
+        for_each_pipe(pipe)
+                error->pipestat[pipe] = I915_READ(PIPESTAT(pipe));
+
+	if (INTEL_INFO(dev)->gen >= 6) {
+                error->error = I915_READ(ERROR_GEN6);
+                error->done_reg = I915_READ(DONE_REG);
+        }
+
+        if (INTEL_INFO(dev)->gen == 7)
+                error->err_int = I915_READ(GEN7_ERR_INT);
+
+        i915_get_extra_instdone(dev, error->extra_instdone);
+
+        i915_gem_record_fences(dev, error);
+        i915_gem_record_rings(dev, error);
+
+        /* Record buffers on the active and pinned lists. */
+        error->active_bo = NULL;
+        error->pinned_bo = NULL;
+
+        i = 0;
+        list_for_each_entry(obj, &dev_priv->mm.active_list, mm_list)
+                i++;
+        error->active_bo_count = i;
+        list_for_each_entry(obj, &dev_priv->mm.bound_list, gtt_list)
+                if (obj->pin_count)
+                        i++;
+        error->pinned_bo_count = i - error->active_bo_count;
+
+        error->active_bo = NULL;
+        error->pinned_bo = NULL;
+        if (i) {
+                error->active_bo = kmalloc(sizeof(*error->active_bo)*i,
+                                           GFP_ATOMIC);
+                if (error->active_bo)
+                        error->pinned_bo =
+                                error->active_bo + error->active_bo_count;
+        }
+
+        if (error->active_bo)
+                error->active_bo_count =
+                        capture_active_bo(error->active_bo,
+                                          error->active_bo_count,
+                                          &dev_priv->mm.active_list);
+
+        if (error->pinned_bo)
+                error->pinned_bo_count =
+                        capture_pinned_bo(error->pinned_bo,
+                                          error->pinned_bo_count,
+                                          &dev_priv->mm.bound_list);
+
+	do_gettimeofday(&error->time);
+
+        error->overlay = intel_overlay_capture_error_state(dev);
+        error->display = intel_display_capture_error_state(dev);
+
+        spin_lock_irqsave(&dev_priv->error_lock, flags);
+        if (dev_priv->first_error == NULL) {
+                dev_priv->first_error = error;
+                error = NULL;
+        }
+        spin_unlock_irqrestore(&dev_priv->error_lock, flags);
+
+        if (error)
+                i915_error_state_free(&error->ref);
+}
+
+void i915_destroy_error_state(struct drm_device *dev)
+{
+        struct drm_i915_private *dev_priv = dev->dev_private;
+        struct drm_i915_error_state *error;
+        unsigned long flags;
+
+        spin_lock_irqsave(&dev_priv->error_lock, flags);
+        error = dev_priv->first_error;
+        dev_priv->first_error = NULL;
+        spin_unlock_irqrestore(&dev_priv->error_lock, flags);
+
+        if (error)
+                kref_put(&error->ref, i915_error_state_free);
+}
+#else
+#define i915_capture_error_state(x)
+#endif
 
 static void i915_report_and_clear_eir(struct drm_device *dev)
 {
@@ -257,6 +729,53 @@ static void i915_report_and_clear_eir(struct drm_device *dev)
 	}
 }
 
+static void intel_display_handle_reset(struct drm_device *dev)
+{
+	struct drm_crtc *crtc;
+	/*
+	 * Flips in the rings have been nuked by the reset,
+	 * so complete all pending flips so that user space
+	 * will get its events and not get stuck.
+	 */
+	 list_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {
+		emgd_crtc_t *emgd_crtc = container_of(crtc, emgd_crtc_t, base);
+
+		if (emgd_crtc->flip_pending)
+			atomic_inc(&emgd_crtc->unpin_work_count);
+
+		crtc_pageflip_handler(dev, emgd_crtc->pipe);
+
+		}
+}
+
+static void i915_error_wake_up(struct drm_i915_private *dev_priv,
+			       bool reset_completed)
+{
+	struct intel_ring_buffer *ring;
+	int i;
+
+	/*
+	 * Notify all waiters for GPU completion events that reset state has
+	 * been changed, and that they need to restart their wait after
+	 * checking for potential errors (and bail out to drop locks if there is
+	 * a gpu reset pending so that i915_error_work_func can acquire them).
+	 */
+
+	/* Wake up __wait_seqno, potentially holding dev->struct_mutex. */
+	for_each_ring(ring, dev_priv, i)
+		wake_up_all(&ring->irq_queue);
+
+	/* Wake up intel_crtc_wait_for_pending_flips, holding crtc->mutex. */
+		wake_up_all(&dev_priv->pending_flip_queue);
+
+	/*
+	 * Signal tasks blocked in i915_gem_wait_for_error that the pending
+	 * reset state is cleared.
+	 */
+	if (reset_completed)
+		wake_up_all(&dev_priv->gpu_error.reset_queue);
+}
+
 /**
  * i915_handle_error - handle an error interrupt
  * @dev: drm device
@@ -270,10 +789,8 @@ static void i915_report_and_clear_eir(struct drm_device *dev)
 void i915_handle_error(struct drm_device *dev, bool wedged)
 {
 	struct drm_i915_private *dev_priv = dev->dev_private;
-	struct intel_ring_buffer *ring;
-	int i;
 
-	//i915_capture_error_state(dev);
+	i915_capture_error_state(dev);
 	i915_report_and_clear_eir(dev);
 
 	if (wedged) {
@@ -283,18 +800,27 @@ void i915_handle_error(struct drm_device *dev, bool wedged)
 				&dev_priv->gpu_error.reset_counter);
 
 		/*
-		 * Wakeup waiting processes so that the reset work item
-		 * doesn't deadlock trying to grab various locks.
+		 * Wakeup waiting processes so that the reset work function
+		 * i915_error_work_func doesn't deadlock trying to grab various
+		 * locks. By bumping the reset counter first, the woken
+		 * processes will see a reset in progress and back off,
+		 * releasing their locks and then wait for the reset completion.
+		 * We must do this for _all_ gpu waiters that might hold locks
+		 * that the reset work needs to acquire.
+		 *
+		 * Note: The wake_up serves as the required memory barrier to
+		 * ensure that the waiters see the updated value of the reset
+		 * counter atomic_t.
+
 		 */
-		for_each_ring(ring, dev_priv, i)
-			wake_up_all(&ring->irq_queue);
+		i915_error_wake_up(dev_priv, false);
 
 #ifdef KERNEL_HAS_ATOMIC_PAGE_FLIP
 		intel_atomic_wedged(dev);
 #endif
 	}
 
-	queue_work(dev_priv->wq, &dev_priv->gpu_error.work);
+	schedule_work(&dev_priv->gpu_error.work);
 }
 
 static u32
@@ -569,6 +1095,7 @@ void i915_error_work_func(struct work_struct *work)
 		kobject_uevent_env(&dev->primary->kdev.kobj, KOBJ_CHANGE, reset_event);
 		
 		ret = i915_reset(dev);
+		intel_display_handle_reset(dev);
 		
 		if (ret == 0) {
 			/*
@@ -589,8 +1116,12 @@ void i915_error_work_func(struct work_struct *work)
 		} else {
 			atomic_set(&error->reset_counter, I915_WEDGED);
 		}
- 
-		wake_up_all(&dev_priv->gpu_error.reset_queue);
+
+		/*
+		 * Note: The wake_up also serves as a memory barrier so that
+		 *  waiters see the update value of the reset counter atomic_t.
+		 */
+		i915_error_wake_up(dev_priv, true);
 	}
 }
 
@@ -824,7 +1355,7 @@ void vlv_queue_rps_work(struct drm_i915_private *dev_priv,
 void vlv_pm_rps_work(struct work_struct *work){
 
 	static int turbo_flag = 0, turbo_down_cnt = 0;
-	unsigned long long constant = 10000000000, temp = 0;
+	unsigned long long constant = 10000000000, render = 0, media = 0;
 	u32 turbo_new_freq = 0;
 
 	drm_i915_private_t *dev_priv = container_of(work, drm_i915_private_t,
@@ -854,28 +1385,50 @@ void vlv_pm_rps_work(struct work_struct *work){
 
 	if (turbo_flag == 0){
 		turbo.render_prev=I915_READ(RENDER_RC0_COUNTER);
+		turbo.media_prev=I915_READ(MEDIA_RC0_COUNTER);
 		valleyview_punit_read(dev_priv, GR_PORT_LSB, &(turbo.punit_timestamp_prev));
 		turbo_flag++;
 	}else{
 		turbo.render_cur=I915_READ(RENDER_RC0_COUNTER);
+		turbo.media_cur=I915_READ(MEDIA_RC0_COUNTER);
 		valleyview_punit_read(dev_priv, GR_PORT_LSB, &(turbo.punit_timestamp_cur));
 
 		turbo.render_prev = (turbo.render_prev > turbo.render_cur)?
 				     0xFFFFFFFF - turbo.render_prev + turbo.render_cur:
 				     turbo.render_cur - turbo.render_prev;
 
-		temp = turbo.render_prev * constant;
+		turbo.media_prev = (turbo.media_prev > turbo.media_cur)?
+				    0xFFFFFFFF - turbo.media_prev + turbo.media_cur:
+				    turbo.media_cur - turbo.media_prev;
+
+		render = turbo.render_prev * constant;
+		media = turbo.media_prev * constant;
 
 		turbo.punit_timestamp_prev = ( turbo.punit_timestamp_prev > turbo.punit_timestamp_cur)?
 					0xFFFFFFFF - turbo.punit_timestamp_prev + turbo.punit_timestamp_cur:
 					turbo.punit_timestamp_cur - turbo.punit_timestamp_prev;
 
+
 		if (turbo.punit_timestamp_prev == 0)
 			turbo.punit_timestamp_prev=1;
 
-		do_div(temp, turbo.punit_timestamp_prev);
+		do_div(render, turbo.punit_timestamp_prev);
+		do_div(media, turbo.punit_timestamp_prev);
+
+		/*
+		 * Media and render in this case refers to residency computation to 
+		 * decide whether we need to boost up the GPU frequency or not. 
+		 * 90000 render residency basically refers to the maximum threshold
+		 * value we baceuse the gives a very huge number. 
+		 *
+		 * However, in certain cases, eg,video encoding/decoding, there 
+		 * is some contribution to the media residency as well. Hence, we 
+		 * have to take this into account as well. The value threshold is
+		 * set to really low becase when mpeg media recidencies much than
+		 * than h264 media residencies. 
+		 */
 
-		if (temp > 90000){
+		if (render > 900000 || media > 1000) {
 			turbo_down_cnt = 0;
 			turbo_new_freq = dev_priv->rps.cur_delay + 3;
 			if (!(turbo_new_freq > dev_priv->rps.max_delay))
@@ -894,6 +1447,7 @@ void vlv_pm_rps_work(struct work_struct *work){
 		}
 
 		turbo.render_prev = turbo.render_cur;
+		turbo.media_prev = turbo.media_cur;
 		turbo.punit_timestamp_prev = turbo.punit_timestamp_cur;
 	}
 	mutex_unlock(&dev_priv->rps.hw_lock);
diff --git a/drivers/gpu/drm/emgd/src/core/i915/i915_gem.c b/drivers/gpu/drm/emgd/src/core/i915/i915_gem.c
index 5eba82e..ac85462 100644
--- a/drivers/gpu/drm/emgd/src/core/i915/i915_gem.c
+++ b/drivers/gpu/drm/emgd/src/core/i915/i915_gem.c
@@ -47,6 +47,7 @@
 #endif
 
 #include "default_config.h"
+#include "kernel-compat.h"
 extern int drm_emgd_configid;
 extern emgd_drm_config_t *config_drm;
 
@@ -2337,7 +2338,6 @@ i915_gem_request_remove_from_client(struct drm_i915_private * dev_priv,
 				file_priv->mm.exec_times[file_priv->mm.last_exec_slot] = exectime;
 				
 				/* A running average execution time calculation*/	
-				if (dev_priv->scheduler.rogue_switch) {
 					if (file_priv->mm.last_exec_slot == 0) {
 						file_priv->mm.sched_avgexectime = 0;
 						for (i = 0; i < MOVING_AVG_RANGE; ++i) {
@@ -2346,7 +2346,6 @@ i915_gem_request_remove_from_client(struct drm_i915_private * dev_priv,
 						if (file_priv->mm.sched_avgexectime) 
 							file_priv->mm.sched_avgexectime = (file_priv->mm.sched_avgexectime / MOVING_AVG_RANGE);
 					}
-				}
 
 			} else {
 				if (time_is_after_jiffies(request->emitted_jiffies)) /* wrap around of jiffies bits? */
@@ -2357,22 +2356,31 @@ i915_gem_request_remove_from_client(struct drm_i915_private * dev_priv,
 						jiffies - request->emitted_jiffies;
 			}
 
-			if (SHARED_NORMAL_PRIORITY == file_priv->mm.sched_priority) {
-				if (dev_priv->scheduler.shared_balance 
-					< usecs_to_jiffies(file_priv->mm.exec_times[file_priv->mm.last_exec_slot]))
-					dev_priv->scheduler.shared_balance = 0;
-				else 
-					dev_priv->scheduler.shared_balance 
-						-= usecs_to_jiffies(file_priv->mm.exec_times[file_priv->mm.last_exec_slot]);
-			} 
-			else if (SHARED_NORMAL_PRIORITY > file_priv->mm.sched_priority) {
-				if (file_priv->mm.sched_balance 
-					< usecs_to_jiffies(file_priv->mm.exec_times[file_priv->mm.last_exec_slot]))
-					file_priv->mm.sched_balance = 0;
-				else
-					file_priv->mm.sched_balance
-						 -= usecs_to_jiffies(file_priv->mm.exec_times[file_priv->mm.last_exec_slot]);
+			if(!dev_priv->scheduler.shared_aereserve) {
+			/* Only reduce the balance budget if we're NOT doing
+			 * AE budgeting for the shared and prioritized processes.
+			 */
+				if (SHARED_NORMAL_PRIORITY == file_priv->mm.sched_priority) {
+					if (dev_priv->scheduler.shared_balance
+						< usecs_to_jiffies(file_priv->mm.exec_times[file_priv->mm.last_exec_slot]))
+						dev_priv->scheduler.shared_balance = 0;
+					else
+						dev_priv->scheduler.shared_balance
+							-= usecs_to_jiffies(file_priv->mm.exec_times[file_priv->mm.last_exec_slot]);
+				}
+				else if (SHARED_NORMAL_PRIORITY > file_priv->mm.sched_priority) {
+					if (file_priv->mm.sched_balance
+						< usecs_to_jiffies(file_priv->mm.exec_times[file_priv->mm.last_exec_slot]))
+						file_priv->mm.sched_balance = 0;
+					else
+						file_priv->mm.sched_balance
+							 -= usecs_to_jiffies(file_priv->mm.exec_times[file_priv->mm.last_exec_slot]);
+				}
 			}
+			/* Take notice that we DONT do the balance budget reduction for
+			 * rogue apps. For rogue we always only do AE budgeting
+			 * i.e. it was already done based on the moving average.
+			 */
 
 			if (WARN_ON(file_priv->mm.outstanding_requests < 0)) {
 				file_priv->mm.outstanding_requests = 0;
@@ -3022,6 +3030,8 @@ static void i915_gem_object_update_fence(struct drm_i915_gem_object *obj,
 		fence->obj = obj;
 		list_move_tail(&fence->lru_list, &dev_priv->mm.fence_list);
 	} else {
+		WARN(fence->pin_count, "disabling fence %d with non-zero pin count %d "
+				"for bo %p\n", reg, fence->pin_count, obj);
 		obj->fence_reg = I915_FENCE_REG_NONE;
 		fence->obj = NULL;
 		list_del_init(&fence->lru_list);
@@ -4434,8 +4444,8 @@ int i915_gem_init(struct drm_device *dev)
 	unsigned long gtt_size, mappable_size;
 	int ret;
 
-	gtt_size = dev_priv->mm.gtt->gtt_total_entries << PAGE_SHIFT;
-	mappable_size = dev_priv->mm.gtt->gtt_mappable_entries << PAGE_SHIFT;
+	gtt_size = GTT(dev_priv)->gtt_total_entries << PAGE_SHIFT;
+	mappable_size = GTT(dev_priv)->gtt_mappable_entries << PAGE_SHIFT;
 
 	mutex_lock(&dev->struct_mutex);
 	if (intel_enable_ppgtt(dev) && HAS_ALIASING_PPGTT(dev)) {
@@ -4619,6 +4629,7 @@ i915_gem_load(struct drm_device *dev)
 	dev_priv->scheduler.video_init_capacity = INITIAL_SHARED_PERIOD;
 	dev_priv->scheduler.shared_period   = INITIAL_SHARED_PERIOD;
 	dev_priv->scheduler.shared_capacity = INITIAL_SHARED_CAPACITY;
+	dev_priv->scheduler.shared_aereserve = true;
 	dev_priv->scheduler.shared_balance  = usecs_to_jiffies(INITIAL_SHARED_CAPACITY);
 	dev_priv->scheduler.shared_last_refresh_jiffs = jiffies;
 	dev_priv->scheduler.rogue_period   = INITIAL_ROGUE_PERIOD;
diff --git a/drivers/gpu/drm/emgd/src/core/i915/i915_gem_execbuffer.c b/drivers/gpu/drm/emgd/src/core/i915/i915_gem_execbuffer.c
index 54f5c64..386a5cf 100644
--- a/drivers/gpu/drm/emgd/src/core/i915/i915_gem_execbuffer.c
+++ b/drivers/gpu/drm/emgd/src/core/i915/i915_gem_execbuffer.c
@@ -889,11 +889,18 @@ i915_schedule(struct drm_device *dev, struct intel_ring_buffer *ring, struct drm
 	if (file_priv->mm.sched_priority) { 
 		/* make sure this client isnt priority-0 - i.e. highest */
 		for ( i=(file_priv->mm.sched_priority-1); i>=0 ; i-- ) {
-			
-			if (dev_priv->scheduler.req_prty_cnts[i])  {
-				higher_priority_requestors += dev_priv->scheduler.req_prty_cnts[i];
-				break;
-			}
+            if (dev_priv->scheduler.req_prty_cnts[i]) {
+				if(i == SHARED_NORMAL_PRIORITY &&
+						dev_priv->scheduler.shared_balance) {
+					higher_priority_requestors += dev_priv->scheduler.req_prty_cnts[i];
+					break;
+				} else if(dev_priv->scheduler.req_prty_fp[i] &&
+						dev_priv->scheduler.req_prty_fp[i]->mm.sched_balance)  {
+					higher_priority_requestors += dev_priv->scheduler.req_prty_cnts[i];
+					break;
+				}
+            }
+
 			if ((sampled_debugs%1000)==0){
 				EMGD_DEBUG("Check higher priorities, i = %d, count = %d",
 					 i, dev_priv->scheduler.req_prty_cnts[i]);
@@ -917,6 +924,7 @@ i915_schedule(struct drm_device *dev, struct intel_ring_buffer *ring, struct drm
 			return GEM_CMD_RESCHED;
 		}
 	} else {
+		/* priority zero! this is highest - like a drm-master, let it thru */
 		spin_unlock(&dev_priv->scheduler.sched_lock);
 		spin_unlock(&file_priv->mm.lock);
 		return GEM_CMD_DONE;
@@ -982,6 +990,19 @@ i915_schedule(struct drm_device *dev, struct intel_ring_buffer *ring, struct drm
 	if (file_priv->mm.sched_priority == SHARED_NORMAL_PRIORITY) {
 		/* this means we're in the common-grouped priority - shared bucket */
 		if (dev_priv->scheduler.shared_balance > 0) {
+
+			/* Lets see if we're using AE Policy for reservation:
+			 * AE means we deduct the balance before returning from scheduler.
+			 * During retirement, DONT double deduct from balance for AE.
+ 			 * NOTE: For rogue, we always only do this.
+			 */
+			if(dev_priv->scheduler.shared_aereserve) {
+				if (dev_priv->scheduler.shared_balance < usecs_to_jiffies(file_priv->mm.sched_avgexectime))
+					dev_priv->scheduler.shared_balance = 0;
+				else
+					dev_priv->scheduler.shared_balance -= usecs_to_jiffies(file_priv->mm.sched_avgexectime);
+			}
+
 			spin_unlock(&dev_priv->scheduler.sched_lock);
 			spin_unlock(&file_priv->mm.lock);
 			return GEM_CMD_DONE;
@@ -1041,6 +1062,17 @@ i915_schedule(struct drm_device *dev, struct intel_ring_buffer *ring, struct drm
 	else {
 		/* this process has its own special priority */
 		if  (file_priv->mm.sched_balance > 0) {
+			/* Lets see if we're using AE Policy for reservation:
+			 * AE means we deduct the balance before returning from scheduler.
+			 * During retirement, DONT double deduct from balance for AE.
+			 * NOTE: For rogue, we always only do this.
+			 */
+			if(dev_priv->scheduler.shared_aereserve) {
+				if (file_priv->mm.sched_balance < usecs_to_jiffies(file_priv->mm.sched_avgexectime))
+					file_priv->mm.sched_balance = 0;
+				else
+					file_priv->mm.sched_balance -= usecs_to_jiffies(file_priv->mm.sched_avgexectime);
+			}
 			spin_unlock(&dev_priv->scheduler.sched_lock);
 			spin_unlock(&file_priv->mm.lock);
 			return GEM_CMD_DONE;
@@ -1271,6 +1303,8 @@ again:
 	if (gem_scheduler && !gem_sched_queued) {
 		spin_lock(&dev_priv->scheduler.sched_lock);
 		dev_priv->scheduler.req_prty_cnts[file_priv->mm.sched_priority]++;
+		dev_priv->scheduler.req_prty_fp[file_priv->mm.sched_priority] = file_priv;
+
 		spin_unlock(&dev_priv->scheduler.sched_lock);
 		gem_sched_queued = 1;
 	}
@@ -1472,7 +1506,10 @@ pre_mutex_err:
 		spin_lock(&dev_priv->scheduler.sched_lock);
 		dev_priv->scheduler.req_prty_cnts[file_priv->mm.sched_priority]--;
 		if (dev_priv->scheduler.req_prty_cnts[file_priv->mm.sched_priority] < 0)
+		{
 			dev_priv->scheduler.req_prty_cnts[file_priv->mm.sched_priority] = 0;
+			dev_priv->scheduler.req_prty_fp[file_priv->mm.sched_priority] = 0;
+		}
 		spin_unlock(&dev_priv->scheduler.sched_lock);
 	}
 	kfree(cliprects);
diff --git a/drivers/gpu/drm/emgd/src/core/i915/i915_gem_gtt.c b/drivers/gpu/drm/emgd/src/core/i915/i915_gem_gtt.c
index 3e803cb..d5edb11 100644
--- a/drivers/gpu/drm/emgd/src/core/i915/i915_gem_gtt.c
+++ b/drivers/gpu/drm/emgd/src/core/i915/i915_gem_gtt.c
@@ -36,6 +36,7 @@
 #include "intel_drv.h"
 
 #include "default_config.h"
+#include "kernel-compat.h"
 extern int drm_emgd_configid;
 extern emgd_drm_config_t *config_drm;
 
@@ -132,7 +133,7 @@ int i915_gem_init_aliasing_ppgtt(struct drm_device *dev)
 	/* ppgtt PDEs reside in the global gtt pagetable, which has 512*1024
 	 * entries. For aliasing ppgtt support we just steal them at the end for
 	 * now. */
-	first_pd_entry_in_global_pt = dev_priv->mm.gtt->gtt_total_entries - I915_PPGTT_PD_ENTRIES;
+	first_pd_entry_in_global_pt = GTT(dev_priv)->gtt_total_entries - I915_PPGTT_PD_ENTRIES;
 
 	ppgtt = kzalloc(sizeof(*ppgtt), GFP_KERNEL);
 	if (!ppgtt)
@@ -151,7 +152,7 @@ int i915_gem_init_aliasing_ppgtt(struct drm_device *dev)
 			goto err_pt_alloc;
 	}
 
-	if (dev_priv->mm.gtt->needs_dmar) {
+	if (GTT(dev_priv)->needs_dmar) {
 		ppgtt->pt_dma_addr = kzalloc(sizeof(dma_addr_t)
 				*ppgtt->num_pd_entries,
 				GFP_KERNEL);
@@ -175,7 +176,7 @@ int i915_gem_init_aliasing_ppgtt(struct drm_device *dev)
 		}
 	}
 
-	ppgtt->scratch_page_dma_addr = dev_priv->mm.gtt->scratch_page_dma;
+	ppgtt->scratch_page_dma_addr = GTT(dev_priv)->scratch_page_dma;
 
 	i915_ppgtt_clear_range(ppgtt, 0,
 			ppgtt->num_pd_entries*I915_PPGTT_PT_ENTRIES);
@@ -417,11 +418,11 @@ void i915_gem_init_ppgtt(struct drm_device *dev)
 		return;
 
 
-	pd_addr = dev_priv->mm.gtt->gtt + ppgtt->pd_offset/sizeof(uint32_t);
+	pd_addr = GTT(dev_priv)->gtt + ppgtt->pd_offset/sizeof(uint32_t);
 	for (i = 0; i < ppgtt->num_pd_entries; i++) {
 		dma_addr_t pt_addr;
 
-		if (dev_priv->mm.gtt->needs_dmar)
+		if (GTT(dev_priv)->needs_dmar)
 			pt_addr = ppgtt->pt_dma_addr[i];
 		else
 			pt_addr = page_to_phys(ppgtt->pt_pages[i]);
@@ -492,7 +493,7 @@ static bool do_idling(struct drm_i915_private *dev_priv)
 {
 	bool ret = dev_priv->mm.interruptible;
 
-	if (unlikely(dev_priv->mm.gtt->do_idle_maps)) {
+	if (unlikely(GTT(dev_priv)->do_idle_maps)) {
 		dev_priv->mm.interruptible = false;
 		if (i915_gpu_idle(dev_priv->dev)) {
 			DRM_ERROR("Couldn't idle GPU\n");
@@ -506,7 +507,7 @@ static bool do_idling(struct drm_i915_private *dev_priv)
 
 static void undo_idling(struct drm_i915_private *dev_priv, bool interruptible)
 {
-	if (unlikely(dev_priv->mm.gtt->do_idle_maps))
+	if (unlikely(GTT(dev_priv)->do_idle_maps))
 		dev_priv->mm.interruptible = interruptible;
 }
 
@@ -516,8 +517,8 @@ static void i915_ggtt_clear_range(struct drm_device *dev,
 {
 	struct drm_i915_private *dev_priv = dev->dev_private;
 	gtt_pte_t scratch_pte;
-	gtt_pte_t __iomem *gtt_base = dev_priv->mm.gtt->gtt + first_entry;
-	const int max_entries = dev_priv->mm.gtt->gtt_total_entries - first_entry;
+	gtt_pte_t __iomem *gtt_base = GTT(dev_priv)->gtt + first_entry;
+	const int max_entries = GTT(dev_priv)->gtt_total_entries - first_entry;
 	int i;
 
 	if (INTEL_INFO(dev)->gen < 6) {
@@ -530,7 +531,7 @@ static void i915_ggtt_clear_range(struct drm_device *dev,
 				first_entry, num_entries, max_entries))
 		num_entries = max_entries;
 
-	scratch_pte = pte_encode(dev, dev_priv->mm.gtt->scratch_page_dma, I915_CACHE_LLC);
+	scratch_pte = pte_encode(dev, GTT(dev_priv)->scratch_page_dma, I915_CACHE_LLC);
 	for (i = 0; i < num_entries; i++)
 		iowrite32(scratch_pte, &gtt_base[i]);
 	readl(gtt_base);
@@ -541,6 +542,8 @@ void i915_gem_restore_gtt_mappings(struct drm_device *dev)
 	struct drm_i915_private *dev_priv = dev->dev_private;
 	struct drm_i915_gem_object *obj;
 
+	i915_check_and_clear_faults(dev);
+
 	/* First fill our portion of the GTT with scratch pages */
 	i915_ggtt_clear_range(dev, dev_priv->mm.gtt_start / PAGE_SIZE,
 			      (dev_priv->mm.gtt_end - dev_priv->mm.gtt_start) / PAGE_SIZE);
@@ -595,8 +598,8 @@ static void gen6_ggtt_bind_object(struct drm_i915_gem_object *obj,
 	struct sg_table *st = obj->pages;
 	struct scatterlist *sg = st->sgl;
 	const int first_entry = obj->gtt_space->start >> PAGE_SHIFT;
-	const int max_entries = dev_priv->mm.gtt->gtt_total_entries - first_entry;
-	gtt_pte_t __iomem *gtt_entries = dev_priv->mm.gtt->gtt + first_entry;
+	const int max_entries = GTT(dev_priv)->gtt_total_entries - first_entry;
+	gtt_pte_t __iomem *gtt_entries = GTT(dev_priv)->gtt + first_entry;
 	int unused, i = 0;
 	unsigned int len, m = 0;
 	dma_addr_t addr;
@@ -799,8 +802,8 @@ static int setup_scratch_page(struct drm_device *dev)
 #else
 	dma_addr = page_to_phys(page);
 #endif
-	dev_priv->mm.gtt->scratch_page = page;
-	dev_priv->mm.gtt->scratch_page_dma = dma_addr;
+	GTT(dev_priv)->scratch_page = page;
+	GTT(dev_priv)->scratch_page_dma = dma_addr;
 
 	return 0;
 }
@@ -808,11 +811,11 @@ static int setup_scratch_page(struct drm_device *dev)
 static void teardown_scratch_page(struct drm_device *dev)
 {
 	struct drm_i915_private *dev_priv = dev->dev_private;
-	set_pages_wb(dev_priv->mm.gtt->scratch_page, 1);
-	pci_unmap_page(dev->pdev, dev_priv->mm.gtt->scratch_page_dma,
+	set_pages_wb(GTT(dev_priv)->scratch_page, 1);
+	pci_unmap_page(dev->pdev, GTT(dev_priv)->scratch_page_dma,
 			PAGE_SIZE, PCI_DMA_BIDIRECTIONAL);
-	put_page(dev_priv->mm.gtt->scratch_page);
-	__free_page(dev_priv->mm.gtt->scratch_page);
+	put_page(GTT(dev_priv)->scratch_page);
+	__free_page(GTT(dev_priv)->scratch_page);
 }
 
 static inline unsigned int gen6_get_total_gtt_size(u16 snb_gmch_ctl)
@@ -845,6 +848,13 @@ int i915_gem_gtt_init(struct drm_device *dev)
 	u16 snb_gmch_ctl;
 	int ret;
 
+#if LINUX_VERSION_CODE >=KERNEL_VERSION(3,10,0)
+	size_t *gtt_total;
+	size_t *stolen;
+	phys_addr_t *mappable_base;
+	unsigned long *mappable_end;
+	struct i915_hw_ppgtt *ppgtt;
+#endif
 	/* On modern platforms we need not worry ourself with the legacy
 	 * hostbridge query stuff. Skip it entirely
 	 */
@@ -855,6 +865,9 @@ int i915_gem_gtt_init(struct drm_device *dev)
 			return -EIO;
 		}
 
+#if LINUX_VERSION_CODE >=KERNEL_VERSION(3,10,0)
+		intel_gtt_get(gtt_total, stolen, mappable_base, mappable_end);
+#else
 		dev_priv->mm.gtt = intel_gtt_get();
 		if (!dev_priv->mm.gtt) {
 			DRM_ERROR("Failed to initialize GTT\n");
@@ -862,40 +875,47 @@ int i915_gem_gtt_init(struct drm_device *dev)
 			return -ENODEV;
 		}
 		return 0;
+#endif
 	}
 
+#if LINUX_VERSION_CODE >=KERNEL_VERSION(3,10,0)
+	ppgtt = kzalloc(sizeof(*ppgtt), GFP_KERNEL);
+	if (!ppgtt)
+		return -ENOMEM;
+#else
 	dev_priv->mm.gtt = kzalloc(sizeof(*dev_priv->mm.gtt), GFP_KERNEL);
 	if (!dev_priv->mm.gtt)
 		return -ENOMEM;
+#endif
 
 	if (!pci_set_dma_mask(dev->pdev, DMA_BIT_MASK(40)))
 		pci_set_consistent_dma_mask(dev->pdev, DMA_BIT_MASK(40));
 
 #ifdef CONFIG_INTEL_IOMMU
-	dev_priv->mm.gtt->needs_dmar = 1;
+	GTT(dev_priv)->needs_dmar = 1;
 #endif
 
 	/* For GEN6+ the PTEs for the ggtt live at 2MB + BAR0 */
 	gtt_bus_addr = pci_resource_start(dev->pdev, 0) + (2<<20);
-	dev_priv->mm.gtt->gma_bus_addr = pci_resource_start(dev->pdev, 2);
+	GTT(dev_priv)->gma_bus_addr = pci_resource_start(dev->pdev, 2);
 
 	/* i9xx_setup */
 	pci_read_config_word(dev->pdev, SNB_GMCH_CTRL, &snb_gmch_ctl);
-	dev_priv->mm.gtt->gtt_total_entries =
+	GTT(dev_priv)->gtt_total_entries =
 		gen6_get_total_gtt_size(snb_gmch_ctl) / sizeof(gtt_pte_t);
 	if ((INTEL_INFO(dev)->gen == 6) || IS_VALLEYVIEW(dev))
-		dev_priv->mm.gtt->stolen_size = gen6_get_stolen_size(snb_gmch_ctl);
+		GTT(dev_priv)->stolen_size = gen6_get_stolen_size(snb_gmch_ctl);
 	else if (INTEL_INFO(dev)->gen == 7)
-		dev_priv->mm.gtt->stolen_size = gen7_get_stolen_size(snb_gmch_ctl);
+		GTT(dev_priv)->stolen_size = gen7_get_stolen_size(snb_gmch_ctl);
 
-	dev_priv->mm.gtt->gtt_mappable_entries = pci_resource_len(dev->pdev, 2) >> PAGE_SHIFT;
+	GTT(dev_priv)->gtt_mappable_entries = pci_resource_len(dev->pdev, 2) >> PAGE_SHIFT;
 	/* 64/512MB is the current min/max we actually know of, but this is just a
 	 * coarse sanity check.
 	 */
-	if ((dev_priv->mm.gtt->gtt_mappable_entries >> 8) < 64 ||
-			dev_priv->mm.gtt->gtt_mappable_entries > dev_priv->mm.gtt->gtt_total_entries) {
+	if ((GTT(dev_priv)->gtt_mappable_entries >> 8) < 64 ||
+			GTT(dev_priv)->gtt_mappable_entries > GTT(dev_priv)->gtt_total_entries) {
 		DRM_ERROR("Unknown GMADR entries (%d)\n",
-				dev_priv->mm.gtt->gtt_mappable_entries);
+				GTT(dev_priv)->gtt_mappable_entries);
 		ret = -ENXIO;
 		goto err_out;
 	}
@@ -906,9 +926,9 @@ int i915_gem_gtt_init(struct drm_device *dev)
 		goto err_out;
 	}
 
-	dev_priv->mm.gtt->gtt = ioremap_wc(gtt_bus_addr,
-			dev_priv->mm.gtt->gtt_total_entries * sizeof(gtt_pte_t));
-	if (!dev_priv->mm.gtt->gtt) {
+	GTT(dev_priv)->gtt = ioremap_wc(gtt_bus_addr,
+			GTT(dev_priv)->gtt_total_entries * sizeof(gtt_pte_t));
+	if (!GTT(dev_priv)->gtt) {
 		DRM_ERROR("Failed to map the gtt page table\n");
 		teardown_scratch_page(dev);
 		ret = -ENOMEM;
@@ -916,14 +936,18 @@ int i915_gem_gtt_init(struct drm_device *dev)
 	}
 
 	/* GMADR is the PCI aperture used by SW to access tiled GFX surfaces in a linear fashion. */
-	DRM_INFO("Memory usable by graphics device = %dM\n", dev_priv->mm.gtt->gtt_total_entries >> 8);
-	DRM_DEBUG_DRIVER("GMADR size = %dM\n", dev_priv->mm.gtt->gtt_mappable_entries >> 8);
-	DRM_DEBUG_DRIVER("GTT stolen size = %dM\n", dev_priv->mm.gtt->stolen_size >> 20);
+	DRM_INFO("Memory usable by graphics device = %dM\n", GTT(dev_priv)->gtt_total_entries >> 8);
+	DRM_DEBUG_DRIVER("GMADR size = %dM\n", GTT(dev_priv)->gtt_mappable_entries >> 8);
+	DRM_DEBUG_DRIVER("GTT stolen size = %dM\n", GTT(dev_priv)->stolen_size >> 20);
 
 	return 0;
 
 err_out:
+#if LINUX_VERSION_CODE >=KERNEL_VERSION(3,10,0)
+	kfree(ppgtt);
+#else
 	kfree(dev_priv->mm.gtt);
+#endif
 	if (INTEL_INFO(dev)->gen < 6)
 		intel_gmch_remove();
 	return ret;
@@ -932,7 +956,7 @@ err_out:
 void i915_gem_gtt_fini(struct drm_device *dev)
 {
 	struct drm_i915_private *dev_priv = dev->dev_private;
-	iounmap(dev_priv->mm.gtt->gtt);
+	iounmap(GTT(dev_priv)->gtt);
 	teardown_scratch_page(dev);
 	if (INTEL_INFO(dev)->gen < 6)
 		intel_gmch_remove();
diff --git a/drivers/gpu/drm/emgd/src/core/i915/i915_gem_stolen.c b/drivers/gpu/drm/emgd/src/core/i915/i915_gem_stolen.c
index 3c76429..b9056ec 100644
--- a/drivers/gpu/drm/emgd/src/core/i915/i915_gem_stolen.c
+++ b/drivers/gpu/drm/emgd/src/core/i915/i915_gem_stolen.c
@@ -34,7 +34,7 @@
 #include "i915_drm.h"
 #include "i915_reg.h"
 #include "drm_emgd_private.h"
-
+#include "kernel-compat.h"
 /*
  * The BIOS typically reserves some of the system's memory for the exclusive
  * use of the integrated graphics. This memory is no longer available for
@@ -230,7 +230,7 @@ void i915_gem_cleanup_stolen(struct drm_device *dev)
 int i915_gem_init_stolen(struct drm_device *dev)
 {
 	struct drm_i915_private *dev_priv = dev->dev_private;
-	unsigned long prealloc_size = dev_priv->mm.gtt->stolen_size;
+	unsigned long prealloc_size = GTT(dev_priv)->stolen_size;
 
 	dev_priv->mm.stolen_base = i915_stolen_to_physical(dev);
 	if (dev_priv->mm.stolen_base == 0)
diff --git a/drivers/gpu/drm/emgd/src/core/i915/i915_reg.h b/drivers/gpu/drm/emgd/src/core/i915/i915_reg.h
index accc55d..3028c1c 100644
--- a/drivers/gpu/drm/emgd/src/core/i915/i915_reg.h
+++ b/drivers/gpu/drm/emgd/src/core/i915/i915_reg.h
@@ -445,6 +445,12 @@
 #define   ARB_MODE_SWIZZLE_SNB (1<<4)
 #define   ARB_MODE_SWIZZLE_IVB (1<<5)
 #define RENDER_HWS_PGA_GEN7	(0x04080)
+#define RING_FAULT_REG(ring)    (0x4094 + 0x100*(ring)->id)
+#define   RING_FAULT_GTTSEL_MASK (1<<11)
+#define   RING_FAULT_SRCID(x)   ((x >> 3) & 0xff)
+#define   RING_FAULT_FAULT_TYPE(x) ((x >> 1) & 0x3)
+#define   RING_FAULT_VALID      (1<<0)
+#define DONE_REG                0x40b0
 #define BSD_HWS_PGA_GEN7	(0x04180)
 #define BLT_HWS_PGA_GEN7	(0x04280)
 #define RING_ACTHD(base)	((base)+0x74)
@@ -483,7 +489,13 @@
 #define GEN7_SC_INSTDONE    0x07100
 #define GEN7_SAMPLER_INSTDONE   0x0e160
 #define GEN7_ROW_INSTDONE   0x0e164
-#define I915_NUM_INSTDONE_REG 4 
+#define RING_DMA_FADD(base)     ((base)+0x78)
+#define RING_INSTPM(base)       ((base)+0xc0)
+#define I915_NUM_INSTDONE_REG 4
+#define RING_IPEIR(base)        ((base)+0x64)
+#define RING_IPEHR(base)        ((base)+0x68)
+#define RING_INSTDONE(base)     ((base)+0x6c)
+#define RING_INSTPS(base)       ((base)+0x70) 
 #define INSTPS		0x02070 /* 965+ only */
 #define INSTDONE1	0x0207c /* 965+ only */
 #define ACTHD_I965	0x02074
@@ -497,6 +509,7 @@
 #define INSTDONE	0x02090
 #define NOPID		0x02094
 #define HWSTAM		0x02098
+#define DMA_FADD_I8XX   0x020d0
 #define VCS_INSTDONE	0x1206C
 #define VCS_IPEIR	0x12064
 #define VCS_IPEHR	0x12068
@@ -507,8 +520,8 @@
 #define BCS_ACTHD	0x22074
 
 #define ERROR_GEN6	0x040a0
-
-
+#define DERRMR          0x44050
+#define GEN7_ERR_INT    0x44040
 /*
  * Performance measurement regs
  */
diff --git a/drivers/gpu/drm/emgd/src/core/i915/i915_trace.h b/drivers/gpu/drm/emgd/src/core/i915/i915_trace.h
index cf42625..7f469b4 100644
--- a/drivers/gpu/drm/emgd/src/core/i915/i915_trace.h
+++ b/drivers/gpu/drm/emgd/src/core/i915/i915_trace.h
@@ -1,3 +1,28 @@
+/*
+ * Copyright (c) 2006 Dave Airlie <airlied@linux.ie>
+ * Copyright (c) 2007-2008 Intel Corporation
+ *   Jesse Barnes <jesse.barnes@intel.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+ * IN THE SOFTWARE.
+ */
+
 #if !defined(_I915_TRACE_H_) || defined(TRACE_HEADER_MULTI_READ)
 #define _I915_TRACE_H_
 
diff --git a/drivers/gpu/drm/emgd/src/core/i915/intel_atomic.c b/drivers/gpu/drm/emgd/src/core/i915/intel_atomic.c
index e693816..6f0028f 100644
--- a/drivers/gpu/drm/emgd/src/core/i915/intel_atomic.c
+++ b/drivers/gpu/drm/emgd/src/core/i915/intel_atomic.c
@@ -475,8 +475,11 @@ static int plane_set(struct intel_atomic_state *s,
 				return -ENOENT;
 			}
 			plane->fb = obj_to_fb(obj);
-		} else
+		} else {
 			plane->fb = NULL;
+
+			state->changed = false;
+		}
 	} else
 		return -ENOENT;
 
@@ -1514,7 +1517,7 @@ static int intel_atomic_check(struct drm_device *dev, void *state)
 		if (!st->dirty || !plane->fb) {
 			if (!plane->fb) {
 				emgd_core_disable_ovlplane((drm_emgd_private_t *)dev->dev_private, 
-							to_intel_plane(plane), 0);
+							to_intel_plane(plane), 1);
 			}
 
 			continue;
diff --git a/drivers/gpu/drm/emgd/src/core/i915/intel_pm.c b/drivers/gpu/drm/emgd/src/core/i915/intel_pm.c
index a382383..7977313 100644
--- a/drivers/gpu/drm/emgd/src/core/i915/intel_pm.c
+++ b/drivers/gpu/drm/emgd/src/core/i915/intel_pm.c
@@ -2510,7 +2510,6 @@ void gen6_set_rps(struct drm_device *dev, u8 val)
 void valleyview_set_rps(struct drm_device *dev, u8 val)
 {
 	struct drm_i915_private *dev_priv = dev->dev_private;
-	unsigned long timeout = jiffies + msecs_to_jiffies(100);
 	u32 limits = gen6_rps_limits(dev_priv, &val);
 	u32 pval;
 
@@ -2523,14 +2522,6 @@ void valleyview_set_rps(struct drm_device *dev, u8 val)
 
 	valleyview_punit_write(dev_priv, PUNIT_REG_GPU_FREQ_REQ, val);
 
-	do {
-		valleyview_punit_read(dev_priv, PUNIT_REG_GPU_FREQ_STS, &pval);
-		if (time_after(jiffies, timeout)) {
-			DRM_DEBUG_DRIVER("timed out waiting for Punit\n");
-			break;
-		}
-		udelay(10);
-	} while (pval & 1);
 
 	valleyview_punit_read(dev_priv, PUNIT_REG_GPU_FREQ_STS, &pval);
 	if ((pval >> 8) != val)
diff --git a/drivers/gpu/drm/emgd/src/core/i915/intel_ringbuffer.h b/drivers/gpu/drm/emgd/src/core/i915/intel_ringbuffer.h
index 428bb66..3e8b60a 100644
--- a/drivers/gpu/drm/emgd/src/core/i915/intel_ringbuffer.h
+++ b/drivers/gpu/drm/emgd/src/core/i915/intel_ringbuffer.h
@@ -1,3 +1,32 @@
+/*
+ * Copyright © 2008-2013 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+ * IN THE SOFTWARE.
+ *
+ * Authors:
+ *    Eric Anholt <eric@anholt.net>
+ *    Zou Nan hai <nanhai.zou@intel.com>
+ *    Xiang Hai hao<haihao.xiang@intel.com>
+ *
+ */
+
 #ifndef _INTEL_RINGBUFFER_H_
 #define _INTEL_RINGBUFFER_H_
 
diff --git a/drivers/gpu/drm/emgd/src/core/init/gn7/micro_init_vlv.c b/drivers/gpu/drm/emgd/src/core/init/gn7/micro_init_vlv.c
index d90c2a1..6c3bf9d 100644
--- a/drivers/gpu/drm/emgd/src/core/init/gn7/micro_init_vlv.c
+++ b/drivers/gpu/drm/emgd/src/core/init/gn7/micro_init_vlv.c
@@ -71,7 +71,7 @@ extern os_pci_dev_t bridge_dev;
 static platform_context_vlv_t platform_context_vlv;
 
 init_dispatch_t init_dispatch_vlv = {
-	"Intel ValleyView Processor",
+	"Intel(R) Atom Processor E3800 Product Family/ Intel(R) Celeron Processor N2920/J1900",
 	"VLV_XXX",
 	"hdmi",
 	query_vlv,
diff --git a/drivers/gpu/drm/emgd/src/display/mode/cmn/kms_mode.c b/drivers/gpu/drm/emgd/src/display/mode/cmn/kms_mode.c
index c866ea0..4b696f7 100644
--- a/drivers/gpu/drm/emgd/src/display/mode/cmn/kms_mode.c
+++ b/drivers/gpu/drm/emgd/src/display/mode/cmn/kms_mode.c
@@ -1118,6 +1118,10 @@ int s3d_mode_set(emgd_crtc_t *emgd_crtc,
 		emgd_fb->igd_flags &= ~IGD_HDMI_STEREO_3D_MODE;
 	}
 
+	/* Instead of every time reading current s3d mode from
+	 * port attributes, save it in crtc for faster access */
+	emgd_crtc->current_s3d_mode = s3d_mode_sel;
+
 	EMGD_TRACE_EXIT;
 	return IGD_SUCCESS;
 }
diff --git a/drivers/gpu/drm/emgd/src/display/mode/gn7/kms_mode_vlv.c b/drivers/gpu/drm/emgd/src/display/mode/gn7/kms_mode_vlv.c
index 1ee8086..fb4eb70 100644
--- a/drivers/gpu/drm/emgd/src/display/mode/gn7/kms_mode_vlv.c
+++ b/drivers/gpu/drm/emgd/src/display/mode/gn7/kms_mode_vlv.c
@@ -59,6 +59,11 @@ extern emgd_drm_config_t *config_drm;
 #define CHECK_VGA(a) 1
 extern os_pci_dev_t bridge_dev; 
 
+#define SPRITE_A 0x2
+#define SPRITE_B 0x3
+#define SPRITE_C 0x5
+#define SPRITE_D 0x4
+
 /*-----------------------------------------------------------------------------
  * Function Prototypes : Exported Device Dependent Hooks for KMS
  *---------------------------------------------------------------------------*/
@@ -3139,7 +3144,15 @@ static int kms_queue_flip_vlv(emgd_crtc_t *emgd_crtc,
 		pitch = emgd_crtc->freezed_pitch | emgd_crtc->freezed_tiled;
 	} else {
        	if (emgd_fb->igd_flags & IGD_HDMI_STEREO_3D_MODE) {
-            pitch = emgd_crtc->base.fb->pitches[plane_select - 1] | bo->tiling_mode;
+       		if (plane_select == SPRITE_A || plane_select == SPRITE_C ) {
+       			pitch = emgd_crtc->base.fb->pitches[1] | bo->tiling_mode;
+       		}
+       		else if (plane_select == SPRITE_B || plane_select == SPRITE_D) {
+       			pitch = emgd_crtc->base.fb->pitches[2] | bo->tiling_mode;
+       		}
+       		else {
+       			pitch = emgd_crtc->base.fb->pitches[0] | bo->tiling_mode;
+       		}
         } else {
            	pitch = emgd_crtc->base.fb->DRMFB_PITCH | bo->tiling_mode;
        	}
diff --git a/drivers/gpu/drm/emgd/src/display/pi/cmn/pi.c b/drivers/gpu/drm/emgd/src/display/pi/cmn/pi.c
index fc67c8f..7fcefee 100644
--- a/drivers/gpu/drm/emgd/src/display/pi/cmn/pi.c
+++ b/drivers/gpu/drm/emgd/src/display/pi/cmn/pi.c
@@ -927,6 +927,17 @@ int pi_pd_init(igd_display_port_t *port,
 	pi_context->igd_context->module_dispatch.mode_filter_modes(pi_context->igd_context,
 		port, pd_timing_table);
 
+	/* This will set it to default, 640x480@60, if there is no supported timings
+	supported by the hardware - in this case, setting one/more user DTDs which are
+	not supported by the harware. In this process, there is no need as well to re-enable
+	the timing again via "enable_disable_timings" function since the standard timing flag has
+	already been abled in mode_table.c*/
+
+	if (!get_native_dtd(pd_timing_table, PI_SUPPORTED_TIMINGS, NULL, 0)) {
+		EMGD_ERROR("No supported resolution, set timing list to 640x480x60\n");
+		OS_MEMCPY(pd_timing_table, &crt_timing_table[0], sizeof(pd_timing_t));
+	}
+
 	/* Now save the timings in port */
 	port->timing_table = pd_timing_table;
 	port->num_timing = get_native_dtd(pd_timing_table,
diff --git a/drivers/gpu/drm/emgd/src/pal/dp/dp_port.c b/drivers/gpu/drm/emgd/src/pal/dp/dp_port.c
index ad496ca..82b73c8 100644
--- a/drivers/gpu/drm/emgd/src/pal/dp/dp_port.c
+++ b/drivers/gpu/drm/emgd/src/pal/dp/dp_port.c
@@ -2107,22 +2107,26 @@ int dp_read_rx_capability(dp_device_context_t *p_ctx)
 	unsigned long dpcd_max_rate = 0;
 	unsigned long dpcd_max_count = 0;
 	unsigned long dpcd_max_downspread = 0;
+
+#ifdef DPCD_DEBUG
 	unsigned long dpcd_rx_no = 0;
 	unsigned long dpcd_downstream_present = 0;
 	unsigned long dpcd_max_channel_coding = 0;
 	unsigned long dpcd_downstream_port_count = 0;
+#endif
 	unsigned long dpcd_training_aux_interval = 0;
-	unsigned long dpcd_i2c_control_cap = 0;
 	unsigned long dpcd_edp_configuration_cap = 0;
-
 	unsigned long dpcd_port0_cap0 = 0;
+
+#ifdef DPCD_DEBUG
+	unsigned long dpcd_i2c_control_cap = 0;
 	unsigned long dpcd_port0_cap1 = 0;
 	unsigned long dpcd_port1_cap0 = 0;
 	unsigned long dpcd_port1_cap1 = 0;
-
 	unsigned long edp_rev = 0;
 	unsigned long edp_gen_cap_reg_1 = 0;
 	unsigned long edp_backlight_adjustment_cap_reg = 0;
+#endif
 
 	EMGD_TRACE_ENTER;
 	EMGD_DEBUG("dp: dp_read_rx_capability()");
@@ -2160,6 +2164,7 @@ int dp_read_rx_capability(dp_device_context_t *p_ctx)
 	p_ctx->dpcd_max_spread = dpcd_max_downspread;
 	EMGD_DEBUG("dp: DPCD_MAX_DOWNSPREAD: 0x%02lx", dpcd_max_downspread);
 
+#ifdef DPCD_DEBUG
 	/* DPCD 4, Number assigned to the RX Port; value = +1 */
 	dpcd_rx_no = dpcdRead(p_ctx, 0, DPCD_NO_RX_PORT_COUNT, 1);
 	EMGD_DEBUG("dp: DPCD_NO_RX_PORT_COUNT: 0x%02lx", dpcd_rx_no);
@@ -2175,12 +2180,14 @@ int dp_read_rx_capability(dp_device_context_t *p_ctx)
 	/* DPCD 7, Number of Downstream Port Count*/
 	dpcd_downstream_port_count = dpcdRead(p_ctx, 0, DPCD_DOWNSTREAM_PORT_COUNT, 1);
 	EMGD_DEBUG("dp: DPCD_DOWNSTREAM_PORT_COUNT: 0x%02lx", dpcd_downstream_port_count);
-
+#endif
 	/* DPCD 8 & DPCD A, Local EDID Present*/
 	dpcd_port0_cap0 = dpcdRead(p_ctx, 0, DPCD_RECEIVE_PORT_0_CAP_0, 1);
-	dpcd_port1_cap0 = dpcdRead(p_ctx, 0, DPCD_RECEIVE_PORT_1_CAP_0, 1);
 	p_ctx->edid_present = (dpcd_port0_cap0 & BIT(1))?1:0;
 	EMGD_DEBUG("dp: DPCD_RECEIVE_PORT_0_CAP_0: 0x%02lx", dpcd_port0_cap0);
+
+#ifdef DPCD_DEBUG
+	dpcd_port1_cap0 = dpcdRead(p_ctx, 0, DPCD_RECEIVE_PORT_1_CAP_0, 1);
 	EMGD_DEBUG("dp: DPCD_RECEIVE_PORT_1_CAP_0: 0x%02lx", dpcd_port1_cap0);
 
 	/* DPCD 9 & DPCD B, Port Lanes Buffer Size; Buffer size = (value + 1)*32 per lane */
@@ -2193,6 +2200,7 @@ int dp_read_rx_capability(dp_device_context_t *p_ctx)
 	/* NOTE: If DisplayPort Rx doesn't implement the Physical I2C Bus, value 0x00 */
 	dpcd_i2c_control_cap = dpcdRead(p_ctx, 0, DPCD_I2C_CONTROL_CAP, 1);
 	EMGD_DEBUG("dp: DPCD_I2C_CONTROL_CAP: 0x%02lx", dpcd_i2c_control_cap);
+#endif
 
 	/* DPCD D, eDP Configuration Capability(eDP or DP detection) */
 	/* NOTE: This DPCD field is RESERVED in DP1.1a, while valid in DP1.2 and eDP1.3 onwards */
@@ -2209,9 +2217,10 @@ int dp_read_rx_capability(dp_device_context_t *p_ctx)
 
 	/* UMG: LFP Panel will be using 6bpc and DFP will be using 8bpc */
 	/*TODO: Need to read downstream bits per color.*/
-	p_ctx->bits_per_color = 0; /*(p_ctx->embedded_panel)? IGD_DISPLAY_BPC_6 : IGD_DISPLAY_BPC_8;*/
+	p_ctx->bits_per_color = 0; 
 	EMGD_DEBUG ("DPCD BPC is 0x%X", p_ctx->bits_per_color);
 	/*eDP AUX control registers*/
+#ifdef DPCD_DEBUG
 	edp_rev = dpcdRead(p_ctx, 0, 0x700, 1);
 	EMGD_DEBUG("dp: EDP_REV: 0x%02lx", edp_rev);
 
@@ -2220,7 +2229,7 @@ int dp_read_rx_capability(dp_device_context_t *p_ctx)
 
 	edp_backlight_adjustment_cap_reg = dpcdRead(p_ctx, 0, 0x702, 1);
 	EMGD_DEBUG("dp: EDP_BACKLIGHT_ADJUSTMENT_CAPABILITY_REGISTER: 0x%02lx", edp_backlight_adjustment_cap_reg);
-
+#endif
 	EMGD_DEBUG ("EDP:@2 p_ctx->embedded_panel = %lu", p_ctx->embedded_panel );
 
 	EMGD_TRACE_EXIT;
@@ -2473,7 +2482,7 @@ int dp_link_training(void *p_context, pd_timing_t *p_mode,unsigned long max_rate
 			 * DP Spec 1.2 states that if dpcd_rd_interval is 0x00, 
 			 * use 100us for CR and 400us for EQ Training
 			 */
-			pd_usleep(1000);
+			pd_usleep(100);
 		}
 
 		/* Checking clock recovery */
@@ -2512,7 +2521,7 @@ int dp_link_training(void *p_context, pd_timing_t *p_mode,unsigned long max_rate
 				eq_done = 1;
 				/* Notify the sink not in training and enable scrambling */
 				EMGD_DEBUG("dp: EQ SUCCESSFUL");
-				EMGD_ERROR("dp: Port:0x%lx Link Training Successful with %s",
+				EMGD_DEBUG("dp: Port:0x%lx Link Training Successful with %s",
 					p_ctx->control_reg, (max_rate == 0xa)?"HBR":"LBR");
 
 				/* Disable Training Pattern */
@@ -2678,7 +2687,7 @@ int dp_program_mntu_regs(dp_device_context_t *p_ctx, pd_timing_t *p_mode, unsign
 
 	EMGD_TRACE_ENTER;
 	
-	edp_panel_fit (p_ctx);
+	/* edp_panel_fit (p_ctx); */
 
 	switch ( bpc ){
 		case IGD_DISPLAY_BPC_10:
@@ -3204,6 +3213,10 @@ static void edp_panel_fit(dp_device_context_t *p_ctx)
 		}
 	}
 
+	/*disabled panel fitter for the cases where its resolution greater or more then 2560x1600*/
+	if(p_ctx->current_mode->width >= 2560 && p_ctx->current_mode->height >= 1600)
+		panel_fit_reg &= ~BIT(31);
+
 	dp_write_mmio_reg(p_ctx, PFIT_CONTROL, panel_fit_reg);
 	EMGD_DEBUG("panel_fit_reg 0x61230 = 0x%lx", panel_fit_reg);
 	EMGD_TRACE_EXIT;
diff --git a/drivers/gpu/drm/emgd/src/state/reg/gn7/reg_vlv.c b/drivers/gpu/drm/emgd/src/state/reg/gn7/reg_vlv.c
index ec429e7..94f2311 100644
--- a/drivers/gpu/drm/emgd/src/state/reg/gn7/reg_vlv.c
+++ b/drivers/gpu/drm/emgd/src/state/reg/gn7/reg_vlv.c
@@ -56,7 +56,6 @@ extern emgd_drm_config_t *config_drm;
 #define PLANE_LATCH_COUNT  4
 
 #define RING_BUFFER        0
-#define MMIO_MISC          1
 
 static reg_buffer_t *reg_alloc_vlv(igd_context_t *context,
 	unsigned long flags, void *_platform_context);
@@ -115,14 +114,9 @@ static unsigned char cr_regs_vlv[] = {
 
 /* MMIO states register to be saved */
 static unsigned long mmio_regs_vlv[] = {
-#if  MMIO_MISC
-	/* Fence Registers */
-	FENCE0, FENCE1, FENCE2, FENCE3, FENCE4, FENCE5, FENCE6, FENCE7,  // Fence
-	FENCE8, FENCE9, FENCE10, FENCE11, FENCE12, FENCE13, FENCE14, FENCE15,
 
 	/* GTT Control */
 	PGTBL_CTL,
-#endif
 
 	/* Program Clocks */
 	VGA0_DIVISOR, VGA1_DIVISOR, VGA_PD,
@@ -155,8 +149,8 @@ static unsigned long mmio_regs_vlv[] = {
 	VBLANK_A, VSYNC_A, PIPEASRC, BCLRPAT_A,
 	/* Program Pipe B */
 	/* Not restoring Pipe B registers so there is no data sent during CDVO reset */
-	PIPEB_STAT, /*HTOTAL_B, HBLANK_B, HSYNC_B, VTOTAL_B,
-	VBLANK_B, VSYNC_B,*/ PIPEBSRC, BCLRPAT_B,
+	PIPEB_STAT, HTOTAL_B, HBLANK_B, HSYNC_B, VTOTAL_B,
+	VBLANK_B, VSYNC_B, PIPEBSRC, BCLRPAT_B,
 
 
 	/* Enable Pipes */
@@ -850,9 +844,14 @@ static int reg_save_vlv(igd_context_t *context,
 		(reg_platform_context_vlv_t *)_platform_context;
 	int                        i;
 	unsigned char              *mmio;
+	struct drm_device *dev;
+	struct drm_i915_private *dev_priv;
+
 	platform_context_vlv_t *platform_context;
 	platform_context = (platform_context_vlv_t *)context->platform_context;
 
+	dev = (struct drm_device *)context->drm_dev;
+	dev_priv = dev->dev_private;
 
 	EMGD_TRACE_ENTER;
 
@@ -903,6 +902,10 @@ static int reg_save_vlv(igd_context_t *context,
 			reg_save_gtt_vlv(context, mmio, reg_args);
 	}
 
+	/*save fence registers*/
+	for (i = 0; i < 16; i++)
+		dev_priv->saveFENCE[i] = I915_READ64(FENCE_REG_SANDYBRIDGE_0 + (i * 8));
+
 	/* Save DAC registers */
 	if (reg_buffer->flags & IGD_REG_SAVE_DAC) {
 		EMGD_DEBUG("Saving DAC registers");
@@ -977,12 +980,18 @@ int reg_restore_vlv(igd_context_t *context,
 	reg_platform_context_vlv_t *reg_platform_context =
 		(reg_platform_context_vlv_t *)_platform_context;
 	unsigned char *mmio;
-	unsigned long *buffer,tmp;
+	unsigned long *buffer, tmp;
 	uint32_t lbb;
 	int i;
+	struct drm_device *dev;
+	struct drm_i915_private *dev_priv;
+
 	platform_context_vlv_t *platform_context;
 	platform_context = (platform_context_vlv_t *)context->platform_context;
 
+	dev = (struct drm_device *)context->drm_dev;
+	dev_priv = dev->dev_private;
+
 	EMGD_DEBUG("Entry - reg_restore");
 
 	tmp = sideband_register_read(context->device_context.virt_mmadr, 0x61, 0x100604f0);
@@ -1022,6 +1031,10 @@ int reg_restore_vlv(igd_context_t *context,
 		}
 	}
 
+	/* restore fence registers */
+	for (i = 0; i < 16; i++)
+		I915_WRITE64(FENCE_REG_SANDYBRIDGE_0 + (i * 8), dev_priv->saveFENCE[i]);
+
 	/* Restore MMIO registers */
 	if (reg_buffer->flags & IGD_REG_SAVE_MMIO) {
 		EMGD_DEBUG("Restoring MMIO registers");
diff --git a/drivers/gpu/drm/emgd/tools/fw_tool/README b/drivers/gpu/drm/emgd/tools/fw_tool/README
index 96c3854..944288c 100644
--- a/drivers/gpu/drm/emgd/tools/fw_tool/README
+++ b/drivers/gpu/drm/emgd/tools/fw_tool/README
@@ -51,9 +51,112 @@ CONFIG_EXTRA_FIRMWARE are set accordingly.  Here is an example:
 If you choose to build the EMGD driver into the kernel, and you want to specify
 the firmware to be used with a module parameter, you should add
 emgd.firmware="emgd.bin" to your kernel boot parameters.
+Please take caution on licensing issue where non-GPL content should not be bundled 
+into the kernel. As an example, a trademark or company logo is usually a non-GPL 
+content and shall not be in any part of the kernel.
+For splash screen feature, there is a method where we can use a non-GPL content. 
+The method will utilise a temporary file system which is called 'initial ram 
+filesystem' or in short 'initramfs'. This file system will be loaded during the 
+boot process of the kernel. Instruction for this method is described below:
+
 You can also build multiple firmware blobs in your kernel, and then choose which
 one you want to use via the kernel or modprobe command line.  For instance you
 can have different binary blobs like: single_10x7.bin, dual_12x10_6x4.bin and
 then specify which of those you want to use in the command line.  You would
 specify multiple firmare blobs to include as follows:
 	CONFIG_EXTRA_FIRMWARE="single_10x7.bin dual_12x10_6x4.bin"
+
+---------------------------------------------------------------------------------------
+Instruction to load binary blob from initramfs:
+
+******************************************************
+STEP 1 --> COMPILE EMGD AS A KERNEL BUILT-IN DRIVER
+******************************************************
+1.1	Make emgd as built-in driver in kernel source compilation:
+		cd <path_to_the_kernel_src> 	
+		make menuconfig
+
+ 	In device drivers->graphics support, put a <*> instead of <M> for 
+	DRM and EMGD.
+	
+	Save & Exit.
+
+1.2	Make sure there is no binary blob configured as a built-in in the kernel 
+	configuration:
+		#CONFIG_FIRMWARE_IN_KERNEL is not set
+		CONFIG_EXTRA_FIRMWARE=""    (leave CONFIG_EXTRA_FIRMWARE to be blanked)
+
+1.3 	Compile kernel source code:
+		make    		
+
+1.4	After the compilation is completed, copy bzImage(kernel image) to /boot:
+		cp <kernel_src>/arch/x86/boot/bzImage /boot/vmlinuz-version-emgd-built-in
+
+************************************************************
+STEP 2 --> CREATE AN INITRAMFS WITH THE BINARY BLOB INSIDE
+************************************************************
+
+2.1	You can either build a new initramfs or modifying the existing one.
+
+2.2	To create a new initramfs, you need a tools named dracut. You can install the 
+	package through yum:
+		yum install dracut
+
+2.3 	Create a new initramfs by doing:
+	FEDORA - Using dracut to create initramfs
+
+		dracut initramfs-XXX.img kernel_name	(kernel_name=uname -r) 
+
+	TIZEN - Using make initramfs script to create initramfs(if dracut is not available)
+		Go to link -> http://www.linuxfromscratch.org/blfs/view/svn/postlfs/initramfs.html
+		Follow the steps in the link to install mkinitramfs.
+
+		mkinitramfs kernel_name 	(kernel_name=uname -r)	
+
+2.4 	Create a folder to store the extracted contents of initramfs:
+		mkdir /root/initramfs
+		cd /root/initramfs
+
+2.5	Extract the contents of initramfs into initramfs folder(might take some time). 
+	You can either pick a new created initramfs or modify the existing initrmafs which 
+	is usually put under /boot/ (Eg. initramfs-3.8.0-FC18-64-WW29.img)
+		gunzip < boot/initramfs-XXX.img | cpio -i     (new) 			
+		OR
+		gunzip < boot/initramfs-3.8.0-FC18-64-WW29.img | cpio -i     (existing)
+
+2.6	You will have the initramfs in the initramfs folder now. The next step is to put the 
+	binary blob, emgd.bin into the initramfs.
+		cd /root/initramfs/lib
+		mkdir firmware
+		cd firmware
+		cp <path_to_local_binary_blob>/emgd.bin .
+		cd ../../../
+
+2.7	Pack all the contents in the initramfs folder back to an img file(might take some time).
+		find | cpio -H newc -o | gzip -9 > /boot/initramfs-XXX-with-binaryblob.img
+
+2.8	Note that now there is a new initramfs with emgd.bin inside in the 
+	/boot/initramfs-XXX-with-binaryblob.img
+
+************************************
+STEP 3 --> CONFIGURE THE BOOT MENU
+************************************
+3.1	Edit the boot menu so it loads the requested kernel and initramfs. Make sure 
+	
+	1.	Kernel load the emgd built-in image:
+			linux /boot/vmlinuz-version-emgd-built-in
+ 
+	2.	emgd.firmware as a linux/ parameter points to the correct name of the binary blob 
+			emgd.firmware="emgd.bin"
+
+	3.	initrd points to the correct initramfs. 
+			initrd /boot/initramfs-XXX-with-binaryblob.img
+
+
+NOTE:
+You can remove all the binary blob in your local filesystem in /lib/firmware to make sure 
+when the kernel built-in EMGD is installed, it will take the firmware from the initramfs not 
+from the real file system. Reboot your system and you will get the splash screen from 
+the initramfs.
+-------------------------------------------------------------------------------------------------------
+
diff --git a/drivers/gpu/drm/emgd/tools/fw_tool/make_blob.sh b/drivers/gpu/drm/emgd/tools/fw_tool/make_blob.sh
index 4bb4f13..dab4a3c 100644
--- a/drivers/gpu/drm/emgd/tools/fw_tool/make_blob.sh
+++ b/drivers/gpu/drm/emgd/tools/fw_tool/make_blob.sh
@@ -31,7 +31,16 @@ then
     	path_to_img_data=$2
 fi
 
+os=`uname -m`
+
+if [ $os == "x86_64" ]
+then
+	bit=64
+else 
+	bit=32
+fi
+
 echo $path_to_img_data
-\cp -f $1 ./user_config.c && \cp -f $path_to_img_data ./image_data.h && make && ./fw_tool -write_binary && \cp -f emgd.bin $pref.bin
+\cp -f $1 ./user_config.c && \cp -f $path_to_img_data ./image_data.h && make && ./fw_tool -write_binary && \cp -f emgd_$bit.bin $pref.bin
 
 
-- 
1.7.5.4

