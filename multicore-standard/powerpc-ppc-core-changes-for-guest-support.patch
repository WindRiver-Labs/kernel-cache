From 47afa29b892b7cc51a2b470c5484867171c057c9 Mon Sep 17 00:00:00 2001
From: WRS Support <support@windriver.com>
Date: Fri, 2 Oct 2009 16:15:25 -0400
Subject: [PATCH] powerpc: ppc core changes for guest support

This represents changes to existing core powerpc kernel files in
order to support linux as a guest OS on WR hypervisor.

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
Signed-off-by: Bruce Ashfield <bruce.ashfield@windriver.com>
---
 arch/powerpc/Makefile                    |    7 ++-
 arch/powerpc/boot/main.c                 |   12 +++-
 arch/powerpc/boot/wrapper                |    2 +-
 arch/powerpc/include/asm/dma-mapping.h   |   52 ++++++++++++++--
 arch/powerpc/include/asm/fs_pd.h         |    4 +
 arch/powerpc/include/asm/hw_irq.h        |   77 ++++++++++++++++++++++++
 arch/powerpc/include/asm/machdep.h       |    2 +
 arch/powerpc/include/asm/mmu_context.h   |    2 +-
 arch/powerpc/include/asm/page_32.h       |    2 +-
 arch/powerpc/include/asm/pgalloc-32.h    |    2 +-
 arch/powerpc/include/asm/pgtable-ppc32.h |   59 ++++++++++++++++---
 arch/powerpc/include/asm/reg.h           |    4 +
 arch/powerpc/include/asm/system.h        |    4 +
 arch/powerpc/kernel/Makefile             |   17 +++++-
 arch/powerpc/kernel/entry_32.S           |   93 +++++++++++++++++++++++-------
 arch/powerpc/kernel/head_booke.h         |    6 +-
 arch/powerpc/kernel/head_wrhv.S          |    5 +-
 arch/powerpc/kernel/irq.c                |   31 ++++++++++-
 arch/powerpc/kernel/kgdb.c               |   16 +++++-
 arch/powerpc/kernel/misc_32.S            |   50 ++++++++++++++++
 arch/powerpc/kernel/module.c             |    1 -
 arch/powerpc/kernel/process.c            |   21 +++++++
 arch/powerpc/kernel/setup-common.c       |   15 +++++
 arch/powerpc/kernel/setup_32.c           |   17 +++++-
 arch/powerpc/kernel/smp.c                |    2 +-
 arch/powerpc/kernel/time.c               |   58 ++++++++++++++++++-
 arch/powerpc/kernel/traps.c              |   19 ++++++-
 arch/powerpc/kvm/Kconfig                 |   24 ++++++++
 arch/powerpc/mm/fault.c                  |   20 ++++++-
 arch/powerpc/mm/fsl_booke_mmu.c          |   24 ++++++--
 arch/powerpc/mm/hash_low_32.S            |    4 +
 arch/powerpc/mm/init_32.c                |   23 ++++++-
 arch/powerpc/mm/mem.c                    |   25 +++++++-
 arch/powerpc/mm/mmu_context_32.c         |    1 +
 arch/powerpc/mm/mmu_decl.h               |   10 +++-
 arch/powerpc/mm/pgtable_32.c             |   18 +++++-
 arch/powerpc/sysdev/fsl_soc.c            |   26 ++++++++-
 37 files changed, 676 insertions(+), 79 deletions(-)

diff --git a/arch/powerpc/Makefile b/arch/powerpc/Makefile
index 2e2d38e..2ed3c59 100644
--- a/arch/powerpc/Makefile
+++ b/arch/powerpc/Makefile
@@ -136,7 +136,12 @@ head-y				:= arch/powerpc/kernel/head_$(CONFIG_WORD_SIZE).o
 head-$(CONFIG_8xx)		:= arch/powerpc/kernel/head_8xx.o
 head-$(CONFIG_40x)		:= arch/powerpc/kernel/head_40x.o
 head-$(CONFIG_44x)		:= arch/powerpc/kernel/head_44x.o
-head-$(CONFIG_FSL_BOOKE)	:= arch/powerpc/kernel/head_fsl_booke.o
+
+ifeq ($(CONFIG_WRHV),y)
+head-$(CONFIG_FSL_BOOKE)        := arch/powerpc/kernel/head_wrhv.o
+else
+head-$(CONFIG_FSL_BOOKE)        := arch/powerpc/kernel/head_fsl_booke.o
+endif
 
 head-$(CONFIG_PPC64)		+= arch/powerpc/kernel/entry_64.o
 head-$(CONFIG_PPC_FPU)		+= arch/powerpc/kernel/fpu.o
diff --git a/arch/powerpc/boot/main.c b/arch/powerpc/boot/main.c
index 9e7f3dd..754b77e 100644
--- a/arch/powerpc/boot/main.c
+++ b/arch/powerpc/boot/main.c
@@ -139,8 +139,10 @@ static void prep_cmdline(void *chosen)
 
 	printf("\n\rLinux/PowerPC load: %s", cmdline);
 	/* If possible, edit the command line */
+#ifndef CONFIG_WRHV
 	if (console_ops.edit_cmdline)
 		console_ops.edit_cmdline(cmdline, COMMAND_LINE_SIZE);
+#endif
 	printf("\n\r");
 
 	/* Put the command line back into the devtree for the kernel */
@@ -195,9 +197,15 @@ void start(void)
 	if (console_ops.close)
 		console_ops.close();
 
-	kentry = (kernel_entry_t) vmlinux.addr;
+	/* For Hypervisor, kernel entry should be at 0xC0000000 */
+#ifdef CONFIG_WRHV
+#define ENT_OFFSET 0xC0000000
+#else
+#define ENT_OFFSET 0
+#endif
+	kentry = (kernel_entry_t) (vmlinux.addr + ENT_OFFSET);
 	if (ft_addr)
-		kentry(ft_addr, 0, NULL);
+		kentry(ft_addr, ENT_OFFSET, NULL);
 	else
 		kentry((unsigned long)initrd.addr, initrd.size,
 		       loader_info.promptr);
diff --git a/arch/powerpc/boot/wrapper b/arch/powerpc/boot/wrapper
index 965c237..2c06771 100755
--- a/arch/powerpc/boot/wrapper
+++ b/arch/powerpc/boot/wrapper
@@ -138,7 +138,7 @@ objflags=-S
 tmp=$tmpdir/zImage.$$.o
 ksection=.kernel:vmlinux.strip
 isection=.kernel:initrd
-link_address='0x400000'
+link_address='0x600000'
 
 case "$platform" in
 pseries)
diff --git a/arch/powerpc/include/asm/dma-mapping.h b/arch/powerpc/include/asm/dma-mapping.h
index c7ca45f..5e84b2c 100644
--- a/arch/powerpc/include/asm/dma-mapping.h
+++ b/arch/powerpc/include/asm/dma-mapping.h
@@ -273,6 +273,7 @@ static inline int dma_set_mask(struct device *dev, u64 dma_mask)
 	return 0;
 }
 
+#ifndef CONFIG_PARAVIRT
 static inline void *dma_alloc_coherent(struct device *dev, size_t size,
 				       dma_addr_t * dma_handle,
 				       gfp_t gfp)
@@ -298,27 +299,64 @@ static inline void *dma_alloc_coherent(struct device *dev, size_t size,
 #endif
 }
 
-static inline void
-dma_free_coherent(struct device *dev, size_t size, void *vaddr,
-		  dma_addr_t dma_handle)
+static inline dma_addr_t
+dma_map_single(struct device *dev, void *ptr, size_t size,
+	       enum dma_data_direction direction)
+{
+	BUG_ON(direction == DMA_NONE);
+
+	__dma_sync(ptr, size, direction);
+	return virt_to_bus(ptr);
+}
+#else
+static inline void *native_dma_alloc_coherent(struct device *dev, size_t size,
+				       dma_addr_t * dma_handle,
+				       gfp_t gfp)
 {
 #ifdef CONFIG_NOT_COHERENT_CACHE
-	__dma_free_coherent(size, vaddr);
+	return __dma_alloc_coherent(size, dma_handle, gfp);
 #else
-	free_pages((unsigned long)vaddr, get_order(size));
+	void *ret;
+	/* ignore region specifiers */
+	gfp &= ~(__GFP_DMA | __GFP_HIGHMEM);
+
+	if (dev == NULL || dev->coherent_dma_mask < 0xffffffff)
+		gfp |= GFP_DMA;
+
+	ret = (void *)__get_free_pages(gfp, get_order(size));
+
+	if (ret != NULL) {
+		memset(ret, 0, size);
+		*dma_handle = virt_to_bus(ret);
+	}
+
+	return ret;
 #endif
 }
 
 static inline dma_addr_t
-dma_map_single(struct device *dev, void *ptr, size_t size,
+native_dma_map_single(struct device *dev, void *ptr, size_t size,
 	       enum dma_data_direction direction)
 {
 	BUG_ON(direction == DMA_NONE);
 
 	__dma_sync(ptr, size, direction);
-
 	return virt_to_bus(ptr);
 }
+#include <asm/pv_dma-mapping.h>
+#endif /* CONFIG_PARAVIRT */
+
+static inline void
+dma_free_coherent(struct device *dev, size_t size, void *vaddr,
+		  dma_addr_t dma_handle)
+{
+#ifdef CONFIG_NOT_COHERENT_CACHE
+	__dma_free_coherent(size, vaddr);
+#else
+	free_pages((unsigned long)vaddr, get_order(size));
+#endif
+}
+
 
 static inline void dma_unmap_single(struct device *dev, dma_addr_t dma_addr,
 				    size_t size,
diff --git a/arch/powerpc/include/asm/fs_pd.h b/arch/powerpc/include/asm/fs_pd.h
index 9361cd5..876d862 100644
--- a/arch/powerpc/include/asm/fs_pd.h
+++ b/arch/powerpc/include/asm/fs_pd.h
@@ -44,7 +44,11 @@ static inline int uart_baudrate(void)
 
 static inline int uart_clock(void)
 {
+#ifdef CONFIG_WRHV
+	return wrhv_cpu_freq;
+#else
         return ppc_proc_freq;
+#endif
 }
 
 #endif
diff --git a/arch/powerpc/include/asm/hw_irq.h b/arch/powerpc/include/asm/hw_irq.h
index 3b3a71d..1368473 100644
--- a/arch/powerpc/include/asm/hw_irq.h
+++ b/arch/powerpc/include/asm/hw_irq.h
@@ -13,6 +13,7 @@
 
 extern void timer_interrupt(struct pt_regs *);
 
+#ifndef CONFIG_PARAVIRT
 #ifdef CONFIG_PPC64
 #include <asm/paca.h>
 
@@ -137,6 +138,82 @@ static inline int irqs_disabled_flags(unsigned long flags)
 
 #endif /* CONFIG_PPC64 */
 
+#else /* !CONFIG_PARAVIRT */
+
+/* native implementation taken from !CONFIG_PPC64 */
+#if defined(CONFIG_BOOKE)
+#define SET_MSR_EE(x)	mtmsr(x)
+#define native_local_irq_restore(flags)	__asm__ __volatile__("wrtee %0" : : "r" (flags) : "memory")
+#else
+#define SET_MSR_EE(x)	mtmsr(x)
+#define native_local_irq_restore(flags)	mtmsr(flags)
+#endif
+
+static inline void native_local_irq_disable(void)
+{
+#ifdef CONFIG_BOOKE
+#ifdef CONFIG_KVM_GUEST
+	__asm__ __volatile__("wrtee %0": : "r"(0) :"memory");
+#else
+	__asm__ __volatile__("wrteei 0": : :"memory");
+#endif
+#else
+	unsigned long msr;
+	__asm__ __volatile__("": : :"memory");
+	msr = mfmsr();
+	SET_MSR_EE(msr & ~MSR_EE);
+#endif
+}
+
+static inline void native_local_irq_enable(void)
+{
+#ifdef CONFIG_BOOKE
+#ifdef CONFIG_KVM_GUEST
+	__asm__ __volatile__("wrtee %0": : "r"(MSR_EE) :"memory");
+#else
+	__asm__ __volatile__("wrteei 1": : :"memory");
+#endif
+#else
+	unsigned long msr;
+	__asm__ __volatile__("": : :"memory");
+	msr = mfmsr();
+	SET_MSR_EE(msr | MSR_EE);
+#endif
+}
+
+static inline void native_local_irq_save_ptr(unsigned long *flags)
+{
+	unsigned long msr;
+	msr = mfmsr();
+	*flags = msr;
+#ifdef CONFIG_BOOKE
+#ifdef CONFIG_KVM_GUEST
+	__asm__ __volatile__("wrtee %0": : "r"(0) :"memory");
+#else
+	__asm__ __volatile__("wrteei 0": : :"memory");
+#endif
+#else
+	SET_MSR_EE(msr & ~MSR_EE);
+#endif
+	__asm__ __volatile__("": : :"memory");
+}
+
+#define native_local_save_flags(flags)	((flags) = mfmsr())
+#define native_local_irq_save(flags)	native_local_irq_save_ptr(&flags)
+#define native_irqs_disabled()		((mfmsr() & MSR_EE) == 0)
+
+#define native_hard_irq_enable()	native_local_irq_enable()
+#define native_hard_irq_disable()	native_local_irq_disable()
+
+static inline int native_irqs_disabled_flags(unsigned long flags)
+{
+	return (flags & MSR_EE) == 0;
+}
+
+/* Hypervior specific implementation */
+#include <asm/pv_hw_irq.h>
+#endif /* CONFIG_PARAVIRT */
+
 /*
  * interrupt-retrigger: should we handle this via lost interrupts and IPIs
  * or should we not care like we do now ? --BenH.
diff --git a/arch/powerpc/include/asm/machdep.h b/arch/powerpc/include/asm/machdep.h
index 893aafd..23c21d2 100644
--- a/arch/powerpc/include/asm/machdep.h
+++ b/arch/powerpc/include/asm/machdep.h
@@ -361,5 +361,7 @@ static inline void log_error(char *buf, unsigned int err_type, int fatal)
 void generic_suspend_disable_irqs(void);
 void generic_suspend_enable_irqs(void);
 
+extern unsigned int get_pvr(void);
+
 #endif /* __KERNEL__ */
 #endif /* _ASM_POWERPC_MACHDEP_H */
diff --git a/arch/powerpc/include/asm/mmu_context.h b/arch/powerpc/include/asm/mmu_context.h
index 249ae7f..6dab487 100644
--- a/arch/powerpc/include/asm/mmu_context.h
+++ b/arch/powerpc/include/asm/mmu_context.h
@@ -65,7 +65,7 @@ static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)
 #define LAST_CONTEXT    	255
 #define FIRST_CONTEXT    	1
 
-#elif defined(CONFIG_E200) || defined(CONFIG_E500)
+#elif defined(CONFIG_E200) || defined(CONFIG_E500) || defined(CONFIG_PARAVIRT)
 #define NO_CONTEXT      	256
 #define LAST_CONTEXT    	255
 #define FIRST_CONTEXT    	1
diff --git a/arch/powerpc/include/asm/page_32.h b/arch/powerpc/include/asm/page_32.h
index ebfae53..eef1d35 100644
--- a/arch/powerpc/include/asm/page_32.h
+++ b/arch/powerpc/include/asm/page_32.h
@@ -18,7 +18,7 @@
  * The basic type of a PTE - 64 bits for those CPUs with > 32 bit
  * physical addressing.  For now this just the IBM PPC440.
  */
-#ifdef CONFIG_PTE_64BIT
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_PARAVIRT)
 typedef unsigned long long pte_basic_t;
 #define PTE_SHIFT	(PAGE_SHIFT - 3)	/* 512 ptes per page */
 #else
diff --git a/arch/powerpc/include/asm/pgalloc-32.h b/arch/powerpc/include/asm/pgalloc-32.h
index 1cb9245..f579541 100644
--- a/arch/powerpc/include/asm/pgalloc-32.h
+++ b/arch/powerpc/include/asm/pgalloc-32.h
@@ -17,7 +17,7 @@ extern void pgd_free(struct mm_struct *mm, pgd_t *pgd);
 #define __pmd_free_tlb(tlb,x)		do { } while (0)
 /* #define pgd_populate(mm, pmd, pte)      BUG() */
 
-#ifndef CONFIG_BOOKE
+#if !defined(CONFIG_BOOKE) || defined (CONFIG_PARAVIRT)
 #define pmd_populate_kernel(mm, pmd, pte)	\
 		(pmd_val(*(pmd)) = __pa(pte) | _PMD_PRESENT)
 #define pmd_populate(mm, pmd, pte)	\
diff --git a/arch/powerpc/include/asm/pgtable-ppc32.h b/arch/powerpc/include/asm/pgtable-ppc32.h
index f154859..bef47c3 100644
--- a/arch/powerpc/include/asm/pgtable-ppc32.h
+++ b/arch/powerpc/include/asm/pgtable-ppc32.h
@@ -76,7 +76,13 @@ extern int icache_44x_need_flush;
  * are an index to the second level table.  The combined pgdir/pmd first
  * level has 2048 entries and the second level has 512 64-bit PTE entries.
  * -Matt
+ *
+ * For WRHV, the combined pgdir/pmd first level has 2 page 2048 entries
+ * and the second level has 9bit indexing into 512 elements with each element
+ * contains an 8-byte PTE
+ * -Yiming
  */
+
 /* PGDIR_SHIFT determines what a top-level page table entry can map */
 #define PGDIR_SHIFT	(PAGE_SHIFT + PTE_SHIFT)
 #define PGDIR_SIZE	(1UL << PGDIR_SHIFT)
@@ -134,8 +140,9 @@ extern int icache_44x_need_flush;
  * (hardware-defined) PowerPC PTE as closely as possible.
  */
 
-#if defined(CONFIG_40x)
-
+#if defined(CONFIG_PARAVIRT)
+#include <asm/pv_pgtable-ppc32.h>
+#elif defined(CONFIG_40x)
 /* There are several potential gotchas here.  The 40x hardware TLBLO
    field looks like this:
 
@@ -277,7 +284,7 @@ extern int icache_44x_need_flush;
 #define _PTE_NONE_MASK	0xffffffff00000000ULL
 
 
-#elif defined(CONFIG_FSL_BOOKE)
+#elif defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT)
 /*
    MMU Assist Register 3:
 
@@ -436,9 +443,15 @@ extern int icache_44x_need_flush;
 
 #ifdef CONFIG_44x
 #define _PAGE_BASE	(_PAGE_PRESENT | _PAGE_ACCESSED | _PAGE_GUARDED)
-#else
+#elif defined (CONFIG_PARAVIRT)
+/* _PAGE_BASE for CONFIG_PARAVIRT is defined in pv_def_pgtable-ppc32.h */
+#ifndef _PAGE_BASE
 #define _PAGE_BASE	(_PAGE_PRESENT | _PAGE_ACCESSED)
 #endif
+#else /* !CONFIG_PARAVIRT */
+#define _PAGE_BASE	(_PAGE_PRESENT | _PAGE_ACCESSED)
+#endif
+
 #define _PAGE_WRENABLE	(_PAGE_RW | _PAGE_DIRTY | _PAGE_HWWRITE)
 #define _PAGE_KERNEL	(_PAGE_BASE | _PAGE_SHARED | _PAGE_WRENABLE)
 
@@ -589,7 +602,7 @@ extern void add_hash_page(unsigned context, unsigned long va,
  * the old pte value.  In the 64-bit PTE case we lock around the
  * low PTE word since we expect ALL flag bits to be there
  */
-#ifndef CONFIG_PTE_64BIT
+#if !defined(CONFIG_PTE_64BIT) && !defined(CONFIG_PARAVIRT)
 static inline unsigned long pte_update(pte_t *p,
 				       unsigned long clr,
 				       unsigned long set)
@@ -618,7 +631,7 @@ static inline unsigned long pte_update(pte_t *p,
 #endif
 	return old;
 }
-#else /* CONFIG_PTE_64BIT */
+#else /* CONFIG_PTE_64BIT && CONFIG_PARAVIRT */
 /* TODO: Change that to only modify the low word and move set_pte_at()
  * out of line
  */
@@ -652,13 +665,14 @@ static inline unsigned long long pte_update(pte_t *p,
 #endif
 	return old;
 }
-#endif /* CONFIG_PTE_64BIT */
+#endif /* CONFIG_PTE_64BIT && CONFIG_PARAVIRT */
 
 /*
  * set_pte stores a linux PTE into the linux page table.
  * On machines which use an MMU hash table we avoid changing the
  * _PAGE_HASHPTE bit.
  */
+#ifndef CONFIG_PARAVIRT
 static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,
 			      pte_t *ptep, pte_t pte)
 {
@@ -668,12 +682,26 @@ static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,
 	*ptep = pte;
 #endif
 }
+#else
+static inline void native_set_pte_at(struct mm_struct *mm, unsigned long addr,
+			      pte_t *ptep, pte_t pte)
+{
+#if _PAGE_HASHPTE != 0
+	pte_update(ptep, ~_PAGE_HASHPTE, pte_val(pte) & ~_PAGE_HASHPTE);
+#else
+	*ptep = pte;
+
+#endif
+}
+
+#endif /* CONFIG_PARAVIRT */
 
 /*
  * 2.6 calls this without flushing the TLB entry; this is wrong
  * for our hash-based implementation, we fix that up here.
  */
 #define __HAVE_ARCH_PTEP_TEST_AND_CLEAR_YOUNG
+#ifndef CONFIG_PARAVIRT
 static inline int __ptep_test_and_clear_young(unsigned int context, unsigned long addr, pte_t *ptep)
 {
 	unsigned long old;
@@ -688,6 +716,21 @@ static inline int __ptep_test_and_clear_young(unsigned int context, unsigned lon
 }
 #define ptep_test_and_clear_young(__vma, __addr, __ptep) \
 	__ptep_test_and_clear_young((__vma)->vm_mm->context.id, __addr, __ptep)
+#else /* CONFIG_PARAVIRT */
+static inline int __ptep_test_and_clear_young(mm_context_t * ctx,
+                                              unsigned long addr, pte_t *ptep)
+{
+	unsigned long old;
+	old = pte_update(ptep, _PAGE_ACCESSED, 0);
+#if 0 
+        vbi_tlb_flush_vmmu (&vmmu_cfg, &addr, 1);
+#endif
+	return (old & _PAGE_ACCESSED) != 0;
+}
+
+#define ptep_test_and_clear_young(__vma, __addr, __ptep) \
+        __ptep_test_and_clear_young(&(__vma)->vm_mm->context.id, __addr, __ptep)
+#endif   /* CONFIG_PARAVIRT */
 
 #define __HAVE_ARCH_PTEP_GET_AND_CLEAR
 static inline pte_t ptep_get_and_clear(struct mm_struct *mm, unsigned long addr,
@@ -747,7 +790,7 @@ extern pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,
  * handler).  On everything else the pmd contains the physical address
  * of the pte page.  -- paulus
  */
-#ifndef CONFIG_BOOKE
+#if !defined(CONFIG_BOOKE) || defined(CONFIG_PARAVIRT)
 #define pmd_page_vaddr(pmd)	\
 	((unsigned long) __va(pmd_val(pmd) & PAGE_MASK))
 #define pmd_page(pmd)		\
diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c6d1ab6..76065bb 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -13,6 +13,10 @@
 #include <linux/stringify.h>
 #include <asm/cputable.h>
 
+/* Pickup paravirt specific registers */
+#if defined (CONFIG_PARAVIRT)
+#include <asm/reg_paravirt.h>
+#endif
 /* Pickup Book E specific registers. */
 #if defined(CONFIG_BOOKE) || defined(CONFIG_40x)
 #include <asm/reg_booke.h>
diff --git a/arch/powerpc/include/asm/system.h b/arch/powerpc/include/asm/system.h
index d6648c1..d4b9329 100644
--- a/arch/powerpc/include/asm/system.h
+++ b/arch/powerpc/include/asm/system.h
@@ -199,6 +199,10 @@ extern u32 booke_wdt_period;
 struct device_node;
 extern void note_scsi_host(struct device_node *, void *);
 
+#ifdef CONFIG_PARAVIRT
+#define prepare_arch_switch(next)      local_irq_disable()
+#endif
+
 extern struct task_struct *__switch_to(struct task_struct *,
 	struct task_struct *);
 #define switch_to(prev, next, last)	((last) = __switch_to((prev), (next)))
diff --git a/arch/powerpc/kernel/Makefile b/arch/powerpc/kernel/Makefile
index a97fa1a..c62f47b 100644
--- a/arch/powerpc/kernel/Makefile
+++ b/arch/powerpc/kernel/Makefile
@@ -59,6 +59,11 @@ obj-$(CONFIG_HIBERNATION)	+= swsusp.o suspend.o \
 				   swsusp_$(CONFIG_WORD_SIZE).o
 obj64-$(CONFIG_HIBERNATION)	+= swsusp_asm64.o
 obj-$(CONFIG_MODULES)		+= module.o module_$(CONFIG_WORD_SIZE).o
+
+ifeq ($(CONFIG_WRHV),y)
+obj-$(CONFIG_WRHV)              += wrhv_entry_32.o wrhv_misc_32.o
+endif
+
 obj-$(CONFIG_44x)		+= cpu_setup_44x.o
 obj-$(USE_IMMEDIATE)		+= immediate.o
 
@@ -66,7 +71,13 @@ extra-$(CONFIG_PPC_STD_MMU)	:= head_32.o
 extra-$(CONFIG_PPC64)		:= head_64.o
 extra-$(CONFIG_40x)		:= head_40x.o
 extra-$(CONFIG_44x)		:= head_44x.o
-extra-$(CONFIG_FSL_BOOKE)	:= head_fsl_booke.o
+
+ifeq ($(CONFIG_WRHV),y)
+extra-$(CONFIG_WRHV)            := head_wrhv.o
+else
+extra-$(CONFIG_FSL_BOOKE)       := head_fsl_booke.o
+endif
+
 extra-$(CONFIG_8xx)		:= head_8xx.o
 extra-y				+= vmlinux.lds
 
@@ -99,6 +110,10 @@ obj-$(CONFIG_8XX_MINIMAL_FPEMU) += softemu8xx.o
 
 obj-$(CONFIG_KVM_GUEST)		+= kvm.o
 
+obj-$(CONFIG_WRHV)		+= vbi/
+
+obj-$(CONFIG_PARAVIRT)         += paravirt.o
+
 ifneq ($(CONFIG_PPC_INDIRECT_IO),y)
 obj-y				+= iomap.o
 endif
diff --git a/arch/powerpc/kernel/entry_32.S b/arch/powerpc/kernel/entry_32.S
index 18c9727..7dcdf97 100644
--- a/arch/powerpc/kernel/entry_32.S
+++ b/arch/powerpc/kernel/entry_32.S
@@ -32,9 +32,6 @@
 #include <asm/unistd.h>
 #include <asm/ftrace.h>
 
-#undef SHOW_SYSCALLS
-#undef SHOW_SYSCALLS_TASK
-
 /*
  * MSR_KERNEL is > 0x10000 on 4xx/Book-E since it include MSR_CE.
  */
@@ -44,6 +41,26 @@
 #define LOAD_MSR_KERNEL(r, x)	li r,(x)
 #endif
 
+/* native macros */
+#define ENABLE_MSR_EE  ori r10,r10,MSR_EE; SYNC; MTMSRD(r10);
+#define DISABLE_MSR_EE LOAD_MSR_KERNEL(r10,MSR_KERNEL); SYNC; MTMSRD(r10);
+
+/* paravirt overrides */
+#ifdef CONFIG_PARAVIRT
+#ifdef PARAVIRT_ENABLE_MSR_EE
+#undef ENABLE_MSR_EE
+#define ENABLE_MSR_EE PARAVIRT_ENABLE_MSR_EE
+#endif
+#endif
+
+#ifdef CONFIG_PARAVIRT
+#ifdef PARAVIRT_DISABLE_MSR_EE
+#undef DISABLE_MSR_EE
+#define DISABLE_MSR_EE PARAVIRT_DISABLE_MSR_EE
+#endif
+#endif
+
+
 #ifdef CONFIG_BOOKE
 	.globl	mcheck_transfer_to_handler
 mcheck_transfer_to_handler:
@@ -130,6 +147,13 @@ transfer_to_handler_full:
 
 	.globl	transfer_to_handler
 transfer_to_handler:
+#ifndef CONFIG_PARAVIRT
+       b       native_transfer_to_handler
+#else
+       b       paravirt_transfer_to_handler
+#endif
+       .globl  native_transfer_to_handler
+native_transfer_to_handler:
 	stw	r2,GPR2(r11)
 	stw	r12,_NIP(r11)
 	stw	r9,_MSR(r11)
@@ -144,7 +168,7 @@ transfer_to_handler:
 	beq	2f			/* if from user, fix up THREAD.regs */
 	addi	r11,r1,STACK_FRAME_OVERHEAD
 	stw	r11,PT_REGS(r12)
-#if defined(CONFIG_40x) || defined(CONFIG_BOOKE)
+#if defined(CONFIG_40x) || defined(CONFIG_BOOKE) && !defined(CONFIG_PARAVIRT)
 	/* Check to see if the dbcr0 register is set up to debug.  Use the
 	   internal debug mode bit to do this. */
 	lwz	r12,THREAD_DBCR0(r12)
@@ -185,13 +209,13 @@ transfer_to_handler:
 	bt-	31-TLF_NAPPING,4f
 	bt-	31-TLF_SLEEPING,7f
 #endif /* CONFIG_6xx || CONFIG_E500 */
-	.globl transfer_to_handler_cont
+
+       .globl  transfer_to_handler_cont
 transfer_to_handler_cont:
 3:
 	mflr	r9
 	lwz	r11,0(r9)		/* virtual address of handler */
 	lwz	r9,4(r9)		/* where to go when done */
-	mtspr	SPRN_SRR0,r11
 	mtspr	SPRN_SRR1,r10
 	mtlr	r9
 	SYNC
@@ -266,8 +290,17 @@ syscall_dotrace_cont:
 	addi	r9,r1,STACK_FRAME_OVERHEAD
 	PPC440EP_ERR42
 	blrl			/* Call handler */
-	.globl	ret_from_syscall
+
+       .globl  ret_from_syscall
 ret_from_syscall:
+#ifndef CONFIG_PARAVIRT
+       b       native_ret_from_syscall
+#else
+       b       paravirt_ret_from_syscall
+#endif 
+
+       .globl  native_ret_from_syscall
+native_ret_from_syscall:
 #ifdef SHOW_SYSCALLS
 	bl	do_show_syscall_exit
 #endif
@@ -288,7 +321,7 @@ ret_from_syscall:
 	oris	r11,r11,0x1000	/* Set SO bit in CR */
 	stw	r11,_CCR(r1)
 syscall_exit_cont:
-#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE)
+#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE) && !(CONFIG_PARAVIRT)
 	/* If the process has its own DBCR0 value, load it up.  The internal
 	   debug mode bit tells us that dbcr0 should be loaded. */
 	lwz	r0,THREAD+THREAD_DBCR0(r2)
@@ -358,7 +391,16 @@ syscall_dotrace:
 	REST_NVGPRS(r1)
 	b	syscall_dotrace_cont
 
+       .globl  syscall_exit_work
 syscall_exit_work:
+#ifndef CONFIG_PARAVIRT
+       b       native_syscall_exit_work
+#else
+       b       paravirt_syscall_exit_work
+#endif
+       
+       .globl  native_syscall_exit_work
+native_syscall_exit_work:
 	andi.	r0,r9,_TIF_RESTOREALL
 	beq+	0f
 	REST_NVGPRS(r1)
@@ -395,6 +437,7 @@ syscall_exit_work:
 	beq	ret_from_except
 
 	/* Re-enable interrupts */
+	
 	ori	r10,r10,MSR_EE
 	SYNC
 	MTMSRD(r10)
@@ -560,6 +603,14 @@ handle_page_fault:
  * in arch/ppc/kernel/process.c
  */
 _GLOBAL(_switch)
+#ifndef CONFIG_PARAVIRT
+       b       native_switch
+#else
+       b       paravirt_switch
+#endif
+
+_GLOBAL(native_switch)
+
 	stwu	r1,-INT_FRAME_SIZE(r1)
 	mflr	r0
 	stw	r0,INT_FRAME_SIZE+4(r1)
@@ -705,10 +756,7 @@ ret_from_except:
 	/* Hard-disable interrupts so that current_thread_info()->flags
 	 * can't change between when we test it and when we return
 	 * from the interrupt. */
-	LOAD_MSR_KERNEL(r10,MSR_KERNEL)
-	SYNC			/* Some chip revs have problems here... */
-	MTMSRD(r10)		/* disable interrupts */
-
+	DISABLE_MSR_EE
 	lwz	r3,_MSR(r1)	/* Returning to user mode? */
 	andi.	r0,r3,MSR_PR
 	beq	resume_kernel
@@ -721,7 +769,7 @@ user_exc_return:		/* r10 contains MSR_KERNEL here */
 	bne	do_work
 
 restore_user:
-#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE)
+#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE) && !defined(CONFIG_PARAVIRT)
 	/* Check whether this process has its own DBCR0 value.  The internal
 	   debug mode bit tells us that dbcr0 should be loaded. */
 	lwz	r0,THREAD+THREAD_DBCR0(r2)
@@ -755,6 +803,13 @@ resume_kernel:
 
 	/* interrupts are hard-disabled at this point */
 restore:
+#ifndef CONFIG_PARAVIRT
+       b       native_restore
+#else
+       b       paravirt_restore
+#endif
+
+native_restore:
 #ifdef CONFIG_44x
 	lis	r4,icache_44x_need_flush@ha
 	lwz	r5,icache_44x_need_flush@l(r4)
@@ -1035,14 +1090,10 @@ do_work:			/* r10 contains MSR_KERNEL here */
 	beq	do_user_signal
 
 do_resched:			/* r10 contains MSR_KERNEL here */
-	ori	r10,r10,MSR_EE
-	SYNC
-	MTMSRD(r10)		/* hard-enable interrupts */
+	ENABLE_MSR_EE
 	bl	schedule
 recheck:
-	LOAD_MSR_KERNEL(r10,MSR_KERNEL)
-	SYNC
-	MTMSRD(r10)		/* disable interrupts */
+	DISABLE_MSR_EE
 	rlwinm	r9,r1,0,0,(31-THREAD_SHIFT)
 	lwz	r9,TI_FLAGS(r9)
 	andi.	r0,r9,_TIF_NEED_RESCHED
@@ -1050,9 +1101,7 @@ recheck:
 	andi.	r0,r9,_TIF_USER_WORK_MASK
 	beq	restore_user
 do_user_signal:			/* r10 contains MSR_KERNEL here */
-	ori	r10,r10,MSR_EE
-	SYNC
-	MTMSRD(r10)		/* hard-enable interrupts */
+	ENABLE_MSR_EE
 	/* save r13-r31 in the exception frame, if not already done */
 	lwz	r3,_TRAP(r1)
 	andi.	r0,r3,1
diff --git a/arch/powerpc/kernel/head_booke.h b/arch/powerpc/kernel/head_booke.h
index 924a13f..ba0c63c 100644
--- a/arch/powerpc/kernel/head_booke.h
+++ b/arch/powerpc/kernel/head_booke.h
@@ -78,7 +78,7 @@
 
 #define EXC_LVL_FRAME_OVERHEAD	(THREAD_SIZE - INT_FRAME_SIZE - EXC_LVL_SIZE)
 
-#ifdef CONFIG_SMP
+#if defined(CONFIG_SMP) && !defined(CONFIG_PARAVIRT) 
 #define BOOKE_LOAD_EXC_LEVEL_STACK(level)		\
 	mfspr	r8,SPRN_PIR;				\
 	slwi	r8,r8,2;				\
@@ -168,8 +168,8 @@ label:									     \
 	nop;								     \
 	isync;
 #else
-#define	START_EXCEPTION(label)						     \
-        .align 5;              						     \
+#define START_EXCEPTION(label)                                               \
+        .align 5;                                                            \
 label:
 #endif
 
diff --git a/arch/powerpc/kernel/head_wrhv.S b/arch/powerpc/kernel/head_wrhv.S
index cdc3bdf..7958316 100644
--- a/arch/powerpc/kernel/head_wrhv.S
+++ b/arch/powerpc/kernel/head_wrhv.S
@@ -44,8 +44,9 @@
 #include <asm/cache.h>
 #include "head_booke.h"
 #include "head_wrhv.h"
-#include <vbi/vbInterface.h>
-#include <vbi/sys/vmmu.h>
+#include <vbi/interface.h>
+#include <vbi/vmmu.h>
+#include <vbi/syscalls.h>
 
 /* As with the other PowerPC ports, it is expected that when code
  * execution begins here, the following registers contain valid, yet
diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index a1928d6..9751e02 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -71,6 +71,20 @@
 #endif
 
 int __irq_offset_value;
+/* get and set method for ppc_spurious_interrupts, so other file 
+   have access to this variable
+ */
+static int ppc_spurious_interrupts;
+int get_ppc_spurious_interrupts(void)
+{
+       return ppc_spurious_interrupts;
+}
+
+void set_ppc_spurious_interrupts(int value)
+{
+       ppc_spurious_interrupts = value;
+}
+
 static int ppc_spurious_interrupts;
 
 #ifdef CONFIG_PPC32
@@ -246,8 +260,14 @@ void fixup_irqs(cpumask_t map)
 }
 #endif
 
+
+void paravirt_do_IRQ(struct pt_regs *regs) __attribute__((weak, alias("native_do_IRQ")));
 void do_IRQ(struct pt_regs *regs)
 {
+       paravirt_do_IRQ(regs);  
+}
+void native_do_IRQ(struct pt_regs *regs)
+{
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	unsigned int irq;
 #ifdef CONFIG_IRQSTACKS
@@ -770,7 +790,10 @@ unsigned int irq_create_of_mapping(struct device_node *controller,
 }
 EXPORT_SYMBOL_GPL(irq_create_of_mapping);
 
-unsigned int irq_of_parse_and_map(struct device_node *dev, int index)
+unsigned int paravirt_irq_of_parse_and_map(struct device_node *dev, int index)
+        __attribute__((weak, alias("native_irq_of_parse_and_map")));
+
+unsigned int native_irq_of_parse_and_map(struct device_node *dev, int index)
 {
 	struct of_irq oirq;
 
@@ -780,6 +803,12 @@ unsigned int irq_of_parse_and_map(struct device_node *dev, int index)
 	return irq_create_of_mapping(oirq.controller, oirq.specifier,
 				     oirq.size);
 }
+
+unsigned int irq_of_parse_and_map(struct device_node *dev, int index)
+{
+       return paravirt_irq_of_parse_and_map(dev, index);
+}
+
 EXPORT_SYMBOL_GPL(irq_of_parse_and_map);
 
 void irq_dispose_mapping(unsigned int virq)
diff --git a/arch/powerpc/kernel/kgdb.c b/arch/powerpc/kernel/kgdb.c
index fe8f71d..3de7c60 100644
--- a/arch/powerpc/kernel/kgdb.c
+++ b/arch/powerpc/kernel/kgdb.c
@@ -318,7 +318,12 @@ void gdb_regs_to_pt_regs(unsigned long *gdb_regs, struct pt_regs *regs)
 /*
  * This function does PowerPC specific procesing for interfacing to gdb.
  */
-int kgdb_arch_handle_exception(int vector, int signo, int err_code,
+int paravirt_kgdb_arch_handle_exception(int vector, int signo, int err_code,
+                               char *remcom_in_buffer, char *remcom_out_buffer,
+                               struct pt_regs *linux_regs) __attribute__
+			((weak, alias("native_kgdb_arch_handle_exception")));
+
+int native_kgdb_arch_handle_exception(int vector, int signo, int err_code,
 			       char *remcom_in_buffer, char *remcom_out_buffer,
 			       struct pt_regs *linux_regs)
 {
@@ -356,6 +361,15 @@ int kgdb_arch_handle_exception(int vector, int signo, int err_code,
 	return -1;
 }
 
+int kgdb_arch_handle_exception(int vector, int signo, int err_code,
+			       char *remcom_in_buffer, char *remcom_out_buffer,
+			       struct pt_regs *linux_regs)
+{
+	return paravirt_kgdb_arch_handle_exception(vector, signo, err_code,
+					remcom_in_buffer, remcom_out_buffer,
+					linux_regs);	
+}
+
 /*
  * Global data
  */
diff --git a/arch/powerpc/kernel/misc_32.S b/arch/powerpc/kernel/misc_32.S
index 8b177b5..7b25f0f 100644
--- a/arch/powerpc/kernel/misc_32.S
+++ b/arch/powerpc/kernel/misc_32.S
@@ -281,6 +281,13 @@ ivax_lock:
  * Flush MMU TLB
  */
 _GLOBAL(_tlbia)
+#ifndef CONFIG_PARAVIRT
+	b	native_tlbia
+#else
+	b	paravirt_tlbia
+#endif
+
+_GLOBAL(native_tlbia)
 #if defined(CONFIG_40x)
 	sync			/* Flush to memory before changing mapping */
 	tlbia
@@ -368,6 +375,13 @@ _GLOBAL(_tlbia)
  * Flush MMU TLB for a particular address
  */
 _GLOBAL(_tlbie)
+#ifndef CONFIG_PARAVIRT
+        b       native_tlbie
+#else
+        b       paravirt_tlbie
+#endif
+
+_GLOBAL(native_tlbie)
 #if defined(CONFIG_40x)
 	/* We run the search with interrupts disabled because we have to change
 	 * the PID and I don't want to preempt when that happens.
@@ -530,6 +544,14 @@ END_FTR_SECTION_IFSET(CPU_FTR_UNIFIED_ID_CACHE)
  * flush_icache_range(unsigned long start, unsigned long stop)
  */
 _KPROBE(__flush_icache_range)
+#ifndef CONFIG_PARAVIRT
+	b	native__flush_icache_range
+#else
+	b	paravirt__flush_icache_range
+#endif
+
+_KPROBE(native__flush_icache_range)
+
 BEGIN_FTR_SECTION
 	blr				/* for 601, do nothing */
 END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
@@ -560,6 +582,13 @@ END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
  * clean_dcache_range(unsigned long start, unsigned long stop)
  */
 _GLOBAL(clean_dcache_range)
+#ifndef CONFIG_PARAVIRT
+        b       native_clean_dcache_range
+#else
+        b       paravirt_clean_dcache_range
+#endif
+
+_GLOBAL(native_clean_dcache_range)
 	li	r5,L1_CACHE_BYTES-1
 	andc	r3,r3,r5
 	subf	r4,r3,r4
@@ -581,6 +610,13 @@ _GLOBAL(clean_dcache_range)
  * flush_dcache_range(unsigned long start, unsigned long stop)
  */
 _GLOBAL(flush_dcache_range)
+#ifndef CONFIG_PARAVIRT
+	b	native_flush_dcache_range
+#else
+	b	paravirt_flush_dcache_range
+#endif
+
+_GLOBAL(native_flush_dcache_range)
 	li	r5,L1_CACHE_BYTES-1
 	andc	r3,r3,r5
 	subf	r4,r3,r4
@@ -626,6 +662,13 @@ _GLOBAL(invalidate_dcache_range)
  *	void __flush_dcache_icache(void *page)
  */
 _GLOBAL(__flush_dcache_icache)
+#ifndef CONFIG_PARAVIRT
+	b	native__flush_dcache_icache
+#else
+	b	paravirt__flush_dcache_icache
+#endif
+
+_GLOBAL(native__flush_dcache_icache)
 BEGIN_FTR_SECTION
 	blr
 END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
@@ -663,6 +706,13 @@ END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
  *	void __flush_dcache_icache_phys(unsigned long physaddr)
  */
 _GLOBAL(__flush_dcache_icache_phys)
+#ifndef CONFIG_PARAVIRT
+	b	native__flush_dcache_icache_phys
+#else
+	b	paravirt__flush_dcache_icache_phys
+#endif
+
+_GLOBAL(native__flush_dcache_icache_phys)
 BEGIN_FTR_SECTION
 	blr					/* for 601, do nothing */
 END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
diff --git a/arch/powerpc/kernel/module.c b/arch/powerpc/kernel/module.c
index 7ff2924..3561412 100644
--- a/arch/powerpc/kernel/module.c
+++ b/arch/powerpc/kernel/module.c
@@ -35,7 +35,6 @@ void *module_alloc(unsigned long size)
 {
 	if (size == 0)
 		return NULL;
-
 	return vmalloc_exec(size);
 }
 
diff --git a/arch/powerpc/kernel/process.c b/arch/powerpc/kernel/process.c
index 5966700..34e37d1 100644
--- a/arch/powerpc/kernel/process.c
+++ b/arch/powerpc/kernel/process.c
@@ -186,6 +186,27 @@ void flush_vsx_to_thread(struct task_struct *tsk)
 
 #ifdef CONFIG_SPE
 
+
+#ifdef CONFIG_PARAVIRT
+/* refer to native implementation in
+ * linux/arch/powerpc/kernel/head_fsl_booke.S
+ */
+void giveup_spe(struct task_struct *tsk)
+{
+	/* if no previous owner, done */
+	if (!tsk){
+                return;
+        }
+
+        /* disable SPE for previous task */
+        tsk->thread.regs->msr &= ~MSR_SPE;
+
+#ifndef CONFIG_SMP
+        last_task_used_spe = 0;
+#endif /* CONFIG_SMP */
+}
+#endif
+
 void enable_kernel_spe(void)
 {
 	WARN_ON(preemptible());
diff --git a/arch/powerpc/kernel/setup-common.c b/arch/powerpc/kernel/setup-common.c
index 9cc5a52..a3a8f1e 100644
--- a/arch/powerpc/kernel/setup-common.c
+++ b/arch/powerpc/kernel/setup-common.c
@@ -159,6 +159,17 @@ extern u32 cpu_temp_both(unsigned long cpu);
 DEFINE_PER_CPU(unsigned int, pvr);
 #endif
 
+unsigned paravirt_get_pvr(void) __attribute__((weak, alias("native_get_pvr")));
+unsigned int native_get_pvr(void)
+{
+       return mfspr(SPRN_PVR);
+}
+
+unsigned int get_pvr(void)
+{
+       return paravirt_get_pvr();
+}
+
 static int show_cpuinfo(struct seq_file *m, void *v)
 {
 	unsigned long cpu_id = (unsigned long)v - 1;
@@ -201,11 +212,15 @@ static int show_cpuinfo(struct seq_file *m, void *v)
 		return 0;
 	}
 
+#ifdef CONFIG_PARAVIRT
+	pvr = get_pvr();
+#else
 #ifdef CONFIG_SMP
 	pvr = per_cpu(pvr, cpu_id);
 #else
 	pvr = mfspr(SPRN_PVR);
 #endif
+#endif /* CONFIG_PARAVIRT */
 	maj = (pvr >> 8) & 0xFF;
 	min = pvr & 0xFF;
 
diff --git a/arch/powerpc/kernel/setup_32.c b/arch/powerpc/kernel/setup_32.c
index d3bde01..63926de 100644
--- a/arch/powerpc/kernel/setup_32.c
+++ b/arch/powerpc/kernel/setup_32.c
@@ -78,6 +78,10 @@ int ucache_bsize;
  * from the address that it was linked at, so we must use RELOC/PTRRELOC
  * to access static data (including strings).  -- paulus
  */
+#ifdef CONFIG_PARAVIRT
+extern void paravirt_init(void);
+#endif
+
 notrace unsigned long __init early_init(unsigned long dt_ptr)
 {
 	unsigned long offset = reloc_offset();
@@ -87,12 +91,19 @@ notrace unsigned long __init early_init(unsigned long dt_ptr)
 	 * caches on yet */
 	memset_io((void __iomem *)PTRRELOC(&__bss_start), 0,
 			__bss_stop - __bss_start);
-
+	
+	/* 
+	 * initialize paravirtual operations 
+	 */
+#ifdef CONFIG_PARAVIRT
+	paravirt_init();
+#endif
+	
 	/*
 	 * Identify the CPU type and fix up code sections
 	 * that depend on which cpu we have.
 	 */
-	spec = identify_cpu(offset, mfspr(SPRN_PVR));
+	spec = identify_cpu(offset, get_pvr());
 
 	do_feature_fixups(spec->cpu_features,
 			  PTRRELOC(&__start___ftr_fixup),
@@ -130,7 +141,7 @@ notrace void __init machine_init(unsigned long dt_ptr, unsigned long phys)
 		ppc_md.power_save = ppc6xx_idle;
 #endif
 
-#ifdef CONFIG_E500
+#if defined(CONFIG_E500) && !defined(CONFIG_PARAVIRT)
 	if (cpu_has_feature(CPU_FTR_CAN_DOZE) ||
 	    cpu_has_feature(CPU_FTR_CAN_NAP))
 		ppc_md.power_save = e500_idle;
diff --git a/arch/powerpc/kernel/smp.c b/arch/powerpc/kernel/smp.c
index 5337ca7..ce183cd 100644
--- a/arch/powerpc/kernel/smp.c
+++ b/arch/powerpc/kernel/smp.c
@@ -178,7 +178,7 @@ struct thread_info *current_set[NR_CPUS];
 
 static void __devinit smp_store_cpu_info(int id)
 {
-	per_cpu(pvr, id) = mfspr(SPRN_PVR);
+	per_cpu(pvr, id) = get_pvr();
 }
 
 static void __init smp_create_idle(unsigned int cpu)
diff --git a/arch/powerpc/kernel/time.c b/arch/powerpc/kernel/time.c
index 5ae9613..f7370c7 100644
--- a/arch/powerpc/kernel/time.c
+++ b/arch/powerpc/kernel/time.c
@@ -73,6 +73,10 @@
 #include <asm/iseries/hv_call_xm.h>
 #endif
 
+#ifdef CONFIG_WRHV
+#include <linux/wrhv.h>
+#endif
+
 /* powerpc clocksource/clockevent code */
 
 #include <linux/clockchips.h>
@@ -125,6 +129,31 @@ struct decrementer_clock {
 
 static DEFINE_PER_CPU(struct decrementer_clock, decrementers);
 
+#ifdef CONFIG_WRHV
+static void wrhv_set_mode(enum clock_event_mode mode,
+				 struct clock_event_device *dev)
+{
+	return;
+}
+
+static int wrhv_set_next_event(unsigned long evt,
+				      struct clock_event_device *dev)
+{
+	//__get_cpu_var(decrementers).next_tb = get_tb_or_rtc() + evt;
+	//set_dec(evt);
+	return 0;
+}
+static struct clock_event_device wrhv_clockevent = {
+       .name           = "wrhv",
+       .shift          = 32,
+       .irq            = 0,
+       .mult           = 1,	/* To be filled in */
+       .set_mode       = wrhv_set_mode,
+       .set_next_event = wrhv_set_next_event,
+       .features       = CLOCK_EVT_FEAT_ONESHOT,
+};
+#endif
+
 #ifdef CONFIG_PPC_ISERIES
 static unsigned long __initdata iSeries_recal_titan;
 static signed long __initdata iSeries_recal_tb;
@@ -607,9 +636,27 @@ void timer_interrupt(struct pt_regs * regs)
 {
 	struct pt_regs *old_regs;
 	struct decrementer_clock *decrementer =  &__get_cpu_var(decrementers);
+#ifdef CONFIG_WRHV
+	struct clock_event_device *evt = &wrhv_clockevent;
+#else	
 	struct clock_event_device *evt = &decrementer->event;
+#endif
 	u64 now;
 
+#ifdef CONFIG_WRHV
+	if (atomic_read(&ppc_n_lost_interrupts) != 0)
+		do_IRQ(regs);
+
+	old_regs = set_irq_regs(regs);
+	irq_enter();
+
+	calculate_steal_time();
+
+	trace_trap_entry(regs, regs->trap);
+
+	wrhv_timer_interrupt(0, NULL);
+#else /* CONFIG_WRHV */
+
 	/* Ensure a positive value is written to the decrementer, or else
 	 * some CPUs will continuue to take decrementer exceptions */
 	set_dec(DECREMENTER_MAX);
@@ -665,6 +712,7 @@ void timer_interrupt(struct pt_regs * regs)
 		cu->current_tb = mfspr(SPRN_PURR);
 	}
 #endif
+#endif /* CONFIG_WRHV */
 
 	irq_exit();
 	set_irq_regs(old_regs);
@@ -889,6 +937,9 @@ void update_vsyscall_tz(void)
 
 static void __init clocksource_init(void)
 {
+#ifdef CONFIG_WRHV
+	return;
+#else
 	struct clocksource *clock;
 
 	if (__USE_RTC())
@@ -906,6 +957,7 @@ static void __init clocksource_init(void)
 
 	printk(KERN_INFO "clocksource: %s mult[%x] shift[%d] registered\n",
 	       clock->name, clock->mult, clock->shift);
+#endif
 }
 
 static int decrementer_set_next_event(unsigned long evt,
@@ -1077,8 +1129,12 @@ void __init time_init(void)
 	/* Register the clocksource, if we're not running on iSeries */
 	if (!firmware_has_feature(FW_FEATURE_ISERIES))
 		clocksource_init();
-
+#ifndef CONFIG_WRHV
 	init_decrementer_clockevent();
+#else
+	wrhv_clockevent.cpumask = cpumask_of_cpu(0);
+	clockevents_register_device(&wrhv_clockevent);
+#endif  /* CONFIG_WRHV */
 }
 
 
diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 74cc478..9c98eb0 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -789,7 +789,15 @@ static int emulate_instruction(struct pt_regs *regs)
 	/* Emulate the mfspr rD, PVR. */
 	if ((instword & INST_MFSPR_PVR_MASK) == INST_MFSPR_PVR) {
 		rd = (instword >> 21) & 0x1f;
+#ifndef CONFIG_WRHV
 		regs->gpr[rd] = mfspr(SPRN_PVR);
+#else
+		/* 
+		 * PVR for wrhv hypervisor should be 0x80200000,
+		 * why is it 0x80200010?
+		 */
+		regs->gpr[rd] = 0x80200010;
+#endif
 		return 0;
 	}
 
@@ -1057,7 +1065,10 @@ void SoftwareEmulation(struct pt_regs *regs)
 
 #if defined(CONFIG_40x) || defined(CONFIG_BOOKE)
 
-void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
+void paravirt_DebugException(struct pt_regs *regs, unsigned long debug_status)
+	 __attribute__((weak, alias("native_DebugException")));
+
+void __kprobes native_DebugException(struct pt_regs *regs, unsigned long debug_status)
 {
 	if (debug_status & DBSR_IC) {	/* instruction completion */
 		regs->msr &= ~MSR_DE;
@@ -1098,6 +1109,12 @@ void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 		do_dabr(regs, mfspr(SPRN_DAC1), debug_status);
 	}
 }
+
+void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
+{
+	paravirt_DebugException(regs, debug_status);
+}
+
 #endif /* CONFIG_4xx || CONFIG_BOOKE */
 
 #if !defined(CONFIG_TAU_INT)
diff --git a/arch/powerpc/kvm/Kconfig b/arch/powerpc/kvm/Kconfig
index 6b07601..5cc5f9f 100644
--- a/arch/powerpc/kvm/Kconfig
+++ b/arch/powerpc/kvm/Kconfig
@@ -14,6 +14,30 @@ menuconfig VIRTUALIZATION
 
 if VIRTUALIZATION
 
+config PARAVIRT
+        bool "Enable paravirtualization code"
+        default y
+        depends on !X86_VOYAGER
+        help
+          This changes the kernel so it can modify itself when it is run
+          under a hypervisor, potentially improving performance significantly
+          over full virtualization.  However, when run without a hypervisor
+          the kernel is theoretically slower and slightly larger.
+
+          CONFIG_PARAVIRT assume a E500 like core and use 64 bit PTE.
+
+config PARAVIRT_CLOCK
+        bool
+        default n
+
+config PARAVIRT_DEBUG
+       bool "paravirt-ops debugging"
+       depends on PARAVIRT && DEBUG_KERNEL
+       help
+         Enable to debug paravirt_ops internals.  Specifically, BUG if
+         a paravirt_op is missing when it is called.
+
+
 config KVM
 	bool "Kernel-based Virtual Machine (KVM) support"
 	depends on 44x && EXPERIMENTAL
diff --git a/arch/powerpc/mm/fault.c b/arch/powerpc/mm/fault.c
index 2b22e0c..7126c5b 100644
--- a/arch/powerpc/mm/fault.c
+++ b/arch/powerpc/mm/fault.c
@@ -40,7 +40,6 @@
 #include <asm/tlbflush.h>
 #include <asm/siginfo.h>
 
-
 #ifdef CONFIG_KPROBES
 static inline int notify_page_fault(struct pt_regs *regs)
 {
@@ -64,6 +63,23 @@ static inline int notify_page_fault(struct pt_regs *regs)
 #endif
 
 /*
+ * this function restore mmu for paravirt operations,
+ * default native operation is noop
+ */
+void paravirt_vmmu_restore(void) __attribute__((weak, alias("native_vmmu_restore")));
+void native_vmmu_restore(void)
+{
+       /* default is noop */
+       return;
+}
+
+void vmmu_restore (void)
+{
+       paravirt_vmmu_restore();        
+       return;
+}
+
+/*
  * Check whether the instruction at regs->nip is a store using
  * an update addressing form which will update r1.
  */
@@ -335,6 +351,7 @@ bad_area_nosemaphore:
 	/* User mode accesses cause a SIGSEGV */
 	if (user_mode(regs)) {
 		_exception(SIGSEGV, regs, code, address);
+                vmmu_restore ();
 		return 0;
 	}
 
@@ -370,6 +387,7 @@ do_sigbus:
 		info.si_code = BUS_ADRERR;
 		info.si_addr = (void __user *)address;
 		force_sig_info(SIGBUS, &info, current);
+	        vmmu_restore ();
 		return 0;
 	}
 	return SIGBUS;
diff --git a/arch/powerpc/mm/fsl_booke_mmu.c b/arch/powerpc/mm/fsl_booke_mmu.c
index 131d729..435da75 100644
--- a/arch/powerpc/mm/fsl_booke_mmu.c
+++ b/arch/powerpc/mm/fsl_booke_mmu.c
@@ -177,18 +177,32 @@ void __init cam_mapin_ram(unsigned long cam0, unsigned long cam1,
 /*
  * MMU_init_hw does the chip-specific initialization of the MMU hardware.
  */
-void __init MMU_init_hw(void)
+void paravirt_MMU_init_hw(void) 
+	__attribute__((weak, alias("native_MMU_init_hw")));
+
+void __init native_MMU_init_hw(void)
 {
-	flush_instruction_cache();
+       flush_instruction_cache();
 }
 
-unsigned long __init mmu_mapin_ram(void)
+void __init MMU_init_hw(void)
 {
-	cam_mapin_ram(__cam0, __cam1, __cam2);
+       paravirt_MMU_init_hw();
+}
 
-	return __cam0 + __cam1 + __cam2;
+unsigned long paravirt_mmu_mapin_ram(void) 
+	__attribute__((weak, alias("native_mmu_mapin_ram")));
+
+unsigned long __init native_mmu_mapin_ram(void)
+{
+       cam_mapin_ram(__cam0, __cam1, __cam2);
+       return __cam0 + __cam1 + __cam2;
 }
 
+unsigned long __init mmu_mapin_ram(void)
+{
+       return paravirt_mmu_mapin_ram();
+}
 
 void __init
 adjust_total_lowmem(void)
diff --git a/arch/powerpc/mm/hash_low_32.S b/arch/powerpc/mm/hash_low_32.S
index b9ba7d9..2a23e27 100644
--- a/arch/powerpc/mm/hash_low_32.S
+++ b/arch/powerpc/mm/hash_low_32.S
@@ -98,7 +98,11 @@ _GLOBAL(hash_page)
 	/* Get PTE (linux-style) and check access */
 	lis	r0,KERNELBASE@h		/* check if kernel address */
 	cmplw	0,r4,r0
+#ifndef CONFIG_PARVIRT
 	mfspr	r8,SPRN_SPRG3		/* current task's THREAD (phys) */
+#else
+	PARAVIRT_MFSPR_SPRG3(r8)
+#endif /* CONFIG_PARAVIRT */
 	ori	r3,r3,_PAGE_USER|_PAGE_PRESENT /* test low addresses as user */
 	lwz	r5,PGDIR(r8)		/* virt page-table root */
 	blt+	112f			/* assume user more likely */
diff --git a/arch/powerpc/mm/init_32.c b/arch/powerpc/mm/init_32.c
index 4ac0e4e..68047ea 100644
--- a/arch/powerpc/mm/init_32.c
+++ b/arch/powerpc/mm/init_32.c
@@ -97,7 +97,9 @@ phys_addr_t __initial_memory_limit_addr = (phys_addr_t)0x10000000;
 /*
  * Check for command-line options that affect what MMU_init will do.
  */
-void MMU_setup(void)
+void paravirt_MMU_setup(void) 
+	__attribute__((weak, alias("native_MMU_setup")));
+void native_MMU_setup(void)
 {
 	/* Check for nobats option (used in mapin_ram). */
 	if (strstr(cmd_line, "nobats")) {
@@ -113,12 +115,19 @@ void MMU_setup(void)
 #endif
 }
 
+void __init MMU_setup(void)
+{
+	paravirt_MMU_setup();
+}
+
 /*
  * MMU_init sets up the basic memory mappings for the kernel,
  * including both RAM and possibly some I/O regions,
  * and sets up the page tables and the MMU hardware ready to go.
  */
-void __init MMU_init(void)
+void paravirt_MMU_init(void) 
+	__attribute__((weak, alias("native_MMU_init")));
+void __init native_MMU_init(void)
 {
 	if (ppc_md.progress)
 		ppc_md.progress("MMU:enter", 0x111);
@@ -142,12 +151,12 @@ void __init MMU_init(void)
 	total_lowmem = total_memory = lmb_end_of_DRAM() - memstart_addr;
 	lowmem_end_addr = memstart_addr + total_lowmem;
 
-#ifdef CONFIG_FSL_BOOKE
+#if defined(CONFIG_FSL_BOOKE) && ! defined(CONFIG_PARAVIRT)
 	/* Freescale Book-E parts expect lowmem to be mapped by fixed TLB
 	 * entries, so we need to adjust lowmem to match the amount we can map
 	 * in the fixed entries */
 	adjust_total_lowmem();
-#endif /* CONFIG_FSL_BOOKE */
+#endif /* CONFIG_FSL_BOOKE && ! defined(CONFIG_PARAVIRT) */
 
 	if (total_lowmem > __max_low_memory) {
 		total_lowmem = __max_low_memory;
@@ -190,6 +199,12 @@ void __init MMU_init(void)
 #ifdef CONFIG_BOOTX_TEXT
 	btext_unmap();
 #endif
+
+}
+
+void __init MMU_init(void)
+{
+	paravirt_MMU_init();
 }
 
 /* This is only called until mem_init is done. */
diff --git a/arch/powerpc/mm/mem.c b/arch/powerpc/mm/mem.c
index 1c93c25..477fe51 100644
--- a/arch/powerpc/mm/mem.c
+++ b/arch/powerpc/mm/mem.c
@@ -406,7 +406,10 @@ void __init mem_init(void)
  * It just marks the page as not i-cache clean.  We do the i-cache
  * flush later when the page is given to a user process, if necessary.
  */
-void flush_dcache_page(struct page *page)
+void paravirt_flush_dcache_page(struct page *page) 
+               __attribute__((weak, alias("native_flush_dcache_page")));
+
+void native_flush_dcache_page(struct page *page)
 {
 	if (cpu_has_feature(CPU_FTR_COHERENT_ICACHE))
 		return;
@@ -414,6 +417,12 @@ void flush_dcache_page(struct page *page)
 	if (test_bit(PG_arch_1, &page->flags))
 		clear_bit(PG_arch_1, &page->flags);
 }
+
+void flush_dcache_page(struct page *page)
+{
+	paravirt_flush_dcache_page(page);
+}
+
 EXPORT_SYMBOL(flush_dcache_page);
 
 void flush_dcache_icache_page(struct page *page)
@@ -485,8 +494,10 @@ EXPORT_SYMBOL(flush_icache_user_range);
  * 
  * This must always be called with the pte lock held.
  */
-void update_mmu_cache(struct vm_area_struct *vma, unsigned long address,
-		      pte_t pte)
+void paravirt_update_mmu_cache(struct vm_area_struct*, unsigned long, pte_t) 
+               __attribute__((weak, alias("native_update_mmu_cache")));
+void native_update_mmu_cache(struct vm_area_struct *vma, unsigned long address,
+                      pte_t pte)
 {
 #ifdef CONFIG_PPC_STD_MMU
 	unsigned long access = 0, trap;
@@ -545,3 +556,11 @@ void update_mmu_cache(struct vm_area_struct *vma, unsigned long address,
 	hash_preload(vma->vm_mm, address, access, trap);
 #endif /* CONFIG_PPC_STD_MMU */
 }
+
+void update_mmu_cache(struct vm_area_struct *vma, unsigned long address,
+                     pte_t pte)
+{
+       paravirt_update_mmu_cache(vma, address, pte);
+}
+
+
diff --git a/arch/powerpc/mm/mmu_context_32.c b/arch/powerpc/mm/mmu_context_32.c
index 349cecf..44f80db 100644
--- a/arch/powerpc/mm/mmu_context_32.c
+++ b/arch/powerpc/mm/mmu_context_32.c
@@ -247,3 +247,4 @@ steal_context(void)
 }
 #endif  /* CONFIG_MPC85xx_DS */
 #endif /* FEW_CONTEXTS */
+
diff --git a/arch/powerpc/mm/mmu_decl.h b/arch/powerpc/mm/mmu_decl.h
index fab3cfa..4d5471b 100644
--- a/arch/powerpc/mm/mmu_decl.h
+++ b/arch/powerpc/mm/mmu_decl.h
@@ -57,7 +57,13 @@ extern phys_addr_t lowmem_end_addr;
 /* ...and now those things that may be slightly different between processor
  * architectures.  -- Dan
  */
-#if defined(CONFIG_8xx)
+#if defined(CONFIG_PARAVIRT)
+
+#define flush_HPTE(pid, va, pg)	_tlbie(va, pid)
+extern void MMU_init_hw(void);
+extern unsigned long mmu_mapin_ram(void);
+
+#elif defined(CONFIG_8xx)
 #define flush_HPTE(X, va, pg)	_tlbie(va, 0 /* 8xx doesn't care about PID */)
 #define MMU_init_hw()		do { } while(0)
 #define mmu_mapin_ram()		(0UL)
@@ -67,7 +73,7 @@ extern phys_addr_t lowmem_end_addr;
 extern void MMU_init_hw(void);
 extern unsigned long mmu_mapin_ram(void);
 
-#elif defined(CONFIG_FSL_BOOKE)
+#elif defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT)
 #define flush_HPTE(pid, va, pg)	_tlbie(va, pid)
 extern void MMU_init_hw(void);
 extern unsigned long mmu_mapin_ram(void);
diff --git a/arch/powerpc/mm/pgtable_32.c b/arch/powerpc/mm/pgtable_32.c
index 2fee1a1..4fd6753 100644
--- a/arch/powerpc/mm/pgtable_32.c
+++ b/arch/powerpc/mm/pgtable_32.c
@@ -48,7 +48,7 @@ EXPORT_SYMBOL(ioremap_bot);	/* aka VMALLOC_END */
 #define HAVE_BATS	1
 #endif
 
-#if defined(CONFIG_FSL_BOOKE)
+#if defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT)
 #define HAVE_TLBCAM	1
 #endif
 
@@ -78,7 +78,7 @@ extern unsigned long p_mapped_by_tlbcam(phys_addr_t pa);
 #define p_mapped_by_tlbcam(x)	(0UL)
 #endif /* HAVE_TLBCAM */
 
-#ifdef CONFIG_PTE_64BIT
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_PARAVIRT)
 /* 44x uses an 8kB pgdir because it has 8-byte Linux PTEs. */
 #define PGDIR_ORDER	1
 #else
@@ -359,7 +359,10 @@ void iounmap(volatile void __iomem *addr)
 }
 EXPORT_SYMBOL(iounmap);
 
-int map_page(unsigned long va, phys_addr_t pa, int flags)
+
+int paravirt_map_page(unsigned long, phys_addr_t, int) 
+	__attribute__((weak, alias("native_map_page")));
+int native_map_page(unsigned long va, phys_addr_t pa, int flags)
 {
 	pmd_t *pd;
 	pte_t *pg;
@@ -381,6 +384,15 @@ int map_page(unsigned long va, phys_addr_t pa, int flags)
 	return err;
 }
 
+int map_page(unsigned long va, phys_addr_t pa, int flags)
+{
+       return paravirt_map_page(va, pa, flags);
+}
+
+#ifdef CONFIG_PARAVIRT
+EXPORT_SYMBOL(map_page);
+#endif
+
 /*
  * Map in all of physical memory starting at PAGE_OFFSET.
  */
diff --git a/arch/powerpc/sysdev/fsl_soc.c b/arch/powerpc/sysdev/fsl_soc.c
index dd1d7ed..a15e9fb 100644
--- a/arch/powerpc/sysdev/fsl_soc.c
+++ b/arch/powerpc/sysdev/fsl_soc.c
@@ -267,7 +267,25 @@ static const char *gfar_tx_intr = "tx";
 static const char *gfar_rx_intr = "rx";
 static const char *gfar_err_intr = "error";
 
-static int __init gfar_of_init(void)
+const char * get_gfar_tx_intr(void)
+{
+	return gfar_tx_intr;
+}
+
+const char * get_gfar_rx_intr(void)
+{
+	return gfar_rx_intr;
+}
+
+const char * get_gfar_err_intr(void)
+{
+	return gfar_err_intr;
+}
+
+int paravirt_gfar_of_init(void) 
+	__attribute__((weak, alias("native_gfar_of_init")));
+
+int __init native_gfar_of_init(void)
 {
 	struct device_node *np;
 	unsigned int i;
@@ -311,7 +329,6 @@ static int __init gfar_of_init(void)
 
 			r[3].name = gfar_err_intr;
 			of_irq_to_resource(np, 2, &r[3]);
-
 			n_res += 2;
 		}
 
@@ -410,6 +427,11 @@ err:
 	return ret;
 }
 
+static int __init gfar_of_init(void)
+{
+	return paravirt_gfar_of_init();
+}
+
 arch_initcall(gfar_of_init);
 
 
-- 
1.6.5.2

