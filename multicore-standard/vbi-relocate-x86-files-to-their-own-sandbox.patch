From cfcde6457cefa7b143a5242ad1bb9f6b6aad5790 Mon Sep 17 00:00:00 2001
From: Paul Gortmaker <paul.gortmaker@windriver.com>
Date: Thu, 15 Oct 2009 16:01:56 -0400
Subject: [PATCH 15/27] vbi: relocate x86 files to their own sandbox.

Also, the vbiIntController.c was just unused cruft, so
delete it rather than relocate it.

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
---
 arch/x86/kernel/Makefile           |   10 +-
 arch/x86/kernel/vbi/Makefile       |   13 +
 arch/x86/kernel/vbi/syscalls.S     | 1201 ++++++++++++++++++++++++++++++++
 arch/x86/kernel/vbi/wrhv.c         | 1335 ++++++++++++++++++++++++++++++++++++
 arch/x86/kernel/vbi/wrhv_initrd.S  |    3 +
 arch/x86/kernel/vbiIntController.c |  116 ----
 arch/x86/kernel/vbiSyscalls.S      | 1201 --------------------------------
 arch/x86/kernel/wrhv.c             | 1335 ------------------------------------
 arch/x86/kernel/wrhv_initrd.S      |    3 -
 9 files changed, 2553 insertions(+), 2664 deletions(-)
 create mode 100644 arch/x86/kernel/vbi/Makefile
 create mode 100644 arch/x86/kernel/vbi/syscalls.S
 create mode 100644 arch/x86/kernel/vbi/wrhv.c
 create mode 100644 arch/x86/kernel/vbi/wrhv_initrd.S
 delete mode 100644 arch/x86/kernel/vbiIntController.c
 delete mode 100644 arch/x86/kernel/vbiSyscalls.S
 delete mode 100644 arch/x86/kernel/wrhv.c
 delete mode 100644 arch/x86/kernel/wrhv_initrd.S

diff --git a/arch/x86/kernel/Makefile b/arch/x86/kernel/Makefile
index a06e1b7..680886a 100644
--- a/arch/x86/kernel/Makefile
+++ b/arch/x86/kernel/Makefile
@@ -92,7 +92,7 @@ obj-$(CONFIG_DEBUG_NX_TEST)	+= test_nx.o
 obj-$(CONFIG_VMI)		+= vmi_32.o vmiclock_32.o
 obj-$(CONFIG_KVM_GUEST)		+= kvm.o
 obj-$(CONFIG_KVM_CLOCK)		+= kvmclock.o
-obj-$(CONFIG_WRHV)		+= wrhv.o wrhv_initrd.o vbiSyscalls.o
+obj-$(CONFIG_WRHV)		+= vbi/
 obj-$(CONFIG_PARAVIRT)		+= paravirt.o paravirt_patch_$(BITS).o
 obj-$(CONFIG_PARAVIRT_CLOCK)	+= pvclock.o
 
@@ -125,11 +125,3 @@ ifeq ($(CONFIG_X86_64),y)
 
         obj-$(CONFIG_PCI_MMCONFIG)	+= mmconf-fam10h_64.o
 endif
-
-# wrhv embeds an initrd in the vmlinux
-$(obj)/wrhv_initrd.o: FORCE
-	@ $(AS) $(srctree)/$(src)/wrhv_initrd.S -o $@
-ifneq (X$(INITRD), X)
-	@ $(OBJCOPY) --add-section .initrd=$(INITRD) $@
-	@ $(OBJCOPY) --set-section-flags .initrd=alloc,load $@
-endif
diff --git a/arch/x86/kernel/vbi/Makefile b/arch/x86/kernel/vbi/Makefile
new file mode 100644
index 0000000..833b770
--- /dev/null
+++ b/arch/x86/kernel/vbi/Makefile
@@ -0,0 +1,13 @@
+#
+# Makefile for the x86 vbi.
+#
+
+obj-y 		= wrhv.o wrhv_initrd.o syscalls.o
+
+# wrhv embeds an initrd in the vmlinux
+$(obj)/wrhv_initrd.o: FORCE
+	@ $(AS) $(srctree)/$(src)/wrhv_initrd.S -o $@
+ifneq (X$(INITRD), X)
+	@ $(OBJCOPY) --add-section .initrd=$(INITRD) $@
+	@ $(OBJCOPY) --set-section-flags .initrd=alloc,load $@
+endif
diff --git a/arch/x86/kernel/vbi/syscalls.S b/arch/x86/kernel/vbi/syscalls.S
new file mode 100644
index 0000000..eb1f8ef
--- /dev/null
+++ b/arch/x86/kernel/vbi/syscalls.S
@@ -0,0 +1,1201 @@
+/* syscalls.S - hypervisor system calls */
+
+/*
+ * Copyright (c) 2009 Wind River Systems, Inc.
+ *
+ * The right to copy, distribute, modify or otherwise make use
+ * of this software may be licensed only pursuant to the terms
+ * of an applicable Wind River license agreement.
+ */
+
+/*
+modification history
+--------------------
+01v,09sep09,mmi  add vbiVtlb stub
+01u,02sep09,mmi  rename vbiReceive to vbiReceiveOp
+01t,01sep09,mmi  update asm.h path
+01s,25aug09,mmi  remove bspIoctl
+01r,13aug09,dtr  Update to vbiHyIoctl.
+01q,06jul09,mmi  added vbi 2.0 vbMgmt api, interrupt redirect op,
+		 registers read/write, memory read/write, 
+01p,02jul09,mmi  add interrupt send syscall stub
+01o,27jun09,mmi  fix stack adjustment for vbiReply
+01n,23jun09,mmi  add vbi 2.0 API's
+01m,18jun09,mmi  changed vbiIntVCoreUnlock not expect a flag
+01l,12jun09,mmi  introduce vbiIntVCoreLock/Unlock APIs
+01k,26feb09,mmi  add name service hypercall
+01j,12feb09,mmi  update API descriptions, descriptions, fix vbiReply #arg pushed
+		 to the stack 
+01i,08feb09,mmi  fix vbiIntEnable/vbiIntDisable routines, remove vbiInt
+01h,23jan09,mmi  update vbiSend/vbiReceive and vbiReply comments
+01g,05dec08,mes  Replaced vbiShelf with vbiVbMgmt
+01f,02dec08,mmi  remove obsolete API's
+01e,20nov08,mmi  adopt vbi naming
+01d,04sep08,dcc  modified vdkInt() to call vdkIoapicIoctl()
+01c,19may08,gws  add vdkIoapicIoctl
+01b,18apr08,md   add extra arg to vdkHyIoctl
+01a,03mar08,md   written
+*/
+
+/*
+DESCRIPTION
+
+This file implements the hypervisor system call stubs for the Razor hypervisor.
+
+*/
+
+#define _ASMLANGUAGE
+
+#ifdef CONFIG_WRHV
+#include <vbi/support/sys/x86/regs.h>
+#include <vbi/support/sys/x86/asm.h>
+#include <vbi/syscall.h>
+#else
+#include <x86/regs.h>
+#include <asm.h>
+#include <vbi/syscall.h>
+#endif /* CONFIG_WRHV */
+
+	/* globals */
+	.globl vbiDebugShellStart
+	.globl vbiVbMemoryWrite
+	.globl vbiVbMemoryRead
+	.globl vbiIoapicOp
+	.globl vbiIoapicIoctl
+	.globl vbiHyIoctl
+	.globl vbiCtxctl
+	.globl vbiSend
+	.globl vbiReceiveOp
+	.globl vbiReply
+	.globl vbiTlbFlush
+	.globl vbiPanic
+	.globl vbiPs
+	.globl vbiKputs
+	.globl vbiKputc
+	.globl vbiIntVCoreUnlock
+	.globl vbiIntVCoreLock
+	.globl vbiVbMgmt
+	.globl vbiMemAttrSet
+	.globl vbiMemAttrGet
+	.globl vbiNsOp
+	.globl vbiVbReset
+	.globl vbiVbRestart
+	.globl vbiVbResume
+	.globl vbiVbSuspend
+	.globl vbiVcoreIntRed_op 
+	.globl vbiVbRegisterRead 
+	.globl vbiVbRegisterWrite 
+	.globl vbiVtlbOp 
+	.text
+	.balign 16
+
+#define VBI_STACK_FRAME_SIZE	4
+
+/*******************************************************************************
+*
+* vbiSend - Send a message to another context
+*
+* This routine makes a hypercall to send a message to the specified context and
+* waits for a reply.  The caller will block until the sender replies to the sent
+* message.
+*
+* SYNOPSIS
+*\cs
+*
+* vbiStatus_t vbiSend
+*    (
+*    vbiCtx_t     id,    /@ context id to send the message to @/
+*    void *       smsg,  /@ pointer to message to send        @/
+*    size_t       slen,  /@ length of message to send         @/
+*    void *       rmsg,  /@ pointer to receive message buffer @/
+*    size_t       rlen,  /@ length of receive message         @/
+*    VBI_MSG_INFO *info  /@ status info structure pointer     @/
+*    VBI_MSG_CTL  *ctl   /@ control data structure pointer    @/
+*    )
+*\ce
+*
+* RETURNS: OK or an error number in case of failure
+*
+* ERRNO: N/A
+*
+* SEE ALSO: vbiReceive(), vbiReply(), WRHV  messaging user's guide
+*/
+
+vbiSend:
+	movl    $VBI_SYS_send,%eax		/* system call number */
+	push	$7				/* number of arguments */
+	vmcall
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+	ret
+
+/*******************************************************************************
+*
+* vbiReceiveOp - Receive a message from another context
+*
+* This routine makes a hypercall and waits for a message to be received from
+* another context. It blocks until a message is received.
+*
+* SYNOPSIS
+*\cs
+*
+* vbiCtx_t vbiReceiveOp
+*    (
+*    void *       smsg,  /@ pointer to message to receive  @/
+*    size_t       len,   /@ length of message to receive   @/
+*    VBI_MSG_INFO *info  /@ status info structure pointer  @/
+*    VBI_MSG_CTL  *ctl   /@ control data structure pointer @/
+*    )
+*\ce
+*
+* RETURNS: sender context Id or an error number in case of failure
+*
+* ERRNO: N/A
+*
+* SEE ALSO: vbiSend(), vbiReply(), WRHV  messaging user's guide
+*/
+
+vbiReceiveOp:
+	movl    $VBI_SYS_receive,%eax		/* system call number */
+	push	$4				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+/*******************************************************************************
+*
+* vbiReply - Reply to message received from another context
+*
+* This routine makes a hypercall in order to reply to a message received from
+* another context. A message is received from remote context by calling
+* vbiReceive(). The reply will unblock the recipient which may preempt
+* the caller.
+*
+* SYNOPSIS
+*\cs
+*
+* vbiStatus_t vbiReply
+*    (
+*    vbiCtx_t   id,    /@ context id to reply the message to @/
+*    void *       buff,  /@ pointer to reply message  @/
+*    size_t       len,   /@ length of message to reply   @/
+*    VBI_MSG_CTL  *ctl   /@ control data structure pointer @/
+*    )
+*\ce
+*
+* RETURNS: OK or an error number in case of failure
+*
+* ERRNO: N/A
+*
+* SEE ALSO: vbiSend(), vbiReceive(), WRHV  messaging user's guide
+*/
+
+vbiReply:
+	movl    $VBI_SYS_reply,%eax		/* system call number */
+	push	$4				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+
+/******************************************************************************
+*
+* vbiKputs - print a string on the kernel console
+*
+* This system call sends the specified string to the system console.
+*
+* C interface:
+*
+*   vbiKputs (char *s)		/@ pointer to string			@/
+*
+* Returns: OK or ERROR
+*
+*/
+
+vbiKputs:
+	movl    $VBI_SYS_kputs,%eax		/* system call number */
+	push	$1				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+
+/******************************************************************************
+*
+* vbiKputc - print a character on the kernel console
+*
+* This system call sends the specified character to the system console.
+*
+* C interface:
+*
+*   vbiKputc (char c)		/@ character to print			@/
+*
+* Returns: OK or ERROR
+*
+*/
+
+vbiKputc:
+	movl    $VBI_SYS_kputc,%eax		/* system call number */
+	push	$1				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+
+/******************************************************************************
+*
+* vbiPanic - panic the system and halt all activity
+*
+* This system call causes the hypervisor to enter a panic state and display
+* various pieces of information on the system console.  The hypervisor
+* then enters an idle state and stops all CPU processing.
+*
+* C interface:
+*
+*   vbiPanic (char *msg)	/@ message string to print on console	@/
+*
+* Returns: does not return
+*
+*/
+
+vbiPanic:
+	movl    $VBI_SYS_panic,%eax		/* system call number */
+	push	$1				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+
+/******************************************************************************
+*
+* vbiPs - display the list of contexts on the console
+*
+* This system call sends a "ps" like output of the hypervisor contexts to
+* the system console.
+*
+* C interface:
+*
+*   vbiPs (void)
+*
+* Returns: OK or ERROR
+*
+*/
+
+vbiPs:
+	movl    $VBI_SYS_ps,%eax		/* system call number */
+	push	$0				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+
+/******************************************************************************
+*
+* vbiIntVCoreUnlock - Re-enable interrupts in the virtual board
+*
+* This call re-enables interrupts in the virtual board, and calls
+* Razor if interrupts are pending.  The value level is the value returned
+* by the corresponding 	
+*
+* C interface:
+*
+*   vbiIntVCoreUnlock (void)
+*
+* Returns: does not return
+*
+*/
+
+vbiIntVCoreUnlock:
+	sti				/* UNLOCK INTERRUPTS */
+	ret
+
+/******************************************************************************
+*
+* vbiIntVCoreLock - Disable interrupts in the virtual core
+*
+* This call disables interrupts in the virtual board.
+*
+* C interface:
+*
+*   int vbiIntVCoreLock (void)
+*
+* Returns: the old value of the interrupt disable 
+*
+*/
+
+vbiIntVCoreLock:
+    pushf				/* push EFLAGS on stack */
+    popl	%eax			/* get EFLAGS in EAX */
+    andl	$EFLAGS_IF,%eax		/* mask it with IF bit */
+    cli				/* LOCK INTERRUPTS */
+    ret
+
+/******************************************************************************
+*
+* vbiVbMgmt - virtual board management
+* 
+* This routine executes the specified command on a given virtual board. The
+* possible commands are:
+* 
+* VBI_VBMGMT_ATTACH 
+* Attach the requesting Virtual Board to the VB management agent for
+* operations on the specified VB.
+*
+* VBI_VBMGMT_DETACH
+* Detatch the requesting Virtual Board from the VB management agent for
+* operations on the specified VB.
+*
+* VBI_VBMGMT_SUSPEND
+* Suspends target Virtual Board from operation.  Fails if Virtual Board
+* has already been suspended
+*
+* VBI_VBMGMT_RESET
+* Resume a target virtual board.  Fails if a Virtual Board has not been
+* suspended. Currently no options are supported
+*
+* VBI_VBMGMT_RESUME
+* Restarts a target Virtual Board which has Preload=0 set in the xml file.
+* Fails if Virtual Board is preloaded (Preload=1)
+*
+*
+* The fourth argument to this routine specifies an flag that must be defined
+* when executing VBI_VBMGMT_RESUME operation. Otherwise the command fails.
+* The possible flgas are:
+*   VBI_VTLB_OP_UPDATE_PMD	
+*   VBI_VTLB_OP_UPDATE_PTE	
+*   VBI_VTLB_OP_DELETE_PMD	
+*   VBI_VTLB_OP_SET_PTE_AT	
+*   VBI_VTLB_OP_SET_PTE	
+*   VBI_VTLB_OP_FLUSH_OPS	
+*   VBI_VTLB_OP_INIT	
+*
+* int32_t vbiVbMgmt 
+*    (
+*    uint32_t	cmd,	    /@ attach, detach, suspend, reset or resume @/
+*    uint32_t	handle,    /@ the operation target board handle @/
+*    int32_t	*outError,  /@ where to set error : OK or error flag @/ 
+*    uint32_t	flags,	    /@ options required by the cmd executed @/
+*    void *ctl		    /@ memory / registers data		    @/ 
+*    )
+*
+* RETURNS: OK or error in case of failure
+*/
+
+vbiVbMgmt:
+	movl    $VBI_SYS_vbMgmt,%eax		/* system call number */
+	push	$5				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+/*******************************************************************************
+*
+* vbiVbSuspend - Suspend a virtual board's core
+*
+* This routine makes a hypercall in order to suspend one or more cores that
+* exist within the specified virtual board. The target core(s) enter HALT state
+* until vbiVbResume() is called change the state of the core(s). This function
+* will return only after all victim cores are suspended unless the opration
+* fails to complete. The second argument passed to this function specifies one
+* or more target cores. For suspending every core within the specified VB the
+* second argument must be set to VBI_VB_CORES_ALL. This implies that the core
+* requesting the suspension may also be included in the list to be suspended.
+* To suspend everyone but the recipient then the second argument passed to this
+* function should be set to VBI_VB_CORES_OTHERS. Otherwise the second argument
+* should be a valid core number within the VB. This hypercall sends a message
+* to a given hypervisor manager that provides virtual board managment service.
+*
+* SYNOPSIS
+*\cs
+*
+*
+* vbiStatus_t vbiVbSuspend
+*    (
+*    vbiVb_t      id,    /@ Id of the VB to suspend     @/
+*    vbiCore_t     core   /@ Core within the VB         @/
+*    )
+*\ce
+*
+* RETURNS: OK or an error number in case of failure
+*
+* ERRNO:
+*
+* SEE ALSO: vbiVbResume(), vbiVbReset(), vbiVbRestart()
+*/
+
+vbiVbSuspend:
+	movl    $VBI_SYS_vbSuspend,%eax		/* system call number */
+	push	$2				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+/*******************************************************************************
+*
+* vbiVbReset - Reset a virtual board's core
+*
+* This routine makes a hypercall in order to reset one or more cores that exist
+* within the specified virtual board. Calling this function puts the target core(s)
+* program counter to it's ENTRY function. The ENTRY function is determined based on
+* the loaded binary image. A core does not execute beyond it's ENTRY function
+* unless vbiVbRestart() is explitly called. Except for core0 within the target VB
+* where VBI_VBMGMT_RESET_AND_START_CORE0 option is set in the flag passed as
+* the third argument to this routine.
+* The hypercall sends a message to a manager that provides VB managment services.
+* This function will return only after all victim cores are reset unless the
+* operation fails to complete. The order of which the victim cores are reset is not
+* determined. The second argument identifies the cores to perform the operation on.
+* The value of the second argument should be set to one of the following:
+*
+*\ms
+*\m -
+* VBI_VB_CORES_ALL: Reset all cores in the specified virtual board
+*\m -
+* VBI_VB_CORES_OTHERS: Exclude the recipient if it belongs to the victim VB
+*\m -
+* A valid core number: Reset the specified core that exist within the Virtual Board.
+*\me
+*
+* The third argument argument passed to this function specifies options that are
+* applicable only when the second argument is VBI_VB_CORES_ALL. The options may be
+* one of the following or a combination:
+*
+*\ms
+*\m -
+* VBI_VBMGMT_RESET_DOWNLOAD: Reset the cores and reload the executable images
+*\m -
+* VBI_VBMGMT_RESET_AND_START_CORE0: Reset and start core0 within the VB
+*\me
+*
+*
+* IMPORTANT:
+* If a user chooses to restart core without reloading the executable image then
+* the data section must be restored to prevent critical errors. It is the guest OS's
+* responsibility to clear the bss data sections in such scenario.
+*
+* SYNOPSIS
+*\cs
+*
+* vbiStatus_t vbiVbReset
+*    (
+*    vbiVb_t      id,       /@ Id of the VB to suspend      @/
+*    vbiCore_t     core,            /@ Core within the VB           @/
+*    uint32_t     options   /@ reload , start options       @/
+*    )
+*\ce
+*
+* RETURNS: OK or an error number in case of failure
+*
+* ERRNO:
+*
+* SEE ALSO: vbiVbResume(), vbiVbSuspend(), vbiVbRestart()
+*/
+
+vbiVbReset:
+        movl    $VBI_SYS_vbReset,%eax            /* system call number */
+        push    $3                              /* number of arguments */
+
+        vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+        ret
+
+/*******************************************************************************
+*
+* vbiVbRestart - Restart a virtual board's core
+*
+* This routine makes a hypercall in order to restart a virtual cores from reset.
+* It's called to start running a core or cores that were previously reset by
+* calling vbiVbReset(). The target core(s) start(s) executing from the ENTRY
+* function retrieved from the corresponding binary image.
+* This function will return only after  all cores are out of reset unless the
+* operation fails to complete.  The second argument represents the cores to restart.
+* For restarting every core in reset mode within the specified VB the second
+* argument is set to VBI_VB_CORES_ALL. To restart a specific core within the
+* VB then the core number must be passed in the second argument.
+*
+* This hypercall sends a message to a manager that provides VB managment
+* services.
+*
+* SYNOPSIS
+*\cs
+*
+* vbiStatus_t vbiVbRestart
+*    (
+*    vbiVb_t      id,    /@ Id of the VB to suspend     @/
+*    vbiCore_t     core   /@ Core within the VB         @/
+*    )
+*\ce
+*
+* RETURNS: OK or an error number in case of failure
+*
+* ERRNO:
+*
+* SEE ALSO: vbiVbResume(), vbiVbSuspend(), vbiVbReset()
+*/
+
+vbiVbRestart:
+        movl    $VBI_SYS_vbRestart,%eax            /* system call number */
+        push    $3                              /* number of arguments */
+
+        vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+        ret
+
+/*******************************************************************************
+*
+* vbiVbResume - Resume a virtual board's core
+*
+* This routine makes a hypercall in order to resume one or cores within
+* the specified virtual board. It reactivates a cores or cores that were
+* previously suspended by calling vbiVbResume(). This function will return only
+* after all victim cores are resumed unless the operation fails. The order of
+* which the cores are resumed is not determined. The second argument may a
+* magic number instead of a valid core number to indicate that the operation
+* is intended for more than one core. For resuming every core within the
+* specified VB then the second argument is set to be equal to VBI_VB_RESUME_ALL.
+* This implies to resume every core within the specified VB. Using this option
+* when some of the cores within the VB are already running is not considered
+* as programming error.
+*
+* SYNOPSIS
+*\cs
+*
+* vbiStatus_t vbiVbResume
+*    (
+*    vbiVb_t      id,    /@ Id of the VB to suspend     @/
+*    vbiCore_t     core   /@ Core within the VB         @/
+*    )
+*\ce
+*
+* RETURNS: OK or an error number in case of failure
+*
+* ERRNO:
+*
+* SEE ALSO: vbiVbResume(), vbiVbSuspend()
+*/
+
+vbiVbResume:
+        movl    $VBI_SYS_vbResume,%eax            /* system call number	*/
+        push    $2                              /* number of arguments	*/
+
+        vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+        ret
+
+/******************************************************************************
+*
+* vbiHyIoctl - hypervisor ioctl call
+*
+* This system call interfaces to the general purpose hypervisor ioctl
+* function.
+*
+* Possible ioctl commands:
+*     VBI_HYIOCTL_GETPID
+*     VBI_HYIOCTL_GETPRIORITY
+*     VBI_HYIOCTL_GETSTATS
+*     VBI_HYIOCTL_PADDR
+*		
+* C interface:
+*
+*   vbiHyIoctl (unsigned int ioctl, /@ the ioctl command      @/
+*               void *arg1,         /@ address of information @/
+*               void *arg2,         /@ address of information @/
+*               void *arg3,         /@ address of information @/
+*               void *arg4)         /@ address of information @/
+*
+* Returns: ioctl specific value
+*
+*/
+
+vbiHyIoctl:
+	movl    $VBI_SYS_hyIoctl,%eax		/* system call number */
+	push	$5				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+/******************************************************************************
+*
+* vbiIoapicIoctl - virtual IO APIC ioctl call
+*
+* This system call interfaces to the virtual IO APIC ioctl
+* function.
+*
+* Possible ioctl commands:
+*     VBI_IOAPICIOCTL_UNMASK
+*     VBI_IOAPICIOCTL_SEND
+*     VBI_IOAPICIOCTL_MASK
+*		
+* C interface:
+*
+*   vbiIoapicIoctl (unsigned int ioctl, /@ the ioctl command      @/
+*                   unsigned arg1,      /@ address of information @/
+*                   unsigned arg2)      /@ address of information @/
+*
+* Returns: ioctl specific value
+*
+*/
+
+vbiIoapicIoctl:
+	movl    $VBI_SYS_vIoapicIoctl,%eax	/* system call number */
+	push	$3				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+/******************************************************************************
+*
+* vbiIoapicOp - virtual IO APIC ioctl call
+*
+* This system call interfaces to the virtual IO APIC.
+*
+* function.
+*
+* Possible commands:
+*     VBI_IOAPICIOCTL_UNMASK
+*     VBI_IOAPICIOCTL_SEND
+*     VBI_IOAPICIOCTL_MASK
+*
+* C interface:
+*
+*   vbiIoapicOp	    (uint32_t cmd,      /@ the operation command     @/
+*                   vbiIrq_t irq,       /@ irq number                @/
+*                   uint32_t filter,    /@ filter                    @/
+*                   vbiVb_t  vbId,      /@ target vb id              @/
+*
+* Returns: ioctl specific value
+*
+*/
+
+vbiIoapicOp:
+	movl    $VBI_SYS_vIoapicIoctl,%eax	/* system call number */
+	push	$4				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+
+/******************************************************************************
+*
+* vbiCtxctl - hypervisor context control call
+*
+* This system call interfaces to the general purpose hypervisor context
+* control function.
+*
+* Possbile operations:
+*	VBI_CTXCTL_IDLE /@ Make this virtual board go idle @/
+*
+* C interface:
+*
+*   vbiHyCtxctl (unsigned int operation, /@ context operation   @/
+*		 void *arg)		 /@ address of argument @/
+*
+* Returns: ioctl specific value
+*
+*/
+
+vbiCtxctl:
+	movl    $VBI_SYS_ctxctl,%eax		/* system call number */
+	push	$2				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+/*******************************************************************************
+*
+* vbiMemAttrSet - Set protection for a page of memory
+*
+* This routine makes a hypercall to set the MMU attribures for the specified
+* memory range. The possible attributes one or a combinarion of the following:
+* 
+* VBI_MMU_PROT_READ -  allow supervisor and user read
+* VBI_MMU_PROT_WRITE -  Allow supervisor and user write
+* VBI_MMU_PROT_EXECUTE - allow supervisor and user execute
+*
+* SYNOPSIS
+*\cs
+* 
+* vbiStatus_t vbiMemAttrSet 
+*		(
+*		void	 *gaddr,	/@ Address of page to change attr   @/
+*		size_t   length,	/@ length of address		    @/
+*		uint32_t attr		/@ mmu attributes to set	    @/
+*		)
+*\ce
+*
+* RETURNS: OK or error number in case of failure
+*
+* ERROR CODES: N/A
+*
+*/
+
+vbiMmuAttrSet:
+	movl    $VBI_SYS_mmu_attr_set,%eax	/* system call number */
+	push	$3				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+/******************************************************************************
+*
+* vbiMemAttrGet - Get MMU page protections
+*
+* This routine makes a hypercall to retrieve the MMU attributes associated for
+* the page where the specified address is mapped. This is not the VMMU
+* attributes. A guest OS has direct access to the mapping table of its VMMU
+* therefore a hypercall is not necessary.
+*
+* SYNOPSIS
+*\cs
+* 
+* vbiStatus_t vbiMemAttrGet 
+*		(
+*		void	 *gaddr		/@ Address of page to change attr   @/
+*		uint32_t *attr		/@ OUT - returned mmu attributes    @/
+*		)
+*\ce
+*
+* RETURNS: OK or error number in case of failure
+*
+* ERROR CODES: N/A
+*
+*/
+
+vbiMmuAttrGet:
+	movl    $VBI_SYS_mmu_attr_get,%eax	/* system call number */
+	push	$1				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+
+/******************************************************************************
+*
+* vbiNsOp - virtua board name service call
+*
+* This system call interfaces to the virtual board
+*
+* commands:
+*	VBI_VBI_NS_REGISTER	   /@ register service	 @/
+*	VBI_VBI_NS_UNREGISTER	   /@ unregister service @/
+*	VBI_VBI_NS_LOOKUP	   /@ lookup service	 @/
+*				
+* C interface:
+*
+*   vbiNsOp ( uint32_t cmd,	    /@ the BSP ioctl command	@/
+*	    char * name,		    /@ the service name		@/
+*	    uint32_t revision,	    /@ service revision		@/
+*	    VBI_HANDLE *handle,	    /@ service handle pointer	@/
+*	  )
+*
+* Returns: OK or ERROR in case of failure
+*
+*/
+
+vbiNsOp:
+	movl    $VBI_SYS_ns_op, %eax		/* system call number */
+	push	$4				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+/*******************************************************************************
+*
+* vbiVbMemoryWrite - copy data to a remote board's memory
+*
+* This routine makes a hypercall to copy to a remote board memory. If the
+* VBI_DCACHE_FLUSH is set in the control memory control structure then this
+* routine flushes the data caches lines corresponding to the range of memory
+* specified. If VBI_ICACHE_INV then this routine ensure that the instruction
+* cache lines corresponding to the range of address is invalidated after the
+* memory is copied. Invalidating the instruction is required if data containing
+* is updated since the instruction cache is not aware of the content in data
+* cache. Therefore flushing the data cache ensures that memory contains the
+* updated data and invalidating the instruction cache ensures that the stale
+* values in the instruction cache is thrown away. 
+* The sizeIn parameter specifies the number of bytes desired to be copied. 
+* The sizeOut parameter indicates the number of bytes successfully copied.
+* A user may set the sizeOut parameter to zero if the output size is not of
+* interest otherwise to a value different than zero.
+* 
+* 
+* struct vbiMemCtl
+*   {
+*   void	*pBuffer;	    /@ address of target context	@/
+*   void	*pAddress;	    /@ address of calling context	@/
+*   size_t	sizeIn;		    /@ IN: number bytes requested	@/
+*   size_t	sizeOut;	    /@ OUT: number of total bytes read	@/
+*   uint32_t	flags;		    /@ data/instruction flush option	@/
+*    } VBI_MEM_CTL;
+*
+* SYNOPSIS
+*\cs
+* 
+* vbiStatus_t vbiVbMemoryWrite 
+*	(
+*	VBI_MEM_CTL	*memCtl, 
+*	vbiVb_t		targetBoard 
+*	)
+*
+*\ce
+*
+* RETURNS: returns OK or error number in case of failure
+*
+* ERROR CODES: N/A
+*
+* SEE ALSO: 
+*/
+
+vbiVbMemoryWrite:
+	movl    $VBI_SYS_memWrite_op, %eax	/* system call number */
+	push	$2				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+/*******************************************************************************
+*
+* vbiVbMemoryRead - Read a virtual board's memory
+*
+* This routine makes a hypercall to read a remote board's memory. The memory control
+* structure contains information about the target memory to read and the destination
+* buffer that hypervisor must populate with the data read. This routine is used
+* to copy data from a remote VB. It is the user's responsability to ensure that
+* the memory read is accessed orthogonally.
+* The sizeIn parameter specifies the number of bytes desired to be copied. 
+* The sizeOut parameter indicates the number of bytes successfully copied.
+* A user may set the sizeOut parameter to zero if the output size is not of
+* interest otherwise to a value different than zero.
+*
+* struct vbiMemCtl
+*   {
+*   void	*pBuffer;	    /@ address of target context	    @/
+*   void	*pAddress;	    /@ address of calling context	    @/
+*   size_t	sizeIn;		    /@ number of bytes to be read	    @/
+*   size_t	sizeOut;	    /@ number of bytes successfully read    @/
+*   uint32_t	reserved;	    /@ reserved for future use		    @/
+*    } VBI_MEM_CTL;
+*
+* SYNOPSIS
+*\cs
+* 
+* vbiStatus_t vbiVbMemoryRead 
+*	(
+*	VBI_MEM_CTL *memCtl,	    /@ control structure for INPUT and OUTPUT	@/
+*	vbiVb_t	    targetBoard	    /@ target board				@/
+*	)
+*
+*\ce
+*
+* RETURNS: returns OK or an error number in case of failure
+*
+* ERROR CODES: N/A
+*
+* SEE ALSO: 
+*/
+
+vbiVbMemoryRead:
+	movl    $VBI_SYS_memRead_op, %eax	/* system call number */
+	push	$2				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+/*******************************************************************************
+*
+* vbiDebugShellStart - start the hypervisor debug shell
+*
+* This routine sends a message to the hypervisor debug shell manager in order to
+* start the WRHV shell program. The shell program spins therefore does not share
+* the processor with any other WRHV context. By default a caller of this routine
+* is detached to allow the caling core to continue executing (as long as the are not
+* scheduled to run on the same processor). An optional flag VBI_SHELL_ATTACH can be
+* specified to force the caller virtual board core to block while the shell program
+* is running.
+*
+* SYNOPSIS
+*\cs
+*
+* void vbiDebugShellStart
+*          (
+*          uint32_t  flags /@ detach by default @/
+*          )
+*
+*\ce
+*
+* RETURNS: N/A
+*
+*
+* SEE ALSO: 
+*/
+
+vbiDebugShellStart:
+
+	movl    $VBI_SYS_dbgShStart, %eax	/* system call number */
+	push	$1				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+
+/*******************************************************************************
+*
+* vbiVbRegisterRead - Read a remote core's registers
+*
+* This routine makes a hypercall to read a remote core's registers. The register
+* control structure contains information about the registers to read and the
+* destination buffers to store them.
+* 
+* SYNOPSIS
+* VBI X86 Architecture Supplements
+*\cs
+* vbiStatus_t vbiVbRegisterRead 
+*	(
+*	VB_ARCH_CONTROL_REGS	*regCtl,    /@ Registers read - OUT	    @/
+*	vbiVb_t	    targetBoard,	    /@ target VB		    @/ 
+*	vbiCore_t   core		    /@ core within the target VB    @/
+*	)
+*\sh VB_ARCH_CONTROL_REGS definition
+*
+*The control registers type used for vbiVbRegister[Read:write] API's
+*
+*typedef struct vbArchControlRegs /@ REG_SET - x86 register set	@/
+*    {
+*    uint32_t  edi;		/@ 00: general register		@/
+*    uint32_t  esi;		/@ 04: general register		@/
+*    uint32_t  ebp;		/@ 08: frame pointer register	@/
+*    uint32_t  esp;		/@ 0C: stack pointer register	@/
+*    uint32_t  ebx;		/@ 10: general register		@/
+*    uint32_t  edx;		/@ 14: general register		@/
+*    uint32_t  ecx;		/@ 18: general register		@/
+*    uint32_t  eax;		/@ 1C: general register		@/
+*    uint32_t  eflags;		/@ 20: status register		@/
+*    INSTR *pc;			/@ 24: program counter		@/
+*    uint32_t  cr0;		/@ 28: control register 0	@/
+*    uint32_t  cr2;		/@ 2C: control register 2	@/
+*    uint32_t  cr3;		/@ 30: control register 3	@/
+*    uint32_t  cr4;		/@ 34: control register 4	@/
+*    uint32_t  cs;		/@ 28: code segment		@/
+*    uint32_t  ds;		/@ 3C: data segment		@/
+*    uint32_t  ss;		/@ 40: stack segment		@/
+*    uint32_t  es;		/@ 44: E segment		@/
+*    uint32_t  fs;		/@ 48: F segment		@/
+*    uint32_t  gs;		/@ 4C: G segment		@/
+*    uint32_t  tsp;		/@ 50: transition stack pointer	@/
+*    } VB_ARCH_CONTROL_REGS;
+*\ce
+*
+* RETURNS: returns OK or error number in case of failure
+*
+* ERROR CODES:
+*
+* SEE ALSO: 
+*/
+
+vbiVbRegisterRead:
+
+	movl    $VBI_SYS_RegsRead_op, %eax	/* system call number */
+	push	$3				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+/*******************************************************************************
+*
+* vbiVbRegisterWrite - write to a remote core's registers
+*
+* This routine makes a hypercall to write to a remote core's registers. The
+* register control structure contains the set of registers to write. 
+* The user must ensure to read first the destination core's registers using
+* vbiVbRegisterRead() then write back the modified set of registers in the 
+* registers control structure.
+* 
+* VBI X86 Architecture Supplements
+*
+* SYNOPSIS
+*\cs
+* vbiStatus_t vbiVbRegisterWrite
+*	(
+*	VB_ARCH_CONTROL_REGS	*regCtl,	/@ registers to write - IN	 @/
+*	vbiVb_t			targetBoard,	/@ The target board		 @/
+*	vbiCore_t		core		/@ The target core within the VB @/
+*	)
+*
+*\sh VB_ARCH_CONTROL_REGS definition
+*
+*The control registers type used for vbiVbRegister[Read:write] API's
+*
+*typedef struct vbArchControlRegs /@ REG_SET - x86 register set	@/
+*    {
+*    uint32_t  edi;		/@ 00: general register		@/
+*    uint32_t  esi;		/@ 04: general register		@/
+*    uint32_t  ebp;		/@ 08: frame pointer register	@/
+*    uint32_t  esp;		/@ 0C: stack pointer register	@/
+*    uint32_t  ebx;		/@ 10: general register		@/
+*    uint32_t  edx;		/@ 14: general register		@/
+*    uint32_t  ecx;		/@ 18: general register		@/
+*    uint32_t  eax;		/@ 1C: general register		@/
+*    uint32_t  eflags;		/@ 20: status register		@/
+*    INSTR *pc;			/@ 24: program counter		@/
+*    uint32_t  cr0;		/@ 28: control register 0	@/
+*    uint32_t  cr2;		/@ 2C: control register 2	@/
+*    uint32_t  cr3;		/@ 30: control register 3	@/
+*    uint32_t  cr4;		/@ 34: control register 4	@/
+*    uint32_t  cs;		/@ 28: code segment		@/
+*    uint32_t  ds;		/@ 3C: data segment		@/
+*    uint32_t  ss;		/@ 40: stack segment		@/
+*    uint32_t  es;		/@ 44: E segment		@/
+*    uint32_t  fs;		/@ 48: F segment		@/
+*    uint32_t  gs;		/@ 4C: G segment		@/
+*    uint32_t  tsp;		/@ 50: transition stack pointer	@/
+*    } VB_ARCH_CONTROL_REGS;
+*
+*\ce
+*
+* RETURNS: returns OK or error number in case of failure
+*
+* ERROR CODES: 
+*
+* SEE ALSO: 
+*/
+
+vbiVbRegisterWrite:
+	movl    $VBI_SYS_RegsWrite_op, %eax	/* system call number */
+	push	$3				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+/*******************************************************************************
+*
+* vbiVcoreIntRed_op - redirect an irq to another vcore
+*
+* SYNOPSIS
+*\cs
+* vbiStatus_t vbiVcoreIntRed_op 
+*	(
+*	vbiIrq_t		irq,	/@ irq number to redirect	 @/
+*	vbiCore_t		core	/@ destination vcore		 @/
+*	)
+*
+* RETURNS: returns OK or error number in case of failure
+*
+* ERROR CODES: 
+*
+* SEE ALSO: vbiVioapicIntRedirect()
+* 
+*\NOMANUAL
+*/
+vbiVcoreIntRed_op:
+
+	movl    $VBI_SYS_intRedirect, %eax	/* system call number */
+	push	$2				/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
+
+	ret
+
+/******************************************************************************
+*
+* vbiVtlbOp - execute a specified VTLB operation
+*
+* This system call executes the specified VTLB operation. The possible VTLB
+* operations are:
+*
+*   VBI_VTLB_OP_UPDATE_PMD	
+*   VBI_VTLB_OP_UPDATE_PTE	
+*   VBI_VTLB_OP_DELETE_PMD	
+*   VBI_VTLB_OP_SET_PTE_AT	
+*   VBI_VTLB_OP_SET_PTE	
+*   VBI_VTLB_OP_FLUSH_OPS	
+*   VBI_VTLB_OP_INIT	
+*
+* SYNOPSIS
+*\cs
+* vbiStatus_t vbiVtlbOp (
+*            unsigned int op,          /@ VTLB operation @/
+*            unsigned long arg1,       /@ VTLB operation argument 1 @/
+*            unsigned long arg2,       /@ VTLB operation argument 2 @/
+*            unsigned long arg3        /@ VTLB operation argument 3 @/
+*            )
+*\ce
+*
+* Returns: OK or ERROR if the VTLB operation has failed
+*/
+
+vbiVtlbOp:
+	movl    $VBI_SYS_vtlb_op, %eax	/* system call number */
+	pushl   $4			/* number of arguments */
+
+	vmcall
+
+	addl	$VBI_STACK_FRAME_SIZE, %esp	/* adjust stack */
+
+	ret
diff --git a/arch/x86/kernel/vbi/wrhv.c b/arch/x86/kernel/vbi/wrhv.c
new file mode 100644
index 0000000..03b82cc
--- /dev/null
+++ b/arch/x86/kernel/vbi/wrhv.c
@@ -0,0 +1,1335 @@
+/*
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2, or (at your option) any
+ *  later version.
+ *
+ *  This program is distributed in the hope that it will be useful, but
+ *  WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  General Public License for more details.
+ *
+ *  Copyright (C) 2009 Wind River Systems, Inc.
+ */
+
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/kthread.h>
+#include <linux/irq.h>
+#include <linux/screen_info.h>
+#include <linux/pci.h>
+#include <linux/kernel_stat.h>
+#include <linux/wrhv.h>
+#include <linux/kgdb.h>
+#include <vbi/vbi.h>
+
+#include <asm/setup.h>
+#include <asm/paravirt.h>
+#include <asm/processor.h>
+#include <asm/i8253.h>
+#include <asm/wrhv.h>
+#include <asm/fixmap.h>
+#include <asm/pgtable.h>
+#include <asm/arch_hooks.h>
+#include <asm/tlbflush.h>
+#include "do_timer.h"
+#include <asm/trampoline.h>
+#include <linux/percpu.h>
+#include <linux/smp.h>
+#include <asm/cpu.h>
+#include <asm/reboot.h>		/* for struct machine_ops */
+
+
+//#define WRHV_DEBUG_MSR	1
+#define WRHV_USE_XMLCONFIG	1
+#define WRHV_POLL_IRQ		7
+
+/* Copied over during early bootstrap */
+VB_CONFIG __wrhvConfig = { .pid = -1 };
+VB_CONFIG *_wrhvConfig; /* Pointer passed from hypervisor */
+VB_CONFIG *wrhvConfig = &__wrhvConfig;
+VB_STATUS *wrhvStatus;
+VB_CONTROL *wrhvControl;
+
+#ifdef CONFIG_PCI
+extern struct pci_ops pci_root_ops;
+extern int (*pcibios_enable_irq)(struct pci_dev *dev);
+extern void (*pcibios_disable_irq)(struct pci_dev *dev);
+#endif
+
+static unsigned long cr3_val[NR_CPUS];
+static VBI_VTLB_CONTROL	vtlb_ctrl[NR_CPUS];
+static unsigned long is_cr3_cache_enabled[NR_CPUS];
+static unsigned long is_vtlb_optim_enabled[NR_CPUS];
+static unsigned long is_vtlb_ops_cache_enabled[NR_CPUS];
+
+#ifdef	CONFIG_SMP
+#define	VTLB_GET_CPU_VAR(var)	var[smp_processor_id()]
+#else
+#define	VTLB_GET_CPU_VAR(var)	var[0]
+#endif
+
+static cpumask_t flush_cpumask;
+static struct mm_struct *flush_mm;
+static unsigned long flush_va;
+static DEFINE_SPINLOCK(tlbstate_lock);
+static DEFINE_SPINLOCK(vioapic_lock);
+
+#define VBI_VTLB_OPTIM_OPTION (\
+			 VBI_VTLB_OPTIM_ENABLED |  \
+			 VBI_VTLB_CR3_CACHE_ENABLED |  \
+			 VBI_VTLB_OPS_CACHE_ENABLED |  \
+			 VBI_VTLB_DIRTY_BIT_SUPPORT_ENABLED)
+
+static void wrhv_vtlb_op (unsigned int op, unsigned long arg1,
+				unsigned long arg2, unsigned long arg3);
+
+static void wrhv_pre_intr_init_hook(void)
+{
+	int i;
+
+	for (i = 0; i < NR_IRQS; i++) {
+		irq_desc[i].status = IRQ_DISABLED;
+		irq_desc[i].action = NULL;
+		irq_desc[i].depth = 1;
+		set_irq_chip_and_handler_name(i, &wrhv_irq_chip, handle_fasteoi_irq, "fasteoi");
+	}
+}
+
+void __init wrhv_init_IRQ(void)
+{
+	int i;
+
+	/* This maps in hypervisor config/status/control space.
+	   It has to be carefully crafted to be an identity mapping.  We ask
+	   for this space to be supplied to us from the hypervisor at
+	   address 0xffff0000 in the virtual board xml, and we essentially
+	   setup FIX_WRHV_END to be 16, representing 16 4K pages from the
+	   end of address space.  This gives us the address 0xffff0000 in Linux
+	   which we need for a virt=phys aka identity mapping.  Why do we
+	   need this to be identity mapped?  Because this block of memory
+	   space is supplied by the hypervisor outside of Linux control, and
+	   it contains pointers to places within itself.  We really don't want
+	   to have to hunt down and modify all those pointers at run time to
+	   be a different (virtual) address.
+	*/
+	   
+	for (i=0; i<(FIX_WRHV_END - FIX_WRHV_START); i++) {
+		__set_fixmap(FIX_WRHV_END - i,
+			 (unsigned long)_wrhvConfig+(i*PAGE_SIZE), PAGE_KERNEL);
+	}
+
+	/* We no longer need to use the vbconfig copy, map it straight in */
+	wrhvConfig = (VB_CONFIG *)fix_to_virt(FIX_WRHV_END);
+		
+	/* Setup the global variables used by the vbi */
+	vbiInit(wrhvConfig);
+
+	wrhv_pre_intr_init_hook();
+
+	for (i = 0; i < (NR_VECTORS - FIRST_EXTERNAL_VECTOR); i++) {
+		int vector = FIRST_EXTERNAL_VECTOR + i;
+		if (i >= NR_IRQS)
+			break;
+		if (vector != SYSCALL_VECTOR)
+			set_intr_gate(vector, interrupt[i]);
+	}
+
+	irq_ctx_init(smp_processor_id());
+
+	/* race during reboot might have left a timer interrupt
+	 * pending and unacked */
+	/*
+	irq_desc[0].chip->ack(0);
+	*/
+}
+
+static void wrhv_init_timer(enum clock_event_mode mode,
+				struct clock_event_device *evt)
+{
+}
+
+static int wrhv_set_next_event(unsigned long delta,
+			    struct clock_event_device *evt)
+{
+	return 0;
+}
+
+static inline void wrhv_send_ipi(int, int);
+static void wrhv_timer_broadcast(cpumask_t mask)
+{
+	int cpu;
+	cpus_and(mask, mask, cpu_online_map);
+
+	for_each_cpu_mask_nr(cpu, mask)
+		wrhv_send_ipi(DUMMY_TIMER_INT, cpu);
+
+}
+
+struct clock_event_device wrhv_clock_event = {
+	.name		= "wrhv",
+	.features	= CLOCK_EVT_FEAT_PERIODIC,
+	.set_mode	= wrhv_init_timer,
+	.set_next_event = wrhv_set_next_event,
+	.broadcast	= wrhv_timer_broadcast,
+	.shift		= 32,
+	.mult		= 1,
+	.irq		= 0,
+};
+
+DEFINE_PER_CPU(struct clock_event_device, wrhv_clock_events);
+
+irqreturn_t wrhv_dummy_timer_interrupt(int irq, void *dev_id)
+{
+	int cpu = smp_processor_id();
+	struct clock_event_device *evt = &per_cpu(wrhv_clock_events, cpu);
+	if (!evt->event_handler) {
+		printk(KERN_WARNING "wrhv timer handler \
+				     has not set yet %d\n", cpu);
+		return IRQ_NONE;
+	}
+
+	evt->event_handler(evt);
+
+	return IRQ_HANDLED;
+}
+
+irqreturn_t wrhv_timer_interrupt(int irq, void *dev_id)
+{
+	int cpu = smp_processor_id();
+	struct clock_event_device *evt = &per_cpu(wrhv_clock_events, cpu);
+
+	if (!evt->event_handler) {
+		printk(KERN_WARNING
+			   "Spurious Hyp timer interrupt on cpu %d\n", cpu);
+		return IRQ_NONE;
+	}
+
+	evt->event_handler(evt);
+
+	return IRQ_HANDLED;
+}
+
+static struct irqaction wrhv_timer_irq = {
+	.handler = wrhv_timer_interrupt,
+	.flags = IRQF_DISABLED | IRQF_NOBALANCING,
+	.mask = CPU_MASK_NONE,
+	.name = "timer",
+};
+
+static inline void wrhv_mask_timer_for_vcore(void);
+static inline void wrhv_umask_timer_for_vcore(void);
+void __devinit wrhv_setup_boot_clock(void)
+{
+#ifdef CONFIG_WRHV_X86_HRTIMERS
+	int ret;
+	struct clock_event_device *evt;
+
+	wrhv_mask_timer_for_vcore();
+	evt = &per_cpu(wrhv_clock_events, 0);
+	memcpy(evt, &wrhv_clock_event, sizeof(*evt));
+	evt->cpumask = cpumask_of_cpu(0);
+	evt->features = CLOCK_EVT_FEAT_DUMMY | CLOCK_EVT_FEAT_ONESHOT;
+	evt->irq = DUMMY_TIMER_INT;
+	evt->rating = 1;
+	clockevents_register_device(evt);
+	wrhv_timer_irq.name = "dummy_ipi_timer";
+	wrhv_timer_irq.handler = wrhv_dummy_timer_interrupt;
+	ret = setup_irq(DUMMY_TIMER_INT, &wrhv_timer_irq);
+	if (ret)
+		printk(KERN_WARNING "setup dummy timer irq failed\n");
+#endif
+}
+
+void __devinit wrhv_setup_secondary_clock(void)
+{
+	int cpu;
+	struct clock_event_device *evt;
+	cpu = smp_processor_id();
+	printk(KERN_INFO "installing wrhv timer for CPU %d\n", cpu);
+
+	evt = &per_cpu(wrhv_clock_events, cpu);
+	memcpy(evt, &wrhv_clock_event, sizeof(*evt));
+	evt->cpumask = cpumask_of_cpu(cpu);
+
+#ifdef CONFIG_WRHV_X86_HRTIMERS
+	evt->features = CLOCK_EVT_FEAT_DUMMY | CLOCK_EVT_FEAT_ONESHOT;
+	evt->irq = DUMMY_TIMER_INT;
+	evt->rating = 1;
+#endif
+	clockevents_register_device(evt);
+}
+
+#ifndef CONFIG_WRHV_X86_HRTIMERS
+static void __init wrhv_time_init(void)
+{
+	struct clock_event_device *evt;
+
+	evt = &per_cpu(wrhv_clock_events, 0);
+	memcpy(evt, &wrhv_clock_event, sizeof(*evt));
+	evt->cpumask = cpumask_of_cpu(0);
+
+	clockevents_register_device(evt);
+	wrhv_timer_irq.mask = cpumask_of_cpu(0);
+	setup_irq(0, &wrhv_timer_irq);
+}
+#endif
+
+#ifdef CONFIG_PCI
+static int wrhv_pci_enable_irq(struct pci_dev *dev)
+{
+	return 0;
+}
+
+static void wrhv_pci_disable_irq(struct pci_dev *dev)
+{
+}
+
+static int wrhv_init_pci(void)
+{
+	pcibios_enable_irq = wrhv_pci_enable_irq;
+	pcibios_disable_irq = wrhv_pci_disable_irq;
+	return 0;
+}
+
+static int __devinitdata __wrhv_kgdboe_poll;
+static int __init wrhv_check_kgdboe(char *str)
+{
+	__wrhv_kgdboe_poll = 1;
+	return 0;
+}
+early_param("kgdboe", wrhv_check_kgdboe);
+
+static void __devinit pci_fixup_wrhv(struct pci_dev *dev)
+{
+	int irq;
+	char *devclass, devname[32] = { "Unknown" };
+	int skip_assign_irq = 0;
+
+	switch (dev->class >> 16) {
+	case PCI_BASE_CLASS_NETWORK:
+		devclass = "Ethernet";
+		if (__wrhv_kgdboe_poll) {
+			skip_assign_irq = 1;
+			irq = WRHV_POLL_IRQ;
+		}
+		break;
+
+	case PCI_BASE_CLASS_STORAGE:
+		devclass = "IDE";
+		break;
+
+	case PCI_BASE_CLASS_DISPLAY:
+		devclass = "VGA";
+		break;
+	default:
+		skip_assign_irq = 1;
+		irq = dev->irq;
+		break;
+	}
+
+	if (!skip_assign_irq) {
+		snprintf(devname, sizeof devname, "pci%s_%x:%x",
+			devclass, dev->bus->number, dev->devfn);
+		irq = vbiIntVecFind(devname, 1);
+		if (irq == VBI_INVALID_IRQ)
+			irq = WRHV_POLL_IRQ;
+	}
+
+	dev->irq = irq;
+	printk(KERN_DEBUG "WRHV-PCI: %s CLASS:%x IRQ%d\n",
+		devname, dev->class, dev->irq);
+}
+
+DECLARE_PCI_FIXUP_HEADER(PCI_ANY_ID, PCI_ANY_ID, pci_fixup_wrhv);
+#endif /* CONFIG_PCI */
+
+static unsigned long long wrhv_read_msr(unsigned int msr, int *err)
+{
+#ifdef WRHV_DEBUG_MSR
+	printk("RDMSR from %p\n", __builtin_return_address(0));
+#endif
+	return native_read_msr(msr);
+}
+
+static int wrhv_write_msr(unsigned int msr, unsigned low, unsigned high)
+{
+#ifdef WRHV_DEBUG_MSR
+	printk("WRMSR from %p\n", __builtin_return_address(0));
+#endif
+	native_write_msr(msr, low, high);
+	return 0;
+}
+
+static unsigned long wrhv_get_debugreg(int regno)
+{
+	unsigned long val = ~0UL;
+
+	switch (regno) {
+	case 0 ... 3:
+		/* undefined state */
+		break;
+	case 6 ... 7:
+		val = 0;
+		break;
+	default:
+		BUG();
+	}
+	return val;
+}
+
+static void wrhv_set_debugreg(int regno, unsigned long value)
+{
+}
+
+void wrhv_cpu_workarounds(struct cpuinfo_x86 *c)
+{
+	/* Simics workaround */
+	c->hlt_works_ok = 0;
+
+	/* WP test fails currently */
+	c->wp_works_ok = 1;
+
+	clear_bit(X86_FEATURE_DE, (void *)boot_cpu_data.x86_capability);
+}
+
+void wrhv_boot_config(void)
+{
+	boot_params.hdr.type_of_loader = 0xff; /* Unknown */
+	if (__initrd_start != __initrd_end) {
+		boot_params.hdr.ramdisk_image = (unsigned long)&__initrd_start - PAGE_OFFSET;
+		boot_params.hdr.ramdisk_size = (unsigned long)&__initrd_end - (unsigned long)&__initrd_start;
+	}
+
+#ifndef WRHV_USE_XMLCONFIG
+	strlcpy(boot_command_line,
+		"pci=conf1 memmap=exactmap memmap=32M@0 mem=nopentium earlyprintk=vga,keep ramdisk_size=16384"
+		" serialnumber nolapic nomce nosep retain_initrd root=/dev/ram init=/bin/busybox console=ttyS0,9600",
+		COMMAND_LINE_SIZE);
+#else
+	/* Use the config space copy here, since we haven't mapped in the
+	   actual hypervisor config/status/control space yet */
+        snprintf(boot_command_line, COMMAND_LINE_SIZE,
+		"retain_initrd pci=conf1 idle=wrhv mem=nopentium serialnumber nolapic nomce nosep memmap=exactmap memmap=%dK@0 %s",
+		wrhvConfig->physicalMemorySize / 1024, wrhvConfig->bootLine);
+#endif
+}
+
+#ifdef CONFIG_SMP
+irqreturn_t wrhv_ipi_func_call_single_handler(int irq, void *dev_id)
+{
+	irq_enter();
+	generic_smp_call_function_single_interrupt();
+	__get_cpu_var(irq_stat).irq_call_count++;
+	irq_exit();
+	vbiVioapicIntUnmask(irq);
+	return IRQ_HANDLED;
+}
+
+irqreturn_t wrhv_ipi_func_call_handler(int irq, void *dev_id)
+{
+	irq_enter();
+	generic_smp_call_function_interrupt();
+	__get_cpu_var(irq_stat).irq_call_count++;
+	irq_exit();
+	vbiVioapicIntUnmask(irq);
+	return IRQ_HANDLED;
+}
+
+irqreturn_t wrhv_ipi_inv_tlb_handler(int irq, void *dev_id)
+{
+	unsigned long cpu;
+
+	cpu = get_cpu();
+
+	if (!cpu_isset(cpu, flush_cpumask))
+		goto out;
+		/*
+		 * This was a BUG() but until someone can quote me the
+		 * line from the intel manual that guarantees an IPI to
+		 * multiple CPUs is retried _only_ on the erroring CPUs
+		 * its staying as a return
+		 *
+		 * BUG();
+		 */
+
+	if (flush_mm == per_cpu(cpu_tlbstate, cpu).active_mm) {
+		if (per_cpu(cpu_tlbstate, cpu).state == TLBSTATE_OK) {
+			if (flush_va == TLB_FLUSH_ALL)
+				local_flush_tlb();
+			else
+				__flush_tlb_one(flush_va);
+		} else {
+			wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD,
+					__pa(flush_mm->pgd), 0, 0);
+			leave_mm(cpu);
+		}
+	} else {
+	    if (flush_va == TLB_FLUSH_ALL)
+			wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD,
+					__pa(flush_mm->pgd),
+					0, 0);
+	    else
+			wrhv_vtlb_op(VBI_VTLB_OP_UPDATE_PTE,
+					__pa(flush_mm->pgd),
+					(unsigned long)flush_mm, 0);
+
+	}
+
+	smp_mb__before_clear_bit();
+	cpu_clear(cpu, flush_cpumask);
+	smp_mb__after_clear_bit();
+out:
+	put_cpu_no_resched();
+	__get_cpu_var(irq_stat).irq_tlb_count++;
+
+	vbiVioapicIntUnmask(irq);
+	return IRQ_HANDLED;
+}
+
+irqreturn_t wrhv_ipi_resched_handler(int irq, void *dev_id)
+{
+	__get_cpu_var(irq_stat).irq_resched_count++;
+	vbiVioapicIntUnmask(irq);
+	return IRQ_HANDLED;
+}
+#endif
+
+static void wrhv_vtlb_op (unsigned int op, unsigned long arg1, unsigned long arg2, unsigned long arg3)
+{
+	unsigned long flags;
+	int i;
+
+	if (!VTLB_GET_CPU_VAR(is_vtlb_ops_cache_enabled))
+		vbiVtlbOp (op, arg1, arg2, arg3);
+	else {
+		local_irq_save(flags);
+		i = VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops_ix;
+		VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops[i].op = op;
+		VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops[i].arg1 = arg1;
+		VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops[i].arg2 = arg2;
+		VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops[i].arg3 = arg3;
+		wmb();
+		/*
+		 * If the buffer is full, flush it. Index will be automatically
+		 * updated by the hypervisor.
+		 */
+
+		if (VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops_ix == (VBI_VTLB_OP_MAX_OPS - 1))
+			vbiVtlbOp (VBI_VTLB_OP_FLUSH_OPS, 0, 0, 0);
+		else
+			VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops_ix += 1;
+
+		local_irq_restore(flags);
+	}
+}
+
+static void wrhv_write_cr3(unsigned long val)
+{
+	unsigned long cr3 = val;
+	int i;
+
+	if (VTLB_GET_CPU_VAR(is_cr3_cache_enabled) && VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops_ix == 0) {
+		for (i = 0; i < VBI_VTLB_OP_CR3_CACHE_ENTRIES; i++) {
+			if (VTLB_GET_CPU_VAR(vtlb_ctrl).cr3_cache[i].guest_cr3 == cr3) {
+				cr3 = VTLB_GET_CPU_VAR(vtlb_ctrl).cr3_cache[i].host_cr3;
+				VTLB_GET_CPU_VAR(vtlb_ctrl).cr3_cache_ix = i;
+				break;
+			}
+		}
+	} else
+		VTLB_GET_CPU_VAR(vtlb_ctrl).cr3_cache_ix = -1;
+
+	asm volatile ("mov %0,%%cr3": :"r" (cr3));
+	VTLB_GET_CPU_VAR(cr3_val) = val;
+}
+
+static unsigned long wrhv_read_cr3(void)
+{
+	/* Use cached value to avoid useless hypercall */
+	return VTLB_GET_CPU_VAR(cr3_val);
+}
+
+static void wrhv_set_pmd(pmd_t *pmdp, pmd_t pmdval)
+{
+	*pmdp = pmdval;
+	wrhv_vtlb_op(VBI_VTLB_OP_UPDATE_PMD,
+			__pa(((unsigned long) pmdp) & PAGE_MASK),
+			__pa(pmdp), 0);
+}
+
+#define is_current_as(mm) ((mm) == current->active_mm || ((mm) == &init_mm))
+
+static void wrhv_pte_update(struct mm_struct *mm, unsigned long addr, pte_t *ptep)
+{
+	if (!is_current_as(mm))
+		wrhv_vtlb_op(VBI_VTLB_OP_UPDATE_PTE, __pa(mm->pgd),
+						addr, __pa(ptep));
+}
+
+static void wrhv_pte_update_defer(struct mm_struct *mm, unsigned long addr, pte_t *ptep)
+{
+	if (!is_current_as(mm))
+		wrhv_pte_update (mm, addr, ptep);
+}
+
+static void wrhv_release_pd(u32 pfn)
+{
+	wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD, pfn << PAGE_SHIFT, 0, 0);
+}
+
+static void wrhv_set_pte(pte_t *ptep, pte_t pte)
+{
+	*ptep = pte;
+}
+
+static void wrhv_flush_tlb_user(void)
+{
+	native_write_cr3(VTLB_GET_CPU_VAR(cr3_val));
+}
+
+static void wrhv_flush_tlb_kernel(void)
+{
+	unsigned long cr4, flags;
+
+	/* This routine is not optimized but since it is very rarely used
+	   let's not worry too much about this for now.
+	 */
+
+	local_irq_save(flags);
+	cr4 = native_read_cr4();
+	native_write_cr4(cr4 & ~X86_CR4_PGE);
+	native_write_cr3(VTLB_GET_CPU_VAR(cr3_val));
+	native_write_cr4(cr4);
+	local_irq_restore(flags);
+}
+
+static void wrhv_flush_tlb_single(unsigned long addr)
+{
+	__native_flush_tlb_single(addr);
+}
+
+static inline void wrhv_send_ipi(int irq, int coreid)
+{
+	int ret;
+	unsigned long flags;
+
+	spin_lock_irqsave(&vioapic_lock, flags);
+	ret = vbiVioapicIntRedirect(irq, coreid);
+	if (unlikely(!!ret))
+		printk(KERN_ERR "IPI: redirect to core%d for IPI%d failed. \n", coreid, irq);
+
+	ret = vbiVioapicIntSend(irq, VBI_IOAPICSEND_OTHERS, VBI_BOARD_ID_GET());
+	spin_unlock_irqrestore(&vioapic_lock, flags);
+	if (unlikely(!!ret))
+		printk(KERN_ERR "IPI: send IPI%d to core%d failed. \n", irq, coreid);
+
+}
+
+static void wrhv_smp_send_invalidate_tlb_ipi(cpumask_t mask)
+{
+	int cpu;
+	cpus_and(mask, mask, cpu_online_map);
+
+	for_each_cpu_mask_nr(cpu, mask)
+		wrhv_send_ipi(WRHV_IPI_INV_TLB, cpu);
+}
+
+static void wrhv_flush_tlb_others(const cpumask_t *cpumaskp, struct mm_struct *mm,
+			     unsigned long va)
+{
+	cpumask_t cpumask = *cpumaskp;
+
+	/*
+	 * A couple of (to be removed) sanity checks:
+	 *
+	 * - current CPU must not be in mask
+	 * - mask must exist :)
+	 */
+	BUG_ON(cpus_empty(cpumask));
+	BUG_ON(cpu_isset(smp_processor_id(), cpumask));
+	BUG_ON(!mm);
+
+	/*
+	 * i'm not happy about this global shared spinlock in the
+	 * MM hot path, but we'll see how contended it is.
+	 * AK: x86-64 has a faster method that could be ported.
+	 */
+	spin_lock(&tlbstate_lock);
+
+	flush_mm = mm;
+	flush_va = va;
+	cpus_or(flush_cpumask, cpumask, flush_cpumask);
+	/*
+	 * We have to send the IPI only to
+	 * CPUs affected.
+	 */
+	wrhv_smp_send_invalidate_tlb_ipi(cpumask);
+
+	while (!cpus_empty(flush_cpumask))
+		/* nothing. lockup detection does not belong here */
+		cpu_relax();
+
+	flush_mm = NULL;
+	flush_va = 0;
+	spin_unlock(&tlbstate_lock);
+}
+
+static void wrhv_set_pte_at(struct mm_struct *mm, unsigned long addr, pte_t *ptep, pte_t pte)
+{
+	if (!is_current_as(mm)) {
+		*ptep = pte;
+		wrhv_vtlb_op(VBI_VTLB_OP_SET_PTE_AT, __pa(mm->pgd),
+						addr, __pa(ptep));
+	} else
+		*ptep = pte;
+}
+
+static unsigned wrhv_patch(u8 type, u16 clobber, void *ibuf,
+				unsigned long addr, unsigned len)
+{
+	return paravirt_patch_default(type, clobber, ibuf, addr, len);
+}
+
+static void wrhv_exit_mmap (struct mm_struct *mm)
+{
+#ifdef CONFIG_SMP
+	/*
+	 * We are deleting the page directory. We need to delete it in
+	 * the current hypervisor cache but also in the cache of the
+	 * hypervisors managing the various virtual cores.
+	 */
+
+	cpumask_t cpumask;
+	int cpu = get_cpu ();
+	wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD, __pa(mm->pgd), 0, 0);
+	cpumask = mm->cpu_vm_mask;
+	cpu_clear(cpu, cpumask);
+	if (!cpus_empty(cpumask))
+	    wrhv_flush_tlb_others (&cpumask, mm, TLB_FLUSH_ALL);
+	put_cpu ();
+#else
+	wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD, __pa(mm->pgd), 0, 0);
+#endif
+}
+
+static void wrhv_init_mm(void)
+{
+	/* Initialize the cached copy of cr3 */
+	VTLB_GET_CPU_VAR(cr3_val) = native_read_cr3();
+
+	/*
+	 * set the size of the vtlb_ctrl structure in the structure provided
+	 * to the hypervisor; the hypervisor may be able to use this later
+	 * for backward compatibility.
+	 */
+
+	VTLB_GET_CPU_VAR(vtlb_ctrl).size = sizeof (VTLB_GET_CPU_VAR(vtlb_ctrl));
+
+	/* First set the options supported by the guest OS. The host will
+	   then update the mode field of vtlb_ctrl option to indicate which
+	   one will actually be in use.
+	*/
+
+	VTLB_GET_CPU_VAR(vtlb_ctrl).mode = VBI_VTLB_OPTIM_OPTION;
+
+	vbiVtlbOp(VBI_VTLB_OP_INIT, __pa_symbol(&VTLB_GET_CPU_VAR(vtlb_ctrl)), 0, 0);
+
+	if (VTLB_GET_CPU_VAR(vtlb_ctrl).mode & VBI_VTLB_CR3_CACHE_ENABLED)
+		VTLB_GET_CPU_VAR(is_cr3_cache_enabled) = 1;
+	if (VTLB_GET_CPU_VAR(vtlb_ctrl).mode & VBI_VTLB_OPTIM_ENABLED)
+		VTLB_GET_CPU_VAR(is_vtlb_optim_enabled) = 1;
+	if (VTLB_GET_CPU_VAR(vtlb_ctrl).mode & VBI_VTLB_OPS_CACHE_ENABLED)
+		VTLB_GET_CPU_VAR(is_vtlb_ops_cache_enabled) = 1;
+
+	pv_mmu_ops.read_cr3 = wrhv_read_cr3;
+	pv_mmu_ops.write_cr3 = wrhv_write_cr3;
+
+	if (VTLB_GET_CPU_VAR(is_vtlb_optim_enabled)) {
+		pv_mmu_ops.set_pte = wrhv_set_pte;
+		pv_mmu_ops.set_pte_at = wrhv_set_pte_at;
+
+		pv_mmu_ops.pte_update = wrhv_pte_update;
+		pv_mmu_ops.pte_update_defer = wrhv_pte_update_defer;
+		pv_mmu_ops.set_pmd = wrhv_set_pmd;
+
+		pv_mmu_ops.release_pmd = wrhv_release_pd;
+
+		pv_mmu_ops.exit_mmap = wrhv_exit_mmap,
+
+		pv_mmu_ops.flush_tlb_user = wrhv_flush_tlb_user;
+		pv_mmu_ops.flush_tlb_kernel = wrhv_flush_tlb_kernel;
+		pv_mmu_ops.flush_tlb_single = wrhv_flush_tlb_single;
+	}
+#ifdef CONFIG_SMP
+	pv_mmu_ops.flush_tlb_others = wrhv_flush_tlb_others;
+#endif
+}
+
+int __init wrhv_late_init(void)
+{
+	return 0;
+}
+late_initcall(wrhv_late_init);
+
+static inline void wrhv_umask_timer_for_vcore(void)
+{
+       /* unmask hypervisor-provided timer interrupt for vcore */
+       vbiVioapicIntUnmask(0);
+}
+
+static inline void wrhv_mask_timer_for_vcore(void)
+{
+       /* mask hypervisor-provided timer interrupt for vcore */
+       vbiVioapicIntMask(0);
+}
+
+#ifdef CONFIG_SMP
+static void __init wrhv_smp_prepare_boot_cpu(void)
+{
+	BUG_ON(smp_processor_id() != 0);
+	native_smp_prepare_boot_cpu();
+	return;
+}
+
+void __init wrhv_calibrate_smp_cpus(void)
+{
+	/* Use the config space copy here, since we haven't mapped in the
+	   actual hypervisor config/status/control space yet */
+	int cpus = wrhvConfig->numCores;
+	int cpuid = wrhvConfig->coreId;
+	if (cpuid != 0)
+		return;
+	printk(KERN_INFO "WRHV: calibrate CPU information according to vbConfig \n");
+	physid_clear(16, phys_cpu_present_map);
+	if (cpus > 1) {
+		smp_found_config = 1;
+		alternatives_smp_switch(1);
+	}
+
+	while( --cpus >= 0) {
+		physid_set(cpus, phys_cpu_present_map);
+		cpu_set(cpus, cpu_present_map);
+		cpu_set(cpus, cpu_possible_map);
+	}
+	return;
+}
+EXPORT_SYMBOL(wrhv_calibrate_smp_cpus);
+
+static void inline wrhv_umask_IPIs_for_vcore(void)
+{
+       /* unmask ipi interrupt for vcore */
+       vbiVioapicIntUnmask(WRHV_IPI_RESCHED);
+       vbiVioapicIntUnmask(WRHV_IPI_INV_TLB);
+       vbiVioapicIntUnmask(WRHV_IPI_FUNC_CALL);
+       vbiVioapicIntUnmask(WRHV_IPI_FUNC_CALL_SINGLE);
+#ifdef CONFIG_WRHV_X86_HRTIMERS
+	vbiVioapicIntUnmask(DUMMY_TIMER_INT);
+#endif
+}
+
+static void x86_wrhv_mask_irq(void *irq)
+{
+	vbiVioapicIntMask((unsigned int)irq);
+}
+
+static void x86_wrhv_unmask_irq(void *irq)
+{
+	vbiVioapicIntUnmask((unsigned int)irq);
+}
+
+/* Currently all the external interrupts are routed to cpu 0 and
+ * handled by cpu0, so we need make sure the startup/shutdown functions
+ * operate cpu 0's vioapic.
+ */
+static void smp_wrhv_shutdown_irq(unsigned int irq)
+{
+	if (smp_processor_id() == 0)
+		x86_wrhv_mask_irq((void *)irq);
+	else {
+		struct call_single_data *data;
+
+		data = kmalloc(sizeof(*data), GFP_ATOMIC);
+		if (!data)
+			return;
+
+		data->flags = CSD_FLAG_ALLOC;
+		data->func = x86_wrhv_mask_irq;
+		data->info = (void *)irq;
+		__smp_call_function_single(0, data);
+	}
+}
+
+static unsigned int smp_wrhv_startup_irq(unsigned int irq)
+{
+	if (smp_processor_id() == 0)
+		x86_wrhv_unmask_irq((void *)irq);
+	else {
+		struct call_single_data *data;
+
+		data = kmalloc(sizeof(*data), GFP_ATOMIC);
+		if (!data)
+			return -ENOMEM;
+
+		data->flags = CSD_FLAG_ALLOC;
+		data->func = x86_wrhv_unmask_irq;
+		data->info = (void *)irq;
+		__smp_call_function_single(0, data);
+	}
+	return 0;
+}
+
+void __init wrhv_smp_prepare_cpus(unsigned int max_cpus)
+{
+	int ret;
+	native_smp_prepare_cpus(max_cpus);
+
+	wrhv_irq_chip.ack = NULL;
+	wrhv_irq_chip.startup = smp_wrhv_startup_irq;
+	wrhv_irq_chip.shutdown = smp_wrhv_shutdown_irq;
+
+	set_irq_chip_and_handler_name(WRHV_IPI_RESCHED,
+			&wrhv_irq_chip, handle_percpu_irq, "per_cpu");
+	set_irq_chip_and_handler_name(WRHV_IPI_INV_TLB,
+			&wrhv_irq_chip, handle_percpu_irq, "per_cpu");
+	set_irq_chip_and_handler_name(WRHV_IPI_FUNC_CALL,
+			&wrhv_irq_chip, handle_percpu_irq, "per_cpu");
+	set_irq_chip_and_handler_name(WRHV_IPI_FUNC_CALL_SINGLE,
+			&wrhv_irq_chip, handle_percpu_irq, "per_cpu");
+
+#ifdef CONFIG_WRHV_X86_HRTIMERS
+	set_irq_chip_and_handler_name(DUMMY_TIMER_INT,
+			&wrhv_irq_chip, handle_percpu_irq, "per_cpu");
+#endif
+
+	ret = request_irq(WRHV_IPI_RESCHED, wrhv_ipi_resched_handler,
+			IRQF_DISABLED|IRQF_NOBALANCING, "ipi_resched",
+			wrhv_ipi_resched_handler);
+	printk("request_irq ret for WRHV_IPI_RESCHED: %d \n", ret);
+
+	ret = request_irq(WRHV_IPI_INV_TLB, wrhv_ipi_inv_tlb_handler,
+			IRQF_DISABLED|IRQF_NOBALANCING, "ipi_inv_tlb",
+			wrhv_ipi_inv_tlb_handler);
+	printk("request_irq ret for WRHV_IPI_INV_TLB: %d \n", ret);
+
+	ret = request_irq(WRHV_IPI_FUNC_CALL, wrhv_ipi_func_call_handler,
+			IRQF_DISABLED|IRQF_NOBALANCING, "ipi_func_call",
+			wrhv_ipi_func_call_handler);
+	printk("request_irq ret for WRHV_IPI_FUNC_CALL: %d \n", ret);
+
+	ret = request_irq(WRHV_IPI_FUNC_CALL_SINGLE,
+			wrhv_ipi_func_call_single_handler,
+			IRQF_DISABLED|IRQF_NOBALANCING, "ipi_func_call_single",
+			wrhv_ipi_func_call_single_handler);
+	printk("request_irq ret for WRHV_IPI_FUNC_CALL_SINGLE: %d \n", ret);
+
+	wrhv_umask_IPIs_for_vcore();
+
+	return;
+}
+
+#ifdef CONFIG_HOTPLUG_CPU
+static DEFINE_PER_CPU(struct task_struct *, idle_thread_array);
+#define get_idle_for_cpu(x)      (per_cpu(idle_thread_array, x))
+#define set_idle_for_cpu(x, p)   (per_cpu(idle_thread_array, x) = (p))
+#else
+extern struct task_struct *idle_thread_array[NR_CPUS] __cpuinitdata ;
+#define get_idle_for_cpu(x)      (idle_thread_array[(x)])
+#define set_idle_for_cpu(x, p)   (idle_thread_array[(x)] = (p))
+#endif
+
+struct create_idle {
+	struct work_struct work;
+	struct task_struct *idle;
+	struct completion done;
+	int cpu;
+};
+
+static void __cpuinit do_fork_idle(struct work_struct *work)
+{
+	struct create_idle *c_idle =
+		container_of(work, struct create_idle, work);
+
+	c_idle->idle = fork_idle(c_idle->cpu);
+	complete(&c_idle->done);
+}
+
+static void __cpuinit wrhv_smp_callin(void)
+{
+	int cpuid;
+	unsigned long timeout;
+
+	cpuid = smp_processor_id();
+	if (cpu_isset(cpuid, cpu_callin_map)) {
+		panic("%s: CPU#%d already present??\n", __func__, cpuid);
+	}
+
+	/*
+	 * Waiting 2s total for startup (udelay is not yet working)
+	 */
+	timeout = jiffies + 2*HZ;
+	while (time_before(jiffies, timeout)) {
+		/*
+		 * Has the boot CPU finished it's STARTUP sequence?
+		 */
+		if (cpu_isset(cpuid, cpu_callout_map))
+			break;
+		cpu_relax();
+	}
+
+	if (!time_before(jiffies, timeout)) {
+		panic("%s: CPU%d started up but did not get a callout!\n",
+			__func__, cpuid);
+	}
+
+	local_irq_enable();
+	calibrate_delay();
+	local_irq_disable();
+
+	smp_store_cpu_info(cpuid);
+
+	/*
+	 * Allow the master to continue.
+	 */
+	cpu_set(cpuid, cpu_callin_map);
+}
+
+static int low_mappings;
+
+static void __cpuinit wrhv_smp_start_cpu(void)
+{
+	wrhv_mask_timer_for_vcore();
+
+	/* Initialize the cached copy of cr3 */
+	VTLB_GET_CPU_VAR(cr3_val) = native_read_cr3();
+
+	/*
+	 * set the size of the vtlb_ctrl structure in the structure provided
+	 * to the hypervisor; the hypervisor may be able to use this later
+	 * for backward compatibility.
+	 */
+
+	VTLB_GET_CPU_VAR(vtlb_ctrl).size = sizeof (VTLB_GET_CPU_VAR(vtlb_ctrl));
+
+	/* First set the options supported by the guest OS. The host will
+	   then update the mode field of vtlb_ctrl option to indicate which
+	   one will actually be in use.
+	*/
+
+	VTLB_GET_CPU_VAR(vtlb_ctrl).mode = VBI_VTLB_OPTIM_OPTION;
+
+	vbiVtlbOp(VBI_VTLB_OP_INIT, __pa_symbol(&VTLB_GET_CPU_VAR(vtlb_ctrl)), 0, 0);
+
+	if (VTLB_GET_CPU_VAR(vtlb_ctrl).mode & VBI_VTLB_CR3_CACHE_ENABLED)
+		VTLB_GET_CPU_VAR(is_cr3_cache_enabled) = 1;
+	if (VTLB_GET_CPU_VAR(vtlb_ctrl).mode & VBI_VTLB_OPTIM_ENABLED)
+		VTLB_GET_CPU_VAR(is_vtlb_optim_enabled) = 1;
+	if (VTLB_GET_CPU_VAR(vtlb_ctrl).mode & VBI_VTLB_OPS_CACHE_ENABLED)
+		VTLB_GET_CPU_VAR(is_vtlb_ops_cache_enabled) = 1;
+
+	cpu_init();
+	wrhv_umask_IPIs_for_vcore();
+	preempt_disable();
+	wrhv_smp_callin();
+
+	/* otherwise gcc will move up smp_processor_id before the cpu_init */
+	barrier();
+
+	/*
+	 * Check TSC synchronization with the BP:
+	 */
+	check_tsc_sync_target();
+
+#ifdef CONFIG_X86_32
+	while (low_mappings) {
+		cpu_relax();
+	}
+	__flush_tlb_all();
+#endif
+
+	set_cpu_sibling_map(raw_smp_processor_id());
+	wmb();
+
+	ipi_call_lock_irq();
+	cpu_set(smp_processor_id(), cpu_online_map);
+	ipi_call_unlock_irq();
+	per_cpu(cpu_state, smp_processor_id()) = CPU_ONLINE;
+
+	setup_secondary_clock();
+
+#ifndef CONFIG_WRHV_X86_HRTIMERS
+	wrhv_umask_timer_for_vcore();
+#endif
+	wmb();
+
+	local_irq_enable();
+	cpu_idle();
+
+}
+
+static int __cpuinit wrhv_wakeup_secondary_cpu(int core)
+{
+	return vbiVbResume(VBI_BOARD_ID_GET(), core);
+}
+
+static int __cpuinit wrhv_do_boot_cpu(int cpu)
+{
+	unsigned long boot_error = 0;
+	unsigned int timeout;
+	struct create_idle c_idle = {
+		.cpu = cpu,
+		.done = COMPLETION_INITIALIZER_ONSTACK(c_idle.done),
+	};
+
+	INIT_WORK(&c_idle.work, do_fork_idle);
+
+	alternatives_smp_switch(1);
+
+	c_idle.idle = get_idle_for_cpu(cpu);
+
+	if (c_idle.idle) {
+		c_idle.idle->thread.sp = (unsigned long) (((struct pt_regs *)
+			(THREAD_SIZE +  task_stack_page(c_idle.idle))) - 1);
+		init_idle(c_idle.idle, cpu);
+		goto do_rest;
+	}
+
+	if (!keventd_up() || current_is_keventd())
+		c_idle.work.func(&c_idle.work);
+	else {
+		schedule_work(&c_idle.work);
+		wait_for_completion(&c_idle.done);
+	}
+
+	if (IS_ERR(c_idle.idle)) {
+		printk("failed fork for CPU %d\n", cpu);
+		return PTR_ERR(c_idle.idle);
+	}
+
+	set_idle_for_cpu(cpu, c_idle.idle);
+
+do_rest:
+
+	per_cpu(current_task, cpu) = c_idle.idle;
+	init_gdt(cpu);
+	irq_ctx_init(cpu);
+
+	early_gdt_descr.address = (unsigned long)get_cpu_gdt_table(cpu);
+	initial_code = (unsigned long)wrhv_smp_start_cpu;
+	stack_start.sp = (void *) c_idle.idle->thread.sp;
+
+	printk(KERN_INFO "Booting processor %d\n", cpu);
+
+	boot_error = wrhv_wakeup_secondary_cpu(cpu);
+
+	if (!boot_error) {
+		/*
+		 * allow APs to start initializing.
+		 */
+		pr_debug("Before Callout %d.\n", cpu);
+		cpu_set(cpu, cpu_callout_map);
+		pr_debug("After Callout %d.\n", cpu);
+
+		/*
+		 * Wait 5s total for a response
+		 */
+		for (timeout = 0; timeout < 50000; timeout++) {
+			if (cpu_isset(cpu, cpu_callin_map))
+				break;	/* It has booted */
+			udelay(100);
+		}
+
+		if (cpu_isset(cpu, cpu_callin_map)) {
+			/* number CPUs logically, starting from 1 (BSP is 0) */
+			pr_debug("OK.\n");
+			printk(KERN_INFO "CPU%d: ", cpu);
+			print_cpu_info(&cpu_data(cpu));
+			pr_debug("CPU has booted.\n");
+		} else {
+			boot_error = 1;
+			printk(KERN_ERR "Not responding.\n");
+		}
+	}
+
+	if (boot_error) {
+		/* Try to put things back the way they were before ... */
+		cpu_clear(cpu, cpu_callout_map);
+		cpu_clear(cpu, cpu_initialized);
+		cpu_clear(cpu, cpu_present_map);
+	}
+
+	return boot_error;
+}
+
+static int __cpuinit wrhv_cpu_up(unsigned int cpu)
+{
+	int err;
+	unsigned long flags;
+
+	if ( !physid_isset(cpu, phys_cpu_present_map)) {
+		printk(KERN_ERR "%s: bad cpu %d\n", __func__, cpu);
+		printk("----------phys_cpu_present_map == %x \n", *(unsigned *)&phys_cpu_present_map);
+		return -EINVAL;
+	}
+
+	/*
+	 * Already booted CPU?
+	 */
+	if (cpu_isset(cpu, cpu_callin_map)) {
+		panic("wrhv_do_boot_cpu core%d Already started\n", cpu);
+		return -ENOSYS;
+	}
+
+	per_cpu(cpu_state, cpu) = CPU_UP_PREPARE;
+
+#ifdef CONFIG_X86_32
+	/* init low mem mapping */
+	clone_pgd_range(swapper_pg_dir, swapper_pg_dir + KERNEL_PGD_BOUNDARY,
+		min_t(unsigned long, KERNEL_PGD_PTRS, KERNEL_PGD_BOUNDARY));
+	flush_tlb_all();
+
+	low_mappings = 1;
+	err = wrhv_do_boot_cpu(cpu);
+	zap_low_mappings();
+	low_mappings = 0;
+#else
+	err = wrhv_do_boot_cpu(cpu);
+#endif
+	if (err) {
+		pr_debug("wrhv_do_boot_cpu failed %d\n", err);
+		return -EIO;
+	}
+
+
+	local_irq_save(flags);
+	check_tsc_sync_source(cpu);
+	local_irq_restore(flags);
+
+	while (!cpu_online(cpu)) {
+		cpu_relax();
+	}
+
+	return 0;
+}
+
+static void wrhv_smp_cpus_done(unsigned int max_cpus)
+{
+	printk(KERN_INFO "BP: smp_init done. \n");
+	native_smp_cpus_done(max_cpus);
+	return;
+}
+
+static void stop_me(void * t)
+{
+	write_cr3((unsigned long)swapper_pg_dir);
+
+	/* Enter into infinite loop to stop self*/
+	while(1);
+}
+
+static void wrhv_smp_send_stop(void)
+{
+	smp_call_function(stop_me, NULL, 0);
+	return;
+}
+
+static void wrhv_smp_send_reschedule(int cpu)
+{
+	wrhv_send_ipi(WRHV_IPI_RESCHED, cpu);
+}
+
+static void wrhv_smp_send_call_func_single_ipi(int cpu)
+{
+	wrhv_send_ipi(WRHV_IPI_FUNC_CALL_SINGLE, cpu);
+}
+
+static void wrhv_smp_send_call_func_ipi(cpumask_t mask)
+{
+	unsigned int cpu;
+	for_each_cpu_mask_nr(cpu, mask)
+		wrhv_send_ipi(WRHV_IPI_FUNC_CALL, cpu);
+}
+
+static const struct smp_ops wrhv_smp_ops __initdata = {
+	.smp_prepare_boot_cpu = wrhv_smp_prepare_boot_cpu,
+	.smp_prepare_cpus = wrhv_smp_prepare_cpus,
+	.cpu_up = wrhv_cpu_up,
+	.smp_cpus_done = wrhv_smp_cpus_done,
+
+	.smp_send_stop = wrhv_smp_send_stop,
+	.smp_send_reschedule = wrhv_smp_send_reschedule,
+
+	.send_call_func_ipi = wrhv_smp_send_call_func_ipi,
+	.send_call_func_single_ipi = wrhv_smp_send_call_func_single_ipi,
+};
+
+void __init wrhv_smp_init(void)
+{
+	smp_ops = wrhv_smp_ops;
+	return;
+}
+#endif
+
+void wrhv_restart(void)
+{
+	int ret;
+	printk(KERN_INFO "WRHV: rebooting \n");
+
+	ret = vbiVbReset(VBI_BOARD_ID_GET(), VBI_VB_CORES_ALL,
+		VBI_VBMGMT_RESET_AND_START_CORE0 |
+		VBI_VBMGMT_RESET_DOWNLOAD |
+		VBI_VBMGMT_RESET_CLEAR
+		);
+
+	if (unlikely(ret != 0))
+		printk(KERN_ERR "WRHV: reboot failed. \n");
+
+	while (1);
+}
+
+void __init wrhv_init(void)
+{
+	pv_info.name = "wrhv";
+	pv_info.paravirt_enabled = 1;
+
+	wrhv_cpu_workarounds(&boot_cpu_data);
+
+	pv_init_ops.patch = wrhv_patch;
+
+	pv_cpu_ops.write_msr = wrhv_write_msr;
+	pv_cpu_ops.read_msr = wrhv_read_msr;
+
+#ifndef CONFIG_WRHV_X86_HRTIMERS
+	pv_time_ops.time_init = wrhv_time_init;
+	pv_time_ops.get_tsc_khz = wrhv_calculate_cpu_khz;
+#endif
+
+	pv_irq_ops.init_IRQ = wrhv_init_IRQ;
+	pv_cpu_ops.get_debugreg = wrhv_get_debugreg;
+	pv_cpu_ops.set_debugreg = wrhv_set_debugreg;
+
+#ifdef CONFIG_X86_LOCAL_APIC
+	pv_apic_ops.setup_boot_clock = wrhv_setup_boot_clock;
+	pv_apic_ops.setup_secondary_clock = wrhv_setup_secondary_clock;
+#endif
+	machine_ops.emergency_restart = wrhv_restart;
+
+#ifdef CONFIG_KGDB
+	arch_kgdb_ops.flags &= ~KGDB_HW_BREAKPOINT,
+	arch_kgdb_ops.set_hw_breakpoint = NULL;
+	arch_kgdb_ops.remove_hw_breakpoint = NULL;
+	arch_kgdb_ops.remove_all_hw_break = NULL;
+	arch_kgdb_ops.correct_hw_break = NULL;
+#endif
+
+	wrhv_init_mm();
+
+#ifdef CONFIG_PCI
+	wrhv_init_pci();
+#endif
+
+#ifdef CONFIG_SMP
+	wrhv_smp_init();
+#endif
+}
diff --git a/arch/x86/kernel/vbi/wrhv_initrd.S b/arch/x86/kernel/vbi/wrhv_initrd.S
new file mode 100644
index 0000000..c5f40d6
--- /dev/null
+++ b/arch/x86/kernel/vbi/wrhv_initrd.S
@@ -0,0 +1,3 @@
+/*
+ *  This file simply exists to trigger the Makefile to include the INITRD
+ */
diff --git a/arch/x86/kernel/vbiIntController.c b/arch/x86/kernel/vbiIntController.c
deleted file mode 100644
index 3479167..0000000
--- a/arch/x86/kernel/vbiIntController.c
+++ /dev/null
@@ -1,116 +0,0 @@
-/* vbiIntController.c - virtual interrupt controller device */
-
-/*
- * Copyright (c) 2009 Wind River Systems, Inc.
- *
- * The right to copy, distribute, modify or otherwise make use
- * of this software may be licensed only pursuant to the terms
- * of an applicable Wind River license agreement.
- */
-
-/*
-modification history
---------------------
-01b,25oct07,foo  update for real hardware interrupt implementation
-01a,09may07,foo  written
-*/
-
-/*
- * This module contains the code for accessing and controlling the
- * virtual interrupt controller as presented to a Virtual Board.
- */
-/* #define DEBUG 1 */
-#ifdef DEBUG
-#define DEBUGM(x) x
-#else
-#define DEBUGM(x)
-#endif
-
-#include <vbi/interface.h>
-#include <vbi/vbInterrupt.h>
-
-#include <linux/string.h>
-#include <linux/irq.h>
-#include <linux/irqreturn.h>
-#include <linux/module.h>
-
-typedef irqreturn_t (*IRQHANDLER) (unsigned int a, ...);
-
-/* Type for storing interrupt handlers provided by the application */
-typedef struct vbiIntControllerHandler
-    {
-    IRQHANDLER handler;  /* The handler to call for the interrupt */
-    void *        param;    /* The parameter to be passed first */
-    } VBI_INT_CONTROLLER_HANDLER;
-
-/* Storage for interrupt handlers */
-VBI_INT_CONTROLLER_HANDLER vbiIntControllerHandlers[VB_MAX_INTERRUPTS];
-
-#define CALL_INT_HANDLER() handle_simple_irq(vector, &irq_desc[vector])
-#define HANDLERFUNCPTR irqreturn_t(*handler)()
-
-void vbiIntControllerHandle(void);
-
-/******************************************************************************
-*
-* vbiIntControllerConnect - connect to a specific vector in the virtual controller
-*
-* RETURNS: None
-*
-*/
-void vbiIntControllerConnect
-    (
-    int vector,
-    VOIDFUNCPTR handler,
-    void * param
-    )
-{
-}
-EXPORT_SYMBOL(vbiIntControllerConnect);
-
-/******************************************************************************
-*
-* vbiIntControllerFindVector - determine the interrupt vector for a specified
-*                              interrupt
-*
-* RETURNS: None
-*
-*/
-void vbiIntControllerFindVector
-    (
-    char * intName,        /* String name of the interrupt */
-    int    inputInterrupt, /* Input vector = 1, Output vector = 0 */
-    int *  vector          /* vector number returned here, -1 if not found */
-    )
-    {
-    VB_INT_INFO * info = wrhvConfig->interruptConfiguration;
-    int           num  = wrhvConfig->numInts;
-    int           i;
-
-    *vector = -1;
-    for (i = 0; i < num; i++, info++)
-        {
-        if (inputInterrupt)
-            {
-            if (info->intDirection != VB_INPUT_INT)
-                {
-                continue;
-                }
-            }
-        else
-            {
-            if (info->intDirection == VB_INPUT_INT)
-                {
-                continue;
-                }
-            }
-        if (!strncmp (intName, info->intName, VB_MAX_WRHV_NAME_LENGTH))
-            {
-            /* Found */
-            *vector = info->intNumber;
-            return;
-            }
-        }
-
-    }
-EXPORT_SYMBOL(vbiIntControllerFindVector);
diff --git a/arch/x86/kernel/vbiSyscalls.S b/arch/x86/kernel/vbiSyscalls.S
deleted file mode 100644
index d5f3f33..0000000
--- a/arch/x86/kernel/vbiSyscalls.S
+++ /dev/null
@@ -1,1201 +0,0 @@
-/* vbiSyscalls.s - hypervisor system calls */
-
-/*
- * Copyright (c) 2009 Wind River Systems, Inc.
- *
- * The right to copy, distribute, modify or otherwise make use
- * of this software may be licensed only pursuant to the terms
- * of an applicable Wind River license agreement.
- */
-
-/*
-modification history
---------------------
-01v,09sep09,mmi  add vbiVtlb stub
-01u,02sep09,mmi  rename vbiReceive to vbiReceiveOp
-01t,01sep09,mmi  update asm.h path
-01s,25aug09,mmi  remove bspIoctl
-01r,13aug09,dtr  Update to vbiHyIoctl.
-01q,06jul09,mmi  added vbi 2.0 vbMgmt api, interrupt redirect op,
-		 registers read/write, memory read/write, 
-01p,02jul09,mmi  add interrupt send syscall stub
-01o,27jun09,mmi  fix stack adjustment for vbiReply
-01n,23jun09,mmi  add vbi 2.0 API's
-01m,18jun09,mmi  changed vbiIntVCoreUnlock not expect a flag
-01l,12jun09,mmi  introduce vbiIntVCoreLock/Unlock APIs
-01k,26feb09,mmi  add name service hypercall
-01j,12feb09,mmi  update API descriptions, descriptions, fix vbiReply #arg pushed
-		 to the stack 
-01i,08feb09,mmi  fix vbiIntEnable/vbiIntDisable routines, remove vbiInt
-01h,23jan09,mmi  update vbiSend/vbiReceive and vbiReply comments
-01g,05dec08,mes  Replaced vbiShelf with vbiVbMgmt
-01f,02dec08,mmi  remove obsolete API's
-01e,20nov08,mmi  adopt vbi naming
-01d,04sep08,dcc  modified vdkInt() to call vdkIoapicIoctl()
-01c,19may08,gws  add vdkIoapicIoctl
-01b,18apr08,md   add extra arg to vdkHyIoctl
-01a,03mar08,md   written
-*/
-
-/*
-DESCRIPTION
-
-This file implements the hypervisor system call stubs for the Razor hypervisor.
-
-*/
-
-#define _ASMLANGUAGE
-
-#ifdef CONFIG_WRHV
-#include <vbi/support/sys/x86/regs.h>
-#include <vbi/support/sys/x86/asm.h>
-#include <vbi/syscall.h>
-#else
-#include <x86/regs.h>
-#include <asm.h>
-#include <vbi/syscall.h>
-#endif /* CONFIG_WRHV */
-
-	/* globals */
-	.globl vbiDebugShellStart
-	.globl vbiVbMemoryWrite
-	.globl vbiVbMemoryRead
-	.globl vbiIoapicOp
-	.globl vbiIoapicIoctl
-	.globl vbiHyIoctl
-	.globl vbiCtxctl
-	.globl vbiSend
-	.globl vbiReceiveOp
-	.globl vbiReply
-	.globl vbiTlbFlush
-	.globl vbiPanic
-	.globl vbiPs
-	.globl vbiKputs
-	.globl vbiKputc
-	.globl vbiIntVCoreUnlock
-	.globl vbiIntVCoreLock
-	.globl vbiVbMgmt
-	.globl vbiMemAttrSet
-	.globl vbiMemAttrGet
-	.globl vbiNsOp
-	.globl vbiVbReset
-	.globl vbiVbRestart
-	.globl vbiVbResume
-	.globl vbiVbSuspend
-	.globl vbiVcoreIntRed_op 
-	.globl vbiVbRegisterRead 
-	.globl vbiVbRegisterWrite 
-	.globl vbiVtlbOp 
-	.text
-	.balign 16
-
-#define VBI_STACK_FRAME_SIZE	4
-
-/*******************************************************************************
-*
-* vbiSend - Send a message to another context
-*
-* This routine makes a hypercall to send a message to the specified context and
-* waits for a reply.  The caller will block until the sender replies to the sent
-* message.
-*
-* SYNOPSIS
-*\cs
-*
-* vbiStatus_t vbiSend
-*    (
-*    vbiCtx_t     id,    /@ context id to send the message to @/
-*    void *       smsg,  /@ pointer to message to send        @/
-*    size_t       slen,  /@ length of message to send         @/
-*    void *       rmsg,  /@ pointer to receive message buffer @/
-*    size_t       rlen,  /@ length of receive message         @/
-*    VBI_MSG_INFO *info  /@ status info structure pointer     @/
-*    VBI_MSG_CTL  *ctl   /@ control data structure pointer    @/
-*    )
-*\ce
-*
-* RETURNS: OK or an error number in case of failure
-*
-* ERRNO: N/A
-*
-* SEE ALSO: vbiReceive(), vbiReply(), WRHV  messaging user's guide
-*/
-
-vbiSend:
-	movl    $VBI_SYS_send,%eax		/* system call number */
-	push	$7				/* number of arguments */
-	vmcall
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-	ret
-
-/*******************************************************************************
-*
-* vbiReceiveOp - Receive a message from another context
-*
-* This routine makes a hypercall and waits for a message to be received from
-* another context. It blocks until a message is received.
-*
-* SYNOPSIS
-*\cs
-*
-* vbiCtx_t vbiReceiveOp
-*    (
-*    void *       smsg,  /@ pointer to message to receive  @/
-*    size_t       len,   /@ length of message to receive   @/
-*    VBI_MSG_INFO *info  /@ status info structure pointer  @/
-*    VBI_MSG_CTL  *ctl   /@ control data structure pointer @/
-*    )
-*\ce
-*
-* RETURNS: sender context Id or an error number in case of failure
-*
-* ERRNO: N/A
-*
-* SEE ALSO: vbiSend(), vbiReply(), WRHV  messaging user's guide
-*/
-
-vbiReceiveOp:
-	movl    $VBI_SYS_receive,%eax		/* system call number */
-	push	$4				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-/*******************************************************************************
-*
-* vbiReply - Reply to message received from another context
-*
-* This routine makes a hypercall in order to reply to a message received from
-* another context. A message is received from remote context by calling
-* vbiReceive(). The reply will unblock the recipient which may preempt
-* the caller.
-*
-* SYNOPSIS
-*\cs
-*
-* vbiStatus_t vbiReply
-*    (
-*    vbiCtx_t   id,    /@ context id to reply the message to @/
-*    void *       buff,  /@ pointer to reply message  @/
-*    size_t       len,   /@ length of message to reply   @/
-*    VBI_MSG_CTL  *ctl   /@ control data structure pointer @/
-*    )
-*\ce
-*
-* RETURNS: OK or an error number in case of failure
-*
-* ERRNO: N/A
-*
-* SEE ALSO: vbiSend(), vbiReceive(), WRHV  messaging user's guide
-*/
-
-vbiReply:
-	movl    $VBI_SYS_reply,%eax		/* system call number */
-	push	$4				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-
-/******************************************************************************
-*
-* vbiKputs - print a string on the kernel console
-*
-* This system call sends the specified string to the system console.
-*
-* C interface:
-*
-*   vbiKputs (char *s)		/@ pointer to string			@/
-*
-* Returns: OK or ERROR
-*
-*/
-
-vbiKputs:
-	movl    $VBI_SYS_kputs,%eax		/* system call number */
-	push	$1				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-
-/******************************************************************************
-*
-* vbiKputc - print a character on the kernel console
-*
-* This system call sends the specified character to the system console.
-*
-* C interface:
-*
-*   vbiKputc (char c)		/@ character to print			@/
-*
-* Returns: OK or ERROR
-*
-*/
-
-vbiKputc:
-	movl    $VBI_SYS_kputc,%eax		/* system call number */
-	push	$1				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-
-/******************************************************************************
-*
-* vbiPanic - panic the system and halt all activity
-*
-* This system call causes the hypervisor to enter a panic state and display
-* various pieces of information on the system console.  The hypervisor
-* then enters an idle state and stops all CPU processing.
-*
-* C interface:
-*
-*   vbiPanic (char *msg)	/@ message string to print on console	@/
-*
-* Returns: does not return
-*
-*/
-
-vbiPanic:
-	movl    $VBI_SYS_panic,%eax		/* system call number */
-	push	$1				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-
-/******************************************************************************
-*
-* vbiPs - display the list of contexts on the console
-*
-* This system call sends a "ps" like output of the hypervisor contexts to
-* the system console.
-*
-* C interface:
-*
-*   vbiPs (void)
-*
-* Returns: OK or ERROR
-*
-*/
-
-vbiPs:
-	movl    $VBI_SYS_ps,%eax		/* system call number */
-	push	$0				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-
-/******************************************************************************
-*
-* vbiIntVCoreUnlock - Re-enable interrupts in the virtual board
-*
-* This call re-enables interrupts in the virtual board, and calls
-* Razor if interrupts are pending.  The value level is the value returned
-* by the corresponding 	
-*
-* C interface:
-*
-*   vbiIntVCoreUnlock (void)
-*
-* Returns: does not return
-*
-*/
-
-vbiIntVCoreUnlock:
-	sti				/* UNLOCK INTERRUPTS */
-	ret
-
-/******************************************************************************
-*
-* vbiIntVCoreLock - Disable interrupts in the virtual core
-*
-* This call disables interrupts in the virtual board.
-*
-* C interface:
-*
-*   int vbiIntVCoreLock (void)
-*
-* Returns: the old value of the interrupt disable 
-*
-*/
-
-vbiIntVCoreLock:
-    pushf				/* push EFLAGS on stack */
-    popl	%eax			/* get EFLAGS in EAX */
-    andl	$EFLAGS_IF,%eax		/* mask it with IF bit */
-    cli				/* LOCK INTERRUPTS */
-    ret
-
-/******************************************************************************
-*
-* vbiVbMgmt - virtual board management
-* 
-* This routine executes the specified command on a given virtual board. The
-* possible commands are:
-* 
-* VBI_VBMGMT_ATTACH 
-* Attach the requesting Virtual Board to the VB management agent for
-* operations on the specified VB.
-*
-* VBI_VBMGMT_DETACH
-* Detatch the requesting Virtual Board from the VB management agent for
-* operations on the specified VB.
-*
-* VBI_VBMGMT_SUSPEND
-* Suspends target Virtual Board from operation.  Fails if Virtual Board
-* has already been suspended
-*
-* VBI_VBMGMT_RESET
-* Resume a target virtual board.  Fails if a Virtual Board has not been
-* suspended. Currently no options are supported
-*
-* VBI_VBMGMT_RESUME
-* Restarts a target Virtual Board which has Preload=0 set in the xml file.
-* Fails if Virtual Board is preloaded (Preload=1)
-*
-*
-* The fourth argument to this routine specifies an flag that must be defined
-* when executing VBI_VBMGMT_RESUME operation. Otherwise the command fails.
-* The possible flgas are:
-*   VBI_VTLB_OP_UPDATE_PMD	
-*   VBI_VTLB_OP_UPDATE_PTE	
-*   VBI_VTLB_OP_DELETE_PMD	
-*   VBI_VTLB_OP_SET_PTE_AT	
-*   VBI_VTLB_OP_SET_PTE	
-*   VBI_VTLB_OP_FLUSH_OPS	
-*   VBI_VTLB_OP_INIT	
-*
-* int32_t vbiVbMgmt 
-*    (
-*    uint32_t	cmd,	    /@ attach, detach, suspend, reset or resume @/
-*    uint32_t	handle,    /@ the operation target board handle @/
-*    int32_t	*outError,  /@ where to set error : OK or error flag @/ 
-*    uint32_t	flags,	    /@ options required by the cmd executed @/
-*    void *ctl		    /@ memory / registers data		    @/ 
-*    )
-*
-* RETURNS: OK or error in case of failure
-*/
-
-vbiVbMgmt:
-	movl    $VBI_SYS_vbMgmt,%eax		/* system call number */
-	push	$5				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-/*******************************************************************************
-*
-* vbiVbSuspend - Suspend a virtual board's core
-*
-* This routine makes a hypercall in order to suspend one or more cores that
-* exist within the specified virtual board. The target core(s) enter HALT state
-* until vbiVbResume() is called change the state of the core(s). This function
-* will return only after all victim cores are suspended unless the opration
-* fails to complete. The second argument passed to this function specifies one
-* or more target cores. For suspending every core within the specified VB the
-* second argument must be set to VBI_VB_CORES_ALL. This implies that the core
-* requesting the suspension may also be included in the list to be suspended.
-* To suspend everyone but the recipient then the second argument passed to this
-* function should be set to VBI_VB_CORES_OTHERS. Otherwise the second argument
-* should be a valid core number within the VB. This hypercall sends a message
-* to a given hypervisor manager that provides virtual board managment service.
-*
-* SYNOPSIS
-*\cs
-*
-*
-* vbiStatus_t vbiVbSuspend
-*    (
-*    vbiVb_t      id,    /@ Id of the VB to suspend     @/
-*    vbiCore_t     core   /@ Core within the VB         @/
-*    )
-*\ce
-*
-* RETURNS: OK or an error number in case of failure
-*
-* ERRNO:
-*
-* SEE ALSO: vbiVbResume(), vbiVbReset(), vbiVbRestart()
-*/
-
-vbiVbSuspend:
-	movl    $VBI_SYS_vbSuspend,%eax		/* system call number */
-	push	$2				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-/*******************************************************************************
-*
-* vbiVbReset - Reset a virtual board's core
-*
-* This routine makes a hypercall in order to reset one or more cores that exist
-* within the specified virtual board. Calling this function puts the target core(s)
-* program counter to it's ENTRY function. The ENTRY function is determined based on
-* the loaded binary image. A core does not execute beyond it's ENTRY function
-* unless vbiVbRestart() is explitly called. Except for core0 within the target VB
-* where VBI_VBMGMT_RESET_AND_START_CORE0 option is set in the flag passed as
-* the third argument to this routine.
-* The hypercall sends a message to a manager that provides VB managment services.
-* This function will return only after all victim cores are reset unless the
-* operation fails to complete. The order of which the victim cores are reset is not
-* determined. The second argument identifies the cores to perform the operation on.
-* The value of the second argument should be set to one of the following:
-*
-*\ms
-*\m -
-* VBI_VB_CORES_ALL: Reset all cores in the specified virtual board
-*\m -
-* VBI_VB_CORES_OTHERS: Exclude the recipient if it belongs to the victim VB
-*\m -
-* A valid core number: Reset the specified core that exist within the Virtual Board.
-*\me
-*
-* The third argument argument passed to this function specifies options that are
-* applicable only when the second argument is VBI_VB_CORES_ALL. The options may be
-* one of the following or a combination:
-*
-*\ms
-*\m -
-* VBI_VBMGMT_RESET_DOWNLOAD: Reset the cores and reload the executable images
-*\m -
-* VBI_VBMGMT_RESET_AND_START_CORE0: Reset and start core0 within the VB
-*\me
-*
-*
-* IMPORTANT:
-* If a user chooses to restart core without reloading the executable image then
-* the data section must be restored to prevent critical errors. It is the guest OS's
-* responsibility to clear the bss data sections in such scenario.
-*
-* SYNOPSIS
-*\cs
-*
-* vbiStatus_t vbiVbReset
-*    (
-*    vbiVb_t      id,       /@ Id of the VB to suspend      @/
-*    vbiCore_t     core,            /@ Core within the VB           @/
-*    uint32_t     options   /@ reload , start options       @/
-*    )
-*\ce
-*
-* RETURNS: OK or an error number in case of failure
-*
-* ERRNO:
-*
-* SEE ALSO: vbiVbResume(), vbiVbSuspend(), vbiVbRestart()
-*/
-
-vbiVbReset:
-        movl    $VBI_SYS_vbReset,%eax            /* system call number */
-        push    $3                              /* number of arguments */
-
-        vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-        ret
-
-/*******************************************************************************
-*
-* vbiVbRestart - Restart a virtual board's core
-*
-* This routine makes a hypercall in order to restart a virtual cores from reset.
-* It's called to start running a core or cores that were previously reset by
-* calling vbiVbReset(). The target core(s) start(s) executing from the ENTRY
-* function retrieved from the corresponding binary image.
-* This function will return only after  all cores are out of reset unless the
-* operation fails to complete.  The second argument represents the cores to restart.
-* For restarting every core in reset mode within the specified VB the second
-* argument is set to VBI_VB_CORES_ALL. To restart a specific core within the
-* VB then the core number must be passed in the second argument.
-*
-* This hypercall sends a message to a manager that provides VB managment
-* services.
-*
-* SYNOPSIS
-*\cs
-*
-* vbiStatus_t vbiVbRestart
-*    (
-*    vbiVb_t      id,    /@ Id of the VB to suspend     @/
-*    vbiCore_t     core   /@ Core within the VB         @/
-*    )
-*\ce
-*
-* RETURNS: OK or an error number in case of failure
-*
-* ERRNO:
-*
-* SEE ALSO: vbiVbResume(), vbiVbSuspend(), vbiVbReset()
-*/
-
-vbiVbRestart:
-        movl    $VBI_SYS_vbRestart,%eax            /* system call number */
-        push    $3                              /* number of arguments */
-
-        vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-        ret
-
-/*******************************************************************************
-*
-* vbiVbResume - Resume a virtual board's core
-*
-* This routine makes a hypercall in order to resume one or cores within
-* the specified virtual board. It reactivates a cores or cores that were
-* previously suspended by calling vbiVbResume(). This function will return only
-* after all victim cores are resumed unless the operation fails. The order of
-* which the cores are resumed is not determined. The second argument may a
-* magic number instead of a valid core number to indicate that the operation
-* is intended for more than one core. For resuming every core within the
-* specified VB then the second argument is set to be equal to VBI_VB_RESUME_ALL.
-* This implies to resume every core within the specified VB. Using this option
-* when some of the cores within the VB are already running is not considered
-* as programming error.
-*
-* SYNOPSIS
-*\cs
-*
-* vbiStatus_t vbiVbResume
-*    (
-*    vbiVb_t      id,    /@ Id of the VB to suspend     @/
-*    vbiCore_t     core   /@ Core within the VB         @/
-*    )
-*\ce
-*
-* RETURNS: OK or an error number in case of failure
-*
-* ERRNO:
-*
-* SEE ALSO: vbiVbResume(), vbiVbSuspend()
-*/
-
-vbiVbResume:
-        movl    $VBI_SYS_vbResume,%eax            /* system call number	*/
-        push    $2                              /* number of arguments	*/
-
-        vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-        ret
-
-/******************************************************************************
-*
-* vbiHyIoctl - hypervisor ioctl call
-*
-* This system call interfaces to the general purpose hypervisor ioctl
-* function.
-*
-* Possible ioctl commands:
-*     VBI_HYIOCTL_GETPID
-*     VBI_HYIOCTL_GETPRIORITY
-*     VBI_HYIOCTL_GETSTATS
-*     VBI_HYIOCTL_PADDR
-*		
-* C interface:
-*
-*   vbiHyIoctl (unsigned int ioctl, /@ the ioctl command      @/
-*               void *arg1,         /@ address of information @/
-*               void *arg2,         /@ address of information @/
-*               void *arg3,         /@ address of information @/
-*               void *arg4)         /@ address of information @/
-*
-* Returns: ioctl specific value
-*
-*/
-
-vbiHyIoctl:
-	movl    $VBI_SYS_hyIoctl,%eax		/* system call number */
-	push	$5				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-/******************************************************************************
-*
-* vbiIoapicIoctl - virtual IO APIC ioctl call
-*
-* This system call interfaces to the virtual IO APIC ioctl
-* function.
-*
-* Possible ioctl commands:
-*     VBI_IOAPICIOCTL_UNMASK
-*     VBI_IOAPICIOCTL_SEND
-*     VBI_IOAPICIOCTL_MASK
-*		
-* C interface:
-*
-*   vbiIoapicIoctl (unsigned int ioctl, /@ the ioctl command      @/
-*                   unsigned arg1,      /@ address of information @/
-*                   unsigned arg2)      /@ address of information @/
-*
-* Returns: ioctl specific value
-*
-*/
-
-vbiIoapicIoctl:
-	movl    $VBI_SYS_vIoapicIoctl,%eax	/* system call number */
-	push	$3				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-/******************************************************************************
-*
-* vbiIoapicOp - virtual IO APIC ioctl call
-*
-* This system call interfaces to the virtual IO APIC.
-*
-* function.
-*
-* Possible commands:
-*     VBI_IOAPICIOCTL_UNMASK
-*     VBI_IOAPICIOCTL_SEND
-*     VBI_IOAPICIOCTL_MASK
-*
-* C interface:
-*
-*   vbiIoapicOp	    (uint32_t cmd,      /@ the operation command     @/
-*                   vbiIrq_t irq,       /@ irq number                @/
-*                   uint32_t filter,    /@ filter                    @/
-*                   vbiVb_t  vbId,      /@ target vb id              @/
-*
-* Returns: ioctl specific value
-*
-*/
-
-vbiIoapicOp:
-	movl    $VBI_SYS_vIoapicIoctl,%eax	/* system call number */
-	push	$4				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-
-/******************************************************************************
-*
-* vbiCtxctl - hypervisor context control call
-*
-* This system call interfaces to the general purpose hypervisor context
-* control function.
-*
-* Possbile operations:
-*	VBI_CTXCTL_IDLE /@ Make this virtual board go idle @/
-*
-* C interface:
-*
-*   vbiHyCtxctl (unsigned int operation, /@ context operation   @/
-*		 void *arg)		 /@ address of argument @/
-*
-* Returns: ioctl specific value
-*
-*/
-
-vbiCtxctl:
-	movl    $VBI_SYS_ctxctl,%eax		/* system call number */
-	push	$2				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-/*******************************************************************************
-*
-* vbiMemAttrSet - Set protection for a page of memory
-*
-* This routine makes a hypercall to set the MMU attribures for the specified
-* memory range. The possible attributes one or a combinarion of the following:
-* 
-* VBI_MMU_PROT_READ -  allow supervisor and user read
-* VBI_MMU_PROT_WRITE -  Allow supervisor and user write
-* VBI_MMU_PROT_EXECUTE - allow supervisor and user execute
-*
-* SYNOPSIS
-*\cs
-* 
-* vbiStatus_t vbiMemAttrSet 
-*		(
-*		void	 *gaddr,	/@ Address of page to change attr   @/
-*		size_t   length,	/@ length of address		    @/
-*		uint32_t attr		/@ mmu attributes to set	    @/
-*		)
-*\ce
-*
-* RETURNS: OK or error number in case of failure
-*
-* ERROR CODES: N/A
-*
-*/
-
-vbiMmuAttrSet:
-	movl    $VBI_SYS_mmu_attr_set,%eax	/* system call number */
-	push	$3				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-/******************************************************************************
-*
-* vbiMemAttrGet - Get MMU page protections
-*
-* This routine makes a hypercall to retrieve the MMU attributes associated for
-* the page where the specified address is mapped. This is not the VMMU
-* attributes. A guest OS has direct access to the mapping table of its VMMU
-* therefore a hypercall is not necessary.
-*
-* SYNOPSIS
-*\cs
-* 
-* vbiStatus_t vbiMemAttrGet 
-*		(
-*		void	 *gaddr		/@ Address of page to change attr   @/
-*		uint32_t *attr		/@ OUT - returned mmu attributes    @/
-*		)
-*\ce
-*
-* RETURNS: OK or error number in case of failure
-*
-* ERROR CODES: N/A
-*
-*/
-
-vbiMmuAttrGet:
-	movl    $VBI_SYS_mmu_attr_get,%eax	/* system call number */
-	push	$1				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-
-/******************************************************************************
-*
-* vbiNsOp - virtua board name service call
-*
-* This system call interfaces to the virtual board
-*
-* commands:
-*	VBI_VBI_NS_REGISTER	   /@ register service	 @/
-*	VBI_VBI_NS_UNREGISTER	   /@ unregister service @/
-*	VBI_VBI_NS_LOOKUP	   /@ lookup service	 @/
-*				
-* C interface:
-*
-*   vbiNsOp ( uint32_t cmd,	    /@ the BSP ioctl command	@/
-*	    char * name,		    /@ the service name		@/
-*	    uint32_t revision,	    /@ service revision		@/
-*	    VBI_HANDLE *handle,	    /@ service handle pointer	@/
-*	  )
-*
-* Returns: OK or ERROR in case of failure
-*
-*/
-
-vbiNsOp:
-	movl    $VBI_SYS_ns_op, %eax		/* system call number */
-	push	$4				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-/*******************************************************************************
-*
-* vbiVbMemoryWrite - copy data to a remote board's memory
-*
-* This routine makes a hypercall to copy to a remote board memory. If the
-* VBI_DCACHE_FLUSH is set in the control memory control structure then this
-* routine flushes the data caches lines corresponding to the range of memory
-* specified. If VBI_ICACHE_INV then this routine ensure that the instruction
-* cache lines corresponding to the range of address is invalidated after the
-* memory is copied. Invalidating the instruction is required if data containing
-* is updated since the instruction cache is not aware of the content in data
-* cache. Therefore flushing the data cache ensures that memory contains the
-* updated data and invalidating the instruction cache ensures that the stale
-* values in the instruction cache is thrown away. 
-* The sizeIn parameter specifies the number of bytes desired to be copied. 
-* The sizeOut parameter indicates the number of bytes successfully copied.
-* A user may set the sizeOut parameter to zero if the output size is not of
-* interest otherwise to a value different than zero.
-* 
-* 
-* struct vbiMemCtl
-*   {
-*   void	*pBuffer;	    /@ address of target context	@/
-*   void	*pAddress;	    /@ address of calling context	@/
-*   size_t	sizeIn;		    /@ IN: number bytes requested	@/
-*   size_t	sizeOut;	    /@ OUT: number of total bytes read	@/
-*   uint32_t	flags;		    /@ data/instruction flush option	@/
-*    } VBI_MEM_CTL;
-*
-* SYNOPSIS
-*\cs
-* 
-* vbiStatus_t vbiVbMemoryWrite 
-*	(
-*	VBI_MEM_CTL	*memCtl, 
-*	vbiVb_t		targetBoard 
-*	)
-*
-*\ce
-*
-* RETURNS: returns OK or error number in case of failure
-*
-* ERROR CODES: N/A
-*
-* SEE ALSO: 
-*/
-
-vbiVbMemoryWrite:
-	movl    $VBI_SYS_memWrite_op, %eax	/* system call number */
-	push	$2				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-/*******************************************************************************
-*
-* vbiVbMemoryRead - Read a virtual board's memory
-*
-* This routine makes a hypercall to read a remote board's memory. The memory control
-* structure contains information about the target memory to read and the destination
-* buffer that hypervisor must populate with the data read. This routine is used
-* to copy data from a remote VB. It is the user's responsability to ensure that
-* the memory read is accessed orthogonally.
-* The sizeIn parameter specifies the number of bytes desired to be copied. 
-* The sizeOut parameter indicates the number of bytes successfully copied.
-* A user may set the sizeOut parameter to zero if the output size is not of
-* interest otherwise to a value different than zero.
-*
-* struct vbiMemCtl
-*   {
-*   void	*pBuffer;	    /@ address of target context	    @/
-*   void	*pAddress;	    /@ address of calling context	    @/
-*   size_t	sizeIn;		    /@ number of bytes to be read	    @/
-*   size_t	sizeOut;	    /@ number of bytes successfully read    @/
-*   uint32_t	reserved;	    /@ reserved for future use		    @/
-*    } VBI_MEM_CTL;
-*
-* SYNOPSIS
-*\cs
-* 
-* vbiStatus_t vbiVbMemoryRead 
-*	(
-*	VBI_MEM_CTL *memCtl,	    /@ control structure for INPUT and OUTPUT	@/
-*	vbiVb_t	    targetBoard	    /@ target board				@/
-*	)
-*
-*\ce
-*
-* RETURNS: returns OK or an error number in case of failure
-*
-* ERROR CODES: N/A
-*
-* SEE ALSO: 
-*/
-
-vbiVbMemoryRead:
-	movl    $VBI_SYS_memRead_op, %eax	/* system call number */
-	push	$2				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-/*******************************************************************************
-*
-* vbiDebugShellStart - start the hypervisor debug shell
-*
-* This routine sends a message to the hypervisor debug shell manager in order to
-* start the WRHV shell program. The shell program spins therefore does not share
-* the processor with any other WRHV context. By default a caller of this routine
-* is detached to allow the caling core to continue executing (as long as the are not
-* scheduled to run on the same processor). An optional flag VBI_SHELL_ATTACH can be
-* specified to force the caller virtual board core to block while the shell program
-* is running.
-*
-* SYNOPSIS
-*\cs
-*
-* void vbiDebugShellStart
-*          (
-*          uint32_t  flags /@ detach by default @/
-*          )
-*
-*\ce
-*
-* RETURNS: N/A
-*
-*
-* SEE ALSO: 
-*/
-
-vbiDebugShellStart:
-
-	movl    $VBI_SYS_dbgShStart, %eax	/* system call number */
-	push	$1				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-
-/*******************************************************************************
-*
-* vbiVbRegisterRead - Read a remote core's registers
-*
-* This routine makes a hypercall to read a remote core's registers. The register
-* control structure contains information about the registers to read and the
-* destination buffers to store them.
-* 
-* SYNOPSIS
-* VBI X86 Architecture Supplements
-*\cs
-* vbiStatus_t vbiVbRegisterRead 
-*	(
-*	VB_ARCH_CONTROL_REGS	*regCtl,    /@ Registers read - OUT	    @/
-*	vbiVb_t	    targetBoard,	    /@ target VB		    @/ 
-*	vbiCore_t   core		    /@ core within the target VB    @/
-*	)
-*\sh VB_ARCH_CONTROL_REGS definition
-*
-*The control registers type used for vbiVbRegister[Read:write] API's
-*
-*typedef struct vbArchControlRegs /@ REG_SET - x86 register set	@/
-*    {
-*    uint32_t  edi;		/@ 00: general register		@/
-*    uint32_t  esi;		/@ 04: general register		@/
-*    uint32_t  ebp;		/@ 08: frame pointer register	@/
-*    uint32_t  esp;		/@ 0C: stack pointer register	@/
-*    uint32_t  ebx;		/@ 10: general register		@/
-*    uint32_t  edx;		/@ 14: general register		@/
-*    uint32_t  ecx;		/@ 18: general register		@/
-*    uint32_t  eax;		/@ 1C: general register		@/
-*    uint32_t  eflags;		/@ 20: status register		@/
-*    INSTR *pc;			/@ 24: program counter		@/
-*    uint32_t  cr0;		/@ 28: control register 0	@/
-*    uint32_t  cr2;		/@ 2C: control register 2	@/
-*    uint32_t  cr3;		/@ 30: control register 3	@/
-*    uint32_t  cr4;		/@ 34: control register 4	@/
-*    uint32_t  cs;		/@ 28: code segment		@/
-*    uint32_t  ds;		/@ 3C: data segment		@/
-*    uint32_t  ss;		/@ 40: stack segment		@/
-*    uint32_t  es;		/@ 44: E segment		@/
-*    uint32_t  fs;		/@ 48: F segment		@/
-*    uint32_t  gs;		/@ 4C: G segment		@/
-*    uint32_t  tsp;		/@ 50: transition stack pointer	@/
-*    } VB_ARCH_CONTROL_REGS;
-*\ce
-*
-* RETURNS: returns OK or error number in case of failure
-*
-* ERROR CODES:
-*
-* SEE ALSO: 
-*/
-
-vbiVbRegisterRead:
-
-	movl    $VBI_SYS_RegsRead_op, %eax	/* system call number */
-	push	$3				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-/*******************************************************************************
-*
-* vbiVbRegisterWrite - write to a remote core's registers
-*
-* This routine makes a hypercall to write to a remote core's registers. The
-* register control structure contains the set of registers to write. 
-* The user must ensure to read first the destination core's registers using
-* vbiVbRegisterRead() then write back the modified set of registers in the 
-* registers control structure.
-* 
-* VBI X86 Architecture Supplements
-*
-* SYNOPSIS
-*\cs
-* vbiStatus_t vbiVbRegisterWrite
-*	(
-*	VB_ARCH_CONTROL_REGS	*regCtl,	/@ registers to write - IN	 @/
-*	vbiVb_t			targetBoard,	/@ The target board		 @/
-*	vbiCore_t		core		/@ The target core within the VB @/
-*	)
-*
-*\sh VB_ARCH_CONTROL_REGS definition
-*
-*The control registers type used for vbiVbRegister[Read:write] API's
-*
-*typedef struct vbArchControlRegs /@ REG_SET - x86 register set	@/
-*    {
-*    uint32_t  edi;		/@ 00: general register		@/
-*    uint32_t  esi;		/@ 04: general register		@/
-*    uint32_t  ebp;		/@ 08: frame pointer register	@/
-*    uint32_t  esp;		/@ 0C: stack pointer register	@/
-*    uint32_t  ebx;		/@ 10: general register		@/
-*    uint32_t  edx;		/@ 14: general register		@/
-*    uint32_t  ecx;		/@ 18: general register		@/
-*    uint32_t  eax;		/@ 1C: general register		@/
-*    uint32_t  eflags;		/@ 20: status register		@/
-*    INSTR *pc;			/@ 24: program counter		@/
-*    uint32_t  cr0;		/@ 28: control register 0	@/
-*    uint32_t  cr2;		/@ 2C: control register 2	@/
-*    uint32_t  cr3;		/@ 30: control register 3	@/
-*    uint32_t  cr4;		/@ 34: control register 4	@/
-*    uint32_t  cs;		/@ 28: code segment		@/
-*    uint32_t  ds;		/@ 3C: data segment		@/
-*    uint32_t  ss;		/@ 40: stack segment		@/
-*    uint32_t  es;		/@ 44: E segment		@/
-*    uint32_t  fs;		/@ 48: F segment		@/
-*    uint32_t  gs;		/@ 4C: G segment		@/
-*    uint32_t  tsp;		/@ 50: transition stack pointer	@/
-*    } VB_ARCH_CONTROL_REGS;
-*
-*\ce
-*
-* RETURNS: returns OK or error number in case of failure
-*
-* ERROR CODES: 
-*
-* SEE ALSO: 
-*/
-
-vbiVbRegisterWrite:
-	movl    $VBI_SYS_RegsWrite_op, %eax	/* system call number */
-	push	$3				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-/*******************************************************************************
-*
-* vbiVcoreIntRed_op - redirect an irq to another vcore
-*
-* SYNOPSIS
-*\cs
-* vbiStatus_t vbiVcoreIntRed_op 
-*	(
-*	vbiIrq_t		irq,	/@ irq number to redirect	 @/
-*	vbiCore_t		core	/@ destination vcore		 @/
-*	)
-*
-* RETURNS: returns OK or error number in case of failure
-*
-* ERROR CODES: 
-*
-* SEE ALSO: vbiVioapicIntRedirect()
-* 
-*\NOMANUAL
-*/
-vbiVcoreIntRed_op:
-
-	movl    $VBI_SYS_intRedirect, %eax	/* system call number */
-	push	$2				/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp			/* adjust stack */
-
-	ret
-
-/******************************************************************************
-*
-* vbiVtlbOp - execute a specified VTLB operation
-*
-* This system call executes the specified VTLB operation. The possible VTLB
-* operations are:
-*
-*   VBI_VTLB_OP_UPDATE_PMD	
-*   VBI_VTLB_OP_UPDATE_PTE	
-*   VBI_VTLB_OP_DELETE_PMD	
-*   VBI_VTLB_OP_SET_PTE_AT	
-*   VBI_VTLB_OP_SET_PTE	
-*   VBI_VTLB_OP_FLUSH_OPS	
-*   VBI_VTLB_OP_INIT	
-*
-* SYNOPSIS
-*\cs
-* vbiStatus_t vbiVtlbOp (
-*            unsigned int op,          /@ VTLB operation @/
-*            unsigned long arg1,       /@ VTLB operation argument 1 @/
-*            unsigned long arg2,       /@ VTLB operation argument 2 @/
-*            unsigned long arg3        /@ VTLB operation argument 3 @/
-*            )
-*\ce
-*
-* Returns: OK or ERROR if the VTLB operation has failed
-*/
-
-vbiVtlbOp:
-	movl    $VBI_SYS_vtlb_op, %eax	/* system call number */
-	pushl   $4			/* number of arguments */
-
-	vmcall
-
-	addl	$VBI_STACK_FRAME_SIZE, %esp	/* adjust stack */
-
-	ret
diff --git a/arch/x86/kernel/wrhv.c b/arch/x86/kernel/wrhv.c
deleted file mode 100644
index 03b82cc..0000000
--- a/arch/x86/kernel/wrhv.c
+++ /dev/null
@@ -1,1335 +0,0 @@
-/*
- *  This program is free software; you can redistribute it and/or modify it
- *  under the terms of the GNU General Public License as published by the
- *  Free Software Foundation; either version 2, or (at your option) any
- *  later version.
- *
- *  This program is distributed in the hope that it will be useful, but
- *  WITHOUT ANY WARRANTY; without even the implied warranty of
- *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- *  General Public License for more details.
- *
- *  Copyright (C) 2009 Wind River Systems, Inc.
- */
-
-
-#include <linux/module.h>
-#include <linux/init.h>
-#include <linux/kthread.h>
-#include <linux/irq.h>
-#include <linux/screen_info.h>
-#include <linux/pci.h>
-#include <linux/kernel_stat.h>
-#include <linux/wrhv.h>
-#include <linux/kgdb.h>
-#include <vbi/vbi.h>
-
-#include <asm/setup.h>
-#include <asm/paravirt.h>
-#include <asm/processor.h>
-#include <asm/i8253.h>
-#include <asm/wrhv.h>
-#include <asm/fixmap.h>
-#include <asm/pgtable.h>
-#include <asm/arch_hooks.h>
-#include <asm/tlbflush.h>
-#include "do_timer.h"
-#include <asm/trampoline.h>
-#include <linux/percpu.h>
-#include <linux/smp.h>
-#include <asm/cpu.h>
-#include <asm/reboot.h>		/* for struct machine_ops */
-
-
-//#define WRHV_DEBUG_MSR	1
-#define WRHV_USE_XMLCONFIG	1
-#define WRHV_POLL_IRQ		7
-
-/* Copied over during early bootstrap */
-VB_CONFIG __wrhvConfig = { .pid = -1 };
-VB_CONFIG *_wrhvConfig; /* Pointer passed from hypervisor */
-VB_CONFIG *wrhvConfig = &__wrhvConfig;
-VB_STATUS *wrhvStatus;
-VB_CONTROL *wrhvControl;
-
-#ifdef CONFIG_PCI
-extern struct pci_ops pci_root_ops;
-extern int (*pcibios_enable_irq)(struct pci_dev *dev);
-extern void (*pcibios_disable_irq)(struct pci_dev *dev);
-#endif
-
-static unsigned long cr3_val[NR_CPUS];
-static VBI_VTLB_CONTROL	vtlb_ctrl[NR_CPUS];
-static unsigned long is_cr3_cache_enabled[NR_CPUS];
-static unsigned long is_vtlb_optim_enabled[NR_CPUS];
-static unsigned long is_vtlb_ops_cache_enabled[NR_CPUS];
-
-#ifdef	CONFIG_SMP
-#define	VTLB_GET_CPU_VAR(var)	var[smp_processor_id()]
-#else
-#define	VTLB_GET_CPU_VAR(var)	var[0]
-#endif
-
-static cpumask_t flush_cpumask;
-static struct mm_struct *flush_mm;
-static unsigned long flush_va;
-static DEFINE_SPINLOCK(tlbstate_lock);
-static DEFINE_SPINLOCK(vioapic_lock);
-
-#define VBI_VTLB_OPTIM_OPTION (\
-			 VBI_VTLB_OPTIM_ENABLED |  \
-			 VBI_VTLB_CR3_CACHE_ENABLED |  \
-			 VBI_VTLB_OPS_CACHE_ENABLED |  \
-			 VBI_VTLB_DIRTY_BIT_SUPPORT_ENABLED)
-
-static void wrhv_vtlb_op (unsigned int op, unsigned long arg1,
-				unsigned long arg2, unsigned long arg3);
-
-static void wrhv_pre_intr_init_hook(void)
-{
-	int i;
-
-	for (i = 0; i < NR_IRQS; i++) {
-		irq_desc[i].status = IRQ_DISABLED;
-		irq_desc[i].action = NULL;
-		irq_desc[i].depth = 1;
-		set_irq_chip_and_handler_name(i, &wrhv_irq_chip, handle_fasteoi_irq, "fasteoi");
-	}
-}
-
-void __init wrhv_init_IRQ(void)
-{
-	int i;
-
-	/* This maps in hypervisor config/status/control space.
-	   It has to be carefully crafted to be an identity mapping.  We ask
-	   for this space to be supplied to us from the hypervisor at
-	   address 0xffff0000 in the virtual board xml, and we essentially
-	   setup FIX_WRHV_END to be 16, representing 16 4K pages from the
-	   end of address space.  This gives us the address 0xffff0000 in Linux
-	   which we need for a virt=phys aka identity mapping.  Why do we
-	   need this to be identity mapped?  Because this block of memory
-	   space is supplied by the hypervisor outside of Linux control, and
-	   it contains pointers to places within itself.  We really don't want
-	   to have to hunt down and modify all those pointers at run time to
-	   be a different (virtual) address.
-	*/
-	   
-	for (i=0; i<(FIX_WRHV_END - FIX_WRHV_START); i++) {
-		__set_fixmap(FIX_WRHV_END - i,
-			 (unsigned long)_wrhvConfig+(i*PAGE_SIZE), PAGE_KERNEL);
-	}
-
-	/* We no longer need to use the vbconfig copy, map it straight in */
-	wrhvConfig = (VB_CONFIG *)fix_to_virt(FIX_WRHV_END);
-		
-	/* Setup the global variables used by the vbi */
-	vbiInit(wrhvConfig);
-
-	wrhv_pre_intr_init_hook();
-
-	for (i = 0; i < (NR_VECTORS - FIRST_EXTERNAL_VECTOR); i++) {
-		int vector = FIRST_EXTERNAL_VECTOR + i;
-		if (i >= NR_IRQS)
-			break;
-		if (vector != SYSCALL_VECTOR)
-			set_intr_gate(vector, interrupt[i]);
-	}
-
-	irq_ctx_init(smp_processor_id());
-
-	/* race during reboot might have left a timer interrupt
-	 * pending and unacked */
-	/*
-	irq_desc[0].chip->ack(0);
-	*/
-}
-
-static void wrhv_init_timer(enum clock_event_mode mode,
-				struct clock_event_device *evt)
-{
-}
-
-static int wrhv_set_next_event(unsigned long delta,
-			    struct clock_event_device *evt)
-{
-	return 0;
-}
-
-static inline void wrhv_send_ipi(int, int);
-static void wrhv_timer_broadcast(cpumask_t mask)
-{
-	int cpu;
-	cpus_and(mask, mask, cpu_online_map);
-
-	for_each_cpu_mask_nr(cpu, mask)
-		wrhv_send_ipi(DUMMY_TIMER_INT, cpu);
-
-}
-
-struct clock_event_device wrhv_clock_event = {
-	.name		= "wrhv",
-	.features	= CLOCK_EVT_FEAT_PERIODIC,
-	.set_mode	= wrhv_init_timer,
-	.set_next_event = wrhv_set_next_event,
-	.broadcast	= wrhv_timer_broadcast,
-	.shift		= 32,
-	.mult		= 1,
-	.irq		= 0,
-};
-
-DEFINE_PER_CPU(struct clock_event_device, wrhv_clock_events);
-
-irqreturn_t wrhv_dummy_timer_interrupt(int irq, void *dev_id)
-{
-	int cpu = smp_processor_id();
-	struct clock_event_device *evt = &per_cpu(wrhv_clock_events, cpu);
-	if (!evt->event_handler) {
-		printk(KERN_WARNING "wrhv timer handler \
-				     has not set yet %d\n", cpu);
-		return IRQ_NONE;
-	}
-
-	evt->event_handler(evt);
-
-	return IRQ_HANDLED;
-}
-
-irqreturn_t wrhv_timer_interrupt(int irq, void *dev_id)
-{
-	int cpu = smp_processor_id();
-	struct clock_event_device *evt = &per_cpu(wrhv_clock_events, cpu);
-
-	if (!evt->event_handler) {
-		printk(KERN_WARNING
-			   "Spurious Hyp timer interrupt on cpu %d\n", cpu);
-		return IRQ_NONE;
-	}
-
-	evt->event_handler(evt);
-
-	return IRQ_HANDLED;
-}
-
-static struct irqaction wrhv_timer_irq = {
-	.handler = wrhv_timer_interrupt,
-	.flags = IRQF_DISABLED | IRQF_NOBALANCING,
-	.mask = CPU_MASK_NONE,
-	.name = "timer",
-};
-
-static inline void wrhv_mask_timer_for_vcore(void);
-static inline void wrhv_umask_timer_for_vcore(void);
-void __devinit wrhv_setup_boot_clock(void)
-{
-#ifdef CONFIG_WRHV_X86_HRTIMERS
-	int ret;
-	struct clock_event_device *evt;
-
-	wrhv_mask_timer_for_vcore();
-	evt = &per_cpu(wrhv_clock_events, 0);
-	memcpy(evt, &wrhv_clock_event, sizeof(*evt));
-	evt->cpumask = cpumask_of_cpu(0);
-	evt->features = CLOCK_EVT_FEAT_DUMMY | CLOCK_EVT_FEAT_ONESHOT;
-	evt->irq = DUMMY_TIMER_INT;
-	evt->rating = 1;
-	clockevents_register_device(evt);
-	wrhv_timer_irq.name = "dummy_ipi_timer";
-	wrhv_timer_irq.handler = wrhv_dummy_timer_interrupt;
-	ret = setup_irq(DUMMY_TIMER_INT, &wrhv_timer_irq);
-	if (ret)
-		printk(KERN_WARNING "setup dummy timer irq failed\n");
-#endif
-}
-
-void __devinit wrhv_setup_secondary_clock(void)
-{
-	int cpu;
-	struct clock_event_device *evt;
-	cpu = smp_processor_id();
-	printk(KERN_INFO "installing wrhv timer for CPU %d\n", cpu);
-
-	evt = &per_cpu(wrhv_clock_events, cpu);
-	memcpy(evt, &wrhv_clock_event, sizeof(*evt));
-	evt->cpumask = cpumask_of_cpu(cpu);
-
-#ifdef CONFIG_WRHV_X86_HRTIMERS
-	evt->features = CLOCK_EVT_FEAT_DUMMY | CLOCK_EVT_FEAT_ONESHOT;
-	evt->irq = DUMMY_TIMER_INT;
-	evt->rating = 1;
-#endif
-	clockevents_register_device(evt);
-}
-
-#ifndef CONFIG_WRHV_X86_HRTIMERS
-static void __init wrhv_time_init(void)
-{
-	struct clock_event_device *evt;
-
-	evt = &per_cpu(wrhv_clock_events, 0);
-	memcpy(evt, &wrhv_clock_event, sizeof(*evt));
-	evt->cpumask = cpumask_of_cpu(0);
-
-	clockevents_register_device(evt);
-	wrhv_timer_irq.mask = cpumask_of_cpu(0);
-	setup_irq(0, &wrhv_timer_irq);
-}
-#endif
-
-#ifdef CONFIG_PCI
-static int wrhv_pci_enable_irq(struct pci_dev *dev)
-{
-	return 0;
-}
-
-static void wrhv_pci_disable_irq(struct pci_dev *dev)
-{
-}
-
-static int wrhv_init_pci(void)
-{
-	pcibios_enable_irq = wrhv_pci_enable_irq;
-	pcibios_disable_irq = wrhv_pci_disable_irq;
-	return 0;
-}
-
-static int __devinitdata __wrhv_kgdboe_poll;
-static int __init wrhv_check_kgdboe(char *str)
-{
-	__wrhv_kgdboe_poll = 1;
-	return 0;
-}
-early_param("kgdboe", wrhv_check_kgdboe);
-
-static void __devinit pci_fixup_wrhv(struct pci_dev *dev)
-{
-	int irq;
-	char *devclass, devname[32] = { "Unknown" };
-	int skip_assign_irq = 0;
-
-	switch (dev->class >> 16) {
-	case PCI_BASE_CLASS_NETWORK:
-		devclass = "Ethernet";
-		if (__wrhv_kgdboe_poll) {
-			skip_assign_irq = 1;
-			irq = WRHV_POLL_IRQ;
-		}
-		break;
-
-	case PCI_BASE_CLASS_STORAGE:
-		devclass = "IDE";
-		break;
-
-	case PCI_BASE_CLASS_DISPLAY:
-		devclass = "VGA";
-		break;
-	default:
-		skip_assign_irq = 1;
-		irq = dev->irq;
-		break;
-	}
-
-	if (!skip_assign_irq) {
-		snprintf(devname, sizeof devname, "pci%s_%x:%x",
-			devclass, dev->bus->number, dev->devfn);
-		irq = vbiIntVecFind(devname, 1);
-		if (irq == VBI_INVALID_IRQ)
-			irq = WRHV_POLL_IRQ;
-	}
-
-	dev->irq = irq;
-	printk(KERN_DEBUG "WRHV-PCI: %s CLASS:%x IRQ%d\n",
-		devname, dev->class, dev->irq);
-}
-
-DECLARE_PCI_FIXUP_HEADER(PCI_ANY_ID, PCI_ANY_ID, pci_fixup_wrhv);
-#endif /* CONFIG_PCI */
-
-static unsigned long long wrhv_read_msr(unsigned int msr, int *err)
-{
-#ifdef WRHV_DEBUG_MSR
-	printk("RDMSR from %p\n", __builtin_return_address(0));
-#endif
-	return native_read_msr(msr);
-}
-
-static int wrhv_write_msr(unsigned int msr, unsigned low, unsigned high)
-{
-#ifdef WRHV_DEBUG_MSR
-	printk("WRMSR from %p\n", __builtin_return_address(0));
-#endif
-	native_write_msr(msr, low, high);
-	return 0;
-}
-
-static unsigned long wrhv_get_debugreg(int regno)
-{
-	unsigned long val = ~0UL;
-
-	switch (regno) {
-	case 0 ... 3:
-		/* undefined state */
-		break;
-	case 6 ... 7:
-		val = 0;
-		break;
-	default:
-		BUG();
-	}
-	return val;
-}
-
-static void wrhv_set_debugreg(int regno, unsigned long value)
-{
-}
-
-void wrhv_cpu_workarounds(struct cpuinfo_x86 *c)
-{
-	/* Simics workaround */
-	c->hlt_works_ok = 0;
-
-	/* WP test fails currently */
-	c->wp_works_ok = 1;
-
-	clear_bit(X86_FEATURE_DE, (void *)boot_cpu_data.x86_capability);
-}
-
-void wrhv_boot_config(void)
-{
-	boot_params.hdr.type_of_loader = 0xff; /* Unknown */
-	if (__initrd_start != __initrd_end) {
-		boot_params.hdr.ramdisk_image = (unsigned long)&__initrd_start - PAGE_OFFSET;
-		boot_params.hdr.ramdisk_size = (unsigned long)&__initrd_end - (unsigned long)&__initrd_start;
-	}
-
-#ifndef WRHV_USE_XMLCONFIG
-	strlcpy(boot_command_line,
-		"pci=conf1 memmap=exactmap memmap=32M@0 mem=nopentium earlyprintk=vga,keep ramdisk_size=16384"
-		" serialnumber nolapic nomce nosep retain_initrd root=/dev/ram init=/bin/busybox console=ttyS0,9600",
-		COMMAND_LINE_SIZE);
-#else
-	/* Use the config space copy here, since we haven't mapped in the
-	   actual hypervisor config/status/control space yet */
-        snprintf(boot_command_line, COMMAND_LINE_SIZE,
-		"retain_initrd pci=conf1 idle=wrhv mem=nopentium serialnumber nolapic nomce nosep memmap=exactmap memmap=%dK@0 %s",
-		wrhvConfig->physicalMemorySize / 1024, wrhvConfig->bootLine);
-#endif
-}
-
-#ifdef CONFIG_SMP
-irqreturn_t wrhv_ipi_func_call_single_handler(int irq, void *dev_id)
-{
-	irq_enter();
-	generic_smp_call_function_single_interrupt();
-	__get_cpu_var(irq_stat).irq_call_count++;
-	irq_exit();
-	vbiVioapicIntUnmask(irq);
-	return IRQ_HANDLED;
-}
-
-irqreturn_t wrhv_ipi_func_call_handler(int irq, void *dev_id)
-{
-	irq_enter();
-	generic_smp_call_function_interrupt();
-	__get_cpu_var(irq_stat).irq_call_count++;
-	irq_exit();
-	vbiVioapicIntUnmask(irq);
-	return IRQ_HANDLED;
-}
-
-irqreturn_t wrhv_ipi_inv_tlb_handler(int irq, void *dev_id)
-{
-	unsigned long cpu;
-
-	cpu = get_cpu();
-
-	if (!cpu_isset(cpu, flush_cpumask))
-		goto out;
-		/*
-		 * This was a BUG() but until someone can quote me the
-		 * line from the intel manual that guarantees an IPI to
-		 * multiple CPUs is retried _only_ on the erroring CPUs
-		 * its staying as a return
-		 *
-		 * BUG();
-		 */
-
-	if (flush_mm == per_cpu(cpu_tlbstate, cpu).active_mm) {
-		if (per_cpu(cpu_tlbstate, cpu).state == TLBSTATE_OK) {
-			if (flush_va == TLB_FLUSH_ALL)
-				local_flush_tlb();
-			else
-				__flush_tlb_one(flush_va);
-		} else {
-			wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD,
-					__pa(flush_mm->pgd), 0, 0);
-			leave_mm(cpu);
-		}
-	} else {
-	    if (flush_va == TLB_FLUSH_ALL)
-			wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD,
-					__pa(flush_mm->pgd),
-					0, 0);
-	    else
-			wrhv_vtlb_op(VBI_VTLB_OP_UPDATE_PTE,
-					__pa(flush_mm->pgd),
-					(unsigned long)flush_mm, 0);
-
-	}
-
-	smp_mb__before_clear_bit();
-	cpu_clear(cpu, flush_cpumask);
-	smp_mb__after_clear_bit();
-out:
-	put_cpu_no_resched();
-	__get_cpu_var(irq_stat).irq_tlb_count++;
-
-	vbiVioapicIntUnmask(irq);
-	return IRQ_HANDLED;
-}
-
-irqreturn_t wrhv_ipi_resched_handler(int irq, void *dev_id)
-{
-	__get_cpu_var(irq_stat).irq_resched_count++;
-	vbiVioapicIntUnmask(irq);
-	return IRQ_HANDLED;
-}
-#endif
-
-static void wrhv_vtlb_op (unsigned int op, unsigned long arg1, unsigned long arg2, unsigned long arg3)
-{
-	unsigned long flags;
-	int i;
-
-	if (!VTLB_GET_CPU_VAR(is_vtlb_ops_cache_enabled))
-		vbiVtlbOp (op, arg1, arg2, arg3);
-	else {
-		local_irq_save(flags);
-		i = VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops_ix;
-		VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops[i].op = op;
-		VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops[i].arg1 = arg1;
-		VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops[i].arg2 = arg2;
-		VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops[i].arg3 = arg3;
-		wmb();
-		/*
-		 * If the buffer is full, flush it. Index will be automatically
-		 * updated by the hypervisor.
-		 */
-
-		if (VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops_ix == (VBI_VTLB_OP_MAX_OPS - 1))
-			vbiVtlbOp (VBI_VTLB_OP_FLUSH_OPS, 0, 0, 0);
-		else
-			VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops_ix += 1;
-
-		local_irq_restore(flags);
-	}
-}
-
-static void wrhv_write_cr3(unsigned long val)
-{
-	unsigned long cr3 = val;
-	int i;
-
-	if (VTLB_GET_CPU_VAR(is_cr3_cache_enabled) && VTLB_GET_CPU_VAR(vtlb_ctrl).vtlb_ops_ix == 0) {
-		for (i = 0; i < VBI_VTLB_OP_CR3_CACHE_ENTRIES; i++) {
-			if (VTLB_GET_CPU_VAR(vtlb_ctrl).cr3_cache[i].guest_cr3 == cr3) {
-				cr3 = VTLB_GET_CPU_VAR(vtlb_ctrl).cr3_cache[i].host_cr3;
-				VTLB_GET_CPU_VAR(vtlb_ctrl).cr3_cache_ix = i;
-				break;
-			}
-		}
-	} else
-		VTLB_GET_CPU_VAR(vtlb_ctrl).cr3_cache_ix = -1;
-
-	asm volatile ("mov %0,%%cr3": :"r" (cr3));
-	VTLB_GET_CPU_VAR(cr3_val) = val;
-}
-
-static unsigned long wrhv_read_cr3(void)
-{
-	/* Use cached value to avoid useless hypercall */
-	return VTLB_GET_CPU_VAR(cr3_val);
-}
-
-static void wrhv_set_pmd(pmd_t *pmdp, pmd_t pmdval)
-{
-	*pmdp = pmdval;
-	wrhv_vtlb_op(VBI_VTLB_OP_UPDATE_PMD,
-			__pa(((unsigned long) pmdp) & PAGE_MASK),
-			__pa(pmdp), 0);
-}
-
-#define is_current_as(mm) ((mm) == current->active_mm || ((mm) == &init_mm))
-
-static void wrhv_pte_update(struct mm_struct *mm, unsigned long addr, pte_t *ptep)
-{
-	if (!is_current_as(mm))
-		wrhv_vtlb_op(VBI_VTLB_OP_UPDATE_PTE, __pa(mm->pgd),
-						addr, __pa(ptep));
-}
-
-static void wrhv_pte_update_defer(struct mm_struct *mm, unsigned long addr, pte_t *ptep)
-{
-	if (!is_current_as(mm))
-		wrhv_pte_update (mm, addr, ptep);
-}
-
-static void wrhv_release_pd(u32 pfn)
-{
-	wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD, pfn << PAGE_SHIFT, 0, 0);
-}
-
-static void wrhv_set_pte(pte_t *ptep, pte_t pte)
-{
-	*ptep = pte;
-}
-
-static void wrhv_flush_tlb_user(void)
-{
-	native_write_cr3(VTLB_GET_CPU_VAR(cr3_val));
-}
-
-static void wrhv_flush_tlb_kernel(void)
-{
-	unsigned long cr4, flags;
-
-	/* This routine is not optimized but since it is very rarely used
-	   let's not worry too much about this for now.
-	 */
-
-	local_irq_save(flags);
-	cr4 = native_read_cr4();
-	native_write_cr4(cr4 & ~X86_CR4_PGE);
-	native_write_cr3(VTLB_GET_CPU_VAR(cr3_val));
-	native_write_cr4(cr4);
-	local_irq_restore(flags);
-}
-
-static void wrhv_flush_tlb_single(unsigned long addr)
-{
-	__native_flush_tlb_single(addr);
-}
-
-static inline void wrhv_send_ipi(int irq, int coreid)
-{
-	int ret;
-	unsigned long flags;
-
-	spin_lock_irqsave(&vioapic_lock, flags);
-	ret = vbiVioapicIntRedirect(irq, coreid);
-	if (unlikely(!!ret))
-		printk(KERN_ERR "IPI: redirect to core%d for IPI%d failed. \n", coreid, irq);
-
-	ret = vbiVioapicIntSend(irq, VBI_IOAPICSEND_OTHERS, VBI_BOARD_ID_GET());
-	spin_unlock_irqrestore(&vioapic_lock, flags);
-	if (unlikely(!!ret))
-		printk(KERN_ERR "IPI: send IPI%d to core%d failed. \n", irq, coreid);
-
-}
-
-static void wrhv_smp_send_invalidate_tlb_ipi(cpumask_t mask)
-{
-	int cpu;
-	cpus_and(mask, mask, cpu_online_map);
-
-	for_each_cpu_mask_nr(cpu, mask)
-		wrhv_send_ipi(WRHV_IPI_INV_TLB, cpu);
-}
-
-static void wrhv_flush_tlb_others(const cpumask_t *cpumaskp, struct mm_struct *mm,
-			     unsigned long va)
-{
-	cpumask_t cpumask = *cpumaskp;
-
-	/*
-	 * A couple of (to be removed) sanity checks:
-	 *
-	 * - current CPU must not be in mask
-	 * - mask must exist :)
-	 */
-	BUG_ON(cpus_empty(cpumask));
-	BUG_ON(cpu_isset(smp_processor_id(), cpumask));
-	BUG_ON(!mm);
-
-	/*
-	 * i'm not happy about this global shared spinlock in the
-	 * MM hot path, but we'll see how contended it is.
-	 * AK: x86-64 has a faster method that could be ported.
-	 */
-	spin_lock(&tlbstate_lock);
-
-	flush_mm = mm;
-	flush_va = va;
-	cpus_or(flush_cpumask, cpumask, flush_cpumask);
-	/*
-	 * We have to send the IPI only to
-	 * CPUs affected.
-	 */
-	wrhv_smp_send_invalidate_tlb_ipi(cpumask);
-
-	while (!cpus_empty(flush_cpumask))
-		/* nothing. lockup detection does not belong here */
-		cpu_relax();
-
-	flush_mm = NULL;
-	flush_va = 0;
-	spin_unlock(&tlbstate_lock);
-}
-
-static void wrhv_set_pte_at(struct mm_struct *mm, unsigned long addr, pte_t *ptep, pte_t pte)
-{
-	if (!is_current_as(mm)) {
-		*ptep = pte;
-		wrhv_vtlb_op(VBI_VTLB_OP_SET_PTE_AT, __pa(mm->pgd),
-						addr, __pa(ptep));
-	} else
-		*ptep = pte;
-}
-
-static unsigned wrhv_patch(u8 type, u16 clobber, void *ibuf,
-				unsigned long addr, unsigned len)
-{
-	return paravirt_patch_default(type, clobber, ibuf, addr, len);
-}
-
-static void wrhv_exit_mmap (struct mm_struct *mm)
-{
-#ifdef CONFIG_SMP
-	/*
-	 * We are deleting the page directory. We need to delete it in
-	 * the current hypervisor cache but also in the cache of the
-	 * hypervisors managing the various virtual cores.
-	 */
-
-	cpumask_t cpumask;
-	int cpu = get_cpu ();
-	wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD, __pa(mm->pgd), 0, 0);
-	cpumask = mm->cpu_vm_mask;
-	cpu_clear(cpu, cpumask);
-	if (!cpus_empty(cpumask))
-	    wrhv_flush_tlb_others (&cpumask, mm, TLB_FLUSH_ALL);
-	put_cpu ();
-#else
-	wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD, __pa(mm->pgd), 0, 0);
-#endif
-}
-
-static void wrhv_init_mm(void)
-{
-	/* Initialize the cached copy of cr3 */
-	VTLB_GET_CPU_VAR(cr3_val) = native_read_cr3();
-
-	/*
-	 * set the size of the vtlb_ctrl structure in the structure provided
-	 * to the hypervisor; the hypervisor may be able to use this later
-	 * for backward compatibility.
-	 */
-
-	VTLB_GET_CPU_VAR(vtlb_ctrl).size = sizeof (VTLB_GET_CPU_VAR(vtlb_ctrl));
-
-	/* First set the options supported by the guest OS. The host will
-	   then update the mode field of vtlb_ctrl option to indicate which
-	   one will actually be in use.
-	*/
-
-	VTLB_GET_CPU_VAR(vtlb_ctrl).mode = VBI_VTLB_OPTIM_OPTION;
-
-	vbiVtlbOp(VBI_VTLB_OP_INIT, __pa_symbol(&VTLB_GET_CPU_VAR(vtlb_ctrl)), 0, 0);
-
-	if (VTLB_GET_CPU_VAR(vtlb_ctrl).mode & VBI_VTLB_CR3_CACHE_ENABLED)
-		VTLB_GET_CPU_VAR(is_cr3_cache_enabled) = 1;
-	if (VTLB_GET_CPU_VAR(vtlb_ctrl).mode & VBI_VTLB_OPTIM_ENABLED)
-		VTLB_GET_CPU_VAR(is_vtlb_optim_enabled) = 1;
-	if (VTLB_GET_CPU_VAR(vtlb_ctrl).mode & VBI_VTLB_OPS_CACHE_ENABLED)
-		VTLB_GET_CPU_VAR(is_vtlb_ops_cache_enabled) = 1;
-
-	pv_mmu_ops.read_cr3 = wrhv_read_cr3;
-	pv_mmu_ops.write_cr3 = wrhv_write_cr3;
-
-	if (VTLB_GET_CPU_VAR(is_vtlb_optim_enabled)) {
-		pv_mmu_ops.set_pte = wrhv_set_pte;
-		pv_mmu_ops.set_pte_at = wrhv_set_pte_at;
-
-		pv_mmu_ops.pte_update = wrhv_pte_update;
-		pv_mmu_ops.pte_update_defer = wrhv_pte_update_defer;
-		pv_mmu_ops.set_pmd = wrhv_set_pmd;
-
-		pv_mmu_ops.release_pmd = wrhv_release_pd;
-
-		pv_mmu_ops.exit_mmap = wrhv_exit_mmap,
-
-		pv_mmu_ops.flush_tlb_user = wrhv_flush_tlb_user;
-		pv_mmu_ops.flush_tlb_kernel = wrhv_flush_tlb_kernel;
-		pv_mmu_ops.flush_tlb_single = wrhv_flush_tlb_single;
-	}
-#ifdef CONFIG_SMP
-	pv_mmu_ops.flush_tlb_others = wrhv_flush_tlb_others;
-#endif
-}
-
-int __init wrhv_late_init(void)
-{
-	return 0;
-}
-late_initcall(wrhv_late_init);
-
-static inline void wrhv_umask_timer_for_vcore(void)
-{
-       /* unmask hypervisor-provided timer interrupt for vcore */
-       vbiVioapicIntUnmask(0);
-}
-
-static inline void wrhv_mask_timer_for_vcore(void)
-{
-       /* mask hypervisor-provided timer interrupt for vcore */
-       vbiVioapicIntMask(0);
-}
-
-#ifdef CONFIG_SMP
-static void __init wrhv_smp_prepare_boot_cpu(void)
-{
-	BUG_ON(smp_processor_id() != 0);
-	native_smp_prepare_boot_cpu();
-	return;
-}
-
-void __init wrhv_calibrate_smp_cpus(void)
-{
-	/* Use the config space copy here, since we haven't mapped in the
-	   actual hypervisor config/status/control space yet */
-	int cpus = wrhvConfig->numCores;
-	int cpuid = wrhvConfig->coreId;
-	if (cpuid != 0)
-		return;
-	printk(KERN_INFO "WRHV: calibrate CPU information according to vbConfig \n");
-	physid_clear(16, phys_cpu_present_map);
-	if (cpus > 1) {
-		smp_found_config = 1;
-		alternatives_smp_switch(1);
-	}
-
-	while( --cpus >= 0) {
-		physid_set(cpus, phys_cpu_present_map);
-		cpu_set(cpus, cpu_present_map);
-		cpu_set(cpus, cpu_possible_map);
-	}
-	return;
-}
-EXPORT_SYMBOL(wrhv_calibrate_smp_cpus);
-
-static void inline wrhv_umask_IPIs_for_vcore(void)
-{
-       /* unmask ipi interrupt for vcore */
-       vbiVioapicIntUnmask(WRHV_IPI_RESCHED);
-       vbiVioapicIntUnmask(WRHV_IPI_INV_TLB);
-       vbiVioapicIntUnmask(WRHV_IPI_FUNC_CALL);
-       vbiVioapicIntUnmask(WRHV_IPI_FUNC_CALL_SINGLE);
-#ifdef CONFIG_WRHV_X86_HRTIMERS
-	vbiVioapicIntUnmask(DUMMY_TIMER_INT);
-#endif
-}
-
-static void x86_wrhv_mask_irq(void *irq)
-{
-	vbiVioapicIntMask((unsigned int)irq);
-}
-
-static void x86_wrhv_unmask_irq(void *irq)
-{
-	vbiVioapicIntUnmask((unsigned int)irq);
-}
-
-/* Currently all the external interrupts are routed to cpu 0 and
- * handled by cpu0, so we need make sure the startup/shutdown functions
- * operate cpu 0's vioapic.
- */
-static void smp_wrhv_shutdown_irq(unsigned int irq)
-{
-	if (smp_processor_id() == 0)
-		x86_wrhv_mask_irq((void *)irq);
-	else {
-		struct call_single_data *data;
-
-		data = kmalloc(sizeof(*data), GFP_ATOMIC);
-		if (!data)
-			return;
-
-		data->flags = CSD_FLAG_ALLOC;
-		data->func = x86_wrhv_mask_irq;
-		data->info = (void *)irq;
-		__smp_call_function_single(0, data);
-	}
-}
-
-static unsigned int smp_wrhv_startup_irq(unsigned int irq)
-{
-	if (smp_processor_id() == 0)
-		x86_wrhv_unmask_irq((void *)irq);
-	else {
-		struct call_single_data *data;
-
-		data = kmalloc(sizeof(*data), GFP_ATOMIC);
-		if (!data)
-			return -ENOMEM;
-
-		data->flags = CSD_FLAG_ALLOC;
-		data->func = x86_wrhv_unmask_irq;
-		data->info = (void *)irq;
-		__smp_call_function_single(0, data);
-	}
-	return 0;
-}
-
-void __init wrhv_smp_prepare_cpus(unsigned int max_cpus)
-{
-	int ret;
-	native_smp_prepare_cpus(max_cpus);
-
-	wrhv_irq_chip.ack = NULL;
-	wrhv_irq_chip.startup = smp_wrhv_startup_irq;
-	wrhv_irq_chip.shutdown = smp_wrhv_shutdown_irq;
-
-	set_irq_chip_and_handler_name(WRHV_IPI_RESCHED,
-			&wrhv_irq_chip, handle_percpu_irq, "per_cpu");
-	set_irq_chip_and_handler_name(WRHV_IPI_INV_TLB,
-			&wrhv_irq_chip, handle_percpu_irq, "per_cpu");
-	set_irq_chip_and_handler_name(WRHV_IPI_FUNC_CALL,
-			&wrhv_irq_chip, handle_percpu_irq, "per_cpu");
-	set_irq_chip_and_handler_name(WRHV_IPI_FUNC_CALL_SINGLE,
-			&wrhv_irq_chip, handle_percpu_irq, "per_cpu");
-
-#ifdef CONFIG_WRHV_X86_HRTIMERS
-	set_irq_chip_and_handler_name(DUMMY_TIMER_INT,
-			&wrhv_irq_chip, handle_percpu_irq, "per_cpu");
-#endif
-
-	ret = request_irq(WRHV_IPI_RESCHED, wrhv_ipi_resched_handler,
-			IRQF_DISABLED|IRQF_NOBALANCING, "ipi_resched",
-			wrhv_ipi_resched_handler);
-	printk("request_irq ret for WRHV_IPI_RESCHED: %d \n", ret);
-
-	ret = request_irq(WRHV_IPI_INV_TLB, wrhv_ipi_inv_tlb_handler,
-			IRQF_DISABLED|IRQF_NOBALANCING, "ipi_inv_tlb",
-			wrhv_ipi_inv_tlb_handler);
-	printk("request_irq ret for WRHV_IPI_INV_TLB: %d \n", ret);
-
-	ret = request_irq(WRHV_IPI_FUNC_CALL, wrhv_ipi_func_call_handler,
-			IRQF_DISABLED|IRQF_NOBALANCING, "ipi_func_call",
-			wrhv_ipi_func_call_handler);
-	printk("request_irq ret for WRHV_IPI_FUNC_CALL: %d \n", ret);
-
-	ret = request_irq(WRHV_IPI_FUNC_CALL_SINGLE,
-			wrhv_ipi_func_call_single_handler,
-			IRQF_DISABLED|IRQF_NOBALANCING, "ipi_func_call_single",
-			wrhv_ipi_func_call_single_handler);
-	printk("request_irq ret for WRHV_IPI_FUNC_CALL_SINGLE: %d \n", ret);
-
-	wrhv_umask_IPIs_for_vcore();
-
-	return;
-}
-
-#ifdef CONFIG_HOTPLUG_CPU
-static DEFINE_PER_CPU(struct task_struct *, idle_thread_array);
-#define get_idle_for_cpu(x)      (per_cpu(idle_thread_array, x))
-#define set_idle_for_cpu(x, p)   (per_cpu(idle_thread_array, x) = (p))
-#else
-extern struct task_struct *idle_thread_array[NR_CPUS] __cpuinitdata ;
-#define get_idle_for_cpu(x)      (idle_thread_array[(x)])
-#define set_idle_for_cpu(x, p)   (idle_thread_array[(x)] = (p))
-#endif
-
-struct create_idle {
-	struct work_struct work;
-	struct task_struct *idle;
-	struct completion done;
-	int cpu;
-};
-
-static void __cpuinit do_fork_idle(struct work_struct *work)
-{
-	struct create_idle *c_idle =
-		container_of(work, struct create_idle, work);
-
-	c_idle->idle = fork_idle(c_idle->cpu);
-	complete(&c_idle->done);
-}
-
-static void __cpuinit wrhv_smp_callin(void)
-{
-	int cpuid;
-	unsigned long timeout;
-
-	cpuid = smp_processor_id();
-	if (cpu_isset(cpuid, cpu_callin_map)) {
-		panic("%s: CPU#%d already present??\n", __func__, cpuid);
-	}
-
-	/*
-	 * Waiting 2s total for startup (udelay is not yet working)
-	 */
-	timeout = jiffies + 2*HZ;
-	while (time_before(jiffies, timeout)) {
-		/*
-		 * Has the boot CPU finished it's STARTUP sequence?
-		 */
-		if (cpu_isset(cpuid, cpu_callout_map))
-			break;
-		cpu_relax();
-	}
-
-	if (!time_before(jiffies, timeout)) {
-		panic("%s: CPU%d started up but did not get a callout!\n",
-			__func__, cpuid);
-	}
-
-	local_irq_enable();
-	calibrate_delay();
-	local_irq_disable();
-
-	smp_store_cpu_info(cpuid);
-
-	/*
-	 * Allow the master to continue.
-	 */
-	cpu_set(cpuid, cpu_callin_map);
-}
-
-static int low_mappings;
-
-static void __cpuinit wrhv_smp_start_cpu(void)
-{
-	wrhv_mask_timer_for_vcore();
-
-	/* Initialize the cached copy of cr3 */
-	VTLB_GET_CPU_VAR(cr3_val) = native_read_cr3();
-
-	/*
-	 * set the size of the vtlb_ctrl structure in the structure provided
-	 * to the hypervisor; the hypervisor may be able to use this later
-	 * for backward compatibility.
-	 */
-
-	VTLB_GET_CPU_VAR(vtlb_ctrl).size = sizeof (VTLB_GET_CPU_VAR(vtlb_ctrl));
-
-	/* First set the options supported by the guest OS. The host will
-	   then update the mode field of vtlb_ctrl option to indicate which
-	   one will actually be in use.
-	*/
-
-	VTLB_GET_CPU_VAR(vtlb_ctrl).mode = VBI_VTLB_OPTIM_OPTION;
-
-	vbiVtlbOp(VBI_VTLB_OP_INIT, __pa_symbol(&VTLB_GET_CPU_VAR(vtlb_ctrl)), 0, 0);
-
-	if (VTLB_GET_CPU_VAR(vtlb_ctrl).mode & VBI_VTLB_CR3_CACHE_ENABLED)
-		VTLB_GET_CPU_VAR(is_cr3_cache_enabled) = 1;
-	if (VTLB_GET_CPU_VAR(vtlb_ctrl).mode & VBI_VTLB_OPTIM_ENABLED)
-		VTLB_GET_CPU_VAR(is_vtlb_optim_enabled) = 1;
-	if (VTLB_GET_CPU_VAR(vtlb_ctrl).mode & VBI_VTLB_OPS_CACHE_ENABLED)
-		VTLB_GET_CPU_VAR(is_vtlb_ops_cache_enabled) = 1;
-
-	cpu_init();
-	wrhv_umask_IPIs_for_vcore();
-	preempt_disable();
-	wrhv_smp_callin();
-
-	/* otherwise gcc will move up smp_processor_id before the cpu_init */
-	barrier();
-
-	/*
-	 * Check TSC synchronization with the BP:
-	 */
-	check_tsc_sync_target();
-
-#ifdef CONFIG_X86_32
-	while (low_mappings) {
-		cpu_relax();
-	}
-	__flush_tlb_all();
-#endif
-
-	set_cpu_sibling_map(raw_smp_processor_id());
-	wmb();
-
-	ipi_call_lock_irq();
-	cpu_set(smp_processor_id(), cpu_online_map);
-	ipi_call_unlock_irq();
-	per_cpu(cpu_state, smp_processor_id()) = CPU_ONLINE;
-
-	setup_secondary_clock();
-
-#ifndef CONFIG_WRHV_X86_HRTIMERS
-	wrhv_umask_timer_for_vcore();
-#endif
-	wmb();
-
-	local_irq_enable();
-	cpu_idle();
-
-}
-
-static int __cpuinit wrhv_wakeup_secondary_cpu(int core)
-{
-	return vbiVbResume(VBI_BOARD_ID_GET(), core);
-}
-
-static int __cpuinit wrhv_do_boot_cpu(int cpu)
-{
-	unsigned long boot_error = 0;
-	unsigned int timeout;
-	struct create_idle c_idle = {
-		.cpu = cpu,
-		.done = COMPLETION_INITIALIZER_ONSTACK(c_idle.done),
-	};
-
-	INIT_WORK(&c_idle.work, do_fork_idle);
-
-	alternatives_smp_switch(1);
-
-	c_idle.idle = get_idle_for_cpu(cpu);
-
-	if (c_idle.idle) {
-		c_idle.idle->thread.sp = (unsigned long) (((struct pt_regs *)
-			(THREAD_SIZE +  task_stack_page(c_idle.idle))) - 1);
-		init_idle(c_idle.idle, cpu);
-		goto do_rest;
-	}
-
-	if (!keventd_up() || current_is_keventd())
-		c_idle.work.func(&c_idle.work);
-	else {
-		schedule_work(&c_idle.work);
-		wait_for_completion(&c_idle.done);
-	}
-
-	if (IS_ERR(c_idle.idle)) {
-		printk("failed fork for CPU %d\n", cpu);
-		return PTR_ERR(c_idle.idle);
-	}
-
-	set_idle_for_cpu(cpu, c_idle.idle);
-
-do_rest:
-
-	per_cpu(current_task, cpu) = c_idle.idle;
-	init_gdt(cpu);
-	irq_ctx_init(cpu);
-
-	early_gdt_descr.address = (unsigned long)get_cpu_gdt_table(cpu);
-	initial_code = (unsigned long)wrhv_smp_start_cpu;
-	stack_start.sp = (void *) c_idle.idle->thread.sp;
-
-	printk(KERN_INFO "Booting processor %d\n", cpu);
-
-	boot_error = wrhv_wakeup_secondary_cpu(cpu);
-
-	if (!boot_error) {
-		/*
-		 * allow APs to start initializing.
-		 */
-		pr_debug("Before Callout %d.\n", cpu);
-		cpu_set(cpu, cpu_callout_map);
-		pr_debug("After Callout %d.\n", cpu);
-
-		/*
-		 * Wait 5s total for a response
-		 */
-		for (timeout = 0; timeout < 50000; timeout++) {
-			if (cpu_isset(cpu, cpu_callin_map))
-				break;	/* It has booted */
-			udelay(100);
-		}
-
-		if (cpu_isset(cpu, cpu_callin_map)) {
-			/* number CPUs logically, starting from 1 (BSP is 0) */
-			pr_debug("OK.\n");
-			printk(KERN_INFO "CPU%d: ", cpu);
-			print_cpu_info(&cpu_data(cpu));
-			pr_debug("CPU has booted.\n");
-		} else {
-			boot_error = 1;
-			printk(KERN_ERR "Not responding.\n");
-		}
-	}
-
-	if (boot_error) {
-		/* Try to put things back the way they were before ... */
-		cpu_clear(cpu, cpu_callout_map);
-		cpu_clear(cpu, cpu_initialized);
-		cpu_clear(cpu, cpu_present_map);
-	}
-
-	return boot_error;
-}
-
-static int __cpuinit wrhv_cpu_up(unsigned int cpu)
-{
-	int err;
-	unsigned long flags;
-
-	if ( !physid_isset(cpu, phys_cpu_present_map)) {
-		printk(KERN_ERR "%s: bad cpu %d\n", __func__, cpu);
-		printk("----------phys_cpu_present_map == %x \n", *(unsigned *)&phys_cpu_present_map);
-		return -EINVAL;
-	}
-
-	/*
-	 * Already booted CPU?
-	 */
-	if (cpu_isset(cpu, cpu_callin_map)) {
-		panic("wrhv_do_boot_cpu core%d Already started\n", cpu);
-		return -ENOSYS;
-	}
-
-	per_cpu(cpu_state, cpu) = CPU_UP_PREPARE;
-
-#ifdef CONFIG_X86_32
-	/* init low mem mapping */
-	clone_pgd_range(swapper_pg_dir, swapper_pg_dir + KERNEL_PGD_BOUNDARY,
-		min_t(unsigned long, KERNEL_PGD_PTRS, KERNEL_PGD_BOUNDARY));
-	flush_tlb_all();
-
-	low_mappings = 1;
-	err = wrhv_do_boot_cpu(cpu);
-	zap_low_mappings();
-	low_mappings = 0;
-#else
-	err = wrhv_do_boot_cpu(cpu);
-#endif
-	if (err) {
-		pr_debug("wrhv_do_boot_cpu failed %d\n", err);
-		return -EIO;
-	}
-
-
-	local_irq_save(flags);
-	check_tsc_sync_source(cpu);
-	local_irq_restore(flags);
-
-	while (!cpu_online(cpu)) {
-		cpu_relax();
-	}
-
-	return 0;
-}
-
-static void wrhv_smp_cpus_done(unsigned int max_cpus)
-{
-	printk(KERN_INFO "BP: smp_init done. \n");
-	native_smp_cpus_done(max_cpus);
-	return;
-}
-
-static void stop_me(void * t)
-{
-	write_cr3((unsigned long)swapper_pg_dir);
-
-	/* Enter into infinite loop to stop self*/
-	while(1);
-}
-
-static void wrhv_smp_send_stop(void)
-{
-	smp_call_function(stop_me, NULL, 0);
-	return;
-}
-
-static void wrhv_smp_send_reschedule(int cpu)
-{
-	wrhv_send_ipi(WRHV_IPI_RESCHED, cpu);
-}
-
-static void wrhv_smp_send_call_func_single_ipi(int cpu)
-{
-	wrhv_send_ipi(WRHV_IPI_FUNC_CALL_SINGLE, cpu);
-}
-
-static void wrhv_smp_send_call_func_ipi(cpumask_t mask)
-{
-	unsigned int cpu;
-	for_each_cpu_mask_nr(cpu, mask)
-		wrhv_send_ipi(WRHV_IPI_FUNC_CALL, cpu);
-}
-
-static const struct smp_ops wrhv_smp_ops __initdata = {
-	.smp_prepare_boot_cpu = wrhv_smp_prepare_boot_cpu,
-	.smp_prepare_cpus = wrhv_smp_prepare_cpus,
-	.cpu_up = wrhv_cpu_up,
-	.smp_cpus_done = wrhv_smp_cpus_done,
-
-	.smp_send_stop = wrhv_smp_send_stop,
-	.smp_send_reschedule = wrhv_smp_send_reschedule,
-
-	.send_call_func_ipi = wrhv_smp_send_call_func_ipi,
-	.send_call_func_single_ipi = wrhv_smp_send_call_func_single_ipi,
-};
-
-void __init wrhv_smp_init(void)
-{
-	smp_ops = wrhv_smp_ops;
-	return;
-}
-#endif
-
-void wrhv_restart(void)
-{
-	int ret;
-	printk(KERN_INFO "WRHV: rebooting \n");
-
-	ret = vbiVbReset(VBI_BOARD_ID_GET(), VBI_VB_CORES_ALL,
-		VBI_VBMGMT_RESET_AND_START_CORE0 |
-		VBI_VBMGMT_RESET_DOWNLOAD |
-		VBI_VBMGMT_RESET_CLEAR
-		);
-
-	if (unlikely(ret != 0))
-		printk(KERN_ERR "WRHV: reboot failed. \n");
-
-	while (1);
-}
-
-void __init wrhv_init(void)
-{
-	pv_info.name = "wrhv";
-	pv_info.paravirt_enabled = 1;
-
-	wrhv_cpu_workarounds(&boot_cpu_data);
-
-	pv_init_ops.patch = wrhv_patch;
-
-	pv_cpu_ops.write_msr = wrhv_write_msr;
-	pv_cpu_ops.read_msr = wrhv_read_msr;
-
-#ifndef CONFIG_WRHV_X86_HRTIMERS
-	pv_time_ops.time_init = wrhv_time_init;
-	pv_time_ops.get_tsc_khz = wrhv_calculate_cpu_khz;
-#endif
-
-	pv_irq_ops.init_IRQ = wrhv_init_IRQ;
-	pv_cpu_ops.get_debugreg = wrhv_get_debugreg;
-	pv_cpu_ops.set_debugreg = wrhv_set_debugreg;
-
-#ifdef CONFIG_X86_LOCAL_APIC
-	pv_apic_ops.setup_boot_clock = wrhv_setup_boot_clock;
-	pv_apic_ops.setup_secondary_clock = wrhv_setup_secondary_clock;
-#endif
-	machine_ops.emergency_restart = wrhv_restart;
-
-#ifdef CONFIG_KGDB
-	arch_kgdb_ops.flags &= ~KGDB_HW_BREAKPOINT,
-	arch_kgdb_ops.set_hw_breakpoint = NULL;
-	arch_kgdb_ops.remove_hw_breakpoint = NULL;
-	arch_kgdb_ops.remove_all_hw_break = NULL;
-	arch_kgdb_ops.correct_hw_break = NULL;
-#endif
-
-	wrhv_init_mm();
-
-#ifdef CONFIG_PCI
-	wrhv_init_pci();
-#endif
-
-#ifdef CONFIG_SMP
-	wrhv_smp_init();
-#endif
-}
diff --git a/arch/x86/kernel/wrhv_initrd.S b/arch/x86/kernel/wrhv_initrd.S
deleted file mode 100644
index c5f40d6..0000000
--- a/arch/x86/kernel/wrhv_initrd.S
+++ /dev/null
@@ -1,3 +0,0 @@
-/*
- *  This file simply exists to trigger the Makefile to include the INITRD
- */
-- 
1.6.3.3

