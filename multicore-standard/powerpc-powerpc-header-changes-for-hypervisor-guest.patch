From 39945c970a8c60177ad25f25892125fc77373fb3 Mon Sep 17 00:00:00 2001
From: WRS Support <support@windriver.com>
Date: Fri, 2 Oct 2009 16:15:25 -0400
Subject: [PATCH 16/24] powerpc: powerpc header changes for hypervisor/guest

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
Signed-off-by: Bruce Ashfield <bruce.ashfield@windriver.com>
---
 arch/powerpc/include/asm/dma-mapping.h   |   52 +++++++++++++++++---
 arch/powerpc/include/asm/fs_pd.h         |    4 ++
 arch/powerpc/include/asm/hw_irq.h        |   77 ++++++++++++++++++++++++++++++
 arch/powerpc/include/asm/machdep.h       |    2 +
 arch/powerpc/include/asm/mmu_context.h   |    2 +-
 arch/powerpc/include/asm/page_32.h       |    2 +-
 arch/powerpc/include/asm/pgalloc-32.h    |    2 +-
 arch/powerpc/include/asm/pgtable-ppc32.h |   59 ++++++++++++++++++++---
 arch/powerpc/include/asm/reg.h           |    4 ++
 arch/powerpc/include/asm/system.h        |    4 ++
 10 files changed, 190 insertions(+), 18 deletions(-)

diff --git a/arch/powerpc/include/asm/dma-mapping.h b/arch/powerpc/include/asm/dma-mapping.h
index c7ca45f..5e84b2c 100644
--- a/arch/powerpc/include/asm/dma-mapping.h
+++ b/arch/powerpc/include/asm/dma-mapping.h
@@ -273,6 +273,7 @@ static inline int dma_set_mask(struct device *dev, u64 dma_mask)
 	return 0;
 }
 
+#ifndef CONFIG_PARAVIRT
 static inline void *dma_alloc_coherent(struct device *dev, size_t size,
 				       dma_addr_t * dma_handle,
 				       gfp_t gfp)
@@ -298,27 +299,64 @@ static inline void *dma_alloc_coherent(struct device *dev, size_t size,
 #endif
 }
 
-static inline void
-dma_free_coherent(struct device *dev, size_t size, void *vaddr,
-		  dma_addr_t dma_handle)
+static inline dma_addr_t
+dma_map_single(struct device *dev, void *ptr, size_t size,
+	       enum dma_data_direction direction)
+{
+	BUG_ON(direction == DMA_NONE);
+
+	__dma_sync(ptr, size, direction);
+	return virt_to_bus(ptr);
+}
+#else
+static inline void *native_dma_alloc_coherent(struct device *dev, size_t size,
+				       dma_addr_t * dma_handle,
+				       gfp_t gfp)
 {
 #ifdef CONFIG_NOT_COHERENT_CACHE
-	__dma_free_coherent(size, vaddr);
+	return __dma_alloc_coherent(size, dma_handle, gfp);
 #else
-	free_pages((unsigned long)vaddr, get_order(size));
+	void *ret;
+	/* ignore region specifiers */
+	gfp &= ~(__GFP_DMA | __GFP_HIGHMEM);
+
+	if (dev == NULL || dev->coherent_dma_mask < 0xffffffff)
+		gfp |= GFP_DMA;
+
+	ret = (void *)__get_free_pages(gfp, get_order(size));
+
+	if (ret != NULL) {
+		memset(ret, 0, size);
+		*dma_handle = virt_to_bus(ret);
+	}
+
+	return ret;
 #endif
 }
 
 static inline dma_addr_t
-dma_map_single(struct device *dev, void *ptr, size_t size,
+native_dma_map_single(struct device *dev, void *ptr, size_t size,
 	       enum dma_data_direction direction)
 {
 	BUG_ON(direction == DMA_NONE);
 
 	__dma_sync(ptr, size, direction);
-
 	return virt_to_bus(ptr);
 }
+#include <asm/pv_dma-mapping.h>
+#endif /* CONFIG_PARAVIRT */
+
+static inline void
+dma_free_coherent(struct device *dev, size_t size, void *vaddr,
+		  dma_addr_t dma_handle)
+{
+#ifdef CONFIG_NOT_COHERENT_CACHE
+	__dma_free_coherent(size, vaddr);
+#else
+	free_pages((unsigned long)vaddr, get_order(size));
+#endif
+}
+
 
 static inline void dma_unmap_single(struct device *dev, dma_addr_t dma_addr,
 				    size_t size,
diff --git a/arch/powerpc/include/asm/fs_pd.h b/arch/powerpc/include/asm/fs_pd.h
index 9361cd5..876d862 100644
--- a/arch/powerpc/include/asm/fs_pd.h
+++ b/arch/powerpc/include/asm/fs_pd.h
@@ -44,7 +44,11 @@ static inline int uart_baudrate(void)
 
 static inline int uart_clock(void)
 {
+#ifdef CONFIG_WRHV
+	return wrhv_cpu_freq;
+#else
         return ppc_proc_freq;
+#endif
 }
 
 #endif
diff --git a/arch/powerpc/include/asm/hw_irq.h b/arch/powerpc/include/asm/hw_irq.h
index 3b3a71d..1368473 100644
--- a/arch/powerpc/include/asm/hw_irq.h
+++ b/arch/powerpc/include/asm/hw_irq.h
@@ -13,6 +13,7 @@
 
 extern void timer_interrupt(struct pt_regs *);
 
+#ifndef CONFIG_PARAVIRT
 #ifdef CONFIG_PPC64
 #include <asm/paca.h>
 
@@ -137,6 +138,82 @@ static inline int irqs_disabled_flags(unsigned long flags)
 
 #endif /* CONFIG_PPC64 */
 
+#else /* !CONFIG_PARAVIRT */
+
+/* native implementation taken from !CONFIG_PPC64 */
+#if defined(CONFIG_BOOKE)
+#define SET_MSR_EE(x)	mtmsr(x)
+#define native_local_irq_restore(flags)	__asm__ __volatile__("wrtee %0" : : "r" (flags) : "memory")
+#else
+#define SET_MSR_EE(x)	mtmsr(x)
+#define native_local_irq_restore(flags)	mtmsr(flags)
+#endif
+
+static inline void native_local_irq_disable(void)
+{
+#ifdef CONFIG_BOOKE
+#ifdef CONFIG_KVM_GUEST
+	__asm__ __volatile__("wrtee %0": : "r"(0) :"memory");
+#else
+	__asm__ __volatile__("wrteei 0": : :"memory");
+#endif
+#else
+	unsigned long msr;
+	__asm__ __volatile__("": : :"memory");
+	msr = mfmsr();
+	SET_MSR_EE(msr & ~MSR_EE);
+#endif
+}
+
+static inline void native_local_irq_enable(void)
+{
+#ifdef CONFIG_BOOKE
+#ifdef CONFIG_KVM_GUEST
+	__asm__ __volatile__("wrtee %0": : "r"(MSR_EE) :"memory");
+#else
+	__asm__ __volatile__("wrteei 1": : :"memory");
+#endif
+#else
+	unsigned long msr;
+	__asm__ __volatile__("": : :"memory");
+	msr = mfmsr();
+	SET_MSR_EE(msr | MSR_EE);
+#endif
+}
+
+static inline void native_local_irq_save_ptr(unsigned long *flags)
+{
+	unsigned long msr;
+	msr = mfmsr();
+	*flags = msr;
+#ifdef CONFIG_BOOKE
+#ifdef CONFIG_KVM_GUEST
+	__asm__ __volatile__("wrtee %0": : "r"(0) :"memory");
+#else
+	__asm__ __volatile__("wrteei 0": : :"memory");
+#endif
+#else
+	SET_MSR_EE(msr & ~MSR_EE);
+#endif
+	__asm__ __volatile__("": : :"memory");
+}
+
+#define native_local_save_flags(flags)	((flags) = mfmsr())
+#define native_local_irq_save(flags)	native_local_irq_save_ptr(&flags)
+#define native_irqs_disabled()		((mfmsr() & MSR_EE) == 0)
+
+#define native_hard_irq_enable()	native_local_irq_enable()
+#define native_hard_irq_disable()	native_local_irq_disable()
+
+static inline int native_irqs_disabled_flags(unsigned long flags)
+{
+	return (flags & MSR_EE) == 0;
+}
+
+/* Hypervior specific implementation */
+#include <asm/pv_hw_irq.h>
+#endif /* CONFIG_PARAVIRT */
+
 /*
  * interrupt-retrigger: should we handle this via lost interrupts and IPIs
  * or should we not care like we do now ? --BenH.
diff --git a/arch/powerpc/include/asm/machdep.h b/arch/powerpc/include/asm/machdep.h
index 893aafd..23c21d2 100644
--- a/arch/powerpc/include/asm/machdep.h
+++ b/arch/powerpc/include/asm/machdep.h
@@ -361,5 +361,7 @@ static inline void log_error(char *buf, unsigned int err_type, int fatal)
 void generic_suspend_disable_irqs(void);
 void generic_suspend_enable_irqs(void);
 
+extern unsigned int get_pvr(void);
+
 #endif /* __KERNEL__ */
 #endif /* _ASM_POWERPC_MACHDEP_H */
diff --git a/arch/powerpc/include/asm/mmu_context.h b/arch/powerpc/include/asm/mmu_context.h
index 249ae7f..6dab487 100644
--- a/arch/powerpc/include/asm/mmu_context.h
+++ b/arch/powerpc/include/asm/mmu_context.h
@@ -65,7 +65,7 @@ static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)
 #define LAST_CONTEXT    	255
 #define FIRST_CONTEXT    	1
 
-#elif defined(CONFIG_E200) || defined(CONFIG_E500)
+#elif defined(CONFIG_E200) || defined(CONFIG_E500) || defined(CONFIG_PARAVIRT)
 #define NO_CONTEXT      	256
 #define LAST_CONTEXT    	255
 #define FIRST_CONTEXT    	1
diff --git a/arch/powerpc/include/asm/page_32.h b/arch/powerpc/include/asm/page_32.h
index ebfae53..eef1d35 100644
--- a/arch/powerpc/include/asm/page_32.h
+++ b/arch/powerpc/include/asm/page_32.h
@@ -18,7 +18,7 @@
  * The basic type of a PTE - 64 bits for those CPUs with > 32 bit
  * physical addressing.  For now this just the IBM PPC440.
  */
-#ifdef CONFIG_PTE_64BIT
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_PARAVIRT)
 typedef unsigned long long pte_basic_t;
 #define PTE_SHIFT	(PAGE_SHIFT - 3)	/* 512 ptes per page */
 #else
diff --git a/arch/powerpc/include/asm/pgalloc-32.h b/arch/powerpc/include/asm/pgalloc-32.h
index 1cb9245..f579541 100644
--- a/arch/powerpc/include/asm/pgalloc-32.h
+++ b/arch/powerpc/include/asm/pgalloc-32.h
@@ -17,7 +17,7 @@ extern void pgd_free(struct mm_struct *mm, pgd_t *pgd);
 #define __pmd_free_tlb(tlb,x)		do { } while (0)
 /* #define pgd_populate(mm, pmd, pte)      BUG() */
 
-#ifndef CONFIG_BOOKE
+#if !defined(CONFIG_BOOKE) || defined (CONFIG_PARAVIRT)
 #define pmd_populate_kernel(mm, pmd, pte)	\
 		(pmd_val(*(pmd)) = __pa(pte) | _PMD_PRESENT)
 #define pmd_populate(mm, pmd, pte)	\
diff --git a/arch/powerpc/include/asm/pgtable-ppc32.h b/arch/powerpc/include/asm/pgtable-ppc32.h
index f154859..de7f114 100644
--- a/arch/powerpc/include/asm/pgtable-ppc32.h
+++ b/arch/powerpc/include/asm/pgtable-ppc32.h
@@ -76,7 +76,13 @@ extern int icache_44x_need_flush;
  * are an index to the second level table.  The combined pgdir/pmd first
  * level has 2048 entries and the second level has 512 64-bit PTE entries.
  * -Matt
+ *
+ * For WRHV, the combined pgdir/pmd first level has 2 page 2048 entries
+ * and the second level has 9bit indexing into 512 elements with each element
+ * contains an 8-byte PTE
+ * -Yiming
  */
+
 /* PGDIR_SHIFT determines what a top-level page table entry can map */
 #define PGDIR_SHIFT	(PAGE_SHIFT + PTE_SHIFT)
 #define PGDIR_SIZE	(1UL << PGDIR_SHIFT)
@@ -134,8 +140,9 @@ extern int icache_44x_need_flush;
  * (hardware-defined) PowerPC PTE as closely as possible.
  */
 
-#if defined(CONFIG_40x)
-
+#if defined(CONFIG_PARAVIRT)
+#include <asm/pv_pgtable-ppc32.h>
+#elif defined(CONFIG_40x)
 /* There are several potential gotchas here.  The 40x hardware TLBLO
    field looks like this:
 
@@ -277,7 +284,7 @@ extern int icache_44x_need_flush;
 #define _PTE_NONE_MASK	0xffffffff00000000ULL
 
 
-#elif defined(CONFIG_FSL_BOOKE)
+#elif defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT)
 /*
    MMU Assist Register 3:
 
@@ -436,9 +443,15 @@ extern int icache_44x_need_flush;
 
 #ifdef CONFIG_44x
 #define _PAGE_BASE	(_PAGE_PRESENT | _PAGE_ACCESSED | _PAGE_GUARDED)
-#else
+#elif defined (CONFIG_PARAVIRT)
+/* _PAGE_BASE for CONFIG_PARAVIRT is defined in pv_def_pgtable-ppc32.h */
+#ifndef _PAGE_BASE
 #define _PAGE_BASE	(_PAGE_PRESENT | _PAGE_ACCESSED)
 #endif
+#else /* !CONFIG_PARAVIRT */
+#define _PAGE_BASE	(_PAGE_PRESENT | _PAGE_ACCESSED)
+#endif
+
 #define _PAGE_WRENABLE	(_PAGE_RW | _PAGE_DIRTY | _PAGE_HWWRITE)
 #define _PAGE_KERNEL	(_PAGE_BASE | _PAGE_SHARED | _PAGE_WRENABLE)
 
@@ -589,7 +602,7 @@ extern void add_hash_page(unsigned context, unsigned long va,
  * the old pte value.  In the 64-bit PTE case we lock around the
  * low PTE word since we expect ALL flag bits to be there
  */
-#ifndef CONFIG_PTE_64BIT
+#if !defined(CONFIG_PTE_64BIT) && !defined(CONFIG_PARAVIRT)
 static inline unsigned long pte_update(pte_t *p,
 				       unsigned long clr,
 				       unsigned long set)
@@ -618,7 +631,7 @@ static inline unsigned long pte_update(pte_t *p,
 #endif
 	return old;
 }
-#else /* CONFIG_PTE_64BIT */
+#else /* CONFIG_PTE_64BIT && CONFIG_PARAVIRT */
 /* TODO: Change that to only modify the low word and move set_pte_at()
  * out of line
  */
@@ -652,13 +665,14 @@ static inline unsigned long long pte_update(pte_t *p,
 #endif
 	return old;
 }
-#endif /* CONFIG_PTE_64BIT */
+#endif /* CONFIG_PTE_64BIT && CONFIG_PARAVIRT */
 
 /*
  * set_pte stores a linux PTE into the linux page table.
  * On machines which use an MMU hash table we avoid changing the
  * _PAGE_HASHPTE bit.
  */
+#ifndef CONFIG_PARAVIRT
 static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,
 			      pte_t *ptep, pte_t pte)
 {
@@ -668,12 +682,26 @@ static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,
 	*ptep = pte;
 #endif
 }
+#else
+static inline void native_set_pte_at(struct mm_struct *mm, unsigned long addr,
+			      pte_t *ptep, pte_t pte)
+{
+#if _PAGE_HASHPTE != 0
+	pte_update(ptep, ~_PAGE_HASHPTE, pte_val(pte) & ~_PAGE_HASHPTE);
+#else
+	*ptep = pte;
+
+#endif
+}
+
+#endif /* CONFIG_PARAVIRT */
 
 /*
  * 2.6 calls this without flushing the TLB entry; this is wrong
  * for our hash-based implementation, we fix that up here.
  */
 #define __HAVE_ARCH_PTEP_TEST_AND_CLEAR_YOUNG
+#ifndef CONFIG_PARAVIRT
 static inline int __ptep_test_and_clear_young(unsigned int context, unsigned long addr, pte_t *ptep)
 {
 	unsigned long old;
@@ -688,6 +716,21 @@ static inline int __ptep_test_and_clear_young(unsigned int context, unsigned lon
 }
 #define ptep_test_and_clear_young(__vma, __addr, __ptep) \
 	__ptep_test_and_clear_young((__vma)->vm_mm->context.id, __addr, __ptep)
+#else /* CONFIG_PARAVIRT */
+static inline int __ptep_test_and_clear_young(mm_context_t * ctx,
+                                              unsigned long addr, pte_t *ptep)
+{
+	unsigned long old;
+	old = pte_update(ptep, _PAGE_ACCESSED, 0);
+#if 0 
+        vbiVmmuTlbFlush (&vmmu_cfg, &addr, 1);
+#endif
+	return (old & _PAGE_ACCESSED) != 0;
+}
+
+#define ptep_test_and_clear_young(__vma, __addr, __ptep) \
+        __ptep_test_and_clear_young(&(__vma)->vm_mm->context.id, __addr, __ptep)
+#endif   /* CONFIG_PARAVIRT */
 
 #define __HAVE_ARCH_PTEP_GET_AND_CLEAR
 static inline pte_t ptep_get_and_clear(struct mm_struct *mm, unsigned long addr,
@@ -747,7 +790,7 @@ extern pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,
  * handler).  On everything else the pmd contains the physical address
  * of the pte page.  -- paulus
  */
-#ifndef CONFIG_BOOKE
+#if !defined(CONFIG_BOOKE) || defined(CONFIG_PARAVIRT)
 #define pmd_page_vaddr(pmd)	\
 	((unsigned long) __va(pmd_val(pmd) & PAGE_MASK))
 #define pmd_page(pmd)		\
diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c6d1ab6..76065bb 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -13,6 +13,10 @@
 #include <linux/stringify.h>
 #include <asm/cputable.h>
 
+/* Pickup paravirt specific registers */
+#if defined (CONFIG_PARAVIRT)
+#include <asm/reg_paravirt.h>
+#endif
 /* Pickup Book E specific registers. */
 #if defined(CONFIG_BOOKE) || defined(CONFIG_40x)
 #include <asm/reg_booke.h>
diff --git a/arch/powerpc/include/asm/system.h b/arch/powerpc/include/asm/system.h
index d6648c1..d4b9329 100644
--- a/arch/powerpc/include/asm/system.h
+++ b/arch/powerpc/include/asm/system.h
@@ -199,6 +199,10 @@ extern u32 booke_wdt_period;
 struct device_node;
 extern void note_scsi_host(struct device_node *, void *);
 
+#ifdef CONFIG_PARAVIRT
+#define prepare_arch_switch(next)      local_irq_disable()
+#endif
+
 extern struct task_struct *__switch_to(struct task_struct *,
 	struct task_struct *);
 #define switch_to(prev, next, last)	((last) = __switch_to((prev), (next)))
-- 
1.6.3.3

