From 4ca2f92a45cf2cb9a94fca21dbe9cb5c10cee5cd Mon Sep 17 00:00:00 2001
From: Yong Zhang <yong.zhang@windriver.com>
Date: Thu, 20 Nov 2014 16:23:14 +0800
Subject: [PATCH] aio: correct reqs_available counting

When running test case in http://marc.info/?l=linux-ext4&m=141284883914726&w=2
below call trace will be triggered:
WARNING: at fs/aio.c:350 put_ioctx+0x1e4/0x1f0()
Modules linked in: snd_hda_codec_analog snd_hda_intel iTCO_wdt acpi_cpufreq iTCO_vendor_support mperf snd_hda_codec processor snd_h
_page_alloc snd_timer snd soundcore lpc_ich ata_generic coretemp
CPU: 0 PID: 265 Comm: kworker/0:2 Not tainted 3.10.55-ltsi-WR6.0.0.0_standard #1
Hardware name: Dell Inc. OptiPlex 755                 /0Y255C, BIOS A11 08/04/2008
Workqueue: events kill_ioctx_work
 0000000000000009 ffff8800758f1d40 ffffffff818dbc81 ffff8800758f1d78
 ffffffff8103c3b1 ffff880075560000 ffff88007866bf68 ffff8800758f1fd8
 ffff88007866be00 0000160000000000 ffff8800758f1d88 ffffffff8103c48a
Call Trace:
 [<ffffffff818dbc81>] dump_stack+0x19/0x1b
 [<ffffffff8103c3b1>] warn_slowpath_common+0x61/0x80
 [<ffffffff8103c48a>] warn_slowpath_null+0x1a/0x20
 [<ffffffff811a1be4>] put_ioctx+0x1e4/0x1f0
 [<ffffffff81061990>] ? wake_up_bit+0x30/0x30
 [<ffffffff811a1c1b>] kill_ioctx_work+0x2b/0x30
 [<ffffffff81059e20>] process_one_work+0x170/0x450
 [<ffffffff8105abb1>] worker_thread+0x121/0x3a0
 [<ffffffff8105aa90>] ? manage_workers.isra.24+0x2b0/0x2b0
 [<ffffffff81060bb0>] kthread+0xc0/0xd0
 [<ffffffff81060af0>] ? kthread_create_on_node+0x120/0x120
 [<ffffffff818ea05c>] ret_from_fork+0x7c/0xb0
 [<ffffffff81060af0>] ? kthread_create_on_node+0x120/0x120
---[ end trace 146ffa8135a0559a ]---

The reason is that the fix for CVE-2014-0206 replaces some code
in fs/aio.c, but the commit 6745cb91b5ec [aio: fix aio request
leak when events are reaped by userspace] from stable tree wants
to touch the code before CVE-2014-0206, thus patch conflict happens.
And the resolution for the conflict is buggy. The patch corrects
it to the right way.

Signed-off-by: Yong Zhang <yong.zhang@windriver.com>
---
 fs/aio.c |    5 ++---
 1 files changed, 2 insertions(+), 3 deletions(-)

diff --git a/fs/aio.c b/fs/aio.c
index cd9c295..a4341f8 100644
--- a/fs/aio.c
+++ b/fs/aio.c
@@ -337,6 +337,7 @@ static void free_ioctx(struct kioctx *ctx)
 			 ? ring->tail - ring->head
 			 : ctx->nr_events - ring->head + ring->tail;
 
+		atomic_add(avail, &ctx->reqs_available);
 		ring->head = ring->tail;
 		kunmap_atomic(ring);
 
@@ -778,7 +779,7 @@ void aio_complete(struct kiocb *iocb, long res, long res2)
 put_rq:
 	/* everything turned out well, dispose of the aiocb. */
 	aio_put_req(iocb);
-	atomic_inc(&ctx->reqs_available);
+	put_reqs_available(ctx, 1);
 
 	/*
 	 * We have to order our ring_info tail store above and test
@@ -860,8 +861,6 @@ static long aio_read_events_ring(struct kioctx *ctx,
 	flush_dcache_page(ctx->ring_pages[0]);
 
 	pr_debug("%li  h%u t%u\n", ret, head, tail);
-
-	put_reqs_available(ctx, ret);
 out:
 	mutex_unlock(&ctx->ring_lock);
 
-- 
1.7.5.4

