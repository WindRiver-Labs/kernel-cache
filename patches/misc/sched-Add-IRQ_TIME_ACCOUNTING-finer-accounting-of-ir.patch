From c08117c2c501407e194604cb9147cea5da1dbe96 Mon Sep 17 00:00:00 2001
From: Li Wang <li.wang@windriver.com>
Date: Mon, 17 Feb 2014 10:53:47 +0800
Subject: [PATCH 2/3] sched: Add IRQ_TIME_ACCOUNTING, finer accounting of irq time

commit b52bfee445d315549d41eacf2fa7c156e7d153d5 upstream

s390/powerpc/ia64 have support for CONFIG_VIRT_CPU_ACCOUNTING which does
the fine granularity accounting of user, system, hardirq, softirq times.
Adding that option on archs like x86 will be challenging however, given the
state of TSC reliability on various platforms and also the overhead it will
add in syscall entry exit.

Instead, add a lighter variant that only does finer accounting of
hardirq and softirq times, providing precise irq times (instead of timer tick
based samples). This accounting is added with a new config option
CONFIG_IRQ_TIME_ACCOUNTING so that there won't be any overhead for users not
interested in paying the perf penalty.

This accounting is based on sched_clock, with the code being generic.
So, other archs may find it useful as well.

This patch just adds the core logic and does not enable this logic yet.

Signed-off-by: Venkatesh Pallipadi <venki@google.com>
Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
LKML-Reference: <1286237003-12406-5-git-send-email-venki@google.com>
Signed-off-by: Ingo Molnar <mingo@elte.hu>
Signed-off-by: Li Wang <li.wang@windriver.com>
---
 include/linux/hardirq.h |    4 +++
 include/linux/sched.h   |   15 ++++++++++++++
 init/Kconfig            |   11 ++++++++++
 kernel/sched.c          |   50 +++++++++++++++++++++++++++++++++++++++++++++++
 4 files changed, 80 insertions(+), 0 deletions(-)

diff --git a/include/linux/hardirq.h b/include/linux/hardirq.h
index b39f49d..8ba1adb 100644
--- a/include/linux/hardirq.h
+++ b/include/linux/hardirq.h
@@ -122,10 +122,14 @@ extern void synchronize_irq(unsigned int irq);
 struct task_struct;
 
 #ifndef CONFIG_VIRT_CPU_ACCOUNTING
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+extern void account_system_vtime(struct task_struct *curr);
+#else
 static inline void account_system_vtime(struct task_struct *tsk)
 {
 }
 #endif
+#endif
 
 #if defined(CONFIG_PREEMPT_RCU) && defined(CONFIG_NO_HZ)
 extern void rcu_irq_enter(void);
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 5b96d1a..2c30a36 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1629,6 +1629,21 @@ extern void sched_clock_idle_wakeup_event(u64 delta_ns);
  */
 extern unsigned long long cpu_clock(int cpu);
 
+#ifndef CONFIG_VIRT_CPU_ACCOUNTING
+#ifdef CONFIG_IRQ_TIME_ACCOUNTING
+/*
+ * An i/f to runtime opt-in for irq time accounting based off of sched_clock.
+ * The reason for this explicit opt-in is not to have perf penalty with
+ * slow sched_clocks.
+ */
+extern void enable_sched_clock_irqtime(void);
+extern void disable_sched_clock_irqtime(void);
+#else
+static inline void enable_sched_clock_irqtime(void) {}
+static inline void disable_sched_clock_irqtime(void) {}
+#endif
+#endif
+
 extern unsigned long long
 task_sched_runtime(struct task_struct *task);
 
diff --git a/init/Kconfig b/init/Kconfig
index 1c5b397..d12f6bb 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -150,6 +150,17 @@ config POSIX_MQUEUE
 
 	  If unsure, say Y.
 
+config IRQ_TIME_ACCOUNTING
+	bool "Fine granularity task level IRQ time accounting"
+	default n
+	help
+	  Select this option to enable fine granularity task irq time
+	  accounting. This is done by reading a timestamp on each
+	  transitions between softirq and hardirq state, so there can be a
+	  small performance impact.
+
+	  If in doubt, say N here.
+
 config BSD_PROCESS_ACCT
 	bool "BSD Process Accounting"
 	help
diff --git a/kernel/sched.c b/kernel/sched.c
index aca05c3..d1e94ac 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -1590,6 +1590,56 @@ static void cfs_rq_set_shares(struct cfs_rq *cfs_rq, unsigned long shares)
 #endif
 
 #include "sched_stats.h"
+
+#if !defined(CONFIG_VIRT_CPU_ACCOUNTING) && defined(CONFIG_IRQ_TIME_ACCOUNTING)
+
+static DEFINE_PER_CPU(u64, cpu_hardirq_time);
+static DEFINE_PER_CPU(u64, cpu_softirq_time);
+
+static DEFINE_PER_CPU(u64, irq_start_time);
+static int sched_clock_irqtime;
+
+void enable_sched_clock_irqtime(void)
+{
+	sched_clock_irqtime = 1;
+}
+
+void disable_sched_clock_irqtime(void)
+{
+	sched_clock_irqtime = 0;
+}
+
+void account_system_vtime(struct task_struct *curr)
+{
+	unsigned long flags;
+	int cpu;
+	u64 now, delta;
+
+	if (!sched_clock_irqtime)
+		return;
+
+	local_irq_save(flags);
+
+	now = sched_clock();
+	cpu = smp_processor_id();
+	delta = now - per_cpu(irq_start_time, cpu);
+	per_cpu(irq_start_time, cpu) = now;
+	/*
+	 * We do not account for softirq time from ksoftirqd here.
+	 * We want to continue accounting softirq time to ksoftirqd thread
+	 * in that case, so as not to confuse scheduler with a special task
+	 * that do not consume any time, but still wants to run.
+	 */
+	if (hardirq_count())
+		per_cpu(cpu_hardirq_time, cpu) += delta;
+	else if (softirq_count() && !(curr->flags & PF_KSOFTIRQD))
+		per_cpu(cpu_softirq_time, cpu) += delta;
+
+	local_irq_restore(flags);
+}
+
+#endif
+
 #include "sched_idletask.c"
 #include "sched_fair.c"
 #include "sched_rt.c"
-- 
1.7.0

