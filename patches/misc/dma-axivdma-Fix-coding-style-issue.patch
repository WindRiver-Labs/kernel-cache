From 4c93531ef7b88acac99a138433ed3834ba147b77 Mon Sep 17 00:00:00 2001
From: Michal Simek <michal.simek@xilinx.com>
Date: Wed, 15 May 2013 10:22:46 +0200
Subject: [PATCH 109/628] dma: axivdma: Fix coding style issue

git://github.com/Xilinx/linux-xlnx.git xilinx-v14.7
commit 13c2ec618fa84b01aa583f6e0698fd5cf3b7380e

Avoid CamelCase.

Signed-off-by: Michal Simek <michal.simek@xilinx.com>
Signed-off-by: Liming Wang <liming.wang@windriver.com>
---
 drivers/dma/xilinx/xilinx_axicdma.c |   20 ++++++++++----------
 drivers/dma/xilinx/xilinx_axidma.c  |   16 ++++++++--------
 drivers/dma/xilinx/xilinx_axivdma.c |   28 ++++++++++++++--------------
 3 files changed, 32 insertions(+), 32 deletions(-)

diff --git a/drivers/dma/xilinx/xilinx_axicdma.c b/drivers/dma/xilinx/xilinx_axicdma.c
index 744c363..3b89249 100644
--- a/drivers/dma/xilinx/xilinx_axicdma.c
+++ b/drivers/dma/xilinx/xilinx_axicdma.c
@@ -161,8 +161,8 @@ struct xilinx_cdma_chan {
 	enum dma_transfer_direction direction;	/* Transfer direction */
 	int max_len;				/* Max data len per transfer */
 	int is_lite;				/* Whether is light build */
-	int has_SG;				/* Support scatter transfers */
-	int has_DRE;				/* For unaligned transfers */
+	int has_sg;				/* Support scatter transfers */
+	int has_dre;				/* For unaligned transfers */
 	int err;				/* Channel has errors */
 	struct tasklet_struct tasklet;		/* Cleanup work after irq */
 	u32 feature;				/* IP feature */
@@ -371,7 +371,7 @@ static void xilinx_cdma_start_transfer(struct xilinx_cdma_chan *chan)
 	desch = list_first_entry(&chan->pending_list,
 			struct xilinx_cdma_desc_sw, node);
 
-	if (chan->has_SG) {
+	if (chan->has_sg) {
 
 		/* If hybrid mode, append pending list to active list */
 		desct = container_of(chan->pending_list.prev,
@@ -443,7 +443,7 @@ static void xilinx_cdma_update_completed_cookie(struct xilinx_cdma_chan *chan)
 
 	/* Get the last completed descriptor, update the cookie to that */
 	list_for_each_entry(desc, &chan->active_list, node) {
-		if (chan->has_SG) {
+		if (chan->has_sg) {
 			hw = &desc->hw;
 
 			/* If a BD has no status bits set, hw has it */
@@ -491,7 +491,7 @@ static int cdma_init(struct xilinx_cdma_chan *chan)
 	}
 
 	/* For Axi CDMA, always do sg transfers if sg mode is built in */
-	if ((chan->feature & XILINX_DMA_IP_CDMA) && chan->has_SG)
+	if ((chan->feature & XILINX_DMA_IP_CDMA) && chan->has_sg)
 		CDMA_OUT(&chan->regs->cr, tmp | XILINX_CDMA_CR_SGMODE_MASK);
 
 	return 0;
@@ -699,7 +699,7 @@ static struct dma_async_tx_descriptor *xilinx_cdma_prep_memcpy(
 	 * If build does not have Data Realignment Engine (DRE),
 	 * src has to be aligned
 	 */
-	if (!chan->has_DRE) {
+	if (!chan->has_dre) {
 		if ((dma_src &
 			(chan->feature & XILINX_CDMA_FTR_DATA_WIDTH_MASK)) ||
 			(dma_dst &
@@ -879,7 +879,7 @@ static int xilinx_cdma_chan_probe(struct xilinx_cdma_device *xdev,
 
 	value = of_get_property(node, "xlnx,include-dre", NULL);
 	if (value)
-		chan->has_DRE = be32_to_cpup(value);
+		chan->has_dre = be32_to_cpup(value);
 
 	value = of_get_property(node, "xlnx,datawidth", NULL);
 	if (value) {
@@ -887,7 +887,7 @@ static int xilinx_cdma_chan_probe(struct xilinx_cdma_device *xdev,
 
 		/* If data width is greater than 8 bytes, DRE is not in hw */
 		if (width > 8)
-			chan->has_DRE = 0;
+			chan->has_dre = 0;
 
 		chan->feature |= width - 1;
 	}
@@ -899,7 +899,7 @@ static int xilinx_cdma_chan_probe(struct xilinx_cdma_device *xdev,
 	chan->direction = DMA_MEM_TO_MEM;
 	chan->start_transfer = xilinx_cdma_start_transfer;
 
-	chan->has_SG = (xdev->feature & XILINX_CDMA_FTR_HAS_SG) >>
+	chan->has_sg = (xdev->feature & XILINX_CDMA_FTR_HAS_SG) >>
 			XILINX_CDMA_FTR_HAS_SG_SHIFT;
 
 	value = of_get_property(node, "xlnx,lite-mode", NULL);
@@ -931,7 +931,7 @@ static int xilinx_cdma_chan_probe(struct xilinx_cdma_device *xdev,
 		(device_id << XILINX_CDMA_DEVICE_ID_SHIFT);
 	chan->common.private = (void *)&(chan->private);
 
-	if (!chan->has_DRE)
+	if (!chan->has_dre)
 		xdev->common.copy_align = my_log(width);
 
 	chan->dev = xdev->dev;
diff --git a/drivers/dma/xilinx/xilinx_axidma.c b/drivers/dma/xilinx/xilinx_axidma.c
index b4a85c7..474eb04 100644
--- a/drivers/dma/xilinx/xilinx_axidma.c
+++ b/drivers/dma/xilinx/xilinx_axidma.c
@@ -178,8 +178,8 @@ struct xilinx_dma_chan {
 					/* Transfer direction */
 	int max_len;			/* Maximum data len per transfer */
 	int is_lite;			/* Whether is light build */
-	int has_SG;			/* Support scatter transfers */
-	int has_DRE;			/* Support unaligned transfers */
+	int has_sg;			/* Support scatter transfers */
+	int has_dre;			/* Support unaligned transfers */
 	int err;			/* Channel has errors */
 	struct tasklet_struct tasklet;	/* Cleanup work after irq */
 	u32 feature;			/* IP feature */
@@ -440,7 +440,7 @@ static void xilinx_dma_start_transfer(struct xilinx_dma_chan *chan)
 	if (chan->err)
 		goto out_unlock;
 
-	if (chan->has_SG) {
+	if (chan->has_sg) {
 		desch = list_first_entry(&chan->pending_list,
 				struct xilinx_dma_desc_sw, node);
 
@@ -529,7 +529,7 @@ static void xilinx_dma_update_completed_cookie(struct xilinx_dma_chan *chan)
 
 	/* Get the last completed descriptor, update the cookie to that */
 	list_for_each_entry(desc, &chan->active_list, node) {
-		if (chan->has_SG) {
+		if (chan->has_sg) {
 			hw = &desc->hw;
 
 			/* If a BD has no status bits set, hw has it */
@@ -981,7 +981,7 @@ static int xilinx_dma_chan_probe(struct xilinx_dma_device *xdev,
 
 	value = of_get_property(node, "xlnx,include-dre", NULL);
 	if (value)
-		chan->has_DRE = be32_to_cpup(value);
+		chan->has_dre = be32_to_cpup(value);
 
 	value = of_get_property(node, "xlnx,datawidth", NULL);
 	if (value) {
@@ -989,7 +989,7 @@ static int xilinx_dma_chan_probe(struct xilinx_dma_device *xdev,
 
 		/* If data width is greater than 8 bytes, DRE is not in hw */
 		if (width > 8)
-			chan->has_DRE = 0;
+			chan->has_dre = 0;
 
 		chan->feature |= width - 1;
 	}
@@ -999,7 +999,7 @@ static int xilinx_dma_chan_probe(struct xilinx_dma_device *xdev,
 		device_id = be32_to_cpup(value);
 
 	if (feature & XILINX_DMA_IP_DMA) {
-		chan->has_SG = (xdev->feature & XILINX_DMA_FTR_HAS_SG) >>
+		chan->has_sg = (xdev->feature & XILINX_DMA_FTR_HAS_SG) >>
 					XILINX_DMA_FTR_HAS_SG_SHIFT;
 
 		chan->start_transfer = xilinx_dma_start_transfer;
@@ -1031,7 +1031,7 @@ static int xilinx_dma_chan_probe(struct xilinx_dma_device *xdev,
 		(device_id << XILINX_DMA_DEVICE_ID_SHIFT);
 	chan->common.private = (void *)&(chan->private);
 
-	if (!chan->has_DRE)
+	if (!chan->has_dre)
 		xdev->common.copy_align = my_log(width);
 
 	chan->dev = xdev->dev;
diff --git a/drivers/dma/xilinx/xilinx_axivdma.c b/drivers/dma/xilinx/xilinx_axivdma.c
index 4720757..f1317ed 100644
--- a/drivers/dma/xilinx/xilinx_axivdma.c
+++ b/drivers/dma/xilinx/xilinx_axivdma.c
@@ -199,8 +199,8 @@ struct xilinx_vdma_chan {
 	int max_len;				/* Max data len per transfer */
 	int is_lite;				/* Whether is light build */
 	int num_frms;				/* Number of frames */
-	int has_SG;				/* Support scatter transfers */
-	int has_DRE;				/* For unaligned transfers */
+	int has_sg;				/* Support scatter transfers */
+	int has_dre;				/* For unaligned transfers */
 	int genlock;				/* Support genlock mode */
 	int err;				/* Channel has errors */
 	struct tasklet_struct tasklet;		/* Cleanup work after irq */
@@ -450,7 +450,7 @@ static void xilinx_vdma_start_transfer(struct xilinx_vdma_chan *chan)
 		goto out_unlock;
 
 	/* If it is SG mode and hardware is busy, cannot submit */
-	if (chan->has_SG && dma_is_running(chan) && !dma_is_idle(chan)) {
+	if (chan->has_sg && dma_is_running(chan) && !dma_is_idle(chan)) {
 		dev_dbg(chan->dev, "DMA controller still busy\n");
 		goto out_unlock;
 	}
@@ -462,7 +462,7 @@ static void xilinx_vdma_start_transfer(struct xilinx_vdma_chan *chan)
 	if (chan->err)
 		goto out_unlock;
 
-	if (chan->has_SG) {
+	if (chan->has_sg) {
 		desch = list_first_entry(&chan->pending_list,
 				struct xilinx_vdma_desc_sw, node);
 
@@ -485,7 +485,7 @@ static void xilinx_vdma_start_transfer(struct xilinx_vdma_chan *chan)
 	 * With SG, start with circular mode, so that BDs can be fetched.
 	 * In direct register mode, if not parking, enable circular mode
 	 */
-	if ((chan->has_SG) || (!config->park))
+	if ((chan->has_sg) || (!config->park))
 		reg |= XILINX_VDMA_CIRC_EN;
 
 	if (config->park)
@@ -531,7 +531,7 @@ static void xilinx_vdma_start_transfer(struct xilinx_vdma_chan *chan)
 	}
 
 	/* Start the transfer */
-	if (chan->has_SG)
+	if (chan->has_sg)
 		VDMA_OUT(&chan->regs->tdr, desct->async_tx.phys);
 	else
 		VDMA_OUT(&chan->addr_regs->vsize, config->vsize);
@@ -816,7 +816,7 @@ static struct dma_async_tx_descriptor *xilinx_vdma_prep_slave_sg(
 		return NULL;
 	}
 
-	if (!chan->has_SG) {
+	if (!chan->has_sg) {
 		VDMA_OUT(&chan->addr_regs->hsize, chan->config.hsize);
 		VDMA_OUT(&chan->addr_regs->frmdly_stride,
 			chan->config.frm_dly << XILINX_VDMA_FRMDLY_SHIFT |
@@ -840,7 +840,7 @@ static struct dma_async_tx_descriptor *xilinx_vdma_prep_slave_sg(
 		hw = &(new->hw);
 
 		dma_src = sg_dma_address(sg);
-		if (chan->has_SG) {
+		if (chan->has_sg) {
 			hw->buf_addr = dma_src;
 
 			/* Fill in the descriptor */
@@ -1073,7 +1073,7 @@ static int xilinx_vdma_chan_probe(struct xilinx_vdma_device *xdev,
 
 	value = of_get_property(node, "xlnx,include-dre", NULL);
 	if (value)
-		chan->has_DRE = be32_to_cpup(value);
+		chan->has_dre = be32_to_cpup(value);
 
 	value = (int *)of_get_property(node, "xlnx,genlock-mode", NULL);
 	if (value)
@@ -1085,7 +1085,7 @@ static int xilinx_vdma_chan_probe(struct xilinx_vdma_device *xdev,
 
 		/* If data width is greater than 8 bytes, DRE is not in hw */
 		if (width > 8)
-			chan->has_DRE = 0;
+			chan->has_dre = 0;
 
 		chan->feature |= width - 1;
 	}
@@ -1099,13 +1099,13 @@ static int xilinx_vdma_chan_probe(struct xilinx_vdma_device *xdev,
 
 	chan->start_transfer = xilinx_vdma_start_transfer;
 
-	chan->has_SG = (xdev->feature & XILINX_VDMA_FTR_HAS_SG) >>
+	chan->has_sg = (xdev->feature & XILINX_VDMA_FTR_HAS_SG) >>
 		XILINX_VDMA_FTR_HAS_SG_SHIFT;
 
 	if (of_device_is_compatible(node,
 			"xlnx,axi-vdma-mm2s-channel")) {
 		chan->direction = DMA_MEM_TO_DEV;
-		if (!chan->has_SG) {
+		if (!chan->has_sg) {
 			chan->addr_regs = (struct vdma_addr_regs *)
 			    ((u32)xdev->regs +
 				 XILINX_VDMA_DIRECT_REG_OFFSET);
@@ -1118,7 +1118,7 @@ static int xilinx_vdma_chan_probe(struct xilinx_vdma_device *xdev,
 
 	if (of_device_is_compatible(node, "xlnx,axi-vdma-s2mm-channel")) {
 		chan->direction = DMA_DEV_TO_MEM;
-		if (!chan->has_SG) {
+		if (!chan->has_sg) {
 			chan->addr_regs = (struct vdma_addr_regs *)
 			    ((u32)xdev->regs +
 				XILINX_VDMA_DIRECT_REG_OFFSET +
@@ -1147,7 +1147,7 @@ static int xilinx_vdma_chan_probe(struct xilinx_vdma_device *xdev,
 		(device_id << XILINX_VDMA_DEVICE_ID_SHIFT);
 	chan->common.private = (void *)&(chan->private);
 
-	if (!chan->has_DRE)
+	if (!chan->has_dre)
 		xdev->common.copy_align = my_log(width);
 
 	chan->dev = xdev->dev;
-- 
1.7.5.4

