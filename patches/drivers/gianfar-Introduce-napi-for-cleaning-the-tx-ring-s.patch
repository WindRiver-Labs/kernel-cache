From 408683cde00e13e11f7a292a9a298bc728be692a Mon Sep 17 00:00:00 2001
From: Xufeng Zhang <xufeng.zhang@windriver.com>
Date: Tue, 9 Aug 2011 19:22:47 +0800
Subject: [PATCH 05/47] gianfar: Introduce napi for cleaning the tx ring(s)

Introduce napi for cleaning the tx rings, thus separating out
the rx cleaning process from tx cleaning, it will help in improving
the dual core performance scenarios.

Extracted from vendor drop QorIQ-NONDPAA-SDK-V1-20110429_ltib.iso
linux-2.6.35-qoriq-gianfar-Introduce-napi-for-cleaning-the.patch.

Signed-off-by: Sandeep Gopalpet <sandeep.kumar@freescale.com>
Signed-off-by: Jiajun Wu <b06378@freescale.com>
Integrated-by: Xufeng Zhang <xufeng.zhang@windriver.com>
---
 drivers/net/Kconfig   |    8 ++
 drivers/net/gianfar.c |  193 ++++++++++++++++++++++++++++++++++++++++++++++++-
 drivers/net/gianfar.h |   13 ++++
 3 files changed, 213 insertions(+), 1 deletions(-)

diff --git a/drivers/net/Kconfig b/drivers/net/Kconfig
index 4d41360..a6a6ea2 100644
--- a/drivers/net/Kconfig
+++ b/drivers/net/Kconfig
@@ -2406,6 +2406,14 @@ config GIANFAR
 	  This driver supports the Gigabit TSEC on the MPC83xx, MPC85xx,
 	  and MPC86xx family of chips, and the FEC on the 8540.
 
+config GIANFAR_TXNAPI
+	default n
+	bool "Introduce seperate tx_napi for cleaning the tx ring(V 0.0.1) (EXPERIMENTAL)"
+	depends on GIANFAR && EXPERIMENTAL
+	help
+	  Selecting this option introduces a seperate TX NAPI for cleaning the
+	  tx ring(s).
+
 config GIANFAR_L2SRAM
 	bool "Selecting L2sram bd allocation"
 	depends on (GIANFAR && FSL_SOC_BOOKE)
diff --git a/drivers/net/gianfar.c b/drivers/net/gianfar.c
index f937314..3def778 100644
--- a/drivers/net/gianfar.c
+++ b/drivers/net/gianfar.c
@@ -130,12 +130,21 @@ static void free_skb_resources(struct gfar_private *priv);
 static void gfar_set_multi(struct net_device *dev);
 static void gfar_set_hash_for_addr(struct net_device *dev, u8 *addr);
 static void gfar_configure_serdes(struct net_device *dev);
+#ifdef CONFIG_GIANFAR_TXNAPI
+static int gfar_poll_tx(struct napi_struct *napi, int budget);
+static int gfar_poll_rx(struct napi_struct *napi, int budget);
+#else
 static int gfar_poll(struct napi_struct *napi, int budget);
+#endif
 #ifdef CONFIG_NET_POLL_CONTROLLER
 static void gfar_netpoll(struct net_device *dev);
 #endif
 int gfar_clean_rx_ring(struct gfar_priv_rx_q *rx_queue, int rx_work_limit);
+#ifdef CONFIG_GIANFAR_TXNAPI
+static int gfar_clean_tx_ring(struct gfar_priv_tx_q *tx_queue, int tx_work_limit);
+#else
 static int gfar_clean_tx_ring(struct gfar_priv_tx_q *tx_queue);
+#endif
 static int gfar_process_frame(struct net_device *dev, struct sk_buff *skb,
 			      int amount_pull);
 static void gfar_vlan_rx_register(struct net_device *netdev,
@@ -636,17 +645,30 @@ static void unmap_group_regs(struct gfar_private *priv)
 static void disable_napi(struct gfar_private *priv)
 {
 	int i = 0;
-
+#ifdef CONFIG_GIANFAR_TXNAPI
+	for (i = 0; i < priv->num_grps; i++) {
+		napi_disable(&priv->gfargrp[i].napi_tx);
+		napi_disable(&priv->gfargrp[i].napi_rx);
+	}
+#else
 	for (i = 0; i < priv->num_grps; i++)
 		napi_disable(&priv->gfargrp[i].napi);
+#endif
 }
 
 static void enable_napi(struct gfar_private *priv)
 {
 	int i = 0;
 
+#ifdef CONFIG_GIANFAR_TXNAPI
+	for (i = 0; i < priv->num_grps; i++) {
+		napi_enable(&priv->gfargrp[i].napi_tx);
+		napi_enable(&priv->gfargrp[i].napi_rx);
+	}
+#else
 	for (i = 0; i < priv->num_grps; i++)
 		napi_enable(&priv->gfargrp[i].napi);
+#endif
 }
 
 static int gfar_parse_group(struct device_node *np,
@@ -1097,9 +1119,19 @@ static int gfar_probe(struct of_device *ofdev,
 	dev->netdev_ops = &gfar_netdev_ops;
 	dev->ethtool_ops = &gfar_ethtool_ops;
 
+#ifdef CONFIG_GIANFAR_TXNAPI
+	/* Seperate napi for tx and rx for each group */
+	for (i = 0; i < priv->num_grps; i++) {
+		netif_napi_add(dev, &priv->gfargrp[i].napi_tx, gfar_poll_tx,
+				GFAR_DEV_WEIGHT);
+		netif_napi_add(dev, &priv->gfargrp[i].napi_rx, gfar_poll_rx,
+				GFAR_DEV_WEIGHT);
+	}
+#else
 	/* Register for napi ...We are registering NAPI for each grp */
 	for (i = 0; i < priv->num_grps; i++)
 		netif_napi_add(dev, &priv->gfargrp[i].napi, gfar_poll, GFAR_DEV_WEIGHT);
+#endif
 
 	if (priv->device_flags & FSL_GIANFAR_DEV_HAS_CSUM) {
 		priv->rx_csum_enable = 1;
@@ -2790,7 +2822,11 @@ static void gfar_timeout(struct net_device *dev)
 }
 
 /* Interrupt Handler for Transmit complete */
+#ifdef CONFIG_GIANFAR_TXNAPI
+static int gfar_clean_tx_ring(struct gfar_priv_tx_q *tx_queue, int tx_work_limit)
+#else
 static int gfar_clean_tx_ring(struct gfar_priv_tx_q *tx_queue)
+#endif
 {
 	struct net_device *dev = tx_queue->dev;
 	struct gfar_private *priv = netdev_priv(dev);
@@ -2810,7 +2846,11 @@ static int gfar_clean_tx_ring(struct gfar_priv_tx_q *tx_queue)
 	bdp = tx_queue->dirty_tx;
 	skb_dirtytx = tx_queue->skb_dirtytx;
 
+#ifdef CONFIG_GIANFAR_TXNAPI
+	while ((skb = tx_queue->tx_skbuff[skb_dirtytx]) && !(--tx_work_limit < 0)) {
+#else
 	while ((skb = tx_queue->tx_skbuff[skb_dirtytx])) {
+#endif
 		unsigned long flags;
 
 		frags = skb_shinfo(skb)->nr_frags;
@@ -2857,9 +2897,13 @@ static int gfar_clean_tx_ring(struct gfar_priv_tx_q *tx_queue)
 			TX_RING_MOD_MASK(tx_ring_size);
 
 		howmany++;
+#ifndef CONFIG_GIANFAR_TXNAPI
 		spin_lock_irqsave(&tx_queue->txlock, flags);
 		tx_queue->num_txbdfree += frags + 1;
 		spin_unlock_irqrestore(&tx_queue->txlock, flags);
+#else
+		tx_queue->num_txbdfree += nr_txbds;
+#endif
 	}
 
 	/* If we freed a buffer, we can restart transmission, if necessary */
@@ -2873,6 +2917,35 @@ static int gfar_clean_tx_ring(struct gfar_priv_tx_q *tx_queue)
 	return howmany;
 }
 
+#ifdef CONFIG_GIANFAR_TXNAPI
+static void gfar_schedule_cleanup_rx(struct gfar_priv_grp *gfargrp)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&gfargrp->grplock, flags);
+	if (napi_schedule_prep(&gfargrp->napi_rx)) {
+		gfar_write(&gfargrp->regs->imask, IMASK_RX_DISABLED);
+		__napi_schedule(&gfargrp->napi_rx);
+	} else {
+		gfar_write(&gfargrp->regs->ievent, IEVENT_RX_MASK);
+	}
+	spin_unlock_irqrestore(&gfargrp->grplock, flags);
+}
+
+static void gfar_schedule_cleanup_tx(struct gfar_priv_grp *gfargrp)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&gfargrp->grplock, flags);
+	if (napi_schedule_prep(&gfargrp->napi_tx)) {
+		gfar_write(&gfargrp->regs->imask, IMASK_TX_DISABLED);
+		__napi_schedule(&gfargrp->napi_tx);
+	} else {
+		gfar_write(&gfargrp->regs->ievent, IEVENT_TX_MASK);
+	}
+	spin_unlock_irqrestore(&gfargrp->grplock, flags);
+}
+#else
 static void gfar_schedule_cleanup(struct gfar_priv_grp *gfargrp)
 {
 	unsigned long flags;
@@ -2891,11 +2964,16 @@ static void gfar_schedule_cleanup(struct gfar_priv_grp *gfargrp)
 	spin_unlock_irqrestore(&gfargrp->grplock, flags);
 
 }
+#endif
 
 /* Interrupt Handler for Transmit complete */
 static irqreturn_t gfar_transmit(int irq, void *grp_id)
 {
+#ifdef CONFIG_GIANFAR_TXNAPI
+	gfar_schedule_cleanup_tx((struct gfar_priv_grp *)grp_id);
+#else
 	gfar_schedule_cleanup((struct gfar_priv_grp *)grp_id);
+#endif
 	return IRQ_HANDLED;
 }
 
@@ -3067,7 +3145,11 @@ irqreturn_t gfar_receive(int irq, void *grp_id)
 		return IRQ_HANDLED;
 	}
 
+#ifdef CONFIG_GIANFAR_TXNAPI
+	gfar_schedule_cleanup_rx((struct gfar_priv_grp *)grp_id);
+#else
 	gfar_schedule_cleanup((struct gfar_priv_grp *)grp_id);
+#endif
 	return IRQ_HANDLED;
 }
 
@@ -3223,6 +3305,114 @@ int gfar_clean_rx_ring(struct gfar_priv_rx_q *rx_queue, int rx_work_limit)
 	return howmany;
 }
 
+#ifdef CONFIG_GIANFAR_TXNAPI
+static int gfar_poll_tx(struct napi_struct *napi, int budget)
+{
+	struct gfar_priv_grp *gfargrp = container_of(napi,
+					struct gfar_priv_grp, napi_tx);
+	struct gfar_private *priv = gfargrp->priv;
+	struct gfar __iomem *regs = gfargrp->regs;
+	struct gfar_priv_tx_q *tx_queue = NULL;
+	int budget_per_queue = 0, tx_cleaned = 0, i = 0;
+	int left_over_budget = budget, num_queues = 0;
+	int tx_cleaned_per_queue = 0;
+	unsigned long serviced_queues = 0;
+	unsigned long flags;
+	u32 imask;
+
+	num_queues = gfargrp->num_tx_queues;
+	budget_per_queue = budget/num_queues;
+
+	gfar_write(&regs->ievent, IEVENT_TX_MASK);
+
+	while (num_queues && left_over_budget) {
+		budget_per_queue = left_over_budget/num_queues;
+		left_over_budget = 0;
+
+		for_each_set_bit(i, &gfargrp->tx_bit_map, priv->num_tx_queues) {
+			if (test_bit(i, &serviced_queues))
+				continue;
+			tx_queue = priv->tx_queue[i];
+			if (spin_trylock_irqsave(&tx_queue->txlock, flags)) {
+				tx_cleaned_per_queue =
+					gfar_clean_tx_ring(tx_queue,
+							budget_per_queue);
+				spin_unlock_irqrestore(&tx_queue->txlock,
+							flags);
+			}
+			tx_cleaned += tx_cleaned_per_queue;
+			if (tx_cleaned_per_queue < budget_per_queue) {
+				left_over_budget = left_over_budget +
+					(budget_per_queue - tx_cleaned_per_queue);
+				set_bit(i, &serviced_queues);
+				num_queues--;
+			}
+		}
+	}
+
+	if (tx_cleaned < budget) {
+		napi_complete(napi);
+		imask = gfar_read(&regs->imask);
+		imask |= IMASK_DEFAULT_TX;
+		gfar_write(&regs->imask, imask);
+		gfar_configure_tx_coalescing(priv, gfargrp->tx_bit_map);
+	}
+
+	return tx_cleaned;
+}
+
+static int gfar_poll_rx(struct napi_struct *napi, int budget)
+{
+	struct gfar_priv_grp *gfargrp = container_of(napi,
+			struct gfar_priv_grp, napi_rx);
+	struct gfar_private *priv = gfargrp->priv;
+	struct gfar __iomem *regs = gfargrp->regs;
+	struct gfar_priv_rx_q *rx_queue = NULL;
+	int rx_cleaned = 0, budget_per_queue = 0, rx_cleaned_per_queue = 0;
+	int i, left_over_budget = budget, num_queues = 0;
+	unsigned long serviced_queues = 0;
+	u32 imask;
+
+	num_queues = gfargrp->num_rx_queues;
+	budget_per_queue = budget/num_queues;
+
+	gfar_write(&regs->ievent, IEVENT_RX_MASK);
+
+	while (num_queues && left_over_budget) {
+		budget_per_queue = left_over_budget/num_queues;
+		left_over_budget = 0;
+		for_each_set_bit(i, &gfargrp->rx_bit_map, priv->num_rx_queues) {
+			if (test_bit(i, &serviced_queues))
+				continue;
+			rx_queue = priv->rx_queue[i];
+			rx_cleaned_per_queue = gfar_clean_rx_ring(rx_queue,
+							budget_per_queue);
+			rx_cleaned += rx_cleaned_per_queue;
+			if (rx_cleaned_per_queue < budget_per_queue) {
+				left_over_budget = left_over_budget +
+					(budget_per_queue - rx_cleaned_per_queue);
+				set_bit(i, &serviced_queues);
+				num_queues--;
+			}
+		}
+	}
+
+	if (rx_cleaned < budget) {
+		napi_complete(napi);
+
+		/* Clear the halt bit in RSTAT */
+		gfar_write(&regs->rstat, gfargrp->rstat);
+
+		imask = gfar_read(&regs->imask);
+		imask |= IMASK_DEFAULT_RX;
+		gfar_write(&regs->imask, imask);
+
+		gfar_configure_rx_coalescing(priv, gfargrp->rx_bit_map);
+	}
+
+	return rx_cleaned;
+}
+#else
 static int gfar_poll(struct napi_struct *napi, int budget)
 {
 	struct gfar_priv_grp *gfargrp = container_of(napi,
@@ -3286,6 +3476,7 @@ static int gfar_poll(struct napi_struct *napi, int budget)
 
 	return rx_cleaned;
 }
+#endif
 
 #ifdef CONFIG_NET_POLL_CONTROLLER
 /*
diff --git a/drivers/net/gianfar.h b/drivers/net/gianfar.h
index 0464ce7..16fc35f 100644
--- a/drivers/net/gianfar.h
+++ b/drivers/net/gianfar.h
@@ -413,6 +413,14 @@ extern const char gfar_driver_version[];
 #define IMASK_RTX_DISABLED ((~(IMASK_RXFEN0 | IMASK_TXFEN | IMASK_BSY)) \
 			   & IMASK_DEFAULT)
 
+#ifdef CONFIG_GIANFAR_TXNAPI
+#define IMASK_DEFAULT_TX	(IMASK_TXFEN | IMASK_TXBEN)
+#define IMASK_DEFAULT_RX	(IMASK_RXFEN0 | IMASK_BSY)
+#define IMASK_RX_DISABLED	((~IMASK_DEFAULT_RX) \
+				& IMASK_DEFAULT)
+#define IMASK_TX_DISABLED	((~IMASK_DEFAULT_TX) \
+				& IMASK_DEFAULT)
+#endif
 /* Fifo management */
 #define FIFO_TX_THR_MASK	0x01ff
 #define FIFO_TX_STARVE_MASK	0x01ff
@@ -1145,7 +1153,12 @@ struct gfar_priv_rx_q {
 
 struct gfar_priv_grp {
 	spinlock_t grplock __attribute__ ((aligned (SMP_CACHE_BYTES)));
+#ifdef CONFIG_GIANFAR_TXNAPI
+	struct napi_struct napi_tx;
+	struct napi_struct napi_rx;
+#else
 	struct	napi_struct napi;
+#endif
 	struct gfar_private *priv;
 	struct gfar __iomem *regs;
 	unsigned int grp_id;
-- 
1.7.0.2

