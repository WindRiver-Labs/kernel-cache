From 57b9a6bdb9bc827b2b7f72998a2b043af6202827 Mon Sep 17 00:00:00 2001
From: Xufeng Zhang <xufeng.zhang@windriver.com>
Date: Tue, 28 Jun 2011 14:45:50 +0800
Subject: [PATCH 05/47] talitos: Adds the support for descriptor recycling

Update the current descriptor allocation and deallocation methodolgy with
a recyling mechanism. This patch allows the descriptors in talitos driver
can be used and avoid un-necessary allocation and free of descriptors.

Extracted from vendor drop QorIQ-NONDPAA-SDK-V1-20110429_ltib.iso
linux-2.6.35-qoriq-talitos-Adds-the-support-for-descriptor.patch.

Signed-off-by: Sandeep Malik <Sandeep.Malik@freescale.com>
Integrated-by: Xufeng Zhang <xufeng.zhang@windriver.com>
---
 drivers/crypto/talitos.c |   63 ++++++++++++++++++++++++++++++++++++++++------
 1 files changed, 55 insertions(+), 8 deletions(-)

diff --git a/drivers/crypto/talitos.c b/drivers/crypto/talitos.c
index eeb6f5e..7b777df 100644
--- a/drivers/crypto/talitos.c
+++ b/drivers/crypto/talitos.c
@@ -64,6 +64,8 @@
 #define MAP_ARRAY(chan_no)     (3 << (chan_no * 2))
 #define MAP_ARRAY_DONE(chan_no)        (1 << (chan_no * 2))
 
+#define MAX_IPSEC_RECYCLE_DESC 64
+#define MAX_DESC_LEN   160
 
 /* descriptor pointer entry */
 struct talitos_ptr {
@@ -146,6 +148,12 @@ struct talitos_private {
 	u8 core_num_chan[MAX_GROUPS];
 	/* channels numbers of channels mapped to a core */
 	u8 core_chan_no[MAX_GROUPS][MAX_CHAN] ____cacheline_aligned;
+	 /* pointer to the cache pool */
+	struct kmem_cache *netcrypto_cache;
+	/* pointer to edescriptor recycle queue */
+	struct talitos_edesc *edesc_rec_queue[NR_CPUS][MAX_IPSEC_RECYCLE_DESC];
+	/* index in edesc recycle queue */
+	u8 curr_edesc[MAX_GROUPS];
 
 	/* request callback napi */
 	struct napi_struct *done_task;	
@@ -185,6 +193,34 @@ struct talitos_edesc {
 #define TALITOS_FTR_SRC_LINK_TBL_LEN_INCLUDES_EXTENT 0x00000001
 #define TALITOS_FTR_HW_AUTH_CHECK 0x00000002
 
+struct talitos_edesc *crypto_edesc_alloc(int len, int flags,
+					struct talitos_private *priv)
+{
+	u32 smp_processor_id = smp_processor_id();
+	u32 current_edesc = priv->curr_edesc[smp_processor_id];
+	if (unlikely(current_edesc == 0)) {
+		return kmem_cache_alloc(priv->netcrypto_cache,
+					GFP_KERNEL | flags);
+	} else {
+		priv->curr_edesc[smp_processor_id] = current_edesc - 1;
+		return priv->edesc_rec_queue[smp_processor_id]
+					[current_edesc - 1];
+	}
+}
+void crypto_edesc_free(struct talitos_edesc *edesc,
+			struct talitos_private *priv)
+{
+	u32 smp_processor_id = smp_processor_id();
+	u32 current_edesc = priv->curr_edesc[smp_processor_id];
+	if (unlikely(current_edesc == (MAX_IPSEC_RECYCLE_DESC - 1))) {
+		kmem_cache_free(priv->netcrypto_cache, edesc);
+	} else {
+		priv->edesc_rec_queue[smp_processor_id][current_edesc] =
+								edesc;
+		priv->curr_edesc[smp_processor_id] = current_edesc + 1;
+	}
+}
+
 static inline unsigned int get_chan_remap(struct talitos_private *priv)
 {
 	return priv->chan_remap;
@@ -957,6 +993,7 @@ static void ipsec_esp_encrypt_done(struct device *dev,
 	struct talitos_edesc *edesc;
 	struct scatterlist *sg;
 	void *icvdata;
+	struct talitos_private *priv = dev_get_drvdata(dev);
 
 	edesc = container_of(desc, struct talitos_edesc, desc);
 
@@ -971,7 +1008,7 @@ static void ipsec_esp_encrypt_done(struct device *dev,
 		       icvdata, ctx->authsize);
 	}
 
-	kfree(edesc);
+	crypto_edesc_free(edesc, priv);
 
 	aead_request_complete(areq, err);
 }
@@ -986,6 +1023,7 @@ static void ipsec_esp_decrypt_swauth_done(struct device *dev,
 	struct talitos_edesc *edesc;
 	struct scatterlist *sg;
 	void *icvdata;
+	struct talitos_private *priv = dev_get_drvdata(dev);
 
 	edesc = container_of(desc, struct talitos_edesc, desc);
 
@@ -1004,7 +1042,7 @@ static void ipsec_esp_decrypt_swauth_done(struct device *dev,
 			     ctx->authsize, ctx->authsize) ? -EBADMSG : 0;
 	}
 
-	kfree(edesc);
+	crypto_edesc_free(edesc, priv);
 
 	aead_request_complete(req, err);
 }
@@ -1015,6 +1053,7 @@ static void ipsec_esp_decrypt_hwauth_done(struct device *dev,
 {
 	struct aead_request *req = context;
 	struct talitos_edesc *edesc;
+	struct talitos_private *priv = dev_get_drvdata(dev);
 
 	edesc = container_of(desc, struct talitos_edesc, desc);
 
@@ -1025,8 +1064,8 @@ static void ipsec_esp_decrypt_hwauth_done(struct device *dev,
 		     DESC_HDR_LO_ICCR1_PASS))
 		err = -EBADMSG;
 
-	kfree(edesc);
-
+	crypto_edesc_free(edesc, priv);
+	
 	aead_request_complete(req, err);
 }
 
@@ -1084,6 +1123,7 @@ static int ipsec_esp(struct talitos_edesc *edesc, struct aead_request *areq,
 	unsigned int ivsize = crypto_aead_ivsize(aead);
 	int sg_count, ret;
 	int sg_link_tbl_len;
+	struct talitos_private *priv = dev_get_drvdata(dev);
 
 	/* hmac key */
 	map_single_talitos_ptr(dev, &desc->ptr[0], ctx->authkeylen, &ctx->key,
@@ -1183,7 +1223,7 @@ static int ipsec_esp(struct talitos_edesc *edesc, struct aead_request *areq,
 	ret = talitos_submit(dev, desc, callback, areq);
 	if (ret != -EINPROGRESS) {
 		ipsec_esp_unmap(dev, edesc, areq);
-		kfree(edesc);
+		crypto_edesc_free(edesc, priv);
 	}
 	return ret;
 }
@@ -1222,6 +1262,7 @@ static struct talitos_edesc *talitos_edesc_alloc(struct device *dev,
 	struct talitos_edesc *edesc;
 	int src_nents, dst_nents, alloc_len, dma_len;
 	int src_chained, dst_chained = 0;
+	struct talitos_private *priv = dev_get_drvdata(dev);
 	gfp_t flags = cryptoflags & CRYPTO_TFM_REQ_MAY_SLEEP ? GFP_KERNEL :
 		      GFP_ATOMIC;
 
@@ -1255,7 +1296,7 @@ static struct talitos_edesc *talitos_edesc_alloc(struct device *dev,
 		alloc_len += icv_stashing ? authsize : 0;
 	}
 
-	edesc = kmalloc(alloc_len, GFP_DMA | flags);
+	edesc = crypto_edesc_alloc(alloc_len, GFP_DMA | flags, priv);
 	if (!edesc) {
 		dev_err(dev, "could not allocate edescriptor\n");
 		return ERR_PTR(-ENOMEM);
@@ -1418,12 +1459,13 @@ static void ablkcipher_done(struct device *dev,
 {
 	struct ablkcipher_request *areq = context;
 	struct talitos_edesc *edesc;
+	struct talitos_private *priv = dev_get_drvdata(dev);
 
 	edesc = container_of(desc, struct talitos_edesc, desc);
 
 	common_nonsnoop_unmap(dev, edesc, areq);
 
-	kfree(edesc);
+	crypto_edesc_free(edesc, priv);
 
 	areq->base.complete(&areq->base, err);
 }
@@ -1442,6 +1484,7 @@ static int common_nonsnoop(struct talitos_edesc *edesc,
 	unsigned int cryptlen = areq->nbytes;
 	unsigned int ivsize;
 	int sg_count, ret;
+	struct talitos_private *priv = dev_get_drvdata(dev);
 
 	/* first DWORD empty */
 	desc->ptr[0].len = 0;
@@ -1524,7 +1567,7 @@ static int common_nonsnoop(struct talitos_edesc *edesc,
 	ret = talitos_submit(dev, desc, callback, areq);
 	if (ret != -EINPROGRESS) {
 		common_nonsnoop_unmap(dev, edesc, areq);
-		kfree(edesc);
+		crypto_edesc_free(edesc, priv);
 	}
 	return ret;
 }
@@ -1884,6 +1927,7 @@ static int talitos_remove(struct of_device *ofdev)
 
 	dev_set_drvdata(dev, NULL);
 
+	kmem_cache_destroy(priv->netcrypto_cache);
 	kfree(priv);
 
 	return 0;
@@ -2161,6 +2205,9 @@ static int talitos_probe(struct of_device *ofdev,
 			}
 		}
 	}
+	priv->netcrypto_cache = kmem_cache_create("netcrypto_cache",
+						MAX_DESC_LEN, 0,
+					SLAB_HWCACHE_ALIGN, NULL);
 
 	return 0;
 
-- 
1.7.0.4

