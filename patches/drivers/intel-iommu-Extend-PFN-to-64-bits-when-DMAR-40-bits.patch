From 01d3d419967be70c9f66bc95f81e378a26b15d0c Mon Sep 17 00:00:00 2001
From: Yang Shi <yang.shi@windriver.com>
Date: Wed, 30 Jan 2013 15:52:22 -0800
Subject: [PATCH] intel-iommu: Extend PFN to 64 bits when DMAR >= 40 bits

On x86_32, when the DMAR width is >= 40 bits and IOMMU is enabled,
unbinding a device from the host PCI driver will hang the associated
userspace process on a wait notifier that is never triggered.

This hang is caused on x86_32 when the DMAR width is >= 40 bits, since it
also means that the PFN is more than 32 bits. This cases the kernel to
infinitely loop in dma_pte_free_pagetable as follows:

  while (tmp && tmp + level_size(level) - 1 <= last_pfn)

Since the condition is always true.

Promote start_pfn and last_pfn parameter to 64 bit for dma_pte_clear_range
and dma_pte_free_pagetable. And, pass __DOMAIN_MAX_PFN to them as last_pfn.

Signed-off-by: Yang Shi <yang.shi@windriver.com>
---
 drivers/iommu/intel-iommu.c | 14 +++++++-------
 1 file changed, 7 insertions(+), 7 deletions(-)

diff --git a/drivers/iommu/intel-iommu.c b/drivers/iommu/intel-iommu.c
index 40f6b47..6b7d093 100644
--- a/drivers/iommu/intel-iommu.c
+++ b/drivers/iommu/intel-iommu.c
@@ -833,8 +833,8 @@ static struct dma_pte *dma_pfn_level_pte(struct dmar_domain *domain,
 
 /* clear last level pte, a tlb flush should be followed */
 static int dma_pte_clear_range(struct dmar_domain *domain,
-				unsigned long start_pfn,
-				unsigned long last_pfn)
+				uint64_t start_pfn,
+				uint64_t last_pfn)
 {
 	int addr_width = agaw_to_width(domain->agaw) - VTD_PAGE_SHIFT;
 	unsigned int large_page = 1;
@@ -901,8 +901,8 @@ next:
 
 /* free page table pages. last level pte should already be cleared */
 static void dma_pte_free_pagetable(struct dmar_domain *domain,
-				   unsigned long start_pfn,
-				   unsigned long last_pfn)
+				   uint64_t start_pfn,
+				   uint64_t last_pfn)
 {
 	int addr_width = agaw_to_width(domain->agaw) - VTD_PAGE_SHIFT;
 
@@ -915,7 +915,7 @@ static void dma_pte_free_pagetable(struct dmar_domain *domain,
 			   domain->pgd, 0, start_pfn, last_pfn);
 
 	/* free pgd */
-	if (start_pfn == 0 && last_pfn == DOMAIN_MAX_PFN(domain->gaw)) {
+	if (start_pfn == 0 && last_pfn == __DOMAIN_MAX_PFN(domain->gaw)) {
 		free_pgtable_page(domain->pgd);
 		domain->pgd = NULL;
 	}
@@ -1507,10 +1507,10 @@ static void domain_exit(struct dmar_domain *domain)
 	put_iova_domain(&domain->iovad);
 
 	/* clear ptes */
-	dma_pte_clear_range(domain, 0, DOMAIN_MAX_PFN(domain->gaw));
+	dma_pte_clear_range(domain, 0, __DOMAIN_MAX_PFN(domain->gaw));
 
 	/* free page tables */
-	dma_pte_free_pagetable(domain, 0, DOMAIN_MAX_PFN(domain->gaw));
+	dma_pte_free_pagetable(domain, 0, __DOMAIN_MAX_PFN(domain->gaw));
 
 	for_each_active_iommu(iommu, drhd)
 		if (test_bit(iommu->seq_id, domain->iommu_bmp))
-- 
2.0.2

