From baf07ac347f91b774740ee547c41f0c9d690116f Mon Sep 17 00:00:00 2001
From: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date: Thu, 13 May 2010 19:28:29 -0400
Subject: [PATCH 361/391] lttng-add-barrier-inside-nesting-count

lttng add barrier inside nesting count

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
---
 ltt/ltt-serialize.c       |   17 ++++++++++++++++-
 ltt/ltt-type-serializer.c |   17 ++++++++++++++++-
 2 files changed, 32 insertions(+), 2 deletions(-)

diff --git a/ltt/ltt-serialize.c b/ltt/ltt-serialize.c
index 6907735..3732803 100644
--- a/ltt/ltt-serialize.c
+++ b/ltt/ltt-serialize.c
@@ -829,7 +829,14 @@ void ltt_vtrace(const struct marker *mdata, void *probe_data, void *call_data,
 	rcu_read_lock_sched_notrace();
 	cpu = smp_processor_id();
 	__get_cpu_var(ltt_nesting)++;
-
+	/*
+	 * asm volatile and "memory" clobber prevent the compiler from moving
+	 * instructions out of the ltt nesting count. This is required to ensure
+	 * that probe side-effects which can cause recursion (e.g. unforeseen
+	 * traps, divisions by 0, ...) are triggered within the incremented
+	 * nesting count section.
+	 */
+	barrier();
 	pdata = (struct ltt_active_marker *)probe_data;
 	eID = mdata->event_id;
 	chan_index = mdata->channel_id;
@@ -900,6 +907,14 @@ void ltt_vtrace(const struct marker *mdata, void *probe_data, void *call_data,
 		/* Out-of-order commit */
 		ltt_commit_slot(buf, chan, buf_offset, data_size, slot_size);
 	}
+	/*
+	 * asm volatile and "memory" clobber prevent the compiler from moving
+	 * instructions out of the ltt nesting count. This is required to ensure
+	 * that probe side-effects which can cause recursion (e.g. unforeseen
+	 * traps, divisions by 0, ...) are triggered within the incremented
+	 * nesting count section.
+	 */
+	barrier();
 	__get_cpu_var(ltt_nesting)--;
 	rcu_read_unlock_sched_notrace();
 }
diff --git a/ltt/ltt-type-serializer.c b/ltt/ltt-type-serializer.c
index c4864ea..a4c18b8 100644
--- a/ltt/ltt-type-serializer.c
+++ b/ltt/ltt-type-serializer.c
@@ -38,7 +38,14 @@ void _ltt_specialized_trace(const struct marker *mdata, void *probe_data,
 	rcu_read_lock_sched_notrace();
 	cpu = smp_processor_id();
 	__get_cpu_var(ltt_nesting)++;
-
+	/*
+	 * asm volatile and "memory" clobber prevent the compiler from moving
+	 * instructions out of the ltt nesting count. This is required to ensure
+	 * that probe side-effects which can cause recursion (e.g. unforeseen
+	 * traps, divisions by 0, ...) are triggered within the incremented
+	 * nesting count section.
+	 */
+	barrier();
 	eID = mdata->event_id;
 	chan_index = mdata->channel_id;
 
@@ -88,6 +95,14 @@ void _ltt_specialized_trace(const struct marker *mdata, void *probe_data,
 		/* Out-of-order commit */
 		ltt_commit_slot(buf, chan, buf_offset, data_size, slot_size);
 	}
+	/*
+	 * asm volatile and "memory" clobber prevent the compiler from moving
+	 * instructions out of the ltt nesting count. This is required to ensure
+	 * that probe side-effects which can cause recursion (e.g. unforeseen
+	 * traps, divisions by 0, ...) are triggered within the incremented
+	 * nesting count section.
+	 */
+	barrier();
 	__get_cpu_var(ltt_nesting)--;
 	rcu_read_unlock_sched_notrace();
 }
-- 
1.6.5.2

