From 2ff8de47a1d8f10a12744b2af65f83aa39d57c0b Mon Sep 17 00:00:00 2001
From: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
Date: Fri, 9 Jan 2009 10:00:26 -0500
Subject: [PATCH] lttng-transport-open-once

LTTng traceport open once

Make sure only one single lttd process can open the channels.

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
---
 ltt/ltt-relay-locked.c |   93 +++++++++++++++++++++++++++++++++--------------
 ltt/ltt-relay.c        |   95 ++++++++++++++++++++++++++++++++++--------------
 2 files changed, 133 insertions(+), 55 deletions(-)

diff --git a/ltt/ltt-relay-locked.c b/ltt/ltt-relay-locked.c
index a3362f5..da7b808 100644
--- a/ltt/ltt-relay-locked.c
+++ b/ltt/ltt-relay-locked.c
@@ -71,7 +71,7 @@ struct ltt_channel_buf_struct {
 					 * Last timestamp written in the buffer.
 					 */
 	long consumed;			/* Current offset in the buffer */
-	long active_readers;		/* Active readers count */
+	atomic_long_t active_readers;	/* Active readers count */
 	long events_lost;
 	long corrupted_subbuffers;
 	wait_queue_head_t write_wait;	/*
@@ -249,6 +249,50 @@ static notrace void ltt_buf_unfull(struct rchan_buf *buf,
 }
 
 /**
+ *	open file op for ltt files
+ *	@inode: opened inode
+ *	@file: opened file
+ *
+ *	Open implementation. Makes sure only one open instance of a buffer is
+ *	done at a given moment.
+ */
+static int ltt_open(struct inode *inode, struct file *file)
+{
+	struct rchan_buf *buf = inode->i_private;
+	struct ltt_channel_struct *ltt_channel =
+		(struct ltt_channel_struct *)buf->chan->private_data;
+	struct ltt_channel_buf_struct *ltt_buf =
+		percpu_ptr(ltt_channel->buf, buf->cpu);
+
+	if (!atomic_long_add_unless(&ltt_buf->active_readers, 1, 1))
+		return -EBUSY;
+	return ltt_relay_file_operations.open(inode, file);
+}
+
+/**
+ *	release file op for ltt files
+ *	@inode: opened inode
+ *	@file: opened file
+ *
+ *	Release implementation.
+ */
+static int ltt_release(struct inode *inode, struct file *file)
+{
+	struct rchan_buf *buf = inode->i_private;
+	struct ltt_channel_struct *ltt_channel =
+		(struct ltt_channel_struct *)buf->chan->private_data;
+	struct ltt_channel_buf_struct *ltt_buf =
+		percpu_ptr(ltt_channel->buf, buf->cpu);
+	int ret;
+
+	WARN_ON(atomic_long_read(&ltt_buf->active_readers) != 1);
+	atomic_long_dec(&ltt_buf->active_readers);
+	ret = ltt_relay_file_operations.release(inode, file);
+	WARN_ON(ret);
+	return ret;
+}
+
+/**
  *	poll file op for ltt files
  *	@filp: the file
  *	@wait: poll table
@@ -270,30 +314,26 @@ static unsigned int ltt_poll(struct file *filp, poll_table *wait)
 
 		local_irq_disable();
 		__raw_spin_lock(&ltt_buf->lock);
-		if (ltt_buf->active_readers != 0) {
-			ret = 0;
+		WARN_ON(atomic_long_read(&ltt_buf->active_readers) != 1);
+		if (SUBBUF_TRUNC(ltt_buf->offset, buf->chan)
+		  - SUBBUF_TRUNC(ltt_buf->consumed, buf->chan)
+		  == 0) {
+			if (buf->finalized)
+				ret = POLLHUP;
+			else
+				ret = 0;
 			goto end;
 		} else {
+			struct rchan *rchan =
+				ltt_channel->trans_channel_data;
+
 			if (SUBBUF_TRUNC(ltt_buf->offset, buf->chan)
 			  - SUBBUF_TRUNC(ltt_buf->consumed, buf->chan)
-			  == 0) {
-				if (buf->finalized)
-					ret = POLLHUP;
-				else
-					ret = 0;
-				goto end;
-			} else {
-				struct rchan *rchan =
-					ltt_channel->trans_channel_data;
-
-				if (SUBBUF_TRUNC(ltt_buf->offset, buf->chan)
-				  - SUBBUF_TRUNC(ltt_buf->consumed, buf->chan)
-				  >= rchan->alloc_size)
-					ret = POLLPRI | POLLRDBAND;
-				else
-					ret = POLLIN | POLLRDNORM;
-				goto end;
-			}
+			  >= rchan->alloc_size)
+				ret = POLLPRI | POLLRDBAND;
+			else
+				ret = POLLIN | POLLRDNORM;
+			goto end;
 		}
 end:
 		__raw_spin_unlock(&ltt_buf->lock);
@@ -333,6 +373,7 @@ static int ltt_ioctl(struct inode *inode, struct file *filp,
 		percpu_ptr(ltt_channel->buf, buf->cpu);
 	u32 __user *argp = (u32 __user *)arg;
 
+	WARN_ON(atomic_long_read(&ltt_buf->active_readers) != 1);
 	switch (cmd) {
 	case RELAY_GET_SUBBUF:
 	{
@@ -340,7 +381,6 @@ static int ltt_ioctl(struct inode *inode, struct file *filp,
 
 		local_irq_disable();
 		__raw_spin_lock(&ltt_buf->lock);
-		ltt_buf->active_readers++;
 		consumed_old = ltt_buf->consumed;
 		consumed_idx = SUBBUF_INDEX(consumed_old, buf->chan);
 		commit_count = ltt_buf->commit_count[consumed_idx];
@@ -353,7 +393,6 @@ static int ltt_ioctl(struct inode *inode, struct file *filp,
 		    - (BUFFER_TRUNC(consumed_old, buf->chan)
 		       >> ltt_channel->n_subbufs_order)
 		    != 0) {
-			ltt_buf->active_readers--;
 			__raw_spin_unlock(&ltt_buf->lock);
 			local_irq_enable();
 			return -EAGAIN;
@@ -365,7 +404,6 @@ static int ltt_ioctl(struct inode *inode, struct file *filp,
 		if ((SUBBUF_TRUNC(write_offset, buf->chan)
 		   - SUBBUF_TRUNC(consumed_old, buf->chan))
 		   == 0) {
-			ltt_buf->active_readers--;
 			__raw_spin_unlock(&ltt_buf->lock);
 			local_irq_enable();
 			return -EAGAIN;
@@ -396,7 +434,6 @@ static int ltt_ioctl(struct inode *inode, struct file *filp,
 			/* We have been pushed by the writer : the last
 			 * buffer read _is_ corrupted! It can also
 			 * happen if this is a buffer we never got. */
-			ltt_buf->active_readers--;
 			__raw_spin_unlock(&ltt_buf->lock);
 			local_irq_enable();
 			return -EIO;
@@ -409,7 +446,6 @@ static int ltt_ioctl(struct inode *inode, struct file *filp,
 			index = SUBBUF_INDEX(consumed_old, buf->chan);
 			data = BUFFER_OFFSET(consumed_old, buf->chan);
 			ltt_buf_unfull(buf, index, data);
-			ltt_buf->active_readers--;
 			__raw_spin_unlock(&ltt_buf->lock);
 			local_irq_enable();
 		}
@@ -493,7 +529,7 @@ static int subbuf_splice_actor(struct file *in,
 	 */
 	local_irq_disable();
 	__raw_spin_lock(&ltt_buf->lock);
-	WARN_ON(ltt_buf->active_readers != 1);
+	WARN_ON(atomic_long_read(&ltt_buf->active_readers) != 1);
 	consumed_old = ltt_buf->consumed;
 	consumed_old += *ppos;
 	consumed_idx = SUBBUF_INDEX(consumed_old, buf->chan);
@@ -687,6 +723,7 @@ static int ltt_relay_create_buffer(struct ltt_trace_struct *trace,
 	kref_get(&trace->ltt_transport_kref);
 	kref_get(&ltt_chan->kref);
 	ltt_buf->offset = ltt_subbuffer_header_size();
+	atomic_long_set(&ltt_buf->active_readers, 0);
 	init_waitqueue_head(&ltt_buf->write_wait);
 	INIT_WORK(&ltt_buf->wake_writers, ltt_wakeup_writers);
 
@@ -1599,6 +1636,8 @@ static int __init ltt_relay_init(void)
 
 	ltt_file_operations = ltt_relay_file_operations;
 	ltt_file_operations.owner = THIS_MODULE;
+	ltt_file_operations.open = ltt_open;
+	ltt_file_operations.release = ltt_release;
 	ltt_file_operations.poll = ltt_poll;
 	ltt_file_operations.splice_read = ltt_relay_file_splice_read,
 	ltt_file_operations.ioctl = ltt_ioctl;
diff --git a/ltt/ltt-relay.c b/ltt/ltt-relay.c
index a8f2303..fcb53f6 100644
--- a/ltt/ltt-relay.c
+++ b/ltt/ltt-relay.c
@@ -257,6 +257,50 @@ static notrace void ltt_buf_unfull(struct rchan_buf *buf,
 }
 
 /**
+ *	open file op for ltt files
+ *	@inode: opened inode
+ *	@file: opened file
+ *
+ *	Open implementation. Makes sure only one open instance of a buffer is
+ *	done at a given moment.
+ */
+static int ltt_open(struct inode *inode, struct file *file)
+{
+	struct rchan_buf *buf = inode->i_private;
+	struct ltt_channel_struct *ltt_channel =
+		(struct ltt_channel_struct *)buf->chan->private_data;
+	struct ltt_channel_buf_struct *ltt_buf =
+		percpu_ptr(ltt_channel->buf, buf->cpu);
+
+	if (!atomic_long_add_unless(&ltt_buf->active_readers, 1, 1))
+		return -EBUSY;
+	return ltt_relay_file_operations.open(inode, file);
+}
+
+/**
+ *	release file op for ltt files
+ *	@inode: opened inode
+ *	@file: opened file
+ *
+ *	Release implementation.
+ */
+static int ltt_release(struct inode *inode, struct file *file)
+{
+	struct rchan_buf *buf = inode->i_private;
+	struct ltt_channel_struct *ltt_channel =
+		(struct ltt_channel_struct *)buf->chan->private_data;
+	struct ltt_channel_buf_struct *ltt_buf =
+		percpu_ptr(ltt_channel->buf, buf->cpu);
+	int ret;
+
+	WARN_ON(atomic_long_read(&ltt_buf->active_readers) != 1);
+	atomic_long_dec(&ltt_buf->active_readers);
+	ret = ltt_relay_file_operations.release(inode, file);
+	WARN_ON(ret);
+	return ret;
+}
+
+/**
  *	poll file op for ltt files
  *	@filp: the file
  *	@wait: poll table
@@ -276,31 +320,28 @@ static unsigned int ltt_poll(struct file *filp, poll_table *wait)
 	if (filp->f_mode & FMODE_READ) {
 		poll_wait(filp, &buf->read_wait, wait);
 
-		if (atomic_long_read(&ltt_buf->active_readers) != 0) {
-			return 0;
+		WARN_ON(atomic_long_read(&ltt_buf->active_readers) != 1);
+		if (SUBBUF_TRUNC(local_read(&ltt_buf->offset),
+							buf->chan)
+		  - SUBBUF_TRUNC(atomic_long_read(&ltt_buf->consumed),
+							buf->chan)
+		  == 0) {
+			if (buf->finalized)
+				return POLLHUP;
+			else
+				return 0;
 		} else {
+			struct rchan *rchan =
+				ltt_channel->trans_channel_data;
 			if (SUBBUF_TRUNC(local_read(&ltt_buf->offset),
-								buf->chan)
-			  - SUBBUF_TRUNC(atomic_long_read(&ltt_buf->consumed),
-								buf->chan)
-			  == 0) {
-				if (buf->finalized)
-					return POLLHUP;
-				else
-					return 0;
-			} else {
-				struct rchan *rchan =
-					ltt_channel->trans_channel_data;
-				if (SUBBUF_TRUNC(local_read(&ltt_buf->offset),
-						buf->chan)
-				  - SUBBUF_TRUNC(atomic_long_read(
-							&ltt_buf->consumed),
-						buf->chan)
-				  >= rchan->alloc_size)
-					return POLLPRI | POLLRDBAND;
-				else
-					return POLLIN | POLLRDNORM;
-			}
+					buf->chan)
+			  - SUBBUF_TRUNC(atomic_long_read(
+						&ltt_buf->consumed),
+					buf->chan)
+			  >= rchan->alloc_size)
+				return POLLPRI | POLLRDBAND;
+			else
+				return POLLIN | POLLRDNORM;
 		}
 	}
 	return mask;
@@ -336,11 +377,11 @@ static int ltt_ioctl(struct inode *inode, struct file *filp,
 		percpu_ptr(ltt_channel->buf, buf->cpu);
 	u32 __user *argp = (u32 __user *)arg;
 
+	WARN_ON(atomic_long_read(&ltt_buf->active_readers) != 1);
 	switch (cmd) {
 	case RELAY_GET_SUBBUF:
 	{
 		long consumed_old, consumed_idx, commit_count, write_offset;
-		atomic_long_inc(&ltt_buf->active_readers);
 		consumed_old = atomic_long_read(&ltt_buf->consumed);
 		consumed_idx = SUBBUF_INDEX(consumed_old, buf->chan);
 		commit_count = local_read(&ltt_buf->commit_count[consumed_idx]);
@@ -360,7 +401,6 @@ static int ltt_ioctl(struct inode *inode, struct file *filp,
 		    - (BUFFER_TRUNC(consumed_old, buf->chan)
 		       >> ltt_channel->n_subbufs_order)
 		    != 0) {
-			atomic_long_dec(&ltt_buf->active_readers);
 			return -EAGAIN;
 		}
 		/*
@@ -370,7 +410,6 @@ static int ltt_ioctl(struct inode *inode, struct file *filp,
 		if ((SUBBUF_TRUNC(write_offset, buf->chan)
 		   - SUBBUF_TRUNC(consumed_old, buf->chan))
 		   == 0) {
-			atomic_long_dec(&ltt_buf->active_readers);
 			return -EAGAIN;
 		}
 		return put_user((u32)consumed_old, argp);
@@ -398,7 +437,6 @@ static int ltt_ioctl(struct inode *inode, struct file *filp,
 			/* We have been pushed by the writer : the last
 			 * buffer read _is_ corrupted! It can also
 			 * happen if this is a buffer we never got. */
-			atomic_long_dec(&ltt_buf->active_readers);
 			spin_unlock(&ltt_buf->full_lock);
 			return -EIO;
 		} else {
@@ -408,7 +446,6 @@ static int ltt_ioctl(struct inode *inode, struct file *filp,
 			index = SUBBUF_INDEX(consumed_old, buf->chan);
 			data = BUFFER_OFFSET(consumed_old, buf->chan);
 			ltt_buf_unfull(buf, index, data);
-			atomic_long_dec(&ltt_buf->active_readers);
 			spin_unlock(&ltt_buf->full_lock);
 		}
 		break;
@@ -1618,6 +1655,8 @@ static int __init ltt_relay_init(void)
 
 	ltt_file_operations = ltt_relay_file_operations;
 	ltt_file_operations.owner = THIS_MODULE;
+	ltt_file_operations.open = ltt_open;
+	ltt_file_operations.release = ltt_release;
 	ltt_file_operations.poll = ltt_poll;
 	ltt_file_operations.splice_read = ltt_relay_file_splice_read,
 	ltt_file_operations.ioctl = ltt_ioctl;
-- 
1.6.0.4

