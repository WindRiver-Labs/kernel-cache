From 9fd11ee4c73d66baaf72a13f26649076c86740fb Mon Sep 17 00:00:00 2001
From: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
Date: Thu, 30 Oct 2008 23:26:57 -0400
Subject: [PATCH] lttng-transport-locked-formal-verif-fix-2-port

LTTng transport formal verif fix 2 port to locked transport

Port the algorithmic changes from the lockless transport which deals with the
fact that a reader might think that a subbuffer is full when it's in fact empty
because the modulo returns 0 for both.

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
CC: Paul McKenney <Paul.McKenney@us.ibm.com>
CC: Robert Wisniewski <bob@watson.ibm.com>
---
 ltt/ltt-relay-locked.c |  210 ++++++++++++++++++++++++++++--------------------
 1 files changed, 123 insertions(+), 87 deletions(-)

diff --git a/ltt/ltt-relay-locked.c b/ltt/ltt-relay-locked.c
index e4c966f..c40bdb2 100644
--- a/ltt/ltt-relay-locked.c
+++ b/ltt/ltt-relay-locked.c
@@ -336,22 +336,33 @@ static int ltt_ioctl(struct inode *inode, struct file *filp,
 	switch (cmd) {
 	case RELAY_GET_SUBBUF:
 	{
-		long consumed_old, consumed_idx;
+		long consumed_old, consumed_idx, commit_count, write_offset;
 
 		local_irq_disable();
 		__raw_spin_lock(&ltt_buf->lock);
 		ltt_buf->active_readers++;
 		consumed_old = ltt_buf->consumed;
 		consumed_idx = SUBBUF_INDEX(consumed_old, buf->chan);
-		if (SUBBUF_OFFSET(ltt_buf->commit_count[consumed_idx],
-				  buf->chan)
+		commit_count = ltt_buf->commit_count[consumed_idx];
+		write_offset = ltt_buf->offset;
+		/*
+		 * Check that the subbuffer we are trying to consume has been
+		 * already fully committed.
+		 */
+		if (commit_count - buf->chan->subbuf_size
+		    - (BUFFER_TRUNC(consumed_old, buf->chan)
+		       >> ltt_channel->n_subbufs_order)
 		    != 0) {
 			ltt_buf->active_readers--;
 			__raw_spin_unlock(&ltt_buf->lock);
 			local_irq_enable();
 			return -EAGAIN;
 		}
-		if ((SUBBUF_TRUNC(ltt_buf->offset, buf->chan)
+		/*
+		 * Check that we are not about to read the same subbuffer in
+		 * which the writer head is.
+		 */
+		if ((SUBBUF_TRUNC(write_offset, buf->chan)
 		   - SUBBUF_TRUNC(consumed_old, buf->chan))
 		   == 0) {
 			ltt_buf->active_readers--;
@@ -573,23 +584,25 @@ static void ltt_relay_print_subbuffer_errors(
 	struct rchan *rchan = ltt_chan->trans_channel_data;
 	struct ltt_channel_buf_struct *ltt_buf =
 		percpu_ptr(ltt_chan->buf, cpu);
-	long cons_idx;
+	long cons_idx, commit_count, write_offset;
 
+	cons_idx = SUBBUF_INDEX(cons_off, rchan);
+	commit_count = ltt_buf->commit_count[cons_idx];
+	write_offset = ltt_buf->offset;
 	printk(KERN_WARNING
 		"LTT : unread channel %s offset is %ld "
 		"and cons_off : %ld (cpu %u)\n",
-		ltt_chan->channel_name,
-		ltt_buf->offset, cons_off, cpu);
-	/* Check each sub-buffer for non zero commit count */
-	cons_idx = SUBBUF_INDEX(cons_off, rchan);
-	if (SUBBUF_OFFSET(ltt_buf->commit_count[cons_idx], rchan))
+		ltt_chan->channel_name, write_offset, cons_off, cpu);
+	/* Check each sub-buffer for non filled commit count */
+	if (commit_count - rchan->subbuf_size
+	    - (BUFFER_TRUNC(cons_off, rchan) >> ltt_chan->n_subbufs_order)
+	    != 0)
 		printk(KERN_ALERT
-			"LTT : %s : subbuffer %lu has non zero "
-			"commit count.\n",
-			ltt_chan->channel_name, cons_idx);
+			"LTT : %s : subbuffer %lu has non filled "
+			"commit count %lu.\n",
+			ltt_chan->channel_name, cons_idx, commit_count);
 	printk(KERN_ALERT "LTT : %s : commit count : %lu, subbuf size %zd\n",
-			ltt_chan->channel_name,
-			ltt_buf->commit_count[cons_idx],
+			ltt_chan->channel_name, commit_count,
 			rchan->subbuf_size);
 }
 
@@ -734,6 +747,7 @@ static int ltt_relay_create_channel(const char *trace_name,
 	(*ltt_chan)->buffer_begin = ltt_buffer_begin_callback;
 	(*ltt_chan)->buffer_end = ltt_buffer_end_callback;
 	(*ltt_chan)->overwrite = overwrite;
+	(*ltt_chan)->n_subbufs_order = get_count_order(n_subbufs);
 	(*ltt_chan)->buf =
 		percpu_alloc_mask(sizeof(struct ltt_channel_buf_struct),
 			GFP_KERNEL, cpu_possible_map);
@@ -915,17 +929,18 @@ static inline int ltt_relay_try_reserve(
 		}
 	}
 	if (offsets->begin_switch) {
+		long subbuf_index;
+
 		if (offsets->end_switch_old)
 			offsets->begin = SUBBUF_ALIGN(offsets->begin,
 						      buf->chan);
 		offsets->begin = offsets->begin + ltt_subbuffer_header_size();
 		/* Test new buffer integrity */
+		subbuf_index = SUBBUF_INDEX(offsets->begin, buf->chan);
 		offsets->reserve_commit_diff =
-			SUBBUF_OFFSET(buf->chan->subbuf_size
-				      - ltt_buf->commit_count[
-						SUBBUF_INDEX(offsets->begin,
-							     buf->chan)],
-				      buf->chan);
+			(BUFFER_TRUNC(offsets->begin, buf->chan)
+			 >> ltt_channel->n_subbufs_order)
+			- ltt_buf->commit_count[subbuf_index];
 		if (offsets->reserve_commit_diff == 0) {
 			/* Next buffer not corrupted. */
 			if (!ltt_channel->overwrite &&
@@ -1003,6 +1018,8 @@ static inline int ltt_relay_try_switch(
 		struct ltt_reserve_switch_offsets *offsets,
 		u64 *tsc)
 {
+	long subbuf_index;
+
 	offsets->begin = ltt_buf->offset;
 	offsets->old = offsets->begin;
 	offsets->begin_switch = 0;
@@ -1023,12 +1040,11 @@ static inline int ltt_relay_try_switch(
 	 * Always begin_switch in FORCE_ACTIVE mode.
 	 * Test new buffer integrity
 	 */
+	subbuf_index = SUBBUF_INDEX(offsets->begin, buf->chan);
 	offsets->reserve_commit_diff =
-		SUBBUF_OFFSET(buf->chan->subbuf_size
-			      - ltt_buf->commit_count[
-					SUBBUF_INDEX(offsets->begin,
-						     buf->chan)],
-			      buf->chan);
+		(BUFFER_TRUNC(offsets->begin, buf->chan)
+		 >> ltt_channel->n_subbufs_order)
+		- ltt_buf->commit_count[subbuf_index];
 	if (offsets->reserve_commit_diff == 0) {
 		/* Next buffer not corrupted. */
 		if (mode == FORCE_ACTIVE
@@ -1052,7 +1068,9 @@ static inline int ltt_relay_try_switch(
 }
 
 static inline void ltt_reserve_push_reader(
-		struct ltt_channel_buf_struct *ltt_buf, struct rchan *rchan,
+		struct ltt_channel_struct *ltt_channel,
+		struct ltt_channel_buf_struct *ltt_buf,
+		struct rchan *rchan,
 		struct rchan_buf *buf,
 		struct ltt_reserve_switch_offsets *offsets)
 {
@@ -1092,13 +1110,27 @@ static inline void ltt_reserve_push_reader(
 		 */
 		if (offsets->reserve_commit_diff) {
 			/*
-			 * We have to alter the sub-buffer commit count : a
-			 * sub-buffer is corrupted. We do not deliver it.
+			 * We have to alter the sub-buffer commit count.
+			 * We do not deliver the previous subbuffer, given it
+			 * was either corrupted or not consumed (overwrite
+			 * mode).
 			 */
 			ltt_buf->commit_count[SUBBUF_INDEX(offsets->begin,
 							   buf->chan)] +=
 						offsets->reserve_commit_diff;
-			ltt_buf->corrupted_subbuffers++;
+			if (!ltt_channel->overwrite
+			    || offsets->reserve_commit_diff
+			       != rchan->subbuf_size) {
+				/*
+				 * The reserve commit diff was not subbuf_size :
+				 * it means the subbuffer was partly written to
+				 * and is therefore corrupted. If it is multiple
+				 * of subbuffer size and we are in flight
+				 * recorder mode, we are skipping over a whole
+				 * subbuffer.
+				 */
+				ltt_buf->corrupted_subbuffers++;
+			}
 		}
 	}
 }
@@ -1130,20 +1162,19 @@ static inline void ltt_reserve_switch_old_subbuf(
 		struct rchan_buf *buf,
 		struct ltt_reserve_switch_offsets *offsets, u64 *tsc)
 {
-	ltt_channel->buffer_end(buf, *tsc, offsets->old,
-		SUBBUF_INDEX(offsets->old - 1, buf->chan));
-	ltt_buf->commit_count[SUBBUF_INDEX(offsets->old - 1, buf->chan)] +=
-		buf->chan->subbuf_size
-		- (SUBBUF_OFFSET(offsets->old - 1, buf->chan)
+	long oldidx = SUBBUF_INDEX(offsets->old - 1, rchan);
+
+	ltt_channel->buffer_end(buf, *tsc, offsets->old, oldidx);
+	ltt_buf->commit_count[oldidx] +=
+		rchan->subbuf_size
+		- (SUBBUF_OFFSET(offsets->old - 1, rchan)
 		+ 1);
-	offsets->commit_count =
-		ltt_buf->commit_count[SUBBUF_INDEX(offsets->old - 1,
-						   buf->chan)];
-	if (SUBBUF_OFFSET(offsets->commit_count, buf->chan) == 0)
-		ltt_deliver(buf,
-			    SUBBUF_INDEX(offsets->old - 1,
-					 buf->chan),
-			    NULL);
+	offsets->commit_count = ltt_buf->commit_count[oldidx];
+	if ((BUFFER_TRUNC(offsets->old - 1, rchan)
+			>> ltt_channel->n_subbufs_order)
+			+ rchan->subbuf_size
+			- offsets->commit_count == 0)
+		ltt_deliver(buf, oldidx, NULL);
 }
 
 /*
@@ -1159,15 +1190,17 @@ static inline void ltt_reserve_switch_new_subbuf(
 		struct rchan_buf *buf,
 		struct ltt_reserve_switch_offsets *offsets, u64 *tsc)
 {
-	ltt_channel->buffer_begin(buf, *tsc, SUBBUF_INDEX(offsets->begin,
-				buf->chan));
-	ltt_buf->commit_count[SUBBUF_INDEX(offsets->begin, buf->chan)] +=
-		ltt_subbuffer_header_size();
-	offsets->commit_count =
-		ltt_buf->commit_count[SUBBUF_INDEX(offsets->begin, buf->chan)];
+	long beginidx = SUBBUF_INDEX(offsets->begin, rchan);
+
+	ltt_channel->buffer_begin(buf, *tsc, beginidx);
+	ltt_buf->commit_count[beginidx] += ltt_subbuffer_header_size();
+	offsets->commit_count = ltt_buf->commit_count[beginidx];
 	/* Check if the written buffer has to be delivered */
-	if (SUBBUF_OFFSET(offsets->commit_count, buf->chan) == 0)
-		ltt_deliver(buf, SUBBUF_INDEX(offsets->begin, buf->chan), NULL);
+	if ((BUFFER_TRUNC(offsets->end - 1, rchan)
+			>> ltt_channel->n_subbufs_order)
+			+ rchan->subbuf_size
+			- offsets->commit_count == 0)
+		ltt_deliver(buf, beginidx, NULL);
 }
 
 
@@ -1195,19 +1228,19 @@ static inline void ltt_reserve_end_switch_current(
 		struct rchan_buf *buf,
 		struct ltt_reserve_switch_offsets *offsets, u64 *tsc)
 {
-	ltt_channel->buffer_end(buf, *tsc, offsets->end,
-		SUBBUF_INDEX(offsets->end - 1, buf->chan));
-	ltt_buf->commit_count[SUBBUF_INDEX(offsets->end - 1, buf->chan)] +=
-		buf->chan->subbuf_size
-		- (SUBBUF_OFFSET(offsets->end - 1, buf->chan)
+	long endidx = SUBBUF_INDEX(offsets->end - 1, rchan);
+
+	ltt_channel->buffer_end(buf, *tsc, offsets->end, endidx);
+	ltt_buf->commit_count[endidx] +=
+		rchan->subbuf_size
+		- (SUBBUF_OFFSET(offsets->end - 1, rchan)
 		+ 1);
-	offsets->commit_count =
-		ltt_buf->commit_count[SUBBUF_INDEX(offsets->end - 1,
-						   buf->chan)];
-	if (SUBBUF_OFFSET(offsets->commit_count, buf->chan) == 0)
-		ltt_deliver(buf,
-			    SUBBUF_INDEX(offsets->end - 1, buf->chan),
-			    NULL);
+	offsets->commit_count = ltt_buf->commit_count[endidx];
+	if ((BUFFER_TRUNC(offsets->end - 1, rchan)
+			>> ltt_channel->n_subbufs_order)
+			+ rchan->subbuf_size
+			- offsets->commit_count == 0)
+		ltt_deliver(buf, endidx, NULL);
 }
 
 /**
@@ -1217,17 +1250,17 @@ static inline void ltt_reserve_end_switch_current(
  * @transport_data : data structure specific to ltt relay
  * @data_size : size of the variable length data to log.
  * @slot_size : pointer to total size of the slot (out)
+ * @buf_offset : pointer to reserved buffer offset (out)
  * @tsc : pointer to the tsc at the slot reservation (out)
  * @cpu : cpuid
  *
- * Return : -ENOSPC if not enough space, else returns the offset
- * 		to the beginning of the reserved slot, aligned for the
- * 		event header.
+ * Return : -ENOSPC if not enough space, else returns 0.
+ *
  * It will take care of sub-buffer switching.
  */
-static notrace ssize_t ltt_relay_reserve_slot(struct ltt_trace_struct *trace,
+static notrace int ltt_relay_reserve_slot(struct ltt_trace_struct *trace,
 		struct ltt_channel_struct *ltt_channel, void **transport_data,
-		size_t data_size, size_t *slot_size, u64 *tsc,
+		size_t data_size, size_t *slot_size, long *buf_offset, u64 *tsc,
 		unsigned int *rflags, int largest_align, int cpu)
 {
 	struct rchan *rchan = ltt_channel->trans_channel_data;
@@ -1268,7 +1301,7 @@ static notrace ssize_t ltt_relay_reserve_slot(struct ltt_trace_struct *trace,
 	/*
 	 * Push the reader if necessary
 	 */
-	ltt_reserve_push_reader(ltt_buf, rchan, buf, &offsets);
+	ltt_reserve_push_reader(ltt_channel, ltt_buf, rchan, buf, &offsets);
 
 	/*
 	 * Switch old subbuffer if needed.
@@ -1288,11 +1321,10 @@ static notrace ssize_t ltt_relay_reserve_slot(struct ltt_trace_struct *trace,
 		ltt_reserve_end_switch_current(ltt_channel, ltt_buf, rchan,
 			buf, &offsets, tsc);
 
-	*slot_size = offsets.size;
-
 	ltt_buf->irqflags = flags;
-
-	return BUFFER_OFFSET(offsets.begin, buf->chan) + offsets.before_hdr_pad;
+	*slot_size = offsets.size;
+	*buf_offset = offsets.begin + offsets.before_hdr_pad;
+	return 0;
 }
 
 /*
@@ -1335,7 +1367,8 @@ static notrace void ltt_force_switch(struct rchan_buf *buf,
 	 * Push the reader if necessary
 	 */
 	if (mode == FORCE_ACTIVE)
-		ltt_reserve_push_reader(ltt_buf, rchan, buf, &offsets);
+		ltt_reserve_push_reader(ltt_channel, ltt_buf, rchan,
+					buf, &offsets);
 
 	/*
 	 * Switch old subbuffer if needed.
@@ -1366,7 +1399,7 @@ static notrace void ltt_force_switch(struct rchan_buf *buf,
  */
 #ifdef CONFIG_LTT_VMCORE
 static inline void ltt_write_commit_counter(struct rchan_buf *buf,
-		size_t reserved, size_t slot_size)
+		long buf_offset, size_t slot_size)
 {
 	struct ltt_channel_struct *ltt_channel =
 		(struct ltt_channel_struct *)buf->chan->private_data;
@@ -1376,8 +1409,8 @@ static inline void ltt_write_commit_counter(struct rchan_buf *buf,
 	long offset, subbuf_idx, commit_count;
 	uint32_t lost_old, lost_new;
 
-	offset = reserved + slot_size;
-	subbuf_idx = (offset - 1) / buf->chan->subbuf_size;
+	subbuf_idx = SUBBUF_INDEX(buf_offset - 1, buf->chan);
+	offset = buf_offset + slot_size;
 	header = (struct ltt_subbuffer_header *)
 			ltt_relay_offset_address(buf,
 				subbuf_idx * buf->chan->subbuf_size);
@@ -1398,7 +1431,7 @@ static inline void ltt_write_commit_counter(struct rchan_buf *buf,
 }
 #else
 static inline void ltt_write_commit_counter(struct rchan_buf *buf,
-		size_t reserved, size_t slot_size)
+		long buf_offset, size_t slot_size)
 {
 }
 #endif
@@ -1411,31 +1444,34 @@ static inline void ltt_write_commit_counter(struct rchan_buf *buf,
  *
  * @ltt_channel : channel structure
  * @transport_data: transport-specific data
- * @reserved : address following the event header.
+ * @buf_offset : offset following the event header.
  * @slot_size : size of the reserved slot.
  */
 static notrace void ltt_relay_commit_slot(
 		struct ltt_channel_struct *ltt_channel,
-		void **transport_data, size_t reserved, size_t slot_size)
+		void **transport_data, long buf_offset, size_t slot_size)
 {
 	struct rchan_buf *buf = *transport_data;
 	struct ltt_channel_buf_struct *ltt_buf =
 			percpu_ptr(ltt_channel->buf, buf->cpu);
-	unsigned int offset_end = reserved;
+	struct rchan *rchan = buf->chan;
+	unsigned int offset_end = buf_offset;
+	long endidx = SUBBUF_INDEX(offset_end - 1, rchan);
 	long commit_count;
 
-	ltt_buf->commit_count[SUBBUF_INDEX(offset_end - 1, buf->chan)] +=
-							slot_size;
-	commit_count = ltt_buf->commit_count[SUBBUF_INDEX(offset_end - 1,
-							  buf->chan)];
+	ltt_buf->commit_count[endidx] += slot_size;
+	commit_count = ltt_buf->commit_count[endidx];
 	/* Check if all commits have been done */
-	if (SUBBUF_OFFSET(commit_count, buf->chan) == 0)
-		ltt_deliver(buf, SUBBUF_INDEX(offset_end - 1, buf->chan), NULL);
+	if ((BUFFER_TRUNC(offset_end - 1, rchan)
+			>> ltt_channel->n_subbufs_order)
+			+ rchan->subbuf_size
+			- commit_count == 0)
+		ltt_deliver(buf, endidx, NULL);
 	/*
 	 * Update lost_size for each commit. It's needed only for extracting
 	 * ltt buffers from vmcore, after crash.
 	 */
-	ltt_write_commit_counter(buf, reserved, slot_size);
+	ltt_write_commit_counter(buf, buf_offset, slot_size);
 	__raw_spin_unlock(&ltt_buf->lock);
 	raw_local_irq_restore(ltt_buf->irqflags);
 }
-- 
1.5.5.1

