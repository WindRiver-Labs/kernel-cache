From a77a5ee880e87837392afb938b3d05286817008a Mon Sep 17 00:00:00 2001
From: Yang Shi <yang.shi@windriver.com>
Date: Wed, 9 May 2012 17:03:57 -0700
Subject: [PATCH 058/248] lttng-instrumentation/lttng-instrumentation-lockdep

LTTng instrumentation lockdep tracepoints

lockdep_hardirqs_off
lockdep_hardirqs_on
lockdep_lock_acquire
lockdep_lock_release
lockdep_softirqs_off
lockdep_softirqs_on

Update for 2.6.37 to remove dependency on immediate values and play nicely with
trace event lockdep instrumentation.

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
---
 include/trace/lockdep.h |   37 +++++++++++++++++++++++++++++++++++++
 kernel/lockdep.c        |   20 ++++++++++++++++++++
 2 files changed, 57 insertions(+), 0 deletions(-)
 create mode 100644 include/trace/lockdep.h

diff --git a/include/trace/lockdep.h b/include/trace/lockdep.h
new file mode 100644
index 0000000..dbd4629
--- /dev/null
+++ b/include/trace/lockdep.h
@@ -0,0 +1,37 @@
+#ifndef _LTTNG_TRACE_LOCKDEP_H
+#define _LTTNG_TRACE_LOCKDEP_H
+
+#include <linux/lockdep.h>
+#include <linux/tracepoint.h>
+
+/*
+ * lockdep tracing must be very careful with respect to reentrancy.
+ *
+ * It should not use immediate values for activation because it involves
+ * traps called when the code patching is done.
+ */
+DECLARE_TRACE(lockdep_hardirqs_on,
+	TP_PROTO(unsigned long retaddr),
+		TP_ARGS(retaddr));
+DECLARE_TRACE(lockdep_hardirqs_off,
+	TP_PROTO(unsigned long retaddr),
+		TP_ARGS(retaddr));
+DECLARE_TRACE(lockdep_softirqs_on,
+	TP_PROTO(unsigned long retaddr),
+		TP_ARGS(retaddr));
+DECLARE_TRACE(lockdep_softirqs_off,
+	TP_PROTO(unsigned long retaddr),
+		TP_ARGS(retaddr));
+
+/* FIXME : some duplication with lockdep TRACE EVENTs */
+DECLARE_TRACE(lockdep_lock_acquire,
+	TP_PROTO(unsigned long retaddr, unsigned int subclass,
+			struct lockdep_map *lock, int trylock, int read,
+			int hardirqs_off),
+		TP_ARGS(retaddr, subclass, lock, trylock, read, hardirqs_off));
+DECLARE_TRACE(lockdep_lock_release,
+	TP_PROTO(unsigned long retaddr, struct lockdep_map *lock, int nested),
+		TP_ARGS(retaddr, lock, nested));
+
+
+#endif /* _LTTNG_TRACE_LOCKDEP_H */
diff --git a/kernel/lockdep.c b/kernel/lockdep.c
index ea9ee45..6a5ffdf 100644
--- a/kernel/lockdep.c
+++ b/kernel/lockdep.c
@@ -67,6 +67,13 @@ module_param(lock_stat, int, 0644);
 #define lock_stat 0
 #endif
 
+DEFINE_TRACE(lockdep_hardirqs_on);
+DEFINE_TRACE(lockdep_hardirqs_off);
+DEFINE_TRACE(lockdep_softirqs_on);
+DEFINE_TRACE(lockdep_softirqs_off);
+DEFINE_TRACE(lockdep_lock_acquire);
+DEFINE_TRACE(lockdep_lock_release);
+
 /*
  * lockdep_lock: protects the lockdep graph, the hashes and the
  *               class/list/hash allocators.
@@ -2558,6 +2565,8 @@ void trace_hardirqs_on_caller(unsigned long ip)
 {
 	time_hardirqs_on(CALLER_ADDR0, ip);
 
+	trace_lockdep_hardirqs_on(ip);
+
 	if (unlikely(!debug_locks || current->lockdep_recursion))
 		return;
 
@@ -2613,6 +2622,8 @@ void trace_hardirqs_off_caller(unsigned long ip)
 
 	time_hardirqs_off(CALLER_ADDR0, ip);
 
+	trace_lockdep_hardirqs_off(ip);
+
 	if (unlikely(!debug_locks || current->lockdep_recursion))
 		return;
 
@@ -2718,6 +2729,10 @@ static void __lockdep_trace_alloc(gfp_t gfp_mask, unsigned long flags)
 {
 	struct task_struct *curr = current;
 
+	trace_lockdep_softirqs_on(ip);
+
+	trace_lockdep_softirqs_off(ip);
+
 	if (unlikely(!debug_locks))
 		return;
 
@@ -3015,6 +3030,9 @@ static int __lock_acquire(struct lockdep_map *lock, unsigned int subclass,
 	int class_idx;
 	u64 chain_key;
 
+	trace_lockdep_lock_acquire(ip, subclass, lock, trylock, read,
+		hardirqs_off);
+
 	if (!prove_locking)
 		check = 1;
 
@@ -3446,6 +3464,8 @@ __lock_release(struct lockdep_map *lock, int nested, unsigned long ip)
 {
 	struct task_struct *curr = current;
 
+	trace_lockdep_lock_release(ip, lock, nested);
+
 	if (!check_unlock(curr, lock, ip))
 		return;
 
-- 
1.7.0.4

