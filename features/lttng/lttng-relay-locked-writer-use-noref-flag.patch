From 5bad3d985a1543c98d2b64da451c713e6a0e0ae8 Mon Sep 17 00:00:00 2001
From: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date: Thu, 13 May 2010 19:27:43 -0400
Subject: [PATCH 272/391] lttng-relay-locked-writer-use-noref-flag

lttng relay locked writer use noref flag

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
---
 ltt/ltt-relay-locked.c |   52 +++++++++++++++++++++++++++++------------------
 ltt/ltt-relay-locked.h |   33 ++++++++++++++++++------------
 2 files changed, 52 insertions(+), 33 deletions(-)

diff --git a/ltt/ltt-relay-locked.c b/ltt/ltt-relay-locked.c
index f6517f0..446cc71 100644
--- a/ltt/ltt-relay-locked.c
+++ b/ltt/ltt-relay-locked.c
@@ -255,6 +255,11 @@ static int get_subbuf(struct rchan_buf *buf, unsigned long *consumed)
 		local_irq_enable();
 		return -EAGAIN;
 	}
+
+	/* No page exchange, use the writer page directly */
+	buf->rchan_rsb.pages = buf->rchan_wsb[consumed_idx].pages;
+	RCHAN_SB_CLEAR_NOREF(buf->rchan_rsb.pages);
+
 	__raw_spin_unlock(&ltt_buf->lock);
 	local_irq_enable();
 	*consumed = consumed_old;
@@ -272,6 +277,7 @@ static int put_subbuf(struct rchan_buf *buf, unsigned long consumed)
 	__raw_spin_lock(&ltt_buf->lock);
 	consumed_old = consumed;
 	consumed_new = SUBBUF_ALIGN(consumed_old, buf->chan);
+	RCHAN_SB_SET_NOREF(buf->rchan_rsb.pages);
 
 	if (ltt_buf->consumed != consumed_old) {
 		/* We have been pushed by the writer : the last
@@ -819,6 +825,8 @@ static int ltt_relay_create_buffer(struct ltt_trace_struct *trace,
 	atomic_long_set(&ltt_buf->active_readers, 0);
 	init_waitqueue_head(&ltt_buf->write_wait);
 	init_waitqueue_head(&ltt_buf->read_wait);
+
+	RCHAN_SB_CLEAR_NOREF(buf->rchan_wsb[0].pages);
 	ltt_buffer_begin(buf, trace->start_tsc, 0);
 	ltt_buf->commit_count[0] += ltt_subbuffer_header_size();
 	ltt_buf->lock = (raw_spinlock_t)__RAW_SPIN_LOCK_UNLOCKED;
@@ -1150,11 +1158,8 @@ static void ltt_reserve_switch_old_subbuf(
 		- (SUBBUF_OFFSET(offsets->old - 1, rchan)
 		+ 1);
 	offsets->commit_count = ltt_buf->commit_count[oldidx];
-	if (likely((BUFFER_TRUNC(offsets->old - 1, rchan)
-			>> ltt_channel->n_subbufs_order)
-			- ((offsets->commit_count - rchan->subbuf_size)
-			   & ltt_channel->commit_count_mask) == 0))
-		ltt_deliver(buf, oldidx, offsets->commit_count);
+	ltt_check_deliver(ltt_channel, ltt_buf, rchan, buf,
+			  offsets->old - 1, offsets->commit_count, oldidx);
 }
 
 /*
@@ -1175,12 +1180,8 @@ static void ltt_reserve_switch_new_subbuf(
 	ltt_buffer_begin(buf, *tsc, beginidx);
 	ltt_buf->commit_count[beginidx] += ltt_subbuffer_header_size();
 	offsets->commit_count = ltt_buf->commit_count[beginidx];
-	/* Check if the written buffer has to be delivered */
-	if (unlikely((BUFFER_TRUNC(offsets->begin, rchan)
-			>> ltt_channel->n_subbufs_order)
-			- ((offsets->commit_count - rchan->subbuf_size)
-			   & ltt_channel->commit_count_mask) == 0))
-		ltt_deliver(buf, beginidx, offsets->commit_count);
+	ltt_check_deliver(ltt_channel, ltt_buf, rchan, buf,
+			  offsets->begin, offsets->commit_count, beginidx);
 }
 
 /*
@@ -1215,11 +1216,8 @@ static void ltt_reserve_end_switch_current(
 		- (SUBBUF_OFFSET(offsets->end - 1, rchan)
 		+ 1);
 	offsets->commit_count = ltt_buf->commit_count[endidx];
-	if (likely((BUFFER_TRUNC(offsets->end - 1, rchan)
-			>> ltt_channel->n_subbufs_order)
-			- ((offsets->commit_count - rchan->subbuf_size)
-			   & ltt_channel->commit_count_mask) == 0))
-		ltt_deliver(buf, endidx, offsets->commit_count);
+	ltt_check_deliver(ltt_channel, ltt_buf, rchan, buf,
+			  offsets->end - 1, offsets->commit_count, endidx);
 }
 
 /*
@@ -1323,16 +1321,22 @@ void ltt_force_switch_locked_slow(struct rchan_buf *buf,
 	/*
 	 * Push the reader if necessary
 	 */
-	if (mode == FORCE_ACTIVE)
+	if (mode == FORCE_ACTIVE) {
 		ltt_reserve_push_reader(ltt_channel, ltt_buf, rchan,
 					buf, &offsets);
+		ltt_clear_noref_flag(rchan, buf, SUBBUF_INDEX(offsets.end - 1,
+							      rchan));
+	}
 
 	/*
 	 * Switch old subbuffer if needed.
 	 */
-	if (offsets.end_switch_old)
+	if (offsets.end_switch_old) {
+		ltt_clear_noref_flag(rchan, buf, SUBBUF_INDEX(offsets.old - 1,
+							      rchan));
 		ltt_reserve_switch_old_subbuf(ltt_channel, ltt_buf, rchan, buf,
 			&offsets, &tsc);
+	}
 
 	/*
 	 * Populate new subbuffer.
@@ -1427,7 +1431,7 @@ static int ltt_relay_try_reserve_slow(
 			 * overwrite mode. Caused by either a writer OOPS or
 			 * too many nested writes over a reserve/commit pair.
 			 */
-			local_inc(&ltt_buf->events_lost);
+			ltt_buf->events_lost++;
 			return -1;
 		}
 		offsets->size = ltt_get_header_size(ltt_channel,
@@ -1513,11 +1517,19 @@ int ltt_reserve_slot_locked_slow(struct ltt_trace_struct *trace,
 	ltt_reserve_push_reader(ltt_channel, ltt_buf, rchan, buf, &offsets);
 
 	/*
+	 * Clear noref flag for this subbuffer.
+	 */
+	ltt_clear_noref_flag(rchan, buf, SUBBUF_INDEX(offsets.end - 1, rchan));
+
+	/*
 	 * Switch old subbuffer if needed.
 	 */
-	if (unlikely(offsets.end_switch_old))
+	if (unlikely(offsets.end_switch_old)) {
+		ltt_clear_noref_flag(rchan, buf, SUBBUF_INDEX(offsets.old - 1,
+							      rchan));
 		ltt_reserve_switch_old_subbuf(ltt_channel, ltt_buf, rchan, buf,
 			&offsets, tsc);
+	}
 
 	/*
 	 * Populate new subbuffer.
diff --git a/ltt/ltt-relay-locked.h b/ltt/ltt-relay-locked.h
index 6a6adb5..ce16cd5 100644
--- a/ltt/ltt-relay-locked.h
+++ b/ltt/ltt-relay-locked.h
@@ -150,16 +150,26 @@ static __inline__ int last_tsc_overflow(struct ltt_channel_buf_struct *ltt_buf,
 }
 #endif
 
-static __inline__ void ltt_deliver(struct rchan_buf *buf,
-		unsigned int subbuf_idx,
-		long commit_count)
+static __inline__ void ltt_check_deliver(struct ltt_channel_struct *ltt_channel,
+		struct ltt_channel_buf_struct *ltt_buf,
+		struct rchan *rchan,
+		struct rchan_buf *buf,
+		long offset, long commit_count, long idx)
 {
-	struct ltt_channel_buf_struct *ltt_buf = buf->chan_private;
-
+	/* Check if all commits have been done */
+	if (unlikely((BUFFER_TRUNC(offset, rchan)
+			>> ltt_channel->n_subbufs_order)
+			- ((commit_count - rchan->subbuf_size)
+			   & ltt_channel->commit_count_mask) == 0)) {
+		/*
+		 * Set noref flag for this subbuffer.
+		 */
+		ltt_set_noref_flag(rchan, buf, idx);
 #ifdef CONFIG_LTT_VMCORE
-	ltt_buf->commit_seq[subbuf_idx] = commit_count;
+		ltt_buf->commit_seq[subbuf_idx] = commit_count;
 #endif
-	ltt_buf->wakeup_readers = 1;
+		ltt_buf->wakeup_readers = 1;
+	}
 }
 
 /*
@@ -343,12 +353,9 @@ static __inline__ void ltt_commit_slot(
 
 	ltt_buf->commit_count[endidx] += slot_size;
 	commit_count = ltt_buf->commit_count[endidx];
-	/* Check if all commits have been done */
-	if (unlikely((BUFFER_TRUNC(offset_end - 1, rchan)
-			>> ltt_channel->n_subbufs_order)
-			- ((commit_count - rchan->subbuf_size)
-			   & ltt_channel->commit_count_mask) == 0))
-		ltt_deliver(buf, endidx, commit_count);
+
+	ltt_check_deliver(ltt_channel, ltt_buf, rchan, buf,
+			  offset_end - 1, commit_count, endidx);
 	/*
 	 * Update lost_size for each commit. It's needed only for extracting
 	 * ltt buffers from vmcore, after crash.
-- 
1.6.5.2

