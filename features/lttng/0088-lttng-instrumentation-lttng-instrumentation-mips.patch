From cbddc92271f2ba3cf302776e675ac35972349967 Mon Sep 17 00:00:00 2001
From: Yang Shi <yang.shi@windriver.com>
Date: Thu, 10 May 2012 10:58:01 -0700
Subject: [PATCH] lttng-instrumentation/lttng-instrumentation-mips

LTTng - MIPS instrumentation

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>

diff --git a/arch/mips/include/asm/mipsregs.h b/arch/mips/include/asm/mipsregs.h
index 7f87d82..d3ea319 100644
--- a/arch/mips/include/asm/mipsregs.h
+++ b/arch/mips/include/asm/mipsregs.h
@@ -438,6 +438,7 @@
  */
 #define  CAUSEB_EXCCODE		2
 #define  CAUSEF_EXCCODE		(_ULCAST_(31)  <<  2)
+#define  CAUSE_EXCCODE(cause)	(((cause) & CAUSEF_EXCCODE) >> CAUSEB_EXCCODE)
 #define  CAUSEB_IP		8
 #define  CAUSEF_IP		(_ULCAST_(255) <<  8)
 #define  CAUSEB_IP0		8
diff --git a/arch/mips/kernel/linux32.c b/arch/mips/kernel/linux32.c
index 922a554..efb3878 100644
--- a/arch/mips/kernel/linux32.c
+++ b/arch/mips/kernel/linux32.c
@@ -34,6 +34,7 @@
 #include <linux/vfs.h>
 #include <linux/ipc.h>
 #include <linux/slab.h>
+#include <trace/ipc.h>
 
 #include <net/sock.h>
 #include <net/scm.h>
@@ -44,6 +45,8 @@
 #include <asm/mmu_context.h>
 #include <asm/mman.h>
 
+DEFINE_TRACE(ipc_call);
+
 /* Use this to get at 32-bit user passed pointers. */
 /* A() macro should be used for places where you e.g.
    have some internal variable u32 and just want to get
@@ -166,6 +169,8 @@ SYSCALL_DEFINE6(32_ipc, u32, call, long, first, long, second, long, third,
 	version = call >> 16; /* hack for backward compatibility */
 	call &= 0xffff;
 
+	trace_ipc_call(call, first);
+
 	switch (call) {
 	case SEMOP:
 		/* struct sembuf is the same on 32 and 64bit :)) */
diff --git a/arch/mips/kernel/process.c b/arch/mips/kernel/process.c
index 69b17a9..d8ad904 100644
--- a/arch/mips/kernel/process.c
+++ b/arch/mips/kernel/process.c
@@ -25,6 +25,7 @@
 #include <linux/completion.h>
 #include <linux/kallsyms.h>
 #include <linux/random.h>
+#include <trace/sched.h>
 
 #include <asm/asm.h>
 #include <asm/bootinfo.h>
@@ -41,6 +42,8 @@
 #include <asm/inst.h>
 #include <asm/stacktrace.h>
 
+DEFINE_TRACE(sched_kthread_create);
+
 /*
  * The idle thread. There's no useful work to be done, so just try to conserve
  * power and have a low exit latency (ie sit in a loop waiting for somebody to
@@ -230,6 +233,7 @@ static void __noreturn kernel_thread_helper(void *arg, int (*fn)(void *))
 long kernel_thread(int (*fn)(void *), void *arg, unsigned long flags)
 {
 	struct pt_regs regs;
+	long pid;
 
 	memset(&regs, 0, sizeof(regs));
 
@@ -245,7 +249,10 @@ long kernel_thread(int (*fn)(void *), void *arg, unsigned long flags)
 #endif
 
 	/* Ok, create the new process.. */
-	return do_fork(flags | CLONE_VM | CLONE_UNTRACED, 0, &regs, 0, NULL, NULL);
+	pid = do_fork(flags | CLONE_VM | CLONE_UNTRACED,
+			0, &regs, 0, NULL, NULL);
+	trace_sched_kthread_create(fn, pid);
+	return pid;
 }
 
 /*
diff --git a/arch/mips/kernel/ptrace.c b/arch/mips/kernel/ptrace.c
index 7c24c29..5729343 100644
--- a/arch/mips/kernel/ptrace.c
+++ b/arch/mips/kernel/ptrace.c
@@ -25,6 +25,7 @@
 #include <linux/security.h>
 #include <linux/audit.h>
 #include <linux/seccomp.h>
+#include <trace/syscall.h>
 
 #include <asm/byteorder.h>
 #include <asm/cpu.h>
@@ -38,6 +39,9 @@
 #include <asm/bootinfo.h>
 #include <asm/reg.h>
 
+DEFINE_TRACE(syscall_entry);
+DEFINE_TRACE(syscall_exit);
+
 /*
  * Called by kernel/ptrace.c when detaching..
  *
@@ -534,6 +538,8 @@ static inline int audit_arch(void)
  */
 asmlinkage void syscall_trace_enter(struct pt_regs *regs)
 {
+	trace_syscall_entry(regs, regs->regs[2]);
+
 	/* do the secure computing check first */
 	secure_computing(regs->regs[2]);
 
@@ -570,6 +576,8 @@ out:
  */
 asmlinkage void syscall_trace_leave(struct pt_regs *regs)
 {
+	trace_syscall_exit(regs->regs[2]);
+
 	audit_syscall_exit(regs);
 
 	if (!(current->ptrace & PT_PTRACED))
diff --git a/arch/mips/kernel/syscall.c b/arch/mips/kernel/syscall.c
index b08220c..8145327 100644
--- a/arch/mips/kernel/syscall.c
+++ b/arch/mips/kernel/syscall.c
@@ -26,6 +26,7 @@
 #include <linux/uaccess.h>
 #include <linux/slab.h>
 #include <linux/elf.h>
+#include <linux/ipc.h>
 
 #include <asm/asm.h>
 #include <asm/branch.h>
diff --git a/arch/mips/kernel/traps.c b/arch/mips/kernel/traps.c
index 16b2ba3..a72dc17 100644
--- a/arch/mips/kernel/traps.c
+++ b/arch/mips/kernel/traps.c
@@ -30,6 +30,7 @@
 #include <linux/kdb.h>
 #include <linux/irq.h>
 #include <linux/perf_event.h>
+#include <trace/trap.h>
 
 #include <asm/bootinfo.h>
 #include <asm/branch.h>
@@ -54,6 +55,12 @@
 #include <asm/stacktrace.h>
 #include <asm/uasm.h>
 
+/*
+ * Also used in unaligned.c and fault.c.
+ */
+DEFINE_TRACE(trap_entry);
+DEFINE_TRACE(trap_exit);
+
 extern void check_wait(void);
 extern asmlinkage void r4k_wait(void);
 extern asmlinkage void rollback_handle_int(void);
@@ -321,7 +328,7 @@ static void __show_regs(const struct pt_regs *regs)
 
 	printk("Cause : %08x\n", cause);
 
-	cause = (cause & CAUSEF_EXCCODE) >> CAUSEB_EXCCODE;
+	cause = CAUSE_EXCCODE(cause);
 	if (1 <= cause && cause <= 5)
 		printk("BadVA : %0*lx\n", field, regs->cp0_badvaddr);
 
@@ -703,6 +710,7 @@ asmlinkage void do_fpe(struct pt_regs *regs, unsigned long fcr31)
 		return;
 	die_if_kernel("FP exception in kernel code", regs);
 
+	trace_trap_entry(regs, CAUSE_EXCCODE(regs->cp0_cause));
 	if (fcr31 & FPU_CSR_UNI_X) {
 		int sig;
 		void __user *fault_addr = NULL;
@@ -735,7 +743,7 @@ asmlinkage void do_fpe(struct pt_regs *regs, unsigned long fcr31)
 
 		/* If something went wrong, signal */
 		process_fpemu_return(sig, fault_addr);
-
+		trace_trap_exit();
 		return;
 	} else if (fcr31 & FPU_CSR_INV_X)
 		info.si_code = FPE_FLTINV;
@@ -753,6 +761,7 @@ asmlinkage void do_fpe(struct pt_regs *regs, unsigned long fcr31)
 	info.si_errno = 0;
 	info.si_addr = (void __user *) regs->cp0_epc;
 	force_sig_info(SIGFPE, &info, current);
+	trace_trap_exit();
 }
 
 static void do_trap_or_bp(struct pt_regs *regs, unsigned int code,
@@ -985,6 +994,8 @@ asmlinkage void do_cpu(struct pt_regs *regs)
 	int status;
 	unsigned long __maybe_unused flags;
 
+	trace_trap_entry(regs, CAUSE_EXCCODE(regs->cp0_cause));
+
 	die_if_kernel("do_cpu invoked from kernel context!", regs);
 
 	msa_kernel();
@@ -998,8 +1009,10 @@ asmlinkage void do_cpu(struct pt_regs *regs)
 		opcode = 0;
 		status = -1;
 
-		if (unlikely(compute_return_epc(regs) < 0))
+		if (unlikely(compute_return_epc(regs) < 0)) {
+			trace_trap_exit();
 			return;
+		}
 
 		if (unlikely(get_user(opcode, epc) < 0))
 			status = SIGSEGV;
@@ -1017,7 +1030,7 @@ asmlinkage void do_cpu(struct pt_regs *regs)
 			regs->cp0_epc = old_epc;	/* Undo skip-over.  */
 			force_sig(status, current);
 		}
-
+		trace_trap_exit();
 		return;
 
 	case 1:
@@ -1037,11 +1050,12 @@ asmlinkage void do_cpu(struct pt_regs *regs)
 			if (!process_fpemu_return(sig, fault_addr))
 				mt_ase_fp_affinity();
 		}
-
+		trace_trap_exit();
 		return;
 
 	case 2:
 		raw_notifier_call_chain(&cu2_chain, CU2_EXCEPTION, regs);
+		trace_trap_exit();
 		return;
 
 	case 3:
@@ -1049,6 +1063,7 @@ asmlinkage void do_cpu(struct pt_regs *regs)
 	}
 
 	force_sig(SIGILL, current);
+	trace_trap_exit();
 }
 
 asmlinkage void do_mdmx(struct pt_regs *regs)
diff --git a/arch/mips/kernel/unaligned.c b/arch/mips/kernel/unaligned.c
index 9c58bdf..554f4f7 100644
--- a/arch/mips/kernel/unaligned.c
+++ b/arch/mips/kernel/unaligned.c
@@ -78,6 +78,7 @@
 #include <linux/sched.h>
 #include <linux/debugfs.h>
 #include <linux/perf_event.h>
+#include <trace/trap.h>
 
 #include <asm/asm.h>
 #include <asm/branch.h>
@@ -515,6 +516,7 @@ asmlinkage void do_ade(struct pt_regs *regs)
 
 	perf_sw_event(PERF_COUNT_SW_ALIGNMENT_FAULTS,
 			1, regs, regs->cp0_badvaddr);
+	trace_trap_entry(regs, CAUSE_EXCCODE(regs->cp0_cause));
 	/*
 	 * Did we catch a fault trying to load an instruction?
 	 * Or are we running in MIPS16 mode?
@@ -540,6 +542,8 @@ asmlinkage void do_ade(struct pt_regs *regs)
 	emulate_load_store_insn(regs, (void __user *)regs->cp0_badvaddr, pc);
 	set_fs(seg);
 
+	trace_trap_exit();
+
 	return;
 
 sigbus:
@@ -549,6 +553,8 @@ sigbus:
 	/*
 	 * XXX On return from the signal handler we should advance the epc
 	 */
+
+	trace_trap_exit();
 }
 
 #ifdef CONFIG_DEBUG_FS
diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index a0706c4..daba703 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -19,6 +19,7 @@
 #include <linux/module.h>
 #include <linux/kprobes.h>
 #include <linux/perf_event.h>
+#include <trace/fault.h>
 
 #include <asm/branch.h>
 #include <asm/mmu_context.h>
@@ -27,6 +28,9 @@
 #include <asm/highmem.h>		/* For VMALLOC_END */
 #include <linux/kdebug.h>
 
+DEFINE_TRACE(page_fault_entry);
+DEFINE_TRACE(page_fault_exit);
+
 /*
  * This routine handles page faults.  It determines the address,
  * and the problem, and then passes it off to one of the appropriate
@@ -152,7 +156,10 @@ good_area:
 	 * make sure we exit gracefully rather than endlessly redo
 	 * the fault.
 	 */
+	trace_page_fault_entry(regs, CAUSE_EXCCODE(regs->cp0_cause), mm, vma,
+			       address, write);
 	fault = handle_mm_fault(mm, vma, address, flags);
+	trace_page_fault_exit(fault);
 
 	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
 		return;
-- 
1.8.3.1

