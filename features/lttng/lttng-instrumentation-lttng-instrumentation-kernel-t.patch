From efc0b598bb8c6d561c6712d26887f279e45775f1 Mon Sep 17 00:00:00 2001
From: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date: Thu, 13 May 2010 19:25:57 -0400
Subject: [PATCH 082/391] lttng-instrumentation/lttng-instrumentation-kernel-tracepoints-probes

LTTng instrumentation kernel tracepoint probes

Create a module which declares kernel tracepoint probes, using markers.

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
CC: Alexander Viro <viro@zeniv.linux.org.uk>
CC: 'Peter Zijlstra' <peterz@infradead.org>
CC: "Frank Ch. Eigler" <fche@redhat.com>
CC: 'Ingo Molnar' <mingo@elte.hu>
CC: 'Hideo AOKI' <haoki@redhat.com>
CC: Takashi Nishiie <t-nishiie@np.css.fujitsu.com>
CC: 'Steven Rostedt' <rostedt@goodmis.org>
CC: Masami Hiramatsu <mhiramat@redhat.com>
---
 ltt/probes/Makefile       |    6 +
 ltt/probes/kernel-trace.c |  551 +++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 557 insertions(+), 0 deletions(-)
 create mode 100644 ltt/probes/kernel-trace.c

diff --git a/ltt/probes/Makefile b/ltt/probes/Makefile
index a8b481e..4ed52f4 100644
--- a/ltt/probes/Makefile
+++ b/ltt/probes/Makefile
@@ -1 +1,7 @@
 # LTTng tracing probes
+
+ifdef CONFIG_FTRACE
+CFLAGS_REMOVE_kernel-trace.o = -pg
+endif
+
+obj-$(CONFIG_LTT_TRACEPROBES)	+= kernel-trace.o
diff --git a/ltt/probes/kernel-trace.c b/ltt/probes/kernel-trace.c
new file mode 100644
index 0000000..dfdbb77
--- /dev/null
+++ b/ltt/probes/kernel-trace.c
@@ -0,0 +1,551 @@
+/*
+ * ltt/probes/kernel-trace.c
+ *
+ * kernel tracepoint probes.
+ *
+ * (C) Copyright 2009 - Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
+ * Dual LGPL v2.1/GPL v2 license.
+ */
+
+#include <linux/module.h>
+#include <linux/irq.h>
+#include <linux/ltt-tracer.h>
+#include <linux/ltt-type-serializer.h>
+#include <trace/events/signal.h>
+#include <trace/irq.h>
+#include <trace/sched.h>
+#include <trace/timer.h>
+#include <trace/kernel.h>
+#include <trace/fault.h>
+
+/*
+ * This should probably be added to s390.
+ */
+#ifdef CONFIG_S390
+static struct pt_regs *get_irq_regs(void)
+{
+	return task_pt_regs(current);
+}
+#endif
+
+/*
+ * FIXME :
+ * currently, the specialized tracepoint probes cannot call into other marker
+ * probes, such as ftrace enable/disable. Given we want them to be as fast as
+ * possible, it might not be so bad to lose this flexibility. But that means
+ * such probes would have to connect to tracepoints on their own.
+ */
+
+/* kernel_irq_entry specialized tracepoint probe */
+
+void probe_irq_entry(unsigned int id, struct pt_regs *regs,
+	struct irqaction *action);
+
+DEFINE_MARKER_TP(kernel_irq_entry, irq_entry, probe_irq_entry,
+	"ip %lu handler %p irq_id #2u%u kernel_mode #1u%u");
+
+notrace void probe_irq_entry(unsigned int id, struct pt_regs *regs,
+	struct irqaction *action)
+{
+	struct marker *marker;
+	struct serialize_long_long_short_char data;
+
+	if (unlikely(!regs))
+		regs = get_irq_regs();
+	if (likely(regs)) {
+		data.f1 = instruction_pointer(regs);
+		data.f4 = !user_mode(regs);
+	} else {
+		data.f1 = 0UL;
+		data.f4 = 1;
+	}
+	data.f2 = (unsigned long) (action ? action->handler : NULL);
+	data.f3 = id;
+
+	marker = &GET_MARKER(kernel_irq_entry);
+	ltt_specialized_trace(marker->single.probe_private,
+		&data, serialize_sizeof(data), sizeof(long));
+}
+
+void probe_irq_next_handler(unsigned int id, struct irqaction *action,
+		irqreturn_t prev_ret);
+
+DEFINE_MARKER_TP(kernel_irq_next_handler, irq_next_handler,
+	probe_irq_next_handler,
+	"handler %p prev_ret #1u%u");
+
+notrace void probe_irq_next_handler(unsigned int id, struct irqaction *action,
+		irqreturn_t prev_ret)
+{
+	struct marker *marker;
+	struct serialize_long_char data;
+
+	data.f1 = (unsigned long) (action ? action->handler : NULL);
+	data.f2 = prev_ret;
+
+	marker = &GET_MARKER(kernel_irq_next_handler);
+	ltt_specialized_trace(marker->single.probe_private,
+		&data, serialize_sizeof(data), sizeof(long));
+}
+
+/* kernel_irq_exit specialized tracepoint probe */
+
+void probe_irq_exit(irqreturn_t retval);
+
+DEFINE_MARKER_TP(kernel_irq_exit, irq_exit, probe_irq_exit,
+	"handled #1u%u");
+
+notrace void probe_irq_exit(irqreturn_t retval)
+{
+	struct marker *marker;
+	unsigned char data;
+
+	data = IRQ_RETVAL(retval);
+
+	marker = &GET_MARKER(kernel_irq_exit);
+	ltt_specialized_trace(marker->single.probe_private,
+		&data, sizeof(data), sizeof(data));
+}
+
+/* kernel_softirq_entry specialized tracepoint probe */
+
+void probe_irq_softirq_entry(struct softirq_action *h,
+	struct softirq_action *softirq_vec);
+
+DEFINE_MARKER_TP(kernel_softirq_entry, irq_softirq_entry,
+	probe_irq_softirq_entry, "softirq_id #1u%lu");
+
+notrace void probe_irq_softirq_entry(struct softirq_action *h,
+	struct softirq_action *softirq_vec)
+{
+	struct marker *marker;
+	unsigned char data;
+
+	data = ((unsigned long)h - (unsigned long)softirq_vec) / sizeof(*h);
+
+	marker = &GET_MARKER(kernel_softirq_entry);
+	ltt_specialized_trace(marker->single.probe_private,
+		&data, sizeof(data), sizeof(data));
+}
+
+/* kernel_softirq_exit specialized tracepoint probe */
+
+void probe_irq_softirq_exit(struct softirq_action *h,
+	struct softirq_action *softirq_vec);
+
+DEFINE_MARKER_TP(kernel_softirq_exit, irq_softirq_exit,
+	probe_irq_softirq_exit, "softirq_id #1u%lu");
+
+notrace void probe_irq_softirq_exit(struct softirq_action *h,
+	struct softirq_action *softirq_vec)
+{
+	struct marker *marker;
+	unsigned char data;
+
+	data = ((unsigned long)h - (unsigned long)softirq_vec) / sizeof(*h);
+
+	marker = &GET_MARKER(kernel_softirq_exit);
+	ltt_specialized_trace(marker->single.probe_private,
+		&data, sizeof(data), sizeof(data));
+}
+
+/* kernel_softirq_raise specialized tracepoint probe */
+
+void probe_irq_softirq_raise(unsigned int nr);
+
+DEFINE_MARKER_TP(kernel_softirq_raise, irq_softirq_raise,
+	probe_irq_softirq_raise, "softirq_id #1u%u");
+
+notrace void probe_irq_softirq_raise(unsigned int nr)
+{
+	struct marker *marker;
+	unsigned char data;
+
+	data = nr;
+
+	marker = &GET_MARKER(kernel_softirq_raise);
+	ltt_specialized_trace(marker->single.probe_private,
+		&data, sizeof(data), sizeof(data));
+}
+
+/* Standard probes */
+void probe_irq_tasklet_low_entry(struct tasklet_struct *t)
+{
+	trace_mark_tp(kernel_tasklet_low_entry, irq_tasklet_low_entry,
+		probe_irq_tasklet_low_entry, "func %p data %lu",
+		t->func, t->data);
+}
+
+void probe_irq_tasklet_low_exit(struct tasklet_struct *t)
+{
+	trace_mark_tp(kernel_tasklet_low_exit, irq_tasklet_low_exit,
+		probe_irq_tasklet_low_exit, "func %p data %lu",
+		t->func, t->data);
+}
+
+void probe_irq_tasklet_high_entry(struct tasklet_struct *t)
+{
+	trace_mark_tp(kernel_tasklet_high_entry, irq_tasklet_high_entry,
+		probe_irq_tasklet_high_entry, "func %p data %lu",
+		t->func, t->data);
+}
+
+void probe_irq_tasklet_high_exit(struct tasklet_struct *t)
+{
+	trace_mark_tp(kernel_tasklet_high_exit, irq_tasklet_high_exit,
+		probe_irq_tasklet_high_exit, "func %p data %lu",
+		t->func, t->data);
+}
+
+void probe_sched_kthread_stop(struct task_struct *t)
+{
+	trace_mark_tp(kernel_kthread_stop, sched_kthread_stop,
+		probe_sched_kthread_stop, "pid %d", t->pid);
+}
+
+void probe_sched_kthread_stop_ret(int ret)
+{
+	trace_mark_tp(kernel_kthread_stop_ret, sched_kthread_stop_ret,
+		probe_sched_kthread_stop_ret, "ret %d", ret);
+}
+
+void probe_sched_wait_task(struct rq *rq, struct task_struct *p)
+{
+	trace_mark_tp(kernel_sched_wait_task, sched_wait_task,
+		probe_sched_wait_task, "pid %d state #2d%ld",
+		p->pid, p->state);
+}
+
+/* kernel_sched_try_wakeup specialized tracepoint probe */
+
+void probe_sched_wakeup(struct rq *rq, struct task_struct *p);
+
+DEFINE_MARKER_TP(kernel_sched_try_wakeup, sched_wakeup,
+	probe_sched_wakeup, "pid %d cpu_id %u state #2d%ld");
+
+notrace void probe_sched_wakeup(struct rq *rq, struct task_struct *p)
+{
+	struct marker *marker;
+	struct serialize_int_int_short data;
+
+	data.f1 = p->pid;
+	data.f2 = task_cpu(p);
+	data.f3 = p->state;
+
+	marker = &GET_MARKER(kernel_sched_try_wakeup);
+	ltt_specialized_trace(marker->single.probe_private,
+		&data, serialize_sizeof(data), sizeof(int));
+}
+
+void probe_sched_wakeup_new(struct rq *rq, struct task_struct *p, int success)
+{
+	trace_mark_tp(kernel_sched_wakeup_new_task, sched_wakeup_new,
+		probe_sched_wakeup_new, "pid %d state #2d%ld cpu_id %u",
+		p->pid, p->state, task_cpu(p));
+}
+
+/* kernel_sched_schedule specialized tracepoint probe */
+
+void probe_sched_switch(struct rq *rq, struct task_struct *prev,
+		struct task_struct *next);
+
+DEFINE_MARKER_TP(kernel_sched_schedule, sched_switch, probe_sched_switch,
+	"prev_pid %d next_pid %d prev_state #2d%ld");
+
+notrace void probe_sched_switch(struct rq *rq, struct task_struct *prev,
+		struct task_struct *next)
+{
+	struct marker *marker;
+	struct serialize_int_int_short data;
+
+	data.f1 = prev->pid;
+	data.f2 = next->pid;
+	data.f3 = prev->state;
+
+	marker = &GET_MARKER(kernel_sched_schedule);
+	ltt_specialized_trace(marker->single.probe_private,
+		&data, serialize_sizeof(data), sizeof(int));
+}
+
+void probe_sched_migrate_task(struct task_struct *p, int dest_cpu)
+{
+	trace_mark_tp(kernel_sched_migrate_task, sched_migrate_task,
+		probe_sched_migrate_task, "pid %d state #2d%ld dest_cpu %d",
+		p->pid, p->state, dest_cpu);
+}
+
+void probe_sched_signal_send(int sig, struct siginfo *info, struct task_struct *t)
+{
+	trace_mark_tp(kernel_send_signal, signal_generate,
+		probe_sched_signal_send, "pid %d signal %d", t->pid, sig);
+}
+
+void probe_sched_process_free(struct task_struct *p)
+{
+	trace_mark_tp(kernel_process_free, sched_process_free,
+		probe_sched_process_free, "pid %d", p->pid);
+}
+
+void probe_sched_process_exit(struct task_struct *p)
+{
+	trace_mark_tp(kernel_process_exit, sched_process_exit,
+		probe_sched_process_exit, "pid %d", p->pid);
+}
+
+void probe_sched_process_wait(struct pid *pid)
+{
+	trace_mark_tp(kernel_process_wait, sched_process_wait,
+		probe_sched_process_wait, "pid %d", pid_nr(pid));
+}
+
+void probe_sched_process_fork(struct task_struct *parent,
+		struct task_struct *child)
+{
+	trace_mark_tp(kernel_process_fork, sched_process_fork,
+		probe_sched_process_fork,
+		"parent_pid %d child_pid %d child_tgid %d",
+		parent->pid, child->pid, child->tgid);
+}
+
+void probe_timer_itimer_expired(struct signal_struct *sig)
+{
+	trace_mark_tp(kernel_timer_itimer_expired, timer_itimer_expired,
+		probe_timer_itimer_expired, "pid %d",
+		pid_nr(sig->leader_pid));
+}
+
+void probe_timer_itimer_set(int which, struct itimerval *value)
+{
+	trace_mark_tp(kernel_timer_itimer_set,
+		timer_itimer_set, probe_timer_itimer_set,
+		"which %d interval_sec %ld interval_usec %ld "
+		"value_sec %ld value_usec %ld",
+		which,
+		value->it_interval.tv_sec,
+		value->it_interval.tv_usec,
+		value->it_value.tv_sec,
+		value->it_value.tv_usec);
+}
+
+/* kernel_timer_set specialized tracepoint probe */
+
+void probe_timer_set(struct timer_list *timer);
+
+DEFINE_MARKER_TP(kernel_timer_set, timer_set, probe_timer_set,
+	"expires %lu function %p data %lu");
+
+notrace void probe_timer_set(struct timer_list *timer)
+{
+	struct marker *marker;
+	struct serialize_long_long_long data;
+
+	data.f1 = timer->expires;
+	data.f2 = (unsigned long)timer->function;
+	data.f3 = timer->data;
+
+	marker = &GET_MARKER(kernel_timer_set);
+	ltt_specialized_trace(marker->single.probe_private,
+		&data, serialize_sizeof(data), sizeof(long));
+}
+
+void probe_timer_update_time(struct timespec *_xtime,
+		struct timespec *_wall_to_monotonic)
+{
+	trace_mark_tp(kernel_timer_update_time, timer_update_time,
+		probe_timer_update_time,
+		"jiffies #8u%llu xtime_sec %ld xtime_nsec %ld "
+		"walltomonotonic_sec %ld walltomonotonic_nsec %ld",
+		(unsigned long long)jiffies_64, _xtime->tv_sec, _xtime->tv_nsec,
+		_wall_to_monotonic->tv_sec, _wall_to_monotonic->tv_nsec);
+}
+
+void probe_timer_timeout(struct task_struct *p)
+{
+	trace_mark_tp(kernel_timer_timeout, timer_timeout,
+		probe_timer_timeout, "pid %d", p->pid);
+}
+
+void probe_kernel_printk(unsigned long retaddr)
+{
+	trace_mark_tp(kernel_printk, kernel_printk,
+		probe_kernel_printk, "ip 0x%lX", retaddr);
+}
+
+void probe_kernel_vprintk(unsigned long retaddr, char *buf, int len)
+{
+	if (len > 0) {
+		unsigned int loglevel;
+		int mark_len;
+		char *mark_buf;
+		char saved_char;
+
+		if (buf[0] == '<' && buf[1] >= '0' &&
+		   buf[1] <= '7' && buf[2] == '>') {
+			loglevel = buf[1] - '0';
+			mark_buf = &buf[3];
+			mark_len = len - 3;
+		} else {
+			loglevel = default_message_loglevel;
+			mark_buf = buf;
+			mark_len = len;
+		}
+		if (mark_buf[mark_len - 1] == '\n')
+			mark_len--;
+		saved_char = mark_buf[mark_len];
+		mark_buf[mark_len] = '\0';
+		trace_mark_tp(kernel_vprintk, kernel_vprintk,
+			probe_kernel_vprintk,
+			"loglevel #1u%u string %s ip 0x%lX",
+			loglevel, mark_buf, retaddr);
+		mark_buf[mark_len] = saved_char;
+	}
+}
+
+#ifdef CONFIG_MODULES
+void probe_kernel_module_free(struct module *mod)
+{
+	trace_mark_tp(kernel_module_free, kernel_module_free,
+		probe_kernel_module_free, "name %s", mod->name);
+}
+
+void probe_kernel_module_load(struct module *mod)
+{
+	trace_mark_tp(kernel_module_load, kernel_module_load,
+		probe_kernel_module_load, "name %s", mod->name);
+}
+#endif
+
+/* kernel_page_fault_entry specialized tracepoint probe */
+
+void probe_kernel_page_fault_entry(struct pt_regs *regs, int trapnr,
+	struct mm_struct *mm, struct vm_area_struct *vma,
+	unsigned long address, int write_access);
+
+DEFINE_MARKER_TP(kernel, page_fault_entry, page_fault_entry,
+	probe_kernel_page_fault_entry,
+	"ip #p%lu address #p%lu trap_id #2u%u write_access #1u%u");
+
+notrace void probe_kernel_page_fault_entry(struct pt_regs *regs, int trapnr,
+	struct mm_struct *mm, struct vm_area_struct *vma,
+	unsigned long address, int write_access)
+{
+	struct marker *marker;
+	struct serialize_long_long_short_char data;
+
+	if (likely(regs))
+		data.f1 = instruction_pointer(regs);
+	else
+		data.f1 = 0UL;
+	data.f2 = address;
+	data.f3 = (unsigned short)trapnr;
+	data.f4 = (unsigned char)!!write_access;
+
+	marker = &GET_MARKER(kernel, page_fault_entry);
+	ltt_specialized_trace(marker, marker->single.probe_private,
+		&data, serialize_sizeof(data), sizeof(long));
+}
+
+/* kernel_page_fault_exit specialized tracepoint probe */
+
+void probe_kernel_page_fault_exit(int res);
+
+DEFINE_MARKER_TP(kernel, page_fault_exit, page_fault_exit,
+	probe_kernel_page_fault_exit,
+	"res %d");
+
+notrace void probe_kernel_page_fault_exit(int res)
+{
+	struct marker *marker;
+
+	marker = &GET_MARKER(kernel, page_fault_exit);
+	ltt_specialized_trace(marker, marker->single.probe_private,
+		&res, sizeof(res), sizeof(res));
+}
+
+/* kernel_page_fault_nosem_entry specialized tracepoint probe */
+
+void probe_kernel_page_fault_nosem_entry(struct pt_regs *regs,
+	int trapnr, unsigned long address);
+
+DEFINE_MARKER_TP(kernel, page_fault_nosem_entry, page_fault_nosem_entry,
+	probe_kernel_page_fault_nosem_entry,
+	"ip #p%lu address #p%lu trap_id #2u%u");
+
+notrace void probe_kernel_page_fault_nosem_entry(struct pt_regs *regs,
+	int trapnr, unsigned long address)
+{
+	struct marker *marker;
+	struct serialize_long_long_short data;
+
+	if (likely(regs))
+		data.f1 = instruction_pointer(regs);
+	else
+		data.f1 = 0UL;
+	data.f2 = address;
+	data.f3 = (unsigned short)trapnr;
+
+	marker = &GET_MARKER(kernel, page_fault_nosem_entry);
+	ltt_specialized_trace(marker, marker->single.probe_private,
+		&data, serialize_sizeof(data), sizeof(long));
+}
+
+/* kernel_page_fault_nosem_exit specialized tracepoint probe */
+
+void probe_kernel_page_fault_nosem_exit(int res);
+
+DEFINE_MARKER_TP(kernel, page_fault_nosem_exit, page_fault_nosem_exit,
+	probe_kernel_page_fault_nosem_exit,
+	MARK_NOARGS);
+
+notrace void probe_kernel_page_fault_nosem_exit(int res)
+{
+	struct marker *marker;
+
+	marker = &GET_MARKER(kernel, page_fault_nosem_exit);
+	ltt_specialized_trace(marker, marker->single.probe_private,
+		NULL, 0, 0);
+}
+
+/* kernel_page_fault_get_user_entry specialized tracepoint probe */
+
+void probe_kernel_page_fault_get_user_entry(struct mm_struct *mm,
+	struct vm_area_struct *vma, unsigned long address, int write_access);
+
+DEFINE_MARKER_TP(kernel, page_fault_get_user_entry, page_fault_get_user_entry,
+	probe_kernel_page_fault_get_user_entry,
+	"address #p%lu write_access #1u%u");
+
+notrace void probe_kernel_page_fault_get_user_entry(struct mm_struct *mm,
+	struct vm_area_struct *vma, unsigned long address, int write_access)
+{
+	struct marker *marker;
+	struct serialize_long_char data;
+
+	data.f1 = address;
+	data.f2 = (unsigned char)!!write_access;
+
+	marker = &GET_MARKER(kernel, page_fault_get_user_entry);
+	ltt_specialized_trace(marker, marker->single.probe_private,
+		&data, serialize_sizeof(data), sizeof(long));
+}
+
+/* kernel_page_fault_get_user_exit specialized tracepoint probe */
+
+void probe_kernel_page_fault_get_user_exit(int res);
+
+DEFINE_MARKER_TP(kernel, page_fault_get_user_exit, page_fault_get_user_exit,
+	probe_kernel_page_fault_get_user_exit,
+	"res %d");
+
+notrace void probe_kernel_page_fault_get_user_exit(int res)
+{
+	struct marker *marker;
+
+	marker = &GET_MARKER(kernel, page_fault_get_user_exit);
+	ltt_specialized_trace(marker, marker->single.probe_private,
+		&res, sizeof(res), sizeof(res));
+}
+
+MODULE_LICENSE("GPL and additional rights");
+MODULE_AUTHOR("Mathieu Desnoyers");
+MODULE_DESCRIPTION("kernel Tracepoint Probes");
-- 
1.6.5.2

