From b2a5a2181f6cf56472fabff8195a31fdef78843f Mon Sep 17 00:00:00 2001
From: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date: Thu, 13 May 2010 19:27:21 -0400
Subject: [PATCH 234/390] lttng-vmcore-fix-irqoff

LTTng vmcore fix irqoff

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
---
 ltt/ltt-relay-irqoff.c |   22 +++++++++++++--
 ltt/ltt-relay-irqoff.h |   71 ++++++++++++++++++++++++-----------------------
 2 files changed, 55 insertions(+), 38 deletions(-)

diff --git a/ltt/ltt-relay-irqoff.c b/ltt/ltt-relay-irqoff.c
index 18dce2a..5ab723b 100644
--- a/ltt/ltt-relay-irqoff.c
+++ b/ltt/ltt-relay-irqoff.c
@@ -791,6 +791,19 @@ static int ltt_relay_create_buffer(struct ltt_trace_struct *trace,
 		kfree(ltt_buf);
 		return -ENOMEM;
 	}
+
+#ifdef CONFIG_LTT_VMCORE
+	ltt_buf->commit_seq =
+		kzalloc_node(ALIGN(sizeof(ltt_buf->commit_seq) * n_subbufs,
+				   1 << INTERNODE_CACHE_SHIFT),
+			GFP_KERNEL, cpu_to_node(cpu));
+	if (!ltt_buf->commit_seq) {
+		kfree(ltt_buf->commit_count);
+		kfree(ltt_buf);
+		return -ENOMEM;
+	}
+#endif
+
 	buf->chan_private = ltt_buf;
 
 	kref_get(&trace->kref);
@@ -828,6 +841,9 @@ static void ltt_relay_destroy_buffer(struct ltt_channel_struct *ltt_chan,
 	kref_put(&ltt_chan->trace->ltt_transport_kref,
 		ltt_release_transport);
 	ltt_relay_print_buffer_errors(ltt_chan, cpu);
+#ifdef CONFIG_LTT_VMCORE
+	kfree(ltt_buf->commit_seq);
+#endif
 	kfree(ltt_buf->commit_count);
 	kfree(ltt_buf);
 	kref_put(&trace->kref, ltt_release_trace);
@@ -1182,7 +1198,7 @@ static void ltt_reserve_switch_old_subbuf(
 			>> ltt_channel->n_subbufs_order)
 			- ((offsets->commit_count - rchan->subbuf_size)
 				& ltt_channel->commit_count_mask) == 0))
-		ltt_deliver(buf, oldidx, NULL);
+		ltt_deliver(buf, oldidx, offsets->commit_count);
 }
 
 /*
@@ -1211,7 +1227,7 @@ static void ltt_reserve_switch_new_subbuf(
 			>> ltt_channel->n_subbufs_order)
 			- ((offsets->commit_count - rchan->subbuf_size)
 				& ltt_channel->commit_count_mask) == 0))
-		ltt_deliver(buf, beginidx, NULL);
+		ltt_deliver(buf, beginidx, offsets->commit_count);
 }
 
 
@@ -1253,7 +1269,7 @@ static void ltt_reserve_end_switch_current(
 			>> ltt_channel->n_subbufs_order)
 			- ((offsets->commit_count - rchan->subbuf_size)
 				& ltt_channel->commit_count_mask) == 0))
-		ltt_deliver(buf, endidx, NULL);
+		ltt_deliver(buf, endidx, offsets->commit_count);
 }
 
 /*
diff --git a/ltt/ltt-relay-irqoff.h b/ltt/ltt-relay-irqoff.h
index 3238dc2..c6b09c2 100644
--- a/ltt/ltt-relay-irqoff.h
+++ b/ltt/ltt-relay-irqoff.h
@@ -77,6 +77,9 @@ struct ltt_channel_buf_struct {
 					 * Last timestamp written in the buffer.
 					 */
 	/* End of first 32 bytes cacheline */
+#ifdef CONFIG_LTT_VMCORE
+	local_t *commit_seq;		/* Consecutive commits */
+#endif
 	atomic_long_t consumed;		/*
 					 * Current offset in the buffer
 					 * standard atomic access (shared)
@@ -158,11 +161,15 @@ static __inline__ int last_tsc_overflow(struct ltt_channel_buf_struct *ltt_buf,
 }
 #endif
 
-static __inline__ void ltt_deliver(struct rchan_buf *buf, unsigned int subbuf_idx,
-		void *subbuf)
+static __inline__ void ltt_deliver(struct rchan_buf *buf,
+		unsigned int subbuf_idx,
+		long commit_count)
 {
 	struct ltt_channel_buf_struct *ltt_buf = buf->chan_private;
 
+#ifdef CONFIG_LTT_VMCORE
+	local_set(&ltt_buf->commit_seq[subbuf_idx], commit_count);
+#endif
 	atomic_set(&ltt_buf->wakeup_readers, 1);
 }
 
@@ -184,7 +191,9 @@ static __inline__ int ltt_relay_try_reserve(
 	*tsc = trace_clock_read64();
 
 	prefetch(&ltt_buf->commit_count[SUBBUF_INDEX(*o_begin, rchan)]);
-
+#ifdef CONFIG_LTT_VMCORE
+	prefetch(&ltt_buf->commit_seq[SUBBUF_INDEX(*o_begin, rchan)]);
+#endif
 	if (last_tsc_overflow(ltt_buf, *tsc))
 		*rflags = LTT_RFLAG_ID_SIZE_TSC;
 
@@ -283,42 +292,31 @@ static __inline__ void ltt_force_switch(struct rchan_buf *buf,
  * This function decrements de subbuffer's lost_size each time the commit count
  * reaches back the reserve offset (module subbuffer size). It is useful for
  * crash dump.
- * We use slot_size - 1 to make sure we deal correctly with the case where we
- * fill the subbuffer completely (so the subbuf index stays in the previous
- * subbuffer).
  */
 #ifdef CONFIG_LTT_VMCORE
 static __inline__ void ltt_write_commit_counter(struct rchan_buf *buf,
-		long buf_offset, size_t slot_size)
+		struct ltt_channel_buf_struct *ltt_buf,
+		long idx, long buf_offset, long commit_count, size_t data_size)
 {
-	struct ltt_channel_buf_struct *ltt_buf = buf->chan_private;
-	struct ltt_subbuffer_header *header;
-	long offset, subbuf_idx, commit_count;
-	uint32_t lost_old, lost_new;
-
-	subbuf_idx = SUBBUF_INDEX(buf_offset - 1, buf->chan);
-	offset = buf_offset + slot_size;
-	header = (struct ltt_subbuffer_header *)
-			ltt_relay_offset_address(buf,
-				subbuf_idx * buf->chan->subbuf_size);
-	for (;;) {
-		lost_old = header->lost_size;
-		commit_count =
-			local_read(&ltt_buf->commit_count[subbuf_idx]);
-		/* SUBBUF_OFFSET includes commit_count_mask */
-		if (likely(!SUBBUF_OFFSET(offset - commit_count, buf->chan))) {
-			lost_new = (uint32_t)buf->chan->subbuf_size
-				   - SUBBUF_OFFSET(commit_count, buf->chan);
-			local_set(&header->lost_size, lost_new);
-			break;
-		} else {
-			break;
-		}
-	}
+	long offset;
+
+	offset = buf_offset + data_size;
+
+	/*
+	 * SUBBUF_OFFSET includes commit_count_mask. We can simply
+	 * compare the offsets within the subbuffer without caring about
+	 * buffer full/empty mismatch because offset is never zero here
+	 * (subbuffer header and event headers have non-zero length).
+	 */
+	if (unlikely(SUBBUF_OFFSET(offset - commit_count, buf->chan)))
+		return;
+
+	local_set(&ltt_buf->commit_seq[idx], commit_count);
 }
 #else
 static __inline__ void ltt_write_commit_counter(struct rchan_buf *buf,
-		long buf_offset, size_t slot_size)
+		struct ltt_channel_buf_struct *ltt_buf,
+		long idx, long buf_offset, long commit_count, size_t data_size)
 {
 }
 #endif
@@ -332,11 +330,13 @@ static __inline__ void ltt_write_commit_counter(struct rchan_buf *buf,
  * @ltt_channel : channel structure
  * @transport_data: transport-specific data
  * @buf_offset : offset following the event header.
+ * @data_size : size of the event data.
  * @slot_size : size of the reserved slot.
  */
 static __inline__ void ltt_commit_slot(
 		struct ltt_channel_struct *ltt_channel,
-		void **transport_data, long buf_offset, size_t slot_size)
+		void **transport_data, long buf_offset,
+		size_t data_size, size_t slot_size)
 {
 	struct rchan_buf *buf = *transport_data;
 	struct ltt_channel_buf_struct *ltt_buf = buf->chan_private;
@@ -354,12 +354,13 @@ static __inline__ void ltt_commit_slot(
 			>> ltt_channel->n_subbufs_order)
 			- ((commit_count - rchan->subbuf_size)
 			   & ltt_channel->commit_count_mask) == 0))
-		ltt_deliver(buf, endidx, NULL);
+		ltt_deliver(buf, endidx, commit_count);
 	/*
 	 * Update lost_size for each commit. It's needed only for extracting
 	 * ltt buffers from vmcore, after crash.
 	 */
-	ltt_write_commit_counter(buf, buf_offset, slot_size);
+	ltt_write_commit_counter(buf, ltt_buf, endidx,
+				 buf_offset, commit_count, data_size);
 	raw_local_irq_restore(ltt_buf->irqflags);
 }
 
-- 
1.6.5.2

