From 94d395a04f21698d94577b3caa4c8edc6d9c6acc Mon Sep 17 00:00:00 2001
From: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date: Thu, 13 May 2010 19:27:54 -0400
Subject: [PATCH 293/390] lttng-instrumentation-net-move-network-tracepoints

LTTng instrumentation net: move network tracepoints

One of the objectives when tracing the network subsystems is to trace packet
emission as late as possible and packet arrival as soon as possible in order
to have more accurate timing measurements.

This patch moves the xmit tracepoint to the dev_hard_start_xmit() function,
the last function called that is not network interface specific but is called
for every frame. The tracepoint is also duplicated to trace each segmented
packet when GSO is in effect.

The receive tracepoint is moved earlier in the netif_receive_skb() function.
The tracepoint is also duplicated in the netif_rx() function. This enables
more precise measurements for pre-NAPI drivers.

Signed-off-by: Benjamin Poirier <benjamin.poirier@polymtl.ca>
Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
---
 net/core/dev.c |   11 ++++++++---
 1 files changed, 8 insertions(+), 3 deletions(-)

diff --git a/net/core/dev.c b/net/core/dev.c
index 81cf832..486f07e 100644
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -1884,6 +1884,8 @@ int dev_hard_start_xmit(struct sk_buff *skb, struct net_device *dev,
 		if (dev->priv_flags & IFF_XMIT_DST_RELEASE)
 			skb_dst_drop(skb);
 
+		trace_net_dev_xmit(skb);
+
 		rc = ops->ndo_start_xmit(skb, dev);
 		if (rc == NETDEV_TX_OK)
 			txq_trans_update(txq);
@@ -1910,7 +1912,6 @@ gso:
 
 		skb->next = nskb->next;
 		nskb->next = NULL;
-
 		/*
 		 * If device doesnt need nskb->dst, release it right now while
 		 * its hot in this cpu cache
@@ -1918,6 +1919,8 @@ gso:
 		if (dev->priv_flags & IFF_XMIT_DST_RELEASE)
 			skb_dst_drop(nskb);
 
+		trace_net_dev_xmit(nskb);
+
 		rc = ops->ndo_start_xmit(nskb, dev);
 		if (unlikely(rc != NETDEV_TX_OK)) {
 			if (rc & ~NETDEV_TX_MASK)
@@ -2109,7 +2112,6 @@ int dev_queue_xmit(struct sk_buff *skb)
 	}
 
 gso:
-	trace_net_dev_xmit(skb);
 	/* Disable soft irqs for various locks below. Also
 	 * stops preemption for RCU.
 	 */
@@ -2216,6 +2218,8 @@ int netif_rx(struct sk_buff *skb)
 	if (!skb->tstamp.tv64)
 		net_timestamp(skb);
 
+	trace_net_dev_receive(skb);
+
 	/*
 	 * The code is rearranged so that the path is the most
 	 * short when CPU is congested, but is still operating.
@@ -2512,6 +2516,8 @@ int netif_receive_skb(struct sk_buff *skb)
 	if (netpoll_receive_skb(skb))
 		return NET_RX_DROP;
 
+	trace_net_dev_receive(skb);
+
 	if (!skb->skb_iif)
 		skb->skb_iif = skb->dev->ifindex;
 
@@ -2527,7 +2533,6 @@ int netif_receive_skb(struct sk_buff *skb)
 
 	__get_cpu_var(netdev_rx_stat).total++;
 
-	trace_net_dev_receive(skb);
 	skb_reset_network_header(skb);
 	skb_reset_transport_header(skb);
 	skb->mac_len = skb->network_header - skb->mac_header;
-- 
1.6.5.2

