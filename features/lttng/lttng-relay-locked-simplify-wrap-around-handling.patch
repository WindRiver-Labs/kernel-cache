From 93fadfcac7c9cbca58ca43d5474c26299eb1c74a Mon Sep 17 00:00:00 2001
From: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date: Thu, 13 May 2010 19:27:37 -0400
Subject: [PATCH 263/391] lttng-relay-locked-simplify-wrap-around-handling

LTTng relay locked - simplify wrap-around handling

Simply drop events if the writer meets a sub-buffer which was previously not
filled.

Situations that could cause this:

- kernel OOPS between reserve and commit.
- too many nested interrupts over a reserve/commit pair, causing a wrap around.

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
---
 ltt/ltt-relay-locked.c |   61 ++++++++++-------------------------------------
 1 files changed, 13 insertions(+), 48 deletions(-)

diff --git a/ltt/ltt-relay-locked.c b/ltt/ltt-relay-locked.c
index d8d752c..240ce60 100644
--- a/ltt/ltt-relay-locked.c
+++ b/ltt/ltt-relay-locked.c
@@ -66,7 +66,7 @@
 struct ltt_reserve_switch_offsets {
 	long begin, end, old;
 	long begin_switch, end_switch_current, end_switch_old;
-	long commit_count, reserve_commit_diff;
+	long commit_count;
 	size_t before_hdr_pad, size;
 };
 
@@ -1111,44 +1111,6 @@ static void ltt_reserve_push_reader(
 		ltt_buf->consumed = consumed_new;
 	} else
 		return;
-
-	if (unlikely(consumed_old != consumed_new)) {
-		/*
-		 * Reader pushed : we are the winner of the push, we can
-		 * therefore reequilibrate reserve and commit. Atomic increment
-		 * of the commit count permits other writers to play around
-		 * with this variable before us. We keep track of
-		 * corrupted_subbuffers even in overwrite mode :
-		 * we never want to write over a non completely committed
-		 * sub-buffer : possible causes : the buffer size is too low
-		 * compared to the unordered data input, or there is a writer
-		 * that died between the reserve and the commit.
-		 */
-		if (likely(offsets->reserve_commit_diff)) {
-			/*
-			 * We have to alter the sub-buffer commit count.
-			 * We do not deliver the previous subbuffer, given it
-			 * was either corrupted or not consumed (overwrite
-			 * mode).
-			 */
-			ltt_buf->commit_count[SUBBUF_INDEX(offsets->begin,
-							   buf->chan)] +=
-						offsets->reserve_commit_diff;
-			if (unlikely(!ltt_channel->overwrite
-			    || offsets->reserve_commit_diff
-			       != rchan->subbuf_size)) {
-				/*
-				 * The reserve commit diff was not subbuf_size :
-				 * it means the subbuffer was partly written to
-				 * and is therefore corrupted. If it is multiple
-				 * of subbuffer size and we are in flight
-				 * recorder mode, we are skipping over a whole
-				 * subbuffer.
-				 */
-				ltt_buf->corrupted_subbuffers++;
-			}
-		}
-	}
 }
 
 /*
@@ -1271,6 +1233,7 @@ static int ltt_relay_try_switch_slow(
 		u64 *tsc)
 {
 	long subbuf_index;
+	long reserve_commit_diff;
 
 	offsets->begin = ltt_buf->offset;
 	offsets->old = offsets->begin;
@@ -1293,12 +1256,12 @@ static int ltt_relay_try_switch_slow(
 	 * Test new buffer integrity
 	 */
 	subbuf_index = SUBBUF_INDEX(offsets->begin, buf->chan);
-	offsets->reserve_commit_diff =
+	reserve_commit_diff =
 		(BUFFER_TRUNC(offsets->begin, buf->chan)
 		 >> ltt_channel->n_subbufs_order)
 		- (ltt_buf->commit_count[subbuf_index]
 		   & ltt_channel->commit_count_mask);
-	if (offsets->reserve_commit_diff == 0) {
+	if (reserve_commit_diff == 0) {
 		/* Next buffer not corrupted. */
 		if (mode == FORCE_ACTIVE
 		    && !ltt_channel->overwrite
@@ -1336,7 +1299,6 @@ void ltt_force_switch_locked_slow(struct rchan_buf *buf,
 	unsigned long flags;
 	u64 tsc;
 
-	offsets.reserve_commit_diff = 0;
 	offsets.size = 0;
 
 	raw_local_irq_save(flags);
@@ -1393,6 +1355,8 @@ static int ltt_relay_try_reserve_slow(
 		struct ltt_reserve_switch_offsets *offsets, size_t data_size,
 		u64 *tsc, unsigned int *rflags, int largest_align)
 {
+	long reserve_commit_diff;
+
 	offsets->begin = ltt_buf->offset;
 	offsets->old = offsets->begin;
 	offsets->begin_switch = 0;
@@ -1430,12 +1394,12 @@ static int ltt_relay_try_reserve_slow(
 		offsets->begin = offsets->begin + ltt_subbuffer_header_size();
 		/* Test new buffer integrity */
 		subbuf_index = SUBBUF_INDEX(offsets->begin, buf->chan);
-		offsets->reserve_commit_diff =
+		reserve_commit_diff =
 			(BUFFER_TRUNC(offsets->begin, buf->chan)
 			 >> ltt_channel->n_subbufs_order)
 			- (ltt_buf->commit_count[subbuf_index]
 			   & ltt_channel->commit_count_mask);
-		if (likely(offsets->reserve_commit_diff == 0)) {
+		if (likely(reserve_commit_diff == 0)) {
 			/* Next buffer not corrupted. */
 			if (unlikely(!ltt_channel->overwrite &&
 				(SUBBUF_TRUNC(offsets->begin, buf->chan)
@@ -1456,10 +1420,12 @@ static int ltt_relay_try_reserve_slow(
 			}
 		} else {
 			/*
-			 * Next subbuffer corrupted. Force pushing reader even
-			 * in normal mode. It's safe to write in this new
-			 * subbuffer.
+			 * Next subbuffer corrupted. Drop event in normal and
+			 * overwrite mode. Caused by either a writer OOPS or
+			 * too many nested writes over a reserve/commit pair.
 			 */
+			local_inc(&ltt_buf->events_lost);
+			return -1;
 		}
 		offsets->size = ltt_get_header_size(ltt_channel,
 					offsets->begin, data_size,
@@ -1525,7 +1491,6 @@ int ltt_reserve_slot_locked_slow(struct ltt_trace_struct *trace,
 	struct ltt_channel_buf_struct *ltt_buf = buf->chan_private;
 	struct ltt_reserve_switch_offsets offsets;
 
-	offsets.reserve_commit_diff = 0;
 	offsets.size = 0;
 
 	if (unlikely(ltt_relay_try_reserve_slow(ltt_channel, ltt_buf,
-- 
1.6.5.2

