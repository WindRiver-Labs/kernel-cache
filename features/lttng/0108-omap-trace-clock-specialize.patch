From 2450e36672d52668389b1225f30ac1822b04d473 Mon Sep 17 00:00:00 2001
From: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date: Wed, 18 May 2011 18:42:04 -0400
Subject: [PATCH 108/248] omap-trace-clock-specialize

omap trace clock specialize

Let trace clock specialize for architectures which can only provide 31 bits
of timestamp counter. On OMAP3, we need to clear the cycle counter top bit
periodically to make sure the ccnt register does not overflow.

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
---
 arch/mips/include/asm/trace-clock.h |   12 ++++++++++++
 arch/sh/include/asm/trace-clock.h   |   12 ++++++++++++
 include/asm-generic/trace-clock.h   |   12 ++++++++++++
 kernel/trace/trace-clock-32-to-64.c |   20 ++++----------------
 4 files changed, 40 insertions(+), 16 deletions(-)

diff --git a/arch/mips/include/asm/trace-clock.h b/arch/mips/include/asm/trace-clock.h
index 93ea9da..b600518 100644
--- a/arch/mips/include/asm/trace-clock.h
+++ b/arch/mips/include/asm/trace-clock.h
@@ -12,6 +12,18 @@
 
 #define TRACE_CLOCK_MIN_PROBE_DURATION 200
 
+/*
+ * Number of hardware clock bits. The higher order bits are expected to be 0.
+ * If the hardware clock source has more than 32 bits, the bits higher than the
+ * 32nd will be truncated by a cast to a 32 bits unsigned. Range : 1 - 32.
+ * (too few bits would be unrealistic though, since we depend on the timer to
+ * detect the overflows).
+ */
+#define TC_HW_BITS			32
+
+/* Expected maximum interrupt latency in ms : 15ms, *2 for security */
+#define TC_EXPECTED_INTERRUPT_LATENCY	30
+
 extern u64 trace_clock_read_synthetic_tsc(void);
 
 /*
diff --git a/arch/sh/include/asm/trace-clock.h b/arch/sh/include/asm/trace-clock.h
index d892179..0fb1603 100644
--- a/arch/sh/include/asm/trace-clock.h
+++ b/arch/sh/include/asm/trace-clock.h
@@ -11,6 +11,18 @@
 #include <linux/timer.h>
 #include <asm/clock.h>
 
+/*
+ * Number of hardware clock bits. The higher order bits are expected to be 0.
+ * If the hardware clock source has more than 32 bits, the bits higher than the
+ * 32nd will be truncated by a cast to a 32 bits unsigned. Range : 1 - 32.
+ * (too few bits would be unrealistic though, since we depend on the timer to
+ * detect the overflows).
+ */
+#define TC_HW_BITS			32
+
+/* Expected maximum interrupt latency in ms : 15ms, *2 for security */
+#define TC_EXPECTED_INTERRUPT_LATENCY	30
+
 extern u64 trace_clock_read_synthetic_tsc(void);
 
 static inline u32 trace_clock_get_read32(void)
diff --git a/include/asm-generic/trace-clock.h b/include/asm-generic/trace-clock.h
index 7446e16..8111aba 100644
--- a/include/asm-generic/trace-clock.h
+++ b/include/asm-generic/trace-clock.h
@@ -14,6 +14,18 @@
 
 #define TRACE_CLOCK_SHIFT 13
 
+/*
+ * Number of hardware clock bits. The higher order bits are expected to be 0.
+ * If the hardware clock source has more than 32 bits, the bits higher than the
+ * 32nd will be truncated by a cast to a 32 bits unsigned. Range : 1 - 32.
+ * (too few bits would be unrealistic though, since we depend on the timer to
+ * detect the overflows).
+ */
+#define TC_HW_BITS			32
+
+/* Expected maximum interrupt latency in ms : 15ms, *2 for security */
+#define TC_EXPECTED_INTERRUPT_LATENCY	30
+
 extern atomic_long_t trace_clock;
 
 static inline u32 trace_clock_read32(void)
diff --git a/kernel/trace/trace-clock-32-to-64.c b/kernel/trace/trace-clock-32-to-64.c
index 11d961d..cac40e3 100644
--- a/kernel/trace/trace-clock-32-to-64.c
+++ b/kernel/trace/trace-clock-32-to-64.c
@@ -30,22 +30,10 @@
 #include <linux/sched.h> /* needed due to include order problem on m68k */
 #include <linux/math64.h>
 
-/*
- * Number of hardware clock bits. The higher order bits are expected to be 0.
- * If the hardware clock source has more than 32 bits, the bits higher than the
- * 32nd will be truncated by a cast to a 32 bits unsigned. Range : 1 - 32.
- * (too few bits would be unrealistic though, since we depend on the timer to
- * detect the overflows).
- */
-#define HW_BITS				32
-
-#define HW_BITMASK			((1ULL << HW_BITS) - 1)
+#define HW_BITMASK			((1ULL << TC_HW_BITS) - 1)
 #define HW_LS32(hw)			((hw) & HW_BITMASK)
 #define SW_MS32(sw)			((sw) & ~HW_BITMASK)
 
-/* Expected maximum interrupt latency in ms : 15ms, *2 for security */
-#define EXPECTED_INTERRUPT_LATENCY	30
-
 static DEFINE_MUTEX(synthetic_tsc_mutex);
 static int synthetic_tsc_refcount;  /* Number of readers */
 static int synthetic_tsc_enabled;   /* synth. TSC enabled on all online CPUs */
@@ -90,7 +78,7 @@ static void update_synthetic_tsc(void)
 		 */
 		cpu_synth->tsc[new_index].val =
 			(SW_MS32(cpu_synth->tsc[cpu_synth->index].val)
-				| (u64)tsc) + (1ULL << HW_BITS);
+				| (u64)tsc) + (1ULL << TC_HW_BITS);
 		cpu_synth->index = new_index;	/* atomic change of index */
 	} else {
 		/*
@@ -118,7 +106,7 @@ u64 notrace trace_clock_read_synthetic_tsc(void)
 	/* Overflow detection */
 	if (unlikely(tsc < HW_LS32(cpu_synth->tsc[index].sel.ls32)))
 		ret = (SW_MS32(cpu_synth->tsc[index].val) | (u64)tsc)
-			+ (1ULL << HW_BITS);
+			+ (1ULL << TC_HW_BITS);
 	else
 		ret = SW_MS32(cpu_synth->tsc[index].val) | (u64)tsc;
 	preempt_enable_notrace();
@@ -161,7 +149,7 @@ static int __init precalc_stsc_interval(void)
 		     * trace_clock_freq_scale())
 		    << 1)
 		 - 1
-		 - (EXPECTED_INTERRUPT_LATENCY * HZ / 1000), &rem_interval)
+		 - (TC_EXPECTED_INTERRUPT_LATENCY * HZ / 1000), &rem_interval)
 		>> 1;
 	WARN_ON(precalc_expire == 0);
 	printk(KERN_DEBUG "Synthetic TSC timer will fire each %u jiffies.\n",
-- 
1.7.0.4

