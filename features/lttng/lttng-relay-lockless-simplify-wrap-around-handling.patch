From eec428c5fed171c68fb910dd2357bbcc2ad4af25 Mon Sep 17 00:00:00 2001
From: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date: Thu, 13 May 2010 19:27:36 -0400
Subject: [PATCH 261/391] lttng-relay-lockless-simplify-wrap-around-handling

LTTng relay lockless - simplify wrap-around handling

Simply drop events if the writer meets a sub-buffer which was previously not
filled.

Situations that could cause this:

- kernel OOPS between reserve and commit.
- too many nested interrupts over a reserve/commit pair, causing a wrap around.

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
---
 ltt/ltt-relay-lockless.c |   61 +++++++++-------------------------------------
 1 files changed, 12 insertions(+), 49 deletions(-)

diff --git a/ltt/ltt-relay-lockless.c b/ltt/ltt-relay-lockless.c
index f015cd6..50a3488 100644
--- a/ltt/ltt-relay-lockless.c
+++ b/ltt/ltt-relay-lockless.c
@@ -67,7 +67,6 @@
 struct ltt_reserve_switch_offsets {
 	long begin, end, old;
 	long begin_switch, end_switch_current, end_switch_old;
-	long reserve_commit_diff;
 	size_t before_hdr_pad, size;
 };
 
@@ -1169,45 +1168,6 @@ static void ltt_reserve_push_reader(
 			return;
 	} while (unlikely(atomic_long_cmpxchg(&ltt_buf->consumed, consumed_old,
 			consumed_new) != consumed_old));
-
-	if (unlikely(consumed_old != consumed_new)) {
-		/*
-		 * Reader pushed : we are the winner of the push, we can
-		 * therefore reequilibrate reserve and commit. Atomic increment
-		 * of the commit count permits other writers to play around
-		 * with this variable before us. We keep track of
-		 * corrupted_subbuffers even in overwrite mode :
-		 * we never want to write over a non completely committed
-		 * sub-buffer : possible causes : the buffer size is too low
-		 * compared to the unordered data input, or there is a writer
-		 * that died between the reserve and the commit.
-		 */
-		if (likely(offsets->reserve_commit_diff)) {
-			/*
-			 * We have to alter the sub-buffer commit count.
-			 * We do not deliver the previous subbuffer, given it
-			 * was either corrupted or not consumed (overwrite
-			 * mode).
-			 */
-			local_add(offsets->reserve_commit_diff,
-				  &ltt_buf->commit_count[
-					SUBBUF_INDEX(offsets->begin,
-						     buf->chan)]);
-			if (unlikely(!ltt_channel->overwrite
-			    || offsets->reserve_commit_diff
-			       != rchan->subbuf_size)) {
-				/*
-				 * The reserve commit diff was not subbuf_size :
-				 * it means the subbuffer was partly written to
-				 * and is therefore corrupted. If it is multiple
-				 * of subbuffer size and we are in flight
-				 * recorder mode, we are skipping over a whole
-				 * subbuffer.
-				 */
-				local_inc(&ltt_buf->corrupted_subbuffers);
-			}
-		}
-	}
 }
 
 
@@ -1355,6 +1315,7 @@ static int ltt_relay_try_switch_slow(
 		u64 *tsc)
 {
 	long subbuf_index;
+	long reserve_commit_diff;
 
 	offsets->begin = local_read(&ltt_buf->offset);
 	offsets->old = offsets->begin;
@@ -1377,12 +1338,12 @@ static int ltt_relay_try_switch_slow(
 	 * Test new buffer integrity
 	 */
 	subbuf_index = SUBBUF_INDEX(offsets->begin, buf->chan);
-	offsets->reserve_commit_diff =
+	reserve_commit_diff =
 		(BUFFER_TRUNC(offsets->begin, buf->chan)
 		 >> ltt_channel->n_subbufs_order)
 		- (local_read(&ltt_buf->commit_count[subbuf_index])
 			& ltt_channel->commit_count_mask);
-	if (offsets->reserve_commit_diff == 0) {
+	if (reserve_commit_diff == 0) {
 		/* Next buffer not corrupted. */
 		if (mode == FORCE_ACTIVE
 		    && !ltt_channel->overwrite
@@ -1423,7 +1384,6 @@ void ltt_force_switch_lockless_slow(struct rchan_buf *buf,
 	struct ltt_reserve_switch_offsets offsets;
 	u64 tsc;
 
-	offsets.reserve_commit_diff = 0;
 	offsets.size = 0;
 
 	/*
@@ -1478,6 +1438,8 @@ static int ltt_relay_try_reserve_slow(struct ltt_channel_struct *ltt_channel,
 		struct ltt_reserve_switch_offsets *offsets, size_t data_size,
 		u64 *tsc, unsigned int *rflags, int largest_align)
 {
+	long reserve_commit_diff;
+
 	offsets->begin = local_read(&ltt_buf->offset);
 	offsets->old = offsets->begin;
 	offsets->begin_switch = 0;
@@ -1515,12 +1477,12 @@ static int ltt_relay_try_reserve_slow(struct ltt_channel_struct *ltt_channel,
 		offsets->begin = offsets->begin + ltt_subbuffer_header_size();
 		/* Test new buffer integrity */
 		subbuf_index = SUBBUF_INDEX(offsets->begin, buf->chan);
-		offsets->reserve_commit_diff =
+		reserve_commit_diff =
 			(BUFFER_TRUNC(offsets->begin, buf->chan)
 			 >> ltt_channel->n_subbufs_order)
 			- (local_read(&ltt_buf->commit_count[subbuf_index])
 				& ltt_channel->commit_count_mask);
-		if (likely(offsets->reserve_commit_diff == 0)) {
+		if (likely(reserve_commit_diff == 0)) {
 			/* Next buffer not corrupted. */
 			if (unlikely(!ltt_channel->overwrite &&
 				(SUBBUF_TRUNC(offsets->begin, buf->chan)
@@ -1543,10 +1505,12 @@ static int ltt_relay_try_reserve_slow(struct ltt_channel_struct *ltt_channel,
 			}
 		} else {
 			/*
-			 * Next subbuffer corrupted. Force pushing reader even
-			 * in normal mode. It's safe to write in this new
-			 * subbuffer.
+			 * Next subbuffer corrupted. Drop event in normal and
+			 * overwrite mode. Caused by either a writer OOPS or
+			 * too many nested writes over a reserve/commit pair.
 			 */
+			local_inc(&ltt_buf->events_lost);
+			return -1;
 		}
 		offsets->size = ltt_get_header_size(ltt_channel,
 					offsets->begin, data_size,
@@ -1610,7 +1574,6 @@ int ltt_reserve_slot_lockless_slow(struct ltt_trace_struct *trace,
 	struct ltt_channel_buf_struct *ltt_buf = buf->chan_private;
 	struct ltt_reserve_switch_offsets offsets;
 
-	offsets.reserve_commit_diff = 0;
 	offsets.size = 0;
 
 	do {
-- 
1.6.5.2

