From 6d2184369563211e7f2962a357335c9d36c2aa6c Mon Sep 17 00:00:00 2001
From: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
Date: Tue, 12 Aug 2008 10:32:53 -0400
Subject: [PATCH] lttng-instrumentation-x86_64

LTTng - x86_64 instrumentation

Changelog :
- Part of the instrumentation is now in i386, since the merge is on its way.

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
CC: Thomas Gleixner <tglx@linutronix.de>
CC: Ingo Molnar <mingo@redhat.com>
CC: H. Peter Anvin <hpa@zytor.com>
---
 arch/x86/ia32/ipc32.c                     |    2 ++
 arch/x86/kernel/apic_64.c                 |   15 +++++++++++++++
 arch/x86/kernel/cpu/common_64.c           |    1 +
 arch/x86/kernel/cpu/mcheck/mce_intel_64.c |    6 ++++++
 arch/x86/kernel/entry_64.S                |    6 +++---
 arch/x86/kernel/process_64.c              |   11 +++++++++++
 arch/x86/kernel/ptrace.c                  |    7 +++----
 arch/x86/kernel/tlb_64.c                  |    5 +++++
 arch/x86/kernel/traps_64.c                |   28 ++++++++++++++++++++++++----
 9 files changed, 70 insertions(+), 11 deletions(-)

diff --git a/arch/x86/ia32/ipc32.c b/arch/x86/ia32/ipc32.c
index d21991c..de2410c 100644
--- a/arch/x86/ia32/ipc32.c
+++ b/arch/x86/ia32/ipc32.c
@@ -17,6 +17,8 @@ asmlinkage long sys32_ipc(u32 call, int first, int second, int third,
 	version = call >> 16; /* hack for backward compatibility */
 	call &= 0xffff;
 
+	trace_mark(kernel_arch_ipc_call, "call %u first %d", call, first);
+
 	switch (call) {
 	case SEMOP:
 		/* struct sembuf is the same on 32 and 64bit :)) */
diff --git a/arch/x86/kernel/apic_64.c b/arch/x86/kernel/apic_64.c
index 7f1f030..4282faf 100644
--- a/arch/x86/kernel/apic_64.c
+++ b/arch/x86/kernel/apic_64.c
@@ -27,6 +27,7 @@
 #include <linux/clockchips.h>
 #include <linux/acpi_pmtmr.h>
 #include <linux/module.h>
+#include <trace/irq.h>
 
 #include <asm/atomic.h>
 #include <asm/smp.h>
@@ -490,7 +491,9 @@ void smp_apic_timer_interrupt(struct pt_regs *regs)
 	 */
 	exit_idle();
 	irq_enter();
+	trace_irq_entry(LOCAL_TIMER_VECTOR, regs);
 	local_apic_timer_interrupt();
+	trace_irq_exit(IRQ_HANDLED);
 	irq_exit();
 	set_irq_regs(old_regs);
 }
@@ -960,6 +963,9 @@ asmlinkage void smp_spurious_interrupt(void)
 	unsigned int v;
 	exit_idle();
 	irq_enter();
+
+	trace_irq_entry(SPURIOUS_APIC_VECTOR, NULL);
+
 	/*
 	 * Check if this really is a spurious interrupt and ACK it
 	 * if it is a vectored one.  Just in case...
@@ -970,6 +976,9 @@ asmlinkage void smp_spurious_interrupt(void)
 		ack_APIC_irq();
 
 	add_pda(irq_spurious_count, 1);
+
+	trace_irq_exit(IRQ_HANDLED);
+
 	irq_exit();
 }
 
@@ -982,6 +991,9 @@ asmlinkage void smp_error_interrupt(void)
 
 	exit_idle();
 	irq_enter();
+
+	trace_irq_entry(ERROR_APIC_VECTOR, NULL);
+
 	/* First tickle the hardware, only then report what went on. -- REW */
 	v = apic_read(APIC_ESR);
 	apic_write(APIC_ESR, 0);
@@ -1001,6 +1013,9 @@ asmlinkage void smp_error_interrupt(void)
 	*/
 	printk(KERN_DEBUG "APIC error on CPU%d: %02x(%02x)\n",
 		smp_processor_id(), v , v1);
+
+	trace_irq_exit(IRQ_HANDLED);
+
 	irq_exit();
 }
 
diff --git a/arch/x86/kernel/cpu/common_64.c b/arch/x86/kernel/cpu/common_64.c
index dd6e3f1..f9f85b7 100644
--- a/arch/x86/kernel/cpu/common_64.c
+++ b/arch/x86/kernel/cpu/common_64.c
@@ -548,6 +548,7 @@ unsigned long kernel_eflags;
  * debugging, no special alignment required.
  */
 DEFINE_PER_CPU(struct orig_ist, orig_ist);
+EXPORT_PER_CPU_SYMBOL_GPL(orig_ist);
 
 /*
  * cpu_init() initializes state that is per-CPU. Some data is already
diff --git a/arch/x86/kernel/cpu/mcheck/mce_intel_64.c b/arch/x86/kernel/cpu/mcheck/mce_intel_64.c
index c17eaf5..efd98aa 100644
--- a/arch/x86/kernel/cpu/mcheck/mce_intel_64.c
+++ b/arch/x86/kernel/cpu/mcheck/mce_intel_64.c
@@ -6,6 +6,7 @@
 #include <linux/init.h>
 #include <linux/interrupt.h>
 #include <linux/percpu.h>
+#include <trace/irq.h>
 #include <asm/processor.h>
 #include <asm/msr.h>
 #include <asm/mce.h>
@@ -22,11 +23,16 @@ asmlinkage void smp_thermal_interrupt(void)
 	exit_idle();
 	irq_enter();
 
+	trace_irq_entry(THERMAL_APIC_VECTOR, NULL);
+
 	rdmsrl(MSR_IA32_THERM_STATUS, msr_val);
 	if (therm_throt_process(msr_val & 1))
 		mce_log_therm_throt_event(smp_processor_id(), msr_val);
 
 	add_pda(irq_thermal_count, 1);
+
+	trace_irq_exit(IRQ_HANDLED);
+
 	irq_exit();
 }
 
diff --git a/arch/x86/kernel/entry_64.S b/arch/x86/kernel/entry_64.S
index 7a02c65..70a069a 100644
--- a/arch/x86/kernel/entry_64.S
+++ b/arch/x86/kernel/entry_64.S
@@ -282,7 +282,7 @@ ENTRY(ret_from_fork)
 	CFI_ADJUST_CFA_OFFSET -4
 	call schedule_tail
 	GET_THREAD_INFO(%rcx)
-	testl $(_TIF_SYSCALL_TRACE|_TIF_SYSCALL_AUDIT),TI_flags(%rcx)
+	testl $(_TIF_SYSCALL_TRACE|_TIF_KERNEL_TRACE|_TIF_SYSCALL_AUDIT),TI_flags(%rcx)
 	jnz rff_trace
 rff_action:	
 	RESTORE_REST
@@ -396,7 +396,7 @@ sysret_check:
 	/* Handle reschedules */
 	/* edx:	work, edi: workmask */	
 sysret_careful:
-	testl $(_TIF_SYSCALL_TRACE|_TIF_SYSCALL_AUDIT|_TIF_SECCOMP),%edx
+	testl $(_TIF_SYSCALL_TRACE|_TIF_SYSCALL_AUDIT|_TIF_KERNEL_TRACE|_TIF_SECCOMP),%edx
 	jnz ret_from_sys_call_trace
 	bt $TIF_NEED_RESCHED,%edx
 	jnc sysret_signal
@@ -1182,7 +1182,7 @@ bad_gs:
  * asm input arguments:
  *	rdi: fn, rsi: arg, rdx: flags
  */
-ENTRY(kernel_thread)
+ENTRY(kernel_thread_asm)
 	CFI_STARTPROC
 	FAKE_STACK_FRAME $child_rip
 	SAVE_ALL
diff --git a/arch/x86/kernel/process_64.c b/arch/x86/kernel/process_64.c
index 3fb62a7..fa0e14e 100644
--- a/arch/x86/kernel/process_64.c
+++ b/arch/x86/kernel/process_64.c
@@ -54,6 +54,9 @@
 
 asmlinkage extern void ret_from_fork(void);
 
+asmlinkage long kernel_thread_asm(int (*fn)(void *), void * arg,
+	 unsigned long flags);
+
 unsigned long kernel_thread_flags = CLONE_VM | CLONE_UNTRACED;
 
 static ATOMIC_NOTIFIER_HEAD(idle_notifier);
@@ -856,3 +859,11 @@ unsigned long arch_randomize_brk(struct mm_struct *mm)
 	unsigned long range_end = mm->brk + 0x02000000;
 	return randomize_range(mm->brk, range_end, 0) ? : mm->brk;
 }
+
+asmlinkage int kernel_thread(int (*fn)(void *), void * arg,
+	 unsigned long flags)
+{
+	int pid = kernel_thread_asm(fn, arg, flags);
+	trace_mark(kernel_arch_kthread_create, "pid %d fn %p", pid, fn);
+	return pid;
+}
diff --git a/arch/x86/kernel/ptrace.c b/arch/x86/kernel/ptrace.c
index 2176178..db78203 100644
--- a/arch/x86/kernel/ptrace.c
+++ b/arch/x86/kernel/ptrace.c
@@ -1426,11 +1426,8 @@ asmregparm long syscall_trace_enter(struct pt_regs *regs)
 	if (test_thread_flag(TIF_SINGLESTEP))
 		regs->flags |= X86_EFLAGS_TF;
 
-	if (!entryexit)
-		trace_mark(kernel_arch_syscall_entry, "syscall_id %d ip #p%ld",
+	trace_mark(kernel_arch_syscall_entry, "syscall_id %d ip #p%ld",
 			(int)regs->orig_ax, instruction_pointer(regs));
-	else
-		trace_mark(kernel_arch_syscall_exit, "ret %ld", regs->ax);
 
 	/* do the secure computing check first */
 	secure_computing(regs->orig_ax);
@@ -1461,6 +1458,8 @@ asmregparm long syscall_trace_enter(struct pt_regs *regs)
 
 asmregparm void syscall_trace_leave(struct pt_regs *regs)
 {
+	trace_mark(kernel_arch_syscall_exit, "ret %ld", regs->ax);
+
 	if (unlikely(current->audit_context))
 		audit_syscall_exit(AUDITSC_RESULT(regs->ax), regs->ax);
 
diff --git a/arch/x86/kernel/tlb_64.c b/arch/x86/kernel/tlb_64.c
index dcbf7a1..91ed739 100644
--- a/arch/x86/kernel/tlb_64.c
+++ b/arch/x86/kernel/tlb_64.c
@@ -7,6 +7,7 @@
 #include <linux/kernel_stat.h>
 #include <linux/mc146818rtc.h>
 #include <linux/interrupt.h>
+#include <trace/irq.h>
 
 #include <asm/mtrr.h>
 #include <asm/pgalloc.h>
@@ -19,6 +20,7 @@
 #include <asm/uv/uv_bau.h>
 
 #include <mach_ipi.h>
+
 /*
  *	Smarter SMP flushing macros.
  *		c/o Linus Torvalds.
@@ -142,6 +144,8 @@ asmlinkage void smp_invalidate_interrupt(struct pt_regs *regs)
 		 * BUG();
 		 */
 
+	trace_irq_entry(sender, regs);
+
 	if (f->flush_mm == read_pda(active_mm)) {
 		if (read_pda(mmu_state) == TLBSTATE_OK) {
 			if (f->flush_va == TLB_FLUSH_ALL)
@@ -155,6 +159,7 @@ out:
 	ack_APIC_irq();
 	cpu_clear(cpu, f->flush_cpumask);
 	add_pda(irq_tlb_count, 1);
+	trace_irq_exit(IRQ_HANDLED);
 }
 
 void native_flush_tlb_others(const cpumask_t *cpumaskp, struct mm_struct *mm,
diff --git a/arch/x86/kernel/traps_64.c b/arch/x86/kernel/traps_64.c
index 87be174..5ae7012 100644
--- a/arch/x86/kernel/traps_64.c
+++ b/arch/x86/kernel/traps_64.c
@@ -601,6 +601,9 @@ do_trap(int trapnr, int signr, char *str, struct pt_regs *regs,
 {
 	struct task_struct *tsk = current;
 
+	trace_mark(kernel_arch_trap_entry, "trap_id %d ip #p%ld", trapnr,
+		instruction_pointer(regs));
+
 	if (!user_mode(regs))
 		goto kernel_trap;
 
@@ -630,6 +633,7 @@ do_trap(int trapnr, int signr, char *str, struct pt_regs *regs,
 		force_sig_info(signr, info, tsk);
 	else
 		force_sig(signr, tsk);
+	trace_mark(kernel_arch_trap_exit, MARK_NOARGS);
 	return;
 
 kernel_trap:
@@ -638,6 +642,7 @@ kernel_trap:
 		tsk->thread.trap_no = trapnr;
 		die(str, regs, error_code);
 	}
+	trace_mark(kernel_arch_trap_exit, MARK_NOARGS);
 	return;
 }
 
@@ -728,7 +733,10 @@ do_general_protection(struct pt_regs *regs, long error_code)
 		printk("\n");
 	}
 
+	trace_mark(kernel_arch_trap_entry, "trap_id %d ip #p%ld", 13,
+		instruction_pointer(regs));
 	force_sig(SIGSEGV, tsk);
+	trace_mark(kernel_arch_trap_exit, MARK_NOARGS);
 	return;
 
 gp_in_kernel:
@@ -803,6 +811,9 @@ asmlinkage notrace __kprobes void default_do_nmi(struct pt_regs *regs)
 	unsigned char reason = 0;
 	int cpu;
 
+	trace_mark(kernel_arch_trap_entry, "trap_id %d ip #p%ld",
+		2, instruction_pointer(regs));
+
 	cpu = smp_processor_id();
 
 	/* Only the BSP gets external NMIs from the system. */
@@ -812,26 +823,28 @@ asmlinkage notrace __kprobes void default_do_nmi(struct pt_regs *regs)
 	if (!(reason & 0xc0)) {
 		if (notify_die(DIE_NMI_IPI, "nmi_ipi", regs, reason, 2, SIGINT)
 								== NOTIFY_STOP)
-			return;
+			goto end;
 		/*
 		 * Ok, so this is none of the documented NMI sources,
 		 * so it must be the NMI watchdog.
 		 */
 		if (nmi_watchdog_tick(regs, reason))
-			return;
+			goto end;
 		if (!do_nmi_callback(regs, cpu))
 			unknown_nmi_error(reason, regs);
 
-		return;
+		goto end;
 	}
 	if (notify_die(DIE_NMI, "nmi", regs, reason, 2, SIGINT) == NOTIFY_STOP)
-		return;
+		goto end;
 
 	/* AK: following checks seem to be broken on modern chipsets. FIXME */
 	if (reason & 0x80)
 		mem_parity_error(reason, regs);
 	if (reason & 0x40)
 		io_check_error(reason, regs);
+end:
+	trace_mark(kernel_arch_trap_exit, MARK_NOARGS);
 }
 
 asmlinkage notrace __kprobes void
@@ -942,7 +955,10 @@ asmlinkage void __kprobes do_debug(struct pt_regs * regs,
 	info.si_errno = 0;
 	info.si_code = TRAP_BRKPT;
 	info.si_addr = user_mode(regs) ? (void __user *)regs->ip : NULL;
+	trace_mark(kernel_arch_trap_entry, "trap_id %d ip #p%ld",
+		1, instruction_pointer(regs));
 	force_sig_info(SIGTRAP, &info, tsk);
+	trace_mark(kernel_arch_trap_exit, MARK_NOARGS);
 
 clear_dr7:
 	set_debugreg(0, 7);
@@ -1098,6 +1114,10 @@ asmlinkage void do_simd_coprocessor_error(struct pt_regs *regs)
 
 asmlinkage void do_spurious_interrupt_bug(struct pt_regs * regs)
 {
+	trace_mark(kernel_arch_trap_entry, "trap_id %d ip #p%ld",
+		16, instruction_pointer(regs));
+
+	trace_mark(kernel_arch_trap_exit, MARK_NOARGS);
 }
 
 asmlinkage void __attribute__((weak)) smp_thermal_interrupt(void)
-- 
1.5.5.1

