From eb64caef3ea68e3abc3d97bc71dcfe86752a4632 Mon Sep 17 00:00:00 2001
From: Jiping Ma <jiping.ma2@windriver.com>
Date: Tue, 15 May 2018 03:25:49 +0000
Subject: [PATCH] BUG: sleeping function called from invalid context

in_atomic(): 1, irqs_disabled(): 128, pid: 0, name: swapper/1
Preemption disabled at:[<ffffff800808f5cc>] secondary_start_kernel+0xec/0x1c8

CPU: 1 PID: 0 Comm: swapper/1 Not tainted 4.8.28-rt10-WR9.0.0.15_preempt-rt #6
Hardware name: Broadcom NS2 SVK (DT)
Call trace:
[<ffffff8008089608>] dump_backtrace+0x0/0x1d0
[<ffffff80080897fc>] show_stack+0x24/0x30
[<ffffff8008456094>] dump_stack+0x90/0xb4
[<ffffff80080c9224>] ___might_sleep+0x15c/0x170
[<ffffff800882103c>] rt_spin_lock+0x2c/0x88
[<ffffff80086bec28>] arm_perf_starting_cpu+0x30/0xb0
[<ffffff800809e07c>] cpuhp_invoke_callback+0x6c/0x200
[<ffffff80080a031c>] notify_cpu_starting+0x74/0x90
[<ffffff800808f5f4>] secondary_start_kernel+0x114/0x1c8
[<0000000080083158>] 0x80083158
CPU1: Booted secondary processor [411fd073]

static int arm_perf_starting_cpu(unsigned int cpu)
{
        struct arm_pmu *pmu;

        spin_lock(&arm_pmu_lock); ---> in RT linux, #define spin_lock(lock)
							rt_spin_lock(lock);
        list_for_each_entry(pmu, &arm_pmu_list, entry) {

                if (!cpumask_test_cpu(cpu, &pmu->supported_cpus))
                        continue;
                if (pmu->reset)
                        pmu->reset(pmu);
        }
        spin_unlock(&arm_pmu_lock);
        return 0;
}

The BUG reported in rt_spin_lock function because rt_mutex can
cause sleep but the context is atomic. The version of rt that
we are using (and in fact, pretty much any version of -rt) recommends
against using cpu hotplug, so there's really no way we can ever
make it "stable".

We use raw_spin_lock replace of spin_lock for this issue, but we
cannot guarantee consistent cpu hotplug under all workloads.

Signed-off-by: Jiping Ma <jiping.ma2@windriver.com>
---
 drivers/perf/arm_pmu.c |   18 +++++++++---------
 1 files changed, 9 insertions(+), 9 deletions(-)

diff --git a/drivers/perf/arm_pmu.c b/drivers/perf/arm_pmu.c
index f5e1008..12d9bbf 100644
--- a/drivers/perf/arm_pmu.c
+++ b/drivers/perf/arm_pmu.c
@@ -688,7 +688,7 @@ static int cpu_pmu_request_irq(struct arm_pmu *cpu_pmu, irq_handler_t handler)
 	return 0;
 }
 
-static DEFINE_SPINLOCK(arm_pmu_lock);
+static DEFINE_RAW_SPINLOCK(arm_pmu_lock);
 static LIST_HEAD(arm_pmu_list);
 
 /*
@@ -701,7 +701,7 @@ static int arm_perf_starting_cpu(unsigned int cpu)
 {
 	struct arm_pmu *pmu;
 
-	spin_lock(&arm_pmu_lock);
+	raw_spin_lock(&arm_pmu_lock);
 	list_for_each_entry(pmu, &arm_pmu_list, entry) {
 
 		if (!cpumask_test_cpu(cpu, &pmu->supported_cpus))
@@ -709,7 +709,7 @@ static int arm_perf_starting_cpu(unsigned int cpu)
 		if (pmu->reset)
 			pmu->reset(pmu);
 	}
-	spin_unlock(&arm_pmu_lock);
+	raw_spin_unlock(&arm_pmu_lock);
 	return 0;
 }
 
@@ -821,9 +821,9 @@ static int cpu_pmu_init(struct arm_pmu *cpu_pmu)
 	if (!cpu_hw_events)
 		return -ENOMEM;
 
-	spin_lock(&arm_pmu_lock);
+	raw_spin_lock(&arm_pmu_lock);
 	list_add_tail(&cpu_pmu->entry, &arm_pmu_list);
-	spin_unlock(&arm_pmu_lock);
+	raw_spin_unlock(&arm_pmu_lock);
 
 	err = cpu_pm_pmu_register(cpu_pmu);
 	if (err)
@@ -859,9 +859,9 @@ static int cpu_pmu_init(struct arm_pmu *cpu_pmu)
 	return 0;
 
 out_unregister:
-	spin_lock(&arm_pmu_lock);
+	raw_spin_lock(&arm_pmu_lock);
 	list_del(&cpu_pmu->entry);
-	spin_unlock(&arm_pmu_lock);
+	raw_spin_unlock(&arm_pmu_lock);
 	free_percpu(cpu_hw_events);
 	return err;
 }
@@ -869,9 +869,9 @@ out_unregister:
 static void cpu_pmu_destroy(struct arm_pmu *cpu_pmu)
 {
 	cpu_pm_pmu_unregister(cpu_pmu);
-	spin_lock(&arm_pmu_lock);
+	raw_spin_lock(&arm_pmu_lock);
 	list_del(&cpu_pmu->entry);
-	spin_unlock(&arm_pmu_lock);
+	raw_spin_unlock(&arm_pmu_lock);
 	free_percpu(cpu_pmu->hw_events);
 }
 
-- 
1.7.5.4

