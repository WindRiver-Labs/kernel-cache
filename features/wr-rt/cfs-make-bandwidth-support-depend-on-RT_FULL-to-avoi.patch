From 069a5729baaaa93de44d0df3ac7c240da7ae2796 Mon Sep 17 00:00:00 2001
From: Paul Gortmaker <paul.gortmaker@windriver.com>
Date: Sun, 29 Mar 2015 20:15:40 -0400
Subject: [PATCH] cfs: make bandwidth support depend on !RT_FULL to avoid
 lockups

We've seen several traces where __account_cfs_rq_runtime() is implicated,
but this one (detected by RCU stall) is the easiest to follow, as it is
all confined to one CPU.

What happens is that ksoftirqd is happily running, and takes the
cfs_b->lock (raw lock, but non irqsave) to do the CFS beancounting.
It is still holding the lock when we take a timer interrupt.

As part of processing that interrupt, we call kvm's apic_timer_fn, which
in our case is registered as irqsafe, meaning it will try and run directly
vs running from the softirq.  From the trace, we can see the path through
ttwu and friends to account_cfs_rq_runtime() where we eventually try to
get the same cfs_b->lock (still held) and then it is game over...

NMI backtrace for cpu 1
CPU: 1 PID: 20 Comm: ksoftirqd/1 Not tainted 3.14.36-rt32-WR7.0.0.0_ovp #1
Hardware name: Dell Inc. Precision T5610/0WN7Y6, BIOS A05 01/18/2014
task: ffff88082a113260 ti: ffff88082a11c000 task.ti: ffff88082a11c000
RIP: 0010:[<ffffffff81abcfd7>]  [<ffffffff81abcfd7>] _raw_spin_lock+0x47/0x60
RSP: 0018:ffff88084fc23ca8  EFLAGS: 00000002
RAX: 0000000000005eda RBX: ffff8808265c30f0 RCX: 0000000000000d38
RDX: 0000000000000d37 RSI: 0000000000000000 RDI: 0000000000000001
RBP: ffff88084fc23cb0 R08: 0000000000000000 R09: 0000000000000001
R10: 0000000000000004 R11: 0000000000000000 R12: ffff8808265c3000
R13: 00000000004c4b40 R14: ffff8808265c30f0 R15: 00000000000e3d69
FS:  0000000000000000(0000) GS:ffff88084fc20000(0000) knlGS:0000000000000000
CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
CR2: 00007fbac7c22000 CR3: 0000000002211000 CR4: 00000000001427e0
Stack:
 ffff8808225ddc00 ffff88084fc23ce0 ffffffff8108bc61 ffff880822af4c00
 ffff8808225ddc00 ffff880822af4b90 0000000000000001 ffff88084fc23d28
 ffffffff8108df65 ffff88084fc23d10 ffff88084fc23dc8 ffff880822af4c00
Call Trace:
 <IRQ>
 [<ffffffff8108bc61>] __account_cfs_rq_runtime+0xa1/0x180
 [<ffffffff8108df65>] enqueue_entity+0x455/0xaf0
 [<ffffffff8108e679>] enqueue_task_fair+0x79/0x5c0
 [<ffffffff810884e6>] ? sched_clock_cpu+0x66/0xf0
 [<ffffffff8107fc5a>] enqueue_task+0x3a/0x60
 [<ffffffff810819b3>] activate_task+0x23/0x30
 [<ffffffff81081c73>] ttwu_do_activate.constprop.96+0x33/0x50
 [<ffffffff81084a5b>] try_to_wake_up+0x25b/0x440
 [<ffffffff81103b72>] ? probe_sched_wakeup+0x22/0x80
 [<ffffffff81084cd0>] wake_up_state+0x10/0x20
 [<ffffffff810965be>] __swait_wake_locked+0x4e/0xb0
 [<ffffffff8109665f>] __swait_wake+0x3f/0x60
 [<ffffffffa0b0043d>] apic_timer_fn+0x3d/0x70 [kvm]
 [<ffffffff8107627b>] __run_hrtimer+0x9b/0x2a0
 [<ffffffffa0b00400>] ? apic_set_eoi+0x1c0/0x1c0 [kvm]
 [<ffffffff810775ae>] hrtimer_interrupt+0x12e/0x2e0
 [<ffffffff81035477>] local_apic_timer_interrupt+0x37/0x60
 [<ffffffff81ac01df>] smp_apic_timer_interrupt+0x3f/0x50
 [<ffffffff81abec6a>] apic_timer_interrupt+0x6a/0x70
 <EOI>
 [<ffffffff810881fc>] ? sched_clock_local+0xc/0x90
 [<ffffffff81088528>] sched_clock_cpu+0xa8/0xf0
 [<ffffffff8108a6c9>] __refill_cfs_bandwidth_runtime.part.58+0x19/0x30
 [<ffffffff8108f0e7>] sched_cfs_period_timer+0xc7/0x1a0
 [<ffffffff8108f020>] ? sched_cfs_slack_timer+0x120/0x120
 [<ffffffff81076985>] run_hrtimer_softirq+0xb5/0x1e0
 [<ffffffff81052fe2>] do_current_softirqs+0x202/0x3a0
 [<ffffffff810533c7>] run_ksoftirqd+0x27/0x50
 [<ffffffff8107af3d>] smpboot_thread_fn+0x18d/0x2d0
 [<ffffffff81abab60>] ? schedule+0x30/0xa0
 [<ffffffff8107adb0>] ? SyS_setgroups+0x170/0x170
 [<ffffffff8107332d>] kthread+0xcd/0xf0
 [<ffffffff81073260>] ? flush_kthread_worker+0x90/0x90
 [<ffffffff81abdcf8>] ret_from_fork+0x58/0x90
 [<ffffffff81073260>] ? flush_kthread_worker+0x90/0x90

Looking at the code, we can see why this failure is intermittent.  First,
you need to have an interrupt come in with the lock held, and secondly
you need to have the bandwidth support enabled and _finally_ you need to
detect a zero runtime remaining condition in order to get to the call to
assign_cfs_rq_runtime() which trys to take the lock (marked FAIL).

  static void __account_cfs_rq_runtime(struct cfs_rq *cfs_rq, u64 delta_exec)
  {
          /* dock delta_exec before expiring quota (as it could span periods) */
          cfs_rq->runtime_remaining -= delta_exec;
          expire_cfs_rq_runtime(cfs_rq);

          if (likely(cfs_rq->runtime_remaining > 0))
                  return;

          /*
           * if we're unable to extend our runtime we resched so that the active
           * hierarchy can be throttled
           */
FAIL -->  if (!assign_cfs_rq_runtime(cfs_rq) && likely(cfs_rq->curr))  <-- FAIL
                  resched_task_lazy(rq_of(cfs_rq)->curr);
  }

  static __always_inline
  void account_cfs_rq_runtime(struct cfs_rq *cfs_rq, u64 delta_exec)
  {
          if (!cfs_bandwidth_used() || !cfs_rq->runtime_enabled)
                  return;

          __account_cfs_rq_runtime(cfs_rq, delta_exec);
  }

A couple instances of the locking in sched/core of cfs_b->lock are of the
raw_spinlock_irq() variants, indicating there was originally thoughts of
this being run from hardirq, but all of the ones in sched/fair are just
the plain raw_lock/raw_unlock variety and so there is no protection
from the above happening if we run ttwu from an interrupt.

Fortunately all the cfs_b->lock operations are within CFS_BANDWIDTH and
we can avoid this by disabling it for RT_FULL.  This isn't all that
unreasonable, since -rt itself already disabled the related option
right below in "sched-Disable-CONFIG_RT_GROUP_SCHED-on-RT.patch" and
we've also found the RT_RUNTIME_SHARE sched feature breaks the -rt
throttling detection.

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/init/Kconfig b/init/Kconfig
index 64fecafc14bb..90076d400839 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1024,6 +1024,7 @@ config FAIR_GROUP_SCHED
 config CFS_BANDWIDTH
 	bool "CPU bandwidth provisioning for FAIR_GROUP_SCHED"
 	depends on FAIR_GROUP_SCHED
+	depends on !PREEMPT_RT_FULL
 	default n
 	help
 	  This option allows users to define CPU bandwidth rates (limits) for
-- 
2.3.3

