From ae900258a93af220cf863f03710be1e9a7781563 Mon Sep 17 00:00:00 2001
From: Zhong Hongbo <hongbo.zhong@windriver.com>
Date: Thu, 12 Jan 2017 18:44:41 +0800
Subject: [PATCH 1/2] kmemleak: Using the raw spin lock to replace the
 read/write lock

The call chain is the below:

preempt_disable()
cpu_stopper_thread
 --->multi_cpu_stop
  --->take_cpu_down
   --->cpu_notify
    ---> __cpu_notify
     ---> raw_notifier_call_chain
      --->x86_pmu_notifier
       ---> intel_pmu_cpu_dying
        --->kfree
         --->kmemleak_free
          --->delete_object_full
           --->find_and_get_object
            --->read_lock_irqsave   <------sleep lock

In the normal, the kfree function is atomic. But when open the
CONFIG_DEBUG_KMEMLEAK, the kfree will call kmemleak_free function,
In CONFIG_PREEMPT_RT_FULL open, the kmemleak_free will use the
read_lock_irqsave. It is a sleep lock.

Using raw_spin_lock_irqsave/irqrestore to replace read_lock_irqsave/irqrestore.
The issue will be fixed.

The call treace as the following:
BUG: sleeping function called from invalid context at
kernel/locking/rtmutex.c:905
in_atomic(): 1, irqs_disabled(): 1, pid: 17, name: migration/1
Preemption disabled at:[<ffffffff8107a23d>]
smpboot_thread_fn+0x18d/0x2d0

CPU: 1 PID: 17 Comm: migration/1 Not tainted
3.14.22-rt9-WR7.0.0.0_preempt-rt #7
Hardware name: Intel Corporation S2600WTT/S2600WTT, BIOS
GRNDSDP1.86B.0030.R03.1405061547 05/06/2014
 ffff8803dda1f080 ffff8803de133bf0 ffffffff819ed7b5 0000000000000000
 ffff8803de133c08 ffffffff8107ee93 ffffffff81e07f80 ffff8803de133c20
 ffffffff819f4250 ffffffff81e07f80 ffff8803de133c38 ffffffff819f4520
Call Trace:
 [<ffffffff819ed7b5>] dump_stack+0x4e/0x7a
 [<ffffffff8107ee93>] __might_sleep+0xe3/0x160
 [<ffffffff819f4250>] __rt_spin_lock+0x20/0x50
 [<ffffffff819f4520>] rt_read_lock+0x30/0x40
 [<ffffffff819f453e>] rt_read_lock_irqsave+0xe/0x20
 [<ffffffff811849c7>] find_and_get_object+0x27/0x140
 [<ffffffff811851c1>] delete_object_full+0x11/0x30
 [<ffffffff819e9636>] kmemleak_free+0x26/0x50
 [<ffffffff81175a78>] kfree+0x118/0x200
 [<ffffffff8101eb5d>] ? intel_pmu_cpu_dying+0x6d/0x70
 [<ffffffff8101eb5d>] intel_pmu_cpu_dying+0x6d/0x70
 [<ffffffff81017b22>] x86_pmu_notifier+0x92/0x100
 [<ffffffff810776ed>] notifier_call_chain+0x4d/0x70
 [<ffffffff810777be>] __raw_notifier_call_chain+0xe/0x10
 [<ffffffff8104d493>] cpu_notify+0x23/0x50
 [<ffffffff819e8147>] take_cpu_down+0x27/0x40
 [<ffffffff810db889>] multi_cpu_stop+0xb9/0xe0
 [<ffffffff810db7d0>] ? wait_for_stop_done+0xb0/0xb0
 [<ffffffff810dbcc2>] cpu_stopper_thread+0xc2/0x160
 [<ffffffff819f1e36>] ? preempt_schedule+0x36/0x50
 [<ffffffff8100d306>] ? ___preempt_schedule+0x56/0xb0
 [<ffffffff81081e1d>] ? get_parent_ip+0xd/0x50
 [<ffffffff819f3edd>] ? _raw_spin_lock_irqsave+0x1d/0x70
 [<ffffffff8107a23d>] smpboot_thread_fn+0x18d/0x2d0
 [<ffffffff819f1a50>] ? schedule+0x30/0xa0
 [<ffffffff8107a0b0>] ? SyS_setgroups+0x180/0x180
 [<ffffffff810726ed>] kthread+0xcd/0xf0
 [<ffffffff81072620>] ? flush_kthread_worker+0x90/0x90
 [<ffffffff819f536c>] ret_from_fork+0x7c/0xb0
 [<ffffffff81072620>] ? flush_kthread_worker+0x90/0x90

Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
Signed-off-by: Liwei Song <liwei.song@windriver.com>
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 mm/kmemleak.c |   18 +++++++++---------
 1 files changed, 9 insertions(+), 9 deletions(-)

diff --git a/mm/kmemleak.c b/mm/kmemleak.c
index 086292f..46bbce4 100644
--- a/mm/kmemleak.c
+++ b/mm/kmemleak.c
@@ -193,7 +193,7 @@ static LIST_HEAD(gray_list);
 /* search tree for object boundaries */
 static struct rb_root object_tree_root = RB_ROOT;
 /* rw_lock protecting the access to object_list and object_tree_root */
-static DEFINE_RWLOCK(kmemleak_lock);
+static DEFINE_RAW_SPINLOCK(kmemleak_lock);
 
 /* allocation caches for kmemleak internal data */
 static struct kmem_cache *object_cache;
@@ -483,9 +483,9 @@ static struct kmemleak_object *find_and_get_object(unsigned long ptr, int alias)
 	struct kmemleak_object *object;
 
 	rcu_read_lock();
-	read_lock_irqsave(&kmemleak_lock, flags);
+	raw_spin_lock_irqsave(&kmemleak_lock, flags);
 	object = lookup_object(ptr, alias);
-	read_unlock_irqrestore(&kmemleak_lock, flags);
+	raw_spin_unlock_irqrestore(&kmemleak_lock, flags);
 
 	/* check whether the object is still available */
 	if (object && !get_object(object))
@@ -505,13 +505,13 @@ static struct kmemleak_object *find_and_remove_object(unsigned long ptr, int ali
 	unsigned long flags;
 	struct kmemleak_object *object;
 
-	write_lock_irqsave(&kmemleak_lock, flags);
+	raw_spin_lock_irqsave(&kmemleak_lock, flags);
 	object = lookup_object(ptr, alias);
 	if (object) {
 		rb_erase(&object->rb_node, &object_tree_root);
 		list_del_rcu(&object->object_list);
 	}
-	write_unlock_irqrestore(&kmemleak_lock, flags);
+	raw_spin_unlock_irqrestore(&kmemleak_lock, flags);
 
 	return object;
 }
@@ -584,7 +584,7 @@ static struct kmemleak_object *create_object(unsigned long ptr, size_t size,
 	/* kernel backtrace */
 	object->trace_len = __save_stack_trace(object->trace);
 
-	write_lock_irqsave(&kmemleak_lock, flags);
+	raw_spin_lock_irqsave(&kmemleak_lock, flags);
 
 	min_addr = min(min_addr, ptr);
 	max_addr = max(max_addr, ptr + size);
@@ -615,7 +615,7 @@ static struct kmemleak_object *create_object(unsigned long ptr, size_t size,
 
 	list_add_tail_rcu(&object->object_list, &object_list);
 out:
-	write_unlock_irqrestore(&kmemleak_lock, flags);
+	raw_spin_unlock_irqrestore(&kmemleak_lock, flags);
 	return object;
 }
 
@@ -1171,7 +1171,7 @@ static void scan_block(void *_start, void *_end,
 	unsigned long *end = _end - (BYTES_PER_POINTER - 1);
 	unsigned long flags;
 
-	read_lock_irqsave(&kmemleak_lock, flags);
+	raw_spin_lock_irqsave(&kmemleak_lock, flags);
 	for (ptr = start; ptr < end; ptr++) {
 		struct kmemleak_object *object;
 		unsigned long pointer;
@@ -1230,7 +1230,7 @@ static void scan_block(void *_start, void *_end,
 		}
 		spin_unlock(&object->lock);
 	}
-	read_unlock_irqrestore(&kmemleak_lock, flags);
+	raw_spin_unlock_irqrestore(&kmemleak_lock, flags);
 }
 
 /*
-- 
1.7.5.4

