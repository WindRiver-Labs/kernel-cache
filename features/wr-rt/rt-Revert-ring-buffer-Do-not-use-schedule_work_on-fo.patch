From f57e1ad5b24ed507967932b60feeca2e4a3e3daf Mon Sep 17 00:00:00 2001
From: Kevin Hao <kexin.hao@windriver.com>
Date: Tue, 29 Oct 2013 19:35:29 +0800
Subject: [PATCH 2/2] rt: Revert "ring-buffer: Do not use schedule_work_on()
 for current CPU"

The commit f5eb5588262c(ring-buffer: Do not use schedule_work_on() for
current CPU) introduces the following call trace for the rt kernel:

  BUG: sleeping function called from invalid context at kernel/rtmutex.c:659
  in_atomic(): 1, irqs_disabled(): 0, pid: 616, name: ftrace_buffer_s
  Preemption disabled at:[<  (null)>]   (null)

  CPU: 0 PID: 616 Comm: ftrace_buffer_s Not tainted 3.10.15-rt11+ #22
  Call Trace:
  [c751bd80] [c0008d1c] show_stack+0xfc/0x1c0 (unreliable)
  [c751bdd0] [c06ffdd4] rt_spin_lock+0x34/0x90
  [c751bde0] [c0115134] free_hot_cold_page+0xb4/0x2e0
  [c751be20] [c00ea760] free_buffer_page+0x20/0x40
  [c751be30] [c00ed680] rb_update_pages+0x230/0x310
  [c751be60] [c00edba8] ring_buffer_resize+0x408/0x5a0
  [c751bea0] [c00f0f18] __tracing_resize_ring_buffer+0x38/0xe0
  [c751bec0] [c00f1198] tracing_entries_write+0xb8/0x140
  [c751bef0] [c01644d4] vfs_write+0xd4/0x1e0
  [c751bf10] [c0164b98] SyS_write+0x58/0xc0
  [c751bf40] [c0011190] ret_from_syscall+0x0/0x3c
  --- Exception: c00 at 0xff225f4
      LR = 0xfec6554

The original commit tried to resolve two issues:
  a) Inefficient invoke of schedule_work_on()
  b) The function ring_buffer_resize() may be invoked by
     tracing_snapshot_alloc() before work queues is initialized

For issue (a) we have to still use the schedule_work_on() even we are
resizing the ring buffer for the current cpu in order to fix the
above call trace.

For issue (b) the ftrace is only functional after the tracer buffer
is allocated. Both the function tracer_alloc_buffers() and
init_workqueues() are initialized as early_initcall, but the
workqueue.o is listed before the trace/trace.o in the kernel/Makefile.
This can make sure that ring_buffer_resize() is never invoked before
the work queue init. So we should never run into a situation like this.

So it is safe to revert this commit.

Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 kernel/trace/ring_buffer.c | 33 ++++++---------------------------
 1 file changed, 6 insertions(+), 27 deletions(-)

diff --git a/kernel/trace/ring_buffer.c b/kernel/trace/ring_buffer.c
index e444ff8..229526b 100644
--- a/kernel/trace/ring_buffer.c
+++ b/kernel/trace/ring_buffer.c
@@ -1686,22 +1686,11 @@ int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size,
 			if (!cpu_buffer->nr_pages_to_update)
 				continue;
 
-			/* The update must run on the CPU that is being updated. */
-			preempt_disable();
-			if (cpu == smp_processor_id() || !cpu_online(cpu)) {
-				rb_update_pages(cpu_buffer);
-				cpu_buffer->nr_pages_to_update = 0;
-			} else {
-				/*
-				 * Can not disable preemption for schedule_work_on()
-				 * on PREEMPT_RT.
-				 */
-				preempt_enable();
+			if (cpu_online(cpu))
 				schedule_work_on(cpu,
 						&cpu_buffer->update_pages_work);
-				preempt_disable();
-			}
-			preempt_enable();
+			else
+				rb_update_pages(cpu_buffer);
 		}
 
 		/* wait for all the updates to complete */
@@ -1739,22 +1728,12 @@ int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size,
 
 		get_online_cpus();
 
-		preempt_disable();
-		/* The update must run on the CPU that is being updated. */
-		if (cpu_id == smp_processor_id() || !cpu_online(cpu_id))
-			rb_update_pages(cpu_buffer);
-		else {
-			/*
-			 * Can not disable preemption for schedule_work_on()
-			 * on PREEMPT_RT.
-			 */
-			preempt_enable();
+		if (cpu_online(cpu_id)) {
 			schedule_work_on(cpu_id,
 					 &cpu_buffer->update_pages_work);
 			wait_for_completion(&cpu_buffer->update_done);
-			preempt_disable();
-		}
-		preempt_enable();
+		} else
+			rb_update_pages(cpu_buffer);
 
 		cpu_buffer->nr_pages_to_update = 0;
 		put_online_cpus();
-- 
1.8.4.93.g57e4c17

