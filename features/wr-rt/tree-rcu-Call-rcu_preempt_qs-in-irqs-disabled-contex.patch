From b5cfbb25470430674cdf2b4ad41f6adb1ce0c3f5 Mon Sep 17 00:00:00 2001
From: Bin Jiang <bin.jiang@windriver.com>
Date: Fri, 6 Dec 2013 13:31:38 +0800
Subject: [PATCH] tree rcu: Call rcu_preempt_qs() in irqs disabled context for
 RT kernel

High networking traffic may make a machine freeze hard without any message
or diagnostics. This was observed on PPC RT_FULL kenrel while running
tests over the loopback device.

When transmit a TCP packet, following will run:
ip_queue_xmit()
    |
    + rcu_read_lock()
    + ip_local_out()
    |    |
    |    + local_bh_enable()
    |         |
    |         + local_irq_enable()
    |         + handle_softirq()
    |         |    |
    |         |    + rcu_bh_qs()
    |         |         |
    |         |         + rcu_preempt_qs()
    |         |              |
    |         |              + current->rcu_read_unlock_special &=
    |         |                               ~RCU_READ_UNLOCK_NEED_QS (*1)
    |         |
    |         + local_irq_disable()
    |         + migrate_enable()
    |              |
    |              + preempt_schedule()
    |                   |
    |                   + rcu_preempt_note_context_switch() (*2)
    |
    + rcu_read_unlock()
         |
         + rcu_read_unlock_special()
              |
              + list_del_init(&t->rcu_node_entry) (*3)

When an interrupt occurs, following will run:
preempt_schedule_irq()
    |
    + rcu_preempt_note_context_switch()
          |
          + if (t->rcu_read_unlock_special & RCU_READ_UNLOCK_BLOCKED) == 0) {
                t->rcu_read_unlock_special |= RCU_READ_UNLOCK_BLOCKED; (*4)
                list_add(&t->rcu_node_entry, &rnp->blkd_tasks); (*5)

When running at (*1), an interrupt occurs and then the operations at (*4)
and (*5) will run. Since the operation at (*1) runs in non-atomic context,
the value of rcu_read_unlock_special set at (*4) may be replaced by the
value set at (*1).

When running at (*2), since the value of rcu_read_unlock_special is
replaced, the operations at (*4) and (*5) will run again. It is clear that
the same task is list_added twice. This results in the blkd_tasks list
being in wrong state.

When running at (*3), the task is removed from blkd_tasks list and links to
itself. But blkd_tasks still links to the task since the blkd_tasks list
is in wrong state.

Now rcu runs into such a state: the rcu-completed task is still thought as
a rcu-blocked task. This makes system run into cpu stall state and call
followings in check_cpu_stall():

    list_for_each_entry_continue(t, &rnp->blkd_tasks, rcu_node_entry) {
        printk(KERN_CONT " P%d", t->pid);
        ndetected++;
    }

Since the task linked by blkd_tasks is rcu-completed and links to itself,
the above for loop runs into endless loop.

Clearly, rcu_preempt_qs must run in irq disabled context. Since RT_FULL has
its own version of rcu_bh_qs(), we can ensure rcu_preempt_qs() called with
irqs disabled by just wrapping that one call site. This will not impact the
other caller hrtimer_interrupt() of rcu_bh_qs() because it calls
rcu_bh_qs() in hardirq context and local_irq_save/restore() can save the
interrupt state.

Signed-off-by: Bin Jiang <bin.jiang@windriver.com>
---
 kernel/rcutree.c |    4 ++++
 1 files changed, 4 insertions(+), 0 deletions(-)

diff --git a/kernel/rcutree.c b/kernel/rcutree.c
index 55915b1..a3b4f27 100644
--- a/kernel/rcutree.c
+++ b/kernel/rcutree.c
@@ -187,7 +187,11 @@ static void rcu_preempt_qs(int cpu);
 
 void rcu_bh_qs(int cpu)
 {
+	unsigned long flags;
+
+	local_irq_save(flags);
 	rcu_preempt_qs(cpu);
+	local_irq_restore(flags);
 }
 #else
 void rcu_bh_qs(int cpu)
-- 
1.7.5.4

