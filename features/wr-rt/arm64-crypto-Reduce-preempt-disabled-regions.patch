From 04b8028661bb1a4da99c3450b2e9b162a15a9850 Mon Sep 17 00:00:00 2001
From: Limeng <Meng.Li@windriver.com>
Date: Mon, 30 Oct 2017 12:40:49 +0800
Subject: [PATCH] arm64: crypto: Reduce preempt disabled regions

Restrict the preempt disabled regions to the actual floating point
operations and enable preemption for the administrative actions.

This is necessary on RT to avoid that kfree and other operations are
called with preemption disabled.

Do this modification base on patch ("x86: crypto: Reduce preempt
disabled regions")

Signed-off-by: Meng Li <Meng.Li@windriver.com>
---
 arch/arm64/crypto/aes-glue.c |   27 ++++++++++++++++-----------
 1 files changed, 16 insertions(+), 11 deletions(-)

diff --git a/arch/arm64/crypto/aes-glue.c b/arch/arm64/crypto/aes-glue.c
index 6b2aa0f..e0a1ac7 100644
--- a/arch/arm64/crypto/aes-glue.c
+++ b/arch/arm64/crypto/aes-glue.c
@@ -113,13 +113,14 @@ static int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,
 	blkcipher_walk_init(&walk, dst, src, nbytes);
 	err = blkcipher_walk_virt(desc, &walk);
 
-	kernel_neon_begin();
 	for (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {
+		kernel_neon_begin();
 		aes_ecb_encrypt(walk.dst.virt.addr, walk.src.virt.addr,
 				(u8 *)ctx->key_enc, rounds, blocks, first);
+		kernel_neon_end();
 		err = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);
 	}
-	kernel_neon_end();
+
 	return err;
 }
 
@@ -135,13 +136,14 @@ static int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,
 	blkcipher_walk_init(&walk, dst, src, nbytes);
 	err = blkcipher_walk_virt(desc, &walk);
 
-	kernel_neon_begin();
 	for (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {
+		kernel_neon_begin();
 		aes_ecb_decrypt(walk.dst.virt.addr, walk.src.virt.addr,
 				(u8 *)ctx->key_dec, rounds, blocks, first);
+		kernel_neon_end();
 		err = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);
 	}
-	kernel_neon_end();
+
 	return err;
 }
 
@@ -157,14 +159,15 @@ static int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,
 	blkcipher_walk_init(&walk, dst, src, nbytes);
 	err = blkcipher_walk_virt(desc, &walk);
 
-	kernel_neon_begin();
 	for (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {
+		kernel_neon_begin();
 		aes_cbc_encrypt(walk.dst.virt.addr, walk.src.virt.addr,
 				(u8 *)ctx->key_enc, rounds, blocks, walk.iv,
 				first);
+		kernel_neon_end();
 		err = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);
 	}
-	kernel_neon_end();
+
 	return err;
 }
 
@@ -180,14 +183,15 @@ static int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,
 	blkcipher_walk_init(&walk, dst, src, nbytes);
 	err = blkcipher_walk_virt(desc, &walk);
 
-	kernel_neon_begin();
 	for (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {
+		kernel_neon_begin();
 		aes_cbc_decrypt(walk.dst.virt.addr, walk.src.virt.addr,
 				(u8 *)ctx->key_dec, rounds, blocks, walk.iv,
 				first);
+		kernel_neon_end();
 		err = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);
 	}
-	kernel_neon_end();
+
 	return err;
 }
 
@@ -204,11 +208,12 @@ static int ctr_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,
 	err = blkcipher_walk_virt_block(desc, &walk, AES_BLOCK_SIZE);
 
 	first = 1;
-	kernel_neon_begin();
 	while ((blocks = (walk.nbytes / AES_BLOCK_SIZE))) {
+		kernel_neon_begin();
 		aes_ctr_encrypt(walk.dst.virt.addr, walk.src.virt.addr,
 				(u8 *)ctx->key_enc, rounds, blocks, walk.iv,
 				first);
+		kernel_neon_end();
 		first = 0;
 		nbytes -= blocks * AES_BLOCK_SIZE;
 		if (nbytes && nbytes == walk.nbytes % AES_BLOCK_SIZE)
@@ -226,13 +231,13 @@ static int ctr_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,
 		 * to tell aes_ctr_encrypt() to only read half a block.
 		 */
 		blocks = (nbytes <= 8) ? -1 : 1;
-
+		kernel_neon_begin();
 		aes_ctr_encrypt(tail, tsrc, (u8 *)ctx->key_enc, rounds,
 				blocks, walk.iv, first);
+		kernel_neon_end();
 		memcpy(tdst, tail, nbytes);
 		err = blkcipher_walk_done(desc, &walk, 0);
 	}
-	kernel_neon_end();
 
 	return err;
 }
-- 
1.7.5.4

