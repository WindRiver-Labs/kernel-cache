From 50dd3e21450661370d17b457efea1c871c1008c7 Mon Sep 17 00:00:00 2001
From: David Mercado <david.mercado@windriver.com>
Date: Tue, 19 Nov 2013 15:02:29 -0500
Subject: [PATCH 134/159] LSI AXM55XX: Port of mach-axxia to 3.10 kernel

git.yoctoproject.org/git/linux-yocto-3.10
commit 271be13be133fe2e22fad7a240207ef28aa48762 standard/axxia/base.

Port mach-axxia BSP from 3.4.x to 3.10.x kernel.

Signed-off-by: David Mercado <david.mercado@windriver.com>
---
 arch/arm/mach-axxia/Kconfig                  |    2 +-
 arch/arm/mach-axxia/Makefile                 |    2 +-
 arch/arm/mach-axxia/axxia-gic.c              |  352 ++++++++++++++++----------
 arch/arm/mach-axxia/axxia.c                  |  121 +++++++--
 arch/arm/mach-axxia/axxia.h                  |    3 +
 arch/arm/mach-axxia/clock.c                  |   30 +--
 arch/arm/mach-axxia/ddr_retention.c          |   33 +--
 arch/arm/mach-axxia/headsmp.S                |    2 +-
 arch/arm/mach-axxia/i2c.c                    |   34 +--
 arch/arm/mach-axxia/include/mach/axxia-gic.h |    1 +
 arch/arm/mach-axxia/include/mach/irqs.h      |    5 +-
 arch/arm/mach-axxia/pci.c                    |   24 +--
 arch/arm/mach-axxia/platsmp.c                |   86 ++++---
 arch/arm/mach-axxia/timers.c                 |    7 +-
 arch/arm/mach-axxia/wrappers.c               |    4 +-
 15 files changed, 421 insertions(+), 285 deletions(-)

diff --git a/arch/arm/mach-axxia/Kconfig b/arch/arm/mach-axxia/Kconfig
index 206c344..92b1dd1 100644
--- a/arch/arm/mach-axxia/Kconfig
+++ b/arch/arm/mach-axxia/Kconfig
@@ -29,6 +29,6 @@ config ARCH_AXXIA_DT
 	  say Y here.
 
 config ARCH_AXXIA_SIM
-       bool "Build for Simulation instead of Emulation or ASIC"
+	bool "Build for Simulation instead of Emulation or ASIC"
 
 endmenu
diff --git a/arch/arm/mach-axxia/Makefile b/arch/arm/mach-axxia/Makefile
index 0459a1f..e49adf1 100644
--- a/arch/arm/mach-axxia/Makefile
+++ b/arch/arm/mach-axxia/Makefile
@@ -1,7 +1,7 @@
 #
 # Makefile for the linux kernel.
 #
-obj-y                                   += wrappers.o
+obj-y					+= wrappers.o
 obj-y					+= axxia.o
 obj-y					+= clock.o
 obj-y                                   += io.o
diff --git a/arch/arm/mach-axxia/axxia-gic.c b/arch/arm/mach-axxia/axxia-gic.c
index f899188..291e90a 100644
--- a/arch/arm/mach-axxia/axxia-gic.c
+++ b/arch/arm/mach-axxia/axxia-gic.c
@@ -54,11 +54,13 @@
 #include <asm/exception.h>
 #include <asm/smp_plat.h>
 #include <asm/mach/irq.h>
-#include <asm/hardware/gic.h>
+#include <linux/irqchip/arm-gic.h>
 
 #include <mach/axxia-gic.h>
 
-static u32 irq_cpuid[1020];
+#define MAX_GIC_INTERRUPTS  1020
+
+static u32 irq_cpuid[MAX_GIC_INTERRUPTS];
 static void __iomem *ipi_mask_reg_base;
 static void __iomem *ipi_send_reg_base;
 
@@ -82,8 +84,72 @@ enum axxia_ext_ipi_num {
 	IPI3_CPU3,
 	MAX_AXM_IPI_NUM
 };
-static u32 mplx_ipi_num_45;
-static u32 mplx_ipi_num_61;
+
+#define AXXIA_RPC 0xff /* Some big arbritary number */
+
+/* We pack these into an integer, so four is the max! */
+enum axxia_mux_msg_type {
+	MUX_MSG_CALL_FUNC = 0,
+	MUX_MSG_CALL_FUNC_SINGLE,
+	MUX_MSG_CPU_STOP,
+	MUX_MSG_CPU_WAKEUP
+};
+
+struct axxia_mux_msg {
+	u32 msg;
+};
+
+static DEFINE_PER_CPU_SHARED_ALIGNED(struct axxia_mux_msg, ipi_mux_msg);
+
+static void muxed_ipi_message_pass(const struct cpumask *mask,
+				   enum axxia_mux_msg_type ipi_num)
+{
+	struct axxia_mux_msg *info;
+	char *message;
+	int cpu;
+
+	/*
+	 * Order previous accesses before accesses in the IPI handler.
+	 */
+	dmb();
+
+	for_each_cpu(cpu, mask) {
+		info = &per_cpu(ipi_mux_msg, cpu_logical_map(cpu));
+		message = (char *)&info->msg;
+		message[ipi_num] = 1;
+	}
+}
+
+static void axxia_ipi_demux(struct pt_regs *regs)
+{
+	struct axxia_mux_msg *info = &__get_cpu_var(ipi_mux_msg);
+	u32 all;
+
+	mb();
+
+	do {
+		all = xchg(&info->msg, 0);
+#ifdef __LITTLE_ENDIAN
+		if (all & (1 << (8 * MUX_MSG_CALL_FUNC)))
+			handle_IPI(3, regs); /* 3 = ARM IPI_CALL_FUNC */
+		if (all & (1 << (8 * MUX_MSG_CALL_FUNC_SINGLE)))
+			handle_IPI(4, regs); /* 4 = ARM IPI_CALL_FUNC_SINGLE */
+		if (all & (1 << (8 * MUX_MSG_CPU_STOP)))
+			handle_IPI(5, regs); /* 5 = ARM IPI_CPU_STOP */
+		if (all & (1 << (8 * MUX_MSG_CPU_WAKEUP)))
+			handle_IPI(0, regs); /* 0 = ARM IPI_WAKEUP */
+#else
+		if (all & (1 << (24 - 8 * MUX_MSG_CALL_FUNC)))
+			handle_IPI(3, regs); /* 3 = ARM IPI_CALL_FUNC */
+		if (all & (1 << (24 - 8 * MUX_MSG_CALL_FUNC_SINGLE)))
+			handle_IPI(4, regs); /* 4 = ARM IPI_CALL_FUNC_SINGLE */
+		if (all & (1 << (24 - 8 * MUX_MSG_CPU_STOP)))
+			handle_IPI(5, regs); /* 5 = ARM IPI_CPU_STOP */
+		if (all & (1 << (24 - 8 * MUX_MSG_CPU_WAKEUP)))
+			handle_IPI(0, regs); /* 0 = ARM IPI_WAKEUP */
+#endif
+	} while (info->msg);
+}
 
 union gic_base {
 	void __iomem *common_base;
@@ -94,9 +160,9 @@ struct gic_chip_data {
 	union gic_base dist_base;
 	union gic_base cpu_base;
 #ifdef CONFIG_CPU_PM
-	u32 saved_spi_enable[DIV_ROUND_UP(1020, 32)];
-	u32 saved_spi_conf[DIV_ROUND_UP(1020, 16)];
-	u32 saved_spi_target[DIV_ROUND_UP(1020, 4)];
+	u32 saved_spi_enable[DIV_ROUND_UP(MAX_GIC_INTERRUPTS, 32)];
+	u32 saved_spi_conf[DIV_ROUND_UP(MAX_GIC_INTERRUPTS, 16)];
+	u32 saved_spi_target[DIV_ROUND_UP(MAX_GIC_INTERRUPTS, 4)];
 	u32 __percpu *saved_ppi_enable;
 	u32 __percpu *saved_ppi_conf;
 #endif
@@ -129,6 +195,65 @@ static inline unsigned int gic_irq(struct irq_data *d)
 	return d->hwirq;
 }
 
+typedef void axxia_call_func_t(void *info);
+
+struct axxia_gic_rpc {
+	int cpu;
+	axxia_call_func_t *func;
+	void *info;
+};
+
+static DEFINE_PER_CPU_SHARED_ALIGNED(struct axxia_gic_rpc, axxia_gic_rpc);
+
+void axxia_gic_handle_gic_rpc(void)
+{
+	u32 this_cpu = cpu_logical_map(smp_processor_id());
+	int cpu;
+
+	for_each_possible_cpu(cpu)
+	{
+		struct axxia_gic_rpc *slot = &per_cpu(axxia_gic_rpc, cpu);
+		if (slot->func && slot->cpu == this_cpu) {
+			slot->func(slot->info);
+			slot->func = NULL;
+			dmb();
+		}
+	}
+}
+
+static void axxia_gic_handle_gic_rpc_ipi(void)
+{
+	irq_enter();
+	axxia_gic_handle_gic_rpc();
+	irq_exit();
+}
+
+static void axxia_gic_run_gic_rpc(int cpu, axxia_call_func_t *func, void *info)
+{
+	struct axxia_gic_rpc *slot = &__get_cpu_var(axxia_gic_rpc);
+	int timeout;
+
+	slot->cpu = cpu;
+	slot->info = info;
+	dsb();
+	slot->func = func;
+
+	/* Make visible before sending the IPI. */
+	dmb();
+
+	/* Send the IPI. */
+	axxia_gic_raise_softirq(cpumask_of(cpu), AXXIA_RPC);
+
+	timeout = 1000000;
+	while (slot->func && --timeout > 0) {
+		axxia_gic_handle_gic_rpc(); /* Execute other CPU requests */
+		cpu_relax();
+	}
+
+	/* We should never hit this! */
+	BUG_ON(timeout == 0);
+}
+
 /*
  * Routines to acknowledge, disable and enable interrupts.
  */
@@ -152,7 +277,9 @@ static void gic_mask_irq(struct irq_data *d)
 	u32 pcpu = cpu_logical_map(smp_processor_id());
 	u32 irqid = gic_irq(d);
 
-	if (irqid >= 1020)
+	BUG_ON(!irqs_disabled());
+
+	if (irqid >= MAX_GIC_INTERRUPTS)
 		return;
 
 	/* Don't mess with the AXM IPIs. */
@@ -171,21 +298,10 @@ static void gic_mask_irq(struct irq_data *d)
 	 * the IRQ masking directly. Otherwise, use the IPI mechanism
 	 * to remotely do the masking.
 	 */
-	if ((cpu_logical_map(irq_cpuid[irqid]) / 4) == (pcpu / 4)) {
+	if ((irq_cpuid[irqid] / 4) == (pcpu / 4))
 		_gic_mask_irq(d);
-	} else {
-		/*
-		 * We are running here with local interrupts
-		 * disabled. Temporarily re-enable them to
-		 * avoid possible deadlock when calling
-		 * smp_call_function_single().
-		 */
-		local_irq_enable();
-		smp_call_function_single(irq_cpuid[irqid],
-					 _gic_mask_irq,
-					 d, 1);
-		local_irq_disable();
-	}
+	else
+		axxia_gic_run_gic_rpc(irq_cpuid[irqid], _gic_mask_irq, d);
 }
 
 static void _gic_unmask_irq(void *arg)
@@ -204,7 +320,9 @@ static void gic_unmask_irq(struct irq_data *d)
 	u32 pcpu = cpu_logical_map(smp_processor_id());
 	u32 irqid = gic_irq(d);
 
-	if (irqid >= 1020)
+	BUG_ON(!irqs_disabled());
+
+	if (irqid >= MAX_GIC_INTERRUPTS)
 		return;
 
 	/* Don't mess with the AXM IPIs. */
@@ -223,21 +341,10 @@ static void gic_unmask_irq(struct irq_data *d)
 	 * the IRQ masking directly. Otherwise, use the IPI mechanism
 	 * to remotely do the masking.
 	 */
-	if ((cpu_logical_map(irq_cpuid[irqid]) / 4) == (pcpu / 4)) {
+	if ((irq_cpuid[irqid] / 4) == (pcpu / 4))
 		_gic_unmask_irq(d);
-	} else {
-		/*
-		 * We are running here with local interrupts
-		 * disabled. Temporarily re-enable them to
-		 * avoid possible deadlock when calling
-		 * smp_call_function_single().
-		 */
-		local_irq_enable();
-		smp_call_function_single(irq_cpuid[irqid],
-					 _gic_unmask_irq,
-					 d, 1);
-		local_irq_disable();
-	}
+	else
+		axxia_gic_run_gic_rpc(irq_cpuid[irqid], _gic_unmask_irq, d);
 }
 
 static void gic_eoi_irq(struct irq_data *d)
@@ -304,16 +411,19 @@ static void gic_set_type_wrapper(void *data)
 		(struct gic_set_type_wrapper_struct *)data;
 
 	pArgs->status = _gic_set_type(pArgs->d, pArgs->type);
+	dmb();
 }
 #endif
 
 static int gic_set_type(struct irq_data *d, unsigned int type)
 {
-#ifdef CONFIG_SMP
 	int i, cpu, nr_cluster_ids = ((nr_cpu_ids-1) / 4) + 1;
 	unsigned int gicirq = gic_irq(d);
 	u32 pcpu = cpu_logical_map(smp_processor_id());
 	struct gic_set_type_wrapper_struct data;
+	int ret;
+
+	BUG_ON(!irqs_disabled());
 
 	/* Interrupt configuration for SGIs can't be changed. */
 	if (gicirq < 16)
@@ -331,32 +441,23 @@ static int gic_set_type(struct irq_data *d, unsigned int type)
 	 * Duplicate IRQ type settings across all clusters. Run
 	 * directly for this cluster, use IPI for all others.
 	 */
+	ret = _gic_set_type(d, type);
 	data.d = d;
 	data.type = type;
 	for (i = 0; i < nr_cluster_ids; i++) {
-		if (i == (pcpu/4))
+		if (i == (pcpu / 4))
 			continue;
 
 		/* Have the first cpu in each cluster execute this. */
 		cpu = i * 4;
 		if (cpu_online(cpu)) {
-			/*
-			 * We are running here with local interrupts
-			 * disabled. Temporarily re-enable them to
-			 * avoid possible deadlock when calling
-			 * smp_call_function_single().
-			 */
-			local_irq_enable();
-			smp_call_function_single(cpu, gic_set_type_wrapper,
-						 &data, 1);
-			local_irq_disable();
+			axxia_gic_run_gic_rpc(cpu, gic_set_type_wrapper, &data);
 			if (data.status != 0)
 				pr_err("Failed to set IRQ type for cpu%d\n",
 				       cpu);
 		}
 	}
-#endif
-	return _gic_set_type(d, type);
+	return ret;
 }
 
 static int gic_retrigger(struct irq_data *d)
@@ -417,10 +518,12 @@ static int gic_set_affinity(struct irq_data *d,
 	unsigned int irqid = gic_irq(d);
 	struct gic_set_affinity_wrapper_struct data;
 
+	BUG_ON(!irqs_disabled());
+
 	if (cpu >= nr_cpu_ids)
 		return -EINVAL;
 
-	if (irqid >= 1020)
+	if (irqid >= MAX_GIC_INTERRUPTS)
 		return -EINVAL;
 
 	/* Interrupt affinity for the AXM IPIs can't be changed. */
@@ -431,7 +534,7 @@ static int gic_set_affinity(struct irq_data *d,
 	 * If the new IRQ affinity is the same as current, then
 	 * there's no need to update anything.
 	 */
-	if (cpu == irq_cpuid[irqid])
+	if (cpu_logical_map(cpu) == irq_cpuid[irqid])
 		return IRQ_SET_MASK_OK;
 
 	/*
@@ -443,41 +546,33 @@ static int gic_set_affinity(struct irq_data *d,
 	data.mask_val = mask_val;
 	data.disable = false;
 
-	if ((cpu_logical_map(cpu) / 4) == (pcpu / 4)) {
+	if ((cpu_logical_map(cpu) / 4) == (pcpu / 4))
 		_gic_set_affinity(&data);
-	} else {
-		/* Temporarily re-enable local interrupts. */
-		local_irq_enable();
-		smp_call_function_single(cpu, _gic_set_affinity, &data, 1);
-		local_irq_disable();
-	}
+	else
+		axxia_gic_run_gic_rpc(cpu, _gic_set_affinity, &data);
 
 	/*
 	 * If the new physical cpu assignment is on a cluster that's
 	 * different than the prior cluster, remove the IRQ affinity
 	 * on the old cluster.
 	 */
-	if ((cpu_logical_map(cpu) / 4) !=
-		(cpu_logical_map(irq_cpuid[irqid]) / 4)) {
+	if ((cpu_logical_map(cpu) / 4) != (irq_cpuid[irqid] / 4)) {
 		/*
 		 * If old cpu assignment falls within the same cluster as
 		 * the cpu we're currently running on, set the IRQ affinity
 		 * directly. Otherwise, use IPI mechanism.
 		 */
 		data.disable = true;
-		if ((cpu_logical_map(irq_cpuid[irqid]) / 4) == (pcpu / 4)) {
+		if ((irq_cpuid[irqid] / 4) == (pcpu / 4))
 			_gic_set_affinity(&data);
-		} else {
-			/* Temporarily re-enable local interrupts. */
-			local_irq_enable();
-			smp_call_function_single(irq_cpuid[irqid],
-						 _gic_set_affinity, &data, 1);
-			local_irq_disable();
-		}
+		else
+			axxia_gic_run_gic_rpc(irq_cpuid[irqid],
+					      _gic_set_affinity,
+					      &data);
 	}
 
-	/* Update Axxia IRQ affinity table with the new logical CPU number. */
-	irq_cpuid[irqid] = cpu;
+	/* Update Axxia IRQ affinity table with the new physical CPU number. */
+	irq_cpuid[irqid] = cpu_logical_map(cpu);
 
 	return IRQ_SET_MASK_OK;
 }
@@ -498,7 +593,6 @@ static int gic_set_wake(struct irq_data *d, unsigned int on)
 asmlinkage void __exception_irq_entry axxia_gic_handle_irq(struct pt_regs *regs)
 {
 	u32 irqstat, irqnr;
-	u32 ipinum = 0;
 	struct gic_chip_data *gic = &gic_data;
 	void __iomem *cpu_base = gic_data_cpu_base(gic);
 
@@ -506,23 +600,23 @@ asmlinkage void __exception_irq_entry axxia_gic_handle_irq(struct pt_regs *regs)
 		irqstat = readl_relaxed(cpu_base + GIC_CPU_INTACK);
 		irqnr = irqstat & ~0x1c00;
 
-		if (likely(irqnr > 15 && irqnr < 1021)) {
+		if (likely(irqnr > 15 && irqnr <= MAX_GIC_INTERRUPTS)) {
 			irqnr = irq_find_mapping(gic->domain, irqnr);
 
 			/*
 			 * Check if this is an external Axxia IPI interrupt.
 			 * Translate to a standard ARM internal IPI number.
 			 * The Axxia only has 4 IPI interrupts, so we
-			 * multiplex IPI_CALL_FUNC and IPI_CALL_FUNC_SINGLE
-			 * as one IPI. We also multiplex IPI_CPU_STOP and
-			 * IPI_WAKEUP as one IPI.
+			 * multiplex various ARM IPIs into a single line
+			 * as outlined below:
 			 *
-			 * IPI0_CPUx = IPI_TIMER (2)
-			 * IPI1_CPUx = IPI_RESCHEDULE (3)
-			 * IPI2_CPUx = IPI_CALL_FUNC (4) /
-			 *             IPI_CALL_FUNC_SINGLE (5)
-			 * IPI3_CPUx = IPI_CPU_STOP (6) /
-			 *             IPI_WAKEUP (1)
+			 * IPI0_CPUx = IPI_TIMER (1)
+			 * IPI1_CPUx = IPI_RESCHEDULE (2)
+			 * IPI2_CPUx = IPI_CALL_FUNC (3) |
+			 *             IPI_CALL_FUNC_SINGLE (4) |
+			 *             IPI_CPU_STOP (5) |
+			 *             IPI_WAKEUP (0)
+			 * IPI3_CPUx = AXXIA_RPC (0xff)
 			 *
 			 * Note that if the ipi_msg_type enum changes in
 			 * arch/arm/kernel/smp.c then this will have to be
@@ -533,51 +627,38 @@ asmlinkage void __exception_irq_entry axxia_gic_handle_irq(struct pt_regs *regs)
 			case IPI0_CPU1:
 			case IPI0_CPU2:
 			case IPI0_CPU3:
-				ipinum = 2;
+				writel_relaxed(irqnr, cpu_base + GIC_CPU_EOI);
+				handle_IPI(1, regs);
 				break;
 
 			case IPI1_CPU0:
 			case IPI1_CPU1:
 			case IPI1_CPU2:
 			case IPI1_CPU3:
-				ipinum = 3;
+				writel_relaxed(irqnr, cpu_base + GIC_CPU_EOI);
+				handle_IPI(2, regs);
 				break;
 
 			case IPI2_CPU0:
 			case IPI2_CPU1:
 			case IPI2_CPU2:
 			case IPI2_CPU3:
-				ipinum = mplx_ipi_num_45; /* 4 or 5 */
+				writel_relaxed(irqnr, cpu_base + GIC_CPU_EOI);
+				axxia_ipi_demux(regs);
 				break;
 
 			case IPI3_CPU0:
 			case IPI3_CPU1:
 			case IPI3_CPU2:
 			case IPI3_CPU3:
-				ipinum = mplx_ipi_num_61; /* 6 or 1 */
+				writel_relaxed(irqnr, cpu_base + GIC_CPU_EOI);
+				axxia_gic_handle_gic_rpc_ipi();
 				break;
 
 			default:
-				/* Not an Axxia IPI */
-				ipinum = 0;
-				break;
-			}
-
-			if (ipinum > 1) { /* Ignore IPI_WAKEUP (1) */
-				/*
-				 * Write the original irq number to the
-				 * EOI register to acknowledge the IRQ.
-				 * No need to write CPUID field, since this
-				 * is really a SPI interrupt, not a SGI.
-				 */
-				writel_relaxed(irqnr, cpu_base + GIC_CPU_EOI);
-#ifdef CONFIG_SMP
-				/* Do the normal IPI handling. */
-				handle_IPI(ipinum, regs);
-#endif
-
-			} else {
+				/* External interrupt */
 				handle_IRQ(irqnr, regs);
+				break;
 			}
 			continue;
 		}
@@ -612,9 +693,9 @@ static void __init gic_axxia_init(struct gic_chip_data *gic)
 
 	/*
 	 * Initialize the Axxia IRQ affinity table. All non-IPI
-	 * interrupts are initially assigned to logical cpu 0.
+	 * interrupts are initially assigned to physical cpu 0.
 	 */
-	for (i = 0; i < 1020; i++)
+	for (i = 0; i < MAX_GIC_INTERRUPTS; i++)
 		irq_cpuid[i] = 0;
 
 	/* Unmask all Axxia IPI interrupts */
@@ -907,18 +988,13 @@ static int gic_notifier(struct notifier_block *self, unsigned long cmd,	void *v)
 	data.v = v;
 	for (i = 0; i < nr_cluster_ids; i++) {
 		/* Skip the cluster we're already executing on - do last. */
-		if ((pcpu/4) == i)
+		if ((pcpu / 4) == i)
 			continue;
 
 		/* Have the first cpu in each cluster execute this. */
 		cpu = i * 4;
-		if (cpu_online(cpu)) {
-			local_irq_enable();
-			smp_call_function_single(cpu,
-						 gic_notifier_wrapper,
-						 &data, 0);
-			local_irq_disable();
-		}
+		if (cpu_online(cpu))
+			axxia_gic_run_gic_rpc(cpu, gic_notifier_wrapper, &data);
 	}
 
 	/* Execute on this cluster. */
@@ -1028,8 +1104,8 @@ void __init gic_init_bases(unsigned int gic_nr, int irq_start,
 	 */
 	gic_irqs = readl_relaxed(gic_data_dist_base(gic) + GIC_DIST_CTR) & 0x1f;
 	gic_irqs = (gic_irqs + 1) * 32;
-	if (gic_irqs > 1020)
-		gic_irqs = 1020;
+	if (gic_irqs > MAX_GIC_INTERRUPTS)
+		gic_irqs = MAX_GIC_INTERRUPTS;
 	gic->gic_irqs = gic_irqs;
 
 	gic_irqs -= hwirq_base; /* calculate # of irqs to allocate */
@@ -1045,6 +1121,10 @@ void __init gic_init_bases(unsigned int gic_nr, int irq_start,
 	if (WARN_ON(!gic->domain))
 		return;
 
+#ifdef CONFIG_SMP
+	set_smp_cross_call(axxia_gic_raise_softirq);
+#endif
+
 	gic_axxia_init(gic);
 	gic_dist_init(gic);
 	gic_cpu_init(gic);
@@ -1080,7 +1160,7 @@ void axxia_gic_raise_softirq(const struct cpumask *mask, unsigned int irq)
 
 	/* Sanity check the physical cpu number */
 	if (phys_cpu >= nr_cpu_ids) {
-		printk(KERN_ERR "Invalid cpu num (%d) >= max (%d)\n",
+		pr_err("Invalid cpu num (%d) >= max (%d)\n",
 			phys_cpu, nr_cpu_ids);
 		return;
 	}
@@ -1109,29 +1189,41 @@ void axxia_gic_raise_softirq(const struct cpumask *mask, unsigned int irq)
 		regoffset = (phys_cpu - 8) * 0x1000 + 0x10000;
 
 	switch (irq) {
-	case 2: /* IPI_TIMER */
+	case 0: /* IPI_WAKEUP */
+		regoffset += 0x8; /* Axxia IPI2 */
+		muxed_ipi_message_pass(mask, MUX_MSG_CPU_WAKEUP);
+		break;
+
+	case 1: /* IPI_TIMER */
 		regoffset += 0x0; /* Axxia IPI0 */
 		break;
 
-	case 3: /* IPI_RESCHEDULE */
+	case 2: /* IPI_RESCHEDULE */
 		regoffset += 0x4; /* Axxia IPI1 */
 		break;
 
-	case 4: /* IPI_CALL_FUNC */
-	case 5: /* IPI_CALL_FUNC_SINGLE */
+	case 3: /* IPI_CALL_FUNC */
+		regoffset += 0x8; /* Axxia IPI2 */
+		muxed_ipi_message_pass(mask, MUX_MSG_CALL_FUNC);
+		break;
+
+	case 4: /* IPI_CALL_FUNC_SINGLE */
+		regoffset += 0x8; /* Axxia IPI2 */
+		muxed_ipi_message_pass(mask, MUX_MSG_CALL_FUNC_SINGLE);
+		break;
+
+	case 5: /* IPI_CPU_STOP */
 		regoffset += 0x8; /* Axxia IPI2 */
-		mplx_ipi_num_45 = irq;
+		muxed_ipi_message_pass(mask, MUX_MSG_CPU_STOP);
 		break;
 
-	case 6: /* IPI_CPU_STOP */
-	case 1: /* IPI_WAKEUP */
+	case AXXIA_RPC:
 		regoffset += 0xC; /* Axxia IPI3 */
-		mplx_ipi_num_61 = irq;
 		break;
 
 	default:
 		/* Unknown ARM IPI */
-		printk(KERN_ERR "Unknown ARM IPI num (%d)!\n", irq);
+		pr_err("Unknown ARM IPI num (%d)!\n", irq);
 		return;
 	}
 
@@ -1163,10 +1255,10 @@ int __init gic_of_init(struct device_node *node, struct device_node *parent)
 	cpu_base = of_iomap(node, 1);
 	WARN(!cpu_base, "unable to map gic cpu registers\n");
 
-	ipi_mask_reg_base = of_iomap(node, 2);
+	ipi_mask_reg_base = of_iomap(node, 4);
 	WARN(!ipi_mask_reg_base, "unable to map Axxia IPI mask registers\n");
 
-	ipi_send_reg_base = of_iomap(node, 3);
+	ipi_send_reg_base = of_iomap(node, 5);
 	WARN(!ipi_send_reg_base, "unable to map Axxia IPI send registers\n");
 
 	if (of_property_read_u32(node, "cpu-offset", &percpu_offset))
diff --git a/arch/arm/mach-axxia/axxia.c b/arch/arm/mach-axxia/axxia.c
index df63dbd..2b7c2c1 100644
--- a/arch/arm/mach-axxia/axxia.c
+++ b/arch/arm/mach-axxia/axxia.c
@@ -35,31 +35,30 @@
 #include <linux/delay.h>
 #include <linux/smsc911x.h>
 #include <linux/spi/spi.h>
+#include <linux/clk-provider.h>
 #include <linux/clkdev.h>
 #ifdef CONFIG_ARM_ARCH_TIMER
 #include <asm/arch_timer.h>
 #endif
-#include <asm/mach-types.h>
 #include <asm/sizes.h>
+#include <asm/pmu.h>
 #include <asm/mach/arch.h>
 #include <asm/mach/map.h>
 #include <asm/mach/time.h>
 #include <asm/hardware/cache-l2x0.h>
-#include <asm/hardware/gic.h>
 #include <mach/timers.h>
 #include <mach/axxia-gic.h>
+#include <linux/irqchip/arm-gic.h>
 #include "axxia.h"
 #include "pci.h"
 #include "i2c.h"
 
-extern void axxia_ddr_retention_init(void);
-
 static const char *axxia_dt_match[] __initconst = {
 	"lsi,axm5516",		/* AXM5516 */
+	"lsi,axm5516-sim",	/* AXM5516 Simulation */
 	NULL
 };
 
-
 static void __iomem *ssp_base;
 
 void __init axxia_dt_map_io(void)
@@ -93,12 +92,8 @@ void __init axxia_dt_timer_init(void)
 	axxia_init_clocks();
 
 #ifdef CONFIG_ARM_ARCH_TIMER
-	{
-		int err = arch_timer_of_register();
-		if (err == 0)
-			err = arch_timer_sched_clock_init();
-		WARN_ON(err);
-	}
+	of_clk_init(NULL);
+	clocksource_of_init();
 #endif
 
 	if (of_property_read_string(of_aliases, "timer", &path)) {
@@ -114,17 +109,9 @@ void __init axxia_dt_timer_init(void)
 	if (WARN_ON(base == NULL))
 		return;
 
-	__sp804_clocksource_and_sched_clock_init(base, "axxia-timer0", 0);
-	sp804_clockevents_init(base + 0x20,
-			       irq_of_parse_and_map(node, 1),
-			       "axxia-timer1");
+	sp804_clocksource_and_sched_clock_init(base, "axxia-timer0");
 }
 
-
-static struct sys_timer axxia_dt_timer = {
-	.init = axxia_dt_timer_init,
-};
-
 static struct mmci_platform_data mmc_plat_data = {
 	.ocr_mask = MMC_VDD_32_33 | MMC_VDD_33_34,
 	.status	  = NULL,
@@ -164,13 +151,64 @@ static struct of_dev_auxdata axxia_auxdata_lookup[] __initdata = {
 	{}
 };
 
+static struct resource axxia_pmu_resources[] = {
+	[0] = {
+		.start  = IRQ_PMU,
+		.end    = IRQ_PMU,
+		.flags  = IORESOURCE_IRQ,
+	},
+};
+
+/*
+ * The PMU IRQ lines of two cores are wired together into a single interrupt.
+ * Bounce the interrupt to other cores if it's not ours.
+ */
+#define CORES_PER_CLUSTER  4
+static irqreturn_t axxia_pmu_handler(int irq, void *dev, irq_handler_t handler)
+{
+	irqreturn_t ret = handler(irq, dev);
+	int cpu = smp_processor_id();
+	int cluster = cpu / CORES_PER_CLUSTER;
+	int other;
+
+	if (ret == IRQ_NONE) {
+
+		/* Look until we find another cpu that's online. */
+		do {
+			other = (++cpu % CORES_PER_CLUSTER) +
+				(cluster * CORES_PER_CLUSTER);
+		} while (!cpu_online(other));
+
+		irq_set_affinity(irq, cpumask_of(other));
+	}
+
+	/*
+	 * We should be able to get away with the amount of IRQ_NONEs we give,
+	 * while still having the spurious IRQ detection code kick in if the
+	 * interrupt really starts hitting spuriously.
+	 */
+	return ret;
+}
+
+static struct arm_pmu_platdata axxia_pmu_platdata = {
+	.handle_irq		= axxia_pmu_handler,
+};
+
+static struct platform_device pmu_device = {
+	.name			= "arm-pmu",
+	.id                     = -1,
+	.num_resources		= ARRAY_SIZE(axxia_pmu_resources),
+	.resource		= axxia_pmu_resources,
+	.dev.platform_data	= &axxia_pmu_platdata,
+};
+
 static inline void
 spidev_chip_select(u32 control, unsigned n)
 {
 	if (control == SSP_CHIP_SELECT)
-		writel(~(1<<n) & 0x1F, ssp_base+0x30);
+		writel(~(1<<n) & 0x1F, ssp_base + 0x30);
 	else
-		writel(0x1F, ssp_base+0x30);
+		writel(0x1F, ssp_base + 0x30);
 }
 
 static void spi_cs_eeprom0(u32 control) { spidev_chip_select(control, 0); }
@@ -207,7 +245,6 @@ static struct spi_board_info spi_devs[] __initdata = {
 	}
 };
 
-
 static int
 l3_set_pstate(void __iomem *l3ctrl, unsigned int req, unsigned int act)
 {
@@ -237,6 +274,30 @@ l3_set_pstate(void __iomem *l3ctrl, unsigned int req, unsigned int act)
 	return 0;
 }
 
+static int
+axxia_bus_notifier(struct notifier_block *nb, unsigned long event, void *obj)
+{
+	struct device *dev = obj;
+
+	if (event != BUS_NOTIFY_ADD_DEVICE)
+		return NOTIFY_DONE;
+
+	if (!of_property_read_bool(dev->of_node, "dma-coherent"))
+		return NOTIFY_DONE;
+
+	set_dma_ops(dev, &arm_coherent_dma_ops);
+
+	return NOTIFY_OK;
+}
+
+static struct notifier_block axxia_platform_nb = {
+	.notifier_call = axxia_bus_notifier,
+};
+
+static struct notifier_block axxia_amba_nb = {
+	.notifier_call = axxia_bus_notifier,
+};
+
 void __init axxia_dt_init(void)
 {
 	void __iomem *l3ctrl;
@@ -255,6 +316,9 @@ void __init axxia_dt_init(void)
 	}
 #endif
 
+	bus_register_notifier(&platform_bus_type, &axxia_platform_nb);
+	bus_register_notifier(&amba_bustype, &axxia_amba_nb);
+
 	of_platform_populate(NULL, of_default_bus_match_table,
 			     axxia_auxdata_lookup, NULL);
 	pm_power_off = NULL; /* TBD */
@@ -266,14 +330,12 @@ void __init axxia_dt_init(void)
 	 */
 	ssp_base = of_iomap(of_find_compatible_node(NULL, NULL, "arm,pl022"),
 			    0);
-	if (!WARN_ON(ssp_base == NULL)) {
-		/* Use legacy mode, bits 0..4 control nCS[0..4] pins */
-		writel(0x1F, ssp_base+0x30);
-	}
 
 	axxia_pcie_init();
 
 	axxia_ddr_retention_init();
+
+	platform_device_register(&pmu_device);
 }
 
 static void axxia_restart(char str, const char *cmd)
@@ -290,14 +352,15 @@ static void axxia_restart(char str, const char *cmd)
 
 DT_MACHINE_START(AXXIA_DT, "LSI Axxia")
 	.dt_compat	= axxia_dt_match,
+	.smp		= smp_ops(axxia_smp_ops),
 	.map_io		= axxia_dt_map_io,
 	.init_early	= axxia_dt_init_early,
 	.init_irq	= axxia_dt_init_irq,
-	.timer		= &axxia_dt_timer,
+	.init_time	= axxia_dt_timer_init,
 	.init_machine	= axxia_dt_init,
 	.handle_irq	= axxia_gic_handle_irq,
 	.restart	= axxia_restart,
 #if defined(CONFIG_ZONE_DMA) && defined(CONFIG_ARM_LPAE)
-	.dma_zone_size	= (4ULL * SZ_1G),
+	.dma_zone_size	= (4ULL * SZ_1G) - 1,
 #endif
 MACHINE_END
diff --git a/arch/arm/mach-axxia/axxia.h b/arch/arm/mach-axxia/axxia.h
index 1c8e800..be1cca6 100644
--- a/arch/arm/mach-axxia/axxia.h
+++ b/arch/arm/mach-axxia/axxia.h
@@ -1,5 +1,8 @@
 #ifndef _AXXIA_H
 
 void axxia_init_clocks(void);
+extern void axxia_ddr_retention_init(void);
+
+extern struct smp_operations axxia_smp_ops;
 
 #endif
diff --git a/arch/arm/mach-axxia/clock.c b/arch/arm/mach-axxia/clock.c
index 49ca80b..63d02de 100644
--- a/arch/arm/mach-axxia/clock.c
+++ b/arch/arm/mach-axxia/clock.c
@@ -28,8 +28,14 @@
 		clkdev_add(cl); \
 	} while (0)
 
-#ifdef CONFIG_ARCH_AXXIA_SIM
+/*
+  ------------------------------------------------------------------------------
+  axxia_init_clocks
 
+  Clock setup for Emulation/ASIC systems.
+*/
+
+#ifdef CONFIG_ARCH_AXXIA_SIM
 void __init
 axxia_init_clocks(void)
 {
@@ -82,19 +88,7 @@ axxia_init_clocks(void)
 	clk_register_clkdev(clk, NULL, "mmci");
 }
 
-#else
-
-static struct of_device_id cpu_pll[] __initconst = {
-	{ .name = "/clocks/cpu", },
-	{},
-};
-
-/*
-  --------------------------------------------------------------------
-  axxia_init_clocks
-
-  Clock setup for Emulation/ASIC systems.
-*/
+#else /* !CONFIG_ARCH_AXXIA_SIM */
 
 void __init
 axxia_init_clocks(void)
@@ -108,7 +102,7 @@ axxia_init_clocks(void)
 
 	if (np) {
 		if (of_property_read_u32(np, "frequency", &frequency))
-			printk(KERN_ERR "%d - Error!", __LINE__);
+			pr_err("%d - Error!", __LINE__);
 	}
 
 	clk = clk_register_fixed_rate(NULL, "clk_cpu", NULL,
@@ -118,7 +112,7 @@ axxia_init_clocks(void)
 
 	if (np) {
 		if (of_property_read_u32(np, "frequency", &frequency))
-			printk(KERN_ERR "%d - Error!", __LINE__);
+			pr_err("%d - Error!", __LINE__);
 	}
 
 	clk = clk_register_fixed_rate(NULL, "clk_per", NULL,
@@ -148,7 +142,7 @@ axxia_init_clocks(void)
 
 	if (np) {
 		if (of_property_read_u32(np, "frequency", &frequency))
-			printk(KERN_ERR "%d - Error!", __LINE__);
+			pr_err("%d - Error!", __LINE__);
 	}
 
 	clk = clk_register_fixed_rate(NULL, "clk_mmci", NULL,
@@ -173,4 +167,4 @@ axxia_init_clocks(void)
 	return;
 }
 
-#endif
+#endif /* CONFIG_ARCH_AXXIA_SIM */
diff --git a/arch/arm/mach-axxia/ddr_retention.c b/arch/arm/mach-axxia/ddr_retention.c
index 988d361..ca426c2 100644
--- a/arch/arm/mach-axxia/ddr_retention.c
+++ b/arch/arm/mach-axxia/ddr_retention.c
@@ -34,7 +34,6 @@
 #include <asm/cacheflush.h>
 #include <../../../drivers/misc/lsi-ncr.h>
 
-extern void flush_l3(void);
 static void __iomem *nca_address;
 static void __iomem *apb_base;
 
@@ -81,7 +80,7 @@ static void quiesce_vp_engine(void)
 	unsigned short node, target;
 	int loop;
 
-	printk(KERN_INFO "quiescing VP engines...\n");
+	pr_info("quiescing VP engines...\n");
 	pRegion = pCnalRegions;
 	while (*pRegion != NCP_REGION_ID(0xff, 0xff)) {
 
@@ -102,14 +101,13 @@ static void quiesce_vp_engine(void)
 
 		if ((ort == 0) && (owt == 0)) {
 			/* this engine has been quiesced, move on to the next */
-			printk(KERN_INFO "quiesced region 0x%02x.0x%02x\n",
+			pr_info("quiesced region 0x%02x.0x%02x\n",
 				node, target);
 			pRegion++;
 		} else {
 			if (loop++ > 10000) {
-				printk(KERN_INFO
-					"Unable to quiesce region 0x%02x.0x%02x ort=0x%x, owt=0x%x\n",
-				     node, target, ort, owt);
+				pr_info("Unable to quiesce region 0x%02x.0x%02x ort=0x%x, owt=0x%x\n",
+					node, target, ort, owt);
 				pRegion++;
 				loop = 0;
 				continue;
@@ -179,13 +177,13 @@ static inline void ncp_ddr_shutdown(void)
 	}
 
 	/* indicate DDR retention reset */
-	writel(0x00000001, apb_base + 0x300dc);	/* set bit 0 of persist_scratch */
+	writel(0x00000001, apb_base + 0x300dc);	/* set persist_scratch bit 0 */
 
 	/* issue chip reset */
-	writel(0x00000040, apb_base + 0x31004);	/* Intrnl Boot, 0xffff0000 Target */
+	writel(0x00000040, apb_base + 0x31004);	/* Internal Boot, 0xffff0000
+						   Target */
 	writel(0x80000000, apb_base + 0x3180c);	/* Set ResetReadDone */
 	writel(0x00080802, apb_base + 0x31008);	/* Chip Reset */
-
 }
 
 void initiate_retention_reset(void)
@@ -198,8 +196,8 @@ void initiate_retention_reset(void)
 
 	/* send stop message to other CPUs */
 	local_irq_disable();
-	asm volatile ("dsb":::"memory");
-	asm volatile ("dmb":::"memory");
+	asm volatile ("dsb" : : : "memory");
+	asm volatile ("dmb" : : : "memory");
 	system_state = SYSTEM_RESTART;
 	smp_send_stop();
 
@@ -209,7 +207,7 @@ void initiate_retention_reset(void)
 	quiesce_vp_engine();
 
 	/* disable sysmem interrupts */
-	printk("disabling sysmem interrupts\n");
+	pr_info("disabling sysmem interrupts\n");
 	value = 0;
 	ncr_write(NCP_REGION_ID(34, 0), 0x414, 4, &value);
 	ncr_write(NCP_REGION_ID(15, 0), 0x414, 4, &value);
@@ -240,11 +238,10 @@ void initiate_retention_reset(void)
 	 * this should cause the next few instructions to be fetched
 	 * into cache
 	 */
-	asm volatile ("dsb":::"memory");
+	asm volatile ("dsb" : : : "memory");
 	prefetch(ncp_ddr_shutdown);
 
 	ncp_ddr_shutdown();
-
 }
 
 static ssize_t axxia_ddr_retention_trigger(struct file *file,
@@ -262,14 +259,10 @@ static const struct file_operations axxia_ddr_retention_proc_ops = {
 
 void axxia_ddr_retention_init(void)
 {
-#ifndef CONFIG_ARCH_AXXIA_SIM
 	if (!proc_create("driver/axxia_ddr_retention_reset", S_IWUSR, NULL,
 			 &axxia_ddr_retention_proc_ops))
-		printk(KERN_INFO
-			"Failed to register DDR retention proc interface\n");
-#endif
+		pr_info("Failed to register DDR retention proc interface\n");
 }
-
 EXPORT_SYMBOL(initiate_retention_reset);
 
 #else
@@ -279,4 +272,4 @@ void axxia_ddr_retention_init(void)
 	return;
 }
 
-#endif
+#endif /* CONFIG_ARCH_AXXIA_SIM */
diff --git a/arch/arm/mach-axxia/headsmp.S b/arch/arm/mach-axxia/headsmp.S
index f467cc5..b4fe409 100644
--- a/arch/arm/mach-axxia/headsmp.S
+++ b/arch/arm/mach-axxia/headsmp.S
@@ -56,7 +56,7 @@ __delay:
 	nop
 	subs	r4,r4,#1
 	bne	__delay
- 	cmp	r7, r0
+	cmp	r7, r0
 	bne	pen
 
 	/*
diff --git a/arch/arm/mach-axxia/i2c.c b/arch/arm/mach-axxia/i2c.c
index 5f9eff3..2fd8f78 100644
--- a/arch/arm/mach-axxia/i2c.c
+++ b/arch/arm/mach-axxia/i2c.c
@@ -67,12 +67,12 @@ axxia_add_i2c_bus(
 	if (!of_property_read_u32(np, "port", (u32 *)&pval)) {
 		portno = pval;
 	} else {
-		printk(KERN_ERR "I2C: Can't find port number for %s\n",
+		pr_err("I2C: Can't find port number for %s\n",
 			np->full_name);
 		return -ENXIO;
 	}
 	if (portno > axxia_i2cx_port_count) {
-		printk(KERN_ERR "I2C: port number out of range for %s\n",
+		pr_err("I2C: port number out of range for %s\n",
 			np->full_name);
 		return -ENXIO;
 	}
@@ -85,7 +85,7 @@ axxia_add_i2c_bus(
 	/* Verify device type */
 	val = of_get_property(np, "device_type", NULL);
 	if (strcmp(val, "i2c")) {
-		printk(KERN_ERR "I2C%d: missing or incorrect device_type for %s\n",
+		pr_err("I2C%d: missing or incorrect device_type for %s\n",
 			portno, np->full_name);
 		return -ENXIO;
 	}
@@ -109,7 +109,7 @@ axxia_add_i2c_bus(
 
 	/* Fetch config space registers address */
 	if (of_address_to_resource(np, 0, &pdata->dev_space)) {
-		printk(KERN_ERR "%s: Can't get I2C device space !",
+		pr_err("%s: Can't get I2C device space !",
 			np->full_name);
 		return -ENXIO;
 	}
@@ -120,19 +120,15 @@ axxia_add_i2c_bus(
 	pdata->int_space.flags = IORESOURCE_IRQ;
 
 	if (pdata->bus_nr == ~0) {
-		printk(KERN_INFO
-			"I2C Port %d found; bus#=<auto> '%s'\n",
+		pr_info("I2C Port %d found; bus#=<auto> '%s'\n",
 			portno, pdata->name);
 	} else {
-		printk(KERN_INFO
-			"I2C Port %d found; bus#=i%d '%s'\n",
+		pr_info("I2C Port %d found; bus#=i%d '%s'\n",
 			portno, pdata->bus_nr, pdata->name);
 	}
-	printk(KERN_INFO
-	    "  dev_space start = 0x%012llx, end = 0x%012llx\n",
-	    pdata->dev_space.start, pdata->dev_space.end);
-	printk(KERN_INFO
-	    "  mappedIrq#=%x\n", (unsigned int)pdata->int_space.start);
+	pr_info("  dev_space start = 0x%012llx, end = 0x%012llx\n",
+		pdata->dev_space.start, pdata->dev_space.end);
+	pr_info("  mappedIrq#=%x\n", (unsigned int)pdata->int_space.start);
 
 	/* Fill in the device */
 	pdev->id = ndx;
@@ -141,11 +137,6 @@ axxia_add_i2c_bus(
 	pdev->resource = &pdata->dev_space;
 	pdev->dev.platform_data = pdata;
 
-	/* printk(KERN_INFO
-	    "pdev: id=%d name='%s' n_r=%d res=%p d.p_d=%p\n",
-	    pdev->id, pdev->name, pdev->num_resources,
-	    pdev->resource, pdev->dev.platform_data); */
-
 	return 0;
 }
 
@@ -176,7 +167,7 @@ axxia_register_i2c_busses(
 				   sizeof(struct axxia_i2c_bus_platform_data),
 				   GFP_KERNEL);
 	if (!axxia_i2cx_ports) {
-		printk(KERN_WARNING "I2C: failed to allocate ports array\n");
+		pr_warn("I2C: failed to allocate ports array\n");
 		return -ENOMEM;
 	}
 	memset(axxia_i2cx_ports, 0,
@@ -187,7 +178,7 @@ axxia_register_i2c_busses(
 				     sizeof(struct platform_device),
 				     GFP_KERNEL);
 	if (!axxia_i2cx_devices) {
-		printk(KERN_WARNING "I2C: failed to allocate devices array\n");
+		pr_warn("I2C: failed to allocate devices array\n");
 		return -ENOMEM;
 	}
 	memset(axxia_i2cx_devices, 0,
@@ -197,8 +188,7 @@ axxia_register_i2c_busses(
 					 sizeof(struct platform_device *),
 					 GFP_KERNEL);
 	if (!axxia_i2cx_device_ptrs) {
-		printk(KERN_WARNING
-			"I2C: failed to allocate device ptrs array\n");
+		pr_warn("I2C: failed to allocate device ptrs array\n");
 		return -ENOMEM;
 	}
 	memset(axxia_i2cx_device_ptrs, 0,
diff --git a/arch/arm/mach-axxia/include/mach/axxia-gic.h b/arch/arm/mach-axxia/include/mach/axxia-gic.h
index 5463260..cc36a51 100644
--- a/arch/arm/mach-axxia/include/mach/axxia-gic.h
+++ b/arch/arm/mach-axxia/include/mach/axxia-gic.h
@@ -12,5 +12,6 @@ void axxia_gic_handle_irq(struct pt_regs *regs);
 void axxia_gic_raise_softirq(const struct cpumask *mask, unsigned int irq);
 void axxia_gic_secondary_cluster_init(void);
 void axxia_gic_secondary_init(void);
+int __init gic_of_init(struct device_node *node, struct device_node *parent);
 
 #endif
diff --git a/arch/arm/mach-axxia/include/mach/irqs.h b/arch/arm/mach-axxia/include/mach/irqs.h
index 5f25c95..ebff99a 100644
--- a/arch/arm/mach-axxia/include/mach/irqs.h
+++ b/arch/arm/mach-axxia/include/mach/irqs.h
@@ -1,4 +1,5 @@
 #define IRQ_LOCALTIMER		29
 #define IRQ_LOCALWDOG		30
-#define AXXIA_MSI_FIRST         224
-#define NR_IRQS	                256
+#define IRQ_PMU			222
+#define AXXIA_MSI_FIRST		224
+#define NR_IRQS			256
diff --git a/arch/arm/mach-axxia/pci.c b/arch/arm/mach-axxia/pci.c
index 2600892f..c0c030f 100644
--- a/arch/arm/mach-axxia/pci.c
+++ b/arch/arm/mach-axxia/pci.c
@@ -47,8 +47,8 @@
 #define PCIE_MPAGE_U(n)          (0x1010 + (n * 8)) /* n = 0..7 */
 #define PCIE_MPAGE_L(n)          (0x1014 + (n * 8)) /* n = 0..7 */
 #define PCIE_TPAGE_BAR0(n)       (0x1050 + (n * 4)) /* n = 0..7 */
-#define   PCIE_TPAGE_32          (0<<31) /* AXI 32-bit access */
-#define   PCIE_TPAGE_128	 (1<<31) /* AXI 128-bit access */
+#define     PCIE_TPAGE_32        (0<<31) /* AXI 32-bit access */
+#define     PCIE_TPAGE_128       (1<<31) /* AXI 128-bit access */
 #define PCIE_TPAGE_BAR1(n)       (0x1070 + (n * 4)) /* n = 0..7 */
 #define PCIE_TPAGE_BAR2(n)       (0x1090 + (n * 4)) /* n = 0..7 */
 #define PCIE_MSG_IN_FIFO         (0x10B0)
@@ -144,7 +144,7 @@ struct axxia_pciex_port {
 static struct axxia_pciex_port *axxia_pciex_ports;
 
 
-static void __init
+static void
 fixup_axxia_pci_bridge(struct pci_dev *dev)
 {
 	/* if we aren't a PCIe don't bother */
@@ -170,7 +170,6 @@ static struct axxia_pciex_port *bus_to_port(struct pci_bus *bus)
 	return axxia_pciex_ports + pci_domain_nr(bus);
 }
 
-
 /*
  * Validate the Bus#/Device#/Function#
  */
@@ -312,8 +311,7 @@ arm_pciex_axxia_read_config(struct pci_bus *bus,
 	}
 
 #ifdef PRINT_CONFIG_ACCESSES
-	printk(KERN_INFO
-		"acp_read_config for PCIE%d: %3d  fn=0x%04x o=0x%04x l=%d "
+	pr_info("acp_read_config for PCIE%d: %3d  fn=0x%04x o=0x%04x l=%d "
 		"a=0x%08x v=0x%08x, dev=%d\n",
 			port->index, bus->number, devfn, offset, len,
 			bus_addr, *val, PCI_SLOT(devfn));
@@ -378,8 +376,7 @@ arm_pciex_axxia_write_config(struct pci_bus *bus,
 	}
 
 #ifdef PRINT_CONFIG_ACCESSES
-	printk(KERN_INFO
-		"acp_write_config: bus=%3d devfn=0x%04x offset=0x%04x len=%d"
+	pr_info("acp_write_config: bus=%3d devfn=0x%04x offset=0x%04x len=%d"
 		"addr=0x%08x val=0x%08x\n",
 		bus->number, devfn, offset, len, bus_addr, val);
 #endif
@@ -562,7 +559,6 @@ pcie_pei0_msi_handler(unsigned int irq, struct irq_desc *desc)
 	irq_desc_get_chip(desc)->irq_eoi(&desc->irq_data);
 }
 
-
 /* PCIe setup function */
 static int axxia_pcie_setup(int portno, struct pci_sys_data *sys)
 {
@@ -743,7 +739,7 @@ pcie_alloc_msi_table(struct pci_dev *pdev, struct axxia_pciex_port *port)
 /*
  * Scan PCIe bus
  */
-static struct pci_bus __init *
+static struct pci_bus *
 axxia_pcie_scan_bus(int nr, struct pci_sys_data *sys)
 {
 	if (WARN_ON(nr >= PCIE_MAX_PORTS))
@@ -755,7 +751,7 @@ axxia_pcie_scan_bus(int nr, struct pci_sys_data *sys)
 
 
 
-static int __init
+static int
 axxia_pcie_map_irq(const struct pci_dev *dev, u8 slot, u8 pin)
 {
 	struct pci_sys_data *sys = dev->sysdata;
@@ -772,13 +768,11 @@ static struct irq_chip axxia_msi_chip = {
 	.irq_unmask  = unmask_msi_irq,
 };
 
-
 /* Port definition struct */
 static struct hw_pci axxia_pcie_hw[] = {
 	[0] = {
 		.nr_controllers = 1,
 		.domain = 0,
-		.swizzle = pci_std_swizzle,
 		.setup = axxia_pcie_setup,
 		.scan = axxia_pcie_scan_bus,
 		.map_irq = axxia_pcie_map_irq
@@ -786,7 +780,6 @@ static struct hw_pci axxia_pcie_hw[] = {
 	[1] = {
 		.nr_controllers = 1,
 		.domain = 1,
-		.swizzle = pci_std_swizzle,
 		.setup = axxia_pcie_setup,
 		.scan = axxia_pcie_scan_bus,
 		.map_irq = axxia_pcie_map_irq
@@ -824,7 +817,7 @@ axxia_probe_pciex_bridge(struct device_node *np)
 
 	port = &axxia_pciex_ports[portno];
 	port->index = portno;
-	snprintf(port->name, sizeof port->name - 1, "PCIE%d", portno);
+	snprintf(port->name, sizeof(port->name) - 1, "PCIE%d", portno);
 	port->node = of_node_get(np);
 
 	/* Check if device_type property is set to "pci" or "pci-endpoint".
@@ -933,7 +926,6 @@ axxia_probe_pciex_bridge(struct device_node *np)
 		portno,
 		port->pci_bar,
 		port->inbound.start, port->inbound.end);
-
 }
 
 /*
diff --git a/arch/arm/mach-axxia/platsmp.c b/arch/arm/mach-axxia/platsmp.c
index a382cb2..33bdfd0 100644
--- a/arch/arm/mach-axxia/platsmp.c
+++ b/arch/arm/mach-axxia/platsmp.c
@@ -18,20 +18,15 @@
 #include <linux/of_fdt.h>
 #include <asm/smp_plat.h>
 #include <asm/cacheflush.h>
-#include <asm/hardware/gic.h>
+#include <linux/irqchip/arm-gic.h>
 #include <asm/mach/map.h>
+#include <asm/virt.h>
 
 #include <mach/axxia-gic.h>
 
-/*
- * Control for which core is the next to come out of the secondary
- * boot "holding pen".
- */
-volatile int __cpuinitdata pen_release = -1;
-
 extern void axxia_secondary_startup(void);
 
-#define APB2_SER3_PHY_ADDR      0x002010030000ULL
+#define APB2_SER3_PHY_ADDR    0x002010030000ULL
 #define APB2_SER3_ADDR_SIZE   0x10000
 
 /*
@@ -49,7 +44,7 @@ static void __cpuinit write_pen_release(int val)
 
 static DEFINE_RAW_SPINLOCK(boot_lock);
 
-void __cpuinit platform_secondary_init(unsigned int cpu)
+void __cpuinit axxia_secondary_init(unsigned int cpu)
 {
 	/*
 	 * If this isn't the first physical core in a secondary cluster
@@ -74,7 +69,7 @@ void __cpuinit platform_secondary_init(unsigned int cpu)
 	_raw_spin_unlock(&boot_lock);
 }
 
-int __cpuinit boot_secondary(unsigned int cpu, struct task_struct *idle)
+int __cpuinit axxia_boot_secondary(unsigned int cpu, struct task_struct *idle)
 {
 	unsigned long timeout;
 	int phys_cpu, cluster;
@@ -121,7 +116,6 @@ int __cpuinit boot_secondary(unsigned int cpu, struct task_struct *idle)
 #else
 	timeout = jiffies + (10 * HZ);
 #endif
-
 	while (time_before(jiffies, timeout)) {
 		smp_rmb();
 		if (pen_release == -1)
@@ -143,7 +137,7 @@ int __cpuinit boot_secondary(unsigned int cpu, struct task_struct *idle)
  * Initialise the CPU possible map early - this describes the CPUs
  * which may be present or become present in the system.
  */
-void __init smp_init_cpus(void)
+static void __init axxia_smp_init_cpus(void)
 {
 	int ncores = 0;
 	struct device_node *np;
@@ -163,12 +157,9 @@ void __init smp_init_cpus(void)
 					 cpu_num);
 		}
 	}
-
-	set_smp_cross_call(axxia_gic_raise_softirq);
 }
 
-void __init
-platform_smp_prepare_cpus(unsigned int max_cpus)
+static void __init axxia_smp_prepare_cpus(unsigned int max_cpus)
 {
 #ifdef CONFIG_ARCH_AXXIA_SIM
 	int i;
@@ -186,15 +177,16 @@ platform_smp_prepare_cpus(unsigned int max_cpus)
 	 * "holding pen".
 	 */
 	*(u32 *)phys_to_virt(0x10000020) =
-		virt_to_phys(axxia_secondary_startup);
+					  virt_to_phys(axxia_secondary_startup);
 #else
 	int i;
+	int cpu_count = 0;
+	u32 phys_cpu = 0;
 	void __iomem *apb2_ser3_base;
 	unsigned long resetVal;
-	int phys_cpu, cpu_count = 0;
 	struct device_node *np;
 	unsigned long release_addr[NR_CPUS] = {0};
-	unsigned long release;
+	u32 release;
 
 	if (of_find_compatible_node(NULL, NULL, "lsi,axm5516")) {
 		for_each_node_by_name(np, "cpu") {
@@ -209,6 +201,9 @@ platform_smp_prepare_cpus(unsigned int max_cpus)
 				continue;
 
 			release_addr[phys_cpu] = release;
+			pr_debug("%s:%d - set address for %d to 0x%08lx\n",
+				 __FILE__, __LINE__,
+				 phys_cpu, release_addr[phys_cpu]);
 		}
 
 		/*
@@ -216,32 +211,40 @@ platform_smp_prepare_cpus(unsigned int max_cpus)
 		 * actually populated at the present time.
 		 */
 
-		apb2_ser3_base =
-			ioremap(APB2_SER3_PHY_ADDR, APB2_SER3_ADDR_SIZE);
+		apb2_ser3_base = ioremap(APB2_SER3_PHY_ADDR,
+					 APB2_SER3_ADDR_SIZE);
 
 		for (i = 0; i < NR_CPUS; i++) {
 			/* check if this is a possible CPU and
-			   it is within max_cpus range */
+			 * it is within max_cpus range */
 			if ((cpu_possible(i)) &&
-			    (cpu_count < max_cpus) &&
+				(cpu_count < max_cpus) &&
 			    (0 != release_addr[i])) {
 				set_cpu_present(cpu_count, true);
 				cpu_count++;
 			}
 
-			/* Release all physical cpu:s since we might want to
-			 * bring them online later. Also we need to get the
-			 * execution into kernel code (it's currently executing
-			 * in u-boot).
-			 */
-			phys_cpu = cpu_logical_map(i);
-
-			if (phys_cpu != 0) {
-				resetVal = readl(apb2_ser3_base + 0x1010);
-				writel(0xab, apb2_ser3_base+0x1000);
-				resetVal &= ~(1 << phys_cpu);
-				writel(resetVal, apb2_ser3_base+0x1010);
-				udelay(1000);
+			if (!is_hyp_mode_available()) {
+				/*
+				 * Release all physical cpus when not in hyp
+				 * mode since we might want to bring them
+				 * online later.
+				 *
+				 * Also we need to get the execution into
+				 * kernel code (it's currently executing in
+				 * u-boot).  u-boot releases the cores from
+				 * reset in hyp mode.
+				 */
+				phys_cpu = cpu_logical_map(i);
+
+				if (phys_cpu != 0) {
+					resetVal = readl(apb2_ser3_base +
+							 0x1010);
+					writel(0xab, apb2_ser3_base+0x1000);
+					resetVal &= ~(1 << phys_cpu);
+					writel(resetVal, apb2_ser3_base+0x1010);
+					udelay(1000);
+				}
 			}
 		}
 
@@ -259,7 +262,8 @@ platform_smp_prepare_cpus(unsigned int max_cpus)
 				*vrel_addr =
 					virt_to_phys(axxia_secondary_startup);
 				smp_wmb();
-				__cpuc_flush_dcache_area(vrel_addr, sizeof(u32));
+				__cpuc_flush_dcache_area(vrel_addr,
+							 sizeof(u32));
 			}
 		}
 	} else if (of_find_compatible_node(NULL, NULL, "lsi,axm5516-sim")) {
@@ -277,7 +281,13 @@ platform_smp_prepare_cpus(unsigned int max_cpus)
 		__cpuc_flush_dcache_area((void *)phys_to_virt(0x10000020),
 					 sizeof(u32));
 	}
-
 	return;
 #endif
 }
+
+struct smp_operations axxia_smp_ops __initdata = {
+	.smp_init_cpus		= axxia_smp_init_cpus,
+	.smp_prepare_cpus	= axxia_smp_prepare_cpus,
+	.smp_secondary_init	= axxia_secondary_init,
+	.smp_boot_secondary	= axxia_boot_secondary,
+};
diff --git a/arch/arm/mach-axxia/timers.c b/arch/arm/mach-axxia/timers.c
index 17b0c73..77770c1 100644
--- a/arch/arm/mach-axxia/timers.c
+++ b/arch/arm/mach-axxia/timers.c
@@ -61,9 +61,8 @@ axxia_timer_set_mode(enum clock_event_mode mode, struct clock_event_device *evt)
 	struct axxia_timer *timer = timer_to_clock_event(evt);
 	unsigned long ctrl = TIMER_CTRL_32BIT | TIMER_CTRL_IE;
 
-	printk(KERN_INFO
-	       "axxia_timer_set_mode: CPU#%d set mode %d on timer %s\n",
-	       smp_processor_id(), mode, timer->dev.name);
+	pr_info("axxia_timer_set_mode: CPU#%d set mode %d on timer %s\n",
+		smp_processor_id(), mode, timer->dev.name);
 
 	writel(ctrl, timer->base + TIMER_CTRL);
 
@@ -200,7 +199,7 @@ axxia_timer_clockevents_init(void __iomem *base,
 	if (WARN_ON(rate < 0))
 		return;
 
-	evt = kzalloc(sizeof *evt, GFP_KERNEL);
+	evt = kzalloc(sizeof(*evt), GFP_KERNEL);
 	if (evt == NULL)
 		return;
 
diff --git a/arch/arm/mach-axxia/wrappers.c b/arch/arm/mach-axxia/wrappers.c
index be5c4b0..dd25901 100644
--- a/arch/arm/mach-axxia/wrappers.c
+++ b/arch/arm/mach-axxia/wrappers.c
@@ -50,7 +50,6 @@ acp_mdio_read(unsigned long address, unsigned long offset,
 {
 	return 0;
 }
-
 EXPORT_SYMBOL(acp_mdio_read);
 
 /*
@@ -64,7 +63,6 @@ acp_mdio_write(unsigned long address, unsigned long offset,
 {
 	return 0;
 }
-
 EXPORT_SYMBOL(acp_mdio_write);
 
 #endif	/* CONFIG_ARCH_AXXIA_SIM */
@@ -164,7 +162,7 @@ EXPORT_SYMBOL(acp_irq_create_mapping);
 int __init
 acp_wrappers_init(void)
 {
-	printk(KERN_INFO "Initializing Axxia Wrappers.\n");
+	pr_info("Initializing Axxia Wrappers.\n");
 
 	return 0;
 }
-- 
1.7.5.4

