diff --git a/drivers/scsi/aacraid/CHANGELOG b/drivers/scsi/aacraid/CHANGELOG
new file mode 100644
index 0000000..514efe0
--- /dev/null
+++ b/drivers/scsi/aacraid/CHANGELOG
@@ -0,0 +1,5122 @@
+Aacraid (ARC) Linux driver release notes. Ascending (chronological) order
+comments. Modifications performed by Mark_Salyzyn@adaptec.com and 
+Achim_Leubner@adaptec.com if not otherwise noted. 
+Document created 2003-05-15 at Version 0.9.10.
+
+Streams support otc-main, avonpark and enzo
+
+Version: 0.9.10
+
+Version: 1.1.2
+
+2003-05-15	Mark_Salyzyn@adaptec.com
+
+Differences between 2.4.21-rc2-ac2 kernel and our 1.1.2 versioned driver,
+changes as performed by Deanna Bonds, Bob Pasteur and Mark Salyzyn.
+
+aachba.c:
+	- If the state of a logical unit is hidden, then do not report. This
+	  state is typically entered when a device is being cleared.
+	- Added support for the Tallahassee project, where one channel is
+	  dedicated to SCSI, and the other channel is dedicated to RAID.
+	- Resolved some issues surrounding PAE support and IA64.
+	- If the driver is a not a boot disk driver, then set the Removable
+	  bit on the inquiry strings returned by the logical units to ensure
+	  that any changes in the arrays will be acquired when the device is
+	  re-attached.
+	- mask the SRB status with 0x3F to deal with misbehaving devices.
+	- Do not report DISKs to inquiry requests on the SCSI bus except if
+	  the channel is designated as a SCSI only bus.
+	- Propagate check conditions to the SCSI command result.
+	- Add support for programmable timeouts to propagate down toe the
+	  requests.
+	- If we have pae mode enabled, right after we get the adapter
+	  information and determine the pae mode capability, we enable the
+	  system to issue 64 bit requests.
+aacraid.h:
+	- Had to drop from 512 commands to 100 commands because some versions
+	  of the firmware would starve commands causing a timeout reaction
+	  which lead to lost commands.
+	- Added a global control variable for nondasd and paemode support.
+	- Dealt with some 64 bit / 32 bit issues in list_head structures and
+	  helper Macros, replacing them with our own more sensitive variants.
+	- Differentiated virtual and physical references to the shared fib
+	  allocations.
+	- information structure not synchronized to firmware, needed to add
+	  a clusterchannelmask.
+	- Added definitions in support of the new configuration information
+	  page bits in support of Tallahassee.
+	- Changed to an allocated fib pool, rather than an array in the hba
+	  structure as this affected the SCSI memory pool.
+	- Added some AIF definitions to permit us to sniff for container
+	  changes to permit a rescan to pick up new information or targets.
+commctrl.c:
+	- The fib reference was changed to a physical and a virtual address,
+	  absorb the name changes.
+	- The list_head structure handlers have been replaced with our own,
+	  absorb the name changes.
+	- The fib address reported in an AIF is a physical (32 bit) reference,
+	  and not a virtual (possibly 64 bit) reference.
+	- added the ioctl handling for sending a raw srb (FSACTL_SEND_RAW_SRB).
+comminit.c:
+	- Deal with IA64 issues.
+	- Change to using the physical address (32 bit) for the AIF references.
+	- The list_head structure handlers have been replaced with our own,
+	  absorb the name changes.
+	- Observed a memory leak, free up the queue resources should we fail
+	  to initialize the adapter.
+commsup.c:
+	- The fib reference was changed to a physical and a virtual address,
+	  absorb the name changes.
+	- Instead of panicking the kernel when a fib allocation was available,
+	  sleep until it is available.
+	- Submitted fib pointers are physical (32 bit) rather than virtual
+	  (possibly 64 bit) values.
+	- producer and consumer indexes should be converted over to local
+	  cpu endian before comparison.
+	- aac_handle_aif now sniffs AIF events and takes plug and play action
+	  for container changes.
+	- The aif thread is set up to be a kernel thread, and not a user
+	  thread. This permits us the ability to make plug and play calls
+	  without prejudice.
+	- Added instrumentation to the aif thread to confirm the plug and
+	  play activity and as an aid to several other debug sessions.
+	- Do not age an aif context based on the last received aif, but rather
+	  the last poll.
+dpcsup.c:
+	- The fib reference was changed to a physical and a virtual address,
+	  absorb the name changes.
+	- Submitted fib pointers are physical (32 bit) rather than virtual
+	  (possibly 64 bit) values.
+linit.c:
+	- Added paemode control.
+	- Added various upcoming board products, and documented better the
+	  existing board product ids. This includes SATA RAID products.
+	- needed to take the io_request_lock during portions of initialization.
+	- allocate the fib resource separately, rather than part of adapter
+	  structure to aid in the precious SCSI resources.
+	- cleanup of none dasd support options.
+	- Added more details about the build date of the driver to the proc
+	  information.
+	- dropped a change that permitted 64 bit DMA resources to be generated
+	  instead of through a 32 bit bounce buffer. (it was moved to aachba.c
+	  where it can be turned on after we determine the adapter's
+	  capabilities).
+	- max_id, max_lun and max_channel parameters are set after the
+	  adapter information has been picked up (the number of channels is
+	  based on the product id table now).
+sa.c:
+	- Context of timeout handling was incorrect, only noticed in IA64
+	  bit machines (due to lack of BIOS initialization).
+
+Differences that need further investigation and could be viewed as regressions
+and added after submission:
+
+rx.c:
+	- Dropped detection of failure to generate kernel command thread.
+sa.c:
+	- Dropped detection of failure to generate kernel command thread.
+
+Version: 1.1.3
+
+2003-07-01	Mark_Salyzyn@adaptec.com
+
+aachba.c:
+	- Added aac_get_container_name to permit override of array inquiry
+	  string with the set name.
+
+2003-07-08	Mark_Salyzyn@adaptec.com
+
+aachba.c:
+	- Return 0 (success) for unsupported commands, the check condition
+	  should perform the necessary action of error handling.
+
+2003-07-10	Mark_Salyzyn@adaptec.com
+
+aachba.c:
+	- The pass-through SCSI SCB command in PAE mode was getting the fib
+	  size count wrong, by using the 32 bit command, then doing an (n-1)
+	  times the size of the 64 bit scatter gather. Resolution was to
+	  subtract the 32 bit scatter gather, then do an n times the 64 scatter
+	  gather size.
+	- Only go into PAE mode if more than 4MB of memory in the system.
+
+2003-07-10	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- Added `Family' product codes and reordered the product discovery code
+	  to produce devices in PCI order rather than in product order.
+	  Dell, Legend and Adaptec Families were produced with the assumption
+	  of 2 available busses.
+
+2003-07-24	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- Added Bearcat (6 ch SATA) and a commented entry for Lancer where
+	  future workarounds may be necessary due to hardware constraints.
+	- Set highmem_io (for kernels of 2.4.18 and above).
+
+aachba.c:
+	- Set highmem_io (for kernels of 2.4.18 and above; and when the
+	  adapter is guaranteed to handle the possible address ranges it
+	  will be provided).
+
+Version: 1.1.4:
+
+2003-07-28	Mark_Salyzyn@adaptec.com
+
+aacraid.h+common/include/fsaioctl.h+aachba.c
+	- Added the FSACTL_REGISTER_FIB_SEND function to the ioctl. This ioctl
+	  is *not* a user accessible ioctl, meant only for driver use to permit
+	  stacking a filter driver just ahead of the hardware layer. The call
+	  to register is:
+
+		typedef void (*fib_callback)(void *ctxt, struct fib *fibctx);
+		typedef struct {
+			int (*fib_send)(u16 command,
+					struct fib * context,
+					unsigned long fib_size,
+					int priority,
+					int wait,
+					int reply
+					fib_callback callback,
+					void * ctxt);
+		} fib_send_t;
+		. . .
+		fib_send_t original;
+		int dummy_fib_send (u16 command,
+				    struct fib * context,
+				    unsigned long fib_size,
+				    int priority,
+				    int wait,
+				    int reply
+				    fib_callback callback,
+				    void * ctxt)
+		{
+			return (*original->fib_send)(command, context, fib_size, priority, wait, reply, callback, ctxt);
+		}
+		. . .
+		Scsi_Host_Template * host;
+		Scsi_Device * adapter;
+		original->fib_send = dummy_fib_send;
+		host->ioctl(adapter, FSACTL_REGISTER_FIB_SEND, &original);
+
+	  Return value from the ioctl include ENOTTY (not supported), EINVAL
+	  (invalid argument pointer) and EBUSY (another function already
+	  registered) and the original fib_send function is returned in the
+	  ioctl argument structure. A NULL value for the fib_send member of the
+	  structure deregisters the filter driver. The fib_callback function is
+	  issued at interrupt priority and should follow all the constraints of
+	  interrupt operation. It is the responsibility of the registered
+	  fib_send function to ensure that the original fib_callback function
+	  is called with the ctxt value when completing the command (this
+	  subtlety is lost in the above dummy function).
+
+2003-07-28	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- Added Kernel, Firmware and BIOS revision and build number to proc
+	  information.
+	- Added board serial number to proc information.
+
+aachba.c:
+	- Do not set removable bit in the inquiry command, the aif delivery
+	  of array status change will handle the reasons for the removable
+	  bit (capacity change and differences in the partition table). Some
+	  customers take issue with the fact our arrays appear as removable.
+
+commctrl.c:
+	- Reported driver version and build number instead of Firmware version
+	  and build number for the Miniport Version Check ioctl. ADPmp57715
+
+2003-08-06	Mark_Salyzyn@adaptec.com and a cast of thousands
+
+all files:
+	- Added appropriate ifdefs, or merged in additions, in support of the
+	  2.6.0-test2 kernels as follows:
+
+Makefile:
+	- Added ifdefs for 2.4 and 2.6 kernels so we can use a common Makefile
+	  for both kernel build environments.
+
+aachba.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+	- define aac_spin_* macros to differentiate between lock requirements
+	  in 2.5+ and 2.4 kernels.
+	- Use the SCSI layers definitions of the SCSI commands, rather than
+	  our own internal SS_* manifests.
+	- Define SCSICMD_TO_* macros to acquire the SCSI target host, channel,
+	  id and lun.
+	- Use the 2.6 SAM_* status codes for return, the 2.4 system will
+	  redefine the SAM_* codes to 2.4 variants.
+	- Change to devname instead of devno when referencing devices to
+	  simplify conversions.
+	- MAXIMUM_NUM_CONTAINERS references were +/- 1 in comparisons, made
+	  this value a `number' rather than a mix of `number' and `limit'.
+	- Resolved `Cast of pointer from integer of different size' by
+	  (void *)(ulong)dma_addr_t.
+	- Change to `id' rather than `target' to match SCSI subsystem
+	  references name for consistency.
+
+aacraid.h:
+	- MAXIMUM_NUM_CONTAINERS references were +/- 1 in comparisons, made
+	  this value a `number' rather than a mix of `number' and `limit'.
+	- Removed AAC_MAX_TARGET, as it is no longer used.
+	- Added CONTAINER_TO_* macros to simplify references.
+	- Change to `id' rather than `target' to match SCSI subsystem
+	  references name for consistency.
+	- Change to devname instead of devno when referencing devices.
+	- Use cap_to_cyls inline to handle 64 bit calculation correctly.
+
+commctrl.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+	- Change to `id' rather than `target' to match SCSI subsystem
+	  references name for consistency.
+
+comminit.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+
+commsup.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+	- Moved CONTAINER_TO_* macros to aacraid.h to simplify references.
+	- Device Discovery loops are different for 2.4 and 2.5+ kernels,
+	  use list_for_each_entry siblings instead of host_queue loop.
+	- daemonize adds the process name as a parameter, and requires
+	  SIGKILL to be enabled to permit kernel shutdown in 2.5+ kernels.
+
+dpcsup.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+
+linit.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+	- added aacids to provide a table hint for installers.
+	- changed over to utilize ANSI structure initialization.
+	- aac_biosparm and aac_procinfo change parameters in 2.5+ kernels.
+	- aac_slave_configure replaces aac_queuedepth in 2.5+ kernels.
+	- detect no longer needs to unlock io_request_lock to do it's duty
+	  in 2.5+ kernels.
+	- use SCSI_set_device in 2.5+ kernels rather than scsi_set_pci_device.
+	- Change to devname instead of devno when referencing devices to
+	  simplify conversions.
+	- Use MAXIMUM_NUM_CONTAINERS rather than AAC_MAX_TARGET
+	- Use cap_to_cyls inline to handle 64 bit calculation correctly in
+	  aac_biosparm.
+	- Use minor in 2.5+ kernels instead of MINOR macro.
+
+rx.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+	- interrupts now return irqreturn_t.
+
+sa.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+	- interrupts now return irqreturn_t.
+
+2003-08-15	Mark_Salyzyn@adaptec.com
+
+install.sh:
+	- increased range of kernel version reports in the magic file to 30.
+
+2003-08-19	Mark_Salyzyn@adaptec.com & ijohns@elipsan.com
+
+aachba.c:
+	- status_byte in the result is shifted down by one.
+	- set_sense spoof was not immediately followed by a copy of the check
+	  condition results into the SCSI command.
+
+2003-08-20	Mark_Salyzyn@adaptec.com, Scott_Long@adaptec.com & Alan Cox
+
+commctrl.c:
+	- The raw SCSI SCB ioctl command in PAE mode was getting the fib
+	  size count wrong, by using the 32 bit command, then doing an (n-1)
+	  times the size of the 64 bit scatter gather. Resolution was to
+	  subtract the 32 bit scatter gather, then do an n times the 64 scatter
+	  gather size.
+
+aacraid.h:
+	- Added definition of CT_FLUSH_CACHE command and structures.
+	- Added AAC_QUIRK_31BIT for ROMB based adapters.
+
+linit.c:
+	- Added AAC_QUIRK_31BIT for ROMB based adapters.
+	- Check return from scsi_register.
+
+aachba.c:
+	- Added support for issuing CT_FLUSH_CACHE command when the SCSI
+	  SYNCHRONIZE command is issued to a container.
+	- Restored mask after adding AAC_QUIRK_31BIT for ROMB based adapters.
+
+2003-08-21	Mark_Salyzyn@adaptec.com
+
+aachba.c:
+	- Changed aac_get_container_name to be a none-blocking function,
+	  completing the incoming scsicmd with the adapter response.
+
+2003-08-26	Mark_Salyzyn@adaptec.com
+
+commsup.c + aacraid.h:
+	- Altered handling of AIF messages from Firmware to differentiate
+	  events in a finer grained manner.
+
+2003-08-29	Mark_Salyzyn@adaptec.com
+
+aachba.c + aacraid.h
+	- Driver too noisy, undefined AAC_DETAILD_STATUS_INFO and incorporated
+	  check condition report into the AAC_DETAILED_STATUS_INFO ifdef.
+
+2003-09-03	Mark_Salyzyn@adaptec.com
+
+aachba.c:
+	- Check if the device is in use and report that as a locked device
+	  to both the FSACTL_QUERY_DISK and FSACTL_DELETE_ARRAY ioctls.
+	- unlock/lock around probe_container as this is a blocking function.
+	  This change addresses a deadlock issue that surfaced in SMP only
+	  environments.
+
+Version: 1.1.4-2172
+
+2003-09-04	Mark_Salyzyn@adaptec.com
+
+commsup.c:
+	- References to the Status Job update structure were at incorrect
+	  offsets causing incorrect operation during an Array Clear with
+	  regards to plug and play actions.
+
+Version: 1.1.4-2177
+
+2003-09-05	Mark_Salyzyn@adaptec.com
+
+aachba.c:
+	- Cleanup request from the SCSI list maintainers.
+	- Dropped use of SCSICMD_TO_CHANNEL & friends since
+	  scsicmd->device->channel is available in all versions of the
+	  operating system.
+	- Removed deprecated code and/or comments related to deprecation.
+	- include <linux/blkdev.h> works in all versions of the operating
+	  system.
+
+2003-09-09	Mark_Salyzyn@adaptec.com
+
+aacraid.h:
+	- NUM_FIBs should be 64 larger (AIFS) larger than the NUM_IO_FIBS.
+
+commsup.c:
+	- efficiency improved if we hold on to the aac_queue variable, aims
+	  towards better code compliance and consistency.
+
+2003-09-15	Mark_Salyzyn@adaptec.com
+
+rkt.c:
+	- Copy if rx.c with rx = rkt
+
+aacraid.h:
+	- Added definition for rkt interface structures, copy of rx, but a
+	  larger reserved region.
+
+linit.c:
+	- Added product code for ROC (Lancer/Rocket) U320 two channel, use rkt
+	  interface.
+
+2003-09-16	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- Show Adapter vendor and model in proc information.
+
+Version: 1.1.4-2185
+
+2003-09-16	Mark_Salyzyn@adaptec.com
+
+aacraid.h:
+	- Added definition of nblank() to assist us in determining if
+	  dprintk(x) is defined as a blank definition to enable us to ifdef
+	  debug code that ends up calling only dprintk functions.
+
+commsup.c:
+	- Ignore events that refer to containers > MAXIMUM_NUM_CONTAINERS
+	- include <linux/blkdev.h> works in all versions of the operating
+	  system.
+
+linit.c:
+	- print more details about outstanding commands when a SCSI hang
+	  occurs (first use of nblank() macro just defined in aacraid.h)
+
+2003-09-19	Mark_Salyzyn@adaptec.com & Mark Haverkamp <markh@osdi.org>
+
+commsup.c & aachba.c:
+	- valid flag has added support for a value of 2, which means target
+	  is still valid, but needs a probe_container.
+
+commsup.c:
+	- fib_alloc should not go to sleep, but return NULL if there are no
+	  available entries in the pool.
+
+dpcsup.c:
+	- print a message if the fib kmalloc fails when forwarding AIFs
+
+comminit.c:
+	- check fib_alloc return, and report -ENOMEM should the pool be
+	  empty.
+
+aachba.c:
+	- Check value of scsicmd->scsi_done in aac_io_done as we can get
+	  errant firmware which returns commands twice (no released firmware
+	  does this, this is a driver hardening issue only).
+	- When a fib_alloc fails, return -1 to SCSI layer. Formerly, we would
+	  send the command with DID_ERROR.
+
+Version: 1.1.4-2192
+
+2003-09-25	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- Moved debug variables into block to reduce impact on none-debug
+	  environments.
+
+dpcsup.c + commsup.c:
+	- Use the fib pool instead of a kmalloc to allocate a fib for the
+	  processing of an AIF.
+
+install.sh:
+	- Install driver into any forgotten /lib/modules directories.
+
+2003-09-26	Mark_Salyzyn@adaptec.com
+
+commctrl.c + aacraid.h:
+	- AMD-64 and IA-64 management applications will fail, need to change
+	  fibctx to a 32 bit unique value.
+
+Version: 1.1.4-2194
+
+2003-09-29	Mark_Salyzyn@adaptec.com & Mark Haverkamp <markh@osdi.org>
+
+aachba.c:
+	- use linux/blkdev.h for all variants on Linux.
+	- hold on to the host pointer in aac_io_done, because it's reference
+	  in the device and scsicmd can go away after scsi_done is called.
+	- check return value of pci_set_dma_mask.
+
+commctrl.c:
+	- use linux/blkdev.h for all variants on Linux.
+
+comminit.c:
+	- use linux/blkdev.h for all variants on Linux.
+
+commsup.c:
+	- use linux/blkdev.h for all variants on Linux.
+	- drop linux/smp_lock.h include as it was added in a debug test from
+	  some time ago.
+	- Added current 2.6 kernel support routines for rescanning.
+
+dpcsup.c:
+	- use linux/blkdev.h for all variants on Linux.
+
+linit.c:
+	- use linux/blkdev.h for all variants on Linux.
+	- check return value of pci_set_dma_mask.
+	- template->present is no longer relevant in 2.6 based kernels.
+
+rx.c:
+	- use linux/blkdev.h for all variants on Linux.
+
+sa.c:
+	- use linux/blkdev.h for all variants on Linux.
+
+rkt.c:
+	- use linux/blkdev.h for all variants on Linux.
+
+2003-10-01	Mark_Salyzyn@adaptec.com
+
+commsup.c:
+	- needed a fib_dealloc call ahead of the fib_free call added when
+	  we moved over to the fib pool to handle the AIFs.
+
+dpcsup.c:
+	- need to use the `local' fibctx so that the AIF command can be
+	  acknowledged.
+
+commctrl.c:
+	- return error status from the send_fib function in ioctl_send_fib.
+
+2003-10-07	Mark_Salyzyn@adaptec.com
+
+aachba.c + linit.c:
+	- serial number contains the cookie (fafa0001) that is at index 1
+	  of the serial number element. Only show the serial number which
+	  is at index 0.
+
+linit.c:
+	- Added registration to receive 32 bit ioctls.
+
+commsup.c + dpcsup.c + aacraid.h:
+	- Dropped code to acquire AIF's from the general FIB pool, it was a
+	  fool's errand. However, we kept the code that limits the AIF's
+	  received and allocated to the AdapterFibsSize / sizeof(hw_fib).
+	  The `last' AIF hw_fib is used to quickly acknowledge the entries,
+	  and drop the results on the floor.
+
+rx.c + rkt.c:
+	- Cache the OIMR data in dev->OIMR, it looks remarkably like irq_mask,
+	  which is really unused, but we can clean that up later.
+
+2003-10-08	Matthew Wilcox <willy@debian.org>
+
+aachba.c:
+	- Use SCp.dma_handle instead of SCp.ptr for holding on to the physical
+	  address of the allocated pci_map_single as part of the request.
+
+compat.h:
+	- define dma_handle to be ptr (in support of SCp.dma_handle change
+	  above) for kernels that do not define this member.
+
+2003-10-08	Christoph Hellwig <hch@infradead.org>
+
+aachba.c:
+	- drop use of scsi_to_pci_dma_dir() as it is a pass-through in all
+	  versions of the kernel.
+
+2003-10-09	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- When an Adapter Reset is requested, wait up to 60 seconds for all
+	  outstanding commands to complete and report SUCCESS.
+
+Version: 1.1.4-2221
+
+2003-10-09	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- Waited for *all* commands to complete for *all* devices on the
+	  controller when an Adapter Reset is requested.
+
+Version: 1.1.4-2222
+
+2003-10-10	Mark_Salyzyn@adaptec.com
+
+aacraid.h + rx.c + rkt.c + sa.c + linit.c:
+	- Added a aac_adapter_check_health, make sure the adapter is healthy
+	  when performing and Adapter Reset request, report error codes.
+
+aachba.c:
+	- revert to use of scsi_to_pci_dma_dir() as it is not a pass-through in
+	  all versions of the kernel.
+
+linit.c:
+	- SCSI_HAS_HOST_LOCK means that we should be working with releasing
+	  host->lock or host->host_lock instead of io_request_lock surrounding
+	  scsi_sleep.
+
+aacraid.h:
+	- Added definition for AAC_MAX_HOSTPHYSMEMPAGES
+
+comminit.c:
+	- Utilized AAC_MAX_HOSTPHYSMEMPAGES to limit the number of open DMA
+	  4096 byte PAGES of memory requested by the operating system.
+
+2003-10-16	Mark_Salyzyn@adaptec.com
+
+install.sh:
+	- Added support for x86_64 installs
+
+aachba.c:
+	- used SENSE KEYS from scsi.h rather than our own definitions.
+
+2003-10-20	Xose Vazquez Perez <xose@wanadoo.es>
+
+linit.c:
+	- Added pci_ids for 0x10110046/0x90050365
+
+Version: 1.1.4-2265
+
+2003-10-23	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- no need to set template->present as this is done by the SCSI layer.
+
+2003-10-24	Mark_Salyzyn@adaptec.com
+
+install.sh
+	- Added support for SuSE kernel determination for finer selection
+	  of modules
+	- If the kernel is compiled for athlon, use that instead of
+	  /proc/cpuinfo
+	- if /proc/cpuinfo is not present, don't show any errors during
+	  install
+
+2003-10-28	Mark_Salyzyn@adaptec.com
+
+install.sh
+	- The entire class of SuSE OS releases (sles7, sles8, suse7, suse8,
+	  suse8.1, suse8.2, ul1, ul1-sp2a) place the driver module results into
+	  /lib/modules/[kernel]/kernel/drivers/scsi/aacraid/aacraid.o. The
+	  package places updates in ...//scsi/aacraid.o (note, one directory
+	  up). The module selected for use in the mkinitrd is fed via a `find'
+	  command which reports files in raw directory order which in the
+	  reiser file system would be in the .../scsi directory, but for EXT2
+	  since the file was added later, would prefer the previously placed
+	  product in ../scsi/aacraid/aacraid.o. The fix is to have the driver
+	  disk post-install remove the older .../scsi/aacraid directory.
+
+2003-10-30	Mark_Salyzyn@adaptec.com
+
+install.sh
+	- For the installations to `extra' /lib/modules directories beyond
+	  the boot set, take the processor clue from the postscript (-athlon,
+	  -x86_64 or -ia64) rather than from /proc/cpuinfo.
+
+Version: 1.1.4-2282
+Version: 1.1.4-2292 (Debug)
+
+2003-10-31	Mark_Salyzyn@adaptec.com
+
+aacraid.h + aachba.c:
+	- Added a nested count to the fsa_scsi_dev structure since some kernels
+	  before 2.4.19 have troubles overflowing their stack when a device
+	  goes offline. The issue is that the SCSI done call nests into sending
+	  another queued command, which in turn spoofs a response back
+	  indicating failure which in turn calls SCSI done. We limit the
+	  nesting to 64 commands before we respond with a busy instead.
+
+Version: 1.1.4-2296 (Debug)
+
+linit.c & .version:
+	- Versioning is defined by the structure:
+	    struct {
+		unsigned char dash; // Dash version number
+		unsigned char type; // Type, 1=Devo, 2=Alpha, 3=Beta, 4=Release
+		unsigned char minor;// Minor version minor
+		unsigned char major;// Major version number
+	    }
+	  Adjusted version data to match this definition for generation and
+	  support.
+
+Version: 1.1.4-2299
+Version: 1.1.4-2301
+Version: 1.1.4-2302
+Version: 1.1.4-2303
+
+linit.c & aacraid.h:
+	- Allow 64 bit apps to call GET_NEXT_ADAPTER_FIB ioctl directly,
+	  promoting 32 bit apps when they call.
+
+aachba.c & aacraid.h:
+	- Set MAX_NESTED to 1, and improve code to reflect this simplicity.
+
+install.sh:
+	- Handle name change of products from *-athlon-athlon to *-athlon.
+	- Warn the user if the initrd shrinks too much
+
+Version: 1.1.4-2308
+
+install.sh:
+	- Add support for identifying 2.4.19-340 kernels.
+
+2003-12-12	Mark Haverkamp <markh@osdl.org>
+
+linit.c:
+	- updated aac_eh_reset to use __shost_for_each_device now that the
+	  device element is now private and we're supposed to use the helper
+	  function for access.
+
+Version: 1.1.4-2309
+Version: 1.1.4-2310 (debug)
+
+2003-12-18	Mark Salyzyn <Mark_Salyzyn@adaptec.com>
+
+linit.c:
+	- suppress unused variable warning in debug code.
+	- cast sys_ioctl when registering as it does not match prototype
+	  argument for ioctl32 registration.
+
+Version: 1.1.4-2311
+
+2003-12-22	Mark Haverkamp <markh@osdl.org>
+
+aachba.c:
+	- change from pae to dac as this is the more public understanding of
+	  the 64 bit support concepts.
+aacraid.h:
+	- Remove padding and SavedIrql
+commsup.c + aachba.c:
+	- use atomic_read when accessing access_count member of device
+	  structure.
+linit.c & aacraid.h
+	- iminor takes the inode, not the inode->i_rdev member.
+
+Version: 1.1.4-2313
+
+aachba.c + commsup.c:
+	- use device_busy, shost_status, in_recovery instead of just
+	  access_count. Adjust for each OS release variant.
+
+Version: 1.1.4-2314
+
+2003-12-22: Ken Beaty <ken@nova.org>
+
+aachba.c + commsup.c:
+	- Adjusted ifdefs for kernel version to make more sense.
+
+2004-01-24: Mark Salyzyn <Mark_Salyzyn@adaptec.com>
+
+install.sh:
+	- Altered script to discover prebuilt binaries from the classic
+	  Adaptec rpm package, the Red Hat install disk format, or the
+	  SuSE install disk format.
+
+2004-02-09: Christoph Hellwig <hch@lst.de>
+
+aachba.c:
+	- Remove fsa_dev structure since fsa_dev is always available.
+
+Version: 1.1.4-2324
+
+2004-02-10: Submit to scsi list for inclusion
+
+2004-02-17: Herve MORILLON <hmorillon@doremilabs.fr> + Mark_Salyzyn@adaptec.com
+
+rx.c + rkt.c:
+	- hit doorbell before processing host_command_normal
+
+aachba.c:
+	- Permit requests larger than 64KB
+
+aacraid.h:
+	- Permit 512 outstanding requests
+
+Version: 1.1.5-2326
+
+linit.c + build:
+	- Added support for vary_io, unfortunately the build system also needed
+	  to be adjusted to generate the SCSI_HAS_VARY_IO if the member is
+	  seen in the drivers/scsi/hosts.h file.
+
+build + install.sh:
+	- Added support for 2.4.19-189, 2.4.19-191 and 2.4.19-201 SuSE Kernels
+
+Version: 1.1.5-2327
+
+rkt.c + rx.c:
+	- Added support to issue the Temperature sync command. Since the
+	  cost of the sync command should not increase, the decision was
+	  made to support a `varargs' approach to dealing with the additional
+	  temperature elements *only* for this command.
+
+linit.c:
+	- Added a proc write that accepts the string "Temperature=[0-9.],..."
+	  to send the off-board temperature value to the Firmware so that it
+	  may be integrated into the Enclosure Data.
+	- Added SkyHawk SATA cards to device list. 2020S changes now to 
+	  2020ZCR, and we add 2020SA.
+
+aachba.c:
+	- PERCRAID RAID-5 is superfluous, changed to to PERC RAID-5.
+
+Version: 1.1.5-2328
+
+linit.c + aacraid.h:
+	- Migrate towards using CONFIG_COMPAT instead of __x86_64__
+
+rx.c + rkt.c:
+	- Added support to pick up an Adapter Blink code. ADPmp64499.
+
+linit.c:
+	- Report the Adapter Blink code to the console log. ADPmp64499.
+
+build:
+	- Correctly built the x86_64 SLES8 and ul1 driver disk. Side effects
+	  discovered also fix problems with ia32 SLES8 install. ADPmp64499.
+
+Version: 1.1.5-2329
+
+linit.c + aacraid.h:
+	- Report an AifExeFirmwarePanic AIF message to applications when the
+	  adapter is in a blinkled state.
+
+aachba.c + commsup.c: Brad House <brad@mainstreetsoftworks.com>
+	- use shost_for_each_device instead of list_for_each_entry.
+
+linit.c + aachba.c:
+	- xscale (arm) systems can not have highmem_io set as virtual/phys
+	  handling does not recognize the page/offset addressing.
+
+rkt.c + rx.c:
+	- The Mailbox[7] in none BBS systems is not active until shortly
+	  before the Firmware kernel is booted. The Outbound Message register
+	  is always active and contains the same bringup conditions. We must
+	  look at the OMR during the *_init wait.
+
+Version: 1.1.5-2330
+
+rkt.c + rx.c + sa.c:
+	- Set the time by using get_seconds (epoch January 1 1970) instead
+	  of jiffies/HZ (epoch machine startup). get_seconds is provided
+	  for kernels < 2.6.
+
+Version: 1.1.5-2331
+
+rkt.c:
+	- Mailbox[7] becomes momentarily inaccessible right after PATUWAIT
+	  on the Callisto, lets loop on OMR only. Do not know if this
+	  problem exists on other systems.
+
+Version: 1.1.5-2332
+
+aachba.c + linit.c:
+	- Issue CT_COMMIT_CONFIG before issuing the VM_NameServe. This is
+	  for systems that do not have a BIOS to perform this step.
+
+Version: 1.1.5-2333
+
+aacraid.h:
+	- SAS requires the ability to handle as many as 32 Adapters in a
+	  system, increased the manifest that limits the number of Adapters.
+	- Testing has shown that allowing 33MB I/O can starve a machine, so
+	  we are limiting the maximum I/O size to 4MB (to match other drivers
+	  that permit large I/O).
+
+linit.c:
+	- Make sure that the driver does not register more than
+	  AAC_MAXIMUM_ADAPTERS instances.
+	- Set the queue depth to each device as divided up from AAC_MAX_IO_FIB
+
+commctrl.c: Chris Wright <chrisw@osdl.org>
+	- aac_send_raw_srb added check for bounding of fibsize value.
+
+all: Mark Haverkamp <markh@osdl.org> & Mark Salyzyn <Mark_Salyzyn@adaptec.com>
+	- merge 2.6 driver changes into tree to synchronize.
+
+Version: 1.1.5-2334
+
+aacraid.h+linit.c+commctrl.c+comminit.c:
+	- Added sg_tablesize and max_fib_size to adapter structure and
+	  negotiate these plus Scsi_Host sg_tablesize, can_queue and
+	  max_sectors based on the adapter capabilities.
+
+aachba.c:
+	- Added aac_raw_io command
+	- Recognize that read_callback is identical to write_callback, which
+	  is in turn identical to raw_io's need for a callback. Renamed to
+	  one callback function io_callback.
+
+rx.c+rkt.c+sa.c:
+	- Moved initialization around to permit New Command Interface probes
+	- dropped irq_mask and associated functions.
+	- moved acknowledgement of F/W commands *before* processing so that
+	  we get re-interrupted if a new command is added to the produced
+	  index while we are processing.
+
+linit.c+aachba.c:
+	- Do not print `bad0' for the serial number
+
+linit.c:
+	- this_id = 32, because it gets in the way of Container 16 being
+	  processed.
+
+aachba.c:
+	- scsi_add_timer call issued just before completion routine called
+	  since error recovery handler is there *just* to detect card
+	  failure and not to affect command processing.
+
+build:
+	- Added 2.4.19.SuSE-343 kernel in support of ul1-sles8-ia32 install,
+	  which adds yet another installation floppy to the list.
+
+Version: 1.1.5-2335
+
+linit.c+all:
+	- Revert temporarily to 1.1.4-2177, Changed ASR-2020S to ASR-2020ZCR,
+	  and ASR-2020S Terminator to ASR-2025ZCR.
+
+Version: 1.1.4-2336
+
+linit.c+all:
+	- Revert temporarily to 1.1.4-2322, Changed ASR-2020S to ASR-2020ZCR,
+	  and ASR-2020S Terminator to ASR-2025ZCR.
+
+Version: 1.1.4-2337
+
+all:
+	- Revert back to 1.1.5 code base.
+
+commsup.c:
+	- Fix Irq Moderation code. A Misnomer, since this is really a PCI
+	  utilization moderation, interrupts are not recurring on F/W.
+
+comminit.c:
+	- Turn on Irq Moderation feature (Tentatively 30% reduction in Host
+	  CPU utilization)
+
+Version: 1.1.5-2337
+
+aacraid.h+commsup.c+dpcsup.c+comminit.c+rx.c:
+	- Added support for the new comm interface.
+
+linit.c:
+	- Added debug information to proc output
+
+Version: 1.1.5-2338
+
+commsup.c: Mark Haverkamp <markh@osdl.org>
+	- Added scsi/scsi_device.h, scsi/scsi_driver.h to include file set
+	- set removable to a value of 1, not to TRUE.
+
+aachba.c: Mark_Salyzyn@adaptec.com
+	- Switch to using max_fib_size rather than FIB_DATA_SIZE_IN_BYTES,
+	  this permits SAS management applications to send ioctl FIBs larger
+	  than 512 bytes in size to adapters that accept larger FIBs.
+	- Added support for SAI_READ_CAPACITY_16, READ_12, WRITE_12, READ_16
+	  and WRITE_16 commands.
+	- Played `tricks' with device_blocked and queue_depth fields in the
+	  scsi_device structure to meter the outstanding commands down when
+	  large sequential activity is detected.
+
+aacraid.h: Mark_Salyzyn@adaptec.com
+	- Remove unused definition of FIB_DATA_SIZE_IN_BYTES.
+
+linit.c:
+	- Setting the maximum number of I/O requests/device to a maximum of
+	  256 would act in the SCSI layer as only allocating to permit 1 I/O
+	  for each device.
+
+Version: 1.1.5-2339
+
+build: Mark_Salyzyn@adaptec.com
+	- Added support for 2.6.4-52 SuSE 9.1 Pro install
+	- Added support for multiple architectures for 2.4.21-15.EL RHEL3 QU2
+	  install.
+
+aacraid.h+aachba.c+linit.c: Mark Haverkamp <markh@osdl.org>
+	- Define 2131 as FSACTL_GET_CONTAINERS
+
+commctrl.c: Adam Manthei <amanthei@redhat.com>, Mark_Salyzyn@adaptec.com
+	- change all printk() to dprintk(()) as this is a user initiated
+	  call for aac_send_rw_srb & aac_get_pci_info.
+
+rx.c+rkt.c: Adam Manthei <amanthei@redhat.com>, Mark_Salyzyn@adaptec.com
+	- use pci_alloc_consistent/pci_free_consistent instead of an
+	  unchecked combination of kmalloc(,_GFP_DMA)/pci_map_single/
+	  pci_unmap_single/kfree.
+
+Version: 1.1.5-2340
+
+linit.c+commctrl.c: Mark Haverkamp <markh@osdl.org>
+	- adjust to reflect linux-scsi submission results
+
+aachba.c: Mark_Salyzyn@adaptec.com
+	- remove print for unhandled commands into a debug print. The
+	  unhandled commands are reported to the caller as unhandled, let
+	  the caller deal with this.
+
+rx.c+rkt.c+sa.c: maximilian attems <janitor@sternwelten.at>
+	- upon failure of the init routine, make sure that the registered
+	  interupt handler is deregistered.
+
+commsup.c:
+	- fib_adapter_complete is supposed to free the hw_fib and that is it,
+	  it tried to talk to hardware and caused a lockup.
+
+Version: 1.1.5-2341
+
+build:
+	- use aacraid.ko for 2.6 releases
+
+Version: 1.1.5-2342
+
+aachba.c: Mark_Salyzyn@adaptec.com
+	- added support for a module parameter 'commit=1' to enable COMMIT
+	  CONFIG to be issued to the adapter.
+	- added support for a module parameter 'coalescethreshold=16' which
+	  sets the maximum block size to consider for pushing back to the
+	  scsi_merge layer.
+	- added support for a module parameter 'acbsize=8192' which sets the
+	  suggested fib size to override the suggestion from Firmare.
+	- dropped call to scsi_add_timer, as it causes a panic. It was placed
+	  in the source to resolve a command completion race condition.
+
+Version: 1.1.5-2343
+
+install.sh: Mark_Salyzyn@adaptec.com
+	- globbing issue caused more whiny complaints about a missing
+	  installation into the initrd.
+	- fixed some issued surrounding using the script for SuSE module
+	  update.
+
+linit.c: Mark_Salyzyn@adaptec.com
+	- if the driver does not discover any targets, report failure.
+	- drop kernel_version hack to support build
+
+build: Mark_Salyzyn@adaptec.com
+	- Use vermagic instead of kernel_version to pick up matching kernel.
+	- when innoculating 2.6 tree builds, one needs a *full* compile in
+	  order to generate the struct_module member.
+	- use module.ko for 2.6 kernels.
+
+Version: 1.1.5-2344
+
+build: Mark_Salyzyn@adaptec.com
+	- floppy linux/suse/${ARCH}-${VERS}/modules/${PRODUCT}.o needs to be
+	  a ${PRODUCT}.ko in the 2.6 based installations.
+	- Placed module in both scsi and scsi/${PRODUCT} directories as it
+	  appears that the post-install is not functioning properly.
+
+aachba.c: Mark_Salyzyn@adaptec.com
+	- Checked if the lba exceeds 32 bit block address for systems that
+	  can not support it. raw_io_64 enables 64 bit block addresses.
+	- Redid math for u64 >> 32 as it appears the xscale 64 bit library
+	  is flawed.
+
+Version: 1.1.5-2345
+
+aachba.c: Mark_Salyzyn@adaptec.com
+	- Overrides to force 8KB fibs needs to be reverted to defaults.
+
+Version: 1.1.5-2346
+
+build: Mark_Salyzyn@adaptec.com
+	- Added 2.4.21-15.0.2.EL kernel
+	- Added 2.6.5-7.97 kernel to the build (SLES9 Gold)
+
+rx.c+rkt.c: Mark_Salyzyn@adaptec.com
+	- Mailbox7 continues to be a consternation regarding reliable
+	  adapter recovery scenarios; switched to using OMRx[0].
+
+Version: 1.1.5-2347
+
+aachba.c: Mark_Salyzyn@adaptec.com
+	- (u64)=((u8)<<24) does not give expected results, sign extension
+	  occurs. Replace with (u64)=((u64)(u8)<<24)
+
+Version: 1.1.5-2348
+
+install.sh: Mark_Salyzyn@adaptec.com
+	- initrd is blocked from incorporating our product if there is
+	  something in /lib/modules/${OS}-${CONFIG}/update/${PRODUCT}.o,
+	  so remove the file.
+
+Version: 1.1.5-2349
+
+aachba.c+aacraid.h:
+	- define commit_config FIB command
+	- define get_container_count FIB command.
+
+aachba.c+aacraid.h+commsup.c+linit.c
+	- fsa_dev becomes a dynamic structure to accommodate a variable
+	  maximum_num_containers.
+
+build:
+	- Added 2.4.21-231 kernel to build system.
+
+linit.c:
+	- Turned on debug printing of scsi timeouts for xscale only.
+
+Version: 1.1.5-2350
+
+rkt.c:
+	- Limit can_queue to 246 for rocket
+
+build:
+	- Added 2.4.19-306 kernel to build system.
+
+aachba.c:
+	- Removed an innocuous (obnoxious?) DEBUG printk
+
+2004-07-15: Mark Salyzyn <Mark_Salyzyn@adaptec.com>
+
+Version: 1.1.5-2351
+
+build:
+	- Added 2.4.9-31 to the build system
+
+module.equiv:
+	- Added 2.4.9-e.41, 2.4.9-e.43, 2.4.21-17.EL & 2.4.21-15.0.3.EL kernels
+
+build:
+	- Dropped 2.4.21-231 from build
+
+2004-07-16: Mark Salyzyn <Mark_Salyzyn@adaptec.com>
+
+Version: 1.1.5-2352
+
+build:
+	- Added 2.6.3-7mdk to the build system
+
+2004-07-20: Mark Salyzyn <Mark_Salyzyn@adaptec.com>
+
+Version: 1.1.5-2353 (7t Build w/o SLES9, SuSE9.1 & SuSE9 errata 231)
+Version: 1.1.5-2354 (7t Build w/o SLES9 & SuSE9 errata 231)
+Version: 1.1.5-2355 (BigQual refresh)
+
+install.sh:
+	- If missing, add a reference to the module to the kernel's module.dep
+	  file (affects drivers that are *not* shipped with the OS; HostRAID
+	  and some dpt_i2o)
+
+aachba.c:
+	- for __arm__ build, the default FIB size is selected by F/W and not
+	  overridden to 8192 bytes.
+
+Version: 1.1.5-2356 (Jupiter)
+
+aacraid.h+comminit.c+rkt.c+commsup.c+linit.c: Ken Sandars <Ken_Sandars@adaptec.com> + Mark Salyzyn
+	- Added AAC_NUM_MGT_FIB, and ensured can_queue represents the
+	  maximum number of I/O commands allowed and not be confused as the
+	  maximum number of FIB commands permitted into the Adapter. Thus
+	  host->can_queue is the maximum number of I/O commands, AAC_NUM_MGT_FIB
+	  is the maximum number of ioctl commands (set to 8 rather than legacy
+	  of 64) and init->MaxIoCommands sent back to the adapter is the total
+	  number of FIBs.
+
+Version: 1.1.5-2357 (Jupiter+BigQual)
+
+commctrl.c: Mark Salyzyn
+	- Added support for issuing FIBs that are larger than the negotiated
+	  size for the management interface.
+
+linit.c: Mark Salyzyn
+	- Added ASR-2240S, ASR-4005SAS, ASR-4000SAS, ASR-4800SAS, ASR-4805SAS
+	  and AAR-2610SA to the product list.
+
+install.sh: Mark Salyzyn
+	- Fixed problems with using the RH & SuSE modules disk as an update
+	  media, most of which was the selection of the extraction name from
+	  the modules.cgz file or acquiring the appropriate update.tar.gz file.
+
+build: Mark Salyzyn
+	- set 700 for update.sh in the modules disks to recognize at least
+	  that the RH modules disk works as an update media.
+
+aachba.c: Mark Salyzyn
+	- Dropped to 8K for the coalesce threshold for xscale builds.
+
+Version: 1.1.5-2358 (BigQual+7t)
+
+aachba.c+commctrl.c+aacraid.h+comminit.c+commsup.c+dpcsup.c+linit.c:
+	- Merged 2.6.8-rc2-bk9 differences into the driver (COSMETIC)
+
+compat.h
+	- Added definition for __user for kernels less than 2.5 (COSMETIC)
+
+linit.c:
+	- The aac_get_next_adapter_fib_ioctl for 64 bit implementations under
+	  2.6 maladdressed the transfer.
+
+Version: 1.1.5-2359 (BigQual+SPOCK+7t)
+
+commctrl.c:
+	- Added support for CODE_STREAM_IDENTIFIER, accessed via a new
+	  ioctl FSACTL_GET_VERSION_MATCHING
+	- Added support for FSACTL_SEND_LARGE_FIB
+
+aacraid.h:
+	- Added definition for struct VersionMatch
+	- Added definition for FSACTL_GET_VERSION_MATCHING
+	- Added definition for FSACTL_SEND_LARGE_FIB
+
+install.sh:
+	- if the modules.dep file does not exist, then ensure no complaints
+	  are made about mv not being able to access the file.
+	- If an entry is missing in modules.dep, construct it correctly.
+
+aachba.c:
+	- Remove any leading spaces from the Container Name. Ensure that
+	  if there is no container name remaining, to leave the existing
+	  one alone.
+
+build:
+	- Added support for 2.4.18-e.43
+	- Added support for 2.4.18-e.47
+	- Added support for 2.4.9-e.48
+	- Added support for 2.4.9-e.49 (RHAS 2.1 QU5)
+	- Added support for 2.4.21-15.0.4.EL
+
+rx.c+rkt.c:
+	- When responding to AIFs, use DoorBellAdapterNormRespReady instead of
+	  DoorBellAdapterNormCmdReady. The code appeared to work without
+	  undue side effects because Firmware would clear off the queues
+	  when new AIFs are delivered.
+
+commsup.c:
+	- If busy, defer scan action to next AIF. Half hearted attempt to
+	  improve the reliability of this unsupported feature.
+
+aacraid.h+linit.c+comminit.c+rx.c+rkt.c+sa.c:
+	- Remove references to Mailbox7 accesses for synchronous commands.
+
+aacraid.h+aachba.c:
+	- Turned on support for Compatibility ID testing. Only enabled if
+	  the build environment defines CODE_STREAM_IDENTIFIER.
+	- Fortify the adapter information to include supplemental information
+	  as well as the GetBusInfo in support of SAS programatic limits.
+
+linit.c+aachba.c:
+	- Use the newly acquired supplement information vendor and product
+	  fields to override the cardtype selection.
+
+Version: 1.1.5-2360
+Version: 1.1.5-2361 (Branch off 1.1.5-2340 in RHEL3 QU3 with aac_info fix in 1.1.5-2364)
+
+linit.c:
+	- register a reboot notifier to flush adapter
+	- faked AIF needs to call fib_init() later (ADPmp70525)
+
+commctrl.c:
+	- Since kfree has the possibility of switching in some esoteric
+	  variants of the kernel, and since the BKL is held during ioctl
+	  calls, we are unlocking the fib lock around these system calls.
+
+Version: 1.1.5-2362
+
+build:
+	- Added support for 2.4.21-17.EL (RHEL3 QU3 beta)
+	- Added support for 2.4.21-20.EL (RHEL3 QU3)
+	- Added support for 2.6.7-1.451.2.3 (RHEL4 alpha 4)
+
+linit.c:
+	- ASR4000 series entries were flawed in the indexes. Added an
+	  additional 8i entry.
+
+Version: 1.1.5-2363
+
+linit.c:
+	- aac_info is flawed and causes periodic panics in certain systems.
+
+build:
+	- Allow the build system to operate as background build
+	- em64t/ia32e binaries did not show in the rpm
+
+Version: 1.1.5-2364 [BigQual, Pratt, Jupiter Dual & 7t]
+
+linit.c:
+	- AAR-2610SA has had a subproduct change from 0x103C/0x0295 to
+	  0x103C/0x3227.
+	- Some adapters have internal limits of 34 SG elements as a result
+	  of a bug of not splitting requests up when cache is disabled when
+	  sending them to the CHIM. Created a quirk for the adapters that
+	  have this limit.
+
+Version: 1.1.5-2365
+
+aachba.c:
+	- Neglected to add maximum_num_physical check to the srb handler.
+	- leading space on inquiry code was flawed as a result of a typographic
+	  error (replace ! with *)
+
+linit.c:
+	- ASR-4005SAS for IBM is designated as an 8i (ADPmp71521)
+	- Added check for late completion of command during timeout
+	- called aac_get_fw_debug_buffer() after init
+
+fwdebug.c+fwdebug.h
+	- Added firmware debug print handlers
+
+build:
+	- RH floppy disk was limited to 864KB, let it open up to 1.4MB. The
+	  risk is that 864KB was about all the ramdisk could handle when
+	  extracting, so we will no longer get a report of disk overrun as
+	  a warning to existing OS releases. We do not know what will overload
+	  the ramdisk during install. (ADPmp72476)
+	- Product ID list for aacraid is broken in the build due to changes
+	  resulting from incorporating the 2.6 tree.
+	- em32t binaries did not show in the rpm fix broke SuSE releases that
+	  utilize the 2.4.19 kernel (ADPmp73104)
+
+commsup.c:
+	- Added support for sending the time every 30 minutes.
+
+Version: 1.1.5-2366
+
+commctrl.c:
+	- Fixed 64 bit version of the SCB ioctl call as it was not translating
+	  the 32 bit scatter-gather correctly for scatter gather elements
+	  beyond the first one. Do not believe this issue presented a problem
+	  for any Adaptec management products due to their needs as they
+	  limited their SG to only one entry.
+
+build:
+	- Added 2.4.19-238
+	- Added 2.4.19-241
+	- Added 2.4.19-248
+	- Added 2.4.19-251
+
+Version: 1.1.5-2367
+
+linit.c:
+	- Added Themisto discovery to driver
+	- Added AAC_QUIRK_MASTER and AAC_QUIRK_SLAVE to deal with controller
+	  pairs.
+	- Changed Prowler "ESD SO-DIMM PCI-X SATA ZCR" to "ASR-2026ZCR".
+	- Return FAILED when hba_reset completed, the ten second bus settling
+	  delay is counter productive.
+
+aacraid.h+linit.c: Christoph Hellwig <hch@lst.de>
+	- drop casting surrounding iomap and ioremap and use the __iomem
+	  type enhancement.
+
+csmi.c+csmi.h:
+	- Added CSMI ioctl support.
+
+install.sh:
+	- log both successful and failed installations and limit complaints
+	  about installation to a minimum by not repeating similar failure
+	  messages.
+
+aachba.c:
+	- vtune reports that 2% of the time dealing with read calls was
+	  devoted to get_sd_devname(). Optimized codepath.
+
+Version: 1.1.5-2368
+
+build:
+	- Added 2.4.27 debian smp kernel to build
+	- Added 2.6.7-1.451.2.3 RHEL4 alpha 4 to the build
+	- Added 2.6.8-1.602 RHEL4 beta 1 to the build
+	- Added 2.6.5-7.109.5 SuSE 9.1 errata to the build
+
+csmi.h:
+	- Changed from CSMI_8_BYTE_ALLIGNED to CSMI_8_BYTE_ALIGNED
+
+csmi.c:
+	- failure on return from copy_to_user is ignored, but (void) is
+	  not the way to ignore it based on compiler warnings.
+	- scb size is set to 16 always.
+	- scb flags is set to 0 always.
+
+linit.c+compat.h:
+	- scsi_sleep() renamed to ssleep() in 2.6.9 kernel
+
+commctrl.c:
+	- 32 bit application issuing a raw srb in a 64 bit address space
+	  is not handled correctly for the fibsize calculation.
+	- Limit the number of scatter gather entries to 32, and zero
+	  out the references to those sg entries.
+
+Version: 1.1.5-2369
+
+compat.h:
+	- 2.6.8-1.602 RHEL4 beta 1 kernel looks more like 2.6.9, so needed to
+	  define scsi_sleep for kernels 2.6.8 and up rather than 2.6.9 and up.
+
+linit.c: Chris Trown <ctrown@uoregon.edu>
+	- Added an include for linux/delay.h to pick up the definition of
+	  ssleep().
+	- Added `other' Themisto ID to list.
+
+csmi.h:
+	- bumped to 0.83 version
+
+csmi.c:
+	- Acquired slot number from Supplementary Adapter Info SlotNumber
+	  field
+	- Added support to determine the actual bus type (SAS, SATA, Other).
+
+build:
+	- Added support for 2.4.21-22.EL (RHEL3 errata)
+	- Added support for 2.6.5-7.111 (SLES9 NLD)
+	- Added support for 2.4.21-243 (SuSE 9.x errata)
+
+aachba.c:
+	- valid must clear if VM_Nameserve fails on scan
+	- setinqstr has the possibility of overflowing the inquiry structure,
+	  the results are a damaged stack.
+
+commsup.c:
+	- do a probe_container before issuing scan as the adapter can take
+	  some time to write DDF data (not SCSI).
+
+aacraid.h:
+	- added definition of probe_container.
+
+Version: 1.1.5-2370
+
+aacraid.h+commsup.c+aachba.c+commctrl.c+comminit.c+linit.c+sa.c: Adrian Bunk <bunk@stusta.de>
+	- Make some needlessly global code static
+
+linit.c:
+	- Added Intruder (AAR-2420SA, AAR-2620SA & AAR-2820SA)
+
+aachba.c+commsup.c:
+	- Enable a 50 second timeout on the first asynchronous command to
+	  permit the driver to error out and report the hardware failure.
+
+linit.c:
+	- Fixed a comment completion problem for Intruder additions.
+
+build:
+	- Added support for 2.6.8-24 (SuSE 9.2)
+
+Version: 1.1.5-2371
+
+aachba.c: Jens Axboe
+	- Use a busy status return with scsi_done rather than -1 to
+	  signal OS to try again later for aac_read and aac_write to
+	  meet with acceptable coding standards.
+
+aachba.c+linit.c: Mark Salyzyn & Christoph Hellwig <hch@infradead.org>
+	- Moved AAC_EXTENDED_TIMEOUT to set sdev->timeout instead of
+	  inline for every command in the 2.6 variant.
+
+linit.c:
+	- There is a subsystem device id clash between SATAHAWK and INTRUDER
+	  and is giving the BIOS group some grief. Therefore the subsystem
+	  device ID for intruder is changed to 029B, 029C and 029D for 8, 6,
+	  and 4 port versions respectively.
+	- Added FSACTL_GET_VERSION_MATCHING and FSACTL_SEND_LARGE_FIB ioctls to
+	  list of supported 32 bit ioctl calls.
+
+build:
+	- enhanced README.txt to also provide a brief description of the
+	  binary file.
+	- Added support for a RHEL3 i686 ISO image as well.
+	- Added support for 2.6.5-7.109.12 (SLES9/SuSE9.1 SP1 B2 i386)
+	- Added support for 2.6.5-7.109.13 (SLES9/SuSE9.1 SP1 B2 x86_64)
+	- Added support for 2.6.5-7.115 (SLES9/SuSE9.1 SP1 B3)
+	- Added support for 2.6.5-1.358 (RH FC2)
+	- Added support for 2.6.9-1.667 (RH FC3)
+	- Added support for 2.4.21-260 (SuSE 9 errata)
+	- Added support for 2.4.21-261 (SuSE 8 errata)
+
+csmi.c:
+	- return code for CSMIGetSATASignature is under the control of the
+	  firmware and should not be blindly set to SUCCESS if the command
+	  succeeded.
+
+
+Version: 1.1.5-2372
+
+build:
+	- Added support for 2.6.9-1.648_EL (RHEL4 beta 2)
+
+linit.c:
+	- trim space from Model
+
+install.sh:
+	- Add /etc/modprobe.conf as another modules configuration file.
+	- If the module in the initrd does not match, but has the same
+	  `size' values, then report a `possibly stripped' warning message.
+
+Version: 1.1.5-2373
+
+build:
+	- Use "Avon Park SIT" for this build for the version identifier
+
+commsup.c:
+	- enable scsi-scan-single (ADPmp75534 & ADPmp69336)
+
+Version: 1.1.5-2374
+
+build:
+	- Added support for 2.6.5-7.111.5 (SLES9 NLD errata)
+	- Added support for 2.6.5-7.128 (SLES9 SP1 B4)
+	- Added support for 2.6.5-7.134 (SLES9 SP1 RC)
+	- Added support for 2.6.9-1.906_EL (RHEL4 RC)
+
+commsup.c:
+	- disable scsi-scan-single for 2.6 kernels, proc_scsi no longer
+	  exported
+
+install.sh
+	- Missed a double quote in the scripting to reduce size sensitivity.
+
+Version: 1.1.5-2375 (Avon Park SIT)
+
+csmi.c:
+	- Paramters.uFlags is a bit field, not a state.
+	- cdbLength needs to be hard coded to 14 from 16 (beware, 2TB warning).
+	- Set the srbFlags based on data direction or if there is any data to
+	  send at all (HOST_FLAGS_DATA_IN/DATA_OUT/NO_DATA_TRANSFER).
+
+csmi.h:
+	- Added definition for HOST_FLAGS_DATA_IN/DATA_OUT/NO_DATA_TRANSFER.
+
+Version: 1.1.5-2376 (This is a code stream identifier)
+
+linit.c:
+	- Added ICP Lancer products ICP9024R0 and ICP9014R0.
+	- Added include of asm/ioctl32.h
+	- Report ServeRAID for driver name if IBM 8i.
+
+aacraid.h
+	- Added definition for IOP_RESET synchronous command
+
+rkt.c+rx.c+linit.c+aacraid.h+commsup.c+aachba.c+csmi.c+comminit.c+commctrl.c+compat.h
+	- Merged code and style changes in 2.6.10-rc3-bk14 into codebase.
+
+aachba.c:
+	- set the scsi device as removeable during the Read Capacity call.
+	  (ADPmp76369)
+
+pci.ids:
+	- Submitted patch to pci-ids@ucw.cz to update the vital product list
+	  to match the products in the linit.c file (ADPmp77082)
+
+build:
+	- Added support for 2.4.21-20.0.1.EL (RHEL3 errata)
+	- Added support for 2.4.21-27.EL (RHEL3 QU4)
+	- Added support for 2.4.21-27.0.1.EL (RHEL3 errata)
+
+Version: 1.1.5-2377 (Avon Park SIT)
+
+linit.c:
+	- Dropped the maximum number of commands down to 16 per target if on
+	  an x86_64 machine with more than 4GB of memory when built in the
+	  2.4.* environment.
+
+Version: 1.1.5-2378 (CERC Test)
+
+linit.c:
+	- Dropped the maximum number of commands down to 10 per target for
+	  this test.
+
+Version: 1.1.5-2379 (CERC Test)
+
+build:
+	- Added support for 2.6.9-5.EL (RHEL4 RC)
+	- Added support for 2.6.5-7.139 (SLES9 SP1)
+	- Added support for 2.4.9-e.57 (RHAS QU6)
+	- Added support for 2.4.9-e.59 (RHAS QU6 errata 59)
+
+commsup.c:
+	- Added kernel ifdef's to handle scsi_add_target and
+	  scsi_remove_target calls.
+
+aachba.c+aacraid.h:
+	- Added AAC_DEBUG_INSTRUMENT_DAC_CERC to disable 64 bit scatter gather
+	  for only the CERC SR2 product.
+
+Version: 1.1.5-2380 (This is a code stream identifier)
+
+aachba.c+comminit.c:
+	- Added numacb insmod parameter.
+
+aachba.c+aacraid.h
+	- Remove AAC_DEBUG_INSTRUMENT_DAC_CERC code.
+
+build:
+	- Error in incorporating the RHAS2.1 QU6 kernel (2.4.9-e.57) on to the
+	  driver disk (ADPmp78010)
+	- Same problem with RHEL4 RC (2.6.9-5.EL) (ADPmp69861)
+
+Version: 1.1.5-2381 (This is a code stream identifier)
+
+build:
+	- Added support for 2.4.21-273 (SLES 8 errata 273)
+	- Added support for 2.6.5-7.111.30 (SLES 9 errata 30)
+	- Added support for 2.6.8-24.11 (SuSE 9.2 errata 11)
+	- Added support for 2.4.19.SuSE-256 (SLES8 x86_64 errata 256)
+	- Added support for 2.4.21-9.EL (RHEL3 QU1)
+	- Added support for 2.6.8.1-12mdk (Mandrake 10.1)
+	- Added support for 2.6.9-1.11_FC2 (FC2)
+	- Added support for 2.6.10-1.9_FC2 (FC2)
+	- Updated dkms to v2.0.5
+
+commsup.c+aacraid.h
+	- Changed Plug-n-Play state machine to be per-array rather than
+	  per-adapter (ADPmp77096)
+
+Version: 1.1.5-2382 (This is a code stream identifier)
+
+build:
+	- Added support for 2.4.21-276 (SLES8/UL1 SP4 B2)
+	- Added support for 2.6.10-1.8_FC2 (FC2)
+	- Added support for 2.6.10-1.12_FC2 (FC2)
+	- Added support for 2.6.9-1.681_FC3-2.6 (FC3)
+	- Added support for 2.6.9-1.724_FC3-2.6 (FC3)
+	- Added support for 2.6.10-1.737_FC3-2.6 (FC3)
+	- Added support for 2.6.10-1.741_FC3-2.6 (FC3)
+	- Added support for 2.6.10-1.760_FC3-2.6 (FC3)
+
+linit.c:
+	- vmware specifically utilizes the file->private_data. They will be
+	  correcting the problem in future releases thus the fix will work
+	  in both environments being obnoxious^H^H^H^H^H^H^H^H^Hinnocuous in
+	  the later releases.
+
+aachba.c:
+	- vmware has problems with the coalescing code.
+
+commctrl.c:
+	- used sizeof(struct sgmap *) instead of sizeof(struct sgmap) and
+	  misrepresented the size of the srb command truncating the scatter
+	  gather size from the incoming data in 64 bit architectures with
+	  more than 4G of memory populated in the system. (ADPmp78515,
+	  ADPmp78128, ADPmp76236 & ADPmp78228)
+
+Version: 1.1.5-2383 (Avon Park SIT)
+
+Makefile:
+	- Self detect the various SCSI_HAS_* flags rather than depending on
+	  the build system to generate them.
+
+aacraid.h+aachba.c
+	- Added VM_NameServe64
+	- Added capacity64 field to end of the mnt information.
+	- Do not respond to SERVICE_ACTION_IN when card not capable of 64 bit
+	  lba.
+
+commctrl.c:
+	- The srbcmd in 64 bit environments with more than 4GB of memory
+	  are utilizing the sgentry64 elements for the scatter gather, thus
+	  the counts were not parsed correctly when copying the data back
+	  to the user. (ADPmp78846)
+
+build:
+	- Removed support for linux-2.4.21-1.1931.2.349.2.2.ent.RH
+	- Removed support for linux-2.4.21-1.1931.2.393.ent.RH
+	- Removed support for linux-2.4.21-1.1931.2.399.ent.RH
+	- Removed support for debug configurations
+	- Split AS2.1 summit/enterprise from up/smp
+	- pcitable for aacraid driver disk is missing " after the ICP cards
+
+Version: 1.1.5-2384 (Avon Park SIT)
+
+aacraid.h+rkt.c+rx.c+sa.c:
+	- use aac_io_cpu_to_le* and aac_io_le*_to_cpu to deal with perceived
+	  discrepancies in write* and read* I/O handlers.
+
+commsup.c+commctrl.c:
+	- header.Size and header.SenderSize is a 16 bit field, erroneously
+	  handled by 32 bit swap handlers.
+
+commsup.c+comminit.c+commctrl.c+aachba.c+dpcsup.c:
+	- missing swap handlers for various packets.
+
+aachba.c:
+	- When 'first' command times out, return error immediately, do not
+	  fall through.
+
+csmi.c+aachba.c+linit.c:
+	- monitor/kernel/build information from adapter needs to be swapped
+	  in BE architectures.
+
+aachba.c:
+	- Revert 64 bit LBA code
+
+Version: 1.1.5-2385 (Avon Park SIT)
+Version: 1.1.5-2386 (Avon Park SIT, revert to 1.1.5-2383, plus one managment change)
+
+aachba.c+linit.c+compat.h: Tobias Klauser <tklauser@nuerscht.ch>
+	- Use the DMA_{64,32}BIT_MASK constants
+
+linit.c:
+	- scsi_host_alloc calls scsi_register which prints a report in some
+	  versions of the 2.4 kernel. The aac_info function is not ready to
+	  be called at that time as the hostdata has not been set up, so we
+	  report a 'default' name of "AAC" (ADPmp78060).
+
+aacraid.h+aachba.c:
+	- Adding any u64 to a structure will cause, in some cases of the
+	  compiler, 8 byte alignment constraints which can reshape the
+	  structure at each element even before the u64 definition. Changed to
+	  using a pair of u32's for capacity64 element in the mount structure.
+	  (ADPmp79142)
+
+Version: 1.1.5-2387 (This is a code stream identifier)
+
+build:
+	- Added support for 2.4.21-277 (SLES8/UL1 SP4 RC1)
+
+aacraid.h+rx.c+rkt.c+sa.c+linit.c+Makefile:
+	- Added support for dump_poll. Currently RHEL4 and RHFC support this
+	  new interface. (ADPmp79442)
+
+Version: 1.1.5-2388 (This is a code stream identifier)
+
+compat.h+aachba.c+aacraid.h+commctrl.c+comminit.c+commsup.c+dpcsup.c+linit.c:
+	- Merged code and style changes in 2.6.11-rc5-bk3 into codebase.
+
+linit.c:
+	- Added support for shost_attrs & sysfs.
+
+linit.c+csmi.c:
+	- Dropped reference to Red Hat in printouts (ADPmp79559 & ADPmp79382)
+
+build:
+	- Strip kernel environment check for sourceball that is part of the
+	  DKMS packaging, broke DKMS build environment (ADPmp79708)
+
+Version: 1.1.5-2389 (This is a code stream identifier)
+
+build:
+	- Switch from 3.3 compiler to 3.4 for RHEL4 ia64 and FC3 all archs
+	  & all errata.
+	- Added support for 2.4.18-19.7.x (RH7.3 errata 19)
+
+linit.c: Domen Puncer <domen@coderock.org>
+	- Change from pci_module_init to pci_register_driver.
+
+linit.c:
+	- Loop for determining unique_id failed and generates a pattern of
+	  0, 1, 0, 0, ... (ADPmp79694)
+	- Added ICP9047MA and ICP9087MA to product probe. Added AvonPark Lite.
+
+linit.c+aachba.c:
+	- An SG list of 1K,4K,...,4K,64K+4K-1K got produced, the math for the
+	  maximum I/O should be (sg_tablesize * 8) + 112 instead.
+
+rkt.c+rx.c:
+	- Adapter Panic handler has AAC_IO_USES_CPU_ORDER misspelled.
+
+commsup.c:
+	- time stamp is an u32, not an unsigned long.
+
+csmi.c:
+	- Send LoopCount rather than bufferOffset to param[4] of GetRAIDConfig
+	  command. (ADPmp77631, ADPmp79282)
+
+Version: 1.1.5-2390 (This is a code stream identifier)
+
+build:
+	- Added support for 2.4.21-278 (SLES8/UL1 SP4 RC3)
+	- Removed support for 2.4.21-276
+	- Removed support for 2.4.21-277
+	- Removed support for 2.4.18-24.7.x (RH7.3 errata 24)
+	- Removed support for 2.4.18-26.7.x (RH7.3 errata 26)
+	- Removed support for 2.6.10-1.741_FC3-2.6 (FC3 errata 741)
+	- Dropped all the sles9-sp1 betas from the packaging.
+	- strip date stamps, then join.file the patches before commiting them
+	  to the archive.
+
+modules.equiv
+	- Declared 2.4.21-277 to be identical to 2.4.21-278
+	- Declared 2.4.18-24.7 to be identical to 2.4.18-19.7
+	- Declared 2.4.18-26.7 to be identical to 2.4.18-19.7
+	- Declared 2.6.10-1.737_FC3-2.6 to be identical to 2.6.10-1.741_FC3-2.6
+
+linit.c:
+	- return code from pci_register_driver() is not of the same form
+	  as pci_module_init. Only negative return values should be reported
+	  as an error.
+
+install.sh:
+	- Added /etc/grub.conf to list of grub files
+	- redirect error on boot configuration file awk script for cases when
+	  boot configuration file is not found.
+
+Version: 1.1.5-2391 (This is a code stream identifier)
+Version: 1.1.5-2392 (Branch off 1.1.5-2372 with pci_unregister_driver if aac_count drops to zero).
+
+build:
+	- Added support for 2.6.10-1.14_FC2-2.6 (RH FC2 Errata 14)
+	- Added support for 2.6.10-1.770_FC2 (RH FC2 Errata 770)
+	- Added support for 2.6.10-1.766_FC3-2.6 (RH FC3 Errata 766)
+	- Added support for 2.6.10-1.770_FC3-2.6 (RH FC3 Errata 770)
+	- Removed support for 2.6.10-1.9_FC2 (FC2) and placed in
+	  module.equiv
+	- Removed support for 2.4.18-e.47 (RHAS 2.1 IA64) and placed in
+	  module.equiv
+	- Added support for 2.4.18-e.52 (RHAS 2.1 IA64) in module.equiv
+	- Added support for 2.4.18-e.54 (RHAS 2.1 IA64) in module.equiv
+	- Generate dkms package with build number, but add a Branch Type
+	  of "dkms" into the version information reported by the driver.
+	- Generate source package with a Branch Type of "custom" into the
+	  version information reported by the driver.
+	- build rpm packages as 'noarch' and not as default of the build
+	  system 'i386'.
+
+csmi.c:
+	- uMaxDrivesPerSet needs to be acquired from the Firmware,
+	  rather than using the driver physical limits (ADPmp80188)
+
+aachba.c:
+	- Added some new container types (RAID5D, RAID5D0, RAID1E, RAID6
+	  and RAID60) to default array naming list.
+	- Changed over to new format of VM_NameServe64 (changed before
+	  customer release of Firmware that utilized interim format).
+
+linit.c:
+	- Added Hurricane ASR-4810SAS
+	- Added sensitivity to AAC_DRIVER_BRANCH in order to propagate
+	  driver source with keys as to their history.
+
+linit.c: (Mark Haverkamp <markh@osdl.org>
+	- Restructured sys handler to match standards expectations.
+	  ADPmp80589
+
+install.sh:
+	- Do not compare result in initrd to any backup orig drivers
+	  that may have been left in the /lib/modules tree.
+	- Added support for elilo.efi
+
+commsup.c+comminit.c:
+	- pci_alloc_consistent acquired GFP_DMA arena pool. This has
+	  been shown as a problem on 2.4 based kernels on em64t machines
+	  with > 4GB of memory which typically exhaust the DMA pool. So,
+	  prior to making the call, we will acquire GFP_ATOMIC
+	  memory first and check if it is 31BIT limited, and instead use
+	  that memory rather than resorting to the precious DMA pool. The
+	  other workarounds are to limit the memory to 4GB, set the
+	  memsize to 4GB, or to tell the SW IOMMU to reduce it's memory
+	  requirements (swiotlb=12288).
+
+Version: 1.1.5-2393 (This is a code stream identifier)
+
+linit.c+commctrl.c:
+	- Added AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB
+
+linit.c: Ming Zhang <mingz@ele.uri.edu> & Mark Salyzyn
+	- Set max_cmd_len to 16 to permit SAI_READ_CAPACITY_16 call to
+	  get through the scsi layer to the driver.
+
+linit.c:
+	- Added calls to csmi_register_ioctl32_conversion() and
+	  csmi_unregister_ioctl32_conversion()
+
+csmi.c:
+	- Added csmi_register_ioctl32_conversion(void) and
+	  csmi_unregister_ioctl32_conversion(void)
+
+install.sh:
+	- notice that we are doing an ELILO configuration on ia64
+
+aachba.c:
+	- Removed sundry debugging prints
+
+build:
+	- Added MODULES_CONF_OBSOLETES_ONLY[0]="${PRODUCT}" to dkms.conf
+	- Added support for 2.6.5-7.147 (SLES9 SP1 errata 147) to
+	  modules.equiv
+	- Added support for 2.6.5-7.151 (SUSE9.1 SP1 errata 151) to
+	  module.equiv
+	- Added support for 2.4.21-278-x86_64 (SLES8 SP4 64 bit)
+
+Makefile:
+	- Use TOPDIR instead of AAC_ROOT
+
+Version: 1.1.5-2394 (This is a code stream identifier)
+
+build:
+	- Added support for 2.4.20-133 (SuSE 8.2 errata 133)
+	- Added support for 2.4.21-286 (SuSE 9.0 errata 286) to module.equiv
+	- Added support for 2.6.8-24.14 (SuSE 9.2 errata 14)
+	- Added support for 2.6.9-5.0.3.EL (RHEL4 errata 3)
+	- Added support for 2.6.9-6.37.EL-2.6 (RHEL4 U1 beta)
+	- Added support for 2.6.10-1.771_FC2 (FC2 errata 771)
+	- Added support for 2.6.11-1.14_FC3 (FC3 errata 773)
+	- Added support for 2.4.21-31.EL (RHEL3 QU5 beta)
+
+aachba.c+linit.c: Tobias Klauser <tklauser@nuerscht.ch> & Domen Puncer <domen@coderock.org>
+	- added include for linux/dma-mapping.h
+
+linit.c: Konstantin Khorenko <khorenko@sw.ru>
+	- aac_info and aac_detect need to be active on in-kernel
+	  versions of the driver.
+
+linit.c:
+	- aac_show_flags is a newline separated list
+	- Added SAI_READ_CAPACITY_16 to list of possible flags in
+	  aac_show_flags
+	- aac_get_adapter_info status needs to be placed in the 'error'
+	  variable to unload correctly and deinit rather than unmap
+	  (ADPmp83209).
+
+commsup.c:
+	- allocate 8 more NewFibs than noticed to deal with high AIF
+	  traffic.
+	- Added support for wait=-2 to do a 'silent' timeout of a
+	  command.
+	- Increased the timeout for wait<0 to 3 minutes from 50 seconds
+	  due to paranoia (ADPmp83209)
+
+comminit.c:
+	- issue the adapter shutdown with a wait=-2 value (ADPmp78635)
+
+aacraid.h+rx.c+rkt.c+sa.c+linit.c:
+	- Added a disable_interrupt method to prevent future adapter
+	  interrupts when shut down. Call this method before free_irq(),
+	  preferably before dealocating structures. (ADPmp83209)
+
+commsup.c+comminit.c:
+	- revert out the GFP_KERNEL kmalloc call to see if it reports an
+	  address <2GB instead of using pci_alloc_consistent. Fix this
+	  another day. (ADPmp83209)
+
+Version: 1.1.5-2395 (This is a code stream identifier)
+
+build:
+	- Added support for 2.6.5-7.162 (SLES9 sp2 beta1)
+
+aachba.c+linit.c+aacraid.h+commsup.c+comminit.c+dpcsup.c:
+	- Merge differences in the 2.6.12-rc2 kernel.org branch of the
+	  driver.
+
+linit.c:
+	- Added ICP9085LI & ICP5085AU
+	- Modified support for ASR4810SAS
+
+aacraid.h+commsup.c:
+	- If ROMB heritage adapter, enable printf
+
+Version: 1.1.5-2396 (Avon Park SIT)
+
+build:
+	- Added support for 2.6.11.4-20a (SUSE 9.3)
+	- Added support for 2.6.9-5.0.3.EL-2.6 (CentOS4) to driver disks
+	- Added support for 2.6.9-5.0.5.EL (RHEL4 Errata 5) to
+	  modules.equiv
+	- Added support for 2.4.21-27.0.2.EL-2.4 (CentOS3) to driver
+	  disks
+
+linit.c+aacraid.h:
+	- Merge differences in the 2.6.12-rc2 kernel.org branch of the
+	  driver.
+
+linit.c:
+	- str() did not do the right thing, needed to nest macros.
+
+aachba.c+aacraid.h+commctrl.c+comminit.c+commsup.c+dpcsup.c+linit.c: Mark Haverkamp <markh@osdl.org>
+	- Remove sparce warnings
+
+readme.txt(dkms):
+	- Added strings for 'ips' driver
+	- Added documentation on how to make a 'suse' driver disk
+
+Version: 1.1.5-2397 (This is a code stream identifier)
+
+build:
+	- sort distributions when code has to cut the products into
+	  pieces.
+
+commctrl.c:
+	- byte_count is converted from le32 to cpu, then again when used
+	  in the following line. Dropped the second le32_to_cpu call. No
+	  side effects in an LE machine.
+
+linit.c:
+	- MODULE_VERSION limited to 2.6.4 and higher
+
+Version: 1.1.5-2398 (Avon Park SIT)
+Version: 1.1.5-2399 (This is a code stream identifier)
+
+build:
+	- Added linked equivalent entries for multi-OS driver disk
+	  images in driverdisks tarball
+	- dkms package versioning is ${VERSION}.${REVISION}.${BUILD} as
+	  required by DKMS and changed the tarball package name to
+	  ${VERSION}.${REVISION}-${BUILD} to match the other build
+	  product names. Adjusted dkms documentation to match.
+	- Added support for 2.4.21-27.0.4.EL-2.4 (RHEL3 QU4 Errata 4) to
+	  modules.equiv
+
+install.sh
+	- RHEL3, RHEL4, FC2 and FC3 all can add a -2.4 or -2.6 into the
+	  kernel name that does not match the /lib/modules/kernel names.
+
+Version: 1.1.2-2400 - 1.1.2-lk2 + LARGE_FIB patch
+Version: 1.1.5-2400 (Enzo)
+
+build:
+	- Added support for 2.6.5-7.104 (SLES9 errata) to module.equiv
+	- Added support for 2.6.5-7.108 (SLES9 errata)
+	- Added support for 2.4.21-169 (SLES8 errata)
+	- Added support for 2.4.21-190 (SLES8 errata) to module.equiv
+	- Added support for 2.4.21-192 (SuSE 9 errata) to module.equiv
+	- Added support for 2.4.21-196 (SLES8 errata) to module.equiv
+	- Added support for 2.4.21-198 (SLES8 errata) to module.equiv
+	- Added support for 2.4.21-199 (SuSE 9 errata)
+	- Added support for 2.4.21-202 (SuSE 9 errata) to module.equiv
+	- Added support for 2.4.21-207 (SLES8 errata) to module.equiv
+	- Added support for 2.4.21-215 (SLES8 errata) to module.equiv
+	- Added support for 2.4.21-226 (SuSE 9 errata) to module.equiv
+	- Added support for 2.4.21-238 (SuSE 9 errata) to module.equiv
+	- Added support for 2.4.21-280 (SLES8 errata) to module.equiv
+	- Added support for 2.6.8-24.3 (SuSE 9.2 errata 3)
+	- Added support for 2.4.9-e.62 (RHAS2.1 QU7)
+	- Switched support for 2.4.19-340 to module.equiv
+	- 2.6.5-7.162 had the wrong .config entries, CONFIG_RELEASE="0"
+	  instead of "7.162"
+
+Version: 1.1.5-2400 (This is a code stream identifier)
+
+aachba.c+linit.c: James Bottomley <James.Bottomley@SteelEye.com> & Mark Haverkamp <markh@osdl.org>
+	- Use blk_queue_max_segment_size() instead of 2.4 kernel fix where
+	  we split up SG elements if they exceed 64KB for the older adapters.
+
+build:
+	- Added support for 2.4.21-32.EL (RHEL3 QU5)
+
+Version: 1.1.5-2401 (Enzo)
+
+aachba.c:
+	- Removed aac_spin* macros, they are no longer needed and reduce the
+	  differences between the kernel.org and Adaptec branch of the driver.
+
+linit.c: Mark Haverkamp <markh@osdl.org>
+	- Dropped aac_host_version from /sys entry names (/sys/modules/aacraid
+	  is a duplicate of this information).
+	- Dropped aac_ from /sys entry names
+	- Dropped supporting wrapping text from /sys entry contents
+
+aachba.c+aacraid.h+commctrl.c+comminit.c+dpcsup.c+rkt.c+sa.c+linit.c:
+	- Back merged cosmetic changes from 2.6.12-rc4-git2
+
+linit.c:
+	- Move DRIVER_FULL_VERSION down so that parameters in aacraid.h
+	  can be picked up if necessary.
+
+install.sh:
+	- Added support for --mail option.
+
+build:
+	- Added report in README for unusual build flags.
+	- SL9.3 build was broken, needed an rpm-version file placed in the
+	  TOPDIR.
+
+Version: 1.1.5-2401 (This is a code stream identifier)
+
+build:
+	- Added support for 2.4.21-32.0.1.EL-2.4 (RHEL3 QU5 errata 1)
+	- Added support for 2.6.11-1.27_FC3-2.6 (FC3 errata 27)
+	- Alterred build of 2.6.11.4-20a (SUSE 9.3)
+	- Alterred build of 2.6.9-6.37.EL (RHEL4 U1 beta)
+
+install.sh:
+	- SLES9, SL9.3 (and probably others) switched from mk_initrd to
+	  mkinitrd using 'SuSE' parameters. Added a check to see if the
+	  /sbin/mkinitrd had "i).*initrd" and "k).*kernel" contained in
+	  the script to differentiate.
+
+commsup.c:
+	- When an array is clearing, we issue a scan when we should be
+	  issuing a delete in the 2.6 stream (ADPmp85455).
+	- When the array clear has completed, we have discovered a means to
+	  add the device for kernels between 2.6.3 and 2.6.10 (ADPmp85455).
+
+commsup.s+aacraid.h:
+	- We added additional code to determine when the container zero
+	  task starts, and issue a container delete when the container
+	  change event occurs. We keep the original container zero detector
+	  as it is also used to detect a container create. (ADPmp85455)
+
+Version: 1.1.5-2402 (This is a code stream identifier)
+
+commctrl.c:
+	- send raw srb has some return code -1, that should be replaced
+	  with ENOMEM and ENXIO to be more descriptive. -1 is
+	  equivalent to indicating EPERM.
+	- used the outgoing swapped value for sg count in 32 bit path
+	  rather than the user value (ADPmp85466)
+
+aacraid.h+linit.c:
+	- Added AAC_DEBUG_INSTRUMENT_PENDING which displays the number
+	  of commands outstanding to the adapter in both the /proc and
+	  /sys interface points.
+
+compat.h:
+	- Recognize that scsi_remove_host should restore the 'aac'
+	  value (ADPmp85994).
+
+linit.c+Makefile:
+	- If scsi_in_detect is present in hosts.c, then we need to
+	  adjust the code that 'hacks' 2.4 functionality. This affects
+	  RHEL3 QU2 and up only (ADPmp85994+). This one was a mind-
+	  bender where they broke support for allocation of adapter
+	  scsi resources before the registration call as a scsi module.
+
+compat.h+Makefile:
+	- If scsi_scan_host is exported in scsi_syms.c, then we need to
+	  use it to improve the timeliness of delivery.
+
+aachba.c:
+	- aac_driver_version is now a character string, compatibility
+	  report needs to be adjusted.
+
+install.sh:
+	- Added support to recognize other versions of em64t
+	  processors, Genuine Intel processors. (ADPmp86028)
+
+Version: 1.1.5-2403 (This is a code stream identifier)
+
+aacraid.h:
+	- Remove AAC_DEBUG_INSTRUMENT_PENDING
+
+Version: 1.1.5-2403 (Enzo)
+
+linit.c:
+	- monitor_version and bios_version should be hba_monitor_version
+	  and hba_bios_version respectively.
+
+build:
+	- Added support for 2.6.9-11.EL-2.6 (RHEL4 U1)
+	- Removed support for 2.6.7-1.451.2.3 (RHEL4 alpha)
+	- Removed support for 2.6.8-1.602 (RHEL4 beta)
+	- Removed support for 2.6.8-1.648_EL (RHEL4 beta)
+	- Removed support for 2.6.9-1.906_EL (RHEL4 beta)
+	- Removed support for 2.6.9-6.37.EL_2.6 (RHEL4 U1 beta)
+
+aachba.c+aacraid.h+csmi.c+linit.c:
+	- Merged in 2.6.12-rc6-git8
+
+commctrl.c:
+	- cdb was not transfered when sending raw srb commands.
+
+Version: 1.1.5-2404 (Enzo)
+
+build:
+	- RHEL3 U5 2.4.21-32.EL was erroneously versioned as 2.4.21-32.EL-2.4
+
+Version: 1.1.5-2405 (Enzo)
+
+compat.h+csmi.c+linit.c:
+	- Incorrect expectations for list_for_each_entry usage, the loop
+	  'entry' variable is undefined when outside the loop. Only
+	  experienced side effect is a failure to load/unload the driver
+	  module in the 2.4 series of the kernels (ADPmp85994). CSMI is
+	  affected, but no reported problems.
+
+compat.h:
+	- 2.4.21-17.EL+ has scsi_scan_host(), but does not have the
+	  corresponding scsi_remove_host() call! We construct one that
+	  issued "scsi remove-single-device" calls to proc
+	  (ADPmp85994).
+
+aachba.c+linit.c:
+	- move probe_container out of the queuecommand path under the
+	  2.4 based timesys kernels. They can not handle a 'blocking'
+	  function, especially one that requires an interrupt response
+	  before returning to the caller.
+
+build:
+	- CHANGELOG inclusion in source is now parameterized
+	  (--nochangelog).  Subsequent Enzo or AvonPark builds will
+	  set this flag.
+
+Version: 1.1.5-2404 (This is a code stream identifier)
+
+build:
+	- Added support for 2.6.5-7.187 (SLES9 sp2 rc3)
+	- Removed driver disk support for 2.6.5-7.162 (SLES9 sp2 beta1)
+	- Added support for 2.6.11-1.35_FC3_2.6 (FC3 errata)
+	- Added support for 2.6.11-1.1369_FC4 (FC4 Gold)
+	- Added support for GCC4 cross/native compile suite.
+	- set ARCH= for all cases, just in case build machine is hosted
+	  on a non-i386 environment.
+	- To support a SLES9 build machine, we need to set LC_ALL and
+	  LANG.
+
+aachba.c:
+	- probe_container call was not ifdef'd out properly for
+	  CONFIG_TIMESYS.
+
+aachba.c+commsup.c+linit.c+csmi.c+aacraid.h
+	- merge scsi-misc-2.6.git cosmetics
+	- remove aac_atoi() and replace with simple_strtol()
+
+install.sh:
+	- set LC_ALL to C.
+
+Version: 1.1.5-2405 (This is a code stream identifier)
+
+build:
+	- Fixed permission issues with creation of iso driver disks that
+	  affected the SuSE portion of the image.
+
+comminit.c+aachba.c+linit.c:
+	- Use NEW_COMM flag to switch between 64K scatter gather element
+	  limits or not. The SGBCOUNT condition has outgrown it's
+	  usefullness.
+	- Dropped SGBCOUNT to 4096 from 8192 as we managed to cause the
+	  2810 to drop out as the WD SD drives can not handle such large
+	  requests.
+
+aachba.c:
+	- Adjusted white space to match better with scsi-misc-2.6.git
+
+commctrl.c:
+	- In the 64 bit data path of the raw srb handler, the scatter
+	  gather data was transferred to the user side rather than the
+	  fib side of the equation (ADPmp87218)
+
+Version: 1.1.5-2406 (This is a code stream identifier)
+Version: 1.1.5-2406 (Enzo)
+
+aacraid.h: Martin Drab <drab@kepler.fjfi.cvut.cz>
+	- Dropped AAC_MAX_32BIT_SGBCOUNT to 512, some field
+	  instability showed up on the adapters.
+
+build:
+	- Added support for 2.6.5-7.155.29 (SuSE 9.1 errata)
+	- Added support for 2.6.5-7.191 (SLES9 SP2)
+	- Added support for 2.6.12-1.1387_FC4-2.6 (FC4 errata)
+	- Added support for 2.6.12-1.1390_FC4-2.6 (FC4 errata)
+
+Version: 1.1.5-2407 (Enzo)
+Version: 1.1.5-2407-1 FSC branch with first two fixes (scsi_bios_ptable
+	NULL, and hot action break from loop) of 1.1.5-2410.
+
+build:
+	- Added object module checking to build script to ensure that
+	  fiasco resulting from a full build done in a dirty environment
+	  does not produce a fubar result. More changes or policy to
+	  come to control the prominence of the warning message(s)
+	- When confronted with a kernel that is not configured as part
+	  of the build, make note, declare an error, but continue.
+	- Added 2.6.5-7.191 (SLES9 sp2) to the driver disk.
+	- Removed driver disk support for 2.6.5-7.162 (SLES9 sp2 beta1)
+	- Removed driver disk support for 2.6.5-7.187 (SLES9 sp2 rc3)
+	- Fixed SL9.3 driver disk creation, neglected to add -20a to
+	  kernel names to be added to this driver disk.
+	- Added 2.6.12-1.1372_FC3 (FC3 errata)
+	- Added 2.6.12-1.1398_FC4 (FC4 errata)
+	- Added 2.6.11.4-21.7 (SL9.3 errata)
+	- Added 2.6.9-7.2.EL (RHEL4 hot fix)
+	- Removing 2.4.19-kdb
+
+linit.c+README+readme.txt.orig+pciids.sourceforge.net
+	- Added IBM ServeRAID 8k/8k-l4 and 8k/8k-l8 product IDs.
+	- Added ICP9067MA product IDs
+
+linit.c: (Christoph Hellwig <hch*lst.de>
+	- Remove scsi_cmnd->state
+
+linit.c+rx.c+rkt.c+sa.c:
+	- Move thread start out of the adapter initialization routines
+	  and certainly after adapter startup so that we don't get any
+	  time updates before the adapter is considered ready. Currently
+	  the thread blocks this from occurring by not setting the time
+	  until a second or more has elapsed. This is not considered a
+	  reliable fence.
+
+linit.c:
+	- ICP9085LI & ICP5085BR used the rkt interface instead of the rx
+	  interface (ADPmp87781)
+	- 8k and ASR4810SAS used the rx interface instead of the rkt
+	  interface.
+
+Version: 1.1.5-2407 (This is a code stream identifier)
+Version: 1.1.5-2407 (AvonPark)
+Version: 1.1.5-2408 (Enzo)
+
+aachba.c+comminit.c: Mark_Salyzyn@adaptec.com & Nagendra_Tomar@adaptec.com
+	- replace sgmap with sgentry when determining the maximum sg
+	  entries to fit in a FIB.
+
+aachba.c: James Bottomley <James.Bottomley@SteelEye.com>
+	- Incorrect used of scsicmd->timeout - jiffies, use
+	  scsicmd->timeout_per_command instead.
+
+commctrl.c:
+	- remove unnecessary unlocks surrounding kfree calls.
+	- kmalloc call has arguments reversed, result was to
+	  allocate a 224 byte structure which currently is 'big
+	  enough' for most command requirements for the srb command.
+	- If a LARGE_FIB is larger than the negotiated size and larger
+	  than 2K, then return EINVAL
+
+install.sh:
+	- Added support to permit /lib/modules/2.4.21-231-SMP
+	  and /lib/modules/2.4.21-231 to be handled by the installer.
+
+build:
+	- Added 2.6.5-7.193 (SL9.1 update)
+	- Added 2.6.8-24.17 (SL9.2 update)
+
+linit.c:
+	- switch to using aac_shutdown instead of aac_reboot_event.
+	- return -ENODEV if the adapter count is 0.
+	- No need to pre-populate device structures with probe_container
+	  calls before issuing the scan, as this is done by the
+	  aac_get_containers() call.
+	- replaced using 'serial_number' with command->request
+	  and command->request->rq_status != RQ_INACTIVE
+
+rx.c+rkt.c+linit.c+commsup.c
+	- Started using IOP_RESET.
+
+commsup.c:
+	- Added a check for fsa_dev as it can be in an uninitialized state
+	  at the time aac_handle_aif() is called.
+
+aachba.c+commsup.c
+	- Added update_interval and check_interval for time sync and
+	  check health to make them tunable.
+
+sa.c:
+	- sa_writew(,,cpu_to_le16(0xffff)) should be sa_writew(,,0xffff)
+
+linit.c+aachba.c:
+	- Support no_uld_attach in lieu of the traditional blocking of
+	  Inquiry responses for kernels that support this flag (2.6.10+).
+	  enforce data protect for RAID components. This also affects
+	  back ports, which currently includes SLES9 SP2 and SLES9 updates.
+
+aachba.c: Mark Haverkamp <markh@osdl.org>
+	- Fix aacraid probe breakage in scsi-block-2.6
+
+Version: 1.1.5-2407 (IBM Jaguar SIT)
+
+linit.c+aachba.c+commsup.c:
+	- Drop references to cmd->owner & cmd->state and duplicate the
+	  functionality in cmd->SCp.phase
+	- split out from aac_check_health() the aac_reset_adapter()
+	  routine and add a "reset_host" sys attribute to call it.
+	  This same entry point returns adapter status.
+
+linit.c:
+	- In the proc handler,
+		echo reset_host >/proc/scsi/aacraid/?
+	  will trigger a reset of the host adapter for legacy kernels
+	  using the new aac_reset_adapter() handler.
+
+commsup.c:
+	- call scsi_block_request()/scsi_unblock_request() instead of
+	  relying purely on the in_reset command queue kickback. Also
+	  released the host_lock early so that we do not have tasks
+	  blocked (we did manage to get a CPU? hang complaint on
+	  weekend testing.
+	- 32 bit math errors when dealing with check_interval (ADPmp90870).
+
+linit.c+Makefile:
+	- Add support for disk dump feature in RHEL3.
+
+Version: 1.1.5-2408 (IBM Jaguar SIT)
+
+aachba.c:
+	- use aac->max_fib_size rather than sizeof(struct hw_fib) in
+	  the BUG statement because if the Adapter negotiates a larger
+	  fib, you *will* get a panic. This is not an issue for any
+	  current driver from Adaptec or from the scsi-misc-2.6 tree,
+	  but since the raw I/O code did not propagate to 2.6.13 yet, it
+	  is a serious issue there.
+
+install.sh:
+	- Did not accommodate module.o & module.ko entries in the
+	  RH driver disk format (ADPmp90502)
+	- One can not trust a break in a case statement (ADPmp90870)
+
+build:
+	- Add 2.6.11.4-21.8 (SL9.3 update)
+	- Add support for CentOS 4.1
+	- Add support for the generation of an RHEL4, FC3, FC4, CentOS
+	  CDROM driver disk.
+
+commsup.c:
+	- The AifDen* packets should result in immediate driver action
+	  (ADPmp90701)
+
+Version: 1.1.5-2408 (This is a code stream identifier)
+
+commsup.c:
+	- user submitted IOP_RESET should perform a VM_CloseAll (flush
+	  cache) before submitting command. Unwind if IOP_RESET is not
+	  supported.
+
+aacraid.h+aachba.c:
+	- If the SlotNumber in the supplement information is unknown,
+	  then set the slot number from the Linux concept of slot
+	  number and inform Adapter of the setting (ADPmp90861).
+	  Should be set by the BIOS normally, but not all Linux systems
+	  have a BIOS!
+
+aachba.c+commsup.c:
+	- Merged current scsi-misc-2.6 cosmetic changes.
+
+build:
+	- x86_64 SuSE dud template is not being transferred.
+
+Version: 1.1.5-2409 (This is a code stream identifier)
+Version: 1.1.5-2409 (IBM Jaguar SIT)
+
+linit.c: Martin Wilck <martin.wilck@fujitsu-siemens.com> & Mark_Salyzyn@adaptec.com
+	- scsi_bios_ptable can return a NULL pointer, if memory is
+	  exhausted or if someone created a zero sized array.
+	  ADPmp91471
+
+commsup.c: Martin Wilck <martin.wilck@fujitsu-siemens.com> & Mark_Salyzyn@adaptec.com
+	- break of device loop once one is discovered so that we are
+	  not presented with a borken device list following one of
+	  the hot actions. ADPmp91471
+
+aachba.c: Ken Sandars <Ken_Sandars@adaptec.com>
+	- scsicmd->cmnd[9] << 32 should be scsicmd->cmnd[5] << 32
+
+aachba.c:
+	- Ifdef SlotNumber setting, decided that BIOS and Management
+	  needs to get their act together.
+
+commctrl.c:
+	- If the aac_command_thread appears to have died, resurrect it!
+	  ADPmp91208.
+
+build:
+	- Add 2.6.0-test5_2 (TL 10 Desktop boot)
+	- Add 2.6.0-6 (TL 10 Desktop install)
+	- Add 2.6.0-24 (TL 10 Desktop update)
+	- Add 2.6.8-1 (TL 10 Server)
+	- Add 2.6.8-5 (TL 10 Server update)
+
+Version: 1.1.5-2410 (This is a code stream identifier)
+Version: 1.1.5-2410 (IBM Jaguar SIT)
+
+build:
+	- Add 2.4.21-37.EL (RHEL3 U6)
+	- Removed CODE_STREAM_IDENTIFIER from channel build
+	- Fixed 2.4.21-37.EL (RHEL3 U6) so that it would land on driver
+	  disk
+	- Add 2.4.22-1.2115.nptl (FC)
+	- Add 2.4.22-1.2199.nptl (FC errata)
+
+aachba.c+commsup.c+linit.c:
+	- Merge scsi-rc-fixes-2.6
+
+commctrl.c+Makefile:
+	- Can not use find_task_by_pid universally, not all kernels
+	  export the symbol for use by the modules ADPmp91208 &
+	  ADPmp91941.
+
+aachba.c: Torry Hoffman <torry@lockdownnetworks.com>
+	- ifdef out variables i and count as they are unused.
+
+Version: 1.1.5-2411 ()
+Version: 1.1.5-2411 (Avon Park SIT)
+Version: 1.1.5-2411 (IBM Jaguar SIT)
+
+build:
+	- README.txt now reports the 2.4.19 sub-version on SuSE
+	  kernels incorporated into the driver disks.
+	- Add 2.6.9-22.EL (RHEL4 U2)
+	- Add 2.6.5-7.224 (SuSE SP3 beta2)
+
+linit.c:
+	- 2.4.2 and 2.4.4 kernels dropped off of build due to
+	  usage of snprintf. Continued pedantic build checking
+	  of the driver in multiple kernels only reason for
+	  repair of this code.
+
+aacraid.h: Juan D Ch <jchimienti@most.com.ar>
+	- Dropped AAC_MAX_32BIT_SGBCOUNT to 256, some field
+	  instability showed up on the adapters.
+
+commsup.c: John Hanson <John_Hanson@adaptec.com>
+	- When we requeue a container for later processing, lets move on
+	  down the list and check if another could be done in the
+	  current cycle ADPmp91038.
+
+Version: 1.1.5-2412 ()
+Version: 1.1.5-2412-IBM () ADPmp92508
+
+commctrl.c:
+	- Only resurrect the aac_command_thread if the resources are
+	  available ADPmp92417
+
+commsup.c: Jesper Juhl <jesper.juhl@gmail.com>
+	- Removed all if (ptr) kfree(ptr) style calls.
+
+Version: 1.1.5-2413-IBM ()
+
+build:
+	- add SCSI_HAS_DUMP* checking in the build scripts to complement
+	  those picked up by the Makefile. This is useful for the ips
+	  and dpt_i2o drivers.
+	- Added 2.6.11.4-21.9 SuSE 9.3 errata kernel.
+	- Various SuSE Pro releases dropped the bigsmp driver because
+	  the build script specified *-bigsmp-ia32 instead of
+	  *-bigsmp-i586
+
+Version: 1.1.5-2413 ()
+
+build:
+	- Added 2.6.13-3 SuSE 10.0 pro
+	- Added 2.6.13-9 SuSE 10.0 pro
+
+compat.h:
+	- include linux/dma-mapping.h ahead of the MASK definitions to
+	  ensure that we do not enter into a situation where the
+	  definitions differ from what the driver utilizes. Purely a
+	  warning issues as the MASK does not differ at this time.
+
+compat.h+aachba.c: Jeff Garzik <jgarzik@pobox.com>
+	- replace scsicmd->device->id and scsicmd->device->channel with
+	  scmd_id(scsicmd) & scmd_channel(scsicmd) respectively.
+	- replace sdev->id with sdev_id(sdev);
+
+commctrl.c: Mark_Salyzyn@adaptec.com & Keith_Conner@adaptec.com
+	- aacraid thread restart needs to occur with the fib_lock
+	  released.
+
+aachba.c+aacraid.h+commctrl.c+comminit.c+commsup.c+csmi.c: Mark_Salyzyn@adaptec.com & Olivier Kaloudoff <kalou@kalou.net>
+	- changed to aac_fib_init defined and used in network code.
+
+aachba.c+commctlr.c+comminit.c:
+	- changed over from pci_map_single to pci_map_page.
+
+aachba.c:
+	- highmem_io was not set when using raw_io.
+
+commsup.c: Christoph Hellwig <hch@lst.de>
+	- replace Scsi_Device with scsi_device in comments to more
+	  accurately reflect the naming of the structure.
+
+commsup.c:
+	- Merged changes from scsi-misc-2.6
+
+Version: 1.1.5-2414 ()
+
+commsup.c: John_Hanson@adaptec.com
+	- perform the aac_probe_container after busy check, but before
+	  scan request to the OS.
+
+comminit.c+aachba.c+linit.c+dpcsup.c compat.h commsup.c aacraid.h
+	- Merged in changes from VMWARE
+
+comminit.c+aachba.c+linit.c+dpcsup.c+commsup.c+aacraid.h+csmi.c+commctrl.c
+	- fib_adapter_complete+fib_init+fib_alloc+fib_send+
+	  fib_complete+fib_free+fib_map_free+fib_setup+probe_container
+	  all have a prefix of aac_ to prevent name space collision when
+	  the driver is compiled into the kernel.
+
+aachba.c+linit.c+rx.c+rkt.c+README
+	- Merged changes from scsi-misc-2.6
+
+aachba.c: Ken Sandars <ken_sandars@adaptec.com>, John Hanson <John_Hanson@adaptec.com> & Mark_Salyzyn@adaptec.com
+	- SAI_READ_CAPACITY_16 compliance with sbc2r16
+
+build:
+	- Added 2.6.13-15 SuSE 10.0 pro
+
+Version: 1.1.5-2415 ()
+
+build:
+	- Added 2.6.12-1.1378_FC3-2.6
+	- Added 2.6.12-1.1380_FC3-2.6
+	- Added 2.6.12-1.1381_FC3-2.6
+	- Added 2.6.12-1.1456_FC4-2.6
+	- Added 2.6.13-1.1526_FC4-2.6
+	- Added 2.6.13-1.1532_FC4-2.6
+	- Added 2.6.9-22.8.EL
+
+aacraid.h+linit.c+commsup.c:
+	- Dell CERC card performs poorly when more than 17 sg elements
+	  are passed into the CHIM.
+
+Version: 1.1.5-2415-IBM ()
+
+aachba.c+commsup.c:
+	- revert change introduced to move aac_probe_container after
+	  busy check and instead decide not to take targets offline if
+	  they happen to be in the aac_probe_container state.
+
+build:
+	- Updated DKMS to 2.0.8
+
+aachba.c+commctlr.c+comminit.c+commsup.c+compat.h:
+	- pci_map_page was rejected by the community, code pulled.
+
+linit.c:
+	- scsi_bios_ptable return check is not in coding style.
+	- set skip_ms_page_8 to soften read cache page warning.
+
+linit.c+aachba.c+compat.h: Mark_Salyzyn@adaptec.com & Christoph Hellwig <hsh@infradead.org>
+	- Used CONTAINER_CHANNEL when matching the virtual channel 0
+	- use sdev_channel & sdev_id
+
+build:
+	- Add 2.4.9-e.62 to modules.equiv
+	- Add 2.4.9-e.65 to modules.equiv
+	- Add 2.6.14-1.1637_FC4-2.6 (FC4 errata)
+	- Add 2.6.14-1.1644_FC4-2.6 (FC4 errata)
+	- Add 2.6.9-22.0.1.EL-2.6 (RHEL4 errata)
+	- Corrected configuration of 2.6.5-7.224 (SuSE SP3 beta2)
+	- Add 2.6.5-7.236 (SuSE SP3 RC1)
+	- Add 2.6.5-7.243 (SuSE SP3 RC3)
+	- Add 2.6.5-7.244 (SLES9 SP3)
+	- Add 2.6.13-15.7 (SuSE 10 errata update)
+	- Add 2.6.5-7.224 as a module.equiv of 2.6.5-7.243
+	- Add 2.6.5-7.236 as a module.equiv of 2.6.5-7.243
+	- Add 2.6.5-7.193 as a module.equiv of 2.6.5-7.191
+
+aachba.c+rx.c+rkt.c+sa.c:
+	- Added support for an insmod parameter startup_timeout. The
+	  default value is set to 3 minutes for channel, 9 minutes for
+	  external.
+
+Version: 1.1.5-2416 ()
+
+linit.c:
+	- set skip_ms_page_3f to soften write enable warning.
+
+aachba.c+commsup.c:
+	- Added support for an insmod parameter aif_timeout. The default
+	  value is set to 2 minutes for channel, 9 minutes for external.
+
+Version: 1.1.5-2416-IBM ()
+
+build:
+	- Removed 2.6.5-7.224 (SLES9 sp3 b2)
+	- Removed 2.6.5-7.236 (SLES9 sp3 rc1)
+	- Removed driver disk support for 2.6.5-7.243 (SLES9 sp3 rc3)
+	- Added 2.6.9-22.EL i586 configuration (CentOS 4.2 i386 desktop)
+	- Added 2.6.9-27.EL (RHEL4 U3 rc)
+
+compat.h+linit.c: M.Gehre <M.Gehre@gmx.de>
+	- Added DMA_31BIT_MASK
+
+Version: 1.1.5-2417 ()
+
+Makefile: Martin Wilck <martin.wilck@fujitsu-siemens.com> & Mark_Salyzyn@adaptec.com
+	- SCSI_HAS_SCSI_SCAN_HOST should check for the presence of
+	  scsi_scan_host in the file.
+
+build:
+	- Moved ia64 and ppc architectures out of RHEL4 and CentOS disks
+	  and moved them into RHEL4-enterprise and CentOS-enterprise.
+	- Added support for reporting architectures in README.txt.
+	- Split sles9-sp's into their own sets, they were mixing with
+	  u11-sp's before.
+	- Adjusted Driver Disk ISO images, moved 2.6 RH kernels into the
+	  SuSE set, moving 2.4 RH kernels on their own. Added sl10. Have
+	  *not* dealt with sles9-sp's as they each require their own
+	  ISOs and will wait until the fan hits ...
+	- Added 2.6.14-1.1653_FC4 (FC4 errata)
+	- Added 2.6.14-1.1656_FC4 (FC4 errata)
+	- Added 2.6.11.4-21.10 (SuSE 9.3 errata)
+	- Added 2.6.9-22.25.EL
+
+commctrl.c:
+	- check the in_reset flag before attempting to restart the AIF
+	  thread.
+
+linit.c:
+	- Added /sys/class/scsi_host/host?/max_channel
+	- Added /sys/class/scsi_host/host?/max_id
+	- max_channel is '0' based, not 1 as it is currently treated.
+	- for kernels from 2.6.7 to 2.6.9 use inq_periph_qual as an
+	  equivalent to no_uld_attach.
+	- for kernels from 2.6.0 to 2.6.7 use inquiry[0] >> 5 as an
+	  equivalent to no_uld_attach.
+	- for kernels before 2.6.0 use type >> 5 as an equivalent to
+	  no_uld_attach.
+
+aachba.c:
+	- Added support for the expose_physicals insmod flag. This flag
+	  sets nondasd & turns off r/w protection for the physicals.
+	- for kernels from 2.6.7 to 2.6.9 use inq_periph_qual as an
+	  equivalent to no_uld_attach.
+	- for kernels from 2.6.0 to 2.6.7 use inquiry[0] >> 5 as an
+	  equivalent to no_uld_attach.
+	- for kernels before 2.6.0 read and write protect the drives.
+
+Version: 1.1.5-2418 ()
+
+build:
+	- Add 2.6.9-32.EL (RHEL4 U3 beta)
+	- Add 2.6.13-15.8 (SuSE 10 errata update)
+	- Add 2.4.21-4.17.EL (RHEL3 Gold 64 bit)
+	- Add 2.4.21-37.18AX (Miracle Linux 3)
+	- Add 2.6.5-7.252 (SLES9 update)
+	- Add 2.6.11.4-21.11 (SuSE 9.3 update)
+	- Add 2.6.15-git12-6 (SLES 10 beta 1)
+
+aachba.c:
+	- Data protect WRITE_LONG, WRITE_VERIFY, MODE_SELECT and
+	  LOG_SELECT.
+
+commsup.c:
+	- added lock_kernel/unlock_kernel around call to write_proc.
+
+aacraid.h+comminit.c+commsup.c+linit.c: Christoph Hellwig <hch@lst.de>
+	- use kthread_API
+
+commctrl.c:
+	- use kthread_API
+
+aachba.c: Takashi Iwai <tiwai@suse.de>
+	- Fix the comparison of sizeof()
+
+Version: 1.1.5-2419 ()
+
+build:
+	- Add 2.4.21-37.EL (RHEL3 U7 beta)
+	- Add 2.6.9-22.0.2.EL-2.6 (RHEL4 errata)
+
+linit.c+commsup.c+aachba.c+comminit.c:
+	- Merge cosmetic changes from scsi-misc-2.6
+
+linit.c+commsup.c+comminit.c+commctrl.c+aacraid.h
+	- kthread_API only invoked past 2.6.5-7.162 ADPmp95987
+
+commsup.c:
+	- Bumped up the AIF timeout to 30 seconds, the adapter could
+	  introduce delays in processing when in lockdrive. ADPmp94961?
+
+Version: 1.1.5-2420 ()
+
+build:
+	- Add 2.6.9-34.EL (RHEL4 U3)
+
+Version: 1.1.5-2419-IBM ()
+
+build:
+	- Add 2.4.21-40.EL (RHEL3 U7)
+
+commsup.c+commctrl.c+linit.c:
+	- Cosmetic changes merged from scsi-misc-2.6
+
+build:
+	- Split RHEL4 & CentOS driver disks into ia32 and x86_64 parts
+	- Dropped RHEL3 beta kernels 2.4.21-17.EL, 2.4.21-31.EL,
+	  and 2.4.21-38.EL from the RHEL3 driver disks.
+
+Version: 1.1.5-2420-HP ()
+Version: 1.1.5-2420-IBM ()
+
+build:
+	- Add 2.6.15-1.2054_FC5 (FC5 Gold)
+	- Add 2.4.21-37.ELvmnix (VMWare 3.1)
+	- Add 2.4.9-e.65 (RHAS2.1 errata 65)
+	- Add 2.4.9-e.68 (RHAS2.1 errata 68)
+	- Add 2.4.9-e.68 to modules.equiv
+	- Dropped 2.4.9-e.62 products (already in modules.equiv)
+
+linit.c:
+	- 32 bit applications in 64 bit space are not handled correctly
+	  in kernels above 2.6.10 for acquisition of AIFs ADPmp95861 &
+	  ADPmp95859.
+
+aacraid.h+linit.c+Makefile: Nobuhiro Tachino <ntachino@redhat.com>
+	- one can not ssleep or msleep during disk dump, so we call our
+	  own versions to differentiate and use mdelay instead during.
+
+aacraid.h+aachba.c+commctrl.c+commsup.c+linit.c:
+	- Merge in scsi-misc-2.6
+
+Version: 1.1.5-2421
+
+build:
+	- Add 2.6.16-rc5-git9-2 (SLES10 rc7)
+
+comminit.c: Andreas Mohr <andi@rhlx01.fht-esslingen.de>
+	- spelling correction.
+
+aacraid.h+linit.c+Makefile:
+	- Added support for diskdump under 2.6.16-rc5-git9-2.SuSE kernel
+
+Version: 1.1.5-2422
+
+build:
+	- Add 2.6.15-1.2054_FC5 (FC5)
+	- Fix 32 bit compile of 2.6.15-git12-6 (SLES10 beta 1)
+	- Fix 32 bit compile of 2.6.16-rc5-git9-2 (SLES10 beta 7)
+
+commsup.c+linit.c:
+	- moved locking around to fix problems with user initiated reset
+
+aachba.c+commsup.c+linit.c:
+	- Added a parameter to aac_get_config_status to request that the
+	  CT_COMMIT_CONFIG be issued. This is to ensure that the
+	  BlinkLED recovery always does a commit config. This change may
+	  morph as we get feedback from the external products.
+
+commsup.c:
+	- block scsi commands & wait for commands to flush before
+	  issuing the VM_CloseAll in the user initiated reset handler.
+
+install.sh:
+	- 'sort +2' is deprecated in FC5. Replace with 'sort -k 2'.
+
+Makefile:
+	- Dropped support for picking up linux/dumplib.h, the library
+	  did not appear to be present during install ADPmp96886. This
+	  reverts a change provided by RedHat by Nobuhiro Tachino
+	  <ntachino@redhat.com>
+
+aachba.c+commsup.c+aacraid.h:
+	- Dropped fib queue list, is not being used.
+
+Version: 1.1.5-2423
+
+README+linit.c:
+	- Hurricane8/4810SAS becomes Huricane44/3800SAS
+
+aachba.c:
+	- enabled aacraid_setup to function from the kernel command
+	  line.
+
+Version: 1.1.5-2424
+
+aachba.c+commsup.c: Alexy Dobriyan <adobriyan@gmail.com> and Eric Sesterhenn <smakebyte@qmx.de>
+	- BUG_ON conversion
+
+linit.c:
+	- clear_user returns 0 on success, not number of bytes zero'd
+	  [ADPmp95861]
+
+Version: 1.1.5-2425
+
+build:
+	- Add 2.4.21-40.6.EL (RHEL3 U8 beta)
+	- Add 2.4.21-41.EL (RHEL3 U8 beta)
+	- Add 2.4.21-43.EL (RHEL3 U8 beta)
+	- Add 2.6.15-1.1830_FC4 (FC4 errata)
+	- Add 2.6.15-1.1831_FC4 (FC4 errata)
+	- Add 2.6.15-1.1833_FC4 (FC4 errata)
+	- Add 2.6.16-1.2069_FC4 (FC4 errata)
+	- Add 2.6.16-1.2096_FC4 (FC4 errata)
+	- Add 2.6.16-1.2096_FC5 (FC5 errata)
+	- Add 2.6.16-1.2107_FC4 (FC4 errata)
+	- Add 2.6.16-1.2108_FC4 (FC4 errata)
+	- Add 2.6.16-1.2111_FC5 (FC5 errata)
+	- Add 2.6.9-34.19.EL (RHEL4 U4 beta)
+	- Add 2.6.9-36.1.EL (RHEL4 U4 beta)
+	- Add 2.6.9-36.EL (RHEL4 U4 beta)
+
+linit.c: Rafael_Ayala@adaptec.com & Mark_Salyzyn@adaptec.com
+	- diskdump_mode is not accessible in 2.4.21-27.EL (RHEL3 QU4)
+
+Version: 1.1.5-2426
+
+aacraid.h:
+	- debugging was turned on for the 1.1.5-2426 build :-(
+
+Version: 1.1.5-2427
+
+aachba.c:
+	- null check of aacraid variable in 2.4 ADPmp97630
+
+commsup.c:
+	- clear out count field in PAUSE_IO request.
+
+Version: 1.1.5-2428
+
+build:
+	- Add 2.6.5-7.257 (SLES9 errata)
+	- Moved 2.6.8-24.11 to module.equiv as alias to 2.6.8-24.21
+	- Moved 2.6.8-24.14 to module.equiv as alias to 2.6.8-24.21
+	- Moved 2.6.8-24.17 to module.equiv as alias to 2.6.8-24.21
+	- Moved 2.6.8-24.18 to module.equiv as alias to 2.6.8-24.21
+	- Moved 2.6.8-24.19 to module.equiv as alias to 2.6.8-24.21
+	- Moved 2.6.8-24.20 to module.equiv as alias to 2.6.8-24.21
+	- Add 2.6.8-24.21 (SuSE 9.2 errata)
+	- Moved 2.6.11.4-21.7 to module.equiv as alias to 2.6.11.4-21.9
+	- Moved 2.6.11.4-21.8 to module.equiv as alias to 2.6.11.4-21.9
+	- Moved 2.6.11.4-21.10 to module.equiv as alias to 2.6.11.4-21.11
+	- Add 2.6.11.4-21.12 (SuSE 9.3 errata) Not quite 100% match to 2.6.11.4-21.11, may work, risk not taken today.
+	- Moved 2.6.13-15.8 to module.equiv as alias to 2.6.13-15.8
+	- Add 2.6.13-15.10 (SuSE 10 errata)
+	- Add 2.6.16.16-1.6 (SLES10/SLED10 RC2)
+
+aachba.c+commctrl.c: Tobias Klauser <tklauser@neurscht.ch> & Andrew Morton <akpm@osdl.org>
+	- use ARRAY_SIZE macro
+
+aachba.c: Christoph Hellwig <hch@lst.de>
+	- fix up request buffer reference
+
+aachba.c: Tejun Heo <htejun@gmail.com>
+	- add cpu cache flushes after kmapping and modifying a page
+
+commsup.c+aacraid.h:
+	- Added support for IOP_RESET_ALWAYS
+
+Version: 1.1.5-2429
+
+build:
+	- Moved 2.6.16-1.2107_FC4-2.6 to module.equiv as alias to 2.6.16-1.2108_FC4-2.6
+	- Moved 2.6.16-1.2069_FC4-2.6 to module.equiv as alias to 2.6.16-1.2096_FC4-2.6
+	- Moved 2.6.15-1.1831_FC4-2.6 to module.equiv as alias to 2.6.15-1.1833_FC4-2.6
+	- Moved 2.6.15-1.1830_FC4-2.6 to module.equiv as alias to 2.6.15-1.1833_FC4-2.6
+	- Moved 2.6.14-1.1637_FC4-2.6 to module.equiv as alias to 2.6.14-1.1644_FC4-2.6
+	- Moved 2.6.13-1.1526_FC4-2.6 to module.equiv as alias to 2.6.13-1.1532_FC4-2.6
+	- Moved 2.6.12-1.1390_FC4-2.6 to module.equiv as alias to 2.6.12-1.1398_FC4-2.6
+	- Moved 2.6.12-1.1387_FC4-2.6 to module.equiv as alias to 2.6.12-1.1398_FC4-2.6
+	- Moved 2.6.12-1.1378_FC3-2.6 to module.equiv as alias to 2.6.12-1.1381_FC3-2.6
+	- Moved 2.6.10-1.770_FC3-2.6 to module.equiv as alias to 2.6.10-1.760_FC3-2.6
+	- Moved 2.6.10-1.766_FC3-2.6 to module.equiv as alias to 2.6.10-1.760_FC3-2.6
+	- Moved 2.6.9-22.25.EL-2.6 to module.equiv as alias to 2.6.9-5.0.3.EL-2.6
+	- Moved 2.6.5-7.243 (+aliases) to module.equiv as alias to 2.6.5-7.244
+	- Moved 2.6.5-7.257 to module.equiv as alias to 2.6.5-7.244
+	- Moved 2.4.21-17.EL to module.equiv as alias to 2.4.21-15.EL
+	- Moved 2.4.21-38.EL to module.equiv as alias to 2.4.21-37.EL
+	- Moved 2.4.21-41.EL to module.equiv as alias to 2.4.21-43.EL
+	- Moved 2.4.21-243 to module.equiv as alias to 2.4.21-241
+	- Moved 2.4.21-251 to module.equiv as alias to 2.4.21-241
+	- Moved 2.4.21-260 to module.equiv as alias to 2.4.21-241
+	- Moved 2.4.21-261 to module.equiv as alias to 2.4.21-241
+	- Moved 2.4.21-273 to module.equiv as alias to 2.4.21-241
+	- Moved 2.4.18-26.8.0 to module.equiv as alias to 2.4.18-24.8.0
+
+commsup.c+comsup.c:
+	- Allow a waiting aac_fib_send to be interruptible ADPmp97267.
+
+Version: 1.1.5-2429-IBM ()
+
+build:
+	- Moved 2.6.8-24.23 to module.equiv as alias to 2.6.8-24.21 (+aliases)
+	- Added 2.6.16.20-0.12 (SLES10 RC3)
+	- Added 2.4.21-37.ELvmnix as alias to 2.4.21-27.ELvmnix. This
+	  relationship has not been proven, added for expediency.
+	- Added 2.4.21-37.0.2.ELvmnix, Compile issue remains.
+
+comminit.c:
+	- Merge kernel.org change to drop GART definition in 2.6.17+
+
+Version: 1.1.5-2430 ()
+
+build:
+	- Added 2.6.16.21-0.8 (SLES10/SLED10)
+	- Added VMware.mak
+
+aachba.c+comminit.c+linit.c+compat.h+rx.c:
+	- Merge changes from 2.4.21-37.0.2.ELvmnix/drivers/scsi/aacraid_esx30/
+
+rkt.c+rx.c+sa.c+compat.h: Thomas Gleixner <tglx@linutronix.de>
+	- scsi: Use the new IRQF_ constansts
+
+Version: 1.1.5-2431 ()
+
+build:
+	- Added 2.6.9-42.EL (RHEL4 U4)
+	- Added 2.4.21-47.EL (RHEL3 U8)
+
+Version: 1.1.5-2431-IBM ()
+Version: 1.1.5-2432 ()
+
+build:
+	- Added 2.6.16.13-4 (SuSE 10.1)
+	- Added 2.6.16-1.2111_FC4 (FC4 errata)
+	- Added 2.6.16-1.2115_FC4 (FC4 errata)
+	- removed 2.6.16-1.2107_FC4, alias of 2.6.16-1.2111_FC4
+	- removed 2.6.16-1.2108_FC4, alias of 2.6.16-1.2111_FC4
+	- Added 2.6.17-1.2139_FC4, alias of 2.6.17-1.2142_FC4
+	- Added 2.6.17-1.2141_FC4, alias of 2.6.17-1.2142_FC4
+	- Added 2.6.17-1.2142_FC4 (FC4 errata)
+	- Added 2.6.16-1.2122_FC5 (FC5 errata)
+	- removed 2.6.16-1.2111_FC5, alias of 2.6.16-1.2122_FC5
+	- Added 2.6.16-1.2133_FC5 (FC5 errata)
+	- Added 2.6.17-1.2139_FC5, alias of 2.6.17-1.2157_FC5
+	- Added 2.6.17-1.2145_FC5, alias of 2.6.17-1.2157_FC5
+	- 2.6.17-1.2157_FC5 (FC5 errata)
+	- removed 2.6.9-22.0.1.EL-2.6, alias of 2.6.9-22.0.2.EL-2.6
+	  (RHEL4 errata)
+	- removed 2.4.21-199 as alias to 2.4.21-278
+	- removed 2.4.21-169 as alias to 2.4.21-278
+	- removed 2.4.18-27.7.x as alias to 2.4.18-19.7.x
+	- removed 2.4.18-27.8.0 as alias to 2.4.18-24.8.0
+	- removed 2.4.9-38 as alias to 2.4.9-31
+	- removed 2.6.11.4-21.11 as alias to 2.6.11.4-21.12
+	- remove aacraid_patches, they do not appear to be relevant
+	  anymore.
+	- problem with 2.6.9-42.EL due to presence of localvers file in
+	  configuration.
+
+aachba.c: Mike Christie <michaelc@cs.wisc.edu>
+	- Convert scsi to the block layer request timer code. The block
+	  layer functions are exactly the ones that used to live in
+	  scsi, so the conversion is rename.
+
+rx.c+rkt.c:
+	- Report the OMRx[0] status if the Adapter is in a Panic state
+	  on init.
+	- Merge rx and rkt code.
+
+sa.c+rx.c+rkt.c+nark.c:
+	- Added support for split bar, by adding an ioremap function.
+
+aachba.c+commsup.c:
+	- return EBUSY, instead of ENODEV, when we are in the middle of
+	  an adapter reset. No consequence to existing management code.
+
+commsup.c:
+	- on adapter reset, make sure we close all outstanding ioctl
+	  commands as well.
+	- Added additional AIF instrumentation code.
+	- Do not call scsi_remove_device as it leaves kref droppings.
+
+install.sh
+	- output of grep fell on floor, every rpm install adds yet
+	  another hostadapter instance. Only side effect was growth of
+	  /etc/modules.conf or /etc/modprobe.conf files.
+
+Version: 1.1.5-2432-IBM ()
+
+build:
+	- problem with 2.6.9-42.EL, 2.6.9-36.1.EL, 2.6.9-36.EL,
+	  2.6.9-34.19.EL, 2.6.9-34.EL, 2.6.9-32.EL, 2.6.9-27.EL
+	  & 2.6.9-22.25.EL with 64 bit largesmp configurations stomping
+	  all over the UP configurations. ADPml01331.
+
+aachba.c+rx.c+commsup.c:
+	- Merge from scsi-misc-2.6, cosmetics.
+
+commsup.c:
+	- Do not call scsi_remove_device as it leaves kref droppings.
+
+Version: 1.1.5-2433-IBM ()
+Version: 1.1.5-2433 ()
+
+build:
+	- 2.4.21-47.EL (RHEL3 U8) was misconfigured when placing
+	  ia32e (em64t) products on the floppy disk.
+
+Version: 1.1.5-2434-IBM ()
+
+build:
+	- Upgraded to VMware DDK v1.0
+	- Altered VMware.inc, VMware.mak, VMware.spec and added
+	  VMware.xml to merge new DDK changes in the asa7211 sample
+	  source (still does not work on latest ESX release).
+	- esxcfg-pciid needed to be made an optional artifact in the
+	  rpm postinstall
+	- use aacraid.xml rather than Vmware.xml for the pciids file.
+	- fill out *all* the pciids in /etc/vmware/pciid/aacraid.xml.
+	- accept vmware-hwdata version 0.99, the DDK's value of 1.00
+	  must be for a followon OS
+	- Added linux_module_heap.c to the source file list to fill in
+	  for some of the linux-kernel-style API, ESX 3.0 deprecated
+	  since the beta.
+	- Add 2.6.8-24.24 (SuSE 9.2 errata)
+	- Remove 2.6.8-24.23 (SuSE 9.2 errata) as alias to 2.6.8-24.24
+	- Changed 2.6.8-24.11 (SuSE 9.2 errata) as alias to 2.6.8-24.24
+	- Changed 2.6.8-24.14 (SuSE 9.2 errata) as alias to 2.6.8-24.24
+	- Changed 2.6.8-24.17 (SuSE 9.2 errata) as alias to 2.6.8-24.24
+	- Changed 2.6.8-24.18 (SuSE 9.2 errata) as alias to 2.6.8-24.24
+	- Changed 2.6.8-24.19 (SuSE 9.2 errata) as alias to 2.6.8-24.24
+	- Changed 2.6.8-24.20 (SuSE 9.2 errata) as alias to 2.6.8-24.24
+	- Changed 2.6.8-24.21 (SuSE 9.2 errata) as alias to 2.6.8-24.24
+	- Add 2.6.11.4-21.13 (SuSE 9.3 errata)
+	- Remove 2.6.11.4-21.12 (SuSE 9.3 errata) as alias to
+	  2.6.11.4-21.13
+	- Changed 2.6.11.4-21.11 (SuSE 9.3 errata) as alias to
+	  2.6.11.4-21.13
+	- Changed 2.6.11.4-21.10 (SuSE 9.3 errata) as alias to
+	  2.6.11.4-21.13
+	- Add 2.6.13-15.11 (SuSE 10.0 errata)
+	- Remove 2.6.13-15.10 (SuSE 10.0 errata) as alias to
+	  2.6.13-15.11
+	- Add 2.6.5-7.267 (SLES9 errata) to module.equiv as alias to
+	  2.6.5-7.244
+	- Add 2.6.5-7.276 (SLES9 errata) to module.equiv as alias to
+	  2.6.5-7.244
+	- Add 2.6.17-1.2519.4.21.el5 (RHEL5 beta1)
+	- Added gcc 4.1.1 to cross compiler set
+	- Added adaptec.spec to adaptec.spec
+
+Version: 1.1.5-2434 ()
+
+README+linit.c+DUD:pcitable:
+	- Changed product names to reflect dropping SAS post-script
+	  when card supports SATA as well.
+
+install.sh:
+	- Added detection of /sbin/vmware-mkinitrd
+
+build:
+	- Moved add-on makes (VMware.* namely) to after the compile
+	  section, but before the prebuilt section so that we can also
+	  populate the rpm.
+	- Added 2.4.9-e.70 to module.equiv file.
+	- Removed 2.6.17-1.2157_FC5 & friends and added them as an alias
+	  of 2.6.17-1.2187_FC5
+	- Added 2.6.17-1.2174_FC5, alias of 2.6.17-1.2187_FC5
+	- Added 2.6.9-42.0.2.EL (RHEL4 errata)
+	- Added 2.6.9-34.0.1.EL as alias to 2.6.9-42.0.2.EL
+	- Added 2.6.9-34.0.2.EL as alias to 2.6.9-42.0.2.EL
+	- Corrected largesmp configurations for x86_64 and ppc64
+	  environments for RHEL4
+	- Corrected kdump configurations for FC5
+
+VMware.mak:
+	- Copy module products to OBJECT_DIR using appropriate names.
+
+comminit.c:
+	- Somehow, debugging left new_comm off, turned it back on.
+	- Added some additional debugging for init struct
+	  investigations, ifdef'd out so no side effects.
+
+commsup.c:
+	- Give a little extra time for the ioctl to complete under
+	  resetiop.
+
+commctrl.c:
+	- return ioctl busy when controller is in reset state.
+
+aacraid.h+rx.c+sa.c+commsup.c+comminit.c:
+	- Added platform functions for interrupt enable, interrupt
+	  handling, packet delivery and transport selection.
+
+aacraid.h+aachba.c:
+	- Added platform functions for bounds checking, read and write.
+
+rx.c+rkt.c+nark.c:
+	- Consolidate startup routines due to addition of transport
+	  selection.
+
+aachba.c:
+	- Move probe_container into aac_get_containers
+
+linit.c:
+	- Added 9005/0288 family (split BAR)
+
+Version: 1.1.5-2435 ()
+
+linit.c+README:
+	- Any references to ICP R0, should be replaced with ICP RO.
+
+aachba.c:
+	- adapter_write is never filled out (ADPml02706)
+
+Version: 1.1.5-2436 ()
+
+README:
+	- Trimmed and Updated list of supported controllers.
+
+build:
+	- Added 2.6.18-1.2747.el5 (RHEL5 beta2)
+
+aachba.c:
+	- Added checking of the parameters fed to the
+	  aac_internal_transfer function (ADPml02711)
+
+install.sh:
+	- Follow KMP guidelines and install driver into the /updates
+	  directory before considering overriding as-shipped driver
+	  modules.
+
+Version: 1.1.5-2437 ()
+
+aacraid.h+aachba.c:
+	- Create _aac_probe_container as a asynchronous response
+	  version of aac_probe_container.
+	- Removed nested, no longer needed for _aac_probe_container.
+
+linit.c+aachba.c:
+	- expose_physicals is now in three states. Default behavior is
+	  to expose protected DASD physical devices, 0 now blocks the
+	  DASD devices and 1 forces full access to those physical
+	  devices.
+
+intall.sh:
+	- some problems with placing modules.dep in updates/modules.dep
+	- speedup dealing with KMP matching.
+
+Version: 1.1.5-2438 ()
+
+aachba.c:
+	- expose_physicals=0 did not work for kernels 2.6.10 and higher.
+
+commsup.c:
+	- we do not deal with a case of a command aborted between
+	  command setup and wait for completion. We also should perform
+	  the BUG_ON check for done within an event lock? (ADPml01735)
+
+aacraid.h+comminit.c+dpcsup.c+rx.c+release.sh+aachba.c:
+	- Adding APRE transport code, ifdef'd with
+	  INITFLAGS_APRE_SUPPORTED
+
+aacraid.h+commctrl.c+commsup.c+csmi.c+dpcsup.c+rx.c
+:
+	- change hw_fib references to hw_fib_va to prevent namespace
+	  collision with struct hw_fib.
+
+install.sh:
+	- corrected minor scripting problem.
+
+Version: 1.1.5-2439 ()
+
+rx.c+commsup.c:
+	- Support USE_OTHER_METHOD for Sunrise Lake IOP reset.
+
+rx.c+comminit.c+aacraid.h+linit.c:
+	- Merge changes in 2.6.20 into driver, dropping pt_regs from
+	  interrupt service routines.
+
+rkt.c:
+	- Merge in changes due to code inspection.
+
+linit.c+aachba.c: Mark Salyzyn & Christoph Hellwig
+	- Use slave configure returning ENXIO to block physicals for
+	  2.6.15+
+
+aachba.c+aacraid.h+comminit.c+linit.c+rkt.c+rx.c+sa.c:
+	- Backmerge scsi-misc-2.6 tree, all cosmetic style issues.
+
+aachba.c: Mark Salyzyn & Christoph Hellwig <hch@infradead.org>
+	- Removed kernel command line parsing from 2.6 based kernels,
+	  already implemented as <module>.<parm>=
+
+install.sh:
+	- Do not check for specifically AMD-K7 or AMD athlon processors
+	  when determining athlon support, instead accept just AMD as
+	  enough of an indicator (ADPml03707)
+
+Version: 1.1.5-2440 ()
+
+build:
+	- Add 2.6.18-8.el5 (RHEL5 RC/GA)
+	- Removed 2.6.17-1.2519.4.21.el5 (RHEL5 beta1)
+	- Removed 2.6.18-1.2747.el5 (RHEL5 beta2)
+	- Removed 2.6.16.20-0.12 (SLES10 RC3) (ADPml03802)
+
+aacraid.h+linit.c+nark.c+rkt.c+rx.c: Adrian Bunk <bunk@susta.de>
+	- Manually applied a cleanup patch that moves function externs
+	  to aacraid.h rather then defined and referenced where needed.
+
+install.sh:
+	- Do not process Module.symvers variants until primary modules
+	  and module.equiv variants are discovered and fleshed out
+	  (ADPml03802)
+
+Version: 1.1.5-2441 ()
+
+build:
+	- Removed 2.6.15-git12-6 (SLES10 beta 1)
+	- Removed 2.6.16-rc5-git9-2 (SLES10 beta 7)
+	- Removed 2.6.16.16-1.6 (SLES10/SLED10 RC2)
+
+commctrl.c:
+	- Added code to sense if the incoming frame has 64 bit sg.
+	  (ADPml03719)
+
+Version: 1.1.5-2441-IBM ()
+Version: 1.1.5-2442 ()
+
+build:
+	- Added 2.4.9-e.71 to modules.equiv
+	- Added 2.6.9-42.0.3.EL to modules.equiv
+	- Added 2.6.9-42.0.8.EL to modules.equiv
+
+linit.c+dpcsup.c+comminit.c+commctrl.c:
+	- Switch from (unsigned long) or (long) casts to (ptrdiff_t)
+	  casts wherever the intent is to convert a pointer to a
+	  same sized integer or back.
+
+comminit.c+rx.c+commsup.c:
+	- Suppress compile warning messages, change kernel version
+	  ifdefs to accomodate.
+
+README+DUD:pcitable+VMWare.xml+DKMS:readme.txt.orig:
+	- Added 9005:0285:108e:7aac for SUN RAID 4i4e
+	- Added 9005:0285:15d9:02b5 for SMC AOC-USAS-S4i (ADPml04007)
+	- Added 9005:0285:15d9:02b6 for SMC AOC-USAS-S8i (ADPml04007)
+	- Added 9005:0285:15d9:02c9 for SMC AOC-USAS-S4iB (ADPml04007)
+	- Added 9005:0285:15d9:02ca for SMC AOC-USAS-S8iB (ADPml04007)
+
+dpcsup.c+linit.c+aacraid.h+commsup.c:
+	- Set the FIB_CONTEXT_FLAG_TIMED_OUT flag for the commands that
+	  are involved in error recovery; when the completion interrupt
+	  happens, simply free the fib resources, do not complete the
+	  command to the OS. (ADPml03975)
+
+commsup.c+aachba.c:
+	- Widen the net for capturing 'busy' to also include the
+	  eh_active state flag if available. (ADPml03975)
+
+linit.c:
+	- For kernels from 2.6.0 to 2.6.12 we set the queue_depth of the
+	  device to zero during the error recovery handler to trick the
+	  LOWER layers to block commands. These kernels have a locking
+	  bug where the error handler holds the host_lock, but commands
+	  issued by user or plug-n-play scan requests manage to slip
+	  through and hit the LOWER layers where host_lock is taken as
+	  well *before* the host check for whether we are in error
+	  recovery or not. Later kernels do not take the host_lock in
+	  the error recovery (ADPml03975)
+	- Added an aac_eh_abort handler, simply testing for TUR and
+	  setting FIB_CONTEXT_FLAG_TIMED_OUT flag and return SUCCESS.
+	  Return FAILED for any other command. TUR is simple enough
+	  that the outstanding portions of the request in the Adapter
+	  are inert. We could apply this to INQUIRY and READ CAPACITY
+	  for the same reasons ... but chose not to at this time
+	  (ADPml03975)
+
+aachba.c:
+	- If the device is offline when the completion handler is called,
+	  free the FIB resources and return in srb_callback (ADPml03975)
+
+Version: 1.1.5-2443 ()
+
+linit.c:
+	- For kernels from 2.6.0 to 2.6.12 we also set the
+	  device_blocked flag during the error recovery handler to trick
+	  the LOWER layers to block commands (ADPml03975)
+	- When we wake up from a sleep, before retaking the locks,
+	  innoculate the block I/O for kernels 2.6.0 through 2.6.12.
+	  (ADPml03975).
+	- The 2.4 calculation for queuedepth erroneously divided the
+	  entire pool for every known target, this limits the number
+	  of outstanding commands available for the logicals by too
+	  much.
+	- If we have a definition of crashdump_mode that we can live
+	  with, let us call aac_poll during error recovery even if
+	  we do not have the ability to enhance msleep or ssleep
+	  calls (ADPml04175).
+	- Simon Waters <simonw@zynet.net> discovered a panic in
+	  vsnprintf within aac_procinfo. I added checking of
+	  (bytes_available - total_len) to make sure it is never
+	  negative in value.
+	- Modified abort handler to close all device related commands.
+
+rx.c:
+	- optimized code by using likely() and unlikely() conditional
+	  hints.
+	- RESET_IOP, RESET_IOP_ALWAYS and RESET_IOP_ALTERNATE handling
+	  adjusted. Added recognition of AAC_FEATURE_MU_RESET.
+
+aacraid.h:
+	- Added definition for AAC_FEATURE_MU_RESET
+
+aachba.c:
+	- If the device is offline when the completion handler is
+	  called, free the FIB resources and return in io_callback,
+	  _aac_probe_container2 and get_container_name_callback
+	  (ADPml03975)
+	- Added instrumentation to report if a scsi command is corrupt.
+	- Adjusted the command line handling to be compliant with
+	  2.6 standards (aacraid.parm=value) and add the 'dd' flag
+	  recognition to set the expose_physicals flag to zero
+	  (ADPml04274)
+	- Added command line parsing 'back' into 2.6 version, but only
+	  perform the parsing for the 'dd' parameter (ADPml04274)
+	- Added a 'dud' parameter that when set, set the
+	  expose_physicals flag to zero (ADPml04274)
+	- When a command goes through the error handler, it gets
+	  reissued to the controller, so that we have multiple FIBs
+	  referencing the same command. Drop the re-issued command on
+	  the floor if it is already on the Adapter (ADPml03975).
+
+linit.c+aacraid.h:
+	- turn on diskdump_mdelay, diskdump_msleep and diskdump_ssleep
+	  even though we do not have DUMPLIB support. Remove calls to
+	  diskdump_update, which did not export under RHEL4 until U6
+	  (ADPml04175)
+
+Version: 1.1.5-2444-IBM ()
+
+build:
+	- Added 2.6.18-1.2200.fc5-2.6 as equivalent to 2.6.18-1.2239.fc5-2.6
+	- Added 2.6.18-1.2239.fc5-2.6
+	- Added 2.6.18-1.2257.fc5-2.6
+	- Added 2.6.18-1.2798.fc6
+	- Added 2.6.18-1.2849.fc6-2.6 as equivalent to 2.6.18-1.2869.fc6-2.6
+	- Added 2.6.18-1.2868.fc6-2.6 as equivalent to 2.6.18-1.2869.fc6-2.6
+	- Added 2.6.18-1.2869.fc6-2.6
+	- Added 2.6.19-1.2895.fc6-2.6 as equivalent to 2.6.19-1.2911.fc6-2.6
+	- Added 2.6.19-1.2911.fc6-2.6
+	- Moved 2.6.9-27.EL (RHEL4 U3 rc) as equivalent to 2.6.9-34.EL (RHEL4 U3)
+	- Moved 2.6.9-32.EL (RHEL4 U3 beta) as equivalent to 2.6.9-34.EL (RHEL4 U3)
+	- Moved 2.6.5-7.252 (SLES9 update) as equivalent to 2.6.5-7.244 (SLES9 SP3)
+
+aachba.c:
+	- Fix some compiler warnings associated with typecasting
+	  constants to scsi_done.
+	- if HAS_BOOT_CONFIG is enabled, default for expose_physicals
+	  is zero (ADPml04274)
+	- When issuing the probe_container, we need to set the device
+	  as online so it passes the device validity check (ADPml04333,
+	  ADPml04331 and ADPml03975)
+
+linit.c:
+	- For kernels from 2.6.0 to 2.6.12 we set the queue_depth of the
+	  device to zero and the device_blocked flag during the error
+	  recovery abort handler to trick the LOWER layers to block
+	  commands. These kernels have a locking bug where the error
+	  handler holds the host_lock, but commands issued by user or
+	  plug-n-play scan requests manage to slip through and hit the
+	  LOWER layers where host_lock is taken as well *before* the
+	  host check for whether we are in error recovery or not.
+	  Later kernels do not take the host_lock in the error recovery
+	  abort handler (ADPml03975)
+	- When we wake up from a printk, or possible dprintk,
+	  innoculate the blocking I/O for kernels 2.6.0 through 2.6.12
+	  and consider altering the locks (ADPml03975).
+	- List of outstanding commands is for a device, so no need to
+	  repeat the debug information outlining the id for each command.
+
+Makefile+aacraid.h:
+	- Define HAS_BOOT_CONFIG if in a limited resource driver, remove
+	  optional pieces. This is one means to compress the resources
+	  on the precious floppy disks. (ADPml04333)
+
+install.sh:
+	- Code to detect the existence of the /updates/ placement was
+	  adjusted from an erroneous 'for' loop into a 'if' test.
+	  (ADPml04333)
+	- Do not complain if the modules.cgz is truncated, if it can
+	  not provide the module, it will be evident later as missing.
+	  (ADPml04333)
+
+sa.c:
+	- aac_sa_init drops pt_regs argument for kernels above 2.6.18
+
+Version: 1.1.5-2445-IBM ()
+
+build:
+	- Added 2.6.11.13mdk-1-1mdk
+	- Added 2.6.12.21mdk-1-1mdk
+
+aachba.c+linit.c+release.sh:
+	- Added BOOTCD ifdef to fortify initialization time firmware
+	  print diagnostics for these configurations.
+
+Version: 1.1.5-2444 ()
+
+build:
+	- Added 2.6.18-8.1.1.el5-2.6
+	- Moved 2.6.9-36.EL as alias to 2.6.9-42.EL
+	- Added 2.6.9-42.0.10.EL
+	- Added 2.6.19-1.2288.fc5
+	- Added 2.6.19-1.2288.2.1.fc5 as alias to 2.6.19-1.2288.2.4.fc5
+	- Added 2.6.19-1.2288.2.4.fc5
+	- Added 2.6.19-1.2911.6.4.fc6 as alias to 2.6.19-1.2911.6.5.fc6
+	- Added 2.6.19-1.2911.6.5.fc6
+	- Added 2.6.20-1.2925.fc6
+
+aachba.c:
+	- Added display of TSID.
+
+install.sh:
+	- for ia32e configuration, any Intel processor running currently
+	  on a 64 bit kernel will do (Son of ADPml04333 and ADPml103707)
+
+Version: 1.1.5-2446-IBM ()
+
+build:
+	- Moved FC ia64 and ppc binaries on driver disks into an
+	  FC-enterprise disk to free up mainstream space since fc6
+	  release.
+	- Moved 2.6.5-7.134 (SLES9 SP1 RC) as alias to 2.6.5-7.139
+	  (SLES9 SP1)
+
+Version: 1.1.5-2445 ()
+
+build:
+	- Added support for RedHat modules.alias file. Base design
+	  on ddiskit-0.9.8. Maybe one day we could use RedHat's
+	  scripting merged into our meta-build.
+
+linit.c+aachba.c+rx.c+dpcsup.c+commsup.c+comminit.c+commctrl.c+aacraid.h:
+	- Adjust code to reflect a back-port of scsi-misc-2.6
+	  March 21 2006 snapshot. All changes are cosmetic.
+
+Makefile+aacraid.h:
+	- Added HAS_SECTOR_T and check for definition of sector_div
+	  macro. If sector_t is 64 bit, then make sure that the return
+	  value maxes out rather than wraps.
+	- Added kdump config detection, turns off SCSI_HAS_DUMP.
+
+README+DUD:pcitable+VMWare.xml+DKMS:readme.txt.orig+Linux:pci.ids:
+	- Changed 9005:0285:108e:7aac to SUN STK RAID REM
+	- Added 9005:0285:108e:0286 for SUN SG-XPCIESAS-R-IN
+	- Added 9005:0285:108e:0287 for SUN SG-XPCIESAS-R-EX
+	- Changed 9005:0285:15d9:02c9 for SMC AOC-USAS-S4iR
+	- Changed 9005:0285:15d9:02ca for SMC AOC-USAS-S8iR
+
+rx.c+aachba.c:
+	- For 2.6.19 and above, use reset_devices flag, for others
+	  read the command line and pick up the reset_devices kernel
+	  flag. Reset the adapter as part of initialization.
+	- Check if the interrupts have been enabled, this is a
+	  fine clue that another driver preceded this one. Useful
+	  for hot transitions from one operating system to the
+	  next (kexec and kdump are but two examples). This is a
+	  substitute for the forced reset_devices flag.
+
+linit.c:
+	- Added kernel version or UTS_RELEASE to the Firmware Print
+
+linit.c+csmi.c+aachba.c:
+	- Changed serial number printout from %x to %06X format.
+
+sa.c:
+	- added aac_sa_restart_adapter method stub.
+
+rx.c: Mark Salyzyn <aacraid@adaptec.com> & Duane Cox <dcox@conxxus.com>
+	- Set adapter_sync_cmd before permitting adapter reset
+	  commands.
+	- If we restart the adapter in the context of the driver,
+	  extend startup timeouts less than 5 minutes to 5 minutes.
+
+Makefile:
+	- Also look in drivers/scsi/scsi_scan.c for scsi_scan_host()
+
+linit.c:
+	- Added driver_version to sysfs
+	- added support for 12 digit serial number.
+	- exported aac_show_serial_number for aachba and csmi.c
+	- Lock mishandling when debugging off (ADPml03975).
+
+aachba.c+csmi.c:
+	- Call aac_show_serial_number to acquire serial number value.
+
+commctrl.c+commsup.c+linit.c:
+	- Turn off ioctl and aif support if using the BOOT
+	  configuration to save space.
+
+aachba.c:
+	- dropped definition of min(a,b) because it is in compat.h
+	- ifdef on 2.6.21 to saved_command_line as a pointer
+	  Steve Fox <drfickle@linux.vnet.ibm.com>
+	- Drop check for HIDDEN as this is not compatible with older
+	  hardware.
+
+fwdebug.c:
+	- if in_atomic(), just time out immediately rather than wait
+	  for the Firmware to catch up
+
+Version: 1.1.5-2446 ()
+
+build:
+	- Added 2.6.9-55.EL (RHEL4 U5)
+	- Added to all legacy RH releases the RHEL_VERSION and
+	  RHEL_UPDATE that correspond with this releases.
+
+aachba.c+comminit.c+commsup.c+dpcsup.c:
+	- replace kmalloc/memset pairs with kzalloc where possible.
+
+fwdebug.c:
+	- use vsnprintf to protect the on-stack firmware buffer.
+	- Add buffering to guarantee delivery of messages issued
+	  during interrupt service routines. Easier said than done,
+	  and includes references to architectural specific assembler
+	  fragment helpers to help maintain atomic operations.
+	- Fortified the conditions where we time out immediately
+	  rather than wait for the Firmware to catch up. These
+	  include host locks, interrupt contexts and when error
+	  recovery actions are currently active. We only allow a
+	  sleep, effectively, at the [aacraid] background thread.
+	- Switch to using readb,readl,writeb,writel to communicate
+	  with the Firmware print buffer, enforce ordering by doing a
+	  readback shortly before issuing the count.
+
+commsup.c:
+	- polled fwprint in adapter kernel thread.
+
+aacraid.h+commsup.c+linit.c:
+	- Added the ability to force an IOP_RESET_ALWAYS from user
+	  initiated sources. 'reset_host!' to the proc node, or
+	  and '!' written to the sys reset_host node.
+
+README+DUD:pcitable+VMWare.xml+DKMS:readme.txt.orig+Linux:pci.ids:
+	- Changed 9005:0285:108e:0286 for SUN STK RAID INT
+	- Changed 9005:0285:108e:0287 for SUN STK RAID EXT
+
+install.sh:
+	- Added support to decode xen and xen Linux executables,
+	  file's magic was not up to the task.
+
+grub.awk:
+	- Added support to detect a xen boot configuration and lift
+	  out the Linux kernel and initrd references.
+
+linit.c:
+	- Added support for recognizing the RHEL_VERSION and
+	  RHEL_UPDATE when reporting to the fwprint
+	- aac_queuedepth for 2.4 kernels did not check if the
+	  incoming scsi_device was a nul or not (ADPml05512)
+
+aacraid.h+linit.c:
+	- Given the apparent instability of long term use of
+	  fwprintf, I suggest keeping it off for releases except
+	  on the bootable CD where things are more controlled. To
+	  aid in that, have added fwprintf next to the dprintk
+	  flag output in /proc and /sys.
+
+aachba.c:
+	- Turn off physicals access by default on the Bootable CD,
+	  allow it to be changed by insmod paramters unlike the
+	  BOOT config which was motivated by code space issues.
+
+rx.c+commctrl.c:
+	- Added more AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB
+	  instrumentation (ADPml04695)
+
+Version: 1.1.5-2447-IBM ()
+
+rx.c+sa.c+aacraid.h: Mark Salyzyn & Rainer Malitzke <malitzke@metronets.com>
+	- Initialize adapter_deliver with aac_rx_deliver_producer
+	  (http://bugzilla.kernel.org/show_bug.cgi?id=8469)
+
+csmi.c:
+	- linux/ioctl32.h has been deprecated in 2.6.21
+
+aachba.c:
+	- Corrected issue with AAC_DEBUG_INSTRUMENT_SG_PROBE
+	- Respond with DID_BUS_BUSY to SRB_STATUS_BUSY.
+
+aachba.c: Mark Salyzyn & James Bottomley <James.Bottomley@SteelEye.com>
+	- fix panic on short Inquiry
+
+aacraid.h+rx.c:
+	- MU_RESET was moved to Options2
+
+aacraid.h+linit.c+aachba.c:
+	- Added support for FUA, use IO_SUREWITE for now.
+	- Added mode page 8 in order to support WCE and FUA
+	- enabled page 8 and page 3f from scsi layers
+
+rx.c+aachba.c:
+	- issue commit config if the adapter was reset during
+	  initialization.
+
+Version: 1.1.5-2447 ()
+
+build:
+	- corrected configuration files for 2.6.5-1.358 (FC2)
+	  namely adding the x86_64 & x86_64-smp configurations.
+
+aachba.c:
+	- SCSI SYNCHRONIZE observes the range fields and only
+	  blocks on writes remaining in the command queue.
+
+compat.h+aachba.c: Fujita Tomonori <fujita.tomonori@lab.ntt.co.jp>
+	- remove the non-use-sg case
+	- convert to use the data buffer accessors
+
+csmi.c+dpcsup.c+sa.c+compat.h:
+	- removed/moved include linux/pci.h
+
+linit.c:
+	- Add change scsi queue depth
+	- Increased resource cleanup of aac_shutdown
+
+linit.c+commsup.c:
+	- After 60 seconds of additional waiting in reset handler,
+	  if still have outstanding commands, issue a blind
+	  reset to the SRL adapters.
+
+aacraid.h+linit.c+commsup.c+aachba.c:
+	- Added support for options ignore reset (SRL).
+
+Version: 1.1.5-2448 ()
+Version: 1.1.5-2448-IBM ()
+
+build:
+	- Add 2.4.21-50.EL (RHEL3 U9)
+	- Drop 2.4.21-9.EL i686 (RHEL3 U1) due to RHEL3 floppy overload
+	- Add 2.6.16.46-0.12 (SLES10/SLED10 SP1)
+
+rx.c:
+	- Only set commit if in default state should the adapter
+	  be reset during initialization.
+
+linit.c:
+	- check if thread running before attempting to shut it down.
+
+linit.c: Brian King <brking@linux.vnet.ibm.com>
+	- driver_version does not make sense given presence of
+	  /sys/module/aacraid/version in later kernels.
+
+linit.c:
+	- Kernels that use the reboot notifier can not perform a
+	  clean (interrupts disabled) shutdown of the controller
+	  because sd_shutdown is called afterwards.  This makes
+	  kexec always issue an Adapter Reset in transition.
+	- SCSI_HAS_SCSI_IN_DETECTION needs to be considered 'off'
+	  for any vmkernel builds.
+
+Version: 1.1.5-2449-IBM ()
+Version: 1.1.5-2449 ()
+
+build:
+	- Fixup 2.6.16.46-0.12 (SLES10/SLED10 SP1) xen, kdump and xenpae
+	  configurations.
+	- Fixup 2.6.16.13-4 (SuSE 10.1) x86_64 confifurations
+
+aachba.c:
+	- aac_build_sgraw move dev assignment into sub-block.
+	- Test unit ready behind an already outstanding long command
+	  to a physical device, assume sequential and report back
+	  NEEDS_RETRY (ADPml05517)
+	- Merged code from 2.6.16.46-0.12 (setinqserial). Why did SuSE
+	  not submit this to kernel.org? (ADPml06710)
+
+aachba.c+aacraid.h+commsup.c: Andrew Morton <akpm@linux-foundation.org>
+	- rename check_reset to aacraid_check_reset
+	- rename aacraid_check_reset to aac_check_reset
+
+linit.c:
+	- Added sysfs uart node, returns YES if supported, NO if
+	  firmware prints are disabled. Printing reports driver
+	  timestamp.
+	- Added proc 'uart=' ability as well, same drill except
+	  that one checks the flags fields for fwprintf to
+	  determine if the feature has a chance.
+	- bug in proc writes, if they are malformed at all, they
+	  never return (!) returning 0 on writes is bad m'kay.
+
+linit.c: Alan Cox <alan@lxorguk.ukuu.org.uk>
+	- Check to make sure ioctl caller is a root user.
+
+README+DUD:pcitable+VMWare.xml+DKMS:readme.txt.orig+Linux:pci.ids:
+	- Added 9005:0285:9005:02ce for 51245
+	- Added 9005:0285:9005:02cf for 51645
+	- Added 9005:0285:9005:02d0 for 52445
+	- Added 9005:0285:9005:02d1 for 5405
+
+README+DUD:pcitable+VMWare.xml+DKMS:readme.txt.orig
+	- Added 9005:0285:108e:7aae for SUN STK RAID EM
+
+DUD:pcitable:
+	- Changed 9005:0285:108e:0286 to SUN STK RAID INT
+	- Changed 9005:0285:108e:0287 to SUN STK RAID EXT
+
+rx.c:
+	- If the Adapter responds 'Use IRCSR to reset' or 0x3803000F
+	  then make sure we transition to the alternate code.
+	  (ADPml06338)
+
+aachba.c+aacraid.h+linit.c+fwdebug.c:
+	- Drop most of the fwdebug instrumentation (ADPml06620)
+
+Version: 1.1.5-2450-IBM ()
+
+linit.c:
+	- removed warning about seconds being unused if the
+	  firmware prints are disabled.
+
+linit.c: Alan Cox <alan@lxorguk.ukuu.org.uk>
+	- Check to make sure compat ioctl caller is a root user.
+
+aachba.c:
+	- Linux standard codify SLES10 setinqserial code.
+	- Added retrieval of Container UID as serial number, so
+	  that VPD does not change through a morph (APDml06710)
+	- corrected locking around search for outstanding commands
+	  to physical targets. (ADPml05517)
+
+aachba.c+commsup.c:
+	- Merge in cosmetics from scsi-misc-2.6 July 18th 2007
+	  snapshot
+
+aachba.c: Ellen Gardiner <gardiner@us.ibm.com>
+	- place flush_kernel_dcache_page() within an ifdef of
+	  ARCH_HAS_FLUSH_ANON_PAGE
+
+release.sh+aacraid.h+fwdebug.c:
+	- filter out AAC_CSMI, AAC_PRINTF_ENABLE, GCC warning filters
+	  and fwprintf
+
+install.sh:
+	- change from 'echo <files> | grep -v orig' to
+	  'ls <files> | grep -v orig' form to correctly list the
+	  files checked to ensure that the initrd contents are
+	  correct.
+	- If /etc/modprobe.conf.local exists s references by
+	  /etc/modprobe.conf and there is currently no references
+	  to aacraid in /etc/modprobe.conf, then use the local
+	  configuration file to add the references instead.
+
+rx.c: Tim Ng <tim_ng@adaptec.com>
+	- drain OutboundQueue when performing a reset of the adapter
+
+Version: 1.1.5-2450 ()
+
+build:
+	- SLES10 (2.6.16.21-0.8 & 2.6.16.46-0.12) utilized the gcc 4.0.2
+	  cross compiler for i586 configurations, it was supposed to use
+	  gcc 4.1.1 (ADPml06710)
+
+Version: 1.1.5-2451 ()
+
+Linux:pci.ids+DKSM:readme.txt.orig:
+	- Added 9005:0285:108e:7aae for SUN STK RAID EM
+
+install.sh
+	- A module failing to install should not be considered fatal,
+	  adjusted the message to suggest that the inbox driver is more
+	  advanced than the package. We still error with a code from
+	  the install script with the hopes that the user will
+	  intelligently accept this should it be a late model operating
+	  system.
+
+aachba.c:
+	- RHEL5 does not exibit the problem with CD writers (ADPml05517)
+	  and thus we will ifdef the code out for the later OS releases.
+	- For *released* SMC cards, support coming up with SMC vendor
+	  id in setinqstr for all 'AOC*' cards.
+	- default maximum num physicals should Get_BusInfo fail is set to
+	  16 (ok for SCSI, kind'a limiting for SAS).
+
+aachba.c+linit.c+aacraid.h:
+	- For OEM release we support sharing the setinqstr handler. Need
+	  to rationalize this differently?
+
+linit.c+aacraid.h: inspired by Sri Dharmasanam <sdharmas@cisco.com>
+	- use the pci device shutdown function to provide a
+	  post-sd_shutdown notification for 2.6.0-2.6.11 kernels.
+	  This will help reduce the occurrences of Bad Stripes.
+	- Move registration of reboot notifier to beginning of
+	  init function so that it is called last (FILO) on way
+	  down.
+
+linit.c:
+	- Set default timeouts to 45 seconds for the arrays.
+	- Added hba_max_channel, hba_max_physical and hba_max_array to
+	  sysfs. Only available for AAC_DEBUG_INSTRUMENT_SETUP for now.
+	- Make sure the outstanding command is either Async or
+	  NoResponseExpected before trusting the callback_data value.
+	  (ADPml08062)
+
+linit.c: Alan Cox <alan@lxorguk.ukuu.org.uk>
+	- Check to make sure config ioctl caller is a root user.
+
+linit.c: Fujita Tomonori <tomof@acm.org>
+	- Added use_sg_chaining enabled.
+
+aacraid.h:
+	- Turn off AAC_CSMI to conserve space.
+	- dropped maximum transfer size to 64K for kernels less than
+	  2.4.18 as we find some of them are capable of producing
+	  requests with too many scatter gather elements coupled with
+	  >64K element sizes that need to be split for legacy cards
+	  (ADPml07201)
+
+Version: 1.1.5-2452 ()
+
+build:
+	- Add 2.6.18-53.el5 (RHEL5.1 RC2)
+	- Added 2.6.9-65.EL (RHEL4 U6 RC)
+	- upgraded to DKMS 2.0.17.4 and added debian version as well.
+	- Add 2.6.22-14.46 (Debian 7.10)
+
+aacraid.h+commsup.c+dpcsup.c+linit.c:
+	- Added FIB_CONTEXT_FLAG to report that there is a scsi layer
+	  context associated with this FIB. (ADPml08062)
+	- if check_reset=-1, then use the always reset feature, rather
+	  than accepting the Firmware reporting that the reset is
+	  disabled. This permits us to bypass Q/A disable to ensure
+	  that the reset paths are doing what we expect (ADPml08062)
+
+commsup.c:
+	- Do not send a VM_Closeall on a blind reset.
+
+aacraid.h+linit.c+aachba.c:
+	- Add a Quirk for the ScsiPortCommand64 missing.
+
+Makefile+linit.c+VMware.mak+aacraid.h+aachba.c:
+	- Added HAS_COMPILE_H
+	- renamed HAS_DUMPLIB to HAS_DISKDUMPLIB_H
+	- renamed HAS_DISKDUMP to HAS_DISKDUMP_H
+	- renamed HAS_BOOTSETUP to HAS_BOOTSETUP_H
+	- renamed HAS_DUMP_DISKDUMP to HAS_DISKDUMP_H
+
+aacraid.h+rx.c+sa.c+Makefile: Jeff Garzik <jeff@garzik.org>
+	- irq_removal: scsi driver trivial. defined
+	  HAS_NEW_IRQ_HANDLER_T to aid transition.
+
+commsup.c: Stephen Rothwell <sfr@canb.auug.org.au>
+	- don't assign cpu_to_le32(constant) to u8
+
+Version: 1.1.5-2453 ()
+
+build:
+	- Removed 2.6.9-65.EL (RHEL4 U6 RC)
+	- Added 2.6.9-67.EL (RHEL4 U6)
+
+aacraid.h+aachba.c+linit.c:
+	- Add support for scsi device raid level report. This
+	  is an experimental feature for the moment.
+	- Add in support for caching commands (FUA and
+	  SYNCHRONIZE_CACHE) to be disabled either permanently, or only
+	  when the card's cache is protected.
+
+aacraid.h+aachba.c+linit.c+commsup.c:
+	- Added initial crack at support for Voodoo Lite (JBOD).
+
+compat.h+commctrl.c+comminit.c+dpcsup.c+linit.c+aachba.c:
+	- switch to uintptr_t from ptrdiff_t, inspired by scsi-misc-2.6
+	  changes on November 5 2007
+
+dpcsup.c:
+	- Removed code to limit number of allocations attempted
+	  for AIF slots. This is now in-line with scsi-misc-2.6.
+
+linit.c:
+	- Use existing fsa_dev info to count the number of containers
+	  to make a more intelligent division of the initial queue
+	  depth. JBOD drives remain as-discovered though.
+
+linit.c: Alan Cox <lxorguk.ukuu.org.uk>
+	- Address weakness in the AACRAID driver, change capability
+	  checking from ADMIN to RAWIO.
+
+aachba.c: Fujita Tomonon <tomof@acm.org>
+	- replace sizeof sense_buffer with SCSI_SENSE_BUFFERSIZE
+
+aachba.c:
+	- Followup to change to SCSI_SENSE_BUFFERSIZE, switch to
+	  min() macro.
+
+README+DUD:pcitable+VMWare.xml+DKMS:readme.txt.orig+Linux:pci.ids:
+	- Added 9005:0285:9005:02d4 for 2045
+	- Added 9005:0285:9005:02d5 for 2405
+	- Added 9005:0285:9005:02d6 for 2445
+	- Added 9005:0285:9005:02d7 for 2805
+
+linit.c: James Bottomley <James.Bottomley@SteelEye.com>
+	- removed use of use_sg_chaining. Only on for 2.6.23-2.6.24.
+
+Version: 1.1.5-2454 ()
+
+linit.c+commsup.c+commctrl.c+aachba.c+aacraid.h:
+	- removes pigs in space
+
+linit.c:
+	- Added SUPPORTED_JBOD to flags (sysfs & procfs) when jbod
+	  adapter is detected.
+	- fixed the serial number report.
+
+aacraid.h+aachba.c:
+	- Added definitions and enabled support code for AifEnAddJBOD
+	  and AifEnDeleteJBOD.
+
+commctrl.c:
+	- wrapped the fib lock around the fib context.
+
+aacraid.h+aachba.c+rx.c+linit.c+sa.c:
+	- Added MSI capability.
+
+linit.c: Fujita Tomonori <tomof@acm.org>
+	- iommu sg merging: use pci_set_dma_max_seg_size
+
+aachba.c:
+	- Drop valid-data bit in sense return data.
+	- optimized set_sense to minimum functionality.
+
+aachba.c+linit.c+commsup.c:
+	- problem with state of Ignore Adapter Reset.
+
+fwdebug.c:
+	- added aacraid.firmware_debug insmod parameter.
+
+commsup.c: Marcin Slusarz <marcin.slusarz@gmail.com>
+	- le*_add_cpu conversion
+
+Version: 1.1.5-2455 ()
+
+install.sh:
+	- Return does not work in context of script, only subroutines,
+	  use exit instead.
+	- If a package has been relocated, and we can not find the
+	  master location, use the current working directory.
+	- If a make init rd command is not found, then revert the
+	  backup copy of the initrd before exiting with the error.
+	- Added support for update-initramfs command present in
+	  Gutsy.
+
+linit.c:
+	- As proposed by Jonas Bonn <jonas@southpole.se> changed
+	  struct pci_device_id table to use DECLARE_PCI_DEVICE_TABLE
+	  if available.
+	- use __devinitdata or __devinitconst depending on kernel
+	  vintage for the legacy pci_device_id table definitions.
+
+aacraid.h+aachba.c+linit.c:
+	- Added definition and code for a ST_NOT_READY response from
+	  an I/O request.
+	- Added FSCS_NOT_READY bit in VM_NAMESERVE
+	- Added Power Management Initflags and option report.
+	- Add defintion and code for issuing START_STOP fib.
+
+aachba.c:
+	- Added additional instrumentation for
+	  AAC_DEBUG_INSTRUMENT_VM_NAMESERVE (ADPml08612)
+
+commsup.c:
+	- Added a retry loop handler for queued scans (ADPml08614
+	  and ADPml08615)
+
+aachba.c+aacraid.h+commctrl.c+commsup.c+dpcsup.c+linit.c+rx.c+sa.c:
+	- Synchronize to latest scsi-misc-2.6 changes on April 30 2008
+	- Changed from class_device_attribute to device_attribute (why?)
+
+README+DUD:pcitable+VMWare.xml+DKMS:readme.txt.orig+Linux:pci.ids:
+	- Change 9005:0285:9005:02d4 for ASR-2045
+	- Change 9005:0285:9005:02d5 for ASR-2405
+	- Change 9005:0285:9005:02d6 for ASR-2445
+	- Change 9005:0285:9005:02d7 for ASR-2805
+	- Add all 'G' cards.
+
+aachba.c+commsup.c+aacraid.h+linit.c+rx.c+commsup.c:
+	- Merged upcoming VMWare port
+
+linit.c: Harvey Harrison <harvey.harrison@gmail.com>
+	- aac_show_serial_number (2.6.25+) should be static
+
+build:
+	- Add VMware 3.5 ddk
+	- Build VMware 3.0, 3.0.1, 3.0.2 and 3.5 products ADPml09413
+
+Version: 1.1.5-2456 ()
+
+VMware*.spec:
+	- Print out instructions on how to do the vmeare-mkinitrd.
+	- Replace yes with true.
+
+build:
+	- Add SLES9.4 2.6.5-7.308
+	- Add RHEL5.2 2.6.18-92.el5
+	- Add SLES10.2 2.6.16.60-0.21
+
+Version: 1.1.5-2457 ()
+
+build:
+	- Added a message telling the user to reboot in the VMware
+	  package.
+	- Added 2.4.21-47.0.1 (RHEL3 u8 errata 1)
+
+commctrl.c:
+	- ioctl scb passthrough needs to check the validity of the
+	  individual scatter gather count fields to the maximum the
+	  adapter supports. Doing so will have the side effect of
+	  preventing copy_from_user() from bugging out while populating
+	  the dma buffers.
+
+aacraid.h:
+	- Added Performance Modes and additional Feature Bits to
+	  Supplemental Info structure.
+
+aachba.c:
+	- Do not provide VPD data for VMware builds. Messes up the SAN
+	  signature.
+	- Add aacraid.wwn insmod parameter to control user preference.
+
+README:
+	- Comment out G series cards.
+
+Version: 1.1.5-2458 ()
+
+commctrl.c:
+	- if the driver is in shutdown, do not restart aacraid kernel
+	  thread (cleanup)
+
+aachba.c:
+	- SLES10 SP2 uses wwn=1, SLES10 SP1 uses wwn=2 as default
+
+Version: 1.1.5-2459 ()
+
+build:
+        - RHEL4.7 added: 2.6.9-78.el
+        - RHEL5.3 added: 2.6.18-92.el5
+
+linit.c+aachba.c:
+        - aac_cache=2 as default to avoid performance problems due to flushes 
+        (Novell Bugzilla #469922)
+        - disable nondasd support for AAC_QUIRK_SCSI_32 controllers to avoid hang
+        (RedHat Bugzilla #457552)
+
+all sources:
+        - changes for VMWare ESX4.0
+
+README:
+        - BLBU Voodoos added
+
+Version: 1.1.5-2460 ()
+
+2009-02-24	Achim_Leubner@adaptec.com
+
+linit.c:
+        - aac_eh_device_reset() and aac_eh_bus_reset() now return SUCCESS
+          to avoid "vmkfstools -L lunreset ..." and "vmkfstools -L busreset ..."
+          failures in the test suite of VMware
+
+all sources:
+        - scsi-misc-2.6 changes, patch against 2.6.29-rc7
+
+Version: 1.1.5-2461 ()
+
+2009-03-31	Achim_Leubner@adaptec.com
+
+commsup.c:
+        - AIF handling: If there is a JBOD drive added to the system, identify the 
+          old one with scsi_device_lookup() and remove it to enable a 
+          fresh scsi_add_device(); otherwise the new JBOD is not available
+          until reboot
+
+Version: 1.1.5-2463 ()
+
+2009-04-14	Achim_Leubner@adaptec.com
+
+aachba.c:
+	- expose_physicals: Phys. drives not available for expose_physicals>0 with new
+	  JBOD firmware - function aac_expose_phy_device() added to reset the appropriate
+	  bit in the first byte of inquiry data 	
+
+Version: 1.1.5-2464 ()
+
+2009-05-18	Mahesh_Rajashekhara@adaptec.com
+
+aachba.c:
+commctrl.c:
+comminit.c
+commsup.c
+dpcsup.c
+linit.c
+aacraid.h
+
+	- Added support for building the driver against Kernel - 2.6.25
+
+Version: 1.1.5-2466 ()
+
+2009-06-24	Mahesh_Rajashekhara@adaptec.com
+
+aachba.c:
+commctrl.c:
+csmi.c
+fwdebug.c
+linit.c
+
+	- Added support for building the driver against Kernel - 2.6.29 & 2.6.30
+
+Version: 1.1.5-2467 ()
+
+2009-07-10	Mahesh_Rajashekhara@adaptec.com
+
+aachba.c:
+commctrl.c:
+csmi.c
+fwdebug.c
+linit.c
+
+	- Added support for building the driver against Kernel - 2.6.26, 2.6.27 & 2.6.28
+
+Version: 1.1.5-2468 ()
+
+2009-07-22	Mahesh_Rajashekhara@adaptec.com
+
+linit.c
+
+	- "DDTS #11875: vmware 4.0 : Shows some junk value in serial number field"
+	  aac_show_serial_number - Added the fix to copy serial number into the buffer
+
+Version: 1.1.5-24800 ()
+
+2009-08-20	Mahesh_Rajashekhara@adaptec.com
+
+aachba.c
+
+	- Added support for handling ATA pass thru commands
+	  When the CC bit is SET by the host in ATA pass thru CDB, driver is supposed to return DID_OK	 
+	  When the CC bit is RESET by the host, driver should return DID_ERROR
+	 
+Version: 1.1.5-24900 ()
+
+2009-14-10	Mahesh_Rajashekhara@adaptec.com
+
+aachba.c
+
+	- VMWARE ESX: Added support for creating RVOLUME 
+
+Version: 1.1.5-25000 ()
+
+2009-11-05	Achim_Leubner@adaptec.com
+
+commctrl.c
+	- Change to avoid XferState != 0 kernel message after a possible sync. cmd timeout after 180s
+
+commsup.c
+	- schedule() call added for ESX35 to avoid deadlock because otherwise bottom half handler does
+	  not run and up() call never occurs
+	- wait=-1 setting removed for ESX40 because we can block under that OS
+
+commsup.c+dpcsup.c
+	- handling after a possible sync. cmd timeout after 180s changed to avoid PSOD due to wrong
+	  event_wait semaphore status
+
+Version: 1.1.5-25100 ()
+
+2009-11-12	Mahesh_Rajashekhara@adaptec.com
+
+aachba.c
+
+	- ADPml11898 SUNMR Spitfire issue
+ 	  Firmware  layer exposes lesser container capacity than the actual one.	
+	  It exposes [Actaul size - Spitfire space(10MB)] to the OS, IO's to the 10MB should be prohibhited from the Linux driver.
+	  Sensekey sets to HARDWARE_ERROR and sending the notification to the MID layer.
+	  Added "expose_hidden_space" flag, by default the fix will be executed. 
+	  Only if the user sets "expose_hidden_space=1", user can access beyond the Array reported size(Spitfire region).	 
+
+commsup.c
+	
+	- ADPml12131 Cannot see 2 luns with a prometheus card on a J4400
+	  When the Enclosure cable is Hot removed/inserted,driver doesn't inform SCSI mid layer about the device Online/Offline status 
+	  leaving "stale" entries. Now with this fix in the driver, it informs the appropriate device Online/Offline status to the 
+	  SCSI mid layer with the help of AIF notification from FW.
+
+Version: 1.1.5-25200 ()
+
+2009-11-17	Mahesh_Rajashekhara@adaptec.com
+
+aachba.c
+
+	- ADPml11898 SUNMR Spitfire issue
+	  Removed extra condition for this fix in aac_read/aac_write function. 
+	  
+Version: 1.1.5-25300 ()
+
+2009-11-30	Achim_Leubner@adaptec.com
+
+commctrl.c
+	- small fix to return correct status if sync. cmd timeout after 180s
+
+commsup.c
+	- schedule() call replaced by direct interrupt handler call due to recommendations by the VMware team
+	- wait=-1 not set for ESX40
+
+Version: 1.1.5-25400 ()
+
+2009-12-04	Mahesh_Rajashekhara@adaptec.com
+
+build:
+        - SLES10 SP3 added: 2.6.16.60-0.54.5
+
+Version: 1.1.5-25500 ()
+
+2009-12-08	Achim_Leubner@adaptec.com
+
+aacraid.h:
+        - "#if (defined(SCSI_HAS_DUMP))" removed for the "aac_adapter_intr()" definition 
+
+build:
+        - RHEL4.8 added: 2.6.9-81.el
+
+Version: 1.1.5-25600 ()
+
+2009-12-16	Mahesh_Rajashekhara@adaptec.com
+
+build:
+        - RHEL5.4 added: 2.6.18-164.el5
+
+Version: 1.1.5-25700 ()
+
+2010-01-08	Mahesh_Rajashekhara@adaptec.com
+
+aacraid.h:
+        - Based on the notification from FW, the driver calls "scsi_remove_device" for the deleted array.
+	  This call not only informs the scsi device status to the SCSI mid layer 
+	  and also it will remove corresponding scsi device entries from the Linux sysfs.
+	  Enabled "AAC_DEBUG_INSTRUMENT_AIF_DELETE" flag  in the Header file, with this flag the driver uses "scsi_remove_device"	
+
+Version: 1.1.5-25800 ()
+
+2010-01-14	Achim_Leubner@adaptec.com
+
+aachba.c:
+        - ESX40: Set aac_wwn=0 to avoid serious driver update problem (cannot mount root - vsd_mount failure)
+aacraid.h+commctrl.c+comminit.c+commsup.c+dpcsup.c:
+	- ESX40: Use cmdready wait queue instead of semaphore to wait for competion in aac_command_thread()
+	- ESX40: Use kthread_stop instead of thread_die flag during shutdown to kill aac_command_thread(), older driver
+	  had a deadlock here
+
+Version: 1.1.5-25900 ()
+
+2010-01-20	Mahesh_Rajashekhara@adaptec.com
+
+build:
+	- RHEL4.8 added: 2.6.9-89.el
+
+aacraid.src.spec:
+	- Added standalone XEN kernel support
+
+Version: 1.1.5-26000 ()
+
+2010-02-02	Mahesh_Rajashekhara@adaptec.com
+
+linit.c:
+	-  "cat /proc/scsi/aacraid/<Node #>" displays invalid argument
+	   The return value in "aac_procinfo" was incorrect and changed to return '0'
+
+Version: 1.1.5-26100 ()
+
+2010-02-16	Achim_Leubner@adaptec.com
+
+build:
+	- Added support to build ESX 4.0 driver ISO image
+
+Version: 1.1.5-26200 ()
+
+2010-02-24	Mahesh_Rajashekhara@adaptec.com
+
+build:
+	- ESX4: Driver ISO image file is renamed to ESX4 product
+
+Version: 1.1.5-26300 ()
+
+2010-02-26	Mahesh_Rajashekhara@adaptec.com
+
+linit.c:
+aachba.c:
+	- Fixed build issues for SLES11
+
+
+Version: 1.1.6-26400 ()
+
+2010-04-21	Achim_Leubner@adaptec.com
+
+linit.c + frey.c + aacraid.h + Makefile + VMware-4.0.sc + VMware.inc:
+        - Cardinal Frey controller support added
+
+Version: 1.1.6-26500 ()
+
+2010-07-28	Mahesh_Rajashekhara@adaptec.com
+
+aacraid.h + compat.h + linit.c + build:
+        - ESXi4.0 - Added fix to create device nodes(/dev/aacX)
+	- ESXi4.0 - Added build support to produce seperate driver binary package
+
+linit.c + fwdebug.c:
+	- Added build support for 2.6.34 and 2.4.37 kernels
+
+build:
+	- RHEL5.5 added: 2.6.18-194.el5
+
+Version: 1.1.6-26600 ()
+
+2010-08-11	Mahesh_Rajashekhara@adaptec.com
+
+build:
+	- SLES11 added: 2.6.27.19-5
+
+Version: 1.1.6-26700 ()
+
+2010-08-24	Mahesh_Rajashekhara@adaptec.com
+
+build:
+	- Fedora Core 11 added: 2.6.29.4-167.fc11
+	- Fedora Core 12 added: 2.6.31.5-127.fc12
+
+Version: 1.1.6-26800 ()
+
+2010-08-30	Mahesh_Rajashekhara@adaptec.com
+
+build:
+	- RHEL6 Beta2 added: 2.6.32-37.el6
+	- RHEL6 Snap8 added: 2.6.32-52.el6
+
+Version: 1.1.7-26900 ()
+
+2010-09-04	Mahesh_Rajashekhara@adaptec.com
+
+build:
+	- SLES11 SP1 added: 2.6.32.12-0.7
+
+Version: 1.1.7-27000 ()
+
+2010-09-06	Achim_Leubner@pmc-sierra.com
+
+frey.c: 
+	- Removed because Marvell Frey support removed
+src.c: 
+	- Added to support PMC SRC controller family (Kittyhawk, Tupelo)
+
+Version: 1.1.7-27100 ()
+
+2010-09-17	Mahesh_Rajashekhara@adaptec.com
+
+build:
+	- SLES11 SP1: Added DUD pre and post installation scripts
+	- SLES11 SP1: Updated README for SLES11 SP1 DUD installation
+
+Version: 1.1.7-27200 ()
+
+2010-09-23	Achim_Leubner@pmc-sierra.com
+
+VMware-3.5.xml + VMware-4.0.xml:
+	- Kittyhawk/Tupelo device IDs added for VMware
+
+rx.c + sa.c + src.c + fwdebug.c + aacraid.h: 
+	- UART trace output reworked because debug buffer is on BAR1 for PMC SRC
+
+Version: 1.1.7-27400 ()
+
+2010-10-19	Mahesh_Rajashekhara@adaptec.com
+
+VMware-4.0.xml:
+	- ESXi 4: Fixed driver load issue
+
+Version: 1.1.7-27500 ()
+
+2010-10-21	Achim_Leubner@pmc-sierra.com
+
+commsup.c:
+	- Deadlock patch (PR 414597) also added for ESX4
+src.c: 
+	- Wait 5 sec. after doorbell initiated FW reset to avoid wrong FW status read
+
+Version: 1.1.7-27600 ()
+
+2010-11-01	Achim_Leubner@pmc-sierra.com
+
+src.c: 
+	- Prep #178897: Avoid wrong doorbell bit clear in the interrupt routine
+	- Prep #178892: Adjust RRQ index in the interrupt routine
+
+Version: 1.1.7-27700 ()
+
+2010-11-18	Achim_Leubner@pmc-sierra.com
+
+src.c: 
+	- Prep #178892: Adjust RRQ index in the interrupt routine - BUG FIXED FROM 27600 BUILD
+
+Version: 1.1.7-27800 ()
+
+2010-11-30	Mahesh_Rajashekhara@adaptec.com
+
+aachba.c: 
+	- Prep #181085: Fixed write error and read-only filesystem issue
+
+Version: 1.1.7-27900 ()
+
+2010-12-07	Mahesh_Rajashekhara@pmc-sierra.com
+
+build:
+	- RHEL6 GA added: 2.6.32-71.el6
+
+Version: 1.1.7-28000 ()
+
+2011-02-16	Mahesh_Rajashekhara@pmc-sierra.com
+
+linit.c:
+	- Prep #192790: Fixed VMware certification SAS_CheckDriver test issue
+
+Version: 1.1.7-28100 ()
+
+2011-04-05	Mahesh_Rajashekhara@pmc-sierra.com
+
+linit.c:
+aachba.c:
+VMware-5.0.mak:
+VMware-5.0.sc:
+VMware-5.0.xml:
+	- Added support for ESXi 5.0 OS
+
+build:
+	- Fedora Core 13 added: 2.6.33.3-85.fc13
+	- Fedora Core 14 added:	2.6.35.6-45.fc14
+	- DKMS: Added Series 6 PCI id's into the 'pcitable' file and latest DKMS tool binary RPM v2.1.1.2
+
+Version: 1.1.7-28200 ()
+
+2011-05-24	Mahesh_Rajashekhara@pmc-sierra.com
+
+linit.c:
+commctrl.c:
+commsup.c:
+	- Fixed Ubuntu 11.04 build issues
+	- Fixed VMware 5.0 SAS_CoreDump test failure issue
+
+build:
+	- Updated driver README
+
+Version: 1.1.7-28300 ()
+
+2011-07-01	Mahesh_Rajashekhara@pmc-sierra.com
+
+linit.c:
+	- Prep #209412: Fixed bug in ioctl interface
+
+Version: 1.1.7-28400 ()
+
+2011-08-22	Mahesh_Rajashekhara@pmc-sierra.com
+
+aachba.c:
+aacraid.h:
+commctrl.c:
+comminit.c:
+commsup.c:
+dpcsup.c:
+VMware-5.0.mak:
+	- Included HCL ServeRAID team submitted upstream driver patch(Patch: [SCSI] aacraid: fix File System going into read-only mode)
+	  http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commitdiff;h=cacb6dc3d7fea751879a225c15e48228415e6359
+	- Added RDM(RAW DEVICE MAPPING) support for VMware ESX/ESXi 4.1 and ESXi5.0
+	  For RDM support, set "aac_wwn = 1" RAID controller response to inquiry VPD page 0x80 to return a unique serial number
+	- Added new DDK (#406165) Makefile for VMware ESXi5.0
+	- Changed sync. timeout from 30s to 300s for rx and src
+
+Version: 1.1.7-28500 ()
+
+2011-09-09	Mahesh_Rajashekhara@pmc-sierra.com
+
+aacraid.h:
+build:
+	- Fixed Prep #216490
+	- RHEL5.6 added: 2.6.18-238.el5 
+
+Version: 1.1.7-28600 ()
+
+2011-10-10	Mahesh_Rajashekhara@pmc-sierra.com
+
+linit.c:
+commsup.c:
+	- Fixed Prep #211135: Changed 'AIF_SNIFF_TIMEOUT' from 30 to 60 seconds because this timeout is too short for a config with a lot of drives. 
+	  Included block request timeout 45 seconds for the kernel versions >= 2.6.27 version 
+	  Initialized 'fibptr->flags' to 0 to avoid kernel derefrencing pointer issue
+	  Initialized 'aac->fibs[]' to 0 completely after allocation
+
+Version: 1.1.7-28700 ()
+
+2011-11-08	Mahesh_Rajashekhara@pmc-sierra.com
+
+build:
+	- A warning message to be printed during the DKMS build that indicates to the user to adjust settings in conf file for DKMS auto_install support
+
+Version: 1.1.7-28800 ()
+
+2011-12-06	Achim_Leubner@pmc-sierra.com
+
+aachba.c:
+linit.c:
+comminit.c:
+commsup.c:
+src.c:
+aacraid.h:
+	- Series 7 (Denali) support added
+	- Sync. mode (for testing) added
+	- Sync. mode switched on automatically if async. mode not supported (for future products - Series 7 with new async. interface, Series 8/9) 
+
+build:
+	- RHEL 6.2 RC added: 2.6.32-220.el6
+	- RHEL 6.1 added: 2.6.32-131.0.15.el6
+	- SLES 10 SP4 added: 2.6.16.60-0.85.1
+
+Version: 1.1.7-28900 ()
+
+2011-12-15	Achim_Leubner@pmc-sierra.com
+
+commsup.c:
+src.c:
+aacraid.h:
+linit.c:
+	- Sync. mode changes to avoid tool errors (management fib handling changes)
+
+Version: 1.2.0-29000 ()
+
+2011-01-18	Mahesh_Rajashekhara@pmc-sierra.com
+
+VMware-4.0.xml:
+VMware-5.0.xml:
+	- Added PCI device id's for Huawei80T, Series 7, 8 and 9 controllers
+
+Version: 1.2.1-29100 ()
+
+2012-03-12	Achim_Leubner@pmc-sierra.com
+
+aacraid.h:
+aachba.c:
+comminit.c:
+commsup.c:
+dpcsup.c:
+linit.c:
+src.c:
+	- Async. (performance) mode added for Series 7 with (native) S/G list, new FIB header, new Raw IO command (RawIo2)
+
+Version: 1.2.1-29500 ()
+
+2012-04-12	Achim_Leubner@pmc-sierra.com
+
+aachba.c:
+comminit.c:
+commctrl.c:
+	- Fast JBOD mode added
+
+2012-04-17	Mahesh_Rajashekhara@pmc-sierra.com
+
+aachba.c:
+	- Added a fix for 'BUG: scheduling while atomic' issue
+
+2012-04-30	Achim_Leubner@pmc-sierra.com
+
+aachba.c:
+dpcsup.c:
+aacraid.h:
+	- Bugfix Fast JBOD mode
+
+2012-05-10      Mahesh_Rajashekhara@pmc-sierra.com
+
+aachba.c:
+commsup.c:
+linit.c:
+Makefile:
+build:
+        - Fedora 15 added: 2.6.38.6-26.rc1.fc15
+        - Fedora 16 added: 3.1.0-7.fc16
+
+Version: 1.2.1-29600 ()
+
+2012-05-25	Mahesh_Rajashekhara@pmc-sierra.com
+
+build:
+        - RHEL 5.8 added: 2.6.18-308.el5
+        - SLES 11 SP2 added: 3.0.13-0.27
+        - Updated README
+
+Version: 1.2.1-29700 ()
+
+2012-06-21	Mahesh_Rajashekhara@pmc-sierra.com
+
+aachba.c:
+	- When we have an I/O that adjoins the previous request, we change the queue depth by calling 'scsi_adjust_queue_depth' API. 
+	  It appears that latest versions of kernel doesn`t support changing the queue depth and backing up of sequential I/O`s at
+	  the SCSI merge layer on a faster systems or controllers, the *lockdep* error caused due to clash between 'scsi_adjust_queue_depth' and
+	  'scsi_dispatch_cmd' routines at the SCSI upper layers.
+
+src.c:
+	- Workaround: To keep OS happy and to avoid disabling IRQ line issue, when the driver is in Async mode and if driver gets an
+	  extra sync. command completion response from the firmware, fix clear`s the ISR interrupt bits and return IRQ_HANDLED from 
+	  the interrupt handler fixes the "Disabling IRQ #" issue.
+
+Version: 1.2.1-29800 ()
+
+2012-07-03	Mahesh_Rajashekhara@pmc-sierra.com
+
+commsup.c:
+	- `udelay` in aac_fib_send to wait for ShutDown command complete that block the other CPUs too long during shutdown if array is rebuilding.
+	  Changed it to use `msleep` instead of `udelay`. 
+
+Version: 1.2.1-29900 ()
+
+2012-07-26	Mahesh_Rajashekhara@pmc-sierra.com
+
+commsup.c:
+aacraid.h:
+	- Added new AIF raw device remove support
+
+VMware-5.1.mak:
+VMware-5.1.sc:
+VMware-5.1.xml:
+	- Added support for VMware 5.1 OS
+
+Version: 1.2.1-30000 ()
+
+2012-12-19	Mahesh.Rajashekhara@pmcs.com
+		Vinay.Goli@pmcs.com
+
+aachba.c:
+	- SCSI dma mapping failure case handling
+	  http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commit;h=0b4334473d48aa18e8448f9f718f1dcd0398c550
+
+aacraid.h:
+comminit.c:
+	- 1024 command support related changes
+
+build:
+fc-post-install.sh:
+install.sh:
+	- New OSes support related changes for 2013.1 program
+
+Makefile:
+	- Instead of modifying OS GLOBAL config settings, creating driver specific conf file.
+
+Version: 1.2.1-30100 ()
+
+2013-01-16	Mahesh.Rajashekhara@pmcs.com
+		Vinay.Goli@pmcs.com
+
+build:
+	- RHEL 5.9 added: 2.6.18-348.el5
+
+aacraid.h:
+comminit.c:
+	- 1024 command support changes for S7 and above hardware only.
+
+Version: 1.2.1-30200 ()
+
+2013-02-11	Mahesh.Rajashekhara@pmcs.com
+		Vinay.Goli@pmcs.com
+
+build:
+install.sh:
+fc-post-install.sh:
+	- Fedora 18 added: 3.6.10-4.fc18
+
+aacraid.h:
+comminit.c:
+src.c:
+	- Added Dual flash fw support
+
+Version: 1.2.1-30300 ()
+
+2013-05-13	Mahesh.Rajashekhara@pmcs.com
+
+aachba.c:
+commsup.c:
+aacraid.h:
+	- Fixes for Prep #309671 and Prep #309674
+
+2013-05-13	Gilbert.Wu@pmcs.com
+
+commctrl.c:
+	- Fix for Prep #304874
+
+Version: 1.2.1-40000 ()
+
+2013-04-04	Achim.Leubner@pmcs.com
+		Mahesh.Rajashekhara@pmcs.com
+
+aacraid.h:
+linit.c:
+aachba.c:
+comminit.c:
+commsup.c:
+src.c:
+	- Added 4K sector support changes
+	- Added MSI-X support changes
+
+Version: 1.2.1-40100 ()
+
+2013-08-12	Mahesh.Rajashekhara@pmcs.com
+
+aacraid.h:
+comminit.c:
+commsup.c:
+linit.c:
+src.c:
+	- Added MSI-X IOP RESET handling changes
+	- Added fix for hang during driver re-load
+	- Added support for the kernel versions >= 3.8
+	- New OSes support packages:
+	  RHEL 6.4 added
+	  SLES 11 SP3 added
+	  VMware 5.5 added
+	  CentOS 6.2 added
+	- Fixed Prep #319611 and Prep #319516
+	- Suppress two GCC warnings
+
+Version: 1.2.1-40200 ()
+
+2013-10-09	Mahesh.Rajashekhara@pmcs.com
+
+comminit.c:
+aachba.c:
+	- Fixed Prep #317771: DKMS driver did not install or build for the updated kernel 3.9.6-200.fc18.x86_64 in Fedora 18.x86_64
+	- Fixed Prep #323488: Size of AUTOLD1 exposed in ARCCONF is different from that in OS
+	- Changed QD = 512 and Maximum FIB size = 4096 for performance
+
+Version: 1.2.1-40300 ()
+
+2013-10-24	Mahesh.Rajashekhara@pmcs.com
+
+aacraid.h:
+dpcsup.c:
+linit.c:
+src.c
+	- Fixes for Prep's below:
+	  Prep #325216: VMware ESXi 5.1 Cert - `ErrorHandling::SAS_CoreDumpTest` failed.
+	  Prep #324456: SLES 11 SP3(x64) : System hang due to CIM Server failed while running overnight IO.
+	  Prep #324481: Kernel panic found while array roaming from 8885E to 81605ZQ
+
+Version: 1.2.1-40400 ()
+
+2013-12-02	Mahesh.Rajashekhara@pmcs.com
+
+build:
+	- RHEL 5.10 added
+
+Version: 1.2.1-40500 ()
+
+2014-02-14	Mahesh.Rajashekhara@pmcs.com
+
+VMware-4.0.xml:
+VMware-5.0.xml:
+VMware-5.1.xml:
+VMware-5.5.xml:
+rx.c:
+	- Updated latest PCI device IDs
+	- kdump fix: http://marc.info/?l=linux-scsi&m=138960673329856&w=2
+
+Version: 1.2.1-40600 ()
+
+2014-03-31	Mahesh.Rajashekhara@pmcs.com
+
+aacraid.h:
+aachba.c:
+	- Fix for Prep#338719: Multiple issues in creating more than 64 Simple volume in SV 240 mode
+
+Version: 1.2.1-40700 ()
+
+2014-05-05	Achim.Leubner@pmcs.com
+
+aacraid.h:
+comminit.c:
+src.c:
+	- Fix for Prep #341911: doorbell reset value now available during initialization for driver
+
+2014-05-05	Mahesh.Rajashekhara@pmcs.com
+
+aacraid.h:
+comminit.c:
+linit.c:
+	- Fix for Prep #337965:  During the shutdown, if driver gets commands from the application layer, driver sends error code to the upper layers.
+
+Version: 1.2.1-50000 ()
+
+2014-07-02	Mahesh.Rajashekhara@pmcs.com
+
+aachba.c:
+aacraid.h:
+commsup.c:
+linit.c:
+
+	- Added support for Katmai boards
+	- Prep 350269: 2K/streamline continuation FIB support
+	- Prep 349878: Linux driver has to populate the right value in FIB header for CF_STATUS_HEADER
+
+Version: 1.2.1-50001 ()
+
+2014-07-23	Achim.Leubner@pmcs.com
+		Santosh.Akula@pmcs.com
+		Mahesh.Rajashekhara@pmcs.com
+
+aachba.c:
+aacraid.h:
+commctrl.c:
+commsup.c:
+linit.c:
+src.c:
+
+	- 352427 - Katmai: Force controller mode to SMART MODE
+	- 351878 - Katmai: Hot plug doesnt work in linux
+	- 351879 - Katmai: Add persistent mapping support
+	- 349443 - change AIF vector number
+	- 348570 - Error code changes
+	- 350053 - Transport reset implemented
+	 
+Version: 1.2.1-50002 ()
+
+2014-08-20	Achim.Leubner@pmcs.com
+		Mahesh.Rajashekhara@pmcs.com
+		Murthy.Bhat@pmcs.com
+		Santosh.Akula@pmcs.com
+
+aachba.c:
+aacraid.h:
+linit.c:
+VMware-4.0.xml:
+VMware-5.0.xml:
+VMware-5.1.xml:
+VMware-5.5.xml:
+build:
+install.sh:
+
+	- Prep 334262: Do not expose SEP devices on VMware ESXi
+	- Prep 352682: AATF Found: LD Name and UID not exposed to the OS
+	- Prep 354136: AATF Found: Controller model not displayed in `cat /proc/scsi/aacraid/` output
+	- RHEL 6.5 GA Kernel version: 2.6.32-431.el6
+	- Added Lenovo 8885E support
+
+Version: 1.2.1-50003 ()
+
+2014-08-26	Mahesh.Rajashekhara@pmcs.com
+		Achim.Leubner@pmcs.com
+
+aacraid_build:
+build:
+CHANGELOG:
+CheckInLog.txt:
+comminit.c:
+commsup.c:
+linit.c:
+aachba.c:
+commctrl.c:
+dpcsup.c:
+
+	- RHEL 7.0 Kernel version: 3.10.0-123.el7 added
+	- Fixed RHEL 5.x Xen kernel issue
+	- 354406 - AATF Found: Drive Firmware version not displayed for SATA drives in ARCConf output in HBA mode
+	- 355642 - Driver module load failed with ARC controller
+
+Version: 1.2.1-50004 ()
+
+2014-09-05	Mahesh.Rajashekhara@pmcs.com
+		Achim.Leubner@pmcs.com
+
+CheckInLog.txt:
+CHANGELOG:
+aachba.c:
+comminit.c:
+aacraid.h:
+build:
+
+	- Increase supported LUNs from 8 to 256
+	- Add 2K FIB support bit
+	- Add Ubuntu 14.04 driver support packages.
+
+Version: 1.2.1-50005 ()
+
+2014-10-07	Mahesh.Rajashekhara@pmcs.com
+
+CHANGELOG:
+CheckInLog.txt:
+aacraid_key.config:
+aacraid_key.priv:
+aacraid_key_pub.der:
+build/aacraid_kmod.spec:
+build/aacraid_build:
+build/aacraid_dd_skel.tar:
+aacraid.spec:
+build/aacraid_dd_skel/dd_sles10_32:
+build/aacraid_dd_skel/dd_sles10_64:
+
+	- Prep # 359111: Fixed SLES 10.x / 11.x driver binary package install/un-install issues.
+	- Prep # 357753: Add RHEL 7.0 GA kernel driver module signing support.
+
+Version: 1.2.1-50006 ()
+
+2014-11-18	Rajinikanth.pandurangan@pmcs.com
+
+aachba.c
+CHANGELOG
+CheckInLog.txt:
+	- Fix for PREP361037 - Add support for Inquiry vpd page 0x83 for logical wwn.
+	- Fix for "smartctl -i" failure in getting mode sense data.
+
+
+ToDo:
+	-
+
+2014-12-19	Gilbert.Wu@pmcs.com
+
+CHANGELOG:
+CheckInLog.txt:
+src.c
+
+1. Fix the IOP_RESET does not work on S8. Sending IOP_RESET command need to wait for only 10 sec instead of 5 minutes
+   in case of firmware does not response IOP_RESET command.
+2. Disable interrupt before setup interrupt routine to prevent spurious interrupt.
+
+Version: 1.2.1-50007 ()
+
+2014-12-19	Rajinikanth.pandurangan@pmcs.com
+
+aachba.c
+CHANGELOG
+CheckInLog.txt:
+	- Fix for PREP361037 - Add support for Inquiry vpd page 0x83 for logical wwn.
+	- Fix for "smartctl -i" failure in getting mode sense data.
+ToDo:
+	-
+	
+Version: 1.2.1-50007 ()
+
+2015-01-13	Rajinikanth.pandurangan@pmcs.com
+
+aachba.c
+comminit.c
+commsup.c
+dpcsup.c
+linit.c
+rx.c
+src.c
+aachba.h
+CheckInLog.txt:
+ - As part of the performance improvement, there are RHEL specific changes and some generic changes.
+    1. Specific for RHEL6.5/CentOS6.5 - For RHEL 6.X, now our driver exposes as lockless driver. This
+    means kernel will not lock before it calls our driver IO entry point.
+    2. Generic changes:
+       a. Now driver sets IRQ affinity hints.  This would help kernel to assign specific MSIx vector
+       to specific cpu core.
+       b. Couple of spin_lock has been removed in IO path.
+       c. If kernel > 2.6.37, by default kernel will not lock before it calls our IO entry.  Now our
+       driver doesn't lock itself before it submits each IO request. 
+ToDo:
+	- There is one more spinlock which can be removed by using atomic variables.
+	- Or rewrite IO path to make it compatible for NUMA.
+
+
+2015-1-16 - Murthy.bhat@pmcs.com
+
+CHANGELOG:
+CheckInLog.txt:
+aacraid_build:
+    - Added Ubuntu 14.10 13.10 and Debian 7.6 OS support
+    - Updated driver README
+
+ToDo:
+	-
+	
+2015-1-23 - Murthy.bhat@pmcs.com
+
+CHANGELOG
+CheckInLog.txt
+build/aacraid_dd_skel.tar
+build/aacraid_dd_skel/dd_fc
+build/aacraid_kmod_fc.spec
+build/kmodtool_aacraid_fc
+
+        - Added new driver SPEC/build scripts for building driver binaries for
+          Fedora, so that driver binaries can be built automatically on a native
+          Fedora virtual machines (automated build server).
+ToDo:
+	-
+
+2015-2-16 - Murthy.bhat@pmcs.com
+
+CHANGELOG
+CheckInLog.txt
+build/aacraid_dd_skel.tar
+build/aacraid_dd_skel/dkms
+build/aacraid_dkms.spec
+build/aacraid.src.spec
+
+        - Added new driver SPEC/build scripts for building DKMS driver binaries
+          and source rpm, so that driver binaries, source rpm can be built 
+          automatically on an automated build server.
+ToDo:
+	-
+
+2015-2-27 - Murthy.bhat@pmcs.com
+
+CHANGELOG
+CheckInLog.txt
+build/aacraid_dd_skel.tar
+build/README.txt
+build/aacraid_dd_skel/dd_fc/README.txt
+
+        - New master README, which explains changed methods in installing the OS on ARC 
+	  array and package name changes etc
+ToDo:
+	-
+2015-3-17 - rajinikanth.pandurangan@pmcs.com
+
+CHANGELOG
+CheckInLog.txt
+build/aacraid_build
+build/aacraid-kmod.spec
+build/README.txt
+
+	- Added automatic build support for RHEL7.1
+ToDo:
+	-
+	
+2015-3-19 - Murthy.bhat@pmcs.com
+
+CHANGELOG
+CheckInLog.txt
+build/aacraid_build
+build/aacraid_dd_skel.tar
+build/README.txt
+build/aacraid-kmod_fc20.spec
+build/aacraid_dd_skel/dd_fc/fc-post-install.sh
+
+    - Added Fedora 21 OS support
+    - Updated driver README
+
+ToDo:
+	-
+
+2015-3-27 - Murthy.bhat@pmcs.com
+
+build/aacraid_kmod.spec
+CHANGELOG
+CheckInLog.txt:
+	- Fix for PREP373778 - KMOD RPM installation not working
+
+ToDo:
+	-
+2015-4-16 - rajinikanth.pandurangan@pmcs.com
+
+linit.c
+CHANGELOG
+CheckInLog.txt:
+	- Fix for PREP #374209 (Title: The arcconf/maxView can not see the controller after release system from Suspend state(Ubuntu 14.04.1))
+
+ToDo:
+	-
+
+2015-4-17 - Murthy.bhat@pmcs.com
+
+CHANGELOG
+commsup.c
+aacraid.h
+CheckInLog.txt:
+	- Fix for Prep 371737 - Container UID to Serial Number to OS is all zeros.
+
+ToDo:
+	-
+
diff --git a/drivers/scsi/aacraid/Makefile b/drivers/scsi/aacraid/Makefile
index 1bd9fd1..9c98630 100644
--- a/drivers/scsi/aacraid/Makefile
+++ b/drivers/scsi/aacraid/Makefile
@@ -3,6 +3,6 @@
 obj-$(CONFIG_SCSI_AACRAID) := aacraid.o
 
 aacraid-objs	:= linit.o aachba.o commctrl.o comminit.o commsup.o \
-		   dpcsup.o rx.o sa.o rkt.o nark.o src.o
+		   dpcsup.o rx.o sa.o rkt.o nark.o src.o fwdebug.o csmi.o
 
 ccflags-y	:= -Idrivers/scsi
diff --git a/drivers/scsi/aacraid/README b/drivers/scsi/aacraid/README
new file mode 100644
index 0000000..4081ac8
--- /dev/null
+++ b/drivers/scsi/aacraid/README
@@ -0,0 +1,172 @@
+AACRAID Driver for Linux (take two)
+
+Introduction
+-------------------------
+The aacraid driver adds support for Adaptec (http://www.adaptec.com)
+RAID controllers. This is a major rewrite from the original
+Adaptec supplied driver. It has significantly cleaned up both the code
+and the running binary size (the module is less than half the size of
+the original).
+
+Supported Cards/Chipsets (Limited release or deprecated cards preceded by a #)
+-------------------------
+	PCI ID (pci.ids)	OEM	Product
+#	9005:0283:9005:0283	Adaptec	Catapult (3210S with arc firmware)
+#	9005:0284:9005:0284	Adaptec	Tomcat (3410S with arc firmware)
+	9005:0285:9005:0285	Adaptec	2200S (Vulcan)
+	9005:0285:9005:0286	Adaptec	2120S (Crusader)
+	9005:0285:9005:0287	Adaptec	2200S (Vulcan-2m)
+	9005:0285:9005:0288	Adaptec	3230S (Harrier)
+	9005:0285:9005:0289	Adaptec	3240S (Tornado)
+	9005:0285:9005:028a	Adaptec	2020ZCR (Skyhawk)
+	9005:0285:9005:028b	Adaptec	2025ZCR (Terminator)
+	9005:0286:9005:028c	Adaptec	2230S (Lancer)
+	9005:0286:9005:028c	Adaptec	2230SLP (Lancer)
+	9005:0286:9005:028d	Adaptec	2130S (Lancer)
+	9005:0285:9005:028e	Adaptec	2020SA (Skyhawk)
+	9005:0285:9005:028f	Adaptec	2025SA (Terminator)
+	9005:0285:9005:0290	Adaptec	2410SA (Jaguar)
+	9005:0285:103c:3227	Adaptec	2610SA (Bearcat HP release)
+#	9005:0285:0e11:0295	Adaptec	2610SA (Bearcat Compaq release)
+	9005:0285:9005:0293	Adaptec	21610SA (Corsair-16)
+	9005:0285:9005:0296	Adaptec	2240S (SabreExpress)
+	9005:0285:9005:0292	Adaptec	2810SA (Corsair-8)
+#	9005:0285:9005:0294	Adaptec	Prowler
+	9005:0285:9005:0297	Adaptec	4005 (AvonPark)
+	9005:0285:9005:0298	Adaptec	4000 (BlackBird)
+	9005:0285:9005:0299	Adaptec	4800SAS (Marauder-X)
+	9005:0285:9005:029a	Adaptec	4805SAS (Marauder-E)
+	9005:0286:9005:029b	Adaptec	2820SA (Intruder)
+	9005:0286:9005:029c	Adaptec	2620SA (Intruder)
+	9005:0286:9005:029d	Adaptec	2420SA (Intruder HP release)
+#	9005:0286:9005:02a2	Adaptec	3800 (Hurricane44)
+#	9005:0286:9005:02a7	Adaptec	3805 (Hurricane80)
+#	9005:0286:9005:02a8	Adaptec	3400 (Hurricane40)
+	9005:0286:9005:02ac	Adaptec	1800 (Typhoon44)
+#	9005:0286:9005:02b3	Adaptec	2400 (Hurricane40lm)
+	9005:0285:9005:02b5	Adaptec	5445 (Voodoo44)
+	9005:0285:15d9:02b5	SMC	AOC-USAS-S4i
+	9005:0285:9005:02b6	Adaptec	5805 (Voodoo80)
+	9005:0285:15d9:02b6	SMC	AOC-USAS-S8i
+	9005:0285:9005:02b7	Adaptec	5085 (Voodoo08)
+	9005:0285:9005:02bb	Adaptec	3405 (Marauder40LP)
+	9005:0285:9005:02bc	Adaptec	3805 (Marauder80LP)
+	9005:0285:9005:02c7	Adaptec	3085 (Marauder08ELP)
+	9005:0285:9005:02bd	Adaptec	31205 (Marauder120)
+	9005:0285:9005:02be	Adaptec	31605 (Marauder160)
+	9005:0285:9005:02c3	Adaptec	51205 (Voodoo120)
+	9005:0285:9005:02c4	Adaptec	51605 (Voodoo160)
+	9005:0285:15d9:02c9	SMC	AOC-USAS-S4iR
+	9005:0285:15d9:02ca	SMC	AOC-USAS-S8iR
+	9005:0285:9005:02ce	Adaptec	51245 (Voodoo124)
+	9005:0285:9005:02cf	Adaptec	51645 (Voodoo164)
+	9005:0285:9005:02d0	Adaptec	52445 (Voodoo244)
+	9005:0285:9005:02d1	Adaptec	5405 (Voodoo40)
+	9005:0285:15d9:02d2	SMC	AOC-USAS-S8i-LP
+	9005:0285:15d9:02d3	SMC	AOC-USAS-S8iR-LP
+	9005:0285:9005:02d4	Adaptec	ASR-2045 (Voodoo04 Lite)
+	9005:0285:9005:02d5	Adaptec	ASR-2405 (Voodoo40 Lite)
+	9005:0285:9005:02d6	Adaptec	ASR-2445 (Voodoo44 Lite)
+	9005:0285:9005:02d7	Adaptec	ASR-2805 (Voodoo80 Lite)
+	9005:0285:9005:02d8	Adaptec	5405Z (Voodoo40 BLBU)
+	9005:0285:9005:02d9	Adaptec	5445Z (Voodoo44 BLBU)
+	9005:0285:9005:02da	Adaptec	5805Z (Voodoo80 BLBU)
+#	9005:0285:9005:02db	Adaptec	5085G (Voodoo08 PM)
+#	9005:0285:9005:02dc	Adaptec	51245G (Voodoo124 PM)
+#	9005:0285:9005:02dd	Adaptec	51645G (Voodoo164 PM)
+#	9005:0285:9005:02de	Adaptec	52445G (Voodoo244 PM)
+#	9005:0285:9005:02df	Adaptec	ASR-2045G (Voodoo04 Lite PM)
+#	9005:0285:9005:02e0	Adaptec	ASR-2405G (Voodoo40 Lite PM)
+#	9005:0285:9005:02e1	Adaptec	ASR-2445G (Voodoo44 Lite PM)
+#	9005:0285:9005:02e2	Adaptec	ASR-2805G (Voodoo80 Lite PM)
+	1011:0046:9005:0364	Adaptec	5400S (Mustang)
+	1011:0046:9005:0365	Adaptec	5400S (Mustang)
+	9005:0287:9005:0800	Adaptec	Themisto (Jupiter)
+	9005:0200:9005:0200	Adaptec	Themisto (Jupiter)
+	9005:0286:9005:0800	Adaptec	Callisto (Jupiter)
+	1011:0046:9005:1364	Dell	PERC 2/QC (Quad Channel, Mustang)
+	1011:0046:9005:1365	Dell	PERC 2/QC (Quad Channel, Mustang)
+	1028:0001:1028:0001	Dell	PERC 2/Si (Iguana)
+	1028:0003:1028:0003	Dell	PERC 3/Si (SlimFast)
+	1028:0002:1028:0002	Dell	PERC 3/Di (Opal)
+	1028:0004:1028:0004	Dell	PERC 3/SiF (Iguana)
+	1028:0004:1028:00d0	Dell	PERC 3/DiF (Iguana)
+	1028:0002:1028:00d1	Dell	PERC 3/DiV (Viper)
+	1028:0002:1028:00d9	Dell	PERC 3/DiL (Lexus)
+	1028:000a:1028:0106	Dell	PERC 3/DiJ (Jaguar)
+	1028:000a:1028:011b	Dell	PERC 3/DiD (Dagger)
+	1028:000a:1028:0121	Dell	PERC 3/DiB (Boxster)
+	9005:0285:1028:0287	Dell	PERC 320/DC (Vulcan)
+	9005:0285:1028:0291	Dell	CERC 2 (DellCorsair)
+	1011:0046:103c:10c2	HP	NetRAID-4M (Mustang)
+	9005:0285:17aa:0286	Legend	S220 (Crusader)
+	9005:0285:17aa:0287	Legend	S230 (Vulcan)
+	9005:0285:9005:0290	IBM	ServeRAID 7t (Jaguar)
+	9005:0285:1014:02F2	IBM	ServeRAID 8i (AvonPark)
+#	9005:0285:1014:0312	IBM	ServeRAID 8i (AvonParkLite)
+	9005:0286:1014:9540	IBM	ServeRAID 8k/8k-l4 (AuroraLite)
+	9005:0286:1014:9580	IBM	ServeRAID 8k/8k-l8 (Aurora)
+#	9005:0286:1014:034d	IBM	ServeRAID 8s (Hurricane)
+	9005:0285:1014:034d	IBM	ServeRAID 8s (Marauder-E)
+	9005:0286:9005:029e	ICP	ICP9024RO (Lancer)
+	9005:0286:9005:029f	ICP	ICP9014RO (Lancer)
+	9005:0286:9005:02a0	ICP	ICP9047MA (Lancer)
+	9005:0286:9005:02a1	ICP	ICP9087MA (Lancer)
+#	9005:0286:9005:02a3	ICP	ICP5445AU (Hurricane44)
+	9005:0285:9005:02a4	ICP	ICP9085LI (Marauder-X)
+	9005:0285:9005:02a5	ICP	ICP5085BR (Marauder-E)
+	9005:0286:9005:02a6	ICP	ICP9067MA (Intruder-6)
+#	9005:0286:9005:02a9	ICP	ICP5085AU (Hurricane80)
+#	9005:0286:9005:02aa	ICP	ICP5045AU (Hurricane40)
+	9005:0285:9005:02b2	ICP	(Voodoo 8 internal 8 external)
+#	9005:0286:9005:02b4	ICP	ICP5045AL (Hurricane40lm)
+	9005:0285:9005:02b8	ICP	ICP5445SL (Voodoo44)
+	9005:0285:9005:02b9	ICP	ICP5085SL (Voodoo80)
+	9005:0285:9005:02ba	ICP	ICP5805SL (Voodoo08)
+	9005:0285:9005:02bf	ICP	ICP5045BL (Marauder40LP)
+	9005:0285:9005:02c0	ICP	ICP5085BL (Marauder80LP)
+	9005:0285:9005:02c8	ICP	ICP5805BL (Marauder08ELP)
+	9005:0285:9005:02c1	ICP	ICP5125BR (Marauder120)
+	9005:0285:9005:02c2	ICP	ICP5165BR (Marauder160)
+	9005:0285:9005:02c5	ICP	ICP5125SL (Voodoo120)
+	9005:0285:9005:02c6	ICP	ICP5165SL (Voodoo160)
+	9005:0286:9005:02ab		(Typhoon40)
+	9005:0286:9005:02ad		(Aurora ARK)
+	9005:0286:9005:02ae		(Aurora Lite ARK)
+	9005:0285:9005:02b0		(Sunrise Lake ARK)
+	9005:0285:9005:02b1	Adaptec	(Voodoo 8 internal 8 external)
+	9005:0285:108e:7aac	SUN	STK RAID REM (Voodoo44 Coyote)
+	9005:0285:108e:0286	SUN	STK RAID INT (Cougar)
+	9005:0285:108e:0287	SUN	STK RAID EXT (Prometheus)
+	9005:0285:108e:7aae	SUN	STK RAID EM (Narvi)
+
+People
+-------------------------
+Alan Cox <alan@redhat.com>
+Christoph Hellwig <hch@infradead.org>	(updates for new-style PCI probing and SCSI host registration,
+					 small cleanups/fixes)
+Matt Domsch <matt_domsch@dell.com>	(revision ioctl, adapter messages)
+Deanna Bonds                            (non-DASD support, PAE fibs and 64 bit, added new adaptec controllers
+					 added new ioctls, changed scsi interface to use new error handler,
+					 increased the number of fibs and outstanding commands to a container)
+
+					(fixed 64bit and 64G memory model, changed confusing naming convention
+					 where fibs that go to the hardware are consistently called hw_fibs and
+					 not just fibs like the name of the driver tracking structure)
+Mark Salyzyn <Mark_Salyzyn@adaptec.com> Fixed panic issues and added some new product ids for upcoming hbas. Performance tuning, card failover and bug mitigations.
+Achim Leubner <Achim_Leubner@adaptec.com>
+
+Original Driver
+-------------------------
+Adaptec Unix OEM Product Group
+
+Mailing List
+-------------------------
+linux-scsi@vger.kernel.org (Interested parties troll here)
+Also note this is very different to Brian's original driver
+so don't expect him to support it.
+Adaptec does support this driver.  Contact Adaptec tech support or
+aacraid@adaptec.com
+
+Original by Brian Boerner February 2001
+Rewritten by Alan Cox, November 2001
diff --git a/drivers/scsi/aacraid/README.ServeRAID b/drivers/scsi/aacraid/README.ServeRAID
new file mode 100644
index 0000000..239c6d3
--- /dev/null
+++ b/drivers/scsi/aacraid/README.ServeRAID
@@ -0,0 +1,115 @@
+AACRAID Driver for Linux v1.1-5[2407]
+
+Introduction
+-------------------------
+The aacraid driver adds support for Adaptec (http://www.adaptec.com)
+RAID controllers. This is a major rewrite from the original 
+Adaptec supplied driver. It has signficantly cleaned up both the code
+and the running binary size (the module is less than half the size of
+the original).
+
+Supported Cards/Chipsets
+-------------------------
+	IBM ServeRAID 7t
+	IBM ServeRAID 8i
+	IBM ServeRAID 8k/8k-l4
+	IBM ServeRAID 8k/8k-l8
+
+Installation Instructions
+-------------------------
+The driver rpm is bundled with binary compiles for all suppoted kernels, all
+supported configurations and all supported architectures. The rpm will take
+steps to match the correct binaries and install them into the /lib/modules
+directory and inspects the grub/lilo/boot configuration to perform the
+necessary make init RAM disk functions. Installations and Removal is a simple
+application of rpm -i and rpm -e respectively. If the kernel is upgraded, the
+rpm needs to be reinstalled, or one can rerun the post script by the following
+steps:
+	# cd /opt/Adaptec/aacraid
+	# ./install.sh
+
+The driver update disks must be installed under RedHat utilizing the 'linux dd'
+boot line to the installation boot prompt.
+
+To determine if the correct driver version is installed, one of:
+	# cat /proc/scsi/aacraid/?
+	# cat /sys/class/scsi_host/host?/*version
+	# dmesg | grep -i aac
+	# modinfo aacraid | grep version
+can be used to query the driver version stamp.
+
+Supported Installations:
+-------------------------
+RHAS2.1
+	2.4.9-e.3	2.4.9-e.5	2.4.9-e.8	2.4.9-e.9
+	2.4.9-e.10	2.4.9-e.12	2.4.9-e.16	2.4.9-e.23
+	2.4.9-e.24	2.4.9-e.25	2.4.9-e.27	2.4.9-e.30
+	2.4.9-e.34	2.4.9-e.35	2.4.9-e.37	2.4.9-e.38
+	2.4.9-e.40	2.4.9-e.41	2.4.9-e.43	2.4.9-e.48
+	2.4.9-e.49	2.4.9-e.57	2.4.9-e.59	2.4.9-e.62
+RHEL3
+	2.4.21-4.EL	   2.4.21-4.0.1.EL	2.4.21-4.0.2.EL
+	2.4.21-9.0.1.EL	   2.4.21-9.0.3.EL	2.4.21-9.EL
+	2.4.21-9.EL.Intel9 2.4.21-15.EL		2.4.21-15.0.2.EL
+	2.4.21-15.0.3.EL   2.4.21-15.0.4.EL	2.4.21-17.EL
+	2.4.21-20.0.1.EL   2.4.21-20.EL		2.4.21-22.EL
+	2.4.21-27.0.1.EL   2.4.21-27.0.2.EL-2.4	2.4.21-27.0.4.EL-2.4
+	2.4.21-27.EL	   2.4.21-31.EL		2.4.21-32.0.1.EL-2.4
+	2.4.21-32.EL
+RHEL4
+	2.6.9-5.EL	2.6.9-5.0.3.EL-2.6	2.6.9-5.0.5.EL-2.6
+	2.6.9-11.EL
+FC2
+	2.6.5-1.358	2.6.9-1.11_FC2		2.6.10-1.8_FC2
+	2.6.10-1.9_FC2	2.6.10-1.12_FC2		2.6.10-1.14_FC2-2.6
+	2.6.10-1.770_FC2
+FC3
+	2.6.9-1.667	     2.6.9-1.681_FC3-2.6	2.6.9-1.724_FC3-2.6
+	2.6.10-1.737_FC3-2.6 2.6.10-1.741_FC3-2.6	2.6.10-1.760_FC3-2.6
+	2.6.10-1.766_FC3-2.6 2.6.10-1.770_FC3-2.6	2.6.11-1.14_FC3-2.6
+	2.6.11-1.27_FC3-2.6  2.6.11-1.35_FC3-2.6
+FC4
+	2.6.11-1.1369_FC4
+
+Support:
+	IBM Support for Drivers on xSeries & IntelliStation Hardware
+	IBM Support Web Site:
+		http://www.pc.ibm.com/support
+	IBM Marketing eServer xSeries Web Site:
+		http://www.pc.ibm.com/us/eserver/xseries
+	During the warranty period for xSeries servers, IntelliStation
+	workstations, and e325 servers, problem determination and service may
+	be obtained from IBM. If you  are not sure the hardware is still under
+	warranty, call IBM along with the machine type and serial number.
+	IBM will determine whether the hardware is under warranty. To locate
+	your local IBM Support telephone number go to URL:
+		http://www.pc.ibm.com/qtechinfo/YAST-3P2QYL.html. 
+
+People
+-------------------------
+Alan Cox <alan@redhat.com>
+Christoph Hellwig <hch@infradead.org>	(updates for new-style PCI probing and SCSI host registration,
+					 small cleanups/fixes)
+Matt Domsch <matt_domsch@dell.com>	(revision ioctl, adapter messages)
+Deanna Bonds                            (non-DASD support, PAE fibs and 64 bit, added new adaptec controllers
+					 added new ioctls, changed scsi interface to use new error handler,
+					 increased the number of fibs and outstanding commands to a container)
+
+					(fixed 64bit and 64G memory model, changed confusing naming convention
+					 where fibs that go to the hardware are consistently called hw_fibs and
+					 not just fibs like the name of the driver tracking structure)
+Mark Salyzyn <Mark_Salyzyn@adaptec.com> Fixed panic issues and added some new product ids for upcoming hbas. Performance tuning, card failover and bug mitigations.
+
+Original Driver
+-------------------------
+Adaptec Unix OEM Product Group
+
+Mailing List
+-------------------------
+linux-scsi@vger.kernel.org (Interested parties troll here)
+Also note this is very different to Brian's original driver
+so don't expect him to support it.
+Adaptec does support this driver.  Contact IBM & Addaptec tech support.
+
+Original by Brian Boerner February 2001
+Rewritten by Alan Cox, November 2001
diff --git a/drivers/scsi/aacraid/TODO b/drivers/scsi/aacraid/TODO
index 78dc863..81585f0 100644
--- a/drivers/scsi/aacraid/TODO
+++ b/drivers/scsi/aacraid/TODO
@@ -1,3 +1,9 @@
 o	Testing
 o	More testing
+o	add %postun (uninstall.sh) script to rpm
 o	I/O size increase
+o	Add support for CONFIG_PM
+	 pci.suspend(struct pci_dev *pdev, pm_message_t state);
+	 pci.suspend_late(struct pci_dev *pdev, pm_message_t state);
+	 pci.resume_early(struct pci_dev *pdev);
+	 pci.resume(struct pci_dev *pdev);
diff --git a/drivers/scsi/aacraid/VMware-3.0.1.c b/drivers/scsi/aacraid/VMware-3.0.1.c
new file mode 100644
index 0000000..c9f7711
--- /dev/null
+++ b/drivers/scsi/aacraid/VMware-3.0.1.c
@@ -0,0 +1,386 @@
+/* ****************************************************************
+ * Portions Copyright 2004 VMware, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ * ****************************************************************/
+
+/*
+ * linux_module_heap.c --
+ *
+ *	This file enables a module to have its own private heap, replete with
+ *	posion-value checks, etc. to guarantee that modules and other kernel
+ *	code don't step on each other's toes. This functionality is available to
+ *	any module that compiles this code and links against it. Options
+ *	specifying the size of the private heap, among other things, must be
+ *	present within the module's Makefile, providing defined preprocessing
+ *	values to the compiler. Thos preprocessing defines should be:
+ *
+ *	Required:
+ *	
+ *	- LINUX_MODULE_HEAP_INITIAL=<number-in-bytes-guaranteed-allocated>
+ *	- LINUX_MODULE_HEAP_MAX=<number-in-bytes-of-maximum-allocation>
+ *	- LINUX_MODULE_HEAP_NAME=<string>
+ *
+ *	Optional:
+ *	
+ *	- LINUX_MODULE_HEAP_NO_AUTO_LOAD
+ *
+ *	The optional preprocessing define should only be used in very rare
+ *	cases. Those cases would be modules that want to perform additional
+ *	operations inside vmk_early_init_module and vmk_late_cleanup_module. The
+ *	first module that actually does this should most likely create a
+ *	linux_module_heap.h file that exports the linux_module_heap_init and
+ *	cleanup functions. That module should make sure to specify
+ *	LINUX_MODULE_HEAP_NO_AUTO_LOAD in its Makefile and link against the
+ *	newly created header file as well as its own .c file that contains new
+ *	vmk_early_init_module and cleanup functions (that still call the
+ *	linux_module_heap_init and cleanup functions).
+ */
+
+#ifndef LINUX_MODULE_HEAP_INITIAL
+#error
+#endif
+
+#ifndef LINUX_MODULE_HEAP_MAX
+#error
+#endif
+
+#ifndef LINUX_MODULE_HEAP_NAME
+#error
+#endif
+
+#if LINUX_MODULE_HEAP_INITIAL > LINUX_MODULE_HEAP_MAX
+#error
+#endif
+
+#if LINUX_MODULE_HEAP_INITIAL < 0
+#error
+#endif
+
+#include <asm/page.h>
+#include <linux/types.h>
+#include <linux/mm.h>
+#include <linux/spinlock.h>
+#include <linux/pci.h>
+#include <linux/module.h>
+
+#include "vmkapi.h"
+
+static vmk_HeapID moduleHeap = VMK_INVALID_HEAP_ID;
+
+/*
+ * The following functions - kfree and kmalloc, are implemented both here and in
+ * vmklinux/linux_stubs.c. Most likely, if there are any changes made to these,
+ * the changes should be propagated to the corresponding functions in vmklinux.
+ * We need to define these functions here so that the drivers are able to
+ * allocate memory from the appropriate driver heap memory.
+ *
+ * NOTE: We could have eliminated these functions and used the versions defined
+ * in linux_stubs.c, but we need to distinguish between the memory allocated
+ * for the drivers vs the memory allocated for vmklinux's internal use - say,
+ * the call sequence is driver->vmklinux->kmalloc(), here the kmalloc() call
+ * is on behalf of vmklinux, but there is no way to determine this from the
+ * World->modStk since we don't push vmklinux's module id on to the stack.
+ */
+
+void
+kfree(const void *p)
+{
+   vmk_HeapFree(moduleHeap, (void *)p);
+}
+
+void *
+kmalloc(size_t size, int priority)
+{
+   size_t actual = 1;
+   void *d;
+
+   /*
+    * Allocate blocks in powers-of-2 (like Linux), so we tolerate any
+    * driver bugs that don't show up because of the large allocation size.
+    */
+   while (actual < size) {
+      actual *= 2;
+   }
+   d = vmk_HeapAllocWithRA(moduleHeap, actual, __builtin_return_address(0));
+   return d;
+}
+
+/* kmem_cache implementation from Mike's infiniband port */
+
+#define KMEM_CACHE_MAGIC	0xfa4b9c23
+
+typedef struct kmem_cache_element {
+   unsigned int magic;
+   struct kmem_cache_element *next;
+} kmem_cache_element;
+
+struct kmem_cache_s {
+   unsigned int size;
+   kmem_cache_element *list;
+   spinlock_t lock;
+   void (*ctor)(void *, kmem_cache_t *, unsigned long);
+};
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_create
+ *
+ *      Create a memory cache that will hold elements of a given size.
+ *
+ * Arguments
+ *      ctor is a constructor that will initialize a cache element
+ *           when allocated from the pool
+ *      dtor is a destructor that would normally be used on an
+ *           element before it is returned to the pool, but we do
+ *           currently not implement it
+ *
+ * Results:
+ *      A pointer to the cache to be used on subsequent calls to
+ *           kmem_cache_{alloc, free, destroy} or NULL on error
+ *
+ * Side effects:
+ *      A kmem cache heap object is allocated
+ *
+ *----------------------------------------------------------------------
+ */
+
+kmem_cache_t *
+kmem_cache_create(const char *name , 
+		  size_t size, size_t offset, unsigned long flags,
+		  void (*ctor)(void *, kmem_cache_t *, unsigned long),
+		  void (*dtor)(void *, kmem_cache_t *, unsigned long))
+{
+   kmem_cache_t *cache;
+
+   if (dtor != NULL) {
+      vmk_Warning("kmem_cache_create: dtor != NULL\n");
+      return NULL;
+   }
+
+   if (offset != 0) {
+      vmk_Warning("kmem_cache_create: offset = %d\n", offset);
+      return NULL;
+   }
+
+   cache = (kmem_cache_t *)vmk_HeapAllocWithRA(moduleHeap, sizeof(kmem_cache_t),
+                                               __builtin_return_address(0));
+   if (cache == NULL) {
+      vmk_Warning("kmem_cache_create: out of memory\n");
+      return NULL;
+   }
+
+   cache->size = size;
+   cache->list = NULL;
+   cache->ctor = ctor;
+
+   // 
+   // This lock can be grabbed with a linux spin lock held so we have to
+   // be at least one higher in rank.
+   //
+   vmk_spin_lock_init(&cache->lock);
+
+   return cache;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_destroy
+ *
+ *      Deallocate all elements in a kmem cache and destroy the
+ *      kmem_cache object itself
+ *
+ * Results:
+ *      Always 0
+ *
+ * Side effects:
+ *      All cached objects and the kmem_cache object itself are freed
+ *
+ *----------------------------------------------------------------------
+ */
+
+int 
+kmem_cache_destroy(kmem_cache_t *cache)
+{
+   vmk_spin_lock_irqsave(&cache->lock);
+   while (cache->list != NULL) {
+      kmem_cache_element *head = cache->list;
+      cache->list = head->next;
+      vmk_HeapFree(moduleHeap, head);
+   }
+   vmk_spin_unlock_irqrestore(&cache->lock);
+   vmk_spin_lock_destroy(&cache->lock);
+   vmk_HeapFree(moduleHeap, cache);
+   return 0;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_alloc
+ *
+ *      Allocate an element from the cache pool. If no free elements
+ *      exist a new one will be allocated from the heap.
+ *
+ * Results:
+ *      A pointer to the allocated object or NULL on error
+ *
+ * Side effects:
+ *      Cache list may change or a new object is allocated from the heap
+ *
+ *----------------------------------------------------------------------
+ */
+
+void *
+kmem_cache_alloc(kmem_cache_t *cache, int flags)
+{
+   void *res;
+   kmem_cache_element *el;
+
+   vmk_spin_lock_irqsave(&cache->lock);
+
+   if (cache->list == NULL) {
+      el = (kmem_cache_element *)vmk_HeapAllocWithRA(moduleHeap, cache->size +
+                                                     sizeof(kmem_cache_element),
+                                                     __builtin_return_address(0));
+      if (el == NULL) {
+         vmk_Warning("kmem_cache_alloc: out of memory\n");
+         vmk_spin_unlock_irqrestore(&cache->lock);
+         return NULL;
+      }
+      el->magic = KMEM_CACHE_MAGIC;
+   } else {
+      el = cache->list;
+      cache->list = el->next;
+   }
+   vmk_spin_unlock_irqrestore(&cache->lock);
+
+   res = (char *)el + sizeof(kmem_cache_element);
+   if (cache->ctor != NULL) {
+      cache->ctor(res, cache, 0);
+   }
+
+   return res;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_free
+ *
+ *      Release an element to the object cache. The memory will not be
+ *      freed until the cache is destroyed
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      Cache list will change
+ *
+ *----------------------------------------------------------------------
+ */
+
+void 
+kmem_cache_free(kmem_cache_t *cache, void *item)
+{
+   kmem_cache_element *el = 
+      (kmem_cache_element *)((char *)item - sizeof(kmem_cache_element));
+
+   if (el->magic != KMEM_CACHE_MAGIC) {
+      panic("kmem_cache_free: Bad magic\n");
+   }
+
+   vmk_spin_lock_irqsave(&cache->lock);
+
+   el->next = cache->list;
+   cache->list = el;
+
+   vmk_spin_unlock_irqrestore(&cache->lock);
+}
+
+#ifdef MODULE
+static int heap_initial = LINUX_MODULE_HEAP_INITIAL;
+MODULE_PARM(heap_initial, "i");
+MODULE_PARM_DESC(heap_initial, "Initial heap size allocated for the driver.");
+
+static int heap_max = LINUX_MODULE_HEAP_MAX;
+MODULE_PARM(heap_max, "i");
+MODULE_PARM_DESC(heap_max, "Maximum attainable heap size for the driver.");
+#else
+#error "You can only compile and link linux_module_heap with modules, which" \
+       "means that MODULE has to be defined when compiling it..."
+#endif
+
+/*
+ * The following two functions are used to create and destroy the private module
+ * heap. The init function MUST be called before any other code in the module
+ * has a chance to call kfree, kmalloc, etc. And the destroy function MUST be
+ * called after those operations are all finished. 
+ *
+ */
+
+int
+linux_module_heap_init(void)
+{
+   vmk_uint32 moduleID;
+
+   moduleID = vmk_ModuleGetCurrentID();
+
+   if (heap_initial > heap_max) {
+      heap_initial = heap_max;
+      vmk_Warning("Initial heap size > max. Limiting to max!!!\n");
+   }
+
+   vmk_Log("Initial heap size : %d, max heap size: %d\n",
+           heap_initial, heap_max);
+   moduleHeap = vmk_HeapCreateDynamic(moduleID,
+				      LINUX_MODULE_HEAP_NAME,
+				      VMK_HEAP_LOW_MEM,
+				      heap_initial,
+				      heap_max);
+
+   vmk_ModuleSetHeapID(moduleID, moduleHeap);
+
+   if (moduleHeap == VMK_INVALID_HEAP_ID) {
+      return -1;
+   }
+
+   return 0;
+}
+ 
+int
+linux_module_heap_cleanup(void)
+{
+   vmk_HeapDestroyDynamic(moduleHeap); 
+
+   moduleHeap = VMK_INVALID_HEAP_ID;
+
+   return 0;
+}
+
+/*
+ * Modules can have the preceding two functions called automatically at the
+ * right time by compiling and linking normally. To disable this automatic
+ * functionality, you can specify LINUX_MODULE_HEAP_NO_AUTO_LOAD in your
+ * Makefile, which will disable the following two functions. See the top of this
+ * file for an explanation of why this might be useful.
+ */
+
+#ifndef LINUX_MODULE_HEAP_NO_AUTO_LOAD
+int
+vmk_early_init_module(void)
+{
+   return linux_module_heap_init();
+}
+
+int
+vmk_late_cleanup_module(void)
+{
+   return linux_module_heap_cleanup();
+}
+#endif // LINUX_MODULE_HEAP_NO_AUTO_LOAD
diff --git a/drivers/scsi/aacraid/VMware-3.0.2.c b/drivers/scsi/aacraid/VMware-3.0.2.c
new file mode 100644
index 0000000..c9f7711
--- /dev/null
+++ b/drivers/scsi/aacraid/VMware-3.0.2.c
@@ -0,0 +1,386 @@
+/* ****************************************************************
+ * Portions Copyright 2004 VMware, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ * ****************************************************************/
+
+/*
+ * linux_module_heap.c --
+ *
+ *	This file enables a module to have its own private heap, replete with
+ *	posion-value checks, etc. to guarantee that modules and other kernel
+ *	code don't step on each other's toes. This functionality is available to
+ *	any module that compiles this code and links against it. Options
+ *	specifying the size of the private heap, among other things, must be
+ *	present within the module's Makefile, providing defined preprocessing
+ *	values to the compiler. Thos preprocessing defines should be:
+ *
+ *	Required:
+ *	
+ *	- LINUX_MODULE_HEAP_INITIAL=<number-in-bytes-guaranteed-allocated>
+ *	- LINUX_MODULE_HEAP_MAX=<number-in-bytes-of-maximum-allocation>
+ *	- LINUX_MODULE_HEAP_NAME=<string>
+ *
+ *	Optional:
+ *	
+ *	- LINUX_MODULE_HEAP_NO_AUTO_LOAD
+ *
+ *	The optional preprocessing define should only be used in very rare
+ *	cases. Those cases would be modules that want to perform additional
+ *	operations inside vmk_early_init_module and vmk_late_cleanup_module. The
+ *	first module that actually does this should most likely create a
+ *	linux_module_heap.h file that exports the linux_module_heap_init and
+ *	cleanup functions. That module should make sure to specify
+ *	LINUX_MODULE_HEAP_NO_AUTO_LOAD in its Makefile and link against the
+ *	newly created header file as well as its own .c file that contains new
+ *	vmk_early_init_module and cleanup functions (that still call the
+ *	linux_module_heap_init and cleanup functions).
+ */
+
+#ifndef LINUX_MODULE_HEAP_INITIAL
+#error
+#endif
+
+#ifndef LINUX_MODULE_HEAP_MAX
+#error
+#endif
+
+#ifndef LINUX_MODULE_HEAP_NAME
+#error
+#endif
+
+#if LINUX_MODULE_HEAP_INITIAL > LINUX_MODULE_HEAP_MAX
+#error
+#endif
+
+#if LINUX_MODULE_HEAP_INITIAL < 0
+#error
+#endif
+
+#include <asm/page.h>
+#include <linux/types.h>
+#include <linux/mm.h>
+#include <linux/spinlock.h>
+#include <linux/pci.h>
+#include <linux/module.h>
+
+#include "vmkapi.h"
+
+static vmk_HeapID moduleHeap = VMK_INVALID_HEAP_ID;
+
+/*
+ * The following functions - kfree and kmalloc, are implemented both here and in
+ * vmklinux/linux_stubs.c. Most likely, if there are any changes made to these,
+ * the changes should be propagated to the corresponding functions in vmklinux.
+ * We need to define these functions here so that the drivers are able to
+ * allocate memory from the appropriate driver heap memory.
+ *
+ * NOTE: We could have eliminated these functions and used the versions defined
+ * in linux_stubs.c, but we need to distinguish between the memory allocated
+ * for the drivers vs the memory allocated for vmklinux's internal use - say,
+ * the call sequence is driver->vmklinux->kmalloc(), here the kmalloc() call
+ * is on behalf of vmklinux, but there is no way to determine this from the
+ * World->modStk since we don't push vmklinux's module id on to the stack.
+ */
+
+void
+kfree(const void *p)
+{
+   vmk_HeapFree(moduleHeap, (void *)p);
+}
+
+void *
+kmalloc(size_t size, int priority)
+{
+   size_t actual = 1;
+   void *d;
+
+   /*
+    * Allocate blocks in powers-of-2 (like Linux), so we tolerate any
+    * driver bugs that don't show up because of the large allocation size.
+    */
+   while (actual < size) {
+      actual *= 2;
+   }
+   d = vmk_HeapAllocWithRA(moduleHeap, actual, __builtin_return_address(0));
+   return d;
+}
+
+/* kmem_cache implementation from Mike's infiniband port */
+
+#define KMEM_CACHE_MAGIC	0xfa4b9c23
+
+typedef struct kmem_cache_element {
+   unsigned int magic;
+   struct kmem_cache_element *next;
+} kmem_cache_element;
+
+struct kmem_cache_s {
+   unsigned int size;
+   kmem_cache_element *list;
+   spinlock_t lock;
+   void (*ctor)(void *, kmem_cache_t *, unsigned long);
+};
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_create
+ *
+ *      Create a memory cache that will hold elements of a given size.
+ *
+ * Arguments
+ *      ctor is a constructor that will initialize a cache element
+ *           when allocated from the pool
+ *      dtor is a destructor that would normally be used on an
+ *           element before it is returned to the pool, but we do
+ *           currently not implement it
+ *
+ * Results:
+ *      A pointer to the cache to be used on subsequent calls to
+ *           kmem_cache_{alloc, free, destroy} or NULL on error
+ *
+ * Side effects:
+ *      A kmem cache heap object is allocated
+ *
+ *----------------------------------------------------------------------
+ */
+
+kmem_cache_t *
+kmem_cache_create(const char *name , 
+		  size_t size, size_t offset, unsigned long flags,
+		  void (*ctor)(void *, kmem_cache_t *, unsigned long),
+		  void (*dtor)(void *, kmem_cache_t *, unsigned long))
+{
+   kmem_cache_t *cache;
+
+   if (dtor != NULL) {
+      vmk_Warning("kmem_cache_create: dtor != NULL\n");
+      return NULL;
+   }
+
+   if (offset != 0) {
+      vmk_Warning("kmem_cache_create: offset = %d\n", offset);
+      return NULL;
+   }
+
+   cache = (kmem_cache_t *)vmk_HeapAllocWithRA(moduleHeap, sizeof(kmem_cache_t),
+                                               __builtin_return_address(0));
+   if (cache == NULL) {
+      vmk_Warning("kmem_cache_create: out of memory\n");
+      return NULL;
+   }
+
+   cache->size = size;
+   cache->list = NULL;
+   cache->ctor = ctor;
+
+   // 
+   // This lock can be grabbed with a linux spin lock held so we have to
+   // be at least one higher in rank.
+   //
+   vmk_spin_lock_init(&cache->lock);
+
+   return cache;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_destroy
+ *
+ *      Deallocate all elements in a kmem cache and destroy the
+ *      kmem_cache object itself
+ *
+ * Results:
+ *      Always 0
+ *
+ * Side effects:
+ *      All cached objects and the kmem_cache object itself are freed
+ *
+ *----------------------------------------------------------------------
+ */
+
+int 
+kmem_cache_destroy(kmem_cache_t *cache)
+{
+   vmk_spin_lock_irqsave(&cache->lock);
+   while (cache->list != NULL) {
+      kmem_cache_element *head = cache->list;
+      cache->list = head->next;
+      vmk_HeapFree(moduleHeap, head);
+   }
+   vmk_spin_unlock_irqrestore(&cache->lock);
+   vmk_spin_lock_destroy(&cache->lock);
+   vmk_HeapFree(moduleHeap, cache);
+   return 0;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_alloc
+ *
+ *      Allocate an element from the cache pool. If no free elements
+ *      exist a new one will be allocated from the heap.
+ *
+ * Results:
+ *      A pointer to the allocated object or NULL on error
+ *
+ * Side effects:
+ *      Cache list may change or a new object is allocated from the heap
+ *
+ *----------------------------------------------------------------------
+ */
+
+void *
+kmem_cache_alloc(kmem_cache_t *cache, int flags)
+{
+   void *res;
+   kmem_cache_element *el;
+
+   vmk_spin_lock_irqsave(&cache->lock);
+
+   if (cache->list == NULL) {
+      el = (kmem_cache_element *)vmk_HeapAllocWithRA(moduleHeap, cache->size +
+                                                     sizeof(kmem_cache_element),
+                                                     __builtin_return_address(0));
+      if (el == NULL) {
+         vmk_Warning("kmem_cache_alloc: out of memory\n");
+         vmk_spin_unlock_irqrestore(&cache->lock);
+         return NULL;
+      }
+      el->magic = KMEM_CACHE_MAGIC;
+   } else {
+      el = cache->list;
+      cache->list = el->next;
+   }
+   vmk_spin_unlock_irqrestore(&cache->lock);
+
+   res = (char *)el + sizeof(kmem_cache_element);
+   if (cache->ctor != NULL) {
+      cache->ctor(res, cache, 0);
+   }
+
+   return res;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_free
+ *
+ *      Release an element to the object cache. The memory will not be
+ *      freed until the cache is destroyed
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      Cache list will change
+ *
+ *----------------------------------------------------------------------
+ */
+
+void 
+kmem_cache_free(kmem_cache_t *cache, void *item)
+{
+   kmem_cache_element *el = 
+      (kmem_cache_element *)((char *)item - sizeof(kmem_cache_element));
+
+   if (el->magic != KMEM_CACHE_MAGIC) {
+      panic("kmem_cache_free: Bad magic\n");
+   }
+
+   vmk_spin_lock_irqsave(&cache->lock);
+
+   el->next = cache->list;
+   cache->list = el;
+
+   vmk_spin_unlock_irqrestore(&cache->lock);
+}
+
+#ifdef MODULE
+static int heap_initial = LINUX_MODULE_HEAP_INITIAL;
+MODULE_PARM(heap_initial, "i");
+MODULE_PARM_DESC(heap_initial, "Initial heap size allocated for the driver.");
+
+static int heap_max = LINUX_MODULE_HEAP_MAX;
+MODULE_PARM(heap_max, "i");
+MODULE_PARM_DESC(heap_max, "Maximum attainable heap size for the driver.");
+#else
+#error "You can only compile and link linux_module_heap with modules, which" \
+       "means that MODULE has to be defined when compiling it..."
+#endif
+
+/*
+ * The following two functions are used to create and destroy the private module
+ * heap. The init function MUST be called before any other code in the module
+ * has a chance to call kfree, kmalloc, etc. And the destroy function MUST be
+ * called after those operations are all finished. 
+ *
+ */
+
+int
+linux_module_heap_init(void)
+{
+   vmk_uint32 moduleID;
+
+   moduleID = vmk_ModuleGetCurrentID();
+
+   if (heap_initial > heap_max) {
+      heap_initial = heap_max;
+      vmk_Warning("Initial heap size > max. Limiting to max!!!\n");
+   }
+
+   vmk_Log("Initial heap size : %d, max heap size: %d\n",
+           heap_initial, heap_max);
+   moduleHeap = vmk_HeapCreateDynamic(moduleID,
+				      LINUX_MODULE_HEAP_NAME,
+				      VMK_HEAP_LOW_MEM,
+				      heap_initial,
+				      heap_max);
+
+   vmk_ModuleSetHeapID(moduleID, moduleHeap);
+
+   if (moduleHeap == VMK_INVALID_HEAP_ID) {
+      return -1;
+   }
+
+   return 0;
+}
+ 
+int
+linux_module_heap_cleanup(void)
+{
+   vmk_HeapDestroyDynamic(moduleHeap); 
+
+   moduleHeap = VMK_INVALID_HEAP_ID;
+
+   return 0;
+}
+
+/*
+ * Modules can have the preceding two functions called automatically at the
+ * right time by compiling and linking normally. To disable this automatic
+ * functionality, you can specify LINUX_MODULE_HEAP_NO_AUTO_LOAD in your
+ * Makefile, which will disable the following two functions. See the top of this
+ * file for an explanation of why this might be useful.
+ */
+
+#ifndef LINUX_MODULE_HEAP_NO_AUTO_LOAD
+int
+vmk_early_init_module(void)
+{
+   return linux_module_heap_init();
+}
+
+int
+vmk_late_cleanup_module(void)
+{
+   return linux_module_heap_cleanup();
+}
+#endif // LINUX_MODULE_HEAP_NO_AUTO_LOAD
diff --git a/drivers/scsi/aacraid/VMware-3.0.c b/drivers/scsi/aacraid/VMware-3.0.c
new file mode 100644
index 0000000..c9f7711
--- /dev/null
+++ b/drivers/scsi/aacraid/VMware-3.0.c
@@ -0,0 +1,386 @@
+/* ****************************************************************
+ * Portions Copyright 2004 VMware, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ * ****************************************************************/
+
+/*
+ * linux_module_heap.c --
+ *
+ *	This file enables a module to have its own private heap, replete with
+ *	posion-value checks, etc. to guarantee that modules and other kernel
+ *	code don't step on each other's toes. This functionality is available to
+ *	any module that compiles this code and links against it. Options
+ *	specifying the size of the private heap, among other things, must be
+ *	present within the module's Makefile, providing defined preprocessing
+ *	values to the compiler. Thos preprocessing defines should be:
+ *
+ *	Required:
+ *	
+ *	- LINUX_MODULE_HEAP_INITIAL=<number-in-bytes-guaranteed-allocated>
+ *	- LINUX_MODULE_HEAP_MAX=<number-in-bytes-of-maximum-allocation>
+ *	- LINUX_MODULE_HEAP_NAME=<string>
+ *
+ *	Optional:
+ *	
+ *	- LINUX_MODULE_HEAP_NO_AUTO_LOAD
+ *
+ *	The optional preprocessing define should only be used in very rare
+ *	cases. Those cases would be modules that want to perform additional
+ *	operations inside vmk_early_init_module and vmk_late_cleanup_module. The
+ *	first module that actually does this should most likely create a
+ *	linux_module_heap.h file that exports the linux_module_heap_init and
+ *	cleanup functions. That module should make sure to specify
+ *	LINUX_MODULE_HEAP_NO_AUTO_LOAD in its Makefile and link against the
+ *	newly created header file as well as its own .c file that contains new
+ *	vmk_early_init_module and cleanup functions (that still call the
+ *	linux_module_heap_init and cleanup functions).
+ */
+
+#ifndef LINUX_MODULE_HEAP_INITIAL
+#error
+#endif
+
+#ifndef LINUX_MODULE_HEAP_MAX
+#error
+#endif
+
+#ifndef LINUX_MODULE_HEAP_NAME
+#error
+#endif
+
+#if LINUX_MODULE_HEAP_INITIAL > LINUX_MODULE_HEAP_MAX
+#error
+#endif
+
+#if LINUX_MODULE_HEAP_INITIAL < 0
+#error
+#endif
+
+#include <asm/page.h>
+#include <linux/types.h>
+#include <linux/mm.h>
+#include <linux/spinlock.h>
+#include <linux/pci.h>
+#include <linux/module.h>
+
+#include "vmkapi.h"
+
+static vmk_HeapID moduleHeap = VMK_INVALID_HEAP_ID;
+
+/*
+ * The following functions - kfree and kmalloc, are implemented both here and in
+ * vmklinux/linux_stubs.c. Most likely, if there are any changes made to these,
+ * the changes should be propagated to the corresponding functions in vmklinux.
+ * We need to define these functions here so that the drivers are able to
+ * allocate memory from the appropriate driver heap memory.
+ *
+ * NOTE: We could have eliminated these functions and used the versions defined
+ * in linux_stubs.c, but we need to distinguish between the memory allocated
+ * for the drivers vs the memory allocated for vmklinux's internal use - say,
+ * the call sequence is driver->vmklinux->kmalloc(), here the kmalloc() call
+ * is on behalf of vmklinux, but there is no way to determine this from the
+ * World->modStk since we don't push vmklinux's module id on to the stack.
+ */
+
+void
+kfree(const void *p)
+{
+   vmk_HeapFree(moduleHeap, (void *)p);
+}
+
+void *
+kmalloc(size_t size, int priority)
+{
+   size_t actual = 1;
+   void *d;
+
+   /*
+    * Allocate blocks in powers-of-2 (like Linux), so we tolerate any
+    * driver bugs that don't show up because of the large allocation size.
+    */
+   while (actual < size) {
+      actual *= 2;
+   }
+   d = vmk_HeapAllocWithRA(moduleHeap, actual, __builtin_return_address(0));
+   return d;
+}
+
+/* kmem_cache implementation from Mike's infiniband port */
+
+#define KMEM_CACHE_MAGIC	0xfa4b9c23
+
+typedef struct kmem_cache_element {
+   unsigned int magic;
+   struct kmem_cache_element *next;
+} kmem_cache_element;
+
+struct kmem_cache_s {
+   unsigned int size;
+   kmem_cache_element *list;
+   spinlock_t lock;
+   void (*ctor)(void *, kmem_cache_t *, unsigned long);
+};
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_create
+ *
+ *      Create a memory cache that will hold elements of a given size.
+ *
+ * Arguments
+ *      ctor is a constructor that will initialize a cache element
+ *           when allocated from the pool
+ *      dtor is a destructor that would normally be used on an
+ *           element before it is returned to the pool, but we do
+ *           currently not implement it
+ *
+ * Results:
+ *      A pointer to the cache to be used on subsequent calls to
+ *           kmem_cache_{alloc, free, destroy} or NULL on error
+ *
+ * Side effects:
+ *      A kmem cache heap object is allocated
+ *
+ *----------------------------------------------------------------------
+ */
+
+kmem_cache_t *
+kmem_cache_create(const char *name , 
+		  size_t size, size_t offset, unsigned long flags,
+		  void (*ctor)(void *, kmem_cache_t *, unsigned long),
+		  void (*dtor)(void *, kmem_cache_t *, unsigned long))
+{
+   kmem_cache_t *cache;
+
+   if (dtor != NULL) {
+      vmk_Warning("kmem_cache_create: dtor != NULL\n");
+      return NULL;
+   }
+
+   if (offset != 0) {
+      vmk_Warning("kmem_cache_create: offset = %d\n", offset);
+      return NULL;
+   }
+
+   cache = (kmem_cache_t *)vmk_HeapAllocWithRA(moduleHeap, sizeof(kmem_cache_t),
+                                               __builtin_return_address(0));
+   if (cache == NULL) {
+      vmk_Warning("kmem_cache_create: out of memory\n");
+      return NULL;
+   }
+
+   cache->size = size;
+   cache->list = NULL;
+   cache->ctor = ctor;
+
+   // 
+   // This lock can be grabbed with a linux spin lock held so we have to
+   // be at least one higher in rank.
+   //
+   vmk_spin_lock_init(&cache->lock);
+
+   return cache;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_destroy
+ *
+ *      Deallocate all elements in a kmem cache and destroy the
+ *      kmem_cache object itself
+ *
+ * Results:
+ *      Always 0
+ *
+ * Side effects:
+ *      All cached objects and the kmem_cache object itself are freed
+ *
+ *----------------------------------------------------------------------
+ */
+
+int 
+kmem_cache_destroy(kmem_cache_t *cache)
+{
+   vmk_spin_lock_irqsave(&cache->lock);
+   while (cache->list != NULL) {
+      kmem_cache_element *head = cache->list;
+      cache->list = head->next;
+      vmk_HeapFree(moduleHeap, head);
+   }
+   vmk_spin_unlock_irqrestore(&cache->lock);
+   vmk_spin_lock_destroy(&cache->lock);
+   vmk_HeapFree(moduleHeap, cache);
+   return 0;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_alloc
+ *
+ *      Allocate an element from the cache pool. If no free elements
+ *      exist a new one will be allocated from the heap.
+ *
+ * Results:
+ *      A pointer to the allocated object or NULL on error
+ *
+ * Side effects:
+ *      Cache list may change or a new object is allocated from the heap
+ *
+ *----------------------------------------------------------------------
+ */
+
+void *
+kmem_cache_alloc(kmem_cache_t *cache, int flags)
+{
+   void *res;
+   kmem_cache_element *el;
+
+   vmk_spin_lock_irqsave(&cache->lock);
+
+   if (cache->list == NULL) {
+      el = (kmem_cache_element *)vmk_HeapAllocWithRA(moduleHeap, cache->size +
+                                                     sizeof(kmem_cache_element),
+                                                     __builtin_return_address(0));
+      if (el == NULL) {
+         vmk_Warning("kmem_cache_alloc: out of memory\n");
+         vmk_spin_unlock_irqrestore(&cache->lock);
+         return NULL;
+      }
+      el->magic = KMEM_CACHE_MAGIC;
+   } else {
+      el = cache->list;
+      cache->list = el->next;
+   }
+   vmk_spin_unlock_irqrestore(&cache->lock);
+
+   res = (char *)el + sizeof(kmem_cache_element);
+   if (cache->ctor != NULL) {
+      cache->ctor(res, cache, 0);
+   }
+
+   return res;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_free
+ *
+ *      Release an element to the object cache. The memory will not be
+ *      freed until the cache is destroyed
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      Cache list will change
+ *
+ *----------------------------------------------------------------------
+ */
+
+void 
+kmem_cache_free(kmem_cache_t *cache, void *item)
+{
+   kmem_cache_element *el = 
+      (kmem_cache_element *)((char *)item - sizeof(kmem_cache_element));
+
+   if (el->magic != KMEM_CACHE_MAGIC) {
+      panic("kmem_cache_free: Bad magic\n");
+   }
+
+   vmk_spin_lock_irqsave(&cache->lock);
+
+   el->next = cache->list;
+   cache->list = el;
+
+   vmk_spin_unlock_irqrestore(&cache->lock);
+}
+
+#ifdef MODULE
+static int heap_initial = LINUX_MODULE_HEAP_INITIAL;
+MODULE_PARM(heap_initial, "i");
+MODULE_PARM_DESC(heap_initial, "Initial heap size allocated for the driver.");
+
+static int heap_max = LINUX_MODULE_HEAP_MAX;
+MODULE_PARM(heap_max, "i");
+MODULE_PARM_DESC(heap_max, "Maximum attainable heap size for the driver.");
+#else
+#error "You can only compile and link linux_module_heap with modules, which" \
+       "means that MODULE has to be defined when compiling it..."
+#endif
+
+/*
+ * The following two functions are used to create and destroy the private module
+ * heap. The init function MUST be called before any other code in the module
+ * has a chance to call kfree, kmalloc, etc. And the destroy function MUST be
+ * called after those operations are all finished. 
+ *
+ */
+
+int
+linux_module_heap_init(void)
+{
+   vmk_uint32 moduleID;
+
+   moduleID = vmk_ModuleGetCurrentID();
+
+   if (heap_initial > heap_max) {
+      heap_initial = heap_max;
+      vmk_Warning("Initial heap size > max. Limiting to max!!!\n");
+   }
+
+   vmk_Log("Initial heap size : %d, max heap size: %d\n",
+           heap_initial, heap_max);
+   moduleHeap = vmk_HeapCreateDynamic(moduleID,
+				      LINUX_MODULE_HEAP_NAME,
+				      VMK_HEAP_LOW_MEM,
+				      heap_initial,
+				      heap_max);
+
+   vmk_ModuleSetHeapID(moduleID, moduleHeap);
+
+   if (moduleHeap == VMK_INVALID_HEAP_ID) {
+      return -1;
+   }
+
+   return 0;
+}
+ 
+int
+linux_module_heap_cleanup(void)
+{
+   vmk_HeapDestroyDynamic(moduleHeap); 
+
+   moduleHeap = VMK_INVALID_HEAP_ID;
+
+   return 0;
+}
+
+/*
+ * Modules can have the preceding two functions called automatically at the
+ * right time by compiling and linking normally. To disable this automatic
+ * functionality, you can specify LINUX_MODULE_HEAP_NO_AUTO_LOAD in your
+ * Makefile, which will disable the following two functions. See the top of this
+ * file for an explanation of why this might be useful.
+ */
+
+#ifndef LINUX_MODULE_HEAP_NO_AUTO_LOAD
+int
+vmk_early_init_module(void)
+{
+   return linux_module_heap_init();
+}
+
+int
+vmk_late_cleanup_module(void)
+{
+   return linux_module_heap_cleanup();
+}
+#endif // LINUX_MODULE_HEAP_NO_AUTO_LOAD
diff --git a/drivers/scsi/aacraid/VMware-3.5.c b/drivers/scsi/aacraid/VMware-3.5.c
new file mode 100644
index 0000000..4003447
--- /dev/null
+++ b/drivers/scsi/aacraid/VMware-3.5.c
@@ -0,0 +1,412 @@
+/* ****************************************************************
+ * Portions Copyright 2004 VMware, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ * ****************************************************************/
+
+/*
+ * linux_module_heap.c --
+ *
+ *	This file enables a module to have its own private heap, replete with
+ *	posion-value checks, etc. to guarantee that modules and other kernel
+ *	code don't step on each other's toes. This functionality is available to
+ *	any module that compiles this code and links against it. Options
+ *	specifying the size of the private heap, among other things, must be
+ *	present within the module's Makefile, providing defined preprocessing
+ *	values to the compiler. Thos preprocessing defines should be:
+ *
+ *	Required:
+ *	
+ *	- LINUX_MODULE_HEAP_INITIAL=<number-in-bytes-guaranteed-allocated>
+ *	- LINUX_MODULE_HEAP_MAX=<number-in-bytes-of-maximum-allocation>
+ *	- LINUX_MODULE_HEAP_NAME=<string>
+ *
+ *	Optional:
+ *	
+ *	- LINUX_MODULE_HEAP_NO_AUTO_LOAD
+ *
+ *	The optional preprocessing define should only be used in very rare
+ *	cases. Those cases would be modules that want to perform additional
+ *	operations inside vmk_early_init_module and vmk_late_cleanup_module. The
+ *	first module that actually does this should most likely create a
+ *	linux_module_heap.h file that exports the linux_module_heap_init and
+ *	cleanup functions. That module should make sure to specify
+ *	LINUX_MODULE_HEAP_NO_AUTO_LOAD in its Makefile and link against the
+ *	newly created header file as well as its own .c file that contains new
+ *	vmk_early_init_module and cleanup functions (that still call the
+ *	linux_module_heap_init and cleanup functions).
+ */
+
+#ifndef LINUX_MODULE_HEAP_INITIAL
+#error
+#endif
+
+#ifndef LINUX_MODULE_HEAP_MAX
+#error
+#endif
+
+#ifndef LINUX_MODULE_HEAP_NAME
+#error
+#endif
+
+#if LINUX_MODULE_HEAP_INITIAL > LINUX_MODULE_HEAP_MAX
+#error
+#endif
+
+#if LINUX_MODULE_HEAP_INITIAL < 0
+#error
+#endif
+
+#include <asm/page.h>
+#include <linux/types.h>
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/pci.h>
+#include <linux/module.h>
+
+#include "vmkapi.h"
+
+static vmk_HeapID moduleHeap = VMK_INVALID_HEAP_ID;
+
+/*
+ * The following functions - kfree and kmalloc, are implemented both here and in
+ * vmklinux/linux_stubs.c. Most likely, if there are any changes made to these,
+ * the changes should be propagated to the corresponding functions in vmklinux.
+ * We need to define these functions here so that the drivers are able to
+ * allocate memory from the appropriate driver heap memory.
+ *
+ * NOTE: We could have eliminated these functions and used the versions defined
+ * in linux_stubs.c, but we need to distinguish between the memory allocated
+ * for the drivers vs the memory allocated for vmklinux's internal use - say,
+ * the call sequence is driver->vmklinux->kmalloc(), here the kmalloc() call
+ * is on behalf of vmklinux, but there is no way to determine this from the
+ * World->modStk since we don't push vmklinux's module id on to the stack.
+ */
+
+void
+kfree(const void *p)
+{
+   if (p != NULL) {
+      vmk_HeapFree(moduleHeap, (void *)p);
+   }
+}
+
+void *
+kmalloc(size_t size, int priority)
+{
+   size_t actual = 1;
+   void *d;
+
+   /*
+    * Allocate blocks in powers-of-2 (like Linux), so we tolerate any
+    * driver bugs that don't show up because of the large allocation size.
+    */
+   while (actual < size) {
+      actual *= 2;
+   }
+   d = vmk_HeapAllocWithRA(moduleHeap, actual, __builtin_return_address(0));
+   return d;
+}
+
+void*
+kmalloc_align(size_t size, int priority, size_t align)
+{
+   size_t actual = 1;
+   void *d;
+
+   /*
+    * Allocate blocks in powers-of-2 (like Linux), so we tolerate any
+    * driver bugs that don't show up because of the large allocation size.
+    */
+   while (actual < size) {
+      actual *= 2;
+   }
+   d = vmk_HeapAlignWithRA(moduleHeap, actual, align,
+                           __builtin_return_address(0));
+   return d;
+}
+
+/* kmem_cache implementation from Mike's infiniband port */
+
+#define KMEM_CACHE_MAGIC	0xfa4b9c23
+
+typedef struct kmem_cache_element {
+   unsigned int magic;
+   struct kmem_cache_element *next;
+} kmem_cache_element;
+
+struct kmem_cache_s {
+   unsigned int size;
+   kmem_cache_element *list;
+   spinlock_t lock;
+   void (*ctor)(void *, kmem_cache_t *, unsigned long);
+};
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_create
+ *
+ *      Create a memory cache that will hold elements of a given size.
+ *
+ * Arguments
+ *      ctor is a constructor that will initialize a cache element
+ *           when allocated from the pool
+ *      dtor is a destructor that would normally be used on an
+ *           element before it is returned to the pool, but we do
+ *           currently not implement it
+ *
+ * Results:
+ *      A pointer to the cache to be used on subsequent calls to
+ *           kmem_cache_{alloc, free, destroy} or NULL on error
+ *
+ * Side effects:
+ *      A kmem cache heap object is allocated
+ *
+ *----------------------------------------------------------------------
+ */
+
+kmem_cache_t *
+kmem_cache_create(const char *name , 
+		  size_t size, size_t offset, unsigned long flags,
+		  void (*ctor)(void *, kmem_cache_t *, unsigned long),
+		  void (*dtor)(void *, kmem_cache_t *, unsigned long))
+{
+   kmem_cache_t *cache;
+
+   if (dtor != NULL) {
+      vmk_WarningMessage("kmem_cache_create: dtor != NULL\n");
+      return NULL;
+   }
+
+   if (offset != 0) {
+      vmk_WarningMessage("kmem_cache_create: offset = %d\n", offset);
+      return NULL;
+   }
+
+   cache = (kmem_cache_t *)vmk_HeapAllocWithRA(moduleHeap, sizeof(kmem_cache_t),
+                                               __builtin_return_address(0));
+   if (cache == NULL) {
+      vmk_WarningMessage("kmem_cache_create: out of memory\n");
+      return NULL;
+   }
+
+   cache->size = size;
+   cache->list = NULL;
+   cache->ctor = ctor;
+
+   // 
+   // This lock can be grabbed with a linux spin lock held so we have to
+   // be at least one higher in rank.
+   //
+   spin_lock_init(&cache->lock);
+
+   return cache;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_destroy
+ *
+ *      Deallocate all elements in a kmem cache and destroy the
+ *      kmem_cache object itself
+ *
+ * Results:
+ *      Always 0
+ *
+ * Side effects:
+ *      All cached objects and the kmem_cache object itself are freed
+ *
+ *----------------------------------------------------------------------
+ */
+
+int 
+kmem_cache_destroy(kmem_cache_t *cache)
+{
+   unsigned long cpu_flags;
+
+   spin_lock_irqsave(&cache->lock, cpu_flags);
+   while (cache->list != NULL) {
+      kmem_cache_element *head = cache->list;
+      cache->list = head->next;
+      vmk_HeapFree(moduleHeap, head);
+   }
+   spin_unlock_irqrestore(&cache->lock, cpu_flags);
+   spin_lock_destroy(&cache->lock);
+   vmk_HeapFree(moduleHeap, cache);
+   return 0;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_alloc
+ *
+ *      Allocate an element from the cache pool. If no free elements
+ *      exist a new one will be allocated from the heap.
+ *
+ * Results:
+ *      A pointer to the allocated object or NULL on error
+ *
+ * Side effects:
+ *      Cache list may change or a new object is allocated from the heap
+ *
+ *----------------------------------------------------------------------
+ */
+
+void *
+kmem_cache_alloc(kmem_cache_t *cache, int flags)
+{
+   void *res;
+   kmem_cache_element *el;
+   unsigned long cpu_flags;
+
+   spin_lock_irqsave(&cache->lock, cpu_flags);
+
+   if (cache->list == NULL) {
+      el = (kmem_cache_element *)vmk_HeapAllocWithRA(moduleHeap, cache->size +
+                                                     sizeof(kmem_cache_element),
+                                                     __builtin_return_address(0));
+      if (el == NULL) {
+         vmk_WarningMessage("kmem_cache_alloc: out of memory\n");
+         spin_unlock_irqrestore(&cache->lock, cpu_flags);
+         return NULL;
+      }
+      el->magic = KMEM_CACHE_MAGIC;
+   } else {
+      el = cache->list;
+      cache->list = el->next;
+   }
+   spin_unlock_irqrestore(&cache->lock, cpu_flags);
+
+   res = (char *)el + sizeof(kmem_cache_element);
+   if (cache->ctor != NULL) {
+      cache->ctor(res, cache, 0);
+   }
+
+   return res;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_free
+ *
+ *      Release an element to the object cache. The memory will not be
+ *      freed until the cache is destroyed
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      Cache list will change
+ *
+ *----------------------------------------------------------------------
+ */
+
+void 
+kmem_cache_free(kmem_cache_t *cache, void *item)
+{
+   unsigned long flags;
+
+   kmem_cache_element *el = 
+      (kmem_cache_element *)((char *)item - sizeof(kmem_cache_element));
+
+   if (el->magic != KMEM_CACHE_MAGIC) {
+      panic("kmem_cache_free: Bad magic\n");
+   }
+
+   spin_lock_irqsave(&cache->lock, flags);
+
+   el->next = cache->list;
+   cache->list = el;
+
+   spin_unlock_irqrestore(&cache->lock, flags);
+}
+
+#ifdef MODULE
+static int heap_initial = LINUX_MODULE_HEAP_INITIAL;
+MODULE_PARM(heap_initial, "i");
+MODULE_PARM_DESC(heap_initial, "Initial heap size allocated for the driver.");
+
+static int heap_max = LINUX_MODULE_HEAP_MAX;
+MODULE_PARM(heap_max, "i");
+MODULE_PARM_DESC(heap_max, "Maximum attainable heap size for the driver.");
+#else
+#error "You can only compile and link linux_module_heap with modules, which" \
+       "means that MODULE has to be defined when compiling it..."
+#endif
+
+/*
+ * The following two functions are used to create and destroy the private module
+ * heap. The init function MUST be called before any other code in the module
+ * has a chance to call kfree, kmalloc, etc. And the destroy function MUST be
+ * called after those operations are all finished. 
+ *
+ */
+
+int
+linux_module_heap_init(void)
+{
+   vmk_uint32 moduleID;
+   VMK_ReturnStatus status;
+
+   moduleID = vmk_ModuleStackTop();
+
+   if (heap_initial > heap_max) {
+      heap_initial = heap_max;
+      vmk_WarningMessage("Initial heap size > max. Limiting to max!!!\n");
+   }
+
+   vmk_LogMessage("Initial heap size : %d, max heap size: %d\n",
+                  heap_initial, heap_max);
+   status = vmk_HeapCreate(LINUX_MODULE_HEAP_NAME,
+                           VMK_HEAP_LOW_MEM,
+                           heap_initial,
+                           heap_max,
+                           &moduleHeap);
+
+   if (status != VMK_OK) {
+      vmk_LogMessage("vmk_HeapCreate failed \n");
+      return -1;
+   }
+
+   vmk_ModuleSetHeapID(moduleID, moduleHeap);
+   return 0;
+}
+ 
+int
+linux_module_heap_cleanup(void)
+{
+   vmk_HeapDestroy(moduleHeap); 
+
+   moduleHeap = VMK_INVALID_HEAP_ID;
+
+   return 0;
+}
+
+/*
+ * Modules can have the preceding two functions called automatically at the
+ * right time by compiling and linking normally. To disable this automatic
+ * functionality, you can specify LINUX_MODULE_HEAP_NO_AUTO_LOAD in your
+ * Makefile, which will disable the following two functions. See the top of this
+ * file for an explanation of why this might be useful.
+ */
+
+#ifndef LINUX_MODULE_HEAP_NO_AUTO_LOAD
+int
+vmk_early_init_module(void)
+{
+   return linux_module_heap_init();
+}
+
+int
+vmk_late_cleanup_module(void)
+{
+   return linux_module_heap_cleanup();
+}
+#endif // LINUX_MODULE_HEAP_NO_AUTO_LOAD
diff --git a/drivers/scsi/aacraid/VMware.c b/drivers/scsi/aacraid/VMware.c
new file mode 100644
index 0000000..c9f7711
--- /dev/null
+++ b/drivers/scsi/aacraid/VMware.c
@@ -0,0 +1,386 @@
+/* ****************************************************************
+ * Portions Copyright 2004 VMware, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ * ****************************************************************/
+
+/*
+ * linux_module_heap.c --
+ *
+ *	This file enables a module to have its own private heap, replete with
+ *	posion-value checks, etc. to guarantee that modules and other kernel
+ *	code don't step on each other's toes. This functionality is available to
+ *	any module that compiles this code and links against it. Options
+ *	specifying the size of the private heap, among other things, must be
+ *	present within the module's Makefile, providing defined preprocessing
+ *	values to the compiler. Thos preprocessing defines should be:
+ *
+ *	Required:
+ *	
+ *	- LINUX_MODULE_HEAP_INITIAL=<number-in-bytes-guaranteed-allocated>
+ *	- LINUX_MODULE_HEAP_MAX=<number-in-bytes-of-maximum-allocation>
+ *	- LINUX_MODULE_HEAP_NAME=<string>
+ *
+ *	Optional:
+ *	
+ *	- LINUX_MODULE_HEAP_NO_AUTO_LOAD
+ *
+ *	The optional preprocessing define should only be used in very rare
+ *	cases. Those cases would be modules that want to perform additional
+ *	operations inside vmk_early_init_module and vmk_late_cleanup_module. The
+ *	first module that actually does this should most likely create a
+ *	linux_module_heap.h file that exports the linux_module_heap_init and
+ *	cleanup functions. That module should make sure to specify
+ *	LINUX_MODULE_HEAP_NO_AUTO_LOAD in its Makefile and link against the
+ *	newly created header file as well as its own .c file that contains new
+ *	vmk_early_init_module and cleanup functions (that still call the
+ *	linux_module_heap_init and cleanup functions).
+ */
+
+#ifndef LINUX_MODULE_HEAP_INITIAL
+#error
+#endif
+
+#ifndef LINUX_MODULE_HEAP_MAX
+#error
+#endif
+
+#ifndef LINUX_MODULE_HEAP_NAME
+#error
+#endif
+
+#if LINUX_MODULE_HEAP_INITIAL > LINUX_MODULE_HEAP_MAX
+#error
+#endif
+
+#if LINUX_MODULE_HEAP_INITIAL < 0
+#error
+#endif
+
+#include <asm/page.h>
+#include <linux/types.h>
+#include <linux/mm.h>
+#include <linux/spinlock.h>
+#include <linux/pci.h>
+#include <linux/module.h>
+
+#include "vmkapi.h"
+
+static vmk_HeapID moduleHeap = VMK_INVALID_HEAP_ID;
+
+/*
+ * The following functions - kfree and kmalloc, are implemented both here and in
+ * vmklinux/linux_stubs.c. Most likely, if there are any changes made to these,
+ * the changes should be propagated to the corresponding functions in vmklinux.
+ * We need to define these functions here so that the drivers are able to
+ * allocate memory from the appropriate driver heap memory.
+ *
+ * NOTE: We could have eliminated these functions and used the versions defined
+ * in linux_stubs.c, but we need to distinguish between the memory allocated
+ * for the drivers vs the memory allocated for vmklinux's internal use - say,
+ * the call sequence is driver->vmklinux->kmalloc(), here the kmalloc() call
+ * is on behalf of vmklinux, but there is no way to determine this from the
+ * World->modStk since we don't push vmklinux's module id on to the stack.
+ */
+
+void
+kfree(const void *p)
+{
+   vmk_HeapFree(moduleHeap, (void *)p);
+}
+
+void *
+kmalloc(size_t size, int priority)
+{
+   size_t actual = 1;
+   void *d;
+
+   /*
+    * Allocate blocks in powers-of-2 (like Linux), so we tolerate any
+    * driver bugs that don't show up because of the large allocation size.
+    */
+   while (actual < size) {
+      actual *= 2;
+   }
+   d = vmk_HeapAllocWithRA(moduleHeap, actual, __builtin_return_address(0));
+   return d;
+}
+
+/* kmem_cache implementation from Mike's infiniband port */
+
+#define KMEM_CACHE_MAGIC	0xfa4b9c23
+
+typedef struct kmem_cache_element {
+   unsigned int magic;
+   struct kmem_cache_element *next;
+} kmem_cache_element;
+
+struct kmem_cache_s {
+   unsigned int size;
+   kmem_cache_element *list;
+   spinlock_t lock;
+   void (*ctor)(void *, kmem_cache_t *, unsigned long);
+};
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_create
+ *
+ *      Create a memory cache that will hold elements of a given size.
+ *
+ * Arguments
+ *      ctor is a constructor that will initialize a cache element
+ *           when allocated from the pool
+ *      dtor is a destructor that would normally be used on an
+ *           element before it is returned to the pool, but we do
+ *           currently not implement it
+ *
+ * Results:
+ *      A pointer to the cache to be used on subsequent calls to
+ *           kmem_cache_{alloc, free, destroy} or NULL on error
+ *
+ * Side effects:
+ *      A kmem cache heap object is allocated
+ *
+ *----------------------------------------------------------------------
+ */
+
+kmem_cache_t *
+kmem_cache_create(const char *name , 
+		  size_t size, size_t offset, unsigned long flags,
+		  void (*ctor)(void *, kmem_cache_t *, unsigned long),
+		  void (*dtor)(void *, kmem_cache_t *, unsigned long))
+{
+   kmem_cache_t *cache;
+
+   if (dtor != NULL) {
+      vmk_Warning("kmem_cache_create: dtor != NULL\n");
+      return NULL;
+   }
+
+   if (offset != 0) {
+      vmk_Warning("kmem_cache_create: offset = %d\n", offset);
+      return NULL;
+   }
+
+   cache = (kmem_cache_t *)vmk_HeapAllocWithRA(moduleHeap, sizeof(kmem_cache_t),
+                                               __builtin_return_address(0));
+   if (cache == NULL) {
+      vmk_Warning("kmem_cache_create: out of memory\n");
+      return NULL;
+   }
+
+   cache->size = size;
+   cache->list = NULL;
+   cache->ctor = ctor;
+
+   // 
+   // This lock can be grabbed with a linux spin lock held so we have to
+   // be at least one higher in rank.
+   //
+   vmk_spin_lock_init(&cache->lock);
+
+   return cache;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_destroy
+ *
+ *      Deallocate all elements in a kmem cache and destroy the
+ *      kmem_cache object itself
+ *
+ * Results:
+ *      Always 0
+ *
+ * Side effects:
+ *      All cached objects and the kmem_cache object itself are freed
+ *
+ *----------------------------------------------------------------------
+ */
+
+int 
+kmem_cache_destroy(kmem_cache_t *cache)
+{
+   vmk_spin_lock_irqsave(&cache->lock);
+   while (cache->list != NULL) {
+      kmem_cache_element *head = cache->list;
+      cache->list = head->next;
+      vmk_HeapFree(moduleHeap, head);
+   }
+   vmk_spin_unlock_irqrestore(&cache->lock);
+   vmk_spin_lock_destroy(&cache->lock);
+   vmk_HeapFree(moduleHeap, cache);
+   return 0;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_alloc
+ *
+ *      Allocate an element from the cache pool. If no free elements
+ *      exist a new one will be allocated from the heap.
+ *
+ * Results:
+ *      A pointer to the allocated object or NULL on error
+ *
+ * Side effects:
+ *      Cache list may change or a new object is allocated from the heap
+ *
+ *----------------------------------------------------------------------
+ */
+
+void *
+kmem_cache_alloc(kmem_cache_t *cache, int flags)
+{
+   void *res;
+   kmem_cache_element *el;
+
+   vmk_spin_lock_irqsave(&cache->lock);
+
+   if (cache->list == NULL) {
+      el = (kmem_cache_element *)vmk_HeapAllocWithRA(moduleHeap, cache->size +
+                                                     sizeof(kmem_cache_element),
+                                                     __builtin_return_address(0));
+      if (el == NULL) {
+         vmk_Warning("kmem_cache_alloc: out of memory\n");
+         vmk_spin_unlock_irqrestore(&cache->lock);
+         return NULL;
+      }
+      el->magic = KMEM_CACHE_MAGIC;
+   } else {
+      el = cache->list;
+      cache->list = el->next;
+   }
+   vmk_spin_unlock_irqrestore(&cache->lock);
+
+   res = (char *)el + sizeof(kmem_cache_element);
+   if (cache->ctor != NULL) {
+      cache->ctor(res, cache, 0);
+   }
+
+   return res;
+}
+
+/*
+ *----------------------------------------------------------------------
+ *
+ * kmem_cache_free
+ *
+ *      Release an element to the object cache. The memory will not be
+ *      freed until the cache is destroyed
+ *
+ * Results:
+ *      None
+ *
+ * Side effects:
+ *      Cache list will change
+ *
+ *----------------------------------------------------------------------
+ */
+
+void 
+kmem_cache_free(kmem_cache_t *cache, void *item)
+{
+   kmem_cache_element *el = 
+      (kmem_cache_element *)((char *)item - sizeof(kmem_cache_element));
+
+   if (el->magic != KMEM_CACHE_MAGIC) {
+      panic("kmem_cache_free: Bad magic\n");
+   }
+
+   vmk_spin_lock_irqsave(&cache->lock);
+
+   el->next = cache->list;
+   cache->list = el;
+
+   vmk_spin_unlock_irqrestore(&cache->lock);
+}
+
+#ifdef MODULE
+static int heap_initial = LINUX_MODULE_HEAP_INITIAL;
+MODULE_PARM(heap_initial, "i");
+MODULE_PARM_DESC(heap_initial, "Initial heap size allocated for the driver.");
+
+static int heap_max = LINUX_MODULE_HEAP_MAX;
+MODULE_PARM(heap_max, "i");
+MODULE_PARM_DESC(heap_max, "Maximum attainable heap size for the driver.");
+#else
+#error "You can only compile and link linux_module_heap with modules, which" \
+       "means that MODULE has to be defined when compiling it..."
+#endif
+
+/*
+ * The following two functions are used to create and destroy the private module
+ * heap. The init function MUST be called before any other code in the module
+ * has a chance to call kfree, kmalloc, etc. And the destroy function MUST be
+ * called after those operations are all finished. 
+ *
+ */
+
+int
+linux_module_heap_init(void)
+{
+   vmk_uint32 moduleID;
+
+   moduleID = vmk_ModuleGetCurrentID();
+
+   if (heap_initial > heap_max) {
+      heap_initial = heap_max;
+      vmk_Warning("Initial heap size > max. Limiting to max!!!\n");
+   }
+
+   vmk_Log("Initial heap size : %d, max heap size: %d\n",
+           heap_initial, heap_max);
+   moduleHeap = vmk_HeapCreateDynamic(moduleID,
+				      LINUX_MODULE_HEAP_NAME,
+				      VMK_HEAP_LOW_MEM,
+				      heap_initial,
+				      heap_max);
+
+   vmk_ModuleSetHeapID(moduleID, moduleHeap);
+
+   if (moduleHeap == VMK_INVALID_HEAP_ID) {
+      return -1;
+   }
+
+   return 0;
+}
+ 
+int
+linux_module_heap_cleanup(void)
+{
+   vmk_HeapDestroyDynamic(moduleHeap); 
+
+   moduleHeap = VMK_INVALID_HEAP_ID;
+
+   return 0;
+}
+
+/*
+ * Modules can have the preceding two functions called automatically at the
+ * right time by compiling and linking normally. To disable this automatic
+ * functionality, you can specify LINUX_MODULE_HEAP_NO_AUTO_LOAD in your
+ * Makefile, which will disable the following two functions. See the top of this
+ * file for an explanation of why this might be useful.
+ */
+
+#ifndef LINUX_MODULE_HEAP_NO_AUTO_LOAD
+int
+vmk_early_init_module(void)
+{
+   return linux_module_heap_init();
+}
+
+int
+vmk_late_cleanup_module(void)
+{
+   return linux_module_heap_cleanup();
+}
+#endif // LINUX_MODULE_HEAP_NO_AUTO_LOAD
diff --git a/drivers/scsi/aacraid/aachba.c b/drivers/scsi/aacraid/aachba.c
index 681434e..b5c5c53 100644
--- a/drivers/scsi/aacraid/aachba.c
+++ b/drivers/scsi/aacraid/aachba.c
@@ -1,12 +1,11 @@
 /*
  *	Adaptec AAC series RAID controller driver
- *	(c) Copyright 2001 Red Hat Inc.
+ *	(c) Copyright 2001 Red Hat Inc.	<alan@redhat.com>
  *
  * based on the old aacraid driver that is..
  * Adaptec aacraid device driver for Linux.
  *
- * Copyright (c) 2000-2010 Adaptec, Inc.
- *               2010 PMC-Sierra, Inc. (aacraid@pmc-sierra.com)
+ * Copyright (c) 2000-2007 Adaptec, Inc. (aacraid@adaptec.com)
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -27,21 +26,92 @@
 #include <linux/kernel.h>
 #include <linux/init.h>
 #include <linux/types.h>
+//#include <linux/sched.h>
 #include <linux/pci.h>
 #include <linux/spinlock.h>
 #include <linux/slab.h>
+#include <linux/version.h> /* For the following test */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,2))
 #include <linux/completion.h>
+#endif
 #include <linux/blkdev.h>
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+#include <asm/semaphore.h>
+#endif
 #include <asm/uaccess.h>
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16))
 #include <linux/highmem.h> /* For flush_kernel_dcache_page */
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || (LINUX_VERSION_CODE >=  KERNEL_VERSION(3,2,0)))
 #include <linux/module.h>
-
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+#define MAJOR_NR SCSI_DISK0_MAJOR	/* For DEVICE_NR() */
+#include <linux/blk.h>	/* for DEVICE_NR & io_request_lock definition */
+#include "scsi.h"
+#include "hosts.h"
+#include "sd.h"
+#define no_uld_attach hostdata
+#else
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,6))
+#include <linux/moduleparam.h>
+#endif
 #include <scsi/scsi.h>
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,1)) && !defined(DID_OK))
+#define DID_OK         0x00
+#define DID_NO_CONNECT 0x01
+#define DID_TIME_OUT   0x03
+#define DID_BAD_TARGET 0x04
+#define DID_ABORT      0x05
+#define DID_PARITY     0x06
+#define DID_ERROR      0x07
+#define DID_RESET      0x08
+#define SUCCESS        0x2002
+#define FAILED         0x2003
+#define SCSI_MLQUEUE_DEVICE_BUSY 0x1056
+#define SCSI_MLQUEUE_HOST_BUSY   0x1055
+#endif
 #include <scsi/scsi_cmnd.h>
 #include <scsi/scsi_device.h>
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,10)) && defined(DID_BUS_BUSY) && !defined(BLIST_NO_ULD_ATTACH))
+#include <scsi/scsi_devinfo.h>	/* Pick up BLIST_NO_ULD_ATTACH? */
+#endif
 #include <scsi/scsi_host.h>
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#include <scsi/scsi_tcq.h> /* For MSG_ORDERED_TAG */
+#endif
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,7)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,10)) && !defined(BLIST_NO_ULD_ATTACH))
+#define no_uld_attach inq_periph_qual
+#elif ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,7)) && !defined(BLIST_NO_ULD_ATTACH))
+#define no_uld_attach hostdata
+#endif
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) && defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+#include "scsi_priv.h" /* For SCSI_CMND_MAGIC */
+#endif
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#if (defined(MODULE))
+#include <linux/proc_fs.h>
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0))
+#include <linux/smp_lock.h>
+#else
+#include <linux/mutex.h>
+#endif
+#endif
+#if (defined(HAS_BOOTSETUP_H))
+#include <asm/bootsetup.h>
+#elif (!defined(HAS_NOT_SETUP))
+#include <asm/setup.h>
+#endif
+#ifndef COMMAND_LINE_SIZE
+# define COMMAND_LINE_SIZE 256
+#endif
+#endif
 
 #include "aacraid.h"
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#include "fwdebug.h"
+#endif
 
 /* values for inqd_pdt: Peripheral device type in plain English */
 #define	INQD_PDT_DA	0x00	/* Direct-access (DISK) device */
@@ -62,6 +132,9 @@
 #define SENCODE_END_OF_DATA			0x00
 #define SENCODE_BECOMING_READY			0x04
 #define SENCODE_INIT_CMD_REQUIRED		0x04
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#define SENCODE_DATA_PROTECT			0x0E
+#endif
 #define SENCODE_PARAM_LIST_LENGTH_ERROR		0x1A
 #define SENCODE_INVALID_COMMAND			0x20
 #define SENCODE_LBA_OUT_OF_RANGE		0x21
@@ -111,6 +184,73 @@
 #define BYTE2(x) (unsigned char)((x) >> 16)
 #define BYTE3(x) (unsigned char)((x) >> 24)
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+/* compatibility */
+#ifndef SAM_STAT_CHECK_CONDITION
+# define SAM_STAT_CHECK_CONDITION	(CHECK_CONDITION << 1)
+#endif
+#ifndef SAM_STAT_GOOD
+# define SAM_STAT_GOOD			(GOOD << 1)
+#endif
+#ifndef SAM_STAT_TASK_SET_FULL
+# define SAM_STAT_TASK_SET_FULL		(QUEUE_FULL << 1)
+#endif
+#ifndef SAM_STAT_BUSY
+# define SAM_STAT_BUSY			(BUSY << 1)
+#endif
+#ifndef SAM_STAT_RESERVATION_CONFLICT
+# define SAM_STAT_RESERVATION_CONFLICT	(RESERVATION_CONFLICT << 1)
+#endif
+#ifndef SAM_STAT_TASK_ABORTED
+# define SAM_STAT_TASK_ABORTED		(TASK_ABORTED << 1)
+#endif
+
+#endif
+
+/* ATA pass thru commands */
+#ifndef ATA_12
+#define ATA_12                0xa1      /* 12-byte pass-thru */
+#endif
+
+#ifndef ATA_16
+#define ATA_16                0x85      /* 16-byte pass-thru */
+#endif
+
+/* MODE_SENSE data format */
+typedef struct {
+	struct {
+		u8	data_length;
+		u8	med_type;
+		u8	dev_par;
+		u8	bd_length;
+	} __attribute__((packed)) hd;
+	struct {
+		u8	dens_code;
+		u8	block_count[3];
+		u8	reserved;
+		u8	block_length[3];
+	} __attribute__((packed)) bd;
+		u8	mpc_buf[3];
+} __attribute__((packed)) aac_modep_data;
+
+/* MODE_SENSE_10 data format */
+typedef struct {
+	struct {
+		u8	data_length[2];
+		u8	med_type;
+		u8	dev_par;
+		u8	rsrvd[2];
+		u8	bd_length[2];
+	} __attribute__((packed)) hd;
+	struct {
+		u8	dens_code;
+		u8	block_count[3];
+		u8	reserved;
+		u8	block_length[3];
+	} __attribute__((packed)) bd;
+		u8	mpc_buf[3];
+} __attribute__((packed)) aac_modep10_data;
+
 /*------------------------------------------------------------------------------
  *              S T R U C T S / T Y P E D E F S
  *----------------------------------------------------------------------------*/
@@ -128,18 +268,74 @@ struct inquiry_data {
 	u8 inqd_prl[4];	/* Product Revision Level */
 };
 
+/* Excluding SUSE as it has issues when inbox driver does not have this support but outbox has it. 
+  Because SUSE uses /dev/disk/by-id mapping entries in the OS grub config and VPD 0X83 creates conflicts */
+#if (!defined(CONFIG_SUSE_KERNEL))
+/* Added for VPD 0x83 */
+typedef struct {
+    u8 CodeSet : 4;          // VPD_CODE_SET
+    u8 Reserved : 4;
+    u8 IdentifierType : 4;   // VPD_IDENTIFIER_TYPE
+    u8 Reserved2 : 4;
+    u8 Reserved3;
+    u8 IdentifierLength;
+    u8 VendId[8];
+    u8 ProductId[16];
+    u8 SerialNumber[8];                   // SN in ASCII
+
+} TVPD_ID_Descriptor_Type_1;
+
+typedef struct {
+    u8 CodeSet : 4;          // VPD_CODE_SET
+    u8 Reserved : 4;
+    u8 IdentifierType : 4;   // VPD_IDENTIFIER_TYPE
+    u8 Reserved2 : 4;
+    u8 Reserved3;
+    u8 IdentifierLength;
+        struct TEU64Id {
+          u32 Serial;
+          u8 Reserved; // The serial number supposed to be 40 bits, bit we only support 32, so make the last byte zero.
+          u8 VendId[3];
+    } EU64Id;
+
+} TVPD_ID_Descriptor_Type_2;
+
+typedef struct {
+    u8 DeviceType : 5;
+    u8 DeviceTypeQualifier : 3;
+    u8 PageCode;
+    u8 Reserved;
+    u8 PageLength;
+    TVPD_ID_Descriptor_Type_1 IdDescriptorType1;
+    TVPD_ID_Descriptor_Type_2 IdDescriptorType2;
+
+} TVPD_Page83;
+
+#endif
+
+
 /*
  *              M O D U L E   G L O B A L S
  */
 
-static long aac_build_sg(struct scsi_cmnd *scsicmd, struct sgmap *sgmap);
-static long aac_build_sg64(struct scsi_cmnd *scsicmd, struct sgmap64 *psg);
-static long aac_build_sgraw(struct scsi_cmnd *scsicmd, struct sgmapraw *psg);
-static long aac_build_sgraw2(struct scsi_cmnd *scsicmd,
-				struct aac_raw_io2 *rio2, int sg_max);
-static int aac_convert_sgraw2(struct aac_raw_io2 *rio2,
-				int pages, int nseg, int nseg_new);
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+static int aac_build_sg(struct scsi_cmnd* scsicmd, struct sgmap* sgmap);
+static int aac_build_sg64(struct scsi_cmnd* scsicmd, struct sgmap64* psg);
+static int aac_build_sgraw(struct scsi_cmnd* scsicmd, struct sgmapraw* psg);
+static int aac_build_sgraw2(struct scsi_cmnd* scsicmd, struct aac_raw_io2* rio2, int sg_max);
+static int aac_build_sghba(struct scsi_cmnd* scsicmd, struct aac_hba_cmd_req * hbacmd, int sg_max, u64 sg_address);
+static int aac_scsi_cmd(struct scsi_cmnd * scsicmd);
+static int aac_scsi_cmd_apre(struct scsi_cmnd * scsicmd);
+#else
+static long aac_build_sg(struct scsi_cmnd* scsicmd, struct sgmap* sgmap);
+static long aac_build_sg64(struct scsi_cmnd* scsicmd, struct sgmap64* psg);
+static long aac_build_sgraw(struct scsi_cmnd* scsicmd, struct sgmapraw* psg);
+static long aac_build_sgraw2(struct scsi_cmnd* scsicmd, struct aac_raw_io2* rio2, int sg_max);
+static long aac_build_sghba(struct scsi_cmnd* scsicmd, struct aac_hba_cmd_req * hbacmd, int sg_max, u64 sg_address);
+#endif
+static int aac_convert_sgraw2(struct aac_raw_io2* rio2, int pages, int nseg, int nseg_new);
 static int aac_send_srb_fib(struct scsi_cmnd* scsicmd);
+static int aac_send_hba_fib(struct scsi_cmnd* scsicmd);
 #ifdef AAC_DETAILED_STATUS_INFO
 static char *aac_get_status_string(u32 status);
 #endif
@@ -151,108 +347,494 @@ static char *aac_get_status_string(u32 status);
 static int nondasd = -1;
 static int aac_cache = 2;	/* WCE=0 to avoid performance problems */
 static int dacmode = -1;
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_ENABLE_MSI) || defined(PCI_HAS_DISABLE_MSI))
 int aac_msi;
+#else
+
+#endif
+#if (defined(__arm__) || defined(CONFIG_EXTERNAL))
+int aac_commit = 1;
+int startup_timeout = 540;
+int aif_timeout = 540;
+#else
 int aac_commit = -1;
 int startup_timeout = 180;
 int aif_timeout = 120;
-int aac_sync_mode;  /* Only Sync. transfer - disabled */
+#endif
+
+int aac_sync_mode = 0;  	/* only sync. transfer - disabled */
 int aac_convert_sgl = 1;	/* convert non-conformable s/g list - enabled */
 
-module_param(aac_sync_mode, int, S_IRUGO|S_IWUSR);
-MODULE_PARM_DESC(aac_sync_mode, "Force sync. transfer mode"
-	" 0=off, 1=on");
-module_param(aac_convert_sgl, int, S_IRUGO|S_IWUSR);
-MODULE_PARM_DESC(aac_convert_sgl, "Convert non-conformable s/g list"
-	" 0=off, 1=on");
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param(nondasd, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(nondasd, "i");
+#endif
 MODULE_PARM_DESC(nondasd, "Control scanning of hba for nondasd devices."
 	" 0=off, 1=on");
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param_named(cache, aac_cache, int, S_IRUGO|S_IWUSR);
 MODULE_PARM_DESC(cache, "Disable Queue Flush commands:\n"
 	"\tbit 0 - Disable FUA in WRITE SCSI commands\n"
 	"\tbit 1 - Disable SYNCHRONIZE_CACHE SCSI command\n"
 	"\tbit 2 - Disable only if Battery is protecting Cache");
+#else
+MODULE_PARM(aac_cache, "i");
+MODULE_PARM_DESC(aac_cache, "Disable Queue Flush commands:\n"
+	"\tbit 0 - Disable FUA in WRITE SCSI commands\n"
+	"\tbit 1 - Disable SYNCHRONIZE_CACHE SCSI command\n"
+	"\tbit 2 - Disable only if Battery is protecting Cache");
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param(dacmode, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(dacmode, "i");
+#endif
 MODULE_PARM_DESC(dacmode, "Control whether dma addressing is using 64 bit DAC."
 	" 0=off, 1=on");
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+module_param(aac_sync_mode, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(aac_sync_mode, "i");
+#endif
+MODULE_PARM_DESC(aac_sync_mode, "Force sync. transfer mode"
+	" 0=off, 1=on");
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+module_param(aac_convert_sgl, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(aac_convert_sgl, "i");
+#endif
+MODULE_PARM_DESC(aac_convert_sgl, "Convert non-conformable s/g list"
+	" 0=off, 1=on");
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param_named(commit, aac_commit, int, S_IRUGO|S_IWUSR);
 MODULE_PARM_DESC(commit, "Control whether a COMMIT_CONFIG is issued to the"
 	" adapter for foreign arrays.\n"
 	"This is typically needed in systems that do not have a BIOS."
 	" 0=off, 1=on");
+#else
+MODULE_PARM(aac_commit, "i");
+MODULE_PARM_DESC(aac_commit, "Control whether a COMMIT_CONFIG is issued to the"
+	" adapter for foreign arrays.\n"
+	"This is typically needed in systems that do not have a BIOS."
+	" 0=off, 1=on");
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_ENABLE_MSI) || defined(PCI_HAS_DISABLE_MSI))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param_named(msi, aac_msi, int, S_IRUGO|S_IWUSR);
 MODULE_PARM_DESC(msi, "IRQ handling."
 	" 0=PIC(default), 1=MSI, 2=MSI-X(unsupported, uses MSI)");
+#else
+MODULE_PARM(aac_msi, "i");
+MODULE_PARM_DESC(aac_msi, "IRQ handling."
+	" 0=PIC(default), 1=MSI, 2=MSI-X(unsupported, uses MSI)");
+#endif
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param(startup_timeout, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(startup_timeout, "i");
+#endif
 MODULE_PARM_DESC(startup_timeout, "The duration of time in seconds to wait for"
 	" adapter to have it's kernel up and\n"
 	"running. This is typically adjusted for large systems that do not"
 	" have a BIOS.");
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param(aif_timeout, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(aif_timeout, "i");
+#endif
 MODULE_PARM_DESC(aif_timeout, "The duration of time in seconds to wait for"
 	" applications to pick up AIFs before\n"
 	"deregistering them. This is typically adjusted for heavily burdened"
 	" systems.");
 
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#if (defined(__arm__) || defined(CONFIG_EXTERNAL) || (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+static int coalescethreshold = 0;
+#else
+static int coalescethreshold = 16; /* 8KB coalesce knee */
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+module_param(coalescethreshold, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(coalescethreshold, "i");
+#endif
+MODULE_PARM_DESC(coalescethreshold, "Control the maximum block size of"
+	" sequential requests that are fed back to the scsi_merge layer for"
+	" coalescing. 0=off, 16 block (8KB) default.");
+
+#endif
 int numacb = -1;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param(numacb, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(numacb, "i");
+#endif
 MODULE_PARM_DESC(numacb, "Request a limit to the number of adapter control"
 	" blocks (FIB) allocated. Valid values are 512 and down. Default is"
 	" to use suggestion from Firmware.");
 
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX__))
+int aac_remove_devnodes  = 0;
+#else
+int aac_remove_devnodes  = 1;
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+module_param(aac_remove_devnodes, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(aac_remove_devnodes, "i");
+#endif
+MODULE_PARM_DESC(aac_remove_devnodes, "Remove device nodes(/dev/sd* and /dev/sg*) permanently when the device goes to offline state."
+	" 0=off, 1=on(Default).");
+
 int acbsize = -1;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param(acbsize, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(acbsize, "i");
+#endif
 MODULE_PARM_DESC(acbsize, "Request a specific adapter control block (FIB)"
 	" size. Valid values are 512, 2048, 4096 and 8192. Default is to use"
 	" suggestion from Firmware.");
 
 int update_interval = 30 * 60;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param(update_interval, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(update_interval, "i");
+#endif
 MODULE_PARM_DESC(update_interval, "Interval in seconds between time sync"
 	" updates issued to adapter.");
 
 int check_interval = 24 * 60 * 60;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param(check_interval, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(check_interval, "i");
+#endif
 MODULE_PARM_DESC(check_interval, "Interval in seconds between adapter health"
 	" checks.");
 
 int aac_check_reset = 1;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param_named(check_reset, aac_check_reset, int, S_IRUGO|S_IWUSR);
 MODULE_PARM_DESC(check_reset, "If adapter fails health check, reset the"
 	" adapter. a value of -1 forces the reset to adapters programmed to"
 	" ignore it.");
+#else
+MODULE_PARM(aac_check_reset, "i");
+MODULE_PARM_DESC(aac_check_reset, "If adapter fails health check, reset the"
+	" adapter. a value of -1 forces the reset to adapters programmed to"
+	" ignore it.");
+#endif
+#if (defined(AAC_EXTENDED_TIMEOUT))
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+int extendedtimeout = -1;
+module_param(extendedtimeout, int, S_IRUGO|S_IWUSR);
+#else
+static int extendedtimeout = -1;
+MODULE_PARM(extendedtimeout, "i");
+#endif
+MODULE_PARM_DESC(extendedtimeout, "Request a specific timeout to override I/O"
+	" requests issed to the adapter.");
+#endif
 
+#if (defined(HAS_BOOT_CONFIG) || (defined(BOOTCD) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,7))))
+int expose_physicals = 0;
+#else
 int expose_physicals = -1;
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param(expose_physicals, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(expose_physicals, "i");
+#endif
 MODULE_PARM_DESC(expose_physicals, "Expose physical components of the arrays."
 	" -1=protect 0=off, 1=on");
 
+#if (defined(HAS_BOOT_CONFIG) || (defined(BOOTCD) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,7))))
+int expose_hidden_space = 0;
+#else
+int expose_hidden_space = -1;
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+module_param(expose_hidden_space, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(expose_hidden_space, "i");
+#endif
+MODULE_PARM_DESC(expose_hidden_space, "Expose hidden space of the Array."
+	" -1=protect 0=off, 1=on");
+
 int aac_reset_devices;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param_named(reset_devices, aac_reset_devices, int, S_IRUGO|S_IWUSR);
 MODULE_PARM_DESC(reset_devices, "Force an adapter reset at initialization.");
+#else
+MODULE_PARM(aac_reset_devices, "i");
+MODULE_PARM_DESC(aac_reset_devices, "Force an adapter reset at initialization.");
+#endif
 
+#if ((LINUX_VERSION_CODE == KERNEL_VERSION(2,6,16)) && (defined(CONFIG_SLES_KERNEL) || defined(CONFIG_SUSE_KERNEL)) && defined(CONFIG_SLE_SP))
+#if (CONFIG_SLE_SP == 1)
+int aac_wwn = 2;
+#else
+int aac_wwn = 1;
+#endif
+#elif (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
 int aac_wwn = 1;
+#else
+int aac_wwn = 1;
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 module_param_named(wwn, aac_wwn, int, S_IRUGO|S_IWUSR);
+#if ((LINUX_VERSION_CODE == KERNEL_VERSION(2,6,16)) && (defined(CONFIG_SLES_KERNEL) || defined(CONFIG_SUSE_KERNEL)) && defined(CONFIG_SLE_SP))
+#if (CONFIG_SLE_SP == 1)
+MODULE_PARM_DESC(wwn, "Select a WWN type for the arrays:\n"
+	"\t0 - Disable\n"
+	"\t1 - Array Meta Data Signature\n"
+	"\t2 - Adapter Serial Number (default)");
+#else
+MODULE_PARM_DESC(wwn, "Select a WWN type for the arrays:\n"
+	"\t0 - Disable\n"
+	"\t1 - Array Meta Data Signature (default)\n"
+	"\t2 - Adapter Serial Number");
+#endif
+#else
 MODULE_PARM_DESC(wwn, "Select a WWN type for the arrays:\n"
 	"\t0 - Disable\n"
 	"\t1 - Array Meta Data Signature (default)\n"
 	"\t2 - Adapter Serial Number");
+#endif
+#else
+MODULE_PARM(aac_wwn, "i");
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,4,21)) && (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__)))
+MODULE_PARM_DESC(aac_wwn, "Select a WWN type for the arrays:\n"
+	"\t0 - Disable (default)\n"
+	"\t1 - Array Meta Data Signature\n"
+	"\t2 - Adapter Serial Number");
+#else
+MODULE_PARM_DESC(aac_wwn, "Select a WWN type for the arrays:\n"
+	"\t0 - Disable\n"
+	"\t1 - Array Meta Data Signature (default)\n"
+	"\t2 - Adapter Serial Number");
+#endif
+#endif
+
+
+#if (!defined(CONFIG_COMMUNITY_KERNEL) && !defined(__VMKLNX30__) && !defined(__VMKLNX__) && ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || !defined(HAS_BOOT_CONFIG)))
+static char * aacraid;
+
+static int aacraid_setup(char *str)
+{
+	int i;
+	char *key;
+	char *value;
+#if (defined(CONFIG_SLES_KERNEL) || defined(CONFIG_SUSE_KERNEL))
+	static int dud = 0;
+#endif
+	struct {
+		char * option_name;
+		int * option_flag;
+		int option_value;
+	} options[] = {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		{ "nondasd", &nondasd, 1 },
+		{ "cache", &aac_cache, 2 },
+		{ "dacmode", &dacmode, 1 },
+		{ "sync_mode", &aac_sync_mode, 0 },
+		{ "convert_sgl", &aac_convert_sgl, 1 },
+		{ "commit", &aac_commit, 1 },
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_ENABLE_MSI) || defined(PCI_HAS_DISABLE_MSI))
+		{ "msi", &aac_msi, 0 ),
+#endif
+#if (defined(__arm__) || defined(CONFIG_EXTERNAL) || (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+		{ "coalescethreshold", &coalescethreshold, 0 },
+#else
+		{ "coalescethreshold", &coalescethreshold, 16 },
+#endif
+		{ "acbsize", &acbsize, 8192 },
+		{ "update_interval", &update_interval, 30 * 60 },
+		{ "check_interval", &check_interval, -1 },
+		{ "check_reset", &aac_check_reset, 1 },
+#if (defined(AAC_EXTENDED_TIMEOUT))
+		{ "extendedtimeout", &extendedtimeout, AAC_EXTENDED_TIMEOUT },
+#endif
+		{ "expose_physicals", &expose_physicals, -1 },
+		{ "expose_hidden_space", &expose_hidden_space, -1},
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX__))
+		{ "aac_remove_devnodes", &aac_remove_devnodes, 0},
+#else
+		{ "aac_remove_devnodes", &aac_remove_devnodes, 1},
+#endif
+		{ "reset_devices", &aac_reset_devices, 1 },
+#endif
+		{ "dd", &expose_physicals, 0 },
+#if (defined(CONFIG_SLES_KERNEL) || defined(CONFIG_SUSE_KERNEL))
+		{ "dud", &dud, 0 },
+#endif
+	};
+
+#if (defined(AAC_DEBUG_INSTRUMENT_SETUP))
+	printk (KERN_INFO "aacraid_setup(\"%s\")\n", (str) ? str : "<null>");
+#endif
+	if (str) while ((key = strsep(&str, ",; \t\r\n"))) {
+		if (!*key)
+			continue;
+		if ((strnicmp (key, "aacraid", 7) == 0)
+		 && ((key[7] == '.') || (key[7] == '=')))
+			key += 8;
+		if (((value = strchr(key, ':')))
+		 || ((value = strchr(key, '='))))
+			*value++ = '\0';
+		for (i = 0; i < (sizeof (options) / sizeof (options[0])); i++) {
+			if (strnicmp (key, options[i].option_name,
+			     strlen(options[i].option_name)) == 0) {
+				*options[i].option_flag
+				  = (value)
+				    ? simple_strtoul(value, NULL, 0)
+				    : options[i].option_value;
+				break;
+			}
+		}
+	}
+#if (defined(CONFIG_SLES_KERNEL) || defined(CONFIG_SUSE_KERNEL))
+	/* SuSE special */
+	if (dud)
+		expose_physicals = 0;
+#endif
 
+	return (1);
+}
 
+#endif
 static inline int aac_valid_context(struct scsi_cmnd *scsicmd,
 		struct fib *fibptr) {
 	struct scsi_device *device;
 
 	if (unlikely(!scsicmd || !scsicmd->scsi_done)) {
 		dprintk((KERN_WARNING "aac_valid_context: scsi command corrupt\n"));
+#if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT) || (0 && defined(BOOTCD)))
+		if (!nblank(dprintk(x)))
+			printk(KERN_WARNING
+			  "aac_valid_context: scsi command corrupt %p->scsi_done=%p\n",
+			  scsicmd, (scsicmd &&
+			  (scsicmd != (struct scsi_cmnd*)(uintptr_t)0x6b6b6b6b6b6b6b6bLL))
+			    ? scsicmd->scsi_done
+			    : (void (*)(struct scsi_cmnd*))(uintptr_t)-1LL);
+		if (nblank(fwprintf(x))) {
+			extern struct list_head aac_devices; /* in linit.c */
+			struct aac_dev *aac;
+			list_for_each_entry(aac, &aac_devices, entry) {
+				fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B,
+				  "scsi command corrupt %p->scsi_done=%p",
+				  scsicmd, (scsicmd &&
+				  (scsicmd != (struct scsi_cmnd*)(uintptr_t)0x6b6b6b6b6b6b6b6bLL))
+				    ? scsicmd->scsi_done
+				    : (void (*)(struct scsi_cmnd*))(uintptr_t)-1LL));
+			}
+		}
+#endif
+		aac_fib_complete(fibptr);
+		aac_fib_free(fibptr);
+		return 0;
+	}
+#if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT) || (0 && defined(BOOTCD)))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,12))
+# define invalid_command_state(x) (((x)->state == SCSI_STATE_FINISHED) || !(x)->state)
+#else
+# define invalid_command_state(x) 0
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+# define invalid_command_magic(x) list_empty(&(x)->list)
+#else
+# define invalid_command_magic(x) (((x)->sc_magic != SCSI_CMND_MAGIC) && (x)->sc_magic)
+#endif
+	if (unlikely((scsicmd == (struct scsi_cmnd*)(uintptr_t)0x6b6b6b6b6b6b6b6bLL) ||
+	  invalid_command_state(scsicmd) ||
+	  (scsicmd->scsi_done == (void (*)(struct scsi_cmnd*))(uintptr_t)0x6b6b6b6b6b6b6b6bLL))) {
+		printk(KERN_WARNING
+		  "aac_valid_context: scsi command corrupt %p->scsi_done=%p%s%s\n",
+		  scsicmd, (scsicmd &&
+		  (scsicmd != (struct scsi_cmnd*)(uintptr_t)0x6b6b6b6b6b6b6b6bLL))
+		    ? scsicmd->scsi_done
+		    : (void (*)(struct scsi_cmnd*))(uintptr_t)-1LL,
+		  (scsicmd &&
+		  (scsicmd != (struct scsi_cmnd*)(uintptr_t)0x6b6b6b6b6b6b6b6bLL) &&
+		  invalid_command_state(scsicmd)) ? " state" : "",
+		  (scsicmd &&
+		  (scsicmd != (struct scsi_cmnd*)(uintptr_t)0x6b6b6b6b6b6b6b6bLL) &&
+		  invalid_command_magic(scsicmd))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+		    ? " list" : ""
+#else
+		    ? " magic" : ""
+#endif
+		);
+		if (nblank(fwprintf(x))) {
+			extern struct list_head aac_devices; /* in linit.c */
+			struct aac_dev *aac;
+			list_for_each_entry(aac, &aac_devices, entry) {
+				fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B,
+				  "scsi command corrupt %p->scsi_done=%p%s%s",
+				  scsicmd, (scsicmd &&
+				  (scsicmd != (struct scsi_cmnd*)(uintptr_t)0x6b6b6b6b6b6b6b6bLL))
+				    ? scsicmd->scsi_done
+				    : (void (*)(struct scsi_cmnd*))(uintptr_t)-1LL,
+				  (scsicmd &&
+				  (scsicmd != (struct scsi_cmnd*)(uintptr_t)0x6b6b6b6b6b6b6b6bLL) &&
+				  invalid_command_state(scsicmd))
+				    ? " state" : "",
+				  (scsicmd &&
+				  (scsicmd != (struct scsi_cmnd*)(uintptr_t)0x6b6b6b6b6b6b6b6bLL) &&
+				  invalid_command_magic(scsicmd))
+				    ? " magic" : ""));
+			}
+		}
 		aac_fib_complete(fibptr);
 		aac_fib_free(fibptr);
 		return 0;
 	}
+#undef invalid_command_state
+#endif
 	scsicmd->SCp.phase = AAC_OWNER_MIDLEVEL;
 	device = scsicmd->device;
+#if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT) || (0 && defined(BOOTCD)))
+	if (unlikely(device == (void *)(uintptr_t)0x6b6b6b6b6b6b6b6bLL)) {
+		printk(KERN_WARNING
+		  "aac_valid_context: scsi device corrupt device=DEALLOCATED\n");
+		if (nblank(fwprintf(x))) {
+			extern struct list_head aac_devices; /* in linit.c */
+			struct aac_dev *aac;
+			list_for_each_entry(aac, &aac_devices, entry) {
+				fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B,
+				  "scsi device corrupt device=DEALLOCATED"));
+			}
+		}
+		aac_fib_complete(fibptr);
+		aac_fib_free(fibptr);
+		return 0;
+	}
+#endif
 	if (unlikely(!device || !scsi_device_online(device))) {
 		dprintk((KERN_WARNING "aac_valid_context: scsi device corrupt\n"));
+#if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT) || (0 && defined(BOOTCD)))
+		if (!nblank(dprintk(x)))
+			printk(KERN_WARNING
+			  "aac_valid_context: scsi device corrupt device=%p online=%d\n",
+			  device, (!device) ? -1 : scsi_device_online(device));
+		if (nblank(fwprintf(x))) {
+			extern struct list_head aac_devices; /* in linit.c */
+			struct aac_dev *aac;
+			list_for_each_entry(aac, &aac_devices, entry) {
+				fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B,
+				  "scsi device corrupt device=%p online=%d",
+				  device, (!device)
+				    ? -1 : scsi_device_online(device)));
+			}
+		}
+#endif
 		aac_fib_complete(fibptr);
 		aac_fib_free(fibptr);
 		return 0;
@@ -286,12 +868,16 @@ int aac_get_config_status(struct aac_dev *dev, int commit_flag)
 
 	status = aac_fib_send(ContainerCommand,
 			    fibptr,
-			    sizeof (struct aac_get_config_status),
+			    sizeof (struct aac_get_config_status_resp),
 			    FsaNormal,
 			    1, 1,
 			    NULL, NULL);
 	if (status < 0) {
 		printk(KERN_WARNING "aac_get_config_status: SendFIB failed.\n");
+#if (0 && defined(BOOTCD))
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "aac_get_config_status: SendFIB failed."));
+#endif
 	} else {
 		struct aac_get_config_status_resp *reply
 		  = (struct aac_get_config_status_resp *) fib_data(fibptr);
@@ -300,10 +886,21 @@ int aac_get_config_status(struct aac_dev *dev, int commit_flag)
 		  le32_to_cpu(reply->response),
 		  le32_to_cpu(reply->status),
 		  le32_to_cpu(reply->data.action)));
+#if (0 && defined(BOOTCD))
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "aac_get_config_status: response=%d status=%d action=%d",
+		  le32_to_cpu(reply->response),
+		  le32_to_cpu(reply->status),
+		  le32_to_cpu(reply->data.action)));
+#endif
 		if ((le32_to_cpu(reply->response) != ST_OK) ||
 		     (le32_to_cpu(reply->status) != CT_OK) ||
 		     (le32_to_cpu(reply->data.action) > CFACT_PAUSE)) {
 			printk(KERN_WARNING "aac_get_config_status: Will not issue the Commit Configuration\n");
+#if (0 && defined(BOOTCD))
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  "aac_get_config_status: Will not issue the Commit Configuration"));
+#endif
 			status = -EINVAL;
 		}
 	}
@@ -331,9 +928,14 @@ int aac_get_config_status(struct aac_dev *dev, int commit_flag)
 			 * receives a response from F/W */
 			if (status >= 0)
 				aac_fib_complete(fibptr);
+
 		} else if (aac_commit == 0) {
 			printk(KERN_WARNING
 			  "aac_get_config_status: Foreign device configurations are being ignored\n");
+#if (0 && defined(BOOTCD))
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  "aac_get_config_status: Foreign device configurations are being ignored"));
+#endif
 		}
 	}
 	/* FIB should be freed only after getting the response from the F/W */
@@ -344,12 +946,88 @@ int aac_get_config_status(struct aac_dev *dev, int commit_flag)
 
 static void aac_expose_phy_device(struct scsi_cmnd *scsicmd)
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+	void *buf;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+	struct scatterlist *sg = scsi_sglist(scsicmd);
+
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+	if (scsicmd->use_sg) {
+#if (!defined(__VMKLNX__) && !defined(__VMKLNX30__))
+		buf = kmap_atomic(sg->page, KM_IRQ0) + sg->offset;
+#else
+#if defined(__ESX5__)
+		buf = phys_to_virt(sg_dma_address(sg));
+#else
+		buf = phys_to_virt(sg->dma_address);
+#endif
+#endif
+	} else {
+		buf = scsicmd->request_buffer;
+	}
+#else
+#if (defined(HAS_SG_PAGE))
+	buf = kmap_atomic(sg_page(sg), KM_IRQ0) + sg->offset;
+#else
+	buf = kmap_atomic(sg->page, KM_IRQ0) + sg->offset;
+#endif
+
+#endif
+	if(((*(char *)buf) & 0x20) && ((*(char *)buf) & 0x1f) == TYPE_DISK)
+	{
+		(*(char *)buf) &= 0xdf;
+	}
+
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+#if (!defined(__VMKLNX__)&& !defined(__VMKLNX30__))
+	if (scsicmd->use_sg) {
+#if (((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16)) && defined(ARCH_HAS_FLUSH_ANON_PAGE)) || defined(CONFIG_PARISC) || defined(CONFIG_COMMUNITY_KERNEL))
+		flush_kernel_dcache_page(kmap_atomic_to_page(buf - sg->offset));
+#endif
+		kunmap_atomic(buf - sg->offset, KM_IRQ0);
+	}
+#endif
+#else
+#if (defined(ARCH_HAS_FLUSH_ANON_PAGE) || defined(CONFIG_COMMUNITY_KERNEL))
+	flush_kernel_dcache_page(kmap_atomic_to_page(buf - sg->offset));
+#endif
+	kunmap_atomic(buf - sg->offset, KM_IRQ0);
+#endif
+
+#elif ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX__)) && !defined(__x86_64__))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,4))
+	void *pptr;
+	vmk_verify_memory_for_io(scsicmd->request_bufferMA, 1);
+	buf = phys_to_kmap(scsicmd->request_bufferMA, 1, &pptr);
+	if(((*(char *)buf) & 0x20) && ((*(char *)buf) & 0x1f) == TYPE_DISK)
+	{
+		(*(char *)buf) &= 0xdf;
+	}
+	phys_to_kmapFree(buf, pptr);
+#else
+	vmk_verify_memory_for_io(scsicmd->request_bufferMA, 1);
+	buf = vmk_phys_to_kmap(scsicmd->request_bufferMA, 1);
+	if(((*(char *)buf) & 0x20) && ((*(char *)buf) & 0x1f) == TYPE_DISK)
+	{
+		(*(char *)buf) &= 0xdf;
+	}
+	vmk_phys_to_kmap_free(buf);
+#endif
+#else
+	buf = scsicmd->request_buffer;
+	if(((*(char *)buf) & 0x20) && ((*(char *)buf) & 0x1f) == TYPE_DISK)
+	{
+		(*(char *)buf) &= 0xdf;
+	}
+#endif
+#else
 	char inq_data;
 	scsi_sg_copy_to_buffer(scsicmd,  &inq_data, sizeof(inq_data));
-	if ((inq_data & 0x20) && (inq_data & 0x1f) == TYPE_DISK) {
+	if((inq_data & 0x20) && (inq_data & 0x1f) == TYPE_DISK) {
 		inq_data &= 0xdf;
 		scsi_sg_copy_from_buffer(scsicmd, &inq_data, sizeof(inq_data));
 	}
+#endif
 }
 
 /**
@@ -385,6 +1063,9 @@ int aac_get_containers(struct aac_dev *dev)
 	if (status >= 0) {
 		dresp = (struct aac_get_container_count_resp *)fib_data(fibptr);
 		maximum_num_containers = le32_to_cpu(dresp->ContainerSwitchEntries);
+		if (fibptr->dev->supplement_adapter_info.SupportedOptions2 &
+		    AAC_OPTION_SUPPORTED_240_VOLUMES)
+			maximum_num_containers = le32_to_cpu(dresp->MaxSimpleVolumes);
 		aac_fib_complete(fibptr);
 	}
 	/* FIB should be freed only after getting the response from the F/W */
@@ -393,10 +1074,18 @@ int aac_get_containers(struct aac_dev *dev)
 
 	if (maximum_num_containers < MAXIMUM_NUM_CONTAINERS)
 		maximum_num_containers = MAXIMUM_NUM_CONTAINERS;
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)) && !defined(HAS_KZALLOC))
+	fsa_dev_ptr = kmalloc(sizeof(*fsa_dev_ptr) * maximum_num_containers,
+			GFP_KERNEL);
+#else
 	fsa_dev_ptr = kzalloc(sizeof(*fsa_dev_ptr) * maximum_num_containers,
 			GFP_KERNEL);
+#endif
 	if (!fsa_dev_ptr)
 		return -ENOMEM;
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)) && !defined(HAS_KZALLOC))
+	memset(fsa_dev_ptr, 0, sizeof(*fsa_dev_ptr) * maximum_num_containers);
+#endif
 
 	dev->fsa_dev = fsa_dev_ptr;
 	dev->maximum_num_containers = maximum_num_containers;
@@ -408,6 +1097,10 @@ int aac_get_containers(struct aac_dev *dev)
 
 		if (status < 0) {
 			printk(KERN_WARNING "aac_get_containers: SendFIB failed.\n");
+#if (0 && defined(BOOTCD))
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  "aac_get_containers: SendFIB failed."));
+#endif
 			break;
 		}
 
@@ -419,7 +1112,238 @@ int aac_get_containers(struct aac_dev *dev)
 	}
 	return status;
 }
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+
+static void aac_io_done(struct scsi_cmnd * scsicmd)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,0)) /* suppress unused variable warning */
+	unsigned long cpu_flags;
+#endif
+
+	if (unlikely((scsicmd == NULL) ||
+	  (scsicmd == (void *)(uintptr_t)0x6b6b6b6b6b6b6b6bLL) ||
+#if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT) || (0 && defined(BOOTCD)))
+	  invalid_command_magic(scsicmd) ||
+#endif
+	  (scsicmd->scsi_done == (void (*)(struct scsi_cmnd*))NULL) ||
+	  (scsicmd->scsi_done == (void (*)(struct scsi_cmnd*))(uintptr_t)0x6b6b6b6b6b6b6b6bLL))) {
+		printk(KERN_WARNING "aac_io_done: scsicmd corrupted\n");
+		return;
+	}
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,0))
+	spin_lock_irqsave(&io_request_lock, cpu_flags);
+#endif
+	scsicmd->scsi_done(scsicmd);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,0))
+	spin_unlock_irqrestore(&io_request_lock, cpu_flags);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING))
+	{
+		u64 lba;
+		u32 count = 0;
+		struct timeval now;
+		struct aac_dev * dev;
+		do_gettimeofday(&now);
+		if ((scsicmd->cmnd[0] == WRITE_6) ||	/* 6 byte command */
+		    (scsicmd->cmnd[0] == READ_6)) {
+			lba = ((scsicmd->cmnd[1] & 0x1F) << 16) |
+			    (scsicmd->cmnd[2] << 8) | scsicmd->cmnd[3];
+			count = scsicmd->cmnd[4];
+			if (count == 0)
+				count = 256;
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(WRITE_16))
+		} else if ((scsicmd->cmnd[0] == WRITE_16) || /* 16 byte command */
+		    (scsicmd->cmnd[0] == READ_16)) {
+			lba = ((u64)scsicmd->cmnd[2] << 56)
+			    | ((u64)scsicmd->cmnd[3] << 48)
+			    | ((u64)scsicmd->cmnd[4] << 40)
+			    | ((u64)scsicmd->cmnd[5] << 32)
+			    | ((u64)scsicmd->cmnd[6] << 24)
+			    | (scsicmd->cmnd[7] << 16)
+			    | (scsicmd->cmnd[8] << 8) | scsicmd->cmnd[9];
+			count = (scsicmd->cmnd[10] << 24)
+			      | (scsicmd->cmnd[11] << 16)
+			      | (scsicmd->cmnd[12] << 8) | scsicmd->cmnd[13];
+#endif
+		} else if ((scsicmd->cmnd[0] == WRITE_12) /* 12 byte command */
+		 || (scsicmd->cmnd[0] == READ_12)) {
+			lba = ((u64)scsicmd->cmnd[2] << 24)
+			    | (scsicmd->cmnd[3] << 16)
+			    | (scsicmd->cmnd[4] << 8) | scsicmd->cmnd[5];
+			count = (scsicmd->cmnd[6] << 24)
+			      | (scsicmd->cmnd[7] << 16)
+			      | (scsicmd->cmnd[8] << 8) | scsicmd->cmnd[9];
+		} else if ((scsicmd->cmnd[0] == WRITE_10) /* 10 byte command */
+		 || (scsicmd->cmnd[0] == READ_10)) {
+			lba = ((u64)scsicmd->cmnd[2] << 24)
+			    | (scsicmd->cmnd[3] << 16)
+			    | (scsicmd->cmnd[4] << 8) | scsicmd->cmnd[5];
+			count = (scsicmd->cmnd[7] << 8) | scsicmd->cmnd[8];
+		} else
+			lba = (u64)(long)scsicmd;
+		dev = (struct aac_dev *)scsicmd->device->host->hostdata;
+		printk(((count)
+		  ? KERN_DEBUG "%lu.%06lu d%lu %llu[%u]\n"
+		  : KERN_DEBUG "%lu.%06lu d%lu 0x%llx\n"),
+		  now.tv_sec % 100, now.tv_usec,
+		  (unsigned long)(atomic_read(&dev->queues->queue[
+#if (defined(INITFLAGS_APRE_SUPPORTED))
+		    (dev->comm_interface == AAC_COMM_APRE)
+		      ? ApreCmdQueue
+		      : AdapNormCmdQueue
+#else
+		    AdapNormCmdQueue
+#endif
+		  ].numpending)), (unsigned long long)lba, count);
+#if (defined(INITFLAGS_APRE_SUPPORTED))
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  ((count)
+		    ? "%lu.%06lu d%lu %llu[%u]"
+		    : "%lu.%06lu d%lu 0x%llx"),
+		  now.tv_sec % 100, now.tv_usec,
+		  (unsigned long)(dev->queues->queue[
+		    (dev->comm_interface == AAC_COMM_APRE)
+		      ? ApreCmdQueue
+		      : AdapNormCmdQueue
+		  ].numpending), (unsigned long long)lba, count));
+#else
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  ((count)
+		    ? "%lu.%06lu d%lu %llu[%u]"
+		    : "%lu.%06lu d%lu 0x%llx"),
+		  now.tv_sec % 100, now.tv_usec,
+		  (unsigned long)(atomic_read(&dev->queues->queue[AdapNormCmdQueue].numpending)), lba, count));
+
+#endif
+	}
+#endif
+}
+
+static inline void __aac_io_done(struct scsi_cmnd * scsicmd)
+{
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING))
+	struct timeval now;
+	struct aac_dev * dev;
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+	BUG_ON((scsicmd == NULL) || (scsicmd == (void *)(uintptr_t)0x6b6b6b6b6b6b6b6bLL));
+	BUG_ON((scsicmd->scsi_done == NULL) || (scsicmd->scsi_done == (void (*)(struct scsi_cmnd*))(uintptr_t)0x6b6b6b6b6b6b6b6bLL));
+#endif
+	scsicmd->scsi_done(scsicmd);
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING))
+	do_gettimeofday(&now);
+	dev = (struct aac_dev *)scsicmd->device->host->hostdata;
+	printk(KERN_DEBUG "%lu.%06lu d%lu %p\n",
+	  now.tv_sec % 100, now.tv_usec,
+	  (unsigned long)(atomic_read(&dev->queues->queue[
+#if (defined(INITFLAGS_APRE_SUPPORTED))
+	    (dev->comm_interface == AAC_COMM_APRE)
+	      ? ApreCmdQueue
+	      : AdapNormCmdQueue
+#else
+	    AdapNormCmdQueue
+#endif
+	  ].numpending)), scsicmd);
+#if (defined(INITFLAGS_APRE_SUPPORTED))
+	fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  "%lu.%06lu d%lu %p",
+	  now.tv_sec % 100, now.tv_usec,
+	  (unsigned long)(dev->queues->queue[
+	    (dev->comm_interface == AAC_COMM_APRE)
+	      ? ApreCmdQueue
+	      : AdapNormCmdQueue
+	  ].numpending), scsicmd));
+#else
+	fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  "%lu.%06lu d%lu %p",
+	  now.tv_sec % 100, now.tv_usec,
+	  (unsigned long)atomic_read(&dev->queues->queue[AdapNormCmdQueue].numpending), scsicmd));
+#endif
+#endif
+}
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static void aac_internal_transfer(struct scsi_cmnd *scsicmd, void *data, unsigned int offset, unsigned int len)
+{
+	void *buf;
+	int transfer_len;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+	struct scatterlist *sg = scsi_sglist(scsicmd);
+
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+	if (scsicmd->use_sg) {
+#if (!defined(__VMKLNX30__) && !defined(__VMKLNX__))
+		buf = kmap_atomic(sg->page, KM_IRQ0) + sg->offset;
+		transfer_len = min(sg->length, len + offset);
+#else
+#if defined(__ESX5__)
+		buf = phys_to_virt(sg_dma_address(sg));
+		transfer_len = min(sg_dma_len(sg), len + offset);
+#else
+		buf = phys_to_virt(sg->dma_address);
+		transfer_len = min(sg->dma_length, len + offset);
+#endif
+#endif
+	} else {
+		buf = scsicmd->request_buffer;
+		transfer_len = min(scsicmd->request_bufflen, len + offset);
+	}
+#else
+#if (defined(HAS_SG_PAGE))
+	buf = kmap_atomic(sg_page(sg), KM_IRQ0) + sg->offset;
+#else
+	buf = kmap_atomic(sg->page, KM_IRQ0) + sg->offset;
+#endif
+	transfer_len = min(sg->length, len + offset);
+
+#endif
+	transfer_len -= offset;
+	if (buf && transfer_len > 0)
+		memcpy(buf + offset, data, transfer_len);
+
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+#if (!defined(__VMKLNX30__) && !defined(__VMKLNX__))
+	if (scsicmd->use_sg) {
+#if (((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,16)) && defined(ARCH_HAS_FLUSH_ANON_PAGE)) || defined(CONFIG_PARISC) || defined(CONFIG_COMMUNITY_KERNEL))
+		flush_kernel_dcache_page(kmap_atomic_to_page(buf - sg->offset));
+#endif
+		kunmap_atomic(buf - sg->offset, KM_IRQ0);
+	}
+#endif
+#else
+#if (defined(ARCH_HAS_FLUSH_ANON_PAGE) || defined(CONFIG_COMMUNITY_KERNEL))
+	flush_kernel_dcache_page(kmap_atomic_to_page(buf - sg->offset));
+#endif
+	kunmap_atomic(buf - sg->offset, KM_IRQ0);
+#endif
+
+#elif ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__)) && !defined(__x86_64__))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,4))
+	void *pptr;
+	vmk_verify_memory_for_io(scsicmd->request_bufferMA, len + offset);
+	buf = phys_to_kmap(scsicmd->request_bufferMA, len + offset, &pptr);
+	transfer_len = min(scsicmd->request_bufflen, len + offset) - offset;
+	if (buf && transfer_len > 0)
+		memcpy(buf + offset, data, transfer_len);
+	phys_to_kmapFree(buf, pptr);
+#else
+	vmk_verify_memory_for_io(scsicmd->request_bufferMA, len + offset);
+	buf = vmk_phys_to_kmap(scsicmd->request_bufferMA, len + offset);
+	transfer_len = min(scsicmd->request_bufflen, len + offset) - offset;
+	if (buf && transfer_len > 0)
+		memcpy(buf + offset, data, transfer_len);
+	vmk_phys_to_kmap_free(buf);
+#endif
+#else
+	buf = scsicmd->request_buffer;
+	transfer_len = min(scsicmd->request_bufflen, len + offset) - offset;
+	if (buf && transfer_len > 0)
+		memcpy(buf + offset, data, transfer_len);
+#endif
+}
 
+#endif
 static void get_container_name_callback(void *context, struct fib * fibptr)
 {
 	struct aac_get_name_resp * get_name_reply;
@@ -431,28 +1355,47 @@ static void get_container_name_callback(void *context, struct fib * fibptr)
 		return;
 
 	dprintk((KERN_DEBUG "get_container_name_callback[cpu %d]: t = %ld.\n", smp_processor_id(), jiffies));
+#if ((0 && defined(BOOTCD)) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	fwprintf((fibptr->dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  "get_container_name_callback"));
+#endif
 	BUG_ON(fibptr == NULL);
 
 	get_name_reply = (struct aac_get_name_resp *) fib_data(fibptr);
 	/* Failure is irrelevant, using default value instead */
+#if ((0 && defined(BOOTCD)) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	fwprintf((fibptr->dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  "  status=%d", le32_to_cpu(get_name_reply->status)));
+#endif
 	if ((le32_to_cpu(get_name_reply->status) == CT_OK)
 	 && (get_name_reply->data[0] != '\0')) {
 		char *sp = get_name_reply->data;
-		sp[sizeof(((struct aac_get_name_resp *)NULL)->data)-1] = '\0';
+		sp[sizeof(((struct aac_get_name_resp *)NULL)->data)] = '\0';
+#if ((0 && defined(BOOTCD)) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+		fwprintf((fibptr->dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "  name=\"%s\"", sp));
+#endif
 		while (*sp == ' ')
 			++sp;
 		if (*sp) {
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26))
 			struct inquiry_data inq;
+#endif
 			char d[sizeof(((struct inquiry_data *)NULL)->inqd_pid)];
 			int count = sizeof(d);
 			char *dp = d;
 			do {
 				*dp++ = (*sp) ? *sp++ : ' ';
 			} while (--count > 0);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+			aac_internal_transfer(scsicmd, d,
+			  offsetof(struct inquiry_data, inqd_pid), sizeof(d));
+#else
 
 			scsi_sg_copy_to_buffer(scsicmd, &inq, sizeof(inq));
 			memcpy(inq.inqd_pid, d, sizeof(d));
 			scsi_sg_copy_from_buffer(scsicmd, &inq, sizeof(inq));
+#endif
 		}
 	}
 
@@ -460,7 +1403,11 @@ static void get_container_name_callback(void *context, struct fib * fibptr)
 
 	aac_fib_complete(fibptr);
 	aac_fib_free(fibptr);
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+	aac_io_done(scsicmd);
+#else
 	scsicmd->scsi_done(scsicmd);
+#endif
 }
 
 /**
@@ -488,7 +1435,7 @@ static int aac_get_container_name(struct scsi_cmnd * scsicmd)
 
 	status = aac_fib_send(ContainerCommand,
 		  cmd_fibcontext,
-		  sizeof (struct aac_get_name),
+		  sizeof (struct aac_get_name_resp),
 		  FsaNormal,
 		  0, 1,
 		  (fib_callback)get_container_name_callback,
@@ -499,10 +1446,21 @@ static int aac_get_container_name(struct scsi_cmnd * scsicmd)
 	 */
 	if (status == -EINPROGRESS) {
 		scsicmd->SCp.phase = AAC_OWNER_FIRMWARE;
+#if ((0 && defined(BOOTCD)) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "aac_get_container_name(%p(%d:%d:%d:%d))", scsicmd,
+		  scsicmd->device->host->host_no, scmd_channel(scsicmd),
+		  scmd_id(scsicmd), scsicmd->device->lun));
+#endif
 		return 0;
 	}
 
 	printk(KERN_WARNING "aac_get_container_name: aac_fib_send failed with status: %d.\n", status);
+#if ((0 && defined(BOOTCD)) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  "aac_get_container_name: aac_fib_send failed with status: %d.",
+	  status));
+#endif
 	aac_fib_complete(cmd_fibcontext);
 	aac_fib_free(cmd_fibcontext);
 	return -1;
@@ -512,11 +1470,28 @@ static int aac_probe_container_callback2(struct scsi_cmnd * scsicmd)
 {
 	struct fsa_dev_info *fsa_dev_ptr = ((struct aac_dev *)(scsicmd->device->host->hostdata))->fsa_dev;
 
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	printk(KERN_INFO "aac_probe_container_callback2(%p)\n", scsicmd);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	if (!list_empty(&((struct aac_dev *)(scsicmd->device->host->hostdata))->entry)) {
+#endif
+	fwprintf(((struct aac_dev *)(scsicmd->device->host->hostdata),
+	  HBA_FLAGS_DBG_FW_PRINT_B, "aac_probe_container_callback2(%p)", scsicmd));
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	}
+#endif
+#endif
 	if ((fsa_dev_ptr[scmd_id(scsicmd)].valid & 1))
 		return aac_scsi_cmd(scsicmd);
 
 	scsicmd->result = DID_NO_CONNECT << 16;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+	__aac_io_done(scsicmd);
+#else
 	scsicmd->scsi_done(scsicmd);
+#endif
 	return 0;
 }
 
@@ -524,21 +1499,78 @@ static void _aac_probe_container2(void * context, struct fib * fibptr)
 {
 	struct fsa_dev_info *fsa_dev_ptr;
 	int (*callback)(struct scsi_cmnd *);
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+	struct aac_dev *dev;
+#endif
 	struct scsi_cmnd * scsicmd = (struct scsi_cmnd *)context;
 
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	printk(KERN_INFO "_aac_probe_container2(%p,%p)\n", scsicmd, fibptr);
+#endif
 
 	if (!aac_valid_context(scsicmd, fibptr))
 		return;
 
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+	dev = fibptr->dev;
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	if (!list_empty(&dev->entry)) {
+#endif
+	fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  "_aac_probe_container2(%p(%d:%d:%d:%d),%p)", scsicmd,
+	  scsicmd->device->host->host_no, scmd_channel(scsicmd),
+	  scmd_id(scsicmd), scsicmd->device->lun, fibptr));
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	}
+#endif
+#endif
 	scsicmd->SCp.Status = 0;
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+	fsa_dev_ptr = dev->fsa_dev;
+#else
 	fsa_dev_ptr = fibptr->dev->fsa_dev;
+#endif
 	if (fsa_dev_ptr) {
 		struct aac_mount * dresp = (struct aac_mount *) fib_data(fibptr);
 		fsa_dev_ptr += scmd_id(scsicmd);
 
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+		printk(KERN_INFO "_aac_probe_container2 (%d:%d:%d:%d)"
+		  " resp={%d,%d,0x%x,%llu}\n",
+		  scsicmd->device->host->host_no, scmd_channel(scsicmd),
+		  scmd_id(scsicmd), scsicmd->device->lun,
+		  le32_to_cpu(dresp->status), le32_to_cpu(dresp->mnt[0].vol),
+		  le32_to_cpu(dresp->mnt[0].state),
+		  ((u64)le32_to_cpu(dresp->mnt[0].capacity)) +
+		    (((u64)le32_to_cpu(dresp->mnt[0].capacityhigh)) << 32));
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+		if (!list_empty(&dev->entry)) {
+#endif
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "_aac_probe_container2 (%d:%d:%d:%d)"
+		  " resp={%d,%d,0x%x,%llu}\n",
+		  scsicmd->device->host->host_no, scmd_channel(scsicmd),
+		  scmd_id(scsicmd), scsicmd->device->lun,
+		  le32_to_cpu(dresp->status), le32_to_cpu(dresp->mnt[0].vol),
+		  le32_to_cpu(dresp->mnt[0].state),
+		  ((u64)le32_to_cpu(dresp->mnt[0].capacity)) +
+		    (((u64)le32_to_cpu(dresp->mnt[0].capacityhigh)) << 32)));
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+		}
+#endif
+#endif
 		if ((le32_to_cpu(dresp->status) == ST_OK) &&
 		    (le32_to_cpu(dresp->mnt[0].vol) != CT_NONE) &&
 		    (le32_to_cpu(dresp->mnt[0].state) != FSCS_HIDDEN)) {
+			if (!(fibptr->dev->supplement_adapter_info.SupportedOptions2 &
+			    AAC_OPTION_VARIABLE_BLOCK_SIZE)) {
+				dresp->mnt[0].fileinfo.bdevinfo.block_size = 0x200;
+				fsa_dev_ptr->block_size = 0x200;
+			} else {
+				fsa_dev_ptr->block_size = le32_to_cpu(dresp->mnt[0].fileinfo.bdevinfo.block_size);
+			}
 			fsa_dev_ptr->valid = 1;
 			/* sense_key holds the current state of the spin-up */
 			if (dresp->mnt[0].state & cpu_to_le32(FSCS_NOT_READY))
@@ -559,6 +1591,18 @@ static void _aac_probe_container2(void * context, struct fib * fibptr)
 	aac_fib_free(fibptr);
 	callback = (int (*)(struct scsi_cmnd *))(scsicmd->SCp.ptr);
 	scsicmd->SCp.ptr = NULL;
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	printk(KERN_INFO "(*%p)(%p)\n", callback, scsicmd);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	if (!list_empty(&dev->entry)) {
+#endif
+	fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B, "(*%p)(%p)", callback, scsicmd));
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	}
+#endif
+#endif
 	(*callback)(scsicmd);
 	return;
 }
@@ -570,8 +1614,23 @@ static void _aac_probe_container1(void * context, struct fib * fibptr)
 	struct aac_query_mount *dinfo;
 	int status;
 
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	printk(KERN_INFO "_aac_probe_container1(%p,%p)\n", context, fibptr);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	if (!list_empty(&fibptr->dev->entry)) {
+#endif
+	fwprintf((fibptr->dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  "_aac_probe_container1(%p,%p)", context, fibptr));
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	}
+#endif
+#endif
 	dresp = (struct aac_mount *) fib_data(fibptr);
-	dresp->mnt[0].capacityhigh = 0;
+	if (!(fibptr->dev->supplement_adapter_info.SupportedOptions2 &
+	    AAC_OPTION_VARIABLE_BLOCK_SIZE))
+		dresp->mnt[0].capacityhigh = 0;
 	if ((le32_to_cpu(dresp->status) != ST_OK) ||
 	    (le32_to_cpu(dresp->mnt[0].vol) != CT_NONE)) {
 		_aac_probe_container2(context, fibptr);
@@ -586,10 +1645,37 @@ static void _aac_probe_container1(void * context, struct fib * fibptr)
 
 	dinfo = (struct aac_query_mount *)fib_data(fibptr);
 
-	dinfo->command = cpu_to_le32(VM_NameServe64);
+	if (fibptr->dev->supplement_adapter_info.SupportedOptions2 &
+	    AAC_OPTION_VARIABLE_BLOCK_SIZE)
+		dinfo->command = cpu_to_le32(VM_NameServeAllBlk);
+	else
+		dinfo->command = cpu_to_le32(VM_NameServe64);
+
 	dinfo->count = cpu_to_le32(scmd_id(scsicmd));
 	dinfo->type = cpu_to_le32(FT_FILESYS);
 
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	if (fibptr->dev->supplement_adapter_info.SupportedOptions2 &
+	    AAC_OPTION_VARIABLE_BLOCK_SIZE)
+		printk(KERN_INFO "aac_fib_send(ContainerCommand,VM_NameServeAllBlk,...)\n");
+	else
+		printk(KERN_INFO "aac_fib_send(ContainerCommand,VM_NameServe64,...)\n");
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	if (!list_empty(&fibptr->dev->entry)) {
+#endif
+	if (fibptr->dev->supplement_adapter_info.SupportedOptions2 &
+	    AAC_OPTION_VARIABLE_BLOCK_SIZE)
+		fwprintf((fibptr->dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "aac_fib_send(ContainerCommand,VM_NameServeAllBlk,...)"));
+	else
+		fwprintf((fibptr->dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "aac_fib_send(ContainerCommand,VM_NameServe64,...)"));
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	}
+#endif
+#endif
 	status = aac_fib_send(ContainerCommand,
 			  fibptr,
 			  sizeof(struct aac_query_mount),
@@ -614,6 +1700,20 @@ static int _aac_probe_container(struct scsi_cmnd * scsicmd, int (*callback)(stru
 	struct fib * fibptr;
 	int status = -ENOMEM;
 
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	printk(KERN_INFO "_aac_probe_container(%p,%p)\n", scsicmd, callback);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	if (!list_empty(&((struct aac_dev *)(scsicmd->device->host->hostdata))->entry)) {
+#endif
+	fwprintf(((struct aac_dev *)(scsicmd->device->host->hostdata),
+	  HBA_FLAGS_DBG_FW_PRINT_B,
+	  "_aac_probe_container(%p,%p)", scsicmd, callback));
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	}
+#endif
+#endif
 	if ((fibptr = aac_fib_alloc((struct aac_dev *)scsicmd->device->host->hostdata))) {
 		struct aac_query_mount *dinfo;
 
@@ -621,11 +1721,38 @@ static int _aac_probe_container(struct scsi_cmnd * scsicmd, int (*callback)(stru
 
 		dinfo = (struct aac_query_mount *)fib_data(fibptr);
 
-		dinfo->command = cpu_to_le32(VM_NameServe);
+		if (fibptr->dev->supplement_adapter_info.SupportedOptions2 &
+		    AAC_OPTION_VARIABLE_BLOCK_SIZE)
+			dinfo->command = cpu_to_le32(VM_NameServeAllBlk);
+		else
+			dinfo->command = cpu_to_le32(VM_NameServe);
+
 		dinfo->count = cpu_to_le32(scmd_id(scsicmd));
 		dinfo->type = cpu_to_le32(FT_FILESYS);
 		scsicmd->SCp.ptr = (char *)callback;
 
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+		if (fibptr->dev->supplement_adapter_info.SupportedOptions2 &
+		    AAC_OPTION_VARIABLE_BLOCK_SIZE)
+			printk(KERN_INFO "aac_fib_send(ContainerCommand,VM_NameServeAllBlk,...)\n");
+		else
+			printk(KERN_INFO "aac_fib_send(ContainerCommand,VM_NameServe,...)\n");
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+		if (!list_empty(&fibptr->dev->entry)) {
+#endif
+			if (fibptr->dev->supplement_adapter_info.SupportedOptions2 &
+			    AAC_OPTION_VARIABLE_BLOCK_SIZE)
+				fwprintf((fibptr->dev, HBA_FLAGS_DBG_FW_PRINT_B,
+				  "aac_fib_send(ContainerCommand,VM_NameServeAllBlk,...)"));
+			else
+				fwprintf((fibptr->dev, HBA_FLAGS_DBG_FW_PRINT_B,
+				  "aac_fib_send(ContainerCommand,VM_NameServe,...)"));
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+		}
+#endif
+#endif
 		status = aac_fib_send(ContainerCommand,
 			  fibptr,
 			  sizeof(struct aac_query_mount),
@@ -669,6 +1796,19 @@ static int _aac_probe_container(struct scsi_cmnd * scsicmd, int (*callback)(stru
  */
 static int aac_probe_container_callback1(struct scsi_cmnd * scsicmd)
 {
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	printk(KERN_INFO "aac_probe_container_callback1(%p)\n", scsicmd);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	if (!list_empty(&((struct aac_dev *)(scsicmd->device->host->hostdata))->entry)) {
+#endif
+	fwprintf(((struct aac_dev *)(scsicmd->device->host->hostdata),
+	  HBA_FLAGS_DBG_FW_PRINT_B, "aac_probe_container_callback1(%p)", scsicmd));
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	}
+#endif
+#endif
 	scsicmd->device = NULL;
 	return 0;
 }
@@ -679,16 +1819,46 @@ int aac_probe_container(struct aac_dev *dev, int cid)
 	struct scsi_device *scsidev = kmalloc(sizeof(*scsidev), GFP_KERNEL);
 	int status;
 
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	printk(KERN_INFO "aac_probe_container(%p,%d)\n", dev, cid);
+#endif
 	if (!scsicmd || !scsidev) {
 		kfree(scsicmd);
 		kfree(scsidev);
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+		printk(KERN_INFO "aac_probe_container returns -ENOMEM\n");
+#endif
 		return -ENOMEM;
 	}
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	if (!list_empty(&dev->entry)) {
+#endif
+	fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  "aac_probe_container(%p,%d)", dev, cid));
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+	}
+#endif
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 	scsicmd->list.next = NULL;
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,12))
+	scsicmd->state = SCSI_STATE_QUEUED;
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) && defined(SCSI_CMND_MAGIC))
+	scsicmd->sc_magic = 0;
+#endif
+#endif
 	scsicmd->scsi_done = (void (*)(struct scsi_cmnd*))aac_probe_container_callback1;
 
 	scsicmd->device = scsidev;
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,6)) && (!defined(SCSI_HAS_SCSI_DEVICE_ONLINE)))
+	scsidev->online = 1;
+#else
 	scsidev->sdev_state = 0;
+#endif
 	scsidev->id = cid;
 	scsidev->host = dev->scsi_host_ptr;
 
@@ -698,9 +1868,40 @@ int aac_probe_container(struct aac_dev *dev, int cid)
 	kfree(scsidev);
 	status = scsicmd->SCp.Status;
 	kfree(scsicmd);
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+	{
+		struct fsa_dev_info * fsa_dev_ptr = &dev->fsa_dev[cid];
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+
+		printk(KERN_INFO
+		  "aac_probe_container returns %d"
+		  " *(&%p->fsa_dev[%d]=%p)={%d,%d,%llu,\"%.*s\"}\n",
+		  status, dev, cid, fsa_dev_ptr, fsa_dev_ptr->valid,
+		  fsa_dev_ptr->type, fsa_dev_ptr->size,
+		  (int)sizeof(fsa_dev_ptr->devname),
+		  fsa_dev_ptr->devname);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE) || (0 && defined(BOOTCD)))
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+		if (!list_empty(&dev->entry)) {
+#endif
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "aac_probe_container returns %d"
+		  " *(&%p->fsa_dev[%d]=%p)={%d,%d,%llu,\"%.*s\"}",
+		  status, dev, cid, fsa_dev_ptr, fsa_dev_ptr->valid,
+		  fsa_dev_ptr->type, fsa_dev_ptr->size,
+		  (int)sizeof(fsa_dev_ptr->devname),
+		  fsa_dev_ptr->devname));
+#if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+		}
+#endif
+	}
+#endif
 	return status;
 }
 
+#if (defined(CONFIG_COMMUNITY_KERNEL))
 /* Local Structure to set SCSI inquiry data strings */
 struct scsi_inq {
 	char vid[8];         /* Vendor ID */
@@ -708,6 +1909,7 @@ struct scsi_inq {
 	char prl[4];         /* Product Revision Level */
 };
 
+#endif
 /**
  *	InqStrCopy	-	string merge
  *	@a:	string to copy from
@@ -747,6 +1949,7 @@ static char *container_types[] = {
 	"RAID60",
 	"Unknown"
 };
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 
 char * get_container_type(unsigned tindex)
 {
@@ -754,17 +1957,22 @@ char * get_container_type(unsigned tindex)
 		tindex = ARRAY_SIZE(container_types) - 1;
 	return container_types[tindex];
 }
+#endif
 
 /* Function: setinqstr
  *
  * Arguments: [1] pointer to void [1] int
  *
  * Purpose: Sets SCSI inquiry data strings for vendor, product
- * and revision level. Allows strings to be set in platform dependent
- * files instead of in OS dependent driver source.
+ * and revision level. Allows strings to be set in platform dependant
+ * files instead of in OS dependant driver source.
  */
 
+#if (defined(CONFIG_COMMUNITY_KERNEL))
 static void setinqstr(struct aac_dev *dev, void *data, int tindex)
+#else
+void setinqstr(struct aac_dev *dev, void *data, int tindex)
+#endif
 {
 	struct scsi_inq *str;
 
@@ -774,6 +1982,7 @@ static void setinqstr(struct aac_dev *dev, void *data, int tindex)
 	if (dev->supplement_adapter_info.AdapterTypeText[0]) {
 		char * cp = dev->supplement_adapter_info.AdapterTypeText;
 		int c;
+		
 		if ((cp[0] == 'A') && (cp[1] == 'O') && (cp[2] == 'C'))
 			inqstrcpy("SMC", str->vid);
 		else {
@@ -801,7 +2010,6 @@ static void setinqstr(struct aac_dev *dev, void *data, int tindex)
 			cp[sizeof(str->pid)] = c;
 	} else {
 		struct aac_driver_ident *mp = aac_get_driver_ident(dev->cardtype);
-
 		inqstrcpy (mp->vname, str->vid);
 		/* last six chars reserved for vol type */
 		inqstrcpy (mp->model, str->pid);
@@ -835,21 +2043,108 @@ static void get_container_serial_callback(void *context, struct fib * fibptr)
 	get_serial_reply = (struct aac_get_serial_resp *) fib_data(fibptr);
 	/* Failure is irrelevant, using default value instead */
 	if (le32_to_cpu(get_serial_reply->status) == CT_OK) {
-		char sp[13];
-		/* EVPD bit set */
-		sp[0] = INQD_PDT_DA;
-		sp[1] = scsicmd->cmnd[2];
-		sp[2] = 0;
-		sp[3] = snprintf(sp+4, sizeof(sp)-4, "%08X",
-		  le32_to_cpu(get_serial_reply->uid));
-		scsi_sg_copy_from_buffer(scsicmd, sp, sizeof(sp));
+
+/* Excluding SUSE as it has issues when inbox driver does not have this support but outbox has it. 
+  Because SUSE uses /dev/disk/by-id mapping entries in the OS grub config and VPD 0X83 creates conflicts */
+#if (!defined(CONFIG_SUSE_KERNEL))
+
+		/*Check to see if it's for VPD 0x83 or 0x80 */
+		if(scsicmd->cmnd[2] == 0x83)
+		{
+				/* vpd page 0x83 - Device Identification Page */
+			int i;	
+			TVPD_Page83 VPDPage83Data;
+				
+				memset(((u8 *)&VPDPage83Data), 0, sizeof(VPDPage83Data));
+
+
+				 VPDPage83Data.DeviceType = 0;			//DIRECT_ACCESS_DEVICE;
+                VPDPage83Data.DeviceTypeQualifier = 0;	//DEVICE_CONNECTED;
+                VPDPage83Data.PageCode = 0x83;			//VPD_DEVICE_IDENTIFIERS;
+                VPDPage83Data.Reserved = 0;
+                VPDPage83Data.PageLength = sizeof(VPDPage83Data.IdDescriptorType1) +
+                                              sizeof(VPDPage83Data.IdDescriptorType2);
+
+                // T10 Vendor Identifier Field Format
+                VPDPage83Data.IdDescriptorType1.CodeSet = 2;			//VpdCodeSetAscii;
+                VPDPage83Data.IdDescriptorType1.IdentifierType = 1;		//VpdIdentifierTypeVendorId;
+                VPDPage83Data.IdDescriptorType1.IdentifierLength = sizeof(VPDPage83Data.IdDescriptorType1) - 4;
+
+                memcpy(VPDPage83Data.IdDescriptorType1.VendId, "ADAPTEC ", // "ADAPTEC " for adaptec
+                       sizeof(VPDPage83Data.IdDescriptorType1.VendId));
+                memcpy(VPDPage83Data.IdDescriptorType1.ProductId, "ARRAY           ",
+                       sizeof(VPDPage83Data.IdDescriptorType1.ProductId));
+
+                // Convert to ascii based serial number.
+                // The LSB is the the end.
+
+                for (i=0; i < 8; i++) {
+                    u8 temp = (u8)((get_serial_reply->uid >> ((7 - i) * 4)) & 0xF);
+                    if (temp  > 0x9)
+                    {
+                        VPDPage83Data.IdDescriptorType1.SerialNumber[i] = 'A' + (temp - 0xA);
+                    } else
+                    {
+                        VPDPage83Data.IdDescriptorType1.SerialNumber[i] = '0' + temp;
+                    }
+                }
+			
+                // EUI-64 Vendor Identifier Field Format, 24 bits for VendId and 40 bits for SN.
+                VPDPage83Data.IdDescriptorType2.CodeSet = 1;				//VpdCodeSetBinary;
+                VPDPage83Data.IdDescriptorType2.IdentifierType = 2;			//VpdIdentifierTypeEUI64;
+                VPDPage83Data.IdDescriptorType2.IdentifierLength = sizeof(VPDPage83Data.IdDescriptorType2) - 4;
+
+                VPDPage83Data.IdDescriptorType2.EU64Id.VendId[0] = 0xD0; // 0x0000055 for IBM, 0x0000D0 for Adaptec.
+                VPDPage83Data.IdDescriptorType2.EU64Id.VendId[1] = 0;
+                VPDPage83Data.IdDescriptorType2.EU64Id.VendId[2] = 0;
+
+			    VPDPage83Data.IdDescriptorType2.EU64Id.Serial = get_serial_reply->uid;
+                VPDPage83Data.IdDescriptorType2.EU64Id.Reserved = 0;
+
+                // Move the inquiry data to the response buffer.
+//                memcpy(arr, &VPDPage83Data, sizeof(VPDPage83Data));
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+				aac_internal_transfer(scsicmd, &VPDPage83Data, 0,
+				  sizeof(VPDPage83Data));
+#else
+				scsi_sg_copy_from_buffer(scsicmd, &VPDPage83Data,
+							 sizeof(VPDPage83Data));
+#endif
+		}
+		else
+#endif
+		{
+			/* It must be for VPD 0x80 */
+			char sp[13];
+			/* EVPD bit set */
+			sp[0] = INQD_PDT_DA;
+			sp[1] = scsicmd->cmnd[2];
+			sp[2] = 0;
+	#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+			sp[3] = snprintf(sp+4, sizeof(sp)-4, "%08X",
+			  le32_to_cpu(get_serial_reply->uid));
+	#else
+			sp[3] = sprintf(sp+4, "%08X",
+			  le32_to_cpu(get_serial_reply->uid));
+	#endif
+	#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+			aac_internal_transfer(scsicmd, sp, 0, sizeof(sp));
+	#else
+			scsi_sg_copy_from_buffer(scsicmd, sp, sizeof(sp));
+	#endif
+		}
 	}
 
 	scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
 
 	aac_fib_complete(fibptr);
 	aac_fib_free(fibptr);
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+	aac_io_done(scsicmd);
+#else
 	scsicmd->scsi_done(scsicmd);
+#endif
 }
 
 /**
@@ -876,7 +2171,7 @@ static int aac_get_container_serial(struct scsi_cmnd * scsicmd)
 
 	status = aac_fib_send(ContainerCommand,
 		  cmd_fibcontext,
-		  sizeof (struct aac_get_serial),
+		  sizeof (struct aac_get_serial_resp),
 		  FsaNormal,
 		  0, 1,
 		  (fib_callback) get_container_serial_callback,
@@ -912,8 +2207,13 @@ static int setinqserial(struct aac_dev *dev, void *data, int cid)
 	/*
 	 *	This breaks array migration.
 	 */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
 	return snprintf((char *)(data), sizeof(struct scsi_inq) - 4, "%08X%02X",
 			le32_to_cpu(dev->adapter_info.serial[0]), cid);
+#else
+	return sprintf((char *)(data), "%08X%02X",
+			le32_to_cpu(dev->adapter_info.serial[0]), cid);
+#endif
 }
 
 static inline void set_sense(struct sense_data *sense_data, u8 sense_key,
@@ -956,7 +2256,11 @@ static int aac_bounds_32(struct aac_dev * dev, struct scsi_cmnd * cmd, u64 lba)
 		memcpy(cmd->sense_buffer, &dev->fsa_dev[cid].sense_data,
 		       min_t(size_t, sizeof(dev->fsa_dev[cid].sense_data),
 			     SCSI_SENSE_BUFFERSIZE));
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(cmd);
+#else
 		cmd->scsi_done(cmd);
+#endif
 		return 1;
 	}
 	return 0;
@@ -982,22 +2286,21 @@ static int aac_read_raw_io(struct fib * fib, struct scsi_cmnd * cmd, u64 lba, u3
 		memset(readcmd2, 0, sizeof(struct aac_raw_io2));
 		readcmd2->blockLow = cpu_to_le32((u32)(lba&0xffffffff));
 		readcmd2->blockHigh = cpu_to_le32((u32)((lba&0xffffffff00000000LL)>>32));
-		readcmd2->byteCount = cpu_to_le32(count<<9);
+		readcmd2->byteCount = cpu_to_le32(count * dev->fsa_dev[scmd_id(cmd)].block_size);
 		readcmd2->cid = cpu_to_le16(scmd_id(cmd));
 		readcmd2->flags = cpu_to_le16(RIO2_IO_TYPE_READ);
-		ret = aac_build_sgraw2(cmd, readcmd2,
-				dev->scsi_host_ptr->sg_tablesize);
+		ret = aac_build_sgraw2(cmd, readcmd2, dev->scsi_host_ptr->sg_tablesize);
 		if (ret < 0)
 			return ret;
 		command = ContainerRawIo2;
-		fibsize = sizeof(struct aac_raw_io2) +
+		fibsize = sizeof(struct aac_raw_io2) + 
 			((le32_to_cpu(readcmd2->sgeCnt)-1) * sizeof(struct sge_ieee1212));
 	} else {
 		struct aac_raw_io *readcmd;
 		readcmd = (struct aac_raw_io *) fib_data(fib);
 		readcmd->block[0] = cpu_to_le32((u32)(lba&0xffffffff));
 		readcmd->block[1] = cpu_to_le32((u32)((lba&0xffffffff00000000LL)>>32));
-		readcmd->count = cpu_to_le32(count<<9);
+		readcmd->count = cpu_to_le32(count * dev->fsa_dev[scmd_id(cmd)].block_size);
 		readcmd->cid = cpu_to_le16(scmd_id(cmd));
 		readcmd->flags = cpu_to_le16(RIO_TYPE_READ);
 		readcmd->bpTotal = 0;
@@ -1006,7 +2309,7 @@ static int aac_read_raw_io(struct fib * fib, struct scsi_cmnd * cmd, u64 lba, u3
 		if (ret < 0)
 			return ret;
 		command = ContainerRawIo;
-		fibsize = sizeof(struct aac_raw_io) +
+		fibsize = sizeof(struct aac_raw_io) + 
 			((le32_to_cpu(readcmd->sg.count)-1) * sizeof(struct sgentryraw));
 	}
 
@@ -1062,6 +2365,7 @@ static int aac_read_block(struct fib * fib, struct scsi_cmnd * cmd, u64 lba, u32
 {
 	u16 fibsize;
 	struct aac_read *readcmd;
+	struct aac_dev *dev = fib->dev;
 	long ret;
 
 	aac_fib_init(fib);
@@ -1069,7 +2373,7 @@ static int aac_read_block(struct fib * fib, struct scsi_cmnd * cmd, u64 lba, u32
 	readcmd->command = cpu_to_le32(VM_CtBlockRead);
 	readcmd->cid = cpu_to_le32(scmd_id(cmd));
 	readcmd->block = cpu_to_le32((u32)(lba&0xffffffff));
-	readcmd->count = cpu_to_le32(count * 512);
+	readcmd->count = cpu_to_le32(count * dev->fsa_dev[scmd_id(cmd)].block_size);
 
 	ret = aac_build_sg(cmd, &readcmd->sg);
 	if (ret < 0)
@@ -1104,37 +2408,40 @@ static int aac_write_raw_io(struct fib * fib, struct scsi_cmnd * cmd, u64 lba, u
 		memset(writecmd2, 0, sizeof(struct aac_raw_io2));
 		writecmd2->blockLow = cpu_to_le32((u32)(lba&0xffffffff));
 		writecmd2->blockHigh = cpu_to_le32((u32)((lba&0xffffffff00000000LL)>>32));
-		writecmd2->byteCount = cpu_to_le32(count<<9);
+		writecmd2->byteCount = cpu_to_le32(count * dev->fsa_dev[scmd_id(cmd)].block_size);
 		writecmd2->cid = cpu_to_le16(scmd_id(cmd));
 		writecmd2->flags = (fua && ((aac_cache & 5) != 1) &&
 						   (((aac_cache & 5) != 5) || !fib->dev->cache_protected)) ?
 			cpu_to_le16(RIO2_IO_TYPE_WRITE|RIO2_IO_SUREWRITE) :
 			cpu_to_le16(RIO2_IO_TYPE_WRITE);
-		ret = aac_build_sgraw2(cmd, writecmd2,
-				dev->scsi_host_ptr->sg_tablesize);
+		ret = aac_build_sgraw2(cmd, writecmd2, dev->scsi_host_ptr->sg_tablesize);
 		if (ret < 0)
 			return ret;
 		command = ContainerRawIo2;
-		fibsize = sizeof(struct aac_raw_io2) +
+		fibsize = sizeof(struct aac_raw_io2) + 
 			((le32_to_cpu(writecmd2->sgeCnt)-1) * sizeof(struct sge_ieee1212));
 	} else {
 		struct aac_raw_io *writecmd;
 		writecmd = (struct aac_raw_io *) fib_data(fib);
 		writecmd->block[0] = cpu_to_le32((u32)(lba&0xffffffff));
 		writecmd->block[1] = cpu_to_le32((u32)((lba&0xffffffff00000000LL)>>32));
-		writecmd->count = cpu_to_le32(count<<9);
+		writecmd->count = cpu_to_le32(count * dev->fsa_dev[scmd_id(cmd)].block_size);
 		writecmd->cid = cpu_to_le16(scmd_id(cmd));
+#if (defined(RIO_SUREWRITE))
 		writecmd->flags = (fua && ((aac_cache & 5) != 1) &&
 						   (((aac_cache & 5) != 5) || !fib->dev->cache_protected)) ?
 			cpu_to_le16(RIO_TYPE_WRITE|RIO_SUREWRITE) :
 			cpu_to_le16(RIO_TYPE_WRITE);
+#else
+		writecmd->flags = cpu_to_le16(RIO_TYPE_WRITE);
+#endif
 		writecmd->bpTotal = 0;
 		writecmd->bpComplete = 0;
 		ret = aac_build_sgraw(cmd, &writecmd->sg);
 		if (ret < 0)
 			return ret;
 		command = ContainerRawIo;
-		fibsize = sizeof(struct aac_raw_io) +
+		fibsize = sizeof(struct aac_raw_io) + 
 			((le32_to_cpu(writecmd->sg.count)-1) * sizeof (struct sgentryraw));
 	}
 
@@ -1190,6 +2497,7 @@ static int aac_write_block(struct fib * fib, struct scsi_cmnd * cmd, u64 lba, u3
 {
 	u16 fibsize;
 	struct aac_write *writecmd;
+	struct aac_dev *dev = fib->dev;
 	long ret;
 
 	aac_fib_init(fib);
@@ -1197,7 +2505,7 @@ static int aac_write_block(struct fib * fib, struct scsi_cmnd * cmd, u64 lba, u3
 	writecmd->command = cpu_to_le32(VM_CtBlockWrite);
 	writecmd->cid = cpu_to_le32(scmd_id(cmd));
 	writecmd->block = cpu_to_le32((u32)(lba&0xffffffff));
-	writecmd->count = cpu_to_le32(count * 512);
+	writecmd->count = cpu_to_le32(count * dev->fsa_dev[scmd_id(cmd)].block_size);
 	writecmd->sg.count = cpu_to_le32(1);
 	/* ->stable is not used - it did mean which type of write */
 
@@ -1250,7 +2558,11 @@ static struct aac_srb * aac_scsi_common(struct fib * fib, struct scsi_cmnd * cmd
 	srbcmd->id       = cpu_to_le32(scmd_id(cmd));
 	srbcmd->lun      = cpu_to_le32(cmd->device->lun);
 	srbcmd->flags    = cpu_to_le32(flag);
+#if (1 && LINUX_VERSION_CODE < KERNEL_VERSION(2,6,27))
+	timeout = cmd->timeout_per_command/HZ;
+#else
 	timeout = cmd->request->timeout/HZ;
+#endif
 	if (timeout == 0)
 		timeout = 1;
 	srbcmd->timeout  = cpu_to_le32(timeout);  // timeout in seconds
@@ -1259,6 +2571,51 @@ static struct aac_srb * aac_scsi_common(struct fib * fib, struct scsi_cmnd * cmd
 	return srbcmd;
 }
 
+static struct aac_hba_cmd_req * aac_construct_hbacmd(struct fib * fib, struct scsi_cmnd * cmd)
+{
+	struct aac_hba_cmd_req * hbacmd;
+	struct aac_dev *dev;
+	int bus, target;
+	u64 address;
+
+	dev = (struct aac_dev *)cmd->device->host->hostdata;
+
+	hbacmd = (struct aac_hba_cmd_req *)fib->hw_fib_va;
+	memset(hbacmd, 0, 96);	/* sizeof(*hbacmd) is not necessary */
+	/* iu_type is a parameter of aac_hba_send */
+	switch (cmd->sc_data_direction) {
+	case DMA_TO_DEVICE:
+		hbacmd->byte1 = 2;
+		break;
+	case DMA_FROM_DEVICE:
+	case DMA_BIDIRECTIONAL:
+		hbacmd->byte1 = 1;
+		break;
+	case DMA_NONE:
+	default:
+		break;
+	}
+	hbacmd->lun[1] = cpu_to_le32(cmd->device->lun);
+
+	bus = aac_logical_to_phys(scmd_channel(cmd));
+	target = scmd_id(cmd);
+	hbacmd->it_nexus = dev->hba_map[bus][target].rmw_nexus;
+
+	/* we fill in reply_qid later in aac_src_deliver_message */
+	/* we fill in iu_type, request_id later in aac_hba_send */
+	/* we fill in emb_data_desc_count later in aac_build_sghba */
+	
+	memcpy(hbacmd->cdb, cmd->cmnd, cmd->cmd_len);
+	hbacmd->data_length = cpu_to_le32(scsi_bufflen(cmd));
+
+	address = (u64)fib->hw_error_pa;
+	hbacmd->error_ptr_hi = cpu_to_le32((u32)(address >> 32));
+	hbacmd->error_ptr_lo = cpu_to_le32((u32)(address & 0xffffffff));
+	hbacmd->error_length = cpu_to_le32(FW_ERROR_BUFFER_SIZE);
+
+	return hbacmd;
+}
+
 static void aac_srb_callback(void *context, struct fib * fibptr);
 
 static int aac_scsi_64(struct fib * fib, struct scsi_cmnd * cmd)
@@ -1267,7 +2624,7 @@ static int aac_scsi_64(struct fib * fib, struct scsi_cmnd * cmd)
 	struct aac_srb * srbcmd = aac_scsi_common(fib, cmd);
 	long ret;
 
-	ret = aac_build_sg64(cmd, (struct sgmap64 *) &srbcmd->sg);
+	ret = aac_build_sg64(cmd, (struct sgmap64*) &srbcmd->sg);
 	if (ret < 0)
 		return ret;
 	srbcmd->count = cpu_to_le32(scsi_bufflen(cmd));
@@ -1298,7 +2655,7 @@ static int aac_scsi_32(struct fib * fib, struct scsi_cmnd * cmd)
 	struct aac_srb * srbcmd = aac_scsi_common(fib, cmd);
 	long ret;
 
-	ret = aac_build_sg(cmd, (struct sgmap *)&srbcmd->sg);
+	ret = aac_build_sg(cmd, (struct sgmap*)&srbcmd->sg);
 	if (ret < 0)
 		return ret;
 	srbcmd->count = cpu_to_le32(scsi_bufflen(cmd));
@@ -1329,14 +2686,51 @@ static int aac_scsi_32_64(struct fib * fib, struct scsi_cmnd * cmd)
 	return aac_scsi_32(fib, cmd);
 }
 
+void aac_hba_callback(void *context, struct fib * fibptr);
+
+static int aac_adapter_hba(struct fib * fib, struct scsi_cmnd * cmd)
+{
+	struct aac_hba_cmd_req * hbacmd = aac_construct_hbacmd(fib, cmd);
+	struct aac_dev *dev;
+	// u16 fibsize;
+	long ret;
+
+	dev = (struct aac_dev *)cmd->device->host->hostdata;
+
+	ret = aac_build_sghba(cmd, hbacmd, 
+		dev->scsi_host_ptr->sg_tablesize, (u64)fib->hw_sgl_pa);
+	if (ret < 0)
+		return ret;
+
+	/*
+	 *	Now send the HBA command to the adapter
+	 */
+	fib->hbacmd_size = 64 + le32_to_cpu(hbacmd->emb_data_desc_count) *
+		sizeof(struct aac_hba_sgl);
+
+	return aac_hba_send(HBA_IU_TYPE_SCSI_CMD_REQ, fib,
+				  (fib_callback) aac_hba_callback,
+				  (void *) cmd);
+}
+
 int aac_get_adapter_info(struct aac_dev* dev)
 {
 	struct fib* fibptr;
-	int rcode;
-	u32 tmp;
+	int rcode, native_mode, is_StreamLinedFIB;
+	u32 tmp, i, bus, target;
 	struct aac_adapter_info *info;
 	struct aac_bus_info *command;
 	struct aac_bus_info_response *bus_info;
+	struct aac_dyn_adap_props *adap_props;
+	struct aac_container_cmd *ccmd;
+	struct aac_container_resp *cresp;
+	struct aac_phydev_list_resp *pdev_list;
+	struct aac_phydev_info_resp *pdev_info;
+	u32 pdev_list_size, cnt_id, cnt_offset, cnt_left;
+	unsigned long ct_pkt_size, fib_data_size;
+
+
+	native_mode = is_StreamLinedFIB = 0;
 
 	if (!(fibptr = aac_fib_alloc(dev)))
 		return -ENOMEM;
@@ -1345,6 +2739,7 @@ int aac_get_adapter_info(struct aac_dev* dev)
 	info = (struct aac_adapter_info *) fib_data(fibptr);
 	memset(info,0,sizeof(*info));
 
+	dev->streamlined_fib_support = 0;
 	rcode = aac_fib_send(RequestAdapterInfo,
 			 fibptr,
 			 sizeof(*info),
@@ -1383,25 +2778,88 @@ int aac_get_adapter_info(struct aac_dev* dev)
 
 		if (rcode >= 0)
 			memcpy(&dev->supplement_adapter_info, sinfo, sizeof(*sinfo));
+
 		if (rcode == -ERESTARTSYS) {
 			fibptr = aac_fib_alloc(dev);
 			if (!fibptr)
 				return -ENOMEM;
 		}
-
+#if (defined(AAC_DEBUG_INSTRUMENT_SLOT))
+		if ((le32_to_cpu(dev->supplement_adapter_info.Version)
+		      < AAC_SIS_VERSION_V3) ||
+		    (dev->supplement_adapter_info.SlotNumber
+		      == cpu_to_le32(AAC_SIS_SLOT_UNKNOWN))) {
+			dev->supplement_adapter_info.SlotNumber
+			  = cpu_to_le32(PCI_SLOT(dev->pdev->devfn));
+			(void)aac_adapter_sync_cmd(dev, SEND_SLOT_NUMBER,
+			  PCI_SLOT(dev->pdev->devfn),
+			  0, 0, 0, 0, 0, NULL, NULL, NULL, NULL, NULL);
+#endif
 	}
+	if (dev->supplement_adapter_info.FeatureBits & AAC_FEATURE_STREAMLINED_CONTINUATION)
+		dev->streamlined_fib_support = 1;
+
+	if (dev->adapter_info.options & AAC_OPT_2K_FIB_SUPPORT)
+		dev->fib_size_supported = FIB_SIZE_2K;
+	else
+		dev->fib_size_supported = FIB_SIZE_STANDARD;
+
+#if (defined(CODE_STREAM_IDENTIFIER) && !defined(CONFIG_COMMUNITY_KERNEL))
+	if (dev->supplement_adapter_info.FeatureBits & AAC_FEATURE_FALCON) {
+		char * finfo;
+
+		aac_fib_init(fibptr);
+
+		finfo = (char *) fib_data(fibptr);
+
+		memset(finfo,0,MAX_CODE_STREAM_IDENTIFIER_LENGTH);
+
+		rcode = aac_fib_send(RequestCompatibilityId,
+			fibptr,
+			MAX_CODE_STREAM_IDENTIFIER_LENGTH,
+			FsaNormal,
+			1, 1,
+			NULL,
+			NULL);
 
+		if (rcode >= 0)
+			memcpy(dev->code_stream_identifier, finfo,
+			  MAX_CODE_STREAM_IDENTIFIER_LENGTH);
+
+		if (dev->code_stream_identifier[0]
+		 && strncmp(CODE_STREAM_IDENTIFIER,
+		  dev->code_stream_identifier,
+		  MAX_CODE_STREAM_IDENTIFIER_LENGTH)) {
+			extern char aac_driver_version[];
+			printk(KERN_INFO
+			  "%s%d: Warning ! ! ! Compatibility Mismatch\n",
+			  dev->name, dev->id);
+			tmp = le32_to_cpu(dev->adapter_info.kernelrev);
+			printk(KERN_INFO
+			  "%s%d: Firmware=%d.%d-%d[%d], Device Driver=%s\n",
+			  dev->name, dev->id,
+			  tmp>>24,(tmp>>16)&0xff,tmp&0xff,
+			  le32_to_cpu(dev->adapter_info.kernelbuild),
+			  aac_driver_version);
+			printk(KERN_INFO
+			  "%s%d: These should be a tested set to avoid possible compatibility problems.\n",
+			  dev->name, dev->id);
+		}
+	}
+#endif
+	
+	/* reset all previous mapped devices (i.e. for init. after IOP_RESET) */
+	for (bus = 0; bus < AAC_MAX_NATIVE_BUSES; bus++)
+		for (target = 0; target < AAC_MAX_NATIVE_TARGETS; target++)
+			dev->hba_map[bus][target].devtype = 0;
 
 	/*
 	 * GetBusInfo
 	 */
-
 	aac_fib_init(fibptr);
 
 	bus_info = (struct aac_bus_info_response *) fib_data(fibptr);
-
 	memset(bus_info, 0, sizeof(*bus_info));
-
 	command = (struct aac_bus_info *)bus_info;
 
 	command->Command = cpu_to_le32(VM_Ioctl);
@@ -1422,6 +2880,224 @@ int aac_get_adapter_info(struct aac_dev* dev)
 		dev->maximum_num_physicals = le32_to_cpu(bus_info->TargetsPerBus);
 		dev->maximum_num_channels = le32_to_cpu(bus_info->BusCount);
 	}
+	
+	if (!dev->sync_mode && 
+		(dev->adapter_info.options & AAC_OPT_NATIVE_HBA)) {
+		/* Firmware supports Smart HBA */
+		if (dev->maximum_num_physicals < AAC_MAX_NATIVE_TARGETS)
+			dev->maximum_num_physicals = AAC_MAX_NATIVE_TARGETS;
+		if (dev->maximum_num_channels < AAC_MAX_NATIVE_BUSES)
+			dev->maximum_num_channels = AAC_MAX_NATIVE_BUSES;
+
+		/*
+		 * VM_GetDynAdapProps 
+		 */
+		aac_fib_init(fibptr);
+		adap_props = (struct aac_dyn_adap_props *) fib_data(fibptr);
+		memset(adap_props, 0, sizeof(*adap_props));
+		adap_props->vmCommand = cpu_to_le32(VM_GetDynAdapProps);
+
+		rcode = aac_fib_send(ContainerCommand,
+				 fibptr,
+				 sizeof (*adap_props),
+				 FsaNormal,
+				 1, 1,
+				 NULL, NULL);
+
+		if (rcode < 0 || 
+			!ARCIO_DYN_ADAP_PROPS_GET_VALID(adap_props, ARCIO_DYN_ADAP_CONTROLLER_FUNCTION_MODE_VALID))
+			goto native_fail;
+
+		/*
+		 * VM_SetDynAdapProps to activate Smart HBA 
+		 */
+		aac_fib_init(fibptr);
+		adap_props->vmCommand = cpu_to_le32(VM_SetDynAdapProps);
+		adap_props->fieldUsedForSet = ARCIO_DYN_ADAP_CONTROLLER_FUNCTION_MODE_VALID;
+		adap_props->data.ControllerFunctionMode = ARCIO_CONTROLLER_SMART_MODE;
+
+		rcode = aac_fib_send(ContainerCommand,
+				 fibptr,
+				 sizeof (*adap_props),
+				 FsaNormal,
+				 1, 1,
+				 NULL, NULL);
+
+		if (rcode < 0)
+			goto native_fail;
+		native_mode = 1;
+
+		/*
+		 * CT_GET_PHYDEV_LIST to scan drives 
+		 */
+		aac_fib_init(fibptr);
+		cresp = (struct aac_container_resp *) fib_data(fibptr);
+		memset(cresp, 0, sizeof(*cresp));
+		ccmd = (struct aac_container_cmd *)cresp;
+
+		ccmd->command = cpu_to_le32(VM_ContainerConfig);
+		ccmd->type = cpu_to_le32(CT_GET_PHYDEV_LIST);
+		pdev_list_size = sizeof(*pdev_list) + 
+			(AAC_MAX_NATIVE_TARGETS-1)*sizeof(u32);
+		ccmd->cnt_size = cpu_to_le32(pdev_list_size);
+		if (dev->streamlined_fib_support)
+			ccmd->cnt_size |= cpu_to_le32(STREAMLINED_CONTINUATION);
+		if (dev->fib_size_supported == 2048) {
+			fib_data_size = FIB_DATA_SIZE_IN_BYTES_VAR(FIB_SIZE_2K);
+			ct_pkt_size = CT_PACKET_SIZE_VAR_FIB(FIB_SIZE_2K);
+		} else {
+			fib_data_size = FIB_DATA_SIZE_IN_BYTES_VAR(FIB_SIZE_STANDARD);
+			ct_pkt_size = CT_PACKET_SIZE_VAR_FIB(FIB_SIZE_STANDARD);
+		}
+		rcode = aac_fib_send(ContainerCommand,
+				 fibptr,
+				 fib_data_size,
+				 FsaNormal,
+				 1, 1,
+				 NULL, NULL);
+
+		if (rcode < 0 || le32_to_cpu(cresp->response) != ST_OK)
+			goto native_fail;
+		cnt_id = le32_to_cpu(cresp->cnt_id);
+		cnt_offset = 0;
+		cnt_left = pdev_list_size;
+
+		pdev_list = kmalloc(pdev_list_size, GFP_KERNEL);
+		if (pdev_list == NULL)
+			goto native_fail;
+		pdev_list->numPhyDev = 0;
+
+		if ((le32_to_cpu(cresp->status) == CT_CONTINUATION_DATA) ||
+		    (le32_to_cpu(cresp->status) == CT_CONTINUATION_OK)) {
+			if (le32_to_cpu(cresp->status) == CT_CONTINUATION_OK) {
+				// stream Lined Fib
+				// Copy first packet
+				is_StreamLinedFIB = 1;
+				if (cnt_left > ct_pkt_size) {
+					memcpy((u8 *)pdev_list + cnt_offset *
+						ct_pkt_size, cresp->data, 
+						ct_pkt_size);
+					cnt_left -= ct_pkt_size;
+				} else {
+					memcpy((u8 *)pdev_list + cnt_offset *
+						ct_pkt_size, cresp->data, cnt_left);
+					cnt_left = 0;
+				}
+				cnt_offset++;
+			}
+			while (cnt_left) {
+				if (cnt_offset == 0 && le32_to_cpu(cresp->status) 
+					!= CT_CONTINUATION_DATA)
+					break; 	
+				aac_fib_init(fibptr);
+				memset(cresp, 0, sizeof(*cresp));
+				ccmd->command = cpu_to_le32(VM_ContainerConfig);
+				ccmd->type = cpu_to_le32(CT_CONTINUE_DATA);
+				ccmd->cnt_id = cpu_to_le32(cnt_id);
+				ccmd->cnt_offset = cpu_to_le32(cnt_offset);
+				if (dev->streamlined_fib_support)
+					ccmd->cnt_size |= cpu_to_le32(STREAMLINED_CONTINUATION);
+
+				rcode = aac_fib_send(ContainerCommand,
+					 	fibptr,
+					 	fib_data_size,
+					 	FsaNormal,
+					 	1, 1,
+					 	NULL, NULL);
+
+				if (rcode < 0 || le32_to_cpu(cresp->response) != ST_OK
+			 	|| le32_to_cpu(cresp->status) != CT_CONTINUATION_OK)
+					break;
+
+				if (cnt_left < ct_pkt_size) {
+					memcpy((u8 *)pdev_list + cnt_offset *
+						ct_pkt_size, cresp->data, cnt_left);
+					cnt_left = 0;
+				} else {
+					memcpy((u8 *)pdev_list + cnt_offset *
+						ct_pkt_size, cresp->data, 
+						ct_pkt_size);
+					cnt_left -= ct_pkt_size;
+				}
+				cnt_id = le32_to_cpu(cresp->cnt_id);
+				cnt_offset++;
+			}
+		}
+
+		if (!is_StreamLinedFIB) {
+			aac_fib_init(fibptr);
+			memset(cresp, 0, sizeof(*cresp));
+			ccmd->command = cpu_to_le32(VM_ContainerConfig);
+			ccmd->type = cpu_to_le32(CT_STOP_DATA);
+			if (dev->streamlined_fib_support)
+				ccmd->cnt_size |= cpu_to_le32(STREAMLINED_CONTINUATION);
+			rcode = aac_fib_send(ContainerCommand,
+				 	fibptr,
+				 	fib_data_size,
+				 	FsaNormal,
+				 	1, 1,
+				 	NULL, NULL);
+
+		}
+		/*
+		 * CT_GET_PHYDEV_INFO to read information about drives 
+		 */
+		for (i = 0; i < le32_to_cpu(pdev_list->numPhyDev); ++i) {
+			aac_fib_init(fibptr);
+			memset(cresp, 0, sizeof(*cresp));
+			ccmd->command = cpu_to_le32(VM_ContainerConfig);
+			ccmd->type = cpu_to_le32(CT_GET_PHYDEV_INFO);
+			ccmd->handle = pdev_list->phyDev[i];
+			ccmd->cnt_size = cpu_to_le32(sizeof(struct aac_phydev_info_resp));
+			if (dev->streamlined_fib_support)
+				ccmd->cnt_size |= cpu_to_le32(STREAMLINED_CONTINUATION);
+
+			rcode = aac_fib_send(ContainerCommand,
+				 fibptr,
+				 fib_data_size,
+				 FsaNormal,
+				 1, 1,
+				 NULL, NULL);
+
+			if (dev->streamlined_fib_support && (rcode < 0 || le32_to_cpu(cresp->response) != ST_OK
+				|| (le32_to_cpu(cresp->status) != CT_CONTINUATION_STOP_OK)))
+				break;
+			else if (!dev->streamlined_fib_support && (rcode < 0 || le32_to_cpu(cresp->response) != ST_OK))
+				break;
+
+			/* map the devices */
+			pdev_info = (struct aac_phydev_info_resp *)cresp->data;
+			bus = le32_to_cpu(pdev_info->bus);
+			target = le32_to_cpu(pdev_info->target);
+			if (bus >= AAC_MAX_NATIVE_BUSES-1 || 
+				target >= AAC_MAX_NATIVE_TARGETS)
+				continue;
+
+			dev->hba_map[bus][target].reset_state = 0;	
+			if (le32_to_cpu(pdev_info->bFsaInitialized))
+				dev->hba_map[bus][target].devtype =	
+					AAC_DEVTYPE_RAID_MEMBER;
+			else if (!le32_to_cpu(pdev_info->bNativeHbaEnabled))
+				dev->hba_map[bus][target].devtype =
+					AAC_DEVTYPE_ARC_RAW;
+			else {
+				dev->hba_map[AAC_SMART_HBA_NATIVE_BUS][target].devtype =
+					AAC_DEVTYPE_NATIVE_RAW;
+				dev->hba_map[AAC_SMART_HBA_NATIVE_BUS][target].rmw_nexus =
+				 *(__le32 *)pdev_info->sasPhy[0].it_nexus;
+				if (*(__le32 *)pdev_info->sasPhy[1].it_nexus
+					!= 0xffffffff) {
+					/* dual ported */
+					dev->hba_map[AAC_DUAL_PORT_NATIVE_BUS][target].devtype =
+						AAC_DEVTYPE_NATIVE_RAW;
+					dev->hba_map[AAC_DUAL_PORT_NATIVE_BUS][target].rmw_nexus =
+						*(__le32 *)pdev_info->sasPhy[1].it_nexus;
+				}
+			}
+		}
+		kfree(pdev_list);
+	}
+native_fail:
 
 	if (!dev->in_reset) {
 		char buffer[16];
@@ -1435,34 +3111,181 @@ int aac_get_adapter_info(struct aac_dev* dev)
 			le32_to_cpu(dev->adapter_info.kernelbuild),
 			(int)sizeof(dev->supplement_adapter_info.BuildDate),
 			dev->supplement_adapter_info.BuildDate);
+#if (0 && defined(BOOTCD))
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "%s%d: kernel %d.%d-%d[%d] %.*s",
+		  dev->name, dev->id,
+		  tmp>>24, (tmp>>16)&0xff, tmp&0xff,
+		  le32_to_cpu(dev->adapter_info.kernelbuild),
+		  (int)sizeof(dev->supplement_adapter_info.BuildDate),
+		  dev->supplement_adapter_info.BuildDate));
+#endif
 		tmp = le32_to_cpu(dev->adapter_info.monitorrev);
 		printk(KERN_INFO "%s%d: monitor %d.%d-%d[%d]\n",
 			dev->name, dev->id,
 			tmp>>24,(tmp>>16)&0xff,tmp&0xff,
 			le32_to_cpu(dev->adapter_info.monitorbuild));
+#if (0 && defined(BOOTCD))
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "%s%d: monitor %d.%d-%d[%d]",
+		  dev->name, dev->id, tmp>>24,(tmp>>16)&0xff,tmp&0xff,
+		  le32_to_cpu(dev->adapter_info.monitorbuild)));
+#endif
 		tmp = le32_to_cpu(dev->adapter_info.biosrev);
 		printk(KERN_INFO "%s%d: bios %d.%d-%d[%d]\n",
 			dev->name, dev->id,
 			tmp>>24,(tmp>>16)&0xff,tmp&0xff,
 			le32_to_cpu(dev->adapter_info.biosbuild));
+#if (0 && defined(BOOTCD))
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "%s%d: bios %d.%d-%d[%d]",
+		  dev->name, dev->id,
+		  tmp>>24,(tmp>>16)&0xff,tmp&0xff,
+		  le32_to_cpu(dev->adapter_info.biosbuild)));
+#endif
 		buffer[0] = '\0';
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+		if (aac_show_serial_number(
+		  shost_to_class(dev->scsi_host_ptr), buffer))
+#else
 		if (aac_get_serial_number(
 		  shost_to_class(dev->scsi_host_ptr), buffer))
+#endif
+#if (0 && defined(BOOTCD))
+		{
+#endif
 			printk(KERN_INFO "%s%d: serial %s",
 			  dev->name, dev->id, buffer);
+#if (0 && defined(BOOTCD))
+			if (nblank(fwprintf(x))) {
+				char * cp = strchr(buffer, '\n');
+				if (cp)
+					*cp = '\0';
+				fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+				  "%s%d: serial %s",
+				  dev->name, dev->id, buffer));
+			}
+		}
+#endif
 		if (dev->supplement_adapter_info.VpdInfo.Tsid[0]) {
 			printk(KERN_INFO "%s%d: TSID %.*s\n",
 			  dev->name, dev->id,
 			  (int)sizeof(dev->supplement_adapter_info.VpdInfo.Tsid),
 			  dev->supplement_adapter_info.VpdInfo.Tsid);
+#if (0 && defined(BOOTCD))
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  "%s%d: TSID %.*s",
+			  dev->name, dev->id,
+			  (int)sizeof(dev->supplement_adapter_info.VpdInfo.Tsid),
+			  dev->supplement_adapter_info.VpdInfo.Tsid));
+#endif
 		}
 		if (!aac_check_reset || ((aac_check_reset == 1) &&
 		  (dev->supplement_adapter_info.SupportedOptions2 &
 		  AAC_OPTION_IGNORE_RESET))) {
 			printk(KERN_INFO "%s%d: Reset Adapter Ignored\n",
 			  dev->name, dev->id);
+#if (0 && defined(BOOTCD))
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  "%s%d: Reset Adapter Ignored",
+			  dev->name, dev->id));
+#endif
+		}
+	}
+#if (!defined(CONFIG_COMMUNITY_KERNEL) && !defined(__VMKLNX30__) && !defined(__VMKLNX__) && ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || !defined(HAS_BOOT_CONFIG)))
+#if (((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)) && !defined(HAS_KZALLOC)) || !defined(MODULE))
+	aacraid = kmalloc(COMMAND_LINE_SIZE, GFP_KERNEL);
+#else
+	aacraid = kzalloc(COMMAND_LINE_SIZE, GFP_KERNEL);
+#endif
+	if (aacraid) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+#if (defined(MODULE))
+		extern struct proc_dir_entry proc_root;
+		struct proc_dir_entry * entry;
+
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)) && !defined(HAS_KZALLOC))
+		memset(aacraid, 0, COMMAND_LINE_SIZE);
+#endif
+		for (entry = proc_root.subdir;
+		  entry != (struct proc_dir_entry *)NULL;
+		  entry = entry->next) {
+#if (defined(AAC_DEBUG_INSTRUMENT_SETUP))
+			printk("\"%.*s\"[%d]=%x ", entry->namelen,
+			  entry->name, entry->namelen, entry->low_ino);
+#endif
+			if ((entry->low_ino != 0)
+			 && (entry->namelen == 7)
+			 && (memcmp ("cmdline", entry->name, 7) == 0)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_SETUP))
+				printk("%p->read_proc=%p ", entry, entry->read_proc);
+#endif
+				if (entry->read_proc != (int (*)(char *, char **, off_t, int, int *, void *))NULL) {
+					char * start = aacraid;
+					int eof;
+					mm_segment_t fs;
+
+					fs = get_fs();
+					set_fs(get_ds());
+					lock_kernel();
+					entry->read_proc(aacraid, &start,
+					  (off_t)0, COMMAND_LINE_SIZE-1, &eof,
+					  NULL);
+					unlock_kernel();
+					set_fs(fs);
+#if (defined(AAC_DEBUG_INSTRUMENT_SETUP))
+					printk(KERN_INFO
+					  "cat /proc/cmdline -> \"%s\"\n",
+					  aacraid);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SETUP) || defined(BOOTCD))
+					fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+					  "cat /proc/cmdline -> \"%s\"",
+					  aacraid));
+#endif
+				}
+				break;
+			}
 		}
+#else
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,20))
+		extern char *saved_command_line;
+#else
+		extern char saved_command_line[];
+#endif
+		memcpy(aacraid, saved_command_line, COMMAND_LINE_SIZE);
+#endif
+#endif
 	}
+	if (aacraid && aacraid[0])
+		aacraid_setup(aacraid);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SETUP))
+#if (defined(AAC_EXTENDED_TIMEOUT))
+	printk(KERN_INFO "nondasd=%d dacmode=%d commit=%d "
+	  "coalescethreshold=%d acbsize=%d extendedtimeout=%d\n",
+	  nondasd, dacmode, aac_commit, coalescethreshold, acbsize,
+	  extendedtimeout);
+#else
+	printk(KERN_INFO "nondasd=%d dacmode=%d commit=%d "
+	  "coalescethreshold=%d acbsize=%d\n",
+	  nondasd, dacmode, aac_commit, coalescethreshold, acbsize);
+#endif
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SETUP) || (0 && defined(BOOTCD)))
+#if (defined(AAC_EXTENDED_TIMEOUT))
+	fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  "nondasd=%d dacmode=%d commit=%d "
+	  "coalescethreshold=%d acbsize=%d extendedtimeout=%d",
+	  nondasd, dacmode, aac_commit, coalescethreshold, acbsize,
+	  extendedtimeout));
+#else
+	fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  "nondasd=%d dacmode=%d commit=%d "
+	  "coalescethreshold=%d acbsize=%d",
+	  nondasd, dacmode, aac_commit, coalescethreshold, acbsize));
+#endif
+#endif
 
 	dev->cache_protected = 0;
 	dev->jbod = ((dev->supplement_adapter_info.FeatureBits &
@@ -1491,24 +3314,57 @@ int aac_get_adapter_info(struct aac_dev* dev)
 	if (dev->raid_scsi_mode != 0)
 		printk(KERN_INFO "%s%d: ROMB RAID/SCSI mode enabled\n",
 				dev->name, dev->id);
-
 	if (nondasd != -1)
 		dev->nondasd_support = (nondasd!=0);
 	if (dev->nondasd_support && !dev->in_reset)
+#if (0 && defined(BOOTCD))
+	{
+#endif
 		printk(KERN_INFO "%s%d: Non-DASD support enabled.\n",dev->name, dev->id);
+#if (0 && defined(BOOTCD))
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "%s%d: Non-DASD support enabled.",dev->name, dev->id));
+	}
+#endif
 
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,7)) && !defined(__VMKLNX__))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0))
+	if (dma_get_required_mask(&dev->pdev->dev) > DMA_32BIT_MASK)
+#else
 	if (dma_get_required_mask(&dev->pdev->dev) > DMA_BIT_MASK(32))
+#endif
+#else
+	if (num_physpages > (0xFFFFFFFFULL >> PAGE_SHIFT))
+#endif
 		dev->needs_dac = 1;
 	dev->dac_support = 0;
+#if (defined(CONFIG_COMMUNITY_KERNEL))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,7))
 	if ((sizeof(dma_addr_t) > 4) && dev->needs_dac &&
 	    (dev->adapter_info.options & AAC_OPT_SGMAP_HOST64)) {
+#else
+	if( (sizeof(dma_addr_t) > 4) && (dev->adapter_info.options & AAC_OPT_SGMAP_HOST64)){
+#endif
 		if (!dev->in_reset)
 			printk(KERN_INFO "%s%d: 64bit support enabled.\n",
 				dev->name, dev->id);
-		dev->dac_support = 1;
-	}
-
-	if(dacmode != -1) {
+#else
+	/*
+	 *	Only enable DAC mode if the dma_addr_t is larger than 32
+	 * bit addressing, and we have more than 32 bit addressing worth of
+	 * memory and if the controller supports 64 bit scatter gather elements.
+	 */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,7))
+	if ((sizeof(dma_addr_t) > 4) && dev->needs_dac &&
+	    (dev->adapter_info.options & AAC_OPT_SGMAP_HOST64)) {
+#else
+	if( (sizeof(dma_addr_t) > 4) && (num_physpages > (0xFFFFFFFFULL >> PAGE_SHIFT)) && (dev->adapter_info.options & AAC_OPT_SGMAP_HOST64)){
+#endif
+#endif
+		dev->dac_support = 1;
+	}
+
+	if(dacmode != -1) {
 		dev->dac_support = (dacmode!=0);
 	}
 
@@ -1521,19 +3377,44 @@ int aac_get_adapter_info(struct aac_dev* dev)
 	}
 
 	if(dev->dac_support != 0) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0))
+		if (!pci_set_dma_mask(dev->pdev, DMA_64BIT_MASK) &&
+			!pci_set_consistent_dma_mask(dev->pdev, DMA_64BIT_MASK)) {
+#else
 		if (!pci_set_dma_mask(dev->pdev, DMA_BIT_MASK(64)) &&
 			!pci_set_consistent_dma_mask(dev->pdev, DMA_BIT_MASK(64))) {
+#endif
 			if (!dev->in_reset)
 				printk(KERN_INFO"%s%d: 64 Bit DAC enabled\n",
 					dev->name, dev->id);
+#if (0 && defined(BOOTCD))
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  "%s%d: 64 Bit DAC enabled",
+			  dev->name, dev->id));
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0))
+		} else if (!pci_set_dma_mask(dev->pdev, DMA_32BIT_MASK) &&
+			!pci_set_consistent_dma_mask(dev->pdev, DMA_32BIT_MASK)) {
+#else
 		} else if (!pci_set_dma_mask(dev->pdev, DMA_BIT_MASK(32)) &&
 			!pci_set_consistent_dma_mask(dev->pdev, DMA_BIT_MASK(32))) {
+#endif
 			printk(KERN_INFO"%s%d: DMA mask set failed, 64 Bit DAC disabled\n",
 				dev->name, dev->id);
+#if (0 && defined(BOOTCD))
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  "%s%d: DMA mask set failed, 64 Bit DAC disabled",
+			  dev->name, dev->id));
+#endif
 			dev->dac_support = 0;
 		} else {
 			printk(KERN_WARNING"%s%d: No suitable DMA available.\n",
 				dev->name, dev->id);
+#if (0 && defined(BOOTCD))
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  "%s%d: No suitable DMA available.",
+			  dev->name, dev->id));
+#endif
 			rcode = -ENOMEM;
 		}
 	}
@@ -1541,6 +3422,16 @@ int aac_get_adapter_info(struct aac_dev* dev)
 	 * Deal with configuring for the individualized limits of each packet
 	 * interface.
 	 */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)) && (!defined(__arm__)) && defined(CONFIG_HIGHMEM) && ((LINUX_VERSION_CODE != KERNEL_VERSION(2,4,19)) || defined(CONFIG_HIGHIO))
+	dev->scsi_host_ptr->highmem_io = 1;
+#endif
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	// WRONG PLACE FOR THIS CHECK TODAY? BUT WE WILL SURVIVE. MGS
+	if (dev->comm_interface == AAC_COMM_APRE)
+		dev->a_ops.adapter_scsi_cmd = aac_scsi_cmd_apre;
+	else {
+		dev->a_ops.adapter_scsi_cmd = aac_scsi_cmd;
+#endif
 	dev->a_ops.adapter_scsi = (dev->dac_support)
 	  ? ((aac_get_driver_ident(dev->cardtype)->quirks & AAC_QUIRK_SCSI_32)
 				? aac_scsi_32_64
@@ -1573,6 +3464,9 @@ int aac_get_adapter_info(struct aac_dev* dev)
 		} else {
 			dev->a_ops.adapter_read = aac_read_block;
 			dev->a_ops.adapter_write = aac_write_block;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)) && (!defined(__arm__)) && defined(CONFIG_HIGHMEM) && ((LINUX_VERSION_CODE != KERNEL_VERSION(2,4,19)) || defined(CONFIG_HIGHIO))
+			dev->scsi_host_ptr->highmem_io = 0;
+#endif
 		}
 		dev->scsi_host_ptr->max_sectors = AAC_MAX_32BIT_SGBCOUNT;
 		if (!(dev->adapter_info.options & AAC_OPT_NEW_COMM)) {
@@ -1589,6 +3483,15 @@ int aac_get_adapter_info(struct aac_dev* dev)
 			  (dev->scsi_host_ptr->sg_tablesize * 8) + 112;
 		}
 	}
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	}
+#endif
+
+	if (native_mode && 
+		dev->scsi_host_ptr->sg_tablesize > HBA_MAX_SG_SEPARATE)
+		dev->scsi_host_ptr->sg_tablesize = dev->sg_tablesize =
+			HBA_MAX_SG_SEPARATE;
+
 	/* FIB should be freed only after getting the response from the F/W */
 	if (rcode != -ERESTARTSYS) {
 		aac_fib_complete(fibptr);
@@ -1622,6 +3525,7 @@ static void io_callback(void *context, struct fib * fibptr)
 			lba = ((scsicmd->cmnd[1] & 0x1F) << 16) |
 			    (scsicmd->cmnd[2] << 8) | scsicmd->cmnd[3];
 			break;
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(WRITE_16))
 		case WRITE_16:
 		case READ_16:
 			lba = ((u64)scsicmd->cmnd[2] << 56) |
@@ -1632,6 +3536,7 @@ static void io_callback(void *context, struct fib * fibptr)
 			      (scsicmd->cmnd[7] << 16) |
 			      (scsicmd->cmnd[8] << 8) | scsicmd->cmnd[9];
 			break;
+#endif
 		case WRITE_12:
 		case READ_12:
 			lba = ((u64)scsicmd->cmnd[2] << 24) |
@@ -1651,8 +3556,20 @@ static void io_callback(void *context, struct fib * fibptr)
 
 	BUG_ON(fibptr == NULL);
 
+#if (!defined(__VMKLNX30__) || defined(__x86_64__))
 	scsi_dma_unmap(scsicmd);
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+	if(!scsi_sg_count(scsicmd) && scsi_bufflen(scsicmd))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		pci_unmap_single(dev->pdev, (dma_addr_t)scsicmd->SCp.dma_handle,
+#else
+		pci_unmap_single(dev->pdev, scsicmd->SCp.dma_handle,
+#endif
+				 scsicmd->request_bufflen,
+				 scsicmd->sc_data_direction);
+#endif
 
+#endif
 	readreply = (struct aac_read_reply *)fib_data(fibptr);
 	switch (le32_to_cpu(readreply->status)) {
 	case ST_OK:
@@ -1687,8 +3604,122 @@ static void io_callback(void *context, struct fib * fibptr)
 	aac_fib_complete(fibptr);
 	aac_fib_free(fibptr);
 
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+	aac_io_done(scsicmd);
+#else
 	scsicmd->scsi_done(scsicmd);
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	if (scsicmd->device->device_blocked) {
+		struct scsi_cmnd * cmd;
+		cid = 0;
+
+		for (cmd = scsicmd->device->device_queue; cmd; cmd = cmd->next)
+			if (cmd->serial_number)
+				++cid;
+		if (cid < scsicmd->device->queue_depth)
+			scsicmd->device->device_blocked = 0;
+	}
+#endif
+}
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+
+static inline void aac_select_queue_depth(
+	struct scsi_cmnd * scsicmd,
+	u64 lba,
+	u32 count)
+{
+	struct scsi_device *device = scsicmd->device;
+	struct aac_dev *dev;
+	unsigned depth;
+	int cid;
+
+#if (1 || defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+	/*-
+		this routine is only used to try to back up
+		sequential IO into linux's scsi_merge layer
+		in an attempt to coalesce them.  vmkernel
+		doesn't do this, and in fact changing the
+		queue_depth like this seems to tickle a bug
+		in our scsi layer where we don't reschedule
+		the IOs in a timely fashion.
+			-gmccready@vmware.com
+	 */
+	return;
+#endif
+	if (coalescethreshold == 0)
+		return;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+	if (!device->tagged_supported)
+		return;
+#endif
+	if (
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,14)) || defined(SCSI_HAS_SHOST_STATE_ENUM))
+	  SHOST_RECOVERY == device->host->shost_state
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,14))
+	  test_bit(SHOST_RECOVERY, &device->host->shost_state)
+#elif (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+	  test_bit(SHOST_RECOVERY, &device->host->shost_state) ||
+	  device->host->eh_active
+#else
+	  device->host->in_recovery || device->host->eh_active
+#endif
+	)
+		return;
+	dev = (struct aac_dev *)device->host->hostdata;
+	cid = scmd_id(scsicmd);
+	if (dev->fsa_dev[cid].queue_depth <= 2)
+		dev->fsa_dev[cid].queue_depth = device->queue_depth;
+	if (lba == dev->fsa_dev[cid].last) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		struct scsi_cmnd * cmd;
+#endif
+		/*
+		 * If larger than coalescethreshold in size, coalescing has
+		 * less effect on overall performance.  Also, if we are
+		 * coalescing right now, leave it alone if above the threshold.
+		 */
+		if (count > coalescethreshold)
+			return;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		depth = 0;
+
+		for (cmd = device->device_queue; cmd; cmd = cmd->next)
+			if ((cmd->serial_number)
+			 && (cmd != scsicmd)
+			 && (++depth > 1)) {
+				device->device_blocked = 1;
+				break;
+			}
+#endif
+		depth = 2;
+	} else {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		device->device_blocked = 0;
+#endif
+		depth = dev->fsa_dev[cid].queue_depth;
+	}
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+	scsi_adjust_queue_depth(device, MSG_ORDERED_TAG, depth);
+#else
+	device->queue_depth = depth;
+#endif
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	dprintk((KERN_DEBUG "l=%llu %llu[%u] q=%u %lu\n",
+	  dev->fsa_dev[cid].last, lba, count, device->queue_depth,
+	  (unsigned long)(atomic_read(&dev->queues->queue[
+	    (dev->comm_interface == AAC_COMM_APRE)
+	      ? ApreCmdQueue
+	      : AdapNormCmdQueue
+	  ].numpending))));
+#else
+	dprintk((KERN_DEBUG "l=%llu %llu[%u] q=%u %lu\n",
+	  dev->fsa_dev[cid].last, lba, count, device->queue_depth,
+	  (unsigned long)(atomic_read(&dev->queues->queue[AdapNormCmdQueue].numpending))));
+#endif
+	dev->fsa_dev[cid].last = lba + count;
 }
+#endif
 
 static int aac_read(struct scsi_cmnd * scsicmd)
 {
@@ -1697,12 +3728,20 @@ static int aac_read(struct scsi_cmnd * scsicmd)
 	int status;
 	struct aac_dev *dev;
 	struct fib * cmd_fibcontext;
-	int cid;
 
 	dev = (struct aac_dev *)scsicmd->device->host->hostdata;
 	/*
 	 *	Get block address and transfer length
 	 */
+#if (defined(AAC_DEBUG_INSTRUMENT_IO))
+	printk(KERN_DEBUG "aac_read: %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x\n",
+	  scsicmd->cmnd[0],  scsicmd->cmnd[1],  scsicmd->cmnd[2],
+	  scsicmd->cmnd[3],  scsicmd->cmnd[4],  scsicmd->cmnd[5],
+	  scsicmd->cmnd[6],  scsicmd->cmnd[7],  scsicmd->cmnd[8],
+	  scsicmd->cmnd[9],  scsicmd->cmnd[10], scsicmd->cmnd[11],
+	  scsicmd->cmnd[12], scsicmd->cmnd[13], scsicmd->cmnd[14],
+	  scsicmd->cmnd[15]);
+#endif
 	switch (scsicmd->cmnd[0]) {
 	case READ_6:
 		dprintk((KERN_DEBUG "aachba: received a read(6) command on id %d.\n", scmd_id(scsicmd)));
@@ -1714,6 +3753,7 @@ static int aac_read(struct scsi_cmnd * scsicmd)
 		if (count == 0)
 			count = 256;
 		break;
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(READ_16))
 	case READ_16:
 		dprintk((KERN_DEBUG "aachba: received a read(16) command on id %d.\n", scmd_id(scsicmd)));
 
@@ -1728,6 +3768,7 @@ static int aac_read(struct scsi_cmnd * scsicmd)
 			(scsicmd->cmnd[11] << 16) |
 			(scsicmd->cmnd[12] << 8) | scsicmd->cmnd[13];
 		break;
+#endif
 	case READ_12:
 		dprintk((KERN_DEBUG "aachba: received a read(12) command on id %d.\n", scmd_id(scsicmd)));
 
@@ -1747,31 +3788,47 @@ static int aac_read(struct scsi_cmnd * scsicmd)
 		count = (scsicmd->cmnd[7] << 8) | scsicmd->cmnd[8];
 		break;
 	}
+/* ADPml11898 SUNMR Spitfire issue
+ * FW layer exposes lesser container capacity than the actual one
+ * It exposes [Actaul size - Spitfire space(10MB)] to the OS, IO's to the 10MB should be prohibhited from the Linux driver
+ * Sensekey sets to HARDWARE_ERROR and sending the notification to the MID layer
+ */
 
-	if ((lba + count) > (dev->fsa_dev[scmd_id(scsicmd)].size)) {
-		cid = scmd_id(scsicmd);
+if(expose_hidden_space <= 0) {
+	if((lba + count) > (dev->fsa_dev[scmd_id(scsicmd)].size)) {
+		int cid = scmd_id(scsicmd);
 		dprintk((KERN_DEBUG "aacraid: Illegal lba\n"));
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 |
 			SAM_STAT_CHECK_CONDITION;
 		set_sense(&dev->fsa_dev[cid].sense_data,
-			  HARDWARE_ERROR, SENCODE_INTERNAL_TARGET_FAILURE,
-			  ASENCODE_INTERNAL_TARGET_FAILURE, 0, 0);
+		  HARDWARE_ERROR, SENCODE_INTERNAL_TARGET_FAILURE,
+		  ASENCODE_INTERNAL_TARGET_FAILURE, 0, 0);
 		memcpy(scsicmd->sense_buffer, &dev->fsa_dev[cid].sense_data,
 		       min_t(size_t, sizeof(dev->fsa_dev[cid].sense_data),
 			     SCSI_SENSE_BUFFERSIZE));
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(scsicmd);
+#else
 		scsicmd->scsi_done(scsicmd);
+#endif
 		return 1;
 	}
+}
 
 	dprintk((KERN_DEBUG "aac_read[cpu %d]: lba = %llu, t = %ld.\n",
 	  smp_processor_id(), (unsigned long long)lba, jiffies));
 	if (aac_adapter_bounds(dev,scsicmd,lba))
 		return 0;
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+	/*
+	 *	Are we in a sequential mode?
+	 */
+	aac_select_queue_depth(scsicmd, lba, count);
+#endif
 	/*
 	 *	Alocate and initialize a Fib
 	 */
 	if (!(cmd_fibcontext = aac_fib_alloc(dev))) {
-		printk(KERN_WARNING "aac_read: fib allocation failed\n");
 		return -1;
 	}
 
@@ -1790,7 +3847,11 @@ static int aac_read(struct scsi_cmnd * scsicmd)
 	 *	For some reason, the Fib didn't queue, return QUEUE_FULL
 	 */
 	scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_TASK_SET_FULL;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+	aac_io_done(scsicmd);
+#else
 	scsicmd->scsi_done(scsicmd);
+#endif
 	aac_fib_complete(cmd_fibcontext);
 	aac_fib_free(cmd_fibcontext);
 	return 0;
@@ -1804,12 +3865,20 @@ static int aac_write(struct scsi_cmnd * scsicmd)
 	int status;
 	struct aac_dev *dev;
 	struct fib * cmd_fibcontext;
-	int cid;
 
 	dev = (struct aac_dev *)scsicmd->device->host->hostdata;
 	/*
 	 *	Get block address and transfer length
 	 */
+#if (defined(AAC_DEBUG_INSTRUMENT_IO))
+	printk(KERN_DEBUG "aac_write: %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x\n",
+	  scsicmd->cmnd[0],  scsicmd->cmnd[1],  scsicmd->cmnd[2],
+	  scsicmd->cmnd[3],  scsicmd->cmnd[4],  scsicmd->cmnd[5],
+	  scsicmd->cmnd[6],  scsicmd->cmnd[7],  scsicmd->cmnd[8],
+	  scsicmd->cmnd[9],  scsicmd->cmnd[10], scsicmd->cmnd[11],
+	  scsicmd->cmnd[12], scsicmd->cmnd[13], scsicmd->cmnd[14],
+	  scsicmd->cmnd[15]);
+#endif
 	if (scsicmd->cmnd[0] == WRITE_6)	/* 6 byte command */
 	{
 		lba = ((scsicmd->cmnd[1] & 0x1F) << 16) | (scsicmd->cmnd[2] << 8) | scsicmd->cmnd[3];
@@ -1817,6 +3886,7 @@ static int aac_write(struct scsi_cmnd * scsicmd)
 		if (count == 0)
 			count = 256;
 		fua = 0;
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(WRITE_16))
 	} else if (scsicmd->cmnd[0] == WRITE_16) { /* 16 byte command */
 		dprintk((KERN_DEBUG "aachba: received a write(16) command on id %d.\n", scmd_id(scsicmd)));
 
@@ -1830,6 +3900,7 @@ static int aac_write(struct scsi_cmnd * scsicmd)
 		count = (scsicmd->cmnd[10] << 24) | (scsicmd->cmnd[11] << 16) |
 			(scsicmd->cmnd[12] << 8) | scsicmd->cmnd[13];
 		fua = scsicmd->cmnd[1] & 0x8;
+#endif
 	} else if (scsicmd->cmnd[0] == WRITE_12) { /* 12 byte command */
 		dprintk((KERN_DEBUG "aachba: received a write(12) command on id %d.\n", scmd_id(scsicmd)));
 
@@ -1845,36 +3916,45 @@ static int aac_write(struct scsi_cmnd * scsicmd)
 		fua = scsicmd->cmnd[1] & 0x8;
 	}
 
-	if ((lba + count) > (dev->fsa_dev[scmd_id(scsicmd)].size)) {
-		cid = scmd_id(scsicmd);
+/* ADPml11898 SUNMR Spitfire issue
+ * FW layer exposes lesser container capacity than the actual one
+ * It exposes [Actaul size - Spitfire space(10MB)] to the OS, IO's to the 10MB should be prohibhited from the Linux driver
+ * Sensekey sets to HARDWARE_ERROR and sending the notification to the MID layer
+ */
+if(expose_hidden_space <= 0) {
+	if((lba + count) > (dev->fsa_dev[scmd_id(scsicmd)].size)) {
+		int cid = scmd_id(scsicmd);
 		dprintk((KERN_DEBUG "aacraid: Illegal lba\n"));
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 |
 			SAM_STAT_CHECK_CONDITION;
 		set_sense(&dev->fsa_dev[cid].sense_data,
-			  HARDWARE_ERROR, SENCODE_INTERNAL_TARGET_FAILURE,
-			  ASENCODE_INTERNAL_TARGET_FAILURE, 0, 0);
+		  HARDWARE_ERROR, SENCODE_INTERNAL_TARGET_FAILURE,
+		  ASENCODE_INTERNAL_TARGET_FAILURE, 0, 0);
 		memcpy(scsicmd->sense_buffer, &dev->fsa_dev[cid].sense_data,
 		       min_t(size_t, sizeof(dev->fsa_dev[cid].sense_data),
 			     SCSI_SENSE_BUFFERSIZE));
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(scsicmd);
+#else
 		scsicmd->scsi_done(scsicmd);
+#endif
 		return 1;
 	}
-
+}
 	dprintk((KERN_DEBUG "aac_write[cpu %d]: lba = %llu, t = %ld.\n",
 	  smp_processor_id(), (unsigned long long)lba, jiffies));
 	if (aac_adapter_bounds(dev,scsicmd,lba))
 		return 0;
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+	/*
+	 *	Are we in a sequential mode?
+	 */
+	aac_select_queue_depth(scsicmd, lba, count);
+#endif
 	/*
 	 *	Allocate and initialize a Fib then setup a BlockWrite command
 	 */
 	if (!(cmd_fibcontext = aac_fib_alloc(dev))) {
-		/* FIB temporarily unavailable,not catastrophic failure */
-
-		/* scsicmd->result = DID_ERROR << 16;
-		 * scsicmd->scsi_done(scsicmd);
-		 * return 0;
-		 */
-		printk(KERN_WARNING "aac_write: fib allocation failed\n");
 		return -1;
 	}
 
@@ -1893,7 +3973,11 @@ static int aac_write(struct scsi_cmnd * scsicmd)
 	 *	For some reason, the Fib didn't queue, return QUEUE_FULL
 	 */
 	scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_TASK_SET_FULL;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+	aac_io_done(scsicmd);
+#else
 	scsicmd->scsi_done(scsicmd);
+#endif
 
 	aac_fib_complete(cmd_fibcontext);
 	aac_fib_free(cmd_fibcontext);
@@ -1938,7 +4022,11 @@ static void synchronize_callback(void *context, struct fib *fibptr)
 
 	aac_fib_complete(fibptr);
 	aac_fib_free(fibptr);
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+	aac_io_done(cmd);
+#else
 	cmd->scsi_done(cmd);
+#endif
 }
 
 static int aac_synchronize(struct scsi_cmnd *scsicmd)
@@ -1953,14 +4041,31 @@ static int aac_synchronize(struct scsi_cmnd *scsicmd)
 	u64 lba = ((u64)scsicmd->cmnd[2] << 24) | (scsicmd->cmnd[3] << 16) |
 		(scsicmd->cmnd[4] << 8) | scsicmd->cmnd[5];
 	u32 count = (scsicmd->cmnd[7] << 8) | scsicmd->cmnd[8];
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 	unsigned long flags;
 
+#if (defined(AAC_DEBUG_INSTRUMENT_SYNCHRONIZE))
+	printk(KERN_INFO "aac_synchronize(%p={.lba=%llu,.count=%lu})\n",
+	    scsicmd, (unsigned long long)lba, (unsigned long)count);
+#endif
 	/*
 	 * Wait for all outstanding queued commands to complete to this
 	 * specific target (block).
 	 */
 	spin_lock_irqsave(&sdev->list_lock, flags);
 	list_for_each_entry(cmd, &sdev->cmd_list, list)
+#else
+#if (defined(AAC_DEBUG_INSTRUMENT_SYNCHRONIZE))
+	printk(KERN_INFO "aac_synchronize(%p={.lba=%llu,.count=%lu})\n",
+	    scsicmd, (unsigned long long)lba, (unsigned long)count);
+#endif
+	for(cmd = sdev->device_queue; cmd; cmd = cmd->next)
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SYNCHRONIZE))
+	{
+		printk(KERN_INFO "%p={.SCp.phase=%x,.cmnd[0]=%u,",
+		  cmd, (unsigned)cmd->SCp.phase, cmd->cmnd[0]);
+#endif
 		if (cmd->SCp.phase == AAC_OWNER_FIRMWARE) {
 			u64 cmnd_lba;
 			u32 cmnd_count;
@@ -1972,6 +4077,7 @@ static int aac_synchronize(struct scsi_cmnd *scsicmd)
 				cmnd_count = cmd->cmnd[4];
 				if (cmnd_count == 0)
 					cmnd_count = 256;
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(WRITE_16))
 			} else if (cmd->cmnd[0] == WRITE_16) {
 				cmnd_lba = ((u64)cmd->cmnd[2] << 56) |
 					((u64)cmd->cmnd[3] << 48) |
@@ -1985,6 +4091,7 @@ static int aac_synchronize(struct scsi_cmnd *scsicmd)
 					(cmd->cmnd[11] << 16) |
 					(cmd->cmnd[12] << 8) |
 					cmd->cmnd[13];
+#endif
 			} else if (cmd->cmnd[0] == WRITE_12) {
 				cmnd_lba = ((u64)cmd->cmnd[2] << 24) |
 					(cmd->cmnd[3] << 16) |
@@ -2002,31 +4109,82 @@ static int aac_synchronize(struct scsi_cmnd *scsicmd)
 				cmnd_count = (cmd->cmnd[7] << 8) |
 					cmd->cmnd[8];
 			} else
+#if (defined(AAC_DEBUG_INSTRUMENT_SYNCHRONIZE))
+			{
+				printk("}\n");
+				continue;
+			}
+			printk(".lba=%llu,.count=%lu,",
+			  (unsigned long long)cmnd_lba,
+			  (unsigned long)cmnd_count);
+#else
 				continue;
+#endif
 			if (((cmnd_lba + cmnd_count) < lba) ||
 			  (count && ((lba + count) < cmnd_lba)))
+#if (defined(AAC_DEBUG_INSTRUMENT_SYNCHRONIZE))
+			{
+				printk("}\n");
+				continue;
+			}
+			printk(".active}\n");
+#else
 				continue;
+#endif
 			++active;
 			break;
 		}
+#if (defined(AAC_DEBUG_INSTRUMENT_SYNCHRONIZE))
+		printk("}\n");
+	}
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 
 	spin_unlock_irqrestore(&sdev->list_lock, flags);
+#endif
 
 	/*
 	 *	Yield the processor (requeue for later)
 	 */
 	if (active)
+#if (defined(AAC_DEBUG_INSTRUMENT_SYNCHRONIZE))
+	{
+		printk(KERN_INFO "aac_synchronize ACTIVE!\n");
+		return SCSI_MLQUEUE_DEVICE_BUSY;
+	}
+#else
 		return SCSI_MLQUEUE_DEVICE_BUSY;
+#endif
 
 	aac = (struct aac_dev *)sdev->host->hostdata;
 	if (aac->in_reset)
+#if (defined(AAC_DEBUG_INSTRUMENT_SYNCHRONIZE))
+	{
+		printk(KERN_INFO "aac_synchronize RESET!\n");
+		return SCSI_MLQUEUE_HOST_BUSY;
+	}
+#else
 		return SCSI_MLQUEUE_HOST_BUSY;
+#endif
 
+#if (defined(AAC_DEBUG_INSTRUMENT_SYNCHRONIZE))
+	printk(KERN_INFO "aac_synchronize START\n");
+#elif (defined(AAC_DEBUG_INSTRUMENT_IO))
+	printk(KERN_DEBUG "aac_synchronize[cpu %d]: t = %ld.\n",
+	  smp_processor_id(), jiffies);
+#endif
 	/*
 	 *	Allocate and initialize a Fib
 	 */
 	if (!(cmd_fibcontext = aac_fib_alloc(aac)))
+#if (defined(AAC_DEBUG_INSTRUMENT_SYNCHRONIZE))
+	{
+		printk(KERN_INFO "aac_synchronize ALLOC!\n");
+		return SCSI_MLQUEUE_HOST_BUSY;
+	}
+#else
 		return SCSI_MLQUEUE_HOST_BUSY;
+#endif
 
 	aac_fib_init(cmd_fibcontext);
 
@@ -2076,7 +4234,11 @@ static void aac_start_stop_callback(void *context, struct fib *fibptr)
 
 	aac_fib_complete(fibptr);
 	aac_fib_free(fibptr);
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+	aac_io_done(scsicmd);
+#else
 	scsicmd->scsi_done(scsicmd);
+#endif
 }
 
 static int aac_start_stop(struct scsi_cmnd *scsicmd)
@@ -2091,7 +4253,11 @@ static int aac_start_stop(struct scsi_cmnd *scsicmd)
 	      AAC_OPTION_POWER_MANAGEMENT)) {
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 |
 				  SAM_STAT_GOOD;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(scsicmd);
+#else
 		scsicmd->scsi_done(scsicmd);
+#endif
 		return 0;
 	}
 
@@ -2140,6 +4306,33 @@ static int aac_start_stop(struct scsi_cmnd *scsicmd)
 	aac_fib_free(cmd_fibcontext);
 	return SCSI_MLQUEUE_HOST_BUSY;
 }
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+
+static inline void get_sd_devname(int disknum, char *buffer)
+{
+	if (disknum < 0) {
+		buffer[0] = '\0';
+		return;
+	}
+
+	buffer[0] = 's';
+	buffer[1] = 'd';
+	if (disknum < 26) {
+		buffer[2] = 'a' + disknum;
+		buffer[3] = '\0';
+	} else {
+		/*
+		 * For larger numbers of disks, we need to go to a new
+		 * naming scheme.
+		 */
+		buffer[2] = 'a' - 1 + (disknum / 26);
+		buffer[3] = 'a' + (disknum % 26);
+		buffer[4] = '\0';
+	}
+}
+
+# define strlcpy(s1,s2,n) strncpy(s1,s2,n);s1[n-1]='\0'
+#endif
 
 /**
  *	aac_scsi_cmd()		-	Process SCSI command
@@ -2149,15 +4342,28 @@ static int aac_start_stop(struct scsi_cmnd *scsicmd)
  *	aacraid firmware.
  */
 
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+static
+#endif
 int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 {
-	u32 cid;
+	u32 cid, bus;
 	struct Scsi_Host *host = scsicmd->device->host;
 	struct aac_dev *dev = (struct aac_dev *)host->hostdata;
 	struct fsa_dev_info *fsa_dev_ptr = dev->fsa_dev;
 
 	if (fsa_dev_ptr == NULL)
 		return -1;
+#	if (defined(AAC_DEBUG_INSTRUMENT_2TB))
+		printk(KERN_NOTICE "scsicmd->cmnd={%02x %02x %02x %02x %02x "
+		  "%02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x}\n",
+		  scsicmd->cmnd[0], scsicmd->cmnd[1], scsicmd->cmnd[2],
+		  scsicmd->cmnd[3], scsicmd->cmnd[4], scsicmd->cmnd[5],
+		  scsicmd->cmnd[6], scsicmd->cmnd[7], scsicmd->cmnd[8],
+		  scsicmd->cmnd[9], scsicmd->cmnd[10], scsicmd->cmnd[11],
+		  scsicmd->cmnd[12], scsicmd->cmnd[13], scsicmd->cmnd[14],
+		  scsicmd->cmnd[15]);
+#	endif
 	/*
 	 *	If the bus, id or lun is out of range, return fail
 	 *	Test does not apply to ID 16, the pseudo id for the controller
@@ -2168,8 +4374,17 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 		if (scmd_channel(scsicmd) == CONTAINER_CHANNEL) {
 			if((cid >= dev->maximum_num_containers) ||
 					(scsicmd->device->lun != 0)) {
+#				if (defined(AAC_DEBUG_INSTRUMENT_2TB))
+					printk(KERN_INFO
+					  "scsicmd(0:%d:%d:0) No Connect\n",
+					  scmd_channel(scsicmd), cid);
+#				endif
 				scsicmd->result = DID_NO_CONNECT << 16;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+				__aac_io_done(scsicmd);
+#else
 				scsicmd->scsi_done(scsicmd);
+#endif
 				return 0;
 			}
 
@@ -2181,11 +4396,13 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 			  (fsa_dev_ptr[cid].sense_data.sense_key ==
 			   NOT_READY)) {
 				switch (scsicmd->cmnd[0]) {
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(SERVICE_ACTION_IN))
 				case SERVICE_ACTION_IN:
 					if (!(dev->raw_io_interface) ||
 					    !(dev->raw_io_64) ||
 					    ((scsicmd->cmnd[1] & 0x1f) != SAI_READ_CAPACITY_16))
 						break;
+#endif
 				case INQUIRY:
 				case READ_CAPACITY:
 				case TEST_UNIT_READY:
@@ -2198,14 +4415,145 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 				}
 			}
 		} else {  /* check for physical non-dasd devices */
-			if (dev->nondasd_support || expose_physicals ||
-					dev->jbod) {
+#			if (defined(AAC_DEBUG_INSTRUMENT_2TB))
+				printk(KERN_INFO "scsicmd(0:%d:%d:0) Phys\n",
+				  scmd_channel(scsicmd), cid);
+#			endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,18))
+			/* ADPml05517 */
+			/*
+			 * If this is a test unit ready and there is already
+			 * a long command outstanding, we will assume a
+			 * sequentially queued device and report back that
+			 * this needs a retry.
+			 */
+			if (scsicmd->cmnd[0] == TEST_UNIT_READY) {
+				struct scsi_cmnd * command;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+				unsigned long flags;
+				spin_lock_irqsave(&scsicmd->device->list_lock,
+				  flags);
+				list_for_each_entry(command,
+				  &scsicmd->device->cmd_list, list)
+#else
+				for(command = scsicmd->device->device_queue;
+				  command; command = command->next)
+#endif
+				{
+					if (command == scsicmd)
+						continue;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,12))
+					if ((command->state == SCSI_STATE_FINISHED)
+					 || (command->state == 0))
+						continue;
+#endif
+#if (1 || (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)))
+					if (command->timeout_per_command
+					  <= scsicmd->timeout_per_command)
+						continue;
+#else
+					if (command->request->timeout
+					  <= scsicmd->request->timeout)
+						continue;
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+					spin_unlock_irqrestore(
+					  &scsicmd->device->list_lock,
+					  flags);
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,10)) || defined(DID_BUS_BUSY))
+					scsicmd->result = DID_BUS_BUSY << 16 |
+						COMMAND_COMPLETE << 8;
+#else
+					scsicmd->result = DID_OK << 16
+					  | COMMAND_COMPLETE << 8
+					  | SAM_STAT_CHECK_CONDITION;
+					set_sense(
+					  &dev->fsa_dev[cid].sense_data,
+					  ABORTED_COMMAND, 0, 0, 0, 0);
+					memcpy(scsicmd->sense_buffer,
+					  &dev->fsa_dev[cid].sense_data,
+					  min_t(size_t, sizeof(
+						dev->fsa_dev[cid].sense_data),
+						SCSI_SENSE_BUFFERSIZE));
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+					__aac_io_done(scsicmd);
+#else
+					scsicmd->scsi_done(scsicmd);
+#endif
+					return 0;
+				}
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+				spin_unlock_irqrestore(
+				  &scsicmd->device->list_lock,
+				  flags);
+#endif
+			}
+#endif
+			bus = aac_logical_to_phys(scmd_channel(scsicmd));
+			if (dev->hba_map[bus][cid].devtype == 
+				AAC_DEVTYPE_NATIVE_RAW) {
+				if (dev->in_reset)
+					return -1;
+				return aac_send_hba_fib(scsicmd);
+			} else if (dev->nondasd_support || expose_physicals ||
+				dev->jbod) {
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+				/*
+				 *	Read and Write protect the exposed
+				 * physical devices.
+				 */
+				if (scsicmd->device->no_uld_attach)
+				switch (scsicmd->cmnd[0]) {
+				/* Filter Format? SMART Verify/Fix? */
+				case MODE_SELECT:
+				case MODE_SELECT_10:
+				case LOG_SELECT:
+				case WRITE_LONG:
+				case WRITE_SAME:
+				case WRITE_VERIFY:
+				case WRITE_VERIFY_12:
+				case WRITE_6:
+				case READ_6:
+				case WRITE_10:
+				case READ_10:
+				case WRITE_12:
+				case READ_12:
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(WRITE_16))
+				case WRITE_16:
+				case READ_16:
+#endif
+					scsicmd->result = DID_OK << 16
+					  | COMMAND_COMPLETE << 8
+					  | SAM_STAT_CHECK_CONDITION;
+					set_sense(
+					  &dev->fsa_dev[cid].sense_data,
+					  DATA_PROTECT, SENCODE_DATA_PROTECT,
+					  ASENCODE_END_OF_DATA, 0, 0);
+					memcpy(scsicmd->sense_buffer,
+					  &dev->fsa_dev[cid].sense_data,
+					  min_t(size_t, sizeof(
+						dev->fsa_dev[cid].sense_data),
+						SCSI_SENSE_BUFFERSIZE));
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+					__aac_io_done(scsicmd);
+#else
+					scsicmd->scsi_done(scsicmd);
+#endif
+					return 0;
+				}
+#endif
 				if (dev->in_reset)
 					return -1;
 				return aac_send_srb_fib(scsicmd);
 			} else {
 				scsicmd->result = DID_NO_CONNECT << 16;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+				__aac_io_done(scsicmd);
+#else
 				scsicmd->scsi_done(scsicmd);
+#endif
 				return 0;
 			}
 		}
@@ -2224,14 +4572,24 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 		memcpy(scsicmd->sense_buffer, &dev->fsa_dev[cid].sense_data,
 		       min_t(size_t, sizeof(dev->fsa_dev[cid].sense_data),
 			     SCSI_SENSE_BUFFERSIZE));
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(scsicmd);
+#else
 		scsicmd->scsi_done(scsicmd);
+#endif
 		return 0;
 	}
 
 
 	/* Handle commands here that don't really require going out to the adapter */
+#	if (defined(AAC_DEBUG_INSTRUMENT_2TB))
+		printk(KERN_NOTICE "cmnd[0]=%02x\n", scsicmd->cmnd[0]);
+#	endif
 	switch (scsicmd->cmnd[0]) {
 	case INQUIRY:
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+		return aac_adapter_inquiry(dev, scsicmd);
+#else
 	{
 		struct inquiry_data inq_data;
 
@@ -2246,12 +4604,24 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 			  INQD_PDT_PROC : INQD_PDT_DA;
 			if (scsicmd->cmnd[2] == 0) {
 				/* supported vital product data pages */
+/* Excluding SUSE as it has issues when inbox driver does not have this support but outbox has it. 
+  Because SUSE uses /dev/disk/by-id mapping entries in the OS grub config and VPD 0X83 creates conflicts */
+#if (!defined(CONFIG_SUSE_KERNEL))
+				arr[3] = 3;
+				arr[6] = 0x83;				
+#else
 				arr[3] = 2;
+#endif
 				arr[4] = 0x0;
 				arr[5] = 0x80;
 				arr[1] = scsicmd->cmnd[2];
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+				aac_internal_transfer(scsicmd, &inq_data, 0,
+				  sizeof(inq_data));
+#else
 				scsi_sg_copy_from_buffer(scsicmd, &inq_data,
 							 sizeof(inq_data));
+#endif
 				scsicmd->result = DID_OK << 16 |
 				  COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
 			} else if (scsicmd->cmnd[2] == 0x80) {
@@ -2259,14 +4629,36 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 				arr[3] = setinqserial(dev, &arr[4],
 				  scmd_id(scsicmd));
 				arr[1] = scsicmd->cmnd[2];
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+				aac_internal_transfer(scsicmd, &inq_data, 0,
+				  sizeof(inq_data));
+#else
 				scsi_sg_copy_from_buffer(scsicmd, &inq_data,
 							 sizeof(inq_data));
+#endif
 				if (aac_wwn != 2)
 					return aac_get_container_serial(
 						scsicmd);
 				/* SLES 10 SP1 special */
 				scsicmd->result = DID_OK << 16 |
 				  COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
+/* Excluding SUSE as it has issues when inbox driver does not have this support but outbox has it. 
+  Because SUSE uses /dev/disk/by-id mapping entries in the OS grub config and VPD 0X83 creates conflicts */
+#if (!defined(CONFIG_SUSE_KERNEL))
+			} else if (scsicmd->cmnd[2] == 0x83) {
+				/* vpd page 0x83 - Device Identification Page */
+				char *sno = (char *)&inq_data;
+
+				sno[3] = setinqserial(dev, &sno[4],
+				  scmd_id(scsicmd));
+				 
+				if (aac_wwn != 2)
+					return aac_get_container_serial(
+						scsicmd);
+
+				scsicmd->result = DID_OK << 16 |
+				  COMMAND_COMPLETE << 8 | SAM_STAT_CHECK_CONDITION;
+#endif
 			} else {
 				/* vpd page not implemented */
 				scsicmd->result = DID_OK << 16 |
@@ -2296,20 +4688,44 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 		if (cid == host->this_id) {
 			setinqstr(dev, (void *) (inq_data.inqd_vid), ARRAY_SIZE(container_types));
 			inq_data.inqd_pdt = INQD_PDT_PROC;	/* Processor device */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+			aac_internal_transfer(scsicmd, &inq_data, 0, sizeof(inq_data));
+#else
 			scsi_sg_copy_from_buffer(scsicmd, &inq_data,
 						 sizeof(inq_data));
+#endif
 			scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+			__aac_io_done(scsicmd);
+#else
 			scsicmd->scsi_done(scsicmd);
+#endif
 			return 0;
 		}
 		if (dev->in_reset)
 			return -1;
 		setinqstr(dev, (void *) (inq_data.inqd_vid), fsa_dev_ptr[cid].type);
 		inq_data.inqd_pdt = INQD_PDT_DA;	/* Direct/random access device */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+		aac_internal_transfer(scsicmd, &inq_data, 0, sizeof(inq_data));
+#else
 		scsi_sg_copy_from_buffer(scsicmd, &inq_data, sizeof(inq_data));
+#endif
 		return aac_get_container_name(scsicmd);
 	}
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(SERVICE_ACTION_IN))
 	case SERVICE_ACTION_IN:
+#if (defined(AAC_DEBUG_INSTRUMENT_2TB))
+		printk(KERN_NOTICE
+		  "SERVICE_ACTION_IN, raw_io_interface=%d raw_io_64=%d\n",
+		  dev->raw_io_interface, dev->raw_io_64);
+#endif
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+		if ((scsicmd->cmnd[1] & 0x1f) != SAI_READ_CAPACITY_16)
+			break;
+		return aac_adapter_read_capacity_16(dev, scsicmd);
+#else
 		if (!(dev->raw_io_interface) ||
 		    !(dev->raw_io_64) ||
 		    ((scsicmd->cmnd[1] & 0x1f) != SAI_READ_CAPACITY_16))
@@ -2329,32 +4745,66 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 		cp[5] = (capacity >> 16) & 0xff;
 		cp[6] = (capacity >> 8) & 0xff;
 		cp[7] = (capacity >> 0) & 0xff;
-		cp[8] = 0;
-		cp[9] = 0;
-		cp[10] = 2;
-		cp[11] = 0;
+		cp[8] = (fsa_dev_ptr[cid].block_size >> 24) & 0xff;
+		cp[9] = (fsa_dev_ptr[cid].block_size >> 16) & 0xff;
+		cp[10] = (fsa_dev_ptr[cid].block_size >> 8) & 0xff;
+		cp[11] = (fsa_dev_ptr[cid].block_size) & 0xff;
 		cp[12] = 0;
+#if (defined(AAC_DEBUG_INSTRUMENT_2TB))
+		printk(KERN_INFO "SAI_READ_CAPACITY_16(%d): "
+		  "%02x %02x %02x %02x %02x %02x %02x %02x "
+		  "%02x %02x %02x %02x %02x\n",
+		  scsicmd->cmnd[13],
+		  cp[0] & 0xff, cp[1] & 0xff, cp[2] & 0xff, cp[3] & 0xff,
+		  cp[4] & 0xff, cp[5] & 0xff, cp[6] & 0xff, cp[7] & 0xff,
+		  cp[8] & 0xff, cp[9] & 0xff, cp[10] & 0xff, cp[11] & 0xff,
+		  cp[12] & 0xff);
+#endif
 
 		alloc_len = ((scsicmd->cmnd[10] << 24)
 			     + (scsicmd->cmnd[11] << 16)
 			     + (scsicmd->cmnd[12] << 8) + scsicmd->cmnd[13]);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+		aac_internal_transfer(scsicmd, cp, 0,
+		  min_t(size_t, alloc_len, sizeof(cp)));
+		if (sizeof(cp) < alloc_len) {
+			unsigned int len, offset = sizeof(cp);
+
+			memset(cp, 0, offset);
+			do {
+				len = min_t(size_t, alloc_len - offset,
+						sizeof(cp));
+				aac_internal_transfer(scsicmd, cp, offset, len);
+			} while ((offset += len) < alloc_len);
+		}
+#else
 
 		alloc_len = min_t(size_t, alloc_len, sizeof(cp));
 		scsi_sg_copy_from_buffer(scsicmd, cp, alloc_len);
 		if (alloc_len < scsi_bufflen(scsicmd))
 			scsi_set_resid(scsicmd,
 				       scsi_bufflen(scsicmd) - alloc_len);
+#endif
 
 		/* Do not cache partition table for arrays */
 		scsicmd->device->removable = 1;
 
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(scsicmd);
+#else
 		scsicmd->scsi_done(scsicmd);
+#endif
 
 		return 0;
 	}
+#endif
 
+#endif
 	case READ_CAPACITY:
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+		return aac_adapter_read_capacity(dev, scsicmd);
+#else
 	{
 		u32 capacity;
 		char cp[8];
@@ -2369,84 +4819,193 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 		cp[1] = (capacity >> 16) & 0xff;
 		cp[2] = (capacity >> 8) & 0xff;
 		cp[3] = (capacity >> 0) & 0xff;
-		cp[4] = 0;
-		cp[5] = 0;
-		cp[6] = 2;
-		cp[7] = 0;
+		cp[4] = (fsa_dev_ptr[cid].block_size >> 24) & 0xff;
+		cp[5] = (fsa_dev_ptr[cid].block_size >> 16) & 0xff;
+		cp[6] = (fsa_dev_ptr[cid].block_size >> 8) & 0xff;
+		cp[7] = (fsa_dev_ptr[cid].block_size) & 0xff;
+#if (defined(AAC_DEBUG_INSTRUMENT_2TB))
+		printk(KERN_INFO "READ_CAPACITY: "
+		  "%02x %02x %02x %02x %02x %02x %02x %02x\n",
+		  cp[0] & 0xff, cp[1] & 0xff, cp[2] & 0xff, cp[3] & 0xff,
+		  cp[4] & 0xff, cp[5] & 0xff, cp[6] & 0xff, cp[7] & 0xff);
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+		aac_internal_transfer(scsicmd, cp, 0, sizeof(cp));
+#else
 		scsi_sg_copy_from_buffer(scsicmd, cp, sizeof(cp));
+#endif
 		/* Do not cache partition table for arrays */
 		scsicmd->device->removable = 1;
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 |
 		  SAM_STAT_GOOD;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(scsicmd);
+#else
 		scsicmd->scsi_done(scsicmd);
+#endif
 
 		return 0;
 	}
-
+#endif
 	case MODE_SENSE:
 	{
-		char mode_buf[7];
 		int mode_buf_length = 4;
+		u32 capacity;
+		aac_modep_data mpd;
+
+		if (fsa_dev_ptr[cid].size <= 0x100000000ULL)
+			capacity = fsa_dev_ptr[cid].size - 1;
+		else
+			capacity = (u32)-1;
 
 		dprintk((KERN_DEBUG "MODE SENSE command.\n"));
-		mode_buf[0] = 3;	/* Mode data length */
-		mode_buf[1] = 0;	/* Medium type - default */
-		mode_buf[2] = 0;	/* Device-specific param,
+		memset((char*)&mpd,0,sizeof(aac_modep_data));
+		mpd.hd.data_length = sizeof(mpd.hd) - 1;	/* Mode data length */
+		mpd.hd.med_type = 0;	/* Medium type - default */
+		mpd.hd.dev_par = 0;	/* Device-specific param,
 					   bit 8: 0/1 = write enabled/protected
 					   bit 4: 0/1 = FUA enabled */
+		
+#if (defined(RIO_SUREWRITE))
 		if (dev->raw_io_interface && ((aac_cache & 5) != 1))
-			mode_buf[2] = 0x10;
-		mode_buf[3] = 0;	/* Block descriptor length */
+			mpd.hd.dev_par = 0x10;
+#endif
+		if (scsicmd->cmnd[1] & 0x8) {
+			mpd.hd.bd_length = 0;   /* Block descriptor length */
+		} else {
+			mpd.hd.bd_length = sizeof(mpd.bd);
+			mpd.hd.data_length += mpd.hd.bd_length;
+			mpd.bd.block_length[0] = (fsa_dev_ptr[cid].block_size >> 16) & 0xff;
+			mpd.bd.block_length[1] = (fsa_dev_ptr[cid].block_size >> 8) &  0xff;
+			mpd.bd.block_length[2] = fsa_dev_ptr[cid].block_size  & 0xff;
+		
+			mpd.mpc_buf[0] = scsicmd->cmnd[2];
+			if(scsicmd->cmnd[2] == 0x1C)
+			{
+				mpd.mpc_buf[1] = 0xa;	//page length
+				mpd.hd.data_length = 23;	/* Mode data length */
+			}
+			else
+				mpd.hd.data_length = 15;	/* Mode data length */
+
+			if (capacity > 0xffffff) {
+				mpd.bd.block_count[0] = 0xff;
+				mpd.bd.block_count[1] = 0xff;
+				mpd.bd.block_count[2] = 0xff;
+			} else {
+				mpd.bd.block_count[0] = (capacity >> 16) & 0xff;
+				mpd.bd.block_count[1] = (capacity >> 8) & 0xff;
+				mpd.bd.block_count[2] = capacity  & 0xff;
+			}
+		}
+			
 		if (((scsicmd->cmnd[2] & 0x3f) == 8) ||
 		  ((scsicmd->cmnd[2] & 0x3f) == 0x3f)) {
-			mode_buf[0] = 6;
-			mode_buf[4] = 8;
-			mode_buf[5] = 1;
-			mode_buf[6] = ((aac_cache & 6) == 2)
-				? 0 : 0x04; /* WCE */
-			mode_buf_length = 7;
-			if (mode_buf_length > scsicmd->cmnd[4])
-				mode_buf_length = scsicmd->cmnd[4];
-		}
-		scsi_sg_copy_from_buffer(scsicmd, mode_buf, mode_buf_length);
+			mpd.hd.data_length += 3;
+			mpd.mpc_buf[0] = 8;
+			mpd.mpc_buf[1] = 1;
+			mpd.mpc_buf[2] = ((aac_cache & 6) == 2)
+				  ? 0 : 0x04; /* WCE */
+			mode_buf_length = sizeof(mpd);
+
+		}
+
+		if (mode_buf_length > scsicmd->cmnd[4])
+			mode_buf_length = scsicmd->cmnd[4];
+		else
+			mode_buf_length = sizeof(mpd);
+
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+		aac_internal_transfer(scsicmd, (char*)&mpd, 0, mode_buf_length);
+#else
+		scsi_sg_copy_from_buffer(scsicmd, (char*)&mpd, mode_buf_length);
+#endif
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(scsicmd);
+#else
 		scsicmd->scsi_done(scsicmd);
+#endif
 
 		return 0;
 	}
 	case MODE_SENSE_10:
 	{
-		char mode_buf[11];
+		u32 capacity;
 		int mode_buf_length = 8;
+		aac_modep10_data mpd10;
+
+		if (fsa_dev_ptr[cid].size <= 0x100000000ULL)
+			capacity = fsa_dev_ptr[cid].size - 1;
+		else
+			capacity = (u32)-1;
 
 		dprintk((KERN_DEBUG "MODE SENSE 10 byte command.\n"));
-		mode_buf[0] = 0;	/* Mode data length (MSB) */
-		mode_buf[1] = 6;	/* Mode data length (LSB) */
-		mode_buf[2] = 0;	/* Medium type - default */
-		mode_buf[3] = 0;	/* Device-specific param,
+		memset((char*)&mpd10,0,sizeof(aac_modep10_data));
+		mpd10.hd.data_length[0] = 0;			/* Mode data length (MSB) */
+		mpd10.hd.data_length[1] = sizeof(mpd10.hd) - 1;	/* Mode data length (LSB) */
+		mpd10.hd.med_type = 0;	/* Medium type - default */
+		mpd10.hd.dev_par = 0;	/* Device-specific param,
 					   bit 8: 0/1 = write enabled/protected
 					   bit 4: 0/1 = FUA enabled */
+#if (defined(RIO_SUREWRITE))
 		if (dev->raw_io_interface && ((aac_cache & 5) != 1))
-			mode_buf[3] = 0x10;
-		mode_buf[4] = 0;	/* reserved */
-		mode_buf[5] = 0;	/* reserved */
-		mode_buf[6] = 0;	/* Block descriptor length (MSB) */
-		mode_buf[7] = 0;	/* Block descriptor length (LSB) */
+			mpd10.hd.dev_par = 0x10;
+#endif
+		mpd10.hd.rsrvd[0] = 0;	/* reserved */
+		mpd10.hd.rsrvd[1] = 0;  /* reserved */
+
+		if (scsicmd->cmnd[1] & 0x8) {
+			mpd10.hd.bd_length[0] = 0;	/* Block descriptor length (MSB) */
+			mpd10.hd.bd_length[1] = 0;	/* Block descriptor length (LSB) */
+		} else {
+			mpd10.hd.bd_length[0] = 0;
+			mpd10.hd.bd_length[1] = sizeof(mpd10.bd);
+
+			mpd10.hd.data_length[1] += mpd10.hd.bd_length[1];
+
+			mpd10.bd.block_length[0] = (fsa_dev_ptr[cid].block_size >> 16) & 0xff;
+			mpd10.bd.block_length[1] = (fsa_dev_ptr[cid].block_size >> 8) & 0xff;
+			mpd10.bd.block_length[2] = fsa_dev_ptr[cid].block_size  & 0xff;
+			
+			if (capacity > 0xffffff) {
+				mpd10.bd.block_count[0] = 0xff;
+				mpd10.bd.block_count[1] = 0xff;
+				mpd10.bd.block_count[2] = 0xff;
+			} else {
+				mpd10.bd.block_count[0] = (capacity >> 16) & 0xff;
+				mpd10.bd.block_count[1] = (capacity >> 8) & 0xff;
+				mpd10.bd.block_count[2] = capacity  & 0xff;
+			}
+		}
 		if (((scsicmd->cmnd[2] & 0x3f) == 8) ||
 		  ((scsicmd->cmnd[2] & 0x3f) == 0x3f)) {
-			mode_buf[1] = 9;
-			mode_buf[8] = 8;
-			mode_buf[9] = 1;
-			mode_buf[10] = ((aac_cache & 6) == 2)
-				? 0 : 0x04; /* WCE */
-			mode_buf_length = 11;
+
+			mpd10.hd.data_length[1] += 3;
+			mpd10.mpc_buf[0] = 8;
+			mpd10.mpc_buf[1] = 1;
+			mpd10.mpc_buf[2] = ((aac_cache & 6) == 2)
+				     ? 0 : 0x04; /* WCE */
+
+			mode_buf_length = sizeof(mpd10);
+			
 			if (mode_buf_length > scsicmd->cmnd[8])
 				mode_buf_length = scsicmd->cmnd[8];
 		}
-		scsi_sg_copy_from_buffer(scsicmd, mode_buf, mode_buf_length);
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+		aac_internal_transfer(scsicmd, (char*)&mpd10, 0, mode_buf_length);
+#else
+		scsi_sg_copy_from_buffer(scsicmd, (char*)&mpd10, mode_buf_length);
+#endif
 
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(scsicmd);
+#else
 		scsicmd->scsi_done(scsicmd);
+#endif
 
 		return 0;
 	}
@@ -2455,7 +5014,11 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 		memcpy(scsicmd->sense_buffer, &dev->fsa_dev[cid].sense_data, sizeof (struct sense_data));
 		memset(&dev->fsa_dev[cid].sense_data, 0, sizeof (struct sense_data));
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(scsicmd);
+#else
 		scsicmd->scsi_done(scsicmd);
+#endif
 		return 0;
 
 	case ALLOW_MEDIUM_REMOVAL:
@@ -2466,7 +5029,11 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 			fsa_dev_ptr[cid].locked = 0;
 
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(scsicmd);
+#else
 		scsicmd->scsi_done(scsicmd);
+#endif
 		return 0;
 	/*
 	 *	These commands are all No-Ops
@@ -2483,7 +5050,11 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 			       min_t(size_t,
 				     sizeof(dev->fsa_dev[cid].sense_data),
 				     SCSI_SENSE_BUFFERSIZE));
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+			__aac_io_done(scsicmd);
+#else
 			scsicmd->scsi_done(scsicmd);
+#endif
 			return 0;
 		}
 		/* FALLTHRU */
@@ -2493,7 +5064,11 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 	case REASSIGN_BLOCKS:
 	case SEEK_10:
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(scsicmd);
+#else
 		scsicmd->scsi_done(scsicmd);
+#endif
 		return 0;
 
 	case START_STOP:
@@ -2505,7 +5080,9 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 		case READ_6:
 		case READ_10:
 		case READ_12:
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(READ_16))
 		case READ_16:
+#endif
 			if (dev->in_reset)
 				return -1;
 			/*
@@ -2513,33 +5090,80 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 			 *	corresponds to a container. Needed to convert
 			 *	containers to /dev/sd device names
 			 */
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) && defined(AAC_EXTENDED_TIMEOUT))
+			if ((scsicmd->eh_state != SCSI_STATE_QUEUED)
+			 && (extendedtimeout > 0)) {
+				mod_timer(&scsicmd->eh_timeout, jiffies + (extendedtimeout * HZ));
+			}
+#endif
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+#if (defined(__VMKLNX30__) || defined(__VMKLNX__))
+			/* This code is commented out because such a mapping 
+			 * doesn't seem to exist in vmklinux.
+			 *
+			 * This information is only used when a QUERY_DISK IOCTL 
+			 * comes down and as far as I can tell there is no
+			 * equivalent check in vmklinux.
+			 */
+#endif
+#if (!defined(__VMKLNX30__) && !defined(__VMKLNX__))
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+			if(fsa_dev_ptr[cid].devname[0]=='\0') {
+				printk(KERN_INFO
+				  "rq_disk=%p disk_name=\"%s\"\n",
+				  scsicmd->request->rq_disk,
+				  scsicmd->request->rq_disk
+				    ? scsicmd->request->rq_disk->disk_name
+				    : "Aiiiii");
+			}
+#endif
 			if (scsicmd->request->rq_disk)
 				strlcpy(fsa_dev_ptr[cid].devname,
 				scsicmd->request->rq_disk->disk_name,
 				min(sizeof(fsa_dev_ptr[cid].devname),
 				sizeof(scsicmd->request->rq_disk->disk_name) + 1));
+#endif
+#else
+			get_sd_devname(DEVICE_NR(scsicmd->request.rq_dev), fsa_dev_ptr[cid].devname);
+#endif
 
 			return aac_read(scsicmd);
 
 		case WRITE_6:
 		case WRITE_10:
 		case WRITE_12:
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(WRITE_16))
 		case WRITE_16:
+#endif
 			if (dev->in_reset)
 				return -1;
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) && defined(AAC_EXTENDED_TIMEOUT))
+			if ((scsicmd->eh_state != SCSI_STATE_QUEUED)
+			 && (extendedtimeout > 0)) {
+				mod_timer(&scsicmd->eh_timeout, jiffies + (extendedtimeout * HZ));
+			}
+#endif
 			return aac_write(scsicmd);
 
 		case SYNCHRONIZE_CACHE:
 			if (((aac_cache & 6) == 6) && dev->cache_protected) {
 				scsicmd->result = DID_OK << 16 |
 					COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+				__aac_io_done(scsicmd);
+#else
 				scsicmd->scsi_done(scsicmd);
+#endif
 				return 0;
 			}
 			/* Issue FIB to tell Firmware to flush it's cache */
 			if ((aac_cache & 6) != 2)
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+				return aac_adapter_synchronize(dev, scsicmd);
+#else
 				return aac_synchronize(scsicmd);
+#endif
 			/* FALLTHRU */
 		default:
 			/*
@@ -2554,42 +5178,178 @@ int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 				min_t(size_t,
 				      sizeof(dev->fsa_dev[cid].sense_data),
 				      SCSI_SENSE_BUFFERSIZE));
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+			__aac_io_done(scsicmd);
+#else
 			scsicmd->scsi_done(scsicmd);
+#endif
 			return 0;
 	}
 }
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
 
-static int query_disk(struct aac_dev *dev, void __user *arg)
+static int aac_scsi_cmd_apre(struct scsi_cmnd * cmd)
 {
-	struct aac_query_disk qd;
-	struct fsa_dev_info *fsa_dev_ptr;
+	struct aac_apre_srb * hw_apre = (struct aac_apre_srb *)&fib->hw_apre_va;
+	struct aac_dev * dev = fib->dev;
+	struct fsa_dev_info * fsa_dev_ptr = &dev->fsa_dev[scmd_id(cmd)];
+	int status;
+	struct fib * fib;
 
-	fsa_dev_ptr = dev->fsa_dev;
-	if (!fsa_dev_ptr)
-		return -EBUSY;
-	if (copy_from_user(&qd, arg, sizeof (struct aac_query_disk)))
-		return -EFAULT;
-	if (qd.cnum == -1)
-		qd.cnum = qd.id;
-	else if ((qd.bus == -1) && (qd.id == -1) && (qd.lun == -1))
-	{
-		if (qd.cnum < 0 || qd.cnum >= dev->maximum_num_containers)
-			return -EINVAL;
-		qd.instance = dev->scsi_host_ptr->host_no;
-		qd.bus = 0;
+	/*
+	 *	Allocate and initialize a Fib then setup a BlockWrite command
+	 */
+	if (!(fib = aac_fib_alloc((struct aac_dev *)cmd->device->host->hostdata))) {
+		cmd->result = DID_ERROR << 16;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		aac_io_done(cmd);
+#else
+		cmd->scsi_done(cmd);
+#endif
+		return 0;
+	}
+
+	fib->Credits = fsa_dev_ptr->Credits;
+	hw_apre->DataDir = 0;
+	if (cmd->request_bufflen) switch (cmd->sc_data_direction) {
+	case DMA_TO_DEVICE:
+		hw_apre->DataDir = AAC_DATA_OUT_IOP_PERSPECTIVE;
+		break;
+	case DMA_BIDIRECTIONAL:
+		hw_apre->DataDir = AAC_DATA_OUT_IOP_PERSPECTIVE | AAC_DATA_IN_IOP_PERSPECTIVE;
+		break;
+	case DMA_FROM_DEVICE:
+		hw_apre->DataDir = AAC_DATA_IN_IOP_PERSPECTIVE;
+		break;
+	}
+	hw_apre->header.Operation = AS_REQ_LKP_CODE_EXEC_SCSI_TASK;
+	hw_apre->header.DestObjHandle = fsa_dev_ptr->DestObjHandle;
+	hw_apre->CDBLength = (cmd->cmd_len - 1);
+	memcpy(hw_apre->Cdb, cmd->cmnd, cmd->cmd_len);
+	hw_apre->TransferSizeLow = cpu_to_le32(cmd->request_bufflen);
+	hw_apre->TransferSizeHigh = cpu_to_le32((u32)((u64)cmd->request_bufflen>>32));
+	status = aac_adapter_build_sg(fib, cmd, &hw_apre->Sgl);
+	hw_apre->NumEsge = (status >
+	  (sizeof(hw_apre->Sgl.nark)/sizeof(hw_apre->Sgl.nark.FirstElement)))
+		? 1 : status;
+	status = aac_adapter_deliver(fib);
+
+	/*
+	 *	Check that the command queued to the controller
+	 */
+	if (status == -EINPROGRESS) {
+		cmd->SCp.phase = AAC_OWNER_FIRMWARE;
+		return 0;
+	}
+
+	printk(KERN_WARNING "aac_scsi_cmd_apre: failed with status: %d\n", status);
+	/*
+	 *	For some reason, the Fib didn't queue, return QUEUE_FULL
+	 */
+	cmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_TASK_SET_FULL;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+	aac_io_done(cmd);
+#else
+	cmd->scsi_done(cmd);
+#endif
+
+	aac_fib_complete(fib);
+	aac_fib_free(fib);
+	return 0;
+}
+#endif
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+
+static int busy_disk(struct aac_dev * dev, int cid)
+{
+	if ((dev != (struct aac_dev *)NULL)
+	 && (dev->scsi_host_ptr != (struct Scsi_Host *)NULL)) {
+		struct scsi_device *device;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0))
+		shost_for_each_device(device, dev->scsi_host_ptr)
+#elif (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+		list_for_each_entry(device, &dev->scsi_host_ptr->my_devices, siblings)
+#else
+		for (device = dev->scsi_host_ptr->host_queue;
+		  device != (struct scsi_device *)NULL;
+		  device = device->next)
+#endif
+		{
+			if ((device->channel == CONTAINER_TO_CHANNEL(cid))
+			 && (device->id == CONTAINER_TO_ID(cid))
+			 && (device->lun == CONTAINER_TO_LUN(cid))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0))
+			 && (atomic_read(&device->access_count)
+			  || test_bit(SHOST_RECOVERY, &dev->scsi_host_ptr->shost_state)
+			  || dev->scsi_host_ptr->eh_active)) {
+#elif ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,14) && (LINUX_VERSION_CODE < KERNEL_VERSION(3,17,0))) || defined(SCSI_HAS_SHOST_STATE_ENUM))
+			&& (device->device_busy
+			  || (SHOST_RECOVERY == dev->scsi_host_ptr->shost_state))) {
+#elif ((LINUX_VERSION_CODE >= KERNEL_VERSION(3,17,0)) || defined(SCSI_HAS_SHOST_STATE_ENUM))
+			&& (atomic_read(&device->device_busy)
+			  || (SHOST_RECOVERY == dev->scsi_host_ptr->shost_state))) {
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,14))
+			&& (device->device_busy
+			  || test_bit(SHOST_RECOVERY, &dev->scsi_host_ptr->shost_state))) {
+#elif (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0))
+			&& (device->device_busy
+			  || test_bit(SHOST_RECOVERY, &dev->scsi_host_ptr->shost_state)
+			  || dev->scsi_host_ptr->eh_active)) {
+#else
+			&& (device->access_count
+			  || dev->scsi_host_ptr->in_recovery
+			  || dev->scsi_host_ptr->eh_active)) {
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0))
+				scsi_device_put(device);
+#endif
+				return 1;
+			}
+		}
+	}
+	return 0;
+}
+#endif
+
+static int query_disk(struct aac_dev *dev, void __user *arg)
+{
+	struct aac_query_disk qd;
+	struct fsa_dev_info *fsa_dev_ptr;
+
+	fsa_dev_ptr = dev->fsa_dev;
+	if (!fsa_dev_ptr)
+		return -EBUSY;
+	if (copy_from_user(&qd, arg, sizeof (struct aac_query_disk)))
+		return -EFAULT;
+	if (qd.cnum == -1)
+		qd.cnum = qd.id;
+	else if ((qd.bus == -1) && (qd.id == -1) && (qd.lun == -1))
+	{
+		if (qd.cnum < 0 || qd.cnum >= dev->maximum_num_containers)
+			return -EINVAL;
+		qd.instance = dev->scsi_host_ptr->host_no;
+		qd.bus = 0;
 		qd.id = CONTAINER_TO_ID(qd.cnum);
 		qd.lun = CONTAINER_TO_LUN(qd.cnum);
 	}
 	else return -EINVAL;
 
 	qd.valid = fsa_dev_ptr[qd.cnum].valid != 0;
+#if (defined(CONFIG_COMMUNITY_KERNEL))
 	qd.locked = fsa_dev_ptr[qd.cnum].locked;
+#else
+	qd.locked = fsa_dev_ptr[qd.cnum].locked || busy_disk(dev, qd.cnum);
+#endif
 	qd.deleted = fsa_dev_ptr[qd.cnum].deleted;
 
+#if (!defined(__VMKLNX30__) && !defined(__VMKLNX__))
 	if (fsa_dev_ptr[qd.cnum].devname[0] == '\0')
 		qd.unmapped = 1;
 	else
 		qd.unmapped = 0;
+#else
+	qd.unmapped = 0;
+#endif
 
 	strlcpy(qd.name, fsa_dev_ptr[qd.cnum].devname,
 	  min(sizeof(qd.name), sizeof(fsa_dev_ptr[qd.cnum].devname) + 1));
@@ -2641,7 +5401,11 @@ static int delete_disk(struct aac_dev *dev, void __user *arg)
 	/*
 	 *	If the container is locked, it can not be deleted by the API.
 	 */
+#if (defined(CONFIG_COMMUNITY_KERNEL))
 	if (fsa_dev_ptr[dd.cnum].locked)
+#else
+	if (fsa_dev_ptr[dd.cnum].locked || busy_disk(dev, dd.cnum))
+#endif
 		return -EBUSY;
 	else {
 		/*
@@ -2653,18 +5417,78 @@ static int delete_disk(struct aac_dev *dev, void __user *arg)
 	}
 }
 
+#if (defined(FSACTL_REGISTER_FIB_SEND) && !defined(CONFIG_COMMUNITY_KERNEL))
+static int aac_register_fib_send(struct aac_dev *dev, void __user *arg)
+{
+	fib_send_t __user callback;
+
+	if (arg == NULL) {
+		return -EINVAL;
+	}
+	callback = *((fib_send_t __user *)arg);
+	*((fib_send_t __user *)arg) = (fib_send_t __user)aac_fib_send;
+	if (callback == (fib_send_t __user)NULL) {
+		aac_fib_send_switch = aac_fib_send;
+		return 0;
+	}
+	if (aac_fib_send_switch != aac_fib_send) {
+		return -EBUSY;
+	}
+	aac_fib_send_switch = (fib_send_t)callback;
+	return 0;
+}
+
+#endif
 int aac_dev_ioctl(struct aac_dev *dev, int cmd, void __user *arg)
 {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	int retval;
+	if (cmd != FSACTL_GET_NEXT_ADAPTER_FIB)
+		printk("aac_dev_ioctl(%p,%x,%p)\n", dev, cmd, arg);
+#endif
 	switch (cmd) {
 	case FSACTL_QUERY_DISK:
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		retval = query_disk(dev, arg);
+		printk("aac_dev_ioctl returns %d\n", retval);
+		return retval;
+#endif
 		return query_disk(dev, arg);
 	case FSACTL_DELETE_DISK:
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		retval = delete_disk(dev, arg);
+		printk("aac_dev_ioctl returns %d\n", retval);
+		return retval;
+#endif
 		return delete_disk(dev, arg);
 	case FSACTL_FORCE_DELETE_DISK:
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		retval = force_delete_disk(dev, arg);
+		printk("aac_dev_ioctl returns %d\n", retval);
+		return retval;
+#endif
 		return force_delete_disk(dev, arg);
 	case FSACTL_GET_CONTAINERS:
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		retval = aac_get_containers(dev);
+		printk("aac_dev_ioctl returns %d\n", retval);
+		return retval;
+#endif
 		return aac_get_containers(dev);
+#if (defined(FSACTL_REGISTER_FIB_SEND) && !defined(CONFIG_COMMUNITY_KERNEL))
+	case FSACTL_REGISTER_FIB_SEND:
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		retval = aac_register_fib_send(dev, arg);
+		printk("aac_dev_ioctl returns %d\n", retval);
+		return retval;
+#endif
+		return aac_register_fib_send(dev, arg);
+#endif
 	default:
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		printk("aac_dev_ioctl returns -ENOTTY\n");
+	case FSACTL_GET_NEXT_ADAPTER_FIB:
+#endif
 		return -ENOTTY;
 	}
 }
@@ -2691,11 +5515,42 @@ static void aac_srb_callback(void *context, struct fib * fibptr)
 		return;
 
 	BUG_ON(fibptr == NULL);
-
 	dev = fibptr->dev;
 
-	srbreply = (struct aac_srb_reply *) fib_data(fibptr);
+	#if (!defined(__VMKLNX30__) || defined(__x86_64__))
+	scsi_dma_unmap(scsicmd);
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+	if(!scsi_sg_count(scsicmd) && scsi_bufflen(scsicmd))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		pci_unmap_single(dev->pdev, (dma_addr_t)scsicmd->SCp.dma_handle, scsicmd->request_bufflen,
+#else
+		pci_unmap_single(dev->pdev, scsicmd->SCp.dma_handle, scsicmd->request_bufflen,
+#endif
+			scsicmd->sc_data_direction);
+#endif
+#endif
+	/* expose physical device if expose_physicald flag is on */
+	if(scsicmd->cmnd[0] == INQUIRY && !(scsicmd->cmnd[1] & 0x01) && expose_physicals > 0)
+		aac_expose_phy_device(scsicmd);
+
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+#if defined(__ESX5__)
+       if (scmd_channel(scsicmd) == 3) {
+               if (scsicmd->cmnd[0] == INQUIRY && !(scsicmd->cmnd[1] & 0x01)) {
+		char inq_data;
 
+		scsi_sg_copy_to_buffer(scsicmd,  &inq_data, sizeof(inq_data));
+	
+		if ((inq_data & 0x1F) == TYPE_ENCLOSURE)
+			inq_data |= 0x20;
+
+		scsi_sg_copy_from_buffer(scsicmd, &inq_data, sizeof(inq_data));
+	}
+       }
+#endif
+#endif
+
+	srbreply = (struct aac_srb_reply *) fib_data(fibptr);
 	scsicmd->sense_buffer[0] = '\0';  /* Initialize sense valid flag to false */
 
 	if (fibptr->flags & FIB_CONTEXT_FLAG_FASTRESP) {
@@ -2708,148 +5563,244 @@ static void aac_srb_callback(void *context, struct fib * fibptr)
 		 */
 		scsi_set_resid(scsicmd, scsi_bufflen(scsicmd)
 				   - le32_to_cpu(srbreply->data_xfer_length));
-	}
-
-	scsi_dma_unmap(scsicmd);
-
-	/* expose physical device if expose_physicald flag is on */
-	if (scsicmd->cmnd[0] == INQUIRY && !(scsicmd->cmnd[1] & 0x01)
-	  && expose_physicals > 0)
-		aac_expose_phy_device(scsicmd);
 
-	/*
-	 * First check the fib status
-	 */
+		/*
+	 	* First check the fib status
+		 */
 
-	if (le32_to_cpu(srbreply->status) != ST_OK){
-		int len;
-		printk(KERN_WARNING "aac_srb_callback: srb failed, status = %d\n", le32_to_cpu(srbreply->status));
-		len = min_t(u32, le32_to_cpu(srbreply->sense_data_size),
+		if (le32_to_cpu(srbreply->status) != ST_OK){
+			int len;
+			printk(KERN_WARNING "aac_srb_callback: srb failed, status = %d\n", le32_to_cpu(srbreply->status));
+			len = min_t(u32, le32_to_cpu(srbreply->sense_data_size),
 			    SCSI_SENSE_BUFFERSIZE);
-		scsicmd->result = DID_ERROR << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_CHECK_CONDITION;
-		memcpy(scsicmd->sense_buffer, srbreply->sense_data, len);
-	}
-
-	/*
-	 * Next check the srb status
-	 */
-	switch( (le32_to_cpu(srbreply->srb_status))&0x3f){
-	case SRB_STATUS_ERROR_RECOVERY:
-	case SRB_STATUS_PENDING:
-	case SRB_STATUS_SUCCESS:
-		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8;
-		break;
-	case SRB_STATUS_DATA_OVERRUN:
-		switch(scsicmd->cmnd[0]){
-		case  READ_6:
-		case  WRITE_6:
-		case  READ_10:
-		case  WRITE_10:
-		case  READ_12:
-		case  WRITE_12:
-		case  READ_16:
-		case  WRITE_16:
-			if (le32_to_cpu(srbreply->data_xfer_length) < scsicmd->underflow) {
-				printk(KERN_WARNING"aacraid: SCSI CMD underflow\n");
-			} else {
-				printk(KERN_WARNING"aacraid: SCSI CMD Data Overrun\n");
+			scsicmd->result = DID_ERROR << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_CHECK_CONDITION;
+			memcpy(scsicmd->sense_buffer, srbreply->sense_data, len);
+		}
+		
+		/*
+		 * Next check the srb status
+	 	*/
+		switch( (le32_to_cpu(srbreply->srb_status))&0x3f){
+		case SRB_STATUS_ERROR_RECOVERY:
+		case SRB_STATUS_PENDING:
+		case SRB_STATUS_SUCCESS:
+//#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,10)) || defined(BLIST_NO_ULD_ATTACH))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,14))
+			scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8;
+#else
+			if ((scsicmd->cmnd[0] == INQUIRY) && (expose_physicals <= 0)) {
+				u8 b;
+				/* We can't expose disk devices because we can't tell
+			 	* whether they are the raw container drives or stand
+			 	* alone drives.  If they have the removable bit set
+			 	* then we should expose them though.
+			 	*/
+				b = *((u8*)scsicmd->request_buffer);
+				if (((b & 0x1F) != TYPE_DISK) ||
+			  	(((u8*)scsicmd->request_buffer)[1] & 0x80) ||
+				/*
+			 	* We will allow disk devices if in RAID/SCSI mode and
+			 	* the channel is 2
+			 	*/
+			  	((dev->raid_scsi_mode) &&
+					(scmd_channel(scsicmd) == 2)) ||
+			  	(dev->jbod && !(b >> 5))) {
+					if (dev->jbod && ((b & 0x1F) == TYPE_DISK))
+						((u8*)scsicmd->request_buffer)[1] |=
+							1 << 7;
+					scsicmd->result = DID_OK << 16 |
+							COMMAND_COMPLETE << 8;
+				} else if (expose_physicals) {
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,7)) && !defined(BLIST_NO_ULD_ATTACH)))
+					scsicmd->device->no_uld_attach = (void *)1;
+#else
+					scsicmd->device->no_uld_attach = 1;
+#endif
+//#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,10)) && (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)))
+					/* Insurance */
+					(*(u8*)scsicmd->request_buffer) |= 1 << 5;
+//#endif
+					scsicmd->result = DID_OK << 16 |
+							COMMAND_COMPLETE << 8;
+				} else
+					scsicmd->result = DID_NO_CONNECT << 16 |
+							COMMAND_COMPLETE << 8;
+			} else
+				scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8;
+#endif
+			break;
+		case SRB_STATUS_DATA_OVERRUN:
+			switch(scsicmd->cmnd[0]){
+			case  READ_6:
+			case  WRITE_6:
+			case  READ_10:
+			case  WRITE_10:
+			case  READ_12:
+			case  WRITE_12:
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(READ_16))
+			case  READ_16:
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(WRITE_16))
+			case  WRITE_16:
+#endif
+				if (le32_to_cpu(srbreply->data_xfer_length) < scsicmd->underflow) {
+					printk(KERN_WARNING"aacraid: SCSI CMD underflow\n");
+				} else {
+					printk(KERN_WARNING"aacraid: SCSI CMD Data Overrun\n");
+				}
+				scsicmd->result = DID_ERROR << 16 | COMMAND_COMPLETE << 8;
+				break;
+			case INQUIRY: {
+//#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,10)) || defined(BLIST_NO_ULD_ATTACH))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,14))
+				scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8;
+#else
+				if (expose_physicals <= 0) {
+					/*
+				 	* We can't expose disk devices because we
+				 	* can't tell whether they are the raw
+				 	* container drives or stand alone drives
+				 	*/
+					u8 b = *((u8*)scsicmd->request_buffer);
+					if ((((b & 0x1f) != TYPE_DISK) ||
+				  	   (((u8*)scsicmd->request_buffer)[1] & 0x80)) ||
+					/*
+				 	* We will allow disk devices if in RAID/SCSI
+				 	* mode and the channel is 2
+				 	*/
+				  	((dev->raid_scsi_mode) &&
+						(scmd_channel(scsicmd) == 2)) ||
+				  	(dev->jbod && !(b >> 5))) {
+						if (dev->jbod && ((b & 0x1F) == TYPE_DISK))
+							((u8*)scsicmd->request_buffer)[1] |=
+								1 << 7;
+						scsicmd->result = DID_OK << 16 |
+							COMMAND_COMPLETE << 8;
+					} else if (expose_physicals) {
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,7)) && !defined(BLIST_NO_ULD_ATTACH)))
+						scsicmd->device->no_uld_attach = (void *)1;
+#else
+						scsicmd->device->no_uld_attach = 1;
+#endif
+//#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,10)) && (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)))
+						/* Insurance */
+						(*(u8*)scsicmd->request_buffer) |= 1 << 5;
+//#endif
+						scsicmd->result = DID_OK << 16 |
+								COMMAND_COMPLETE << 8;
+					} else
+						scsicmd->result = DID_NO_CONNECT << 16 |
+								COMMAND_COMPLETE << 8;
+				} else
+					scsicmd->result = DID_OK << 16 |
+							COMMAND_COMPLETE << 8;
+#endif
+				break;
+			}
+			default:
+				scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8;
+				break;
 			}
-			scsicmd->result = DID_ERROR << 16 | COMMAND_COMPLETE << 8;
 			break;
-		case INQUIRY: {
-			scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8;
+
+		case SRB_STATUS_ABORTED:
+			scsicmd->result = DID_ABORT << 16 | ABORT << 8;
 			break;
-		}
-		default:
-			scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8;
+		
+		case SRB_STATUS_ABORT_FAILED:
+			// Not sure about this one - but assuming the hba was trying to abort for some reason
+			scsicmd->result = DID_ERROR << 16 | ABORT << 8;
+			break;
+		
+		case SRB_STATUS_PARITY_ERROR:
+			scsicmd->result = DID_PARITY << 16 | MSG_PARITY_ERROR << 8;
+			break;
+	
+		case SRB_STATUS_NO_DEVICE:
+		case SRB_STATUS_INVALID_PATH_ID:
+		case SRB_STATUS_INVALID_TARGET_ID:
+		case SRB_STATUS_INVALID_LUN:
+		case SRB_STATUS_SELECTION_TIMEOUT:
+			scsicmd->result = DID_NO_CONNECT << 16 | COMMAND_COMPLETE << 8;
 			break;
-		}
-		break;
-	case SRB_STATUS_ABORTED:
-		scsicmd->result = DID_ABORT << 16 | ABORT << 8;
-		break;
-	case SRB_STATUS_ABORT_FAILED:
-		// Not sure about this one - but assuming the hba was trying to abort for some reason
-		scsicmd->result = DID_ERROR << 16 | ABORT << 8;
-		break;
-	case SRB_STATUS_PARITY_ERROR:
-		scsicmd->result = DID_PARITY << 16 | MSG_PARITY_ERROR << 8;
-		break;
-	case SRB_STATUS_NO_DEVICE:
-	case SRB_STATUS_INVALID_PATH_ID:
-	case SRB_STATUS_INVALID_TARGET_ID:
-	case SRB_STATUS_INVALID_LUN:
-	case SRB_STATUS_SELECTION_TIMEOUT:
-		scsicmd->result = DID_NO_CONNECT << 16 | COMMAND_COMPLETE << 8;
-		break;
 
-	case SRB_STATUS_COMMAND_TIMEOUT:
-	case SRB_STATUS_TIMEOUT:
-		scsicmd->result = DID_TIME_OUT << 16 | COMMAND_COMPLETE << 8;
-		break;
+		case SRB_STATUS_COMMAND_TIMEOUT:
+		case SRB_STATUS_TIMEOUT:
+			scsicmd->result = DID_TIME_OUT << 16 | COMMAND_COMPLETE << 8;
+			break;
 
-	case SRB_STATUS_BUSY:
-		scsicmd->result = DID_BUS_BUSY << 16 | COMMAND_COMPLETE << 8;
-		break;
+		case SRB_STATUS_BUSY:
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,10)) || defined(DID_BUS_BUSY))
+			scsicmd->result = DID_BUS_BUSY << 16 | COMMAND_COMPLETE << 8;
+#else
+			scsicmd->result = DID_NO_CONNECT << 16 | COMMAND_COMPLETE << 8;
+#endif
+			break;
 
-	case SRB_STATUS_BUS_RESET:
-		scsicmd->result = DID_RESET << 16 | COMMAND_COMPLETE << 8;
-		break;
+		case SRB_STATUS_BUS_RESET:
+			scsicmd->result = DID_RESET << 16 | COMMAND_COMPLETE << 8;
+			break;
 
-	case SRB_STATUS_MESSAGE_REJECTED:
-		scsicmd->result = DID_ERROR << 16 | MESSAGE_REJECT << 8;
-		break;
-	case SRB_STATUS_REQUEST_FLUSHED:
-	case SRB_STATUS_ERROR:
-	case SRB_STATUS_INVALID_REQUEST:
-	case SRB_STATUS_REQUEST_SENSE_FAILED:
-	case SRB_STATUS_NO_HBA:
-	case SRB_STATUS_UNEXPECTED_BUS_FREE:
-	case SRB_STATUS_PHASE_SEQUENCE_FAILURE:
-	case SRB_STATUS_BAD_SRB_BLOCK_LENGTH:
-	case SRB_STATUS_DELAYED_RETRY:
-	case SRB_STATUS_BAD_FUNCTION:
-	case SRB_STATUS_NOT_STARTED:
-	case SRB_STATUS_NOT_IN_USE:
-	case SRB_STATUS_FORCE_ABORT:
-	case SRB_STATUS_DOMAIN_VALIDATION_FAIL:
-	default:
-#ifdef AAC_DETAILED_STATUS_INFO
-		printk("aacraid: SRB ERROR(%u) %s scsi cmd 0x%x - scsi status 0x%x\n",
-			le32_to_cpu(srbreply->srb_status) & 0x3F,
-			aac_get_status_string(
-				le32_to_cpu(srbreply->srb_status) & 0x3F),
-			scsicmd->cmnd[0],
-			le32_to_cpu(srbreply->scsi_status));
-#endif
-		if ((scsicmd->cmnd[0] == ATA_12)
-		  || (scsicmd->cmnd[0] == ATA_16)) {
-			if (scsicmd->cmnd[2] & (0x01 << 5)) {
-				scsicmd->result = DID_OK << 16
-						| COMMAND_COMPLETE << 8;
-				break;
-			} else {
-				scsicmd->result = DID_ERROR << 16
-						| COMMAND_COMPLETE << 8;
-				break;
-			}
-		} else {
-			scsicmd->result = DID_ERROR << 16
-					| COMMAND_COMPLETE << 8;
+		case SRB_STATUS_MESSAGE_REJECTED:
+			scsicmd->result = DID_ERROR << 16 | MESSAGE_REJECT << 8;
 			break;
+
+		case SRB_STATUS_REQUEST_FLUSHED:
+		case SRB_STATUS_ERROR:
+		case SRB_STATUS_INVALID_REQUEST:
+		case SRB_STATUS_REQUEST_SENSE_FAILED:
+		case SRB_STATUS_NO_HBA:
+		case SRB_STATUS_UNEXPECTED_BUS_FREE:
+		case SRB_STATUS_PHASE_SEQUENCE_FAILURE:
+		case SRB_STATUS_BAD_SRB_BLOCK_LENGTH:
+		case SRB_STATUS_DELAYED_RETRY:
+		case SRB_STATUS_BAD_FUNCTION:
+		case SRB_STATUS_NOT_STARTED:
+		case SRB_STATUS_NOT_IN_USE:
+		case SRB_STATUS_FORCE_ABORT:
+		case SRB_STATUS_DOMAIN_VALIDATION_FAIL:
+		default:
+#ifdef AAC_DETAILED_STATUS_INFO
+			printk("aacraid: SRB ERROR(%u) %s scsi cmd 0x%x - scsi status 0x%x\n",
+				le32_to_cpu(srbreply->srb_status) & 0x3F,
+				aac_get_status_string(
+					le32_to_cpu(srbreply->srb_status) & 0x3F),
+				scsicmd->cmnd[0],
+				le32_to_cpu(srbreply->scsi_status));
+#endif
+			if((scsicmd->cmnd[0] == ATA_12) || (scsicmd->cmnd[0] == ATA_16)) {
+
+			/* 
+		 	* When the CC bit is SET by the host in ATA pass thru CDB, driver is supposed to return DID_OK
+		 	* When the CC bit is RESET by the host, driver should return DID_ERROR
+		 	*/
+            	if(scsicmd->cmnd[2] & (0x01 << 5)) {
+                	scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8;
+                    break;
+                }
+                else {
+                	scsicmd->result = DID_ERROR << 16 | COMMAND_COMPLETE << 8;
+                	break;
+                }
+            }
+            else {
+            	scsicmd->result = DID_ERROR << 16 | COMMAND_COMPLETE << 8;
+                	break;
+            }
 		}
-	}
-	if (le32_to_cpu(srbreply->scsi_status) == SAM_STAT_CHECK_CONDITION) {
-		int len;
-		scsicmd->result |= SAM_STAT_CHECK_CONDITION;
-		len = min_t(u32, le32_to_cpu(srbreply->sense_data_size),
-			    SCSI_SENSE_BUFFERSIZE);
+		if (le32_to_cpu(srbreply->scsi_status) == SAM_STAT_CHECK_CONDITION) {
+			int len;
+			scsicmd->result |= SAM_STAT_CHECK_CONDITION;
+			len = min_t(u32, le32_to_cpu(srbreply->sense_data_size),
+					SCSI_SENSE_BUFFERSIZE);
 #ifdef AAC_DETAILED_STATUS_INFO
-		printk(KERN_WARNING "aac_srb_callback: check condition, status = %d len=%d\n",
-					le32_to_cpu(srbreply->status), len);
+			printk(KERN_WARNING "aac_srb_callback: check condition, status = %d len=%d\n",
+						le32_to_cpu(srbreply->status), len);
 #endif
-		memcpy(scsicmd->sense_buffer, srbreply->sense_data, len);
+			memcpy(scsicmd->sense_buffer, srbreply->sense_data, len);
+		}
 	}
+
 	/*
 	 * OR in the scsi status (already shifted up a bit)
 	 */
@@ -2857,7 +5808,175 @@ static void aac_srb_callback(void *context, struct fib * fibptr)
 
 	aac_fib_complete(fibptr);
 	aac_fib_free(fibptr);
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+	aac_io_done(scsicmd);
+#else
 	scsicmd->scsi_done(scsicmd);
+#endif
+}
+
+/**
+ *
+ * aac_hba_callback
+ * @context: the context set in the fib - here it is scsi cmd
+ * @fibptr: pointer to the fib
+ *
+ * Handles the completion of a native HBA scsi command
+ *
+ */
+
+void aac_hba_callback(void *context, struct fib * fibptr)
+{
+	struct aac_dev *dev;
+	struct scsi_cmnd *scsicmd;
+
+	scsicmd = (struct scsi_cmnd *) context;
+
+	if (!aac_valid_context(scsicmd, fibptr))
+		return;
+
+	BUG_ON(fibptr == NULL);
+	dev = fibptr->dev;
+
+	if (!(fibptr->flags & FIB_CONTEXT_FLAG_NATIVE_HBA_TMF)) {
+#if (!defined(__VMKLNX30__) || defined(__x86_64__))
+		scsi_dma_unmap(scsicmd);
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+		if(!scsi_sg_count(scsicmd) && scsi_bufflen(scsicmd))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+			pci_unmap_single(dev->pdev, (dma_addr_t)
+			 scsicmd->SCp.dma_handle, scsicmd->request_bufflen,
+#else
+			pci_unmap_single(dev->pdev, 
+			 scsicmd->SCp.dma_handle, scsicmd->request_bufflen,
+#endif
+			 scsicmd->sc_data_direction);
+#endif
+#endif
+	}
+
+	if (fibptr->flags & FIB_CONTEXT_FLAG_FASTRESP) {
+		/* fast response */
+		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8;
+	} else {
+		struct aac_hba_resp *err = 
+			&((struct aac_native_hba *)fibptr->hw_fib_va)->resp.err;
+
+		BUG_ON(err->iu_type != HBA_IU_TYPE_RESP);
+		if (err->service_response == HBA_RESP_SVCRES_TASK_COMPLETE) {
+			scsicmd->result = err->status;
+			/* set residual count */
+			scsi_set_resid(scsicmd, 
+				le32_to_cpu(err->residual_count));
+	
+			switch (err->status) {
+			case SAM_STAT_GOOD:
+				scsicmd->result |= DID_OK << 16 |
+					COMMAND_COMPLETE << 8;
+				break;
+			case SAM_STAT_CHECK_CONDITION:
+			{
+				int len;
+
+				len = min_t(u8, err->sense_response_data_len,
+					SCSI_SENSE_BUFFERSIZE);
+				if (len)
+					memcpy(scsicmd->sense_buffer, 
+						err->sense_response_buf, len);
+				scsicmd->result |= DID_OK << 16 |
+					COMMAND_COMPLETE << 8;
+				break;
+			}
+			case SAM_STAT_BUSY:
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,10)) || defined(DID_BUS_BUSY))
+				scsicmd->result |= DID_BUS_BUSY << 16 | 
+					COMMAND_COMPLETE << 8;
+#else
+				scsicmd->result |= DID_NO_CONNECT << 16 | 
+					COMMAND_COMPLETE << 8;
+#endif
+			case SAM_STAT_TASK_ABORTED:
+				scsicmd->result |= DID_ABORT << 16 |
+					ABORT << 8;
+				break;
+			case SAM_STAT_RESERVATION_CONFLICT:
+			case SAM_STAT_TASK_SET_FULL:
+			default:	
+				scsicmd->result |= DID_ERROR << 16 |
+					COMMAND_COMPLETE << 8;
+				break;
+			}
+		} else if (err->service_response == HBA_RESP_SVCRES_FAILURE) {
+			switch (err->status) {
+			case HBA_RESP_STAT_HBAMODE_DISABLED:
+			{	
+				u32 bus, cid;
+
+				bus=aac_logical_to_phys(scmd_channel(scsicmd));
+				cid=scmd_id(scsicmd);
+				if (dev->hba_map[bus][cid].devtype ==
+					AAC_DEVTYPE_NATIVE_RAW) {
+					dev->hba_map[bus][cid].devtype =
+						AAC_DEVTYPE_ARC_RAW;
+					dev->hba_map[bus][cid].rmw_nexus =
+						0xffffffff;
+				}
+				scsicmd->result = DID_NO_CONNECT << 16 |
+					COMMAND_COMPLETE << 8;
+				break;	
+			}
+			case HBA_RESP_STAT_IO_ERROR:
+			case HBA_RESP_STAT_NO_PATH_TO_DEVICE:
+				scsicmd->result = DID_OK << 16 |
+					COMMAND_COMPLETE << 8 | SAM_STAT_BUSY;
+				break;
+			case HBA_RESP_STAT_IO_ABORTED:
+				scsicmd->result = DID_ABORT << 16 |
+					ABORT << 8;
+				break;
+			case HBA_RESP_STAT_INVALID_DEVICE:
+				scsicmd->result = DID_NO_CONNECT << 16 |
+					COMMAND_COMPLETE << 8;
+				break;
+			case HBA_RESP_STAT_UNDERRUN:
+			case HBA_RESP_STAT_OVERRUN:
+			default:	
+				scsicmd->result = DID_ERROR << 16 |
+					COMMAND_COMPLETE << 8;
+				break;
+			}
+		} else if (err->service_response ==
+			HBA_RESP_SVCRES_TMF_REJECTED) {
+			scsicmd->result = 
+				DID_ERROR << 16 | MESSAGE_REJECT << 8;
+		} else if (err->service_response ==
+			HBA_RESP_SVCRES_TMF_LUN_INVALID) {
+			scsicmd->result = 
+				DID_NO_CONNECT << 16 | COMMAND_COMPLETE << 8;
+		} else if ((err->service_response ==
+			HBA_RESP_SVCRES_TMF_COMPLETE) ||
+			(err->service_response ==
+			HBA_RESP_SVCRES_TMF_SUCCEEDED)) {
+			scsicmd->result = 
+				DID_OK << 16 | COMMAND_COMPLETE << 8;
+		} else {
+			scsicmd->result = 
+				DID_ERROR << 16 | COMMAND_COMPLETE << 8;
+		}
+	}
+
+	aac_fib_complete(fibptr);
+	aac_fib_free(fibptr);
+
+	if (fibptr->flags & FIB_CONTEXT_FLAG_NATIVE_HBA_TMF) {
+		scsicmd->SCp.sent_command = 1;
+	} else {
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		aac_io_done(scsicmd);
+#else
+		scsicmd->scsi_done(scsicmd);
+#endif
+	}
 }
 
 /**
@@ -2877,9 +5996,13 @@ static int aac_send_srb_fib(struct scsi_cmnd* scsicmd)
 
 	dev = (struct aac_dev *)scsicmd->device->host->hostdata;
 	if (scmd_id(scsicmd) >= dev->maximum_num_physicals ||
-			scsicmd->device->lun > 7) {
+			scsicmd->device->lun > AAC_MAX_LUN - 1) {
 		scsicmd->result = DID_NO_CONNECT << 16;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(scsicmd);
+#else
 		scsicmd->scsi_done(scsicmd);
+#endif
 		return 0;
 	}
 
@@ -2906,13 +6029,74 @@ static int aac_send_srb_fib(struct scsi_cmnd* scsicmd)
 	return -1;
 }
 
-static long aac_build_sg(struct scsi_cmnd *scsicmd, struct sgmap *psg)
+/**
+ *
+ * aac_send_hba_fib
+ * @scsicmd: the scsi command block
+ *
+ * This routine will form a FIB and fill in the aac_hba_cmd_req from the
+ * scsicmd passed in.
+ */
+
+static int aac_send_hba_fib(struct scsi_cmnd* scsicmd)
+{
+	struct fib* cmd_fibcontext;
+	struct aac_dev* dev;
+	int status;
+
+	dev = (struct aac_dev *)scsicmd->device->host->hostdata;
+	if (scmd_id(scsicmd) >= dev->maximum_num_physicals ||
+			scsicmd->device->lun > AAC_MAX_LUN - 1) {
+		scsicmd->result = DID_NO_CONNECT << 16;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING) || defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		__aac_io_done(scsicmd);
+#else
+		scsicmd->scsi_done(scsicmd);
+#endif
+		return 0;
+	}
+
+	/*
+	 *	Allocate and initialize a Fib then setup a BlockWrite command
+	 */
+	if (!(cmd_fibcontext = aac_fib_alloc(dev))) {
+		return -1;
+	}
+	status = aac_adapter_hba(cmd_fibcontext, scsicmd);
+
+	/*
+	 *	Check that the command queued to the controller
+	 */
+	if (status == -EINPROGRESS) {
+		scsicmd->SCp.phase = AAC_OWNER_FIRMWARE;
+		return 0;
+	}
+
+	printk(KERN_WARNING "aac_hba_cmd_req: aac_fib_send failed with status: %d\n", status);
+	aac_fib_complete(cmd_fibcontext);
+	aac_fib_free(cmd_fibcontext);
+
+	return -1;
+}
+
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+static int aac_build_sg(struct scsi_cmnd* scsicmd, struct sgmap* psg)
+#else
+static long aac_build_sg(struct scsi_cmnd* scsicmd, struct sgmap* psg)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	struct Scsi_Host *host = scsicmd->device->host;
+#endif
 	struct aac_dev *dev;
 	unsigned long byte_count = 0;
 	int nseg;
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	dev = (struct aac_dev *)host->hostdata;
+#else
 	dev = (struct aac_dev *)scsicmd->device->host->hostdata;
+#endif
 	// Get rid of old data
 	psg->count = 0;
 	psg->sg[0].addr = 0;
@@ -2924,14 +6108,75 @@ static long aac_build_sg(struct scsi_cmnd *scsicmd, struct sgmap *psg)
 	if (nseg) {
 		struct scatterlist *sg;
 		int i;
+#if (defined(AAC_DEBUG_INSTRUMENT_SG) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)))
+		int nseg_hold = nseg;
+#endif
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 		psg->count = cpu_to_le32(nseg);
 
-		scsi_for_each_sg(scsicmd, sg, nseg, i) {
+#endif
+		scsi_for_each_sg(scsicmd, sg, nseg, i) {
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || defined(AAC_DEBUG_INSTRUMENT_SG_PROBE) || defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+			int count = sg_dma_len(sg);
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+			u32 addr = sg_dma_address(sg);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SG_PROBE))
+			char c = ((char *)sg->page + sg->offset)[0];
+			c = ((char *)sg->page + sg->offset)[count-1];
+#endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__))
+			vmk_verify_memory_for_io(addr, count);
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+			if (!(dev->adapter_info.options & AAC_OPT_NEW_COMM))
+			while (count > 65536) {
+				psg->sg[i].addr = cpu_to_le32(addr);
+				psg->sg[i].count = cpu_to_le32(65536);
+				++i;
+				if (++nseg > host->sg_tablesize) {
+#if (defined(AAC_DEBUG_INSTRUMENT_SG))
+					printk(KERN_INFO
+					  "SG List[%d] too large based on original[%d]:\n",
+					  nseg, nseg_hold);
+					sg = (struct scatterlist *) scsicmd->request_buffer;
+					for (i = 0; i < nseg_hold; i++) {
+						printk(KERN_INFO "0x%llx[%d] ",
+						  (u64)(sg_dma_address(sg)),
+						  (int)(sg_dma_len(sg)));
+						++sg;
+					}
+					printk(KERN_INFO "...\n");
+#endif
+					BUG();
+				}
+				byte_count += 65536;
+				addr += 65536;
+				count -= 65536;
+			}
+
+			psg->sg[i].addr = cpu_to_le32(addr);
+			psg->sg[i].count = cpu_to_le32(count);
+			byte_count += count;
+#else
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+			psg->sg[i].addr = cpu_to_le32(addr);
+#else
 			psg->sg[i].addr = cpu_to_le32(sg_dma_address(sg));
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SG_PROBE) || defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+			psg->sg[i].count = cpu_to_le32(count);
+#else
 			psg->sg[i].count = cpu_to_le32(sg_dma_len(sg));
+#endif
 			byte_count += sg_dma_len(sg);
+#endif
 		}
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		psg->count = cpu_to_le32(nseg);
+#endif
 		/* hba wants the size to be exact */
 		if (byte_count > scsi_bufflen(scsicmd)) {
 			u32 temp = le32_to_cpu(psg->sg[i-1].count) -
@@ -2945,18 +6190,112 @@ static long aac_build_sg(struct scsi_cmnd *scsicmd, struct sgmap *psg)
 					byte_count, scsicmd->underflow);
 		}
 	}
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+	else if(scsicmd->request_bufflen) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		int i, count;
+#endif
+		u32 addr;
+#if (defined(AAC_DEBUG_INSTRUMENT_SG_PROBE))
+		char c = ((char *)scsicmd->request_buffer)[0];
+		c = ((char *)scsicmd->request_buffer)[scsicmd->request_bufflen-1];
+#endif
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__x86_64__))
+		scsicmd->SCp.dma_handle = scsicmd->request_bufferMA;
+		vmk_verify_memory_for_io(scsicmd->request_bufferMA, scsicmd->request_bufflen);
+#else
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		scsicmd->SCp.dma_handle = (char *)(uintptr_t)pci_map_single(dev->pdev,
+#else
+		scsicmd->SCp.dma_handle = pci_map_single(dev->pdev,
+#endif
+				scsicmd->request_buffer,
+				scsicmd->request_bufflen,
+				scsicmd->sc_data_direction);
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		addr = (u32)(uintptr_t)scsicmd->SCp.dma_handle;
+#else
+		addr = scsicmd->SCp.dma_handle;
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		count = scsicmd->request_bufflen;
+		i = 0;
+		if (!(dev->adapter_info.options & AAC_OPT_NEW_COMM))
+		while (count > 65536) {
+			psg->sg[i].addr = cpu_to_le32(addr);
+			psg->sg[i].count = cpu_to_le32(65536);
+			if (++i >= host->sg_tablesize) {
+#if (defined(AAC_DEBUG_INSTRUMENT_SG))
+				printk(KERN_INFO
+				  "SG List[%d] too large based on original single element %d in size\n",
+				  i, scsicmd->request_bufflen);
+#endif
+				BUG();
+			}
+			addr += 65536;
+			count -= 65536;
+		}
+		psg->count = cpu_to_le32(1+i);
+		psg->sg[i].addr = cpu_to_le32(addr);
+		psg->sg[i].count = cpu_to_le32(count);
+#else
+		psg->count = cpu_to_le32(1);
+		psg->sg[0].addr = cpu_to_le32(addr);
+		psg->sg[0].count = cpu_to_le32(scsicmd->request_bufflen);
+#endif
+		byte_count = scsicmd->request_bufflen;
+	}
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SG))
+{
+	int i, nseg = le32_to_cpu(psg->count);
+	printk("aac_build_sg:");
+	for (i = 0; i < nseg; i++) {
+		int count = le32_to_cpu(psg->sg[i].count);
+		u32 addr = le32_to_cpu(psg->sg[i].addr);
+		printk(" %x[%d]", addr, count);
+	}
+	printk ("\n");
+}
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+	if (le32_to_cpu(psg->count) > aac_config.peak_sg) {
+		aac_config.peak_sg = le32_to_cpu(psg->count);
+		printk ("peak_sg=%u\n", aac_config.peak_sg);
+	}
+	if (byte_count > aac_config.peak_size) {
+		aac_config.peak_size = byte_count;
+		printk ("peak_size=%u\n", aac_config.peak_size);
+	}
+#endif
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	return le32_to_cpu(psg->count);
+#else
 	return byte_count;
+#endif
 }
 
 
-static long aac_build_sg64(struct scsi_cmnd *scsicmd, struct sgmap64 *psg)
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+static int aac_build_sg64(struct scsi_cmnd* scsicmd, struct sgmap64* psg)
+#else
+static long aac_build_sg64(struct scsi_cmnd* scsicmd, struct sgmap64* psg)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	struct Scsi_Host *host = scsicmd->device->host;
+#endif
 	struct aac_dev *dev;
 	unsigned long byte_count = 0;
 	u64 addr;
 	int nseg;
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	dev = (struct aac_dev *)host->hostdata;
+#else
 	dev = (struct aac_dev *)scsicmd->device->host->hostdata;
+#endif
 	// Get rid of old data
 	psg->count = 0;
 	psg->sg[0].addr[0] = 0;
@@ -2969,10 +6308,48 @@ static long aac_build_sg64(struct scsi_cmnd *scsicmd, struct sgmap64 *psg)
 	if (nseg) {
 		struct scatterlist *sg;
 		int i;
+#if (defined(AAC_DEBUG_INSTRUMENT_SG) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)))
+		int nseg_hold = nseg;
+#endif
 
 		scsi_for_each_sg(scsicmd, sg, nseg, i) {
 			int count = sg_dma_len(sg);
 			addr = sg_dma_address(sg);
+#if (defined(AAC_DEBUG_INSTRUMENT_SG_PROBE))
+			char c = ((char *)sg->page + sg->offset)[0];
+			c = ((char *)sg->page + sg->offset)[count-1];
+#endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__))
+			vmk_verify_memory_for_io(addr, count);
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+			if (!(dev->adapter_info.options & AAC_OPT_NEW_COMM))
+			while (count > 65536) {
+				psg->sg[i].addr[1] = cpu_to_le32((u32)(addr>>32));
+				psg->sg[i].addr[0] = cpu_to_le32((u32)(addr & 0xffffffff));
+				psg->sg[i].count = cpu_to_le32(65536);
+				++i;
+				if (++nseg > host->sg_tablesize) {
+#if (defined(AAC_DEBUG_INSTRUMENT_SG))
+					printk(KERN_INFO
+					  "SG List[%d] too large based on original[%d]:\n",
+					  nseg, nseg_hold);
+					sg = (struct scatterlist *) scsicmd->request_buffer;
+					for (i = 0; i < nseg_hold; i++) {
+						printk(KERN_INFO "0x%llx[%d] ",
+						  (u64)sg_dma_address(sg),
+						  (int)sg_dma_len(sg));
+						++sg;
+					}
+					printk(KERN_INFO "...\n");
+#endif
+					BUG();
+				}
+				byte_count += 65536;
+				addr += 65536;
+				count -= 65536;
+			}
+#endif
 			psg->sg[i].addr[0] = cpu_to_le32(addr & 0xffffffff);
 			psg->sg[i].addr[1] = cpu_to_le32(addr>>32);
 			psg->sg[i].count = cpu_to_le32(count);
@@ -2992,10 +6369,104 @@ static long aac_build_sg64(struct scsi_cmnd *scsicmd, struct sgmap64 *psg)
 					byte_count, scsicmd->underflow);
 		}
 	}
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+	else if(scsicmd->request_bufflen) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		int i;
+		int count;
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SG_PROBE))
+		char c = ((char *)scsicmd->request_buffer)[0];
+		c = ((char *)scsicmd->request_buffer)[scsicmd->request_bufflen-1];
+#endif
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__x86_64__))
+		scsicmd->SCp.dma_handle = scsicmd->request_bufferMA;
+		vmk_verify_memory_for_io(scsicmd->request_bufferMA, scsicmd->request_bufflen);
+#else
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		scsicmd->SCp.dma_handle = (char *)(uintptr_t)pci_map_single(dev->pdev,
+#else
+		scsicmd->SCp.dma_handle = pci_map_single(dev->pdev,
+#endif
+				scsicmd->request_buffer,
+				scsicmd->request_bufflen,
+				scsicmd->sc_data_direction);
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		addr = (u64)(uintptr_t)scsicmd->SCp.dma_handle;
+#else
+		addr = scsicmd->SCp.dma_handle;
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		count = scsicmd->request_bufflen;
+		i = 0;
+		if (!(dev->adapter_info.options & AAC_OPT_NEW_COMM))
+		while (count > 65536) {
+			psg->sg[i].addr[1] = cpu_to_le32((u32)(addr>>32));
+			psg->sg[i].addr[0] = cpu_to_le32((u32)(addr & 0xffffffff));
+			psg->sg[i].count = cpu_to_le32(65536);
+			if (++i >= host->sg_tablesize) {
+#if (defined(AAC_DEBUG_INSTRUMENT_SG))
+				printk(KERN_INFO
+				  "SG List[%d] too large based on original single element %d in size\n",
+				  i, scsicmd->request_bufflen);
+#endif
+				BUG();
+			}
+			addr += 65536;
+			count -= 65536;
+		}
+		psg->count = cpu_to_le32(1+i);
+		psg->sg[i].addr[0] = cpu_to_le32(addr & 0xffffffff);
+		psg->sg[i].addr[1] = cpu_to_le32(addr >> 32);
+		psg->sg[i].count = cpu_to_le32(count);
+#else
+		psg->count = cpu_to_le32(1);
+		psg->sg[0].addr[0] = cpu_to_le32(addr & 0xffffffff);
+		psg->sg[0].addr[1] = cpu_to_le32(addr >> 32);
+		psg->sg[0].count = cpu_to_le32(scsicmd->request_bufflen);
+#endif
+		byte_count = scsicmd->request_bufflen;
+	}
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SG))
+{
+	int i, nseg = le32_to_cpu(psg->count);
+	printk("aac_build_sg64:");
+	for (i = 0; i < nseg; i++) {
+		int count = le32_to_cpu(psg->sg[i].count);
+		u32 addr0 = le32_to_cpu(psg->sg[i].addr[0]);
+		u32 addr1 = le32_to_cpu(psg->sg[i].addr[1]);
+		if (addr1 == 0)
+			printk(" %x[%d]", addr0, count);
+		else
+			printk(" %x%08x[%d]", addr1, addr0, count);
+	}
+	printk ("\n");
+}
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+	if (le32_to_cpu(psg->count) > aac_config.peak_sg) {
+		aac_config.peak_sg = le32_to_cpu(psg->count);
+		printk ("peak_sg=%u\n", aac_config.peak_sg);
+	}
+	if (byte_count > aac_config.peak_size) {
+		aac_config.peak_size = byte_count;
+		printk ("peak_size=%u\n", aac_config.peak_size);
+	}
+#endif
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	return le32_to_cpu(psg->count);
+#else
 	return byte_count;
+#endif
 }
 
-static long aac_build_sgraw(struct scsi_cmnd *scsicmd, struct sgmapraw *psg)
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+static int aac_build_sgraw(struct scsi_cmnd* scsicmd, struct sgmapraw* psg)
+#else
+static long aac_build_sgraw(struct scsi_cmnd* scsicmd, struct sgmapraw* psg)
+#endif
 {
 	unsigned long byte_count = 0;
 	int nseg;
@@ -3019,6 +6490,10 @@ static long aac_build_sgraw(struct scsi_cmnd *scsicmd, struct sgmapraw *psg)
 		scsi_for_each_sg(scsicmd, sg, nseg, i) {
 			int count = sg_dma_len(sg);
 			u64 addr = sg_dma_address(sg);
+#if (defined(AAC_DEBUG_INSTRUMENT_SG_PROBE))
+			char c = ((char *)sg->page + sg->offset)[0];
+			c = ((char *)sg->page + sg->offset)[count-1];
+#endif
 			psg->sg[i].next = 0;
 			psg->sg[i].prev = 0;
 			psg->sg[i].addr[1] = cpu_to_le32((u32)(addr>>32));
@@ -3041,11 +6516,68 @@ static long aac_build_sgraw(struct scsi_cmnd *scsicmd, struct sgmapraw *psg)
 					byte_count, scsicmd->underflow);
 		}
 	}
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+	else if(scsicmd->request_bufflen) {
+#if ((!defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__)) || defined(__VMKLNX__))
+		struct aac_dev *dev = (struct aac_dev *)scsicmd->device->host->hostdata;
+#endif
+		int count;
+		u64 addr;
+#if (defined(AAC_DEBUG_INSTRUMENT_SG_PROBE))
+		char c = ((char *)scsicmd->request_buffer)[0];
+		c = ((char *)scsicmd->request_buffer)[scsicmd->request_bufflen-1];
+#endif
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__x86_64__))
+		scsicmd->SCp.dma_handle = scsicmd->request_bufferMA;
+		vmk_verify_memory_for_io(scsicmd->request_bufferMA, scsicmd->request_bufflen);
+#else
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		scsicmd->SCp.dma_handle = (char *)(uintptr_t)pci_map_single(dev->pdev,
+#else
+		scsicmd->SCp.dma_handle = pci_map_single(dev->pdev,
+#endif
+				scsicmd->request_buffer,
+				scsicmd->request_bufflen,
+				scsicmd->sc_data_direction);
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		addr = (u64)(uintptr_t)scsicmd->SCp.dma_handle;
+#else
+		addr = scsicmd->SCp.dma_handle;
+#endif
+		count = scsicmd->request_bufflen;
+		psg->count = cpu_to_le32(1);
+		psg->sg[0].next = 0;
+		psg->sg[0].prev = 0;
+		psg->sg[0].addr[1] = cpu_to_le32((u32)(addr>>32));
+		psg->sg[0].addr[0] = cpu_to_le32((u32)(addr & 0xffffffff));
+		psg->sg[0].count = cpu_to_le32(count);
+		psg->sg[0].flags = 0;
+		byte_count = scsicmd->request_bufflen;
+	}
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+	if (le32_to_cpu(psg->count) > aac_config.peak_sg) {
+		aac_config.peak_sg = le32_to_cpu(psg->count);
+		printk ("peak_sg=%u\n", aac_config.peak_sg);
+	}
+	if (byte_count > aac_config.peak_size) {
+		aac_config.peak_size = byte_count;
+		printk ("peak_size=%u\n", aac_config.peak_size);
+	}
+#endif
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	return le32_to_cpu(psg->count);
+#else
 	return byte_count;
+#endif
 }
 
-static long aac_build_sgraw2(struct scsi_cmnd *scsicmd,
-				struct aac_raw_io2 *rio2, int sg_max)
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+static int aac_build_sgraw2(struct scsi_cmnd* scsicmd, struct aac_raw_io2* rio2, int sg_max)
+#else
+static long aac_build_sgraw2(struct scsi_cmnd* scsicmd, struct aac_raw_io2* rio2, int sg_max)
+#endif
 {
 	unsigned long byte_count = 0;
 	int nseg;
@@ -3061,7 +6593,10 @@ static long aac_build_sgraw2(struct scsi_cmnd *scsicmd,
 		scsi_for_each_sg(scsicmd, sg, nseg, i) {
 			int count = sg_dma_len(sg);
 			u64 addr = sg_dma_address(sg);
-
+#if (defined(AAC_DEBUG_INSTRUMENT_SG_PROBE))
+			char c = ((char *)sg->page + sg->offset)[0];
+			c = ((char *)sg->page + sg->offset)[count-1];
+#endif
 			BUG_ON(i >= sg_max);
 			rio2->sge[i].addrHigh = cpu_to_le32((u32)(addr>>32));
 			rio2->sge[i].addrLow = cpu_to_le32((u32)(addr & 0xffffffff));
@@ -3114,16 +6649,69 @@ static long aac_build_sgraw2(struct scsi_cmnd *scsicmd,
 			rio2->flags |= cpu_to_le16(RIO2_SGL_CONFORMANT);
 
 		/* Check for command underflow */
-		if (scsicmd->underflow && (byte_count < scsicmd->underflow)) {
+		if(scsicmd->underflow && (byte_count < scsicmd->underflow)){
 			printk(KERN_WARNING"aacraid: cmd len %08lX cmd underflow %08X\n",
 					byte_count, scsicmd->underflow);
 		}
 	}
-
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+	else if(scsicmd->request_bufflen) {
+#if ((!defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__)) || defined(__VMKLNX__))
+		struct aac_dev *dev = (struct aac_dev *)scsicmd->device->host->hostdata;
+#endif
+		int count;
+		u64 addr;
+#if (defined(AAC_DEBUG_INSTRUMENT_SG_PROBE))
+		char c = ((char *)scsicmd->request_buffer)[0];
+		c = ((char *)scsicmd->request_buffer)[scsicmd->request_bufflen-1];
+#endif
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__x86_64__))
+		scsicmd->SCp.dma_handle = scsicmd->request_bufferMA;
+		vmk_verify_memory_for_io(scsicmd->request_bufferMA, scsicmd->request_bufflen);
+#else
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		scsicmd->SCp.dma_handle = (char *)(uintptr_t)pci_map_single(dev->pdev,
+#else
+		scsicmd->SCp.dma_handle = pci_map_single(dev->pdev,
+#endif
+				scsicmd->request_buffer,
+				scsicmd->request_bufflen,
+				scsicmd->sc_data_direction);
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		addr = (u64)(uintptr_t)scsicmd->SCp.dma_handle;
+#else
+		addr = scsicmd->SCp.dma_handle;
+#endif
+		count = scsicmd->request_bufflen;
+		rio2->sgeCnt = cpu_to_le32(1);
+		rio2->sge[0].addrHigh = cpu_to_le32((u32)(addr>>32));
+		rio2->sge[0].addrLow = cpu_to_le32((u32)(addr & 0xffffffff));
+		rio2->sge[0].length = cpu_to_le32(count);
+		rio2->sge[0].flags = 0;
+		rio2->sgeFirstSize = cpu_to_le32(count);
+		rio2->flags |= cpu_to_le16(RIO2_SGL_CONFORMANT|RIO2_SG_FORMAT_IEEE1212);
+		byte_count = scsicmd->request_bufflen;
+	}
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+	if (le32_to_cpu(psg->count) > aac_config.peak_sg) {
+		aac_config.peak_sg = le32_to_cpu(psg->count);
+		printk ("peak_sg=%u\n", aac_config.peak_sg);
+	}
+	if (byte_count > aac_config.peak_size) {
+		aac_config.peak_size = byte_count;
+		printk ("peak_size=%u\n", aac_config.peak_size);
+	}
+#endif
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	return le32_to_cpu(psg->count);
+#else
 	return byte_count;
+#endif
 }
 
-static int aac_convert_sgraw2(struct aac_raw_io2 *rio2, int pages, int nseg, int nseg_new)
+static int aac_convert_sgraw2(struct aac_raw_io2* rio2, int pages, int nseg, int nseg_new)
 {
 	struct sge_ieee1212 *sge;
 	int i, j, pos;
@@ -3133,7 +6721,7 @@ static int aac_convert_sgraw2(struct aac_raw_io2 *rio2, int pages, int nseg, int
 		return 0;
 
 	sge = kmalloc(nseg_new * sizeof(struct sge_ieee1212), GFP_ATOMIC);
-	if (sge == NULL)
+	if (sge == NULL) 
 		return -1;
 
 	for (i = 1, pos = 1; i < nseg-1; ++i) {
@@ -3158,6 +6746,417 @@ static int aac_convert_sgraw2(struct aac_raw_io2 *rio2, int pages, int nseg, int
 	return 0;
 }
 
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+static int aac_build_sghba(struct scsi_cmnd* scsicmd, struct aac_hba_cmd_req * hbacmd, int sg_max, u64 sg_address)
+#else
+static long aac_build_sghba(struct scsi_cmnd* scsicmd, struct aac_hba_cmd_req * hbacmd, int sg_max, u64 sg_address)
+#endif
+{
+	unsigned long byte_count = 0;
+	int nseg;
+
+	nseg = scsi_dma_map(scsicmd);
+	if (nseg < 0)
+		return nseg;
+	if (nseg) {
+		struct scatterlist *sg;
+		int i;
+		u32 cur_size;
+		struct aac_hba_sgl *sge;
+
+		if (nseg > HBA_MAX_SG_EMBEDDED)
+			sge = &hbacmd->sge[2];
+		else
+			sge = &hbacmd->sge[0];
+		scsi_for_each_sg(scsicmd, sg, nseg, i) {
+			int count = sg_dma_len(sg);
+			u64 addr = sg_dma_address(sg);
+#if (defined(AAC_DEBUG_INSTRUMENT_SG_PROBE))
+			char c = ((char *)sg->page + sg->offset)[0];
+			c = ((char *)sg->page + sg->offset)[count-1];
+#endif
+			BUG_ON(i >= sg_max);
+			sge->addr_hi = cpu_to_le32((u32)(addr>>32));
+			sge->addr_lo = cpu_to_le32((u32)(addr & 0xffffffff));
+			cur_size = cpu_to_le32(count);
+			sge->len = cur_size;
+			sge->flags = 0;
+			byte_count += count;
+			sge++;
+		}
+
+		sge--;
+		/* hba wants the size to be exact */
+		if (byte_count > scsi_bufflen(scsicmd)) {
+			u32 temp = le32_to_cpu(sge->len) -
+				(byte_count - scsi_bufflen(scsicmd));
+			sge->len = cpu_to_le32(temp);
+			byte_count = scsi_bufflen(scsicmd);
+		}
+
+		if (nseg <= HBA_MAX_SG_EMBEDDED) {
+			hbacmd->emb_data_desc_count = cpu_to_le32(nseg);
+			sge->flags = cpu_to_le32(0x40000000);
+		} else {
+			/* not embedded */
+			hbacmd->sge[0].flags = cpu_to_le32(0x80000000);
+			hbacmd->emb_data_desc_count = cpu_to_le32(1);
+			hbacmd->sge[0].addr_hi = 
+				cpu_to_le32((u32)(sg_address >> 32));
+			hbacmd->sge[0].addr_lo = 
+				cpu_to_le32((u32)(sg_address & 0xffffffff));
+		}
+
+		/* Check for command underflow */
+		if(scsicmd->underflow && (byte_count < scsicmd->underflow)){
+			printk(KERN_WARNING"aacraid: cmd len %08lX cmd underflow %08X\n",
+					byte_count, scsicmd->underflow);
+		}
+	}
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+	else if(scsicmd->request_bufflen) {
+#if ((!defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__)) || defined(__VMKLNX__))
+		struct aac_dev *dev = (struct aac_dev *)scsicmd->device->host->hostdata;
+#endif
+		int count;
+		u64 addr;
+#if (defined(AAC_DEBUG_INSTRUMENT_SG_PROBE))
+		char c = ((char *)scsicmd->request_buffer)[0];
+		c = ((char *)scsicmd->request_buffer)[scsicmd->request_bufflen-1];
+#endif
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__x86_64__))
+		scsicmd->SCp.dma_handle = scsicmd->request_bufferMA;
+		vmk_verify_memory_for_io(scsicmd->request_bufferMA, scsicmd->request_bufflen);
+#else
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		scsicmd->SCp.dma_handle = (char *)(uintptr_t)pci_map_single(dev->pdev,
+#else
+		scsicmd->SCp.dma_handle = pci_map_single(dev->pdev,
+#endif
+				scsicmd->request_buffer,
+				scsicmd->request_bufflen,
+				scsicmd->sc_data_direction);
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		addr = (u64)(uintptr_t)scsicmd->SCp.dma_handle;
+#else
+		addr = scsicmd->SCp.dma_handle;
+#endif
+		count = scsicmd->request_bufflen;
+		hbacmd->emb_data_desc_count = cpu_to_le32(1);
+		hbacmd->sge[0].addr_hi = cpu_to_le32((u32)(addr>>32));
+		hbacmd->sge[0].addr_lo = cpu_to_le32((u32)(addr & 0xffffffff));
+		hbacmd->sge[0].len = cpu_to_le32(count);
+		hbacmd->sge[0].flags = cpu_to_le32(0x40000000);
+		byte_count = scsicmd->request_bufflen;
+	}
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+	if (le32_to_cpu(psg->count) > aac_config.peak_sg) {
+		aac_config.peak_sg = le32_to_cpu(psg->count);
+		printk ("peak_sg=%u\n", aac_config.peak_sg);
+	}
+	if (byte_count > aac_config.peak_size) {
+		aac_config.peak_size = byte_count;
+		printk ("peak_size=%u\n", aac_config.peak_size);
+	}
+#endif
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	return le32_to_cpu(psg->count);
+#else
+	return byte_count;
+#endif
+}
+
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+
+int aac_build_sg_nark(struct fib * fib, struct scsi_cmnd* scsicmd, union aac_apre_embedded_sglist* psg)
+{
+	struct aac_dev *dev = fib->dev;
+	struct aac_apre_element_nark * sglist = &(psg->nark.FirstElement);
+#if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+	unsigned long byte_count = 0;
+#endif
+	int nseg = scsi_dma_map(scsicmd);
+	BUG_ON(nseg < 0);
+
+	if (nseg) {
+		struct scatterlist *sg;
+		int i;
+
+		scsi_for_each_sg(scsicmd, sg, nseg, i) {
+			int count = sg_dma_len(sg);
+			u64 addr;
+			if (i == (sizeof(psg->nark)/sizeof(*sglist))) {
+				int Index = fib->hw_fib_va - dev->hw_fib_va;
+				struct hw_apre * frame = (struct hw_apre *)&dev->hw_fib_va[Index];
+				sglist = (struct aac_apre_element_nark *)frame->sg;
+				*((union aac_apre_embedded_sglist *)frame->sg) = *psg;
+				addr = fib->hw_fib_pa + offsetof(struct hw_apre, sg[0]);
+				psg->nark.FirstElement.physAddrLow = cpu_to_le32((u32)(addr & 0xffffffff));
+				psg->nark.FirstElement.physAddrHigh = cpu_to_le32((u32)(addr>>32));
+				psg->nark.FirstElement.elementByteCount = cpu_to_le32(sg_count * sizeof(psg->nark.FirstElement));
+				psg->nark.FirstElement.elementType = APRE_BUFFER_DESC_POINTER;
+			}
+			addr = sg_dma_address(sg);
+			sglist->physAddrLow = cpu_to_le32((u32)(addr & 0xffffffff));
+			sglist->physAddrHigh = cpu_to_le32((u32)(addr>>32));
+			sglist->elementByteCount = cpu_to_le32(count);
+			sglist->domainSelect = APRE_OFF_CHIP_MEM_DOMAIN;
+			sglist->elementType = APRE_BUFFER_DESC_ENTRY;
+#if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+			byte_count += count;
+#endif
+			sglist++;
+		}
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+	} else if (scsicmd->request_bufflen) {
+		int count;
+		u64 addr;
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__x86_64__))
+		scsicmd->SCp.dma_handle = scsicmd->request_bufferMA;
+		vmk_verify_memory_for_io(scsicmd->request_bufferMA, scsicmd->request_bufflen);
+#else
+		scsicmd->SCp.dma_handle = pci_map_single(dev->pdev,
+				scsicmd->request_buffer,
+				scsicmd->request_bufflen,
+				scsicmd->sc_data_direction);
+#endif
+		addr = scsicmd->SCp.dma_handle;
+		count = scsicmd->request_bufflen;
+#if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+		byte_count = count;
+#endif
+		sg_count = 1;
+		sglist->physAddrLow = cpu_to_le32((u32)(addr & 0xffffffff));
+		sglist->physAddrHigh = cpu_to_le32((u32)(addr>>32));
+		sglist->elementByteCount = cpu_to_le32(count);
+		sglist->domainSelect = APRE_OFF_CHIP_MEM_DOMAIN;
+		sglist->elementType = APRE_BUFFER_DESC_ENTRY;
+	}
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+	if (sg_count > aac_config.peak_sg) {
+		aac_config.peak_sg = sg_count;
+		printk ("peak_sg=%u\n", aac_config.peak_sg);
+	}
+	if (byte_count > aac_config.peak_size) {
+		aac_config.peak_size = byte_count;
+		printk ("peak_size=%u\n", aac_config.peak_size);
+	}
+#endif
+	return sg_count;
+}
+
+int aac_build_sg_rx(struct fib * fib, struct scsi_cmnd* scsicmd, union aac_apre_embedded_sglist* psg)
+{
+	return 0;
+}
+#endif
+#if (defined(INITFLAGS_BEDROC_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+int aac_build_sg_bedroc(struct fib * fib, struct scsi_cmnd* scsicmd, struct sgmap64* psg)
+{
+	struct SGformat {
+		__le32	TotalSize:12;
+		__le32	PageSize:4;  /* Page size in Power of two times 512 */
+		__le32	MaximumEntries:8;
+		__le32	AddressBE:1;
+		__le32	LengthBE:1;
+		__le32	EndBitEnable:1;
+		__le32	EndBitPre:1; /* place end bit in 2nd to last
+					entry for pipelines, rather than
+					in last entry */
+		__le32	LinkBitEnable:1;
+		__le32	LinkBitPre:1; /* place end bit in 2nd to last entry */
+		__le32	Version:2;	/* Zero */
+		__le32	AddressSize:12;	/* Address SG field size in # bytes */
+		__le32	AddressReserved:2;
+		__le32	AddressBoundary:1: /* Address must be on page
+					      boundary (except first) */
+		__le32	AddressPage:1;	/* Address is page number */
+		__le32	AddressOffset:16;/* Address SG field offset # bytes */
+		__le32	LengthSize:12;	 /* Length SG field size in # bytes */
+		__le32	LengthReserved:3;
+		__le32	LengthBoundary:1; /* Length must not exceed page size */
+		__le32	LengthPage:1;     /* Length is number of pages */
+		__le32	LengthOffset:16;  /* Length SG field offset # bytes */
+		__le31	EndBitLocationBit:3; /* End bit field with the byte */
+		__le32	EndBitLocationOffset:12; /* End bit field offset in
+						    # of bytes, must be less
+						    less than TotalSize, upper
+						    bits above that ignored */
+		__le32	EndBitSignedness:1;	/* 0 indicates 1 is active */
+		__le31	LinkBitLocationBit:3; /* Link bit field with the byte */
+		__le32	LinkBitLocationOffset:12; /* Link bit field offset */
+		__le32	LinkBitSignedness:1;	/* 0 indicates 1 is active */
+	};
+
+	dev->SGformat
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	struct Scsi_Host *host = scsicmd->device->host;
+#endif
+	struct aac_dev *dev;
+	unsigned long byte_count = 0;
+	u64 addr;
+	int nseg;
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	dev = (struct aac_dev *)host->hostdata;
+#else
+	dev = (struct aac_dev *)scsicmd->device->host->hostdata;
+#endif
+	// Get rid of old data
+	psg->count = 0;
+	memset(&psg->sg[0], 0, dev->SGformat.TotalSize);
+	nseg = scsi_dma_map(scsicmd);
+	BUG_ON(nseg < 0);
+	if (nseg) {
+		struct scatterlist *sg;
+		int i;
+#if (defined(AAC_DEBUG_INSTRUMENT_SG) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)))
+		int nseg_hold = nseg;
+#endif
+
+		scsi_for_each_sg(scsicmd, sg, nseg, i) {
+			int count = sg_dma_len(sg);
+			addr = sg_dma_address(sg);
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__))
+			vmk_verify_memory_for_io(addr, count);
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+			if (!(dev->adapter_info.options & AAC_OPT_NEW_COMM))
+			while (count > 65536) {
+				psg->sg[i].addr[1] = cpu_to_le32((u32)(addr>>32));
+				psg->sg[i].addr[0] = cpu_to_le32((u32)(addr & 0xffffffff));
+				psg->sg[i].count = cpu_to_le32(65536);
+				++i;
+				if (++nseg > host->sg_tablesize) {
+#if (defined(AAC_DEBUG_INSTRUMENT_SG))
+					printk(KERN_INFO
+					  "SG List[%d] too large based on original[%d]:\n",
+					  nseg, nseg_hold);
+					sg = (struct scatterlist *) scsicmd->request_buffer;
+					for (i = 0; i < nseg_hold; i++) {
+						printk(KERN_INFO "0x%llx[%d] ",
+						  (u64)sg_dma_address(sg),
+						  (int)sg_dma_len(sg));
+						++sg;
+					}
+					printk(KERN_INFO "...\n");
+#endif
+					BUG();
+				}
+				byte_count += 65536;
+				addr += 65536;
+				count -= 65536;
+			}
+#endif
+			psg->sg[i].addr[0] = cpu_to_le32(addr & 0xffffffff);
+			psg->sg[i].addr[1] = cpu_to_le32(addr>>32);
+			psg->sg[i].count = cpu_to_le32(count);
+			byte_count += count;
+		}
+		psg->count = cpu_to_le32(nseg);
+		/* hba wants the size to be exact */
+		if(byte_count > scsi_bufflen(scsicmd)) {
+			u32 temp = le32_to_cpu(psg->sg[i-1].count) -
+				(byte_count - scsi_bufflen(scsicmd));
+			psg->sg[i-1].count = cpu_to_le32(temp);
+			byte_count = scsi_bufflen(scsicmd);
+		}
+		/* Check for command underflow */
+		if(scsicmd->underflow && (byte_count < scsicmd->underflow)){
+			printk(KERN_WARNING"aacraid: cmd len %08lX cmd underflow %08X\n",
+					byte_count, scsicmd->underflow);
+		}
+	}
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+	else if(scsicmd->request_bufflen) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		int i;
+		int count;
+#endif
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__x86_64__))
+		scsicmd->SCp.dma_handle = scsicmd->request_bufferMA;
+		vmk_verify_memory_for_io(scsicmd->request_bufferMA, scsicmd->request_bufflen);
+#else
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		scsicmd->SCp.dma_handle = (char *)(uintptr_t)pci_map_single(dev->pdev,
+#else
+		scsicmd->SCp.dma_handle = pci_map_single(dev->pdev,
+#endif
+				scsicmd->request_buffer,
+				scsicmd->request_bufflen,
+				scsicmd->sc_data_direction);
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+		addr = (u64)(uintptr_t)scsicmd->SCp.dma_handle;
+#else
+		addr = scsicmd->SCp.dma_handle;
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		count = scsicmd->request_bufflen;
+		i = 0;
+		if (!(dev->adapter_info.options & AAC_OPT_NEW_COMM))
+		while (count > 65536) {
+			psg->sg[i].addr[1] = cpu_to_le32((u32)(addr>>32));
+			psg->sg[i].addr[0] = cpu_to_le32((u32)(addr & 0xffffffff));
+			psg->sg[i].count = cpu_to_le32(65536);
+			if (++i >= host->sg_tablesize) {
+#if (defined(AAC_DEBUG_INSTRUMENT_SG))
+				printk(KERN_INFO
+				  "SG List[%d] too large based on original single element %d in size\n",
+				  i, scsicmd->request_bufflen);
+#endif
+				BUG();
+			}
+			addr += 65536;
+			count -= 65536;
+		}
+		psg->count = cpu_to_le32(1+i);
+		psg->sg[i].addr[0] = cpu_to_le32(addr & 0xffffffff);
+		psg->sg[i].addr[1] = cpu_to_le32(addr >> 32);
+		psg->sg[i].count = cpu_to_le32(count);
+#else
+		psg->count = cpu_to_le32(1);
+		psg->sg[0].addr[0] = cpu_to_le32(addr & 0xffffffff);
+		psg->sg[0].addr[1] = cpu_to_le32(addr >> 32);
+		psg->sg[0].count = cpu_to_le32(scsicmd->request_bufflen);
+#endif
+		byte_count = scsicmd->request_bufflen;
+	}
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SG))
+{
+	int i, nseg = le32_to_cpu(psg->count);
+	printk("aac_build_sg64:");
+	for (i = 0; i < nseg; i++) {
+		int count = le32_to_cpu(psg->sg[i].count);
+		u32 addr0 = le32_to_cpu(psg->sg[i].addr[0]);
+		u32 addr1 = le32_to_cpu(psg->sg[i].addr[1]);
+		if (addr1 == 0)
+			printk(" %x[%d]", addr0, count);
+		else
+			printk(" %x%08x[%d]", addr1, addr0, count);
+	}
+	printk ("\n");
+}
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+	if (le32_to_cpu(psg->count) > aac_config.peak_sg) {
+		aac_config.peak_sg = le32_to_cpu(psg->count);
+		printk ("peak_sg=%u\n", aac_config.peak_sg);
+	}
+	if (byte_count > aac_config.peak_size) {
+		aac_config.peak_size = byte_count;
+		printk ("peak_size=%u\n", aac_config.peak_size);
+	}
+#endif
+	return le32_to_cpu(psg->count);
+	return 0;
+}
+#endif
+
 #ifdef AAC_DETAILED_STATUS_INFO
 
 struct aac_srb_status_info {
@@ -3213,3 +7212,78 @@ char *aac_get_status_string(u32 status)
 }
 
 #endif
+
+void aac_simulate_scsi_error(struct aac_dev *dev, struct hw_fib *hw_fib)
+{	
+	struct aac_hba_resp *err = 
+		&((struct aac_native_hba *)hw_fib)->resp.err;
+
+	err->iu_type = HBA_IU_TYPE_RESP;
+	err->service_response = HBA_RESP_SVCRES_TASK_COMPLETE;
+	err->residual_count = 0;
+		
+	if (dev->simulated_scsi_error & 0x01) {
+		err->status = SAM_STAT_CHECK_CONDITION;
+		err->datapres = 0x02; /* Indicate Sense Data */
+		err->sense_response_data_len = 0x08;
+		err->sense_response_buf[0] = 0x72; /* Descriptor Sense Data */
+		err->sense_response_buf[1] = 0x05; /* Illegal Request */
+		err->sense_response_buf[2] = 0x24; /* ASC: Invalid field in the CDB */
+		err->sense_response_buf[3] = 0x00; /* ASCQ */
+		err->sense_response_buf[4] = 0x00; /* Reserved */
+		err->sense_response_buf[5] = 0x00; /* Reserved */
+		err->sense_response_buf[6] = 0x00; /* Reserved */
+		err->sense_response_buf[7] = 0x00; /* Additional Sense Length */
+	} else if (dev->simulated_scsi_error & 0x02) {
+		err->status = SAM_STAT_BUSY;
+		err->datapres = 0x00; /* No Data */
+		err->sense_response_data_len = 0x00;
+	} else if (dev->simulated_scsi_error & 0x04) {
+		err->status = SAM_STAT_RESERVATION_CONFLICT;
+		err->datapres = 0x00; /* No Data */
+		err->sense_response_data_len = 0x00;
+	} else if (dev->simulated_scsi_error & 0x08) {
+		err->status = SAM_STAT_TASK_SET_FULL;
+		err->datapres = 0x00; /* No Data */
+		err->sense_response_data_len = 0x00;
+	} else if (dev->simulated_scsi_error & 0x10) {
+		err->status = SAM_STAT_TASK_ABORTED;
+		err->datapres = 0x00; /* No Data */
+		err->sense_response_data_len = 0x00;
+	}
+}
+
+void aac_simulate_tgt_failure(struct aac_dev *dev, struct hw_fib *hw_fib)
+{
+	struct aac_hba_resp *err = 
+		&((struct aac_native_hba *)hw_fib)->resp.err;
+
+	err->iu_type = HBA_IU_TYPE_RESP;
+	err->service_response = HBA_RESP_SVCRES_FAILURE;
+	err->datapres = 0;
+	
+	if (dev->simulated_tgt_failure & 0x01) {
+		err->status = HBA_RESP_STAT_HBAMODE_DISABLED;
+	} else if (dev->simulated_tgt_failure & 0x02) {
+		err->status = HBA_RESP_STAT_IO_ERROR;
+		err->sense_response_data_len = 0;
+	} else if (dev->simulated_tgt_failure & 0x04) {
+		err->status = HBA_RESP_STAT_IO_ABORTED;
+		err->sense_response_data_len = 0;
+	} else if (dev->simulated_tgt_failure & 0x08) {
+		err->status = HBA_RESP_STAT_NO_PATH_TO_DEVICE;
+		err->sense_response_data_len = 0;
+	} else if (dev->simulated_tgt_failure & 0x10) {
+		err->status = HBA_RESP_STAT_INVALID_DEVICE;
+		err->sense_response_data_len = 0;
+	} else if (dev->simulated_tgt_failure & 0x20) {
+		err->status = HBA_RESP_STAT_UNDERRUN;
+		err->residual_count = 1;
+		err->sense_response_data_len -= 1;
+	} else if (dev->simulated_tgt_failure & 0x40) {
+		err->status = HBA_RESP_STAT_OVERRUN;
+		err->residual_count = 1;
+		err->sense_response_data_len -= 1;
+	}
+}
+
diff --git a/drivers/scsi/aacraid/aacraid.h b/drivers/scsi/aacraid/aacraid.h
index 9323d05..ecf0217 100644
--- a/drivers/scsi/aacraid/aacraid.h
+++ b/drivers/scsi/aacraid/aacraid.h
@@ -1,32 +1,370 @@
-#ifndef dprintk
-# define dprintk(x)
+#undef AAC_DRIVER_BRANCH
+#define AAC_DRIVER_BRANCH "custom"
+#define fwprintf(x) aac_fw_printf x
+//#define dprintk(x) printk x
+#if (!defined(dprintk))
+# define dprintk(x) 
 #endif
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#if (defined(BOOTCD))
+#define fwprintf(x) aac_fw_printf x
+#endif
+#if (!defined(fwprintf) || defined(HAS_BOOT_CONFIG))
+# undef fwprintf
+# define fwprintf(x)
+#endif
+#endif
+//#define AAC_DETAILED_STATUS_INFO
+//#define AAC_DEBUG_INSTRUMENT_INIT
+//#define AAC_DEBUG_INSTRUMENT_SETUP
+//#define AAC_DEBUG_INSTRUMENT_TIMING
+//#define AAC_DEBUG_INSTRUMENT_AIF
+//#define AAC_DEBUG_INSTRUMENT_IOCTL
+//#define AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB 0x0030
+//#define AAC_DEBUG_INSTRUMENT_AAC_CONFIG
+//#define AAC_DEBUG_INSTRUMENT_RESET
+//#define AAC_DEBUG_INSTRUMENT_FIB
+//#define AAC_DEBUG_INSTRUMENT_CONTEXT
+//#define AAC_DEBUG_INSTRUMENT_2TB
+//#define AAC_DEBUG_INSTRUMENT_SENDFIB
+//#define AAC_DEBUG_INSTRUMENT_IO
+//#define AAC_DEBUG_INSTRUMENT_PENDING
+//#define AAC_DEBUG_INSTRUMENT_SG
+//#define AAC_DEBUG_INSTRUMENT_SG_PROBE
+//#define AAC_DEBUG_INSTRUMENT_VM_NAMESERVE
+//#define AAC_DEBUG_INSTRUMENT_SERIAL
+//#define AAC_DEBUG_INSTRUMENT_SYNCHRONIZE
+//#define AAC_DEBUG_INSTRUMENT_SHUTDOWN
+//#define AAC_DEBUG_INSTRUMENT_MSIX
 /* eg: if (nblank(dprintk(x))) */
 #define _nblank(x) #x
 #define nblank(x) _nblank(x)[0]
 
+/* preprocessor defines for ESX35/ESX40 because
+ * the check is no longer in the Makefile 
+ */
+#if defined(__VMKLNX__)
+#define PCI_HAS_SHUTDOWN
+#define PCI_HAS_ENABLE_MSI
+#define PCI_HAS_DISABLE_MSI
+#define SCSI_HAS_SSLEEP
+#define SCSI_HAS_SCSI_DEVICE_ONLINE
+#define HAS_NO_SETUP
+#define SCSI_HAS_SHOST_STATE_ENUM
+#define HAS_BITWISE_TYPE
+#define HAS_SECTOR_T
+#define HAS_MSLEEP
+#elif (defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__))
+#define HAS_NO_SETUP
+#endif
+
+/* changes for Smart HBA */
+#define	AAC_MAX_NATIVE_TARGETS		1024
+
+/* 4 old buses, 1 for dual channel, 1 for Smart HBA */
+#define AAC_MAX_NATIVE_BUSES		6	
+#define AAC_DUAL_PORT_NATIVE_BUS	(AAC_MAX_NATIVE_BUSES - 1)	/* 1 bus for dual channel */
+#define AAC_SMART_HBA_NATIVE_BUS	(AAC_MAX_NATIVE_BUSES - 2)	/* 1 bus for Smart HBA */
+#define AAC_MAX_NATIVE_SIZE		2048
+#define FW_ERROR_BUFFER_SIZE	512
+
+#define	HBA_MAX_SG_EMBEDDED		28
+#define HBA_MAX_SG_SEPARATE		90
+#define	HBA_SENSE_DATA_LEN_MAX		32
+#define	HBA_REQUEST_TAG_ERROR_FLAG	0x00000002
+#define	HBA_SGL_FLAGS_EXT		0x80000000UL
+
+struct aac_hba_sgl {
+	u32		addr_lo; /* Lower 32-bits of SGL element address */
+	u32		addr_hi; /* Upper 32-bits of SGL element address */
+	u32		len;	/* Length of SGL element in bytes */
+	u32		flags;	/* SGL element flags */
+};
+
+enum {
+	HBA_IU_TYPE_SCSI_CMD_REQ		= 0x40,
+	HBA_IU_TYPE_SCSI_TM_REQ			= 0x41,
+	HBA_IU_TYPE_SATA_REQ			= 0x42,
+	HBA_IU_TYPE_RESP			= 0x60,
+	HBA_IU_TYPE_COALESCED_RESP		= 0x61,
+	HBA_IU_TYPE_INT_COALESCING_CFG_REQ	= 0x70
+};
+
+enum
+{
+	HBA_CMD_BYTE1_DATA_DIR_IN	= 0x1,
+	HBA_CMD_BYTE1_DATA_DIR_OUT	= 0x2,
+	HBA_CMD_BYTE1_DATA_TYPE_DDR	= 0x4,
+	HBA_CMD_BYTE1_CRYPTO_ENABLE	= 0x8
+};
+
+enum
+{
+	HBA_CMD_BYTE1_BITOFF_DATA_DIR_IN	= 0,
+	HBA_CMD_BYTE1_BITOFF_DATA_DIR_OUT,
+	HBA_CMD_BYTE1_BITOFF_DATA_TYPE_DDR,
+	HBA_CMD_BYTE1_BITOFF_CRYPTO_ENABLE
+};
+
+enum
+{
+	HBA_RESP_DATAPRES_NO_DATA	= 0x0,
+	HBA_RESP_DATAPRES_RESPONSE_DATA,
+	HBA_RESP_DATAPRES_SENSE_DATA
+};
+
+enum
+{
+	HBA_RESP_SVCRES_TASK_COMPLETE	= 0x0,
+	HBA_RESP_SVCRES_FAILURE,
+	HBA_RESP_SVCRES_TMF_COMPLETE,
+	HBA_RESP_SVCRES_TMF_SUCCEEDED,
+	HBA_RESP_SVCRES_TMF_REJECTED,
+	HBA_RESP_SVCRES_TMF_LUN_INVALID
+};
+
+enum
+{
+	HBA_RESP_STAT_IO_ERROR = 0x1,
+	HBA_RESP_STAT_IO_ABORTED,
+	HBA_RESP_STAT_NO_PATH_TO_DEVICE,
+	HBA_RESP_STAT_INVALID_DEVICE,
+	HBA_RESP_STAT_HBAMODE_DISABLED	= 0xE,
+	HBA_RESP_STAT_UNDERRUN = 0x51,
+	HBA_RESP_STAT_OVERRUN = 0x75
+};
+
+struct aac_hba_cmd_req {
+	u8	iu_type;	/* HBA information unit type */
+	/*
+	 ** byte1:
+	 ** [1:0] DIR - 0=No data, 0x1 = IN, 0x2 = OUT
+	 ** [2]   TYPE - 0=PCI, 1=DDR
+	 ** [3]   CRYPTO_ENABLE - 0=Crypto disabled, 1=Crypto enabled
+	 */
+	u8	byte1;
+	u8	reply_qid;	/* Host reply queue to post response to */
+	u8	reserved1;
+	__le32	it_nexus;	/* Device handle for the request */
+	__le32	request_id;	/* Sender context */
+	__le32	tweak_value_lo;	/* Lower 32-bits of tweak value for crypto enabled IOs */
+	u8	cdb[16];	/* SCSI CDB of the command */
+	u8	lun[8];		/* SCSI LUN of the command */
+	__le32	data_length;	/* Total data length in bytes to be read/written (if any) */
+
+	u8	attr_prio;	/* [2:0] Task Attribute, [6:3] Command Priority */
+	u8	emb_data_desc_count;	/* Number of SGL elements embedded in the HBA req */
+	__le16	dek_index;	/* DEK index for crypto enabled IOs */
+	__le32	error_ptr_lo;	/* Lower 32-bits of reserved error data target location on the host */
+	__le32	error_ptr_hi;	/* Upper 32-bits of reserved error data target location on the host */
+	__le32	error_length;	/* Length of reserved error data area on the host in bytes */
+	__le32	tweak_value_hi;	/* Upper 32-bits of tweak value for crypto enabled IOs */
+
+	struct aac_hba_sgl sge[HBA_MAX_SG_SEPARATE+2]; /* SG list space */
+	/* structure must not exceed AAC_MAX_NATIVE_SIZE-FW_ERROR_BUFFER_SIZE */
+};
+
+/* Task Management Functions (TMF) */
+#define HBA_TMF_ABORT_TASK	0x01
+#define HBA_TMF_LUN_RESET	0x08
+
+struct aac_hba_tm_req {
+	u8	iu_type;	/* HBA information unit type */
+	u8	reply_qid;	/* Host reply queue to post response to */
+	u8	tmf;		/* Task management function */
+	u8	reserved1;
+
+	__le32	it_nexus;	/* Device handle for the command */
+
+	u8	lun[8];		/* SCSI LUN */
+
+	/* Used to hold sender context. */
+	__le32	request_id;	/* Sender context */
+	__le32	reserved2;
+
+	/* Request identifier of managed task */
+	__le32	managed_request_id;	/* Sender context being managed */ 
+	__le32	reserved3;
+
+	__le32	error_ptr_lo;	/* Lower 32-bits of reserved error data target location on the host */
+	__le32	error_ptr_hi;	/* Upper 32-bits of reserved error data target location on the host */
+	__le32	error_length;	/* Length of reserved error data area on the host in bytes */
+};
+
+struct aac_hba_reset_req {
+	u8	iu_type;	/* HBA information unit type */
+	u8	reset_type;	/* 0 - reset specified device, 1 - reset all devices */
+	u8	reply_qid;	/* Host reply queue to post response to */
+	u8	reserved1;
+
+	__le32	it_nexus;	/* Device handle for the command */
+	__le32	request_id;	/* Sender context */
+
+	__le32	error_ptr_lo;	/* Lower 32-bits of reserved error data target location on the host */
+	__le32	error_ptr_hi;	/* Upper 32-bits of reserved error data target location on the host */
+	__le32	error_length;	/* Length of reserved error data area on the host in bytes */
+};
+
+struct aac_hba_resp {
+	u8	iu_type;	/* HBA information unit type */
+	u8	reserved1[3];
+	__le32	request_identifier;	/* sender context */
+	__le32	reserved2;
+	u8	service_response;	/* SCSI service response */
+	u8	status;	/* SCSI status */
+	u8	datapres;	/* [1:0] - data present, [7:2] - reserved */
+	u8	sense_response_data_len;	/* Sense/response data length */
+	__le32	residual_count;	/* Residual data length in bytes */
+	u8	sense_response_buf[HBA_SENSE_DATA_LEN_MAX];	/* Sense/response data */
+};
+
+struct aac_native_hba {
+	union {
+		struct aac_hba_cmd_req cmd; 
+		struct aac_hba_tm_req tmr;
+		u8 cmd_bytes[AAC_MAX_NATIVE_SIZE-FW_ERROR_BUFFER_SIZE];
+	} cmd;
+	union {
+		struct aac_hba_resp err;
+		u8 resp_bytes[FW_ERROR_BUFFER_SIZE];
+	} resp;
+};
+
+/*
+ * Interrupts
+ */
+#define AAC_MAX_MSIX		8	/* vectors */
+#define AAC_PCI_MSI_ENABLE	0x8000
+
+enum {
+	AAC_ENABLE_INTERRUPT	= 0x0,
+	AAC_DISABLE_INTERRUPT,
+	AAC_ENABLE_MSIX,
+	AAC_DISABLE_MSIX,
+	AAC_CLEAR_AIF_BIT,
+	AAC_CLEAR_SYNC_BIT,
+	AAC_ENABLE_INTX
+};
+
+#define AAC_INT_MODE_INTX		(1<<0)
+#define AAC_INT_MODE_MSI		(1<<1)
+#define AAC_INT_MODE_AIF		(1<<2)
+#define AAC_INT_MODE_SYNC		(1<<3)
+
+#define AAC_INT_ENABLE_TYPE1_INTX	0xfffffffb
+#define AAC_INT_ENABLE_TYPE1_MSIX	0xfffffffa
+#define AAC_INT_DISABLE_ALL		0xffffffff
+
+/* Bit definitions in IOA->Host Interrupt Register */
+#define PMC_TRANSITION_TO_OPERATIONAL	(0x80000000 >> 0)
+#define PMC_IOARCB_TRANSFER_FAILED	(0x80000000 >> 3)
+#define PMC_IOA_UNIT_CHECK		(0x80000000 >> 4)
+#define PMC_NO_HOST_RRQ_FOR_CMD_RESPONSE (0x80000000 >> 5)
+#define PMC_CRITICAL_IOA_OP_IN_PROGRESS	(0x80000000 >> 6)
+#define PMC_IOARRIN_LOST		(0x80000000 >> 27)
+#define PMC_SYSTEM_BUS_MMIO_ERROR	(0x80000000 >> 28)
+#define PMC_IOA_PROCESSOR_IN_ERROR_STATE (0x80000000 >> 29)
+#define PMC_HOST_RRQ_VALID		(0x80000000 >> 30)
+#define PMC_OPERATIONAL_STATUS		(0x80000000 >> 0)
+#define PMC_ALLOW_MSIX_VECTOR0		(0x80000000 >> 31)
+
+#define PMC_IOA_ERROR_INTERRUPTS	(PMC_IOARCB_TRANSFER_FAILED | \
+					 PMC_IOA_UNIT_CHECK | \
+					 PMC_NO_HOST_RRQ_FOR_CMD_RESPONSE | \
+					 PMC_IOARRIN_LOST | \
+					 PMC_SYSTEM_BUS_MMIO_ERROR | \
+					 PMC_IOA_PROCESSOR_IN_ERROR_STATE)
+
+#define PMC_ALL_INTERRUPT_BITS		(PMC_IOA_ERROR_INTERRUPTS | \
+					 PMC_HOST_RRQ_VALID | \
+					 PMC_TRANSITION_TO_OPERATIONAL | \
+					 PMC_ALLOW_MSIX_VECTOR0)
+
+#define PMC_GLOBAL_INT_BIT2		0x00000004
+#define PMC_GLOBAL_INT_BIT0		0x00000001
+
+// in linit.c too
+#if (!defined(CONFIG_COMMUNITY_KERNEL) && !defined(CONFIG_DISKDUMP) && !defined(CONFIG_DISKDUMP_MODULE) && !defined(CONFIG_CRASH_DUMP) && !defined(CONFIG_CRASH_DUMP_MODULE))
+#undef SCSI_HAS_DUMP
+#endif
+#if (defined(HAS_KDUMP_CONFIG))
+#undef SCSI_HAS_DUMP
+#endif
+//
 #include <linux/interrupt.h>
+#include <linux/pci.h>
+#include "compat.h"
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,23))
+#if (!defined(IRQ_NONE))
+  typedef void irqreturn_t;
+# define IRQ_HANDLED
+# define IRQ_NONE
+#endif
+#endif
+#if (defined(SCSI_HAS_DUMP))
+#if (defined(HAS_DISKDUMP_H))
+#include <linux/diskdump.h>
+#endif
+#if (defined(lkcd_dump_mode) && !defined(crashdump_mode))
+# define crashdump_mode() lkcd_dump_mode()
+#endif
+#if ((defined(HAS_DISKDUMPLIB_H) || defined(crashdump_mode)) && (defined(CONFIG_DISKDUMP) || defined(CONFIG_DISKDUMP_MODULE) || defined(CONFIG_CRASH_DUMP) || defined(CONFIG_CRASH_DUMP_MODULE)))
+#undef ssleep
+#undef msleep
+#if (!defined(HAS_DUMP_SSLEEP))
+ void aac_diskdump_ssleep(unsigned int seconds);
+ void aac_diskdump_msleep(unsigned int msecs);
+#define ssleep(seconds)	aac_diskdump_ssleep(seconds)
+#define msleep(msec)	aac_diskdump_msleep(msec)
+#else
+#define ssleep(seconds)	diskdump_ssleep(seconds)
+#define msleep(msec)	diskdump_msleep(msec)
+#endif
+#if (defined(HAS_DUMP_MDELAY))
+ void aac_diskdump_mdelay(unsigned int msecs);
+#undef mdelay
+#define mdelay(msec)	aac_diskdump_mdelay(msec)
+#endif
+#endif
+#endif
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,9)) && !defined(HAS_BOOT_CONFIG) && !defined(CONFIG_EXTERNAL) && !defined(CONFIG_COMMUNITY_KERNEL) && !defined(__arm__) && !defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__) && !defined(__VMKLNX__))
+//#define AAC_CSMI
+#endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+#include "scsi.h"
+#if (!defined (__VMKLNX__))
+#include "hosts.h"
+#include "vmklinux_dist.h"
+#endif
+#define num_physpages AAC_MAX_HOSTPHYSMEMPAGES /* vmkernel does not support 64-bit card access */
+#endif
 
 /*------------------------------------------------------------------------------
  *              D E F I N E S
  *----------------------------------------------------------------------------*/
 
+//#define AAC_EXTENDED_TIMEOUT	120
+//
 #ifndef AAC_DRIVER_BUILD
-# define AAC_DRIVER_BUILD 30200
+# define AAC_DRIVER_BUILD 41018
+#if (defined(CONFIG_COMMUNITY_KERNEL))
 # define AAC_DRIVER_BRANCH "-ms"
 #endif
+#endif
 #define MAXIMUM_NUM_CONTAINERS	32
 
 #define AAC_NUM_MGT_FIB         8
 #define AAC_NUM_IO_FIB		(1024 - AAC_NUM_MGT_FIB)
 #define AAC_NUM_FIB		(AAC_NUM_IO_FIB + AAC_NUM_MGT_FIB)
 
-#define AAC_MAX_LUN		(8)
+#define AAC_MAX_LUN		256
 
 #define AAC_MAX_HOSTPHYSMEMPAGES (0xfffff)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18))
+#define AAC_MAX_32BIT_SGBCOUNT	((unsigned short)128)
+#else
 #define AAC_MAX_32BIT_SGBCOUNT	((unsigned short)256)
-
-#define AAC_DEBUG_INSTRUMENT_AIF_DELETE
+#endif
 
 /*
  * These macros convert from physical channels to virtual channels
@@ -36,14 +374,22 @@
 #define CONTAINER_TO_ID(cont)		(cont)
 #define CONTAINER_TO_LUN(cont)		(0)
 
-#define PMC_DEVICE_S7	0x28c
-#define PMC_DEVICE_S8	0x28d
-#define PMC_DEVICE_S9	0x28f
+#define	PMC_DEVICE_S6	0x28b
+#define	PMC_DEVICE_S7	0x28c
+#define	PMC_DEVICE_S8	0x28d
+#define	PMC_DEVICE_S9	0x28f
 
 #define aac_phys_to_logical(x)  ((x)+1)
 #define aac_logical_to_phys(x)  ((x)?(x)-1:0)
 
 /* #define AAC_DETAILED_STATUS_INFO */
+#if (defined(__arm__) && !defined(CONFIG_COMMUNITY_KERNEL))
+#define AAC_LM_SENSOR
+#endif
+#if (defined(__VMKLNX__))
+#define spin_lock_destroy(lock)
+#define vmk_verify_memory_for_io(a,b)
+#endif  
 
 struct diskparm
 {
@@ -58,10 +404,24 @@ struct diskparm
  */
 
 #define		CT_NONE			0
+#define		CT_CONTINUATION_STOP_OK	198
+#define		CT_CONTINUATION_ERROR	199
+#define		CT_CONTINUATION_OK	200
+#define		CT_CONTINUATION_DATA	201
 #define		CT_OK			218
+#define		CT_ID_CONFLICT		282
 #define		FT_FILESYS	8	/* ADAPTEC's "FSA"(tm) filesystem */
 #define		FT_DRIVE	9	/* physical disk - addressable in scsi by bus/id/lun */
 
+/* continuation */
+#define STREAMLINED_CONTINUATION    0x80000000
+#define CT_RESPONSE_DATA_PACKET_SIZE( RESPONSE_SIZE )   \
+                                                (RESPONSE_SIZE - (sizeof(u32)*8))
+#define		FIB_DATA_SIZE_IN_BYTES_VAR(FIB_SIZE)	(FIB_SIZE - sizeof(struct aac_fibhdr))
+#define		CT_PACKET_SIZE_VAR_FIB(FIB_SIZE)  CT_RESPONSE_DATA_PACKET_SIZE(FIB_DATA_SIZE_IN_BYTES_VAR (FIB_SIZE))
+#define		CT_CONTINUE_DATA		83
+#define		CT_STOP_DATA		84
+
 /*
  *	Host side memory scatter gather list
  *	Used by the adapter for read, write, and readdirplus operations
@@ -105,10 +465,10 @@ struct user_sgentryraw {
 };
 
 struct sge_ieee1212 {
-	u32	addrLow;
-	u32	addrHigh;
-	u32	length;
-	u32	flags;
+	u32		addrLow;
+	u32		addrHigh;
+	u32		length;
+	u32		flags;
 };
 
 /*
@@ -280,8 +640,8 @@ enum aac_queue_types {
  *	Assign type values to the FSA communication data structures
  */
 
-#define		FIB_MAGIC	0x0001
-#define		FIB_MAGIC2	0x0004
+#define		FIB_MAGIC		0x0001
+#define		FIB_MAGIC2		0x0004
 #define		FIB_MAGIC2_64	0x0005
 
 /*
@@ -292,19 +652,20 @@ enum aac_queue_types {
 
 /* transport FIB header (PMC) */
 struct aac_fib_xporthdr {
-	u64	HostAddress;	/* FIB host address w/o xport header */
-	u32	Size;		/* FIB size excluding xport header */
-	u32	Handle;		/* driver handle to reference the FIB */
-	u64	Reserved[2];
+	__le64	HostAddress;	/* FIB host address w/o xport header */
+	__le32	Size;		/* FIB size excluding xport header */
+	__le32	Handle;		/* driver handle to reference the FIB */
+	__le64	Reserved[2];
 };
 
-#define		ALIGN32		32
-
 /*
  * Define the FIB. The FIB is the where all the requested data and
  * command information are put to the application on the FSA adapter.
  */
-
+#define	FIB_SIZE_STANDARD			512	/* for all legacy FIBs that has header+payload <= 512 bytes */
+#define	FIB_SIZE_2K				2048	/* AAC_OPT_2K_FIB_SUPPORT: Support for larger payloads */
+#define	FIB_DATA_SIZE_IN_BYTES_VAR(FIB_SIZE)	(FIB_SIZE - sizeof(struct aac_fibhdr))
+#define	FIB_DATA_SIZE_IN_BYTES			FIB_DATA_SIZE_IN_BYTES_VAR(FIB_SIZE_STANDARD)
 struct aac_fibhdr {
 	__le32 XferState;	/* Current transfer state for this CCB */
 	__le16 Command;		/* Routing information for the destination */
@@ -320,15 +681,58 @@ struct aac_fibhdr {
 		__le32 SenderFibAddressHigh;/* upper 32bit of phys. FIB address */
 		__le32 TimeStamp;	/* otherwise timestamp for FW internal use */
 	} u;
-	u32 Handle;		/* FIB handle used for MSGU commnunication */
+	__le32 Handle;		/* FIB handle used for MSGU commnunication */
 	u32 Previous;		/* FW internal use */
 	u32 Next;		/* FW internal use */
 };
 
 struct hw_fib {
 	struct aac_fibhdr header;
-	u8 data[512-sizeof(struct aac_fibhdr)];	// Command specific data
+	u8 data[FIB_DATA_SIZE_IN_BYTES];	// Command specific data
 };
+//#define INITFLAGS_APRE_SUPPORTED
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+
+struct aac_apre_hdr {
+	__le32	nextaddr_lower;
+	__le32	nextaddr_upper;
+	__le16	Operation;
+	__le16	reserved0;
+	u16	tcNumber;
+	__le16	reserved1;
+	u32	DestObjHandle;
+	u8	hSourceObj[4];
+	u8	hDesContext[4];
+};
+
+struct hw_apre {
+	struct aac_apre_hdr header;
+	u8 data[128-sizeof(struct aac_apre_hdr)];
+	u32 sg[17*4];
+};
+
+union hw_cmnd {
+	struct hw_fib fib;
+	struct hw_apre apre;
+};
+
+union hw_cmnd_ptr {
+	struct hw_fib * fib;
+	struct hw_apre * apre;
+};
+
+/* APRE 8 byte Done List Entry definition */
+
+struct donelist_entry
+{
+	u8	status0;
+	u8	status1;
+	u16	tcNumber;
+        __le16	consumerIndex;
+        u8	resv0;
+        u8	DLIndicator;
+};
+#endif
 
 /*
  *	FIB commands
@@ -389,6 +793,10 @@ struct hw_fib {
 #define		SendHostTime			705
 #define		RequestSupplementAdapterInfo	706
 #define		LastMiscCommand			707
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+
+#define		RequestCompatibilityId		802
+#endif
 
 /*
  * Commands that will target the failover level on the FSA adapter
@@ -416,9 +824,8 @@ enum fib_xfer_state {
 	AdapterMicroFib			= (1<<17),
 	BIOSFibPath			= (1<<18),
 	FastResponseCapable		= (1<<19),
-	ApiFib				= (1<<20),	/* Its an API Fib */
-	/* PMC NEW COMM: There is no more AIF data pending */
-	NoMoreAifDataAvailable		= (1<<21)
+	ApiFib				= (1<<20),	// Its an API Fib.
+	NoMoreAifDataAvailable		= (1<<21)	// PMC NEW COMM: There is no more AIF data pending
 };
 
 /*
@@ -428,13 +835,13 @@ enum fib_xfer_state {
 
 #define ADAPTER_INIT_STRUCT_REVISION		3
 #define ADAPTER_INIT_STRUCT_REVISION_4		4 // rocket science
-#define ADAPTER_INIT_STRUCT_REVISION_6		6 /* PMC src */
-#define ADAPTER_INIT_STRUCT_REVISION_7		7 /* Denali */
+#define ADAPTER_INIT_STRUCT_REVISION_6		6 // Tupelo
+#define ADAPTER_INIT_STRUCT_REVISION_7		7 // Denali
 
 struct aac_init
 {
 	__le32	InitStructRevision;
-	__le32	MiniPortRevision;
+	__le32	NoOfMSIXVectors;
 	__le32	fsrev;
 	__le32	CommHeaderAddress;
 	__le32	FastIoCommAreaAddress;
@@ -452,20 +859,39 @@ struct aac_init
 	 */
 	__le32	InitFlags;	/* flags for supported features */
 #define INITFLAGS_NEW_COMM_SUPPORTED	0x00000001
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+#undef INITFLAGS_APRE_SUPPORTED
+#define INITFLAGS_APRE_SUPPORTED	0x00000004
+#endif
 #define INITFLAGS_DRIVER_USES_UTC_TIME	0x00000010
 #define INITFLAGS_DRIVER_SUPPORTS_PM	0x00000020
-#define INITFLAGS_NEW_COMM_TYPE1_SUPPORTED	0x00000040
-#define INITFLAGS_FAST_JBOD_SUPPORTED	0x00000080
-#define INITFLAGS_NEW_COMM_TYPE2_SUPPORTED	0x00000100
+#define INITFLAGS_NEW_COMM_TYPE1_SUPPORTED  0x00000040
+#define INITFLAGS_FAST_JBOD_SUPPORTED  0x00000080
+#define INITFLAGS_NEW_COMM_TYPE2_SUPPORTED  0x00000100
 	__le32	MaxIoCommands;	/* max outstanding commands */
 	__le32	MaxIoSize;	/* largest I/O command */
 	__le32	MaxFibSize;	/* largest FIB to adapter */
 	/* ADAPTER_INIT_STRUCT_REVISION_5 begins here */
-	__le32	MaxNumAif;	/* max number of aif */
+	__le32	MaxNumAif;	/* max number of aif */ 
 	/* ADAPTER_INIT_STRUCT_REVISION_6 begins here */
 	__le32	HostRRQ_AddrLow;
-	__le32	HostRRQ_AddrHigh;	/* Host RRQ (response queue) for SRC */
+	__le32	HostRRQ_AddrHigh;		/* Host RRQ (response queue) for SRC */
+};
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+
+#define A_OP_INIT_STRUCT 0xC0
+struct aac_apre_init {
+	struct aac_apre_hdr header;
+	__le32	inboundMsgBaseLower;
+	__le32	inboundMsgBaseUpper;
+	__le16	NumMsgEnvelopes;
+	u8	reserved1[2];
+	__le32	DoneListBaseAddrLower;
+	__le32	DoneListBaseAddreUpper;
+	__le16	NumDoneListEntries;
+	u8	reserved2[76];
 };
+#endif
 
 enum aac_log_level {
 	LOG_AAC_INIT			= 10,
@@ -494,17 +920,35 @@ struct adapter_ops
 	void (*adapter_disable_int)(struct aac_dev *dev);
 	void (*adapter_enable_int)(struct aac_dev *dev);
 	int  (*adapter_sync_cmd)(struct aac_dev *dev, u32 command, u32 p1, u32 p2, u32 p3, u32 p4, u32 p5, u32 p6, u32 *status, u32 *r1, u32 *r2, u32 *r3, u32 *r4);
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	int  (*adapter_sync_apre)(struct aac_dev *dev, struct hw_apre * command, struct hw_apre * response);
+#endif
 	int  (*adapter_check_health)(struct aac_dev *dev);
 	int  (*adapter_restart)(struct aac_dev *dev, int bled);
+	void (*adapter_start)(struct aac_dev *dev);
 	/* Transport operations */
 	int  (*adapter_ioremap)(struct aac_dev * dev, u32 size);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19))
+	irqreturn_t (*adapter_intr)(int irq, void *dev_id, struct pt_regs *regs);
+#if defined(__ESX5__)
+	irqreturn_t (*adapter_intr_poll)(int irq, void *dev_id, struct pt_regs *regs);
+#endif
+#else
 	irq_handler_t adapter_intr;
+#if defined(__ESX5__)
+	irq_handler_t adapter_intr_poll;
+#endif
+#endif
 	/* Packet operations */
 	int  (*adapter_deliver)(struct fib * fib);
 	int  (*adapter_bounds)(struct aac_dev * dev, struct scsi_cmnd * cmd, u64 lba);
 	int  (*adapter_read)(struct fib * fib, struct scsi_cmnd * cmd, u64 lba, u32 count);
 	int  (*adapter_write)(struct fib * fib, struct scsi_cmnd * cmd, u64 lba, u32 count, int fua);
 	int  (*adapter_scsi)(struct fib * fib, struct scsi_cmnd * cmd);
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	int  (*adapter_scsi_cmd)(struct scsi_cmnd * cmd);
+	int  (*adapter_build_sg)(struct fib * fib, struct scsi_cmnd * cmd, void * psg);
+#endif
 	/* Administrative operations */
 	int  (*adapter_comm)(struct aac_dev * dev, int comm);
 };
@@ -562,10 +1006,10 @@ struct aac_driver_ident
 
 /*
  *	The adapter interface specs all queues to be located in the same
- *	physically contiguous block. The host structure that defines the
+ *	physically contigous block. The host structure that defines the
  *	commuication queues will assume they are each a separate physically
- *	contiguous memory region that will support them all being one big
- *	contiguous block.
+ *	contigous memory region that will support them all being one big
+ *	contigous block.
  *	There is a command and response queue for each level and direction of
  *	commuication. These regions are accessed by both the host and adapter.
  */
@@ -576,14 +1020,26 @@ struct aac_queue {
 	struct aac_qhdr		headers;	/*producer,consumer q headers*/
 	u32			entries;	/*Number of queue entries */
 	wait_queue_head_t	qfull;		/*Event to wait on if q full */
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__VMKLNX__))
+	struct semaphore	cmdready;		/* Indicates there is a Command ready from the adapter. */
+#else
 	wait_queue_head_t	cmdready;	/*Cmd ready from the adapter */
+#endif
 		/* This is only valid for adapter to host command queues. */
 	spinlock_t		*lock;		/* Spinlock for this queue must take this lock before accessing the lock */
 	spinlock_t		lockdata;	/* Actual lock (used only on one side of the lock) */
 	struct list_head	cmdq;		/* A queue of FIBs which need to be prcessed by the FS thread. This is */
 						/* only valid for command queues which receive entries from the adapter. */
-	u32			numpending;	/* Number of entries on outstanding queue. */
+	atomic_t			numpending;	/* Number of entries on outstanding queue. */
 	struct aac_dev *	dev;		/* Back pointer to adapter structure */
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	struct donelist_entry *	DoneListPool;
+	struct donelist_entry *	NxtDoneListEntry;
+	u32			Credits;
+#define APRE_MAX_CREDITS 254
+	u8			DLIndicator;
+#define ApreCmdQueue HostNormCmdQueue
+#endif
 };
 
 /*
@@ -667,6 +1123,10 @@ struct sa_registers {
 #define sa_writew(AEP, CSR, value)	writew(value, &((AEP)->regs.sa->CSR))
 #define sa_writel(AEP, CSR, value)	writel(value, &((AEP)->regs.sa->CSR))
 
+#if defined(writeq)
+#define	sa_writeq(AEP, CSR, value) writeq(value, &((AEP)->regs.sa->CSR))
+#endif
+
 /*
  *	Rx Message Unit Registers
  */
@@ -708,12 +1168,20 @@ struct rx_inbound {
 #define INBOUNDDOORBELL_4	0x00000010
 #define INBOUNDDOORBELL_5	0x00000020
 #define INBOUNDDOORBELL_6	0x00000040
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+#define INBOUNDDOORBELL_8	0x00000100
+#define INBOUNDDOORBELL_9	0x00000200
+#endif
 
 #define	OUTBOUNDDOORBELL_0	0x00000001
 #define OUTBOUNDDOORBELL_1	0x00000002
 #define OUTBOUNDDOORBELL_2	0x00000004
 #define OUTBOUNDDOORBELL_3	0x00000008
 #define OUTBOUNDDOORBELL_4	0x00000010
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+#define OUTBOUNDDOORBELL_8	0x00000100
+#define OUTBOUNDDOORBELL_9	0x00000200
+#endif
 
 #define InboundDoorbellReg	MUnit.IDR
 #define OutboundDoorbellReg	MUnit.ODR
@@ -747,37 +1215,42 @@ struct rkt_registers {
 #define rkt_writeb(AEP, CSR, value)	writeb(value, &((AEP)->regs.rkt->CSR))
 #define rkt_writel(AEP, CSR, value)	writel(value, &((AEP)->regs.rkt->CSR))
 
-/*
+/* 
  * PMC SRC message unit registers
- */
+ */ 
 
 #define src_inbound rx_inbound
 
 struct src_mu_registers {
-				/*	PCI*| Name */
-	__le32	reserved0[8];	/*	00h | Reserved */
-	__le32	IDR;		/*	20h | Inbound Doorbell Register */
-	__le32	IISR;		/*	24h | Inbound Int. Status Register */
-	__le32	reserved1[3];	/*	28h | Reserved */
-	__le32	OIMR;		/*	34h | Outbound Int. Mask Register */
-	__le32	reserved2[25];	/*	38h | Reserved */
-	__le32	ODR_R;		/*	9ch | Outbound Doorbell Read */
-	__le32	ODR_C;		/*	a0h | Outbound Doorbell Clear */
-	__le32	reserved3[6];	/*	a4h | Reserved */
-	__le32	OMR;		/*	bch | Outbound Message Register */
+				/*  PCI*| Name */
+	__le32	reserved0[6];	/*  00h | Reserved */
+	__le32	IOAR[2];	/*  18h | IOA->host interrupt register */
+	__le32	IDR;		/*  20h | Inbound Doorbell Register */
+	__le32	IISR;	    	/*  24h | Inbound Int. Status Register */
+	__le32	reserved1[3];	/*  28h | Reserved */
+	__le32	OIMR;	    	/*  34h | Outbound Int. Mask Register */
+	__le32	reserved2[25];  /*  38h | Reserved */
+	__le32	ODR_R;  	/*  9ch | Outbound Doorbell Read */
+	__le32	ODR_C;  	/*  a0h | Outbound Doorbell Clear */
+	__le32	reserved3[6];	/*  a4h | Reserved */
+	__le32	OMR;  		/*  bch | Outbound Message Register */
 	__le32	IQ_L;		/*  c0h | Inbound Queue (Low address) */
 	__le32	IQ_H;		/*  c4h | Inbound Queue (High address) */
+	__le32	ODR_MSI;	/*  c8h | MSI register for sync./AIF */
+	__le32  reserved4;	/*  cch | Reserved */
+	__le32	IQN_L;		/*  d0h | Inbound (native cmd) low  */
+	__le32	IQN_H;		/*  d4h | Inbound (native cmd) high */
 };
 
 struct src_registers {
-	struct src_mu_registers MUnit;	/* 00h - c7h */
+	struct src_mu_registers MUnit;			/* 00h - d7h */
 	union {
 		struct {
-			__le32 reserved1[130790];	/* c8h - 7fc5fh */
+			__le32 reserved1[130786];	/* d8h - 7fc5fh */
 			struct src_inbound IndexRegs;	/* 7fc60h */
 		} tupelo;
 		struct {
-			__le32 reserved1[974];		/* c8h - fffh */
+			__le32 reserved1[970];		/* d8h - fffh */
 			struct src_inbound IndexRegs;	/* 1000h */
 		} denali;
 	} u;
@@ -785,13 +1258,15 @@ struct src_registers {
 
 #define src_readb(AEP, CSR)		readb(&((AEP)->regs.src.bar0->CSR))
 #define src_readl(AEP, CSR)		readl(&((AEP)->regs.src.bar0->CSR))
-#define src_writeb(AEP, CSR, value)	writeb(value, \
-						&((AEP)->regs.src.bar0->CSR))
-#define src_writel(AEP, CSR, value)	writel(value, \
-						&((AEP)->regs.src.bar0->CSR))
+#define src_writeb(AEP, CSR, value)	writeb(value, &((AEP)->regs.src.bar0->CSR))
+#define src_writel(AEP, CSR, value)	writel(value, &((AEP)->regs.src.bar0->CSR))
+
+#if defined(writeq)
+#define	src_writeq(AEP, CSR, value) writeq(value, &((AEP)->regs.src.bar0->CSR))
+#endif
 
-#define SRC_ODR_SHIFT		12
-#define SRC_IDR_SHIFT		9
+#define SRC_ODR_SHIFT 		12
+#define SRC_IDR_SHIFT 		9
 
 typedef void (*fib_callback)(void *ctxt, struct fib *fibctx);
 
@@ -846,6 +1321,10 @@ struct sense_data {
 struct fsa_dev_info {
 	u64		last;
 	u64		size;
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	u32		Credits;
+	u32		DestObjHandle;
+#endif
 	u32		type;
 	u32		config_waiting_on;
 	unsigned long	config_waiting_stamp;
@@ -857,6 +1336,7 @@ struct fsa_dev_info {
 	u8		deleted;
 	char		devname[8];
 	struct sense_data sense_data;
+	u32		block_size;
 };
 
 struct fib {
@@ -884,8 +1364,35 @@ struct fib {
 	 */
 	struct list_head	fiblink;
 	void			*data;
-	struct hw_fib		*hw_fib_va;		/* Actual shared object */
-	dma_addr_t		hw_fib_pa;		/* physical address of hw_fib*/
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	union hw_cmnd_ptr	hw_cmnd_va;
+#	define hw_fib_va	hw_cmnd_va.fib
+#	define hw_apre_va	hw_cmnd_va.apre
+#else
+	struct hw_fib		*hw_fib_va;	/* also used for native */
+#endif
+	dma_addr_t		hw_fib_pa;	/* physical address of hw_fib*/
+	dma_addr_t		hw_sgl_pa;	/* extra sgl for native */
+	dma_addr_t		hw_error_pa;	/* error buffer for native */
+	u32			hbacmd_size;	/* cmd size for native */
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	u32			Credits;
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING))
+	unsigned long		DriverTimeStartS;
+	unsigned long		DriverTimeStartuS;
+	unsigned long		DriverTimeDoneS;
+	unsigned long		DriverTimeDoneuS;
+#endif
+};
+
+#define AAC_DEVTYPE_RAID_MEMBER	1
+#define AAC_DEVTYPE_ARC_RAW	2
+#define AAC_DEVTYPE_NATIVE_RAW	3
+struct aac_hba_map_info {
+	__le32	rmw_nexus;		/* nexus for native HBA devices */
+	u8		devtype;		/* device type */
+	u8		reset_state;	/* 0 - no reset, 1..x - after xth TM LUN reset */
 };
 
 /*
@@ -951,16 +1458,36 @@ struct aac_supplement_adapter_info
 	/* StructExpansion == 1 */
 	__le32	FeatureBits3;
 	__le32	SupportedPerformanceModes;
-	__le32	ReservedForFutureGrowth[80];
-};
-#define AAC_FEATURE_FALCON	cpu_to_le32(0x00000010)
-#define AAC_FEATURE_JBOD	cpu_to_le32(0x08000000)
+	u8	HostBusType;	    /* uses HOST_BUS_TYPE_xxx defines */
+	u8	HostBusWidth;	    /* actual width in bits or links */
+	u16	HostBusSpeed;	    /* actual bus speed / link xfer rate in MHz */
+	u8	MaxRRCDrives;		/* The max. number of ITP-RRC drives per RRC pool */
+	u8	MaxDiskXtasks;		/* The max. possible number of DiskX Tasks */
+	
+	u8	CpldVerLoaded;
+	u8	CpldVerInFlash;
+
+	__le64	MaxRRCCapacity;	/* The max capacity to MaxIQ pool in blocks */
+	__le32	CompiledMaxHistLogLevel;
+	u8	CustomBoardName[12]; /* Will be used to identify customer board */
+	u16	SupportedCntlrMode; /* to identify supported controller modes */
+	u16	ReservedForFuture16;
+	__le32	SupportedOptions3; /* reserved for future options */
+	
+	__le32	ReservedForFutureGrowth[70];
+};
+#define AAC_FEATURE_FALCON			cpu_to_le32(0x00000010)
+#define AAC_FEATURE_JBOD			cpu_to_le32(0x08000000)
+#define AAC_FEATURE_STREAMLINED_CONTINUATION	cpu_to_le32(0x00002000)
 /* SupportedOptions2 */
 #define AAC_OPTION_MU_RESET		cpu_to_le32(0x00000001)
 #define AAC_OPTION_IGNORE_RESET		cpu_to_le32(0x00000002)
 #define AAC_OPTION_POWER_MANAGEMENT	cpu_to_le32(0x00000004)
 #define AAC_OPTION_DOORBELL_RESET	cpu_to_le32(0x00004000)
+#define AAC_OPTION_VARIABLE_BLOCK_SIZE	cpu_to_le32(0x00040000) /* 4KB sector size */
+#define AAC_OPTION_SUPPORTED_240_VOLUMES cpu_to_le32(0x10000000)
 #define AAC_SIS_VERSION_V3	3
+#define AAC_SIS_VERSION_V15	15
 #define AAC_SIS_SLOT_UNKNOWN	0xFF
 
 #define GetBusInfo 0x00000009
@@ -1018,14 +1545,24 @@ struct aac_bus_info_response {
 #define AAC_OPT_NONDASD			cpu_to_le32(1<<12)
 #define AAC_OPT_SCSI_MANAGED		cpu_to_le32(1<<13)
 #define AAC_OPT_RAID_SCSI_MODE		cpu_to_le32(1<<14)
+#define AAC_OPT_2K_FIB_SUPPORT  cpu_to_le32(1<<15)
 #define AAC_OPT_SUPPLEMENT_ADAPTER_INFO	cpu_to_le32(1<<16)
 #define AAC_OPT_NEW_COMM		cpu_to_le32(1<<17)
 #define AAC_OPT_NEW_COMM_64		cpu_to_le32(1<<18)
-#define AAC_OPT_NEW_COMM_TYPE1		cpu_to_le32(1<<28)
-#define AAC_OPT_NEW_COMM_TYPE2		cpu_to_le32(1<<29)
-#define AAC_OPT_NEW_COMM_TYPE3		cpu_to_le32(1<<30)
-#define AAC_OPT_NEW_COMM_TYPE4		cpu_to_le32(1<<31)
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+#define AAC_OPT_APRE			cpu_to_le32(1<<23)
+#endif
+#define AAC_OPT_NATIVE_HBA		cpu_to_le32(1<<25)
+#define AAC_OPT_NEW_COMM_TYPE1	cpu_to_le32(1<<28)
+#define AAC_OPT_NEW_COMM_TYPE2	cpu_to_le32(1<<29)
+#define AAC_OPT_NEW_COMM_TYPE3	cpu_to_le32(1<<30)
+#define AAC_OPT_NEW_COMM_TYPE4	cpu_to_le32(1<<31)
 
+/* MSIX context */
+struct aac_msix_ctx {
+	int		vector_no;
+	struct aac_dev	*dev;
+};
 
 struct aac_dev
 {
@@ -1040,11 +1577,17 @@ struct aac_dev
 	unsigned		sg_tablesize;
 	unsigned		max_num_aif;
 
+	unsigned		max_cmd_size;	/* max_fib_size or MAX_NATIVE */
+
 	/*
 	 *	Map for 128 fib objects (64k)
 	 */
-	dma_addr_t		hw_fib_pa;
-	struct hw_fib		*hw_fib_va;
+	dma_addr_t		hw_fib_pa;	/* also used for native cmd */
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	union hw_cmnd_ptr	hw_cmnd_va;
+#else
+	struct hw_fib		*hw_fib_va;	/* also used for native cmd */
+#endif
 	struct hw_fib		*aif_base_va;
 	/*
 	 *	Fib Headers
@@ -1067,24 +1610,30 @@ struct aac_dev
 	struct adapter_ops	a_ops;
 	unsigned long		fsrev;		/* Main driver's revision number */
 
-	resource_size_t		base_start;	/* main IO base */
-	resource_size_t		dbg_base;	/* address of UART
-						 * debug buffer */
-
-	resource_size_t		base_size, dbg_size;	/* Size of
-							 *  mapped in region */
-
+	unsigned long		dbg_base;	/* address of UART debug buffer */
+	unsigned		base_size, dbg_size;	/* Size of mapped in region */
 	struct aac_init		*init;		/* Holds initialization info to communicate with adapter */
 	dma_addr_t		init_pa;	/* Holds physical address of the init struct */
 
-	u32			*host_rrq;	/* response queue
-						 * if AAC_COMM_MESSAGE_TYPE1 */
-
+	__le32 *		host_rrq;	/* response queue (if AAC_COMM_MESSAGE_TYPE1) */
 	dma_addr_t		host_rrq_pa;	/* phys. address */
-	u32			host_rrq_idx;	/* index into rrq buffer */
-
+	u32			host_rrq_idx[AAC_MAX_MSIX];
+	atomic_t		rrq_outstanding[AAC_MAX_MSIX];
+	u32			fibs_pushed_no;
 	struct pci_dev		*pdev;		/* Our PCI interface */
 	void *			printfbuf;	/* pointer to buffer used for printf's from the adapter */
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+	spinlock_t		PrintQueueLock;
+	struct list_head	PrintQueue;
+	u32			DebugFlags;	/* Debug print flags bitmap */
+	volatile u8 __iomem *	FwDebugBuffer_P;/* Addr FW Debug Buffer */
+	volatile __le32 __iomem * FwDebugFlags_P;/* Addr FW Debug Flags */
+	u32			FwDebugFlags;	/* FW Debug Flags */
+	volatile __le32 __iomem * FwDebugStrLength_P;/* Addr FW Debug String Length */
+	volatile u8 __iomem *	FwDebugBLEDflag_P;/* Addr FW Debug BLED */
+	volatile u8 __iomem *	FwDebugBLEDvalue_P;/* Addr FW Debug BLED */
+	u32			FwDebugBufferSize;/* FW Debug Buffer Size in Bytes */
+#endif
 	void *			comm_addr;	/* Base address of Comm area */
 	dma_addr_t		comm_phys;	/* Physical Address of Comm area */
 	size_t			comm_size;
@@ -1094,18 +1643,31 @@ struct aac_dev
 	int			maximum_num_physicals;
 	int			maximum_num_channels;
 	struct fsa_dev_info	*fsa_dev;
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+	pid_t			thread_pid;
+#else
 	struct task_struct	*thread;
+#endif
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__VMKLNX__))
+	int			thread_die;
+#endif
 	int			cardtype;
 
 	/*
+	 *	This lock will protect the two 32-bit
+	 *  writes to the Inbound Queue
+	 */
+	spinlock_t iq_lock;
+
+	/*
 	 *	The following is the device specific extension.
 	 */
-#ifndef AAC_MIN_FOOTPRINT_SIZE
-#	define AAC_MIN_FOOTPRINT_SIZE 8192
-#	define AAC_MIN_SRC_BAR0_SIZE 0x400000
-#	define AAC_MIN_SRC_BAR1_SIZE 0x800
-#	define AAC_MIN_SRCV_BAR0_SIZE 0x100000
-#	define AAC_MIN_SRCV_BAR1_SIZE 0x400
+#if (!defined(AAC_MIN_FOOTPRINT_SIZE))
+#define AAC_MIN_FOOTPRINT_SIZE	8192
+#define AAC_MIN_SRC_BAR0_SIZE	0x400000
+#define AAC_MIN_SRC_BAR1_SIZE	0x800
+#define AAC_MIN_SRCV_BAR0_SIZE	0x100000
+#define AAC_MIN_SRCV_BAR1_SIZE	0x400
 #endif
 	union
 	{
@@ -1118,14 +1680,27 @@ struct aac_dev
 		} src;
 	} regs;
 	volatile void __iomem *base, *dbg_base_mapped;
+#if (!defined(CONFIG_COMMUNITY_KERNEL) && defined(CONFIG_IA64))
+	struct rx_inbound __iomem *IndexRegs;
+#else
 	volatile struct rx_inbound __iomem *IndexRegs;
+#endif
 	u32			OIMR; /* Mask Register Cache */
 	/*
 	 *	AIF thread states
 	 */
 	u32			aif_thread;
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+	struct completion	aif_completion;
+#endif
 	struct aac_adapter_info adapter_info;
 	struct aac_supplement_adapter_info supplement_adapter_info;
+#if (defined(CODE_STREAM_IDENTIFIER) && !defined(CONFIG_COMMUNITY_KERNEL))
+# if (!defined(MAX_CODE_STREAM_IDENTIFIER_LENGTH))
+#  define MAX_CODE_STREAM_IDENTIFIER_LENGTH 64
+# endif
+	char			code_stream_identifier[MAX_CODE_STREAM_IDENTIFIER_LENGTH];
+#endif
 	/* These are in adapter info but they are in the io flow so
 	 * lets break them out so we don't have to do an AND to check them
 	 */
@@ -1138,19 +1713,44 @@ struct aac_dev
 	u8			comm_interface;
 #	define AAC_COMM_PRODUCER 0
 #	define AAC_COMM_MESSAGE  1
-#	define AAC_COMM_MESSAGE_TYPE1	3
-#	define AAC_COMM_MESSAGE_TYPE2	4
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+#	define AAC_COMM_APRE	2
+#endif
+#	define AAC_COMM_MESSAGE_TYPE1	3    
+#	define AAC_COMM_MESSAGE_TYPE2	4    
 	u8			raw_io_interface;
 	u8			raw_io_64;
 	u8			printf_enabled;
 	u8			in_reset;
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN) || ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)) && ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,11)) && !defined(PCI_HAS_SHUTDOWN)))))
+	/* Used to indicate the adapter is shut down */
+	u8			shutdown;
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_ENABLE_MSI) || defined(PCI_HAS_DISABLE_MSI))
 	u8			msi;
+#endif
+	u8			simulated_scsi_error;
+	u8			simulated_tgt_failure;
+#if (defined(__ESXi4__))
+	int			major_number; //ESXi4 support
+#endif
 	int			management_fib_count;
 	spinlock_t		manage_lock;
 	spinlock_t		sync_lock;
 	int			sync_mode;
 	struct fib		*sync_fib;
 	struct list_head	sync_fib_list;
+	u32			doorbell_mask;	/* from GET_ADAPTER_PROP */
+	u32			max_msix;	/* max. MSI-X vectors */
+	u32			vector_cap;	/* MSI-X vector capab.*/
+	int			msi_enabled;	/* MSI/MSI-X enabled */
+	int			streamlined_fib_support;
+	int			fib_size_supported;
+	struct msix_entry	msixentry[AAC_MAX_MSIX];
+	struct aac_msix_ctx	aac_msix[AAC_MAX_MSIX]; /* context */
+	struct aac_hba_map_info
+		hba_map[AAC_MAX_NATIVE_BUSES][AAC_MAX_NATIVE_TARGETS];
+	u8			adapter_shutdown;
 };
 
 #define aac_adapter_interrupt(dev) \
@@ -1167,6 +1767,11 @@ struct aac_dev
 
 #define aac_adapter_sync_cmd(dev, command, p1, p2, p3, p4, p5, p6, status, r1, r2, r3, r4) \
 	(dev)->a_ops.adapter_sync_cmd(dev, command, p1, p2, p3, p4, p5, p6, status, r1, r2, r3, r4)
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+
+#define aac_adapter_sync_apre(dev, command, response) \
+	(dev)->a_ops.adapter_sync_apre(dev, command, response)
+#endif
 
 #define aac_adapter_check_health(dev) \
 	(dev)->a_ops.adapter_check_health(dev)
@@ -1174,9 +1779,34 @@ struct aac_dev
 #define aac_adapter_restart(dev,bled) \
 	(dev)->a_ops.adapter_restart(dev,bled)
 
+#define aac_adapter_start(dev) \
+	(dev)->a_ops.adapter_start(dev)
+
 #define aac_adapter_ioremap(dev, size) \
 	(dev)->a_ops.adapter_ioremap(dev, size)
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19))
+#define aac_adapter_intr(dev) \
+	(dev)->a_ops.adapter_intr(dev->pdev->irq, (void *)dev, (struct pt_regs *)NULL)
+#elif (defined(HAS_NEW_IRQ_HANDLER_T))
+#define aac_adapter_intr(dev) (dev)->a_ops.adapter_intr((void *)dev)
+#else
+#define aac_adapter_intr(dev) \
+	(dev)->a_ops.adapter_intr(dev->pdev->irq, (void *)dev)
+#endif
+
+#if defined(__ESX5__)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19))
+#define aac_adapter_intr_poll(dev) \
+	(dev)->a_ops.adapter_intr_poll(dev->pdev->irq, (void *)dev, (struct pt_regs *)NULL)
+#elif (defined(HAS_NEW_IRQ_HANDLER_T))
+#define aac_adapter_intr_poll(dev) (dev)->a_ops.adapter_intr_poll((void *)dev)
+#else
+#define aac_adapter_intr_poll(dev) \
+	(dev)->a_ops.adapter_intr_poll(dev->pdev->irq, (void *)dev)
+#endif
+#endif
+
 #define aac_adapter_deliver(fib) \
 	((fib)->dev)->a_ops.adapter_deliver(fib)
 
@@ -1191,6 +1821,14 @@ struct aac_dev
 
 #define aac_adapter_scsi(fib,cmd) \
 	((fib)->dev)->a_ops.adapter_scsi(fib,cmd)
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+
+#define aac_adapter_scsi_cmd(dev,cmd) \
+	dev->a_ops.adapter_scsi_cmd(cmd)
+
+#define aac_adapter_build_sg(fib,cmd,psg) \
+	((fib)->dev)->a_ops.adapter_build_sg(fib,cmd,psg)
+#endif
 
 #define aac_adapter_comm(dev,comm) \
 	(dev)->a_ops.adapter_comm(dev, comm)
@@ -1199,6 +1837,8 @@ struct aac_dev
 #define FIB_CONTEXT_FLAG			(0x00000002)
 #define FIB_CONTEXT_FLAG_WAIT			(0x00000004)
 #define FIB_CONTEXT_FLAG_FASTRESP		(0x00000008)
+#define FIB_CONTEXT_FLAG_NATIVE_HBA		(0x00000010)
+#define FIB_CONTEXT_FLAG_NATIVE_HBA_TMF		(0x00000020)
 
 /*
  *	Define the command values
@@ -1295,7 +1935,7 @@ struct aac_dev
 #define CACHE_UNSTABLE		2
 
 /*
- *	Lets the client know at which level the data was committed on
+ *	Lets the client know at which level the data was commited on
  *	a write request
  */
 
@@ -1305,6 +1945,7 @@ struct aac_dev
 #define CMDATA_SYNCH		4
 #define CMUNSTABLE		5
 
+
 #define	RIO_TYPE_WRITE 			0x0000
 #define	RIO_TYPE_READ			0x0001
 #define	RIO_SUREWRITE			0x0008
@@ -1314,12 +1955,12 @@ struct aac_dev
 #define RIO2_IO_TYPE_READ		0x0001
 #define RIO2_IO_TYPE_VERIFY		0x0002
 #define RIO2_IO_ERROR			0x0004
-#define RIO2_IO_SUREWRITE		0x0008
-#define RIO2_SGL_CONFORMANT		0x0010
+#define RIO2_IO_SUREWRITE		0x0008  
+#define RIO2_SGL_CONFORMANT		0x0010  
 #define RIO2_SG_FORMAT			0xF000
 #define RIO2_SG_FORMAT_ARC		0x0000
 #define RIO2_SG_FORMAT_SRL		0x1000
-#define RIO2_SG_FORMAT_IEEE1212		0x2000
+#define RIO2_SG_FORMAT_IEEE1212	0x2000
 
 struct aac_read
 {
@@ -1379,13 +2020,14 @@ struct aac_raw_io
 	__le32		block[2];
 	__le32		count;
 	__le16		cid;
-	__le16		flags;		/* 00 W, 01 R */
+	__le16		flags;		/* RIO flags */
 	__le16		bpTotal;	/* reserved for F/W use */
 	__le16		bpComplete;	/* reserved for F/W use */
 	struct sgmapraw	sg;
 };
 
-struct aac_raw_io2 {
+struct aac_raw_io2
+{
 	__le32		blockLow;
 	__le32		blockHigh;
 	__le32		byteCount;
@@ -1561,6 +2203,72 @@ struct aac_srb_reply
 #define SRB_STATUS_NOT_IN_USE		    0x30
 #define SRB_STATUS_FORCE_ABORT		    0x31
 #define SRB_STATUS_DOMAIN_VALIDATION_FAIL   0x32
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+
+struct aac_apre_element_rx {
+	__le32	physAddrLow;
+	__le32	physAddrHigh;
+	__le32	elementByteCount;
+	u8	reserver0[3];
+	u8	reserved1:4;
+	u8	domainSelect:2;
+	u8	endOfList:1;
+	u8	endOfSubList:1;
+};
+
+struct aac_apre_element_link {
+	__le32	physAddrLow;
+	__le32	physAddrHigh;
+	__le32	reserved0[2];
+};
+
+struct aac_apre_element_nark {
+	__le32	elementByteCount:24;
+	__le32	domainSelect:4;
+#define APRE_OFF_CHIP_MEM_DOMAIN 0x0
+	__le32	elementType:4;
+#define APRE_BUFFER_DESC_ENTRY   0x0
+#define APRE_BUFFER_DESC_POINTER 0x4
+	__le32	physAddrLow;
+	__le32	physAddrHigh;
+};
+
+union aac_apre_embedded_sglist {
+	struct {
+		struct aac_apre_element_rx	FirstElement;
+		struct aac_apre_element_rx	SecondElement;
+		struct aac_apre_element_link	ThirdElement;
+	} rx;
+	struct {
+		struct aac_apre_element_nark	FirstElement;
+		struct aac_apre_element_nark	SecondElement;
+		struct aac_apre_element_nark	ThirdElement;
+	} nark;
+};
+
+#define AS_REQ_LKP_CODE_EXEC_SCSI_TASK ((u16)0x600)
+
+struct aac_apre_srb {
+	struct aac_apre_hdr header;
+#define AAC_DATA_IN_IOP_PERSPECTIVE  0x02
+#define AAC_DATA_OUT_IOP_PERSPECTIVE 0x01
+	u8	DataDir:2;
+	u8	NumEsge:2;
+	u8	CDBLength:4;
+	u8	Ind_Cdb:1;
+	u8	Reserved0:3;
+	u8	Task_Attr:3;
+	u8	Reserved1:1;
+	u8	Task_Pri:4;
+	u8	Reserved2:4;
+	u8	Reserved3;
+	u8	Cdb[16];
+	__le32	TransferSizeLow;
+	__le32	TransferSizeHigh;
+	u8	Pad[24];
+	union aac_apre_embedded_sglist Sgl;
+};
+#endif
 
 /*
  * Object-Server / Volume-Manager Dispatch Classes
@@ -1589,6 +2297,9 @@ struct aac_srb_reply
 #define		VM_CtHostWrite64	20
 #define		VM_DrvErrTblLog		21
 #define		VM_NameServe64		22
+#define		VM_GetDynAdapProps	25
+#define		VM_SetDynAdapProps	26
+#define		VM_NameServeAllBlk	30
 
 #define		MAX_VMCOMMAND_NUM	23	/* used for sizing stats array - leave last */
 
@@ -1611,8 +2322,13 @@ struct aac_fsinfo {
 	__le32  fsInodeDensity;
 };	/* valid iff ObjType == FT_FILESYS && !(ContentState & FSCS_NOTCLEAN) */
 
+struct  aac_blockdevinfo {
+	__le32	block_size;
+};
+
 union aac_contentinfo {
-	struct aac_fsinfo filesys;	/* valid iff ObjType == FT_FILESYS && !(ContentState & FSCS_NOTCLEAN) */
+	struct	aac_fsinfo		filesys;	/* valid iff ObjType == FT_FILESYS && !(ContentState & FSCS_NOTCLEAN) */
+	struct	aac_blockdevinfo	bdevinfo;
 };
 
 /*
@@ -1655,7 +2371,6 @@ struct aac_get_config_status_resp {
  */
 
 #define CT_COMMIT_CONFIG 152
-
 struct aac_commit_config {
 	__le32		command;	/* VM_ContainerConfig */
 	__le32		type;		/* CT_COMMIT_CONFIG */
@@ -1677,6 +2392,7 @@ struct aac_get_container_count_resp {
 	__le32		MaxContainers;
 	__le32		ContainerSwitchEntries;
 	__le32		MaxPartitions;
+	__le32		MaxSimpleVolumes;
 };
 
 
@@ -1757,6 +2473,382 @@ struct aac_get_serial_resp {
 	__le32		uid;
 };
 
+struct aac_container_cmd {
+	__le32		command;	/* VM_ContainerConfig */
+	__le32		type;		/* CT_xxx */
+	__le32		handle;		/* cid, pid, ... */
+	__le32		parm1;
+	__le32		parm2;
+	__le32		cnt_id;
+	__le32		cnt_offset;
+	__le32		cnt_size;	/* total expected size */
+	u8              data[CT_PACKET_SIZE_VAR_FIB(FIB_SIZE_STANDARD)];
+};
+
+struct aac_container_resp {
+	__le32		response;	/* ST_OK etc. */
+	__le32		type;		/* usually echos command "type" */
+	__le32		status;		/* CT_OK etc. */
+	__le32		cnt_left;	/* bytes left to be read */
+	__le32		dummy1;		/* echos "status" */
+	__le32		cnt_id;		/* continuation ID */
+	__le32		dummy2;		/* echos "cnt_offset" */
+	__le32		dummy3;		/* echos "cnt_size" */
+	u8		data[CT_PACKET_SIZE_VAR_FIB(FIB_SIZE_STANDARD)];
+};
+
+#define CT_GET_PHYDEV_LIST	247
+#define CT_GET_PHYDEV_INFO	248
+struct aac_phydev_list_resp {
+	__le32	numPhyDev; /* Number of physical devices returned in this resp. */
+	__le32	phyDev[1]; /* Physical device identifiers */
+};
+
+struct aac_standard_inq	{
+	u8	devtype;
+	u8	rmb;
+	u8	version;
+	u8	data_format;
+	u8	additionalLength;
+	u8	bit_field1;
+	u8	bit_field2;
+	u8	bit_field3;
+	u8	vendorID[8];
+	u8	productID[16];
+	u8	revision[4];
+	u8	vendorSpecific[20];
+	u8	bit_field4;
+	u8	reserved4;
+	__le16	versionDescriptor[8];
+	u8	reserved5[22];	
+};	/* 96 bytes */
+
+struct aac_sas_phy_info	{
+	u8	reserved0;
+	u8	phyIdentifier;
+	u8	phyOperation;
+	u8	outstandingIos;
+	u8	attachedDeviceType;
+	u8	negotiatedLinkRate;
+	u8	attachedInitiatorProtocols;
+	u8	attachedTargetProtocols;
+	u8	sasAddress[8];
+	u8	attachedSASAddress[8];
+	u8	attachedPhyIdentifier;
+	u8	reserved25[7];
+	u8	minimumLinkRate;
+	u8	maximumLinkRate;
+	u8	reserved34[8];
+	u8	vendorSpecific[2];
+	u8	it_nexus[4];	/* Native HBA device handle */
+};	/* 48 bytes */
+
+struct aac_smart_info {
+	u8	smartSupported;		/* 1 == SMART is supported, 0 = SMART is not supported */
+	u8	smartEnabled;		/* 1 == SMART is enabled, 0 = SMART is not enabled */
+
+	/* --- Mode page 0x1C start --- */
+	u8	bit_field1;
+	u8	bit_field2;
+	__le32	intervalTimer;
+	__le32	reportCount;
+	/* --- Mode page 0x1C end --- */
+
+	__le32	errorCount;
+};	/* 16 bytes */
+
+struct aac_phydev_info_resp {
+	__le32	supportedOptions1;		/* Expansion bits: Add support for for all future expansion of structure. */
+	__le32	supportedOptions2;		/* Expansion bits (future expansion) */
+	__le32	handle;					/* handle to device */
+	__le32	bus;					/* Bus */
+	__le32	target;					/* Target */
+	__le32	slice;					/* Slice */
+	__le64	lun;					/* Lun */
+	__le32	negotiatedSpeedMBSec;	/* True neg. speed. ScsiRate does not account for wide and is only 8 bits. */
+	u8		negotiatedBusType;		/* Negotiated Bus Type (ARCIO_PHYDEV_BUS_TYPE_T) */
+	u8		deviceType;				/* Device type (ARCIO_PHYDEV_DEV_TYPE_T) */
+	u8		wrCacheSetting;			/* Write cache setting (ARCIO_PHYDEV_WCACHE_STATE_T) */
+	u8		enclNvsramIndex;		/* in case of SEP device */
+	__le64	totalNumBlocks;			/* The actual capacity of the physical device */
+	__le64	usableBlocks;			/* Subtracts drive coercing and metadata */ 
+	__le64	maxUsableBlocks;		/* Subtracts metadata */
+	__le32	blockSize;			/* Block size */
+
+	__le32	bDead     :1;			/* Device is dead */
+	__le32	bBlinking    :1;		/* Device is blinking */
+	__le32	bGlobalHS    :1;		/* Device is global hot spare */
+	__le32	bDedicatedHS :1;		/* Device is a dedicated hot spare */
+	__le32	bAacManaged  :1;		/* Set to 1 if AAC managed (should always be set) */
+	__le32	bSataNCQ     :1;		/* SATA device supports NCQ */
+	__le32	bFsaInitialized 	:1;	/* Device has been initialized for use */
+	__le32	bNonRotatingMedia	:1;	/* Device is a Non Spinning Device */
+	__le32	bItpRrcCapable		:1;	/* This Drive can be used for ITP features */
+	__le32	bItpRrcAssigned		:1;	/* This Drive is Assigned to an ITP-RRC pool */
+	__le32	bCopybackSource		:1;	/* This is Copyback Source drive */
+	__le32	bCopybackTarget		:1;	/* This is Copyback Target drive */
+	__le32	bATAsecuritySupport 	:1; 	/* Device Supports ATA SECURITY operations */
+	__le32	bATAsecurityLock	:1;	/* ATA device is Security Locked */
+	__le32	bOsPartitionPresent 	:1;	/* OS partition is present. Used in Denali */     
+	__le32	bNativeHbaCapable	:1;	/* device is connected to Native HBA port */
+	__le32	bNativeHbaEnabled	:1;	/* Device operation mode (0=ARC IO, 1=Native HBA IO) */
+	__le32	reservedBool 		:15;	/* Reserved boolean bits for growth */
+
+	__le64	fingerPrint;			/* ARC specific unique fingerprint */
+
+	struct aac_standard_inq	inquiry;	/* SCSCI inquiry page */
+	struct aac_sas_phy_info	sasPhy[2];	/* SAS PHY details */
+	struct aac_smart_info	smart;		/* SMART details */
+
+	u8		wwn[16];		/* Inquiry VPD page 0x83: 8, 12, or 16 byte WWN */
+	u8		serialNum[20];		/* Unit serial # */
+	u8		sataExtendedRevision[4]; /* Additional 4 Bytes for SATA drive firmware */
+
+	__le32	bit_field2;
+
+	__le32	unsupportedDeviceReason;	/* Set to a non zero value for devices that are not supported. */
+
+	__le32	taskType;			/* Type of task running on this device (ARCIO_PHYDEV_TASK_TYPE_T) */
+	__le32	taskProgress;			/* Progress of the active task (0 - 100) */
+	__le32	taskState;			/* Task state (ARCIO_PHYDEV_TASK_STATE_T) */
+	__le32	taskPriority;			/* Task priority */
+
+	__le32	pwrMgtState;			/* Power management state (ARCIO_PHYDEV_PWR_STATE_T) */
+	__le32	pwrMgtSupportOpts;		/* Power management support options (ARCIO_BF_PWR_*) */
+
+	__le32	sataPort;
+	__le32	sataPortMultiplier;
+
+	__le32	beginMDBlockCount;		/* Metadata block count beginning of drive */
+	__le32	endMDBlockCount;		/* Metadata block count end of drive */
+
+	__le32	hostBusPhy0;			/* Host Bus Id(phy0) */
+	__le32	hostTargetPhy0;			/* Host Target Id(phy0) */
+	__le32	hostLunPhy0;			/* Host Lun Id(phy0) */
+
+	__le32	hostBusPhy1;			/* Host Bus Id(phy1) */
+	__le32	hostTargetPhy1;			/* Host Target Id(phy1) */
+	__le32	hostLunPhy1;			/* Host Lun Id(phy1) */
+
+	__le32	connMask;			/* controller connection */
+
+	__le32 fill[5];		/* Reserved space fill (pads to 432 bytes) */
+};
+
+/*
+ *  Dynamic adapter properties returned from GetDynAdapPropsFIB or
+ *  used in SetDynAdapPropsFIB 
+ */
+#define DYNPROPS_FIB_DATA_SIZE_IN_BYTES 480
+struct aac_dyn_adap_props_data {
+	__le32	task_priority;
+	__le32	property_bits;
+
+	u8		deviceCachePolicy;	/* adapter wide device cache policy */
+	u8		rrcDrivesInUse;		/* Number of ITP-RRC drive */
+	__le16	MaxCacheFetchFlushRate;      
+
+	__le16	batteryTemperature;	/* PICBAT_STATUS_IOCTL.temperature */
+
+	u8		rBalanceFactor;		/* read Balancefactor for rrc cache strat. */
+	u8		wBalanceFactor;		/* write Balancefactor for rrc cache strat. */
+
+	__le32	batteryStatusBits;			/* PICIOCTL_STAT_* */
+	__le32	batteryCapabilitiesBits;	/* PICIOCTL_CAPA_* */
+	__le16	batteryFullCapacity;		/* PICBAT_STATUS_IOCTL.full_capacity */
+	__le16	batteryRemainingCapacity;	/* PICBAT_STATUS_IOCTL.remaining_capacity */
+	__le16	batteryDRAMCurrentDraw;		/* PICBAT_STATUS_IOCTL.DRAM_current_draw */
+	__le16	dataScrubRate;				/* _E_BG_VERIFY_RATE or in days */
+
+	__le16	heatSensorTemp;				/* ADP_ENV_INFO.temperature */
+	__le16	heatSensorThresholdLo;		/* ADP_ENV_INFO.thresholdLo */
+
+	__le16	heatSensorThresholdHi;		/* ADP_ENV_INFO.thresholdHi */
+    u8		biosHaltOnMissingDriveCount;  /* MSFT */
+	u8		reserved4;
+
+	__le32	keyedOptions;			/* Keyable_Features_Response_FIB.presentlyEnabledKeyableOptions */
+	__le32	performanceMode;		/* Active performance mode */
+
+	__le32	pm_bits;
+	__le32	pmStayAwakeStart;			/* Power management daily stay awake start time (in minutes since midnight) */
+	__le32	pmStayAwakeEnd;				/* Power management daily stay awake end time (in minutes since midnight) */
+	__le32	pmSpinupLimitInternal;		/* Maximum number of internal drives to spin up simultaneously */
+	__le32	pmSpinupLimitExternal;		/* Maximum number of external drives to spin up simultaneously */
+	__le32	pmUTCToLocalTimeDiff;		/* Time zone value used in FW and set by the BIOS and OS utilities (in minutes) */
+	__le32	AdapterTime;				/* Time (local) in secs since 00:00:00 1 Jan 1970 (Unix Epoch) */
+	u8		MaxCacheDirtyThreshold;		/* Number of ITP-RRC drive currently configured into the RRC-Pool */
+	u8		ControllerFunctionMode;	    /* See ARCIO_CONTROLLER_FUNCTION_MODE_T for values */
+	u8		reserved6 [2];
+	u8		OsBootDevId[8];
+
+    /* backup unit parameters */
+	__le32	bu_bits;
+	/* Temperature */
+	__le16	buFuelPresentTemperature;		/* Current temperature in C */
+	__le16	buFuelTemperatureThreshold;  	/* User threshold for Temperature in C */
+	__le16	buFuelLifeTimeMaxTemperature;	/* Life-time max temperature recorded */
+	__le16	buFuelLifeTimeMinTemperature;	/* Life-time min temperature recorded */
+												
+	/* voltage */
+	__le16	buFuelPresentVoltage;		/* supercap's Present voltage in mV */
+	__le16	buFuelMaxVoltage;			/* Maximum voltage supercap may have in mV */
+	__le16	buFuelLifeTimeMaxVoltage;	/* Life-time max voltage recorded */
+
+	/* current */
+	__le16	buFuelCurrentDraw;		/* Current draw in mA */
+	__le16	buFuelMaxCurrentDraw;	/* Max Current draw limit in mA */ 
+
+	/* misc */
+    __le16	buHealth;				/* health level in % */
+    __le16	buErrorCode;			/* General error code */
+	__le16	buHwType;				/* HW type */
+
+	__le16	buFuelChargeLevel; 		/* Current level of energy in % */
+	__le32	buFuelLifeTimeEstimate;	/* Supercap life-time estimation in days */
+	u8		buFuelSerialNumber[16];	/* AFM board serial number in ascii */
+	
+	u8		Rsvd[2];		/* For AFM future use */
+	u8		maxSasPhyLinkRate;	/* max phy link rate on S8 cards (2014.1) */
+	u8		severityHistLog;	/* severity for smart history logging (2014.1) */
+		
+	__le32	cable_bits;								
+	__le16	rescan_status;	/* 1 - running, 0 - completed, any other value - not running. */
+
+	/* Smart HBA: connector settings */
+	__le32	connHBAmask;	/* 0xf: supports native HBA dev., 0 otherwise */
+	__le32	connRAIDmask;	/* 0xf: support RAID dev., 0 otherwise */
+	__le32	connMode;	/* 0xf: RAID use, 0: native HBA use */
+	__le32	connChangeMask;
+};
+
+/*
+ * Index(bit position) into validFieldsBitMap used to indicate which fields are valid
+ */
+enum aac_dyn_adap_valid_type
+{
+	ARCIO_DYN_ADAP_DEFAULT_CTR_TASK_PRIORITY_VALID,		/* bit 0 (byte 0) */
+	ARCIO_DYN_ADAP_ALARM_STATE_VALID,
+	ARCIO_DYN_ADAP_AUTO_FAILOVER_ENABLED_VALID,
+	ARCIO_DYN_ADAP_DEVICE_CACHE_POLICY_VALID,
+	ARCIO_DYN_ADAP_BATTERY_DATA_VALID,
+	ARCIO_DYN_ADAP_DATA_SCRUBBING_ACTIVE_VALID,
+	ARCIO_DYN_ADAP_DATA_SCRUB_RATE_VALID,
+	ARCIO_DYN_ADAP_COPYBACK_ENABLED_VALID,				/* bit 7 (byte 0) */
+
+	ARCIO_DYN_ADAP_HEAT_SENSOR_DATA_VALID,				/* bit 8 (byte 1) */
+	ARCIO_DYN_ADAP_KEYED_OPTIONS_VALID,
+	ARCIO_DYN_ADAP_SELECTABLE_PERF_MODE_VALID,
+	ARCIO_DYN_ADAP_STATISTIC_DATA_COLLECTION_VALID,
+
+	ARCIO_DYN_ADAP_PM_ACTIVE_FLAGS_VALID,		/* pmEnabled, pmActive, pmStayAwakeActive */
+	ARCIO_DYN_ADAP_PM_QUALIFIER_FLAGS_VALID,	/* pmTimeQualifierUTC, pmTimeQualifierLocal */
+	ARCIO_DYN_ADAP_PM_STAY_AWAKE_VALID,			/* pmStayAwakeStart and pmStayAwakeEnd */
+	ARCIO_DYN_ADAP_PM_SPINUP_VALID,				/* pmSpinupLimitInternal and pmSpinupLimitExternal */
+	ARCIO_DYN_ADAP_PM_TIME_DIFF_VALID,			/* pmUTCToLocalTimeDiff */
+	
+	ARCIO_DYN_ADAP_LOCAL_TIME_VALID,			/* localTime */
+
+	ARCIO_DYN_ADAP_PM_STAY_AWAKE_DOW_VALID,		/* pmStayAwakeStart and pmStayAwakeEnd
+												   pmStayAwakeMainEnable, pmStayAwakeDaysOfWeek */
+
+	ARCIO_DYN_ADAP_SATA_NCQ_ENABLED_VALID,		/* SataNCQEnabled */
+
+	ARCIO_DYN_ADAP_RRCCNT_VALID,				/* rrcDrivesInUse */
+
+	ARCIO_DYN_ADAP_MAXCACHE_FETCH_FLUSH_RATE_VALID,		/* Fetch rate option enabled */
+
+	ARCIO_DYN_ADAP_RW_BALANCE_FACTORS_VALID,		/* RW Balance Factors */
+
+    ARCIO_DYN_ADAP_MAXCACHE_DIRTYTHRESHOLD_VALID,		/* MaxcacheDirtyThreshold enabled */
+
+	ARCIO_DYN_ADAP_MAXCACHE_NONREDUNDANT_WC,       /* Write-Cache support with non-redundant Cache pools - (0/1-Disabled/Enabled) */
+
+    ARCIO_DYN_ADAP_CONTROLLER_FUNCTION_MODE_VALID,   /* HBA mode */
+
+    ARCIO_DYN_ADAP_OS_BOOT_DEV_ID_VALID,
+
+	ARCIO_DYN_ADAP_BACKUP_MANAGER_VALID,				/* bit 27 - Backup Unit Manager supported */
+	ARCIO_DYN_ADAP_BACKUP_UNIT_STATUS_VALID,
+    ARCIO_DYN_ADAP_BACKUP_MANAGER_TEMPERATURE_THRESHOLD_VALID,
+    ARCIO_DYN_ADAP_BACKUP_HEALTH_ALERT_VALID,
+	ARCIO_DYN_ADAP_BACKUP_TEMPREATURE_ALERT_VALID,
+
+	ARCIO_DYN_ADAP_MAXCACHE_COHERENCY_CHECK_VALID,		/* max cache background coherency check */
+
+	ARCIO_DYN_ADAP_BACKUP_LTE, 	/* bit 33 - Backup unit manager Life-time estimation support */
+	
+	ARCIO_DYN_ADAP_RESCAN_STATUS_VALID,
+
+	ARCIO_DYN_ADAP_DDR_CACHE_PRESERVATION_STATUS_VALID,
+
+	ARCIO_DYN_ADAP_CONTROLLER_STATUS_VALID,
+
+	ARCIO_DYN_ADAP_CABLE_TYPE_SETTING,
+
+	ARCIO_DYN_ADAP_BIOS_HALT_MISSING_DRIVE_COUNT_VALID,
+
+	ARCIO_DYN_ADAP_HISTORY_LOG_SEVERITY_SETTING_VALID,	/* severity setting for smart history logging (2014.1) */
+
+	ARCIO_DYN_ADAP_MAX_SAS_PHY_LINK_RATE_VALID,			/* max phy link rate on S8 cards (2014.1) */
+
+	ARCIO_DYN_ADAP_SHBA_CTRL_CONN_MODE_VALID,			/* Connector mode config for Smart-HBA */
+
+	ARCIO_DYN_ADAP_LAST	/* Do not remove!  Insert new property indexes above this line */
+};
+
+#define VALID_FIELDS_BITMAP_COUNT 32
+#define VALID_FIELDS_BITMAP_SIZE_IN_BYTES (sizeof(u8) * VALID_FIELDS_BITMAP_COUNT)
+
+struct aac_dyn_adap_props
+{
+	__le32	vmCommand;	/* VM_GetDynAdapProps/VM_SetDynAdapProps */
+	u8	validFieldsBitMap[VALID_FIELDS_BITMAP_COUNT];	
+	/* Bit map (up to 32*8 = 256 fields) indicating which properties
+	(See ARCIO_DYN_ADAP_PROPS_VALID_T) are valid within the 'data' struct */
+	enum aac_dyn_adap_valid_type	fieldUsedForSet; /* When host calls with SetDynAdapPropsFIB, indicates field/property to set */
+	__le32	returnStatus;	/* Usually a _E_CT_GENERAL_STATUS, but can be other return status (ex: ALARM_STATUS) */
+
+	struct aac_dyn_adap_props_data	data;	/* actual dynamic data */
+	/* Pad used to guarantee interface struct fits within a FIB. */
+	u8	pad[DYNPROPS_FIB_DATA_SIZE_IN_BYTES - sizeof(__le32) - VALID_FIELDS_BITMAP_SIZE_IN_BYTES - sizeof(enum aac_dyn_adap_valid_type) - sizeof(__le32) - sizeof(struct aac_dyn_adap_props_data)];
+};
+
+/* Convenience macros to set/get valid properties
+ * Takes a pointer to a ARCIO_DYN_ADAP_PROPS_INTERFACE_T object and a property index (ARCIO_DYN_ADAP_PROPS_VALID_T) and sets the
+ * corresponding bit in the validFieldsBitMap
+ */ 
+#define ARCIO_DYN_ADAP_PROPS_SET_VALID(pInterface, propIndex) \
+	(((propIndex)/8 < 32 && (propIndex) < ARCIO_DYN_ADAP_LAST) ? (*(pInterface)).validFieldsBitMap[(propIndex)/8] |= (1 << ((propIndex) % 8)) : 0)
+
+/* Takes a pointer to a ARCIO_DYN_ADAP_PROPS_INTERFACE_T object and a property index (ARCIO_DYN_ADAP_PROPS_VALID_T) and returns
+ * non-zero if property is set in the validFieldsBitMap
+ */ 
+#define ARCIO_DYN_ADAP_PROPS_GET_VALID(pInterface, propIndex) \
+	(((propIndex)/8 < 32 && (propIndex) < ARCIO_DYN_ADAP_LAST) ? (*(pInterface)).validFieldsBitMap[(propIndex)/8] & (1 << ((propIndex) % 8)) : 0)
+
+#define ARCIO_CONTROLLER_FUNCTION_RAID		 	  	(0x00)
+#define ARCIO_CONTROLLER_FUNCTION_HBA		  		(0x01)
+#define ARCIO_CONTROLLER_FUNCTION_EXPOSE_RAW_DEVICES		(0x02)
+#define ARCIO_CONTROLLER_FUNCTION_AUTO_VOLUME	  		(0x04)
+#define ARCIO_CONTROLLER_FUNCTION_SIMPLE_VOLUME_240	  	(0x08)
+#define ARCIO_CONTROLLER_FUNCTION_NATIVE_HBA	  		(0x10)
+
+enum aac_controller_function_mode {
+ ARCIO_CONTROLLER_RAID_MODE_HIDE_RAW_DEVICES = (ARCIO_CONTROLLER_FUNCTION_RAID),
+ ARCIO_CONTROLLER_RAID_MODE_EXPOSE_RAW_DEVICES = 
+  (ARCIO_CONTROLLER_FUNCTION_EXPOSE_RAW_DEVICES|ARCIO_CONTROLLER_FUNCTION_RAID),
+ ARCIO_CONTROLLER_AUTO_VOLUME_MODE = 
+  (ARCIO_CONTROLLER_FUNCTION_EXPOSE_RAW_DEVICES|ARCIO_CONTROLLER_FUNCTION_AUTO_VOLUME),
+ ARCIO_CONTROLLER_HBA_MODE = 
+  (ARCIO_CONTROLLER_FUNCTION_EXPOSE_RAW_DEVICES|ARCIO_CONTROLLER_FUNCTION_HBA),
+ ARCIO_CONTROLLER_SIMPLE_VOLUME_240_MODE = 
+  (ARCIO_CONTROLLER_FUNCTION_EXPOSE_RAW_DEVICES|ARCIO_CONTROLLER_FUNCTION_SIMPLE_VOLUME_240),
+ ARCIO_CONTROLLER_SMART_MODE = 
+  (ARCIO_CONTROLLER_FUNCTION_NATIVE_HBA | ARCIO_CONTROLLER_FUNCTION_EXPOSE_RAW_DEVICES | ARCIO_CONTROLLER_FUNCTION_RAID)
+};
+
+
 /*
  * The following command is sent to shut down each container.
  */
@@ -1798,6 +2890,17 @@ struct revision
 	__le32 version;
 	__le32 build;
 };
+#if (defined(CODE_STREAM_IDENTIFIER) && !defined(CONFIG_COMMUNITY_KERNEL))
+
+#define VERSION_MATCH_SUCCESS		1
+#define VERSION_MATCH_FAILED		2
+#define VERSION_MATCH_UNSUPPORTED	3
+struct VersionMatch {
+	u32 status;
+	char driver[MAX_CODE_STREAM_IDENTIFIER_LENGTH];
+	char firmware[MAX_CODE_STREAM_IDENTIFIER_LENGTH];
+};
+#endif
 
 
 /*
@@ -1830,9 +2933,20 @@ struct revision
 #define FSACTL_MINIPORT_REV_CHECK               CTL_CODE(2107, METHOD_BUFFERED)
 #define FSACTL_GET_PCI_INFO			CTL_CODE(2119, METHOD_BUFFERED)
 #define FSACTL_FORCE_DELETE_DISK		CTL_CODE(2120, METHOD_NEITHER)
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#define FSACTL_REGISTER_FIB_SEND		CTL_CODE(2136, METHOD_BUFFERED)
+#endif
 #define FSACTL_GET_CONTAINERS			2131
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#define FSACTL_GET_VERSION_MATCHING		CTL_CODE(2137, METHOD_BUFFERED)
+#endif
 #define FSACTL_SEND_LARGE_FIB			CTL_CODE(2138, METHOD_BUFFERED)
 
+#define FSACTL_ERROR_INJECT			CTL_CODE(9000, METHOD_BUFFERED)
+struct aac_error_inject_str {
+	u8	type;
+	u8	value;
+};
 
 struct aac_common
 {
@@ -1844,12 +2958,21 @@ struct aac_common
 	u32 peak_fibs;
 	u32 zero_fibs;
 	u32 fib_timeouts;
+#if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+	u32 peak_size;
+	u32 peak_sg;
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING))
+	u32 peak_duration;
+#endif
 	/*
 	 *	Statistical counters in debug mode
 	 */
 #ifdef DBG
 	u32 FibsSent;
 	u32 FibRecved;
+	u32 NativeSent;
+	u32 NativeRecved;
 	u32 NoResponseSent;
 	u32 NoResponseRecved;
 	u32 AsyncSent;
@@ -1887,6 +3010,9 @@ extern struct aac_common aac_config;
 #define COMMAND_POST_RESULTS		0x00000014
 #define GET_ADAPTER_PROPERTIES		0x00000019
 #define GET_DRIVER_BUFFER_PROPERTIES	0x00000023
+#if (defined(AAC_DEBUG_INSTRUMENT_SLOT))
+#define SEND_SLOT_NUMBER		0x00000024
+#endif
 #define RCV_TEMP_READINGS		0x00000025
 #define GET_COMM_PREFERRED_SETTINGS	0x00000026
 #define IOP_RESET			0x00001000
@@ -1918,10 +3044,19 @@ extern struct aac_common aac_config;
 #define	MONITOR_PANIC			0x00000020
 #define	KERNEL_UP_AND_RUNNING		0x00000080
 #define	KERNEL_PANIC			0x00000100
+
+/*
+ * Dual firmware image support
+ */
 #define	FLASH_UPD_PENDING		0x00002000
 #define	FLASH_UPD_SUCCESS		0x00004000
 #define	FLASH_UPD_FAILED		0x00008000
-#define	FWUPD_TIMEOUT			(5 * 60)
+
+/*
+ * We wait this many seconds for the adapter to come ready  
+ * after flash update
+ */
+#define FWUPD_TIMEOUT	(5 * 60)
 
 /*
  *	Doorbell bit defines
@@ -1935,22 +3070,24 @@ extern struct aac_common aac_config;
 #define DoorBellAdapterNormRespNotFull	(1<<4)	/* Adapter -> Host */
 #define DoorBellPrintfReady		(1<<5)	/* Adapter -> Host */
 #define DoorBellAifPending		(1<<6)	/* Adapter -> Host */
-
 /* PMC specific outbound doorbell bits */
-#define PmDoorBellResponseSent		(1<<1)	/* Adapter -> Host */
+#define PmDoorBellResponseSent			(1<<1)	// Adapter -> Host
+
 
 /*
  *	For FIB communication, we need all of the following things
  *	to send back to the user.
  */
 
-#define		AifCmdEventNotify	1	/* Notify of event */
+#define			AifCmdEventNotify	1	/* Notify of event */
 #define			AifEnConfigChange	3	/* Adapter configuration change */
 #define			AifEnContainerChange	4	/* Container configuration change */
 #define			AifEnDeviceFailure	5	/* SCSI device failed */
 #define			AifEnEnclosureManagement 13	/* EM_DRIVE_* */
-#define				EM_DRIVE_INSERTION	31
-#define				EM_DRIVE_REMOVAL	32
+#define			EM_DRIVE_INSERTION	31
+#define			EM_DRIVE_REMOVAL	32
+#define			EM_SES_DRIVE_INSERTION	33
+#define			EM_SES_DRIVE_REMOVAL	26
 #define			AifEnBatteryEvent	14	/* Change in Battery State */
 #define			AifEnAddContainer	15	/* A new array was created */
 #define			AifEnDeleteContainer	16	/* A container was deleted */
@@ -1963,6 +3100,10 @@ extern struct aac_common aac_config;
 #define		AifCmdJobProgress	2	/* Progress report */
 #define			AifJobCtrZero	101	/* Array Zero progress */
 #define			AifJobStsSuccess 1	/* Job completes */
+#define		AifJobStsAborted 3	/* Job aborted */
+#define		AifJobStsFailed 4	/* Job failed */
+#define		AifJobStsPreempted 5	/* Job preempted */
+#define		AifJobStsPended 6	/* Job suspended */
 #define			AifJobStsRunning 102	/* Job running */
 #define		AifCmdAPIReport		3	/* Report from other user of API */
 #define		AifCmdDriverNotify	4	/* Notify host driver of event */
@@ -1979,9 +3120,10 @@ extern struct aac_common aac_config;
 #define		AifReqAPIJobStart	108	/* Start a job from the API */
 #define		AifReqAPIJobUpdate	109	/* Update a job report from the API */
 #define		AifReqAPIJobFinish	110	/* Finish a job from the API */
-
-/* PMC NEW COMM: Request the event data */
-#define		AifReqEvent		200
+#define		AifReqEvent		200	/* PMC NEW COMM: Request the event data */
+#define		AifRawDeviceRemove	203	/* RAW device deleted */
+#define		AifNativeDeviceAdd	204	/* native HBA device added */
+#define		AifNativeDeviceRemove	205	/* native HBA device removed */
 
 /*
  *	Adapter Initiated FIB command structures. Start with the adapter
@@ -2000,9 +3142,22 @@ struct aac_aifcmd {
  *	accounting for the fact capacity could be a 64 bit value
  *
  */
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) && !defined(HAS_SECTOR_T))
+typedef unsigned long sector_t;
+
+#endif
 static inline unsigned int cap_to_cyls(sector_t capacity, unsigned divisor)
 {
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)) || defined(sector_div))
 	sector_div(capacity, divisor);
+#else
+	capacity /= divisor;
+#endif
+#if 0
+	if ((sizeof(sector_t) > sizeof(int)) &&
+	  ((unsigned long long)capacity > ((1LL << (8 * sizeof(int))) - 1)))
+		capacity = ((1LL << (8 * sizeof(int))) - 1LL);
+#endif
 	return capacity;
 }
 
@@ -2012,6 +3167,8 @@ static inline unsigned int cap_to_cyls(sector_t capacity, unsigned divisor)
 #define AAC_OWNER_ERROR_HANDLER	0x103
 #define AAC_OWNER_FIRMWARE	0x106
 
+int aac_acquire_irq(struct aac_dev *dev);
+void aac_free_irq(struct aac_dev *dev);
 const char *aac_driverinfo(struct Scsi_Host *);
 struct fib *aac_fib_alloc(struct aac_dev *dev);
 int aac_fib_setup(struct aac_dev *dev);
@@ -2020,19 +3177,51 @@ void aac_fib_free(struct fib * context);
 void aac_fib_init(struct fib * context);
 void aac_printf(struct aac_dev *dev, u32 val);
 int aac_fib_send(u16 command, struct fib * context, unsigned long size, int priority, int wait, int reply, fib_callback callback, void *ctxt);
+int aac_hba_send(u8 command, struct fib * context, fib_callback callback, void *ctxt);
+#if (defined(FSACTL_REGISTER_FIB_SEND) && !defined(CONFIG_COMMUNITY_KERNEL))
+typedef int (*fib_send_t)(u16 command, struct fib * context, unsigned long size, int priority, int wait, int reply, fib_callback callback, void *ctxt);
+extern fib_send_t aac_fib_send_switch;
+#define aac_fib_send aac_fib_send_switch
+#endif
 int aac_consumer_get(struct aac_dev * dev, struct aac_queue * q, struct aac_entry **entry);
 void aac_consumer_free(struct aac_dev * dev, struct aac_queue * q, u32 qnum);
 int aac_fib_complete(struct fib * context);
 #define fib_data(fibctx) ((void *)(fibctx)->hw_fib_va->data)
 struct aac_dev *aac_init_adapter(struct aac_dev *dev);
+void aac_src_access_devreg(struct aac_dev *dev, int mode);
 int aac_get_config_status(struct aac_dev *dev, int commit_flag);
 int aac_get_containers(struct aac_dev *dev);
+#if (!defined(INITFLAGS_APRE_SUPPORTED) || defined(CONFIG_COMMUNITY_KERNEL))
 int aac_scsi_cmd(struct scsi_cmnd *cmd);
+#endif
 int aac_dev_ioctl(struct aac_dev *dev, int cmd, void __user *arg);
+#if (defined(AAC_CSMI))
+int aac_csmi_ioctl(struct aac_dev *dev, int cmd, void __user *arg);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11))
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) ? defined(__x86_64__) : defined(CONFIG_COMPAT))
+void aac_csmi_register_ioctl32_conversion(void);
+void aac_csmi_unregister_ioctl32_conversion(void);
+#endif
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+#define class_device Scsi_Host
+#define class_to_shost(class_dev) class_dev
+#define shost_to_class(shost) shost
+#elif (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+#ifndef shost_to_class
+#define shost_to_class(shost) &shost->shost_classdev
+#endif
+#else
 #ifndef shost_to_class
 #define shost_to_class(shost) &shost->shost_dev
 #endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+ssize_t aac_show_serial_number(struct class_device *class_dev, char *buf);
+#else
 ssize_t aac_get_serial_number(struct device *dev, char *buf);
+#endif
 int aac_do_ioctl(struct aac_dev * dev, int cmd, void __user *arg);
 int aac_rx_init(struct aac_dev *dev);
 int aac_rkt_init(struct aac_dev *dev);
@@ -2043,30 +3232,53 @@ int aac_srcv_init(struct aac_dev *dev);
 int aac_queue_get(struct aac_dev * dev, u32 * index, u32 qid, struct hw_fib * hw_fib, int wait, struct fib * fibptr, unsigned long *nonotify);
 unsigned int aac_response_normal(struct aac_queue * q);
 unsigned int aac_command_normal(struct aac_queue * q);
-unsigned int aac_intr_normal(struct aac_dev *dev, u32 Index,
-			int isAif, int isFastResponse,
-			struct hw_fib *aif_fib);
+void aac_simulate_scsi_error(struct aac_dev *dev, struct hw_fib *hw_fib);
+void aac_simulate_tgt_failure(struct aac_dev *dev, struct hw_fib *hw_fib);
+unsigned int aac_intr_normal(struct aac_dev * dev, u32 Index, int isAif,
+	int isFastResponse, struct hw_fib *aif_fib);
 int aac_reset_adapter(struct aac_dev * dev, int forced);
 int aac_check_health(struct aac_dev * dev);
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+int aac_command_thread(struct aac_dev * dev);
+#else
 int aac_command_thread(void *data);
+#endif
 int aac_close_fib_context(struct aac_dev * dev, struct aac_fib_context *fibctx);
 int aac_fib_adapter_complete(struct fib * fibptr, unsigned short size);
 struct aac_driver_ident* aac_get_driver_ident(int devtype);
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+/* Local Structure to set SCSI inquiry data strings */
+struct scsi_inq {
+	char vid[8];         /* Vendor ID */
+	char pid[16];        /* Product ID */
+	char prl[4];         /* Product Revision Level */
+};
+void setinqstr(struct aac_dev *dev, void *data, int tindex);
+#endif
 int aac_get_adapter_info(struct aac_dev* dev);
 int aac_send_shutdown(struct aac_dev *dev);
 int aac_probe_container(struct aac_dev *dev, int cid);
 int _aac_rx_init(struct aac_dev *dev);
 int aac_rx_select_comm(struct aac_dev *dev, int comm);
 int aac_rx_deliver_producer(struct fib * fib);
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+int aac_build_sg_rx(struct fib * fib, struct scsi_cmnd * scsicmd, void * psg);
+int aac_build_sg_nark(struct fib * fib, struct scsi_cmnd * scsicmd, void * psg);
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 char * get_container_type(unsigned type);
+#endif
 extern int numacb;
 extern int acbsize;
 extern char aac_driver_version[];
 extern int startup_timeout;
 extern int aif_timeout;
 extern int expose_physicals;
+extern int aac_remove_devnodes;
 extern int aac_reset_devices;
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,4)) || defined(PCI_HAS_ENABLE_MSI) || defined(PCI_HAS_DISABLE_MSI))
 extern int aac_msi;
+#endif
 extern int aac_commit;
 extern int update_interval;
 extern int check_interval;
diff --git a/drivers/scsi/aacraid/build_number.h b/drivers/scsi/aacraid/build_number.h
new file mode 100644
index 0000000..5ae3964
--- /dev/null
+++ b/drivers/scsi/aacraid/build_number.h
@@ -0,0 +1 @@
+#define BUILD_VERSION B41018 
diff --git a/drivers/scsi/aacraid/commctrl.c b/drivers/scsi/aacraid/commctrl.c
index ee6cadd..354f383 100644
--- a/drivers/scsi/aacraid/commctrl.c
+++ b/drivers/scsi/aacraid/commctrl.c
@@ -1,12 +1,11 @@
 /*
  *	Adaptec AAC series RAID controller driver
- *	(c) Copyright 2001 Red Hat Inc.
+ *	(c) Copyright 2001 Red Hat Inc.	<alan@redhat.com>
  *
  * based on the old aacraid driver that is..
  * Adaptec aacraid device driver for Linux.
  *
- * Copyright (c) 2000-2010 Adaptec, Inc.
- *               2010 PMC-Sierra, Inc. (aacraid@pmc-sierra.com)
+ * Copyright (c) 2000-2007 Adaptec, Inc. (aacraid@adaptec.com)
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -32,20 +31,53 @@
 #include <linux/kernel.h>
 #include <linux/init.h>
 #include <linux/types.h>
+//#include <linux/sched.h>
 #include <linux/pci.h>
 #include <linux/spinlock.h>
 #include <linux/slab.h>
+#include <linux/version.h> /* for the following test */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,2))
 #include <linux/completion.h>
+#endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
 #include <linux/dma-mapping.h>
+#endif
 #include <linux/blkdev.h>
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,9)) || defined(SCSI_HAS_SSLEEP)
 #include <linux/delay.h> /* ssleep prototype */
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,5)) || defined(HAS_KTHREAD))
 #include <linux/kthread.h>
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+#include <asm/semaphore.h>
+#else
 #include <linux/semaphore.h>
+#endif
 #include <asm/uaccess.h>
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,0))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,9))
+#include <scsi/scsi_cmnd.h>
+#endif
 #include <scsi/scsi_host.h>
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,9))
+#include <scsi/scsi_device.h>
+#include <scsi/scsi_eh.h>
+#endif
+#else
+#include "scsi.h"
+#include "hosts.h"
+#endif
 
 #include "aacraid.h"
-
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#include "fwdebug.h"
+#endif
+#if (defined(AAC_CSMI))
+# include "csmi.h"
+#endif
+
+#if (!defined(HAS_BOOT_CONFIG))
 /**
  *	ioctl_send_fib	-	send a FIB from userspace
  *	@dev:	adapter is being processed
@@ -54,8 +86,37 @@
  *	This routine sends a fib to the adapter on behalf of a user level
  *	program.
  */
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0xF)
+static char * aac_debug_timestamp(void)
+{
+	unsigned long seconds = get_seconds();
+	static char buffer[80];
+	sprintf(buffer, "%02u:%02u:%02u: ",
+	  (int)((seconds / 3600) % 24),
+	  (int)((seconds / 60) % 60),
+	  (int)(seconds % 60));
+	return buffer;
+}
+# define AAC_DEBUG_PREAMBLE	"%s"
+# define AAC_DEBUG_POSTAMBLE	,aac_debug_timestamp()
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL) || defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB7))
+# define AAC_DEBUG_PREAMBLE_SIZE 10
+#endif
+#else
 # define AAC_DEBUG_PREAMBLE	KERN_INFO
 # define AAC_DEBUG_POSTAMBLE
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL) || defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB7))
+# define AAC_DEBUG_PREAMBLE_SIZE 0
+#endif
+#endif
+#else
+# define AAC_DEBUG_PREAMBLE	KERN_INFO
+# define AAC_DEBUG_POSTAMBLE
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL) || defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB7))
+# define AAC_DEBUG_PREAMBLE_SIZE 0
+#endif
+#endif
 
 static int ioctl_send_fib(struct aac_dev * dev, void __user *arg)
 {
@@ -65,12 +126,48 @@ static int ioctl_send_fib(struct aac_dev * dev, void __user *arg)
 	dma_addr_t hw_fib_pa = (dma_addr_t)0LL;
 	unsigned size;
 	int retval;
-
+	struct aac_container_resp *cresp;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	printk(KERN_DEBUG AAC_DEBUG_PREAMBLE "ioctl_send_fib(%p,%p)\n" AAC_DEBUG_POSTAMBLE,
+	  dev, arg);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x2)
+	fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  AAC_DEBUG_PREAMBLE "ioctl_send_fib(%p,%p)" AAC_DEBUG_POSTAMBLE,
+	  dev, arg));
+#endif
+#endif
 	if (dev->in_reset) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		printk(KERN_DEBUG AAC_DEBUG_PREAMBLE
+		  "ioctl_send_fib(%p,%p) returns -EBUSY\n"
+		  AAC_DEBUG_POSTAMBLE, dev, arg);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x2)
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  AAC_DEBUG_PREAMBLE "ioctl_send_fib(%p,%p) returns -EBUSY"
+		  AAC_DEBUG_POSTAMBLE, dev, arg));
+#endif
+#endif
 		return -EBUSY;
 	}
 	fibptr = aac_fib_alloc(dev);
 	if(fibptr == NULL) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		printk(KERN_DEBUG AAC_DEBUG_PREAMBLE
+		  "ioctl_send_fib(%p,%p) returns -ENOMEM\n"
+		  AAC_DEBUG_POSTAMBLE, dev, arg);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x2)
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  AAC_DEBUG_PREAMBLE "ioctl_send_fib(%p,%p) returns -ENOMEM"
+		  AAC_DEBUG_POSTAMBLE, dev, arg));
+#endif
+#endif
 		return -ENOMEM;
 	}
 
@@ -80,6 +177,18 @@ static int ioctl_send_fib(struct aac_dev * dev, void __user *arg)
 	 */
 	if (copy_from_user((void *)kfib, arg, sizeof(struct aac_fibhdr))) {
 		aac_fib_free(fibptr);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		printk(KERN_DEBUG AAC_DEBUG_PREAMBLE
+		  "ioctl_send_fib(%p,%p) returns -EFAULT\n"
+		  AAC_DEBUG_POSTAMBLE, dev, arg);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x2)
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  AAC_DEBUG_PREAMBLE "ioctl_send_fib(%p,%p) returns -EFAULT"
+		  AAC_DEBUG_POSTAMBLE, dev, arg));
+#endif
+#endif
 		return -EFAULT;
 	}
 	/*
@@ -112,6 +221,12 @@ static int ioctl_send_fib(struct aac_dev * dev, void __user *arg)
 		memset(((char *)kfib) + dev->max_fib_size, 0, size - dev->max_fib_size);
 		memcpy(kfib, hw_fib, dev->max_fib_size);
 	}
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+	if (kfib->header.XferState & cpu_to_le32(Async | ResponseExpected | NoResponseExpected)) {
+		retval = -EINVAL;
+		goto cleanup;
+	}
+#endif
 
 	if (copy_from_user(kfib, arg, size)) {
 		retval = -EFAULT;
@@ -126,14 +241,126 @@ static int ioctl_send_fib(struct aac_dev * dev, void __user *arg)
 		 */
 		kfib->header.XferState = 0;
 	} else {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x7)
+#define AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB7
+#endif
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL) || defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB7))
+		{
+			u8 * fib = (u8 *)kfib;
+			unsigned len = le16_to_cpu(kfib->header.Size);
+			char buffer[80-AAC_DEBUG_PREAMBLE_SIZE];
+			char * cp = buffer;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB7))
+			unsigned long DebugFlags;
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x4) == 0)
+			unsigned header_length;
+			sprintf(cp, "FIB=%p=", fib);
+			header_length = strlen(cp);
+#else
+#			define header_length 4
+			strcpy(cp, "FIB=");
+#endif
+			if (nblank(fwprintf(x))) {
+				DebugFlags = dev->FwDebugFlags;
+				dev->FwDebugFlags |= FW_DEBUG_FLAGS_NO_HEADERS_B;
+			}
+#else
+#			define header_length 4
+			strcpy(cp, "FIB=");
+#endif
+			cp += header_length;
+			while (len > 0) {
+				if (cp >= &buffer[sizeof(buffer)-4]) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+					printk (KERN_DEBUG
+					  AAC_DEBUG_PREAMBLE "%s\n"
+					  AAC_DEBUG_POSTAMBLE,
+					  buffer);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x1)
+					fwprintf((dev,
+					  HBA_FLAGS_DBG_FW_PRINT_B,
+					  AAC_DEBUG_PREAMBLE "%s\n"
+					  AAC_DEBUG_POSTAMBLE,
+					  buffer));
+#endif
+#endif
+					sprintf(cp = buffer, "%*s", header_length, "");
+					cp += header_length;
+				}
+				sprintf (cp, "%02x ", *(fib++));
+				cp += strlen(cp);
+				--len;
+			}
+			if (cp > &buffer[header_length]) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+				printk (KERN_DEBUG
+				  AAC_DEBUG_PREAMBLE "%s\n"
+				  AAC_DEBUG_POSTAMBLE, buffer);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x1)
+				fwprintf((dev,
+				  HBA_FLAGS_DBG_FW_PRINT_B,
+				  AAC_DEBUG_PREAMBLE "%s\n"
+				  AAC_DEBUG_POSTAMBLE, buffer));
+#endif
+#endif
+			}
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB7))
+			if (nblank(fwprintf(x)))
+				dev->FwDebugFlags = DebugFlags;
+#endif
+		}
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		printk(KERN_DEBUG AAC_DEBUG_PREAMBLE
+		  "aac_fib_send(%x,,%d,...)\n"
+		  AAC_DEBUG_POSTAMBLE, kfib->header.Command,
+		  le16_to_cpu(kfib->header.Size));
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x4)
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  AAC_DEBUG_PREAMBLE "aac_fib_send(%x,,%d,...)"
+		  AAC_DEBUG_POSTAMBLE, kfib->header.Command,
+		  le16_to_cpu(kfib->header.Size)));
+#endif
+#endif
+#endif
 		retval = aac_fib_send(le16_to_cpu(kfib->header.Command), fibptr,
 				le16_to_cpu(kfib->header.Size) , FsaNormal,
 				1, 1, NULL, NULL);
-		if (retval) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+			printk(KERN_DEBUG AAC_DEBUG_PREAMBLE
+			  "aac_fib_send(%x,,%d,...) returns %d\n"
+			  AAC_DEBUG_POSTAMBLE, kfib->header.Command,
+			  le16_to_cpu(kfib->header.Size, retval));
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x4)
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  AAC_DEBUG_PREAMBLE "aac_fib_send(%x,,%d,...) returns %d"
+			  AAC_DEBUG_POSTAMBLE, kfib->header.Command,
+			  le16_to_cpu(kfib->header.Size), retval));
+#endif
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x5) == 0x1)
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  AAC_DEBUG_PREAMBLE "FIB=%p returns %d"
+			  AAC_DEBUG_POSTAMBLE, kfib, retval));
+#endif
+#endif
+		if (aac_fib_complete(fibptr) != 0) {
+			if (!retval)
+				retval = -EINVAL;
 			goto cleanup;
 		}
-		if (aac_fib_complete(fibptr) != 0) {
-			retval = -EINVAL;
+		if (retval) {
 			goto cleanup;
 		}
 	}
@@ -145,6 +372,44 @@ static int ioctl_send_fib(struct aac_dev * dev, void __user *arg)
 	 *	was already included by the adapter.)
 	 */
 
+	/* handle special case CT_ID_CONFLICT for Smart HBA mapping */
+	cresp = (struct aac_container_resp *) kfib->data;
+	if (le32_to_cpu(cresp->type) == CT_GET_PHYDEV_INFO &&
+	  le32_to_cpu(cresp->response) == ST_OK &&
+	  le32_to_cpu(cresp->dummy1) == CT_ID_CONFLICT) {
+	  struct aac_phydev_info_resp *pdev_info =
+		(struct aac_phydev_info_resp *)cresp->data;
+	  u32 bus, tid;
+	  int found = 0;
+
+	  if (!le32_to_cpu(pdev_info->bFsaInitialized) &&
+	 	le32_to_cpu(pdev_info->bNativeHbaEnabled)) {
+		bus = AAC_SMART_HBA_NATIVE_BUS;
+		tid = le32_to_cpu(pdev_info->target);
+		if (dev->hba_map[bus][tid].devtype == AAC_DEVTYPE_NATIVE_RAW &&
+			dev->hba_map[bus][tid].rmw_nexus ==
+				*(__le32 *)pdev_info->sasPhy[0].it_nexus) {
+			pdev_info->hostBusPhy0 = 
+				cpu_to_le32(aac_phys_to_logical(bus));
+			pdev_info->hostTargetPhy0 = pdev_info->target;
+			pdev_info->hostLunPhy0 = 0;
+			found++;
+		}
+		bus = AAC_DUAL_PORT_NATIVE_BUS;
+		if (dev->hba_map[bus][tid].devtype == AAC_DEVTYPE_NATIVE_RAW &&
+			dev->hba_map[bus][tid].rmw_nexus ==
+				*(__le32 *)pdev_info->sasPhy[1].it_nexus) {
+			pdev_info->hostBusPhy1 = 
+				cpu_to_le32(aac_phys_to_logical(bus));
+			pdev_info->hostTargetPhy1 = pdev_info->target;
+			pdev_info->hostLunPhy1 = 0;
+			found++;
+		}
+	  }
+	  if (found)
+		cresp->dummy1 = cpu_to_le32(CT_OK);
+	}
+
 	retval = 0;
 	if (copy_to_user(arg, (void *)kfib, size))
 		retval = -EFAULT;
@@ -156,6 +421,35 @@ cleanup:
 	}
 	if (retval != -ERESTARTSYS)
 		aac_fib_free(fibptr);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL) || defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+	else {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		printk(KERN_DEBUG AAC_DEBUG_PREAMBLE
+		  "ioctl_send_fib(%p,%p) returns -ERESTARTSYS\n"
+		  AAC_DEBUG_POSTAMBLE, dev, arg);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x2)
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "ioctl_send_fib(%p,%p) returns -ERESTARTSYS"
+		  AAC_DEBUG_POSTAMBLE, dev, arg));
+#endif
+#endif
+		return retval;
+	}
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	printk(KERN_DEBUG AAC_DEBUG_PREAMBLE
+	  "ioctl_send_fib(%p,%p) returns %d\n"
+	  AAC_DEBUG_POSTAMBLE, dev, arg, retval);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x2)
+	fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  AAC_DEBUG_PREAMBLE "ioctl_send_fib(%p,%p) returns %d"
+	  AAC_DEBUG_POSTAMBLE, dev, arg, retval));
+#endif
+#endif
 	return retval;
 }
 
@@ -191,7 +485,12 @@ static int open_getadapter_fib(struct aac_dev * dev, void __user *arg)
 		/*
 		 *	Initialize the mutex used to wait for the next AIF.
 		 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,38))
+		init_MUTEX_LOCKED(&fibctx->wait_sem);
+#else
 		sema_init(&fibctx->wait_sem, 0);
+#endif
+
 		fibctx->wait = 0;
 		/*
 		 *	Initialize the fibs and set the count of fibs on
@@ -248,7 +547,14 @@ static int next_getadapter_fib(struct aac_dev * dev, void __user *arg)
 	unsigned long flags;
 
 	if(copy_from_user((void *)&f, arg, sizeof(struct fib_ioctl)))
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL) && defined(AAC_DEBUG_INSTRUMENT_AIF))
+	{
+		printk(KERN_INFO"next_getadapter_fib(%p,%p)=-EFAULT\n", dev, arg);
+#endif
 		return -EFAULT;
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL) && defined(AAC_DEBUG_INSTRUMENT_AIF))
+	}
+#endif
 	/*
 	 *	Verify that the HANDLE passed in was a valid AdapterFibContext
 	 *
@@ -273,6 +579,9 @@ static int next_getadapter_fib(struct aac_dev * dev, void __user *arg)
 	if (!fibctx) {
 		spin_unlock_irqrestore(&dev->fib_lock, flags);
 		dprintk ((KERN_INFO "Fib Context not found\n"));
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL) && defined(AAC_DEBUG_INSTRUMENT_AIF))
+		printk(KERN_INFO"next_getadapter_fib(%p,%p)=-EINVAL no fib context\n", dev, arg);
+#endif
 		return -EINVAL;
 	}
 
@@ -280,6 +589,9 @@ static int next_getadapter_fib(struct aac_dev * dev, void __user *arg)
 		 (fibctx->size != sizeof(struct aac_fib_context))) {
 		spin_unlock_irqrestore(&dev->fib_lock, flags);
 		dprintk ((KERN_INFO "Fib Context corrupt?\n"));
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL) && defined(AAC_DEBUG_INSTRUMENT_AIF))
+		printk(KERN_INFO"next_getadapter_fib(%p,%p)=-EINVAL fib context corrupt\n", dev, arg);
+#endif
 		return -EINVAL;
 	}
 	status = 0;
@@ -289,6 +601,7 @@ static int next_getadapter_fib(struct aac_dev * dev, void __user *arg)
 	 */
 return_fib:
 	if (!list_empty(&fibctx->fib_list)) {
+//		struct list_head * entry;
 		/*
 		 *	Pull the next fib from the fibs
 		 */
@@ -301,6 +614,12 @@ return_fib:
 		if (copy_to_user(f.fib, fib->hw_fib_va, sizeof(struct hw_fib))) {
 			kfree(fib->hw_fib_va);
 			kfree(fib);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL) && defined(AAC_DEBUG_INSTRUMENT_AIF))
+			printk(KERN_INFO
+			  "next_getadapter_fib(%p,%p)=-EFAULT copy_to_user(%p,%p,%u)\n",
+			  dev, arg, f.fib, fib->hw_fib_va,
+			  (unsigned)sizeof(struct hw_fib));
+#endif
 			return -EFAULT;
 		}
 		/*
@@ -309,20 +628,62 @@ return_fib:
 		kfree(fib->hw_fib_va);
 		kfree(fib);
 		status = 0;
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL) && defined(AAC_DEBUG_INSTRUMENT_AIF))
+		printk(KERN_INFO"next_getadapter_fib(%p,%p)=0\n", dev, arg);
+#endif
 	} else {
 		spin_unlock_irqrestore(&dev->fib_lock, flags);
 		/* If someone killed the AIF aacraid thread, restart it */
 		status = !dev->aif_thread;
+#if (defined(HAS_FIND_TASK_BY_PID))
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,16))
+		if (!status) { /* Insurance */
+			read_lock(&tasklist_lock);
+#else
+		if (!status) /* Insurance */
+#endif
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+			status = !find_task_by_pid(dev->thread_pid);
+#else
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+			status = !find_task_by_pid(dev->thread->pid);
+#else
+			status = !find_task_by_vpid(dev->thread->pid);
+#endif
+#endif
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,16))
+			read_unlock(&tasklist_lock);
+		}
+#endif
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN) || ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)) && ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,11)) && !defined(PCI_HAS_SHUTDOWN)))))
+		if (!dev->shutdown)
+#endif
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD) && (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)))
+		if (!dev->thread_die)
+#endif
 		if (status && !dev->in_reset && dev->queues && dev->fsa_dev) {
 			/* Be paranoid, be very paranoid! */
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+			kill_proc(dev->thread_pid, SIGKILL, 0);
+#else
 			kthread_stop(dev->thread);
+#endif
 			ssleep(1);
 			dev->aif_thread = 0;
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+			dev->thread_pid = kernel_thread(
+			  (int (*)(void *))aac_command_thread, dev, 0);
+#else
 			dev->thread = kthread_run(aac_command_thread, dev, dev->name);
+#endif
 			ssleep(1);
 		}
 		if (f.wait) {
 			if(down_interruptible(&fibctx->wait_sem) < 0) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL) && defined(AAC_DEBUG_INSTRUMENT_AIF))
+				printk(KERN_INFO"next_getadapter_fib(%p,%p)=-EINTR\n", dev, arg);
+#endif
 				status = -ERESTARTSYS;
 			} else {
 				/* Lock again and retry */
@@ -331,6 +692,9 @@ return_fib:
 			}
 		} else {
 			status = -EAGAIN;
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL) && defined(AAC_DEBUG_INSTRUMENT_AIF))
+			printk(KERN_INFO"next_getadapter_fib(%p,%p)=-EAGAIN\n", dev, arg);
+#endif
 		}
 	}
 	fibctx->jiffies = jiffies/HZ;
@@ -444,7 +808,7 @@ static int check_revision(struct aac_dev *dev, void __user *arg)
 	version += simple_strtol(driver_version + 1, &driver_version, 10) << 16;
 	version += simple_strtol(driver_version + 1, NULL, 10);
 	response.version = cpu_to_le32(version);
-#	ifdef AAC_DRIVER_BUILD
+#	if (defined(AAC_DRIVER_BUILD))
 		response.build = cpu_to_le32(AAC_DRIVER_BUILD);
 #	else
 		response.build = cpu_to_le32(9999);
@@ -455,6 +819,56 @@ static int check_revision(struct aac_dev *dev, void __user *arg)
 	return 0;
 }
 
+#if (defined(CODE_STREAM_IDENTIFIER) && !defined(CONFIG_COMMUNITY_KERNEL))
+/**
+ *	check_code_stream	-	close down user fib context
+ *	@dev: adapter
+ *	@arg: ioctl arguments
+ *
+ *	This routine returns the driver code stream identifier
+ */
+
+static int check_code_stream_identifier(struct aac_dev *dev, void __user *arg)
+{
+	struct VersionMatch response;
+
+	memset (&response, 0, sizeof(response));
+	strncpy (response.driver, CODE_STREAM_IDENTIFIER,
+	  MAX_CODE_STREAM_IDENTIFIER_LENGTH);
+	strncpy (response.firmware, dev->code_stream_identifier,
+	  MAX_CODE_STREAM_IDENTIFIER_LENGTH);
+	if (response.firmware[0] == '\0')
+		response.status = VERSION_MATCH_UNSUPPORTED;
+	else if (strncmp(response.driver, response.firmware,
+	  MAX_CODE_STREAM_IDENTIFIER_LENGTH))
+		response.status = VERSION_MATCH_FAILED;
+	else
+		response.status = VERSION_MATCH_SUCCESS;
+
+	if (copy_to_user(arg, &response, sizeof(response)))
+		return -EFAULT;
+	return 0;
+}
+#endif
+
+static int aac_error_inject(struct aac_dev *dev, void __user *arg)
+{
+	struct aac_error_inject_str inj;
+	struct fsa_dev_info *fsa_dev_ptr;
+
+	fsa_dev_ptr = dev->fsa_dev;
+	if (!fsa_dev_ptr)
+		return -EBUSY;
+
+	if (copy_from_user(&inj, arg, sizeof(struct aac_error_inject_str)))
+		return -EFAULT;
+
+	if (inj.type == 1)
+		dev->simulated_scsi_error = (1 << inj.value);
+	else if (inj.type == 2)
+		dev->simulated_tgt_failure = (1 << inj.value);
+	return 0;
+}	
 
 /**
  *
@@ -467,20 +881,22 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 	struct fib* srbfib;
 	int status;
 	struct aac_srb *srbcmd = NULL;
+	struct aac_hba_cmd_req *hbacmd = NULL;
 	struct user_aac_srb *user_srbcmd = NULL;
 	struct user_aac_srb __user *user_srb = arg;
 	struct aac_srb_reply __user *user_reply;
-	struct aac_srb_reply* reply;
-	u32 fibsize = 0;
+	u32 chn, fibsize = 0;
 	u32 flags = 0;
 	s32 rcode = 0;
 	u32 data_dir;
-	void __user *sg_user[32];
-	void *sg_list[32];
+	void __user *sg_user[HBA_MAX_SG_EMBEDDED];
+	void *sg_list[HBA_MAX_SG_EMBEDDED];
+	u32 sg_count[HBA_MAX_SG_EMBEDDED];
 	u32 sg_indx = 0;
 	u32 byte_count = 0;
 	u32 actual_fibsize64, actual_fibsize = 0;
-	int i;
+	int i, is_native_device;
+	u64 address;
 
 
 	if (dev->in_reset) {
@@ -497,11 +913,6 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 	if (!(srbfib = aac_fib_alloc(dev))) {
 		return -ENOMEM;
 	}
-	aac_fib_init(srbfib);
-	/* raw_srb FIB is not FastResponseCapable */
-	srbfib->hw_fib_va->header.XferState &= ~cpu_to_le32(FastResponseCapable);
-
-	srbcmd = (struct aac_srb*) fib_data(srbfib);
 
 	memset(sg_list, 0, sizeof(sg_list)); /* cleanup may take issue */
 	if(copy_from_user(&fibsize, &user_srb->count,sizeof(u32))){
@@ -510,8 +921,7 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 		goto cleanup;
 	}
 
-	if ((fibsize < (sizeof(struct user_aac_srb) - sizeof(struct user_sgentry))) ||
-	    (fibsize > (dev->max_fib_size - sizeof(struct aac_fibhdr)))) {
+	if (fibsize > (dev->max_fib_size - sizeof(struct aac_fibhdr))) {
 		rcode = -EINVAL;
 		goto cleanup;
 	}
@@ -527,22 +937,31 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 		rcode = -EFAULT;
 		goto cleanup;
 	}
-
-	user_reply = arg+fibsize;
+#	if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		{
+			u8 * srb = (u8 *)user_srbcmd;
+			unsigned len = fibsize;
+			char buffer[80];
+			char * cp = buffer;
+
+			strcpy(cp, "SRB=");
+			cp += 4;
+			while (len > 0) {
+				if (cp >= &buffer[sizeof(buffer)-4]) {
+					printk (KERN_INFO "%s\n", buffer);
+					strcpy(cp = buffer, "    ");
+					cp += 4;
+				}
+				sprintf (cp, "%02x ", *(srb++));
+				cp += strlen(cp);
+				--len;
+			}
+			if (cp > &buffer[4])
+				printk (KERN_INFO "%s\n", buffer);
+		}
+#	endif
 
 	flags = user_srbcmd->flags; /* from user in cpu order */
-	// Fix up srb for endian and force some values
-
-	srbcmd->function = cpu_to_le32(SRBF_ExecuteScsi);	// Force this
-	srbcmd->channel	 = cpu_to_le32(user_srbcmd->channel);
-	srbcmd->id	 = cpu_to_le32(user_srbcmd->id);
-	srbcmd->lun	 = cpu_to_le32(user_srbcmd->lun);
-	srbcmd->timeout	 = cpu_to_le32(user_srbcmd->timeout);
-	srbcmd->flags	 = cpu_to_le32(flags);
-	srbcmd->retry_limit = 0; // Obsolete parameter
-	srbcmd->cdb_size = cpu_to_le32(user_srbcmd->cdb_size);
-	memcpy(srbcmd->cdb, user_srbcmd->cdb, sizeof(srbcmd->cdb));
-
 	switch (flags & (SRB_DataIn | SRB_DataOut)) {
 	case SRB_DataOut:
 		data_dir = DMA_TO_DEVICE;
@@ -557,8 +976,12 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 		data_dir = DMA_NONE;
 	}
 	if (user_srbcmd->sg.count > ARRAY_SIZE(sg_list)) {
-		dprintk((KERN_DEBUG"aacraid: too many sg entries %d\n",
-		  le32_to_cpu(srbcmd->sg.count)));
+		dprintk((KERN_DEBUG"aacraid: too many sg entries %d\n", user_srbcmd->sg.count));
+		rcode = -EINVAL;
+		goto cleanup;
+	}
+	if ((data_dir == DMA_NONE) && user_srbcmd->sg.count) {
+		dprintk((KERN_DEBUG"aacraid: SG with no direction specified in Raw SRB command\n"));
 		rcode = -EINVAL;
 		goto cleanup;
 	}
@@ -578,13 +1001,121 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 		rcode = -EINVAL;
 		goto cleanup;
 	}
-	if ((data_dir == DMA_NONE) && user_srbcmd->sg.count) {
-		dprintk((KERN_DEBUG"aacraid: SG with no direction specified in Raw SRB command\n"));
-		rcode = -EINVAL;
-		goto cleanup;
+	
+	chn = aac_logical_to_phys(user_srbcmd->channel);
+	if (chn < AAC_MAX_NATIVE_BUSES && user_srbcmd->id < AAC_MAX_NATIVE_TARGETS && 
+		dev->hba_map[chn][user_srbcmd->id].devtype == AAC_DEVTYPE_NATIVE_RAW) {
+		is_native_device = 1;
+		hbacmd = (struct aac_hba_cmd_req *)srbfib->hw_fib_va;
+		memset(hbacmd, 0, 96);	/* sizeof(*hbacmd) is not necessary */
+	
+		/* iu_type is a parameter of aac_hba_send */
+		switch (data_dir) {
+		case DMA_TO_DEVICE:
+			hbacmd->byte1 = 2;
+			break;
+		case DMA_FROM_DEVICE:
+		case DMA_BIDIRECTIONAL:
+			hbacmd->byte1 = 1;
+			break;
+		case DMA_NONE:
+		default:
+			break;
+		}
+		hbacmd->lun[1] = cpu_to_le32(user_srbcmd->lun);
+		hbacmd->it_nexus = dev->hba_map[chn][user_srbcmd->id].rmw_nexus;
+
+		/* we fill in reply_qid later in aac_src_deliver_message */
+		/* we fill in iu_type, request_id later in aac_hba_send */
+		/* we fill in emb_data_desc_count, data_length later in sg list build */
+	
+		memcpy(hbacmd->cdb, user_srbcmd->cdb, sizeof(hbacmd->cdb));
+
+		address = (u64)srbfib->hw_error_pa;
+		hbacmd->error_ptr_hi = cpu_to_le32((u32)(address >> 32));
+		hbacmd->error_ptr_lo = cpu_to_le32((u32)(address & 0xffffffff));
+		hbacmd->error_length = cpu_to_le32(FW_ERROR_BUFFER_SIZE);
+		hbacmd->emb_data_desc_count = cpu_to_le32(user_srbcmd->sg.count);
+		srbfib->hbacmd_size = 64 + 
+			user_srbcmd->sg.count * sizeof(struct aac_hba_sgl);
+		
+	} else {
+		is_native_device = 0;
+		aac_fib_init(srbfib);
+		
+		/* raw_srb FIB is not FastResponseCapable */
+		srbfib->hw_fib_va->header.XferState &= ~cpu_to_le32(FastResponseCapable);
+
+		srbcmd = (struct aac_srb*) fib_data(srbfib);
+	
+		// Fix up srb for endian and force some values
+
+		srbcmd->function = cpu_to_le32(SRBF_ExecuteScsi);	// Force this
+		srbcmd->channel	 = cpu_to_le32(user_srbcmd->channel);
+		srbcmd->id	 = cpu_to_le32(user_srbcmd->id);
+		srbcmd->lun	 = cpu_to_le32(user_srbcmd->lun);
+		srbcmd->timeout	 = cpu_to_le32(user_srbcmd->timeout);
+		srbcmd->flags	 = cpu_to_le32(flags);
+		srbcmd->retry_limit = 0; // Obsolete parameter
+		srbcmd->cdb_size = cpu_to_le32(user_srbcmd->cdb_size);
+		memcpy(srbcmd->cdb, user_srbcmd->cdb, sizeof(srbcmd->cdb));
 	}
+
 	byte_count = 0;
-	if (dev->adapter_info.options & AAC_OPT_SGMAP_HOST64) {
+	if (is_native_device) {
+		struct user_sgmap* usg32 = &user_srbcmd->sg;
+		struct user_sgmap64* usg64 = (struct user_sgmap64*)&user_srbcmd->sg;
+		for (i = 0; i < usg32->count; i++) {
+			void *p;
+			u64 addr;
+			
+			sg_count[i] = (actual_fibsize64 == fibsize) ?
+				usg64->sg[i].count : usg32->sg[i].count;
+			if (sg_count[i] > (dev->scsi_host_ptr->max_sectors << 9)) {
+#				if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+					printk (KERN_INFO "aacraid: upsg->sg[%d].count=%lu>%u\n", 
+						i, sg_count[i], dev->scsi_host_ptr->max_sectors << 9);
+#				endif
+				rcode = -EINVAL;
+				goto cleanup;
+			}
+			p = kmalloc(sg_count[i], GFP_KERNEL|__GFP_DMA);
+			if (!p) {
+				dprintk((KERN_DEBUG"aacraid: Could not allocate SG buffer - size = %d buffer number %d of %d\n",
+					  sg_count[i], i, user_srbcmd->sg.count));
+				rcode = -ENOMEM;
+				goto cleanup;
+			}
+			if (actual_fibsize64 == fibsize) {
+				addr = (u64)usg64->sg[i].addr[0];
+				addr += ((u64)usg64->sg[i].addr[1]) << 32;
+			} else {
+				addr = (u64)usg32->sg[i].addr;
+			}
+			sg_user[i] = (void __user *)(uintptr_t)addr;
+			sg_list[i] = p; // save so we can clean up later
+			sg_indx = i;
+
+			if (flags & SRB_DataOut) {
+				if (copy_from_user(p, sg_user[i], sg_count[i])) {
+					dprintk((KERN_DEBUG"aacraid: Could not copy sg data from user\n"));
+					rcode = -EFAULT;
+					goto cleanup;
+				}
+			}
+			addr = pci_map_single(dev->pdev, p, sg_count[i], data_dir);
+			hbacmd->sge[i].addr_hi = cpu_to_le32((u32)(addr>>32));
+			hbacmd->sge[i].addr_lo = cpu_to_le32((u32)(addr & 0xffffffff));
+			hbacmd->sge[i].len = cpu_to_le32(sg_count[i]);
+			hbacmd->sge[i].flags = 0;
+			byte_count += sg_count[i];
+		}
+		if (usg32->count > 0)	/* embedded sglist */
+			hbacmd->sge[usg32->count-1].flags = cpu_to_le32(0x40000000);
+		hbacmd->data_length = cpu_to_le32(byte_count);
+		status = aac_hba_send(HBA_IU_TYPE_SCSI_CMD_REQ, srbfib, NULL, NULL);
+		
+	} else if (dev->adapter_info.options & AAC_OPT_SGMAP_HOST64) {
 		struct user_sgmap64* upsg = (struct user_sgmap64*)&user_srbcmd->sg;
 		struct sgmap64* psg = (struct sgmap64*)&srbcmd->sg;
 
@@ -596,19 +1127,24 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 			for (i = 0; i < upsg->count; i++) {
 				u64 addr;
 				void* p;
-				if (upsg->sg[i].count >
+				
+				sg_count[i] = upsg->sg[i].count;
+				if (sg_count[i] >
 				    ((dev->adapter_info.options &
 				     AAC_OPT_NEW_COMM) ?
 				      (dev->scsi_host_ptr->max_sectors << 9) :
 				      65536)) {
+#					if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+						printk (KERN_INFO "aacraid: upsg->sg[%d].count=%lu>%u\n", i, sg_count[i], (dev->adapter_info.options & AAC_OPT_NEW_COMM) ? (dev->scsi_host_ptr->max_sectors << 9) : 65536);
+#					endif
 					rcode = -EINVAL;
 					goto cleanup;
 				}
 				/* Does this really need to be GFP_DMA? */
-				p = kmalloc(upsg->sg[i].count,GFP_KERNEL|__GFP_DMA);
+				p = kmalloc(sg_count[i], GFP_KERNEL|__GFP_DMA);
 				if(!p) {
 					dprintk((KERN_DEBUG"aacraid: Could not allocate SG buffer - size = %d buffer number %d of %d\n",
-					  upsg->sg[i].count,i,upsg->count));
+					  sg_count[i], i, upsg->count));
 					rcode = -ENOMEM;
 					goto cleanup;
 				}
@@ -619,18 +1155,18 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 				sg_indx = i;
 
 				if (flags & SRB_DataOut) {
-					if(copy_from_user(p,sg_user[i],upsg->sg[i].count)){
+					if(copy_from_user(p, sg_user[i], sg_count[i])){
 						dprintk((KERN_DEBUG"aacraid: Could not copy sg data from user\n"));
 						rcode = -EFAULT;
 						goto cleanup;
 					}
 				}
-				addr = pci_map_single(dev->pdev, p, upsg->sg[i].count, data_dir);
+				addr = pci_map_single(dev->pdev, p, sg_count[i], data_dir);
 
 				psg->sg[i].addr[0] = cpu_to_le32(addr & 0xffffffff);
 				psg->sg[i].addr[1] = cpu_to_le32(addr>>32);
-				byte_count += upsg->sg[i].count;
-				psg->sg[i].count = cpu_to_le32(upsg->sg[i].count);
+				byte_count += sg_count[i];
+				psg->sg[i].count = cpu_to_le32(sg_count[i]);
 			}
 		} else {
 			struct user_sgmap* usg;
@@ -648,21 +1184,25 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 			for (i = 0; i < usg->count; i++) {
 				u64 addr;
 				void* p;
-				if (usg->sg[i].count >
+				
+				sg_count[i] = usg->sg[i].count;
+				if (sg_count[i] >
 				    ((dev->adapter_info.options &
 				     AAC_OPT_NEW_COMM) ?
 				      (dev->scsi_host_ptr->max_sectors << 9) :
 				      65536)) {
-					kfree(usg);
+#					if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+						printk (KERN_INFO "aacraid: usg->sg[%d].count=%lu>%u\n", i, sg_count[i], (dev->adapter_info.options & AAC_OPT_NEW_COMM) ? (dev->scsi_host_ptr->max_sectors << 9) : 65536);
+#					endif
 					rcode = -EINVAL;
 					goto cleanup;
 				}
 				/* Does this really need to be GFP_DMA? */
-				p = kmalloc(usg->sg[i].count,GFP_KERNEL|__GFP_DMA);
+				p = kmalloc(sg_count[i], GFP_KERNEL|__GFP_DMA);
 				if(!p) {
-					dprintk((KERN_DEBUG "aacraid: Could not allocate SG buffer - size = %d buffer number %d of %d\n",
-					  usg->sg[i].count,i,usg->count));
-					kfree(usg);
+					kfree (usg);
+					dprintk((KERN_DEBUG"aacraid: Could not allocate SG buffer - size = %d buffer number %d of %d\n",
+					  sg_count[i], i, usg->count));
 					rcode = -ENOMEM;
 					goto cleanup;
 				}
@@ -671,24 +1211,53 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 				sg_indx = i;
 
 				if (flags & SRB_DataOut) {
-					if(copy_from_user(p,sg_user[i],upsg->sg[i].count)){
+					if(copy_from_user(p, sg_user[i], sg_count[i])){
 						kfree (usg);
 						dprintk((KERN_DEBUG"aacraid: Could not copy sg data from user\n"));
 						rcode = -EFAULT;
 						goto cleanup;
 					}
 				}
-				addr = pci_map_single(dev->pdev, p, usg->sg[i].count, data_dir);
+				addr = pci_map_single(dev->pdev, p, sg_count[i], data_dir);
 
 				psg->sg[i].addr[0] = cpu_to_le32(addr & 0xffffffff);
 				psg->sg[i].addr[1] = cpu_to_le32(addr>>32);
-				byte_count += usg->sg[i].count;
-				psg->sg[i].count = cpu_to_le32(usg->sg[i].count);
+				byte_count += sg_count[i];
+				psg->sg[i].count = cpu_to_le32(sg_count[i]);
 			}
 			kfree (usg);
 		}
 		srbcmd->count = cpu_to_le32(byte_count);
-		psg->count = cpu_to_le32(sg_indx+1);
+		if(user_srbcmd->sg.count)
+			psg->count = cpu_to_le32(sg_indx+1);
+		else
+			psg->count = 0;
+#		if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+			{
+				u8 * srb = (u8 *)srbfib->hw_fib_va;
+				unsigned len = actual_fibsize + sizeof(struct aac_fibhdr);
+				char buffer[80];
+				char * cp = buffer;
+
+				strcpy(cp, "FIB=");
+				cp += 4;
+				while (len > 0) {
+					if (cp >= &buffer[sizeof(buffer)-4]) {
+						printk (KERN_INFO "%s\n", buffer);
+						strcpy(cp = buffer, "    ");
+						cp += 4;
+					}
+					sprintf (cp, "%02x ", *(srb++));
+					cp += strlen(cp);
+					--len;
+				}
+				if (cp > &buffer[4])
+					printk (KERN_INFO "%s\n", buffer);
+			}
+			printk(KERN_INFO
+			  "aac_fib_send(ScsiPortCommand64,,%d,...)\n",
+			  actual_fibsize);
+#		endif
 		status = aac_fib_send(ScsiPortCommand64, srbfib, actual_fibsize, FsaNormal, 1, 1,NULL,NULL);
 	} else {
 		struct user_sgmap* upsg = &user_srbcmd->sg;
@@ -699,19 +1268,24 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 			for (i = 0; i < upsg->count; i++) {
 				uintptr_t addr;
 				void* p;
+				
+				sg_count[i] = usg->sg[i].count;
 				if (usg->sg[i].count >
 				    ((dev->adapter_info.options &
 				     AAC_OPT_NEW_COMM) ?
 				      (dev->scsi_host_ptr->max_sectors << 9) :
 				      65536)) {
+#					if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+						printk (KERN_INFO "aacraid: usg->sg[%d].count=%lu>%u\n", i, sg_count[i], (dev->adapter_info.options & AAC_OPT_NEW_COMM) ? (dev->scsi_host_ptr->max_sectors << 9) : 65536);
+#					endif
 					rcode = -EINVAL;
 					goto cleanup;
 				}
 				/* Does this really need to be GFP_DMA? */
-				p = kmalloc(usg->sg[i].count,GFP_KERNEL|__GFP_DMA);
+				p = kmalloc(sg_count[i], GFP_KERNEL|__GFP_DMA);
 				if(!p) {
 					dprintk((KERN_DEBUG"aacraid: Could not allocate SG buffer - size = %d buffer number %d of %d\n",
-					  usg->sg[i].count,i,usg->count));
+					  sg_count[i], i, usg->count));
 					rcode = -ENOMEM;
 					goto cleanup;
 				}
@@ -722,34 +1296,39 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 				sg_indx = i;
 
 				if (flags & SRB_DataOut) {
-					if(copy_from_user(p,sg_user[i],usg->sg[i].count)){
+					if(copy_from_user(p, sg_user[i], sg_count[i])){
 						dprintk((KERN_DEBUG"aacraid: Could not copy sg data from user\n"));
 						rcode = -EFAULT;
 						goto cleanup;
 					}
 				}
-				addr = pci_map_single(dev->pdev, p, usg->sg[i].count, data_dir);
+				addr = pci_map_single(dev->pdev, p, sg_count[i], data_dir);
 
 				psg->sg[i].addr = cpu_to_le32(addr & 0xffffffff);
-				byte_count += usg->sg[i].count;
-				psg->sg[i].count = cpu_to_le32(usg->sg[i].count);
+				byte_count += sg_count[i];
+				psg->sg[i].count = cpu_to_le32(sg_count[i]);
 			}
 		} else {
 			for (i = 0; i < upsg->count; i++) {
 				dma_addr_t addr;
 				void* p;
-				if (upsg->sg[i].count >
+				
+				sg_count[i] = upsg->sg[i].count;
+				if (sg_count[i] >
 				    ((dev->adapter_info.options &
 				     AAC_OPT_NEW_COMM) ?
 				      (dev->scsi_host_ptr->max_sectors << 9) :
 				      65536)) {
+#					if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+						printk (KERN_INFO "aacraid: upsg->sg[%d].count=%lu>%u\n", i, sg_count[i], (dev->adapter_info.options & AAC_OPT_NEW_COMM) ? (dev->scsi_host_ptr->max_sectors << 9) : 65536);
+#					endif
 					rcode = -EINVAL;
 					goto cleanup;
 				}
-				p = kmalloc(upsg->sg[i].count, GFP_KERNEL);
+				p = kmalloc(sg_count[i], GFP_KERNEL);
 				if (!p) {
 					dprintk((KERN_DEBUG"aacraid: Could not allocate SG buffer - size = %d buffer number %d of %d\n",
-					  upsg->sg[i].count, i, upsg->count));
+					  sg_count[i], i, upsg->count));
 					rcode = -ENOMEM;
 					goto cleanup;
 				}
@@ -758,31 +1337,60 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 				sg_indx = i;
 
 				if (flags & SRB_DataOut) {
-					if(copy_from_user(p, sg_user[i],
-							upsg->sg[i].count)) {
+					if(copy_from_user(p, sg_user[i], sg_count[i])) {
 						dprintk((KERN_DEBUG"aacraid: Could not copy sg data from user\n"));
 						rcode = -EFAULT;
 						goto cleanup;
 					}
 				}
 				addr = pci_map_single(dev->pdev, p,
-					upsg->sg[i].count, data_dir);
+					sg_count[i], data_dir);
 
 				psg->sg[i].addr = cpu_to_le32(addr);
-				byte_count += upsg->sg[i].count;
-				psg->sg[i].count = cpu_to_le32(upsg->sg[i].count);
+				byte_count += sg_count[i];
+				psg->sg[i].count = cpu_to_le32(sg_count[i]);
 			}
 		}
 		srbcmd->count = cpu_to_le32(byte_count);
-		psg->count = cpu_to_le32(sg_indx+1);
+		if (user_srbcmd->sg.count)
+			psg->count = cpu_to_le32(sg_indx+1);
+		else
+			psg->count = 0;
+#		if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+			{
+				u8 * srb = (u8 *)srbfib->hw_fib_va;
+				unsigned len = actual_fibsize + sizeof(struct aac_fibhdr);
+				char buffer[80];
+				char * cp = buffer;
+
+				strcpy(cp, "FIB=");
+				cp += 4;
+				while (len > 0) {
+					if (cp >= &buffer[sizeof(buffer)-4]) {
+						printk (KERN_INFO "%s\n", buffer);
+						strcpy(cp = buffer, "    ");
+						cp += 4;
+					}
+					sprintf (cp, "%02x ", *(srb++));
+					cp += strlen(cp);
+					--len;
+				}
+				if (cp > &buffer[4])
+					printk (KERN_INFO "%s\n", buffer);
+			}
+			printk(KERN_INFO
+			  "aac_fib_send(ScsiPortCommand,,%d,...)\n",
+			  actual_fibsize);
+#		endif
 		status = aac_fib_send(ScsiPortCommand, srbfib, actual_fibsize, FsaNormal, 1, 1, NULL, NULL);
 	}
+	
 	if (status == -ERESTARTSYS) {
 		rcode = -ERESTARTSYS;
 		goto cleanup;
 	}
 
-	if (status != 0){
+	if (status != 0) {
 		dprintk((KERN_DEBUG"aacraid: Could not send raw srb fib to hba\n"));
 		rcode = -ENXIO;
 		goto cleanup;
@@ -790,11 +1398,7 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 
 	if (flags & SRB_DataIn) {
 		for(i = 0 ; i <= sg_indx; i++){
-			byte_count = le32_to_cpu(
-			  (dev->adapter_info.options & AAC_OPT_SGMAP_HOST64)
-			      ? ((struct sgmap64*)&srbcmd->sg)->sg[i].count
-			      : srbcmd->sg.sg[i].count);
-			if(copy_to_user(sg_user[i], sg_list[i], byte_count)){
+			if (copy_to_user(sg_user[i], sg_list[i], sg_count[i])) {
 				dprintk((KERN_DEBUG"aacraid: Could not copy sg data to user\n"));
 				rcode = -EFAULT;
 				goto cleanup;
@@ -803,11 +1407,41 @@ static int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
 		}
 	}
 
-	reply = (struct aac_srb_reply *) fib_data(srbfib);
-	if(copy_to_user(user_reply,reply,sizeof(struct aac_srb_reply))){
-		dprintk((KERN_DEBUG"aacraid: Could not copy reply to user\n"));
-		rcode = -EFAULT;
-		goto cleanup;
+	user_reply = arg + fibsize;
+	if (is_native_device) {
+		struct aac_hba_resp *err = 
+			&((struct aac_native_hba *)srbfib->hw_fib_va)->resp.err;
+		struct aac_srb_reply reply;
+			
+		reply.status = ST_OK;	
+		if (srbfib->flags & FIB_CONTEXT_FLAG_FASTRESP) {
+			/* fast response */
+			reply.srb_status = SRB_STATUS_SUCCESS;
+			reply.scsi_status = 0;
+			reply.data_xfer_length = byte_count;
+		} else {
+			reply.srb_status = err->service_response;
+			reply.scsi_status = err->status;
+			reply.data_xfer_length = byte_count - 
+				le32_to_cpu(err->residual_count);
+			reply.sense_data_size = err->sense_response_data_len;
+			memcpy(reply.sense_data, err->sense_response_buf, 
+				AAC_SENSE_BUFFERSIZE);
+		}
+		if (copy_to_user(user_reply, &reply, sizeof(struct aac_srb_reply))) {
+			dprintk((KERN_DEBUG"aacraid: Could not copy reply to user\n"));
+			rcode = -EFAULT;
+			goto cleanup;
+		}
+	} else {
+		struct aac_srb_reply *reply;
+
+		reply = (struct aac_srb_reply *) fib_data(srbfib);
+		if (copy_to_user(user_reply, reply, sizeof(struct aac_srb_reply))) {
+			dprintk((KERN_DEBUG"aacraid: Could not copy reply to user\n"));
+			rcode = -EFAULT;
+			goto cleanup;
+		}
 	}
 
 cleanup:
@@ -848,14 +1482,39 @@ int aac_do_ioctl(struct aac_dev * dev, int cmd, void __user *arg)
 {
 	int status;
 
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	if (cmd != FSACTL_GET_NEXT_ADAPTER_FIB)
+		printk("aac_do_ioctl(%p,%x,%p)\n", dev, cmd, arg);
+#endif
 	/*
 	 *	HBA gets first crack
 	 */
 
 	status = aac_dev_ioctl(dev, cmd, arg);
-	if (status != -ENOTTY)
+	if(status != -ENOTTY)
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	{
+		printk("aac_do_ioctl returns %d\n", status);
+#endif
 		return status;
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	}
+#endif
 
+#if (defined(AAC_CSMI))
+	/*
+	 *	HP gets second crack
+	 */
+	 
+	status = aac_csmi_ioctl(dev, cmd, arg);
+	if (status != -ENOTTY) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		printk("aac_do_ioctl returns %d\n", status);
+#endif
+		return status;
+	}
+
+#endif
 	switch (cmd) {
 	case FSACTL_MINIPORT_REV_CHECK:
 		status = check_revision(dev, arg);
@@ -879,10 +1538,23 @@ int aac_do_ioctl(struct aac_dev * dev, int cmd, void __user *arg)
 	case FSACTL_GET_PCI_INFO:
 		status = aac_get_pci_info(dev,arg);
 		break;
+#if (defined(CODE_STREAM_IDENTIFIER) && !defined(CONFIG_COMMUNITY_KERNEL))
+	case FSACTL_GET_VERSION_MATCHING:
+		status = check_code_stream_identifier(dev,arg);
+		break;
+#endif
+	case FSACTL_ERROR_INJECT:
+		status = aac_error_inject(dev, arg);
+		break;
 	default:
 		status = -ENOTTY;
 		break;
 	}
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	if (cmd != FSACTL_GET_NEXT_ADAPTER_FIB)
+		printk("aac_do_ioctl returns %d\n", status);
+#endif
 	return status;
 }
+#endif
 
diff --git a/drivers/scsi/aacraid/comminit.c b/drivers/scsi/aacraid/comminit.c
index 177b094..42831b1 100644
--- a/drivers/scsi/aacraid/comminit.c
+++ b/drivers/scsi/aacraid/comminit.c
@@ -1,12 +1,11 @@
 /*
  *	Adaptec AAC series RAID controller driver
- *	(c) Copyright 2001 Red Hat Inc.
+ *	(c) Copyright 2001 Red Hat Inc.	<alan@redhat.com>
  *
  * based on the old aacraid driver that is..
  * Adaptec aacraid device driver for Linux.
  *
- * Copyright (c) 2000-2010 Adaptec, Inc.
- *               2010 PMC-Sierra, Inc. (aacraid@pmc-sierra.com)
+ * Copyright (c) 2000-2007 Adaptec, Inc. (aacraid@adaptec.com)
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -33,16 +32,30 @@
 #include <linux/kernel.h>
 #include <linux/init.h>
 #include <linux/types.h>
+//#include <linux/sched.h>
 #include <linux/pci.h>
 #include <linux/spinlock.h>
 #include <linux/slab.h>
 #include <linux/blkdev.h>
+#include <linux/version.h>	/* Needed for the following */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,2))
 #include <linux/completion.h>
+#endif
 #include <linux/mm.h>
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 #include <scsi/scsi_host.h>
+#else
+#include "scsi.h"
+#include "hosts.h"
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+#include <asm/semaphore.h>
+#endif
 
 #include "aacraid.h"
 
+void aac_define_int_mode(struct aac_dev *dev);
+
 struct aac_common aac_config = {
 	.irq_mod = 1
 };
@@ -51,21 +64,42 @@ static int aac_alloc_comm(struct aac_dev *dev, void **commaddr, unsigned long co
 {
 	unsigned char *base;
 	unsigned long size, align;
-	const unsigned long fibsize = 4096;
+	const unsigned long fibsize = dev->max_fib_size;
 	const unsigned long printfbufsiz = 256;
 	unsigned long host_rrq_size = 0;
 	struct aac_init *init;
+#if (((__GNUC__ * 10000) + (__GNUC_MINOR__ * 100) + __GNUC_PATCHLEVEL__) > 400002)
 	dma_addr_t phys;
+#else
+	dma_addr_t phys = 0;
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,7)) || !defined(CONFIG_GART_IOMMU))
 	unsigned long aac_max_hostphysmempages;
+#endif
 
 	if (dev->comm_interface == AAC_COMM_MESSAGE_TYPE1 ||
-	    dev->comm_interface == AAC_COMM_MESSAGE_TYPE2)
-		host_rrq_size = (dev->scsi_host_ptr->can_queue
-			+ AAC_NUM_MGT_FIB) * sizeof(u32);
-	size = fibsize + sizeof(struct aac_init) + commsize +
-			commalign + printfbufsiz + host_rrq_size;
+		dev->comm_interface == AAC_COMM_MESSAGE_TYPE2) 
+		host_rrq_size = 
+			(dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB) * sizeof(u32);
+	size = fibsize + sizeof(struct aac_init) + commsize + commalign + printfbufsiz + host_rrq_size;
+
+#if 0 && ((defined(CONFIG_X86) || defined(CONFIG_X86_64)) && (KERNEL_VERSION_CODE < KERNEL_VERSION(2,5,0)))
+	base = kmalloc(size, GFP_ATOMIC|GFP_KERNEL);
+	if (base) {
+		phys = pci_map_single(dev->pdev, base, size, DMA_BIDIRECTIONAL);
+		if (phys > (0x80000000UL - size)) {
+			kfree(base);
+			base = NULL;
+		}
+	}
+	if (base == NULL)
+#endif
  
 	base = pci_alloc_consistent(dev->pdev, size, &phys);
+#	if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+		printk(KERN_INFO "pci_alloc_consistent(%p,%lu,%p={0x%lx))=%p\n",
+		   dev->pdev, size, &phys, (unsigned long)phys, base);
+#	endif
 
 	if(base == NULL)
 	{
@@ -75,9 +109,9 @@ static int aac_alloc_comm(struct aac_dev *dev, void **commaddr, unsigned long co
 	dev->comm_addr = (void *)base;
 	dev->comm_phys = phys;
 	dev->comm_size = size;
-	
+
 	if (dev->comm_interface == AAC_COMM_MESSAGE_TYPE1 ||
-	    dev->comm_interface == AAC_COMM_MESSAGE_TYPE2) {
+		dev->comm_interface == AAC_COMM_MESSAGE_TYPE2) { 
 		dev->host_rrq = (u32 *)(base + fibsize);
 		dev->host_rrq_pa = phys + fibsize;
 		memset(dev->host_rrq, 0, host_rrq_size);
@@ -85,13 +119,17 @@ static int aac_alloc_comm(struct aac_dev *dev, void **commaddr, unsigned long co
 
 	dev->init = (struct aac_init *)(base + fibsize + host_rrq_size);
 	dev->init_pa = phys + fibsize + host_rrq_size;
+#	if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+		printk(KERN_INFO "aac->init=%p aac->init_pa=0x%lx\n",
+		  dev->init, (unsigned long)dev->init_pa);
+#	endif
 
 	init = dev->init;
 
 	init->InitStructRevision = cpu_to_le32(ADAPTER_INIT_STRUCT_REVISION);
 	if (dev->max_fib_size != sizeof(struct hw_fib))
 		init->InitStructRevision = cpu_to_le32(ADAPTER_INIT_STRUCT_REVISION_4);
-	init->MiniPortRevision = cpu_to_le32(Sa_MINIPORT_REVISION);
+	init->NoOfMSIXVectors = cpu_to_le32(Sa_MINIPORT_REVISION);
 	init->fsrev = cpu_to_le32(dev->fsrev);
 
 	/*
@@ -111,14 +149,31 @@ static int aac_alloc_comm(struct aac_dev *dev, void **commaddr, unsigned long co
 	 * had *troubles* dealing with the math overloading past 32 bits, thus
 	 * we must limit this field.
 	 */
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,7)) && !defined(__VMKLNX__))
 	aac_max_hostphysmempages = dma_get_required_mask(&dev->pdev->dev) >> 12;
 	if (aac_max_hostphysmempages < AAC_MAX_HOSTPHYSMEMPAGES)
 		init->HostPhysMemPages = cpu_to_le32(aac_max_hostphysmempages);
 	else
 		init->HostPhysMemPages = cpu_to_le32(AAC_MAX_HOSTPHYSMEMPAGES);
+#elif (defined(CONFIG_GART_IOMMU))
+	/*
+	 * This assumes the memory is mapped zero->n, which isn't
+	 * always true on real computers. It also has some slight problems
+	 * with the GART on x86-64. I've btw never tried DMA from PCI space
+	 * on this platform but don't be surprised if its problematic.
+	 */
+	init->HostPhysMemPages = cpu_to_le32(AAC_MAX_HOSTPHYSMEMPAGES);
+#else
+	/* num_physpages is in system page units. */
+	aac_max_hostphysmempages = num_physpages << (PAGE_SHIFT - 12);
+	if (aac_max_hostphysmempages < AAC_MAX_HOSTPHYSMEMPAGES)
+		init->HostPhysMemPages = cpu_to_le32(aac_max_hostphysmempages);
+	else 
+		init->HostPhysMemPages = cpu_to_le32(AAC_MAX_HOSTPHYSMEMPAGES);
+#endif
 
 	init->InitFlags = cpu_to_le32(INITFLAGS_DRIVER_USES_UTC_TIME |
-		INITFLAGS_DRIVER_SUPPORTS_PM);
+								  INITFLAGS_DRIVER_SUPPORTS_PM);
 	init->MaxIoCommands = cpu_to_le32(dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB);
 	init->MaxIoSize = cpu_to_le32(dev->scsi_host_ptr->max_sectors << 9);
 	init->MaxFibSize = cpu_to_le32(dev->max_fib_size);
@@ -129,28 +184,38 @@ static int aac_alloc_comm(struct aac_dev *dev, void **commaddr, unsigned long co
 		dprintk((KERN_WARNING"aacraid: New Comm Interface enabled\n"));
 	} else if (dev->comm_interface == AAC_COMM_MESSAGE_TYPE1) {
 		init->InitStructRevision = cpu_to_le32(ADAPTER_INIT_STRUCT_REVISION_6);
-		init->InitFlags |= cpu_to_le32(INITFLAGS_NEW_COMM_SUPPORTED |
+		init->InitFlags |= cpu_to_le32(INITFLAGS_NEW_COMM_SUPPORTED | 
 			INITFLAGS_NEW_COMM_TYPE1_SUPPORTED | INITFLAGS_FAST_JBOD_SUPPORTED);
-		init->HostRRQ_AddrHigh = cpu_to_le32((u32)((u64)dev->host_rrq_pa >> 32));
-		init->HostRRQ_AddrLow = cpu_to_le32((u32)(dev->host_rrq_pa & 0xffffffff));
+		init->HostRRQ_AddrHigh = (u32)((u64)dev->host_rrq_pa >> 32);
+		init->HostRRQ_AddrLow = (u32)(dev->host_rrq_pa & 0xffffffff);
 		dprintk((KERN_WARNING"aacraid: New Comm Interface type1 enabled\n"));
 	} else if (dev->comm_interface == AAC_COMM_MESSAGE_TYPE2) {
 		init->InitStructRevision = cpu_to_le32(ADAPTER_INIT_STRUCT_REVISION_7);
-		init->InitFlags |= cpu_to_le32(INITFLAGS_NEW_COMM_SUPPORTED |
+		init->InitFlags |= cpu_to_le32(INITFLAGS_NEW_COMM_SUPPORTED | 
 			INITFLAGS_NEW_COMM_TYPE2_SUPPORTED | INITFLAGS_FAST_JBOD_SUPPORTED);
-		init->HostRRQ_AddrHigh = cpu_to_le32((u32)((u64)dev->host_rrq_pa >> 32));
-		init->HostRRQ_AddrLow = cpu_to_le32((u32)(dev->host_rrq_pa & 0xffffffff));
-		init->MiniPortRevision = cpu_to_le32(0L);		/* number of MSI-X */
+		init->HostRRQ_AddrHigh = (u32)((u64)dev->host_rrq_pa >> 32);
+		init->HostRRQ_AddrLow = (u32)(dev->host_rrq_pa & 0xffffffff);
+		init->NoOfMSIXVectors = cpu_to_le32(dev->max_msix);		/* number of MSI-X */
+		/* must be the COMM_PREFERRED_SETTINGS values */
+#if 0
+		init->MaxIoSize = cpu_to_le32(256L * 1024L);	/* always 256KB */
+		init->MaxFibSize = cpu_to_le32(2L * 1024L);		/* always 2KB */
+#endif
 		dprintk((KERN_WARNING"aacraid: New Comm Interface type2 enabled\n"));
 	}
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	else if (dev->comm_interface == AAC_COMM_APRE) {
+		init->InitFlags |= cpu_to_le32(INITFLAGS_APRE_SUPPORTED);
+		dprintk((KERN_WARNING"aacraid: APRE Interface enabled\n"));
+	}
+#endif
 
 	/*
 	 * Increment the base address by the amount already used
 	 */
 	base = base + fibsize + host_rrq_size + sizeof(struct aac_init);
-	phys = (dma_addr_t)((ulong)phys + fibsize + host_rrq_size +
+	phys = (dma_addr_t)((ulong)phys + fibsize + host_rrq_size + 
 		sizeof(struct aac_init));
-
 	/*
 	 *	Align the beginning of Headers to commalign
 	 */
@@ -179,9 +244,13 @@ static int aac_alloc_comm(struct aac_dev *dev, void **commaddr, unsigned long co
     
 static void aac_queue_init(struct aac_dev * dev, struct aac_queue * q, u32 *mem, int qsize)
 {
-	q->numpending = 0;
+	atomic_set(&q->numpending, 0);
 	q->dev = dev;
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__VMKLNX__))
+	q->cmdready = (struct semaphore) __SEMAPHORE_INITIALIZER(q->cmdready, 0);
+#else
 	init_waitqueue_head(&q->cmdready);
+#endif
 	INIT_LIST_HEAD(&q->cmdq);
 	init_waitqueue_head(&q->qfull);
 	spin_lock_init(&q->lockdata);
@@ -228,6 +297,13 @@ int aac_send_shutdown(struct aac_dev * dev)
 	/* FIB should be freed only after getting the response from the F/W */
 	if (status != -ERESTARTSYS)
 		aac_fib_free(fibctx);
+	dev->adapter_shutdown = 1;
+	if ((dev->pdev->device == PMC_DEVICE_S7 ||
+	     dev->pdev->device == PMC_DEVICE_S8 ||
+	     dev->pdev->device == PMC_DEVICE_S9) &&
+	     dev->msi_enabled)
+		aac_src_access_devreg(dev, AAC_ENABLE_INTX);
+
 	return status;
 }
 
@@ -256,12 +332,22 @@ static int aac_comm_init(struct aac_dev * dev)
 	 *	on the system memory size.  We also initialize the mutex used
 	 *	to protect the zone.
 	 */
+#if (!defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__) && !defined(__VMKLNX__))
 	spin_lock_init(&dev->fib_lock);
+#endif
 
 	/*
-	 *	Allocate the physically contiguous space for the commuication
+	 *	Allocate the physically contigous space for the commuication
 	 *	queue headers. 
 	 */
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	if (dev->comm_interface == AAC_COMM_APRE) {
+		hdrsize = sizeof(u32) * 2;
+		queuesize = (128 + sizeof(struct donelist_entry))
+		          * (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB)
+		          + (sizeof(struct donelist_entry) * 20);
+	}
+#endif
 
 	size = hdrsize + queuesize;
 
@@ -271,6 +357,19 @@ static int aac_comm_init(struct aac_dev * dev)
 	queues = (struct aac_entry *)(((ulong)headers) + hdrsize);
 
 	/* Adapter to Host normal priority Command queue */ 
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	if (dev->comm_interface == AAC_COMM_APRE) {
+		comm->queue[ApreCmdQueue].base = queues;
+		aac_queue_init(dev, &comm->queue[ApreCmdQueue], headers,
+		  dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB);
+		comm->queue[ApreCmdQueue].NxtDoneListEntry =
+		    comm->queue[ApreCmdQueue].DoneListPool = (void *)queues
+		        + (128
+		        * (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB));
+		comm->queue[ApreCmdQueue].Credits = APRE_MAX_CREDITS;
+		return 0;
+	}
+#endif
 	comm->queue[HostNormCmdQueue].base = queues;
 	aac_queue_init(dev, &comm->queue[HostNormCmdQueue], headers, HOST_NORM_CMD_ENTRIES);
 	queues += HOST_NORM_CMD_ENTRIES;
@@ -341,6 +440,7 @@ struct aac_dev *aac_init_adapter(struct aac_dev *dev)
 	dev->management_fib_count = 0;
 	spin_lock_init(&dev->manage_lock);
 	spin_lock_init(&dev->sync_lock);
+	spin_lock_init(&dev->iq_lock);
 	dev->max_fib_size = sizeof(struct hw_fib);
 	dev->sg_tablesize = host->sg_tablesize = (dev->max_fib_size
 		- sizeof(struct aac_fibhdr)
@@ -348,31 +448,69 @@ struct aac_dev *aac_init_adapter(struct aac_dev *dev)
 			/ sizeof(struct sgentry);
 	dev->comm_interface = AAC_COMM_PRODUCER;
 	dev->raw_io_interface = dev->raw_io_64 = 0;
-
+#	if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+		status[0] = 0xFFFFFFFF;
+#	endif
 	if ((!aac_adapter_sync_cmd(dev, GET_ADAPTER_PROPERTIES,
-		0, 0, 0, 0, 0, 0, status+0, status+1, status+2, NULL, NULL)) &&
+		0,0,0,0,0,0, status+0, status+1, status+2, status+3, NULL)) &&
 	 		(status[0] == 0x00000001)) {
+#		if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+			printk(KERN_INFO "GET_ADAPTER_PROPERTIES: 0x%x %u 0x%x\n",
+			  status[1], status[2], status[3]);
+#		endif
+		dev->doorbell_mask = status[3];
 		if (status[1] & le32_to_cpu(AAC_OPT_NEW_COMM_64))
 			dev->raw_io_64 = 1;
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+		if (dev->a_ops.adapter_comm) {
+			if (status[1] & le32_to_cpu(AAC_OPT_NEW_COMM)) {
+				dev->comm_interface = AAC_COMM_MESSAGE;
+				dev_>raw_io_interface = 1;	
+			} else if (status[1] & le32_to_cpu(AAC_OPT_APRE)) {
+				dev->comm_interface = AAC_COMM_APRE;
+				dev->raw_io_interface = dev->raw_io_64 = 1;
+				host->sg_tablesize = dev->sg_tablesize = 17;
+				if (host->can_queue > 128)
+					host->can_queue = 128;
+			}
+		}
+#else
 		dev->sync_mode = aac_sync_mode;
 		if (dev->a_ops.adapter_comm &&
 			(status[1] & le32_to_cpu(AAC_OPT_NEW_COMM))) {
-				dev->comm_interface = AAC_COMM_MESSAGE;
-				dev->raw_io_interface = 1;
+			dev->comm_interface = AAC_COMM_MESSAGE;
+			dev->raw_io_interface = 1;
 			if ((status[1] & le32_to_cpu(AAC_OPT_NEW_COMM_TYPE1))) {
 				/* driver supports TYPE1 (Tupelo) */
 				dev->comm_interface = AAC_COMM_MESSAGE_TYPE1;
 			} else if ((status[1] & le32_to_cpu(AAC_OPT_NEW_COMM_TYPE2))) {
-				/* driver supports TYPE2 (Denali) */
+				/* driver supports TYPE2 (Denali, Yosemite) */
 				dev->comm_interface = AAC_COMM_MESSAGE_TYPE2;
-			} else if ((status[1] & le32_to_cpu(AAC_OPT_NEW_COMM_TYPE4)) ||
-				  (status[1] & le32_to_cpu(AAC_OPT_NEW_COMM_TYPE3))) {
-				/* driver doesn't TYPE3 and TYPE4 */
-				/* switch to sync. mode */
+			} else if ((status[1] & le32_to_cpu(AAC_OPT_NEW_COMM_TYPE3)) ||
+				(status[1] & le32_to_cpu(AAC_OPT_NEW_COMM_TYPE4))) {
+				/* not supported TYPE - switch to sync. mode */
 				dev->comm_interface = AAC_COMM_MESSAGE_TYPE2;
 				dev->sync_mode = 1;
 			}
 		}
+#endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+		/*
+		 * serveraid 8i returns 0x800000 (8MB) for this,
+		 * which works fine in Linux and the COS, but
+		 * fails in the VMkernel which imposes a max
+		 * size of 1MB.  as such, clamp anything over
+		 * 1MB down to AAC_MIN_FOOTPRINT_SIZE and use
+		 * the old communications interface.
+		 *	-gmccready@vmware.com
+		 */
+#		define VMK_MAX_MAP_SIZE 0x100000
+
+		if (status[2] > VMK_MAX_MAP_SIZE) {
+			printk("aacraid: card asked for %d (0x%x), we truncated to %d (0x%x)\n", status[2], status[2], AAC_MIN_FOOTPRINT_SIZE, AAC_MIN_FOOTPRINT_SIZE);
+			dev->comm_interface = AAC_COMM_PRODUCER;
+		}
+#endif
 		if ((dev->comm_interface == AAC_COMM_MESSAGE) &&
 		    (status[2] > dev->base_size)) {
 			aac_adapter_ioremap(dev, 0);
@@ -388,6 +526,16 @@ struct aac_dev *aac_init_adapter(struct aac_dev *dev)
 			}
 		}
 	}
+#	if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+		else
+			printk(KERN_INFO
+			  "GET_ADAPTER_PROPERTIES 0x%lx failed\n",
+			  (unsigned long)status[0]);
+		status[0] = 0xFFFFFFFF;
+#	endif
+	dev->max_msix = 0;
+	dev->msi_enabled = 0;
+	dev->adapter_shutdown = 0;
 	if ((!aac_adapter_sync_cmd(dev, GET_COMM_PREFERRED_SETTINGS,
 	  0, 0, 0, 0, 0, 0,
 	  status+0, status+1, status+2, status+3, status+4))
@@ -399,17 +547,30 @@ struct aac_dev *aac_init_adapter(struct aac_dev *dev)
 		 *	status[2] & 0xFFFF	maximum SG elements from driver
 		 *	status[3] & 0xFFFF	maximum number FIBs outstanding
 		 */
+#		if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+			printk(KERN_INFO "GET_COMM_PREFERRED_SETTINGS: %uKB %uB sg<%u sg<%u queue<%u\n",
+			  status[1] >> 16, status[1] & 0xFFFF,
+			  status[2] >> 16, status[2] & 0xFFFF,
+			  status[3] & 0xFFFF);
+#		endif
 		host->max_sectors = (status[1] >> 16) << 1;
-		/* Multiple of 32 for PMC */
-		dev->max_fib_size = status[1] & 0xFFE0;
+		dev->max_fib_size = status[1] & 0xFFE0;	/* multiple of 32 for PMC */
 		host->sg_tablesize = status[2] >> 16;
 		dev->sg_tablesize = status[2] & 0xFFFF;
 		if (dev->pdev->device == PMC_DEVICE_S7 ||
 		    dev->pdev->device == PMC_DEVICE_S8 ||
-		    dev->pdev->device == PMC_DEVICE_S9)
-			host->can_queue = ((status[3] >> 16) ? (status[3] >> 16) :
-				(status[3] & 0xFFFF)) - AAC_NUM_MGT_FIB;
-		else
+		    dev->pdev->device == PMC_DEVICE_S9) {
+#if (defined(AAC_CITRIX))
+			if (host->can_queue > 248)
+				host->can_queue = 248;
+#elif (defined(CONFIG_XEN) && LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19))
+			if (host->can_queue > 128)
+				host->can_queue = 128;
+#else
+			if (host->can_queue > (status[3] >> 16) - AAC_NUM_MGT_FIB)
+				host->can_queue = (status[3] >> 16) - AAC_NUM_MGT_FIB;
+#endif
+		} else if (host->can_queue > (status[3] & 0xFFFF) - AAC_NUM_MGT_FIB)
 			host->can_queue = (status[3] & 0xFFFF) - AAC_NUM_MGT_FIB;
 		dev->max_num_aif = status[4] & 0xFFFF;
 		/*
@@ -425,29 +586,37 @@ struct aac_dev *aac_init_adapter(struct aac_dev *dev)
 			  = (512 - sizeof(struct aac_fibhdr)
 			    - sizeof(struct aac_write) + sizeof(struct sgentry))
 			     / sizeof(struct sgentry);
-			host->can_queue = AAC_NUM_IO_FIB;
 		} else if (acbsize == 2048) {
 			host->max_sectors = 512;
 			dev->max_fib_size = 2048;
 			host->sg_tablesize = 65;
 			dev->sg_tablesize = 81;
-			host->can_queue = 512 - AAC_NUM_MGT_FIB;
+			if (host->can_queue > 512 - AAC_NUM_MGT_FIB)
+				host->can_queue = 512 - AAC_NUM_MGT_FIB;
 		} else if (acbsize == 4096) {
 			host->max_sectors = 1024;
 			dev->max_fib_size = 4096;
 			host->sg_tablesize = 129;
 			dev->sg_tablesize = 166;
-			host->can_queue = 256 - AAC_NUM_MGT_FIB;
+			if (host->can_queue > 256 - AAC_NUM_MGT_FIB)
+				host->can_queue = 256 - AAC_NUM_MGT_FIB;
 		} else if (acbsize == 8192) {
 			host->max_sectors = 2048;
 			dev->max_fib_size = 8192;
 			host->sg_tablesize = 257;
 			dev->sg_tablesize = 337;
-			host->can_queue = 128 - AAC_NUM_MGT_FIB;
+			if (host->can_queue > 128 - AAC_NUM_MGT_FIB)
+				host->can_queue = 128 - AAC_NUM_MGT_FIB;
 		} else if (acbsize > 0) {
 			printk("Illegal acbsize=%d ignored\n", acbsize);
 		}
 	}
+#	if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+		else
+			printk(KERN_INFO
+			  "GET_COMM_PREFERRED_SETTINGS 0x%lx failed\n",
+			  (unsigned long)status[0]);
+#	endif
 	{
 
 		if (numacb > 0) {
@@ -458,18 +627,28 @@ struct aac_dev *aac_init_adapter(struct aac_dev *dev)
 		}
 	}
 
-	if (host->can_queue > AAC_NUM_IO_FIB)
-		host->can_queue = AAC_NUM_IO_FIB;
-
+	if (dev->pdev->device == PMC_DEVICE_S6 ||
+	    dev->pdev->device == PMC_DEVICE_S7 ||
+	    dev->pdev->device == PMC_DEVICE_S8 ||
+	    dev->pdev->device == PMC_DEVICE_S9)
+		aac_define_int_mode(dev);
+		
 	/*
 	 *	Ok now init the communication subsystem
 	 */
 
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)) && !defined(HAS_KZALLOC))
+	dev->queues = kmalloc(sizeof(struct aac_queue_block), GFP_KERNEL);
+#else
 	dev->queues = kzalloc(sizeof(struct aac_queue_block), GFP_KERNEL);
+#endif
 	if (dev->queues == NULL) {
 		printk(KERN_ERR "Error could not allocate comm region.\n");
 		return NULL;
 	}
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)) && !defined(HAS_KZALLOC))
+	memset(dev->queues, 0, sizeof(struct aac_queue_block));
+#endif
 
 	if (aac_comm_init(dev)<0){
 		kfree(dev->queues);
@@ -485,8 +664,92 @@ struct aac_dev *aac_init_adapter(struct aac_dev *dev)
 		
 	INIT_LIST_HEAD(&dev->fib_list);
 	INIT_LIST_HEAD(&dev->sync_fib_list);
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+	init_completion(&dev->aif_completion);
+#endif
 
 	return dev;
 }
 
-    
+
+void aac_define_int_mode(struct aac_dev *dev)
+{
+	int i, msi_count;
+	msi_count = i = 0;
+
+	/* max. vectors from GET_COMM_PREFERRED_SETTINGS */
+	if (dev->max_msix == 0 || dev->pdev->device == PMC_DEVICE_S6 || dev->sync_mode) {
+		dev->max_msix = 1;
+		dev->vector_cap = dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB;
+#if (defined(AAC_DEBUG_INSTRUMENT_MSIX))
+		printk(KERN_INFO "aacraid: dev->msi_enabled %d dev->msi %d dev->vector_cap %d dev->max_msix %d dev->scsi_host_ptr->can_queue %d\n",
+			  dev->msi_enabled, dev->msi, dev->vector_cap, dev->max_msix, dev->scsi_host_ptr->can_queue);
+#endif
+		return;
+	}
+
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_ENABLE_MSI))
+#if ((!defined(CONFIG_XEN) || LINUX_VERSION_CODE > KERNEL_VERSION(2,6,19)) || \
+     defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+	/* Don't bother allocating more MSI-X vectors than cpus */
+	msi_count = min(dev->max_msix,
+		(unsigned int)num_online_cpus());
+
+	dev->max_msix = msi_count;
+
+	if (msi_count > AAC_MAX_MSIX)
+		msi_count = AAC_MAX_MSIX;
+
+	for (i = 0; i < msi_count; i++)
+		dev->msixentry[i].entry = i;
+
+	if (msi_count > 1 && pci_find_capability(dev->pdev, PCI_CAP_ID_MSIX)) {
+
+		i = pci_enable_msix(dev->pdev, dev->msixentry, msi_count);
+		/*
+		 * Check how many MSIX vectors are allocated 
+		 */
+		if (i >= 0) {
+			dev->msi_enabled = 1;
+			if (i) {
+				msi_count = i;
+				if (pci_enable_msix(dev->pdev, dev->msixentry, msi_count)) {
+					dev->msi_enabled = 0;
+					printk(KERN_ERR "%s%d: MSIX not supported!! Will try MSI 0x%x.\n",
+							dev->name, dev->id, i);
+				}
+			}
+		} else {
+			dev->msi_enabled = 0;
+			printk(KERN_ERR "%s%d: MSIX not supported!! Will try MSI 0x%x.\n",
+					dev->name, dev->id, i);
+		}
+	}
+
+	if (!dev->msi_enabled) {
+		msi_count = 1;
+		i = !pci_enable_msi(dev->pdev);
+
+		if (i) {
+			dev->msi_enabled = 1;
+			dev->msi = 1;
+		}
+		else
+			printk(KERN_ERR "%s%d: MSI not supported!! Will try INTx 0x%x.\n",
+					dev->name, dev->id, i);
+	}
+#endif
+#endif
+
+	if (!dev->msi_enabled)
+		dev->max_msix = msi_count = 1;
+	else {
+		if (dev->max_msix > msi_count)
+			dev->max_msix = msi_count;
+	}
+	dev->vector_cap = (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB) / msi_count;
+#if (defined(AAC_DEBUG_INSTRUMENT_MSIX))
+		printk(KERN_INFO "aacraid: dev->msi_enabled %d dev->msi %d dev->vector_cap %d dev->max_msix %d dev->scsi_host_ptr->can_queue %d\n",
+			  dev->msi_enabled, dev->msi, dev->vector_cap, dev->max_msix, dev->scsi_host_ptr->can_queue);
+#endif
+}
diff --git a/drivers/scsi/aacraid/commsup.c b/drivers/scsi/aacraid/commsup.c
index 1be0776..176f780 100644
--- a/drivers/scsi/aacraid/commsup.c
+++ b/drivers/scsi/aacraid/commsup.c
@@ -1,12 +1,11 @@
 /*
  *	Adaptec AAC series RAID controller driver
- *	(c) Copyright 2001 Red Hat Inc.
+ *	(c) Copyright 2001 Red Hat Inc.	<alan@redhat.com>
  *
  * based on the old aacraid driver that is..
  * Adaptec aacraid device driver for Linux.
  *
- * Copyright (c) 2000-2010 Adaptec, Inc.
- *               2010 PMC-Sierra, Inc. (aacraid@pmc-sierra.com)
+ * Copyright (c) 2000-2007 Adaptec, Inc. (aacraid@adaptec.com)
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -37,18 +36,54 @@
 #include <linux/pci.h>
 #include <linux/spinlock.h>
 #include <linux/slab.h>
+#include <linux/version.h>	/* Needed for the following */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,2))
 #include <linux/completion.h>
+#endif
 #include <linux/blkdev.h>
 #include <linux/delay.h>
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,5)) || defined(HAS_KTHREAD))
 #include <linux/kthread.h>
+#endif
 #include <linux/interrupt.h>
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26))
 #include <linux/semaphore.h>
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+#include <linux/smp_lock.h>
+#include <asm/uaccess.h>
+#include "scsi.h"
+#include "hosts.h"
+#if (!defined(SCSI_HAS_HOST_LOCK))
+#include <linux/blk.h>	/* for io_request_lock definition */
+#endif
+#else
+#if (((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,3)) && defined(MODULE))) && !defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__) && !defined(__VMKLNX__)
+#include <linux/proc_fs.h>
+#include <linux/smp_lock.h>
+#endif
 #include <scsi/scsi.h>
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,1)) && !defined(DID_OK))
+#define DID_OK 0x00
+#endif
 #include <scsi/scsi_host.h>
 #include <scsi/scsi_device.h>
 #include <scsi/scsi_cmnd.h>
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,9))
+#include <scsi/scsi_eh.h>
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11)) && defined(MODULE))
+#include <scsi/scsi_driver.h>
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+#include <asm/semaphore.h>
+#endif
 
 #include "aacraid.h"
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#include "fwdebug.h"
+#endif
 
 /**
  *	fib_map_alloc		-	allocate the fib objects
@@ -60,15 +95,37 @@
 
 static int fib_map_alloc(struct aac_dev *dev)
 {
+	if (AAC_MAX_NATIVE_SIZE > dev->max_fib_size)
+		dev->max_cmd_size = AAC_MAX_NATIVE_SIZE;
+	else
+		dev->max_cmd_size = dev->max_fib_size;
+
 	dprintk((KERN_INFO
 	  "allocate hardware fibs pci_alloc_consistent(%p, %d * (%d + %d), %p)\n",
-	  dev->pdev, dev->max_fib_size, dev->scsi_host_ptr->can_queue,
+	  dev->pdev, dev->max_cmd_size, dev->scsi_host_ptr->can_queue,
 	  AAC_NUM_MGT_FIB, &dev->hw_fib_pa));
-	dev->hw_fib_va = pci_alloc_consistent(dev->pdev,
-		(dev->max_fib_size + sizeof(struct aac_fib_xporthdr))
-		* (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB) + (ALIGN32 - 1),
-		&dev->hw_fib_pa);
+#if 0 && ((defined(CONFIG_X86) || defined(CONFIG_X86_64)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)))
+	/* Bug in pci_alloc_consistent dealing with respecting dma map */
+	dev->hw_fib_va = kmalloc(
+	  dev->max_cmd_size * (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB),
+	  GFP_ATOMIC|GFP_KERNEL);
+	if (dev->hw_fib_va) {
+		dev->hw_fib_pa = pci_map_single(dev->pdev, dev->hw_fib_va,
+		  dev->max_fib_size * (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB),
+		  DMA_BIDIRECTIONAL);
+		if (dev->hw_fib_pa > (0x80000000UL
+		  - (dev->max_fib_size
+		   * (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB)))) {
+			kfree(dev->hw_fib_va);
+			dev->hw_fib_va = NULL;
+		}
+	}
 	if (dev->hw_fib_va == NULL)
+#endif
+	if((dev->hw_fib_va = pci_alloc_consistent(dev->pdev, 
+		(dev->max_cmd_size + sizeof(struct aac_fib_xporthdr))
+		* (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB) + 31,
+		&dev->hw_fib_pa)) == NULL)
 		return -ENOMEM;
 	return 0;
 }
@@ -84,8 +141,9 @@ static int fib_map_alloc(struct aac_dev *dev)
 void aac_fib_map_free(struct aac_dev *dev)
 {
 	pci_free_consistent(dev->pdev,
-	  dev->max_fib_size * (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB),
-	  dev->hw_fib_va, dev->hw_fib_pa);
+		(dev->max_cmd_size *
+		dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB),
+	  	dev->hw_fib_va, dev->hw_fib_pa);
 	dev->hw_fib_va = NULL;
 	dev->hw_fib_pa = 0;
 }
@@ -94,7 +152,7 @@ void aac_fib_map_free(struct aac_dev *dev)
  *	aac_fib_setup	-	setup the fibs
  *	@dev: Adapter to set up
  *
- *	Allocate the PCI space for the fibs, map it and then initialise the
+ *	Allocate the PCI space for the fibs, map it and then intialise the
  *	fib area, the unmapped fib data and also the free list
  */
 
@@ -114,12 +172,12 @@ int aac_fib_setup(struct aac_dev * dev)
 		return -ENOMEM;
 
 	/* 32 byte alignment for PMC */
-	hw_fib_pa = (dev->hw_fib_pa + (ALIGN32 - 1)) & ~(ALIGN32 - 1);
+	hw_fib_pa = (dev->hw_fib_pa + 31) & ~31;
 	dev->hw_fib_va = (struct hw_fib *)((unsigned char *)dev->hw_fib_va +
 		(hw_fib_pa - dev->hw_fib_pa));
 	dev->hw_fib_pa = hw_fib_pa;
-	memset(dev->hw_fib_va, 0,
-		(dev->max_fib_size + sizeof(struct aac_fib_xporthdr)) *
+	memset(dev->hw_fib_va, 0, 
+		(dev->max_cmd_size + sizeof(struct aac_fib_xporthdr)) * 
 		(dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB));
 
 	/* add Xport header */
@@ -141,15 +199,25 @@ int aac_fib_setup(struct aac_dev * dev)
 		fibptr->hw_fib_va = hw_fib;
 		fibptr->data = (void *) fibptr->hw_fib_va->data;
 		fibptr->next = fibptr+1;	/* Forward chain the fibs */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,38))
+		init_MUTEX_LOCKED(&fibptr->event_wait);
+#else
 		sema_init(&fibptr->event_wait, 0);
+#endif
 		spin_lock_init(&fibptr->event_lock);
 		hw_fib->header.XferState = cpu_to_le32(0xffffffff);
 		hw_fib->header.SenderSize = cpu_to_le16(dev->max_fib_size);
 		fibptr->hw_fib_pa = hw_fib_pa;
-		hw_fib = (struct hw_fib *)((unsigned char *)hw_fib +
-			dev->max_fib_size + sizeof(struct aac_fib_xporthdr));
-		hw_fib_pa = hw_fib_pa +
-			dev->max_fib_size + sizeof(struct aac_fib_xporthdr);
+		fibptr->hw_sgl_pa = hw_fib_pa +
+			offsetof(struct aac_hba_cmd_req, sge[2]);
+		/* one element is for the ptr to the separate sg list,
+		   second element for 32 byte alignment */
+		fibptr->hw_error_pa = hw_fib_pa +
+			offsetof(struct aac_native_hba, resp.resp_bytes[0]);	
+		hw_fib = (struct hw_fib *)((unsigned char *)hw_fib + 
+			dev->max_cmd_size + sizeof(struct aac_fib_xporthdr));
+		hw_fib_pa = hw_fib_pa + 
+			dev->max_cmd_size + sizeof(struct aac_fib_xporthdr);
 	}
 	/*
 	 *	Add the fib chain to the free list
@@ -195,6 +263,16 @@ struct fib *aac_fib_alloc(struct aac_dev *dev)
 	fibptr->flags = 0;
 	fibptr->callback = NULL;
 	fibptr->callback_data = NULL;
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING))
+	{
+		struct timeval now;
+		do_gettimeofday(&now);
+		fibptr->DriverTimeStartS = now.tv_sec;
+		fibptr->DriverTimeStartuS = now.tv_usec;
+	}
+	fibptr->DriverTimeDoneS = 0;
+	fibptr->DriverTimeDoneuS = 0;
+#endif
 
 	return fibptr;
 }
@@ -208,19 +286,33 @@ struct fib *aac_fib_alloc(struct aac_dev *dev)
 
 void aac_fib_free(struct fib *fibptr)
 {
-	unsigned long flags, flagsv;
 
-	spin_lock_irqsave(&fibptr->event_lock, flagsv);
+	unsigned long flags;
+
+	/* fib with status wait timeout? */
 	if (fibptr->done == 2) {
-		spin_unlock_irqrestore(&fibptr->event_lock, flagsv);
 		return;
 	}
-	spin_unlock_irqrestore(&fibptr->event_lock, flagsv);
 
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING))
+	struct timeval now;
+	do_gettimeofday(&now);
+	fibptr->DriverTimeDoneS = now.tv_sec;
+	fibptr->DriverTimeDoneuS = now.tv_usec;
+	flags = (fibptr->DriverTimeDoneS - fibptr->DriverTimeStartS) * 1000000L
+	      + fibptr->DriverTimeDoneuS - fibptr->DriverTimeStartuS;
+	if (flags > aac_config.peak_duration) {
+		aac_config.peak_duration = flags;
+		printk(KERN_INFO "peak_duration %lduseconds\n", flags);
+		fwprintf((fibptr->dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "peak_duration %lduseconds", flags));
+	}
+#endif
 	spin_lock_irqsave(&fibptr->dev->fib_lock, flags);
 	if (unlikely(fibptr->flags & FIB_CONTEXT_FLAG_TIMED_OUT))
 		aac_config.fib_timeouts++;
-	if (fibptr->hw_fib_va->header.XferState != 0) {
+	if (!(fibptr->flags & FIB_CONTEXT_FLAG_NATIVE_HBA) &&
+		fibptr->hw_fib_va->header.XferState != 0) {
 		printk(KERN_WARNING "aac_fib_free, XferState != 0, fibptr = 0x%p, XferState = 0x%x\n",
 			 (void*)fibptr,
 			 le32_to_cpu(fibptr->hw_fib_va->header.XferState));
@@ -321,7 +413,7 @@ static int aac_get_entry (struct aac_dev * dev, u32 qid, struct aac_entry **entr
 	/* Queue is full */
 	if ((*index + 1) == le32_to_cpu(*(q->headers.consumer))) {
 		printk(KERN_WARNING "Queue %d full, %u outstanding.\n",
-				qid, q->numpending);
+				qid, atomic_read(&q->numpending));
 		return 0;
 	} else {
 		*entry = q->base + *index;
@@ -370,7 +462,7 @@ int aac_queue_get(struct aac_dev * dev, u32 * index, u32 qid, struct hw_fib * hw
 		entry->size = cpu_to_le32(le16_to_cpu(hw_fib->header.Size));
 		entry->addr = hw_fib->header.SenderFibAddress;
 			/* Restore adapters pointer to the FIB */
-		hw_fib->header.u.ReceiverFibAddress = hw_fib->header.SenderFibAddress;  /* Let the adapter now where to find its data */
+		hw_fib->header.u.ReceiverFibAddress = hw_fib->header.SenderFibAddress;	/* Let the adapter now where to find its data */
 		map = 0;
 	}
 	/*
@@ -406,23 +498,29 @@ int aac_queue_get(struct aac_dev * dev, u32 * index, u32 qid, struct hw_fib * hw
  *	an event to wait on must be supplied. This event will be set when a
  *	response FIB is received from the adapter.
  */
+#if (defined(FSACTL_REGISTER_FIB_SEND) && !defined(CONFIG_COMMUNITY_KERNEL))
+#undef aac_fib_send
+fib_send_t aac_fib_send_switch = aac_fib_send;
+#endif
 
 int aac_fib_send(u16 command, struct fib *fibptr, unsigned long size,
 		int priority, int wait, int reply, fib_callback callback,
 		void *callback_data)
+#if (defined(FSACTL_REGISTER_FIB_SEND) && !defined(CONFIG_COMMUNITY_KERNEL))
+#define aac_fib_send aac_fib_send_switch
+#endif
 {
 	struct aac_dev * dev = fibptr->dev;
 	struct hw_fib * hw_fib = fibptr->hw_fib_va;
 	unsigned long flags = 0;
-	unsigned long qflags;
 	unsigned long mflags = 0;
-	unsigned long sflags = 0;
-
+	unsigned long sflags;
 
 	if (!(hw_fib->header.XferState & cpu_to_le32(HostOwned)))
 		return -EBUSY;
+
 	/*
-	 *	There are 5 cases with the wait and response requested flags.
+	 *	There are 5 cases with the wait and reponse requested flags.
 	 *	The only invalid cases are if the caller requests to wait and
 	 *	does not request a response and if the caller does not want a
 	 *	response and the Fib is not allocated from pool. If a response
@@ -444,13 +542,46 @@ int aac_fib_send(u16 command, struct fib *fibptr, unsigned long size,
 	} else if (wait && reply) {
 		hw_fib->header.XferState |= cpu_to_le32(ResponseExpected);
 		FIB_COUNTER_INCREMENT(aac_config.NormalSent);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x8)
+		if ((wait == 1) && (reply == 1) && !callback &&
+		  !callback_data && !list_empty(&dev->entry)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+			printk(KERN_INFO
+			  "aac_fib_send(%u,%p,%lu,%d,1,1,NULL,NULL)\n",
+			  command, fibptr, size, priority);
+#endif
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  "aac_fib_send(%u,%p,%lu,%d,1,1,NULL,NULL)",
+			  command, fibptr, size, priority));
+		}
+#endif
+#endif
+#if (defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX__))
+		/* If wait >0 and reply != 0 then there's a potential
+		 * to land in down() below which will eventually land
+		 * us where we'll try to sleep. We can't sleep in this
+		 * routine because we're in the issuing path for the
+		 * VMkernel. Setting wait <0 causes us to spin for up
+		 * to three minutes with down_trylock() instead of down()
+		 * so we won't trip the World_AssertIsSafeToBlock().
+		 */
+		wait = -1;
+#endif
 	}
 	/*
 	 *	Map the fib into 32bits by using the fib number
 	 */
 
-	hw_fib->header.SenderFibAddress = cpu_to_le32(((u32)(fibptr - dev->fibs)) << 2);
-	hw_fib->header.Handle = (u32)(fibptr - dev->fibs) + 1;
+	hw_fib->header.SenderFibAddress = 
+		cpu_to_le32(((u32)(fibptr - dev->fibs)) << 2);
+	
+	/* use the same shifted value for handle to be compatible
+	 * with the new native hba command handle
+	 */
+	hw_fib->header.Handle = 
+		cpu_to_le32((((u32)(fibptr - dev->fibs)) << 2) + 1);
+
 	/*
 	 *	Set FIB state to indicate where it came from and if we want a
 	 *	response from the adapter. Also load the command from the
@@ -465,6 +596,21 @@ int aac_fib_send(u16 command, struct fib *fibptr, unsigned long size,
 	 */
 	hw_fib->header.Size = cpu_to_le16(sizeof(struct aac_fibhdr) + size);
 	if (le16_to_cpu(hw_fib->header.Size) > le16_to_cpu(hw_fib->header.SenderSize)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x8)
+		if ((wait == 1) && (reply == 1) && !callback &&
+		  !callback_data && !list_empty(&dev->entry)) {
+#if (defined(AAC_DEBUG_INSTRUMNET_IOCTL))
+			printk(KERN_INFO
+			  "aac_fib_send(%u,%p,%lu,%d,1,1,NULL,NULL) returns -EMSGSIZE\n",
+			  command, fibptr, size, priority);
+#endif
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  "aac_fib_send(%u,%p,%lu,%d,1,1,NULL,NULL) returns -EMSGSIZE",
+			  command, fibptr, size, priority));
+		}
+#endif
+#endif
 		return -EMSGSIZE;
 	}
 	/*
@@ -485,6 +631,30 @@ int aac_fib_send(u16 command, struct fib *fibptr, unsigned long size,
 
 	fibptr->done = 0;
 
+#	if (defined(AAC_DEBUG_INSTRUMENT_FIB))
+		printk(KERN_INFO "Fib content %p[%d] P=%llx:\n",
+		  hw_fib, le16_to_cpu(hw_fib->header.Size), fibptr->hw_fib_pa);
+		{
+			int size = le16_to_cpu(hw_fib->header.Size)
+					/ sizeof(u32);
+			char buffer[80];
+			u32 * up = (u32 *)hw_fib;
+
+			while (size > 0) {
+				sprintf (buffer,
+				  "  %08x %08x %08x %08x %08x %08x %08x %08x\n",
+				  up[0], up[1], up[2], up[3], up[4], up[5],
+				  up[6], up[7]);
+				up += 8;
+				size -= 8;
+				if (size < 0) {
+					buffer[73+(size*9)] = '\n';
+					buffer[74+(size*9)] = '\0';
+				}
+				printk(KERN_INFO "%s", buffer);
+			}
+		}
+#	endif
 	FIB_COUNTER_INCREMENT(aac_config.FibsSent);
 
 	dprintk((KERN_DEBUG "Fib contents:.\n"));
@@ -496,14 +666,35 @@ int aac_fib_send(u16 command, struct fib *fibptr, unsigned long size,
 	dprintk((KERN_DEBUG "  fib being sent=%p\n",fibptr));
 
 	if (!dev->queues)
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB) || defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+	{
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x8)
+		if ((wait == 1) && (reply == 1) && !callback &&
+		  !callback_data && !list_empty(&dev->entry)) {
+#if (defined(AAC_DEBUG_INSTRUMNET_IOCTL))
+			printk(KERN_INFO
+			  "aac_fib_send(%u,%p,%lu,%d,1,1,NULL,NULL) returns -EBUSY\n",
+			  command, fibptr, size, priority);
+#endif
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  "aac_fib_send(%u,%p,%lu,%d,1,1,NULL,NULL) returns -EBUSY",
+			  command, fibptr, size, priority));
+		}
+#endif
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB))
+		printk(KERN_INFO "aac_fib_send: dev->queues gone!\n");
+#endif
+#endif
 		return -EBUSY;
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB) || defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+	}
+#endif
 
-	if (wait) {
-
+	if(wait) {
 		spin_lock_irqsave(&dev->manage_lock, mflags);
 		if (dev->management_fib_count >= AAC_NUM_MGT_FIB) {
-			printk(KERN_INFO "No management Fibs Available:%d\n",
-						dev->management_fib_count);
 			spin_unlock_irqrestore(&dev->manage_lock, mflags);
 			return -EBUSY;
 		}
@@ -522,8 +713,8 @@ int aac_fib_send(u16 command, struct fib *fibptr, unsigned long size,
 		} else {
 			dev->sync_fib = fibptr;
 			spin_unlock_irqrestore(&dev->sync_lock, sflags);
-			aac_adapter_sync_cmd(dev, SEND_SYNCHRONOUS_FIB,
-				(u32)fibptr->hw_fib_pa, 0, 0, 0, 0, 0,
+			aac_adapter_sync_cmd(dev, SEND_SYNCHRONOUS_FIB, 
+				(u32)fibptr->hw_fib_pa, 0, 0, 0, 0, 0, 
 				NULL, NULL, NULL, NULL, NULL);
 		}
 		if (wait) {
@@ -538,7 +729,6 @@ int aac_fib_send(u16 command, struct fib *fibptr, unsigned long size,
 	}
 
 	if (aac_adapter_deliver(fibptr) != 0) {
-		printk(KERN_ERR "aac_fib_send: returned -EBUSY\n");
 		if (wait) {
 			spin_unlock_irqrestore(&fibptr->event_lock, flags);
 			spin_lock_irqsave(&dev->manage_lock, mflags);
@@ -548,7 +738,6 @@ int aac_fib_send(u16 command, struct fib *fibptr, unsigned long size,
 		return -EBUSY;
 	}
 
-
 	/*
 	 *	If the caller wanted us to wait for response wait now.
 	 */
@@ -563,20 +752,30 @@ int aac_fib_send(u16 command, struct fib *fibptr, unsigned long size,
 			 * functioning because an interrupt routing or other
 			 * hardware failure has occurred.
 			 */
-			unsigned long timeout = jiffies + (180 * HZ); /* 3 minutes */
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX__))
+			unsigned long count = 180000L;  /* 3 minutes */
+#else
+			unsigned long count = jiffies + (180 * HZ); /* 3 minutes */
+#endif
 			while (down_trylock(&fibptr->event_wait)) {
 				int blink;
-				if (time_is_before_eq_jiffies(timeout)) {
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX__))
+				if (--count == 0) {
+#else
+				if (time_after(jiffies, count)) {
+#endif
 					struct aac_queue * q = &dev->queues->queue[AdapNormCmdQueue];
-					spin_lock_irqsave(q->lock, qflags);
-					q->numpending--;
-					spin_unlock_irqrestore(q->lock, qflags);
+					atomic_dec(&q->numpending);
 					if (wait == -1) {
 	        				printk(KERN_ERR "aacraid: aac_fib_send: first asynchronous command timed out.\n"
 						  "Usually a result of a PCI interrupt routing problem;\n"
 						  "update mother board BIOS or consider utilizing one of\n"
 						  "the SAFE mode kernel options (acpi, apic etc)\n");
 					}
+					spin_lock_irqsave(&fibptr->event_lock, flags);
+					fibptr->done = 2;
+					spin_unlock_irqrestore(&fibptr->event_lock, flags);
+					dprintk((KERN_ERR "aacraid: sync. command timed out after 180 seconds\n"));
 					return -ETIMEDOUT;
 				}
 				if ((blink = aac_adapter_check_health(dev)) > 0) {
@@ -587,27 +786,102 @@ int aac_fib_send(u16 command, struct fib *fibptr, unsigned long size,
 					}
 					return -EFAULT;
 				}
-				/* We used to udelay() here but that absorbed
-				 * a CPU when a timeout occured. Not very
-				 * useful. */
+#if (defined(CONFIG_XEN) && LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19) && !defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX__))
+				udelay(5);
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,32))
 				cpu_relax();
+#else
+				msleep(1);
+#endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX__))
+				/**
+				* We are waiting for an interrupt but might be in a deadlock here.
+				* Since vmkernel is non-preemtible and we are hogging the CPU,
+				* in special circumstances the interrupt handler may not get to run.
+				* For more details, please see PR 414597.
+				*/
+				if ((count % 5L) == 0L) {
+					// busy waiting for at most 5 ms at a time.
+					dprintk((KERN_INFO "aacraid: aac_fib_send: Calling interrupt handler\n"));
+					if (!dev->msi_enabled) {
+						if (dev->pdev->device != PMC_DEVICE_S6 &&
+	    				    	    dev->pdev->device != PMC_DEVICE_S7 &&
+	    				    	    dev->pdev->device != PMC_DEVICE_S8 &&
+	    				    	    dev->pdev->device != PMC_DEVICE_S9) {
+							disable_irq(dev->scsi_host_ptr->irq);
+							aac_adapter_intr(dev);
+							enable_irq(dev->scsi_host_ptr->irq);
+						}
+					}
+				}
+#endif
 			}
 		} else if (down_interruptible(&fibptr->event_wait)) {
-			/* Do nothing ... satisfy
-			 * down_interruptible must_check */
+			fibptr->done = 2;
+			up(&fibptr->event_wait);
 		}
-
 		spin_lock_irqsave(&fibptr->event_lock, flags);
-		if (fibptr->done == 0) {
+		if ((fibptr->done == 0) || (fibptr->done == 2)) {
 			fibptr->done = 2; /* Tell interrupt we aborted */
 			spin_unlock_irqrestore(&fibptr->event_lock, flags);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x8)
+			if ((wait == 1) && (reply == 1) && !callback &&
+			  !callback_data && !list_empty(&dev->entry)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+				printk(KERN_INFO
+				  "aac_fib_send(%u,%p,%lu,%d,1,1,NULL,NULL) returns -EINTR\n",
+				  command, fibptr, size, priority);
+#endif
+				fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+				  "aac_fib_send(%u,%p,%lu,%d,1,1,NULL,NULL) returns -EINTR",
+				  command, fibptr, size, priority));
+			}
+#endif
+#endif
 			return -ERESTARTSYS;
 		}
 		spin_unlock_irqrestore(&fibptr->event_lock, flags);
 		BUG_ON(fibptr->done == 0);
 
 		if(unlikely(fibptr->flags & FIB_CONTEXT_FLAG_TIMED_OUT))
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x8)
+		{
+			if ((wait == 1) && (reply == 1) && !callback &&
+			  !callback_data && !list_empty(&dev->entry)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+				printk(KERN_INFO
+				  "aac_fib_send(%u,%p,%lu,%d,1,1,NULL,NULL) returns -ETIMEDOUT\n",
+				  command, fibptr, size, priority);
+#endif
+				fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+				  "aac_fib_send(%u,%p,%lu,%d,1,1,NULL,NULL) returns -ETIMEDOUT",
+				  command, fibptr, size, priority));
+			}
+			return -ETIMEDOUT;
+		}
+#else
 			return -ETIMEDOUT;
+#endif
+#else
+			return -ETIMEDOUT;
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x8)
+		if ((wait == 1) && (reply == 1) && !callback &&
+		  !callback_data && !list_empty(&dev->entry)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+			printk(KERN_INFO
+			  "aac_fib_send(%u,%p,%lu,%d,1,1,NULL,NULL) returns 0\n",
+			  command, fibptr, size, priority);
+#endif
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  "aac_fib_send(%u,%p,%lu,%d,1,1,NULL,NULL) returns 0",
+			  command, fibptr, size, priority));
+		}
+#endif
+#endif
 		return 0;
 	}
 	/*
@@ -620,6 +894,173 @@ int aac_fib_send(u16 command, struct fib *fibptr, unsigned long size,
 		return 0;
 }
 
+int aac_hba_send(u8 command, struct fib *fibptr, fib_callback callback,
+		void *callback_data)
+{
+	struct aac_dev * dev = fibptr->dev;
+	int wait;
+	unsigned long flags = 0;
+	unsigned long mflags = 0;
+
+	fibptr->flags = (FIB_CONTEXT_FLAG | FIB_CONTEXT_FLAG_NATIVE_HBA);
+	if (callback) {
+		wait = 0;
+		fibptr->callback = callback;
+		fibptr->callback_data = callback_data;
+	} else {	
+#if (defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX__))
+		wait = -1;
+#else
+		wait = 1;
+#endif		
+	}
+	
+	if (command == HBA_IU_TYPE_SCSI_CMD_REQ) {
+		struct aac_hba_cmd_req *hbacmd = 
+			(struct aac_hba_cmd_req *)fibptr->hw_fib_va;
+	
+		hbacmd->iu_type = command;
+		/* bit1 of request_id must be 0 */
+		hbacmd->request_id =
+			cpu_to_le32((((u32)(fibptr - dev->fibs)) << 2) + 1);
+	} else if (command == HBA_IU_TYPE_SCSI_TM_REQ) {
+		struct aac_hba_tm_req *hbacmd = 
+			(struct aac_hba_tm_req *)fibptr->hw_fib_va;
+	
+		hbacmd->iu_type = command;
+		/* bit1 of request_id must be 0 */
+		hbacmd->request_id =
+			cpu_to_le32((((u32)(fibptr - dev->fibs)) << 2) + 1);
+		fibptr->flags |= FIB_CONTEXT_FLAG_NATIVE_HBA_TMF;
+	} else if (command == HBA_IU_TYPE_SATA_REQ) {
+		struct aac_hba_reset_req *hbacmd = 
+			(struct aac_hba_reset_req *)fibptr->hw_fib_va;
+	
+		hbacmd->iu_type = command;
+		/* bit1 of request_id must be 0 */
+		hbacmd->request_id =
+			cpu_to_le32((((u32)(fibptr - dev->fibs)) << 2) + 1);
+		fibptr->flags |= FIB_CONTEXT_FLAG_NATIVE_HBA_TMF;
+	} else {
+		return -EINVAL;
+	}	
+
+	if (wait) {
+		spin_lock_irqsave(&dev->manage_lock, mflags);
+		if (dev->management_fib_count >= AAC_NUM_MGT_FIB) {
+			spin_unlock_irqrestore(&dev->manage_lock, mflags);
+			return -EBUSY;
+		}
+		dev->management_fib_count++;
+		spin_unlock_irqrestore(&dev->manage_lock, mflags);
+		spin_lock_irqsave(&fibptr->event_lock, flags);
+	}	
+	
+	if (aac_adapter_deliver(fibptr) != 0) { 
+		if (wait) {
+			spin_unlock_irqrestore(&fibptr->event_lock, flags);
+			spin_lock_irqsave(&dev->manage_lock, mflags);
+			dev->management_fib_count--;
+			spin_unlock_irqrestore(&dev->manage_lock, mflags);
+		}
+		return -EBUSY;
+	}
+	FIB_COUNTER_INCREMENT(aac_config.NativeSent);
+
+	if (wait) {
+		spin_unlock_irqrestore(&fibptr->event_lock, flags);
+		/* Only set for first known interruptable command */
+		if (wait < 0) {
+			/*
+			 * *VERY* Dangerous to time out a command, the
+			 * assumption is made that we have no hope of
+			 * functioning because an interrupt routing or other
+			 * hardware failure has occurred.
+			 */
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX__))
+			unsigned long count = 180000L;  /* 3 minutes */
+#else
+			unsigned long count = jiffies + (180 * HZ); /* 3 minutes */
+#endif
+			while (down_trylock(&fibptr->event_wait)) {
+				int blink;
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX__))
+				if (--count == 0) {
+#else
+				if (time_after(jiffies, count)) {
+#endif
+					struct aac_queue * q = &dev->queues->queue[AdapNormCmdQueue];
+					atomic_dec(&q->numpending);
+					if (wait == -1) {
+	        				printk(KERN_ERR "aacraid: aac_fib_send: first asynchronous command timed out.\n"
+						  "Usually a result of a PCI interrupt routing problem;\n"
+						  "update mother board BIOS or consider utilizing one of\n"
+						  "the SAFE mode kernel options (acpi, apic etc)\n");
+					}
+					spin_lock_irqsave(&fibptr->event_lock, flags);
+					fibptr->done = 2;
+					spin_unlock_irqrestore(&fibptr->event_lock, flags);
+					dprintk((KERN_ERR "aacraid: sync. command timed out after 180 seconds\n"));
+					return -ETIMEDOUT;
+				}
+				if ((blink = aac_adapter_check_health(dev)) > 0) {
+					if (wait == -1) {
+	        				printk(KERN_ERR "aacraid: aac_fib_send: adapter blinkLED 0x%x.\n"
+						  "Usually a result of a serious unrecoverable hardware problem\n",
+						  blink);
+					}
+					return -EFAULT;
+				}
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX__))
+				msleep(1);
+#else
+				cpu_relax();
+#endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX__))
+				/**
+				* We are waiting for an interrupt but might be in a deadlock here.
+				* Since vmkernel is non-preemtible and we are hogging the CPU,
+				* in special circumstances the interrupt handler may not get to run.
+				* For more details, please see PR 414597.
+				*/
+				if ((count % 5L) == 0L) {
+					// busy waiting for at most 5 ms at a time.
+					dprintk((KERN_INFO "aacraid: aac_fib_send: Calling interrupt handler\n"));
+					if (!dev->msi_enabled) {
+						if (dev->pdev->device != PMC_DEVICE_S6 &&
+	    				    	    dev->pdev->device != PMC_DEVICE_S7 &&
+	    				    	    dev->pdev->device != PMC_DEVICE_S8 &&
+	    				    	    dev->pdev->device != PMC_DEVICE_S9) {
+							disable_irq(dev->scsi_host_ptr->irq);
+							aac_adapter_intr(dev);
+							enable_irq(dev->scsi_host_ptr->irq);
+						}
+					}
+				}
+#endif
+			}
+		} else if (down_interruptible(&fibptr->event_wait)) {
+			fibptr->done = 2;
+			up(&fibptr->event_wait);
+		}
+		spin_lock_irqsave(&fibptr->event_lock, flags);
+		if ((fibptr->done == 0) || (fibptr->done == 2)) {
+			fibptr->done = 2; /* Tell interrupt we aborted */
+			spin_unlock_irqrestore(&fibptr->event_lock, flags);
+			return -ERESTARTSYS;
+		}
+		spin_unlock_irqrestore(&fibptr->event_lock, flags);
+		BUG_ON(fibptr->done == 0);
+
+		if(unlikely(fibptr->flags & FIB_CONTEXT_FLAG_TIMED_OUT))
+			return -ETIMEDOUT;
+
+		return 0;
+	}
+	
+	return -EINPROGRESS;
+}
+
 /**
  *	aac_consumer_get	-	get the top of the queue
  *	@dev: Adapter
@@ -674,7 +1115,11 @@ void aac_consumer_free(struct aac_dev * dev, struct aac_queue *q, u32 qid)
 	if (le32_to_cpu(*q->headers.consumer) >= q->entries)
 		*q->headers.consumer = cpu_to_le32(1);
 	else
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,24)) && !defined(HAS_LE32_ADD_CPU))
+		*q->headers.consumer = cpu_to_le32(le32_to_cpu(*q->headers.consumer)+1);
+#else
 		le32_add_cpu(q->headers.consumer, 1);
+#endif
 
 	if (wasfull) {
 		switch (qid) {
@@ -710,25 +1155,25 @@ int aac_fib_adapter_complete(struct fib *fibptr, unsigned short size)
 	unsigned long nointr = 0;
 	unsigned long qflags;
 
-	if (dev->comm_interface == AAC_COMM_MESSAGE_TYPE1 ||
-	    dev->comm_interface == AAC_COMM_MESSAGE_TYPE2) {
-		kfree(hw_fib);
+	if (dev->comm_interface == AAC_COMM_MESSAGE_TYPE1 || 
+		dev->comm_interface == AAC_COMM_MESSAGE_TYPE2) {
+		kfree (hw_fib);
 		return 0;
 	}
 
 	if (hw_fib->header.XferState == 0) {
 		if (dev->comm_interface == AAC_COMM_MESSAGE)
-			kfree(hw_fib);
+			kfree (hw_fib);
 		return 0;
 	}
 	/*
 	 *	If we plan to do anything check the structure type first.
 	 */
 	if (hw_fib->header.StructType != FIB_MAGIC &&
-	    hw_fib->header.StructType != FIB_MAGIC2 &&
-	    hw_fib->header.StructType != FIB_MAGIC2_64) {
+		hw_fib->header.StructType != FIB_MAGIC2 &&
+		hw_fib->header.StructType != FIB_MAGIC2_64) {
 		if (dev->comm_interface == AAC_COMM_MESSAGE)
-			kfree(hw_fib);
+			kfree (hw_fib);
 		return -EINVAL;
 	}
 	/*
@@ -775,22 +1220,27 @@ int aac_fib_adapter_complete(struct fib *fibptr, unsigned short size)
 
 int aac_fib_complete(struct fib *fibptr)
 {
-	unsigned long flags;
 	struct hw_fib * hw_fib = fibptr->hw_fib_va;
 
 	/*
-	 *	Check for a fib which has already been completed
+	 *	Check for a fib which has already been completed or with a
+	 *	status wait timeout
 	 */
 
-	if (hw_fib->header.XferState == 0)
+	if (fibptr->flags & FIB_CONTEXT_FLAG_NATIVE_HBA) {
+		fib_dealloc(fibptr);
+		return 0;
+	}
+
+	if (hw_fib->header.XferState == 0 || fibptr->done == 2)
 		return 0;
 	/*
 	 *	If we plan to do anything check the structure type first.
 	 */
 
 	if (hw_fib->header.StructType != FIB_MAGIC &&
-	    hw_fib->header.StructType != FIB_MAGIC2 &&
-	    hw_fib->header.StructType != FIB_MAGIC2_64)
+		hw_fib->header.StructType != FIB_MAGIC2 &&
+		hw_fib->header.StructType != FIB_MAGIC2_64)
 		return -EINVAL;
 	/*
 	 *	This block completes a cdb which orginated on the host and we
@@ -798,12 +1248,6 @@ int aac_fib_complete(struct fib *fibptr)
 	 *	command is complete that we had sent to the adapter and this
 	 *	cdb could be reused.
 	 */
-	spin_lock_irqsave(&fibptr->event_lock, flags);
-	if (fibptr->done == 2) {
-		spin_unlock_irqrestore(&fibptr->event_lock, flags);
-		return 0;
-	}
-	spin_unlock_irqrestore(&fibptr->event_lock, flags);
 
 	if((hw_fib->header.XferState & cpu_to_le32(SentFromHost)) &&
 		(hw_fib->header.XferState & cpu_to_le32(AdapterProcessed)))
@@ -837,7 +1281,9 @@ int aac_fib_complete(struct fib *fibptr)
 void aac_printf(struct aac_dev *dev, u32 val)
 {
 	char *cp = dev->printfbuf;
+#if (!defined(AAC_PRINTF_ENABLED))
 	if (dev->printf_enabled)
+#endif
 	{
 		int length = val & 0xffff;
 		int level = (val >> 16) & 0xffff;
@@ -868,21 +1314,37 @@ void aac_printf(struct aac_dev *dev, u32 val)
  *	dispatches it to the appropriate routine for handling.
  */
 
-#define AIF_SNIFF_TIMEOUT	(30*HZ)
+#define AIF_SNIFF_TIMEOUT	(500*HZ)
 static void aac_handle_aif(struct aac_dev * dev, struct fib * fibptr)
 {
 	struct hw_fib * hw_fib = fibptr->hw_fib_va;
 	struct aac_aifcmd * aifcmd = (struct aac_aifcmd *)hw_fib->data;
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,3))
+	int busy;
+#endif
 	u32 channel, id, lun, container;
 	struct scsi_device *device;
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)) && (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,10)) && defined(MODULE))
+	struct scsi_driver * drv;
+#endif
 	enum {
 		NOTHING,
 		DELETE,
 		ADD,
 		CHANGE
 	} device_config_needed = NOTHING;
+//#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,3)) && defined(MODULE))) && !defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX__)
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,3)) && defined(MODULE)))
+	extern struct proc_dir_entry * proc_scsi;
+#endif
 
 	/* Sniff for container changes */
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+	printk (KERN_INFO
+	  "aac_handle_aif: Aif command=%x type=%x container=%d\n",
+	  le32_to_cpu(aifcmd->command), le32_to_cpu(*(__le32 *)aifcmd->data),
+	  le32_to_cpu(((__le32 *)aifcmd->data)[1]));
+#endif
 
 	if (!dev || !dev->fsa_dev)
 		return;
@@ -897,6 +1359,133 @@ static void aac_handle_aif(struct aac_dev * dev, struct fib * fibptr)
 	switch (le32_to_cpu(aifcmd->command)) {
 	case AifCmdDriverNotify:
 		switch (le32_to_cpu(((__le32 *)aifcmd->data)[0])) {
+		case AifRawDeviceRemove:
+			container = le32_to_cpu(((__le32 *)aifcmd->data)[1]);
+			if ((container >> 28)) {
+				container = (u32)-1;
+				break;
+			}
+			channel = (container >> 24) & 0xF;
+			if (channel >= dev->maximum_num_channels) {
+				container = (u32)-1;
+				break;
+			}
+			id = container & 0xFFFF;
+			if (id >= dev->maximum_num_physicals) {
+				container = (u32)-1;
+				break;
+			}
+			lun = (container >> 16) & 0xFF;
+			container = (u32)-1;
+			channel = aac_phys_to_logical(channel);
+			device_config_needed = DELETE;
+			break;
+
+		case AifNativeDeviceAdd:
+		{
+			__le32 handle, nexus;
+			struct fib *fibptr;
+			u32 bus, tgt;
+	
+			handle = ((__le32 *)aifcmd->data)[1];
+			nexus = ((__le32 *)aifcmd->data)[2];
+
+			if ((fibptr = aac_fib_alloc(dev))) {
+			 struct aac_container_cmd *ccmd;
+			 struct aac_container_resp *cresp;
+			 struct aac_phydev_info_resp *pdev_info;
+			 int rcode, found;
+
+			 aac_fib_init(fibptr);
+			 cresp = (struct aac_container_resp *)fib_data(fibptr);
+			 ccmd = (struct aac_container_cmd *)cresp;
+
+			 memset(cresp, 0, sizeof(*cresp));
+			 ccmd->command = cpu_to_le32(VM_ContainerConfig);
+			 ccmd->type = cpu_to_le32(CT_GET_PHYDEV_INFO);
+			 ccmd->handle = handle;
+			 ccmd->cnt_size = cpu_to_le32(
+				sizeof(struct aac_phydev_info_resp));
+
+			if (dev->streamlined_fib_support)
+                                ccmd->cnt_size |= cpu_to_le32(STREAMLINED_CONTINUATION);
+
+			 rcode = aac_fib_send(ContainerCommand,
+				fibptr,
+				sizeof (*ccmd),
+				FsaNormal,
+				1, 1,
+				NULL, NULL);
+
+			 if (rcode >= 0 && le32_to_cpu(cresp->response)==ST_OK
+			  && le32_to_cpu(cresp->dummy1)==CT_ID_CONFLICT) {
+			  pdev_info = (struct aac_phydev_info_resp *)
+			   	cresp->data;
+			  bus = le32_to_cpu(pdev_info->bus);
+			  tgt = le32_to_cpu(pdev_info->target);
+			  if (bus < AAC_MAX_NATIVE_BUSES-1 && 
+			   tgt < AAC_MAX_NATIVE_TARGETS) {
+			   found = 0;	
+			   if (*(__le32 *)pdev_info->sasPhy[0].it_nexus
+				== nexus) {
+				found = 1;
+				bus = AAC_SMART_HBA_NATIVE_BUS;
+			   } else if (*(__le32 *)pdev_info->sasPhy[1].it_nexus
+				== nexus) {
+				found = 1;
+				bus = AAC_DUAL_PORT_NATIVE_BUS;
+			   }
+			   if (found) {
+			   	dev->hba_map[bus][tgt].rmw_nexus = nexus;
+			   	dev->hba_map[bus][tgt].devtype =
+					AAC_DEVTYPE_NATIVE_RAW;
+				channel = aac_phys_to_logical(
+					bus);
+				id = tgt;
+				lun = 0;
+				device_config_needed = ADD;
+			   }
+			  }
+			 }
+			 if (rcode >= 0)
+				aac_fib_complete(fibptr);
+			 if (rcode != -ERESTARTSYS)
+				aac_fib_free(fibptr);
+			}
+			break;
+		}
+
+		case AifNativeDeviceRemove:
+		{
+			__le32 nexus;
+			u32 bus, tgt;
+			int found;
+
+			container = (u32)-1;
+			nexus = ((__le32 *)aifcmd->data)[2];
+			found = 0;
+			for (bus = 0; bus < AAC_MAX_NATIVE_BUSES; bus++) {
+			 for (tgt = 0; tgt < AAC_MAX_NATIVE_TARGETS; tgt++) {
+			  if ((dev->hba_map[bus][tgt].devtype == 
+			   AAC_DEVTYPE_NATIVE_RAW) && 
+			   (dev->hba_map[bus][tgt].rmw_nexus == nexus)) {
+				found = 1;
+				break;
+			  }
+			 }
+			 if (found)
+			  break;	
+			}
+			if (found) {
+				dev->hba_map[bus][tgt].devtype = 0;
+				channel = aac_phys_to_logical(bus);
+				id = tgt;
+				lun = 0;
+				device_config_needed = DELETE;
+			}
+			break;
+		}
+
 		/*
 		 *	Morph or Expand complete
 		 */
@@ -905,6 +1494,16 @@ static void aac_handle_aif(struct aac_dev * dev, struct fib * fibptr)
 			container = le32_to_cpu(((__le32 *)aifcmd->data)[1]);
 			if (container >= dev->maximum_num_containers)
 				break;
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+			channel = CONTAINER_TO_CHANNEL(container);
+			id = CONTAINER_TO_ID(container);
+			lun = CONTAINER_TO_LUN(container);
+			printk (KERN_INFO "container=%d(%d,%d,%d,%d)\n",
+			  container,
+			  (dev && dev->scsi_host_ptr)
+			    ? dev->scsi_host_ptr->host_no
+			    : -1, channel, id, lun);
+#endif
 
 			/*
 			 *	Find the scsi_device associated with the SCSI
@@ -914,16 +1513,53 @@ static void aac_handle_aif(struct aac_dev * dev, struct fib * fibptr)
 			 */
 
 			if ((dev != NULL) && (dev->scsi_host_ptr != NULL)) {
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,3))
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+				device = scsi_device_lookup(dev->scsi_host_ptr,
+					channel, id, lun);
+#else
 				device = scsi_device_lookup(dev->scsi_host_ptr,
 					CONTAINER_TO_CHANNEL(container),
 					CONTAINER_TO_ID(container),
 					CONTAINER_TO_LUN(container));
+#endif
 				if (device) {
 					dev->fsa_dev[container].config_needed = CHANGE;
 					dev->fsa_dev[container].config_waiting_on = AifEnConfigChange;
 					dev->fsa_dev[container].config_waiting_stamp = jiffies;
 					scsi_device_put(device);
 				}
+#else
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0))
+				shost_for_each_device(device,
+					dev->scsi_host_ptr)
+#elif (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+				list_for_each_entry(device,
+					&dev->scsi_host_ptr->my_devices,
+					siblings)
+#else
+				for (device = dev->scsi_host_ptr->host_queue;
+				  device != (struct scsi_device *)NULL;
+				  device = device->next)
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+					if ((device->channel == channel)
+					 && (device->id == id)
+					 && (device->lun == lun)) {
+#else
+					if ((device->channel ==
+						CONTAINER_TO_CHANNEL(container))
+					 && (device->id ==
+						CONTAINER_TO_ID(container))
+					 && (device->lun ==
+						CONTAINER_TO_LUN(container))) {
+#endif
+						dev->fsa_dev[container].config_needed = CHANGE;
+						dev->fsa_dev[container].config_waiting_on = AifEnConfigChange;
+						dev->fsa_dev[container].config_waiting_stamp = jiffies;
+						break;
+					}
+#endif
 			}
 		}
 
@@ -1022,30 +1658,42 @@ static void aac_handle_aif(struct aac_dev * dev, struct fib * fibptr)
 			device_config_needed =
 			  (((__le32 *)aifcmd->data)[0] ==
 			    cpu_to_le32(AifEnAddJBOD)) ? ADD : DELETE;
+
+			/*	ADPml11423: JBOD created in Redhat 5.3 OS are not available until System Reboot
+			 *  After JBOD creation, Dynamic updation of scsi_device table was not handled earlier
+			 *  Below code is to reinitialize scsi device, After creation of JBOD
+			 *  Device structure is freshly initialized and discovered the same, 'fdisk -l' lists JBOD
+			 */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,3)) 
 			if (device_config_needed == ADD) {
-				device = scsi_device_lookup(dev->scsi_host_ptr,
-					channel,
-					id,
-					lun);
+				device = scsi_device_lookup(dev->scsi_host_ptr, channel, id, lun);
 				if (device) {
 					scsi_remove_device(device);
 					scsi_device_put(device);
 				}
 			}
+#endif	
 			break;
 
 		case AifEnEnclosureManagement:
-			/*
-			 * If in JBOD mode, automatic exposure of new
-			 * physical target to be suppressed until configured.
-			 */
-			if (dev->jbod)
-				break;
+
 			switch (le32_to_cpu(((__le32 *)aifcmd->data)[3])) {
 			case EM_DRIVE_INSERTION:
 			case EM_DRIVE_REMOVAL:
+			case EM_SES_DRIVE_INSERTION:
+			case EM_SES_DRIVE_REMOVAL:
 				container = le32_to_cpu(
 					((__le32 *)aifcmd->data)[2]);
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+				printk (KERN_INFO "dev_t=%x(%d,%d,%d,%d)\n",
+				  container,
+				  (dev && dev->scsi_host_ptr)
+				    ? dev->scsi_host_ptr->host_no
+				    : -1,
+				  aac_phys_to_logical((container >> 24) & 0xF),
+				  container & 0xFFF,
+				  (container >> 16) & 0xFF);
+#endif
 				if ((container >> 28)) {
 					container = (u32)-1;
 					break;
@@ -1069,9 +1717,11 @@ static void aac_handle_aif(struct aac_dev * dev, struct fib * fibptr)
 				}
 				channel = aac_phys_to_logical(channel);
 				device_config_needed =
-				  (((__le32 *)aifcmd->data)[3]
-				    == cpu_to_le32(EM_DRIVE_INSERTION)) ?
-				  ADD : DELETE;
+				  ((((__le32 *)aifcmd->data)[3]
+				    == cpu_to_le32(EM_DRIVE_INSERTION)) ||
+				    (((__le32 *)aifcmd->data)[3]
+				    == cpu_to_le32(EM_SES_DRIVE_INSERTION))) ?
+				    ADD : DELETE;
 				break;
 			}
 			break;
@@ -1105,10 +1755,22 @@ static void aac_handle_aif(struct aac_dev * dev, struct fib * fibptr)
 		 * change so we monitor the job status complete on a clear then
 		 * wait for a container change.
 		 */
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+		printk (KERN_INFO
+		  "aac_handle_aif: Aif command=AifCmdJobProgress job=%x [4]=%x [5]=%x [6]=%x\n",
+		  le32_to_cpu(((__le32 *)aifcmd->data)[1]),
+		  le32_to_cpu(((__le32 *)aifcmd->data)[4]),
+		  le32_to_cpu(((__le32 *)aifcmd->data)[5]),
+		  le32_to_cpu(((__le32 *)aifcmd->data)[6]));
+#endif
 
 		if (((__le32 *)aifcmd->data)[1] == cpu_to_le32(AifJobCtrZero) &&
 		    (((__le32 *)aifcmd->data)[6] == ((__le32 *)aifcmd->data)[5] ||
-		     ((__le32 *)aifcmd->data)[4] == cpu_to_le32(AifJobStsSuccess))) {
+		     ((__le32 *)aifcmd->data)[4] == cpu_to_le32(AifJobStsSuccess) || 
+		     ((__le32 *)aifcmd->data)[4] == cpu_to_le32(AifJobStsAborted) || 
+		     ((__le32 *)aifcmd->data)[4] == cpu_to_le32(AifJobStsFailed) || 
+		     ((__le32 *)aifcmd->data)[4] == cpu_to_le32(AifJobStsPreempted) || 
+		     ((__le32 *)aifcmd->data)[4] == cpu_to_le32(AifJobStsPended) )) {
 			for (container = 0;
 			    container < dev->maximum_num_containers;
 			    ++container) {
@@ -1122,6 +1784,10 @@ static void aac_handle_aif(struct aac_dev * dev, struct fib * fibptr)
 				dev->fsa_dev[container].config_waiting_stamp =
 					jiffies;
 			}
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+			printk (KERN_INFO
+			  "aac_handle_aif: Wait=AifEnContainerChange ADD\n");
+#endif
 		}
 		if (((__le32 *)aifcmd->data)[1] == cpu_to_le32(AifJobCtrZero) &&
 		    ((__le32 *)aifcmd->data)[6] == 0 &&
@@ -1139,14 +1805,35 @@ static void aac_handle_aif(struct aac_dev * dev, struct fib * fibptr)
 				dev->fsa_dev[container].config_waiting_stamp =
 					jiffies;
 			}
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+			printk (KERN_INFO
+			  "aac_handle_aif: Wait=AifEnContainerChange DELETE\n");
+#endif
 		}
 		break;
 	}
 
+//#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,3)) && defined(MODULE))) && !defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX__)
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,3)) && defined(MODULE)))
+	container = 0;
+//#if (!defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX__))
+retry_next_on_busy:
+//#endif
+	if (device_config_needed == NOTHING)
+	for (; container < dev->maximum_num_containers; ++container) {
+#else
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,3))
+	if (device_config_needed == NOTHING)
+	for (container = 0; container < dev->maximum_num_containers;
+	    ++container) {
+#else
 	container = 0;
 retry_next:
 	if (device_config_needed == NOTHING)
 	for (; container < dev->maximum_num_containers; ++container) {
+#endif
+#endif
+	
 		if ((dev->fsa_dev[container].config_waiting_on == 0) &&
 			(dev->fsa_dev[container].config_needed != NOTHING) &&
 			time_before(jiffies, dev->fsa_dev[container].config_waiting_stamp + AIF_SNIFF_TIMEOUT)) {
@@ -1167,6 +1854,16 @@ retry_next:
 	 * schedule it here on the way out the door, please close the door
 	 * behind you.
 	 */
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,3))
+
+	busy = 0;
+
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+	printk (KERN_INFO "id=(%d,%d,%d,%d)\n", (dev && dev->scsi_host_ptr) ?
+	  dev->scsi_host_ptr->host_no : -1,
+	  channel, id, lun);
+#endif
 
 	/*
 	 *	Find the scsi_device associated with the SCSI address,
@@ -1185,22 +1882,42 @@ retry_next:
 			dev->fsa_dev[container].valid = 2;
 		aac_probe_container(dev, container);
 	}
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,3))
 	device = scsi_device_lookup(dev->scsi_host_ptr, channel, id, lun);
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+	printk(KERN_INFO "scsi_device_lookup(%p,%d,%d,%d)=%p %s %s\n",
+	  dev->scsi_host_ptr, channel, id, lun, device,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,3))
+	  ((busy) ? "BUSY" : "AVAILABLE"),
+#else
+	  "",
+#endif
+	  (device_config_needed == NOTHING)
+	   ? "NOTHING"
+	   : (device_config_needed == DELETE)
+	     ? "DELETE"
+	     : (device_config_needed == ADD)
+	       ? "ADD"
+	       : (device_config_needed == CHANGE)
+		 ? "CHANGE"
+		 : "UNKNOWN");
+#endif
 	if (device) {
 		switch (device_config_needed) {
 		case DELETE:
-#if (defined(AAC_DEBUG_INSTRUMENT_AIF_DELETE))
-			scsi_remove_device(device);
-#else
-			if (scsi_device_online(device)) {
-				scsi_device_set_state(device, SDEV_OFFLINE);
-				sdev_printk(KERN_INFO, device,
-					"Device offlined - %s\n",
-					(channel == CONTAINER_CHANNEL) ?
-						"array deleted" :
-						"enclosure services event");
+			if (aac_remove_devnodes > 0) {
+				/* Bug in sysfs removing then adding devices quickly */
+				scsi_remove_device(device);
+			} else {
+				if (scsi_device_online(device)) {
+					scsi_device_set_state(device, SDEV_OFFLINE);
+					sdev_printk(KERN_INFO, device,
+						"Device offlined - %s\n",
+						(channel == CONTAINER_CHANNEL) ?
+							"array deleted" :
+							"enclosure services event");
+				}
 			}
-#endif
 			break;
 		case ADD:
 			if (!scsi_device_online(device)) {
@@ -1215,19 +1932,32 @@ retry_next:
 		case CHANGE:
 			if ((channel == CONTAINER_CHANNEL)
 			 && (!dev->fsa_dev[container].valid)) {
-#if (defined(AAC_DEBUG_INSTRUMENT_AIF_DELETE))
-				scsi_remove_device(device);
-#else
-				if (!scsi_device_online(device))
-					break;
-				scsi_device_set_state(device, SDEV_OFFLINE);
-				sdev_printk(KERN_INFO, device,
-					"Device offlined - %s\n",
-					"array failed");
-#endif
+				if (aac_remove_devnodes > 0)
+					scsi_remove_device(device);
+				else {
+					if (!scsi_device_online(device))
+						break;
+					scsi_device_set_state(device, SDEV_OFFLINE);
+					sdev_printk(KERN_INFO, device,
+						"Device offlined - %s\n",
+						"array failed");
+				}
 				break;
 			}
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,10)) || !defined(MODULE))
 			scsi_rescan_device(&device->sdev_gendev);
+#else
+			if (!device->sdev_gendev.driver)
+				break;
+			drv = to_scsi_driver(
+				device->sdev_gendev.driver);
+			if (!try_module_get(drv->owner))
+				break;
+			/* scsi_rescan_device code fragment */
+			if(drv->rescan)
+				drv->rescan(&device->sdev_gendev);
+			module_put(drv->owner);
+#endif
 
 		default:
 			break;
@@ -1235,13 +1965,296 @@ retry_next:
 		scsi_device_put(device);
 		device_config_needed = NOTHING;
 	}
+#else
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0))
+	shost_for_each_device(device, dev->scsi_host_ptr)
+#elif (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+	list_for_each_entry(device, &dev->scsi_host_ptr->my_devices, siblings)
+#else
+	for (device = dev->scsi_host_ptr->host_queue;
+	  device != (struct scsi_device *)NULL;
+	  device = device->next)
+#endif
+	{
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+		printk(KERN_INFO "aifd: device (%d,%d,%d,%d)?\n",
+		  dev->scsi_host_ptr->host_no, device->channel, device->id,
+		  device->lun);
+#endif
+		if ((device->channel == channel)
+		 && (device->id == id)
+		 && (device->lun == lun)) {
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0))
+			busy |= atomic_read(&device->access_count) ||
+				test_bit(SHOST_RECOVERY,
+				(const unsigned long*)&dev->scsi_host_ptr->shost_state) ||
+				dev->scsi_host_ptr->eh_active;
+#elif (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0))
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,14)) || defined(SCSI_HAS_SHOST_STATE_ENUM))
+			busy |= device->device_busy ||
+				(SHOST_RECOVERY == device->host->shost_state);
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,14))
+			busy |= device->device_busy ||
+				test_bit(SHOST_RECOVERY,
+				(const unsigned long*)&dev->scsi_host_ptr->shost_state);
+#else
+			busy |= device->device_busy ||
+				test_bit(SHOST_RECOVERY,
+				(const unsigned long*)&dev->scsi_host_ptr->shost_state) ||
+				dev->scsi_host_ptr->eh_active;
+#endif
+#else
+			busy |= device->access_count ||
+				dev->scsi_host_ptr->in_recovery ||
+				dev->scsi_host_ptr->eh_active;
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+			printk(KERN_INFO " %s %s\n",
+			  ((busy) ? "BUSY" : "AVAILABLE"),
+			  (device_config_needed == NOTHING)
+			   ? "NOTHING"
+			   : (device_config_needed == DELETE)
+			     ? "DELETE"
+			     : (device_config_needed == ADD)
+			       ? "ADD"
+			       : (device_config_needed == CHANGE)
+				 ? "CHANGE"
+				 : "UNKNOWN");
+#endif
+			if (busy == 0) {
+				device->removable = 1;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+				switch (device_config_needed) {
+#if 0
+				case ADD:
+					/*
+					 *	No need to call
+					 * scsi_scan_single_target
+					 */
+					device_config_needed = CHANGE;
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,3)) || !defined(MODULE))
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+					printk(KERN_INFO
+					  "scsi_add_device(%p{%d}, %d, %d, %d)\n",
+					  dev->scsi_host_ptr,
+					  dev->scsi_host_ptr->host_no,
+					  device->channel, device->id,
+					  device->lun);
+#endif
+					scsi_add_device(dev->scsi_host_ptr,
+					  device->channel, device->id,
+					  device->lun);
+					break;
+#endif
+#endif
+				case DELETE:
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,3)) || !defined(MODULE))
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+					printk(KERN_INFO
+					  "scsi_remove_device(%p{%d:%d:%d:%d})\n",
+					  device, device->host->host_no,
+					  device->channel, device->id,
+					  device->lun);
+#endif
+					scsi_remove_device(device);
+					break;
+#endif
+				case CHANGE:
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,3)) || !defined(MODULE))
+					if ((channel == CONTAINER_CHANNEL) &&
+					  !dev->fsa_dev[container].valid) {
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+						printk(KERN_INFO
+						  "scsi_remove_device(%p{%d:%d:%d:%d})\n",
+						  device,
+						  device->host->host_no,
+						  device->channel, device->id,
+						  device->lun);
+#endif
+						scsi_remove_device(device);
+						break;
+					}
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,10)) || !defined(MODULE))
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+					printk(KERN_INFO
+					  "scsi_rescan_device(&%p{%d:%d:%d:%d}->sdev_gendev)\n",
+					  device, device->host->host_no,
+					  device->channel, device->id,
+					  device->lun);
+#endif
+					scsi_rescan_device(&device->sdev_gendev);
+#else
+					if (!device->sdev_gendev.driver)
+						break;
+					drv = to_scsi_driver(
+						device->sdev_gendev.driver);
+					if (!try_module_get(drv->owner))
+						break;
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+					printk(KERN_INFO
+					  "drv->rescan{%p}(&%p{%d:%d:%d:%d}->sdev_gendev)\n",
+					  drv->rescan, device,
+					  device->host->host_no,
+					  device->channel, device->id,
+					  device->lun);
+#endif
+					/* scsi_rescan_device code fragment */
+					if(drv->rescan)
+						drv->rescan(&device->sdev_gendev);
+					module_put(drv->owner);
+#endif
+
+				default:
+					break;
+				}
+#endif
+			}
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0))
+			scsi_device_put(device);
+#endif
+			break;
+		}
+	}
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,3)) || !defined(MODULE))
 	if (device_config_needed == ADD)
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+	{
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,3)) || !defined(MODULE))
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+		printk(KERN_INFO
+		  "scsi_add_device(%p{%d}, %d, %d, %d)\n",
+		  dev->scsi_host_ptr, dev->scsi_host_ptr->host_no,
+		  channel, id, lun);
+#endif
 		scsi_add_device(dev->scsi_host_ptr, channel, id, lun);
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,10))
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+		printk(KERN_INFO
+		  "scsi_scan_single_target(%p{%d}, %d, %d)\n",
+		  dev->scsi_host_ptr, dev->scsi_host_ptr->host_no,
+		  channel, id);
+#endif
+		scsi_scan_single_target(dev->scsi_host_ptr, channel, id);
+#elif (!defined(MODULE))
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+		printk(KERN_INFO
+		  "scsi_scan_host_selected(%p{%d}, %d, %d, %d, 0)\n",
+		  dev->scsi_host_ptr, dev->scsi_host_ptr->host_no,
+		  channel, id, lun);
+#endif
+		scsi_scan_host_selected(dev->scsi_host_ptr, channel, id, lun, 0);
+#else
+		;
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+	}
+#endif
+#endif
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,3))
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+	printk (KERN_INFO "busy=%d\n", busy);
+#endif
+
+#endif
+//#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,3)) && defined(MODULE))) && !defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX__)
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,3)) && defined(MODULE)))
+	/*
+	 * if (busy == 0) {
+	 *	scan_scsis(dev->scsi_host_ptr, 1,
+	 *	  CONTAINER_TO_CHANNEL(container),
+	 *	  CONTAINER_TO_ID(container),
+	 *	  CONTAINER_TO_LUN(container));
+	 * }
+	 * is not exported as accessible, so we need to go around it
+	 * another way. So, we look for the "proc/scsi/scsi" entry in
+	 * the proc filesystem (using proc_scsi as a shortcut) and send
+	 * it a message. This deals with new devices that have
+	 * appeared. If the device has gone offline, scan_scsis will
+	 * also discover this, but we do not want the device to
+	 * go away. We need to check the access_count for the
+	 * device since we are not wanting the devices to go away.
+	 */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+	if (device_config_needed != NOTHING)
+#endif
+	if ((channel == CONTAINER_CHANNEL) && busy) {
+		dev->fsa_dev[container].config_waiting_on = 0;
+		dev->fsa_dev[container].config_needed = device_config_needed;
+		/*
+		 * Jump back and check if any other containers are ready for
+		 * processing.
+		 */
+		container++;
+		device_config_needed = NOTHING;
+		goto retry_next_on_busy;
+	}
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+	if (device_config_needed != NOTHING)
+#endif
+	if (proc_scsi != (struct proc_dir_entry *)NULL) {
+		struct proc_dir_entry * entry;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+		printk(KERN_INFO "proc_scsi=%p ", proc_scsi);
+#endif
+		for (entry = proc_scsi->subdir;
+		  entry != (struct proc_dir_entry *)NULL;
+		  entry = entry->next) {
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+			printk("\"%.*s\"[%d]=%x ", entry->namelen,
+			  entry->name, entry->namelen, entry->low_ino);
+#endif
+			if ((entry->low_ino != 0)
+			 && (entry->namelen == 4)
+			 && (memcmp ("scsi", entry->name, 4) == 0)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+				printk("%p->write_proc=%p ", entry, entry->write_proc);
+#endif
+				if (entry->write_proc != (int (*)(struct file *, const char *, unsigned long, void *))NULL) {
+					char buffer[80];
+					int length;
+					mm_segment_t fs;
+
+					sprintf (buffer,
+					  "scsi %s-single-device %d %d %d %d\n",
+					  ((device_config_needed == DELETE)
+					   ? "remove"
+					   : "add"),
+					  dev->scsi_host_ptr->host_no,
+					  channel, id, lun);
+					length = strlen (buffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+					printk(KERN_INFO
+					  "echo %.*s > /proc/scsi/scsi\n",
+					  length-1, buffer);
+#endif
+					fs = get_fs();
+					set_fs(get_ds());
+					lock_kernel();
+					length = entry->write_proc(
+					  NULL, buffer, length, NULL);
+					unlock_kernel();
+					set_fs(fs);
+#if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+					printk(KERN_INFO "returns %d\n",
+					  length);
+#endif
+				}
+				break;
+			}
+		}
+	}
+#endif /* (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,3))
 	if (channel == CONTAINER_CHANNEL) {
 		container++;
 		device_config_needed = NOTHING;
 		goto retry_next;
 	}
+#endif
 }
 
 static int _aac_reset_adapter(struct aac_dev *aac, int forced)
@@ -1267,21 +2280,39 @@ static int _aac_reset_adapter(struct aac_dev *aac, int forced)
 	host = aac->scsi_host_ptr;
 	scsi_block_requests(host);
 	aac_adapter_disable_int(aac);
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+	if (aac->thread_pid != current->pid) {
+		kill_proc(aac->thread_pid, SIGKILL, 0);
+		/* Chance of sleeping in this context, must unlock */
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+		spin_unlock_irq(host->host_lock);
+#else
+		spin_unlock_irq(host->lock);
+#endif
+#else
+		spin_unlock_irq(&io_request_lock);
+#endif
+		wait_for_completion(&aac->aif_completion);
+		jafo = 1;
+	}
+#else
 	if (aac->thread->pid != current->pid) {
 		spin_unlock_irq(host->host_lock);
 		kthread_stop(aac->thread);
 		jafo = 1;
 	}
+#endif
 
 	/*
 	 *	If a positive health, means in a known DEAD PANIC
 	 * state and the adapter could be reset to `try again'.
 	 */
 	retval = aac_adapter_restart(aac, forced ? 0 : aac_adapter_check_health(aac));
-
+	
 	if (retval)
 		goto out;
-
+	
 	/*
 	 *	Loop through the fibs, close the synchronous FIBS
 	 */
@@ -1290,11 +2321,17 @@ static int _aac_reset_adapter(struct aac_dev *aac, int forced)
 		if (!(fib->hw_fib_va->header.XferState & cpu_to_le32(NoResponseExpected | Async)) &&
 		  (fib->hw_fib_va->header.XferState & cpu_to_le32(ResponseExpected))) {
 			unsigned long flagv;
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+			printk(KERN_INFO "returning FIB %p undone\n", fib);
+#endif
 			spin_lock_irqsave(&fib->event_lock, flagv);
 			up(&fib->event_wait);
 			spin_unlock_irqrestore(&fib->event_lock, flagv);
 			schedule();
 			retval = 0;
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+			printk(KERN_INFO "returned FIB %p undone\n", fib);
+#endif
 		}
 	}
 	/* Give some extra time for ioctls to complete. */
@@ -1315,33 +2352,58 @@ static int _aac_reset_adapter(struct aac_dev *aac, int forced)
 	aac->comm_phys = 0;
 	kfree(aac->queues);
 	aac->queues = NULL;
-	free_irq(aac->pdev->irq, aac);
-	if (aac->msi)
-		pci_disable_msi(aac->pdev);
+	aac_free_irq(aac);
 	kfree(aac->fsa_dev);
 	aac->fsa_dev = NULL;
 	quirks = aac_get_driver_ident(index)->quirks;
 	if (quirks & AAC_QUIRK_31BIT) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0))
+		if (((retval = pci_set_dma_mask(aac->pdev, DMA_31BIT_MASK))) ||
+		  ((retval = pci_set_consistent_dma_mask(aac->pdev, DMA_31BIT_MASK))))
+#else
 		if (((retval = pci_set_dma_mask(aac->pdev, DMA_BIT_MASK(31)))) ||
 		  ((retval = pci_set_consistent_dma_mask(aac->pdev, DMA_BIT_MASK(31)))))
+#endif
 			goto out;
 	} else {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0))
+		if (((retval = pci_set_dma_mask(aac->pdev, DMA_32BIT_MASK))) ||
+		  ((retval = pci_set_consistent_dma_mask(aac->pdev, DMA_32BIT_MASK))))
+#else
 		if (((retval = pci_set_dma_mask(aac->pdev, DMA_BIT_MASK(32)))) ||
 		  ((retval = pci_set_consistent_dma_mask(aac->pdev, DMA_BIT_MASK(32)))))
+#endif
 			goto out;
 	}
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+	printk(KERN_INFO "Calling adapter init\n");
+#endif
 	if ((retval = (*(aac_get_driver_ident(index)->init))(aac)))
 		goto out;
 	if (quirks & AAC_QUIRK_31BIT)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0))
+		if ((retval = pci_set_dma_mask(aac->pdev, DMA_32BIT_MASK)))
+#else
 		if ((retval = pci_set_dma_mask(aac->pdev, DMA_BIT_MASK(32))))
+#endif
 			goto out;
 	if (jafo) {
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+		aac->thread_pid = retval = kernel_thread(
+		  (int (*)(void *))aac_command_thread, aac, 0);
+		if (retval < 0)
+			goto out;
+#else
 		aac->thread = kthread_run(aac_command_thread, aac, aac->name);
 		if (IS_ERR(aac->thread)) {
 			retval = PTR_ERR(aac->thread);
 			goto out;
 		}
+#endif
 	}
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+	printk(KERN_INFO "Acquiring adapter information\n");
+#endif
 	(void)aac_get_adapter_info(aac);
 	if ((quirks & AAC_QUIRK_34SG) && (host->sg_tablesize > 34)) {
 		host->sg_tablesize = 34;
@@ -1351,13 +2413,23 @@ static int _aac_reset_adapter(struct aac_dev *aac, int forced)
 		host->sg_tablesize = 17;
 		host->max_sectors = (host->sg_tablesize * 8) + 112;
 	}
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+	printk(KERN_INFO "Determine the configuration status\n");
+#endif
 	aac_get_config_status(aac, 1);
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+	printk(KERN_INFO "Probing all arrays to confirm status\n");
+#endif
 	aac_get_containers(aac);
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+	printk(KERN_INFO "Completing all outstanding driver commands as BUSY\n");
+#endif
 	/*
 	 * This is where the assumption that the Adapter is quiesced
 	 * is important.
 	 */
 	command_list = NULL;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 	__shost_for_each_device(dev, host) {
 		unsigned long flags;
 		spin_lock_irqsave(&dev->list_lock, flags);
@@ -1368,7 +2440,21 @@ static int _aac_reset_adapter(struct aac_dev *aac, int forced)
 			}
 		spin_unlock_irqrestore(&dev->list_lock, flags);
 	}
+#else
+#ifndef SAM_STAT_TASK_SET_FULL
+# define SAM_STAT_TASK_SET_FULL (QUEUE_FULL << 1)
+#endif
+	for (dev = host->host_queue; dev != (struct scsi_device *)NULL; dev = dev->next)
+		for(command = dev->device_queue; command; command = command->next)
+			if (command->SCp.phase == AAC_OWNER_FIRMWARE) {
+				command->SCp.buffer = (struct scatterlist *)command_list;
+				command_list = command;
+			}
+#endif
 	while ((command = command_list)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+		printk(KERN_INFO "returning %p for retry\n", command);
+#endif
 		command_list = (struct scsi_cmnd *)command->SCp.buffer;
 		command->SCp.buffer = NULL;
 		command->result = DID_OK << 16
@@ -1377,13 +2463,24 @@ static int _aac_reset_adapter(struct aac_dev *aac, int forced)
 		command->SCp.phase = AAC_OWNER_ERROR_HANDLER;
 		command->scsi_done(command);
 	}
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+	printk(KERN_INFO "Continue where we left off\n");
+#endif
 	retval = 0;
 
 out:
 	aac->in_reset = 0;
 	scsi_unblock_requests(host);
 	if (jafo) {
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
 		spin_lock_irq(host->host_lock);
+#else
+		spin_lock_irq(host->lock);
+#endif
+#else
+		spin_lock_irq(&io_request_lock);
+#endif
 	}
 	return retval;
 }
@@ -1416,6 +2513,7 @@ int aac_reset_adapter(struct aac_dev * aac, int forced)
 		struct scsi_cmnd * command;
 		int active = 0;
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 		__shost_for_each_device(dev, host) {
 			spin_lock_irqsave(&dev->list_lock, flagv);
 			list_for_each_entry(command, &dev->cmd_list, list) {
@@ -1429,6 +2527,16 @@ int aac_reset_adapter(struct aac_dev * aac, int forced)
 				break;
 
 		}
+#else
+		for (dev = host->host_queue; dev != (struct scsi_device *)NULL; dev = dev->next) {
+			for(command = dev->device_queue; command; command = command->next) {
+				if (command->SCp.phase == AAC_OWNER_FIRMWARE) {
+					++active;
+					break;
+				}
+			}
+		}
+#endif
 		/*
 		 * We can exit If all the commands are complete
 		 */
@@ -1440,9 +2548,25 @@ int aac_reset_adapter(struct aac_dev * aac, int forced)
 	/* Quiesce build, flush cache, write through mode */
 	if (forced < 2)
 		aac_send_shutdown(aac);
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
 	spin_lock_irqsave(host->host_lock, flagv);
+#else
+	spin_lock_irqsave(host->lock, flagv);
+#endif
+#else
+	spin_lock_irqsave(&io_request_lock, flagv);
+#endif
 	retval = _aac_reset_adapter(aac, forced ? forced : ((aac_check_reset != 0) && (aac_check_reset != 1)));
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
 	spin_unlock_irqrestore(host->host_lock, flagv);
+#else
+	spin_unlock_irqrestore(host->lock, flagv);
+#endif
+#else
+	spin_unlock_irqrestore(&io_request_lock, flagv);
+#endif
 
 	if ((forced < 2) && (retval == -ENODEV)) {
 		/* Unwind aac_send_shutdown() IOP_RESET unsupported/disabled */
@@ -1484,9 +2608,15 @@ int aac_reset_adapter(struct aac_dev * aac, int forced)
 int aac_check_health(struct aac_dev * aac)
 {
 	int BlinkLED;
+#if (!defined(HAS_BOOT_CONFIG))
 	unsigned long time_now, flagv = 0;
 	struct list_head * entry;
+#else
+	unsigned long flagv = 0;
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,13))
 	struct Scsi_Host * host;
+#endif
 
 	/* Extending the scope of fib_lock slightly to protect aac->in_reset */
 	if (spin_trylock_irqsave(&aac->fib_lock, flagv) == 0)
@@ -1499,6 +2629,7 @@ int aac_check_health(struct aac_dev * aac)
 
 	aac->in_reset = 1;
 
+#if (!defined(HAS_BOOT_CONFIG))
 	/* Fake up an AIF:
 	 *	aac_aifcmd.command = AifCmdEventNotify = 1
 	 *	aac_aifcmd.seqnum = 0xFFFFFFFF
@@ -1550,11 +2681,20 @@ int aac_check_health(struct aac_dev * aac)
 		 * Warning: no sleep allowed while
 		 * holding spinlock
 		 */
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)) && !defined(HAS_KZALLOC))
+		hw_fib = kmalloc(sizeof(struct hw_fib), GFP_ATOMIC);
+		fib = kmalloc(sizeof(struct fib), GFP_ATOMIC);
+#else
 		hw_fib = kzalloc(sizeof(struct hw_fib), GFP_ATOMIC);
 		fib = kzalloc(sizeof(struct fib), GFP_ATOMIC);
+#endif
 		if (fib && hw_fib) {
 			struct aac_aifcmd * aif;
 
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)) && !defined(HAS_KZALLOC))
+			memset(hw_fib, 0, sizeof(struct hw_fib));
+			memset(fib, 0, sizeof(struct fib));
+#endif
 			fib->hw_fib_va = hw_fib;
 			fib->dev = aac;
 			aac_fib_init(fib);
@@ -1587,6 +2727,7 @@ int aac_check_health(struct aac_dev * aac)
 		}
 		entry = entry->next;
 	}
+#endif
 
 	spin_unlock_irqrestore(&aac->fib_lock, flagv);
 
@@ -1601,6 +2742,7 @@ int aac_check_health(struct aac_dev * aac)
 		(aac->supplement_adapter_info.SupportedOptions2 &
 			AAC_OPTION_IGNORE_RESET)))
 		goto out;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,13))
 	host = aac->scsi_host_ptr;
 	if (aac->thread->pid != current->pid)
 		spin_lock_irqsave(host->host_lock, flagv);
@@ -1608,6 +2750,9 @@ int aac_check_health(struct aac_dev * aac)
 	if (aac->thread->pid != current->pid)
 		spin_unlock_irqrestore(host->host_lock, flagv);
 	return BlinkLED;
+#else
+	return _aac_reset_adapter(aac, aac_check_reset != 1);
+#endif
 
 out:
 	aac->in_reset = 0;
@@ -1625,32 +2770,80 @@ out:
  *	more FIBs.
  */
 
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+int aac_command_thread(struct aac_dev * dev)
+#else
 int aac_command_thread(void *data)
+#endif
 {
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,5)) || defined(HAS_KTHREAD))
 	struct aac_dev *dev = data;
+#endif
+#if (!defined(HAS_BOOT_CONFIG))
 	struct hw_fib *hw_fib, *hw_newfib;
 	struct fib *fib, *newfib;
 	struct aac_fib_context *fibctx;
+#else
+	struct hw_fib *hw_fib;
+	struct fib *fib;
+#endif
 	unsigned long flags;
+#if ((!defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__)) || defined(__VMKLNX__))
 	DECLARE_WAITQUEUE(wait, current);
+#endif
 	unsigned long next_jiffies = jiffies + HZ;
 	unsigned long next_check_jiffies = next_jiffies;
 	long difference = HZ;
 
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	if (dev->comm_interface == AAC_COMM_APRE)
+		return 0;
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+	printk(KERN_ERR "update_interval=%d:%02d check_interval=%ds\n",
+	  update_interval / 60, update_interval % 60, check_interval);
+#endif
 	/*
 	 *	We can only have one thread per adapter for AIF's.
 	 */
 	if (dev->aif_thread)
 		return -EINVAL;
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+#if (!defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__) && !defined(__VMKLNX__))
+	/*
+	 *	Set up the name that will appear in 'ps'
+	 *	stored in  task_struct.comm[16].
+	 */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+	daemonize(dev->name);
+	allow_signal(SIGKILL);
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+	snprintf(current->comm, sizeof(current->comm), dev->name);
+	daemonize();
+#else
+	sprintf(current->comm, dev->name);
+	daemonize();
+#endif
+#endif
+#else
 
+#endif
 	/*
 	 *	Let the DPC know it has a place to send the AIF's to.
 	 */
 	dev->aif_thread = 1;
+#if ((!defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__)) || defined(__VMKLNX__))
 	add_wait_queue(&dev->queues->queue[HostNormCmdQueue].cmdready, &wait);
+#endif
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+	// warning: value computed is not used
+#endif
 	set_current_state(TASK_INTERRUPTIBLE);
 	dprintk ((KERN_INFO "aac_command_thread start\n"));
 	while (1) {
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+		fwprintf((NULL, HBA_FLAGS_DBG_FW_PRINT_B, ""));
+#endif
 		spin_lock_irqsave(dev->queues->queue[HostNormCmdQueue].lock, flags);
 		while(!list_empty(&(dev->queues->queue[HostNormCmdQueue].cmdq))) {
 			struct list_head *entry;
@@ -1686,6 +2879,8 @@ int aac_command_thread(void *data)
 				*(__le32 *)hw_fib->data = cpu_to_le32(ST_OK);
 				aac_fib_adapter_complete(fib, (u16)sizeof(u32));
 			} else {
+#if (!defined(HAS_BOOT_CONFIG))
+//				struct list_head *entry;
 				/* The u32 here is important and intended. We are using
 				   32bit wrapping time to fit the adapter field */
 
@@ -1694,6 +2889,7 @@ int aac_command_thread(void *data)
 				unsigned num;
 				struct hw_fib ** hw_fib_pool, ** hw_fib_p;
 				struct fib ** fib_pool, ** fib_p;
+#endif
 
 				/* Sniff events */
 				if ((aifcmd->command ==
@@ -1703,6 +2899,7 @@ int aac_command_thread(void *data)
 					aac_handle_aif(dev, fib);
 				}
 
+#if (!defined(HAS_BOOT_CONFIG))
 				time_now = jiffies/HZ;
 
 				/*
@@ -1816,11 +3013,13 @@ int aac_command_thread(void *data)
 					}
 					entry = entry->next;
 				}
+#endif
 				/*
 				 *	Set the status of this FIB
 				 */
 				*(__le32 *)hw_fib->data = cpu_to_le32(ST_OK);
 				aac_fib_adapter_complete(fib, sizeof(u32));
+#if (!defined(HAS_BOOT_CONFIG))
 				spin_unlock_irqrestore(&dev->fib_lock, flagv);
 				/* Free up the remaining resources */
 				hw_fib_p = hw_fib_pool;
@@ -1833,6 +3032,7 @@ int aac_command_thread(void *data)
 				}
 				kfree(hw_fib_pool);
 				kfree(fib_pool);
+#endif
 			}
 			kfree(fib);
 			spin_lock_irqsave(dev->queues->queue[HostNormCmdQueue].lock, flags);
@@ -1842,6 +3042,9 @@ int aac_command_thread(void *data)
 		 */
 		spin_unlock_irqrestore(dev->queues->queue[HostNormCmdQueue].lock, flags);
 
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+		fwprintf((NULL, HBA_FLAGS_DBG_FW_PRINT_B, ""));
+#endif
 		/*
 		 *	Background activity
 		 */
@@ -1851,6 +3054,9 @@ int aac_command_thread(void *data)
 			if (aac_check_health(dev) == 0) {
 				difference = ((long)(unsigned)check_interval)
 					   * HZ;
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+				fwprintf((NULL, HBA_FLAGS_DBG_FW_PRINT_B, ""));
+#endif
 				next_check_jiffies = jiffies + difference;
 			} else if (!dev->queues)
 				break;
@@ -1864,6 +3070,9 @@ int aac_command_thread(void *data)
 			ret = aac_check_health(dev);
 			if (!ret && !dev->queues)
 				break;
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+			fwprintf((NULL, HBA_FLAGS_DBG_FW_PRINT_B, ""));
+#endif
 			next_check_jiffies = jiffies
 					   + ((long)(unsigned)check_interval)
 					   * HZ;
@@ -1896,10 +3105,12 @@ int aac_command_thread(void *data)
 						1, 1,
 						NULL,
 						NULL);
+
 					/* Do not set XferState to zero unless
 					 * receives a response from F/W */
 					if (status >= 0)
 						aac_fib_complete(fibptr);
+
 					/* FIB should be freed only after
 					 * getting the response from the F/W */
 					if (status != -ERESTARTSYS)
@@ -1916,14 +3127,126 @@ int aac_command_thread(void *data)
 		}
 		if (difference <= 0)
 			difference = 1;
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+		if (nblank(fwprintf(x)) && (difference > HZ))
+			difference = HZ;
+#endif
 		set_current_state(TASK_INTERRUPTIBLE);
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__VMKLNX__))
+		if (dev->thread_die)
+			break;
+
+		down(&dev->queues->queue[HostNormCmdQueue].cmdready);
+#else
 		schedule_timeout(difference);
 
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+		if(signal_pending(current))
+#else
 		if (kthread_should_stop())
+#endif
 			break;
+#endif
 	}
+#if ((!defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__)) || defined(__VMKLNX__))
 	if (dev->queues)
 		remove_wait_queue(&dev->queues->queue[HostNormCmdQueue].cmdready, &wait);
+#endif
 	dev->aif_thread = 0;
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+	complete_and_exit(&dev->aif_completion, 0);
+#endif
 	return 0;
 }
+
+int aac_acquire_irq(struct aac_dev *dev)
+{
+	
+	int i;
+	int j;
+	int ret = 0;
+#if ((defined(RHEL_MAJOR) && RHEL_MAJOR == 6 && RHEL_MINOR >= 2)\
+	  || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,35)))
+	int cpu;
+	cpu = cpumask_first(cpu_online_mask);
+#endif
+	if (!dev->sync_mode && dev->msi_enabled && dev->max_msix > 1) {
+		for (i = 0; i < dev->max_msix; i++) {
+			dev->aac_msix[i].vector_no = i;
+			dev->aac_msix[i].dev = dev;
+			if (request_irq(dev->msixentry[i].vector, dev->a_ops.adapter_intr,
+					0,"aacraid", &(dev->aac_msix[i]))) {
+				printk(KERN_ERR "%s%d: Failed to register IRQ for vector %d.\n",
+						dev->name, dev->id, i);
+				for (j = 0 ; j < i ; j++)
+					free_irq(dev->msixentry[j].vector,
+						 &(dev->aac_msix[j]));
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_DISABLE_MSI))
+				pci_disable_msix(dev->pdev);
+#endif
+				ret = -1;
+			}
+#if ((defined(RHEL_MAJOR) && RHEL_MAJOR == 6 && RHEL_MINOR >= 2)\
+	  || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,35)))
+			if(irq_set_affinity_hint(dev->msixentry[i].vector, get_cpu_mask(cpu))) {
+				printk(KERN_ERR "%s%d: Failed to set IRQ affinity for cpu %d\n",
+					    dev->name, dev->id, cpu);
+			}
+			cpu = cpumask_next(cpu, cpu_online_mask);
+#endif
+		}
+	} else {
+		dev->aac_msix[0].vector_no = 0;
+		dev->aac_msix[0].dev = dev;
+
+		if (request_irq(dev->pdev->irq, dev->a_ops.adapter_intr,
+			IRQF_SHARED|IRQF_DISABLED, "aacraid", &(dev->aac_msix[0])) < 0) {
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_DISABLE_MSI))
+			if (dev->msi)
+				pci_disable_msi(dev->pdev);
+#endif
+			printk(KERN_ERR "%s%d: Interrupt unavailable.\n",
+					dev->name, dev->id);
+			ret = -1;
+		}
+	}
+	return ret;
+}
+
+void aac_free_irq(struct aac_dev *dev)
+{
+	int i;
+#if ((defined(RHEL_MAJOR) && RHEL_MAJOR == 6 && RHEL_MINOR >= 2)\
+	  || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,35)))
+	int cpu;
+	cpu = cpumask_first(cpu_online_mask);
+#endif
+	if (dev->pdev->device == PMC_DEVICE_S6 ||
+	    dev->pdev->device == PMC_DEVICE_S7 ||
+	    dev->pdev->device == PMC_DEVICE_S8 ||
+	    dev->pdev->device == PMC_DEVICE_S9) {
+		if (dev->max_msix > 1) {
+			for (i = 0; i < dev->max_msix; i++){
+#if ((defined(RHEL_MAJOR) && RHEL_MAJOR == 6 && RHEL_MINOR >= 2)\
+	  || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,35)))
+				if(irq_set_affinity_hint(dev->msixentry[i].vector, NULL)) {
+				printk(KERN_ERR "%s%d: Failed to reset IRQ affinity for cpu %d\n",
+					    dev->name, dev->id, cpu);
+				}
+				cpu = cpumask_next(cpu, cpu_online_mask);
+#endif
+				free_irq(dev->msixentry[i].vector, &(dev->aac_msix[i]));
+			}
+		} else {
+			free_irq(dev->pdev->irq, &(dev->aac_msix[0]));
+		}
+	} else {
+		free_irq(dev->pdev->irq, dev);
+	}
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_DISABLE_MSI))
+	if (dev->msi)
+		pci_disable_msi(dev->pdev);
+	else if (dev->max_msix > 1)
+		pci_disable_msix(dev->pdev);
+#endif
+}
diff --git a/drivers/scsi/aacraid/compat.h b/drivers/scsi/aacraid/compat.h
new file mode 100644
index 0000000..8811a8e
--- /dev/null
+++ b/drivers/scsi/aacraid/compat.h
@@ -0,0 +1,403 @@
+/*
+ *	Adaptec AAC series RAID controller driver
+ *	(c) Copyright 2001 Red Hat Inc.	<alan@redhat.com>
+ *
+ * Copyright (c) 2004-2007 Adaptec, Inc. (aacraid@adaptec.com)
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; see the file COPYING.  If not, write to
+ * the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ */
+/*
+ * This file is for backwards compatibility with older kernel versions
+ */
+#include <linux/version.h>
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,15))
+#ifndef sdev_channel
+#define sdev_channel(x)	(x)->channel
+#endif
+#ifndef scmd_channel
+#define scmd_channel(x)	sdev_channel((x)->device)
+#endif
+#ifndef sdev_id
+#define sdev_id(x)	(x)->id
+#endif
+#ifndef scmd_id
+#define scmd_id(x)	sdev_id((x)->device)
+#endif
+
+#endif
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22))
+#ifndef scsi_sglist
+#define scsi_sglist(cmd) ((struct scatterlist *)((cmd)->request_buffer))
+#endif
+#ifndef scsi_bufflen
+#define scsi_bufflen(cmd) ((cmd)->request_bufflen)
+#endif
+#ifndef scsi_sg_count
+#define scsi_sg_count(cmd) ((cmd)->use_sg)
+#endif
+#ifndef SCSI_HAS_DMA_MAP
+#define scsi_dma_unmap(cmd) if(scsi_sg_count(cmd))pci_unmap_sg(((struct aac_dev *)cmd->device->host->hostdata)->pdev,scsi_sglist(cmd),scsi_sg_count(cmd),cmd->sc_data_direction)
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__VMKLNX__))
+#define scsi_dma_map(cmd) scsi_sg_count(cmd)
+#else
+#define scsi_dma_map(cmd) ((scsi_sg_count(cmd))?pci_map_sg(((struct aac_dev *)cmd->device->host->hostdata)->pdev,scsi_sglist(cmd),scsi_sg_count(cmd),cmd->sc_data_direction):0)
+#endif
+#endif
+#if (!defined(__VMKLNX__))
+#define sg_next(sg) ((sg)+1)
+#endif
+#ifndef scsi_resid
+#define scsi_resid(cmd) ((cmd)->resid)
+#define scsi_set_resid(cmd,res) (cmd)->resid = res
+#endif
+#ifndef scsi_for_each_sg
+#define scsi_for_each_sg(cmd, sg, nseg, __i) \
+	for (__i = 0, sg = scsi_sglist(cmd); __i < (nseg); __i++, sg = sg_next(sg))
+#endif
+
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24))
+# define uintptr_t ptrdiff_t
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,9)) && !defined(SCSI_HAS_SSLEEP))
+#undef ssleep
+#define ssleep(x) scsi_sleep((x)*HZ)
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,7)) && !defined(HAS_MSLEEP))
+#define msleep(x) set_current_state(TASK_UNINTERRUPTIBLE); schedule_timeout(x)
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,19))
+#ifndef __builtin_expect
+#define __builtin_expect(x,expected_value) (x)
+#endif
+#ifndef unlikely
+#define unlikely(x) __builtin_expect(!!(x),0)
+#endif
+#ifndef likely
+#define likely(x) __builtin_expect(!!(x),1)
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,9))
+#ifndef BUG_ON
+#define BUG_ON(condition) do { if (unlikely((condition)!=0)) BUG(); } while (0)
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,10))
+#ifndef min
+#define min(a,b) (((a)<(b))?(a):(b))
+#endif
+#ifndef min_t
+#define min_t(a,b,c) (((a)(b)<(a)(c))?(a)(b):(a)(c))
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,0))
+ typedef unsigned long dma_addr_t;
+#include <linux/kcomp.h>
+#define PCI_ANY_ID (~0)
+#define SCSI_DATA_UNKNOWN	0
+#define SCSI_DATA_WRITE		1
+#define SCSI_DATA_READ		2
+#define SCSI_DATA_NONE		3
+ /* Sigh ... a *lot* more needs to be done for this Grandpa */
+
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+#include <linux/time.h>
+static inline unsigned long get_seconds(void)
+{
+	struct timeval now;
+	do_gettimeofday(&now);
+	return now.tv_sec;
+}
+#define scsi_host_template SHT
+#define DMA_BIDIRECTIONAL	SCSI_DATA_UNKNOWN
+#define DMA_TO_DEVICE		SCSI_DATA_WRITE
+#define DMA_FROM_DEVICE		SCSI_DATA_READ
+#define DMA_NONE		SCSI_DATA_NONE
+#if (defined(__ESXi4__))
+#define imajor(x) MAJOR(x->i_rdev) //ESXi4 support
+#else
+#define iminor(x) MINOR(x->i_rdev)
+#endif
+#define scsi_host_alloc(t,s) scsi_register(t,s)
+#if (defined(CONFIG_VMNIX) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,4)))
+#define scsi_host_put(s)
+#else
+#define scsi_host_put(s) scsi_unregister(s)
+#endif
+#ifndef pci_set_consistent_dma_mask
+#define pci_set_consistent_dma_mask(d,m) 0
+#endif
+#ifndef SCSI_HAS_SCSI_SCAN_HOST
+#ifndef scsi_scan_host
+#define scsi_scan_host(s)
+#endif
+#endif
+#define scsi_add_host(s,d) 0
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,4,20)) && !defined(list_for_each_entry))
+#if (!defined(_LINUX_PREFETCH_H))
+static inline void prefetch(const void *x) {;}
+#endif
+#define list_for_each_entry(pos, head, member)                          \
+        for (pos = list_entry((head)->next, typeof(*pos), member),      \
+                     prefetch(pos->member.next);                        \
+             &pos->member != (head);                                    \
+             pos = list_entry(pos->member.next, typeof(*pos), member),  \
+                     prefetch(pos->member.next))
+#endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+#define scsi_remove_host(s)
+#else
+#define scsi_remove_host(s)					\
+	struct proc_dir_entry * entry = NULL;			\
+	struct scsi_device *device;				\
+	extern struct proc_dir_entry * proc_scsi;		\
+	if (proc_scsi != (struct proc_dir_entry *)NULL)		\
+	for (entry = proc_scsi->subdir;				\
+	  entry != (struct proc_dir_entry *)NULL &&		\
+	  (!entry->low_ino ||					\
+	    (entry->namelen != 4) ||				\
+	    memcmp ("scsi", entry->name, 4));			\
+	  entry = entry->next);					\
+	if (entry && entry->write_proc)				\
+	for (device = s->host_queue;				\
+	  device != (struct scsi_device *)NULL;			\
+	  device = device->next)				\
+		if (!device->access_count && !s->in_recovery) {	\
+			char buffer[80];			\
+			int length;				\
+			mm_segment_t fs;			\
+			device->removable = 1;			\
+			sprintf (buffer, "scsi "		\
+			  "remove-single-device %d %d %d %d\n", \
+			  s->host_no, device->channel,		\
+			  device->id, device->lun);		\
+			length = strlen (buffer);		\
+			fs = get_fs();				\
+			set_fs(get_ds());			\
+			length = entry->write_proc(		\
+			  NULL, buffer, length, NULL);		\
+			set_fs(fs);				\
+		}
+#endif
+#if (!defined(__devexit_p))
+# if (defined(MODULE))
+#  define __devexit_p(x) x
+# else
+#  define __devexit_p(x) NULL
+# endif
+#endif
+#define __user
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,6)) && (!defined(SCSI_HAS_SCSI_DEVICE_ONLINE)))
+#define scsi_device_online(d) ((d)->online)
+#ifndef SDEV_RUNNING
+#define SDEV_RUNNING 1
+#endif
+#ifndef SDEV_OFFLINE
+#define SDEV_OFFLINE 0
+#endif
+#define scsi_device_set_state(d,s) ((d)->online=(s!=SDEV_OFFLINE))
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,9))
+#define __iomem
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,9)) && !defined(HAS_BITWISE_TYPE))
+typedef u64 __le64;
+typedef u32 __le32;
+typedef u16 __le16;
+
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,13))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+#include <linux/dma-mapping.h>
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,5))
+#ifndef DMA_64BIT_MASK
+#define DMA_64BIT_MASK ((dma_addr_t)0xffffffffffffffffULL)
+#endif
+#ifndef DMA_32BIT_MASK
+#define DMA_32BIT_MASK ((dma_addr_t)0xffffffffULL)
+#endif
+#endif
+#ifndef DMA_31BIT_MASK
+#define DMA_31BIT_MASK ((dma_addr_t)0x7fffffffULL)
+#endif
+
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11))
+#ifndef spin_trylock_irqsave
+#define spin_trylock_irqsave(lock, flags) \
+({ \
+	local_irq_save(flags); \
+	spin_trylock(lock) ? \
+	1 : ({local_irq_restore(flags); 0 ;}); \
+})
+#endif
+
+#endif
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,1)) && defined(SCSI_HAS_MY_DEVICES))
+#define shost_for_each_device(sdev, shost) \
+	for ((sdev) = __scsi_iterate_devices((shost), NULL); \
+	     (sdev); \
+	     (sdev) = __scsi_iterate_devices((shost), (sdev)))
+#define __shost_for_each_device(sdev, shost) \
+	list_for_each_entry((sdev), &((shost)->my_devices), siblings)
+#include <scsi/scsi_host.h>
+#include <scsi/scsi_device.h>
+static inline struct scsi_device *__scsi_iterate_devices(struct Scsi_Host *shost,
+			                   struct scsi_device *prev)
+{
+	struct list_head *list = (prev ? &prev->siblings : &shost->my_devices);
+	struct scsi_device *next = NULL;
+	unsigned long flags;
+
+	spin_lock_irqsave(shost->host_lock, flags);
+	while (list->next != &shost->my_devices) {
+		next = list_entry(list->next, struct scsi_device, siblings);
+		/* skip devices that we can't get a reference to */
+		if (!scsi_device_get(next))
+			break;
+		list = list->next;
+	}
+	spin_unlock_irqrestore(shost->host_lock, flags);
+
+	if (prev)
+		scsi_device_put(prev);
+	return next;
+}
+
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,18)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,9)) && (LINUX_VERSION_CODE != KERNEL_VERSION(2,4,13))
+# define dma_handle ptr
+
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,11))
+#include <linux/blk.h>
+
+static inline unsigned int block_size(kdev_t dev)
+{
+	int retval = BLOCK_SIZE;
+	int major = MAJOR(dev);
+
+	if (blksize_size[major]) {
+		int minor = MINOR(dev);
+		if (blksize_size[major][minor])
+			retval = blksize_size[major][minor];
+	}
+	return retval;
+}
+
+#endif
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,4,4))
+# define pci_disable_device(x)
+
+#endif
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,4,7))
+
+#ifndef COMPLETION_INITIALIZER
+
+#include <linux/wait.h>
+
+struct completion {
+	unsigned int done;
+	wait_queue_head_t wait;
+};
+#define COMPLETION_INITIALIZER(work) \
+	{ 0, __WAIT_QUEUE_HEAD_INITIALIZER((work).wait) }
+
+#define DECLARE_COMPLETION(work) \
+	struct completion work = COMPLETION_INITIALIZER(work)
+#define INIT_COMPLETION(x)	((x).done = 0)
+
+static inline void init_completion(struct completion *x)
+{
+	x->done = 0;
+	init_waitqueue_head(&x->wait);
+}
+#endif
+
+#ifndef complete_and_exit
+static inline void complete_and_exit(struct completion *comp, long code)
+{
+	/*
+	if (comp)
+		complete(comp);
+
+	do_exit(code);
+	*/
+}
+#endif
+
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,23)) && !defined(sdev_printk))
+#define sdev_printk(prefix, sdev, fmt, a...) \
+	printk(prefix " %d:%d:%d:%d: " fmt, sdev->host->host_no, \
+		sdev_channel(sdev), sdev_id(sdev), sdev->lun, ##a)
+#endif
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,4,2))
+#include <linux/pci.h>
+
+//static inline void scsi_set_pci_device(struct Scsi_Host *SHpnt,
+//                                       struct pci_dev *pdev)
+//{
+///*	SHpnt->pci_dev = pdev;	*/
+//}
+#define scsi_set_pci_device(SHpnt,pdev)
+
+static inline void wait_for_completion(struct completion *x)
+{
+	spin_lock_irq(&x->wait.lock);
+	if (!x->done) {
+		DECLARE_WAITQUEUE(wait, current);
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,0))
+		wait.flags |= WQ_FLAG_EXCLUSIVE;
+#endif
+		__add_wait_queue_tail(&x->wait, &wait);
+		do {
+			__set_current_state(TASK_UNINTERRUPTIBLE);
+			spin_unlock_irq(&x->wait.lock);
+			schedule();
+			spin_lock_irq(&x->wait.lock);
+		} while (!x->done);
+		__remove_wait_queue(&x->wait, &wait);
+	}
+	x->done--;
+	spin_unlock_irq(&x->wait.lock);
+}
+
+static inline int pci_set_dma_mask(struct pci_dev *dev, dma_addr_t mask)
+{
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,0))
+    dev->dma_mask = mask;
+#endif
+
+    return 0;
+}
+
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,18))
+
+#ifndef IRQF_SHARED
+# define IRQF_SHARED SA_SHIRQ
+#endif
+#ifndef IRQF_DISABLED
+# define IRQF_DISABLED SA_INTERRUPT /* Counter intuitive? */
+#endif
+#endif
diff --git a/drivers/scsi/aacraid/csmi.c b/drivers/scsi/aacraid/csmi.c
new file mode 100644
index 0000000..b492026
--- /dev/null
+++ b/drivers/scsi/aacraid/csmi.c
@@ -0,0 +1,1800 @@
+/*
+ *	Adaptec AAC series RAID controller driver
+ *	(c) Copyright 2004-2007 Adaptec, Inc
+ *
+ * Copyright (c) 2004-2007 Adaptec, Inc. (aacraid@adaptec.com)
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; see the file COPYING.  If not, write to
+ * the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Module Name:
+ *   csmi.c
+ *
+ * Abstract: All CSMI IOCTL processing is handled here.
+ */
+
+/*
+ * Include Files
+ */
+
+#include <linux/types.h>
+#include <linux/wait.h>
+#include <linux/spinlock.h>
+#include <linux/kernel.h>
+#include <linux/blkdev.h>
+#include <linux/version.h> /* For the following test */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+#include <asm/semaphore.h>
+#endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,2))
+#include <linux/completion.h>
+#endif
+#include <linux/string.h>
+#include <linux/sched.h>
+#include <linux/pci.h>
+#include <asm/uaccess.h> /* For copy_from_user()/copy_to_user() definitions */
+#include <linux/slab.h> /* For kmalloc()/kfree() definitions */
+#include "aacraid.h"
+#include "fwdebug.h"
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+# include "scsi.h"
+# include "hosts.h"
+#else
+# include <scsi/scsi.h>
+# include <scsi/scsi_host.h>
+//# include <linux/pci.h>
+# include <linux/dma-mapping.h>
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) ? defined(__x86_64__) : defined(CONFIG_COMPAT))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,3))
+#include <linux/syscalls.h>
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,13))
+#include <linux/ioctl32.h>
+#endif
+#endif
+#if ((KERNEL_VERSION(2,4,19) <= LINUX_VERSION_CODE) && (LINUX_VERSION_CODE <= KERNEL_VERSION(2,4,21)))
+# include <asm-x86_64/ioctl32.h>
+#elif (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+# include <asm/ioctl32.h>
+#elif (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,3))
+# include <linux/ioctl32.h>
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+# include <asm/uaccess.h>
+#endif
+#endif
+
+#if (defined(AAC_CSMI))
+
+#include "csmi.h"
+
+
+/*
+ * Routine Description:
+ *	This routine will verify that the *ppHeader is big enough
+ *	for the expected CSMI IOCTL buffer.
+ * Return Value:
+ *	ppHeader
+ *	0 - Success ppHeader set up with successful completion code
+ *	!0 - CSMI_SAS_STATUS_INVALID_PARAMETER as the ReturnCode.
+ */
+static int
+aac_VerifyCSMIBuffer(
+	struct aac_dev ** pDev,
+	void __user * arg,
+	unsigned long csmiBufferSizeToVerify,
+	PIOCTL_HEADER * ppHeader)
+{
+	u32 Length;
+	int Rtnval;
+	struct aac_dev * dev = *pDev;
+	extern struct list_head aac_devices; /* in linit.c */
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev, HBA_FLAGS_DBG_FUNCTION_ENTRY_B,
+	  "aac_VerifyCSMIBuffer: Enter"));
+#endif
+
+	*ppHeader = (PIOCTL_HEADER)NULL;
+
+	if (copy_from_user((void *)&Length,
+	  (void __user *)&((PIOCTL_HEADER)arg)->Length, sizeof(u32))) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev, HBA_FLAGS_DBG_ERROR_B,
+		  "aac_VerifyCSMIBuffer: Acquire Length Failure"));
+#endif
+		Length = CSMI_SAS_STATUS_INVALID_PARAMETER;
+		/* Will msot probably fail */
+		Rtnval = copy_to_user(
+		  (void __user *)&((PIOCTL_HEADER)arg)->ReturnCode,
+		  (void *)&Length, sizeof(u32));
+		Rtnval = -EFAULT;
+	} else if ((Length < sizeof(IOCTL_HEADER))
+	 || (Length < csmiBufferSizeToVerify)
+	 || (csmiBufferSizeToVerify < sizeof(IOCTL_HEADER))) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev, HBA_FLAGS_DBG_ERROR_B,
+		  "aac_VerifyCSMIBuffer:"
+		  " sizeof(IOCTL_HEADER)=%u, Length=%u, MinPacketLength=%u",
+		  sizeof(IOCTL_HEADER), Length, csmiBufferSizeToVerify));
+#endif
+		Length = CSMI_SAS_STATUS_INVALID_PARAMETER;
+		if (copy_to_user(
+		  (void __user *)&((PIOCTL_HEADER)arg)->ReturnCode,
+		  (void *)&Length, sizeof(u32)))
+			Rtnval = -EFAULT;
+		else
+			Rtnval = -EINVAL;
+	} else if (!(*ppHeader = kmalloc(Length, GFP_KERNEL))) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev, HBA_FLAGS_DBG_ERROR_B,
+		  "aac_VerifyCSMIBuffer: Acquire Memory %u Failure",
+		  Length));
+#endif
+		Length = CSMI_SAS_STATUS_INVALID_PARAMETER;
+		if (copy_to_user(
+		  (void __user *)&((PIOCTL_HEADER)arg)->ReturnCode,
+		  (void *)&Length, sizeof(u32)))
+			Rtnval = -EFAULT;
+		else
+			Rtnval = -ENOMEM;
+	} else if (copy_from_user((void *)*ppHeader, arg, Length)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev, HBA_FLAGS_DBG_ERROR_B,
+		  "aac_VerifyCSMIBuffer: Acquire Content Failure"));
+#endif
+		kfree(*ppHeader);
+		*ppHeader = NULL;
+		Length = CSMI_SAS_STATUS_INVALID_PARAMETER;
+		/* Will most probably fail */
+		Rtnval = copy_to_user(
+		  (void __user *)&((PIOCTL_HEADER)arg)->ReturnCode,
+		  (void *)&Length, sizeof(u32));
+		Rtnval = -EFAULT;
+	} else {
+		struct aac_dev * found = (struct aac_dev *)NULL;
+		list_for_each_entry(dev, &aac_devices, entry)
+			if (dev->id == (*ppHeader)->IOControllerNumber) {
+				found = dev;
+				break;
+			}
+		dev = found;
+		if (dev == (struct aac_dev *)NULL) {
+			dev = *pDev; /* Return to original host */
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+			fwprintf((dev, HBA_FLAGS_DBG_ERROR_B,
+			  "aac_VerifyCSMIBuffer: Acquire %d Indexed Controller Failure",
+			  (*ppHeader)->IOControllerNumber));
+#endif
+			kfree(*ppHeader);
+			*ppHeader = NULL;
+			Length = CSMI_SAS_STATUS_INVALID_PARAMETER;
+			if (copy_to_user(
+			  (void __user *)&((PIOCTL_HEADER)arg)->ReturnCode,
+			  (void *)&Length, sizeof(u32)))
+				Rtnval = -EFAULT;
+			else
+				Rtnval = -EINVAL;
+		} else {
+			(*ppHeader)->ReturnCode = CSMI_SAS_STATUS_SUCCESS;
+			*pDev = dev;
+			Rtnval = 0;
+		}
+	}
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev, HBA_FLAGS_DBG_FUNCTION_EXIT_B,
+	  "aac_VerifyCSMIBuffer: Exit, ReturnValue=%d",Rtnval));
+#endif
+
+	return Rtnval;
+
+}
+
+
+/*
+ * Routine Description:
+ *	This routine will close the *ppHeader.
+ * Return Value:
+ *	0 - Success
+ *	!0 - Failure
+ */
+static inline int
+aac_CloseCSMIBuffer(
+	struct aac_dev * dev,
+	void __user * arg,
+	PIOCTL_HEADER pHeader)
+{
+	int Rtnval = 0;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev, HBA_FLAGS_DBG_FUNCTION_ENTRY_B,
+	  "aac_CloseCSMIBuffer: Enter"));
+#endif
+
+	if (pHeader) {
+		if (copy_to_user(arg, (void *)pHeader, pHeader->Length))
+			Rtnval = -EFAULT;
+		kfree (pHeader);
+	}
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev, HBA_FLAGS_DBG_FUNCTION_EXIT_B,
+	  "aac_CloseCSMIBuffer: Exit, ReturnValue=%d",Rtnval));
+#endif
+
+	return Rtnval;
+
+}
+
+typedef struct aac_bus_info DIOCTL;
+typedef DIOCTL * PDIOCTL;
+/* IOCTL Functions */
+#define CsmiGetPhyInfo		0x0070
+#define CsmiSataSignature	0x0071
+
+typedef struct {
+	u32	Status;		/* ST_OK */
+	u32	ObjType;	
+	u32	MethodId;	/* unused */
+	u32	ObjectId;	/* unused */
+	u32	CtlCmd;		/* unused */
+} DIOCTLRESPONSE;
+typedef DIOCTLRESPONSE * PDIOCTLRESPONSE;
+
+#define EnhancedGetBusInfo	0x0000000C
+#define SCSI_MAX_PORTS	10
+#define CSS_BUS_TYPE_SATA 11
+#define CSS_BUS_TYPE_SAS	12
+typedef struct aac_enhanced_bus_info_response {
+	struct aac_bus_info_response BusInfo;
+	/* Enhancements */
+	u32	Version;
+	u32	BusType[SCSI_MAX_PORTS];
+	u8	NumPortsMapped[SCSI_MAX_PORTS];
+	u8	ReservedPad0[2];
+	u32	Reserved[17];
+} ENHANCED_GBI_CSS;
+
+/*
+ * Routine Description:
+ *	This routine is called to request the version information for the
+ *	hardware, firmware, and boot BIOS associated with a storage controller.
+ *
+ * Return Value:
+ *	Status value, to be returned by aac_HandleCSMI, and returned to
+ *	--> Must set CSMI status value in pHeader->ReturnCode.
+ */
+int
+aac_CSMIGetControllerConfig(
+	struct aac_dev * dev,
+	void __user * arg)
+{
+	int Rtnval;
+	PCSMI_SAS_CNTLR_CONFIG_BUFFER pControllerConfigBuffer;
+	PDIOCTL pIoctlInfo;
+	ENHANCED_GBI_CSS * EnhancedBusInfo;
+	struct fib * fibptr;
+	int status;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_ENTRY_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetControllerConfig: Enter"));
+#endif
+
+	/*
+	 * Verify buffer size. If buffer is too small, the error status will
+	 * be set for pHeader->ReturnCode in aac_VerifyCSMIBuffer.
+	 */
+	if ((Rtnval = aac_VerifyCSMIBuffer(&dev, arg,
+	  sizeof(CSMI_SAS_CNTLR_CONFIG_BUFFER),
+	  (PIOCTL_HEADER *)&pControllerConfigBuffer))) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMISTPPassThru: Exit, ReturnValue = %d",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	pControllerConfigBuffer->Configuration.uBaseIoAddress = 0;
+	pControllerConfigBuffer->Configuration.BaseMemoryAddress.uHighPart
+	  = ((u64)dev->scsi_host_ptr->base) >> 32;
+	pControllerConfigBuffer->Configuration.BaseMemoryAddress.uLowPart
+	  = dev->scsi_host_ptr->base & 0xffffffff;
+	pControllerConfigBuffer->Configuration.uBoardID
+	  = (dev->pdev->subsystem_device << 16)
+	  + dev->pdev->subsystem_vendor;
+	/*
+	 * Slot number can be pulled from
+	 * dev->supplement_adapter_info->SlotNumber in later versions of
+	 * the firmware else we could choose to take Linux PCI device slot
+	 * number PCI_SLOT(dev->pdev->devfn) instead?
+	 */
+	if ((dev->supplement_adapter_info.Version < AAC_SIS_VERSION_V3)
+	 || (dev->supplement_adapter_info.SlotNumber == AAC_SIS_SLOT_UNKNOWN)) {
+		pControllerConfigBuffer->Configuration.usSlotNumber
+		  = SLOT_NUMBER_UNKNOWN;
+	} else {
+		pControllerConfigBuffer->Configuration.usSlotNumber
+		 = dev->supplement_adapter_info.SlotNumber;
+	}
+	pControllerConfigBuffer->Configuration.bControllerClass
+	  = CSMI_SAS_CNTLR_CLASS_HBA;
+	pControllerConfigBuffer->Configuration.bIoBusType
+	  = CSMI_SAS_BUS_TYPE_PCI;
+	pControllerConfigBuffer->Configuration.BusAddress.PciAddress.bBusNumber
+	  = dev->pdev->bus->number;
+	pControllerConfigBuffer->Configuration.BusAddress.PciAddress.bDeviceNumber
+	  = PCI_SLOT(dev->pdev->devfn);
+	pControllerConfigBuffer->Configuration.BusAddress.PciAddress.bFunctionNumber
+	  = PCI_FUNC(dev->pdev->devfn);
+	pControllerConfigBuffer->Configuration.szSerialNumber[0] = '\0';
+	(void)aac_show_serial_number(shost_to_class(dev->scsi_host_ptr),
+	  pControllerConfigBuffer->Configuration.szSerialNumber);
+	{
+		char * cp = strchr(pControllerConfigBuffer->Configuration.szSerialNumber, '\n');
+		if (cp)
+			*cp = '\0';
+	}
+	/* Get Bus Type */
+	fibptr = aac_fib_alloc(dev);
+	if (fibptr == NULL) {
+		pControllerConfigBuffer->Configuration.uControllerFlags
+		  = CSMI_SAS_CNTLR_SATA_RAID;
+	} else {
+		aac_fib_init(fibptr);
+
+		pIoctlInfo = (PDIOCTL) fib_data(fibptr);
+		pIoctlInfo->Command = cpu_to_le32(VM_Ioctl);
+		pIoctlInfo->ObjType = cpu_to_le32(FT_DRIVE);
+		pIoctlInfo->MethodId = cpu_to_le32(1);
+		pIoctlInfo->ObjectId = 0;
+		pIoctlInfo->CtlCmd = cpu_to_le32(EnhancedGetBusInfo);
+
+		status = aac_fib_send(ContainerCommand, fibptr,
+		  sizeof(*EnhancedBusInfo),
+		  FsaNormal, 1, 1, NULL, NULL);
+	
+		aac_fib_complete(fibptr);
+	
+		EnhancedBusInfo = (struct aac_enhanced_bus_info_response *) pIoctlInfo;
+	
+		if (status < 0) {
+			pControllerConfigBuffer->Configuration.uControllerFlags
+			  = CSMI_SAS_CNTLR_SATA_RAID;
+		} else switch (EnhancedBusInfo->BusType[0]) {
+		case CSS_BUS_TYPE_SATA:
+			pControllerConfigBuffer->Configuration.uControllerFlags
+			  = CSMI_SAS_CNTLR_SATA_RAID;
+			break;
+		case CSS_BUS_TYPE_SAS:
+			pControllerConfigBuffer->Configuration.uControllerFlags
+			  = CSMI_SAS_CNTLR_SAS_RAID;
+			break;
+		default:
+			pControllerConfigBuffer->Configuration.uControllerFlags
+			  = 0;
+			break;
+		}
+		aac_fib_free(fibptr);
+	}
+
+	pControllerConfigBuffer->Configuration.usBIOSBuildRevision
+	  = cpu_to_le16(le32_to_cpu(dev->adapter_info.biosbuild));
+	pControllerConfigBuffer->Configuration.usBIOSMajorRevision
+	  = cpu_to_le16(le32_to_cpu(dev->adapter_info.biosrev) >> 24);
+	pControllerConfigBuffer->Configuration.usBIOSMinorRevision
+	  = cpu_to_le16((le32_to_cpu(dev->adapter_info.biosrev) >> 16) & 0xff);
+	pControllerConfigBuffer->Configuration.usBIOSReleaseRevision
+	  = cpu_to_le16(le32_to_cpu(dev->adapter_info.biosrev) & 0xff);
+	pControllerConfigBuffer->Configuration.usBuildRevision
+	  = cpu_to_le16(le32_to_cpu(dev->adapter_info.kernelbuild));
+	pControllerConfigBuffer->Configuration.usMajorRevision
+	  = cpu_to_le16(le32_to_cpu(dev->adapter_info.kernelrev) >> 24);
+	pControllerConfigBuffer->Configuration.usMinorRevision
+	  = cpu_to_le16((le32_to_cpu(dev->adapter_info.kernelrev) >> 16) & 0xff);
+	pControllerConfigBuffer->Configuration.usReleaseRevision
+	  = cpu_to_le16(le32_to_cpu(dev->adapter_info.kernelrev) & 0xff);
+	pControllerConfigBuffer->Configuration.usRromBIOSBuildRevision = 0;
+	pControllerConfigBuffer->Configuration.usRromBIOSMajorRevision = 0;
+	pControllerConfigBuffer->Configuration.usRromBIOSMinorRevision = 0;
+	pControllerConfigBuffer->Configuration.usRromBIOSReleaseRevision = 0;
+	pControllerConfigBuffer->Configuration.usRromBuildRevision = 0;
+	pControllerConfigBuffer->Configuration.usRromMajorRevision = 0;
+	pControllerConfigBuffer->Configuration.usRromMinorRevision = 0;
+	pControllerConfigBuffer->Configuration.usRromReleaseRevision = 0;
+
+	Rtnval = aac_CloseCSMIBuffer(dev, arg,
+	  (PIOCTL_HEADER)pControllerConfigBuffer);
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetControllerConfig: Exit, ReturnValue=%d, ReturnCode=%x",
+	  Rtnval, pControllerConfigBuffer->IoctlHeader.ReturnCode));
+#endif
+
+	return Rtnval;
+
+}
+
+
+/*
+ * Routine Description:
+ *	This routine is called to request the current status of the controller.
+ *
+ * Return Value:
+ *	Status value, to be returned by aac_HandleCSMI, and returned to the OS.
+ *	--> Must set CSMI status value in pHeader->ReturnCode.
+ */
+int
+aac_CSMIGetControllerStatus(
+	struct aac_dev * dev,
+	void __user * arg)
+{
+	int Rtnval;
+	PCSMI_SAS_CNTLR_STATUS_BUFFER pStatusBuffer;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_ENTRY_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetControllerStatus: Enter"));
+#endif
+
+	/*
+	 * Verify buffer size. If buffer is too small, the error status will
+	 * be set for pHeader->ReturnCode in aac_VerifyCSMIBuffer.
+	 */
+	if ((Rtnval = aac_VerifyCSMIBuffer(&dev, arg,
+	  sizeof(CSMI_SAS_CNTLR_STATUS_BUFFER),
+	  (PIOCTL_HEADER *)&pStatusBuffer))) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetControllerStatus: Exit, ReturnValue=%d",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	/*
+	 * Determine and set adapter state
+	 */
+	switch (aac_adapter_check_health(dev)) {
+	case 0:
+		pStatusBuffer->Status.uStatus = CSMI_SAS_CNTLR_STATUS_GOOD;
+		break;
+	case -1:
+	case -2:
+	case -3:
+		pStatusBuffer->Status.uStatus = CSMI_SAS_CNTLR_STATUS_FAILED;
+		break;
+	default:
+		pStatusBuffer->Status.uStatus = CSMI_SAS_CNTLR_STATUS_OFFLINE;
+		pStatusBuffer->Status.uOfflineReason
+		  = CSMI_SAS_OFFLINE_REASON_NO_REASON;
+	}
+
+	Rtnval = aac_CloseCSMIBuffer(dev, arg, (PIOCTL_HEADER)pStatusBuffer);
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetControllerStatus: Exit, ReturnValue=%d, ReturnCode=%x",
+	  Rtnval, pStatusBuffer->IoctlHeader.ReturnCode));
+#endif
+
+	return Rtnval;
+
+}
+
+
+/*
+ * Routine Description:
+ *	This routine is called to request information for a specified RAID set
+ *	on a controller that supports RAID.
+ * Return Value:
+ *	Status value, to be returned by aac_HandleCSMI, and returned to the OS
+ *	--> Must set CSMI status value in pHeader->ReturnCode.
+ */
+int
+aac_CSMIGetRAIDConfig(
+	struct aac_dev * dev,
+	void __user * arg)
+{
+	int Rtnval;
+	PCSMI_SAS_RAID_CONFIG_BUFFER pRaidConfigBuffer;
+	typedef struct {
+		u32	command;
+		u32	type;
+		u32	cid;
+		u32	parm1;
+		u32	parm2;
+		u32	uid;
+		u32	offset;
+		u32	parm5;
+	} CONTAINER;
+	CONTAINER * ct;
+#	define CT_PACKET_SIZE (sizeof(((struct hw_fib *)NULL)->data)-(sizeof(u32)*12))
+#	define CT_CONTINUE_DATA		83
+#	define CT_STOP_DATA		84
+#	define CT_GET_RAID_CONFIG	215
+	typedef struct {
+		u32	response;
+		u32	type;
+		u32	status;
+		u32	count;
+		u32	parm2;
+		u32	uid;
+		u32	parm4;
+		u32	parm5;
+		u32	data[1];
+	} CONTAINERRESPONSE;
+	CONTAINERRESPONSE * ctr;
+#	define CT_CONTINUATION_ERROR 199
+	u16 bufferOffset = 0;
+	u16 LoopCount = 0;
+	unsigned long uniqueID = 0, sizeLeft = 0;
+	unsigned char *DestinationBuffer;
+	struct fib * fibptr;
+	int status;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_ENTRY_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetRAIDConfig: Enter"));
+#endif
+
+	/*
+	 * Verify buffer size. If buffer is too small, the error status will
+	 * be set for pHeader->ReturnCode in aac_VerifyCSMIBuffer.
+	 */
+	if ((Rtnval = aac_VerifyCSMIBuffer(&dev, arg,
+	  sizeof(CSMI_SAS_RAID_CONFIG_BUFFER),
+	  (PIOCTL_HEADER *)&pRaidConfigBuffer))) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetRAIDConfig: Exit, ReturnValue = %d",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	/*
+	 * Make sure the requested container number exists
+	 */
+	if ((pRaidConfigBuffer->Configuration.uRaidSetIndex == 0)
+	 || (pRaidConfigBuffer->Configuration.uRaidSetIndex
+	  > dev->maximum_num_containers)
+	 || !dev->fsa_dev
+	 || (!dev->
+	  fsa_dev[pRaidConfigBuffer->Configuration.uRaidSetIndex-1].valid)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev, HBA_FLAGS_DBG_ERROR_B,
+		  ((pRaidConfigBuffer->Configuration.uRaidSetIndex
+		    >= dev->maximum_num_containers)
+		      ? "aac_CSMIGetRAIDConfig: RaidIndex=%d > Maximum=%d"
+		      : "aac_CSMIGetRAIDConfig: RaidIndex=%d invalid"),
+		  pRaidConfigBuffer->Configuration.uRaidSetIndex,
+		  dev->maximum_num_containers));
+#endif
+
+		/*
+		 * Indicate the RaidSetIndex is invalid
+		 */
+		pRaidConfigBuffer->IoctlHeader.ReturnCode
+		  = CSMI_SAS_RAID_SET_OUT_OF_RANGE;
+		Rtnval = aac_CloseCSMIBuffer(dev, arg,
+		  (PIOCTL_HEADER)pRaidConfigBuffer);
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetRAIDConfig: Exit, ReturnValue=%d,"
+		  " ReturnCode=CSMI_SAS_RAID_SET_OUT_OF_RANGE",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	fibptr = aac_fib_alloc(dev);
+	if (fibptr == NULL) {
+		pRaidConfigBuffer->IoctlHeader.ReturnCode
+		  = CSMI_SAS_STATUS_FAILED;
+		Rtnval = aac_CloseCSMIBuffer(dev, arg,
+		  (PIOCTL_HEADER)pRaidConfigBuffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetRAIDConfig: Exit, ReturnValue=%d,"
+		  " ReturnCode=CSMI_SAS_STATUS_FAILED",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+	aac_fib_init (fibptr);
+	fibptr->hw_fib_va->header.SenderSize = cpu_to_le16(sizeof(struct hw_fib));
+
+	/*
+	 * Setup and send CT_GET_RAID_CONFIG command to FW to
+	 * fill in IOCTL buffer
+	 */
+	ct = (CONTAINER *) fib_data(fibptr);
+	ct->command = cpu_to_le32(VM_ContainerConfig);
+	ct->type = cpu_to_le32(CT_GET_RAID_CONFIG);
+ 	/* Container number */
+	ct->cid = cpu_to_le32(pRaidConfigBuffer->Configuration.uRaidSetIndex-1);
+
+	status = aac_fib_send(ContainerCommand, fibptr, sizeof(CONTAINER),
+	  FsaNormal, 1, 1, NULL, NULL);
+	aac_fib_complete(fibptr);
+
+	if (status < 0) {
+		aac_fib_free(fibptr);
+		pRaidConfigBuffer->IoctlHeader.ReturnCode
+		  = CSMI_SAS_STATUS_FAILED;
+		Rtnval = aac_CloseCSMIBuffer(dev, arg,
+		  (PIOCTL_HEADER)pRaidConfigBuffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetRAIDConfig: Exit, ReturnValue=%d,"
+		  " ReturnCode=CSMI_SAS_STATUS_FAILED",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	ctr = (CONTAINERRESPONSE *) ct;
+	/*
+	 * Check for error conditions
+	 */
+	if (ctr->status == cpu_to_le32(CT_CONTINUATION_ERROR)) {
+		aac_fib_free(fibptr);
+		/*
+		 * Indicate failure for this IOCTL
+		 */
+		pRaidConfigBuffer->IoctlHeader.ReturnCode
+		  = CSMI_SAS_STATUS_FAILED;
+		Rtnval = aac_CloseCSMIBuffer(dev, arg,
+		  (PIOCTL_HEADER)pRaidConfigBuffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetRAIDConfig: Exit, ReturnValue=%d,"
+		  " ReturnCode=CSMI_SAS_STATUS_FAILED",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	/*
+	 * Grab the total size of data to be returned so we can loop through
+	 * and get it all
+	 */
+	sizeLeft = le32_to_cpu(ctr->count);
+
+	/*
+	 * Get Unique ID for this continuation session
+	 */
+	uniqueID = ctr->uid;
+
+	/*
+	 * If there is more data, continue looping until we're done
+	 */
+	DestinationBuffer = (unsigned char *)(&pRaidConfigBuffer->Configuration);
+
+	while (sizeLeft) {
+		aac_fib_init (fibptr);
+		fibptr->hw_fib_va->header.SenderSize
+		  = cpu_to_le16(sizeof(struct hw_fib));
+
+		ct->command = cpu_to_le32(VM_ContainerConfig);
+		ct->type = cpu_to_le32(CT_CONTINUE_DATA);
+		ct->uid = uniqueID;
+		ct->offset = cpu_to_le32(LoopCount);
+
+		status = aac_fib_send(ContainerCommand, fibptr, sizeof(CONTAINER),
+		  FsaNormal, 1, 1, NULL, NULL);
+		aac_fib_complete(fibptr);
+
+		if (status < 0) {
+			/*
+			 * Indicate failure for this IOCTL
+			 */
+			pRaidConfigBuffer->IoctlHeader.ReturnCode
+			  = CSMI_SAS_STATUS_FAILED;
+			break;
+		}
+
+		/*
+		 * Check for error conditions
+		 */
+		if (ctr->status == cpu_to_le32(CT_CONTINUATION_ERROR)) {
+			/*
+			 * Indicate failure for this IOCTL
+			 */
+			pRaidConfigBuffer->IoctlHeader.ReturnCode
+			  = CSMI_SAS_STATUS_FAILED;
+			break;
+		}
+
+		/*
+		 * No error so copy the remaining data
+		 */
+		/*
+		 * Move the full packet size and update for the next loop
+		 */
+		if (sizeLeft >= CT_PACKET_SIZE) {
+			memcpy(DestinationBuffer, ctr->data, CT_PACKET_SIZE);
+
+			/*
+			 * Set current offset in buffer, so we can continue
+			 * copying data.
+			 */
+			bufferOffset += CT_PACKET_SIZE;
+			DestinationBuffer += CT_PACKET_SIZE;
+			sizeLeft -= CT_PACKET_SIZE;
+			++LoopCount;
+		}
+
+		/*
+		 * last transfer; is less than CT_PACKET_SIZE, so just use
+		 * sizeLeft
+		 */
+		else {
+			memcpy(DestinationBuffer, ctr->data, sizeLeft);
+			sizeLeft = 0;
+		}
+	}
+
+	/*
+	 * At this point, we have copied back
+	 * all of the data. Send a STOP command
+	 * to finish things off.
+	 */
+	aac_fib_init (fibptr);
+
+	ct->command = cpu_to_le32(VM_ContainerConfig);
+	ct->type = cpu_to_le32(CT_STOP_DATA);
+	ct->uid = uniqueID;
+
+	aac_fib_send(ContainerCommand, fibptr, sizeof(CONTAINER),
+	  FsaNormal, 1, 1, NULL, NULL);
+	aac_fib_complete(fibptr);
+	aac_fib_free(fibptr);
+
+	Rtnval = aac_CloseCSMIBuffer(dev, arg, (PIOCTL_HEADER)pRaidConfigBuffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetRAIDConfig: Exit, ReturnValue=%d, ReturnCode=%x",
+	  Rtnval, pRaidConfigBuffer->IoctlHeader.ReturnCode));
+#endif
+
+	return Rtnval;
+
+}
+
+
+/*
+ * Routine Description:
+ *	This routine is called to request information on the number of RAID
+ *	volumes and number of physical drives on a controller.
+ * Return Value:
+ *	Status value, to be returned by aac_HandleCSMI, and returned to the OS.
+ *	--> Must set CSMI status value in pHeader->ReturnCode.
+ */
+int
+aac_CSMIGetRAIDInfo(
+	struct aac_dev * dev,
+	void __user * arg)
+{
+	int Rtnval;
+	PCSMI_SAS_RAID_INFO_BUFFER pRaidInfoBuffer;
+	u16 NumRaidSets = 0;
+	int lcv;
+	PDIOCTL pIoctlInfo;
+	ENHANCED_GBI_CSS * EnhancedBusInfo;
+	struct fib * fibptr;
+	int status;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_ENTRY_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetRAIDInfo: Enter"));
+#endif
+
+	/*
+	 * Verify buffer size. If buffer is too small, the error status will
+	 * be set for pHeader->ReturnCode in aac_VerifyCSMIBuffer.
+	 */
+	if ((Rtnval = aac_VerifyCSMIBuffer(&dev, arg,
+	  sizeof(CSMI_SAS_RAID_INFO_BUFFER),
+	  (PIOCTL_HEADER *)&pRaidInfoBuffer))) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetRAIDInfo: Exit, ReturnValue=%d",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	/*
+	 * Traverse the container list and count all containers
+	 */
+	if (dev->fsa_dev)
+	for (lcv = 0; lcv < dev->maximum_num_containers; lcv++)
+		if (dev->fsa_dev[lcv].valid)
+			NumRaidSets++;
+	pRaidInfoBuffer->Information.uNumRaidSets = NumRaidSets;
+
+	/*
+	 * Find the absolute maximum number of physical drives that can make
+	 * up a container. It's pretty ambiquous so we'll default it to the
+	 * Falcon maximum number of drives supported and then try to figure
+	 * out from firmware the max number of drives we can attach to this
+	 * controller.
+	 */
+	pRaidInfoBuffer->Information.uMaxDrivesPerSet = 128;
+	fibptr = aac_fib_alloc(dev);
+	if (fibptr) {
+		aac_fib_init(fibptr);
+
+		pIoctlInfo = (PDIOCTL) fib_data(fibptr);
+		pIoctlInfo->Command = cpu_to_le32(VM_Ioctl);
+		pIoctlInfo->ObjType = cpu_to_le32(FT_DRIVE);
+		pIoctlInfo->MethodId = cpu_to_le32(1);
+		pIoctlInfo->ObjectId = 0;
+		pIoctlInfo->CtlCmd = cpu_to_le32(EnhancedGetBusInfo);
+
+		status = aac_fib_send(ContainerCommand, fibptr,
+		  sizeof(*EnhancedBusInfo),
+		  FsaNormal, 1, 1, NULL, NULL);
+	
+		aac_fib_complete(fibptr);
+	
+		EnhancedBusInfo = (struct aac_enhanced_bus_info_response *) pIoctlInfo;
+	
+		if (status >= 0) switch (EnhancedBusInfo->BusType[0]) {
+		case CSS_BUS_TYPE_SATA:
+			pRaidInfoBuffer->Information.uMaxDrivesPerSet
+			  = le32_to_cpu(dev->supplement_adapter_info.MaxNumberPorts);
+			break;
+		case CSS_BUS_TYPE_SAS:
+			pRaidInfoBuffer->Information.uMaxDrivesPerSet = 128;
+			break;
+		default:
+			pRaidInfoBuffer->Information.uMaxDrivesPerSet
+			  = dev->maximum_num_physicals
+			  * dev->maximum_num_channels;
+			break;
+		}
+		aac_fib_free(fibptr);
+	}
+
+	Rtnval = aac_CloseCSMIBuffer(dev, arg, (PIOCTL_HEADER)pRaidInfoBuffer);
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetRAIDInfo: Exit, ReturnValue=%d, ReturnCode=%x",
+	  Rtnval, pRaidInfoBuffer->IoctlHeader.ReturnCode));
+#endif
+
+	return Rtnval;
+}
+
+
+/*
+ * Routine Description:
+ *	This routine is called to request information about physical
+ *	characteristics and interconnect to the SATA or SAS domain.
+ * Return Value:
+ *	Status value, to be returned by aac_HandleCSMI, and returned to the OS.
+ *	--> Must set CSMI status value in pHeader->ReturnCode.
+ */
+int
+aac_CSMIGetPhyInfo(
+	struct aac_dev * dev,
+	void __user * arg)
+{
+	int Rtnval;
+	PCSMI_SAS_PHY_INFO_BUFFER pPhyInfoBuffer;
+	PDIOCTL pIoctlInfo;
+	PDIOCTLRESPONSE pIoctlResp;
+	struct fib * fibptr;
+	int status;
+	u32 Length;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_ENTRY_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetPhyInfo: Enter scsi%d",
+	  dev->scsi_host_ptr->host_no));
+#endif
+
+#if 0
+	/* Command can not be issued to the adapter */
+	if (!(dev->supplement_adapter_info.FeatureBits
+	 & le32_to_cpu(AAC_FEATURE_FALCON))) {
+		Rtnval = -ENOENT;
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetPhyInfo: Exit, ReturnValue=-ENOENT",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+#endif
+	/*
+	 * Verify buffer size. If buffer is too small, the error status will
+	 * be set for pHeader->ReturnCode in aac_VerifyCSMIBuffer.
+	 */
+	if ((Rtnval = aac_VerifyCSMIBuffer(&dev, arg,
+	  sizeof(CSMI_SAS_PHY_INFO_BUFFER),
+	  (PIOCTL_HEADER *)&pPhyInfoBuffer))) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetPhyInfo: Exit, ReturnValue=%d",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	/* TODO : Figure out the correct size to send or do a continue fib */
+
+	fibptr = aac_fib_alloc(dev);
+	if (fibptr == NULL) {
+		pPhyInfoBuffer->IoctlHeader.ReturnCode = CSMI_SAS_STATUS_FAILED;
+		Rtnval = aac_CloseCSMIBuffer(dev, arg,
+		  (PIOCTL_HEADER)pPhyInfoBuffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetPhyInfo: Exit, ReturnValue=%d,"
+		  " ReturnCode=CSMI_SAS_STATUS_FAILED",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+	aac_fib_init(fibptr);
+	fibptr->hw_fib_va->header.SenderSize = cpu_to_le16(sizeof(struct hw_fib));
+
+	pIoctlInfo = (PDIOCTL) fib_data(fibptr);
+	pIoctlInfo->Command = cpu_to_le32(VM_Ioctl);
+	pIoctlInfo->ObjType = cpu_to_le32(FT_DRIVE);
+	pIoctlInfo->MethodId = cpu_to_le32(1);
+	pIoctlInfo->ObjectId = 0;
+	pIoctlInfo->CtlCmd = cpu_to_le32(CsmiGetPhyInfo);
+	Length = pPhyInfoBuffer->IoctlHeader.Length;
+	/* Issue a Larger FIB? */
+	if (Length > (sizeof(struct hw_fib) - sizeof(struct aac_fibhdr)
+					- sizeof(*pIoctlInfo))) {
+		Length = sizeof(struct hw_fib) - sizeof(struct aac_fibhdr)
+		       - sizeof(*pIoctlInfo);
+		pPhyInfoBuffer->IoctlHeader.Length = Length;
+	}
+	memcpy(((char *)pIoctlInfo) + sizeof(*pIoctlInfo),
+	  pPhyInfoBuffer, Length);
+
+	status = aac_fib_send(ContainerCommand, fibptr,
+	  Length + sizeof(*pIoctlInfo),
+	  FsaNormal, 1, 1, NULL, NULL);
+
+	aac_fib_complete(fibptr);
+
+	if (status < 0) {
+		aac_fib_free(fibptr);
+		pPhyInfoBuffer->IoctlHeader.ReturnCode = CSMI_SAS_STATUS_FAILED;
+		Rtnval = aac_CloseCSMIBuffer(dev, arg,
+		  (PIOCTL_HEADER)pPhyInfoBuffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetPhyInfo: Exit, ReturnValue=%d,"
+		  " ReturnCode=CSMI_SAS_STATUS_FAILED",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	pIoctlResp = (PDIOCTLRESPONSE) pIoctlInfo;
+
+	/*
+	 * Copy back the filled out buffer to complete the
+	 * request
+	 */
+	memcpy(pPhyInfoBuffer, ((char *)pIoctlResp) + sizeof(*pIoctlResp),
+	  Length);
+
+	aac_fib_free(fibptr);
+
+	Rtnval = aac_CloseCSMIBuffer(dev, arg, (PIOCTL_HEADER)pPhyInfoBuffer);
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetPhyInfo: Exit, Rtnval, ReturnCode=%x",
+	  Rtnval, pPhyInfoBuffer->IoctlHeader.ReturnCode));
+#endif
+
+	return Rtnval;
+
+}
+
+
+/*
+ * Routine Description:
+ *	This routine is called to obtain the initial SATA signature (the
+ *	initial Register Device to the Host FIS) from a directly attached SATA
+ *	device.
+ * Return Value:
+ *	Status value, to be returned by aac_HandleCSMI, and returned to the OS.
+ *	--> Must set CSMI status value in pHeader->ReturnCode.
+ */
+int
+aac_CSMIGetSATASignature(
+	struct aac_dev * dev,
+	void __user * arg)
+{
+	int Rtnval;
+	PCSMI_SAS_SATA_SIGNATURE_BUFFER pSataSignatureBuffer;
+	PDIOCTL pIoctlInfo;
+	PDIOCTLRESPONSE pIoctlResp;
+	struct fib * fibptr;
+	int status;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_ENTRY_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetSATASignature: Enter scsi%d",
+	  dev->scsi_host_ptr->host_no));
+#endif
+
+	/*
+	 * Verify buffer size. If buffer is too small, the error status will
+	 * be set for pHeader->ReturnCode in aac_VerifyCSMIBuffer.
+	 */
+	if ((Rtnval = aac_VerifyCSMIBuffer(&dev, arg,
+	  sizeof(CSMI_SAS_SATA_SIGNATURE_BUFFER),
+	  (PIOCTL_HEADER *)&pSataSignatureBuffer))) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetSATASignature: Exit, ReturnValue=%d",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	pSataSignatureBuffer->IoctlHeader.ReturnCode = CSMI_SAS_NO_SATA_DEVICE;
+
+	fibptr = aac_fib_alloc(dev);
+	if (fibptr == NULL) {
+		pSataSignatureBuffer->IoctlHeader.ReturnCode
+		  = CSMI_SAS_STATUS_FAILED;
+		Rtnval = aac_CloseCSMIBuffer(dev, arg,
+		  (PIOCTL_HEADER)pSataSignatureBuffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetSATASignature: Exit, ReturnValue=%d,"
+		  " ReturnCode=CSMI_SAS_STATUS_FAILED",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+	aac_fib_init(fibptr);
+
+	pIoctlInfo = (PDIOCTL) fib_data(fibptr);
+	pIoctlInfo->Command = cpu_to_le32(VM_Ioctl);
+	pIoctlInfo->ObjType = cpu_to_le32(FT_DRIVE);
+	pIoctlInfo->MethodId = cpu_to_le32(1);
+	pIoctlInfo->ObjectId = 0;
+	pIoctlInfo->CtlCmd = cpu_to_le32(CsmiSataSignature);
+	memcpy(((char *)pIoctlInfo) + sizeof(*pIoctlInfo),
+	  pSataSignatureBuffer,sizeof(CSMI_SAS_SATA_SIGNATURE_BUFFER));
+
+	status = aac_fib_send(ContainerCommand, fibptr, sizeof(*pIoctlInfo)
+	  - sizeof(u32) + sizeof(CSMI_SAS_SATA_SIGNATURE_BUFFER), FsaNormal,
+	  1, 1, NULL, NULL);
+
+	aac_fib_complete(fibptr);
+
+	if (status < 0) {
+		aac_fib_free(fibptr);
+		pSataSignatureBuffer->IoctlHeader.ReturnCode
+		  = CSMI_SAS_STATUS_FAILED;
+		Rtnval = aac_CloseCSMIBuffer(dev, arg,
+		  (PIOCTL_HEADER)pSataSignatureBuffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetSATASignature: Exit, ReturnValue=%d,"
+		  " ReturnCode=CSMI_SAS_STATUS_FAILED",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	pIoctlResp = (PDIOCTLRESPONSE) pIoctlInfo;
+
+	/*
+	 * Copy back the filled out buffer to complete the
+	 * request
+	 */
+	memcpy(pSataSignatureBuffer,
+	  ((char *)pIoctlResp) + sizeof(*pIoctlResp),
+	  sizeof(CSMI_SAS_SATA_SIGNATURE_BUFFER));
+
+	aac_fib_free(fibptr);
+
+	/*
+	 * Indicate success for this IOCTL
+	 *	pSataSignatureBuffer->IoctlHeader.ReturnCode
+	 *		= CSMI_SAS_STATUS_SUCCESS;
+	 * is set by the Firmware Response.
+	 */
+	Rtnval = aac_CloseCSMIBuffer(dev, arg,
+	  (PIOCTL_HEADER)pSataSignatureBuffer);
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetSATASignature: Exit, ReturnValue=%d,"
+	  " ReturnCode=CSMI_SAS_STATUS_SUCCESS",
+	  Rtnval));
+#endif
+
+	return Rtnval;
+
+}
+
+
+/*
+ * Routine Description:
+ *	This routine is called to return the driver information.
+ * Return Value:
+ *	Status value, to be returned by aac_HandleCSMI, and returned to the OS.
+ *	--> Must set CSMI status value in pHeader->ReturnCode.
+ */
+int
+aac_CSMIGetDriverInfo(
+	struct aac_dev * dev,
+	void __user * arg)
+{
+	int Rtnval;
+	PCSMI_SAS_DRIVER_INFO_BUFFER pDriverInfoBuffer;
+	char * driver_version = aac_driver_version;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_ENTRY_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetDriverInfo: Enter"));
+#endif
+
+	/*
+	 * Verify buffer size. If buffer is too small, the error status will
+	 * be set for pHeader->ReturnCode in aac_VerifyCSMIBuffer.
+	 */
+	if ((Rtnval = aac_VerifyCSMIBuffer(&dev, arg,
+	  sizeof(CSMI_SAS_DRIVER_INFO_BUFFER),
+	  (PIOCTL_HEADER *)&pDriverInfoBuffer))) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetDriverInfo: Exit, ReturnValue=%d",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	/*
+	 * Fill in the information member of the pDriverInfoBuffer
+	 * structure.
+	 */
+
+	/*
+	 * Driver name
+	 */
+	strncpy(pDriverInfoBuffer->Information.szName,
+	  (dev->scsi_host_ptr->hostt->info
+	    ? dev->scsi_host_ptr->hostt->info(dev->scsi_host_ptr)
+	    : dev->scsi_host_ptr->hostt->name),
+	  sizeof(pDriverInfoBuffer->Information.szName));
+
+	/*
+	 * Driver Description
+	 */
+	sprintf(pDriverInfoBuffer->Information.szDescription,
+	  "Adaptec %s driver",
+	  dev->scsi_host_ptr->hostt->name);
+
+	/*
+	 * Set version number information
+	 */
+	pDriverInfoBuffer->Information.usMajorRevision
+	  = cpu_to_le16(simple_strtol(driver_version, &driver_version, 10));
+	pDriverInfoBuffer->Information.usMinorRevision
+	  = cpu_to_le16(simple_strtol(driver_version + 1, &driver_version, 10));
+#if (defined(AAC_DRIVER_BUILD))
+	pDriverInfoBuffer->Information.usBuildRevision = cpu_to_le16(AAC_DRIVER_BUILD);
+#else
+	pDriverInfoBuffer->Information.usBuildRevision = cpu_to_le16(9999);
+#endif
+	pDriverInfoBuffer->Information.usReleaseRevision
+	  = cpu_to_le16(simple_strtol(driver_version + 1, NULL, 10));
+	pDriverInfoBuffer->Information.usCSMIMajorRevision
+	  = cpu_to_le16(CSMI_MAJOR_REVISION);
+	pDriverInfoBuffer->Information.usCSMIMinorRevision
+	  = cpu_to_le16(CSMI_MINOR_REVISION);
+
+	Rtnval = aac_CloseCSMIBuffer(dev, arg, (PIOCTL_HEADER)pDriverInfoBuffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMIGetDriverInfo: Exit, ReturnValue=%d, ReturnCode=%x",
+	  Rtnval, pDriverInfoBuffer->IoctlHeader.ReturnCode));
+#endif
+
+	return Rtnval;
+
+}
+
+
+
+/*
+ * Routine Description:
+ *	This routine is called to change the physical characteristics of a phy.
+ *	We currently do not support this functionality, and are not required to
+ *	in order to support CSMI.
+ * Return Value:
+ *	Status value, to be returned by aac_HandleCSMI, and returned to the OS.
+ *	--> Must set CSMI status value in pHeader->ReturnCode.
+ */
+int
+aac_CSMISetPhyInfo(
+	struct aac_dev * dev,
+	void __user * arg)
+{
+	int Rtnval;
+	u32 ReturnCode;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_ENTRY_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMISetPhyInfo: Enter scsi%d",
+	  dev->scsi_host_ptr->host_no));
+#endif
+
+	ReturnCode = CSMI_SAS_PHY_INFO_NOT_CHANGEABLE;
+	Rtnval = 0;
+	if (copy_to_user((void __user *)&((PIOCTL_HEADER)arg)->ReturnCode,
+	  (void *)&ReturnCode, sizeof(u32)))
+		Rtnval = -EFAULT;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMISetPhyInfo: Exit, ReturnValue=%d,"
+	  " ReturnCode=CSMI_SAS_PHY_INFO_NOT_CHANGEABLE",
+	  Rtnval));
+#endif
+
+	return Rtnval;
+
+}
+
+
+/*
+ * Routine Description:
+ *	This routine is called to send generic STP or SATA commands to a
+ *	specific SAS address.
+ * Return Value:
+ *	Status value, to be returned by aac_HandleCSMI, and returned to the OS.
+ *	--> Must set CSMI status value in pHeader->ReturnCode.
+ */
+int
+aac_CSMISTPPassThru(
+	struct aac_dev * dev,
+	void __user * arg)
+{
+	int Rtnval;
+	PCSMI_SAS_STP_PASSTHRU_BUFFER pPassThruBuffer;
+	unsigned bytesLeft = 0;
+	u8 * pDataPointer = NULL;
+	/* function */
+#	define SATAPASSTHROUGH_REGISTER		0x00000000
+#	define SATAPASSTHROUGH_SOFTRESET	0x00000001
+	typedef struct {
+		u32	function;
+		u32	bus;
+		u32	targetId;
+		u32	lun;
+		u32	timeOutValue;
+		u32	srbFlags;
+#			define	HOSTSRB_FLAGS_NO_DATA_TRANSFER	0x00000000
+#			define	HOSTSRB_FLAGS_DATA_IN		0x00000040
+#			define	HOSTSRB_FLAGS_DATA_OUT		0x00000080
+		u32	dataTransferLength;
+		u32	retryLimit;
+		u32	cdbLength;
+		u8	command;
+		u8	features;
+		u8	sectorNumber;
+		u8	cylinderLow;
+		u8	cylinderHigh;
+		u8	deviceHead;
+		u8	sectorNumber_Exp;
+		u8	cylinderLow_Exp;
+		u8	cylinderHigh_Exp;
+		u8	features_Exp;
+		u8	sectorCount;
+		u8	sectorCount_Exp;
+		u8	reserved;
+		u8	control;
+		u8	reserved1[2];
+		u32	reserved2[4];
+		struct sgmap64	sgMap;
+	} HOST_SATA_REQUEST_BLOCK;
+	typedef HOST_SATA_REQUEST_BLOCK * PHOST_SATA_REQUEST_BLOCK;
+	PHOST_SATA_REQUEST_BLOCK pSataRequest;
+	typedef struct {
+		u32	status;
+		u32	srbStatus;
+		u32	scsiStatus;
+		u32	dataTransferLength;
+		u32	senseInfoBufferLength;
+		u8	statusReg;
+		u8	error;
+		u8	sectorNumber;
+		u8	cylinderLow;
+		u8	cylinderHigh;
+		u8	deviceHead;
+		u8	sectorNumber_Exp;
+		u8	cylinderLow_Exp;
+		u8	cylinderHigh_Exp;
+		u8	deviceRegister_Exp;
+		u8	features;
+		u8	featuers_Exp;
+		u8	reserved1[4];
+	} HOST_SATA_REQUEST_BLOCK_RESULT;
+	typedef HOST_SATA_REQUEST_BLOCK_RESULT * PHOST_SATA_REQUEST_BLOCK_RESULT;
+	PHOST_SATA_REQUEST_BLOCK_RESULT pSataResponse;
+	struct sgmap64 * pSgMap;
+	struct fib * fibptr;
+	int status;
+	dma_addr_t addr;
+	void * p = NULL;
+#	define SataPortCommandU64	602
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_ENTRY_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMISTPPassThru: Enter scsi%d",
+	  dev->scsi_host_ptr->host_no));
+#endif
+
+	/*
+	 * Verify buffer size. If buffer is too small, the error status will
+	 * be set for pHeader->ReturnCode in aac_VerifyCSMIBuffer.
+	 */
+	if ((Rtnval = aac_VerifyCSMIBuffer(&dev, arg,
+	  sizeof(CSMI_SAS_STP_PASSTHRU_BUFFER),
+	  (PIOCTL_HEADER *)&pPassThruBuffer))) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMISTPPassThru: Exit, ReturnValue=%d",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+	/*
+	 * Weed out the flags we don't support
+	 */
+	if ((pPassThruBuffer->Parameters.uFlags & CSMI_SAS_STP_DMA)
+	 || (pPassThruBuffer->Parameters.uFlags & CSMI_SAS_STP_DMA_QUEUED)) {
+		/*
+		 * Indicate failure for this IOCTL
+		 */
+		pPassThruBuffer->IoctlHeader.ReturnCode
+		  = CSMI_SAS_STATUS_FAILED;
+		Rtnval = aac_CloseCSMIBuffer(dev, arg,
+		  (PIOCTL_HEADER)pPassThruBuffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMISTPPassThru: Exit, ReturnValue=%d,"
+		  " ReturnCode=CSMI_SAS_STATUS_FAILED",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	fibptr = aac_fib_alloc(dev);
+	if (fibptr == NULL) {
+		pPassThruBuffer->IoctlHeader.ReturnCode
+		  = CSMI_SAS_STATUS_FAILED;
+		Rtnval = aac_CloseCSMIBuffer(dev, arg,
+		  (PIOCTL_HEADER)pPassThruBuffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMISTPPassThru: Exit, ReturnValue=%d,"
+		  " ReturnCode=CSMI_SAS_STATUS_FAILED",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+	aac_fib_init(fibptr);
+
+	pSataRequest = (PHOST_SATA_REQUEST_BLOCK) fib_data(fibptr);
+	pSgMap = &pSataRequest->sgMap;
+	pSataResponse = (PHOST_SATA_REQUEST_BLOCK_RESULT) pSataRequest;
+
+	/*
+	 * Setup HOST_SATA_REQUEST_BLOCK structure
+	 */
+	memset(pSataRequest,0,sizeof(*pSataRequest));
+	memset(pSataResponse,0,sizeof(HOST_SATA_REQUEST_BLOCK_RESULT));
+	if (pPassThruBuffer->Parameters.uFlags & CSMI_SAS_STP_RESET_DEVICE)
+		pSataRequest->function = SATAPASSTHROUGH_SOFTRESET;
+	else
+		pSataRequest->function = SATAPASSTHROUGH_REGISTER;
+
+	/*
+	 * Pull relevant data from header.
+	 */
+	if (pPassThruBuffer->Parameters.uFlags & CSMI_SAS_STP_READ)
+		pSataRequest->srbFlags = HOSTSRB_FLAGS_DATA_IN;
+	else
+		pSataRequest->srbFlags = HOSTSRB_FLAGS_DATA_OUT;
+	pSataRequest->timeOutValue = pPassThruBuffer->IoctlHeader.Timeout;
+
+	/*
+	 * Obsolete parameter - adapter firmware ignores this
+	 */
+	pSataRequest->retryLimit = 0;
+	pSataRequest->cdbLength = 14;
+
+	/*
+	 * Fill in remaining data from IOCTL Parameters
+	 */
+	/* Someday will be: SAS_ADDR_TO_BUS((*((u64*)pPassThruBuffer->Parameters.bDestinationSASAddress))); */
+	pSataRequest->bus = 0;
+	/* Someday will be: SAS_ADDR_TO_TARGET((*((u64*)pPassThruBuffer->Parameters.bDestinationSASAddress))); */
+	pSataRequest->targetId = pPassThruBuffer->Parameters.bPhyIdentifier;
+	/* Someday will be: SAS_ADDR_TO_LUN((*((u64*)pPassThruBuffer->Parameters.bDestinationSASAddress))); */
+	pSataRequest->lun = 0;
+	pSataRequest->dataTransferLength
+	  = pPassThruBuffer->Parameters.uDataLength;
+
+	/*
+	 * SATA Task Set Register Listing
+	 */
+	pSataRequest->command = pPassThruBuffer->Parameters.bCommandFIS[2];
+	pSataRequest->features = pPassThruBuffer->Parameters.bCommandFIS[3];
+	pSataRequest->sectorNumber = pPassThruBuffer->Parameters.bCommandFIS[4];
+	pSataRequest->cylinderLow = pPassThruBuffer->Parameters.bCommandFIS[5];
+	pSataRequest->cylinderHigh = pPassThruBuffer->Parameters.bCommandFIS[6];
+	pSataRequest->deviceHead = pPassThruBuffer->Parameters.bCommandFIS[7];
+	pSataRequest->sectorNumber_Exp
+	  = pPassThruBuffer->Parameters.bCommandFIS[8];
+	pSataRequest->cylinderLow_Exp
+	  = pPassThruBuffer->Parameters.bCommandFIS[9];
+	pSataRequest->cylinderHigh_Exp
+	  = pPassThruBuffer->Parameters.bCommandFIS[10];
+	pSataRequest->features_Exp
+	  = pPassThruBuffer->Parameters.bCommandFIS[11];
+	pSataRequest->sectorCount
+	  = pPassThruBuffer->Parameters.bCommandFIS[12];
+	pSataRequest->sectorCount_Exp
+	  = pPassThruBuffer->Parameters.bCommandFIS[13];
+	pSataRequest->control = pPassThruBuffer->Parameters.bCommandFIS[15];
+
+	/*
+	 * Build SGMAP
+	 */
+	if (pPassThruBuffer->Parameters.uDataLength) {
+
+		pDataPointer = &pPassThruBuffer->bDataBuffer[0];
+		bytesLeft = pPassThruBuffer->Parameters.uDataLength;
+
+		/*
+		 * Get physical address and length of
+		 * contiguous physical buffer
+		 */
+		p = pci_alloc_consistent(dev->pdev, bytesLeft, &addr);
+		if(p == 0) {
+			aac_fib_free(fibptr);
+			pPassThruBuffer->IoctlHeader.ReturnCode
+			  = CSMI_SAS_STATUS_FAILED;
+			Rtnval = aac_CloseCSMIBuffer(dev, arg,
+			  (PIOCTL_HEADER)pPassThruBuffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+			fwprintf((dev, HBA_FLAGS_DBG_FUNCTION_EXIT_B
+			   | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+			  "aac_CSMISTPPassThru: Exit, ReturnValue=%d,"
+			  " ReturnCode=CSMI_SAS_STATUS_FAILED",
+			  Rtnval));
+#endif
+			return Rtnval;
+		}
+		memcpy(p, pDataPointer, bytesLeft);
+
+		pSgMap->sg[0].addr[1] = cpu_to_le32((u32)((u64)addr>>32));
+		pSgMap->sg[0].addr[0] = cpu_to_le32((u32)(addr & 0xffffffff));
+
+		/*
+		 * Store the length for this entry
+		 */
+		pSgMap->sg[0].count = bytesLeft;
+
+		/*
+		 * Store final count of entries
+		 */
+		pSgMap->count = 1;
+
+	} else
+		pSataRequest->srbFlags = HOSTSRB_FLAGS_NO_DATA_TRANSFER;
+
+	/*
+	 * Send FIB
+	 */
+	status = aac_fib_send(SataPortCommandU64, fibptr, sizeof(*pSataRequest),
+	  FsaNormal, 1, 1, NULL, NULL);
+
+	aac_fib_complete(fibptr);
+
+	if (status < 0) {
+		if (pPassThruBuffer->Parameters.uDataLength)
+			pci_free_consistent(dev->pdev, bytesLeft,p, addr);
+		aac_fib_free(fibptr);
+		pPassThruBuffer->IoctlHeader.ReturnCode
+		  = CSMI_SAS_STATUS_FAILED;
+		Rtnval = aac_CloseCSMIBuffer(dev, arg,
+		  (PIOCTL_HEADER)pPassThruBuffer);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev,
+		  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_CSMIGetSATASignature: Exit, ReturnValue=%d,"
+		  " ReturnCode=CSMI_SAS_STATUS_FAILED",
+		  Rtnval));
+#endif
+		return Rtnval;
+	}
+
+	if (pPassThruBuffer->Parameters.uDataLength) {
+		memcpy(pDataPointer, p, bytesLeft);
+		pci_free_consistent(dev->pdev, bytesLeft,p, addr);
+	}
+
+	/*
+	 * pull response data and respond to IOCTL
+	 */
+
+	/*
+	 * Return relevant data
+	 */
+	pPassThruBuffer->Status.bConnectionStatus = CSMI_SAS_OPEN_ACCEPT;
+	pPassThruBuffer->Status.bStatusFIS[2] = pSataResponse->statusReg;
+
+	/*
+	 * pPassThruBuffer->Status.uSCR = ??;
+	 */
+	pPassThruBuffer->Status.uDataBytes = pSataResponse->dataTransferLength;
+
+	aac_fib_free(fibptr);
+
+	/*
+	 * Indicate success for this IOCTL
+	 */
+	pPassThruBuffer->IoctlHeader.ReturnCode = CSMI_SAS_STATUS_SUCCESS;
+	Rtnval = aac_CloseCSMIBuffer(dev, arg, (PIOCTL_HEADER)pPassThruBuffer);
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_CSMISTPPassThru: Exit, ReturnValue=%d,"
+	  " ReturnCode=CSMI_SAS_STATUS_SUCCESS",
+	  Rtnval));
+#endif
+
+	return Rtnval;
+
+}
+
+
+/*
+ *
+ * Routine Description:
+ *
+ *   This routine is the main entry point for all CSMI function calls.
+ *
+ */
+int aac_csmi_ioctl(
+	struct aac_dev * dev,
+	int cmd,
+	void __user * arg)
+{
+	int returnStatus = -ENOTTY;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_ENTRY_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_HandleCSMI: Enter, (scsi%d) ControlCode = %x",
+	  dev->scsi_host_ptr->host_no, cmd));
+#endif
+
+	/*
+	 * Handle the supported CSMI commands
+	 */
+	switch (cmd) {
+	case CC_CSMI_SAS_GET_DRIVER_INFO:
+		returnStatus = aac_CSMIGetDriverInfo(dev, arg);
+		break;
+
+	case CC_CSMI_SAS_GET_CNTLR_CONFIG:
+		returnStatus = aac_CSMIGetControllerConfig(dev, arg);
+		break;
+
+	case CC_CSMI_SAS_GET_CNTLR_STATUS:
+		returnStatus = aac_CSMIGetControllerStatus(dev, arg);
+		break;
+
+	case CC_CSMI_SAS_GET_RAID_INFO:
+		returnStatus = aac_CSMIGetRAIDInfo(dev, arg);
+		break;
+
+	case CC_CSMI_SAS_GET_PHY_INFO:
+		returnStatus = aac_CSMIGetPhyInfo(dev, arg);
+		break;
+
+	case CC_CSMI_SAS_SET_PHY_INFO:
+		returnStatus = aac_CSMISetPhyInfo(dev, arg);
+		break;
+
+	case CC_CSMI_SAS_GET_SATA_SIGNATURE:
+		returnStatus = aac_CSMIGetSATASignature(dev, arg);
+		break;
+
+	case CC_CSMI_SAS_GET_RAID_CONFIG:
+		returnStatus = aac_CSMIGetRAIDConfig(dev, arg);
+		break;
+
+	case CC_CSMI_SAS_STP_PASSTHRU:
+		returnStatus = aac_CSMISTPPassThru(dev, arg);
+		break;
+
+	/*
+	 * Unsupported CSMI control code
+	 */
+	case CC_CSMI_SAS_FIRMWARE_DOWNLOAD:
+	case CC_CSMI_SAS_GET_SCSI_ADDRESS:
+	case CC_CSMI_SAS_GET_DEVICE_ADDRESS:
+	case CC_CSMI_SAS_SMP_PASSTHRU:
+	case CC_CSMI_SAS_SSP_PASSTHRU:
+	case CC_CSMI_SAS_GET_LINK_ERRORS:
+	case CC_CSMI_SAS_TASK_MANAGEMENT:
+	case CC_CSMI_SAS_GET_CONNECTOR_INFO:
+	case CC_CSMI_SAS_PHY_CONTROL:
+	{
+		PIOCTL_HEADER pHeader;
+
+		/*
+		 * Verify buffer size. If buffer is too small, the error
+		 * status will be set for pHeader->ReturnCode in
+		 * aac_VerifyCSMIBuffer.
+		 */
+		if (!(returnStatus = aac_VerifyCSMIBuffer(&dev, arg,
+		  sizeof(PIOCTL_HEADER), &pHeader))) {
+			pHeader->ReturnCode = CSMI_SAS_STATUS_BAD_CNTL_CODE;
+			if (!(returnStatus = aac_CloseCSMIBuffer(dev, arg,
+			  pHeader)))
+				returnStatus = -EINVAL;
+		}
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		fwprintf((dev, HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+		  "aac_HandleCSMI: Unsupported ControlCode=%x",
+		  cmd));
+#endif
+		break;
+	}
+	}
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	fwprintf((dev,
+	  HBA_FLAGS_DBG_FUNCTION_EXIT_B | HBA_FLAGS_DBG_CSMI_COMMANDS_B,
+	  "aac_HandleCSMI: Exit, ReturnCode=%d", returnStatus));
+#endif
+
+	return(returnStatus);
+}
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11))
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) ? defined(__x86_64__) : defined(CONFIG_COMPAT))
+void aac_csmi_register_ioctl32_conversion(void)
+{
+	register_ioctl32_conversion(CC_CSMI_SAS_GET_DRIVER_INFO,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_GET_CNTLR_CONFIG,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_GET_CNTLR_STATUS,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_GET_RAID_INFO,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_GET_PHY_INFO,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_SET_PHY_INFO,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_GET_SATA_SIGNATURE,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_GET_RAID_CONFIG,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_STP_PASSTHRU,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_FIRMWARE_DOWNLOAD,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_GET_SCSI_ADDRESS,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_GET_DEVICE_ADDRESS,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_SMP_PASSTHRU,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_SSP_PASSTHRU,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_GET_LINK_ERRORS,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_TASK_MANAGEMENT,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_GET_CONNECTOR_INFO,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+	register_ioctl32_conversion(CC_CSMI_SAS_PHY_CONTROL,
+	  (int(*)(unsigned int,unsigned int,unsigned long,struct file*))sys_ioctl);
+}
+
+void aac_csmi_unregister_ioctl32_conversion(void)
+{
+	unregister_ioctl32_conversion(CC_CSMI_SAS_GET_DRIVER_INFO);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_GET_CNTLR_CONFIG);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_GET_CNTLR_STATUS);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_GET_RAID_INFO);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_GET_PHY_INFO);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_SET_PHY_INFO);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_GET_SATA_SIGNATURE);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_GET_RAID_CONFIG);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_STP_PASSTHRU);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_FIRMWARE_DOWNLOAD);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_GET_SCSI_ADDRESS);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_GET_DEVICE_ADDRESS);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_SMP_PASSTHRU);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_SSP_PASSTHRU);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_GET_LINK_ERRORS);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_TASK_MANAGEMENT);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_GET_CONNECTOR_INFO);
+	unregister_ioctl32_conversion(CC_CSMI_SAS_PHY_CONTROL);
+}
+#endif
+#endif
+
+#endif
diff --git a/drivers/scsi/aacraid/csmi.h b/drivers/scsi/aacraid/csmi.h
new file mode 100644
index 0000000..eb09745
--- /dev/null
+++ b/drivers/scsi/aacraid/csmi.h
@@ -0,0 +1,402 @@
+/*
+ *	Adaptec AAC series RAID controller driver
+ *	(c) Copyright 2004-2007 Adaptec, Inc
+ *
+ * Copyright (c) 2004-2007 Adaptec, Inc. (aacraid@adaptec.com)
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; see the file COPYING.  If not, write to
+ * the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Module Name:
+ *   csmi.h
+ *
+ * Abstract: All CSMI IOCTL definitions are here
+ */
+
+/*
+ *	This file is based on the following CSMI revision
+ */
+#define	CSMI_MAJOR_REVISION	0
+#define	CSMI_MINOR_REVISION	82
+
+/*
+ *	IoctlHeader.ReturnCode
+ */
+#define	CSMI_SAS_STATUS_SUCCESS			0
+#define	CSMI_SAS_STATUS_FAILED			1
+#define	CSMI_SAS_STATUS_BAD_CNTL_CODE		2
+#define	CSMI_SAS_STATUS_INVALID_PARAMETER	3
+#define CSMI_SAS_PHY_INFO_NOT_CHANGEABLE	2000
+#define CSMI_SAS_NO_SATA_DEVICE			2009
+
+/*
+ *	Status.uStatus
+ */
+#define	CSMI_SAS_CNTLR_STATUS_GOOD	1
+#define	CSMI_SAS_CNTLR_STATUS_FAILED	2
+#define CSMI_SAS_CNTLR_STATUS_OFFLINE	3
+
+/*
+ *	Status.uOfflineReason
+ */
+#define CSMI_SAS_OFFLINE_REASON_NO_REASON	0
+
+/*
+ *	IoctlHeader.ControlCode
+ */
+#define CSMI_SAS_RAID_SET_OUT_OF_RANGE	1000
+
+/*
+ *	Parameters.uFlags
+ */
+#define	CSMI_SAS_STP_READ		0x00000001
+#define	CSMI_SAS_STP_DMA		0x00000020
+#define	CSMI_SAS_STP_DMA_QUEUED		0x00000080
+#define	CSMI_SAS_STP_RESET_DEVICE	0x00000200	
+
+/*
+ *	Status.bConnectionStatus
+ */
+#define	CSMI_SAS_OPEN_ACCEPT		0
+
+/*
+ *	Configuration.bIoBusType
+ */
+#define	CSMI_SAS_BUS_TYPE_PCI		3
+
+/*
+ *	Configuration.bControllerClass
+ */
+#define	CSMI_SAS_CNTLR_CLASS_HBA	5
+
+/*
+ *	Configuration.uControllerFlags
+ */
+#define	CSMI_SAS_CNTLR_SAS_HBA		0x00000001
+#define	CSMI_SAS_CNTLR_SAS_RAID		0x00000002
+#define	CSMI_SAS_CNTLR_SATA_HBA		0x00000004
+#define	CSMI_SAS_CNTLR_SATA_RAID	0x00000008
+
+/*
+ *	Configuration.usSlotNumber
+ */
+#define SLOT_NUMBER_UNKNOWN		0xFFFF
+
+/*
+ *	CSMI ioctl commands
+ */
+/* #define CSMI_ALL_SIGNATURE		"CSMIALL" */
+#define	CC_CSMI_SAS_GET_DRIVER_INFO	0xCC770001
+#define	CC_CSMI_SAS_GET_CNTLR_CONFIG	0xCC770002
+#define	CC_CSMI_SAS_GET_CNTLR_STATUS	0xCC770003
+#define	CC_CSMI_SAS_FIRMWARE_DOWNLOAD	0xCC770004
+
+/* #define CSMI_RAID_SIGNATURE		"CSMIARY" */
+#define	CC_CSMI_SAS_GET_RAID_INFO	0xCC77000A
+#define	CC_CSMI_SAS_GET_RAID_CONFIG	0xCC77000B
+
+/* #define CSMI_SAS_SIGNATURE		"CSMISAS" */
+#define	CC_CSMI_SAS_GET_PHY_INFO	0xCC770014
+#define	CC_CSMI_SAS_SET_PHY_INFO	0xCC770015
+#define	CC_CSMI_SAS_GET_LINK_ERRORS	0xCC770016
+#define	CC_CSMI_SAS_SSP_PASSTHRU	0xCC770017
+#define	CC_CSMI_SAS_SMP_PASSTHRU	0xCC770018
+#define	CC_CSMI_SAS_STP_PASSTHRU	0xCC770019
+#define CC_CSMI_SAS_GET_SATA_SIGNATURE	0xCC770020
+#define	CC_CSMI_SAS_GET_SCSI_ADDRESS	0xCC770021
+#define	CC_CSMI_SAS_GET_DEVICE_ADDRESS	0xCC770022
+#define	CC_CSMI_SAS_TASK_MANAGEMENT	0xCC770023
+#define	CC_CSMI_SAS_GET_CONNECTOR_INFO	0xCC770024
+
+/* #define CSMI_PHY_SIGNATURE		"CSMIPHY" */
+#define CC_CSMI_SAS_PHY_CONTROL		0xCC77003C
+
+typedef struct {
+	u32	IOControllerNumber;
+	u32	Length;
+	u32	ReturnCode;
+	u32	Timeout;
+	u16	Direction;
+#if (defined(CSMI_8_BYTE_ALIGNED))
+	u16	Reserved[3];
+#endif
+} IOCTL_HEADER;
+typedef IOCTL_HEADER *PIOCTL_HEADER;
+
+/* CC_CSMI_SAS_GET_DRIVER_INFO */
+
+typedef struct {
+	u8	szName[81];
+	u8	szDescription[81];
+	u16	usMajorRevision;
+	u16	usMinorRevision;
+	u16	usBuildRevision;
+	u16	usReleaseRevision;
+	u16	usCSMIMajorRevision;
+	u16	usCSMIMinorRevision;
+#if (defined(CSMI_8_BYTE_ALIGNED))
+	u16	usReserved;
+#endif
+} CSMI_SAS_DRIVER_INFO;
+
+typedef struct {
+	IOCTL_HEADER	IoctlHeader;
+	CSMI_SAS_DRIVER_INFO	Information;
+} CSMI_SAS_DRIVER_INFO_BUFFER;
+typedef CSMI_SAS_DRIVER_INFO_BUFFER * PCSMI_SAS_DRIVER_INFO_BUFFER;
+
+/* CC_CSMI_SAS_GET_CNTLR_CONFIG */
+
+typedef struct {
+	u8	bBusNumber;
+	u8	bDeviceNumber;
+	u8	bFunctionNumber;
+	u8	bReserved;
+} CSMI_SAS_PCI_BUS_ADDRESS;
+
+typedef union {
+	CSMI_SAS_PCI_BUS_ADDRESS	PciAddress;
+	u8	bReserved[32];
+} CSMI_SAS_IO_BUS_ADDRESS;
+
+typedef struct {
+	u32	uBaseIoAddress;
+#if (defined(CSMI_8_BYTE_ALIGNED))
+	u32	uReserved;
+#endif
+	struct {
+		u32	uLowPart;
+		u32	uHighPart;
+	} BaseMemoryAddress;
+	u32	uBoardID;
+	u16	usSlotNumber;
+	u8	bControllerClass;
+	u8	bIoBusType;
+	CSMI_SAS_IO_BUS_ADDRESS	BusAddress;
+	u8	szSerialNumber[81];
+#if (defined(CSMI_8_BYTE_ALIGNED))
+	u8	bReserve;
+#endif
+	u16	usMajorRevision;
+	u16	usMinorRevision;
+	u16	usBuildRevision;
+	u16	usReleaseRevision;
+	u16	usBIOSMajorRevision;
+	u16	usBIOSMinorRevision;
+	u16	usBIOSBuildRevision;
+	u16	usBIOSReleaseRevision;
+#if (defined(CSMI_8_BYTE_ALIGNED))
+	u16	usReserved;
+#endif
+	u32	uControllerFlags;
+	u16	usRromMajorRevision;
+	u16	usRromMinorRevision;
+	u16	usRromBuildRevision;
+	u16	usRromReleaseRevision;
+	u16	usRromBIOSMajorRevision;
+	u16	usRromBIOSMinorRevision;
+	u16	usRromBIOSBuildRevision;
+	u16	usRromBIOSReleaseRevision;
+	u8	bReserved[7];
+#if (defined(CSMI_8_BYTE_ALIGNED))
+	u8	bReserved1;
+#endif
+} CSMI_SAS_CNTLR_CONFIG;
+
+typedef struct {
+	IOCTL_HEADER	IoctlHeader;
+	CSMI_SAS_CNTLR_CONFIG	Configuration;
+} CSMI_SAS_CNTLR_CONFIG_BUFFER;
+typedef CSMI_SAS_CNTLR_CONFIG_BUFFER * PCSMI_SAS_CNTLR_CONFIG_BUFFER;
+
+/* CC_CSMI_SAS_GET_CNTLR_STATUS */
+
+typedef struct {
+	u32	uStatus;
+	u32	uOfflineReason;
+	u8	bReserved[28];
+#if (defined(CSMI_8_BYTE_ALIGNED))
+	u8	bReserved[4];
+#endif
+} CSMI_SAS_CNTLR_STATUS;
+
+typedef struct {
+	IOCTL_HEADER	IoctlHeader;
+	CSMI_SAS_CNTLR_STATUS	Status;
+} CSMI_SAS_CNTLR_STATUS_BUFFER;
+typedef CSMI_SAS_CNTLR_STATUS_BUFFER * PCSMI_SAS_CNTLR_STATUS_BUFFER;
+
+/* CC_CSMI_SAS_GET_SATA_SIGNATURE */
+
+typedef struct {
+	u8	pPhyIdentifier;
+	u8	bReserved[3];
+	u8	bSignatureFIS[20];
+} CSMI_SAS_SATA_SIGNATURE;
+
+typedef struct {
+	IOCTL_HEADER IoctlHeader;
+	CSMI_SAS_SATA_SIGNATURE Signature;
+} CSMI_SAS_SATA_SIGNATURE_BUFFER;
+typedef CSMI_SAS_SATA_SIGNATURE_BUFFER * PCSMI_SAS_SATA_SIGNATURE_BUFFER;
+
+/* CC_CSMI_SAS_GET_RAID_INFO */
+
+typedef struct {
+	u32	uNumRaidSets;
+	u32	uMaxDrivesPerSet;
+	u8	bReserved[92];
+#if (defined(CSMI_8_BYTE_ALIGNED))
+	u8	bReserved1[4];
+#endif
+} CSMI_SAS_RAID_INFO;
+
+typedef struct {
+	IOCTL_HEADER	IoctlHeader;
+	CSMI_SAS_RAID_INFO	Information;
+} CSMI_SAS_RAID_INFO_BUFFER;
+typedef CSMI_SAS_RAID_INFO_BUFFER * PCSMI_SAS_RAID_INFO_BUFFER;
+
+/* CC_CSMI_SAS_GET_RAID_CONFIG */
+
+typedef struct {
+	u8	bModel[40];
+	u8	bFirmware[8];
+	u8	bSerialNumber[40];
+	u8	bSASAddress[8];
+	u8	bSASLun[8];
+	u8	bDriveStatus;
+	u8	bDriveUsage;
+	u8	bReserved[30];
+} CSMI_SAS_RAID_DRIVES;
+
+typedef struct {
+	u32	uRaidSetIndex;
+	u32	uCapacity;
+	u32	uStripeSize;
+	u8	bRaidType;
+	u8	bStatus;
+	u8	bInformation;
+	u8	bDriveCount;
+	u8	bReserved[20];
+#if (defined(CSMI_8_BYTE_ALIGNED))
+	u8	bReserved1[4];
+#endif
+	CSMI_SAS_RAID_DRIVES	Drives[1];
+} CSMI_SAS_RAID_CONFIG;
+
+typedef struct {
+	IOCTL_HEADER IoctlHeader;
+	CSMI_SAS_RAID_CONFIG Configuration;
+} CSMI_SAS_RAID_CONFIG_BUFFER;
+typedef CSMI_SAS_RAID_CONFIG_BUFFER * PCSMI_SAS_RAID_CONFIG_BUFFER;
+
+/* CC_CSMI_SAS_GET_PHY_INFO */
+
+typedef struct {
+	u8	bDeviceType;
+	u8	bRestricted;
+	u8	bInitiatorPortProtocol;
+	u8	bTargetPortProtocol;
+	u8	bRestricted2[8];
+	u8	bSASAddress[8];
+	u8	bPhyIdentifier;
+	u8	bSignalClass;
+	u8	bReserved[6];
+#if (defined(CSMI_8_BYTE_ALIGNED))
+	u8	bReserved1[4];
+#endif
+} CSMI_SAS_IDENTIFY;
+
+typedef struct {
+	CSMI_SAS_IDENTIFY	Identify;
+	u8	bPortIdentifier;
+	u8	bNegotiatedLinkRate;
+	u8	bMinimumLinkRate;
+	u8	bMaximumLinkRate;
+	u8	bPhyChangeCount;
+	u8	bAutoDiscover;
+	u8	bReserved[2];
+	CSMI_SAS_IDENTIFY	Attached;
+} CSMI_SAS_PHY_ENTITY;
+
+typedef struct {
+	u8	bNumberofPhys;
+	u8	bReserved[3];
+#if (defined(CSMI_8_BYTE_ALIGNED))
+	u8	bReserved1[4];
+#endif
+	CSMI_SAS_PHY_ENTITY Phy[32];
+} CSMI_SAS_PHY_INFO;
+
+typedef struct {
+	IOCTL_HEADER IoctlHeader;
+	CSMI_SAS_PHY_INFO Information;
+} CSMI_SAS_PHY_INFO_BUFFER;
+typedef CSMI_SAS_PHY_INFO_BUFFER * PCSMI_SAS_PHY_INFO_BUFFER;
+
+/* CC_CSMI_SAS_SET_PHY_INFO */
+
+typedef struct {
+	u8	bPhyIdentifier;
+	u8	bNegotiatedLinkRate;
+	u8	bProgrammedMinimumLinkRate;
+	u8	bProgrammedMaximumLinkRate;
+	u8	bSignalClass;
+	u8	bReserved[3];
+} CSMI_SAS_SET_PHY_INFO;
+
+typedef struct {
+	IOCTL_HEADER IoctlHeader;
+	CSMI_SAS_SET_PHY_INFO Information;
+} CSMI_SAS_SET_PHY_INFO_BUFFER;
+typedef CSMI_SAS_SET_PHY_INFO_BUFFER * PCSMI_SAS_SET_PHY_INFO_BUFFER;
+
+/* CC_CSMI_SAS_STP_PASSTHRU */
+
+typedef struct {
+	u8	bPhyIdentifier;
+	u8	bPortIdentifier;
+	u8	bConnectionRate;
+	u8	bReserved;
+	u8	bDestinationSASAddress[8];
+	u8	bReserved2[4];
+	u8	bCommandFIS[20];
+	u32	uFlags;
+	u32	uDataLength;
+#if (defined(CSMI_8_BYTE_ALIGNED))
+	u32	uReserved;
+#endif
+} CSMI_SAS_STP_PASSTHRU;
+
+typedef struct {
+	u8	bConnectionStatus;
+	u8	bReserved[3];
+	u8	bStatusFIS[20];
+	u32	uSCR[16];
+	u32	uDataBytes;
+#if (defined(CSMI_8_BYTE_ALIGNED))
+	u32	uReserved;
+#endif
+} CSMI_SAS_STP_PASSTHRU_STATUS;
+
+typedef struct {
+	IOCTL_HEADER	IoctlHeader;
+	CSMI_SAS_STP_PASSTHRU	Parameters;
+	CSMI_SAS_STP_PASSTHRU_STATUS	Status;
+	u8	bDataBuffer[1];
+} CSMI_SAS_STP_PASSTHRU_BUFFER;
+typedef CSMI_SAS_STP_PASSTHRU_BUFFER * PCSMI_SAS_STP_PASSTHRU_BUFFER;
+
+int aac_csmi_ioctl(struct aac_dev *, int, void __user *);
diff --git a/drivers/scsi/aacraid/dpcsup.c b/drivers/scsi/aacraid/dpcsup.c
index d81b281..e81fa28 100644
--- a/drivers/scsi/aacraid/dpcsup.c
+++ b/drivers/scsi/aacraid/dpcsup.c
@@ -1,12 +1,11 @@
 /*
  *	Adaptec AAC series RAID controller driver
- *	(c) Copyright 2001 Red Hat Inc.
+ *	(c) Copyright 2001 Red Hat Inc.	<alan@redhat.com>
  *
  * based on the old aacraid driver that is..
  * Adaptec aacraid device driver for Linux.
  *
- * Copyright (c) 2000-2010 Adaptec, Inc.
- *               2010 PMC-Sierra, Inc. (aacraid@pmc-sierra.com)
+ * Copyright (c) 2000-2007 Adaptec, Inc. (aacraid@adaptec.com)
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -33,13 +32,33 @@
 #include <linux/kernel.h>
 #include <linux/init.h>
 #include <linux/types.h>
+//#include <linux/sched.h>
+//#include <linux/pci.h>
 #include <linux/spinlock.h>
 #include <linux/slab.h>
+#include <linux/version.h>
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,2))
 #include <linux/completion.h>
+#endif
 #include <linux/blkdev.h>
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+#include <asm/semaphore.h>
+#else
 #include <linux/semaphore.h>
+#endif
 
 #include "aacraid.h"
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#include "fwdebug.h"
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+#include <scsi/scsi_host.h>
+#else
+#include "scsi.h"
+#include "hosts.h"
+#endif
+#endif
 
 /**
  *	aac_response_normal	-	Handle command replies
@@ -60,7 +79,7 @@ unsigned int aac_response_normal(struct aac_queue * q)
 	int consumed = 0;
 	unsigned long flags, mflags;
 
-	spin_lock_irqsave(q->lock, flags);
+	spin_lock_irqsave(q->lock, flags);	
 	/*
 	 *	Keep pulling response QEs off the response queue and waking
 	 *	up the waiters until there are no more QEs. We then return
@@ -84,9 +103,13 @@ unsigned int aac_response_normal(struct aac_queue * q)
 		 *	continue. The caller has already been notified that
 		 *	the fib timed out.
 		 */
-		dev->queues->queue[AdapNormCmdQueue].numpending--;
+		atomic_dec(&dev->queues->queue[AdapNormCmdQueue].numpending);
 
 		if (unlikely(fib->flags & FIB_CONTEXT_FLAG_TIMED_OUT)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+			printk(KERN_WARNING "aacraid: FIB timeout (%x).\n", fib->flags);
+			printk(KERN_DEBUG"aacraid: hwfib=%p fib index=%i fib=%p\n",hwfib, hwfib->header.Handle,fib);
+#endif
 			spin_unlock_irqrestore(q->lock, flags);
 			aac_fib_complete(fib);
 			aac_fib_free(fib);
@@ -122,12 +145,16 @@ unsigned int aac_response_normal(struct aac_queue * q)
 			 *	NOTE:  we cannot touch the fib after this
 			 *	    call, because it may have been deallocated.
 			 */
-			fib->flags &= FIB_CONTEXT_FLAG_FASTRESP;
 			fib->callback(fib->callback_data, fib);
 		} else {
 			unsigned long flagv;
+			int complete = 0;
 			spin_lock_irqsave(&fib->event_lock, flagv);
-			if (!fib->done) {
+			if (fib->done == 2) {
+				dprintk((KERN_INFO "complete fib with pending wait status\n"));
+				fib->done = 1;
+				complete = 1;
+			} else {
 				fib->done = 1;
 				up(&fib->event_wait);
 			}
@@ -138,20 +165,47 @@ unsigned int aac_response_normal(struct aac_queue * q)
 			spin_unlock_irqrestore(&dev->manage_lock, mflags);
 
 			FIB_COUNTER_INCREMENT(aac_config.NormalRecved);
-			if (fib->done == 2) {
-				spin_lock_irqsave(&fib->event_lock, flagv);
-				fib->done = 0;
-				spin_unlock_irqrestore(&fib->event_lock, flagv);
+			if (complete) {
 				aac_fib_complete(fib);
 				aac_fib_free(fib);
 			}
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x8)
+			if ((hwfib->header.XferState &
+			  cpu_to_le32(ResponseExpected)) &&
+			  !fib->callback && !fib->callback_data &&
+			  !list_empty(&dev->entry)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+				printk(KERN_INFO
+				  "aac_send_fib(%u,%p,%u,?,?,1,NULL,NULL) wakeup done=%d\n",
+				  le16_to_cpu(hwfib->header.Command),
+				  fib, (unsigned)(
+				  le16_to_cpu(hwfib->header.Size) -
+				  sizeof(struct aac_fibhdr)), fib->done);
+#endif
+				fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+				  "aac_send_fib(%u,%p,%u,?,?,1,NULL,NULL) wakeup done=%d",
+				  le16_to_cpu(hwfib->header.Command),
+				  fib, (unsigned)(
+				  le16_to_cpu(hwfib->header.Size) -
+				  sizeof(struct aac_fibhdr)), fib->done));
+			}
+#endif
+#endif
 		}
 		consumed++;
 		spin_lock_irqsave(q->lock, flags);
 	}
 
 	if (consumed > aac_config.peak_fibs)
+#if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+	{
+#endif
 		aac_config.peak_fibs = consumed;
+#if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+		printk("peak_fibs=%d\n", aac_config.peak_fibs);
+	}
+#endif
 	if (consumed == 0) 
 		aac_config.zero_fibs++;
 
@@ -191,6 +245,10 @@ unsigned int aac_command_normal(struct aac_queue *q)
 		struct fib *fib = &fibctx;
 		
 		index = le32_to_cpu(entry->addr) / sizeof(struct hw_fib);
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB))
+		printk(KERN_INFO "index=%d or %d\n", index,
+		  le32_to_cpu(entry->addr / sizeof(struct hw_fib)));
+#endif
 		hw_fib = &dev->aif_base_va[index];
 		
 		/*
@@ -214,7 +272,11 @@ unsigned int aac_command_normal(struct aac_queue *q)
 		if (dev->aif_thread && fib != &fibctx) {
 		        list_add_tail(&fib->fiblink, &q->cmdq);
 	 	        aac_consumer_free(dev, q, HostNormCmdQueue);
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__VMKLNX__))
+			up(&q->cmdready);
+#else
 		        wake_up_interruptible(&q->cmdready);
+#endif
 		} else {
 	 	        aac_consumer_free(dev, q, HostNormCmdQueue);
 			spin_unlock_irqrestore(q->lock, flags);
@@ -230,7 +292,8 @@ unsigned int aac_command_normal(struct aac_queue *q)
 	return 0;
 }
 
-/*
+
+/**
  *
  * aac_aif_callback
  * @context: the context set in the fib - here it is scsi cmd
@@ -242,7 +305,7 @@ unsigned int aac_command_normal(struct aac_queue *q)
 
 static void aac_aif_callback(void *context, struct fib * fibptr)
 {
-	struct fib *fibctx;
+	struct fib * fibctx;
 	struct aac_dev *dev;
 	struct aac_aifcmd *cmd;
 	int status;
@@ -251,8 +314,8 @@ static void aac_aif_callback(void *context, struct fib * fibptr)
 	BUG_ON(fibptr == NULL);
 	dev = fibptr->dev;
 
-	if (fibptr->hw_fib_va->header.XferState &
-	    cpu_to_le32(NoMoreAifDataAvailable)) {
+	if (fibptr->hw_fib_va->header.XferState & 
+		cpu_to_le32(NoMoreAifDataAvailable)) {
 		aac_fib_complete(fibptr);
 		aac_fib_free(fibptr);
 		return;
@@ -272,7 +335,6 @@ static void aac_aif_callback(void *context, struct fib * fibptr)
 		(fib_callback)aac_aif_callback, fibctx);
 }
 
-
 /**
  *	aac_intr_normal	-	Handle command replies
  *	@dev: Device
@@ -282,12 +344,13 @@ static void aac_aif_callback(void *context, struct fib * fibptr)
  *	know there is a response on our normal priority queue. We will pull off
  *	all QE there are and wake up all the waiters before exiting.
  */
-unsigned int aac_intr_normal(struct aac_dev *dev, u32 index,
-			int isAif, int isFastResponse, struct hw_fib *aif_fib)
+
+unsigned int aac_intr_normal(struct aac_dev * dev, u32 index, int isAif,
+	int isFastResponse, struct hw_fib *aif_fib)
 {
 	unsigned long mflags;
 	dprintk((KERN_INFO "aac_intr_normal(%p,%x)\n", dev, index));
-	if (isAif == 1) {	/* AIF - common */
+	if (isAif == 1) {		/* AIF - common */
 		struct hw_fib * hw_fib;
 		struct fib * fib;
 		struct aac_queue *q = &dev->queues->queue[HostNormCmdQueue];
@@ -299,19 +362,32 @@ unsigned int aac_intr_normal(struct aac_dev *dev, u32 index,
 		 * manage the linked lists.
 		 */
 		if ((!dev->aif_thread)
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)) && !defined(HAS_KZALLOC))
+		 || (!(fib = kmalloc(sizeof(struct fib),GFP_ATOMIC))))
+#else
 		 || (!(fib = kzalloc(sizeof(struct fib),GFP_ATOMIC))))
+#endif
 			return 1;
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)) && !defined(HAS_KZALLOC))
+		if (!(hw_fib = kmalloc(sizeof(struct hw_fib),GFP_ATOMIC))) {
+#else
 		if (!(hw_fib = kzalloc(sizeof(struct hw_fib),GFP_ATOMIC))) {
+#endif
 			kfree (fib);
 			return 1;
 		}
-		if (aif_fib != NULL) {
-			memcpy(hw_fib, aif_fib, sizeof(struct hw_fib));
-		} else {
-			memcpy(hw_fib,
-				(struct hw_fib *)(((uintptr_t)(dev->regs.sa)) +
-				index), sizeof(struct hw_fib));
-		}
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)) && !defined(HAS_KZALLOC))
+		memset(hw_fib, 0, sizeof(struct hw_fib));
+#endif
+        if (aif_fib != NULL) {
+            memcpy(hw_fib, aif_fib, sizeof(struct hw_fib));
+        } else {
+            memcpy(hw_fib, (struct hw_fib *)(((uintptr_t)(dev->regs.sa)) +
+                index), sizeof(struct hw_fib));
+        }
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)) && !defined(HAS_KZALLOC))
+		memset(fib, 0, sizeof(struct fib));
+#endif
 		INIT_LIST_HEAD(&fib->fiblink);
 		fib->type = FSAFS_NTC_FIB_CONTEXT;
 		fib->size = sizeof(struct fib);
@@ -321,11 +397,15 @@ unsigned int aac_intr_normal(struct aac_dev *dev, u32 index,
 	
 		spin_lock_irqsave(q->lock, flags);
 		list_add_tail(&fib->fiblink, &q->cmdq);
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__VMKLNX__))
+		up(&q->cmdready);
+#else
 	        wake_up_interruptible(&q->cmdready);
+#endif
 		spin_unlock_irqrestore(q->lock, flags);
 		return 1;
-	} else if (isAif == 2) {	/* AIF - new (SRC) */
-		struct fib *fibctx;
+	} else if (isAif == 2) {		/* AIF - new (SRC) */
+		struct fib * fibctx;
 		struct aac_aifcmd *cmd;
 
 		fibctx = aac_fib_alloc(dev);
@@ -343,9 +423,13 @@ unsigned int aac_intr_normal(struct aac_dev *dev, u32 index,
 			0, 1,
 			(fib_callback)aac_aif_callback, fibctx);
 	} else {
-		struct fib *fib = &dev->fibs[index];
-		struct hw_fib * hwfib = fib->hw_fib_va;
+		struct fib * fib = &dev->fibs[index];
+		int start_callback = 0;
 
+#if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+		BUG_ON(index >= (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB));
+		BUG_ON(fib->type != FSAFS_NTC_FIB_CONTEXT);
+#endif
 		/*
 		 *	Remove this fib from the Outstanding I/O queue.
 		 *	But only if it has not already been timed out.
@@ -354,67 +438,182 @@ unsigned int aac_intr_normal(struct aac_dev *dev, u32 index,
 		 *	continue. The caller has already been notified that
 		 *	the fib timed out.
 		 */
-		dev->queues->queue[AdapNormCmdQueue].numpending--;
+		atomic_dec(&dev->queues->queue[AdapNormCmdQueue].numpending);
 
 		if (unlikely(fib->flags & FIB_CONTEXT_FLAG_TIMED_OUT)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+			printk(KERN_WARNING "aacraid: FIB timeout (%x).\n", fib->flags);
+			printk(KERN_DEBUG
+			  "aacraid: hwfib=%p index=%i fib[%d]=%p\n",
+			  hwfib, index, fib);
+#endif
 			aac_fib_complete(fib);
 			aac_fib_free(fib);
 			return 0;
 		}
 
-		if (isFastResponse) {
-			/*
-			 *	Doctor the fib
-			 */
-			*(__le32 *)hwfib->data = cpu_to_le32(ST_OK);
-			hwfib->header.XferState |= cpu_to_le32(AdapterProcessed);
-			fib->flags |= FIB_CONTEXT_FLAG_FASTRESP;
-		}
-
 		FIB_COUNTER_INCREMENT(aac_config.FibRecved);
 
-		if (hwfib->header.Command == cpu_to_le16(NuFileSystem))
-		{
-			__le32 *pstatus = (__le32 *)hwfib->data;
-			if (*pstatus & cpu_to_le32(0xffff0000))
-				*pstatus = cpu_to_le32(ST_OK);
-		}
-		if (hwfib->header.XferState & cpu_to_le32(NoResponseExpected | Async)) 
-		{
-	        	if (hwfib->header.XferState & cpu_to_le32(NoResponseExpected))
-				FIB_COUNTER_INCREMENT(aac_config.NoResponseRecved);
-			else 
-				FIB_COUNTER_INCREMENT(aac_config.AsyncRecved);
-			/*
-			 *	NOTE:  we cannot touch the fib after this
-			 *	    call, because it may have been deallocated.
-			 */
-			fib->flags &= FIB_CONTEXT_FLAG_FASTRESP;
-			fib->callback(fib->callback_data, fib);
-		} else {
-			unsigned long flagv;
-	  		dprintk((KERN_INFO "event_wait up\n"));
-			spin_lock_irqsave(&fib->event_lock, flagv);
-			if (!fib->done) {
-				fib->done = 1;
-				up(&fib->event_wait);
+		if (fib->flags & FIB_CONTEXT_FLAG_NATIVE_HBA) {
+			if (dev->simulated_scsi_error) {
+				aac_simulate_scsi_error(dev, fib->hw_fib_va);
+				dev->simulated_scsi_error = 0;
+			} else if (dev->simulated_tgt_failure) {
+				aac_simulate_tgt_failure(dev, fib->hw_fib_va);
+				dev->simulated_tgt_failure = 0;
+			} else if (isFastResponse) {
+				fib->flags |= FIB_CONTEXT_FLAG_FASTRESP;
 			}
-			spin_unlock_irqrestore(&fib->event_lock, flagv);
+			if (fib->callback) {
+				start_callback = 1;
+			} else {
+				unsigned long flagv;
+				int complete = 0;
+	  			dprintk((KERN_INFO "event_wait up\n"));
+				spin_lock_irqsave(&fib->event_lock, flagv);
+				if (fib->done == 2) {
+					fib->done = 1;
+					complete = 1;
+				} else {
+					fib->done = 1;
+					up(&fib->event_wait);
+				}
+				spin_unlock_irqrestore(&fib->event_lock, flagv);
 
-			spin_lock_irqsave(&dev->manage_lock, mflags);
-			dev->management_fib_count--;
-			spin_unlock_irqrestore(&dev->manage_lock, mflags);
+				spin_lock_irqsave(&dev->manage_lock, mflags);
+				dev->management_fib_count--;
+				spin_unlock_irqrestore(&dev->manage_lock, 
+					mflags);
 
-			FIB_COUNTER_INCREMENT(aac_config.NormalRecved);
-			if (fib->done == 2) {
+				FIB_COUNTER_INCREMENT(aac_config.NativeRecved);
+				if (complete) {
+					aac_fib_complete(fib);
+					aac_fib_free(fib);
+				} 
+			}
+		} else {
+			struct hw_fib * hwfib = fib->hw_fib_va;
+#if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+			BUG_ON(hwfib->header.XferState == 0);
+#endif
+			if (isFastResponse) {
+				/* Doctor the fib */
+				*(__le32 *)hwfib->data = cpu_to_le32(ST_OK);
+				hwfib->header.XferState |= 
+					cpu_to_le32(AdapterProcessed);
+				fib->flags |= FIB_CONTEXT_FLAG_FASTRESP;
+			}
+
+			if (hwfib->header.Command == cpu_to_le16(NuFileSystem))
+			{
+				__le32 *pstatus = (__le32 *)hwfib->data;
+				if (*pstatus & cpu_to_le32(0xffff0000))
+					*pstatus = cpu_to_le32(ST_OK);
+			}
+			if (hwfib->header.XferState & cpu_to_le32(
+				NoResponseExpected | Async)) 
+			{
+	        		if (hwfib->header.XferState & cpu_to_le32(
+					NoResponseExpected))
+					FIB_COUNTER_INCREMENT(
+						aac_config.NoResponseRecved);
+				else 
+					FIB_COUNTER_INCREMENT(
+						aac_config.AsyncRecved);
+				start_callback = 1;
+			} else {
+				unsigned long flagv;
+				int complete = 0;
+	  			dprintk((KERN_INFO "event_wait up\n"));
 				spin_lock_irqsave(&fib->event_lock, flagv);
-				fib->done = 0;
+				if (fib->done == 2) {
+					fib->done = 1;
+					complete = 1;
+				} else {
+					fib->done = 1;
+					up(&fib->event_wait);
+				}
 				spin_unlock_irqrestore(&fib->event_lock, flagv);
+
+				spin_lock_irqsave(&dev->manage_lock, mflags);
+				dev->management_fib_count--;
+				spin_unlock_irqrestore(&dev->manage_lock, 
+					mflags);
+
+				FIB_COUNTER_INCREMENT(aac_config.NormalRecved);
+				if (complete) {
+					aac_fib_complete(fib);
+					aac_fib_free(fib);
+				} 
+			}
+		}
+
+		if (start_callback) {
+			/*
+		 	 * NOTE:  we cannot touch the fib after this
+		 	 *  call, because it may have been deallocated.
+		 	 */
+#if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+			BUG_ON((fib->callback == NULL) || (fib->callback_data == NULL));
+			BUG_ON((fib->callback == (void *)(uintptr_t)0x6b6b6b6b6b6b6b6bLL) || (fib->callback_data == (void *)(uintptr_t)0x6b6b6b6b6b6b6b6bLL));
+			BUG_ON((fib->callback < (fib_callback)aac_get_driver_ident));
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB))
+			if (likely(fib->callback && fib->callback_data)) {
+				fib->callback(fib->callback_data, fib);
+			} else
+				printk(KERN_INFO
+				  "Invalid callback fib[%d>>2] (*%p)(%p)\n",
+				  index, fib->callback, fib->callback_data);
+#else
+			if (likely(fib->callback && fib->callback_data)) {
+				fib->callback(fib->callback_data, fib);
+			} else {
 				aac_fib_complete(fib);
 				aac_fib_free(fib);
 			}
+#endif
+		}
+	}
+	return 0;
+}
 
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+/**
+ *	aac_command_apre	-	Handle command replies
+ *	@dev: Device
+ *
+ *	This DPC routine will be run when the adapter interrupts us to let us
+ *	know there is a response on our apre queue. We will pull off
+ *	all QE there are and wake up all the waiters before exiting.
+ */
+
+unsigned int aac_command_apre(struct aac_dev * dev)
+{
+	struct aac_queue *q = &dev->queues->queue[ApreCmdQueue];
+
+	for (;;) {
+		struct donelist_entry *d;
+		unsigned long qflags;
+		struct fib * fib;
+
+		spin_lock_irqsave(q->lock, qflags);
+		d = q->NxtDoneListEntry;
+		if (d->DLIndicator == q->DLIndicator) {
+			spin_unlock_irqrestore(q->lock, qflags);
+			break;
+		}
+		fib = &dev->fibs[d->tcNumber >> 2];
+		q->Credits += fib->Credits;
+		if (++d >= &q->DoneListPool[q->entries]) {
+			d = q->DoneListPool;
+			q->DLIndicator = (q->DLIndicator == 0);
 		}
-		return 0;
+		q->NxtDoneListEntry = d;
+		spin_unlock_irqrestore(q->lock, qflags);
+
+		fib->callback(fib->callback_data, fib);
 	}
+	return 0;
 }
+#endif
diff --git a/drivers/scsi/aacraid/frey.c b/drivers/scsi/aacraid/frey.c
new file mode 100644
index 0000000..1ff9eab
--- /dev/null
+++ b/drivers/scsi/aacraid/frey.c
@@ -0,0 +1,878 @@
+/*
+ *	Adaptec AAC series RAID controller driver
+ *
+ * based on the old aacraid driver that is..
+ * Adaptec aacraid device driver for Linux.
+ *
+ * Copyright (c) 2006-2010 Adaptec, Inc. (aacraid@adaptec.com)
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; see the file COPYING.  If not, write to
+ * the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Module Name:
+ *  frey.c
+ *
+ * Abstract: Hardware Device Interface for Cardinal Frey
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/types.h>
+//#include <linux/sched.h>
+#include <linux/pci.h>
+#include <linux/spinlock.h>
+#include <linux/slab.h>
+#include <linux/blkdev.h>
+#include <linux/delay.h>
+#include <linux/version.h>	/* Needed for the following */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,2))
+#include <linux/completion.h>
+#endif
+#include <linux/time.h>
+#include <linux/interrupt.h>
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,23))
+#if (!defined(IRQ_NONE))
+  typedef void irqreturn_t;
+# define IRQ_HANDLED
+# define IRQ_NONE
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,25))
+#include <asm/semaphore.h>
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0))
+#include "scsi.h"
+#include "hosts.h"
+#else
+#include <scsi/scsi_host.h>
+#endif
+
+#include "aacraid.h"
+
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x70)
+static char * aac_debug_timestamp(void)
+{
+	unsigned long seconds = get_seconds();
+	static char buffer[80];
+	sprintf(buffer, "%02u:%02u:%02u: ",
+	  (int)((seconds / 3600) % 24),
+	  (int)((seconds / 60) % 60),
+	  (int)(seconds % 60));
+	return buffer;
+}
+# define AAC_DEBUG_PREAMBLE	"%s"
+# define AAC_DEBUG_POSTAMBLE	,aac_debug_timestamp()
+# define AAC_DEBUG_PREAMBLE_SIZE 10
+#else
+# define AAC_DEBUG_PREAMBLE	
+# define AAC_DEBUG_POSTAMBLE
+# define AAC_DEBUG_PREAMBLE_SIZE 0
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19))
+static irqreturn_t aac_frey_intr_message(int irq, void *dev_id, struct pt_regs *regs)
+#elif (defined(HAS_NEW_IRQ_HANDLER_T))
+static irqreturn_t aac_frey_intr_message(void *dev_id)
+#else
+static irqreturn_t aac_frey_intr_message(int irq, void *dev_id)
+#endif
+{
+	struct aac_dev *dev = dev_id;
+	u32 Index = frey_readl0(dev, MUnit.OutboundQueue);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30)
+	static unsigned empty_count = 0;
+	if (nblank(fwprintf(x)) &&
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x10)
+	  ((Index == 0xFFFFFFFFL) || (!(Index & 0x00000002L) &&
+	  (((Index >> 2) >= (dev->scsi_host_ptr->can_queue+AAC_NUM_MGT_FIB)) ||
+	  !(dev->fibs[Index >> 2].hw_fib_va->header.XferState &
+	  cpu_to_le32(NoResponseExpected | Async))))) &&
+#else
+	  dev->aif_thread &&
+#endif
+	  ((Index != 0xFFFFFFFFL) || (++empty_count < 3))) {
+		unsigned long DebugFlags = dev->FwDebugFlags;
+		dev->FwDebugFlags |= FW_DEBUG_FLAGS_NO_HEADERS_B;
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x30)
+		if (!(Index & 0x00000002L) && ((Index >> 2) >=
+		  (dev->scsi_host_ptr->can_queue+AAC_NUM_MGT_FIB))) {
+			struct hw_fib * f = dev->fibs[Index >> 2].hw_fib_va;
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B, AAC_DEBUG_PREAMBLE
+			  "irq%d Q=0x%X %u+%u+%u\n" AAC_DEBUG_POSTAMBLE,
+			  irq, Index, le16_to_cpu(f->header.Command),
+			  le32_to_cpu(((struct aac_query_mount *)f->data)->command),
+			  le32_to_cpu(((struct aac_query_mount *)f->data)->type)));
+		} else
+#endif
+		{
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  AAC_DEBUG_PREAMBLE "irq%d Q=0x%X\n"
+			  AAC_DEBUG_POSTAMBLE, irq, Index));
+		}
+		dev->FwDebugFlags = DebugFlags;
+	}
+#endif
+#endif
+	if (unlikely(Index == 0xFFFFFFFFL))
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30)
+	{
+#endif
+#endif
+		Index = frey_readl0(dev, MUnit.OutboundQueue);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30)
+		if (nblank(fwprintf(x))
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x10)
+		 && (!(Index & 0x00000002L) && (((Index >> 2) >=
+		  (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB)) ||
+		  !(dev->fibs[Index >> 2].hw_fib_va->header.XferState &
+		  cpu_to_le32(NoResponseExpected | Async))))
+#else
+		 && dev->aif_thread
+#endif
+		) {
+			unsigned long DebugFlags = dev->FwDebugFlags;
+			dev->FwDebugFlags |= FW_DEBUG_FLAGS_NO_HEADERS_B;
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x30)
+			if (!(Index & 0x00000002L) && ((Index >> 2) >=
+			  (dev->scsi_host_ptr->can_queue+AAC_NUM_MGT_FIB))) {
+				struct hw_fib * f = dev->fibs[
+				  Index >> 2].hw_fib_va;
+				fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+				  AAC_DEBUG_PREAMBLE " Q=0x%X %u+%u+%u\n"
+				  AAC_DEBUG_POSTAMBLE, Index,
+				  le16_to_cpu(f->header.Command),
+				  le32_to_cpu(((struct aac_query_mount *)
+				    f->data)->command),
+				  le32_to_cpu(((struct aac_query_mount *)
+				    f->data)->type)));
+			} else
+#endif
+			{
+				fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+				  AAC_DEBUG_PREAMBLE " Q=0x%X\n"
+				  AAC_DEBUG_POSTAMBLE, Index));
+			}
+			dev->FwDebugFlags = DebugFlags;
+		}
+	}
+#endif
+#endif
+	if (likely(Index != 0xFFFFFFFFL)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30)
+		if (nblank(fwprintf(x)))
+			empty_count = 0;
+#endif
+#endif
+		do {
+			if (unlikely(aac_intr_normal(dev, Index))) {
+				frey_writel0(dev, MUnit.OutboundQueue, Index);
+				frey_writel1(dev, F0_Doorbell, DoorBellAdapterNormRespReady);
+			}
+			Index = frey_readl0(dev, MUnit.OutboundQueue);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30)
+			if (nblank(fwprintf(x))
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x10)
+			 && !(Index & 0x00000002L) && (((Index >> 2) >=
+			  (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB)) ||
+			  !(dev->fibs[Index >> 2].hw_fib_va->header.XferState &
+			  cpu_to_le32(NoResponseExpected | Async)))
+#else
+			 && dev->aif_thread
+#endif
+			) {
+				unsigned long DebugFlags = dev->FwDebugFlags;
+				dev->FwDebugFlags |= FW_DEBUG_FLAGS_NO_HEADERS_B;
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x30)
+				if (!(Index & 0x00000002L) && ((Index >> 2) >=
+				  (dev->scsi_host_ptr->can_queue +
+				  AAC_NUM_MGT_FIB))) {
+					struct hw_fib * f = dev->fibs[
+					  Index >> 2].hw_fib_va;
+					fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+					  AAC_DEBUG_PREAMBLE " Q=0x%X %u+%u+%u\n"
+					  AAC_DEBUG_POSTAMBLE, Index,
+					  le16_to_cpu(f->header.Command),
+					  le32_to_cpu(
+					    ((struct aac_query_mount *)f->data)
+					      ->command),
+					  le32_to_cpu(
+					    ((struct aac_query_mount *)f->data)
+					      ->type)));
+				} else
+#endif
+				{
+					fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+					  AAC_DEBUG_PREAMBLE " Q=0x%X\n"
+					  AAC_DEBUG_POSTAMBLE, Index));
+				}
+				dev->FwDebugFlags = DebugFlags;
+			}
+#endif
+#endif
+		} while (Index != 0xFFFFFFFFL);
+		return IRQ_HANDLED;
+	}
+	return IRQ_NONE;
+}
+
+/**
+ *	aac_frey_disable_interrupt	-	Disable interrupts
+ *	@dev: Adapter
+ */
+
+static void aac_frey_disable_interrupt(struct aac_dev *dev)
+{
+	frey_writel1(dev, PCIeF0_Int_Enable, 0x0000UL);
+}
+
+/**
+ *	aac_frey_enable_interrupt_message	-	Enable interrupts
+ *	@dev: Adapter
+ */
+
+static void aac_frey_enable_interrupt_message(struct aac_dev *dev)
+{
+	frey_writel1(dev, PCIeF0_Int_Enable, 0x1010UL);
+}
+
+/**
+ *	frey_sync_cmd	-	send a command and wait
+ *	@dev: Adapter
+ *	@command: Command to execute
+ *	@p1: first parameter
+ *	@ret: adapter status
+ *
+ *	This routine will send a synchronous command to the adapter and wait 
+ *	for its	completion.
+ */
+
+static int frey_sync_cmd(struct aac_dev *dev, u32 command,
+	u32 p1, u32 p2, u32 p3, u32 p4, u32 p5, u32 p6,
+	u32 *status, u32 * r1, u32 * r2, u32 * r3, u32 * r4)
+{
+	unsigned long start;
+	int ok;
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB))
+	printk(KERN_INFO "frey_sync_cmd(%p,0x%lx,0x%lx,0x%lx,0x%lx,0x%lx,"
+	  "0x%lx,0x%lx,%p,%p,%p,%p,%p)\n",
+	  dev, command, p1, p2, p3, p4, p5, p6, status, r1, r2, r3, r4);
+#endif
+	/*
+	 *	Write the command into Mailbox 0
+	 */
+	frey_writel0(dev, IndexRegs.Mailbox[0], command);
+	/*
+	 *	Write the parameters into Mailboxes 1 - 6
+	 */
+	frey_writel0(dev, IndexRegs.Mailbox[1], p1);
+	frey_writel0(dev, IndexRegs.Mailbox[2], p2);
+	frey_writel0(dev, IndexRegs.Mailbox[3], p3);
+	frey_writel0(dev, IndexRegs.Mailbox[4], p4);
+#if (defined(AAC_LM_SENSOR) && !defined(CONFIG_COMMUNITY_KERNEL))
+	frey_writel0(dev, IndexRegs.Mailbox[5], p5);
+	frey_writel0(dev, IndexRegs.Mailbox[6], p6);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB))
+	printk(KERN_INFO "OutMaiboxes=%p="
+	  "{0x%lx,0x%lx,0x%lx,0x%lx,0x%lx,0x%lx,0x%lx}\n",
+	  &dev->IndexRegs->Mailbox[0],
+	  frey_readl0(dev, IndexRegs.Mailbox[0]),
+	  frey_readl0(dev, IndexRegs.Mailbox[1]),
+	  frey_readl0(dev, IndexRegs.Mailbox[2]),
+	  frey_readl0(dev, IndexRegs.Mailbox[3]),
+	  frey_readl0(dev, IndexRegs.Mailbox[4]),
+	  frey_readl0(dev, IndexRegs.Mailbox[5]),
+	  frey_readl0(dev, IndexRegs.Mailbox[6]));
+#endif
+	/*
+	 *	Clear the synch command doorbell to start on a clean slate.
+	 */
+	frey_writel1(dev, F0_Doorbell, OUTBOUNDDOORBELL_0);
+	/*
+	 *	Disable doorbell interrupts
+	 */
+	aac_adapter_disable_int(dev);
+	/*
+	 *	Force the completion of the mask register write before issuing
+	 *	the interrupt.
+	 */
+	frey_readl1(dev, PCIeF0_Int_Enable);
+	/*
+	 *	Signal that there is a new synch command
+	 */
+	frey_writel1(dev, F0_To_CPU_Doorbell, INBOUNDDOORBELL_0);
+
+	ok = 0;
+	start = jiffies;
+
+	/*
+	 *	Wait up to 30 seconds
+	 */
+	while (time_before(jiffies, start+30*HZ)) 
+	{
+		udelay(5);	/* Delay 5 microseconds to let Mon960 get info. */
+		/*
+		 *	Mon960 will set doorbell0 bit when it has completed the command.
+		 */
+		if (frey_readl1(dev, F0_Doorbell) & OUTBOUNDDOORBELL_0) {
+			/*
+			 *	Clear the doorbell.
+			 */
+			frey_writel1(dev, F0_Doorbell, OUTBOUNDDOORBELL_0);
+			ok = 1;
+			break;
+		}
+		/*
+		 *	Yield the processor in case we are slow 
+		 */
+		msleep(1);
+	}
+	if (unlikely(ok != 1)) {
+		/*
+		 *	Restore interrupt mask even though we timed out
+		 */
+		aac_adapter_enable_int(dev);
+		return -ETIMEDOUT;
+	}
+	/*
+	 *	Pull the synch status from Mailbox 0.
+	 */
+	if (status)
+		*status = frey_readl0(dev, IndexRegs.Mailbox[0]);
+	if (r1)
+		*r1 = frey_readl0(dev, IndexRegs.Mailbox[1]);
+	if (r2)
+		*r2 = frey_readl0(dev, IndexRegs.Mailbox[2]);
+	if (r3)
+		*r3 = frey_readl0(dev, IndexRegs.Mailbox[3]);
+	if (r4)
+		*r4 = frey_readl0(dev, IndexRegs.Mailbox[4]);
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB))
+	printk(KERN_INFO "InMaiboxes={0x%lx,0x%lx,0x%lx,0x%lx,0x%lx}\n",
+	  frey_readl0(dev, IndexRegs.Mailbox[0]),
+	  frey_readl0(dev, IndexRegs.Mailbox[1]),
+	  frey_readl0(dev, IndexRegs.Mailbox[2]),
+	  frey_readl0(dev, IndexRegs.Mailbox[3]),
+	  frey_readl0(dev, IndexRegs.Mailbox[4]));
+#endif
+	/*
+	 *	Clear the synch command doorbell.
+	 */
+	frey_writel1(dev, F0_Doorbell, OUTBOUNDDOORBELL_0);
+	/*
+	 *	Restore interrupt mask
+	 */
+	aac_adapter_enable_int(dev);
+	return 0;
+
+}
+
+/**
+ *	aac_frey_interrupt_adapter	-	interrupt adapter
+ *	@dev: Adapter
+ *
+ *	Send an interrupt to the i960 and breakpoint it.
+ */
+
+static void aac_frey_interrupt_adapter(struct aac_dev *dev)
+{
+	frey_sync_cmd(dev, BREAKPOINT_REQUEST, 0, 0, 0, 0, 0, 0, NULL, NULL, NULL, NULL, NULL);
+}
+
+/**
+ *	aac_frey_notify_adapter		-	send an event to the adapter
+ *	@dev: Adapter
+ *	@event: Event to send
+ *
+ *	Notify the i960 that something it probably cares about has
+ *	happened.
+ */
+
+static void aac_frey_notify_adapter(struct aac_dev *dev, u32 event)
+{
+	switch (event) {
+
+	case AdapNormCmdQue:
+		frey_writel1(dev, F0_To_CPU_Doorbell, INBOUNDDOORBELL_1);
+		break;
+	case HostNormRespNotFull:
+		frey_writel1(dev, F0_To_CPU_Doorbell, INBOUNDDOORBELL_4);
+		break;
+	case AdapNormRespQue:
+		frey_writel1(dev, F0_To_CPU_Doorbell, INBOUNDDOORBELL_2);
+		break;
+	case HostNormCmdNotFull:
+		frey_writel1(dev, F0_To_CPU_Doorbell, INBOUNDDOORBELL_3);
+		break;
+	case HostShutdown:
+//		frey_sync_cmd(dev, HOST_CRASHING, 0, 0, 0, 0, 0, 0,
+//		  NULL, NULL, NULL, NULL, NULL);
+		break;
+	case FastIo:
+		frey_writel1(dev, F0_To_CPU_Doorbell, INBOUNDDOORBELL_6);
+		break;
+	case AdapPrintfDone:
+		frey_writel1(dev, F0_To_CPU_Doorbell, INBOUNDDOORBELL_5);
+		break;
+	default:
+		BUG();
+		break;
+	}
+}
+
+/**
+ *	aac_frey_start_adapter		-	activate adapter
+ *	@dev:	Adapter
+ *
+ *	Start up processing on an i960 based AAC adapter
+ */
+
+static void aac_frey_start_adapter(struct aac_dev *dev)
+{
+	struct aac_init *init;
+
+	init = dev->init;
+	init->HostElapsedSeconds = cpu_to_le32(get_seconds());
+	// We can only use a 32 bit address here
+	frey_sync_cmd(dev, INIT_STRUCT_BASE_ADDRESS, (u32)(ulong)dev->init_pa,
+	  0, 0, 0, 0, 0, NULL, NULL, NULL, NULL, NULL);
+#	if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+		printk(KERN_INFO"INIT_STRUCT_BASE_ADDRESS=0x%lx\n",
+		  (unsigned long)dev->init_pa);
+#	endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+	/*
+	 * On some cards, without a wait here after the INIT_STRUCT_BASE_ADDRESS
+	 * command, the ContainerCommand in AacHba_ProbeContainers() fails to
+	 * report the container.
+	 * The wait time was determined by trial-and-error.
+	 */
+	 mdelay(500);
+#endif
+}
+
+/**
+ *	aac_frey_check_health
+ *	@dev: device to check if healthy
+ *
+ *	Will attempt to determine if the specified adapter is alive and
+ *	capable of handling requests, returning 0 if alive.
+ */
+static int aac_frey_check_health(struct aac_dev *dev)
+{
+	u32 status = frey_readl0(dev, OMR0);
+
+	/*
+	 *	Check to see if the board failed any self tests.
+	 */
+	if (unlikely(status & SELF_TEST_FAILED))
+		return -1;
+	/*
+	 *	Check to see if the board panic'd.
+	 */
+	if (unlikely(status & KERNEL_PANIC)) {
+		char * buffer;
+		struct POSTSTATUS {
+			__le32 Post_Command;
+			__le32 Post_Address;
+		} * post;
+		dma_addr_t paddr, baddr;
+		int ret;
+
+		if (likely((status & 0xFF000000L) == 0xBC000000L))
+			return (status >> 16) & 0xFF;
+#if (((__GNUC__ * 10000) + (__GNUC_MINOR__ * 100) + __GNUC_PATCHLEVEL__) <= 400002)
+		baddr = 0;
+#endif
+		buffer = pci_alloc_consistent(dev->pdev, 512, &baddr);
+		ret = -2;
+		if (unlikely(buffer == NULL))
+			return ret;
+#if (((__GNUC__ * 10000) + (__GNUC_MINOR__ * 100) + __GNUC_PATCHLEVEL__) <= 400002)
+		paddr = 0;
+#endif
+		post = pci_alloc_consistent(dev->pdev,
+		  sizeof(struct POSTSTATUS), &paddr);
+		if (unlikely(post == NULL)) {
+			pci_free_consistent(dev->pdev, 512, buffer, baddr);
+			return ret;
+		}
+		memset(buffer, 0, 512);
+		post->Post_Command = cpu_to_le32(COMMAND_POST_RESULTS);
+		post->Post_Address = cpu_to_le32(baddr);
+		frey_writel0(dev, IMR0, paddr);
+		frey_sync_cmd(dev, COMMAND_POST_RESULTS, baddr, 0, 0, 0, 0, 0,
+		  NULL, NULL, NULL, NULL, NULL);
+		pci_free_consistent(dev->pdev, sizeof(struct POSTSTATUS),
+		  post, paddr);
+		if (likely((buffer[0] == '0') && ((buffer[1] == 'x') || (buffer[1] == 'X')))) {
+			ret = (buffer[2] <= '9') ? (buffer[2] - '0') : (buffer[2] - 'A' + 10);
+			ret <<= 4;
+			ret += (buffer[3] <= '9') ? (buffer[3] - '0') : (buffer[3] - 'A' + 10);
+		}
+		pci_free_consistent(dev->pdev, 512, buffer, baddr);
+		return ret;
+	}
+	/*
+	 *	Wait for the adapter to be up and running.
+	 */
+	if (unlikely(!(status & KERNEL_UP_AND_RUNNING)))
+		return -3;
+	/*
+	 *	Everything is OK
+	 */
+	return 0;
+}
+
+/**
+ *	aac_frey_deliver_message
+ *	@fib: fib to issue
+ *
+ *	Will send a fib, returning 0 if successful.
+ */
+static int aac_frey_deliver_message(struct fib * fib)
+{
+	struct aac_dev *dev = fib->dev;
+	struct aac_queue *q = &dev->queues->queue[AdapNormCmdQueue];
+	unsigned long qflags;
+	u32 Index;
+	u64 addr;
+	volatile void __iomem *device;
+
+	unsigned long count = 10000000L; /* 50 seconds */
+	spin_lock_irqsave(q->lock, qflags);
+	q->numpending++;
+	spin_unlock_irqrestore(q->lock, qflags);
+	for(;;) {
+		Index = frey_readl0(dev, MUnit.InboundQueue);
+		if (unlikely(Index == 0xFFFFFFFFL))
+			Index = frey_readl0(dev, MUnit.InboundQueue);
+		if (likely(Index != 0xFFFFFFFFL))
+			break;
+		if (--count == 0) {
+			spin_lock_irqsave(q->lock, qflags);
+			q->numpending--;
+			spin_unlock_irqrestore(q->lock, qflags);
+#			if (defined(AAC_DEBUG_INSTRUMENT_FIB))
+				printk(KERN_INFO "aac_fib_send: message unit full\n");
+#			endif
+			return -ETIMEDOUT;
+		}
+		udelay(5);
+	}
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x70)
+	if (nblank(fwprintf(x))
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x10)
+	 && !(fib->hw_fib_va->header.XferState &
+	  cpu_to_le32(NoResponseExpected | Async))
+#else
+	 && dev->aif_thread
+#endif
+	) {
+		unsigned long DebugFlags = dev->FwDebugFlags;
+		dev->FwDebugFlags |= FW_DEBUG_FLAGS_NO_HEADERS_B;
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30)
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B, AAC_DEBUG_PREAMBLE
+		  "send Q=0x%X I=0x%X %u+%u+%u\n" AAC_DEBUG_POSTAMBLE,
+		  ((int)(fib - dev->fibs)) << 2, Index,
+		  le16_to_cpu(fib->hw_fib_va->header.Command),
+		  le32_to_cpu(((struct aac_query_mount *)
+		    fib->hw_fib_va->data)->command),
+		  le32_to_cpu(((struct aac_query_mount *)
+		    fib->hw_fib_va->data)->type)));
+#endif
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x40)
+		{
+			u8 * p = (u8 *)fib->hw_fib_va;
+			unsigned len = le16_to_cpu(fib->hw_fib_va->header.Size);
+			char buffer[80-AAC_DEBUG_PREAMBLE_SIZE];
+			char * cp = buffer;
+
+			strcpy(cp, "FIB=");
+			cp += 4;
+			while (len > 0) {
+				if (cp >= &buffer[sizeof(buffer)-4]) {
+					fwprintf((dev,
+					  HBA_FLAGS_DBG_FW_PRINT_B,
+					  AAC_DEBUG_PREAMBLE "%s\n"
+					  AAC_DEBUG_POSTAMBLE,
+					  buffer));
+					strcpy(cp = buffer, "    ");
+					cp += 4;
+				}
+				sprintf (cp, "%02x ", *(p++));
+				cp += strlen(cp);
+				--len;
+			}
+			if (cp > &buffer[4]) {
+				fwprintf((dev,
+				  HBA_FLAGS_DBG_FW_PRINT_B,
+				  AAC_DEBUG_PREAMBLE "%s\n"
+				  AAC_DEBUG_POSTAMBLE, buffer));
+			}
+		}
+#endif
+		dev->FwDebugFlags = DebugFlags;
+	}
+#endif
+#endif
+	device = dev->base + Index;
+	addr = fib->hw_fib_pa;
+	writel((u32)(addr & 0xffffffff), device);
+	device += sizeof(u32);
+	writel((u32)(addr >> 32), device);
+	device += sizeof(u32);
+	writel(le16_to_cpu(fib->hw_fib_va->header.Size), device);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x70)
+//qflags=readl(device);
+#endif
+#endif
+	frey_writel0(dev, MUnit.InboundQueue, Index);
+	return 0;
+}
+
+/**
+ *	aac_frey_ioremap
+ *	@size: mapping resize request
+ *
+ */
+static int aac_frey_ioremap(struct aac_dev * dev, u32 size)
+{
+	if (!size) {
+		iounmap(dev->regs.rx);
+		dev->regs.rx = NULL;
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,9))
+		iounmap((void __iomem *)dev->base);
+#else
+		iounmap(dev->base);
+#endif
+		dev->base = NULL;
+		return 0;
+	}
+	dev->regs.frey.bar1 = 
+        ioremap(pci_resource_start(dev->pdev, 2), AAC_MIN_FREY_BAR1_SIZE);
+	dev->base = NULL;
+	if (dev->regs.frey.bar1 == NULL)
+		return -1;
+	dev->base = dev->regs.frey.bar0 = ioremap(dev->scsi_host_ptr->base, size);
+	if (dev->base == NULL) {
+		iounmap(dev->regs.frey.bar1);
+		dev->regs.frey.bar1 = NULL;
+		return -1;
+	}
+    /* IndexRegs not really needed, only for debugging purposes */
+	dev->IndexRegs = &((struct frey_registers __iomem *)dev->base)->IndexRegs;
+	return 0;
+}
+
+static int aac_frey_restart_adapter(struct aac_dev *dev, int bled)
+{
+	u32 var;
+
+	if (!(dev->supplement_adapter_info.SupportedOptions2 &
+	  AAC_OPTION_MU_RESET) || (bled >= 0) || (bled == -2)) {
+		if (bled)
+			printk(KERN_ERR "%s%d: adapter kernel panic'd %x.\n",
+				dev->name, dev->id, bled);
+		else {
+			bled = aac_adapter_sync_cmd(dev, IOP_RESET_ALWAYS,
+			  0, 0, 0, 0, 0, 0, &var, NULL, NULL, NULL, NULL);
+			if (!bled && (var != 0x00000001) && (var != 0x3803000F))
+				bled = -EINVAL;
+		}
+		if (bled && (bled != -ETIMEDOUT))
+			bled = aac_adapter_sync_cmd(dev, IOP_RESET,
+			  0, 0, 0, 0, 0, 0, &var, NULL, NULL, NULL, NULL);
+
+		if (bled && (bled != -ETIMEDOUT))
+			return -EINVAL;
+	}
+	if (frey_readl0(dev, OMR0) & KERNEL_PANIC)
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+	{
+		if (var == 10)
+			printk(KERN_INFO "IOP_RESET disabled\n");
+#endif
+		return -ENODEV;
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+	}
+#endif
+	if (startup_timeout < 300)
+		startup_timeout = 300;
+	return 0;
+}
+
+/**
+ *	aac_frey_select_comm	-	Select communications method
+ *	@dev: Adapter
+ *	@comm: communications method
+ */
+int aac_frey_select_comm(struct aac_dev *dev, int comm)
+{
+	switch (comm) {
+	case AAC_COMM_MESSAGE:
+		dev->a_ops.adapter_enable_int = aac_frey_enable_interrupt_message;
+		dev->a_ops.adapter_intr = aac_frey_intr_message;
+		dev->a_ops.adapter_deliver = aac_frey_deliver_message;
+		break;
+	default:
+		return 1;
+	}
+	return 0;
+}
+
+/**
+ *  aac_frey_init	-	initialize an Cardinal Frey Bar card
+ *  @dev: device to configure
+ *
+ */
+
+int aac_frey_init(struct aac_dev * dev)
+{
+	unsigned long start;
+	unsigned long status;
+	int restart = 0;
+	int instance = dev->id;
+	const char * name = dev->name;
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19)) && !defined(HAS_RESET_DEVICES))
+#	define reset_devices aac_reset_devices
+#endif
+
+	dev->a_ops.adapter_ioremap = aac_frey_ioremap;
+	dev->a_ops.adapter_comm = aac_frey_select_comm;
+
+	dev->base_size = AAC_MIN_FREY_BAR0_SIZE;
+	if (aac_adapter_ioremap(dev, dev->base_size)) {
+		printk(KERN_WARNING "%s: unable to map adapter.\n", name);
+		goto error_iounmap;
+	}
+
+	/* Failure to reset here is an option ... */
+	dev->a_ops.adapter_sync_cmd = frey_sync_cmd;
+	dev->a_ops.adapter_enable_int = aac_frey_disable_interrupt;
+	if ((aac_reset_devices || reset_devices) &&
+	  !aac_frey_restart_adapter(dev, 0))
+		/* Make sure the Hardware FIFO is empty */
+		while ((++restart < 512) &&
+		  (frey_readl0(dev, MUnit.OutboundQueue) != 0xFFFFFFFFL));
+	/*
+	 *	Check to see if the board panic'd while booting.
+	 */
+	status = frey_readl0(dev, OMR0);
+	if (status & KERNEL_PANIC) {
+		if (aac_frey_restart_adapter(dev, aac_frey_check_health(dev)))
+			goto error_iounmap;
+		++restart;
+	}
+	/*
+	 *	Check to see if the board failed any self tests.
+	 */
+	status = frey_readl0(dev, OMR0);
+	if (status & SELF_TEST_FAILED) {
+		printk(KERN_ERR "%s%d: adapter self-test failed.\n", dev->name, instance);
+		goto error_iounmap;
+	}
+	/*
+	 *	Check to see if the monitor panic'd while booting.
+	 */
+	if (status & MONITOR_PANIC) {
+		printk(KERN_ERR "%s%d: adapter monitor panic.\n", dev->name, instance);
+		goto error_iounmap;
+	}
+	start = jiffies;
+	/*
+	 *	Wait for the adapter to be up and running. Wait up to 3 minutes
+	 */
+	while (!((status = frey_readl0(dev, OMR0)) & KERNEL_UP_AND_RUNNING))
+	{
+		if ((restart &&
+		  (status & (KERNEL_PANIC|SELF_TEST_FAILED|MONITOR_PANIC))) ||
+		  time_after(jiffies, start+HZ*startup_timeout)) {
+			printk(KERN_ERR "%s%d: adapter kernel failed to start, init status = %lx.\n", 
+					dev->name, instance, status);
+			goto error_iounmap;
+		}
+		if (!restart &&
+		  ((status & (KERNEL_PANIC|SELF_TEST_FAILED|MONITOR_PANIC)) ||
+		  time_after(jiffies, start + HZ *
+		  ((startup_timeout > 60)
+		    ? (startup_timeout - 60)
+		    : (startup_timeout / 2))))) {
+			if (likely(!aac_frey_restart_adapter(dev, aac_frey_check_health(dev))))
+				start = jiffies;
+			++restart;
+		}
+		msleep(1);
+	}
+	if (restart && aac_commit)
+		aac_commit = 1;
+	/*
+	 *	Fill in the common function dispatch table.
+	 */
+	dev->a_ops.adapter_interrupt = aac_frey_interrupt_adapter;
+	dev->a_ops.adapter_disable_int = aac_frey_disable_interrupt;
+	dev->a_ops.adapter_notify = aac_frey_notify_adapter;
+	dev->a_ops.adapter_sync_cmd = frey_sync_cmd;
+	dev->a_ops.adapter_check_health = aac_frey_check_health;
+	dev->a_ops.adapter_restart = aac_frey_restart_adapter;
+
+	/*
+	 *	First clear out all interrupts.  Then enable the one's that we
+	 *	can handle.
+	 */
+	aac_adapter_comm(dev, AAC_COMM_MESSAGE);
+	aac_adapter_disable_int(dev);
+	frey_writel1(dev, F0_Doorbell, 0xffffffff);
+	aac_adapter_enable_int(dev);
+
+	if (aac_init_adapter(dev) == NULL)
+		goto error_iounmap;
+	if (dev->comm_interface != AAC_COMM_MESSAGE)
+		goto error_iounmap;
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_ENABLE_MSI))
+	dev->msi = aac_msi && !pci_enable_msi(dev->pdev);
+#endif
+	if (request_irq(dev->pdev->irq, dev->a_ops.adapter_intr,
+			IRQF_SHARED|IRQF_DISABLED, "aacraid", dev) < 0) {
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_DISABLE_MSI))
+		if (dev->msi)
+			pci_disable_msi(dev->pdev);
+#endif
+		printk(KERN_ERR "%s%d: Interrupt unavailable.\n",
+			name, instance);
+		goto error_iounmap;
+	}
+	aac_adapter_enable_int(dev);
+	/*
+	 *	Tell the adapter that all is configured, and it can
+	 * start accepting requests
+	 */
+	aac_frey_start_adapter(dev);
+
+	return 0;
+
+error_iounmap:
+
+	return -1;
+}
diff --git a/drivers/scsi/aacraid/fwdebug.c b/drivers/scsi/aacraid/fwdebug.c
new file mode 100644
index 0000000..e6d4ea2
--- /dev/null
+++ b/drivers/scsi/aacraid/fwdebug.c
@@ -0,0 +1,661 @@
+/*
+ *	Adaptec AAC series RAID controller driver
+ *
+ * Copyright (c) 2004-2007 Adaptec, Inc. (aacraid@adaptec.com)
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; see the file COPYING.  If not, write to
+ * the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <stdarg.h>
+#include <linux/types.h>
+#include <linux/wait.h>
+#include <linux/spinlock.h>
+#include <linux/kernel.h>
+#include <linux/blkdev.h>
+#include <linux/version.h>
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+#include <asm/semaphore.h>
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+#include <linux/blk.h>	/* for io_request_lock definition */
+#endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,2))
+#include <linux/completion.h>
+#endif
+#include <linux/string.h>
+#include <linux/sched.h>
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,33))
+#include <linux/slab.h>
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || (LINUX_VERSION_CODE >=  KERNEL_VERSION(3,2,0)))
+#include <linux/module.h>
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+#include <scsi/scsi.h>
+#include <scsi/scsi_cmnd.h>
+#include <scsi/scsi_host.h>
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,6))
+#include <linux/moduleparam.h>
+#endif
+#else
+#include "scsi.h"
+#include "hosts.h"
+#endif
+#include "aacraid.h"
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#include "fwdebug.h"
+
+static int aac_firmware_debug=1;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+module_param_named(firmware_debug, aac_firmware_debug, int, S_IRUGO|S_IWUSR);
+#else
+MODULE_PARM(aac_firmware_debug, "i");
+#endif
+MODULE_PARM_DESC(firmware_debug, "Enable Firmware print debugging.\n"
+	"\t0=off\n"
+	"\t1=print to adapter diagnostic (default)\n"
+	"\t2=print to syslog\n"
+	"\t3=adapter diagnostic to syslog (unsupported)");
+
+/*
+ * Debug flags to be put into the HBA flags field when initialized
+ */
+static const unsigned long aac_debug_flags = /* Variable to setup with above flags. */
+/*			HBA_FLAGS_DBG_KERNEL_PRINT_B |		*/
+			HBA_FLAGS_DBG_FW_PRINT_B |
+			HBA_FLAGS_DBG_FUNCTION_ENTRY_B |
+			HBA_FLAGS_DBG_FUNCTION_EXIT_B |
+			HBA_FLAGS_DBG_ERROR_B |
+/*			HBA_FLAGS_DBG_INIT_B |			*/
+/*			HBA_FLAGS_DBG_OS_COMMANDS_B |		*/
+/*			HBA_FLAGS_DBG_SCAN_B |			*/
+/*			HBA_FLAGS_DBG_COALESCE_B |		*/
+/*			HBA_FLAGS_DBG_IOCTL_COMMANDS_B |	*/
+/*			HBA_FLAGS_DBG_SYNC_COMMANDS_B |		*/
+/*			HBA_FLAGS_DBG_COMM_B |			*/
+/*			HBA_FLAGS_DBG_AIF_B |			*/
+/*			HBA_FLAGS_DBG_CSMI_COMMANDS_B | 	*/
+/*			HBA_FLAGS_DBG_FLAGS_MASK | 		*/
+0;
+
+int aac_get_fw_debug_buffer(struct aac_dev * dev)
+{
+	if (nblank(fwprintf(x)) && (aac_firmware_debug == 1)) {
+		u32 MonDriverBufferPhysAddrLow = 0;
+		u32 MonDriverBufferPhysAddrHigh = 0;
+		u32 MonDriverBufferSize = 0;
+		u32 MonDriverHeaderSize = 0;
+		u32 ReturnStatus = 0;
+
+		/*
+		 * Initialize the firmware print buffer fields
+		 */
+		/* Marked list and lock initialized */
+		if (dev->FwDebugBuffer_P == (volatile u8 __iomem *)NULL) {
+			spin_lock_init(&dev->PrintQueueLock);
+			INIT_LIST_HEAD(&dev->PrintQueue);
+			/*
+			 * Mark list and lock initialized, but not print
+			 * ability
+			  */
+			dev->FwDebugBuffer_P = (volatile u8 __iomem *)
+				dev->dbg_base_mapped;
+		}
+
+		/*
+		 * Get the firmware print buffer parameters from the firmware
+		 * If the command was successful map in the address.
+		 */
+		if (!aac_adapter_sync_cmd(dev, GET_DRIVER_BUFFER_PROPERTIES,
+		  0, 0, 0, 0, 0, 0,
+		  &ReturnStatus,
+		  &MonDriverBufferPhysAddrLow,
+		  &MonDriverBufferPhysAddrHigh,
+		  &MonDriverBufferSize,
+		  &MonDriverHeaderSize) && MonDriverBufferSize) {
+			unsigned long Offset = MonDriverBufferPhysAddrLow -
+			     (dev->dbg_base & 0xffffffff);
+
+			/*
+			 * See if the address is already mapped in and if so
+			 * set it up from the base address
+			 */
+			if (((u32)(((u64)dev->dbg_base) >> 32)
+			  == MonDriverBufferPhysAddrHigh)
+			 && ((Offset + MonDriverBufferSize) < dev->dbg_size))
+				dev->FwDebugBuffer_P =
+				  (volatile u8 __iomem *)dev->dbg_base_mapped + Offset;
+
+			/*
+			 * If mapping went well, Set up the debug buffer fields
+			 * in the HBA structure from the data returned
+			 */
+			if (dev->FwDebugBuffer_P !=
+			  (volatile u8 __iomem *)NULL) {
+				dev->FwDebugFlags_P =
+				  (volatile __le32 __iomem *)
+				    (dev->FwDebugBuffer_P +
+				      FW_DEBUG_FLAGS_OFFSET);
+				dev->FwDebugStrLength_P =
+				  (volatile __le32 __iomem *)
+				    (dev->FwDebugBuffer_P +
+				      FW_DEBUG_STR_LENGTH_OFFSET);
+				dev->FwDebugBLEDvalue_P =
+				  dev->FwDebugBuffer_P +
+				  FW_DEBUG_BLED_OFFSET;
+				dev->FwDebugBLEDflag_P =
+				  dev->FwDebugBLEDvalue_P + 1;
+				dev->FwDebugBufferSize = MonDriverBufferSize;
+				dev->FwDebugBuffer_P += MonDriverHeaderSize;
+				dev->FwDebugFlags = 0;
+				dev->DebugFlags = aac_debug_flags;
+				return 1;
+			}
+		}
+
+		/*
+		 * The GET_DRIVER_BUFFER_PROPERTIES command failed
+		 */
+	}
+	return 0;
+}
+
+#define PRINT_TIMEOUT ((HZ+2)/4) /* 1/4 second */
+
+static int aac_fw_send(struct aac_dev * dev, unsigned long PrintFlags,
+	const char * PrintBuffer_P, int jafo)
+{
+	if (nblank(fwprintf(x)) && (aac_firmware_debug == 1)) {
+		/*
+		 * Make sure the HBA structure has been passed in for this
+		 * section
+		 */
+		if (dev && dev->FwDebugBufferSize) {
+			/*
+			 * If we are set up for a Firmware print
+			 */
+			if ((dev->DebugFlags & HBA_FLAGS_DBG_FW_PRINT_B) &&
+			  ((PrintFlags &
+			    (HBA_FLAGS_DBG_KERNEL_PRINT_B |
+			      HBA_FLAGS_DBG_FW_PRINT_B)) !=
+			  HBA_FLAGS_DBG_KERNEL_PRINT_B)) {
+				/*
+				 * Wait for no more than PRINT_TIMEOUT for the
+				 * previous message length to clear (the
+				 * handshake).
+				 */
+				if (!jafo) {
+					unsigned long counter = 400000000L /
+						HZ * PRINT_TIMEOUT;
+					unsigned long next_jiffies = jiffies +
+								PRINT_TIMEOUT;
+					while (readl(dev->FwDebugStrLength_P)
+					 && !time_after(jiffies, next_jiffies)
+					 && --counter)
+						continue; /* schedule(); */
+				}
+	
+				/*
+				 * If the Length is clear, copy over the
+				 * message, the flags, and the length. Make
+				 * sure the length is the last because that is
+				 * the signal for the Firmware to pick it up.
+				 */
+				if (readl(dev->FwDebugStrLength_P))
+					return -1;
+				{
+					/*
+					 * Make sure string size is within
+					 * boundaries
+					 */
+					unsigned Length;
+					volatile u8 __iomem * dst =
+						dev->FwDebugBuffer_P;
+					const u8 * src =
+						(const u8 *)PrintBuffer_P;
+					unsigned Count = strlen(src);
+	
+					if (Count > dev->FwDebugBufferSize)
+						Count = dev->FwDebugBufferSize;
+					if ((Length = Count)) do {
+						writeb(*src, dst);
+						++src;
+						++dst;
+					} while (--Length);
+					writel(dev->FwDebugFlags
+					  & HBA_FLAGS_DBG_FLAGS_MASK,
+					  dev->FwDebugFlags_P);
+					/* Enforce ordering, PCIe break */
+					readl(dev->FwDebugFlags_P);
+					writel(Count, dev->FwDebugStrLength_P);
+				}
+			}
+	
+			/*
+			 * If the Kernel Debug Print flag is set, send it off
+			 * to the Kernel debugger
+			 */
+			if (!(dev->DebugFlags & HBA_FLAGS_DBG_KERNEL_PRINT_B))
+				return 0;
+		}
+	}
+
+	if (nblank(fwprintf(x))) {
+		if ((aac_firmware_debug == 2) ||
+		   ((aac_firmware_debug == 1) && ((PrintFlags &
+		    (HBA_FLAGS_DBG_KERNEL_PRINT_B|HBA_FLAGS_DBG_FW_PRINT_B)) !=
+		     HBA_FLAGS_DBG_FW_PRINT_B))) {
+			if (dev &&
+			  (dev->FwDebugFlags & FW_DEBUG_FLAGS_NO_HEADERS_B))
+				printk ("%s", PrintBuffer_P);
+			else if (dev)
+				printk (KERN_INFO "%s: %s\n",
+				  dev->scsi_host_ptr->hostt->proc_name,
+				  PrintBuffer_P);
+			else
+				printk (KERN_INFO "%s\n", PrintBuffer_P);
+		}
+	}
+
+	if (nblank(fwprintf(x)) && (aac_firmware_debug == 1))
+		return (jafo && dev && !dev->FwDebugBufferSize);
+	else
+		return 0;
+}
+
+void aac_fw_printf(struct aac_dev * dev, unsigned long PrintFlags, const char * fmt, ...)
+{
+	if (nblank(fwprintf(x)) &&
+	  ((aac_firmware_debug == 1) || (aac_firmware_debug == 2))) {
+		va_list args;
+		char PrintBuffer_P[PRINT_BUFFER_SIZE+1];
+		static struct PrintQueue {
+			struct list_head entry;
+			unsigned long PrintFlags;
+			unsigned long DebugFlags;
+			char PrintBuffer_P[1];
+		}
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+		* Spare[2048];
+#elif (defined(BOOTCD))
+		* Spare[32];
+#else
+		* Spare[512];
+#endif
+		unsigned long pflags = 0;
+#if (defined(irqs_disabled))
+#if (defined(in_atomic))
+		int jafo = in_atomic() | in_interrupt() | irqs_disabled();
+#else
+		int jafo = in_interrupt() | irqs_disabled();
+#endif
+#elif (defined(in_atomic))
+		int jafo = in_atomic() | in_interrupt();
+#else
+		int jafo = in_interrupt();
+#endif
+	
+		if (!jafo && dev) {
+			struct Scsi_Host * host = dev->scsi_host_ptr;
+	
+			jafo = (
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,14)) || defined(SCSI_HAS_SHOST_STATE_ENUM))
+			  SHOST_RECOVERY == host->shost_state
+#elif (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+			  test_bit(SHOST_RECOVERY, &host->shost_state) ||
+			  host->eh_active
+#else
+			  host->in_recovery || host->eh_active
+#endif
+			);
+		}
+		if (!jafo) {
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+			if (dev)
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+				jafo = spin_is_locked(
+					dev->scsi_host_ptr->host_lock);
+#else
+				jafo = spin_is_locked(dev->scsi_host_ptr->lock);
+#endif
+#else
+			jafo = spin_is_locked(&io_request_lock);
+#endif
+		}
+		/* In case a print is issued *before* we are set up */
+		if (dev && !dev->FwDebugBufferSize &&
+		  (dev->FwDebugBuffer_P == (volatile u8 __iomem *)NULL)) {
+			spin_lock_init(&dev->PrintQueueLock);
+			INIT_LIST_HEAD(&dev->PrintQueue);
+			/*
+			 * Mark list and lock initialized, but not print
+			 * ability
+			 */
+			dev->FwDebugBuffer_P = (volatile u8 __iomem *)dev->dbg_base_mapped;
+		}
+		/*
+		 *	Print any queued items
+		 */
+		if (!jafo) {
+			struct aac_dev * aac;
+			extern struct list_head aac_devices; /* in linit.c */
+			int count;
+			struct PrintQueue * ooops = NULL;
+	
+			/* RePhil the 'lazy' pre-allocated Buckets */
+			for (count = sizeof(Spare)/sizeof(Spare[0]); count;) {
+				/*
+				 * We should not need GFP_ATOMIC, but we also
+				 * need to remain paranoid
+				 */
+				if (!ooops && !(ooops = kmalloc(
+				  PRINT_BUFFER_SIZE + sizeof(*ooops),
+				  GFP_KERNEL|GFP_ATOMIC)))
+					break;
+				--count;
+				/*
+				 * atomic_xchg works with ints, there is no
+				 * current support for ptrdiff_t which would
+				 * embody pointers as well. xchg in the intel
+				 * architecture is atomic for pointers, so we
+				 * will accept it's use as one means of
+				 * lockless handling of the pre-allocated list.
+				 */
+				ooops = xchg(&Spare[count], ooops);
+			}
+			list_for_each_entry(aac, &aac_devices, entry) {
+				int jafo1;
+				struct Scsi_Host * host;
+				unsigned long DebugFlags;
+	
+				if (list_empty(&aac->PrintQueue))
+					continue;
+				/* do not mull around too long */
+				count = sizeof(Spare)/sizeof(Spare[0]) + 1;
+				host = aac->scsi_host_ptr;
+				jafo1 = (
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,14)) || defined(SCSI_HAS_SHOST_STATE_ENUM))
+				  (SHOST_RECOVERY == host->shost_state)
+#elif (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+				  test_bit(SHOST_RECOVERY,
+					&host->shost_state) ||
+				  host->eh_active
+#else
+				  host->in_recovery || host->eh_active
+#endif
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+				  || spin_is_locked(host->host_lock)
+#else
+				  || spin_is_locked(host->lock)
+#endif
+#endif
+				);
+				if (!jafo1)
+					spin_lock_irqsave (
+						&aac->PrintQueueLock, pflags);
+				else if (!spin_trylock_irqsave (
+						&aac->PrintQueueLock, pflags))
+					continue;
+				DebugFlags = aac->FwDebugFlags;
+				do {
+					struct PrintQueue * item = list_entry(
+					  aac->PrintQueue.next,
+					  struct PrintQueue, entry);
+					aac->FwDebugFlags = item->DebugFlags;
+					if (aac_fw_send(aac, item->PrintFlags,
+					  item->PrintBuffer_P, jafo1))
+						break;
+					list_del(&item->entry);
+					kfree(item);
+				} while (--count &&
+				  !list_empty(&aac->PrintQueue));
+				aac->FwDebugFlags = DebugFlags;
+				spin_unlock_irqrestore (&aac->PrintQueueLock,
+					pflags);
+				if (!count)
+					printk(KERN_INFO "aac_fw_printf: you "
+					  "need a bigger buffer or a smaller "
+					  "hammer");
+				/* RePhil the lazy pre-allocated Buckets */
+				for (count = sizeof(Spare)/sizeof(Spare[0]);
+				  count;) {
+					if (!ooops && !(ooops = kmalloc(
+					  PRINT_BUFFER_SIZE + sizeof(*ooops),
+					  GFP_KERNEL|GFP_ATOMIC)))
+						break;
+					--count;
+					ooops = xchg(&Spare[count], ooops);
+				}
+			}
+			kfree(ooops);
+		}
+		if ((((PrintFlags
+		  & ~(HBA_FLAGS_DBG_KERNEL_PRINT_B|HBA_FLAGS_DBG_FW_PRINT_B)))
+		  && dev && !(dev->DebugFlags & PrintFlags))
+		 || (dev && !(dev->DebugFlags
+		   & (HBA_FLAGS_DBG_KERNEL_PRINT_B|HBA_FLAGS_DBG_FW_PRINT_B))))
+			return;
+		/*
+		 * Set up parameters and call sprintf function to format the
+		 * data
+		 */
+		va_start(args, fmt);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		vsnprintf(PrintBuffer_P, PRINT_BUFFER_SIZE, fmt, args);
+#else
+		vsprintf(PrintBuffer_P, fmt, args);
+#endif
+		PrintBuffer_P[PRINT_BUFFER_SIZE] = '\0';
+		va_end(args);
+	
+		if (dev) {
+#if 1
+			spin_lock_irqsave (&dev->PrintQueueLock, pflags);
+#else
+			if (!jafo)
+				spin_lock_irqsave (&dev->PrintQueueLock,
+					pflags);
+			else if (!spin_trylock_irqsave (&dev->PrintQueueLock,
+					pflags)) {
+				struct PrintQueue * item;
+	
+				/* Reuse jafo as an index into Spare */
+				jafo = 0;
+				do {
+					if ((item = xchg(&Spare[jafo], NULL)))
+						break;
+				} while (++jafo <
+					(sizeof(Spare)/sizeof(Spare[0])));
+				if (!item) {
+					printk(KERN_INFO "aac_fw_printf: "
+						"buffer empty 1\n");
+					return;
+				}
+				if (!item &&
+				/* Will cause a switch in interrupt context */
+				  !(item = kmalloc(
+				  strlen(PrintBuffer_P) + sizeof(*item),
+				  GFP_KERNEL|GFP_ATOMIC)))
+					return;
+				item->PrintFlags = PrintFlags;
+				item->DebugFlags = dev->FwDebugFlags;
+				strcpy(item->PrintBuffer_P, PrintBuffer_P);
+				/*
+				 * Danger, we are not locked but that is
+				 * why we are using spin_*_irqsave...
+				 */
+				list_add_tail(&item->entry, &dev->PrintQueue);
+				return;
+			}
+#endif
+			if (!list_empty(&dev->PrintQueue)
+			 || aac_fw_send(dev, PrintFlags, PrintBuffer_P, jafo)) {
+				struct PrintQueue * item = NULL;
+	
+				if (jafo) {
+					/* Reuse jafo as Spare index */
+					jafo = 0;
+					do {
+						if ((item = xchg(&Spare[jafo],
+								NULL)))
+							break;
+					} while (++jafo <
+					  (sizeof(Spare)/sizeof(Spare[0])));
+				}
+				if (!item) {
+#if 0
+					/*
+					 * if !item jafo actually same as
+					 * original purpose and not just an
+					 * index into the Spare array.
+					 */
+					if (jafo)
+						printk(KERN_INFO
+						  "aac_fw_printf: "
+						  "buffer empty 2\n");
+					else
+#endif
+					/*
+					 * Could cause a switch in interrupt
+					 * context
+					 */
+					item = kmalloc(
+					  strlen(PrintBuffer_P) + sizeof(*item),
+					  GFP_KERNEL|GFP_ATOMIC);
+				}
+				if (item) {
+					/*
+					 * Should print a warning on the
+					 * console if failed to buffer the
+					 * print, but we are already in more
+					 * trouble than we can handle if we
+					 * failed to get here.
+					 */
+					item->PrintFlags = PrintFlags;
+					item->DebugFlags = dev->FwDebugFlags;
+					strcpy(item->PrintBuffer_P,
+						PrintBuffer_P);
+					list_add_tail(&item->entry,
+						&dev->PrintQueue);
+				}
+			}
+			spin_unlock_irqrestore (&dev->PrintQueueLock, pflags);
+		} else
+			(void)aac_fw_send(dev, PrintFlags, PrintBuffer_P, jafo);
+	}
+}
+
+void aac_fw_print_mem(struct aac_dev * dev, unsigned long PrintFlags, u8 * Addr, int Count)
+{
+if (nblank(fwprintf(x)) || (aac_firmware_debug == 1)) {
+	int Offset, i;
+	u32 DebugFlags = 0;
+	char Buffer[100];
+	char * LineBuffer_P;
+
+	/*
+	 * If we have an HBA structure, save off the flags and set the no
+	 * headers flag so we don't have garbage between our lines of data
+	 */
+	if (dev != NULL) {
+		DebugFlags = dev->FwDebugFlags;
+		dev->FwDebugFlags |= FW_DEBUG_FLAGS_NO_HEADERS_B;
+	}
+
+	Offset = 0;
+
+	/*
+	 * Loop through all the data
+	 */
+	while (Offset < Count) {
+		/*
+		 * We will format each line into a buffer and then print out
+		 * the entire line so set the pointer to the beginning of the
+		 * buffer
+		 */
+		LineBuffer_P = Buffer;
+
+		/*
+		 * Set up the address in HEX
+		 */
+		sprintf(LineBuffer_P, "\n%04x  ", Offset);
+		LineBuffer_P += 6;
+
+		/*
+		 * Set up 16 bytes in HEX format
+		 */
+		for (i = 0; i < 16; ++i) {
+			/*
+			 * If we are past the count of data bytes to output,
+			 * pad with blanks
+			 */
+			sprintf (LineBuffer_P,
+			  (((Offset + i) >= Count) ? "   " : "%02x "),
+			  Addr[Offset + i]);
+			LineBuffer_P += 3;
+
+			/*
+			 * At the mid point we will put in a divider
+			 */
+			if (i == 7) {
+				sprintf (LineBuffer_P, "- ");
+				LineBuffer_P += 2;
+			}
+		}
+		/*
+		 * Now do the same 16 bytes at the end of the line in ASCII
+		 * format
+		 */
+		sprintf (LineBuffer_P, "  ");
+		LineBuffer_P += 2;
+		for (i = 0; i < 16; ++i) {
+			/*
+			 * If all data processed, OUT-O-HERE
+			 */
+			if ((Offset + i) >= Count)
+				break;
+
+			/*
+			 * If this is a printable ASCII character, convert it
+			 */
+			sprintf (LineBuffer_P,
+			  (((Addr[Offset + i] > 0x1F)
+			   && (Addr[Offset + i] < 0x7F))
+				? "%c"
+				: "."), Addr[Offset + i]);
+
+			++LineBuffer_P;
+		}
+		/*
+		 * The line is now formatted, so print it out
+		 */
+		aac_fw_printf(dev, PrintFlags, "%s", Buffer);
+
+		/*
+		 * Bump the offset by 16 for the next line
+		 */
+		Offset += 16;
+
+	}
+
+	/*
+	 * Restore the saved off flags
+	 */
+	if (dev != NULL)
+		dev->FwDebugFlags = DebugFlags;
+}
+}
+#endif
diff --git a/drivers/scsi/aacraid/fwdebug.h b/drivers/scsi/aacraid/fwdebug.h
new file mode 100644
index 0000000..385dc4a
--- /dev/null
+++ b/drivers/scsi/aacraid/fwdebug.h
@@ -0,0 +1,73 @@
+/*
+ *	Adaptec AAC series RAID controller driver
+ *
+ * Copyright (c) 2004-2007 Adaptec, Inc. (aacraid@adaptec.com)
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; see the file COPYING.  If not, write to
+ * the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ */
+
+#ifndef PRINT_BUFFER_SIZE
+
+#define PRINT_BUFFER_SIZE     512       /* Debugging print buffer size */
+
+#define HBA_FLAGS_DBG_FLAGS_MASK         0x0000ffff  /* Mask for debug flags */
+#define HBA_FLAGS_DBG_KERNEL_PRINT_B     0x00000001  /* Kernel Debugger Print */
+#define HBA_FLAGS_DBG_FW_PRINT_B         0x00000002  /* Firmware Debugger Print */
+#define HBA_FLAGS_DBG_FUNCTION_ENTRY_B   0x00000004  /* Function Entry Point */
+#define HBA_FLAGS_DBG_FUNCTION_EXIT_B    0x00000008  /* Function Exit */
+#define HBA_FLAGS_DBG_ERROR_B            0x00000010  /* Error Conditions */
+#define HBA_FLAGS_DBG_INIT_B             0x00000020  /* Init Prints */
+#define HBA_FLAGS_DBG_OS_COMMANDS_B      0x00000040  /* OS Command Info */
+#define HBA_FLAGS_DBG_SCAN_B             0x00000080  /* Device Scan */
+#define HBA_FLAGS_DBG_COALESCE_B         0x00000100  /* Coalescing Queueing flags */
+#define HBA_FLAGS_DBG_IOCTL_COMMANDS_B   0x00000200  /* IOCTL Command Info */
+#define HBA_FLAGS_DBG_SYNC_COMMANDS_B    0x00000400  /* SYNC Command Info */
+#define HBA_FLAGS_DBG_COMM_B             0x00000800  /* Comm Info */
+#define HBA_FLAGS_DBG_CSMI_COMMANDS_B    0x00001000  /* CSMI Command Info */
+#define HBA_FLAGS_DBG_AIF_B              0x00001000  /* Aif Info */
+
+#define FW_DEBUG_STR_LENGTH_OFFSET       0x00
+#define FW_DEBUG_FLAGS_OFFSET            0x04
+#define FW_DEBUG_BLED_OFFSET             0x08
+#define FW_DEBUG_FLAGS_NO_HEADERS_B      0x01 
+
+int aac_get_fw_debug_buffer(struct aac_dev *);
+void aac_fw_printf(struct aac_dev *, unsigned long, const char *, ...);
+void aac_fw_print_mem(struct aac_dev *, unsigned long, u8 *, int);
+
+#define	CT_GET_LOG_SIZE		189
+struct aac_get_log_size {
+	__le32	command;	/* VM_ContainerConfig & ST_OK response */
+	__le32	type;		/* CT_GET_LOG_SIZE */
+	__le32	index;
+	__le32	size;
+	__le32	count;
+};
+
+#define CT_GET_NVLOG_ENTRY	57
+struct aac_get_nvlog_entry {
+	__le32	command;	/* VM_ContainerConfig & ST_OK response */
+	__le32	type;		/* CT_GET_NVLOG_ENTRY */
+	__le32	status;		/* CT_OK response */
+	__le32	index;
+	__le32	count;
+	__le32	parm3;
+	__le32	parm4;
+	__le32	parm5;
+	u8	data[512-sizeof(__le32)*8-sizeof(struct aac_fibhdr)]; /* 448 */
+};
+
+#endif
diff --git a/drivers/scsi/aacraid/inject.c b/drivers/scsi/aacraid/inject.c
new file mode 100644
index 0000000..92fd484
--- /dev/null
+++ b/drivers/scsi/aacraid/inject.c
@@ -0,0 +1,145 @@
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <sys/stat.h>
+#include <stdint.h>
+
+#define BUF	255
+
+#define CTL_CODE(function, method) (                 \
+    (4<< 16) | ((function) << 2) | (method) \
+)
+#define METHOD_BUFFERED                 0
+#define METHOD_NEITHER                  3
+#define FSACTL_ERROR_INJECT		CTL_CODE(9000, METHOD_BUFFERED)
+struct aac_error_inject_str {
+	unsigned char	type;
+	unsigned char 	value;
+};
+
+
+int PrintHelp (int noHeader) 
+{
+	if (noHeader == 0) {
+		printf("\ninject revision 1.00		(c) 2014 PMC-Sierra, Inc.");
+
+		printf("\n-------------------------------------------------------");
+		printf("\nError injection tool");
+	}
+	printf("\n\nUsage");
+	printf("\ninject <type> <value>");
+	printf("\n<type>:  SCSI_ERROR | TGT_FAILURE");
+	printf("\n<value>: type==SCSI_ERROR:");
+	printf("\n\tCHECK_CONDITION | BUSY | RESERVATION_CONFLICT |");
+	printf("\n\tTASK_SET_FULL | TASK_ABORTED");
+	printf("\n<value>: type==TGT_FAILURE:");
+	printf("\n\tHBAMODE_DISABLED | IO_ERROR | IO_ABORTED | NO_PATH_TO_DEVICE |");
+	printf("\n\tNO_PATH_TO_DEVICE | INVALID_DEVICE | DEVICE_FAULT | UNDERRUN");
+	printf("\n");
+	return (0);
+}
+
+int GetMajor ()
+{
+	int major = -1;
+	FILE *f;
+	char buffer[BUF];
+
+	f = fopen("/proc/devices", "r");
+	if (f == NULL)
+		return(major);
+
+	while (fgets(buffer, BUF, f) != NULL) {
+		if (strstr(buffer, "aac") != NULL) {
+			major = atoi(buffer);
+			break;
+		}
+	}
+
+	fclose(f);
+	return(major);
+}
+				
+int main( int argc, char *argv[] )
+{
+	int i, major;
+	int hDevice = -1;
+	char dPath[] = "/dev/aac0";
+	char buffer[BUF];
+	struct aac_error_inject_str inj;
+
+	if (argc != 3) {
+        	PrintHelp(0);
+        	return(0);
+ 	}
+
+	if (!strcmp(argv[1], "SCSI_ERROR")) {
+		inj.type = 1;
+		if (!strcmp(argv[2], 		"CHECK_CONDITION"))
+			inj.value = 0;
+		else if (!strcmp(argv[2], 	"BUSY"))
+			inj.value = 1;
+		else if (!strcmp(argv[2], 	"RESERVATION_CONFLICT"))
+			inj.value = 2;
+		else if (!strcmp(argv[2], 	"TASK_SET_FULL"))
+			inj.value = 3;
+		else if (!strcmp(argv[2], 	"TASK_ABORTED"))
+			inj.value = 4;
+		else {
+			PrintHelp(1);
+			return(-1);
+		}
+	} else if (!strcmp(argv[1], "TGT_FAILURE")) {
+		inj.type = 2;
+		if (!strcmp(argv[2], 		"HBAMODE_DISABLED"))
+			inj.value = 0;
+		else if (!strcmp(argv[2], 	"IO_ERROR"))
+			inj.value = 1;
+		else if (!strcmp(argv[2], 	"IO_ABORTED"))
+			inj.value = 2;
+		else if (!strcmp(argv[2], 	"NO_PATH_TO_DEVICE"))
+			inj.value = 3;
+		else if (!strcmp(argv[2], 	"INVALID_DEVICE"))
+			inj.value = 4;
+		else if (!strcmp(argv[2], 	"DEVICE_FAULT"))
+			inj.value = 5;
+		else if (!strcmp(argv[2], 	"UNDERRUN"))
+			inj.value = 6;
+		else {
+			PrintHelp(1);
+			return(-1);
+		}
+	} else {
+		PrintHelp(1);
+		return(-1);
+	}
+
+	hDevice = open(dPath, O_RDWR);
+	if (hDevice == -1) {
+		if (errno != ENOENT) {
+			printf("\nOpen aac0 device failed, errno=%d\n", errno);
+			return(-1);
+		}
+		if ((major = GetMajor()) == -1) {
+			printf("\nOpen failed, driver not loaded?\n");
+			return(-1);
+		}
+		sprintf(buffer, "mknod %s c %d 0", dPath, major);
+		system(buffer);	
+		hDevice = open(dPath, O_RDWR);
+		if (hDevice == -1) {
+			printf("\nOpen aac0 device failed, errno=%d\n", errno);
+			return(-1);
+		}
+	}
+
+	printf("Inject type %d value %d\n", inj.type, inj.value);
+	if (ioctl(hDevice, FSACTL_ERROR_INJECT, &inj) == -1) {
+		printf("\nIOCTL failed, errno=%d\n", errno);
+	}
+
+	close(dPath);
+	return(0);
+} 
diff --git a/drivers/scsi/aacraid/linit.c b/drivers/scsi/aacraid/linit.c
index 4921ed1..ee21568 100644
--- a/drivers/scsi/aacraid/linit.c
+++ b/drivers/scsi/aacraid/linit.c
@@ -1,12 +1,11 @@
 /*
  *	Adaptec AAC series RAID controller driver
- *	(c) Copyright 2001 Red Hat Inc.
+ *	(c) Copyright 2001 Red Hat Inc.	<alan@redhat.com>
  *
  * based on the old aacraid driver that is..
  * Adaptec aacraid device driver for Linux.
  *
- * Copyright (c) 2000-2010 Adaptec, Inc.
- *               2010 PMC-Sierra, Inc. (aacraid@pmc-sierra.com)
+ * Copyright (c) 2000-2007 Adaptec, Inc. (aacraid@adaptec.com)
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -29,57 +28,263 @@
  */
 
 
+#include <linux/version.h> /* for the following test */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,3))
 #include <linux/compat.h>
+#endif
+#if (!defined(UTS_RELEASE) && ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)) && LINUX_VERSION_CODE < KERNEL_VERSION(2,6,33)) && !defined(__VMKLNX__))
+#include <linux/utsrelease.h>
+#endif
+#if (defined(HAS_COMPILE_H) && (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,10)) && !defined(CONFIG_COMMUNITY_KERNEL) && !defined(UTS_MACHINE))
+#include <linux/compile.h>
+#endif
 #include <linux/blkdev.h>
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,2))
 #include <linux/completion.h>
+#endif
 #include <linux/init.h>
 #include <linux/interrupt.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,3))
 #include <linux/moduleparam.h>
+#else
+#include <linux/config.h>
+#include <linux/types.h>
+#include <linux/sched.h>
+#endif
 #include <linux/pci.h>
-#include <linux/pci-aspm.h>
 #include <linux/slab.h>
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0))
+#include <linux/smp_lock.h>
+#else
 #include <linux/mutex.h>
+#endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,30))
+#include <linux/pci-aspm.h>
+#endif
 #include <linux/spinlock.h>
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,3))
+#if (!defined(__VMKLNX30__) && !defined(__VMKLNX__))
 #include <linux/syscalls.h>
+#else
+#if defined(__ESX5__)
+#include "vmklinux_9/vmklinux_scsi.h"
+#else
+#include "vmklinux26/vmklinux26_scsi.h"
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,13))
+#include <linux/ioctl32.h>
+#endif
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,9)) || defined(SCSI_HAS_SSLEEP)
 #include <linux/delay.h>
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,5)) || defined(HAS_KTHREAD))
 #include <linux/kthread.h>
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+#include <asm/semaphore.h>
+#endif
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 #include <scsi/scsi.h>
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,1)) && !defined(FAILED))
+#define SUCCESS 0x2002
+#define FAILED  0x2003
+#endif
 #include <scsi/scsi_cmnd.h>
 #include <scsi/scsi_device.h>
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,10)) && defined(DID_BUS_BUSY) && !defined(BLIST_NO_ULD_ATTACH))
+#include <scsi/scsi_devinfo.h>	/* Pick up BLIST_NO_ULD_ATTACH? */
+#endif
 #include <scsi/scsi_host.h>
 #include <scsi/scsi_tcq.h>
 #include <scsi/scsicam.h>
 #include <scsi/scsi_eh.h>
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,7)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,10)) && !defined(BLIST_NO_ULD_ATTACH))
+#define no_uld_attach inq_periph_qual
+#elif ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,7)) && !defined(BLIST_NO_ULD_ATTACH))
+#define no_uld_attach hostdata
+#endif
+#else
+#include "scsi.h"
+#include "hosts.h"
+#include "sd.h"
+#define no_uld_attach hostdata
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) && defined(SCSI_HAS_DUMP))
+#include "scsi_dump.h"
+#endif
+#include <linux/blk.h>	/* for io_request_lock definition */
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11))
+#if (((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) ? defined(__x86_64__) : defined(CONFIG_COMPAT)) && !defined(HAS_BOOT_CONFIG))
+#if ((KERNEL_VERSION(2,4,19) <= LINUX_VERSION_CODE) && (LINUX_VERSION_CODE <= KERNEL_VERSION(2,4,21)))
+# include <asm-x86_64/ioctl32.h>
+#elif (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+# include <asm/ioctl32.h>
+#elif (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,3))
+# include <linux/ioctl32.h>
+#endif
+  /* Cast the function, since sys_ioctl does not match */
+# define aac_ioctl32(x,y) register_ioctl32_conversion((x), \
+    (int(*)(unsigned int,unsigned int,unsigned long,struct file*))(y))
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+# include <asm/uaccess.h>
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,11)) && !defined(PCI_HAS_SHUTDOWN)))
+#include <linux/reboot.h>
+#endif
+
+// in aacraid.h
+#if (!defined(CONFIG_COMMUNITY_KERNEL) && !defined(CONFIG_DISKDUMP) && !defined(CONFIG_DISKDUMP_MODULE) && !defined(CONFIG_CRASH_DUMP) && !defined(CONFIG_CRASH_DUMP_MODULE))
+#undef SCSI_HAS_DUMP
+#endif
+#if (defined(HAS_KDUMP_CONFIG))
+#undef SCSI_HAS_DUMP
+#endif
+#if (defined(SCSI_HAS_DUMP))
+#if (defined(HAS_DISKDUMP_H))
+#include <linux/diskdump.h>
+#endif
+#if (defined(lkcd_dump_mode) && !defined(crashdump_mode))
+# define crashdump_mode() lkcd_dump_mode()
+#endif
+//
+static void aac_poll(struct scsi_device *);
+#if (!defined(HAS_DUMP_SSLEEP) && (defined(HAS_DISKDUMPLIB_H) || defined(crashdump_mode)) && (defined(CONFIG_DISKDUMP) || defined(CONFIG_DISKDUMP_MODULE) || defined(CONFIG_CRASH_DUMP) || defined(CONFIG_CRASH_DUMP_MODULE)))
+
+#if (defined(HAS_DISKDUMPLIB_H))
+#include <linux/diskdumplib.h>
+#endif
+
+/* partial compat.h, prior to aacraid.h's pollution of definitions */
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,9)) && !defined(SCSI_HAS_SSLEEP))
+#undef ssleep
+#define ssleep(x) scsi_sleep((x)*HZ)
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,7)) && !defined(HAS_MSLEEP))
+#define msleep(x) set_current_state(TASK_UNINTERRUPTIBLE); schedule_timeout(x)
+#endif
+#if (!defined(HAS_DUMP_MDELAY))
+#include <linux/delay.h>
+#endif
+
+void aac_diskdump_msleep(unsigned int msecs)
+{
+	if (crashdump_mode()) {
+#if (defined(HAS_DUMP_MDELAY))
+		diskdump_mdelay(msecs);
+#else
+		mdelay(msecs);
+#endif
+#if (defined(HAS_DISKDUMPLIB_H))
+		diskdump_update();
+#endif
+	} else {
+		msleep(msecs);
+	}
+}
+
+#include <linux/nmi.h>
+
+void aac_diskdump_ssleep(unsigned int seconds)
+{
+	unsigned int i;
+
+	if (crashdump_mode()) {
+		for (i = 0; i < seconds; i++) {
+#if (defined(HAS_DUMP_MDELAY))
+			diskdump_mdelay(1000);
+#else
+			mdelay(1000);
+#endif
+#if (!defined(HAS_DUMP_MDELAY))
+			touch_nmi_watchdog();
+#endif
+#if (defined(HAS_DISKDUMPLIB_H))
+			diskdump_update();
+#endif
+		}
+	} else {
+		ssleep(seconds);
+	}
+}
 
+#if (defined(HAS_DUMP_MDELAY))
+void aac_diskdump_mdelay(unsigned int msec)
+{
+	diskdump_mdelay(msec);
+}
+#endif
+#endif
+#endif
 #include "aacraid.h"
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#include "fwdebug.h"
+#endif
+
+#if (defined(__VMKLNX__))
+#define ESX4X_AAC_DRIVER_VERSION	"1.2.1"
+#else
+#define AAC_DRIVER_VERSION		"1.2-1"
+#endif
 
-#define AAC_DRIVER_VERSION		"1.2-0"
 #ifndef AAC_DRIVER_BRANCH
 #define AAC_DRIVER_BRANCH		""
 #endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+#define AAC_DRIVER_BUILD_DATE		__DATE__
+#else
+#define AAC_DRIVER_BUILD_DATE		__DATE__ " " __TIME__
+#endif
 #define AAC_DRIVERNAME			"aacraid"
 
-#ifdef AAC_DRIVER_BUILD
+#if (defined(AAC_DRIVER_BUILD))
 #define _str(x) #x
 #define str(x) _str(x)
-#define AAC_DRIVER_FULL_VERSION	AAC_DRIVER_VERSION "[" str(AAC_DRIVER_BUILD) "]" AAC_DRIVER_BRANCH
+#if (defined(__VMKLNX__))
+#define AAC_DRIVER_FULL_VERSION ESX4X_AAC_DRIVER_VERSION "." str(AAC_DRIVER_BUILD)
+#else
+#define AAC_DRIVER_FULL_VERSION	AAC_DRIVER_VERSION "." str(AAC_DRIVER_BUILD) "" AAC_DRIVER_BRANCH
+#endif
 #else
-#define AAC_DRIVER_FULL_VERSION	AAC_DRIVER_VERSION AAC_DRIVER_BRANCH
+#define AAC_DRIVER_FULL_VERSION	AAC_DRIVER_VERSION AAC_DRIVER_BRANCH " " AAC_DRIVER_BUILD_DATE
+#endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+spinlock_t io_request_lock;
 #endif
 
 MODULE_AUTHOR("Red Hat Inc and Adaptec");
 MODULE_DESCRIPTION("Dell PERC2, 2/Si, 3/Si, 3/Di, "
 		   "Adaptec Advanced Raid Products, "
 		   "HP NetRAID-4M, IBM ServeRAID & ICP SCSI driver");
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,7))
 MODULE_LICENSE("GPL");
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,3)) || defined(MODULE_VERSION))
 MODULE_VERSION(AAC_DRIVER_FULL_VERSION);
-
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,0,0))
 static DEFINE_MUTEX(aac_mutex);
+#endif
+#if (defined(AAC_CSMI))
+extern struct list_head aac_devices;
+LIST_HEAD(aac_devices);
+#else
+#if (defined(CONFIG_COMMUNITY_KERNEL))
 static LIST_HEAD(aac_devices);
+#else
+extern struct list_head aac_devices;
+LIST_HEAD(aac_devices); /* fwprint */
+#endif
+#endif
+#if (!defined(HAS_BOOT_CONFIG))
 static int aac_cfg_major = -1;
+#endif
 char aac_driver_version[] = AAC_DRIVER_FULL_VERSION;
 
 /*
@@ -88,7 +293,17 @@ char aac_driver_version[] = AAC_DRIVER_FULL_VERSION;
  *
  * Note: The last field is used to index into aac_drivers below.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,8,0))
+#ifdef DECLARE_PCI_DEVICE_TABLE
+static DECLARE_PCI_DEVICE_TABLE(aac_pci_tbl) = {
+#elif (defined(__devinitconst))
+static const struct pci_device_id aac_pci_tbl[] __devinitconst = {
+#else
+static const struct pci_device_id aac_pci_tbl[] __devinitdata = {
+#endif
+#else
 static const struct pci_device_id aac_pci_tbl[] = {
+#endif
 	{ 0x1028, 0x0001, 0x1028, 0x0001, 0, 0, 0 }, /* PERC 2/Si (Iguana/PERC2Si) */
 	{ 0x1028, 0x0002, 0x1028, 0x0002, 0, 0, 1 }, /* PERC 3/Di (Opal/PERC3Di) */
 	{ 0x1028, 0x0003, 0x1028, 0x0003, 0, 0, 2 }, /* PERC 3/Si (SlimFast/PERC3Si */
@@ -181,8 +396,8 @@ static struct aac_driver_ident aac_drivers[] = {
 	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT | AAC_QUIRK_34SG | AAC_QUIRK_SCSI_32 }, /* PERC 3/Di (Boxster/PERC3DiB) */
 	{ aac_rx_init, "aacraid",  "ADAPTEC ", "catapult        ", 2, AAC_QUIRK_31BIT | AAC_QUIRK_34SG | AAC_QUIRK_SCSI_32 }, /* catapult */
 	{ aac_rx_init, "aacraid",  "ADAPTEC ", "tomcat          ", 2, AAC_QUIRK_31BIT | AAC_QUIRK_34SG | AAC_QUIRK_SCSI_32 }, /* tomcat */
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 2120S   ", 1, AAC_QUIRK_31BIT | AAC_QUIRK_34SG },		      /* Adaptec 2120S (Crusader) */
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 2200S   ", 2, AAC_QUIRK_31BIT | AAC_QUIRK_34SG },		      /* Adaptec 2200S (Vulcan) */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 2120S   ", 1, AAC_QUIRK_31BIT | AAC_QUIRK_34SG },		       /* Adaptec 2120S (Crusader) */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 2200S   ", 2, AAC_QUIRK_31BIT | AAC_QUIRK_34SG },		       /* Adaptec 2200S (Vulcan) */
 	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 2200S   ", 2, AAC_QUIRK_31BIT | AAC_QUIRK_34SG | AAC_QUIRK_SCSI_32 }, /* Adaptec 2200S (Vulcan-2m) */
 	{ aac_rx_init, "aacraid",  "Legend  ", "Legend S220     ", 1, AAC_QUIRK_31BIT | AAC_QUIRK_34SG | AAC_QUIRK_SCSI_32 }, /* Legend S220 (Legend Crusader) */
 	{ aac_rx_init, "aacraid",  "Legend  ", "Legend S230     ", 2, AAC_QUIRK_31BIT | AAC_QUIRK_34SG | AAC_QUIRK_SCSI_32 }, /* Legend S230 (Legend Vulcan) */
@@ -234,13 +449,107 @@ static struct aac_driver_ident aac_drivers[] = {
 	{ aac_rx_init, "aacraid",  "Legend  ", "RAID            ", 2, AAC_QUIRK_31BIT | AAC_QUIRK_34SG | AAC_QUIRK_SCSI_32 }, /* Legend Catchall */
 	{ aac_rx_init, "aacraid",  "ADAPTEC ", "RAID            ", 2 }, /* Adaptec Catch All */
 	{ aac_rkt_init, "aacraid", "ADAPTEC ", "RAID            ", 2 }, /* Adaptec Rocket Catch All */
-	{ aac_nark_init, "aacraid", "ADAPTEC ", "RAID           ", 2 }, /* Adaptec NEMER/ARK Catch All */
+	{ aac_nark_init, "aacraid", "ADAPTEC ", "RAID            ", 2 }, /* Adaptec NEMER/ARK Catch All */
 	{ aac_src_init, "aacraid", "ADAPTEC ", "RAID            ", 2 }, /* Adaptec PMC Series 6 (Tupelo) */
 	{ aac_srcv_init, "aacraid", "ADAPTEC ", "RAID            ", 2 }, /* Adaptec PMC Series 7 (Denali) */
 	{ aac_srcv_init, "aacraid", "ADAPTEC ", "RAID            ", 2 }, /* Adaptec PMC Series 8 */
 	{ aac_srcv_init, "aacraid", "ADAPTEC ", "RAID            ", 2 } /* Adaptec PMC Series 9 */
 };
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11))
+
+#if (((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) ? defined(__x86_64__) : defined(CONFIG_COMPAT)) && !defined(HAS_BOOT_CONFIG))
+/*
+ * Promote 32 bit apps that call get_next_adapter_fib_ioctl to 64 bit version
+ */
+static int aac_get_next_adapter_fib_ioctl(unsigned int fd, unsigned int cmd,
+		unsigned long arg, struct file *file)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	struct fib_ioctl f;
+	mm_segment_t fs;
+	int retval;
+
+	memset (&f, 0, sizeof(f));
+	if (copy_from_user(&f, (void __user *)arg, sizeof(f) - sizeof(u32)))
+		return -EFAULT;
+	fs = get_fs();
+	set_fs(get_ds());
+	retval = sys_ioctl(fd, cmd, (unsigned long)&f);
+	set_fs(fs);
+	return retval;
+#else
+	struct fib_ioctl __user *f;
 
+	f = compat_alloc_user_space(sizeof(*f));
+	if (!access_ok(VERIFY_WRITE, f, sizeof(*f)))
+		return -EFAULT;
+
+	clear_user(f, sizeof(*f));
+	if (copy_in_user(f, (void __user *)arg, sizeof(*f) - sizeof(u32)))
+		return -EFAULT;
+
+	return sys_ioctl(fd, cmd, (unsigned long)f);
+#endif
+}
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+#define sys_ioctl NULL	/* register_ioctl32_conversion defaults to this when NULL passed in as a handler */
+#endif
+#endif
+
+#endif
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,5,0))
+#if (!defined(SCSI_HAS_SCSI_IN_DETECTION) && !defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__) && !defined(__VMKLNX__))
+static struct Scsi_Host * aac_dummy;
+#endif
+
+/**
+ *	aac_detect	-	Probe for aacraid cards
+ *	@template: SCSI driver template
+ *
+ *	This is but a stub to convince the 2.4 scsi layer to scan targets,
+ *	the pci scan has already picked up the adapters.
+ */
+static int aac_detect(Scsi_Host_Template *template)
+{
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+	printk(KERN_INFO "aac_detect(%p)\n", template);
+#endif
+#if (defined(__VMKERNEL_MODULE__) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,4)))
+	if (!VmkLinux_SetModuleVersion(AAC_DRIVERNAME " (" AAC_DRIVER_FULL_VERSION ")")) {
+		return 0;
+	}
+#endif
+#if (!defined(SCSI_HAS_SCSI_IN_DETECTION) && !defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__) && !defined(__VMKLNX__))
+	/* By changing the host list we trick a scan */
+	if (aac_dummy) {
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+		printk(KERN_INFO "scsi_host_put(%p)\n", aac_dummy);
+#endif
+		scsi_host_put(aac_dummy);
+		aac_dummy = NULL;
+	}
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+	printk(KERN_INFO "aac_detect()=%d\n", !list_empty(&aac_devices));
+#endif
+	return !list_empty(&aac_devices);
+#else
+	return template->present = 1;
+#endif
+}
+
+#endif
+
+#if (defined(__VMKERNEL_MODULE__) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,4)))
+static void __devexit aac_remove_one(struct pci_dev *pdev);
+
+static int aac_release(struct Scsi_Host *sh) {
+	struct aac_dev *aac = (struct aac_dev *)sh->hostdata;
+
+	if (aac)
+		aac_remove_one(aac->pdev);
+	return 0;
+}
+#endif
 /**
  *	aac_queuecommand	-	queue a SCSI command
  *	@cmd:		SCSI command to queue
@@ -251,26 +560,132 @@ static struct aac_driver_ident aac_drivers[] = {
  *	TODO: unify with aac_scsi_cmd().
  */
 
-static int aac_queuecommand_lck(struct scsi_cmnd *cmd, void (*done)(struct scsi_cmnd *))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,37))
+static int aac_queuecommand(struct scsi_cmnd *cmd, void (*done)(struct scsi_cmnd *))
+#else
+static int aac_queuecommand(struct Scsi_Host *shost, struct scsi_cmnd *cmd)
+#endif
 {
-	struct Scsi_Host *host = cmd->device->host;
-	struct aac_dev *dev = (struct aac_dev *)host->hostdata;
-	u32 count = 0;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,37))
+	int r = 0;  
+#endif
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,6)) && !defined(SCSI_DEVICE_HAS_TIMEOUT))
+	struct scsi_device *device = cmd->device;
+	struct Scsi_Host *host = device->host;
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_TIMING))
+	u64 lba;
+	struct timeval now;
+	do_gettimeofday(&now);
+	if ((cmd->cmnd[0] == WRITE_6)	/* 6 byte command */
+	 || (cmd->cmnd[0] == READ_6)) {
+		lba = ((cmd->cmnd[1] & 0x1F) << 16)
+		    | (cmd->cmnd[2] << 8) | cmd->cmnd[3];
+		count = cmd->cmnd[4];
+		if (count == 0)
+			count = 256;
+#if (defined(WRITE_16))
+	} else if ((cmd->cmnd[0] == WRITE_16) /* 16 byte command */
+	 || (cmd->cmnd[0] == READ_16)) {
+		lba = ((u64)cmd->cmnd[2] << 56)
+		    | ((u64)cmd->cmnd[3] << 48)
+		    | ((u64)cmd->cmnd[4] << 40)
+		    | ((u64)cmd->cmnd[9] << 32)
+		    | (cmd->cmnd[6] << 24)
+		    | (cmd->cmnd[7] << 16)
+		    | (cmd->cmnd[8] << 8) | cmd->cmnd[9];
+		count = (cmd->cmnd[10] << 24)
+		      | (cmd->cmnd[11] << 16)
+		      | (cmd->cmnd[12] << 8) | cmd->cmnd[13];
+#endif
+	} else if ((cmd->cmnd[0] == WRITE_12) /* 12 byte command */
+	 || (cmd->cmnd[0] == READ_12)) {
+		lba = (cmd->cmnd[2] << 24)
+		    | (cmd->cmnd[3] << 16)
+		    | (cmd->cmnd[4] << 8) | cmd->cmnd[5];
+		count = (cmd->cmnd[6] << 24)
+		      | (cmd->cmnd[7] << 16)
+		      | (cmd->cmnd[8] << 8) | cmd->cmnd[9];
+	} else if ((cmd->cmnd[0] == WRITE_10) /* 10 byte command */
+	 || (cmd->cmnd[0] == READ_10)) {
+		lba = (cmd->cmnd[2] << 24)
+		    | (cmd->cmnd[3] << 16)
+		    | (cmd->cmnd[4] << 8) | cmd->cmnd[5];
+		count = (cmd->cmnd[7] << 8) | cmd->cmnd[8];
+	} else
+		lba = (u64)(uintptr_t)cmd;
+	printk(((count)
+	  ? KERN_DEBUG "%lu.%06lu q%lu %llu[%u]\n"
+	  : KERN_DEBUG "%lu.%06lu q%lu 0x%llx\n"),
+	  now.tv_sec % 100, now.tv_usec,
+	  (unsigned long)(atomic_read(&dev->queues->queue[
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	    (dev->comm_interface == AAC_COMM_APRE)
+	      ? ApreCmdQueue
+	      : AdapNormCmdQueue
+#else
+	    AdapNormCmdQueue
+#endif
+	  ].numpending)), (unsigned long long)lba, count);
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  ((count)
+	    ? "%lu.%06lu q%lu %llu[%u]"
+	    : "%lu.%06lu q%lu 0x%llx"),
+	  now.tv_sec % 100, now.tv_usec,
+	  (unsigned long)(atomic_read(&dev->queues->queue[
+	    (dev->comm_interface == AAC_COMM_APRE)
+	      ? ApreCmdQueue
+	      : AdapNormCmdQueue
+	  ].numpending)), (unsigned long long)lba, count));
+#else
+	fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+	  ((count)
+	    ? "%lu.%06lu q%lu %llu[%u]"
+	    : "%lu.%06lu q%lu 0x%llx"),
+	  now.tv_sec % 100, now.tv_usec,
+	  (unsigned long)(atomic_read(&dev->queues->queue[
+	    AdapNormCmdQueue
+	  ].numpending)), (unsigned long long)lba, count));
+#endif
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+	if (dev->shutdown) {
+		printk(KERN_INFO
+		  "aac_queuecommand(%p={.cmnd[0]=%x},%p) post-shutdown\n",
+		  cmd, cmd->cmnd[0], done);
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "aac_queuecommand(%p={.cmnd[0]=%x},%p) post-shutdown\n",
+		  cmd, cmd->cmnd[0], done));
+	}
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,37))
 	cmd->scsi_done = done;
-	for (; count < (host->can_queue + AAC_NUM_MGT_FIB); ++count) {
-		struct fib * fib = &dev->fibs[count];
-		struct scsi_cmnd * command;
-		if (fib->hw_fib_va->header.XferState &&
-		    ((command = fib->callback_data)) &&
-		    (command == cmd) &&
-		    (cmd->SCp.phase == AAC_OWNER_FIRMWARE))
-			return 0; /* Already owned by Adapter */
+#endif
+
+
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,6)) && !defined(SCSI_DEVICE_HAS_TIMEOUT))
+	if ((cmd->eh_state != SCSI_STATE_QUEUED)
+	 && (device->type == TYPE_DISK)
+	 && (sdev_channel(device) == CONTAINER_CHANNEL)
+	 && (cmd->eh_timeout.expires < (60 * HZ))) {
+		/* The controller is doing error recovery */
+		mod_timer(&cmd->eh_timeout, 60 * HZ);
 	}
+#endif
 	cmd->SCp.phase = AAC_OWNER_LOWLEVEL;
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	return (aac_adapter_scsi_cmd(dev, cmd) ? FAILED : 0);
+#else
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,37))
 	return (aac_scsi_cmd(cmd) ? FAILED : 0);
+#else
+	r = (aac_scsi_cmd(cmd) ? FAILED : 0);
+	return r;
+#endif
+#endif
 }
 
-static DEF_SCSI_QCMD(aac_queuecommand)
 
 /**
  *	aac_info		-	Returns the host adapter name
@@ -281,7 +696,21 @@ static DEF_SCSI_QCMD(aac_queuecommand)
 
 static const char *aac_info(struct Scsi_Host *shost)
 {
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,5,0))
+	struct aac_dev *dev;
+#if (!defined(SCSI_HAS_SCSI_IN_DETECTION) && !defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__) && !defined(__VMKLNX__))
+	if (shost == aac_dummy)
+		return shost->hostt->name;
+#endif
+	dev = (struct aac_dev *)shost->hostdata;
+	if (!dev
+	 || (dev->cardtype >= (sizeof(aac_drivers)/sizeof(aac_drivers[0]))))
+		return shost->hostt->name;
+	if (dev->scsi_host_ptr != shost)
+		return shost->hostt->name;
+#else
 	struct aac_dev *dev = (struct aac_dev *)shost->hostdata;
+#endif
 	return aac_drivers[dev->cardtype].name;
 }
 
@@ -299,6 +728,10 @@ struct aac_driver_ident* aac_get_driver_ident(int devtype)
 
 /**
  *	aac_biosparm	-	return BIOS parameters for disk
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+ *	@disk: SCSI disk object to process
+ *	@device: kdev_t of the disk in question
+#endif
  *	@sdev: The scsi device corresponding to the disk
  *	@bdev: the block device corresponding to the disk
  *	@capacity: the sector capacity of the disk
@@ -319,11 +752,20 @@ struct aac_driver_ident* aac_get_driver_ident(int devtype)
  *	be displayed.
  */
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 static int aac_biosparm(struct scsi_device *sdev, struct block_device *bdev,
 			sector_t capacity, int *geom)
+#else
+static int aac_biosparm(Scsi_Disk *disk, kdev_t dev, int *geom)
+#endif
 {
 	struct diskparm *param = (struct diskparm *)geom;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 	unsigned char *buf;
+#else
+	struct buffer_head * buf;
+	sector_t capacity = disk->capacity;
+#endif
 
 	dprintk((KERN_DEBUG "aac_biosparm.\n"));
 
@@ -351,11 +793,20 @@ static int aac_biosparm(struct scsi_device *sdev, struct block_device *bdev,
 	 *	entry whose end_head matches one of the standard geometry
 	 *	translations ( 64/32, 128/32, 255/63 ).
 	 */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 	buf = scsi_bios_ptable(bdev);
+#else
+	buf = bread(MKDEV(MAJOR(dev), MINOR(dev)&~0xf), 0, block_size(dev));
+#endif
 	if (!buf)
 		return 0;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 	if(*(__le16 *)(buf + 0x40) == cpu_to_le16(0xaa55)) {
 		struct partition *first = (struct partition * )buf;
+#else
+	if(*(unsigned short *)(buf->b_data + 0x1fe) == cpu_to_le16(0xaa55)) {
+		struct partition *first = (struct partition * )(buf->b_data + 0x1be);
+#endif
 		struct partition *entry = first;
 		int saved_cylinders = param->cylinders;
 		int num;
@@ -398,10 +849,15 @@ static int aac_biosparm(struct scsi_device *sdev, struct block_device *bdev,
 					param->heads, param->sectors));
 		}
 	}
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 	kfree(buf);
+#else
+	brelse(buf);
+#endif
 	return 0;
 }
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 /**
  *	aac_slave_configure		-	compute queue depths
  *	@sdev:	SCSI device we are considering
@@ -414,20 +870,56 @@ static int aac_biosparm(struct scsi_device *sdev, struct block_device *bdev,
 static int aac_slave_configure(struct scsi_device *sdev)
 {
 	struct aac_dev *aac = (struct aac_dev *)sdev->host->hostdata;
-	if (aac->jbod && (sdev->type == TYPE_DISK))
-		sdev->removable = 1;
-	if ((sdev->type == TYPE_DISK) &&
+	int chn, is_native_device = 0;
+
+	chn = aac_logical_to_phys(sdev_channel(sdev));
+	if (aac->hba_map[chn][sdev_id(sdev)].devtype == AAC_DEVTYPE_NATIVE_RAW)
+		is_native_device = 1;
+
+//#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,11)) && !defined(BLIST_RETRY_HWERROR))
+//	if (sdev_channel(sdev) == CONTAINER_CHANNEL)
+//		sdev->retry_hwerror = 1;
+//#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,7)) && !defined(BLIST_NO_ULD_ATTACH))
+	sdev->no_uld_attach = 0;
+#endif
+	if (!is_native_device) {
+		if (aac->jbod && (sdev->type == TYPE_DISK))
+			sdev->removable = 1;
+		if ((sdev->type == TYPE_DISK) &&
 			(sdev_channel(sdev) != CONTAINER_CHANNEL) &&
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,7))
 			(!aac->jbod || sdev->inq_periph_qual) &&
+#else
+			(!aac->jbod || (sdev->inquiry[0] >> 5)) &&
+#endif
 			(!aac->raid_scsi_mode || (sdev_channel(sdev) != 2))) {
-		if (expose_physicals == 0)
-			return -ENXIO;
-		if (expose_physicals < 0)
-			sdev->no_uld_attach = 1;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,14))
+			if (expose_physicals == 0)
+				return -ENXIO;
+#endif
+			if (expose_physicals < 0)
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,10)) && !defined(BLIST_NO_ULD_ATTACH))
+			{
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,7)) && !defined(BLIST_NO_ULD_ATTACH))
+				sdev->no_uld_attach = (void *)1;
+#else
+				sdev->no_uld_attach = 1;
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,10)) && !defined(BLIST_NO_ULD_ATTACH))
+				/* Force it not to match sd */
+				sdev->inquiry[0] |= 1 << 5;
+				sdev->type = TYPE_DISK | (1 << 5);
+			}
+#endif
+		}
 	}
-	if (sdev->tagged_supported && (sdev->type == TYPE_DISK) &&
+
+	if (is_native_device || 
+		(sdev->tagged_supported && (sdev->type == TYPE_DISK) &&
 			(!aac->raid_scsi_mode || (sdev_channel(sdev) != 2)) &&
-			!sdev->no_uld_attach) {
+			!sdev->no_uld_attach)) {
 		struct scsi_device * dev;
 		struct Scsi_Host *host = sdev->host;
 		unsigned num_lsu = 0;
@@ -435,39 +927,145 @@ static int aac_slave_configure(struct scsi_device *sdev)
 		unsigned depth;
 		unsigned cid;
 
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,6)) || defined(SCSI_DEVICE_HAS_TIMEOUT))
 		/*
 		 * Firmware has an individual device recovery time typically
 		 * of 35 seconds, give us a margin.
 		 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,27))
+		if (sdev->timeout < (45 * HZ))
+			sdev->timeout = 45 * HZ;
+#else
 		if (sdev->request_queue->rq_timeout < (45 * HZ))
 			blk_queue_rq_timeout(sdev->request_queue, 45*HZ);
-		for (cid = 0; cid < aac->maximum_num_containers; ++cid)
-			if (aac->fsa_dev[cid].valid)
-				++num_lsu;
-		__shost_for_each_device(dev, host) {
-			if (dev->tagged_supported && (dev->type == TYPE_DISK) &&
+#endif
+#endif
+		if (!is_native_device) {
+			for (cid = 0; cid < aac->maximum_num_containers; ++cid)
+				if (aac->fsa_dev[cid].valid)
+					++num_lsu;
+			__shost_for_each_device(dev, host) {
+				if (dev->tagged_supported &&
+					(dev->type == TYPE_DISK) &&
 					(!aac->raid_scsi_mode ||
 						(sdev_channel(sdev) != 2)) &&
 					!dev->no_uld_attach) {
+				 if ((sdev_channel(dev) != CONTAINER_CHANNEL)
+				  || !aac->fsa_dev[sdev_id(dev)].valid)
+					++num_lsu;
+				} else
+				 ++num_one;
+			}
+			if (num_lsu == 0)
+				++num_lsu;
+			depth = (host->can_queue - num_one) / num_lsu;
+			if (depth > 256)
+				depth = 256;
+			else if (depth < 2)
+				depth = 2;
+			scsi_adjust_queue_depth(sdev, MSG_ORDERED_TAG, depth);
+		} else {
+			scsi_adjust_queue_depth(sdev, MSG_ORDERED_TAG, 32);
+		}
+
+#if (!defined(__ESX5__) && (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,24)) && !defined(PCI_HAS_SET_DMA_MAX_SEG_SIZE))
+		if (sdev->request_queue) {
+			if (!(((struct aac_dev *)host->hostdata)->adapter_info.options &
+				AAC_OPT_NEW_COMM))
+				blk_queue_max_segment_size(sdev->request_queue, 65536);
+			else
+				blk_queue_max_segment_size(sdev->request_queue,
+					host->max_sectors << 9);
+		}
+#endif
+	} else
+		scsi_adjust_queue_depth(sdev, 0, 1);
+
+#if (((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,6)) || defined(SCSI_DEVICE_HAS_TIMEOUT)) && defined(AAC_EXTENDED_TIMEOUT))
+	{
+		extern int extendedtimeout;
+
+		if (extendedtimeout != -1)
+			sdev->timeout = extendedtimeout * HZ;
+	}
+#endif
+	return 0;
+}
+#else
+/**
+ *	aac_queuedepth		-	compute queue depths
+ *	@host:	SCSI host in question
+ *	@dev:	SCSI device we are considering
+ *
+ *	Selects queue depths for each target device based on the host adapter's
+ *	total capacity and the queue depth supported by the target device.
+ *	A queue depth of one automatically disables tagged queueing.
+ */
+
+static void aac_queuedepth(struct Scsi_Host * host, struct scsi_device * dev )
+{
+	struct scsi_device * dptr;
+	unsigned num_lsu = 0;
+	unsigned num_one = 0;
+	unsigned depth;
+	struct aac_dev *aac = (struct aac_dev *)host->hostdata;
+	unsigned cid;
+
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+	printk(KERN_INFO "aac_queuedepth(%p,%p)\n", host, dev);
+#endif
+	for (cid = 0; cid < aac->maximum_num_containers; ++cid)
+		if (aac->fsa_dev[cid].valid)
+			++num_lsu;
+	for(dptr = dev; dptr != NULL; dptr = dptr->next)
+		if (dptr->host == host) {
+			if ((dev->type == TYPE_DISK) && !dev->no_uld_attach) {
 				if ((sdev_channel(dev) != CONTAINER_CHANNEL)
 				 || !aac->fsa_dev[sdev_id(dev)].valid)
 					++num_lsu;
 			} else
 				++num_one;
 		}
-		if (num_lsu == 0)
-			++num_lsu;
-		depth = (host->can_queue - num_one) / num_lsu;
-		if (depth > 256)
-			depth = 256;
-		else if (depth < 2)
-			depth = 2;
-		scsi_adjust_queue_depth(sdev, MSG_ORDERED_TAG, depth);
-	} else
-		scsi_adjust_queue_depth(sdev, 0, 1);
 
-	return 0;
+	dprintk((KERN_DEBUG "can_queue=%d num_lsu=%d num_one=%d\n", host->can_queue, num_lsu, num_one));
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+	printk(KERN_INFO "can_queue=%d num_lsu=%d num_one=%d\n", host->can_queue, num_lsu, num_one);
+#endif
+	if (num_lsu == 0)
+		++num_lsu;
+	depth = (host->can_queue - num_one) / num_lsu;
+	if (depth > 255)
+		depth = 255;
+	else if (depth < 2)
+		depth = 2;
+	/* Rebalance */
+	dprintk((KERN_DEBUG "aac_queuedepth.\n"));
+	dprintk((KERN_DEBUG "Device #   Q Depth   Online\n"));
+	dprintk((KERN_DEBUG "---------------------------\n"));
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+	printk(KERN_INFO "aac_queuedepth.\n");
+	printk(KERN_INFO "Device #   Q Depth   Online\n");
+	printk(KERN_INFO "---------------------------\n");
+#endif
+	for(dptr = dev; dptr != NULL; dptr = dptr->next)
+	{
+		if(dptr->host == host) {
+			if ((dptr->type == TYPE_DISK) && !dptr->no_uld_attach)
+				dptr->queue_depth = depth;
+			else
+				dptr->queue_depth = 1;
+
+			dprintk((KERN_DEBUG "  %2d         %d        %d\n",
+			  dptr->id, dptr->queue_depth, scsi_device_online(dptr)));
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+			printk(KERN_INFO "  %2d         %d        %d\n",
+			  dptr->id, dptr->queue_depth, scsi_device_online(dptr));
+#endif
+		}
+	}
 }
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 
 /**
  *	aac_change_queue_depth		-	alter queue depths
@@ -477,13 +1075,13 @@ static int aac_slave_configure(struct scsi_device *sdev)
  *	Alters queue depths for target device based on the host adapter's
  *	total capacity and the queue depth supported by the target device.
  */
-
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,33))
+static int aac_change_queue_depth(struct scsi_device *sdev, int depth)
+#else
 static int aac_change_queue_depth(struct scsi_device *sdev, int depth,
 				  int reason)
+#endif
 {
-	if (reason != SCSI_QDEPTH_DEFAULT)
-		return -EOPNOTSUPP;
-
 	if (sdev->tagged_supported && (sdev->type == TYPE_DISK) &&
 	    (sdev_channel(sdev) == CONTAINER_CHANNEL)) {
 		struct scsi_device * dev;
@@ -509,8 +1107,37 @@ static int aac_change_queue_depth(struct scsi_device *sdev, int depth,
 		scsi_adjust_queue_depth(sdev, 0, 1);
 	return sdev->queue_depth;
 }
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11))
+
+static ssize_t aac_store_queue_depth(struct device *dev, const char * buf,
+  size_t count)
+{
+	aac_change_queue_depth(to_scsi_device(dev),
+	  simple_strtoul(buf, NULL, 10));
+	return strlen(buf);
+}
+
+static ssize_t aac_show_queue_depth(struct device *dev, char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%d\n",
+	  to_scsi_device(dev)->queue_depth);
+}
+
+static struct device_attribute aac_queue_depth_attr = {
+	.attr = {
+		.name =	"queue_depth",
+		.mode = S_IWUSR|S_IRUGO,
+	},
+	.store = aac_store_queue_depth,
+	.show = aac_show_queue_depth
+};
+#endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,13))
+static ssize_t aac_show_raid_level(struct device *dev, char *buf)
+#else
 static ssize_t aac_show_raid_level(struct device *dev, struct device_attribute *attr, char *buf)
+#endif
 {
 	struct scsi_device *sdev = to_scsi_device(dev);
 	struct aac_dev *aac = (struct aac_dev *)(sdev->host->hostdata);
@@ -532,38 +1159,294 @@ static struct device_attribute aac_raid_level_attr = {
 
 static struct device_attribute *aac_dev_attrs[] = {
 	&aac_raid_level_attr,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11))
+	&aac_queue_depth_attr,
+#endif
 	NULL,
 };
+#endif
+#if (!defined(HAS_BOOT_CONFIG))
 
 static int aac_ioctl(struct scsi_device *sdev, int cmd, void __user * arg)
 {
 	struct aac_dev *dev = (struct aac_dev *)sdev->host->hostdata;
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	int retval;
+	printk("aac_ioctl(%p, %x, %p)\n", sdev, cmd, arg);
+	retval = capable(CAP_SYS_RAWIO) ? aac_do_ioctl(dev, cmd, arg) : -EPERM;
+	printk("aac_ioctl returns %d\n", retval);
+	return retval;
+#else
 	if (!capable(CAP_SYS_RAWIO))
 		return -EPERM;
 	return aac_do_ioctl(dev, cmd, arg);
+#endif
 }
+#endif
 
-static int aac_eh_abort(struct scsi_cmnd* cmd)
+extern void aac_hba_callback(void *context, struct fib * fibptr);
+
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+/**
+ *	aac_eh_device_reset	-	Reset command handling
+ *	@cmd:	SCSI command block causing the reset
+ *
+ *	Issue a reset of a SCSI device. We are ourselves not truely a SCSI
+ *	controller and our firmware will do the work for us anyway. Thus this
+ *	is a no-op.
+ *	We return SUCCESS to avoid a "vmkfstools -L lunreset ..." failure
+ */
+
+static int aac_eh_device_reset(struct scsi_cmnd *cmd)
+{
+	return SUCCESS;
+}
+
+/**
+ *	aac_eh_bus_reset	-	Reset command handling
+ *	@scsi_cmd:	SCSI command block causing the reset
+ *
+ *	Issue a reset of a SCSI bus. We are ourselves not truely a SCSI
+ *	controller and our firmware will do the work for us anyway. Thus this
+ *	is a no-op.
+ *	We return SUCCESS to avoid a "vmkfstools -L busreset ..." failure
+ */
+
+static int aac_eh_bus_reset(struct scsi_cmnd* cmd)
+{
+	return SUCCESS;
+}
+
+#endif
+#if (defined(__arm__))
+//DEBUG
+#define AAC_DEBUG_INSTRUMENT_RESET
+#endif
+static int aac_eh_abort(struct scsi_cmnd* cmd)
 {
 	struct scsi_device * dev = cmd->device;
 	struct Scsi_Host * host = dev->host;
 	struct aac_dev * aac = (struct aac_dev *)host->hostdata;
-	int count;
+	int count, found;
+	u32 bus, cid;
 	int ret = FAILED;
 
-	printk(KERN_ERR "%s: Host adapter abort request (%d,%d,%d,%d)\n",
-		AAC_DRIVERNAME,
-		host->host_no, sdev_channel(dev), sdev_id(dev), dev->lun);
-	switch (cmd->cmnd[0]) {
-	case SERVICE_ACTION_IN:
-		if (!(aac->raw_io_interface) ||
-		    !(aac->raw_io_64) ||
-		    ((cmd->cmnd[1] & 0x1f) != SAI_READ_CAPACITY_16))
-			break;
-	case INQUIRY:
-	case READ_CAPACITY:
-		/* Mark associated FIB to not complete, eh handler does this */
+	bus = aac_logical_to_phys(scmd_channel(cmd));
+	cid = scmd_id(cmd);
+	if (aac->hba_map[bus][cid].devtype == AAC_DEVTYPE_NATIVE_RAW) {
+		struct fib *fib;
+		struct aac_hba_tm_req *tmf;
+		int status;
+		u64 address;
+		__le32 managed_request_id;
+
+		printk(KERN_ERR "%s: Host adapter abort request (%d,%d,%d,%d)\n",
+		 AAC_DRIVERNAME,
+		 host->host_no, sdev_channel(dev), sdev_id(dev), dev->lun);
+		
+		found = 0;
 		for (count = 0; count < (host->can_queue + AAC_NUM_MGT_FIB); ++count) {
+			fib = &aac->fibs[count];
+			if (*(u8 *)fib->hw_fib_va != 0 &&
+				(fib->flags & FIB_CONTEXT_FLAG_NATIVE_HBA) &&
+				(fib->callback_data == cmd)) {
+				found = 1;
+				managed_request_id = ((struct aac_hba_cmd_req *)
+					fib->hw_fib_va)->request_id;
+				break;
+			}
+		}
+		if (!found)
+			return ret;
+
+		/* start a HBA_TMF_ABORT_TASK TMF request */
+		if (!(fib = aac_fib_alloc(aac))) {
+			return ret;
+		}
+
+		tmf = (struct aac_hba_tm_req *)fib->hw_fib_va;
+		memset(tmf, 0, sizeof(*tmf));
+		tmf->tmf = HBA_TMF_ABORT_TASK;
+		tmf->it_nexus = aac->hba_map[bus][cid].rmw_nexus;
+		tmf->lun[1] = cmd->device->lun;
+		
+		address = (u64)fib->hw_error_pa;
+		tmf->error_ptr_hi = cpu_to_le32((u32)(address >> 32));
+		tmf->error_ptr_lo = cpu_to_le32((u32)(address & 0xffffffff));
+		tmf->error_length = cpu_to_le32(FW_ERROR_BUFFER_SIZE);
+	
+		fib->hbacmd_size = sizeof(*tmf);
+		cmd->SCp.sent_command = 0;
+
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12))
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+		spin_unlock_irq(host->host_lock);
+#else
+		spin_unlock_irq(host->lock);
+#endif
+#else
+		spin_unlock_irq(&io_request_lock);
+#endif
+#endif
+		status = aac_hba_send(HBA_IU_TYPE_SCSI_TM_REQ, fib,
+				  (fib_callback) aac_hba_callback,
+				  (void *) cmd);
+
+		/* Wait up to 2 minutes for completion */
+		for (count = 0; count < 120; ++count) {
+			if (cmd->SCp.sent_command) {
+				ret = SUCCESS;	
+				break;
+			}
+			msleep(1000);
+		}	
+
+		if (ret != SUCCESS)
+		 printk(KERN_ERR "%s: Host adapter abort request timed out\n",
+			AAC_DRIVERNAME);
+	
+		/* check status */
+		/* ... */
+
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12))
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+		spin_lock_irq(host->host_lock);
+#else
+		spin_lock_irq(host->lock);
+#endif
+#else
+		spin_lock_irq(&io_request_lock);
+#endif
+#endif
+
+	} else {
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET) || (0 && defined(BOOTCD)))
+		struct scsi_cmnd * command;
+		int active;
+		unsigned long DebugFlags;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+		unsigned long flags;
+#endif
+#if ((KERNEL_VERSION(2,5,0) <= LINUX_VERSION_CODE) && (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12)))
+		unsigned short saved_queue_depth;
+		unsigned int saved_device_blocked;
+		/*
+	 	 * Bug in these kernels allows commands to come through to 
+	 	 * controller. We provide an additional hack, a coarse lock to 
+	 	 * prevent new commands from being issued during this delicate
+	 	 * phase. We can not use scsi_adjust_queue_depth, and besides,
+	 	 * that is not the point, we have to have a test that punts
+	 	 * commands back at the lower layers while we are in error 
+		 * recovery; where the test for it is embedded
+	 	 * in a host_lock deadlock state.
+	 	 */
+		saved_device_blocked = dev->device_blocked;
+		dev->device_blocked = dev->max_device_blocked;
+		saved_queue_depth = dev->queue_depth;
+		dev->queue_depth = 0;
+		if (saved_queue_depth < 2) save_queue_depth =
+			aac->fsa_dev[scmd_id(cmd)].queue_depth;
+		if (saved_queue_depth < 2)
+			saved_queue_depth = 2;
+#endif
+
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12))
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+		spin_unlock_irq(host->host_lock);
+#else
+		spin_unlock_irq(host->lock);
+#endif
+#else
+		spin_unlock_irq(&io_request_lock);
+#endif
+#endif
+		printk(KERN_ERR
+	  		"%s: Host adapter abort request.\n"
+	  		"%s: Outstanding commands on (%d,%d,%d,%d):\n",
+	  		AAC_DRIVERNAME, AAC_DRIVERNAME,
+	  		host->host_no,sdev_channel(dev),sdev_id(dev),dev->lun);
+		if (nblank(fwprintf(x))) {
+			fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B,
+		  		"abort request.\n"
+		  		"Outstanding commands on (%d,%d,%d,%d):",
+		  	host->host_no,sdev_channel(dev),sdev_id(dev),dev->lun));
+			DebugFlags = aac->FwDebugFlags;
+			aac->FwDebugFlags |= FW_DEBUG_FLAGS_NO_HEADERS_B;
+		}
+		active = 0;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+		spin_lock_irqsave(&dev->list_lock, flags);
+		list_for_each_entry(command, &dev->cmd_list, list)
+#else
+		for(command = dev->device_queue;command;command = command->next)
+#endif
+		{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,12))
+			if ((command->state == SCSI_STATE_FINISHED)
+		 		|| (command->state == 0))
+				continue;
+#endif
+			fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B,
+		 "%4d %c%c %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x\n",
+		  	 active,
+		  	 (command->SCp.phase == AAC_OWNER_FIRMWARE) ? 'A' : 'C',
+		  	 (cmd == command) ? '*' : ' ',
+		  	 command->cmnd[0], command->cmnd[1], command->cmnd[2],
+		  	 command->cmnd[3], command->cmnd[4], command->cmnd[5],
+		  	 command->cmnd[6], command->cmnd[7], command->cmnd[8],
+		  	 command->cmnd[9]));
+			printk(KERN_ERR
+		 "%4d %c%c %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x\n",
+		  	 active,
+		  	 (command->SCp.phase == AAC_OWNER_FIRMWARE) ? 'A' : 'C',
+		  	 (cmd == command) ? '*' : ' ',
+		  	 command->cmnd[0], command->cmnd[1], command->cmnd[2],
+		  	 command->cmnd[3], command->cmnd[4], command->cmnd[5],
+		  	 command->cmnd[6], command->cmnd[7], command->cmnd[8],
+		  	 command->cmnd[9]);
+			++active;
+		}
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+		spin_unlock_irqrestore(&dev->list_lock, flags);
+#endif
+		if (nblank(fwprintf(x)))
+			aac->FwDebugFlags = DebugFlags;
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+		dev->device_blocked = dev->max_device_blocked;
+		dev->queue_depth = 0;
+#endif
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+		spin_lock_irq(host->host_lock);
+#else
+		spin_lock_irq(host->lock);
+#endif
+#else
+		spin_lock_irq(&io_request_lock);
+#endif
+#endif
+#else
+
+		printk(KERN_ERR "%s: Host adapter abort request (%d,%d,%d,%d)\n",
+		 AAC_DRIVERNAME,
+		 host->host_no, sdev_channel(dev), sdev_id(dev), dev->lun);
+#endif /* AAC_DEBUG_INSTRUMENT_RESET */
+		switch (cmd->cmnd[0]) {
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(SERVICE_ACTION_IN))
+		case SERVICE_ACTION_IN:
+			if (!(aac->raw_io_interface) ||
+		    		!(aac->raw_io_64) ||
+		    		((cmd->cmnd[1] & 0x1f) != SAI_READ_CAPACITY_16))
+				break;
+#endif
+		case INQUIRY:
+		case READ_CAPACITY:
+		 /* Mark associated FIB to not complete, eh handler does this */
+		 for (count = 0; count < (host->can_queue + AAC_NUM_MGT_FIB); ++count) {
 			struct fib * fib = &aac->fibs[count];
 			if (fib->hw_fib_va->header.XferState &&
 			  (fib->flags & FIB_CONTEXT_FLAG) &&
@@ -572,12 +1455,14 @@ static int aac_eh_abort(struct scsi_cmnd* cmd)
 				cmd->SCp.phase = AAC_OWNER_ERROR_HANDLER;
 				ret = SUCCESS;
 			}
-		}
-		break;
-	case TEST_UNIT_READY:
-		/* Mark associated FIB to not complete, eh handler does this */
-		for (count = 0; count < (host->can_queue + AAC_NUM_MGT_FIB); ++count) {
+		 }
+		 break;
+		case TEST_UNIT_READY:
+		 /* Mark associated FIB to not complete, eh handler does this */
+		 for (count = 0; count < (host->can_queue + AAC_NUM_MGT_FIB); ++count) {
+#if (!defined(AAC_DEBUG_INSTRUMENT_RESET) && !(0 && defined(BOOTCD)))
 			struct scsi_cmnd * command;
+#endif
 			struct fib * fib = &aac->fibs[count];
 			if ((fib->hw_fib_va->header.XferState & cpu_to_le32(Async | NoResponseExpected)) &&
 			  (fib->flags & FIB_CONTEXT_FLAG) &&
@@ -588,8 +1473,16 @@ static int aac_eh_abort(struct scsi_cmnd* cmd)
 				if (command == cmd)
 					ret = SUCCESS;
 			}
+		 }
 		}
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+#if ((KERNEL_VERSION(2,5,0) <= LINUX_VERSION_CODE) && (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12)))
+		dev->queue_depth = saved_queue_depth;
+		dev->device_blocked = saved_device_blocked;
+#endif
+#endif /* AAC_DEBUG_INSTRUMENT_RESET */
 	}
+
 	return ret;
 }
 
@@ -602,72 +1495,422 @@ static int aac_eh_reset(struct scsi_cmnd* cmd)
 {
 	struct scsi_device * dev = cmd->device;
 	struct Scsi_Host * host = dev->host;
-	struct scsi_cmnd * command;
-	int count;
 	struct aac_dev * aac = (struct aac_dev *)host->hostdata;
-	unsigned long flags;
+	int count;
+	u32 bus, cid;
+	int ret = FAILED;
 
-	/* Mark the associated FIB to not complete, eh handler does this */
-	for (count = 0; count < (host->can_queue + AAC_NUM_MGT_FIB); ++count) {
-		struct fib * fib = &aac->fibs[count];
-		if (fib->hw_fib_va->header.XferState &&
-		  (fib->flags & FIB_CONTEXT_FLAG) &&
-		  (fib->callback_data == cmd)) {
-			fib->flags |= FIB_CONTEXT_FLAG_TIMED_OUT;
-			cmd->SCp.phase = AAC_OWNER_ERROR_HANDLER;
+	bus = aac_logical_to_phys(scmd_channel(cmd));
+	cid = scmd_id(cmd);
+	if (aac->hba_map[bus][cid].devtype == AAC_DEVTYPE_NATIVE_RAW) {
+		struct fib *fib;
+		int status;
+		u64 address;
+		u8 command;
+
+		printk(KERN_ERR "%s: Host adapter reset request. SCSI hang ?\n",
+			AAC_DRIVERNAME);
+		
+		if (!(fib = aac_fib_alloc(aac))) {
+			return ret;
 		}
-	}
-	printk(KERN_ERR "%s: Host adapter reset request. SCSI hang ?\n",
-					AAC_DRIVERNAME);
+		
+		if (aac->hba_map[bus][cid].reset_state == 0) {
+			struct aac_hba_tm_req *tmf;
+		
+			/* start a HBA_TMF_LUN_RESET TMF request */
+			tmf = (struct aac_hba_tm_req *)fib->hw_fib_va;
+			memset(tmf, 0, sizeof(*tmf));
+			tmf->tmf = HBA_TMF_LUN_RESET;
+			tmf->it_nexus = aac->hba_map[bus][cid].rmw_nexus;
+			tmf->lun[1] = cmd->device->lun;
+		
+			address = (u64)fib->hw_error_pa;
+			tmf->error_ptr_hi = cpu_to_le32((u32)(address >> 32));
+			tmf->error_ptr_lo = cpu_to_le32((u32)(address & 0xffffffff));
+			tmf->error_length = cpu_to_le32(FW_ERROR_BUFFER_SIZE);
+			fib->hbacmd_size = sizeof(*tmf);
+			
+			command = HBA_IU_TYPE_SCSI_TM_REQ;
+			aac->hba_map[bus][cid].reset_state++;
+		} else if (aac->hba_map[bus][cid].reset_state >= 1) {
+			struct aac_hba_reset_req *rst;
+
+			/* already tried, start a hard reset now */
+			rst = (struct aac_hba_reset_req *)fib->hw_fib_va;
+			memset(rst, 0, sizeof(*rst));
+			/* reset_type is already zero... */
+			rst->it_nexus = aac->hba_map[bus][cid].rmw_nexus;
+		
+			address = (u64)fib->hw_error_pa;
+			rst->error_ptr_hi = cpu_to_le32((u32)(address >> 32));
+			rst->error_ptr_lo = cpu_to_le32((u32)(address & 0xffffffff));
+			rst->error_length = cpu_to_le32(FW_ERROR_BUFFER_SIZE);
+			fib->hbacmd_size = sizeof(*rst);
+			
+			command = HBA_IU_TYPE_SATA_REQ;
+			aac->hba_map[bus][cid].reset_state = 0;
+		}
+		cmd->SCp.sent_command = 0;
 
-	if ((count = aac_check_health(aac)))
-		return count;
-	/*
-	 * Wait for all commands to complete to this specific
-	 * target (block maximum 60 seconds).
-	 */
-	for (count = 60; count; --count) {
-		int active = aac->in_reset;
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12))
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+		spin_unlock_irq(host->host_lock);
+#else
+		spin_unlock_irq(host->lock);
+#endif
+#else
+		spin_unlock_irq(&io_request_lock);
+#endif
+#endif
+		status = aac_hba_send(command, fib,
+				  (fib_callback) aac_hba_callback,
+				  (void *) cmd);
+
+		/* Wait up to 2 minutes for completion */
+		for (count = 0; count < 120; ++count) {
+			if (cmd->SCp.sent_command) {
+				ret = SUCCESS;	
+				break;
+			}
+			msleep(1000);
+		}	
+
+		if (ret != SUCCESS)
+		 printk(KERN_ERR "%s: Host adapter reset request timed out\n",
+			AAC_DRIVERNAME);
+	
+		/* check status */
+		/* ... */
+
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12))
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+		spin_lock_irq(host->host_lock);
+#else
+		spin_lock_irq(host->lock);
+#endif
+#else
+		spin_lock_irq(&io_request_lock);
+#endif
+#endif
 
-		if (active == 0)
-		__shost_for_each_device(dev, host) {
-			spin_lock_irqsave(&dev->list_lock, flags);
-			list_for_each_entry(command, &dev->cmd_list, list) {
+	} else {
+#if (!defined(AAC_DEBUG_INSTRUMENT_RESET) && defined(__arm__))
+		return SUCCESS; /* Cause an immediate retry of the command with a ten second delay after successful tur */
+#else
+		struct scsi_cmnd * command;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+		unsigned long flags;
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET) || (0 && defined(BOOTCD)))
+		int active;
+		unsigned long DebugFlags;
+#endif /* AAC_DEBUG_INSTRUMENT_RESET */
+#if ((KERNEL_VERSION(2,5,0) <= LINUX_VERSION_CODE) && (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12)))
+		unsigned short saved_queue_depth;
+		unsigned int saved_device_blocked;
+		/*
+	 	 * Bug in these kernels allows commands to come through to 
+	 	 * controller. We provide an additional hack, a coarse lock to 
+	 	 * prevent new commands from being issued during this delicate
+	 	 * phase. We can not use scsi_adjust_queue_depth, and besides,
+	 	 * that is not the point, we have to have a test that punts
+	 	 * commands back at the lower layers while we are in error 
+		 * recovery; where the test for it is embedded
+	 	 * in a host_lock deadlock state.
+	 	 */
+		saved_device_blocked = dev->device_blocked;
+		dev->device_blocked = dev->max_device_blocked;
+		saved_queue_depth = dev->queue_depth;
+		dev->queue_depth = 0;
+		if (saved_queue_depth < 2) saved_queue_depth =
+			aac->fsa_dev[scmd_id(cmd)].queue_depth;
+		if (saved_queue_depth < 2)
+			saved_queue_depth = 2;
+#endif
+
+		/* Mark the assoc. FIB to not complete, eh handler does this */
+		for (count = 0; count < (host->can_queue + AAC_NUM_MGT_FIB); ++count) {
+			struct fib * fib = &aac->fibs[count];
+			if (fib->hw_fib_va->header.XferState &&
+		  		(fib->flags & FIB_CONTEXT_FLAG) &&
+		  		(fib->callback_data == cmd)) {
+				fib->flags |= FIB_CONTEXT_FLAG_TIMED_OUT;
+				cmd->SCp.phase = AAC_OWNER_ERROR_HANDLER;
+			}
+		}
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12))
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+		spin_unlock_irq(host->host_lock);
+#else
+		spin_unlock_irq(host->lock);
+#endif
+#else
+		spin_unlock_irq(&io_request_lock);
+#endif
+#endif
+		printk(KERN_ERR "%s: Host adapter reset request. SCSI hang ?\n",
+			AAC_DRIVERNAME);
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+		fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B, "reset request. SCSI hang ?"));
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET) || (0 && defined(BOOTCD)))
+		printk(KERN_ERR
+	  	 AAC_DRIVERNAME ": Outstanding commands on (%d,%d,%d,%d):\n",
+	  	 host->host_no, sdev_channel(dev), sdev_id(dev), dev->lun);
+		if (nblank(fwprintf(x))) {
+		 DebugFlags = aac->FwDebugFlags;
+		 aac->FwDebugFlags |= FW_DEBUG_FLAGS_NO_HEADERS_B;
+		 fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "Outstanding commands on (%d,%d,%d,%d):\n",
+		  host->host_no, sdev_channel(dev), sdev_id(dev), dev->lun));
+		}
+		active = 0;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+		spin_lock_irqsave(&dev->list_lock, flags);
+		list_for_each_entry(command, &dev->cmd_list, list)
+#else
+		for (command=dev->device_queue; command; command=command->next)
+#endif
+		{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,12))
+			if ((command->state == SCSI_STATE_FINISHED)
+		 		|| (command->state == 0))
+				continue;
+#endif
+			fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B,
+		 "%4d %c%c %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x\n",
+		  	 active,
+		  	 (command->SCp.phase == AAC_OWNER_FIRMWARE) ? 'A' : 'C',
+		   	 (cmd == command) ? '*' : ' ',
+		  	 command->cmnd[0], command->cmnd[1], command->cmnd[2],
+		  	 command->cmnd[3], command->cmnd[4], command->cmnd[5],
+		  	 command->cmnd[6], command->cmnd[7], command->cmnd[8],
+		  	 command->cmnd[9]));
+			printk(KERN_ERR
+		 "%4d %c%c %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x\n",
+		  	 active,
+		  	 (command->SCp.phase == AAC_OWNER_FIRMWARE) ? 'A' : 'C',
+		  	 (cmd == command) ? '*' : ' ',
+		  	 command->cmnd[0], command->cmnd[1], command->cmnd[2],
+		  	 command->cmnd[3], command->cmnd[4], command->cmnd[5],
+		  	 command->cmnd[6], command->cmnd[7], command->cmnd[8],
+		  	 command->cmnd[9]);
+			++active;
+		}
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+		spin_unlock_irqrestore(&dev->list_lock, flags);
+#endif
+		if (nblank(fwprintf(x)))
+			aac->FwDebugFlags = DebugFlags;
+#endif /* AAC_DEBUG_INSTRUMENT_RESET */
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+		dev->device_blocked = dev->max_device_blocked;
+		dev->queue_depth = 0;
+#endif
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+		spin_lock_irq(host->host_lock);
+#else
+		spin_lock_irq(host->lock);
+#endif
+#else
+		spin_lock_irq(&io_request_lock);
+#endif
+#endif
+
+		if ((count = aac_check_health(aac)))
+#if ((KERNEL_VERSION(2,5,0) <= LINUX_VERSION_CODE) && (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12)))
+		{
+			dev->queue_depth = saved_queue_depth;
+			dev->device_blocked = saved_device_blocked;
+#endif
+			return count;
+#if ((KERNEL_VERSION(2,5,0) <= LINUX_VERSION_CODE) && (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12)))
+		}
+#endif
+		/*
+	 	 * Wait for all commands to complete to this specific
+	 	 * target (block maximum 60 seconds).
+	 	 */
+		for (count = 60; count; --count) {
+			int active = aac->in_reset;
+
+			if (active == 0)
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+			__shost_for_each_device(dev, host) {
+			 spin_lock_irqsave(&dev->list_lock, flags);
+			 list_for_each_entry(command, &dev->cmd_list, list) {
 				if ((command != cmd) &&
-				    (command->SCp.phase == AAC_OWNER_FIRMWARE)) {
+				    (command->SCp.phase==AAC_OWNER_FIRMWARE)) {
 					active++;
 					break;
 				}
-			}
-			spin_unlock_irqrestore(&dev->list_lock, flags);
-			if (active)
+			 }
+			 spin_unlock_irqrestore(&dev->list_lock, flags);
+			 if (active)
 				break;
 
+			}
+#else
+			for (dev = host->host_queue; dev != (struct scsi_device *)NULL; dev = dev->next) {
+			 for(command = dev->device_queue; command; command = command->next) {
+				if ((command != cmd)
+				 && (command->SCp.phase==AAC_OWNER_FIRMWARE)) {
+					++active;
+					break;
+				}
+			 }
+			}
+#endif
+			/*
+		 	 * We can exit If all the commands are complete
+		 	 */
+#if ((KERNEL_VERSION(2,5,0) <= LINUX_VERSION_CODE) && (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12)))
+			dev = cmd->device;
+#endif
+			if (active == 0)
+#if ((KERNEL_VERSION(2,5,0) <= LINUX_VERSION_CODE) && (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12)))
+			{
+				dev->queue_depth = saved_queue_depth;
+				dev->device_blocked = saved_device_blocked;
+#endif
+				return SUCCESS;
+#if ((KERNEL_VERSION(2,5,0) <= LINUX_VERSION_CODE) && (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12)))
+			}
+#endif
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12))
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+			spin_unlock_irq(host->host_lock);
+#else
+			spin_unlock_irq(host->lock);
+#endif
+#else
+			spin_unlock_irq(&io_request_lock);
+#endif
+#endif
+			ssleep(1);
+#if (defined(SCSI_HAS_DUMP) && (defined(HAS_DISKDUMPLIB_H) || defined(crashdump_mode)) && (defined(CONFIG_DISKDUMP) || defined(CONFIG_CRASH_DUMP)))
+			if (crashdump_mode())
+				aac_poll(dev);
+#endif
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+			dev->device_blocked = dev->max_device_blocked;
+			dev->queue_depth = 0;
+#endif
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+			spin_lock_irq(host->host_lock);
+#else
+			spin_lock_irq(host->lock);
+#endif
+#else
+			spin_lock_irq(&io_request_lock);
+#endif
+#endif
 		}
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12))
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+		spin_unlock_irq(host->host_lock);
+#else
+		spin_unlock_irq(host->lock);
+#endif
+#else
+		spin_unlock_irq(&io_request_lock);
+#endif
+#endif
+		printk(KERN_ERR "%s: SCSI bus appears hung\n", AAC_DRIVERNAME);
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+		fwprintf((aac,HBA_FLAGS_DBG_FW_PRINT_B,"SCSI bus appears hung"));
+#endif
 		/*
-		 * We can exit If all the commands are complete
-		 */
-		if (active == 0)
-			return SUCCESS;
-		ssleep(1);
+	 	 * This adapter needs a blind reset, only do so for Adapters
+	 	 * that support a register, instead of a commanded, reset.
+	 	 */
+		if (((aac->supplement_adapter_info.SupportedOptions2 & 
+         		AAC_OPTION_MU_RESET) || 
+         		(aac->supplement_adapter_info.SupportedOptions2 & 
+         		AAC_OPTION_DOORBELL_RESET)) &&
+	  		aac_check_reset &&
+	  		((aac_check_reset != 1) ||
+	   		!(aac->supplement_adapter_info.SupportedOptions2 &
+	    		AAC_OPTION_IGNORE_RESET)))
+			aac_reset_adapter(aac, 2); /* Bypass wait for command quiesce */
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+		dev->device_blocked = dev->max_device_blocked;
+		dev->queue_depth = 0;
+#endif
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+		spin_lock_irq(host->host_lock);
+#else
+		spin_lock_irq(host->lock);
+#endif
+#else
+		spin_lock_irq(&io_request_lock);
+#endif
+#endif
+#if ((KERNEL_VERSION(2,5,0) <= LINUX_VERSION_CODE) && (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,12)))
+		dev->queue_depth = saved_queue_depth;
+		dev->device_blocked = saved_device_blocked;
+#endif
+		ret = SUCCESS;
+#endif
 	}
-	printk(KERN_ERR "%s: SCSI bus appears hung\n", AAC_DRIVERNAME);
-	/*
-	 * This adapter needs a blind reset, only do so for Adapters that
-	 * support a register, instead of a commanded, reset.
+	
+	/* Cause an immediate retry of the command with a ten second delay 
+	 * after successful tur
 	 */
-	if (((aac->supplement_adapter_info.SupportedOptions2 &
-	  AAC_OPTION_MU_RESET) ||
-	  (aac->supplement_adapter_info.SupportedOptions2 &
-	  AAC_OPTION_DOORBELL_RESET)) &&
-	  aac_check_reset &&
-	  ((aac_check_reset != 1) ||
-	   !(aac->supplement_adapter_info.SupportedOptions2 &
-	    AAC_OPTION_IGNORE_RESET)))
-		aac_reset_adapter(aac, 2); /* Bypass wait for command quiesce */
-	return SUCCESS; /* Cause an immediate retry of the command with a ten second delay after successful tur */
+	return ret;
+}
+
+
+#if (defined(SCSI_HAS_DUMP))
+#if (defined(SCSI_HAS_DUMP_SANITY_CHECK))
+
+static int aac_sanity_check(struct scsi_device * sdev)
+{
+	return 0;
 }
 
+#endif
+static void aac_poll(struct scsi_device * sdev)
+{
+	struct Scsi_Host * shost = sdev->host;
+	struct aac_dev *dev = (struct aac_dev *)shost->hostdata;
+	unsigned long flags;
+
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+	spin_lock_irqsave(shost->host_lock, flags);
+#else
+	spin_lock_irqsave(shost->lock, flags);
+#endif
+#else
+	spin_lock_irqsave(&io_request_lock, flags);
+#endif
+	aac_adapter_intr(dev);
+#if (defined(SCSI_HAS_HOST_LOCK) || (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,4,21)) || !defined(CONFIG_CFGNAME))
+	spin_unlock_irqrestore(shost->host_lock, flags);
+#else
+	spin_unlock_irqrestore(shost->lock, flags);
+#endif
+#else
+	spin_unlock_irqrestore(&io_request_lock, flags);
+#endif
+}
+#endif
+#if (!defined(HAS_BOOT_CONFIG))
+
 /**
  *	aac_cfg_open		-	open a configuration file
  *	@inode: inode being opened
@@ -683,22 +1926,55 @@ static int aac_eh_reset(struct scsi_cmnd* cmd)
 static int aac_cfg_open(struct inode *inode, struct file *file)
 {
 	struct aac_dev *aac;
-	unsigned minor_number = iminor(inode);
 	int err = -ENODEV;
 
-	mutex_lock(&aac_mutex);  /* BKL pushdown: nothing else protects this list */
+#if (defined(__ESXi4__))
+	unsigned major_number = imajor(inode); //ESXi4 support
+#else
+	unsigned minor_number = iminor(inode);
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0))
+	lock_kernel();  /* BKL pushdown: nothing else protects this list */
+#else
+	mutex_lock(&aac_mutex);	/* BKL pushdown: nothing else protects this list */
+#endif
 	list_for_each_entry(aac, &aac_devices, entry) {
+#if (defined(__ESXi4__))
+		if (aac->major_number == major_number) {
+#else
 		if (aac->id == minor_number) {
+#endif
 			file->private_data = aac;
 			err = 0;
 			break;
 		}
 	}
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0))
+	unlock_kernel();
+#else
 	mutex_unlock(&aac_mutex);
+#endif
 
 	return err;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+/**
+ *	aac_cfg_release		-	close down an AAC config device
+ *	@inode: inode of configuration file
+ *	@file: file handle of configuration file
+ *
+ *	Called when the last close of the configuration file handle
+ *	is performed.
+ */
+
+static int aac_cfg_release(struct inode * inode, struct file * file )
+{
+	return 0;
+}
+
+#endif
 /**
  *	aac_cfg_ioctl		-	AAC configuration request
  *	@inode: inode of device
@@ -713,24 +1989,61 @@ static int aac_cfg_open(struct inode *inode, struct file *file)
  *	Bugs: Needs to handle hot plugging
  */
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,35))
+static int aac_cfg_ioctl(struct inode *inode, struct file *file,
+		unsigned int cmd, unsigned long arg)
+#else
 static long aac_cfg_ioctl(struct file *file,
 		unsigned int cmd, unsigned long arg)
+#endif
 {
-	int ret;
-	if (!capable(CAP_SYS_RAWIO))
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+	struct aac_dev * aac;
+	list_for_each_entry(aac, &aac_devices, entry) {
+#if (defined(__ESXi4__))
+		if (aac->major_number == imajor(inode)) { //ESXi4 support
+#else
+		if (aac->id == iminor(inode)) {
+#endif
+			file->private_data = aac;
+			break;
+		}
+	}
+	if (file->private_data == NULL)
+		return -ENODEV;
+#else
+	struct aac_dev * aac;
+	aac = (struct aac_dev *) file->private_data;
+#endif
+	if (!capable(CAP_SYS_RAWIO) || aac->adapter_shutdown)
 		return -EPERM;
-	mutex_lock(&aac_mutex);
-	ret = aac_do_ioctl(file->private_data, cmd, (void __user *)arg);
-	mutex_unlock(&aac_mutex);
-
-	return ret;
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+	{
+		int retval;
+		if (cmd != FSACTL_GET_NEXT_ADAPTER_FIB)
+			printk("aac_cfg_ioctl(%p,%p,%x,%lx)\n",
+			  inode, file, cmd, arg);
+		retval = aac_do_ioctl(
+		  file->private_data, cmd, (void __user *)arg);
+		if (cmd != FSACTL_GET_NEXT_ADAPTER_FIB)
+			printk("aac_cfg_ioctl returns %d\n", retval);
+		return retval;
+	}
+#else
+	return aac_do_ioctl(file->private_data, cmd, (void __user *)arg);
+#endif
 }
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11))
 #ifdef CONFIG_COMPAT
 static long aac_compat_do_ioctl(struct aac_dev *dev, unsigned cmd, unsigned long arg)
 {
 	long ret;
+#if (LINUX_VERSION_CODE <  KERNEL_VERSION(3,0,0))
+	lock_kernel();
+#else
 	mutex_lock(&aac_mutex);
+#endif
 	switch (cmd) {
 	case FSACTL_MINIPORT_REV_CHECK:
 	case FSACTL_SENDFIB:
@@ -742,7 +2055,13 @@ static long aac_compat_do_ioctl(struct aac_dev *dev, unsigned cmd, unsigned long
 	case FSACTL_DELETE_DISK:
 	case FSACTL_FORCE_DELETE_DISK:
 	case FSACTL_GET_CONTAINERS:
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+	case FSACTL_GET_VERSION_MATCHING:
+#endif
 	case FSACTL_SEND_LARGE_FIB:
+#if (defined(FSACTL_REGISTER_FIB_SEND) && !defined(CONFIG_COMMUNITY_KERNEL))
+	case FSACTL_REGISTER_FIB_SEND:
+#endif
 		ret = aac_do_ioctl(dev, cmd, (void __user *)arg);
 		break;
 
@@ -750,29 +2069,55 @@ static long aac_compat_do_ioctl(struct aac_dev *dev, unsigned cmd, unsigned long
 		struct fib_ioctl __user *f;
 
 		f = compat_alloc_user_space(sizeof(*f));
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		printk(KERN_INFO"FSACTL_GET_NEXT_ADAPTER_FIB:"
+		  " compat_alloc_user_space(%lu)=%p\n", sizeof(*f), f);
+#endif
 		ret = 0;
 		if (clear_user(f, sizeof(*f)))
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		{
+			printk(KERN_INFO"clear_user(%p,%lu)\n", f, sizeof(*f));
+#endif
 			ret = -EFAULT;
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		}
+#endif
 		if (copy_in_user(f, (void __user *)arg, sizeof(struct fib_ioctl) - sizeof(u32)))
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		{
+			printk(KERN_INFO"copy_in_user(%p,%p,%lu)\n", f,
+			  (void __user *)arg,
+			  sizeof(struct fib_ioctl) - sizeof(u32));
+#endif
 			ret = -EFAULT;
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+		}
+#endif
 		if (!ret)
 			ret = aac_do_ioctl(dev, cmd, f);
 		break;
 	}
 
 	default:
+#if (defined(AAC_CSMI))
+		ret = aac_csmi_ioctl(dev, cmd, (void __user *)arg);
+		if (ret == -ENOTTY)
+#endif
 		ret = -ENOIOCTLCMD;
 		break;
 	}
+#if (LINUX_VERSION_CODE <  KERNEL_VERSION(3,0,0))
+	unlock_kernel();
+#else
 	mutex_unlock(&aac_mutex);
+#endif
 	return ret;
 }
 
 static int aac_compat_ioctl(struct scsi_device *sdev, int cmd, void __user *arg)
 {
 	struct aac_dev *dev = (struct aac_dev *)sdev->host->hostdata;
-	if (!capable(CAP_SYS_RAWIO))
-		return -EPERM;
 	return aac_compat_do_ioctl(dev, cmd, (unsigned long)arg);
 }
 
@@ -780,15 +2125,27 @@ static long aac_compat_cfg_ioctl(struct file *file, unsigned cmd, unsigned long
 {
 	if (!capable(CAP_SYS_RAWIO))
 		return -EPERM;
-	return aac_compat_do_ioctl(file->private_data, cmd, arg);
+	return aac_compat_do_ioctl((struct aac_dev *)file->private_data, cmd, arg);
 }
 #endif
+#endif
+#endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static ssize_t aac_show_model(struct class_device *class_dev,
+		char *buf)
+#else
 static ssize_t aac_show_model(struct device *device,
 			      struct device_attribute *attr, char *buf)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+	struct aac_dev *dev = (struct aac_dev*)class_to_shost(class_dev)->hostdata;
+#else
 	struct aac_dev *dev = (struct aac_dev*)class_to_shost(device)->hostdata;
+#endif
 	int len;
+#if (defined(CONFIG_COMMUNITY_KERNEL))
 
 	if (dev->supplement_adapter_info.AdapterTypeText[0]) {
 		char * cp = dev->supplement_adapter_info.AdapterTypeText;
@@ -796,153 +2153,601 @@ static ssize_t aac_show_model(struct device *device,
 			++cp;
 		while (*cp == ' ')
 			++cp;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
 		len = snprintf(buf, PAGE_SIZE, "%s\n", cp);
+#else
+		len = sprintf(buf, "%s\n", cp);
+#endif
 	} else
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
 		len = snprintf(buf, PAGE_SIZE, "%s\n",
+#else
+		len = sprintf(buf, "%s\n",
+#endif
 		  aac_drivers[dev->cardtype].model);
+#else
+	struct scsi_inq scsi_inq;
+	char *cp;
+
+	setinqstr(dev, &scsi_inq, 255);
+	cp = &scsi_inq.pid[sizeof(scsi_inq.pid)-1];
+	while (*cp && *cp == ' ' && cp > scsi_inq.pid)
+		--cp;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+	len = snprintf(buf, PAGE_SIZE,
+#else
+	len = sprintf(buf,
+#endif
+	  "%.*s\n", (int)(cp - scsi_inq.pid) + 1, scsi_inq.pid);
+#endif
 	return len;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static ssize_t aac_show_vendor(struct class_device *class_dev,
+		char *buf)
+#else
 static ssize_t aac_show_vendor(struct device *device,
 			       struct device_attribute *attr, char *buf)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+	struct aac_dev *dev = (struct aac_dev*)class_to_shost(class_dev)->hostdata;
+#else
 	struct aac_dev *dev = (struct aac_dev*)class_to_shost(device)->hostdata;
+#endif
 	int len;
+#if (defined(CONFIG_COMMUNITY_KERNEL))
 
 	if (dev->supplement_adapter_info.AdapterTypeText[0]) {
 		char * cp = dev->supplement_adapter_info.AdapterTypeText;
 		while (*cp && *cp != ' ')
 			++cp;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
 		len = snprintf(buf, PAGE_SIZE, "%.*s\n",
+#else
+		len = sprintf(buf, "%.*s\n",
+#endif
 		  (int)(cp - (char *)dev->supplement_adapter_info.AdapterTypeText),
 		  dev->supplement_adapter_info.AdapterTypeText);
 	} else
-		len = snprintf(buf, PAGE_SIZE, "%s\n",
-		  aac_drivers[dev->cardtype].vname);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+	len = snprintf(buf, PAGE_SIZE, "%s\n",
+#else
+	len = sprintf(buf, "%s\n",
+#endif
+	  aac_drivers[dev->cardtype].vname);
+#else
+	struct scsi_inq scsi_inq;
+	char *cp;
+
+	setinqstr(dev, &scsi_inq, 255);
+	cp = &scsi_inq.vid[sizeof(scsi_inq.vid)-1];
+	while (*cp && *cp == ' ' && cp > scsi_inq.vid)
+		--cp;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+	len = snprintf(buf, PAGE_SIZE,
+#else
+	len = sprintf(buf,
+#endif
+	  "%.*s\n", (int)(cp - scsi_inq.vid) + 1, scsi_inq.vid);
+#endif
 	return len;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static ssize_t aac_show_flags(struct class_device *class_dev, char *buf)
+#else
 static ssize_t aac_show_flags(struct device *cdev,
 			      struct device_attribute *attr, char *buf)
+#endif
 {
 	int len = 0;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+	struct aac_dev *dev = (struct aac_dev*)class_to_shost(class_dev)->hostdata;
+#else
 	struct aac_dev *dev = (struct aac_dev*)class_to_shost(cdev)->hostdata;
+#endif
 
 	if (nblank(dprintk(x)))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
 		len = snprintf(buf, PAGE_SIZE, "dprintk\n");
-#ifdef AAC_DETAILED_STATUS_INFO
+#else
+		len = sprintf(buf, "dprintk\n");
+#endif
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+	if (nblank(fwprintf(x)))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len, "fwprintf\n");
+#else
+		len += sprintf(buf + len, "fwprintf\n");
+#endif
+#endif
+#if (defined(AAC_DETAILED_STATUS_INFO))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
 	len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+	len += sprintf(buf + len,
+#endif
 			"AAC_DETAILED_STATUS_INFO\n");
 #endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_INIT\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_SETUP))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_SETUP\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_AAC_CONFIG))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_AAC_CONFIG\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_AIF))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_AIF\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_IOCTL))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_IOCTL\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_TIMING))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_TIMING\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_RESET\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_FIB))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_FIB\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_CONTEXT))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_CONTEXT\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_2TB))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_2TB\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB=0x%X\n",
+		  AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB);
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_IO))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_IO\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_SG))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_SG\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_SG_PROBE))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_SG_PROBE\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_VM_NAMESERVE))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_VM_NAMESERVE\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_SERIAL))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_SERIAL\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_SYNCHRONIZE))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_SYNCHRONIZE\n");
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_SHUTDOWN\n");
+#	endif
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)) || (defined(SERVICE_ACTION_IN) && defined(SAI_READ_CAPACITY_16)))
 	if (dev->raw_io_interface && dev->raw_io_64)
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
 		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
 				"SAI_READ_CAPACITY_16\n");
+#endif
+#	if (defined(SCSI_HAS_VARY_IO))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "SCSI_HAS_VARY_IO\n");
+#	endif
+#if (defined(SCSI_HAS_DUMP))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+	len += snprintf(buf + len, PAGE_SIZE - len, "SCSI_HAS_DUMP\n");
+#else
+	len += sprintf(buf + len, "SCSI_HAS_DUMP\n");
+#endif
+#endif
+#	if (defined(BOOTCD))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len, "BOOTCD\n");
+#else
+		len += sprintf(buf + len, "BOOTCD\n");
+#endif
+#	endif
+#	if (defined(AAC_DEBUG_INSTRUMENT_PENDING))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len += snprintf(buf + len, PAGE_SIZE - len,
+#else
+		len += sprintf(buf + len,
+#endif
+		  "AAC_DEBUG_INSTRUMENT_PENDING=%u\n",
+		   atomic_read(&dev->queues->queue[
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+		    (dev->comm_interface == AAC_COMM_APRE)
+		      ? ApreCmdQueue
+		      : AdapNormCmdQueue
+#else
+		    AdapNormCmdQueue
+#endif
+		  ].numpending));
+#	endif
 	if (dev->jbod)
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
 		len += snprintf(buf + len, PAGE_SIZE - len, "SUPPORTED_JBOD\n");
+#else
+		len += sprintf(buf + len, "SUPPORTED_JBOD\n");
+#endif
 	if (dev->supplement_adapter_info.SupportedOptions2 &
 		AAC_OPTION_POWER_MANAGEMENT)
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
 		len += snprintf(buf + len, PAGE_SIZE - len,
 				"SUPPORTED_POWER_MANAGEMENT\n");
+#else
+		len += sprintf(buf + len, "SUPPORTED_POWER_MANAGEMENT\n");
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_ENABLE_MSI) || defined(PCI_HAS_DISABLE_MSI))
 	if (dev->msi)
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
 		len += snprintf(buf + len, PAGE_SIZE - len, "PCI_HAS_MSI\n");
+#else
+		len += sprintf(buf + len, "PCI_HAS_MSI\n");
+#endif
+#endif
 	return len;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static ssize_t aac_show_kernel_version(struct class_device *class_dev,
+		char *buf)
+#else
 static ssize_t aac_show_kernel_version(struct device *device,
 				       struct device_attribute *attr,
 				       char *buf)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+	struct aac_dev *dev = (struct aac_dev*)class_to_shost(class_dev)->hostdata;
+#else
 	struct aac_dev *dev = (struct aac_dev*)class_to_shost(device)->hostdata;
+#endif
 	int len, tmp;
 
 	tmp = le32_to_cpu(dev->adapter_info.kernelrev);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
 	len = snprintf(buf, PAGE_SIZE, "%d.%d-%d[%d]\n",
+#else
+	len = sprintf(buf, "%d.%d-%d[%d]\n",
+#endif
 	  tmp >> 24, (tmp >> 16) & 0xff, tmp & 0xff,
 	  le32_to_cpu(dev->adapter_info.kernelbuild));
 	return len;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static ssize_t aac_show_monitor_version(struct class_device *class_dev,
+		char *buf)
+#else
 static ssize_t aac_show_monitor_version(struct device *device,
 					struct device_attribute *attr,
 					char *buf)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+	struct aac_dev *dev = (struct aac_dev*)class_to_shost(class_dev)->hostdata;
+#else
 	struct aac_dev *dev = (struct aac_dev*)class_to_shost(device)->hostdata;
+#endif
 	int len, tmp;
 
 	tmp = le32_to_cpu(dev->adapter_info.monitorrev);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
 	len = snprintf(buf, PAGE_SIZE, "%d.%d-%d[%d]\n",
+#else
+	len = sprintf(buf, "%d.%d-%d[%d]\n",
+#endif
 	  tmp >> 24, (tmp >> 16) & 0xff, tmp & 0xff,
 	  le32_to_cpu(dev->adapter_info.monitorbuild));
 	return len;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static ssize_t aac_show_bios_version(struct class_device *class_dev,
+		char *buf)
+#else
 static ssize_t aac_show_bios_version(struct device *device,
 				     struct device_attribute *attr,
 				     char *buf)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+	struct aac_dev *dev = (struct aac_dev*)class_to_shost(class_dev)->hostdata;
+#else
 	struct aac_dev *dev = (struct aac_dev*)class_to_shost(device)->hostdata;
+#endif
 	int len, tmp;
 
 	tmp = le32_to_cpu(dev->adapter_info.biosrev);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
 	len = snprintf(buf, PAGE_SIZE, "%d.%d-%d[%d]\n",
+#else
+	len = sprintf(buf, "%d.%d-%d[%d]\n",
+#endif
 	  tmp >> 24, (tmp >> 16) & 0xff, tmp & 0xff,
 	  le32_to_cpu(dev->adapter_info.biosbuild));
 	return len;
 }
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,10)))
+
+static ssize_t aac_show_driver_version(struct class_device *class_dev,
+		char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%s\n", aac_driver_version);
+}
+#endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+ssize_t aac_show_serial_number(struct class_device *class_dev, char *buf)
+#else
 static ssize_t aac_show_serial_number(struct device *device,
 			       struct device_attribute *attr, char *buf)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+	struct aac_dev *dev = (struct aac_dev*)class_to_shost(class_dev)->hostdata;
+#else
 	struct aac_dev *dev = (struct aac_dev*)class_to_shost(device)->hostdata;
+#endif
 	int len = 0;
 
 	if (le32_to_cpu(dev->adapter_info.serial[0]) != 0xBAD0)
-		len = snprintf(buf, 16, "%06X\n",
-		  le32_to_cpu(dev->adapter_info.serial[0]));
-	if (len &&
-	  !memcmp(&dev->supplement_adapter_info.MfgPcbaSerialNo[
-	    sizeof(dev->supplement_adapter_info.MfgPcbaSerialNo)-len],
-	  buf, len-1))
-		len = snprintf(buf, 16, "%.*s\n",
+#if (defined(AAC_DEBUG_INSTRUMENT_SERIAL))
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len = snprintf(buf, PAGE_SIZE, "%06X|%.*s\n",
+#else
+		len = sprintf(buf, "%06X|%.*s\n",
+#endif
+		  le32_to_cpu(dev->adapter_info.serial[0]),
 		  (int)sizeof(dev->supplement_adapter_info.MfgPcbaSerialNo),
 		  dev->supplement_adapter_info.MfgPcbaSerialNo);
+#else
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len = snprintf(buf, PAGE_SIZE, "%06X\n",
+#else
+		len = sprintf(buf, "%06X\n",
+#endif
+		  le32_to_cpu(dev->adapter_info.serial[0]));
+#endif
+	/*
+	 * "DDTS# 11875: vmware 4.0 : Shows some junk value in serial number field"
+	 *		 Added this fix to copy serial number into buffer	
+	 */
 
-	return min(len, 16);
+	if (len)
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len = snprintf(buf, PAGE_SIZE, "%.*s\n",
+#else
+		len = sprintf(buf, "%.*s\n",
+#endif
+		  (int)sizeof(dev->supplement_adapter_info.MfgPcbaSerialNo),
+		  dev->supplement_adapter_info.MfgPcbaSerialNo);
+	return len;
 }
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static ssize_t aac_show_max_channel(struct class_device *class_dev, char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%d\n",
+	  class_to_shost(class_dev)->max_channel);
+}
+#else
 static ssize_t aac_show_max_channel(struct device *device,
 				    struct device_attribute *attr, char *buf)
 {
 	return snprintf(buf, PAGE_SIZE, "%d\n",
 	  class_to_shost(device)->max_channel);
 }
+#endif
+
+#if (defined(AAC_DEBUG_INSTRUMENT_SETUP))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static ssize_t aac_show_hba_max_channel(struct class_device *class_dev, char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%d\n",
+	  ((struct aac_dev*)class_to_shost(class_dev)->hostdata)
+	    ->maximum_num_channels);
+}
+
+static ssize_t aac_show_hba_max_physical(struct class_device *class_dev, char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%d\n",
+	  ((struct aac_dev*)class_to_shost(class_dev)->hostdata)
+	    ->maximum_num_physicals);
+}
+
+static ssize_t aac_show_hba_max_array(struct class_device *class_dev, char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%d\n",
+	  ((struct aac_dev*)class_to_shost(class_dev)->hostdata)
+	    ->maximum_num_containers);
+}
+#else
+static ssize_t aac_show_hba_max_channel(struct device *device,
+					struct device_attribute *attr,
+					char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%d\n",
+	  ((struct aac_dev*)class_to_shost(device)->hostdata)
+	    ->maximum_num_channels);
+}
+
+static ssize_t aac_show_hba_max_physical(struct device *device,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%d\n",
+	  ((struct aac_dev*)class_to_shost(device)->hostdata)
+	    ->maximum_num_physicals);
+}
 
+static ssize_t aac_show_hba_max_array(struct device *device,
+				      struct device_attribute *attr,
+				      char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%d\n",
+	  ((struct aac_dev*)class_to_shost(device)->hostdata)
+	    ->maximum_num_containers);
+}
+#endif
+
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static ssize_t aac_show_max_id(struct class_device *class_dev, char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%d\n",
+	  class_to_shost(class_dev)->max_id);
+}
+#else
 static ssize_t aac_show_max_id(struct device *device,
 			       struct device_attribute *attr, char *buf)
 {
 	return snprintf(buf, PAGE_SIZE, "%d\n",
 	  class_to_shost(device)->max_id);
 }
+#endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static ssize_t aac_store_reset_adapter(struct class_device *class_dev,
+		const char *buf, size_t count)
+#else
 static ssize_t aac_store_reset_adapter(struct device *device,
 				       struct device_attribute *attr,
 				       const char *buf, size_t count)
+#endif
 {
 	int retval = -EACCES;
 
 	if (!capable(CAP_SYS_ADMIN))
 		return retval;
+//	if (buf[0] == '?')
+//		Dump UART log into the KERN_INFO printk
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+	retval = aac_reset_adapter((struct aac_dev*)class_to_shost(class_dev)->hostdata, buf[0] == '!');
+#else
 	retval = aac_reset_adapter((struct aac_dev*)class_to_shost(device)->hostdata, buf[0] == '!');
+#endif
 	if (retval >= 0)
 		retval = count;
 	return retval;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static ssize_t aac_show_reset_adapter(struct class_device *class_dev,
+		char *buf)
+#else
 static ssize_t aac_show_reset_adapter(struct device *device,
 				      struct device_attribute *attr,
 				      char *buf)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+	struct aac_dev *dev = (struct aac_dev*)class_to_shost(class_dev)->hostdata;
+#else
 	struct aac_dev *dev = (struct aac_dev*)class_to_shost(device)->hostdata;
+#endif
 	int len, tmp;
 
 	tmp = aac_adapter_check_health(dev);
@@ -952,70 +2757,205 @@ static ssize_t aac_show_reset_adapter(struct device *device,
 	return len;
 }
 
+#endif
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static ssize_t aac_store_uart_adapter(struct class_device *class_dev,
+		const char *buf, size_t count)
+#else
+static ssize_t aac_store_uart_adapter(struct device *device,
+				      struct device_attribute *attr,
+				      const char *buf, size_t count)
+#endif
+{
+	if (nblank(fwprintf(x))) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+		struct aac_dev *dev = (struct aac_dev*)class_to_shost(class_dev)->hostdata;
+#else
+		struct aac_dev *dev = (struct aac_dev*)class_to_shost(device)->hostdata;
+#endif
+		unsigned len = count;
+		unsigned long seconds = get_seconds();
+
+		/* Trim off trailing space */
+		while ((len > 0) && ((buf[len-1] == '\n') ||
+		  (buf[len-1] == '\r') || (buf[len-1] == '\t') ||
+		  (buf[len-1] == ' ')))
+			--len;
+		if (len > (dev->FwDebugBufferSize - 10))
+			len = dev->FwDebugBufferSize - 10;
+		seconds = seconds;
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B, "%02u:%02u:%02u: %.*s",
+		  (int)((seconds / 3600) % 24), (int)((seconds / 60) % 60),
+		  (int)(seconds % 60), len, buf));
+	}
+	return count;
+}
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static ssize_t aac_show_uart_adapter(struct class_device *class_dev,
+		char *buf)
+#else
+static ssize_t aac_show_uart_adapter(struct device *device,
+				     struct device_attribute *attr,
+				     char *buf)
+#endif
+{
+	return snprintf(buf, PAGE_SIZE, nblank(fwprintf(x)) ? "YES\n" : "NO\n");
+}
+
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_model = {
+#else
 static struct device_attribute aac_model = {
+#endif
 	.attr = {
 		.name = "model",
 		.mode = S_IRUGO,
 	},
 	.show = aac_show_model,
 };
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_vendor = {
+#else
 static struct device_attribute aac_vendor = {
+#endif
 	.attr = {
 		.name = "vendor",
 		.mode = S_IRUGO,
 	},
 	.show = aac_show_vendor,
 };
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_flags = {
+#else
 static struct device_attribute aac_flags = {
+#endif
 	.attr = {
 		.name = "flags",
 		.mode = S_IRUGO,
 	},
 	.show = aac_show_flags,
 };
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_kernel_version = {
+#else
 static struct device_attribute aac_kernel_version = {
+#endif
 	.attr = {
 		.name = "hba_kernel_version",
 		.mode = S_IRUGO,
 	},
 	.show = aac_show_kernel_version,
 };
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_monitor_version = {
+#else
 static struct device_attribute aac_monitor_version = {
+#endif
 	.attr = {
 		.name = "hba_monitor_version",
 		.mode = S_IRUGO,
 	},
 	.show = aac_show_monitor_version,
 };
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_bios_version = {
+#else
 static struct device_attribute aac_bios_version = {
+#endif
 	.attr = {
 		.name = "hba_bios_version",
 		.mode = S_IRUGO,
 	},
 	.show = aac_show_bios_version,
 };
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,10))
+static struct class_device_attribute aac_lld_version = {
+	.attr = {
+		.name = "driver_version",
+		.mode = S_IRUGO,
+	},
+	.show = aac_show_driver_version,
+};
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_serial_number = {
+#else
 static struct device_attribute aac_serial_number = {
+#endif
 	.attr = {
 		.name = "serial_number",
 		.mode = S_IRUGO,
 	},
 	.show = aac_show_serial_number,
 };
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_max_channel = {
+#else
 static struct device_attribute aac_max_channel = {
+#endif
 	.attr = {
 		.name = "max_channel",
 		.mode = S_IRUGO,
 	},
 	.show = aac_show_max_channel,
 };
+#if (defined(AAC_DEBUG_INSTRUMENT_SETUP))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_hba_max_channel = {
+#else
+static struct device_attribute aac_hba_max_channel = {
+#endif
+	.attr = {
+		.name = "hba_max_channel",
+		.mode = S_IRUGO,
+	},
+	.show = aac_show_hba_max_channel,
+};
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_hba_max_physical = {
+#else
+static struct device_attribute aac_hba_max_physical = {
+#endif
+	.attr = {
+		.name = "hba_max_physical",
+		.mode = S_IRUGO,
+	},
+	.show = aac_show_hba_max_physical,
+};
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_hba_max_array = {
+#else
+static struct device_attribute aac_hba_max_array = {
+#endif
+	.attr = {
+		.name = "hba_max_array",
+		.mode = S_IRUGO,
+	},
+	.show = aac_show_hba_max_array,
+};
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_max_id = {
+#else
 static struct device_attribute aac_max_id = {
+#endif
 	.attr = {
 		.name = "max_id",
 		.mode = S_IRUGO,
 	},
 	.show = aac_show_max_id,
 };
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_reset = {
+#else
 static struct device_attribute aac_reset = {
+#endif
 	.attr = {
 		.name = "reset_host",
 		.mode = S_IWUSR|S_IRUGO,
@@ -1023,51 +2963,457 @@ static struct device_attribute aac_reset = {
 	.store = aac_store_reset_adapter,
 	.show = aac_show_reset_adapter,
 };
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute aac_uart = {
+#else
+static struct device_attribute aac_uart = {
+#endif
+	.attr = {
+		.name = "uart",
+		.mode = S_IWUSR|S_IRUGO,
+	},
+	.store = aac_store_uart_adapter,
+	.show = aac_show_uart_adapter,
+};
+#endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct class_device_attribute *aac_attrs[] = {
+#else
 static struct device_attribute *aac_attrs[] = {
+#endif
 	&aac_model,
 	&aac_vendor,
 	&aac_flags,
 	&aac_kernel_version,
 	&aac_monitor_version,
 	&aac_bios_version,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,10))
+	&aac_lld_version,
+#endif
 	&aac_serial_number,
 	&aac_max_channel,
+#if (defined(AAC_DEBUG_INSTRUMENT_SETUP))
+	&aac_hba_max_channel,
+	&aac_hba_max_physical,
+	&aac_hba_max_array,
+#endif
 	&aac_max_id,
 	&aac_reset,
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+	&aac_uart,
+#endif
 	NULL
 };
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26))
 
 ssize_t aac_get_serial_number(struct device *device, char *buf)
 {
 	return aac_show_serial_number(device, &aac_serial_number, buf);
 }
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,10,0))
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || defined(CONFIG_SCSI_PROC_FS))
+
+/**
+ *	aac_procinfo	-	Implement /proc/scsi/<drivername>/<n>
+ *	@proc_buffer: memory buffer for I/O
+ *	@start_ptr: pointer to first valid data
+ *	@offset: offset into file
+ *	@bytes_available: space left
+ *	@host_no: scsi host ident
+ *	@write: direction of I/O
+ *
+ *	Used to export driver statistics and other infos to the world outside
+ *	the kernel using the proc file system. Also provides an interface to
+ *	feed the driver with information.
+ *
+ *		For reads
+ *			- if offset > 0 return -EINVAL
+ *			- if offset == 0 write data to proc_buffer and set the start_ptr to
+ *			beginning of proc_buffer, return the number of characters written.
+ *		For writes
+ *			- writes currently not supported, return -EINVAL
+ *
+ *	Bugs:	Only offset zero is handled
+ */
+static int aac_procinfo(
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
+	struct Scsi_Host * shost,
+#endif
+	char *proc_buffer, char **start_ptr,off_t offset,
+	int bytes_available,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	int host_no,
+#endif
+	int write)
+{
+	struct aac_dev * dev = (struct aac_dev *)NULL;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	struct Scsi_Host * shost = (struct Scsi_Host *)NULL;
+#endif
+	char *buf;
+	int len;
+	int total_len = 0;
+
+	*start_ptr = proc_buffer;
+#if (defined(AAC_LM_SENSOR) || defined(IOP_RESET))
+	if(offset > 0)
+#else
+	if ((!nblank(fwprintf(x)) && write) || offset > 0)
+#endif
+		return 0;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	list_for_each_entry(dev, &aac_devices, entry) {
+		shost = dev->scsi_host_ptr;
+		if (shost->host_no == host_no)
+			break;
+	}
+	if (shost == (struct Scsi_Host *)NULL)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		return 0;
+#else
+		return -ENODEV;
+#endif
+#endif
+	dev = (struct aac_dev *)shost->hostdata;
+	if (dev == (struct aac_dev *)NULL)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		return 0;
+#else
+		return -ENODEV;
+#endif
+	if (!write) {
+		buf = kmalloc(PAGE_SIZE, GFP_KERNEL);
+		if (!buf)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+			return 0;
+#else
+			return -ENOMEM;
+#endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+		len = snprintf(proc_buffer, bytes_available,
+		  "Adaptec Raid Controller: %s\n", aac_driver_version);
+#else
+		len = sprintf(proc_buffer,
+		  "Adaptec Raid Controller: %s\n", aac_driver_version);
+#endif
+		total_len = len;
+		proc_buffer += len;
+		if (bytes_available > total_len) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+			len = aac_show_vendor(shost_to_class(shost), buf);
+#else
+			len = aac_show_vendor(shost_to_class(shost), &aac_vendor, buf);
+#endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+			len = snprintf(proc_buffer, bytes_available - total_len,
+			  "Vendor: %.*s  ", len - 1, buf);
+#else
+			len = sprintf(proc_buffer, "Vendor: %.*s  ", len - 1, buf);
+#endif
+			total_len += len;
+			proc_buffer += len;
+		}
+		if (bytes_available > total_len) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+			len = aac_show_model(shost_to_class(shost), buf);
+#else
+			len = aac_show_model(shost_to_class(shost), &aac_model, buf);
+#endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+			len = snprintf(proc_buffer, bytes_available - total_len,
+			  "Model: %.*s", len, buf);
+#else
+			len = sprintf(proc_buffer, "Model: %.*s", len, buf);
+#endif
+			total_len += len;
+			proc_buffer += len;
+		}
+		if (bytes_available > total_len) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+			len = aac_show_flags(shost_to_class(shost), buf);
+#else
+			len = aac_show_flags(shost_to_class(shost), &aac_flags, buf);
+#endif
+			if (len) {
+				char *cp = proc_buffer;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+				len = snprintf(cp, bytes_available - total_len,
+				  "flags=%.*s", len, buf);
+#else
+				len = sprintf(cp, "flags=%.*s", len, buf);
+#endif
+				total_len += len;
+				proc_buffer += len;
+				while (--len > 0) {
+					if (*cp == '\n')
+						*cp = '+';
+					++cp;
+				}
+			}
+		}
+		if (bytes_available > total_len) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+			len = aac_show_kernel_version(shost_to_class(shost), buf);
+#else
+			len = aac_show_kernel_version(shost_to_class(shost), &aac_kernel_version, buf);
+#endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+			len = snprintf(proc_buffer, bytes_available - total_len,
+			  "kernel: %.*s", len, buf);
+#else
+			len = sprintf(proc_buffer, "kernel: %.*s", len, buf);
+			total_len += len;
+			proc_buffer += len;
+#endif
+		}
+		if (bytes_available > total_len) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+			len = aac_show_monitor_version(shost_to_class(shost), buf);
+#else
+			len = aac_show_monitor_version(shost_to_class(shost), &aac_monitor_version, buf);
+#endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+			len = snprintf(proc_buffer, bytes_available - total_len,
+			  "monitor: %.*s", len, buf);
+#else
+			len = sprintf(proc_buffer, "monitor: %.*s", len, buf);
+#endif
+			total_len += len;
+			proc_buffer += len;
+		}
+		if (bytes_available > total_len) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+			len = aac_show_bios_version(shost_to_class(shost), buf);
+#else
+			len = aac_show_bios_version(shost_to_class(shost), &aac_bios_version, buf);
+#endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+			len = snprintf(proc_buffer, bytes_available - total_len,
+			  "bios: %.*s", len, buf);
+#else
+			len = sprintf(proc_buffer, "bios: %.*s", len, buf);
+#endif
+			total_len += len;
+			proc_buffer += len;
+		}
+		if (bytes_available > total_len) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+			len = aac_show_serial_number(shost_to_class(shost), buf);
+#else
+			len = aac_get_serial_number(shost_to_class(shost), buf);
+#endif
+			if (len) {
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,4))
+				len = snprintf(proc_buffer, bytes_available - total_len,
+				  "serial: %.*s", len, buf);
+#else
+				len = sprintf(proc_buffer, "serial: %.*s", len, buf);
+#endif
+				total_len += len;
+			}
+		}
+		kfree(buf);
+		return total_len;
+	}
+#if (defined(IOP_RESET))
+	{
+		static char reset[] = "reset_host";
+		if (strnicmp (proc_buffer, reset, sizeof(reset) - 1) == 0) {
+			if (!capable(CAP_SYS_ADMIN))
+				return -EPERM;
+			(void)aac_reset_adapter(dev,
+			    proc_buffer[sizeof(reset) - 1] == '!');
+			return bytes_available;
+		}
+	}
+#endif
+	if (nblank(fwprintf(x))) {
+		static char uart[] = "uart=";
+		if (strnicmp (proc_buffer, uart, sizeof(uart) - 1) == 0) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+			(void)aac_store_uart_adapter(shost_to_class(shost),
+			  &proc_buffer[sizeof(uart) - 1],
+			  bytes_available - (sizeof(uart) - 1));
+#else
+			(void)aac_store_uart_adapter(shost_to_class(shost),
+			  &aac_uart,		
+			  &proc_buffer[sizeof(uart) - 1],
+			  bytes_available - (sizeof(uart) - 1));
+#endif
+			return bytes_available;
+		}
+	}
+#if (defined(AAC_LM_SENSOR))
+	{
+		int ret, tmp, index;
+		s32 temp[5];
+		static char temperature[] = "temperature=";
+		if (strnicmp (proc_buffer, temperature, sizeof(temperature) - 1))
+			return bytes_available;
+		for (index = 0;
+		  index < (sizeof(temp)/sizeof(temp[0]));
+		  ++index)
+			temp[index] = 0x80000000;
+		ret = sizeof(temperature) - 1;
+		for (index = 0;
+		  index < (sizeof(temp)/sizeof(temp[0]));
+		  ++index) {
+			int sign, mult, c;
+			if (ret >= bytes_available)
+				break;
+			c = proc_buffer[ret];
+			if (c == '\n') {
+				++ret;
+				break;
+			}
+			if (c == ',') {
+				++ret;
+				continue;
+			}
+			sign = 1;
+			mult = 0;
+			tmp = 0;
+			if (c == '-') {
+				sign = -1;
+				++ret;
+			}
+			for (;
+			  (ret < bytes_available) && ((c = proc_buffer[ret]));
+			  ++ret) {
+				if (('0' <= c) && (c <= '9')) {
+					tmp *= 10;
+					tmp += c - '0';
+					mult *= 10;
+				} else if ((c == '.') && (mult == 0))
+					mult = 1;
+				else
+					break;
+			}
+			if ((ret < bytes_available)
+			 && ((c == ',') || (c == '\n')))
+				++ret;
+			if (!mult)
+				mult = 1;
+			if (sign < 0)
+				tmp = -tmp;
+			temp[index] = ((tmp << 8) + (mult >> 1)) / mult;
+			if (c == '\n')
+				break;
+		}
+		ret = index;
+		if (nblank(dprintk(x))) {
+			for (index = 0; index < ret; ++index) {
+				int sign;
+				tmp = temp[index];
+				sign = tmp < 0;
+				if (sign)
+					tmp = -tmp;
+				dprintk((KERN_DEBUG "%s%s%d.%08doC",
+				  (index ? "," : ""),
+				  (sign ? "-" : ""),
+				  tmp >> 8, (tmp % 256) * 390625));
+			}
+		}
+		/* Send temperature message to Firmware */
+		(void)aac_adapter_sync_cmd(dev, RCV_TEMP_READINGS,
+		  ret, temp[0], temp[1], temp[2], temp[3], temp[4],
+		  NULL, NULL, NULL, NULL, NULL);
+		return bytes_available;
+	}
+#endif
+	return -EINVAL;
+}
+#endif
+#endif
+#if (!defined(HAS_BOOT_CONFIG))
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+static struct file_operations aac_cfg_fops = {
+#else
 static const struct file_operations aac_cfg_fops = {
+#endif
 	.owner		= THIS_MODULE,
-	.unlocked_ioctl	= aac_cfg_ioctl,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,35))
+	.ioctl		= aac_cfg_ioctl,
+#else
+	.unlocked_ioctl = aac_cfg_ioctl,
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11))
 #ifdef CONFIG_COMPAT
 	.compat_ioctl   = aac_compat_cfg_ioctl,
 #endif
+#endif
 	.open		= aac_cfg_open,
-	.llseek		= noop_llseek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	.release	= aac_cfg_release
+#endif
+};
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) && defined(SCSI_HAS_DUMP))
+static struct scsi_dump_ops aac_dump_ops = {
+#if (defined(SCSI_HAS_DUMP_SANITY_CHECK))
+	.sanity_check	= aac_sanity_check,
+#endif
+	.poll		= aac_poll,
 };
 
+#define aac_driver_template aac_driver_template_dump.hostt
+static struct SHT_dump aac_driver_template_dump = {
+	.hostt = {
+#else
+
 static struct scsi_host_template aac_driver_template = {
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	.detect				= aac_detect,
+#endif
+#if (defined(__VMKERNEL_MODULE__) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,4)))
+	.release			= aac_release,
+#endif
 	.module				= THIS_MODULE,
+#if (defined(__VMKLNX30__) || defined(__VMKLNX__))
+	.name				= "aacraid",
+#else
 	.name				= "AAC",
+#endif
 	.proc_name			= AAC_DRIVERNAME,
 	.info				= aac_info,
+#if (!defined(HAS_BOOT_CONFIG))
 	.ioctl				= aac_ioctl,
-#ifdef CONFIG_COMPAT
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11))
+#if (defined(CONFIG_COMPAT) && !defined(HAS_BOOT_CONFIG))
 	.compat_ioctl			= aac_compat_ioctl,
 #endif
+#endif
 	.queuecommand			= aac_queuecommand,
 	.bios_param			= aac_biosparm,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,10,0))
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || defined(CONFIG_SCSI_PROC_FS))
+	.proc_info			= aac_procinfo,
+#endif
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0))
 	.shost_attrs			= aac_attrs,
 	.slave_configure		= aac_slave_configure,
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11))
 	.change_queue_depth		= aac_change_queue_depth,
+#endif
+#ifdef RHEL_MAJOR
+#if (RHEL_MAJOR == 6 && RHEL_MINOR >= 2)
+	.lockless			= 1,
+#endif
+#endif
 	.sdev_attrs			= aac_dev_attrs,
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+	.eh_device_reset_handler	= aac_eh_device_reset,
+	.eh_bus_reset_handler		= aac_eh_bus_reset,
+#endif
 	.eh_abort_handler		= aac_eh_abort,
 	.eh_host_reset_handler		= aac_eh_reset,
 	.can_queue			= AAC_NUM_IO_FIB,
@@ -1079,16 +3425,65 @@ static struct scsi_host_template aac_driver_template = {
 #else
 	.cmd_per_lun			= AAC_NUM_IO_FIB,
 #endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	.use_new_eh_code		= 1,
+#endif
 	.use_clustering			= ENABLE_CLUSTERING,
+#if (((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,23)) || defined(ENABLE_SG_CHAINING)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)))
+	.use_sg_chaining		= ENABLE_SG_CHAINING,
+#endif
 	.emulated			= 1,
-	.no_write_same			= 1,
+#if (defined(SCSI_HAS_VARY_IO))
+	.vary_io			= 1,
+#endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,0))
+#if (defined(SCSI_HAS_DUMP))
+#if (defined(SCSI_HAS_DUMP_SANITY_CHECK))
+	.dump_sanity_check		= aac_sanity_check,
+#endif
+	.dump_poll			= aac_poll,
+#endif
+#elif (defined(SCSI_HAS_DUMP))
+	.disk_dump			= 1,
+},
+	.dump_ops			= &aac_dump_ops,
+#endif
 };
 
 static void __aac_shutdown(struct aac_dev * aac)
 {
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+	printk(KERN_INFO
+	  "__aac_shutdown(%p={.aif_thread=%d,.thread_pid=%d,.shutdown=%d) - ENTER\n"
+	  aac, aac->aif_thread, aac->thread_pid, aac->shutdown);
+#endif
+	if (aac->aif_thread && (aac->thread_pid > 0)) {
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+		aac->thread_die = 1;
+#else
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+		printk(KERN_INFO "kill_proc(%d,SIGKILL,0)\n", aac->thread_pid);
+#endif
+		kill_proc(aac->thread_pid, SIGKILL, 0);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+		printk(KERN_INFO "wait_for_completion(%p)\n",
+		  &aac->aif_completion);
+#endif
+		wait_for_completion(&aac->aif_completion);
+	}
+#else
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+	printk(KERN_INFO
+	  "__aac_shutdown(%p={.aif_thread=%d,.thread=%p,.shutdown=%d) - ENTER\n",
+	  aac, aac->aif_thread, aac->thread, aac->shutdown);
+#endif
 	if (aac->aif_thread) {
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+		printk(KERN_INFO "kthread_stop(%p)\n", aac->thread);
+#endif
 		int i;
-		/* Clear out events first */
 		for (i = 0; i < (aac->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB); i++) {
 			struct fib *fib = &aac->fibs[i];
 			if (!(fib->hw_fib_va->header.XferState & cpu_to_le32(NoResponseExpected | Async)) &&
@@ -1097,14 +3492,47 @@ static void __aac_shutdown(struct aac_dev * aac)
 		}
 		kthread_stop(aac->thread);
 	}
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+	printk(KERN_INFO "aac_send_shutdown(%p)\n", aac);
+#endif
 	aac_send_shutdown(aac);
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+	printk(KERN_INFO "aac_adapter_disable_int(%p)\n", aac);
+#endif
 	aac_adapter_disable_int(aac);
-	free_irq(aac->pdev->irq, aac);
-	if (aac->msi)
-		pci_disable_msi(aac->pdev);
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+	printk(KERN_INFO "free_irq(%d,%p)\n", aac->pdev->irq, aac);
+#endif
+	aac_free_irq(aac);
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+	printk(KERN_INFO "__aac_shutdown(%p) - EXIT\n", aac);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN) || ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)) && ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,11)) && !defined(PCI_HAS_SHUTDOWN)))))
+	aac->shutdown = 1;
+#endif
+}
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)) && ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,11)) && !defined(PCI_HAS_SHUTDOWN))))
+
+static void aac_device_shutdown(struct device *dev)
+{
+	struct aac_dev *aac;
+
+	list_for_each_entry(aac, &aac_devices, entry)
+		if (!aac->shutdown && (dev == &aac->pdev->dev)) {
+			scsi_block_requests(aac->scsi_host_ptr);
+			__aac_shutdown(aac);
+		}
 }
+#endif
 
-static int aac_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,8,0))
+static int __devinit aac_probe_one(struct pci_dev *pdev,
+		const struct pci_device_id *id)
+#else
+static int aac_probe_one(struct pci_dev *pdev,
+		const struct pci_device_id *id)
+#endif
 {
 	unsigned index = id->driver_data;
 	struct Scsi_Host *shost;
@@ -1112,9 +3540,51 @@ static int aac_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)
 	struct list_head *insert = &aac_devices;
 	int error = -ENODEV;
 	int unique_id = 0;
-	u64 dmamask;
+#if (defined(__arm__) || defined(CONFIG_EXTERNAL))
+	static struct pci_dev * slave = NULL;
+	static int nslave = 0;
+#endif
 	extern int aac_sync_mode;
 
+#if (defined(__arm__) || defined(CONFIG_EXTERNAL))
+	if (aac_drivers[index].quirks & AAC_QUIRK_SLAVE) {
+		/* detect adjoining slaves */
+		if (slave) {
+			if ((pci_resource_start(pdev, 0)
+			  + pci_resource_len(pdev, 0))
+			  == pci_resource_start(slave, 0))
+				slave = pdev;
+			else if ((pci_resource_start(slave, 0)
+			  + (pci_resource_len(slave, 0) * nslave))
+			  != pci_resource_start(pdev, 0)) {
+				printk(KERN_WARNING AAC_DRIVERNAME
+				  ": multiple sets of slave controllers discovered\n");
+				nslave = 0;
+				slave = pdev;
+			}
+		} else
+			slave = pdev;
+		if (pci_resource_start(slave,0)) {
+			error = pci_enable_device(pdev);
+			if (error) {
+				printk(KERN_WARNING AAC_DRIVERNAME
+				  ": failed to enable slave\n");
+				nslave = 0;
+				slave = NULL;
+				return error;
+			}
+			++nslave;
+			pci_set_master(pdev);
+		} else {
+			printk(KERN_WARNING AAC_DRIVERNAME
+			  ": slave BAR0 is not set\n");
+			nslave = 0;
+			slave = NULL;
+			return error;
+		}
+		return 1;
+	}
+#endif
 	list_for_each_entry(aac, &aac_devices, entry) {
 		if (aac->id > unique_id)
 			break;
@@ -1122,49 +3592,122 @@ static int aac_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)
 		unique_id++;
 	}
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,30))
 	pci_disable_link_state(pdev, PCIE_LINK_STATE_L0S | PCIE_LINK_STATE_L1 |
-			       PCIE_LINK_STATE_CLKPM);
-
+					PCIE_LINK_STATE_CLKPM);
+#endif
 	error = pci_enable_device(pdev);
 	if (error)
 		goto out;
 	error = -ENODEV;
+#if (defined(__arm__) || defined(CONFIG_EXTERNAL))
+	if ((aac_drivers[index].quirks & AAC_QUIRK_MASTER) && (slave)) {
+		unsigned long base = pci_resource_start(pdev, 0);
+		struct master_registers {
+			u32 x[51];
+			u32	E_CONFIG1;
+			u32 y[3];
+			u32	E_CONFIG2;
+		} __iomem * map = ioremap(base, AAC_MIN_FOOTPRINT_SIZE);
+		if (!map) {
+			printk(KERN_WARNING AAC_DRIVERNAME
+			  ": unable to map master adapter to configure slaves.\n");
+		} else {
+			((struct master_registers *)map)->E_CONFIG2
+			  = cpu_to_le32(pci_resource_start(slave, 0));
+			((struct master_registers *)map)->E_CONFIG1
+			  = cpu_to_le32(0x5A000000 + nslave);
+			iounmap(map);
+		}
+		nslave = 0;
+		slave = NULL;
+	}
+#endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0))
+	if (pci_set_dma_mask(pdev, DMA_32BIT_MASK) ||
+			pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK))
+#else
+	if (pci_set_dma_mask(pdev, DMA_BIT_MASK(32)) ||
+			pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32)))
+#endif
+		goto out_disable_pdev;
 	/*
 	 * If the quirk31 bit is set, the adapter needs adapter
 	 * to driver communication memory to be allocated below 2gig
 	 */
 	if (aac_drivers[index].quirks & AAC_QUIRK_31BIT)
-		dmamask = DMA_BIT_MASK(31);
-	else
-		dmamask = DMA_BIT_MASK(32);
-
-	if (pci_set_dma_mask(pdev, dmamask) ||
-			pci_set_consistent_dma_mask(pdev, dmamask))
-		goto out_disable_pdev;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0))
+		if (pci_set_dma_mask(pdev, DMA_31BIT_MASK) ||
+				pci_set_consistent_dma_mask(pdev, DMA_31BIT_MASK))
+#else
+		if (pci_set_dma_mask(pdev, DMA_BIT_MASK(31)) ||
+				pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(31)))
+#endif
+			goto out_disable_pdev;
 
 	pci_set_master(pdev);
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14))
+	aac_driver_template.name = aac_drivers[index].name;
+#endif
+#if ((defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__)) && !defined(__VMKLNX__))
+	shost = vmk_scsi_register(&aac_driver_template, sizeof(struct aac_dev), pdev->bus->number, pdev->devfn);
+#else
 	shost = scsi_host_alloc(&aac_driver_template, sizeof(struct aac_dev));
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+	printk(KERN_INFO "scsi_host_alloc(%p,%u)=%p\n",
+	  &aac_driver_template, sizeof(struct aac_dev), shost);
+#endif
 	if (!shost)
 		goto out_disable_pdev;
 
 	shost->irq = pdev->irq;
+	shost->base = pci_resource_start(pdev, 0);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	scsi_set_pci_device(shost, pdev);
+#elif (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,9))
+	scsi_set_device(shost, &pdev->dev);
+#endif
 	shost->unique_id = unique_id;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	/*
+	 *	This function is called after the device list
+	 *	has been built to find the tagged queueing
+	 *	depth supported for each device.
+	 */
+	shost->select_queue_depths = aac_queuedepth;
+#endif
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)) || defined(SERVICE_ACTION_IN))
 	shost->max_cmd_len = 16;
+#endif
 
 	aac = (struct aac_dev *)shost->hostdata;
-	aac->base_start = pci_resource_start(pdev, 0);
 	aac->scsi_host_ptr = shost;
 	aac->pdev = pdev;
 	aac->name = aac_driver_template.name;
 	aac->id = shost->unique_id;
 	aac->cardtype = index;
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_ENABLE_MSI) || defined(PCI_HAS_DISABLE_MSI))
+//	aac->msi = 0;
+#endif
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,5,0)) && ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,11)) && !defined(PCI_HAS_SHUTDOWN))))
+	pdev->dev.driver->shutdown = aac_device_shutdown;
+#endif
 	INIT_LIST_HEAD(&aac->entry);
 
-	aac->fibs = kzalloc(sizeof(struct fib) * (shost->can_queue + AAC_NUM_MGT_FIB), GFP_KERNEL);
+#if (defined(CONFIG_VMNIX) && !defined(__VMKERNEL_MODULE__) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,4)))
+	shost->bus = pdev->bus->number;
+	shost->devfn = pdev->devfn;
+	shost->devid = (void *)aac;
+#endif
+	do {
+		aac->fibs = kmalloc(sizeof(struct fib) * (shost->can_queue + AAC_NUM_MGT_FIB), GFP_KERNEL);
+	} while (!aac->fibs && (shost->can_queue -= 16) >= (64 - AAC_NUM_MGT_FIB));	
 	if (!aac->fibs)
 		goto out_free_host;
+	memset(aac->fibs, 0, sizeof(struct fib) * (shost->can_queue + AAC_NUM_MGT_FIB));
 	spin_lock_init(&aac->fib_lock);
 
 	/*
@@ -1175,30 +3718,165 @@ static int aac_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)
 		goto out_unmap;
 
 	if (aac->sync_mode) {
-		if (aac_sync_mode)
-			printk(KERN_INFO "%s%d: Sync. mode enforced "
-				"by driver parameter. This will cause "
-				"a significant performance decrease!\n",
-				aac->name,
-				aac->id);
-		else
-			printk(KERN_INFO "%s%d: Async. mode not supported "
-				"by current driver, sync. mode enforced."
-				"\nPlease update driver to get full performance.\n",
-				aac->name,
-				aac->id);
+		if (aac_sync_mode) 
+			printk(KERN_INFO "%s%d: Sync. mode enforced by driver parameter. This will cause a significant performance decrease!\n", aac->name, aac->id);
+		else  
+			printk(KERN_INFO "%s%d: Async. mode not supported by current driver, sync. mode enforced.\nPlease update driver to get full performance.\n", aac->name, aac->id);
 	}
 
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+	if (nblank(fwprintf(x))) {
+		aac_get_fw_debug_buffer(aac);
+#if (defined(UTS_MACHINE))
+#if (defined(CONFIG_M586))
+#undef UTS_MACHINE
+#define UTS_MACHINE "i586"
+#elif (defined(CONFIG_M686))
+#undef UTS_MACHINE
+#define UTS_MACHINE "i686"
+#elif (defined(CONFIG_PPC64))
+#undef UTS_MACHINE
+#define UTS_MACHINE "ppc64"
+#endif
+#else
+#if (defined(CONFIG_M386))
+#define UTS_MACHINE "i386"
+#elif (defined(CONFIG_M486))
+#define UTS_MACHINE "i486"
+#elif (defined(CONFIG_MK6))
+#define UTS_MACHINE "i486"
+#elif (defined(CONFIG_M586))
+#define UTS_MACHINE "i586"
+#elif (defined(CONFIG_MPENTIUMII))
+#define UTS_MACHINE "i586"
+#elif (defined(CONFIG_M686))
+#define UTS_MACHINE "i686"
+#elif (defined(CONFIG_MPENTIUMIII))
+#define UTS_MACHINE "i686"
+#elif (defined(CONFIG_MPENTIUM4))
+#define UTS_MACHINE "i686"
+#elif (defined(CONFIG_MK7))
+#define UTS_MACHINE "athlon"
+#elif (defined(CONFIG_MK8))
+#define UTS_MACHINE "x86_64"
+#elif (defined(CONFIG_IA32E))
+#define UTS_MACHINE "ia32e"
+#elif (defined(CONFIG_IA64))
+#define UTS_MACHINE "ia64"
+#elif (defined(CONFIG_X86_64))
+#define UTS_MACHINE "x86_64"
+#elif (defined(CONFIG_PPC64))
+#define UTS_MACHINE "ppc64"
+#elif (defined(CONFIG_PPC))
+#define UTS_MACHINE "ppc"
+#elif (defined(CONFIG_CPU_XSCALE_80200))
+#define UTS_MACHINE "xscale"
+#elif (defined(CONFIG_ARM))
+#define UTS_MACHINE "arm"
+#elif (defined(CONFIG_X86))
+#define UTS_MACHINE "i386"
+#endif
+#endif
+#if (defined(RHEL_VERSION))
+#define _str(x) #x
+#define str(x) _str(x)
+#if (RHEL_VERSION < 3)
+#define OSNAME "RHAS"
+#else
+#define OSNAME "RHEL"
+#endif
+#if (defined(RHEL_UPDATE))
+#if (RHEL_UPDATE != 0)
+#define OSVERSION str(RHEL_VERSION) "u" str(RHEL_UPDATE)
+#else
+#define OSVERSION str(RHEL_VERSION)
+#endif
+#else
+#define OSVERSION str(RHEL_VERSION)
+#endif
+#elif (defined(CONFIG_SUSE_KERNEL))
+#define OSNAME "SuSE"
+#define OSVERSION
+#elif (defined(CONFIG_SLES_KERNEL))
+#define OSNAME "SLES"
+#define OSVERSION
+#endif
+#if (defined(OSNAME))
+#if (defined(UTS_MACHINE))
+#define ARCH_NAME "(" OSNAME OSVERSION " " UTS_MACHINE ") "
+#else
+#define ARCH_NAME "(" OSNAME OSVERSION ") "
+#endif
+#elif (defined(UTS_MACHINE))
+#define ARCH_NAME "(" UTS_MACHINE ") "
+#else
+#define ARCH_NAME
+#endif
+#if (!defined(UTS_SYSNAME))
+#define UTS_SYSNAME "Linux"
+#endif
+#if (defined(UTS_RELEASE))
+#define UTS_ARGS
+#else
+#define UTS_RELEASE "%d.%d.%d"
+#define UTS_ARGS , LINUX_VERSION_CODE >> 16, (LINUX_VERSION_CODE >> 8) & 0xFF, LINUX_VERSION_CODE & 0xFF
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || defined(BOOTCD))
+		fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B, UTS_SYSNAME " "
+		  UTS_RELEASE " " ARCH_NAME AAC_DRIVERNAME " driver "
+		  AAC_DRIVER_FULL_VERSION " " AAC_DRIVER_BUILD_DATE
+		  "\nBAR0=0x%lx BAR1=0x%lx BAR2=0x%lx host->base=0x%lx rx=%p"
+		  " base=%p Index=%p base_size=%lu" UTS_ARGS,
+		  pci_resource_start(pdev, 0),
+		  pci_resource_start(pdev, 1),
+		  pci_resource_start(pdev, 2),
+		  shost->base, aac->regs.rx, aac->base, aac->IndexRegs,
+		  (unsigned long)aac->base_size));
+#else
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,16,0))
+		fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B, UTS_SYSNAME " "
+		  UTS_RELEASE " " ARCH_NAME AAC_DRIVERNAME " driver "
+		  AAC_DRIVER_FULL_VERSION " " AAC_DRIVER_BUILD_DATE UTS_ARGS));
+#endif
+#endif
+	}
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+	printk(KERN_INFO"BAR0=0x%lx BAR1=0x%lx BAR2=0x%lx"
+	  " host->base=0x%lx rx=%p base=%p Index=%p base_size=%lu\n",
+	  pci_resource_start(pdev, 0),
+	  pci_resource_start(pdev, 1),
+	  pci_resource_start(pdev, 2),
+	  shost->base, aac->regs.rx, aac->base, aac->IndexRegs,
+	  (unsigned long)aac->base_size);
+#endif
 	/*
 	 *	Start any kernel threads needed
 	 */
+#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,5)) && !defined(HAS_KTHREAD))
+	aac->thread_pid = kernel_thread((int (*)(void *))aac_command_thread,
+	  aac, 0);
+	if (aac->thread_pid < 0) {
+		printk(KERN_ERR "aacraid: Unable to create command thread.\n");
+#if (0 && defined(BOOTCD))
+		fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "aacraid: Unable to create command thread."));
+#endif
+		goto out_deinit;
+	}
+#else
 	aac->thread = kthread_run(aac_command_thread, aac, AAC_DRIVERNAME);
 	if (IS_ERR(aac->thread)) {
 		printk(KERN_ERR "aacraid: Unable to create command thread.\n");
 		error = PTR_ERR(aac->thread);
 		aac->thread = NULL;
+#if (0 && defined(BOOTCD))
+		fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B,
+		  "aacraid: Unable to create command thread."));
+#endif
 		goto out_deinit;
 	}
+#endif
 
 	/*
 	 * If we had set a smaller DMA mask earlier, set it to 4gig
@@ -1206,7 +3884,11 @@ static int aac_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)
 	 * address space.
 	 */
 	if (aac_drivers[index].quirks & AAC_QUIRK_31BIT)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,0,0))
+		if (pci_set_dma_mask(pdev, DMA_32BIT_MASK))
+#else
 		if (pci_set_dma_mask(pdev, DMA_BIT_MASK(32)))
+#endif
 			goto out_deinit;
 
 	aac->maximum_num_channels = aac_drivers[index].channels;
@@ -1229,12 +3911,14 @@ static int aac_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)
 		shost->max_sectors = (shost->sg_tablesize * 8) + 112;
 	}
 
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,24)) || defined(PCI_HAS_SET_DMA_MAX_SEG_SIZE))
 	error = pci_set_dma_max_seg_size(pdev,
 		(aac->adapter_info.options & AAC_OPT_NEW_COMM) ?
 			(shost->max_sectors << 9) : 65536);
 	if (error)
 		goto out_deinit;
 
+#endif
 	/*
 	 * Firmware printf works only with older firmware.
 	 */
@@ -1252,8 +3936,11 @@ static int aac_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)
 		shost->max_channel = aac->maximum_num_channels;
 	else
 		shost->max_channel = 0;
-
-	aac_get_config_status(aac, 0);
+#if defined(__powerpc__) || defined(__PPC__) || defined(__ppc__)
+	aac_get_config_status(aac, 1);
+#else
+    aac_get_config_status(aac, 0);
+#endif
 	aac_get_containers(aac);
 	list_add(&aac->entry, insert);
 
@@ -1271,6 +3958,15 @@ static int aac_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)
 	 */
 	shost->max_lun = AAC_MAX_LUN;
 
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,4))
+	scsi_register_uinfo(shost, pdev->bus->number, pdev->devfn, (void *)aac);
+#elif (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	vmk_scsi_register_uinfo(shost, pdev->bus->number, pdev->devfn, (void *)aac);
+#else
+	shost->xportFlags = VMKLNX_SCSI_TRANSPORT_TYPE_PSCSI;
+#endif
+#endif
 	pci_set_drvdata(pdev, shost);
 
 	error = scsi_add_host(shost, &pdev->dev);
@@ -1278,6 +3974,44 @@ static int aac_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)
 		goto out_deinit;
 	scsi_scan_host(shost);
 
+#if defined(__ESX5__)
+	if (aac->pdev->device == PMC_DEVICE_S6 ||
+	    aac->pdev->device == PMC_DEVICE_S7 ||
+	    aac->pdev->device == PMC_DEVICE_S8 ||
+	    aac->pdev->device == PMC_DEVICE_S9) {
+		if (aac->max_msix > 1)
+			vmklnx_scsi_register_poll_handler(shost, aac->msixentry[0].vector,
+				aac->a_ops.adapter_intr_poll, &(aac->aac_msix[0]));
+		else
+			vmklnx_scsi_register_poll_handler(shost, aac->pdev->irq,
+				aac->a_ops.adapter_intr, &(aac->aac_msix[0]));
+
+	} else {
+		vmklnx_scsi_register_poll_handler(shost, aac->pdev->irq,
+			aac->a_ops.adapter_intr, aac);
+	}
+#endif
+
+#if (defined(AAC_DEBUG_INSTRUMENT_INIT) || (0 && defined(BOOTCD)))
+	fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B,
+	  "aac_probe_one() returns success"));
+#endif
+
+	if (aac->pdev->device == PMC_DEVICE_S6) {
+		if (aac->msi)
+			fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B, "%s%d: This Tupelo driver is MSI enabled", aac->name, aac->id));
+		else
+			fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B, "%s%d: This Tupelo driver is INTx enabled", aac->name, aac->id));
+	} else if(aac->pdev->device == PMC_DEVICE_S7 ||
+		  aac->pdev->device == PMC_DEVICE_S8) {
+		if (aac->max_msix > 1)
+			fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B, "%s%d: This driver is MSI-x enabled", aac->name, aac->id));
+		else if (aac->msi)
+			fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B, "%s%d: This driver is MSI enabled", aac->name, aac->id));
+		else
+			fwprintf((aac, HBA_FLAGS_DBG_FW_PRINT_B, "%s%d: This driver is INTx enabled", aac->name, aac->id));
+	}
+
 	return 0;
 
  out_deinit:
@@ -1291,6 +4025,9 @@ static int aac_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)
 	aac_adapter_ioremap(aac, 0);
 	kfree(aac->fibs);
 	kfree(aac->fsa_dev);
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+	spin_lock_destroy(&aac->fib_lock);
+#endif
  out_free_host:
 	scsi_host_put(shost);
  out_disable_pdev:
@@ -1299,6 +4036,99 @@ static int aac_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)
 	return error;
 }
 
+#if (defined(CONFIG_PM))
+extern void aac_define_int_mode(struct aac_dev *dev);
+void aac_release_resources(struct aac_dev *aac) 
+{
+	aac_adapter_disable_int(aac);
+	aac_free_irq(aac);
+}
+
+static int aac_acquire_resources(struct aac_dev *dev) {
+	unsigned long status;
+	/*
+	 *	First clear out all interrupts.  Then enable the one's that we
+	 *	can handle.
+	 */
+	while (!((status=src_readl(dev, MUnit.OMR)) & KERNEL_UP_AND_RUNNING) ||
+		status == 0xffffffff)
+			msleep(1);
+
+	aac_adapter_disable_int(dev);
+	aac_adapter_enable_int(dev);
+
+	if ((dev->pdev->device == PMC_DEVICE_S7 ||
+	     dev->pdev->device == PMC_DEVICE_S8 ||
+	     dev->pdev->device == PMC_DEVICE_S9))
+		aac_define_int_mode(dev);
+
+	if (dev->msi_enabled)
+		aac_src_access_devreg(dev, AAC_ENABLE_MSIX);
+	
+	if(aac_acquire_irq(dev))
+		goto error_iounmap;
+
+	aac_adapter_enable_int(dev);
+
+	if (!dev->sync_mode)
+		aac_adapter_start(dev);
+	return 0;
+
+error_iounmap:
+	return -1;
+	
+}
+static int aac_suspend(struct pci_dev *pdev, pm_message_t state) {
+	
+	struct Scsi_Host *shost = pci_get_drvdata(pdev);
+	struct aac_dev *aac = (struct aac_dev *)shost->hostdata;
+	
+	scsi_block_requests(shost);
+	aac_send_shutdown(aac);
+
+	aac_release_resources(aac);
+
+	pci_set_drvdata(pdev, shost);
+	pci_save_state(pdev);
+	pci_disable_device(pdev);
+	pci_set_power_state(pdev, pci_choose_state(pdev, state));
+
+	return 0;
+}
+
+static int aac_resume(struct pci_dev *pdev) {
+	struct Scsi_Host *shost = pci_get_drvdata(pdev);
+	struct aac_dev *aac = (struct aac_dev *)shost->hostdata;
+	int r;
+	
+	pci_set_power_state(pdev, PCI_D0);
+	pci_enable_wake(pdev, PCI_D0, 0);
+	pci_restore_state(pdev);
+	r = pci_enable_device(pdev);
+
+	if (r)
+		goto fail_device;
+
+	pci_set_master(pdev);
+	if (aac_acquire_resources(aac))
+		goto fail_device;
+	/*
+	* reset this flag to unblock ioctl() as it was set at aac_send_shutdown() to block ioctls from upperlayer
+	*/
+	aac->adapter_shutdown = 0;
+	scsi_unblock_requests(shost);
+
+        return 0;
+
+fail_device:
+	printk(KERN_INFO "%s%d: resume failed.\n", aac->name, aac->id);
+	scsi_host_put(shost);
+	pci_disable_device(pdev);
+	return -ENODEV;
+}
+#endif
+
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,11)) || defined(PCI_HAS_SHUTDOWN)))
 static void aac_shutdown(struct pci_dev *dev)
 {
 	struct Scsi_Host *shost = pci_get_drvdata(dev);
@@ -1306,7 +4136,12 @@ static void aac_shutdown(struct pci_dev *dev)
 	__aac_shutdown((struct aac_dev *)shost->hostdata);
 }
 
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,8,0))
+static void __devexit aac_remove_one(struct pci_dev *pdev)
+#else
 static void aac_remove_one(struct pci_dev *pdev)
+#endif
 {
 	struct Scsi_Host *shost = pci_get_drvdata(pdev);
 	struct aac_dev *aac = (struct aac_dev *)shost->hostdata;
@@ -1324,49 +4159,251 @@ static void aac_remove_one(struct pci_dev *pdev)
 	kfree(aac->fibs);
 	kfree(aac->fsa_dev);
 
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+	spin_lock_destroy(&aac->fib_lock);
+#endif
 	list_del(&aac->entry);
 	scsi_host_put(shost);
 	pci_disable_device(pdev);
+#if (!defined(HAS_BOOT_CONFIG))
 	if (list_empty(&aac_devices)) {
 		unregister_chrdev(aac_cfg_major, "aac");
 		aac_cfg_major = -1;
 	}
+#endif
 }
 
 static struct pci_driver aac_pci_driver = {
 	.name		= AAC_DRIVERNAME,
 	.id_table	= aac_pci_tbl,
 	.probe		= aac_probe_one,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,8,0))
+	.remove		= __devexit_p(aac_remove_one),
+#else
 	.remove		= aac_remove_one,
+#endif
+#if (defined(CONFIG_PM))
+	.suspend	= aac_suspend,
+	.resume		= aac_resume,
+#endif
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)) && ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,11)) || defined(PCI_HAS_SHUTDOWN)))
 	.shutdown	= aac_shutdown,
+#endif
+};
+
+//#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,11)) && !defined(PCI_HAS_SHUTDOWN)))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+static int aac_reboot_event(struct notifier_block * n, ulong code, void *p)
+{
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+	printk(KERN_INFO "aac_reboot_event(%p,%lu,%p) - ENTER\n", n, code, p);
+#endif
+	if ((code == SYS_RESTART)
+	 || (code == SYS_HALT)
+	 || (code == SYS_POWER_OFF)) {
+		struct aac_dev *aac;
+
+		/*
+		 * We would like to do a block and __aac_shutdown but we
+		 * can not because sd_shutdown has yet to be called and
+		 * it will trigger additional commands to the driver.
+		 */
+		list_for_each_entry(aac, &aac_devices, entry)
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+		{
+#endif
+			aac_send_shutdown(aac);
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+			aac->shutdown = 1;
+		}
+#endif
+	}
+#if (defined(AAC_DEBUG_INSTRUMENT_SHUTDOWN))
+	printk(KERN_INFO "aac_reboot_event(%p,%lu,%p) - EXIT NOTIFY_DONE\n",
+	  n, code, p);
+#endif
+	return NOTIFY_DONE;
+}
+
+static struct notifier_block aac_reboot_notifier =
+{
+	aac_reboot_event,
+	NULL,
+	0
 };
 
+#endif
 static int __init aac_init(void)
 {
 	int error;
 
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,4) && !defined(__VMKLNX__))
+	if (!vmk_set_module_version(AAC_DRIVERNAME " (" AAC_DRIVER_BUILD_DATE ")"))
+		return 0;
+#endif
+	spin_lock_init(&io_request_lock);
+#if (!defined(__VMKLNX__))
+	aac_driver_template.driverLock = &io_request_lock;
+#endif
+#endif
 	printk(KERN_INFO "Adaptec %s driver %s\n",
 	  AAC_DRIVERNAME, aac_driver_version);
+//#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11)) || ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,11)) && !defined(PCI_HAS_SHUTDOWN)))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	register_reboot_notifier(&aac_reboot_notifier);
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) && defined(SCSI_HAS_SCSI_IN_DETECTION) && !defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__) && !defined(__VMKLNX__))
+	scsi_register_module(MODULE_SCSI_HA,&aac_driver_template);
+	/* Reverse 'detect' action */
+	aac_driver_template.present = 0;
+#endif
+#if (defined(__VMKLNX30__) && (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0)))
+	if (!vmklnx_set_module_version("%s", aac_driver_version))
+		return -ENODEV;
+#endif
 
 	error = pci_register_driver(&aac_pci_driver);
+#if (defined(CONFIG_COMMUNITY_KERNEL))
 	if (error < 0)
+//#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,11)) && !defined(PCI_HAS_SHUTDOWN))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	{
+		unregister_reboot_notifier(&aac_reboot_notifier);
+#endif
+		return error;
+//#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,11)) && !defined(PCI_HAS_SHUTDOWN))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	}
+#endif
+#else
+	if (error < 0 || list_empty(&aac_devices)) {
+//#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,11)) && !defined(PCI_HAS_SHUTDOWN))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+		unregister_reboot_notifier(&aac_reboot_notifier);
+#endif
+		if (error >= 0) {
+			pci_unregister_driver(&aac_pci_driver);
+			error = -ENODEV;
+		}
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) && defined(SCSI_HAS_SCSI_IN_DETECTION) && !defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__) && !defined(__VMKLNX__))
+		scsi_unregister_module(MODULE_SCSI_HA,&aac_driver_template);
+#endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+		spin_lock_destroy(&io_request_lock);
+#endif
 		return error;
+	}
+#endif
+#if (!defined(HAS_BOOT_CONFIG))
+	/*
+	 * ESXi4 do not support character device with multiple minor numbers
+	 * So we will have to create interfaces with different major numbers 
+	 * for each such interface
+	 */
+#if (defined(__ESXi4__))
+	struct aac_dev		*aac;
+	char			name[5];
 
+	list_for_each_entry(aac, &aac_devices, entry) {
+		sprintf(name, "aac%d", aac->id);
+		aac_cfg_major = register_chrdev( 0, name, &aac_cfg_fops);
+		if (aac_cfg_major < 0) {
+			printk(KERN_WARNING
+				"aacraid: unable to register \"%s\" device.\n", name);
+		} else
+			aac->major_number = aac_cfg_major;
+	}
+#else
 	aac_cfg_major = register_chrdev( 0, "aac", &aac_cfg_fops);
 	if (aac_cfg_major < 0) {
 		printk(KERN_WARNING
 			"aacraid: unable to register \"aac\" device.\n");
 	}
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11))
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) ? defined(__x86_64__) : defined(CONFIG_COMPAT))
+	aac_ioctl32(FSACTL_MINIPORT_REV_CHECK, sys_ioctl);
+	aac_ioctl32(FSACTL_SENDFIB, sys_ioctl);
+	aac_ioctl32(FSACTL_OPEN_GET_ADAPTER_FIB, sys_ioctl);
+	aac_ioctl32(FSACTL_GET_NEXT_ADAPTER_FIB,
+	  aac_get_next_adapter_fib_ioctl);
+	aac_ioctl32(FSACTL_CLOSE_GET_ADAPTER_FIB, sys_ioctl);
+	aac_ioctl32(FSACTL_SEND_RAW_SRB, sys_ioctl);
+	aac_ioctl32(FSACTL_GET_PCI_INFO, sys_ioctl);
+	aac_ioctl32(FSACTL_QUERY_DISK, sys_ioctl);
+	aac_ioctl32(FSACTL_DELETE_DISK, sys_ioctl);
+	aac_ioctl32(FSACTL_FORCE_DELETE_DISK, sys_ioctl);
+	aac_ioctl32(FSACTL_GET_CONTAINERS, sys_ioctl);
+#if (defined(FSACTL_REGISTER_FIB_SEND))
+	aac_ioctl32(FSACTL_REGISTER_FIB_SEND, sys_ioctl);
+#endif
+	aac_ioctl32(FSACTL_GET_VERSION_MATCHING, sys_ioctl);
+	aac_ioctl32(FSACTL_SEND_LARGE_FIB, sys_ioctl);
+#if (defined(AAC_CSMI))
+	aac_csmi_register_ioctl32_conversion();
+#endif
+#endif
+#endif
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) && !defined(SCSI_HAS_SCSI_IN_DETECTION) && !defined(__VMKERNEL_MODULE__) && !defined(__VMKLNX30__) && !defined(__VMKLNX__))
+	/* Trigger a target scan in the 2.4 tree */
+	if (!aac_dummy) {
+		aac_dummy = scsi_host_alloc(&aac_driver_template,0);
+	}
+#endif
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) && (!defined(SCSI_HAS_SCSI_IN_DETECTION) || defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__)))
+	scsi_register_module(MODULE_SCSI_HA,&aac_driver_template);
+#endif
 
 	return 0;
 }
 
 static void __exit aac_exit(void)
 {
+#if (!defined(HAS_BOOT_CONFIG))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,11))
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)) ? defined(__x86_64__) : defined(CONFIG_COMPAT))
+	unregister_ioctl32_conversion(FSACTL_MINIPORT_REV_CHECK);
+	unregister_ioctl32_conversion(FSACTL_SENDFIB);
+	unregister_ioctl32_conversion(FSACTL_OPEN_GET_ADAPTER_FIB);
+	unregister_ioctl32_conversion(FSACTL_GET_NEXT_ADAPTER_FIB);
+	unregister_ioctl32_conversion(FSACTL_CLOSE_GET_ADAPTER_FIB);
+	unregister_ioctl32_conversion(FSACTL_SEND_RAW_SRB);
+	unregister_ioctl32_conversion(FSACTL_GET_PCI_INFO);
+	unregister_ioctl32_conversion(FSACTL_QUERY_DISK);
+	unregister_ioctl32_conversion(FSACTL_DELETE_DISK);
+	unregister_ioctl32_conversion(FSACTL_FORCE_DELETE_DISK);
+	unregister_ioctl32_conversion(FSACTL_GET_CONTAINERS);
+#if (defined(FSACTL_REGISTER_FIB_SEND))
+	unregister_ioctl32_conversion(FSACTL_REGISTER_FIB_SEND);
+#endif
+	unregister_ioctl32_conversion(FSACTL_GET_VERSION_MATCHING);
+	unregister_ioctl32_conversion(FSACTL_SEND_LARGE_FIB);
+#if (defined(AAC_CSMI))
+	aac_csmi_unregister_ioctl32_conversion();
+#endif
+#endif
+#endif
 	if (aac_cfg_major > -1)
 		unregister_chrdev(aac_cfg_major, "aac");
+#endif
+//#if ((LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,11)) && !defined(PCI_HAS_SHUTDOWN))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	unregister_reboot_notifier(&aac_reboot_notifier);
+#endif
 	pci_unregister_driver(&aac_pci_driver);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+	scsi_unregister_module(MODULE_SCSI_HA,&aac_driver_template);
+#endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+	spin_lock_destroy(&io_request_lock);
+#endif
 }
 
 module_init(aac_init);
 module_exit(aac_exit);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+EXPORT_NO_SYMBOLS;
+#endif
diff --git a/drivers/scsi/aacraid/nark.c b/drivers/scsi/aacraid/nark.c
index 6c53b1d..9cfdbfd 100644
--- a/drivers/scsi/aacraid/nark.c
+++ b/drivers/scsi/aacraid/nark.c
@@ -4,8 +4,7 @@
  * based on the old aacraid driver that is..
  * Adaptec aacraid device driver for Linux.
  *
- * Copyright (c) 2000-2010 Adaptec, Inc.
- *               2010 PMC-Sierra, Inc. (aacraid@pmc-sierra.com)
+ * Copyright (c) 2006-2007 Adaptec, Inc. (aacraid@adaptec.com)
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -30,8 +29,14 @@
 
 #include <linux/pci.h>
 #include <linux/blkdev.h>
+#include <linux/version.h>	/* Needed for the following */
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0))
+#include "scsi.h"
+#include "hosts.h"
+#else
 #include <scsi/scsi_host.h>
+#endif
 
 #include "aacraid.h"
 
@@ -45,18 +50,22 @@ static int aac_nark_ioremap(struct aac_dev * dev, u32 size)
 	if (!size) {
 		iounmap(dev->regs.rx);
 		dev->regs.rx = NULL;
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,9))
+		iounmap((void __iomem *)dev->base);
+#else
 		iounmap(dev->base);
+#endif
 		dev->base = NULL;
 		return 0;
 	}
-	dev->base_start = pci_resource_start(dev->pdev, 2);
+	dev->scsi_host_ptr->base = pci_resource_start(dev->pdev, 2);
 	dev->regs.rx = ioremap((u64)pci_resource_start(dev->pdev, 0) |
 	  ((u64)pci_resource_start(dev->pdev, 1) << 32),
 	  sizeof(struct rx_registers) - sizeof(struct rx_inbound));
 	dev->base = NULL;
 	if (dev->regs.rx == NULL)
 		return -1;
-	dev->base = ioremap(dev->base_start, size);
+	dev->base = ioremap(dev->scsi_host_ptr->base, size);
 	if (dev->base == NULL) {
 		iounmap(dev->regs.rx);
 		dev->regs.rx = NULL;
@@ -65,6 +74,20 @@ static int aac_nark_ioremap(struct aac_dev * dev, u32 size)
 	dev->IndexRegs = &((struct rx_registers __iomem *)dev->base)->IndexRegs;
 	return 0;
 }
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+
+/**
+ *	aac_nark_select_comm	-	Select communications method
+ *	@dev: Adapter
+ *	@comm: communications method
+ */
+int aac_nark_select_comm(struct aac_dev *dev, int comm)
+{
+	int ret = aac_rx_select_comm(dev, comm);
+	dev->a_ops.adapter_build_sg = aac_build_sg_nark;
+	return ret;
+}
+#endif
 
 /**
  *	aac_nark_init	-	initialize an NEMER/ARK Split Bar card
@@ -78,7 +101,11 @@ int aac_nark_init(struct aac_dev * dev)
 	 *	Fill in the function dispatch table.
 	 */
 	dev->a_ops.adapter_ioremap = aac_nark_ioremap;
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	dev->a_ops.adapter_comm = aac_nark_select_comm;
+#else
 	dev->a_ops.adapter_comm = aac_rx_select_comm;
+#endif
 
 	return _aac_rx_init(dev);
 }
diff --git a/drivers/scsi/aacraid/rkt.c b/drivers/scsi/aacraid/rkt.c
index 7d8013f..24eeae7 100644
--- a/drivers/scsi/aacraid/rkt.c
+++ b/drivers/scsi/aacraid/rkt.c
@@ -1,12 +1,11 @@
 /*
  *	Adaptec AAC series RAID controller driver
- *	(c) Copyright 2001 Red Hat Inc.
+ *	(c) Copyright 2001 Red Hat Inc.	<alan@redhat.com>
  *
  * based on the old aacraid driver that is..
  * Adaptec aacraid device driver for Linux.
  *
- * Copyright (c) 2000-2010 Adaptec, Inc.
- *               2010 PMC-Sierra, Inc. (aacraid@pmc-sierra.com)
+ * Copyright (c) 2000-2007 Adaptec, Inc. (aacraid@adaptec.com)
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -30,8 +29,14 @@
  */
 
 #include <linux/blkdev.h>
+#include <linux/version.h>	/* Needed for the following */
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0))
+#include "scsi.h"
+#include "hosts.h"
+#else
 #include <scsi/scsi_host.h>
+#endif
 
 #include "aacraid.h"
 
@@ -79,7 +84,7 @@ static int aac_rkt_ioremap(struct aac_dev * dev, u32 size)
 		iounmap(dev->regs.rkt);
 		return 0;
 	}
-	dev->base = dev->regs.rkt = ioremap(dev->base_start, size);
+	dev->base = dev->regs.rkt = ioremap(dev->scsi_host_ptr->base, size);
 	if (dev->base == NULL)
 		return -1;
 	dev->IndexRegs = &dev->regs.rkt->IndexRegs;
diff --git a/drivers/scsi/aacraid/rx.c b/drivers/scsi/aacraid/rx.c
index dada38a..78e361b 100644
--- a/drivers/scsi/aacraid/rx.c
+++ b/drivers/scsi/aacraid/rx.c
@@ -1,12 +1,11 @@
 /*
  *	Adaptec AAC series RAID controller driver
- *	(c) Copyright 2001 Red Hat Inc.
+ *	(c) Copyright 2001 Red Hat Inc.	<alan@redhat.com>
  *
  * based on the old aacraid driver that is..
  * Adaptec aacraid device driver for Linux.
  *
- * Copyright (c) 2000-2010 Adaptec, Inc.
- *               2010 PMC-Sierra, Inc. (aacraid@pmc-sierra.com)
+ * Copyright (c) 2000-2007 Adaptec, Inc. (aacraid@adaptec.com)
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -32,19 +31,48 @@
 #include <linux/kernel.h>
 #include <linux/init.h>
 #include <linux/types.h>
+//#include <linux/sched.h>
 #include <linux/pci.h>
 #include <linux/spinlock.h>
+#include <linux/slab.h>
 #include <linux/blkdev.h>
 #include <linux/delay.h>
+#include <linux/version.h>	/* Needed for the following */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,2))
 #include <linux/completion.h>
+#endif
 #include <linux/time.h>
 #include <linux/interrupt.h>
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,23))
+#if (!defined(IRQ_NONE))
+  typedef void irqreturn_t;
+# define IRQ_HANDLED
+# define IRQ_NONE
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,25))
+#include <asm/semaphore.h>
+#endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0))
+#include "scsi.h"
+#include "hosts.h"
+#else
 #include <scsi/scsi_host.h>
+#endif
 
 #include "aacraid.h"
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#include "fwdebug.h"
+#endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19))
+static irqreturn_t aac_rx_intr_producer(int irq, void *dev_id, struct pt_regs *regs)
+#elif (defined(HAS_NEW_IRQ_HANDLER_T))
+static irqreturn_t aac_rx_intr_producer(void *dev_id)
+#else
 static irqreturn_t aac_rx_intr_producer(int irq, void *dev_id)
+#endif
 {
 	struct aac_dev *dev = dev_id;
 	unsigned long bellbits;
@@ -83,45 +111,218 @@ static irqreturn_t aac_rx_intr_producer(int irq, void *dev_id)
 	return IRQ_NONE;
 }
 
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x70)
+static char * aac_debug_timestamp(void)
+{
+	unsigned long seconds = get_seconds();
+	static char buffer[80];
+	sprintf(buffer, "%02u:%02u:%02u: ",
+	  (int)((seconds / 3600) % 24),
+	  (int)((seconds / 60) % 60),
+	  (int)(seconds % 60));
+	return buffer;
+}
+# define AAC_DEBUG_PREAMBLE	"%s"
+# define AAC_DEBUG_POSTAMBLE	,aac_debug_timestamp()
+# define AAC_DEBUG_PREAMBLE_SIZE 10
+#else
+# define AAC_DEBUG_PREAMBLE	
+# define AAC_DEBUG_POSTAMBLE
+# define AAC_DEBUG_PREAMBLE_SIZE 0
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19))
+static irqreturn_t aac_rx_intr_message(int irq, void *dev_id, struct pt_regs *regs)
+#elif (defined(HAS_NEW_IRQ_HANDLER_T))
+static irqreturn_t aac_rx_intr_message(void *dev_id)
+#else
 static irqreturn_t aac_rx_intr_message(int irq, void *dev_id)
+#endif
 {
 	int isAif, isFastResponse, isSpecial;
 	struct aac_dev *dev = dev_id;
 	u32 Index = rx_readl(dev, MUnit.OutboundQueue);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30)
+	static unsigned empty_count = 0;
+	if (nblank(fwprintf(x)) &&
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x10)
+	  ((Index == 0xFFFFFFFFL) || (!(Index & 0x00000002L) &&
+	  (((Index >> 2) >= (dev->scsi_host_ptr->can_queue+AAC_NUM_MGT_FIB)) ||
+	  !(dev->fibs[Index >> 2].hw_fib_va->header.XferState &
+	  cpu_to_le32(NoResponseExpected | Async))))) &&
+#else
+	  dev->aif_thread &&
+#endif
+	  ((Index != 0xFFFFFFFFL) || (++empty_count < 3))) {
+		unsigned long DebugFlags = dev->FwDebugFlags;
+		dev->FwDebugFlags |= FW_DEBUG_FLAGS_NO_HEADERS_B;
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x30)
+		if (!(Index & 0x00000002L) && ((Index >> 2) >=
+		  (dev->scsi_host_ptr->can_queue+AAC_NUM_MGT_FIB))) {
+			struct hw_fib * f = dev->fibs[Index >> 2].hw_fib_va;
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B, AAC_DEBUG_PREAMBLE
+			  "irq%d Q=0x%X %u+%u+%u\n" AAC_DEBUG_POSTAMBLE,
+			  irq, Index, le16_to_cpu(f->header.Command),
+			  le32_to_cpu(((struct aac_query_mount *)f->data)->command),
+			  le32_to_cpu(((struct aac_query_mount *)f->data)->type)));
+		} else
+#endif
+		{
+			fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+			  AAC_DEBUG_PREAMBLE "irq%d Q=0x%X\n"
+			  AAC_DEBUG_POSTAMBLE, irq, Index));
+		}
+		dev->FwDebugFlags = DebugFlags;
+	}
+#endif
+#endif
 	if (unlikely(Index == 0xFFFFFFFFL))
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30)
+	{
+#endif
+#endif
 		Index = rx_readl(dev, MUnit.OutboundQueue);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30)
+		if (nblank(fwprintf(x))
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x10)
+		 && (!(Index & 0x00000002L) && (((Index >> 2) >=
+		  (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB)) ||
+		  !(dev->fibs[Index >> 2].hw_fib_va->header.XferState &
+		  cpu_to_le32(NoResponseExpected | Async))))
+#else
+		 && dev->aif_thread
+#endif
+		) {
+			unsigned long DebugFlags = dev->FwDebugFlags;
+			dev->FwDebugFlags |= FW_DEBUG_FLAGS_NO_HEADERS_B;
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x30)
+			if (!(Index & 0x00000002L) && ((Index >> 2) >=
+			  (dev->scsi_host_ptr->can_queue+AAC_NUM_MGT_FIB))) {
+				struct hw_fib * f = dev->fibs[
+				  Index >> 2].hw_fib_va;
+				fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+				  AAC_DEBUG_PREAMBLE " Q=0x%X %u+%u+%u\n"
+				  AAC_DEBUG_POSTAMBLE, Index,
+				  le16_to_cpu(f->header.Command),
+				  le32_to_cpu(((struct aac_query_mount *)
+				    f->data)->command),
+				  le32_to_cpu(((struct aac_query_mount *)
+				    f->data)->type)));
+			} else
+#endif
+			{
+				fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+				  AAC_DEBUG_PREAMBLE " Q=0x%X\n"
+				  AAC_DEBUG_POSTAMBLE, Index));
+			}
+			dev->FwDebugFlags = DebugFlags;
+		}
+	}
+#endif
+#endif
 	if (likely(Index != 0xFFFFFFFFL)) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30)
+		if (nblank(fwprintf(x)))
+			empty_count = 0;
+#endif
+#endif
 		do {
 			isAif = isFastResponse = isSpecial = 0;
 			if (Index & 0x00000002L) {
 				isAif = 1;
-				if (Index == 0xFFFFFFFEL)
+				if (Index == 0xFFFFFFFEL) 
 					isSpecial = 1;
 				Index &= ~0x00000002L;
 			} else {
-				if (Index & 0x00000001L)
+				if (Index & 0x00000001L) 
 					isFastResponse = 1;
 				Index >>= 2;
 			}
 			if (!isSpecial) {
-				if (unlikely(aac_intr_normal(dev,
-						Index, isAif,
-						isFastResponse, NULL))) {
-					rx_writel(dev,
-						MUnit.OutboundQueue,
-						Index);
-					rx_writel(dev,
-						MUnit.ODR,
-						DoorBellAdapterNormRespReady);
+				if (unlikely(aac_intr_normal(dev, Index, isAif, isFastResponse, NULL))) {
+					rx_writel(dev, MUnit.OutboundQueue, Index);
+					rx_writel(dev, MUnit.ODR, DoorBellAdapterNormRespReady);
 				}
 			}
 			Index = rx_readl(dev, MUnit.OutboundQueue);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30)
+			if (nblank(fwprintf(x))
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x10)
+			 && !(Index & 0x00000002L) && (((Index >> 2) >=
+			  (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB)) ||
+			  !(dev->fibs[Index >> 2].hw_fib_va->header.XferState &
+			  cpu_to_le32(NoResponseExpected | Async)))
+#else
+			 && dev->aif_thread
+#endif
+			) {
+				unsigned long DebugFlags = dev->FwDebugFlags;
+				dev->FwDebugFlags |= FW_DEBUG_FLAGS_NO_HEADERS_B;
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x30)
+				if (!(Index & 0x00000002L) && ((Index >> 2) >=
+				  (dev->scsi_host_ptr->can_queue +
+				  AAC_NUM_MGT_FIB))) {
+					struct hw_fib * f = dev->fibs[
+					  Index >> 2].hw_fib_va;
+					fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+					  AAC_DEBUG_PREAMBLE " Q=0x%X %u+%u+%u\n"
+					  AAC_DEBUG_POSTAMBLE, Index,
+					  le16_to_cpu(f->header.Command),
+					  le32_to_cpu(
+					    ((struct aac_query_mount *)f->data)
+					      ->command),
+					  le32_to_cpu(
+					    ((struct aac_query_mount *)f->data)
+					      ->type)));
+				} else
+#endif
+				{
+					fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B,
+					  AAC_DEBUG_PREAMBLE " Q=0x%X\n"
+					  AAC_DEBUG_POSTAMBLE, Index));
+				}
+				dev->FwDebugFlags = DebugFlags;
+			}
+#endif
+#endif
 		} while (Index != 0xFFFFFFFFL);
 		return IRQ_HANDLED;
 	}
 	return IRQ_NONE;
 }
 
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19))
+static irqreturn_t aac_rx_intr_apre(int irq, void *dev_id, struct pt_regs *regs)
+#elif (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,24))
+static irqreturn_t aac_rx_intr_apre(int irq, void *dev_id)
+#else
+static irqreturn_t aac_rx_intr_apre(void *dev_id)
+#endif
+{
+	struct aac_dev *dev = dev_id;
+	unsigned long bellbits;
+	u8 intstat = rx_readb(dev, MUnit.OISR);
+
+	if (likely(intstat & ~(dev->OIMR))) {
+		bellbits = rx_readl(dev, OutboundDoorbellReg);
+		if (bellbits & DoorBellSyncCmdAvailable) {
+			extern int aac_command_apre(struct aac_dev *);
+			rx_writel(dev, MUnit.ODR, DoorBellSyncCmdAvailable);
+			aac_command_apre(dev);
+		}
+		return IRQ_HANDLED;
+	}
+	return IRQ_NONE;
+}
+
+#endif
 /**
  *	aac_rx_disable_interrupt	-	Disable interrupts
  *	@dev: Adapter
@@ -152,6 +353,18 @@ static void aac_rx_enable_interrupt_message(struct aac_dev *dev)
 	rx_writeb(dev, MUnit.OIMR, dev->OIMR = 0xf7);
 }
 
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+/**
+ *	aac_rx_enable_interrupt_apre	-	Enable interrupts
+ *	@dev: Adapter
+ */
+
+static void aac_rx_enable_interrupt_apre(struct aac_dev *dev)
+{
+	rx_writeb(dev, MUnit.OIMR, dev->OIMR = 0xf8);
+}
+
+#endif
 /**
  *	rx_sync_cmd	-	send a command and wait
  *	@dev: Adapter
@@ -169,6 +382,11 @@ static int rx_sync_cmd(struct aac_dev *dev, u32 command,
 {
 	unsigned long start;
 	int ok;
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB))
+	printk(KERN_INFO "rx_sync_cmd(%p,0x%lx,0x%lx,0x%lx,0x%lx,0x%lx,"
+	  "0x%lx,0x%lx,%p,%p,%p,%p,%p)\n",
+	  dev, command, p1, p2, p3, p4, p5, p6, status, r1, r2, r3, r4);
+#endif
 	/*
 	 *	Write the command into Mailbox 0
 	 */
@@ -180,6 +398,22 @@ static int rx_sync_cmd(struct aac_dev *dev, u32 command,
 	writel(p2, &dev->IndexRegs->Mailbox[2]);
 	writel(p3, &dev->IndexRegs->Mailbox[3]);
 	writel(p4, &dev->IndexRegs->Mailbox[4]);
+#if (defined(AAC_LM_SENSOR) && !defined(CONFIG_COMMUNITY_KERNEL))
+	writel(p5, &dev->IndexRegs->Mailbox[5]);
+	writel(p6, &dev->IndexRegs->Mailbox[6]);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB))
+	printk(KERN_INFO "OutMaiboxes=%p="
+	  "{0x%lx,0x%lx,0x%lx,0x%lx,0x%lx,0x%lx,0x%lx}\n",
+	  &dev->IndexRegs->Mailbox[0],
+	  readl(&dev->IndexRegs->Mailbox[0]),
+	  readl(&dev->IndexRegs->Mailbox[1]),
+	  readl(&dev->IndexRegs->Mailbox[2]),
+	  readl(&dev->IndexRegs->Mailbox[3]),
+	  readl(&dev->IndexRegs->Mailbox[4]),
+	  readl(&dev->IndexRegs->Mailbox[5]),
+	  readl(&dev->IndexRegs->Mailbox[6]));
+#endif
 	/*
 	 *	Clear the synch command doorbell to start on a clean slate.
 	 */
@@ -202,9 +436,9 @@ static int rx_sync_cmd(struct aac_dev *dev, u32 command,
 	start = jiffies;
 
 	/*
-	 *	Wait up to 30 seconds
+	 *	Wait up to 5 minutes
 	 */
-	while (time_before(jiffies, start+30*HZ)) 
+	while (time_before(jiffies, start+300*HZ)) 
 	{
 		udelay(5);	/* Delay 5 microseconds to let Mon960 get info. */
 		/*
@@ -243,6 +477,14 @@ static int rx_sync_cmd(struct aac_dev *dev, u32 command,
 		*r3 = readl(&dev->IndexRegs->Mailbox[3]);
 	if (r4)
 		*r4 = readl(&dev->IndexRegs->Mailbox[4]);
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB))
+	printk(KERN_INFO "InMaiboxes={0x%lx,0x%lx,0x%lx,0x%lx,0x%lx}\n",
+	  readl(&dev->IndexRegs->Mailbox[0]),
+	  readl(&dev->IndexRegs->Mailbox[1]),
+	  readl(&dev->IndexRegs->Mailbox[2]),
+	  readl(&dev->IndexRegs->Mailbox[3]),
+	  readl(&dev->IndexRegs->Mailbox[4]));
+#endif
 	/*
 	 *	Clear the synch command doorbell.
 	 */
@@ -254,6 +496,144 @@ static int rx_sync_cmd(struct aac_dev *dev, u32 command,
 	return 0;
 
 }
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+
+/**
+ *	rx_sync_apre	-	send a command and wait
+ *	@dev: Adapter
+ *	@command: Command to execute
+ *	@ret: adapter status
+ *
+ *	This routine will send a synchronous command to the adapter and wait 
+ *	for its	completion.
+ */
+
+static int rx_sync_apre(struct aac_dev *dev, struct hw_apre * command, struct hw_apre * response)
+{
+	u32 * cmd;
+	int Index;
+	unsigned long start;
+	
+	/*
+	 *	Write the command into Mailbox
+	 */
+	for (cmd = (u32 *)command, Index = 0;
+	  Index < (sizeof(*command) / sizeof(u32));
+	  ++cmd, ++Index)
+		writel(*cmd, &dev->IndexRegs->Mailbox[Index]);
+	/*
+	 *	Clear the synch command doorbell to start on a clean slate.
+	 */
+	rx_writel(dev, OutboundDoorbellReg, OUTBOUNDDOORBELL_8);
+	/*
+	 *	Disable doorbell interrupts
+	 */
+	rx_writeb(dev, MUnit.OIMR, dev->OIMR = 0xff);
+	/*
+	 *	Force the completion of the mask register write before issuing
+	 *	the interrupt.
+	 */
+	rx_readb (dev, MUnit.OIMR);
+
+	/*
+	 *	Signal that there is a new synch command
+	 */
+	rx_writel(dev, InboundDoorbellReg, INBOUNDDOORBELL_8);
+
+	Index = 0;
+	start = jiffies;
+
+	/*
+	 *	Wait up to 30 seconds
+	 */
+	while (time_before(jiffies, start+30*HZ)) 
+	{
+		udelay(5);	/* Delay 5 microseconds to let Mon960 get info. */
+		/*
+		 *	Mon960 will set doorbell0 bit when it has completed the command.
+		 */
+		if (rx_readl(dev, OutboundDoorbellReg) & OUTBOUNDDOORBELL_8) {
+			/*
+			 *	Clear the doorbell.
+			 */
+			rx_writel(dev, OutboundDoorbellReg, OUTBOUNDDOORBELL_8);
+			Index = 1;
+			break;
+		}
+		/*
+		 *	Yield the processor in case we are slow 
+		 */
+		msleep(1);
+	}
+	if (unlikely(Index != 1)) {
+		/*
+		 *	Restore interrupt mask even though we timed out
+		 */
+		aac_adapter_enable_int(dev);
+		return -ETIMEDOUT;
+	}
+
+	/*
+	 *	Clear the synch command doorbell.
+	 */
+	rx_writel(dev, OutboundDoorbellReg, OUTBOUNDDOORBELL_8);
+
+	Index = 0;
+	start = jiffies;
+
+	/*
+	 *	Wait up to 30 seconds
+	 */
+	while (time_before(jiffies, start+30*HZ)) 
+	{
+		udelay(5);	/* Delay 5 microseconds to let Mon960 get info. */
+		/*
+		 *	Mon960 will set doorbell0 bit when it has completed the command.
+		 */
+		if (rx_readl(dev, OutboundDoorbellReg) & OUTBOUNDDOORBELL_9) {
+			/*
+			 *	Clear the doorbell.
+			 */
+			rx_writel(dev, OutboundDoorbellReg, OUTBOUNDDOORBELL_9);
+			Index = 1;
+			break;
+		}
+		/*
+		 *	Yield the processor in case we are slow 
+		 */
+		msleep(1);
+	}
+	if (unlikely(Index != 1)) {
+		/*
+		 *	Restore interrupt mask even though we timed out
+		 */
+		aac_adapter_enable_int(dev);
+		return -ETIMEDOUT;
+	}
+
+	/*
+	 *	Clear the synch command doorbell.
+	 */
+	rx_writel(dev, OutboundDoorbellReg, OUTBOUNDDOORBELL_9);
+
+
+	if (response)
+		for (cmd = (u32 *)response, Index = 0;
+		  Index < (sizeof(*response) / sizeof(u32));
+		  ++cmd, ++Index)
+			*cmd = readl(&dev->IndexRegs->Mailbox[Index]);
+	/*
+	 *	Signal that buffer is free.
+	 */
+	rx_writel(dev, InboundDoorbellReg, INBOUNDDOORBELL_9);
+
+	/*
+	 *	Restore interrupt mask
+	 */
+	aac_adapter_enable_int(dev);
+	return 0;
+}
+#endif
 
 /**
  *	aac_rx_interrupt_adapter	-	interrupt adapter
@@ -293,6 +673,8 @@ static void aac_rx_notify_adapter(struct aac_dev *dev, u32 event)
 		rx_writel(dev, MUnit.IDR,INBOUNDDOORBELL_3);
 		break;
 	case HostShutdown:
+//		rx_sync_cmd(dev, HOST_CRASHING, 0, 0, 0, 0, 0, 0,
+//		  NULL, NULL, NULL, NULL, NULL);
 		break;
 	case FastIo:
 		rx_writel(dev, MUnit.IDR,INBOUNDDOORBELL_6);
@@ -322,6 +704,36 @@ static void aac_rx_start_adapter(struct aac_dev *dev)
 	// We can only use a 32 bit address here
 	rx_sync_cmd(dev, INIT_STRUCT_BASE_ADDRESS, (u32)(ulong)dev->init_pa,
 	  0, 0, 0, 0, 0, NULL, NULL, NULL, NULL, NULL);
+#	if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+		printk(KERN_INFO"INIT_STRUCT_BASE_ADDRESS=0x%lx\n",
+		  (unsigned long)dev->init_pa);
+#	endif
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	if (dev->comm_interface == AAC_COMM_APRE) {
+		struct aac_apre_init init;
+
+		memset(&init, 0, sizeof(init));
+		init.inboundMsgBaseLower = dev->init->CommHeaderAddress;
+//		init.inboundMsgBaseUpper = 0;
+		init.NumMsgEnvelopes = dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB;
+		init.DoneListBaseAddrLower = dev->init->CommHeaderAddress
+		                           + (128 * init.NumMsgEnvelopes);
+//		init.DoneListBaseAddrUpper = 0;
+		init.NumDoneListEntries = init.NumMsgEnvelopes + 20;
+		init.header.tcNumber = 1;
+		init.header.Operation = A_OP_INIT_STRUCT;
+		(void)rx_sync_apre(dev, (struct hw_apre *)&init, NULL);
+	}
+#endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+	/*
+	 * On some cards, without a wait here after the INIT_STRUCT_BASE_ADDRESS
+	 * command, the ContainerCommand in AacHba_ProbeContainers() fails to
+	 * report the container.
+	 * The wait time was determined by trial-and-error.
+	 */
+	 mdelay(500);
+#endif
 }
 
 /**
@@ -354,10 +766,16 @@ static int aac_rx_check_health(struct aac_dev *dev)
 
 		if (likely((status & 0xFF000000L) == 0xBC000000L))
 			return (status >> 16) & 0xFF;
+#if (((__GNUC__ * 10000) + (__GNUC_MINOR__ * 100) + __GNUC_PATCHLEVEL__) <= 400002)
+		baddr = 0;
+#endif
 		buffer = pci_alloc_consistent(dev->pdev, 512, &baddr);
 		ret = -2;
 		if (unlikely(buffer == NULL))
 			return ret;
+#if (((__GNUC__ * 10000) + (__GNUC_MINOR__ * 100) + __GNUC_PATCHLEVEL__) <= 400002)
+		paddr = 0;
+#endif
 		post = pci_alloc_consistent(dev->pdev,
 		  sizeof(struct POSTSTATUS), &paddr);
 		if (unlikely(post == NULL)) {
@@ -373,8 +791,9 @@ static int aac_rx_check_health(struct aac_dev *dev)
 		pci_free_consistent(dev->pdev, sizeof(struct POSTSTATUS),
 		  post, paddr);
 		if (likely((buffer[0] == '0') && ((buffer[1] == 'x') || (buffer[1] == 'X')))) {
-			ret = (hex_to_bin(buffer[2]) << 4) +
-				hex_to_bin(buffer[3]);
+			ret = (buffer[2] <= '9') ? (buffer[2] - '0') : (buffer[2] - 'A' + 10);
+			ret <<= 4;
+			ret += (buffer[3] <= '9') ? (buffer[3] - '0') : (buffer[3] - 'A' + 10);
 		}
 		pci_free_consistent(dev->pdev, 512, buffer, baddr);
 		return ret;
@@ -400,16 +819,13 @@ int aac_rx_deliver_producer(struct fib * fib)
 {
 	struct aac_dev *dev = fib->dev;
 	struct aac_queue *q = &dev->queues->queue[AdapNormCmdQueue];
-	unsigned long qflags;
 	u32 Index;
 	unsigned long nointr = 0;
 
-	spin_lock_irqsave(q->lock, qflags);
 	aac_queue_get( dev, &Index, AdapNormCmdQueue, fib->hw_fib_va, 1, fib, &nointr);
 
-	q->numpending++;
+	atomic_inc(&q->numpending);
 	*(q->headers.producer) = cpu_to_le32(Index + 1);
-	spin_unlock_irqrestore(q->lock, qflags);
 	if (!(nointr & aac_config.irq_mod))
 		aac_adapter_notify(dev, AdapNormCmdQueue);
 
@@ -426,15 +842,19 @@ static int aac_rx_deliver_message(struct fib * fib)
 {
 	struct aac_dev *dev = fib->dev;
 	struct aac_queue *q = &dev->queues->queue[AdapNormCmdQueue];
-	unsigned long qflags;
 	u32 Index;
 	u64 addr;
 	volatile void __iomem *device;
 
 	unsigned long count = 10000000L; /* 50 seconds */
-	spin_lock_irqsave(q->lock, qflags);
-	q->numpending++;
-	spin_unlock_irqrestore(q->lock, qflags);
+
+	if (fib->flags & FIB_CONTEXT_FLAG_NATIVE_HBA)
+		return -EINVAL;
+
+	atomic_inc(&q->numpending);
+
+
+
 	for(;;) {
 		Index = rx_readl(dev, MUnit.InboundQueue);
 		if (unlikely(Index == 0xFFFFFFFFL))
@@ -442,13 +862,71 @@ static int aac_rx_deliver_message(struct fib * fib)
 		if (likely(Index != 0xFFFFFFFFL))
 			break;
 		if (--count == 0) {
-			spin_lock_irqsave(q->lock, qflags);
-			q->numpending--;
-			spin_unlock_irqrestore(q->lock, qflags);
+			atomic_dec(&q->numpending);
+#			if (defined(AAC_DEBUG_INSTRUMENT_FIB))
+				printk(KERN_INFO "aac_fib_send: message unit full\n");
+#			endif
 			return -ETIMEDOUT;
 		}
 		udelay(5);
 	}
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x70)
+	if (nblank(fwprintf(x))
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x10)
+	 && !(fib->hw_fib_va->header.XferState &
+	  cpu_to_le32(NoResponseExpected | Async))
+#else
+	 && dev->aif_thread
+#endif
+	) {
+		unsigned long DebugFlags = dev->FwDebugFlags;
+		dev->FwDebugFlags |= FW_DEBUG_FLAGS_NO_HEADERS_B;
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30)
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B, AAC_DEBUG_PREAMBLE
+		  "send Q=0x%X I=0x%X %u+%u+%u\n" AAC_DEBUG_POSTAMBLE,
+		  ((int)(fib - dev->fibs)) << 2, Index,
+		  le16_to_cpu(fib->hw_fib_va->header.Command),
+		  le32_to_cpu(((struct aac_query_mount *)
+		    fib->hw_fib_va->data)->command),
+		  le32_to_cpu(((struct aac_query_mount *)
+		    fib->hw_fib_va->data)->type)));
+#endif
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x40)
+		{
+			u8 * p = (u8 *)fib->hw_fib_va;
+			unsigned len = le16_to_cpu(fib->hw_fib_va->header.Size);
+			char buffer[80-AAC_DEBUG_PREAMBLE_SIZE];
+			char * cp = buffer;
+
+			strcpy(cp, "FIB=");
+			cp += 4;
+			while (len > 0) {
+				if (cp >= &buffer[sizeof(buffer)-4]) {
+					fwprintf((dev,
+					  HBA_FLAGS_DBG_FW_PRINT_B,
+					  AAC_DEBUG_PREAMBLE "%s\n"
+					  AAC_DEBUG_POSTAMBLE,
+					  buffer));
+					strcpy(cp = buffer, "    ");
+					cp += 4;
+				}
+				sprintf (cp, "%02x ", *(p++));
+				cp += strlen(cp);
+				--len;
+			}
+			if (cp > &buffer[4]) {
+				fwprintf((dev,
+				  HBA_FLAGS_DBG_FW_PRINT_B,
+				  AAC_DEBUG_PREAMBLE "%s\n"
+				  AAC_DEBUG_POSTAMBLE, buffer));
+			}
+		}
+#endif
+		dev->FwDebugFlags = DebugFlags;
+	}
+#endif
+#endif
 	device = dev->base + Index;
 	addr = fib->hw_fib_pa;
 	writel((u32)(addr & 0xffffffff), device);
@@ -456,10 +934,51 @@ static int aac_rx_deliver_message(struct fib * fib)
 	writel((u32)(addr >> 32), device);
 	device += sizeof(u32);
 	writel(le16_to_cpu(fib->hw_fib_va->header.Size), device);
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x70)
+//qflags=readl(device);
+#endif
+#endif
 	rx_writel(dev, MUnit.InboundQueue, Index);
 	return 0;
 }
 
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+/**
+ *	aac_rx_deliver_apre
+ *	@fib: fib to issue
+ *
+ *	Will send a fib, returning 0 if successful.
+ */
+static int aac_rx_deliver_apre(struct fib * fib)
+{
+	struct aac_dev *dev = fib->dev;
+	struct aac_queue *q = &dev->queues->queue[ApreCmdQueue];
+	u32 Index;
+
+	if (unlikely((atomic_read(&q->numpending) >= q->entries) || ((q->Credits - fib->Credits) < 0))) {
+		spin_unlock_irqrestore(q->lock, qflags);
+		return -EBUSY;
+	}
+	q->Credits -= fib->Credits;
+	atomic_inc(q->numpending);
+	fib->hw_apre_va->header.tcNumber = ((u32)(fib - dev->fibs)) << 2;
+	Index = le32_to_cpu(*(q->headers.producer));
+	/* Not a 1:1 mapping between tcNumber reference and producer reference */
+	memcpy(
+	  q->headers.producer + sizeof(u32)*2 +
+	    sizeof(fib->hw_apre_va->header.nextaddr_lower) +
+	    (Index * sizeof(struct hw_apre)),
+	  (void *)fib->hw_apre_va + sizeof(fib->hw_apre_va->header.nextaddr_lower),
+	  sizeof(struct hw_apre) - sizeof(fib->hw_apre_va->header.nextaddr_lower));
+	if (unlikely(++Index >= q->entries))
+		Index = 0;
+	*(q->headers.producer) = cpu_to_le32(Index);
+	rx_writel(dev, MUnit.IMRx[0], Index);
+	spin_unlock_irqrestore(q->lock, qflags);
+	return 0;
+}
+#endif
 /**
  *	aac_rx_ioremap
  *	@size: mapping resize request
@@ -471,7 +990,7 @@ static int aac_rx_ioremap(struct aac_dev * dev, u32 size)
 		iounmap(dev->regs.rx);
 		return 0;
 	}
-	dev->base = dev->regs.rx = ioremap(dev->base_start, size);
+	dev->base = dev->regs.rx = ioremap(dev->scsi_host_ptr->base, size);
 	if (dev->base == NULL)
 		return -1;
 	dev->IndexRegs = &dev->regs.rx->IndexRegs;
@@ -480,7 +999,7 @@ static int aac_rx_ioremap(struct aac_dev * dev, u32 size)
 
 static int aac_rx_restart_adapter(struct aac_dev *dev, int bled)
 {
-	u32 var;
+	u32 var = 0;
 
 	if (!(dev->supplement_adapter_info.SupportedOptions2 &
 	  AAC_OPTION_MU_RESET) || (bled >= 0) || (bled == -2)) {
@@ -500,15 +1019,24 @@ static int aac_rx_restart_adapter(struct aac_dev *dev, int bled)
 		if (bled && (bled != -ETIMEDOUT))
 			return -EINVAL;
 	}
-	if (bled || (var == 0x3803000F)) { /* USE_OTHER_METHOD */
+	if (bled && (var == 0x3803000F)) { /* USE_OTHER_METHOD */
 		rx_writel(dev, MUnit.reserved2, 3);
 		msleep(5000); /* Delay 5 seconds */
 		var = 0x00000001;
 	}
-	if (var != 0x00000001)
+	if (bled && (var != 0x00000001))
 		return -EINVAL;
+	ssleep(5);
 	if (rx_readl(dev, MUnit.OMRx[0]) & KERNEL_PANIC)
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+	{
+		if (var == 10)
+			printk(KERN_INFO "IOP_RESET disabled\n");
+#endif
 		return -ENODEV;
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+	}
+#endif
 	if (startup_timeout < 300)
 		startup_timeout = 300;
 	return 0;
@@ -533,6 +1061,13 @@ int aac_rx_select_comm(struct aac_dev *dev, int comm)
 		dev->a_ops.adapter_intr = aac_rx_intr_message;
 		dev->a_ops.adapter_deliver = aac_rx_deliver_message;
 		break;
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	case AAC_COMM_APRE:
+		dev->a_ops.adapter_enable_int = aac_rx_enable_interrupt_apre;
+		dev->a_ops.adapter_intr = aac_rx_intr_apre;
+		dev->a_ops.adapter_deliver = aac_rx_deliver_apre;
+		dev->a_ops.adapter_build_sg = aac_build_sg_rx;
+#endif
 	default:
 		return 1;
 	}
@@ -556,6 +1091,10 @@ int _aac_rx_init(struct aac_dev *dev)
 	int instance = dev->id;
 	const char * name = dev->name;
 
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19)) && !defined(HAS_RESET_DEVICES))
+#	define reset_devices aac_reset_devices
+#endif
+
 	if (aac_adapter_ioremap(dev, dev->base_size)) {
 		printk(KERN_WARNING "%s: unable to map adapter.\n", name);
 		goto error_iounmap;
@@ -628,8 +1167,12 @@ int _aac_rx_init(struct aac_dev *dev)
 	dev->a_ops.adapter_disable_int = aac_rx_disable_interrupt;
 	dev->a_ops.adapter_notify = aac_rx_notify_adapter;
 	dev->a_ops.adapter_sync_cmd = rx_sync_cmd;
+#if (defined(INITFLAGS_APRE_SUPPORTED) && !defined(CONFIG_COMMUNITY_KERNEL))
+	dev->a_ops.adapter_sync_apre = rx_sync_apre;
+#endif
 	dev->a_ops.adapter_check_health = aac_rx_check_health;
 	dev->a_ops.adapter_restart = aac_rx_restart_adapter;
+	dev->a_ops.adapter_start = aac_rx_start_adapter;
 
 	/*
 	 *	First clear out all interrupts.  Then enable the one's that we
@@ -643,17 +1186,21 @@ int _aac_rx_init(struct aac_dev *dev)
 	if (aac_init_adapter(dev) == NULL)
 		goto error_iounmap;
 	aac_adapter_comm(dev, dev->comm_interface);
-	dev->sync_mode = 0;	/* sync. mode not supported */
+	dev->sync_mode = 0;				/* sync. mode not supported */
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_ENABLE_MSI))
 	dev->msi = aac_msi && !pci_enable_msi(dev->pdev);
+#endif
 	if (request_irq(dev->pdev->irq, dev->a_ops.adapter_intr,
-			IRQF_SHARED|IRQF_DISABLED, "aacraid", dev) < 0) {
+		IRQF_SHARED|IRQF_DISABLED, "aacraid", dev) < 0) {
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_DISABLE_MSI))
 		if (dev->msi)
 			pci_disable_msi(dev->pdev);
+#endif
 		printk(KERN_ERR "%s%d: Interrupt unavailable.\n",
 			name, instance);
 		goto error_iounmap;
 	}
-	dev->dbg_base = dev->base_start;
+	dev->dbg_base = dev->scsi_host_ptr->base;
 	dev->dbg_base_mapped = dev->base;
 	dev->dbg_size = dev->base_size;
 
diff --git a/drivers/scsi/aacraid/sa.c b/drivers/scsi/aacraid/sa.c
index 2244f31..21a3eee 100644
--- a/drivers/scsi/aacraid/sa.c
+++ b/drivers/scsi/aacraid/sa.c
@@ -1,12 +1,11 @@
 /*
  *	Adaptec AAC series RAID controller driver
- *	(c) Copyright 2001 Red Hat Inc.
+ *	(c) Copyright 2001 Red Hat Inc.	<alan@redhat.com>
  *
  * based on the old aacraid driver that is..
  * Adaptec aacraid device driver for Linux.
  *
- * Copyright (c) 2000-2010 Adaptec, Inc.
- *               2010 PMC-Sierra, Inc. (aacraid@pmc-sierra.com)
+ * Copyright (c) 2000-2007 Adaptec, Inc. (aacraid@adaptec.com)
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -32,19 +31,45 @@
 #include <linux/kernel.h>
 #include <linux/init.h>
 #include <linux/types.h>
+//#include <linux/sched.h>
 #include <linux/pci.h>
 #include <linux/spinlock.h>
+#include <linux/slab.h>
 #include <linux/blkdev.h>
 #include <linux/delay.h>
+#include <linux/version.h>	/* Needed for the following */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,2))
 #include <linux/completion.h>
+#endif
 #include <linux/time.h>
 #include <linux/interrupt.h>
-
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,23))
+#if (!defined(IRQ_NONE))
+  typedef void irqreturn_t;
+# define IRQ_HANDLED
+# define IRQ_NONE
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,25))
+#include <asm/semaphore.h>
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0))
+#include "scsi.h"
+#include "hosts.h"
+#else
 #include <scsi/scsi_host.h>
+#endif
 
 #include "aacraid.h"
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19))
+static irqreturn_t aac_sa_intr(int irq, void *dev_id, struct pt_regs *regs)
+#elif (defined(HAS_NEW_IRQ_HANDLER_T))
+static irqreturn_t aac_sa_intr(void *dev_id)
+#else
 static irqreturn_t aac_sa_intr(int irq, void *dev_id)
+#endif
 {
 	struct aac_dev *dev = dev_id;
 	unsigned short intstat, mask;
@@ -171,6 +196,10 @@ static int sa_sync_cmd(struct aac_dev *dev, u32 command,
 	sa_writel(dev, Mailbox2, p2);
 	sa_writel(dev, Mailbox3, p3);
 	sa_writel(dev, Mailbox4, p4);
+#if (defined(AAC_LM_SENSOR) && !defined(CONFIG_COMMUNITY_KERNEL))
+	sa_writel(dev, Mailbox5, p5);
+	sa_writel(dev, Mailbox6, p6);
+#endif
 
 	/*
 	 *	Clear the synch command doorbell to start on a clean slate.
@@ -246,6 +275,7 @@ static void aac_sa_interrupt_adapter (struct aac_dev *dev)
 static void aac_sa_start_adapter(struct aac_dev *dev)
 {
 	struct aac_init *init;
+
 	/*
 	 * Fill in the remaining pieces of the init.
 	 */
@@ -305,7 +335,7 @@ static int aac_sa_ioremap(struct aac_dev * dev, u32 size)
 		iounmap(dev->regs.sa);
 		return 0;
 	}
-	dev->base = dev->regs.sa = ioremap(dev->base_start, size);
+	dev->base = dev->regs.sa = ioremap(dev->scsi_host_ptr->base, size);
 	return (dev->base == NULL) ? -1 : 0;
 }
 
@@ -372,6 +402,7 @@ int aac_sa_init(struct aac_dev *dev)
 	dev->a_ops.adapter_sync_cmd = sa_sync_cmd;
 	dev->a_ops.adapter_check_health = aac_sa_check_health;
 	dev->a_ops.adapter_restart = aac_sa_restart_adapter;
+	dev->a_ops.adapter_start = aac_sa_start_adapter;
 	dev->a_ops.adapter_intr = aac_sa_intr;
 	dev->a_ops.adapter_deliver = aac_rx_deliver_producer;
 	dev->a_ops.adapter_ioremap = aac_sa_ioremap;
@@ -385,15 +416,15 @@ int aac_sa_init(struct aac_dev *dev)
 
 	if(aac_init_adapter(dev) == NULL)
 		goto error_irq;
-	dev->sync_mode = 0;	/* sync. mode not supported */
-	if (request_irq(dev->pdev->irq, dev->a_ops.adapter_intr,
-			IRQF_SHARED|IRQF_DISABLED,
-			"aacraid", (void *)dev ) < 0) {
+	dev->sync_mode = 0;		/* sync. mode not supported */
+   	if (request_irq(dev->pdev->irq, dev->a_ops.adapter_intr,
+		IRQF_SHARED|IRQF_DISABLED,
+		"aacraid", (void *)dev ) < 0) {
 		printk(KERN_WARNING "%s%d: Interrupt unavailable.\n",
 			name, instance);
 		goto error_iounmap;
 	}
-	dev->dbg_base = dev->base_start;
+	dev->dbg_base = dev->scsi_host_ptr->base;
 	dev->dbg_base_mapped = dev->base;
 	dev->dbg_size = dev->base_size;
 
diff --git a/drivers/scsi/aacraid/src.c b/drivers/scsi/aacraid/src.c
index 7e17107..6f0971a 100644
--- a/drivers/scsi/aacraid/src.c
+++ b/drivers/scsi/aacraid/src.c
@@ -1,12 +1,11 @@
 /*
  *	Adaptec AAC series RAID controller driver
- *	(c) Copyright 2001 Red Hat Inc.
  *
  * based on the old aacraid driver that is..
  * Adaptec aacraid device driver for Linux.
  *
- * Copyright (c) 2000-2010 Adaptec, Inc.
- *               2010 PMC-Sierra, Inc. (aacraid@pmc-sierra.com)
+ * Copyright (c) 2006-2010 Adaptec, Inc. (aacraid@adaptec.com)
+ *               2010 PMC-Sierra, Inc.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -32,110 +31,207 @@
 #include <linux/kernel.h>
 #include <linux/init.h>
 #include <linux/types.h>
+//#include <linux/sched.h>
 #include <linux/pci.h>
 #include <linux/spinlock.h>
 #include <linux/slab.h>
 #include <linux/blkdev.h>
 #include <linux/delay.h>
+#include <linux/version.h>	/* Needed for the following */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,4,2))
 #include <linux/completion.h>
+#endif
 #include <linux/time.h>
 #include <linux/interrupt.h>
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,23))
+#if (!defined(IRQ_NONE))
+  typedef void irqreturn_t;
+# define IRQ_HANDLED
+# define IRQ_NONE
+#endif
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,4,25))
+#include <asm/semaphore.h>
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0))
+#include "scsi.h"
+#include "hosts.h"
+#else
 #include <scsi/scsi_host.h>
+#endif
 
 #include "aacraid.h"
+#if (!defined(CONFIG_COMMUNITY_KERNEL))
+#include "fwdebug.h"
+#endif
 
-static irqreturn_t aac_src_intr_message(int irq, void *dev_id)
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x70)
+static char * aac_debug_timestamp(void)
 {
-	struct aac_dev *dev = dev_id;
-	unsigned long bellbits, bellbits_shifted;
-	int our_interrupt = 0;
-	int isFastResponse;
-	u32 index, handle;
+	unsigned long seconds = get_seconds();
+	static char buffer[80];
+	sprintf(buffer, "%02u:%02u:%02u: ",
+	  (int)((seconds / 3600) % 24),
+	  (int)((seconds / 60) % 60),
+	  (int)(seconds % 60));
+	return buffer;
+}
+# define AAC_DEBUG_PREAMBLE	"%s"
+# define AAC_DEBUG_POSTAMBLE	,aac_debug_timestamp()
+# define AAC_DEBUG_PREAMBLE_SIZE 10
+#else
+# define AAC_DEBUG_PREAMBLE	
+# define AAC_DEBUG_POSTAMBLE
+# define AAC_DEBUG_PREAMBLE_SIZE 0
+#endif
+#endif
+
+static int aac_src_get_sync_status(struct aac_dev *dev);
+
+#if defined(__ESX5__)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19))
+irqreturn_t aac_src_intr_message_poll(int irq, void *dev_id, struct pt_regs *regs)
+#elif (defined(HAS_NEW_IRQ_HANDLER_T))
+irqreturn_t aac_src_intr_message_poll(void *dev_id)
+#else
+irqreturn_t aac_src_intr_message_poll(int irq, void *dev_id)
+#endif
+{
+	struct aac_msix_ctx *ctx;
+	struct aac_dev *dev;
+	int vector_no;
 
-	bellbits = src_readl(dev, MUnit.ODR_R);
-	if (bellbits & PmDoorBellResponseSent) {
-		bellbits = PmDoorBellResponseSent;
-		/* handle async. status */
-		src_writel(dev, MUnit.ODR_C, bellbits);
-		src_readl(dev, MUnit.ODR_C);
-		our_interrupt = 1;
-		index = dev->host_rrq_idx;
-		for (;;) {
-			isFastResponse = 0;
-			/* remove toggle bit (31) */
-			handle = le32_to_cpu(dev->host_rrq[index]) & 0x7fffffff;
-			/* check fast response bit (30) */
-			if (handle & 0x40000000)
-				isFastResponse = 1;
-			handle &= 0x0000ffff;
-			if (handle == 0)
-				break;
+	ctx = (struct aac_msix_ctx *)dev_id;
+	dev = ctx->dev;
 
-			aac_intr_normal(dev, handle-1, 0, isFastResponse, NULL);
+	for (vector_no = 0; vector_no < dev->max_msix; vector_no++)
+		aac_src_intr_message(vector_no, &(dev->aac_msix[vector_no]));
+}
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19))
+irqreturn_t aac_src_intr_message(int irq, void *dev_id, struct pt_regs *regs)
+#elif (defined(HAS_NEW_IRQ_HANDLER_T))
+irqreturn_t aac_src_intr_message(void *dev_id)
+#else
+irqreturn_t aac_src_intr_message(int irq, void *dev_id)
+#endif
+{
+	struct aac_msix_ctx *ctx;
+	struct aac_dev *dev; 
+	unsigned long bellbits, bellbits_shifted;
+	int vector_no;
+	int isFastResponse, mode;
+	u32 index, handle;
 
-			dev->host_rrq[index++] = 0;
-			if (index == dev->scsi_host_ptr->can_queue +
-						AAC_NUM_MGT_FIB)
-				index = 0;
-			dev->host_rrq_idx = index;
+	ctx = (struct aac_msix_ctx *)dev_id;
+	dev = ctx->dev;
+	vector_no = ctx->vector_no;
+
+	if (dev->msi_enabled) {
+		mode = AAC_INT_MODE_MSI;
+		if (vector_no == 0) {
+			bellbits = src_readl(dev, MUnit.ODR_MSI);
+			if (bellbits & 0x40000)
+				mode |= AAC_INT_MODE_AIF;
+			if (bellbits & 0x1000)
+				mode |= AAC_INT_MODE_SYNC;
 		}
 	} else {
-		bellbits_shifted = (bellbits >> SRC_ODR_SHIFT);
-		if (bellbits_shifted & DoorBellAifPending) {
+		mode = AAC_INT_MODE_INTX;
+		bellbits = src_readl(dev, MUnit.ODR_R);
+		if (bellbits & PmDoorBellResponseSent) {
+			bellbits = PmDoorBellResponseSent;
+			src_writel(dev, MUnit.ODR_C, bellbits);
+			src_readl(dev, MUnit.ODR_C);
+		} else {
+			bellbits_shifted = (bellbits >> SRC_ODR_SHIFT);
 			src_writel(dev, MUnit.ODR_C, bellbits);
 			src_readl(dev, MUnit.ODR_C);
-			our_interrupt = 1;
-			/* handle AIF */
-			aac_intr_normal(dev, 0, 2, 0, NULL);
-		} else if (bellbits_shifted & OUTBOUNDDOORBELL_0) {
-			unsigned long sflags;
-			struct list_head *entry;
-			int send_it = 0;
-			extern int aac_sync_mode;
 
+			if (bellbits_shifted & DoorBellAifPending)
+				mode |= AAC_INT_MODE_AIF;
+			else if (bellbits_shifted & OUTBOUNDDOORBELL_0)
+				 mode |= AAC_INT_MODE_SYNC;
+		}
+	}
+
+	if (mode & AAC_INT_MODE_SYNC) {
+		unsigned long sflags;
+		struct list_head *entry;
+		int send_it = 0;
+		extern int aac_sync_mode;
+
+		if (!aac_sync_mode && !dev->msi_enabled) {
 			src_writel(dev, MUnit.ODR_C, bellbits);
 			src_readl(dev, MUnit.ODR_C);
+		}
 
-			if (!aac_sync_mode) {
-				src_writel(dev, MUnit.ODR_C, bellbits);
-				src_readl(dev, MUnit.ODR_C);
-				our_interrupt = 1;
+		if (dev->sync_fib) {	
+			if (dev->sync_fib->callback)
+				dev->sync_fib->callback(dev->sync_fib->callback_data, 
+					dev->sync_fib);
+			spin_lock_irqsave(&dev->sync_fib->event_lock, sflags);
+			if (dev->sync_fib->flags & FIB_CONTEXT_FLAG_WAIT) {
+				dev->management_fib_count--;
+				up(&dev->sync_fib->event_wait);
 			}
-
-			if (dev->sync_fib) {
-				our_interrupt = 1;
-				if (dev->sync_fib->callback)
-					dev->sync_fib->callback(dev->sync_fib->callback_data,
-						dev->sync_fib);
-				spin_lock_irqsave(&dev->sync_fib->event_lock, sflags);
-				if (dev->sync_fib->flags & FIB_CONTEXT_FLAG_WAIT) {
-					dev->management_fib_count--;
-					up(&dev->sync_fib->event_wait);
-				}
-				spin_unlock_irqrestore(&dev->sync_fib->event_lock, sflags);
-				spin_lock_irqsave(&dev->sync_lock, sflags);
-				if (!list_empty(&dev->sync_fib_list)) {
-					entry = dev->sync_fib_list.next;
-					dev->sync_fib = list_entry(entry, struct fib, fiblink);
-					list_del(entry);
-					send_it = 1;
-				} else {
-					dev->sync_fib = NULL;
-				}
-				spin_unlock_irqrestore(&dev->sync_lock, sflags);
-				if (send_it) {
-					aac_adapter_sync_cmd(dev, SEND_SYNCHRONOUS_FIB,
-						(u32)dev->sync_fib->hw_fib_pa, 0, 0, 0, 0, 0,
-						NULL, NULL, NULL, NULL, NULL);
-				}
+			spin_unlock_irqrestore(&dev->sync_fib->event_lock, sflags);
+			spin_lock_irqsave(&dev->sync_lock, sflags);
+			if (!list_empty(&dev->sync_fib_list)) { 
+				entry = dev->sync_fib_list.next;
+				dev->sync_fib = list_entry(entry, struct fib, fiblink);
+				list_del(entry); 
+				send_it = 1;
+			} else {
+				dev->sync_fib = NULL;
+			}
+			spin_unlock_irqrestore(&dev->sync_lock, sflags);
+			if (send_it) {
+				aac_adapter_sync_cmd(dev, SEND_SYNCHRONOUS_FIB, 
+					(u32)dev->sync_fib->hw_fib_pa, 0, 0, 0, 0, 0, 
+					NULL, NULL, NULL, NULL, NULL);
 			}
 		}
+		if (!dev->msi_enabled)
+			mode = 0;
+
 	}
+	if (mode & AAC_INT_MODE_AIF) {
+		/* handle AIF */
+		aac_intr_normal(dev, 0, 2, 0, NULL);
+		if (dev->msi_enabled)
+			aac_src_access_devreg(dev, AAC_CLEAR_AIF_BIT);
+		else	
+			mode = 0;
+	}
+	if (mode) {
+		index = dev->host_rrq_idx[vector_no];
 
-	if (our_interrupt) {
-		return IRQ_HANDLED;
+		for (;;) {
+			isFastResponse = 0;
+			/* remove toggle bit (31) */
+			handle = le32_to_cpu((dev->host_rrq[index]) 
+				& 0x7fffffff);
+			/* check fast response bits (30, 1) */
+			if (handle & 0x40000000) 
+				isFastResponse = 1;
+			handle &= 0x0000ffff;
+			if (handle == 0) 
+				break;
+			handle >>= 2;
+			atomic_dec(&dev->rrq_outstanding[vector_no]);
+			aac_intr_normal(dev, handle, 0, isFastResponse, NULL);
+			dev->host_rrq[index++] = 0;
+			if (index == (vector_no + 1) * dev->vector_cap)
+				index = vector_no * dev->vector_cap;
+			dev->host_rrq_idx[vector_no] = index;
+		}
+		mode = 0;
 	}
-	return IRQ_NONE;
+	return IRQ_HANDLED;
 }
 
 /**
@@ -155,7 +251,7 @@ static void aac_src_disable_interrupt(struct aac_dev *dev)
 
 static void aac_src_enable_interrupt_message(struct aac_dev *dev)
 {
-	src_writel(dev, MUnit.OIMR, dev->OIMR = 0xfffffff8);
+	aac_src_access_devreg(dev, AAC_ENABLE_INTERRUPT);
 }
 
 /**
@@ -165,7 +261,7 @@ static void aac_src_enable_interrupt_message(struct aac_dev *dev)
  *	@p1: first parameter
  *	@ret: adapter status
  *
- *	This routine will send a synchronous command to the adapter and wait
+ *	This routine will send a synchronous command to the adapter and wait 
  *	for its	completion.
  */
 
@@ -174,7 +270,13 @@ static int src_sync_cmd(struct aac_dev *dev, u32 command,
 	u32 *status, u32 * r1, u32 * r2, u32 * r3, u32 * r4)
 {
 	unsigned long start;
+	unsigned long delay;
 	int ok;
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB) || defined(AAC_DEBUG_INSTRUMENT_MSIX))
+	printk(KERN_INFO "src_sync_cmd(%p,0x%lx,0x%lx,0x%lx,0x%lx,0x%lx,"
+	  "0x%lx,0x%lx,%p,%p,%p,%p,%p)\n",
+	  dev, command, p1, p2, p3, p4, p5, p6, status, r1, r2, r3, r4);
+#endif
 
 	/*
 	 *	Write the command into Mailbox 0
@@ -187,23 +289,36 @@ static int src_sync_cmd(struct aac_dev *dev, u32 command,
 	writel(p2, &dev->IndexRegs->Mailbox[2]);
 	writel(p3, &dev->IndexRegs->Mailbox[3]);
 	writel(p4, &dev->IndexRegs->Mailbox[4]);
-
+#if (defined(AAC_LM_SENSOR) && !defined(CONFIG_COMMUNITY_KERNEL))
+	writel(p5, &dev->IndexRegs->Mailbox[5]);
+	writel(p6, &dev->IndexRegs->Mailbox[6]);
+#endif
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB) || defined(AAC_DEBUG_INSTRUMENT_MSIX))
+	printk(KERN_INFO "OutMaiboxes=%p="
+	  "{0x%lx,0x%lx,0x%lx,0x%lx,0x%lx,0x%lx,0x%lx}\n",
+	  &dev->IndexRegs->Mailbox[0],
+	  readl(&dev->IndexRegs->Mailbox[0]),
+	  readl(&dev->IndexRegs->Mailbox[1]),
+	  readl(&dev->IndexRegs->Mailbox[2]),
+	  readl(&dev->IndexRegs->Mailbox[3]),
+	  readl(&dev->IndexRegs->Mailbox[4]),
+	  readl(&dev->IndexRegs->Mailbox[5]),
+	  readl(&dev->IndexRegs->Mailbox[6]));
+#endif
 	/*
 	 *	Clear the synch command doorbell to start on a clean slate.
 	 */
-	src_writel(dev, MUnit.ODR_C, OUTBOUNDDOORBELL_0 << SRC_ODR_SHIFT);
-
+	if (!dev->msi_enabled)
+		src_writel(dev, MUnit.ODR_C, OUTBOUNDDOORBELL_0 << SRC_ODR_SHIFT);
 	/*
 	 *	Disable doorbell interrupts
 	 */
 	src_writel(dev, MUnit.OIMR, dev->OIMR = 0xffffffff);
-
 	/*
 	 *	Force the completion of the mask register write before issuing
 	 *	the interrupt.
 	 */
 	src_readl(dev, MUnit.OIMR);
-
 	/*
 	 *	Signal that there is a new synch command
 	 */
@@ -213,24 +328,38 @@ static int src_sync_cmd(struct aac_dev *dev, u32 command,
 		ok = 0;
 		start = jiffies;
 
-		/*
-		 *	Wait up to 5 minutes
-		 */
-		while (time_before(jiffies, start+300*HZ)) {
+		if(command == IOP_RESET_ALWAYS)
+		{
+			/*
+			 *	Wait up to 10 sec
+			 */
+			delay = 10*HZ;
+		}
+		else
+		{
+			/*
+			 *	Wait up to 5 minutes
+			 */
+			delay = 300*HZ;
+		}
+		while (time_before(jiffies,start+delay )) {
 			udelay(5);	/* Delay 5 microseconds to let Mon960 get info. */
 			/*
 			 *	Mon960 will set doorbell0 bit when it has completed the command.
 			 */
-			if ((src_readl(dev, MUnit.ODR_R) >> SRC_ODR_SHIFT) & OUTBOUNDDOORBELL_0) {
+			if (aac_src_get_sync_status(dev) & OUTBOUNDDOORBELL_0) {
 				/*
 				 *	Clear the doorbell.
 				 */
-				src_writel(dev, MUnit.ODR_C, OUTBOUNDDOORBELL_0 << SRC_ODR_SHIFT);
+				if (dev->msi_enabled)
+					aac_src_access_devreg(dev, AAC_CLEAR_SYNC_BIT);
+				else
+					src_writel(dev, MUnit.ODR_C, OUTBOUNDDOORBELL_0 << SRC_ODR_SHIFT);
 				ok = 1;
 				break;
 			}
 			/*
-			 *	Yield the processor in case we are slow
+			 *	Yield the processor in case we are slow 
 			 */
 			msleep(1);
 		}
@@ -255,10 +384,22 @@ static int src_sync_cmd(struct aac_dev *dev, u32 command,
 		if (r4)
 			*r4 = readl(&dev->IndexRegs->Mailbox[4]);
 
+		if (command == GET_COMM_PREFERRED_SETTINGS)
+			dev->max_msix = readl(&dev->IndexRegs->Mailbox[5]) & 0xFFFF;
+#if (defined(AAC_DEBUG_INSTRUMENT_FIB) || defined(AAC_DEBUG_INSTRUMENT_MSIX))
+		printk(KERN_INFO "InMaiboxes={0x%lx,0x%lx,0x%lx,0x%lx,0x%lx}\n",
+			   readl(&dev->IndexRegs->Mailbox[0]),
+			   readl(&dev->IndexRegs->Mailbox[1]),
+			   readl(&dev->IndexRegs->Mailbox[2]),
+			   readl(&dev->IndexRegs->Mailbox[3]),
+			   readl(&dev->IndexRegs->Mailbox[4]));
+#endif
+
 		/*
 		 *	Clear the synch command doorbell.
 		 */
-		src_writel(dev, MUnit.ODR_C, OUTBOUNDDOORBELL_0 << SRC_ODR_SHIFT);
+		if (!dev->msi_enabled)
+			src_writel(dev, MUnit.ODR_C, OUTBOUNDDOORBELL_0 << SRC_ODR_SHIFT);
 	}
 
 	/*
@@ -266,6 +407,7 @@ static int src_sync_cmd(struct aac_dev *dev, u32 command,
 	 */
 	aac_adapter_enable_int(dev);
 	return 0;
+
 }
 
 /**
@@ -277,9 +419,7 @@ static int src_sync_cmd(struct aac_dev *dev, u32 command,
 
 static void aac_src_interrupt_adapter(struct aac_dev *dev)
 {
-	src_sync_cmd(dev, BREAKPOINT_REQUEST,
-		0, 0, 0, 0, 0, 0,
-		NULL, NULL, NULL, NULL, NULL);
+	src_sync_cmd(dev, BREAKPOINT_REQUEST, 0, 0, 0, 0, 0, 0, NULL, NULL, NULL, NULL, NULL);
 }
 
 /**
@@ -296,28 +436,26 @@ static void aac_src_notify_adapter(struct aac_dev *dev, u32 event)
 	switch (event) {
 
 	case AdapNormCmdQue:
-		src_writel(dev, MUnit.ODR_C,
-			INBOUNDDOORBELL_1 << SRC_ODR_SHIFT);
+		src_writel(dev, MUnit.ODR_C, INBOUNDDOORBELL_1 << SRC_ODR_SHIFT);
 		break;
 	case HostNormRespNotFull:
-		src_writel(dev, MUnit.ODR_C,
-			INBOUNDDOORBELL_4 << SRC_ODR_SHIFT);
+		src_writel(dev, MUnit.ODR_C, INBOUNDDOORBELL_4 << SRC_ODR_SHIFT);
 		break;
 	case AdapNormRespQue:
-		src_writel(dev, MUnit.ODR_C,
-			INBOUNDDOORBELL_2 << SRC_ODR_SHIFT);
+		src_writel(dev, MUnit.ODR_C, INBOUNDDOORBELL_2 << SRC_ODR_SHIFT);
 		break;
 	case HostNormCmdNotFull:
-		src_writel(dev, MUnit.ODR_C,
-			INBOUNDDOORBELL_3 << SRC_ODR_SHIFT);
+		src_writel(dev, MUnit.ODR_C, INBOUNDDOORBELL_3 << SRC_ODR_SHIFT);
+		break;
+	case HostShutdown:
+//		src_sync_cmd(dev, HOST_CRASHING, 0, 0, 0, 0, 0, 0,
+//		  NULL, NULL, NULL, NULL, NULL);
 		break;
 	case FastIo:
-		src_writel(dev, MUnit.ODR_C,
-			INBOUNDDOORBELL_6 << SRC_ODR_SHIFT);
+		src_writel(dev, MUnit.ODR_C, INBOUNDDOORBELL_6 << SRC_ODR_SHIFT);
 		break;
 	case AdapPrintfDone:
-		src_writel(dev, MUnit.ODR_C,
-			INBOUNDDOORBELL_5 << SRC_ODR_SHIFT);
+		src_writel(dev, MUnit.ODR_C, INBOUNDDOORBELL_5 << SRC_ODR_SHIFT);
 		break;
 	default:
 		BUG();
@@ -335,16 +473,33 @@ static void aac_src_notify_adapter(struct aac_dev *dev, u32 event)
 static void aac_src_start_adapter(struct aac_dev *dev)
 {
 	struct aac_init *init;
+	int i;
 
-	 /* reset host_rrq_idx first */
-	dev->host_rrq_idx = 0;
+	/* reset host_rrq_idx first */
+	for (i = 0; i < dev->max_msix; i++) {
+		dev->host_rrq_idx[i] = i * dev->vector_cap;
+		atomic_set(&dev->rrq_outstanding[i], 0);
+	}
+	dev->fibs_pushed_no = 0;
 
 	init = dev->init;
 	init->HostElapsedSeconds = cpu_to_le32(get_seconds());
-
-	/* We can only use a 32 bit address here */
+	// We can only use a 32 bit address here
 	src_sync_cmd(dev, INIT_STRUCT_BASE_ADDRESS, (u32)(ulong)dev->init_pa,
 	  0, 0, 0, 0, 0, NULL, NULL, NULL, NULL, NULL);
+#	if (defined(AAC_DEBUG_INSTRUMENT_INIT))
+		printk(KERN_INFO"INIT_STRUCT_BASE_ADDRESS=0x%lx\n",
+		  (unsigned long)dev->init_pa);
+#	endif
+#if (defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+	/*
+	 * On some cards, without a wait here after the INIT_STRUCT_BASE_ADDRESS
+	 * command, the ContainerCommand in AacHba_ProbeContainers() fails to
+	 * report the container.
+	 * The wait time was determined by trial-and-error.
+	 */
+	 mdelay(500);
+#endif
 }
 
 /**
@@ -369,6 +524,7 @@ static int aac_src_check_health(struct aac_dev *dev)
 	 */
 	if (unlikely(status & KERNEL_PANIC))
 		return (status >> 16) & 0xFF;
+	
 	/*
 	 *	Wait for the adapter to be up and running.
 	 */
@@ -386,57 +542,187 @@ static int aac_src_check_health(struct aac_dev *dev)
  *
  *	Will send a fib, returning 0 if successful.
  */
-static int aac_src_deliver_message(struct fib *fib)
+static int aac_src_deliver_message(struct fib * fib)
 {
 	struct aac_dev *dev = fib->dev;
 	struct aac_queue *q = &dev->queues->queue[AdapNormCmdQueue];
-	unsigned long qflags;
 	u32 fibsize;
-	dma_addr_t address;
+	u64 address;
 	struct aac_fib_xporthdr *pFibX;
-	u16 hdr_size = le16_to_cpu(fib->hw_fib_va->header.Size);
-
-	spin_lock_irqsave(q->lock, qflags);
-	q->numpending++;
-	spin_unlock_irqrestore(q->lock, qflags);
-
-	if (dev->comm_interface == AAC_COMM_MESSAGE_TYPE2) {
-		/* Calculate the amount to the fibsize bits */
-		fibsize = (hdr_size + 127) / 128 - 1;
-		if (fibsize > (ALIGN32 - 1))
-			return -EMSGSIZE;
-		/* New FIB header, 32-bit */
-		address = fib->hw_fib_pa;
-		fib->hw_fib_va->header.StructType = FIB_MAGIC2;
-		fib->hw_fib_va->header.SenderFibAddress = (u32)address;
-		fib->hw_fib_va->header.u.TimeStamp = 0;
-		BUG_ON(upper_32_bits(address) != 0L);
-		address |= fibsize;
-	} else {
-		/* Calculate the amount to the fibsize bits */
-		fibsize = (sizeof(struct aac_fib_xporthdr) + hdr_size + 127) / 128 - 1;
-		if (fibsize > (ALIGN32 - 1))
-			return -EMSGSIZE;
-
-		/* Fill XPORT header */
-		pFibX = (void *)fib->hw_fib_va - sizeof(struct aac_fib_xporthdr);
-		pFibX->Handle = cpu_to_le32(fib->hw_fib_va->header.Handle);
-		pFibX->HostAddress = cpu_to_le64(fib->hw_fib_pa);
-		pFibX->Size = cpu_to_le32(hdr_size);
-
-		/*
-		 * The xport header has been 32-byte aligned for us so that fibsize
-		 * can be masked out of this address by hardware. -- BenC
-		 */
-		address = fib->hw_fib_pa - sizeof(struct aac_fib_xporthdr);
-		if (address & (ALIGN32 - 1))
-			return -EINVAL;
-		address |= fibsize;
+	int native_hba;
+
+#if !defined(writeq)
+	unsigned long flags;
+#endif
+
+	atomic_inc(&q->numpending); 
+
+	native_hba = (fib->flags & FIB_CONTEXT_FLAG_NATIVE_HBA) ? 1 : 0;
+
+	if (!native_hba) {
+#if (defined(AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB))
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x70)
+	if (nblank(fwprintf(x))
+#if ((AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30) == 0x10)
+	 && !(fib->hw_fib_va->header.XferState &
+	  cpu_to_le32(NoResponseExpected | Async))
+#else
+	 && dev->aif_thread
+#endif
+	) {
+		unsigned long DebugFlags = dev->FwDebugFlags;
+		dev->FwDebugFlags |= FW_DEBUG_FLAGS_NO_HEADERS_B;
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x30)
+		fwprintf((dev, HBA_FLAGS_DBG_FW_PRINT_B, AAC_DEBUG_PREAMBLE
+		  "send Q=0x%X I=0x%X %u+%u+%u\n" AAC_DEBUG_POSTAMBLE,
+		  (int)(fib - dev->fibs), 
+	   	  fib->hw_fib_va->header.Handle,
+		  le16_to_cpu(fib->hw_fib_va->header.Command),
+		  le32_to_cpu(((struct aac_query_mount *)
+		    fib->hw_fib_va->data)->command),
+		  le32_to_cpu(((struct aac_query_mount *)
+		    fib->hw_fib_va->data)->type)));
+#endif
+#if (AAC_DEBUG_INSTRUMENT_IOCTL_SENDFIB & 0x40)
+		{
+			u8 * p = (u8 *)fib->hw_fib_va;
+			unsigned len = le16_to_cpu(fib->hw_fib_va->header.Size);
+			char buffer[80-AAC_DEBUG_PREAMBLE_SIZE];
+			char * cp = buffer;
+
+			strcpy(cp, "FIB=");
+			cp += 4;
+			while (len > 0) {
+				if (cp >= &buffer[sizeof(buffer)-4]) {
+					fwprintf((dev,
+					  HBA_FLAGS_DBG_FW_PRINT_B,
+					  AAC_DEBUG_PREAMBLE "%s\n"
+					  AAC_DEBUG_POSTAMBLE,
+					  buffer));
+					strcpy(cp = buffer, "    ");
+					cp += 4;
+				}
+				sprintf (cp, "%02x ", *(p++));
+				cp += strlen(cp);
+				--len;
+			}
+			if (cp > &buffer[4]) {
+				fwprintf((dev,
+				  HBA_FLAGS_DBG_FW_PRINT_B,
+				  AAC_DEBUG_PREAMBLE "%s\n"
+				  AAC_DEBUG_POSTAMBLE, buffer));
+			}
+		}
+#endif
+		dev->FwDebugFlags = DebugFlags;
+	}
+#endif
+#endif
 	}
 
-	src_writel(dev, MUnit.IQ_H, upper_32_bits(address) & 0xffffffff);
-	src_writel(dev, MUnit.IQ_L, address & 0xffffffff);
+	if (dev->msi_enabled && dev->max_msix > 1 &&
+		(native_hba || fib->hw_fib_va->header.Command != AifRequest)) {
+		u_int16_t vector_no, first_choice = 0xffff;
 
+		vector_no = dev->fibs_pushed_no % dev->max_msix;
+		do {
+			if (atomic_read(&dev->rrq_outstanding[vector_no]) <
+			    dev->vector_cap)
+				break;
+			if (0xffff == first_choice)
+				first_choice = vector_no;
+			else if (vector_no == first_choice)
+				break;
+			vector_no += 1;
+			if (vector_no == dev->max_msix)
+				vector_no = 0;
+		} while(1);
+		if (vector_no == first_choice)
+			return -EBUSY;
+		atomic_inc(&dev->rrq_outstanding[vector_no]);
+		if (dev->fibs_pushed_no == 0xffffffff)
+			dev->fibs_pushed_no = 0;
+		else
+			dev->fibs_pushed_no++;
+		if (native_hba) {
+			if (fib->flags & FIB_CONTEXT_FLAG_NATIVE_HBA_TMF) {
+			 ((struct aac_hba_tm_req *)fib->hw_fib_va)->reply_qid
+				= vector_no;
+			 ((struct aac_hba_tm_req *)fib->hw_fib_va)->request_id
+				+= (vector_no << 16);
+			} else {	
+			 ((struct aac_hba_cmd_req *)fib->hw_fib_va)->reply_qid
+				= vector_no;
+			 ((struct aac_hba_cmd_req *)fib->hw_fib_va)->request_id
+				+= (vector_no << 16);
+			}
+		} else {
+			fib->hw_fib_va->header.Handle += (vector_no << 16);
+		}
+	} else {
+		atomic_inc(&dev->rrq_outstanding[0]);
+	}
+		
+	if (native_hba) {
+		address = fib->hw_fib_pa;
+		fibsize = (fib->hbacmd_size + 127) / 128 - 1;
+		if (fibsize > 31)
+			fibsize = 31;
+
+#if defined(writeq)
+		src_writeq(dev, MUnit.IQN_L, (u64)address + (u64)fibsize);
+#else
+		spin_lock_irqsave(&fib->dev->iq_lock, flags);
+		src_writel(dev, MUnit.IQN_H, 
+			((u32)(((address) >> 16) >> 16)) & 0xffffffff);
+		src_writel(dev, MUnit.IQN_L, 
+			(u32)(address & 0xffffffff) + fibsize);
+		spin_unlock_irqrestore(&fib->dev->iq_lock, flags);
+#endif
+		
+	} else {
+		if (dev->comm_interface == AAC_COMM_MESSAGE_TYPE2) {
+			/* Calculate the amount to the fibsize bits */
+			fibsize = (le16_to_cpu(fib->hw_fib_va->header.Size)
+				+ 127) / 128 - 1;
+			/* New FIB header, 32-bit */
+			address = fib->hw_fib_pa;
+			fib->hw_fib_va->header.StructType = FIB_MAGIC2;
+			fib->hw_fib_va->header.SenderFibAddress = 
+				cpu_to_le32((u32)address);
+			fib->hw_fib_va->header.u.TimeStamp = 0; 
+			BUG_ON(((u32)(((address) >> 16) >> 16)) != 0L);
+		} else {
+			/* Calculate the amount to the fibsize bits */
+			fibsize = (sizeof(struct aac_fib_xporthdr) + 
+				le16_to_cpu(fib->hw_fib_va->header.Size)
+				+ 127) / 128 - 1; 
+			/* Fill XPORT header */ 
+			pFibX = (struct aac_fib_xporthdr *)
+				((unsigned char *)fib->hw_fib_va - 
+				sizeof(struct aac_fib_xporthdr));
+			pFibX->Handle = fib->hw_fib_va->header.Handle;
+			pFibX->HostAddress = 
+				cpu_to_le64((u64)fib->hw_fib_pa);
+			pFibX->Size = cpu_to_le32(
+				le16_to_cpu(fib->hw_fib_va->header.Size));
+			address = fib->hw_fib_pa - 
+				(u64)sizeof(struct aac_fib_xporthdr);
+		}
+		if (fibsize > 31) 
+			fibsize = 31;
+
+#if defined(writeq)
+		src_writeq(dev, MUnit.IQ_L, (u64)address + (u64)fibsize);
+#else
+		spin_lock_irqsave(&fib->dev->iq_lock, flags);
+		src_writel(dev, MUnit.IQ_H, 
+			((u32)(((address) >> 16) >> 16)) & 0xffffffff);
+		src_writel(dev, MUnit.IQ_L, 
+			(u32)(address & 0xffffffff) + fibsize);
+		spin_unlock_irqrestore(&fib->dev->iq_lock, flags);
+#endif
+	}	
 	return 0;
 }
 
@@ -445,28 +731,25 @@ static int aac_src_deliver_message(struct fib *fib)
  *	@size: mapping resize request
  *
  */
-static int aac_src_ioremap(struct aac_dev *dev, u32 size)
+static int aac_src_ioremap(struct aac_dev * dev, u32 size)
 {
 	if (!size) {
-		iounmap(dev->regs.src.bar1);
-		dev->regs.src.bar1 = NULL;
 		iounmap(dev->regs.src.bar0);
 		dev->base = dev->regs.src.bar0 = NULL;
 		return 0;
 	}
-	dev->regs.src.bar1 = ioremap(pci_resource_start(dev->pdev, 2),
-		AAC_MIN_SRC_BAR1_SIZE);
+	dev->regs.src.bar1 = 
+        ioremap(pci_resource_start(dev->pdev, 2), AAC_MIN_SRC_BAR1_SIZE);
 	dev->base = NULL;
 	if (dev->regs.src.bar1 == NULL)
 		return -1;
-	dev->base = dev->regs.src.bar0 = ioremap(dev->base_start, size);
+	dev->base = dev->regs.src.bar0 = ioremap(dev->scsi_host_ptr->base, size);
 	if (dev->base == NULL) {
 		iounmap(dev->regs.src.bar1);
 		dev->regs.src.bar1 = NULL;
 		return -1;
 	}
-	dev->IndexRegs = &((struct src_registers __iomem *)
-		dev->base)->u.tupelo.IndexRegs;
+	dev->IndexRegs = &((struct src_registers __iomem *)dev->base)->u.tupelo.IndexRegs;
 	return 0;
 }
 
@@ -475,18 +758,25 @@ static int aac_src_ioremap(struct aac_dev *dev, u32 size)
  *	@size: mapping resize request
  *
  */
-static int aac_srcv_ioremap(struct aac_dev *dev, u32 size)
+static int aac_srcv_ioremap(struct aac_dev * dev, u32 size)
 {
 	if (!size) {
 		iounmap(dev->regs.src.bar0);
 		dev->base = dev->regs.src.bar0 = NULL;
 		return 0;
 	}
-	dev->base = dev->regs.src.bar0 = ioremap(dev->base_start, size);
-	if (dev->base == NULL)
+	dev->regs.src.bar1 = 
+        ioremap(pci_resource_start(dev->pdev, 2), AAC_MIN_SRCV_BAR1_SIZE);
+	dev->base = NULL;
+	if (dev->regs.src.bar1 == NULL)
 		return -1;
-	dev->IndexRegs = &((struct src_registers __iomem *)
-		dev->base)->u.denali.IndexRegs;
+	dev->base = dev->regs.src.bar0 = ioremap(dev->scsi_host_ptr->base, size);
+	if (dev->base == NULL) {
+		iounmap(dev->regs.src.bar1);
+		dev->regs.src.bar1 = NULL;
+		return -1;
+	}
+	dev->IndexRegs = &((struct src_registers __iomem *)dev->base)->u.denali.IndexRegs;
 	return 0;
 }
 
@@ -498,23 +788,52 @@ static int aac_src_restart_adapter(struct aac_dev *dev, int bled)
 		if (bled)
 			printk(KERN_ERR "%s%d: adapter kernel panic'd %x.\n",
 				dev->name, dev->id, bled);
+
+		dev->a_ops.adapter_enable_int = aac_src_disable_interrupt;
+
 		bled = aac_adapter_sync_cmd(dev, IOP_RESET_ALWAYS,
 			0, 0, 0, 0, 0, 0, &var, &reset_mask, NULL, NULL, NULL);
-			if (bled || (var != 0x00000001))
-				return -EINVAL;
-		if (dev->supplement_adapter_info.SupportedOptions2 &
-			AAC_OPTION_DOORBELL_RESET) {
+			if ((bled || var != 0x00000001) && !dev->doorbell_mask)
+				bled = -EINVAL;
+			else if (dev->doorbell_mask) {
+				reset_mask = dev->doorbell_mask;
+				bled = 0;
+				var = 0x00000001;
+			}
+		
+			if ((dev->pdev->device == PMC_DEVICE_S7 ||
+	     		    dev->pdev->device == PMC_DEVICE_S8 ||
+	     		    dev->pdev->device == PMC_DEVICE_S9) && dev->msi_enabled) {
+				aac_src_access_devreg(dev, AAC_ENABLE_INTX);
+				dev->msi_enabled = 0;
+				msleep(5000); /* Delay 5 seconds */
+			}
+		if (!bled && (dev->supplement_adapter_info.SupportedOptions2 &
+			AAC_OPTION_DOORBELL_RESET)) {
 			src_writel(dev, MUnit.IDR, reset_mask);
-			msleep(5000); /* Delay 5 seconds */
+			ssleep(45);
+		}
+		else
+		{
+
+			src_writel(dev, MUnit.IDR, 0x100);
+			ssleep(45);
+
 		}
 	}
 
 	if (src_readl(dev, MUnit.OMR) & KERNEL_PANIC)
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+	{
+		if (var == 10)
+			printk(KERN_INFO "IOP_RESET disabled\n");
+#endif
 		return -ENODEV;
-
+#if (defined(AAC_DEBUG_INSTRUMENT_RESET))
+	}
+#endif
 	if (startup_timeout < 300)
 		startup_timeout = 300;
-
 	return 0;
 }
 
@@ -527,8 +846,10 @@ int aac_src_select_comm(struct aac_dev *dev, int comm)
 {
 	switch (comm) {
 	case AAC_COMM_MESSAGE:
-		dev->a_ops.adapter_enable_int = aac_src_enable_interrupt_message;
 		dev->a_ops.adapter_intr = aac_src_intr_message;
+#if defined(__ESX5__)
+		dev->a_ops.adapter_intr_poll = aac_src_intr_message_poll;
+#endif
 		dev->a_ops.adapter_deliver = aac_src_deliver_message;
 		break;
 	default:
@@ -543,13 +864,17 @@ int aac_src_select_comm(struct aac_dev *dev, int comm)
  *
  */
 
-int aac_src_init(struct aac_dev *dev)
+int aac_src_init(struct aac_dev * dev)
 {
 	unsigned long start;
 	unsigned long status;
 	int restart = 0;
 	int instance = dev->id;
-	const char *name = dev->name;
+	const char * name = dev->name;
+
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19)) && !defined(HAS_RESET_DEVICES))
+#	define reset_devices aac_reset_devices
+#endif
 
 	dev->a_ops.adapter_ioremap = aac_src_ioremap;
 	dev->a_ops.adapter_comm = aac_src_select_comm;
@@ -580,28 +905,26 @@ int aac_src_init(struct aac_dev *dev)
 	 */
 	status = src_readl(dev, MUnit.OMR);
 	if (status & SELF_TEST_FAILED) {
-		printk(KERN_ERR "%s%d: adapter self-test failed.\n",
-			dev->name, instance);
+		printk(KERN_ERR "%s%d: adapter self-test failed.\n", dev->name, instance);
 		goto error_iounmap;
 	}
 	/*
 	 *	Check to see if the monitor panic'd while booting.
 	 */
 	if (status & MONITOR_PANIC) {
-		printk(KERN_ERR "%s%d: adapter monitor panic.\n",
-			dev->name, instance);
+		printk(KERN_ERR "%s%d: adapter monitor panic.\n", dev->name, instance);
 		goto error_iounmap;
 	}
 	start = jiffies;
 	/*
 	 *	Wait for the adapter to be up and running. Wait up to 3 minutes
 	 */
-	while (!((status = src_readl(dev, MUnit.OMR)) &
-		KERNEL_UP_AND_RUNNING)) {
+	while (!((status = src_readl(dev, MUnit.OMR)) & KERNEL_UP_AND_RUNNING))
+	{
 		if ((restart &&
 		  (status & (KERNEL_PANIC|SELF_TEST_FAILED|MONITOR_PANIC))) ||
 		  time_after(jiffies, start+HZ*startup_timeout)) {
-			printk(KERN_ERR "%s%d: adapter kernel failed to start, init status = %lx.\n",
+			printk(KERN_ERR "%s%d: adapter kernel failed to start, init status = %lx.\n", 
 					dev->name, instance, status);
 			goto error_iounmap;
 		}
@@ -611,8 +934,7 @@ int aac_src_init(struct aac_dev *dev)
 		  ((startup_timeout > 60)
 		    ? (startup_timeout - 60)
 		    : (startup_timeout / 2))))) {
-			if (likely(!aac_src_restart_adapter(dev,
-			    aac_src_check_health(dev))))
+			if (likely(!aac_src_restart_adapter(dev, aac_src_check_health(dev))))
 				start = jiffies;
 			++restart;
 		}
@@ -625,10 +947,12 @@ int aac_src_init(struct aac_dev *dev)
 	 */
 	dev->a_ops.adapter_interrupt = aac_src_interrupt_adapter;
 	dev->a_ops.adapter_disable_int = aac_src_disable_interrupt;
+	dev->a_ops.adapter_enable_int = aac_src_disable_interrupt;
 	dev->a_ops.adapter_notify = aac_src_notify_adapter;
 	dev->a_ops.adapter_sync_cmd = src_sync_cmd;
 	dev->a_ops.adapter_check_health = aac_src_check_health;
 	dev->a_ops.adapter_restart = aac_src_restart_adapter;
+	dev->a_ops.adapter_start = aac_src_start_adapter;
 
 	/*
 	 *	First clear out all interrupts.  Then enable the one's that we
@@ -643,15 +967,21 @@ int aac_src_init(struct aac_dev *dev)
 		goto error_iounmap;
 	if (dev->comm_interface != AAC_COMM_MESSAGE_TYPE1)
 		goto error_iounmap;
-
-	dev->msi = aac_msi && !pci_enable_msi(dev->pdev);
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_ENABLE_MSI))
+#if ((!defined(CONFIG_XEN) || LINUX_VERSION_CODE > KERNEL_VERSION(2,6,19)) || \
+     defined(__VMKERNEL_MODULE__) || defined(__VMKLNX30__) || defined(__VMKLNX__))
+	dev->msi = !pci_enable_msi(dev->pdev);
+#endif
+#endif
+	dev->aac_msix[0].vector_no = 0;
+	dev->aac_msix[0].dev = dev;
 
 	if (request_irq(dev->pdev->irq, dev->a_ops.adapter_intr,
-			IRQF_SHARED|IRQF_DISABLED, "aacraid", dev) < 0) {
-
+		IRQF_SHARED|IRQF_DISABLED, "aacraid", &(dev->aac_msix[0])) < 0) {
+#if ((LINUX_VERSION_CODE > KERNEL_VERSION(2,6,8)) || defined(PCI_HAS_DISABLE_MSI))
 		if (dev->msi)
 			pci_disable_msi(dev->pdev);
-
+#endif
 		printk(KERN_ERR "%s%d: Interrupt unavailable.\n",
 			name, instance);
 		goto error_iounmap;
@@ -659,12 +989,14 @@ int aac_src_init(struct aac_dev *dev)
 	dev->dbg_base = pci_resource_start(dev->pdev, 2);
 	dev->dbg_base_mapped = dev->regs.src.bar1;
 	dev->dbg_size = AAC_MIN_SRC_BAR1_SIZE;
+	dev->a_ops.adapter_enable_int = aac_src_enable_interrupt_message;
+
 
 	aac_adapter_enable_int(dev);
 
 	if (!dev->sync_mode) {
 		/*
-		 * Tell the adapter that all is configured, and it can
+		 *	Tell the adapter that all is configured, and it can
 		 * start accepting requests
 		 */
 		aac_src_start_adapter(dev);
@@ -682,14 +1014,17 @@ error_iounmap:
  *
  */
 
-int aac_srcv_init(struct aac_dev *dev)
+int aac_srcv_init(struct aac_dev * dev)
 {
 	unsigned long start;
 	unsigned long status;
 	int restart = 0;
 	int instance = dev->id;
-	const char *name = dev->name;
-
+	int waitCount;
+	const char * name = dev->name;
+#if ((LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19)) && !defined(HAS_RESET_DEVICES))
+#	define reset_devices aac_reset_devices
+#endif
 	dev->a_ops.adapter_ioremap = aac_srcv_ioremap;
 	dev->a_ops.adapter_comm = aac_src_select_comm;
 
@@ -715,18 +1050,20 @@ int aac_srcv_init(struct aac_dev *dev)
 		do {
 			status = src_readl(dev, MUnit.OMR);
 			if (time_after(jiffies, start+HZ*FWUPD_TIMEOUT)) {
-				printk(KERN_ERR "%s%d: adapter flash update failed.\n",
-					dev->name, instance);
+				printk(KERN_ERR "%s%d: adapter flash update failed.\n", dev->name, instance);
 				goto error_iounmap;
 			}
-		} while (!(status & FLASH_UPD_SUCCESS) &&
-			 !(status & FLASH_UPD_FAILED));
-		/* Delay 10 seconds.
-		 * Because right now FW is doing a soft reset,
-		 * do not read scratch pad register at this time
+		} while (!(status & FLASH_UPD_SUCCESS) && !(status & FLASH_UPD_FAILED));
+		/* Delay 10 seconds. Because right now FW is doing a soft reset, do not
+		 * read scratch pad register at this time
 		 */
-		ssleep(10);
+		waitCount = 10 * 10000;
+		while (waitCount) {
+			udelay(100);	/* delay 100 microseconds */
+			waitCount--;
+		}
 	}
+			
 	/*
 	 *	Check to see if the board panic'd while booting.
 	 */
@@ -755,13 +1092,13 @@ int aac_srcv_init(struct aac_dev *dev)
 	/*
 	 *	Wait for the adapter to be up and running. Wait up to 3 minutes
 	 */
-	while (!((status = src_readl(dev, MUnit.OMR)) &
-		KERNEL_UP_AND_RUNNING) ||
-		status == 0xffffffff) {
+	while (!((status = src_readl(dev, MUnit.OMR)) & KERNEL_UP_AND_RUNNING) ||
+	       status == 0xffffffff)
+	{
 		if ((restart &&
 		  (status & (KERNEL_PANIC|SELF_TEST_FAILED|MONITOR_PANIC))) ||
 		  time_after(jiffies, start+HZ*startup_timeout)) {
-			printk(KERN_ERR "%s%d: adapter kernel failed to start, init status = %lx.\n",
+			printk(KERN_ERR "%s%d: adapter kernel failed to start, init status = %lx.\n", 
 					dev->name, instance, status);
 			goto error_iounmap;
 		}
@@ -784,10 +1121,12 @@ int aac_srcv_init(struct aac_dev *dev)
 	 */
 	dev->a_ops.adapter_interrupt = aac_src_interrupt_adapter;
 	dev->a_ops.adapter_disable_int = aac_src_disable_interrupt;
+	dev->a_ops.adapter_enable_int = aac_src_disable_interrupt;
 	dev->a_ops.adapter_notify = aac_src_notify_adapter;
 	dev->a_ops.adapter_sync_cmd = src_sync_cmd;
 	dev->a_ops.adapter_check_health = aac_src_check_health;
 	dev->a_ops.adapter_restart = aac_src_restart_adapter;
+	dev->a_ops.adapter_start = aac_src_start_adapter;
 
 	/*
 	 *	First clear out all interrupts.  Then enable the one's that we
@@ -802,26 +1141,25 @@ int aac_srcv_init(struct aac_dev *dev)
 		goto error_iounmap;
 	if (dev->comm_interface != AAC_COMM_MESSAGE_TYPE2)
 		goto error_iounmap;
-	dev->msi = aac_msi && !pci_enable_msi(dev->pdev);
-	if (request_irq(dev->pdev->irq, dev->a_ops.adapter_intr,
-		IRQF_SHARED|IRQF_DISABLED, "aacraid", dev) < 0) {
-		if (dev->msi)
-			pci_disable_msi(dev->pdev);
-		printk(KERN_ERR "%s%d: Interrupt unavailable.\n",
-			name, instance);
+
+	if (dev->msi_enabled)
+		aac_src_access_devreg(dev, AAC_ENABLE_MSIX);
+
+	if(aac_acquire_irq(dev))
 		goto error_iounmap;
-	}
-	dev->dbg_base = dev->base_start;
-	dev->dbg_base_mapped = dev->base;
-	dev->dbg_size = dev->base_size;
 
-	aac_adapter_enable_int(dev);
+	dev->dbg_base = pci_resource_start(dev->pdev, 2);
+	dev->dbg_base_mapped = dev->regs.src.bar1;
+	dev->dbg_size = AAC_MIN_SRCV_BAR1_SIZE;
+	dev->a_ops.adapter_enable_int = aac_src_enable_interrupt_message;
 
+	aac_adapter_enable_int(dev);
+	
 	if (!dev->sync_mode) {
 		/*
-		 * Tell the adapter that all is configured, and it can
-		 * start accepting requests
-		 */
+	 	 *	Tell the adapter that all is configured, and it can
+	 	 * start accepting requests
+	 	 */
 		aac_src_start_adapter(dev);
 	}
 	return 0;
@@ -831,3 +1169,86 @@ error_iounmap:
 	return -1;
 }
 
+
+void aac_src_access_devreg(struct aac_dev *dev, int mode) {
+	u_int32_t val;
+
+	switch (mode) {
+	case AAC_ENABLE_INTERRUPT:
+		src_writel(dev, MUnit.OIMR, dev->OIMR = (dev->msi_enabled ? AAC_INT_ENABLE_TYPE1_MSIX :
+									    AAC_INT_ENABLE_TYPE1_INTX));
+		break;
+
+	case AAC_DISABLE_INTERRUPT:
+		src_writel(dev, MUnit.OIMR, dev->OIMR = AAC_INT_DISABLE_ALL);
+		break;
+		
+	case AAC_ENABLE_MSIX:
+		/* set bit 6 */
+		val = src_readl(dev, MUnit.IDR);
+		val |= 0x40;
+		src_writel(dev,  MUnit.IDR, val);
+		src_readl(dev, MUnit.IDR);
+		/* unmask int. */
+		val = PMC_ALL_INTERRUPT_BITS;
+		src_writel(dev, MUnit.IOAR, val);
+		val = src_readl(dev, MUnit.OIMR);
+		src_writel(dev, MUnit.OIMR,
+				val & (~(PMC_GLOBAL_INT_BIT2 | PMC_GLOBAL_INT_BIT0)));
+		break;
+
+	case AAC_DISABLE_MSIX:
+		/* reset bit 6 */
+		val = src_readl(dev, MUnit.IDR);
+		val &= ~0x40;
+		src_writel(dev, MUnit.IDR, val);
+		src_readl(dev, MUnit.IDR);
+		break;
+
+	case AAC_CLEAR_AIF_BIT:
+		/* set bit 5 */
+		val = src_readl(dev, MUnit.IDR);
+		val |= 0x20;
+		src_writel(dev, MUnit.IDR, val);
+		src_readl(dev, MUnit.IDR);
+		break;
+
+	case AAC_CLEAR_SYNC_BIT:
+		/* set bit 4 */
+		val = src_readl(dev, MUnit.IDR);
+		val |= 0x10;
+		src_writel(dev, MUnit.IDR, val);
+		src_readl(dev, MUnit.IDR);
+		break;
+
+	case AAC_ENABLE_INTX:
+		/* set bit 7 */
+		val = src_readl(dev, MUnit.IDR);
+		val |= 0x80;
+		src_writel(dev, MUnit.IDR, val);
+		src_readl(dev, MUnit.IDR);
+		/* unmask int. */
+		val = PMC_ALL_INTERRUPT_BITS;
+		src_writel(dev, MUnit.IOAR, val);
+		src_readl(dev, MUnit.IOAR);
+		val = src_readl(dev, MUnit.OIMR);
+		src_writel(dev, MUnit.OIMR,
+				val & (~(PMC_GLOBAL_INT_BIT2)));
+		break;
+
+	default:
+		break;
+	}
+}
+
+static int aac_src_get_sync_status(struct aac_dev *dev) {
+
+	int val;
+
+	if (dev->msi_enabled)
+		val = src_readl(dev, MUnit.ODR_MSI) & 0x1000 ? 1 : 0;
+	else
+		val = src_readl(dev, MUnit.ODR_R) >> SRC_ODR_SHIFT;
+
+	return val;
+}
