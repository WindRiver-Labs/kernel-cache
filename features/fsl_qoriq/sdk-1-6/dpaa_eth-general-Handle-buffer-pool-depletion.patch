From ac9075be70744ddaad1355cd70dea58b860f4ad5 Mon Sep 17 00:00:00 2001
From: Ioana Radulescu <ruxandra.radulescu@freescale.com>
Date: Fri, 21 Jun 2013 20:51:00 +0000
Subject: [PATCH 0365/1089] dpaa_eth: Handle buffer pool depletion

[Original patch taken from QorIQ-SDK-V1.6-SOURCE-20140619-yocto.iso]

If the system gets into an out-of-memory state, we are unable to
refill the default buffer pool with new buffers. While this lasts,
just release any incoming frame back to the pool without further
processing.

Signed-off-by: Ioana Radulescu <ruxandra.radulescu@freescale.com>
Signed-off-by: Bogdan Hamciuc <bogdan.hamciuc@freescale.com>
Change-Id: Ia7fe59c44aa371f81540b45d197aef896b6d6b3a
Reviewed-on: http://git.am.freescale.net:8181/3050
Reviewed-by: Bucur Madalin-Cristian-B32716 <madalin.bucur@freescale.com>
Reviewed-by: Fleming Andrew-AFLEMING <AFLEMING@freescale.com>
Tested-by: Fleming Andrew-AFLEMING <AFLEMING@freescale.com>
---
 drivers/net/ethernet/freescale/dpa/dpaa_eth.c | 34 +++++++++++++++++++++++----
 1 file changed, 30 insertions(+), 4 deletions(-)

diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth.c b/drivers/net/ethernet/freescale/dpa/dpaa_eth.c
index e74a5c2..5cccf27 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth.c
@@ -386,13 +386,14 @@ static void dpaa_eth_seed_pool(struct dpa_bp *bp)
  * Add buffers/pages/skbuffs for Rx processing whenever bpool count falls below
  * REFILL_THRESHOLD.
  */
-static void dpaa_eth_refill_bpools(struct dpa_percpu_priv_s *percpu_priv)
+static int dpaa_eth_refill_bpools(struct dpa_percpu_priv_s *percpu_priv)
 {
 	int *countptr = percpu_priv->dpa_bp_count;
 	int count = *countptr;
 	const struct dpa_bp *dpa_bp = percpu_priv->dpa_bp;
-	int new_pages;
+	int new_pages __maybe_unused;
 #ifndef CONFIG_FSL_DPAA_ETH_SG_SUPPORT
+
 	/* this function is called in softirq context;
 	 * no need to protect smp_processor_id() on RT kernel
 	 */
@@ -418,7 +419,12 @@ static void dpaa_eth_refill_bpools(struct dpa_percpu_priv_s *percpu_priv)
 		count += new_pages;
 	}
 	*countptr = count;
+
+	if (*countptr < CONFIG_FSL_DPAA_ETH_MAX_BUF_COUNT)
+		return -ENOMEM;
 #endif
+
+	return 0;
 }
 
 static int dpa_make_shared_port_pool(struct dpa_bp *bp)
@@ -2189,6 +2195,7 @@ ingress_rx_error_dqrr(struct qman_portal		*portal,
 	struct net_device		*net_dev;
 	struct dpa_priv_s		*priv;
 	struct dpa_percpu_priv_s	*percpu_priv;
+	int err;
 
 	net_dev = ((struct dpa_fq *)fq)->net_dev;
 	priv = netdev_priv(net_dev);
@@ -2200,7 +2207,16 @@ ingress_rx_error_dqrr(struct qman_portal		*portal,
 		return qman_cb_dqrr_stop;
 	}
 
-	dpaa_eth_refill_bpools(percpu_priv);
+	err = dpaa_eth_refill_bpools(percpu_priv);
+	if (err) {
+		/* Unable to refill the buffer pool due to insufficient
+		 * system memory. Just release the frame back into the pool,
+		 * otherwise we'll soon end up with an empty buffer pool.
+		 */
+		dpa_fd_release(net_dev, &dq->fd);
+		return qman_cb_dqrr_consume;
+	}
+
 	_dpa_rx_error(net_dev, priv, percpu_priv, &dq->fd, fq->fqid);
 
 	return qman_cb_dqrr_consume;
@@ -2348,6 +2364,7 @@ ingress_rx_default_dqrr(struct qman_portal		*portal,
 	struct net_device		*net_dev;
 	struct dpa_priv_s		*priv;
 	struct dpa_percpu_priv_s	*percpu_priv;
+	int err;
 
 	net_dev = ((struct dpa_fq *)fq)->net_dev;
 	priv = netdev_priv(net_dev);
@@ -2364,7 +2381,16 @@ ingress_rx_default_dqrr(struct qman_portal		*portal,
 	}
 
 	/* Vale of plenty: make sure we didn't run out of buffers */
-	dpaa_eth_refill_bpools(percpu_priv);
+	err = dpaa_eth_refill_bpools(percpu_priv);
+	if (err) {
+		/* Unable to refill the buffer pool due to insufficient
+		 * system memory. Just release the frame back into the pool,
+		 * otherwise we'll soon end up with an empty buffer pool.
+		 */
+		dpa_fd_release(net_dev, &dq->fd);
+		return qman_cb_dqrr_consume;
+	}
+
 	_dpa_rx(net_dev, priv, percpu_priv, &dq->fd, fq->fqid);
 
 	return qman_cb_dqrr_consume;
-- 
2.0.2

