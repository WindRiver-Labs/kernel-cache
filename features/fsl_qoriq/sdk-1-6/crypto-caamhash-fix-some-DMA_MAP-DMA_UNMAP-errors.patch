From 33a9484a252f0fcbf9a8080669e2b8ec1d484faf Mon Sep 17 00:00:00 2001
From: Yanjiang Jin <yanjiang.jin@windriver.com>
Date: Sun, 15 Feb 2015 15:52:04 +0800
Subject: [PATCH 08/10] crypto: caamhash: fix some DMA_MAP/DMA_UNMAP errors

Fix some caamhash DMA_MAP/DMA_UNMAP errors to avoid the calltrace like below:

caam_jr ffe301000.jr: DMA-API: device driver tries to free DMA memory it has not allocated [device address=0x00000000f7511c90] [size=0 bytes]
------------[ cut here ]------------
WARNING: at lib/dma-debug.c:877
Modules linked in:
CPU: 0 PID: 100 Comm: cryptomgr_test Not tainted 3.10.62-ltsi-WR6.0.0.0_standard #185
task: c0000000f74b3300 ti: c0000000f76c8000 task.ti: c0000000f76c8000
NIP: c0000000004f5ed8 LR: c0000000004f5ed4 CTR: c00000000055a160
REGS: c0000000f76cb260 TRAP: 0700   Not tainted  (3.10.62-ltsi-WR6.0.0.0_standard)
MSR: 0000000080029000 <CE,EE,ME>  CR: 24042084  XER: 00000000
SOFTE: 1

GPR00: c0000000004f5ed4 c0000000f76cb4e0 c0000000012af360 000000000000008d
GPR04: 0000000024042084 0000000000000000 c00000000125f1c8 000000000000018d
GPR08: 0000000000000060 0000000000000001 000000000d0ce172 0000000000000020
GPR12: 000000000000018d c000000001fff000 0000000003619bb8 0000000000000dd4
GPR16: c0000000011b0e98 c0000000011b0e98 0000000000000000 c0000000f7511c90
GPR20: 0000000000000014 0000000000000014 0000000000000020 0000000000000009
GPR24: c00000007f024054 00000000f7511c90 c0000000f709b848 c0000000011b0e98
GPR28: 0000000000000000 c000000001565b80 c0000000f76cb5f0 c0000000f7625c10
NIP [c0000000004f5ed8] .check_unmap+0x848/0x9c0
LR [c0000000004f5ed4] .check_unmap+0x844/0x9c0
Call Trace:
[c0000000f76cb4e0] [c0000000004f5ed4] .check_unmap+0x844/0x9c0 (unreliable)
[c0000000f76cb580] [c0000000004f60d4] .debug_dma_unmap_page+0x84/0xb0
[c0000000f76cb6b0] [c000000000827d9c] .ahash_final_ctx+0x3bc/0xb40
[c0000000f76cb7b0] [c000000000825554] .ahash_final+0x34/0x50
[c0000000f76cb830] [c00000000048e8b8] .crypto_ahash_op+0x58/0x150
[c0000000f76cb8c0] [c000000000495148] .test_hash+0x5b8/0x7d0
[c0000000f76cbb30] [c000000000495424] .alg_test_hash+0xc4/0xf0
[c0000000f76cbbc0] [c000000000494928] .alg_test+0xa8/0x2c0
[c0000000f76cbcb0] [c000000000491164] .cryptomgr_test+0x64/0x80
[c0000000f76cbd30] [c00000000009a8d0] .kthread+0xf0/0x100
[c0000000f76cbe30] [c000000000000a08] .ret_from_kernel_thread+0x5c/0xd4
Instruction dump:
7c641b78 419e0160 e8a90050 2fa50000 409e0008 e8a90010 e8de0028 e8fe0030
3c62ff90 38638308 485469c9 60000000 <0fe00000> 4bffff34 e87e0010 2fa30000
---[ end trace 37e1b3342bd2fc8e ]---

Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 drivers/crypto/caam/caamhash.c |   49 +++++++++++++++++++++++++++++++---------
 1 files changed, 38 insertions(+), 11 deletions(-)

diff --git a/drivers/crypto/caam/caamhash.c b/drivers/crypto/caam/caamhash.c
index 72b5fcf..0e98ba5 100644
--- a/drivers/crypto/caam/caamhash.c
+++ b/drivers/crypto/caam/caamhash.c
@@ -204,10 +204,9 @@ try_buf_map_to_sec4_sg(struct device *jrdev, struct sec4_sg_entry *sec4_sg,
 		       u8 *buf, dma_addr_t buf_dma, int buflen,
 		       int last_buflen)
 {
-	if (buf_dma && !dma_mapping_error(jrdev, buf_dma))
-		dma_unmap_single(jrdev, buf_dma, last_buflen, DMA_TO_DEVICE);
 	if (buflen)
-		buf_dma = buf_map_to_sec4_sg(jrdev, sec4_sg, buf, buflen);
+		buf_dma = buf_map_to_sec4_sg(jrdev, sec4_sg, buf,
+				sizeof(u8)*CAAM_MAX_HASH_BLOCK_SIZE);
 	else
 		buf_dma = 0;
 
@@ -480,9 +479,9 @@ static int hash_digest_key(struct caam_hash_ctx *ctx, const u8 *key_in,
 			       digestsize, 1);
 #endif
 	}
-	*keylen = digestsize;
 
 	dma_unmap_single(jrdev, src_dma, *keylen, DMA_TO_DEVICE);
+	*keylen = digestsize;
 	dma_unmap_single(jrdev, dst_dma, digestsize, DMA_FROM_DEVICE);
 
 	kfree(desc);
@@ -695,7 +694,7 @@ static void ahash_done_ctx_src(struct device *jrdev, u32 *desc, u32 err,
 		dev_err(jrdev, "%08x: %s\n", err, caam_jr_strstatus(tmp, err));
 	}
 
-	ahash_unmap_ctx(jrdev, edesc, req, digestsize, DMA_FROM_DEVICE);
+	ahash_unmap_ctx(jrdev, edesc, req, digestsize, DMA_TO_DEVICE);
 	kfree(edesc);
 
 #ifdef DEBUG
@@ -733,7 +732,7 @@ static void ahash_done_ctx_dst(struct device *jrdev, u32 *desc, u32 err,
 		dev_err(jrdev, "%08x: %s\n", err, caam_jr_strstatus(tmp, err));
 	}
 
-	ahash_unmap_ctx(jrdev, edesc, req, ctx->ctx_len, DMA_TO_DEVICE);
+	ahash_unmap_ctx(jrdev, edesc, req, ctx->ctx_len, DMA_FROM_DEVICE);
 	kfree(edesc);
 
 #ifdef DEBUG
@@ -854,6 +853,11 @@ static int ahash_update_ctx(struct ahash_request *req)
 					   DMA_BIDIRECTIONAL);
 			kfree(edesc);
 		}
+
+		if (state->buf_dma && !dma_mapping_error(jrdev, state->buf_dma))
+			dma_unmap_single(jrdev, state->buf_dma,
+					sizeof(u8)*CAAM_MAX_HASH_BLOCK_SIZE,
+					DMA_TO_DEVICE);
 	} else if (*next_buflen) {
 		sg_copy(buf + *buflen, req->src, req->nbytes);
 		*buflen = *next_buflen;
@@ -942,6 +946,9 @@ static int ahash_final_ctx(struct ahash_request *req)
 		kfree(edesc);
 	}
 
+	if (state->buf_dma && !dma_mapping_error(jrdev, state->buf_dma))
+		dma_unmap_single(jrdev, state->buf_dma,
+			sizeof(u8)*CAAM_MAX_HASH_BLOCK_SIZE, DMA_TO_DEVICE);
 	return ret;
 }
 
@@ -1025,6 +1032,10 @@ static int ahash_finup_ctx(struct ahash_request *req)
 		kfree(edesc);
 	}
 
+	if (state->buf_dma && !dma_mapping_error(jrdev, state->buf_dma))
+		dma_unmap_single(jrdev, state->buf_dma,
+			sizeof(u8)*CAAM_MAX_HASH_BLOCK_SIZE, DMA_TO_DEVICE);
+
 	return ret;
 }
 
@@ -1047,7 +1058,8 @@ static int ahash_digest(struct ahash_request *req)
 	int sh_len;
 
 	src_nents = sg_count(req->src, req->nbytes, &chained);
-	dma_map_sg_chained(jrdev, req->src, src_nents ? : 1, DMA_TO_DEVICE,
+	src_nents = src_nents ? : 1;
+	dma_map_sg_chained(jrdev, req->src, src_nents, DMA_TO_DEVICE,
 			   chained);
 	sec4_sg_bytes = src_nents * sizeof(struct sec4_sg_entry);
 
@@ -1068,6 +1080,7 @@ static int ahash_digest(struct ahash_request *req)
 	}
 	edesc->src_nents = src_nents;
 	edesc->chained = chained;
+	edesc->sec4_sg_bytes = sec4_sg_bytes;
 
 	sh_len = desc_len(sh_desc);
 	desc = edesc->hw_desc;
@@ -1132,7 +1145,9 @@ static int ahash_final_no_ctx(struct ahash_request *req)
 	desc = edesc->hw_desc;
 	init_job_desc_shared(desc, ptr, sh_len, HDR_SHARE_DEFER | HDR_REVERSE);
 
-	state->buf_dma = dma_map_single(jrdev, buf, buflen, DMA_TO_DEVICE);
+	state->buf_dma = dma_map_single(jrdev, buf,
+				sizeof(u8)*CAAM_MAX_HASH_BLOCK_SIZE,
+				DMA_TO_DEVICE);
 	if (dma_mapping_error(jrdev, state->buf_dma)) {
 		dev_err(jrdev, "unable to map shared descriptor\n");
 		return -ENOMEM;
@@ -1157,6 +1172,10 @@ static int ahash_final_no_ctx(struct ahash_request *req)
 		kfree(edesc);
 	}
 
+	if (state->buf_dma && !dma_mapping_error(jrdev, state->buf_dma))
+		dma_unmap_single(jrdev, state->buf_dma,
+			sizeof(u8)*CAAM_MAX_HASH_BLOCK_SIZE, DMA_TO_DEVICE);
+
 	return ret;
 }
 
@@ -1217,8 +1236,8 @@ static int ahash_update_no_ctx(struct ahash_request *req)
 			return -ENOMEM;
 		}
 
-		state->buf_dma = buf_map_to_sec4_sg(jrdev, edesc->sec4_sg,
-						    buf, *buflen);
+		state->buf_dma = buf_map_to_sec4_sg(jrdev, edesc->sec4_sg, buf,
+					sizeof(u8)*CAAM_MAX_HASH_BLOCK_SIZE);
 		src_map_to_sec4_sg(jrdev, req->src, src_nents,
 				   edesc->sec4_sg + 1, chained);
 		if (*next_buflen) {
@@ -1253,6 +1272,10 @@ static int ahash_update_no_ctx(struct ahash_request *req)
 					DMA_TO_DEVICE);
 			kfree(edesc);
 		}
+		if (state->buf_dma && !dma_mapping_error(jrdev, state->buf_dma))
+			dma_unmap_single(jrdev, state->buf_dma,
+					sizeof(u8)*CAAM_MAX_HASH_BLOCK_SIZE,
+					DMA_TO_DEVICE);
 	} else if (*next_buflen) {
 		sg_copy(buf + *buflen, req->src, req->nbytes);
 		*buflen = *next_buflen;
@@ -1345,6 +1368,9 @@ static int ahash_finup_no_ctx(struct ahash_request *req)
 		ahash_unmap(jrdev, edesc, req, digestsize);
 		kfree(edesc);
 	}
+	if (state->buf_dma && !dma_mapping_error(jrdev, state->buf_dma))
+		dma_unmap_single(jrdev, state->buf_dma,
+			sizeof(u8)*CAAM_MAX_HASH_BLOCK_SIZE, DMA_TO_DEVICE);
 
 	return ret;
 }
@@ -1379,7 +1405,8 @@ static int ahash_update_first(struct ahash_request *req)
 	if (to_hash) {
 		src_nents = sg_count(req->src, req->nbytes - (*next_buflen),
 				     &chained);
-		dma_map_sg_chained(jrdev, req->src, src_nents ? : 1,
+		src_nents = src_nents ? : 1;
+		dma_map_sg_chained(jrdev, req->src, src_nents,
 				   DMA_TO_DEVICE, chained);
 		sec4_sg_bytes = src_nents * sizeof(struct sec4_sg_entry);
 
-- 
1.7.5.4

