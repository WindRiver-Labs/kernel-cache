From 792c9a10cd752f0ea73b044f1ef6764a4c0139b5 Mon Sep 17 00:00:00 2001
From: Ioana Radulescu <ruxandra.radulescu@nxp.com>
Date: Mon, 25 Jul 2016 18:44:46 +0300
Subject: [PATCH 319/388] staging: fsl-dpaa2/eth: Driver cleanup

Cleanup based on work for upstreaming the driver,
including feedback received in the process.

* access the FD[FRC] field through proper accessors
* use defines for FAS size and offset
* cleanup code for: buffer layout configuration, irq handler,
  set_hash(), dpio_setup()
* fix ops order in probe vs remove
* use GFP_KERNEL for probe-time allocations
* replace number of enqueue retries with a hardcoded value
* fix spacing style

Signed-off-by: Ioana Radulescu <ruxandra.radulescu@nxp.com>
[Original patch taken from SDK-V2.0-1703]
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c | 170 ++++++++++++-------------
 drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h |  24 ++--
 2 files changed, 99 insertions(+), 95 deletions(-)

diff --git a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c
index 76c2bd1..a90ba4e 100644
--- a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c
+++ b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c
@@ -270,7 +270,7 @@ static void dpaa2_eth_rx(struct dpaa2_eth_priv *priv,
 	}
 
 	/* Check if we need to validate the L4 csum */
-	if (likely(fd->simple.frc & DPAA2_FD_FRC_FASV)) {
+	if (likely(dpaa2_fd_get_frc(fd) & DPAA2_FD_FRC_FASV)) {
 		fas = (struct dpaa2_fas *)
 				(vaddr + priv->buf_layout.private_data_size);
 		status = le32_to_cpu(fas->status);
@@ -324,7 +324,7 @@ static void dpaa2_eth_rx_err(struct dpaa2_eth_priv *priv,
 	/* check frame errors in the FD field */
 	if (fd->simple.ctrl & DPAA2_FD_RX_ERR_MASK) {
 		check_fas_errors = !!(fd->simple.ctrl & DPAA2_FD_CTRL_FAERR) &&
-			!!(fd->simple.frc & DPAA2_FD_FRC_FASV);
+			!!(dpaa2_fd_get_frc(fd) & DPAA2_FD_FRC_FASV);
 		if (net_ratelimit())
 			netdev_dbg(priv->net_dev, "Rx frame FD err: %x08\n",
 				fd->simple.ctrl & DPAA2_FD_RX_ERR_MASK);
@@ -466,10 +466,10 @@ static int build_sg_fd(struct dpaa2_eth_priv *priv,
 	/* PTA from egress side is passed as is to the confirmation side so
 	 * we need to clear some fields here in order to find consistent values
 	 * on TX confirmation. We are clearing FAS (Frame Annotation Status)
-	 * field here.
+	 * field from the hardware annotation area
 	 */
 	hwa = sgt_buf + priv->buf_layout.private_data_size;
-	memset(hwa, 0, 8);
+	memset(hwa + DPAA2_FAS_OFFSET, 0, DPAA2_FAS_SIZE);
 
 	sgt = (struct dpaa2_sg_entry *)(sgt_buf + priv->tx_data_offset);
 
@@ -488,7 +488,8 @@ static int build_sg_fd(struct dpaa2_eth_priv *priv,
 
 	/* Store the skb backpointer in the SGT buffer.
 	 * Fit the scatterlist and the number of buffers alongside the
-	 * skb backpointer in the SWA. We'll need all of them on Tx Conf.
+	 * skb backpointer in the software annotation area. We'll need
+	 * all of them on Tx Conf.
 	 */
 	swa = (struct dpaa2_eth_swa *)sgt_buf;
 	swa->skb = skb;
@@ -546,10 +547,10 @@ static int build_single_fd(struct dpaa2_eth_priv *priv,
 	/* PTA from egress side is passed as is to the confirmation side so
 	 * we need to clear some fields here in order to find consistent values
 	 * on TX confirmation. We are clearing FAS (Frame Annotation Status)
-	 * field here
+	 * field from the hardware annotation area
 	 */
 	hwa = buffer_start + priv->buf_layout.private_data_size;
-	memset(hwa, 0, 8);
+	memset(hwa + DPAA2_FAS_OFFSET, 0, DPAA2_FAS_SIZE);
 
 	/* Store a backpointer to the skb at the beginning of the buffer
 	 * (in the private data area) such that we can release it
@@ -723,7 +724,7 @@ static int dpaa2_eth_tx(struct sk_buff *skb, struct net_device *net_dev)
 	trace_dpaa2_tx_fd(net_dev, &fd);
 
 	fq = priv->fq[queue_mapping];
-	for (i = 0; i < (DPAA2_ETH_MAX_TX_QUEUES << 1); i++) {
+	for (i = 0; i < DPAA2_ETH_ENQUEUE_RETRIES; i++) {
 		err = dpaa2_io_service_enqueue_qd(NULL, priv->tx_qdid, 0,
 				fq.tx_qdbin, &fd);
 		/* TODO: This doesn't work. Check on simulator.
@@ -775,7 +776,7 @@ static void dpaa2_eth_tx_conf(struct dpaa2_eth_priv *priv,
 	/* check frame errors in the FD field */
 	if (unlikely(errors)) {
 		check_fas_errors = !!(fd->simple.ctrl & DPAA2_FD_CTRL_FAERR) &&
-			!!(fd->simple.frc & DPAA2_FD_FRC_FASV);
+			!!(dpaa2_fd_get_frc(fd) & DPAA2_FD_FRC_FASV);
 		if (net_ratelimit())
 			netdev_dbg(priv->net_dev, "Tx frame FD err: %x08\n",
 				fd->simple.ctrl & DPAA2_FD_TX_ERR_MASK);
@@ -1646,7 +1647,7 @@ alloc_channel(struct dpaa2_eth_priv *priv)
 	struct device *dev = priv->net_dev->dev.parent;
 	int err;
 
-	channel = kzalloc(sizeof(*channel), GFP_ATOMIC);
+	channel = kzalloc(sizeof(*channel), GFP_KERNEL);
 	if (!channel)
 		return NULL;
 
@@ -1692,18 +1693,24 @@ static int setup_dpio(struct dpaa2_eth_priv *priv)
 	struct device *dev = priv->net_dev->dev.parent;
 	int i, err;
 
-	/* Don't allocate more channels than strictly necessary and assign
-	 * them to cores starting from the first one available in
-	 * cpu_online_mask.
-	 * If the number of channels is lower than the number of cores,
-	 * there will be no rx/tx conf processing on the last cores in the mask.
+	/* We want the ability to spread ingress traffic (RX, TX conf) to as
+	 * many cores as possible, so we need one channel for each core
+	 * (unless there's fewer queues than cores, in which case the extra
+	 * channels would be wasted).
+	 * Allocate one channel per core and register it to the core's
+	 * affine DPIO. If not enough channels are available for all cores
+	 * or if some cores don't have an affine DPIO, there will be no
+	 * ingress frame processing on those cores.
 	 */
 	cpumask_clear(&priv->dpio_cpumask);
 	for_each_online_cpu(i) {
 		/* Try to allocate a channel */
 		channel = alloc_channel(priv);
-		if (!channel)
+		if (!channel) {
+			dev_info(dev,
+				 "No affine channel for cpu %d and above\n", i);
 			goto err_alloc_ch;
+		}
 
 		priv->channel[priv->num_channels] = channel;
 
@@ -1716,12 +1723,11 @@ static int setup_dpio(struct dpaa2_eth_priv *priv)
 		/* Register the new context */
 		err = dpaa2_io_service_register(NULL, nctx);
 		if (err) {
-			dev_info(dev, "No affine DPIO for core %d\n", i);
-			/* This core doesn't have an affine DPIO, but there's
-			 * a chance another one does, so keep trying
+			dev_info(dev, "No affine DPIO for cpu %d\n", i);
+			/* If no affine DPIO for this core, there's probably
+			 * none available for next cores either.
 			 */
-			free_channel(priv, channel);
-			continue;
+			goto err_service_reg;
 		}
 
 		/* Register DPCON notification with MC */
@@ -1742,7 +1748,10 @@ static int setup_dpio(struct dpaa2_eth_priv *priv)
 		cpumask_set_cpu(i, &priv->dpio_cpumask);
 		priv->num_channels++;
 
-		if (priv->num_channels == dpaa2_eth_max_channels(priv))
+		/* Stop if we already have enough channels to accommodate all
+		 * RX and TX conf queues
+		 */
+		if (priv->num_channels == dpaa2_eth_queue_count(priv))
 			break;
 	}
 
@@ -1755,6 +1764,7 @@ static int setup_dpio(struct dpaa2_eth_priv *priv)
 
 err_set_cdan:
 	dpaa2_io_service_deregister(NULL, nctx);
+err_service_reg:
 	free_channel(priv, channel);
 err_alloc_ch:
 	if (cpumask_empty(&priv->dpio_cpumask)) {
@@ -1763,6 +1773,9 @@ err_alloc_ch:
 	}
 	cpumask_copy(&priv->txconf_cpumask, &priv->dpio_cpumask);
 
+	dev_info(dev, "Cores %*pbl available for processing ingress traffic\n",
+		 cpumask_pr_args(&priv->dpio_cpumask));
+
 	return 0;
 }
 
@@ -1980,49 +1993,42 @@ static int setup_dpni(struct fsl_mc_device *ls_dev)
 		goto err_set_rx_queues;
 	}
 
-	/* Configure our buffers' layout */
-	priv->buf_layout.options = DPNI_BUF_LAYOUT_OPT_PARSER_RESULT |
-					DPNI_BUF_LAYOUT_OPT_FRAME_STATUS |
-					DPNI_BUF_LAYOUT_OPT_PRIVATE_DATA_SIZE |
-					DPNI_BUF_LAYOUT_OPT_DATA_ALIGN;
+	/* Configure buffer layouts */
+	/* rx buffer */
 	priv->buf_layout.pass_parser_result = true;
 	priv->buf_layout.pass_frame_status = true;
 	priv->buf_layout.private_data_size = DPAA2_ETH_SWA_SIZE;
-	/* HW erratum mandates data alignment in multiples of 256 */
 	priv->buf_layout.data_align = DPAA2_ETH_RX_BUF_ALIGN;
-
-	/* rx buffer */
+	priv->buf_layout.options = DPNI_BUF_LAYOUT_OPT_PARSER_RESULT |
+					DPNI_BUF_LAYOUT_OPT_FRAME_STATUS |
+					DPNI_BUF_LAYOUT_OPT_PRIVATE_DATA_SIZE |
+					DPNI_BUF_LAYOUT_OPT_DATA_ALIGN;
 	err = dpni_set_buffer_layout(priv->mc_io, 0, priv->mc_token,
 				DPNI_QUEUE_RX, &priv->buf_layout);
 	if (err) {
 		dev_err(dev,
-		"dpni_set_buffer_layout() DPNI_QUEUE_RX failed (%d)\n",
-		err);
+		"dpni_set_buffer_layout(RX) failed\n");
 		goto err_buf_layout;
 	}
 
-	/* tx buffer: remove Rx-only options */
-	priv->buf_layout.options &= ~(DPNI_BUF_LAYOUT_OPT_DATA_ALIGN |
-					DPNI_BUF_LAYOUT_OPT_PARSER_RESULT);
+	/* tx buffer */
+	priv->buf_layout.options = DPNI_BUF_LAYOUT_OPT_FRAME_STATUS |
+				   DPNI_BUF_LAYOUT_OPT_PRIVATE_DATA_SIZE;
 	err = dpni_set_buffer_layout(priv->mc_io, 0, priv->mc_token,
 				DPNI_QUEUE_TX, &priv->buf_layout);
 	if (err) {
 		dev_err(dev,
-		"dpni_set_buffer_layout() DPNI_QUEUE_TX failed (%d)\n",
-		err);
+		"dpni_set_buffer_layout(TX) failed\n");
 		goto err_buf_layout;
 	}
 
-	/* tx-confirm: same options as tx */
-	priv->buf_layout.options &= ~DPNI_BUF_LAYOUT_OPT_PRIVATE_DATA_SIZE;
-	priv->buf_layout.options |= DPNI_BUF_LAYOUT_OPT_TIMESTAMP;
+	/* tx-confirm buffer */
+	priv->buf_layout.options = DPNI_BUF_LAYOUT_OPT_FRAME_STATUS;
 	priv->buf_layout.pass_timestamp = 1;
 	err = dpni_set_buffer_layout(priv->mc_io, 0, priv->mc_token,
 				DPNI_QUEUE_TX_CONFIRM, &priv->buf_layout);
 	if (err) {
-		dev_err(dev,
-		"dpni_set_buffer_layout() DPNI_QUEUE_TX_CONFIRM failed (%d)\n",
-		err);
+		dev_err(dev, "dpni_set_buffer_layout(TX_CONF) failed\n");
 		goto err_buf_layout;
 	}
 
@@ -2040,7 +2046,7 @@ static int setup_dpni(struct fsl_mc_device *ls_dev)
 		dev_warn(dev, "Tx data offset (%d) not a multiple of 64B",
 			 priv->tx_data_offset);
 
-	/* Accommodate SWA space. */
+	/* Accommodate software annotation space (SWA) */
 	priv->tx_data_offset += DPAA2_ETH_SWA_SIZE;
 
 	/* allocate classification rule space */
@@ -2073,6 +2079,8 @@ static void free_dpni(struct dpaa2_eth_priv *priv)
 			    err);
 
 	dpni_close(priv->mc_io, 0, priv->mc_token);
+
+	kfree(priv->cls_rule);
 }
 
 static int setup_rx_flow(struct dpaa2_eth_priv *priv,
@@ -2282,8 +2290,7 @@ int set_hash(struct dpaa2_eth_priv *priv)
 	err = dpni_prepare_key_cfg(&cls_cfg, dma_mem);
 	if (err) {
 		dev_err(dev, "dpni_prepare_key_cfg() failed (%d)", err);
-		kfree(dma_mem);
-		return err;
+		goto err_prep_key;
 	}
 
 	memset(&dist_cfg, 0, sizeof(dist_cfg));
@@ -2294,8 +2301,8 @@ int set_hash(struct dpaa2_eth_priv *priv)
 					       DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, dist_cfg.key_cfg_iova)) {
 		dev_err(dev, "DMA mapping failed\n");
-		kfree(dma_mem);
-		return -ENOMEM;
+		err = -ENOMEM;
+		goto err_dma_map;
 	}
 
 	dist_cfg.dist_size = dpaa2_eth_queue_count(priv);
@@ -2309,13 +2316,13 @@ int set_hash(struct dpaa2_eth_priv *priv)
 	err = dpni_set_rx_tc_dist(priv->mc_io, 0, priv->mc_token, 0, &dist_cfg);
 	dma_unmap_single(dev, dist_cfg.key_cfg_iova,
 			 DPAA2_CLASSIFIER_DMA_SIZE, DMA_TO_DEVICE);
-	kfree(dma_mem);
-	if (err) {
+	if (err)
 		dev_err(dev, "dpni_set_rx_tc_dist() failed (%d)\n", err);
-		return err;
-	}
 
-	return 0;
+err_dma_map:
+err_prep_key:
+	kfree(dma_mem);
+	return err;
 }
 
 /* Bind the DPNI to its needed objects and resources: buffer pool, DPIOs,
@@ -2487,8 +2494,7 @@ static int netdev_init(struct net_device *net_dev)
 		 */
 		eth_hw_addr_random(net_dev);
 		/* Make the user aware, without cluttering the boot log */
-		pr_info_once(KBUILD_MODNAME
-			" device(s) have zero hwaddr, replaced with random");
+		dev_dbg_once(dev, " device(s) have all-zero hwaddr, replaced with random\n");
 		err = dpni_set_primary_mac_addr(priv->mc_io, 0,
 					     priv->mc_token, net_dev->dev_addr);
 		if (err) {
@@ -2567,7 +2573,6 @@ static irqreturn_t dpni_irq0_handler(int irq_num, void *arg)
 
 static irqreturn_t dpni_irq0_handler_thread(int irq_num, void *arg)
 {
-	u8 irq_index = DPNI_IRQ_INDEX;
 	u32 status = 0, clear = 0;
 	struct device *dev = (struct device *)arg;
 	struct fsl_mc_device *dpni_dev = to_fsl_mc_device(dev);
@@ -2575,7 +2580,7 @@ static irqreturn_t dpni_irq0_handler_thread(int irq_num, void *arg)
 	int err;
 
 	err = dpni_get_irq_status(dpni_dev->mc_io, 0, dpni_dev->mc_handle,
-				  irq_index, &status);
+				  DPNI_IRQ_INDEX, &status);
 	if (unlikely(err)) {
 		netdev_err(net_dev, "Can't get irq status (err %d)", err);
 		clear = 0xffffffff;
@@ -2589,7 +2594,7 @@ static irqreturn_t dpni_irq0_handler_thread(int irq_num, void *arg)
 
 out:
 	dpni_clear_irq_status(dpni_dev->mc_io, 0, dpni_dev->mc_handle,
-			      irq_index, clear);
+			      DPNI_IRQ_INDEX, clear);
 	return IRQ_HANDLED;
 }
 
@@ -2597,8 +2602,6 @@ static int setup_irqs(struct fsl_mc_device *ls_dev)
 {
 	int err = 0;
 	struct fsl_mc_device_irq *irq;
-	u8 irq_index = DPNI_IRQ_INDEX;
-	u32 mask = DPNI_IRQ_EVENT_LINK_CHANGED;
 
 	err = fsl_mc_allocate_irqs(ls_dev);
 	if (err) {
@@ -2618,14 +2621,14 @@ static int setup_irqs(struct fsl_mc_device *ls_dev)
 	}
 
 	err = dpni_set_irq_mask(ls_dev->mc_io, 0, ls_dev->mc_handle,
-				irq_index, mask);
+				DPNI_IRQ_INDEX, DPNI_IRQ_EVENT_LINK_CHANGED);
 	if (err < 0) {
 		dev_err(&ls_dev->dev, "dpni_set_irq_mask(): %d", err);
 		goto free_irq;
 	}
 
 	err = dpni_set_irq_enable(ls_dev->mc_io, 0, ls_dev->mc_handle,
-				  irq_index, 1);
+				  DPNI_IRQ_INDEX, 1);
 	if (err < 0) {
 		dev_err(&ls_dev->dev, "dpni_set_irq_enable(): %d", err);
 		goto free_irq;
@@ -2815,10 +2818,10 @@ void dpaa2_eth_sysfs_remove(struct device *dev)
 
 static int dpaa2_eth_probe(struct fsl_mc_device *dpni_dev)
 {
-	struct device			*dev;
-	struct net_device		*net_dev = NULL;
-	struct dpaa2_eth_priv		*priv = NULL;
-	int				err = 0;
+	struct device *dev;
+	struct net_device *net_dev = NULL;
+	struct dpaa2_eth_priv *priv = NULL;
+	int err = 0;
 
 	dev = &dpni_dev->dev;
 
@@ -2942,8 +2945,7 @@ err_bind:
 err_dpbp_setup:
 	free_dpio(priv);
 err_dpio_setup:
-	kfree(priv->cls_rule);
-	dpni_close(priv->mc_io, 0, priv->mc_token);
+	free_dpni(priv);
 err_dpni_setup:
 	fsl_mc_portal_free(priv->mc_io);
 err_portal_alloc:
@@ -2955,8 +2957,8 @@ err_portal_alloc:
 
 static int dpaa2_eth_remove(struct fsl_mc_device *ls_dev)
 {
-	struct device		*dev;
-	struct net_device	*net_dev;
+	struct device *dev;
+	struct net_device *net_dev;
 	struct dpaa2_eth_priv *priv;
 
 	dev = &ls_dev->dev;
@@ -2969,24 +2971,22 @@ static int dpaa2_eth_remove(struct fsl_mc_device *ls_dev)
 	unregister_netdev(net_dev);
 	dev_info(net_dev->dev.parent, "Removed interface %s\n", net_dev->name);
 
-	free_dpio(priv);
+	if (priv->do_link_poll)
+		kthread_stop(priv->poll_thread);
+	else
+		fsl_mc_free_irqs(ls_dev);
+
 	free_rings(priv);
+	free_percpu(priv->percpu_stats);
+	free_percpu(priv->percpu_extras);
+
 	del_ch_napi(priv);
 	free_dpbp(priv);
+	free_dpio(priv);
 	free_dpni(priv);
 
 	fsl_mc_portal_free(priv->mc_io);
 
-	free_percpu(priv->percpu_stats);
-	free_percpu(priv->percpu_extras);
-
-	if (priv->do_link_poll)
-		kthread_stop(priv->poll_thread);
-	else
-		fsl_mc_free_irqs(ls_dev);
-
-	kfree(priv->cls_rule);
-
 	dev_set_drvdata(dev, NULL);
 	free_netdev(net_dev);
 
@@ -3005,11 +3005,11 @@ static const struct fsl_mc_device_match_id dpaa2_eth_match_id_table[] = {
 
 static struct fsl_mc_driver dpaa2_eth_driver = {
 	.driver = {
-		.name		= KBUILD_MODNAME,
-		.owner		= THIS_MODULE,
+		.name = KBUILD_MODNAME,
+		.owner = THIS_MODULE,
 	},
-	.probe		= dpaa2_eth_probe,
-	.remove		= dpaa2_eth_remove,
+	.probe = dpaa2_eth_probe,
+	.remove = dpaa2_eth_remove,
 	.match_id_table = dpaa2_eth_match_id_table
 };
 
diff --git a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h
index ca72c93..c174551 100644
--- a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h
+++ b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h
@@ -178,6 +178,12 @@ struct dpaa2_faead {
 #define DPAA2_FAEAD_UPDV		0x00001000
 #define DPAA2_FAEAD_UPD			0x00000010
 
+/* Frame annotation status word is located in the first 8 bytes
+ * of the buffer's hardware annotation area
+ */
+#define DPAA2_FAS_OFFSET		0
+#define DPAA2_FAS_SIZE			(sizeof(struct dpaa2_fas))
+
 /* Error and status bits in the frame annotation status word */
 /* Debug frame, otherwise supposed to be discarded */
 #define DPAA2_FAS_DISC			0x80000000
@@ -232,6 +238,13 @@ struct dpaa2_faead {
 /* Time in milliseconds between link state updates */
 #define DPAA2_ETH_LINK_STATE_REFRESH	1000
 
+/* Number of times to retry a frame enqueue before giving up.
+ * Value determined empirically, in order to minimize the number
+ * of frames dropped on Tx
+ */
+#define DPAA2_ETH_ENQUEUE_RETRIES      10
+
+
 /* Driver statistics, other than those in struct rtnl_link_stats64.
  * These are usually collected per-CPU and aggregated by ethtool.
  */
@@ -405,20 +418,11 @@ struct dpaa2_eth_priv {
 
 extern const struct ethtool_ops dpaa2_ethtool_ops;
 
-static int dpaa2_eth_queue_count(struct dpaa2_eth_priv *priv)
+static inline int dpaa2_eth_queue_count(struct dpaa2_eth_priv *priv)
 {
 	return priv->dpni_attrs.num_queues;
 }
 
-static inline int dpaa2_eth_max_channels(struct dpaa2_eth_priv *priv)
-{
-	/* Ideally, we want a number of channels large enough
-	 * to accommodate both the Rx distribution size
-	 * and the max number of Tx confirmation queues
-	 */
-	return dpaa2_eth_queue_count(priv);
-}
-
 void check_cls_support(struct dpaa2_eth_priv *priv);
 
 #endif	/* __DPAA2_H */
-- 
2.9.3

