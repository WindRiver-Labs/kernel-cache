From ebec99ad06c456a7831f2a68b4a8100d2231d97e Mon Sep 17 00:00:00 2001
From: Ioana Radulescu <ruxandra.radulescu@nxp.com>
Date: Mon, 7 Mar 2016 19:48:01 +0200
Subject: [PATCH 271/388] staging: fsl-dpaa2/eth: Updates to flow steering
 support

When flow steering was initially added MC did not support any
masking. Given this and the fact that both hashing and FS must
share a single key, the code was severely limited.

With the addition of masking, flow steering support in ethtool
was somewhat improved. We now take into account the flow type
and also support more key options.

MC currently supports a maximum number of 10 fields in a key.
If and when this limitation is addressed, more flow steering
options can be implemented.

After adding latest FS support code, function prep_cls_rule()
grows to an unmanageable size. So split in separate function for
each user option.

Signed-off-by: Ioana Radulescu <ruxandra.radulescu@nxp.com>
[Original patch taken from SDK-V2.0-1703]
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c     |  12 +
 drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h     |   4 +
 drivers/staging/fsl-dpaa2/ethernet/dpaa2-ethtool.c | 311 ++++++++++++++-------
 3 files changed, 219 insertions(+), 108 deletions(-)

diff --git a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c
index ea5f897..2051f64 100644
--- a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c
+++ b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c
@@ -2155,6 +2155,18 @@ static struct dpaa2_eth_hash_fields default_hash_fields[] = {
 		.cls_field = NH_FLD_ETH_DA,
 		.size = 6,
 	}, {
+		.cls_prot = NET_PROT_ETH,
+		.cls_field = NH_FLD_ETH_SA,
+		.size = 6,
+	}, {
+		/* This is the last ethertype field parsed:
+		 * depending on frame format, it can be the MAC ethertype
+		 * or the VLAN etype.
+		 */
+		.cls_prot = NET_PROT_ETH,
+		.cls_field = NH_FLD_ETH_TYPE,
+		.size = 2,
+	}, {
 		/* VLAN header */
 		.rxnfc_field = RXH_VLAN,
 		.cls_prot = NET_PROT_VLAN,
diff --git a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h
index ad49d92..bdcdbd6 100644
--- a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h
+++ b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h
@@ -289,6 +289,7 @@ struct dpaa2_eth_hash_fields {
 	u64 rxnfc_field;
 	enum net_prot cls_prot;
 	int cls_field;
+	int offset;
 	int size;
 };
 
@@ -360,6 +361,9 @@ struct dpaa2_eth_priv {
 #define dpaa2_eth_fs_enabled(priv)	\
 	((priv)->dpni_attrs.options & DPNI_OPT_DIST_FS)
 
+#define dpaa2_eth_fs_mask_enabled(priv)	\
+	((priv)->dpni_attrs.options & DPNI_OPT_FS_MASK_SUPPORT)
+
 #define DPAA2_CLASSIFIER_ENTRY_COUNT 16
 
 /* Required by struct dpni_attr::ext_cfg_iova */
diff --git a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-ethtool.c b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-ethtool.c
index 7e3a159..1d792cd 100644
--- a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-ethtool.c
+++ b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-ethtool.c
@@ -274,12 +274,13 @@ static void dpaa2_eth_get_ethtool_stats(struct net_device *net_dev,
 #endif
 }
 
-static int cls_key_off(struct dpaa2_eth_priv *priv, u64 flag)
+static int cls_key_off(struct dpaa2_eth_priv *priv, int prot, int field)
 {
 	int i, off = 0;
 
 	for (i = 0; i < priv->num_hash_fields; i++) {
-		if (priv->hash_fields[i].rxnfc_field & flag)
+		if (priv->hash_fields[i].cls_prot == prot &&
+		    priv->hash_fields[i].cls_field == field)
 			return off;
 		off += priv->hash_fields[i].size;
 	}
@@ -316,15 +317,182 @@ void check_cls_support(struct dpaa2_eth_priv *priv)
 		}
 	}
 
-	if (dpaa2_eth_fs_enabled(priv) && !dpaa2_eth_hash_enabled(priv)) {
-		dev_dbg(dev, "DPNI_OPT_DIST_HASH option missing. Flow steering is disabled\n");
-		goto disable_cls;
+	if (dpaa2_eth_fs_enabled(priv)) {
+		if (!dpaa2_eth_hash_enabled(priv)) {
+			dev_dbg(dev, "DPNI_OPT_DIST_HASH option missing. Steering is disabled\n");
+			goto disable_cls;
+		}
+		if (!dpaa2_eth_fs_mask_enabled(priv)) {
+			dev_dbg(dev, "Key masks not supported. Steering is disabled\n");
+			goto disable_fs;
+		}
 	}
 
 	return;
 
 disable_cls:
-	priv->dpni_attrs.options &= ~(DPNI_OPT_DIST_FS | DPNI_OPT_DIST_HASH);
+	priv->dpni_attrs.options &= ~DPNI_OPT_DIST_HASH;
+disable_fs:
+	priv->dpni_attrs.options &= ~(DPNI_OPT_DIST_FS |
+				      DPNI_OPT_FS_MASK_SUPPORT);
+}
+
+static int prep_l4_rule(struct dpaa2_eth_priv *priv,
+			struct ethtool_tcpip4_spec *l4_value,
+			struct ethtool_tcpip4_spec *l4_mask,
+			void *key, void *mask, u8 l4_proto)
+{
+	int offset;
+
+	if (l4_mask->tos) {
+		netdev_err(priv->net_dev, "ToS is not supported for IPv4 L4\n");
+		return -EOPNOTSUPP;
+	}
+
+	if (l4_mask->ip4src) {
+		offset = cls_key_off(priv, NET_PROT_IP, NH_FLD_IP_SRC);
+		*(u32 *)(key + offset) = l4_value->ip4src;
+		*(u32 *)(mask + offset) = l4_mask->ip4src;
+	}
+
+	if (l4_mask->ip4dst) {
+		offset = cls_key_off(priv, NET_PROT_IP, NH_FLD_IP_DST);
+		*(u32 *)(key + offset) = l4_value->ip4dst;
+		*(u32 *)(mask + offset) = l4_mask->ip4dst;
+	}
+
+	if (l4_mask->psrc) {
+		offset = cls_key_off(priv, NET_PROT_UDP, NH_FLD_UDP_PORT_SRC);
+		*(u32 *)(key + offset) = l4_value->psrc;
+		*(u32 *)(mask + offset) = l4_mask->psrc;
+	}
+
+	if (l4_mask->pdst) {
+		offset = cls_key_off(priv, NET_PROT_UDP, NH_FLD_UDP_PORT_DST);
+		*(u32 *)(key + offset) = l4_value->pdst;
+		*(u32 *)(mask + offset) = l4_mask->pdst;
+	}
+
+	/* Only apply the rule for the user-specified L4 protocol
+	 * and if ethertype matches IPv4
+	 */
+	offset = cls_key_off(priv, NET_PROT_ETH, NH_FLD_ETH_TYPE);
+	*(u16 *)(key + offset) = htons(ETH_P_IP);
+	*(u16 *)(mask + offset) = 0xFFFF;
+
+	offset = cls_key_off(priv, NET_PROT_IP, NH_FLD_IP_PROTO);
+	*(u8 *)(key + offset) = l4_proto;
+	*(u8 *)(mask + offset) = 0xFF;
+
+	/* TODO: check IP version */
+
+	return 0;
+}
+
+static int prep_eth_rule(struct dpaa2_eth_priv *priv,
+			 struct ethhdr *eth_value, struct ethhdr *eth_mask,
+			 void *key, void *mask)
+{
+	int offset;
+
+	if (eth_mask->h_proto) {
+		netdev_err(priv->net_dev, "Ethertype is not supported!\n");
+		return -EOPNOTSUPP;
+	}
+
+	if (!is_zero_ether_addr(eth_mask->h_source)) {
+		offset = cls_key_off(priv, NET_PROT_ETH, NH_FLD_ETH_SA);
+		ether_addr_copy(key + offset, eth_value->h_source);
+		ether_addr_copy(mask + offset, eth_mask->h_source);
+	}
+
+	if (!is_zero_ether_addr(eth_mask->h_dest)) {
+		offset = cls_key_off(priv, NET_PROT_ETH, NH_FLD_ETH_DA);
+		ether_addr_copy(key + offset, eth_value->h_dest);
+		ether_addr_copy(mask + offset, eth_mask->h_dest);
+	}
+
+	return 0;
+}
+
+static int prep_user_ip_rule(struct dpaa2_eth_priv *priv,
+			     struct ethtool_usrip4_spec *uip_value,
+			     struct ethtool_usrip4_spec *uip_mask,
+			     void *key, void *mask)
+{
+	int offset;
+
+	if (uip_mask->tos)
+		return -EOPNOTSUPP;
+
+	if (uip_mask->ip4src) {
+		offset = cls_key_off(priv, NET_PROT_IP, NH_FLD_IP_SRC);
+		*(u32 *)(key + offset) = uip_value->ip4src;
+		*(u32 *)(mask + offset) = uip_mask->ip4src;
+	}
+
+	if (uip_mask->ip4dst) {
+		offset = cls_key_off(priv, NET_PROT_IP, NH_FLD_IP_DST);
+		*(u32 *)(key + offset) = uip_value->ip4dst;
+		*(u32 *)(mask + offset) = uip_mask->ip4dst;
+	}
+
+	if (uip_mask->proto) {
+		offset = cls_key_off(priv, NET_PROT_IP, NH_FLD_IP_PROTO);
+		*(u32 *)(key + offset) = uip_value->proto;
+		*(u32 *)(mask + offset) = uip_mask->proto;
+	}
+	if (uip_mask->l4_4_bytes) {
+		offset = cls_key_off(priv, NET_PROT_UDP, NH_FLD_UDP_PORT_SRC);
+		*(u16 *)(key + offset) = uip_value->l4_4_bytes << 16;
+		*(u16 *)(mask + offset) = uip_mask->l4_4_bytes << 16;
+
+		offset = cls_key_off(priv, NET_PROT_UDP, NH_FLD_UDP_PORT_DST);
+		*(u16 *)(key + offset) = uip_value->l4_4_bytes & 0xFFFF;
+		*(u16 *)(mask + offset) = uip_mask->l4_4_bytes & 0xFFFF;
+	}
+
+	/* Ethertype must be IP */
+	offset = cls_key_off(priv, NET_PROT_ETH, NH_FLD_ETH_TYPE);
+	*(u16 *)(key + offset) = htons(ETH_P_IP);
+	*(u16 *)(mask + offset) = 0xFFFF;
+
+	return 0;
+}
+
+static int prep_ext_rule(struct dpaa2_eth_priv *priv,
+			 struct ethtool_flow_ext *ext_value,
+			 struct ethtool_flow_ext *ext_mask,
+			 void *key, void *mask)
+{
+	int offset;
+
+	if (ext_mask->vlan_etype)
+		return -EOPNOTSUPP;
+
+	if (ext_mask->vlan_tci) {
+		offset = cls_key_off(priv, NET_PROT_VLAN, NH_FLD_VLAN_TCI);
+		*(u16 *)(key + offset) = ext_value->vlan_tci;
+		*(u16 *)(mask + offset) = ext_mask->vlan_tci;
+	}
+
+	return 0;
+}
+
+static int prep_mac_ext_rule(struct dpaa2_eth_priv *priv,
+			     struct ethtool_flow_ext *ext_value,
+			     struct ethtool_flow_ext *ext_mask,
+			     void *key, void *mask)
+{
+	int offset;
+
+	if (!is_zero_ether_addr(ext_mask->h_dest)) {
+		offset = cls_key_off(priv, NET_PROT_ETH, NH_FLD_ETH_DA);
+		ether_addr_copy(key + offset, ext_value->h_dest);
+		ether_addr_copy(mask + offset, ext_mask->h_dest);
+	}
+
+	return 0;
 }
 
 static int prep_cls_rule(struct net_device *net_dev,
@@ -332,113 +500,55 @@ static int prep_cls_rule(struct net_device *net_dev,
 			 void *key)
 {
 	struct dpaa2_eth_priv *priv = netdev_priv(net_dev);
-	struct ethtool_tcpip4_spec *l4ip4_h, *l4ip4_m;
-	struct ethhdr *eth_h, *eth_m;
-	struct ethtool_flow_ext *ext_h, *ext_m;
 	const u8 key_size = cls_key_size(priv);
 	void *msk = key + key_size;
+	int err;
 
 	memset(key, 0, key_size * 2);
 
-	/* This code is a major mess, it has to be cleaned up after the
-	 * classification mask issue is fixed and key format will be made static
-	 */
-
 	switch (fs->flow_type & 0xff) {
 	case TCP_V4_FLOW:
-		l4ip4_h = &fs->h_u.tcp_ip4_spec;
-		l4ip4_m = &fs->m_u.tcp_ip4_spec;
-		/* TODO: ethertype to match IPv4 and protocol to match TCP */
-		goto l4ip4;
-
+		err = prep_l4_rule(priv, &fs->h_u.tcp_ip4_spec,
+				   &fs->m_u.tcp_ip4_spec, key, msk,
+				   IPPROTO_TCP);
+		break;
 	case UDP_V4_FLOW:
-		l4ip4_h = &fs->h_u.udp_ip4_spec;
-		l4ip4_m = &fs->m_u.udp_ip4_spec;
-		goto l4ip4;
-
+		err = prep_l4_rule(priv, &fs->h_u.udp_ip4_spec,
+				   &fs->m_u.udp_ip4_spec, key, msk,
+				   IPPROTO_UDP);
+		break;
 	case SCTP_V4_FLOW:
-		l4ip4_h = &fs->h_u.sctp_ip4_spec;
-		l4ip4_m = &fs->m_u.sctp_ip4_spec;
-
-l4ip4:
-		if (l4ip4_m->tos) {
-			netdev_err(net_dev,
-				   "ToS is not supported for IPv4 L4\n");
-			return -EOPNOTSUPP;
-		}
-
-		if (l4ip4_m->ip4src) {
-			*(u32 *)(key + cls_key_off(priv, RXH_IP_SRC))
-				= l4ip4_h->ip4src;
-			*(u32 *)(msk + cls_key_off(priv, RXH_IP_SRC))
-				= l4ip4_m->ip4src;
-		}
-
-		if (l4ip4_m->ip4dst) {
-			*(u32 *)(key + cls_key_off(priv, RXH_IP_DST))
-				= l4ip4_h->ip4dst;
-			*(u32 *)(msk + cls_key_off(priv, RXH_IP_DST))
-				= l4ip4_m->ip4dst;
-		}
-
-		if (l4ip4_m->psrc) {
-			*(u32 *)(key + cls_key_off(priv, RXH_L4_B_0_1))
-				= l4ip4_h->psrc;
-			*(u32 *)(msk + cls_key_off(priv, RXH_L4_B_0_1))
-				= l4ip4_m->psrc;
-		}
-
-		if (l4ip4_m->pdst) {
-			*(u32 *)(key + cls_key_off(priv, RXH_L4_B_2_3))
-				= l4ip4_h->pdst;
-			*(u32 *)(msk + cls_key_off(priv, RXH_L4_B_2_3))
-				= l4ip4_m->pdst;
-		}
+		err = prep_l4_rule(priv, &fs->h_u.sctp_ip4_spec,
+				   &fs->m_u.sctp_ip4_spec, key, msk,
+				   IPPROTO_SCTP);
 		break;
-
 	case ETHER_FLOW:
-		eth_h = &fs->h_u.ether_spec;
-		eth_m = &fs->m_u.ether_spec;
-
-		if (eth_m->h_proto) {
-			netdev_err(net_dev, "Ethertype is not supported!\n");
-			return -EOPNOTSUPP;
-		}
-
-		if (!is_zero_ether_addr(eth_m->h_source)) {
-			netdev_err(net_dev, "ETH SRC is not supported!\n");
-			return -EOPNOTSUPP;
-		}
-
-		if (!is_zero_ether_addr(eth_m->h_dest)) {
-			ether_addr_copy(key + cls_key_off(priv, RXH_L2DA),
-					eth_h->h_dest);
-			ether_addr_copy(msk + cls_key_off(priv, RXH_L2DA),
-					eth_m->h_dest);
-		}
+		err = prep_eth_rule(priv, &fs->h_u.ether_spec,
+				    &fs->m_u.ether_spec, key, msk);
+		break;
+	case IP_USER_FLOW:
+		err = prep_user_ip_rule(priv, &fs->h_u.usr_ip4_spec,
+					&fs->m_u.usr_ip4_spec, key, msk);
 		break;
-
 	default:
-		/* TODO: IP user flow, AH, ESP */
+		/* TODO: AH, ESP */
 		return -EOPNOTSUPP;
 	}
+	if (err)
+		return err;
 
 	if (fs->flow_type & FLOW_EXT) {
-		/* TODO: ETH data, VLAN ethertype, VLAN TCI .. */
-		return -EOPNOTSUPP;
+		err = prep_ext_rule(priv, &fs->h_ext, &fs->m_ext, key, msk);
+		if (err)
+			return err;
 	}
 
 	if (fs->flow_type & FLOW_MAC_EXT) {
-		ext_h = &fs->h_ext;
-		ext_m = &fs->m_ext;
-
-		if (!is_zero_ether_addr(ext_m->h_dest)) {
-			ether_addr_copy(key + cls_key_off(priv, RXH_L2DA),
-					ext_h->h_dest);
-			ether_addr_copy(msk + cls_key_off(priv, RXH_L2DA),
-					ext_m->h_dest);
-		}
+		err = prep_mac_ext_rule(priv, &fs->h_ext, &fs->m_ext, key, msk);
+		if (err)
+			return err;
 	}
+
 	return 0;
 }
 
@@ -482,21 +592,6 @@ static int do_cls(struct net_device *net_dev,
 
 	rule_cfg.mask_iova = rule_cfg.key_iova + rule_cfg.key_size;
 
-	if (!(priv->dpni_attrs.options & DPNI_OPT_FS_MASK_SUPPORT)) {
-		int i;
-		u8 *mask = dma_mem + rule_cfg.key_size;
-
-		/* check that nothing is masked out, otherwise it won't work */
-		for (i = 0; i < rule_cfg.key_size; i++) {
-			if (mask[i] == 0xff)
-				continue;
-			netdev_err(net_dev, "dev does not support masking!\n");
-			err = -EOPNOTSUPP;
-			goto err_free_mem;
-		}
-		rule_cfg.mask_iova = 0;
-	}
-
 	/* No way to control rule order in firmware */
 	if (add)
 		err = dpni_add_fs_entry(priv->mc_io, 0, priv->mc_token, 0,
@@ -508,7 +603,7 @@ static int do_cls(struct net_device *net_dev,
 	dma_unmap_single(dev, rule_cfg.key_iova,
 			 rule_cfg.key_size * 2, DMA_TO_DEVICE);
 	if (err) {
-		netdev_err(net_dev, "dpaa2_add_cls() error %d\n", err);
+		netdev_err(net_dev, "dpaa2_add/remove_cls() error %d\n", err);
 		goto err_free_mem;
 	}
 
-- 
2.9.3

