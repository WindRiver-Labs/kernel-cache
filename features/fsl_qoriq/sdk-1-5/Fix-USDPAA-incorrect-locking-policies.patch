From be07716a452570f873b740d00b9d91ceff929020 Mon Sep 17 00:00:00 2001
From: Ying Xue <ying.xue@windriver.com>
Date: Tue, 23 Jun 2015 16:02:46 +0800
Subject: [PATCH] Fix USDPAA incorrect locking policies

When a new portal element is inserted into ctx->portals list in
ioctl_portal_map(), the ctx->portals list is protected by mem_lock,
however, when a portal is deleted from the list in usdpaa_release(),
the list is not protected by any lock at all. Meanwhile, when the
list is iterated in usdpaa_get_portal_config(), it's protected by
a different lock - ctx->lock. This inconsistent or incorrect locking
policies often lead to serious bugs, such as kernel panic.

So the locking policies associated with USDPAA are uniformly adjusted
as follows:
- ctx->portals, which is protected by mem_lock
- ctx->maps, which is protected by mem_lock
- ctx->resources[], which is protected by ctx->lock
- mem_list, which is protected by mem_lock

By the way, we also found other locking issues, for example:
- While accessing ctx->resources[], the resources[] is not protected
  by ctx->lock at all in several places.
- While iterating mem_list in ioctl_dma_stats(), the list is not
  protected too.

Signed-off-by: Ying Xue <ying.xue@windriver.com>
---
 drivers/staging/fsl_qbman/fsl_usdpaa.c |   25 ++++++++++++++++++++-----
 1 files changed, 20 insertions(+), 5 deletions(-)

diff --git a/drivers/staging/fsl_qbman/fsl_usdpaa.c b/drivers/staging/fsl_qbman/fsl_usdpaa.c
index 35171e9..5797d85 100644
--- a/drivers/staging/fsl_qbman/fsl_usdpaa.c
+++ b/drivers/staging/fsl_qbman/fsl_usdpaa.c
@@ -426,22 +426,29 @@ static bool check_channel_device(void *_ctx, u32 channel)
 	struct active_resource *res;
 
 	/* See if the FQ is destined for one of the portals we're cleaning up */
+	spin_lock(&mem_lock);
 	list_for_each_entry_safe(portal, tmpportal, &ctx->portals, list) {
 		if (portal->user.type == usdpaa_portal_qman) {
 			if (portal->qportal->public_cfg.channel == channel) {
 				/* This FQs destination is a portal
 				   we're cleaning, send a retire */
+				spin_unlock(&mem_lock);
 				return true;
 			}
 		}
 	}
+	spin_unlock(&mem_lock);
 
 	/* Check the pool channels that will be released as well */
+	spin_lock(&ctx->lock);
 	list_for_each_entry(res, &ctx->resources[usdpaa_id_qpool], list) {
 		if ((res->id >= channel) &&
-		    ((res->id + res->num - 1) <= channel))
+		    ((res->id + res->num - 1) <= channel)) {
+			spin_unlock(&ctx->lock);
 			return true;
+		}
 	}
+	spin_unlock(&ctx->lock);
 	return false;
 }
 
@@ -477,6 +484,7 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 	   in the kernel
 	*/
 
+	spin_lock(&mem_lock);
 	list_for_each_entry_safe(portal, tmpportal, &ctx->portals, list) {
 		/* Try to recover any portals that weren't shut down */
 		if (portal->user.type == usdpaa_portal_qman) {
@@ -501,6 +509,8 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 				bm_cleanup_portal = &portal->bman_portal_low;
 		}
 	}
+	spin_unlock(&mem_lock);
+
 	/* If no portal was found, allocate one for cleanup */
 	if (!qm_cleanup_portal) {
 		qm_alloced_portal = qm_get_unused_portal();
@@ -534,6 +544,7 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 
 	while (backend->id_type != usdpaa_id_max) {
 		int leaks = 0;
+		spin_lock(&ctx->lock);
 		list_for_each_entry(res, &ctx->resources[backend->id_type],
 				    list) {
 			if (backend->id_type == usdpaa_id_fqid) {
@@ -548,6 +559,7 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 			leaks += res->num;
 			backend->release(res->id, res->num);
 		}
+		spin_unlock(&ctx->lock);
 		if (leaks)
 			pr_crit("USDPAA process leaking %d %s%s\n", leaks,
 				backend->acronym, (leaks > 1) ? "s" : "");
@@ -574,7 +586,6 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 		list_del(&map->list);
 		kfree(map);
 	}
-	spin_unlock(&mem_lock);
 
 	/* Return portals */
 	list_for_each_entry_safe(portal, tmpportal, &ctx->portals, list) {
@@ -591,6 +602,8 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 		list_del(&portal->list);
 		kfree(portal);
 	}
+	spin_unlock(&mem_lock);
+
 	if (qm_alloced_portal) {
 		qm_put_unused_portal(qm_alloced_portal);
 		kfree(qm_cleanup_portal);
@@ -1066,9 +1079,11 @@ static long ioctl_dma_stats(struct ctx *ctx, void __user *arg)
 	result.free_bytes = 0;
 	result.total_bytes = phys_size;
 
+	spin_lock(&mem_lock);
 	list_for_each_entry(frag, &mem_list, list) {
 		result.free_bytes += frag->len;
 	}
+	spin_unlock(&mem_lock);
 
 	return copy_to_user(arg, &result, sizeof(result)); }
 
@@ -1421,7 +1436,7 @@ int usdpaa_get_portal_config(struct file *filp, void *cinh,
 	if (filp->f_op->open != usdpaa_open)
 		return -ENODEV;
 	context = filp->private_data;
-	spin_lock(&context->lock);
+	spin_lock(&mem_lock);
 	list_for_each_entry(portal, &context->portals, list) {
 		if (portal->user.type == ptype &&
 		    portal->user.addr.cinh == cinh) {
@@ -1432,11 +1447,11 @@ int usdpaa_get_portal_config(struct file *filp, void *cinh,
 				*irq = portal->bportal->public_cfg.irq;
 				*iir_reg = portal->bportal->addr_virt[1] + BM_REG_IIR;
 			}
-			spin_unlock(&context->lock);
+			spin_unlock(&mem_lock);
 			return 0;
 		}
 	}
-	spin_unlock(&context->lock);
+	spin_unlock(&mem_lock);
 	return -EINVAL;
 }
 
-- 
1.7.5.4

