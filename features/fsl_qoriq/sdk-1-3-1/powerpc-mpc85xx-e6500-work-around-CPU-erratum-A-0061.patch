From 18570d9ec82e098b6f9092ab283ab6d3aef71d5e Mon Sep 17 00:00:00 2001
From: Scott Wood <scottwood@freescale.com>
Date: Wed, 5 Dec 2012 07:59:18 +0000
Subject: [PATCH 219/227] powerpc/mpc85xx/e6500: work around CPU erratum
 A-006198

Erratum A-006198 says that a CPU can hang if a certain race
occurs between threads, involving CFX instructions (which includes
mtmsr).  The workaround is to avoid using mtmsr to disable
MSR[EE/CE/DE].  To accomplish this, we use rfmci instead,
with some gymnastics to be resistant to races that overwrite
MCSRR0/MCSRR1.

Signed-off-by: Scott Wood <scottwood@freescale.com>
Signed-off-by: Andy Fleming <afleming@freescale.com>
[Kevin: Original patch taken from fsl sdk 1.3.1
QorIQ-SDK-V1.3.1-SOURCE-20121220-yocto.iso. Some parts don't
apply due to the context changes.]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 arch/powerpc/include/asm/hw_irq.h      |   34 +++++++++++++++++++++++++
 arch/powerpc/include/asm/ppc_asm.h     |   43 ++++++++++++++++++++++++++++++++
 arch/powerpc/kernel/entry_64.S         |    4 +--
 arch/powerpc/kernel/exceptions-64e.S   |    6 +++--
 arch/powerpc/kernel/idle_book3e.S      |    2 +-
 arch/powerpc/kernel/misc_64.S          |    3 +++
 arch/powerpc/mm/tlb_nohash_low.S       |   24 +++++++++---------
 arch/powerpc/platforms/Kconfig.cputype |    7 ++++++
 8 files changed, 106 insertions(+), 17 deletions(-)

diff --git a/arch/powerpc/include/asm/hw_irq.h b/arch/powerpc/include/asm/hw_irq.h
index 0554ab0..3bf2f7d 100644
--- a/arch/powerpc/include/asm/hw_irq.h
+++ b/arch/powerpc/include/asm/hw_irq.h
@@ -87,7 +87,27 @@ static inline bool arch_irqs_disabled(void)
 
 #ifdef CONFIG_PPC_BOOK3E
 #define __hard_irq_enable()	asm volatile("wrteei 1" : : : "memory")
+
+#ifdef CONFIG_FSL_ERRATUM_A_006198
+static inline void __hard_irq_disable(void)
+{
+	unsigned long tmp;
+
+	asm volatile("ld %0, 1f@got(2);"
+		     "mtlr %0;"
+		     "ld %0, .fsl_erratum_a006198_return@got(2);"
+		     "mtspr %1, %0;"
+		     "mfmsr %0;"
+		     "rlwinm %0, %0, 0, ~%3;"
+		     "mtspr %2, %0;"
+		     "rfmci;"
+		     "1: mtmsr %0" : "=&r" (tmp) :
+		     "i" (SPRN_MCSRR0), "i" (SPRN_MCSRR1),
+		     "i" (MSR_EE) : "memory", "lr");
+}
+#else
 #define __hard_irq_disable()	asm volatile("wrteei 0" : : : "memory")
+#endif
 #else
 #define __hard_irq_enable()	__mtmsrd(local_paca->kernel_msr | MSR_EE, 1)
 #define __hard_irq_disable()	__mtmsrd(local_paca->kernel_msr, 1)
@@ -139,7 +159,21 @@ static inline unsigned long arch_local_save_flags(void)
 static inline void arch_local_irq_restore(unsigned long flags)
 {
 #if defined(CONFIG_BOOKE)
+#ifdef CONFIG_FSL_ERRATUM_A_006198
+	unsigned long tmp;
+
+	asm volatile("ld %0, 1f@got(2);"
+		     "mtlr %0;"
+		     "ld %0, .fsl_erratum_a006198_return@got(2);"
+		     "mtspr %1, %3;"
+		     "mtspr %2, %0;"
+		     "rfmci;"
+		     "1: mtmsr %3" : "=&r" (tmp) :
+		     "i" (SPRN_MCSRR1), "i" (SPRN_MCSRR0),
+		     "r" (flags) : "memory", "lr");
+#else
 	asm volatile("wrtee %0" : : "r" (flags) : "memory");
+#endif
 #else
 	mtmsr(flags);
 #endif
diff --git a/arch/powerpc/include/asm/ppc_asm.h b/arch/powerpc/include/asm/ppc_asm.h
index 50f73aa..4a0fc4b 100644
--- a/arch/powerpc/include/asm/ppc_asm.h
+++ b/arch/powerpc/include/asm/ppc_asm.h
@@ -696,6 +696,49 @@ END_FTR_SECTION_IFCLR(CPU_FTR_601)
 #define N_SLINE	68
 #define N_SO	100
 
+.macro fsl_erratum_a006198_mtmsr newmsr scratch1 scratch2
+#ifdef CONFIG_FSL_ERRATUM_A_006198
+	mflr	\scratch2
+	LOAD_REG_IMMEDIATE(\scratch1, 237f)
+	mtlr	\scratch1
+	LOAD_REG_IMMEDIATE(\scratch1, .fsl_erratum_a006198_return)
+	mtspr	SPRN_MCSRR1, \newmsr
+	mtspr	SPRN_MCSRR0, \scratch1
+	rfmci
+237:	mtmsr	\newmsr
+	mtlr	\scratch2
+#else
+	mtmsr	\newmsr
+#endif
+.endm
+
+.macro fsl_erratum_a006198_wrteei0 scratch1 scratch2
+#ifdef CONFIG_FSL_ERRATUM_A_006198
+	mflr	\scratch2
+	LOAD_REG_IMMEDIATE(\scratch1, 237f)
+	mtlr	\scratch1
+	LOAD_REG_IMMEDIATE(\scratch1, .fsl_erratum_a006198_return)
+	mtspr	SPRN_MCSRR0, \scratch1
+	mfmsr	\scratch1
+	rlwinm	\scratch1, \scratch1, 0, ~MSR_EE
+	mtspr	SPRN_MCSRR1, \scratch1
+	rfmci
+237:	mtmsr	\scratch1
+	mtlr	\scratch2
+#else
+	wrteei	0
+#endif
+.endm
+
+.macro fsl_erratum_a006198_restore_srr scratch
+#ifdef CONFIG_FSL_ERRATUM_A_006198
+	LOAD_REG_IMMEDIATE(\scratch, .fsl_erratum_a006198_return)
+	mtspr	SPRN_MCSRR0, \scratch
+	lis	\scratch, MSR_CM@h
+	mtspr	SPRN_MCSRR1, \scratch
+#endif
+.endm
+
 #endif /*  __ASSEMBLY__ */
 
 #endif /* _ASM_POWERPC_PPC_ASM_H */
diff --git a/arch/powerpc/kernel/entry_64.S b/arch/powerpc/kernel/entry_64.S
index 498917e..ff94be3 100644
--- a/arch/powerpc/kernel/entry_64.S
+++ b/arch/powerpc/kernel/entry_64.S
@@ -198,7 +198,7 @@ syscall_exit:
 	 * and so that we don't get interrupted after loading SRR0/1.
 	 */
 #ifdef CONFIG_PPC_BOOK3E
-	wrteei	0
+	fsl_erratum_a006198_wrteei0 r10 r9
 #else
 	ld	r10,PACAKMSR(r13)
 	mtmsrd	r10,1
@@ -567,7 +567,7 @@ _GLOBAL(ret_from_except_lite)
 	 * from the interrupt.
 	 */
 #ifdef CONFIG_PPC_BOOK3E
-	wrteei	0
+	fsl_erratum_a006198_wrteei0 r10 r9
 #else
 	ld	r10,PACAKMSR(r13) /* Get kernel MSR without EE */
 	mtmsrd	r10,1		  /* Update machine state */
diff --git a/arch/powerpc/kernel/exceptions-64e.S b/arch/powerpc/kernel/exceptions-64e.S
index fe21862..88860ed 100644
--- a/arch/powerpc/kernel/exceptions-64e.S
+++ b/arch/powerpc/kernel/exceptions-64e.S
@@ -709,6 +709,7 @@ masked_interrupt_book3e_full_mask:
 	mtspr	SPRN_SRR1,r10
 1:	ld	r10,PACA_EXGEN+EX_R10(r13);
 	ld	r11,PACA_EXGEN+EX_R11(r13);
+	fsl_erratum_a006198_restore_srr r13
 	mfspr	r13,SPRN_SPRG_GEN_SCRATCH;
 	rfi
 	b	.
@@ -795,7 +796,7 @@ _GLOBAL(exception_return_book3e)
  */
 	.globl fast_exception_return
 fast_exception_return:
-	wrteei	0
+	fsl_erratum_a006198_wrteei0 r0 r10
 1:	mr	r0,r13
 	ld	r10,_MSR(r1)
 	REST_4GPRS(2, r1)
@@ -831,6 +832,7 @@ fast_exception_return:
 	mtspr	SPRN_SRR1,r11
 	ld	r10,PACA_EXGEN+EX_R10(r13)
 	ld	r11,PACA_EXGEN+EX_R11(r13)
+	fsl_erratum_a006198_restore_srr r13
 	mfspr	r13,SPRN_SPRG_GEN_SCRATCH
 	rfi
 
@@ -1402,7 +1404,7 @@ _STATIC(init_thread_book3e)
 	mtspr	SPRN_EPCR,r3
 
 	/* Make sure interrupts are off */
-	wrteei	0
+	fsl_erratum_a006198_wrteei0 r3 r4
 
 	/* disable all timers and clear out status */
 	li	r3,0
diff --git a/arch/powerpc/kernel/idle_book3e.S b/arch/powerpc/kernel/idle_book3e.S
index 4c7cb400..14c2d7b 100644
--- a/arch/powerpc/kernel/idle_book3e.S
+++ b/arch/powerpc/kernel/idle_book3e.S
@@ -26,7 +26,7 @@ _GLOBAL(book3e_idle)
 	std	r0,16(r1)
 
 	/* Hard disable interrupts */
-	wrteei	0
+	fsl_erratum_a006198_wrteei0 r0 r3
 
 	/* Now check if an interrupt came in while we were soft disabled
 	 * since we may otherwise lose it (doorbells etc...).
diff --git a/arch/powerpc/kernel/misc_64.S b/arch/powerpc/kernel/misc_64.S
index e8a77d7..76c2f3e 100644
--- a/arch/powerpc/kernel/misc_64.S
+++ b/arch/powerpc/kernel/misc_64.S
@@ -696,3 +696,6 @@ _GLOBAL(kexec_sequence)
 	li	r5,0
 	blr	/* image->start(physid, image->start, 0); */
 #endif /* CONFIG_KEXEC */
+
+_GLOBAL(fsl_erratum_a006198_return)
+	blr
diff --git a/arch/powerpc/mm/tlb_nohash_low.S b/arch/powerpc/mm/tlb_nohash_low.S
index 4d808ba..3b796b6 100644
--- a/arch/powerpc/mm/tlb_nohash_low.S
+++ b/arch/powerpc/mm/tlb_nohash_low.S
@@ -365,12 +365,12 @@ ALT_MMU_FTR_SECTION_END_IFCLR(MMU_FTR_USE_TLBILX)
 _GLOBAL(_tlbil_pid)
 	slwi	r4,r3,MAS6_SPID_SHIFT
 	mfmsr	r10
-	wrteei	0
+	fsl_erratum_a006198_wrteei0 r0 r7
 	tlb_lock
 	mtspr	SPRN_MAS6,r4
 	PPC_TLBILX_PID(0,0)
 	tlb_unlock
-	wrtee	r10
+	fsl_erratum_a006198_mtmsr r10 r0 r7
 	msync
 	isync
 	blr
@@ -379,30 +379,30 @@ _GLOBAL(_tlbil_pid_noind)
 	slwi	r4,r3,MAS6_SPID_SHIFT
 	mfmsr	r10
 	ori	r4,r4,MAS6_SIND
-	wrteei	0
+	fsl_erratum_a006198_wrteei0 r0 r7
 	tlb_lock
 	mtspr	SPRN_MAS6,r4
 	PPC_TLBILX_PID(0,0)
 	tlb_unlock
-	wrtee	r10
+	fsl_erratum_a006198_mtmsr r10 r0 r7
 	msync
 	isync
 	blr
 
 _GLOBAL(_tlbil_all)
 	mfmsr	r10
-	wrteei	0
+	fsl_erratum_a006198_wrteei0 r0 r7
 	tlb_lock
 	PPC_TLBILX_ALL(0,0)
 	msync
 	isync
 	tlb_unlock
-	wrtee	r10
+	fsl_erratum_a006198_mtmsr r10 r0 r7
 	blr
 
 _GLOBAL(_tlbil_va)
 	mfmsr	r10
-	wrteei	0
+	fsl_erratum_a006198_wrteei0 r0 r7
 	tlb_lock
 	cmpwi	cr0,r6,0
 	slwi	r4,r4,MAS6_SPID_SHIFT
@@ -414,12 +414,12 @@ _GLOBAL(_tlbil_va)
 	msync
 	isync
 	tlb_unlock
-	wrtee	r10
+	fsl_erratum_a006198_mtmsr r10 r0 r7
 	blr
 
 _GLOBAL(_tlbivax_bcast)
 	mfmsr	r10
-	wrteei	0
+	fsl_erratum_a006198_wrteei0 r0 r7
 	cmpwi	cr0,r6,0
 	slwi	r4,r4,MAS6_SPID_SHIFT
 	rlwimi	r4,r5,MAS6_ISIZE_SHIFT,MAS6_ISIZE_MASK
@@ -430,7 +430,7 @@ _GLOBAL(_tlbivax_bcast)
 	eieio
 	tlbsync
 	sync
-	wrtee	r10
+	fsl_erratum_a006198_mtmsr r10 r0 r7
 	blr
 
 _GLOBAL(set_context)
@@ -456,7 +456,7 @@ _GLOBAL(set_context)
  */
 _GLOBAL(loadcam_entry)
 	mfmsr	r10
-	wrteei	0
+	fsl_erratum_a006198_wrteei0 r0 r7
 	tlb_lock
 
 	LOAD_REG_ADDR(r4, TLBCAM)
@@ -479,6 +479,6 @@ END_MMU_FTR_SECTION_IFSET(MMU_FTR_BIG_PHYS)
 	isync
 
 	tlb_unlock
-	wrtee	r10
+	fsl_erratum_a006198_mtmsr r10 r0 r7
 	blr
 #endif
diff --git a/arch/powerpc/platforms/Kconfig.cputype b/arch/powerpc/platforms/Kconfig.cputype
index f822087..2049cd7 100644
--- a/arch/powerpc/platforms/Kconfig.cputype
+++ b/arch/powerpc/platforms/Kconfig.cputype
@@ -148,6 +148,13 @@ config PPC_E6500_REV1_BUGS
           Do not define this if you are running on a simulator or rev2,
           and want features like hardware tablewalk.
 
+config FSL_ERRATUM_A_006198
+	bool "Work around e6500 rev1 erratum A-006198"
+	depends on PPC_E500MC
+	help
+	  Define this if running e6500 rev1, to avoid a source
+	  of hangs due to CPU erratum A-006198.
+
 config PPC_FPU
 	bool
 	default y if PPC64
-- 
1.7.9.7

