From 67398c5ed6e64eae04fb6c10eeccae9ff7a42435 Mon Sep 17 00:00:00 2001
From: Geoff Thorpe <Geoff.Thorpe@freescale.com>
Date: Wed, 14 Mar 2012 04:49:35 +0000
Subject: [PATCH 069/121] qbman: don't spawn threads to init portals

Portal-initialisation and recovery-exit needs to execute on the affine
core, but this can be achieved by changing the cpumask of the current
task rather than spawning a thread to do it. The latter, apart from
being overkill, also requires a lot more code.

Also, the return value from [qb]man_recovery_exit() was to convey any
errors associated with thread-creation, which is no longer relevant,
so the API is changed to be void-typed.

Signed-off-by: Geoff Thorpe <Geoff.Thorpe@freescale.com>
[Kevin: Original patch taken from FSL
QorIQ-SDK-V1.2-SOURCE-20120614-yocto.iso image]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 drivers/staging/fsl_qbman/bman_driver.c |  111 ++++++----------------------
 drivers/staging/fsl_qbman/qman_driver.c |  121 +++++++------------------------
 include/linux/fsl_bman.h                |    2 +-
 include/linux/fsl_qman.h                |    2 +-
 4 files changed, 51 insertions(+), 185 deletions(-)

diff --git a/drivers/staging/fsl_qbman/bman_driver.c b/drivers/staging/fsl_qbman/bman_driver.c
index 59cc66e..18bed5b 100644
--- a/drivers/staging/fsl_qbman/bman_driver.c
+++ b/drivers/staging/fsl_qbman/bman_driver.c
@@ -39,10 +39,6 @@ EXPORT_SYMBOL(bman_ip_rev);
 u16 bman_pool_max;
 EXPORT_SYMBOL(bman_pool_max);
 
-/*****************/
-/* Portal driver */
-/*****************/
-
 /* Compatibility behaviour (when no bpool-range is present) is that;
  * (a) on a control plane, all pools that aren't explicitly mentioned in the dtb
  *     are available for allocation,
@@ -153,69 +149,33 @@ void bm_pool_free(u32 bpid)
 EXPORT_SYMBOL(bm_pool_free);
 
 #ifdef CONFIG_FSL_BMAN_PORTAL
-/* To understand the use of this structure and the flow of operation for all
- * this portal-setup code, please see qman_driver.c. The Bman case is much the
- * same, but simpler (no Qman-specific fiddly bits). */
-struct affine_portal_data {
-	struct completion done;
-	const struct bm_portal_config *pconfig;
-	struct bman_portal *redirect;
-	int recovery_mode;
+static __init struct bman_portal *init_affine_portal(
+					struct bm_portal_config *pconfig,
+					int cpu, struct bman_portal *redirect,
+					int recovery_mode)
+{
 	struct bman_portal *portal;
-};
+	struct cpumask oldmask = *tsk_cpus_allowed(current);
+	const struct cpumask *newmask = get_cpu_mask(cpu);
 
-static __init int thread_init_affine_portal(void *__data)
-{
-	struct affine_portal_data *data = __data;
-	const struct bm_portal_config *pconfig = data->pconfig;
-	if (data->redirect)
-		data->portal = bman_create_affine_slave(data->redirect);
+	set_cpus_allowed_ptr(current, newmask);
+
+	if (redirect)
+		portal = bman_create_affine_slave(redirect);
 	else {
-		data->portal = bman_create_affine_portal(pconfig,
-					data->recovery_mode);
+		portal = bman_create_affine_portal(pconfig, recovery_mode);
 #ifdef CONFIG_FSL_DPA_PIRQ_SLOW
-		if (data->portal)
+		if (portal)
 			bman_irqsource_add(BM_PIRQ_RCRI | BM_PIRQ_BSCN);
 #endif
 	}
-	complete(&data->done);
-	return 0;
-}
 
-static __init struct bman_portal *init_affine_portal(
-					struct bm_portal_config *pconfig,
-					int cpu, struct bman_portal *redirect,
-					int recovery_mode)
-{
-	struct affine_portal_data data = {
-		.done = COMPLETION_INITIALIZER_ONSTACK(data.done),
-		.pconfig = pconfig,
-		.redirect = redirect,
-		.recovery_mode = recovery_mode,
-		.portal = NULL
-	};
-	struct task_struct *k = kthread_create(thread_init_affine_portal, &data,
-		"bman_affine%d", cpu);
-	int ret;
-	if (IS_ERR(k)) {
-		pr_err("Failed to init %sBman affine portal for cpu %d\n",
-			redirect ? "(slave) " : "", cpu);
-		return NULL;
-	}
-	kthread_bind(k, cpu);
-	wake_up_process(k);
-	wait_for_completion(&data.done);
-	ret = kthread_stop(k);
-	if (ret) {
-		pr_err("Bman portal initialisation failed, cpu %d, code %d\n",
-			cpu, ret);
-		return NULL;
-	}
-	if (data.portal)
+	set_cpus_allowed_ptr(current, &oldmask);
+	if (portal)
 		pr_info("Bman portal %sinitialised, cpu %d\n",
 			redirect ? "(slave) " :
 			pconfig->public_cfg.is_shared ? "(shared) " : "", cpu);
-	return data.portal;
+	return portal;
 }
 #endif
 
@@ -426,38 +386,18 @@ static int __init fsl_bpool_range_init(struct device_node *node,
 }
 
 #ifdef CONFIG_FSL_BMAN_PORTAL
-static __init int __leave_recovery(void *__data)
-{
-	struct completion *done = __data;
-	bman_recovery_exit_local();
-	complete(done);
-	return 0;
-}
-
-int bman_recovery_exit(void)
+void bman_recovery_exit(void)
 {
-	struct completion done = COMPLETION_INITIALIZER_ONSTACK(done);
 	unsigned int cpu;
 
 	for_each_cpu(cpu, bman_affine_cpus()) {
-		struct task_struct *k = kthread_create(__leave_recovery, &done,
-						"bman_recovery");
-		int ret;
-		if (IS_ERR(k)) {
-			pr_err("Thread failure (recovery) on cpu %d\n", cpu);
-			return -ENOMEM;
-		}
-		kthread_bind(k, cpu);
-		wake_up_process(k);
-		wait_for_completion(&done);
-		ret = kthread_stop(k);
-		if (ret) {
-			pr_err("Failed to exit recovery on cpu %d\n", cpu);
-			return ret;
-		}
+		struct cpumask oldmask = *tsk_cpus_allowed(current);
+		const struct cpumask *newmask = get_cpu_mask(cpu);
+		set_cpus_allowed_ptr(current, newmask);
+		bman_recovery_exit_local();
+		set_cpus_allowed_ptr(current, &oldmask);
 		pr_info("Bman portal exited recovery, cpu %d\n", cpu);
 	}
-	return 0;
 }
 EXPORT_SYMBOL(bman_recovery_exit);
 #endif
@@ -573,11 +513,8 @@ static __init int bman_init(void)
 #ifdef CONFIG_FSL_BMAN_PORTAL
 	/* If using private BPID allocation, exit recovery mode automatically
 	 * (ie. after automatic recovery) */
-	if (recovery_mode && explicit_allocator) {
-		ret = bman_recovery_exit();
-		if (ret)
-			return ret;
-	}
+	if (recovery_mode && explicit_allocator)
+		bman_recovery_exit();
 #endif
 	for_each_compatible_node(dn, NULL, "fsl,bpool") {
 		ret = fsl_bpool_init(dn);
diff --git a/drivers/staging/fsl_qbman/qman_driver.c b/drivers/staging/fsl_qbman/qman_driver.c
index cf9ca12..86b005b 100644
--- a/drivers/staging/fsl_qbman/qman_driver.c
+++ b/drivers/staging/fsl_qbman/qman_driver.c
@@ -41,10 +41,6 @@ EXPORT_SYMBOL(qman_ip_rev);
 static u32 fqd_size = (PAGE_SIZE << CONFIG_FSL_QMAN_FQD_SZ);
 #endif
 
-/*****************/
-/* Portal driver */
-/*****************/
-
 static struct dpa_uio_class qman_uio = {
 	.list = LIST_HEAD_INIT(qman_uio.list),
 	.dev_prefix = "qman-uio-"
@@ -56,33 +52,23 @@ const struct dpa_uio_class *dpa_uio_qman(void)
 EXPORT_SYMBOL(dpa_uio_qman);
 
 #ifdef CONFIG_FSL_QMAN_PORTAL
-/* This structure carries parameters from the device-tree handling code that
- * wants to set up a portal for use on 1 or more CPUs, and each temporary thread
- * created to run on those CPUs. The 'portal' member is the return value. */
-struct affine_portal_data {
-	struct completion done;
-	const struct qm_portal_config *pconfig;
-	struct qman_portal *redirect;
-	int recovery_mode;
+static __init struct qman_portal *init_affine_portal(
+					struct qm_portal_config *pconfig,
+					int cpu, struct qman_portal *redirect,
+					int recovery_mode)
+{
 	struct qman_portal *portal;
-};
+	struct cpumask oldmask = *tsk_cpus_allowed(current);
+	const struct cpumask *newmask = get_cpu_mask(cpu);
 
-/* This function is called in a temporary thread for each CPU, to initialise the
- * "affine" portal that the CPU should use. The thread is created and run from
- * the init_affine_portal() bootstrapper. If the CPU has not been assigned its
- * own portal, "redirect" will be non-NULL indicating it should share another
- * CPU's portal (it becomes a "slave"). */
-static __init int thread_init_affine_portal(void *__data)
-{
-	struct affine_portal_data *data = __data;
-	const struct qm_portal_config *pconfig = data->pconfig;
-	if (data->redirect)
-		data->portal = qman_create_affine_slave(data->redirect);
+	set_cpus_allowed_ptr(current, newmask);
+
+	if (redirect)
+		portal = qman_create_affine_slave(redirect);
 	else {
-		/* TODO: cgrs ?? */
-		data->portal = qman_create_affine_portal(pconfig, NULL,
-				data->recovery_mode);
-		if (data->portal) {
+		portal = qman_create_affine_portal(pconfig, NULL,
+				recovery_mode);
+		if (portal) {
 			u32 irq_sources = 0;
 			/* default: enable all (available) pool channels */
 			qman_static_dequeue_add(~0);
@@ -97,47 +83,13 @@ static __init int thread_init_affine_portal(void *__data)
 			qman_irqsource_add(irq_sources);
 		}
 	}
-	complete(&data->done);
-	return 0;
-}
 
-/* This function is just a bootstrap for running thread_init_affine_portal() on
- * a given CPU. The parameters are passed in via the (void*) thread-arg (and
- * results are received back) using the affine_portal_data struct. */
-static __init struct qman_portal *init_affine_portal(
-					const struct qm_portal_config *pconfig,
-					int cpu, struct qman_portal *redirect,
-					int recovery_mode)
-{
-	struct affine_portal_data data = {
-		.done = COMPLETION_INITIALIZER_ONSTACK(data.done),
-		.pconfig = pconfig,
-		.redirect = redirect,
-		.recovery_mode = recovery_mode,
-		.portal = NULL
-	};
-	struct task_struct *k = kthread_create(thread_init_affine_portal, &data,
-		"qman_affine%d", cpu);
-	int ret;
-	if (IS_ERR(k)) {
-		pr_err("Failed to init %sQman affine portal for cpu %d\n",
-			redirect ? "(slave) " : "", cpu);
-		return NULL;
-	}
-	kthread_bind(k, cpu);
-	wake_up_process(k);
-	wait_for_completion(&data.done);
-	ret = kthread_stop(k);
-	if (ret) {
-		pr_err("Qman portal initialisation failed, cpu %d, code %d\n",
-			cpu, ret);
-		return NULL;
-	}
-	if (data.portal)
+	set_cpus_allowed_ptr(current, &oldmask);
+	if (portal)
 		pr_info("Qman portal %sinitialised, cpu %d\n",
 			redirect ? "(slave) " :
 			pconfig->public_cfg.is_shared ? "(shared) " : "", cpu);
-	return data.portal;
+	return portal;
 }
 #endif
 
@@ -340,38 +292,18 @@ static __init int fsl_fqid_range_init(struct device_node *node,
 }
 
 #ifdef CONFIG_FSL_QMAN_PORTAL
-static __init int __leave_recovery(void *__data)
-{
-	struct completion *done = __data;
-	qman_recovery_exit_local();
-	complete(done);
-	return 0;
-}
-
-int qman_recovery_exit(void)
+void qman_recovery_exit(void)
 {
-	struct completion done = COMPLETION_INITIALIZER_ONSTACK(done);
 	unsigned int cpu;
 
 	for_each_cpu(cpu, qman_affine_cpus()) {
-		struct task_struct *k = kthread_create(__leave_recovery, &done,
-						"qman_recovery");
-		int ret;
-		if (IS_ERR(k)) {
-			pr_err("Thread failure (recovery) on cpu %d\n", cpu);
-			return -ENOMEM;
-		}
-		kthread_bind(k, cpu);
-		wake_up_process(k);
-		wait_for_completion(&done);
-		ret = kthread_stop(k);
-		if (ret) {
-			pr_err("Failed to exit recovery on cpu %d\n", cpu);
-			return ret;
-		}
+		struct cpumask oldmask = *tsk_cpus_allowed(current);
+		const struct cpumask *newmask = get_cpu_mask(cpu);
+		set_cpus_allowed_ptr(current, newmask);
+		qman_recovery_exit_local();
+		set_cpus_allowed_ptr(current, &oldmask);
 		pr_info("Qman portal exited recovery, cpu %d\n", cpu);
 	}
-	return 0;
 }
 EXPORT_SYMBOL(qman_recovery_exit);
 #endif
@@ -486,11 +418,8 @@ static __init int qman_init(void)
 #ifdef CONFIG_FSL_QMAN_PORTAL
 	/* If using private FQ allocation, exit recovery mode automatically (ie.
 	 * after automatic recovery) */
-	if (recovery_mode && !use_bpid0) {
-		ret = qman_recovery_exit();
-		if (ret)
-			return ret;
-	}
+	if (recovery_mode && !use_bpid0)
+		qman_recovery_exit();
 	for (cgr.cgrid = 0; cgr.cgrid < __CGR_NUM; cgr.cgrid++) {
 		/* This is to ensure h/w-internal CGR memory is zeroed out. Note
 		 * that we do this for all conceivable CGRIDs, not all of which
diff --git a/include/linux/fsl_bman.h b/include/linux/fsl_bman.h
index 6976a8d..1d312ea 100644
--- a/include/linux/fsl_bman.h
+++ b/include/linux/fsl_bman.h
@@ -365,7 +365,7 @@ int bman_recovery_cleanup_bpid(u32 bpid);
 /**
  * bman_recovery_exit - leave recovery mode
  */
-int bman_recovery_exit(void);
+void bman_recovery_exit(void);
 
 /**
  * bman_rcr_is_empty - Determine if portal's RCR is empty
diff --git a/include/linux/fsl_qman.h b/include/linux/fsl_qman.h
index 15c7aaa..9014c42 100644
--- a/include/linux/fsl_qman.h
+++ b/include/linux/fsl_qman.h
@@ -1292,7 +1292,7 @@ int qman_recovery_cleanup_fq(u32 fqid);
 /**
  * qman_recovery_exit - leave recovery mode
  */
-int qman_recovery_exit(void);
+void qman_recovery_exit(void);
 
 /**
  * qman_stop_dequeues - Stop h/w dequeuing to the s/w portal
-- 
1.7.9.7

