From 77132c4392072df01721758b4a325ae526e4e467 Mon Sep 17 00:00:00 2001
From: Vakul Garg <vakul@freescale.com>
Date: Mon, 19 Mar 2012 15:19:20 +0530
Subject: [PATCH 091/121] qbman: Flush memory reserved for private areas from
 cache

This is required so that transactions initiated by QM/BM for their private
areas can be marked non-coherent by PAMU. This reduces snoop overhead in the
cores

Signed-off-by: Vakul Garg <vakul@freescale.com>
[Kevin: Original patch taken from FSL
QorIQ-SDK-V1.2-SOURCE-20120614-yocto.iso image]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 drivers/staging/fsl_qbman/bman_config.c |   17 ++++++++++++++---
 drivers/staging/fsl_qbman/qman_config.c |   15 +++++++++++++--
 2 files changed, 27 insertions(+), 5 deletions(-)

diff --git a/drivers/staging/fsl_qbman/bman_config.c b/drivers/staging/fsl_qbman/bman_config.c
index 01be61f..a57b0e9 100644
--- a/drivers/staging/fsl_qbman/bman_config.c
+++ b/drivers/staging/fsl_qbman/bman_config.c
@@ -33,6 +33,7 @@
 #include <linux/smp.h>	/* get_hard_smp_processor_id() */
 #endif
 
+#include <asm/cacheflush.h>
 #include "bman_private.h"
 
 /* Last updated for v00.79 of the BG */
@@ -259,20 +260,26 @@ static struct device_node *bm_node;
 #define DEFAULT_FBPR_SZ	(PAGE_SIZE << 12)
 
 /* Parse the <name> property to extract the memory location and size and
- * memblock_reserve() it. If it isn't supplied, memblock_alloc() the default size. */
+ * memblock_reserve() it. If it isn't supplied, memblock_alloc() the default
+ * size. Also flush this memory range from data cache so that BMAN originated
+ * transactions for this memory region could be marked non-coherent.
+ */
 static __init int parse_mem_property(struct device_node *node, const char *name,
 				dma_addr_t *addr, size_t *sz, int zero)
 {
 	const u32 *pint;
 	int ret;
+	unsigned long vaddr;
 
 	pint = of_get_property(node, name, &ret);
 	if (!pint || (ret != 16)) {
 		pr_info("No %s property '%s', using memblock_alloc(%016zx)\n",
 				node->full_name, name, *sz);
 		*addr = memblock_alloc(*sz, *sz);
+		vaddr = (unsigned long)phys_to_virt(*addr);
 		if (zero)
-			memset(phys_to_virt(*addr), 0, *sz);
+			memset((void *)vaddr, 0, *sz);
+		flush_dcache_range(vaddr, vaddr + *sz);
 		return 0;
 	}
 	pr_info("Using %s property '%s'\n", node->full_name, name);
@@ -291,12 +298,16 @@ static __init int parse_mem_property(struct device_node *node, const char *name,
 			pr_err("Failed to reserve %s\n", name);
 			return -ENOMEM;
 		}
+		vaddr = (unsigned long)phys_to_virt(*addr);
 		if (zero)
-			memset(phys_to_virt(*addr), 0, *sz);
+			memset((void *)vaddr, 0, *sz);
+		flush_dcache_range(vaddr, vaddr + *sz);
 	} else if (zero) {
 		/* map as cacheable, non-guarded */
 		void *tmpp = ioremap_prot(*addr, *sz, 0);
 		memset(tmpp, 0, *sz);
+		vaddr = (unsigned long)tmpp;
+		flush_dcache_range(vaddr, vaddr + *sz);
 		iounmap(tmpp);
 	}
 	return 0;
diff --git a/drivers/staging/fsl_qbman/qman_config.c b/drivers/staging/fsl_qbman/qman_config.c
index 179abb6..a26f8c8 100644
--- a/drivers/staging/fsl_qbman/qman_config.c
+++ b/drivers/staging/fsl_qbman/qman_config.c
@@ -33,6 +33,7 @@
 #include <linux/smp.h>	/* get_hard_smp_processor_id() */
 #endif
 
+#include <asm/cacheflush.h>
 #include "qman_private.h"
 
 /* Last updated for v00.800 of the BG */
@@ -506,20 +507,26 @@ static struct qman *qm;
 static struct device_node *qm_node;
 
 /* Parse the <name> property to extract the memory location and size and
- * memblock_reserve() it. If it isn't supplied, memblock_alloc() the default size. */
+ * memblock_reserve() it. If it isn't supplied, memblock_alloc() the default
+ * size. Also flush this memory range from data cache so that QMAN originated
+ * transactions for this memory region could be marked non-coherent.
+ */
 static __init int parse_mem_property(struct device_node *node, const char *name,
 				dma_addr_t *addr, size_t *sz, int zero)
 {
 	const u32 *pint;
 	int ret;
+	unsigned long vaddr;
 
 	pint = of_get_property(node, name, &ret);
 	if (!pint || (ret != 16)) {
 		pr_info("No %s property '%s', using memblock_alloc(%016zx)\n",
 				node->full_name, name, *sz);
 		*addr = memblock_alloc(*sz, *sz);
+		vaddr = (unsigned long)phys_to_virt(*addr);
 		if (zero)
-			memset(phys_to_virt(*addr), 0, *sz);
+			memset((void *)vaddr, 0, *sz);
+		flush_dcache_range(vaddr, vaddr + *sz);
 		return 0;
 	}
 	pr_info("Using %s property '%s'\n", node->full_name, name);
@@ -538,12 +545,16 @@ static __init int parse_mem_property(struct device_node *node, const char *name,
 			pr_err("Failed to reserve %s\n", name);
 			return -ENOMEM;
 		}
+		vaddr = (unsigned long)phys_to_virt(*addr);
 		if (zero)
 			memset(phys_to_virt(*addr), 0, *sz);
+		flush_dcache_range(vaddr, vaddr + *sz);
 	} else if (zero) {
 		/* map as cacheable, non-guarded */
 		void *tmpp = ioremap_prot(*addr, *sz, 0);
 		memset(tmpp, 0, *sz);
+		vaddr = (unsigned long)tmpp;
+		flush_dcache_range(vaddr, vaddr + *sz);
 		iounmap(tmpp);
 	}
 	return 0;
-- 
1.7.9.7

