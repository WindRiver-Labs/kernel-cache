From 42824fde84328e5bfaad38c8a66e17bacbee592f Mon Sep 17 00:00:00 2001
From: Geoff Thorpe <Geoff.Thorpe@freescale.com>
Date: Wed, 29 Feb 2012 23:36:59 +0000
Subject: [PATCH 064/128] qbman: do not disable pre-emption in poll APIs

Poll functions assume the caller is cpu-affine and in no risk of
re-entrance, which are the two reasons we usually use the
get/put_cpu_var() semantic - ie. to disable pre-emption. Some use-cases
expect the execution context to remain as non-atomic during
poll-triggered callbacks as it was when the poll API was first called
(eg. NAPI), so we go out of our way in this case to not disable
pre-emption

Signed-off-by: Geoff Thorpe <Geoff.Thorpe@freescale.com>
[Kevin: Original patch taken from FSL
QorIQ-SDK-V1.2-SOURCE-20120614-yocto.iso image]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 drivers/staging/fsl_qbman/bman_high.c |   13 +++++++++----
 drivers/staging/fsl_qbman/qman_high.c |   25 +++++++++++++++++--------
 2 files changed, 26 insertions(+), 12 deletions(-)

diff --git a/drivers/staging/fsl_qbman/bman_high.c b/drivers/staging/fsl_qbman/bman_high.c
index f5d6c32..334cde7 100644
--- a/drivers/staging/fsl_qbman/bman_high.c
+++ b/drivers/staging/fsl_qbman/bman_high.c
@@ -108,6 +108,11 @@ static inline void put_affine_portal(void)
 {
 	put_cpu_var(bman_affine_portal);
 }
+static inline struct bman_portal *get_poll_portal(void)
+{
+	return &__get_cpu_var(bman_affine_portal);
+}
+#define put_poll_portal() do { ; } while (0)
 
 /* GOTCHA: this object type refers to a pool, it isn't *the* pool. There may be
  * more than one such object per Bman buffer pool, eg. if different users of the
@@ -502,7 +507,7 @@ EXPORT_SYMBOL(bman_affine_cpus);
 
 u32 bman_poll_slow(void)
 {
-	struct bman_portal *p = get_raw_affine_portal();
+	struct bman_portal *p = get_poll_portal();
 	u32 ret;
 #ifdef CONFIG_FSL_DPA_PORTAL_SHARE
 	if (unlikely(p->sharing_redirect))
@@ -514,7 +519,7 @@ u32 bman_poll_slow(void)
 		ret = __poll_portal_slow(p, is);
 		bm_isr_status_clear(&p->p, ret);
 	}
-	put_affine_portal();
+	put_poll_portal();
 	return ret;
 }
 EXPORT_SYMBOL(bman_poll_slow);
@@ -522,7 +527,7 @@ EXPORT_SYMBOL(bman_poll_slow);
 /* Legacy wrapper */
 void bman_poll(void)
 {
-	struct bman_portal *p = get_raw_affine_portal();
+	struct bman_portal *p = get_poll_portal();
 #ifdef CONFIG_FSL_DPA_PORTAL_SHARE
 	if (unlikely(p->sharing_redirect))
 		goto done;
@@ -538,7 +543,7 @@ void bman_poll(void)
 #ifdef CONFIG_FSL_DPA_PORTAL_SHARE
 done:
 #endif
-	put_affine_portal();
+	put_poll_portal();
 }
 EXPORT_SYMBOL(bman_poll);
 
diff --git a/drivers/staging/fsl_qbman/qman_high.c b/drivers/staging/fsl_qbman/qman_high.c
index 3ff15c9..3c6d1bd 100644
--- a/drivers/staging/fsl_qbman/qman_high.c
+++ b/drivers/staging/fsl_qbman/qman_high.c
@@ -156,6 +156,17 @@ static inline void put_affine_portal(void)
 {
 	put_cpu_var(qman_affine_portal);
 }
+/* Exception: poll functions assume the caller is cpu-affine and in no risk of
+ * re-entrance, which are the two reasons we usually use the get/put_cpu_var()
+ * semantic - ie. to disable pre-emption. Some use-cases expect the execution
+ * context to remain as non-atomic during poll-triggered callbacks as it was
+ * when the poll API was first called (eg. NAPI), so we go out of our way in
+ * this case to not disable pre-emption. */
+static inline struct qman_portal *get_poll_portal(void)
+{
+	return &__get_cpu_var(qman_affine_portal);
+}
+#define put_poll_portal() do { ; } while (0)
 
 /* This gives a FQID->FQ lookup to cover the fact that we can't directly demux
  * retirement notifications (the fact they are sometimes h/w-consumed means that
@@ -1002,8 +1013,7 @@ EXPORT_SYMBOL(qman_affine_cpus);
 
 int qman_poll_dqrr(unsigned int limit)
 {
-	/* We need to fail when called for a "slave", so use "raw" */
-	struct qman_portal *p = get_raw_affine_portal();
+	struct qman_portal *p = get_poll_portal();
 	int ret;
 #ifdef CONFIG_FSL_DPA_PORTAL_SHARE
 	if (unlikely(p->sharing_redirect))
@@ -1014,15 +1024,14 @@ int qman_poll_dqrr(unsigned int limit)
 		BUG_ON(p->irq_sources & QM_PIRQ_DQRI);
 		ret = __poll_portal_fast(p, limit);
 	}
-	put_affine_portal();
+	put_poll_portal();
 	return ret;
 }
 EXPORT_SYMBOL(qman_poll_dqrr);
 
 u32 qman_poll_slow(void)
 {
-	/* We need to fail when called for a "slave", so use "raw" */
-	struct qman_portal *p = get_raw_affine_portal();
+	struct qman_portal *p = get_poll_portal();
 	u32 ret;
 #ifdef CONFIG_FSL_DPA_PORTAL_SHARE
 	if (unlikely(p->sharing_redirect))
@@ -1034,7 +1043,7 @@ u32 qman_poll_slow(void)
 		ret = __poll_portal_slow(p, is);
 		qm_isr_status_clear(&p->p, ret);
 	}
-	put_affine_portal();
+	put_poll_portal();
 	return ret;
 }
 EXPORT_SYMBOL(qman_poll_slow);
@@ -1042,7 +1051,7 @@ EXPORT_SYMBOL(qman_poll_slow);
 /* Legacy wrapper */
 void qman_poll(void)
 {
-	struct qman_portal *p = get_raw_affine_portal();
+	struct qman_portal *p = get_poll_portal();
 #ifdef CONFIG_FSL_DPA_PORTAL_SHARE
 	if (unlikely(p->sharing_redirect))
 		goto done;
@@ -1063,7 +1072,7 @@ void qman_poll(void)
 #ifdef CONFIG_FSL_DPA_PORTAL_SHARE
 done:
 #endif
-	put_affine_portal();
+	put_poll_portal();
 }
 EXPORT_SYMBOL(qman_poll);
 
-- 
1.7.9.7

