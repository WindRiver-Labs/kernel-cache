From 0bf12da3f02880db5df6965b0dd6f88536ec6538 Mon Sep 17 00:00:00 2001
From: Ioana Radulescu <ruxandra.radulescu@freescale.com>
Date: Thu, 26 Jan 2012 13:49:31 +0200
Subject: [PATCH 090/128] dpaa_eth: Fix dma mappings

The DMA map/unmap functions are supposed to be called immediately
before handing the buffer to HW/after we took the buffer from HW.
Software is not supposed to touch the buffer in any way between the
DMA map and unmap operations.

Fix several instances where buffer contents were read before doing
DMA unmap. Also fix error path in the rx function where an unmapped
buffer was returned to the BMan buffer pool. And make sure the return
value of a DMA map call is always validated.

Signed-off-by: Ioana Radulescu <ruxandra.radulescu@freescale.com>
[Kevin: Original patch taken from FSL
QorIQ-SDK-V1.2-SOURCE-20120614-yocto.iso image]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 drivers/net/ethernet/freescale/dpa/dpaa_eth.c |   24 ++++++++++++++----------
 1 file changed, 14 insertions(+), 10 deletions(-)

diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth.c b/drivers/net/ethernet/freescale/dpa/dpaa_eth.c
index 7b06985..de9be31 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth.c
@@ -227,6 +227,10 @@ static void dpa_bp_add_8(struct dpa_bp *dpa_bp)
 
 		addr = dma_map_single(dpa_bp->dev, skb->head + pad,
 				dpa_bp->size, DMA_FROM_DEVICE);
+		if (unlikely(dma_mapping_error(dpa_bp->dev, addr))) {
+			dpaa_eth_err(dpa_bp->dev, "DMA mapping failed");
+			break;
+		}
 
 		bm_buffer_set64(&bmb[i], addr);
 	}
@@ -410,11 +414,12 @@ _dpa_bp_free(struct dpa_bp *dpa_bp)
 			for (i = 0; i < num; i++) {
 				dma_addr_t addr = bm_buf_addr(&bmb[i]);
 				struct sk_buff **skbh = phys_to_virt(addr);
-				struct sk_buff *skb = *skbh;
+				struct sk_buff *skb;
 
 				dma_unmap_single(bp->dev, addr, bp->size,
 						DMA_FROM_DEVICE);
 
+				skb = *skbh;
 				dev_kfree_skb_any(skb);
 			}
 		} while (num == 8);
@@ -837,10 +842,10 @@ static void _dpa_tx_error(struct net_device		*net_dev,
 	percpu_priv->stats.tx_errors++;
 
 	skbh = (struct sk_buff **)phys_to_virt(addr);
-	skb = *skbh;
 
 	dma_unmap_single(bp->dev, addr, bp->size, DMA_TO_DEVICE);
 
+	skb = *skbh;
 	dev_kfree_skb(skb);
 }
 
@@ -875,8 +880,7 @@ static void __hot _dpa_rx(struct net_device *net_dev,
 
 	dpa_bp = dpa_bpid2pool(fd->bpid);
 
-	dma_unmap_single(dpa_bp->dev, qm_fd_addr(fd), dpa_bp->size,
-				DMA_FROM_DEVICE);
+	dma_unmap_single(dpa_bp->dev, addr, dpa_bp->size, DMA_FROM_DEVICE);
 
 	skb = *skbh;
 	prefetch(skb);
@@ -922,8 +926,8 @@ static void __hot _dpa_rx(struct net_device *net_dev,
 	return;
 
 drop_large_frame:
-	(*percpu_priv->dpa_bp_count)++;
-	skb_recycle(skb);
+	dev_kfree_skb(skb);
+	return;
 _return_dpa_fd_release:
 	dpa_fd_release(net_dev, fd);
 }
@@ -1007,6 +1011,8 @@ static void __hot _dpa_tx(struct net_device		*net_dev,
 	}
 
 	skbh = (struct sk_buff **)phys_to_virt(addr);
+
+	dma_unmap_single(bp->dev, addr, bp->size, DMA_TO_DEVICE);
 	skb = *skbh;
 
 #ifdef CONFIG_FSL_DPA_1588
@@ -1014,8 +1020,6 @@ static void __hot _dpa_tx(struct net_device		*net_dev,
 		dpa_ptp_store_txstamp(net_dev, skb, fd);
 #endif
 
-	dma_unmap_single(bp->dev, addr, bp->size, DMA_TO_DEVICE);
-
 	dev_kfree_skb(skb);
 }
 
@@ -1325,7 +1329,7 @@ static int __hot dpa_tx(struct sk_buff *skb, struct net_device *net_dev)
 	}
 
 	addr = dma_map_single(dpa_bp->dev, skbh, dpa_bp->size, DMA_TO_DEVICE);
-	if (unlikely(addr == 0)) {
+	if (unlikely(dma_mapping_error(dpa_bp->dev, addr))) {
 		if (netif_msg_tx_err(priv)  && net_ratelimit())
 			cpu_netdev_err(net_dev, "dma_map_single() failed\n");
 		goto dma_map_failed;
@@ -1589,10 +1593,10 @@ static void egress_ern(struct qman_portal	*portal,
 	}
 
 	skbh = (struct sk_buff **)phys_to_virt(addr);
-	skb = *skbh;
 
 	dma_unmap_single(bp->dev, addr, bp->size, DMA_TO_DEVICE);
 
+	skb = *skbh;
 	dev_kfree_skb_any(skb);
 }
 
-- 
1.7.9.7

