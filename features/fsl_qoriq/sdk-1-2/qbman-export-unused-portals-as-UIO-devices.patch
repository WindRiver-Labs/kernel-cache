From 8b56bf689a5d4e35da5d778c0a35285bd91489ea Mon Sep 17 00:00:00 2001
From: Geoff Thorpe <Geoff.Thorpe@freescale.com>
Date: Wed, 14 Mar 2012 04:49:43 +0000
Subject: [PATCH 077/121] qbman: export unused portals as UIO devices

This is an overhaul of the previous UIO driver. UIO devices are created
out of any portals that weren't initialised for the kernel's own
requirements, rather than being statically pre-destined for user-space nor
statically pre-configured for stashing affinity to a particular cpu. The
user-space thread should open the device after it has pinned itself to one
cpu, because that's the cpu the driver will set the stashing affinity to.
The code has also been reorganised for better re-use and to get rid of
union structures.

Signed-off-by: Geoff Thorpe <Geoff.Thorpe@freescale.com>
[Kevin: Original patch taken from FSL
QorIQ-SDK-V1.2-SOURCE-20120614-yocto.iso image]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 drivers/staging/fsl_qbman/Kconfig       |    9 ++
 drivers/staging/fsl_qbman/Makefile      |    3 +
 drivers/staging/fsl_qbman/bman_driver.c |   86 +++++++++++++-
 drivers/staging/fsl_qbman/dpa_sys.h     |   28 +++++
 drivers/staging/fsl_qbman/dpa_uio.c     |  190 +++++++++++++++++++++++++++++++
 drivers/staging/fsl_qbman/qman_driver.c |   93 ++++++++++++++-
 6 files changed, 402 insertions(+), 7 deletions(-)
 create mode 100644 drivers/staging/fsl_qbman/dpa_uio.c

diff --git a/drivers/staging/fsl_qbman/Kconfig b/drivers/staging/fsl_qbman/Kconfig
index 71b3380..b557bab 100644
--- a/drivers/staging/fsl_qbman/Kconfig
+++ b/drivers/staging/fsl_qbman/Kconfig
@@ -34,6 +34,15 @@ config FSL_DPA_PORTAL_SHARE
 	bool
 	default y
 
+config FSL_DPA_UIO
+	tristate "export USDPAA portals via UIO"
+	depends on UIO
+	default y
+	---help---
+	  Any portals unused by the kernel are exported as UIO devices for
+	  use by USDPAA (User Space DataPath Acceleration Architecture)
+	  applications.
+
 config FSL_BMAN
 	bool "Freescale Buffer Manager (BMan) support"
 	default y
diff --git a/drivers/staging/fsl_qbman/Makefile b/drivers/staging/fsl_qbman/Makefile
index 7e385aa..330cdfb 100644
--- a/drivers/staging/fsl_qbman/Makefile
+++ b/drivers/staging/fsl_qbman/Makefile
@@ -20,3 +20,6 @@ qman_tester-y			 = qman_test.o qman_test_hotpotato.o \
 qman_tester-$(CONFIG_FSL_QMAN_TEST_ERRATA) += qman_test_errata.o
 obj-$(CONFIG_FSL_QMAN_DEBUGFS)	+= qman_debugfs_interface.o
 qman_debugfs_interface-y	 = qman_debugfs.o
+
+# USDPAA
+obj-$(CONFIG_FSL_DPA_UIO)	+= dpa_uio.o
diff --git a/drivers/staging/fsl_qbman/bman_driver.c b/drivers/staging/fsl_qbman/bman_driver.c
index b31308f..ff6c9e6 100644
--- a/drivers/staging/fsl_qbman/bman_driver.c
+++ b/drivers/staging/fsl_qbman/bman_driver.c
@@ -3,13 +3,13 @@
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
+ *	 notice, this list of conditions and the following disclaimer.
  *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in the
- *       documentation and/or other materials provided with the distribution.
+ *	 notice, this list of conditions and the following disclaimer in the
+ *	 documentation and/or other materials provided with the distribution.
  *     * Neither the name of Freescale Semiconductor nor the
- *       names of its contributors may be used to endorse or promote products
- *       derived from this software without specific prior written permission.
+ *	 names of its contributors may be used to endorse or promote products
+ *	 derived from this software without specific prior written permission.
  *
  *
  * ALTERNATIVELY, this software may be distributed under the terms of the
@@ -160,6 +160,13 @@ err:
 	return NULL;
 }
 
+static void destroy_pcfg(struct bm_portal_config *pcfg)
+{
+	iounmap(pcfg->addr_virt[DPA_PORTAL_CI]);
+	iounmap(pcfg->addr_virt[DPA_PORTAL_CE]);
+	kfree(pcfg);
+}
+
 static struct bm_portal_config *get_pcfg(struct list_head *list)
 {
 	struct bm_portal_config *pcfg;
@@ -170,6 +177,59 @@ static struct bm_portal_config *get_pcfg(struct list_head *list)
 	return pcfg;
 }
 
+/* UIO handling callbacks */
+#define BMAN_UIO_PREAMBLE() \
+	const struct bm_portal_config *pcfg = \
+		container_of(__p, struct bm_portal_config, list)
+static int bman_uio_cb_init(const struct list_head *__p, struct uio_info *info)
+{
+	BMAN_UIO_PREAMBLE();
+	/* big enough for "bman-uio-xx" */
+	char *name = kzalloc(16, GFP_KERNEL);
+	if (!name)
+		return -ENOMEM;
+	sprintf(name, "bman-uio-%x", pcfg->public_cfg.index);
+	info->name = name;
+	info->mem[DPA_PORTAL_CE].name = "cena";
+	info->mem[DPA_PORTAL_CE].addr = pcfg->addr_phys[DPA_PORTAL_CE].start;
+	info->mem[DPA_PORTAL_CE].size =
+		resource_size(&pcfg->addr_phys[DPA_PORTAL_CE]);
+	info->mem[DPA_PORTAL_CE].memtype = UIO_MEM_PHYS;
+	info->mem[DPA_PORTAL_CI].name = "cinh";
+	info->mem[DPA_PORTAL_CI].addr = pcfg->addr_phys[DPA_PORTAL_CI].start;
+	info->mem[DPA_PORTAL_CI].size =
+		resource_size(&pcfg->addr_phys[DPA_PORTAL_CI]);
+	info->mem[DPA_PORTAL_CI].memtype = UIO_MEM_PHYS;
+	info->irq = pcfg->public_cfg.irq;
+	return 0;
+}
+static void bman_uio_cb_destroy(const struct list_head *__p,
+				struct uio_info *info)
+{
+	BMAN_UIO_PREAMBLE();
+	kfree(info->name);
+	/* We own this struct but had passed it to the dpa_uio layer as a const
+	 * so that we don't accidentally meddle with it in the dpa_uio code.
+	 * Here it's passed back to us for final clean it up, so de-constify. */
+	destroy_pcfg((struct bm_portal_config *)pcfg);
+}
+static void bman_uio_cb_interrupt(const struct list_head *__p)
+{
+	BMAN_UIO_PREAMBLE();
+	/* This is the only manipulation of a portal register that isn't in the
+	 * regular kernel portal driver (_high.c/_low.h). It is also the only
+	 * time the kernel touches a register on a portal that is otherwise
+	 * being driven by a user-space driver. So rather than messing up
+	 * encapsulation for one trivial call, I am hard-coding the offset to
+	 * the inhibit register and writing it directly from here. */
+	out_be32(pcfg->addr_virt[DPA_PORTAL_CI] + 0xe0c, ~(u32)0);
+}
+static const struct dpa_uio_vtable bman_uio = {
+	.init_uio = bman_uio_cb_init,
+	.destroy = bman_uio_cb_destroy,
+	.on_interrupt = bman_uio_cb_interrupt
+};
+
 static struct bman_portal *init_pcfg(struct bm_portal_config *pcfg)
 {
 	struct bman_portal *p;
@@ -210,7 +270,7 @@ static void init_slave(int cpu)
  * and/or ranges of indexes, with each being optionally prefixed by "s" to
  * explicitly mark it or them for sharing.
  *    Eg;
- *        bportals=s0,1-3,s4
+ *	  bportals=s0,1-3,s4
  * means that cpus 1,2,3 get "unshared" portals, cpus 0 and 4 get "shared"
  * portals, and any remaining cpus share the portals that are assigned to cpus 0
  * or 4, selected in a round-robin fashion. (In this example, cpu 5 would share
@@ -251,6 +311,7 @@ __setup("bportals=", parse_bportals);
  * 5. Shared portals are initialised on their respective cpus.
  * 6. Each remaining cpu is initialised to slave to one of the shared portals,
  *    which are selected in a round-robin fashion.
+ * Any portal configs left unused are exported as UIO devices.
  */
 static __init int bman_init(void)
 {
@@ -364,6 +425,19 @@ static __init int bman_init(void)
 		for_each_cpu(cpu, &slave_cpus)
 			init_slave(cpu);
 	pr_info("Bman portals initialised\n");
+#ifdef CONFIG_FSL_DPA_UIO
+	/* Export any left over portals as UIO devices */
+	do {
+		pcfg = get_pcfg(&unused_pcfgs);
+		if (!pcfg)
+			break;
+		ret = dpa_uio_register(&pcfg->list, &bman_uio);
+		if (ret) {
+			pr_err("Failure registering BMan UIO portal\n");
+			destroy_pcfg(pcfg);
+		}
+	} while (1);
+#endif
 	return 0;
 }
 subsys_initcall(bman_init);
diff --git a/drivers/staging/fsl_qbman/dpa_sys.h b/drivers/staging/fsl_qbman/dpa_sys.h
index 67f9659..e802f11 100644
--- a/drivers/staging/fsl_qbman/dpa_sys.h
+++ b/drivers/staging/fsl_qbman/dpa_sys.h
@@ -54,6 +54,7 @@
 #include <linux/debugfs.h>
 #include <linux/seq_file.h>
 #include <linux/device.h>
+#include <linux/uio_driver.h>
 #include <linux/smp.h>
 #include <sysdev/fsl_soc.h>
 #include <linux/fsl_hypervisor.h>
@@ -81,6 +82,33 @@ void dpa_alloc_free(struct dpa_alloc *alloc, u32 fqid, u32 count);
 /* When copying aligned words or shorts, try to avoid memcpy() */
 #define CONFIG_TRY_BETTER_MEMCPY
 
+/* Handle portals destined for USDPAA (user-space).
+ *
+ * The UIO handling is mostly in dpa_uio.c which is common to qman and bman, but
+ * there are some specifics to each case, and they have independent data
+ * structures. The "pcfg"s for qman and bman portals are maintained in lists in
+ * their respective drivers, and they're detached from those lists when they are
+ * to be registered as UIO devices, so we have dpa_uio.c store them in a
+ * mixed-type list, and use this vtable of callbacks to let the qman+bman
+ * drivers container_of() the list item to their respective object wrappers and
+ * implement whatever logic distinguishes them.
+ */
+struct dpa_uio_vtable {
+	/* This callback should fill in 'name', 'mem', and 'irq'. The rest will
+	 * be filled in by dpa_uio.c */
+	int (*init_uio)(const struct list_head *pcfg, struct uio_info *info);
+	/* Free up whatever object contains 'pcfg' */
+	void (*destroy)(const struct list_head *pcfg, struct uio_info *info);
+	/* Called when the portal is opened (Qman uses this for rerouting
+	 * stashing to the current cpu) */
+	int (*on_open)(const struct list_head *pcfg);
+	void (*on_close)(const struct list_head *pcfg);
+	/* Called when an interrupt fires - must disable interrupts */
+	void (*on_interrupt)(const struct list_head *pcfg);
+};
+int __init dpa_uio_register(struct list_head *new_pcfg,
+			    const struct dpa_uio_vtable *vtable);
+
 /* For 2-element tables related to cache-inhibited and cache-enabled mappings */
 #define DPA_PORTAL_CE 0
 #define DPA_PORTAL_CI 1
diff --git a/drivers/staging/fsl_qbman/dpa_uio.c b/drivers/staging/fsl_qbman/dpa_uio.c
new file mode 100644
index 0000000..cdb78db
--- /dev/null
+++ b/drivers/staging/fsl_qbman/dpa_uio.c
@@ -0,0 +1,190 @@
+/* Copyright 2011 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "bman_private.h"
+#include "qman_private.h"
+
+static const char dpa_uio_version[] = "USDPAA UIO portal driver v0.2";
+
+static LIST_HEAD(dpa_uio_list);
+
+struct dpa_uio_info {
+	const struct dpa_uio_vtable *vtable;
+	const struct list_head *pcfg;
+	atomic_t ref; /* exclusive, only one open() at a time */
+	struct uio_info uio;
+	struct platform_device *pdev;
+	struct list_head node;
+};
+
+static int dpa_uio_open(struct uio_info *info, struct inode *inode)
+{
+	struct dpa_uio_info *i = container_of(info, struct dpa_uio_info, uio);
+	int ret = 0;
+
+	if (!atomic_dec_and_test(&i->ref)) {
+		atomic_inc(&i->ref);
+		return -EBUSY;
+	}
+	if (i->vtable->on_open) {
+		ret = i->vtable->on_open(i->pcfg);
+		if (ret)
+			atomic_inc(&i->ref);
+	}
+	return ret;
+}
+
+static int dpa_uio_release(struct uio_info *info, struct inode *inode)
+{
+	struct dpa_uio_info *i = container_of(info, struct dpa_uio_info, uio);
+	if (i->vtable->on_close)
+		i->vtable->on_close(i->pcfg);
+	atomic_inc(&i->ref);
+	return 0;
+}
+
+static pgprot_t dpa_uio_pgprot(struct uio_info *info, unsigned int mem_idx,
+				   pgprot_t prot)
+{
+	if (mem_idx == DPA_PORTAL_CE)
+		/* It's the cache-enabled portal region. NB, we shouldn't use
+		 * pgprot_cached() here because it includes _PAGE_COHERENT. The
+		 * region is cachable but *not* coherent - stashing (if enabled)
+		 * leads to "coherent-like" behaviour, otherwise the driver
+		 * explicitly invalidates/prefetches. */
+		return pgprot_cached_noncoherent(prot);
+	/* Otherwise it's the cache-inhibited portal region */
+	return pgprot_noncached(prot);
+}
+
+static irqreturn_t dpa_uio_irq_handler(int irq, struct uio_info *info)
+{
+	struct dpa_uio_info *i = container_of(info, struct dpa_uio_info, uio);
+	i->vtable->on_interrupt(i->pcfg);
+	return IRQ_HANDLED;
+}
+
+static int __init dpa_uio_portal_init(struct dpa_uio_info *info)
+{
+	int ret;
+
+	/* Fill in qbman-specific fields of uio_info */
+	ret = info->vtable->init_uio(info->pcfg, &info->uio);
+	if (ret) {
+		pr_err("dpa_uio_portal: qbman parameter setup failed\n");
+		return -ENODEV;
+	}
+
+	/* Fill in common fields of uio_info */
+	info->uio.version = dpa_uio_version;
+	info->uio.handler = dpa_uio_irq_handler;
+	info->uio.set_pgprot = dpa_uio_pgprot;
+	info->uio.open = dpa_uio_open;
+	info->uio.release = dpa_uio_release;
+
+	/* Fill in state private to this file */
+	atomic_set(&info->ref, 1);
+	info->pdev = platform_device_alloc(info->uio.name, -1);
+	if (!info->pdev) {
+		info->vtable->destroy(info->pcfg, &info->uio);
+		pr_err("dpa_uio_portal: platform_device_alloc() failed\n");
+		return -ENOMEM;
+	}
+	ret = platform_device_add(info->pdev);
+	if (ret) {
+		platform_device_put(info->pdev);
+		info->vtable->destroy(info->pcfg, &info->uio);
+		pr_err("dpa_uio_portal: platform_device_add() failed\n");
+		return -ENOMEM;
+	}
+
+	/* Register the device */
+	ret = uio_register_device(&info->pdev->dev, &info->uio);
+	if (ret) {
+		platform_device_del(info->pdev);
+		platform_device_put(info->pdev);
+		info->vtable->destroy(info->pcfg, &info->uio);
+		pr_err("dpa_uio_portal: UIO registration failed\n");
+		return -EBUSY;
+	}
+	pr_info("USDPAA portal initialised, %s\n", info->uio.name);
+	return 0;
+}
+
+static void __init dpa_uio_portal_finish(struct dpa_uio_info *info)
+{
+	info->vtable->destroy(info->pcfg, &info->uio);
+	uio_unregister_device(&info->uio);
+	platform_device_del(info->pdev);
+	platform_device_put(info->pdev);
+	pr_info("USDPAA portal removed, %s\n", info->uio.name);
+}
+
+static int __init dpa_uio_init(void)
+{
+	struct dpa_uio_info *info, *tmp;
+	list_for_each_entry_safe(info, tmp, &dpa_uio_list, node) {
+		int ret = dpa_uio_portal_init(info);
+		if (ret) {
+			list_del(&info->node);
+			kfree(info);
+		}
+	}
+	pr_info("USDPAA portal layer loaded\n");
+	return 0;
+}
+
+static void __exit dpa_uio_exit(void)
+{
+	struct dpa_uio_info *info, *tmp;
+	list_for_each_entry_safe(info, tmp, &dpa_uio_list, node) {
+		dpa_uio_portal_finish(info);
+		list_del(&info->node);
+		kfree(info);
+	}
+	pr_info("USDPAA portal layer unloaded\n");
+}
+
+int __init dpa_uio_register(struct list_head *new_pcfg,
+			    const struct dpa_uio_vtable *vtable)
+{
+	struct dpa_uio_info *info = kzalloc(sizeof(*info), GFP_KERNEL);
+	if (!info)
+		return -ENOMEM;
+	info->vtable = vtable;
+	info->pcfg = new_pcfg;
+	list_add_tail(&info->node, &dpa_uio_list);
+	return 0;
+}
+
+module_init(dpa_uio_init)
+module_exit(dpa_uio_exit)
+MODULE_LICENSE("GPL");
diff --git a/drivers/staging/fsl_qbman/qman_driver.c b/drivers/staging/fsl_qbman/qman_driver.c
index c4f838c..1fb8ae6 100644
--- a/drivers/staging/fsl_qbman/qman_driver.c
+++ b/drivers/staging/fsl_qbman/qman_driver.c
@@ -164,6 +164,13 @@ err:
 	return NULL;
 }
 
+static void destroy_pcfg(struct qm_portal_config *pcfg)
+{
+	iounmap(pcfg->addr_virt[DPA_PORTAL_CI]);
+	iounmap(pcfg->addr_virt[DPA_PORTAL_CE]);
+	kfree(pcfg);
+}
+
 static struct qm_portal_config *get_pcfg(struct list_head *list)
 {
 	struct qm_portal_config *pcfg;
@@ -187,6 +194,78 @@ static void set_liodns(const struct qm_portal_config *pcfg, int cpu)
 #define set_liodns(pcfg, cpu) do { } while (0)
 #endif
 
+/* UIO handling callbacks */
+#define QMAN_UIO_PREAMBLE() \
+	const struct qm_portal_config *pcfg = \
+		container_of(__p, struct qm_portal_config, list)
+static int qman_uio_cb_init(const struct list_head *__p, struct uio_info *info)
+{
+	QMAN_UIO_PREAMBLE();
+	/* big enough for "qman-uio-xx" */
+	char *name = kzalloc(16, GFP_KERNEL);
+	if (!name)
+		return -ENOMEM;
+	sprintf(name, "qman-uio-%x", pcfg->public_cfg.index);
+	info->name = name;
+	info->mem[DPA_PORTAL_CE].name = "cena";
+	info->mem[DPA_PORTAL_CE].addr = pcfg->addr_phys[DPA_PORTAL_CE].start;
+	info->mem[DPA_PORTAL_CE].size =
+		resource_size(&pcfg->addr_phys[DPA_PORTAL_CE]);
+	info->mem[DPA_PORTAL_CE].memtype = UIO_MEM_PHYS;
+	info->mem[DPA_PORTAL_CI].name = "cinh";
+	info->mem[DPA_PORTAL_CI].addr = pcfg->addr_phys[DPA_PORTAL_CI].start;
+	info->mem[DPA_PORTAL_CI].size =
+		resource_size(&pcfg->addr_phys[DPA_PORTAL_CI]);
+	info->mem[DPA_PORTAL_CI].memtype = UIO_MEM_PHYS;
+	info->irq = pcfg->public_cfg.irq;
+	return 0;
+}
+static void qman_uio_cb_destroy(const struct list_head *__p,
+				struct uio_info *info)
+{
+	QMAN_UIO_PREAMBLE();
+	kfree(info->name);
+	/* We own this struct but had passed it to the dpa_uio layer as a const
+	 * so that we don't accidentally meddle with it in the dpa_uio code.
+	 * Here it's passed back to us for final clean it up, so de-constify. */
+	destroy_pcfg((struct qm_portal_config *)pcfg);
+}
+static int qman_uio_cb_open(const struct list_head *__p)
+{
+	QMAN_UIO_PREAMBLE();
+	/* Bind stashing LIODNs to the CPU we are currently executing on. The
+	 * user-space driver assumption is that the pthread has to already be
+	 * affine to one cpu only before opening a portal. If that check is
+	 * circumvented, the only risk is a performance degradation - stashing
+	 * will go to whatever cpu they happened to be running on when opening
+	 * the device file, and if that isn't the cpu they subsequently bind to
+	 * and do their polling on, tough. */
+	set_liodns(pcfg, hard_smp_processor_id());
+	return 0;
+}
+static void qman_uio_cb_close(const struct list_head *__p)
+{
+	QMAN_UIO_PREAMBLE();
+}
+static void qman_uio_cb_interrupt(const struct list_head *__p)
+{
+	QMAN_UIO_PREAMBLE();
+	/* This is the only manipulation of a portal register that isn't in the
+	 * regular kernel portal driver (_high.c/_low.h). It is also the only
+	 * time the kernel touches a register on a portal that is otherwise
+	 * being driven by a user-space driver. So rather than messing up
+	 * encapsulation for one trivial call, I am hard-coding the offset to
+	 * the inhibit register and writing it directly from here. */
+	out_be32(pcfg->addr_virt[DPA_PORTAL_CI] + 0xe0c, ~(u32)0);
+}
+static const struct dpa_uio_vtable qman_uio = {
+	.init_uio = qman_uio_cb_init,
+	.destroy = qman_uio_cb_destroy,
+	.on_open = qman_uio_cb_open,
+	.on_close = qman_uio_cb_close,
+	.on_interrupt = qman_uio_cb_interrupt
+};
+
 static struct qman_portal *init_pcfg(struct qm_portal_config *pcfg)
 {
 	struct qman_portal *p;
@@ -351,7 +430,19 @@ static __init int qman_init(void)
 		for_each_cpu(cpu, &slave_cpus)
 			init_slave(cpu);
 	pr_info("Qman portals initialised\n");
-
+#ifdef CONFIG_FSL_DPA_UIO
+	/* Export any left over portals as UIO devices */
+	do {
+		pcfg = get_pcfg(&unused_pcfgs);
+		if (!pcfg)
+			break;
+		ret = dpa_uio_register(&pcfg->list, &qman_uio);
+		if (ret) {
+			pr_err("Failure registering QMan UIO portal\n");
+			destroy_pcfg(pcfg);
+		}
+	} while (1);
+#endif
 	/* This is to ensure h/w-internal CGR memory is zeroed out. Note that we
 	 * do this for all conceivable CGRIDs, not all of which are necessarily
 	 * available on the underlying hardware version. We ignore any errors
-- 
1.7.9.7

