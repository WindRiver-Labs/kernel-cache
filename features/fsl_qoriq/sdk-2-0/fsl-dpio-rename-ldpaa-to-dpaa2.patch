From b2e841741de41cbacb3e0ce49233014b955d8e28 Mon Sep 17 00:00:00 2001
From: Haiying Wang <Haiying.wang@freescale.com>
Date: Thu, 5 Nov 2015 12:04:32 -0500
Subject: [PATCH 0659/1429] fsl/dpio: rename ldpaa to dpaa2

Signed-off-by: Haiying Wang <Haiying.wang@freescale.com>
(Stuart: removed eth part out into separate patch)
Signed-off-by: Stuart Yoder <stuart.yoder@nxp.com>
[Original patch taken from QorIQ-SDK-V2.0-20160527-yocto]
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 drivers/staging/fsl-mc/bus/dpio/dpio-drv.c         |   58 +-
 drivers/staging/fsl-mc/bus/dpio/dpio-drv.h         |    4 +-
 drivers/staging/fsl-mc/bus/dpio/dpio_service.c     |  240 +++++-----
 drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h |   58 +-
 drivers/staging/fsl-mc/bus/dpio/qbman_portal.c     |   84 ++--
 drivers/staging/fsl-mc/bus/dpio/qbman_portal.h     |    4 +-
 drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h      |  471 +++++++++++++++++
 drivers/staging/fsl-mc/include/fsl_dpaa2_io.h      |  554 ++++++++++++++++++++
 drivers/staging/fsl-mc/include/fsl_dpaa_fd.h       |  470 -----------------
 drivers/staging/fsl-mc/include/fsl_dpaa_io.h       |  554 --------------------
 10 files changed, 1249 insertions(+), 1248 deletions(-)
 create mode 100644 drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h
 create mode 100644 drivers/staging/fsl-mc/include/fsl_dpaa2_io.h
 delete mode 100644 drivers/staging/fsl-mc/include/fsl_dpaa_fd.h
 delete mode 100644 drivers/staging/fsl-mc/include/fsl_dpaa_io.h

diff --git a/drivers/staging/fsl-mc/bus/dpio/dpio-drv.c b/drivers/staging/fsl-mc/bus/dpio/dpio-drv.c
index dbf1a45..dce28d5 100644
--- a/drivers/staging/fsl-mc/bus/dpio/dpio-drv.c
+++ b/drivers/staging/fsl-mc/bus/dpio/dpio-drv.c
@@ -39,7 +39,7 @@
 #include <linux/delay.h>
 
 #include "../../include/mc.h"
-#include "../../include/fsl_dpaa_io.h"
+#include "../../include/fsl_dpaa2_io.h"
 
 #include "fsl_qbman_portal.h"
 #include "fsl_dpio.h"
@@ -56,20 +56,20 @@ MODULE_DESCRIPTION(DPIO_DESCRIPTION);
 #define MAX_DPIO_IRQ_NAME 16 /* Big enough for "FSL DPIO %d" */
 
 struct dpio_priv {
-	struct dpaa_io *io;
+	struct dpaa2_io *io;
 	char irq_name[MAX_DPIO_IRQ_NAME];
 	struct task_struct *thread;
 };
 
 static int dpio_thread(void *data)
 {
-	struct dpaa_io *io = data;
+	struct dpaa2_io *io = data;
 
 	while (!kthread_should_stop()) {
-		int err = dpaa_io_poll(io);
+		int err = dpaa2_io_poll(io);
 
 		if (err) {
-			pr_err("dpaa_io_poll() failed\n");
+			pr_err("dpaa2_io_poll() failed\n");
 			return err;
 		}
 		msleep(50);
@@ -82,7 +82,7 @@ static irqreturn_t dpio_irq_handler(int irq_num, void *arg)
 	struct device *dev = (struct device *)arg;
 	struct dpio_priv *priv = dev_get_drvdata(dev);
 
-	return dpaa_io_irq(priv->io);
+	return dpaa2_io_irq(priv->io);
 }
 
 static void unregister_dpio_irq_handlers(struct fsl_mc_device *ls_dev)
@@ -150,14 +150,14 @@ error_unregister_irq_handlers:
 }
 
 static int __cold
-ldpaa_dpio_probe(struct fsl_mc_device *ls_dev)
+dpaa2_dpio_probe(struct fsl_mc_device *ls_dev)
 {
 	struct dpio_attr dpio_attrs;
-	struct dpaa_io_desc desc;
+	struct dpaa2_io_desc desc;
 	struct dpio_priv *priv;
 	int err = -ENOMEM;
 	struct device *dev = &ls_dev->dev;
-	struct dpaa_io *defservice;
+	struct dpaa2_io *defservice;
 	bool irq_allocated = false;
 	static int next_cpu;
 
@@ -233,10 +233,10 @@ ldpaa_dpio_probe(struct fsl_mc_device *ls_dev)
 			desc.has_irq = 0;
 	}
 
-	priv->io = dpaa_io_create(&desc);
+	priv->io = dpaa2_io_create(&desc);
 	if (!priv->io) {
 		dev_err(dev, "DPIO setup failed\n");
-		goto err_dpaa_io_create;
+		goto err_dpaa2_io_create;
 	}
 
 	/* If no irq then go to poll mode */
@@ -270,12 +270,12 @@ ldpaa_dpio_probe(struct fsl_mc_device *ls_dev)
 		wake_up_process(priv->thread);
 	}
 
-	defservice = dpaa_io_default_service();
-	err = dpaa_io_service_add(defservice, priv->io);
-	dpaa_io_down(defservice);
+	defservice = dpaa2_io_default_service();
+	err = dpaa2_io_service_add(defservice, priv->io);
+	dpaa2_io_down(defservice);
 	if (err) {
 		dev_err(dev, "DPIO add-to-service failed\n");
-		goto err_dpaa_io_add;
+		goto err_dpaa2_io_add;
 	}
 
 	dev_info(dev, "dpio: probed object %d\n", ls_dev->obj_desc.id);
@@ -286,14 +286,14 @@ ldpaa_dpio_probe(struct fsl_mc_device *ls_dev)
 	fsl_mc_portal_free(ls_dev->mc_io);
 	return 0;
 
-err_dpaa_io_add:
+err_dpaa2_io_add:
 	unregister_dpio_irq_handlers(ls_dev);
 /* TEMP: To be restored once polling is removed
   err_register_dpio_irq:
 	fsl_mc_free_irqs(ls_dev);
 */
 err_dpaa_thread:
-err_dpaa_io_create:
+err_dpaa2_io_create:
 	dpio_disable(ls_dev->mc_io, 0, ls_dev->mc_handle);
 err_get_attr:
 	dpio_close(ls_dev->mc_io, 0, ls_dev->mc_handle);
@@ -317,7 +317,7 @@ static void dpio_teardown_irqs(struct fsl_mc_device *ls_dev)
 }
 
 static int __cold
-ldpaa_dpio_remove(struct fsl_mc_device *ls_dev)
+dpaa2_dpio_remove(struct fsl_mc_device *ls_dev)
 {
 	struct device *dev;
 	struct dpio_priv *priv;
@@ -350,7 +350,7 @@ ldpaa_dpio_remove(struct fsl_mc_device *ls_dev)
 	}
 
 	dev_set_drvdata(dev, NULL);
-	dpaa_io_down(priv->io);
+	dpaa2_io_down(priv->io);
 
 	err = 0;
 
@@ -362,7 +362,7 @@ err_mcportal:
 	return err;
 }
 
-static const struct fsl_mc_device_match_id ldpaa_dpio_match_id_table[] = {
+static const struct fsl_mc_device_match_id dpaa2_dpio_match_id_table[] = {
 	{
 		.vendor = FSL_MC_VENDOR_FREESCALE,
 		.obj_type = "dpio",
@@ -372,32 +372,32 @@ static const struct fsl_mc_device_match_id ldpaa_dpio_match_id_table[] = {
 	{ .vendor = 0x0 }
 };
 
-static struct fsl_mc_driver ldpaa_dpio_driver = {
+static struct fsl_mc_driver dpaa2_dpio_driver = {
 	.driver = {
 		.name		= KBUILD_MODNAME,
 		.owner		= THIS_MODULE,
 	},
-	.probe		= ldpaa_dpio_probe,
-	.remove		= ldpaa_dpio_remove,
-	.match_id_table = ldpaa_dpio_match_id_table
+	.probe		= dpaa2_dpio_probe,
+	.remove		= dpaa2_dpio_remove,
+	.match_id_table = dpaa2_dpio_match_id_table
 };
 
 static int dpio_driver_init(void)
 {
 	int err;
 
-	err = dpaa_io_service_driver_init();
+	err = dpaa2_io_service_driver_init();
 	if (!err) {
-		err = fsl_mc_driver_register(&ldpaa_dpio_driver);
+		err = fsl_mc_driver_register(&dpaa2_dpio_driver);
 		if (err)
-			dpaa_io_service_driver_exit();
+			dpaa2_io_service_driver_exit();
 	}
 	return err;
 }
 static void dpio_driver_exit(void)
 {
-	fsl_mc_driver_unregister(&ldpaa_dpio_driver);
-	dpaa_io_service_driver_exit();
+	fsl_mc_driver_unregister(&dpaa2_dpio_driver);
+	dpaa2_io_service_driver_exit();
 }
 module_init(dpio_driver_init);
 module_exit(dpio_driver_exit);
diff --git a/drivers/staging/fsl-mc/bus/dpio/dpio-drv.h b/drivers/staging/fsl-mc/bus/dpio/dpio-drv.h
index 24707ee..fe8d40b 100644
--- a/drivers/staging/fsl-mc/bus/dpio/dpio-drv.h
+++ b/drivers/staging/fsl-mc/bus/dpio/dpio-drv.h
@@ -29,5 +29,5 @@
  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
-int dpaa_io_service_driver_init(void);
-void dpaa_io_service_driver_exit(void);
+int dpaa2_io_service_driver_init(void);
+void dpaa2_io_service_driver_exit(void);
diff --git a/drivers/staging/fsl-mc/bus/dpio/dpio_service.c b/drivers/staging/fsl-mc/bus/dpio/dpio_service.c
index e0e5cc8..7cb0333f 100644
--- a/drivers/staging/fsl-mc/bus/dpio/dpio_service.c
+++ b/drivers/staging/fsl-mc/bus/dpio/dpio_service.c
@@ -31,7 +31,7 @@
 #include <linux/types.h>
 #include "fsl_qbman_portal.h"
 #include "../../include/mc.h"
-#include "../../include/fsl_dpaa_io.h"
+#include "../../include/fsl_dpaa2_io.h"
 #include "fsl_dpio.h"
 #include <linux/init.h>
 #include <linux/module.h>
@@ -48,22 +48,22 @@
 #define MAGIC_SERVICE 0xabcd9876
 #define MAGIC_OBJECT 0x1234fedc
 
-struct dpaa_io {
+struct dpaa2_io {
 	/* If MAGIC_SERVICE, this is a group of objects, use the 'service' part
 	 * of the union. If MAGIC_OBJECT, use the 'object' part of the union. If
 	 * it's neither, something got corrupted. This is mainly to satisfy
-	 * dpaa_io_from_registration(), which dereferences a caller-instantiated
-	 * struct and so warrants a bug-checking step - hence the magic rather
-	 * than a boolean.
+	 * dpaa2_io_from_registration(), which dereferences a caller-
+	 * instantiated struct and so warrants a bug-checking step - hence the
+	 * magic rather than a boolean.
 	 */
 	unsigned int magic;
 	atomic_t refs;
 	union {
-		struct dpaa_io_service {
+		struct dpaa2_io_service {
 			spinlock_t lock;
 			struct list_head list;
-			/* for targeted dpaa_io selection */
-			struct dpaa_io *objects_by_cpu[NR_CPUS];
+			/* for targeted dpaa2_io selection */
+			struct dpaa2_io *objects_by_cpu[NR_CPUS];
 			cpumask_t cpus_notifications;
 			cpumask_t cpus_stashing;
 			int has_nonaffine;
@@ -72,13 +72,13 @@ struct dpaa_io {
 			 * need to avoid a kfree() ... */
 			int is_defservice;
 		} service;
-		struct dpaa_io_object {
-			struct dpaa_io_desc dpio_desc;
+		struct dpaa2_io_object {
+			struct dpaa2_io_desc dpio_desc;
 			struct qbman_swp_desc swp_desc;
 			struct qbman_swp *swp;
 			/* If the object is part of a service, this is it (and
 			 * 'node' is linked into the service's list) */
-			struct dpaa_io *service;
+			struct dpaa2_io *service;
 			struct list_head node;
 			/* Interrupt mask, as used with
 			 * qbman_swp_interrupt_[gs]et_vanish(). This isn't
@@ -98,10 +98,10 @@ struct dpaa_io {
 	};
 };
 
-struct dpaa_io_store {
+struct dpaa2_io_store {
 	unsigned int max;
 	dma_addr_t paddr;
-	struct ldpaa_dq *vaddr;
+	struct dpaa2_dq *vaddr;
 	void *alloced_addr; /* the actual return from kmalloc as it may
 			       be adjusted for alignment purposes */
 	unsigned int idx; /* position of the next-to-be-returned entry */
@@ -109,15 +109,15 @@ struct dpaa_io_store {
 	struct device *dev; /* device used for DMA mapping */
 };
 
-static struct dpaa_io def_serv;
+static struct dpaa2_io def_serv;
 
 /**********************/
 /* Internal functions */
 /**********************/
 
-static void service_init(struct dpaa_io *d, int is_defservice)
+static void service_init(struct dpaa2_io *d, int is_defservice)
 {
-	struct dpaa_io_service *s = &d->service;
+	struct dpaa2_io_service *s = &d->service;
 
 	d->magic = MAGIC_SERVICE;
 	atomic_set(&d->refs, 1);
@@ -130,13 +130,13 @@ static void service_init(struct dpaa_io *d, int is_defservice)
 }
 
 /* Selection algorithms, stupid ones at that. These are to handle the case where
- * the given dpaa_io is a service, by choosing the non-service dpaa_io within it
- * to use.
+ * the given dpaa2_io is a service, by choosing the non-service dpaa2_io within
+ * it to use.
  */
-static struct dpaa_io *_service_select_by_cpu_slow(struct dpaa_io_service *ss,
+static struct dpaa2_io *_service_select_by_cpu_slow(struct dpaa2_io_service *ss,
 						   int cpu)
 {
-	struct dpaa_io *o;
+	struct dpaa2_io *o;
 	unsigned long irqflags;
 
 	spin_lock_irqsave(&ss->lock, irqflags);
@@ -156,7 +156,7 @@ static struct dpaa_io *_service_select_by_cpu_slow(struct dpaa_io_service *ss,
 
 	/* No joy. Try the first object. Told you it was horrible. */
 	if (!list_empty(&ss->list))
-		o = list_entry(ss->list.next, struct dpaa_io, object.node);
+		o = list_entry(ss->list.next, struct dpaa2_io, object.node);
 	else
 		o = NULL;
 
@@ -165,9 +165,9 @@ found:
 	return o;
 }
 
-static struct dpaa_io *service_select_by_cpu(struct dpaa_io *d, int cpu)
+static struct dpaa2_io *service_select_by_cpu(struct dpaa2_io *d, int cpu)
 {
-	struct dpaa_io_service *ss;
+	struct dpaa2_io_service *ss;
 	unsigned long irqflags;
 
 	if (!d)
@@ -193,10 +193,10 @@ static struct dpaa_io *service_select_by_cpu(struct dpaa_io *d, int cpu)
 	return ss->objects_by_cpu[cpu];
 }
 
-static inline struct dpaa_io *service_select_any(struct dpaa_io *d)
+static inline struct dpaa2_io *service_select_any(struct dpaa2_io *d)
 {
-	struct dpaa_io_service *ss;
-	struct dpaa_io *o;
+	struct dpaa2_io_service *ss;
+	struct dpaa2_io *o;
 	unsigned long irqflags;
 
 	if (!d)
@@ -216,7 +216,7 @@ static inline struct dpaa_io *service_select_any(struct dpaa_io *d)
 	ss = &d->service;
 	spin_lock_irqsave(&ss->lock, irqflags);
 	if (!list_empty(&ss->list)) {
-		o = list_entry(ss->list.next, struct dpaa_io, object.node);
+		o = list_entry(ss->list.next, struct dpaa2_io, object.node);
 		list_del(&o->object.node);
 		list_add_tail(&o->object.node, &ss->list);
 	} else
@@ -228,9 +228,9 @@ static inline struct dpaa_io *service_select_any(struct dpaa_io *d)
 /* If the context is not preemptible, select the service affine to the
  * current cpu. Otherwise, "select any".
  */
-static inline struct dpaa_io *_service_select(struct dpaa_io *d)
+static inline struct dpaa2_io *_service_select(struct dpaa2_io *d)
 {
-	struct dpaa_io *temp = d;
+	struct dpaa2_io *temp = d;
 
 	if (likely(!preemptible())) {
 		d = service_select_by_cpu(d, smp_processor_id());
@@ -244,10 +244,10 @@ static inline struct dpaa_io *_service_select(struct dpaa_io *d)
 /* Exported functions */
 /**********************/
 
-struct dpaa_io *dpaa_io_create(const struct dpaa_io_desc *desc)
+struct dpaa2_io *dpaa2_io_create(const struct dpaa2_io_desc *desc)
 {
-	struct dpaa_io *ret = kmalloc(sizeof(*ret), GFP_KERNEL);
-	struct dpaa_io_object *o = &ret->object;
+	struct dpaa2_io *ret = kmalloc(sizeof(*ret), GFP_KERNEL);
+	struct dpaa2_io_object *o = &ret->object;
 
 	if (!ret)
 		return NULL;
@@ -278,26 +278,26 @@ struct dpaa_io *dpaa_io_create(const struct dpaa_io_desc *desc)
 		qbman_swp_push_set(o->swp, 0, 1);
 	return ret;
 }
-EXPORT_SYMBOL(dpaa_io_create);
+EXPORT_SYMBOL(dpaa2_io_create);
 
-struct dpaa_io *dpaa_io_create_service(void)
+struct dpaa2_io *dpaa2_io_create_service(void)
 {
-	struct dpaa_io *ret = kmalloc(sizeof(*ret), GFP_KERNEL);
+	struct dpaa2_io *ret = kmalloc(sizeof(*ret), GFP_KERNEL);
 
 	if (ret)
 		service_init(ret, 0);
 	return ret;
 }
-EXPORT_SYMBOL(dpaa_io_create_service);
+EXPORT_SYMBOL(dpaa2_io_create_service);
 
-struct dpaa_io *dpaa_io_default_service(void)
+struct dpaa2_io *dpaa2_io_default_service(void)
 {
 	atomic_inc(&def_serv.refs);
 	return &def_serv;
 }
-EXPORT_SYMBOL(dpaa_io_default_service);
+EXPORT_SYMBOL(dpaa2_io_default_service);
 
-void dpaa_io_down(struct dpaa_io *d)
+void dpaa2_io_down(struct dpaa2_io *d)
 {
 	if (!atomic_dec_and_test(&d->refs))
 		return;
@@ -313,12 +313,12 @@ void dpaa_io_down(struct dpaa_io *d)
 	}
 	kfree(d);
 }
-EXPORT_SYMBOL(dpaa_io_down);
+EXPORT_SYMBOL(dpaa2_io_down);
 
-int dpaa_io_service_add(struct dpaa_io *s, struct dpaa_io *o)
+int dpaa2_io_service_add(struct dpaa2_io *s, struct dpaa2_io *o)
 {
-	struct dpaa_io_service *ss = &s->service;
-	struct dpaa_io_object *oo = &o->object;
+	struct dpaa2_io_service *ss = &s->service;
+	struct dpaa2_io_object *oo = &o->object;
 	int res = -EINVAL;
 
 	if ((s->magic != MAGIC_SERVICE) || (o->magic != MAGIC_OBJECT))
@@ -335,7 +335,7 @@ int dpaa_io_service_add(struct dpaa_io *s, struct dpaa_io *o)
 					&ss->cpus_notifications);
 			/* Update the fast-access array */
 			ss->objects_by_cpu[oo->dpio_desc.cpu] =
-				container_of(oo, struct dpaa_io, object);
+				container_of(oo, struct dpaa2_io, object);
 		}
 		if (oo->dpio_desc.stash_affinity)
 			cpumask_set_cpu(oo->dpio_desc.cpu,
@@ -347,14 +347,14 @@ int dpaa_io_service_add(struct dpaa_io *s, struct dpaa_io *o)
 	}
 	spin_unlock(&ss->lock);
 	if (res) {
-		dpaa_io_down(s);
-		dpaa_io_down(o);
+		dpaa2_io_down(s);
+		dpaa2_io_down(o);
 	}
 	return res;
 }
-EXPORT_SYMBOL(dpaa_io_service_add);
+EXPORT_SYMBOL(dpaa2_io_service_add);
 
-int dpaa_io_get_descriptor(struct dpaa_io *obj, struct dpaa_io_desc *desc)
+int dpaa2_io_get_descriptor(struct dpaa2_io *obj, struct dpaa2_io_desc *desc)
 {
 	if (obj->magic == MAGIC_SERVICE)
 		return -EINVAL;
@@ -362,13 +362,13 @@ int dpaa_io_get_descriptor(struct dpaa_io *obj, struct dpaa_io_desc *desc)
 	*desc = obj->object.dpio_desc;
 	return 0;
 }
-EXPORT_SYMBOL(dpaa_io_get_descriptor);
+EXPORT_SYMBOL(dpaa2_io_get_descriptor);
 
 #define DPAA_POLL_MAX 32
 
-int dpaa_io_poll(struct dpaa_io *obj)
+int dpaa2_io_poll(struct dpaa2_io *obj)
 {
-	const struct ldpaa_dq *dq;
+	const struct dpaa2_dq *dq;
 	struct qbman_swp *swp;
 	int max = 0;
 
@@ -378,7 +378,7 @@ int dpaa_io_poll(struct dpaa_io *obj)
 	dq = qbman_swp_dqrr_next(swp);
 	while (dq) {
 		if (qbman_result_is_SCN(dq)) {
-			struct dpaa_io_notification_ctx *ctx;
+			struct dpaa2_io_notification_ctx *ctx;
 			uint64_t q64;
 
 			q64 = qbman_result_SCN_ctx(dq);
@@ -394,9 +394,9 @@ int dpaa_io_poll(struct dpaa_io *obj)
 	}
 	return 0;
 }
-EXPORT_SYMBOL(dpaa_io_poll);
+EXPORT_SYMBOL(dpaa2_io_poll);
 
-int dpaa_io_irq(struct dpaa_io *obj)
+int dpaa2_io_irq(struct dpaa2_io *obj)
 {
 	struct qbman_swp *swp;
 	uint32_t status;
@@ -407,56 +407,56 @@ int dpaa_io_irq(struct dpaa_io *obj)
 	status = qbman_swp_interrupt_read_status(swp);
 	if (!status)
 		return IRQ_NONE;
-	dpaa_io_poll(obj);
+	dpaa2_io_poll(obj);
 	qbman_swp_interrupt_clear_status(swp, status);
 	qbman_swp_interrupt_set_inhibit(swp, 0);
 	return IRQ_HANDLED;
 }
-EXPORT_SYMBOL(dpaa_io_irq);
+EXPORT_SYMBOL(dpaa2_io_irq);
 
-int dpaa_io_pause_poll(struct dpaa_io *obj)
+int dpaa2_io_pause_poll(struct dpaa2_io *obj)
 {
 	UNIMPLEMENTED();
 	return -EINVAL;
 }
-EXPORT_SYMBOL(dpaa_io_pause_poll);
+EXPORT_SYMBOL(dpaa2_io_pause_poll);
 
-int dpaa_io_resume_poll(struct dpaa_io *obj)
+int dpaa2_io_resume_poll(struct dpaa2_io *obj)
 {
 	UNIMPLEMENTED();
 	return -EINVAL;
 }
-EXPORT_SYMBOL(dpaa_io_resume_poll);
+EXPORT_SYMBOL(dpaa2_io_resume_poll);
 
-void dpaa_io_service_notifications(struct dpaa_io *s, cpumask_t *mask)
+void dpaa2_io_service_notifications(struct dpaa2_io *s, cpumask_t *mask)
 {
-	struct dpaa_io_service *ss = &s->service;
+	struct dpaa2_io_service *ss = &s->service;
 
 	BUG_ON(s->magic != MAGIC_SERVICE);
 	cpumask_copy(mask, &ss->cpus_notifications);
 }
-EXPORT_SYMBOL(dpaa_io_service_notifications);
+EXPORT_SYMBOL(dpaa2_io_service_notifications);
 
-void dpaa_io_service_stashing(struct dpaa_io *s, cpumask_t *mask)
+void dpaa2_io_service_stashing(struct dpaa2_io *s, cpumask_t *mask)
 {
-	struct dpaa_io_service *ss = &s->service;
+	struct dpaa2_io_service *ss = &s->service;
 
 	BUG_ON(s->magic != MAGIC_SERVICE);
 	cpumask_copy(mask, &ss->cpus_stashing);
 }
-EXPORT_SYMBOL(dpaa_io_service_stashing);
+EXPORT_SYMBOL(dpaa2_io_service_stashing);
 
-int dpaa_io_service_has_nonaffine(struct dpaa_io *s)
+int dpaa2_io_service_has_nonaffine(struct dpaa2_io *s)
 {
-	struct dpaa_io_service *ss = &s->service;
+	struct dpaa2_io_service *ss = &s->service;
 
 	BUG_ON(s->magic != MAGIC_SERVICE);
 	return ss->has_nonaffine;
 }
-EXPORT_SYMBOL(dpaa_io_service_has_nonaffine);
+EXPORT_SYMBOL(dpaa2_io_service_has_nonaffine);
 
-int dpaa_io_service_register(struct dpaa_io *d,
-			     struct dpaa_io_notification_ctx *ctx)
+int dpaa2_io_service_register(struct dpaa2_io *d,
+			     struct dpaa2_io_notification_ctx *ctx)
 {
 	unsigned long irqflags;
 
@@ -476,12 +476,12 @@ int dpaa_io_service_register(struct dpaa_io *d,
 						  ctx->qman64);
 	return 0;
 }
-EXPORT_SYMBOL(dpaa_io_service_register);
+EXPORT_SYMBOL(dpaa2_io_service_register);
 
-int dpaa_io_service_deregister(struct dpaa_io *service,
-			       struct dpaa_io_notification_ctx *ctx)
+int dpaa2_io_service_deregister(struct dpaa2_io *service,
+			       struct dpaa2_io_notification_ctx *ctx)
 {
-	struct dpaa_io *d = ctx->dpio_private;
+	struct dpaa2_io *d = ctx->dpio_private;
 	unsigned long irqflags;
 
 	if (!service)
@@ -495,10 +495,10 @@ int dpaa_io_service_deregister(struct dpaa_io *service,
 	spin_unlock_irqrestore(&d->object.lock_notifications, irqflags);
 	return 0;
 }
-EXPORT_SYMBOL(dpaa_io_service_deregister);
+EXPORT_SYMBOL(dpaa2_io_service_deregister);
 
-int dpaa_io_service_rearm(struct dpaa_io *d,
-			  struct dpaa_io_notification_ctx *ctx)
+int dpaa2_io_service_rearm(struct dpaa2_io *d,
+			  struct dpaa2_io_notification_ctx *ctx)
 {
 	unsigned long irqflags;
 	int err;
@@ -514,13 +514,13 @@ int dpaa_io_service_rearm(struct dpaa_io *d,
 	spin_unlock_irqrestore(&d->object.lock_mgmt_cmd, irqflags);
 	return err;
 }
-EXPORT_SYMBOL(dpaa_io_service_rearm);
+EXPORT_SYMBOL(dpaa2_io_service_rearm);
 
-int dpaa_io_from_registration(struct dpaa_io_notification_ctx *ctx,
-			      struct dpaa_io **io)
+int dpaa2_io_from_registration(struct dpaa2_io_notification_ctx *ctx,
+			      struct dpaa2_io **io)
 {
-	struct dpaa_io_notification_ctx *tmp;
-	struct dpaa_io *d = ctx->dpio_private;
+	struct dpaa2_io_notification_ctx *tmp;
+	struct dpaa2_io *d = ctx->dpio_private;
 	unsigned long irqflags;
 	int ret = 0;
 
@@ -540,10 +540,10 @@ found:
 	}
 	return ret;
 }
-EXPORT_SYMBOL(dpaa_io_from_registration);
+EXPORT_SYMBOL(dpaa2_io_from_registration);
 
-int dpaa_io_service_get_persistent(struct dpaa_io *service, int cpu,
-				   struct dpaa_io **ret)
+int dpaa2_io_service_get_persistent(struct dpaa2_io *service, int cpu,
+				   struct dpaa2_io **ret)
 {
 	if (cpu == -1)
 		*ret = service_select_any(service);
@@ -555,10 +555,10 @@ int dpaa_io_service_get_persistent(struct dpaa_io *service, int cpu,
 	}
 	return -ENODEV;
 }
-EXPORT_SYMBOL(dpaa_io_service_get_persistent);
+EXPORT_SYMBOL(dpaa2_io_service_get_persistent);
 
-int dpaa_io_service_pull_fq(struct dpaa_io *d, uint32_t fqid,
-			    struct dpaa_io_store *s)
+int dpaa2_io_service_pull_fq(struct dpaa2_io *d, uint32_t fqid,
+			    struct dpaa2_io_store *s)
 {
 	struct qbman_pull_desc pd;
 	int err;
@@ -576,10 +576,10 @@ int dpaa_io_service_pull_fq(struct dpaa_io *d, uint32_t fqid,
 		s->swp = NULL;
 	return err;
 }
-EXPORT_SYMBOL(dpaa_io_service_pull_fq);
+EXPORT_SYMBOL(dpaa2_io_service_pull_fq);
 
-int dpaa_io_service_pull_channel(struct dpaa_io *d, uint32_t channelid,
-				 struct dpaa_io_store *s)
+int dpaa2_io_service_pull_channel(struct dpaa2_io *d, uint32_t channelid,
+				 struct dpaa2_io_store *s)
 {
 	struct qbman_pull_desc pd;
 	int err;
@@ -597,9 +597,9 @@ int dpaa_io_service_pull_channel(struct dpaa_io *d, uint32_t channelid,
 		s->swp = NULL;
 	return err;
 }
-EXPORT_SYMBOL(dpaa_io_service_pull_channel);
+EXPORT_SYMBOL(dpaa2_io_service_pull_channel);
 
-int dpaa_io_service_enqueue_fq(struct dpaa_io *d,
+int dpaa2_io_service_enqueue_fq(struct dpaa2_io *d,
 			       uint32_t fqid,
 			       const struct dpaa_fd *fd)
 {
@@ -614,9 +614,9 @@ int dpaa_io_service_enqueue_fq(struct dpaa_io *d,
 	return qbman_swp_enqueue(d->object.swp, &ed,
 				 (const struct qbman_fd *)fd);
 }
-EXPORT_SYMBOL(dpaa_io_service_enqueue_fq);
+EXPORT_SYMBOL(dpaa2_io_service_enqueue_fq);
 
-int dpaa_io_service_enqueue_qd(struct dpaa_io *d,
+int dpaa2_io_service_enqueue_qd(struct dpaa2_io *d,
 			       uint32_t qdid, uint8_t prio, uint16_t qdbin,
 			       const struct dpaa_fd *fd)
 {
@@ -631,9 +631,9 @@ int dpaa_io_service_enqueue_qd(struct dpaa_io *d,
 	return qbman_swp_enqueue(d->object.swp, &ed,
 				 (const struct qbman_fd *)fd);
 }
-EXPORT_SYMBOL(dpaa_io_service_enqueue_qd);
+EXPORT_SYMBOL(dpaa2_io_service_enqueue_qd);
 
-int dpaa_io_service_release(struct dpaa_io *d,
+int dpaa2_io_service_release(struct dpaa2_io *d,
 			    uint32_t bpid,
 			    const uint64_t *buffers,
 			    unsigned int num_buffers)
@@ -647,9 +647,9 @@ int dpaa_io_service_release(struct dpaa_io *d,
 	qbman_release_desc_set_bpid(&rd, bpid);
 	return qbman_swp_release(d->object.swp, &rd, buffers, num_buffers);
 }
-EXPORT_SYMBOL(dpaa_io_service_release);
+EXPORT_SYMBOL(dpaa2_io_service_release);
 
-int dpaa_io_service_acquire(struct dpaa_io *d,
+int dpaa2_io_service_acquire(struct dpaa2_io *d,
 			    uint32_t bpid,
 			    uint64_t *buffers,
 			    unsigned int num_buffers)
@@ -665,19 +665,19 @@ int dpaa_io_service_acquire(struct dpaa_io *d,
 	spin_unlock_irqrestore(&d->object.lock_mgmt_cmd, irqflags);
 	return err;
 }
-EXPORT_SYMBOL(dpaa_io_service_acquire);
+EXPORT_SYMBOL(dpaa2_io_service_acquire);
 
-struct dpaa_io_store *dpaa_io_store_create(unsigned int max_frames,
+struct dpaa2_io_store *dpaa2_io_store_create(unsigned int max_frames,
 					   struct device *dev)
 {
-	struct dpaa_io_store *ret = kmalloc(sizeof(*ret), GFP_KERNEL);
+	struct dpaa2_io_store *ret = kmalloc(sizeof(*ret), GFP_KERNEL);
 	size_t size;
 
 	BUG_ON(!max_frames || (max_frames > 16));
 	if (!ret)
 		return NULL;
 	ret->max = max_frames;
-	size = max_frames * sizeof(struct ldpaa_dq) + 64;
+	size = max_frames * sizeof(struct dpaa2_dq) + 64;
 	ret->alloced_addr = kmalloc(size, GFP_KERNEL);
 	if (!ret->alloced_addr) {
 		kfree(ret);
@@ -685,7 +685,7 @@ struct dpaa_io_store *dpaa_io_store_create(unsigned int max_frames,
 	}
 	ret->vaddr =  PTR_ALIGN(ret->alloced_addr, 64);
 	ret->paddr = dma_map_single(dev, ret->vaddr,
-				    sizeof(struct ldpaa_dq) * max_frames,
+				    sizeof(struct dpaa2_dq) * max_frames,
 				    DMA_FROM_DEVICE);
 	if (dma_mapping_error(dev, ret->paddr)) {
 		kfree(ret->alloced_addr);
@@ -696,21 +696,21 @@ struct dpaa_io_store *dpaa_io_store_create(unsigned int max_frames,
 	ret->dev = dev;
 	return ret;
 }
-EXPORT_SYMBOL(dpaa_io_store_create);
+EXPORT_SYMBOL(dpaa2_io_store_create);
 
-void dpaa_io_store_destroy(struct dpaa_io_store *s)
+void dpaa2_io_store_destroy(struct dpaa2_io_store *s)
 {
-	dma_unmap_single(s->dev, s->paddr, sizeof(struct ldpaa_dq) * s->max,
+	dma_unmap_single(s->dev, s->paddr, sizeof(struct dpaa2_dq) * s->max,
 			 DMA_FROM_DEVICE);
 	kfree(s->alloced_addr);
 	kfree(s);
 }
-EXPORT_SYMBOL(dpaa_io_store_destroy);
+EXPORT_SYMBOL(dpaa2_io_store_destroy);
 
-struct ldpaa_dq *dpaa_io_store_next(struct dpaa_io_store *s, int *is_last)
+struct dpaa2_dq *dpaa2_io_store_next(struct dpaa2_io_store *s, int *is_last)
 {
 	int match;
-	struct ldpaa_dq *ret = &s->vaddr[s->idx];
+	struct dpaa2_dq *ret = &s->vaddr[s->idx];
 
 	match = qbman_result_has_new_result(s->swp, ret);
 	if (!match) {
@@ -719,22 +719,22 @@ struct ldpaa_dq *dpaa_io_store_next(struct dpaa_io_store *s, int *is_last)
 	}
 	BUG_ON(!qbman_result_is_DQ(ret));
 	s->idx++;
-	if (ldpaa_dq_is_pull_complete(ret)) {
+	if (dpaa2_dq_is_pull_complete(ret)) {
 		*is_last = 1;
 		s->idx = 0;
 		/* If we get an empty dequeue result to terminate a zero-results
 		 * vdqcr, return NULL to the caller rather than expecting him to
 		 * check non-NULL results every time. */
-		if (!(ldpaa_dq_flags(ret) & LDPAA_DQ_STAT_VALIDFRAME))
+		if (!(dpaa2_dq_flags(ret) & DPAA2_DQ_STAT_VALIDFRAME))
 			ret = NULL;
 	} else
 		*is_last = 0;
 	return ret;
 }
-EXPORT_SYMBOL(dpaa_io_store_next);
+EXPORT_SYMBOL(dpaa2_io_store_next);
 
 #ifdef CONFIG_FSL_QBMAN_DEBUG
-int dpaa_io_query_fq_count(struct dpaa_io *d, uint32_t fqid,
+int dpaa2_io_query_fq_count(struct dpaa2_io *d, uint32_t fqid,
 			   uint32_t *fcnt, uint32_t *bcnt)
 {
 	struct qbman_attr state;
@@ -757,9 +757,9 @@ int dpaa_io_query_fq_count(struct dpaa_io *d, uint32_t fqid,
 
 	return 0;
 }
-EXPORT_SYMBOL(dpaa_io_query_fq_count);
+EXPORT_SYMBOL(dpaa2_io_query_fq_count);
 
-int dpaa_io_query_bp_count(struct dpaa_io *d, uint32_t bpid,
+int dpaa2_io_query_bp_count(struct dpaa2_io *d, uint32_t bpid,
 			   uint32_t *num)
 {
 	struct qbman_attr state;
@@ -780,20 +780,20 @@ int dpaa_io_query_bp_count(struct dpaa_io *d, uint32_t bpid,
 	*num = qbman_bp_info_num_free_bufs(&state);
 	return 0;
 }
-EXPORT_SYMBOL(dpaa_io_query_bp_count);
+EXPORT_SYMBOL(dpaa2_io_query_bp_count);
 
 #endif
 
 /* module init/exit hooks called from dpio-drv.c. These are declared in
  * dpio-drv.h.
  */
-int dpaa_io_service_driver_init(void)
+int dpaa2_io_service_driver_init(void)
 {
 	service_init(&def_serv, 1);
 	return 0;
 }
 
-void dpaa_io_service_driver_exit(void)
+void dpaa2_io_service_driver_exit(void)
 {
 	if (atomic_read(&def_serv.refs) != 1)
 		pr_err("default DPIO service leaves dangling DPIO objects!\n");
diff --git a/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h b/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h
index 3ec2c8c..e0ef31a 100644
--- a/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h
+++ b/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h
@@ -125,11 +125,11 @@ void qbman_swp_interrupt_set_inhibit(struct qbman_swp *p, int inhibit);
 	/************/
 
 /* See the QBMan driver API documentation for details on the enqueue
- * mechanisms. NB: the use of a 'ldpaa_' prefix for this type is because it is
+ * mechanisms. NB: the use of a 'dpaa2_' prefix for this type is because it is
  * primarily used by the "DPIO" layer that sits above (and hides) the QBMan
  * driver. The structure is defined in the DPIO interface, but to avoid circular
  * dependencies we just pre/re-declare it here opaquely. */
-struct ldpaa_dq;
+struct dpaa2_dq;
 
 /* ------------------- */
 /* Push-mode dequeuing */
@@ -197,7 +197,7 @@ void qbman_pull_desc_clear(struct qbman_pull_desc *d);
  * those writes to main-memory express a cache-warming attribute.
  */
 void qbman_pull_desc_set_storage(struct qbman_pull_desc *d,
-				 struct ldpaa_dq *storage,
+				 struct dpaa2_dq *storage,
 				 dma_addr_t storage_phys,
 				 int stash);
 /**
@@ -255,7 +255,7 @@ int qbman_swp_pull(struct qbman_swp *, struct qbman_pull_desc *d);
  * only once, so repeated calls can return a sequence of DQRR entries, without
  * requiring they be consumed immediately or in any particular order.
  */
-const struct ldpaa_dq *qbman_swp_dqrr_next(struct qbman_swp *s);
+const struct dpaa2_dq *qbman_swp_dqrr_next(struct qbman_swp *s);
 
 /**
  * qbman_swp_dqrr_consume() -  Consume DQRR entries previously returned from
@@ -263,7 +263,7 @@ const struct ldpaa_dq *qbman_swp_dqrr_next(struct qbman_swp *s);
  * @s: the software portal object.
  * @dq: the DQRR entry to be consumed.
  */
-void qbman_swp_dqrr_consume(struct qbman_swp *s, const struct ldpaa_dq *dq);
+void qbman_swp_dqrr_consume(struct qbman_swp *s, const struct dpaa2_dq *dq);
 
 /* ------------------------------------------------- */
 /* Polling user-provided storage for dequeue results */
@@ -288,7 +288,7 @@ void qbman_swp_dqrr_consume(struct qbman_swp *s, const struct ldpaa_dq *dq);
  * dequeue result.
  */
 int qbman_result_has_new_result(struct qbman_swp *,
-				  const struct ldpaa_dq *);
+				  const struct dpaa2_dq *);
 
 /* -------------------------------------------------------- */
 /* Parsing dequeue entries (DQRR and user-provided storage) */
@@ -300,7 +300,7 @@ int qbman_result_has_new_result(struct qbman_swp *,
  *
  * DQRR entries may contain non-dequeue results, ie. notifications
  */
-int qbman_result_is_DQ(const struct ldpaa_dq *);
+int qbman_result_is_DQ(const struct dpaa2_dq *);
 
 /**
  * qbman_result_is_SCN() - Check the dequeue result is notification or not
@@ -310,7 +310,7 @@ int qbman_result_is_DQ(const struct ldpaa_dq *);
  * notifications" of one type or another. Some APIs apply to all of them, of the
  * form qbman_result_SCN_***().
  */
-static inline int qbman_result_is_SCN(const struct ldpaa_dq *dq)
+static inline int qbman_result_is_SCN(const struct dpaa2_dq *dq)
 {
 	return !qbman_result_is_DQ(dq);
 }
@@ -319,49 +319,49 @@ static inline int qbman_result_is_SCN(const struct ldpaa_dq *dq)
  * Recognise different notification types, only required if the user allows for
  * these to occur, and cares about them when they do.
  */
-int qbman_result_is_FQDAN(const struct ldpaa_dq *);
+int qbman_result_is_FQDAN(const struct dpaa2_dq *);
 				/* FQ Data Availability */
-int qbman_result_is_CDAN(const struct ldpaa_dq *);
+int qbman_result_is_CDAN(const struct dpaa2_dq *);
 				/* Channel Data Availability */
-int qbman_result_is_CSCN(const struct ldpaa_dq *);
+int qbman_result_is_CSCN(const struct dpaa2_dq *);
 				/* Congestion State Change */
-int qbman_result_is_BPSCN(const struct ldpaa_dq *);
+int qbman_result_is_BPSCN(const struct dpaa2_dq *);
 				/* Buffer Pool State Change */
-int qbman_result_is_CGCU(const struct ldpaa_dq *);
+int qbman_result_is_CGCU(const struct dpaa2_dq *);
 				/* Congestion Group Count Update */
 /* Frame queue state change notifications; (FQDAN in theory counts too as it
  * leaves a FQ parked, but it is primarily a data availability notification) */
-int qbman_result_is_FQRN(const struct ldpaa_dq *); /* Retirement */
-int qbman_result_is_FQRNI(const struct ldpaa_dq *);
+int qbman_result_is_FQRN(const struct dpaa2_dq *); /* Retirement */
+int qbman_result_is_FQRNI(const struct dpaa2_dq *);
 				/* Retirement Immediate */
-int qbman_result_is_FQPN(const struct ldpaa_dq *); /* Park */
+int qbman_result_is_FQPN(const struct dpaa2_dq *); /* Park */
 
 /* NB: for parsing dequeue results (when "is_DQ" is TRUE), use the higher-layer
- * ldpaa_dq_*() functions. */
+ * dpaa2_dq_*() functions. */
 
 /* State-change notifications (FQDAN/CDAN/CSCN/...). */
 /**
  * qbman_result_SCN_state() - Get the state field in State-change notification
  */
-uint8_t qbman_result_SCN_state(const struct ldpaa_dq *);
+uint8_t qbman_result_SCN_state(const struct dpaa2_dq *);
 /**
  * qbman_result_SCN_rid() - Get the resource id in State-change notification
  */
-uint32_t qbman_result_SCN_rid(const struct ldpaa_dq *);
+uint32_t qbman_result_SCN_rid(const struct dpaa2_dq *);
 /**
  * qbman_result_SCN_ctx() - Get the context data in State-change notification
  */
-uint64_t qbman_result_SCN_ctx(const struct ldpaa_dq *);
+uint64_t qbman_result_SCN_ctx(const struct dpaa2_dq *);
 /**
  * qbman_result_SCN_state_in_mem() - Get the state field in State-change
  * notification which is written to memory instead of DQRR.
  */
-uint8_t qbman_result_SCN_state_in_mem(const struct ldpaa_dq *);
+uint8_t qbman_result_SCN_state_in_mem(const struct dpaa2_dq *);
 /**
  * qbman_result_SCN_rid_in_mem() - Get the resource id in State-change
  * notification which is written to memory instead of DQRR.
  */
-uint32_t qbman_result_SCN_rid_in_mem(const struct ldpaa_dq *);
+uint32_t qbman_result_SCN_rid_in_mem(const struct dpaa2_dq *);
 
 /* Type-specific "resource IDs". Mainly for illustration purposes, though it
  * also gives the appropriate type widths. */
@@ -377,34 +377,34 @@ uint32_t qbman_result_SCN_rid_in_mem(const struct ldpaa_dq *);
  *
  * Return the buffer pool id.
  */
-uint16_t qbman_result_bpscn_bpid(const struct ldpaa_dq *);
+uint16_t qbman_result_bpscn_bpid(const struct dpaa2_dq *);
 /**
  * qbman_result_bpscn_has_free_bufs() - Check whether there are free
  * buffers in the pool from BPSCN.
  *
  * Return the number of free buffers.
  */
-int qbman_result_bpscn_has_free_bufs(const struct ldpaa_dq *);
+int qbman_result_bpscn_has_free_bufs(const struct dpaa2_dq *);
 /**
  * qbman_result_bpscn_is_depleted() - Check BPSCN to see whether the
  * buffer pool is depleted.
  *
  * Return the status of buffer pool depletion.
  */
-int qbman_result_bpscn_is_depleted(const struct ldpaa_dq *);
+int qbman_result_bpscn_is_depleted(const struct dpaa2_dq *);
 /**
  * qbman_result_bpscn_is_surplus() - Check BPSCN to see whether the buffer
  * pool is surplus or not.
  *
  * Return the status of buffer pool surplus.
  */
-int qbman_result_bpscn_is_surplus(const struct ldpaa_dq *);
+int qbman_result_bpscn_is_surplus(const struct dpaa2_dq *);
 /**
  * qbman_result_bpscn_ctx() - Get the BPSCN CTX from BPSCN message
  *
  * Return the BPSCN context.
  */
-uint64_t qbman_result_bpscn_ctx(const struct ldpaa_dq *);
+uint64_t qbman_result_bpscn_ctx(const struct dpaa2_dq *);
 
 /* Parsing CGCU */
 /**
@@ -412,13 +412,13 @@ uint64_t qbman_result_bpscn_ctx(const struct ldpaa_dq *);
  *
  * Return the CGCU resource id.
  */
-uint16_t qbman_result_cgcu_cgid(const struct ldpaa_dq *);
+uint16_t qbman_result_cgcu_cgid(const struct dpaa2_dq *);
 /**
  * qbman_result_cgcu_icnt() - Get the I_CNT from CGCU
  *
  * Return instantaneous count in the CGCU notification.
  */
-uint64_t qbman_result_cgcu_icnt(const struct ldpaa_dq *);
+uint64_t qbman_result_cgcu_icnt(const struct dpaa2_dq *);
 
 	/************/
 	/* Enqueues */
diff --git a/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c b/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c
index ea071d1..091685b 100644
--- a/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c
+++ b/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c
@@ -492,7 +492,7 @@ void qbman_pull_desc_clear(struct qbman_pull_desc *d)
 }
 
 void qbman_pull_desc_set_storage(struct qbman_pull_desc *d,
-				 struct ldpaa_dq *storage,
+				 struct dpaa2_dq *storage,
 				 dma_addr_t storage_phys,
 				 int stash)
 {
@@ -606,12 +606,12 @@ static struct qb_attr_code code_dqpi_pi = QB_CODE(0, 0, 4);
 /* NULL return if there are no unconsumed DQRR entries. Returns a DQRR entry
  * only once, so repeated calls can return a sequence of DQRR entries, without
  * requiring they be consumed immediately or in any particular order. */
-const struct ldpaa_dq *qbman_swp_dqrr_next(struct qbman_swp *s)
+const struct dpaa2_dq *qbman_swp_dqrr_next(struct qbman_swp *s)
 {
 	uint32_t verb;
 	uint32_t response_verb;
 	uint32_t flags;
-	const struct ldpaa_dq *dq;
+	const struct dpaa2_dq *dq;
 	const uint32_t *p;
 
 	/* Before using valid-bit to detect if something is there, we have to
@@ -674,11 +674,11 @@ const struct ldpaa_dq *qbman_swp_dqrr_next(struct qbman_swp *s)
 
 	/* If this is the final response to a volatile dequeue command
 	   indicate that the vdq is no longer busy */
-	flags = ldpaa_dq_flags(dq);
+	flags = dpaa2_dq_flags(dq);
 	response_verb = qb_attr_code_decode(&code_dqrr_response, &verb);
 	if ((response_verb == QBMAN_RESULT_DQ) &&
-	    (flags & LDPAA_DQ_STAT_VOLATILE) &&
-	    (flags & LDPAA_DQ_STAT_EXPIRED))
+	    (flags & DPAA2_DQ_STAT_VOLATILE) &&
+	    (flags & DPAA2_DQ_STAT_EXPIRED))
 		atomic_inc(&s->vdq.busy);
 
 	qbman_cena_invalidate_prefetch(&s->sys,
@@ -687,7 +687,7 @@ const struct ldpaa_dq *qbman_swp_dqrr_next(struct qbman_swp *s)
 }
 
 /* Consume DQRR entries previously returned from qbman_swp_dqrr_next(). */
-void qbman_swp_dqrr_consume(struct qbman_swp *s, const struct ldpaa_dq *dq)
+void qbman_swp_dqrr_consume(struct qbman_swp *s, const struct dpaa2_dq *dq)
 {
 	qbman_cinh_write(&s->sys, QBMAN_CINH_SWP_DCAP, QBMAN_IDX_FROM_DQRR(dq));
 }
@@ -697,7 +697,7 @@ void qbman_swp_dqrr_consume(struct qbman_swp *s, const struct ldpaa_dq *dq)
 /*********************************/
 
 int qbman_result_has_new_result(struct qbman_swp *s,
-				  const struct ldpaa_dq *dq)
+				  const struct dpaa2_dq *dq)
 {
 	/* To avoid converting the little-endian DQ entry to host-endian prior
 	 * to us knowing whether there is a valid entry or not (and run the
@@ -711,7 +711,7 @@ int qbman_result_has_new_result(struct qbman_swp *s,
 	 * however the same address that was provided to us non-const in the
 	 * first place, for directing hardware DMA to. So we can cast away the
 	 * const because it is mutable from our perspective. */
-	uint32_t *p = qb_cl((struct ldpaa_dq *)dq);
+	uint32_t *p = qb_cl((struct dpaa2_dq *)dq);
 	uint32_t token;
 
 	token = qb_attr_code_decode(&code_dqrr_tok_detect, &p[1]);
@@ -747,7 +747,7 @@ int qbman_result_has_new_result(struct qbman_swp *s,
 static struct qb_attr_code code_result_in_mem =
 			QB_CODE(0, QBMAN_RESULT_VERB_OFFSET_IN_MEM, 7);
 
-static inline int __qbman_result_is_x(const struct ldpaa_dq *dq, uint32_t x)
+static inline int __qbman_result_is_x(const struct dpaa2_dq *dq, uint32_t x)
 {
 	const uint32_t *p = qb_cl(dq);
 	uint32_t response_verb = qb_attr_code_decode(&code_dqrr_response, p);
@@ -755,7 +755,7 @@ static inline int __qbman_result_is_x(const struct ldpaa_dq *dq, uint32_t x)
 	return response_verb == x;
 }
 
-static inline int __qbman_result_is_x_in_mem(const struct ldpaa_dq *dq,
+static inline int __qbman_result_is_x_in_mem(const struct dpaa2_dq *dq,
 					     uint32_t x)
 {
 	const uint32_t *p = qb_cl(dq);
@@ -764,48 +764,48 @@ static inline int __qbman_result_is_x_in_mem(const struct ldpaa_dq *dq,
 	return (response_verb == x);
 }
 
-int qbman_result_is_DQ(const struct ldpaa_dq *dq)
+int qbman_result_is_DQ(const struct dpaa2_dq *dq)
 {
 	return __qbman_result_is_x(dq, QBMAN_RESULT_DQ);
 }
 
-int qbman_result_is_FQDAN(const struct ldpaa_dq *dq)
+int qbman_result_is_FQDAN(const struct dpaa2_dq *dq)
 {
 	return __qbman_result_is_x(dq, QBMAN_RESULT_FQDAN);
 }
 
-int qbman_result_is_CDAN(const struct ldpaa_dq *dq)
+int qbman_result_is_CDAN(const struct dpaa2_dq *dq)
 {
 	return __qbman_result_is_x(dq, QBMAN_RESULT_CDAN);
 }
 
-int qbman_result_is_CSCN(const struct ldpaa_dq *dq)
+int qbman_result_is_CSCN(const struct dpaa2_dq *dq)
 {
 	return __qbman_result_is_x_in_mem(dq, QBMAN_RESULT_CSCN_MEM) ||
 		__qbman_result_is_x(dq, QBMAN_RESULT_CSCN_WQ);
 }
 
-int qbman_result_is_BPSCN(const struct ldpaa_dq *dq)
+int qbman_result_is_BPSCN(const struct dpaa2_dq *dq)
 {
 	return __qbman_result_is_x_in_mem(dq, QBMAN_RESULT_BPSCN);
 }
 
-int qbman_result_is_CGCU(const struct ldpaa_dq *dq)
+int qbman_result_is_CGCU(const struct dpaa2_dq *dq)
 {
 	return __qbman_result_is_x_in_mem(dq, QBMAN_RESULT_CGCU);
 }
 
-int qbman_result_is_FQRN(const struct ldpaa_dq *dq)
+int qbman_result_is_FQRN(const struct dpaa2_dq *dq)
 {
 	return __qbman_result_is_x_in_mem(dq, QBMAN_RESULT_FQRN);
 }
 
-int qbman_result_is_FQRNI(const struct ldpaa_dq *dq)
+int qbman_result_is_FQRNI(const struct dpaa2_dq *dq)
 {
 	return __qbman_result_is_x_in_mem(dq, QBMAN_RESULT_FQRNI);
 }
 
-int qbman_result_is_FQPN(const struct ldpaa_dq *dq)
+int qbman_result_is_FQPN(const struct dpaa2_dq *dq)
 {
 	return __qbman_result_is_x(dq, QBMAN_RESULT_FQPN);
 }
@@ -816,63 +816,63 @@ int qbman_result_is_FQPN(const struct ldpaa_dq *dq)
 
 /* These APIs assume qbman_result_is_DQ() is TRUE */
 
-uint32_t ldpaa_dq_flags(const struct ldpaa_dq *dq)
+uint32_t dpaa2_dq_flags(const struct dpaa2_dq *dq)
 {
 	const uint32_t *p = qb_cl(dq);
 
 	return qb_attr_code_decode(&code_dqrr_stat, p);
 }
 
-uint16_t ldpaa_dq_seqnum(const struct ldpaa_dq *dq)
+uint16_t dpaa2_dq_seqnum(const struct dpaa2_dq *dq)
 {
 	const uint32_t *p = qb_cl(dq);
 
 	return (uint16_t)qb_attr_code_decode(&code_dqrr_seqnum, p);
 }
 
-uint16_t ldpaa_dq_odpid(const struct ldpaa_dq *dq)
+uint16_t dpaa2_dq_odpid(const struct dpaa2_dq *dq)
 {
 	const uint32_t *p = qb_cl(dq);
 
 	return (uint16_t)qb_attr_code_decode(&code_dqrr_odpid, p);
 }
 
-uint32_t ldpaa_dq_fqid(const struct ldpaa_dq *dq)
+uint32_t dpaa2_dq_fqid(const struct dpaa2_dq *dq)
 {
 	const uint32_t *p = qb_cl(dq);
 
 	return qb_attr_code_decode(&code_dqrr_fqid, p);
 }
 
-uint32_t ldpaa_dq_byte_count(const struct ldpaa_dq *dq)
+uint32_t dpaa2_dq_byte_count(const struct dpaa2_dq *dq)
 {
 	const uint32_t *p = qb_cl(dq);
 
 	return qb_attr_code_decode(&code_dqrr_byte_count, p);
 }
 
-uint32_t ldpaa_dq_frame_count(const struct ldpaa_dq *dq)
+uint32_t dpaa2_dq_frame_count(const struct dpaa2_dq *dq)
 {
 	const uint32_t *p = qb_cl(dq);
 
 	return qb_attr_code_decode(&code_dqrr_frame_count, p);
 }
 
-uint64_t ldpaa_dq_fqd_ctx(const struct ldpaa_dq *dq)
+uint64_t dpaa2_dq_fqd_ctx(const struct dpaa2_dq *dq)
 {
 	const uint64_t *p = (uint64_t *)qb_cl(dq);
 
 	return qb_attr_code_decode_64(&code_dqrr_ctx_lo, p);
 }
-EXPORT_SYMBOL(ldpaa_dq_fqd_ctx);
+EXPORT_SYMBOL(dpaa2_dq_fqd_ctx);
 
-const struct dpaa_fd *ldpaa_dq_fd(const struct ldpaa_dq *dq)
+const struct dpaa_fd *dpaa2_dq_fd(const struct dpaa2_dq *dq)
 {
 	const uint32_t *p = qb_cl(dq);
 
 	return (const struct dpaa_fd *)&p[8];
 }
-EXPORT_SYMBOL(ldpaa_dq_fd);
+EXPORT_SYMBOL(dpaa2_dq_fd);
 
 /**************************************/
 /* Parsing state-change notifications */
@@ -886,35 +886,35 @@ static struct qb_attr_code code_scn_rid_in_mem =
 			QB_CODE(1, SCN_RID_OFFSET_IN_MEM, 24);
 static struct qb_attr_code code_scn_ctx_lo = QB_CODE(2, 0, 32);
 
-uint8_t qbman_result_SCN_state(const struct ldpaa_dq *scn)
+uint8_t qbman_result_SCN_state(const struct dpaa2_dq *scn)
 {
 	const uint32_t *p = qb_cl(scn);
 
 	return (uint8_t)qb_attr_code_decode(&code_scn_state, p);
 }
 
-uint32_t qbman_result_SCN_rid(const struct ldpaa_dq *scn)
+uint32_t qbman_result_SCN_rid(const struct dpaa2_dq *scn)
 {
 	const uint32_t *p = qb_cl(scn);
 
 	return qb_attr_code_decode(&code_scn_rid, p);
 }
 
-uint64_t qbman_result_SCN_ctx(const struct ldpaa_dq *scn)
+uint64_t qbman_result_SCN_ctx(const struct dpaa2_dq *scn)
 {
 	const uint64_t *p = (uint64_t *)qb_cl(scn);
 
 	return qb_attr_code_decode_64(&code_scn_ctx_lo, p);
 }
 
-uint8_t qbman_result_SCN_state_in_mem(const struct ldpaa_dq *scn)
+uint8_t qbman_result_SCN_state_in_mem(const struct dpaa2_dq *scn)
 {
 	const uint32_t *p = qb_cl(scn);
 
 	return (uint8_t)qb_attr_code_decode(&code_scn_state_in_mem, p);
 }
 
-uint32_t qbman_result_SCN_rid_in_mem(const struct ldpaa_dq *scn)
+uint32_t qbman_result_SCN_rid_in_mem(const struct dpaa2_dq *scn)
 {
 	const uint32_t *p = qb_cl(scn);
 	uint32_t result_rid;
@@ -926,27 +926,27 @@ uint32_t qbman_result_SCN_rid_in_mem(const struct ldpaa_dq *scn)
 /*****************/
 /* Parsing BPSCN */
 /*****************/
-uint16_t qbman_result_bpscn_bpid(const struct ldpaa_dq *scn)
+uint16_t qbman_result_bpscn_bpid(const struct dpaa2_dq *scn)
 {
 	return (uint16_t)qbman_result_SCN_rid_in_mem(scn) & 0x3FFF;
 }
 
-int qbman_result_bpscn_has_free_bufs(const struct ldpaa_dq *scn)
+int qbman_result_bpscn_has_free_bufs(const struct dpaa2_dq *scn)
 {
 	return !(int)(qbman_result_SCN_state_in_mem(scn) & 0x1);
 }
 
-int qbman_result_bpscn_is_depleted(const struct ldpaa_dq *scn)
+int qbman_result_bpscn_is_depleted(const struct dpaa2_dq *scn)
 {
 	return (int)(qbman_result_SCN_state_in_mem(scn) & 0x2);
 }
 
-int qbman_result_bpscn_is_surplus(const struct ldpaa_dq *scn)
+int qbman_result_bpscn_is_surplus(const struct dpaa2_dq *scn)
 {
 	return (int)(qbman_result_SCN_state_in_mem(scn) & 0x4);
 }
 
-uint64_t qbman_result_bpscn_ctx(const struct ldpaa_dq *scn)
+uint64_t qbman_result_bpscn_ctx(const struct dpaa2_dq *scn)
 {
 	return qbman_result_SCN_ctx(scn);
 }
@@ -954,12 +954,12 @@ uint64_t qbman_result_bpscn_ctx(const struct ldpaa_dq *scn)
 /*****************/
 /* Parsing CGCU  */
 /*****************/
-uint16_t qbman_result_cgcu_cgid(const struct ldpaa_dq *scn)
+uint16_t qbman_result_cgcu_cgid(const struct dpaa2_dq *scn)
 {
 	return (uint16_t)qbman_result_SCN_rid_in_mem(scn) & 0xFFFF;
 }
 
-uint64_t qbman_result_cgcu_icnt(const struct ldpaa_dq *scn)
+uint64_t qbman_result_cgcu_icnt(const struct dpaa2_dq *scn)
 {
 	return qbman_result_SCN_ctx(scn) & 0xFFFFFFFFFF;
 }
diff --git a/drivers/staging/fsl-mc/bus/dpio/qbman_portal.h b/drivers/staging/fsl-mc/bus/dpio/qbman_portal.h
index c81e4f9..b3985f1 100644
--- a/drivers/staging/fsl-mc/bus/dpio/qbman_portal.h
+++ b/drivers/staging/fsl-mc/bus/dpio/qbman_portal.h
@@ -31,7 +31,7 @@
 
 #include "qbman_private.h"
 #include "fsl_qbman_portal.h"
-#include "../../include/fsl_dpaa_fd.h"
+#include "../../include/fsl_dpaa2_fd.h"
 
 /* All QBMan command and result structures use this "valid bit" encoding */
 #define QB_VALID_BIT ((uint32_t)0x80)
@@ -88,7 +88,7 @@ struct qbman_swp {
 		 * targeting DQRR or main-memory, and detected is based on the
 		 * presence of the dequeue command's "token" showing up in
 		 * dequeue entries in DQRR or main-memory (respectively). */
-		struct ldpaa_dq *storage; /* NULL if DQRR */
+		struct dpaa2_dq *storage; /* NULL if DQRR */
 	} vdq;
 	/* DQRR */
 	struct {
diff --git a/drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h b/drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h
new file mode 100644
index 0000000..f5b3e72
--- /dev/null
+++ b/drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h
@@ -0,0 +1,471 @@
+/* Copyright 2014 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef __FSL_DPAA2_FD_H
+#define __FSL_DPAA2_FD_H
+
+/**
+ * struct dpaa_fd - Place-holder for FDs.
+ *
+ * We represent it via the simplest form that we need for now. Different
+ * overlays may be needed to support different options, etc. (It is impractical
+ * to define One True Struct, because the resulting encoding routines (lots of
+ * read-modify-writes) would be worst-case performance whether or not
+ * circumstances required them.)
+ */
+struct dpaa_fd {
+	union {
+		u32 words[8];
+		struct dpaa_fd_simple {
+			u32 addr_lo;
+			u32 addr_hi;
+			u32 len;
+			/* offset in the MS 16 bits, BPID in the LS 16 bits */
+			u32 bpid_offset;
+			u32 frc; /* frame context */
+			/* "err", "va", "cbmt", "asal", [...] */
+			u32 ctrl;
+			/* flow context */
+			u32 flc_lo;
+			u32 flc_hi;
+		} simple;
+	};
+};
+
+enum dpaa_fd_format {
+	dpaa_fd_single = 0,
+	dpaa_fd_list,
+	dpaa_fd_sg
+};
+
+/* Accessors for SG entry fields
+ *
+ * These setters and getters assume little endian format. For converting
+ * between LE and cpu endianness, the specific conversion functions must be
+ * called before the SGE contents are accessed by the core (on Rx),
+ * respectively before the SG table is sent to hardware (on Tx)
+ */
+
+/**
+ * dpaa2_fd_get_addr() - get the addr field of frame descriptor
+ * @fd: the given frame descriptor.
+ *
+ * Return the address in the frame descritpor.
+ */
+static inline dma_addr_t dpaa2_fd_get_addr(const struct dpaa_fd *fd)
+{
+	return (dma_addr_t)((((uint64_t)fd->simple.addr_hi) << 32)
+				+ fd->simple.addr_lo);
+}
+
+/**
+ * dpaa2_fd_set_addr() - Set the addr field of frame descriptor
+ * @fd: the given frame descriptor.
+ * @addr: the address needs to be set in frame descriptor.
+ */
+static inline void dpaa2_fd_set_addr(struct dpaa_fd *fd, dma_addr_t addr)
+{
+	fd->simple.addr_hi = upper_32_bits(addr);
+	fd->simple.addr_lo = lower_32_bits(addr);
+}
+
+/**
+ * dpaa2_fd_get_len() - Get the length in the frame descriptor
+ * @fd: the given frame descriptor.
+ *
+ * Return the length field in the frame descriptor.
+ */
+static inline u32 dpaa2_fd_get_len(const struct dpaa_fd *fd)
+{
+	return fd->simple.len;
+}
+
+/**
+ * dpaa2_fd_set_len() - Set the length field of frame descriptor
+ * @fd: the given frame descriptor.
+ * @len: the length needs to be set in frame descriptor.
+ */
+static inline void dpaa2_fd_set_len(struct dpaa_fd *fd, u32 len)
+{
+	fd->simple.len = len;
+}
+
+/**
+ * dpaa2_fd_get_offset() - Get the offset field in the frame descriptor
+ * @fd: the given frame descriptor.
+ *
+ * Return the offset.
+ */
+static inline uint16_t dpaa2_fd_get_offset(const struct dpaa_fd *fd)
+{
+	return (uint16_t)(fd->simple.bpid_offset >> 16) & 0x0FFF;
+}
+
+/**
+ * dpaa2_fd_set_offset() - Set the offset field of frame descriptor
+ *
+ * @fd: the given frame descriptor.
+ * @offset: the offset needs to be set in frame descriptor.
+ */
+static inline void dpaa2_fd_set_offset(struct dpaa_fd *fd, uint16_t offset)
+{
+	fd->simple.bpid_offset &= 0xF000FFFF;
+	fd->simple.bpid_offset |= (u32)offset << 16;
+}
+
+/**
+ * dpaa2_fd_get_format() - Get the format field in the frame descriptor
+ * @fd: the given frame descriptor.
+ *
+ * Return the format.
+ */
+static inline enum dpaa_fd_format dpaa2_fd_get_format(const struct dpaa_fd *fd)
+{
+	return (enum dpaa_fd_format)((fd->simple.bpid_offset >> 28) & 0x3);
+}
+
+/**
+ * dpaa2_fd_set_format() - Set the format field of frame descriptor
+ *
+ * @fd: the given frame descriptor.
+ * @format: the format needs to be set in frame descriptor.
+ */
+static inline void dpaa2_fd_set_format(struct dpaa_fd *fd,
+				       enum dpaa_fd_format format)
+{
+	fd->simple.bpid_offset &= 0xCFFFFFFF;
+	fd->simple.bpid_offset |= (u32)format << 28;
+}
+
+/**
+ * dpaa2_fd_get_bpid() - Get the bpid field in the frame descriptor
+ * @fd: the given frame descriptor.
+ *
+ * Return the bpid.
+ */
+static inline uint16_t dpaa2_fd_get_bpid(const struct dpaa_fd *fd)
+{
+	return (uint16_t)(fd->simple.bpid_offset & 0xFFFF);
+}
+
+/**
+ * dpaa2_fd_set_bpid() - Set the bpid field of frame descriptor
+ *
+ * @fd: the given frame descriptor.
+ * @bpid: the bpid needs to be set in frame descriptor.
+ */
+static inline void dpaa2_fd_set_bpid(struct dpaa_fd *fd, uint16_t bpid)
+{
+	fd->simple.bpid_offset &= 0xFFFF0000;
+	fd->simple.bpid_offset |= (u32)bpid;
+}
+
+/**
+ * struct dpaa_sg_entry - the scatter-gathering structure
+ */
+struct dpaa_sg_entry {
+	u32 addr_lo;
+	u32 addr_hi;
+	u32 len;
+	u32 bpid_offset;
+};
+
+enum dpaa_sg_format {
+	dpaa_sg_single = 0,
+	dpaa_sg_frame_data,
+	dpaa_sg_sgt_ext
+};
+
+/**
+ * dpaa2_sg_get_addr() - Get the address from SG entry
+ * @sg: the given scatter-gathering object.
+ *
+ * Return the address.
+ */
+static inline dma_addr_t dpaa2_sg_get_addr(const struct dpaa_sg_entry *sg)
+{
+	return (dma_addr_t)((((u64)sg->addr_hi) << 32) + sg->addr_lo);
+}
+
+/**
+ * dpaa2_sg_set_addr() - Set the address in SG entry
+ * @sg: the given scatter-gathering object.
+ * @addr: the address to be set.
+ */
+static inline void dpaa2_sg_set_addr(struct dpaa_sg_entry *sg, dma_addr_t addr)
+{
+	sg->addr_hi = upper_32_bits(addr);
+	sg->addr_lo = lower_32_bits(addr);
+}
+
+
+static inline bool dpaa2_sg_short_len(const struct dpaa_sg_entry *sg)
+{
+	return (sg->bpid_offset >> 30) & 0x1;
+}
+
+/**
+ * dpaa2_sg_get_len() - Get the length in SG entry
+ * @sg: the given scatter-gathering object.
+ *
+ * Return the length.
+ */
+static inline u32 dpaa2_sg_get_len(const struct dpaa_sg_entry *sg)
+{
+	if (dpaa2_sg_short_len(sg))
+		return sg->len & 0x1FFFF;
+	return sg->len;
+}
+
+/**
+ * dpaa2_sg_set_len() - Set the length in SG entry
+ * @sg: the given scatter-gathering object.
+ * @len: the length to be set.
+ */
+static inline void dpaa2_sg_set_len(struct dpaa_sg_entry *sg, u32 len)
+{
+	sg->len = len;
+}
+
+/**
+ * dpaa2_sg_get_offset() - Get the offset in SG entry
+ * @sg: the given scatter-gathering object.
+ *
+ * Return the offset.
+ */
+static inline u16 dpaa2_sg_get_offset(const struct dpaa_sg_entry *sg)
+{
+	return (u16)(sg->bpid_offset >> 16) & 0x0FFF;
+}
+
+/**
+ * dpaa2_sg_set_offset() - Set the offset in SG entry
+ * @sg: the given scatter-gathering object.
+ * @offset: the offset to be set.
+ */
+static inline void dpaa2_sg_set_offset(struct dpaa_sg_entry *sg,
+				       u16 offset)
+{
+	sg->bpid_offset &= 0xF000FFFF;
+	sg->bpid_offset |= (u32)offset << 16;
+}
+
+/**
+ * dpaa2_sg_get_format() - Get the SG format in SG entry
+ * @sg: the given scatter-gathering object.
+ *
+ * Return the format.
+ */
+static inline enum dpaa_sg_format
+	dpaa2_sg_get_format(const struct dpaa_sg_entry *sg)
+{
+	return (enum dpaa_sg_format)((sg->bpid_offset >> 28) & 0x3);
+}
+
+/**
+ * dpaa2_sg_set_format() - Set the SG format in SG entry
+ * @sg: the given scatter-gathering object.
+ * @format: the format to be set.
+ */
+static inline void dpaa2_sg_set_format(struct dpaa_sg_entry *sg,
+				       enum dpaa_sg_format format)
+{
+	sg->bpid_offset &= 0xCFFFFFFF;
+	sg->bpid_offset |= (u32)format << 28;
+}
+
+/**
+ * dpaa2_sg_get_bpid() - Get the buffer pool id in SG entry
+ * @sg: the given scatter-gathering object.
+ *
+ * Return the bpid.
+ */
+static inline u16 dpaa2_sg_get_bpid(const struct dpaa_sg_entry *sg)
+{
+	return (u16)(sg->bpid_offset & 0x3FFF);
+}
+
+/**
+ * dpaa2_sg_set_bpid() - Set the buffer pool id in SG entry
+ * @sg: the given scatter-gathering object.
+ * @bpid: the bpid to be set.
+ */
+static inline void dpaa2_sg_set_bpid(struct dpaa_sg_entry *sg, u16 bpid)
+{
+	sg->bpid_offset &= 0xFFFFC000;
+	sg->bpid_offset |= (u32)bpid;
+}
+
+/**
+ * dpaa2_sg_is_final() - Check final bit in SG entry
+ * @sg: the given scatter-gathering object.
+ *
+ * Return bool.
+ */
+static inline bool dpaa2_sg_is_final(const struct dpaa_sg_entry *sg)
+{
+	return !!(sg->bpid_offset >> 31);
+}
+
+/**
+ * dpaa2_sg_set_final() - Set the final bit in SG entry
+ * @sg: the given scatter-gathering object.
+ * @final: the final boolean to be set.
+ */
+static inline void dpaa2_sg_set_final(struct dpaa_sg_entry *sg, bool final)
+{
+	sg->bpid_offset &= 0x7FFFFFFF;
+	sg->bpid_offset |= (u32)final << 31;
+}
+
+/* Endianness conversion helper functions
+ * The accelerator drivers which construct / read scatter gather entries
+ * need to call these in order to account for endianness mismatches between
+ * hardware and cpu
+ */
+#ifdef __BIG_ENDIAN
+static inline void dpaa2_sg_cpu_to_le(struct dpaa_sg_entry *sg)
+{
+	uint32_t *p = (uint32_t *)sg;
+	int i;
+
+	for (i = 0; i < sizeof(*sg) / sizeof(u32); i++)
+		cpu_to_le32s(p++);
+}
+
+static inline void dpaa2_sg_le_to_cpu(struct dpaa_sg_entry *sg)
+{
+	uint32_t *p = (uint32_t *)sg;
+	int i;
+
+	for (i = 0; i < sizeof(*sg) / sizeof(u32); i++)
+		le32_to_cpus(p++);
+}
+#else
+#define dpaa2_sg_cpu_to_le(sg)
+#define dpaa2_sg_le_to_cpu(sg)
+#endif /* __BIG_ENDIAN */
+
+/**
+ * struct dpaa2_dq - the qman result structure
+ *
+ * When frames are dequeued, the FDs show up inside "dequeue" result structures
+ * (if at all, not all dequeue results contain valid FDs). This structure type
+ * is intentionally defined without internal detail, and the only reason it
+ * isn't declared opaquely (without size) is to allow the user to provide
+ * suitably-sized (and aligned) memory for these entries.
+ */
+struct dpaa2_dq {
+	uint32_t dont_manipulate_directly[16];
+};
+
+/* Parsing frame dequeue results */
+#define DPAA2_DQ_STAT_FQEMPTY       0x80
+#define DPAA2_DQ_STAT_HELDACTIVE    0x40
+#define DPAA2_DQ_STAT_FORCEELIGIBLE 0x20
+#define DPAA2_DQ_STAT_VALIDFRAME    0x10
+#define DPAA2_DQ_STAT_ODPVALID      0x04
+#define DPAA2_DQ_STAT_VOLATILE      0x02
+#define DPAA2_DQ_STAT_EXPIRED       0x01
+/**
+ * dpaa2_dq_flags() - Get the stat field of dequeue response
+ */
+uint32_t dpaa2_dq_flags(const struct dpaa2_dq *);
+
+/**
+ * dpaa2_dq_is_pull() - Check whether the dq response is from a pull
+ * command.
+ * @dq: the dequeue result.
+ *
+ * Return 1 for volatile(pull) dequeue, 0 for static dequeue.
+ */
+static inline int dpaa2_dq_is_pull(const struct dpaa2_dq *dq)
+{
+	return (int)(dpaa2_dq_flags(dq) & DPAA2_DQ_STAT_VOLATILE);
+}
+
+/**
+ * dpaa2_dq_is_pull_complete() - Check whether the pull command is completed.
+ * @dq: the dequeue result.
+ *
+ * Return boolean.
+ */
+static inline int dpaa2_dq_is_pull_complete(
+					const struct dpaa2_dq *dq)
+{
+	return (int)(dpaa2_dq_flags(dq) & DPAA2_DQ_STAT_EXPIRED);
+}
+
+/**
+ * dpaa2_dq_seqnum() - Get the seqnum field in dequeue response
+ * seqnum is valid only if VALIDFRAME flag is TRUE
+ *
+ * Return seqnum.
+ */
+uint16_t dpaa2_dq_seqnum(const struct dpaa2_dq *);
+/**
+ * dpaa2_dq_odpid() - Get the seqnum field in dequeue response
+ * odpid is valid only if ODPVAILD flag is TRUE.
+ *
+ * Return odpid.
+ */
+uint16_t dpaa2_dq_odpid(const struct dpaa2_dq *);
+/**
+ * dpaa2_dq_fqid() - Get the fqid in dequeue response
+ *
+ * Return fqid.
+ */
+uint32_t dpaa2_dq_fqid(const struct dpaa2_dq *);
+/**
+ * dpaa2_dq_byte_count() - Get the byte count in dequeue response
+ *
+ * Return the byte count remaining in the FQ.
+ */
+uint32_t dpaa2_dq_byte_count(const struct dpaa2_dq *);
+/**
+ * dpaa2_dq_frame_count() - Get the frame count in dequeue response
+ *
+ * Return the frame count remaining in the FQ.
+ */
+uint32_t dpaa2_dq_frame_count(const struct dpaa2_dq *);
+/**
+ * dpaa2_dq_fd_ctx() - Get the frame queue context in dequeue response
+ *
+ * Return the frame queue context.
+ */
+uint64_t dpaa2_dq_fqd_ctx(const struct dpaa2_dq *dq);
+/**
+ * dpaa2_dq_fd() - Get the frame descriptor in dequeue response
+ *
+ * Return the frame descriptor.
+ */
+const struct dpaa_fd *dpaa2_dq_fd(const struct dpaa2_dq *);
+
+#endif /* __FSL_DPAA2_FD_H */
diff --git a/drivers/staging/fsl-mc/include/fsl_dpaa2_io.h b/drivers/staging/fsl-mc/include/fsl_dpaa2_io.h
new file mode 100644
index 0000000..35e92d9
--- /dev/null
+++ b/drivers/staging/fsl-mc/include/fsl_dpaa2_io.h
@@ -0,0 +1,554 @@
+/* Copyright 2014 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef __FSL_DPAA2_IO_H
+#define __FSL_DPAA2_IO_H
+
+#include "fsl_dpaa2_fd.h"
+
+struct dpaa2_io;
+struct dpaa2_io_store;
+
+/***************************/
+/* DPIO Service management */
+/***************************/
+
+/**
+ * struct dpaa2_io_desc - The DPIO descriptor.
+ *
+ * Describe the attributes and features of the DPIO object.
+ */
+struct dpaa2_io_desc {
+	/* non-zero iff the DPIO has a channel */
+	int receives_notifications;
+	/* non-zero if the DPIO portal interrupt is handled. If so, the
+	 * caller/OS handles the interrupt and calls dpaa2_io_service_irq(). */
+	int has_irq;
+	/* non-zero if the caller/OS is prepared to called the
+	 * dpaa2_io_service_poll() routine as part of its run-to-completion (or
+	 * scheduling) loop. If so, the DPIO service may dynamically switch some
+	 * of its processing between polling-based and irq-based. It is illegal
+	 * combination to have (!has_irq && !will_poll). */
+	int will_poll;
+	/* ignored unless 'receives_notifications'. Non-zero iff the channel has
+	 * 8 priority WQs, otherwise the channel has 2. */
+	int has_8prio;
+	/* the cpu index that at least interrupt handlers will execute on. And
+	 * if 'stash_affinity' is non-zero, the cache targeted by stash
+	 * transactions is affine to this cpu. */
+	int cpu;
+	/* non-zero if stash transactions for this portal favour 'cpu' over
+	 * other CPUs. (Eg. zero if there's no stashing, or stashing is to
+	 * shared cache.) */
+	int stash_affinity;
+	/* Caller-provided flags, determined by bus-scanning and/or creation of
+	 * DPIO objects via MC commands. */
+	void *regs_cena;
+	void *regs_cinh;
+	int dpio_id;
+};
+
+/**
+ * dpaa2_io_create() - create a dpaa2_io object.
+ * @desc: the dpaa2_io descriptor
+ *
+ * Activates a "struct dpaa2_io" corresponding to the given config of an actual
+ * DPIO object. This handle can be used on it's own (like a one-portal "DPIO
+ * service") or later be added to a service-type "struct dpaa2_io" object. Note,
+ * the information required on 'cfg' is copied so the caller is free to do as
+ * they wish with the input parameter upon return.
+ *
+ * Return a valid dpaa2_io object for success, or NULL for failure.
+ */
+struct dpaa2_io *dpaa2_io_create(const struct dpaa2_io_desc *desc);
+
+/**
+ * dpaa2_io_create_service() -  Create an (initially empty) DPIO service.
+ *
+ * Return a valid dpaa2_io object for success, or NULL for failure.
+ */
+struct dpaa2_io *dpaa2_io_create_service(void);
+
+/**
+ * dpaa2_io_default_service() - Use the driver's own global (and initially
+ * empty) DPIO service.
+ *
+ * This increments the reference count, so don't forget to use dpaa2_io_down()
+ * for each time this function is called.
+ *
+ * Return a valid dpaa2_io object for success, or NULL for failure.
+ */
+struct dpaa2_io *dpaa2_io_default_service(void);
+
+/**
+ * dpaa2_io_down() - release the dpaa2_io object.
+ * @d: the dpaa2_io object to be released.
+ *
+ * The "struct dpaa2_io" type can represent an individual DPIO object (as
+ * described by "struct dpaa2_io_desc") or an instance of a "DPIO service",
+ * which can be used to group/encapsulate multiple DPIO objects. In all cases,
+ * each handle obtained should be released using this function.
+ */
+void dpaa2_io_down(struct dpaa2_io *d);
+
+/**
+ * dpaa2_io_service_add() - Add the given DPIO object to the given DPIO service.
+ * @service: the given DPIO service.
+ * @obj: the given DPIO object.
+ *
+ * 'service' must have been created by dpaa2_io_create_service() and 'obj'
+ * must have been created by dpaa2_io_create(). This increments the reference
+ * count on the object that 'obj' refers to, so the user could call
+ * dpaa2_io_down(obj) after this and the object will persist within the service
+ * (and will be destroyed when the service is destroyed).
+ *
+ * Return 0 for success, or -EINVAL for failure.
+ */
+int dpaa2_io_service_add(struct dpaa2_io *service, struct dpaa2_io *obj);
+
+/**
+ * dpaa2_io_get_descriptor() - Get the DPIO descriptor of the given DPIO object.
+ * @obj: the given DPIO object.
+ * @desc: the returned DPIO descriptor.
+ *
+ * This function will return failure if the given dpaa2_io struct represents a
+ * service rather than an individual DPIO object, otherwise it returns zero and
+ * the given 'cfg' structure is filled in.
+ *
+ * Return 0 for success, or -EINVAL for failure.
+ */
+int dpaa2_io_get_descriptor(struct dpaa2_io *obj, struct dpaa2_io_desc *desc);
+
+/**
+ * dpaa2_io_poll() -  Process any notifications and h/w-initiated events that
+ * are polling-driven.
+ * @obj: the given DPIO object.
+ *
+ * Obligatory for DPIO objects that have dpaa2_io_desc::will_poll non-zero.
+ *
+ * Return 0 for success, or -EINVAL for failure.
+ */
+int dpaa2_io_poll(struct dpaa2_io *obj);
+
+/**
+ * dpaa2_io_irq() - Process any notifications and h/w-initiated events that are
+ * irq-driven.
+ * @obj: the given DPIO object.
+ *
+ * Obligatory for DPIO objects that have dpaa2_io_desc::has_irq non-zero.
+ *
+ * Return IRQ_HANDLED for success, or -EINVAL for failure.
+ */
+int dpaa2_io_irq(struct dpaa2_io *obj);
+
+/**
+ * dpaa2_io_pause_poll() - Used to stop polling.
+ * @obj: the given DPIO object.
+ *
+ * If a polling application is going to stop polling for a period of time and
+ * supports interrupt processing, it can call this function to convert all
+ * processing to IRQ. (Eg. when sleeping.)
+ *
+ * Return -EINVAL.
+ */
+int dpaa2_io_pause_poll(struct dpaa2_io *obj);
+
+/**
+ * dpaa2_io_resume_poll() - Resume polling
+ * @obj: the given DPIO object.
+ *
+ * Return -EINVAL.
+ */
+int dpaa2_io_resume_poll(struct dpaa2_io *obj);
+
+/**
+ * dpaa2_io_service_notifications() - Get a mask of cpus that the DPIO service
+ * can receive notifications on.
+ * @s: the given DPIO object.
+ * @mask: the mask of cpus.
+ *
+ * Note that this is a run-time snapshot. If things like cpu-hotplug are
+ * supported in the target system, then an attempt to register notifications
+ * for a cpu that appears present in the given mask might fail if that cpu has
+ * gone offline in the mean time.
+ */
+void dpaa2_io_service_notifications(struct dpaa2_io *s, cpumask_t *mask);
+
+/**
+ * dpaa2_io_service_stashing - Get a mask of cpus that the DPIO service has stash
+ * affinity to.
+ * @s: the given DPIO object.
+ * @mask: the mask of cpus.
+ */
+void dpaa2_io_service_stashing(struct dpaa2_io *s, cpumask_t *mask);
+
+/**
+ * dpaa2_io_service_nonaffine() - Check the DPIO service's cpu affinity
+ * for stashing.
+ * @s: the given DPIO object.
+ *
+ * Return a boolean, whether or not the DPIO service has resources that have no
+ * particular cpu affinity for stashing. (Useful to know if you wish to operate
+ * on CPUs that the service has no affinity to, you would choose to use
+ * resources that are neutral, rather than affine to a different CPU.) Unlike
+ * other service-specific APIs, this one doesn't return an error if it is passed
+ * a non-service object. So don't do it.
+ */
+int dpaa2_io_service_has_nonaffine(struct dpaa2_io *s);
+
+/*************************/
+/* Notification handling */
+/*************************/
+
+/**
+ * struct dpaa2_io_notification_ctx - The DPIO notification context structure.
+ *
+ * When a FQDAN/CDAN registration is made (eg. by DPNI/DPCON/DPAI code), a
+ * context of the following type is used. The caller can embed it within a
+ * larger structure in order to add state that is tracked along with the
+ * notification (this may be useful when callbacks are invoked that pass this
+ * notification context as a parameter).
+ */
+struct dpaa2_io_notification_ctx {
+	/* the callback to be invoked when the notification arrives */
+	void (*cb)(struct dpaa2_io_notification_ctx *);
+	/* Zero/FALSE for FQDAN, non-zero/TRUE for CDAN */
+	int is_cdan;
+	uint32_t id; /* FQID or channel ID, needed for rearm */
+	/* This specifies which cpu the user wants notifications to show up on
+	 * (ie. to execute 'cb'). If notification-handling on that cpu is not
+	 * available at the time of notification registration, the registration
+	 * will fail. */
+	int desired_cpu;
+	/* If the target platform supports cpu-hotplug or other features
+	 * (related to power-management, one would expect) that can migrate IRQ
+	 * handling of a given DPIO object, then this value will potentially be
+	 * different to 'desired_cpu' at run-time. */
+	int actual_cpu;
+	/* And if migration does occur and this callback is non-NULL, it will
+	 * be invoked prior to any futher notification callbacks executing on
+	 * 'newcpu'. Note that 'oldcpu' is what 'actual_cpu' was prior to the
+	 * migration, and 'newcpu' is what it is now. Both could conceivably be
+	 * different to 'desired_cpu'. */
+	void (*migration_cb)(struct dpaa2_io_notification_ctx *,
+			     int oldcpu, int newcpu);
+	/* These are returned from dpaa2_io_service_register().
+	 * 'dpio_id' is the dpaa2_io_desc::dpio_id value of the DPIO object that
+	 * has been selected by the service for receiving the notifications. The
+	 * caller can use this value in the MC command that attaches the FQ (or
+	 * channel) of their DPNI (or DPCON, respectively) to this DPIO for
+	 * notification-generation.
+	 * 'qman64' is the 64-bit context value that needs to be sent in the
+	 * same MC command in order to be programmed into the FQ or channel -
+	 * this is the 64-bit value that shows up in the FQDAN/CDAN messages to
+	 * the DPIO object, and the DPIO service specifies this value back to
+	 * the caller so that the notifications that show up will be
+	 * comprensible/demux-able to the DPIO service. */
+	int dpio_id;
+	uint64_t qman64;
+	/* These fields are internal to the DPIO service once the context is
+	 * registered. TBD: may require more internal state fields. */
+	struct list_head node;
+	void *dpio_private;
+};
+
+/**
+ * dpaa2_io_service_register() - Prepare for servicing of FQDAN or CDAN
+ * notifications on the given DPIO service.
+ * @service: the given DPIO service.
+ * @ctx: the notificaiton context.
+ *
+ * The MC command to attach the caller's DPNI/DPCON/DPAI device to a
+ * DPIO object is performed after this function is called. In that way, (a) the
+ * DPIO service is "ready" to handle a notification arrival (which might happen
+ * before the "attach" command to MC has returned control of execution back to
+ * the caller), and (b) the DPIO service can provide back to the caller the
+ * 'dpio_id' and 'qman64' parameters that it should pass along in the MC command
+ * in order for the DPNI/DPCON/DPAI resources to be configured to produce the
+ * right notification fields to the DPIO service.
+ *
+ * Return 0 for success, or -ENODEV for failure.
+ */
+int dpaa2_io_service_register(struct dpaa2_io *service,
+			     struct dpaa2_io_notification_ctx *ctx);
+
+/**
+ * dpaa2_io_service_deregister - The opposite of 'register'.
+ * @service: the given DPIO service.
+ * @ctx: the notificaiton context.
+ *
+ * Note that 'register' should be called *before*
+ * making the MC call to attach the notification-producing device to the
+ * notification-handling DPIO service, the 'unregister' function should be
+ * called *after* making the MC call to detach the notification-producing
+ * device.
+ *
+ * Return 0 for success.
+ */
+int dpaa2_io_service_deregister(struct dpaa2_io *service,
+			       struct dpaa2_io_notification_ctx *ctx);
+
+/**
+ * dpaa2_io_service_rearm() - Rearm the notification for the given DPIO service.
+ * @service: the given DPIO service.
+ * @ctx: the notificaiton context.
+ *
+ * Once a FQDAN/CDAN has been produced, the corresponding FQ/channel is
+ * considered "disarmed". Ie. the user can issue pull dequeue operations on that
+ * traffic source for as long as it likes. Eventually it may wish to "rearm"
+ * that source to allow it to produce another FQDAN/CDAN, that's what this
+ * function achieves.
+ *
+ * Return 0 for success, or -ENODEV if no service available, -EBUSY/-EIO for not
+ * being able to implement the rearm the notifiaton due to setting CDAN or
+ * scheduling fq.
+ */
+int dpaa2_io_service_rearm(struct dpaa2_io *service,
+			  struct dpaa2_io_notification_ctx *ctx);
+
+/**
+ * dpaa2_io_from_registration() - Get the DPIO object from the given notification
+ * context.
+ * @ctx: the given notifiation context.
+ * @ret: the returned DPIO object.
+ *
+ * Like 'dpaa2_io_service_get_persistent()' (see below), except that the
+ * returned handle is not selected based on a 'cpu' argument, but is the same
+ * DPIO object that the given notification context is registered against. The
+ * returned handle carries a reference count, so a corresponding dpaa2_io_down()
+ * would be required when the reference is no longer needed.
+ *
+ * Return 0 for success, or -EINVAL for failure.
+ */
+int dpaa2_io_from_registration(struct dpaa2_io_notification_ctx *ctx,
+			      struct dpaa2_io **ret);
+
+/**********************************/
+/* General usage of DPIO services */
+/**********************************/
+
+/**
+ * dpaa2_io_service_get_persistent() - Get the DPIO resource from the given
+ * notification context and cpu.
+ * @ctx: the given notifiation context.
+ * @cpu: the cpu that the DPIO resource has stashing affinity to.
+ * @ret: the returned DPIO resource.
+ *
+ * The various DPIO interfaces can accept a "struct dpaa2_io" handle that refers
+ * to an individual DPIO object or to a whole service. In the latter case, an
+ * internal choice is made for each operation. This function supports the former
+ * case, by selecting an individual DPIO object *from* the service in order for
+ * it to be used multiple times to provide "persistence". The returned handle
+ * also carries a reference count, so a corresponding dpaa2_io_down() would be
+ * required when the reference is no longer needed. Note, a parameter of -1 for
+ * 'cpu' will select a DPIO resource that has no particular stashing affinity to
+ * any cpu (eg. one that stashes to platform cache).
+ *
+ * Return 0 for success, or -ENODEV for failure.
+ */
+int dpaa2_io_service_get_persistent(struct dpaa2_io *service, int cpu,
+				   struct dpaa2_io **ret);
+
+/*****************/
+/* Pull dequeues */
+/*****************/
+
+/**
+ * dpaa2_io_service_pull_fq()
+ * dpaa2_io_service_pull_channel() - pull dequeue functions from fq or channel.
+ * @d: the given DPIO service.
+ * @fqid: the given frame queue id.
+ * @channelid: the given channel id.
+ * @s: the dpaa2_io_store object for the result.
+ *
+ * To support DCA/order-preservation, it will be necessary to support an
+ * alternative form, because they must ultimately dequeue to DQRR rather than a
+ * user-supplied dpaa2_io_store. Furthermore, those dequeue results will
+ * "complete" using a caller-provided callback (from DQRR processing) rather
+ * than the caller explicitly looking at their dpaa2_io_store for results. Eg.
+ * the alternative form will likely take a callback parameter rather than a
+ * store parameter. Ignoring it for now to keep the picture clearer.
+ *
+ * Return 0 for success, or error code for failure.
+ */
+int dpaa2_io_service_pull_fq(struct dpaa2_io *d, uint32_t fqid,
+			    struct dpaa2_io_store *s);
+int dpaa2_io_service_pull_channel(struct dpaa2_io *d, uint32_t channelid,
+				 struct dpaa2_io_store *s);
+
+/************/
+/* Enqueues */
+/************/
+
+/**
+ * dpaa2_io_service_enqueue_fq()
+ * dpaa2_io_service_enqueue_qd() - The enqueue functions to FQ or QD
+ * @d: the given DPIO service.
+ * @fqid: the given frame queue id.
+ * @qdid: the given queuing destination id.
+ * @prio: the given queuing priority.
+ * @qdbin: the given queuing destination bin.
+ * @fd: the frame descriptor which is enqueued.
+ *
+ * This definition bypasses some features that are not expected to be priority-1
+ * features, and may not be needed at all via current assumptions (QBMan's
+ * feature set is wider than the MC object model is intendeding to support,
+ * initially at least). Plus, keeping them out (for now) keeps the API view
+ * simpler. Missing features are;
+ *  - enqueue confirmation (results DMA'd back to the user)
+ *  - ORP
+ *  - DCA/order-preservation (see note in "pull dequeues")
+ *  - enqueue consumption interrupts
+ *
+ * Return 0 for successful enqueue, or -EBUSY if the enqueue ring is not ready,
+ * or -ENODEV if there is no dpio service.
+ */
+int dpaa2_io_service_enqueue_fq(struct dpaa2_io *d,
+			       uint32_t fqid,
+			       const struct dpaa_fd *fd);
+int dpaa2_io_service_enqueue_qd(struct dpaa2_io *d,
+			       uint32_t qdid, uint8_t prio, uint16_t qdbin,
+			       const struct dpaa_fd *fd);
+
+/*******************/
+/* Buffer handling */
+/*******************/
+
+/**
+ * dpaa2_io_service_release() - Release buffers to a buffer pool.
+ * @d: the given DPIO object.
+ * @bpid: the buffer pool id.
+ * @buffers: the buffers to be released.
+ * @num_buffers: the number of the buffers to be released.
+ *
+ * Return 0 for success, and negative error code for failure.
+ */
+int dpaa2_io_service_release(struct dpaa2_io *d,
+			    uint32_t bpid,
+			    const uint64_t *buffers,
+			    unsigned int num_buffers);
+
+/**
+ * dpaa2_io_service_acquire() - Acquire buffers from a buffer pool.
+ * @d: the given DPIO object.
+ * @bpid: the buffer pool id.
+ * @buffers: the buffer addresses for acquired buffers.
+ * @num_buffers: the expected number of the buffers to acquire.
+ *
+ * Return a negative error code if the command failed, otherwise it returns
+ * the number of buffers acquired, which may be less than the number requested.
+ * Eg. if the buffer pool is empty, this will return zero.
+ */
+int dpaa2_io_service_acquire(struct dpaa2_io *,
+			    uint32_t bpid,
+			    uint64_t *buffers,
+			    unsigned int num_buffers);
+
+/***************/
+/* DPIO stores */
+/***************/
+
+/* These are reusable memory blocks for retrieving dequeue results into, and to
+ * assist with parsing those results once they show up. They also hide the
+ * details of how to use "tokens" to make detection of DMA results possible (ie.
+ * comparing memory before the DMA and after it) while minimising the needless
+ * clearing/rewriting of those memory locations between uses.
+ */
+
+/**
+ * dpaa2_io_store_create()
+ * dpaa2_io_store_destroy() - Create/destroy the dma memory storage for dequeue
+ * result.
+ * @max_frames: the maximum number of dequeued result for frames, must be <= 16.
+ * @dev: the device to allow mapping/unmapping the DMAable region.
+ * @s: the storage memory to be destroyed.
+ *
+ * Constructor/destructor - max_frames must be <= 16. The user provides the
+ * device struct to allow mapping/unmapping of the DMAable region. Area for
+ * storage will be allocated during create. The size of this storage is
+ * "max_frames*sizeof(struct dpaa2_dq)". The 'dpaa2_io_store' returned is a
+ * wrapper structure allocated within the DPIO code, which owns and manages
+ * allocated store.
+ *
+ * Return dpaa2_io_store struct for successfuly created storage memory, or NULL
+ * if not getting the stroage for dequeue result in create API.
+ */
+struct dpaa2_io_store *dpaa2_io_store_create(unsigned int max_frames,
+					   struct device *dev);
+void dpaa2_io_store_destroy(struct dpaa2_io_store *s);
+
+/**
+ * dpaa2_io_store_next() - Determine when the next dequeue result is available.
+ * @s: the dpaa2_io_store object.
+ * @is_last: indicate whether this is the last frame in the pull command.
+ *
+ * Once dpaa2_io_store has been passed to a function that performs dequeues to
+ * it, like dpaa_ni_rx(), this function can be used to determine when the next
+ * frame result is available. Once this function returns non-NULL, a subsequent
+ * call to it will try to find the *next* dequeue result.
+ *
+ * Note that if a pull-dequeue has a null result because the target FQ/channel
+ * was empty, then this function will return NULL rather than expect the caller
+ * to always check for this on his own side. As such, "is_last" can be used to
+ * differentiate between "end-of-empty-dequeue" and "still-waiting".
+ *
+ * Return dequeue result for a valid dequeue result, or NULL for empty dequeue.
+ */
+struct dpaa2_dq *dpaa2_io_store_next(struct dpaa2_io_store *s, int *is_last);
+
+#ifdef CONFIG_FSL_QBMAN_DEBUG
+/**
+ * dpaa2_io_query_fq_count() - Get the frame and byte count for a given fq.
+ * @d: the given DPIO object.
+ * @fqid: the id of frame queue to be queried.
+ * @fcnt: the queried frame count.
+ * @bcnt: the queried byte count.
+ *
+ * Knowing the FQ count at run-time can be useful in debugging situations.
+ * The instantaneous frame- and byte-count are hereby returned.
+ *
+ * Return 0 for a successful query, and negative error code if query fails.
+ */
+int dpaa2_io_query_fq_count(struct dpaa2_io *d, uint32_t fqid,
+			   uint32_t *fcnt, uint32_t *bcnt);
+
+/**
+ * dpaa2_io_query_bp_count() - Query the number of buffers currenty in a
+ * buffer pool.
+ * @d: the given DPIO object.
+ * @bpid: the index of buffer pool to be queried.
+ * @num: the queried number of buffers in the buffer pool.
+ *
+ * Return 0 for a sucessful query, and negative error code if query fails.
+ */
+int dpaa2_io_query_bp_count(struct dpaa2_io *d, uint32_t bpid,
+			   uint32_t *num);
+#endif
+#endif /* __FSL_DPAA2_IO_H */
diff --git a/drivers/staging/fsl-mc/include/fsl_dpaa_fd.h b/drivers/staging/fsl-mc/include/fsl_dpaa_fd.h
deleted file mode 100644
index 9a7c7de..0000000
--- a/drivers/staging/fsl-mc/include/fsl_dpaa_fd.h
+++ /dev/null
@@ -1,470 +0,0 @@
-/* Copyright 2014 Freescale Semiconductor Inc.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are met:
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in the
- *       documentation and/or other materials provided with the distribution.
- *     * Neither the name of Freescale Semiconductor nor the
- *       names of its contributors may be used to endorse or promote products
- *       derived from this software without specific prior written permission.
- *
- *
- * ALTERNATIVELY, this software may be distributed under the terms of the
- * GNU General Public License ("GPL") as published by the Free Software
- * Foundation, either version 2 of that License or (at your option) any
- * later version.
- *
- * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
- * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
- * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
- * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
- * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
- * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
- * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
- * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-#ifndef __FSL_DPAA_FD_H
-#define __FSL_DPAA_FD_H
-
-/**
- * struct dpaa_fd - Place-holder for FDs.
- *
- * We represent it via the simplest form that we need for now. Different
- * overlays may be needed to support different options, etc. (It is impractical
- * to define One True Struct, because the resulting encoding routines (lots of
- * read-modify-writes) would be worst-case performance whether or not
- * circumstances required them.)
- */
-struct dpaa_fd {
-	union {
-		u32 words[8];
-		struct dpaa_fd_simple {
-			u32 addr_lo;
-			u32 addr_hi;
-			u32 len;
-			/* offset in the MS 16 bits, BPID in the LS 16 bits */
-			u32 bpid_offset;
-			u32 frc; /* frame context */
-			/* "err", "va", "cbmt", "asal", [...] */
-			u32 ctrl;
-			/* flow context */
-			u32 flc_lo;
-			u32 flc_hi;
-		} simple;
-	};
-};
-
-enum dpaa_fd_format {
-	dpaa_fd_single = 0,
-	dpaa_fd_list,
-	dpaa_fd_sg
-};
-
-/**
- * ldpaa_fd_get_addr() - get the addr field of frame descriptor
- * @fd: the given frame descriptor.
- *
- * Return the address in the frame descritpor.
- */
-static inline dma_addr_t ldpaa_fd_get_addr(const struct dpaa_fd *fd)
-{
-	return (dma_addr_t)((((uint64_t)fd->simple.addr_hi) << 32)
-				+ fd->simple.addr_lo);
-}
-
-/**
- * ldpaa_fd_set_addr() - Set the addr field of frame descriptor
- * @fd: the given frame descriptor.
- * @addr: the address needs to be set in frame descriptor.
- */
-static inline void ldpaa_fd_set_addr(struct dpaa_fd *fd, dma_addr_t addr)
-{
-	fd->simple.addr_hi = upper_32_bits(addr);
-	fd->simple.addr_lo = lower_32_bits(addr);
-}
-
-/**
- * ldpaa_fd_get_len() - Get the length in the frame descriptor
- * @fd: the given frame descriptor.
- *
- * Return the length field in the frame descriptor.
- */
-static inline u32 ldpaa_fd_get_len(const struct dpaa_fd *fd)
-{
-	return fd->simple.len;
-}
-
-/**
- * ldpaa_fd_set_len() - Set the length field of frame descriptor
- * @fd: the given frame descriptor.
- * @len: the length needs to be set in frame descriptor.
- */
-static inline void ldpaa_fd_set_len(struct dpaa_fd *fd, u32 len)
-{
-	fd->simple.len = len;
-}
-
-/**
- * ldpaa_fd_get_offset() - Get the offset field in the frame descriptor
- * @fd: the given frame descriptor.
- *
- * Return the offset.
- */
-static inline uint16_t ldpaa_fd_get_offset(const struct dpaa_fd *fd)
-{
-	return (uint16_t)(fd->simple.bpid_offset >> 16) & 0x0FFF;
-}
-
-/**
- * ldpaa_fd_set_offset() - Set the offset field of frame descriptor
- *
- * @fd: the given frame descriptor.
- * @offset: the offset needs to be set in frame descriptor.
- */
-static inline void ldpaa_fd_set_offset(struct dpaa_fd *fd, uint16_t offset)
-{
-	fd->simple.bpid_offset &= 0xF000FFFF;
-	fd->simple.bpid_offset |= (u32)offset << 16;
-}
-
-/**
- * ldpaa_fd_get_format() - Get the format field in the frame descriptor
- * @fd: the given frame descriptor.
- *
- * Return the format.
- */
-static inline enum dpaa_fd_format ldpaa_fd_get_format(const struct dpaa_fd *fd)
-{
-	return (enum dpaa_fd_format)((fd->simple.bpid_offset >> 28) & 0x3);
-}
-
-/**
- * ldpaa_fd_set_format() - Set the format field of frame descriptor
- *
- * @fd: the given frame descriptor.
- * @format: the format needs to be set in frame descriptor.
- */
-static inline void ldpaa_fd_set_format(struct dpaa_fd *fd,
-				       enum dpaa_fd_format format)
-{
-	fd->simple.bpid_offset &= 0xCFFFFFFF;
-	fd->simple.bpid_offset |= (u32)format << 28;
-}
-
-/**
- * ldpaa_fd_get_bpid() - Get the bpid field in the frame descriptor
- * @fd: the given frame descriptor.
- *
- * Return the bpid.
- */
-static inline uint16_t ldpaa_fd_get_bpid(const struct dpaa_fd *fd)
-{
-	return (uint16_t)(fd->simple.bpid_offset & 0xFFFF);
-}
-
-/**
- * ldpaa_fd_set_bpid() - Set the bpid field of frame descriptor
- *
- * @fd: the given frame descriptor.
- * @bpid: the bpid needs to be set in frame descriptor.
- */
-static inline void ldpaa_fd_set_bpid(struct dpaa_fd *fd, uint16_t bpid)
-{
-	fd->simple.bpid_offset &= 0xFFFF0000;
-	fd->simple.bpid_offset |= (u32)bpid;
-}
-
-/**
- * struct dpaa_sg_entry - the scatter-gathering structure
- */
-struct dpaa_sg_entry {
-	u32 addr_lo;
-	u32 addr_hi;
-	u32 len;
-	u32 bpid_offset;
-};
-
-enum dpaa_sg_format {
-	dpaa_sg_single = 0,
-	dpaa_sg_frame_data,
-	dpaa_sg_sgt_ext
-};
-
-/* Accessors for SG entry fields
- *
- * These setters and getters assume little endian format. For converting
- * between LE and cpu endianness, the specific conversion functions must be
- * called before the SGE contents are accessed by the core (on Rx),
- * respectively before the SG table is sent to hardware (on Tx)
- */
-
-/**
- * ldpaa_sg_get_addr() - Get the address from SG entry
- * @sg: the given scatter-gathering object.
- *
- * Return the address.
- */
-static inline dma_addr_t ldpaa_sg_get_addr(const struct dpaa_sg_entry *sg)
-{
-	return (dma_addr_t)((((u64)sg->addr_hi) << 32) + sg->addr_lo);
-}
-
-/**
- * ldpaa_sg_set_addr() - Set the address in SG entry
- * @sg: the given scatter-gathering object.
- * @addr: the address to be set.
- */
-static inline void ldpaa_sg_set_addr(struct dpaa_sg_entry *sg, dma_addr_t addr)
-{
-	sg->addr_hi = upper_32_bits(addr);
-	sg->addr_lo = lower_32_bits(addr);
-}
-
-static inline bool ldpaa_sg_short_len(const struct dpaa_sg_entry *sg)
-{
-	return (sg->bpid_offset >> 30) & 0x1;
-}
-
-/**
- * ldpaa_sg_get_len() - Get the length in SG entry
- * @sg: the given scatter-gathering object.
- *
- * Return the length.
- */
-static inline u32 ldpaa_sg_get_len(const struct dpaa_sg_entry *sg)
-{
-	if (ldpaa_sg_short_len(sg))
-		return sg->len & 0x1FFFF;
-	return sg->len;
-}
-
-/**
- * ldpaa_sg_set_len() - Set the length in SG entry
- * @sg: the given scatter-gathering object.
- * @len: the length to be set.
- */
-static inline void ldpaa_sg_set_len(struct dpaa_sg_entry *sg, u32 len)
-{
-	sg->len = len;
-}
-
-/**
- * ldpaa_sg_get_offset() - Get the offset in SG entry
- * @sg: the given scatter-gathering object.
- *
- * Return the offset.
- */
-static inline u16 ldpaa_sg_get_offset(const struct dpaa_sg_entry *sg)
-{
-	return (u16)(sg->bpid_offset >> 16) & 0x0FFF;
-}
-
-/**
- * ldpaa_sg_set_offset() - Set the offset in SG entry
- * @sg: the given scatter-gathering object.
- * @offset: the offset to be set.
- */
-static inline void ldpaa_sg_set_offset(struct dpaa_sg_entry *sg,
-				       u16 offset)
-{
-	sg->bpid_offset &= 0xF000FFFF;
-	sg->bpid_offset |= (u32)offset << 16;
-}
-
-/**
- * ldpaa_sg_get_format() - Get the SG format in SG entry
- * @sg: the given scatter-gathering object.
- *
- * Return the format.
- */
-static inline enum dpaa_sg_format
-	ldpaa_sg_get_format(const struct dpaa_sg_entry *sg)
-{
-	return (enum dpaa_sg_format)((sg->bpid_offset >> 28) & 0x3);
-}
-
-/**
- * ldpaa_sg_set_format() - Set the SG format in SG entry
- * @sg: the given scatter-gathering object.
- * @format: the format to be set.
- */
-static inline void ldpaa_sg_set_format(struct dpaa_sg_entry *sg,
-				       enum dpaa_sg_format format)
-{
-	sg->bpid_offset &= 0xCFFFFFFF;
-	sg->bpid_offset |= (u32)format << 28;
-}
-
-/**
- * ldpaa_sg_get_bpid() - Get the buffer pool id in SG entry
- * @sg: the given scatter-gathering object.
- *
- * Return the bpid.
- */
-static inline u16 ldpaa_sg_get_bpid(const struct dpaa_sg_entry *sg)
-{
-	return (u16)(sg->bpid_offset & 0x3FFF);
-}
-
-/**
- * ldpaa_sg_set_bpid() - Set the buffer pool id in SG entry
- * @sg: the given scatter-gathering object.
- * @bpid: the bpid to be set.
- */
-static inline void ldpaa_sg_set_bpid(struct dpaa_sg_entry *sg, u16 bpid)
-{
-	sg->bpid_offset &= 0xFFFFC000;
-	sg->bpid_offset |= (u32)bpid;
-}
-
-/**
- * ldpaa_sg_is_final() - Check final bit in SG entry
- * @sg: the given scatter-gathering object.
- *
- * Return bool.
- */
-static inline bool ldpaa_sg_is_final(const struct dpaa_sg_entry *sg)
-{
-	return !!(sg->bpid_offset >> 31);
-}
-
-/**
- * ldpaa_sg_set_final() - Set the final bit in SG entry
- * @sg: the given scatter-gathering object.
- * @final: the final boolean to be set.
- */
-static inline void ldpaa_sg_set_final(struct dpaa_sg_entry *sg, bool final)
-{
-	sg->bpid_offset &= 0x7FFFFFFF;
-	sg->bpid_offset |= (u32)final << 31;
-}
-
-/* Endianness conversion helper functions
- * The accelerator drivers which construct / read scatter gather entries
- * need to call these in order to account for endianness mismatches between
- * hardware and cpu
- */
-#ifdef __BIG_ENDIAN
-static inline void ldpaa_sg_cpu_to_le(struct dpaa_sg_entry *sg)
-{
-	uint32_t *p = (uint32_t *)sg;
-	int i;
-
-	for (i = 0; i < sizeof(*sg) / sizeof(u32); i++)
-		cpu_to_le32s(p++);
-}
-
-static inline void ldpaa_sg_le_to_cpu(struct dpaa_sg_entry *sg)
-{
-	uint32_t *p = (uint32_t *)sg;
-	int i;
-
-	for (i = 0; i < sizeof(*sg) / sizeof(u32); i++)
-		le32_to_cpus(p++);
-}
-#else
-#define ldpaa_sg_cpu_to_le(sg)
-#define ldpaa_sg_le_to_cpu(sg)
-#endif /* __BIG_ENDIAN */
-
-/**
- * struct ldpaa_dq - the qman result structure
- *
- * When frames are dequeued, the FDs show up inside "dequeue" result structures
- * (if at all, not all dequeue results contain valid FDs). This structure type
- * is intentionally defined without internal detail, and the only reason it
- * isn't declared opaquely (without size) is to allow the user to provide
- * suitably-sized (and aligned) memory for these entries.
- */
-struct ldpaa_dq {
-	uint32_t dont_manipulate_directly[16];
-};
-
-/* Parsing frame dequeue results */
-#define LDPAA_DQ_STAT_FQEMPTY       0x80
-#define LDPAA_DQ_STAT_HELDACTIVE    0x40
-#define LDPAA_DQ_STAT_FORCEELIGIBLE 0x20
-#define LDPAA_DQ_STAT_VALIDFRAME    0x10
-#define LDPAA_DQ_STAT_ODPVALID      0x04
-#define LDPAA_DQ_STAT_VOLATILE      0x02
-#define LDPAA_DQ_STAT_EXPIRED       0x01
-/**
- * ldpaa_dq_flags() - Get the stat field of dequeue response
- */
-uint32_t ldpaa_dq_flags(const struct ldpaa_dq *);
-
-/**
- * ldpaa_dq_is_pull() - Check whether the dq response is from a pull
- * command.
- * @dq: the dequeue result.
- *
- * Return 1 for volatile(pull) dequeue, 0 for static dequeue.
- */
-static inline int ldpaa_dq_is_pull(const struct ldpaa_dq *dq)
-{
-	return (int)(ldpaa_dq_flags(dq) & LDPAA_DQ_STAT_VOLATILE);
-}
-
-/**
- * ldpaa_dq_is_pull_complete() - Check whether the pull command is completed.
- * @dq: the dequeue result.
- *
- * Return boolean.
- */
-static inline int ldpaa_dq_is_pull_complete(
-					const struct ldpaa_dq *dq)
-{
-	return (int)(ldpaa_dq_flags(dq) & LDPAA_DQ_STAT_EXPIRED);
-}
-
-/**
- * ldpaa_dq_seqnum() - Get the seqnum field in dequeue response
- * seqnum is valid only if VALIDFRAME flag is TRUE
- *
- * Return seqnum.
- */
-uint16_t ldpaa_dq_seqnum(const struct ldpaa_dq *);
-/**
- * ldpaa_dq_odpid() - Get the seqnum field in dequeue response
- * odpid is valid only if ODPVAILD flag is TRUE.
- *
- * Return odpid.
- */
-uint16_t ldpaa_dq_odpid(const struct ldpaa_dq *);
-/**
- * ldpaa_dq_fqid() - Get the fqid in dequeue response
- *
- * Return fqid.
- */
-uint32_t ldpaa_dq_fqid(const struct ldpaa_dq *);
-/**
- * ldpaa_dq_byte_count() - Get the byte count in dequeue response
- *
- * Return the byte count remaining in the FQ.
- */
-uint32_t ldpaa_dq_byte_count(const struct ldpaa_dq *);
-/**
- * ldpaa_dq_frame_count() - Get the frame count in dequeue response
- *
- * Return the frame count remaining in the FQ.
- */
-uint32_t ldpaa_dq_frame_count(const struct ldpaa_dq *);
-/**
- * ldpaa_dq_fd_ctx() - Get the frame queue context in dequeue response
- *
- * Return the frame queue context.
- */
-uint64_t ldpaa_dq_fqd_ctx(const struct ldpaa_dq *dq);
-/**
- * ldpaa_dq_fd() - Get the frame descriptor in dequeue response
- *
- * Return the frame descriptor.
- */
-const struct dpaa_fd *ldpaa_dq_fd(const struct ldpaa_dq *);
-
-#endif /* __FSL_DPAA_FD_H */
diff --git a/drivers/staging/fsl-mc/include/fsl_dpaa_io.h b/drivers/staging/fsl-mc/include/fsl_dpaa_io.h
deleted file mode 100644
index 2bc2e5d..0000000
--- a/drivers/staging/fsl-mc/include/fsl_dpaa_io.h
+++ /dev/null
@@ -1,554 +0,0 @@
-/* Copyright 2014 Freescale Semiconductor Inc.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are met:
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in the
- *       documentation and/or other materials provided with the distribution.
- *     * Neither the name of Freescale Semiconductor nor the
- *       names of its contributors may be used to endorse or promote products
- *       derived from this software without specific prior written permission.
- *
- *
- * ALTERNATIVELY, this software may be distributed under the terms of the
- * GNU General Public License ("GPL") as published by the Free Software
- * Foundation, either version 2 of that License or (at your option) any
- * later version.
- *
- * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
- * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
- * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
- * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
- * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
- * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
- * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
- * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-#ifndef __FSL_DPAA_IO_H
-#define __FSL_DPAA_IO_H
-
-#include "fsl_dpaa_fd.h"
-
-struct dpaa_io;
-struct dpaa_io_store;
-
-/***************************/
-/* DPIO Service management */
-/***************************/
-
-/**
- * struct dpaa_io_desc - The DPIO descriptor.
- *
- * Describe the attributes and features of the DPIO object.
- */
-struct dpaa_io_desc {
-	/* non-zero iff the DPIO has a channel */
-	int receives_notifications;
-	/* non-zero if the DPIO portal interrupt is handled. If so, the
-	 * caller/OS handles the interrupt and calls dpaa_io_service_irq(). */
-	int has_irq;
-	/* non-zero if the caller/OS is prepared to called the
-	 * dpaa_io_service_poll() routine as part of its run-to-completion (or
-	 * scheduling) loop. If so, the DPIO service may dynamically switch some
-	 * of its processing between polling-based and irq-based. It is illegal
-	 * combination to have (!has_irq && !will_poll). */
-	int will_poll;
-	/* ignored unless 'receives_notifications'. Non-zero iff the channel has
-	 * 8 priority WQs, otherwise the channel has 2. */
-	int has_8prio;
-	/* the cpu index that at least interrupt handlers will execute on. And
-	 * if 'stash_affinity' is non-zero, the cache targeted by stash
-	 * transactions is affine to this cpu. */
-	int cpu;
-	/* non-zero if stash transactions for this portal favour 'cpu' over
-	 * other CPUs. (Eg. zero if there's no stashing, or stashing is to
-	 * shared cache.) */
-	int stash_affinity;
-	/* Caller-provided flags, determined by bus-scanning and/or creation of
-	 * DPIO objects via MC commands. */
-	void *regs_cena;
-	void *regs_cinh;
-	int dpio_id;
-};
-
-/**
- * dpaa_io_create() - create a dpaa_io object.
- * @desc: the dpaa_io descriptor
- *
- * Activates a "struct dpaa_io" corresponding to the given config of an actual
- * DPIO object. This handle can be used on it's own (like a one-portal "DPIO
- * service") or later be added to a service-type "struct dpaa_io" object. Note,
- * the information required on 'cfg' is copied so the caller is free to do as
- * they wish with the input parameter upon return.
- *
- * Return a valid dpaa_io object for success, or NULL for failure.
- */
-struct dpaa_io *dpaa_io_create(const struct dpaa_io_desc *desc);
-
-/**
- * dpaa_io_create_service() -  Create an (initially empty) DPIO service.
- *
- * Return a valid dpaa_io object for success, or NULL for failure.
- */
-struct dpaa_io *dpaa_io_create_service(void);
-
-/**
- * dpaa_io_default_service() - Use the driver's own global (and initially
- * empty) DPIO service.
- *
- * This increments the reference count, so don't forget to use dpaa_io_down()
- * for each time this function is called.
- *
- * Return a valid dpaa_io object for success, or NULL for failure.
- */
-struct dpaa_io *dpaa_io_default_service(void);
-
-/**
- * dpaa_io_down() - release the dpaa_io object.
- * @d: the dpaa_io object to be released.
- *
- * The "struct dpaa_io" type can represent an individual DPIO object (as
- * described by "struct dpaa_io_desc") or an instance of a "DPIO service", which
- * can be used to group/encapsulate multiple DPIO objects. In all cases, each
- * handle obtained should be released using this function.
- */
-void dpaa_io_down(struct dpaa_io *d);
-
-/**
- * dpaa_io_service_add() - Add the given DPIO object to the given DPIO service.
- * @service: the given DPIO service.
- * @obj: the given DPIO object.
- *
- * 'service' must have been created by dpaa_io_create_service() and 'obj'
- * must have been created by dpaa_io_create(). This increments the reference
- * count on the object that 'obj' refers to, so the user could call
- * dpaa_io_down(obj) after this and the object will persist within the service
- * (and will be destroyed when the service is destroyed).
- *
- * Return 0 for success, or -EINVAL for failure.
- */
-int dpaa_io_service_add(struct dpaa_io *service, struct dpaa_io *obj);
-
-/**
- * dpaa_io_get_descriptor() - Get the DPIO descriptor of the given DPIO object.
- * @obj: the given DPIO object.
- * @desc: the returned DPIO descriptor.
- *
- * This function will return failure if the given dpaa_io struct represents a
- * service rather than an individual DPIO object, otherwise it returns zero and
- * the given 'cfg' structure is filled in.
- *
- * Return 0 for success, or -EINVAL for failure.
- */
-int dpaa_io_get_descriptor(struct dpaa_io *obj, struct dpaa_io_desc *desc);
-
-/**
- * dpaa_io_poll() -  Process any notifications and h/w-initiated events that
- * are polling-driven.
- * @obj: the given DPIO object.
- *
- * Obligatory for DPIO objects that have dpaa_io_desc::will_poll non-zero.
- *
- * Return 0 for success, or -EINVAL for failure.
- */
-int dpaa_io_poll(struct dpaa_io *obj);
-
-/**
- * dpaa_io_irq() - Process any notifications and h/w-initiated events that are
- * irq-driven.
- * @obj: the given DPIO object.
- *
- * Obligatory for DPIO objects that have dpaa_io_desc::has_irq non-zero.
- *
- * Return IRQ_HANDLED for success, or -EINVAL for failure.
- */
-int dpaa_io_irq(struct dpaa_io *obj);
-
-/**
- * dpaa_io_pause_poll() - Used to stop polling.
- * @obj: the given DPIO object.
- *
- * If a polling application is going to stop polling for a period of time and
- * supports interrupt processing, it can call this function to convert all
- * processing to IRQ. (Eg. when sleeping.)
- *
- * Return -EINVAL.
- */
-int dpaa_io_pause_poll(struct dpaa_io *obj);
-
-/**
- * dpaa_io_resume_poll() - Resume polling
- * @obj: the given DPIO object.
- *
- * Return -EINVAL.
- */
-int dpaa_io_resume_poll(struct dpaa_io *obj);
-
-/**
- * dpaa_io_service_notifications() - Get a mask of cpus that the DPIO service
- * can receive notifications on.
- * @s: the given DPIO object.
- * @mask: the mask of cpus.
- *
- * Note that this is a run-time snapshot. If things like cpu-hotplug are
- * supported in the target system, then an attempt to register notifications
- * for a cpu that appears present in the given mask might fail if that cpu has
- * gone offline in the mean time.
- */
-void dpaa_io_service_notifications(struct dpaa_io *s, cpumask_t *mask);
-
-/**
- * dpaa_io_service_stashing - Get a mask of cpus that the DPIO service has stash
- * affinity to.
- * @s: the given DPIO object.
- * @mask: the mask of cpus.
- */
-void dpaa_io_service_stashing(struct dpaa_io *s, cpumask_t *mask);
-
-/**
- * dpaa_io_service_nonaffine() - Check the DPIO service's cpu affinity
- * for stashing.
- * @s: the given DPIO object.
- *
- * Return a boolean, whether or not the DPIO service has resources that have no
- * particular cpu affinity for stashing. (Useful to know if you wish to operate
- * on CPUs that the service has no affinity to, you would choose to use
- * resources that are neutral, rather than affine to a different CPU.) Unlike
- * other service-specific APIs, this one doesn't return an error if it is passed
- * a non-service object. So don't do it.
- */
-int dpaa_io_service_has_nonaffine(struct dpaa_io *s);
-
-/*************************/
-/* Notification handling */
-/*************************/
-
-/**
- * struct dpaa_io_notification_ctx - The DPIO notification context structure.
- *
- * When a FQDAN/CDAN registration is made (eg. by DPNI/DPCON/DPAI code), a
- * context of the following type is used. The caller can embed it within a
- * larger structure in order to add state that is tracked along with the
- * notification (this may be useful when callbacks are invoked that pass this
- * notification context as a parameter).
- */
-struct dpaa_io_notification_ctx {
-	/* the callback to be invoked when the notification arrives */
-	void (*cb)(struct dpaa_io_notification_ctx *);
-	/* Zero/FALSE for FQDAN, non-zero/TRUE for CDAN */
-	int is_cdan;
-	uint32_t id; /* FQID or channel ID, needed for rearm */
-	/* This specifies which cpu the user wants notifications to show up on
-	 * (ie. to execute 'cb'). If notification-handling on that cpu is not
-	 * available at the time of notification registration, the registration
-	 * will fail. */
-	int desired_cpu;
-	/* If the target platform supports cpu-hotplug or other features
-	 * (related to power-management, one would expect) that can migrate IRQ
-	 * handling of a given DPIO object, then this value will potentially be
-	 * different to 'desired_cpu' at run-time. */
-	int actual_cpu;
-	/* And if migration does occur and this callback is non-NULL, it will
-	 * be invoked prior to any futher notification callbacks executing on
-	 * 'newcpu'. Note that 'oldcpu' is what 'actual_cpu' was prior to the
-	 * migration, and 'newcpu' is what it is now. Both could conceivably be
-	 * different to 'desired_cpu'. */
-	void (*migration_cb)(struct dpaa_io_notification_ctx *,
-			     int oldcpu, int newcpu);
-	/* These are returned from dpaa_io_service_register().
-	 * 'dpio_id' is the dpaa_io_desc::dpio_id value of the DPIO object that
-	 * has been selected by the service for receiving the notifications. The
-	 * caller can use this value in the MC command that attaches the FQ (or
-	 * channel) of their DPNI (or DPCON, respectively) to this DPIO for
-	 * notification-generation.
-	 * 'qman64' is the 64-bit context value that needs to be sent in the
-	 * same MC command in order to be programmed into the FQ or channel -
-	 * this is the 64-bit value that shows up in the FQDAN/CDAN messages to
-	 * the DPIO object, and the DPIO service specifies this value back to
-	 * the caller so that the notifications that show up will be
-	 * comprensible/demux-able to the DPIO service. */
-	int dpio_id;
-	uint64_t qman64;
-	/* These fields are internal to the DPIO service once the context is
-	 * registered. TBD: may require more internal state fields. */
-	struct list_head node;
-	void *dpio_private;
-};
-
-/**
- * dpaa_io_service_register() - Prepare for servicing of FQDAN or CDAN
- * notifications on the given DPIO service.
- * @service: the given DPIO service.
- * @ctx: the notificaiton context.
- *
- * The MC command to attach the caller's DPNI/DPCON/DPAI device to a
- * DPIO object is performed after this function is called. In that way, (a) the
- * DPIO service is "ready" to handle a notification arrival (which might happen
- * before the "attach" command to MC has returned control of execution back to
- * the caller), and (b) the DPIO service can provide back to the caller the
- * 'dpio_id' and 'qman64' parameters that it should pass along in the MC command
- * in order for the DPNI/DPCON/DPAI resources to be configured to produce the
- * right notification fields to the DPIO service.
- *
- * Return 0 for success, or -ENODEV for failure.
- */
-int dpaa_io_service_register(struct dpaa_io *service,
-			     struct dpaa_io_notification_ctx *ctx);
-
-/**
- * dpaa_io_service_deregister - The opposite of 'register'.
- * @service: the given DPIO service.
- * @ctx: the notificaiton context.
- *
- * Note that 'register' should be called *before*
- * making the MC call to attach the notification-producing device to the
- * notification-handling DPIO service, the 'unregister' function should be
- * called *after* making the MC call to detach the notification-producing
- * device.
- *
- * Return 0 for success.
- */
-int dpaa_io_service_deregister(struct dpaa_io *service,
-			       struct dpaa_io_notification_ctx *ctx);
-
-/**
- * dpaa_io_service_rearm() - Rearm the notification for the given DPIO service.
- * @service: the given DPIO service.
- * @ctx: the notificaiton context.
- *
- * Once a FQDAN/CDAN has been produced, the corresponding FQ/channel is
- * considered "disarmed". Ie. the user can issue pull dequeue operations on that
- * traffic source for as long as it likes. Eventually it may wish to "rearm"
- * that source to allow it to produce another FQDAN/CDAN, that's what this
- * function achieves.
- *
- * Return 0 for success, or -ENODEV if no service available, -EBUSY/-EIO for not
- * being able to implement the rearm the notifiaton due to setting CDAN or
- * scheduling fq.
- */
-int dpaa_io_service_rearm(struct dpaa_io *service,
-			  struct dpaa_io_notification_ctx *ctx);
-
-/**
- * dpaa_io_from_registration() - Get the DPIO object from the given notification
- * context.
- * @ctx: the given notifiation context.
- * @ret: the returned DPIO object.
- *
- * Like 'dpaa_io_service_get_persistent()' (see below), except that the returned
- * handle is not selected based on a 'cpu' argument, but is the same DPIO object
- * that the given notification context is registered against. The returned
- * handle carries a reference count, so a corresponding dpaa_io_down() would be
- * required when the reference is no longer needed.
- *
- * Return 0 for success, or -EINVAL for failure.
- */
-int dpaa_io_from_registration(struct dpaa_io_notification_ctx *ctx,
-			      struct dpaa_io **ret);
-
-/**********************************/
-/* General usage of DPIO services */
-/**********************************/
-
-/**
- * dpaa_io_service_get_persistent() - Get the DPIO resource from the given
- * notification context and cpu.
- * @ctx: the given notifiation context.
- * @cpu: the cpu that the DPIO resource has stashing affinity to.
- * @ret: the returned DPIO resource.
- *
- * The various DPIO interfaces can accept a "struct dpaa_io" handle that refers
- * to an individual DPIO object or to a whole service. In the latter case, an
- * internal choice is made for each operation. This function supports the former
- * case, by selecting an individual DPIO object *from* the service in order for
- * it to be used multiple times to provide "persistence". The returned handle
- * also carries a reference count, so a corresponding dpaa_io_down() would be
- * required when the reference is no longer needed. Note, a parameter of -1 for
- * 'cpu' will select a DPIO resource that has no particular stashing affinity to
- * any cpu (eg. one that stashes to platform cache).
- *
- * Return 0 for success, or -ENODEV for failure.
- */
-int dpaa_io_service_get_persistent(struct dpaa_io *service, int cpu,
-				   struct dpaa_io **ret);
-
-/*****************/
-/* Pull dequeues */
-/*****************/
-
-/**
- * dpaa_io_service_pull_fq()
- * dpaa_io_service_pull_channel() - pull dequeue functions from fq or channel.
- * @d: the given DPIO service.
- * @fqid: the given frame queue id.
- * @channelid: the given channel id.
- * @s: the dpaa_io_store object for the result.
- *
- * To support DCA/order-preservation, it will be necessary to support an
- * alternative form, because they must ultimately dequeue to DQRR rather than a
- * user-supplied dpaa_io_store. Furthermore, those dequeue results will
- * "complete" using a caller-provided callback (from DQRR processing) rather
- * than the caller explicitly looking at their dpaa_io_store for results. Eg.
- * the alternative form will likely take a callback parameter rather than a
- * store parameter. Ignoring it for now to keep the picture clearer.
- *
- * Return 0 for success, or error code for failure.
- */
-int dpaa_io_service_pull_fq(struct dpaa_io *d, uint32_t fqid,
-			    struct dpaa_io_store *s);
-int dpaa_io_service_pull_channel(struct dpaa_io *d, uint32_t channelid,
-				 struct dpaa_io_store *s);
-
-/************/
-/* Enqueues */
-/************/
-
-/**
- * dpaa_io_service_enqueue_fq()
- * dpaa_io_service_enqueue_qd() - The enqueue functions to FQ or QD
- * @d: the given DPIO service.
- * @fqid: the given frame queue id.
- * @qdid: the given queuing destination id.
- * @prio: the given queuing priority.
- * @qdbin: the given queuing destination bin.
- * @fd: the frame descriptor which is enqueued.
- *
- * This definition bypasses some features that are not expected to be priority-1
- * features, and may not be needed at all via current assumptions (QBMan's
- * feature set is wider than the MC object model is intendeding to support,
- * initially at least). Plus, keeping them out (for now) keeps the API view
- * simpler. Missing features are;
- *  - enqueue confirmation (results DMA'd back to the user)
- *  - ORP
- *  - DCA/order-preservation (see note in "pull dequeues")
- *  - enqueue consumption interrupts
- *
- * Return 0 for successful enqueue, or -EBUSY if the enqueue ring is not ready,
- * or -ENODEV if there is no dpio service.
- */
-int dpaa_io_service_enqueue_fq(struct dpaa_io *d,
-			       uint32_t fqid,
-			       const struct dpaa_fd *fd);
-int dpaa_io_service_enqueue_qd(struct dpaa_io *d,
-			       uint32_t qdid, uint8_t prio, uint16_t qdbin,
-			       const struct dpaa_fd *fd);
-
-/*******************/
-/* Buffer handling */
-/*******************/
-
-/**
- * dpaa_io_service_release() - Release buffers to a buffer pool.
- * @d: the given DPIO object.
- * @bpid: the buffer pool id.
- * @buffers: the buffers to be released.
- * @num_buffers: the number of the buffers to be released.
- *
- * Return 0 for success, and negative error code for failure.
- */
-int dpaa_io_service_release(struct dpaa_io *d,
-			    uint32_t bpid,
-			    const uint64_t *buffers,
-			    unsigned int num_buffers);
-
-/**
- * dpaa_io_service_acquire() - Acquire buffers from a buffer pool.
- * @d: the given DPIO object.
- * @bpid: the buffer pool id.
- * @buffers: the buffer addresses for acquired buffers.
- * @num_buffers: the expected number of the buffers to acquire.
- *
- * Return a negative error code if the command failed, otherwise it returns
- * the number of buffers acquired, which may be less than the number requested.
- * Eg. if the buffer pool is empty, this will return zero.
- */
-int dpaa_io_service_acquire(struct dpaa_io *,
-			    uint32_t bpid,
-			    uint64_t *buffers,
-			    unsigned int num_buffers);
-
-/***************/
-/* DPIO stores */
-/***************/
-
-/* These are reusable memory blocks for retrieving dequeue results into, and to
- * assist with parsing those results once they show up. They also hide the
- * details of how to use "tokens" to make detection of DMA results possible (ie.
- * comparing memory before the DMA and after it) while minimising the needless
- * clearing/rewriting of those memory locations between uses.
- */
-
-/**
- * dpaa_io_store_create()
- * dpaa_io_store_destroy() - Create/destroy the dma memory storage for dequeue
- * result.
- * @max_frames: the maximum number of dequeued result for frames, must be <= 16.
- * @dev: the device to allow mapping/unmapping the DMAable region.
- * @s: the storage memory to be destroyed.
- *
- * Constructor/destructor - max_frames must be <= 16. The user provides the
- * device struct to allow mapping/unmapping of the DMAable region. Area for
- * storage will be allocated during create. The size of this storage is
- * "max_frames*sizeof(struct ldpaa_dq)". The 'dpaa_io_store' returned is a
- * wrapper structure allocated within the DPIO code, which owns and manages
- * allocated store.
- *
- * Return dpaa_io_store struct for successfuly created storage memory, or NULL
- * if not getting the stroage for dequeue result in create API.
- */
-struct dpaa_io_store *dpaa_io_store_create(unsigned int max_frames,
-					   struct device *dev);
-void dpaa_io_store_destroy(struct dpaa_io_store *s);
-
-/**
- * dpaa_io_store_next() - Determine when the next dequeue result is available.
- * @s: the dpaa_io_store object.
- * @is_last: indicate whether this is the last frame in the pull command.
- *
- * Once dpaa_io_store has been passed to a function that performs dequeues to
- * it, like dpaa_ni_rx(), this function can be used to determine when the next
- * frame result is available. Once this function returns non-NULL, a subsequent
- * call to it will try to find the *next* dequeue result.
- *
- * Note that if a pull-dequeue has a null result because the target FQ/channel
- * was empty, then this function will return NULL rather than expect the caller
- * to always check for this on his own side. As such, "is_last" can be used to
- * differentiate between "end-of-empty-dequeue" and "still-waiting".
- *
- * Return dequeue result for a valid dequeue result, or NULL for empty dequeue.
- */
-struct ldpaa_dq *dpaa_io_store_next(struct dpaa_io_store *s, int *is_last);
-
-#ifdef CONFIG_FSL_QBMAN_DEBUG
-/**
- * dpaa_io_query_fq_count() - Get the frame and byte count for a given fq.
- * @d: the given DPIO object.
- * @fqid: the id of frame queue to be queried.
- * @fcnt: the queried frame count.
- * @bcnt: the queried byte count.
- *
- * Knowing the FQ count at run-time can be useful in debugging situations.
- * The instantaneous frame- and byte-count are hereby returned.
- *
- * Return 0 for a successful query, and negative error code if query fails.
- */
-int dpaa_io_query_fq_count(struct dpaa_io *d, uint32_t fqid,
-			   uint32_t *fcnt, uint32_t *bcnt);
-
-/**
- * dpaa_io_query_bp_count() - Query the number of buffers currenty in a
- * buffer pool.
- * @d: the given DPIO object.
- * @bpid: the index of buffer pool to be queried.
- * @num: the queried number of buffers in the buffer pool.
- *
- * Return 0 for a sucessful query, and negative error code if query fails.
- */
-int dpaa_io_query_bp_count(struct dpaa_io *d, uint32_t bpid,
-			   uint32_t *num);
-#endif
-#endif /* __FSL_DPAA_IO_H */
-- 
1.7.5.4

