From 7c6d68d0dd52b354557c65138e38915ee66b69ed Mon Sep 17 00:00:00 2001
From: Bogdan Hamciuc <bogdan.hamciuc@freescale.com>
Date: Fri, 23 Oct 2015 16:23:09 +0300
Subject: [PATCH 0755/1429] dpaa2-eth: Force atomic context for lazy bpool
 seeding

We use the same ldpaa_bp_add_7() function for initial buffer pool
seeding (from .ndo_open) and for hotpath pool replenishing. The function
is using napi_alloc_frag() as an optimization for the Rx datapath, but
that turns out to require atomic execution because of a this_cpu_ptr()
call down its stack.
This patch temporarily disables preemption around the initial seeding of
the Rx buffer pool.

Signed-off-by: Bogdan Hamciuc <bogdan.hamciuc@freescale.com>
[Original patch taken from QorIQ-SDK-V2.0-20160527-yocto]
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c |   12 +++++++++++-
 1 files changed, 11 insertions(+), 1 deletions(-)

diff --git a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c
index 23e2f9a..a963ea4 100644
--- a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c
+++ b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c
@@ -1620,16 +1620,26 @@ static int ldpaa_dpbp_seed(struct ldpaa_eth_priv *priv, uint16_t bpid)
 	int new_count;
 	int *count;
 
+	/* This is the lazy seeding of Rx buffer pools.
+	 * ldpaa_bp_add_7() is also used on the Rx hotpath and calls
+	 * napi_alloc_frag(). The trouble with that is that it in turn ends up
+	 * calling this_cpu_ptr(), which mandates execution in atomic context.
+	 * Rather than splitting up the code, do a one-off preempt disable.
+	 */
+	preempt_disable();
 	for_each_possible_cpu(j) {
 		for (i = 0; i < LDPAA_ETH_NUM_BUFS; i += 7) {
 			new_count = ldpaa_bp_add_7(priv, bpid);
 			count = per_cpu_ptr(priv->buf_count, j);
 			*count += new_count;
 
-			if (unlikely(new_count < 7))
+			if (unlikely(new_count < 7)) {
+				preempt_enable();
 				goto out_of_memory;
+			}
 		}
 	}
+	preempt_enable();
 
 	return 0;
 
-- 
1.7.5.4

