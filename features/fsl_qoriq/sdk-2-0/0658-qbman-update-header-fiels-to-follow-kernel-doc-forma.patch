From 2ce023fba8b24489abfec7b337db0f34f94e1882 Mon Sep 17 00:00:00 2001
From: Haiying Wang <Haiying.wang@freescale.com>
Date: Wed, 4 Nov 2015 15:40:44 -0500
Subject: [PATCH 0658/1383] qbman: update header fiels to follow kernel-doc
 format

Plus rename orp_id as opr_id based on the BG.

Signed-off-by: Haiying Wang <Haiying.wang@freescale.com>
[Original patch taken from QorIQ-SDK-V2.0-20160527-yocto]
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 drivers/staging/fsl-mc/bus/dpio/fsl_qbman_base.h   |  21 +-
 drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h | 563 +++++++++++++++++----
 drivers/staging/fsl-mc/bus/dpio/qbman_portal.c     |  14 +-
 3 files changed, 484 insertions(+), 114 deletions(-)

diff --git a/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_base.h b/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_base.h
index 14421c3..a1622f7 100644
--- a/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_base.h
+++ b/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_base.h
@@ -31,22 +31,30 @@
 #ifndef _FSL_QBMAN_BASE_H
 #define _FSL_QBMAN_BASE_H
 
-/* Descriptor for a QBMan instance on the SoC. On partitions/targets that do not
+/**
+ * struct qbman_block_desc - qbman block descriptor structure
+ *
+ * Descriptor for a QBMan instance on the SoC. On partitions/targets that do not
  * control this QBMan instance, these values may simply be place-holders. The
  * idea is simply that we be able to distinguish between them, eg. so that SWP
- * descriptors can identify which QBMan instance they belong to. */
+ * descriptors can identify which QBMan instance they belong to.
+ */
 struct qbman_block_desc {
 	void *ccsr_reg_bar; /* CCSR register map */
 	int irq_rerr;  /* Recoverable error interrupt line */
 	int irq_nrerr; /* Non-recoverable error interrupt line */
 };
 
-/* Descriptor for a QBMan software portal, expressed in terms that make sense to
+/**
+ * struct qbman_swp_desc - qbman software portal descriptor structure
+ *
+ * Descriptor for a QBMan software portal, expressed in terms that make sense to
  * the user context. Ie. on MC, this information is likely to be true-physical,
  * and instantiated statically at compile-time. On GPP, this information is
  * likely to be obtained via "discovery" over a partition's "layerscape bus"
  * (ie. in response to a MC portal command), and would take into account any
- * virtualisation of the GPP user's address space and/or interrupt numbering. */
+ * virtualisation of the GPP user's address space and/or interrupt numbering.
+ */
 struct qbman_swp_desc {
 	const struct qbman_block_desc *block; /* The QBMan instance */
 	void *cena_bar; /* Cache-enabled portal register map */
@@ -56,7 +64,10 @@ struct qbman_swp_desc {
 /* Driver object for managing a QBMan portal */
 struct qbman_swp;
 
-/* Place-holder for FDs, we represent it via the simplest form that we need for
+/**
+ * struct qbman_fd - basci structure for qbman frame descriptor
+ *
+ * Place-holder for FDs, we represent it via the simplest form that we need for
  * now. Different overlays may be needed to support different options, etc. (It
  * is impractical to define One True Struct, because the resulting encoding
  * routines (lots of read-modify-writes) would be worst-case performance whether
diff --git a/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h b/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h
index 69fd8c4..3ec2c8c 100644
--- a/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h
+++ b/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h
@@ -33,13 +33,30 @@
 
 #include "fsl_qbman_base.h"
 
-/* Create and destroy a functional object representing the given QBMan portal
- * descriptor. */
-struct qbman_swp *qbman_swp_init(const struct qbman_swp_desc *);
-void qbman_swp_finish(struct qbman_swp *);
+/**
+ * qbman_swp_init() - Create a functional object representing the given
+ * QBMan portal descriptor.
+ * @d: the given qbman swp descriptor
+ *
+ * Return qbman_swp portal object for success, NULL if the object cannot
+ * be created.
+ */
+struct qbman_swp *qbman_swp_init(const struct qbman_swp_desc *d);
+/**
+ * qbman_swp_finish() - Create and destroy a functional object representing
+ * the given QBMan portal descriptor.
+ * @p: the qbman_swp object to be destroyed.
+ *
+ */
+void qbman_swp_finish(struct qbman_swp *p);
 
-/* Returns the descriptor for this portal. */
-const struct qbman_swp_desc *qbman_swp_get_desc(struct qbman_swp *);
+/**
+ * qbman_swp_get_desc() - Get the descriptor of the given portal object.
+ * @p: the given portal object.
+ *
+ * Return the descriptor for this portal.
+ */
+const struct qbman_swp_desc *qbman_swp_get_desc(struct qbman_swp *p);
 
 	/**************/
 	/* Interrupts */
@@ -53,14 +70,55 @@ const struct qbman_swp_desc *qbman_swp_get_desc(struct qbman_swp *);
 #define QBMAN_SWP_INTERRUPT_RCRI ((uint32_t)0x00000008)
 #define QBMAN_SWP_INTERRUPT_RCDI ((uint32_t)0x00000010)
 #define QBMAN_SWP_INTERRUPT_VDCI ((uint32_t)0x00000020)
-uint32_t qbman_swp_interrupt_get_vanish(struct qbman_swp *);
-void qbman_swp_interrupt_set_vanish(struct qbman_swp *, uint32_t mask);
-uint32_t qbman_swp_interrupt_read_status(struct qbman_swp *);
-void qbman_swp_interrupt_clear_status(struct qbman_swp *, uint32_t mask);
-uint32_t qbman_swp_interrupt_get_trigger(struct qbman_swp *);
-void qbman_swp_interrupt_set_trigger(struct qbman_swp *, uint32_t mask);
-int qbman_swp_interrupt_get_inhibit(struct qbman_swp *);
-void qbman_swp_interrupt_set_inhibit(struct qbman_swp *, int inhibit);
+
+/**
+ * qbman_swp_interrupt_get_vanish()
+ * qbman_swp_interrupt_set_vanish() - Get/Set the data in software portal
+ * interrupt status disable register.
+ * @p: the given software portal object.
+ * @mask: The mask to set in SWP_IDSR register.
+ *
+ * Return the settings in SWP_ISDR register for Get function.
+ */
+uint32_t qbman_swp_interrupt_get_vanish(struct qbman_swp *p);
+void qbman_swp_interrupt_set_vanish(struct qbman_swp *p, uint32_t mask);
+
+/**
+ * qbman_swp_interrupt_read_status()
+ * qbman_swp_interrupt_clear_status() - Get/Set the data in software portal
+ * interrupt status register.
+ * @p: the given software portal object.
+ * @mask: The mask to set in SWP_ISR register.
+ *
+ * Return the settings in SWP_ISR register for Get function.
+ *
+ */
+uint32_t qbman_swp_interrupt_read_status(struct qbman_swp *p);
+void qbman_swp_interrupt_clear_status(struct qbman_swp *p, uint32_t mask);
+
+/**
+ * qbman_swp_interrupt_get_trigger()
+ * qbman_swp_interrupt_set_trigger() - Get/Set the data in software portal
+ * interrupt enable register.
+ * @p: the given software portal object.
+ * @mask: The mask to set in SWP_IER register.
+ *
+ * Return the settings in SWP_IER register for Get function.
+ */
+uint32_t qbman_swp_interrupt_get_trigger(struct qbman_swp *p);
+void qbman_swp_interrupt_set_trigger(struct qbman_swp *p, uint32_t mask);
+
+/**
+ * qbman_swp_interrupt_get_inhibit()
+ * qbman_swp_interrupt_set_inhibit() - Set/Set the data in software portal
+ * interrupt inhibit register.
+ * @p: the given software portal object.
+ * @mask: The mask to set in SWP_IIR register.
+ *
+ * Return the settings in SWP_IIR register for Get function.
+ */
+int qbman_swp_interrupt_get_inhibit(struct qbman_swp *p);
+void qbman_swp_interrupt_set_inhibit(struct qbman_swp *p, int inhibit);
 
 	/************/
 	/* Dequeues */
@@ -73,34 +131,38 @@ void qbman_swp_interrupt_set_inhibit(struct qbman_swp *, int inhibit);
  * dependencies we just pre/re-declare it here opaquely. */
 struct ldpaa_dq;
 
-/* A DQRI interrupt can be generated when there are dequeue results on the
- * portal's DQRR (this mechanism does not deal with "pull" dequeues to
- * user-supplied 'storage' addresses). There are two parameters to this
- * interrupt source, one is a threshold and the other is a timeout. The
- * interrupt will fire if either the fill-level of the ring exceeds 'thresh', or
- * if the ring has been non-empty for been longer than 'timeout' nanoseconds.
- * For timeout, an approximation to the desired nanosecond-granularity value is
- * made, so there are get and set APIs to allow the user to see what actual
- * timeout is set (compared to the timeout that was requested). */
-int qbman_swp_dequeue_thresh(struct qbman_swp *, unsigned int thresh);
-int qbman_swp_dequeue_set_timeout(struct qbman_swp *, unsigned int timeout);
-int qbman_swp_dequeue_get_timeout(struct qbman_swp *, unsigned int *timeout);
-
 /* ------------------- */
 /* Push-mode dequeuing */
 /* ------------------- */
 
-/* The user of a portal can enable and disable push-mode dequeuing of up to 16
+/**
+ * qbman_swp_push_get() - Get the push dequeue setup.
+ * @p: the software portal object.
+ * @channel_idx: the channel index to query.
+ * @enabled: returned boolean to show whether the push dequeue is enabled for
+ * the given channel.
+ */
+void qbman_swp_push_get(struct qbman_swp *, uint8_t channel_idx, int *enabled);
+/**
+ * qbman_swp_push_set() - Enable or disable push dequeue.
+ * @p: the software portal object.
+ * @channel_idx: the channel index..
+ * @enable: enable or disable push dequeue.
+ *
+ * The user of a portal can enable and disable push-mode dequeuing of up to 16
  * channels independently. It does not specify this toggling by channel IDs, but
  * rather by specifying the index (from 0 to 15) that has been mapped to the
- * desired channel. */
-void qbman_swp_push_get(struct qbman_swp *, uint8_t channel_idx, int *enabled);
+ * desired channel.
+ */
 void qbman_swp_push_set(struct qbman_swp *, uint8_t channel_idx, int enable);
 
 /* ------------------- */
 /* Pull-mode dequeuing */
 /* ------------------- */
 
+/**
+ * struct qbman_pull_desc - the structure for pull dequeue descriptor
+ */
 struct qbman_pull_desc {
 	uint32_t dont_manipulate_directly[6];
 };
@@ -114,20 +176,51 @@ enum qbman_pull_type_e {
 	qbman_pull_type_active_noics
 };
 
-/* Clear the contents of a descriptor to default/starting state. */
-void qbman_pull_desc_clear(struct qbman_pull_desc *);
-/* If not called, or if called with 'storage' as NULL, the result pull dequeues
+/**
+ * qbman_pull_desc_clear() - Clear the contents of a descriptor to
+ * default/starting state.
+ * @d: the pull dequeue descriptor to be cleared.
+ */
+void qbman_pull_desc_clear(struct qbman_pull_desc *d);
+
+/**
+ * qbman_pull_desc_set_storage()- Set the pull dequeue storage
+ * @d: the pull dequeue descriptor to be set.
+ * @storage: the pointer of the memory to store the dequeue result.
+ * @storage_phys: the physical address of the storage memory.
+ * @stash: to indicate whether write allocate is enabled.
+ *
+ * If not called, or if called with 'storage' as NULL, the result pull dequeues
  * will produce results to DQRR. If 'storage' is non-NULL, then results are
  * produced to the given memory location (using the physical/DMA address which
  * the caller provides in 'storage_phys'), and 'stash' controls whether or not
- * those writes to main-memory express a cache-warming attribute. */
-void qbman_pull_desc_set_storage(struct qbman_pull_desc *,
+ * those writes to main-memory express a cache-warming attribute.
+ */
+void qbman_pull_desc_set_storage(struct qbman_pull_desc *d,
 				 struct ldpaa_dq *storage,
 				 dma_addr_t storage_phys,
 				 int stash);
-/* numframes must be between 1 and 16, inclusive */
+/**
+ * qbman_pull_desc_set_numframes() - Set the number of frames to be dequeued.
+ * @d: the pull dequeue descriptor to be set.
+ * @numframes: number of frames to be set, must be between 1 and 16, inclusive.
+ */
 void qbman_pull_desc_set_numframes(struct qbman_pull_desc *, uint8_t numframes);
-/* Exactly one of the following descriptor "actions" should be set. (Calling any
+
+/**
+ * qbman_pull_desc_set_fq() - Set fqid from which the dequeue command dequeues.
+ * @fqid: the frame queue index of the given FQ.
+ *
+ * qbman_pull_desc_set_wq() - Set wqid from which the dequeue command dequeues.
+ * @wqid: composed of channel id and wqid within the channel.
+ * @dct: the dequeue command type.
+ *
+ * qbman_pull_desc_set_channel() - Set channelid from which the dequeue command
+ * dequeues.
+ * @chid: the channel id to be dequeued.
+ * @dct: the dequeue command type.
+ *
+ * Exactly one of the following descriptor "actions" should be set. (Calling any
  * one of these will replace the effect of any prior call to one of these.)
  * - pull dequeue from the given frame queue (FQ)
  * - pull dequeue from any FQ in the given work queue (WQ)
@@ -139,24 +232,49 @@ void qbman_pull_desc_set_wq(struct qbman_pull_desc *, uint32_t wqid,
 void qbman_pull_desc_set_channel(struct qbman_pull_desc *, uint32_t chid,
 				 enum qbman_pull_type_e dct);
 
-/* Issue the pull dequeue command */
-int qbman_swp_pull(struct qbman_swp *, struct qbman_pull_desc *);
+/**
+ * qbman_swp_pull() - Issue the pull dequeue command
+ * @s: the software portal object.
+ * @d: the software portal descriptor which has been configured with
+ * the set of qbman_pull_desc_set_*() calls.
+ *
+ * Return 0 for success, and -EBUSY if the software portal is not ready
+ * to do pull dequeue.
+ */
+int qbman_swp_pull(struct qbman_swp *, struct qbman_pull_desc *d);
 
 /* -------------------------------- */
 /* Polling DQRR for dequeue results */
 /* -------------------------------- */
 
-/* NULL return if there are no unconsumed DQRR entries. Returns a DQRR entry
+/**
+ * qbman_swp_dqrr_next() - Get an valid DQRR entry.
+ * @s: the software portal object.
+ *
+ * Return NULL if there are no unconsumed DQRR entries. Return a DQRR entry
  * only once, so repeated calls can return a sequence of DQRR entries, without
- * requiring they be consumed immediately or in any particular order. */
-const struct ldpaa_dq *qbman_swp_dqrr_next(struct qbman_swp *);
-/* Consume DQRR entries previously returned from qbman_swp_dqrr_next(). */
-void qbman_swp_dqrr_consume(struct qbman_swp *, const struct ldpaa_dq *);
+ * requiring they be consumed immediately or in any particular order.
+ */
+const struct ldpaa_dq *qbman_swp_dqrr_next(struct qbman_swp *s);
+
+/**
+ * qbman_swp_dqrr_consume() -  Consume DQRR entries previously returned from
+ * qbman_swp_dqrr_next().
+ * @s: the software portal object.
+ * @dq: the DQRR entry to be consumed.
+ */
+void qbman_swp_dqrr_consume(struct qbman_swp *s, const struct ldpaa_dq *dq);
 
 /* ------------------------------------------------- */
 /* Polling user-provided storage for dequeue results */
 /* ------------------------------------------------- */
-/* Only used for user-provided storage of dequeue results, not DQRR. For
+/**
+ * qbman_result_has_new_result() - Check and get the dequeue response from the
+ * dq storage memory set in pull dequeue command
+ * @s: the software portal object.
+ * @dq: the dequeue result read from the memory.
+ *
+ * Only used for user-provided storage of dequeue results, not DQRR. For
  * efficiency purposes, the driver will perform any required endianness
  * conversion to ensure that the user's dequeue result storage is in host-endian
  * format (whether or not that is the same as the little-endian format that
@@ -165,6 +283,9 @@ void qbman_swp_dqrr_consume(struct qbman_swp *, const struct ldpaa_dq *);
  * they should not call it again on the same memory location (except of course
  * if another dequeue command has been executed to produce a new result to that
  * location).
+ *
+ * Return 1 for getting a valid dequeue result, or 0 for not getting a valid
+ * dequeue result.
  */
 int qbman_result_has_new_result(struct qbman_swp *,
 				  const struct ldpaa_dq *);
@@ -173,17 +294,31 @@ int qbman_result_has_new_result(struct qbman_swp *,
 /* Parsing dequeue entries (DQRR and user-provided storage) */
 /* -------------------------------------------------------- */
 
-/* DQRR entries may contain non-dequeue results, ie. notifications */
+/**
+ * qbman_result_is_DQ() - check the dequeue result is a dequeue response or not
+ * @dq: the dequeue result to be checked.
+ *
+ * DQRR entries may contain non-dequeue results, ie. notifications
+ */
 int qbman_result_is_DQ(const struct ldpaa_dq *);
-/* All the non-dequeue results (FQDAN/CDAN/CSCN/...) are "state change
+
+/**
+ * qbman_result_is_SCN() - Check the dequeue result is notification or not
+ * @dq: the dequeue result to be checked.
+ *
+ * All the non-dequeue results (FQDAN/CDAN/CSCN/...) are "state change
  * notifications" of one type or another. Some APIs apply to all of them, of the
- * form qbman_result_SCN_***(). */
+ * form qbman_result_SCN_***().
+ */
 static inline int qbman_result_is_SCN(const struct ldpaa_dq *dq)
 {
 	return !qbman_result_is_DQ(dq);
 }
-/* Recognise different notification types, only required if the user allows for
- * these to occur, and cares about them when they do. */
+
+/**
+ * Recognise different notification types, only required if the user allows for
+ * these to occur, and cares about them when they do.
+ */
 int qbman_result_is_FQDAN(const struct ldpaa_dq *);
 				/* FQ Data Availability */
 int qbman_result_is_CDAN(const struct ldpaa_dq *);
@@ -205,10 +340,27 @@ int qbman_result_is_FQPN(const struct ldpaa_dq *); /* Park */
  * ldpaa_dq_*() functions. */
 
 /* State-change notifications (FQDAN/CDAN/CSCN/...). */
+/**
+ * qbman_result_SCN_state() - Get the state field in State-change notification
+ */
 uint8_t qbman_result_SCN_state(const struct ldpaa_dq *);
+/**
+ * qbman_result_SCN_rid() - Get the resource id in State-change notification
+ */
 uint32_t qbman_result_SCN_rid(const struct ldpaa_dq *);
+/**
+ * qbman_result_SCN_ctx() - Get the context data in State-change notification
+ */
 uint64_t qbman_result_SCN_ctx(const struct ldpaa_dq *);
+/**
+ * qbman_result_SCN_state_in_mem() - Get the state field in State-change
+ * notification which is written to memory instead of DQRR.
+ */
 uint8_t qbman_result_SCN_state_in_mem(const struct ldpaa_dq *);
+/**
+ * qbman_result_SCN_rid_in_mem() - Get the resource id in State-change
+ * notification which is written to memory instead of DQRR.
+ */
 uint32_t qbman_result_SCN_rid_in_mem(const struct ldpaa_dq *);
 
 /* Type-specific "resource IDs". Mainly for illustration purposes, though it
@@ -220,40 +372,77 @@ uint32_t qbman_result_SCN_rid_in_mem(const struct ldpaa_dq *);
 #define qbman_result_CDAN_cid(dq) ((uint16_t)qbman_result_SCN_rid(dq))
 #define qbman_result_CSCN_cgid(dq) ((uint16_t)qbman_result_SCN_rid(dq))
 
-/* Parsing BPSCN */
+/**
+ * qbman_result_bpscn_bpid() - Get the bpid from BPSCN
+ *
+ * Return the buffer pool id.
+ */
 uint16_t qbman_result_bpscn_bpid(const struct ldpaa_dq *);
-/* Check BPSCN to see whether there are free buffers in the pool.
+/**
+ * qbman_result_bpscn_has_free_bufs() - Check whether there are free
+ * buffers in the pool from BPSCN.
+ *
+ * Return the number of free buffers.
  */
 int qbman_result_bpscn_has_free_bufs(const struct ldpaa_dq *);
-/* Check BPSCN to see whether the buffer pool is depleted.
+/**
+ * qbman_result_bpscn_is_depleted() - Check BPSCN to see whether the
+ * buffer pool is depleted.
+ *
+ * Return the status of buffer pool depletion.
  */
 int qbman_result_bpscn_is_depleted(const struct ldpaa_dq *);
-/* Check BPSCN to see whether the buffer pool is surplus or not.
+/**
+ * qbman_result_bpscn_is_surplus() - Check BPSCN to see whether the buffer
+ * pool is surplus or not.
+ *
+ * Return the status of buffer pool surplus.
  */
 int qbman_result_bpscn_is_surplus(const struct ldpaa_dq *);
-/* Get the BPSCN CTX from BPSCN message */
+/**
+ * qbman_result_bpscn_ctx() - Get the BPSCN CTX from BPSCN message
+ *
+ * Return the BPSCN context.
+ */
 uint64_t qbman_result_bpscn_ctx(const struct ldpaa_dq *);
 
 /* Parsing CGCU */
-/* Check CGCU resouce id, i.e. cgid */
+/**
+ * qbman_result_cgcu_cgid() - Check CGCU resouce id, i.e. cgid
+ *
+ * Return the CGCU resource id.
+ */
 uint16_t qbman_result_cgcu_cgid(const struct ldpaa_dq *);
-/* Get the I_CNT from CGCU */
+/**
+ * qbman_result_cgcu_icnt() - Get the I_CNT from CGCU
+ *
+ * Return instantaneous count in the CGCU notification.
+ */
 uint64_t qbman_result_cgcu_icnt(const struct ldpaa_dq *);
 
 	/************/
 	/* Enqueues */
 	/************/
-
+/**
+ * struct qbman_eq_desc - structure of enqueue descriptor
+ */
 struct qbman_eq_desc {
 	uint32_t dont_manipulate_directly[8];
 };
 
+/**
+ * struct qbman_eq_response - structure of enqueue response
+ */
 struct qbman_eq_response {
 	uint32_t dont_manipulate_directly[16];
 };
 
-/* Clear the contents of a descriptor to default/starting state. */
+/**
+ * qbman_eq_desc_clear() - Clear the contents of a descriptor to
+ * default/starting state.
+ */
 void qbman_eq_desc_clear(struct qbman_eq_desc *);
+
 /* Exactly one of the following descriptor "actions" should be set. (Calling
  * any one of these will replace the effect of any prior call to one of these.)
  * - enqueue without order-restoration
@@ -265,27 +454,85 @@ void qbman_eq_desc_clear(struct qbman_eq_desc *);
  * 'incomplete' indicates that other fragments of the same 'seqnum' are yet to
  * be enqueued.
  */
-void qbman_eq_desc_set_no_orp(struct qbman_eq_desc *, int respond_success);
-void qbman_eq_desc_set_orp(struct qbman_eq_desc *, int respond_success,
-			   uint32_t orp_id, uint32_t seqnum, int incomplete);
-void qbman_eq_desc_set_orp_hole(struct qbman_eq_desc *, uint32_t orp_id,
+/**
+ * qbman_eq_desc_set_no_orp() - Set enqueue descriptor without orp
+ * @d: the enqueue descriptor.
+ * @response_success: 1 = enqueue with response always; 0 = enqueue with
+ * rejections returned on a FQ.
+ */
+void qbman_eq_desc_set_no_orp(struct qbman_eq_desc *d, int respond_success);
+
+/**
+ * qbman_eq_desc_set_orp() - Set order-resotration in the enqueue descriptor
+ * @d: the enqueue descriptor.
+ * @response_success: 1 = enqueue with response always; 0 = enqueue with
+ * rejections returned on a FQ.
+ * @opr_id: the order point record id.
+ * @seqnum: the order restoration sequence number.
+ * @incomplete: indiates whether this is the last fragments using the same
+ * sequeue number.
+ */
+void qbman_eq_desc_set_orp(struct qbman_eq_desc *d, int respond_success,
+			   uint32_t opr_id, uint32_t seqnum, int incomplete);
+
+/**
+ * qbman_eq_desc_set_orp_hole() - fill a hole in the order-restoration sequence
+ * without any enqueue
+ * @d: the enqueue descriptor.
+ * @opr_id: the order point record id.
+ * @seqnum: the order restoration sequence number.
+ */
+void qbman_eq_desc_set_orp_hole(struct qbman_eq_desc *d, uint32_t opr_id,
 				uint32_t seqnum);
-void qbman_eq_desc_set_orp_nesn(struct qbman_eq_desc *, uint32_t orp_id,
+
+/**
+ * qbman_eq_desc_set_orp_nesn() -  advance NESN (Next Expected Sequence Number)
+ * without any enqueue
+ * @d: the enqueue descriptor.
+ * @opr_id: the order point record id.
+ * @seqnum: the order restoration sequence number.
+ */
+void qbman_eq_desc_set_orp_nesn(struct qbman_eq_desc *d, uint32_t opr_id,
 				uint32_t seqnum);
-/* In the case where an enqueue response is DMA'd, this determines where that
+
+/**
+ * qbman_eq_desc_set_response() - Set the enqueue response info.
+ * @d: the enqueue descriptor
+ * @storage_phys: the physical address of the enqueue response in memory.
+ * @stash: indicate that the write allocation enabled or not.
+ *
+ * In the case where an enqueue response is DMA'd, this determines where that
  * response should go. (The physical/DMA address is given for hardware's
  * benefit, but software should interpret it as a "struct qbman_eq_response"
  * data structure.) 'stash' controls whether or not the write to main-memory
- * expresses a cache-warming attribute. */
-void qbman_eq_desc_set_response(struct qbman_eq_desc *,
+ * expresses a cache-warming attribute.
+ */
+void qbman_eq_desc_set_response(struct qbman_eq_desc *d,
 				dma_addr_t storage_phys,
 				int stash);
-/* token is the value that shows up in an enqueue response that can be used to
+/**
+ * qbman_eq_desc_set_token() - Set token for the enqueue command
+ * @d: the enqueue descriptor
+ * @token: the token to be set.
+ *
+ * token is the value that shows up in an enqueue response that can be used to
  * detect when the results have been published. The easiest technique is to zero
  * result "storage" before issuing an enqueue, and use any non-zero 'token'
- * value. */
-void qbman_eq_desc_set_token(struct qbman_eq_desc *, uint8_t token);
-/* Exactly one of the following descriptor "targets" should be set. (Calling any
+ * value.
+ */
+void qbman_eq_desc_set_token(struct qbman_eq_desc *d, uint8_t token);
+
+/**
+ * qbman_eq_desc_set_fq()
+ * qbman_eq_desc_set_qd() - Set eithe FQ or Queuing Destination for the enqueue
+ * command.
+ * @d: the enqueue descriptor
+ * @fqid: the id of the frame queue to be enqueued.
+ * @qdid: the id of the queuing destination to be enqueued.
+ * @qd_bin: the queuing destination bin
+ * @qd_prio: the queuing destination priority.
+ *
+ * Exactly one of the following descriptor "targets" should be set. (Calling any
  * one of these will replace the effect of any prior call to one of these.)
  * - enqueue to a frame queue
  * - enqueue to a queuing destination
@@ -295,53 +542,107 @@ void qbman_eq_desc_set_token(struct qbman_eq_desc *, uint8_t token);
 void qbman_eq_desc_set_fq(struct qbman_eq_desc *, uint32_t fqid);
 void qbman_eq_desc_set_qd(struct qbman_eq_desc *, uint32_t qdid,
 			  uint32_t qd_bin, uint32_t qd_prio);
-/* Determines whether or not the portal's EQDI interrupt source should be
- * asserted after the enqueue command is completed. */
+
+/**
+ * qbman_eq_desc_set_eqdi() - enable/disable EQDI interrupt
+ * @d: the enqueue descriptor
+ * @enable: boolean to enable/disable EQDI
+ *
+ * Determines whether or not the portal's EQDI interrupt source should be
+ * asserted after the enqueue command is completed.
+ */
 void qbman_eq_desc_set_eqdi(struct qbman_eq_desc *, int enable);
-/* Determines whether or not a portal DQRR entry should be consumed once the
- * enqueue command is completed. (And if so, and the DQRR entry corresponds to a
- * held-active (order-preserving) FQ, whether the FQ should be parked instead of
- * being rescheduled.) */
+
+/**
+ * qbman_eq_desc_set_dca() - Set DCA mode in the enqueue command.
+ * @d: the enqueue descriptor.
+ * @enable: enabled/disable DCA mode.
+ * @dqrr_idx: DCAP_CI, the DCAP consumer index.
+ * @park: determine the whether park the FQ or not
+ *
+ * Determines whether or not a portal DQRR entry should be consumed once the
+ * enqueue command is completed.  (And if so, and the DQRR entry corresponds
+ * to a held-active (order-preserving) FQ, whether the FQ should be parked
+ * instead of being rescheduled.)
+ */
 void qbman_eq_desc_set_dca(struct qbman_eq_desc *, int enable,
 				uint32_t dqrr_idx, int park);
 
-/* Issue an enqueue command. ('fd' should only be NULL if the "action" of the
- * descriptor is "orp_hole" or "orp_nesn".) */
+/**
+ * qbman_swp_enqueue() - Issue an enqueue command.
+ * @s: the software portal used for enqueue.
+ * @d: the enqueue descriptor.
+ * @fd: the frame descriptor to be enqueued.
+ *
+ * Please note that 'fd' should only be NULL if the "action" of the
+ * descriptor is "orp_hole" or "orp_nesn".
+ *
+ * Return 0 for successful enqueue, -EBUSY if the EQCR is not ready.
+ */
 int qbman_swp_enqueue(struct qbman_swp *, const struct qbman_eq_desc *,
 		      const struct qbman_fd *fd);
 
-/* An EQRI interrupt can be generated when the fill-level of EQCR falls below
- * the 'thresh' value set here. Setting thresh==0 (the default) disables. */
+/**
+ * qbman_swp_enqueue_thresh() - Set the threshold for EQRI interrupt.
+ *
+ * An EQRI interrupt can be generated when the fill-level of EQCR falls below
+ * the 'thresh' value set here. Setting thresh==0 (the default) disables.
+ */
 int qbman_swp_enqueue_thresh(struct qbman_swp *, unsigned int thresh);
 
 	/*******************/
 	/* Buffer releases */
 	/*******************/
-
+/**
+ * struct qbman_release_desc - The structure for buffer release descriptor
+ */
 struct qbman_release_desc {
 	uint32_t dont_manipulate_directly[1];
 };
 
-/* Clear the contents of a descriptor to default/starting state. */
+/**
+ * qbman_release_desc_clear() - Clear the contents of a descriptor to
+ * default/starting state.
+ */
 void qbman_release_desc_clear(struct qbman_release_desc *);
-/* Set the ID of the buffer pool to release to */
+
+/**
+ * qbman_release_desc_set_bpid() - Set the ID of the buffer pool to release to
+ */
 void qbman_release_desc_set_bpid(struct qbman_release_desc *, uint32_t bpid);
-/* Determines whether or not the portal's RCDI interrupt source should be
- * asserted after the release command is completed. */
+
+/**
+ * qbman_release_desc_set_rcdi() - Determines whether or not the portal's RCDI
+ * interrupt source should be asserted after the release command is completed.
+ */
 void qbman_release_desc_set_rcdi(struct qbman_release_desc *, int enable);
 
-/* Issue a release command. 'num_buffers' must be less than 8. */
-int qbman_swp_release(struct qbman_swp *, const struct qbman_release_desc *,
+/**
+ * qbman_swp_release() - Issue a buffer release command.
+ * @s: the software portal object.
+ * @d: the release descriptor.
+ * @buffers: a pointer pointing to the buffer address to be released.
+ * @num_buffers: number of buffers to be released,  must be less than 8.
+ *
+ * Return 0 for success, -EBUSY if the release command ring is not ready.
+ */
+int qbman_swp_release(struct qbman_swp *s, const struct qbman_release_desc *d,
 		      const uint64_t *buffers, unsigned int num_buffers);
 
-/* An RCRI interrupt can be generated when the fill-level of RCR falls below
- * the 'thresh' value set here. Setting thresh==0 (the default) disables. */
-int qbman_swp_release_thresh(struct qbman_swp *, unsigned int thresh);
-
 	/*******************/
 	/* Buffer acquires */
 	/*******************/
 
+/**
+ * qbman_swp_acquire() - Issue a buffer acquire command.
+ * @s: the software portal object.
+ * @bpid: the buffer pool index.
+ * @buffers: a pointer pointing to the acquired buffer address|es.
+ * @num_buffers: number of buffers to be acquired, must be less than 8.
+ *
+ * Return 0 for success, or negative error code if the acquire command
+ * fails.
+ */
 int qbman_swp_acquire(struct qbman_swp *, uint32_t bpid, uint64_t *buffers,
 		      unsigned int num_buffers);
 
@@ -349,27 +650,52 @@ int qbman_swp_acquire(struct qbman_swp *, uint32_t bpid, uint64_t *buffers,
 	/* FQ management */
 	/*****************/
 
-/* There are a couple of different ways that a FQ can end up parked state,
- * This schedules it. */
-int qbman_swp_fq_schedule(struct qbman_swp *, uint32_t fqid);
+/**
+ * qbman_swp_fq_schedule() - Move the fq to the scheduled state.
+ * @s: the software portal object.
+ * @fqid: the index of frame queue to be scheduled.
+ *
+ * There are a couple of different ways that a FQ can end up parked state,
+ * This schedules it.
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
+int qbman_swp_fq_schedule(struct qbman_swp *s, uint32_t fqid);
 
-/* Force eligible will force a tentatively-scheduled FQ to be fully-scheduled
+/**
+ * qbman_swp_fq_force() - Force the FQ to fully scheduled state.
+ * @s: the software portal object.
+ * @fqid: the index of frame queue to be forced.
+ *
+ * Force eligible will force a tentatively-scheduled FQ to be fully-scheduled
  * and thus be available for selection by any channel-dequeuing behaviour (push
  * or pull). If the FQ is subsequently "dequeued" from the channel and is still
  * empty at the time this happens, the resulting dq_entry will have no FD.
- * (qbman_result_DQ_fd() will return NULL.) */
-int qbman_swp_fq_force(struct qbman_swp *, uint32_t fqid);
+ * (qbman_result_DQ_fd() will return NULL.)
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
+int qbman_swp_fq_force(struct qbman_swp *s, uint32_t fqid);
 
-/* These functions change the FQ flow-control stuff between XON/XOFF. (The
+/**
+ * qbman_swp_fq_xon()
+ * qbman_swp_fq_xoff() - XON/XOFF the frame queue.
+ * @s: the software portal object.
+ * @fqid: the index of frame queue.
+ *
+ * These functions change the FQ flow-control stuff between XON/XOFF. (The
  * default is XON.) This setting doesn't affect enqueues to the FQ, just
  * dequeues. XOFF FQs will remain in the tenatively-scheduled state, even when
  * non-empty, meaning they won't be selected for scheduled dequeuing. If a FQ is
  * changed to XOFF after it had already become truly-scheduled to a channel, and
  * a pull dequeue of that channel occurs that selects that FQ for dequeuing,
  * then the resulting dq_entry will have no FD. (qbman_result_DQ_fd() will
- * return NULL.) */
-int qbman_swp_fq_xon(struct qbman_swp *, uint32_t fqid);
-int qbman_swp_fq_xoff(struct qbman_swp *, uint32_t fqid);
+ * return NULL.)
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
+int qbman_swp_fq_xon(struct qbman_swp *s, uint32_t fqid);
+int qbman_swp_fq_xoff(struct qbman_swp *s, uint32_t fqid);
 
 	/**********************/
 	/* Channel management */
@@ -384,10 +710,43 @@ int qbman_swp_fq_xoff(struct qbman_swp *, uint32_t fqid);
  * combination function is provided if the user wishes to modify the "context"
  * (which shows up in each CDAN message) each time they reenable, as a single
  * command to hardware. */
+/**
+ * qbman_swp_CDAN_set_context() - Set CDAN context
+ * @s: the software portal object.
+ * @channelid: the channel index.
+ * @ctx: the context to be set in CDAN.
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
 int qbman_swp_CDAN_set_context(struct qbman_swp *, uint16_t channelid,
 				uint64_t ctx);
+
+/**
+ * qbman_swp_CDAN_enable() - Enable CDAN for the channel.
+ * @s: the software portal object.
+ * @channelid: the index of the channel to generate CDAN.
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
 int qbman_swp_CDAN_enable(struct qbman_swp *, uint16_t channelid);
+
+/**
+ * qbman_swp_CDAN_disable() - disable CDAN for the channel.
+ * @s: the software portal object.
+ * @channelid: the index of the channel to generate CDAN.
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
 int qbman_swp_CDAN_disable(struct qbman_swp *, uint16_t channelid);
+
+/**
+ * qbman_swp_CDAN_set_context_enable() - Set CDAN contest and enable CDAN
+ * @s: the software portal object.
+ * @channelid: the index of the channel to generate CDAN.
+ * @ctx: the context set in CDAN.
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
 int qbman_swp_CDAN_set_context_enable(struct qbman_swp *, uint16_t channelid,
 				      uint64_t ctx);
 
diff --git a/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c b/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c
index ce30b26..ea071d1 100644
--- a/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c
+++ b/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c
@@ -283,7 +283,7 @@ static struct qb_attr_code code_eq_orp_en = QB_CODE(0, 2, 1);
 static struct qb_attr_code code_eq_orp_is_nesn = QB_CODE(0, 31, 1);
 static struct qb_attr_code code_eq_orp_nlis = QB_CODE(0, 30, 1);
 static struct qb_attr_code code_eq_orp_seqnum = QB_CODE(0, 16, 14);
-static struct qb_attr_code code_eq_orp_id = QB_CODE(1, 0, 16);
+static struct qb_attr_code code_eq_opr_id = QB_CODE(1, 0, 16);
 static struct qb_attr_code code_eq_tgt_id = QB_CODE(2, 0, 24);
 /* static struct qb_attr_code code_eq_tag = QB_CODE(3, 0, 32); */
 static struct qb_attr_code code_eq_qd_en = QB_CODE(0, 4, 1);
@@ -318,7 +318,7 @@ void qbman_eq_desc_set_no_orp(struct qbman_eq_desc *d, int respond_success)
 }
 
 void qbman_eq_desc_set_orp(struct qbman_eq_desc *d, int respond_success,
-			   uint32_t orp_id, uint32_t seqnum, int incomplete)
+			   uint32_t opr_id, uint32_t seqnum, int incomplete)
 {
 	uint32_t *cl = qb_cl(d);
 
@@ -326,32 +326,32 @@ void qbman_eq_desc_set_orp(struct qbman_eq_desc *d, int respond_success,
 	qb_attr_code_encode(&code_eq_cmd, cl,
 			    respond_success ? qbman_eq_cmd_respond :
 					      qbman_eq_cmd_respond_reject);
-	qb_attr_code_encode(&code_eq_orp_id, cl, orp_id);
+	qb_attr_code_encode(&code_eq_opr_id, cl, opr_id);
 	qb_attr_code_encode(&code_eq_orp_seqnum, cl, seqnum);
 	qb_attr_code_encode(&code_eq_orp_nlis, cl, !!incomplete);
 }
 
-void qbman_eq_desc_set_orp_hole(struct qbman_eq_desc *d, uint32_t orp_id,
+void qbman_eq_desc_set_orp_hole(struct qbman_eq_desc *d, uint32_t opr_id,
 				uint32_t seqnum)
 {
 	uint32_t *cl = qb_cl(d);
 
 	qb_attr_code_encode(&code_eq_orp_en, cl, 1);
 	qb_attr_code_encode(&code_eq_cmd, cl, qbman_eq_cmd_empty);
-	qb_attr_code_encode(&code_eq_orp_id, cl, orp_id);
+	qb_attr_code_encode(&code_eq_opr_id, cl, opr_id);
 	qb_attr_code_encode(&code_eq_orp_seqnum, cl, seqnum);
 	qb_attr_code_encode(&code_eq_orp_nlis, cl, 0);
 	qb_attr_code_encode(&code_eq_orp_is_nesn, cl, 0);
 }
 
-void qbman_eq_desc_set_orp_nesn(struct qbman_eq_desc *d, uint32_t orp_id,
+void qbman_eq_desc_set_orp_nesn(struct qbman_eq_desc *d, uint32_t opr_id,
 				uint32_t seqnum)
 {
 	uint32_t *cl = qb_cl(d);
 
 	qb_attr_code_encode(&code_eq_orp_en, cl, 1);
 	qb_attr_code_encode(&code_eq_cmd, cl, qbman_eq_cmd_empty);
-	qb_attr_code_encode(&code_eq_orp_id, cl, orp_id);
+	qb_attr_code_encode(&code_eq_opr_id, cl, opr_id);
 	qb_attr_code_encode(&code_eq_orp_seqnum, cl, seqnum);
 	qb_attr_code_encode(&code_eq_orp_nlis, cl, 0);
 	qb_attr_code_encode(&code_eq_orp_is_nesn, cl, 1);
-- 
2.8.1

