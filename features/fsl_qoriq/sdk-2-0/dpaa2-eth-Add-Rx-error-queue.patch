From 1762bf1a599d881b89250a46c88765bd3f23759a Mon Sep 17 00:00:00 2001
From: Ioana Radulescu <ruxandra.radulescu@freescale.com>
Date: Fri, 15 May 2015 17:11:01 +0300
Subject: [PATCH 0691/1429] dpaa2-eth: Add Rx error queue

Add a Kconfigurable option that allows Rx error frames to be
enqueued on an error FQ. By default error frames are discarded,
but for debug purposes we may want to process them at driver
level.

Note: Checkpatch issues a false positive about complex macros that
should be parenthesized.

Signed-off-by: Ioana Radulescu <ruxandra.radulescu@freescale.com>
Reviewed-by: Bogdan Hamciuc <bogdan.hamciuc@freescale.com>
Change-Id: I7d19d00b5d5445514ebd112c886ce8ccdbb1f0da
Reviewed-on: http://git.am.freescale.net:8181/37672
Reviewed-by: Stuart Yoder <stuart.yoder@freescale.com>
Tested-by: Stuart Yoder <stuart.yoder@freescale.com>
[Original patch taken from QorIQ-SDK-V2.0-20160527-yocto]
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 drivers/staging/fsl-dpaa2/ethernet/Kconfig     |   10 ++
 drivers/staging/fsl-dpaa2/ethernet/ldpaa_eth.c |  141 +++++++++++++++++++-----
 drivers/staging/fsl-dpaa2/ethernet/ldpaa_eth.h |   12 +-
 3 files changed, 129 insertions(+), 34 deletions(-)

diff --git a/drivers/staging/fsl-dpaa2/ethernet/Kconfig b/drivers/staging/fsl-dpaa2/ethernet/Kconfig
index 7d767be..df8edd7 100644
--- a/drivers/staging/fsl-dpaa2/ethernet/Kconfig
+++ b/drivers/staging/fsl-dpaa2/ethernet/Kconfig
@@ -29,4 +29,14 @@ config FSL_DPAA2_ETH_LINK_POLL
 	---help---
 	  Poll for detecting link state changes instead of using
 	  interrupts.
+
+config FSL_DPAA2_ETH_USE_ERR_QUEUE
+	bool "Enable Rx error queue"
+	default n
+	---help---
+	  Allow Rx error frames to be enqueued on an error queue
+	  and processed by the driver (by default they are dropped
+	  in hardware).
+	  This may impact performance, recommended for debugging
+	  purposes only.
 endif
diff --git a/drivers/staging/fsl-dpaa2/ethernet/ldpaa_eth.c b/drivers/staging/fsl-dpaa2/ethernet/ldpaa_eth.c
index fe7ae5a..3718a77 100644
--- a/drivers/staging/fsl-dpaa2/ethernet/ldpaa_eth.c
+++ b/drivers/staging/fsl-dpaa2/ethernet/ldpaa_eth.c
@@ -243,32 +243,6 @@ static void ldpaa_eth_rx(struct ldpaa_eth_priv *priv,
 	percpu_stats = this_cpu_ptr(priv->percpu_stats);
 	percpu_extras = this_cpu_ptr(priv->percpu_extras);
 
-	if (fd->simple.frc & LDPAA_FD_FRC_FASV) {
-		/* Read the frame annotation status word and check for errors */
-		/* TODO ideally, we'd have a struct describing the HW FA */
-		fas = (struct ldpaa_fas *)
-				(vaddr + priv->buf_layout.private_data_size);
-		status = le32_to_cpu(fas->status);
-		if (status & LDPAA_ETH_RX_ERR_MASK) {
-			dev_err(dev, "Rx frame error(s): 0x%08x\n",
-				status & LDPAA_ETH_RX_ERR_MASK);
-			/* TODO when we grow up and get to run in Rx softirq,
-			* we won't need this. Besides, on RT we'd only need
-			* migrate_disable().
-			*/
-			percpu_stats->rx_errors++;
-			ldpaa_eth_free_rx_fd(priv, fd);
-			return;
-		} else if (status & LDPAA_ETH_RX_UNSUPP_MASK) {
-			/* TODO safety net; to be removed as we support more and
-			* more of these, e.g. rx multicast
-			*/
-			netdev_info(priv->net_dev,
-				    "Unsupported feature in bitmask: 0x%08x\n",
-				    status & LDPAA_ETH_RX_UNSUPP_MASK);
-		}
-	}
-
 	if (fd_format == dpaa_fd_single) {
 		skb = ldpaa_eth_build_linear_skb(priv, fd, vaddr);
 	} else if (fd_format == dpaa_fd_sg) {
@@ -292,8 +266,12 @@ static void ldpaa_eth_rx(struct ldpaa_eth_priv *priv,
 	skb->protocol = eth_type_trans(skb, priv->net_dev);
 
 	/* Check if we need to validate the L4 csum */
-	if (fd->simple.frc & LDPAA_FD_FRC_FASV)
+	if (likely(fd->simple.frc & LDPAA_FD_FRC_FASV)) {
+		fas = (struct ldpaa_fas *)
+				(vaddr + priv->buf_layout.private_data_size);
+		status = le32_to_cpu(fas->status);
 		ldpaa_eth_rx_csum(priv, status, skb);
+	}
 
 	if (unlikely(netif_rx(skb) == NET_RX_DROP))
 		/* Nothing to do here, the stack updates the dropped counter */
@@ -308,6 +286,38 @@ err_build_skb:
 	percpu_stats->rx_dropped++;
 }
 
+#ifdef CONFIG_FSL_DPAA2_ETH_USE_ERR_QUEUE
+static void ldpaa_eth_rx_err(struct ldpaa_eth_priv *priv,
+			     const struct dpaa_fd *fd)
+{
+	struct device *dev = priv->net_dev->dev.parent;
+	dma_addr_t addr = ldpaa_fd_get_addr(fd);
+	void *vaddr;
+	struct rtnl_link_stats64 *percpu_stats;
+	struct ldpaa_fas *fas;
+	uint32_t status = 0;
+
+	dma_unmap_single(dev, addr, LDPAA_ETH_RX_BUFFER_SIZE, DMA_FROM_DEVICE);
+	vaddr = phys_to_virt(addr);
+
+	if (fd->simple.frc & LDPAA_FD_FRC_FASV) {
+		fas = (struct ldpaa_fas *)
+			(vaddr + priv->buf_layout.private_data_size);
+		status = le32_to_cpu(fas->status);
+
+		/* All frames received on this queue should have at least
+		 * one of the Rx error bits set */
+		WARN_ON_ONCE((status & LDPAA_ETH_RX_ERR_MASK) == 0);
+		netdev_dbg(priv->net_dev, "Rx frame error: 0x%08x\n",
+			   status & LDPAA_ETH_RX_ERR_MASK);
+	}
+	ldpaa_eth_free_rx_fd(priv, fd);
+
+	percpu_stats = this_cpu_ptr(priv->percpu_stats);
+	percpu_stats->rx_errors++;
+}
+#endif
+
 /* Consume all frames pull-dequeued into the store. This is the simplest way to
  * make sure we don't accidentally issue another volatile dequeue which would
  * overwrite (leak) frames already in the store.
@@ -1135,6 +1145,11 @@ static void ldpaa_eth_fqdan_cb(struct dpaa_io_notification_ctx *ctx)
 	case LDPAA_TX_CONF_FQ:
 		fq->stats.tx_conf_fqdan++;
 		break;
+#ifdef CONFIG_FSL_DPAA2_ETH_USE_ERR_QUEUE
+	case LDPAA_RX_ERR_FQ:
+		/* For now, we don't collect FQDAN stats on the error queue */
+		break;
+#endif
 	default:
 		WARN_ONCE(1, "Unknown FQ type: %d!", fq->type);
 	}
@@ -1179,6 +1194,13 @@ static void ldpaa_eth_setup_fqs(struct ldpaa_eth_priv *priv)
 		priv->fq[priv->num_fqs].consume = ldpaa_eth_rx;
 		priv->fq[priv->num_fqs++].flowid = i;
 	}
+
+#ifdef CONFIG_FSL_DPAA2_ETH_USE_ERR_QUEUE
+	/* We have exactly one Rx error queue per DPNI */
+	priv->fq[priv->num_fqs].netdev_priv = priv;
+	priv->fq[priv->num_fqs].type = LDPAA_RX_ERR_FQ;
+	priv->fq[priv->num_fqs++].consume = ldpaa_eth_rx_err;
+#endif
 }
 
 static int __cold ldpaa_dpio_setup(struct ldpaa_eth_priv *priv)
@@ -1595,12 +1617,46 @@ static int ldpaa_tx_flow_setup(struct ldpaa_eth_priv *priv,
 	return 0;
 }
 
+#ifdef CONFIG_FSL_DPAA2_ETH_USE_ERR_QUEUE
+static int ldpaa_rx_err_setup(struct ldpaa_eth_priv *priv,
+			      struct ldpaa_eth_fq *fq)
+{
+	struct dpni_queue_attr queue_attr;
+	struct dpni_queue_cfg queue_cfg;
+	int err;
+
+	/* Configure the Rx error queue to generate FQDANs,
+	 * just like the Rx queues */
+	queue_cfg.options = DPNI_QUEUE_OPT_USER_CTX | DPNI_QUEUE_OPT_DEST;
+	queue_cfg.dest_cfg.dest_type = DPNI_DEST_DPIO;
+	queue_cfg.dest_cfg.priority = 4;	/* FIXME */
+	queue_cfg.user_ctx = fq->nctx.qman64;
+	queue_cfg.dest_cfg.dest_id = fq->nctx.dpio_id;
+	err = dpni_set_rx_err_queue(priv->mc_io, priv->mc_token, &queue_cfg);
+	if (unlikely(err)) {
+		netdev_err(priv->net_dev, "dpni_set_rx_err_queue() failed\n");
+		return err;
+	}
+
+	/* Get the FQID */
+	err = dpni_get_rx_err_queue(priv->mc_io, priv->mc_token, &queue_attr);
+	if (unlikely(err)) {
+		netdev_err(priv->net_dev, "dpni_get_rx_err_queue() failed\n");
+		return err;
+	}
+	fq->fqid = queue_attr.fqid;
+	fq->nctx.id = fq->fqid;
+
+	return 0;
+}
+#endif
 
 static int ldpaa_dpni_bind(struct ldpaa_eth_priv *priv)
 {
 	struct net_device *net_dev = priv->net_dev;
 	struct device *dev = net_dev->dev.parent;
 	struct dpni_pools_cfg pools_params;
+	struct dpni_error_cfg err_cfg;
 	int err = 0;
 	int i;
 
@@ -1621,12 +1677,39 @@ static int ldpaa_dpni_bind(struct ldpaa_eth_priv *priv)
 		return err;
 	}
 
+	/* Configure handling of error frames */
+	err_cfg.errors = LDPAA_ETH_RX_ERR_MASK;
+	err_cfg.set_frame_annotation = 1;
+#ifdef CONFIG_FSL_DPAA2_ETH_USE_ERR_QUEUE
+	err_cfg.error_action = DPNI_ERROR_ACTION_SEND_TO_ERROR_QUEUE;
+#else
+	err_cfg.error_action = DPNI_ERROR_ACTION_DISCARD;
+#endif
+	err = dpni_set_errors_behavior(priv->mc_io, priv->mc_token, &err_cfg);
+	if (unlikely(err)) {
+		netdev_err(priv->net_dev, "dpni_set_errors_behavior failed\n");
+		return err;
+	}
+
 	/* Configure Rx and Tx conf queues to generate FQDANs */
 	for (i = 0; i < priv->num_fqs; i++) {
-		if (priv->fq[i].type == LDPAA_RX_FQ)
+		switch (priv->fq[i].type) {
+		case LDPAA_RX_FQ:
 			err = ldpaa_rx_flow_setup(priv, &priv->fq[i]);
-		else
+			break;
+		case LDPAA_TX_CONF_FQ:
 			err = ldpaa_tx_flow_setup(priv, &priv->fq[i]);
+			break;
+#ifdef CONFIG_FSL_DPAA2_ETH_USE_ERR_QUEUE
+		case LDPAA_RX_ERR_FQ:
+			err = ldpaa_rx_err_setup(priv, &priv->fq[i]);
+			break;
+#endif
+		default:
+			netdev_err(net_dev, "Invalid FQ type %d\n",
+				   priv->fq[i].type);
+			return -EINVAL;
+		}
 		if (unlikely(err))
 			return err;
 	}
diff --git a/drivers/staging/fsl-dpaa2/ethernet/ldpaa_eth.h b/drivers/staging/fsl-dpaa2/ethernet/ldpaa_eth.h
index 6bd0084..fbf4e4f 100644
--- a/drivers/staging/fsl-dpaa2/ethernet/ldpaa_eth.h
+++ b/drivers/staging/fsl-dpaa2/ethernet/ldpaa_eth.h
@@ -140,8 +140,7 @@ struct ldpaa_fas {
 /* L4 csum error */
 #define LDPAA_ETH_FAS_L4CE		0x00000001
 /* These bits always signal errors */
-#define LDPAA_ETH_RX_ERR_MASK		(LDPAA_ETH_FAS_DISC	| \
-					 LDPAA_ETH_FAS_KSE	| \
+#define LDPAA_ETH_RX_ERR_MASK		(LDPAA_ETH_FAS_KSE	| \
 					 LDPAA_ETH_FAS_EOFHE	| \
 					 LDPAA_ETH_FAS_MNLE	| \
 					 LDPAA_ETH_FAS_TIDE	| \
@@ -201,12 +200,15 @@ struct ldpaa_eth_ring {
 /* Maximum number of Rx queues associated with a DPNI */
 #define LDPAA_ETH_MAX_RX_QUEUES		NR_CPUS
 #define LDPAA_ETH_MAX_TX_QUEUES		NR_CPUS
-#define LDPAA_ETH_MAX_QUEUES	\
-	(LDPAA_ETH_MAX_RX_QUEUES + LDPAA_ETH_MAX_TX_QUEUES)
+#define LDPAA_ETH_MAX_RX_ERR_QUEUES	1
+#define LDPAA_ETH_MAX_QUEUES	(LDPAA_ETH_MAX_RX_QUEUES + \
+				LDPAA_ETH_MAX_TX_QUEUES + \
+				LDPAA_ETH_MAX_RX_ERR_QUEUES)
 
 enum ldpaa_eth_fq_type {
 	LDPAA_RX_FQ = 0,
-	LDPAA_TX_CONF_FQ
+	LDPAA_TX_CONF_FQ,
+	LDPAA_RX_ERR_FQ
 };
 
 struct ldpaa_eth_priv;
-- 
1.7.5.4

