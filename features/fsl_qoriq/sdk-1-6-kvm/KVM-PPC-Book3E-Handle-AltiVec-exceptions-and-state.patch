From 7fcacc2f3f292e95bc575efbb115d1076111e1a9 Mon Sep 17 00:00:00 2001
From: Mihai Caraman <mihai.caraman@freescale.com>
Date: Mon, 13 May 2013 16:21:22 +0300
Subject: [PATCH] KVM: PPC: Book3E: Handle AltiVec exceptions and state

commit 7fcacc2f3f292e95bc575efbb115d1076111e1a9 git://git.freescale.com/ppc/sdk/linux.git

KVM Book3E FPU support gracefully reuse host infrastructure so we do the
same for AltiVec.

One improvement that can be made once layzee integration settles is to move
kvmppc_load_guest_altivec() call from kvm_ppc_core_vcpu_put() to handle_exit()
just before returning to guest. This will save us some save/load operations
when other processes are competing on AltiVec resources (it applies for FPU
also).

Signed-off-by: Mihai Caraman <mihai.caraman@freescale.com>
Change-Id: I7d6f0aec71cedca83a4b079a736d72c4be336679
Reviewed-on: http://git.am.freescale.net:8181/2460
Reviewed-by: Yoder Stuart-B08248 <stuart.yoder@freescale.com>
Reviewed-by: Fleming Andrew-AFLEMING <AFLEMING@freescale.com>
Tested-by: Fleming Andrew-AFLEMING <AFLEMING@freescale.com>
Signed-off-by: Vu Tran <vu.tran@windriver.com>

diff --git a/arch/powerpc/include/asm/kvm_host.h b/arch/powerpc/include/asm/kvm_host.h
index c09adf8..eafa505 100644
--- a/arch/powerpc/include/asm/kvm_host.h
+++ b/arch/powerpc/include/asm/kvm_host.h
@@ -426,6 +426,7 @@ struct kvm_vcpu_arch {
 	u64 acc;
 #endif
 #ifdef CONFIG_ALTIVEC
+	int vec_active;
 	vector128 vr[32];
 	vector128 vscr;
 #endif
diff --git a/arch/powerpc/kvm/booke.c b/arch/powerpc/kvm/booke.c
index cf495a5..e1d56cb 100644
--- a/arch/powerpc/kvm/booke.c
+++ b/arch/powerpc/kvm/booke.c
@@ -390,6 +390,8 @@ static int kvmppc_booke_irqprio_deliver(struct kvm_vcpu *vcpu,
 	case BOOKE_IRQPRIO_SPE_FP_DATA:
 	case BOOKE_IRQPRIO_SPE_FP_ROUND:
 	case BOOKE_IRQPRIO_AP_UNAVAIL:
+	case BOOKE_IRQPRIO_ALTIVEC_UNAVAIL:
+	case BOOKE_IRQPRIO_ALTIVEC_ASSIST:
 		allowed = 1;
 		msr_mask = MSR_CE | MSR_ME | MSR_DE;
 		int_class = INT_CLASS_NONCRIT;
@@ -724,6 +726,12 @@ int kvmppc_vcpu_run(struct kvm_run *kvm_run, struct kvm_vcpu *vcpu)
 	int fpexc_mode;
 #endif
 
+#ifdef CONFIG_ALTIVEC
+	vector128 vr[32];
+	vector128 vscr;
+	int used_vr;
+#endif
+
 	if (!vcpu->arch.sane) {
 		kvm_run->exit_reason = KVM_EXIT_INTERNAL_ERROR;
 		return -EINVAL;
@@ -761,6 +769,24 @@ int kvmppc_vcpu_run(struct kvm_run *kvm_run, struct kvm_vcpu *vcpu)
 	kvmppc_load_guest_fp(vcpu);
 #endif
 
+#ifdef CONFIG_ALTIVEC
+	/* Save userspace VEC state in stack */
+	enable_kernel_altivec();
+	memcpy(vr, current->thread.vr_state.vr,
+	       sizeof(current->thread.vr_state.vr));
+	vscr = current->thread.vr_state.vscr;
+	used_vr = current->thread.used_vr;
+
+	/* Restore guest VEC state to thread */
+	memcpy(current->thread.vr_state.vr, vcpu->arch.vr,
+	       sizeof(vcpu->arch.vr));
+	current->thread.vr_state.vscr = vcpu->arch.vscr;
+
+	vcpu->arch.vec_active = 1;
+
+	kvmppc_load_guest_altivec(vcpu);
+#endif
+
 	/*
 	 * Clear current->thread.dbcr0 so that kernel does not
 	 * restore h/w registers on context switch in vcpu running state.
@@ -797,6 +823,23 @@ int kvmppc_vcpu_run(struct kvm_run *kvm_run, struct kvm_vcpu *vcpu)
 	current->thread.fpexc_mode = fpexc_mode;
 #endif
 
+#ifdef CONFIG_ALTIVEC
+	kvmppc_save_guest_altivec(vcpu);
+
+	vcpu->arch.vec_active = 0;
+
+	/* Save guest VEC state from thread */
+	memcpy(vcpu->arch.vr, current->thread.vr_state.vr,
+	       sizeof(vcpu->arch.vr));
+	vcpu->arch.vscr = current->thread.vr_state.vscr;
+
+	/* Restore userspace VEC state from stack */
+	memcpy(current->thread.vr_state.vr, vr,
+	       sizeof(current->thread.vr_state.vr));
+	current->thread.vr_state.vscr = vscr;
+	current->thread.used_vr = used_vr;
+#endif
+
 out:
 	vcpu->mode = OUTSIDE_GUEST_MODE;
 	return ret;
diff --git a/arch/powerpc/kvm/booke.h b/arch/powerpc/kvm/booke.h
index a1ff67d..6d0344b 100644
--- a/arch/powerpc/kvm/booke.h
+++ b/arch/powerpc/kvm/booke.h
@@ -35,23 +35,25 @@
 #define BOOKE_IRQPRIO_SPE_UNAVAIL 5
 #define BOOKE_IRQPRIO_SPE_FP_DATA 6
 #define BOOKE_IRQPRIO_SPE_FP_ROUND 7
-#define BOOKE_IRQPRIO_SYSCALL 8
-#define BOOKE_IRQPRIO_AP_UNAVAIL 9
-#define BOOKE_IRQPRIO_DTLB_MISS 10
-#define BOOKE_IRQPRIO_ITLB_MISS 11
-#define BOOKE_IRQPRIO_MACHINE_CHECK 12
-#define BOOKE_IRQPRIO_DEBUG 13
-#define BOOKE_IRQPRIO_CRITICAL 14
-#define BOOKE_IRQPRIO_WATCHDOG 15
-#define BOOKE_IRQPRIO_EXTERNAL 16
-#define BOOKE_IRQPRIO_FIT 17
-#define BOOKE_IRQPRIO_DECREMENTER 18
-#define BOOKE_IRQPRIO_PERFORMANCE_MONITOR 19
+#define BOOKE_IRQPRIO_ALTIVEC_UNAVAIL 8
+#define BOOKE_IRQPRIO_ALTIVEC_ASSIST 9
+#define BOOKE_IRQPRIO_SYSCALL 10
+#define BOOKE_IRQPRIO_AP_UNAVAIL 11
+#define BOOKE_IRQPRIO_DTLB_MISS 12
+#define BOOKE_IRQPRIO_ITLB_MISS 13
+#define BOOKE_IRQPRIO_MACHINE_CHECK 14
+#define BOOKE_IRQPRIO_DEBUG 15
+#define BOOKE_IRQPRIO_CRITICAL 16
+#define BOOKE_IRQPRIO_WATCHDOG 17
+#define BOOKE_IRQPRIO_EXTERNAL 18
+#define BOOKE_IRQPRIO_FIT 19
+#define BOOKE_IRQPRIO_DECREMENTER 20
+#define BOOKE_IRQPRIO_PERFORMANCE_MONITOR 21
 /* Internal pseudo-irqprio for level triggered externals */
-#define BOOKE_IRQPRIO_EXTERNAL_LEVEL 20
-#define BOOKE_IRQPRIO_DBELL 21
-#define BOOKE_IRQPRIO_DBELL_CRIT 22
-#define BOOKE_IRQPRIO_MAX 23
+#define BOOKE_IRQPRIO_EXTERNAL_LEVEL 22
+#define BOOKE_IRQPRIO_DBELL 23
+#define BOOKE_IRQPRIO_DBELL_CRIT 24
+#define BOOKE_IRQPRIO_MAX 25
 
 #define BOOKE_IRQMASK_EE ((1 << BOOKE_IRQPRIO_EXTERNAL_LEVEL) | \
 			  (1 << BOOKE_IRQPRIO_PERFORMANCE_MONITOR) | \
@@ -134,4 +136,36 @@ static inline void kvmppc_clear_dbsr(void)
 {
 	mtspr(SPRN_DBSR, mfspr(SPRN_DBSR));
 }
+
+/*
+ * Load up guest vcpu VEC state if it's needed.
+ * It also set the MSR_VEC in thread so that host know
+ * we're holding VEC, and then host can help to save
+ * guest vcpu VEC state if other threads require to use FPU.
+ * This simulates an VEC unavailable fault.
+ *
+ * It requires to be called with preemption disabled.
+ */
+static inline void kvmppc_load_guest_altivec(struct kvm_vcpu *vcpu)
+{
+#ifdef CONFIG_ALTIVEC
+	if (vcpu->arch.vec_active && !(current->thread.regs->msr & MSR_VEC)) {
+		load_up_altivec(NULL);
+		current->thread.regs->msr |= MSR_VEC;
+	}
+#endif
+}
+
+/*
+ * Save guest vcpu VEC state into thread.
+ * It requires to be called with preemption disabled.
+ */
+static inline void kvmppc_save_guest_altivec(struct kvm_vcpu *vcpu)
+{
+#ifdef CONFIG_ALTIVEC
+	if (vcpu->arch.vec_active && (current->thread.regs->msr & MSR_VEC))
+		giveup_altivec(current);
+#endif
+}
+
 #endif /* __KVM_BOOKE_H__ */
diff --git a/arch/powerpc/kvm/e500_emulate.c b/arch/powerpc/kvm/e500_emulate.c
index 26687c3..fcbfde9 100644
--- a/arch/powerpc/kvm/e500_emulate.c
+++ b/arch/powerpc/kvm/e500_emulate.c
@@ -231,9 +231,11 @@ int kvmppc_core_emulate_mtspr(struct kvm_vcpu *vcpu, int sprn, ulong spr_val)
 	/* extra exceptions */
 	case SPRN_IVOR32:
 		vcpu->arch.ivor[BOOKE_IRQPRIO_SPE_UNAVAIL] = spr_val;
+		vcpu->arch.ivor[BOOKE_IRQPRIO_ALTIVEC_UNAVAIL] = spr_val;
 		break;
 	case SPRN_IVOR33:
 		vcpu->arch.ivor[BOOKE_IRQPRIO_SPE_FP_DATA] = spr_val;
+		vcpu->arch.ivor[BOOKE_IRQPRIO_ALTIVEC_ASSIST] = spr_val;
 		break;
 	case SPRN_IVOR34:
 		vcpu->arch.ivor[BOOKE_IRQPRIO_SPE_FP_ROUND] = spr_val;
@@ -348,9 +350,13 @@ int kvmppc_core_emulate_mfspr(struct kvm_vcpu *vcpu, int sprn, ulong *spr_val)
 
 	/* extra exceptions */
 	case SPRN_IVOR32:
+		WARN_ON_ONCE(vcpu->arch.ivor[BOOKE_IRQPRIO_SPE_UNAVAIL] !=
+			     vcpu->arch.ivor[BOOKE_IRQPRIO_ALTIVEC_UNAVAIL]);
 		*spr_val = vcpu->arch.ivor[BOOKE_IRQPRIO_SPE_UNAVAIL];
 		break;
 	case SPRN_IVOR33:
+		WARN_ON_ONCE(vcpu->arch.ivor[BOOKE_IRQPRIO_SPE_FP_DATA] !=
+			     vcpu->arch.ivor[BOOKE_IRQPRIO_ALTIVEC_ASSIST]);
 		*spr_val = vcpu->arch.ivor[BOOKE_IRQPRIO_SPE_FP_DATA];
 		break;
 	case SPRN_IVOR34:
diff --git a/arch/powerpc/kvm/e500mc.c b/arch/powerpc/kvm/e500mc.c
index ca246f6..3f2f123 100644
--- a/arch/powerpc/kvm/e500mc.c
+++ b/arch/powerpc/kvm/e500mc.c
@@ -158,6 +158,7 @@ void kvmppc_core_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
 	}
 
 	kvmppc_load_guest_fp(vcpu);
+	kvmppc_load_guest_altivec(vcpu);
 }
 
 void kvmppc_core_vcpu_put(struct kvm_vcpu *vcpu)
-- 
1.9.1

