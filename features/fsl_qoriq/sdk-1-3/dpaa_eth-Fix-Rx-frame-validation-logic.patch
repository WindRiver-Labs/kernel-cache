From 8e782a70d0a29242320fa98a2272c2dfa2ce5828 Mon Sep 17 00:00:00 2001
From: Bogdan Hamciuc <bogdan.hamciuc@freescale.com>
Date: Wed, 17 Oct 2012 16:35:23 +0300
Subject: [PATCH 054/162] dpaa_eth: Fix Rx frame validation logic

The frame validation logic on the Rx path was flawed in its assumptions
about the flags set by FMan's Hardware Parser. Specifically, an incoming
frame with bad L4 checksum (but otherwise properly encapsulated at L3
and L2) would go undetected and be passed as such on to the stack, which
would presumably have a hard time figuring out what to do with it.

Fix and refactor the frame validation logic, choose to drop such frames
which we might encounter, and update statistics to track this new kind
of event.

Signed-off-by: Bogdan Hamciuc <bogdan.hamciuc@freescale.com>
[Kevin: Original patch taken from FSL
QorIQ-SDK-V1.3-SOURCE-20121114-yocto.iso tarball.]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 drivers/net/ethernet/freescale/dpa/dpaa_eth.c    |  150 +++++++++++++------
 drivers/net/ethernet/freescale/dpa/dpaa_eth.h    |   50 +++++++
 drivers/net/ethernet/freescale/dpa/dpaa_eth_sg.c |  167 ++++++++--------------
 3 files changed, 219 insertions(+), 148 deletions(-)

diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth.c b/drivers/net/ethernet/freescale/dpa/dpaa_eth.c
index 2f870dd..1838998 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth.c
@@ -1109,6 +1109,93 @@ static void _dpa_tx_error(struct net_device		*net_dev,
 	dev_kfree_skb(skb);
 }
 
+/*
+ * Helper function to factor out frame validation logic on all Rx paths. Its
+ * purpose is to extract from the Parse Results structure information about
+ * the integrity of the frame, its checksum, the length of the parsed headers
+ * and whether the frame is suitable for GRO.
+ *
+ * @skb		will have its ip_summed field overwritten;
+ * @use_gro	will only be written with 0, if the frame is definitely not
+ *		GRO-able; otherwise, it will be left unchanged;
+ * @hdr_size	will be written with a safe value, at least the size of the
+ *		headers' length.
+ *
+ * Returns 0 if the frame contained no detectable error (including if the FMan
+ * Parser has not in fact been running), and a non-zero value if the Parser
+ * has run but encountered an error.
+ */
+int __hot _dpa_process_parse_results(const t_FmPrsResult *parse_results,
+	const struct qm_fd *fd,
+	struct sk_buff *skb,
+	int *use_gro,
+	unsigned int *hdr_size __maybe_unused)
+{
+	if (likely(fm_l4_hxs_has_run(parse_results))) {
+		/*
+		 * Was there any parsing error? Note: this includes the check
+		 * for a valid L4 checksum.
+		 */
+		if (unlikely(fm_l4_hxs_error(parse_results)))
+			/* Leave it to the caller to handle the frame. */
+			return parse_results->l4r;
+
+#ifdef CONFIG_DPAA_ETH_SG_SUPPORT
+		/*
+		 * If the HXS Parser has successfully run, we can reduce the
+		 * number of bytes we'll memcopy into skb->data.
+		 */
+		*hdr_size = parse_results->nxthdr_off;
+#endif
+		/*
+		 * We know the frame is valid. But has the L4 checksum actually
+		 * been validated? (The L4CV bit is only set if the frame is
+		 * TCP or UDP-with-non-zero-csum.)
+		 */
+		if (fd->status & FM_FD_STAT_L4CV)
+			skb->ip_summed = CHECKSUM_UNNECESSARY;
+		else
+			/*
+			 * If it turns out to be a 0-csum UDP, the stack will
+			 * figure it out itself later, sparing us an extra
+			 * check here on the fastpath of every incoming frame.
+			 */
+			skb->ip_summed = CHECKSUM_NONE;
+
+		/*
+		 * Don't go through GRO for certain types of traffic that
+		 * we know are not GRO-able, such as dgram-based protocols.
+		 * In the worst-case scenarios, such as small-pkt terminating
+		 * UDP, the extra GRO processing would be overkill.
+		 *
+		 * The only protocol the Parser supports that is also GRO-able
+		 * is currently TCP.
+		 */
+		if (!fm_l4_frame_is_tcp(parse_results))
+			*use_gro = 0;
+	} else {
+		/* Inform the stack that we haven't done any csum validation. */
+		skb->ip_summed = CHECKSUM_NONE;
+#ifdef CONFIG_DPAA_ETH_SG_SUPPORT
+		/*
+		 * Also, since the Parser hasn't run, we don't know the size of
+		 * the headers, so we fall back to a safe default.
+		 */
+		*hdr_size = min((ssize_t)DPA_COPIED_HEADERS_SIZE,
+				dpa_fd_length(fd));
+#endif
+		/*
+		 * Bypass GRO for unknown traffic or if no PCDs are applied.
+		 * It's unlikely that a GRO handler is installed for this proto
+		 * or, if it is, user does not seem to care about performance
+		 * (otherwise, PCDs would have been in place).
+		 */
+		*use_gro = 0;
+	}
+
+	return 0;
+}
+
 #ifndef CONFIG_DPAA_ETH_SG_SUPPORT
 void __hot _dpa_rx(struct net_device *net_dev,
 		const struct dpa_priv_s *priv,
@@ -1123,6 +1210,8 @@ void __hot _dpa_rx(struct net_device *net_dev,
 	u32 fd_status = fd->status;
 	unsigned int skb_len;
 	t_FmPrsResult *parse_result;
+	int ret;
+	unsigned int hdr_size_unused;
 	int use_gro = net_dev->features & NETIF_F_GRO;
 
 	skbh = (struct sk_buff **)phys_to_virt(addr);
@@ -1168,46 +1257,6 @@ void __hot _dpa_rx(struct net_device *net_dev,
 		goto drop_large_frame;
 	}
 
-	/* Check if the FMan Parser has already validated the L4 csum. */
-	if (fd_status & FM_FD_STAT_L4CV) {
-		/* If we're here, the csum must be valid (if it hadn't,
-		 * the frame would have been received on the Error FQ,
-		 * respectively on the _dpa_rx_error() path). */
-		skb->ip_summed = CHECKSUM_UNNECESSARY;
-		if (use_gro) {
-			/*
-			 * Don't go through GRO for certain types of traffic
-			 * that we know are not GRO-able, such as dgram-based
-			 * protocols. In the worst-case scenarios, such as
-			 * small-pkt terminating UDP or similar IP forwarding,
-			 * the extra GRO processing would be overkill.
-			 *
-			 * So if the FMan Parser is running, the only supported
-			 * protocol that's also GRO-able is currently TCP.
-			 */
-			parse_result = (t_FmPrsResult *)((u8 *)skbh +
-				DPA_RX_PRIV_DATA_SIZE);
-			if (!(parse_result->l4r & FM_L4_PARSE_RESULT_TCP))
-				use_gro = 0;
-		}
-	} else {
-		skb->ip_summed = CHECKSUM_NONE;
-		/*
-		 * Bypass GRO for unknown traffic or if no PCDs are applied.
-		 * It's unlikely that a GRO handler is installed for this proto
-		 * or, if it is, user does not seem to care about performance
-		 * (otherwise, PCDs would have been in place).
-		 *
-		 * TODO: Ultimately, we might still leave GRO for frames larger
-		 * than a certain size (beyond which the GRO overhead becomes
-		 * negligible - that is, empirically, around 1500 bytes), but
-		 * that approach is rather clumsy. The way to go is knowing
-		 * for sure whether the Parser was running, and only disable
-		 * GRO for unrecognized frames.
-		 */
-		use_gro = 0;
-	}
-
 	/* Execute the Rx processing hook, if it exists. */
 	if (dpaa_eth_hooks.rx_default && dpaa_eth_hooks.rx_default(skb,
 		net_dev, fqid) == DPAA_ETH_STOLEN)
@@ -1216,6 +1265,15 @@ void __hot _dpa_rx(struct net_device *net_dev,
 
 	skb_len = skb->len;
 
+	/* Validate the skb csum and figure out whether GRO is appropriate */
+	parse_result = (t_FmPrsResult *)((u8 *)skbh + DPA_RX_PRIV_DATA_SIZE);
+	ret = _dpa_process_parse_results(parse_result, fd, skb, &use_gro,
+					 &hdr_size_unused);
+	if (unlikely(ret)) {
+		percpu_priv->l4_hxs_errors++;
+		percpu_priv->stats.rx_dropped++;
+		goto drop_invalid_frame;
+	}
 	if (use_gro) {
 		gro_result_t gro_result;
 
@@ -1235,12 +1293,13 @@ void __hot _dpa_rx(struct net_device *net_dev,
 packet_dropped:
 skb_stolen:
 	net_dev->last_rx = jiffies;
-
 	return;
 
+drop_invalid_frame:
 drop_large_frame:
 	dev_kfree_skb(skb);
 	return;
+
 _return_dpa_fd_release:
 	dpa_fd_release(net_dev, fd);
 }
@@ -2868,7 +2927,7 @@ static int __cold dpa_debugfs_show(struct seq_file *file, void *offset)
 	/* "Standard" counters */
 	seq_printf(file, "\nDPA counters for %s:\n"
 		"CPU           irqs        rx        tx   recycle" \
-		"   confirm     tx sg    tx err    rx err  bp count\n",
+		"   confirm     tx sg    tx err    rx err   l4 hxs drp    bp count\n",
 		priv->net_dev->name);
 	for_each_online_cpu(i) {
 		percpu_priv = per_cpu_ptr(priv->percpu_priv, i);
@@ -2886,10 +2945,11 @@ static int __cold dpa_debugfs_show(struct seq_file *file, void *offset)
 		total.tx_frag_skbuffs += percpu_priv->tx_frag_skbuffs;
 		total.stats.tx_errors += percpu_priv->stats.tx_errors;
 		total.stats.rx_errors += percpu_priv->stats.rx_errors;
+		total.l4_hxs_errors += percpu_priv->l4_hxs_errors;
 		count_total += dpa_bp_count;
 
 		seq_printf(file, "     %hu/%hu  %8u  %8lu  %8lu  %8u  %8u" \
-				"  %8u  %8lu  %8lu  %8d\n",
+				"  %8u  %8lu  %8lu     %8u    %8d\n",
 				get_hard_smp_processor_id(i), i,
 				percpu_priv->in_interrupt,
 				percpu_priv->stats.rx_packets,
@@ -2899,10 +2959,11 @@ static int __cold dpa_debugfs_show(struct seq_file *file, void *offset)
 				percpu_priv->tx_frag_skbuffs,
 				percpu_priv->stats.tx_errors,
 				percpu_priv->stats.rx_errors,
+				percpu_priv->l4_hxs_errors,
 				dpa_bp_count);
 	}
 	seq_printf(file, "Total     %8u  %8u  %8lu  %8u  %8u  %8u  %8lu  %8lu" \
-				"  %8d\n",
+				"     %8u    %8d\n",
 			total.in_interrupt,
 			total.ingress_calls,
 			total.stats.tx_packets,
@@ -2911,6 +2972,7 @@ static int __cold dpa_debugfs_show(struct seq_file *file, void *offset)
 			total.tx_frag_skbuffs,
 			total.stats.tx_errors,
 			total.stats.rx_errors,
+			total.l4_hxs_errors,
 			count_total);
 
 	/* Congestion stats */
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth.h b/drivers/net/ethernet/freescale/dpa/dpaa_eth.h
index 75fd3aa..39501f4 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth.h
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth.h
@@ -159,6 +159,12 @@ void fsl_dpaa_eth_set_hooks(struct dpaa_eth_hooks_s *hooks);
  * A lower value may help with recycling rates, at least on forwarding
  */
 #define DEFAULT_BUF_SIZE	PAGE_SIZE
+/*
+ * Default amount data to be copied from the beginning of a frame into the
+ * linear part of the skb, in case we aren't using the hardware parser.
+ */
+#define DPA_COPIED_HEADERS_SIZE 128
+
 #else
 /*
  * Default buffer size is based on L2 MAX_FRM value, minus the FCS which is
@@ -177,11 +183,20 @@ void fsl_dpaa_eth_set_hooks(struct dpaa_eth_hooks_s *hooks);
 
 /*
  * Values for the L4R field of the FM Parse Results
+ * See $8.8.4.7.20 - L4 HXS - L4 Results from DPAA-Rev2 Reference Manual.
  */
 /* L4 Type field: UDP */
 #define FM_L4_PARSE_RESULT_UDP	0x40
 /* L4 Type field: TCP */
 #define FM_L4_PARSE_RESULT_TCP	0x20
+/*
+ * This includes L4 checksum errors, but also other errors that the Hard Parser
+ * can detect, such as invalid combinations of TCP control flags, or bad UDP
+ * lengths.
+ */
+#define FM_L4_PARSE_ERROR	0x10
+/* Check if the hardware parser has run */
+#define FM_L4_HXS_RUN		0xE0
 
 /*
  * FD status field indicating whether the FM Parser has attempted to validate
@@ -200,6 +215,28 @@ void fsl_dpaa_eth_set_hooks(struct dpaa_eth_hooks_s *hooks);
 
 #define FM_FD_STAT_ERR_PHYSICAL	FM_PORT_FRM_ERR_PHYSICAL
 
+/*
+ * Check if the FMan Hardware Parser has run for L4 protocols.
+ *
+ * @parse_result_ptr must be of type (t_FmPrsResult *).
+ */
+#define fm_l4_hxs_has_run(parse_result_ptr) \
+	((parse_result_ptr)->l4r & FM_L4_HXS_RUN)
+/*
+ * Iff the FMan Hardware Parser has run for L4 protocols, check error status.
+ *
+ * @parse_result_ptr must be of type (t_FmPrsResult *).
+ */
+#define fm_l4_hxs_error(parse_result_ptr) \
+	((parse_result_ptr)->l4r & FM_L4_PARSE_ERROR)
+/*
+ * Check if the parsed frame was found to be a TCP segment.
+ *
+ * @parse_result_ptr must be of type (t_FmPrsResult *).
+ */
+#define fm_l4_frame_is_tcp(parse_result_ptr) \
+	((parse_result_ptr)->l4r & FM_L4_PARSE_RESULT_TCP)
+
 struct pcd_range {
 	uint32_t			 base;
 	uint32_t			 count;
@@ -296,6 +333,13 @@ struct dpa_percpu_priv_s {
 	u32 tx_confirm;
 	/* fragmented (non-linear) skbuffs received from the stack */
 	u32 tx_frag_skbuffs;
+	/*
+	 * Frames identified as L4 packets (by FMan's Hardware Parser, but for
+	 * which the parsing failed due to some error condition. If we come
+	 * across such frames, we drop them instead of passing them up the
+	 * stack, which means the L4 stats in the stack won't increment.
+	 */
+	u32 l4_hxs_errors;
 	struct net_device_stats	 stats;
 	struct dpa_rx_errors rx_errors;
 	struct dpa_ern_cnt ern_cnt;
@@ -365,6 +409,12 @@ int __hot dpa_tx(struct sk_buff *skb, struct net_device *net_dev);
 struct sk_buff *_dpa_cleanup_tx_fd(const struct dpa_priv_s *priv,
 				   const struct qm_fd *fd);
 
+int __hot _dpa_process_parse_results(const t_FmPrsResult *parse_results,
+				     const struct qm_fd *fd,
+				     struct sk_buff *skb,
+				     int *use_gro,
+				     unsigned int *hdr_size __maybe_unused);
+
 #ifdef CONFIG_DPAA_ETH_SG_SUPPORT
 void dpa_bp_add_8_pages(struct dpa_bp *dpa_bp, int cpu_id);
 
diff --git a/drivers/net/ethernet/freescale/dpa/dpaa_eth_sg.c b/drivers/net/ethernet/freescale/dpa/dpaa_eth_sg.c
index 8c74dd1..4a3fb7a 100644
--- a/drivers/net/ethernet/freescale/dpa/dpaa_eth_sg.c
+++ b/drivers/net/ethernet/freescale/dpa/dpaa_eth_sg.c
@@ -43,8 +43,6 @@
 #include "dpaa_1588.h"
 
 #ifdef CONFIG_DPAA_ETH_SG_SUPPORT
-
-#define DPA_COPIED_HEADERS_SIZE 128
 #define DPA_SGT_MAX_ENTRIES 16 /* maximum number of entries in SG Table */
 
 /*
@@ -276,19 +274,22 @@ struct sk_buff *_dpa_cleanup_tx_fd(const struct dpa_priv_s *priv,
  *
  * If the entire frame fits in the skb linear buffer, the page holding the
  * received data is recycled as it is no longer required.
+ *
+ * Return 0 if the ingress skb was properly constructed, non-zero if an error
+ * was encountered and the frame should be dropped.
  */
-static void __hot contig_fd_to_skb(const struct dpa_priv_s *priv,
-				   const struct qm_fd *fd, struct sk_buff *skb,
-				   int *use_gro)
+static int __hot contig_fd_to_skb(const struct dpa_priv_s *priv,
+	const struct qm_fd *fd, struct sk_buff *skb, int *use_gro)
 {
-	unsigned int copy_size;
+	unsigned int copy_size = DPA_COPIED_HEADERS_SIZE;
 	dma_addr_t addr = qm_fd_addr(fd);
 	void *vaddr;
 	struct page *page;
 	int frag_offset, page_offset;
 	struct dpa_bp *dpa_bp = priv->dpa_bp;
 	unsigned char *tailptr;
-	t_FmPrsResult *parse_results;
+	const t_FmPrsResult *parse_results;
+	int ret;
 
 	vaddr = phys_to_virt(addr);
 
@@ -297,59 +298,13 @@ static void __hot contig_fd_to_skb(const struct dpa_priv_s *priv,
 		dpa_ptp_store_rxstamp(priv->net_dev, skb, fd);
 #endif
 
-	/*
-	 * If the FMan Parser has already validated the L4 csum, we can take
-	 * some shortcuts knowing that the protocol headers have been parsed.
-	 */
-	if (fd->status & FM_FD_STAT_L4CV) {
-		/*
-		 * If we're here, the csum must be valid (if it hadn't,
-		 * the frame would have been received on the Error FQ,
-		 * respectively on the _dpa_rx_error() path).
-		 */
-		skb->ip_summed = CHECKSUM_UNNECESSARY;
-
-		/* Reduce the size of the buffer to memcopy in the skb data */
-		parse_results = (t_FmPrsResult *)(vaddr +
-			DPA_RX_PRIV_DATA_SIZE);
-		copy_size = parse_results->nxthdr_off;
-
-		/*
-		 * Don't go through GRO for certain types of traffic
-		 * that we know are not GRO-able, such as dgram-based
-		 * protocols. In the worst-case scenarios, such as
-		 * small-pkt terminating UDP or similar IP forwarding,
-		 * the extra GRO processing would be overkill.
-		 *
-		 * So if the FMan Parser is running, the only supported
-		 * protocol that's also GRO-able is currently TCP.
-		 */
-		if (*use_gro && !(parse_results->l4r & FM_L4_PARSE_RESULT_TCP))
-			*use_gro = 0;
-	} else {
-		skb->ip_summed = CHECKSUM_NONE;
-		/*
-		 * We don't know the parsed headers' length, so we default
-		 * to the compile-time constant or the frame length.
-		 */
-		copy_size = min((ssize_t)DPA_COPIED_HEADERS_SIZE,
-			dpa_fd_length(fd));
-
-		/*
-		 * Bypass GRO for unknown traffic or if no PCDs are applied.
-		 * It's unlikely that a GRO handler is installed for this proto
-		 * or, if it is, user does not seem to care about performance
-		 * (otherwise, PCDs would have been in place).
-		 *
-		 * TODO: Ultimately, we might still leave GRO for frames larger
-		 * than a certain size (beyond which the GRO overhead becomes
-		 * negligible - that is, empirically, around 1500 bytes), but
-		 * that approach is rather clumsy. The way to go is knowing
-		 * for sure whether the Parser was running, and only disable
-		 * GRO for unrecognized frames.
-		 */
-		*use_gro = 0;
-	}
+	/* Peek at the parse results for frame validation. */
+	parse_results = (const t_FmPrsResult *)(vaddr + DPA_RX_PRIV_DATA_SIZE);
+	ret = _dpa_process_parse_results(parse_results, fd, skb, use_gro,
+		&copy_size);
+	if (unlikely(ret))
+		/* This is definitely a bad frame, don't go further. */
+		return ret;
 
 	tailptr = skb_put(skb, copy_size);
 
@@ -376,17 +331,19 @@ static void __hot contig_fd_to_skb(const struct dpa_priv_s *priv,
 
 	/* Copy (at least) the headers in the linear portion */
 	memcpy(tailptr, vaddr + dpa_fd_offset(fd), copy_size);
+
+	return 0;
 }
 
 
 /*
- * Move the first DPA_COPIED_HEADERS_SIZE bytes to the skb linear buffer to
- * provide the networking stack the headers it requires in the linear buffer
+ * Move the first bytes of the frame to the skb linear buffer to
+ * provide the networking stack the headers it requires in the linear buffer,
  * and add the rest of the frame as skb fragments.
  *
  * The page holding the S/G Table is recycled here.
  */
-static void __hot sg_fd_to_skb(const struct dpa_priv_s *priv,
+static int __hot sg_fd_to_skb(const struct dpa_priv_s *priv,
 			       const struct qm_fd *fd, struct sk_buff *skb,
 			       int *use_gro)
 {
@@ -398,10 +355,22 @@ static void __hot sg_fd_to_skb(const struct dpa_priv_s *priv,
 	struct page *page;
 	int frag_offset, frag_len;
 	int page_offset;
-	int i;
-	t_FmPrsResult *parse_results;
+	int i, ret;
+	unsigned int copy_size = DPA_COPIED_HEADERS_SIZE;
+	const t_FmPrsResult *parse_results;
 
 	vaddr = phys_to_virt(addr);
+	/*
+	 * In the case of a SG frame, FMan stores the Internal Context
+	 * in the buffer containing the sgt.
+	 */
+	parse_results = (const t_FmPrsResult *)(vaddr + DPA_RX_PRIV_DATA_SIZE);
+	/* Validate the frame before anything else. */
+	ret = _dpa_process_parse_results(parse_results, fd, skb, use_gro,
+		&copy_size);
+	if (unlikely(ret))
+		/* Bad frame, stop processing now. */
+		return ret;
 
 	/*
 	 * Iterate through the SGT entries and add the data buffers as
@@ -430,14 +399,13 @@ static void __hot sg_fd_to_skb(const struct dpa_priv_s *priv,
 		if (i == 0) {
 			/* This is the first fragment */
 			/* Move the network headers in the skb linear portion */
-			memcpy(skb_put(skb, DPA_COPIED_HEADERS_SIZE),
+			memcpy(skb_put(skb, copy_size),
 				sg_vaddr + sgt[i].offset,
-				DPA_COPIED_HEADERS_SIZE);
+				copy_size);
 
 			/* Adjust offset/length for the remaining data */
-			frag_offset = sgt[i].offset + page_offset +
-				      DPA_COPIED_HEADERS_SIZE;
-			frag_len = sgt[i].length - DPA_COPIED_HEADERS_SIZE;
+			frag_offset = sgt[i].offset + page_offset + copy_size;
+			frag_len = sgt[i].length - copy_size;
 		} else {
 			/*
 			 * Not the first fragment; all data from buferr will
@@ -453,33 +421,6 @@ static void __hot sg_fd_to_skb(const struct dpa_priv_s *priv,
 			break;
 	}
 
-	/* Check if the FMan Parser has already validated the L4 csum. */
-	if (fd->status & FM_FD_STAT_L4CV) {
-		/*
-		 * If we're here, the csum must be valid (if it hadn't,
-		 * the frame would have been received on the Error FQ,
-		 * respectively on the _dpa_rx_error() path).
-		 */
-		skb->ip_summed = CHECKSUM_UNNECESSARY;
-
-		/*
-		 * In the case of a SG frame, FMan stores the Internal Context
-		 * in the buffer containing the sgt.
-		 */
-		parse_results = (t_FmPrsResult *)(vaddr +
-			DPA_RX_PRIV_DATA_SIZE);
-		/*
-		 * Selectively disable GRO. See comment in contig_fd_to_skb().
-		 */
-		if (*use_gro && !(parse_results->l4r & FM_L4_PARSE_RESULT_TCP))
-			*use_gro = 0;
-	} else {
-		skb->ip_summed = CHECKSUM_NONE;
-		/* Bypass GRO. See comment in contig_fd_to_skb(). */
-		use_gro = 0;
-	}
-
-
 #ifdef CONFIG_FSL_DPA_1588
 	if (priv->tsu && priv->tsu->valid && priv->tsu->hwts_rx_en_ioctl)
 		dpa_ptp_store_rxstamp(priv->net_dev, skb, fd);
@@ -489,6 +430,8 @@ static void __hot sg_fd_to_skb(const struct dpa_priv_s *priv,
 	dpa_bp = dpa_bpid2pool(fd->bpid);
 	BUG_ON(IS_ERR(dpa_bp));
 	dpa_bp_add_page(dpa_bp, (unsigned long)vaddr);
+
+	return 0;
 }
 
 void __hot _dpa_rx(struct net_device *net_dev,
@@ -541,11 +484,25 @@ void __hot _dpa_rx(struct net_device *net_dev,
 	/* prefetch the first 64 bytes of the frame or the SGT start */
 	prefetch(phys_to_virt(addr) + dpa_fd_offset(fd));
 
-	if (likely(fd->format == qm_fd_contig))
-		contig_fd_to_skb(priv, fd, skb, &use_gro);
-	else if (fd->format == qm_fd_sg)
-		sg_fd_to_skb(priv, fd, skb, &use_gro);
-	else
+	if (likely(fd->format == qm_fd_contig)) {
+		if (unlikely(contig_fd_to_skb(priv, fd, skb, &use_gro))) {
+			/*
+			 * There was a L4 HXS error - e.g. the L4 csum was
+			 * invalid - so drop the frame early instead of passing
+			 * it on to the stack. We'll increment our private
+			 * counters to track this event.
+			 */
+			percpu_priv->l4_hxs_errors++;
+			percpu_priv->stats.rx_dropped++;
+			goto drop_bad_frame;
+		}
+	} else if (fd->format == qm_fd_sg) {
+		if (unlikely(sg_fd_to_skb(priv, fd, skb, &use_gro))) {
+			percpu_priv->l4_hxs_errors++;
+			percpu_priv->stats.rx_dropped++;
+			goto drop_bad_frame;
+		}
+	} else
 		/* The only FD types that we may receive are contig and S/G */
 		BUG();
 
@@ -553,8 +510,7 @@ void __hot _dpa_rx(struct net_device *net_dev,
 
 	if (unlikely(dpa_check_rx_mtu(skb, net_dev->mtu))) {
 		percpu_priv->stats.rx_dropped++;
-		dev_kfree_skb(skb);
-		return;
+		goto drop_bad_frame;
 	}
 
 	skb_len = skb->len;
@@ -577,7 +533,10 @@ void __hot _dpa_rx(struct net_device *net_dev,
 
 packet_dropped:
 	net_dev->last_rx = jiffies;
+	return;
 
+drop_bad_frame:
+	dev_kfree_skb(skb);
 	return;
 
 _release_frame:
-- 
1.7.9.7

