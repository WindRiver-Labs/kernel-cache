From f65530ba1cda237a38896a31068d4357be81f72d Mon Sep 17 00:00:00 2001
From: "Lu.Jiang" <lu.jiang@windriver.com>
Date: Fri, 5 Sep 2014 13:35:58 +0800
Subject: [PATCH 124/987] dpaa_eth,temp: Temporarily revert skb recycling
 removal

[Original patch taken from QorIQ-SDK-V1.6-SOURCE-20140619-yocto.iso]

Partially reverting commit acb600def2110b1310466c0e485c0d26299898ae, in
that we leave the skb recycling functions around until we rebase our
code onto the new 3.8 kernel base.
1. We'll first move this capability back into our driver.
2. At a later stage, we'll remove this capability in this particular
form from the driver altogether, as we integrate the new net APIs.

Signed-off-by: Bogdan Hamciuc <bogdan.hamciuc@freescale.com>
Signed-off-by: Lu.Jiang <lu.jiang@windriver.com>
[Fix context to apply to WRL.]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 include/linux/skbuff.h | 24 ++++++++++++++++++++++++
 net/core/skbuff.c      | 47 +++++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 71 insertions(+)

diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h
index f15154a..7f3f2fd 100644
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -829,6 +829,9 @@ static inline struct sk_buff *alloc_skb_head(gfp_t priority)
 	return __alloc_skb_head(priority, -1);
 }
 
+void skb_recycle(struct sk_buff *skb);
+bool skb_recycle_check(struct sk_buff *skb, int skb_size);
+
 struct sk_buff *skb_morph(struct sk_buff *dst, struct sk_buff *src);
 int skb_copy_ubufs(struct sk_buff *skb, gfp_t gfp_mask);
 struct sk_buff *skb_clone(struct sk_buff *skb, gfp_t priority);
@@ -2937,6 +2940,27 @@ static inline int skb_csum_unnecessary(const struct sk_buff *skb)
 		 skb_checksum_start_offset(skb) >= 0));
 }
 
+static inline bool skb_is_recycleable(const struct sk_buff *skb, int skb_size)
+{
+	if (irqs_disabled())
+		return false;
+
+	if (skb_shinfo(skb)->tx_flags & SKBTX_DEV_ZEROCOPY)
+		return false;
+
+	if (skb_is_nonlinear(skb) || skb->fclone != SKB_FCLONE_UNAVAILABLE)
+		return false;
+
+	skb_size = SKB_DATA_ALIGN(skb_size + NET_SKB_PAD);
+	if (skb_end_offset(skb) < skb_size)
+		return false;
+
+	if (skb_shared(skb) || skb_cloned(skb))
+		return false;
+
+	return true;
+}
+
 /**
  *	skb_checksum_complete - Calculate checksum of an entire packet
  *	@skb: packet to process
diff --git a/net/core/skbuff.c b/net/core/skbuff.c
index 41ec022..ce3d127 100644
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -802,6 +802,53 @@ EXPORT_SYMBOL(consume_skb);
 	BUILD_BUG_ON(offsetof(struct sk_buff, field) >		\
 		     offsetof(struct sk_buff, headers_end));	\
 
+/**
+ * 	skb_recycle - clean up an skb for reuse
+ * 	@skb: buffer
+ *
+ * 	Recycles the skb to be reused as a receive buffer. This
+ * 	function does any necessary reference count dropping, and
+ * 	cleans up the skbuff as if it just came from __alloc_skb().
+ */
+void skb_recycle(struct sk_buff *skb)
+{
+	struct skb_shared_info *shinfo;
+
+	skb_release_head_state(skb);
+
+	shinfo = skb_shinfo(skb);
+	memset(shinfo, 0, offsetof(struct skb_shared_info, dataref));
+	atomic_set(&shinfo->dataref, 1);
+
+	memset(skb, 0, offsetof(struct sk_buff, tail));
+	skb->data = skb->head + NET_SKB_PAD;
+	skb_reset_tail_pointer(skb);
+}
+EXPORT_SYMBOL(skb_recycle);
+
+/**
+ *	skb_recycle_check - check if skb can be reused for receive
+ *	@skb: buffer
+ *	@skb_size: minimum receive buffer size
+ *
+ *	Checks that the skb passed in is not shared or cloned, and
+ *	that it is linear and its head portion at least as large as
+ *	skb_size so that it can be recycled as a receive buffer.
+ *	If these conditions are met, this function does any necessary
+ *	reference count dropping and cleans up the skbuff as if it
+ *	just came from __alloc_skb().
+ */
+bool skb_recycle_check(struct sk_buff *skb, int skb_size)
+{
+	if (!skb_is_recycleable(skb, skb_size))
+		return false;
+
+	skb_recycle(skb);
+
+	return true;
+}
+EXPORT_SYMBOL(skb_recycle_check);
+
 static void __copy_skb_header(struct sk_buff *new, const struct sk_buff *old)
 {
 	new->tstamp		= old->tstamp;
-- 
1.9.1

