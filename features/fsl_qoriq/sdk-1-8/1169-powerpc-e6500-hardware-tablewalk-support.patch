From 0a7d4c5f58b01de6fc167731cd275982ef433f57 Mon Sep 17 00:00:00 2001
From: "Lu.Jiang" <lu.jiang@windriver.com>
Date: Tue, 23 Sep 2014 14:46:29 +0800
Subject: [PATCH 1169/1207] powerpc/e6500: hardware tablewalk support

[Original patch taken from QorIQ-SDK-V1.6-SOURCE-20140619-yocto.iso]

Preliminary support for e6500 hardware tablewalk.  This is for simulator
(and rev2) only.  On rev1 hardware, be sure to set
CONFIG_PPC_FSL_BUGGY_HW_TABLEWALK.

Locking is introduced to make TLB misses threadsafe.  TODO: add locking to
the non-tablewalk miss handlers, which was the main reason for making the
locking conditional.

Signed-off-by: Scott Wood <scott@tyr.buserror.net>
Signed-off-by: Andy Fleming <afleming@freescale.net>
(cherry-picked from commit f071125a3d33816772caa91146936af0716f0f78)
Signed-off-by: Lu.Jiang <lu.jiang@windriver.com>
---
 arch/powerpc/include/asm/paca.h      | 10 ++++++++--
 arch/powerpc/kernel/paca.c           |  2 +-
 arch/powerpc/kernel/setup_64.c       | 16 ++++------------
 arch/powerpc/mm/hugetlbpage-book3e.c |  2 +-
 arch/powerpc/mm/tlb_low_64e.S        | 10 +++++-----
 5 files changed, 19 insertions(+), 21 deletions(-)

diff --git a/arch/powerpc/include/asm/paca.h b/arch/powerpc/include/asm/paca.h
index 70bd438..5624407 100644
--- a/arch/powerpc/include/asm/paca.h
+++ b/arch/powerpc/include/asm/paca.h
@@ -111,8 +111,14 @@ struct paca_struct {
 	pgd_t *pgd __aligned(0x40); /* Current PGD */
 	pgd_t *kernel_pgd;		/* Kernel PGD */
 
-	/* Shared by all threads of a core -- points to tcd of first thread */
-	struct tlb_core_data *tcd_ptr;
+	/*
+	* Points to the tlb_per_core of the first thread on this core.
+	* The low bit is set if there is more than one thread per core
+	* (a bit gross, but avoids an extra load in the TLB miss handler,
+	* or atomic instructions where none are needed).
+	*/
+#define TLB_PER_CORE_HAS_LOCK 1
+	uintptr_t tcd_ptr;
 
 	/*
 	 * We can have up to 3 levels of reentrancy in the TLB miss handler,
diff --git a/arch/powerpc/kernel/paca.c b/arch/powerpc/kernel/paca.c
index 5a23b69..32a7bff 100644
--- a/arch/powerpc/kernel/paca.c
+++ b/arch/powerpc/kernel/paca.c
@@ -175,7 +175,7 @@ void __init initialise_paca(struct paca_struct *new_paca, int cpu)
 
 #ifdef CONFIG_PPC_BOOK3E
 	/* For now -- if we have threads this will be adjusted later */
-	new_paca->tcd_ptr = &new_paca->tcd;
+	new_paca->tcd_ptr = (uintptr_t)&new_paca->tcd;
 #endif
 }
 
diff --git a/arch/powerpc/kernel/setup_64.c b/arch/powerpc/kernel/setup_64.c
index 2d935f5..3f05f18 100644
--- a/arch/powerpc/kernel/setup_64.c
+++ b/arch/powerpc/kernel/setup_64.c
@@ -108,20 +108,12 @@ static void setup_tlb_core_data(void)
 	for_each_possible_cpu(cpu) {
 		int first = cpu_first_thread_sibling(cpu);
 
-		paca[cpu].tcd_ptr = &paca[first].tcd;
+		paca[cpu].tcd_ptr = (uintptr_t)&paca[first].tcd;
 
-		/*
-		 * If we have threads, we need either tlbsrx.
-		 * or e6500 tablewalk mode, or else TLB handlers
-		 * will be racy and could produce duplicate entries.
-		 */
+		/* If we have threads but no tlbsrx., use a per-core lock */
 		if (smt_enabled_at_boot >= 2 &&
-		    !mmu_has_feature(MMU_FTR_USE_TLBRSRV) &&
-		    book3e_htw_mode != PPC_HTW_E6500) {
-			/* Should we panic instead? */
-			WARN_ONCE("%s: unsupported MMU configuration -- expect problems\n",
-				  __func__);
-		}
+		    !mmu_has_feature(MMU_FTR_USE_TLBRSRV))
+			paca[cpu].tcd_ptr |= TLB_PER_CORE_HAS_LOCK;
 	}
 }
 #else
diff --git a/arch/powerpc/mm/hugetlbpage-book3e.c b/arch/powerpc/mm/hugetlbpage-book3e.c
index a1f03ae..f2926a4 100644
--- a/arch/powerpc/mm/hugetlbpage-book3e.c
+++ b/arch/powerpc/mm/hugetlbpage-book3e.c
@@ -16,7 +16,7 @@ static inline int tlb1_next(void)
 	struct tlb_core_data *tcd;
 	int this, next;
 
-	tcd = paca->tcd_ptr;
+	tcd = (struct tlb_core_data *)(paca->tcd_ptr & ~1UL);
 	this = tcd->esel_next;
 
 	next = this + 1;
diff --git a/arch/powerpc/mm/tlb_low_64e.S b/arch/powerpc/mm/tlb_low_64e.S
index 38e07a5..f3ec653 100644
--- a/arch/powerpc/mm/tlb_low_64e.S
+++ b/arch/powerpc/mm/tlb_low_64e.S
@@ -123,7 +123,7 @@ END_FTR_SECTION_IFSET(CPU_FTR_EMB_HV)
 	oris	r11,r10,_PAGE_ACCESSED@h
 
 BEGIN_FTR_SECTION
-	ld	r10,PACA_TLB_PER_CORE_PTR(r13)
+	ld	r10,PACA_TCD_PTR(r13)
 END_FTR_SECTION_IFSET(CPU_FTR_SMT)
 
 	TLB_MISS_STATS_SAVE_INFO_BOLTED
@@ -148,7 +148,7 @@ tlb_miss_common_bolted:
 	 */
 BEGIN_FTR_SECTION
 	mtocrf	0x01,r10
-	addi	r10,r10,PACA_TLB_LOCK-1 /* -1 to compensate for low bit set */
+	addi	r10,r10,TCD_LOCK-1 /* -1 to compensate for low bit set */
 	bf	31,1f		/* no lock if TLB_PER_CORE_HAS_LOCK clear */
 2:	lbarx	r15,0,r10
 	cmpdi	r15,0
@@ -239,11 +239,11 @@ END_FTR_SECTION_IFSET(CPU_FTR_SMT)
 tlb_miss_done_bolted:
 	.macro	tlb_unlock_bolted
 BEGIN_FTR_SECTION
-	ld	r10,PACA_TLB_PER_CORE_PTR(r13)
+	ld	r10,PACA_TCD_PTR(r13)
 	bf	31,1f
 	li	r15,0
 	isync
-	stb	r15,PACA_TLB_LOCK-1(r10)
+	stb	r15,TCD_LOCK-1(r10)
 1:
 END_FTR_SECTION_IFSET(CPU_FTR_SMT)
 	.endm
@@ -289,7 +289,7 @@ itlb_miss_fault_bolted:
 	bne-	itlb_miss_fault_bolted
 
 BEGIN_FTR_SECTION
-	ld	r10,PACA_TLB_PER_CORE_PTR(r13)
+	ld	r10,PACA_TCD_PTR(r13)
 END_FTR_SECTION_IFSET(CPU_FTR_SMT)
 	li	r11,_PAGE_PRESENT|_PAGE_EXEC	/* Base perm */
 
-- 
2.0.2

