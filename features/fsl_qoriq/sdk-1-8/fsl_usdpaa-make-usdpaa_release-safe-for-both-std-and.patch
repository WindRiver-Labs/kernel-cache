From cb4f13bcbe9266f93c7760151a0df5f90c8e318a Mon Sep 17 00:00:00 2001
From: Kevin Hao <kexin.hao@windriver.com>
Date: Tue, 26 Jan 2016 16:24:17 +0800
Subject: [PATCH] fsl_usdpaa: make usdpaa_release() safe for both std and rt
 kernel

The usdpaa release operation can't be migrated to another CPU as
CPU specific variables may be used during cleanup. So patch
("Disable CPU migration during USDPAA Cleanup") disable/enable the
migration by using migrate_disable/enable(), but these functions only
exist in rt kernel, for std kernel we still need to use
preempt_disable/enable() to avoid the CPU migration. Introduce
usdpaa_migrate_disable/enable() help functions so they can work
for both std and rt kernel.

Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 drivers/staging/fsl_qbman/fsl_usdpaa.c |   32 ++++++++++++++++++++++++++------
 1 files changed, 26 insertions(+), 6 deletions(-)

diff --git a/drivers/staging/fsl_qbman/fsl_usdpaa.c b/drivers/staging/fsl_qbman/fsl_usdpaa.c
index 31875c4..31ad343 100644
--- a/drivers/staging/fsl_qbman/fsl_usdpaa.c
+++ b/drivers/staging/fsl_qbman/fsl_usdpaa.c
@@ -505,7 +505,27 @@ static bool check_portal_channel(void *ctx, u32 channel)
 	return false;
 }
 
+#ifdef CONFIG_PREEMPT_RT_FULL
+static void usdpaa_migrate_disable(void)
+{
+	migrate_disable();
+}
+
+static void usdpaa_migrate_enable(void)
+{
+	migrate_enable();
+}
+#else
+static void usdpaa_migrate_disable(void)
+{
+	preempt_disable();
+}
 
+static void usdpaa_migrate_enable(void)
+{
+	preempt_enable();
+}
+#endif
 
 static int usdpaa_release(struct inode *inode, struct file *filp)
 {
@@ -524,7 +544,7 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 
 	/* Ensure the release operation cannot be migrated to another
 	   CPU as CPU specific variables may be needed during cleanup */
-	migrate_disable();
+	usdpaa_migrate_disable();
 
 	/* The following logic is used to recover resources that were not
 	   correctly released by the process that is closing the FD.
@@ -561,13 +581,13 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 		qm_alloced_portal = qm_get_unused_portal();
 		if (!qm_alloced_portal) {
 			pr_crit("No QMan portal avalaible for cleanup\n");
-			migrate_enable();
+			usdpaa_migrate_enable();
 			return -1;
 		}
 		qm_cleanup_portal = kmalloc(sizeof(struct qm_portal),
 					    GFP_KERNEL);
 		if (!qm_cleanup_portal) {
-			migrate_enable();
+			usdpaa_migrate_enable();
 			return -ENOMEM;
 		}
 		init_qm_portal(qm_alloced_portal, qm_cleanup_portal);
@@ -578,13 +598,13 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 		bm_alloced_portal = bm_get_unused_portal();
 		if (!bm_alloced_portal) {
 			pr_crit("No BMan portal avalaible for cleanup\n");
-			migrate_enable();
+			usdpaa_migrate_enable();
 			return -1;
 		}
 		bm_cleanup_portal = kmalloc(sizeof(struct bm_portal),
 					    GFP_KERNEL);
 		if (!bm_cleanup_portal) {
-			migrate_enable();
+			usdpaa_migrate_enable();
 			return -ENOMEM;
 		}
 		init_bm_portal(bm_alloced_portal, bm_cleanup_portal);
@@ -662,7 +682,7 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 	}
 
 	kfree(ctx);
-	migrate_enable();
+	usdpaa_migrate_enable();
 	return 0;
 }
 
-- 
1.7.5.4

