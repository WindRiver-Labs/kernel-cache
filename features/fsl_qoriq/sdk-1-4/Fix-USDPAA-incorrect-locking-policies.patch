From 3e94bbd283b816dbdb37b7c44ab6d23764b64a3c Mon Sep 17 00:00:00 2001
From: Ying Xue <ying.xue@windriver.com>
Date: Tue, 23 Jun 2015 16:02:46 +0800
Subject: [PATCH] Fix USDPAA incorrect locking policies

When a new portal element is inserted into ctx->portals list in
ioctl_portal_map(), the ctx->portals list is protected by mem_lock,
however, when a portal is deleted from the list in usdpaa_release(),
the list is not protected by any lock at all. Meanwhile, when the
list is iterated in usdpaa_get_portal_config(), it's protected by
a different lock - ctx->lock. This inconsistent or incorrect locking
policies often lead to serious bugs, such as kernel panic.

So the locking policies associated with USDPAA are uniformly adjusted
as follows:
- ctx->portals, which is protected by mem_lock
- ctx->maps, which is protected by mem_lock
- ctx->resources[], which is protected by ctx->lock
- mem_list, which is protected by mem_lock

By the way, we also found other locking issues, for example:
- While accessing ctx->resources[], the resources[] is not protected
  by ctx->lock at all in several places.
- While iterating mem_list in ioctl_dma_stats(), the list is not
  protected too.

Signed-off-by: Ying Xue <ying.xue@windriver.com>
---
 drivers/staging/fsl_qbman/fsl_usdpaa.c |   31 +++++++++++++++++++++++--------
 1 files changed, 23 insertions(+), 8 deletions(-)

diff --git a/drivers/staging/fsl_qbman/fsl_usdpaa.c b/drivers/staging/fsl_qbman/fsl_usdpaa.c
index bce680f..cfe8046 100644
--- a/drivers/staging/fsl_qbman/fsl_usdpaa.c
+++ b/drivers/staging/fsl_qbman/fsl_usdpaa.c
@@ -422,22 +422,29 @@ static bool check_channel_device(void *_ctx, u32 channel)
 	struct active_resource *res;
 
 	/* See if the FQ is destined for one of the portals we're cleaning up */
+	spin_lock(&mem_lock);
 	list_for_each_entry_safe(portal, tmpportal, &ctx->portals, list) {
 		if (portal->user.type == usdpaa_portal_qman) {
 			if (portal->qportal->public_cfg.channel == channel) {
 				/* This FQs destination is a portal
 				   we're cleaning, send a retire */
+				spin_unlock(&mem_lock);
 				return true;
 			}
 		}
 	}
+	spin_unlock(&mem_lock);
 
 	/* Check the pool channels that will be released as well */
+	spin_lock(&ctx->lock);
 	list_for_each_entry(res, &ctx->resources[usdpaa_id_qpool], list) {
 		if ((res->id >= channel) &&
-		    ((res->id + res->num - 1) <= channel))
+		    ((res->id + res->num - 1) <= channel)) {
+			spin_unlock(&ctx->lock);
 			return true;
+		}
 	}
+	spin_unlock(&ctx->lock);
 	return false;
 }
 
@@ -461,6 +468,7 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 	   in the kernel
 	*/
 
+	spin_lock(&mem_lock);
 	list_for_each_entry_safe(portal, tmpportal, &ctx->portals, list) {
 		/* Try to recover any portals that weren't shut down */
 		if (portal->user.type == usdpaa_portal_qman) {
@@ -476,6 +484,8 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 				bm_cleanup_portal = &portal->bman_portal_low;
 		}
 	}
+	spin_unlock(&mem_lock);
+
 	/* If no portal was found, allocate one for cleanup */
 	if (!qm_cleanup_portal) {
 		qm_alloced_portal = qm_get_unused_portal();
@@ -508,11 +518,13 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 
 	while (backend->id_type != usdpaa_id_max) {
 		int leaks = 0;
+		spin_lock(&ctx->lock);
 		list_for_each_entry(res, &ctx->resources[backend->id_type],
 				    list) {
 			leaks += res->num;
 			backend->release(res->id, res->num);
 		}
+		spin_unlock(&ctx->lock);
 		if (leaks)
 			pr_crit("USDPAA process leaking %d %s%s\n", leaks,
 				backend->acronym, (leaks > 1) ? "s" : "");
@@ -534,7 +546,6 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 		list_del(&map->list);
 		kfree(map);
 	}
-	spin_unlock(&mem_lock);
 
 	/* Return portals */
 	list_for_each_entry_safe(portal, tmpportal, &ctx->portals, list) {
@@ -547,6 +558,8 @@ static int usdpaa_release(struct inode *inode, struct file *filp)
 		list_del(&portal->list);
 		kfree(portal);
 	}
+	spin_unlock(&mem_lock);
+
 	if (qm_alloced_portal) {
 		qm_put_unused_portal(qm_alloced_portal);
 		kfree(qm_cleanup_portal);
@@ -935,9 +948,11 @@ static long ioctl_dma_stats(struct ctx *ctx, void __user *arg)
 	result.free_bytes = 0;
 	result.total_bytes = phys_size;
 
+	spin_lock(&mem_lock);
 	list_for_each_entry(frag, &mem_list, list) {
 		result.free_bytes += frag->len;
 	}
+	spin_unlock(&mem_lock);
 
 	return copy_to_user(arg, &result, sizeof(result)); }
 
@@ -1294,15 +1309,15 @@ struct qm_portal_config *usdpaa_get_qm_portal_config(struct file *filp,
 	if (filp->f_op->open != usdpaa_open)
 		return NULL;
 	context = filp->private_data;
-	spin_lock(&context->lock);
+	spin_lock(&mem_lock);
 	list_for_each_entry(portal, &context->portals, list) {
 		if (portal->user.type == usdpaa_portal_qman &&
 		    portal->user.addr.cinh == hint) {
-			spin_unlock(&context->lock);
+			spin_unlock(&mem_lock);
 			return portal->qportal;
 		}
 	}
-	spin_unlock(&context->lock);
+	spin_unlock(&mem_lock);
 	return NULL;
 }
 
@@ -1321,15 +1336,15 @@ struct bm_portal_config *usdpaa_get_bm_portal_config(struct file *filp,
 
 	context = filp->private_data;
 
-	spin_lock(&context->lock);
+	spin_lock(&mem_lock);
 	list_for_each_entry(portal, &context->portals, list) {
 		if (portal->user.type == usdpaa_portal_bman &&
 		    portal->user.addr.cinh == hint) {
-			spin_unlock(&context->lock);
+			spin_unlock(&mem_lock);
 			return portal->bportal;
 		}
 	}
-	spin_unlock(&context->lock);
+	spin_unlock(&mem_lock);
 	return NULL;
 }
 
-- 
1.7.5.4

