From b273f261f18d57b84c15f38f769dc5b2b2dfbc5b Mon Sep 17 00:00:00 2001
From: Steven Rostedt <srostedt@redhat.com>
Date: Tue, 30 Sep 2008 17:01:54 -0400
Subject: [PATCH] With the added boost of SCHED_OTHER, the balancing load starts to stain
 latencies. Bring it back down again.

NOTE: This is a workaround, we need to fix this because this work around
will once again hurt SCHED_OTHER performance.

Signed-off-by: Steven Rostedt <srostedt@redhat.com>
---
 kernel/sched.c |    4 ++++
 1 files changed, 4 insertions(+), 0 deletions(-)

diff --git a/kernel/sched.c b/kernel/sched.c
index 71fe0bd..fd53d23 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -867,7 +867,11 @@ late_initcall(sched_init_debug);
  * Number of tasks to iterate in a single balance run.
  * Limited because this is done with IRQs disabled.
  */
+#ifdef CONFIG_PREEMPT_RT
+const_debug unsigned int sysctl_sched_nr_migrate = 8;
+#else
 const_debug unsigned int sysctl_sched_nr_migrate = 32;
+#endif
 
 /*
  * ratelimit for updating the group shares.
-- 
1.6.0.90.g436ed

