ipi: call and data to raw lock.

preempt-realtime-x86_64.patch used to bump the call_lock up to a
raw lock, however 3b16cf8 removed the lock;  implicit in the change,
is that call_function_lock (kernel/smp.c) is now in charge of keeping
things sane.  For sanity to remain, we also need to bump up the call
lock, queue lock and the data lock to a raw lock.  (see also b7d7a2404).

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
---
 kernel/smp.c |    6 +++---
 1 files changed, 3 insertions(+), 3 deletions(-)

diff --git a/kernel/smp.c b/kernel/smp.c
index f362a85..4d988a5 100644
--- a/kernel/smp.c
+++ b/kernel/smp.c
@@ -13,7 +13,7 @@
 
 static DEFINE_PER_CPU(struct call_single_queue, call_single_queue);
 static LIST_HEAD(call_function_queue);
-__cacheline_aligned_in_smp DEFINE_SPINLOCK(call_function_lock);
+__cacheline_aligned_in_smp DEFINE_RAW_SPINLOCK(call_function_lock);
 
 enum {
 	CSD_FLAG_WAIT		= 0x01,
@@ -22,7 +22,7 @@ enum {
 
 struct call_function_data {
 	struct call_single_data csd;
-	spinlock_t lock;
+	raw_spinlock_t lock;
 	unsigned int refs;
 	cpumask_t cpumask;
 	struct rcu_head rcu_head;
@@ -30,7 +30,7 @@ struct call_function_data {
 
 struct call_single_queue {
 	struct list_head list;
-	spinlock_t lock;
+	raw_spinlock_t lock;
 };
 
 static int __cpuinit init_call_single_data(void)
