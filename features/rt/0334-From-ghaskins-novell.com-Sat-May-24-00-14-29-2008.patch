From c9c3f05aaf9ad24207792025958c23fd35678fb8 Mon Sep 17 00:00:00 2001
From: Gregory Haskins <ghaskins@novell.com>
Date: Fri, 5 Sep 2008 00:23:55 -0400
Subject: [PATCH] From ghaskins@novell.com Sat May 24 00:14:29 2008
 Date: Tue, 20 May 2008 10:49:36 -0400
 To: mingo@elte.hu, tglx@linutronix.de, rostedt@goodmis.org,
      linux-rt-users@vger.kernel.org
 Cc: linux-kernel@vger.kernel.org, sdietrich@novell.com, pmorreale@novell.com,
      mkohari@novell.com, ghaskins@novell.com
 Subject: [PATCH 5/5] remove the extra call to try_to_take_lock
     [ The following text is in the "utf-8" character set. ]
     [ Your display is set for the "iso-8859-1" character set.  ]
     [ Some characters may be displayed incorrectly. ]

Remove the redundant attempt to get the lock.  While it is true that the
exit path with this patch adds an un-necessary xchg (in the event the
lock is granted without further traversal in the loop) experimentation
shows that we almost never encounter this situation.

Signed-off-by: Peter W. Morreale <pmorreale@novell.com>
Signed-off-by: Gregory Haskins <ghaskins@novell.com>
---
 kernel/rtmutex.c |    6 ------
 1 files changed, 0 insertions(+), 6 deletions(-)

diff --git a/kernel/rtmutex.c b/kernel/rtmutex.c
index c98a2de..f2fc4e7 100644
--- a/kernel/rtmutex.c
+++ b/kernel/rtmutex.c
@@ -843,12 +843,6 @@ rt_spin_lock_slowlock(struct rt_mutex *lock)
 	spin_lock_irqsave(&lock->wait_lock, flags);
 	init_lists(lock);
 
-	/* Try to acquire the lock again: */
-	if (do_try_to_take_rt_mutex(lock, STEAL_LATERAL)) {
-		spin_unlock_irqrestore(&lock->wait_lock, flags);
-		return;
-	}
-
 	BUG_ON(rt_mutex_owner(lock) == current);
 
 	/*
-- 
1.6.0.90.g436ed

