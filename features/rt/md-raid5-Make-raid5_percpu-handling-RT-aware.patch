From 049c62eaa31a515a4fe5cee8a4932b889026529c Mon Sep 17 00:00:00 2001
From: Thomas Gleixner <tglx@linutronix.de>
Date: Tue, 6 Apr 2010 16:51:31 +0200
Subject: [PATCH] md: raid5: Make raid5_percpu handling RT aware

__raid_run_ops() disables preemption with get_cpu() around the access
to the raid5_percpu variables. That causes scheduling while atomic
spews on RT.

Serialize the access to the percpu data with a lock and keep the code
preemptible.

Reported-by: Udo van den Heuvel <udovdh@xs4all.nl>
Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
Tested-by: Udo van den Heuvel <udovdh@xs4all.nl>
[PG: refresh for post 3.4.80 stable additions.]
Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/drivers/md/raid5.c b/drivers/md/raid5.c
index 17b918d3d6b3..cc82518a3d3e 100644
--- a/drivers/md/raid5.c
+++ b/drivers/md/raid5.c
@@ -1321,8 +1321,9 @@ static void __raid_run_ops(struct stripe_head *sh, unsigned long ops_request)
 	struct raid5_percpu *percpu;
 	unsigned long cpu;
 
-	cpu = get_cpu();
+	cpu = get_cpu_light();
 	percpu = per_cpu_ptr(conf->percpu, cpu);
+	spin_lock(&percpu->lock);
 	if (test_bit(STRIPE_OP_BIOFILL, &ops_request)) {
 		ops_run_biofill(sh);
 		overlap_clear++;
@@ -1374,7 +1375,8 @@ static void __raid_run_ops(struct stripe_head *sh, unsigned long ops_request)
 			if (test_and_clear_bit(R5_Overlap, &dev->flags))
 				wake_up(&sh->raid_conf->wait_for_overlap);
 		}
-	put_cpu();
+	spin_unlock(&percpu->lock);
+	put_cpu_light();
 }
 
 #ifdef CONFIG_MULTICORE_RAID456
@@ -4766,6 +4768,7 @@ static int raid5_alloc_percpu(struct r5conf *conf)
 	if (!conf->percpu)
 		return -ENOMEM;
 
+	spin_lock_init(&per_cpu_ptr(conf->percpu, cpu)->lock);
 #ifdef CONFIG_HOTPLUG_CPU
 	conf->cpu_notify.notifier_call = raid456_cpu_notify;
 	conf->cpu_notify.priority = 0;
diff --git a/drivers/md/raid5.h b/drivers/md/raid5.h
index f1ed18e54db4..cf44cfcf089e 100644
--- a/drivers/md/raid5.h
+++ b/drivers/md/raid5.h
@@ -418,6 +418,7 @@ struct r5conf {
 	int			recovery_disabled;
 	/* per cpu variables */
 	struct raid5_percpu {
+		spinlock_t	lock;	     /* Protection for -RT */
 		struct page	*spare_page; /* Used when checking P/Q in raid6 */
 		void		*scribble;   /* space for constructing buffer
 					      * lists and performing address
-- 
1.8.5.2

