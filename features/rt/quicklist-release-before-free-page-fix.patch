---
 include/linux/quicklist.h |   18 ++++++++----------
 mm/quicklist.c            |    8 ++------
 2 files changed, 10 insertions(+), 16 deletions(-)

diff --git a/include/linux/quicklist.h b/include/linux/quicklist.h
index 2b5707a..1bc3d46 100644
--- a/include/linux/quicklist.h
+++ b/include/linux/quicklist.h
@@ -30,13 +30,10 @@ DECLARE_PER_CPU_LOCKED(struct quicklist, quicklist)[CONFIG_NR_QUICK];
  * The fast patch in quicklist_alloc touched only a per cpu cacheline and
  * the first cacheline of the page itself. There is minmal overhead involved.
  */
-static inline void *__quicklist_alloc(int cpu, int nr, gfp_t flags, void (*ctor)(void *))
+static inline void *__quicklist_alloc(struct quicklist *q)
 {
-	struct quicklist *q;
-	void **p = NULL;
+	void **p = q->page;
 
-	q = &__get_cpu_var_locked(quicklist, cpu)[nr];
-	p = q->page;
 	if (likely(p)) {
 		q->page = p[0];
 		p[0] = NULL;
@@ -48,11 +45,11 @@ static inline void *__quicklist_alloc(int cpu, int nr, gfp_t flags, void (*ctor)
 static inline void *quicklist_alloc(int nr, gfp_t flags, void (*ctor)(void *))
 {
 	struct quicklist *q;
-	void **p = NULL;
+	void **p;
 	int cpu;
 
-	(void)get_cpu_var_locked(quicklist, &cpu)[nr];
-	p = __quicklist_alloc(cpu, nr, flags, ctor);
+	q = &get_cpu_var_locked(quicklist, &cpu)[nr];
+	p = __quicklist_alloc(q);
 	put_cpu_var_locked(quicklist, cpu);
 	if (likely(p))
 		return p;
@@ -67,12 +64,13 @@ static inline void __quicklist_free(int nr, void (*dtor)(void *), void *p,
 	struct page *page)
 {
 	struct quicklist *q;
+	int cpu;
 
-	q = &get_cpu_var(quicklist)[nr];
+	q = &get_cpu_var_locked(quicklist, &cpu)[nr];
 	*(void **)p = q->page;
 	q->page = p;
 	q->nr_pages++;
-	put_cpu_var(quicklist);
+	put_cpu_var_locked(quicklist, cpu);
 }
 
 static inline void quicklist_free(int nr, void (*dtor)(void *), void *pp)
diff --git a/mm/quicklist.c b/mm/quicklist.c
index b275f6e..e965be7 100644
--- a/mm/quicklist.c
+++ b/mm/quicklist.c
@@ -73,11 +73,7 @@ void quicklist_trim(int nr, void (*dtor)(void *),
 		pages_to_free = min_pages_to_free(q, min_pages, max_free);
 
 		while (pages_to_free > 0) {
-			/*
-			 * We pass a gfp_t of 0 to quicklist_alloc here
-			 * because we will never call into the page allocator.
-			 */
-			void *p = __quicklist_alloc(cpu, nr, 0, NULL);
+			void *p = __quicklist_alloc(q);
 
 			if (dtor)
 				dtor(p);
@@ -95,7 +91,7 @@ unsigned long quicklist_total_size(void)
 	struct quicklist *ql, *q;
 
 	for_each_online_cpu(cpu) {
-		ql = per_cpu(quicklist, cpu);
+		ql = per_cpu_var_locked(quicklist, cpu);
 		for (q = ql; q < ql + CONFIG_NR_QUICK; q++)
 			count += q->nr_pages;
 	}
