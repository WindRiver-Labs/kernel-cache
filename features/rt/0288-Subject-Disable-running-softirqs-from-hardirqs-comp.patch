From 1f2c55ffd7ee327f0740bfa3af7ea5e0bde4b34c Mon Sep 17 00:00:00 2001
From: Steven Rostedt <srostedt@redhat.com>
Date: Tue, 30 Sep 2008 17:01:06 -0400
Subject: [PATCH] Subject: Disable running softirqs from hardirqs completely!
 There's too many problems with running softirqs from the hardirq context.
 Softirqs are not allowed to migrate, and hardirqs might.
 Perhaps this will be better when softirqs can migrate.

Signed-off-by: Steven Rostedt <srostedt@redhat.com>
---
 kernel/irq/manage.c |   27 +--------------------------
 kernel/softirq.c    |   21 ---------------------
 2 files changed, 1 insertions(+), 47 deletions(-)

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index bc149f8..4d1ffd1 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -861,28 +861,11 @@ static int do_irqd(void * __desc)
 {
 	struct sched_param param = { 0, };
 	struct irq_desc *desc = __desc;
-	int run_softirq = 1;
 
 #ifdef CONFIG_SMP
 	cpumask_t cpus_allowed;
 
 	cpus_allowed = desc->affinity;
-	/*
-	 * If the irqd is bound to one CPU we let it run softirqs
-	 * that have the same priority as the irqd thread. We do
-	 * not run it if the irqd is bound to more than one CPU
-	 * due to the fact that it can
-	 *  1) migrate to other CPUS while running the softirqd
-	 *  2) if we pin the irqd to a CPU to run the softirqd, then
-	 *     we risk a high priority process from waking up and
-	 *     preempting the irqd. Although the irqd may be able to
-	 *     run on other CPUS due to its irq affinity, it will not
-	 *     be able to since we bound it to a CPU to run softirqs.
-	 *     So a RT hog could starve the irqd from running on
-	 *     other CPUS that it's allowed to run on.
-	 */
-	if (cpus_weight(cpus_allowed) != 1)
-		run_softirq = 0; /* turn it off */
 #endif
 	current->flags |= PF_NOFREEZE | PF_HARDIRQ;
 
@@ -898,8 +881,6 @@ static int do_irqd(void * __desc)
 		do {
 			set_current_state(TASK_INTERRUPTIBLE);
 			do_hardirq(desc);
-			if (run_softirq)
-				do_softirq_from_hardirq();
 		} while (current->state == TASK_RUNNING);
 
 		local_irq_enable_nort();
@@ -907,14 +888,8 @@ static int do_irqd(void * __desc)
 		/*
 		 * Did IRQ affinities change?
 		 */
-		if (!cpus_equal(cpus_allowed, desc->affinity)) {
+		if (!cpus_equal(cpus_allowed, desc->affinity))
 			cpus_allowed = desc->affinity;
-			/*
-			 * Only allow the irq thread to run the softirqs
-			 * if it is bound to a single CPU.
-			 */
-			run_softirq = (cpus_weight(cpus_allowed) == 1);
-		}
 #endif
 		schedule();
 	}
diff --git a/kernel/softirq.c b/kernel/softirq.c
index 307713c..9f07acc 100644
--- a/kernel/softirq.c
+++ b/kernel/softirq.c
@@ -105,27 +105,6 @@ static void wakeup_softirqd(int softirq)
 
 	if (unlikely(!tsk))
 		return;
-#if defined(CONFIG_PREEMPT_SOFTIRQS) && defined(CONFIG_PREEMPT_HARDIRQS)
-	/*
-	 * Optimization: if we are in a hardirq thread context, and
-	 * if the priority of the softirq thread is the same as the
-	 * priority of the hardirq thread, then 'merge' softirq
-	 * processing into the hardirq context. (it will later on
-	 * execute softirqs via do_softirq_from_hardirq()).
-	 * So here we can skip the wakeup and can rely on the hardirq
-	 * context processing it later on.
-	 */
-	if ((current->flags & PF_HARDIRQ) && !hardirq_count() &&
-			(tsk->normal_prio == current->normal_prio) &&
-	    /*
-	     * The hard irq thread must be bound to a single CPU to run
-	     * a softirq. Don't worry about locking, the irq thread
-	     * should be the only one to modify the cpus_allowed, when
-	     * the irq affinity changes.
-	     */
-	    (cpus_weight(current->cpus_allowed) == 1))
-		return;
-#endif
 	/*
 	 * Wake up the softirq task:
 	 */
-- 
1.6.0.90.g436ed

