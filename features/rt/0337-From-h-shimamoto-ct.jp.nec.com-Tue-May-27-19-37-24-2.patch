From 826ba4b627a6a7133f1e80eff4ebc9957e080e7d Mon Sep 17 00:00:00 2001
From: Hiroshi Shimamoto <h-shimamoto@ct.jp.nec.com>
Date: Fri, 3 Oct 2008 11:49:32 -0400
Subject: [PATCH] From h-shimamoto@ct.jp.nec.com Tue May 27 19:37:24 2008
 Date: Tue, 27 May 2008 15:45:00 -0700
 To: Steven Rostedt <rostedt@goodmis.org>, Ingo Molnar <mingo@elte.hu>,
      Thomas Gleixner <tglx@linutronix.de>
 Cc: linux-kernel@vger.kernel.org, linux-rt-users@vger.kernel.org
 Subject: [PATCH -rt] fix sysrq+l when nmi_watchdog disabled
 In nmi_show_all_regs(), set nmi_show_regs for all cpus but NMI never come
 to itself when nmi_watchdog is disabled. It means the kernel hangs up when
 sysrq+l is issued.

Call irq_show_regs_callback() itself before calling smp_send_nmi_allbutself().

Signed-off-by: Hiroshi Shimamoto <h-shimamoto@ct.jp.nec.com>
---
 arch/x86/kernel/nmi.c |   55 +++++++++++++++++++++++++++++++-----------------
 1 files changed, 35 insertions(+), 20 deletions(-)

diff --git a/arch/x86/kernel/nmi.c b/arch/x86/kernel/nmi.c
index 69a7dfd..6a36980 100644
--- a/arch/x86/kernel/nmi.c
+++ b/arch/x86/kernel/nmi.c
@@ -385,21 +385,53 @@ EXPORT_SYMBOL(touch_nmi_watchdog);
 
 int nmi_show_regs[NR_CPUS];
 
+static DEFINE_RAW_SPINLOCK(nmi_print_lock);
+
+notrace int irq_show_regs_callback(int cpu, struct pt_regs *regs)
+{
+	if (!nmi_show_regs[cpu])
+		return 0;
+
+	spin_lock(&nmi_print_lock);
+	printk(KERN_WARNING "NMI show regs on CPU#%d:\n", cpu);
+	printk(KERN_WARNING "apic_timer_irqs: %d\n",
+#ifdef CONFIG_X86_64
+		read_pda(apic_timer_irqs));
+#else
+		per_cpu(irq_stat, cpu).apic_timer_irqs);
+#endif
+	show_regs(regs);
+	spin_unlock(&nmi_print_lock);
+	nmi_show_regs[cpu] = 0;
+	return 1;
+}
+
 void nmi_show_all_regs(void)
 {
-	int i;
+	struct pt_regs *regs;
+	int i, cpu;
 
 	if (system_state == SYSTEM_BOOTING)
 		return;
 
-	printk(KERN_WARNING "nmi_show_all_regs(): start on CPU#%d.\n",
-		raw_smp_processor_id());
+	preempt_disable();
+
+	regs = get_irq_regs();
+	cpu = smp_processor_id();
+
+	printk(KERN_WARNING "nmi_show_all_regs(): start on CPU#%d.\n", cpu);
 	dump_stack();
 
 	for_each_online_cpu(i)
 		nmi_show_regs[i] = 1;
 
+	if (regs)
+		irq_show_regs_callback(cpu, regs);
+	else
+		nmi_show_regs[cpu] = 0;
+
 	smp_send_nmi_allbutself();
+	preempt_enable();
 
 	for_each_online_cpu(i) {
 		while (nmi_show_regs[i] == 1)
@@ -407,23 +439,6 @@ void nmi_show_all_regs(void)
 	}
 }
 
-static DEFINE_RAW_SPINLOCK(nmi_print_lock);
-
-notrace int irq_show_regs_callback(int cpu, struct pt_regs *regs)
-{
-	if (!nmi_show_regs[cpu])
-		return 0;
-
-	spin_lock(&nmi_print_lock);
-	printk(KERN_WARNING "NMI show regs on CPU#%d:\n", cpu);
-	printk(KERN_WARNING "apic_timer_irqs: %d\n",
-		per_cpu(irq_stat, cpu).apic_timer_irqs);
-	show_regs(regs);
-	spin_unlock(&nmi_print_lock);
-	nmi_show_regs[cpu] = 0;
-	return 1;
-}
-
 notrace __kprobes int
 nmi_watchdog_tick(struct pt_regs *regs, unsigned reason)
 {
-- 
1.6.0.90.g436ed

