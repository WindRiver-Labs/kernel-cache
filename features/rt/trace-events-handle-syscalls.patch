Add syscall tracing in event trace.

Signed-off-by: Steven Rostedt <srostedt@redhat.com>
---
 kernel/trace/trace.c          |  104 +++++++++++++++++++++++++++++++++++++++++
 kernel/trace/trace.h          |   30 ++++++++++++
 kernel/trace/trace_events.c   |   92 ++++++++++++++++++++++++++++++++++++
 kernel/trace/trace_selftest.c |    2 +
 4 files changed, 228 insertions(+), 0 deletions(-)

diff --git a/kernel/trace/trace.c b/kernel/trace/trace.c
index 0dcef22..adb6bad 100644
--- a/kernel/trace/trace.c
+++ b/kernel/trace/trace.c
@@ -32,6 +32,9 @@
 
 #include <linux/stacktrace.h>
 
+#include <asm/asm-offsets.h>
+#include <asm/unistd.h>
+
 #include "trace.h"
 
 unsigned long __read_mostly	tracing_max_latency = (cycle_t)ULONG_MAX;
@@ -1141,6 +1144,42 @@ void tracing_event_task_deactivate(struct trace_array *tr,
 	entry->task.cpu		= task_cpu;
 }
 
+void tracing_event_syscall(struct trace_array *tr,
+			   struct trace_array_cpu *data,
+			   unsigned long flags,
+			   unsigned long ip,
+			   unsigned long nr,
+			   unsigned long p1,
+			   unsigned long p2,
+			   unsigned long p3)
+{
+	struct trace_entry *entry;
+
+	entry = tracing_get_trace_entry(tr, data);
+	tracing_generic_entry_update(entry, flags);
+	entry->type			= TRACE_SYSCALL;
+	entry->syscall.ip		= ip;
+	entry->syscall.nr		= nr;
+	entry->syscall.p1		= p1;
+	entry->syscall.p2		= p2;
+	entry->syscall.p3		= p3;
+}
+
+void tracing_event_sysret(struct trace_array *tr,
+			  struct trace_array_cpu *data,
+			  unsigned long flags,
+			  unsigned long ip,
+			  unsigned long ret)
+{
+	struct trace_entry *entry;
+
+	entry = tracing_get_trace_entry(tr, data);
+	tracing_generic_entry_update(entry, flags);
+	entry->type			= TRACE_SYSRET;
+	entry->sysret.ip		= ip;
+	entry->sysret.ret		= ret;
+}
+
 #ifdef CONFIG_FTRACE
 static void
 function_trace_call(unsigned long ip, unsigned long parent_ip)
@@ -1462,6 +1501,13 @@ seq_print_ip_sym(struct trace_seq *s, unsigned long ip, unsigned long sym_flags)
 	return ret;
 }
 
+extern unsigned long sys_call_table[NR_syscalls];
+
+#if defined(CONFIG_COMPAT) && defined(CONFIG_X86)
+extern unsigned long ia32_sys_call_table[], ia32_syscall_end[];
+# define IA32_NR_syscalls (ia32_syscall_end - ia32_sys_call_table)
+#endif
+
 static void print_lat_help_header(struct seq_file *m)
 {
 	seq_puts(m, "#                _------=> CPU#            \n");
@@ -1615,6 +1661,7 @@ print_lat_fmt(struct trace_iterator *iter, unsigned int trace_idx, int cpu)
 	struct trace_entry *entry = iter->ent;
 	unsigned long abs_usecs;
 	unsigned long rel_usecs;
+	unsigned long nr;
 	char *comm;
 	int S, T;
 	int i;
@@ -1729,6 +1776,34 @@ print_lat_fmt(struct trace_iterator *iter, unsigned int trace_idx, int cpu)
 			   comm, entry->task.pid,
 			   entry->task.prio, entry->task.cpu);
 		break;
+	case TRACE_SYSCALL:
+		seq_print_ip_sym(s, entry->syscall.ip, sym_flags);
+		nr = entry->syscall.nr;
+		trace_seq_putc(s, ' ');
+#if defined(CONFIG_COMPAT) && defined(CONFIG_X86)
+		if (nr & 0x80000000) {
+			nr &= ~0x80000000;
+			if (nr < IA32_NR_syscalls)
+				seq_print_ip_sym(s, ia32_sys_call_table[nr], 0);
+			else
+				trace_seq_printf(s, "<badsys(%lu)>", nr);
+		} else
+#endif
+			if (nr < NR_syscalls)
+				seq_print_ip_sym(s, sys_call_table[nr], 0);
+			else
+				trace_seq_printf(s, "<badsys(%lu)>", nr);
+
+		trace_seq_printf(s, " (%lx %lx %lx)\n",
+			   entry->syscall.p1,
+			   entry->syscall.p2,
+			   entry->syscall.p3);
+		break;
+	case TRACE_SYSRET:
+		seq_print_ip_sym(s, entry->sysret.ip, sym_flags);
+		trace_seq_printf(s, " < (%ld)\n",
+			   entry->sysret.ret);
+		break;
 	default:
 		trace_seq_printf(s, "Unknown type %d\n", entry->type);
 	}
@@ -1743,6 +1818,7 @@ static int print_trace_fmt(struct trace_iterator *iter)
 	unsigned long usec_rem;
 	unsigned long long t;
 	unsigned long secs;
+	long nr;
 	char *comm;
 	int ret;
 	int S, T;
@@ -1878,6 +1954,34 @@ static int print_trace_fmt(struct trace_iterator *iter)
 			   comm, entry->task.pid,
 			   entry->task.prio, entry->task.cpu);
 		break;
+	case TRACE_SYSCALL:
+		seq_print_ip_sym(s, entry->syscall.ip, sym_flags);
+		nr = entry->syscall.nr;
+		trace_seq_putc(s, ' ');
+#if defined(CONFIG_COMPAT) && defined(CONFIG_X86)
+		if (nr & 0x80000000) {
+			nr &= ~0x80000000;
+			if (nr < IA32_NR_syscalls)
+				seq_print_ip_sym(s, ia32_sys_call_table[nr], 0);
+			else
+				trace_seq_printf(s, "<badsys(%lu)>", nr);
+		} else
+#endif
+			if (nr < NR_syscalls)
+				seq_print_ip_sym(s, sys_call_table[nr], 0);
+			else
+				trace_seq_printf(s, "<badsys(%lu)>", nr);
+
+		trace_seq_printf(s, " (%lx %lx %lx)\n",
+			   entry->syscall.p1,
+			   entry->syscall.p2,
+			   entry->syscall.p3);
+		break;
+	case TRACE_SYSRET:
+		seq_print_ip_sym(s, entry->sysret.ip, sym_flags);
+		trace_seq_printf(s, "< (%ld)\n",
+			   entry->sysret.ret);
+		break;
 	}
 	return 1;
 }
diff --git a/kernel/trace/trace.h b/kernel/trace/trace.h
index 3f3660b..337372f 100644
--- a/kernel/trace/trace.h
+++ b/kernel/trace/trace.h
@@ -24,6 +24,8 @@ enum trace_type {
 	TRACE_TIMESTAMP,
 	TRACE_TASK_ACT,
 	TRACE_TASK_DEACT,
+	TRACE_SYSCALL,
+	TRACE_SYSRET,
 
 	__TRACE_LAST_TYPE
 };
@@ -96,6 +98,19 @@ struct wakeup_entry {
 	unsigned		curr_prio;
 };
 
+struct syscall_entry {
+	unsigned long		ip;
+	unsigned long		nr;
+	unsigned long		p1;
+	unsigned long		p2;
+	unsigned long		p3;
+};
+
+struct sysret_entry {
+	unsigned long		ip;
+	unsigned long		ret;
+};
+
 /*
  * Stack-trace entry:
  */
@@ -132,6 +147,8 @@ struct trace_entry {
 		struct timestamp_entry		timestamp;
 		struct task_entry		task;
 		struct wakeup_entry		wakeup;
+		struct syscall_entry		syscall;
+		struct sysret_entry		sysret;
 	};
 };
 
@@ -320,6 +337,19 @@ void tracing_event_wakeup(struct trace_array *tr,
 			  unsigned long ip,
 			  pid_t pid, int prio,
 			  int curr_prio);
+void tracing_event_syscall(struct trace_array *tr,
+			   struct trace_array_cpu *data,
+			   unsigned long flags,
+			   unsigned long ip,
+			   unsigned long nr,
+			   unsigned long p1,
+			   unsigned long p2,
+			   unsigned long p3);
+void tracing_event_sysret(struct trace_array *tr,
+			  struct trace_array_cpu *data,
+			  unsigned long flags,
+			  unsigned long ip,
+			  unsigned long ret);
 
 void tracing_start_cmdline_record(void);
 void tracing_stop_cmdline_record(void);
diff --git a/kernel/trace/trace_events.c b/kernel/trace/trace_events.c
index 55801c2..149d2a6 100644
--- a/kernel/trace/trace_events.c
+++ b/kernel/trace/trace_events.c
@@ -36,6 +36,98 @@ static void event_reset(struct trace_array *tr)
 	tr->time_start = ftrace_now(raw_smp_processor_id());
 }
 
+/* HACK */
+void notrace
+sys_call(unsigned long nr, unsigned long p1, unsigned long p2, unsigned long p3)
+{
+	struct trace_array *tr;
+	struct trace_array_cpu *data;
+	unsigned long flags;
+	unsigned long ip;
+	int cpu;
+
+	if (!tracer_enabled)
+		return;
+
+	tr = events_trace;
+	local_irq_save(flags);
+	cpu = raw_smp_processor_id();
+	data = tr->data[cpu];
+
+	atomic_inc(&data->disabled);
+	if (atomic_read(&data->disabled) != 1)
+		goto out;
+
+	ip = CALLER_ADDR0;
+
+	tracing_event_syscall(tr, data, flags, ip, nr, p1, p2, p3);
+
+ out:
+	atomic_dec(&data->disabled);
+	local_irq_restore(flags);
+}
+
+#if defined(CONFIG_COMPAT) && defined(CONFIG_X86)
+void notrace
+sys_ia32_call(unsigned long nr, unsigned long p1, unsigned long p2,
+	      unsigned long p3)
+{
+	struct trace_array *tr;
+	struct trace_array_cpu *data;
+	unsigned long flags;
+	unsigned long ip;
+	int cpu;
+
+	if (!tracer_enabled)
+		return;
+
+	tr = events_trace;
+	local_irq_save(flags);
+	cpu = raw_smp_processor_id();
+	data = tr->data[cpu];
+
+	atomic_inc(&data->disabled);
+	if (atomic_read(&data->disabled) != 1)
+		goto out;
+
+	ip = CALLER_ADDR0;
+	tracing_event_syscall(tr, data, flags, ip, nr | 0x80000000, p1, p2, p3);
+
+ out:
+	atomic_dec(&data->disabled);
+	local_irq_restore(flags);
+}
+#endif
+
+void notrace
+sys_ret(unsigned long ret)
+{
+	struct trace_array *tr;
+	struct trace_array_cpu *data;
+	unsigned long flags;
+	unsigned long ip;
+	int cpu;
+
+	if (!tracer_enabled)
+		return;
+
+	tr = events_trace;
+	local_irq_save(flags);
+	cpu = raw_smp_processor_id();
+	data = tr->data[cpu];
+
+	atomic_inc(&data->disabled);
+	if (atomic_read(&data->disabled) != 1)
+		goto out;
+
+	ip = CALLER_ADDR0;
+	tracing_event_sysret(tr, data, flags, ip, ret);
+
+ out:
+	atomic_dec(&data->disabled);
+	local_irq_restore(flags);
+}
+
 static void
 event_irq_callback(int irq, int user, unsigned long ip)
 {
diff --git a/kernel/trace/trace_selftest.c b/kernel/trace/trace_selftest.c
index bcdc35d..88c13d0 100644
--- a/kernel/trace/trace_selftest.c
+++ b/kernel/trace/trace_selftest.c
@@ -18,6 +18,8 @@ static inline int trace_valid_entry(struct trace_entry *entry)
 	case TRACE_TIMESTAMP:
 	case TRACE_TASK_ACT:
 	case TRACE_TASK_DEACT:
+	case TRACE_SYSCALL:
+	case TRACE_SYSRET:
 		return 1;
 	}
 	return 0;
