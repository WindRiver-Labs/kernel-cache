ipi call: raw lock.

preempt-realtime-x86_64.patch used to bump the call_lock up to a
raw lock, however 3b16cf8 removed the lock;  implicit in the change,
is that call_function_lock (kernel/smp.c) is now in charge of keeping
things sane.  For sanity to remain, we also need to bump up this
one to a raw lock.  (see also b7d7a2404).
diff --git a/kernel/smp.c b/kernel/smp.c
index f362a85..09f6bc7 100644
--- a/kernel/smp.c
+++ b/kernel/smp.c
@@ -13,7 +13,7 @@
 
 static DEFINE_PER_CPU(struct call_single_queue, call_single_queue);
 static LIST_HEAD(call_function_queue);
-__cacheline_aligned_in_smp DEFINE_SPINLOCK(call_function_lock);
+__cacheline_aligned_in_smp DEFINE_RAW_SPINLOCK(call_function_lock);
 
 enum {
 	CSD_FLAG_WAIT		= 0x01,
