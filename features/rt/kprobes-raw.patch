From: Paul Gortmaker <paul.gortmaker@windriver.com>
Subject: kprobes: upgrade to raw lock

The RT patch named "preempt-realtime-rawlocks.patch" used to up
the kretprobe_lock to raw, but since it has since been renamed
and shuffled around, that lock is now covered by the locks in this
patch.

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
---
 include/linux/kprobes.h |    2 +-
 kernel/kprobes.c        |   10 +++++-----
 2 files changed, 6 insertions(+), 6 deletions(-)

diff --git a/include/linux/kprobes.h b/include/linux/kprobes.h
index 0be7795..9e263b6 100644
--- a/include/linux/kprobes.h
+++ b/include/linux/kprobes.h
@@ -157,7 +157,7 @@ struct kretprobe {
 	int nmissed;
 	size_t data_size;
 	struct hlist_head free_instances;
-	spinlock_t lock;
+	raw_spinlock_t lock;
 };
 
 struct kretprobe_instance {
diff --git a/kernel/kprobes.c b/kernel/kprobes.c
index 3d91b89..d7e6604 100644
--- a/kernel/kprobes.c
+++ b/kernel/kprobes.c
@@ -75,7 +75,7 @@ static struct {
 	raw_spinlock_t lock ____cacheline_aligned;
 } kretprobe_table_locks[KPROBE_TABLE_SIZE];
 
-static spinlock_t *kretprobe_table_lock_ptr(unsigned long hash)
+static raw_spinlock_t *kretprobe_table_lock_ptr(unsigned long hash)
 {
 	return &(kretprobe_table_locks[hash].lock);
 }
@@ -397,7 +397,7 @@ void kretprobe_hash_lock(struct task_struct *tsk,
 			 struct hlist_head **head, unsigned long *flags)
 {
 	unsigned long hash = hash_ptr(tsk, KPROBE_HASH_BITS);
-	spinlock_t *hlist_lock;
+	raw_spinlock_t *hlist_lock;
 
 	*head = &kretprobe_inst_table[hash];
 	hlist_lock = kretprobe_table_lock_ptr(hash);
@@ -406,14 +406,14 @@ void kretprobe_hash_lock(struct task_struct *tsk,
 
 void kretprobe_table_lock(unsigned long hash, unsigned long *flags)
 {
-	spinlock_t *hlist_lock = kretprobe_table_lock_ptr(hash);
+	raw_spinlock_t *hlist_lock = kretprobe_table_lock_ptr(hash);
 	spin_lock_irqsave(hlist_lock, *flags);
 }
 
 void kretprobe_hash_unlock(struct task_struct *tsk, unsigned long *flags)
 {
 	unsigned long hash = hash_ptr(tsk, KPROBE_HASH_BITS);
-	spinlock_t *hlist_lock;
+	raw_spinlock_t *hlist_lock;
 
 	hlist_lock = kretprobe_table_lock_ptr(hash);
 	spin_unlock_irqrestore(hlist_lock, *flags);
@@ -421,7 +421,7 @@ void kretprobe_hash_unlock(struct task_struct *tsk, unsigned long *flags)
 
 void kretprobe_table_unlock(unsigned long hash, unsigned long *flags)
 {
-	spinlock_t *hlist_lock = kretprobe_table_lock_ptr(hash);
+	raw_spinlock_t *hlist_lock = kretprobe_table_lock_ptr(hash);
 	spin_unlock_irqrestore(hlist_lock, *flags);
 }
 
-- 
1.6.5.rc1

