---
 include/linux/preempt.h |   18 +++++++++++++++---
 include/linux/smp.h     |    2 +-
 init/main.c             |    2 +-
 kernel/sched.c          |   24 ++++++++++++++++++++++--
 kernel/softirq.c        |    6 +++---
 5 files changed, 42 insertions(+), 10 deletions(-)

diff --git a/include/linux/preempt.h b/include/linux/preempt.h
index 36cc97a..109bea2 100644
--- a/include/linux/preempt.h
+++ b/include/linux/preempt.h
@@ -9,6 +9,7 @@
 #include <linux/thread_info.h>
 #include <linux/linkage.h>
 #include <linux/list.h>
+#include <linux/thread_info.h>
 
 #if defined(CONFIG_DEBUG_PREEMPT) || defined(CONFIG_PREEMPT_TRACER) || \
 	defined(CONFIG_PREEMPT_TRACE)
@@ -22,11 +23,12 @@
 #define inc_preempt_count() add_preempt_count(1)
 #define dec_preempt_count() sub_preempt_count(1)
 
-#define preempt_count()	(current_thread_info()->preempt_count)
+#define preempt_count()		(current_thread_info()->preempt_count)
 
 #ifdef CONFIG_PREEMPT
 
 asmlinkage void preempt_schedule(void);
+asmlinkage void preempt_schedule_irq(void);
 
 #define preempt_disable() \
 do { \
@@ -34,12 +36,19 @@ do { \
 	barrier(); \
 } while (0)
 
-#define preempt_enable_no_resched() \
+#define __preempt_enable_no_resched() \
 do { \
 	barrier(); \
 	dec_preempt_count(); \
 } while (0)
 
+
+#ifdef CONFIG_DEBUG_PREEMPT
+extern void notrace preempt_enable_no_resched(void);
+#else
+# define preempt_enable_no_resched() __preempt_enable_no_resched()
+#endif
+
 #define preempt_check_resched() \
 do { \
 	if (unlikely(test_thread_flag(TIF_NEED_RESCHED))) \
@@ -48,7 +57,7 @@ do { \
 
 #define preempt_enable() \
 do { \
-	preempt_enable_no_resched(); \
+	__preempt_enable_no_resched(); \
 	barrier(); \
 	preempt_check_resched(); \
 } while (0)
@@ -85,6 +94,7 @@ do { \
 
 #define preempt_disable()		do { } while (0)
 #define preempt_enable_no_resched()	do { } while (0)
+#define __preempt_enable_no_resched()	do { } while (0)
 #define preempt_enable()		do { } while (0)
 #define preempt_check_resched()		do { } while (0)
 
@@ -92,6 +102,8 @@ do { \
 #define preempt_enable_no_resched_notrace()	do { } while (0)
 #define preempt_enable_notrace()		do { } while (0)
 
+#define preempt_schedule_irq()		do { } while (0)
+
 #endif
 
 #ifdef CONFIG_PREEMPT_NOTIFIERS
diff --git a/include/linux/smp.h b/include/linux/smp.h
index 66484d4..6ca0d03 100644
--- a/include/linux/smp.h
+++ b/include/linux/smp.h
@@ -164,7 +164,7 @@ static inline void init_call_single_data(void)
 
 #define get_cpu()		({ preempt_disable(); smp_processor_id(); })
 #define put_cpu()		preempt_enable()
-#define put_cpu_no_resched()	preempt_enable_no_resched()
+#define put_cpu_no_resched()	__preempt_enable_no_resched()
 
 void smp_setup_processor_id(void);
 
diff --git a/init/main.c b/init/main.c
index 64b267c..7046af6 100644
--- a/init/main.c
+++ b/init/main.c
@@ -474,7 +474,7 @@ static void noinline __init_refok rest_init(void)
 	 * at least once to get things moving:
 	 */
 	init_idle_bootup_task(current);
-	preempt_enable_no_resched();
+	__preempt_enable_no_resched();
 	schedule();
 	preempt_disable();
 
diff --git a/kernel/sched.c b/kernel/sched.c
index 8b0cbce..71c895d 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -2437,6 +2437,26 @@ void wake_up_new_task(struct task_struct *p, unsigned long clone_flags)
 
 #ifdef CONFIG_PREEMPT_NOTIFIERS
 
+#ifdef CONFIG_DEBUG_PREEMPT
+void notrace preempt_enable_no_resched(void)
+{
+	static int once = 1;
+
+	barrier();
+	dec_preempt_count();
+
+	if (once && !preempt_count()) {
+		once = 0;
+		printk(KERN_ERR "BUG: %s:%d task might have lost a preemption check!\n",
+			current->comm, current->pid);
+		dump_stack();
+	}
+}
+
+EXPORT_SYMBOL(preempt_enable_no_resched);
+#endif
+
+
 /**
  * preempt_notifier_register - tell me when current is being being preempted & rescheduled
  * @notifier: notifier struct to register
@@ -4504,7 +4524,7 @@ need_resched_nonpreemptible:
 	if (unlikely(reacquire_kernel_lock(current) < 0))
 		goto need_resched_nonpreemptible;
 
-	preempt_enable_no_resched();
+	__preempt_enable_no_resched();
 	if (unlikely(test_thread_flag(TIF_NEED_RESCHED)))
 		goto need_resched;
 }
@@ -8331,7 +8351,7 @@ void __init sched_init(void)
 	scheduler_running = 1;
 }
 
-#ifdef CONFIG_DEBUG_SPINLOCK_SLEEP
+#if defined(CONFIG_DEBUG_SPINLOCK_SLEEP) || defined(CONFIG_DEBUG_PREEMPT)
 void __might_sleep(char *file, int line)
 {
 #ifdef in_atomic
diff --git a/kernel/softirq.c b/kernel/softirq.c
index a624971..517b356 100644
--- a/kernel/softirq.c
+++ b/kernel/softirq.c
@@ -359,7 +359,7 @@ void irq_exit(void)
 		tick_nohz_stop_sched_tick(0);
 	rcu_irq_exit();
 #endif
-	preempt_enable_no_resched();
+	__preempt_enable_no_resched();
 }
 
 /*
@@ -558,7 +558,7 @@ static int ksoftirqd(void * __data)
 	while (!kthread_should_stop()) {
 		preempt_disable();
 		if (!(local_softirq_pending() & mask)) {
-			preempt_enable_no_resched();
+			__preempt_enable_no_resched();
 			schedule();
 			preempt_disable();
 		}
@@ -577,7 +577,7 @@ static int ksoftirqd(void * __data)
 				goto wait_to_die;
 
 			local_irq_disable();
-			preempt_enable_no_resched();
+			__preempt_enable_no_resched();
 			set_softirq_pending(local_softirq_pending() & ~mask);
 			local_bh_disable();
 			local_irq_enable();
