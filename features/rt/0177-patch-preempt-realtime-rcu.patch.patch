From b0f711cd031a4e11bb2bca4ec652d47b4462064d Mon Sep 17 00:00:00 2001
From: Paul Gortmaker <paul.gortmaker@windriver.com>
Date: Tue, 30 Sep 2008 16:58:34 -0400
Subject: [PATCH] patch preempt-realtime-rcu.patch

---
 include/linux/rcuclassic.h |    2 +-
 kernel/rcuclassic.c        |    4 ++--
 kernel/rcupreempt-boost.c  |    4 ++--
 kernel/rcupreempt.c        |    6 +++---
 4 files changed, 8 insertions(+), 8 deletions(-)

diff --git a/include/linux/rcuclassic.h b/include/linux/rcuclassic.h
index fd9497d..dc891de 100644
--- a/include/linux/rcuclassic.h
+++ b/include/linux/rcuclassic.h
@@ -49,7 +49,7 @@ struct rcu_ctrlblk {
 
 	int	signaled;
 
-	spinlock_t	lock	____cacheline_internodealigned_in_smp;
+	raw_spinlock_t	lock	____cacheline_internodealigned_in_smp;
 	cpumask_t	cpumask; /* CPUs that need to switch in order    */
 				 /* for current batch to proceed.        */
 } ____cacheline_internodealigned_in_smp;
diff --git a/kernel/rcuclassic.c b/kernel/rcuclassic.c
index 94787a4..7ce4601 100644
--- a/kernel/rcuclassic.c
+++ b/kernel/rcuclassic.c
@@ -60,13 +60,13 @@ EXPORT_SYMBOL_GPL(rcu_lock_map);
 static struct rcu_ctrlblk rcu_ctrlblk = {
 	.cur = -300,
 	.completed = -300,
-	.lock = __SPIN_LOCK_UNLOCKED(&rcu_ctrlblk.lock),
+	.lock = RAW_SPIN_LOCK_UNLOCKED(&rcu_ctrlblk.lock),
 	.cpumask = CPU_MASK_NONE,
 };
 static struct rcu_ctrlblk rcu_bh_ctrlblk = {
 	.cur = -300,
 	.completed = -300,
-	.lock = __SPIN_LOCK_UNLOCKED(&rcu_bh_ctrlblk.lock),
+	.lock = RAW_SPIN_LOCK_UNLOCKED(&rcu_bh_ctrlblk.lock),
 	.cpumask = CPU_MASK_NONE,
 };
 
diff --git a/kernel/rcupreempt-boost.c b/kernel/rcupreempt-boost.c
index a13206e..5282b19 100644
--- a/kernel/rcupreempt-boost.c
+++ b/kernel/rcupreempt-boost.c
@@ -30,13 +30,13 @@
 #include <linux/syscalls.h>
 #include <linux/kthread.h>
 
-DEFINE_SPINLOCK(rcu_boost_wake_lock);
+DEFINE_RAW_SPINLOCK(rcu_boost_wake_lock);
 static int rcu_boost_prio = MAX_PRIO;	/* Prio to set preempted RCU readers */
 static long rcu_boost_counter;		/* used to keep track of who boosted */
 static int rcu_preempt_thread_secs = 3;	/* Seconds between waking rcupreemptd thread */
 
 struct rcu_boost_dat {
-	spinlock_t rbs_lock;		/* Sync changes to this struct */
+	raw_spinlock_t rbs_lock;	/* Sync changes to this struct */
 	int rbs_prio;			/* CPU copy of rcu_boost_prio  */
 	struct list_head rbs_toboost;	/* Preempted RCU readers       */
 	struct list_head rbs_boosted;	/* RCU readers that have been boosted */
diff --git a/kernel/rcupreempt.c b/kernel/rcupreempt.c
index 3794a1f..9b0da60 100644
--- a/kernel/rcupreempt.c
+++ b/kernel/rcupreempt.c
@@ -79,7 +79,7 @@
  */
 #define GP_STAGES    2
 struct rcu_data {
-	spinlock_t	lock;		/* Protect rcu_data fields. */
+	raw_spinlock_t	lock;		/* Protect rcu_data fields. */
 	long		completed;	/* Number of last completed batch. */
 	int		waitlistcount;
 	struct rcu_head *nextlist;
@@ -146,7 +146,7 @@ enum rcu_sched_sleep_states {
 };
 
 struct rcu_ctrlblk {
-	spinlock_t	fliplock;	/* Protect state-machine transitions. */
+	raw_spinlock_t	fliplock;	/* Protect state-machine transitions. */
 	long		completed;	/* Number of last completed batch. */
 	enum rcu_try_flip_states rcu_try_flip_state; /* The current state of
 							the rcu state machine */
@@ -157,7 +157,7 @@ struct rcu_ctrlblk {
 
 static DEFINE_PER_CPU(struct rcu_data, rcu_data);
 static struct rcu_ctrlblk rcu_ctrlblk = {
-	.fliplock = __SPIN_LOCK_UNLOCKED(rcu_ctrlblk.fliplock),
+	.fliplock = RAW_SPIN_LOCK_UNLOCKED(rcu_ctrlblk.fliplock),
 	.completed = 0,
 	.rcu_try_flip_state = rcu_try_flip_idle_state,
 	.schedlock = __SPIN_LOCK_UNLOCKED(rcu_ctrlblk.schedlock),
-- 
1.6.0.90.g436ed

