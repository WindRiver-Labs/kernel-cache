From ad0559be932f0f5f5dd922a8a4219147040f9ca9 Mon Sep 17 00:00:00 2001
From: Jason HU <yongqi.hu@windriver.com>
Date: Tue, 1 Jun 2010 03:32:47 -0700
Subject: [PATCH] lttng: PMEM enhancement for lttng

PMEM enhancement for lttng was added to kernel which offers the option
of storing the lttng trace to persistent memory and can corporate with
the user space tools to recover the last events after system crash or
reboot.

Signed-off-by: Jason HU <yongqi.hu@windriver.com>
---
 include/linux/ltt-relay.h  |   28 ++++++++
 include/linux/ltt-tracer.h |    8 +++
 ltt/Kconfig                |   10 +++
 ltt/ltt-relay-alloc.c      |  150 +++++++++++++++++++++++++++++++++++++++++++-
 ltt/ltt-relay-lockless.c   |   56 ++++++++++++++++-
 ltt/ltt-relay-lockless.h   |   51 +++++++++++++++-
 ltt/ltt-relay-splice.c     |   12 ++++
 ltt/ltt-tracer.c           |  107 +++++++++++++++++++++++++++++++
 8 files changed, 418 insertions(+), 4 deletions(-)

diff --git a/include/linux/ltt-relay.h b/include/linux/ltt-relay.h
index 4ec2bb5..07e7a5d 100644
--- a/include/linux/ltt-relay.h
+++ b/include/linux/ltt-relay.h
@@ -22,6 +22,12 @@
 #include <linux/mm.h>
 #include <linux/ltt-core.h>
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+#include <linux/pmem.h>
+extern struct part_handle ltt_part_handle;
+#define LTT_PMEM_PART_NAME "ltt"
+#endif /* CONFIG_LTT_PMEM_SUPPORT */
+
 /* Use lowest pointer bit to show the sub-buffer has no reference. */
 #define RCHAN_NOREF_FLAG	0x1UL
 
@@ -53,6 +59,9 @@ struct ltt_chanbuf_alloc {
 	struct ltt_chan_alloc *chan;	/* Associated channel */
 	unsigned int cpu;		/* This buffer's cpu */
 	unsigned int allocated:1;	/* Bool: is buffer allocated ? */
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	void *start;
+#endif
 };
 
 /*
@@ -74,11 +83,30 @@ struct ltt_chan_alloc {
 	struct dentry *ascii_dentry;	/* Text output dentry */
 	struct ltt_trace *trace;	/* Associated trace */
 	char filename[NAME_MAX];	/* Filename for channel files */
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	int use_pmem;                   /* persistent memory channel ? */
+	pmem_handle_t pmem_h;           /* handle to pmem region */
+	char *tmp_name;                 /* ugh, CAREFUL! volatile memory,
+					 * avoids passing extra parameter,
+					 * used only during initialization,
+					 * single-threaded */
+#endif
 };
 
 int ltt_chanbuf_alloc_create(struct ltt_chanbuf_alloc *buf,
 			     struct ltt_chan_alloc *chan, int cpu);
 void ltt_chanbuf_alloc_free(struct ltt_chanbuf_alloc *buf);
+
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+enum relay_mem_type {RELAY_MEM_TYPE_KERNEL_HEAP, RELAY_MEM_TYPE_PMEM};
+int ltt_chan_alloc_init_mem(struct ltt_chan_alloc *chan,
+		struct ltt_trace *trace,
+		const char *base_filename,
+		struct dentry *parent, size_t sb_size,
+		size_t n_sb, int extra_reader_sb, int overwrite,
+		enum relay_mem_type mem_type);
+#endif
+
 int ltt_chan_alloc_init(struct ltt_chan_alloc *chan, struct ltt_trace *trace,
 			const char *base_filename,
 			struct dentry *parent, size_t sb_size,
diff --git a/include/linux/ltt-tracer.h b/include/linux/ltt-tracer.h
index aa4a108..c8b567a 100644
--- a/include/linux/ltt-tracer.h
+++ b/include/linux/ltt-tracer.h
@@ -25,6 +25,10 @@
 #include <asm/atomic.h>
 #include <asm/local.h>
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+#include <linux/pmem.h>
+#endif /* CONFIG_LTT_PMEM_SUPPORT */
+
 /* Number of bytes to log with a read/write event */
 #define LTT_LOG_RW_SIZE			32L
 
@@ -214,6 +218,10 @@ struct ltt_trace {
 	struct kref ltt_transport_kref;
 	wait_queue_head_t kref_wq; /* Place for ltt_trace_destroy to sleep */
 	char trace_name[NAME_MAX];
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	int use_pmem;   /* data stored in persistent memory ? */
+	pmem_handle_t pmem_h;   /* partition handle */
+#endif
 } ____cacheline_aligned;
 
 /* Hardcoded event headers
diff --git a/ltt/Kconfig b/ltt/Kconfig
index f81f4ec..e2fade7 100644
--- a/ltt/Kconfig
+++ b/ltt/Kconfig
@@ -85,6 +85,16 @@ choice
 
 endchoice
 
+config LTT_PMEM_SUPPORT
+	bool "Support for persistent memory (PMEM) in relay channels"
+	depends on LTT_RELAY_LOCKLESS
+	depends on PMEM
+	default y
+	help
+	  Allows storing of the data in the relay channels in persistent memory
+	  (PMEM) instead of the default location (RAM). This allows a user to
+	  recover the data after a kernel crash or reboot.
+
 config LTT_SERIALIZE
 	tristate "Linux Trace Toolkit Serializer"
 	depends on LTT_TRACER
diff --git a/ltt/ltt-relay-alloc.c b/ltt/ltt-relay-alloc.c
index 5d4bb83..cf03fc8 100644
--- a/ltt/ltt-relay-alloc.c
+++ b/ltt/ltt-relay-alloc.c
@@ -148,6 +148,45 @@ int ltt_chanbuf_alloc_create(struct ltt_chanbuf_alloc *buf,
 {
 	int ret = 0;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	buf->start = NULL;
+	if (chan->use_pmem) {
+		struct pmem_reg_region region;
+		pmem_handle_t part_h = (pmem_handle_t)&ltt_part_handle;
+		if (strlen(chan->tmp_name) >= PMEM_DESC_MAX) {
+			ret = -EINVAL;
+			goto end;
+		}
+
+		strncpy(region.desc, chan->tmp_name, PMEM_DESC_MAX - 1);
+		region.desc[PMEM_DESC_MAX - 1] = 0;
+		/* allocate  page aligned mem */
+		/* now pmem assures this */
+		region.size = chan->buf_size = PAGE_ALIGN(chan->buf_size);
+		region.flags = 0;
+		region.fixed_size = 0;
+		region.num_log_desc = 0;
+		region.version = 1;
+		region.block_id = PMEM_ACTIVE_BLOCK;
+
+		ret = pmem_partition_get(LTT_PMEM_PART_NAME, &part_h);
+		if (ret < 0) {
+			printk(KERN_ERR "failed to obtain LTT PMEM part\n");
+			goto end;
+		}
+
+		ret = pmem_region_reg(part_h, &region, &chan->pmem_h);
+		if (ret < 0) {
+			printk(KERN_ERR "failed region %s creation\n",
+					region.desc);
+			goto end;
+		}
+		buf->start = pmem_get_data_ptr(chan->pmem_h);
+		pmem_memset(buf->start, 0, chan->buf_size);
+	}
+	/* we have to  allocate pages for splice actor usage. */
+#endif
+
 	ret = ltt_chanbuf_allocate(buf, chan->buf_size, chan->n_sb,
 				   chan->extra_reader_sb);
 	if (ret)
@@ -165,6 +204,16 @@ void ltt_chanbuf_alloc_free(struct ltt_chanbuf_alloc *buf)
 	struct page **pages;
 	long i;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	/* do nothing for pmem*/
+	if (chan->use_pmem) {
+		buf->start = NULL;
+	}
+	/* We have to  allocate  pages for splice,
+	   so free them here.
+	*/
+#endif
+
 	/* Destroy index */
 	if (chan->extra_reader_sb) {
 		RCHAN_SB_CLEAR_NOREF(buf->buf_rsb.pages);
@@ -274,10 +323,26 @@ void ltt_chan_for_each_channel(void (*cb) (struct ltt_chanbuf *buf), int cpu)
  * base_filename_0...base_filename_N-1.  File permissions will
  * be %S_IRUSR.
  */
-int ltt_chan_alloc_init(struct ltt_chan_alloc *chan, struct ltt_trace *trace,
+/**
+ * For ltt pmem support only:
+ * relay_open_mem variant - allows using pmem instead of kernel heap
+ * for storage
+ *	@mem_type: RELAY_MEM_TYPE_KERNEL_HEAP or RELAY_MEM_TYPE_PMEM
+ */
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+int ltt_chan_alloc_init_mem(struct ltt_chan_alloc *chan,
+			struct ltt_trace *trace,
+			const char *base_filename,
+			struct dentry *parent, size_t sb_size,
+			size_t n_sb, int extra_reader_sb, int overwrite,
+			enum relay_mem_type mem_type)
+#else
+int ltt_chan_alloc_init(struct ltt_chan_alloc *chan,
+			struct ltt_trace *trace,
 			const char *base_filename,
 			struct dentry *parent, size_t sb_size,
 			size_t n_sb, int extra_reader_sb, int overwrite)
+#endif
 {
 	unsigned int i;
 	int ret;
@@ -306,6 +371,9 @@ int ltt_chan_alloc_init(struct ltt_chan_alloc *chan, struct ltt_trace *trace,
 	chan->n_sb = n_sb;
 	chan->parent = parent;
 	strlcpy(chan->filename, base_filename, NAME_MAX);
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	chan->use_pmem = mem_type == RELAY_MEM_TYPE_PMEM ? 1 : 0;
+#endif
 	kref_init(&chan->kref);
 	kref_get(&chan->trace->kref);
 
@@ -337,6 +405,21 @@ free_chan:
 	return -ENOMEM;
 }
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+EXPORT_SYMBOL_GPL(ltt_chan_alloc_init_mem);
+
+int ltt_chan_alloc_init(struct ltt_chan_alloc *chan, struct ltt_trace *trace,
+			const char *base_filename,
+			struct dentry *parent, size_t sb_size,
+			size_t n_sb, int extra_reader_sb, int overwrite)
+{
+	return ltt_chan_alloc_init_mem(chan, trace, base_filename,
+				parent, sb_size,
+				n_sb, extra_reader_sb, overwrite,
+				RELAY_MEM_TYPE_KERNEL_HEAP);
+}
+#endif
+
 /**
  * ltt_chan_alloc_remove_files - remove channel files.
  * @chan: the channel
@@ -403,7 +486,34 @@ void _ltt_relay_write(struct ltt_chanbuf_alloc *bufa, size_t offset,
 	struct ltt_chan_alloc *chana = bufa->chan;
 	size_t sbidx, index;
 	struct chanbuf_page *rpages;
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (bufa->chan->use_pmem) {
+		__pmem_memcpy_toio(bufa->start + offset + pagecpy,
+			 src + pagecpy, len - pagecpy);
+		PMEM_FLUSH_CACHE(bufa->start + offset, len);
+		wmb();
+	} else {
+	do {
+		len -= pagecpy;
+		src += pagecpy;
+		offset += pagecpy;
+		sbidx = offset >> chana->sb_size_order;
+		index = (offset & (chana->sb_size - 1)) >> PAGE_SHIFT;
+
+		/*
+		 * Underlying layer should never ask for writes across
+		 * subbuffers.
+		 */
+		WARN_ON(offset >= chana->buf_size);
 
+		pagecpy = min_t(size_t, len, PAGE_SIZE - (offset & ~PAGE_MASK));
+		rpages = bufa->buf_wsb[sbidx].pages;
+		WARN_ON_ONCE(RCHAN_SB_IS_NOREF(rpages));
+		ltt_relay_do_copy(rpages[index].virt + (offset & ~PAGE_MASK),
+				  src, pagecpy);
+	} while (unlikely(len != pagecpy));
+	}
+#else
 	do {
 		len -= pagecpy;
 		src += pagecpy;
@@ -423,6 +533,7 @@ void _ltt_relay_write(struct ltt_chanbuf_alloc *bufa, size_t offset,
 		ltt_relay_do_copy(rpages[index].virt + (offset & ~PAGE_MASK),
 				  src, pagecpy);
 	} while (unlikely(len != pagecpy));
+#endif
 }
 EXPORT_SYMBOL_GPL(_ltt_relay_write);
 
@@ -448,6 +559,10 @@ int ltt_relay_read(struct ltt_chanbuf_alloc *bufa, size_t offset, void *dest,
 	index = (offset & (chana->sb_size - 1)) >> PAGE_SHIFT;
 	if (unlikely(!len))
 		return 0;
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (chana->use_pmem) {
+		__pmem_memcpy_fromio(dest, bufa->start+offset, len);
+	} else {
 	for (;;) {
 		pagecpy = min_t(size_t, len, PAGE_SIZE - (offset & ~PAGE_MASK));
 		rpages = bufa->buf_rsb.pages;
@@ -466,6 +581,27 @@ int ltt_relay_read(struct ltt_chanbuf_alloc *bufa, size_t offset, void *dest,
 		 */
 		WARN_ON(offset >= chana->buf_size);
 	}
+	}
+#else
+	for (;;) {
+		pagecpy = min_t(size_t, len, PAGE_SIZE - (offset & ~PAGE_MASK));
+		rpages = bufa->buf_rsb.pages;
+		WARN_ON_ONCE(RCHAN_SB_IS_NOREF(rpages));
+		memcpy(dest, rpages[index].virt + (offset & ~PAGE_MASK),
+		       pagecpy);
+		len -= pagecpy;
+		if (likely(!len))
+			break;
+		dest += pagecpy;
+		offset += pagecpy;
+		index = (offset & (chana->sb_size - 1)) >> PAGE_SHIFT;
+		/*
+		 * Underlying layer should never ask for reads across
+		 * subbuffers.
+		 */
+		WARN_ON(offset >= chana->buf_size);
+	}
+#endif
 	return orig_len;
 }
 EXPORT_SYMBOL_GPL(ltt_relay_read);
@@ -562,6 +698,12 @@ void *ltt_relay_read_offset_address(struct ltt_chanbuf_alloc *bufa,
 	struct ltt_chan_alloc *chana = bufa->chan;
 
 	offset &= chana->buf_size - 1;
+
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (bufa->chan->use_pmem)
+		return bufa->start + offset;
+#endif
+
 	index = (offset & (chana->sb_size - 1)) >> PAGE_SHIFT;
 	rpages = bufa->buf_rsb.pages;
 	WARN_ON_ONCE(RCHAN_SB_IS_NOREF(rpages));
@@ -586,6 +728,12 @@ void *ltt_relay_offset_address(struct ltt_chanbuf_alloc *bufa, size_t offset)
 	struct ltt_chan_alloc *chana = bufa->chan;
 
 	offset &= chana->buf_size - 1;
+
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (bufa->chan->use_pmem)
+		return bufa->start + offset;
+#endif
+
 	sbidx = offset >> chana->sb_size_order;
 	index = (offset & (chana->sb_size - 1)) >> PAGE_SHIFT;
 	rpages = bufa->buf_wsb[sbidx].pages;
diff --git a/ltt/ltt-relay-lockless.c b/ltt/ltt-relay-lockless.c
index a9b7efd..8119157 100644
--- a/ltt/ltt-relay-lockless.c
+++ b/ltt/ltt-relay-lockless.c
@@ -54,6 +54,9 @@
 #include <asm/atomic.h>
 #include <asm/local.h>
 #include <linux/notifier.h>
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+#include <linux/hardirq.h>
+#endif
 
 #include "ltt-relay-lockless.h"
 
@@ -81,14 +84,32 @@ static
 void ltt_buffer_begin(struct ltt_chanbuf *buf, u64 tsc, unsigned int subbuf_idx)
 {
 	struct ltt_chan *chan = container_of(buf->a.chan, struct ltt_chan, a);
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	struct ltt_subbuffer_header tmpheader;
+#endif
 	struct ltt_subbuffer_header *header =
 		(struct ltt_subbuffer_header *)
 			ltt_relay_offset_address(&buf->a,
 				subbuf_idx * chan->a.sb_size);
-
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (chan->a.use_pmem) {
+		memset(&tmpheader, 0, sizeof(tmpheader));
+		tmpheader.cycle_count_begin = tsc;
+		tmpheader.data_size = 0xFFFFFFFF; /* for debugging */
+		ltt_write_trace_header(chan->a.trace, &tmpheader);
+		__pmem_memcpy_toio(header, &tmpheader, sizeof(tmpheader));
+		PMEM_FLUSH_CACHE(header, sizeof(tmpheader));
+		smp_wmb();
+	} else {
+		header->cycle_count_begin = tsc;
+		header->data_size = 0xFFFFFFFF; /* for debugging */
+		ltt_write_trace_header(chan->a.trace, header);
+	}
+#else
 	header->cycle_count_begin = tsc;
 	header->data_size = 0xFFFFFFFF; /* for debugging */
 	ltt_write_trace_header(chan->a.trace, header);
+#endif
 }
 
 /*
@@ -100,17 +121,40 @@ void ltt_buffer_end(struct ltt_chanbuf *buf, u64 tsc, unsigned int offset,
 		    unsigned int subbuf_idx)
 {
 	struct ltt_chan *chan = container_of(buf->a.chan, struct ltt_chan, a);
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	struct ltt_subbuffer_header tmpheader;
+#endif
 	struct ltt_subbuffer_header *header =
 		(struct ltt_subbuffer_header *)
 			ltt_relay_offset_address(&buf->a,
 				subbuf_idx * chan->a.sb_size);
 	u32 data_size = SUBBUF_OFFSET(offset - 1, chan) + 1;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (chan->a.use_pmem) {
+		memset(&tmpheader, 0, sizeof(tmpheader));
+		tmpheader.cycle_count_begin = tsc;
+		tmpheader.sb_size = PAGE_ALIGN(data_size);
+		tmpheader.data_size = data_size;
+		tmpheader.events_lost = local_read(&buf->events_lost);
+		ltt_write_trace_header(chan->a.trace, &tmpheader);
+		__pmem_memcpy_toio(header, &tmpheader, sizeof(tmpheader));
+		PMEM_FLUSH_CACHE(header, sizeof(tmpheader));
+		smp_wmb();
+	} else {
+		header->data_size = data_size;
+		header->sb_size = PAGE_ALIGN(data_size);
+		header->cycle_count_end = tsc;
+		header->events_lost = local_read(&buf->events_lost);
+		header->subbuf_corrupt = local_read(&buf->corrupted_subbuffers);
+	}
+#else
 	header->data_size = data_size;
 	header->sb_size = PAGE_ALIGN(data_size);
 	header->cycle_count_end = tsc;
 	header->events_lost = local_read(&buf->events_lost);
 	header->subbuf_corrupt = local_read(&buf->corrupted_subbuffers);
+#endif
 }
 
 /*
@@ -246,8 +290,16 @@ int ltt_chan_create(const char *base_filename,
 
 	chan->overwrite = overwrite;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	ret = ltt_chan_alloc_init_mem(&chan->a, trace, base_filename, parent,
+			sb_size, n_sb, overwrite, overwrite,
+			trace->use_pmem ?
+				 RELAY_MEM_TYPE_PMEM :
+				 RELAY_MEM_TYPE_KERNEL_HEAP);
+#else
 	ret = ltt_chan_alloc_init(&chan->a, trace, base_filename, parent,
-				  sb_size, n_sb, overwrite, overwrite);
+			sb_size, n_sb, overwrite, overwrite);
+#endif
 	if (ret)
 		goto error;
 
diff --git a/ltt/ltt-relay-lockless.h b/ltt/ltt-relay-lockless.h
index 9f17357..325da81 100644
--- a/ltt/ltt-relay-lockless.h
+++ b/ltt/ltt-relay-lockless.h
@@ -387,6 +387,19 @@ int ltt_reserve_slot(struct ltt_chan *chan,
 	long o_begin, o_end, o_old;
 	size_t before_hdr_pad;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+#ifndef CONFIG_LTT_DEBUG_EVENT_SIZE
+	/* We need the event size to recover the record from the pmem.
+	   If there is not such information, we can not parse the events.
+	   Another way is fall back to event schema.
+	*/
+	if (buf->chan->use_pmem &&
+		!(*rflags &  (LTT_RFLAG_ID_SIZE_TSC  | LTT_RFLAG_ID_SIZE))) {
+		*rflags = LTT_RFLAG_ID_SIZE;
+	}
+#endif
+#endif
+
 	/*
 	 * Perform retryable operations.
 	 */
@@ -470,11 +483,47 @@ void ltt_write_commit_counter(struct ltt_chanbuf *buf, struct ltt_chan *chan,
 	 */
 	if (unlikely(SUBBUF_OFFSET(offset - commit_count, chan)))
 		return;
-
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (!chan->a.use_pmem)
+#endif
 	commit_seq_old = local_read(&buf->commit_seq[idx]);
+
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (chan->a.use_pmem) {
+		for (;;) {
+			unsigned long flags;
+			preempt_disable_notrace();
+			raw_local_irq_save(flags);
+			__pmem_memcpy_fromio(&commit_seq_old,
+				&buf->commit_seq[idx],
+				sizeof(commit_seq_old));
+			smp_rmb();
+			if (commit_seq_old == 0xFFFFFFFF ||
+				commit_seq_old < commit_count) {
+				__pmem_memcpy_toio(
+					&buf->commit_seq[idx],
+					&commit_seq_old,
+					sizeof(commit_seq_old));
+					PMEM_FLUSH_CACHE(&buf->commit_seq[idx],
+					sizeof(lost_new));
+				smp_wmb();
+			}
+
+			raw_local_irq_restore(flags);
+			preempt_enable_notrace();
+			if (commit_seq_old == 0xFFFFFFFF ||
+				commit_seq_old <= commit_count)
+				break;
+		}
+	} else
+		while (commit_seq_old < commit_count)
+			commit_seq_old = local_cmpxchg(&buf->commit_seq[idx],
+				commit_seq_old, commit_count);
+#else
 	while (commit_seq_old < commit_count)
 		commit_seq_old = local_cmpxchg(&buf->commit_seq[idx],
 					 commit_seq_old, commit_count);
+#endif
 }
 #else
 static __inline__
diff --git a/ltt/ltt-relay-splice.c b/ltt/ltt-relay-splice.c
index aa72820..d93efd2 100644
--- a/ltt/ltt-relay-splice.c
+++ b/ltt/ltt-relay-splice.c
@@ -106,6 +106,18 @@ static int subbuf_splice_actor(struct file *in,
 
 		this_len = PAGE_SIZE - poff;
 		page = ltt_relay_read_get_page(&buf->a, roffset);
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+		if (chan->a.use_pmem) {
+			/* we have to allocate pages and do page copy  for
+			   splice since  pmem mostly should  be in io memory
+			*/
+			__pmem_memcpy_fromio(page_address(page) + poff,
+				buf->a.start + BUFFER_OFFSET(roffset, chan)
+				+ poff,
+				this_len);
+			smp_rmb();
+		}
+#endif
 		spd.pages[spd.nr_pages] = page;
 		spd.partial[spd.nr_pages].offset = poff;
 		spd.partial[spd.nr_pages].len = this_len;
diff --git a/ltt/ltt-tracer.c b/ltt/ltt-tracer.c
index 972289a..c0614e9 100644
--- a/ltt/ltt-tracer.c
+++ b/ltt/ltt-tracer.c
@@ -41,6 +41,11 @@
 #include <linux/vmalloc.h>
 #include <asm/atomic.h>
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+#include <linux/pmem.h>
+struct part_handle ltt_part_handle;
+#endif
+
 static void synchronize_trace(void)
 {
 	synchronize_sched();
@@ -613,6 +618,34 @@ static void _ltt_trace_free(struct ltt_trace *trace)
 	kfree(trace);
 }
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+/* generic routine to try to match a channel name with a transport type */
+static inline int match_transport_type(char *channel_name,
+					char *transport_name)
+{
+	while (*channel_name == *transport_name) {
+		/* this bit provides a match between relay+pmem and relay */
+		if (*(channel_name+1) == '+' && !*(transport_name+1))
+			return 1;
+		if (!*channel_name)
+			return 1;
+		++channel_name;
+		++transport_name;
+	}
+	return 0;
+}
+
+/* find out if a channel is using persistent memory as its storage */
+static inline int use_pmem(char *channel_name)
+{
+	while (*(channel_name++)) {
+		if (*channel_name == '+')
+			return strcmp(channel_name+1, "pmem") == 0;
+	}
+	return 0;
+}
+#endif /* CONFIG_LTT_PMEM_SUPPORT */
+
 int ltt_trace_set_type(const char *trace_name, const char *trace_type)
 {
 	int err = 0;
@@ -629,7 +662,11 @@ int ltt_trace_set_type(const char *trace_name, const char *trace_type)
 	}
 
 	list_for_each_entry(tran_iter, &ltt_transport_list, node) {
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+		if (match_transport_type(trace_type, tran_iter->name)) {
+#else
 		if (!strcmp(tran_iter->name, trace_type)) {
+#endif
 			transport = tran_iter;
 			break;
 		}
@@ -642,6 +679,9 @@ int ltt_trace_set_type(const char *trace_name, const char *trace_type)
 	}
 
 	trace->transport = transport;
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	trace->use_pmem = use_pmem(trace_type);
+#endif
 
 traces_error:
 	ltt_unlock_traces();
@@ -649,6 +689,64 @@ traces_error:
 }
 EXPORT_SYMBOL_GPL(ltt_trace_set_type);
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+static int ltt_trace_pmem_alloc(const char *trace_name,
+		     unsigned int subbuf_size_low, unsigned int n_subbufs_low,
+		     unsigned int subbuf_size_med, unsigned int n_subbufs_med,
+		     unsigned int subbuf_size_high, unsigned int n_subbufs_high)
+{
+	int err = 0;
+	struct ltt_trace *trace;
+	ltt_lock_traces();
+
+	trace = _ltt_trace_find_setup(trace_name);
+	if (!trace) {
+		printk(KERN_ERR "LTT : Trace not found %s\n", trace_name);
+		err = -ENOENT;
+		goto traces_error;
+	}
+
+	#define FIX_SIZE(x) ((((x) - 1) & PAGE_MASK) + PAGE_SIZE)
+	#define PADDING	FIX_SIZE(64*1024) /* should be enough */
+
+	if (trace->use_pmem) {
+		struct pmem_reg_part part;
+
+		if (strlen(LTT_PMEM_PART_NAME) >= PMEM_DESC_MAX) {
+			printk(KERN_ERR"LTT PMEM partition name too long\n");
+			err = -EINVAL;
+			goto traces_error;
+		}
+		strncpy(part.desc, LTT_PMEM_PART_NAME, PMEM_DESC_MAX - 1);
+		part.desc[PMEM_DESC_MAX - 1] = 0;
+		part.num_blocks = 1;
+		part.size = num_possible_cpus()  * (
+			4 * FIX_SIZE(n_subbufs_low * subbuf_size_low) +
+			FIX_SIZE(n_subbufs_med * subbuf_size_med) +
+			FIX_SIZE(n_subbufs_high * subbuf_size_high));
+		part.size *= part.num_blocks;
+		part.size += PADDING;
+		part.version = 1;
+
+		trace->pmem_h = (pmem_handle_t)&ltt_part_handle;
+		err = pmem_partition_reg(&part, &trace->pmem_h);
+		if (err < 0) {
+			printk(KERN_ERR "failed partition %s creation\n",
+				part.desc);
+			goto traces_error;
+		}
+
+	}
+
+	#undef FIX_SIZE
+	#undef PADDING
+
+traces_error:
+	ltt_unlock_traces();
+	return err;
+}
+#endif
+
 int ltt_trace_set_channel_subbufsize(const char *trace_name,
 				     const char *channel_name,
 				     unsigned int size)
@@ -957,6 +1055,15 @@ int ltt_trace_create(const char *trace_name, const char *trace_type,
 	if (IS_ERR_VALUE(err))
 		return err;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	err = ltt_trace_pmem_alloc(trace_name,
+			subbuf_size_low,  n_subbufs_low,
+			subbuf_size_med,  n_subbufs_med,
+			subbuf_size_high, n_subbufs_high);
+	if (IS_ERR_VALUE(err))
+		return err;
+#endif
+
 	err = ltt_trace_alloc(trace_name);
 	if (IS_ERR_VALUE(err))
 		return err;
-- 
1.6.5.2

