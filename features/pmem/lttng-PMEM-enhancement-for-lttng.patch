From 0d380686961345eb5c7f35ef062f19c4e40f9e43 Mon Sep 17 00:00:00 2001
From: Jason HU <yongqi.hu@windriver.com>
Date: Tue, 1 Jun 2010 03:32:47 -0700
Subject: [PATCH] lttng: PMEM enhancement for lttng

PMEM enhancement for lttng was added to kernel which offers the option
of storing the lttng trace to persistent memory and can corporate with
the user space tools to recover the last events after system crash or
reboot.

Signed-off-by: Jason HU <yongqi.hu@windriver.com>
---
 include/linux/ltt-relay.h  |   58 +++++++++++++
 include/linux/ltt-tracer.h |   18 ++++
 ltt/Kconfig                |   10 ++
 ltt/ltt-ascii.c            |   18 ++++
 ltt/ltt-relay-alloc.c      |  204 +++++++++++++++++++++++++++++++++++++++++++-
 ltt/ltt-relay-lockless.c   |   55 ++++++++++++-
 ltt/ltt-relay-lockless.h   |   23 +++++-
 ltt/ltt-relay-splice.c     |   16 ++++
 ltt/ltt-tracer.c           |  167 +++++++++++++++++++++++++++++++++++-
 9 files changed, 563 insertions(+), 6 deletions(-)

diff --git a/include/linux/ltt-relay.h b/include/linux/ltt-relay.h
index 4ec2bb5..bf403bc 100644
--- a/include/linux/ltt-relay.h
+++ b/include/linux/ltt-relay.h
@@ -22,6 +22,12 @@
 #include <linux/mm.h>
 #include <linux/ltt-core.h>
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+#include <linux/pmem.h>
+extern struct part_handle ltt_part_handle;
+#define LTT_PMEM_PART_NAME "ltt"
+#endif /* CONFIG_LTT_PMEM_SUPPORT */
+
 /* Use lowest pointer bit to show the sub-buffer has no reference. */
 #define RCHAN_NOREF_FLAG	0x1UL
 
@@ -53,6 +59,9 @@ struct ltt_chanbuf_alloc {
 	struct ltt_chan_alloc *chan;	/* Associated channel */
 	unsigned int cpu;		/* This buffer's cpu */
 	unsigned int allocated:1;	/* Bool: is buffer allocated ? */
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	void *start;
+#endif
 };
 
 /*
@@ -74,11 +83,26 @@ struct ltt_chan_alloc {
 	struct dentry *ascii_dentry;	/* Text output dentry */
 	struct ltt_trace *trace;	/* Associated trace */
 	char filename[NAME_MAX];	/* Filename for channel files */
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	int use_pmem;                   /* persistent memory channel ? */
+	pmem_handle_t pmem_h;           /* handle to pmem region */
+#endif
 };
 
 int ltt_chanbuf_alloc_create(struct ltt_chanbuf_alloc *buf,
 			     struct ltt_chan_alloc *chan, int cpu);
 void ltt_chanbuf_alloc_free(struct ltt_chanbuf_alloc *buf);
+
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+enum relay_mem_type {RELAY_MEM_TYPE_KERNEL_HEAP, RELAY_MEM_TYPE_PMEM};
+int ltt_chan_alloc_init_mem(struct ltt_chan_alloc *chan,
+		struct ltt_trace *trace,
+		const char *base_filename,
+		struct dentry *parent, size_t sb_size,
+		size_t n_sb, int extra_reader_sb, int overwrite,
+		enum relay_mem_type mem_type);
+#endif
+
 int ltt_chan_alloc_init(struct ltt_chan_alloc *chan, struct ltt_trace *trace,
 			const char *base_filename,
 			struct dentry *parent, size_t sb_size,
@@ -104,6 +128,29 @@ extern int ltt_relay_read_cstr(struct ltt_chanbuf_alloc *bufa,
 extern struct page *ltt_relay_read_get_page(struct ltt_chanbuf_alloc *bufa,
 					    size_t offset);
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+/**
+ * ltt_relay_read_get_page_virt - Get a the page virtual address  to read from
+ * @bufa : buffer
+ * @offset : offset within the buffer
+ *
+ * Should be protected by get_subbuf/put_subbuf.
+ */
+static inline void  *ltt_relay_read_get_page_virt(
+		struct ltt_chanbuf_alloc *bufa,
+		size_t offset)
+{
+	size_t index;
+	struct chanbuf_page *rpages;
+	struct ltt_chan_alloc *chana = bufa->chan;
+
+	offset &= chana->buf_size - 1;
+	index = (offset & (chana->sb_size - 1)) >> PAGE_SHIFT;
+	rpages = bufa->buf_rsb.pages;
+	WARN_ON_ONCE(RCHAN_SB_IS_NOREF(rpages));
+	return rpages[index].virt;
+}
+#endif
 /*
  * Return the address where a given offset is located.
  * Should be used to get the current subbuffer header pointer. Given we know
@@ -212,8 +259,19 @@ int ltt_relay_write(struct ltt_chanbuf_alloc *bufa,
 	pagecpy = min_t(size_t, len, (- offset) & ~PAGE_MASK);
 	rpages = bufa->buf_wsb[sbidx].pages;
 	WARN_ON_ONCE(RCHAN_SB_IS_NOREF(rpages));
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (bufa->chan->use_pmem) {
+		__pmem_memcpy_toio(bufa->start + offset, src, pagecpy);
+		PMEM_FLUSH_CACHE(bufa->start + offset, pagecpy);
+		wmb();
+	} else {
+		ltt_relay_do_copy(rpages[index].virt + (offset & ~PAGE_MASK),
+			  src, pagecpy);
+	}
+#else
 	ltt_relay_do_copy(rpages[index].virt + (offset & ~PAGE_MASK),
 			  src, pagecpy);
+#endif
 
 	if (unlikely(len != pagecpy))
 		_ltt_relay_write(bufa, offset, src, len, pagecpy);
diff --git a/include/linux/ltt-tracer.h b/include/linux/ltt-tracer.h
index aa4a108..b17b161 100644
--- a/include/linux/ltt-tracer.h
+++ b/include/linux/ltt-tracer.h
@@ -25,6 +25,10 @@
 #include <asm/atomic.h>
 #include <asm/local.h>
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+#include <linux/pmem.h>
+#endif /* CONFIG_LTT_PMEM_SUPPORT */
+
 /* Number of bytes to log with a read/write event */
 #define LTT_LOG_RW_SIZE			32L
 
@@ -214,6 +218,11 @@ struct ltt_trace {
 	struct kref ltt_transport_kref;
 	wait_queue_head_t kref_wq; /* Place for ltt_trace_destroy to sleep */
 	char trace_name[NAME_MAX];
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	int use_pmem;   /* data stored in persistent memory ? */
+	pmem_handle_t pmem_h;   /* partition handle */
+	int pmem_part_reged;
+#endif
 } ____cacheline_aligned;
 
 /* Hardcoded event headers
@@ -527,12 +536,21 @@ size_t ltt_read_event_header(struct ltt_chanbuf_alloc *bufa, long buf_offset,
 #define LTT_ASCII			"ascii"
 
 /* Tracer properties */
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+#define LTT_DEFAULT_SUBBUF_SIZE_LOW	16384
+#define LTT_DEFAULT_N_SUBBUFS_LOW	2
+#define LTT_DEFAULT_SUBBUF_SIZE_MED	65536
+#define LTT_DEFAULT_N_SUBBUFS_MED	2
+#define LTT_DEFAULT_SUBBUF_SIZE_HIGH	262144
+#define LTT_DEFAULT_N_SUBBUFS_HIGH	2
+#else
 #define LTT_DEFAULT_SUBBUF_SIZE_LOW	65536
 #define LTT_DEFAULT_N_SUBBUFS_LOW	2
 #define LTT_DEFAULT_SUBBUF_SIZE_MED	262144
 #define LTT_DEFAULT_N_SUBBUFS_MED	2
 #define LTT_DEFAULT_SUBBUF_SIZE_HIGH	1048576
 #define LTT_DEFAULT_N_SUBBUFS_HIGH	2
+#endif
 #define LTT_TRACER_MAGIC_NUMBER		0x00D6B7ED
 #define LTT_TRACER_VERSION_MAJOR	2
 #define LTT_TRACER_VERSION_MINOR	6
diff --git a/ltt/Kconfig b/ltt/Kconfig
index f81f4ec..e2fade7 100644
--- a/ltt/Kconfig
+++ b/ltt/Kconfig
@@ -85,6 +85,16 @@ choice
 
 endchoice
 
+config LTT_PMEM_SUPPORT
+	bool "Support for persistent memory (PMEM) in relay channels"
+	depends on LTT_RELAY_LOCKLESS
+	depends on PMEM
+	default y
+	help
+	  Allows storing of the data in the relay channels in persistent memory
+	  (PMEM) instead of the default location (RAM). This allows a user to
+	  recover the data after a kernel crash or reboot.
+
 config LTT_SERIALIZE
 	tristate "Linux Trace Toolkit Serializer"
 	depends on LTT_TRACER
diff --git a/ltt/ltt-ascii.c b/ltt/ltt-ascii.c
index 76da1cd..af769dd 100644
--- a/ltt/ltt-ascii.c
+++ b/ltt/ltt-ascii.c
@@ -98,6 +98,14 @@ static int is_subbuffer_offset_end(struct ltt_relay_cpu_iter *citer,
 					     struct ltt_chan, a);
 	long sub_offset = SUBBUF_OFFSET(offset - 1, chan) + 1;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	struct ltt_subbuffer_header tmpheader;
+	if (citer->buf->a.chan->use_pmem) {
+		__pmem_memcpy_fromio(citer->header, &tmpheader,
+			sizeof(struct ltt_subbuffer_header));
+		return (sub_offset <= tmpheader.data_size);
+	} else
+#endif
 	return (sub_offset <= citer->header->data_size);
 }
 
@@ -185,11 +193,21 @@ static int subbuffer_start(struct ltt_relay_cpu_iter *citer, long *offset)
 	int ret;
 	struct ltt_relay_iter *iter = citer->iter;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	struct ltt_subbuffer_header tmpheader;
+#endif
 	ret = ltt_chanbuf_get_subbuf(citer->buf, offset);
 	if (!ret) {
 		citer->header = ltt_relay_read_offset_address(&citer->buf->a,
 							      *offset);
 		citer->hdr_offset = (*offset) + ltt_sb_header_size();
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+		if (citer->buf->a.chan->use_pmem) {
+			__pmem_memcpy_fromio(&tmpheader, citer->header,
+				sizeof(struct ltt_subbuffer_header));
+			citer->tsc = tmpheader.cycle_count_begin;
+		} else
+#endif
 		citer->tsc = citer->header->cycle_count_begin;
 		iter->nr_refs++;
 		citer->sb_ref = 1;
diff --git a/ltt/ltt-relay-alloc.c b/ltt/ltt-relay-alloc.c
index 5d4bb83..7a38b69 100644
--- a/ltt/ltt-relay-alloc.c
+++ b/ltt/ltt-relay-alloc.c
@@ -148,6 +148,57 @@ int ltt_chanbuf_alloc_create(struct ltt_chanbuf_alloc *buf,
 {
 	int ret = 0;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	struct ltt_chan *chan_parent = container_of(chan, struct ltt_chan, a);
+	char *tmpname = NULL;
+	tmpname = kzalloc(NAME_MAX + 1, GFP_KERNEL);
+	if (!tmpname) {
+		ret = -ENOMEM;
+		goto end;
+	}
+
+	snprintf(tmpname, NAME_MAX, "%s%s_%d",
+		 chan_parent->overwrite ? LTT_FLIGHT_PREFIX : "",
+		 chan->filename, cpu);
+
+	buf->start = NULL;
+	if (chan->use_pmem) {
+		struct pmem_reg_region region;
+		pmem_handle_t part_h = (pmem_handle_t)&ltt_part_handle;
+		if (strlen(tmpname) >= PMEM_DESC_MAX) {
+			ret = -EINVAL;
+			goto end;
+		}
+
+		strncpy(region.desc, tmpname, PMEM_DESC_MAX - 1);
+		region.desc[PMEM_DESC_MAX - 1] = 0;
+		/* allocate  page aligned mem */
+		/* now pmem assures this */
+		region.size = chan->buf_size = PAGE_ALIGN(chan->buf_size);
+		region.flags = 0;
+		region.fixed_size = 0;
+		region.num_log_desc = 0;
+		region.version = 1;
+		region.block_id = PMEM_ACTIVE_BLOCK;
+
+		ret = pmem_partition_get(LTT_PMEM_PART_NAME, &part_h);
+		if (ret < 0) {
+			printk(KERN_ERR "failed to obtain LTT PMEM part\n");
+			goto end;
+		}
+
+		ret = pmem_region_reg(part_h, &region, &chan->pmem_h);
+		if (ret < 0) {
+			printk(KERN_ERR "failed region %s creation\n",
+					region.desc);
+			goto end;
+		}
+		buf->start = pmem_get_data_ptr(chan->pmem_h);
+		pmem_memset(buf->start, 0, chan->buf_size);
+	}
+	/* we have to allocate pages for splice actor usage. */
+#endif
+
 	ret = ltt_chanbuf_allocate(buf, chan->buf_size, chan->n_sb,
 				   chan->extra_reader_sb);
 	if (ret)
@@ -155,7 +206,11 @@ int ltt_chanbuf_alloc_create(struct ltt_chanbuf_alloc *buf,
 
 	buf->chan = chan;
 	buf->cpu = cpu;
+
 end:
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	kfree(tmpname);
+#endif
 	return ret;
 }
 
@@ -165,6 +220,14 @@ void ltt_chanbuf_alloc_free(struct ltt_chanbuf_alloc *buf)
 	struct page **pages;
 	long i;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	/* do nothing for pmem*/
+	if (chan->use_pmem) {
+		buf->start = NULL;
+	}
+	/* We have allocated pages for splice, so free them here. */
+#endif
+
 	/* Destroy index */
 	if (chan->extra_reader_sb) {
 		RCHAN_SB_CLEAR_NOREF(buf->buf_rsb.pages);
@@ -274,10 +337,26 @@ void ltt_chan_for_each_channel(void (*cb) (struct ltt_chanbuf *buf), int cpu)
  * base_filename_0...base_filename_N-1.  File permissions will
  * be %S_IRUSR.
  */
-int ltt_chan_alloc_init(struct ltt_chan_alloc *chan, struct ltt_trace *trace,
+/**
+ * For ltt pmem support only:
+ * relay_open_mem variant - allows using pmem instead of kernel heap
+ * for storage
+ *	@mem_type: RELAY_MEM_TYPE_KERNEL_HEAP or RELAY_MEM_TYPE_PMEM
+ */
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+int ltt_chan_alloc_init_mem(struct ltt_chan_alloc *chan,
+			struct ltt_trace *trace,
+			const char *base_filename,
+			struct dentry *parent, size_t sb_size,
+			size_t n_sb, int extra_reader_sb, int overwrite,
+			enum relay_mem_type mem_type)
+#else
+int ltt_chan_alloc_init(struct ltt_chan_alloc *chan,
+			struct ltt_trace *trace,
 			const char *base_filename,
 			struct dentry *parent, size_t sb_size,
 			size_t n_sb, int extra_reader_sb, int overwrite)
+#endif
 {
 	unsigned int i;
 	int ret;
@@ -306,6 +385,11 @@ int ltt_chan_alloc_init(struct ltt_chan_alloc *chan, struct ltt_trace *trace,
 	chan->n_sb = n_sb;
 	chan->parent = parent;
 	strlcpy(chan->filename, base_filename, NAME_MAX);
+
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	chan->use_pmem = mem_type == RELAY_MEM_TYPE_PMEM ? 1 : 0;
+#endif
+
 	kref_init(&chan->kref);
 	kref_get(&chan->trace->kref);
 
@@ -337,6 +421,21 @@ free_chan:
 	return -ENOMEM;
 }
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+EXPORT_SYMBOL_GPL(ltt_chan_alloc_init_mem);
+
+int ltt_chan_alloc_init(struct ltt_chan_alloc *chan, struct ltt_trace *trace,
+			const char *base_filename,
+			struct dentry *parent, size_t sb_size,
+			size_t n_sb, int extra_reader_sb, int overwrite)
+{
+	return ltt_chan_alloc_init_mem(chan, trace, base_filename,
+				parent, sb_size,
+				n_sb, extra_reader_sb, overwrite,
+				RELAY_MEM_TYPE_KERNEL_HEAP);
+}
+#endif
+
 /**
  * ltt_chan_alloc_remove_files - remove channel files.
  * @chan: the channel
@@ -403,7 +502,36 @@ void _ltt_relay_write(struct ltt_chanbuf_alloc *bufa, size_t offset,
 	struct ltt_chan_alloc *chana = bufa->chan;
 	size_t sbidx, index;
 	struct chanbuf_page *rpages;
-
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (bufa->chan->use_pmem) {
+		__pmem_memcpy_toio(bufa->start + offset + pagecpy,
+			 src + pagecpy, len - pagecpy);
+		PMEM_FLUSH_CACHE(bufa->start + offset + pagecpy, len - pagecpy);
+		wmb();
+	} else {
+		do {
+			len -= pagecpy;
+			src += pagecpy;
+			offset += pagecpy;
+			sbidx = offset >> chana->sb_size_order;
+			index = (offset & (chana->sb_size - 1)) >> PAGE_SHIFT;
+
+			/*
+			  * Underlying layer should never ask for writes across
+			  * subbuffers.
+			 */
+			WARN_ON(offset >= chana->buf_size);
+
+			pagecpy = min_t(size_t, len,
+					PAGE_SIZE - (offset & ~PAGE_MASK));
+			rpages = bufa->buf_wsb[sbidx].pages;
+			WARN_ON_ONCE(RCHAN_SB_IS_NOREF(rpages));
+			ltt_relay_do_copy(rpages[index].virt +
+					(offset & ~PAGE_MASK),
+				  src, pagecpy);
+		} while (unlikely(len != pagecpy));
+	}
+#else
 	do {
 		len -= pagecpy;
 		src += pagecpy;
@@ -423,6 +551,7 @@ void _ltt_relay_write(struct ltt_chanbuf_alloc *bufa, size_t offset,
 		ltt_relay_do_copy(rpages[index].virt + (offset & ~PAGE_MASK),
 				  src, pagecpy);
 	} while (unlikely(len != pagecpy));
+#endif
 }
 EXPORT_SYMBOL_GPL(_ltt_relay_write);
 
@@ -448,6 +577,31 @@ int ltt_relay_read(struct ltt_chanbuf_alloc *bufa, size_t offset, void *dest,
 	index = (offset & (chana->sb_size - 1)) >> PAGE_SHIFT;
 	if (unlikely(!len))
 		return 0;
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (chana->use_pmem) {
+		__pmem_memcpy_fromio(dest, bufa->start + offset, len);
+	} else {
+		for (;;) {
+			pagecpy = min_t(size_t, len,
+					PAGE_SIZE - (offset & ~PAGE_MASK));
+			rpages = bufa->buf_rsb.pages;
+			WARN_ON_ONCE(RCHAN_SB_IS_NOREF(rpages));
+			memcpy(dest, rpages[index].virt + (offset & ~PAGE_MASK),
+				pagecpy);
+			len -= pagecpy;
+			if (likely(!len))
+				break;
+			dest += pagecpy;
+			offset += pagecpy;
+			index = (offset & (chana->sb_size - 1)) >> PAGE_SHIFT;
+			/*
+			 * Underlying layer should never ask for reads across
+			 * subbuffers.
+			 */
+			WARN_ON(offset >= chana->buf_size);
+		}
+	}
+#else
 	for (;;) {
 		pagecpy = min_t(size_t, len, PAGE_SIZE - (offset & ~PAGE_MASK));
 		rpages = bufa->buf_rsb.pages;
@@ -466,6 +620,7 @@ int ltt_relay_read(struct ltt_chanbuf_alloc *bufa, size_t offset, void *dest,
 		 */
 		WARN_ON(offset >= chana->buf_size);
 	}
+#endif
 	return orig_len;
 }
 EXPORT_SYMBOL_GPL(ltt_relay_read);
@@ -489,12 +644,37 @@ int ltt_relay_read_cstr(struct ltt_chanbuf_alloc *bufa, size_t offset,
 	char *str;
 	struct chanbuf_page *rpages;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	long consumed_old, consumed_idx;
+	struct ltt_chanbuf *buf = container_of(bufa, struct ltt_chanbuf, a);
+	struct ltt_chan *chan = container_of(chana, struct ltt_chan, a);
+	if (bufa->chan->use_pmem) {
+		consumed_old = atomic_long_read(&buf->consumed);
+		consumed_idx = SUBBUF_INDEX(consumed_old, chan);
+	}
+#endif
+
 	offset &= chana->buf_size - 1;
 	index = (offset & (chana->sb_size - 1)) >> PAGE_SHIFT;
 	orig_offset = offset;
+
 	for (;;) {
 		rpages = bufa->buf_rsb.pages;
 		WARN_ON_ONCE(RCHAN_SB_IS_NOREF(rpages));
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	/*
+	 * We may use the page since they are allocated.
+	 * It is necessary to do enough testing before dong the copy.
+	 * Copy data no longer than a page, and page by page.
+	 */
+	if (bufa->chan->use_pmem) {
+		__pmem_memcpy_fromio(
+			rpages[index].virt + (offset & ~PAGE_MASK),
+			bufa->start + consumed_idx * chana->sb_size +
+				(offset & (chana->sb_size - 1)),
+			PAGE_SIZE - (offset & ~PAGE_MASK));
+	}
+#endif
 		str = (char *)rpages[index].virt + (offset & ~PAGE_MASK);
 		pagelen = PAGE_SIZE - (offset & ~PAGE_MASK);
 		strpagelen = strnlen(str, pagelen);
@@ -560,8 +740,22 @@ void *ltt_relay_read_offset_address(struct ltt_chanbuf_alloc *bufa,
 	size_t index;
 	struct chanbuf_page *rpages;
 	struct ltt_chan_alloc *chana = bufa->chan;
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	struct ltt_chanbuf *buf = container_of(bufa, struct ltt_chanbuf, a);
+	struct ltt_chan *chan = container_of(buf->a.chan, struct ltt_chan, a);
+	long consumed_old = atomic_long_read(&buf->consumed);
+	long consumed_idx = SUBBUF_INDEX(consumed_old, chan);
+#endif
 
 	offset &= chana->buf_size - 1;
+
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (bufa->chan->use_pmem)
+		return bufa->start +
+				consumed_idx *  bufa->chan->sb_size +
+				(offset & (bufa->chan->sb_size - 1));
+#endif
+
 	index = (offset & (chana->sb_size - 1)) >> PAGE_SHIFT;
 	rpages = bufa->buf_rsb.pages;
 	WARN_ON_ONCE(RCHAN_SB_IS_NOREF(rpages));
@@ -586,6 +780,12 @@ void *ltt_relay_offset_address(struct ltt_chanbuf_alloc *bufa, size_t offset)
 	struct ltt_chan_alloc *chana = bufa->chan;
 
 	offset &= chana->buf_size - 1;
+
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (bufa->chan->use_pmem)
+		return bufa->start + offset;
+#endif
+
 	sbidx = offset >> chana->sb_size_order;
 	index = (offset & (chana->sb_size - 1)) >> PAGE_SHIFT;
 	rpages = bufa->buf_wsb[sbidx].pages;
diff --git a/ltt/ltt-relay-lockless.c b/ltt/ltt-relay-lockless.c
index a9b7efd..5bd9a5a 100644
--- a/ltt/ltt-relay-lockless.c
+++ b/ltt/ltt-relay-lockless.c
@@ -54,6 +54,9 @@
 #include <asm/atomic.h>
 #include <asm/local.h>
 #include <linux/notifier.h>
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+#include <linux/hardirq.h>
+#endif
 
 #include "ltt-relay-lockless.h"
 
@@ -81,14 +84,32 @@ static
 void ltt_buffer_begin(struct ltt_chanbuf *buf, u64 tsc, unsigned int subbuf_idx)
 {
 	struct ltt_chan *chan = container_of(buf->a.chan, struct ltt_chan, a);
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	struct ltt_subbuffer_header tmpheader;
+#endif
 	struct ltt_subbuffer_header *header =
 		(struct ltt_subbuffer_header *)
 			ltt_relay_offset_address(&buf->a,
 				subbuf_idx * chan->a.sb_size);
-
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (chan->a.use_pmem) {
+		memset(&tmpheader, 0, sizeof(tmpheader));
+		tmpheader.cycle_count_begin = tsc;
+		tmpheader.data_size = 0xFFFFFFFF; /* for debugging */
+		ltt_write_trace_header(chan->a.trace, &tmpheader);
+		__pmem_memcpy_toio(header, &tmpheader, sizeof(tmpheader));
+		PMEM_FLUSH_CACHE(header, sizeof(tmpheader));
+		smp_wmb();
+	} else {
+		header->cycle_count_begin = tsc;
+		header->data_size = 0xFFFFFFFF; /* for debugging */
+		ltt_write_trace_header(chan->a.trace, header);
+	}
+#else
 	header->cycle_count_begin = tsc;
 	header->data_size = 0xFFFFFFFF; /* for debugging */
 	ltt_write_trace_header(chan->a.trace, header);
+#endif
 }
 
 /*
@@ -106,11 +127,33 @@ void ltt_buffer_end(struct ltt_chanbuf *buf, u64 tsc, unsigned int offset,
 				subbuf_idx * chan->a.sb_size);
 	u32 data_size = SUBBUF_OFFSET(offset - 1, chan) + 1;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (chan->a.use_pmem) {
+		struct ltt_subbuffer_header tmpheader;
+		__pmem_memcpy_fromio(&tmpheader, header,  sizeof(tmpheader));
+		tmpheader.data_size = data_size;
+		tmpheader.sb_size = PAGE_ALIGN(data_size);
+		tmpheader.cycle_count_end = tsc;
+		tmpheader.events_lost = local_read(&buf->events_lost);
+		tmpheader.subbuf_corrupt =
+			local_read(&buf->corrupted_subbuffers);
+		__pmem_memcpy_toio(header, &tmpheader, sizeof(tmpheader));
+		PMEM_FLUSH_CACHE(header, sizeof(tmpheader));
+		smp_wmb();
+	} else {
+		header->data_size = data_size;
+		header->sb_size = PAGE_ALIGN(data_size);
+		header->cycle_count_end = tsc;
+		header->events_lost = local_read(&buf->events_lost);
+		header->subbuf_corrupt = local_read(&buf->corrupted_subbuffers);
+	}
+#else
 	header->data_size = data_size;
 	header->sb_size = PAGE_ALIGN(data_size);
 	header->cycle_count_end = tsc;
 	header->events_lost = local_read(&buf->events_lost);
 	header->subbuf_corrupt = local_read(&buf->corrupted_subbuffers);
+#endif
 }
 
 /*
@@ -246,8 +289,16 @@ int ltt_chan_create(const char *base_filename,
 
 	chan->overwrite = overwrite;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	ret = ltt_chan_alloc_init_mem(&chan->a, trace, base_filename, parent,
+			sb_size, n_sb, overwrite, overwrite,
+			trace->use_pmem ?
+				 RELAY_MEM_TYPE_PMEM :
+				 RELAY_MEM_TYPE_KERNEL_HEAP);
+#else
 	ret = ltt_chan_alloc_init(&chan->a, trace, base_filename, parent,
-				  sb_size, n_sb, overwrite, overwrite);
+			sb_size, n_sb, overwrite, overwrite);
+#endif
 	if (ret)
 		goto error;
 
diff --git a/ltt/ltt-relay-lockless.h b/ltt/ltt-relay-lockless.h
index 9f17357..9386498 100644
--- a/ltt/ltt-relay-lockless.h
+++ b/ltt/ltt-relay-lockless.h
@@ -324,6 +324,14 @@ u32 get_read_sb_size(struct ltt_chanbuf *buf)
 	struct ltt_subbuffer_header *header =
 		(struct ltt_subbuffer_header *)
 			ltt_relay_read_offset_address(&buf->a, 0);
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	if (buf->a.chan->use_pmem) {
+		struct ltt_subbuffer_header tmpheader;
+		__pmem_memcpy_fromio(&tmpheader,
+			header, sizeof(struct ltt_subbuffer_header));
+		return tmpheader.sb_size;
+	} else
+#endif
 	return header->sb_size;
 }
 
@@ -387,6 +395,19 @@ int ltt_reserve_slot(struct ltt_chan *chan,
 	long o_begin, o_end, o_old;
 	size_t before_hdr_pad;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+#ifndef CONFIG_LTT_DEBUG_EVENT_SIZE
+	/* We need the event size to recover the record from the pmem.
+	 * We can not parse the events if there is not such information,
+	 * Another way is falling back to event meta data.
+	 */
+	if (chan->a.use_pmem &&
+		!(*rflags &  (LTT_RFLAG_ID_SIZE_TSC  | LTT_RFLAG_ID_SIZE))) {
+		*rflags = LTT_RFLAG_ID_SIZE;
+	}
+#endif
+#endif
+
 	/*
 	 * Perform retryable operations.
 	 */
@@ -470,8 +491,8 @@ void ltt_write_commit_counter(struct ltt_chanbuf *buf, struct ltt_chan *chan,
 	 */
 	if (unlikely(SUBBUF_OFFSET(offset - commit_count, chan)))
 		return;
-
 	commit_seq_old = local_read(&buf->commit_seq[idx]);
+
 	while (commit_seq_old < commit_count)
 		commit_seq_old = local_cmpxchg(&buf->commit_seq[idx],
 					 commit_seq_old, commit_count);
diff --git a/ltt/ltt-relay-splice.c b/ltt/ltt-relay-splice.c
index aa72820..cfdfc45 100644
--- a/ltt/ltt-relay-splice.c
+++ b/ltt/ltt-relay-splice.c
@@ -106,6 +106,22 @@ static int subbuf_splice_actor(struct file *in,
 
 		this_len = PAGE_SIZE - poff;
 		page = ltt_relay_read_get_page(&buf->a, roffset);
+
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+		if (chan->a.use_pmem) {
+			/* we have to do page copy for splice since
+			 * pmem mostly should be in io memory.
+			 */
+			__pmem_memcpy_fromio(
+				ltt_relay_read_get_page_virt(&buf->a, roffset)
+					+ poff,
+				buf->a.start +
+					(roffset & (chan->a.buf_size - 1))
+					+ poff,
+				this_len);
+			smp_rmb();
+		}
+#endif
 		spd.pages[spd.nr_pages] = page;
 		spd.partial[spd.nr_pages].offset = poff;
 		spd.partial[spd.nr_pages].len = this_len;
diff --git a/ltt/ltt-tracer.c b/ltt/ltt-tracer.c
index 972289a..181b69f 100644
--- a/ltt/ltt-tracer.c
+++ b/ltt/ltt-tracer.c
@@ -41,6 +41,11 @@
 #include <linux/vmalloc.h>
 #include <asm/atomic.h>
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+#include <linux/pmem.h>
+struct part_handle ltt_part_handle;
+#endif
+
 static void synchronize_trace(void)
 {
 	synchronize_sched();
@@ -175,6 +180,12 @@ struct chan_info_struct {
 	},
 };
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+#define LTT_N_LOWSIZE_CHANNEL	12
+#define LTT_N_MEDSIZE_CHANNEL	5
+#define LTT_N_HIGHSIZE_CHANNEL	1
+
+#endif
 static enum ltt_channels get_channel_type_from_name(const char *name)
 {
 	int i;
@@ -585,6 +596,10 @@ int _ltt_trace_setup(const char *trace_name)
 			chan_infos[chantype].def_n_sb;
 	}
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	new_trace->pmem_part_reged = 0;
+#endif
+
 	list_add(&new_trace->list, &ltt_traces.setup_head);
 	return 0;
 
@@ -613,6 +628,34 @@ static void _ltt_trace_free(struct ltt_trace *trace)
 	kfree(trace);
 }
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+/* generic routine to try to match a channel name with a transport type */
+static inline int match_transport_type(const char *channel_name,
+					char *transport_name)
+{
+	while (*channel_name == *transport_name) {
+		/* this bit provides a match between relay+pmem and relay */
+		if (*(channel_name+1) == '+' && !*(transport_name+1))
+			return 1;
+		if (!*channel_name)
+			return 1;
+		++channel_name;
+		++transport_name;
+	}
+	return 0;
+}
+
+/* find out if a channel is using persistent memory as its storage */
+static inline int use_pmem(const char *channel_name)
+{
+	while (*(channel_name++)) {
+		if (*channel_name == '+')
+			return strcmp(channel_name+1, "pmem") == 0;
+	}
+	return 0;
+}
+#endif /* CONFIG_LTT_PMEM_SUPPORT */
+
 int ltt_trace_set_type(const char *trace_name, const char *trace_type)
 {
 	int err = 0;
@@ -629,7 +672,11 @@ int ltt_trace_set_type(const char *trace_name, const char *trace_type)
 	}
 
 	list_for_each_entry(tran_iter, &ltt_transport_list, node) {
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+		if (match_transport_type(trace_type, tran_iter->name)) {
+#else
 		if (!strcmp(tran_iter->name, trace_type)) {
+#endif
 			transport = tran_iter;
 			break;
 		}
@@ -642,6 +689,9 @@ int ltt_trace_set_type(const char *trace_name, const char *trace_type)
 	}
 
 	trace->transport = transport;
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	trace->use_pmem = use_pmem(trace_type);
+#endif
 
 traces_error:
 	ltt_unlock_traces();
@@ -649,6 +699,101 @@ traces_error:
 }
 EXPORT_SYMBOL_GPL(ltt_trace_set_type);
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+static inline int   __ltt_trace_pmem_alloc(struct ltt_trace *trace,
+	     unsigned int subbuf_size_low, unsigned int n_subbufs_low,
+	     unsigned int subbuf_size_med, unsigned int n_subbufs_med,
+	     unsigned int subbuf_size_high, unsigned int n_subbufs_high,
+	     int cal_realsize)
+{
+	int err = 0;
+	int chan;
+
+	#define FIX_SIZE(x) ((((x) - 1) & PAGE_MASK) + PAGE_SIZE)
+	#define PADDING	FIX_SIZE(64*1024) /* should be enough */
+
+	if (trace->use_pmem) {
+		struct pmem_reg_part part;
+
+		if (trace->pmem_part_reged)
+			return 0;
+
+		if (strlen(LTT_PMEM_PART_NAME) >= PMEM_DESC_MAX) {
+			printk(KERN_ERR"LTT PMEM partition name too long\n");
+			return  -EINVAL;
+		}
+		strncpy(part.desc, LTT_PMEM_PART_NAME, PMEM_DESC_MAX - 1);
+		part.desc[PMEM_DESC_MAX - 1] = 0;
+		part.num_blocks = 1;
+
+		/* calculate real size */
+		if (cal_realsize) {
+			part.size = 0;
+			for (chan = 0; chan < trace->nr_channels; chan++) {
+				part.size += trace->channels[chan].a.sb_size *
+					trace->channels[chan].a.n_sb;
+			}
+		} else {
+			part.size = LTT_N_LOWSIZE_CHANNEL *
+					FIX_SIZE(n_subbufs_low *
+						subbuf_size_low) +
+				LTT_N_MEDSIZE_CHANNEL *
+					FIX_SIZE(n_subbufs_med *
+						subbuf_size_med) +
+				LTT_N_HIGHSIZE_CHANNEL *
+					FIX_SIZE(n_subbufs_high *
+						subbuf_size_high);
+		}
+		part.size *= num_possible_cpus() ;
+		part.size *= part.num_blocks;
+		part.size += PADDING;
+		part.version = 1;
+
+		trace->pmem_h = (pmem_handle_t)&ltt_part_handle;
+		err = pmem_partition_reg(&part, &trace->pmem_h);
+		if (err < 0) {
+			printk(KERN_ERR "failed partition %s creation\n",
+				part.desc);
+			return err;
+		}
+
+		trace->pmem_part_reged = 1;
+
+	}
+
+	#undef FIX_SIZE
+	#undef PADDING
+
+	return err;
+}
+
+
+ int ltt_trace_pmem_alloc(const char *trace_name,
+		     unsigned int subbuf_size_low, unsigned int n_subbufs_low,
+		     unsigned int subbuf_size_med, unsigned int n_subbufs_med,
+		     unsigned int subbuf_size_high, unsigned int n_subbufs_high)
+{
+	int err = 0;
+	struct ltt_trace *trace;
+	ltt_lock_traces();
+
+	trace = _ltt_trace_find_setup(trace_name);
+	if (!trace) {
+		printk(KERN_ERR "LTT : Trace not found %s\n", trace_name);
+		err = -ENOENT;
+		goto traces_error;
+	}
+
+	err = __ltt_trace_pmem_alloc(trace,
+			subbuf_size_low, n_subbufs_low,
+			subbuf_size_med, n_subbufs_med,
+			subbuf_size_high, n_subbufs_high, 0);
+traces_error:
+	ltt_unlock_traces();
+	return err;
+}
+#endif
+
 int ltt_trace_set_channel_subbufsize(const char *trace_name,
 				     const char *channel_name,
 				     unsigned int size)
@@ -834,7 +979,7 @@ int ltt_trace_alloc(const char *trace_name)
 	struct ltt_trace *trace;
 	int sb_size, n_sb;
 	unsigned long flags;
-	int chan;
+	int chan = 0;
 	const char *channel_name;
 
 	ltt_lock_traces();
@@ -877,6 +1022,17 @@ int ltt_trace_alloc(const char *trace_name)
 	do_gettimeofday(&trace->start_time);
 	local_irq_restore(flags);
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	err  = __ltt_trace_pmem_alloc(trace,
+		LTT_DEFAULT_SUBBUF_SIZE_LOW,  LTT_DEFAULT_N_SUBBUFS_LOW,
+		LTT_DEFAULT_SUBBUF_SIZE_MED, LTT_DEFAULT_N_SUBBUFS_MED,
+		LTT_DEFAULT_SUBBUF_SIZE_HIGH, LTT_DEFAULT_N_SUBBUFS_HIGH,
+		1);
+
+	if (err != 0)
+		goto create_channel_error;
+#endif
+
 	for (chan = 0; chan < trace->nr_channels; chan++) {
 		if (!(trace->channels[chan].active))
 			continue;
@@ -957,6 +1113,15 @@ int ltt_trace_create(const char *trace_name, const char *trace_type,
 	if (IS_ERR_VALUE(err))
 		return err;
 
+#ifdef CONFIG_LTT_PMEM_SUPPORT
+	err = ltt_trace_pmem_alloc(trace_name,
+			subbuf_size_low,  n_subbufs_low,
+			subbuf_size_med,  n_subbufs_med,
+			subbuf_size_high, n_subbufs_high);
+	if (IS_ERR_VALUE(err))
+		return err;
+#endif
+
 	err = ltt_trace_alloc(trace_name);
 	if (IS_ERR_VALUE(err))
 		return err;
-- 
1.6.0.3

