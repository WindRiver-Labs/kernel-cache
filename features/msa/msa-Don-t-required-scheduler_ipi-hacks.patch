From d09fff9951c16229f280cd0ac1492e495dd339d8 Mon Sep 17 00:00:00 2001
From: Corey Minyard <cminyard@mvista.com>
Date: Tue, 13 Nov 2012 16:38:48 -0600
Subject: [PATCH 17/18] msa: Don't required scheduler_ipi() hacks

From the upstream project:
git://microstate.git.sourceforge.net/gitroot/microstate/linux-msa

Rework the handling of scheduler_ipi() (and smp_call_function_interrupt()
on MIPS) to not require hacking of the parameters.  Instead, the callers
are required to handle calling the proper MSA irq_enter() and irq_exit()
functions if MSA is enabled.

Signed-off-by: Corey Minyard <cminyard@mvista.com>
---
 arch/arm/kernel/smp.c        |  5 ++++-
 arch/mips/Kconfig.debug      |  1 -
 arch/mips/include/asm/smp.h  |  4 ----
 arch/mips/kernel/smp-bmips.c |  4 ++--
 arch/mips/kernel/smp.c       | 28 ++++++++++------------------
 arch/mips/kernel/smtc.c      |  6 +++++-
 arch/x86/kernel/smp.c        |  6 ++++--
 include/linux/sched.h        | 12 ++----------
 kernel/sched/core.c          | 15 +++++++++------
 9 files changed, 36 insertions(+), 45 deletions(-)

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index e8d089a..40468f2 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -545,7 +545,10 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 		break;
 
 	case IPI_RESCHEDULE:
-		scheduler_ipi(SCHED_IPI_PARMSET(ipinr, user_mode(regs)));
+		irq_enter();
+		msa_start_irq(ipinr);
+		scheduler_ipi();
+		msa_irq_exit(ipinr, user_mode(regs));
 		break;
 
 	case IPI_CALL_FUNC:
diff --git a/arch/mips/Kconfig.debug b/arch/mips/Kconfig.debug
index de7dfe0..d2e3ee6 100644
--- a/arch/mips/Kconfig.debug
+++ b/arch/mips/Kconfig.debug
@@ -130,7 +130,6 @@ config SPINLOCK_TEST
 
 config MICROSTATE_ACCT
 	bool "Microstate accounting"
-	depends on MIPS_MT_DISABLED
 	help
 	  This option causes the kernel to keep very accurate track of
 	  how long your threads spend on the runqueues, running, or asleep or
diff --git a/arch/mips/include/asm/smp.h b/arch/mips/include/asm/smp.h
index 78baa00..d4fb4d8 100644
--- a/arch/mips/include/asm/smp.h
+++ b/arch/mips/include/asm/smp.h
@@ -75,11 +75,7 @@ static inline void __cpu_die(unsigned int cpu)
 extern void play_dead(void);
 #endif
 
-#ifdef CONFIG_MICROSTATE_ACCT
-extern asmlinkage void smp_call_function_interrupt(int irq);
-#else
 extern asmlinkage void smp_call_function_interrupt(void);
-#endif
 
 static inline void arch_send_call_function_single_ipi(int cpu)
 {
diff --git a/arch/mips/kernel/smp-bmips.c b/arch/mips/kernel/smp-bmips.c
index 13a009e..3046e29 100644
--- a/arch/mips/kernel/smp-bmips.c
+++ b/arch/mips/kernel/smp-bmips.c
@@ -243,7 +243,7 @@ static irqreturn_t bmips_ipi_interrupt(int irq, void *dev_id)
 	write_c0_brcm_action(ACTION_CLR_IPI(smp_processor_id(), action));
 
 	if (action == 0)
-		scheduler_ipi(SCHED_IPI_PARMSET(irq, msa_get_reg()));
+		scheduler_ipi();
 	else
 		smp_call_function_interrupt();
 
@@ -288,7 +288,7 @@ static irqreturn_t bmips_ipi_interrupt(int irq, void *dev_id)
 	spin_unlock_irqrestore(&ipi_lock, flags);
 
 	if (action & SMP_RESCHEDULE_YOURSELF)
-		scheduler_ipi(SCHED_IPI_PARMSET(irq, msa_get_reg()));
+		scheduler_ipi();
 	if (action & SMP_CALL_FUNCTION)
 		smp_call_function_interrupt();
 
diff --git a/arch/mips/kernel/smp.c b/arch/mips/kernel/smp.c
index 2c9505c..5f5d17b 100644
--- a/arch/mips/kernel/smp.c
+++ b/arch/mips/kernel/smp.c
@@ -132,33 +132,25 @@ asmlinkage __cpuinit void start_secondary(void)
 	cpu_idle();
 }
 
-#ifdef CONFIG_MICROSTATE_ACCT
-/*
- * Only caller of smp_call_function_interrupt() knows irq number.
- * So smp_call_function_interrupt() should have irq argument.
- */
-void __irq_entry smp_call_function_interrupt(int irq)
-#else
 /*
  * Call into both interrupt handlers, as we share the IPI for them
  */
 void __irq_entry smp_call_function_interrupt(void)
-#endif
 {
-#ifndef CONFIG_MICROSTATE_ACCT
+#ifdef CONFIG_MICROSTATE_ACCT
 	/*
-	* When MSA isn't selected msa_start_irq() is empty and
-	* and we don't care what irq number would be passed
-	* to msa_start_irq()/msa_irq_exit().
-	*/
-       int irq = 0;
-#endif
-
+	 * When MSA is enabled, the caller must call irq_enter() and
+	 * irq_exit().
+	 */
+	BUG_ON(!in_irq());
+#else
 	irq_enter();
-	msa_start_irq(irq);
+#endif
 	generic_smp_call_function_single_interrupt();
 	generic_smp_call_function_interrupt();
-	msa_irq_exit(irq, msa_get_reg());
+#ifndef CONFIG_MICROSTATE_ACCT
+	irq_exit();
+#endif
 }
 
 static void stop_this_cpu(void *dummy)
diff --git a/arch/mips/kernel/smtc.c b/arch/mips/kernel/smtc.c
index b791bd1..4c78101 100644
--- a/arch/mips/kernel/smtc.c
+++ b/arch/mips/kernel/smtc.c
@@ -39,6 +39,7 @@
 #include <asm/cacheflush.h>
 #include <asm/time.h>
 #include <asm/addrspace.h>
+#include <asm/setup.h>
 #include <asm/smtc.h>
 #include <asm/smtc_proc.h>
 
@@ -928,7 +929,7 @@ static void post_direct_ipi(int cpu, struct smtc_ipi *pipi)
 
 static void ipi_resched_interrupt(void)
 {
-	scheduler_ipi(SCHED_IPI_PARMSET(IPI0_IRQ, msa_get_reg()));
+	scheduler_ipi();
 }
 
 static void ipi_call_interrupt(void)
@@ -1114,7 +1115,10 @@ static irqreturn_t ipi_interrupt(int irq, void *dev_idm)
 				if (pipi->type == LINUX_SMP_IPI &&
 				    (int)pipi->arg == SMP_RESCHEDULE_YOURSELF)
 					IPIQ[cpu].resched_flag = 0;
+				irq_enter();
+				msa_start_irq(irq);
 				ipi_decode(pipi);
+				msa_irq_exit(irq, msa_get_reg());
 				local_irq_restore(flags);
 			}
 		}
diff --git a/arch/x86/kernel/smp.c b/arch/x86/kernel/smp.c
index ed272b4..ee4a274 100644
--- a/arch/x86/kernel/smp.c
+++ b/arch/x86/kernel/smp.c
@@ -261,8 +261,10 @@ void smp_reschedule_interrupt(struct pt_regs *regs)
 {
 	ack_APIC_irq();
 	inc_irq_stat(irq_resched_count);
-	scheduler_ipi(SCHED_IPI_PARMSET(RESCHEDULE_VECTOR,
-					regs->cs != __KERNEL_CS));
+	irq_enter();
+	msa_start_irq(RESCHEDULE_VECTOR);
+	scheduler_ipi();
+	msa_irq_exit(RESCHEDULE_VECTOR, regs->cs != __KERNEL_CS);
 	/*
 	 * KVM uses this interrupt to force a cpu out of guest mode
 	 */
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 4ce2c12..89678af 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -2346,19 +2346,11 @@ struct task_struct *fork_idle(int);
 extern void set_task_comm(struct task_struct *tsk, char *from);
 extern char *get_task_comm(char *to, struct task_struct *tsk);
 
-#ifdef CONFIG_MICROSTATE_ACCT
-#define SCHED_IPI_PARMS int irq, int is_going_to_user
-#define SCHED_IPI_PARMSET(a, b) a, b
-#else
-#define SCHED_IPI_PARMS void
-#define SCHED_IPI_PARMSET(a, b)
-#endif
-
 #ifdef CONFIG_SMP
-void scheduler_ipi(SCHED_IPI_PARMS);
+void scheduler_ipi(void);
 extern unsigned long wait_task_inactive(struct task_struct *, long match_state);
 #else
-static inline void scheduler_ipi(SCHED_IPI_PARMS) { }
+static inline void scheduler_ipi(void) { }
 static inline unsigned long wait_task_inactive(struct task_struct *p,
 					       long match_state)
 {
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 1c40a25..6d9d36c3 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -1484,7 +1484,7 @@ static void sched_ttwu_pending(void)
 	raw_spin_unlock(&rq->lock);
 }
 
-void scheduler_ipi(SCHED_IPI_PARMS)
+void scheduler_ipi()
 {
 	if (llist_empty(&this_rq()->wake_list) && !got_nohz_idle_kick())
 		return;
@@ -1502,9 +1502,14 @@ void scheduler_ipi(SCHED_IPI_PARMS)
 	 * however a fair share of IPIs are still resched only so this would
 	 * somewhat pessimize the simple resched case.
 	 */
-	irq_enter();
 #ifdef CONFIG_MICROSTATE_ACCT
-	msa_start_irq(irq);
+	/*
+	 * MSA requires that the caller handle calling irq_enter(),
+	 * msa_start_irq(), and msa_irq_exit().
+	 */
+	BUG_ON(!in_irq());
+#else
+	irq_enter();
 #endif
 	sched_ttwu_pending();
 
@@ -1515,9 +1520,7 @@ void scheduler_ipi(SCHED_IPI_PARMS)
 		this_rq()->idle_balance = 1;
 		raise_softirq_irqoff(SCHED_SOFTIRQ);
 	}
-#ifdef CONFIG_MICROSTATE_ACCT
-	msa_irq_exit(irq, is_going_to_user);
-#else
+#ifndef CONFIG_MICROSTATE_ACCT
 	irq_exit();
 #endif
 }
-- 
1.8.0.1.264.g226dcb5

