From 9581a3863691bde1791c8fa4c09bee4bee680c73 Mon Sep 17 00:00:00 2001
From: Corey Minyard <cminyard@mvista.com>
Date: Thu, 6 May 2010 14:26:38 -0500
Subject: [PATCH 02/18] msa-x86

Source: git://microstate.git.sourceforge.net/gitroot/microstate/microstate
MR: 37518
Type: Integration
Disposition: Local
ChangeID: eb94282eb6fe53bde6c3b19e177970e4b24d6a4b
Description:

Microstate accounting support for x86.

Signed-off-by: Corey Minyard <cminyard@mvista.com>
Signed-off-by: Dale Farnsworth <dfarnsworth@mvista.com>
---
 arch/x86/Kconfig.debug           |   32 ++++++++++++++++++++++++++++++++
 arch/x86/ia32/ia32entry.S        |   25 +++++++++++++++++++++++++
 arch/x86/include/asm/msa.h       |   38 ++++++++++++++++++++++++++++++++++++++
 arch/x86/kernel/apic/apic.c      |    9 ++++++---
 arch/x86/kernel/entry_32.S       |   20 ++++++++++++++++++++
 arch/x86/kernel/entry_64.S       |   25 +++++++++++++++++++++++++
 arch/x86/kernel/irq.c            |    9 ++++++---
 arch/x86/kernel/smp.c            |    6 ++++--
 arch/x86/mm/fault.c              |    5 ++++-
 arch/x86/syscalls/syscall_32.tbl |    1 +
 arch/x86/syscalls/syscall_64.tbl |    1 +
 11 files changed, 162 insertions(+), 9 deletions(-)
 create mode 100644 arch/x86/include/asm/msa.h

diff --git a/arch/x86/Kconfig.debug b/arch/x86/Kconfig.debug
index e46c214..e2861ca 100644
--- a/arch/x86/Kconfig.debug
+++ b/arch/x86/Kconfig.debug
@@ -5,6 +5,38 @@ config TRACE_IRQFLAGS_SUPPORT
 
 source "lib/Kconfig.debug"
 
+config MICROSTATE_ACCT
+	bool "Microstate accounting"
+	help
+	  This option causes the kernel to keep very accurate track of
+	  how long your threads spend on the runqueues, running, or asleep or
+	  stopped.  It will slow down your kernel.
+	  Times are reported in /proc/pid/msa and through a new msa()
+	  system call.
+
+choice
+	depends on MICROSTATE_ACCT
+	prompt "Microstate timing source"
+	default MICROSTATE_ACCT_SCHED_CLOCK_CLOCKSOURCE
+
+config MICROSTATE_ACCT_SCHED_CLOCK_CLOCKSOURCE
+        bool "Use the sched_clock clocksource for microstate timing"
+        help
+	  Use the kernel's built-in sched_clock clock-source for
+	  timing.  In some cases the TSC runs at a variable rate,
+	  which will distort the microstate measurements.  This timer,
+          although having slightly more overhead, and probably a lower
+          resolution will always run at a constant rate.
+
+config MICROSTATE_ACCT_TSC_CLOCKSOURCE
+	bool "Use on-chip TSC for microstate timings"
+	depends on X86_TSC
+	help
+	  If your machine's clock runs at constant rate, then this timer
+	  gives you cycle precision in measuring times spent in microstates.
+
+endchoice
+
 config STRICT_DEVMEM
 	bool "Filter access to /dev/mem"
 	---help---
diff --git a/arch/x86/ia32/ia32entry.S b/arch/x86/ia32/ia32entry.S
index e3e7340..3fc738f 100644
--- a/arch/x86/ia32/ia32entry.S
+++ b/arch/x86/ia32/ia32entry.S
@@ -125,6 +125,11 @@ ENTRY(ia32_sysenter_target)
 	 * No need to follow this irqs on/off section: the syscall
 	 * disabled irqs, here we enable it straight after entry:
 	 */
+#ifdef CONFIG_MICROSTATE_ACCT
+	SAVE_ARGS
+	call msa_kernel
+	RESTORE_ARGS
+#endif
 	ENABLE_INTERRUPTS(CLBR_NONE)
  	movl	%ebp,%ebp		/* zero extension */
 	pushq_cfi $__USER32_DS
@@ -165,6 +170,11 @@ sysenter_dispatch:
 	testl	$_TIF_ALLWORK_MASK,TI_flags+THREAD_INFO(%rsp,RIP-ARGOFFSET)
 	jnz	sysexit_audit
 sysexit_from_sys_call:
+#ifdef CONFIG_MICROSTATE_ACCT
+	call msa_user
+	GET_THREAD_INFO(%r10)
+	movl RAX-ARGOFFSET(%rsp),%eax	/* reload syscall return value */
+#endif
 	andl    $~TS_COMPAT,TI_status+THREAD_INFO(%rsp,RIP-ARGOFFSET)
 	/* clear IF, that popfq doesn't enable interrupts early */
 	andl  $~0x200,EFLAGS-R11(%rsp) 
@@ -285,6 +295,11 @@ ENTRY(ia32_cstar_target)
 	 * No need to follow this irqs on/off section: the syscall
 	 * disabled irqs and here we enable it straight after entry:
 	 */
+#ifdef CONFIG_MICROSTATE_ACCT
+	SAVE_ARGS
+	call msa_kernel
+	RESTORE_ARGS
+#endif
 	ENABLE_INTERRUPTS(CLBR_NONE)
 	SAVE_ARGS 8,0,0
 	movl 	%eax,%eax	/* zero extension */
@@ -322,6 +337,11 @@ cstar_dispatch:
 	testl $_TIF_ALLWORK_MASK,TI_flags+THREAD_INFO(%rsp,RIP-ARGOFFSET)
 	jnz sysretl_audit
 sysretl_from_sys_call:
+#ifdef CONFIG_MICROSTATE_ACCT
+	call msa_user
+	GET_THREAD_INFO(%r10)
+	movl RAX-ARGOFFSET(%rsp),%eax	/* reload syscall return value */
+#endif
 	andl $~TS_COMPAT,TI_status+THREAD_INFO(%rsp,RIP-ARGOFFSET)
 	RESTORE_ARGS 0,-ARG_SKIP,0,0,0
 	movl RIP-ARGOFFSET(%rsp),%ecx
@@ -408,6 +428,11 @@ ENTRY(ia32_syscall)
 	 * No need to follow this irqs on/off section: the syscall
 	 * disabled irqs and here we enable it straight after entry:
 	 */
+#ifdef CONFIG_MICROSTATE_ACCT
+	SAVE_ARGS
+	call msa_kernel
+	RESTORE_ARGS
+#endif
 	ENABLE_INTERRUPTS(CLBR_NONE)
 	movl %eax,%eax
 	pushq_cfi %rax
diff --git a/arch/x86/include/asm/msa.h b/arch/x86/include/asm/msa.h
new file mode 100644
index 0000000..9ac31d8
--- /dev/null
+++ b/arch/x86/include/asm/msa.h
@@ -0,0 +1,38 @@
+/************************************************************************
+ * msa.h
+ *
+ * Provide an architecture-specific clock for x86.
+ ***********************************************************************/
+
+#ifndef _ASM_X86_MSA_H
+# define _ASM_X86_MSA_H
+
+# if defined(CONFIG_MICROSTATE_ACCT_TSC_CLOCKSOURCE)
+/*
+ * Use the processor's time-stamp counter as a timesource
+ */
+#  include <linux/compiler.h>
+#  include <asm/msr.h>
+#  include <asm/div64.h>
+
+#  define MSA_NOW(now)  rdtscll(now)
+
+/*
+ * Note that interrupts are configured before cpu_khz is set, so we have
+ * to have the check here.
+ */
+#  define MSA_TO_NSEC(clk) ({\
+	msa_time_t _x = 0;			\
+	if (likely(cpu_khz)) {			\
+		_x = ((clk) * 1000000ULL);	\
+		do_div(_x, cpu_khz);		\
+	}					\
+	_x; })
+
+# elif defined(CONFIG_MICROSTATE_ACCT_SCHED_CLOCK_CLOCKSOURCE)
+#  include <asm-generic/msa.h>
+# else
+#  error "No clocksource defined for Microstate Accounting"
+# endif
+
+#endif /* _ASM_X86_MSA_H */
diff --git a/arch/x86/kernel/apic/apic.c b/arch/x86/kernel/apic/apic.c
index edc2448..09a2fad 100644
--- a/arch/x86/kernel/apic/apic.c
+++ b/arch/x86/kernel/apic/apic.c
@@ -894,8 +894,9 @@ void __irq_entry smp_apic_timer_interrupt(struct pt_regs *regs)
 	 */
 	irq_enter();
 	exit_idle();
+	msa_start_irq(LOCAL_TIMER_VECTOR);
 	local_apic_timer_interrupt();
-	irq_exit();
+	msa_irq_exit(LOCAL_TIMER_VECTOR, regs->cs != __KERNEL_CS);
 
 	set_irq_regs(old_regs);
 }
@@ -1875,6 +1876,7 @@ void smp_spurious_interrupt(struct pt_regs *regs)
 
 	irq_enter();
 	exit_idle();
+	msa_start_irq(SPURIOUS_APIC_VECTOR);
 	/*
 	 * Check if this really is a spurious interrupt and ACK it
 	 * if it is a vectored one.  Just in case...
@@ -1889,7 +1891,7 @@ void smp_spurious_interrupt(struct pt_regs *regs)
 	/* see sw-dev-man vol 3, chapter 7.4.13.5 */
 	pr_info("spurious APIC interrupt on CPU#%d, "
 		"should never happen.\n", smp_processor_id());
-	irq_exit();
+	msa_irq_exit(SPURIOUS_APIC_VECTOR, regs->cs != __KERNEL_CS);
 }
 
 /*
@@ -1912,6 +1914,7 @@ void smp_error_interrupt(struct pt_regs *regs)
 
 	irq_enter();
 	exit_idle();
+	msa_start_irq(ERROR_APIC_VECTOR);
 	/* First tickle the hardware, only then report what went on. -- REW */
 	v0 = apic_read(APIC_ESR);
 	apic_write(APIC_ESR, 0);
@@ -1932,7 +1935,7 @@ void smp_error_interrupt(struct pt_regs *regs)
 
 	apic_printk(APIC_DEBUG, KERN_CONT "\n");
 
-	irq_exit();
+	msa_irq_exit(ERROR_APIC_VECTOR, regs->cs != __KERNEL_CS);
 }
 
 /**
diff --git a/arch/x86/kernel/entry_32.S b/arch/x86/kernel/entry_32.S
index 7b784f4..d3e3180 100644
--- a/arch/x86/kernel/entry_32.S
+++ b/arch/x86/kernel/entry_32.S
@@ -343,6 +343,11 @@ ENTRY(resume_userspace)
 					# setting need_resched or sigpending
 					# between sampling and the iret
 	TRACE_IRQS_OFF
+#ifdef CONFIG_MICROSTATE_ACCT
+	pushl %eax
+	call msa_user
+	popl %eax
+#endif
 	movl TI_flags(%ebp), %ecx
 	andl $_TIF_WORK_MASK, %ecx	# is there any work to be done on
 					# int/exception return?
@@ -405,6 +410,11 @@ sysenter_past_esp:
 
 	pushl_cfi %eax
 	SAVE_ALL
+#ifdef CONFIG_MICROSTATE_ACCT
+	pushl %eax
+	call msa_kernel
+	popl %eax
+#endif
 	ENABLE_INTERRUPTS(CLBR_NONE)
 
 /*
@@ -436,6 +446,11 @@ sysenter_do_call:
 	testl $_TIF_ALLWORK_MASK, %ecx
 	jne sysexit_audit
 sysenter_exit:
+#ifdef CONFIG_MICROSTATE_ACCT
+	pushl %eax
+	call msa_user
+	popl %eax
+#endif
 /* if something modifies registers it must also disable sysexit */
 	movl PT_EIP(%esp), %edx
 	movl PT_OLDESP(%esp), %ecx
@@ -501,6 +516,11 @@ ENTRY(system_call)
 	RING0_INT_FRAME			# can't unwind into user space anyway
 	pushl_cfi %eax			# save orig_eax
 	SAVE_ALL
+#ifdef CONFIG_MICROSTATE_ACCT
+	pushl %eax
+	call msa_kernel
+	popl %eax
+#endif
 	GET_THREAD_INFO(%ebp)
 					# system call tracing in operation / emulation
 	testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%ebp)
diff --git a/arch/x86/kernel/entry_64.S b/arch/x86/kernel/entry_64.S
index cdc79b5..5ffb8d8 100644
--- a/arch/x86/kernel/entry_64.S
+++ b/arch/x86/kernel/entry_64.S
@@ -477,6 +477,11 @@ GLOBAL(system_call_after_swapgs)
 	SAVE_ARGS 8,0
 	movq  %rax,ORIG_RAX-ARGOFFSET(%rsp)
 	movq  %rcx,RIP-ARGOFFSET(%rsp)
+#ifdef CONFIG_MICROSTATE_ACCT
+	SAVE_ARGS
+	call msa_kernel
+	RESTORE_ARGS
+#endif
 	CFI_REL_OFFSET rip,RIP-ARGOFFSET
 	testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags+THREAD_INFO(%rsp,RIP-ARGOFFSET)
 	jnz tracesys
@@ -511,6 +516,11 @@ sysret_check:
 	 */
 	TRACE_IRQS_ON
 	movq RIP-ARGOFFSET(%rsp),%rcx
+#ifdef CONFIG_MICROSTATE_ACCT
+	SAVE_ARGS
+	call msa_user
+	RESTORE_ARGS
+#endif
 	CFI_REGISTER	rip,rcx
 	RESTORE_ARGS 1,-ARG_SKIP,0
 	/*CFI_REGISTER	rflags,r11*/
@@ -619,6 +629,11 @@ tracesys:
 GLOBAL(int_ret_from_sys_call)
 	DISABLE_INTERRUPTS(CLBR_NONE)
 	TRACE_IRQS_OFF
+#ifdef CONFIG_MICROSTATE_ACCT
+	SAVE_ARGS
+	call msa_user
+	RESTORE_ARGS
+#endif
 	movl $_TIF_ALLWORK_MASK,%edi
 	/* edi:	mask to check */
 GLOBAL(int_with_check)
@@ -672,6 +687,11 @@ int_restore_rest:
 	RESTORE_REST
 	DISABLE_INTERRUPTS(CLBR_NONE)
 	TRACE_IRQS_OFF
+#ifdef CONFIG_MICROSTATE_ACCT
+	SAVE_ARGS
+	call msa_user
+	RESTORE_ARGS
+#endif
 	jmp int_with_check
 	CFI_ENDPROC
 END(system_call)
@@ -1510,6 +1530,11 @@ ENTRY(error_exit)
 	movl %ebx,%eax
 	RESTORE_REST
 	DISABLE_INTERRUPTS(CLBR_NONE)
+#ifdef CONFIG_MICROSTATE_ACCT
+	SAVE_ARGS
+	call msa_user
+	RESTORE_ARGS
+#endif
 	TRACE_IRQS_OFF
 	GET_THREAD_INFO(%rcx)
 	testl %eax,%eax
diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 3dafc60..86cadf9 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -10,6 +10,7 @@
 #include <linux/ftrace.h>
 #include <linux/delay.h>
 #include <linux/export.h>
+#include <linux/msa.h>
 
 #include <asm/apic.h>
 #include <asm/io_apic.h>
@@ -191,6 +192,8 @@ unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 
 	irq = __this_cpu_read(vector_irq[vector]);
 
+	msa_start_irq(vector);
+
 	if (!handle_irq(irq, regs)) {
 		ack_APIC_irq();
 
@@ -199,7 +202,7 @@ unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 				__func__, smp_processor_id(), vector, irq);
 	}
 
-	irq_exit();
+	msa_irq_exit(vector, regs->cs != __KERNEL_CS);
 
 	set_irq_regs(old_regs);
 	return 1;
@@ -215,15 +218,15 @@ void smp_x86_platform_ipi(struct pt_regs *regs)
 	ack_APIC_irq();
 
 	irq_enter();
-
 	exit_idle();
+	msa_start_irq(X86_PLATFORM_IPI_VECTOR);
 
 	inc_irq_stat(x86_platform_ipis);
 
 	if (x86_platform_ipi_callback)
 		x86_platform_ipi_callback();
 
-	irq_exit();
+	msa_irq_exit(X86_PLATFORM_IPI_VECTOR, regs->cs != __KERNEL_CS);
 
 	set_irq_regs(old_regs);
 }
diff --git a/arch/x86/kernel/smp.c b/arch/x86/kernel/smp.c
index 66c74f4..54403a4 100644
--- a/arch/x86/kernel/smp.c
+++ b/arch/x86/kernel/smp.c
@@ -271,18 +271,20 @@ void smp_call_function_interrupt(struct pt_regs *regs)
 {
 	ack_APIC_irq();
 	irq_enter();
+	msa_start_irq(CALL_FUNCTION_SINGLE_VECTOR);
 	generic_smp_call_function_interrupt();
 	inc_irq_stat(irq_call_count);
-	irq_exit();
+	msa_irq_exit(CALL_FUNCTION_SINGLE_VECTOR, regs->cs != __KERNEL_CS);
 }
 
 void smp_call_function_single_interrupt(struct pt_regs *regs)
 {
 	ack_APIC_irq();
 	irq_enter();
+	msa_start_irq(CALL_FUNCTION_SINGLE_VECTOR);
 	generic_smp_call_function_single_interrupt();
 	inc_irq_stat(irq_call_count);
-	irq_exit();
+	msa_irq_exit(CALL_FUNCTION_SINGLE_VECTOR, regs->cs != __KERNEL_CS);
 }
 
 static int __init nonmi_ipi_setup(char *str)
diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c
index 3ecfd1a..ea485f9 100644
--- a/arch/x86/mm/fault.c
+++ b/arch/x86/mm/fault.c
@@ -13,6 +13,7 @@
 #include <linux/perf_event.h>		/* perf_sw_event		*/
 #include <linux/hugetlb.h>		/* hstate_index_to_shift	*/
 #include <linux/prefetch.h>		/* prefetchw			*/
+#include <linux/msa.h>			/* msa_kernel()			*/
 
 #include <asm/traps.h>			/* dotraplinkage, ...		*/
 #include <asm/pgalloc.h>		/* pgd_*(), ...			*/
@@ -1065,7 +1066,9 @@ do_page_fault(struct pt_regs *regs, unsigned long error_code)
 		bad_area_nosemaphore(regs, error_code, address);
 
 		return;
-	}
+	} else
+		/* We just left userspace */
+		msa_kernel();
 
 	/* kprobes don't want to hook the spurious faults: */
 	if (unlikely(notify_page_fault(regs)))
diff --git a/arch/x86/syscalls/syscall_32.tbl b/arch/x86/syscalls/syscall_32.tbl
index 29f9f05..f856d07 100644
--- a/arch/x86/syscalls/syscall_32.tbl
+++ b/arch/x86/syscalls/syscall_32.tbl
@@ -355,3 +355,4 @@
 346	i386	setns			sys_setns
 347	i386	process_vm_readv	sys_process_vm_readv		compat_sys_process_vm_readv
 348	i386	process_vm_writev	sys_process_vm_writev		compat_sys_process_vm_writev
+349	i386	msa			sys_msa
diff --git a/arch/x86/syscalls/syscall_64.tbl b/arch/x86/syscalls/syscall_64.tbl
index dd29a9e..f16739d 100644
--- a/arch/x86/syscalls/syscall_64.tbl
+++ b/arch/x86/syscalls/syscall_64.tbl
@@ -318,6 +318,7 @@
 309	common	getcpu			sys_getcpu
 310	64	process_vm_readv	sys_process_vm_readv
 311	64	process_vm_writev	sys_process_vm_writev
+312	common	msa			sys_msa
 #
 # x32-specific system call numbers start at 512 to avoid cache impact
 # for native 64-bit operation.
-- 
1.7.9.7

