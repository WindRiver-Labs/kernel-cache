From b753b40d9560690b3741f03f3caf4a0434a7d774 Mon Sep 17 00:00:00 2001
From: Corey Minyard <cminyard@mvista.com>
Date: Thu, 6 May 2010 14:26:38 -0500
Subject: [PATCH 04/18] msa-cputime

Source: git://microstate.git.sourceforge.net/gitroot/microstate/microstate
MR: 37518
Type: Integration
Disposition: Local
ChangeID: 59fb14455f31f430eef6f3ce7354ab9dedbc49a3
Description:

Convert the standard process timekeeping to use microstate accounting
if microstate accounting is enabled.  This way, "top" and other
standard process display programs will be accurate.  And virtual
itimers can be used reliably.

Signed-off-by: Corey Minyard <cminyard@mvista.com>
Signed-off-by: Dale Farnsworth <dfarnsworth@mvista.com>
---
 include/asm-generic/cputime.h     |    5 ++
 include/asm-generic/cputime_msa.h |   84 +++++++++++++++++++++
 include/asm-generic/msa.h         |    1 +
 include/linux/kernel_stat.h       |   15 +++-
 include/linux/sched.h             |    8 +-
 kernel/fork.c                     |    2 +-
 kernel/msa.c                      |   42 +++++++++--
 kernel/sched/core.c               |  148 +++++++++++++++++++++++++++----------
 kernel/sched/stats.h              |    6 +-
 kernel/time.c                     |    1 +
 kernel/time/tick-sched.c          |    4 +-
 11 files changed, 261 insertions(+), 55 deletions(-)
 create mode 100644 include/asm-generic/cputime_msa.h

diff --git a/include/asm-generic/cputime.h b/include/asm-generic/cputime.h
index 9a62937..7fc2379 100644
--- a/include/asm-generic/cputime.h
+++ b/include/asm-generic/cputime.h
@@ -1,6 +1,10 @@
 #ifndef _ASM_GENERIC_CPUTIME_H
 #define _ASM_GENERIC_CPUTIME_H
 
+#ifdef CONFIG_MICROSTATE_ACCT
+#include "cputime_msa.h"
+#else
+
 #include <linux/time.h>
 #include <linux/jiffies.h>
 
@@ -67,3 +71,4 @@ typedef u64 __nocast cputime64_t;
 	jiffies_64_to_clock_t(cputime64_to_jiffies64(__ct))
 
 #endif
+#endif
diff --git a/include/asm-generic/cputime_msa.h b/include/asm-generic/cputime_msa.h
new file mode 100644
index 0000000..983fbb8
--- /dev/null
+++ b/include/asm-generic/cputime_msa.h
@@ -0,0 +1,84 @@
+#ifndef _ASM_GENERIC_CPUTIME_MSA_H
+#define _ASM_GENERIC_CPUTIME_MSA_H
+
+#include <linux/time.h>
+#include <linux/jiffies.h>
+#include <linux/msa.h>
+#include <linux/math64.h>
+
+#define msa_to_cputime(msa)		MSA_TO_NSEC(msa)
+#define msa_to_cputime64(msa)		MSA_TO_NSEC(msa)
+
+typedef u64 cputime_t;
+
+#define cputime_zero			0
+#define cputime_one_jiffy		jiffies_to_cputime(1)
+#define cputime_max			((~((cputime_t)0) >> 1) - 1)
+#define cputime_add(__a, __b)		((__a) +  (__b))
+#define cputime_sub(__a, __b)		((__a) -  (__b))
+#define cputime_div(__a, __n)		({ u64 __x = (__a); do_div(__x, __n); __x; })
+#define cputime_halve(__a)		((__a) >> 1)
+#define cputime_eq(__a, __b)		((__a) == (__b))
+#define cputime_gt(__a, __b)		((__a) >  (__b))
+#define cputime_ge(__a, __b)		((__a) >= (__b))
+#define cputime_lt(__a, __b)		((__a) <  (__b))
+#define cputime_le(__a, __b)		((__a) <= (__b))
+#define cputime_to_jiffies(__ct)	((unsigned long) cputime_div(__ct, TICK_NSEC))
+#define cputime_to_scaled(__ct)		cputime_to_jiffies(__ct)
+#define jiffies_to_cputime(__hz)	((cputime_t)__hz * TICK_NSEC)
+
+typedef u64 cputime64_t;
+
+#define cputime64_zero			0
+#define cputime64_add(__a, __b)		((__a) + (__b))
+#define cputime64_sub(__a, __b)		((__a) - (__b))
+#define cputime64_to_jiffies64(__ct)	(__ct)
+#define jiffies64_to_cputime64(__jif)	(__jif)
+#define cputime_to_cputime64(__ct)	(__ct)
+#define nsecs_to_cputime64(__ct)	\
+	jiffies64_to_cputime64(nsecs_to_jiffies64(__ct))
+#define usecs_to_cputime64(__ct)	\
+	jiffies64_to_cputime64(nsecs_to_jiffies64((__ct)*1000))
+
+
+/*
+ * Convert cputime to milliseconds and back.
+ */
+#define cputime_to_msecs(__ct)		((unsigned int) cputime_div(__ct, NSEC_PER_MSEC))
+#define msecs_to_cputime(__msecs)	((cputime_t)(__msecs) * NSEC_PER_MSEC)
+
+/*
+ * Convert cputime to seconds and back.
+ */
+#define cputime_to_secs(msa)		((unsigned long) cputime_div(msa, NSEC_PER_SEC))
+#define secs_to_cputime(sec)		((cputime_t)(sec) * NSEC_PER_SEC)
+
+/*
+ * Convert cputime to timespec and back.
+ */
+#define timespec_to_cputime(__spec)	\
+  ((cputime_t)((__spec)->tv_sec) * NSEC_PER_SEC + (__spec)->tv_nsec)
+#define cputime_to_timespec(__ct,__spec) \
+  ({ s32 nsec; \
+   (__spec)->tv_sec = div_s64_rem(__ct, NSEC_PER_SEC, &nsec); \
+   (__spec)->tv_nsec = nsec; })
+
+/*
+ * Convert cputime to timeval and back.
+ */
+#define timeval_to_cputime(__val)	\
+  ((cputime_t)((__val)->tv_sec) * NSEC_PER_SEC + (__val)->tv_usec * NSEC_PER_USEC)
+#define cputime_to_timeval(__ct,__val)	(*(__val) = ns_to_timeval(__ct))
+
+/*
+ * Convert cputime to clock and back.
+ */
+#define cputime_to_clock_t(__ct)	((clock_t) nsec_to_clock_t(__ct))
+#define clock_t_to_cputime(__x)		((cputime_t) (clock_t_to_jiffies(__x) * TICK_NSEC))
+
+/*
+ * Convert cputime64 to clock.
+ */
+#define cputime64_to_clock_t(__ct)	nsec_to_clock_t(__ct)
+
+#endif
diff --git a/include/asm-generic/msa.h b/include/asm-generic/msa.h
index ded8090..c995b99 100644
--- a/include/asm-generic/msa.h
+++ b/include/asm-generic/msa.h
@@ -14,6 +14,7 @@
  */
 #  define MSA_NOW(now)  do { (now) = sched_clock(); } while (0)
 #  define MSA_TO_NSEC(clk) (clk)
+#  define MICROSTATE_ACCT_USING_SCHED_CLOCK
 # endif
 
 #endif /* _ASM_GENERIC_MSA_H */
diff --git a/include/linux/kernel_stat.h b/include/linux/kernel_stat.h
index 2fbd905..cfe506f 100644
--- a/include/linux/kernel_stat.h
+++ b/include/linux/kernel_stat.h
@@ -121,10 +121,23 @@ static inline unsigned int kstat_cpu_irqs_sum(unsigned int cpu)
  */
 extern unsigned long long task_delta_exec(struct task_struct *);
 
+#ifdef CONFIG_MICROSTATE_ACCT
+/* stub those out: */
+static inline void account_user_time(struct task_struct *p, cputime_t c,
+				     cputime_t s) { }
+static inline void account_system_time(struct task_struct *p, int o,
+				       cputime_t c, cputime_t s) { }
+static inline void account_idle_time(cputime_t c) { }
+/* and use those instead: */
+extern void msa_user_time(struct task_struct *, cputime_t);
+extern void msa_system_time(struct task_struct *, cputime_t);
+#else
 extern void account_user_time(struct task_struct *, cputime_t, cputime_t);
 extern void account_system_time(struct task_struct *, int, cputime_t, cputime_t);
-extern void account_steal_time(cputime_t);
 extern void account_idle_time(cputime_t);
+#endif
+
+extern void account_steal_time(cputime_t);
 
 extern void account_process_tick(struct task_struct *, int user);
 extern void account_steal_ticks(unsigned long ticks);
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 107f02e..35d0853 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -748,7 +748,8 @@ extern struct user_struct root_user;
 struct backing_dev_info;
 struct reclaim_state;
 
-#if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT)
+#if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT) || \
+    defined(CONFIG_MICROSTATE_ACCT)
 struct sched_info {
 	/* cumulative counters */
 	unsigned long pcount;	      /* # of times run on this cpu */
@@ -1314,7 +1315,8 @@ struct task_struct {
 	struct rt_mutex *rcu_boost_mutex;
 #endif /* #ifdef CONFIG_RCU_BOOST */
 
-#if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT)
+#if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT) || \
+    defined(CONFIG_MICROSTATE_ACCT)
 	struct sched_info sched_info;
 #endif
 
@@ -1392,7 +1394,7 @@ struct task_struct {
 
 	cputime_t utime, stime, utimescaled, stimescaled;
 	cputime_t gtime;
-#ifndef CONFIG_VIRT_CPU_ACCOUNTING
+#if !defined(CONFIG_VIRT_CPU_ACCOUNTING) && !defined(CONFIG_MICROSTATE_ACCT)
 	cputime_t prev_utime, prev_stime;
 #endif
 	unsigned long nvcsw, nivcsw; /* context switch counts */
diff --git a/kernel/fork.c b/kernel/fork.c
index 5977caa..6721136 100644
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -1210,7 +1210,7 @@ static struct task_struct *copy_process(unsigned long clone_flags,
 
 	p->utime = p->stime = p->gtime = 0;
 	p->utimescaled = p->stimescaled = 0;
-#ifndef CONFIG_VIRT_CPU_ACCOUNTING
+#if !defined(CONFIG_VIRT_CPU_ACCOUNTING) && !defined(CONFIG_MICROSTATE_ACCT)
 	p->prev_utime = p->prev_stime = 0;
 #endif
 #if defined(SPLIT_RSS_COUNTING)
diff --git a/kernel/msa.c b/kernel/msa.c
index 72e9eb0..b91da98 100644
--- a/kernel/msa.c
+++ b/kernel/msa.c
@@ -21,6 +21,7 @@
 #include <linux/hardirq.h>
 #include <linux/sched.h>
 #include <linux/jiffies.h>
+#include <linux/kernel_stat.h>
 #include <linux/acct.h>
 #include <linux/tsacct_kern.h>
 #include <linux/proc_fs.h>
@@ -39,6 +40,13 @@ struct msa_irq {
 };
 
 /*
+ * Dummy this out for the moment.
+ */
+void account_process_tick(struct task_struct *p, int user_tick)
+{
+}
+
+/*
  * Time spent in interrupt handlers
  */
 static DEFINE_PER_CPU(struct msa_irq[NR_IRQS + 1], msa_irq);
@@ -69,6 +77,7 @@ void msa_switch(struct task_struct *prev, struct task_struct *next)
 
 	next_msp->timers[next_msp->cur_state] += now - next_msp->last_change;
 	prev_msp->timers[prev_msp->cur_state] += now - prev_msp->last_change;
+	msa_system_time(prev, msa_to_cputime(now - prev_msp->last_change));
 
 	/*
 	 * Update states, state is sort of a bitmask, except that
@@ -195,8 +204,11 @@ out:
  */
 void msa_set_timer(struct task_struct *p, int next_state)
 {
-	struct microstates *msp = &current->microstates;
-	__msa_set_timer(msp, MSA_ONCPU_SYS);
+	struct microstates *msp = &p->microstates;
+	msa_time_t delta;
+
+	delta = __msa_set_timer(msp, MSA_ONCPU_SYS);
+	msa_user_time(p, msa_to_cputime(delta));
 }
 
 /*
@@ -210,8 +222,13 @@ void msa_set_timer(struct task_struct *p, int next_state)
  */
 asmlinkage void msa_kernel(void)
 {
-	struct microstates *msp = &current->microstates;
-	__msa_set_timer(msp, MSA_ONCPU_SYS);
+	struct task_struct *p = current;
+	struct microstates *msp = &p->microstates;
+	msa_time_t delta;
+
+	delta = __msa_set_timer_onswitch(msp, MSA_ONCPU_SYS);
+	if (delta)
+		msa_user_time(p, msa_to_cputime(delta));
 }
 
 /**
@@ -221,8 +238,13 @@ asmlinkage void msa_kernel(void)
  */
 asmlinkage void msa_user(void)
 {
-	struct microstates *msp = &current->microstates;
-	__msa_set_timer(msp, MSA_ONCPU_USER);
+	struct task_struct *p = current;
+	struct microstates *msp = &p->microstates;
+	msa_time_t delta;
+
+	delta = __msa_set_timer_onswitch(msp, MSA_ONCPU_USER);
+	if (delta)
+		msa_system_time(p, msa_to_cputime(delta));
 }
 
 /**
@@ -258,6 +280,10 @@ void msa_start_irq(int irq_id)
 		msa_time_t delta = now - msp->last_change;
 		msp->timers[msp->cur_state] += delta;
 		msp->last_change = now;
+		if (msp->cur_state == MSA_ONCPU_USER)
+			msa_user_time(p, msa_to_cputime(delta));
+		else
+			msa_system_time(p, msa_to_cputime(delta));
 		if (msp->cur_state == MSA_ONCPU_USER
 				|| msp->cur_state == MSA_ONCPU_SYS) {
 			msp->next_state = msp->cur_state;
@@ -310,6 +336,7 @@ void msa_irq_exit(int irq_id, int is_going_to_user)
 {
 	struct task_struct *p = current;
 	struct microstates *msp = &p->microstates;
+	u64 *cpustat = kcpustat_this_cpu->cpustat;
 	msa_time_t now, delta;
 	struct msa_irq *mip;
 	int nested;
@@ -323,6 +350,8 @@ void msa_irq_exit(int irq_id, int is_going_to_user)
 	MSA_NOW(now);
 	delta = now - mip[irq_id].last_entered;
 	mip[irq_id].times += delta;
+	if (!nested)
+		cpustat[CPUTIME_IRQ] +=	msa_to_cputime64(delta);
 
 	irq_exit();
 
@@ -330,6 +359,7 @@ void msa_irq_exit(int irq_id, int is_going_to_user)
 		msa_time_t before = now;
 		MSA_NOW(now);
 		delta = now - before;
+		cpustat[CPUTIME_SOFTIRQ] += msa_to_cputime64(delta);
 		msp->timers[msp->cur_state] += now - msp->last_change;
 		msp->last_change = now;
 		if (is_going_to_user)
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 14b6acb..3e24804 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -2657,32 +2657,6 @@ static inline void task_group_account_field(struct task_struct *p, int index,
 #endif
 }
 
-
-/*
- * Account user cpu time to a process.
- * @p: the process that the cpu time gets accounted to
- * @cputime: the cpu time spent in user space since the last update
- * @cputime_scaled: cputime scaled by cpu frequency
- */
-void account_user_time(struct task_struct *p, cputime_t cputime,
-		       cputime_t cputime_scaled)
-{
-	int index;
-
-	/* Add user time to process. */
-	p->utime += cputime;
-	p->utimescaled += cputime_scaled;
-	account_group_user_time(p, cputime);
-
-	index = (TASK_NICE(p) > 0) ? CPUTIME_NICE : CPUTIME_USER;
-
-	/* Add user time to cpustat. */
-	task_group_account_field(p, index, (__force u64) cputime);
-
-	/* Account for user time used */
-	acct_update_integrals(p);
-}
-
 /*
  * Account guest cpu time to a process.
  * @p: the process that the cpu time gets accounted to
@@ -2710,6 +2684,32 @@ static void account_guest_time(struct task_struct *p, cputime_t cputime,
 	}
 }
 
+#ifndef CONFIG_MICROSTATE_ACCT
+/*
+ * Account user cpu time to a process.
+ * @p: the process that the cpu time gets accounted to
+ * @cputime: the cpu time spent in user space since the last update
+ * @cputime_scaled: cputime scaled by cpu frequency
+ */
+void account_user_time(struct task_struct *p, cputime_t cputime,
+		       cputime_t cputime_scaled)
+{
+	int index;
+
+	/* Add user time to process. */
+	p->utime += cputime;
+	p->utimescaled += cputime_scaled;
+	account_group_user_time(p, cputime);
+
+	index = (TASK_NICE(p) > 0) ? CPUTIME_NICE : CPUTIME_USER;
+
+	/* Add user time to cpustat. */
+	task_group_account_field(p, index, (__force u64) cputime);
+
+	/* Account for user time used */
+	acct_update_integrals(p);
+}
+
 /*
  * Account system cpu time to a process and desired cpustat field
  * @p: the process that the cpu time gets accounted to
@@ -2761,17 +2761,6 @@ void account_system_time(struct task_struct *p, int hardirq_offset,
 }
 
 /*
- * Account for involuntary wait time.
- * @cputime: the cpu time spent in involuntary wait
- */
-void account_steal_time(cputime_t cputime)
-{
-	u64 *cpustat = kcpustat_this_cpu->cpustat;
-
-	cpustat[CPUTIME_STEAL] += (__force u64) cputime;
-}
-
-/*
  * Account for idle time.
  * @cputime: the cpu time spent in idle wait
  */
@@ -2786,6 +2775,83 @@ void account_idle_time(cputime_t cputime)
 		cpustat[CPUTIME_IDLE] += (__force u64) cputime;
 }
 
+#else
+
+/*
+ * In the microstate case we do things a bit differently as irq and softirq
+ * accounting are done separately.  The user version is duplicated under
+ * a different name because invokations with the original name are stubbed
+ * away.
+ */
+
+void msa_user_time(struct task_struct *p, cputime_t cputime)
+{
+	int index;
+	u64 *cpustat;
+
+	preempt_disable();
+	cpustat = kcpustat_this_cpu->cpustat;
+	p->utime = cputime_add(p->utime, cputime);
+	p->utimescaled = cputime_add(p->utimescaled,
+				     cputime_to_scaled(cputime));
+	account_group_user_time(p, cputime);
+
+	/* Add user time to cpustat. */
+	index = (TASK_NICE(p) > 0) ? CPUTIME_NICE : CPUTIME_USER;
+	task_group_account_field(p, index, (__force u64) cputime);
+	preempt_enable();
+
+	/* Account for user time used */
+	acct_update_integrals(p);
+}
+
+void msa_system_time(struct task_struct *p, cputime_t cputime)
+{
+	u64 *cpustat;
+	cputime_t cputime_scaled = cputime_to_scaled(cputime);
+	struct rq *rq = this_rq();
+	cputime64_t tmp;
+
+	preempt_disable();
+
+	if ((p->flags & PF_VCPU) && (irq_count() - HARDIRQ_OFFSET == 0)) {
+		account_guest_time(p, cputime, cputime_scaled);
+		preempt_enable();
+		return;
+	}
+
+	cpustat = kcpustat_this_cpu->cpustat;
+	p->stime = cputime_add(p->stime, cputime);
+	p->stimescaled = cputime_add(p->stimescaled, cputime_scaled);
+	account_group_system_time(p, cputime);
+
+	/* Add system time to cpustat. */
+	tmp = cputime_to_cputime64(cputime);
+	if (p != rq->idle)
+		cpustat[CPUTIME_SYSTEM] += tmp;
+	else if (atomic_read(&rq->nr_iowait) > 0)
+		cpustat[CPUTIME_IOWAIT] += tmp;
+	else
+		cpustat[CPUTIME_IDLE] += tmp;
+	preempt_enable();
+
+	/* Account for system time used */
+	acct_update_integrals(p);
+}
+
+#endif  /* CONFIG_MICROSTATE_ACCT */
+
+/*
+ * Account for involuntary wait time.
+ * @cputime: the cpu time spent in involuntary wait
+ */
+void account_steal_time(cputime_t cputime)
+{
+	u64 *cpustat = kcpustat_this_cpu->cpustat;
+
+	cpustat[CPUTIME_STEAL] += (__force u64) cputime;
+}
+
 static __always_inline bool steal_account_process_tick(void)
 {
 #ifdef CONFIG_PARAVIRT
@@ -2805,7 +2871,7 @@ static __always_inline bool steal_account_process_tick(void)
 	return false;
 }
 
-#ifndef CONFIG_VIRT_CPU_ACCOUNTING
+#if !defined(CONFIG_VIRT_CPU_ACCOUNTING) && !defined(CONFIG_MICROSTATE_ACCT)
 
 #ifdef CONFIG_IRQ_TIME_ACCOUNTING
 /*
@@ -2928,12 +2994,12 @@ void account_idle_ticks(unsigned long ticks)
 	account_idle_time(jiffies_to_cputime(ticks));
 }
 
-#endif
+#endif /*!defined(CONFIG_VIRT_CPU_ACCOUNTING) && !defined(CONFIG_MICROSTATE_ACCT) */
 
 /*
  * Use precise platform statistics if available:
  */
-#ifdef CONFIG_VIRT_CPU_ACCOUNTING
+#if defined(CONFIG_VIRT_CPU_ACCOUNTING) || defined(CONFIG_MICROSTATE_ACCT)
 void task_times(struct task_struct *p, cputime_t *ut, cputime_t *st)
 {
 	*ut = p->utime;
@@ -3012,7 +3078,7 @@ void thread_group_times(struct task_struct *p, cputime_t *ut, cputime_t *st)
 	*ut = sig->prev_utime;
 	*st = sig->prev_stime;
 }
-#endif
+#endif /* defined(CONFIG_VIRT_CPU_ACCOUNTING) || defined(CONFIG_MICROSTATE_ACCT) */
 
 /*
  * This function gets called by the timer code, with HZ frequency.
diff --git a/kernel/sched/stats.h b/kernel/sched/stats.h
index 2ef90a5..0cd14fd 100644
--- a/kernel/sched/stats.h
+++ b/kernel/sched/stats.h
@@ -47,7 +47,8 @@ rq_sched_info_depart(struct rq *rq, unsigned long long delta)
 # define schedstat_set(var, val)	do { } while (0)
 #endif
 
-#if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT)
+#if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT) || \
+    defined(CONFIG_MICROSTATE_ACCT)
 static inline void sched_info_reset_dequeued(struct task_struct *t)
 {
 	t->sched_info.last_queued = 0;
@@ -68,6 +69,9 @@ static inline void sched_info_dequeued(struct task_struct *t)
 			delta = now - t->sched_info.last_queued;
 	sched_info_reset_dequeued(t);
 	t->sched_info.run_delay += delta;
+#ifdef MICROSTATE_ACCT_USING_SCHED_CLOCK
+	t->microstates.last_change += delta;
+#endif
 
 	rq_sched_info_dequeued(task_rq(t), delta);
 }
diff --git a/kernel/time.c b/kernel/time.c
index ba744cf..4227651 100644
--- a/kernel/time.c
+++ b/kernel/time.c
@@ -667,6 +667,7 @@ u64 nsecs_to_jiffies64(u64 n)
 	return div_u64(n * 9, (9ull * NSEC_PER_SEC + HZ / 2) / HZ);
 #endif
 }
+EXPORT_SYMBOL(nsec_to_clock_t);
 
 /**
  * nsecs_to_jiffies - Convert nsecs in u64 to jiffies
diff --git a/kernel/time/tick-sched.c b/kernel/time/tick-sched.c
index 6a3a5b9..c4bdc8f 100644
--- a/kernel/time/tick-sched.c
+++ b/kernel/time/tick-sched.c
@@ -551,7 +551,7 @@ void tick_nohz_idle_exit(void)
 {
 	int cpu = smp_processor_id();
 	struct tick_sched *ts = &per_cpu(tick_cpu_sched, cpu);
-#ifndef CONFIG_VIRT_CPU_ACCOUNTING
+#if !defined(CONFIG_VIRT_CPU_ACCOUNTING) && !defined(CONFIG_MICROSTATE_ACCT)
 	unsigned long ticks;
 #endif
 	ktime_t now;
@@ -577,7 +577,7 @@ void tick_nohz_idle_exit(void)
 	select_nohz_load_balancer(0);
 	tick_do_update_jiffies64(now);
 
-#ifndef CONFIG_VIRT_CPU_ACCOUNTING
+#if !defined(CONFIG_VIRT_CPU_ACCOUNTING) && !defined(CONFIG_MICROSTATE_ACCT)
 	/*
 	 * We stopped the tick in idle. Update process times would miss the
 	 * time we slept as update_process_times does only a 1 tick
-- 
1.7.9.7

