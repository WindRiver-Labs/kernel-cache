From 61b4b421405de7c7e6837206a30bf601fd18e338 Mon Sep 17 00:00:00 2001
From: reshmic <reshmic@broadcom.com>
Date: Thu, 8 Mar 2012 13:39:41 +0530
Subject: [PATCH 1490/1532] Support for 32 bit kernel and fragments in sae
 module

[Based on SDK 3.2]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 drivers/crypto/sae/nlm_aead.c   |  66 +++++++++++++++++-----
 drivers/crypto/sae/nlm_auth.c   | 122 ++++++++++++++++++++++++----------------
 drivers/crypto/sae/nlm_crypto.c |   8 +--
 drivers/crypto/sae/nlm_enc.c    |  19 +++++--
 4 files changed, 144 insertions(+), 71 deletions(-)

diff --git a/drivers/crypto/sae/nlm_aead.c b/drivers/crypto/sae/nlm_aead.c
index 9754170..5b639b2 100755
--- a/drivers/crypto/sae/nlm_aead.c
+++ b/drivers/crypto/sae/nlm_aead.c
@@ -72,8 +72,8 @@ struct nlm_aead_ctx
 	struct crypto_aead  * fallback;
 };
 
-#define MAX_FRAGS		18
-#define CTRL_DESC_SIZE		(sizeof(struct nlm_aead_ctx) + 128)
+#define MAX_FRAGS		0xfff	
+#define CTRL_DESC_SIZE		(sizeof(struct nlm_aead_ctx) + 64)
 #define DES3_CTRL_DESC_SIZE	(2*CTRL_DESC_SIZE + 2*64)	//Allocate 2 separate control desc for encryption and decryption
 #define CACHE_ALIGN		64
 #define IV_AEAD_PADDING         128
@@ -88,8 +88,8 @@ struct nlm_aead_ctx
  */
 
 #define PACKET_DESC_SIZE	(CACHE_ALIGN + sizeof(struct nlm_crypto_pkt_param) + MAX_FRAGS*(2*CACHE_ALIGN) + CACHE_ALIGN + sizeof(struct nlm_async_crypto) + IV_AEAD_PADDING + TAG_LEN)
-#define NLM_CRYPTO_PKT_PARAM_OFFSET(addr)	(((unsigned long)addr + CACHE_ALIGN ) & ~0x3fULL)
-#define NLM_ASYNC_PTR_PARAM_OFFSET(addr)	(((unsigned long)(addr + CACHE_ALIGN + sizeof(struct nlm_crypto_pkt_param) + MAX_FRAGS*(2*CACHE_ALIGN)) + CACHE_ALIGN) & ~0x3fULL)
+#define NLM_CRYPTO_PKT_PARAM_OFFSET(addr)	(((unsigned long)addr + CACHE_ALIGN ) & ~0x3fUL)
+#define NLM_ASYNC_PTR_PARAM_OFFSET(addr)	(((unsigned long)(addr + CACHE_ALIGN + sizeof(struct nlm_crypto_pkt_param) + MAX_FRAGS*(2*CACHE_ALIGN)) + CACHE_ALIGN) & ~0x3fUL)
 #define NLM_HASH_OFFSET(addr)			((unsigned long)addr + (PACKET_DESC_SIZE - TAG_LEN))
 #define NLM_IV_OFFSET(addr)			((unsigned long)addr + (PACKET_DESC_SIZE - TAG_LEN - IV_AEAD_PADDING ))
 
@@ -144,12 +144,12 @@ static void print_buf(unsigned char *msg, unsigned char *buf, int len)
 
 static struct nlm_aead_ctx *nlm_crypto_aead_ctx(struct crypto_aead *tfm)
 {
-	return (struct nlm_aead_ctx *)(((unsigned long)((uint8_t *)crypto_aead_ctx(tfm) + 63)) & ~(0x3f));
+	return (struct nlm_aead_ctx *)(((unsigned long)((uint8_t *)crypto_aead_ctx(tfm) + 63)) & ~(0x3fUL));
 }
 
 static struct nlm_aead_ctx *nlm_crypto_tfm_ctx(struct crypto_tfm *tfm)
 {
-	return (struct nlm_aead_ctx *)(((unsigned long)((uint8_t *)crypto_tfm_ctx(tfm) + 63)) & ~(0x3f));
+	return (struct nlm_aead_ctx *)(((unsigned long)((uint8_t *)crypto_tfm_ctx(tfm) + 63)) & ~(0x3fUL));
 }
 
 
@@ -392,7 +392,7 @@ static int xlp_aes_ctr_setkey( struct crypto_aead *tfm, u8 *key,
 static int  xlp_3des_setkey(struct crypto_aead *tfm, u8 *key, unsigned int keylen, int hash, int mode,uint16_t h_stat )
 {
 	struct nlm_aead_ctx *ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
-	struct nlm_aead_ctx * nlm_ctx = (struct  nlm_aead_ctx *)(( unsigned long )(( uint8_t *)ctx + CTRL_DESC_SIZE + 63) & ~(0x3f));
+	struct nlm_aead_ctx * nlm_ctx = (struct  nlm_aead_ctx *)(( unsigned long )(( uint8_t *)ctx + CTRL_DESC_SIZE + 63) & ~(0x3fUL));
         unsigned int cipher_keylen=0, auth_keylen=0;
 	struct nlm_crypto_pkt_ctrl *ctrl = &ctx->ctrl;
         int ret;
@@ -808,6 +808,7 @@ static int aead_crypt_gcm(struct aead_request *req, unsigned int op)
 	struct nlm_crypto_pkt_ctrl *ctrl = &ctx->ctrl;
 	char * iv = (uint8_t *)NLM_IV_OFFSET(aead_request_ctx(req)); 
 	uint8_t *tmp_iv = iv;
+	unsigned long msgrng_flags;
 
 	authsize = crypto_aead_crt(crt->base)->authsize;
 	maxauthsize= aead->maxauthsize;
@@ -815,7 +816,6 @@ static int aead_crypt_gcm(struct aead_request *req, unsigned int op)
 	if ( (op &&  (req->cryptlen == 0 )) || (!op && req->cryptlen <= aead->maxauthsize))
 	{
 		int ret =0;
-		struct crypto_aead *tfm = req->base.tfm;
 		ret = crypto_aead_setauthsize(ctx->fallback, authsize);
 		aead_request_set_tfm(req, ctx->fallback);
 		if ( op )
@@ -870,7 +870,11 @@ static int aead_crypt_gcm(struct aead_request *req, unsigned int op)
 
 	seg += nr_enc_frags;
 
-
+	if ( seg > MAX_FRAGS) {
+		printk("fragments exceeded 0xfff. Cannot handle this\n");
+		return 0;
+	}
+		
 	nlm_crypto_fill_cipher_auth_pkt_param(ctrl, param, op, hash_source, iv_off, 
 		iv_size, auth_off, auth_len, 0, cipher_off, cipher_len, hash_addr);
 	
@@ -903,7 +907,9 @@ static int aead_crypt_gcm(struct aead_request *req, unsigned int op)
 	tx_id = (uint64_t)async;
 
 	//construct pkt, send to engine and receive reply
+	msgrng_access_enable(msgrng_flags);
 	err = nlm_hal_send_msg3(crypto_vc_base, 0 /*code */ , entry0, entry1, tx_id);
+	msgrng_access_disable(msgrng_flags);
 	if(err){
 		printk("err\n");
 		return -EIO;
@@ -941,6 +947,7 @@ static int aead_crypt_ccm(struct aead_request *req, unsigned int op)
 	int seg = 0;
 	int nr_enc_frags;
 	uint8_t *tmp_iv = &iv[1];
+	unsigned long msgrng_flags;
 	param = (struct nlm_crypto_pkt_param *)NLM_CRYPTO_PKT_PARAM_OFFSET(aead_request_ctx(req));
 	hash_addr = (uint8_t *)NLM_HASH_OFFSET(aead_request_ctx(req));
 
@@ -950,7 +957,6 @@ static int aead_crypt_ccm(struct aead_request *req, unsigned int op)
 	if ( (op &&  (req->cryptlen == 0 )) || (!op && req->cryptlen <= aead->maxauthsize))
 	{
 		int ret =0;
-		struct crypto_aead *tfm = req->base.tfm;
 		ret = crypto_aead_setauthsize(ctx->fallback, authsize);
 		aead_request_set_tfm(req, ctx->fallback);
 		if ( op )
@@ -1064,6 +1070,11 @@ static int aead_crypt_ccm(struct aead_request *req, unsigned int op)
 		seg++;
 	}
 	auth_len = cipher_off + cipher_len - 16 + extralen; 
+	
+	if ( seg > MAX_FRAGS) {
+		printk("fragments exceeded 0xfff. Cannot handle this\n");
+		return 0;
+	}
 
 	nlm_crypto_fill_cipher_auth_pkt_param(ctrl, param, op, hash_source, iv_off,
 			iv_size, auth_off, auth_len, 0, cipher_off, cipher_len, hash_addr);
@@ -1098,7 +1109,9 @@ static int aead_crypt_ccm(struct aead_request *req, unsigned int op)
 	tx_id = (uint64_t)async;
 
 	//construct pkt, send to engine and receive reply
+	msgrng_access_enable(msgrng_flags);
 	err = nlm_hal_send_msg3(crypto_vc_base, 0 /*code */ , entry0, entry1, tx_id);
+	msgrng_access_disable(msgrng_flags);
 	if(err){
 		printk("err\n");
 		return -EIO;
@@ -1132,7 +1145,8 @@ static int aead_crypt_ctr(struct aead_request *req, unsigned int op)
 	unsigned int authsize,maxauthsize;
 	uint8_t *iv = (uint8_t *)NLM_IV_OFFSET(addr); 
 	struct nlm_crypto_pkt_ctrl *ctrl = &ctx->ctrl;
-	
+	unsigned long msgrng_flags;
+
 	authsize = crypto_aead_crt(crt->base)->authsize;
 	maxauthsize= aead->maxauthsize;
 
@@ -1183,6 +1197,11 @@ static int aead_crypt_ctr(struct aead_request *req, unsigned int op)
 
 	seg += nr_enc_frags;
 
+	if ( seg > MAX_FRAGS) {
+		printk("fragments exceeded 0xfff. Cannot handle this\n");
+		return 0;
+	}
+
 	nlm_crypto_fill_cipher_auth_pkt_param(ctrl, param, op, op, iv_off, 
 			CTR_RFC3686_BLOCK_SIZE, auth_off, auth_len, 0, cipher_off, cipher_len, hash_addr);
 	
@@ -1216,7 +1235,9 @@ static int aead_crypt_ctr(struct aead_request *req, unsigned int op)
 	tx_id = (uint64_t)async;
 
 	//construct pkt, send to engine and receive reply
+	msgrng_access_enable(msgrng_flags);
 	err = nlm_hal_send_msg3(crypto_vc_base, 0 /*code */ , entry0, entry1, tx_id);
+	msgrng_access_disable(msgrng_flags);
 	if(err){
 		return -EIO;
 	}
@@ -1247,7 +1268,8 @@ static int aead_crypt_3des(struct aead_request *req, unsigned int op)
 	uint8_t *new_iv_ptr_lo = NULL;
 	uint8_t *new_iv_ptr_hi = NULL;
 	struct nlm_crypto_pkt_ctrl *ctrl = NULL;
-	ctx = (struct  nlm_aead_ctx *)(( unsigned long )(( uint8_t *)ctx + CTRL_DESC_SIZE + 63) & ~(0x3f));
+	unsigned long msgrng_flags;
+	ctx = (struct  nlm_aead_ctx *)(( unsigned long )(( uint8_t *)ctx + CTRL_DESC_SIZE + 63) & ~(0x3fUL));
 	ctrl = &ctx->ctrl;
 	
 	authsize = crypto_aead_crt(crt->base)->authsize;
@@ -1305,6 +1327,11 @@ static int aead_crypt_3des(struct aead_request *req, unsigned int op)
 
 	seg += nr_enc_frags;
 
+	if ( seg > MAX_FRAGS) {
+		printk("fragments exceeded 0xfff. Cannot handle this\n");
+		return 0;
+	}
+
 	nlm_crypto_fill_cipher_auth_pkt_param(ctrl, param, op, op, iv_off, 
 			ivsize, auth_off, auth_len, 0, cipher_off, cipher_len, hash_addr);
 	
@@ -1337,7 +1364,9 @@ static int aead_crypt_3des(struct aead_request *req, unsigned int op)
 	tx_id = (uint64_t)async;
 
 	//construct pkt, send to engine and receive reply
+	msgrng_access_enable(msgrng_flags);
 	err = nlm_hal_send_msg3(crypto_vc_base, 0 /*code */ , entry0, entry1, tx_id);
+	msgrng_access_disable(msgrng_flags);
 	if(err){
 		printk("err\n");
 		return -EIO;
@@ -1369,7 +1398,8 @@ static int aead_crypt(struct aead_request *req, unsigned int op)
 	uint8_t *new_iv_ptr_lo = NULL;
 	uint8_t *new_iv_ptr_hi = NULL;
 	struct nlm_crypto_pkt_ctrl *ctrl = &ctx->ctrl;
-	
+	unsigned long msgrng_flags;
+
 	authsize = crypto_aead_crt(crt->base)->authsize;
 	maxauthsize= aead->maxauthsize;
 
@@ -1425,6 +1455,11 @@ static int aead_crypt(struct aead_request *req, unsigned int op)
 
 	seg += nr_enc_frags;
 
+	if ( seg > MAX_FRAGS) {
+		printk("fragments exceeded 0xfff. Cannot handle this\n");
+		return 0;
+	}
+
 	nlm_crypto_fill_cipher_auth_pkt_param(ctrl, param, op, op, iv_off, 
 			ivsize, auth_off, auth_len, 0, cipher_off, cipher_len, hash_addr);
 	
@@ -1456,8 +1491,11 @@ static int aead_crypt(struct aead_request *req, unsigned int op)
 	async->bytes = req->cryptlen; 
 	tx_id = (uint64_t)async;
 
+
 	//construct pkt, send to engine and receive reply
+	msgrng_access_enable(msgrng_flags);
 	err = nlm_hal_send_msg3(crypto_vc_base, 0 /*code */ , entry0, entry1, tx_id);
+	msgrng_access_disable(msgrng_flags);
 	if(err){
 		printk("err\n");
 		return -EIO;
@@ -2053,7 +2091,7 @@ static struct crypto_alg xlp_aes_ctr_hmac_md5_cipher_auth = {
 int xlp_aead_alg_init(void)
 {
 	int ret = 0;
-	
+
 	if ((ret = crypto_register_alg(&xlp_aes_cbc_hmac_sha256_cipher_auth)))
 		goto end;
 	no_of_alg_registered++;
diff --git a/drivers/crypto/sae/nlm_auth.c b/drivers/crypto/sae/nlm_auth.c
index 693e4cf..aec0088 100644
--- a/drivers/crypto/sae/nlm_auth.c
+++ b/drivers/crypto/sae/nlm_auth.c
@@ -28,6 +28,7 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #include <crypto/internal/hash.h>
 #include "nlmcrypto.h"
 #include "nlm_async.h"
+#include <asm/netlogic/msgring.h>
 
 #define XLP_AUTH_PRIORITY      300
 #define XLP_HMAC_PRIORITY      300
@@ -79,19 +80,16 @@ struct nlm_auth_ctx
 
 struct auth_pkt_desc
 {
-	uint32_t curr_index;
-	uint32_t total_len;
-	uint8_t pad[56];
-	struct nlm_crypto_pkt_param pkt_param; 
+	uint16_t curr_index;
+	uint16_t total_len;
 	uint16_t stat;
-	/*maintain shash_desc at the end*/
-	struct shash_desc fallback;
-	
+	struct shash_desc * fallback;
+	struct nlm_crypto_pkt_param * pkt_param; /* maintain at the end */ 
 };
 
-#define PACKET_DESC_SIZE   (64+sizeof(struct auth_pkt_desc) + MAX_FRAGS*(2*64) + 64 + sizeof(struct nlm_async_crypto) + 64)
-#define NLM_CRYPTO_PKT_PARAM_OFFSET(addr)       (((unsigned long)addr + 64) & ~0x3fULL)
-#define NLM_ASYNC_PTR_PARAM_OFFSET(addr)        (((unsigned long)(addr + 64 + sizeof(struct nlm_crypto_pkt_param) + MAX_FRAGS*(2*64)) + 64) & ~0x3fULL)
+#define PACKET_DESC_SIZE   (64+sizeof(struct auth_pkt_desc) + MAX_FRAGS*(2*64) ) /* should be less than PAGE_SIZE/8 */ 
+#define NLM_CRYPTO_PKT_PARAM_OFFSET(addr)       (((unsigned long)addr + 64) & ~0x3fUL)
+#define NLM_ASYNC_PTR_PARAM_OFFSET(addr)        (((unsigned long)(addr + 64 + sizeof(struct nlm_crypto_pkt_param) + MAX_FRAGS*(2*64)) + 64) & ~0x3fUL)
 /*
    All extern declaration goes here.
  */
@@ -138,7 +136,7 @@ static void print_buf(unsigned char *msg, unsigned char *buf, int len)
 static struct nlm_auth_ctx *nlm_shash_auth_ctx(struct crypto_shash *shash)
 {
 	uint8_t *ctx = crypto_tfm_ctx(crypto_shash_tfm(shash));
-	ctx = (uint8_t *)(((unsigned long)ctx + 63) & ~(0x3f));
+	ctx = (uint8_t *)(((unsigned long)ctx + 63) & ~(0x3fUL));
 	return (struct nlm_auth_ctx *)ctx;
 }
 
@@ -153,7 +151,6 @@ xlp_cra_xcbc_init(struct crypto_tfm *tfm)
 	struct crypto_shash * hash = __crypto_shash_cast(tfm);
 	struct nlm_auth_ctx * nlm_ctx = nlm_shash_auth_ctx(hash);
 	nlm_ctx->fallback_tfm = crypto_alloc_shash("xcbc(aes-generic)",CRYPTO_ALG_TYPE_SHASH ,0 );
-	hash->descsize += crypto_shash_descsize(nlm_ctx->fallback_tfm);
 	return 0;
 }
 
@@ -163,7 +160,6 @@ xlp_cra_hmac_sha1_init(struct crypto_tfm *tfm)
 	struct crypto_shash * hash = __crypto_shash_cast(tfm);
 	struct nlm_auth_ctx * nlm_ctx = nlm_shash_auth_ctx(hash);
 	nlm_ctx->fallback_tfm = crypto_alloc_shash("hmac(sha1-generic)",CRYPTO_ALG_TYPE_SHASH ,0 );
-	hash->descsize += crypto_shash_descsize(nlm_ctx->fallback_tfm);
 	return 0;
 }
 static int
@@ -172,7 +168,6 @@ xlp_cra_hmac_sha256_init(struct crypto_tfm *tfm)
 	struct crypto_shash * hash = __crypto_shash_cast(tfm);
 	struct nlm_auth_ctx * nlm_ctx = nlm_shash_auth_ctx(hash);
 	nlm_ctx->fallback_tfm = crypto_alloc_shash("hmac(sha256-generic)",CRYPTO_ALG_TYPE_SHASH ,0 );
-	hash->descsize += crypto_shash_descsize(nlm_ctx->fallback_tfm);
 	return 0;
 }
 
@@ -182,38 +177,46 @@ xlp_cra_md5_init(struct crypto_tfm *tfm)
 	struct crypto_shash * hash = __crypto_shash_cast(tfm);
 	struct nlm_auth_ctx * nlm_ctx = nlm_shash_auth_ctx(hash);
 	nlm_ctx->fallback_tfm = crypto_alloc_shash("hmac(md5-generic)",CRYPTO_ALG_TYPE_SHASH ,0 );
-	hash->descsize += crypto_shash_descsize(nlm_ctx->fallback_tfm);
 	
 	return 0;
 }
 static int
 xlp_auth_init(struct shash_desc *desc)
 {
-	struct auth_pkt_desc *auth_pkt_desc = (struct auth_pkt_desc * )NLM_CRYPTO_PKT_PARAM_OFFSET(shash_desc_ctx(desc));
-	struct nlm_auth_ctx * nlm_ctx = nlm_shash_auth_ctx(desc->tfm);
-	auth_pkt_desc->fallback.tfm = nlm_ctx->fallback_tfm;
-	auth_pkt_desc->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP; 
-	crypto_shash_init(&auth_pkt_desc->fallback);
-
+	struct auth_pkt_desc *auth_pkt_desc = (struct auth_pkt_desc * )shash_desc_ctx(desc);
 	auth_pkt_desc->curr_index = 0;
 	auth_pkt_desc->total_len = 0;
+	auth_pkt_desc->fallback = NULL;
+	auth_pkt_desc->pkt_param = NLM_CRYPTO_PKT_PARAM_OFFSET((unsigned long )auth_pkt_desc + sizeof(struct auth_pkt_desc ));
 	return 0;
 }
 static int
 xlp_auth_update(struct shash_desc *desc,
 		const uint8_t * data, unsigned int length)
 {
-	struct auth_pkt_desc *auth_pkt_desc = (struct auth_pkt_desc *)NLM_CRYPTO_PKT_PARAM_OFFSET(shash_desc_ctx(desc));
+	struct auth_pkt_desc *auth_pkt_desc = (struct auth_pkt_desc *)shash_desc_ctx(desc);
 	struct nlm_auth_ctx * nlm_ctx = nlm_shash_auth_ctx(desc->tfm);
 	int index = auth_pkt_desc->curr_index;
 	unsigned char * data_index = &nlm_ctx->data[auth_pkt_desc->total_len];
 	struct nlm_crypto_pkt_param  *pkt_param  = &(auth_pkt_desc->pkt_param);
 
-	crypto_shash_update(&auth_pkt_desc->fallback,data,length);
 	auth_pkt_desc->total_len += length;
-
-	if ( auth_pkt_desc->total_len > MAX_AUTH_DATA)
+	if ( (auth_pkt_desc->total_len >= MAX_AUTH_DATA) || (index >= MAX_FRAGS)) {
+		if (auth_pkt_desc->fallback == NULL ) {
+			auth_pkt_desc->fallback = kmalloc((sizeof(struct shash_desc ) + 
+				crypto_shash_descsize(nlm_ctx->fallback_tfm))
+									,GFP_KERNEL);
+			auth_pkt_desc->fallback->tfm = nlm_ctx->fallback_tfm;
+			auth_pkt_desc->fallback->flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;
+			crypto_shash_init(auth_pkt_desc->fallback);
+			auth_pkt_desc->total_len -= length;
+			crypto_shash_update(auth_pkt_desc->fallback,nlm_ctx->data,auth_pkt_desc->total_len);
+			auth_pkt_desc->total_len += length;
+		}
+		crypto_shash_update(auth_pkt_desc->fallback,data,length);
+		
 		return 0;
+	}
 
 	memcpy(data_index,data,length);
 	nlm_crypto_fill_src_seg(pkt_param, index, data_index, length);
@@ -236,33 +239,50 @@ crypto_get_sync_fb_vc(void)
 static int
 xlp_auth_final(struct shash_desc *desc, uint8_t *out)
 {
-	struct auth_pkt_desc *auth_pkt_desc = (struct auth_pkt_desc *)NLM_CRYPTO_PKT_PARAM_OFFSET(shash_desc_ctx(desc));
+	struct auth_pkt_desc *auth_pkt_desc = (struct auth_pkt_desc *)shash_desc_ctx(desc);
 	int index = auth_pkt_desc->curr_index;
 	struct nlm_crypto_pkt_param  *pkt_param  = &(auth_pkt_desc->pkt_param);
 	struct nlm_auth_ctx  * auth_ctx   = pkt_ctrl_auth_ctx(desc);
 	int fb_vc ;
-	uint64_t entry0, entry1, tx_id=0x12345678;
+	uint64_t entry0, entry1, tx_id=0x12345678ULL;
 	uint64_t  timeout = 0;
 	struct nlm_crypto_pkt_ctrl *ctrl = &auth_ctx->ctrl;
 	uint32_t size,code,src;
 	uint16_t stat = auth_ctx->stat;
 	int cpu = hard_smp_processor_id();
         extern int ipsec_sync_vc;
-
-	if ( (auth_pkt_desc->total_len == 0 ) ||  ( auth_pkt_desc->total_len > MAX_AUTH_DATA)){
-		crypto_shash_final(&auth_pkt_desc->fallback,out);
+	unsigned long msgrng_flags;
+
+	if ( (auth_pkt_desc->total_len == 0 ) ||  ( auth_pkt_desc->total_len > MAX_AUTH_DATA) 
+						|| (index >=  MAX_FRAGS)){
+		if (auth_pkt_desc->fallback == NULL ) {
+			auth_pkt_desc->fallback = kmalloc((sizeof(struct shash_desc ) + 
+				crypto_shash_descsize(auth_ctx->fallback_tfm))
+									,GFP_KERNEL);
+			auth_pkt_desc->fallback->tfm = auth_ctx->fallback_tfm;
+			auth_pkt_desc->fallback->flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;
+			crypto_shash_init(auth_pkt_desc->fallback);
+		}
+		
+		crypto_shash_final(auth_pkt_desc->fallback,out);
 		return 0;
 	}
+	if ( auth_pkt_desc->fallback != NULL ) {
+		kfree(auth_pkt_desc->fallback);
+		auth_pkt_desc->fallback = NULL;
+	}
 		
 	nlm_crypto_fill_auth_pkt_param(ctrl,pkt_param,
 			0,auth_pkt_desc->total_len,0,out); 
 
 	preempt_disable();
+	msgrng_access_enable(msgrng_flags);
 
 	fb_vc = crypto_get_sync_fb_vc();
 	entry0 = nlm_crypto_form_pkt_fmn_entry0(fb_vc, 0, 0, 0, virt_to_phys(ctrl));
 	entry1 = nlm_crypto_form_pkt_fmn_entry1(0, ctrl->hashkeylen, (32 + index * 16 ), virt_to_phys(pkt_param));
 	
+	while (nlm_hal_send_msg3(crypto_vc_base, 0 /*code */ , entry0, entry1, tx_id) != 0 );
 
 #ifdef NLM_CRYPTO_DEBUG
 	print_crypto_msg_desc(entry0, entry1, tx_id);
@@ -271,40 +291,45 @@ xlp_auth_final(struct shash_desc *desc, uint8_t *out)
 #endif
 
 	//construct pkt, send to engine and receive reply
-	xlp_message_send_block_fast_3(0, crypto_vc_base, entry0, entry1, tx_id);
 	timeout = 0;
 	do {
 		timeout++;
 		nlm_hal_recv_msg2(ipsec_sync_vc, &src, &size, &code, &entry0, &entry1);
-	} while(entry0 != tx_id && timeout < 0xffffffff) ;
+	} while(entry0 != tx_id && timeout < 0xffffffffULL) ;
 	
 
-
-	if (timeout >= 0xffffffff) {
-		printk("Error: FreeBack message is not received");
+	if (timeout >= 0xffffffffULL) {
+		printk("\nError: FreeBack message is not received");
+		msgrng_access_disable(msgrng_flags);
 		preempt_enable();
 		return -EIO;
 	}
 #ifdef NLM_CRYPTO_DEBUG
 	print_buf("AUTH:", out, 16);
 #endif
+	msgrng_access_disable(msgrng_flags);
+	preempt_enable();
 	crypto_stat[cpu].auth[stat] ++;
 	crypto_stat[cpu].auth_tbytes[stat] += auth_pkt_desc->total_len + ctrl->taglen;
-	preempt_enable();
  	return 0;
 }
 static int xlp_auth_export(struct shash_desc *desc, void *out)
 {
-	struct auth_pkt_desc *auth_pkt_desc = (struct auth_pkt_desc *)NLM_CRYPTO_PKT_PARAM_OFFSET(shash_desc_ctx(desc));
-	return crypto_shash_export(&auth_pkt_desc->fallback,out);
+	struct auth_pkt_desc *auth_pkt_desc = (struct auth_pkt_desc *)shash_desc_ctx(desc);
+	if ( auth_pkt_desc->fallback == NULL )
+		return 0;
+	return crypto_shash_export(auth_pkt_desc->fallback,out);
 }
 
-static int xlp_auth_import(struct shash_desc *desc, const void *in) 
+static int xlp_auth_import(struct shash_desc *desc, const void *in)
 {
-	struct auth_pkt_desc *auth_pkt_desc = (struct auth_pkt_desc *)NLM_CRYPTO_PKT_PARAM_OFFSET(shash_desc_ctx(desc));
-	return crypto_shash_import(&auth_pkt_desc->fallback, in);
+	struct auth_pkt_desc *auth_pkt_desc = (struct auth_pkt_desc *)shash_desc_ctx(desc);
+	if ( auth_pkt_desc->fallback == NULL )
+		return 0;
+	return crypto_shash_import(auth_pkt_desc->fallback, in);
 }
 
+
 /*
    All Setkey goes here.
  */
@@ -316,15 +341,16 @@ int hash_key(int alg, int mode, const uint8_t * key, unsigned int keylen, uint8_
 	uint64_t entry0,entry1;
 	uint32_t size,code,src;
         extern int ipsec_sync_vc;
-	uint64_t tx_id=0x12345678;
+	uint64_t tx_id=0x12345678ULL;
 	uint64_t  timeout = 0;
+	unsigned long msgrng_flags;
 	char * tmp = kmalloc(keylen + sizeof(struct nlm_crypto_pkt_ctrl) + sizeof( struct nlm_crypto_pkt_param ) 
 											+ 128, GFP_KERNEL);
-	struct nlm_crypto_pkt_ctrl * ctrl = (struct nlm_crypto_pkt_ctrl * ) ((((unsigned long)tmp + 63)) & ~(0x3f)); 
+	struct nlm_crypto_pkt_ctrl * ctrl = (struct nlm_crypto_pkt_ctrl * ) ((((unsigned long)tmp + 63)) & ~(0x3fUL)); 
 	struct nlm_crypto_pkt_param * pkt_param = (struct nlm_crypto_pkt_param * )
-		(((unsigned long) ctrl + sizeof(struct nlm_crypto_pkt_ctrl) + 63) & ~(0x3f));
+		(((unsigned long) ctrl + sizeof(struct nlm_crypto_pkt_ctrl) + 63) & ~(0x3fUL));
 	char *tmp_key = (char *)(((unsigned long) pkt_param + 
-			sizeof(struct nlm_crypto_pkt_param ) + 63)  & ~(0x3f));
+			sizeof(struct nlm_crypto_pkt_param ) + 63)  & ~(0x3fUL));
 
 	memcpy(tmp_key,key,keylen);
         nlm_crypto_fill_pkt_ctrl(ctrl,0,alg,mode,0,0,0,NULL,0,NULL,0);
@@ -332,8 +358,8 @@ int hash_key(int alg, int mode, const uint8_t * key, unsigned int keylen, uint8_
         nlm_crypto_fill_src_seg(pkt_param,0,tmp_key,keylen);
         nlm_crypto_fill_dst_seg(pkt_param,0,tmp_key,keylen);
 
-	preempt_disable();
 
+	msgrng_access_enable(msgrng_flags);
         fb_vc = crypto_get_sync_fb_vc();
         entry0 = nlm_crypto_form_pkt_fmn_entry0(fb_vc, 0, 0, 0, virt_to_phys(ctrl));
         entry1 = nlm_crypto_form_pkt_fmn_entry1(0, 0, (32 + 16 ), virt_to_phys(pkt_param));
@@ -351,9 +377,9 @@ int hash_key(int alg, int mode, const uint8_t * key, unsigned int keylen, uint8_
         do {
                 timeout++;
                 nlm_hal_recv_msg2(ipsec_sync_vc, &src, &size, &code, &entry0, &entry1);
-        } while(entry0 != tx_id && timeout < 0xffffffff) ;
-	preempt_enable();
+        } while(entry0 != tx_id && timeout < 0xfffffUL) ;
 	kfree(tmp);
+	msgrng_access_disable(msgrng_flags);
 	return 0;
 
 	
diff --git a/drivers/crypto/sae/nlm_crypto.c b/drivers/crypto/sae/nlm_crypto.c
index b9c263a..bad3e07 100644
--- a/drivers/crypto/sae/nlm_crypto.c
+++ b/drivers/crypto/sae/nlm_crypto.c
@@ -42,6 +42,7 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #define TRACE_RET ((void) 0)
 #endif				/* TRACING */
 #undef NLM_CRYPTO_DEBUG
+#define NLM_CRYPTO_DEBUG
 
 
 /**
@@ -250,10 +251,9 @@ char *nlm_crypto_auth_mode_get_name(unsigned int auth_mode)
 
 void print_crypto_msg_desc(uint64_t entry1, uint64_t entry2, uint64_t entry3)
 {
-
-        printk("Security Message Descriptor 0: 0x%lx\n", entry1);
-        printk("Security Message Descriptor 1: 0x%lx\n", entry2);
-        printk("Security Message Descriptor 2: 0x%lx\n", entry3);
+        printk("Security Message Descriptor 0: 0x%llx\n", entry1);
+        printk("Security Message Descriptor 1: 0x%llx\n", entry2);
+        printk("Security Message Descriptor 2: 0x%llx\n", entry3);
 
 
         printk("Free descriptor response destination : 0x%llx  \n", xtract_bits(entry1, 48, 16));
diff --git a/drivers/crypto/sae/nlm_enc.c b/drivers/crypto/sae/nlm_enc.c
index d08da35..6ff52c2 100755
--- a/drivers/crypto/sae/nlm_enc.c
+++ b/drivers/crypto/sae/nlm_enc.c
@@ -30,6 +30,7 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #include "nlmcrypto.h"
 #include <nlm_hal_fmn.h>
 #include <asm/netlogic/hal/nlm_hal.h>
+#include <asm/netlogic/msgring.h>
 
 #include "nlm_async.h"
 #undef NLM_CRYPTO_DEBUG
@@ -44,7 +45,7 @@ struct nlm_enc_ctx {
 	char nonce[4];
 };
 /* mem utilisation of CTX_SIZE */
-#define MAX_FRAGS               18
+#define MAX_FRAGS               0xfff 
 #define CTRL_DESC_SIZE          (sizeof(struct nlm_enc_ctx) + 64)
 #define DES3_CTRL_DESC_SIZE     (2*CTRL_DESC_SIZE + 2*64)
 
@@ -52,8 +53,8 @@ struct nlm_enc_ctx {
 /* mem utilisation of req mem */
 
 #define PACKET_DESC_SIZE        (64 + sizeof(struct nlm_crypto_pkt_param) + MAX_FRAGS*(2*64) + 64 + sizeof(struct nlm_async_crypto) + 64)
-#define NLM_CRYPTO_PKT_PARAM_OFFSET(addr)       (((unsigned long)addr + 64) & ~0x3fULL)
-#define NLM_ASYNC_PTR_PARAM_OFFSET(addr)        (((unsigned long)(addr + 64 + sizeof(struct nlm_crypto_pkt_param) + MAX_FRAGS*(2*64)) + 64) & ~0x3fULL)
+#define NLM_CRYPTO_PKT_PARAM_OFFSET(addr)       (((unsigned long)addr + 64) & ~0x3fUL)
+#define NLM_ASYNC_PTR_PARAM_OFFSET(addr)        (((unsigned long)(addr + 64 + sizeof(struct nlm_crypto_pkt_param) + MAX_FRAGS*(2*64)) + 64) & ~0x3fUL)
 #define NLM_IV_OFFSET(addr)			((unsigned long)addr + (PACKET_DESC_SIZE - 64))
 
 
@@ -83,12 +84,12 @@ static int enc_cra_init(struct crypto_tfm *tfm)
 
 static struct nlm_enc_ctx * nlm_crypto_ablkcipher_ctx(struct crypto_ablkcipher *tfm)
 {
-	return (struct  nlm_enc_ctx *)(((unsigned long)((uint8_t *)crypto_ablkcipher_ctx(tfm) + 63 )) & ~(0x3f));
+	return (struct  nlm_enc_ctx *)(((unsigned long)((uint8_t *)crypto_ablkcipher_ctx(tfm) + 63 )) & ~(0x3fUL));
 } 
 
 static struct nlm_enc_ctx * nlm_crypto_ablkcipher_ctx_2(struct crypto_ablkcipher *tfm)
 {
-	return (struct  nlm_enc_ctx *)(( unsigned long )(( uint8_t *)nlm_crypto_ablkcipher_ctx(tfm) + CTRL_DESC_SIZE + 63) & ~(0x3f));
+	return (struct  nlm_enc_ctx *)(( unsigned long )(( uint8_t *)nlm_crypto_ablkcipher_ctx(tfm) + CTRL_DESC_SIZE + 63) & ~(0x3fUL));
 }
 
 static int
@@ -253,6 +254,7 @@ xlp_crypt(struct ablkcipher_request *req, unsigned int enc, int iv_size, struct
 	int len;
 	int pktdescsize = 0;
 	int fb_vc;
+	unsigned long msgrng_flags;
 	
 	unsigned int cipher_len = req->nbytes;
 	struct nlm_crypto_pkt_param * pkt_param = (struct nlm_crypto_pkt_param *) NLM_CRYPTO_PKT_PARAM_OFFSET(ablkcipher_request_ctx(req));
@@ -271,6 +273,11 @@ xlp_crypt(struct ablkcipher_request *req, unsigned int enc, int iv_size, struct
 			virt = page_address(scatterwalk_page(&walk)) + offset_in_page(walk.offset);
 			nlm_crypto_fill_src_seg(pkt_param,seg,virt,len);
 			seg = nlm_crypto_fill_dst_seg(pkt_param,seg,virt,len);
+			if(seg == MAX_FRAGS) {
+				printk("fragments exceeded 0xfff. Cannot handle the packet\n");
+				return 0;
+			}
+				
 			cipher_len -= len;
 		}
 	}
@@ -330,7 +337,9 @@ xlp_crypt(struct ablkcipher_request *req, unsigned int enc, int iv_size, struct
 	async->stat = stat; 
 	async->bytes = req->nbytes; 
 	mb();
+	msgrng_access_enable(msgrng_flags);
 	while( nlm_hal_send_msg3(crypto_vc_base, 0 /*code */ , msg0, msg1, (unsigned long )async) != 0 );
+	msgrng_access_disable(msgrng_flags);
 	preempt_enable();
 	return -EINPROGRESS;
 }
-- 
1.9.1

