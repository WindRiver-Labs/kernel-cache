From 5d726f6d732057d7ad9108a55042afe2573d615f Mon Sep 17 00:00:00 2001
From: Prabhath P Raman <prabhath@broadcom.com>
Date: Thu, 11 Oct 2012 16:54:10 +0530
Subject: [PATCH 1378/1532] XLP Network Driver: Fix for ping not happening on
 mgmt ports

Cleanup and bring in the code between the following checkin's of
sdk 2.2.5:
7c3364482014552db49a0594a9e04bbd5867c09e and
3f8ca81ef19fdcef7a38c4e2511f163e743cadab
With this we have support for MacSec, HiGig, XLP2xx in linux 3.0
[Based on SDK 3.2]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 drivers/net/ethernet/broadcom/nae/xlpge.h     |  24 +++-
 drivers/net/ethernet/broadcom/nae/xlpge_nae.c | 195 +++++++++++++++++++++++---
 drivers/net/ethernet/broadcom/nae/xlpge_rx.c  |  46 ++++++
 drivers/net/ethernet/broadcom/nae/xlpge_tso.c |  96 ++++++++++++-
 4 files changed, 334 insertions(+), 27 deletions(-)

diff --git a/drivers/net/ethernet/broadcom/nae/xlpge.h b/drivers/net/ethernet/broadcom/nae/xlpge.h
index aee6877..deb1198c 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge.h
+++ b/drivers/net/ethernet/broadcom/nae/xlpge.h
@@ -41,7 +41,9 @@
 
 #define	MAX_TSO_SKB_PEND_REQS		200
 #define	MAX_PACKET_SZ_PER_MSG		16384
-#define	P2P_SKB_OFF			(MAX_SKB_FRAGS + P2P_EXTRA_DESCS - 1)
+#define	MSEC_EXTRA_MEM			(8)
+#define	P2P_SKB_OFF			(MAX_SKB_FRAGS + P2P_EXTRA_DESCS + \
+						MSEC_EXTRA_MEM - 1)
 #define	RX_IP_CSUM_VALID		(1 << 3)
 #define	RX_TCP_CSUM_VALID		(1 << 2)
 #define CPU_INDEX(cpu)			((cpu) * 8)
@@ -88,6 +90,11 @@
 #define	RX_ALIGNMENT_ERROR_COUNTER	0x2f
 #define	RX_CARRIER_SENSE_ERROR_COUNTER	0x32
 #define	TX_EXCESSIVE_COLLISION_PACKET_COUNTER	0x42
+#define	MAC_HEADER_LEN			12
+#define	MAC_ADDR_LEN			6
+#define	MACSEC_ETHER_TYPE		0x88e5
+#define	PROTOCOL_TYPE_IP		0x0800
+#define	MAC_SEC_PADDING			(12+16+16+16)
 
 #define	NLM_RX_ETH_BUF_SIZE		(ETH_DATA_LEN + ETH_HLEN + 	\
 	ETH_FCS_LEN + BYTE_OFFSET + PREPAD_LEN + SKB_BACK_PTR_SIZE +	\
@@ -364,6 +371,21 @@ static __inline__ void print_fmn_send_error(const char *str,
 			__func__, send_result);
 }
 
+static __inline__ void dump_buffer(unsigned char *buf, uint32_t len,
+				   unsigned char *msg)
+{
+	int k;
+
+	printk("\n%s\n", msg);
+
+	for (k = 0; k < len; k++) {
+		printk("%.2x ", buf[k]);
+		if ((k + 1) % 16 == 0)
+			printk("\n");
+	}
+	printk("\n");
+}
+
 void nlm_xlp_nae_init(void);
 void nlm_xlp_nae_remove(void);
 extern int xlpge_eeprom_init(void);
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_nae.c b/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
index c82b963..bfa6d84 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
@@ -78,32 +78,46 @@ static unsigned short nlm_select_queue(struct net_device *dev,
 /*
  * As there is a port level fifo checkup done in NAE h/w, we need to fill up
  * the port fifos ( 0, 4, 8, 12 & 16) with some dummy entries if it is not
- * owned by linux.  If these are owned by an app, these dummy entries need to
- * be cleared by the app before reinitializing it
+ * owned by anyone.
  */
 static int init_dummy_entries_for_port_fifos(int node,
-					     nlm_nae_config_ptr nae_cfg,
-					     int jumbo_enabled)
+					     nlm_nae_config_ptr nae_cfg)
 {
+	struct sk_buff *skb;
 	static uint64_t msg;
 	uint32_t __attribute__ ((unused)) mflags;
-	int rv = 0, vc_index, i, j, ret, code = 0;
+	uint32_t fifo_mask = 0;
+	int rv = 0, vc_index = 0, i, j, ret, code = 0, shdom;
+	int size = NLM_RX_JUMBO_BUF_SIZE;
 
-	if (!nae_cfg->dummy_pktdata_addr)
-		return 0;
+	skb = nlm_xlp_alloc_skb_atomic(size, node);
+	if (!skb) {
+		printk("[%s] alloc skb failed\n", __func__);
+		panic("panic...");
+		return -ENOMEM;
+	}
+
+	msg = (uint64_t)virt_to_bus(skb->data) & 0xffffffffffULL;
 
-	msg = (uint64_t)nae_cfg->dummy_pktdata_addr & 0xffffffffffULL;
+	for (shdom = 0; shdom <= NLM_NAE_MAX_SHARED_DOMS; shdom++) {
+		if (!nae_cfg->shinfo[shdom].valid)
+			continue;
+
+		fifo_mask |= nlm_hal_retrieve_freein_fifo_mask(fdt, node,
+				nae_cfg->shinfo[shdom].domid);
+	}
 
 	msgrng_access_enable(mflags);
 
 	for (i = 0; i < nae_cfg->frin_total_queue; i++) {
-		/* nothing to do, if it is owned by linux */
-		if((1 << i) & nae_cfg->freein_fifo_dom_mask) 
+		/* nothing to do, if it is owned by some domain */
+		if((1 << i) & fifo_mask) 
 			continue;
 
 		vc_index = i + nae_cfg->frin_queue_base;
 
 		for (j = 0; j < 4; j++) {
+			__sync();
 			if ((ret = nlm_hal_send_msg1(vc_index, code, msg))
 				& 0x7) {
 				print_fmn_send_error(__func__, ret);
@@ -114,9 +128,15 @@ static int init_dummy_entries_for_port_fifos(int node,
 				goto err;
 			}
 		}
+		printk("Send %d dummy descriptors for queue %d(vc %d) of length %d\n",
+			j, i, vc_index, size);
 	}
 err:
 	msgrng_access_disable(mflags);
+
+	/* if not used */
+	if(!vc_index)
+		dev_kfree_skb_any(skb);
 	return rv;
 }
 
@@ -166,16 +186,145 @@ static int nlm_initialize_vfbid(int node, nlm_nae_config_ptr nae_cfg)
 	return 0;
 }
 
+static inline uint32_t fdt32_to_cpu(uint32_t x)
+{
+	#define _BYT(n) ((unsigned long long)((unsigned char *)&x)[n])
+#ifdef __MIPSEL__
+	return (_BYT(0) << 24) | (_BYT(1) << 16) | (_BYT(2) << 8) | _BYT(3);
+#else
+	return x;
+#endif
+}
+
+static int nlm_configure_shared_freein_fifo(int node,
+					    nlm_nae_config_ptr nae_cfg)
+{
+	uint64_t paddr, psize, epaddr;
+	uint64_t msg;
+	uint32_t cnode, fmask, dsize, dppadsz, ndescs;
+	uint32_t *t;
+	uint32_t owner_replenish = 0, paddr_info_len, desc_info_len;
+	ulong __attribute__ ((unused)) mflags;
+	int vc_index, rv = 0, code = 0, descs, fifo;
+	int shdom, err = 0;
+	int len = 0, i = 0;
+	char *paddr_info, *desc_info;
+
+	for(shdom = 0; shdom <= NLM_NAE_MAX_SHARED_DOMS; shdom++) {
+		if(!nae_cfg->shinfo[shdom].valid)
+			continue;
+		/* ignore my own domain id */
+		if(nae_cfg->shinfo[shdom].domid == 0)
+			continue;
+
+		rv = nlm_hal_retrieve_shared_freein_fifo_info(fdt,
+				nae_cfg->shinfo[shdom].domid,
+				&owner_replenish,
+				&paddr_info, &paddr_info_len,
+				&desc_info, &desc_info_len);
+		if(rv != 0) 
+			continue;
+
+		if(!owner_replenish)
+			continue;
+
+		t = (uint32_t *)paddr_info;
+		i = 0;
+		do {
+			/* extract the config */
+			cnode = fdt32_to_cpu(t[i]);
+			paddr = ((uint64_t)fdt32_to_cpu(t[i + 1])) << 32;
+			paddr |= ((uint64_t)fdt32_to_cpu(t[i + 2]));
+			psize = ((uint64_t)fdt32_to_cpu(t[i + 3])) << 32;
+			psize |= ((uint64_t)fdt32_to_cpu(t[i + 4]));
+		
+			i += 5;
+			len = i * 4;
+			if(cnode == node)
+				break;
+		} while(len < paddr_info_len);
+
+		printk("domid %d node %d addr %llx size %llx\n", 
+					nae_cfg->shinfo[shdom].domid, cnode,
+					paddr, psize); 
+
+		epaddr = paddr + psize;
+		t = (uint32_t *)desc_info;
+		i = 0;
+		do {
+
+			/* extract the config */
+			cnode = fdt32_to_cpu(t[i]);
+			fmask = fdt32_to_cpu(t[i + 1]);
+			dsize = fdt32_to_cpu(t[i + 2]);
+			dppadsz = fdt32_to_cpu(t[i + 3]);
+			ndescs = fdt32_to_cpu(t[i + 4]);
+		 
+			i += 5;
+			len = i * 4;
+
+			if(cnode != node)
+				continue;
+
+			printk("node %d fmask %x dsize %d dppadsz %d ndescs %d \n",
+					cnode, fmask, dsize, dppadsz, ndescs);
+
+			for(fifo = 0; fifo < NLM_NAE_MAX_FREEIN_FIFOS_PER_NODE;
+				fifo++) {
+				if(!((1 << fifo) & fmask)) 
+					continue;
+				msgrng_access_enable(mflags);
+				vc_index = fifo + nae_cfg->frin_queue_base;
+				for(descs = 0; descs < ndescs; descs++) {
+					if((paddr + dsize) > epaddr) {
+						msgrng_access_disable(mflags);
+						printk("Error, descriptors \
+							buffer overflow \n");
+						err = -1;
+						goto err_exit;
+					}
+					msg = paddr + dppadsz;
+
+					__sync();
+					rv = nlm_hal_send_msg1(vc_index, code, msg);
+					if(rv & 0x7) {
+						msgrng_access_disable(mflags);
+						printk("Unable to send \
+							configured free desc, \
+							check freein carving \
+							(qid=%d)\n", vc_index);
+						err = -1;
+						goto err_exit;
+					}
+
+					paddr += dsize;
+
+				}
+				msgrng_access_disable(mflags);
+				printk("Send %d descriptors for queue \
+						%d(%d) of length %d\n", 
+						ndescs, fifo, vc_index, dsize); 
+
+			}
+
+		} while(len < desc_info_len);
+
+	}
+
+err_exit:
+	return err;
+}
+
 static int initialize_nae_per_node(int node, uint32_t *phys_cpu_map, int mode,
 				   int *jumbo_enabled)
 {
 	nlm_nae_config_ptr nae_cfg;
-	int i, len, pos, bitoff;
+	int i, len, pos, bitoff, rv = -1;
 
 	nae_cfg = nlm_node_cfg.nae_cfg[node];
 
 	if (nae_cfg == NULL) 
-		return -1;
+		goto err;
 
 	for (i = 0; i <= NLM_NAE_MAX_SHARED_DOMS; i++) {
 		lnx_shinfo[i].valid = nae_cfg->shinfo[i].valid;
@@ -263,7 +412,7 @@ static int initialize_nae_per_node(int node, uint32_t *phys_cpu_map, int mode,
 		nlm_initialize_vfbid(node, nae_cfg);
 	
 	if (nae_cfg->owned == 0)
-		return -1;
+		goto err;
 
 	/* Update RX_CONFIG for desc size */
 	len = (ETH_HLEN + ETH_FCS_LEN + SMP_CACHE_BYTES);
@@ -274,10 +423,12 @@ static int initialize_nae_per_node(int node, uint32_t *phys_cpu_map, int mode,
 		nlm_hal_init_ingress (node,
 			(len + ETH_DATA_LEN) & ~(SMP_CACHE_BYTES - 1));
 
-	if (init_dummy_entries_for_port_fifos(node, nae_cfg,
-		*jumbo_enabled) != 0)
-		return -1;
+	if (nlm_configure_shared_freein_fifo(node, nae_cfg) != 0)
+		goto err;
+
+	init_dummy_entries_for_port_fifos(node, nae_cfg);
 	
+#if 0
 	if (is_nlm_xlp2xx()) {
 		nlm_hal_msec_tx_default_config(node,
 			0xff,			/* port enable  */
@@ -290,8 +441,11 @@ static int initialize_nae_per_node(int node, uint32_t *phys_cpu_map, int mode,
 			0x0,			/* packet num   */
 			0x0);			/* replay win size */
 	}
+#endif
+	rv = 0;
 
-	return 0;
+err:
+	return rv;
 }
 
 int initialize_nae(uint32_t *phys_cpu_map, int mode, int *jumbo_enabled)
@@ -507,12 +661,13 @@ int nlm_xlp_link_up(struct dev_data *priv, int phy)
 static int p2p_desc_mem_init(void)
 {
 	int cpu, cnt;
-	int dsize, tsize;
+	int dsize, tsize, pktsize;
 	void *buf;
 	/* MAX_SKB_FRAGS + 4.  Out of 4, 2 will be used for skb and
 	 * freeback storage
 	 */
-	dsize = ((((MAX_SKB_FRAGS + P2P_EXTRA_DESCS) * sizeof(uint64_t)) +
+	pktsize = MAX_SKB_FRAGS + P2P_EXTRA_DESCS + MSEC_EXTRA_MEM;
+	dsize = (((pktsize * sizeof(uint64_t)) +
 			CACHELINE_SIZE - 1) & (~((CACHELINE_SIZE)-1)));
 	tsize = dsize * MAX_TSO_SKB_PEND_REQS;
 
@@ -1144,7 +1299,7 @@ static int nlm_per_port_nae_init(int node, int port,
 
 	priv->cycles.mask = CLOCKSOURCE_MASK(64);
 	
-	if (is_nlm_xlp3xx())
+	if (is_nlm_xlp3xx() || is_nlm_xlp2xx())
 		priv->cycles.mult = 1000 / XLP3XX_MAX_NAE_FREQUENCY; /* Mhz */
 	else
 		priv->cycles.mult = 0x2; /*500 Mhz*/
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_rx.c b/drivers/net/ethernet/broadcom/nae/xlpge_rx.c
index b2c7be4..bccc6dd 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_rx.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_rx.c
@@ -59,6 +59,8 @@ static inline void process_rx_packets(int cpu, unsigned int src_id,
 	uint64_t ns;
 	struct skb_shared_hwtstamps *shhwtstamps;
 #endif
+	nlm_nae_config_ptr nae_cfg;
+	uint32_t msec_port;
 
 	err = (msg1 >> 4) & 0x1;
 
@@ -133,6 +135,50 @@ static inline void process_rx_packets(int cpu, unsigned int src_id,
 	skb_reserve(skb, PREPAD_LEN);
 #endif
 
+	if (priv->index == XGMAC)
+		msec_port = (priv->port | 0xf) << (4 * priv->block);
+	else
+		msec_port = 1 << port;
+
+	nae_cfg = nlm_node_cfg.nae_cfg[node];
+
+#ifdef MACSEC_DEBUG
+	printk("%s nae_cfg->sectag_offset = %d sectag_len = %d icv_len = %d\n",
+		__func__, nae_cfg->sectag_offset[port],
+		nae_cfg->sectag_len[port], nae_cfg->icv_len[port]);
+	dump_buffer(skb->data, len, "RX skb pkt:");
+	printk("msec_port = %x port = %d len = %d \
+		nae_cfg->msec_port_enable = %x\n",msec_port, port,
+		len, nae_cfg->msec_port_enable);
+#endif
+
+	/* check if port is tx port is enabled for msec
+	 * else bypass MACSec
+	 */
+	if(nae_cfg->msec_port_enable & msec_port) {
+		short ether_type = *(short*)(((char*)skb->data) +
+					MAC_HEADER_LEN);
+
+		/* Enable MACSec processing */
+		if((ether_type & 0xffff) == MACSEC_ETHER_TYPE) {
+			memcpy((char*)(skb->data + MAC_HEADER_LEN +
+				nae_cfg->sectag_len[port] -
+				MAC_ADDR_LEN /*DST MAC LEN*/),
+				(((char*)skb->data)+MAC_ADDR_LEN),
+				MAC_ADDR_LEN);
+			memcpy((char*)(skb->data + MAC_HEADER_LEN +
+				nae_cfg->sectag_len[port] -
+				(MAC_ADDR_LEN * 2) /*SRC MAC LEN*/),
+				((char*)skb->data), MAC_ADDR_LEN);
+			len = len - nae_cfg->sectag_len[port] -
+				nae_cfg->icv_len[port];
+			skb_reserve(skb, nae_cfg->sectag_len[port]);
+#ifdef MACSEC_DEBUG
+			dump_buffer(skb->data, len, "RX mod skb pkt:");
+#endif
+		}
+	}
+
 	skb->dev = pdev;
 	skb_put(skb, len);
 	skb->protocol = eth_type_trans(skb, pdev);
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_tso.c b/drivers/net/ethernet/broadcom/nae/xlpge_tso.c
index 945bbc6..580058d 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_tso.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_tso.c
@@ -43,6 +43,7 @@ static __inline__ uint64_t nae_tso_desc0(
 		unsigned int type,
 		unsigned int subtype,
 		unsigned int opcode,
+		unsigned int param_index,
 		unsigned int l3hdroff,
 		unsigned int l4hdroff,
 		unsigned int l3chksumoff,
@@ -54,6 +55,7 @@ static __inline__ uint64_t nae_tso_desc0(
 	return ((uint64_t)(type & 0x3) << 62) |
 		((uint64_t)(subtype & 3) << 60) |
 		((uint64_t)(opcode & 0xf) << 56) |
+		((uint64_t)(param_index & 0xf) << 49) |
 		((uint64_t)(l3hdroff & 0x3f) << 43) |
 		((uint64_t)(l4hdroff & 0x7f) << 36) |
 		((uint64_t)(l3chksumoff & 0x1f) << 31) |
@@ -97,6 +99,56 @@ inline int tso_xmit_skb(struct sk_buff *skb, struct net_device *dev)
 	int is_skbts = skb->sk && sock_flag(skb->sk,
 		SOCK_TIMESTAMPING_TX_HARDWARE);
 #endif
+	uint32_t msec_port, send_msec = 0, msec_bypass = 0;
+	uint32_t pad_len, icv_len, param_index = 0;
+
+#ifdef MACSEC_DEBUG
+	printk("nae_cfg->sectag_offset = %d sectag_len = %d icv_len = %d\n",
+		nae_cfg->sectag_offset[priv->port],
+		nae_cfg->sectag_len[priv->port], nae_cfg->icv_len[priv->port]);
+#endif
+	if(priv->index == XGMAC)
+		msec_port = (priv->port | 0xf) << (4 * priv->block);
+	else
+		msec_port = 1 << priv->port;
+
+#ifdef MACSEC_DEBUG
+	dump_buffer(skb->data, skb->len, "Org skb pkt:");
+	printk("msec_port = %x priv->port = %d priv->block = %d \
+		priv->index = %d skb->len = %d \
+		nae_cfg->msec_port_enable = %x\n",
+		msec_port, priv->port, priv->block, priv->index,
+		skb->len, nae_cfg->msec_port_enable);
+#endif
+	/* check if tx port is enabled for msec
+	 * else bypass MACSec
+	 */
+	if (nae_cfg->msec_port_enable & msec_port) {
+		short ether_type = *(short*)(((char*)skb->data) +
+					MAC_HEADER_LEN);
+
+#ifdef MACSEC_DEBUG
+	printk("skb->len = %d ether_type = %x\n",
+			skb->len, ether_type);
+#endif
+		/* Enable Macsec processing */
+		if((ether_type & 0xffff) == PROTOCOL_TYPE_IP) {
+			send_msec = 1;
+			/* param_index should be between 1 - 7 */
+			param_index = (priv->port)?priv->port:1;
+
+			pad_len =  nae_cfg->sectag_offset[priv->port] +
+					nae_cfg->sectag_len[priv->port];
+			icv_len = nae_cfg->icv_len[priv->port];
+
+#ifdef MACSEC_DEBUG
+	printk("pad_len = %d icv_len = %d ether_type = %x\n",
+			pad_len, icv_len, ether_type);
+#endif
+		}
+		else
+			msec_bypass = 1;
+	}
 
 	p2pdesc = alloc_p2p_desc_mem(cpu);
 	if (p2pdesc == NULL) {
@@ -136,22 +188,45 @@ inline int tso_xmit_skb(struct sk_buff *skb, struct net_device *dev)
 			iph->check = 0;
 			iph->tot_len = 0;
 			mscmsg0 = nae_tso_desc0(MSC, 1, TSO_IP_TCP_CHKSUM,
-				iphdroff, tcphdroff, (iphdroff + 10),
-				pcsum, tcphdroff + 16, pyldoff);
+				param_index, iphdroff, tcphdroff,
+				(iphdroff + 10), pcsum, tcphdroff + 16,
+				pyldoff);
 			mscmsg1 = nae_tso_desc1(MSC, 2, 0, mss, 0, 0);
 		} else if(tcp_packet) {
 			mscmsg0 = nae_tso_desc0(MSC, 0, TCP_CHKSUM,
-				iphdroff, tcphdroff, (iphdroff + 10),
-				pcsum, tcphdroff + 16, pyldoff);
+				param_index, iphdroff, tcphdroff,
+				(iphdroff + 10), pcsum, tcphdroff + 16,
+				pyldoff);
 		} else {
 			mscmsg0 = nae_tso_desc0(MSC, 0, UDP_CHKSUM,
-				iphdroff, tcphdroff, (iphdroff + 10),
-				pcsum, tcphdroff + 6, pyldoff);
+				param_index, iphdroff, tcphdroff,
+				(iphdroff + 10), pcsum, tcphdroff + 6,
+				pyldoff);
 		}
 
+	} else if (send_msec || msec_bypass) {
+		mscmsg0 = nae_tso_desc0(MSC, 0, 0, param_index,
+				0, 0, 0, 0, 0, 0);
 	}
 
 	if(((len = skb_headlen(skb)) != 0)) {
+		if (send_msec) {
+			memcpy((char*)&p2pdesc[P2P_SKB_OFF-8], skb->data,
+				MAC_HEADER_LEN);
+			idx = create_p2p_desc(virt_to_bus((char *)
+				&p2pdesc[P2P_SKB_OFF-8]), pad_len,
+				p2pdesc, idx);
+			idx = create_p2p_desc(virt_to_bus((((char *)skb->data) +
+				MAC_HEADER_LEN)), (len - MAC_HEADER_LEN),
+				p2pdesc, idx);
+#ifdef MACSEC_DEBUG
+			dump_buffer((char *)&p2pdesc[P2P_SKB_OFF-8],
+				pad_len, "first_seg:");
+			printk(" len = %d pad_len = %d icv_len = %d \
+				param_index = %d\n", len, pad_len, icv_len,
+				param_index);
+#endif
+		} else
 #ifdef IEEE_1588_PTP_ENABLED	
 		if(!is_skbts)
 #endif
@@ -166,6 +241,13 @@ inline int tso_xmit_skb(struct sk_buff *skb, struct net_device *dev)
 				fp->size, p2pdesc, idx);
 	}
 
+	if (send_msec) {
+		if (!param_index)
+			idx = create_p2p_desc(virt_to_bus((char *)
+				&p2pdesc[P2P_SKB_OFF-2]), icv_len,
+				p2pdesc, idx);
+	}
+
 
 	qid = nae_cfg->vfbtbl_sw_offset + (cpu % NLM_NCPUS_PER_NODE);
 #ifdef IEEE_1588_PTP_ENABLED
@@ -198,6 +280,8 @@ retry_send:
 		ret = nlm_hal_send_msg2(priv->nae_tx_qid, 0, msg, msg1);	
 	} 
 #endif
+	else if (send_msec || msec_bypass)
+		ret = nlm_hal_send_msg2(priv->nae_tx_qid, 0, mscmsg0, msg);
 	else
 		ret = nlm_hal_send_msg1(priv->nae_tx_qid, 0, msg);
 	msgrng_access_disable(mflags);
-- 
1.9.1

