From d5758b951f7db03308f0931bd43ce5c5392a5121 Mon Sep 17 00:00:00 2001
From: Vikas Gupta <vikasg@netlogicmicro.com>
Date: Thu, 13 Oct 2011 18:51:28 +0530
Subject: [PATCH 1082/1532] 1) Fix :Memory leak for transmit buffers. Buffers
 are shared between interrupt context and xmit path. 2) Enable counters.

[Based on SDK 3.2]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 drivers/misc/netlogic/nae_jumbo/xlp_nae_jumbo.c | 34 +++++++++++++++++--------
 1 file changed, 24 insertions(+), 10 deletions(-)

diff --git a/drivers/misc/netlogic/nae_jumbo/xlp_nae_jumbo.c b/drivers/misc/netlogic/nae_jumbo/xlp_nae_jumbo.c
index d5314ca..8700f9a 100755
--- a/drivers/misc/netlogic/nae_jumbo/xlp_nae_jumbo.c
+++ b/drivers/misc/netlogic/nae_jumbo/xlp_nae_jumbo.c
@@ -142,6 +142,7 @@ jumbo_rx_info_t  jumbo_rx_buff[NR_CPUS];
 //static struct tasklet_struct mac_frin_replenish_task[MAC_FRIN_WORK_NUM];
 static struct work_struct mac_frin_replenish_work[MAC_FRIN_WORK_NUM];
 static void mac_frin_replenish(unsigned long arg /* ignored */);
+static void tx_free_buffer(unsigned long arg /* ignored */);
 
 #define MAX_PACKET_SZ_PER_MSG	16384
 #define P2P_EXTRA_DESCS	      	((PAGE_SIZE / MAX_PACKET_SZ_PER_MSG) + 4)
@@ -623,6 +624,7 @@ static void mac_frin_replenish(unsigned long  arg/* ignored */)
 				mac_frin_replenish_one_normal_msg(dev);
 
 			atomic_sub(num_fr_in, frin_to_be_sent);
+			atomic64_add(num_fr_in, &priv->total_frin_sent);
 
 			continue;
 		skip:
@@ -699,7 +701,7 @@ static int mac_fill_rxfr(struct net_device *dev)
 			nr_buffs--;
 			atomic64_dec(&priv->frin_to_be_sent);
 
-			//atomic64_inc(&priv->total_frin_sent);
+			atomic64_inc(&priv->total_frin_sent);
 		}
 	}
 	return 0;
@@ -918,7 +920,7 @@ static int p2p_desc_mem_init(void)
 
 	for(cpu = 0; cpu < NR_CPUS; cpu++) {
 		buf = cacheline_aligned_kmalloc(tsize, GFP_KERNEL);		      
-		spin_lock_init(&p2p_desc_mem[cpu].lock);
+		//spin_lock_init(&p2p_desc_mem[cpu].lock);
 		if (!buf)
 			return -ENOMEM;
 		p2p_desc_mem[cpu].mem = buf;
@@ -937,15 +939,20 @@ static inline void *alloc_p2p_desc_mem(int cpu)
 {
 	void *buf;
     	//unsigned long flags;
-	buf = p2p_desc_mem[cpu].mem;
     	//spin_lock_irqsave(&p2p_desc_mem[cpu].lock, flags);
+    	/*Disabling irq as the critical section shared between
+ 	inteerupt context and xmit path. */	
+    	local_irq_disable();	
+	buf = p2p_desc_mem[cpu].mem;
 	if(buf) {
 		p2p_desc_mem[cpu].mem = (void *)*(unsigned long *)(buf);
+
 	} else {
 		buf = cacheline_aligned_kmalloc(p2p_desc_mem[cpu].dsize, GFP_KERNEL);
 		p2p_dynamic_alloc_cnt[CPU_INDEX(cpu)]++;
 		//printk("alloc_p2p_desc_mem p2p_dynamic_alloc_cnt cpu=0x%x\n", cpu);	
 	}
+    	local_irq_enable();	
 	//spin_unlock_irqrestore(&p2p_desc_mem[cpu].lock, flags);
 	return buf;
 }
@@ -953,11 +960,10 @@ static inline void *alloc_p2p_desc_mem(int cpu)
 static inline void free_p2p_desc_mem(int cpu, void *buf)
 {
 	unsigned long flags;
-	*(unsigned long *)buf = (unsigned long)p2p_desc_mem[cpu].mem;
     	//spin_lock_irqsave(&p2p_desc_mem[cpu].lock, flags);
+	*(unsigned long *)buf = (unsigned long)p2p_desc_mem[cpu].mem;
 	p2p_desc_mem[cpu].mem = buf;
 	//spin_unlock_irqrestore(&p2p_desc_mem[cpu].lock, flags);
-
 }
 
 static inline int create_p2p_desc(uint64_t paddr, uint64_t len, uint64_t *p2pmsg, int idx)
@@ -1081,6 +1087,7 @@ retry_send:
 		if(retry_cnt >= 128) {
 			dev_kfree_skb_any(skb);
 			free_p2p_desc_mem(cpu, p2pdesc);
+			STATS_ADD(priv->stats.tx_errors, 1);
 			goto out_unlock;
 		}
 		goto retry_send;
@@ -1088,8 +1095,8 @@ retry_send:
 
 	dev->trans_start = jiffies;
 	STATS_ADD(priv->stats.tx_bytes, skb->len);
-	STATS_ADD(priv->stats.tx_packets, idx);
-	priv->cpu_stats[cpu].tx_packets += idx;
+	STATS_ADD(priv->stats.tx_packets, 1);
+	priv->cpu_stats[cpu].tx_packets += 1;
 
 out_unlock:
 	//if(ret)
@@ -1175,7 +1182,7 @@ static int nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu)
 	}
 	if(priv->type==XAUI_IF){
 		nlm_hal_write_mac_reg(priv->block, priv->index, XAUI_MAX_FRAME_LEN, (((local_jumbo_mtu/4)<<16) | local_jumbo_mtu));
-		printk("Max frmae len set = %d bytes\n", nlm_hal_read_mac_reg(priv->block, XGMAC, XAUI_MAX_FRAME_LEN) & (0xffff));
+		printk("Max frame len set = %d bytes\n", nlm_hal_read_mac_reg(priv->block, XGMAC, XAUI_MAX_FRAME_LEN) & (0xffff));
 	}
 
 	dev->mtu = new_mtu;
@@ -1314,9 +1321,12 @@ static void nlm_xlp_nae_msgring_handler(uint32_t vc, uint32_t src_id,
 //#if 0		
 		p2pfbdesc = bus_to_virt(addr);
 		skb = (struct sk_buff *)(p2pfbdesc[P2P_SKB_OFF]);
+		priv = netdev_priv(skb->dev);
 		free_p2p_desc_mem(cpu, p2pfbdesc);
+		//schedule_work(&tx_free_buffer_work[cpu]);
 		if(skb)
 			dev_kfree_skb_any(skb);
+		priv->cpu_stats[cpu].txc_packets++;
 //#endif
 #if 0
 
@@ -1460,6 +1470,7 @@ static void nlm_xlp_nae_msgring_handler(uint32_t vc, uint32_t src_id,
 			mac_frin_replenish_msgs(dev_mac[port], tot_desc);
 			return;
 		}
+		mac_frin_replenish_msgs(dev_mac[port], tot_desc);
 
 		/* allocate an skb for header */
 		skb = dev_alloc_skb(NETL_JUMBO_SKB_HDR_LEN + 16);
@@ -1470,7 +1481,6 @@ static void nlm_xlp_nae_msgring_handler(uint32_t vc, uint32_t src_id,
 			recycle_rx_desc(addr, pdev);
 			return;
 		}
-		mac_frin_replenish_msgs(dev_mac[port], tot_desc);
 		skb->dev = dev_mac[port];
 		hlen = (len > NETL_JUMBO_SKB_HDR_LEN) ? 
 				NETL_JUMBO_SKB_HDR_LEN: len;
@@ -1583,11 +1593,12 @@ static int xlp_mac_proc_read(char *page, char **start, off_t off,
 			       atomic64_read(&priv->total_frin_sent));
 
 		len += sprintf(page + len,
-			       "per port@%d: %lu(rxp) %lu(rxb) %lu(txp) %lu(txb)\n",
+			       "per port@%d: %lu(rxp) %lu(rxb) %lu(txp) %lu(txerr) %lu(txb)\n",
 			       i,
 			       STATS_READ(priv->stats.rx_packets),
 			       STATS_READ(priv->stats.rx_bytes),
 			       STATS_READ(priv->stats.tx_packets),
+			       STATS_READ(priv->stats.tx_errors),
 			       STATS_READ(priv->stats.tx_bytes));
 
 		for (cpu = 0; cpu < NR_CPUS ; cpu++) {
@@ -1602,6 +1613,9 @@ static int xlp_mac_proc_read(char *page, char **start, off_t off,
 				       cpu, tx, txc, rx, ints);
 		}
 	}
+	for (cpu = 0; cpu < NR_CPUS; cpu++) {
+		len += sprintf(page + len, "per cpu@%d: %lu(p2p_dynamic_alloc_cnt)\n", cpu ,p2p_dynamic_alloc_cnt[CPU_INDEX(cpu)]);
+	}
 
 	*eof = 1;
 
-- 
1.9.1

