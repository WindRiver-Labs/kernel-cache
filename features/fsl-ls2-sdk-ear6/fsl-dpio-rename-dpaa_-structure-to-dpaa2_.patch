From bacc8f73326aa180c495bc77b0c6aa33fa0433a9 Mon Sep 17 00:00:00 2001
From: Haiying Wang <Haiying.wang@freescale.com>
Date: Tue, 10 Nov 2015 11:26:17 -0500
Subject: [PATCH 323/452] fsl-dpio: rename dpaa_* structure to dpaa2_*

Signed-off-by: Haiying Wang <Haiying.wang@freescale.com>
[Xulin: Original patch taken from FSL LS2085 SDK EAR6.0,
LS2085A-SDK-SOURCE-20160304-yocto.iso]
Signed-off-by: Xulin Sun <xulin.sun@windriver.com>
---
 drivers/crypto/dpaa2-caam/dpaa2-caam.c             |  206 ++++++++++----------
 drivers/crypto/dpaa2-caam/dpaa2-caam.h             |    8 +-
 drivers/crypto/dpaa2-caam/sg_sw_qm.h               |   11 +-
 .../staging/fsl-dpaa2/ethernet/dpaa2-eth-trace.h   |    8 +-
 drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c     |   52 +++---
 drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h     |    2 +-
 drivers/staging/fsl-mc/bus/dpio/dpio_service.c     |    4 +-
 drivers/staging/fsl-mc/bus/dpio/qbman_portal.c     |    4 +-
 drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h      |  153 ++++++++-------
 drivers/staging/fsl-mc/include/fsl_dpaa2_io.h      |    6 +-
 10 files changed, 231 insertions(+), 223 deletions(-)

diff --git a/drivers/crypto/dpaa2-caam/dpaa2-caam.c b/drivers/crypto/dpaa2-caam/dpaa2-caam.c
index 04d931d..6d5a94b 100644
--- a/drivers/crypto/dpaa2-caam/dpaa2-caam.c
+++ b/drivers/crypto/dpaa2-caam/dpaa2-caam.c
@@ -621,7 +621,7 @@ int gen_split_key(struct device *dev, u8 *key_out, int split_key_len,
 	struct split_key_result result;
 	dma_addr_t dma_addr_in, dma_addr_out, flc_dma;
 	struct caam_flc *flc;
-	struct dpaa_fl_entry *in_fle, *out_fle;
+	struct dpaa2_fl_entry *in_fle, *out_fle;
 	int ret = -ENOMEM;
 
 	req_ctx = kzalloc(sizeof(*req_ctx), GFP_KERNEL | GFP_DMA);
@@ -679,10 +679,10 @@ int gen_split_key(struct device *dev, u8 *key_out, int split_key_len,
 	}
 
 	dpaa2_fl_set_final(in_fle, true);
-	dpaa2_fl_set_format(in_fle, dpaa_fl_single);
+	dpaa2_fl_set_format(in_fle, dpaa2_fl_single);
 	dpaa2_fl_set_addr(in_fle, dma_addr_in);
 	dpaa2_fl_set_len(in_fle, keylen);
-	dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+	dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 	dpaa2_fl_set_addr(out_fle, dma_addr_out);
 	dpaa2_fl_set_len(out_fle, split_key_pad_len);
 
@@ -804,8 +804,8 @@ static struct aead_edesc *aead_edesc_alloc(struct aead_request *req,
 {
 	struct crypto_aead *aead = crypto_aead_reqtfm(req);
 	struct caam_request *req_ctx = aead_request_ctx(req);
-	struct dpaa_fl_entry *in_fle = &req_ctx->fd_flt[1];
-	struct dpaa_fl_entry *out_fle = &req_ctx->fd_flt[0];
+	struct dpaa2_fl_entry *in_fle = &req_ctx->fd_flt[1];
+	struct dpaa2_fl_entry *out_fle = &req_ctx->fd_flt[0];
 	struct caam_ctx *ctx = crypto_aead_ctx(aead);
 	struct device *dev = ctx->priv->dev;
 	gfp_t flags = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
@@ -819,7 +819,7 @@ static struct aead_edesc *aead_edesc_alloc(struct aead_request *req,
 	int ivsize = crypto_aead_ivsize(aead);
 	int qm_sg_index = 0, qm_sg_nents = 0, qm_sg_bytes;
 	unsigned int authsize = ctx->authsize;
-	struct dpaa_sg_entry *sg_table;
+	struct dpaa2_sg_entry *sg_table;
 	bool is_gcm = false;
 
 	assoc_nents = sg_count(req->assoc, req->assoclen, &assoc_chained);
@@ -881,7 +881,7 @@ static struct aead_edesc *aead_edesc_alloc(struct aead_request *req,
 	}
 
 	qm_sg_nents += dst_nents;
-	qm_sg_bytes = qm_sg_nents * sizeof(struct dpaa_sg_entry);
+	qm_sg_bytes = qm_sg_nents * sizeof(struct dpaa2_sg_entry);
 
 	/* allocate space for base edesc and link tables */
 	edesc = qi_cache_alloc(GFP_DMA | flags);
@@ -910,7 +910,7 @@ static struct aead_edesc *aead_edesc_alloc(struct aead_request *req,
 	dpaa2_fl_set_final(in_fle, true);
 
 	if (!all_contig) {
-		dpaa2_fl_set_format(in_fle, dpaa_fl_sg);
+		dpaa2_fl_set_format(in_fle, dpaa2_fl_sg);
 		dpaa2_fl_set_addr(in_fle, edesc->qm_sg_dma);
 
 		if (!is_gcm) {
@@ -931,7 +931,7 @@ static struct aead_edesc *aead_edesc_alloc(struct aead_request *req,
 				 0);
 		qm_sg_index += src_nents;
 	} else {
-		dpaa2_fl_set_format(in_fle, dpaa_fl_single);
+		dpaa2_fl_set_format(in_fle, dpaa2_fl_single);
 		if (is_gcm)
 			dpaa2_fl_set_addr(in_fle, iv_dma);
 		else
@@ -944,21 +944,21 @@ static struct aead_edesc *aead_edesc_alloc(struct aead_request *req,
 
 	if (req->src == req->dst) {
 		if (src_nents <= 1) {
-			dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+			dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 			dpaa2_fl_set_addr(out_fle, sg_dma_address(req->src));
 		} else {
-			dpaa2_fl_set_format(out_fle, dpaa_fl_sg);
+			dpaa2_fl_set_format(out_fle, dpaa2_fl_sg);
 			dpaa2_fl_set_addr(out_fle, edesc->qm_sg_dma +
 					  ((edesc->assoc_nents ? : 1) + 1) *
-					  sizeof(struct dpaa_sg_entry));
+					  sizeof(struct dpaa2_sg_entry));
 		}
 	} else if (!dst_nents) {
-		dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+		dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 		dpaa2_fl_set_addr(out_fle, sg_dma_address(req->dst));
 	} else {
-		dpaa2_fl_set_format(out_fle, dpaa_fl_sg);
+		dpaa2_fl_set_format(out_fle, dpaa2_fl_sg);
 		dpaa2_fl_set_addr(out_fle, edesc->qm_sg_dma + qm_sg_index *
-				  sizeof(struct dpaa_sg_entry));
+				  sizeof(struct dpaa2_sg_entry));
 	}
 
 	dma_sync_single_for_device(dev, edesc->qm_sg_dma, qm_sg_bytes,
@@ -977,8 +977,8 @@ static struct aead_edesc *aead_giv_edesc_alloc(struct aead_givcrypt_request
 {
 	struct aead_request *req = &areq->areq;
 	struct caam_request *req_ctx = aead_request_ctx(req);
-	struct dpaa_fl_entry *in_fle = &req_ctx->fd_flt[1];
-	struct dpaa_fl_entry *out_fle = &req_ctx->fd_flt[0];
+	struct dpaa2_fl_entry *in_fle = &req_ctx->fd_flt[1];
+	struct dpaa2_fl_entry *out_fle = &req_ctx->fd_flt[0];
 	struct crypto_aead *aead = crypto_aead_reqtfm(req);
 	struct caam_ctx *ctx = crypto_aead_ctx(aead);
 	struct device *dev = ctx->priv->dev;
@@ -992,7 +992,7 @@ static struct aead_edesc *aead_giv_edesc_alloc(struct aead_givcrypt_request
 	int ivsize = crypto_aead_ivsize(aead);
 	bool assoc_chained = false, src_chained = false, dst_chained = false;
 	int qm_sg_index = 0, qm_sg_nents = 0, qm_sg_bytes;
-	struct dpaa_sg_entry *sg_table;
+	struct dpaa2_sg_entry *sg_table;
 	bool is_gcm = false;
 
 	assoc_nents = sg_count(req->assoc, req->assoclen, &assoc_chained);
@@ -1068,7 +1068,7 @@ static struct aead_edesc *aead_giv_edesc_alloc(struct aead_givcrypt_request
 		qm_sg_nents += 1 + dst_nents;
 	}
 
-	qm_sg_bytes = qm_sg_nents * sizeof(struct dpaa_sg_entry);
+	qm_sg_bytes = qm_sg_nents * sizeof(struct dpaa2_sg_entry);
 
 	/* allocate space for base edesc and link tables */
 	edesc = qi_cache_alloc(GFP_DMA | flags);
@@ -1097,7 +1097,7 @@ static struct aead_edesc *aead_giv_edesc_alloc(struct aead_givcrypt_request
 	dpaa2_fl_set_final(in_fle, true);
 
 	if (!(contig & GIV_SRC_CONTIG)) {
-		dpaa2_fl_set_format(in_fle, dpaa_fl_sg);
+		dpaa2_fl_set_format(in_fle, dpaa2_fl_sg);
 		dpaa2_fl_set_addr(in_fle, edesc->qm_sg_dma);
 
 		if (!is_gcm) {
@@ -1119,7 +1119,7 @@ static struct aead_edesc *aead_giv_edesc_alloc(struct aead_givcrypt_request
 				 0);
 		qm_sg_index += src_nents;
 	} else {
-		dpaa2_fl_set_format(in_fle, dpaa_fl_single);
+		dpaa2_fl_set_format(in_fle, dpaa2_fl_single);
 		if (is_gcm)
 			dpaa2_fl_set_addr(in_fle, iv_dma);
 		else
@@ -1127,12 +1127,12 @@ static struct aead_edesc *aead_giv_edesc_alloc(struct aead_givcrypt_request
 	}
 
 	if (!(contig & GIV_DST_CONTIG)) {
-		dpaa2_fl_set_format(out_fle, dpaa_fl_sg);
+		dpaa2_fl_set_format(out_fle, dpaa2_fl_sg);
 		if (req->src == req->dst) {
 			dpaa2_fl_set_addr(out_fle, edesc->qm_sg_dma +
 					  (edesc->assoc_nents + (is_gcm ? 1 +
 					   edesc->src_nents : 0)) *
-					   sizeof(struct dpaa_sg_entry));
+					   sizeof(struct dpaa2_sg_entry));
 			if (is_gcm) {
 				dma_to_qm_sg_one(sg_table + qm_sg_index, iv_dma,
 						 ivsize, 0);
@@ -1143,7 +1143,7 @@ static struct aead_edesc *aead_giv_edesc_alloc(struct aead_givcrypt_request
 		} else {
 			dpaa2_fl_set_addr(out_fle, edesc->qm_sg_dma +
 					  qm_sg_index *
-					  sizeof(struct dpaa_sg_entry));
+					  sizeof(struct dpaa2_sg_entry));
 			dma_to_qm_sg_one(sg_table + qm_sg_index, iv_dma, ivsize,
 					 0);
 			qm_sg_index += 1;
@@ -1151,7 +1151,7 @@ static struct aead_edesc *aead_giv_edesc_alloc(struct aead_givcrypt_request
 					 qm_sg_index, 0);
 		}
 	} else {
-		dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+		dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 		dpaa2_fl_set_addr(out_fle, iv_dma);
 	}
 
@@ -1691,8 +1691,8 @@ static struct ablkcipher_edesc *ablkcipher_edesc_alloc(struct ablkcipher_request
 {
 	struct crypto_ablkcipher *ablkcipher = crypto_ablkcipher_reqtfm(req);
 	struct caam_request *req_ctx = ablkcipher_request_ctx(req);
-	struct dpaa_fl_entry *in_fle = &req_ctx->fd_flt[1];
-	struct dpaa_fl_entry *out_fle = &req_ctx->fd_flt[0];
+	struct dpaa2_fl_entry *in_fle = &req_ctx->fd_flt[1];
+	struct dpaa2_fl_entry *out_fle = &req_ctx->fd_flt[0];
 	struct caam_ctx *ctx = crypto_ablkcipher_ctx(ablkcipher);
 	struct device *dev = ctx->priv->dev;
 	gfp_t flags = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
@@ -1705,7 +1705,7 @@ static struct ablkcipher_edesc *ablkcipher_edesc_alloc(struct ablkcipher_request
 	int sgc;
 	int ivsize = crypto_ablkcipher_ivsize(ablkcipher);
 	bool src_chained = false, dst_chained = false;
-	struct dpaa_sg_entry *sg_table;
+	struct dpaa2_sg_entry *sg_table;
 	int qm_sg_index = 0;
 
 	src_nents = sg_count(req->src, req->nbytes, &src_chained);
@@ -1738,7 +1738,7 @@ static struct ablkcipher_edesc *ablkcipher_edesc_alloc(struct ablkcipher_request
 	else
 		src_nents = src_nents ? : 1;
 	qm_sg_bytes = ((iv_contig ? 0 : 1) + src_nents + dst_nents) *
-		      sizeof(struct dpaa_sg_entry);
+		      sizeof(struct dpaa2_sg_entry);
 
 	/* allocate space for base edesc and link tables */
 	edesc = qi_cache_alloc(GFP_DMA | flags);
@@ -1765,34 +1765,34 @@ static struct ablkcipher_edesc *ablkcipher_edesc_alloc(struct ablkcipher_request
 	dpaa2_fl_set_final(in_fle, true);
 
 	if (!iv_contig) {
-		dpaa2_fl_set_format(in_fle, dpaa_fl_sg);
+		dpaa2_fl_set_format(in_fle, dpaa2_fl_sg);
 		dpaa2_fl_set_addr(in_fle, edesc->qm_sg_dma);
 
 		dma_to_qm_sg_one(sg_table, iv_dma, ivsize, 0);
 		sg_to_qm_sg_last(req->src, src_nents, sg_table + 1, 0);
 		qm_sg_index = 1 + src_nents;
 	} else {
-		dpaa2_fl_set_format(in_fle, dpaa_fl_single);
+		dpaa2_fl_set_format(in_fle, dpaa2_fl_single);
 		dpaa2_fl_set_addr(in_fle, iv_dma);
 	}
 
 	if (req->src == req->dst) {
 		if (!iv_contig) {
-			dpaa2_fl_set_format(out_fle, dpaa_fl_sg);
+			dpaa2_fl_set_format(out_fle, dpaa2_fl_sg);
 			dpaa2_fl_set_addr(out_fle, edesc->qm_sg_dma +
-					  sizeof(struct dpaa_sg_entry));
+					  sizeof(struct dpaa2_sg_entry));
 		} else {
-			dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+			dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 			dpaa2_fl_set_addr(out_fle, sg_dma_address(req->src));
 		}
 	} else if (dst_nents) {
-		dpaa2_fl_set_format(out_fle, dpaa_fl_sg);
+		dpaa2_fl_set_format(out_fle, dpaa2_fl_sg);
 		dpaa2_fl_set_addr(out_fle, edesc->qm_sg_dma + qm_sg_index *
-				  sizeof(struct dpaa_sg_entry));
+				  sizeof(struct dpaa2_sg_entry));
 		sg_to_qm_sg_last(req->dst, dst_nents, sg_table + qm_sg_index,
 				 0);
 	} else {
-		dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+		dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 		dpaa2_fl_set_addr(out_fle, sg_dma_address(req->dst));
 	}
 
@@ -1813,8 +1813,8 @@ static struct ablkcipher_edesc *ablkcipher_giv_edesc_alloc(
 	struct ablkcipher_request *req = &greq->creq;
 	struct crypto_ablkcipher *ablkcipher = crypto_ablkcipher_reqtfm(req);
 	struct caam_request *req_ctx = ablkcipher_request_ctx(req);
-	struct dpaa_fl_entry *in_fle = &req_ctx->fd_flt[1];
-	struct dpaa_fl_entry *out_fle = &req_ctx->fd_flt[0];
+	struct dpaa2_fl_entry *in_fle = &req_ctx->fd_flt[1];
+	struct dpaa2_fl_entry *out_fle = &req_ctx->fd_flt[0];
 	struct caam_ctx *ctx = crypto_ablkcipher_ctx(ablkcipher);
 	struct device *dev = ctx->priv->dev;
 	gfp_t flags = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
@@ -1827,7 +1827,7 @@ static struct ablkcipher_edesc *ablkcipher_giv_edesc_alloc(
 	int sgc;
 	int ivsize = crypto_ablkcipher_ivsize(ablkcipher);
 	bool src_chained = false, dst_chained = false;
-	struct dpaa_sg_entry *sg_table;
+	struct dpaa2_sg_entry *sg_table;
 	int qm_sg_index = 0;
 
 	src_nents = sg_count(req->src, req->nbytes, &src_chained);
@@ -1860,7 +1860,7 @@ static struct ablkcipher_edesc *ablkcipher_giv_edesc_alloc(
 	else
 		dst_nents = dst_nents ? : 1;
 	qm_sg_bytes = ((iv_contig ? 0 : 1) + src_nents + dst_nents) *
-		      sizeof(struct dpaa_sg_entry);
+		      sizeof(struct dpaa2_sg_entry);
 
 	/* allocate space for base edesc and link tables */
 	edesc = qi_cache_alloc(GFP_DMA | flags);
@@ -1887,17 +1887,17 @@ static struct ablkcipher_edesc *ablkcipher_giv_edesc_alloc(
 	dpaa2_fl_set_final(in_fle, true);
 
 	if (src_nents) {
-		dpaa2_fl_set_format(in_fle, dpaa_fl_sg);
+		dpaa2_fl_set_format(in_fle, dpaa2_fl_sg);
 		dpaa2_fl_set_addr(in_fle, edesc->qm_sg_dma);
 		sg_to_qm_sg_last(req->src, src_nents, sg_table, 0);
 		qm_sg_index = src_nents;
 	} else {
-		dpaa2_fl_set_format(in_fle, dpaa_fl_single);
+		dpaa2_fl_set_format(in_fle, dpaa2_fl_single);
 		dpaa2_fl_set_addr(in_fle, sg_dma_address(req->src));
 	}
 
 	if (!iv_contig) {
-		dpaa2_fl_set_format(out_fle, dpaa_fl_sg);
+		dpaa2_fl_set_format(out_fle, dpaa2_fl_sg);
 		dpaa2_fl_set_addr(out_fle, edesc->qm_sg_dma);
 
 		dma_to_qm_sg_one(sg_table + qm_sg_index, iv_dma, ivsize, 0);
@@ -1905,7 +1905,7 @@ static struct ablkcipher_edesc *ablkcipher_giv_edesc_alloc(
 		sg_to_qm_sg_last(req->dst, dst_nents, sg_table + qm_sg_index,
 				 0);
 	} else {
-		dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+		dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 		dpaa2_fl_set_addr(out_fle, sg_dma_address(req->dst));
 	}
 
@@ -3085,7 +3085,7 @@ struct caam_hash_template {
 
 /* Map current buffer in state and put it in link table */
 static inline dma_addr_t buf_map_to_qm_sg(struct device *dev,
-					  struct dpaa_sg_entry *qm_sg, u8 *buf,
+					  struct dpaa2_sg_entry *qm_sg, u8 *buf,
 					  int buflen)
 {
 	dma_addr_t buf_dma;
@@ -3098,7 +3098,7 @@ static inline dma_addr_t buf_map_to_qm_sg(struct device *dev,
 
 /* Map req->src and put it in link table */
 static inline void src_map_to_qm_sg(struct device *dev, struct scatterlist *src,
-				    int src_nents, struct dpaa_sg_entry *qm_sg,
+				    int src_nents, struct dpaa2_sg_entry *qm_sg,
 				    bool chained)
 {
 	dma_map_sg_chained(dev, src, src_nents, DMA_TO_DEVICE, chained);
@@ -3110,7 +3110,7 @@ static inline void src_map_to_qm_sg(struct device *dev, struct scatterlist *src,
  * since a buffer has previously been used, and needs to be unmapped,
  */
 static inline dma_addr_t
-try_buf_map_to_qm_sg(struct device *dev, struct dpaa_sg_entry *qm_sg, u8 *buf,
+try_buf_map_to_qm_sg(struct device *dev, struct dpaa2_sg_entry *qm_sg, u8 *buf,
 		     dma_addr_t buf_dma, int buflen, int last_buflen)
 {
 	if (buf_dma && !dma_mapping_error(dev, buf_dma))
@@ -3221,7 +3221,7 @@ static int hash_digest_key(struct caam_hash_ctx *ctx, const u8 *key_in,
 	dma_addr_t src_dma, dst_dma, flc_dma;
 	struct caam_flc *flc;
 	int ret = -ENOMEM;
-	struct dpaa_fl_entry *in_fle, *out_fle;
+	struct dpaa2_fl_entry *in_fle, *out_fle;
 
 	req_ctx = kzalloc(sizeof(*req_ctx), GFP_KERNEL | GFP_DMA);
 	if (!req_ctx)
@@ -3266,10 +3266,10 @@ static int hash_digest_key(struct caam_hash_ctx *ctx, const u8 *key_in,
 	}
 
 	dpaa2_fl_set_final(in_fle, true);
-	dpaa2_fl_set_format(in_fle, dpaa_fl_single);
+	dpaa2_fl_set_format(in_fle, dpaa2_fl_single);
 	dpaa2_fl_set_addr(in_fle, src_dma);
 	dpaa2_fl_set_len(in_fle, *keylen);
-	dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+	dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 	dpaa2_fl_set_addr(out_fle, dst_dma);
 	dpaa2_fl_set_len(out_fle, digestsize);
 
@@ -3685,8 +3685,8 @@ static int ahash_update_ctx(struct ahash_request *req)
 	struct caam_hash_state *state = ahash_request_ctx(req);
 	struct caam_request *req_ctx = &state->caam_req;
 	struct device *dev = ctx->priv->dev;
-	struct dpaa_fl_entry *in_fle = &req_ctx->fd_flt[1];
-	struct dpaa_fl_entry *out_fle = &req_ctx->fd_flt[0];
+	struct dpaa2_fl_entry *in_fle = &req_ctx->fd_flt[1];
+	struct dpaa2_fl_entry *out_fle = &req_ctx->fd_flt[0];
 	gfp_t flags = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
 		       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;
 	u8 *buf = state->current_buf ? state->buf_1 : state->buf_0;
@@ -3697,7 +3697,7 @@ static int ahash_update_ctx(struct ahash_request *req)
 	int in_len = *buflen + req->nbytes, to_hash;
 	int src_nents, qm_sg_bytes, qm_sg_src_index;
 	struct ahash_edesc *edesc;
-	struct dpaa_sg_entry *sg_table;
+	struct dpaa2_sg_entry *sg_table;
 	bool chained = false;
 	int ret = 0;
 
@@ -3710,7 +3710,7 @@ static int ahash_update_ctx(struct ahash_request *req)
 				       &chained);
 		qm_sg_src_index = 1 + (*buflen ? 1 : 0);
 		qm_sg_bytes = (qm_sg_src_index + src_nents) *
-				 sizeof(struct dpaa_sg_entry);
+				 sizeof(struct dpaa2_sg_entry);
 
 		/* allocate space for base edesc and link tables */
 		edesc = qi_cache_zalloc(GFP_DMA | flags);
@@ -3761,9 +3761,9 @@ static int ahash_update_ctx(struct ahash_request *req)
 		memset(&req_ctx->fd_flt, 0, sizeof(req_ctx->fd_flt));
 		dpaa2_fl_set_final(in_fle, true);
 
-		dpaa2_fl_set_format(in_fle, dpaa_fl_sg);
+		dpaa2_fl_set_format(in_fle, dpaa2_fl_sg);
 		dpaa2_fl_set_addr(in_fle, edesc->qm_sg_dma);
-		dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+		dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 		dpaa2_fl_set_addr(out_fle, state->ctx_dma);
 
 		dpaa2_fl_set_len(out_fle, ctx->ctx_len);
@@ -3805,8 +3805,8 @@ static int ahash_final_ctx(struct ahash_request *req)
 	struct caam_hash_state *state = ahash_request_ctx(req);
 	struct caam_request *req_ctx = &state->caam_req;
 	struct device *dev = ctx->priv->dev;
-	struct dpaa_fl_entry *in_fle = &req_ctx->fd_flt[1];
-	struct dpaa_fl_entry *out_fle = &req_ctx->fd_flt[0];
+	struct dpaa2_fl_entry *in_fle = &req_ctx->fd_flt[1];
+	struct dpaa2_fl_entry *out_fle = &req_ctx->fd_flt[0];
 	gfp_t flags = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
 		       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;
 	u8 *buf = state->current_buf ? state->buf_1 : state->buf_0;
@@ -3816,11 +3816,11 @@ static int ahash_final_ctx(struct ahash_request *req)
 	int qm_sg_bytes, qm_sg_src_index;
 	int digestsize = crypto_ahash_digestsize(ahash);
 	struct ahash_edesc *edesc;
-	struct dpaa_sg_entry *sg_table;
+	struct dpaa2_sg_entry *sg_table;
 	int ret = 0;
 
 	qm_sg_src_index = 1 + (buflen ? 1 : 0);
-	qm_sg_bytes = qm_sg_src_index * sizeof(struct dpaa_sg_entry);
+	qm_sg_bytes = qm_sg_src_index * sizeof(struct dpaa2_sg_entry);
 
 	/* allocate space for base edesc and link tables */
 	edesc = qi_cache_zalloc(GFP_DMA | flags);
@@ -3861,10 +3861,10 @@ static int ahash_final_ctx(struct ahash_request *req)
 
 	memset(&req_ctx->fd_flt, 0, sizeof(req_ctx->fd_flt));
 	dpaa2_fl_set_final(in_fle, true);
-	dpaa2_fl_set_format(in_fle, dpaa_fl_sg);
+	dpaa2_fl_set_format(in_fle, dpaa2_fl_sg);
 	dpaa2_fl_set_addr(in_fle, edesc->qm_sg_dma);
 	dpaa2_fl_set_len(in_fle, ctx->ctx_len + buflen);
-	dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+	dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 	dpaa2_fl_set_addr(out_fle, edesc->dst_dma);
 	dpaa2_fl_set_len(out_fle, digestsize);
 
@@ -3890,8 +3890,8 @@ static int ahash_finup_ctx(struct ahash_request *req)
 	struct caam_hash_state *state = ahash_request_ctx(req);
 	struct caam_request *req_ctx = &state->caam_req;
 	struct device *dev = ctx->priv->dev;
-	struct dpaa_fl_entry *in_fle = &req_ctx->fd_flt[1];
-	struct dpaa_fl_entry *out_fle = &req_ctx->fd_flt[0];
+	struct dpaa2_fl_entry *in_fle = &req_ctx->fd_flt[1];
+	struct dpaa2_fl_entry *out_fle = &req_ctx->fd_flt[0];
 	gfp_t flags = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
 		       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;
 	u8 *buf = state->current_buf ? state->buf_1 : state->buf_0;
@@ -3902,14 +3902,14 @@ static int ahash_finup_ctx(struct ahash_request *req)
 	int src_nents;
 	int digestsize = crypto_ahash_digestsize(ahash);
 	struct ahash_edesc *edesc;
-	struct dpaa_sg_entry *sg_table;
+	struct dpaa2_sg_entry *sg_table;
 	bool chained = false;
 	int ret = 0;
 
 	src_nents = __sg_count(req->src, req->nbytes, &chained);
 	qm_sg_src_index = 1 + (buflen ? 1 : 0);
 	qm_sg_bytes = (qm_sg_src_index + src_nents) *
-		      sizeof(struct dpaa_sg_entry);
+		      sizeof(struct dpaa2_sg_entry);
 
 	/* allocate space for base edesc and link tables */
 	edesc = qi_cache_zalloc(GFP_DMA | flags);
@@ -3955,9 +3955,9 @@ static int ahash_finup_ctx(struct ahash_request *req)
 
 	memset(&req_ctx->fd_flt, 0, sizeof(req_ctx->fd_flt));
 	dpaa2_fl_set_final(in_fle, true);
-	dpaa2_fl_set_format(in_fle, dpaa_fl_sg);
+	dpaa2_fl_set_format(in_fle, dpaa2_fl_sg);
 	dpaa2_fl_set_addr(in_fle, edesc->qm_sg_dma);
-	dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+	dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 	dpaa2_fl_set_addr(out_fle, edesc->dst_dma);
 
 	dpaa2_fl_set_len(out_fle, digestsize);
@@ -3985,21 +3985,21 @@ static int ahash_digest(struct ahash_request *req)
 	struct caam_hash_state *state = ahash_request_ctx(req);
 	struct caam_request *req_ctx = &state->caam_req;
 	struct device *dev = ctx->priv->dev;
-	struct dpaa_fl_entry *in_fle = &req_ctx->fd_flt[1];
-	struct dpaa_fl_entry *out_fle = &req_ctx->fd_flt[0];
+	struct dpaa2_fl_entry *in_fle = &req_ctx->fd_flt[1];
+	struct dpaa2_fl_entry *out_fle = &req_ctx->fd_flt[0];
 	gfp_t flags = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
 		       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;
 	int digestsize = crypto_ahash_digestsize(ahash);
 	int src_nents, qm_sg_bytes;
 	struct ahash_edesc *edesc;
-	struct dpaa_sg_entry *sg_table;
+	struct dpaa2_sg_entry *sg_table;
 	bool chained = false;
 	int ret = 0;
 
 	src_nents = sg_count(req->src, req->nbytes, &chained);
 	dma_map_sg_chained(dev, req->src, src_nents ? : 1, DMA_TO_DEVICE,
 			   chained);
-	qm_sg_bytes = src_nents * sizeof(struct dpaa_sg_entry);
+	qm_sg_bytes = src_nents * sizeof(struct dpaa2_sg_entry);
 
 	/* allocate space for base edesc and link tables */
 	edesc = qi_cache_zalloc(GFP_DMA | flags);
@@ -4023,10 +4023,10 @@ static int ahash_digest(struct ahash_request *req)
 			dev_err(dev, "unable to map S/G table\n");
 			return -ENOMEM;
 		}
-		dpaa2_fl_set_format(in_fle, dpaa_fl_sg);
+		dpaa2_fl_set_format(in_fle, dpaa2_fl_sg);
 		dpaa2_fl_set_addr(in_fle, edesc->qm_sg_dma);
 	} else {
-		dpaa2_fl_set_format(in_fle, dpaa_fl_single);
+		dpaa2_fl_set_format(in_fle, dpaa2_fl_single);
 		dpaa2_fl_set_addr(in_fle, sg_dma_address(req->src));
 	}
 
@@ -4038,7 +4038,7 @@ static int ahash_digest(struct ahash_request *req)
 	}
 
 	dpaa2_fl_set_final(in_fle, true);
-	dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+	dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 	dpaa2_fl_set_addr(out_fle, edesc->dst_dma);
 
 	dpaa2_fl_set_len(out_fle, digestsize);
@@ -4066,8 +4066,8 @@ static int ahash_final_no_ctx(struct ahash_request *req)
 	struct caam_hash_state *state = ahash_request_ctx(req);
 	struct caam_request *req_ctx = &state->caam_req;
 	struct device *dev = ctx->priv->dev;
-	struct dpaa_fl_entry *in_fle = &req_ctx->fd_flt[1];
-	struct dpaa_fl_entry *out_fle = &req_ctx->fd_flt[0];
+	struct dpaa2_fl_entry *in_fle = &req_ctx->fd_flt[1];
+	struct dpaa2_fl_entry *out_fle = &req_ctx->fd_flt[0];
 	gfp_t flags = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
 		       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;
 	u8 *buf = state->current_buf ? state->buf_1 : state->buf_0;
@@ -4098,10 +4098,10 @@ static int ahash_final_no_ctx(struct ahash_request *req)
 
 	memset(&req_ctx->fd_flt, 0, sizeof(req_ctx->fd_flt));
 	dpaa2_fl_set_final(in_fle, true);
-	dpaa2_fl_set_format(in_fle, dpaa_fl_single);
+	dpaa2_fl_set_format(in_fle, dpaa2_fl_single);
 	dpaa2_fl_set_addr(in_fle, state->buf_dma);
 	dpaa2_fl_set_len(in_fle, buflen);
-	dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+	dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 	dpaa2_fl_set_addr(out_fle, edesc->dst_dma);
 	dpaa2_fl_set_len(out_fle, digestsize);
 
@@ -4127,8 +4127,8 @@ static int ahash_update_no_ctx(struct ahash_request *req)
 	struct caam_hash_state *state = ahash_request_ctx(req);
 	struct caam_request *req_ctx = &state->caam_req;
 	struct device *dev = ctx->priv->dev;
-	struct dpaa_fl_entry *in_fle = &req_ctx->fd_flt[1];
-	struct dpaa_fl_entry *out_fle = &req_ctx->fd_flt[0];
+	struct dpaa2_fl_entry *in_fle = &req_ctx->fd_flt[1];
+	struct dpaa2_fl_entry *out_fle = &req_ctx->fd_flt[0];
 	gfp_t flags = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
 		       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;
 	u8 *buf = state->current_buf ? state->buf_1 : state->buf_0;
@@ -4139,7 +4139,7 @@ static int ahash_update_no_ctx(struct ahash_request *req)
 	int in_len = *buflen + req->nbytes, to_hash;
 	int qm_sg_bytes, src_nents;
 	struct ahash_edesc *edesc;
-	struct dpaa_sg_entry *sg_table;
+	struct dpaa2_sg_entry *sg_table;
 	bool chained = false;
 	int ret = 0;
 
@@ -4149,7 +4149,7 @@ static int ahash_update_no_ctx(struct ahash_request *req)
 	if (to_hash) {
 		src_nents = __sg_count(req->src, req->nbytes - (*next_buflen),
 				       &chained);
-		qm_sg_bytes = (1 + src_nents) * sizeof(struct dpaa_sg_entry);
+		qm_sg_bytes = (1 + src_nents) * sizeof(struct dpaa2_sg_entry);
 
 		/* allocate space for base edesc and link tables */
 		edesc = qi_cache_zalloc(GFP_DMA | flags);
@@ -4189,9 +4189,9 @@ static int ahash_update_no_ctx(struct ahash_request *req)
 
 		memset(&req_ctx->fd_flt, 0, sizeof(req_ctx->fd_flt));
 		dpaa2_fl_set_final(in_fle, true);
-		dpaa2_fl_set_format(in_fle, dpaa_fl_sg);
+		dpaa2_fl_set_format(in_fle, dpaa2_fl_sg);
 		dpaa2_fl_set_addr(in_fle, edesc->qm_sg_dma);
-		dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+		dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 		dpaa2_fl_set_addr(out_fle, state->ctx_dma);
 
 		dpaa2_fl_set_len(out_fle, ctx->ctx_len);
@@ -4237,8 +4237,8 @@ static int ahash_finup_no_ctx(struct ahash_request *req)
 	struct caam_hash_state *state = ahash_request_ctx(req);
 	struct caam_request *req_ctx = &state->caam_req;
 	struct device *dev = ctx->priv->dev;
-	struct dpaa_fl_entry *in_fle = &req_ctx->fd_flt[1];
-	struct dpaa_fl_entry *out_fle = &req_ctx->fd_flt[0];
+	struct dpaa2_fl_entry *in_fle = &req_ctx->fd_flt[1];
+	struct dpaa2_fl_entry *out_fle = &req_ctx->fd_flt[0];
 	gfp_t flags = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
 		       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;
 	u8 *buf = state->current_buf ? state->buf_1 : state->buf_0;
@@ -4248,14 +4248,14 @@ static int ahash_finup_no_ctx(struct ahash_request *req)
 	int qm_sg_bytes, qm_sg_src_index, src_nents;
 	int digestsize = crypto_ahash_digestsize(ahash);
 	struct ahash_edesc *edesc;
-	struct dpaa_sg_entry *sg_table;
+	struct dpaa2_sg_entry *sg_table;
 	bool chained = false;
 	int ret = 0;
 
 	src_nents = __sg_count(req->src, req->nbytes, &chained);
 	qm_sg_src_index = 2;
 	qm_sg_bytes = (qm_sg_src_index + src_nents) *
-			 sizeof(struct dpaa_sg_entry);
+			 sizeof(struct dpaa2_sg_entry);
 
 	/* allocate space for base edesc and link tables */
 	edesc = qi_cache_zalloc(GFP_DMA | flags);
@@ -4291,9 +4291,9 @@ static int ahash_finup_no_ctx(struct ahash_request *req)
 
 	memset(&req_ctx->fd_flt, 0, sizeof(req_ctx->fd_flt));
 	dpaa2_fl_set_final(in_fle, true);
-	dpaa2_fl_set_format(in_fle, dpaa_fl_sg);
+	dpaa2_fl_set_format(in_fle, dpaa2_fl_sg);
 	dpaa2_fl_set_addr(in_fle, edesc->qm_sg_dma);
-	dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+	dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 	dpaa2_fl_set_addr(out_fle, edesc->dst_dma);
 
 	/* TODO: Is this really needed? */
@@ -4325,8 +4325,8 @@ static int ahash_update_first(struct ahash_request *req)
 	struct caam_hash_state *state = ahash_request_ctx(req);
 	struct caam_request *req_ctx = &state->caam_req;
 	struct device *dev = ctx->priv->dev;
-	struct dpaa_fl_entry *in_fle = &req_ctx->fd_flt[1];
-	struct dpaa_fl_entry *out_fle = &req_ctx->fd_flt[0];
+	struct dpaa2_fl_entry *in_fle = &req_ctx->fd_flt[1];
+	struct dpaa2_fl_entry *out_fle = &req_ctx->fd_flt[0];
 	gfp_t flags = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
 		       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;
 	u8 *next_buf = state->current_buf ? state->buf_1 : state->buf_0;
@@ -4335,7 +4335,7 @@ static int ahash_update_first(struct ahash_request *req)
 	int to_hash;
 	int qm_sg_bytes, src_nents;
 	struct ahash_edesc *edesc;
-	struct dpaa_sg_entry *sg_table;
+	struct dpaa2_sg_entry *sg_table;
 	bool chained = false;
 	int ret = 0;
 
@@ -4348,7 +4348,7 @@ static int ahash_update_first(struct ahash_request *req)
 				     &chained);
 		dma_map_sg_chained(dev, req->src, src_nents ? : 1,
 				   DMA_TO_DEVICE, chained);
-		qm_sg_bytes = src_nents * sizeof(struct dpaa_sg_entry);
+		qm_sg_bytes = src_nents * sizeof(struct dpaa2_sg_entry);
 
 		/* allocate space for base edesc and link tables */
 		edesc = qi_cache_zalloc(GFP_DMA | flags);
@@ -4374,10 +4374,10 @@ static int ahash_update_first(struct ahash_request *req)
 				dev_err(dev, "unable to map S/G table\n");
 				return -ENOMEM;
 			}
-			dpaa2_fl_set_format(in_fle, dpaa_fl_sg);
+			dpaa2_fl_set_format(in_fle, dpaa2_fl_sg);
 			dpaa2_fl_set_addr(in_fle, edesc->qm_sg_dma);
 		} else {
-			dpaa2_fl_set_format(in_fle, dpaa_fl_single);
+			dpaa2_fl_set_format(in_fle, dpaa2_fl_single);
 			dpaa2_fl_set_addr(in_fle, sg_dma_address(req->src));
 		}
 
@@ -4392,7 +4392,7 @@ static int ahash_update_first(struct ahash_request *req)
 			return -ENOMEM;
 		}
 
-		dpaa2_fl_set_format(out_fle, dpaa_fl_single);
+		dpaa2_fl_set_format(out_fle, dpaa2_fl_single);
 		dpaa2_fl_set_addr(out_fle, state->ctx_dma);
 
 		dpaa2_fl_set_len(out_fle, ctx->ctx_len);
@@ -4849,13 +4849,13 @@ static void dpaa2_dpseci_free(struct dpaa2_caam_priv *priv)
 }
 
 static void dpaa2_caam_process_fd(struct dpaa2_caam_priv *priv,
-				  const struct dpaa_fd *fd)
+				  const struct dpaa2_fd *fd)
 {
 	struct caam_request *req;
 	dma_addr_t rflc_dma;
 	u32 err;
 
-	if (dpaa2_fd_get_format(fd) != dpaa_fd_list) {
+	if (dpaa2_fd_get_format(fd) != dpaa2_fd_list) {
 		dev_err(priv->dev, "Only Frame List FD format is supported!\n");
 		return;
 	}
@@ -5281,7 +5281,7 @@ static int __cold dpaa2_caam_remove(struct fsl_mc_device *ls_dev)
 int dpaa2_caam_enqueue(struct device *dev, struct caam_request *req)
 {
 	size_t size;
-	struct dpaa_fd fd;
+	struct dpaa2_fd fd;
 	struct dpaa2_caam_priv *priv = dev_get_drvdata(dev);
 	dma_addr_t rflc_dma;
 	int err, i;
@@ -5300,7 +5300,7 @@ int dpaa2_caam_enqueue(struct device *dev, struct caam_request *req)
 	}
 
 	memset(&fd, 0, sizeof(fd));
-	dpaa2_fd_set_format(&fd, dpaa_fd_list);
+	dpaa2_fd_set_format(&fd, dpaa2_fd_list);
 	dpaa2_fd_set_addr(&fd, req->fd_flt_dma);
 	dpaa2_fd_set_len(&fd, req->fd_flt[1].len);
 	dpaa2_fd_set_flc(&fd, req->flc_dma);
diff --git a/drivers/crypto/dpaa2-caam/dpaa2-caam.h b/drivers/crypto/dpaa2-caam/dpaa2-caam.h
index da90624..b8ab040 100644
--- a/drivers/crypto/dpaa2-caam/dpaa2-caam.h
+++ b/drivers/crypto/dpaa2-caam/dpaa2-caam.h
@@ -145,7 +145,7 @@ struct aead_edesc {
 	dma_addr_t iv_dma;
 	int qm_sg_bytes;
 	dma_addr_t qm_sg_dma;
-	struct dpaa_sg_entry qm_sg[0];
+	struct dpaa2_sg_entry qm_sg[0];
 };
 
 /*
@@ -167,7 +167,7 @@ struct ablkcipher_edesc {
 	dma_addr_t iv_dma;
 	int qm_sg_bytes;
 	dma_addr_t qm_sg_dma;
-	struct dpaa_sg_entry qm_sg[0];
+	struct dpaa2_sg_entry qm_sg[0];
 };
 
 /*
@@ -185,7 +185,7 @@ struct ahash_edesc {
 	int src_nents;
 	int qm_sg_bytes;
 	dma_addr_t qm_sg_dma;
-	struct dpaa_sg_entry qm_sg[0];
+	struct dpaa2_sg_entry qm_sg[0];
 };
 
 /**
@@ -212,7 +212,7 @@ struct caam_flc {
  * @edesc: extended descriptor; points to one of {ablkcipher,ahash,aead}_edesc
  */
 struct caam_request {
-	struct dpaa_fl_entry fd_flt[2];
+	struct dpaa2_fl_entry fd_flt[2];
 	dma_addr_t fd_flt_dma;
 	struct caam_flc *flc;
 	dma_addr_t flc_dma;
diff --git a/drivers/crypto/dpaa2-caam/sg_sw_qm.h b/drivers/crypto/dpaa2-caam/sg_sw_qm.h
index 368c513..c5c62ce 100644
--- a/drivers/crypto/dpaa2-caam/sg_sw_qm.h
+++ b/drivers/crypto/dpaa2-caam/sg_sw_qm.h
@@ -34,11 +34,11 @@
 
 #include "../../../drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h"
 
-static inline void dma_to_qm_sg_one(struct dpaa_sg_entry *qm_sg_ptr,
+static inline void dma_to_qm_sg_one(struct dpaa2_sg_entry *qm_sg_ptr,
 				    dma_addr_t dma, u32 len, u16 offset)
 {
 	dpaa2_sg_set_addr(qm_sg_ptr, dma);
-	dpaa2_sg_set_format(qm_sg_ptr, dpaa_sg_single);
+	dpaa2_sg_set_format(qm_sg_ptr, dpaa2_sg_single);
 	dpaa2_sg_set_final(qm_sg_ptr, false);
 	dpaa2_sg_set_len(qm_sg_ptr, len);
 	dpaa2_sg_set_bpid(qm_sg_ptr, 0);
@@ -49,9 +49,9 @@ static inline void dma_to_qm_sg_one(struct dpaa_sg_entry *qm_sg_ptr,
  * convert scatterlist to h/w link table format
  * but does not have final bit; instead, returns last entry
  */
-static inline struct dpaa_sg_entry *
+static inline struct dpaa2_sg_entry *
 sg_to_qm_sg(struct scatterlist *sg, int sg_count,
-	    struct dpaa_sg_entry *qm_sg_ptr, u16 offset)
+	    struct dpaa2_sg_entry *qm_sg_ptr, u16 offset)
 {
 	while (sg_count && sg) {
 		dma_to_qm_sg_one(qm_sg_ptr, sg_dma_address(sg),
@@ -68,7 +68,8 @@ sg_to_qm_sg(struct scatterlist *sg, int sg_count,
  * scatterlist must have been previously dma mapped
  */
 static inline void sg_to_qm_sg_last(struct scatterlist *sg, int sg_count,
-				    struct dpaa_sg_entry *qm_sg_ptr, u16 offset)
+				    struct dpaa2_sg_entry *qm_sg_ptr,
+				    u16 offset)
 {
 	qm_sg_ptr = sg_to_qm_sg(sg, sg_count, qm_sg_ptr, offset);
 	dpaa2_sg_set_final(qm_sg_ptr, true);
diff --git a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth-trace.h b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth-trace.h
index adb5aa4..f2ba5bd 100644
--- a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth-trace.h
+++ b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth-trace.h
@@ -52,7 +52,7 @@
 DECLARE_EVENT_CLASS(dpaa2_eth_fd,
 		    /* Trace function prototype */
 		    TP_PROTO(struct net_device *netdev,
-			     const struct dpaa_fd *fd),
+			     const struct dpaa2_fd *fd),
 
 		    /* Repeat argument list here */
 		    TP_ARGS(netdev, fd),
@@ -97,7 +97,7 @@ DECLARE_EVENT_CLASS(dpaa2_eth_fd,
 /* Tx (egress) fd */
 DEFINE_EVENT(dpaa2_eth_fd, dpaa2_tx_fd,
 	     TP_PROTO(struct net_device *netdev,
-		      const struct dpaa_fd *fd),
+		      const struct dpaa2_fd *fd),
 
 	     TP_ARGS(netdev, fd)
 );
@@ -105,7 +105,7 @@ DEFINE_EVENT(dpaa2_eth_fd, dpaa2_tx_fd,
 /* Rx fd */
 DEFINE_EVENT(dpaa2_eth_fd, dpaa2_rx_fd,
 	     TP_PROTO(struct net_device *netdev,
-		      const struct dpaa_fd *fd),
+		      const struct dpaa2_fd *fd),
 
 	     TP_ARGS(netdev, fd)
 );
@@ -113,7 +113,7 @@ DEFINE_EVENT(dpaa2_eth_fd, dpaa2_rx_fd,
 /* Tx confirmation fd */
 DEFINE_EVENT(dpaa2_eth_fd, dpaa2_tx_conf_fd,
 	     TP_PROTO(struct net_device *netdev,
-		      const struct dpaa_fd *fd),
+		      const struct dpaa2_fd *fd),
 
 	     TP_ARGS(netdev, fd)
 );
diff --git a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c
index e4584b3..5518615 100644
--- a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c
+++ b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.c
@@ -100,15 +100,15 @@ static void dpaa2_eth_rx_csum(struct dpaa2_eth_priv *priv,
  * Not to be used for Tx conf FDs or on any other paths.
  */
 static void dpaa2_eth_free_rx_fd(struct dpaa2_eth_priv *priv,
-				 const struct dpaa_fd *fd,
+				 const struct dpaa2_fd *fd,
 				 void *vaddr)
 {
 	struct device *dev = priv->net_dev->dev.parent;
 	dma_addr_t addr = dpaa2_fd_get_addr(fd);
 	uint8_t fd_format = dpaa2_fd_get_format(fd);
 
-	if (fd_format == dpaa_fd_sg) {
-		struct dpaa_sg_entry *sgt = vaddr + dpaa2_fd_get_offset(fd);
+	if (fd_format == dpaa2_fd_sg) {
+		struct dpaa2_sg_entry *sgt = vaddr + dpaa2_fd_get_offset(fd);
 		void *sg_vaddr;
 		int i;
 
@@ -132,7 +132,7 @@ static void dpaa2_eth_free_rx_fd(struct dpaa2_eth_priv *priv,
 
 /* Build a linear skb based on a single-buffer frame descriptor */
 static struct sk_buff *dpaa2_eth_build_linear_skb(struct dpaa2_eth_priv *priv,
-						  const struct dpaa_fd *fd,
+						  const struct dpaa2_fd *fd,
 						  void *fd_vaddr)
 {
 	struct sk_buff *skb = NULL;
@@ -159,7 +159,7 @@ static struct sk_buff *dpaa2_eth_build_linear_skb(struct dpaa2_eth_priv *priv,
 
 /* Build a non linear (fragmented) skb based on a S/G table */
 static struct sk_buff *dpaa2_eth_build_frag_skb(struct dpaa2_eth_priv *priv,
-						struct dpaa_sg_entry *sgt)
+						struct dpaa2_sg_entry *sgt)
 {
 	struct sk_buff *skb = NULL;
 	struct device *dev = priv->net_dev->dev.parent;
@@ -173,12 +173,12 @@ static struct sk_buff *dpaa2_eth_build_frag_skb(struct dpaa2_eth_priv *priv,
 	int i;
 
 	for (i = 0; i < DPAA2_ETH_MAX_SG_ENTRIES; i++) {
-		struct dpaa_sg_entry *sge = &sgt[i];
+		struct dpaa2_sg_entry *sge = &sgt[i];
 
 		dpaa2_sg_le_to_cpu(sge);
 
 		/* We don't support anything else yet! */
-		BUG_ON(dpaa2_sg_get_format(sge) != dpaa_sg_single);
+		BUG_ON(dpaa2_sg_get_format(sge) != dpaa2_sg_single);
 
 		/* Get the address, offset and length from the S/G entry */
 		sg_addr = dpaa2_sg_get_addr(sge);
@@ -235,7 +235,7 @@ static struct sk_buff *dpaa2_eth_build_frag_skb(struct dpaa2_eth_priv *priv,
 }
 
 static void dpaa2_eth_rx(struct dpaa2_eth_priv *priv,
-			 const struct dpaa_fd *fd,
+			 const struct dpaa2_fd *fd,
 			 struct napi_struct *napi)
 {
 	dma_addr_t addr = dpaa2_fd_get_addr(fd);
@@ -260,10 +260,10 @@ static void dpaa2_eth_rx(struct dpaa2_eth_priv *priv,
 	percpu_stats = this_cpu_ptr(priv->percpu_stats);
 	percpu_extras = this_cpu_ptr(priv->percpu_extras);
 
-	if (fd_format == dpaa_fd_single) {
+	if (fd_format == dpaa2_fd_single) {
 		skb = dpaa2_eth_build_linear_skb(priv, fd, vaddr);
-	} else if (fd_format == dpaa_fd_sg) {
-		struct dpaa_sg_entry *sgt =
+	} else if (fd_format == dpaa2_fd_sg) {
+		struct dpaa2_sg_entry *sgt =
 				vaddr + dpaa2_fd_get_offset(fd);
 		skb = dpaa2_eth_build_frag_skb(priv, sgt);
 		put_page(virt_to_head_page(vaddr));
@@ -309,7 +309,7 @@ err_build_skb:
 
 #ifdef CONFIG_FSL_DPAA2_ETH_USE_ERR_QUEUE
 static void dpaa2_eth_rx_err(struct dpaa2_eth_priv *priv,
-			     const struct dpaa_fd *fd,
+			     const struct dpaa2_fd *fd,
 			     struct napi_struct *napi __always_unused)
 {
 	struct device *dev = priv->net_dev->dev.parent;
@@ -351,7 +351,7 @@ static int dpaa2_eth_store_consume(struct dpaa2_eth_channel *ch)
 	struct dpaa2_eth_priv *priv = ch->priv;
 	struct dpaa2_eth_fq *fq;
 	struct dpaa2_dq *dq;
-	const struct dpaa_fd *fd;
+	const struct dpaa2_fd *fd;
 	int cleaned = 0;
 	int is_last;
 
@@ -385,13 +385,13 @@ static int dpaa2_eth_store_consume(struct dpaa2_eth_channel *ch)
 
 static int dpaa2_eth_build_sg_fd(struct dpaa2_eth_priv *priv,
 				 struct sk_buff *skb,
-				 struct dpaa_fd *fd)
+				 struct dpaa2_fd *fd)
 {
 	struct device *dev = priv->net_dev->dev.parent;
 	void *sgt_buf = NULL;
 	dma_addr_t addr;
 	int nr_frags = skb_shinfo(skb)->nr_frags;
-	struct dpaa_sg_entry *sgt;
+	struct dpaa2_sg_entry *sgt;
 	int i, j, err;
 	int sgt_buf_size;
 	struct scatterlist *scl, *crt_scl;
@@ -421,7 +421,7 @@ static int dpaa2_eth_build_sg_fd(struct dpaa2_eth_priv *priv,
 
 	/* Prepare the HW SGT structure */
 	sgt_buf_size = priv->tx_data_offset +
-		       sizeof(struct dpaa_sg_entry) * (1 + num_dma_bufs);
+		       sizeof(struct dpaa2_sg_entry) * (1 + num_dma_bufs);
 	sgt_buf = kzalloc(sgt_buf_size + DPAA2_ETH_TX_BUF_ALIGN, GFP_ATOMIC);
 	if (unlikely(!sgt_buf)) {
 		netdev_err(priv->net_dev, "failed to allocate SGT buffer\n");
@@ -437,14 +437,14 @@ static int dpaa2_eth_build_sg_fd(struct dpaa2_eth_priv *priv,
 	 */
 	memset(sgt_buf + priv->buf_layout.private_data_size, 0, 8);
 
-	sgt = (struct dpaa_sg_entry *)(sgt_buf + priv->tx_data_offset);
+	sgt = (struct dpaa2_sg_entry *)(sgt_buf + priv->tx_data_offset);
 
 	/* Fill in the HW SGT structure.
 	 *
 	 * sgt_buf is zeroed out, so the following fields are implicit
 	 * in all sgt entries:
 	 *   - offset is 0
-	 *   - format is 'dpaa_sg_single'
+	 *   - format is 'dpaa2_sg_single'
 	 */
 	for_each_sg(scl, crt_scl, num_dma_bufs, i) {
 		dpaa2_sg_set_addr(&sgt[i], sg_dma_address(crt_scl));
@@ -474,7 +474,7 @@ static int dpaa2_eth_build_sg_fd(struct dpaa2_eth_priv *priv,
 	}
 	dpaa2_fd_set_offset(fd, priv->tx_data_offset);
 	dpaa2_fd_set_bpid(fd, priv->dpbp_attrs.bpid);
-	dpaa2_fd_set_format(fd, dpaa_fd_sg);
+	dpaa2_fd_set_format(fd, dpaa2_fd_sg);
 	dpaa2_fd_set_addr(fd, addr);
 	dpaa2_fd_set_len(fd, skb->len);
 
@@ -494,7 +494,7 @@ dma_map_sg_failed:
 
 static int dpaa2_eth_build_single_fd(struct dpaa2_eth_priv *priv,
 				     struct sk_buff *skb,
-				     struct dpaa_fd *fd)
+				     struct dpaa2_fd *fd)
 {
 	struct device *dev = priv->net_dev->dev.parent;
 	uint8_t *buffer_start;
@@ -532,7 +532,7 @@ static int dpaa2_eth_build_single_fd(struct dpaa2_eth_priv *priv,
 	dpaa2_fd_set_offset(fd, (uint16_t)(skb->data - buffer_start));
 	dpaa2_fd_set_bpid(fd, priv->dpbp_attrs.bpid);
 	dpaa2_fd_set_len(fd, skb->len);
-	dpaa2_fd_set_format(fd, dpaa_fd_single);
+	dpaa2_fd_set_format(fd, dpaa2_fd_single);
 
 	fd->simple.ctrl = DPAA2_FD_CTRL_ASAL | DPAA2_FD_CTRL_PTA |
 			 DPAA2_FD_CTRL_PTV1;
@@ -548,7 +548,7 @@ static int dpaa2_eth_build_single_fd(struct dpaa2_eth_priv *priv,
  * to be checked if we're on the confirmation path.
  */
 static void dpaa2_eth_free_fd(const struct dpaa2_eth_priv *priv,
-			       const struct dpaa_fd *fd,
+			       const struct dpaa2_fd *fd,
 			       uint32_t *status)
 {
 	struct device *dev = priv->net_dev->dev.parent;
@@ -564,7 +564,7 @@ static void dpaa2_eth_free_fd(const struct dpaa2_eth_priv *priv,
 
 	fd_addr = dpaa2_fd_get_addr(fd);
 	skbh = phys_to_virt(fd_addr);
-	fd_single = (dpaa2_fd_get_format(fd) == dpaa_fd_single);
+	fd_single = (dpaa2_fd_get_format(fd) == dpaa2_fd_single);
 
 	if (fd_single) {
 		skb = *skbh;
@@ -589,7 +589,7 @@ static void dpaa2_eth_free_fd(const struct dpaa2_eth_priv *priv,
 		/* Unmap the SGT buffer */
 		nr_frags = skb_shinfo(skb)->nr_frags;
 		unmap_size = priv->tx_data_offset +
-		       sizeof(struct dpaa_sg_entry) * (1 + num_dma_bufs);
+		       sizeof(struct dpaa2_sg_entry) * (1 + num_dma_bufs);
 		dma_unmap_single(dev, fd_addr, unmap_size, DMA_TO_DEVICE);
 	}
 
@@ -613,7 +613,7 @@ static void dpaa2_eth_free_fd(const struct dpaa2_eth_priv *priv,
 static int dpaa2_eth_tx(struct sk_buff *skb, struct net_device *net_dev)
 {
 	struct dpaa2_eth_priv *priv = netdev_priv(net_dev);
-	struct dpaa_fd fd;
+	struct dpaa2_fd fd;
 	struct rtnl_link_stats64 *percpu_stats;
 	struct dpaa2_eth_stats *percpu_extras;
 	int err, i;
@@ -695,7 +695,7 @@ err_alloc_headroom:
 }
 
 static void dpaa2_eth_tx_conf(struct dpaa2_eth_priv *priv,
-			      const struct dpaa_fd *fd,
+			      const struct dpaa2_fd *fd,
 			      struct napi_struct *napi __always_unused)
 {
 	struct rtnl_link_stats64 *percpu_stats;
diff --git a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h
index c2056bc..264a441 100644
--- a/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h
+++ b/drivers/staging/fsl-dpaa2/ethernet/dpaa2-eth.h
@@ -229,7 +229,7 @@ struct dpaa2_eth_fq {
 	enum dpaa2_eth_fq_type type;
 
 	void (*consume)(struct dpaa2_eth_priv *,
-			const struct dpaa_fd *,
+			const struct dpaa2_fd *,
 			struct napi_struct *);
 	struct dpaa2_eth_priv *netdev_priv;	/* backpointer */
 	struct dpaa2_eth_fq_stats stats;
diff --git a/drivers/staging/fsl-mc/bus/dpio/dpio_service.c b/drivers/staging/fsl-mc/bus/dpio/dpio_service.c
index 7cb0333f..4f62f9d 100644
--- a/drivers/staging/fsl-mc/bus/dpio/dpio_service.c
+++ b/drivers/staging/fsl-mc/bus/dpio/dpio_service.c
@@ -601,7 +601,7 @@ EXPORT_SYMBOL(dpaa2_io_service_pull_channel);
 
 int dpaa2_io_service_enqueue_fq(struct dpaa2_io *d,
 			       uint32_t fqid,
-			       const struct dpaa_fd *fd)
+			       const struct dpaa2_fd *fd)
 {
 	struct qbman_eq_desc ed;
 
@@ -618,7 +618,7 @@ EXPORT_SYMBOL(dpaa2_io_service_enqueue_fq);
 
 int dpaa2_io_service_enqueue_qd(struct dpaa2_io *d,
 			       uint32_t qdid, uint8_t prio, uint16_t qdbin,
-			       const struct dpaa_fd *fd)
+			       const struct dpaa2_fd *fd)
 {
 	struct qbman_eq_desc ed;
 
diff --git a/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c b/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c
index 091685b..584265d 100644
--- a/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c
+++ b/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c
@@ -866,11 +866,11 @@ uint64_t dpaa2_dq_fqd_ctx(const struct dpaa2_dq *dq)
 }
 EXPORT_SYMBOL(dpaa2_dq_fqd_ctx);
 
-const struct dpaa_fd *dpaa2_dq_fd(const struct dpaa2_dq *dq)
+const struct dpaa2_fd *dpaa2_dq_fd(const struct dpaa2_dq *dq)
 {
 	const uint32_t *p = qb_cl(dq);
 
-	return (const struct dpaa_fd *)&p[8];
+	return (const struct dpaa2_fd *)&p[8];
 }
 EXPORT_SYMBOL(dpaa2_dq_fd);
 
diff --git a/drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h b/drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h
index 810a717..bf478e4 100644
--- a/drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h
+++ b/drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h
@@ -32,7 +32,7 @@
 #define __FSL_DPAA2_FD_H
 
 /**
- * struct dpaa_fd - Place-holder for FDs.
+ * struct dpaa2_fd - Place-holder for FDs.
  *
  * We represent it via the simplest form that we need for now. Different
  * overlays may be needed to support different options, etc. (It is impractical
@@ -40,10 +40,10 @@
  * read-modify-writes) would be worst-case performance whether or not
  * circumstances required them.)
  */
-struct dpaa_fd {
+struct dpaa2_fd {
 	union {
 		u32 words[8];
-		struct dpaa_fd_simple {
+		struct dpaa2_fd_simple {
 			u32 addr_lo;
 			u32 addr_hi;
 			u32 len;
@@ -59,10 +59,10 @@ struct dpaa_fd {
 	};
 };
 
-enum dpaa_fd_format {
-	dpaa_fd_single = 0,
-	dpaa_fd_list,
-	dpaa_fd_sg
+enum dpaa2_fd_format {
+	dpaa2_fd_single = 0,
+	dpaa2_fd_list,
+	dpaa2_fd_sg
 };
 
 /* Accessors for SG entry fields
@@ -79,7 +79,7 @@ enum dpaa_fd_format {
  *
  * Return the address in the frame descritpor.
  */
-static inline dma_addr_t dpaa2_fd_get_addr(const struct dpaa_fd *fd)
+static inline dma_addr_t dpaa2_fd_get_addr(const struct dpaa2_fd *fd)
 {
 	return (dma_addr_t)((((uint64_t)fd->simple.addr_hi) << 32)
 				+ fd->simple.addr_lo);
@@ -90,7 +90,7 @@ static inline dma_addr_t dpaa2_fd_get_addr(const struct dpaa_fd *fd)
  * @fd: the given frame descriptor.
  * @addr: the address needs to be set in frame descriptor.
  */
-static inline void dpaa2_fd_set_addr(struct dpaa_fd *fd, dma_addr_t addr)
+static inline void dpaa2_fd_set_addr(struct dpaa2_fd *fd, dma_addr_t addr)
 {
 	fd->simple.addr_hi = upper_32_bits(addr);
 	fd->simple.addr_lo = lower_32_bits(addr);
@@ -102,7 +102,7 @@ static inline void dpaa2_fd_set_addr(struct dpaa_fd *fd, dma_addr_t addr)
  *
  * Return the frame context field in the frame descriptor.
  */
-static inline u32 dpaa2_fd_get_frc(const struct dpaa_fd *fd)
+static inline u32 dpaa2_fd_get_frc(const struct dpaa2_fd *fd)
 {
 	return fd->simple.frc;
 }
@@ -112,7 +112,7 @@ static inline u32 dpaa2_fd_get_frc(const struct dpaa_fd *fd)
  * @fd: the given frame descriptor.
  * @frc: the frame context needs to be set in frame descriptor.
  */
-static inline void dpaa2_fd_set_frc(struct dpaa_fd *fd, u32 frc)
+static inline void dpaa2_fd_set_frc(struct dpaa2_fd *fd, u32 frc)
 {
 	fd->simple.frc = frc;
 }
@@ -123,7 +123,7 @@ static inline void dpaa2_fd_set_frc(struct dpaa_fd *fd, u32 frc)
  *
  * Return the flow context in the frame descriptor.
  */
-static inline dma_addr_t dpaa2_fd_get_flc(const struct dpaa_fd *fd)
+static inline dma_addr_t dpaa2_fd_get_flc(const struct dpaa2_fd *fd)
 {
 	return (dma_addr_t)((((uint64_t)fd->simple.flc_hi) << 32) +
 			    fd->simple.flc_lo);
@@ -134,7 +134,7 @@ static inline dma_addr_t dpaa2_fd_get_flc(const struct dpaa_fd *fd)
  * @fd: the given frame descriptor.
  * @flc_addr: the flow context needs to be set in frame descriptor.
  */
-static inline void dpaa2_fd_set_flc(struct dpaa_fd *fd,  dma_addr_t flc_addr)
+static inline void dpaa2_fd_set_flc(struct dpaa2_fd *fd,  dma_addr_t flc_addr)
 {
 	fd->simple.flc_hi = upper_32_bits(flc_addr);
 	fd->simple.flc_lo = lower_32_bits(flc_addr);
@@ -146,7 +146,7 @@ static inline void dpaa2_fd_set_flc(struct dpaa_fd *fd,  dma_addr_t flc_addr)
  *
  * Return the length field in the frame descriptor.
  */
-static inline u32 dpaa2_fd_get_len(const struct dpaa_fd *fd)
+static inline u32 dpaa2_fd_get_len(const struct dpaa2_fd *fd)
 {
 	return fd->simple.len;
 }
@@ -156,7 +156,7 @@ static inline u32 dpaa2_fd_get_len(const struct dpaa_fd *fd)
  * @fd: the given frame descriptor.
  * @len: the length needs to be set in frame descriptor.
  */
-static inline void dpaa2_fd_set_len(struct dpaa_fd *fd, u32 len)
+static inline void dpaa2_fd_set_len(struct dpaa2_fd *fd, u32 len)
 {
 	fd->simple.len = len;
 }
@@ -167,7 +167,7 @@ static inline void dpaa2_fd_set_len(struct dpaa_fd *fd, u32 len)
  *
  * Return the offset.
  */
-static inline uint16_t dpaa2_fd_get_offset(const struct dpaa_fd *fd)
+static inline uint16_t dpaa2_fd_get_offset(const struct dpaa2_fd *fd)
 {
 	return (uint16_t)(fd->simple.bpid_offset >> 16) & 0x0FFF;
 }
@@ -178,7 +178,7 @@ static inline uint16_t dpaa2_fd_get_offset(const struct dpaa_fd *fd)
  * @fd: the given frame descriptor.
  * @offset: the offset needs to be set in frame descriptor.
  */
-static inline void dpaa2_fd_set_offset(struct dpaa_fd *fd, uint16_t offset)
+static inline void dpaa2_fd_set_offset(struct dpaa2_fd *fd, uint16_t offset)
 {
 	fd->simple.bpid_offset &= 0xF000FFFF;
 	fd->simple.bpid_offset |= (u32)offset << 16;
@@ -190,9 +190,10 @@ static inline void dpaa2_fd_set_offset(struct dpaa_fd *fd, uint16_t offset)
  *
  * Return the format.
  */
-static inline enum dpaa_fd_format dpaa2_fd_get_format(const struct dpaa_fd *fd)
+static inline enum dpaa2_fd_format dpaa2_fd_get_format(
+						const struct dpaa2_fd *fd)
 {
-	return (enum dpaa_fd_format)((fd->simple.bpid_offset >> 28) & 0x3);
+	return (enum dpaa2_fd_format)((fd->simple.bpid_offset >> 28) & 0x3);
 }
 
 /**
@@ -201,8 +202,8 @@ static inline enum dpaa_fd_format dpaa2_fd_get_format(const struct dpaa_fd *fd)
  * @fd: the given frame descriptor.
  * @format: the format needs to be set in frame descriptor.
  */
-static inline void dpaa2_fd_set_format(struct dpaa_fd *fd,
-				       enum dpaa_fd_format format)
+static inline void dpaa2_fd_set_format(struct dpaa2_fd *fd,
+				       enum dpaa2_fd_format format)
 {
 	fd->simple.bpid_offset &= 0xCFFFFFFF;
 	fd->simple.bpid_offset |= (u32)format << 28;
@@ -214,7 +215,7 @@ static inline void dpaa2_fd_set_format(struct dpaa_fd *fd,
  *
  * Return the bpid.
  */
-static inline uint16_t dpaa2_fd_get_bpid(const struct dpaa_fd *fd)
+static inline uint16_t dpaa2_fd_get_bpid(const struct dpaa2_fd *fd)
 {
 	return (uint16_t)(fd->simple.bpid_offset & 0xFFFF);
 }
@@ -225,26 +226,26 @@ static inline uint16_t dpaa2_fd_get_bpid(const struct dpaa_fd *fd)
  * @fd: the given frame descriptor.
  * @bpid: the bpid needs to be set in frame descriptor.
  */
-static inline void dpaa2_fd_set_bpid(struct dpaa_fd *fd, uint16_t bpid)
+static inline void dpaa2_fd_set_bpid(struct dpaa2_fd *fd, uint16_t bpid)
 {
 	fd->simple.bpid_offset &= 0xFFFF0000;
 	fd->simple.bpid_offset |= (u32)bpid;
 }
 
 /**
- * struct dpaa_sg_entry - the scatter-gathering structure
+ * struct dpaa2_sg_entry - the scatter-gathering structure
  */
-struct dpaa_sg_entry {
+struct dpaa2_sg_entry {
 	u32 addr_lo;
 	u32 addr_hi;
 	u32 len;
 	u32 bpid_offset;
 };
 
-enum dpaa_sg_format {
-	dpaa_sg_single = 0,
-	dpaa_sg_frame_data,
-	dpaa_sg_sgt_ext
+enum dpaa2_sg_format {
+	dpaa2_sg_single = 0,
+	dpaa2_sg_frame_data,
+	dpaa2_sg_sgt_ext
 };
 
 /**
@@ -253,7 +254,7 @@ enum dpaa_sg_format {
  *
  * Return the address.
  */
-static inline dma_addr_t dpaa2_sg_get_addr(const struct dpaa_sg_entry *sg)
+static inline dma_addr_t dpaa2_sg_get_addr(const struct dpaa2_sg_entry *sg)
 {
 	return (dma_addr_t)((((u64)sg->addr_hi) << 32) + sg->addr_lo);
 }
@@ -263,14 +264,14 @@ static inline dma_addr_t dpaa2_sg_get_addr(const struct dpaa_sg_entry *sg)
  * @sg: the given scatter-gathering object.
  * @addr: the address to be set.
  */
-static inline void dpaa2_sg_set_addr(struct dpaa_sg_entry *sg, dma_addr_t addr)
+static inline void dpaa2_sg_set_addr(struct dpaa2_sg_entry *sg, dma_addr_t addr)
 {
 	sg->addr_hi = upper_32_bits(addr);
 	sg->addr_lo = lower_32_bits(addr);
 }
 
 
-static inline bool dpaa2_sg_short_len(const struct dpaa_sg_entry *sg)
+static inline bool dpaa2_sg_short_len(const struct dpaa2_sg_entry *sg)
 {
 	return (sg->bpid_offset >> 30) & 0x1;
 }
@@ -281,7 +282,7 @@ static inline bool dpaa2_sg_short_len(const struct dpaa_sg_entry *sg)
  *
  * Return the length.
  */
-static inline u32 dpaa2_sg_get_len(const struct dpaa_sg_entry *sg)
+static inline u32 dpaa2_sg_get_len(const struct dpaa2_sg_entry *sg)
 {
 	if (dpaa2_sg_short_len(sg))
 		return sg->len & 0x1FFFF;
@@ -293,7 +294,7 @@ static inline u32 dpaa2_sg_get_len(const struct dpaa_sg_entry *sg)
  * @sg: the given scatter-gathering object.
  * @len: the length to be set.
  */
-static inline void dpaa2_sg_set_len(struct dpaa_sg_entry *sg, u32 len)
+static inline void dpaa2_sg_set_len(struct dpaa2_sg_entry *sg, u32 len)
 {
 	sg->len = len;
 }
@@ -304,7 +305,7 @@ static inline void dpaa2_sg_set_len(struct dpaa_sg_entry *sg, u32 len)
  *
  * Return the offset.
  */
-static inline u16 dpaa2_sg_get_offset(const struct dpaa_sg_entry *sg)
+static inline u16 dpaa2_sg_get_offset(const struct dpaa2_sg_entry *sg)
 {
 	return (u16)(sg->bpid_offset >> 16) & 0x0FFF;
 }
@@ -314,7 +315,7 @@ static inline u16 dpaa2_sg_get_offset(const struct dpaa_sg_entry *sg)
  * @sg: the given scatter-gathering object.
  * @offset: the offset to be set.
  */
-static inline void dpaa2_sg_set_offset(struct dpaa_sg_entry *sg,
+static inline void dpaa2_sg_set_offset(struct dpaa2_sg_entry *sg,
 				       u16 offset)
 {
 	sg->bpid_offset &= 0xF000FFFF;
@@ -327,10 +328,10 @@ static inline void dpaa2_sg_set_offset(struct dpaa_sg_entry *sg,
  *
  * Return the format.
  */
-static inline enum dpaa_sg_format
-	dpaa2_sg_get_format(const struct dpaa_sg_entry *sg)
+static inline enum dpaa2_sg_format
+	dpaa2_sg_get_format(const struct dpaa2_sg_entry *sg)
 {
-	return (enum dpaa_sg_format)((sg->bpid_offset >> 28) & 0x3);
+	return (enum dpaa2_sg_format)((sg->bpid_offset >> 28) & 0x3);
 }
 
 /**
@@ -338,8 +339,8 @@ static inline enum dpaa_sg_format
  * @sg: the given scatter-gathering object.
  * @format: the format to be set.
  */
-static inline void dpaa2_sg_set_format(struct dpaa_sg_entry *sg,
-				       enum dpaa_sg_format format)
+static inline void dpaa2_sg_set_format(struct dpaa2_sg_entry *sg,
+				       enum dpaa2_sg_format format)
 {
 	sg->bpid_offset &= 0xCFFFFFFF;
 	sg->bpid_offset |= (u32)format << 28;
@@ -351,7 +352,7 @@ static inline void dpaa2_sg_set_format(struct dpaa_sg_entry *sg,
  *
  * Return the bpid.
  */
-static inline u16 dpaa2_sg_get_bpid(const struct dpaa_sg_entry *sg)
+static inline u16 dpaa2_sg_get_bpid(const struct dpaa2_sg_entry *sg)
 {
 	return (u16)(sg->bpid_offset & 0x3FFF);
 }
@@ -361,7 +362,7 @@ static inline u16 dpaa2_sg_get_bpid(const struct dpaa_sg_entry *sg)
  * @sg: the given scatter-gathering object.
  * @bpid: the bpid to be set.
  */
-static inline void dpaa2_sg_set_bpid(struct dpaa_sg_entry *sg, u16 bpid)
+static inline void dpaa2_sg_set_bpid(struct dpaa2_sg_entry *sg, u16 bpid)
 {
 	sg->bpid_offset &= 0xFFFFC000;
 	sg->bpid_offset |= (u32)bpid;
@@ -373,7 +374,7 @@ static inline void dpaa2_sg_set_bpid(struct dpaa_sg_entry *sg, u16 bpid)
  *
  * Return bool.
  */
-static inline bool dpaa2_sg_is_final(const struct dpaa_sg_entry *sg)
+static inline bool dpaa2_sg_is_final(const struct dpaa2_sg_entry *sg)
 {
 	return !!(sg->bpid_offset >> 31);
 }
@@ -383,7 +384,7 @@ static inline bool dpaa2_sg_is_final(const struct dpaa_sg_entry *sg)
  * @sg: the given scatter-gathering object.
  * @final: the final boolean to be set.
  */
-static inline void dpaa2_sg_set_final(struct dpaa_sg_entry *sg, bool final)
+static inline void dpaa2_sg_set_final(struct dpaa2_sg_entry *sg, bool final)
 {
 	sg->bpid_offset &= 0x7FFFFFFF;
 	sg->bpid_offset |= (u32)final << 31;
@@ -395,7 +396,7 @@ static inline void dpaa2_sg_set_final(struct dpaa_sg_entry *sg, bool final)
  * hardware and cpu
  */
 #ifdef __BIG_ENDIAN
-static inline void dpaa2_sg_cpu_to_le(struct dpaa_sg_entry *sg)
+static inline void dpaa2_sg_cpu_to_le(struct dpaa2_sg_entry *sg)
 {
 	uint32_t *p = (uint32_t *)sg;
 	int i;
@@ -404,7 +405,7 @@ static inline void dpaa2_sg_cpu_to_le(struct dpaa_sg_entry *sg)
 		cpu_to_le32s(p++);
 }
 
-static inline void dpaa2_sg_le_to_cpu(struct dpaa_sg_entry *sg)
+static inline void dpaa2_sg_le_to_cpu(struct dpaa2_sg_entry *sg)
 {
 	uint32_t *p = (uint32_t *)sg;
 	int i;
@@ -419,12 +420,12 @@ static inline void dpaa2_sg_le_to_cpu(struct dpaa_sg_entry *sg)
 
 
 /**
- * struct dpaa_fl_entry - structure for frame list entry.
+ * struct dpaa2_fl_entry - structure for frame list entry.
  *
  * Frame List Entry (FLE)
- * Identical to dpaa_fd.simple layout, but some bits are different
+ * Identical to dpaa2_fd.simple layout, but some bits are different
  */
-struct dpaa_fl_entry {
+struct dpaa2_fl_entry {
 	u32 addr_lo;
 	u32 addr_hi;
 	u32 len;
@@ -435,10 +436,10 @@ struct dpaa_fl_entry {
 	u32 flc_hi;
 };
 
-enum dpaa_fl_format {
-	dpaa_fl_single = 0,
-	dpaa_fl_res,
-	dpaa_fl_sg
+enum dpaa2_fl_format {
+	dpaa2_fl_single = 0,
+	dpaa2_fl_res,
+	dpaa2_fl_sg
 };
 
 /**
@@ -449,11 +450,13 @@ enum dpaa_fl_format {
  *
  * Return address for the get function.
  */
-static inline dma_addr_t dpaa2_fl_get_addr(const struct dpaa_fl_entry *fle)
+static inline dma_addr_t dpaa2_fl_get_addr(const struct dpaa2_fl_entry *fle)
 {
 	return (dma_addr_t)((((uint64_t)fle->addr_hi) << 32) + fle->addr_lo);
 }
-static inline void dpaa2_fl_set_addr(struct dpaa_fl_entry *fle, dma_addr_t addr)
+
+static inline void dpaa2_fl_set_addr(struct dpaa2_fl_entry *fle,
+				     dma_addr_t addr)
 {
 	fle->addr_hi = upper_32_bits(addr);
 	fle->addr_lo = lower_32_bits(addr);
@@ -467,11 +470,12 @@ static inline void dpaa2_fl_set_addr(struct dpaa_fl_entry *fle, dma_addr_t addr)
  *
  * Return flow context for the get function.
  */
-static inline dma_addr_t dpaa2_fl_get_flc(const struct dpaa_fl_entry *fle)
+static inline dma_addr_t dpaa2_fl_get_flc(const struct dpaa2_fl_entry *fle)
 {
 	return (dma_addr_t)((((uint64_t)fle->flc_hi) << 32) + fle->flc_lo);
 }
-static inline void dpaa2_fl_set_flc(struct dpaa_fl_entry *fle,
+
+static inline void dpaa2_fl_set_flc(struct dpaa2_fl_entry *fle,
 				    dma_addr_t flc_addr)
 {
 	fle->flc_hi = upper_32_bits(flc_addr);
@@ -486,11 +490,12 @@ static inline void dpaa2_fl_set_flc(struct dpaa_fl_entry *fle,
  *
  * Return length for the get function.
  */
-static inline u32 dpaa2_fl_get_len(const struct dpaa_fl_entry *fle)
+static inline u32 dpaa2_fl_get_len(const struct dpaa2_fl_entry *fle)
 {
 	return fle->len;
 }
-static inline void dpaa2_fl_set_len(struct dpaa_fl_entry *fle, u32 len)
+
+static inline void dpaa2_fl_set_len(struct dpaa2_fl_entry *fle, u32 len)
 {
 	fle->len = len;
 }
@@ -503,12 +508,12 @@ static inline void dpaa2_fl_set_len(struct dpaa_fl_entry *fle, u32 len)
  *
  * Return offset for the get function.
  */
-static inline uint16_t dpaa2_fl_get_offset(const struct dpaa_fl_entry *fle)
+static inline uint16_t dpaa2_fl_get_offset(const struct dpaa2_fl_entry *fle)
 {
 	return (uint16_t)(fle->bpid_offset >> 16) & 0x0FFF;
 }
 
-static inline void dpaa2_fl_set_offset(struct dpaa_fl_entry *fle,
+static inline void dpaa2_fl_set_offset(struct dpaa2_fl_entry *fle,
 				       uint16_t offset)
 {
 	fle->bpid_offset &= 0xF000FFFF;
@@ -523,13 +528,14 @@ static inline void dpaa2_fl_set_offset(struct dpaa_fl_entry *fle,
  *
  * Return frame list format for the get function.
  */
-static inline enum dpaa_fl_format dpaa2_fl_get_format(
-	const struct dpaa_fl_entry *fle)
+static inline enum dpaa2_fl_format dpaa2_fl_get_format(
+	const struct dpaa2_fl_entry *fle)
 {
-	return (enum dpaa_fl_format)((fle->bpid_offset >> 28) & 0x3);
+	return (enum dpaa2_fl_format)((fle->bpid_offset >> 28) & 0x3);
 }
-static inline void dpaa2_fl_set_format(struct dpaa_fl_entry *fle,
-				       enum dpaa_fl_format format)
+
+static inline void dpaa2_fl_set_format(struct dpaa2_fl_entry *fle,
+				       enum dpaa2_fl_format format)
 {
 	fle->bpid_offset &= 0xCFFFFFFF;
 	fle->bpid_offset |= (u32)(format & 0x3) << 28;
@@ -543,22 +549,23 @@ static inline void dpaa2_fl_set_format(struct dpaa_fl_entry *fle,
  *
  * Return bpid for the get function.
  */
-static inline uint16_t dpaa2_fl_get_bpid(const struct dpaa_fl_entry *fle)
+static inline uint16_t dpaa2_fl_get_bpid(const struct dpaa2_fl_entry *fle)
 {
 	return (uint16_t)(fle->bpid_offset & 0x3FFF);
 }
-static inline void dpaa2_fl_set_bpid(struct dpaa_fl_entry *fle, uint16_t bpid)
+
+static inline void dpaa2_fl_set_bpid(struct dpaa2_fl_entry *fle, uint16_t bpid)
 {
 	fle->bpid_offset &= 0xFFFFC000;
 	fle->bpid_offset |= (u32)bpid;
 }
 
-/** dpaa_fl_is_final() - check the final bit is set or not in the frame list.
+/** dpaa2_fl_is_final() - check the final bit is set or not in the frame list.
  * @fle: the given frame list entry.
  *
  * Return final bit settting.
  */
-static inline bool dpaa2_fl_is_final(const struct dpaa_fl_entry *fle)
+static inline bool dpaa2_fl_is_final(const struct dpaa2_fl_entry *fle)
 {
 	return !!(fle->bpid_offset >> 31);
 }
@@ -569,7 +576,7 @@ static inline bool dpaa2_fl_is_final(const struct dpaa_fl_entry *fle)
  * @final: the final bit needs to be set.
  *
  */
-static inline void dpaa2_fl_set_final(struct dpaa_fl_entry *fle, bool final)
+static inline void dpaa2_fl_set_final(struct dpaa2_fl_entry *fle, bool final)
 {
 	fle->bpid_offset &= 0x7FFFFFFF;
 	fle->bpid_offset |= (u32)final << 31;
@@ -668,6 +675,6 @@ uint64_t dpaa2_dq_fqd_ctx(const struct dpaa2_dq *dq);
  *
  * Return the frame descriptor.
  */
-const struct dpaa_fd *dpaa2_dq_fd(const struct dpaa2_dq *);
+const struct dpaa2_fd *dpaa2_dq_fd(const struct dpaa2_dq *);
 
 #endif /* __FSL_DPAA2_FD_H */
diff --git a/drivers/staging/fsl-mc/include/fsl_dpaa2_io.h b/drivers/staging/fsl-mc/include/fsl_dpaa2_io.h
index 35e92d9..cfa0fc6 100644
--- a/drivers/staging/fsl-mc/include/fsl_dpaa2_io.h
+++ b/drivers/staging/fsl-mc/include/fsl_dpaa2_io.h
@@ -432,10 +432,10 @@ int dpaa2_io_service_pull_channel(struct dpaa2_io *d, uint32_t channelid,
  */
 int dpaa2_io_service_enqueue_fq(struct dpaa2_io *d,
 			       uint32_t fqid,
-			       const struct dpaa_fd *fd);
+			       const struct dpaa2_fd *fd);
 int dpaa2_io_service_enqueue_qd(struct dpaa2_io *d,
 			       uint32_t qdid, uint8_t prio, uint16_t qdbin,
-			       const struct dpaa_fd *fd);
+			       const struct dpaa2_fd *fd);
 
 /*******************/
 /* Buffer handling */
@@ -510,7 +510,7 @@ void dpaa2_io_store_destroy(struct dpaa2_io_store *s);
  * @is_last: indicate whether this is the last frame in the pull command.
  *
  * Once dpaa2_io_store has been passed to a function that performs dequeues to
- * it, like dpaa_ni_rx(), this function can be used to determine when the next
+ * it, like dpaa2_ni_rx(), this function can be used to determine when the next
  * frame result is available. Once this function returns non-NULL, a subsequent
  * call to it will try to find the *next* dequeue result.
  *
-- 
1.7.5.4

