From e7a427ed542a4472034b84a9c1e9493dad87960b Mon Sep 17 00:00:00 2001
From: Allan Stephens <allan.stephens@windriver.com>
Date: Wed, 10 Nov 2010 22:22:24 -0800
Subject: [PATCH 18/22] tipc: Prevent loss of fragmented messages over broadcast link

commit ca8ac6ff0d2eb83cc2cf230308e73ca38dd584bc
http://tipc.cslab.ericsson.net/cgi-bin/gitweb.cgi?p=people/allan/tipc.git;a=shortlog;h=tipc1.7

Modifies TIPC's broadcast link so that an incoming fragmented message
is not lost if reassembly cannot begin because there currently is no
buffer big enough to hold the entire reassembled message. The broadcast
link now ignores the first fragment completely, which causes the
sending node to retransmit the first fragment so that reassembly can be
re-attempted.

Signed-off-by: Howard Xu <hao.xu@windriver.com>
Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
Integrated-by: Howard Xu <Hao.Xu@windriver.com>
---
 net/tipc/tipc_bcast.c |   65 +++++++++++++++++++++++++++++++++----------------
 1 files changed, 44 insertions(+), 21 deletions(-)

diff --git a/net/tipc/tipc_bcast.c b/net/tipc/tipc_bcast.c
index f603cb1..2d8e061 100644
--- a/net/tipc/tipc_bcast.c
+++ b/net/tipc/tipc_bcast.c
@@ -371,6 +371,32 @@ exit:
 }
 
 /**
+ * bclink_accept_pkt - accept an incoming, in-sequence broadcast packet
+ *
+ * Called with both sending node's lock and bc_lock taken.
+ */
+
+static void bclink_accept_pkt(struct tipc_node *node, u32 seqno)
+{
+	bclink_update_last_sent(node, seqno);
+	node->bclink.last_in = seqno;
+	node->bclink.oos_state = 0;
+	bcl->stats.recv_info++;
+
+	/*
+	 * Unicast an ACK periodically, ensuring that
+	 * all nodes in the cluster don't ACK at the same time
+	 */
+
+	if (((seqno - tipc_own_addr) % TIPC_MIN_LINK_WIN) == 0) {
+	        tipc_link_send_proto_msg(
+	                node->active_links[node->elm.addr & 1],
+	                STATE_MSG, 0, 0, 0, 0, 0, 0);
+	        bcl->stats.sent_acks++;
+	}
+}
+
+/**
  * tipc_bclink_recv_pkt - receive a broadcast packet, and deliver upwards
  *
  * tipc_net_lock is read_locked, no other locks set
@@ -383,6 +409,7 @@ void tipc_bclink_recv_pkt(struct sk_buff *buf)
 	u32 seqno;
 	u32 next_in;
 	int deferred;
+	int ret;
 
 #if (TIPC_BCAST_LOSS_RATE)
 	static int rx_count = 0;
@@ -434,42 +461,32 @@ void tipc_bclink_recv_pkt(struct sk_buff *buf)
 	next_in = mod(node->bclink.last_in + 1);
 
 	if (seqno == next_in) {
-		bclink_update_last_sent(node, seqno);
 receive:
-		node->bclink.last_in = seqno;
-		node->bclink.oos_state = 0;
-
-		spin_lock_bh(&bc_lock);
-		bcl->stats.recv_info++;
-
-		/*
-		 * Unicast an ACK periodically, ensuring that
-		 * all nodes in the cluster don't ACK at the same time
-		 */
-
-		if (((seqno - tipc_own_addr) % TIPC_MIN_LINK_WIN) == 0) {
-			tipc_link_send_proto_msg(
-				node->active_links[node->elm.addr & 1],
-				STATE_MSG, 0, 0, 0, 0, 0, 0);
-			bcl->stats.sent_acks++;
-		}
-
 		/* Deliver message to destination */
 
 		if (likely(msg_isdata(msg))) {
+			spin_lock_bh(&bc_lock);
+			bclink_accept_pkt(node, seqno);
 			spin_unlock_bh(&bc_lock);
 			tipc_node_unlock(node);
 			tipc_port_recv_mcast(buf, NULL);
 		} else if (msg_user(msg) == MSG_BUNDLER) {
+			spin_lock_bh(&bc_lock);
+			bclink_accept_pkt(node, seqno);
 			bcl->stats.recv_bundles++;
 			bcl->stats.recv_bundled += msg_msgcnt(msg);
 			spin_unlock_bh(&bc_lock);
 			tipc_node_unlock(node);
 			tipc_link_recv_bundle(buf);
 		} else if (msg_user(msg) == MSG_FRAGMENTER) {
+			ret = tipc_link_recv_fragment(&node->bclink.defragm,
+						      &buf, &msg);
+			if (ret < 0)
+				goto unlock;
+			spin_lock_bh(&bc_lock);
+			bclink_accept_pkt(node, seqno);
 			bcl->stats.recv_fragments++;
-			if (tipc_link_recv_fragment(&node->bclink.defragm,
-						    &buf, &msg)) {
+			if (ret > 0) {
 				bcl->stats.recv_fragmented++;
 				msg_set_destnode_cache(msg, tipc_own_addr);
 			}
@@ -477,14 +494,20 @@ receive:
 			tipc_node_unlock(node);
 			tipc_net_route_msg(buf);
 		} else if (msg_user(msg) == NAME_DISTRIBUTOR) {
+			spin_lock_bh(&bc_lock);
+			bclink_accept_pkt(node, seqno);
 			spin_unlock_bh(&bc_lock);
 			tipc_node_unlock(node);
 			tipc_named_recv(buf);
 		} else if (msg_user(msg) == ROUTE_DISTRIBUTOR) {
+			spin_lock_bh(&bc_lock);
+			bclink_accept_pkt(node, seqno);
 			spin_unlock_bh(&bc_lock);
 			tipc_node_unlock(node);
 			tipc_route_recv(buf);
 		} else {
+			spin_lock_bh(&bc_lock);
+			bclink_accept_pkt(node, seqno);
 			spin_unlock_bh(&bc_lock);
 			tipc_node_unlock(node);
 			tipc_net_route_msg(buf);
-- 
1.6.5.2

