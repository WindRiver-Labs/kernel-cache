From 4f78117e49f427dda82b946ae529010ab1dbea87 Mon Sep 17 00:00:00 2001
From: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
Date: Mon, 25 Jun 2012 08:41:11 -0700
Subject: [PATCH] rcu: Allow RCU quiescent-state forcing to be preempted

commit b4be093fee0200789df59b6c90e2d099a20f55b3 upstream.

RCU quiescent-state forcing is currently carried out without preemption
points, which can result in excessive latency spikes on large systems
(many hundreds or thousands of CPUs).  This patch therefore inserts
a voluntary preemption point into force_qs_rnp(), which should greatly
reduce the magnitude of these spikes.

Reported-by: Mike Galbraith <mgalbraith@suse.de>
Reported-by: Dimitri Sivanich <sivanich@sgi.com>
Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Reviewed-by: Josh Triplett <josh@joshtriplett.org>
Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
Signed-off-by: Yang Shi <yang.shi@windriver.com>

diff --git a/kernel/rcutree.c b/kernel/rcutree.c
index a24051d..249dbb1 100644
--- a/kernel/rcutree.c
+++ b/kernel/rcutree.c
@@ -1783,6 +1783,7 @@ static void force_qs_rnp(struct rcu_state *rsp, int (*f)(struct rcu_data *))
 	struct rcu_node *rnp;
 
 	rcu_for_each_leaf_node(rsp, rnp) {
+		cond_resched();
 		mask = 0;
 		raw_spin_lock_irqsave(&rnp->lock, flags);
 		if (!rcu_gp_in_progress(rsp)) {
-- 
1.7.5.4

