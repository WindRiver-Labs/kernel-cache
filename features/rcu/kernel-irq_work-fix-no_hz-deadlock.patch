From 5b897925d6f97077a3686e4922a083c027f33a70 Mon Sep 17 00:00:00 2001
From: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date: Fri, 10 Apr 2015 11:50:22 +0200
Subject: [PATCH] kernel/irq_work: fix no_hz deadlock

This originally started out as:

  kernel-irq_work-fix-no_hz-deadlock.patch
  md5: 4f89af428718cff2f56c590a678ee286
  from patches-3.18.11-rt7.tar.xz found at
  https://www.kernel.org/pub/linux/kernel/projects/rt/3.18/

which had the following commit log:

 --------------------8<---------------------------------
    Invoking NO_HZ's irq_work callback from timer irq is not working very
    well if the callback decides to invoke hrtimer_cancel():

    |hrtimer_try_to_cancel+0x55/0x5f
    |hrtimer_cancel+0x16/0x28
    |tick_nohz_restart+0x17/0x72
    |__tick_nohz_full_check+0x8e/0x93
    |nohz_full_kick_work_func+0xe/0x10
    |irq_work_run_list+0x39/0x57
    |irq_work_tick+0x60/0x67
    |update_process_times+0x57/0x67
    |tick_sched_handle+0x4a/0x59
    |tick_sched_timer+0x3b/0x64
    |__run_hrtimer+0x7a/0x149
    |hrtimer_interrupt+0x1cc/0x2c5

    and here we deadlock while waiting for the lock which we are holding.
    To fix this I'm doing the same thing that upstream is doing: is the
    irq_work dedicated IRQ and use it only for what is marked as "hirq"
    which should only be the FULL_NO_HZ related work.

    Reported-by: Carsten Emde <C.Emde@osadl.org>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
 --------------------8<---------------------------------

Here we backport to 3.10-rt + nohz; irq_work has two in_irq() checks
already removed via existing backports;  see backport of:
    irq_work: Force raised irq work to run on irq work interrupt
       (commit 76a33061b9323b7fdb220ae5fa116c10833ec22e upstream)
and see in a related hrtimer_cancel backport:
    nohz: nohz full depends on irq work self IPI support
       (commit 9b01f5bf3999a3db5b1bbd9fdfd80d8d304e94ee upstream)
with the latter being a proactive detection as per its log. Also
drop the arm/smp chunk; not appropriate for this 3.10 baseline.

In addition to that, a lot of this original commit was an implicit
revert of the -rt patch "irq_work: allow certain work in hard irq context"
Since we have already reverted that, this patch here is much smaller
than the original 3.18-rt patch.

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/x86/kernel/irq_work.c b/arch/x86/kernel/irq_work.c
index f718d1911f7c..b4325a6c67c3 100644
--- a/arch/x86/kernel/irq_work.c
+++ b/arch/x86/kernel/irq_work.c
@@ -18,7 +18,6 @@ void smp_irq_work_interrupt(struct pt_regs *regs)
 	irq_exit();
 }
 
-#ifndef CONFIG_PREEMPT_RT_FULL
 void arch_irq_work_raise(void)
 {
 #ifdef CONFIG_X86_LOCAL_APIC
@@ -29,4 +28,3 @@ void arch_irq_work_raise(void)
 	apic_wait_icr_idle();
 #endif
 }
-#endif
diff --git a/kernel/irq_work.c b/kernel/irq_work.c
index b6433fbcb20f..90670fe4937f 100644
--- a/kernel/irq_work.c
+++ b/kernel/irq_work.c
@@ -17,6 +17,7 @@
 #include <linux/cpu.h>
 #include <linux/notifier.h>
 #include <linux/smp.h>
+#include <linux/interrupt.h>
 #include <asm/processor.h>
 
 
@@ -97,7 +98,7 @@ bool irq_work_queue(struct irq_work *work)
 	if (work->flags & IRQ_WORK_LAZY) {
 		if (llist_add(&work->llnode, &__get_cpu_var(lazy_list)) &&
 		    tick_nohz_tick_stopped())
-			arch_irq_work_raise();
+			raise_softirq(TIMER_SOFTIRQ);
 	} else {
 		if (llist_add(&work->llnode, &__get_cpu_var(raised_list)))
 			arch_irq_work_raise();
diff --git a/kernel/time/tick-sched.c b/kernel/time/tick-sched.c
index bd1ac81eae13..da3f06443a96 100644
--- a/kernel/time/tick-sched.c
+++ b/kernel/time/tick-sched.c
@@ -176,6 +176,11 @@ static bool can_stop_full_tick(void)
 		return false;
 	}
 
+	if (!arch_irq_work_has_interrupt()) {
+		trace_tick_stop(0, "missing irq work interrupt\n");
+		return false;
+	}
+
 	/* sched_clock_tick() needs us? */
 #ifdef CONFIG_HAVE_UNSTABLE_SCHED_CLOCK
 	/*
diff --git a/kernel/timer.c b/kernel/timer.c
index 9316a71f03c5..8ee5f4df7e43 100644
--- a/kernel/timer.c
+++ b/kernel/timer.c
@@ -1450,8 +1450,7 @@ void update_process_times(int user_tick)
 	run_local_timers();
 	rcu_check_callbacks(cpu, user_tick);
 #if defined(CONFIG_IRQ_WORK) && !defined(CONFIG_PREEMPT_RT_FULL)
-	if (in_irq())
-		irq_work_tick();
+	irq_work_tick();
 #endif
 	run_posix_cpu_timers(p);
 }
-- 
2.4.3

