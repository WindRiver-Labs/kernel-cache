From 78675bb28d741a0ce48ba24aeb94c75f4333526e Mon Sep 17 00:00:00 2001
From: Jason HU <yongqi.hu@windriver.com>
Date: Thu, 6 May 2010 23:31:21 -0700
Subject: [PATCH 3/5] vMC: Add core Virtual Management Controller code.

Core code for the virtual IPMI management controller was added.

vMC is used to create IPMI compliant software sensors that can
generate IPMI fault events and works as part of a fault management
infrastructure for the kernel.

The following change, enhancement, or fix up were also added:

1.  Fall back on vMC's driver name to bypass all vMCs and register
    smi_watcher for BMC SMI since multiple vMCs are supported,
    comparing vMC's intf_num with 1 would no longer be applicable.

2.  Remove obsolete CONFIG_IPMI_VMC_SEL_EXTENDED_SIZE macro

    By default this macro is zero, and the size of a SEL would be
    that of the fault_record_s structure plus 16 bytes. Otherwise
    the SEL size would be 16 plus the macro's current value. The
    problem with such algorithm is that if the user inadvertently
    make this macro less than the size of the fault_record_s
    structure, the vMC PMEM region requested would not be large
    enough to accommodate the number of SELs requested by the user.

    Moreover, since EDAC is and always will be the only user of
    vMC that would ever report it "fault" event, the maximum
    extended data size of a SEL could be as fixed as that of the
    fault_record_s structure reported by EDAC. Consequently, the
    size of the SEL kernel structure could be fixed and
    maintained by kernel cache.

    Last, if PMEM is used to store SELs only the 16 bytes at the
    head should be saved into PMEM, rather than the rest of SEL
    kernel structure which are used by vMC kernel driver for
    run-time management.

3.  Introduce CONFIG_IPMI_VMC_PMEM_BLOCKS_NUMBER kernel option
    and make it no less than three, so that the active block in
    vMC PMEM partition could be locked during PMEM block rotation.

4.  Remove sel_disable_count

    The sel_disable_count and sel_record_count counters are
    originally designed for the case when vMC uses PMEM to store
    SELs. The SELs stored in PMEM won't be deleted when vMC handles
    "Clear SEL" command or when vMC gets unloaded. The
    sel_disable_count will record the number of times when vMC is
    requested to clear SEL, and sel_record_count will save all
    existing SELs stored in PMEM by far. When vMC re-enables SEL
    later or gets loaded once again, vMC could re-use previous
    registered PMEM region and the new SEL will be appended after
    those old SELs.

    These two counters are used to skip all those old SELs when
    dumping all SELs or fetching a particular one for current vMC
    instance. However, current codes related with them are
    problematic in the following way:

    When enabling SEL vMC should *always* try to register its PMEM
    partition and region, rather than at the very first time.
    Because related PMEM APIs are capable of matching old vMC
    partition and region against current request and return
    existing handlers if a match is found.

    When getting a particular SEL from PMEM current code will
    read a structure of size of PMEM_LOG_DESC_DATA_SIZE, which is
    very wrong since vMC's PMEM region is to save fixed size
    entries and has nothing to do with structures used when
    region is to save un-fixed size logs.

    Moreover, the fact that the new SELs appended successively
    and dumped  altogether with the old ones won't be a big issue
    because we can get SELs selectively by their IDs and
    discriminate them by their timestamps

5.  Make vMC free from PMEM internals by using newly added PMEM
    read functions that support POSIX read semantics.

6.  Make vMC able to be removed by making vMC kernel module's
    initialization and cleanup routines and all their
    sub-functions have symmetric behaviors to prevent memory
    leak.

Signed-off-by: Jason HU <yongqi.hu@windriver.com>
---
 drivers/char/ipmi/Kconfig           |   44 +
 drivers/char/ipmi/Makefile          |    6 +
 drivers/char/ipmi/ipmi_msghandler.c |   12 +-
 drivers/char/ipmi/vmc_cmd.c         |  841 ++++++
 drivers/char/ipmi/vmc_emu.c         | 5041 +++++++++++++++++++++++++++++++++++
 drivers/char/ipmi/vmc_emu.h         |  412 +++
 drivers/char/ipmi/vmc_ipmb.c        |  256 ++
 drivers/char/ipmi/vmc_ipmb.h        |   46 +
 drivers/char/ipmi/vmc_kapi.c        |  374 +++
 drivers/char/ipmi/vmc_main.c        |  433 +++
 drivers/char/ipmi/vmc_smi.c         |  518 ++++
 drivers/char/ipmi/vmc_smi.h         |   52 +
 include/linux/ipmi_smi.h            |    5 +
 include/linux/vmc.h                 |    6 +
 14 files changed, 8045 insertions(+), 1 deletions(-)
 create mode 100644 drivers/char/ipmi/vmc_cmd.c
 create mode 100644 drivers/char/ipmi/vmc_emu.c
 create mode 100644 drivers/char/ipmi/vmc_emu.h
 create mode 100644 drivers/char/ipmi/vmc_ipmb.c
 create mode 100644 drivers/char/ipmi/vmc_ipmb.h
 create mode 100644 drivers/char/ipmi/vmc_kapi.c
 create mode 100644 drivers/char/ipmi/vmc_main.c
 create mode 100644 drivers/char/ipmi/vmc_smi.c
 create mode 100644 drivers/char/ipmi/vmc_smi.h

diff --git a/drivers/char/ipmi/Kconfig b/drivers/char/ipmi/Kconfig
index 22e20d2..f6bf11e 100644
--- a/drivers/char/ipmi/Kconfig
+++ b/drivers/char/ipmi/Kconfig
@@ -76,4 +76,48 @@ config IPMI_VMC_STUB
 	  generally be statically compiled into the kernel, but, may be created
 	  as a module for testing purposes.
 
+config IPMI_VMC
+	tristate 'IPMI Virtual Management Controller'
+	depends on IPMI_HANDLER && IPMI_VMC_STUB
+	help
+	  This enables a virtual IPMI management controller in the kernel. The
+	  vMC is used to create IPMI compliant software sensors that can
+	  generate IPMI fault events. The vMC is part of a fault management
+	  infrastructure for the kernel.
+
+config IPMI_VMC_ENABLE_IPMB
+	bool 'IPMI vMC IPMB support'
+	depends on IPMI_VMC
+	default y
+	help
+	  The vMC can be configured to use a real BMC device to send critical
+	  faults. If no BMC device exists on a board, the vMC can still be used
+	  via IPMB over LAN or local IPMI/HPI applications. If this option is
+	  enabled then the vMC will attempt to connect to a real BMC device and
+	  use it to send critical events to a shelf manager.
+
+config IPMI_VMC_ENABLE_PMEM
+	bool 'IPMI vMC persistent memory support'
+	depends on IPMI_VMC && PMEM
+	default y
+	help
+	  The vMC can be configured to store it's event log in persistent memory
+	  using the persistent memory framework. If this option is not enabled,
+	  then the event log will be allocated from normal kernel memory.
+
+config IPMI_VMC_PMEM_BLOCKS_NUMBER
+	int "IPMI vMC PMEM partition blocks number"
+	depends on IPMI_VMC_ENABLE_PMEM
+	range 3 10
+	default 3
+	help
+	  The number of blocks in the PMEM partition created by vMC.
+
+	  Note, this number should be no less than three so that previous
+	  active block could be locked during rotation in order to enforce
+	  PMEM driver to select block other than the latest one so that
+	  critical information could be preserved during system reboot.
+	  After dumping the content of a locked block, the user could
+	  manually mark it as unlocked for future usage.
+
 endif # IPMI_HANDLER
diff --git a/drivers/char/ipmi/Makefile b/drivers/char/ipmi/Makefile
index 2733696..045ce82 100644
--- a/drivers/char/ipmi/Makefile
+++ b/drivers/char/ipmi/Makefile
@@ -3,6 +3,11 @@
 #
 
 ipmi_si-objs := ipmi_si_intf.o ipmi_kcs_sm.o ipmi_smic_sm.o ipmi_bt_sm.o
+vmc-objs     := vmc_main.o vmc_emu.o vmc_cmd.o vmc_kapi.o vmc_smi.o
+
+ifeq ($(CONFIG_IPMI_VMC_ENABLE_IPMB),y)
+vmc-objs     += vmc_ipmb.o
+endif
 
 obj-$(CONFIG_IPMI_HANDLER) += ipmi_msghandler.o
 obj-$(CONFIG_IPMI_DEVICE_INTERFACE) += ipmi_devintf.o
@@ -10,3 +15,4 @@ obj-$(CONFIG_IPMI_SI) += ipmi_si.o
 obj-$(CONFIG_IPMI_WATCHDOG) += ipmi_watchdog.o
 obj-$(CONFIG_IPMI_POWEROFF) += ipmi_poweroff.o
 obj-$(CONFIG_IPMI_VMC_STUB) += vmc_stub.o
+obj-$(CONFIG_IPMI_VMC) += vmc.o
diff --git a/drivers/char/ipmi/ipmi_msghandler.c b/drivers/char/ipmi/ipmi_msghandler.c
index 71eec32..4931a48 100644
--- a/drivers/char/ipmi/ipmi_msghandler.c
+++ b/drivers/char/ipmi/ipmi_msghandler.c
@@ -1963,8 +1963,9 @@ static int stat_file_read_proc(char *page, char **start, off_t off,
 }
 #endif /* CONFIG_PROC_FS */
 
-int ipmi_smi_add_proc_entry(ipmi_smi_t smi, char *name,
+int __ipmi_smi_add_proc_entry(ipmi_smi_t smi, char *name,
 			    read_proc_t *read_proc,
+			    write_proc_t *write_proc,
 			    void *data)
 {
 	int                    rv = 0;
@@ -1991,6 +1992,7 @@ int ipmi_smi_add_proc_entry(ipmi_smi_t smi, char *name,
 	} else {
 		file->data = data;
 		file->read_proc = read_proc;
+		file->write_proc = write_proc;
 
 		mutex_lock(&smi->proc_entry_lock);
 		/* Stick it on the list. */
@@ -2002,6 +2004,14 @@ int ipmi_smi_add_proc_entry(ipmi_smi_t smi, char *name,
 
 	return rv;
 }
+EXPORT_SYMBOL(__ipmi_smi_add_proc_entry);
+
+inline int ipmi_smi_add_proc_entry(ipmi_smi_t smi, char *name,
+			read_proc_t *read_proc, void *data)
+{
+	return __ipmi_smi_add_proc_entry(smi, name, read_proc, NULL,
+				data);
+}
 EXPORT_SYMBOL(ipmi_smi_add_proc_entry);
 
 static int add_proc_entries(ipmi_smi_t smi, int num)
diff --git a/drivers/char/ipmi/vmc_cmd.c b/drivers/char/ipmi/vmc_cmd.c
new file mode 100644
index 0000000..fae9320
--- /dev/null
+++ b/drivers/char/ipmi/vmc_cmd.c
@@ -0,0 +1,841 @@
+/*
+ * Wind River IPMI virtual Management Controller
+ *
+ * The virtual Management Controller (vMC) implements a subset of an IPMI
+ * Baseboard Management Controller (BMC) in a kernel module. The vMC
+ * plugs into the OpenIPMI KLM which makes it look like a normal
+ * IPMI management controller to user applications.
+ *
+ * This file implements a command based configuration interface that it
+ * accessed via sysfs. A user can write a command to a sysfs file and
+ * read the command response. Commands are defined that allow for
+ * configuration and testing of the vMC.
+ *
+ * This implementation was based on the user space emulator by
+ * Monta Vista.
+ *
+ * Author: Wind River Systems
+ *         Chris Stone <christopher.stone@windriver.com>
+ *
+ * Copyright 2005 Wind River Systems
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2 of the License, or (at your
+ *  option) any later version.
+ *
+ *
+ *  THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
+ *  WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
+ *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
+ *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+ *  BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
+ *  OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ *  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
+ *  TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ *  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/string.h>
+#include "vmc_emu.h"
+#include "vmc_smi.h"
+
+typedef int (*ipmi_emu_cmd_handler) (lmc_data_t *mc, unsigned char ipmb,
+				     char **toks);
+
+static int get_uchar(char **toks, unsigned char *val,
+		     char *errstr, int empty_ok)
+{
+	char *str, *tmpstr;
+
+	str = strsep(toks, " \t\n");
+	if (!str) {
+		if (empty_ok)
+			return VMC_ENOSPC;
+		if (errstr)
+			sprintf(response, "**No %s given\n", errstr);
+		return VMC_EINVAL;
+	}
+	if (str[0] == '\'') {
+		*val = str[1];
+		return 0;
+	}
+	*val = (unsigned char) simple_strtoul(str, &tmpstr, 16);
+	if (*tmpstr != '\0') {
+		if (errstr)
+			sprintf(response, "**Invalid %s given\n", errstr);
+		return VMC_EINVAL;
+	}
+
+	return 0;
+}
+
+static int get_uint(char **toks, unsigned int *val, char *errstr)
+{
+	char *str, *tmpstr;
+
+	str = strsep(toks, " \t\n");
+	if (!str) {
+		if (errstr)
+			sprintf(response, "**No %s given\n", errstr);
+		return VMC_EINVAL;
+	}
+	*val = (unsigned int) simple_strtoul(str, &tmpstr, 16);
+	if (*tmpstr != '\0') {
+		if (errstr)
+			sprintf(response, "**Invalid %s given\n", errstr);
+		return VMC_EINVAL;
+	}
+
+	return 0;
+}
+
+static int sel_enable(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	int rv;
+	unsigned int max_records;
+	unsigned char flags;
+
+	rv = get_uint(toks, &max_records, "max records");
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &flags, "flags", 0);
+	if (rv)
+		return rv;
+
+	rv = ipmi_mc_enable_sel(mc, max_records, flags);
+	printk(KERN_INFO "sel_enable; rv=%d; mc=%p\n", rv, mc);
+
+	if (rv)
+		sprintf(response, "**Unable to enable sel, error 0x%x\n", rv);
+	return rv;
+}
+
+static int sel_disable(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	int rv;
+
+	rv = ipmi_mc_disable_sel(mc);
+	if (rv)
+		sprintf(response, "**Unable to disable sel, error 0x%x\n", rv);
+	return rv;
+}
+
+static int main_sdr_add(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	int i;
+	int rv;
+	vMC_ipmi_sdr_t *sdr;
+	unsigned char record_type;
+	unsigned char record_length;
+
+	if (get_uchar(toks, &record_type, "record type", 1)) {
+		sprintf(response, "**Invalid SDR record.\n");
+		return VMC_EINVAL;
+	}
+
+	if (get_uchar(toks, &record_length, "record length", 1)) {
+		sprintf(response, "**Invalid SDR record.\n");
+		return VMC_EINVAL;
+	}
+
+	sdr = vMC_alloc_sdr_record(ipmi_emu_get_mc_addr(mc), record_type, &rv);
+	if (sdr == NULL) {
+		sprintf(response, "**Unable to add to sdr, error %d\n", rv);
+		return rv;
+	}
+
+	sdr->sdr_hdr.sdr_major_version = 1;
+	sdr->sdr_hdr.sdr_minor_version = 5;
+	sdr->sdr_hdr.record_type = record_type;
+	sdr->sdr_hdr.record_length = record_length;
+
+	for (i = 0; i < MAX_SDR_DATA; i++) {
+		rv = get_uchar(toks, &(sdr->sdr_body.data[i]), "data byte", 1);
+		if (rv == VMC_ENOSPC)
+			break;
+		if (rv) {
+			sprintf(response, "**Error %d in data byte %d\n",
+				rv, i);
+			vmc_kfree(sdr);
+			return rv;
+		}
+	}
+
+	return ipmi_mc_add_main_sdr(sdr);
+}
+
+static int
+device_sdr_add(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	int i;
+	int rv;
+	vMC_ipmi_sdr_t *sdr;
+	unsigned char record_type;
+	unsigned char record_length;
+
+	if (get_uchar(toks, &record_type, "record type", 1)) {
+		sprintf(response, "**Invalid SDR record.\n");
+		return VMC_EINVAL;
+	}
+
+	if (get_uchar(toks, &record_length, "record length", 1)) {
+		sprintf(response, "**Invalid SDR record.\n");
+		return VMC_EINVAL;
+	}
+
+	sdr = vMC_alloc_sdr_record(ipmi_emu_get_mc_addr(mc), record_type, &rv);
+	if (sdr == NULL) {
+		sprintf(response, "**Unable to add to sdr, error 0x%x\n", rv);
+		return rv;
+	}
+
+	sdr->sdr_hdr.sdr_major_version = 1;
+	sdr->sdr_hdr.sdr_minor_version = 5;
+	sdr->sdr_hdr.record_type = record_type;
+	sdr->sdr_hdr.record_length = record_length;
+
+	for (i = 0; i < MAX_SDR_DATA; i++) {
+		rv = get_uchar(toks, &(sdr->sdr_body.data[i]), "data byte", 1);
+		if (rv == VMC_ENOSPC)
+			break;
+		if (rv) {
+			sprintf(response, "**Error 0x%x in data byte %d\n",
+				rv, i);
+			vmc_kfree(sdr);
+			return rv;
+		}
+	}
+
+	return ipmi_mc_add_device_sdr(sdr);
+}
+
+static int sensor_set_bit(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	int rv;
+	unsigned char lun;
+	unsigned char num;
+	unsigned char bit;
+	unsigned char value;
+	vMC_ipmi_sensor_ident_t sensor_ident;
+
+	rv = get_uchar(toks, &lun, "LUN", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &num, "sensor num", 0);
+	if (rv)
+		return rv;
+
+	sensor_ident.sensor_mc = ipmb;
+	sensor_ident.sensor_lun = lun;
+	sensor_ident.sensor_num = num;
+
+	rv = get_uchar(toks, &bit, "bit to set", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &value, "bit value", 0);
+	if (rv)
+		return rv;
+
+	rv = ipmi_mc_sensor_set_bit(&sensor_ident, (unsigned int) bit,
+				    (unsigned int) value, NULL);
+	if (rv)
+		sprintf(response, "**Unable to set sensor bit, error 0x%x\n",
+			rv);
+	return rv;
+}
+
+static int sensor_inc_value(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	int rv;
+	int i;
+	unsigned char lun;
+	unsigned char num;
+	unsigned char value;
+	vMC_ipmi_sensor_ident_t sensor_ident;
+
+	rv = get_uchar(toks, &lun, "LUN", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &num, "sensor num", 0);
+	if (rv)
+		return rv;
+	sensor_ident.sensor_mc = ipmb;
+	sensor_ident.sensor_lun = lun;
+	sensor_ident.sensor_num = num;
+
+	rv = get_uchar(toks, &value, "value", 0);
+	if (rv)
+		return rv;
+
+	for (i = 0; i < value; i++) {
+		rv = ipmi_mc_sensor_inc_value(&sensor_ident, 1, NULL);
+		if (rv) {
+			sprintf(response,
+				"**Unable to inc sensor value, error 0x%x\n",
+				rv);
+			return rv;
+		}
+	}
+	return rv;
+}
+static int sensor_dec_value(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	int rv;
+	int i;
+	unsigned char lun;
+	unsigned char num;
+	unsigned char value;
+	vMC_ipmi_sensor_ident_t sensor_ident;
+
+	rv = get_uchar(toks, &lun, "LUN", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &num, "sensor num", 0);
+	if (rv)
+		return rv;
+	sensor_ident.sensor_mc = ipmb;
+	sensor_ident.sensor_lun = lun;
+	sensor_ident.sensor_num = num;
+
+	rv = get_uchar(toks, &value, "value", 0);
+	if (rv)
+		return rv;
+
+	for (i = 0; i < value; i++) {
+		rv = ipmi_mc_sensor_dec_value(&sensor_ident, 1, NULL);
+		if (rv) {
+			sprintf(response,
+				"**Unable to dec sensor value, error 0x%x\n",
+				rv);
+			return rv;
+		}
+	}
+	return rv;
+}
+
+static int sensor_set_value(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	int rv;
+	unsigned char lun;
+	unsigned char num;
+	unsigned char value;
+	vMC_ipmi_sensor_ident_t sensor_ident;
+
+	rv = get_uchar(toks, &lun, "LUN", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &num, "sensor num", 0);
+	if (rv)
+		return rv;
+
+	sensor_ident.sensor_mc = ipmb;
+	sensor_ident.sensor_lun = lun;
+	sensor_ident.sensor_num = num;
+
+	rv = get_uchar(toks, &value, "value", 0);
+	if (rv)
+		return rv;
+
+	rv = ipmi_mc_sensor_set_value(&sensor_ident, value, NULL);
+	if (rv)
+		sprintf(response, "**Unable to set sensor value, error 0x%x\n",
+			rv);
+	return rv;
+}
+
+static int sensor_set_hysteresis(lmc_data_t *mc, unsigned char ipmb,
+				 char **toks)
+{
+	int rv;
+	unsigned char lun;
+	unsigned char num;
+	unsigned char support;
+	unsigned char positive, negative;
+	vMC_ipmi_sensor_ident_t sensor_ident;
+
+	rv = get_uchar(toks, &lun, "LUN", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &num, "sensor num", 0);
+	if (rv)
+		return rv;
+
+	sensor_ident.sensor_mc = ipmb;
+	sensor_ident.sensor_lun = lun;
+	sensor_ident.sensor_num = num;
+
+	rv = get_uchar(toks, &support, "hysteresis support", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &positive, "positive hysteresis", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &negative, "negative hysteresis", 0);
+	if (rv)
+		return rv;
+
+	rv = ipmi_mc_sensor_set_hysteresis(&sensor_ident, support, positive,
+					   negative);
+	if (rv)
+		sprintf(response,
+			"**Unable to set sensor hysteresis, error 0x%x\n", rv);
+	return rv;
+}
+
+static int sensor_set_threshold(lmc_data_t *mc, unsigned char ipmb,
+				char **toks)
+{
+	int rv;
+	unsigned char lun;
+	unsigned char num;
+	unsigned char support;
+	unsigned char readmask, setmask;
+	unsigned char thresholds[6];
+	vMC_ipmi_sensor_ident_t sensor_ident;
+	int i;
+
+	rv = get_uchar(toks, &lun, "LUN", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &num, "sensor num", 0);
+	if (rv)
+		return rv;
+
+	sensor_ident.sensor_mc = ipmb;
+	sensor_ident.sensor_lun = lun;
+	sensor_ident.sensor_num = num;
+
+	rv = get_uchar(toks, &support, "threshold support", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &readmask, "threshold readmask", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &setmask, "threshold setmask", 0);
+	if (rv)
+		return rv;
+
+	for (i = 5; i >= 0; i--) {
+		rv = get_uchar(toks, &thresholds[i], "threshold value", 0);
+		if (rv)
+			return rv;
+	}
+
+	rv = ipmi_mc_sensor_set_threshold(&sensor_ident, support, readmask,
+					  setmask, thresholds);
+	if (rv)
+		sprintf(response,
+			"**Unable to set sensor thresholds, error 0x%x\n", rv);
+	return rv;
+}
+
+static int sensor_set_event_support(lmc_data_t *mc, unsigned char ipmb,
+				    char **toks)
+{
+	int rv;
+	unsigned char lun;
+	unsigned char num;
+	unsigned char support;
+	unsigned int assert_support;
+	unsigned int deassert_support;
+	vMC_ipmi_sensor_ident_t sensor_ident;
+
+	rv = get_uchar(toks, &lun, "LUN", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &num, "sensor num", 0);
+	if (rv)
+		return rv;
+
+	sensor_ident.sensor_mc = ipmb;
+	sensor_ident.sensor_lun = lun;
+	sensor_ident.sensor_num = num;
+
+	rv = get_uchar(toks, &support, "event support", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uint(toks, &assert_support, "assert support");
+	if (rv)
+		return rv;
+
+	rv = get_uint(toks, &deassert_support, "deassert support");
+	if (rv)
+		return rv;
+
+	rv = ipmi_mc_sensor_set_event_support(&sensor_ident, support,
+					      assert_support, deassert_support);
+	if (rv)
+		sprintf(response,
+			"**Unable to set sensor thresholds, error 0x%x\n", rv);
+	return rv;
+}
+
+static int sensor_get_val(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	int rv;
+	unsigned char lun;
+	unsigned char num;
+	vMC_ipmi_sensor_ident_t sensor_ident;
+	unsigned int val;
+
+	rv = get_uchar(toks, &lun, "LUN", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uchar(toks, &num, "sensor num", 0);
+	if (rv)
+		return rv;
+
+	sensor_ident.sensor_mc = ipmb;
+	sensor_ident.sensor_lun = lun;
+	sensor_ident.sensor_num = num;
+
+	rv = ipmi_mc_sensor_get_value(&sensor_ident, &val);
+	if (rv)
+		sprintf(response, "**Unable to get sensor value, error %d\n",
+			rv);
+	else
+		printk(KERN_INFO "Sensor 0x%x value is: 0x%x\n", num, val);
+	return rv;
+}
+
+static int mc_add(lmc_data_t *mc, unsigned char mcipmb, char **toks)
+{
+	unsigned char ipmb;
+	unsigned char device_id;
+	unsigned char has_device_sdrs;
+	unsigned char device_revision;
+	unsigned char major_fw_rev;
+	unsigned char minor_fw_rev;
+	unsigned char device_support;
+	unsigned char mfg_id[3];
+	unsigned int mfg_id_i;
+	unsigned char product_id[2];
+	unsigned int product_id_i;
+	unsigned char dyn_sens = 0;
+	unsigned char channel;
+	int rv;
+
+	rv = get_uchar(toks, &ipmb, "IPMB address", 0);
+	if (rv)
+		return rv;
+	rv = get_uchar(toks, &channel, "IPMI channel", 0);
+	if (rv)
+		return rv;
+	channel = channel & 0x0F;
+	rv = get_uchar(toks, &device_id, "Device ID", 0);
+	if (rv)
+		return rv;
+	rv = get_uchar(toks, &has_device_sdrs, "Has Device SDRs", 0);
+	if (rv)
+		return rv;
+	if ((has_device_sdrs != 0x01) && (has_device_sdrs != 0x00)) {
+		printk(KERN_INFO
+		       "vMC: MC using default value for device sdr flag\n");
+		has_device_sdrs = 0x01;
+	}
+	rv = get_uchar(toks, &device_revision, "Device Revision", 0);
+	if (rv)
+		return rv;
+	rv = get_uchar(toks, &major_fw_rev, "Major FW Rev", 0);
+	if (rv)
+		return rv;
+	rv = get_uchar(toks, &minor_fw_rev, "Minor FW Rev", 0);
+	if (rv)
+		return rv;
+	rv = get_uchar(toks, &device_support, "Device Support", 0);
+	if (rv)
+		return rv;
+	rv = get_uint(toks, &mfg_id_i, "Manufacturer ID");
+	if (rv)
+		return rv;
+	rv = get_uint(toks, &product_id_i, "Product ID");
+	if (rv)
+		return rv;
+	rv = get_uchar(toks, &dyn_sens, "Dynamic Sensor Population", 1);
+	if (rv)
+		return rv;
+	if ((dyn_sens != 0x01) && (dyn_sens != 0x00)) {
+		printk(KERN_INFO
+		       "vMC: MC using default value for dynamic " \
+		       "sensor population\n");
+		dyn_sens = 0x01;
+	}
+
+	mfg_id[0] = mfg_id_i & 0xff;
+	mfg_id[1] = (mfg_id_i >> 8) & 0xff;
+	mfg_id[2] = (mfg_id_i >> 16) & 0xff;
+	product_id[0] = product_id_i & 0xff;
+	product_id[1] = (product_id_i >> 8) & 0xff;
+	rv = ipmi_emu_add_mc(ipmb, channel, device_id, has_device_sdrs,
+			     device_revision, major_fw_rev, minor_fw_rev,
+			     device_support, mfg_id, product_id, dyn_sens);
+	if (rv)
+		sprintf(response, "**Unable to add the MC, error 0x%x\n", rv);
+	return rv;
+}
+
+static int mc_delete(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	ipmi_emu_delete_mc(mc);
+	return 0;
+}
+
+static int mc_disable(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	ipmi_mc_disable(mc);
+	return 0;
+}
+
+static int mc_enable(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	ipmi_mc_enable(mc);
+	return 0;
+}
+
+static int mc_setbmc(lmc_data_t *mc, unsigned char mcipmb, char **toks)
+{
+	unsigned char ipmb;
+	int rv;
+
+	rv = get_uchar(toks, &ipmb, "IPMB address of BMC", 0);
+	if (rv)
+		return rv;
+	rv = ipmi_emu_set_bmc_mc(ipmb);
+	if (rv)
+		sprintf(response, "**Invalid IPMB address\n");
+	return rv;
+}
+
+static int mc_set_dev_id(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	int rv;
+	unsigned char dev_id;
+	rv = get_uchar(toks, &dev_id, "device id", 0);
+	if (rv)
+		return rv;
+
+	ipmi_mc_set_device_id(mc, dev_id);
+	return 0;
+}
+
+static int mc_get_dev_id(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	sprintf(response, "Device id = %c\n", ipmi_mc_get_device_id(mc));
+	return 0;
+}
+
+static int dump_sel(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	ipmi_emu_dump_sel(mc);
+	return 0;
+}
+
+static int dump_dev_sdr(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	ipmi_emu_dump_dev_sdr(mc);
+	return 0;
+}
+
+static int dump_main_sdr(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	ipmi_emu_dump_main_sdr(mc);
+	return 0;
+}
+
+static int atca_set_site(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	int rv;
+	unsigned char hw_address;
+	unsigned char site_type;
+	unsigned char site_number;
+
+	rv = get_uchar(toks, &hw_address, "hardware address", 0);
+	if (rv)
+		return rv;
+	rv = get_uchar(toks, &site_type, "site type", 0);
+	if (rv)
+		return rv;
+	rv = get_uchar(toks, &site_number, "site number", 0);
+	if (rv)
+		return rv;
+
+	rv = ipmi_emu_atca_set_site(hw_address, site_type, site_number);
+	if (rv)
+		sprintf(response, "**Unable to set site type, error 0x%x\n",
+			rv);
+	return rv;
+}
+
+#define MAX_FRU_SIZE 8192
+static int mc_add_fru_data(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	unsigned char *data;
+	unsigned char devid;
+	unsigned int length;
+	int i;
+	int rv;
+
+	rv = get_uchar(toks, &devid, "Device ID", 0);
+	if (rv)
+		return rv;
+
+	rv = get_uint(toks, &length, "FRU physical size");
+	if (rv)
+		return rv;
+
+	data = (unsigned char *) vmc_kmalloc(length, GFP_KERNEL);
+	if (!data) {
+		sprintf(response, "vMC out of memory for FRU data.\n");
+		return -1;
+	}
+	for (i = 0; i < length; i++) {
+		rv = get_uchar(toks, &data[i], "data byte", 1);
+		if (rv == VMC_ENOSPC)
+			break;
+		if (rv) {
+			sprintf(response, "**Error 0x%x in data byte %d\n", rv,
+				i);
+			return rv;
+		}
+	}
+
+	rv = ipmi_mc_add_fru_data(mc, devid, length, data, i);
+	if (rv)
+		sprintf(response, "**Unable to add FRU data, error 0x%x\n", rv);
+	return rv;
+}
+
+static int mc_setchan(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	unsigned char channel;
+	unsigned char medium_type;
+	unsigned char protocol_type;
+	unsigned char session_support;
+	int rv;
+
+	rv = get_uchar(toks, &channel, "Channel Number", 0);
+	if (rv)
+		return rv;
+	rv = get_uchar(toks, &medium_type, "Medium Type", 0);
+	if (rv)
+		return rv;
+	rv = get_uchar(toks, &protocol_type, "Protocol Type", 0);
+	if (rv)
+		return rv;
+	rv = get_uchar(toks, &session_support, "Session Support", 0);
+	if (rv)
+		return rv;
+	rv = ipmi_emu_set_mc_channel(mc, channel, medium_type, protocol_type,
+				     session_support);
+	if (rv)
+		sprintf(response, "**Unable to set up channel, error 0x%x\n",
+			rv);
+	return rv;
+}
+
+static int memstats(lmc_data_t *mc, unsigned char ipmb, char **toks)
+{
+	int all = vmc_mem_allocs;
+	int free = vmc_mem_frees;
+
+	printk(KERN_INFO "Mem allocs: %d Mem frees: %d Delta: %d\n", all, free,
+	       all - free);
+	return 0;
+}
+
+#define MC	1
+#define NOMC	0
+static struct {
+	char *name;
+	int flags;
+	ipmi_emu_cmd_handler handler;
+} cmds[] = {
+	{"sel_enable", MC, sel_enable},
+	{"sel_disable", MC, sel_disable},
+	{"main_sdr_add", MC, main_sdr_add},
+	{"device_sdr_add", MC, device_sdr_add},
+	{"sensor_set_bit", MC, sensor_set_bit},
+	{"sensor_inc_value", MC, sensor_inc_value},
+	{"sensor_dec_value", MC, sensor_dec_value},
+	{"sensor_set_value", MC, sensor_set_value},
+	{"sensor_set_hysteresis", MC, sensor_set_hysteresis},
+	{"sensor_set_threshold", MC, sensor_set_threshold},
+	{"sensor_set_event_support", MC, sensor_set_event_support},
+	{"sensor_get_value", MC, sensor_get_val},
+	{"mc_add", NOMC, mc_add},
+	{"mc_delete", MC, mc_delete},
+	{"mc_disable", MC, mc_disable},
+	{"mc_enable", MC, mc_enable},
+	{"mc_setbmc", NOMC, mc_setbmc},
+	{"mc_set_dev_id", MC, mc_set_dev_id},
+	{"mc_get_dev_id", MC, mc_get_dev_id},
+	{"dump_sel", MC, dump_sel},
+	{"dump_dev_sdr", MC, dump_dev_sdr},
+	{"dump_sdr", MC, dump_main_sdr},
+	{"atca_set_site", NOMC, atca_set_site},
+	{"mc_add_fru_data", MC, mc_add_fru_data},
+	{"mc_setchan", MC, mc_setchan},
+	{"memstat", MC, memstats},
+	{NULL}
+};
+
+int ipmi_emu_cmd(char *cmd_str)
+{
+	char *cmd;
+	int i;
+	int rv = 0;
+	lmc_data_t *mc = NULL;
+	unsigned char ipmb = 0;
+
+	cmd = strsep(&cmd_str, " \t\n");
+	if (!cmd)
+		return 0;
+	if (cmd[0] == '#')
+		return 0;
+
+	for (i = 0; cmds[i].name; i++) {
+		if (strcmp(cmd, cmds[i].name) == 0) {
+			if (cmds[i].flags & MC) {
+				rv = get_uchar(&cmd_str, &ipmb, "MC address",
+					       0);
+				if (rv)
+					return rv;
+				rv = ipmi_emu_get_mc_by_addr(ipmb, &mc);
+				if (rv) {
+					sprintf(response,
+						"**Invalid MC address\n");
+					return rv;
+				}
+			}
+			rv = cmds[i].handler(mc, ipmb, &cmd_str);
+			if (rv)
+				return rv;
+			sprintf(response, "Ready.\n");
+			return 0;
+		}
+	}
+
+	sprintf(response, "**Unknown command: %s\n", cmd);
+	return 0;
+}
diff --git a/drivers/char/ipmi/vmc_emu.c b/drivers/char/ipmi/vmc_emu.c
new file mode 100644
index 0000000..810af45
--- /dev/null
+++ b/drivers/char/ipmi/vmc_emu.c
@@ -0,0 +1,5041 @@
+/*
+ * Wind River IPMI virtual Management Controller mainline
+ *
+ * The virtual Management Controller (vMC) implements a subset of an IPMI
+ * Baseboard Management Controller (BMC) in a kernel module. The vMC
+ * plugs into the OpenIPMI KLM which makes it look like a normal
+ * IPMI management controller to user applications.
+ *
+ * This file implements the heart of the vMC. All of the system event
+ * log, sensor data repository, and management controller emulation
+ * can be found in this file. This code was based on the user space
+ * emulator implemented by Monta Vista.
+ *
+ * Author: Wind River Systems
+ *         Chris Stone <christopher.stone@windriver.com>
+ *
+ * Copyright 2005 Wind River Systems
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2 of the License, or (at your
+ *  option) any later version.
+ *
+ *
+ *  THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
+ *  WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
+ *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
+ *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+ *  BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
+ *  OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ *  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
+ *  TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ *  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include "vmc_emu.h"
+#include "vmc_ipmb.h"
+#include "vmc_smi.h"
+#include "ipmi_msgbits.h"
+
+#include <linux/spinlock.h>
+#include <linux/slab.h>
+#include <asm/atomic.h>
+#include <linux/delay.h>
+#include <asm/atomic.h>
+
+#define VMC_INVALID_PARTITION_INDEX      -1
+#define VMC_SEL_LIST_EMPTY               -2
+#define VMC_INVALID_RECORD_ID            -3
+#define VMC_SEL_NOT_ENABLE               -4
+#define VMC_DEVICE_NOT_SUPPORT           -5
+#define VMC_INVALID_RESERVATION          -6
+#define VMC_INVALID_DATA_FIELD           -7
+#define VMC_NOT_PRESENT                  -8
+#define VMC_INVALID_MSG_LEN              -9
+#define VMC_PMEM_WRITE_ERROR             -10
+#define VMC_INVALID_PARAMETER            -11
+#define VMC_SEL_EMPTY                    -12
+
+#define PMEM_LOG_DESC_DATA_SIZE		sizeof(struct pmem_log_desc_data)
+#define PMEM_REGION_DATA_HDR_SIZE	sizeof(struct pmem_region_data_hdr)
+
+#define VMC_CACHE_NAME_SIZE	16
+
+typedef struct ipmi_msg_s {
+	int data_len;
+	unsigned char netfn;
+	unsigned char cmd;
+	unsigned char data[IPMI_MAX_MSG_LENGTH - 2];
+} ipmi_msg_t;
+
+/* Counters to track kmalloc, kfree */
+int vmc_mem_allocs, vmc_mem_frees;
+
+/* Device ID support bits */
+#define IPMI_DEVID_CHASSIS_DEVICE	(1 << 7)
+#define IPMI_DEVID_BRIDGE		(1 << 6)
+#define IPMI_DEVID_IPMB_EVENT_GEN	(1 << 5)
+#define IPMI_DEVID_IPMB_EVENT_RCV	(1 << 4)
+#define IPMI_DEVID_FRU_INVENTORY_DEV	(1 << 3)
+#define IPMI_DEVID_SEL_DEVICE		(1 << 2)
+#define IPMI_DEVID_SDR_REPOSITORY_DEV	(1 << 1)
+#define IPMI_DEVID_SENSOR_DEV		(1 << 0)
+
+/* SEL support bits */
+#define IPMI_SEL_SUPPORTS_DELETE         (1 << 3)
+#define IPMI_SEL_SUPPORTS_RESERVE        (1 << 1)
+#define IPMI_SEL_SUPPORTS_GET_ALLOC_INFO (1 << 0)
+
+#define IPMI_SEL_OVERFLOW_FLAG  (1 << 7)
+
+/* Wait queue for when we need to sleep. */
+static DECLARE_WAIT_QUEUE_HEAD(emuq);
+
+static struct emu_data_s *emu;
+
+#ifdef CONFIG_IPMI_VMC_ENABLE_PMEM
+#include <linux/pmem.h>
+
+#define MAX_NUMBER_VMCS  20
+struct pmem_reg_part vMC_pmem_sel_partition[MAX_NUMBER_VMCS];
+struct pmem_reg_region sel_region[MAX_NUMBER_VMCS];
+pmem_handle_t partition_handle[MAX_NUMBER_VMCS];
+pmem_handle_t region_write_handle[MAX_NUMBER_VMCS];
+pmem_handle_t region_read_handle[MAX_NUMBER_VMCS];
+
+/*
+ * 	Utility functions
+ */
+static int partition_index(char id, int *index)
+{
+	char name[20];
+	char answer[] = "vMC SEL Record";
+	char mc_id = id;
+	int i;
+	sprintf(name, "%s%d", answer, mc_id);
+
+	for (i = 0; i < 20; i++) {
+		if (strcmp(vMC_pmem_sel_partition[i].desc, name) == 0) {
+			*index = i;
+			return VMC_NO_ERROR;
+		}
+	}
+
+	return VMC_INVALID_PARTITION_INDEX;
+}
+
+#endif
+
+void dump_mem(char *title, void *mem, int len)
+{
+	unsigned char *p;
+	int k, m;
+
+	p = mem;
+	printk(KERN_INFO "%s: ", title);
+	for (k = 0; k < ((len / 4) + 1); k++) {
+		for (m = 0; m < 4; m++)
+			printk("%02x", p[(k*4)+m]);
+		printk(" ");
+	}
+	printk("\n");
+}
+
+#ifdef CONFIG_IPMI_VMC_ENABLE_PMEM
+static int entrynum;
+#endif
+
+/* Deal with multi-byte data, IPMI (little-endian) style. */
+static unsigned int ipmi_get_uint16(uint8_t *data)
+{
+	return data[0]
+		|(data[1] << 8);
+}
+
+static void ipmi_set_uint16(uint8_t *data, int val)
+{
+	data[0] = val & 0xff;
+	data[1] = (val >> 8) & 0xff;
+}
+
+static unsigned int ipmi_get_uint32(uint8_t *data)
+{
+	return data[0]
+		| (data[1] << 8)
+		| (data[2] << 16)
+		| (data[3] << 24);
+}
+
+static void ipmi_set_uint32(uint8_t *data, int val)
+{
+	data[0] = val & 0xff;
+	data[1] = (val >> 8) & 0xff;
+	data[2] = (val >> 16) & 0xff;
+	data[3] = (val >> 24) & 0xff;
+}
+
+static void ipmi_emu_dump_sdr(vMC_ipmi_sdr_t *entry, int count, char *name)
+{
+	unsigned int k, m;
+	unsigned char *p;
+
+	p = (unsigned char *) entry;
+	printk(KERN_INFO "%s SDR %d: ", name, count);
+	for (k = 0; k < ((sizeof(vMC_ipmi_sdr_t) / 4) + 1); k++) {
+		for (m = 0; m < 4; m++)
+			printk("%02x", p[(k * 4) + m]);
+		printk(" ");
+	}
+	printk("\n");
+}
+
+static void handle_error_response(unsigned char err_code,
+		      unsigned char *rdata, unsigned int *rdata_len)
+{
+	rdata[0] = err_code;
+	*rdata_len = 1;
+}
+
+static void handle_invalid_cmd(unsigned char *rdata, unsigned int *rdata_len)
+{
+	handle_error_response(IPMI_INVALID_CMD_CC, rdata, rdata_len);
+}
+
+static int check_msg_length(ipmi_msg_t *msg,
+		 unsigned int len,
+		 unsigned char *rdata, unsigned int *rdata_len)
+{
+	if (msg->data_len < len) {
+		handle_error_response(IPMI_REQUEST_DATA_LENGTH_INVALID_CC,
+				      rdata, rdata_len);
+		return VMC_INVALID_MSG_LEN;
+	}
+
+	return VMC_NO_ERROR;
+}
+
+/*
+ * System Event Log implementation
+ */
+
+#ifndef CONFIG_IPMI_VMC_ENABLE_PMEM
+static vMC_ipmi_sel_record_t *
+find_sel_event_by_recid(lmc_data_t *mc,
+			uint16_t record_id, vMC_ipmi_sel_record_t **prev)
+{
+	vMC_ipmi_sel_record_t *entry, *n;
+	vMC_ipmi_sel_record_t *p_entry = NULL;
+
+	if (list_empty(&(mc->sel.entries)))
+		return NULL;
+
+	list_for_each_entry_safe(entry, n, &(mc->sel.entries), list) {
+		if (record_id == entry->recid)
+			goto found;
+		p_entry = entry;
+	}
+
+	if (prev)
+		*prev = p_entry;
+	return NULL;
+
+found:
+	if (prev)
+		*prev = p_entry;
+	return entry;
+}
+#endif
+
+int ipmi_mc_enable_sel(lmc_data_t *mc, int max_entries, unsigned char flags)
+{
+	struct timeval t;
+
+#ifdef CONFIG_IPMI_VMC_ENABLE_PMEM
+	char part_name[18];
+	char reg_name[18];
+	char name_region[] = "vMC SEL Entries";
+	char name_partition[] = "vMC SEL Record";
+	char buffer1[sizeof(struct pmem_log_desc_index)];
+#endif
+
+	if (!mc)
+		return VMC_EINVAL;
+	if (mc->sel.enabled)
+		return VMC_NO_ERROR;
+
+#ifdef CONFIG_IPMI_VMC_ENABLE_PMEM
+	sprintf(part_name, "%s%d", name_partition, mc->device_id);
+	strcpy(vMC_pmem_sel_partition[entrynum].desc, part_name);
+	vMC_pmem_sel_partition[entrynum].size = max_entries *
+				PMEM_SEL_DATA_LENGTH *
+				CONFIG_IPMI_VMC_PMEM_BLOCKS_NUMBER;
+	vMC_pmem_sel_partition[entrynum].num_blocks =
+				CONFIG_IPMI_VMC_PMEM_BLOCKS_NUMBER;
+	vMC_pmem_sel_partition[entrynum].version = 1;
+	if (pmem_partition_reg(&vMC_pmem_sel_partition[entrynum],
+			       &partition_handle[entrynum]) < 0) {
+		printk(KERN_ERR "Unable to register vMC partition\n");
+		return PMEM_INVALID_BLOCK;
+	}
+
+	sprintf(reg_name, "%s%d", name_region, mc->device_id);
+	strncpy(sel_region[entrynum].desc, reg_name, PMEM_DESC_MAX);
+	sel_region[entrynum].size = max_entries * PMEM_SEL_DATA_LENGTH;
+	sel_region[entrynum].flags = PMEM_REGION_FLAG_CIRCBUF;
+	sel_region[entrynum].fixed_size = PMEM_SEL_DATA_LENGTH;
+	sel_region[entrynum].num_log_desc = 0;
+	sel_region[entrynum].version = 1;
+	sel_region[entrynum].block_id = PMEM_ACTIVE_BLOCK;
+
+	if (pmem_region_reg(partition_handle[entrynum],
+			    &sel_region[entrynum],
+			    &region_read_handle[entrynum]) < 0) {
+		printk(KERN_ERR "Unable to get general logs region");
+		return -1;
+	}
+	pmem_read_data(region_read_handle[entrynum],
+		       buffer1, sizeof(struct pmem_log_desc_index));
+	if (pmem_region_reg(partition_handle[entrynum],
+			    &sel_region[entrynum],
+			    &region_write_handle[entrynum]) < 0) {
+		printk(KERN_ERR "Unable to get general logs region");
+		return -1;
+	}
+	entrynum++;
+#endif
+
+	spin_lock(&mc->sel.lock);
+
+#ifndef CONFIG_IPMI_VMC_ENABLE_PMEM
+	INIT_LIST_HEAD(&(mc->sel.entries));
+#endif
+
+	do_gettimeofday(&t);
+	atomic_set(&mc->sel.count, 0);
+	mc->sel.max_count = max_entries;
+	mc->sel.last_add_time = t.tv_sec;
+	mc->sel.last_erase_time = t.tv_sec;
+	/*
+	 * Don't support Reserve SEL,
+	 * support Delete SEL only when PMEM not used.
+	 */
+#ifdef CONFIG_IPMI_VMC_ENABLE_PMEM
+	mc->sel.flags = flags & IPMI_SEL_SUPPORTS_GET_ALLOC_INFO;
+#else
+	mc->sel.flags = flags & (IPMI_SEL_SUPPORTS_DELETE |
+				 IPMI_SEL_SUPPORTS_GET_ALLOC_INFO);
+#endif
+	mc->sel.reservation = 0;
+	mc->sel.next_entry = 1;
+	mc->sel.enabled = 1;
+
+	spin_unlock(&mc->sel.lock);
+	return VMC_NO_ERROR;
+}
+
+static int clear_sel(lmc_data_t *mc)
+{
+#ifndef CONFIG_IPMI_VMC_ENABLE_PMEM
+	vMC_ipmi_sel_record_t *entry, *n;
+
+	if (!list_empty(&mc->sel.entries)) {
+		list_for_each_entry_safe(entry, n, &mc->sel.entries, list) {
+			spin_lock(&mc->sel.lock);
+			list_del(&entry->list);
+			spin_unlock(&mc->sel.lock);
+			kmem_cache_free(mc->sel.selCache, entry);
+		}
+	}
+
+#else
+	/*
+	 * TODO:
+	 * From history we know normally only one vMC instance would
+	 * be installed. However, If multiple vMC instances are used,
+	 * the entrynum for current vMC instance should be saved into
+	 * its private data structure rather than using a global variable.
+	 */
+	entrynum--;
+
+	/*
+	 * When current vMC instance deleted, its PMEM SEL parition &
+	 * region won't be unregistered and could be re-used if
+	 * added later. So do NOT set pmem_handle pointers NULL
+	 * in arries of partition_handle[], region_read_handle[] and
+	 * region_write_handle[], neither touch its element in
+	 * vMC_pmem_sel_partition[].
+	 */
+#endif
+
+	if (vmcDebug)
+		printk(KERN_INFO "vMC SEL cleared.\n");
+
+	atomic_set(&mc->sel.count, 0);
+	mc->sel.enabled = 0;
+
+	return VMC_NO_ERROR;
+}
+
+int ipmi_mc_disable_sel(lmc_data_t *mc)
+{
+	if (!mc)
+		return VMC_EINVAL;
+
+	if (!mc->sel.enabled) {
+		printk(KERN_INFO "SEL is already disabled!\n");
+		return VMC_NO_ERROR;
+	}
+
+	clear_sel(mc);
+
+	return VMC_NO_ERROR;
+}
+
+static unsigned int ipmi_assign_recid(vMC_ipmi_sel_record_t *record)
+{
+	spin_lock(&record->mc->sel.lock);
+	if (!record->mc->sel.enabled) {
+		record->mc->sel.flags |= IPMI_SEL_OVERFLOW_FLAG;
+		spin_unlock(&record->mc->sel.lock);
+		vMC_free_sel_record(record);
+		printk(KERN_ERR "Event log not enabled, dropping events\n");
+		return 0;
+	}
+
+	if (atomic_read(&record->mc->sel.count) >= record->mc->sel.max_count) {
+#ifdef CONFIG_IPMI_VMC_ENABLE_PMEM
+		printk(KERN_INFO "Event log full, dropping oldest event\n");
+#else
+		record->mc->sel.flags |= IPMI_SEL_OVERFLOW_FLAG;
+#endif
+	}
+
+	record->recid = record->mc->sel.next_entry++;
+	/* wrap recid on rollover */
+	if (record->mc->sel.next_entry == 0xFFFF)
+		record->recid = record->mc->sel.next_entry = 1;
+	spin_unlock(&record->mc->sel.lock);
+
+#ifndef CONFIG_IPMI_VMC_ENABLE_PMEM
+	while ((record->recid == 0)
+	       || find_sel_event_by_recid(record->mc, record->recid, NULL)) {
+		spin_lock(&record->mc->sel.lock);
+		record->recid = record->mc->sel.next_entry++;
+		spin_unlock(&record->mc->sel.lock);
+	}
+#endif
+
+	return record->recid;
+}
+
+static int ipmi_mc_send_sel_msg(struct ipmi_smi_msg *smiMsg)
+{
+	vMC_kapi_cmd_t *cmd;
+
+	cmd = vmc_kmalloc(sizeof(vMC_kapi_cmd_t), GFP_ATOMIC);
+	if (cmd == NULL)
+		return VMC_ENOMEM;
+
+	cmd->cmd = IPMI_SEND_CMD;
+	cmd->smiMsg = smiMsg;
+	kapicmd(cmd);
+
+	return VMC_NO_ERROR;
+}
+
+#define SEL_RECORD_TYPE_NONTIMESTAMP  0xe0
+
+/*
+ * Note the following function is not SMP safe, but, is only meant to be
+ * called from the SEL tasklet which owns the event pending list. The tasklet
+ * will not be run on multiple CPU's in the SMP case.
+ * NOTE NOTE - PMEM writing occurs in gen_event now.
+ */
+static int ipmi_mc_add_to_sel(lmc_data_t *mc, vMC_ipmi_sel_record_t *record)
+{
+	struct ipmi_smi_msg *smiMsg;
+
+	if (!record)
+		return VMC_INVALID_PARAMETER;
+
+	if (mc->global_enables & 0x04) {
+		smiMsg = ipmi_alloc_smi_msg();
+		if (smiMsg == NULL) {
+			mc->smiMissed = 1;
+			printk(KERN_INFO "ipmi_alloc_smi_msg failed\n");
+		} else {
+			smiMsg->data_size = 0;
+			smiMsg->data[0] = IPMI_NETFN_APP_REQUEST << 2;
+			smiMsg->data[1] = IPMI_READ_EVENT_MSG_BUFFER_CMD;
+			smiMsg->rsp[0] = (IPMI_NETFN_APP_REQUEST | 1) << 2;
+			smiMsg->rsp[1] = IPMI_READ_EVENT_MSG_BUFFER_CMD;
+			smiMsg->rsp[2] = 0x00;
+			memcpy(&(smiMsg->rsp[3]), record, 16);
+			smiMsg->rsp_size = 19;
+			/* northbound: */
+			if (ipmi_mc_send_sel_msg(smiMsg) == VMC_NO_ERROR)
+				record->sm_sent = 1;	/* currently NOT used */
+			else {
+				mc->smiMissed = 1;
+				printk(KERN_INFO
+				       "ipmi_mc_send_sel_msg failed\n");
+			}
+		}
+	} else {
+		mc->smiMissed = 1;
+	}
+
+#ifdef CONFIG_IPMI_VMC_ENABLE_PMEM
+	vMC_free_sel_record(record);
+#else
+	list_add_tail(&record->list, &(mc->sel.entries));
+	atomic_inc(&record->mc->sel.count);
+#endif
+
+	return VMC_NO_ERROR;
+}
+
+static void ipmi_scan_sel(lmc_data_t *mc)
+{
+#ifdef CONFIG_IPMI_VMC_ENABLE_PMEM
+	printk(KERN_INFO "ipmi_scan_sel ran.\n");
+#endif
+}
+
+void ipmi_request_events(void)
+{
+	lmc_data_t *mc;
+
+	if (emu->bmc_mc == 0)
+		return;
+
+	if (emu->ipmb[emu->bmc_mc >> 1] == NULL) {
+		printk(KERN_INFO "NO ipmb available.\n");
+		return;
+	}
+
+	mc = emu->ipmb[emu->bmc_mc >> 1];
+
+	if (mc->global_enables & 0x04) {
+		if (mc->smiMissed) {
+			ipmi_scan_sel(mc);
+			mc->smiMissed = 0;
+		}
+	}
+}
+
+void ipmi_add_to_sel_tlet(vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	unsigned long flags;
+
+	/* Place record in tasklet queue and kick the tasklet */
+	spin_lock_irqsave(&vMC_sel_record->mc->sel.lock, flags);
+	list_add_tail(&vMC_sel_record->list, &sel_tasklet.list);
+	if (sel_tasklet.hi)
+		tasklet_hi_schedule(&sel_tasklet.tlet);
+	else
+		tasklet_schedule(&sel_tasklet.tlet);
+	spin_unlock_irqrestore(&vMC_sel_record->mc->sel.lock, flags);
+
+}
+
+static int write_sel_to_pmem(vMC_ipmi_sel_record_t *selr)
+{
+#ifdef CONFIG_IPMI_VMC_ENABLE_PMEM
+	char id;
+	int rc, index, lsize;
+	unsigned char *p;
+
+	id = selr->mc->device_id;
+
+	if (partition_index(id, &index) != VMC_INVALID_PARTITION_INDEX) {
+
+		lsize = sel_region[index].fixed_size;
+
+		p = vmc_kmalloc(PMEM_SEL_DATA_LENGTH, GFP_ATOMIC);
+		if (p)
+			memset(p, 0, PMEM_SEL_DATA_LENGTH);
+		else
+			return VMC_ENOMEM;
+
+		memcpy(p, (unsigned char *) selr, IPMI_SEL_DATA_LENGTH);
+
+		if (selr->extended_event_length > 0) {
+			if (selr->extended_event_data == NULL) {
+				vMC_free_sel_record(selr);
+				vmc_kfree(p);
+				printk(KERN_INFO "extended data NULL!\n");
+				return VMC_PMEM_WRITE_ERROR;
+			} else if (selr->extended_event_length >
+				   SEL_MAX_EXTENDED_DATA_LENGTH) {
+				vMC_free_sel_record(selr);
+				vmc_kfree(p);
+				printk(KERN_INFO
+				       "extended data out of range!\n");
+				return VMC_PMEM_WRITE_ERROR;
+			} else
+				memcpy(p + IPMI_SEL_DATA_LENGTH,
+				       (unsigned char *) selr->
+				       extended_event_data,
+				       SEL_MAX_EXTENDED_DATA_LENGTH);
+		}
+		rc = pmem_write_data(region_write_handle[index], p, lsize);
+
+		vmc_kfree(p);
+		if (rc == lsize) {
+			/* successful store of SEL, so bump sel_count now */
+			atomic_inc(&selr->mc->sel.count);
+			/* printk(KERN_INFO "pmem_write_data OK!\n"); */
+		} else if (rc == 0) {
+			printk(KERN_INFO "pmem full!\n");
+			return VMC_PMEM_WRITE_ERROR;
+		} else {
+			printk(KERN_INFO "pmem_write_data failed!\n");
+			return VMC_PMEM_WRITE_ERROR;
+		}
+	}
+#endif
+	return VMC_NO_ERROR;
+}
+
+static void ipmi_add_to_sel_recid(vMC_ipmi_sel_record_t *vMC_sel_record,
+				  unsigned int *recid)
+{
+	if (NULL == vMC_sel_record)
+		return;
+	*recid = ipmi_assign_recid(vMC_sel_record);
+	if (*recid == 0)
+		return;
+	vMC_sel_record->recid = *recid;
+
+	/* write sel to PMEM, if configured */
+	write_sel_to_pmem(vMC_sel_record);
+	/* send SEL northbound, and store on linked list if PMEM */
+	/* not configured (frees SEL also, if PMEM configured)   */
+	ipmi_add_to_sel_tlet(vMC_sel_record);
+}
+
+void ipmi_add_to_sel(struct vMC_tasklet_data *sel_tasklet)
+{
+	vMC_ipmi_sel_record_t *entry, *n;
+	unsigned long flags;
+
+	list_for_each_entry_safe(entry, n, &sel_tasklet->list, list) {
+		spin_lock_irqsave(&entry->mc->sel.lock, flags);
+		list_del(&entry->list);
+		spin_unlock_irqrestore(&entry->mc->sel.lock, flags);
+		ipmi_mc_add_to_sel(entry->mc, entry);
+	}
+}
+
+static int _ipmi_mc_add_to_sel(lmc_data_t *mc,
+		    unsigned char record_type,
+		    unsigned char event[13], unsigned int *recid)
+{
+#define SEL_SLAVE_ADDR_SHIFT 1
+#define SEL_LUN_MASK         0x03
+#define SEL_IDTYPE_MASK      0x01
+	int rc;
+	vMC_ipmi_sel_record_t *selRecord =
+	    vMC_alloc_sel_record(0, mc->ipmb, &rc);
+
+	if (selRecord) {
+		selRecord->recid = 0;
+		selRecord->type = record_type;
+		selRecord->timestamp = 0;
+		selRecord->id_type = event[4] & SEL_IDTYPE_MASK;
+		selRecord->id_ipmb = event[4] >> SEL_SLAVE_ADDR_SHIFT;
+		selRecord->ipmb_lun = event[5] & SEL_LUN_MASK;
+		selRecord->evmrev = event[6];
+		selRecord->sensortype = event[7];
+		selRecord->sensornum = event[8];
+		selRecord->event_type = event[9];
+		selRecord->sel_event_data.event_data[0] = event[10];
+		selRecord->sel_event_data.event_data[1] = event[11];
+		selRecord->sel_event_data.event_data[2] = event[12];
+
+		ipmi_add_to_sel_recid(selRecord, recid);
+		if (*recid)
+			return VMC_NO_ERROR;
+		else
+			return VMC_ENOSPC;
+	}
+
+	return rc;
+}
+
+/*
+ * IPMI SEL message handler functions:
+ */
+
+static void handle_get_sel_info(lmc_data_t *mc, unsigned char *rdata,
+				unsigned int *rdata_len)
+{
+#define GETSEL_RPLY_LEN 15
+	if (!mc->sel.enabled) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (!(mc->device_support & IPMI_DEVID_SEL_DEVICE)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	memset(rdata, 0, GETSEL_RPLY_LEN);
+	rdata[1] = SDR_VER_IPMI15;
+	ipmi_set_uint16(rdata + 2, atomic_read(&mc->sel.count));
+	ipmi_set_uint16(rdata + 4,
+			(mc->sel.max_count - atomic_read(&mc->sel.count)) * 16);
+	ipmi_set_uint32(rdata + 6, mc->sel.last_add_time);
+	ipmi_set_uint32(rdata + 10, mc->sel.last_erase_time);
+	rdata[14] = mc->sel.flags;
+	*rdata_len = GETSEL_RPLY_LEN;
+}
+
+static void handle_get_sel_allocation_info(lmc_data_t *mc,
+					   unsigned char *rdata,
+					   unsigned int *rdata_len)
+{
+#define GETSELALL_RPLY_LEN 10
+	if (!mc->sel.enabled) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (!(mc->device_support & IPMI_DEVID_SEL_DEVICE)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	if (!(mc->sel.flags & IPMI_SEL_SUPPORTS_GET_ALLOC_INFO)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	memset(rdata, 0, GETSELALL_RPLY_LEN);
+	ipmi_set_uint16(rdata + 1, mc->sel.max_count * 16);
+	ipmi_set_uint16(rdata + 3, 16);
+	ipmi_set_uint16(rdata + 5,
+			(mc->sel.max_count - atomic_read(&mc->sel.count)) * 16);
+	ipmi_set_uint16(rdata + 7,
+			(mc->sel.max_count - atomic_read(&mc->sel.count)) * 16);
+	rdata[9] = 1;
+
+	*rdata_len = GETSELALL_RPLY_LEN;
+}
+
+static void handle_reserve_sel(lmc_data_t *mc, unsigned char *rdata,
+			       unsigned int *rdata_len)
+{
+#define GETSEL_RPLY_LEN 15
+	if (!(mc->device_support & IPMI_DEVID_SEL_DEVICE)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	if (!(mc->sel.flags & IPMI_SEL_SUPPORTS_RESERVE)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	mc->sel.reservation++;
+	if (mc->sel.reservation == 0)
+		/* Generate a new reservation id (0 is not allowed though!) */
+		mc->sel.reservation++;
+	rdata[0] = 0;
+	ipmi_set_uint16(rdata + 1, mc->sel.reservation);
+	*rdata_len = 3;
+
+	return;
+}
+
+static int handle_get_sel_entry(lmc_data_t *mc, ipmi_msg_t *msg,
+				unsigned char *rdata, unsigned int *rdata_len)
+{
+	uint16_t record_id;
+	uint16_t recid_tmp;
+	int offset;
+	int count;
+	vMC_ipmi_sel_record_t *entry;
+	void *p;
+
+#ifdef CONFIG_IPMI_VMC_ENABLE_PMEM
+	int index;
+
+	if (partition_index(mc->device_id, &index) ==
+				VMC_INVALID_PARTITION_INDEX)
+		return VMC_INVALID_PARTITION_INDEX;
+#endif
+
+	if (!mc->sel.enabled) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return VMC_SEL_NOT_ENABLE;
+	}
+	if (!(mc->device_support & IPMI_DEVID_SEL_DEVICE)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return VMC_DEVICE_NOT_SUPPORT;
+	}
+
+	if (check_msg_length(msg, 6, rdata, rdata_len))
+		return VMC_INVALID_MSG_LEN;
+
+	if (mc->sel.flags & IPMI_SEL_SUPPORTS_RESERVE) {
+		uint16_t reservation = ipmi_get_uint16(msg->data + 0);
+
+		if ((reservation != 0)
+		   && (reservation != mc->sel.reservation)) {
+			rdata[0] = IPMI_INVALID_RESERVATION_CC;
+			*rdata_len = 1;
+			return VMC_INVALID_RESERVATION;
+		}
+	}
+
+	record_id = ipmi_get_uint16(msg->data + 2);
+	offset = msg->data[4];
+	count = msg->data[5];
+
+	if (offset >= 16) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return VMC_INVALID_DATA_FIELD;
+	}
+
+	down(&mc->sel.sem);
+
+#ifdef CONFIG_IPMI_VMC_ENABLE_PMEM
+	int get_last_sel = 0, ret;
+	struct pmem_handle *hdl =
+		(struct pmem_handle *)region_read_handle[index];
+	int log_size = sel_region[index].fixed_size;
+	char buffer[log_size];
+	int log_num;
+
+	log_num = atomic_read(&mc->sel.count) % mc->sel.max_count;
+	if ((log_num == 0) && (atomic_read(&mc->sel.count) > 0))
+		log_num = mc->sel.max_count;
+
+	/*
+	 * The last SEL could ALWAYS be fetched, however, if the record_id
+	 * specified by user is greater than that of the last SEL, nothing
+	 * would be fetched, and user would get completion code of "cb".
+	 */
+	if ((record_id == 0xffff) || (record_id == log_num - 1)) {
+		hdl->offset = log_size *
+			((atomic_read(&mc->sel.count) - 1) % mc->sel.max_count);
+		get_last_sel = 1;
+	} else
+		hdl->offset = record_id * log_size;
+
+	ret = pmem_read_region_per_cpu(region_read_handle[index],
+				buffer, log_size,
+				0); /* PERPROC disabled for vMC region */
+	if (ret <= 0)
+		entry = NULL;
+	else
+		entry = (vMC_ipmi_sel_record_t *)buffer;
+#else
+	if (list_empty(&(mc->sel.entries))) {
+		up(&mc->sel.sem);
+		handle_error_response(IPMI_NOT_PRESENT_CC, rdata, rdata_len);
+		return VMC_SEL_LIST_EMPTY;
+	}
+
+	if (record_id == 0) {
+		entry =
+		    list_entry(mc->sel.entries.next, vMC_ipmi_sel_record_t,
+			       list);
+	} else if (record_id == 0xffff) {
+		entry =
+		    list_entry(mc->sel.entries.prev, vMC_ipmi_sel_record_t,
+			       list);
+	} else {
+		entry = find_sel_event_by_recid(mc, record_id, NULL);
+	}
+#endif
+
+	if (entry == NULL) {
+		up(&mc->sel.sem);
+		handle_error_response(IPMI_NOT_PRESENT_CC, rdata, rdata_len);
+		return VMC_NOT_PRESENT;
+	}
+
+	rdata[0] = 0;
+	if ((offset + count) > 16)
+		count = 16 - offset;
+	p = (void *) entry;
+	memcpy(rdata + 3, p + offset, count);
+	/* The recid must be converted from native to IPMI endianness ! */
+	/* (It's the only member of vMC_ipmi_sel_record_s that is  */
+	/* stored native and thus needs conversion) */
+	recid_tmp = *(uint16_t *) (rdata + 3);
+	ipmi_set_uint16(rdata + 3, recid_tmp);
+#ifdef CONFIG_IPMI_VMC_ENABLE_PMEM
+	/* If we retrieve the last one, bytes 2:3 ("Next SEL */
+	/* Record ID") must be ffff; otherwise, bytes 2:3    */
+	/* should be set to the record ID being retrieved +1 */
+	if (get_last_sel == 0) {
+		record_id++;
+		ipmi_set_uint16(rdata + 1, record_id);
+	} else {
+		rdata[1] = 0xff;
+		rdata[2] = 0xff;
+	}
+
+#else
+	if (entry->list.next != &(mc->sel.entries)) {
+		entry =
+		    list_entry(entry->list.next, vMC_ipmi_sel_record_t, list);
+		ipmi_set_uint16(rdata + 1, entry->recid);
+	} else {
+		rdata[1] = 0xff;
+		rdata[2] = 0xff;
+	}
+#endif
+
+	up(&mc->sel.sem);
+	*rdata_len = count + 3;
+	return VMC_NO_ERROR;
+}
+
+static void handle_add_sel_entry(lmc_data_t *mc, ipmi_msg_t *msg,
+				 unsigned char *rdata, unsigned int *rdata_len)
+{
+	int rv;
+	unsigned int r;
+
+	if (!mc->sel.enabled) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (!(mc->device_support & IPMI_DEVID_SEL_DEVICE)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	if (check_msg_length(msg, 16, rdata, rdata_len))
+		return;
+
+	/* assume fail... */
+	*rdata_len = 1;
+
+	rv = _ipmi_mc_add_to_sel(mc, msg->data[2], msg->data + 3, &r);
+
+	if (rv == VMC_ENOSPC) {
+		rdata[0] = IPMI_OUT_OF_SPACE_CC;
+	} else if (rv) {
+		rdata[0] = IPMI_UNKNOWN_ERR_CC;
+	} else {
+		rdata[0] = 0;
+		ipmi_set_uint16(rdata + 1, r);
+		*rdata_len = 3;
+	}
+
+	return;
+}
+
+#ifndef CONFIG_IPMI_VMC_ENABLE_PMEM
+static void handle_delete_sel_entry(lmc_data_t *mc, ipmi_msg_t *msg,
+				    unsigned char *rdata,
+				    unsigned int *rdata_len)
+{
+	uint16_t record_id;
+	vMC_ipmi_sel_record_t *entry;
+
+	if (!mc->sel.enabled) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (!(mc->device_support & IPMI_DEVID_SEL_DEVICE)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (!(mc->sel.flags & IPMI_SEL_SUPPORTS_DELETE)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (check_msg_length(msg, 4, rdata, rdata_len))
+		return;
+
+	if (mc->sel.flags & IPMI_SEL_SUPPORTS_RESERVE) {
+		uint16_t reservation = ipmi_get_uint16(msg->data + 0);
+
+		if ((reservation != 0)
+		    && (reservation != mc->sel.reservation)) {
+			rdata[0] = IPMI_INVALID_RESERVATION_CC;
+			*rdata_len = 1;
+			return;
+		}
+	}
+
+	record_id = ipmi_get_uint16(msg->data + 2);
+
+	if (list_empty(&(mc->sel.entries))) {
+		handle_error_response(IPMI_NOT_PRESENT_CC, rdata, rdata_len);
+		return;
+	}
+
+	down(&mc->sel.sem);
+	spin_lock(&mc->sel.lock);
+	if (record_id == 0) {
+		entry =
+		    list_entry(mc->sel.entries.next, vMC_ipmi_sel_record_t,
+			       list);
+		spin_unlock(&mc->sel.lock);
+	} else if (record_id == 0xffff) {
+		list_for_each_entry_reverse(entry, &(mc->sel.entries), list) {
+			break;
+		}
+		spin_unlock(&mc->sel.lock);
+	} else {
+		spin_unlock(&mc->sel.lock);
+		entry = find_sel_event_by_recid(mc, record_id, NULL);
+	}
+
+	if (!entry) {
+		up(&mc->sel.sem);
+		handle_error_response(IPMI_NOT_PRESENT_CC, rdata, rdata_len);
+		return;
+	}
+
+	spin_lock(&mc->sel.lock);
+	list_del(&entry->list);
+	spin_unlock(&mc->sel.lock);
+	up(&mc->sel.sem);
+
+	rdata[0] = 0;
+	ipmi_set_uint16(rdata + 1, entry->recid);
+	*rdata_len = 3;
+
+	vMC_free_sel_record(entry);
+}
+#endif
+
+static void handle_clear_sel(lmc_data_t *mc,
+		 ipmi_msg_t *msg,
+		 unsigned char *rdata, unsigned int *rdata_len)
+{
+	unsigned char op;
+	struct timeval t;
+
+	if (!mc->sel.enabled) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (!(mc->device_support & IPMI_DEVID_SEL_DEVICE)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	if (check_msg_length(msg, 6, rdata, rdata_len))
+		return;
+
+	if (mc->sel.flags & IPMI_SEL_SUPPORTS_RESERVE) {
+		uint16_t reservation = ipmi_get_uint16(msg->data + 0);
+
+		if ((reservation != 0)
+		    && (reservation != mc->sel.reservation)) {
+			rdata[0] = IPMI_INVALID_RESERVATION_CC;
+			*rdata_len = 1;
+			return;
+		}
+	}
+
+	if ((msg->data[2] != 'C')
+	    || (msg->data[3] != 'L')
+	    || (msg->data[4] != 'R')) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	op = msg->data[5];
+	if ((op != 0) && (op != 0xaa)) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	rdata[1] = 1;
+	if (op == 0) {
+		down(&mc->sel.sem);
+		clear_sel(mc);
+		up(&mc->sel.sem);
+	}
+
+	do_gettimeofday(&t);
+	mc->sel.last_erase_time = t.tv_sec;
+
+	rdata[0] = 0;
+	*rdata_len = 2;
+}
+
+static void handle_get_sel_time(lmc_data_t *mc, unsigned char *rdata,
+				unsigned int *rdata_len)
+{
+	if (!mc->sel.enabled) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (!(mc->device_support & IPMI_DEVID_SEL_DEVICE)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	rdata[0] = 0;
+	ipmi_set_uint32(rdata + 1, mc->sel.time_offset);
+	*rdata_len = 5;
+}
+
+static void handle_set_sel_time(lmc_data_t *mc, ipmi_msg_t *msg,
+				unsigned char *rdata, unsigned int *rdata_len)
+{
+	if (!mc->sel.enabled) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (!(mc->device_support & IPMI_DEVID_SEL_DEVICE)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (check_msg_length(msg, 4, rdata, rdata_len))
+		return;
+
+	mc->sel.time_offset = ipmi_get_uint32(msg->data);
+
+	handle_error_response(0x0, rdata, rdata_len);
+}
+
+/*
+ * SDR Implementation
+ */
+
+#define IPMI_SDR_GET_MODAL(v)   (((v) >> 5) & 0x3)
+#define IPMI_SDR_MODAL_UNSPECIFIED	0
+#define IPMI_SDR_NON_MODAL_ONLY		1
+#define IPMI_SDR_MODAL_ONLY		2
+#define IPMI_SDR_MODAL_BOTH		3
+#define IPMI_SDR_DELETE_SDR_SUPPORTED			(1 << 3)
+#define IPMI_SDR_PARTIAL_ADD_SDR_SUPPORTED		(1 << 2)
+#define IPMI_SDR_RESERVE_SDR_SUPPORTED			(1 << 1)
+#define IPMI_SDR_GET_SDR_ALLOC_INFO_SDR_SUPPORTED	(1 << 0)
+
+#define VMC_NEW_LEAK_PARADIGM
+#define MAX_RATE_BASED_SENSORS  64
+#define LEAK_RATE 1		/* second */
+static sensor_t *rate_based_sensors[MAX_RATE_BASED_SENSORS];
+static atomic_t rate_based_sensor_count = ATOMIC_INIT(0);
+static struct timer_list sensor_timer;
+
+/*
+ * SDR Utility Functions
+ */
+
+static vMC_ipmi_sdr_t *find_sdr_by_recid(lmc_data_t *mc, sdrs_t *sdrs,
+					 uint16_t record_id, ipmi_msg_t *msg,
+					 unsigned char *rdata,
+					 unsigned int *rdata_len)
+{
+	vMC_ipmi_sdr_t *entry, *n;
+
+	spin_lock(&sdrs->lock);
+	if (list_empty(&(sdrs->sdrs))) {
+		spin_unlock(&sdrs->lock);
+		if (rdata_len) {
+			handle_error_response(IPMI_NOT_PRESENT_CC, rdata,
+					      rdata_len);
+		}
+		return NULL;
+	}
+
+	if (record_id == 0) {
+		entry = list_entry(sdrs->sdrs.next, vMC_ipmi_sdr_t, list);
+	} else if (record_id == 0xffff) {
+		list_for_each_entry_reverse(entry, &(sdrs->sdrs), list) {
+			break;
+		}
+	} else {
+		list_for_each_entry_safe(entry, n, &(sdrs->sdrs), list) {
+			if (record_id == entry->sdr_hdr.record_id)
+				goto done;
+		}
+		spin_unlock(&sdrs->lock);
+		if (rdata_len) {
+			handle_error_response(IPMI_NOT_PRESENT_CC, rdata,
+					      rdata_len);
+		}
+		return NULL;
+	}
+
+done:
+	spin_unlock(&sdrs->lock);
+	return entry;
+}
+
+static uint16_t new_sdr_recid(lmc_data_t *mc, sdrs_t *sdrs)
+{
+	uint16_t start_recid, new_recid;
+
+	spin_lock(&sdrs->lock);
+	start_recid = sdrs->next_entry++;
+	spin_unlock(&sdrs->lock);
+	new_recid = start_recid;
+	while (find_sdr_by_recid(mc, sdrs, new_recid, NULL, NULL, NULL)) {
+		spin_lock(&sdrs->lock);
+		new_recid = sdrs->next_entry++;
+		if (sdrs->next_entry == 0xffff)
+			sdrs->next_entry = 1;
+		spin_unlock(&sdrs->lock);
+		if (new_recid == start_recid)
+			return 0;
+	}
+
+	return new_recid;
+}
+
+static void add_sdr_entry(lmc_data_t *mc, sdrs_t *sdrs,
+			  vMC_ipmi_sdr_t *entry)
+{
+	struct timeval t;
+
+	spin_lock(&sdrs->lock);
+	list_add_tail(&entry->list, &sdrs->sdrs);
+	spin_unlock(&sdrs->lock);
+
+	do_gettimeofday(&t);
+	sdrs->last_add_time = t.tv_sec + mc->main_sdrs.time_offset;
+	spin_lock(&sdrs->lock);
+	sdrs->sdr_count++;
+	spin_unlock(&sdrs->lock);
+}
+
+static void free_sdr(vMC_ipmi_sdr_t *sdr, spinlock_t *lock)
+{
+#define GETSELALL_RPLY_LEN 10
+	if (sdr == NULL)
+		return;
+
+	if (sdr->sdr_hdr.record_type == IPMI_SDR_FULL_TYPE) {
+		struct timeval t;
+
+		do_gettimeofday(&t);
+		/* Free sdr alloc'd in ipmi_mc_add_device_sdr */
+		vmc_kfree(sdr->mc->sensors[sdr->sdr_body.sdr_full.sensor_owner_lun][sdr->sdr_body.sdr_full.sensor_number]);
+		sdr->mc->sensors[sdr->sdr_body.sdr_full.sensor_owner_lun][sdr->sdr_body.sdr_full.sensor_number] = NULL;
+		sdr->mc->sensor_population_change_time = t.tv_sec + sdr->mc->main_sdrs.time_offset;
+		sdr->mc->num_sensors_per_lun[sdr->sdr_body.sdr_full.sensor_owner_lun]--;
+		if (!sdr->mc->num_sensors_per_lun[sdr->sdr_body.sdr_full.sensor_owner_lun])
+			sdr->mc->lun_has_sensors[sdr->sdr_body.sdr_full.sensor_owner_lun] = 0;
+	}
+
+	spin_lock(lock);
+	list_del(&sdr->list);
+	spin_unlock(lock);
+	/* Free sdr alloc'd in vMC_alloc_sdr_record */
+	vmc_kfree(sdr);
+}
+
+static void clear_sdr(struct list_head *sdrhead, spinlock_t *lock)
+{
+	vMC_ipmi_sdr_t *entry, *n;
+
+	if (list_empty(sdrhead))
+		return;
+
+	list_for_each_entry_safe(entry, n, sdrhead, list) {
+		free_sdr(entry, lock);
+	}
+
+	if (vmcDebug)
+		printk("vMC Sensor Data Repository cleared.\n");
+}
+
+/*  do_event  UNUSED BY ALL EXCEPT sensor_set_bit, which is
+ *            not used because we don't support discrete currently........
+ */
+static void
+do_event(sensor_t *sensor,
+	 unsigned char direction, vMC_ipmi_sel_record_t *selr)
+{
+	lmc_data_t *dest_mc;
+	struct timeval tv;
+
+	if ((sensor->mc->event_receiver == 0)
+	    || (sensor->sdr->sdr_body.sdr_full.sens_capable_event_msg_control ==
+		NO_EVENTS_FROM_SENSOR)
+	    || (!sensor->sdr->sdr_body.sdr_full.event_generation_enabled)) {
+		vMC_free_sel_record(selr);
+		return;
+	}
+	if (ipmi_emu_get_mc_by_addr(sensor->mc->event_receiver, &dest_mc)) {
+		vMC_free_sel_record(selr);
+		return;
+	}
+
+	selr->type = IPMI_SEL_SYS_TYPE;
+	do_gettimeofday(&tv);
+	selr->timestamp = (unsigned long)tv.tv_sec;
+	selr->id_type = 0;
+	selr->id_ipmb = sensor->mc->ipmb >> 1;
+	selr->ipmb_lun = sensor->sdr->sdr_body.sdr_full.sensor_owner_lun;
+	selr->res = 0;
+	selr->evmrev = IPMI_EM_V15_VERSION;
+	selr->sensortype = sensor->sdr->sdr_body.sdr_full.sensor_type;
+	selr->sensornum = sensor->sdr->sdr_body.sdr_full.sensor_number;
+	selr->event_dir = direction & 0x01;
+	selr->event_type =
+	    sensor->sdr->sdr_body.sdr_full.event_reading_type_code & 0x7f;
+
+#ifdef CONFIG_IPMI_VMC_ENABLE_IPMB
+	if (sensor->sdr->sdr_body.sdr_full.bmc_enable) {
+		/* Send event southbound */
+		bmc_send_event_msg(selr);
+		sensor->sdr->sdr_body.sdr_full.bmc_enable = 0;
+	}
+#endif
+
+	if (selr->recid == 0) {
+		uint16_t recid = ipmi_assign_recid(selr);
+		if (recid == 0) {/* SEL has been freed*/
+			printk(KERN_ERR "SEL not enabled, event dropped!\n");
+			return;
+		}
+		selr->recid = recid;
+	}
+
+	/* write sel to PMEM, if configured */
+	write_sel_to_pmem(selr);
+	/* send SEL northbound, and store on linked list if PMEM */
+	/* not configured (frees SEL also, if PMEM configured)   */
+	ipmi_add_to_sel_tlet(selr);
+}
+
+/*  gen_event  Format an Event Record for southbound and northbound.
+ *             Store the record in PMEM if enabled.  Send the record
+ *             southbound.  Send the record to the tasklet to be sent
+ *             northbound (if PMEM is not enabled, the tasklet also
+ *             stores the record on a linked list).  Finally, run
+ *             any containment handlers that have been registered.
+ *
+ *             Returns VMC_NO_ERROR, VMC_INVALID_MC, VMC_ENOMEM, or VMC_ENOSPC.
+ */
+
+static int gen_event(vMC_ipmi_sel_record_t *selr, unsigned char direction,
+		     sensor_t *sensor, int offset)
+{
+	int rc = VMC_NO_ERROR;
+	struct timeval t;
+	vMC_ipmi_sel_record_t southbound_selr;
+	uint16_t recid;
+
+#define EVENT_DATA_NONOEM_CODE 1	/* see IPMI spec 1.5 section 23.7 */
+#define EVENT_DATA_OEM_CODE 2
+#define EVENT_DATA_NONOEM_MASK (EVENT_DATA_NONOEM_CODE<<6 | \
+					EVENT_DATA_NONOEM_CODE<<4)
+
+	do_gettimeofday(&t);
+
+	if ((sensor->mc->event_receiver == 0)
+	    || (sensor->sdr->sdr_body.sdr_full.sens_capable_event_msg_control ==
+		NO_EVENTS_FROM_SENSOR)
+	    || (!sensor->sdr->sdr_body.sdr_full.event_generation_enabled)) {
+		vMC_free_sel_record(selr);
+		return VMC_NO_ERROR;
+	}
+
+	if (selr == NULL) {
+		selr = vMC_alloc_sel_record(SEL_MAX_EXTENDED_DATA_LENGTH,
+					    sensor->mc->event_receiver, &rc);
+		if (selr == NULL) {
+			printk(KERN_ERR
+			       "SEL out of memory, dropping events.\n");
+			return rc;
+		}
+		/* Indicate bytes 1/2 contain trigger reading */
+		/* and threshold, and put offset in bits 0-3. */
+		/* Discrete sensors NOT currently supported.  */
+		selr->sel_event_data.event_data[0] =
+		    EVENT_DATA_NONOEM_MASK | offset;
+	}
+
+	selr->type = IPMI_SEL_SYS_TYPE;
+	selr->timestamp = (unsigned long)t.tv_sec;
+	selr->id_type = 0;
+	selr->id_ipmb = sensor->mc->ipmb >> 1;
+	selr->ipmb_lun = sensor->sdr->sdr_body.sdr_full.sensor_owner_lun;
+	selr->res = 0;
+	selr->evmrev = IPMI_EM_V15_VERSION;
+	selr->sensortype = sensor->sdr->sdr_body.sdr_full.sensor_type;
+	selr->sensornum = sensor->sdr->sdr_body.sdr_full.sensor_number;
+	selr->event_dir = direction & 0x01;
+	selr->event_type =
+	    sensor->sdr->sdr_body.sdr_full.event_reading_type_code & 0x7f;
+
+	/* Make copy of northbound because south gets different record */
+	/* (no need to copy extended data, southbound doesn't get it)  */
+	memcpy(&southbound_selr, selr, sizeof(vMC_ipmi_sel_record_t));
+
+	/* If event_data[0] demands, fill in trigger reading and   */
+	/* threshold in 2nd/3rd bytes.  HACK HACK: For southbound  */
+	/* only, if event_data[0] doesn't indicate 'OEM', put      */
+	/* offset in bits 0-3.         NOTE- Discrete sensors NOT  */
+	/*                                currently supported.     */
+	selr->sel_event_data.event_data[0] &= 0xf0;
+	selr->sel_event_data.event_data[0] |= offset;
+	if (((selr->sel_event_data.event_data[0] & 0xc0) >> 6) ==
+	    EVENT_DATA_NONOEM_CODE) {
+		selr->sel_event_data.event_data[1] = sensor->value;
+	}
+	if (((selr->sel_event_data.event_data[0] & 0x30) >> 4) ==
+	    EVENT_DATA_NONOEM_CODE) {
+		selr->sel_event_data.event_data[2] =
+		    sensor->sdr->sdr_body.sdr_full.thresholds[5 - (offset / 2)];
+	}
+
+	if (((southbound_selr.sel_event_data.event_data[0] & 0xc0) >> 6) ==
+	    EVENT_DATA_NONOEM_CODE) {
+		southbound_selr.sel_event_data.event_data[1] = sensor->value;
+	}
+	if (((southbound_selr.sel_event_data.event_data[0] & 0x30) >> 4) ==
+	    EVENT_DATA_NONOEM_CODE) {
+		southbound_selr.sel_event_data.event_data[2] =
+		    sensor->sdr->sdr_body.sdr_full.thresholds[5 - (offset / 2)];
+	}
+	/* FIXME: HACK !  HACK !  WARNING ! See above comment. */
+	if (((southbound_selr.sel_event_data.event_data[0] & 0xc0) >> 6) !=
+	    EVENT_DATA_OEM_CODE
+	    || ((southbound_selr.sel_event_data.event_data[0] & 0x30) >> 4) !=
+	    EVENT_DATA_OEM_CODE) {
+		southbound_selr.sel_event_data.event_data[0] &= 0xf0;
+		southbound_selr.sel_event_data.event_data[0] |= offset;
+	}
+	/* end hack */
+
+	spin_lock(&sensor->mc->sel.lock);
+
+	/* This is used to be done in the tasklet */
+	if (atomic_read(&sensor->mc->sel.count) == 0)
+		selr->recid = 0;
+
+	sensor->mc->sel.last_add_time = t.tv_sec;
+
+	if (selr->type < SEL_RECORD_TYPE_NONTIMESTAMP) {
+		ipmi_set_uint32(((void *) selr) + 3,
+				sensor->mc->sel.last_add_time);	/* dest->mc? */
+		ipmi_set_uint32(((void *) &southbound_selr) + 3,
+				sensor->mc->sel.last_add_time);	/* dest->mc? */
+	}
+
+	spin_unlock(&sensor->mc->sel.lock);
+
+	if (selr->recid == 0) {
+		/* This code will drop the event record if there is an error,
+		 * and assign a SEL record id. Events that are generated from
+		 * places like crossing a threshold are running on a workqueue
+		 * so there is no time constraint, and a record id will already
+		 * be assigned.
+		 */
+		recid = ipmi_assign_recid(selr);
+		if (recid == 0) {
+			/* can't i still send south or do something if no recid
+			 * SEL full, or not enabled:
+			 */
+			return VMC_ENOSPC;
+		}
+		selr->recid = recid;
+	}
+	/* bump sel_count now... */
+	/* atomic_inc(&sensor->mc->sel.count); */
+
+	/* Write record to PMEM if available; will be kfreed by tasklet later */
+	write_sel_to_pmem(selr);
+
+	/* Send southbound as req'd */
+#ifdef CONFIG_IPMI_VMC_ENABLE_IPMB
+	if (sensor->sdr->sdr_body.sdr_full.bmc_enable) {
+		bmc_send_event_msg(&southbound_selr);
+		sensor->sdr->sdr_body.sdr_full.bmc_enable = 0;
+	}
+#endif
+
+	/* Send to tasklet for northbound processing (and storing
+	   on the SEL linked list, if CONFIG_IPMI_VMC_ENABLE_PMEM
+	   is not defined) */
+	ipmi_add_to_sel_tlet(selr);
+
+	return rc;
+}
+
+#ifdef CONFIG_PORT_CONTAINMENT
+static void run_port_containment(unsigned char direction, sensor_t *sensor,
+				 int offset)
+{
+	if ((sensor->sdr->sdr_body.sdr_full.containment_enable) &&
+	    (direction == IPMI_ASSERTION) &&
+	    ((offset == SEVERITY_UPPER_NON_RECOVERABLE_GOING_HIGH) ||
+	     (offset == SEVERITY_LOWER_NON_RECOVERABLE_GOING_HIGH))) {
+		contain_ports("Fault Detected");
+	}
+}
+#else
+#define run_port_containment(a, b, c) do { } while (0)
+#endif
+
+static void run_containment(unsigned char direction, sensor_t *sensor,
+		int offset)
+{
+	/* Now that the SEL is safely stored in PMEM, run any containment
+	   hndlr */
+	if ((sensor->sdr->sdr_body.sdr_full.containment_enable) &&
+	    (vMC_containment_handler[offset] != NULL)
+	    && direction == IPMI_ASSERTION) {
+		printk(KERN_INFO "run_containment: vmc containment handler\n");
+		(vMC_containment_handler[offset]) ();
+	} else {
+		printk(KERN_INFO
+		       "run_containment: No vmc containment handler\n");
+	}
+}
+
+static int check_thresholds(sensor_t *sensor, int suppressEvent,
+			    vMC_ipmi_sel_record_t *selr)
+{
+	int rc = VMC_NO_ERROR, i;
+	int bits_to_set = 0;
+	int bits_to_clear = 0;
+	int event_sent = 0;
+	int bits_to_set_southbound = 0;
+	int bits_to_clear_southbound = 0;
+	int southbound_bitmask = 0;
+	uint16_t bitmask;
+	unsigned char tmp_selr[sizeof(vMC_ipmi_sel_record_t) +
+			       SEL_MAX_EXTENDED_DATA_LENGTH];
+	int tmp_ext_len = 0;
+
+	for (i = 0; i < 3; i++) {
+		if (sensor->sdr->sdr_body.sdr_full.set_thres_mask & (1 << i)) {
+			if (sensor->value <= sensor->thresholds[5 - i])
+				bits_to_set |= (1 << i * 2);
+			else if ((sensor->direction == SENSOR_INCREASING) &&
+				 ((sensor->value -
+				   sensor->sdr->sdr_body.sdr_full.
+				   negative_hysteresis) >
+				  sensor->thresholds[5 - i]))
+				bits_to_clear |= (1 << i * 2);
+		}
+	}
+
+	for (i = 0; i < 3; i++) {
+		if (sensor->sdr->sdr_body.sdr_full.set_thres_mask & (1 << i)) {
+			if (sensor->value > sensor->thresholds[5 - i])
+				bits_to_set |= (1 << ((i * 2) + 1));
+			else if ((sensor->direction == SENSOR_DECREASING) &&
+				 ((sensor->value +
+				   sensor->sdr->sdr_body.sdr_full.
+				   positive_hysteresis) <=
+				  sensor->thresholds[5 - i]))
+				bits_to_clear |= (1 << ((i * 2) + 1));
+		}
+	}
+
+	for (i = 3; i < 6; i++) {
+		if (sensor->sdr->sdr_body.sdr_full.set_thres_mask & (1 << i)) {
+			if (sensor->value >= sensor->thresholds[5 - i])
+				bits_to_set |= (1 << ((i * 2) + 1));
+			else if ((sensor->direction == SENSOR_DECREASING) &&
+				 ((sensor->value +
+				   sensor->sdr->sdr_body.sdr_full.
+				   positive_hysteresis) <
+				  sensor->thresholds[5 - i]))
+				bits_to_clear |= (1 << ((i * 2) + 1));
+		}
+	}
+
+	for (i = 3; i < 6; i++) {
+		if (sensor->sdr->sdr_body.sdr_full.set_thres_mask & (1 << i)) {
+			if (sensor->value < sensor->thresholds[5 - i])
+				bits_to_set |= (1 << (i * 2));
+			else if ((sensor->direction == SENSOR_INCREASING) &&
+				 ((sensor->value -
+				   sensor->sdr->sdr_body.sdr_full.
+				   negative_hysteresis) >=
+				  sensor->thresholds[5 - i]))
+				bits_to_clear |= (1 << (i * 2));
+		}
+	}
+
+	/* We want going-high and going-low events to go    */
+	/* southbound, if the sensor's masks would allow it */
+	southbound_bitmask =
+	    ((sensor->sdr->sdr_body.sdr_full.ipmb_lower_non_critical_enable <<
+	      SEVERITY_LOWER_NON_CRITICAL_GOING_LOW) |
+	     (sensor->sdr->sdr_body.sdr_full.ipmb_lower_non_critical_enable <<
+	      SEVERITY_LOWER_NON_CRITICAL_GOING_HIGH) |
+	     (sensor->sdr->sdr_body.sdr_full.ipmb_lower_critical_enable <<
+	      SEVERITY_LOWER_CRITICAL_GOING_LOW) |
+	     (sensor->sdr->sdr_body.sdr_full.ipmb_lower_critical_enable <<
+	      SEVERITY_LOWER_CRITICAL_GOING_HIGH) |
+	     (sensor->sdr->sdr_body.sdr_full.
+	      ipmb_lower_non_recoverable_enable <<
+	      SEVERITY_LOWER_NON_RECOVERABLE_GOING_LOW) | (sensor->sdr->
+							   sdr_body.sdr_full.
+							   ipmb_lower_non_recoverable_enable
+							   <<
+							   SEVERITY_LOWER_NON_RECOVERABLE_GOING_HIGH)
+	     | (sensor->sdr->sdr_body.sdr_full.
+		ipmb_upper_non_critical_enable <<
+		SEVERITY_UPPER_NON_CRITICAL_GOING_LOW) | (sensor->sdr->sdr_body.
+							  sdr_full.
+							  ipmb_upper_non_critical_enable
+							  <<
+							  SEVERITY_UPPER_NON_CRITICAL_GOING_HIGH)
+	     | (sensor->sdr->sdr_body.sdr_full.
+		ipmb_upper_critical_enable << SEVERITY_UPPER_CRITICAL_GOING_LOW)
+	     | (sensor->sdr->sdr_body.sdr_full.
+		ipmb_upper_critical_enable <<
+		SEVERITY_UPPER_CRITICAL_GOING_HIGH) | (sensor->sdr->sdr_body.
+						       sdr_full.
+						       ipmb_upper_non_recoverable_enable
+						       <<
+						       SEVERITY_UPPER_NON_RECOVERABLE_GOING_LOW)
+	     | (sensor->sdr->sdr_body.sdr_full.
+		ipmb_upper_non_recoverable_enable <<
+		SEVERITY_UPPER_NON_RECOVERABLE_GOING_HIGH));
+
+	bits_to_set_southbound = (bits_to_set & southbound_bitmask);
+	bits_to_clear_southbound = (bits_to_clear & southbound_bitmask);
+
+	/* Generate events "backwards" so non-recoverable go out first */
+	bitmask = 1 << 11;
+	for (i = 11; i >= 0; i--) {
+		if ((bits_to_set & bitmask) && !sensor->event_status[i]) {
+			/* This bit was not set, but we need to set it. */
+			sensor->event_status[i] = 1;
+			if (sensor->sdr->sdr_body.sdr_full.assertion_event_mask & bitmask) {
+				if (!suppressEvent) {
+					if (bits_to_set_southbound & bitmask)
+						sensor->sdr->sdr_body.sdr_full.bmc_enable = 1;
+					else
+						sensor->sdr->sdr_body.sdr_full.bmc_enable = 0;
+					if (!event_sent) {
+						/* Make copy because it will be freed later by tasklet */
+						if (selr) {
+							memcpy(&tmp_selr, selr, sizeof(vMC_ipmi_sel_record_t) + selr->extended_event_length);
+							tmp_ext_len = selr->extended_event_length;
+						}
+						run_port_containment(IPMI_ASSERTION, sensor, i);
+						rc = gen_event(selr, IPMI_ASSERTION, sensor, i);
+						run_containment(IPMI_ASSERTION,	sensor, i);
+						event_sent = 1;
+					} else {
+						if (selr) {
+							/* If we were provided with a SEL, copy */
+							/* it to a new record and send */
+							vMC_ipmi_sel_record_t *selRecord;
+							selRecord = vMC_alloc_sel_record(tmp_ext_len, sensor->mc->event_receiver, &rc);
+							if (selRecord == NULL) {
+								printk(KERN_ERR "SEL out of memory, dropping events.\n");
+								return rc;
+							}
+							memcpy(selRecord, &tmp_selr, sizeof(vMC_ipmi_sel_record_t) + tmp_ext_len);
+							rc = gen_event(selRecord, IPMI_ASSERTION, sensor, i);
+							run_containment(IPMI_ASSERTION, sensor, i);
+						} else {
+							run_port_containment(IPMI_ASSERTION, sensor, i);
+							rc = gen_event(NULL, IPMI_ASSERTION, sensor, i);
+							run_containment(IPMI_ASSERTION, sensor, i);
+						}
+					}
+				}
+			}
+		} else if ((bits_to_clear & bitmask) && sensor->event_status[i]) {
+			/* This bit was not clear, but we need to clear it. */
+			sensor->event_status[i] = 0;
+			if (sensor->sdr->sdr_body.sdr_full.
+			    deassertion_event_mask & bitmask) {
+				if (!suppressEvent) {
+					if (bits_to_clear_southbound & bitmask)
+						sensor->sdr->sdr_body.sdr_full.bmc_enable = 1;
+					else
+						sensor->sdr->sdr_body.sdr_full.bmc_enable = 0;
+
+					if (!event_sent) {
+						if (selr) {
+							memcpy(&tmp_selr, selr, sizeof(vMC_ipmi_sel_record_t) + selr->extended_event_length);
+							tmp_ext_len = selr->extended_event_length;
+						}
+						rc = gen_event(selr, IPMI_DEASSERTION, sensor, i);
+						run_containment(IPMI_DEASSERTION, sensor, i);
+						event_sent = 1;
+					} else {
+						if (selr) {
+							/* If we were provided with a SEL, copy */
+							/* it to a new record and send */
+							vMC_ipmi_sel_record_t *selRecord;
+							selRecord = vMC_alloc_sel_record(tmp_ext_len, sensor->mc->event_receiver, &rc);
+							if (selRecord == NULL) {
+								printk(KERN_ERR "SEL out of memory, dropping events\n");
+								return rc;
+							}
+							memcpy(selRecord, &tmp_selr, sizeof(vMC_ipmi_sel_record_t) + tmp_ext_len);
+							rc = gen_event(selRecord, IPMI_DEASSERTION, sensor, i);
+							run_containment(IPMI_DEASSERTION, sensor, i);
+						} else {
+							rc = gen_event(NULL, IPMI_DEASSERTION, sensor, i);
+							run_containment(IPMI_DEASSERTION, sensor, i);
+						}
+					}
+				}
+			}
+		}
+		bitmask >>= 1;
+	}
+	if (!event_sent)
+		vMC_free_sel_record(selr);
+	return rc;
+}
+
+int ipmi_mc_add_main_sdr(vMC_ipmi_sdr_t *sdr)
+{
+	if (sdr == NULL)
+		return VMC_NO_ERROR;
+
+	if (sdr->sdr_hdr.record_type == IPMI_SDR_FULL_TYPE)
+		return VMC_INVALID_RECORD_TYPE;
+	sdr->sdr_hdr.record_id = new_sdr_recid(sdr->mc, &sdr->mc->main_sdrs);
+
+	add_sdr_entry(sdr->mc, &sdr->mc->main_sdrs, sdr);
+
+	return VMC_NO_ERROR;
+}
+
+int internal_ipmi_mc_sensor_dec_value(sensor_t *sensor,
+				      unsigned char value,
+				      vMC_ipmi_sel_record_t *vMC_sel_record);
+
+/* If high_res_timers avail., and old leaking regime wanted:
+ * (but leave some of the old code around for now just in case)
+ */
+#if defined(CONFIG_HIGH_RES_TIMERS) && !defined(VMC_NEW_LEAK_PARADIGM)
+
+static void check_rate(sensor_t *s, sensor_rate_t *newts)
+{
+	sensor_rate_t *entry, *n;
+	unsigned long long ns1, now;
+	unsigned int decrease_amount = 0;
+
+	if (NULL == s)
+		return;
+	if (newts == NULL) {
+		now =
+		    (((unsigned long long)
+		      arch_cycle_to_nsec(arch_cycles_per_jiffy)) *
+		     ((unsigned long long) jiffies)) +
+		    (unsigned long long) get_arch_cycles(jiffies);
+	} else {
+		now = newts->nsec;
+	}
+
+	switch (s->sdr->sdr_body.sdr_full.sensor_units_1_rate_unit) {
+	case RATE_US:
+		ns1 = 1000LL;
+		break;
+	case RATE_MS:
+		ns1 = 1000000LL;
+		break;
+	case RATE_S:
+		ns1 = 1000000000LL;
+		break;
+	default:
+		ns1 = 1000000LL;
+		printk(KERN_INFO "Bad rate!\n");	/* should not happen */
+		break;
+	}
+
+	if (!spin_trylock(&(s->lock)))
+		return;
+
+	list_for_each_entry_safe(entry, n, &(s->timestamps), link) {
+#ifdef VMC_NEW_LEAK_PARADIGM
+		/* should only be one timestamp ! */
+		/* Do a trick similar to time_after, but for long long, to handle wrapping */
+		if (s->cvalue > 0
+		    &&
+		    (((signed long long) now -
+		      (signed long long) (entry->nsec + ns1)) >= 0)) {
+			decrease_amount = 1;
+			entry->nsec = now;
+		}
+#else
+		if (((signed long long) now -
+		     (signed long long) (entry->nsec + ns1)) >= 0) {
+			decrease_amount++;
+			list_del(&entry->link);
+			vmc_kfree(entry);
+		}
+#endif
+	}
+
+	if (decrease_amount)
+		internal_ipmi_mc_sensor_dec_value(s, decrease_amount, NULL);
+	spin_unlock(&(s->lock));
+}
+
+#else /* no CONFIG_HIGH_RES_TIMERS, or VMC_NEW_LEAK_PARADIGM */
+
+static void check_rate(sensor_t *s, sensor_rate_t *newts)
+{
+	sensor_rate_t *entry, *n;
+	unsigned long ns1, now;
+	unsigned int decrease_amount = 0;
+
+	if (NULL == s)
+		return;
+	if (newts == NULL)
+		now = jiffies;
+	else
+		now = newts->nsec;
+
+	switch (s->sdr->sdr_body.sdr_full.sensor_units_1_rate_unit) {
+	case RATE_MS:
+		ns1 = HZ / 1000;
+		break;
+	case RATE_S:
+		ns1 = HZ;
+		break;
+	case RATE_MINUTE:
+		ns1 = 60 * HZ;
+		break;
+	case RATE_HOUR:
+		ns1 = 3600 * HZ;
+		break;
+	case RATE_DAY:
+		ns1 = 24 * 3600 * HZ;
+		break;
+	default:
+		ns1 = HZ;
+		printk(KERN_INFO "Bad rate!\n");	/* should not happen */
+		break;
+	}
+
+	if (!spin_trylock(&(s->lock)))
+		return;
+
+	list_for_each_entry_safe(entry, n, &(s->timestamps), link) {
+#ifdef VMC_NEW_LEAK_PARADIGM
+		/* there should only be one timestamp ! */
+		if (s->cvalue > 0
+		    && time_after_eq(now, (unsigned long) entry->nsec + ns1)) {
+			decrease_amount = 1;
+			entry->nsec = now;
+		}
+#else
+		if (time_after_eq(now, entry->nsec + ns1)) {
+			decrease_amount++;
+			list_del(&entry->link);
+			vmc_kfree(entry);
+		}
+#endif
+	}
+
+	if (decrease_amount)
+		internal_ipmi_mc_sensor_dec_value(s, decrease_amount, NULL);
+	spin_unlock(&(s->lock));
+}
+
+#endif	/* CONFIG_HIGH_RES_TIMERS && !VMC_NEW_LEAK_PARADIGM */
+
+static void leak_sensors(unsigned long val)
+{
+	int i;
+
+	for (i = 0; i < MAX_RATE_BASED_SENSORS; i++)
+		check_rate(rate_based_sensors[i], NULL);
+	/* re-init, to fire LEAK_RATE sec from now */
+	sensor_timer.expires = jiffies + (LEAK_RATE * HZ);
+	add_timer(&sensor_timer);
+}
+
+static void add_timestamp(sensor_t *s)
+{
+	sensor_rate_t *sr;
+
+#ifdef VMC_NEW_LEAK_PARADIGM
+	/* need one timestamp only, to hold original time */
+	if (list_empty(&(s->timestamps))) {
+		sr = vmc_kmalloc(sizeof(sensor_rate_t), GFP_ATOMIC);
+		if (sr == NULL)
+			return;
+		sr->nsec = jiffies;
+		list_add_tail(&sr->link, &(s->timestamps));
+	}
+#else
+	sr = vmc_kmalloc(sizeof(sensor_rate_t), GFP_ATOMIC);
+	if (sr == NULL)
+		return;
+
+#ifdef CONFIG_HIGH_RES_TIMERS
+	sr->nsec =
+	    (((unsigned long long) arch_cycle_to_nsec(arch_cycles_per_jiffy)) *
+	     (unsigned long long) jiffies)
+	    + (unsigned long long) get_arch_cycles(jiffies);
+#else
+	sr->nsec = jiffies;
+#endif
+
+	list_add_tail(&sr->link, &(s->timestamps));
+
+	check_rate(s, sr);
+#endif
+}
+
+int ipmi_mc_add_device_sdr(vMC_ipmi_sdr_t *sdr)
+{
+	struct timeval t;
+	sensor_t *sensor = NULL;
+	int i;
+
+	if (sdr == NULL)
+		return VMC_ENOSYS;
+
+	if (vmcDebug) {
+		dump_mem("IPMI sdr add: ", (void *) sdr,
+			 sizeof(vMC_ipmi_sdr_t));
+	}
+
+	if (!(sdr->mc->has_device_sdrs))
+		return VMC_ENOSYS;
+	if (sdr->mc->
+	    sensors[sdr->sdr_body.sdr_full.sensor_owner_lun][sdr->sdr_body.
+							     sdr_full.
+							     sensor_number] !=
+	    NULL) {
+		printk(KERN_INFO "sensor number exists\n");
+		return VMC_INVALID_SENSOR_NUMBER;
+	}
+
+	if (sdr->sdr_hdr.record_type == IPMI_SDR_FULL_TYPE) {
+		if (sdr->sdr_body.sdr_full.sensor_owner_lun >= 4)
+			return VMC_INVALID_LUN;
+		if (sdr->sdr_body.sdr_full.sensor_number >= 255)
+			return VMC_INVALID_SENSOR_NUMBER;
+		if (sdr->sdr_body.sdr_full.sensor_units_1_rate_unit !=
+		    RATE_NONE) {
+#if defined(CONFIG_HIGH_RES_TIMERS) && !defined(VMC_NEW_LEAK_PARADIGM)
+			if ((sdr->sdr_body.sdr_full.sensor_units_1_rate_unit !=
+			     RATE_US)
+			    && (sdr->sdr_body.sdr_full.
+				sensor_units_1_rate_unit != RATE_MS)
+			    && (sdr->sdr_body.sdr_full.
+				sensor_units_1_rate_unit != RATE_S))
+				return VMC_INVALID_RATE_SENSOR;
+#else
+			if ((sdr->sdr_body.sdr_full.sensor_units_1_rate_unit !=
+			     RATE_MS)
+			    && (sdr->sdr_body.sdr_full.
+				sensor_units_1_rate_unit != RATE_S)
+			    && (sdr->sdr_body.sdr_full.
+				sensor_units_1_rate_unit != RATE_MINUTE)
+			    && (sdr->sdr_body.sdr_full.
+				sensor_units_1_rate_unit != RATE_HOUR)
+			    && (sdr->sdr_body.sdr_full.
+				sensor_units_1_rate_unit != RATE_DAY))
+				return VMC_INVALID_RATE_SENSOR;
+#endif				/* defined(CONFIG_HIGH_RES_TIMERS) && !defined(VMC_NEW_LEAK_PARADIGM) */
+
+			if (atomic_read(&rate_based_sensor_count) ==
+			    MAX_RATE_BASED_SENSORS) {
+				return VMC_TOO_MANY_RATE_SENSORS;
+			}
+		}
+
+		sensor = vmc_kmalloc(sizeof(sensor_t), GFP_ATOMIC);
+		if (sensor == NULL)
+			return VMC_ENOMEM;
+		memset(sensor, 0, sizeof(sensor_t));
+		sensor->sdr = sdr;
+		sensor->mc = sdr->mc;
+		sensor->direction = SENSOR_UNCHANGED;
+		sensor->M =
+		    (sdr->sdr_body.sdr_full.M_ms2bits * 256) +
+		    sdr->sdr_body.sdr_full.M_ls8bits;
+		sensor->B =
+		    (sdr->sdr_body.sdr_full.B_ms2bits * 256) +
+		    sdr->sdr_body.sdr_full.B_ls8bits;
+		for (i = 0; i < 6; i++)
+			sensor->thresholds[i] =
+			    ((uint16_t) sdr->sdr_body.sdr_full.thresholds[i] *
+			     sensor->M) + sensor->B;
+		if (sdr->sdr_body.sdr_full.event_reading_type_code ==
+		    IPMI_EVENT_READING_TYPE_THRESHOLD) {
+			if (sdr->sdr_body.sdr_full.nominal_reading_specified)
+				sensor->cvalue =
+				    sdr->sdr_body.sdr_full.nominal_reading;
+			else
+				sensor->cvalue = 0x0;
+			sensor->value =
+			    (sensor->cvalue * sensor->M) + sensor->B;
+			check_thresholds(sensor, 1, NULL);	/* with suppress=1, always return NO_ERROR */
+		}
+		init_MUTEX(&sensor->sem);
+		spin_lock_init(&sensor->lock);
+		INIT_LIST_HEAD(&(sensor->timestamps));
+	}
+
+	sdr->sdr_hdr.record_id = new_sdr_recid(sdr->mc,
+		&sdr->mc->device_sdrs[sdr->sdr_body.sdr_full.sensor_owner_lun]);
+	if (sdr->sdr_hdr.record_id == 0) {
+		if (sensor)
+			vmc_kfree(sensor);
+		return VMC_ENOSPC;
+	}
+
+	do_gettimeofday(&t);
+
+	spin_lock(&
+		  (sdr->mc->
+		   device_sdrs[sdr->sdr_body.sdr_full.sensor_owner_lun].lock));
+	list_add_tail(&(sdr->list),
+		      &(sdr->mc->
+			device_sdrs[sdr->sdr_body.sdr_full.sensor_owner_lun].
+			sdrs));
+
+	sdr->mc->device_sdrs[sdr->sdr_body.sdr_full.sensor_owner_lun].
+	    last_add_time = t.tv_sec + sdr->mc->main_sdrs.time_offset;
+	sdr->mc->device_sdrs[sdr->sdr_body.sdr_full.sensor_owner_lun].
+	    sdr_count++;
+
+	if (sdr->sdr_hdr.record_type == IPMI_SDR_FULL_TYPE) {
+		sdr->mc->sensors[sdr->sdr_body.sdr_full.sensor_owner_lun][sdr->
+									  sdr_body.
+									  sdr_full.
+									  sensor_number]
+		    = sensor;
+		sdr->mc->sensor_population_change_time =
+		    t.tv_sec + sdr->mc->main_sdrs.time_offset;
+		sdr->mc->lun_has_sensors[sdr->sdr_body.sdr_full.
+					 sensor_owner_lun] = 1;
+		sdr->mc->num_sensors_per_lun[sdr->sdr_body.sdr_full.
+					     sensor_owner_lun]++;
+	}
+	sdr->mc->init_lun[sdr->sdr_body.sdr_full.sensor_owner_lun] = 1;
+	spin_unlock(&
+		    (sdr->mc->
+		     device_sdrs[sdr->sdr_body.sdr_full.sensor_owner_lun].
+		     lock));
+
+	if (sdr->sdr_body.sdr_full.sensor_units_1_rate_unit != RATE_NONE) {
+		for (i = 0; rate_based_sensors[i] != NULL; i++)
+			;
+		if (i < MAX_RATE_BASED_SENSORS) {
+			rate_based_sensors[i] = sensor;
+			atomic_inc(&rate_based_sensor_count);
+		} else
+			return VMC_TOO_MANY_RATE_SENSORS;
+
+		if (atomic_read(&rate_based_sensor_count) == 1) {
+			init_timer(&sensor_timer);	/* init the timer structure */
+			sensor_timer.function = leak_sensors;	/* to fire LEAK_RATE sec from now */
+			sensor_timer.expires = jiffies + (LEAK_RATE * HZ);
+			add_timer(&sensor_timer);
+		}
+	}
+
+	return VMC_NO_ERROR;
+}
+
+static sensor_t *ipmi_find_sensor_byid(vMC_ipmi_sensor_ident_t *sensid,
+					int *rc)
+{
+	lmc_data_t *mc;
+	sensor_t *s;
+
+	*rc = ipmi_emu_get_mc_by_addr(sensid->sensor_mc, &mc);
+	if (*rc != VMC_NO_ERROR)
+		return NULL;
+
+	if ((sensid->sensor_lun >= 4)
+	    || (mc->init_lun[sensid->sensor_lun] != 1)) {
+		*rc = VMC_INVALID_LUN;
+		return NULL;
+	}
+
+	if (!mc->sensors[sensid->sensor_lun][sensid->sensor_num]) {
+		*rc = VMC_INVALID_SENSOR_NUMBER;
+		return NULL;
+	}
+
+	s = mc->sensors[sensid->sensor_lun][sensid->sensor_num];
+	spin_lock(&s->lock);
+	if (s->refcount >= 0)
+		s->refcount++;
+	else {
+		*rc = VMC_LOCKED;
+		s = NULL;
+	}
+	spin_unlock(&s->lock);
+	return s;
+}
+
+static sensor_t *ipmi_find_sensor_bynum(unsigned char ipmb, unsigned char lun,
+					unsigned char num, int *rc)
+{
+	vMC_ipmi_sensor_ident_t sensid;
+
+	sensid.sensor_mc = ipmb;
+	sensid.sensor_lun = lun;
+	sensid.sensor_num = num;
+
+	return ipmi_find_sensor_byid(&sensid, rc);
+}
+
+static void ipmi_release_sensor(sensor_t *s)
+{
+	spin_lock(&s->lock);
+	s->refcount--;
+	spin_unlock(&s->lock);
+	wake_up(&emuq);
+}
+
+static int _ipmi_mc_delete_device_sdr(lmc_data_t *mc, sensor_t *s)
+{
+	spin_lock(&s->lock);
+	if (s->deleted) {
+		spin_unlock(&s->lock);
+		ipmi_release_sensor(s);
+		return VMC_NO_ERROR;
+	}
+	s->deleted = 1;
+	if (s->refcount != 1) {
+		DECLARE_WAITQUEUE(wait, current);
+		add_wait_queue(&emuq, &wait);
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		while (s->refcount != 1) {
+			spin_unlock(&s->lock);
+			schedule();
+			spin_lock(&s->lock);
+		}
+		set_current_state(TASK_RUNNING);
+		remove_wait_queue(&emuq, &wait);
+		s->refcount = -1;
+	}
+	spin_unlock(&s->lock);
+
+	free_sdr(s->sdr,
+		 &(mc->device_sdrs[s->sdr->sdr_body.sdr_full.sensor_owner_lun].
+		   lock));
+	return VMC_NO_ERROR;
+}
+
+int ipmi_mc_delete_device_sdr(vMC_ipmi_sensor_ident_t *sensid)
+{
+	sensor_t *s;
+	int rc, i;
+	lmc_data_t *mc;
+	vMC_kapi_cmd_t *cmd;
+
+	rc = ipmi_emu_get_mc_by_addr(sensid->sensor_mc, &mc);
+	if (rc != VMC_NO_ERROR)
+		return VMC_INVALID_MC;
+
+	s = ipmi_find_sensor_byid(sensid, &rc);
+	if (!s)
+		return rc;
+
+/* #ifdef CONFIG_HIGH_RES_TIMERS */
+	if (s->sdr->sdr_body.sdr_full.sensor_units_1_rate_unit != RATE_NONE) {
+		for (i = 0;
+		     (rate_based_sensors[i] != s)
+		     && (i < MAX_RATE_BASED_SENSORS); i++)
+			;
+		if (i < MAX_RATE_BASED_SENSORS) {
+			rate_based_sensors[i] = NULL;
+			atomic_dec(&rate_based_sensor_count);
+		}
+		if (atomic_read(&rate_based_sensor_count) == 0)
+			del_timer_sync(&sensor_timer);
+	}
+/* #endif */
+	cmd = vmc_kmalloc(sizeof(vMC_kapi_cmd_t), GFP_ATOMIC);
+	if (cmd == NULL) {
+		ipmi_release_sensor(s);
+		return VMC_ENOMEM;
+	}
+
+	cmd->cmd = DELETE_DEVICE_SDR;
+	cmd->s = s;
+	cmd->mc = mc;
+	kapicmd(cmd);
+
+	return VMC_NO_ERROR;
+}
+
+int ipmi_mc_add_fru_data(lmc_data_t *mc, unsigned char device_id,
+			 unsigned int length, unsigned char *data,
+			 unsigned int data_len)
+{
+	if (!(mc->device_support & IPMI_DEVID_FRU_INVENTORY_DEV)) {
+		vmc_kfree(data);
+		return ENOSYS;
+	}
+	if (device_id >= 255) {
+		vmc_kfree(data);
+		return EINVAL;
+	}
+	if (data_len > length) {
+		vmc_kfree(data);
+		return EINVAL;
+	}
+	if (mc->frus[device_id].data) {
+		vmc_kfree(mc->frus[device_id].data);
+		mc->frus[device_id].length = 0;
+	}
+
+	mc->frus[device_id].data = data;
+	mc->frus[device_id].length = length;
+	return VMC_NO_ERROR;
+}
+
+/*
+ * IPMI SDR message handling functions.
+ */
+
+static void handle_get_sdr_repository_info(lmc_data_t *mc,
+					    unsigned char *rdata,
+					    unsigned int *rdata_len)
+{
+	unsigned int space;
+
+	if (!(mc->device_support & IPMI_DEVID_SDR_REPOSITORY_DEV)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	rdata[0] = 0x0;
+	rdata[1] = SDR_VER_IPMI15;
+	ipmi_set_uint16(rdata + 2, mc->main_sdrs.sdr_count);
+	space = MAX_SDR_DATA * (MAX_NUM_SDRS - mc->main_sdrs.sdr_count);
+	if (space > 0xfffe)
+		space = 0xfffe;
+	ipmi_set_uint16(rdata + 4, space);
+	ipmi_set_uint32(rdata + 6, mc->main_sdrs.last_add_time);
+	ipmi_set_uint32(rdata + 10, mc->main_sdrs.last_erase_time);
+	rdata[14] = mc->main_sdrs.flags;
+	*rdata_len = 15;
+}
+
+static void handle_get_sdr_repository_alloc_info(lmc_data_t *mc,
+						 unsigned char *rdata,
+						 unsigned int *rdata_len)
+{
+	if (!(mc->device_support & IPMI_DEVID_SDR_REPOSITORY_DEV)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (!(mc->main_sdrs.flags & IPMI_SDR_GET_SDR_ALLOC_INFO_SDR_SUPPORTED)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	rdata[0] = 0;
+	ipmi_set_uint16(rdata + 1, MAX_NUM_SDRS);
+	ipmi_set_uint16(rdata + 3, MAX_SDR_DATA);
+	ipmi_set_uint16(rdata + 5, MAX_NUM_SDRS - mc->main_sdrs.sdr_count);
+	ipmi_set_uint16(rdata + 7, MAX_NUM_SDRS - mc->main_sdrs.sdr_count);
+	rdata[9] = 1;
+	*rdata_len = 10;
+}
+
+static void handle_reserve_sdr_repository(lmc_data_t *mc, unsigned char *rdata,
+					  unsigned int *rdata_len)
+{
+	if (!(mc->device_support & IPMI_DEVID_SDR_REPOSITORY_DEV)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	if (!(mc->main_sdrs.flags & IPMI_SDR_RESERVE_SDR_SUPPORTED)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	mc->main_sdrs.reservation++;
+	if (mc->main_sdrs.reservation == 0)
+		mc->main_sdrs.reservation++;
+
+	rdata[0] = 0;
+	ipmi_set_uint16(rdata + 1, mc->main_sdrs.reservation);
+	*rdata_len = 3;
+
+	return;
+}
+
+static void handle_get_sdr(lmc_data_t *mc, ipmi_msg_t *msg,
+			   unsigned char *rdata, unsigned int *rdata_len)
+{
+	uint16_t record_id;
+	int offset;
+	int count;
+	vMC_ipmi_sdr_t *entry;
+	void *p;
+
+	if (!(mc->device_support & IPMI_DEVID_SDR_REPOSITORY_DEV)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (check_msg_length(msg, 6, rdata, rdata_len))
+		return;
+
+	if (mc->main_sdrs.flags & IPMI_SDR_RESERVE_SDR_SUPPORTED) {
+		uint16_t reservation = ipmi_get_uint16(msg->data + 0);
+
+		if ((reservation != 0)
+		    && (reservation != mc->main_sdrs.reservation)) {
+			rdata[0] = IPMI_INVALID_RESERVATION_CC;
+			*rdata_len = 1;
+			return;
+		}
+	}
+
+	down(&mc->main_sdrs.sem);
+
+	record_id = ipmi_get_uint16(msg->data + 2);
+	offset = msg->data[4];
+	count = msg->data[5];
+
+	entry = find_sdr_by_recid(mc, &mc->main_sdrs, record_id, msg, rdata,
+				  rdata_len);
+	if (entry == NULL) {
+		up(&mc->main_sdrs.sem);
+		return;
+	}
+
+	if (offset >= entry->sdr_hdr.record_length + 5) {
+		up(&mc->main_sdrs.sem);
+		rdata[0] = IPMI_PARAMETER_OUT_OF_RANGE_CC;
+		*rdata_len = 1;
+		return;
+	}
+
+	if ((offset + count) > entry->sdr_hdr.record_length + 5)
+		count = entry->sdr_hdr.record_length - (offset - 5);
+	if (count + 3 > IPMI_MAX_MSG_LENGTH) {
+		/* Too much data to put into response. */
+		up(&mc->main_sdrs.sem);
+		rdata[0] = IPMI_REQUESTED_DATA_LENGTH_EXCEEDED_CC;
+		*rdata_len = 1;
+		return;
+	}
+
+	rdata[0] = 0;
+	p = (void *) entry;
+	memcpy(rdata + 3, p + offset, count);
+	if (entry->list.next != &(mc->main_sdrs.sdrs)) {
+		entry = list_entry(entry->list.next, vMC_ipmi_sdr_t, list);
+		ipmi_set_uint16(rdata + 1, entry->sdr_hdr.record_id);
+	} else {
+		rdata[1] = 0xff;
+		rdata[2] = 0xff;
+	}
+
+	up(&mc->main_sdrs.sem);
+	*rdata_len = count + 3;
+}
+
+static void handle_add_sdr(lmc_data_t *mc, ipmi_msg_t *msg,
+			   unsigned char *rdata, unsigned int *rdata_len)
+{
+	int rc, modal;
+	vMC_ipmi_sdr_t *entry;
+
+	if (!(mc->device_support & IPMI_DEVID_SDR_REPOSITORY_DEV)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	modal = IPMI_SDR_GET_MODAL(mc->main_sdrs.flags);
+	if ((modal == IPMI_SDR_NON_MODAL_ONLY)
+	    && !mc->in_update_mode) {
+		rdata[0] = IPMI_NOT_SUPPORTED_IN_PRESENT_STATE_CC;
+		*rdata_len = 1;
+		return;
+	}
+	if (check_msg_length(msg, 6, rdata, rdata_len))
+		return;
+	if (msg->data_len != msg->data[5] + 6) {
+		rdata[0] = 0x80;	/* Length is invalid. */
+		*rdata_len = 1;
+		return;
+	}
+
+	entry = vMC_alloc_sdr_record(mc->ipmb, msg->data[3], &rc);
+	if (!entry) {
+		handle_error_response(IPMI_OUT_OF_SPACE_CC, rdata, rdata_len);
+		return;
+	}
+
+	entry->sdr_hdr.record_length = msg->data[4];
+	entry->sdr_hdr.record_id = new_sdr_recid(mc, &mc->main_sdrs);
+	memcpy(entry->sdr_body.data, (msg->data) + 5,
+	       entry->sdr_hdr.record_length);
+
+	add_sdr_entry(mc, &mc->main_sdrs, entry);
+
+	rdata[0] = 0;
+	ipmi_set_uint16(rdata + 1, entry->sdr_hdr.record_id);
+	*rdata_len = 3;
+}
+
+static void handle_delete_sdr(lmc_data_t *mc, ipmi_msg_t *msg,
+			      unsigned char *rdata, unsigned int *rdata_len)
+{
+	uint16_t record_id;
+	vMC_ipmi_sdr_t *entry;
+	struct timeval t;
+
+	if (!(mc->device_support & IPMI_DEVID_SDR_REPOSITORY_DEV)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (check_msg_length(msg, 4, rdata, rdata_len))
+		return;
+
+	if (mc->main_sdrs.flags & IPMI_SDR_RESERVE_SDR_SUPPORTED) {
+		uint16_t reservation = ipmi_get_uint16(msg->data + 0);
+
+		if ((reservation != 0)
+		    && (reservation != mc->main_sdrs.reservation)) {
+			rdata[0] = IPMI_INVALID_RESERVATION_CC;
+			*rdata_len = 1;
+			return;
+		}
+	}
+
+	record_id = ipmi_get_uint16(rdata + 2);
+
+	down(&mc->main_sdrs.sem);
+
+	entry = find_sdr_by_recid(mc, &mc->main_sdrs, record_id, msg, rdata,
+				  rdata_len);
+	if (entry == NULL) {
+		up(&mc->main_sdrs.sem);
+		return;
+	}
+
+	spin_lock(&mc->main_sdrs.lock);
+	list_del(&entry->list);
+	spin_unlock(&mc->main_sdrs.lock);
+
+	rdata[0] = 0;
+	ipmi_set_uint16(rdata + 1, entry->sdr_hdr.record_id);
+	*rdata_len = 3;
+
+	free_sdr(entry, &mc->main_sdrs.lock);
+
+	do_gettimeofday(&t);
+	spin_lock(&mc->main_sdrs.lock);
+	mc->main_sdrs.last_erase_time = t.tv_sec + mc->main_sdrs.time_offset;
+	mc->main_sdrs.sdr_count--;
+	spin_unlock(&mc->main_sdrs.lock);
+	up(&mc->main_sdrs.sem);
+}
+
+static void handle_clear_sdr_repository(lmc_data_t *mc, ipmi_msg_t *msg,
+					unsigned char *rdata,
+					unsigned int *rdata_len)
+{
+	struct timeval t;
+	unsigned char op;
+
+	if (!(mc->device_support & IPMI_DEVID_SDR_REPOSITORY_DEV)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (check_msg_length(msg, 6, rdata, rdata_len))
+		return;
+
+	if (mc->main_sdrs.flags & IPMI_SDR_RESERVE_SDR_SUPPORTED) {
+		uint16_t reservation = ipmi_get_uint16(msg->data + 0);
+
+		if ((reservation != 0)
+		    && (reservation != mc->main_sdrs.reservation)) {
+			rdata[0] = IPMI_INVALID_RESERVATION_CC;
+			*rdata_len = 1;
+			return;
+		}
+	}
+
+	if ((msg->data[2] != 'C')
+	    || (msg->data[3] != 'L')
+	    || (msg->data[4] != 'R')) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	op = msg->data[5];
+	if ((op != 0) && (op != 0xaa)) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	rdata[1] = 1;
+	if (op == 0) {
+		down(&mc->main_sdrs.sem);
+		clear_sdr(&(mc->main_sdrs.sdrs), &(mc->main_sdrs.lock));
+		up(&mc->main_sdrs.sem);
+	}
+
+	rdata[0] = 0;
+	*rdata_len = 1;
+
+	do_gettimeofday(&t);
+	mc->main_sdrs.last_erase_time = t.tv_sec + mc->main_sdrs.time_offset;
+}
+
+static void handle_get_sdr_repository_time(lmc_data_t *mc,
+					   unsigned char *rdata,
+					   unsigned int *rdata_len)
+{
+	struct timeval t;
+
+	if (!(mc->device_support & IPMI_DEVID_SDR_REPOSITORY_DEV)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	do_gettimeofday(&t);
+	rdata[0] = 0;
+	ipmi_set_uint32(rdata + 1, t.tv_sec + mc->main_sdrs.time_offset);
+	*rdata_len = 5;
+}
+
+static void handle_set_sdr_repository_time(lmc_data_t *mc, ipmi_msg_t *msg,
+					   unsigned char *rdata,
+					   unsigned int *rdata_len)
+{
+	struct timeval t;
+
+	if (!(mc->device_support & IPMI_DEVID_SDR_REPOSITORY_DEV)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (check_msg_length(msg, 4, rdata, rdata_len))
+		return;
+
+	do_gettimeofday(&t);
+	mc->main_sdrs.time_offset = ipmi_get_uint32(msg->data) - t.tv_sec;
+
+	rdata[0] = 0;
+	*rdata_len = 1;
+}
+
+static void handle_enter_sdr_repository_update(lmc_data_t *mc,
+					       unsigned char *rdata,
+					       unsigned int *rdata_len)
+{
+	int modal;
+
+	if (!(mc->device_support & IPMI_DEVID_SDR_REPOSITORY_DEV)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	modal = IPMI_SDR_GET_MODAL(mc->main_sdrs.flags);
+	if ((modal == IPMI_SDR_MODAL_UNSPECIFIED)
+	    || (modal == IPMI_SDR_NON_MODAL_ONLY)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	mc->in_update_mode = 1;
+
+	rdata[0] = 0;
+	*rdata_len = 1;
+}
+
+static void handle_exit_sdr_repository_update(lmc_data_t *mc,
+					      unsigned char *rdata,
+					      unsigned int *rdata_len)
+{
+	int modal;
+
+	if (!(mc->device_support & IPMI_DEVID_SDR_REPOSITORY_DEV)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	modal = IPMI_SDR_GET_MODAL(mc->main_sdrs.flags);
+	if ((modal == IPMI_SDR_MODAL_UNSPECIFIED)
+	    || (modal == IPMI_SDR_NON_MODAL_ONLY)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	mc->in_update_mode = 0;
+
+	rdata[0] = 0;
+	*rdata_len = 1;
+}
+
+static void handle_get_fru_inventory_area_info(lmc_data_t *mc,
+					       ipmi_msg_t *msg,
+					       unsigned char *rdata,
+					       unsigned int *rdata_len)
+{
+	unsigned char devid;
+
+	if (check_msg_length(msg, 1, rdata, rdata_len))
+		return;
+
+	devid = msg->data[0];
+	if ((devid >= 255) || (!mc->frus[devid].data)) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	rdata[0] = 0;
+	ipmi_set_uint16(rdata + 1, mc->frus[devid].length);
+	rdata[3] = 0;		/* We only support byte access for now. */
+	*rdata_len = 4;
+}
+
+static void handle_read_fru_data(lmc_data_t *mc, ipmi_msg_t *msg,
+				 unsigned char *rdata, unsigned int *rdata_len)
+{
+	unsigned char devid;
+	int offset;
+	int count;
+
+	if (check_msg_length(msg, 4, rdata, rdata_len))
+		return;
+
+	devid = msg->data[0];
+	if ((devid >= 255) || (!mc->frus[devid].data)) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	offset = ipmi_get_uint16(msg->data + 1);
+	count = msg->data[3];
+
+	if (offset >= mc->frus[devid].length) {
+		handle_error_response(IPMI_PARAMETER_OUT_OF_RANGE_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	if ((offset + count) > mc->frus[devid].length)
+		count = mc->frus[devid].length - offset;
+	if (count + 2 > IPMI_MAX_MSG_LENGTH) {
+		/* Too much data to put into response. */
+		handle_error_response(IPMI_REQUESTED_DATA_LENGTH_EXCEEDED_CC,
+				      rdata, rdata_len);
+		return;
+	}
+
+	rdata[0] = 0;
+	rdata[1] = count;
+	memcpy(rdata + 2, mc->frus[devid].data + offset, count);
+	*rdata_len = 2 + count;
+}
+
+static void handle_write_fru_data(lmc_data_t *mc, ipmi_msg_t *msg,
+				  unsigned char *rdata, unsigned int *rdata_len)
+{
+	unsigned char devid;
+	int offset;
+	int count;
+
+	if (check_msg_length(msg, 3, rdata, rdata_len))
+		return;
+
+	devid = msg->data[0];
+	if ((devid >= 255) || (!mc->frus[devid].data)) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	offset = ipmi_get_uint16(msg->data + 1);
+	count = msg->data_len - 3;
+
+	if (offset >= mc->frus[devid].length) {
+		handle_error_response(IPMI_PARAMETER_OUT_OF_RANGE_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	if ((offset + count) > mc->frus[devid].length) {
+		/* Too much data to put into FRU. */
+		handle_error_response(IPMI_REQUESTED_DATA_LENGTH_EXCEEDED_CC,
+				      rdata, rdata_len);
+		return;
+	}
+
+	memcpy(mc->frus[devid].data + offset, msg->data + 3, count);
+	rdata[0] = 0;
+	rdata[1] = count;
+	*rdata_len = 2;
+}
+
+static void handle_storage_netfn(lmc_data_t *mc, unsigned char lun,
+				 ipmi_msg_t *msg, unsigned char *rdata,
+				 unsigned int *rdata_len)
+{
+	switch (msg->cmd) {
+	case IPMI_GET_SEL_INFO_CMD:
+		handle_get_sel_info(mc, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_SEL_ALLOCATION_INFO_CMD:
+		handle_get_sel_allocation_info(mc, rdata, rdata_len);
+		break;
+
+	case IPMI_RESERVE_SEL_CMD:
+		handle_reserve_sel(mc, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_SEL_ENTRY_CMD:
+		handle_get_sel_entry(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_ADD_SEL_ENTRY_CMD:
+		handle_add_sel_entry(mc, msg, rdata, rdata_len);
+		break;
+
+#ifndef CONFIG_IPMI_VMC_ENABLE_PMEM
+	case IPMI_DELETE_SEL_ENTRY_CMD:
+		handle_delete_sel_entry(mc, msg, rdata, rdata_len);
+		break;
+#endif
+
+	case IPMI_CLEAR_SEL_CMD:
+		handle_clear_sel(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_SEL_TIME_CMD:
+		handle_get_sel_time(mc, rdata, rdata_len);
+		break;
+
+	case IPMI_SET_SEL_TIME_CMD:
+		handle_set_sel_time(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_SDR_REPOSITORY_INFO_CMD:
+		handle_get_sdr_repository_info(mc, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_SDR_REPOSITORY_ALLOC_INFO_CMD:
+		handle_get_sdr_repository_alloc_info(mc, rdata, rdata_len);
+		break;
+
+	case IPMI_RESERVE_SDR_REPOSITORY_CMD:
+		handle_reserve_sdr_repository(mc, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_SDR_CMD:
+		handle_get_sdr(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_ADD_SDR_CMD:
+		handle_add_sdr(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_DELETE_SDR_CMD:
+		handle_delete_sdr(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_CLEAR_SDR_REPOSITORY_CMD:
+		handle_clear_sdr_repository(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_SDR_REPOSITORY_TIME_CMD:
+		handle_get_sdr_repository_time(mc, rdata, rdata_len);
+		break;
+
+	case IPMI_SET_SDR_REPOSITORY_TIME_CMD:
+		handle_set_sdr_repository_time(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_ENTER_SDR_REPOSITORY_UPDATE_CMD:
+		handle_enter_sdr_repository_update(mc, rdata, rdata_len);
+		break;
+
+	case IPMI_EXIT_SDR_REPOSITORY_UPDATE_CMD:
+		handle_exit_sdr_repository_update(mc, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_FRU_INVENTORY_AREA_INFO_CMD:
+		handle_get_fru_inventory_area_info(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_READ_FRU_DATA_CMD:
+		handle_read_fru_data(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_WRITE_FRU_DATA_CMD:
+		handle_write_fru_data(mc, msg, rdata, rdata_len);
+		break;
+
+	default:
+		handle_invalid_cmd(rdata, rdata_len);
+		break;
+	}
+}
+
+/*
+ *  IPMI MC msg handling functions:
+ */
+
+static void handle_get_device_id(lmc_data_t *mc, ipmi_msg_t *msg,
+				 unsigned char *rdata, unsigned int *rdata_len)
+{
+	memset(rdata, 0, 12);
+	rdata[0] = 0x0;
+	rdata[1] = mc->device_id;
+	rdata[2] = (((mc->has_device_sdrs << 7) & 0x80)
+		    | (mc->device_revision & 0x0f));
+	rdata[3] = mc->major_fw_rev & 0x7f;
+	rdata[4] = mc->minor_fw_rev;
+	rdata[5] = SDR_VER_IPMI15;
+	rdata[6] = mc->device_support;
+	memcpy(rdata + 7, mc->mfg_id, 3);
+	memcpy(rdata + 10, mc->product_id, 2);
+	*rdata_len = 12;
+}
+
+static void handle_get_channel_info(lmc_data_t *mc, unsigned char chan,
+				    ipmi_msg_t *msg,
+				    unsigned char *rdata,
+				    unsigned int *rdata_len)
+{
+	unsigned char lchan;
+
+	if (msg->data_len < 1) {
+		rdata[0] = IPMI_REQUEST_DATA_LENGTH_INVALID_CC;
+		*rdata_len = 1;
+		return;
+	}
+
+	lchan = msg->data[0];
+	if (lchan == 0xe)
+		lchan = chan;
+	else if (lchan >= IPMI_MAX_CHANNELS) {
+		rdata[0] = IPMI_INVALID_DATA_FIELD_CC;
+		*rdata_len = 1;
+		return;
+	}
+
+	if (!mc->chans[lchan].medium_type) {
+		rdata[0] = IPMI_NOT_PRESENT_CC;
+		*rdata_len = 1;
+		return;
+	}
+
+	rdata[0] = 0;
+	rdata[1] = lchan;
+	rdata[2] = mc->chans[lchan].medium_type;
+	rdata[3] = mc->chans[lchan].protocol_type;
+	/* FIXME - no handling of active sessions */
+	rdata[4] = mc->chans[lchan].session_support << 6;
+	rdata[5] = 0xf2;
+	rdata[6] = 0x1b;
+	rdata[7] = 0x00;
+	rdata[8] = 0x00;
+	rdata[9] = 0x00;
+	*rdata_len = 10;
+}
+
+static void handle_set_bmc_global_enables(lmc_data_t *mc, ipmi_msg_t *msg,
+					  unsigned char *rdata,
+					  unsigned int *rdata_len)
+{
+	/* interrupt flags are not supported */
+	mc->global_enables = msg->data[0] & 0xfc;
+	mc->sel.enabled = mc->global_enables & 0x08;
+	rdata[0] = 0x0;
+	*rdata_len = 1;
+}
+
+static void handle_get_bmc_global_enables(lmc_data_t *mc, ipmi_msg_t *msg,
+					  unsigned char *rdata,
+					  unsigned int *rdata_len)
+{
+	rdata[0] = 0x0;
+	rdata[1] = mc->global_enables;
+	*rdata_len = 2;
+}
+
+static void handle_clear_msg_flags(lmc_data_t *mc, ipmi_msg_t *msg,
+				   unsigned char *rdata,
+				   unsigned int *rdata_len)
+{
+	ipmi_request_events();
+	rdata[0] = 0x0;
+	*rdata_len = 1;
+}
+
+static void handle_get_msg_flags(lmc_data_t *mc, ipmi_msg_t *msg,
+				 unsigned char *rdata, unsigned int *rdata_len)
+{
+	rdata[0] = 0x0;
+	rdata[1] = 0x0;
+	*rdata_len = 2;
+}
+
+static void handle_app_netfn(lmc_data_t *mc, unsigned char chan,
+			     unsigned char lun, ipmi_msg_t *msg,
+			     unsigned char *rdata, unsigned int *rdata_len)
+{
+	switch (msg->cmd) {
+	case IPMI_GET_DEVICE_ID_CMD:
+		handle_get_device_id(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_CHANNEL_INFO_CMD:
+		handle_get_channel_info(mc, chan, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_SET_BMC_GLOBAL_ENABLES_CMD:
+		handle_set_bmc_global_enables(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_BMC_GLOBAL_ENABLES_CMD:
+		handle_get_bmc_global_enables(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_CLEAR_MSG_FLAGS_CMD:
+		handle_clear_msg_flags(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_MSG_FLAGS_CMD:
+		handle_get_msg_flags(mc, msg, rdata, rdata_len);
+		break;
+
+	default:
+		handle_invalid_cmd(rdata, rdata_len);
+		break;
+	}
+}
+
+/*
+ *  IPMI Sensor message handling functions
+ */
+
+static void handle_get_event_receiver(lmc_data_t *mc, ipmi_msg_t *msg,
+				      unsigned char *rdata,
+				      unsigned int *rdata_len)
+{
+	if (!(mc->device_support & IPMI_DEVID_IPMB_EVENT_GEN)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	rdata[0] = 0;
+	rdata[1] = mc->event_receiver;
+	rdata[2] = mc->event_receiver_lun & 0x3;
+	*rdata_len = 3;
+}
+
+static void handle_set_event_receiver(lmc_data_t *mc, ipmi_msg_t *msg,
+				      unsigned char *rdata, unsigned int *rdata_len)
+{
+	if (!(mc->device_support & IPMI_DEVID_IPMB_EVENT_GEN)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+	if (check_msg_length(msg, 2, rdata, rdata_len))
+		return;
+
+	mc->event_receiver = msg->data[0] & 0xfe;
+	mc->event_receiver_lun = msg->data[1] & 0x3;
+
+	rdata[0] = 0;
+	*rdata_len = 1;
+}
+
+static void handle_get_device_sdr_info(lmc_data_t *mc, unsigned char lun,
+				       ipmi_msg_t *msg, unsigned char *rdata,
+				       unsigned int *rdata_len)
+{
+	if (!mc->has_device_sdrs) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	rdata[0] = 0;
+	rdata[1] = mc->num_sensors_per_lun[lun];
+	rdata[2] = (((mc->dynamic_sensor_population << 7) & 0x80)
+		    | ((mc->lun_has_sensors[3] << 3) & 0x08)
+		    | ((mc->lun_has_sensors[2] << 2) & 0x04)
+		    | ((mc->lun_has_sensors[1] << 1) & 0x02)
+		    | ((mc->lun_has_sensors[0] << 0) & 0x01));
+	if (!mc->dynamic_sensor_population) {
+		*rdata_len = 3;
+		return;
+	}
+
+	ipmi_set_uint32(rdata + 3, mc->sensor_population_change_time);
+	*rdata_len = 7;
+}
+
+static void handle_reserve_device_sdr_repository(lmc_data_t *mc,
+						 unsigned char lun,
+						 ipmi_msg_t *msg,
+						 unsigned char *rdata,
+						 unsigned int *rdata_len)
+{
+	if (!(mc->has_device_sdrs)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	if (!(mc->dynamic_sensor_population)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	mc->device_sdrs[lun].reservation++;
+	if (mc->device_sdrs[lun].reservation == 0)
+		mc->device_sdrs[lun].reservation++;
+
+	rdata[0] = 0;
+	ipmi_set_uint16(rdata + 1, mc->device_sdrs[lun].reservation);
+	*rdata_len = 3;
+
+	return;
+}
+
+static void handle_get_device_sdr(lmc_data_t *mc, unsigned char lun,
+				  ipmi_msg_t *msg, unsigned char *rdata,
+				  unsigned int *rdata_len)
+{
+	uint16_t record_id;
+	int offset;
+	int count;
+	vMC_ipmi_sdr_t *entry;
+	void *p;
+#ifdef __BIG_ENDIAN__
+	uint16_t *assert_mask;
+	uint16_t *deassert_mask;
+#endif
+
+	if (!(mc->has_device_sdrs)) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	}
+
+	if (check_msg_length(msg, 6, rdata, rdata_len))
+		return;
+
+	if (mc->dynamic_sensor_population) {
+		uint16_t reservation = ipmi_get_uint16(msg->data + 0);
+
+		if ((reservation != 0)
+		    && (reservation != mc->device_sdrs[lun].reservation)) {
+			rdata[0] = IPMI_INVALID_RESERVATION_CC;
+			*rdata_len = 1;
+			return;
+		}
+	}
+
+	record_id = ipmi_get_uint16(msg->data + 2);
+	offset = msg->data[4];
+	count = msg->data[5];
+
+	down(&mc->device_sdrs[lun].sem);
+
+	entry = find_sdr_by_recid(mc, &mc->device_sdrs[lun], record_id, msg,
+				  rdata, rdata_len);
+	if (entry == NULL) {
+		up(&mc->device_sdrs[lun].sem);
+		return;
+	}
+
+	if (offset >= entry->sdr_hdr.record_length + 5) {
+		up(&mc->device_sdrs[lun].sem);
+		rdata[0] = IPMI_PARAMETER_OUT_OF_RANGE_CC;
+		*rdata_len = 1;
+		return;
+	}
+
+	if ((offset + count) > entry->sdr_hdr.record_length + 5)
+		count = entry->sdr_hdr.record_length - (offset - 5);
+	if (count + 3 > IPMI_MAX_MSG_LENGTH) {
+		/* Too much data to put into response. */
+		up(&mc->device_sdrs[lun].sem);
+		rdata[0] = IPMI_REQUESTED_DATA_LENGTH_EXCEEDED_CC;
+		*rdata_len = 1;
+		return;
+	}
+#ifdef __BIG_ENDIAN__
+	/*
+	 * IPMI specifies that multi-byte values need to be transfered in
+	 * little endian format. Assertion_event_mask and deassertion_event_mask
+	 * are both defined as uint16_t -- multi-bytes values. We swap them before
+	 * we memcpy the SDR record into the IPMI message buffer and then...
+	 */
+	assert_mask = &entry->sdr_body.sdr_full.assertion_event_mask;
+	deassert_mask = &entry->sdr_body.sdr_full.deassertion_event_mask;
+
+	*assert_mask = __swab16(*assert_mask);
+	*deassert_mask = __swab16(*deassert_mask);
+#endif
+
+	rdata[0] = 0;
+	p = (void *) entry;
+	memcpy(rdata + 3, p + offset, count);
+
+#ifdef __BIG_ENDIAN__
+	/*
+	 * swap them again to keep the native endianness in vMC storage.
+	 */
+	*assert_mask = __swab16(*assert_mask);
+	*deassert_mask = __swab16(*deassert_mask);
+#endif
+
+	if (entry->list.next != &(mc->device_sdrs[lun].sdrs)) {
+		entry = list_entry(entry->list.next, vMC_ipmi_sdr_t, list);
+		ipmi_set_uint16(rdata + 1, entry->sdr_hdr.record_id);
+	} else {
+		rdata[1] = 0xff;
+		rdata[2] = 0xff;
+	}
+
+	up(&mc->device_sdrs[lun].sem);
+	*rdata_len = count + 3;
+}
+
+static void handle_set_sensor_hysteresis(lmc_data_t *mc, unsigned char lun,
+					 ipmi_msg_t *msg, unsigned char *rdata,
+					 unsigned int *rdata_len)
+{
+	int sens_num;
+	sensor_t *sensor;
+	int rc;
+
+	if (check_msg_length(msg, 4, rdata, rdata_len))
+		return;
+
+	sens_num = msg->data[0];
+	sensor = ipmi_find_sensor_bynum(mc->ipmb, lun, sens_num, &rc);
+	if (sensor == NULL) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	if ((sensor->sdr->sdr_hdr.record_type != IPMI_SDR_FULL_TYPE) ||
+	    (sensor->sdr->sdr_body.sdr_full.sens_capable_hysteresis_support !=
+	     HYSTERESIS_READABLE_SETTABLE)) {
+		ipmi_release_sensor(sensor);
+		handle_error_response(IPMI_INVALID_CMD_CC, rdata, rdata_len);
+		return;
+	}
+
+	down(&sensor->sem);
+	sensor->sdr->sdr_body.sdr_full.positive_hysteresis = msg->data[2];
+	sensor->sdr->sdr_body.sdr_full.negative_hysteresis = msg->data[3];
+	up(&sensor->sem);
+
+	ipmi_release_sensor(sensor);
+
+	rdata[0] = 0;
+	*rdata_len = 1;
+}
+
+static void handle_get_sensor_hysteresis(lmc_data_t *mc, unsigned char lun,
+					 ipmi_msg_t *msg, unsigned char *rdata,
+					 unsigned int *rdata_len)
+{
+	int sens_num, rc;
+	sensor_t *sensor;
+
+	if (check_msg_length(msg, 1, rdata, rdata_len))
+		return;
+
+	sens_num = msg->data[0];
+	sensor = ipmi_find_sensor_bynum(mc->ipmb, lun, sens_num, &rc);
+	if (sensor == NULL) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	if ((sensor->sdr->sdr_hdr.record_type != IPMI_SDR_FULL_TYPE) ||
+	    (sensor->sdr->sdr_body.sdr_full.sens_capable_hysteresis_support ==
+	     NO_HYSTERESIS)
+	    || (sensor->sdr->sdr_body.sdr_full.
+		sens_capable_hysteresis_support ==
+		FIXED_UNREADABLE_HYSTERESIS)) {
+		ipmi_release_sensor(sensor);
+		handle_error_response(IPMI_INVALID_CMD_CC, rdata, rdata_len);
+		return;
+	}
+
+	rdata[0] = 0;
+	down(&sensor->sem);
+	rdata[1] = sensor->sdr->sdr_body.sdr_full.positive_hysteresis;
+	rdata[2] = sensor->sdr->sdr_body.sdr_full.negative_hysteresis;
+	up(&sensor->sem);
+	*rdata_len = 3;
+}
+
+static void sensor_set_bit(vMC_kapi_cmd_t *cmd)
+/* FIXME: not functional- calls do_event, which needs work. The function
+ * declaration has been commented out in the kernel API header file (vmc.h),
+ * as has the register_vMC_api() (in vmc_kapi.c) registration of this API. */
+{
+	uint16_t bitmask = 1 << cmd->bit;
+
+	down(&(cmd->s->sem));
+	if (cmd->value != cmd->s->event_status[cmd->bit]) {
+		/* The bit value has changed. */
+		cmd->s->event_status[cmd->bit] = cmd->value;
+		if (cmd->value)
+			cmd->s->value |= bitmask;
+		else
+			cmd->s->value &= ~bitmask;
+		up(&(cmd->s->sem));
+		if (cmd->selr->sel_event_data.event_data[0] == 0x0) {
+			cmd->selr->sel_event_data.event_data[0] =
+			    0x00 | cmd->bit;
+			cmd->selr->sel_event_data.event_data[1] = 0x0;
+			cmd->selr->sel_event_data.event_data[2] = 0x0;
+		}
+/* for discrete !
+  Not fully impl., because diff sensors define diff bits! (16 per sensor)
+*/
+		if (cmd->value
+		    && (cmd->s->sdr->sdr_body.sdr_full.
+			assertion_event_mask & bitmask)) {
+			do_event(cmd->s, IPMI_ASSERTION, cmd->selr);
+			if ((cmd->s->sdr->sdr_body.sdr_full.containment_enable)
+			    && (vMC_containment_handler[cmd->bit] != NULL))
+				(vMC_containment_handler[cmd->bit]) ();
+		} else if (!cmd->value
+			   && (cmd->s->sdr->sdr_body.sdr_full.
+			       deassertion_event_mask & bitmask)) {
+			do_event(cmd->s, IPMI_DEASSERTION, cmd->selr);
+			if ((cmd->s->sdr->sdr_body.sdr_full.containment_enable)
+			    && (vMC_containment_handler[cmd->bit] != NULL))
+				(vMC_containment_handler[cmd->bit]) ();
+		}
+	} else {
+		up(&cmd->s->sem);
+		vMC_free_sel_record(cmd->selr);
+	}
+
+	if (cmd->s->sensor_update_handler)
+		cmd->s->sensor_update_handler(cmd->s);
+
+	ipmi_release_sensor(cmd->s);
+}
+
+static void handle_set_sensor_thresholds(lmc_data_t *mc, unsigned char lun,
+					 ipmi_msg_t *msg, unsigned char *rdata,
+					 unsigned int *rdata_len)
+{
+	int sens_num;
+	sensor_t *sensor;
+	int i, rc;
+
+	if (check_msg_length(msg, 8, rdata, rdata_len))
+		return;
+
+	sens_num = msg->data[0];
+	sensor = ipmi_find_sensor_bynum(mc->ipmb, lun, sens_num, &rc);
+	if (sensor == NULL) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	if (sensor->sdr->sdr_body.sdr_full.sens_capable_threshold_access !=
+	    THRESHOLDS_READABLE_SETTABLE) {
+		ipmi_release_sensor(sensor);
+		handle_error_response(IPMI_INVALID_CMD_CC, rdata, rdata_len);
+		return;
+	}
+
+	for (i = 0; i < 6; i++) {
+		if ((msg->data[1] & (1 << i))
+		    && (sensor->sdr->sdr_body.sdr_full.
+			set_thres_mask & (1 << i))) {
+			ipmi_release_sensor(sensor);
+			handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+					      rdata_len);
+			return;
+		}
+	}
+
+	down(&sensor->sem);
+	for (i = 0; i < 6; i++) {
+		if (msg->data[1] & (1 << i)) {
+			sensor->sdr->sdr_body.sdr_full.thresholds[i] =
+			    msg->data[i + 2];
+			sensor->thresholds[i] =
+			    ((uint16_t) sensor->sdr->sdr_body.sdr_full.
+			     thresholds[i] * sensor->M) + sensor->B;
+		}
+	}
+
+	check_thresholds(sensor, 0, NULL);
+	up(&sensor->sem);
+
+	ipmi_release_sensor(sensor);
+
+	rdata[0] = 0;
+	*rdata_len = 1;
+}
+
+static void handle_get_sensor_thresholds(lmc_data_t *mc, unsigned char lun,
+					 ipmi_msg_t *msg, unsigned char *rdata,
+					 unsigned int *rdata_len)
+{
+	int sens_num, rc;
+	sensor_t *sensor;
+	int i;
+
+	if (check_msg_length(msg, 1, rdata, rdata_len))
+		return;
+
+	sens_num = msg->data[0];
+	sensor = ipmi_find_sensor_bynum(mc->ipmb, lun, sens_num, &rc);
+	if (sensor == NULL) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	if ((sensor->sdr->sdr_body.sdr_full.sens_capable_threshold_access !=
+	     THRESHOLDS_READABLE_SETTABLE)
+	    && (sensor->sdr->sdr_body.sdr_full.sens_capable_threshold_access !=
+		THRESHOLDS_READABLE)) {
+		ipmi_release_sensor(sensor);
+		handle_error_response(IPMI_INVALID_CMD_CC, rdata, rdata_len);
+		return;
+	}
+
+	rdata[0] = 0;
+	rdata[1] = 0;
+	down(&sensor->sem);
+	for (i = 0; i < 6; i++) {
+		if (sensor->sdr->sdr_body.sdr_full.read_thres_mask & (1 << i)) {
+			rdata[1] |= 1 << i;
+			rdata[2 + i] =
+			    sensor->sdr->sdr_body.sdr_full.thresholds[i];
+		} else
+			rdata[2 + i] = 0;
+	}
+	up(&sensor->sem);
+	ipmi_release_sensor(sensor);
+
+	*rdata_len = 8;
+}
+
+static void handle_set_sensor_event_enable(lmc_data_t *mc, unsigned char lun,
+					   ipmi_msg_t *msg,
+					   unsigned char *rdata,
+					   unsigned int *rdata_len)
+{
+	int sens_num, rc;
+	sensor_t *sensor;
+	int i, j, e;
+	unsigned char op;
+
+#define A_NON_ZERO_VALUE 1
+
+	if (check_msg_length(msg, 2, rdata, rdata_len))
+		return;
+
+	sens_num = msg->data[0];
+	sensor = ipmi_find_sensor_bynum(mc->ipmb, lun, sens_num, &rc);
+	if (sensor == NULL) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	if ((sensor->sdr->sdr_body.sdr_full.sens_capable_event_msg_control ==
+	     NO_EVENTS_FROM_SENSOR)
+	    || (sensor->sdr->sdr_body.sdr_full.sens_capable_event_msg_control ==
+		PER_THRESHOLD_SHUTDOWN)) {
+		ipmi_release_sensor(sensor);
+		handle_error_response(IPMI_INVALID_CMD_CC, rdata, rdata_len);
+		return;
+	}
+
+	op = (msg->data[1] >> 4) & 0x3;
+	if (sensor->sdr->sdr_body.sdr_full.sens_capable_event_msg_control ==
+	    ENTIRE_SENSOR_ONLY) {
+		if (op != 0) {
+			ipmi_release_sensor(sensor);
+			handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+					      rdata_len);
+			return;
+		}
+	}
+
+	if (op == 3) {		/* reserved */
+		ipmi_release_sensor(sensor);
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	down(&sensor->sem);
+	sensor->sdr->sdr_body.sdr_full.event_generation_enabled =
+	    (msg->data[1] >> 7) & 1;
+	sensor->sdr->sdr_body.sdr_full.sensor_scanning_enabled =
+	    (msg->data[1] >> 6) & 1;
+
+	if (op == 0) {		/* don't change */
+		up(&sensor->sem);
+		ipmi_release_sensor(sensor);
+		return;
+	} else if (op == 1)
+		/* Enable selected events */
+		op = A_NON_ZERO_VALUE;
+	else
+		/* Disable selected events */
+		op = 0;
+
+	e = 0;
+	for (i = 2; i <= 3; i++) {
+		for (j = 0; j < 8; j++, e++) {
+			if (e >= 15)
+				break;
+			if ((msg->data[i] >> j) & 1) {
+				if (op) {
+					sensor->sdr->sdr_body.sdr_full.
+					    assertion_event_mask |= (1 << e);
+				} else {
+					sensor->sdr->sdr_body.sdr_full.
+					    assertion_event_mask &= ~(1 << e);
+				}
+			}
+		}
+	}
+
+	e = 0;
+	for (i = 4; i <= 5; i++) {
+		for (j = 0; j < 8; j++, e++) {
+			if (e >= 15)
+				break;
+			if ((msg->data[i] >> j) & 1) {
+				if (op) {
+					sensor->sdr->sdr_body.sdr_full.
+					    deassertion_event_mask |= (1 << e);
+				} else {
+					sensor->sdr->sdr_body.sdr_full.
+					    deassertion_event_mask &= ~(1 << e);
+				}
+			}
+		}
+	}
+	up(&sensor->sem);
+	ipmi_release_sensor(sensor);
+
+	rdata[0] = 0;
+	*rdata_len = 1;
+}
+
+static void handle_get_sensor_event_enable(lmc_data_t *mc, unsigned char lun,
+					   ipmi_msg_t *msg,
+					   unsigned char *rdata,
+					   unsigned int *rdata_len)
+{
+	int sens_num, rc;
+	sensor_t *sensor;
+	int i, j, e;
+
+	if (check_msg_length(msg, 1, rdata, rdata_len))
+		return;
+
+	sens_num = msg->data[0];
+	sensor = ipmi_find_sensor_bynum(mc->ipmb, lun, sens_num, &rc);
+	if (sensor == NULL) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	if (sensor->sdr->sdr_body.sdr_full.sens_capable_event_msg_control ==
+	    NO_EVENTS_FROM_SENSOR) {
+		ipmi_release_sensor(sensor);
+		handle_error_response(IPMI_INVALID_CMD_CC, rdata, rdata_len);
+		return;
+	}
+
+	rdata[0] = 0;
+	down(&sensor->sem);
+	rdata[1] =
+	    ((sensor->sdr->sdr_body.sdr_full.event_generation_enabled << 7)
+	     | (sensor->sdr->sdr_body.sdr_full.sensor_scanning_enabled << 6));
+
+	if (sensor->sdr->sdr_body.sdr_full.sens_capable_event_msg_control ==
+	    ENTIRE_SENSOR_ONLY) {
+		up(&sensor->sem);
+		ipmi_release_sensor(sensor);
+		*rdata_len = 2;
+		return;
+	}
+
+	e = 0;
+	for (i = 2; i <= 3; i++) {
+		rdata[i] = 0;
+		for (j = 0; j < 8; j++, e++) {
+			if (e >= 15)
+				break;
+			rdata[i] |=
+			    ((sensor->sdr->sdr_body.sdr_full.
+			      assertion_event_mask & (1 << e)) ? 1 : 0) << j;
+		}
+	}
+
+	e = 0;
+	for (i = 4; i <= 5; i++) {
+		rdata[i] = 0;
+		for (j = 0; j < 8; j++, e++) {
+			if (e >= 15)
+				break;
+			rdata[i] |=
+			    ((sensor->sdr->sdr_body.sdr_full.
+			      deassertion_event_mask & (1 << e)) ? 1 : 0) << j;
+		}
+	}
+	up(&sensor->sem);
+	ipmi_release_sensor(sensor);
+
+	*rdata_len = 6;
+}
+
+static void handle_set_sensor_type(lmc_data_t *mc, unsigned char lun,
+				   ipmi_msg_t *msg, unsigned char *rdata,
+				   unsigned int *rdata_len)
+{
+	handle_invalid_cmd(rdata, rdata_len);
+}
+
+static void handle_get_sensor_type(lmc_data_t *mc, unsigned char lun,
+				   ipmi_msg_t *msg, unsigned char *rdata,
+				   unsigned int *rdata_len)
+{
+	int sens_num, rc;
+	sensor_t *sensor;
+
+	if (check_msg_length(msg, 1, rdata, rdata_len))
+		return;
+
+	sens_num = msg->data[0];
+	sensor = ipmi_find_sensor_bynum(mc->ipmb, lun, sens_num, &rc);
+	if (sensor == NULL) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	rdata[0] = 0;
+	rdata[1] = sensor->sdr->sdr_body.sdr_full.sensor_type;
+	rdata[2] = sensor->sdr->sdr_body.sdr_full.event_reading_type_code;
+	ipmi_release_sensor(sensor);
+	*rdata_len = 3;
+}
+
+static void handle_get_sensor_reading(lmc_data_t *mc, unsigned char lun,
+				      ipmi_msg_t *msg, unsigned char *rdata,
+				      unsigned int *rdata_len)
+{
+	int sens_num, rc;
+	sensor_t *sensor;
+
+	if (check_msg_length(msg, 1, rdata, rdata_len))
+		return;
+
+	sens_num = msg->data[0];
+	sensor = ipmi_find_sensor_bynum(mc->ipmb, lun, sens_num, &rc);
+	if (sensor == NULL) {
+		handle_error_response(IPMI_INVALID_DATA_FIELD_CC, rdata,
+				      rdata_len);
+		return;
+	}
+
+	rdata[0] = 0;
+	down(&sensor->sem);
+	rdata[1] = (unsigned char) sensor->cvalue;
+	rdata[2] =
+	    ((sensor->sdr->sdr_body.sdr_full.event_generation_enabled << 7)
+	     | (sensor->sdr->sdr_body.sdr_full.sensor_scanning_enabled << 6));
+	ipmi_set_uint16(rdata + 3, sensor->value);
+	up(&sensor->sem);
+	ipmi_release_sensor(sensor);
+	*rdata_len = 5;
+}
+
+/* Write a SEL record to the SEL */
+int ipmi_mc_add_sel_cmd(vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	vMC_kapi_cmd_t *cmd;
+
+	cmd = vmc_kmalloc(sizeof(vMC_kapi_cmd_t), GFP_ATOMIC);
+	if (cmd == NULL) {
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_ENOMEM;
+	}
+	cmd->cmd = SEL_ADD_CMD;
+	cmd->selr = vMC_sel_record;
+	kapicmd(cmd);
+
+	return VMC_NO_ERROR;
+}
+
+/* Write a SEL record to the SEL, in a Machine-check-execution- */
+/* level safe way (i.e. let a MC-safe workqueue do the writing  */
+int ipmi_mc_add_sel_cmd_mcsafe(vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	vMC_kapi_cmd_t *cmd;
+
+	cmd = vmc_kmalloc(sizeof(vMC_kapi_cmd_t), GFP_ATOMIC);
+	if (cmd == NULL) {
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_ENOMEM;
+	}
+	cmd->cmd = SEL_ADD_CMD;
+	cmd->selr = vMC_sel_record;
+	kapicmd_mcsafe(cmd);
+
+	return VMC_NO_ERROR;
+}
+
+int ipmi_mc_sensor_set_bit(vMC_ipmi_sensor_ident_t *sensor_ident,
+			   unsigned int bit, unsigned int val,
+			   vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	sensor_t *sensor;
+	int rc;
+	vMC_kapi_cmd_t *cmd;
+
+	if (bit > 15) {
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_EINVAL;
+	}
+	if ((val != 0) && (val != 1)) {
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_EINVAL;
+	}
+	sensor = ipmi_find_sensor_byid(sensor_ident, &rc);
+	if (sensor == NULL) {
+		vMC_free_sel_record(vMC_sel_record);
+		printk(KERN_ERR "Can't get sensor bit, err %d\n", rc);
+		return rc;
+	}
+	if (sensor->sdr->sdr_body.sdr_full.event_reading_type_code ==
+	    IPMI_EVENT_READING_TYPE_THRESHOLD) {
+		ipmi_release_sensor(sensor);
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_INVALID_SENSOR_TYPE;
+	}
+
+	cmd = vmc_kmalloc(sizeof(vMC_kapi_cmd_t), GFP_ATOMIC);
+	if (cmd == NULL) {
+		ipmi_release_sensor(sensor);
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_ENOMEM;
+	}
+
+	if (vMC_sel_record == NULL) {
+		vMC_sel_record = vMC_alloc_sel_record(0,
+					sensor->mc->event_receiver, &rc);
+		if (vMC_sel_record == NULL) {
+			ipmi_release_sensor(sensor);
+			vmc_kfree(cmd);
+			return VMC_ENOMEM;
+		}
+	}
+
+	cmd->cmd = SENSOR_SET_BIT;
+	cmd->s = sensor;
+	cmd->bit = (unsigned char) bit;
+	cmd->value = (unsigned char) val;
+	cmd->selr = vMC_sel_record;
+	kapicmd(cmd);
+
+	return VMC_NO_ERROR;
+}
+
+int ipmi_mc_sensor_get_value(vMC_ipmi_sensor_ident_t *sensor_ident,
+			     unsigned int *val)
+{
+	sensor_t *sensor;
+	int rc;
+
+	sensor = ipmi_find_sensor_byid(sensor_ident, &rc);
+	if (sensor == NULL) {
+		printk(KERN_ERR "Can't get sensor val, err %d\n", rc);
+		return rc;
+	}
+
+	*val = sensor->value;
+
+	ipmi_release_sensor(sensor);
+	return VMC_NO_ERROR;
+}
+
+int ipmi_mc_sensor_set_external_event_mask(vMC_ipmi_sensor_ident_t *sensor_ident,
+					   unsigned char mask)
+{
+	sensor_t *sensor;
+	int rc;
+
+	sensor = ipmi_find_sensor_byid(sensor_ident, &rc);
+	if (sensor == NULL) {
+		printk(KERN_ERR "Can't set ext ev mask, err %d\n", rc);
+		return rc;
+	}
+
+	sensor->sdr->sdr_body.sdr_full.ipmb_upper_non_recoverable_enable =
+	    (mask & 0x01) ? 1 : 0;
+	sensor->sdr->sdr_body.sdr_full.ipmb_upper_critical_enable =
+	    (mask & 0x02) ? 1 : 0;
+	sensor->sdr->sdr_body.sdr_full.ipmb_upper_non_critical_enable =
+	    (mask & 0x04) ? 1 : 0;
+	sensor->sdr->sdr_body.sdr_full.ipmb_lower_non_recoverable_enable =
+	    (mask & 0x08) ? 1 : 0;
+	sensor->sdr->sdr_body.sdr_full.ipmb_lower_critical_enable =
+	    (mask & 0x10) ? 1 : 0;
+	sensor->sdr->sdr_body.sdr_full.ipmb_lower_non_critical_enable =
+	    (mask & 0x20) ? 1 : 0;
+	sensor->sdr->sdr_body.sdr_full.containment_enable =
+	    (mask & 0x40) ? 1 : 0;
+	sensor->sdr->sdr_body.sdr_full.bmc_enable = (mask & 0x80) ? 1 : 0;
+	ipmi_release_sensor(sensor);
+
+	return VMC_NO_ERROR;
+}
+
+int ipmi_mc_sensor_set_value(vMC_ipmi_sensor_ident_t *sensor_ident,
+			     unsigned char value,
+			     vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	sensor_t *sensor;
+	int rc;
+	vMC_kapi_cmd_t *cmd;
+
+	sensor = ipmi_find_sensor_byid(sensor_ident, &rc);
+	if (sensor == NULL) {
+		vMC_free_sel_record(vMC_sel_record);
+		printk(KERN_ERR "Can't set sensor val, err %d\n", rc);
+		return rc;
+	}
+	if (sensor->sdr->sdr_body.sdr_full.event_reading_type_code !=
+	    IPMI_EVENT_READING_TYPE_THRESHOLD) {
+		ipmi_release_sensor(sensor);
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_INVALID_SENSOR_TYPE;
+	}
+
+/*	if (sensor->sdr->sdr_body.sdr_full.sensor_units_1_rate_unit != RATE_NONE) {
+		ipmi_release_sensor(sensor);
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_INVALID_SENSOR_TYPE;
+	}
+*/
+	cmd = vmc_kmalloc(sizeof(vMC_kapi_cmd_t), GFP_ATOMIC);
+	if (cmd == NULL) {
+		ipmi_release_sensor(sensor);
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_ENOMEM;
+	}
+
+	if (vMC_sel_record == NULL) {
+		vMC_sel_record = vMC_alloc_sel_record(0, 0x00, &rc);
+		if (vMC_sel_record == NULL) {
+			ipmi_release_sensor(sensor);
+			vmc_kfree(cmd);
+			return VMC_ENOMEM;
+		}
+	}
+
+	cmd->cmd = SENSOR_SET_VALUE;
+	cmd->s = sensor;
+	cmd->value = value;
+	cmd->selr = vMC_sel_record;
+	kapicmd(cmd);
+
+	return VMC_NO_ERROR;
+}
+
+int ipmi_mc_sensor_inc_value(vMC_ipmi_sensor_ident_t *sensor_ident,
+			     unsigned char value,
+			     vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	sensor_t *sensor;
+	int rc;
+	vMC_kapi_cmd_t *cmd;
+
+	sensor = ipmi_find_sensor_byid(sensor_ident, &rc);
+	if (sensor == NULL) {
+		vMC_free_sel_record(vMC_sel_record);
+		printk(KERN_ERR "Can't inc sensor, err %d\n", rc);
+		return rc;
+	}
+	if (sensor->sdr->sdr_body.sdr_full.event_reading_type_code !=
+	    IPMI_EVENT_READING_TYPE_THRESHOLD) {
+		ipmi_release_sensor(sensor);
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_INVALID_SENSOR_TYPE;
+	}
+
+	if (sensor->sdr->sdr_body.sdr_full.sensor_units_1_rate_unit !=
+	    RATE_NONE) {
+		if (value != 0x01) {
+			ipmi_release_sensor(sensor);
+			vMC_free_sel_record(vMC_sel_record);
+			return VMC_INVALID_SENSOR_TYPE;
+		}
+	}
+
+	cmd = vmc_kmalloc(sizeof(vMC_kapi_cmd_t), GFP_ATOMIC);
+	if (cmd == NULL) {
+		ipmi_release_sensor(sensor);
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_ENOMEM;
+	}
+
+	if (vMC_sel_record == NULL) {
+		vMC_sel_record = vMC_alloc_sel_record(0, 0x00, &rc);
+		if (vMC_sel_record == NULL) {
+			ipmi_release_sensor(sensor);
+			vmc_kfree(cmd);
+			return VMC_ENOMEM;
+		}
+	}
+
+	cmd->cmd = SENSOR_SET_VALUE_IN;
+	cmd->s = sensor;
+	cmd->value = value;
+	cmd->selr = vMC_sel_record;
+	kapicmd(cmd);
+
+	return VMC_NO_ERROR;
+}
+
+int ipmi_mc_sensor_inc_value_mcsafe(vMC_ipmi_sensor_ident_t *sensor_ident,
+				    unsigned char value,
+				    vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	sensor_t *sensor;
+	int rc;
+	vMC_kapi_cmd_t *cmd;
+
+	sensor = ipmi_find_sensor_byid(sensor_ident, &rc);
+	if (sensor == NULL) {
+		vMC_free_sel_record(vMC_sel_record);
+		printk(KERN_ERR "Can't inc sensor, err %d\n", rc);
+		return rc;
+	}
+	if (sensor->sdr->sdr_body.sdr_full.event_reading_type_code !=
+	    IPMI_EVENT_READING_TYPE_THRESHOLD) {
+		ipmi_release_sensor(sensor);
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_INVALID_SENSOR_TYPE;
+	}
+
+	if (sensor->sdr->sdr_body.sdr_full.sensor_units_1_rate_unit !=
+	    RATE_NONE) {
+		if (value != 0x01) {
+			ipmi_release_sensor(sensor);
+			vMC_free_sel_record(vMC_sel_record);
+			return VMC_INVALID_SENSOR_TYPE;
+		}
+	}
+
+	cmd = vmc_kmalloc(sizeof(vMC_kapi_cmd_t), GFP_ATOMIC);
+	if (cmd == NULL) {
+		ipmi_release_sensor(sensor);
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_ENOMEM;
+	}
+
+	if (vMC_sel_record == NULL) {
+		vMC_sel_record = vMC_alloc_sel_record(0, 0x00, &rc);
+		if (vMC_sel_record == NULL) {
+			ipmi_release_sensor(sensor);
+			vmc_kfree(cmd);
+			return VMC_ENOMEM;
+		}
+	}
+
+	cmd->cmd = SENSOR_SET_VALUE_IN;
+	cmd->s = sensor;
+	cmd->value = value;
+	cmd->selr = vMC_sel_record;
+	kapicmd_mcsafe(cmd);
+
+	return VMC_NO_ERROR;
+}
+
+int ipmi_mc_sensor_dec_value(vMC_ipmi_sensor_ident_t *sensor_ident,
+			     unsigned char value,
+			     vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	sensor_t *sensor;
+	int rc;
+	vMC_kapi_cmd_t *cmd;
+
+	sensor = ipmi_find_sensor_byid(sensor_ident, &rc);
+	if (sensor == NULL) {
+		vMC_free_sel_record(vMC_sel_record);
+		printk(KERN_ERR "Can't dec sensor, err %d\n", rc);
+		return rc;
+	}
+	if (sensor->sdr->sdr_body.sdr_full.event_reading_type_code !=
+	    IPMI_EVENT_READING_TYPE_THRESHOLD) {
+		ipmi_release_sensor(sensor);
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_INVALID_SENSOR_TYPE;
+	}
+
+	if (sensor->sdr->sdr_body.sdr_full.sensor_units_1_rate_unit !=
+	    RATE_NONE) {
+		ipmi_release_sensor(sensor);
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_INVALID_SENSOR_TYPE;
+	}
+
+	cmd = vmc_kmalloc(sizeof(vMC_kapi_cmd_t), GFP_ATOMIC);
+	if (cmd == NULL) {
+		ipmi_release_sensor(sensor);
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_ENOMEM;
+	}
+
+	if (vMC_sel_record == NULL) {
+		vMC_sel_record = vMC_alloc_sel_record(0, 0x00, &rc);
+		if (vMC_sel_record == NULL) {
+			ipmi_release_sensor(sensor);
+			vmc_kfree(cmd);
+			return VMC_ENOMEM;
+		}
+	}
+
+	cmd->cmd = SENSOR_SET_VALUE_DE;
+	cmd->s = sensor;
+	cmd->value = value;
+	cmd->selr = vMC_sel_record;
+	kapicmd(cmd);
+
+	return VMC_NO_ERROR;
+}
+
+/* Function to handle leaking of rate-based sensors */
+/* (also causes approp. events to be generated). */
+int internal_ipmi_mc_sensor_dec_value(sensor_t *sensor, unsigned char value,
+				      vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	int rc;
+	vMC_kapi_cmd_t *cmd;
+
+	if (sensor->sdr->sdr_body.sdr_full.event_reading_type_code !=
+	    IPMI_EVENT_READING_TYPE_THRESHOLD) {
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_INVALID_SENSOR_TYPE;
+	}
+
+	cmd = vmc_kmalloc(sizeof(vMC_kapi_cmd_t), GFP_ATOMIC);
+	if (cmd == NULL) {
+		vMC_free_sel_record(vMC_sel_record);
+		return VMC_ENOMEM;
+	}
+
+	if (vMC_sel_record == NULL) {
+		vMC_sel_record = vMC_alloc_sel_record(0, 0x00, &rc);
+		if (vMC_sel_record == NULL) {
+			vmc_kfree(cmd);
+			return VMC_ENOMEM;
+		}
+	}
+
+	cmd->cmd = SENSOR_SET_VALUE_LEAKING;
+	cmd->s = sensor;
+	cmd->value = value;
+	cmd->selr = vMC_sel_record;
+	kapicmd(cmd);
+
+	return VMC_NO_ERROR;
+}
+
+int ipmi_mc_sensor_set_hysteresis(vMC_ipmi_sensor_ident_t *sensor_ident,
+				  unsigned char support,
+				  unsigned char positive,
+				  unsigned char negative)
+{
+	sensor_t *sensor;
+	int rc;
+	vMC_kapi_cmd_t *cmd;
+
+	sensor = ipmi_find_sensor_byid(sensor_ident, &rc);
+	if (sensor == NULL) {
+		printk(KERN_ERR "Can't set hysteresis, err %d\n", rc);
+		return rc;
+	}
+
+	cmd = vmc_kmalloc(sizeof(vMC_kapi_cmd_t), GFP_ATOMIC);
+	if (cmd == NULL) {
+		ipmi_release_sensor(sensor);
+		return VMC_ENOMEM;
+	}
+
+	cmd->cmd = SENSOR_SET_HYSTERESIS;
+	cmd->s = sensor;
+	cmd->support = support;
+	cmd->positive = positive;
+	cmd->negative = negative;
+	kapicmd(cmd);
+
+	return VMC_NO_ERROR;
+}
+
+int ipmi_mc_sensor_set_threshold(vMC_ipmi_sensor_ident_t *sensor_ident,
+				 unsigned char support,
+				 unsigned char readmask,
+				 unsigned char setmask, unsigned char *values)
+{
+	sensor_t *sensor;
+	int rc, i;
+	vMC_kapi_cmd_t *cmd;
+
+	sensor = ipmi_find_sensor_byid(sensor_ident, &rc);
+	if (sensor == NULL) {
+		printk(KERN_ERR "Can't set thresh, err %d\n", rc);
+		return rc;
+	}
+
+	cmd = vmc_kmalloc(sizeof(vMC_kapi_cmd_t), GFP_ATOMIC);
+	if (cmd == NULL) {
+		ipmi_release_sensor(sensor);
+		return VMC_ENOMEM;
+	}
+
+	cmd->cmd = SENSOR_SET_THRESHOLD;
+	cmd->s = sensor;
+	cmd->support = support;
+	cmd->readmask = readmask;
+	cmd->setmask = setmask;
+	for (i = 0; i < 6; i++)
+		cmd->thresholds[i] = values[i];
+	kapicmd(cmd);
+
+	return VMC_NO_ERROR;
+}
+
+int ipmi_mc_sensor_set_event_support(vMC_ipmi_sensor_ident_t *sensor_ident,
+				     unsigned char support,
+				     unsigned int assertions_supported,
+				     unsigned int deassertions_supported)
+{
+	sensor_t *sensor;
+	int rc;
+	vMC_kapi_cmd_t *cmd;
+
+	sensor = ipmi_find_sensor_byid(sensor_ident, &rc);
+	if (sensor == NULL) {
+		printk(KERN_ERR "Can't set ev support, err %d\n", rc);
+		return rc;
+	}
+
+	cmd = vmc_kmalloc(sizeof(vMC_kapi_cmd_t), GFP_ATOMIC);
+	if (cmd == NULL) {
+		ipmi_release_sensor(sensor);
+		return VMC_ENOMEM;
+	}
+
+	cmd->cmd = SENSOR_SET_EVENT_SUPPORT;
+	cmd->s = sensor;
+	cmd->support = support;
+	cmd->assertions = assertions_supported;
+	cmd->deassertions = deassertions_supported;
+	kapicmd(cmd);
+
+	return VMC_NO_ERROR;
+}
+
+static void handle_sensor_event_netfn(lmc_data_t *mc, unsigned char lun,
+				      ipmi_msg_t *msg, unsigned char *rdata,
+				      unsigned int *rdata_len)
+{
+	switch (msg->cmd) {
+	case IPMI_GET_EVENT_RECEIVER_CMD:
+		handle_get_event_receiver(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_SET_EVENT_RECEIVER_CMD:
+		handle_set_event_receiver(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_DEVICE_SDR_INFO_CMD:
+		handle_get_device_sdr_info(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_RESERVE_DEVICE_SDR_REPOSITORY_CMD:
+		handle_reserve_device_sdr_repository(mc, lun, msg, rdata,
+						     rdata_len);
+		break;
+
+	case IPMI_GET_DEVICE_SDR_CMD:
+		handle_get_device_sdr(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_SET_SENSOR_HYSTERESIS_CMD:
+		handle_set_sensor_hysteresis(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_SENSOR_HYSTERESIS_CMD:
+		handle_get_sensor_hysteresis(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_SET_SENSOR_THRESHOLD_CMD:
+		handle_set_sensor_thresholds(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_SENSOR_THRESHOLD_CMD:
+		handle_get_sensor_thresholds(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_SET_SENSOR_EVENT_ENABLE_CMD:
+		handle_set_sensor_event_enable(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_SENSOR_EVENT_ENABLE_CMD:
+		handle_get_sensor_event_enable(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_SET_SENSOR_TYPE_CMD:
+		handle_set_sensor_type(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_SENSOR_TYPE_CMD:
+		handle_get_sensor_type(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_SENSOR_READING_CMD:
+		handle_get_sensor_reading(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GET_SENSOR_EVENT_STATUS_CMD:
+	case IPMI_REARM_SENSOR_EVENTS_CMD:
+	case IPMI_GET_SENSOR_READING_FACTORS_CMD:
+	default:
+		handle_invalid_cmd(rdata, rdata_len);
+		break;
+	}
+}
+
+static void handle_picmg_get_properties(lmc_data_t *mc, ipmi_msg_t *msg,
+					unsigned char *rdata,
+					unsigned int *rdata_len)
+{
+	rdata[0] = 0;
+	rdata[1] = IPMI_PICMG_GRP_EXT;
+	rdata[2] = 0x02;	/* Indicate Version 2.0 */
+	rdata[3] = 0;		/* Only have one FRU. */
+	rdata[4] = 0;		/* As defined by spec. */
+	*rdata_len = 5;
+}
+
+static void handle_picmg_get_address_info(lmc_data_t *mc, ipmi_msg_t *msg,
+					  unsigned char *rdata,
+					  unsigned int *rdata_len)
+{
+	atca_site_t *sites = mc->emu->atca_sites;
+	unsigned char hw_addr = mc->ipmb >> 1;
+	unsigned char devid = 0;
+	int i;
+
+	if (msg->data_len == 3) {
+		rdata[0] = IPMI_INVALID_DATA_FIELD_CC;
+		*rdata_len = 1;
+		return;
+	}
+
+	if (msg->data_len >= 2)
+		devid = msg->data[1];
+
+	if (msg->data_len >= 4) {
+		switch (msg->data[2]) {
+		case 0:
+			hw_addr = msg->data[3];
+			break;
+
+		case 1:
+			hw_addr = msg->data[3] >> 1;
+			break;
+
+		case 3:
+			if (msg->data_len < 5) {
+				rdata[0] = IPMI_INVALID_DATA_FIELD_CC;
+				*rdata_len = 1;
+				return;
+			}
+			for (i = 0; i < 128; i++) {
+				if (sites[i].valid
+				    && (sites[i].site_type == msg->data[4])
+				    && (sites[i].site_number == msg->data[3])) {
+					break;
+				}
+			}
+			if (i == 128) {
+				rdata[0] = IPMI_DESTINATION_UNAVAILABLE_CC;
+				*rdata_len = 1;
+				return;
+			}
+			hw_addr = i;
+			break;
+
+		default:
+			rdata[0] = IPMI_INVALID_DATA_FIELD_CC;
+			*rdata_len = 1;
+			return;
+		}
+	}
+
+	if ((hw_addr >= 128) || (!sites[hw_addr].valid) || (devid > 0)) {
+		rdata[0] = IPMI_DESTINATION_UNAVAILABLE_CC;
+		*rdata_len = 1;
+		return;
+	}
+
+	rdata[0] = 0;
+	rdata[1] = IPMI_PICMG_GRP_EXT;
+	rdata[2] = hw_addr;
+	rdata[3] = hw_addr << 1;
+	rdata[4] = 0xff;
+	rdata[5] = devid;
+	rdata[6] = sites[hw_addr].site_number;
+	rdata[7] = sites[hw_addr].site_type;
+	*rdata_len = 8;
+}
+
+void ipmi_emu_atca_enable(void)
+{
+	emu->atca_mode = 1;
+}
+
+int ipmi_emu_atca_set_site(unsigned char hw_address, unsigned char site_type,
+			   unsigned char site_number)
+{
+	if (hw_address >= 128)
+		return VMC_EINVAL;
+
+	emu->atca_sites[hw_address].valid = 1;
+	emu->atca_sites[hw_address].hw_address = hw_address;
+	emu->atca_sites[hw_address].site_type = site_type;
+	emu->atca_sites[hw_address].site_number = site_number;
+	return 0;
+}
+
+static void handle_picmg_msg(lmc_data_t *mc, unsigned char lun,
+			     ipmi_msg_t *msg, unsigned char *rdata,
+			     unsigned int *rdata_len)
+{
+	switch (msg->cmd) {
+	case IPMI_PICMG_CMD_GET_PROPERTIES:
+		handle_picmg_get_properties(mc, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_PICMG_CMD_GET_ADDRESS_INFO:
+		handle_picmg_get_address_info(mc, msg, rdata, rdata_len);
+		break;
+
+	default:
+		handle_invalid_cmd(rdata, rdata_len);
+		break;
+	}
+}
+
+static void handle_group_extension_netfn(lmc_data_t *mc, unsigned char lun,
+					ipmi_msg_t *msg, unsigned char *rdata,
+					unsigned int *rdata_len)
+{
+	if (check_msg_length(msg, 1, rdata, rdata_len))
+		return;
+
+	switch (msg->data[0]) {
+	case IPMI_PICMG_GRP_EXT:
+		if (emu->atca_mode)
+			handle_picmg_msg(mc, lun, msg, rdata, rdata_len);
+		else
+			handle_invalid_cmd(rdata, rdata_len);
+		break;
+
+	default:
+		handle_invalid_cmd(rdata, rdata_len);
+		break;
+	}
+}
+
+static uint8_t ipmb_checksum(uint8_t *data, int size, uint8_t start)
+{
+	uint8_t csum = start;
+
+	for (; size > 0; size--, data++)
+		csum += *data;
+
+	return -csum;
+}
+
+static void _ipmi_emu_handle_msg(ipmi_msg_t *msg, unsigned char *rdata,
+				 unsigned int *rdata_len)
+{
+	unsigned char lun;
+	unsigned char chan = 0x00;
+	lmc_data_t *mc;
+	ipmi_msg_t *smsg = NULL;
+	ipmi_msg_t *omsg = msg;
+	unsigned char *data = NULL;
+
+	if (msg->cmd == IPMI_SEND_MSG_CMD) {
+		handle_invalid_cmd(rdata, rdata_len);
+		return;
+	} else {
+		mc = emu->ipmb[emu->bmc_mc >> 1];
+		if (!mc || !mc->enabled) {
+			handle_error_response(0xff, rdata, rdata_len);
+			return;
+		}
+	}
+
+	lun = msg->netfn & 0x03;
+	switch (msg->netfn >> 2) {
+	case IPMI_APP_NETFN:
+		handle_app_netfn(mc, chan, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_SENSOR_EVENT_NETFN:
+		handle_sensor_event_netfn(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_STORAGE_NETFN:
+		handle_storage_netfn(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	case IPMI_GROUP_EXTENSION_NETFN:
+		handle_group_extension_netfn(mc, lun, msg, rdata, rdata_len);
+		break;
+
+	default:
+		handle_invalid_cmd(rdata, rdata_len);
+		break;
+	}
+
+	if (smsg)
+		vmc_kfree(smsg);
+
+	if (omsg->cmd == IPMI_SEND_MSG_CMD) {
+		int i;
+		for (i = *rdata_len - 1; i >= 0; i--)
+			rdata[i + 7] = rdata[i];
+		rdata[0] = 0;
+		rdata[1] = emu->bmc_mc;
+		rdata[2] = ((msg->netfn | 1) << 2) | (data[4] & 0x3);	/* using data uninitialized! */
+		rdata[3] = ipmb_checksum(rdata + 1, 2, 0);
+		rdata[4] = data[0];
+		rdata[5] = (data[4] & 0xfc) | (data[1] & 0x03);
+		rdata[6] = data[5];
+		*rdata_len += 7;
+		rdata[*rdata_len] = ipmb_checksum(rdata, *rdata_len, 0);
+		*rdata_len += 1;
+	}
+}
+
+void ipmi_emu_handle_msg(struct ipmi_smi_msg *msg)
+{
+	ipmi_msg_t *ipmimsg;
+
+	ipmimsg = (ipmi_msg_t *) &(msg->data_size);
+	ipmimsg->data_len -= 2;
+	msg->rsp[0] = ipmimsg->netfn | 4;
+	msg->rsp[1] = ipmimsg->cmd;
+
+	_ipmi_emu_handle_msg(ipmimsg, &(msg->rsp[2]), &msg->rsp_size);
+	ipmimsg->data_len += 2;
+	msg->rsp_size += 2;
+}
+
+void kapi_handle_msg(vMC_kapi_cmd_t *cmd)
+{
+	int i;
+	unsigned char old;
+	unsigned int recid;
+
+	switch (cmd->cmd) {
+	case SEL_ADD_CMD:
+		ipmi_add_to_sel_recid(cmd->selr, &recid);
+		break;
+
+	case DELETE_DEVICE_SDR:
+		_ipmi_mc_delete_device_sdr(cmd->mc, cmd->s);
+		break;
+
+	case SENSOR_SET_BIT:
+		sensor_set_bit(cmd);
+		break;
+
+	case SENSOR_SET_VALUE:
+		if (cmd->value > cmd->s->value)
+			cmd->s->direction = SENSOR_INCREASING;
+		else if (cmd->value < cmd->s->value)
+			cmd->s->direction = SENSOR_DECREASING;
+		else
+			cmd->s->direction = SENSOR_UNCHANGED;
+
+		down(&cmd->s->sem);
+		spin_lock(&cmd->s->lock);
+		cmd->s->cvalue = cmd->value;
+		cmd->s->value = ((uint16_t) cmd->value * cmd->s->M) + cmd->s->B;
+		spin_unlock(&cmd->s->lock);
+
+		if (cmd->s->sensor_update_handler)
+			cmd->s->sensor_update_handler(cmd->s);
+
+		if (cmd->s->direction != SENSOR_UNCHANGED) {
+			if (cmd->s->sdr->sdr_body.sdr_full.
+			    sensor_units_1_rate_unit != RATE_NONE)
+				add_timestamp(cmd->s);
+			check_thresholds(cmd->s, 0, cmd->selr);
+		} else {
+			vMC_free_sel_record(cmd->selr);
+		}
+		up(&cmd->s->sem);
+		ipmi_release_sensor(cmd->s);
+		break;
+
+	case SENSOR_SET_VALUE_IN:
+		down(&cmd->s->sem);
+		spin_lock(&cmd->s->lock);
+		old = cmd->s->cvalue;
+		/* Don't allow sensor val to wrap 8 bits */
+		if ((cmd->s->cvalue + cmd->value) > 0xff)
+			cmd->s->cvalue = 0xff;
+		else
+			cmd->s->cvalue += cmd->value;
+		cmd->s->value =
+		    ((uint16_t) cmd->s->cvalue * cmd->s->M) + cmd->s->B;
+		spin_unlock(&cmd->s->lock);
+		if (cmd->s->cvalue > old)
+			cmd->s->direction = SENSOR_INCREASING;
+		else
+			cmd->s->direction = SENSOR_UNCHANGED;
+
+		if (cmd->s->sensor_update_handler)
+			cmd->s->sensor_update_handler(cmd->s);
+
+		if (cmd->s->direction != SENSOR_UNCHANGED) {
+			if (cmd->s->sdr->sdr_body.sdr_full.
+			    sensor_units_1_rate_unit != RATE_NONE)
+				add_timestamp(cmd->s);
+			check_thresholds(cmd->s, 0, cmd->selr);
+		} else
+			vMC_free_sel_record(cmd->selr);
+		up(&cmd->s->sem);
+		ipmi_release_sensor(cmd->s);
+		break;
+
+	case SENSOR_SET_VALUE_DE:
+		/* Don't support decrementing rate-based */
+		if (cmd->s->sdr->sdr_body.sdr_full.sensor_units_1_rate_unit ==
+		    RATE_NONE) {
+			down(&cmd->s->sem);
+			spin_lock(&cmd->s->lock);
+			old = cmd->s->cvalue;
+			/* Don't allow sensor val to underflow */
+			if ((cmd->s->cvalue - cmd->value) < 0)
+				cmd->s->cvalue = 0;
+			else
+				cmd->s->cvalue -= cmd->value;
+			cmd->s->value =
+			    ((uint16_t) cmd->s->cvalue * cmd->s->M) + cmd->s->B;
+			spin_unlock(&cmd->s->lock);
+			if (cmd->s->cvalue < old)
+				cmd->s->direction = SENSOR_DECREASING;
+			else
+				cmd->s->direction = SENSOR_UNCHANGED;
+
+			if (cmd->s->sensor_update_handler)
+				cmd->s->sensor_update_handler(cmd->s);
+
+			if (cmd->s->direction != SENSOR_UNCHANGED)
+				check_thresholds(cmd->s, 0, cmd->selr);
+			else
+				vMC_free_sel_record(cmd->selr);
+			up(&cmd->s->sem);
+		}
+		ipmi_release_sensor(cmd->s);
+		break;
+
+	case SENSOR_SET_VALUE_LEAKING:
+		if (cmd->s->sdr->sdr_body.sdr_full.sensor_units_1_rate_unit !=
+		    RATE_NONE) {
+			down(&cmd->s->sem);
+			spin_lock(&cmd->s->lock);
+			if (cmd->s->cvalue == 0) {
+				spin_unlock(&cmd->s->lock);
+				up(&cmd->s->sem);
+				/* printk(KERN_INFO "already 0!!\n"); */
+				break;
+			}
+			cmd->s->cvalue -= cmd->value;
+			cmd->s->value =
+			    ((uint16_t) cmd->s->cvalue * cmd->s->M) + cmd->s->B;
+			spin_unlock(&cmd->s->lock);
+			if (cmd->value)
+				cmd->s->direction = SENSOR_DECREASING;
+			else
+				cmd->s->direction = SENSOR_UNCHANGED;
+
+			if (cmd->s->sensor_update_handler)
+				cmd->s->sensor_update_handler(cmd->s);
+
+			if (cmd->s->direction != SENSOR_UNCHANGED)
+				check_thresholds(cmd->s, 0, cmd->selr);
+			else
+				vMC_free_sel_record(cmd->selr);
+			up(&cmd->s->sem);
+		}
+		break;
+
+	case SENSOR_SET_HYSTERESIS:
+		down(&cmd->s->sem);
+		cmd->s->sdr->sdr_body.sdr_full.sens_capable_hysteresis_support =
+		    cmd->support;
+		if (cmd->s->sdr->sdr_body.sdr_full.
+		    sens_capable_hysteresis_support ==
+		    HYSTERESIS_READABLE_SETTABLE) {
+			cmd->s->sdr->sdr_body.sdr_full.positive_hysteresis =
+			    cmd->positive;
+			cmd->s->sdr->sdr_body.sdr_full.negative_hysteresis =
+			    cmd->negative;
+		}
+		check_thresholds(cmd->s, 0, NULL);
+		up(&cmd->s->sem);
+
+		ipmi_release_sensor(cmd->s);
+		break;
+
+	case SENSOR_SET_THRESHOLD:
+		down(&cmd->s->sem);
+		cmd->s->sdr->sdr_body.sdr_full.sens_capable_threshold_access =
+		    cmd->support;
+		if (cmd->s->sdr->sdr_body.sdr_full.
+		    sens_capable_threshold_access ==
+		    THRESHOLDS_READABLE_SETTABLE) {
+			cmd->s->sdr->sdr_body.sdr_full.read_thres_mask =
+			    cmd->readmask;
+			cmd->s->sdr->sdr_body.sdr_full.set_thres_mask =
+			    cmd->setmask;
+			for (i = 0; i < 6; i++) {
+				cmd->s->sdr->sdr_body.sdr_full.thresholds[i] =
+				    cmd->thresholds[i];
+				cmd->s->thresholds[i] =
+				    ((uint16_t) cmd->s->sdr->sdr_body.sdr_full.
+				     thresholds[i] * cmd->s->M) + cmd->s->B;
+			}
+		}
+		check_thresholds(cmd->s, 0, NULL);
+		up(&cmd->s->sem);
+
+		ipmi_release_sensor(cmd->s);
+		break;
+
+	case SENSOR_SET_EVENT_SUPPORT:
+		down(&cmd->s->sem);
+		cmd->s->sdr->sdr_body.sdr_full.sens_capable_event_msg_control =
+		    cmd->support;
+		cmd->s->sdr->sdr_body.sdr_full.assertion_event_mask =
+		    cmd->assertions;
+		cmd->s->sdr->sdr_body.sdr_full.deassertion_event_mask =
+		    cmd->deassertions;
+
+		check_thresholds(cmd->s, 0, NULL);
+		up(&cmd->s->sem);
+
+		ipmi_release_sensor(cmd->s);
+		break;
+
+	case IPMI_SEND_CMD:
+		send_event_buffer(cmd->smiMsg);
+		break;
+
+	default:
+		break;
+	}
+}
+
+int ipmi_emu_alloc(void *user_data)
+{
+	if (emu)
+		return VMC_NO_ERROR;
+
+	emu = vmc_kmalloc(sizeof(struct emu_data_s), GFP_KERNEL);
+
+	if (emu) {
+		memset(emu, 0, sizeof(struct emu_data_s));
+		emu->user_data = user_data;
+		return VMC_NO_ERROR;
+	}
+
+	return VMC_ENOMEM;
+}
+
+void ipmi_emu_free(void)
+{
+	/* free all memory allocated to the emulator */
+	int i;
+
+#define A_NON_ZERO_VALUE 1
+
+	for (i = 0; i < 128; i++) {
+		if (emu->ipmb[i] != NULL)
+			ipmi_emu_delete_mc(emu->ipmb[i]);
+	}
+
+	if (emu->user_data != NULL)
+		vmc_kfree(emu->user_data);
+
+	vmc_kfree(emu);
+}
+
+void *ipmi_emu_get_user_data(void)
+{
+	return emu->user_data;
+}
+
+void ipmi_emu_delete_mc(lmc_data_t *mc)
+{
+	int i, j, rc;
+
+	emu->ipmb[mc->ipmb >> 1] = NULL;
+
+	/* SELs will be cleared by 'sel_disable' command */
+
+	clear_sdr(&(mc->main_sdrs.sdrs), &(mc->main_sdrs.lock));
+
+	for (i = 0; i < 4; i++) {
+		clear_sdr(&(mc->device_sdrs[i].sdrs),
+			  &(mc->device_sdrs[i].lock));
+		for (j = 0; j < 255; j++) {
+			if (mc->sensors[i][j] != NULL)
+				vmc_kfree(mc->sensors[i][j]);
+		}
+	}
+
+	rc = destroy_vmc_smi(mc);
+	if (rc != 0)
+		printk(KERN_ERR "%s: Failed to destroy associated vMC SMI\n",
+			__func__);
+
+	kmem_cache_destroy(mc->sel.selCache);
+	vmc_kfree(mc);
+}
+
+int ipmi_emu_set_mc_channel(lmc_data_t *mc,
+			    unsigned char channel,
+			    unsigned char medium_type,
+			    unsigned char protocol_type,
+			    unsigned char session_support)
+{
+	if (channel >= IPMI_MAX_CHANNELS)
+		return VMC_EINVAL;
+	mc->chans[channel].medium_type = medium_type;
+	mc->chans[channel].protocol_type = protocol_type;
+	mc->chans[channel].session_support = session_support & 0x3;
+	return 0;
+}
+
+void ipmi_mc_disable(lmc_data_t *mc)
+{
+	mc->enabled = 0;
+}
+
+void ipmi_mc_enable(lmc_data_t *mc)
+{
+	mc->enabled = 1;
+}
+
+int ipmi_emu_add_mc(unsigned char ipmb,
+		    unsigned char channel,
+		    unsigned char device_id,
+		    unsigned char has_device_sdrs,
+		    unsigned char device_revision,
+		    unsigned char major_fw_rev,
+		    unsigned char minor_fw_rev,
+		    unsigned char device_support,
+		    unsigned char mfg_id[3],
+		    unsigned char product_id[2],
+		    unsigned char dynamic_sensor_population)
+{
+	lmc_data_t *mc;
+	int i, rc;
+	struct timeval t;
+	char selCacheName[VMC_CACHE_NAME_SIZE];
+
+	if (ipmb & 1)
+		return VMC_EINVAL;
+
+	if (emu->ipmb[ipmb >> 1])
+		return VMC_EINVAL;
+
+	mc = vmc_kmalloc(sizeof(*mc), GFP_KERNEL);
+	if (!mc)
+		return VMC_ENOMEM;
+	memset(mc, 0, sizeof(*mc));
+
+	mc->emu = emu;
+	mc->ipmb = ipmb;
+	mc->channel = channel;
+	mc->device_id = device_id;
+	mc->has_device_sdrs = has_device_sdrs;
+	mc->device_revision = device_revision;
+	mc->major_fw_rev = major_fw_rev;
+	mc->minor_fw_rev = minor_fw_rev;
+	mc->device_support = device_support;
+	mc->dynamic_sensor_population = dynamic_sensor_population;
+	mc->global_enables = 0x0c;
+	mc->smiMissed = 1;
+	memcpy(mc->mfg_id, mfg_id, 3);
+	memcpy(mc->product_id, product_id, 2);
+	spin_lock_init(&mc->lock);
+	spin_lock_init(&mc->sel.lock);
+	init_MUTEX(&mc->sel.sem);
+
+	i = snprintf(selCacheName, VMC_CACHE_NAME_SIZE, "%s", "sel");
+	i += snprintf(selCacheName+i, VMC_CACHE_NAME_SIZE-i, "%d", ipmb);
+	selCacheName[i] = 0;
+	mc->sel.selCache = kmem_cache_create(selCacheName, /* name */
+				KERNEL_SEL_DATA_LENGTH, /* object size */
+				0, 			/* align */
+				0,			/* flags */
+				NULL);			/* ctor */
+	do_gettimeofday(&t);
+	mc->sel.time_offset = 0;
+	mc->main_sdrs.time_offset = 0;
+	mc->main_sdrs.last_add_time = t.tv_sec;
+	mc->main_sdrs.last_erase_time = t.tv_sec;
+	mc->main_sdrs.next_entry = 1;
+	mc->main_sdrs.flags = 0x2B;
+	init_MUTEX(&mc->main_sdrs.sem);
+	spin_lock_init(&mc->main_sdrs.lock);
+	INIT_LIST_HEAD(&(mc->main_sdrs.sdrs));
+	for (i = 0; i < 4; i++) {
+		mc->device_sdrs[i].time_offset = 0;
+		mc->device_sdrs[i].last_add_time = t.tv_sec;
+		mc->device_sdrs[i].last_erase_time = t.tv_sec;
+		mc->device_sdrs[i].next_entry = 1;
+		mc->device_sdrs[i].flags = 0x09;
+		init_MUTEX(&mc->device_sdrs[i].sem);
+		spin_lock_init(&mc->device_sdrs[i].lock);
+		INIT_LIST_HEAD(&(mc->device_sdrs[i].sdrs));
+
+	}
+
+	mc->event_receiver = ipmb;
+	mc->event_receiver_lun = 0;
+
+	emu->ipmb[ipmb >> 1] = mc;
+
+	rc = create_vmc_smi(mc);
+	if (rc == -ENOMEM)
+		return VMC_ENOMEM;
+	else if (rc < 0)
+		return VMC_EINVAL;
+
+	return VMC_NO_ERROR;
+}
+
+void ipmi_mc_set_device_id(lmc_data_t *mc, unsigned char device_id)
+{
+	mc->device_id = device_id;
+}
+
+unsigned char ipmi_mc_get_device_id(lmc_data_t *mc)
+{
+	return mc->device_id;
+}
+
+void ipmi_set_has_device_sdrs(lmc_data_t *mc, unsigned char has_device_sdrs)
+{
+	mc->has_device_sdrs = has_device_sdrs;
+}
+
+unsigned char ipmi_get_has_device_sdrs(lmc_data_t *mc)
+{
+	return mc->has_device_sdrs;
+}
+
+void ipmi_set_device_revision(lmc_data_t *mc, unsigned char device_revision)
+{
+	mc->device_revision = device_revision;
+}
+
+unsigned char ipmi_get_device_revision(lmc_data_t *mc)
+{
+	return mc->device_revision;
+}
+
+void ipmi_set_major_fw_rev(lmc_data_t *mc, unsigned char major_fw_rev)
+{
+	mc->major_fw_rev = major_fw_rev;
+}
+
+unsigned char ipmi_get_major_fw_rev(lmc_data_t *mc)
+{
+	return mc->major_fw_rev;
+}
+
+void ipmi_set_minor_fw_rev(lmc_data_t *mc, unsigned char minor_fw_rev)
+{
+	mc->minor_fw_rev = minor_fw_rev;
+}
+
+unsigned char ipmi_get_minor_fw_rev(lmc_data_t *mc)
+{
+	return mc->minor_fw_rev;
+}
+
+void ipmi_set_device_support(lmc_data_t *mc, unsigned char device_support)
+{
+	mc->device_support = device_support;
+}
+
+unsigned char ipmi_get_device_support(lmc_data_t *mc)
+{
+	return mc->device_support;
+}
+
+void ipmi_set_mfg_id(lmc_data_t *mc, unsigned char mfg_id[3])
+{
+	memcpy(mc->mfg_id, mfg_id, 3);
+}
+
+void ipmi_get_mfg_id(lmc_data_t *mc, unsigned char mfg_id[3])
+{
+	memcpy(mfg_id, mc->mfg_id, 3);
+}
+
+void ipmi_set_product_id(lmc_data_t *mc, unsigned char product_id[2])
+{
+	memcpy(mc->product_id, product_id, 2);
+}
+
+void ipmi_get_product_id(lmc_data_t *mc, unsigned char product_id[2])
+{
+	memcpy(product_id, mc->product_id, 2);
+}
+
+unsigned char ipmi_emu_get_mc_addr(lmc_data_t *mc)
+{
+	return mc->ipmb;
+}
+
+int ipmi_emu_get_mc_by_addr(unsigned char ipmb, lmc_data_t **mc)
+{
+	if (ipmb == 0x00)
+		ipmb = emu->bmc_mc;
+	if (ipmb & 1)
+		return VMC_INVALID_MC;
+	if (!emu->ipmb[ipmb >> 1])
+		return VMC_INVALID_MC;
+	*mc = emu->ipmb[ipmb >> 1];
+	return VMC_NO_ERROR;
+}
+
+int ipmi_emu_set_bmc_mc(unsigned char ipmb)
+{
+	int i;
+
+	if (ipmb & 1)
+		return VMC_EINVAL;
+	emu->bmc_mc = ipmb;
+
+	for (i = 0; i < MAX_MCS; i++) {
+		if (emu->ipmb[i] != NULL) {
+			emu->ipmb[i]->event_receiver = ipmb;
+			emu->ipmb[i]->event_receiver_lun = 0x00;
+		}
+	}
+	return VMC_NO_ERROR;
+}
+
+int ipmi_emu_dump_sel(lmc_data_t *mc)
+{
+	unsigned int k, m, i = 0;
+	unsigned char *p;
+
+#ifdef CONFIG_IPMI_VMC_ENABLE_PMEM
+	/*
+	 * If PMEM is used to store SELs, current vMC instance
+	 * could make use of the PMEM SEL partition & region
+	 * created by the last vMC instance, and should be albe
+	 * to dump all available SELs.
+	 * Also, this should be the case even after SEL has been
+	 * disabled for the current vMC instance.
+	 */
+	char id = mc->device_id;
+	int index, count = 0, ret;
+
+	if (atomic_read(&mc->sel.count) == 0)
+		printk(KERN_INFO "No SELs for current vMC instance,\n"
+			"go on to dump all available SELs in PMEM.\n");
+
+	if (partition_index(id, &index) == VMC_INVALID_PARTITION_INDEX)
+		return VMC_INVALID_PARTITION_INDEX;
+
+	int log_size = sel_region[index].fixed_size;
+	unsigned char buffer[log_size];
+
+	((struct pmem_handle *)region_read_handle[index])->offset = 0;
+	do {
+		/* Read SEL from vMC's region, PERPROC disabled */
+		ret = pmem_read_region_per_cpu(region_read_handle[index],
+						buffer, log_size, 0);
+		if (ret <= 0) /* error occurs, or reaching end */
+			break;
+
+		/* Decode SEL */
+		p = (unsigned char *)buffer;
+		printk(KERN_INFO "SEL %d:\n", count++);
+		for (k = 0; k < 4; k++) {
+			for (m = 0; m < 4; m++)
+				printk("%02x", p[(k * 4) + m]);
+			printk(" ");
+		}
+		printk("\n");
+
+		struct fault_record_s fault_rec;
+		struct vMC_ipmi_sel_record_s seltmp;
+		memcpy(&seltmp, p, IPMI_SEL_DATA_LENGTH);
+		memcpy(&fault_rec, p + IPMI_SEL_DATA_LENGTH,
+			SEL_MAX_EXTENDED_DATA_LENGTH);
+
+		printk(KERN_INFO "Record Id, Type, Timestamp:%04x %02x %08x\n",
+		       seltmp.recid, seltmp.type, seltmp.timestamp);
+		printk(KERN_INFO "Id_Type, Id_IPMB          :%02x %02x\n",
+		       seltmp.id_type, seltmp.id_ipmb << 1);
+		printk(KERN_INFO "IPMB_LUN, Res, Channel    :%02x %02x %02x\n",
+		       seltmp.ipmb_lun, seltmp.res, seltmp.chan);
+		printk(KERN_INFO "Sensor Number, Type       :%02x %02x\n",
+		       seltmp.sensornum, seltmp.sensortype);
+		printk(KERN_INFO "Event Dir, Type, Offset   :%02x %02x %02x\n",
+		       seltmp.event_dir, seltmp.event_type,
+		       seltmp.sel_event_data.event_data[0]);
+		printk(KERN_INFO "Extended data: fault type :%d\n",
+		       fault_rec.fault_type);
+		for (i = 0; i < MAX_FAULT_RECORD_SIZE; i++) {
+			printk(KERN_INFO "fault %d Reg name %28s =0x%08x\n", i,
+			       fault_rec.fault_record_data[i].reg_name,
+			       fault_rec.fault_record_data[i].data);
+		}
+	} while (ret > 0);
+
+#else
+	vMC_ipmi_sel_record_t *entry, *n;
+	unsigned int q;
+
+	if ((atomic_read(&mc->sel.count) == 0) ||
+	    list_empty(&(mc->sel.entries))) {
+		printk(KERN_INFO "SEL is empty.\n");
+		return VMC_SEL_LIST_EMPTY;
+	}
+
+	list_for_each_entry_safe(entry, n, &(mc->sel.entries), list) {
+		p = (unsigned char *) entry;
+		printk(KERN_INFO "SEL %d: ", i++);
+		for (k = 0; k < 4; k++) {
+			for (m = 0; m < 4; m++)
+				printk("%02x", p[(k * 4) + m]);
+			printk(" ");
+		}
+		printk("\n");
+
+		printk(KERN_INFO "Record Id, Type, Timestamp:%04x %02x %08x\n",
+			entry->recid, entry->type, entry->timestamp);
+		printk(KERN_INFO "Id_Type, Id_IPMB          :%02x %02x\n",
+			entry->id_type, entry->id_ipmb << 1);
+		printk(KERN_INFO "IPMB_LUN, Res, Channel    :%02x %02x %02x\n",
+			entry->ipmb_lun, entry->res, entry->chan);
+		printk(KERN_INFO "Sensor Number, Type       :%02x %02x\n",
+			entry->sensornum, entry->sensortype);
+		printk(KERN_INFO "Event Dir, Type, Offset   :%02x %02x %02x\n",
+			entry->event_dir, entry->event_type,
+			entry->sel_event_data.event_data[0]);
+
+		if ((entry->extended_event_length > 0) &&
+			entry->extended_event_data){
+			p = (unsigned char *)(entry->extended_event_data);
+			q = 0;
+			printk(KERN_INFO "Extended Data: ");
+			for (k = 0;
+			     k < ((sizeof(entry->extended_event_length)/4) + 1);
+			     k++) {
+				for (m = 0; m < 4; m++) {
+					printk("%02x", p[(k * 4) + m]);
+					if (++q == entry->extended_event_length)
+						break;
+				}
+				printk(" ");
+			}
+			printk("\n");
+		}
+		printk("\n");
+	}
+#endif
+
+	return VMC_NO_ERROR;
+}
+
+void ipmi_emu_dump_main_sdr(lmc_data_t *mc)
+{
+	vMC_ipmi_sdr_t *entry, *n;
+	unsigned int i = 0;
+
+	if (list_empty(&(mc->main_sdrs.sdrs))) {
+		printk(KERN_INFO "Main SDR is empty.\n");
+		return;
+	}
+	list_for_each_entry_safe(entry, n, &(mc->main_sdrs.sdrs), list) {
+		ipmi_emu_dump_sdr(entry, i, "Main");
+		i++;
+	}
+	return;
+}
+
+void ipmi_emu_dump_dev_sdr(lmc_data_t *mc)
+{
+	vMC_ipmi_sdr_t *entry, *n;
+	unsigned int i = 0, j;
+	unsigned char name[20];
+
+	for (j = 0; j < 4; j++) {
+		if (list_empty(&(mc->device_sdrs[j].sdrs))) {
+			printk(KERN_INFO "LUN %d SDR is empty.\n", j);
+			continue;
+		}
+		list_for_each_entry_safe(entry, n, &(mc->device_sdrs[j].sdrs),
+					 list) {
+			sprintf(name, "LUN %d", j);
+			ipmi_emu_dump_sdr(entry, i, name);
+			i++;
+		}
+		i = 0;
+	}
+	return;
+}
diff --git a/drivers/char/ipmi/vmc_emu.h b/drivers/char/ipmi/vmc_emu.h
new file mode 100644
index 0000000..a361a86
--- /dev/null
+++ b/drivers/char/ipmi/vmc_emu.h
@@ -0,0 +1,412 @@
+/*
+ * Wind River IPMI virtual Management Controller
+ *
+ * The virtual Management Controller (vMC) implements a subset of an IPMI
+ * Baseboard Management Controller (BMC) in a kernel module. The vMC
+ * plugs into the OpenIPMI KLM which makes it look like a normal
+ * IPMI management controller to user applications.
+ *
+ * This file contains common type definitions that are used by the various
+ * vMC components.
+ *
+ * Author: MontaVista Software, Inc.
+ *         Corey Minyard <minyard@mvista.com>
+ *         source@mvista.com
+ *
+ * Copyright 2003 MontaVista Software Inc.
+ * Portions Copyright 2005 Wind River Systems
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2 of the License, or (at your
+ *  option) any later version.
+ *
+ *
+ *  THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
+ *  WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
+ *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
+ *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+ *  BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
+ *  OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ *  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
+ *  TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ *  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/vmc.h>
+#include <linux/ipmi.h>
+#include <linux/interrupt.h>
+#include <linux/ipmi_smi.h>
+#include <asm/atomic.h>
+
+#define IPMI_SEL_DATA_LENGTH	16
+#define SEL_MAX_EXTENDED_DATA_LENGTH sizeof(struct fault_record_s)
+#define PMEM_SEL_DATA_LENGTH \
+	(IPMI_SEL_DATA_LENGTH + SEL_MAX_EXTENDED_DATA_LENGTH)
+#define KERNEL_SEL_DATA_LENGTH \
+	(sizeof(vMC_ipmi_sel_record_t) + SEL_MAX_EXTENDED_DATA_LENGTH)
+
+/* #define VMC_DEBUG 1 */
+
+/* IPMI 1.5 SDR version numbers */
+#define SDR_VER_IPMI15        0x51
+#define SDR_VER_MINOR_IPMI15  0x5
+#define SDR_VER_MAJOR_IPMI15  0x1
+
+/* This data structure used as "data" for the timer and tasklet functions */
+struct vMC_tasklet_data {
+	struct tasklet_struct tlet;
+	int hi;			/* tasklet or tasklet_hi */
+	struct list_head list;
+};
+
+#define IPMI_MAX_CHANNELS 8
+typedef struct lmc_channel_info_s {
+	unsigned char medium_type;
+	unsigned char protocol_type;
+	unsigned char session_support;
+} lmc_channel_info_t;
+
+struct sel_s {
+	struct list_head entries;
+	atomic_t count;
+	int max_count;
+	uint32_t last_add_time;
+	uint32_t last_erase_time;
+	unsigned char flags;
+	uint16_t reservation;
+	uint16_t next_entry;
+	long time_offset;
+	int enabled;
+	atomic_t wrapped;
+	spinlock_t lock;
+	struct kmem_cache *selCache;
+	struct semaphore sem;
+};
+typedef struct sel_s sel_t;
+
+#define MAX_NUM_SDRS   1024
+typedef struct sdrs_s {
+	uint16_t reservation;
+	uint16_t sdr_count;
+	uint16_t sensor_count;
+	uint32_t last_add_time;
+	uint32_t last_erase_time;
+	long time_offset;
+	unsigned char flags;
+	uint16_t next_entry;
+	unsigned int sdrs_length;
+	spinlock_t lock;
+	struct semaphore sem;
+
+	/* A linked list of SDR entries. */
+	struct list_head sdrs;
+} sdrs_t;
+
+typedef struct sensor_rate_s {
+	unsigned long long nsec;
+	struct list_head link;
+} sensor_rate_t;
+
+typedef struct sensor_s sensor_t;
+struct sensor_s {
+	uint16_t value;
+	unsigned char cvalue;
+
+#define			SENSOR_INCREASING 0
+#define         SENSOR_DECREASING 1
+#define         SENSOR_UNCHANGED  2
+	unsigned int direction;
+	unsigned int M;
+	unsigned int B;
+	unsigned int deleted;
+	signed int refcount;
+	spinlock_t lock;
+	struct semaphore sem;
+	struct list_head timestamps;
+
+	unsigned char event_status[15];
+	uint16_t thresholds[6];
+
+	/* Called when the sensor changes values. */
+	void (*sensor_update_handler) (sensor_t *sensor);
+
+	vMC_ipmi_sdr_t *sdr;	/* Associated SDR entry */
+	lmc_data_t *mc;		/* Associated MC */
+};
+
+typedef struct led_data_s {
+	unsigned char off_dur;
+	unsigned char def_off_dur;
+	unsigned char on_dur;
+	unsigned char def_on_dur;
+	unsigned char color;
+	unsigned char color_sup;
+	unsigned char loc_cnt;
+	unsigned char loc_cnt_sup;
+	unsigned char def_loc_cnt_color;
+	unsigned char def_override_color;
+} led_data_t;
+
+typedef struct fru_data_s {
+	unsigned int length;
+	unsigned char *data;
+} fru_data_t;
+
+typedef struct atca_site_s {
+	unsigned char valid;
+	unsigned char hw_address;
+	unsigned char site_type;
+	unsigned char site_number;
+} atca_site_t;
+
+#define MAX_MCS 128
+#define MAX_LUNS_SUPPORTED 4
+typedef struct emu_data_s {
+	int bmc_mc;
+	lmc_data_t *ipmb[MAX_MCS];
+
+	int atca_mode;
+	atca_site_t atca_sites[MAX_MCS];	/* Indexed by HW address. */
+
+	void *user_data;
+} emu_data_t;
+
+struct lmc_data_s {
+	emu_data_t *emu;
+
+	int enabled;
+
+	unsigned char ipmb;
+
+	/* Get Device Id contents. */
+	unsigned char device_id;	/* byte 2 */
+	unsigned char has_device_sdrs;	/* byte 3, bit 7 */
+	unsigned char device_revision;	/* byte 3, bits 0-6 */
+	unsigned char major_fw_rev;	/* byte 4, bits 0-6 */
+	unsigned char minor_fw_rev;	/* byte 5 */
+	unsigned char device_support;	/* byte 7 */
+	unsigned char mfg_id[3];	/* bytes 8-10 */
+	unsigned char product_id[2];	/* bytes 11-12 */
+
+	lmc_channel_info_t chans[IPMI_MAX_CHANNELS];
+
+	sel_t sel;
+
+	sdrs_t main_sdrs;
+	int in_update_mode;
+
+	unsigned char event_receiver;
+	unsigned char event_receiver_lun;
+	unsigned char channel;
+
+	sdrs_t device_sdrs[MAX_LUNS_SUPPORTED];
+	unsigned int dynamic_sensor_population:1;
+	unsigned int sensors_enabled:1;
+	unsigned int smiMissed:1;
+	unsigned char global_enables;
+	unsigned char lun_has_sensors[MAX_LUNS_SUPPORTED];
+	unsigned char num_sensors_per_lun[MAX_LUNS_SUPPORTED];
+	unsigned char init_lun[MAX_LUNS_SUPPORTED];
+	sensor_t *(sensors[MAX_LUNS_SUPPORTED][255]);
+	uint32_t sensor_population_change_time;
+
+	fru_data_t frus[255];
+
+	spinlock_t lock;
+};
+
+extern int vmc_mem_allocs, vmc_mem_frees;
+
+static inline void *
+vmc_kmalloc(size_t size, int flags)
+{
+	++vmc_mem_allocs;
+	return kmalloc(size, flags);
+}
+
+static inline void
+vmc_kfree(const void *objp)
+{
+	++vmc_mem_frees;
+	kfree(objp);
+}
+
+int ipmi_emu_alloc(void *user_data);
+void ipmi_emu_free(void);
+
+void ipmi_request_events(void);
+void send_event_buffer(struct ipmi_smi_msg *msg);
+
+void ipmi_emu_handle_msg(struct ipmi_smi_msg *msg);
+
+int ipmi_emu_add_mc(unsigned char ipmb,
+		    unsigned char channel,
+		    unsigned char device_id,
+		    unsigned char has_device_sdrs,
+		    unsigned char device_revision,
+		    unsigned char major_fw_rev,
+		    unsigned char minor_fw_rev,
+		    unsigned char device_support,
+		    unsigned char mfg_id[3],
+		    unsigned char product_id[2],
+		    unsigned char dynamic_sensor_population);
+
+void ipmi_emu_delete_mc(lmc_data_t *mc);
+
+void ipmi_mc_disable(lmc_data_t *mc);
+void ipmi_mc_enable(lmc_data_t *mc);
+
+int ipmi_emu_set_bmc_mc(unsigned char ipmb);
+
+unsigned char ipmi_emu_get_mc_addr(lmc_data_t *mc);
+
+int ipmi_emu_get_mc_by_addr(unsigned char ipmb, lmc_data_t **mc);
+
+int ipmi_mc_enable_sel(lmc_data_t *mc, int max_entries, unsigned char flags);
+
+int ipmi_mc_disable_sel(lmc_data_t *mc);
+
+int ipmi_mc_add_main_sdr(vMC_ipmi_sdr_t *sdr);
+
+int ipmi_mc_add_device_sdr(vMC_ipmi_sdr_t *sdr);
+
+int ipmi_mc_add_sel_cmd(vMC_ipmi_sel_record_t *vMC_sel_record);
+
+int ipmi_mc_add_sel_cmd_mcsafe(vMC_ipmi_sel_record_t *vMC_sel_record);
+
+int ipmi_mc_sensor_set_bit(vMC_ipmi_sensor_ident_t *sensor_ident,
+			   unsigned int bit, unsigned int val,
+			   vMC_ipmi_sel_record_t *vMC_sel_record);
+
+int ipmi_mc_sensor_set_value(vMC_ipmi_sensor_ident_t *sensor_ident,
+			     unsigned char value,
+			     vMC_ipmi_sel_record_t *vMC_sel_record);
+
+int ipmi_mc_sensor_inc_value(vMC_ipmi_sensor_ident_t *sensor_ident,
+			     unsigned char value,
+			     vMC_ipmi_sel_record_t *vMC_sel_record);
+
+int ipmi_mc_sensor_inc_value_mcsafe(vMC_ipmi_sensor_ident_t *sensor_ident,
+				    unsigned char value,
+				    vMC_ipmi_sel_record_t *vMC_sel_record);
+
+int ipmi_mc_sensor_dec_value(vMC_ipmi_sensor_ident_t *sensor_ident,
+			     unsigned char value,
+			     vMC_ipmi_sel_record_t *vMC_sel_record);
+
+int ipmi_mc_sensor_set_hysteresis(vMC_ipmi_sensor_ident_t *sensor_ident,
+				  unsigned char support,
+				  unsigned char positive,
+				  unsigned char negative);
+
+int ipmi_mc_sensor_set_threshold(vMC_ipmi_sensor_ident_t *sensor_ident,
+				 unsigned char support,
+				 unsigned char readmask,
+				 unsigned char setmask, unsigned char *values);
+
+int ipmi_mc_sensor_set_event_support(vMC_ipmi_sensor_ident_t *sensor_ident,
+				     unsigned char support,
+				     unsigned int assertions_supported,
+				     unsigned int deassertions_supported);
+
+int ipmi_mc_add_sensor(lmc_data_t *mc,
+		       unsigned char lun,
+		       unsigned char sens_num,
+		       unsigned char type, unsigned char event_reading_code);
+
+int ipmi_mc_add_fru_data(lmc_data_t *mc,
+			 unsigned char device_id,
+			 unsigned int length,
+			 unsigned char *data, unsigned int data_len);
+
+int ipmi_emu_set_mc_channel(lmc_data_t *mc,
+			    unsigned char channel,
+			    unsigned char medium_type,
+			    unsigned char protocol_type,
+			    unsigned char session_support);
+
+int ipmi_emu_dump_sel(lmc_data_t *mc);
+void ipmi_emu_dump_dev_sdr(lmc_data_t *mc);
+void ipmi_emu_dump_main_sdr(lmc_data_t *mc);
+
+void ipmi_emu_atca_enable(void);
+int ipmi_emu_atca_set_site(unsigned char hw_address,
+			   unsigned char site_type, unsigned char site_number);
+
+int ipmi_emu_cmd(char *cmd_str);
+
+void ipmi_add_to_sel(struct vMC_tasklet_data *sel_tasklet);
+int ipmi_mc_delete_device_sdr(vMC_ipmi_sensor_ident_t *sensid);
+int ipmi_mc_sensor_set_external_event_mask(vMC_ipmi_sensor_ident_t *
+					   sensor_ident, unsigned char mask);
+int ipmi_mc_sensor_get_value(vMC_ipmi_sensor_ident_t *sensor_ident,
+			     unsigned int *val);
+
+void ipmi_mc_set_device_id(lmc_data_t *mc, unsigned char device_id);
+
+unsigned char ipmi_mc_get_device_id(lmc_data_t *mc);
+
+enum vMC_kapi_cmd {
+	DELETE_DEVICE_SDR,
+	SENSOR_SET_BIT,
+	SENSOR_SET_VALUE,
+	SENSOR_SET_VALUE_IN,
+	SENSOR_SET_VALUE_DE,
+	SENSOR_SET_VALUE_LEAKING,
+	SENSOR_SET_HYSTERESIS,
+	SENSOR_SET_THRESHOLD,
+	SENSOR_SET_EVENT_SUPPORT,
+	SEL_ADD_CMD,
+	IPMI_SEND_CMD
+};
+typedef struct vMC_kapi_cmd_s {
+	enum vMC_kapi_cmd cmd;
+	unsigned char bit;
+	unsigned char value;
+	unsigned char support;
+	unsigned char positive;
+	unsigned char negative;
+	unsigned char readmask;
+	unsigned char setmask;
+	unsigned char thresholds[6];
+	unsigned int assertions;
+	unsigned int deassertions;
+	vMC_ipmi_sel_record_t *selr;
+	vMC_ipmi_sensor_ident_t *ident;
+	struct ipmi_smi_msg *smiMsg;
+	lmc_data_t *mc;
+	sensor_t *s;
+	struct list_head link;
+} vMC_kapi_cmd_t;
+
+void kapicmd(vMC_kapi_cmd_t *kapi_cmd);
+void kapicmd_mcsafe(vMC_kapi_cmd_t *kapi_cmd);
+
+void kapi_handle_msg(vMC_kapi_cmd_t *kapi_cmd);
+
+void vMC_free_sel_record(vMC_ipmi_sel_record_t *vMC_sel_record);
+
+extern void (*vMC_containment_handler[16]) (void);
+
+extern void dump_mem(char *title, void *mem, int len);
+
+extern int vmcDebug;
+
+extern struct vMC_tasklet_data sel_tasklet;
+
+/* Used by Kernel API */
+extern struct vMC_tasklet_data sel_tasklet;
+extern void register_vMC_stubs(void);
+extern int vmcDebug;
+extern void ipmi_add_to_sel_tlet(vMC_ipmi_sel_record_t *vMC_sel_record);
+
+/* Used by vmc_main */
+extern void register_vMC_api(void);
+extern void unregister_vMC_api(void);
+extern int wdt_reset(void);
diff --git a/drivers/char/ipmi/vmc_ipmb.c b/drivers/char/ipmi/vmc_ipmb.c
new file mode 100644
index 0000000..bb01d8f
--- /dev/null
+++ b/drivers/char/ipmi/vmc_ipmb.c
@@ -0,0 +1,256 @@
+/*
+ * Wind River IPMI virtual Management Controller mainline
+ *
+ * The virtual Management Controller (vMC) implements a subset of an IPMI
+ * Baseboard Management Controller (BMC) in a kernel module. The vMC
+ * plugs into the OpenIPMI KLM which makes it look like a normal
+ * IPMI management controller to user applications.
+ *
+ * This file contains common type definitions that are used to
+ * send critical events on the IPMB to the Shelf Manager
+ *
+ * Author: Wind River Systems
+ *         Chris Stone <christopher.stone@windriver.com>
+ *
+ * Copyright 2005 Wind River Systems
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2 of the License, or (at your
+ *  option) any later version.
+ *
+ *
+ *  THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
+ *  WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
+ *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
+ *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+ *  BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
+ *  OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ *  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
+ *  TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ *  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/spinlock.h>
+#include <linux/ipmi.h>
+#include "vmc_emu.h"
+#include "vmc_smi.h"
+#include "vmc_ipmb.h"
+
+struct bmc_private {
+	ipmi_user_t             user;
+	spinlock_t              recv_msg_lock;
+	struct list_head        recv_msgs;
+	wait_queue_head_t       wait;
+	struct semaphore        recv_sem;
+	int                     default_retries;
+	unsigned int            default_retry_time_ms;
+	struct ipmi_system_interface_addr  bmc_addr;
+	int                     if_num;
+	struct list_head        link;
+};
+
+long bmc_msgid;
+
+LIST_HEAD(ipmi_intfq);
+
+/* OpenIPMI handler for BMC response messages */
+void bmc_receive_handler(struct ipmi_recv_msg *msg, void *handler_data)
+{
+	/* struct bmc_private *priv = handler_data; */
+
+	if (vmcDebug) {
+		dump_mem("BMC response", (void *) msg->msg_data, 4);
+		printk(KERN_INFO "Response msg id = %ld\n", msg->msgid);
+	}
+	msg->done(msg);
+}
+
+struct kernel_ipmi_msg *format_bmc_message(vMC_ipmi_sel_record_t *selR)
+{
+	struct kernel_ipmi_msg *msg = kmalloc(sizeof(struct kernel_ipmi_msg),
+			GFP_KERNEL);
+
+	if (msg == NULL)
+		return NULL;
+	msg->netfn    = 0x2e;	/* IPMI NetFn (OEM Group) */
+	msg->cmd      = 0xf0;	/* Motorola OEM command F0
+				 * (Send Firmware Progress State) */
+	msg->data_len = 6;
+	msg->data = kmalloc(6, GFP_KERNEL);
+	if (msg->data == NULL) {
+		kfree(msg);
+		return NULL;
+	}
+	msg->data[0]  = 0x00; /* Motorola IANA codes */
+	msg->data[1]  = 0x00;
+	msg->data[2]  = 0xa1;
+	msg->data[3]  = 0x00; /* Event data 1 */
+	msg->data[4]  = 0x04; /* Event data 2 */
+	msg->data[5]  = 0xff; /* Event data 3 */
+	return msg;
+}
+
+struct ipmi_user_hndl ipmi_hndlrs = {
+	.ipmi_recv_hndl	= bmc_receive_handler,
+};
+
+int bmc_send_event_msg(vMC_ipmi_sel_record_t *selR)
+{
+	struct kernel_ipmi_msg	*msg;
+	struct bmc_private	*entry, *n;
+	int			rc = VMC_NO_ERROR;
+
+	/* send the message */
+	if (!list_empty(&ipmi_intfq)) {
+		list_for_each_entry_safe(entry, n, &ipmi_intfq, link) {
+			msg = format_bmc_message(selR);
+			if (msg == NULL) {
+				printk(KERN_ERR "vMC: Can not allocate " \
+					" critical fault message at %s:%d\n",
+					__FILE__, __LINE__);
+				return VMC_ENOMEM;
+			}
+			if (vmcDebug) {
+				/* Print contents of msg, including msg->data
+				 * (7 bytes of SEL data) */
+				dump_mem("BMC request", (void *) msg,
+					sizeof(struct kernel_ipmi_msg));
+				dump_mem("BMC request", (void *) msg->data, 7);
+			}
+			rc = ipmi_request_settime(entry->user,
+				(struct ipmi_addr *) &(entry->bmc_addr),
+				bmc_msgid++, msg, NULL,	2,
+				entry->default_retries,
+				entry->default_retry_time_ms);
+
+			if (vmcDebug) {
+				printk(KERN_INFO "Sent message to BMC on " \
+				"interface %d, rc=%d\n", entry->if_num, rc);
+			}
+			/* Collect all errors under one VMC error code */
+			if (rc)
+				rc = VMC_EINVAL;
+
+			kfree(msg->data);
+			kfree(msg);
+		}
+	}
+
+	return rc;
+}
+
+void ipmi_new_smi(int if_num, struct device *device)
+{
+	struct bmc_private *bmc_priv;
+	int rc;
+
+	/* Bypass vMC itself */
+	if (strcmp(device->driver->name, VMC_DEVICE_NAME) == 0) {
+		if (vmcDebug) {
+			printk(KERN_INFO "vMC: Ignoring registration of IPMI " \
+				"interface number %d\n", if_num);
+		}
+		return;
+	}
+
+	/* Register ourselves as a user of the BMC interface. */
+	bmc_priv = vmc_kmalloc(sizeof(*bmc_priv), GFP_KERNEL);
+	if (!bmc_priv)
+		return;
+
+	bmc_priv->if_num = if_num;
+
+	/* Use the low-level defaults. */
+	bmc_priv->default_retries = -1;
+	bmc_priv->default_retry_time_ms = 0;
+
+	/* Set up the BMC address field */
+	bmc_priv->bmc_addr.addr_type  = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;
+	bmc_priv->bmc_addr.channel    = 0x00;
+	bmc_priv->bmc_addr.lun        = 0x00;
+
+	spin_lock_init(&(bmc_priv->recv_msg_lock));
+	INIT_LIST_HEAD(&(bmc_priv->recv_msgs));
+	init_waitqueue_head(&bmc_priv->wait);
+	sema_init(&(bmc_priv->recv_sem), 1);
+
+	rc = ipmi_create_user(if_num, &ipmi_hndlrs,
+		bmc_priv, &(bmc_priv->user));
+
+	if (rc) {
+		printk(KERN_ERR "vMC: Unable to open channel to BMC device: " \
+			"error %d\n", rc);
+		vmc_kfree(bmc_priv);
+	}
+
+	list_add_tail(&bmc_priv->link, &ipmi_intfq);
+
+	if (vmcDebug)
+		printk(KERN_INFO "vMC: Registered IPMI user on BMC interface " \
+			"number %d\n", if_num);
+}
+
+void ipmi_smi_gone(int if_num)
+{
+	struct bmc_private *entry, *n;
+
+	if (!list_empty(&ipmi_intfq)) {
+		list_for_each_entry_safe(entry, n, &ipmi_intfq, link) {
+			if (if_num == entry->if_num) {
+				ipmi_destroy_user(entry->user);
+				list_del(&(entry->link));
+				vmc_kfree(entry);
+				break;
+			}
+		}
+	}
+
+	if (vmcDebug)
+		printk(KERN_INFO "vMC: Unregistered IPMI user on BMC " \
+			"interface number %d\n", if_num);
+}
+
+struct ipmi_smi_watcher vmc_smi_watcher = {
+	.owner    = THIS_MODULE,
+	.new_smi  = ipmi_new_smi,
+	.smi_gone = ipmi_smi_gone
+};
+
+int vmc_ipmb_init()
+{
+	int rc = 0;
+
+	/* Initialize a list to hold registered IPMI interfaces */
+	INIT_LIST_HEAD(&ipmi_intfq);
+
+	rc = ipmi_smi_watcher_register(&vmc_smi_watcher);
+
+	if (rc < 0)
+		printk(KERN_ERR "vMC: can't register smi watcher\n");
+
+	return rc;
+}
+
+int vmc_ipmb_exit()
+{
+	struct bmc_private *entry, *n;
+
+	/* Free BMC registrations */
+	if (!list_empty(&ipmi_intfq)) {
+		list_for_each_entry_safe(entry, n, &ipmi_intfq, link) {
+			list_del(&(entry->link));
+			ipmi_destroy_user(entry->user);
+			vmc_kfree(entry);
+		}
+	}
+
+	ipmi_smi_watcher_unregister(&vmc_smi_watcher);  /* always returns 0 */
+
+	return 0;
+}
diff --git a/drivers/char/ipmi/vmc_ipmb.h b/drivers/char/ipmi/vmc_ipmb.h
new file mode 100644
index 0000000..d7e8efb
--- /dev/null
+++ b/drivers/char/ipmi/vmc_ipmb.h
@@ -0,0 +1,46 @@
+/*
+ * Wind River IPMI virtual Management Controller
+ *
+ * The virtual Management Controller (vMC) implements a subset of an IPMI
+ * Baseboard Management Controller (BMC) in a kernel module. The vMC
+ * plugs into the OpenIPMI KLM which makes it look like a normal
+ * IPMI management controller to user applications.
+ *
+ * This file contains common type definitions that are used to
+ * send critical events on the IPMB to the Shelf Manager
+ *
+ * Author: MontaVista Software, Inc.
+ *         Corey Minyard <minyard@mvista.com>
+ *         source@mvista.com
+ *
+ * Copyright 2003 MontaVista Software Inc.
+ * Portions Copyright 2005 Wind River Systems
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2 of the License, or (at your
+ *  option) any later version.
+ *
+ *
+ *  THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
+ *  WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
+ *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
+ *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+ *  BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
+ *  OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ *  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
+ *  TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ *  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+extern struct ipmi_smi_watcher vmc_smi_watcher;
+
+extern int bmc_send_event_msg(vMC_ipmi_sel_record_t *selR);
+
+int vmc_ipmb_init(void);
+int vmc_ipmb_exit(void);
diff --git a/drivers/char/ipmi/vmc_kapi.c b/drivers/char/ipmi/vmc_kapi.c
new file mode 100644
index 0000000..51c7907
--- /dev/null
+++ b/drivers/char/ipmi/vmc_kapi.c
@@ -0,0 +1,374 @@
+/*
+ * Wind River IPMI virtual Management Controller
+ *
+ * The virtual Management Controller (vMC) implements a subset of an IPMI
+ * Baseboard Management Controller (BMC) in a kernel module. The vMC
+ * plugs into the OpenIPMI KLM which makes it look like a normal
+ * IPMI management controller to user applications.
+ *
+ * This file contains vMC's Kernel API. Device drivers use this API in this
+ * to perform IPMI operations.
+ *
+ * Author: Wind River Systems
+ *         Chris Stone <christopher.stone@windriver.com>
+ *
+ * Copyright 2005 Wind River Systems
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2 of the License, or (at your
+ *  option) any later version.
+ *
+ *
+ *  THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
+ *  WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
+ *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
+ *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+ *  BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
+ *  OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ *  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
+ *  TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ *  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/ipmi_bits.h>
+#include "vmc_emu.h"
+
+/*
+ *  Virtual Management Controller Function API Implementation
+ */
+
+
+/* vMC_alloc_sel_record
+ *       Allocate storage for a vMC_ipmi_sel_record_t type. */
+static vMC_ipmi_sel_record_t *
+_vMC_alloc_sel_record(unsigned int extended_data_length,
+		      unsigned char mc_ipmb, int *rc)
+{
+	vMC_ipmi_sel_record_t *p;
+	unsigned char *pchar;
+	lmc_data_t *mc;
+	*rc = VMC_NO_ERROR;
+
+	if (extended_data_length > SEL_MAX_EXTENDED_DATA_LENGTH) {
+		*rc = VMC_ENOMEM;
+		return NULL;
+	}
+
+	if (ipmi_emu_get_mc_by_addr(mc_ipmb, &mc)) {
+		*rc = VMC_INVALID_MC;
+		return NULL;
+	}
+
+	p = kmem_cache_alloc(mc->sel.selCache, GFP_ATOMIC);
+	if (p) {
+		memset(p, 0, KERNEL_SEL_DATA_LENGTH);
+		if (extended_data_length) {
+			pchar = (unsigned char *) p;
+			p->extended_event_data =
+			    pchar + sizeof(vMC_ipmi_sel_record_t);
+		} else
+			p->extended_event_data = NULL;
+		p->extended_event_length = extended_data_length;
+		p->mc = mc;
+		INIT_LIST_HEAD(&p->list);
+	} else
+		*rc = VMC_ENOMEM;
+
+	return p;
+}
+
+
+/* vMC_free_sel_record
+ *      Free a vMC_ipmi_sel_record_t. */
+void vMC_free_sel_record(vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	if (vMC_sel_record == NULL)
+		return;
+
+	kmem_cache_free(vMC_sel_record->mc->sel.selCache, vMC_sel_record);
+}
+
+
+/* vMC_alloc_sdr_record
+ *   Allocate storage for a vMC_ipmi_sdr_t type. */
+static vMC_ipmi_sdr_t *
+_vMC_alloc_sdr_record(unsigned char mc_ipmb, unsigned char record_type, int *rc)
+{
+	vMC_ipmi_sdr_t *sdr;
+	lmc_data_t *mc;
+
+	*rc = VMC_NO_ERROR;
+
+	if (ipmi_emu_get_mc_by_addr(mc_ipmb, &mc)) {
+		*rc = VMC_INVALID_MC;
+		return NULL;
+	}
+
+	sdr = vmc_kmalloc(sizeof(vMC_ipmi_sdr_t), GFP_KERNEL);
+	if (sdr) {
+		memset(sdr, 0, sizeof(vMC_ipmi_sdr_t));
+		sdr->sdr_hdr.sdr_major_version = SDR_VER_MAJOR_IPMI15;
+		sdr->sdr_hdr.sdr_minor_version = SDR_VER_MINOR_IPMI15;
+		sdr->sdr_hdr.record_type = record_type;
+		sdr->mc = mc;
+		INIT_LIST_HEAD(&sdr->list);
+	} else
+		*rc = VMC_ENOMEM;
+
+	return sdr;
+}
+
+
+/* vMC_sel_add
+ *   Add the given event to the SEL of the vMC.  This command may also send the
+ *   IPMI portion of the event to an onboard BMC chipset. */
+static int _vMC_sel_add(vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	/* Verify the record */
+	if ((vMC_sel_record->type != IPMI_SEL_SYS_TYPE) &&
+	    (vMC_sel_record->type < IPMI_SEL_OEM_TYPE))
+		return VMC_INVALID_RECORD_TYPE;
+
+	if (vMC_sel_record->evmrev != IPMI_EM_V15_VERSION)
+		return VMC_INVALID_EVENT_MSG_FORMAT;
+
+	/*ipmi_add_to_sel_tlet(vMC_sel_record); wrote pmem/LList, and northbound*/
+
+	ipmi_mc_add_sel_cmd(vMC_sel_record);
+
+	return VMC_NO_ERROR;
+}
+
+/* Same as above, but safe to call from a machine-check  level. */
+static int _vMC_sel_add_mcsafe(vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	/* Verify the record */
+	if ((vMC_sel_record->type != IPMI_SEL_SYS_TYPE) &&
+	    (vMC_sel_record->type < IPMI_SEL_OEM_TYPE))
+		return VMC_INVALID_RECORD_TYPE;
+
+	if (vMC_sel_record->evmrev != IPMI_EM_V15_VERSION)
+		return VMC_INVALID_EVENT_MSG_FORMAT;
+
+	/*ipmi_add_to_sel_tlet(vMC_sel_record); wrote pmem/LList, and northbound*/
+
+	ipmi_mc_add_sel_cmd_mcsafe(vMC_sel_record);
+
+	return VMC_NO_ERROR;
+}
+
+
+/* vMC_device_sdr_add
+ *   Add the given SDR to the Device SDR Repository of the vMC. */
+static int _vMC_device_sdr_add(vMC_ipmi_sdr_t *vMC_sdr_record)
+{
+	if (vmcDebug) {
+		dump_mem("KAPI sdr add: ", (void *) vMC_sdr_record,
+			 sizeof(vMC_ipmi_sdr_t));
+	}
+	/* Verify the record */
+	if (!((vMC_sdr_record->sdr_hdr.record_type != IPMI_SDR_FULL_TYPE) ^
+	      (vMC_sdr_record->sdr_hdr.record_type != IPMI_SDR_OEM_TYPE)))
+		return VMC_INVALID_RECORD_TYPE;
+
+	if (vMC_sdr_record->sdr_hdr.record_type == IPMI_SDR_FULL_TYPE) {
+		if ((vMC_sdr_record->sdr_body.sdr_full.sensor_type > 0x29) &&
+		    (vMC_sdr_record->sdr_body.sdr_full.sensor_type < 0xC0))
+			return VMC_INVALID_SENSOR_TYPE;
+
+		if ((vMC_sdr_record->sdr_body.sdr_full.
+		     event_reading_type_code !=
+		     IPMI_EVENT_READING_TYPE_THRESHOLD)
+		    &&
+		    ((vMC_sdr_record->sdr_body.sdr_full.
+		      event_reading_type_code < 0x70)
+		     || (vMC_sdr_record->sdr_body.sdr_full.
+			 event_reading_type_code > 0x7f))
+		    && (vMC_sdr_record->sdr_body.sdr_full.
+			event_reading_type_code != 0x6f))
+			return VMC_INVALID_EVENT_TYPE;
+	}
+	/* Add record to appropriate SDR */
+	return ipmi_mc_add_device_sdr(vMC_sdr_record);
+}
+
+
+/* vMC_device_sdr_delete
+ *   Delete the given SDR from the Device SDR Repository of the vMC. */
+static int _vMC_device_sdr_delete(vMC_ipmi_sensor_ident_t *sensor_ident)
+{
+	return ipmi_mc_delete_device_sdr(sensor_ident);
+}
+
+
+/* vMC_sensor_get_threshold_value
+ *   Read current value of a threshold sensor */
+static int _vMC_sensor_get_value(vMC_ipmi_sensor_ident_t *sensor_ident, unsigned int *val)
+{
+	return ipmi_mc_sensor_get_value(sensor_ident, val);
+}
+
+
+/* vMC_sensor_set_bit
+ *   Only for discrete sensors.  The lower 15 bits of the mask value will be
+ *   AND'd with the sensor value. Sensor bits can be set on or off by setting
+ *   the appropriate bit of the mask to 1 or 0. If a sensor bit changes value
+ *   and event notification is enabled a sensor event will be generated. The
+ *   extended_event_length may be zero, but if not, the contents of
+ *   extended_event_data will be added to the SEL */
+static int _vMC_sensor_set_bit(vMC_ipmi_sensor_ident_t *sensor_ident,
+			       unsigned bit, unsigned val,
+			       vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	return ipmi_mc_sensor_set_bit(sensor_ident, bit, val, vMC_sel_record);
+}
+
+
+/* vMC_sensor_set_value
+ *   Only for threshold sensors.  Set the sensor to the given value.
+ *   An event will be generated if the sensor crosses an enabled event
+ *   threshold. The extended_event_length may be zero, but if not, the
+ *   contents of extended_event_data will be added to the SEL */
+static int _vMC_sensor_set_value(vMC_ipmi_sensor_ident_t *sensor_ident,
+				 unsigned char value,
+				 vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	return ipmi_mc_sensor_set_value(sensor_ident, value, vMC_sel_record);
+}
+
+
+/* vMC_sensor_increment_value
+ *   Only for threshold sensors.  Increment the sensor value by value.
+ *   An event will be generated if the sensor crosses an enabled event
+ *   threshold. The extended_event_length may be zero, but if not, the contents
+ *   of extended_event_data will be added to the SEL. The event_bytes parameter
+ *   points to a three byte field that will be used to form the last three bytes
+ *   of the standard IPMI SEL record. */
+static int _vMC_sensor_increment_value(vMC_ipmi_sensor_ident_t *sensor_ident,
+				       unsigned char value,
+				       vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	return ipmi_mc_sensor_inc_value(sensor_ident, value, vMC_sel_record);
+}
+static int
+_vMC_sensor_increment_value_mcsafe(vMC_ipmi_sensor_ident_t *sensor_ident,
+				   unsigned char value,
+				   vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	return ipmi_mc_sensor_inc_value_mcsafe
+		(sensor_ident, value, vMC_sel_record);
+}
+
+
+/* vMC_sensor_decrement_value
+ *   Only for threshold sensors.  Decrement the sensor value by value.
+ *   An event will be generated if the sensor crosses an enabled event
+ *   threshold. The extended_event_length may be zero, but if not, the contents
+ *   of extended_event_data will be added to the SEL. The event_bytes parameter
+ *   points to a three byte field that will be used to form the last three bytes
+ *   of the standard IPMI SEL record. */
+static int _vMC_sensor_decrement_value(vMC_ipmi_sensor_ident_t *sensor_ident,
+				       unsigned char value,
+				       vMC_ipmi_sel_record_t *vMC_sel_record)
+{
+	return ipmi_mc_sensor_dec_value(sensor_ident, value, vMC_sel_record);
+}
+
+
+/* vMC_sensor_external_event_mask
+ *   This function masks event generation for the sensor over a physical IPMB
+ *   bus. */
+static int
+_vMC_sensor_external_event_mask(vMC_ipmi_sensor_ident_t *sensor_ident,
+				unsigned char mask)
+{
+	return ipmi_mc_sensor_set_external_event_mask(sensor_ident, mask);
+}
+
+
+/* vMC_sensor_set_hysteresis
+ *   Only for threshold sensors.  Set the hysteresis for the sensor.
+ *   <support> is the standard values from the SDR, which are:
+ *      0 - NO_HYSTERESIS
+ *      1 - HYSTERESIS_READABLE
+ *      2 - HYSTERESIS_READABLE_SETTABLE
+ *      3 - FIXED_UNREADABLE_HYSTERESIS
+ *   <pos> is the positive hysteresis value, and <neg> is the negative one */
+static int _vMC_sensor_set_hysteresis(vMC_ipmi_sensor_ident_t *sensor_ident,
+				      unsigned char support, unsigned char pos,
+				      unsigned char neg)
+{
+	return ipmi_mc_sensor_set_hysteresis(sensor_ident, support, pos, neg);
+}
+
+
+/* vMC_sensor_set_threshold
+ *   Only for threshold sensors. This sets the threshold support type, supported
+ *   thresholds, and initial values */
+static int _vMC_sensor_set_threshold(vMC_ipmi_sensor_ident_t *sensor_ident,
+				     unsigned char support,
+				     unsigned char readmask,
+				     unsigned char setmask, unsigned char *val)
+{
+	return ipmi_mc_sensor_set_threshold(sensor_ident, support, readmask,
+					    setmask, val);
+}
+
+
+/* vMC_sensor_set_event_support
+ *   Sets the event support for the sensors */
+static int _vMC_sensor_set_event_support(vMC_ipmi_sensor_ident_t *sensor_ident,
+					 unsigned char support,
+					 unsigned int assertions_supported,
+					 unsigned int deassertions_supported)
+{
+	return ipmi_mc_sensor_set_event_support(sensor_ident, support,
+						assertions_supported,
+						deassertions_supported);
+}
+
+
+/* register_vMC_api
+ *   Replace stub implementations of the vMC API with the real implementations
+ *   contained in this module. */
+void register_vMC_api(void)
+{
+	/* FIXME: _vMC_sensor_set_bit is broken and commented out below. See
+	 * comments at sensor_set_bit() definition in vmc_emu.c for details */
+	(void)_vMC_sensor_set_bit; /* suppress unused function warning */
+
+	vMC_alloc_sel_record = _vMC_alloc_sel_record;
+	vMC_alloc_sdr_record = _vMC_alloc_sdr_record;
+	vMC_sel_add = _vMC_sel_add;
+	vMC_sel_add_mcsafe = _vMC_sel_add_mcsafe;
+	vMC_device_sdr_add = _vMC_device_sdr_add;
+	vMC_device_sdr_delete = _vMC_device_sdr_delete;
+	vMC_sensor_get_value = _vMC_sensor_get_value;
+	/* vMC_sensor_set_bit = _vMC_sensor_set_bit; */
+	vMC_sensor_set_value = _vMC_sensor_set_value;
+	vMC_sensor_increment_value = _vMC_sensor_increment_value;
+	vMC_sensor_decrement_value = _vMC_sensor_decrement_value;
+	vMC_sensor_increment_value_mcsafe = _vMC_sensor_increment_value_mcsafe;
+	vMC_sensor_external_event_mask = _vMC_sensor_external_event_mask;
+	vMC_sensor_set_hysteresis = _vMC_sensor_set_hysteresis;
+	vMC_sensor_set_threshold = _vMC_sensor_set_threshold;
+	vMC_sensor_set_event_support = _vMC_sensor_set_event_support;
+}
+
+
+/* unregister_vMC_api
+ *   Replace vMC API implementations of the vMC API with the stub
+ *   implementations. This function must be called when the vMC module is
+ *   unloaded. */
+void unregister_vMC_api(void)
+{
+	register_vMC_stubs();
+}
diff --git a/drivers/char/ipmi/vmc_main.c b/drivers/char/ipmi/vmc_main.c
new file mode 100644
index 0000000..8eff0e5
--- /dev/null
+++ b/drivers/char/ipmi/vmc_main.c
@@ -0,0 +1,433 @@
+/*
+ * Wind River IPMI virtual Management Controller mainline
+ *
+ * The virtual Management Controller (vMC) implements a subset of an IPMI
+ * Baseboard Management Controller (BMC) in a kernel module. The vMC
+ * plugs into the OpenIPMI KLM which makes it look like a normal
+ * IPMI management controller to user applications.
+ *
+ * Author: Wind River Systems
+ *         Chris Stone <christopher.stone@windriver.com>
+ *
+ * Copyright 2005 Wind River Systems
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2 of the License, or (at your
+ *  option) any later version.
+ *
+ *
+ *  THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
+ *  WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
+ *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
+ *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+ *  BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
+ *  OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ *  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
+ *  TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ *  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+
+#include <linux/time.h>
+#include <linux/timer.h>
+#include <linux/kernel.h>
+#include <linux/proc_fs.h>
+#include <linux/types.h>
+#include <linux/spinlock.h>
+#include <linux/interrupt.h>
+#include <linux/workqueue.h>
+#include <linux/device.h>
+#include <linux/sysdev.h>
+#include <linux/kobject.h>
+#include <linux/sysfs.h>
+#include <linux/ipmi_smi.h>
+#include <linux/reboot.h>
+#include <linux/hardirq.h>
+#include <linux/cdev.h>
+#include <linux/uaccess.h> /* copy_from_user() */
+
+#include "vmc_emu.h"
+#include "vmc_ipmb.h"
+#include "vmc_smi.h"
+
+MODULE_AUTHOR("Wind River Systems");
+MODULE_LICENSE("GPL");
+
+int vmcDebug;
+module_param(vmcDebug, int, 0644);
+
+/* Oct 17/08  Was: 1.2.1 */
+/* Dec 22/09  Was: 1.2.2 */
+#define VMC_VERSION_NUMBER "1.2.3"
+#define VMC_CMDINTF_NAME "vmc"
+
+/*
+ * Data structures for the tasklets
+ * Hard-coded priority to high-add to beginning of queue
+ */
+struct vMC_tasklet_data sel_tasklet = {
+	.hi	= 1,
+	.list	= LIST_HEAD_INIT(sel_tasklet.list),
+};
+
+/*
+ *  Data structures for the Kernel API command workqueue
+ */
+static void vMC_workqueue_kapicmd(struct work_struct *work);
+struct workqueue_struct *kapiworkq;
+DECLARE_WORK(kapiwork, vMC_workqueue_kapicmd);
+LIST_HEAD(kapicmdq);
+LIST_HEAD(kapicmdq_mcsafe);
+static DEFINE_SPINLOCK(kapi_cmd_lock);
+static DEFINE_SPINLOCK(kapi_cmd_mcsafe_lock);
+
+/*
+ *  Data structures for sysfs files
+ */
+
+void send_event_buffer(struct ipmi_smi_msg *msg)
+{
+    vmc_smi_msg_received(msg);
+}
+
+/* Queue Kernel API commands to the workqueue */
+void kapicmd(vMC_kapi_cmd_t *kapi_cmd)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&kapi_cmd_lock, flags);
+	list_add_tail(&(kapi_cmd->link), &kapicmdq);
+	spin_unlock_irqrestore(&kapi_cmd_lock, flags);
+	queue_work(kapiworkq, &kapiwork);
+}
+
+/* Queue Kernel API commands to the workqueue, in a Machine Check-safe way */
+void kapicmd_mcsafe(vMC_kapi_cmd_t *kapi_cmd)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&kapi_cmd_mcsafe_lock, flags);
+	list_add_tail(&(kapi_cmd->link), &kapicmdq_mcsafe);
+	spin_unlock_irqrestore(&kapi_cmd_mcsafe_lock, flags);
+	queue_work(kapiworkq, &kapiwork);
+}
+
+/* Process Kernel API commands coming from fault drivers */
+static void vMC_workqueue_kapicmd(struct work_struct *work)
+{
+	vMC_kapi_cmd_t *msg;
+	unsigned long flags;
+
+	/* If there is nothing in either list, then all work is done. */
+	while (!list_empty(&kapicmdq)) {
+		/* Process one entry from the work list */
+		spin_lock_irqsave(&kapi_cmd_lock, flags);
+		msg = list_entry((&kapicmdq)->next, typeof(*msg), link);
+		list_del(&(msg->link));
+		spin_unlock_irqrestore(&kapi_cmd_lock, flags);
+		kapi_handle_msg(msg);
+		vmc_kfree(msg);
+	}
+	while (!list_empty(&kapicmdq_mcsafe)) {
+		/* Process one entry from the work list */
+		spin_lock_irqsave(&kapi_cmd_mcsafe_lock, flags);
+		msg = list_entry((&kapicmdq_mcsafe)->next, typeof(*msg), link);
+		list_del(&(msg->link));
+		spin_unlock_irqrestore(&kapi_cmd_mcsafe_lock, flags);
+		kapi_handle_msg(msg);
+		vmc_kfree(msg);
+	}
+}
+
+/* Process requests to add event logs */
+static void vMC_tasklet_sel(unsigned long arg)
+{
+	/* If there is nothing in the list, then all work is done. */
+	if (list_empty(&sel_tasklet.list))
+		return;
+
+	/* Process the work list */
+    ipmi_add_to_sel(&sel_tasklet);
+}
+
+struct vmc_device {
+	struct cdev cdev;	/* Char device structure */
+	dev_t dev;
+};
+
+static struct vmc_device *vmc_dev;
+
+ssize_t vmc_read(struct file *filp, char __user *buf,
+		size_t count, loff_t *f_pos)
+{
+	ssize_t retval = 0;
+	int resp_len;
+
+	resp_len = strlen(response);
+
+	if (*f_pos >= resp_len)
+		goto out;
+	if (*f_pos + count > resp_len)
+		count = resp_len - *f_pos;
+
+	if (copy_to_user(buf, response + *f_pos, count)) {
+		retval = -EFAULT;
+		goto out;
+	}
+	*f_pos += count;
+	retval = count;
+
+out:
+	return retval;
+}
+
+/* Emulator command interface */
+static void exec_emu_command(const char *cmd_buf)
+{
+	char *cmd, *cmdorig;
+
+	cmd = vmc_kmalloc(strlen(cmd_buf) + 1, GFP_KERNEL);
+	if (!cmd) {
+		printk(KERN_ERR "vMC out of memory at %d in %s\n",
+			__LINE__, __FILE__);
+		sprintf(response, "** vMC out of memory.");
+		return;
+	}
+	memcpy(cmd, cmd_buf, strlen(cmd_buf)+1);
+	cmdorig = cmd;
+	if (ipmi_emu_cmd(cmd))
+		printk(KERN_INFO "vMC Command error %s\n", response);
+	if (vmcDebug)
+		printk(KERN_INFO "%s response is %s\n", cmd_buf, response);
+	vmc_kfree(cmdorig);
+}
+
+ssize_t vmc_write(struct file *filp, const char __user *buf,
+		size_t count, loff_t *f_pos)
+{
+	ssize_t retval = -ENOMEM; /* value used in "goto out" statements */
+	char *input = NULL;
+
+	/* All writes must be to offset zero */
+	if (*f_pos) {
+		retval = -EINVAL;
+		goto out;
+	}
+
+	input = kmalloc(count + 1, GFP_KERNEL);
+
+	if (!input) {
+		retval = -ENOMEM;
+		goto out;
+	}
+
+	if (copy_from_user(input, buf, count)) {
+		retval = -EFAULT;
+		goto out;
+	}
+
+	input[count] = '\0';
+
+	exec_emu_command(input);
+
+	retval = count;
+out:
+	kfree(input);	/* kfree of NULL is fine */
+	return retval;
+}
+
+static const struct file_operations vmc_fops = {
+	.owner		= THIS_MODULE,
+	.read		= vmc_read,
+	.write		= vmc_write,
+};
+
+/*
+ * Create vMC char device interface.
+ * Multiple vMCs may exist, all of them would be setup through
+ * this device node, with different IPMB address
+ */
+static int create_vmc_device(void)
+{
+	int rc;
+
+	vmc_dev = kmalloc(sizeof(struct vmc_device), GFP_KERNEL);
+	if (!vmc_dev) {
+		printk(KERN_ERR
+			"%s: Could not allocate memory for vMC char device\n",
+			__func__);
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	rc = alloc_chrdev_region(&(vmc_dev->dev), 0, 1, VMC_CMDINTF_NAME);
+	if (rc < 0) {
+		printk(KERN_ERR
+			"%s: Could not alloc char device region for vMC: %d\n",
+			__func__, rc);
+		rc = -EINVAL;
+		goto fail_1;
+	}
+
+	cdev_init(&(vmc_dev->cdev), &vmc_fops);
+	rc = cdev_add(&(vmc_dev->cdev), vmc_dev->dev, 1);
+	if (rc < 0) {
+		printk(KERN_ERR
+			"%s: Could not add vMC char device: %d\n",
+			__func__, rc);
+		rc = -EINVAL;
+		goto fail_2;
+	}
+
+	rc = 0;
+	printk(KERN_INFO "vMC: char device interface installed\n");
+	goto out;
+
+fail_2:
+	unregister_chrdev_region(vmc_dev->dev, 1);
+fail_1:
+	kfree(vmc_dev);
+out:
+	return rc;
+}
+
+/* Destroy vMC char device interface */
+static void destroy_vmc_device(void)
+{
+	cdev_del(&(vmc_dev->cdev));
+
+	unregister_chrdev_region(vmc_dev->dev, 1);
+
+	kfree(vmc_dev);
+
+	printk(KERN_INFO "vMC: char device interface deleted\n");
+}
+
+int __init vMC_init(void)
+{
+	int rc;
+
+	/* Init counters to track kmallocs, kfrees */
+	vmc_mem_allocs = vmc_mem_frees = 0;
+
+	printk(KERN_INFO "Virtual Management Controller version %s\n",
+		VMC_VERSION_NUMBER);
+	printk(KERN_INFO "vMC: vmcDebug=%d\n", vmcDebug);
+
+	rc = create_vmc_device();
+	if (rc < 0) {
+		printk(KERN_ERR "vMC: Failed to create device: %d\n", rc);
+		goto out;
+	}
+
+	/* Replace stub functions with real implementations */
+	register_vMC_api();
+
+	/* Initialize emulator */
+	if (ipmi_emu_alloc(NULL)) {
+		printk(KERN_ERR "vMC: Unable to allocate emulator\n");
+		rc = -ENOMEM;
+		goto fail_1;
+	}
+	ipmi_emu_atca_enable();
+
+	/* Initialize tasklets to handle vMC SEL functions */
+	tasklet_init(&sel_tasklet.tlet, vMC_tasklet_sel, 0);
+
+	/*
+	 * Initialize a workqueue to process Kernel API requests
+	 * through vMC character device interface
+	 */
+	INIT_LIST_HEAD(&kapicmdq);
+	INIT_LIST_HEAD(&kapicmdq_mcsafe);
+	kapiworkq = create_singlethread_workqueue("kapicmd");
+	if (!kapiworkq) {
+		printk(KERN_ERR "vMC: Unable to create kapiworkq\n");
+		rc = -EINVAL;
+		goto fail_2;
+	}
+
+	/*
+	 * Initialize a workqueue to process IPMI messages
+	 * through vMC SMI interface
+	 */
+	rc = vmc_smi_init();
+	if (rc) {
+		printk(KERN_ERR "vMC: Failed to create ipmiworkq\n");
+		rc = -EINVAL;
+		goto fail_3;
+	}
+
+#ifdef CONFIG_IPMI_VMC_ENABLE_IPMB
+	rc = vmc_ipmb_init();
+	if (rc) {
+		printk(KERN_ERR "vMC: Failed to initialize vMC IPMB "
+			"connection: error %d\n", rc);
+		goto fail_4;
+	}
+#endif /* CONFIG_IPMI_VMC_ENABLE_IPMB */
+
+	printk(KERN_INFO "vMC: Initialization complete.\n");
+
+	rc = 0;
+	goto out;
+
+fail_4:
+	vmc_smi_exit();
+fail_3:
+	flush_workqueue(kapiworkq);
+	destroy_workqueue(kapiworkq);
+fail_2:
+	ipmi_emu_free();
+	tasklet_kill(&sel_tasklet.tlet);
+fail_1:
+	unregister_vMC_api();
+	destroy_vmc_device();
+out:
+	return rc;
+}
+
+void __exit vMC_cleanup(void)
+{
+#ifdef CONFIG_IPMI_VMC_ENABLE_IPMB
+	vmc_ipmb_exit();
+#endif /* CONFIG_IPMI_VMC_ENABLE_IPMB */
+
+	vmc_smi_exit();
+
+	/* Empty the Kernel API work queue list, waiting items are processed
+	 * (might create SEL entries) */
+	vMC_workqueue_kapicmd(NULL);
+
+	/* Now empty the SEL list */
+	vMC_tasklet_sel(0);
+
+	/* Clean up and Destroy Kernel API workqueue */
+	flush_workqueue(kapiworkq);
+	destroy_workqueue(kapiworkq);
+
+	/* Now remove tasklet */
+	tasklet_kill(&sel_tasklet.tlet);
+
+	/* Free memory allocated to the emulator */
+	ipmi_emu_free();
+
+	/* Set vMC api to point to stub functions */
+	unregister_vMC_api();
+
+	destroy_vmc_device();
+
+	printk(KERN_INFO "vMC: Uninitialization complete.\n");
+}
+
+module_init(vMC_init);
+module_exit(vMC_cleanup);
diff --git a/drivers/char/ipmi/vmc_smi.c b/drivers/char/ipmi/vmc_smi.c
new file mode 100644
index 0000000..25f108e
--- /dev/null
+++ b/drivers/char/ipmi/vmc_smi.c
@@ -0,0 +1,518 @@
+/*
+ * Wind River IPMI virtual Management Controller mainline
+ *
+ * The virtual Management Controller (vMC) implements a subset of an IPMI
+ * Baseboard Management Controller (BMC) in a kernel module. The vMC
+ * plugs into the OpenIPMI KLM which makes it look like a normal
+ * IPMI management controller to user applications.
+ *
+ * This file contains common type definitions that are used for creating
+ * IPMI System Management Interfaces for the vMC management controllers.
+ *
+ *
+ * Author: Wind River Systems
+ *         Chris Stone <christopher.stone@windriver.com>
+ *
+ * Copyright 2005 Wind River Systems
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2 of the License, or (at your
+ *  option) any later version.
+ *
+ *
+ *  THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
+ *  WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
+ *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
+ *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+ *  BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
+ *  OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ *  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
+ *  TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ *  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/spinlock.h>
+#include <linux/workqueue.h>
+#include <linux/ipmi.h>
+#include <linux/ipmi_smi.h>
+#include <linux/vmc.h>
+#include <linux/uaccess.h> /* copy_from_user() */
+#include "vmc_emu.h"
+#include "vmc_smi.h"
+
+/* saves the result from the last exec_emu_command */
+unsigned char response[RESPONSE_SIZE];
+
+/*
+ * Multiple vMCs may exist at the same time, each of them has
+ * its own vmc_smi_info sturcture and IPMI SMI interface.
+ * They share the same IPMI SMI handlers but have different
+ * intf_num corresponding to different device nodes of /dev/ipmi*
+ */
+struct vmc_smi_info {
+	int                       intf_num;
+	ipmi_smi_t                intf;
+
+	/* link item for workqueue */
+	struct list_head          link;
+
+	struct ipmi_smi_handlers  *handlers;
+
+	/* From the get device id response... */
+	struct ipmi_device_id     device_id;
+
+	spinlock_t                si_lock;
+	spinlock_t                msg_lock;
+	struct list_head          xmit_msgs;
+	struct list_head          hp_xmit_msgs;
+	struct ipmi_smi_msg       *curr_msg;
+
+	/* Driver model stuff. */
+	struct device             *dev;
+	struct platform_device    *pdev;
+
+	/* the associated virtual MC */
+	lmc_data_t                *mc;
+
+	/*
+	 * True, if we allocated the device,
+	 * False, if it came from someplace else (like PCI).
+	 */
+	int dev_registered;
+
+	/* Slave address, could be reported from DMI. */
+	unsigned char slave_addr;
+
+	/*
+	 * If true, run the state machine to completion on every send
+	 * call.  Generally used after a panic to make sure stuff goes
+	 * out.
+	 */
+	int run_to_completion;
+};
+
+/* Track all initialized vmc_smi_info structures */
+static LIST_HEAD(vmc_smi_infos);
+static DEFINE_MUTEX(vmc_smi_lock);
+static int vmc_smi_num; /* Used to sequence the VMC SMIs */
+
+static struct platform_driver vmc_platform_driver = {
+	.driver = {
+		.name = VMC_DEVICE_NAME,
+		.bus = &platform_bus_type
+	}
+};
+
+/* IPMI device ID data
+ * Be sure to update IMC_ADD_STRING if changing any of these */
+#define IPMI_DEVREV 1
+#define IPMI_MAJOR_FWREV 1
+#define IPMI_MINOR_FWREV 1
+#define IPMI_VERSION 0x15 /* IPMI v1.5 */
+#define IPMI_MAN 0
+#define IPMI_PROD_ID 0
+
+/* Device model stuff */
+struct ipmi_device_id vMC_device_id = {
+	.device_id = 0,
+	.device_revision = IPMI_DEVREV,
+	.firmware_revision_1 = IPMI_MAJOR_FWREV,
+	.firmware_revision_2 = IPMI_MINOR_FWREV,
+	.ipmi_version = IPMI_VERSION,
+	.additional_device_support = 0,
+	.manufacturer_id = IPMI_MAN,
+	.product_id = IPMI_PROD_ID,
+	.aux_firmware_revision_set = 0,
+};
+
+/*
+ *  Data structures for the IPMI command workqueue
+ */
+struct workqueue_struct *ipmiworkq;
+DECLARE_WORK(ipmiwork, vmc_workqueue);
+
+/* Debug dump of incoming IPMI messages */
+static void dump_smi_msg(struct ipmi_smi_msg *msg)
+{
+	unsigned char *p;
+	int k;
+
+	if (msg->data_size > 0) {
+		p = msg->data;
+		printk(KERN_INFO "IPMI Request %d: ", msg->data_size);
+		for (k = 0; k < msg->data_size; k++) {
+			printk("%02x", p[k]);
+			if (k%4 == 3)
+				printk(" ");
+		}
+		printk("\n");
+	}
+
+	if (msg->rsp_size > 0) {
+		p = msg->rsp;
+		printk(KERN_INFO "IPMI Response %d: ", msg->rsp_size);
+		for (k = 0; k < msg->rsp_size; k++)	{
+			printk("%02x", p[k]);
+			if (k%4 == 3)
+				printk(" ");
+		}
+		printk("\n");
+	}
+}
+
+/* Process IPMI commands coming from OpenIPMI */
+void vmc_smi_msg_received(struct ipmi_smi_msg *msg)
+{
+	struct vmc_smi_info *curr_smi;
+
+	curr_smi = list_entry(vmc_smi_infos.next, typeof(*curr_smi), link);
+
+	ipmi_smi_msg_received(curr_smi->intf, msg);
+	/* ipmi_free_smi_msg(msg); */
+}
+
+void vmc_workqueue(struct work_struct *work)
+{
+	struct ipmi_smi_msg *msg;
+	struct vmc_smi_info *curr_smi;
+
+	/* First service high-priority messages */
+	mutex_lock(&vmc_smi_lock);
+	list_for_each_entry(curr_smi, &vmc_smi_infos, link) {
+		spin_lock(&(curr_smi->msg_lock));
+		while (!list_empty(&(curr_smi->hp_xmit_msgs))) {
+			/* Process one entry from the work list */
+			msg = list_entry(curr_smi->hp_xmit_msgs.next,
+					typeof(*msg), link);
+			list_del(&(msg->link));
+			spin_unlock(&(curr_smi->msg_lock));
+
+			ipmi_emu_handle_msg(msg);
+
+			if (vmcDebug)
+				dump_smi_msg(msg);
+
+			ipmi_smi_msg_received(curr_smi->intf, msg);
+			spin_lock(&(curr_smi->msg_lock));
+		}
+		spin_unlock(&(curr_smi->msg_lock));
+	}
+	mutex_unlock(&vmc_smi_lock);
+
+	/* Then service normal-priority messages */
+	mutex_lock(&vmc_smi_lock);
+	list_for_each_entry(curr_smi, &vmc_smi_infos, link) {
+		spin_lock(&(curr_smi->msg_lock));
+		while (!list_empty(&(curr_smi->xmit_msgs))) {
+			/* Process one entry from the work list */
+			msg = list_entry(curr_smi->xmit_msgs.next,
+					typeof(*msg), link);
+			list_del(&(msg->link));
+			spin_unlock(&(curr_smi->msg_lock));
+
+			ipmi_emu_handle_msg(msg);
+
+			if (vmcDebug)
+				dump_smi_msg(msg);
+
+			ipmi_smi_msg_received(curr_smi->intf, msg);
+			spin_lock(&(curr_smi->msg_lock));
+		}
+		spin_unlock(&(curr_smi->msg_lock));
+	}
+	mutex_unlock(&vmc_smi_lock);
+}
+
+int start_processing(void *send_info, ipmi_smi_t intf)
+{
+	struct vmc_smi_info *new_smi = send_info;
+
+	printk(KERN_DEBUG "%s: send_info %p, intf %p\n",
+		__func__, send_info, intf);
+	new_smi->intf = intf;
+	return 0;
+}
+
+/* Send an IPMI message to the vMC handling code */
+void sender(void *send_info, struct ipmi_smi_msg *msg, int priority)
+{
+	struct vmc_smi_info   *smi_info = send_info;
+	unsigned long     flags;
+
+	if (msg == NULL) {
+		printk(KERN_ERR "NULL IPMI message received by vMC " \
+		"is ignored.\n");
+		return;
+	}
+
+	if (vmcDebug)
+		printk(KERN_INFO "IPMI message received by vMC.\n");
+
+	spin_lock_irqsave(&(smi_info->msg_lock), flags);
+	if (priority)
+		list_add(&(msg->link), &(smi_info->hp_xmit_msgs));
+	else
+		list_add_tail(&(msg->link), &(smi_info->xmit_msgs));
+	spin_unlock_irqrestore(&(smi_info->msg_lock), flags);
+
+	queue_work(ipmiworkq, &ipmiwork);
+}
+
+/* Request events from vMC */
+void request_events(void *send_info)
+{
+    ipmi_request_events();
+}
+
+/* Put interface in run to completion mode */
+void set_run_to_completion(void *send_info, int run_to_completion)
+{
+}
+
+/* OpenIPMI handler interface */
+struct ipmi_smi_handlers vmc_smi_handlers = {
+	.owner                  = THIS_MODULE,
+	.start_processing	= start_processing,
+	.sender			= sender,
+	.request_events		= request_events,
+	.set_run_to_completion  = set_run_to_completion,
+};
+
+/* procfs entries for vMC SMI */
+
+/* Create a procfs entry to set SEL tasklet priority */
+static int selpriority_read_proc(char *page, char **start, off_t off,
+			int count, int *eof, void *data)
+{
+	char *out = page + off;
+	*eof = 1;
+	return sprintf(out, "%d\n", sel_tasklet.hi);
+}
+
+static int selpriority_write_proc(struct file *file, const char *buffer,
+			unsigned long count, void *data)
+{
+	int val;
+	int rc = 0;
+#define MAX_SELPRIORITY_WRITE 2
+	char input[MAX_SELPRIORITY_WRITE];
+
+	if (count > MAX_SELPRIORITY_WRITE)
+		return -EINVAL;
+
+	if (copy_from_user(input, buffer, count))
+		return -EFAULT;
+
+	input[MAX_SELPRIORITY_WRITE - 1] = '\0';
+
+	val = simple_strtoul(input, NULL, 0);
+
+	if ((val == 0) || (val == 1))
+		sel_tasklet.hi = val;
+	else
+		rc = -EINVAL;
+
+	return count;
+}
+
+static int type_file_read_proc(char *page, char **start, off_t off,
+			       int count, int *eof, void *data)
+{
+	return sprintf(page, VMC_DEVICE_NAME"\n");
+}
+
+/* Register IPMI SMI structure for current vMC */
+int create_vmc_smi(lmc_data_t *mc)
+{
+#define	VMC_PROC_SELPRIORITY	"selpriority"
+#define VMC_PROC_TYPE		"type"
+
+	int rc;
+	struct vmc_smi_info *new_smi;
+
+	new_smi = kzalloc(sizeof(struct vmc_smi_info), GFP_KERNEL);
+	if (!new_smi) {
+		printk(KERN_ERR "vMC: Could not allocate memory for "
+			"SMI structure.\n");
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	new_smi->mc = mc;
+	new_smi->intf_num = vmc_smi_num++;
+	new_smi->handlers = &vmc_smi_handlers;
+	new_smi->run_to_completion = 0;
+
+	INIT_LIST_HEAD(&(new_smi->xmit_msgs));
+	INIT_LIST_HEAD(&(new_smi->hp_xmit_msgs));
+	new_smi->curr_msg = NULL;
+	spin_lock_init(&(new_smi->si_lock));
+	spin_lock_init(&(new_smi->msg_lock));
+
+	/*
+	 * If we don't already have a device from something
+	 * else (like PCI), then register a new one.
+	 */
+	new_smi->pdev = platform_device_alloc(VMC_DEVICE_NAME,
+					      new_smi->intf_num);
+	if (!new_smi->pdev) {
+		printk(KERN_ERR "%s: Unable to allocate platform "
+				"device\n", __func__);
+		rc = -ENOMEM;
+		goto fail_1;
+	}
+	new_smi->dev = &new_smi->pdev->dev;
+	new_smi->dev->driver = &vmc_platform_driver.driver;
+
+	rc = platform_device_add(new_smi->pdev);
+	if (rc) {
+		printk(KERN_ERR "%s: Unable to register system "
+				"interface device: %d\n", __func__, rc);
+		rc = -ENOMEM;
+		goto fail_2;
+	}
+	new_smi->dev_registered = 1;
+
+	/*
+	 * Must add the current SMI to vmc_smi_infos before
+	 * ipmi_register_smi() sends a message and invokes the workqueue
+	 */
+	mutex_lock(&vmc_smi_lock);
+	list_add_tail(&(new_smi->link), &vmc_smi_infos);
+	mutex_unlock(&vmc_smi_lock);
+
+	/*
+	 * Register ourselves as a system management interface.
+	 * The pointer to ipmi_smi structure would be saved into
+	 * our new_smi->intf by vmc_smi_handler.start_processing()
+	 */
+	rc = ipmi_register_smi(new_smi->handlers, new_smi,
+			&new_smi->device_id, new_smi->dev,
+			VMC_DEVICE_NAME, new_smi->slave_addr);
+	if (rc) {
+		printk(KERN_ERR "vMC: Unable to register ipmi SMI device\n");
+		rc = -EINVAL;
+		goto fail_3;
+	}
+
+	rc = __ipmi_smi_add_proc_entry(new_smi->intf, VMC_PROC_SELPRIORITY,
+					selpriority_read_proc,
+					selpriority_write_proc,
+					new_smi);
+	if (rc) {
+		printk(KERN_ERR "vMC: Unable to create proc entry "
+			VMC_PROC_SELPRIORITY "\n");
+		rc = -EINVAL;
+		goto fail_4;
+	}
+
+	rc = __ipmi_smi_add_proc_entry(new_smi->intf, VMC_PROC_TYPE,
+					type_file_read_proc,
+					NULL,
+					new_smi);
+	if (rc) {
+		printk(KERN_ERR "vMC: Unable to create proc entry "
+			VMC_PROC_TYPE "\n");
+		rc = -EINVAL;
+		goto fail_4;
+	}
+
+	rc = 0;
+	goto out;
+
+fail_4:
+	ipmi_unregister_smi(new_smi->intf);
+fail_3:
+	list_del(&(new_smi->link));
+	platform_device_del(new_smi->pdev);
+fail_2:
+	platform_device_put(new_smi->pdev);
+fail_1:
+	kfree(new_smi);
+out:
+	return rc;
+}
+
+int destroy_vmc_smi(lmc_data_t *mc)
+{
+	struct vmc_smi_info *entry, *n;
+
+	mutex_lock(&vmc_smi_lock);
+	list_for_each_entry_safe(entry, n, &vmc_smi_infos, link) {
+		if ((unsigned long)(entry->mc) == (unsigned long)mc) {
+			mutex_unlock(&vmc_smi_lock);
+			goto found;
+		}
+	}
+	mutex_unlock(&vmc_smi_lock);
+	return VMC_INVALID_MC;
+
+found:
+	/*
+	 * All procfs entries for a SMI interface would be linked
+	 * in ipmi_smi.proc_entries and get automatically removed by
+	 * remove_proc_entries() in ipmi_msghandler.c.
+	 */
+
+	platform_device_del(entry->pdev);
+	platform_device_put(entry->pdev);
+
+	/* Empty pending messages that need to be transmitted*/
+	vmc_workqueue(NULL);
+
+	ipmi_unregister_smi(entry->intf);
+
+	list_del(&(entry->link));
+	kfree(entry);
+	vmc_smi_num--;
+
+	return VMC_NO_ERROR;
+}
+
+/* Create a workqueue for IPMI messages through vMC SMI interface. */
+int vmc_smi_init(void)
+{
+	int rc = 0;
+
+	/* Register the device drivers. */
+	rc = driver_register(&vmc_platform_driver.driver);
+	if (rc) {
+		printk(KERN_ERR "%s: Unable to register driver: %d\n",
+			__func__, rc);
+		rc = -EINVAL;
+		goto out;
+	}
+
+	/* Initialize a workqueue to process IPMI commands */
+	ipmiworkq = create_singlethread_workqueue("ipmicmd");
+	if (!ipmiworkq) {
+		printk(KERN_ERR "%s: Unable to create ipmiworkq\n", __func__);
+		rc = -EINVAL;
+		goto fail;
+	}
+
+	memset(response, '\0', RESPONSE_SIZE);
+	memcpy(response, "Ready.\n", 7);
+
+	rc = 0;
+	goto out;
+
+fail:
+	driver_unregister(&vmc_platform_driver.driver);
+out:
+	return rc;
+}
+
+void vmc_smi_exit(void)
+{
+	driver_unregister(&vmc_platform_driver.driver);
+
+	flush_workqueue(ipmiworkq);
+	destroy_workqueue(ipmiworkq);
+}
diff --git a/drivers/char/ipmi/vmc_smi.h b/drivers/char/ipmi/vmc_smi.h
new file mode 100644
index 0000000..be53488
--- /dev/null
+++ b/drivers/char/ipmi/vmc_smi.h
@@ -0,0 +1,52 @@
+/*
+ * Wind River IPMI virtual Management Controller
+ *
+ * The virtual Management Controller (vMC) implements a subset of an IPMI
+ * Baseboard Management Controller (BMC) in a kernel module. The vMC
+ * plugs into the OpenIPMI KLM which makes it look like a normal
+ * IPMI management controller to user applications.
+ *
+ * This file contains common type definitions that are used for creating
+ * IPMI System Management Interfaces for the vMC management controllers.
+ *
+ * Author: MontaVista Software, Inc.
+ *         Corey Minyard <minyard@mvista.com>
+ *         source@mvista.com
+ *
+ * Copyright 2003 MontaVista Software Inc.
+ * Portions Copyright 2005 Wind River Systems
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2 of the License, or (at your
+ *  option) any later version.
+ *
+ *
+ *  THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
+ *  WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ *  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
+ *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
+ *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+ *  BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
+ *  OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ *  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
+ *  TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ *  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+extern void vmc_workqueue(struct work_struct *);
+extern struct workqueue_struct *ipmiworkq;
+
+int create_vmc_smi(lmc_data_t *mc);
+int destroy_vmc_smi(lmc_data_t *mc);
+
+int vmc_smi_init(void);
+void vmc_smi_exit(void);
+void vmc_smi_msg_received(struct ipmi_smi_msg *msg);
+
+#define RESPONSE_SIZE 128
+extern unsigned char response[];
diff --git a/include/linux/ipmi_smi.h b/include/linux/ipmi_smi.h
index 4b48318..e96b9af 100644
--- a/include/linux/ipmi_smi.h
+++ b/include/linux/ipmi_smi.h
@@ -231,4 +231,9 @@ int ipmi_smi_add_proc_entry(ipmi_smi_t smi, char *name,
 			    read_proc_t *read_proc,
 			    void *data);
 
+int __ipmi_smi_add_proc_entry(ipmi_smi_t smi, char *name,
+			      read_proc_t *read_proc,
+			      write_proc_t *write_proc,
+			      void *data);
+
 #endif /* __LINUX_IPMI_SMI_H */
diff --git a/include/linux/vmc.h b/include/linux/vmc.h
index 904043a..c2e8d12 100644
--- a/include/linux/vmc.h
+++ b/include/linux/vmc.h
@@ -62,6 +62,7 @@
 #error "Neither Big nor little endian defined!"
 #endif
 
+#define VMC_DEVICE_NAME                "vMC"
 #define MAX_SDR_DATA 64
 #define IPMI_EM_V15_VERSION 0x04
 typedef struct lmc_data_s lmc_data_t;
@@ -824,6 +825,9 @@ extern int (*vMC_sensor_get_value) (vMC_ipmi_sensor_ident_t *sensor_ident,
 				    unsigned int *val);
 
 /* vMC_sensor_set_bit
+ *   FIXME: This kernel API function is currently unsupported.  See comments
+ *   regarding breakage at the function definition in vmc_kapi.c.
+ *
  *   Only for discrete sensors.  The bit identified by bit is set to 0 or 1
  *   depending on the contents of val.  If a sensor bit changes value and event
  *   notification is enabled a sensor event will be generated.
@@ -832,9 +836,11 @@ extern int (*vMC_sensor_get_value) (vMC_ipmi_sensor_ident_t *sensor_ident,
  *   NULL, in which case the vMC will allocate a default SEL record if an
  *   event is generated. If vMC_sel_record is not NULL, but no event is
  *   generated, the vMC will free the record. */
+/*
 extern int (*vMC_sensor_set_bit) (vMC_ipmi_sensor_ident_t *sensor_ident,
 				  unsigned int bit, unsigned int val,
 				  vMC_ipmi_sel_record_t *vMC_sel_record);
+*/
 
 /* vMC_sensor_set_value
  *   Only for threshold sensors.  Set the sensor to the given value. An event
-- 
1.6.5.2

