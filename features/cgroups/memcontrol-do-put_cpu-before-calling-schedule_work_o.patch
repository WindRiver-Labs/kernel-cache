From 31a6622973e6a6448d403b7a160420fe3dbbfe0f Mon Sep 17 00:00:00 2001
From: Paul Gortmaker <paul.gortmaker@windriver.com>
Date: Thu, 13 Jun 2013 15:00:14 -0400
Subject: [PATCH] memcontrol: do put_cpu before calling schedule_work_on()

Doing an "lxc-execute -n foo /bin/bash" and then exiting the
resulting shell causes the following:

 BUG: sleeping function called from invalid context at kernel/rtmutex.c:658
 in_atomic(): 1, irqs_disabled(): 0, pid: 1241, name: lxc-execute
 3 locks held by lxc-execute/1241:
  #0:  (&sb->s_type->i_mutex_key#12/1){+.+.+.}, at: [<ffffffff811b59a2>] do_rmdir+0x72/0x130
  #1:  (&sb->s_type->i_mutex_key#12){+.+.+.}, at: [<ffffffff811b5864>] vfs_rmdir+0x74/0x140
  #2:  (percpu_charge_mutex){+.+...}, at: [<ffffffff811a05ee>] mem_cgroup_force_empty+0xce/0x5e0
 Pid: 1241, comm: lxc-execute Not tainted 3.4.47-rt62 #3
 Call Trace:
  [<ffffffff810bb0b4>] __might_sleep+0x134/0x1f0
  [<ffffffff817cf874>] rt_spin_lock+0x24/0x60
  [<ffffffff810a52b2>] __queue_work+0x62/0x5b0
  [<ffffffff817d0185>] ? _raw_spin_unlock+0x35/0x60
  [<ffffffff810a5825>] queue_work_on+0x25/0x30
  [<ffffffff810a5848>] schedule_work_on+0x18/0x20
  [<ffffffff8119b9e2>] drain_all_stock+0xc2/0x180
  [<ffffffff811a05fb>] mem_cgroup_force_empty+0xdb/0x5e0
  [<ffffffff810bebf9>] ? sub_preempt_count+0x79/0xd0
  [<ffffffff817d0185>] ? _raw_spin_unlock+0x35/0x60
  [<ffffffff811a0b14>] mem_cgroup_pre_destroy+0x14/0x20
  [<ffffffff8110067f>] cgroup_rmdir+0xaf/0x570
  [<ffffffff810ae500>] ? __init_waitqueue_head+0xa0/0xa0
  [<ffffffff811b58c5>] vfs_rmdir+0xd5/0x140
  [<ffffffff811b5a43>] do_rmdir+0x113/0x130
  [<ffffffff8140f966>] ? trace_hardirqs_on_thunk+0x3a/0x3f
  [<ffffffff811b71e6>] sys_rmdir+0x16/0x20
  [<ffffffff817d0f16>] system_call_fastpath+0x1a/0x1f

The problem is that drain_all_stock is wrapped in get/put_cpu
(and online_cpu as well) so preempt is disabled, but __queue_work
operates on global_cwq's spin lock which is the rt_spin_lock
at the top of the above trace.

Drop all holds on CPUs before calling schedule_work_on, and
retake them again once done.  If we've moved CPUs in the
process then restart.  On the odd chance that this happens,
we'll be quick through the 2nd time since the test_and_set_bit
will skip processing any that have been done already.

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/mm/memcontrol.c b/mm/memcontrol.c
index 81c275b..4cf4864 100644
--- a/mm/memcontrol.c
+++ b/mm/memcontrol.c
@@ -2080,6 +2080,7 @@ static void drain_all_stock(struct mem_cgroup *root_memcg, bool sync)
 {
 	int cpu, curcpu;
 
+restart:
 	/* Notify other cpus that system-wide "drain" is running */
 	get_online_cpus();
 	curcpu = get_cpu();
@@ -2093,10 +2094,22 @@ static void drain_all_stock(struct mem_cgroup *root_memcg, bool sync)
 		if (!mem_cgroup_same_or_subtree(root_memcg, memcg))
 			continue;
 		if (!test_and_set_bit(FLUSHING_CACHED_CHARGE, &stock->flags)) {
-			if (cpu == curcpu)
+			if (cpu == curcpu) {
 				drain_local_stock(&stock->work);
-			else
+			} else {
+				int latest_cpu;
+
+				put_cpu();
+				put_online_cpus();
 				schedule_work_on(cpu, &stock->work);
+				get_online_cpus();
+				latest_cpu = get_cpu();
+				if (latest_cpu == curcpu)
+					continue;
+				put_cpu();
+				put_online_cpus();
+				goto restart;
+			}
 		}
 	}
 	put_cpu();
-- 
1.8.1.2

