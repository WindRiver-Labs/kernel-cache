From 8d297e0a8cfb05dd3dd14cc74982155314546ce2 Mon Sep 17 00:00:00 2001
From: Paul Gortmaker <paul.gortmaker@windriver.com>
Date: Thu, 21 Jun 2012 13:38:38 -0400
Subject: [PATCH] cgroup: remove cgroup_subsys ss arg from task_counter

Commit 761b3ef50e1c2649cffbfa67a4dcb2dcdb7982ed

    "cgroup: remove cgroup_subsys argument from callbacks"

was added to mainline since the last posting of the task_counter
support (v8:  https://lkml.org/lkml/2012/1/31/489 ) and so we have
to do the same here.

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/kernel/cgroup_task_counter.c b/kernel/cgroup_task_counter.c
index a4d87ac..98b1629 100644
--- a/kernel/cgroup_task_counter.c
+++ b/kernel/cgroup_task_counter.c
@@ -47,8 +47,7 @@ static inline struct res_counter *cgroup_task_res_counter(struct cgroup *cgrp)
 	return &cnt->res;
 }
 
-static struct cgroup_subsys_state *
-task_counter_create(struct cgroup_subsys *ss, struct cgroup *cgrp)
+static struct cgroup_subsys_state *task_counter_create(struct cgroup *cgrp)
 {
 	struct task_counter *cnt;
 	struct res_counter *parent_res;
@@ -72,14 +71,13 @@ task_counter_create(struct cgroup_subsys *ss, struct cgroup *cgrp)
  * a limit below or equal to the one of the parent which can be changed
  * concurrently anyway. This is just to honour the clone flag.
  */
-static void task_counter_post_clone(struct cgroup_subsys *ss,
-				    struct cgroup *cgrp)
+static void task_counter_post_clone(struct cgroup *cgrp)
 {
 	/* cgrp can't be root, so cgroup_task_res_counter() can't return NULL */
 	res_counter_inherit(cgroup_task_res_counter(cgrp), RES_LIMIT);
 }
 
-static void task_counter_destroy(struct cgroup_subsys *ss, struct cgroup *cgrp)
+static void task_counter_destroy(struct cgroup *cgrp)
 {
 	struct task_counter *cnt = cgroup_task_counter(cgrp);
 
@@ -87,8 +85,8 @@ static void task_counter_destroy(struct cgroup_subsys *ss, struct cgroup *cgrp)
 }
 
 /* Uncharge the cgroup the task was attached to */
-static void task_counter_exit(struct cgroup_subsys *ss, struct cgroup *cgrp,
-			      struct cgroup *old_cgrp, struct task_struct *task)
+static void task_counter_exit(struct cgroup *cgrp, struct cgroup *old_cgrp,
+			      struct task_struct *task)
 {
 	/* Optimize for the root cgroup case */
 	if (old_cgrp->parent)
@@ -121,8 +119,7 @@ static void task_counter_cancel_attach_until(struct res_counter *res,
  * cgroup can fork before and steal the last remaining count.
  * Thus we need to charge the dest cgroup right now.
  */
-static int task_counter_can_attach(struct cgroup_subsys *ss,
-				   struct cgroup *cgrp,
+static int task_counter_can_attach(struct cgroup *cgrp,
 				   struct cgroup_taskset *tset)
 {
 	struct res_counter *res = cgroup_task_res_counter(cgrp);
@@ -160,8 +157,7 @@ static int task_counter_can_attach(struct cgroup_subsys *ss,
 }
 
 /* Uncharge the dest cgroup that we charged in task_counter_can_attach() */
-static void task_counter_cancel_attach(struct cgroup_subsys *ss,
-				       struct cgroup *cgrp,
+static void task_counter_cancel_attach(struct cgroup *cgrp,
 				       struct cgroup_taskset *tset)
 {
 	task_counter_cancel_attach_until(cgroup_task_res_counter(cgrp),
@@ -175,7 +171,7 @@ static void task_counter_cancel_attach(struct cgroup_subsys *ss,
  * we uncharge and reach the task counter limit, making our return there
  * not possible.
  */
-static void task_counter_attach(struct cgroup_subsys *ss, struct cgroup *cgrp,
+static void task_counter_attach(struct cgroup *cgrp,
 				struct cgroup_taskset *tset)
 {
 	struct res_counter *res = cgroup_task_res_counter(cgrp);
@@ -236,8 +232,7 @@ static int task_counter_populate(struct cgroup_subsys *ss, struct cgroup *cgrp)
  * Charge the task counter with the new child coming, or reject it if we
  * reached the limit.
  */
-static int task_counter_fork(struct cgroup_subsys *ss,
-			     struct task_struct *child)
+static int task_counter_fork(struct task_struct *child)
 {
 	struct cgroup_subsys_state *css;
 	struct cgroup *cgrp;
-- 
1.7.7

