From: Zumeng Chen <zumeng.chen@windriver.com>
Date: Thu, 6 Nov 2008 17:14:19 +0800
Subject: [PATCH 1/1] fix task_lock recursive locking

It is obvious that the pair of spin_lock should not include
semaphore inside, so this fix looks clear. another reason is
that it is more performance for other processes to read_lock
tasklist_lock timely; And I think it is also clear that the
author has considered one situation, which is that c->mm may
be changed before task_lock(c) is acquired by current thread,
so there is a "goto retry" to remedy.

   The following is the original commit id in 2.6.28
      9363b9f23c9cc36cc8ef6c05fdf879ee4a96ae92 

Signed-off-by: Balbir Singh <balbir@linux.vnet.ibm.com>
Integrated-by: Zumeng Chen <zumeng.chen@windriver.com>

---
 kernel/exit.c |   11 ++++-------
 1 files changed, 4 insertions(+), 7 deletions(-)

diff --git a/kernel/exit.c b/kernel/exit.c
index 25a1c70..7c58c06 100644
--- a/kernel/exit.c
+++ b/kernel/exit.c
@@ -648,28 +648,25 @@ retry:
 assign_new_owner:
 	BUG_ON(c == p);
 	get_task_struct(c);
+	read_unlock(&tasklist_lock);
 	down_write(&mm->mmap_sem);
 	/*
 	 * The task_lock protects c->mm from changing.
 	 * We always want mm->owner->mm == mm
 	 */
 	task_lock(c);
-	/*
-	 * Delay read_unlock() till we have the task_lock()
-	 * to ensure that c does not slip away underneath us
-	 */
-	read_unlock(&tasklist_lock);
+
 	if (c->mm != mm) {
 		task_unlock(c);
-		put_task_struct(c);
 		up_write(&mm->mmap_sem);
+		put_task_struct(c);
 		goto retry;
 	}
 	cgroup_mm_owner_callbacks(mm->owner, c);
 	mm->owner = c;
 	task_unlock(c);
-	put_task_struct(c);
 	up_write(&mm->mmap_sem);
+	put_task_struct(c);
 }
 #endif /* CONFIG_MM_OWNER */
 
-- 
1.5.5.1.67.gbdb8

