From 5d8a3f565970e22852a27cbfaedfd275d7c6fdc1 Mon Sep 17 00:00:00 2001
From: Weiwei Wang <weiwei.wang@windriver.com>
Date: Mon, 5 Jul 2010 09:13:43 +0800
Subject: [PATCH] x86: base 64-bit guest support

SMP + vtlb optim off + nfs/ramdisk rootfs succeeds

Signed-off-by: Weiwei Wang <weiwei.wang@windriver.com>
---
 arch/x86/boot/compressed/head_64.S     |   39 ++++++++-
 arch/x86/boot/compressed/vmlinux.lds.S |   12 +++
 arch/x86/include/asm/fixmap.h          |   11 ++
 arch/x86/include/asm/trampoline.h      |    2 +
 arch/x86/include/asm/wrhv.h            |    8 ++
 arch/x86/kernel/asm-offsets_64.c       |   11 ++
 arch/x86/kernel/head.c                 |    2 +
 arch/x86/kernel/head64.c               |    2 +
 arch/x86/kernel/head_64.S              |   11 ++
 arch/x86/kernel/smpboot.c              |    2 +
 arch/x86/kernel/trampoline.c           |    8 ++-
 arch/x86/kernel/trampoline_64.S        |   20 ++++
 arch/x86/kernel/vbi/wrhv.c             |  158 +++++++++++++++++++++++++++++---
 13 files changed, 271 insertions(+), 15 deletions(-)

diff --git a/arch/x86/boot/compressed/head_64.S b/arch/x86/boot/compressed/head_64.S
index faff0dc..b67ac67 100644
--- a/arch/x86/boot/compressed/head_64.S
+++ b/arch/x86/boot/compressed/head_64.S
@@ -38,6 +38,10 @@
 	.code32
 ENTRY(startup_32)
 	cld
+
+#ifdef CONFIG_WRHV
+	jmp 1f
+#endif
 	/*
 	 * Test KEEP_SEGMENTS flag to see if the bootloader is asking
 	 * us to not reload segments
@@ -51,6 +55,21 @@ ENTRY(startup_32)
 	movl	%eax, %es
 	movl	%eax, %ss
 1:
+#ifdef CONFIG_WRHV
+	/*Copy wrhv config */
+	movl %esi, %eax
+	movl 0x4(%esp), %esi
+	/* Store the address of wrhv config so we can map it later */
+	movl $wrhv_config, %edi
+	movl %esi, (%edi)
+	movl $0, 0x4(%edi)
+	addl $8, %edi
+	movl $1024,%ecx
+	cld
+	rep
+	movsl
+	movl %eax, %esi
+#endif
 
 /*
  * Calculate the delta between where we were compiled to run
@@ -60,7 +79,9 @@ ENTRY(startup_32)
  * data at 0x1e4 (defined as a scratch field) are used as the stack
  * for this calculation. Only 4 bytes are needed.
  */
+#ifndef CONFIG_WRHV
 	leal	(BP_scratch+4)(%esi), %esp
+#endif
 	call	1f
 1:	popl	%ebp
 	subl	$1b, %ebp
@@ -83,7 +104,7 @@ ENTRY(startup_32)
  * for safe in-place decompression.
  */
 
-#ifdef CONFIG_RELOCATABLE
+#if defined(CONFIG_RELOCATABLE) && !defined(CONFIG_WRHV)
 	movl	%ebp, %ebx
 	movl	BP_kernel_alignment(%esi), %eax
 	decl	%eax
@@ -225,7 +246,7 @@ ENTRY(startup_64)
 	 */
 
 	/* Start with the delta to where the kernel will run at. */
-#ifdef CONFIG_RELOCATABLE
+#if defined(CONFIG_RELOCATABLE) && !defined(CONFIG_WRHV)
 	leaq	startup_32(%rip) /* - $startup_32 */, %rbp
 	movl	BP_kernel_alignment(%rsi), %eax
 	decl	%eax
@@ -282,6 +303,9 @@ relocated:
 /*
  * Do the decompression, and jump to the new kernel..
  */
+#ifdef CONFIG_WRHV
+	pushq   %rbx
+#endif
 	pushq	%rsi			/* Save the real mode argument */
 	movq	%rsi, %rdi		/* real mode address */
 	leaq	boot_heap(%rip), %rsi	/* malloc area for uncompression */
@@ -291,6 +315,11 @@ relocated:
 	call	decompress_kernel
 	popq	%rsi
 
+#ifdef CONFIG_WRHV
+	popq   %rbx
+	leaq wrhv_config(%rbx), %rsi
+#endif
+
 /*
  * Jump to the decompressed kernel.
  */
@@ -308,6 +337,12 @@ gdt:
 	.quad   0x0000000000000000	/* TS continued */
 gdt_end:
 
+#ifdef CONFIG_WRHV
+.balign 8
+wrhv_config:
+	.fill 0x1008, 1, 0
+#endif
+
 /*
  * Stack and heap for uncompression
  */
diff --git a/arch/x86/boot/compressed/vmlinux.lds.S b/arch/x86/boot/compressed/vmlinux.lds.S
index a6f1a59..5f24244 100644
--- a/arch/x86/boot/compressed/vmlinux.lds.S
+++ b/arch/x86/boot/compressed/vmlinux.lds.S
@@ -9,7 +9,14 @@ OUTPUT_FORMAT(CONFIG_OUTPUT_FORMAT, CONFIG_OUTPUT_FORMAT, CONFIG_OUTPUT_FORMAT)
 
 #ifdef CONFIG_X86_64
 OUTPUT_ARCH(i386:x86-64)
+#ifdef CONFIG_WRHV
+/* VB initial status is 32-bit mode, so take use of 32-bit start
+ * up code to do 32-bit to 64-bit transition in x86-64 guest os
+ */
+ENTRY(startup_32)
+#else
 ENTRY(startup_64)
+#endif
 #else
 OUTPUT_ARCH(i386)
 ENTRY(startup_32)
@@ -20,7 +27,12 @@ SECTIONS
 	/* Be careful parts of head_64.S assume startup_32 is at
 	 * address 0.
 	 */
+#if defined(CONFIG_WRHV) && defined(CONFIG_X86_64)
+	/* The address must equal to TRAMPOLINE_BASE for AP boot */
+	. = 0x6000;
+#else
 	. = 0;
+#endif
 	.head.text : {
 		_head = . ;
 		HEAD_TEXT
diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index d07b44f..dca0543 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -26,6 +26,10 @@
 #include <asm/vsyscall.h>
 #endif
 
+#if defined(CONFIG_WRHV) && defined(CONFIG_X86_64)
+#include <asm/wrhv.h>
+#endif
+
 /*
  * We can't declare FIXADDR_TOP as variable for x86_64 because vsyscall
  * uses fixmaps that relies on FIXADDR_TOP for proper address calculation.
@@ -116,6 +120,13 @@ enum fixed_addresses {
 #endif
 	FIX_TEXT_POKE1,	/* reserve 2 pages for text_poke() */
 	FIX_TEXT_POKE0, /* first page is last, because allocation is backward */
+
+#if defined(CONFIG_WRHV) && defined(CONFIG_X86_64)
+	FIX_WRHV_RESERVED_BEGIN,
+	FIX_WRHV_RESERVED_END = FIX_WRHV_RESERVED_BEGIN
+				+ WRHV_RESERVED_PAGES - 1,
+#endif
+
 	__end_of_permanent_fixed_addresses,
 	/*
 	 * 256 temporary boot-time mappings, used by early_ioremap(),
diff --git a/arch/x86/include/asm/trampoline.h b/arch/x86/include/asm/trampoline.h
index 4dde797..4ac7387 100644
--- a/arch/x86/include/asm/trampoline.h
+++ b/arch/x86/include/asm/trampoline.h
@@ -1,6 +1,8 @@
 #ifndef _ASM_X86_TRAMPOLINE_H
 #define _ASM_X86_TRAMPOLINE_H
 
+#define TRAMPOLINE_BASE 0x6000
+
 #ifndef __ASSEMBLY__
 
 #ifdef CONFIG_X86_TRAMPOLINE
diff --git a/arch/x86/include/asm/wrhv.h b/arch/x86/include/asm/wrhv.h
index 538f96c..05a33c3 100644
--- a/arch/x86/include/asm/wrhv.h
+++ b/arch/x86/include/asm/wrhv.h
@@ -22,6 +22,8 @@ enum WRHV_IPI_INTS {
 	WRHV_IPI_LAST = WRHV_IPI_RESCHED,
 };
 
+#define WRHV_RESERVED_PAGES	16
+#define WRHV_RESERVED_TOP	(WRHV_RESERVED_PAGES * PAGE_SIZE)
 extern void wrhv_init(void);
 extern void wrhv_boot_config(void);
 extern void wrhv_cpu_workarounds(struct cpuinfo_x86 *);
@@ -49,4 +51,10 @@ extern void wrhv_calibrate_smp_cpus(void);
 extern void wrhv_init_pci(void);
 #endif
 
+#ifdef CONFIG_X86_32
+#define WRS_SYSCALL_VECTOR SYSCALL_VECTOR
+#else
+#define WRS_SYSCALL_VECTOR IA32_SYSCALL_VECTOR
+#endif
+
 #endif /* _ASM_WRHV_H */
diff --git a/arch/x86/kernel/asm-offsets_64.c b/arch/x86/kernel/asm-offsets_64.c
index 1aea11c..eea2bb6 100644
--- a/arch/x86/kernel/asm-offsets_64.c
+++ b/arch/x86/kernel/asm-offsets_64.c
@@ -23,6 +23,10 @@
 
 #include <asm/sigframe.h>
 
+#ifdef CONFIG_WRHV
+#include <vbi/vbi.h>
+#endif
+
 #define __NO_STUBS 1
 #undef __SYSCALL
 #undef _ASM_X86_UNISTD_64_H
@@ -131,6 +135,13 @@ int main(void)
 
 	BLANK();
 	DEFINE(PAGE_SIZE_asm, PAGE_SIZE);
+#ifdef CONFIG_WRHV
+	BLANK();
+	DEFINE(WRHV_VB_CONFIG_SIZE, sizeof(struct vb_config));
+	DEFINE(VB_MAX_BOOTLINE_LENGTH, VB_MAX_BOOTLINE_LENGTH);
+	OFFSET(WRHV_COREID_OFFSET, vb_config, coreId);
+	OFFSET(WRHV_BOOTLINE_OFFSET, vb_config, bootLine);
+#endif
 #ifdef CONFIG_XEN
 	BLANK();
 	OFFSET(XEN_vcpu_info_mask, vcpu_info, evtchn_upcall_mask);
diff --git a/arch/x86/kernel/head.c b/arch/x86/kernel/head.c
index 3e66bd3..f611ccb 100644
--- a/arch/x86/kernel/head.c
+++ b/arch/x86/kernel/head.c
@@ -26,7 +26,9 @@ void __init reserve_ebda_region(void)
 	/* that area is absent. We'll just have to assume */
 	/* that the paravirt case can handle memory setup */
 	/* correctly, without our help. */
+#ifndef CONFIG_WRHV /* too early in wrhv for paravirt test */
 	if (paravirt_enabled())
+#endif
 		return;
 
 	/* end of low (conventional) memory */
diff --git a/arch/x86/kernel/head64.c b/arch/x86/kernel/head64.c
index 7147143..3a01ee7 100644
--- a/arch/x86/kernel/head64.c
+++ b/arch/x86/kernel/head64.c
@@ -96,7 +96,9 @@ void __init x86_64_start_kernel(char * real_mode_data)
 
 void __init x86_64_start_reservations(char *real_mode_data)
 {
+#ifndef CONFIG_WRHV /* real mode data is not provided by wrhv */
 	copy_bootdata(__va(real_mode_data));
+#endif
 
 	reserve_early(__pa_symbol(&_text), __pa_symbol(&__bss_stop), "TEXT DATA BSS");
 
diff --git a/arch/x86/kernel/head_64.S b/arch/x86/kernel/head_64.S
index 3d1e6f1..5a51bc6 100644
--- a/arch/x86/kernel/head_64.S
+++ b/arch/x86/kernel/head_64.S
@@ -45,6 +45,17 @@ L3_START_KERNEL = pud_index(__START_KERNEL_map)
 	.globl startup_64
 startup_64:
 
+#ifdef CONFIG_WRHV
+	movq (%rsi), %rdi
+	movq %rdi, _wr_config(%rip)
+	addq $8, %rsi
+	leaq __wr_config(%rip), %rdi
+	movq $(WRHV_VB_CONFIG_SIZE/4),%rcx
+	cld
+	rep
+	movsl
+#endif
+
 	/*
 	 * At this point the CPU runs in 64bit mode CS.L = 1 CS.D = 1,
 	 * and someone has loaded an identity mapped page table
diff --git a/arch/x86/kernel/smpboot.c b/arch/x86/kernel/smpboot.c
index 9a4fdc5..584bbd7 100644
--- a/arch/x86/kernel/smpboot.c
+++ b/arch/x86/kernel/smpboot.c
@@ -1031,6 +1031,7 @@ static int __init smp_sanity_check(unsigned max_cpus)
 	}
 	preempt_enable();
 
+#ifndef CONFIG_WRHV
 	/*
 	 * If we couldn't find a local APIC, then get out of here now!
 	 */
@@ -1046,6 +1047,7 @@ static int __init smp_sanity_check(unsigned max_cpus)
 		arch_disable_smp_support();
 		return -1;
 	}
+#endif
 
 	verify_local_APIC();
 
diff --git a/arch/x86/kernel/trampoline.c b/arch/x86/kernel/trampoline.c
index e2a5952..3c4cfe0 100644
--- a/arch/x86/kernel/trampoline.c
+++ b/arch/x86/kernel/trampoline.c
@@ -17,8 +17,13 @@ unsigned char *__trampinitdata trampoline_base;
 
 void __init reserve_trampoline_memory(void)
 {
-	unsigned long mem;
 
+#if defined(CONFIG_X86_64) && defined(CONFIG_WRHV)
+	trampoline_base = __va(TRAMPOLINE_BASE);
+	reserve_early(TRAMPOLINE_BASE, TRAMPOLINE_BASE + TRAMPOLINE_SIZE,
+		      "TRAMPOLINE");
+#else
+	unsigned long mem;
 	/* Has to be in very low memory so we can execute real-mode AP code. */
 	mem = find_e820_area(0, 1<<20, TRAMPOLINE_SIZE, PAGE_SIZE);
 	if (mem == -1L)
@@ -26,6 +31,7 @@ void __init reserve_trampoline_memory(void)
 
 	trampoline_base = __va(mem);
 	reserve_early(mem, mem + TRAMPOLINE_SIZE, "TRAMPOLINE");
+#endif
 }
 
 /*
diff --git a/arch/x86/kernel/trampoline_64.S b/arch/x86/kernel/trampoline_64.S
index 3af2dff..fb9e417 100644
--- a/arch/x86/kernel/trampoline_64.S
+++ b/arch/x86/kernel/trampoline_64.S
@@ -31,6 +31,7 @@
 #include <asm/msr.h>
 #include <asm/segment.h>
 #include <asm/processor-flags.h>
+#include <asm/trampoline.h>
 
 #ifdef CONFIG_ACPI_SLEEP
 .section .rodata, "a", @progbits
@@ -38,6 +39,8 @@
 /* We can free up the trampoline after bootup if cpu hotplug is not supported. */
 __CPUINITRODATA
 #endif
+
+#ifndef CONFIG_WRHV
 .code16
 
 ENTRY(trampoline_data)
@@ -85,11 +88,28 @@ r_base = .
 	# flush prefetch and jump to startup_32
 	ljmpl	*(startup_32_vector - r_base)
 
+#else
+ENTRY(trampoline_data)
+#endif
 	.code32
 	.balign 4
 startup_32:
+#ifdef CONFIG_WRHV
+r_base = .
+	movl $(TRAMPOLINE_BASE), %esi
+	/* setup a stack */
+	leal	(trampoline_stack_end - r_base)(%esi), %esp
+	/* fix 64 vector */
+	addl    %esi, (startup_64_vector - r_base)(%esi)
+
+	/* Load new gdt */
+	leal	(tgdt - r_base)(%esi), %eax
+	movl	%eax, (tgdt -r_base + 2)(%esi)
+	lgdt	(tgdt - r_base)(%esi)
+#else
 	movl	$__KERNEL_DS, %eax	# Initialize the %ds segment register
 	movl	%eax, %ds
+#endif
 
 	movl	$X86_CR4_PAE, %eax
 	movl	%eax, %cr4		# Enable PAE mode
diff --git a/arch/x86/kernel/vbi/wrhv.c b/arch/x86/kernel/vbi/wrhv.c
index 9aa51a2..7dba506 100644
--- a/arch/x86/kernel/vbi/wrhv.c
+++ b/arch/x86/kernel/vbi/wrhv.c
@@ -19,6 +19,7 @@
 #include <linux/kgdb.h>
 #include <linux/kernel_stat.h>
 #include <vbi/vbi.h>
+#include <vbi/compat.h>
 #include <asm/setup.h>
 #include <asm/paravirt.h>
 #include <asm/processor.h>
@@ -26,6 +27,7 @@
 #include <asm/pgtable.h>
 #include <asm/tlbflush.h>
 #include <asm/trampoline.h>
+#include <asm/fixmap.h>
 #include <linux/percpu.h>
 #include <linux/smp.h>
 #include <linux/clockchips.h>      /* for enum clock_event_mode */
@@ -33,19 +35,23 @@
 #include <asm/reboot.h>            /* for struct machine_ops */
 #include <asm/x86_init.h>
 
+#include <asm/desc.h>
+#include <asm/e820.h>
+#include <asm/i8259.h>
+
 
 #define WRHV_DEBUG_MSR          0
 #define WRHV_USE_XMLCONFIG      1
 #define WRHV_POLL_IRQ           7
-#define WRHV_RESERVED_PAGES     16
-#define WRHV_RESERVED_TOP       (WRHV_RESERVED_PAGES * PAGE_SIZE)
 
 #define WRHV_BOOTARG_BUF_SIZE   256
 
 /* Copied over during early bootstrap */
 struct vb_config __wr_config = { .pid = -1 };
-struct vb_config *_wr_config; /* Pointer passed from hypervisor */
+/* Pointer passed from hypervisor */
+struct vb_config *_wr_config = &__wr_config;
 struct vb_config *wr_config = &__wr_config;
+struct vb_config *fake_wr_config = &__wr_config;
 struct vb_status *wr_status;
 struct vb_control *wr_control;
 
@@ -104,18 +110,59 @@ static void wrhv_pre_intr_init_hook(void)
 	}
 }
 
+#ifdef CONFIG_X86_32
 static void __wrhv_map_page(unsigned long vaddr, unsigned long paddr,
 				pgprot_t prot)
 {
 	pte_t pte = pfn_pte(paddr >> PAGE_SHIFT, prot);
 	set_pte_vaddr(vaddr, pte);
 }
+#endif
+
+#ifdef CONFIG_X86_64
+static inline void construct_fake_wr_config(void)
+{
+	unsigned long delta;
+
+	delta = (unsigned long)wr_config - (unsigned long)_wr_config;
+	fake_wr_config = (struct vb_config *)
+			 (delta + (unsigned long)wr_config->corePrivate);
+
+	*fake_wr_config = *wr_config;
+	fake_wr_config->vb_control = (struct vb_control *)
+			(delta + (unsigned long)wr_config->vb_control);
+	fake_wr_config->vb_status = (struct vb_status *)
+			(delta + (unsigned long)wr_config->vb_status);
+
+	if (wr_config->sharedMemoryRegionsConfigAddress != NULL) {
+		fake_wr_config->sharedMemoryRegionsConfigAddress =
+			(struct vb_sm_info *)(delta +
+		(unsigned long)wr_config->sharedMemoryRegionsConfigAddress);
+	}
+
+	if (wr_config->memoryRegionsConfigAddress != NULL) {
+		fake_wr_config->memoryRegionsConfigAddress =
+			(struct vb_mem_info *)(delta +
+		(unsigned long)wr_config->sharedMemoryRegionsConfigAddress);
+	}
+
+	fake_wr_config->interruptConfiguration = (struct vb_int_info *)
+		(delta + (unsigned long)wr_config->interruptConfiguration);
+
+	if ((unsigned long)fake_wr_config->vb_control->vIoapic <
+	    ((unsigned long)1 << 32))
+		fake_wr_config->vb_control->vIoapic = (void *)(delta +
+			(unsigned long)fake_wr_config->vb_control->vIoapic);
+}
+
+#endif
 
 void __init wrhv_init_IRQ(void)
 {
 	int i;
 	unsigned long addr;
 
+#ifdef CONFIG_X86_32
 	/* The following code maps in hypervisor config/status/control space.
 	   It has to be carefully crafted to be an identity mapping.  We ask
 	   for this space to be supplied to us from the hypervisor at
@@ -145,6 +192,30 @@ void __init wrhv_init_IRQ(void)
 
 	/* Setup the global variables used by the vbi */
 	vbi_init(wr_config);
+#else
+	/* vbi_init() needs a non guest-wise per cpu pointer as its parameter.
+	 * for x86-32, it is _wr_config(0xffff0000); Since 0xffff0000 is just
+	 * at the top of kernel space in 32-bit linux, we can reserve them for
+	 * use; However on 64-bit, 0xffff0000 is no longer in kernel space, so
+	 * fixmap is only way to do so. But we can't use fixmaped _wr_config
+	 * (0xffff0000) as parameter of vbi_init, because the pointers in
+	 * _wr_config are still guest-physical address(0xffff0000-0xffffffff),
+	 * not a 64-bit kernel space address, it will cause trouble in future.
+	 * And we can't modify the points in _wr_config since _wr_config is
+	 * set to read-only by hypervisor. So here use per cpu pointer
+	 * corePrivate(writeable) in _wr_config to fake a hypervisor config,
+	 * and change related pointers with fixmaped address then. it works!
+	 */
+	addr = (unsigned long)_wr_config;
+	for (i = WRHV_RESERVED_PAGES - 1; i >= 0; addr += PAGE_SIZE, i--)
+		set_fixmap((FIX_WRHV_RESERVED_BEGIN + i), addr);
+
+	wr_config = (VB_CONFIG *)fix_to_virt(FIX_WRHV_RESERVED_END);
+
+	construct_fake_wr_config();
+	vbi_init(fake_wr_config);
+
+#endif
 
 	/* Now that critical hypervisor global regions are mapped in,
 	   proceed with doing the actual interrupt initialization work.
@@ -157,11 +228,14 @@ void __init wrhv_init_IRQ(void)
 
 		if (i >= NR_IRQS)
 			break;
-		if (vector != SYSCALL_VECTOR)
+
+		if (vector != WRS_SYSCALL_VECTOR)
 			set_intr_gate(vector, interrupt[i]);
 	}
 
+#ifdef CONFIG_X86_32
 	irq_ctx_init(smp_processor_id());
+#endif
 
 	wrhv_setup_timer_irq();
 }
@@ -494,6 +568,7 @@ static int wrhv_write_msr(unsigned int msr, unsigned low, unsigned high)
 
 void wrhv_cpu_workarounds(struct cpuinfo_x86 *c)
 {
+#ifdef CONFIG_X86_32
 	/* Simics workaround */
 	c->hlt_works_ok = 0;
 
@@ -502,16 +577,43 @@ void wrhv_cpu_workarounds(struct cpuinfo_x86 *c)
 
 	clear_bit(X86_FEATURE_DE, (void *)boot_cpu_data.x86_capability);
 	clear_bit(X86_FEATURE_XSAVE, (void *)boot_cpu_data.x86_capability);
+#else
+	setup_clear_cpu_cap(X86_FEATURE_RDTSCP);
+#endif
 }
 
+#ifdef CONFIG_X86_64
+char *__init wrhv_memory_setup(void)
+{
+	char *who = "WRHV-e820";
+	e820_add_region(0, wr_config->phys_mem_size, E820_RAM);
+	e820_add_region((u64)_wr_config, 0x10000, E820_RESERVED);
+	update_e820();
+	return who;
+
+}
+#endif
+
 void __init wrhv_boot_config(void)
 {
 	boot_params.hdr.type_of_loader = 0xff; /* Unknown */
 	if (__initrd_start != __initrd_end) {
-		boot_params.hdr.ramdisk_image = (unsigned long)&__initrd_start - PAGE_OFFSET;
-		boot_params.hdr.ramdisk_size = (unsigned long)&__initrd_end - (unsigned long)&__initrd_start;
+#ifdef CONFIG_X86_32
+		boot_params.hdr.ramdisk_image =
+			(unsigned long)&__initrd_start - PAGE_OFFSET;
+#else
+		boot_params.hdr.ramdisk_image =
+			(unsigned long)&__initrd_start - __START_KERNEL_map;
+#endif
+		boot_params.hdr.ramdisk_size =
+		(unsigned long)&__initrd_end - (unsigned long)&__initrd_start;
 	}
 
+#ifdef CONFIG_X86_64
+	x86_init.resources.memory_setup = wrhv_memory_setup;
+#endif
+	legacy_pic = &null_legacy_pic;
+
 #ifndef WRHV_USE_XMLCONFIG
 	strlcpy(boot_command_line,
 		"pci=conf1 memmap=exactmap memmap=32M@0 mem=nopentium earlyprintk=vga,keep ramdisk_size=16384"
@@ -520,10 +622,17 @@ void __init wrhv_boot_config(void)
 #else
 	/* Use the config space copy here, since we haven't mapped in the
 	   actual hypervisor config/status/control space yet */
+#ifdef CONFIG_X86_32
         snprintf(boot_command_line, COMMAND_LINE_SIZE,
 		"retain_initrd pci=wrhv idle=wrhv serialnumber nolapic nomce nosep memmap=exactmap memmap=%dK@0 %s",
 		wr_config->phys_mem_size / 1024,
 		wr_config->bootLine);
+#else
+	snprintf(boot_command_line, COMMAND_LINE_SIZE,
+		"retain_initrd pci=wrhv idle=wrhv serialnumber nolapic nomce nosep nogbpages noexec=off novtlbopt %s",
+		wr_config->bootLine);
+#endif
+
 #endif
 	if (strstr(boot_command_line, "novtlbopt"))
 		novtlbopt = 1;
@@ -536,7 +645,7 @@ irqreturn_t wrhv_ipi_func_call_single_handler(int irq, void *dev_id)
 {
 	irq_enter();
 	generic_smp_call_function_single_interrupt();
-	__get_cpu_var(irq_stat).irq_call_count++;
+	inc_irq_stat(irq_call_count);
 	irq_exit();
 	return IRQ_HANDLED;
 }
@@ -545,7 +654,7 @@ irqreturn_t wrhv_ipi_func_call_handler(int irq, void *dev_id)
 {
 	irq_enter();
 	generic_smp_call_function_interrupt();
-	__get_cpu_var(irq_stat).irq_call_count++;
+	inc_irq_stat(irq_call_count);
 	irq_exit();
 	return IRQ_HANDLED;
 }
@@ -594,14 +703,14 @@ irqreturn_t wrhv_ipi_inv_tlb_handler(int irq, void *dev_id)
 	smp_mb__after_clear_bit();
 out:
 	put_cpu();
-	__get_cpu_var(irq_stat).irq_tlb_count++;
+	inc_irq_stat(irq_tlb_count);
 
 	return IRQ_HANDLED;
 }
 
 irqreturn_t wrhv_ipi_resched_handler(int irq, void *dev_id)
 {
-	__get_cpu_var(irq_stat).irq_resched_count++;
+	inc_irq_stat(irq_resched_count);
 	return IRQ_HANDLED;
 }
 #endif
@@ -1017,6 +1126,7 @@ static void __cpuinit wrhv_smp_callin(void)
 {
 	int cpuid;
 	unsigned long timeout;
+	int i;
 
 	cpuid = smp_processor_id();
 	if (cpumask_test_cpu(cpuid, cpu_callin_mask)) {
@@ -1041,6 +1151,12 @@ static void __cpuinit wrhv_smp_callin(void)
 			__func__, cpuid);
 	}
 
+	/*
+	 * Need to setup vector mappings before we enable interrupts.
+	 */
+	for (i = FIRST_EXTERNAL_VECTOR; i < NR_VECTORS; i++)
+		__get_cpu_var(vector_irq)[i] = (i-FIRST_EXTERNAL_VECTOR);
+
 	local_irq_enable();
 	calibrate_delay();
 	local_irq_disable();
@@ -1053,15 +1169,21 @@ static void __cpuinit wrhv_smp_callin(void)
 	cpumask_set_cpu(cpuid, cpu_callin_mask);
 }
 
+#ifdef CONFIG_X86_32
 static int low_mappings;
+#endif
 
 static void __cpuinit wrhv_smp_start_cpu(void)
 {
+#ifdef CONFIG_X86_64
+	construct_fake_wr_config();
+#endif
+	cpu_init();
+
 	wrhv_mask_timer_for_vcore(WRHV_VTIMER_INT);
 
 	wrhv_init_vtlb_per_cpu();
 
-	cpu_init();
 	wrhv_umask_IPIs_for_vcore();
 	preempt_disable();
 	wrhv_smp_callin();
@@ -1114,12 +1236,13 @@ static int __cpuinit wrhv_do_boot_cpu(int cpu)
 {
 	unsigned long boot_error = 0;
 	unsigned int timeout;
+	unsigned long start_ip;
 	struct create_idle c_idle = {
 		.cpu = cpu,
 		.done = COMPLETION_INITIALIZER_ONSTACK(c_idle.done),
 	};
 
-	INIT_WORK(&c_idle.work, do_fork_idle);
+	INIT_WORK_ON_STACK(&c_idle.work, do_fork_idle);
 
 	alternatives_smp_switch(1);
 
@@ -1149,12 +1272,23 @@ static int __cpuinit wrhv_do_boot_cpu(int cpu)
 do_rest:
 
 	per_cpu(current_task, cpu) = c_idle.idle;
+#ifdef CONFIG_X86_32
 	irq_ctx_init(cpu);
+#else
+	clear_tsk_thread_flag(c_idle.idle, TIF_FORK);
+	initial_gs = per_cpu_offset(cpu);
+	per_cpu(kernel_stack, cpu) =
+		(unsigned long)task_stack_page(c_idle.idle) -
+		KERNEL_STACK_OFFSET + THREAD_SIZE;
+#endif
 
 	early_gdt_descr.address = (unsigned long)get_cpu_gdt_table(cpu);
 	initial_code = (unsigned long)wrhv_smp_start_cpu;
 	stack_start.sp = (void *) c_idle.idle->thread.sp;
 
+	/* start_ip had better be page-aligned! */
+	start_ip = setup_trampoline();
+
 	printk(KERN_INFO "Booting processor %d\n", cpu);
 
 	boot_error = wrhv_wakeup_secondary_cpu(cpu);
-- 
1.7.4.1

