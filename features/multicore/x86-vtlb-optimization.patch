From 37cf83162e9603576c287b13512186f3a64bc537 Mon Sep 17 00:00:00 2001
From: Weiwei Wang <weiwei.wang@windriver.com>
Date: Fri, 21 May 2010 15:50:08 +0800
Subject: [PATCH 2/2] x86: vtlb optimization

a. native flush_tlb_kernel is better than wrhv_flush_tlb_kernel,
(drop into hypervisor one time less), so change back using
native way;
b. clean redundant code in wrhv_pte_update_defer();
c. clean flush_mm->cpu_vm_mask after issuing vtlb opt
VBI_VTLB_OP_DELETE_PMD, it reduces the number of invalidate
tlb ipi a lot;
d. para function pgd_free is better than exit_mmap to be the place
holder of deleting vtlbs, because what exit_mmap actually want to do
is clearing user space pgd entries and pte entries, but not freeing
the whole pgd page, kernel may still use the pgd(cr3) a while after
exit_mmap. so after we issue vtlb opt VBI_VTLB_OP_DELETE_PMD in
exit_mmap, hypervisor may immediately reconstruct the vtlb cache
again(kernel space),here we not only waste the time of vtlb
reconstruction, but also get no chance to delete this cr3 cache
afterwards. pgd_free is called just before pgd page is freed, so
it is the best place to delete related cr3 cache in hypervisor.

Signed-off-by: Weiwei Wang <weiwei.wang@windriver.com>
---
 arch/x86/kernel/vbi/wrhv.c |   32 +++++++-------------------------
 1 files changed, 7 insertions(+), 25 deletions(-)

diff --git a/arch/x86/kernel/vbi/wrhv.c b/arch/x86/kernel/vbi/wrhv.c
index eaabda1..5ded583 100644
--- a/arch/x86/kernel/vbi/wrhv.c
+++ b/arch/x86/kernel/vbi/wrhv.c
@@ -572,11 +572,12 @@ irqreturn_t wrhv_ipi_inv_tlb_handler(int irq, void *dev_id)
 			leave_mm(cpu);
 		}
 	} else {
-	    if (flush_va == TLB_FLUSH_ALL)
+	    if (flush_va == TLB_FLUSH_ALL) {
 			wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD,
 					__pa(flush_mm->pgd),
 					0, 0);
-	    else
+			cpu_clear(cpu, flush_mm->cpu_vm_mask);
+	    } else
 			wrhv_vtlb_op(VBI_VTLB_OP_UPDATE_PTE,
 					__pa(flush_mm->pgd),
 					(unsigned long)flush_va, 0);
@@ -675,7 +676,6 @@ static void wrhv_pte_update(struct mm_struct *mm, unsigned long addr, pte_t *pte
 
 static void wrhv_pte_update_defer(struct mm_struct *mm, unsigned long addr, pte_t *ptep)
 {
-	if (!is_current_as(mm))
 		wrhv_pte_update (mm, addr, ptep);
 }
 
@@ -694,23 +694,6 @@ static void wrhv_flush_tlb_user(void)
 	native_write_cr3(VTLB_GET_CPU_VAR(cr3_val));
 }
 
-static void wrhv_flush_tlb_kernel(void)
-{
-	unsigned long cr4, flags;
-
-	/*
-	 * This routine is not optimized but since it is very rarely used
-	 * let's not worry too much about this for now.
-	 */
-
-	local_irq_save(flags);
-	cr4 = native_read_cr4();
-	native_write_cr4(cr4 & ~X86_CR4_PGE);
-	native_write_cr3(VTLB_GET_CPU_VAR(cr3_val));
-	native_write_cr4(cr4);
-	local_irq_restore(flags);
-}
-
 static void wrhv_flush_tlb_single(unsigned long addr)
 {
 	__native_flush_tlb_single(addr);
@@ -781,7 +764,7 @@ static unsigned wrhv_patch(u8 type, u16 clobber, void *ibuf,
 	return paravirt_patch_default(type, clobber, ibuf, addr, len);
 }
 
-static void wrhv_exit_mmap(struct mm_struct *mm)
+static void wrhv_pgd_free(struct mm_struct *mm, pgd_t *pgd)
 {
 #ifdef CONFIG_SMP
 	/*
@@ -792,14 +775,14 @@ static void wrhv_exit_mmap(struct mm_struct *mm)
 
 	cpumask_t cpumask;
 	int cpu = get_cpu();
-	wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD, __pa(mm->pgd), 0, 0);
+	wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD, __pa(pgd), 0, 0);
 	cpumask = mm->cpu_vm_mask;
 	cpu_clear(cpu, cpumask);
 	if (!cpus_empty(cpumask))
 	    wrhv_flush_tlb_others (&cpumask, mm, TLB_FLUSH_ALL);
 	put_cpu();
 #else
-	wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD, __pa(mm->pgd), 0, 0);
+	wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD, __pa(pgd), 0, 0);
 #endif
 }
 
@@ -858,10 +841,9 @@ static void wrhv_init_mm(void)
 
 		pv_mmu_ops.release_pmd = wrhv_release_pd;
 
-		pv_mmu_ops.exit_mmap = wrhv_exit_mmap,
+		pv_mmu_ops.pgd_free = wrhv_pgd_free;
 
 		pv_mmu_ops.flush_tlb_user = wrhv_flush_tlb_user;
-		pv_mmu_ops.flush_tlb_kernel = wrhv_flush_tlb_kernel;
 		pv_mmu_ops.flush_tlb_single = wrhv_flush_tlb_single;
 	}
 #ifdef CONFIG_SMP
-- 
1.6.5.2

