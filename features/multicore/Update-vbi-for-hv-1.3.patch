From 0d5b9d8a22cb3285fcb84ab13acf17ecdda24bc3 Mon Sep 17 00:00:00 2001
From: Jim Somerville <Jim.Somerville@windriver.com>
Date: Thu, 19 May 2011 16:22:36 -0400
Subject: [PATCH] Update vbi for hv 1.3

This brings it up to the May 13 release, which is 1.3.1
- also introduces the arm vbi

Signed-off-by: Jim Somerville <Jim.Somerville@windriver.com>
---
 arch/arm/include/asm/arch_vbi.h     |  515 +++++++++++++
 arch/arm/include/asm/reg_vbi.h      |   69 ++
 arch/arm/include/asm/vbi.h          |  262 +++++++
 arch/arm/kernel/vbi/Makefile        |    5 +
 arch/arm/kernel/vbi/show.c          |  158 ++++
 arch/arm/kernel/vbi/syscalls.S      | 1432 +++++++++++++++++++++++++++++++++++
 arch/mips/include/asm/arch_vbi.h    |   48 +--
 arch/mips/include/asm/reg_vbi.h     |   21 +-
 arch/mips/include/asm/vbi.h         |    2 +-
 arch/mips/kernel/vbi/syscalls.S     |  103 +++
 arch/powerpc/include/asm/arch_vbi.h |   25 +-
 arch/powerpc/kernel/vbi/syscalls.S  |   86 ++-
 arch/x86/include/asm/arch_vbi.h     |  284 +-------
 arch/x86/include/asm/reg_vbi.h      |   76 ++-
 arch/x86/kernel/vbi/syscalls.S      |   59 ++-
 include/vbi/compat.h                |   12 +
 include/vbi/cpu_types.h             |    7 +-
 include/vbi/dynamic.h               |  123 +++
 include/vbi/interface.h             |   72 ++-
 include/vbi/pdc.h                   |   45 +-
 include/vbi/syscall.h               |   65 +-
 include/vbi/syscalls.h              |   74 ++-
 include/vbi/types.h                 |    6 +-
 include/vbi/vbi.h                   |   29 +-
 include/vbi/version.h               |    4 +-
 include/vbi/vmmu.h                  |  217 +++---
 kernel/vbi/io_apic.c                |    5 +-
 kernel/vbi/lib.c                    |    2 -
 kernel/vbi/ns.c                     |    6 +-
 kernel/vbi/show.c                   |    6 +-
 kernel/vbi/wrhv.c                   |    1 +
 31 files changed, 3220 insertions(+), 599 deletions(-)
 create mode 100644 arch/arm/include/asm/arch_vbi.h
 create mode 100644 arch/arm/include/asm/reg_vbi.h
 create mode 100644 arch/arm/include/asm/vbi.h
 create mode 100644 arch/arm/kernel/vbi/Makefile
 create mode 100644 arch/arm/kernel/vbi/show.c
 create mode 100644 arch/arm/kernel/vbi/syscalls.S
 mode change 100755 => 100644 arch/mips/include/asm/reg_vbi.h
 mode change 100755 => 100644 arch/mips/include/asm/vbi.h
 create mode 100644 include/vbi/dynamic.h

diff --git a/arch/arm/include/asm/arch_vbi.h b/arch/arm/include/asm/arch_vbi.h
new file mode 100644
index 0000000..d018362
--- /dev/null
+++ b/arch/arm/include/asm/arch_vbi.h
@@ -0,0 +1,515 @@
+/*
+ * arch_vbi.h - ARM architecture specific definitions
+ *
+ * Copyright 2010-2011 Wind River Systems, Inc.
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See the GNU General Public License for more details.
+ *
+ */
+
+#ifndef _ASM_ARCH_VBI_H
+#define _ASM_ARCH_VBI_H
+
+#if (CPU == ARMCA9)
+#define USE_TRUSTZONE
+#endif
+
+/* For now restrict operation to little endian. */
+/* Later this should come from the build system. */
+
+#define __VBI_BYTE_ORDER __VBI_LITTLE_ENDIAN
+
+/* VIOAPIC number of entries */
+
+#define VB_VIOAPIC_ENTRIES_SIZE		    64 
+
+#define _WRHV_ARCH_HAS_STATUS_REGS	    1
+#define _WRHV_ARCH_HAS_CTRL_REGS	    1
+
+#define VB_STATUS_REGS_OFFSET_BASE	 0
+#define VB_STATUS_MODE			(4 * (VB_STATUS_REGS_OFFSET_BASE + 0))
+#define VB_STATUS_DFSR			(4 * (VB_STATUS_REGS_OFFSET_BASE + 1))
+#define VB_STATUS_IFSR			(4 * (VB_STATUS_REGS_OFFSET_BASE + 2))
+#define VB_STATUS_DFAR			(4 * (VB_STATUS_REGS_OFFSET_BASE + 3))
+#define VB_STATUS_IFAR			(4 * (VB_STATUS_REGS_OFFSET_BASE + 4))
+#define VB_STATUS_INTVECTOR		(4 * (VB_STATUS_REGS_OFFSET_BASE + 5))
+#define VB_STATUS_COPROC_RIGHTS		(4 * (VB_STATUS_REGS_OFFSET_BASE + 6))
+#define VB_STATUS_COPROC_GRANTS		(4 * (VB_STATUS_REGS_OFFSET_BASE + 7))
+#define VB_STATUS_BANKED_REGS		(4 * (VB_STATUS_REGS_OFFSET_BASE + 8))
+/* (SPSR, SP, LR) * 16 = 48 */
+
+#define VB_STATUS_REG_STRUCT_END	(4 * (VB_STATUS_REGS_OFFSET_BASE + 56))
+
+#define VB_CONTROL_REGS_OFFSET_BASE	 0
+
+#define VB_CONTROL_CPSR		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 0))
+#define VB_CONTROL_SPSR		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 1))
+#define VB_CONTROL_R0		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 2))
+#define VB_CONTROL_R1		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 3))
+#define VB_CONTROL_R2		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 4))
+#define VB_CONTROL_R3		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 5))
+#define VB_CONTROL_R4		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 6))
+#define VB_CONTROL_R5		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 7))
+#define VB_CONTROL_R6		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 8))
+#define VB_CONTROL_R7		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 9))
+#define VB_CONTROL_R8		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 10))
+#define VB_CONTROL_R9		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 11))
+#define VB_CONTROL_R10		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 12))
+#define VB_CONTROL_R11		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 13))
+#define VB_CONTROL_R12		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 14))
+#define VB_CONTROL_R13		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 15))
+#define VB_CONTROL_R14		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 16))
+#define VB_CONTROL_R15		(4 * (VB_CONTROL_REGS_OFFSET_BASE + 17))
+#define VB_CONTROL_SP		VB_CONTROL_R13
+#define VB_CONTROL_LR		VB_CONTROL_R14
+#define VB_CONTROL_PC		VB_CONTROL_R15
+
+#define VB_CONTROL_REG_STRUCT_END	(4 * (VB_CONTROL_REGS_OFFSET_BASE + 18))
+
+/* status register size for arm */
+
+#ifndef _ASMLANGUAGE
+
+#define VB_STATUS_REGS_ACCESS(base, field)	\
+	base->vb_status_regs.field		
+
+#define VB_CONTROL_REGS_ACCESS(base, field)	\
+	base->vb_control_regs.field		
+
+
+/*
+ * vb_arch_ctrl_regs - Virtual core ARM control structure
+ *
+ * Virtual board emulated control registers. These registers are used
+ * by a guest running on hypervisor to configure the virtual CPU register.
+ *
+ * ARM Control structure graphical illustration
+ *        _______________ 
+ *       |       PC      |
+ *       |---------------|
+ *       |       MSR     |
+ *       |---------------|
+ *       |       CR      |
+ *       |---------------|
+ *       |               |
+ *       |general purpose|
+ *       |     r[0:13]   |
+ *       |               |
+ *       |---------------|
+ *       |emulated MSR   |
+ *       |---------------|
+ *       |       dbsr    |
+ *       |---------------|
+ *       | dbcr[0:2]     |
+ *       |---------------|
+ *       |IAC[1:2]       |
+ *       |---------------|
+ *       |DAC[1:2]       |
+ *       |---------------|
+ *       |reserved[0:9]  |
+ *       |---------------|
+ *
+ */
+
+struct vb_arch_ctrl_regs
+{
+	unsigned long cpsr;		/* saved CPSR */
+	unsigned long spsr;		/* saved SPSR */
+
+	/* registers that can be restored by a sys_ret fast system call */
+
+	unsigned long r0;		/* general purpose register R0  */
+	unsigned long r1;		/* general purpose register R1  */
+	unsigned long r2;		/* general purpose register R2  */
+	unsigned long r3;		/* general purpose register R3  */
+	unsigned long r4;		/* general purpose register R4  */
+	unsigned long r5;		/* general purpose register R5  */
+	unsigned long r6;		/* general purpose register R6  */
+	unsigned long r7;		/* general purpose register R7  */
+	unsigned long r8;		/* general purpose register R8  */
+	unsigned long r9;		/* general purpose register R9  */
+	unsigned long r10;		/* general purpose register R10 */
+	unsigned long r11;		/* general purpose register R11 */
+	unsigned long r12;		/* general purpose register R12 */
+	unsigned long sp;		/* r13 */
+	unsigned long lr;		/* r14 */
+	unsigned long pc;		/* r15 */
+
+	unsigned long asid;		/* Virtual ASID */
+	unsigned long vmmu_handle;  	/* VMMU Handle returned from
+					   vbi_create_vmmu */
+};
+
+/*
+ *
+ * vb_arch_stat_regs - Virtual core emulated status registers
+ *
+ * Virtual board emulated CPU status registers
+ *
+ *
+ * ARM Status structure graphical illustration
+ *        _______________   ---------------------------
+ *       |    SRR0       |
+ *       |---------------|
+ *       |    SRR1       |   Registers save by WRHV
+ *       |---------------|   before injecting an exception/interrupt
+ *       |    CR         |
+ *       |---------------|
+ *       |    LR         |
+ *       |---------------|
+ *       |    r3         |
+ *       |---------------|
+ *       |    r4         |
+ *       |---------------|   ---------------------------
+ *       |    mcsrr0     |
+ *       |---------------|  Registers saved duing exception handling
+ *       |    mcssr1     |
+ *       |---------------|
+ *       |    esr        |
+ *       |---------------|
+ *       |    mcsr       |
+ *       |---------------|
+ *       |    mcar       |
+ *       |---------------|
+ *       |    dear       |
+ *       |---------------|
+ *       |    emsr       |
+ *       |---------------|
+ *       |    esrr0      |
+ *       |---------------|
+ *       |    esrr1      |
+ *       |---------------|    -------------------------
+ *       | reserved[8]   |      8 x 32bits for future enhencements
+ *       |---------------|    -------------------------
+ *       |    svr        |
+ *       |---------------|
+ *       |    pir        |
+ *       |---------------|
+ *       |    pvr        |    Configuration registers updated
+ *       |---------------|    upon board creation
+ *       |    hid0       |
+ *       |---------------|
+ *       |    hid1       |
+ *       |---------------|
+ *       |    buscr      |
+ *       |---------------|
+ *       |    l1csr0     |
+ *       |---------------|
+ *       |    l1csr1     |
+ *       |---------------|   --------------------------
+ *       | reserved[0:8] | 9x 32bit
+ *       |---------------|
+ *
+ */
+
+struct vb_arch_stat_regs
+{
+	/* 
+	 * registers saved by Razor for all interrupts exceptions
+	 * before setting the PC in the virtual board to the exception/interrupt
+	 * vector address
+	 */
+
+	unsigned long mode;
+	unsigned long dfsr;	/* cp15 c5, Data Fault Status Register */
+	unsigned long ifsr;	/* cp15 c5, Instruction Fault Status Register */
+	unsigned long dfar;	/* like cp15 c6, Fault Address Register */
+	unsigned long ifar;	/* like cp15 c6, Fault Address Register */
+	unsigned long intVector; /* vector index indicating highest pri pend */
+
+	/* bit0 = cp0, ..., bit13 = cp13; 1 = grant, 0 = deny */
+	unsigned long coprocRights; /* CP access rights for this VB [13:0] */
+
+	/* CPs that have been granted user-mode access by the VB [13:0] */
+	/* coprocGrants is changed in sync with regs->coprocAccess */
+	unsigned long coprocGrants;
+
+	struct
+	{
+		unsigned long spsr;	/* mode specific SPSR */
+		unsigned long sp;	/* mode specific r13 (stack pointer) */
+		unsigned long lr;	/* mode specific r14 (link register) */
+	} modeSpecificReg[16];
+};
+
+
+/*
+ * VBI_HREG_SET - hardware register set, for read/write
+ *
+ * Used by vbi_vb_read_reg/vbi_vb_write_reg to read/write registers in
+ * another VB
+ *
+ */
+
+#define VBI_GREG_NUM	13	/* has 32 32/64-bit data registers */
+
+typedef struct
+{
+	uint32_t r[VBI_GREG_NUM];	/* general purpose registers 0-12 */
+	INSTR *pc;			/* program counter. aka r[15] */
+	uint32_t cpsr;
+	uint32_t sp_usr;		/* or sys mode. aka r[13] */
+	uint32_t lr_usr;		/* or sys mode. aka r[14] */
+} VBI_HREG_SET;
+
+
+/* complex register set definition */
+
+typedef union
+{
+	VBI_HREG_SET    hreg32;	/* 32 bit register set */
+} VBI_HREG_SET_CMPLX;
+
+
+typedef struct
+{
+	uint32_t	vbiRegType;
+	VBI_HREG_SET_CMPLX vbiRegSet;
+} VBI_HREG_SET_CMPLX_QUALIFIED;
+
+/* common system wide message header structure */
+
+typedef struct vbi_msg_header {
+	uint32_t msgId;	/* message type identification */
+	uint32_t msgArg;	/* argument associated with message type */
+} VBI_MSG_HEADER;
+
+/* request message */
+
+typedef struct 
+    {
+    VBI_MSG_HEADER hdr;			/* message header */
+    uint32_t   request;			/* request type */
+
+    } VBI_BSP_MSG;
+
+typedef struct 
+{
+	VBI_MSG_HEADER hdr;			/* message header */
+	uint32_t   status;			/* request completion status */
+	uint32_t   dataVal;
+} VBI_BSP_MSG_REPLY;
+
+#else /*_ASMLANGUAGE */
+
+/*
+ *
+ * VBI_INT_VCORE_LOCK - lock a core's interrupts macro
+ *
+ * This macro disables the currently running core interrupts and returns the
+ * previous state.
+ *
+ * A hypercall is not needed to perform this operation. 
+ *
+ */
+
+#define ARM_IMM	#
+#define CPSR_I	0x80
+#define CPSR_F	0x40
+
+#ifdef USE_TRUSTZONE
+
+/*
+ * Trustzone Implementation
+ *
+ * REG0 = CPSR
+ * REG0 &= (CPSR_I | CPSR_F)
+ * set CPSR.I and CPSR.F
+ *
+ * REG1 and REG2 not used.
+ */
+
+#define VBI_INT_VCORE_LOCK(REG0, REG1, REG2) \
+	mrs	REG0, cpsr;					\
+	and	REG0, REG0, ARM_IMM (CPSR_I | CPSR_F);		\
+	cpsid	if
+
+#else /* USE_TRUSTZONE */
+
+/*
+ * Non-Trustzone Implementation
+ *
+ * wrhvVbControl->intDisable = -1; return old value
+ *
+ * REG1 = -1
+ * REG2 = &wrvhVbControl
+ * REG2 = wrvhVbControl
+ * REG0 = wrhvVbControl->intDisable
+ * wrhvVbControl->intDisable = REG1
+ *
+ * THIS NON-TRUSTZONE VERSION IS NOT TESTED.
+ */
+
+#define VBI_INT_VCORE_LOCK(REG0, REG1, REG2) \
+	mvn	REG1, ARM_IMM 0;				\
+	ldr	REG2, =wrhvVbControl;				\
+	ldr	REG2, [REG2];					\
+	ldr	REG0, [REG2, ARM_IMM VB_CONTROL_INT_DISABLE];	\
+	str	REG1, [REG2, ARM_IMM VB_CONTROL_INT_DISABLE]
+
+#endif /* USE_TRUSTZONE */
+
+/*
+ *
+ * VBI_INT_VCORE_UNLOCK - unlock a core's interrupts
+ *
+ * This macro enables a core's interrupts.
+ *
+ */
+
+#ifdef USE_TRUSTZONE
+
+/*
+ * Trustzone Implementation
+ *
+ * Clear CPSR.I and CPSR.F. No hypercall is needed; any pending interrupts
+ * are immediately taken.
+ *
+ * REG0 and REG1 not used.
+ */
+
+#define VBI_INT_VCORE_UNLOCK(REG0, REG1) \
+	cpsie	if
+
+#else /* USE_TRUSTZONE */
+
+/*
+ * Non-Trustzone Implementation
+ *
+ * wrhvVbControl->intDisable = 0;
+ * if (wrhvVbControl->intPending != 0xffff)
+ *     syscall
+ *
+ * THIS NON-TRUSTZONE VERSION IS NOT COMPLETE. The #if 0 code is partial; the
+ * #else code intentionally does nothing, and should make it obvious when it
+ * is first used that it needs finishing and testing.
+ *
+ * It is NOT a good idea to just set intDisable to zero, without figuring out
+ * how to decide if a syscall is needed and then making it if so, since that
+ * would "kinda work".
+ */
+
+#if 0
+#define VBI_INT_VCORE_UNLOCK(REG0, REG1) \
+	mov	REG0, ARM_IMM 0;				\
+	ldr	REG1, =wrhvVbControl;				\
+	ldr	REG1, [REG1];					\
+	str	REG0, [REG1, ARM_IMM VB_CONTROL_INT_DISABLE]
+/* XXX check if any interrupts are pending and if so, make hypercall */
+#else
+#define VBI_INT_VCORE_UNLOCK(REG0, REG1)
+#endif
+
+#endif /* USE_TRUSTZONE */
+
+/*
+ *
+ * VBI_INT_VCORE_STATE_GET - Get interrupts state
+ *
+ * This macro reads the interrupt state of the currently running core. It uses
+ * a passed in general purpose register to store the current state of
+ * interrupts.  The status is nonzero if locked or 0 if not locked.
+ *
+ */
+
+#ifdef USE_TRUSTZONE
+
+/*
+ * Trustzone Implementation
+ *
+ * REG0 = CPSR
+ * REG0 &= (CPSR_I | CPSR_F)
+ */
+
+#define VBI_INT_VCORE_STATE_GET(REG0) \
+	mrs	REG0, cpsr;					\
+	and	REG0, REG0, ARM_IMM (CPSR_I | CPSR_F)
+
+#else /* USE_TRUSTZONE */
+
+/*
+ * Non-Trustzone Implementation
+ *
+ * return wrhvVbControl->intDisable;
+ *
+ * REG0 = &wrvhVbControl
+ * REG0 = wrvhVbControl
+ * REG0 = wrhvVbControl->intDisable
+ *
+ * THIS NON-TRUSTZONE VERSION IS NOT TESTED.
+ */
+
+#define VBI_INT_VCORE_STATE_GET(REG0) \
+	ldr	REG0, =wrhvVbControl;				\
+	ldr	REG0, [REG0];					\
+	ldr	REG0, [REG0, ARM_IMM VB_CONTROL_INT_DISABLE]
+
+#endif /* USE_TRUSTZONE */
+
+/*
+ *
+ * VBI_CONFIG_ADDR_GET - Get virtual core configuration structure base address
+ *
+ * This macro returns the base address of the configuration structure of the 
+ * running core. 
+ *
+ */
+
+#if 0
+#define VBI_CONFIG_ADDR_GET(reg)		    \
+        lis     reg, HIADJ(wrhvVbConfig);	    \
+        lwz     reg, LO(wrhvVbConfig)(reg)	    
+#endif
+
+/*
+ *
+ * VBI_CNTRL_ADDR_GET - Get virtual core control structure base address
+ *
+ * This macro returns the base address of the running virtual core's control
+ * structure.
+ *
+ */
+
+#if 0
+#define VBI_CNTRL_ADDR_GET(reg)			    \
+        lis     reg, HIADJ(wrhvVbControl);	    \
+        lwz     reg, LO(wrhvVbControl)(reg) 	     
+#endif
+
+/*
+ *
+ * VBI_STATUS_ADDR_GET - Get virtual core status structure address
+ *
+ * This macro returns the base address of the status structure of currently
+ * running core. This structure is read-only and contains a description of
+ * the running virtual core. Hypervisor uses this data to inform the
+ * virtual board time variant data that may be updated during hypervisor context
+ * Switch. Typical that are available in the status structure are:
+ *
+ *Timer tick counter
+ *
+ *Pending interrupt state
+ *
+ *The interrupt state before this core was schedule
+ *
+ *VMMU configuration
+ *
+ *Virtual core registers state
+ *
+ */
+
+#if 0
+#define VBI_STATUS_ADDR_GET(reg)			    \
+        lis     reg, HIADJ(wrhvVbStatus);		    \
+        lwz     reg, LO(wrhvVbStatus)(reg)	     
+#endif
+
+#endif /*_ASMLANGUAGE */
+    
+#endif /* _ASM_ARCH_VBI_H */
diff --git a/arch/arm/include/asm/reg_vbi.h b/arch/arm/include/asm/reg_vbi.h
new file mode 100644
index 0000000..99bbd25
--- /dev/null
+++ b/arch/arm/include/asm/reg_vbi.h
@@ -0,0 +1,69 @@
+/*
+ * arm reg_vbi.h - ARMv6 cpu registers */
+ *
+ * Copyright (c) 2008-2010 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See the GNU General Public License for more details.
+ *
+ */
+
+#ifndef __INCarmRegsh
+#define __INCarmRegsh
+
+#define GREG_NUM        13      /* general purpose registers */
+#define	_ARM_HREG_SIZE	4	/* only support 32-bit registers */
+
+#define VFP_D_NUM	32      /* VFP has 32 single-precision registers */
+
+#ifndef	_ASMLANGUAGE
+
+/* some common names for registers */
+
+#define fpReg           r[11]   /* frame pointer */
+
+#endif	/* _ASMLANGUAGE */
+
+#define HREG_SET_G_REG_BASE     0x00
+#define HREG_SET_GR(n)		(HREG_SET_G_REG_BASE + _ARM_HREG_SIZE*(n))
+#define HREG_SET_PC		(_ARM_HREG_SIZE*13)
+#define HREG_SET_CPSR		(_ARM_HREG_SIZE*14)
+
+#define HREG_SET_SP_USR		(_ARM_HREG_SIZE*15)
+#define HREG_SET_LR_USR		(_ARM_HREG_SIZE*16)
+
+#define HREG_SET_UNBANKED_SIZE	(HREG_SET_LR_USR + _ARM_HREG_SIZE)
+
+/* Banked registers */
+#define HREG_SET_SP_SVC		(_ARM_HREG_SIZE*17)
+#define HREG_SET_LR_SVC		(_ARM_HREG_SIZE*18)
+
+#define HREG_SET_SP_ABT		(_ARM_HREG_SIZE*19)
+#define HREG_SET_LR_ABT		(_ARM_HREG_SIZE*20)
+
+#define HREG_SET_SP_UND		(_ARM_HREG_SIZE*21)
+#define HREG_SET_LR_UND		(_ARM_HREG_SIZE*22)
+
+#define HREG_SET_SP_IRQ		(_ARM_HREG_SIZE*23)
+#define HREG_SET_LR_IRQ		(_ARM_HREG_SIZE*24)
+
+/* FIQ register base */
+#define HREG_SET_SPSR_FIQ_GREG	(_ARM_HREG_SIZE*25)
+#define HREG_SET_SP_FIQ		(_ARM_HREG_SIZE*30)
+#define HREG_SET_LR_FIQ		(_ARM_HREG_SIZE*31)
+
+#define HREG_SET_SPSR_SVC	(_ARM_HREG_SIZE*32)
+#define HREG_SET_SPSR_ABT	(_ARM_HREG_SIZE*33)
+#define HREG_SET_SPSR_UND	(_ARM_HREG_SIZE*34)
+#define HREG_SET_SPSR_IRQ	(_ARM_HREG_SIZE*35)
+#define HREG_SET_SPSR_FIQ	(_ARM_HREG_SIZE*36)
+
+#define HREG_SET_COPROC_ACCESS	(_ARM_HREG_SIZE*37)
+
+#endif /* __INCarmRegsh */
diff --git a/arch/arm/include/asm/vbi.h b/arch/arm/include/asm/vbi.h
new file mode 100644
index 0000000..d116241
--- /dev/null
+++ b/arch/arm/include/asm/vbi.h
@@ -0,0 +1,262 @@
+/*
+ * asm/vbi.h - ARM tool dependent headers
+ *
+ * Copyright 2008-2010 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See the GNU General Public License for more details.
+ *
+ */
+
+#ifndef __INCsysArmAsmh
+#define __INCsysArmAsmh
+
+#if !defined(_DIAB_TOOL) && !defined(_GNU_TOOL)
+#define	_GNU_TOOL
+#endif
+
+#define	_ARM_HREG_SIZE		4	/* default register size */
+#define _ARM_TEXT_SEG_ALIGN     4	/* 4 byte text segment alignment */
+#define REG_STORAGE		(_ARM_HREG_SIZE * 16)
+#define _ARM_VECTOR_SEG_ALIGN	0x1000	/* page alignment */
+
+/* macros for stack frame */
+
+/*
+SVR4 Stack space allocation:
+
+    Before Dynamic stack allocation
+
+    +----------------------------------+
+    |       Back Chain                 |
+    |----------------------------------|
+    |  Register save areas             |
+    |----------------------------------|
+    |  local,non-static variables      |
+    |----------------------------------|
+    |  parameter lists for callees     | (overloaded parameters with #)
+    |----------------------------------|
+    |      LR save word                |
+    |----------------------------------|
+SP=>|      Back chain                  |
+    +----------------------------------+
+
+    After Dynamic stack allocation
+
+    +----------------------------------+
+    |       Back Chain                 |
+    |----------------------------------|
+    |  Register save areas             |
+    |----------------------------------|
+    |  local,non-static variables      |
+    |----------------------------------|
+    |  Dynamic Allocation Area         | 16 byte stack alignment
+    |----------------------------------|
+    |  parameter lists for callees     |
+    |----------------------------------|
+    |      LR save word                |
+    |----------------------------------|
+SP=>|      Back chain                  |
+    +----------------------------------+ 16 bytes stack alignment
+*/
+
+  /* Stack and Allocation alignment */
+
+/*
+ * While it is possible to use different stack alignments for different
+ * ARM processors, current compilers use 16-byte alignment for all.
+ */
+
+#define _CPU_STACK_ALIGN_SIZE	16	/* stack alignment (for all ARM) */
+#define	_CPU_STACK_ALIGN_SHIFT	4
+
+#define	FRAMEBASESZ		16	/* minimum stack frame size */
+
+/*
+ *
+ * _WRS_ARCH_USER_STACK_FRAME_EXTENSION - creating words on the stack for the 
+ *                                        back chain word and the LR register.
+ *
+ * This macro is used in creating the initial stack frame for an RTP's initial 
+ * task. It performs the extra steps of creating words on the stack for the 
+ * back chain word and the LR register. Both these locations are set to 0 to 
+ * prevent stack traces and debuggers from looking ahead.
+ *
+ */
+
+#define _WRS_ARCH_USER_STACK_FRAME_EXTENSION(sp)			     \
+do									     \
+{								     \
+	(sp) -= 2*sizeof(int *);					     \
+	*((int *)(sp)) = (int)0;					     \
+	*((int *)((sp)+4)) = (int)0;					     \
+} while ((0))
+
+
+#ifdef	_ASMLANGUAGE
+
+#define hash #
+
+#ifdef	_GNU_TOOL
+
+/* Macro for hiadjust and lo */
+
+#define HIADJ(arg)	arg@ha
+#define HI(arg)		arg@h
+#define LO(arg)		arg@l
+
+#endif	/* _GNU_TOOL */
+
+#ifdef	_DIAB_TOOL
+
+/* Macro for hiadjust and lo */
+
+#define HIADJ(arg)      %hiadj(arg)
+#define HI(arg)		%hi(arg)
+#define LO(arg)      	%lo(arg)
+
+#endif	/* _DIAB_TOOL */
+
+/*
+ * define r2 as VTOC/GOT(EABI), system use(SVR4)/TOC/GOT(PO),dedicated. 
+ * define r13 as CTOC/GOT anchor pointer, dedicated (EABI), non-volatile
+ * register (SVR4, PO) 
+ */
+
+#define FUNC(func)	    func
+#define FUNC_LABEL(func)    func:
+#define VAR(name) name
+
+#if ARM_THUMB 
+#define _ARM_FUNCTION_CALLED_FROM_C(a) \
+	.code	16	;\
+	.balign	4	;\
+	.thumb_func	;\
+a:			;\
+	BX	pc	;\
+	NOP		;\
+	.code	32	;\
+A##a:
+#else
+#define _ARM_FUNCTION_CALLED_FROM_C(a) \
+	.code	32	;\
+	.balign	4	;\
+a:
+#endif
+
+#define _ARM_FUNCTION(a)	\
+	.code	32	;\
+	.balign	4	;\
+a:
+
+#if ARM_THUMB
+#define _THUMB_FUNCTION(a)	\
+	.code	16	;\
+	.balign	2	;\
+	.thumb_func	;\
+a:
+#endif
+
+/* place the address of label into register r */
+#define _ARM_PER_CPU_ADRS_GET(r, scratch, label)              \
+        _ARM_CPU_INDEX_GET(r)                      ; \
+        ADD  r, r, r, LSL ARM_WIND_VARS_ALIGN_SHIFT         ; \
+        LDR  scratch, L$_vxKernelVars                       ; \
+        ADD  scratch, scratch, ARM_HASH _ARM_WIND_VARS_OFFSET(label) ; \
+        ADD  r, r, scratch
+
+/* place the value at label into register r */
+#define _ARM_PER_CPU_VALUE_GET(r,scratch,label)               \
+        _ARM_CPU_INDEX_GET(r)                      ; \
+        ADD  r, r, r, LSL ARM_WIND_VARS_ALIGN_SHIFT         ; \
+        LDR  scratch, L$_vxKernelVars                       ; \
+        ADD  scratch, scratch, ARM_HASH _ARM_WIND_VARS_OFFSET(label) ; \
+        ADD  r, r, scratch                                  ; \
+        LDR  r, [r]
+
+/* place value at label in ra, also place address at label in rv */
+#define _ARM_PER_CPU_VALUE_AND_ADRS_GET(rv,ra,label)       \
+        _ARM_CPU_INDEX_GET(rv)                       ; \
+        ADD  rv, rv, rv, LSL ARM_WIND_VARS_ALIGN_SHIFT   ; \
+        LDR  ra, L$_vxKernelVars                         ; \
+        ADD  ra, ra, ARM_HASH _ARM_WIND_VARS_OFFSET(label)        ; \
+        ADD  ra, ra, rv                                  ; \
+        LDR  rv, [ra]
+
+#define	FUNC_EXPORT(func)	.global	func ;
+#define	DATA_EXPORT(var)	.globl	VAR(var)
+#define	FUNC_IMPORT(func)	.extern	FUNC(func)
+#define	DATA_IMPORT(var)	.extern	VAR_DECL(var)
+#define	FUNC_BEGIN(func)	FUNC_LABEL(func)
+#define	FUNC_END(func)		.size	FUNC(func), . - FUNC(func)
+
+/* Macro for beginning a text segment */
+
+#define _WRS_TEXT_SEG_START \
+        .text ; .balign _ARM_TEXT_SEG_ALIGN
+
+#define	FRAMESZ(nregs)	\
+    	  ALIGN_UP((FRAMEBASESZ + nregs * _ARM_HREG_SIZE), _STACK_ALIGN_SIZE)
+
+#define AUDIT_STUB_CREATE(x)           \
+        FUNC_EXPORT(x);            \
+        FUNC_BEGIN(x);             \
+        FUNC_END(x);              
+
+#define AUDIT_STUB_VAR(x)              \
+        DATA_EXPORT(x)              \
+        x:
+
+/* Macro to form the contents of the CONTEXTIDR register
+ *
+ * Inputs: ctx (ctx *), asid
+ * Output: ctx (unchanged), asid (CONTEXTIDR)
+ */
+
+#define BUILD_CONTEXTIDR(ctx, asid, x, y)			\
+	/* find ctx->id */					\
+	ldr	x, [ctx, hash(CTX_ID_OFF)]			; \
+	ldr	y, =(CONTEXTIDR_CTXID_BASEMASK)			; \
+	and	x, x, y						; \
+	orr	asid, asid, x, lsl hash(CONTEXTIDR_CTXID_SHIFT)	; \
+	/* find ctx->mmu->vmmuHandle */				; \
+	ldr	x, [ctx, hash(CTX_MMU_OFF)]			; \
+	ldr	x, [x, hash(CTX_MMU_VMMU_HANDLE)]		; \
+	ldr	y, =(CONTEXTIDR_PROCHANDLE_BASEMASK)		; \
+	and	x, x, y						; \
+	orr	asid, asid, x, lsl hash(CONTEXTIDR_PROCHANDLE_SHIFT);
+
+#else	/* _ASMLANGUAGE */
+
+#define _WRS_ASM(x) __asm volatile (x)
+
+/*
+ * Use constant sizes if known (when building for a specific CPU type)
+ * else fetch from a global variable (when building for generic ARM)
+ */
+
+#ifdef	_CPU_STACK_ALIGN_SIZE
+#define	_STACK_ALIGN_SIZE	_CPU_STACK_ALIGN_SIZE
+#else	/* _CPU_STACK_ALIGN_SIZE */
+#define	_STACK_ALIGN_SIZE	_armStackAlignSize
+extern	int	_armStackAlignSize;
+#endif	/* _CPU_STACK_ALIGN_SIZE */
+
+#ifdef	_CPU_ALLOC_ALIGN_SIZE
+#define	_ALLOC_ALIGN_SIZE	_CPU_ALLOC_ALIGN_SIZE
+#else	/* _CPU_ALLOC_ALIGN_SIZE */
+#define	_ALLOC_ALIGN_SIZE	_armAllocationQuantumSize
+extern	int	_armAllocationQuantumSize;
+#endif	/* _CPU_ALLOC_ALIGN_SIZE */
+
+#define	FUNCREF(func)	func
+
+#endif	/* _ASMLANGUAGE */
+
+#endif /* __INCsysArmAsmh */
diff --git a/arch/arm/kernel/vbi/Makefile b/arch/arm/kernel/vbi/Makefile
new file mode 100644
index 0000000..6639318
--- /dev/null
+++ b/arch/arm/kernel/vbi/Makefile
@@ -0,0 +1,5 @@
+#
+# Makefile for the vbi arm.
+#
+
+obj-y		:= syscalls.o wrhv.o show.o
diff --git a/arch/arm/kernel/vbi/show.c b/arch/arm/kernel/vbi/show.c
new file mode 100644
index 0000000..a320046
--- /dev/null
+++ b/arch/arm/kernel/vbi/show.c
@@ -0,0 +1,158 @@
+/* show.c - vbi ARM show routines */
+
+/*
+ * Copyright (c) 2010 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See the GNU General Public License for more details.
+ *
+ */
+
+
+#include <linux/kernel.h>
+#include <vbi/vbi.h>
+
+/*******************************************************************************
+ *
+ * vbi_disp_status_regs - display registers from a vb_status
+ *
+ * This routine display the contents of the ARM emulated status registers
+ * structure on the console.
+ *
+ */
+
+void vbi_disp_status_regs(void)
+    {
+    struct vb_status *p = VBI_STATUS_ADDR_GET();
+
+    printk ("  dfsr/ifsr:            0x%08x 0x%08x\n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, dfsr) ,
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, ifsr));
+
+    printk ("  dfar/ifar:            0x%08x 0x%08x\n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, dfar) ,
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, ifar));
+
+    printk ("  mode/intVector:       0x%08x 0x%08x\n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, mode) ,
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, intVector));
+
+    printk ("  cpRights/cpGrants:    0x%08x 0x%08x\n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, coprocRights) ,
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, coprocGrants));
+
+    printk ("  User Mode spsr:       0x%08x \n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[0].spsr));
+
+    printk ("  User Mode sp/lr:      0x%08x 0x%08x\n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[0].sp) ,
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[0].lr));
+
+    printk ("  FIQ Mode spsr:        0x%08x \n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[1].spsr));
+
+    printk ("  FIQ Mode sp/lr:       0x%08x 0x%08x\n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[1].sp) ,
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[1].lr));
+
+    printk ("  IRQ Mode spsr:        0x%08x \n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[2].spsr));
+
+    printk ("  IRQ Mode sp/lr:       0x%08x 0x%08x\n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[2].sp) ,
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[2].lr));
+
+    printk ("  SVC Mode spsr:        0x%08x \n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[3].spsr));
+
+    printk ("  SVC Mode sp/lr:       0x%08x 0x%08x\n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[3].sp) ,
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[3].lr));
+
+    printk ("  MON Mode spsr:        0x%08x \n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[6].spsr));
+
+    printk ("  MON Mode sp/lr:       0x%08x 0x%08x\n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[6].sp) ,
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[6].lr));
+
+    printk ("  Abort Mode spsr:      0x%08x \n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[7].spsr));
+
+    printk ("  Abort Mode sp/lr:     0x%08x 0x%08x\n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[7].sp) ,
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[7].lr));
+
+    printk ("  Undef Mode spsr:      0x%08x \n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[0x0B].spsr));
+
+    printk ("  Undef Mode sp/lr:     0x%08x 0x%08x\n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[0x0B].sp) ,
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[0x0B].lr));
+
+    printk ("  SYS Mode spsr:        0x%08x \n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[0x0F].spsr));
+
+    printk ("  SYS Mode sp/lr:       0x%08x 0x%08x\n",
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[0x0F].sp) ,
+        (unsigned int)VB_STATUS_REGS_ACCESS (p, modeSpecificReg[0x0F].lr));
+
+
+       }
+
+/*******************************************************************************
+ *
+ * vbi_disp_ctrl_regs - display registers from a vb_control
+ *
+ * This routine display the contents of the ARM emulated status registers
+ * structure on the console.
+ *
+ */
+
+void vbi_disp_ctrl_regs(void)
+    {
+    struct vb_control * p = VBI_CNTRL_ADDR_GET();
+
+    printk ("  cpsr/spsr:            0x%08x 0x%08x\n",
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, cpsr) ,
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, spsr));
+
+    printk ("  r0/r1:                0x%08x 0x%08x\n",
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, r0) ,
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, r1));
+
+    printk ("  r2/r3:                0x%08x 0x%08x\n",
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, r2) ,
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, r3));
+
+    printk ("  r4/r5:                0x%08x 0x%08x\n",
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, r4) ,
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, r5));
+
+    printk ("  r6/r7:                0x%08x 0x%08x\n",
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, r6) ,
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, r7));
+
+    printk ("  r8/r9:                0x%08x 0x%08x\n",
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, r8) ,
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, r9));
+
+    printk ("  r10/r11:              0x%08x 0x%08x\n",
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, r10) ,
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, r11));
+
+    printk ("  r12/sp:               0x%08x 0x%08x\n",
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, r12) ,
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, sp));
+
+    printk ("  lr/pc:                0x%08x 0x%08x\n",
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, lr) ,
+        (unsigned int)VB_CONTROL_REGS_ACCESS (p, pc));
+
+    }
diff --git a/arch/arm/kernel/vbi/syscalls.S b/arch/arm/kernel/vbi/syscalls.S
new file mode 100644
index 0000000..b2c042a
--- /dev/null
+++ b/arch/arm/kernel/vbi/syscalls.S
@@ -0,0 +1,1432 @@
+/* syscalls.S - hypervisor system calls */
+
+/*
+ * Copyright (c) 2007-2008,2010 Wind River Systems, Inc.
+ *
+ * The right to copy, distribute, modify or otherwise make use
+ * of this software may be licensed only pursuant to the terms
+ * of an applicable Wind River license agreement.
+ */
+
+/*
+DESCRIPTION
+
+This file implements the hypervisor system call stubs for the hypervisor.
+
+Note that for multiple reasons (consistent interface vs ppc, pushing work
+from hypervisor into guest context, not having to access user-mode SP from
+SVC, etc...) r0-r7 are loaded with the (up to) 8 arguments for the syscall.
+This breaks with ARM ABI, which would normally store the first 4 args in
+r0-r3 and any additional args on the stack. This is most useful for fast
+syscalls - normal syscalls have to push the registers onto the stack for
+the C function sysCallHandler().
+
+For this reason and others, THIS CODE WILL PROBABLY NOT WORK IN THUMB MODE.
+
+*/
+
+#define _ASMLANGUAGE
+
+#include <vbi/vbi.h>
+#include <asm/vbi.h>
+
+#if (CPU == ARMCA9)
+#define USE_TRUSTZONE
+#endif
+
+/* TLB Unified (Instruction + Data) Invalidate All */
+#undef TLBIALL
+#define TLBIALL(x)		mcr    p15, 0, x, c8, c7, 0
+
+/* TLB Unified (Instruction + Data) Invalidate by ASID */
+#undef TLBIASID
+#define TLBIASID(x)		mcr    p15, 0, x, c8, c7, 2
+
+/* Context ID Register */
+#undef CONTEXTIDR_READ
+#define CONTEXTIDR_READ(x)	mrc     p15, 0, x, c13, c0, 1
+
+#undef HASH
+#define HASH #
+
+#define INVALIDATE_CURR_ASID(temp)	\
+	CONTEXTIDR_READ(temp)		;\
+	and     temp, temp, HASH(0xFF)	;\
+	TLBIASID(temp)
+
+        /* globals */
+
+        /* vbiIdle */
+        FUNC_EXPORT(vbi_ctx_ctl)
+
+        /* vbiLib */
+        FUNC_EXPORT(vbi_vb_suspend)
+        FUNC_EXPORT(vbi_vb_reset)
+        FUNC_EXPORT(vbi_vb_restart)
+        FUNC_EXPORT(vbi_vb_resume)
+        FUNC_EXPORT(vbi_kputs)
+        FUNC_EXPORT(vbi_kputc)
+        FUNC_EXPORT(vbi_panic)
+        FUNC_EXPORT(vbi_shell_start_debug)
+        FUNC_EXPORT(vbi_vb_read_mem)
+        FUNC_EXPORT(vbi_vb_write_mem)
+        FUNC_EXPORT(vbi_vb_read_reg)
+        FUNC_EXPORT(vbi_vb_write_reg)
+        FUNC_EXPORT(vbi_set_mem_attr)
+        FUNC_EXPORT(vbi_get_mem_attr)
+        FUNC_EXPORT(vbi_vb_remote)
+
+	/* Dynamic VB API */
+	FUNC_EXPORT(vbi_vb_create)
+	FUNC_EXPORT(vbi_vb_delete)
+	FUNC_EXPORT(vbi_board_simple_config_get)
+	FUNC_EXPORT(vbi_board_config_get)
+	FUNC_EXPORT(vbi_vb_move)
+	FUNC_EXPORT(vbi_vb_priority_set)
+
+        /* vbiMsg */
+        FUNC_EXPORT(vbi_rx_op)
+        FUNC_EXPORT(vbi_reply)
+        FUNC_EXPORT(vbi_send)
+
+        /* vbiNs */
+        FUNC_EXPORT(vbi_ns_op)
+
+        /* vbiPaddr */
+        FUNC_EXPORT(vbi_hy_ioctl)
+
+        /* vbiVioApic */
+        FUNC_EXPORT(vbi_io_apic_op)
+        FUNC_EXPORT(vbi_io_apic_ioctl)
+        FUNC_EXPORT(vbi_vcore_irq_redirect)
+
+	FUNC_EXPORT(vbi_flush_icache)
+	FUNC_EXPORT(vbi_flush_dcache)
+	FUNC_EXPORT(vbi_update_text_cache)
+
+        /* vbiVmmu */
+        FUNC_EXPORT(vbi_config_vmmu)
+        FUNC_EXPORT(vbi_enable_vmmu)
+        FUNC_EXPORT(vbi_disable_vmmu)
+        FUNC_EXPORT(vbi_create_vmmu)
+        FUNC_EXPORT(vbi_delete_vmmu)
+        FUNC_EXPORT(vbi_flush_tlb)
+
+        /* ARM */
+        FUNC_EXPORT(vbi_vcore_irq_lock)
+        FUNC_EXPORT(vbi_vcore_irq_unlock)
+        FUNC_EXPORT(vbi_vcore_irq_state)
+        FUNC_EXPORT(vbi_set_exc_base)
+        FUNC_EXPORT(vbi_set_exc_offset)
+        FUNC_EXPORT(vbi_get_exc_offset)
+	FUNC_EXPORT(vbi_load_ctx)
+
+
+        /*
+         * This macro saves the R8 register that is used for holding the HV function
+         * code, saves registers r4-r7 that are needed for passing additional args
+         * to the HV, and also loads them with values from the caller's stack
+         * frame.
+         * It is the caller's responsibility to set the number of args that are
+         * needed from the stack.
+         */
+        .macro  SAVEREGS regs=0
+        .if (\regs == 0)
+                stmfd   sp!, {r8}
+        .elseif (\regs == 1)
+                stmfd   sp!, {r4,r8}
+                ldr     r4, [sp, #0x8]
+        .elseif (\regs == 2)
+                stmfd   sp!, {r4-r5,r8}
+                ldr     r4, [sp, #0x0c]
+                ldr     r5, [sp, #0x10]
+        .elseif (\regs == 3)
+                stmfd   sp!, {r4-r6,r8}
+                ldr     r4, [sp, #0x10]
+                ldr     r5, [sp, #0x14]
+                ldr     r6, [sp, #0x18]
+        .elseif (\regs == 4)
+                stmfd   sp!, {r4-r7,r8}
+                ldr     r4, [sp, #0x14]
+                ldr     r5, [sp, #0x18]
+                ldr     r6, [sp, #0x1c]
+                ldr     r7, [sp, #0x20]
+        .else
+                .err
+        .endif
+        .endm
+
+        /*
+         * This macro restores registers saved by the SAVEREGS macro above.
+         * The caller must specify the number of regs that were pushed - it
+         * must match the value given to SAVEREGS.
+         */
+        .macro  RESTOREREGS     regs=0
+        .if (\regs == 0)
+                ldmfd   sp!, {r8}
+        .elseif (\regs == 1)
+                ldmfd   sp!, {r4, r8}
+        .elseif (\regs == 2)
+                ldmfd   sp!, {r4-r5, r8}
+        .elseif (\regs == 3)
+                ldmfd   sp!, {r4-r6, r8}
+        .elseif (\regs == 4)
+                ldmfd   sp!, {r4-r7, r8}
+        .else
+                .err
+        .endif
+        .endm
+
+        /*
+         * How a hypercall is made depends on whether trustzone is
+         * implemented in the core or not.
+         */
+        .macro  HCALL
+#ifdef USE_TRUSTZONE
+	smc     #0
+#else /* not trustzone */
+        swi     #HY_CALL_ID
+#endif
+        .endm
+
+        _WRS_TEXT_SEG_START
+
+/******************************************************************************
+*
+* vbi_load_ctx - hypervisor context load call
+*
+* This system call implements guest-side context-switch functionality.
+*
+* For a thread-based guest operating system, this may provide support for
+* loading a new set of general purpose registers (see below).
+*
+* For a process-based guest operating system, this may provide support for
+* loading a new set of general purpose registers (see below) and a new
+* virtual memory context.
+*
+* For privileged guests, this call will only affect the virtual memory
+* context - all other registers may be loaded directly by the guest
+* afterwards.
+*
+* For unprivileged guests, this call will affect the virtual memory
+* context, and will also perform the context switch of the general
+* purpose registers.
+*
+* For privileged guests, the following values will be taken from the
+* VB control structure and loaded / take effect:
+*
+* asid (virtual ASID)		    => selects hardware ASID (CONTEXTIDR)
+* asid (virtual ASID) + vmmuHandle  => selects page table (TTBR0)
+*
+* For unprivileged guests, the following additional values will be
+* taken from the VB control structure and loaded / take effect:
+*
+* ... TBD
+*
+* Note that all other registers must be context switched by the guest.
+*
+*/
+
+FUNC_LABEL(vbi_load_ctx)
+        SAVEREGS
+        ldr     r8, =VBI_SYS_ctx_load
+        HCALL
+
+	INVALIDATE_CURR_ASID(r8)
+
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_load_ctx)
+
+/******************************************************************************
+*
+* vbi_ctx_ctl - hypervisor context control call
+*
+* This system call interfaces to the general purpose hypervisor context
+* control function.
+*
+* Returns: ioctl-specific value
+*
+*/
+
+FUNC_LABEL(vbi_ctx_ctl)
+        /*
+         * r0 - unsigned int op
+         * r1 - void * arg
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_ctxctl
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_ctx_ctl)
+
+/*******************************************************************************
+*
+* vbi_vb_suspend - Suspend a virtual board's core
+*
+* This routine makes a hypercall in order to suspend one or more cores that
+* exist within the specified virtual board. The target core(s) enter HALT state
+* until vbi_vb_resume() is called change the state of the core(s). This function
+* will return only after all victim cores are suspended unless the opration
+* fails to complete. The second argument passed to this function specifies one
+* or more target cores. For suspending every core within the specified VB the
+* second argument must be set to VBI_VB_CORES_ALL. This implies that the core
+* requesting the suspension may also be included in the list to be suspended.
+* To suspend everyone but the recipient then the second argument passed to this
+* function should be set to VBI_VB_CORES_OTHERS. Otherwise the second argument
+* should be a valid core number within the VB. This hypercall sends a message
+* to a given hypervisor manager that provides virtual board managment service.
+*
+* RETURNS: OK or an error number in case of failure
+*
+*/
+
+FUNC_LABEL(vbi_vb_suspend)
+        /*
+         * r0 - virtual board id
+         * r1 - virtual core (a flag or a valid vcore id)
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vbSuspend
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vb_suspend)
+
+/*******************************************************************************
+*
+* vbi_vb_reset - Reset a virtual board's core
+*
+* This routine makes a hypercall in order to reset one or more cores that exist
+* within the specified virtual board. Calling this function puts the target
+* core(s) program counter to it's ENTRY function. The ENTRY function is
+* determined based on the loaded binary image. A core does not execute beyond
+* it's ENTRY function unless vbi_vb_restart() is explitly called.
+* Except for core0 within the target VB where VBI_VBMGMT_RESET_AND_START_CORE0
+* option is set in the flag passed as the third argument to this routine.
+* The hypercall sends a message to a manager that provides VB managment
+* services.
+* This function will return only after all victim cores are reset unless the
+* operation fails to complete. The order of which the victim cores are reset
+* is not determined. The second argument identifies the cores to perform the
+* operation on.
+* The value of the second argument should be set to one of the following:
+*
+*\ms
+*\m -
+* VBI_VB_CORES_ALL: Reset all cores in the specified virtual board
+*\m -
+* VBI_VB_CORES_OTHERS: Exclude the recipient if it belongs to the victim VB
+*\m -
+* A valid core number: Reset the specified core that exist within the Virtual
+* Board.
+*\me
+*
+* The third argument argument passed to this function specifies options that are
+* applicable only when the second argument is VBI_VB_CORES_ALL. The options
+* may be
+* one of the following or a combination:
+*
+*\ms
+*\m -
+* VBI_VBMGMT_RESET_CLEAR: Zero out the core's memory, can only be used in
+* conjunction with VBI_VBMGMT_RESET_DOWNLOAD
+*\m -
+* VBI_VBMGMT_RESET_DOWNLOAD: Reset the cores and reload the executable images
+*\m -
+* VBI_VBMGMT_RESET_AND_START_CORE0: Reset and start core0 within the VB
+*\me
+*
+*
+* IMPORTANT:
+* If a user chooses to restart core without reloading the executable image then
+* the data section must be restored to prevent critical errors. It is the guest
+* OS's responsibility to clear the bss data sections in such scenario.
+*
+*/
+
+FUNC_LABEL(vbi_vb_reset)
+        /*
+         * r0 - virtual board id
+         * r1 - virtual core (a flag or a valid vcore id)
+         * r2 - options
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vbReset
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vb_reset)
+
+/*******************************************************************************
+*
+* vbi_vb_restart - Restart a virtual board's core
+*
+* This routine makes a hypercall in order to restart a virtual cores from reset.
+* It's called to start running a core or cores that were previously reset by
+* calling vbiVbReset(). The target core(s) start(s) executing from the ENTRY
+* function retrieved from the corresponding binary image.
+* This function will return only after  all cores are out of reset unless the
+* operation fails to complete.  The second argument represents the cores to
+* restart.
+* For restarting every core in reset mode within the specified VB the second
+* argument is set to VBI_VB_CORES_ALL. To restart a specific core within the
+* VB then the core number must be passed in the second argument.
+*
+* This hypercall sends a message to a manager that provides VB managment
+* services.
+*
+*/
+
+FUNC_LABEL(vbi_vb_restart)
+        /*
+         * r0 - virtual board id
+         * r1 - virtual core (a flag or a valid vcore id)
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vbRestart
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vb_restart)
+
+/*******************************************************************************
+*
+* vbi_vb_resume - Resume a virtual board's core
+*
+* This routine makes a hypercall in order to resume one or cores within
+* the specified virtual board. It reactivates a cores or cores that were
+* previously suspended. This function will return only
+* after all victim cores are resumed unless the operation fails. The order of
+* which the cores are resumed is not determined. The second argument may a
+* magic number instead of a valid core number to indicate that the operation
+* is intended for more than one core. For resuming every core within the
+* specified VB then the second argument is set to be equal to VBI_VB_RESUME_ALL.
+* This implies to resume every core within the specified VB. Using this option
+* when some of the cores within the VB are already running is not considered
+* as programming error.
+*
+* RETURNS: OK or an error number in case of failure
+*
+*/
+
+FUNC_LABEL(vbi_vb_resume)
+        /*
+         * r0 - virtual board id
+         * r1 - virtual core (a flag or a valid vcore id)
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vbResume
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vb_resume)
+
+/******************************************************************************
+*
+* vbiVbMgmt - virtual board management
+* 
+* This routine executes the specified command on a given virtual board. The
+* possible commands are:
+* 
+* VBI_VBMGMT_ATTACH 
+* Attach the requesting Virtual Board to the VB management agent for
+* operations on the specified VB.
+*
+* VBI_VBMGMT_DETACH
+* Detatch the requesting Virtual Board from the VB management agent for
+* operations on the specified VB.
+*
+* VBI_VBMGMT_SUSPEND
+* Suspends target Virtual Board from operation.  Fails if Virtual Board
+* has already been suspended
+*
+* VBI_VBMGMT_RESET
+* Resume a target virtual board.  Fails if a Virtual Board has not been
+* suspended. Currently no options are supported
+*
+* VBI_VBMGMT_RESUME
+* Restarts a target Virtual Board which has Preload=0 set in the xml file.
+* Fails if Virtual Board is preloaded (Preload=1)
+*
+*
+* The fourth argument to this routine specifies an flag that must be defined
+* when executing VBI_VBMGMT_RESUME operation. Otherwise the command fails.
+* The possible flgas are:
+*   VBI_VTLB_OP_UPDATE_PMD	
+*   VBI_VTLB_OP_UPDATE_PTE	
+*   VBI_VTLB_OP_DELETE_PMD	
+*   VBI_VTLB_OP_SET_PTE_AT	
+*   VBI_VTLB_OP_SET_PTE	
+*   VBI_VTLB_OP_FLUSH_OPS	
+*   VBI_VTLB_OP_INIT	
+*
+* int32_t vbiVbMgmt 
+*    (
+*    uint32_t	cmd,	   /@ attach, detach, suspend, reset or resume @/
+*    uint32_t	handle,    /@ the operation target board handle        @/
+*    int32_t   *outError,  /@ where to set error : OK or error flag    @/ 
+*    uint32_t	flags,	   /@ options required by the cmd executed     @/
+*    void *ctl		   /@ memory / registers data		       @/ 
+*    )
+*
+* RETURNS: OK or error in case of failure
+*/
+FUNC_LABEL(vbiVbMgmt)
+        SAVEREGS 1
+        ldr     r8, =VBI_SYS_vbMgmt
+        HCALL
+        RESTOREREGS 1
+        mov     pc, lr
+FUNC_END(vbiVbMgmt)
+
+/******************************************************************************
+*
+* vbiKputs - print a string on the kernel console
+*
+* This system call sends the specified string to the system console.
+*
+*/
+
+FUNC_LABEL(vbiKputs)
+        /*
+         * r0 - char * s
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_kputs
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbiKputs)
+
+/******************************************************************************
+*
+* vbi_kputc - print a character on the kernel console
+*
+* This system call sends the specified character to the system console.
+*
+*/
+
+FUNC_LABEL(vbi_kputc)
+        /*
+         * r0 - char * s
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_kputc
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_kputc)
+
+/******************************************************************************
+*
+* vbi_panic - panic the system and halt all activity
+*
+* This system call causes the hypervisor to enter a panic state and display
+* various pieces of information on the system console.  The hypervisor
+* then enters an idle state and stops all CPU processing.
+*
+* Returns: does not return
+*
+*/
+
+FUNC_LABEL(vbi_panic)
+        /*
+         * r0 - const char * msg
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_panic
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_panic)
+
+/*******************************************************************************
+*
+* vbi_shell_start_debug - start the hypervisor debug shell
+*
+* This routine sends a message to the hypervisor debug shell manager in order to
+* start the WRHV shell program. The shell program spins therefore does not share
+* the processor with any other WRHV context. By default a caller of this routine
+* is detached to allow the caling core to continue executing (as long as they
+* are not * scheduled to run on the same processor). An optional flag
+* VBI_SHELL_ATTACH can be specified to force the caller virtual board core to
+* block while the shell program is running.
+*
+*/
+
+FUNC_LABEL(vbi_shell_start_debug)
+        /*
+         * r0 - uint32_t flags
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_dbgShStart
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_shell_start_debug)
+
+/*******************************************************************************
+*
+* vbi_vb_read_mem - Read a virtual board's memory
+*
+* This routine makes a hypercall to read a remote board's memory. The memory
+* control structure contains information about the target memory to read and
+* the destination buffer that hypervisor must populate with the data read.
+* This routine is used to copy data from a remote VB. It is the user's
+* responsibility to ensure that the memory read is accessed orthogonally.
+* The sizeIn parameter specifies the number of bytes desired to be copied. 
+* The sizeOut parameter indicates the number of bytes successfully copied.
+* A user may set the sizeOut parameter to zero if the output size is not of
+* interest otherwise to a value different than zero.
+*
+* RETURNS: returns OK or an error number in case of failure
+*
+*/
+FUNC_LABEL(vbi_vb_read_mem)
+        SAVEREGS
+        ldr     r8, =VBI_SYS_memRead_op
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vb_read_mem)
+
+/*******************************************************************************
+*
+* vbi_vb_write_mem - copy data to a remote board's memory
+*
+* This routine makes a hypercall to copy to a remote board memory. If the
+* VBI_DCACHE_FLUSH is set in the control memory control structure then this
+* routine flushes the data caches lines corresponding to the range of memory
+* specified. If VBI_ICACHE_INV then this routine ensure that the instruction
+* cache lines corresponding to the range of address is invalidated after the
+* memory is copied. Invalidating the instruction is required if data containing
+* is updated since the instruction cache is not aware of the content in data
+* cache. Therefore flushing the data cache ensures that memory contains the
+* updated data and invalidating the instruction cache ensures that the stale
+* values in the instruction cache is thrown away. 
+* The sizeIn parameter specifies the number of bytes desired to be copied. 
+* The sizeOut parameter indicates the number of bytes successfully copied.
+* A user may set the sizeOut parameter to zero if the output size is not of
+* interest otherwise to a value different than zero.
+* 
+* RETURNS: returns OK or error number in case of failure
+*
+*/
+FUNC_LABEL(vbi_vb_write_mem)
+        SAVEREGS
+        ldr     r8, =VBI_SYS_memWrite_op
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vb_write_mem)
+
+/*******************************************************************************
+*
+* vbi_set_mem_attr - Set the attributes on entries within a WRHV pagetable
+*
+* This function moves some of the complexity of page table management
+* out of the Guest and replaces it with Hypervisor functionality.
+*
+* This function provides a simplifed interface to alter attributes of
+* mapped memory when the VMMU is disabled. When this call is made,
+* the Hypervisor will validate the existing mapping, adjust the page
+* table attributes in the page table that hardware is using for the
+* Guest, and invalidate the TLB to cause the attribute change to 
+* take effect immediately.
+*
+* Note that this function cannot alter mappings (virtual to physical) -
+* for this, the VMMU must be used.
+*
+* The possible attributes may be a combination of the following:
+* 
+* VBI_MMU_PROT_USER_READ -  allow supervisor and user read
+* VBI_MMU_PROT_USER_WRITE -  allow supervisor and user write
+* VBI_MMU_PROT_USER_EXECUTE - allow supervisor and user execute
+* VBI_MMU_PROT_SUPV_READ -  allow supervisor read
+* VBI_MMU_PROT_SUPV_WRITE -  allow supervisor write
+* VBI_MMU_PROT_SUPV_EXECUTE - allow supervisor execute
+*
+* (It is defined as not possible to set a privilege as 'user only'.)
+*
+*/
+FUNC_LABEL(vbi_set_mem_attr)
+        SAVEREGS
+        ldr     r8, =VBI_SYS_mmu_attr_set
+        HCALL
+	INVALIDATE_CURR_ASID(r8)
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_set_mem_attr)
+
+/*******************************************************************************
+*
+* vbi_get_mem_attr - Determine attributes for a page of memory
+*
+* This routine provides a simplifed interface to discover attributes of
+* mapped memory. When this call is made, the Hypervisor will validate
+* the existing mapping, returning the page table attributes in the page
+* table that hardware is using for the Guest.
+*
+* This function moves some of the complexity of page table management
+* out of the Guest and replaces it with Hypervisor functionality.
+*
+* The possible attributes returned may be a combination of the
+* following:
+* 
+* VBI_MMU_PROT_USER_READ -  allow supervisor and user read
+* VBI_MMU_PROT_USER_WRITE -  allow supervisor and user write
+* VBI_MMU_PROT_USER_EXECUTE - allow supervisor and user execute
+* VBI_MMU_PROT_SUPV_READ -  allow supervisor read
+* VBI_MMU_PROT_SUPV_WRITE -  allow supervisor write
+* VBI_MMU_PROT_SUPV_EXECUTE - allow supervisor execute
+*
+*/
+FUNC_LABEL(vbi_get_mem_attr)
+        SAVEREGS
+        ldr     r8, =VBI_SYS_mmu_attr_get
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_get_mem_attr)
+
+/******************************************************************************
+*
+* vbi_vb_remote - VB remote operations
+*
+* This system call interfaces to the virtual board and requests for information
+* about a remote VB
+*
+* Returns: OK or ERROR in case of failure
+*
+*/
+
+FUNC_LABEL(vbi_vb_remote)
+        /*
+         * r0 - uint32_t op
+         * r1 - vbiVb_t boardId
+         * r2 - vbiCore_t coreId
+         * r3 - void * out
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vbRemote
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vb_remote)
+
+/*******************************************************************************
+*
+* vbi_rx_op - Receive a message from another context
+*
+* This routine makes a hypercall and waits for a message to be received from
+* another context. It blocks until a message is received.
+*
+* RETURNS: sender context Id or an error number in case of failure
+*
+*/
+
+FUNC_LABEL(vbi_rx_op)
+        /*
+         * r0 - smsg pointer
+         * r1 - size of smsg
+         * r2 - info pointer
+         * r3 - ctl pointer
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_receive
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_rx_op)
+
+/*******************************************************************************
+*
+* vbi_reply - Reply to message received from another context
+*
+* This routine makes a hypercall in order to reply to a message received from
+* another context. A message is received from remote context by calling
+* vbiReceive(). The reply will unblock the recipient which may preempt
+* the caller.
+*
+*/
+
+FUNC_LABEL(vbi_reply)
+        /*
+         * r0 - vbiCtx_t id
+         * r1 - void * buff
+         * r2 - size_t len
+         * r3 - VBI_MSG_CTL * ctl
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_reply
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_reply)
+
+/*******************************************************************************
+*
+* vbi_send - Send a message to another context
+*
+* This routine makes a hypercall to send a message to the specified context and
+* waits for a reply.  The caller will block until the sender replies to the sent
+* message.
+*
+* RETURNS: OK or an error number in case of failure
+*
+*/
+
+FUNC_LABEL(vbi_send)
+        /*
+         * r0 - ctx id
+         * r1 - smsg pointer
+         * r2 - size of smsg
+         * r3 - rmsg pointer
+         * r4 - rmsg length
+         * r5 - info pointer
+         * r6 - ctl pointer
+         */
+        SAVEREGS 3
+        ldr     r8, =VBI_SYS_send
+        HCALL
+        RESTOREREGS 3
+        mov     pc, lr
+FUNC_END(vbi_send)
+
+/******************************************************************************
+*
+* vbi_ns_op - virtual board name service call
+*
+* Returns: OK or ERROR in case of failure
+*
+*/
+
+FUNC_LABEL(vbi_ns_op)
+        /*
+         * r0 - uint32_t cmd
+         * r1 - char * name
+         * r2 - uint32_t rev
+         * r3 - VBI_HANDLE * handle
+	 * stack->r4 - uint32_t timeout
+	 * stack->r5 - uint32_t options
+         */
+        SAVEREGS 2
+        ldr     r8, =VBI_SYS_ns_op
+        HCALL
+        RESTOREREGS 2
+        mov     pc, lr
+FUNC_END(vbi_ns_op)
+
+/******************************************************************************
+*
+* vbi_hy_ioctl - hypervisor ioctl call
+*
+* This system call interfaces to the general purpose hypervisor ioctl
+* function.
+*
+* Returns: ioctl-specific value
+*
+*/
+
+FUNC_LABEL(vbi_hy_ioctl)
+        /*
+         * r0 - unsigned int ioctl
+         * r1..r7 - args
+         */
+        SAVEREGS 4
+        ldr     r8, =VBI_SYS_hyIoctl
+        HCALL
+        RESTOREREGS 4
+        mov     pc, lr
+FUNC_END(vbi_hy_ioctl)
+
+/******************************************************************************
+*
+* vbi_io_apic_op - virtual IO APIC ioctl call
+*
+* This system call interfaces to the virtual IO APIC ioctl function.
+*
+* Returns: ioctl-specific value
+*
+*/
+
+FUNC_LABEL(vbi_io_apic_op)
+        /*
+         * r0 - unsigned int ioctl
+         * r1 - vbiIrq_t irq
+         * r2 - uint32_t filter
+         * r3 - vbiVb_t vbId
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vIoapicIoctl
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_io_apic_op)
+
+/******************************************************************************
+*
+* vbi_io_apic_ioctl - virtual IO APIC ioctl call
+*
+* This system call interfaces to the virtual IO APIC ioctl
+* function. 
+*
+* Possible ioctl commands:
+*     VBI_IOAPICIOCTL_UNMASK
+*     VBI_IOAPICIOCTL_SEND
+*     VBI_IOAPICIOCTL_MASK
+*		
+*/
+
+FUNC_LABEL(vbi_io_apic_ioctl)
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vIoapicIoctl
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_io_apic_ioctl)
+
+/*******************************************************************************
+*
+* vbi_vcore_irq_redirect - redirect an irq to another vcore
+*
+* RETURNS: returns OK or error number in case of failure
+*
+*/
+
+FUNC_LABEL(vbi_vcore_irq_redirect)
+        /*
+         * r0 - vbiIrq_t irq
+         * r1 - vbiCore_t core
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_intRedirect
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vcore_irq_redirect)
+
+/******************************************************************************
+*
+* vbi_config_vmmu - configure the hypervisor virtual MMU
+*
+* This system call configures the context's virtual MMU within the hypervisor.
+*
+*/
+
+FUNC_LABEL(vbi_config_vmmu)
+        /*
+         * r0 - VMMU_CONFIG * config
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vmmu_config
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_config_vmmu)
+
+/******************************************************************************
+*
+* vbi_enable_vmmu - enables the virtual MMU
+*
+* This system call enables a context's virtual MMU.
+*
+*/
+
+FUNC_LABEL(vbi_enable_vmmu)
+        /*
+         * r0 - unsigned int vmmu_handle
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vmmu_enable
+        HCALL
+
+	/* Invalidate current ASID - it may be shared between the
+	 * VMMU enabled and VMMU disabled states.
+	*/
+
+	INVALIDATE_CURR_ASID(r8)
+
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_enable_vmmu)
+
+/******************************************************************************
+*
+* vbi_disable_vmmu - disable the virtual MMU
+*
+* This system call disables a context's virtual MMU.
+*
+*/
+
+FUNC_LABEL(vbi_disable_vmmu)
+        /*
+         * r0 - unsigned int vmmu_handle
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vmmu_disable
+        HCALL
+
+	/* Invalidate current ASID - it may be shared between the
+	 * VMMU enabled and VMMU disabled states.
+	*/
+
+	INVALIDATE_CURR_ASID(r8)
+
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_disable_vmmu)
+
+/******************************************************************************
+*
+* vbi_flush_tlb - flush an MMU TLB entry
+*
+* This system call flushes the TLB associated with the specified context id
+*
+*/
+
+FUNC_LABEL(vbi_flush_tlb)
+        /*
+         * r0 - unsigned int id
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_tlb_flush
+        HCALL
+	INVALIDATE_CURR_ASID(r8)
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_flush_tlb)
+
+/*******************************************************************************
+*
+* vbi_vcore_irq_lock - lock interrupts
+*
+* This routine locks interrupts for the calling core. This is a C wrapper
+* function for VBI_INT_VCORE_LOCK() assembly macro. It locks interrupts returns
+* and returns the previous state of interrupts.
+*
+*/
+
+FUNC_LABEL(vbi_vcore_irq_lock)
+	VBI_INT_VCORE_LOCK (r0, r1, r2)
+	mov	pc, lr
+FUNC_END(vbi_vcore_irq_lock)
+
+/*******************************************************************************
+*
+* vbi_vcore_irq_unlock - unlock interrupts for running core
+*
+* This routine unlocks interrupts. This is a C wrapper function for the
+* assembly macro VBI_INT_VCORE_UNLOCK().
+*
+*/
+
+FUNC_LABEL(vbi_vcore_irq_unlock)
+	VBI_INT_VCORE_UNLOCK (r0, r1)
+        mov     pc, lr
+FUNC_END(vbi_vcore_irq_unlock)
+
+/*******************************************************************************
+*
+* vbi_vcore_irq_state - Get interrupts state for running core
+*
+* This routine returns the interrupt lock state for the calling core. If
+* interrupts are locked it returns nonzero (true). If interrupts are not locked
+* it returns zero (false).
+*
+*/
+
+FUNC_LABEL(vbi_vcore_irq_state)
+	VBI_INT_VCORE_STATE_GET (r0)
+        mov     pc, lr
+FUNC_END(vbi_vcore_irq_state)
+
+/*******************************************************************************
+*
+* vbi_set_exc_base - Set the exceptions vector table base for a virtual core
+*
+* This routine changes the exceptions vector table base address for the active
+* virtual core. By default the base address of the exception table is at address
+* 0x0.
+* If the guest OS programmer wishes to move this address then this function must
+* be called to inform hypervisor. This function must be called with interrupts
+* disabled to prevent hypervisor to deliver interrupts to an incorrect table.
+*
+*/
+
+FUNC_LABEL(vbi_set_exc_base)
+        /*
+         * r0 - void * excBase
+         */
+
+        /*
+         * alignment check -
+         * return error if lower five bits are not zero
+         *
+         * XXX Hypervisor should enforce this
+         */
+        tst     r0, #0x1f
+        movne   r0, #VBI_EXCBASE_SET_ERROR
+        movne   pc, lr
+
+        /* convert to hyioctl */
+        mov     r1, r0
+        ldr     r0, =VBI_HYIOCTL_EXCBASE
+
+        /*
+         * make the hypercall:
+         * r0 - VBI_HYIOCTL_EXCBASE
+         * r1 - void * excBase
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_hyIoctl
+        HCALL
+        RESTOREREGS
+
+        mov     pc, lr
+FUNC_END(vbi_set_exc_base)
+
+/*******************************************************************************
+*
+* vbi_vb_read_reg - Read a remote core's registers
+*
+*/
+
+FUNC_LABEL(vbi_vb_read_reg)
+        SAVEREGS
+        ldr     r8, =VBI_SYS_RegsRead_op
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vb_read_reg)
+
+/*******************************************************************************
+*
+* vbi_vb_write_reg - write to a remote core's registers
+*
+*/
+
+FUNC_LABEL(vbi_vb_write_reg)
+        SAVEREGS
+        ldr     r8, =VBI_SYS_RegsWrite_op
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vb_write_reg)
+
+/*******************************************************************************
+*
+* vbi_set_exc_offset - Set the exceptions vector offsetcs for a virtual core
+*
+* This routine changes the exceptions vector table offset addresses for the
+* active virtual core. By default they follow the standard ARM exception
+* offsets. vbi_get_exc_offset will provide the offsets being used for the
+* virtual board. The offset table uses an index based on IVOR number.
+* If the guest OS programmer wishes to move these address then this function
+* must be called to inform hypervisor. This function must be called with
+* interrupts disabled to prevent hypervisor to deliver interrupts to an
+* incorrect exception offset. The table is not validated by the hypervisor so
+* it must be complete and functional otherwize the VB will not behave as
+* expected.
+* For SMP systems it is recommended this API be called for each core as it is
+* started up and before it's added to the scheduler for the guest OS.
+*
+*/
+
+FUNC_LABEL(vbi_set_exc_offset)
+        /*
+         * r0 - VBI_EXC_OFFSETS_TABLE * excOffsetsTable
+         */
+
+        /* convert to hyioctl */
+        mov     r1, r0
+        ldr     r0, =VBI_HYIOCTL_EXCOFFSETS_SET
+
+        /*
+         * make the hypercall:
+         * r0 - VBI_HYIOCTL_EXCOFFSETS_SET
+         * r1 - VBI_EXC_OFFSETS_TABLE * excOffsetsTable
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_hyIoctl
+        HCALL
+        RESTOREREGS
+
+        mov     pc, lr
+FUNC_END(vbi_set_exc_offset)
+
+/*******************************************************************************
+*
+* vbi_get_exc_offset - Get the exceptions vector offsetcs for a virtual core
+*
+* This routine gets the exceptions vector table offset addresses for the
+* active virtual core. By default they follow the standard ARM exception
+* offsets. vbi_set_exc_offset will enable the offsets to be changed for the
+* virtual board. The offset table uses an index based on IVOR number.
+*
+*/
+
+FUNC_LABEL(vbi_get_exc_offset)
+        /*
+         * r0 - VBI_EXC_OFFSETS_TABLE * excOffsetsTable
+         */
+
+        /* convert to hyioctl */
+        mov     r1, r0
+        ldr     r0, =VBI_HYIOCTL_EXCOFFSETS_GET
+
+        /*
+         * make the hypercall:
+         * r0 - VBI_HYIOCTL_EXCOFFSETS_GET
+         * r1 - VBI_EXC_OFFSETS_TABLE * excOffsetsTable
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_hyIoctl
+        HCALL
+        RESTOREREGS
+
+        mov     pc, lr
+FUNC_END(vbi_get_exc_offset)
+
+/*******************************************************************************
+*
+* vbi_flush_icache - flush the instruction cache
+*
+* This routine makes a hypercall to flush the instruction cache of the calling
+* core for the specified address range.
+*
+*/
+
+FUNC_LABEL(vbi_flush_icache)
+        /*
+         * r0 - void * addr
+         * r1 - size_t len
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_icache_flush
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_flush_icache)
+
+/*******************************************************************************
+*
+* vbi_flush_dcache - flush the specified Data cache
+*
+* This routine makes a hypercall to flush the data cache of the calling core
+* for the specified address range.
+*
+* RETURNS: OK or error number in case of failure
+*
+*/
+
+FUNC_LABEL(vbi_flush_dcache)
+        /*
+         * r0 - void * addr
+         * r1 - size_t len
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_dcache_flush
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_flush_dcache)
+
+/*******************************************************************************
+*
+* vbi_update_text_cache - flush data cache then invalidate instruction cache
+*
+* This routine makes a hypercall to flush the data cache then invalidates the
+* instruction cache of the calling core for the specified address range.
+*
+*/
+
+FUNC_LABEL(vbi_update_text_cache)
+        /*
+         * r0 - void * addr
+         * r1 - size_t len
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_cache_text_update
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_update_text_cache)
+
+/******************************************************************************
+*
+* vbi_create_vmmu - create the virtual MMU handle
+*
+* This system call enables a context's virtual MMU.
+*
+*/
+
+FUNC_LABEL(vbi_create_vmmu)
+        /*
+         * r0 - VMMU_CONFIG * cfg
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vmmu_create
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_create_vmmu)
+
+/******************************************************************************
+*
+* vbi_delete_vmmu - delete the virtual MMU handle
+*
+* This system call enables a context's virtual MMU.
+*
+*/
+
+FUNC_LABEL(vbi_delete_vmmu)
+        /*
+         * r0 - VMMU_CONFIG * cfg
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vmmu_delete
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_delete_vmmu)
+
+/******************************************************************************
+*
+* vbi_tlb_load_vmmu - load a TLB entry into the virtual MMU
+*
+* This system call loads the TLB entries for the specified address range into
+* the virtual MMU.
+*
+*/
+
+FUNC_LABEL(vbi_tlb_load_vmmu)
+        /*
+         * r0 - VMMU_CONFIG * cfg
+         * r1 - void * addr
+         * r2 - unsigned int len
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vmmu_tlbload
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_tlb_load_vmmu)
+
+/******************************************************************************
+*
+* vbi_tlb_flush_vmmu - load a TLB entry into the virtual MMU
+*
+* This system call invalidates the TLB entries for the specified address range
+* from the virtual MMU.
+*
+*/
+
+FUNC_LABEL(vbi_tlb_flush_vmmu)
+        /*
+         * r0 - VMMU_CONFIG * cfg
+         * r1 - void * addr
+         * r2 - unsigned int len
+         */
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vmmu_tlbflush
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_tlb_flush_vmmu)
+
+/******************************************************************************
+*
+* vbi_vb_create - VB create
+*
+* This system call interface 
+*
+* options:
+*	VBI_CREATE_RESUME        /@ start VB after create @/
+*	VBI_CREATE_HALT           /@ keep VB ahlted after creation  @/
+*				
+*/
+FUNC_LABEL(vbi_vb_create)
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vbCreate
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vb_create)
+
+/******************************************************************************
+*
+* vbi_vb_delete - VB delete
+*
+* This system call interface 
+*
+*/
+FUNC_LABEL(vbi_vb_delete)
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vbDelete
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vb_delete)
+
+/******************************************************************************
+*
+* vbi_board_simple_config_get - Get VB basic configuration information.
+*
+* This system call interface 
+*				
+*/
+FUNC_LABEL(vbi_board_simple_config_get)	
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vbBoardSimpleConfigGet
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_board_simple_config_get)
+
+/******************************************************************************
+*
+* vbi_board_config_get - Get VB Configuration information and device information
+*
+* This system call interface 
+*
+*/
+FUNC_LABEL(vbi_board_config_get)
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vbBoardConfigGet
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_board_config_get)
+	
+/******************************************************************************
+*
+* vbi_vb_move - Move a VB to another core and/or priority
+*
+* This system call interface moves a VB to another core and/or priority
+*
+*/
+FUNC_LABEL(vbi_vb_move)
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vbMove
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vb_move)
+
+/******************************************************************************
+*
+* vbi_vb_priority_set - Move a VB to another core and/or priority
+*
+* This system call interface moves a VB to another core and/or priority
+*
+*/
+FUNC_LABEL(vbi_vb_priority_set)
+        SAVEREGS
+        ldr     r8, =VBI_SYS_vbPrioSet
+        HCALL
+        RESTOREREGS
+        mov     pc, lr
+FUNC_END(vbi_vb_priority_set)
diff --git a/arch/mips/include/asm/arch_vbi.h b/arch/mips/include/asm/arch_vbi.h
index bea004e..249027d 100644
--- a/arch/mips/include/asm/arch_vbi.h
+++ b/arch/mips/include/asm/arch_vbi.h
@@ -1,7 +1,7 @@
 /*
  * arch_vbi.h - MIPS64 architecture specific definitions
  *
- * Copyright 2010 Wind River Systems, Inc.
+ * Copyright 2009-2011 Wind River Systems, Inc.
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
@@ -20,18 +20,6 @@
 
 #define __VBI_BYTE_ORDER __VBI_BIG_ENDIAN
 
-/* exception defines */
-
-#define ARCH_MAX_INTERRUPT		    36
-#define VBI_ARCH_EXC_TABLE_SIZE		    36
-#define VBI_ARCH_IRQ_TABLE_SIZE		    256
-/* TODO: revisit syscall table implementation */
-#undef  _WRHV_ARCH_HAS_VB_SYSTBL 
-
-/* maximum number of virtual cores */
-
-#define	VBI_MAX_CORES			    8
-
 /* VIOAPIC number of entries */
 
 #define VB_VIOAPIC_ENTRIES_SIZE		    64 
@@ -93,21 +81,6 @@
  * Virtual board emulated control registers. These registers are used
  * by a guest running on hypervisor to configure the virtual CPU register.
  *
- * MIPS64 Control structure graphical illustration
- *        _______________   
- *       |      EPC      |   
- *       |---------------|
- *       |      SR       |	    
- *       |---------------|
- *       |      K0       |
- *       |---------------|
- *       |      K1       |
- *       |---------------|
- *       |      V0       |
- *       |---------------|
- *       |reserved[0:9]  |
- *       |---------------|
- *
  */
 
 struct vb_arch_ctrl_regs
@@ -132,25 +105,6 @@ struct vb_arch_ctrl_regs
  * Virtual board emulated CPU status registers
  *
  * MIPS64 Status structure graphical illustration
- *        _______________ 
- *       |    EPC        |   
- *       |---------------|
- *       |    SR         |
- *       |---------------|
- *       |    CAUSE      |
- *       |---------------|
- *       |    RA         |
- *       |---------------|
- *       |    K0         |
- *       |---------------|
- *       |    K1         |
- *       |---------------|
- *       |    ciuSum     |	
- *       |---------------|
- *       |    V0         |
- *       |---------------|
- *       |    badva      |
- *       |---------------|
  *
  */
 
diff --git a/arch/mips/include/asm/reg_vbi.h b/arch/mips/include/asm/reg_vbi.h
old mode 100755
new mode 100644
index 84d64a9..bd22e40
--- a/arch/mips/include/asm/reg_vbi.h
+++ b/arch/mips/include/asm/reg_vbi.h
@@ -38,9 +38,9 @@ typedef struct		/* REG_SET - MIPS architecture register set */
 
     ULONG intCtrl;              /* extended interrupt control */
     ULONG _ULextra1;            /* extra */
-    _RType tlbhi;				/* current address space storage */
-    _RType intDisable;           /* intDisable */
-    _RType c0_context;         	/* coprocessor0 context, ptebase */
+    _RType tlbhi;		/* current address space storage */
+    _RType intDisable;          /* intDisable */
+    _RType _RTextra3;           /* extra */
     _RType _RTextra4;           /* extra */
     _RType _RTextra5;           /* extra */
     _RType _RTextra6;           /* extra */
@@ -48,8 +48,8 @@ typedef struct		/* REG_SET - MIPS architecture register set */
     _RType _RTextra8;           /* extra */
     _RType _RTextra9;           /* extra */
     _RType _RTextra10;          /* extra */
-    
-    _RType badvaddr;			/* c0_badvaddr */
+    _RType c0_context;          /* coprocessor0 context, ptebase */
+    _RType badvaddr;		/* c0_badvaddr */
     } HREG_SET;
 
 #ifdef CONFIG_CPU_CAVIUM_OCTEON 
@@ -179,7 +179,8 @@ typedef struct wind_cpu_state
 #define RTEXTRA8	(GREG_END+4*SIZEOF_RTYPE+7*_RTypeSize) /* extra */
 #define RTEXTRA9	(GREG_END+4*SIZEOF_RTYPE+8*_RTypeSize) /* extra */
 #define RTEXTRA10	(GREG_END+4*SIZEOF_RTYPE+9*_RTypeSize) /* extra */
-#define BADVADDR	(GREG_END+4*SIZEOF_RTYPE+10*_RTypeSize) 
+#define C0CONTEXT	(GREG_END+4*SIZEOF_RTYPE+10*_RTypeSize)
+#define BADVADDR	(GREG_END+4*SIZEOF_RTYPE+11*_RTypeSize)
 
 
 #ifdef CONFIG_CPU_CAVIUM_OCTEON 
@@ -193,7 +194,7 @@ typedef struct wind_cpu_state
 #define THIREG		RTEXTRA10
 #endif /* CONFIG_CPU_CAVIUM_OCTEON */
 
-#define REG_SET_SIZE	(GREG_END+4*SIZEOF_RTYPE+11*_RTypeSize)
+#define REG_SET_SIZE	(GREG_END+4*SIZEOF_RTYPE+12*_RTypeSize)
 
 #define	HREG_REGS	(0 + N32_REG_OFFSET)
 #define HREG_GREG_BASE	(HREG_REGS+2*SIZEOF_RTYPE+2*_RTypeSize)
@@ -209,8 +210,9 @@ typedef struct wind_cpu_state
 #define HREG_INTCTRL        (HREG_GREG_END + 2*SIZEOF_RTYPE)
 #define HREG_EXTRA1         (HREG_GREG_END + 3*SIZEOF_RTYPE)
 #define HREG_TLBHI          (HREG_GREG_END + 4*SIZEOF_RTYPE + 0*_RTypeSize)
-#define HREG_INTDISABLE     (HREG_GREG_END + 4*SIZEOF_RTYPE + 1*_RTypeSize)
-#define HREG_C0_CONTEXT     (HREG_GREG_END + 4*SIZEOF_RTYPE + 2*_RTypeSize)
+#define HREG_EXTRA2         (HREG_GREG_END + 4*SIZEOF_RTYPE + 1*_RTypeSize)
+#define HREG_INTDISABLE     HREG_EXTRA2
+#define HREG_EXTRA3         (HREG_GREG_END + 4*SIZEOF_RTYPE + 2*_RTypeSize)
 #define HREG_EXTRA4         (HREG_GREG_END + 4*SIZEOF_RTYPE + 3*_RTypeSize)
 #define HREG_EXTRA5         (HREG_GREG_END + 4*SIZEOF_RTYPE + 4*_RTypeSize)
 #define HREG_EXTRA6         (HREG_GREG_END + 4*SIZEOF_RTYPE + 5*_RTypeSize)
@@ -218,6 +220,7 @@ typedef struct wind_cpu_state
 #define HREG_EXTRA8         (HREG_GREG_END + 4*SIZEOF_RTYPE + 7*_RTypeSize)
 #define HREG_EXTRA9         (HREG_GREG_END + 4*SIZEOF_RTYPE + 8*_RTypeSize)
 #define HREG_EXTRA10        (HREG_GREG_END + 4*SIZEOF_RTYPE + 9*_RTypeSize)
+#define HREG_C0_CONTEXT     (HREG_GREG_END + 4*SIZEOF_RTYPE + 10*_RTypeSize)
 
 #ifdef CONFIG_CPU_CAVIUM_OCTEON
 #define HREG_P0		HREG_EXTRA3
diff --git a/arch/mips/include/asm/vbi.h b/arch/mips/include/asm/vbi.h
old mode 100755
new mode 100644
index fd01a1c..8c0e1c4
--- a/arch/mips/include/asm/vbi.h
+++ b/arch/mips/include/asm/vbi.h
@@ -1,7 +1,7 @@
 /*
  * asm/vbi.h - MIPS64 tool dependent headers
  *
- * Copyright 2010 Wind River Systems, Inc.
+ * Copyright 2011 Wind River Systems, Inc.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
diff --git a/arch/mips/kernel/vbi/syscalls.S b/arch/mips/kernel/vbi/syscalls.S
index a52d43d..31f4cf7 100644
--- a/arch/mips/kernel/vbi/syscalls.S
+++ b/arch/mips/kernel/vbi/syscalls.S
@@ -72,6 +72,12 @@
 	FUNC_EXPORT(vbi_sys_ctx_load)
 	FUNC_EXPORT(vbi_ctx_load)
 	FUNC_EXPORT(vbi_vb_remote)
+	FUNC_EXPORT(vbi_vb_create)
+	FUNC_EXPORT(vbi_vb_delete)
+	FUNC_EXPORT(vbi_board_simple_config_get)
+	FUNC_EXPORT(vbi_board_config_get)
+	FUNC_EXPORT(vbi_vb_move)
+	FUNC_EXPORT(vbi_vb_priority_set)
 	FUNC_EXPORT(vbi_vb_read_mem)
 	FUNC_EXPORT(vbi_vb_write_mem)
 	FUNC_EXPORT(vbi_vb_read_reg)
@@ -780,6 +786,103 @@ FUNC_LABEL(vbi_vb_remote)
 	nop
 FUNC_END(vbi_vb_remote)
 
+/*
+ *
+ * vbi_vb_create - VB create
+ *
+ * options:
+ *       VBI_CREATE_RESUME        /@ start VB after create @/
+ *       VBI_CREATE_HALT          /@ keep VB halted after creation  @/
+ *
+ * Returns: VB BOARD_ID or 0 if failed.
+ *
+ */
+
+FUNC_LABEL(vbi_vb_create)
+	FIX_SIGN_EXTENSION(a1)
+	li		v0, VBI_SYS_vbCreate
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_create)
+
+/*
+ *
+ * vbi_vb_delete - VB delete
+ *
+ *
+ * Returns: VB BOARD_ID or 0 if failed.
+ *
+ */
+
+FUNC_LABEL(vbi_vb_delete)
+	FIX_SIGN_EXTENSION(a0)
+	li		v0, VBI_SYS_vbDelete
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_delete)
+
+/*
+ *
+ * vbi_board_simple_config_get - Get VB basic configuration info
+ *
+ *
+ */
+
+FUNC_LABEL(vbi_board_simple_config_get)
+	FIX_SIGN_EXTENSION(a0)
+	li		v0, VBI_SYS_vbBoardSimpleConfigGet
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_board_simple_config_get)
+
+/*
+ *
+ * vbi_board_config_get - Get VB configuration and device info
+ *
+ *
+ */
+
+FUNC_LABEL(vbi_board_config_get)
+	FIX_SIGN_EXTENSION(a0)
+	li		v0, VBI_SYS_vbBoardConfigGet
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_board_config_get)
+
+/*
+ *
+ * vbi_vb_move - Move a VB to another core and/or priority
+ *
+ */
+
+FUNC_LABEL(vbi_vb_move)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a2)
+	li		v0, VBI_SYS_vbMove
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_move)
+
+/*
+ *
+ * vbi_vb_priority_set
+ *
+ */
+
+FUNC_LABEL(vbi_vb_priority_set)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a2)
+	li		v0, VBI_SYS_vbPrioSet
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_priority_set)
+
 
 /*
  * vbi_io_apic_op - virtual IO APIC operation
diff --git a/arch/powerpc/include/asm/arch_vbi.h b/arch/powerpc/include/asm/arch_vbi.h
index 19d5369..b94d36a 100644
--- a/arch/powerpc/include/asm/arch_vbi.h
+++ b/arch/powerpc/include/asm/arch_vbi.h
@@ -1,7 +1,7 @@
 /*
  * arch_vbi.h - PowerPC architecture specific definitions
  *
- * Copyright 2009 Wind River Systems, Inc.
+ * Copyright 2009-2011 Wind River Systems, Inc.
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
@@ -20,29 +20,6 @@
 
 #define __VBI_BYTE_ORDER __VBI_BIG_ENDIAN
 
-/* exceptions generated by the hypervisor */
-
-#define VBI_EXC_OFF_MACH	0x0200	/* machine check */
-#define VBI_EXC_OFF_DATA	0x0300	/* data storage */
-#define VBI_EXC_OFF_INST	0x0400	/* instruction storage */
-#define VBI_EXC_OFF_INTR	0x0500	/* external interrupt*/
-#define VBI_EXC_OFF_ALIGN	0x0600	/* alignment error */
-#define VBI_EXC_OFF_PROG	0x0700	/* program check */
-#define VBI_EXC_OFF_FPU		0x0800	/* floating point */
-#define VBI_EXC_OFF_SYSCALL	0x0900	/* system call */
-#define VBI_EXC_OFF_DATA_MISS	0x0e00	/* MMU data miss */
-#define VBI_EXC_OFF_INST_MISS	0x0f00	/* MMU instruction miss*/
-#define VBI_EXC_OFF_DECR	0x0b00	/* decrementer */
-#define VBI_CLOCK_TIMER_VECTOR	(VBI_EXC_OFF_DECR >> 8)
-
-#define VBI_MAX_CORES		8	/* maximum number of virtual cores */
-
-/* exception defines */
-
-#define ARCH_MAX_INTERRUPT		36
-#define VBI_ARCH_EXC_TABLE_SIZE		36
-#define VBI_ARCH_IRQ_TABLE_SIZE		256
-
 /* VIOAPIC number of entries */
 
 #define VB_VIOAPIC_ENTRIES_SIZE		64
diff --git a/arch/powerpc/kernel/vbi/syscalls.S b/arch/powerpc/kernel/vbi/syscalls.S
index b9b9b1f..a7f55c4 100644
--- a/arch/powerpc/kernel/vbi/syscalls.S
+++ b/arch/powerpc/kernel/vbi/syscalls.S
@@ -22,7 +22,6 @@
 #include <asm/ppc_asm.h>
 #include <asm/asm-offsets.h>
 
-
 #ifdef CONFIG_PPC85xx_VT_MODE	/* not currently implemented */
 #define HCALL sc 1
 #else
@@ -80,6 +79,12 @@ FUNC_EXPORT(vbi_vb_reset)
 FUNC_EXPORT(vbi_vb_restart)
 FUNC_EXPORT(vbi_vb_resume)
 FUNC_EXPORT(vbi_vb_remote)
+FUNC_EXPORT(vbi_vb_create)
+FUNC_EXPORT(vbi_vb_delete)
+FUNC_EXPORT(vbi_get_board_simple_config)
+FUNC_EXPORT(vbi_get_board_config)
+FUNC_EXPORT(vbi_vb_move)
+FUNC_EXPORT(vbi_set_vb_priority)
 FUNC_EXPORT(vbi_direct_IRQ_EOI)
 
 _WRS_TEXT_SEG_START
@@ -373,28 +378,28 @@ FUNC_LABEL(vbi_load_ctx)
 
 	/* Where do we want to return to when we
 	are finished calling sys_ctx_load? */
-	lis	r3, leave_load_ctx@h
-	ori	r3, r3, leave_load_ctx@l
+	lis     r3, leave_load_ctx@h
+	ori     r3, r3, leave_load_ctx@l
 
-	lis	r9,wr_control@ha
-	lwz	r9,wr_control@l(r9)
+	lis     r9,wr_control@ha
+	lwz     r9,wr_control@l(r9)
 	/* Location of where we want to come back to
 	   so the HV returns us to the right spot */
-	stw	r3,VB_CONTROL_SRR0(r9)
-	mfcr	r11
-	stw	r11,VB_CONTROL_CR(r9)
-	stw	r0,VB_CONTROL_R0(r9)
+	stw     r3,VB_CONTROL_SRR0(r9)
+	mfcr    r11
+	stw     r11,VB_CONTROL_CR(r9)
+	stw     r0,VB_CONTROL_R0(r9)
 
-	lis	r12,wr_status@ha
-	lwz	r12,wr_status@l(r12)
+	lis     r12,wr_status@ha
+	lwz     r12,wr_status@l(r12)
 	/* Make sure our IRQ status / control are set
 	so we don't get intr when we are not expecting them */
-	lwz	r11,VB_STATUS_OLD_INT_DISABLE(r12)
-	stw	r11,VB_CONTROL_NEW_INT_DISABLE(r9)
+	lwz     r11,VB_STATUS_OLD_INT_DISABLE(r12)
+	stw     r11,VB_CONTROL_NEW_INT_DISABLE(r9)
 
-	lis	r0,VBI_SYS_ctx_load@h
-	ori	r0,r0,VBI_SYS_ctx_load@l
-	sc
+	lis     r0, HI(VBI_SYS_ctx_load)
+	ori     r0, r0, LO(VBI_SYS_ctx_load)
+	HCALL
 
 leave_load_ctx: /* return here - When HV calls rfi within
 	the sys_ctx_load fast hypercall, it will return us
@@ -857,3 +862,52 @@ FUNC_LABEL(vbi_direct_IRQ_EOI)
 	blr
 FUNC_END(vbi_direct_IRQ_EOI)
 
+/*
+ *
+ * vbi_vb_create - VB create
+ *
+ * options:
+ *      VBI_CREATE_RESUME        /@ start VB after create @/
+ *      VBI_CREATE_HALT           /@ keep VB ahlted after creation  @/
+ *
+ */
+vbi_hcall(vbi_vb_create, vbCreate)
+
+/*
+ *
+ * vbi_vb_delete - VB delete
+ *
+ */
+vbi_hcall(vbi_vb_delete, vbDelete)
+
+/*
+ *
+ * vbi_get_board_simple_config - Get VB basic configuration information.
+ *
+ */
+vbi_hcall(vbi_get_board_simple_config, vbBoardSimpleConfigGet)
+
+/*
+ *
+ * vbi_get_board_config - Get VB configuration info and device info
+ *
+ */
+vbi_hcall(vbi_get_board_config, vbBoardConfigGet)
+
+/*
+ *
+ * vbi_vb_move - Move a VB to another core
+ *
+ * This system call interface moves a VB to another core
+ *
+ */
+vbi_hcall(vbi_vb_move, vbMove)
+
+/*
+ *
+ * vbi_set_vb_priority - Move a VB to another core and/or priority
+ *
+ * This system call interface moves a VB to another core and/or priority
+ *                              
+ */
+vbi_hcall(vbi_set_vb_priority, vbPrioSet)
diff --git a/arch/x86/include/asm/arch_vbi.h b/arch/x86/include/asm/arch_vbi.h
index 169b8fe..8f480c7 100644
--- a/arch/x86/include/asm/arch_vbi.h
+++ b/arch/x86/include/asm/arch_vbi.h
@@ -20,20 +20,34 @@
 #ifndef _ASMLANGUAGE
 
 /* struct of system descriptor table registers (VBI_GDTR, VBI_IDTR, VBI_LDTR) */
+#ifdef _MSC_TOOL
+#pragma pack(push,1)
+#endif
 
 struct VBI_XDTR
 {
 	uint16_t limit;		/* maximum size of the DT */
 	size_t base;		/* address of DT */
 	uint16_t pad;
-} __attribute__((packed));
+}
+#ifndef _MSC_TOOL
+__attribute__((packed));
+#endif
+;
 
 struct VBI_XDTR32
 {
 	uint16_t limit;
 	uint32_t base;
 	uint16_t pad;
-} __attribute__((packed));
+}
+#ifndef _MSC_TOOL
+__attribute__((packed));
+#endif
+;
+#ifdef _MSC_TOOL
+#pragma pack(pop)
+#endif
 
 typedef struct VBI_XDTR vbi_gdtr;
 typedef struct VBI_XDTR vbi_idtr;
@@ -145,270 +159,4 @@ typedef struct
 
 #define __VBI_BYTE_ORDER __VBI_LITTLE_ENDIAN
 
-#define VBI_X86_MAX_VECTORS         256	/* maximum number of vectors */
-#define VBI_ARCH_EXC_TABLE_SIZE     32
-#define VBI_ARCH_IRQ_TABLE_SIZE     (VBI_X86_MAX_VECTORS - VBI_ARCH_EXC_TABLE_SIZE)
-
-#define VBI_MAX_CORES			 8 /* maximum number of virtual cores */
-
-#define VBI_IN_DIVIDE_ERROR		 0
-#define VBI_IN_DEBUG			 1
-#define VBI_IN_NON_MASKABLE		 2
-#define VBI_IN_BREAKPOINT		 3
-#define VBI_IN_OVERFLOW			 4
-#define VBI_IN_BOUND			 5
-#define VBI_IN_INVALID_OPCODE		 6
-#define VBI_IN_NO_DEVICE		 7
-#define VBI_IN_DOUBLE_FAULT		 8
-#define VBI_IN_CP_OVERRUN		 9
-#define VBI_IN_INVALID_TSS		10
-#define VBI_IN_NO_SEGMENT		11
-#define VBI_IN_STACK_FAULT		12
-#define VBI_IN_PROTECTION_FAULT		13
-#define VBI_IN_PAGE_FAULT		14
-#define VBI_IN_RESERVED			15
-#define VBI_IN_CP_ERROR			16
-#define VBI_IN_ALIGNMENT		17
-#define VBI_IN_MACHINE_CHECK		18
-#define VBI_IN_SIMD			19
-
-/* 19-31 Intel reserved exceptions  */
-
-/* 32-255 user defined exceptions  */
-
-#define VBI_IN_EXT_IRQ_BASE		32	/* local timer interrupt */
-
-#define VBI_IN_EXT_IRQ0			(VBI_IN_EXT_IRQ_BASE + 0)
-#define VBI_IN_EXT_IRQ1			(VBI_IN_EXT_IRQ_BASE + 1)
-#define VBI_IN_EXT_IRQ2			(VBI_IN_EXT_IRQ_BASE + 2)
-#define VBI_IN_EXT_IRQ3			(VBI_IN_EXT_IRQ_BASE + 3)
-#define VBI_IN_EXT_IRQ4			(VBI_IN_EXT_IRQ_BASE + 4)
-#define VBI_IN_EXT_IRQ5			(VBI_IN_EXT_IRQ_BASE + 5)
-#define VBI_IN_EXT_IRQ6			(VBI_IN_EXT_IRQ_BASE + 6)
-#define VBI_IN_EXT_IRQ7			(VBI_IN_EXT_IRQ_BASE + 7)
-#define VBI_IN_EXT_IRQ8			(VBI_IN_EXT_IRQ_BASE + 8)
-#define VBI_IN_EXT_IRQ9			(VBI_IN_EXT_IRQ_BASE + 9)
-#define VBI_IN_EXT_IRQ10		(VBI_IN_EXT_IRQ_BASE + 10)
-#define VBI_IN_EXT_IRQ11		(VBI_IN_EXT_IRQ_BASE + 11)
-#define VBI_IN_EXT_IRQ12		(VBI_IN_EXT_IRQ_BASE + 12)
-#define VBI_IN_EXT_IRQ13		(VBI_IN_EXT_IRQ_BASE + 13)
-#define VBI_IN_EXT_IRQ14		(VBI_IN_EXT_IRQ_BASE + 14)
-#define VBI_IN_EXT_IRQ15		(VBI_IN_EXT_IRQ_BASE + 15)
-#define VBI_IN_EXT_IRQ16		(VBI_IN_EXT_IRQ_BASE + 16)
-#define VBI_IN_EXT_IRQ17		(VBI_IN_EXT_IRQ_BASE + 17)
-#define VBI_IN_EXT_IRQ18		(VBI_IN_EXT_IRQ_BASE + 18)
-#define VBI_IN_EXT_IRQ19		(VBI_IN_EXT_IRQ_BASE + 19)
-#define VBI_IN_EXT_IRQ20		(VBI_IN_EXT_IRQ_BASE + 20)
-#define VBI_IN_EXT_IRQ21		(VBI_IN_EXT_IRQ_BASE + 21)
-#define VBI_IN_EXT_IRQ22		(VBI_IN_EXT_IRQ_BASE + 22)
-#define VBI_IN_EXT_IRQ23		(VBI_IN_EXT_IRQ_BASE + 23)
-#define VBI_IN_EXT_IRQ24		(VBI_IN_EXT_IRQ_BASE + 24)
-#define VBI_IN_EXT_IRQ25		(VBI_IN_EXT_IRQ_BASE + 25)
-#define VBI_IN_EXT_IRQ26		(VBI_IN_EXT_IRQ_BASE + 26)
-#define VBI_IN_EXT_IRQ27		(VBI_IN_EXT_IRQ_BASE + 27)
-#define VBI_IN_EXT_IRQ28		(VBI_IN_EXT_IRQ_BASE + 28)
-#define VBI_IN_EXT_IRQ29		(VBI_IN_EXT_IRQ_BASE + 29)
-#define VBI_IN_EXT_IRQ30		(VBI_IN_EXT_IRQ_BASE + 30)
-#define VBI_IN_EXT_IRQ31		(VBI_IN_EXT_IRQ_BASE + 31)
-#define VBI_IN_EXT_IRQ32		(VBI_IN_EXT_IRQ_BASE + 32)
-#define VBI_IN_EXT_IRQ33		(VBI_IN_EXT_IRQ_BASE + 33)
-#define VBI_IN_EXT_IRQ34		(VBI_IN_EXT_IRQ_BASE + 34)
-#define VBI_IN_EXT_IRQ35		(VBI_IN_EXT_IRQ_BASE + 35)
-#define VBI_IN_EXT_IRQ36		(VBI_IN_EXT_IRQ_BASE + 36)
-#define VBI_IN_EXT_IRQ37		(VBI_IN_EXT_IRQ_BASE + 37)
-#define VBI_IN_EXT_IRQ38		(VBI_IN_EXT_IRQ_BASE + 38)
-#define VBI_IN_EXT_IRQ39		(VBI_IN_EXT_IRQ_BASE + 39)
-#define VBI_IN_EXT_IRQ40		(VBI_IN_EXT_IRQ_BASE + 40)
-#define VBI_IN_EXT_IRQ41		(VBI_IN_EXT_IRQ_BASE + 41)
-#define VBI_IN_EXT_IRQ42		(VBI_IN_EXT_IRQ_BASE + 42)
-#define VBI_IN_EXT_IRQ43		(VBI_IN_EXT_IRQ_BASE + 43)
-#define VBI_IN_EXT_IRQ44		(VBI_IN_EXT_IRQ_BASE + 44)
-#define VBI_IN_EXT_IRQ45		(VBI_IN_EXT_IRQ_BASE + 45)
-#define VBI_IN_EXT_IRQ46		(VBI_IN_EXT_IRQ_BASE + 46)
-#define VBI_IN_EXT_IRQ47		(VBI_IN_EXT_IRQ_BASE + 47)
-#define VBI_IN_EXT_IRQ48		(VBI_IN_EXT_IRQ_BASE + 48)
-#define VBI_IN_EXT_IRQ49		(VBI_IN_EXT_IRQ_BASE + 49)
-#define VBI_IN_EXT_IRQ50		(VBI_IN_EXT_IRQ_BASE + 50)
-#define VBI_IN_EXT_IRQ51		(VBI_IN_EXT_IRQ_BASE + 51)
-#define VBI_IN_EXT_IRQ52		(VBI_IN_EXT_IRQ_BASE + 52)
-#define VBI_IN_EXT_IRQ53		(VBI_IN_EXT_IRQ_BASE + 53)
-#define VBI_IN_EXT_IRQ54		(VBI_IN_EXT_IRQ_BASE + 54)
-#define VBI_IN_EXT_IRQ55		(VBI_IN_EXT_IRQ_BASE + 55)
-#define VBI_IN_EXT_IRQ56		(VBI_IN_EXT_IRQ_BASE + 56)
-#define VBI_IN_EXT_IRQ57		(VBI_IN_EXT_IRQ_BASE + 57)
-#define VBI_IN_EXT_IRQ58		(VBI_IN_EXT_IRQ_BASE + 58)
-#define VBI_IN_EXT_IRQ59		(VBI_IN_EXT_IRQ_BASE + 59)
-#define VBI_IN_EXT_IRQ60		(VBI_IN_EXT_IRQ_BASE + 60)
-#define VBI_IN_EXT_IRQ61		(VBI_IN_EXT_IRQ_BASE + 61)
-#define VBI_IN_EXT_IRQ62		(VBI_IN_EXT_IRQ_BASE + 62)
-#define VBI_IN_EXT_IRQ63		(VBI_IN_EXT_IRQ_BASE + 63)
-#define VBI_IN_EXT_IRQ64		(VBI_IN_EXT_IRQ_BASE + 64)
-#define VBI_IN_EXT_IRQ65		(VBI_IN_EXT_IRQ_BASE + 65)
-#define VBI_IN_EXT_IRQ66		(VBI_IN_EXT_IRQ_BASE + 66)
-#define VBI_IN_EXT_IRQ67		(VBI_IN_EXT_IRQ_BASE + 67)
-#define VBI_IN_EXT_IRQ68		(VBI_IN_EXT_IRQ_BASE + 68)
-#define VBI_IN_EXT_IRQ69		(VBI_IN_EXT_IRQ_BASE + 69)
-#define VBI_IN_EXT_IRQ70		(VBI_IN_EXT_IRQ_BASE + 70)
-#define VBI_IN_EXT_IRQ71		(VBI_IN_EXT_IRQ_BASE + 71)
-#define VBI_IN_EXT_IRQ72		(VBI_IN_EXT_IRQ_BASE + 72)
-#define VBI_IN_EXT_IRQ73		(VBI_IN_EXT_IRQ_BASE + 73)
-#define VBI_IN_EXT_IRQ74		(VBI_IN_EXT_IRQ_BASE + 74)
-#define VBI_IN_EXT_IRQ75		(VBI_IN_EXT_IRQ_BASE + 75)
-#define VBI_IN_EXT_IRQ76		(VBI_IN_EXT_IRQ_BASE + 76)
-#define VBI_IN_EXT_IRQ77		(VBI_IN_EXT_IRQ_BASE + 77)
-#define VBI_IN_EXT_IRQ78		(VBI_IN_EXT_IRQ_BASE + 78)
-#define VBI_IN_EXT_IRQ79		(VBI_IN_EXT_IRQ_BASE + 79)
-#define VBI_IN_EXT_IRQ80		(VBI_IN_EXT_IRQ_BASE + 80)
-#define VBI_IN_EXT_IRQ81		(VBI_IN_EXT_IRQ_BASE + 81)
-#define VBI_IN_EXT_IRQ82		(VBI_IN_EXT_IRQ_BASE + 82)
-#define VBI_IN_EXT_IRQ83		(VBI_IN_EXT_IRQ_BASE + 83)
-#define VBI_IN_EXT_IRQ84		(VBI_IN_EXT_IRQ_BASE + 84)
-#define VBI_IN_EXT_IRQ85		(VBI_IN_EXT_IRQ_BASE + 85)
-#define VBI_IN_EXT_IRQ86		(VBI_IN_EXT_IRQ_BASE + 86)
-#define VBI_IN_EXT_IRQ87		(VBI_IN_EXT_IRQ_BASE + 87)
-#define VBI_IN_EXT_IRQ88		(VBI_IN_EXT_IRQ_BASE + 88)
-#define VBI_IN_EXT_IRQ89		(VBI_IN_EXT_IRQ_BASE + 89)
-#define VBI_IN_EXT_IRQ90		(VBI_IN_EXT_IRQ_BASE + 90)
-#define VBI_IN_EXT_IRQ91		(VBI_IN_EXT_IRQ_BASE + 91)
-#define VBI_IN_EXT_IRQ92		(VBI_IN_EXT_IRQ_BASE + 92)
-#define VBI_IN_EXT_IRQ93		(VBI_IN_EXT_IRQ_BASE + 93)
-#define VBI_IN_EXT_IRQ94		(VBI_IN_EXT_IRQ_BASE + 94)
-#define VBI_IN_EXT_IRQ95		(VBI_IN_EXT_IRQ_BASE + 95)
-#define VBI_IN_EXT_IRQ96		(VBI_IN_EXT_IRQ_BASE + 96)
-#define VBI_IN_EXT_IRQ97		(VBI_IN_EXT_IRQ_BASE + 97)
-#define VBI_IN_EXT_IRQ98		(VBI_IN_EXT_IRQ_BASE + 98)
-#define VBI_IN_EXT_IRQ99		(VBI_IN_EXT_IRQ_BASE + 99)
-#define VBI_IN_EXT_IRQ100		(VBI_IN_EXT_IRQ_BASE + 100)
-#define VBI_IN_EXT_IRQ101		(VBI_IN_EXT_IRQ_BASE + 101)
-#define VBI_IN_EXT_IRQ102		(VBI_IN_EXT_IRQ_BASE + 102)
-#define VBI_IN_EXT_IRQ103		(VBI_IN_EXT_IRQ_BASE + 103)
-#define VBI_IN_EXT_IRQ104		(VBI_IN_EXT_IRQ_BASE + 104)
-#define VBI_IN_EXT_IRQ105		(VBI_IN_EXT_IRQ_BASE + 105)
-#define VBI_IN_EXT_IRQ106		(VBI_IN_EXT_IRQ_BASE + 106)
-#define VBI_IN_EXT_IRQ107		(VBI_IN_EXT_IRQ_BASE + 107)
-#define VBI_IN_EXT_IRQ108		(VBI_IN_EXT_IRQ_BASE + 108)
-#define VBI_IN_EXT_IRQ109		(VBI_IN_EXT_IRQ_BASE + 109)
-#define VBI_IN_EXT_IRQ110		(VBI_IN_EXT_IRQ_BASE + 110)
-#define VBI_IN_EXT_IRQ111		(VBI_IN_EXT_IRQ_BASE + 111)
-#define VBI_IN_EXT_IRQ112		(VBI_IN_EXT_IRQ_BASE + 112)
-#define VBI_IN_EXT_IRQ113		(VBI_IN_EXT_IRQ_BASE + 113)
-#define VBI_IN_EXT_IRQ114		(VBI_IN_EXT_IRQ_BASE + 114)
-#define VBI_IN_EXT_IRQ115		(VBI_IN_EXT_IRQ_BASE + 115)
-#define VBI_IN_EXT_IRQ116		(VBI_IN_EXT_IRQ_BASE + 116)
-#define VBI_IN_EXT_IRQ117		(VBI_IN_EXT_IRQ_BASE + 117)
-#define VBI_IN_EXT_IRQ118		(VBI_IN_EXT_IRQ_BASE + 118)
-#define VBI_IN_EXT_IRQ119		(VBI_IN_EXT_IRQ_BASE + 119)
-#define VBI_IN_EXT_IRQ120		(VBI_IN_EXT_IRQ_BASE + 120)
-#define VBI_IN_EXT_IRQ121		(VBI_IN_EXT_IRQ_BASE + 121)
-#define VBI_IN_EXT_IRQ122		(VBI_IN_EXT_IRQ_BASE + 122)
-#define VBI_IN_EXT_IRQ123		(VBI_IN_EXT_IRQ_BASE + 123)
-#define VBI_IN_EXT_IRQ124		(VBI_IN_EXT_IRQ_BASE + 124)
-#define VBI_IN_EXT_IRQ125		(VBI_IN_EXT_IRQ_BASE + 125)
-#define VBI_IN_EXT_IRQ126		(VBI_IN_EXT_IRQ_BASE + 126)
-#define VBI_IN_EXT_IRQ127		(VBI_IN_EXT_IRQ_BASE + 127)
-#define VBI_IN_EXT_IRQ128		(VBI_IN_EXT_IRQ_BASE + 128)
-#define VBI_IN_EXT_IRQ129		(VBI_IN_EXT_IRQ_BASE + 129)
-#define VBI_IN_EXT_IRQ130		(VBI_IN_EXT_IRQ_BASE + 130)
-#define VBI_IN_EXT_IRQ131		(VBI_IN_EXT_IRQ_BASE + 131)
-#define VBI_IN_EXT_IRQ132		(VBI_IN_EXT_IRQ_BASE + 132)
-#define VBI_IN_EXT_IRQ133		(VBI_IN_EXT_IRQ_BASE + 133)
-#define VBI_IN_EXT_IRQ134		(VBI_IN_EXT_IRQ_BASE + 134)
-#define VBI_IN_EXT_IRQ135		(VBI_IN_EXT_IRQ_BASE + 135)
-#define VBI_IN_EXT_IRQ136		(VBI_IN_EXT_IRQ_BASE + 136)
-#define VBI_IN_EXT_IRQ137		(VBI_IN_EXT_IRQ_BASE + 137)
-#define VBI_IN_EXT_IRQ138		(VBI_IN_EXT_IRQ_BASE + 138)
-#define VBI_IN_EXT_IRQ139		(VBI_IN_EXT_IRQ_BASE + 139)
-#define VBI_IN_EXT_IRQ140		(VBI_IN_EXT_IRQ_BASE + 140)
-#define VBI_IN_EXT_IRQ141		(VBI_IN_EXT_IRQ_BASE + 141)
-#define VBI_IN_EXT_IRQ142		(VBI_IN_EXT_IRQ_BASE + 142)
-#define VBI_IN_EXT_IRQ143		(VBI_IN_EXT_IRQ_BASE + 143)
-#define VBI_IN_EXT_IRQ144		(VBI_IN_EXT_IRQ_BASE + 144)
-#define VBI_IN_EXT_IRQ145		(VBI_IN_EXT_IRQ_BASE + 145)
-#define VBI_IN_EXT_IRQ146		(VBI_IN_EXT_IRQ_BASE + 146)
-#define VBI_IN_EXT_IRQ147		(VBI_IN_EXT_IRQ_BASE + 147)
-#define VBI_IN_EXT_IRQ148		(VBI_IN_EXT_IRQ_BASE + 148)
-#define VBI_IN_EXT_IRQ149		(VBI_IN_EXT_IRQ_BASE + 149)
-#define VBI_IN_EXT_IRQ150		(VBI_IN_EXT_IRQ_BASE + 150)
-#define VBI_IN_EXT_IRQ151		(VBI_IN_EXT_IRQ_BASE + 151)
-#define VBI_IN_EXT_IRQ152		(VBI_IN_EXT_IRQ_BASE + 152)
-#define VBI_IN_EXT_IRQ153		(VBI_IN_EXT_IRQ_BASE + 153)
-#define VBI_IN_EXT_IRQ154		(VBI_IN_EXT_IRQ_BASE + 154)
-#define VBI_IN_EXT_IRQ155		(VBI_IN_EXT_IRQ_BASE + 155)
-#define VBI_IN_EXT_IRQ156		(VBI_IN_EXT_IRQ_BASE + 156)
-#define VBI_IN_EXT_IRQ157		(VBI_IN_EXT_IRQ_BASE + 157)
-#define VBI_IN_EXT_IRQ158		(VBI_IN_EXT_IRQ_BASE + 158)
-#define VBI_IN_EXT_IRQ159		(VBI_IN_EXT_IRQ_BASE + 159)
-#define VBI_IN_EXT_IRQ160		(VBI_IN_EXT_IRQ_BASE + 160)
-#define VBI_IN_EXT_IRQ161		(VBI_IN_EXT_IRQ_BASE + 161)
-#define VBI_IN_EXT_IRQ162		(VBI_IN_EXT_IRQ_BASE + 162)
-#define VBI_IN_EXT_IRQ163		(VBI_IN_EXT_IRQ_BASE + 163)
-#define VBI_IN_EXT_IRQ164		(VBI_IN_EXT_IRQ_BASE + 164)
-#define VBI_IN_EXT_IRQ165		(VBI_IN_EXT_IRQ_BASE + 165)
-#define VBI_IN_EXT_IRQ166		(VBI_IN_EXT_IRQ_BASE + 166)
-#define VBI_IN_EXT_IRQ167		(VBI_IN_EXT_IRQ_BASE + 167)
-#define VBI_IN_EXT_IRQ168		(VBI_IN_EXT_IRQ_BASE + 168)
-#define VBI_IN_EXT_IRQ169		(VBI_IN_EXT_IRQ_BASE + 169)
-#define VBI_IN_EXT_IRQ170		(VBI_IN_EXT_IRQ_BASE + 170)
-#define VBI_IN_EXT_IRQ171		(VBI_IN_EXT_IRQ_BASE + 171)
-#define VBI_IN_EXT_IRQ172		(VBI_IN_EXT_IRQ_BASE + 172)
-#define VBI_IN_EXT_IRQ173		(VBI_IN_EXT_IRQ_BASE + 173)
-#define VBI_IN_EXT_IRQ174		(VBI_IN_EXT_IRQ_BASE + 174)
-#define VBI_IN_EXT_IRQ175		(VBI_IN_EXT_IRQ_BASE + 175)
-#define VBI_IN_EXT_IRQ176		(VBI_IN_EXT_IRQ_BASE + 176)
-#define VBI_IN_EXT_IRQ177		(VBI_IN_EXT_IRQ_BASE + 177)
-#define VBI_IN_EXT_IRQ178		(VBI_IN_EXT_IRQ_BASE + 178)
-#define VBI_IN_EXT_IRQ179		(VBI_IN_EXT_IRQ_BASE + 179)
-#define VBI_IN_EXT_IRQ180		(VBI_IN_EXT_IRQ_BASE + 180)
-#define VBI_IN_EXT_IRQ181		(VBI_IN_EXT_IRQ_BASE + 181)
-#define VBI_IN_EXT_IRQ182		(VBI_IN_EXT_IRQ_BASE + 182)
-#define VBI_IN_EXT_IRQ183		(VBI_IN_EXT_IRQ_BASE + 183)
-#define VBI_IN_EXT_IRQ184		(VBI_IN_EXT_IRQ_BASE + 184)
-#define VBI_IN_EXT_IRQ185		(VBI_IN_EXT_IRQ_BASE + 185)
-#define VBI_IN_EXT_IRQ186		(VBI_IN_EXT_IRQ_BASE + 186)
-#define VBI_IN_EXT_IRQ187		(VBI_IN_EXT_IRQ_BASE + 187)
-#define VBI_IN_EXT_IRQ188		(VBI_IN_EXT_IRQ_BASE + 188)
-#define VBI_IN_EXT_IRQ189		(VBI_IN_EXT_IRQ_BASE + 189)
-#define VBI_IN_EXT_IRQ190		(VBI_IN_EXT_IRQ_BASE + 190)
-#define VBI_IN_EXT_IRQ191		(VBI_IN_EXT_IRQ_BASE + 191)
-#define VBI_IN_EXT_IRQ192		(VBI_IN_EXT_IRQ_BASE + 192)
-#define VBI_IN_EXT_IRQ193		(VBI_IN_EXT_IRQ_BASE + 193)
-#define VBI_IN_EXT_IRQ194		(VBI_IN_EXT_IRQ_BASE + 194)
-#define VBI_IN_EXT_IRQ195		(VBI_IN_EXT_IRQ_BASE + 195)
-#define VBI_IN_EXT_IRQ196		(VBI_IN_EXT_IRQ_BASE + 196)
-#define VBI_IN_EXT_IRQ197		(VBI_IN_EXT_IRQ_BASE + 197)
-#define VBI_IN_EXT_IRQ198		(VBI_IN_EXT_IRQ_BASE + 198)
-#define VBI_IN_EXT_IRQ199		(VBI_IN_EXT_IRQ_BASE + 199)
-#define VBI_IN_EXT_IRQ200		(VBI_IN_EXT_IRQ_BASE + 200)
-#define VBI_IN_EXT_IRQ201		(VBI_IN_EXT_IRQ_BASE + 201)
-#define VBI_IN_EXT_IRQ202		(VBI_IN_EXT_IRQ_BASE + 202)
-#define VBI_IN_EXT_IRQ203		(VBI_IN_EXT_IRQ_BASE + 203)
-#define VBI_IN_EXT_IRQ204		(VBI_IN_EXT_IRQ_BASE + 204)
-#define VBI_IN_EXT_IRQ205		(VBI_IN_EXT_IRQ_BASE + 205)
-#define VBI_IN_EXT_IRQ206		(VBI_IN_EXT_IRQ_BASE + 206)
-#define VBI_IN_EXT_IRQ207		(VBI_IN_EXT_IRQ_BASE + 207)
-#define VBI_IN_EXT_IRQ208		(VBI_IN_EXT_IRQ_BASE + 208)
-#define VBI_IN_EXT_IRQ209		(VBI_IN_EXT_IRQ_BASE + 209)
-#define VBI_IN_EXT_IRQ210		(VBI_IN_EXT_IRQ_BASE + 210)
-#define VBI_IN_EXT_IRQ211		(VBI_IN_EXT_IRQ_BASE + 211)
-#define VBI_IN_EXT_IRQ212		(VBI_IN_EXT_IRQ_BASE + 212)
-#define VBI_IN_EXT_IRQ213		(VBI_IN_EXT_IRQ_BASE + 213)
-#define VBI_IN_EXT_IRQ214		(VBI_IN_EXT_IRQ_BASE + 214)
-#define VBI_IN_EXT_IRQ215		(VBI_IN_EXT_IRQ_BASE + 215)
-#define VBI_IN_EXT_IRQ216		(VBI_IN_EXT_IRQ_BASE + 216)
-#define VBI_IN_EXT_IRQ217		(VBI_IN_EXT_IRQ_BASE + 217)
-#define VBI_IN_EXT_IRQ218		(VBI_IN_EXT_IRQ_BASE + 218)
-#define VBI_IN_EXT_IRQ219		(VBI_IN_EXT_IRQ_BASE + 219)
-#define VBI_IN_EXT_IRQ220		(VBI_IN_EXT_IRQ_BASE + 220)
-#define VBI_IN_EXT_IRQ221		(VBI_IN_EXT_IRQ_BASE + 221)
-#define VBI_IN_EXT_IRQ222		(VBI_IN_EXT_IRQ_BASE + 222)
-#define VBI_IN_EXT_IRQ223		(VBI_IN_EXT_IRQ_BASE + 223)
-
-/* timer vector */
-
-#define VBI_CLOCK_TIMER_VECTOR		0
-#define VBI_IN_APIC_TIMER		(VBI_IN_EXT_IRQ0)
-
-/* XXX this is less than desireable */
-#define IS_GUEST_REG_64(pCtx) (pCtx->arch->
-
 #endif /* _ASM_ARCH_VBI_H */
diff --git a/arch/x86/include/asm/reg_vbi.h b/arch/x86/include/asm/reg_vbi.h
index fe774f1..157a22a 100644
--- a/arch/x86/include/asm/reg_vbi.h
+++ b/arch/x86/include/asm/reg_vbi.h
@@ -1,7 +1,7 @@
 /*
  * x86 regs_vbi.h - x86 cpu registers
  *
- * Copyright (c) 2007-2009 Wind River Systems, Inc.
+ * Copyright (c) 2007-2011 Wind River Systems, Inc.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
@@ -281,30 +281,6 @@ typedef union
     uint32_t value;
     } CPUID_80000001_EDX;
 
-/* fields in the EDX register when EAX=0x80000001 */
-typedef union
-    {
-    struct
-	{
-	uint32_t reserved1:11;
-	uint32_t syscall:1;	/* SYSCALL/SYSRET instructions */
-	uint32_t reserved2:7;
-	uint32_t mp:1;		/* Multi-processor capable */
-	uint32_t nx:1;		/* Execute disable */
-	uint32_t reserved3:1;
-	uint32_t amdmmx:1;	/* AMD MMX extensions */
-	uint32_t reserved4:2;
-	uint32_t fxsave_opt:1;	/* FXSAVE/FXRSTOR optimizations */
-	uint32_t gbpage:1;	/* Gigabyte page support */
-	uint32_t rdtscp:1;	/* RDTSCP support */
-	uint32_t reserved5:1;
-	uint32_t lm:1;		/* Long mode em64t */
-	uint32_t amd3dnow2:1;	/* AMD 3DNow! extensions */
-	uint32_t amd3dnow:1;	/* AMD 3DNow! extensions */
-	} field;
-    uint32_t value;
-    } CPUID_80000001_EDX;
-
 /* fields in the EAX/EBX/ECX/EDX register when EAX=4 */
 
 /* CPUID: deterministic cache parameters definitions */
@@ -794,12 +770,21 @@ typedef struct idt64_entry
 
 /* structure of the system descriptor table registers (GDTR, IDTR, LDTR) */
 
+#if(TOOL == msc)
+#pragma pack(push,1)
+#endif
+
 struct XDTR
 {
 	uint16_t limit;		/* maximum size of the DT */
 	size_t   base;		/* address of DT */
 	uint16_t pad;
-} __attribute__((packed));
+}
+#ifndef _MSC_TOOL
+__attribute__((packed));
+#endif
+;
+
 
 
 struct XDTR32
@@ -807,7 +792,14 @@ struct XDTR32
 	uint16_t limit;
 	uint32_t base;
 	uint16_t pad;
-} __attribute__((packed));
+} 
+#ifndef _MSC_TOOL
+__attribute__((packed))
+#endif
+;
+#if(TOOL == msc)
+#pragma pack(pop)
+#endif
 
 typedef struct XDTR GDTR;
 typedef struct XDTR IDTR;
@@ -918,6 +910,10 @@ typedef struct taskGate		/* task gate */
     uint8_t	dpl:2;		/* DPL 14:13			*/
     uint8_t	p:1;		/* present 15:15		*/
     uint16_t    reserved3;      /* reserved3 31:16		*/
+#ifdef LP64
+    uint32_t	padding1;	/* padding to align to IDT_ENTRY*/
+    uint32_t	padding2;
+#endif
     } TGATE_DESC;
 
 typedef struct callGate		/* call gate */
@@ -939,6 +935,10 @@ typedef struct intGate		/* interrupt gate */
     uint8_t	dpl:2;		/* DPL 14:13			*/
     uint8_t	p:1;		/* present 15:15		*/
     uint16_t    offsetHi;	/* offset 31:16			*/
+#ifdef LP64
+    uint32_t	padding1;	/* padding to align to IDT_ENTRY*/
+    uint32_t	padding2;
+#endif
     } IGATE_DESC;
 
 #define IGATE_OFFSET00_SHIFT	00
@@ -956,6 +956,10 @@ typedef struct trapGate		/* trap gate */
     uint8_t	dpl:2;		/* DPL 14:13			*/
     uint8_t	p:1;		/* present 15:15		*/
     uint16_t    offsetHi;	/* offset 31:16			*/
+#ifdef LP64
+    uint32_t	padding1;	/* padding to align to IDT_ENTRY*/
+    uint32_t	padding2;
+#endif
     } TRGATE_DESC;
 
 #define TRGATE_OFFSET00_SHIFT	00
@@ -1019,6 +1023,9 @@ extern void	x86GetCpuid (uint32_t operation,
 			     uint32_t *eaxValue, uint32_t *ebxValue,
 			     uint32_t *ecxValue, uint32_t *edxValue);
 
+extern void	x87StateSave (void *);
+extern void	x87StateRestore (void *);
+
 #endif	/* _ASMLANGUAGE */
 
 /* CPU FAMILY & FPU type */
@@ -1088,6 +1095,8 @@ extern void	x86GetCpuid (uint32_t operation,
 #define HREG_TSP		0x50
 #endif /* LP64 */
 
+#define NUM_CR_REG	5		/* number of CR registers */
+
 /* bits on EFLAGS */
 
 #define EFLAGS_EMPTY	0x00000020	/* empty eflags */
@@ -1382,6 +1391,10 @@ extern void	x86GetCpuid (uint32_t operation,
 #define MSR_PLATFORM_INFO		0x00ce
 #define MSR_FLEX_RATIO			0x0194
 #define MSR_CORE_THREAD_COUNT		0x0035
+#define MSR_CORE_PERF_FIXED_CTR0	0x0309
+#define MSR_CORE_PERF_FIXED_CTR1	0x030a
+#define MSR_CORE_PERF_FIXED_CTR2	0x030b
+#define MSR_CORE_PERF_FIXED_CTR_CTRL	0x038d
 #define MSR_CORE_PERF_GLOBAL_STATUS	0x038e
 #define MSR_CORE_PERF_GLOBAL_CTRL	0x038f
 #define MSR_CORE_PERF_GLOBAL_OVF_CTRL	0x0390
@@ -1402,6 +1415,10 @@ extern void	x86GetCpuid (uint32_t operation,
 #define MSR_VMX_VMCS_ENUM		0x048A
 #define MSR_VMX_PROCBASED_CTLS2_MSR	0x048B
 #define MSR_VMX_EPT_VPID_CAP		0x048C
+#define MSR_VMX_TRUE_PINBASED_CTLS	0x048D
+#define MSR_VMX_TRUE_PROCBASED_CTLS	0x048E
+#define MSR_VMX_TRUE_EXIT_CTLS		0x048F
+#define MSR_VMX_TRUE_ENTRY_CTLS		0x0490
 
 /* MSR, Architectural MSRs (common MSRs in IA32) */
 
@@ -1484,6 +1501,7 @@ extern void	x86GetCpuid (uint32_t operation,
 #define IA32_MC3_MISC		0x040f			/* P6, addr changed */
 #define IA32_DS_AREA		0x0600			/* Pentium4 */
 #define IA32_PERF_STAT		0x0198			/* Core2 */
+#define IA32_PERF_CTRL		0x0199			/* Core2 */
 #define IA32_EFER		0xc0000080		/* Core2 - extended feature */
 #define IA32_STAR		0xc0000081		/* */
 #define IA32_LSTAR		0xc0000082		/* */
@@ -1494,6 +1512,10 @@ extern void	x86GetCpuid (uint32_t operation,
 #define IA32_GSBASE		0xc0000101		/* P4 */
 #define IA32_KERNEL_GSBASE	0xc0000102		/* P4 */
 
+/* P-state hardware coordination feedback registers */
+#define IA32_MPERF		0x00E7
+#define IA32_APERF		0x00E8
+
 /* MSR, IA32_DEBUGCTL, in Pentium4, bits */
 
 #define DBG_P7_LBR		0x00000001
diff --git a/arch/x86/kernel/vbi/syscalls.S b/arch/x86/kernel/vbi/syscalls.S
index a018d50..af390a9 100644
--- a/arch/x86/kernel/vbi/syscalls.S
+++ b/arch/x86/kernel/vbi/syscalls.S
@@ -72,7 +72,7 @@ name:						\
 #ifdef LP64
 .globl vbi_send;
 vbi_send:
-	mov     ARG7(VBI_STACK_FRAME_SIZE),%rax /* ctl */
+	mov     %rax,ARG7(VBI_STACK_FRAME_SIZE) /* ctl */
 	push    %r10            /* save the value of r10 */
 	mov     %rax,%r10       /* load r10 with the values of "ctl" */
 	push    $7              /* number of arguments */
@@ -123,6 +123,7 @@ vbi_hcall(vbi_reply, reply, 4)
 vbi_hcall(vbi_kputs, kputs, 1)
 vbi_hcall(cert_debug_vbi_kputs, kputs, 1)
 
+
 /*
  * vbi_kputc - print a character on the kernel console
  *
@@ -516,6 +517,7 @@ vbi_hcall(vbi_vb_read_mem, memRead_op, 2)
 vbi_hcall(vbi_shell_start_debug, dbgShStart, 1)
 vbi_hcall(cert_debug_vbi_shell_start_debug, dbgShStart, 1)
 
+
 /*
  * vbi_vb_read_reg - Read a remote core's registers
  *
@@ -581,6 +583,61 @@ vbi_hcall(vbi_vtlb_op, vtlb_op, 4)
 vbi_hcall(vbi_vb_remote, vbRemote, 4)
 
 /*
+ *
+ * vbi_vb_create - VB create
+ *
+ * options:
+ *      VBI_CREATE_RESUME        /@ start VB after create @/
+ *      VBI_CREATE_HALT           /@ keep VB halted after creation  @/
+ *                              
+ * Returns: VB BOARD_ID or 0 if failed.
+ */
+vbi_hcall(vbi_vb_create, vbCreate, 2)
+
+/*
+ *
+ * vbi_vb_delete - VB delete
+ *
+ * Returns: VB BOARD_ID or 0 if failed.
+ */
+vbi_hcall(vbi_vb_delete, vbDelete, 1)
+
+/*
+ *
+ * vbi_get_board_simple_config - Get VB basic configuration information.
+ *
+ * Returns: OK or ERROR.
+ */
+vbi_hcall(vbi_get_board_simple_config, vbBoardSimpleConfigGet, 2)
+
+/*
+ *
+ * vbi_get_board_config - Get VB Configuration info and device info
+ *
+ * Returns: OK or ERROR.
+ *
+ */
+vbi_hcall(vbi_get_board_config, vbBoardConfigGet, 2)
+
+/*
+ *
+ * vbi_vb_move - Move a VB to another core
+ *
+ * Returns: OK or ERROR.
+ *
+ */
+vbi_hcall(vbi_vb_move, vbMove, 3)
+
+/*
+ *
+ * vbi_vb_set_priority - Move a VB to another priority
+ *
+ * Returns: OK or ERROR.
+ *
+ */
+vbi_hcall(vbi_vb_set_priority, vbPrioSet, 3)
+
+/*
  * vbiSchedTransitionOp - transition the  frame scheduler
  *
  * This system call executes a frame scheduler transition.   Possible scheduler
diff --git a/include/vbi/compat.h b/include/vbi/compat.h
index 803bea8..2ef5fd6 100644
--- a/include/vbi/compat.h
+++ b/include/vbi/compat.h
@@ -79,6 +79,7 @@
 #define vbiVector_t		int32_t
 #define vbiCoreSet_t		uint32_t
 #define vbiRegSet_t		uint32_t
+#define virtAddr_t		uint64_t
 
 /*
  * struct fields and similar
@@ -127,6 +128,10 @@
 #define intPending		irq_pend
 #define intPendingType		irq_pend_type
 
+#define vbiPciDevice_t		struct vbi_pci_device
+#define vbSimpleInformation_t	struct vb_simple_information
+#define vbInformation_t		struct vb_information
+
 /*
  * function calls, etc.
  */
@@ -243,4 +248,11 @@
 
 #define vbiCtxLoad		vbi_ctx_load
 
+#define vbiVbCreate		vbi_vb_create
+#define vbiVbDelete		vbi_vb_delete
+#define vbiBoardSimpleConfigGet	vbi_board_simple_config_get
+#define vbiBoardConfigGet	vbi_board_config_get
+#define vbiVbMove		vbi_vb_move
+#define	vbiVbPrioritySet	vbi_vb_priority_set
+
 #endif  /* _VBI_COMPAT_H */
diff --git a/include/vbi/cpu_types.h b/include/vbi/cpu_types.h
index cf31dd1..61c5500 100644
--- a/include/vbi/cpu_types.h
+++ b/include/vbi/cpu_types.h
@@ -25,15 +25,14 @@
 #define ARMCA9		7
 #define PPCE200		8
 
-
 #ifndef _ASMLANGUAGE
 
 /* MIPS64R2 specific types */
 #if (CPU == MIPSI64R2)
 
-#define CPU_MIPS_32BIT	0 
+#define CPU_MIPS_32BIT 0
 
-#define CPU_MIPS_64BIT	1
+#define CPU_MIPS_64BIT 1
 
 typedef unsigned long	INSTR;		/* 32 bit word-aligned instructions */
 
@@ -66,7 +65,7 @@ typedef unsigned int	_RType;
 #endif
 #endif /* CPU == PENTIUM */
 
-#if (CPU == ARM1136)
+#if (CPU == ARM1136) || (CPU == ARMCA9)
 typedef unsigned long	INSTR;		/* 32 bit word-aligned instructions */
 typedef unsigned int	_RType;		/* register type */
 #endif
diff --git a/include/vbi/dynamic.h b/include/vbi/dynamic.h
new file mode 100644
index 0000000..03dc11b
--- /dev/null
+++ b/include/vbi/dynamic.h
@@ -0,0 +1,123 @@
+/* dynamic.h - Dynamic VB VBI interface */
+
+/* Copyright 2010 Wind River Systems, Inc. */
+
+#ifndef _VBI_DYNAMIC_H
+#define _VBI_DYNAMIC_H
+
+#include <vbi/types.h>
+
+#ifndef VB_ALIGN_FIELD_64
+#if defined(LP64)
+#define VB_ALIGN_FIELD_64(decl_var, pad_var)	\
+			   __attribute__(( aligned(8) )) \
+			   decl_var
+#else
+#if (__VBI_BYTE_ORDER == __VBI_LITTLE_ENDIAN)
+#define VB_ALIGN_FIELD_64(decl_var, pad_var)	\
+			    __attribute__(( aligned(8) )) \
+			    decl_var; \
+			    uint32_t pad_var
+# else
+#define VB_ALIGN_FIELD_64(decl_var, pad_var)	\
+			    __attribute__(( aligned(8) )) \
+			    uint32_t pad_var; \
+			    decl_var
+#endif
+#endif
+#endif
+
+#define NAME_LENGTH 64
+#define BOOTLINE_LENGTH 256
+
+typedef char vbi_name_t[NAME_LENGTH];
+typedef char vbi_bootline_t[BOOTLINE_LENGTH];
+
+struct vbi_pci_device
+{
+	vbi_name_t	Name;			/*  64 bytes */
+	uint32_t	Bus;			/*   4 bytes */
+	uint32_t	Device;			/*   4 bytes */
+	uint32_t	Function;		/*   4 bytes */
+	uint32_t	WriteEnable;		/*   4 bytes */
+};
+
+struct vb_simple_information
+{
+	uint64_t	RamAliasSize;			/*   8 bytes */
+	uint64_t	RamAliasAddr;			/*   8 bytes */
+	uint64_t	RamSize;			/*   8 bytes */
+	uint64_t	SystemRamSize;			/*   8 bytes */
+	uint64_t	BackgroundModeStartAddr;	/*   8 bytes */
+	uint32_t	EnableVmmuOnException;		/*   4 bytes */
+	uint32_t	TickTimerFrequency;		/*   4 bytes */
+	uint32_t	BoardConfig;			/*   4 bytes */
+	vbi_name_t	Name;				/*  64 bytes */
+	vbi_bootline_t	BootLine;			/* 256 bytes */
+	int32_t		PassFaults;			/*   4 bytes */
+	int32_t		TrapIoFault;			/*   4 bytes */
+	int32_t		TraceIoFault;			/*   4 bytes */
+	uint32_t	Cpu;				/*   4 bytes */
+	int32_t		Preload;			/*   4 bytes */
+	int32_t		Priority;			/*   4 bytes */
+	uint32_t	SystemCallAccessRights;		/*   4 bytes */
+	vbi_name_t	BoardType;			/*  64 bytes */
+	int32_t		SupervisoryMode;		/*   4 bytes */
+	uint32_t	Cores;				/*   4 bytes */
+	uint32_t	GuestOS;			/*   4 bytes */
+	uint32_t	VMSize;				/*   4 bytes */
+	uint32_t	BackgroundModeEnabled;		/*   4 bytes */
+	uint32_t	NumOfGuestDevices;		/*   4 bytes */
+	uint32_t	NumPciDevices;			/*   4 bytes */
+	uint32_t	Reserved[32];			/* reserved 128 bytes */
+};
+
+
+struct vb_information
+{
+	struct vb_simple_information vbSimpleInformation;
+	VB_ALIGN_FIELD_64(uint32_t *pCpuList, pad1); /* already aligned
+							- 8 bytes*/
+	VB_ALIGN_FIELD_64(uint32_t *pCpuPriorityList, pad2);	/* 8 bytes */
+	VB_ALIGN_FIELD_64(vbi_name_t *pDeviceList, pad3);	/* 8 bytes */
+	VB_ALIGN_FIELD_64(struct vbi_pci_device *pPciDevices, pad4);
+								/* 8 bytes */
+	uint32_t    Reserved[32];    /* reserved for later use - 128 bytes */
+};
+
+/* This returns only the simple contiguous data */
+int32_t vbi_board_simple_config_get(uint32_t vbId, 
+				     struct vb_simple_information *pVbInfo);
+
+/* this returns also the complex data that has variable sixe e.g.device list */
+int32_t vbi_board_config_get(uint32_t vbId,
+			       struct vb_information *pVbInfo); 
+
+uint32_t vbi_vb_create(struct vb_information *pVbInfo, uint32_t options);
+int32_t vbi_vb_delete(uint32_t vbId);
+
+/* Additive/Subtractive - i.e. not in zombie configuration */
+int32_t vbiVbSharedMemoryAlloc(uint32_t vbId, vbi_name_t smRegionName, 
+				   uint64_t *va, size_t size);
+int32_t vbiVbSharedMemoryFree(uint32_t vbId, vbi_name_t smRegionName, 
+				  uint64_t va);
+int32_t vbiVbRamAlloc(uint32_t vbId, uint64_t *va, size_t size);
+int32_t vbiVbRamFree(uint32_t vbId, uint64_t va);
+
+/* Vb Core Migration */
+
+/* Information can be optained for the Virtual boards such as prio and 
+ * present Cpu using vbiBoardConfigGet() */
+int32_t vbi_vb_move(uint32_t vbId, uint32_t *pCpuList, 
+		      uint32_t options);
+
+#define VBIMOVE_OPTION_RESUME    0
+#define VBIMOVE_OPTION_NO_RESUME 1
+
+int32_t vbi_vb_priority_set(uint32_t vbId, uint32_t *pCpuPriorityList,
+			     uint32_t options);
+
+#define VBIPRIOSET_OPTION_RESUME    0
+#define VBIPRIOSET_OPTION_NO_RESUME 1
+
+#endif
diff --git a/include/vbi/interface.h b/include/vbi/interface.h
index c982377..ce18ef9 100644
--- a/include/vbi/interface.h
+++ b/include/vbi/interface.h
@@ -88,9 +88,12 @@ identity mapped.
 
 /* VB versioning information */
 #define	VBI_VERSION_MAJOR	2	/* major version */
-#define	VBI_VERSION_MINOR	1	/* minor version */
+#define	VBI_VERSION_MINOR	2	/* minor version */
 #define	VBI_VERSION_MAINT	0	/* maintenance version */
 
+
+#ifndef _MSC_TOOL
+
 /* macro to align guest fields for a 64-bit hypervisor */
 #if defined(LP64)
 #define VB_ALIGN_FIELD_64(decl_var, pad_var)	\
@@ -110,6 +113,27 @@ identity mapped.
 #endif
 #endif
 
+#else
+
+/* macro to align guest fields for a 64-bit hypervisor */
+#if defined(LP64)
+# define VB_ALIGN_FIELD_64(decl_var, pad_var)  \
+				DECLSPEC_ALIGN(8) decl_var
+#else
+#if (__VBI_BYTE_ORDER == __VBI_LITTLE_ENDIAN)
+#define VB_ALIGN_FIELD_64(decl_var, pad_var) \
+				DECLSPEC_ALIGN(8) decl_var; \
+				uint32_t pad_var
+#else
+#define VB_ALIGN_FIELD_64(decl_var, pad_var) \
+				DECLSPEC_ALIGN(8) \
+				uint32_t pad_var; \
+				decl_var
+#endif
+#endif
+
+#endif
+
 #undef VB_DEBUG  /* define it to turn on debugging */
 #ifdef VB_DEBUG
 #define VB_DEBUG_MSG(fmt, args...)    printk(fmt, ##args)
@@ -121,7 +145,7 @@ identity mapped.
 #define VB_MAX_VIRTUAL_BOARDS		1024
 #define VB_MAX_BUSES			1024
 
-#define VB_MAX_CORES			8
+#define VB_MAX_CORES			64
 
 /* Type definitions for all name identifer strings in the hypervisor */
 #define VB_NAMELEN		64
@@ -183,16 +207,17 @@ identity mapped.
 #define VB_STATUS_TIMESTAMP_HIGH	((4*2) + VB_STATUS_REG_STRUCT_END)
 #define VB_STATUS_TIMESTAMP_LOW		((4*3) + VB_STATUS_REG_STRUCT_END)
 #define VB_STATUS_OLD_INT_DISABLE	((4*4) + VB_STATUS_REG_STRUCT_END)
+#define VB_STATUS_RESERVED2		((4*5) + VB_STATUS_REG_STRUCT_END)
 #if (__VBI_BYTE_ORDER == __VBI_BIG_ENDIAN)
-#define VB_STATUS_VMMU0_HIGH		((4*5) + VB_STATUS_REG_STRUCT_END)
-#define VB_STATUS_VMMU0		((4*6) + VB_STATUS_REG_STRUCT_END)
-#define VB_STATUS_VMMU1_HIGH		((4*7) + VB_STATUS_REG_STRUCT_END)
-#define VB_STATUS_VMMU1		((4*8) + VB_STATUS_REG_STRUCT_END)
-#else
-#define VB_STATUS_VMMU0		((4*5) + VB_STATUS_REG_STRUCT_END)
 #define VB_STATUS_VMMU0_HIGH		((4*6) + VB_STATUS_REG_STRUCT_END)
-#define VB_STATUS_VMMU1		((4*7) + VB_STATUS_REG_STRUCT_END)
+#define VB_STATUS_VMMU0			((4*7) + VB_STATUS_REG_STRUCT_END)
 #define VB_STATUS_VMMU1_HIGH		((4*8) + VB_STATUS_REG_STRUCT_END)
+#define VB_STATUS_VMMU1			((4*9) + VB_STATUS_REG_STRUCT_END)
+#else
+#define VB_STATUS_VMMU0			((4*6) + VB_STATUS_REG_STRUCT_END)
+#define VB_STATUS_VMMU0_HIGH		((4*7) + VB_STATUS_REG_STRUCT_END)
+#define VB_STATUS_VMMU1			((4*8) + VB_STATUS_REG_STRUCT_END)
+#define VB_STATUS_VMMU1_HIGH		((4*9) + VB_STATUS_REG_STRUCT_END)
 #endif /* __VBI_BYTE_ORDER */
 
 /* Assembler offsets for vb_config */
@@ -334,7 +359,7 @@ struct vb_control
 	uint32_t irq_pend;		/* actual virtual interrupt pending */
 
 #ifdef CONFIG_WRHV_CERT
-	char name[VB_NAMELEN];  /* used for sched transition */
+	char name[VB_NAMELEN];		/* used for sched transition */
 #endif
 
 };
@@ -431,6 +456,10 @@ struct vb_status {
 	 */
 	uint32_t prev_irq_disable;
 
+	/* Padding to naturally align the following pointer fields */
+
+	uint32_t   reserved2;
+
 	/* VMMU tables which were active when an MMU exception occurred */
 	VB_ALIGN_FIELD_64 (void *vmmu0, pad1);
 	VB_ALIGN_FIELD_64 (void *vmmu1, pad2);
@@ -551,19 +580,18 @@ struct config_page_map
 
 #if defined(CONFIG_WRHV_CERT)
 /* order in this structure must match the ones in board_q_port_t */
-struct vbPortConfig{
-	uint32_t vbPortId;       /* unique Id starting at 0 */
-	char name[VB_NAMELEN];   /* port name */
-	uint32_t vbId;           /* vb Id where port reside */
-	uint32_t channelId;      /* channel id to which the port is connected */
-	uint32_t direction;      /* SOURCE or DESTINATION */
-	uint32_t protocol;       /* SENDER_BLOCK or RECEIVER_DISCARD */
-	uint32_t maxMsgSize;     /* max messages size in bytes */
-	uint32_t maxNumMsgs;     /* queue length */
+struct vbPortConfig {
+	uint32_t vbPortId;	/* unique Id starting at 0 */
+	char name[VB_NAMELEN];	/* port name */
+	uint32_t vbId;		/* vb Id where port reside */
+	uint32_t channelId;	/* channel id to which the port is connected */
+	uint32_t direction;	/* SOURCE or DESTINATION */
+	uint32_t protocol;	/* SENDER_BLOCK or RECEIVER_DISCARD */
+	uint32_t maxMsgSize;	/* max messages size in bytes */
+	uint32_t maxNumMsgs;	/* queue length */
 };
 #endif
 
-/* vb_config matched with hypervisor include/vbInterface.h */
 struct vb_config
 {
 
@@ -695,11 +723,15 @@ struct vb_config
 	/* ports configuration information */
 	VB_ALIGN_FIELD_64(struct vbPortConfig *portConfig, pad12);
 #else
+
 	/* provide mappings for all configuration pages */
 	struct config_page_map configPageMap[MAX_VB_CONFIG_REGIONS];
 	uint32_t configPageNum;
 #endif
 
+	/* guest type */
+
+	uint32_t   guestOS;
 };
 
 #endif /*_ASMLANGUAGE */
diff --git a/include/vbi/pdc.h b/include/vbi/pdc.h
index 7d634e6..044e805 100644
--- a/include/vbi/pdc.h
+++ b/include/vbi/pdc.h
@@ -64,20 +64,22 @@ struct ioctlOp
 }
 #endif /* DEV_ASYNC_IOCTL */
 
-/* following structure is taken from hypervisor
- * include/sys/wrhvDevCore.h
- */
-struct intrDeviceChannelBuffer
+struct intr_device_channel_buffer
 {
-	VB_ALIGN_FIELD_64 (void *rxBuf, pad1);      /* rx buffer to rx  */
-	VB_ALIGN_FIELD_64 (size_t rxBufLen, pad2);  /* rx buffer length */
-	VB_ALIGN_FIELD_64 (void *txBuf, pad3);      /* tx buffer to tx  */
-	VB_ALIGN_FIELD_64 (size_t txBufLen, pad4);  /* tx buffer length */
-	uint32_t rxBufRdPtr;                /* rx buffer read pointer  */
-	uint32_t rxBufWrPtr;                /* rx buffer write pointer */
-	uint32_t txBufRdPtr;                /* tx buffer read pointer  */
-	uint32_t txBufWrPtr;                /* tx buffer write pointer */
-	uint32_t intStatus;                 /* intStatus, or what intr */
+	VB_ALIGN_FIELD_64 (void *rxBuf, pad1);
+	VB_ALIGN_FIELD_64 (size_t rxBufLen, pad2);
+	VB_ALIGN_FIELD_64 (void *txBuf, pad3);
+	VB_ALIGN_FIELD_64 (size_t txBufLen, pad4);
+	uint64_t rxBufRdPtr;
+	uint64_t rxBufWrPtr;
+	uint64_t txBufRdPtr;
+	uint64_t txBufWrPtr;
+#ifdef DEV_ASYNC_IOCTL
+	VB_ALIGN_FIELD_64 (struct ioctlOp *ioctlBuf, pad5);
+	VB_ALIGN_FIELD_64 (size_t ioctlBufLen, pad6);
+	uint64_t ioctlBufRdPtr;
+	uint64_t ioctlBufWrPtr;
+#endif
 };
 
 #define SYS_PDC_REQUEST_OK		0
@@ -89,16 +91,21 @@ struct intrDeviceChannelBuffer
 #define PDC_IOCTL_SIO_HUP		4
 #define PDC_IOCTL_SIO_OPEN		5
 
+#define PDC_IOCTL_AMIO_CHANNEL_SET	20
+
 #define PDC_IOCTL_SIO_REQUEST_RESPONSE  0x8000
 #define PDC_IOCTL_SIO_GET_IER		(PDC_IOCTL_SIO_REQUEST_RESPONSE | 2)
 
 typedef enum {
-	PDC_REQUEST_MIN		= 1,
-	PDC_REQUEST_IOCTL	= 1,
-	PDC_REQUEST_READ	= 2,
-	PDC_REQUEST_WRITE	= 3,
-	PDC_REQUEST_INIT	= 4,
-	PDC_REQUEST_MAX		= 4
+	PDC_REQUEST_MIN			= 1,
+	PDC_REQUEST_IOCTL		= 1,
+	PDC_REQUEST_READ		= 2,
+	PDC_REQUEST_WRITE		= 3,
+	PDC_REQUEST_INIT		= 4,
+	PDC_REQUEST_ATTACH_GUEST	= 5,
+	PDC_REQUEST_DETACH_GUEST	= 6,
+	PDC_REQUEST_CORE_MSG		= 7,
+	PDC_REQUEST_MAX			= 7
 } vbi_pdc_request;
 
 extern int32_t vbi_pdc_op(vbi_pdc_handle pdcHandle,
diff --git a/include/vbi/syscall.h b/include/vbi/syscall.h
index 3da0390..2bbd84c 100644
--- a/include/vbi/syscall.h
+++ b/include/vbi/syscall.h
@@ -36,11 +36,15 @@ struct vbi_msg_info
 {
 	int32_t  id;		/* context id of sender */
 	uint32_t type;		/* message type (msg/event) */
-	size_t   slen;		/* length of sent buffer */
-	size_t   rlen;		/* length of received buffer */
+	VB_ALIGN_FIELD_64(size_t slen, pad1);	/* length of sent buffer */
+	VB_ALIGN_FIELD_64(size_t rlen, pad2);	/* length of received buffer */
 	uint16_t status;	/* message status information */
 	uint16_t error;		/* extended error status */
-	time_t   timestamp;	/* time message was sent */
+#ifndef _MSC_TOOL
+	time_t timestamp;	/* time message was sent */
+#else
+	hv_time_t timestamp;	/* time message was sent */
+#endif
 	uint32_t nmsg;		/* number of queued messages remaining */
 };
 
@@ -71,7 +75,11 @@ struct vbi_msg_ctl
 {
 	uint32_t flags;		/* operation flags */
 	uint32_t ordering;	/* order to receive messages */
+#ifndef _MSC_TOOL
 	time_t timeout;		/* receive timeout */
+#else
+	hv_time_t timeout;	/* receive timeout */
+#endif
 };
 
 /* message control flags */
@@ -81,8 +89,8 @@ struct vbi_msg_ctl
 /* memory read/write control structure */
 struct vbi_mem_ctl
 {
-	VB_ALIGN_FIELD_64 (void *pBuffer, pad1); /* address of target context   */
-	VB_ALIGN_FIELD_64 (void *pAddress, pad2);/* address of calling context  */
+	VB_ALIGN_FIELD_64(void *pBuffer, pad1); /* address of target context */
+	VB_ALIGN_FIELD_64(void *pAddress, pad2);/* address of calling context */
 	uint64_t size_in;	    /* number of bytes to be read	    */
 	uint64_t size_out;	    /* number of bytes successfully read    */
 	uint32_t flags;	    /* data/instruction flush option	    */
@@ -114,7 +122,8 @@ extern asmlinkage int vbi_vtlb_op(unsigned int op, unsigned long arg1,
 
 /* message receive */
 extern int32_t vbi_receive(void *rmsg, uint32_t rlen, struct vbi_msg_info *info,
-			struct vbi_msg_ctl *ctl);
+				struct vbi_msg_ctl *ctl);
+
 extern asmlinkage int32_t vbi_panic(const char *msg);
 extern int32_t vbi_flush_dcache(void *saddr, size_t size);
 extern int32_t vbi_flush_icache(void *saddr, size_t size);
@@ -142,13 +151,6 @@ extern int32_t vbi_tlb_flush_vmmu(struct vmmuConfig * config, void *addr, size_t
 #endif
 extern int32_t vbi_get_max_asid_vmmu(void);
 
-/* Prior to vbi 2.0 these api were vbi_set_mmu_attr/Get */
-
-
-/*
- * START: New APIs introduced for vbi 2.0
- */
-
 extern asmlinkage void vbi_vcore_irq_unlock(void);
 extern asmlinkage int32_t vbi_vcore_irq_lock(void);
 extern int32_t vbi_update_text_cache(void *saddr, size_t size);
@@ -157,17 +159,12 @@ extern int32_t vbi_set_exc_base(void *excTblBase);
 /* virtual board management API's */
 extern asmlinkage int32_t vbi_vb_reset(uint32_t id, int32_t core, uint32_t options);
 
-
-/*
- * END: New APIs introduced for vbi 2.0
- */
-
 /* commerical hypervisor and certifiable hypervisor stub functions */
 #if !defined(CONFIG_WRHV_CERT)
 extern asmlinkage int vbi_ctx_ctl(unsigned operation, unsigned arg1,
 				unsigned arg2);
 extern asmlinkage int32_t vbi_vb_mgmt(uint32_t cmd, uint32_t boardId,
-				int32_t *outError, uint32_t flags, void *ctl);
+				int32_t *outError, uint32_t flags, void * ctl);
 /* message reply */
 extern asmlinkage int32_t vbi_reply(int32_t id, void *smsg, size_t slen,
 				struct vbi_msg_ctl *ctl);
@@ -175,9 +172,9 @@ extern asmlinkage int32_t vbi_reply(int32_t id, void *smsg, size_t slen,
 extern asmlinkage int32_t vbi_kputs(const char *s);
 extern asmlinkage int32_t vbi_kputc(int c);
 extern asmlinkage void vbi_shell_start_debug(uint32_t  flags);
-extern asmlinkage int32_t vbi_set_mem_attr(void *vaddr, size_t len,
-					int32_t attr);
-extern asmlinkage int32_t vbi_get_mem_attr(void *vaddr, int32_t *attr);
+extern asmlinkage int32_t  vbi_set_mem_attr(void *vaddr, size_t len,
+						int32_t attr);
+extern asmlinkage int32_t  vbi_get_mem_attr(void *vaddr, int32_t * attr);
 extern asmlinkage int32_t vbi_vb_suspend(uint32_t id, int32_t core);
 extern asmlinkage int32_t vbi_vb_restart(uint32_t id, int32_t core);
 extern asmlinkage int32_t vbi_vb_resume(uint32_t id, int32_t core);
@@ -311,24 +308,18 @@ static inline int32_t vbi_vb_write_reg(VBI_HREG_SET_CMPLX_QUALIFIED *regSet,
 }
 #else
 /* Message send */
-extern asmlinkage
-int32_t vbi_send(int32_t id, void *smsg, size_t slen,
-			void *rmsg, size_t rlen, struct vbi_msg_info *info,
-			struct vbi_msg_ctl *ctl);
+extern asmlinkage int32_t vbi_send(int32_t id, void *smsg, size_t slen,
+			    void *rmsg, size_t rlen, struct vbi_msg_info *info,
+			    struct vbi_msg_ctl *ctl);
 /* read/write remote vb's registers */
-extern asmlinkage
-int32_t vbi_vb_read_reg(VBI_HREG_SET_CMPLX_QUALIFIED *regSet,
-				uint32_t targetBoard, int32_t core);
-extern asmlinkage
-int32_t vbi_vb_write_reg(VBI_HREG_SET_CMPLX_QUALIFIED *regSet,
-				uint32_t targetBoard, int32_t core);
+extern asmlinkage int32_t vbi_vb_read_reg(VBI_HREG_SET_CMPLX_QUALIFIED *regSet,
+				       uint32_t targetBoard, int32_t core);
+extern asmlinkage int32_t vbi_vb_write_reg(VBI_HREG_SET_CMPLX_QUALIFIED *regSet,
+					uint32_t targetBoard, int32_t core);
 /* read remote vb's memory */
-extern asmlinkage int32_t vbi_vb_read_mem(struct vbi_mem_ctl *memCtl,
-					 uint32_t targetBoard);
-extern asmlinkage int32_t vbi_vb_write_mem(struct vbi_mem_ctl *memCtl,
-					uint32_t targetBoard);
+extern asmlinkage int32_t vbi_vb_read_mem(struct vbi_mem_ctl *memCtl, uint32_t targetBoard);
+extern asmlinkage int32_t vbi_vb_write_mem(struct vbi_mem_ctl *memCtl, uint32_t targetBoard);
 #endif
 
-
 #endif	/* _ASMLANGUAGE */
 #endif  /* _VBI_SYSCALL_H */
diff --git a/include/vbi/syscalls.h b/include/vbi/syscalls.h
index a6d63d3..6aa1204 100644
--- a/include/vbi/syscalls.h
+++ b/include/vbi/syscalls.h
@@ -1,7 +1,7 @@
 /*
  * syscalls.h - hypervisor system calls
  *
- * Copyright (c) 2007-2010 Wind River Systems, Inc.
+ * Copyright (c) 2007-2011 Wind River Systems, Inc.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
@@ -114,6 +114,7 @@
 #ifdef CONFIG_WRHV_CERT
 #define VBI_SYS_schedTransition HY_SYSCALL(27)  /* transition frame scheduler */
 #endif
+
 /* Additional VMMU calls */
 #define VBI_SYS_vmmu_create	HY_SYSCALL(30)
 #define VBI_SYS_vmmu_delete	HY_SYSCALL(31)
@@ -144,9 +145,23 @@
 #define VBI_SYS_Pstate_set	HY_SYSCALL(74)	/* set core P state    */
 #define VBI_SYS_Cstate_set	HY_SYSCALL(75)	/* set core C state    */
 
+/* Dynamic VB create/delete and VB Migration */
+#define VBI_SYS_vbCreate	HY_SYSCALL(80)
+#define VBI_SYS_vbDelete	HY_SYSCALL(81)
+#define VBI_SYS_vbBoardSimpleConfigGet	HY_SYSCALL(82)
+#define VBI_SYS_vbBoardConfigGet	HY_SYSCALL(83)
+#define VBI_SYS_vbMove		HY_SYSCALL(84)
+#define VBI_SYS_vbPrioSet	HY_SYSCALL(85)
+
+/* Dynamic modification of VB */
+#define VBI_SYS_vbSharedMemoryAlloc	HY_SYSCALL(90)
+#define VBI_SYS_vbSharedMemoryFree	HY_SYSCALL(91)
+#define VBI_SYS_vbRamAlloc		HY_SYSCALL(92)
+#define VBI_SYS_vbRamFree		HY_SYSCALL(93)
+
 /* Max number of syscalls*/
 
-#define VBI_SYS_max		(75 + 1)
+#define VBI_SYS_max		(101 + 1)
 
 /* hyIoctl system call supported ioctl's */
 #define VBI_HYIOCTL_GETPID	 1	/* get context's pid		*/
@@ -189,10 +204,19 @@
 #define VBI_VBREMOTE_RAMSIZE        2       /* get memory size */
 
 /* MMU protection attributes */
+/* For backwards compatibility, these are preserved: */
 #define VBI_MMU_PROT_READ	0x00000001	/* read allowed    */
 #define VBI_MMU_PROT_WRITE	0x00000002	/* write allowed   */
 #define VBI_MMU_PROT_EXECUTE	0x00000004	/* execute allowed */
 
+/* Newer vbiMemAttrSet/Get interface: */
+#define	VBI_MMU_PROT_USER_READ		0x00000001  /* user read */
+#define	VBI_MMU_PROT_USER_WRITE		0x00000002  /* user write */
+#define	VBI_MMU_PROT_USER_EXECUTE	0x00000004  /* user execute */
+#define	VBI_MMU_PROT_SUPV_READ		0x00000008  /* supervisor read */
+#define	VBI_MMU_PROT_SUPV_WRITE		0x00000010  /* supervisor write */
+#define	VBI_MMU_PROT_SUPV_EXECUTE	0x00000020  /* supervisor execute */
+
 /* ETSEC MDIO supported ioctl's */
 #define VBI_BSPIOCTL_DRV_MDIO	1		/* mdio messages */
 
@@ -249,14 +273,24 @@
 #define VBI_VB_CORES_OTHERS	(0x40000000)
 
 /* VTLB operation command and flags (intel-vt specific) */
-#define VBI_VTLB_OP_UPDATE_PMD		1
-#define VBI_VTLB_OP_UPDATE_PTE		2
-#define VBI_VTLB_OP_DELETE_PMD		3
+#define VBI_VTLB_OP_UPDATE_PMD		1	/* 32-bit: L1 */
+#define VBI_VTLB_OP_UPDATE_PTE		2	/* 32-bit: L2 */
+#define VBI_VTLB_OP_DELETE_PMD		3	/* 32-bit: L1 */
 #define VBI_VTLB_OP_SET_PTE_AT		4
 #define VBI_VTLB_OP_SET_PTE		5
 #define VBI_VTLB_OP_FLUSH_OPS		6
 #define VBI_VTLB_OP_INIT		7
 
+#define VBI_VTLB_OP_INIT64		10
+#define VBI_VTLB_OP_UPDATE_PML4		11	/* 64-bit: L1 */
+#define VBI_VTLB_OP_UPDATE_PDP		12	/* 64-bit: L2 */
+#define VBI_VTLB_OP_UPDATE_PDE		13	/* 64-bit: L3 */
+#define VBI_VTLB_OP_UPDATE_PTE		 2	/* 64-bit: L4 */
+#define VBI_VTLB_OP_DELETE_PML4		15	/* 64-bit: L1 */
+#define VBI_VTLB_OP_DELETE_PDP		16	/* 64-bit: L2 */
+#define VBI_VTLB_OP_DELETE_PDE		17	/* 64-bit: L3 */
+
+
 /* VTLB macros */
 #define VBI_VTLB_OP_MAX_OPS		100
 #define VBI_VTLB_OP_CR3_CACHE_ENTRIES	4
@@ -291,7 +325,8 @@ struct vbi_ctx_stats
 	unsigned long reset;		/* number of times context reset     */
 };
 
-/* VTLB operation structures (x86 specific) */
+/* VTLB operation structures (x86 specific, 32-bit version) */
+
 struct vbi_vtlb_op
 {
 	uint32_t op;		/* VTLB operation id */
@@ -317,6 +352,33 @@ struct vbi_vtlb_control
 	struct vbi_vtlb_cr3_cache cr3_cache[VBI_VTLB_OP_CR3_CACHE_ENTRIES];
 };
 
+/* VTLB operation structures (x86 specific, 64-bit version) */
+
+struct vbi_vtlb_op64		/* VTLB operation */
+{
+	uint32_t	op;		/* VTLB operation id */
+	uint64_t	arg1;		/* VTLB operation arg 1 */
+	uint64_t	arg2;		/* VTLB operation arg 2 */
+	uint64_t	arg3;		/* VTLB operation arg 3 */
+};
+
+struct vbi_vtlb_cr3_cache64
+{
+	uint64_t	guest_cr3;	/* Guest CR3 register */
+	uint64_t	host_cr3;	/* Host CR3 register */
+};
+
+struct vbi_vtlb_control64
+{
+	uint32_t	size;		/* VTLB Control structure size */
+	uint32_t	mode;		/* VTLB module */
+	uint32_t	vtlb_ops_ix;	/* VTLB operation index */
+					/* VTLB ops array */
+	struct vbi_vtlb_op64	vtlb_ops[VBI_VTLB_OP_MAX_OPS];
+	uint32_t	cr3_cache_ix;	/* CR3 cache and index */
+	struct vbi_vtlb_cr3_cache64 cr3_cache[VBI_VTLB_OP_CR3_CACHE_ENTRIES];
+};					/* VBI VTLB control */
+
 /*
  * Control structure used by vbi_vb_mgmt for commands memory read, memory write,
  *  register read, and register write.
diff --git a/include/vbi/types.h b/include/vbi/types.h
index df8e9f6..e3777ff 100644
--- a/include/vbi/types.h
+++ b/include/vbi/types.h
@@ -33,7 +33,11 @@
 #ifdef CONFIG_CPU_CAVIUM_OCTEON
 #define CPU MIPSI64R2
 #endif /* CONFIG_CPU_CAVIUM_OCTEON */
- 
+
+#ifdef CONFIG_ARM
+#define CPU ARMCA9
+#endif /* CONFIG_ARM */
+
 #include <vbi/cpu_types.h>	/* for PENTIUM, PPC85XX, etc */
 
 #endif  /* _VBI_TYPES_H */
diff --git a/include/vbi/vbi.h b/include/vbi/vbi.h
index ef0ca93..73a42bb 100644
--- a/include/vbi/vbi.h
+++ b/include/vbi/vbi.h
@@ -1,7 +1,7 @@
 /*
  * vbi.h - virtual board support definitions
  *
- * Copyright (c) 2007 - 2010 Wind River Systems, Inc.
+ * Copyright (c) 2007 - 2011 Wind River Systems, Inc.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
@@ -17,6 +17,29 @@
 #ifndef _VBI_VBI_H
 #define _VBI_VBI_H
 
+/* alignment macros for MSC */
+#define _MSC_VER 0	/* change to suit */
+#ifndef DECLSPEC_ALIGN
+#if (_MSC_VER >= 1300) && !defined(MIDL_PASS)
+#define DECLSPEC_ALIGN(x)   __declspec(align(x))
+#else
+#define DECLSPEC_ALIGN(x)
+#endif
+#endif
+
+#ifndef SYSTEM_CACHE_ALIGNMENT_SIZE
+#if defined(_AMD64_) || defined(_X86_)
+#define SYSTEM_CACHE_ALIGNMENT_SIZE 64
+#else
+#define SYSTEM_CACHE_ALIGNMENT_SIZE 128
+#endif
+#endif
+
+#ifndef DECLSPEC_CACHEALIGN
+#define DECLSPEC_CACHEALIGN DECLSPEC_ALIGN(SYSTEM_CACHE_ALIGNMENT_SIZE)
+#endif
+
+
 #ifdef CONFIG_64BIT
 #ifndef LP64
 #define LP64
@@ -520,7 +543,6 @@ struct vbi_clk_hook
 extern struct vb_config *wr_vb_config;
 extern struct vb_status *wr_vb_status;
 extern struct vb_control *wr_vb_control;
-extern int32_t vb_int_nested; /* wrhvVbIntNested */
 extern void vbi_init(struct vb_config *config);
 extern void vbi_exc_stub(void);
 extern void ASSERT_FN(const char *, const char *, int);
@@ -533,8 +555,6 @@ extern int32_t vbi_mask_vioapic_irq(int32_t irq);
 extern int32_t vbi_ack_vioapic_irq(int32_t irq);
 extern asmlinkage void vbi_di_eoi(void);
 extern int32_t vbi_send_vioapic_irq(int32_t irq, uint32_t filter,
-				      uint32_t target);
-extern int32_t vbi_send_vioapic_irq(int32_t irq, uint32_t filter,
 				     uint32_t vb);
 extern int32_t vbi_redir_vioapic_irq(int32_t irq, int32_t tCore);
 extern int32_t vbi_send_vcore_vioapic_irq(int32_t irq, uint32_t vcoreSet,
@@ -551,6 +571,7 @@ extern void vbi_show_cfg(void);
 extern void vbi_show_mem(void);
 extern void vbi_disp_status_regs(void);
 extern void vbi_disp_ctrl_regs(void);
+extern size_t kprintf(const char *, ...);
 extern int32_t vbi_vb_find_board_config(uint32_t board_id, int32_t core_id,
 						void *paddr);
 extern void vbi_show_config_page_map(void);
diff --git a/include/vbi/version.h b/include/vbi/version.h
index c8a375d..a39ac3b 100644
--- a/include/vbi/version.h
+++ b/include/vbi/version.h
@@ -1,7 +1,7 @@
 /*
  * version.h - vbi version information
  *
- * Copyright (c) 2009 Wind River Systems, Inc.
+ * Copyright (c) 2009-2011 Wind River Systems, Inc.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
@@ -24,7 +24,7 @@
  */
 
 #define VBI_RUNTIME_NAME     "Wind River Hypervisor Virtual board interface"
-#define VBI_RUNTIME_VERSION  "2.1.0"
+#define VBI_RUNTIME_VERSION  "2.2.0"
 
 /* textual description of this product version */
 
diff --git a/include/vbi/vmmu.h b/include/vbi/vmmu.h
index 6c12eb6..cecf9b5 100644
--- a/include/vbi/vmmu.h
+++ b/include/vbi/vmmu.h
@@ -18,109 +18,117 @@
 #define _VBI_VMMU_H
 
 /*
-
-The vmmu virtual address space is restricted to 32 bits and is decoded using
-a level-1/level-2 page table.  The virtual address is decoded as follows:
-
-
-                          32-bit Virtual Address
-        +---------------------------------------------------------+
-        |      L1 offset       | L2 offset |    Page offset       |
-        +---------------------------------------------------------+
-		11 bits           9 bits           12 bits
-                  |                 |
-                  |                 |
-    +-------------+                 |
-    |                               |
-    |                               |
-    |           L1 Table            |            L2 Table
-    |    2047 +----------+          |      511 +----------+
-    |         |          |          |          |          |
-    |         |          |          |          |          |
-    |         |          |          |          |----------|
-    |         |          |          |   +----->|    PTE   | 8 byte PTE
-    |         |          |          |   |      |----------|
-    |         |          |          |   |      |          |
-    |         |----------| 20 bits  |   |      |          |
-    +-------->|  L2 ptr  |----------+---+      |          |
-              |----------|                     |          |
-              |          |                     |          |
-              |          |                     |          |
-            0 +----------+                   0 +----------+
-               2 page (8KB)                    1 page (4KB)
-             2048 L2 pointers                 512 PTE entries
-
-
-
-Each page table entry is 8 bytes (2 words) and uses the following format:
-
-
-word 0 (32-bits):
-
-	  0 1            7 8           15 1 1 1 1 2 2 2 2 24   26 27  31
-	                                  6 7 8 9 0 1 2 3
-	 +-+--------------+--------------+-+-+-+-+-+-+-+-+-------+------+
-	 |V|  Hypervisor  |   Reserved   |U|U|U|U|U|U|U|U| ERPN  | ATTR |
-	 | |   Reserved   |              |0|1|2|3|4|5|6|7|       |      |
-	 +-+--------------+--------------+-+-+-+-+-+-+-+-+-------+------+
-
-		V          - valid bit
-		Hypervisor - reserved for use by hypervisor
-		U0-U7      - user defined attributes
-		ERPN       - extended real page number bits
-		ATTR       - page attributes
-
-
-word 1 (32-bits):
-
-	  0                                19 20      23 2 2 2 2 2 2 3 3
-	                                                 4 5 6 7 8 9 0 1
-	 +-----------------------------------+----------+-+-+-+-+-+-+-+-+
-	 |                RPN                | Reserved |R|C|U|S|U|S|U|S|
-	 |                                   |          | | |X|X|W|W|R|R|
-	 +-----------------------------------+----------+-+-+-+-+-+-+-+-+
-
-		RPN        - real page number
-		R          - page referenced bit
-		C          - page changed bit
-		SX,SW,SR   - supervisor mode protection bits
-		UX,UW,UR   - user mode protection bits
-
-Above page table bits are numbered as per PPC(IBM) format MSB bit as 0, 
-The same entry can be represented using LSB bit as 0, as in mips64 arch:
-
-word 0 (32-bits):
-       
-          3 30          24 23          16 1 1 1 1 1 1 9 8 7     5 4    0
-          1                               5 4 3 2 1 0
-        +-+--------------+--------------+-+-+-+-+-+-+-+-+-------+------+
-        |V|  Hypervisor  |   Reserved   |U|U|U|U|U|U|U|U| ERPN  | ATTR |
-        | |   Reserved   |              |0|1|2|3|4|5|6|7|       |      |
-        +-+--------------+--------------+-+-+-+-+-+-+-+-+-------+------+
-
-               V          - valid bit
-               Hypervisor - reserved for use by hypervisor
-               U0-U7      - user defined attributes
-               ERPN       - extended real page number bits
-               ATTR       - page attributes
-
-
-word 1 (32-bits):
-
-          31                               12 11       8 7 6 5 4 3 2 1 0
-        +-----------------------------------+----------+-+-+-+-+-+-+-+-+
-        |                RPN                | Reserved |R|C|U|S|U|S|U|S|
-        |                                   |          | | |X|X|W|W|R|R|
-        +-----------------------------------+----------+-+-+-+-+-+-+-+-+
-
-               RPN        - real page number
-               R          - page referenced bit
-               C          - page changed bit
-               SX,SW,SR   - supervisor mode protection bits
-               UX,UW,UR   - user mode protection bits
-
-
-*/
+ *
+ * VMMU format - 32-bit Virtual MMU format for Guest OS
+ * 
+ * 32-bit Virtual MMU format for Guest OS 
+ * 
+ * SYNOPSIS
+ *
+ * 
+ * 
+ * The vmmu virtual address space is restricted to 32 bits and is decoded using
+ * a level-1/level-2 page table.  The virtual address is decoded as follows:
+ * 
+ * 
+ *                           32-bit Virtual Address
+ *         +---------------------------------------------------------+
+ *         |      L1 offset       | L2 offset |    Page offset       |
+ *         +---------------------------------------------------------+
+ * 		11 bits           9 bits           12 bits
+ *                   |                 |
+ *                   |                 |
+ *     +-------------+                 |
+ *     |                               |
+ *     |                               |
+ *     |           L1 Table            |            L2 Table
+ *     |    2047 +----------+          |      511 +----------+
+ *     |         |          |          |          |          |
+ *     |         |          |          |          |          |
+ *     |         |          |          |          |----------|
+ *     |         |          |          |   +----->|    PTE   | 8 byte PTE
+ *     |         |          |          |   |      |----------|
+ *     |         |          |          |   |      |          |
+ *     |         |----------| 20 bits  |   |      |          |
+ *     +-------->|  L2 ptr  |----------+---+      |          |
+ *               |----------|                     |          |
+ *               |          |                     |          |
+ *               |          |                     |          |
+ *             0 +----------+                   0 +----------+
+ *                2 page (8KB)                    1 page (4KB)
+ *              2048 L2 pointers                 512 PTE entries
+ * 
+ * 
+ * 
+ * Each page table entry is 8 bytes (2 words) and uses the following format:
+ * 
+ * 
+ * word 0 (32-bits):
+ * 	
+ * 	  0 1            7 8           15 1 1 1 1 2 2 2 2 24   26 27  31
+ * 	                                  6 7 8 9 0 1 2 3               
+ * 	 +-+--------------+--------------+-+-+-+-+-+-+-+-+-------+------+
+ * 	 |V|  Hypervisor  |   Reserved   |U|U|U|U|U|U|U|U| ERPN  | ATTR |
+ * 	 | |   Reserved   |              |0|1|2|3|4|5|6|7|       |      |
+ * 	 +-+--------------+--------------+-+-+-+-+-+-+-+-+-------+------+
+ * 
+ * 		V          - valid bit
+ * 		Hypervisor - reserved for use by hypervisor
+ * 		U0-U7      - user defined attributes
+ * 		ERPN       - extended real page number bits
+ * 		ATTR       - page attributes
+ * 
+ * 
+ * word 1 (32-bits):
+ * 
+ * 	  0                                19 20      23 2 2 2 2 2 2 3 3
+ * 	                                                 4 5 6 7 8 9 0 1
+ * 	 +-----------------------------------+----------+-+-+-+-+-+-+-+-+
+ * 	 |                RPN                | Reserved |R|C|U|S|U|S|U|S|
+ * 	 |                                   |          | | |X|X|W|W|R|R|
+ * 	 +-----------------------------------+----------+-+-+-+-+-+-+-+-+
+ * 
+ * 		RPN        - real page number
+ * 		R          - page referenced bit
+ * 		C          - page changed bit
+ * 		SX,SW,SR   - supervisor mode protection bits
+ * 		UX,UW,UR   - user mode protection bits
+ * 
+ * 
+ * Above page table bits are numbered as per PPC(IBM) format MSB bit as 0, 
+ * The same entry can be represented using LSB bit as 0, as in mips64 arch:
+ * 
+ * word 0 (32-bits):
+ * 	
+ *           3 30          24 23          16 1 1 1 1 1 1 9 8 7     5 4    0
+ *           1                               5 4 3 2 1 0
+ * 	 +-+--------------+--------------+-+-+-+-+-+-+-+-+-------+------+
+ * 	 |V|  Hypervisor  |   Reserved   |U|U|U|U|U|U|U|U| ERPN  | ATTR |
+ * 	 | |   Reserved   |              |0|1|2|3|4|5|6|7|       |      |
+ * 	 +-+--------------+--------------+-+-+-+-+-+-+-+-+-------+------+
+ * 
+ * 		V          - valid bit
+ * 		Hypervisor - reserved for use by hypervisor
+ * 		U0-U7      - user defined attributes
+ * 		ERPN       - extended real page number bits
+ * 		ATTR       - page attributes
+ * 
+ * 
+ * word 1 (32-bits):
+ * 
+ *           31                               12 11       8 7 6 5 4 3 2 1 0
+ * 	 +-----------------------------------+----------+-+-+-+-+-+-+-+-+
+ * 	 |                RPN                | Reserved |R|C|U|S|U|S|U|S|
+ * 	 |                                   |          | | |X|X|W|W|R|R|
+ * 	 +-----------------------------------+----------+-+-+-+-+-+-+-+-+
+ * 
+ * 		RPN        - real page number
+ * 		R          - page referenced bit
+ * 		C          - page changed bit
+ * 		SX,SW,SR   - supervisor mode protection bits
+ * 		UX,UW,UR   - user mode protection bits
+ * 
+ */
 
 #ifndef	_ASMLANGUAGE
 
@@ -269,6 +277,9 @@ typedef struct vmmuConfig
 #define	VMMU_PROT_USER_WRITE	0x00000008	/* user write allowed	      */
 #define	VMMU_PROT_SUPV_EXECUTE	0x00000010	/* supervisor execute allowed */
 #define	VMMU_PROT_USER_EXECUTE	0x00000020	/* user execute allowed	      */
+#define	VMMU_PROT_COW_INVALID	0x00000040	/* copy-on-write invalid      */
+#define	VMMU_PROT_COW_VALID	0x00000080	/* copy-on-write valid	      */
+
 
 
 #define	VMMU_PROT_USER_RWX	VMMU_PROT_USER_READ | \
diff --git a/kernel/vbi/io_apic.c b/kernel/vbi/io_apic.c
index fa85018..57d8478 100644
--- a/kernel/vbi/io_apic.c
+++ b/kernel/vbi/io_apic.c
@@ -274,7 +274,8 @@ int32_t vbi_send_vcore_vioapic_irq(int32_t irq, uint32_t coreSet,
 			"vbi_send_vcore_vioapic_irq");
 		return -1;
 	}
-	return vbi_io_apic_op(VBI_IOAPICIOCTL_VCORE_SEND, irq, coreSet, options);
+	return vbi_io_apic_op(VBI_IOAPICIOCTL_VCORE_SEND, irq, coreSet,
+				options);
 }
 
 /*
@@ -346,7 +347,7 @@ void vbi_disp_vioapic(void)
 	/* Certifiable hypervisor does not support this function */
 	if (is_cert_hyp()) {
 		VBISTAT_VERBOSE(vbistat_count.vbi_disp_vioapic,
-		"vbi_disp_vioapic");
+			"vbi_disp_vioapic");
 		return;
 	}
 
diff --git a/kernel/vbi/lib.c b/kernel/vbi/lib.c
index 7b75425..356126b 100644
--- a/kernel/vbi/lib.c
+++ b/kernel/vbi/lib.c
@@ -116,8 +116,6 @@ struct vb_status *wr_vb_status;	/* The address of the core's Status area */
 EXPORT_SYMBOL(wr_vb_control);
 EXPORT_SYMBOL(wr_vb_status);
 
-int32_t wr_irq_nested; /* Used by VBI interrupt/exception management */
- 
 /*
  * vbi_init - Initialize support for vbi library functions
  *
diff --git a/kernel/vbi/ns.c b/kernel/vbi/ns.c
index b501f96..d668297 100644
--- a/kernel/vbi/ns.c
+++ b/kernel/vbi/ns.c
@@ -104,8 +104,8 @@ int32_t vbi_ns_unregister(char *name, uint32_t revision)
 int32_t vbi_ns_lookup_old(char *name, uint32_t revision, VBI_NS_HANDLE *handle)
 {
 	/* Optional VBI, Certifiable hypervisor does not
-	   support this function */
-        if (is_corevbi_only()) {
+		support this function */
+	if (is_corevbi_only()) {
 		VBISTAT_VERBOSE(vbistat_count.vbi_ns_lookup,
 			"vbi_ns_lookup");
 		return -1;
@@ -143,7 +143,7 @@ int32_t vbi_ns_lookup(char *name, uint32_t revision, VBI_NS_HANDLE *handle,
 			uint32_t timeout, uint32_t options)
 {
 	/* Optional VBI, Certifiable hypervisor does not
-	   support this function */
+		support this function */
 	if (is_corevbi_only()) {
 		VBISTAT_VERBOSE(vbistat_count.vbi_ns_lookup,
 			"vbi_ns_lookup");
diff --git a/kernel/vbi/show.c b/kernel/vbi/show.c
index 778092d..e0322d0 100644
--- a/kernel/vbi/show.c
+++ b/kernel/vbi/show.c
@@ -145,8 +145,8 @@ static void vbi_show_device(void)
 	unsigned int num_devices = config->numDevices;
 	unsigned int i, j, k;
 
-	printk("%d device configurations, Config at 0x%x\n", num_devices,
-			(unsigned int)p);
+	printk("%d device configurations, Config at %p\n", num_devices,
+			p);
 
 	for (i = 0; i < num_devices; i++, p++) {
 
@@ -283,7 +283,7 @@ void vbi_show_config_page_map()
 			" Mapping Size 0x%x\n",i,
 			pConfigPageMap[i].address,
 			pConfigPageMap[i].accessPriv,
-			pConfigPageMap[i].size);
+			(unsigned int)pConfigPageMap[i].size);
 }
 #endif
 
diff --git a/kernel/vbi/wrhv.c b/kernel/vbi/wrhv.c
index 92b8082..6b0b156 100644
--- a/kernel/vbi/wrhv.c
+++ b/kernel/vbi/wrhv.c
@@ -28,6 +28,7 @@
 #include <vbi/private.h>
 #include <linux/reboot.h>
 #include <linux/pci.h>
+#include <vbi/dynamic.h>
 
 #include "procfs.h"
 
-- 
1.7.0.4

