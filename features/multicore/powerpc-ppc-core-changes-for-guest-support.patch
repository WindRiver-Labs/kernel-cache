From e22df32820d6f2caffd754dc190041ebc882410a Mon Sep 17 00:00:00 2001
From: WRS Support <support@windriver.com>
Date: Tue, 27 Apr 2010 15:48:12 +0800
Subject: [PATCH] powerpc: ppc core changes for guest support

From 9932c4f8590d2542f5b77bfc66902395255aa531 Mon Sep 17 00:00:00 2001
Subject: [PATCH 14/18] powerpc: ppc core changes for guest support
This represents changes to existing core powerpc kernel files in
order to support linux as a guest OS on WR hypervisor.

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
Signed-off-by: Bruce Ashfield <bruce.ashfield@windriver.com>
[Leave gianfar related work to 85xx GOS]
Signed-off-by: Tiejun Chen <tiejun.chen@windriver.com>
---
 arch/powerpc/Makefile                    |    7 ++-
 arch/powerpc/boot/Makefile               |    4 ++
 arch/powerpc/boot/main.c                 |   17 ++++++-
 arch/powerpc/boot/serial.c               |   63 ++++++++++++++++++++++++
 arch/powerpc/boot/wrapper                |    2 +-
 arch/powerpc/include/asm/fs_pd.h         |   12 +++++
 arch/powerpc/include/asm/hw_irq.h        |   77 +++++++++++++++++++++++++++++
 arch/powerpc/include/asm/machdep.h       |    6 ++
 arch/powerpc/include/asm/page_32.h       |    4 +-
 arch/powerpc/include/asm/pgalloc-32.h    |    2 +-
 arch/powerpc/include/asm/pgtable-ppc32.h |   40 +++++++++++++--
 arch/powerpc/include/asm/pgtable.h       |   10 +++-
 arch/powerpc/include/asm/processor.h     |    6 ++
 arch/powerpc/include/asm/pte-common.h    |    2 +-
 arch/powerpc/include/asm/ptrace.h        |    4 ++
 arch/powerpc/include/asm/reg.h           |    5 ++
 arch/powerpc/include/asm/system.h        |    4 ++
 arch/powerpc/include/asm/wrhv.h          |    3 +
 arch/powerpc/kernel/Makefile             |   16 ++++++-
 arch/powerpc/kernel/entry_32.S           |   79 ++++++++++++++++++++++++------
 arch/powerpc/kernel/head_booke.h         |    2 +-
 arch/powerpc/kernel/irq.c                |   28 +++++++++--
 arch/powerpc/kernel/kgdb.c               |   16 ++++++-
 arch/powerpc/kernel/misc_32.S            |   30 +++++++++++
 arch/powerpc/kernel/module.c             |    9 +++
 arch/powerpc/kernel/paravirt.c           |    2 -
 arch/powerpc/kernel/process.c            |   20 ++++++++
 arch/powerpc/kernel/prom.c               |   13 +++++-
 arch/powerpc/kernel/setup-common.c       |   15 ++++++
 arch/powerpc/kernel/setup_32.c           |   20 +++++++-
 arch/powerpc/kernel/smp.c                |    2 +-
 arch/powerpc/kernel/time.c               |   42 ++++++++++++++--
 arch/powerpc/kernel/traps.c              |   18 ++++++-
 arch/powerpc/kvm/Kconfig                 |   23 +++++++++
 arch/powerpc/mm/fault.c                  |   20 ++++++++
 arch/powerpc/mm/fsl_booke_mmu.c          |   21 +++++++-
 arch/powerpc/mm/init_32.c                |   24 ++++++++--
 arch/powerpc/mm/mem.c                    |   11 ++++-
 arch/powerpc/mm/mmu_decl.h               |    9 +++-
 arch/powerpc/mm/pgtable_32.c             |   32 +++++++++++--
 40 files changed, 659 insertions(+), 61 deletions(-)

diff --git a/arch/powerpc/Makefile b/arch/powerpc/Makefile
index 6cc62dd..15b3e06 100644
--- a/arch/powerpc/Makefile
+++ b/arch/powerpc/Makefile
@@ -140,7 +140,12 @@ head-y				:= arch/powerpc/kernel/head_$(CONFIG_WORD_SIZE).o
 head-$(CONFIG_8xx)		:= arch/powerpc/kernel/head_8xx.o
 head-$(CONFIG_40x)		:= arch/powerpc/kernel/head_40x.o
 head-$(CONFIG_44x)		:= arch/powerpc/kernel/head_44x.o
-head-$(CONFIG_FSL_BOOKE)	:= arch/powerpc/kernel/head_fsl_booke.o
+
+ifeq ($(CONFIG_WRHV),y)
+head-$(CONFIG_FSL_BOOKE)        := arch/powerpc/kernel/head_wrhv.o
+else
+head-$(CONFIG_FSL_BOOKE)        := arch/powerpc/kernel/head_fsl_booke.o
+endif
 
 head-$(CONFIG_PPC64)		+= arch/powerpc/kernel/entry_64.o
 head-$(CONFIG_PPC_FPU)		+= arch/powerpc/kernel/fpu.o
diff --git a/arch/powerpc/boot/Makefile b/arch/powerpc/boot/Makefile
index bb2465b..20e008f 100644
--- a/arch/powerpc/boot/Makefile
+++ b/arch/powerpc/boot/Makefile
@@ -29,6 +29,10 @@ ifdef CONFIG_DEBUG_INFO
 BOOTCFLAGS	+= -g
 endif
 
+ifdef CONFIG_WRHV
+BOOTCFLAGS	+= -DCONFIG_WRHV
+endif
+
 ifeq ($(call cc-option-yn, -fstack-protector),y)
 BOOTCFLAGS	+= -fno-stack-protector
 endif
diff --git a/arch/powerpc/boot/main.c b/arch/powerpc/boot/main.c
index a28f021..91e43a2 100644
--- a/arch/powerpc/boot/main.c
+++ b/arch/powerpc/boot/main.c
@@ -18,6 +18,10 @@
 #include "gunzip_util.h"
 #include "reg.h"
 
+#ifdef CONFIG_WRHV
+#include "wrhv_boot.h"
+#endif
+
 static struct gunzip_state gzstate;
 
 struct addr_range {
@@ -192,6 +196,9 @@ void start(void)
 	vmlinux = prep_kernel();
 	initrd = prep_initrd(vmlinux, chosen,
 			     loader_info.initrd_addr, loader_info.initrd_size);
+#ifdef CONFIG_WRHV
+	strncpy(cmdline,(char *)(WRHV_CMDLINE_ADDR),WRHV_CMDLINE_SIZE);
+#endif
 	prep_cmdline(chosen);
 
 	printf("Finalizing device tree...");
@@ -205,9 +212,15 @@ void start(void)
 	if (console_ops.close)
 		console_ops.close();
 
-	kentry = (kernel_entry_t) vmlinux.addr;
+	/* For Hypervisor, kernel entry should be at 0xC0000000 */
+#ifdef CONFIG_WRHV
+#define ENT_OFFSET 0xC0000000
+#else
+#define ENT_OFFSET 0
+#endif
+	kentry = (kernel_entry_t) (vmlinux.addr + ENT_OFFSET);
 	if (ft_addr)
-		kentry(ft_addr, 0, NULL);
+		kentry(ft_addr, ENT_OFFSET, NULL);
 	else
 		kentry((unsigned long)initrd.addr, initrd.size,
 		       loader_info.promptr);
diff --git a/arch/powerpc/boot/serial.c b/arch/powerpc/boot/serial.c
index f2156f0..725a35d 100644
--- a/arch/powerpc/boot/serial.c
+++ b/arch/powerpc/boot/serial.c
@@ -19,6 +19,10 @@
 #include "io.h"
 #include "ops.h"
 
+#ifdef CONFIG_WRHV
+#include "wrhv_boot.h"
+#endif
+
 static int serial_open(void)
 {
 	struct serial_console_data *scdp = console_ops.data;
@@ -82,6 +86,56 @@ static void serial_close(void)
 		scdp->close();
 }
 
+#ifdef CONFIG_WRHV
+static inline const char * wrhv_serial(int port_index)
+{
+	switch(port_index) {
+		case  0:
+			return "serial0";
+		case  1:
+			return "serial1";
+		case  2:
+			return "serial2";
+		case  3:
+			return "serial3";
+		default:
+			return NULL;
+	}
+}
+
+static void * wrhv_serial_get_stdout_devp(void)
+{
+	void *devp;
+	char *cmdline_p = (char *)(WRHV_CMDLINE_ADDR);
+	char wrhv_path[256];
+	int i = 0, serial_index = -1;
+
+	do{
+		if(!strncmp(&cmdline_p[i],"wrhv_earlycon=",WRHV_EARLYCON_SIZE)){
+			serial_index = cmdline_p[i+WRHV_EARLYCON_SIZE];
+			break;
+		}
+		/* Try to find next space  */
+		while((i < 242) && (cmdline_p[i] != 0x20))
+			i++;
+		/*skip the space */
+		i++;
+	}while(i < WRHV_CMDLINE_SIZE);
+
+	devp = finddevice("/aliases");
+	if (devp == NULL)
+		goto null_out;
+
+	if (getprop(devp,wrhv_serial((serial_index - 0x30)),wrhv_path,256) > 0){
+		devp =  finddevice(wrhv_path);
+		return devp;
+	}
+
+null_out:
+	return NULL;
+}
+#endif
+
 static void *serial_get_stdout_devp(void)
 {
 	void *devp;
@@ -113,6 +167,11 @@ int serial_console_init(void)
 	void *devp;
 	int rc = -1;
 
+#ifdef CONFIG_WRHV
+	devp = wrhv_serial_get_stdout_devp();
+	if(devp == NULL)
+#endif
+
 	devp = serial_get_stdout_devp();
 	if (devp == NULL)
 		goto err_out;
@@ -142,7 +201,11 @@ int serial_console_init(void)
 		console_ops.data = &serial_cd;
 
 		if (serial_cd.getc)
+#ifdef CONFIG_WRHV
+			console_ops.edit_cmdline = NULL;
+#else	
 			console_ops.edit_cmdline = serial_edit_cmdline;
+#endif
 
 		return 0;
 	}
diff --git a/arch/powerpc/boot/wrapper b/arch/powerpc/boot/wrapper
index f4594ed..45fa72b 100755
--- a/arch/powerpc/boot/wrapper
+++ b/arch/powerpc/boot/wrapper
@@ -142,7 +142,7 @@ objflags=-S
 tmp=$tmpdir/zImage.$$.o
 ksection=.kernel:vmlinux.strip
 isection=.kernel:initrd
-link_address='0x400000'
+link_address='0x600000'
 
 case "$platform" in
 pseries)
diff --git a/arch/powerpc/include/asm/fs_pd.h b/arch/powerpc/include/asm/fs_pd.h
index 9361cd5..9df3b12 100644
--- a/arch/powerpc/include/asm/fs_pd.h
+++ b/arch/powerpc/include/asm/fs_pd.h
@@ -42,9 +42,21 @@ static inline int uart_baudrate(void)
         return get_baudrate();
 }
 
+#ifdef CONFIG_PARAVIRT
+extern int paravirt_ppc_proc_freq(void);
+static inline int native_ppc_proc_freq(void)
+{
+	return ppc_proc_freq;
+}
+#endif
+
 static inline int uart_clock(void)
 {
+#ifdef CONFIG_PARAVIRT
+	return paravirt_ppc_proc_freq();
+#else
         return ppc_proc_freq;
+#endif
 }
 
 #endif
diff --git a/arch/powerpc/include/asm/hw_irq.h b/arch/powerpc/include/asm/hw_irq.h
index bd100fc..8aa2614 100644
--- a/arch/powerpc/include/asm/hw_irq.h
+++ b/arch/powerpc/include/asm/hw_irq.h
@@ -13,6 +13,7 @@
 
 extern void timer_interrupt(struct pt_regs *);
 
+#ifndef CONFIG_PARAVIRT
 #ifdef CONFIG_PPC64
 #include <asm/paca.h>
 
@@ -124,6 +125,82 @@ static inline int irqs_disabled_flags(unsigned long flags)
 
 #endif /* CONFIG_PPC64 */
 
+#else /* !CONFIG_PARAVIRT */
+
+/* native implementation taken from !CONFIG_PPC64 */
+#if defined(CONFIG_BOOKE)
+#define SET_MSR_EE(x)	mtmsr(x)
+#define native_local_irq_restore(flags)	__asm__ __volatile__("wrtee %0" : : "r" (flags) : "memory")
+#else
+#define SET_MSR_EE(x)	mtmsr(x)
+#define native_local_irq_restore(flags)	mtmsr(flags)
+#endif
+
+static inline void native_local_irq_disable(void)
+{
+#ifdef CONFIG_BOOKE
+#ifdef CONFIG_KVM_GUEST
+	__asm__ __volatile__("wrtee %0": : "r"(0) :"memory");
+#else
+	__asm__ __volatile__("wrteei 0": : :"memory");
+#endif
+#else
+	unsigned long msr;
+	__asm__ __volatile__("": : :"memory");
+	msr = mfmsr();
+	SET_MSR_EE(msr & ~MSR_EE);
+#endif
+}
+
+static inline void native_local_irq_enable(void)
+{
+#ifdef CONFIG_BOOKE
+#ifdef CONFIG_KVM_GUEST
+	__asm__ __volatile__("wrtee %0": : "r"(MSR_EE) :"memory");
+#else
+	__asm__ __volatile__("wrteei 1": : :"memory");
+#endif
+#else
+	unsigned long msr;
+	__asm__ __volatile__("": : :"memory");
+	msr = mfmsr();
+	SET_MSR_EE(msr | MSR_EE);
+#endif
+}
+
+static inline void native_local_irq_save_ptr(unsigned long *flags)
+{
+	unsigned long msr;
+	msr = mfmsr();
+	*flags = msr;
+#ifdef CONFIG_BOOKE
+#ifdef CONFIG_KVM_GUEST
+	__asm__ __volatile__("wrtee %0": : "r"(0) :"memory");
+#else
+	__asm__ __volatile__("wrteei 0": : :"memory");
+#endif
+#else
+	SET_MSR_EE(msr & ~MSR_EE);
+#endif
+	__asm__ __volatile__("": : :"memory");
+}
+
+#define native_local_save_flags(flags)	((flags) = mfmsr())
+#define native_local_irq_save(flags)	native_local_irq_save_ptr(&flags)
+#define native_irqs_disabled()		((mfmsr() & MSR_EE) == 0)
+
+#define native_hard_irq_enable()	native_local_irq_enable()
+#define native_hard_irq_disable()	native_local_irq_disable()
+
+static inline int native_irqs_disabled_flags(unsigned long flags)
+{
+	return (flags & MSR_EE) == 0;
+}
+
+/* Hypervior specific implementation */
+#include <asm/pv_hw_irq.h>
+#endif /* CONFIG_PARAVIRT */
+
 /*
  * interrupt-retrigger: should we handle this via lost interrupts and IPIs
  * or should we not care like we do now ? --BenH.
diff --git a/arch/powerpc/include/asm/machdep.h b/arch/powerpc/include/asm/machdep.h
index de73b07..134682a 100644
--- a/arch/powerpc/include/asm/machdep.h
+++ b/arch/powerpc/include/asm/machdep.h
@@ -275,6 +275,10 @@ struct machdep_calls {
 	ssize_t (*cpu_probe)(const char *, size_t);
 	ssize_t (*cpu_release)(const char *, size_t);
 #endif
+
+#ifdef CONFIG_VIRTUALIZATION
+	int (*earlycon_setup)(void);
+#endif
 };
 
 extern void e500_idle(void);
@@ -373,5 +377,7 @@ static inline void log_error(char *buf, unsigned int err_type, int fatal)
 void generic_suspend_disable_irqs(void);
 void generic_suspend_enable_irqs(void);
 
+extern unsigned int get_pvr(void);
+
 #endif /* __KERNEL__ */
 #endif /* _ASM_POWERPC_MACHDEP_H */
diff --git a/arch/powerpc/include/asm/page_32.h b/arch/powerpc/include/asm/page_32.h
index bd0849d..9558b0c 100644
--- a/arch/powerpc/include/asm/page_32.h
+++ b/arch/powerpc/include/asm/page_32.h
@@ -13,7 +13,7 @@
 #define ARCH_KMALLOC_MINALIGN	L1_CACHE_BYTES
 #endif
 
-#ifdef CONFIG_PTE_64BIT
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_PARAVIRT)
 #define PTE_FLAGS_OFFSET	4	/* offset of PTE flags, in bytes */
 #else
 #define PTE_FLAGS_OFFSET	0
@@ -30,7 +30,7 @@
  * The basic type of a PTE - 64 bits for those CPUs with > 32 bit
  * physical addressing.
  */
-#ifdef CONFIG_PTE_64BIT
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_PARAVIRT)
 typedef unsigned long long pte_basic_t;
 #else
 typedef unsigned long pte_basic_t;
diff --git a/arch/powerpc/include/asm/pgalloc-32.h b/arch/powerpc/include/asm/pgalloc-32.h
index 580cf73..f1b14d2 100644
--- a/arch/powerpc/include/asm/pgalloc-32.h
+++ b/arch/powerpc/include/asm/pgalloc-32.h
@@ -20,7 +20,7 @@ extern void pgd_free(struct mm_struct *mm, pgd_t *pgd);
 #define __pmd_free_tlb(tlb,x,a)		do { } while (0)
 /* #define pgd_populate(mm, pmd, pte)      BUG() */
 
-#ifndef CONFIG_BOOKE
+#if !defined(CONFIG_BOOKE) || defined (CONFIG_PARAVIRT)
 #define pmd_populate_kernel(mm, pmd, pte)	\
 		(pmd_val(*(pmd)) = __pa(pte) | _PMD_PRESENT)
 #define pmd_populate(mm, pmd, pte)	\
diff --git a/arch/powerpc/include/asm/pgtable-ppc32.h b/arch/powerpc/include/asm/pgtable-ppc32.h
index 55646ad..f98fe3f 100644
--- a/arch/powerpc/include/asm/pgtable-ppc32.h
+++ b/arch/powerpc/include/asm/pgtable-ppc32.h
@@ -27,6 +27,11 @@ extern int icache_44x_need_flush;
  * are an index to the second level table.  The combined pgdir/pmd first
  * level has 2048 entries and the second level has 512 64-bit PTE entries.
  * -Matt
+ *
+ * For WRHV, the combined pgdir/pmd first level has 2 page 2048 entries
+ * and the second level has 9bit indexing into 512 elements with each element
+ * contains an 8-byte PTE
+ * -Yiming
  */
 /* PGDIR_SHIFT determines what a top-level page table entry can map */
 #define PGDIR_SHIFT	(PAGE_SHIFT + PTE_SHIFT)
@@ -107,13 +112,15 @@ extern int icache_44x_need_flush;
  * (hardware-defined) PowerPC PTE as closely as possible.
  */
 
-#if defined(CONFIG_40x)
+#if defined(CONFIG_PARAVIRT)
+#include <asm/pv_pgtable-ppc32.h>
+#elif defined(CONFIG_40x)
 #include <asm/pte-40x.h>
 #elif defined(CONFIG_44x)
 #include <asm/pte-44x.h>
 #elif defined(CONFIG_FSL_BOOKE) && defined(CONFIG_PTE_64BIT)
 #include <asm/pte-book3e.h>
-#elif defined(CONFIG_FSL_BOOKE)
+#elif defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT)
 #include <asm/pte-fsl-booke.h>
 #elif defined(CONFIG_8xx)
 #include <asm/pte-8xx.h>
@@ -164,7 +171,7 @@ extern void flush_hash_entry(struct mm_struct *mm, pte_t *ptep,
  * to properly flush the virtually tagged instruction cache of
  * those implementations.
  */
-#ifndef CONFIG_PTE_64BIT
+#if !defined(CONFIG_PTE_64BIT) && !defined(CONFIG_PARAVIRT)
 static inline unsigned long pte_update(pte_t *p,
 				       unsigned long clr,
 				       unsigned long set)
@@ -193,7 +200,7 @@ static inline unsigned long pte_update(pte_t *p,
 #endif
 	return old;
 }
-#else /* CONFIG_PTE_64BIT */
+#else /* CONFIG_PTE_64BIT && CONFIG_PARAVIRT */
 static inline unsigned long long pte_update(pte_t *p,
 					    unsigned long clr,
 					    unsigned long set)
@@ -224,13 +231,14 @@ static inline unsigned long long pte_update(pte_t *p,
 #endif
 	return old;
 }
-#endif /* CONFIG_PTE_64BIT */
+#endif /* CONFIG_PTE_64BIT && CONFIG_PARAVIRT */
 
 /*
  * 2.6 calls this without flushing the TLB entry; this is wrong
  * for our hash-based implementation, we fix that up here.
  */
 #define __HAVE_ARCH_PTEP_TEST_AND_CLEAR_YOUNG
+#ifndef CONFIG_PARAVIRT
 static inline int __ptep_test_and_clear_young(unsigned int context, unsigned long addr, pte_t *ptep)
 {
 	unsigned long old;
@@ -243,9 +251,29 @@ static inline int __ptep_test_and_clear_young(unsigned int context, unsigned lon
 #endif
 	return (old & _PAGE_ACCESSED) != 0;
 }
+#else /* CONFIG_PARAVIRT */
+static inline int __ptep_test_and_clear_young(mm_context_t * ctx,
+                                              unsigned long addr, pte_t *ptep)
+{
+	unsigned long old;
+	old = pte_update(ptep, _PAGE_ACCESSED, 0);
+#if _PAGE_HASHPTE != 0
+	if (old & _PAGE_HASHPTE) {
+		unsigned long ptephys = __pa(ptep) & PAGE_MASK;
+		flush_hash_pages(context, addr, ptephys, 1);
+	}
+#endif
+#if 0 
+        vbi_tlb_flush_vmmu (&vmmu_cfg, &addr, 1);
+#endif
+	return (old & _PAGE_ACCESSED) != 0;
+}
+#endif   /* CONFIG_PARAVIRT */
+
 #define ptep_test_and_clear_young(__vma, __addr, __ptep) \
 	__ptep_test_and_clear_young((__vma)->vm_mm->context.id, __addr, __ptep)
 
+
 #define __HAVE_ARCH_PTEP_GET_AND_CLEAR
 static inline pte_t ptep_get_and_clear(struct mm_struct *mm, unsigned long addr,
 				       pte_t *ptep)
@@ -283,7 +311,7 @@ static inline void __ptep_set_access_flags(pte_t *ptep, pte_t entry)
  * handler).  On everything else the pmd contains the physical address
  * of the pte page.  -- paulus
  */
-#ifndef CONFIG_BOOKE
+#if !defined(CONFIG_BOOKE) || defined(CONFIG_PARAVIRT)
 #define pmd_page_vaddr(pmd)	\
 	((unsigned long) __va(pmd_val(pmd) & PAGE_MASK))
 #define pmd_page(pmd)		\
diff --git a/arch/powerpc/include/asm/pgtable.h b/arch/powerpc/include/asm/pgtable.h
index 89f1587..b8cbbe2 100644
--- a/arch/powerpc/include/asm/pgtable.h
+++ b/arch/powerpc/include/asm/pgtable.h
@@ -88,7 +88,7 @@ extern void set_pte_at(struct mm_struct *mm, unsigned long addr, pte_t *ptep,
  * an horrible mess that I'm not going to try to clean up now but
  * I'm keeping it in one place rather than spread around
  */
-static inline void __set_pte_at(struct mm_struct *mm, unsigned long addr,
+static inline void native__set_pte_at(struct mm_struct *mm, unsigned long addr,
 				pte_t *ptep, pte_t pte, int percpu)
 {
 #if defined(CONFIG_PPC_STD_MMU_32) && defined(CONFIG_SMP) && !defined(CONFIG_PTE_64BIT)
@@ -146,6 +146,14 @@ static inline void __set_pte_at(struct mm_struct *mm, unsigned long addr,
 #endif
 }
 
+extern void paravirt__set_pte_at(struct mm_struct *mm, unsigned long addr, 
+				pte_t *ptep, pte_t pte, int percpu);
+
+static inline void __set_pte_at(struct mm_struct *mm, unsigned long addr, 
+				pte_t *ptep, pte_t pte, int percpu)
+{
+	paravirt__set_pte_at(mm, addr, ptep, pte, percpu);
+}
 
 #define __HAVE_ARCH_PTEP_SET_ACCESS_FLAGS
 extern int ptep_set_access_flags(struct vm_area_struct *vma, unsigned long address,
diff --git a/arch/powerpc/include/asm/processor.h b/arch/powerpc/include/asm/processor.h
index 221ba62..94e3fce 100644
--- a/arch/powerpc/include/asm/processor.h
+++ b/arch/powerpc/include/asm/processor.h
@@ -42,6 +42,12 @@
 
 #if defined(__KERNEL__) && defined(CONFIG_PPC32)
 
+#ifdef CONFIG_PARAVIRT
+extern int paravirt_enabled(void);
+#else
+#define paravirt_enabled()      0
+#endif
+
 extern int _chrp_type;
 
 #ifdef CONFIG_PPC_PREP
diff --git a/arch/powerpc/include/asm/pte-common.h b/arch/powerpc/include/asm/pte-common.h
index f2b3701..51f5eb6 100644
--- a/arch/powerpc/include/asm/pte-common.h
+++ b/arch/powerpc/include/asm/pte-common.h
@@ -78,7 +78,7 @@ extern unsigned long bad_call_to_PMD_PAGE_SIZE(void);
 /* The mask convered by the RPN must be a ULL on 32-bit platforms with
  * 64-bit PTEs
  */
-#if defined(CONFIG_PPC32) && defined(CONFIG_PTE_64BIT)
+#if defined(CONFIG_PPC32) && defined(CONFIG_PTE_64BIT) || (defined(CONFIG_PARAVIRT) && !defined(CONFIG_PPC85xx_VT_MODE))
 #define PTE_RPN_MAX	(1ULL << (64 - PTE_RPN_SHIFT))
 #define PTE_RPN_MASK	(~((1ULL<<PTE_RPN_SHIFT)-1))
 #else
diff --git a/arch/powerpc/include/asm/ptrace.h b/arch/powerpc/include/asm/ptrace.h
index 77bbc68..e90f8d2 100644
--- a/arch/powerpc/include/asm/ptrace.h
+++ b/arch/powerpc/include/asm/ptrace.h
@@ -133,7 +133,11 @@ do {									      \
 } while (0)
 #endif /* __powerpc64__ */
 
+#ifndef CONFIG_PARAVIRT
 #define arch_has_single_step()	(1)
+#else
+#define arch_has_single_step()	(0)
+#endif
 #define arch_has_block_step()	(!cpu_has_feature(CPU_FTR_601))
 #define ARCH_HAS_USER_SINGLE_STEP_INFO
 
diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 5572e86..7022b5f 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -13,6 +13,11 @@
 #include <linux/stringify.h>
 #include <asm/cputable.h>
 
+/* Pickup paravirt specific registers */
+#if defined (CONFIG_PARAVIRT)
+#include <asm/reg_paravirt.h>
+#endif
+
 /* Pickup Book E specific registers. */
 #if defined(CONFIG_BOOKE) || defined(CONFIG_40x)
 #include <asm/reg_booke.h>
diff --git a/arch/powerpc/include/asm/system.h b/arch/powerpc/include/asm/system.h
index a6297c6..216c89e 100644
--- a/arch/powerpc/include/asm/system.h
+++ b/arch/powerpc/include/asm/system.h
@@ -206,6 +206,10 @@ extern u32 booke_wdt_period;
 struct device_node;
 extern void note_scsi_host(struct device_node *, void *);
 
+#ifdef CONFIG_PARAVIRT
+#define prepare_arch_switch(next)      local_irq_disable()
+#endif
+
 extern struct task_struct *__switch_to(struct task_struct *,
 	struct task_struct *);
 #define switch_to(prev, next, last)	((last) = __switch_to((prev), (next)))
diff --git a/arch/powerpc/include/asm/wrhv.h b/arch/powerpc/include/asm/wrhv.h
index 275c203..fa3b4f0 100644
--- a/arch/powerpc/include/asm/wrhv.h
+++ b/arch/powerpc/include/asm/wrhv.h
@@ -28,5 +28,8 @@ extern int __init wrhv_earlycon_setup(void);
 
 extern unsigned long wrhv_cpu_freq;
 
+extern uint32_t service_handle;
+extern void get_hv_bsp_server_handle(void);
+extern int get_bsp_clock_freq(void);
 #endif /* CONFIG_WRHV */
 #endif /* __ASM_WRHV_H */
diff --git a/arch/powerpc/kernel/Makefile b/arch/powerpc/kernel/Makefile
index b7d4b19..daebb3e 100644
--- a/arch/powerpc/kernel/Makefile
+++ b/arch/powerpc/kernel/Makefile
@@ -61,6 +61,11 @@ obj-$(CONFIG_HIBERNATION)	+= swsusp.o suspend.o \
 				   swsusp_$(CONFIG_WORD_SIZE).o
 obj64-$(CONFIG_HIBERNATION)	+= swsusp_asm64.o
 obj-$(CONFIG_MODULES)		+= module.o module_$(CONFIG_WORD_SIZE).o
+
+ifeq ($(CONFIG_WRHV),y)
+obj-$(CONFIG_WRHV)              += wrhv_entry_32.o wrhv_misc_32.o
+endif
+
 obj-$(CONFIG_44x)		+= cpu_setup_44x.o
 obj-$(CONFIG_FSL_BOOKE)		+= cpu_setup_fsl_booke.o dbell.o
 obj-$(USE_IMMEDIATE)		+= immediate.o
@@ -69,7 +74,13 @@ extra-y				:= head_$(CONFIG_WORD_SIZE).o
 extra-$(CONFIG_PPC_BOOK3E_32)	:= head_new_booke.o
 extra-$(CONFIG_40x)		:= head_40x.o
 extra-$(CONFIG_44x)		:= head_44x.o
-extra-$(CONFIG_FSL_BOOKE)	:= head_fsl_booke.o
+
+ifeq ($(CONFIG_WRHV),y)
+extra-$(CONFIG_WRHV)            := head_wrhv.o
+else
+extra-$(CONFIG_FSL_BOOKE)       := head_fsl_booke.o
+endif
+
 extra-$(CONFIG_8xx)		:= head_8xx.o
 extra-y				+= vmlinux.lds
 
@@ -111,6 +122,9 @@ obj-$(CONFIG_FSL_EMB_PERF_EVENT_E500) += e500-pmu.o
 
 obj-$(CONFIG_8XX_MINIMAL_FPEMU) += softemu8xx.o
 
+obj-$(CONFIG_WRHV)		+= vbi/
+obj-$(CONFIG_PARAVIRT)         += paravirt.o
+
 ifneq ($(CONFIG_PPC_INDIRECT_IO),y)
 obj-y				+= iomap.o
 endif
diff --git a/arch/powerpc/kernel/entry_32.S b/arch/powerpc/kernel/entry_32.S
index 1175a85..5f7671b 100644
--- a/arch/powerpc/kernel/entry_32.S
+++ b/arch/powerpc/kernel/entry_32.S
@@ -32,8 +32,10 @@
 #include <asm/unistd.h>
 #include <asm/ftrace.h>
 
+#ifndef CONFIG_PARAVIRT
 #undef SHOW_SYSCALLS
 #undef SHOW_SYSCALLS_TASK
+#endif
 
 /*
  * MSR_KERNEL is > 0x10000 on 4xx/Book-E since it include MSR_CE.
@@ -44,6 +46,25 @@
 #define LOAD_MSR_KERNEL(r, x)	li r,(x)
 #endif
 
+/* native macros */
+#define ENABLE_MSR_EE  ori r10,r10,MSR_EE; SYNC; MTMSRD(r10);
+#define DISABLE_MSR_EE LOAD_MSR_KERNEL(r10,MSR_KERNEL); SYNC; MTMSRD(r10);
+
+/* paravirt overrides */
+#ifdef CONFIG_PARAVIRT
+#ifdef PARAVIRT_ENABLE_MSR_EE
+#undef ENABLE_MSR_EE
+#define ENABLE_MSR_EE PARAVIRT_ENABLE_MSR_EE
+#endif
+#endif
+
+#ifdef CONFIG_PARAVIRT
+#ifdef PARAVIRT_DISABLE_MSR_EE
+#undef DISABLE_MSR_EE
+#define DISABLE_MSR_EE PARAVIRT_DISABLE_MSR_EE
+#endif
+#endif
+
 #ifdef CONFIG_BOOKE
 	.globl	mcheck_transfer_to_handler
 mcheck_transfer_to_handler:
@@ -130,6 +151,13 @@ transfer_to_handler_full:
 
 	.globl	transfer_to_handler
 transfer_to_handler:
+#ifndef CONFIG_PARAVIRT
+	b       native_transfer_to_handler
+#else
+	b       paravirt_transfer_to_handler
+#endif
+	.globl  native_transfer_to_handler
+native_transfer_to_handler:
 	stw	r2,GPR2(r11)
 	stw	r12,_NIP(r11)
 	stw	r9,_MSR(r11)
@@ -144,7 +172,7 @@ transfer_to_handler:
 	beq	2f			/* if from user, fix up THREAD.regs */
 	addi	r11,r1,STACK_FRAME_OVERHEAD
 	stw	r11,PT_REGS(r12)
-#if defined(CONFIG_40x) || defined(CONFIG_BOOKE)
+#if defined(CONFIG_40x) || defined(CONFIG_BOOKE) && !defined(CONFIG_PARAVIRT)
 	/* Check to see if the dbcr0 register is set up to debug.  Use the
 	   internal debug mode bit to do this. */
 	lwz	r12,THREAD_DBCR0(r12)
@@ -331,6 +359,13 @@ syscall_dotrace_cont:
 	blrl			/* Call handler */
 	.globl	ret_from_syscall
 ret_from_syscall:
+#ifndef CONFIG_PARAVIRT
+	b       native_ret_from_syscall
+#else
+	b       paravirt_ret_from_syscall
+#endif 
+	.globl  native_ret_from_syscall
+native_ret_from_syscall:
 #ifdef SHOW_SYSCALLS
 	bl	do_show_syscall_exit
 #endif
@@ -365,7 +400,7 @@ syscall_exit_cont:
 	lwz	r3,GPR3(r1)
 1:
 #endif /* CONFIG_TRACE_IRQFLAGS */
-#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE)
+#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE) && !(CONFIG_PARAVIRT)
 	/* If the process has its own DBCR0 value, load it up.  The internal
 	   debug mode bit tells us that dbcr0 should be loaded. */
 	lwz	r0,THREAD+THREAD_DBCR0(r2)
@@ -434,7 +469,15 @@ syscall_dotrace:
 	REST_NVGPRS(r1)
 	b	syscall_dotrace_cont
 
+	.globl  syscall_exit_work
 syscall_exit_work:
+#ifndef CONFIG_PARAVIRT
+	b       native_syscall_exit_work
+#else
+	b       paravirt_syscall_exit_work
+#endif
+	.globl  native_syscall_exit_work
+native_syscall_exit_work:
 	andi.	r0,r9,_TIF_RESTOREALL
 	beq+	0f
 	REST_NVGPRS(r1)
@@ -638,6 +681,13 @@ handle_page_fault:
  * in arch/ppc/kernel/process.c
  */
 _GLOBAL(_switch)
+#ifndef CONFIG_PARAVIRT
+	b	native_switch
+#else
+	b	paravirt_switch
+#endif
+
+_GLOBAL(native_switch)
 	stwu	r1,-INT_FRAME_SIZE(r1)
 	mflr	r0
 	stw	r0,INT_FRAME_SIZE+4(r1)
@@ -784,9 +834,7 @@ ret_from_except:
 	 * can't change between when we test it and when we return
 	 * from the interrupt. */
 	/* Note: We don't bother telling lockdep about it */
-	LOAD_MSR_KERNEL(r10,MSR_KERNEL)
-	SYNC			/* Some chip revs have problems here... */
-	MTMSRD(r10)		/* disable interrupts */
+	DISABLE_MSR_EE
 
 	lwz	r3,_MSR(r1)	/* Returning to user mode? */
 	andi.	r0,r3,MSR_PR
@@ -800,7 +848,7 @@ user_exc_return:		/* r10 contains MSR_KERNEL here */
 	bne	do_work
 
 restore_user:
-#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE)
+#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE) && !defined(CONFIG_PARAVIRT)
 	/* Check whether this process has its own DBCR0 value.  The internal
 	   debug mode bit tells us that dbcr0 should be loaded. */
 	lwz	r0,THREAD+THREAD_DBCR0(r2)
@@ -847,6 +895,13 @@ resume_kernel:
 
 	/* interrupts are hard-disabled at this point */
 restore:
+#ifndef CONFIG_PARAVIRT
+	b       native_restore
+#else
+	b       paravirt_restore
+#endif
+
+native_restore:
 #ifdef CONFIG_44x
 	lis	r4,icache_44x_need_flush@ha
 	lwz	r5,icache_44x_need_flush@l(r4)
@@ -1150,18 +1205,14 @@ do_resched:			/* r10 contains MSR_KERNEL here */
 	/* Note: We don't need to inform lockdep that we are enabling
 	 * interrupts here. As far as it knows, they are already enabled
 	 */
-	ori	r10,r10,MSR_EE
-	SYNC
-	MTMSRD(r10)		/* hard-enable interrupts */
+	ENABLE_MSR_EE
 	bl	schedule
 recheck:
 	/* Note: And we don't tell it we are disabling them again
 	 * neither. Those disable/enable cycles used to peek at
 	 * TI_FLAGS aren't advertised.
 	 */
-	LOAD_MSR_KERNEL(r10,MSR_KERNEL)
-	SYNC
-	MTMSRD(r10)		/* disable interrupts */
+	DISABLE_MSR_EE
 	rlwinm	r9,r1,0,0,(31-THREAD_SHIFT)
 	lwz	r9,TI_FLAGS(r9)
 	andi.	r0,r9,_TIF_NEED_RESCHED
@@ -1169,9 +1220,7 @@ recheck:
 	andi.	r0,r9,_TIF_USER_WORK_MASK
 	beq	restore_user
 do_user_signal:			/* r10 contains MSR_KERNEL here */
-	ori	r10,r10,MSR_EE
-	SYNC
-	MTMSRD(r10)		/* hard-enable interrupts */
+	ENABLE_MSR_EE
 	/* save r13-r31 in the exception frame, if not already done */
 	lwz	r3,_TRAP(r1)
 	andi.	r0,r3,1
diff --git a/arch/powerpc/kernel/head_booke.h b/arch/powerpc/kernel/head_booke.h
index a9dc7b8..13603d6 100644
--- a/arch/powerpc/kernel/head_booke.h
+++ b/arch/powerpc/kernel/head_booke.h
@@ -77,7 +77,7 @@
 
 #define EXC_LVL_FRAME_OVERHEAD	(THREAD_SIZE - INT_FRAME_SIZE - EXC_LVL_SIZE)
 
-#ifdef CONFIG_SMP
+#if defined(CONFIG_SMP) && !defined(CONFIG_PARAVIRT) 
 #define BOOKE_LOAD_EXC_LEVEL_STACK(level)		\
 	mfspr	r8,SPRN_PIR;				\
 	slwi	r8,r8,2;				\
diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index dd94248..1b797cd 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -315,7 +315,7 @@ void fixup_irqs(cpumask_t map)
 #endif
 
 #ifdef CONFIG_IRQSTACKS
-static inline void handle_one_irq(unsigned int irq)
+inline void handle_one_irq(unsigned int irq)
 {
 	struct thread_info *curtp, *irqtp;
 	unsigned long saved_sp_limit;
@@ -356,13 +356,13 @@ static inline void handle_one_irq(unsigned int irq)
 		set_bits(irqtp->flags, &curtp->flags);
 }
 #else
-static inline void handle_one_irq(unsigned int irq)
+inline void handle_one_irq(unsigned int irq)
 {
 	generic_handle_irq(irq);
 }
 #endif
 
-static inline void check_stack_overflow(void)
+inline void check_stack_overflow(void)
 {
 #ifdef CONFIG_DEBUG_STACKOVERFLOW
 	long sp;
@@ -378,8 +378,20 @@ static inline void check_stack_overflow(void)
 #endif
 }
 
+#ifdef CONFIG_WRHV
+EXPORT_SYMBOL(handle_one_irq);
+EXPORT_SYMBOL(check_stack_overflow);
+#endif
+
+void paravirt_do_IRQ(struct pt_regs *regs) __attribute__((weak, alias("native_do_IRQ")));
+
 void do_IRQ(struct pt_regs *regs)
 {
+	paravirt_do_IRQ(regs);  
+}
+
+void native_do_IRQ(struct pt_regs *regs)
+{
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	unsigned int irq;
 
@@ -806,7 +818,10 @@ unsigned int irq_create_of_mapping(struct device_node *controller,
 }
 EXPORT_SYMBOL_GPL(irq_create_of_mapping);
 
-unsigned int irq_of_parse_and_map(struct device_node *dev, int index)
+unsigned int paravirt_irq_of_parse_and_map(struct device_node *dev, int index)
+        __attribute__((weak, alias("native_irq_of_parse_and_map")));
+
+unsigned int native_irq_of_parse_and_map(struct device_node *dev, int index)
 {
 	struct of_irq oirq;
 
@@ -816,6 +831,11 @@ unsigned int irq_of_parse_and_map(struct device_node *dev, int index)
 	return irq_create_of_mapping(oirq.controller, oirq.specifier,
 				     oirq.size);
 }
+
+unsigned int irq_of_parse_and_map(struct device_node *dev, int index)
+{
+	return paravirt_irq_of_parse_and_map(dev, index);
+}
 EXPORT_SYMBOL_GPL(irq_of_parse_and_map);
 
 void irq_dispose_mapping(unsigned int virq)
diff --git a/arch/powerpc/kernel/kgdb.c b/arch/powerpc/kernel/kgdb.c
index 82a7b22..6f9557a 100644
--- a/arch/powerpc/kernel/kgdb.c
+++ b/arch/powerpc/kernel/kgdb.c
@@ -319,7 +319,12 @@ void kgdb_arch_set_pc(struct pt_regs *regs, unsigned long pc)
 /*
  * This function does PowerPC specific procesing for interfacing to gdb.
  */
-int kgdb_arch_handle_exception(int vector, int signo, int err_code,
+int paravirt_kgdb_arch_handle_exception(int vector, int signo, int err_code,
+                               char *remcom_in_buffer, char *remcom_out_buffer,
+                               struct pt_regs *linux_regs) __attribute__
+			((weak, alias("native_kgdb_arch_handle_exception")));
+
+int native_kgdb_arch_handle_exception(int vector, int signo, int err_code,
 			       char *remcom_in_buffer, char *remcom_out_buffer,
 			       struct pt_regs *linux_regs)
 {
@@ -357,6 +362,15 @@ int kgdb_arch_handle_exception(int vector, int signo, int err_code,
 	return -1;
 }
 
+int kgdb_arch_handle_exception(int vector, int signo, int err_code,
+			       char *remcom_in_buffer, char *remcom_out_buffer,
+			       struct pt_regs *linux_regs)
+{
+	return paravirt_kgdb_arch_handle_exception(vector, signo, err_code,
+					remcom_in_buffer, remcom_out_buffer,
+					linux_regs);	
+}
+
 /*
  * Global data
  */
diff --git a/arch/powerpc/kernel/misc_32.S b/arch/powerpc/kernel/misc_32.S
index 88ebaec..6fde005 100644
--- a/arch/powerpc/kernel/misc_32.S
+++ b/arch/powerpc/kernel/misc_32.S
@@ -327,6 +327,12 @@ END_FTR_SECTION_IFSET(CPU_FTR_UNIFIED_ID_CACHE)
  * flush_icache_range(unsigned long start, unsigned long stop)
  */
 _KPROBE(__flush_icache_range)
+#ifndef CONFIG_PARAVIRT
+	b	native__flush_icache_range
+#else
+	b	paravirt__flush_icache_range
+#endif
+_KPROBE(native__flush_icache_range)
 BEGIN_FTR_SECTION
 	blr				/* for 601, do nothing */
 END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
@@ -364,6 +370,12 @@ END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
  * clean_dcache_range(unsigned long start, unsigned long stop)
  */
 _GLOBAL(clean_dcache_range)
+#ifndef CONFIG_PARAVIRT
+        b       native_clean_dcache_range
+#else
+        b       paravirt_clean_dcache_range
+#endif
+_GLOBAL(native_clean_dcache_range)
 	li	r5,L1_CACHE_BYTES-1
 	andc	r3,r3,r5
 	subf	r4,r3,r4
@@ -385,6 +397,12 @@ _GLOBAL(clean_dcache_range)
  * flush_dcache_range(unsigned long start, unsigned long stop)
  */
 _GLOBAL(flush_dcache_range)
+#ifndef CONFIG_PARAVIRT
+	b	native_flush_dcache_range
+#else
+	b	paravirt_flush_dcache_range
+#endif
+_GLOBAL(native_flush_dcache_range)
 	li	r5,L1_CACHE_BYTES-1
 	andc	r3,r3,r5
 	subf	r4,r3,r4
@@ -430,6 +448,12 @@ _GLOBAL(invalidate_dcache_range)
  *	void __flush_dcache_icache(void *page)
  */
 _GLOBAL(__flush_dcache_icache)
+#ifndef CONFIG_PARAVIRT
+	b	native__flush_dcache_icache
+#else
+	b	paravirt__flush_dcache_icache
+#endif
+_GLOBAL(native__flush_dcache_icache)
 BEGIN_FTR_SECTION
 	blr
 END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
@@ -467,6 +491,12 @@ END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
  *	void __flush_dcache_icache_phys(unsigned long physaddr)
  */
 _GLOBAL(__flush_dcache_icache_phys)
+#ifndef CONFIG_PARAVIRT
+	b	native__flush_dcache_icache_phys
+#else
+	b	paravirt__flush_dcache_icache_phys
+#endif
+_GLOBAL(native__flush_dcache_icache_phys)
 BEGIN_FTR_SECTION
 	blr					/* for 601, do nothing */
 END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
diff --git a/arch/powerpc/kernel/module.c b/arch/powerpc/kernel/module.c
index 477c663..987b251 100644
--- a/arch/powerpc/kernel/module.c
+++ b/arch/powerpc/kernel/module.c
@@ -26,6 +26,7 @@
 #include <asm/uaccess.h>
 #include <asm/firmware.h>
 #include <linux/sort.h>
+#include <linux/slab.h>
 
 #include "setup.h"
 
@@ -36,13 +37,21 @@ void *module_alloc(unsigned long size)
 	if (size == 0)
 		return NULL;
 
+#if defined(CONFIG_WRHV) && defined(CONFIG_PPC)
+	return kmalloc(size, GFP_KERNEL);
+#else
 	return vmalloc_exec(size);
+#endif
 }
 
 /* Free memory returned from module_alloc */
 void module_free(struct module *mod, void *module_region)
 {
+#if defined(CONFIG_WRHV) && defined(CONFIG_PPC)
+	kfree(module_region);
+#else
 	vfree(module_region);
+#endif
 }
 
 static const Elf_Shdr *find_section(const Elf_Ehdr *hdr,
diff --git a/arch/powerpc/kernel/paravirt.c b/arch/powerpc/kernel/paravirt.c
index 50939cc..ae9e98c 100644
--- a/arch/powerpc/kernel/paravirt.c
+++ b/arch/powerpc/kernel/paravirt.c
@@ -52,8 +52,6 @@
 #include <linux/backlight.h> 
 #include <linux/bug.h>
 #include <linux/kdebug.h>
-#include <linux/ltt-core.h>
-#include <trace/trap.h>
 #include <linux/kallsyms.h> 
 
 #include <mm/mmu_decl.h>
diff --git a/arch/powerpc/kernel/process.c b/arch/powerpc/kernel/process.c
index 08fd668..0d4c2f7 100644
--- a/arch/powerpc/kernel/process.c
+++ b/arch/powerpc/kernel/process.c
@@ -192,6 +192,26 @@ void flush_vsx_to_thread(struct task_struct *tsk)
 
 #ifdef CONFIG_SPE
 
+#ifdef CONFIG_PARAVIRT
+/* refer to native implementation in
+ * linux/arch/powerpc/kernel/head_fsl_booke.S
+ */
+void giveup_spe(struct task_struct *tsk)
+{
+	/* if no previous owner, done */
+	if (!tsk){
+                return;
+        }
+
+        /* disable SPE for previous task */
+        tsk->thread.regs->msr &= ~MSR_SPE;
+
+#ifndef CONFIG_SMP
+        last_task_used_spe = 0;
+#endif /* CONFIG_SMP */
+}
+#endif
+
 void enable_kernel_spe(void)
 {
 	WARN_ON(preemptible());
diff --git a/arch/powerpc/kernel/prom.c b/arch/powerpc/kernel/prom.c
index 05131d6..d17d45b 100644
--- a/arch/powerpc/kernel/prom.c
+++ b/arch/powerpc/kernel/prom.c
@@ -479,7 +479,11 @@ static int __init early_init_dt_scan_drconf_memory(unsigned long node)
 #define early_init_dt_scan_drconf_memory(node)	0
 #endif /* CONFIG_PPC_PSERIES */
 
-static int __init early_init_dt_scan_memory_ppc(unsigned long node,
+int paravirt_early_init_dt_scan_memory_ppc(unsigned long node,
+			const char *uname, int depth, void *data)
+	__attribute__((weak, alias("native_early_init_dt_scan_memory_ppc")));
+
+int __init native_early_init_dt_scan_memory_ppc(unsigned long node,
 						const char *uname,
 						int depth, void *data)
 {
@@ -490,6 +494,13 @@ static int __init early_init_dt_scan_memory_ppc(unsigned long node,
 	return early_init_dt_scan_memory(node, uname, depth, data);
 }
 
+static int __init early_init_dt_scan_memory_ppc(unsigned long node,
+						const char *uname,
+						int depth, void *data)
+{
+	return  paravirt_early_init_dt_scan_memory_ppc(node, uname, depth, data);
+}
+
 void __init early_init_dt_add_memory_arch(u64 base, u64 size)
 {
 #if defined(CONFIG_PPC64)
diff --git a/arch/powerpc/kernel/setup-common.c b/arch/powerpc/kernel/setup-common.c
index 48f0a00..94cdaf0 100644
--- a/arch/powerpc/kernel/setup-common.c
+++ b/arch/powerpc/kernel/setup-common.c
@@ -161,6 +161,17 @@ extern u32 cpu_temp_both(unsigned long cpu);
 DEFINE_PER_CPU(unsigned int, cpu_pvr);
 #endif
 
+unsigned paravirt_get_pvr(void) __attribute__((weak, alias("native_get_pvr")));
+unsigned int native_get_pvr(void)
+{
+	return mfspr(SPRN_PVR);
+}
+
+unsigned int get_pvr(void)
+{
+	return paravirt_get_pvr();
+}
+
 static int show_cpuinfo(struct seq_file *m, void *v)
 {
 	unsigned long cpu_id = (unsigned long)v - 1;
@@ -209,11 +220,15 @@ static int show_cpuinfo(struct seq_file *m, void *v)
 		return 0;
 	}
 
+#ifdef CONFIG_PARAVIRT
+	pvr = get_pvr();
+#else
 #ifdef CONFIG_SMP
 	pvr = per_cpu(cpu_pvr, cpu_id);
 #else
 	pvr = mfspr(SPRN_PVR);
 #endif
+#endif /* CONFIG_PARAVIRT */
 	maj = (pvr >> 8) & 0xFF;
 	min = pvr & 0xFF;
 
diff --git a/arch/powerpc/kernel/setup_32.c b/arch/powerpc/kernel/setup_32.c
index 8f58986..7116179 100644
--- a/arch/powerpc/kernel/setup_32.c
+++ b/arch/powerpc/kernel/setup_32.c
@@ -78,6 +78,10 @@ int ucache_bsize;
  * from the address that it was linked at, so we must use RELOC/PTRRELOC
  * to access static data (including strings).  -- paulus
  */
+#ifdef CONFIG_PARAVIRT
+extern void paravirt_init(void);
+#endif
+
 notrace unsigned long __init early_init(unsigned long dt_ptr)
 {
 	unsigned long offset = reloc_offset();
@@ -87,12 +91,19 @@ notrace unsigned long __init early_init(unsigned long dt_ptr)
 	 * caches on yet */
 	memset_io((void __iomem *)PTRRELOC(&__bss_start), 0,
 			__bss_stop - __bss_start);
+	
+	/* 
+	 * initialize paravirtual operations 
+	 */
+#ifdef CONFIG_PARAVIRT
+	paravirt_init();
+#endif
 
 	/*
 	 * Identify the CPU type and fix up code sections
 	 * that depend on which cpu we have.
 	 */
-	spec = identify_cpu(offset, mfspr(SPRN_PVR));
+	spec = identify_cpu(offset, get_pvr());
 
 	do_feature_fixups(spec->cpu_features,
 			  PTRRELOC(&__start___ftr_fixup),
@@ -136,7 +147,7 @@ notrace void __init machine_init(unsigned long dt_ptr)
 		ppc_md.power_save = ppc6xx_idle;
 #endif
 
-#ifdef CONFIG_E500
+#if defined(CONFIG_E500) && !defined(CONFIG_PARAVIRT)
 	if (cpu_has_feature(CPU_FTR_CAN_DOZE) ||
 	    cpu_has_feature(CPU_FTR_CAN_NAP))
 		ppc_md.power_save = e500_idle;
@@ -295,6 +306,11 @@ void __init setup_arch(char **cmdline_p)
 	if (ppc_md.init_early)
 		ppc_md.init_early();
 
+	/* give an opporunity for special legacy serial or
+	   other setup to be run */
+	if (ppc_md.earlycon_setup)
+		ppc_md.earlycon_setup();
+
 	find_legacy_serial_ports();
 
 	smp_setup_cpu_maps();
diff --git a/arch/powerpc/kernel/smp.c b/arch/powerpc/kernel/smp.c
index c2ee144..642687b 100644
--- a/arch/powerpc/kernel/smp.c
+++ b/arch/powerpc/kernel/smp.c
@@ -235,7 +235,7 @@ struct thread_info *current_set[NR_CPUS];
 
 static void __devinit smp_store_cpu_info(int id)
 {
-	per_cpu(cpu_pvr, id) = mfspr(SPRN_PVR);
+	per_cpu(cpu_pvr, id) = get_pvr();
 }
 
 static void __init smp_create_idle(unsigned int cpu)
diff --git a/arch/powerpc/kernel/time.c b/arch/powerpc/kernel/time.c
index 14ee644..4800525 100644
--- a/arch/powerpc/kernel/time.c
+++ b/arch/powerpc/kernel/time.c
@@ -602,7 +602,15 @@ void set_perf_event_pending(void)
  * timer_interrupt - gets called when the decrementer overflows,
  * with interrupts disabled.
  */
-void timer_interrupt(struct pt_regs * regs)
+void paravirt_timer_interrupt(struct pt_regs *regs)
+	__attribute__((weak, alias("native_timer_interrupt")));
+
+void timer_interrupt(struct pt_regs *regs)
+{
+	paravirt_timer_interrupt(regs);
+}
+
+void native_timer_interrupt(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs;
 	struct decrementer_clock *decrementer =  &__get_cpu_var(decrementers);
@@ -783,7 +791,7 @@ static int __init get_freq(char *name, int cells, unsigned long *val)
 /* should become __cpuinit when secondary_cpu_time_init also is */
 void start_cpu_decrementer(void)
 {
-#if defined(CONFIG_BOOKE) || defined(CONFIG_40x)
+#if (defined(CONFIG_BOOKE) || defined(CONFIG_40x)) && !defined(CONFIG_WRHV)
 	/* Clear any pending timer interrupts */
 	mtspr(SPRN_TSR, TSR_ENW | TSR_WIS | TSR_DIS | TSR_FIS);
 
@@ -910,7 +918,15 @@ void update_vsyscall_tz(void)
 	++vdso_data->tb_update_count;
 }
 
-static void __init clocksource_init(void)
+void paravirt_clocksource_init(void)
+	__attribute__((weak, alias("native_clocksource_init")));
+
+void __init clocksource_init(void)
+{
+	paravirt_clocksource_init();
+}
+
+void __init native_clocksource_init(void)
 {
 	struct clocksource *clock;
 
@@ -1009,6 +1025,23 @@ void secondary_cpu_time_init(void)
 	register_decrementer_clockevent(smp_processor_id());
 }
 
+/* time_init() is seperate into two parts, the first part is common to
+ * native and paravirtual target. The 2nd part, time_init_cont is target
+ * specific init
+ */
+void paravirt_time_init_cont(void)
+	__attribute__((weak, alias("native_time_init_cont")));
+
+void __init time_init_cont(void)
+{
+	paravirt_time_init_cont();
+}
+
+void __init native_time_init_cont(void)
+{
+	init_decrementer_clockevent();
+}
+
 /* This function is only called on the boot processor */
 void __init time_init(void)
 {
@@ -1117,7 +1150,8 @@ void __init time_init(void)
 	if (!firmware_has_feature(FW_FEATURE_ISERIES))
 		clocksource_init();
 
-	init_decrementer_clockevent();
+	/* continue with native or paravirtual specific time_init */
+	time_init_cont();
 }
 
 
diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 398c3ba..3286e6d 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -769,7 +769,15 @@ static int emulate_instruction(struct pt_regs *regs)
 	if ((instword & PPC_INST_MFSPR_PVR_MASK) == PPC_INST_MFSPR_PVR) {
 		PPC_WARN_EMULATED(mfpvr, regs);
 		rd = (instword >> 21) & 0x1f;
+#ifndef CONFIG_WRHV
 		regs->gpr[rd] = mfspr(SPRN_PVR);
+#else
+		/* 
+		 * PVR for wrhv hypervisor should be 0x80200000,
+		 * why is it 0x80200010?
+		 */
+		regs->gpr[rd] = 0x80200010;
+#endif
 		return 0;
 	}
 
@@ -1110,7 +1118,10 @@ static void handle_debug(struct pt_regs *regs, unsigned long debug_status)
 		mtspr(SPRN_DBCR0, current->thread.dbcr0);
 }
 
-void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
+void paravirt_DebugException(struct pt_regs *regs, unsigned long debug_status)
+	 __attribute__((weak, alias("native_DebugException")));
+
+void __kprobes native_DebugException(struct pt_regs *regs, unsigned long debug_status)
 {
 	current->thread.dbsr = debug_status;
 
@@ -1173,6 +1184,11 @@ void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 	} else
 		handle_debug(regs, debug_status);
 }
+
+void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
+{
+	paravirt_DebugException(regs, debug_status);
+}
 #endif /* CONFIG_PPC_ADV_DEBUG_REGS */
 
 #if !defined(CONFIG_TAU_INT)
diff --git a/arch/powerpc/kvm/Kconfig b/arch/powerpc/kvm/Kconfig
index 60624cc..60e1505 100644
--- a/arch/powerpc/kvm/Kconfig
+++ b/arch/powerpc/kvm/Kconfig
@@ -16,6 +16,29 @@ menuconfig VIRTUALIZATION
 
 if VIRTUALIZATION
 
+config PARAVIRT
+        bool "Enable paravirtualization code"
+        default y
+        depends on !X86_VOYAGER
+        help
+          This changes the kernel so it can modify itself when it is run
+          under a hypervisor, potentially improving performance significantly
+          over full virtualization.  However, when run without a hypervisor
+          the kernel is theoretically slower and slightly larger.
+
+          CONFIG_PARAVIRT assume a E500 like core and use 64 bit PTE.
+
+config PARAVIRT_CLOCK
+        bool
+        default n
+
+config PARAVIRT_DEBUG
+       bool "paravirt-ops debugging"
+       depends on PARAVIRT && DEBUG_KERNEL
+       help
+         Enable to debug paravirt_ops internals.  Specifically, BUG if
+         a paravirt_op is missing when it is called.
+
 config KVM
 	bool
 	select PREEMPT_NOTIFIERS
diff --git a/arch/powerpc/mm/fault.c b/arch/powerpc/mm/fault.c
index dcc1720..abb333e 100644
--- a/arch/powerpc/mm/fault.c
+++ b/arch/powerpc/mm/fault.c
@@ -69,6 +69,24 @@ static inline int notify_page_fault(struct pt_regs *regs)
 #endif
 
 /*
+ * this function restore mmu for paravirt operations,
+ * default native operation is noop
+ */
+void paravirt_vmmu_restore(void) __attribute__((weak, alias("native_vmmu_restore")));
+
+void native_vmmu_restore(void)
+{
+	/* default is noop */
+	return;
+}
+
+void vmmu_restore (void)
+{
+	paravirt_vmmu_restore();
+	return;
+}
+
+/*
  * Check whether the instruction at regs->nip is a store using
  * an update addressing form which will update r1.
  */
@@ -348,6 +366,7 @@ bad_area_nosemaphore:
 	/* User mode accesses cause a SIGSEGV */
 	if (user_mode(regs)) {
 		_exception(SIGSEGV, regs, code, address);
+		vmmu_restore ();
 		return 0;
 	}
 
@@ -383,6 +402,7 @@ do_sigbus:
 		info.si_code = BUS_ADRERR;
 		info.si_addr = (void __user *)address;
 		force_sig_info(SIGBUS, &info, current);
+		vmmu_restore ();
 		return 0;
 	}
 	return SIGBUS;
diff --git a/arch/powerpc/mm/fsl_booke_mmu.c b/arch/powerpc/mm/fsl_booke_mmu.c
index 1ed6b52..04f90cd 100644
--- a/arch/powerpc/mm/fsl_booke_mmu.c
+++ b/arch/powerpc/mm/fsl_booke_mmu.c
@@ -202,19 +202,36 @@ unsigned long map_mem_in_cams(unsigned long ram, int max_cam_idx)
 	return amount_mapped;
 }
 
-unsigned long __init mmu_mapin_ram(unsigned long top)
+unsigned long paravirt_mmu_mapin_ram(unsigned long top) 
+	__attribute__((weak, alias("native_mmu_mapin_ram")));
+
+unsigned long native_mmu_mapin_ram(unsigned long top)
 {
 	return tlbcam_addrs[tlbcam_index - 1].limit - PAGE_OFFSET + 1;
 }
 
+unsigned long __init mmu_mapin_ram(unsigned long top)
+{
+	return paravirt_mmu_mapin_ram(top);
+}
+
 /*
  * MMU_init_hw does the chip-specific initialization of the MMU hardware.
  */
-void __init MMU_init_hw(void)
+
+void paravirt_MMU_init_hw(void) 
+	__attribute__((weak, alias("native_MMU_init_hw")));
+
+void __init native_MMU_init_hw(void)
 {
 	flush_instruction_cache();
 }
 
+void __init MMU_init_hw(void)
+{
+	paravirt_MMU_init_hw();
+}
+
 void __init adjust_total_lowmem(void)
 {
 	unsigned long ram;
diff --git a/arch/powerpc/mm/init_32.c b/arch/powerpc/mm/init_32.c
index 7673330..591178d 100644
--- a/arch/powerpc/mm/init_32.c
+++ b/arch/powerpc/mm/init_32.c
@@ -100,7 +100,10 @@ phys_addr_t __initial_memory_limit_addr = (phys_addr_t)0x10000000;
 /*
  * Check for command-line options that affect what MMU_init will do.
  */
-void MMU_setup(void)
+void paravirt_MMU_setup(void) 
+	__attribute__((weak, alias("native_MMU_setup")));
+
+void native_MMU_setup(void)
 {
 	/* Check for nobats option (used in mapin_ram). */
 	if (strstr(cmd_line, "nobats")) {
@@ -116,12 +119,20 @@ void MMU_setup(void)
 #endif
 }
 
+void MMU_setup(void)
+{
+	paravirt_MMU_setup();
+}
+
 /*
  * MMU_init sets up the basic memory mappings for the kernel,
  * including both RAM and possibly some I/O regions,
  * and sets up the page tables and the MMU hardware ready to go.
  */
-void __init MMU_init(void)
+void paravirt_MMU_init(void) 
+	__attribute__((weak, alias("native_MMU_init")));
+
+void __init native_MMU_init(void)
 {
 	if (ppc_md.progress)
 		ppc_md.progress("MMU:enter", 0x111);
@@ -149,12 +160,12 @@ void __init MMU_init(void)
 	total_lowmem = total_memory = lmb_end_of_DRAM() - memstart_addr;
 	lowmem_end_addr = memstart_addr + total_lowmem;
 
-#ifdef CONFIG_FSL_BOOKE
+#if defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT)
 	/* Freescale Book-E parts expect lowmem to be mapped by fixed TLB
 	 * entries, so we need to adjust lowmem to match the amount we can map
 	 * in the fixed entries */
 	adjust_total_lowmem();
-#endif /* CONFIG_FSL_BOOKE */
+#endif /* CONFIG_FSL_BOOKE && !defined(CONFIG_PARAVIRT) */
 
 	if (total_lowmem > __max_low_memory) {
 		total_lowmem = __max_low_memory;
@@ -192,6 +203,11 @@ void __init MMU_init(void)
 #endif
 }
 
+void __init MMU_init(void)
+{
+	paravirt_MMU_init();
+}
+
 /* This is only called until mem_init is done. */
 void __init *early_get_page(void)
 {
diff --git a/arch/powerpc/mm/mem.c b/arch/powerpc/mm/mem.c
index 0f594d7..748eaa5 100644
--- a/arch/powerpc/mm/mem.c
+++ b/arch/powerpc/mm/mem.c
@@ -413,7 +413,11 @@ void __init mem_init(void)
  * It just marks the page as not i-cache clean.  We do the i-cache
  * flush later when the page is given to a user process, if necessary.
  */
-void flush_dcache_page(struct page *page)
+
+void paravirt_flush_dcache_page(struct page *page) 
+               __attribute__((weak, alias("native_flush_dcache_page")));
+
+void native_flush_dcache_page(struct page *page)
 {
 	if (cpu_has_feature(CPU_FTR_COHERENT_ICACHE))
 		return;
@@ -421,6 +425,11 @@ void flush_dcache_page(struct page *page)
 	if (test_bit(PG_arch_1, &page->flags))
 		clear_bit(PG_arch_1, &page->flags);
 }
+
+void flush_dcache_page(struct page *page)
+{
+	paravirt_flush_dcache_page(page);
+}
 EXPORT_SYMBOL(flush_dcache_page);
 
 void flush_dcache_icache_page(struct page *page)
diff --git a/arch/powerpc/mm/mmu_decl.h b/arch/powerpc/mm/mmu_decl.h
index d49a775..2973434 100644
--- a/arch/powerpc/mm/mmu_decl.h
+++ b/arch/powerpc/mm/mmu_decl.h
@@ -137,7 +137,12 @@ extern void wii_memory_fixups(void);
 /* ...and now those things that may be slightly different between processor
  * architectures.  -- Dan
  */
-#if defined(CONFIG_8xx)
+#if defined(CONFIG_PARAVIRT)
+
+extern void MMU_init_hw(void);
+extern unsigned long mmu_mapin_ram(unsigned long top);
+
+#elif defined(CONFIG_8xx)
 #define MMU_init_hw()		do { } while(0)
 #define mmu_mapin_ram(top)	(0UL)
 
@@ -145,7 +150,7 @@ extern void wii_memory_fixups(void);
 extern void MMU_init_hw(void);
 extern unsigned long mmu_mapin_ram(unsigned long top);
 
-#elif defined(CONFIG_FSL_BOOKE)
+#elif defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT)
 extern void MMU_init_hw(void);
 extern unsigned long mmu_mapin_ram(unsigned long top);
 extern void adjust_total_lowmem(void);
diff --git a/arch/powerpc/mm/pgtable_32.c b/arch/powerpc/mm/pgtable_32.c
index b9243e7..e1a6ec2 100644
--- a/arch/powerpc/mm/pgtable_32.c
+++ b/arch/powerpc/mm/pgtable_32.c
@@ -44,7 +44,7 @@ EXPORT_SYMBOL(ioremap_bot);	/* aka VMALLOC_END */
 #define HAVE_BATS	1
 #endif
 
-#if defined(CONFIG_FSL_BOOKE)
+#if defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT)
 #define HAVE_TLBCAM	1
 #endif
 
@@ -150,12 +150,24 @@ ioremap_flags(phys_addr_t addr, unsigned long size, unsigned long flags)
 }
 EXPORT_SYMBOL(ioremap_flags);
 
-void __iomem *
-__ioremap(phys_addr_t addr, unsigned long size, unsigned long flags)
+void __iomem * paravirt___ioremap(phys_addr_t addr, unsigned long size, unsigned long flags)
+               __attribute__((weak, alias("native___ioremap")));
+
+/* Native __ioremap implementation. For paravirt version please 
+ * refer to arch/powerpc/kernel/vbi/wrhv.c 
+ */
+void __iomem * 
+native___ioremap(phys_addr_t addr, unsigned long size, unsigned long flags)
 {
 	return __ioremap_caller(addr, size, flags, __builtin_return_address(0));
 }
 
+void __iomem * 
+__ioremap(phys_addr_t addr, unsigned long size, unsigned long flags) 
+{
+	return paravirt___ioremap(addr, size, flags);
+}
+
 void __iomem *
 __ioremap_caller(phys_addr_t addr, unsigned long size, unsigned long flags,
 		 void *caller)
@@ -262,7 +274,10 @@ void iounmap(volatile void __iomem *addr)
 }
 EXPORT_SYMBOL(iounmap);
 
-int map_page(unsigned long va, phys_addr_t pa, int flags)
+int paravirt_map_page(unsigned long, phys_addr_t, int) 
+	__attribute__((weak, alias("native_map_page")));
+
+int native_map_page(unsigned long va, phys_addr_t pa, int flags)
 {
 	pmd_t *pd;
 	pte_t *pg;
@@ -285,6 +300,15 @@ int map_page(unsigned long va, phys_addr_t pa, int flags)
 	return err;
 }
 
+int map_page(unsigned long va, phys_addr_t pa, int flags)
+{
+	return paravirt_map_page(va, pa, flags);
+}
+
+#ifdef CONFIG_PARAVIRT
+EXPORT_SYMBOL(map_page);
+#endif
+
 /*
  * Map in a chunk of physical memory starting at start.
  */
-- 
1.6.4.4

