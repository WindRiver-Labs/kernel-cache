From 5315de7fa04a8a99673f9f2ca9123e6c5bd049aa Mon Sep 17 00:00:00 2001
From: WRS Support <support@windriver.com>
Date: Fri, 2 Oct 2009 16:14:05 -0400
Subject: [PATCH] x86: core x86 changes for hypervisor/guest

These changes represent the footprint of the guest implemention
into existing x86 kernel files.

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
Signed-off-by: Bruce Ashfield <bruce.ashfield@windriver.com>
Signed-off-by: Jim Somerville <Jim.Somerville@windriver.com>
Signed-off-by: Liang Li <liang.li@windriver.com>
Signed-off-by: Weiwei Wang <weiwei.wang@windriver.com>
---
 arch/x86/Kconfig                   |    4 +++-
 arch/x86/include/asm/mmu_context.h |    2 ++
 arch/x86/kernel/Makefile           |    1 +
 arch/x86/kernel/alternative.c      |    3 +++
 arch/x86/kernel/asm-offsets_32.c   |   12 ++++++++++++
 arch/x86/kernel/cpu/intel.c        |   10 +++++++++-
 arch/x86/kernel/e820.c             |    5 +++++
 arch/x86/kernel/head_32.S          |   30 ++++++++++++++++++++++++++++++
 arch/x86/kernel/i8237.c            |    8 +++++++-
 arch/x86/kernel/i8253.c            |    3 +++
 arch/x86/kernel/i8259.c            |    8 +++++++-
 arch/x86/kernel/kgdb.c             |   15 +++++++++++++++
 arch/x86/kernel/pci-dma.c          |    1 -
 arch/x86/kernel/pci-nommu.c        |   16 ++++++++++++++++
 arch/x86/kernel/process.c          |   19 +++++++++++++++++++
 arch/x86/kernel/setup.c            |   18 ++++++++++++++++++
 arch/x86/kernel/time.c             |    8 ++++++++
 arch/x86/kernel/tsc.c              |    4 ++++
 arch/x86/kernel/vbi/wrhv.c         |   35 +++++++----------------------------
 arch/x86/kernel/vmlinux.lds.S      |    9 +++++++++
 arch/x86/mm/tlb.c                  |   11 +++++++++++
 21 files changed, 189 insertions(+), 33 deletions(-)

diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index 1a5e0bd..708f3d6 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -556,7 +556,9 @@ source "arch/x86/lguest/Kconfig"
 
 config PARAVIRT
 	bool "Enable paravirtualization code"
-	---help---
+	default y
+	depends on !X86_VOYAGER
+	help
 	  This changes the kernel so it can modify itself when it is run
 	  under a hypervisor, potentially improving performance significantly
 	  over full virtualization.  However, when run without a hypervisor
diff --git a/arch/x86/include/asm/mmu_context.h b/arch/x86/include/asm/mmu_context.h
index 4a2d4e0..5c6ba30 100644
--- a/arch/x86/include/asm/mmu_context.h
+++ b/arch/x86/include/asm/mmu_context.h
@@ -37,7 +37,9 @@ static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,
 
 	if (likely(prev != next)) {
 		/* stop flush ipis for the previous mm */
+#if !defined(CONFIG_WRHV)
 		cpumask_clear_cpu(cpu, mm_cpumask(prev));
+#endif
 #ifdef CONFIG_SMP
 		percpu_write(cpu_tlbstate.state, TLBSTATE_OK);
 		percpu_write(cpu_tlbstate.active_mm, next);
diff --git a/arch/x86/kernel/Makefile b/arch/x86/kernel/Makefile
index f079408..b114081 100644
--- a/arch/x86/kernel/Makefile
+++ b/arch/x86/kernel/Makefile
@@ -97,6 +97,7 @@ obj-$(CONFIG_DEBUG_NX_TEST)	+= test_nx.o
 obj-$(CONFIG_VMI)		+= vmi_32.o vmiclock_32.o
 obj-$(CONFIG_KVM_GUEST)		+= kvm.o
 obj-$(CONFIG_KVM_CLOCK)		+= kvmclock.o
+obj-$(CONFIG_WRHV)		+= vbi/
 obj-$(CONFIG_PARAVIRT)		+= paravirt.o paravirt_patch_$(BITS).o
 obj-$(CONFIG_PARAVIRT_SPINLOCKS)+= paravirt-spinlocks.o
 obj-$(CONFIG_PARAVIRT_CLOCK)	+= pvclock.o
diff --git a/arch/x86/kernel/alternative.c b/arch/x86/kernel/alternative.c
index c7772b7..65d09f2 100644
--- a/arch/x86/kernel/alternative.c
+++ b/arch/x86/kernel/alternative.c
@@ -356,8 +356,11 @@ void alternatives_smp_switch(int smp)
 	printk("lockdep: fixing up alternatives.\n");
 #endif
 
+#ifndef CONFIG_WRHV
 	if (noreplace_smp || smp_alt_once)
 		return;
+#endif
+
 	BUG_ON(!smp && (num_online_cpus() > 1));
 
 	mutex_lock(&smp_alt);
diff --git a/arch/x86/kernel/asm-offsets_32.c b/arch/x86/kernel/asm-offsets_32.c
index c486e52..6f1cc41 100644
--- a/arch/x86/kernel/asm-offsets_32.c
+++ b/arch/x86/kernel/asm-offsets_32.c
@@ -22,6 +22,10 @@
 
 #include <xen/interface/xen.h>
 
+#ifdef CONFIG_WRHV
+#include <vbi/interface.h>
+#endif
+
 #include <linux/lguest.h>
 #include "../../../drivers/lguest/lg.h"
 
@@ -118,6 +122,14 @@ void foo(void)
 	OFFSET(PV_CPU_read_cr0, pv_cpu_ops, read_cr0);
 #endif
 
+#ifdef CONFIG_WRHV
+	BLANK();
+	DEFINE(WRHV_VB_CONFIG_SIZE, sizeof(struct vb_config));
+	DEFINE(VB_MAX_BOOTLINE_LENGTH, VB_MAX_BOOTLINE_LENGTH);
+	OFFSET(WRHV_COREID_OFFSET, vb_config, coreId);
+	OFFSET(WRHV_BOOTLINE_OFFSET, vb_config, bootLine);
+#endif
+
 #ifdef CONFIG_XEN
 	BLANK();
 	OFFSET(XEN_vcpu_info_mask, vcpu_info, evtchn_upcall_mask);
diff --git a/arch/x86/kernel/cpu/intel.c b/arch/x86/kernel/cpu/intel.c
index 1366c7c..c127c29 100644
--- a/arch/x86/kernel/cpu/intel.c
+++ b/arch/x86/kernel/cpu/intel.c
@@ -22,7 +22,9 @@
 #endif
 
 #include "cpu.h"
-
+#ifdef CONFIG_WRHV
+#include <asm/wrhv.h>
+#endif
 #ifdef CONFIG_X86_LOCAL_APIC
 #include <asm/mpspec.h>
 #include <asm/apic.h>
@@ -30,6 +32,7 @@
 
 static void __cpuinit early_init_intel(struct cpuinfo_x86 *c)
 {
+#ifndef CONFIG_WRHV
 	/* Unmask CPUID levels if masked: */
 	if (c->x86 > 6 || (c->x86 == 6 && c->x86_model >= 0xd)) {
 		u64 misc_enable;
@@ -42,6 +45,7 @@ static void __cpuinit early_init_intel(struct cpuinfo_x86 *c)
 			c->cpuid_level = cpuid_eax(0);
 		}
 	}
+#endif
 
 	if ((c->x86 == 0xf && c->x86_model >= 0x03) ||
 		(c->x86 == 0x6 && c->x86_model >= 0x0e))
@@ -190,6 +194,7 @@ static void __cpuinit intel_smp_check(struct cpuinfo_x86 *c)
 
 static void __cpuinit intel_workarounds(struct cpuinfo_x86 *c)
 {
+#ifndef CONFIG_WRHV
 	unsigned long lo, hi;
 
 #ifdef CONFIG_X86_F00F_BUG
@@ -267,6 +272,9 @@ static void __cpuinit intel_workarounds(struct cpuinfo_x86 *c)
 #endif
 
 	intel_smp_check(c);
+#else
+	wrhv_cpu_workarounds(c);
+#endif
 }
 #else
 static void __cpuinit intel_workarounds(struct cpuinfo_x86 *c)
diff --git a/arch/x86/kernel/e820.c b/arch/x86/kernel/e820.c
index 7bca3c6..734049a 100644
--- a/arch/x86/kernel/e820.c
+++ b/arch/x86/kernel/e820.c
@@ -244,9 +244,11 @@ int __init sanitize_e820_map(struct e820entry *biosmap, int max_nr_map,
 	int old_nr, new_nr, chg_nr;
 	int i;
 
+#ifndef CONFIG_WRHV
 	/* if there's only one memory region, don't bother */
 	if (*pnr_map < 2)
 		return -1;
+#endif
 
 	old_nr = *pnr_map;
 	BUG_ON(old_nr > max_nr_map);
@@ -1103,6 +1105,9 @@ void __init e820_reserve_resources(void)
 
 	for (i = 0; i < e820_saved.nr_map; i++) {
 		struct e820entry *entry = &e820_saved.map[i];
+#ifdef CONFIG_WRHV
+		if (entry->size > 0)
+#endif
 		firmware_map_add_early(entry->addr,
 			entry->addr + entry->size - 1,
 			e820_type_to_string(entry->type));
diff --git a/arch/x86/kernel/head_32.S b/arch/x86/kernel/head_32.S
index 37c3d4b..e637c2d 100644
--- a/arch/x86/kernel/head_32.S
+++ b/arch/x86/kernel/head_32.S
@@ -83,10 +83,13 @@ RESERVE_BRK(pagetables, INIT_MAP_SIZE)
  */
 __HEAD
 ENTRY(startup_32)
+
+#ifndef CONFIG_WRHV
 	/* test KEEP_SEGMENTS flag to see if the bootloader is asking
 		us to not reload segments */
 	testb $(1<<6), BP_loadflags(%esi)
 	jnz 2f
+#endif
 
 /*
  * Set segments to known values.
@@ -98,6 +101,13 @@ ENTRY(startup_32)
 	movl %eax,%fs
 	movl %eax,%gs
 2:
+#if defined(CONFIG_WRHV) && defined(CONFIG_SMP)
+	movl 0x4(%esp), %esi
+	movl WRHV_COREID_OFFSET(%esi), %eax
+	cmpl $0,%eax
+	jne startup_32_smp
+#endif
+
 
 /*
  * Clear BSS first so that there are no surprises...
@@ -117,6 +127,7 @@ ENTRY(startup_32)
  * (kexec on panic case). Hence copy out the parameters before initializing
  * page tables.
  */
+#ifndef CONFIG_WRHV
 	movl $pa(boot_params),%edi
 	movl $(PARAM_SIZE/4),%ecx
 	cld
@@ -163,6 +174,25 @@ subarch_entries:
 num_subarch_entries = (. - subarch_entries) / 4
 .previous
 #endif /* CONFIG_PARAVIRT */
+#else  /* CONFIG_WRHV */
+	/* Copy over the wrhv config, it's assumed the stack hasn't been fiddled with yet */
+	movl 0x4(%esp), %esi
+	/* Store the address of wrhv config so we can map it in later */
+	movl %esi, pa(_wr_config)
+	movl $pa(__wr_config), %edi
+	movl $(WRHV_VB_CONFIG_SIZE/4),%ecx
+	cld
+	rep
+	movsl
+
+	/* Fill in the boot command line */
+	movl $pa(__wr_config + WRHV_BOOTLINE_OFFSET), %esi
+	movl $pa(boot_command_line),%edi
+	movl $(VB_MAX_BOOTLINE_LENGTH/4),%ecx
+	rep
+	movsl
+#endif
+
 
 /*
  * Initialize page tables.  This creates a PDE and a set of page
diff --git a/arch/x86/kernel/i8237.c b/arch/x86/kernel/i8237.c
index b42ca69..e40b5c4 100644
--- a/arch/x86/kernel/i8237.c
+++ b/arch/x86/kernel/i8237.c
@@ -63,9 +63,15 @@ static struct sys_device device_i8237A = {
 
 static int __init i8237A_init_sysfs(void)
 {
-	int error = sysdev_class_register(&i8237_sysdev_class);
+	int error = -ENOSYS;
+
+	if (paravirt_enabled())
+		goto done;
+
+	error = sysdev_class_register(&i8237_sysdev_class);
 	if (!error)
 		error = sysdev_register(&device_i8237A);
+done:
 	return error;
 }
 device_initcall(i8237A_init_sysfs);
diff --git a/arch/x86/kernel/i8253.c b/arch/x86/kernel/i8253.c
index 23c1679..6ed2c28 100644
--- a/arch/x86/kernel/i8253.c
+++ b/arch/x86/kernel/i8253.c
@@ -194,6 +194,9 @@ static struct clocksource pit_cs = {
 
 static int __init init_pit_clocksource(void)
 {
+	if (paravirt_enabled())
+		return 0;
+
 	 /*
 	  * Several reasons not to register PIT as a clocksource:
 	  *
diff --git a/arch/x86/kernel/i8259.c b/arch/x86/kernel/i8259.c
index 7c9f02c..0651d98 100644
--- a/arch/x86/kernel/i8259.c
+++ b/arch/x86/kernel/i8259.c
@@ -278,9 +278,15 @@ static struct sys_device device_i8259A = {
 
 static int __init i8259A_init_sysfs(void)
 {
-	int error = sysdev_class_register(&i8259_sysdev_class);
+	int error = -ENOSYS;
+
+	if (paravirt_enabled())
+		goto done;
+
+	error = sysdev_class_register(&i8259_sysdev_class);
 	if (!error)
 		error = sysdev_register(&device_i8259A);
+done:
 	return error;
 }
 
diff --git a/arch/x86/kernel/kgdb.c b/arch/x86/kernel/kgdb.c
index 7e3fd12..c291366 100644
--- a/arch/x86/kernel/kgdb.c
+++ b/arch/x86/kernel/kgdb.c
@@ -412,6 +412,15 @@ void kgdb_disable_hw_debug(struct pt_regs *regs)
 }
 
 #ifdef CONFIG_SMP
+
+#ifdef CONFIG_WRHV
+static int kgdb_call_nmi_hook(struct pt_regs *regs)
+{
+       kgdb_nmicallback(raw_smp_processor_id(), regs);
+       return 0;
+}
+#endif
+
 /**
  *	kgdb_roundup_cpus - Get other CPUs into a holding pattern
  *	@flags: Current IRQ state
@@ -430,7 +439,13 @@ void kgdb_disable_hw_debug(struct pt_regs *regs)
  */
 void kgdb_roundup_cpus(unsigned long flags)
 {
+#ifdef CONFIG_WRHV
+	local_irq_enable();
+	smp_call_function(kgdb_call_nmi_hook, NULL, 0);
+	local_irq_disable();
+#else
 	apic->send_IPI_allbutself(APIC_DM_NMI);
+#endif
 }
 #endif
 
diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 4b7e3d8..b4d4156 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -5,7 +5,6 @@
 #include <linux/gfp.h>
 #include <linux/pci.h>
 #include <linux/kmemleak.h>
-
 #include <asm/proto.h>
 #include <asm/dma.h>
 #include <asm/iommu.h>
diff --git a/arch/x86/kernel/pci-nommu.c b/arch/x86/kernel/pci-nommu.c
index 3af4af8..adc4562 100644
--- a/arch/x86/kernel/pci-nommu.c
+++ b/arch/x86/kernel/pci-nommu.c
@@ -8,6 +8,11 @@
 #include <linux/pci.h>
 #include <linux/mm.h>
 
+#ifdef CONFIG_WRHV
+#include <vbi/interface.h>
+#include <vbi/vbi.h>
+#endif
+
 #include <asm/processor.h>
 #include <asm/iommu.h>
 #include <asm/dma.h>
@@ -65,6 +70,17 @@ static int nommu_map_sg(struct device *hwdev, struct scatterlist *sg,
 
 	for_each_sg(sg, s, nents, i) {
 		BUG_ON(!sg_page(s));
+#ifdef CONFIG_WRHV
+		if (paravirt_enabled()) {
+			u64 paddr;
+			dma_addr_t addr = sg_phys(s);
+
+			if (vbi_get_guest_dma_addr((void *)addr, &paddr) == 0)
+				s->dma_address = (dma_addr_t)paddr;
+			else
+				s->dma_address = -1;
+		} else
+#endif
 		s->dma_address = sg_phys(s);
 		if (!check_addr("map_sg", hwdev, s->dma_address, s->length))
 			return 0;
diff --git a/arch/x86/kernel/process.c b/arch/x86/kernel/process.c
index 3ac4845..808cda7 100644
--- a/arch/x86/kernel/process.c
+++ b/arch/x86/kernel/process.c
@@ -24,6 +24,10 @@
 #include <asm/ds.h>
 #include <asm/debugreg.h>
 
+#ifdef CONFIG_WRHV
+#include <vbi/vbi.h>
+#endif
+
 unsigned long idle_halt;
 EXPORT_SYMBOL(idle_halt);
 unsigned long idle_nomwait;
@@ -478,6 +482,16 @@ static void mwait_idle(void)
 		local_irq_enable();
 }
 
+#ifdef CONFIG_WRHV
+static void wrhv_idle(void)
+{
+	if (!need_resched()) {
+		local_irq_enable();
+		vbi_idle(1);
+	}
+}
+#endif
+
 /*
  * On SMP it's slightly faster (but much more power-consuming!)
  * to poll the ->work.need_resched flag instead of waiting for the
@@ -689,6 +703,11 @@ static int __init idle_setup(char *str)
 		 */
 		idle_nomwait = 1;
 		return 0;
+#ifdef CONFIG_WRHV
+	} else if (!strncmp(str, "wrhv", 5)) {
+		printk("using hypercall in idle threads\n");
+		pm_idle = wrhv_idle;
+#endif
 	} else
 		return -1;
 
diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b4ae4ac..bfa34c5 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -107,6 +107,11 @@
 #include <asm/topology.h>
 #include <asm/apicdef.h>
 #include <asm/k8.h>
+
+#ifdef CONFIG_WRHV
+#include <asm/wrhv.h>
+#endif
+
 #ifdef CONFIG_X86_64
 #include <asm/numa_64.h>
 #endif
@@ -410,7 +415,14 @@ static void __init reserve_initrd(void)
 		return;
 	}
 
+#ifdef CONFIG_X86_32
 	relocate_initrd();
+#else
+	printk(KERN_ERR "initrd extends beyond end of memory "
+              "(0x%08llx > 0x%08llx)\ndisabling initrd\n",
+              ramdisk_end, end_of_lowmem);
+	initrd_start = 0;
+#endif
 
 	free_early(ramdisk_image, ramdisk_end);
 }
@@ -726,6 +738,8 @@ void __init setup_arch(char **cmdline_p)
 	int acpi = 0;
 	int k8 = 0;
 
+	wrhv_boot_config();
+
 #ifdef CONFIG_X86_32
 	memcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));
 	visws_early_detect();
@@ -828,6 +842,8 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	x86_configure_nx();
 
+	wrhv_init();
+
 	parse_early_param();
 
 	x86_report_nx();
@@ -1052,6 +1068,8 @@ void __init setup_arch(char **cmdline_p)
 
 	e820_setup_gap();
 
+	wrhv_calibrate_smp_cpus();
+
 #ifdef CONFIG_VT
 #if defined(CONFIG_VGA_CONSOLE)
 	if (!efi_enabled || (efi_mem_type(0xa0000) != EFI_CONVENTIONAL_MEMORY))
diff --git a/arch/x86/kernel/time.c b/arch/x86/kernel/time.c
index fb5cc5e..e0f5c56 100644
--- a/arch/x86/kernel/time.c
+++ b/arch/x86/kernel/time.c
@@ -22,6 +22,10 @@
 #include <asm/hpet.h>
 #include <asm/time.h>
 
+#ifdef CONFIG_WRHV
+#include <asm/wrhv.h>
+#endif
+
 #if defined(CONFIG_X86_32) && defined(CONFIG_X86_IO_APIC)
 int timer_ack;
 #endif
@@ -94,7 +98,11 @@ static struct irqaction irq0  = {
 
 void __init setup_default_timer_irq(void)
 {
+#ifdef CONFIG_WRHV
+	setup_irq(TIMER_INT_NUM, &irq0);
+#else
 	setup_irq(0, &irq0);
+#endif
 }
 
 /* Default timer init function */
diff --git a/arch/x86/kernel/tsc.c b/arch/x86/kernel/tsc.c
index 9faf91a..c810073 100644
--- a/arch/x86/kernel/tsc.c
+++ b/arch/x86/kernel/tsc.c
@@ -752,8 +752,12 @@ static struct clocksource clocksource_tsc = {
 	.resume			= resume_tsc,
 	.mask                   = CLOCKSOURCE_MASK(64),
 	.shift                  = 22,
+#ifdef CONFIG_WRHV
+	.flags                  = CLOCK_SOURCE_IS_CONTINUOUS,
+#else
 	.flags                  = CLOCK_SOURCE_IS_CONTINUOUS |
 				  CLOCK_SOURCE_MUST_VERIFY,
+#endif
 #ifdef CONFIG_X86_64
 	.vread                  = vread_tsc,
 #endif
diff --git a/arch/x86/kernel/vbi/wrhv.c b/arch/x86/kernel/vbi/wrhv.c
index 432df57..4117d9c 100644
--- a/arch/x86/kernel/vbi/wrhv.c
+++ b/arch/x86/kernel/vbi/wrhv.c
@@ -68,6 +68,7 @@ static struct mm_struct *flush_mm;
 static unsigned long flush_va;
 static DEFINE_SPINLOCK(tlbstate_lock);
 static int enable_hrtimer = 0;
+static int novtlbopt;
 
 #define VBI_VTLB_OPTIM_OPTION (\
 			 VBI_VTLB_OPTIM_ENABLED |  \
@@ -369,27 +370,6 @@ static int wrhv_write_msr(unsigned int msr, unsigned low, unsigned high)
 	return 0;
 }
 
-static unsigned long wrhv_get_debugreg(int regno)
-{
-	unsigned long val = ~0UL;
-
-	switch (regno) {
-	case 0 ... 3:
-		/* undefined state */
-		break;
-	case 6 ... 7:
-		val = 0;
-		break;
-	default:
-		BUG();
-	}
-	return val;
-}
-
-static void wrhv_set_debugreg(int regno, unsigned long value)
-{
-}
-
 void wrhv_cpu_workarounds(struct cpuinfo_x86 *c)
 {
 	/* Simics workaround */
@@ -401,7 +381,7 @@ void wrhv_cpu_workarounds(struct cpuinfo_x86 *c)
 	clear_bit(X86_FEATURE_DE, (void *)boot_cpu_data.x86_capability);
 }
 
-void wrhv_boot_config(void)
+void __init wrhv_boot_config(void)
 {
 	boot_params.hdr.type_of_loader = 0xff; /* Unknown */
 	if (__initrd_start != __initrd_end) {
@@ -422,6 +402,8 @@ void wrhv_boot_config(void)
 		wr_config->phys_mem_size / 1024, (int)WRHV_RESERVED_TOP,
 		wr_config->bootLine);
 #endif
+	if (strstr(boot_command_line, "novtlbopt"))
+		novtlbopt = 1;
 }
 
 #ifdef CONFIG_SMP
@@ -708,7 +690,7 @@ static void wrhv_exit_mmap (struct mm_struct *mm)
 #endif
 }
 
-static void wrhv_init_vtlb_per_cpu(void)
+static void __cpuinit wrhv_init_vtlb_per_cpu(void)
 {
 	/* Initialize the cached copy of cr3 */
 	VTLB_GET_CPU_VAR(cr3_val) = native_read_cr3();
@@ -726,7 +708,7 @@ static void wrhv_init_vtlb_per_cpu(void)
 	   one will actually be in use.
 	*/
 
-	if (strstr(boot_command_line, "novtlbopt")) {
+	if (novtlbopt) {
 		VTLB_GET_CPU_VAR(vtlb_ctrl).mode = VBI_VTLB_OPTIM_OPTION_NOOPT;
 		printk("WRHV:  CPU %d vtlb optimization disabled\n",
 			smp_processor_id());
@@ -822,7 +804,6 @@ void __init wrhv_calibrate_smp_cpus(void)
 	}
 	return;
 }
-EXPORT_SYMBOL(wrhv_calibrate_smp_cpus);
 
 static void inline wrhv_umask_IPIs_for_vcore(void)
 {
@@ -1142,7 +1123,7 @@ static int __cpuinit wrhv_cpu_up(unsigned int cpu)
 	return 0;
 }
 
-static void wrhv_smp_cpus_done(unsigned int max_cpus)
+static void __init wrhv_smp_cpus_done(unsigned int max_cpus)
 {
 	printk(KERN_INFO "BP: smp_init done. \n");
 	native_smp_cpus_done(max_cpus);
@@ -1256,8 +1237,6 @@ void __init wrhv_init(void)
 	pv_cpu_ops.read_msr = wrhv_read_msr;
 
 	pv_irq_ops.init_IRQ = wrhv_init_IRQ;
-	pv_cpu_ops.get_debugreg = wrhv_get_debugreg;
-	pv_cpu_ops.set_debugreg = wrhv_set_debugreg;
 
 	machine_ops.emergency_restart = wrhv_restart;
 
diff --git a/arch/x86/kernel/vmlinux.lds.S b/arch/x86/kernel/vmlinux.lds.S
index 2cc2497..0faef4b 100644
--- a/arch/x86/kernel/vmlinux.lds.S
+++ b/arch/x86/kernel/vmlinux.lds.S
@@ -272,6 +272,15 @@ SECTIONS
 		EXIT_DATA
 	}
 
+#if defined(CONFIG_WRHV)
+	. = ALIGN(4096);
+	.initrd : {
+		__initrd_start = .;
+		*(.initrd)
+		__initrd_end = .;
+	}
+#endif
+
 #if !defined(CONFIG_X86_64) || !defined(CONFIG_SMP)
 	PERCPU(PAGE_SIZE)
 #endif
diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c
index 566f95c..545ec1c 100644
--- a/arch/x86/mm/tlb.c
+++ b/arch/x86/mm/tlb.c
@@ -13,6 +13,11 @@
 #include <asm/apic.h>
 #include <asm/uv/uv.h>
 
+#ifdef CONFIG_WRHV
+#include <vbi/vbi.h>
+#include <asm/wrhv.h>
+#endif
+
 DEFINE_PER_CPU_SHARED_ALIGNED(struct tlb_state, cpu_tlbstate)
 			= { &init_mm, 0, };
 
@@ -61,6 +66,12 @@ void leave_mm(int cpu)
 {
 	if (percpu_read(cpu_tlbstate.state) == TLBSTATE_OK)
 		BUG();
+
+#ifdef CONFIG_WRHV
+	wrhv_vtlb_op(VBI_VTLB_OP_DELETE_PMD,
+			__pa(per_cpu(cpu_tlbstate, cpu).active_mm->pgd), 0, 0);
+#endif
+
 	cpumask_clear_cpu(cpu,
 			  mm_cpumask(percpu_read(cpu_tlbstate.active_mm)));
 	load_cr3(swapper_pg_dir);
-- 
1.6.5.2

