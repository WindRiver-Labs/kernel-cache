From b7d74cd362daa10a9c991e83aad89f962799e2ea Mon Sep 17 00:00:00 2001
From: Liang Li <liang.li@windriver.com>
Date: Wed, 13 Jul 2011 23:47:55 +0800
Subject: [PATCH] wrhv: powerpc: introduce powerpc specifics of WR guest

These powerpc specific additons are the Linux specific
additions that were not a part of the reference VBI
implementation.

o support for e500 and e500mc guest
[
- create e500 common config option
- implement tlb invalidate function based tlbilx/tlbivax.
- paravirtualize TLB cache flushing
- set_context behaves different on e500/e500mc
  For e500mc set_context uses the PID register to point to
  the current process.  Where as the standard e500 needs to
  copy the kernel page tables from the init process to the
  current process.

- set proper permissions on kernel pages
  The hypervisor needs the TLB pages to be marked as:
  SX/SW/SR/UW/UR/UX
]

o enable SPE support for E500
[
Add SPE support for E500 core. Currently in hypervisor the
debug exception is defined by default. So we have to add a
dummy handler in linux kernel in order to create the correct
interrupt vector offset as the hypervisor.

When support SPE we introduce a dummy handler in linux kernel in order
to create the correct SPE interrupt vector offset as the hypervisor. But
actually that should be used for debug exception is defined by guest OS.
]

o support for SMP
[
Provide basic e500 SMP support which will be shared by all
non e500mc hypervisor guests.

Our implementation differs from upstream in that it does
not make use of the MPIC for IPIs, rather it uses the VIOAPIC
as its IPI communication mechanism.
]

o use kmalloc instead of vmalloc for modules
[
Replace vmalloc(...) with kmalloc(..., GFP_KERNEL) for PPC.
]

wrhv: powerpc: misc fixes
[
wrhv/e500: tlb_cam fixes for paravirtualized kernels

The following commit in 2.6.34.1 adjusts the tlb cam code
for e500 based boards.

commit b8504b8d34bf036b952c3f3b0f5cd5864d5f42e5
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Thu May 13 14:38:21 2010 -0500

    powerpc/fsl-booke: Move loadcam_entry back to asm code to fix SMP ftrace

    commit 78f622377f7d31d988db350a43c5689dd5f31876 upstream.

    When we build with ftrace enabled its possible that loadcam_entry would
    have used the stack pointer (even though the code doesn't need it).  We
    call loadcam_entry in __secondary_start before the stack is setup.  To
    ensure that loadcam_entry doesn't use the stack pointer the easiest
    solution is to just have it in asm code.

    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

We need to modify the paravirtualized code to declare and define
the functions that have been relocated.
]

Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
Signed-off-by: Bruce Ashfield <bruce.ashfield@windriver.com>
Signed-off-by: Tiejun Chen <tiejun.chen@windriver.com>
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
Signed-off-by: Jeremy McNicoll <jeremy.mcnicoll@windriver.com>
Signed-off-by: Liang Li <liang.li@windriver.com>
---
 arch/powerpc/Kconfig.debug                  |    7 +
 arch/powerpc/Makefile                       |   14 +-
 arch/powerpc/boot/Makefile                  |   16 +-
 arch/powerpc/boot/dts/wrhv_p4080ds.dts      | 1861 +++++++++++++++++++
 arch/powerpc/boot/main.c                    |   17 +-
 arch/powerpc/boot/ns16550.c                 |   37 +
 arch/powerpc/boot/serial.c                  |   63 +
 arch/powerpc/boot/wrapper                   |    5 +
 arch/powerpc/boot/wrhv_boot.h               |   15 +
 arch/powerpc/include/asm/fs_pd.h            |   12 +
 arch/powerpc/include/asm/hw_irq.h           |   77 +
 arch/powerpc/include/asm/machdep.h          |   14 +
 arch/powerpc/include/asm/mmu-book3e.h       |    4 +
 arch/powerpc/include/asm/page_32.h          |    4 +-
 arch/powerpc/include/asm/paravirt.h         |  135 ++
 arch/powerpc/include/asm/pgalloc-32.h       |    2 +-
 arch/powerpc/include/asm/pgtable-ppc32.h    |   45 +-
 arch/powerpc/include/asm/pgtable.h          |   14 +-
 arch/powerpc/include/asm/ppc_asm.h          |    3 +-
 arch/powerpc/include/asm/processor.h        |    6 +
 arch/powerpc/include/asm/pte-common.h       |   24 +-
 arch/powerpc/include/asm/pv_hw_irq.h        |   80 +
 arch/powerpc/include/asm/pv_pgtable-ppc32.h |   92 +
 arch/powerpc/include/asm/reg.h              |   37 +-
 arch/powerpc/include/asm/reg_paravirt.h     |   22 +
 arch/powerpc/include/asm/reg_wrhv.h         |  207 +++
 arch/powerpc/include/asm/system.h           |    4 +
 arch/powerpc/include/asm/time.h             |   22 +-
 arch/powerpc/include/asm/udbg.h             |    1 +
 arch/powerpc/include/asm/wrhv.h             |   73 +
 arch/powerpc/kernel/Makefile                |   29 +-
 arch/powerpc/kernel/cpu_setup_fsl_booke.S   |   27 +
 arch/powerpc/kernel/dma.c                   |   36 +
 arch/powerpc/kernel/entry_32.S              |   89 +-
 arch/powerpc/kernel/head_booke.h            |    2 +-
 arch/powerpc/kernel/head_wrhv.S             |  948 ++++++++++
 arch/powerpc/kernel/head_wrhv.h             |  166 ++
 arch/powerpc/kernel/head_wrhv_p4080.S       |  908 +++++++++
 arch/powerpc/kernel/irq.c                   |   28 +-
 arch/powerpc/kernel/kgdb.c                  |   16 +-
 arch/powerpc/kernel/legacy_serial.c         |    7 +
 arch/powerpc/kernel/misc_32.S               |   30 +
 arch/powerpc/kernel/module.c                |    9 +
 arch/powerpc/kernel/paravirt.c              |  349 ++++
 arch/powerpc/kernel/paravirt_entry_32.S     |   44 +
 arch/powerpc/kernel/paravirt_misc_32.S      |   32 +
 arch/powerpc/kernel/pci-common.c            |    9 +-
 arch/powerpc/kernel/process.c               |   29 +-
 arch/powerpc/kernel/prom.c                  |   13 +-
 arch/powerpc/kernel/setup-common.c          |   28 +
 arch/powerpc/kernel/setup_32.c              |   27 +-
 arch/powerpc/kernel/smp.c                   |    8 +-
 arch/powerpc/kernel/time.c                  |   49 +-
 arch/powerpc/kernel/traps.c                 |   18 +-
 arch/powerpc/kernel/udbg.c                  |    2 +
 arch/powerpc/kernel/udbg_16550.c            |   60 +-
 arch/powerpc/kernel/vbi/util.c              |  164 ++
 arch/powerpc/kernel/vbi/vmmu_display.c      |  140 ++
 arch/powerpc/kernel/vbi/wrhv.c              | 2655 +++++++++++++++++++++++++++
 arch/powerpc/kernel/vdso32/gettimeofday.S   |   21 +
 arch/powerpc/kernel/wrhv_entry_32.S         |  551 ++++++
 arch/powerpc/kernel/wrhv_misc_32.S          |   74 +
 arch/powerpc/kvm/Kconfig                    |   28 +
 arch/powerpc/mm/Makefile                    |   10 +-
 arch/powerpc/mm/fault.c                     |   20 +
 arch/powerpc/mm/fsl_booke_mmu.c             |   21 +-
 arch/powerpc/mm/init_32.c                   |   24 +-
 arch/powerpc/mm/mem.c                       |   11 +-
 arch/powerpc/mm/mmu_context_nohash.c        |   33 +-
 arch/powerpc/mm/mmu_decl.h                  |   31 +-
 arch/powerpc/mm/pgtable_32.c                |   32 +-
 arch/powerpc/mm/wrhv_tlb_nohash_low.S       |  210 +++
 arch/powerpc/platforms/85xx/Kconfig         |   19 +
 arch/powerpc/platforms/85xx/Makefile        |    1 +
 arch/powerpc/platforms/85xx/wrhv_p4080_ds.c |  331 ++++
 arch/powerpc/sysdev/fsl_pci.c               |   16 +
 drivers/Kconfig                             |    1 +
 drivers/Makefile                            |    1 +
 drivers/net/gianfar.c                       |   59 +-
 drivers/serial/8250.c                       |  200 ++
 drivers/serial/Kconfig                      |    7 +
 drivers/wrhv/Kconfig                        |   34 +
 drivers/wrhv/Makefile                       |    7 +
 drivers/wrhv/wrhv_devices.c                 |  480 +++++
 drivers/wrhv/wrhv_devices.h                 |  105 ++
 drivers/wrhv/wrhv_duart.c                   |  163 ++
 drivers/wrhv/wrhv_frame_irq.c               |   91 +
 drivers/wrhv/wrhv_serial.c                  |  244 +++
 include/linux/interrupt.h                   |    2 +-
 include/linux/wrhv.h                        |    4 +-
 include/vbi/duart.h                         |   24 +
 init/Kconfig.wrhv                           |   21 +
 kernel/module.c                             |   22 +-
 kernel/vbi/wrhv.c                           |   22 +-
 mm/vmalloc.c                                |    5 +
 95 files changed, 11658 insertions(+), 102 deletions(-)
 create mode 100644 arch/powerpc/boot/dts/wrhv_p4080ds.dts
 create mode 100644 arch/powerpc/boot/wrhv_boot.h
 create mode 100644 arch/powerpc/include/asm/paravirt.h
 create mode 100644 arch/powerpc/include/asm/pv_hw_irq.h
 create mode 100644 arch/powerpc/include/asm/pv_pgtable-ppc32.h
 create mode 100644 arch/powerpc/include/asm/reg_paravirt.h
 create mode 100644 arch/powerpc/include/asm/reg_wrhv.h
 create mode 100644 arch/powerpc/include/asm/wrhv.h
 create mode 100644 arch/powerpc/kernel/head_wrhv.S
 create mode 100644 arch/powerpc/kernel/head_wrhv.h
 create mode 100644 arch/powerpc/kernel/head_wrhv_p4080.S
 create mode 100644 arch/powerpc/kernel/paravirt.c
 create mode 100644 arch/powerpc/kernel/paravirt_entry_32.S
 create mode 100644 arch/powerpc/kernel/paravirt_misc_32.S
 create mode 100644 arch/powerpc/kernel/vbi/util.c
 create mode 100644 arch/powerpc/kernel/vbi/vmmu_display.c
 create mode 100644 arch/powerpc/kernel/vbi/wrhv.c
 create mode 100644 arch/powerpc/kernel/wrhv_entry_32.S
 create mode 100644 arch/powerpc/kernel/wrhv_misc_32.S
 create mode 100644 arch/powerpc/mm/wrhv_tlb_nohash_low.S
 create mode 100644 arch/powerpc/platforms/85xx/wrhv_p4080_ds.c
 create mode 100644 drivers/wrhv/Kconfig
 create mode 100644 drivers/wrhv/Makefile
 create mode 100644 drivers/wrhv/wrhv_devices.c
 create mode 100644 drivers/wrhv/wrhv_devices.h
 create mode 100644 drivers/wrhv/wrhv_duart.c
 create mode 100644 drivers/wrhv/wrhv_frame_irq.c
 create mode 100644 drivers/wrhv/wrhv_serial.c
 create mode 100644 include/vbi/duart.h

diff --git a/arch/powerpc/Kconfig.debug b/arch/powerpc/Kconfig.debug
index 5cdd7ed..3b11cfb 100644
--- a/arch/powerpc/Kconfig.debug
+++ b/arch/powerpc/Kconfig.debug
@@ -245,6 +245,13 @@ config PPC_EARLY_DEBUG_40x
 	  inbuilt serial port. This works on chips with a 16550 compatible
 	  UART. Xilinx chips with uartlite cannot use this option.
 
+config PPC_EARLY_DEBUG_WRHV_DUART
+	bool "Early serial debugging using wrhv duart"
+	depends on WRHV
+	help
+	  Select this to enable early debugging via the wrhv duart
+	  device driver.
+
 config PPC_EARLY_DEBUG_CPM
 	bool "Early serial debugging for Freescale CPM-based serial ports"
 	depends on SERIAL_CPM
diff --git a/arch/powerpc/Makefile b/arch/powerpc/Makefile
index 710943e..1316ca7 100644
--- a/arch/powerpc/Makefile
+++ b/arch/powerpc/Makefile
@@ -140,7 +140,16 @@ head-y				:= arch/powerpc/kernel/head_$(CONFIG_WORD_SIZE).o
 head-$(CONFIG_8xx)		:= arch/powerpc/kernel/head_8xx.o
 head-$(CONFIG_40x)		:= arch/powerpc/kernel/head_40x.o
 head-$(CONFIG_44x)		:= arch/powerpc/kernel/head_44x.o
-head-$(CONFIG_FSL_BOOKE)	:= arch/powerpc/kernel/head_fsl_booke.o
+
+ifeq ($(CONFIG_WRHV),y)
+ifeq ($(CONFIG_WRHV_P4080DS),y)
+head-$(CONFIG_FSL_BOOKE)        := arch/powerpc/kernel/head_wrhv_p4080.o
+else
+head-$(CONFIG_FSL_BOOKE)        := arch/powerpc/kernel/head_wrhv.o
+endif
+else
+head-$(CONFIG_FSL_BOOKE)        := arch/powerpc/kernel/head_fsl_booke.o
+endif
 
 head-$(CONFIG_PPC64)		+= arch/powerpc/kernel/entry_64.o
 head-$(CONFIG_PPC_FPU)		+= arch/powerpc/kernel/fpu.o
@@ -162,7 +171,7 @@ all: zImage
 
 # With make 3.82 we cannot mix normal and wildcard targets
 BOOT_TARGETS1 := zImage zImage.initrd uImage
-BOOT_TARGETS2 := zImage% dtbImage% treeImage.% cuImage.% simpleImage.%
+BOOT_TARGETS2 := zImage% dtbImage% treeImage.% cuImage.% simpleImage.% wrhvImage.%
 
 PHONY += $(BOOT_TARGETS1) $(BOOT_TARGETS2)
 
@@ -202,6 +211,7 @@ define archhelp
   @echo '                    versions which do not support device trees'
   @echo '  dtbImage.<dt>   - zImage with an embedded device tree blob'
   @echo '  simpleImage.<dt> - Firmware independent image.'
+  @echo '  wrhvImage.<dt> - Wind River Hypervisor image.'
   @echo '  treeImage.<dt>  - Support for older IBM 4xx firmware (not U-Boot)'
   @echo '  install         - Install kernel using'
   @echo '                    (your) ~/bin/$(INSTALLKERNEL) or'
diff --git a/arch/powerpc/boot/Makefile b/arch/powerpc/boot/Makefile
index 55a97e4..b0afdc3 100644
--- a/arch/powerpc/boot/Makefile
+++ b/arch/powerpc/boot/Makefile
@@ -29,6 +29,13 @@ ifdef CONFIG_DEBUG_INFO
 BOOTCFLAGS	+= -g
 endif
 
+ifdef CONFIG_WRHV
+BOOTCFLAGS	+= -DCONFIG_WRHV
+ifdef	CONFIG_WRHV_P4080DS
+BOOTCFLAGS	+= -DCONFIG_WRHV_P4080DS
+endif
+endif
+
 ifeq ($(call cc-option-yn, -fstack-protector),y)
 BOOTCFLAGS	+= -fno-stack-protector
 endif
@@ -275,7 +282,8 @@ initrd-  := $(patsubst zImage%, zImage.initrd%, $(image-n) $(image-))
 initrd-y := $(patsubst zImage%, zImage.initrd%, \
 		$(patsubst dtbImage%, dtbImage.initrd%, \
 		$(patsubst simpleImage%, simpleImage.initrd%, \
-		$(patsubst treeImage%, treeImage.initrd%, $(image-y)))))
+		$(patsubst wrhvImage%, wrhvImage.initrd%, \
+		$(patsubst treeImage%, treeImage.initrd%, $(image-y))))))
 initrd-y := $(filter-out $(image-y), $(initrd-y))
 targets	+= $(image-y) $(initrd-y)
 
@@ -323,6 +331,12 @@ $(obj)/simpleImage.initrd.%: vmlinux $(obj)/%.dtb $(wrapperbits)
 $(obj)/simpleImage.%: vmlinux $(obj)/%.dtb $(wrapperbits)
 	$(call if_changed,wrap,simpleboot-$*,,$(obj)/$*.dtb)
 
+$(obj)/wrhvImage.initrd.%: vmlinux $(obj)/%.dtb $(wrapperbits)
+	$(call if_changed,wrap,wrhvboot-$*,,$(obj)/$*.dtb,$(obj)/ramdisk.image.gz)
+
+$(obj)/wrhvImage.%: vmlinux $(obj)/%.dtb $(wrapperbits)
+	$(call if_changed,wrap,wrhvboot-$*,,$(obj)/$*.dtb)
+
 $(obj)/treeImage.initrd.%: vmlinux $(obj)/%.dtb $(wrapperbits)
 	$(call if_changed,wrap,treeboot-$*,,$(obj)/$*.dtb,$(obj)/ramdisk.image.gz)
 
diff --git a/arch/powerpc/boot/dts/wrhv_p4080ds.dts b/arch/powerpc/boot/dts/wrhv_p4080ds.dts
new file mode 100644
index 0000000..8a00609
--- /dev/null
+++ b/arch/powerpc/boot/dts/wrhv_p4080ds.dts
@@ -0,0 +1,1861 @@
+/*
+ * P4080DS Device Tree Source
+ *
+ * Copyright 2009-2010 Freescale Semiconductor Inc.
+ *
+ * This program is free software; you can redistribute	it and/or modify it
+ * under  the terms of	the GNU General	 Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ */
+
+/dts-v1/;
+
+/ {
+	model = "fsl,P4080DS";
+	compatible = "fsl,P4080DS";
+	#address-cells = <2>;
+	#size-cells = <2>;
+
+	aliases {
+		ccsr = &soc;
+
+		ethernet0 = &enet0;
+		ethernet1 = &enet1;
+		ethernet2 = &enet2;
+		ethernet3 = &enet3;
+		ethernet4 = &enet4;
+		ethernet5 = &enet5;
+		ethernet6 = &enet6;
+		ethernet7 = &enet7;
+		ethernet8 = &enet8;
+		ethernet9 = &enet9;
+		phy_rgmii = &phyrgmii;
+		phy5_slot3 = &phy5slot3;
+		phy6_slot3 = &phy6slot3;
+		phy7_slot3 = &phy7slot3;
+		phy8_slot3 = &phy8slot3;
+		emi1_slot3 = &p4080mdio2;
+		emi1_slot4 = &p4080mdio1;
+		emi1_slot5 = &p4080mdio3;
+		emi1_rgmii = &p4080mdio0;
+		emi2_slot4 = &p4080xmdio1;
+		emi2_slot5 = &p4080xmdio3;
+		serial0 = &serial0;
+		serial1 = &serial1;
+		serial2 = &serial2;
+		serial3 = &serial3;
+		pci0 = &pci0;
+		usb0 = &usb0;
+		usb1 = &usb1;
+		dma0 = &dma0;
+		dma1 = &dma1;
+		bman = &bman;
+		qman = &qman;
+		pme = &pme;
+		sdhc = &sdhc;
+		msi0 = &msi0;
+		msi1 = &msi1;
+		msi2 = &msi2;
+
+		crypto = &crypto;
+		sec_jq0 = &sec_jq0;
+		sec_jq1 = &sec_jq1;
+		sec_jq2 = &sec_jq2;
+		sec_jq3 = &sec_jq3;
+		rtic_a = &rtic_a;
+		rtic_b = &rtic_b;
+		rtic_c = &rtic_c;
+		rtic_d = &rtic_d;
+		snvs = &snvs;
+
+		fman0 = &fman0;
+		fman0_oh0 = &fman0_oh0;
+		fman0_oh1 = &fman0_oh1;
+		fman0_oh2 = &fman0_oh2;
+		fman0_oh3 = &fman0_oh3;
+		fman0_oh4 = &fman0_oh4;
+		fman0_oh5 = &fman0_oh5;
+		fman0_oh6 = &fman0_oh6;
+		fman0_rx0 = &fman0_rx0;
+		fman0_rx1 = &fman0_rx1;
+		fman0_rx2 = &fman0_rx2;
+		fman0_rx3 = &fman0_rx3;
+		fman0_rx4 = &fman0_rx4;
+
+		fman1 = &fman1;
+		fman1_oh0 = &fman1_oh0;
+		fman1_oh1 = &fman1_oh1;
+		fman1_oh2 = &fman1_oh2;
+		fman1_oh3 = &fman1_oh3;
+		fman1_oh4 = &fman1_oh4;
+		fman1_oh5 = &fman1_oh5;
+		fman1_oh6 = &fman1_oh6;
+		fman1_rx0 = &fman1_rx0;
+		fman1_rx1 = &fman1_rx1;
+		fman1_rx2 = &fman1_rx2;
+		fman1_rx3 = &fman1_rx3;
+		fman1_rx4 = &fman1_rx4;
+		rio0 = &rapidio0;
+	};
+
+	cpus {
+		#address-cells = <1>;
+		#size-cells = <0>;
+
+		cpu0: PowerPC,4080@0 {
+			device_type = "cpu";
+			reg = <0>;
+			next-level-cache = <&L2_0>;
+			L2_0: l2-cache {
+				next-level-cache = <&L3_0>;
+			};
+		};
+		cpu1: PowerPC,4080@1 {
+			device_type = "cpu";
+			reg = <1>;
+			next-level-cache = <&L2_1>;
+			L2_1: l2-cache {
+				next-level-cache = <&L3_0>;
+			};
+		};
+		cpu2: PowerPC,4080@2 {
+			device_type = "cpu";
+			reg = <2>;
+			next-level-cache = <&L2_2>;
+			L2_2: l2-cache {
+				next-level-cache = <&L3_0>;
+			};
+		};
+		cpu3: PowerPC,4080@3 {
+			device_type = "cpu";
+			reg = <3>;
+			next-level-cache = <&L2_3>;
+			L2_3: l2-cache {
+				next-level-cache = <&L3_0>;
+			};
+		};
+		cpu4: PowerPC,4080@4 {
+			device_type = "cpu";
+			reg = <4>;
+			next-level-cache = <&L2_4>;
+			L2_4: l2-cache {
+				next-level-cache = <&L3_0>;
+			};
+		};
+		cpu5: PowerPC,4080@5 {
+			device_type = "cpu";
+			reg = <5>;
+			next-level-cache = <&L2_5>;
+			L2_5: l2-cache {
+				next-level-cache = <&L3_0>;
+			};
+		};
+		cpu6: PowerPC,4080@6 {
+			device_type = "cpu";
+			reg = <6>;
+			next-level-cache = <&L2_6>;
+			L2_6: l2-cache {
+				next-level-cache = <&L3_0>;
+			};
+		};
+		cpu7: PowerPC,4080@7 {
+			device_type = "cpu";
+			reg = <7>;
+			next-level-cache = <&L2_7>;
+			L2_7: l2-cache {
+				next-level-cache = <&L3_0>;
+			};
+		};
+	};
+
+	memory {
+		device_type = "memory";
+		reg = <0 0x0 0 0x10000000>;
+	};
+
+	bman-portals@f4000000 {
+		#address-cells = <0x1>;
+		#size-cells = <0x1>;
+		compatible = "simple-bus";
+		ranges = <0x0 0x0 0xf4000000 0x200000>;
+		bman-portal@0 {
+			cell-index = <0x0>;
+			compatible = "fsl,p4080-bman-portal", "fsl,bman-portal";
+			reg = <0x0 0x4000 0x100000 0x1000>;
+			cpu-handle = <&cpu0>;
+			interrupts = <0x69 2>;
+			interrupt-parent = <&mpic>;
+		};
+		bman-portal@4000 {
+			cell-index = <0x1>;
+			compatible = "fsl,p4080-bman-portal", "fsl,bman-portal";
+			reg = <0x4000 0x4000 0x101000 0x1000>;
+			cpu-handle = <&cpu1>;
+			interrupts = <0x6b 2>;
+			interrupt-parent = <&mpic>;
+		};
+		bman-portal@8000 {
+			cell-index = <2>;
+			compatible = "fsl,p4080-bman-portal", "fsl,bman-portal";
+			reg = <0x8000 0x4000 0x102000 0x1000>;
+			cpu-handle = <&cpu2>;
+			interrupts = <0x6d 2>;
+			interrupt-parent = <&mpic>;
+		};
+		bman-portal@c000 {
+			cell-index = <0x3>;
+			compatible = "fsl,p4080-bman-portal", "fsl,bman-portal";
+			reg = <0xc000 0x4000 0x103000 0x1000>;
+			cpu-handle = <&cpu3>;
+			interrupts = <0x6f 2>;
+			interrupt-parent = <&mpic>;
+		};
+		bman-portal@10000 {
+			cell-index = <0x4>;
+			compatible = "fsl,p4080-bman-portal", "fsl,bman-portal";
+			reg = <0x10000 0x4000 0x104000 0x1000>;
+			cpu-handle = <&cpu4>;
+			interrupts = <0x71 2>;
+			interrupt-parent = <&mpic>;
+		};
+		bman-portal@14000 {
+			cell-index = <0x5>;
+			compatible = "fsl,p4080-bman-portal", "fsl,bman-portal";
+			reg = <0x14000 0x4000 0x105000 0x1000>;
+			cpu-handle = <&cpu5>;
+			interrupts = <0x73 2>;
+			interrupt-parent = <&mpic>;
+		};
+		bman-portal@18000 {
+			cell-index = <0x6>;
+			compatible = "fsl,p4080-bman-portal", "fsl,bman-portal";
+			reg = <0x18000 0x4000 0x106000 0x1000>;
+			cpu-handle = <&cpu6>;
+			interrupts = <0x75 2>;
+			interrupt-parent = <&mpic>;
+		};
+		bman-portal@1c000 {
+			cell-index = <0x7>;
+			compatible = "fsl,p4080-bman-portal", "fsl,bman-portal";
+			reg = <0x1c000 0x4000 0x107000 0x1000>;
+			cpu-handle = <&cpu7>;
+			interrupts = <0x77 2>;
+			interrupt-parent = <&mpic>;
+		};
+		bman-portal@20000 {
+			cell-index = <0x8>;
+			compatible = "fsl,p4080-bman-portal", "fsl,bman-portal";
+			reg = <0x20000 0x4000 0x108000 0x1000>;
+			interrupts = <0x79 2>;
+			interrupt-parent = <&mpic>;
+		};
+		bman-portal@24000 {
+			cell-index = <0x9>;
+			compatible = "fsl,p4080-bman-portal", "fsl,bman-portal";
+			reg = <0x24000 0x4000 0x109000 0x1000>;
+			interrupts = <0x7b 2>;
+			interrupt-parent = <&mpic>;
+		};
+
+		buffer-pool@0 {
+			compatible = "fsl,p4080-bpool", "fsl,bpool";
+			fsl,bpid = <0>;
+			fsl,bpool-cfg = <0 0x100 0 1 0 0x100>;
+		};
+	};
+
+	qman-portals@f4200000 {
+		#address-cells = <0x1>;
+		#size-cells = <0x1>;
+		compatible = "simple-bus";
+		ranges = <0x0 0x0 0xf4200000 0x200000>;
+		qportal0: qman-portal@0 {
+			cell-index = <0x0>;
+			compatible = "fsl,p4080-qman-portal", "fsl,qman-portal";
+			reg = <0x0 0x4000 0x100000 0x1000>;
+			cpu-handle = <&cpu0>;
+			interrupts = <0x68 0x2>;
+			interrupt-parent = <&mpic>;
+			fsl,qman-channel-id = <0x0>;
+			fsl,qman-pool-channels = <&qpool1 &qpool2 &qpool3
+						  &qpool4 &qpool5 &qpool6
+						  &qpool7 &qpool8 &qpool9
+						  &qpool10 &qpool11 &qpool12
+						  &qpool13 &qpool14 &qpool15>;
+			crypto@0 {
+				dev-handle = <&crypto>;
+			};
+			pme@0 {
+				dev-handle = <&pme>;
+			};
+			fman@0 {
+				dev-handle = <&fman0>;
+			};
+			fman@1 {
+				dev-handle = <&fman1>;
+			};
+		};
+
+		qportal1: qman-portal@4000 {
+			cell-index = <0x1>;
+			compatible = "fsl,p4080-qman-portal", "fsl,qman-portal";
+			reg = <0x4000 0x4000 0x101000 0x1000>;
+			cpu-handle = <&cpu1>;
+			interrupts = <0x6a 0x2>;
+			interrupt-parent = <&mpic>;
+			fsl,qman-channel-id = <0x1>;
+			fsl,qman-pool-channels = <&qpool1 &qpool2 &qpool3
+						  &qpool4 &qpool5 &qpool6
+						  &qpool7 &qpool8 &qpool9
+						  &qpool10 &qpool11 &qpool12
+						  &qpool13 &qpool14 &qpool15>;
+			crypto@0 {
+				dev-handle = <&crypto>;
+			};
+			pme@0 {
+				dev-handle = <&pme>;
+			};
+			fman@0 {
+				dev-handle = <&fman0>;
+			};
+			fman@1 {
+				dev-handle = <&fman1>;
+			};
+		};
+
+		qportal2: qman-portal@8000 {
+			cell-index = <0x2>;
+			compatible = "fsl,p4080-qman-portal", "fsl,qman-portal";
+			reg = <0x8000 0x4000 0x102000 0x1000>;
+			cpu-handle = <&cpu2>;
+			interrupts = <0x6c 0x2>;
+			interrupt-parent = <&mpic>;
+			fsl,qman-channel-id = <0x2>;
+			fsl,qman-pool-channels = <&qpool1 &qpool2 &qpool3
+						  &qpool4 &qpool5 &qpool6
+						  &qpool7 &qpool8 &qpool9
+						  &qpool10 &qpool11 &qpool12
+						  &qpool13 &qpool14 &qpool15>;
+			crypto@0 {
+				dev-handle = <&crypto>;
+			};
+			pme@0 {
+				dev-handle = <&pme>;
+			};
+			fman@0 {
+				dev-handle = <&fman0>;
+			};
+			fman@1 {
+				dev-handle = <&fman1>;
+			};
+		};
+
+		qportal3: qman-portal@c000 {
+			cell-index = <0x3>;
+			compatible = "fsl,p4080-qman-portal", "fsl,qman-portal";
+			reg = <0xc000 0x4000 0x103000 0x1000>;
+			cpu-handle = <&cpu3>;
+			interrupts = <0x6e 0x2>;
+			interrupt-parent = <&mpic>;
+			fsl,qman-channel-id = <0x3>;
+			fsl,qman-pool-channels = <&qpool1 &qpool2 &qpool3
+						  &qpool4 &qpool5 &qpool6
+						  &qpool7 &qpool8 &qpool9
+						  &qpool10 &qpool11 &qpool12
+						  &qpool13 &qpool14 &qpool15>;
+			crypto@0 {
+				dev-handle = <&crypto>;
+			};
+			pme@0 {
+				dev-handle = <&pme>;
+			};
+			fman@0 {
+				dev-handle = <&fman0>;
+			};
+			fman@1 {
+				dev-handle = <&fman1>;
+			};
+		};
+
+		qportal4: qman-portal@10000 {
+			cell-index = <0x4>;
+			compatible = "fsl,p4080-qman-portal", "fsl,qman-portal";
+			reg = <0x10000 0x4000 0x104000 0x1000>;
+			cpu-handle = <&cpu4>;
+			interrupts = <0x70 0x2>;
+			interrupt-parent = <&mpic>;
+			fsl,qman-channel-id = <0x4>;
+			fsl,qman-pool-channels = <&qpool1 &qpool2 &qpool3
+						  &qpool4 &qpool5 &qpool6
+						  &qpool7 &qpool8 &qpool9
+						  &qpool10 &qpool11 &qpool12
+						  &qpool13 &qpool14 &qpool15>;
+			crypto@0 {
+				dev-handle = <&crypto>;
+			};
+			pme@0 {
+				dev-handle = <&pme>;
+			};
+			fman@0 {
+				dev-handle = <&fman0>;
+			};
+			fman@1 {
+				dev-handle = <&fman1>;
+			};
+		};
+
+		qportal5: qman-portal@14000 {
+			cell-index = <0x5>;
+			compatible = "fsl,p4080-qman-portal", "fsl,qman-portal";
+			reg = <0x14000 0x4000 0x105000 0x1000>;
+			cpu-handle = <&cpu5>;
+			interrupts = <0x72 0x2>;
+			interrupt-parent = <&mpic>;
+			fsl,qman-channel-id = <0x5>;
+			fsl,qman-pool-channels = <&qpool1 &qpool2 &qpool3
+						  &qpool4 &qpool5 &qpool6
+						  &qpool7 &qpool8 &qpool9
+						  &qpool10 &qpool11 &qpool12
+						  &qpool13 &qpool14 &qpool15>;
+			crypto@0 {
+				dev-handle = <&crypto>;
+			};
+			pme@0 {
+				dev-handle = <&pme>;
+			};
+			fman@0 {
+				dev-handle = <&fman0>;
+			};
+			fman@1 {
+				dev-handle = <&fman1>;
+			};
+		};
+
+		qportal6: qman-portal@18000 {
+			cell-index = <0x6>;
+			compatible = "fsl,p4080-qman-portal", "fsl,qman-portal";
+			reg = <0x18000 0x4000 0x106000 0x1000>;
+			cpu-handle = <&cpu6>;
+			interrupts = <0x74 0x2>;
+			interrupt-parent = <&mpic>;
+			fsl,qman-channel-id = <0x6>;
+			fsl,qman-pool-channels = <&qpool1 &qpool2 &qpool3
+						  &qpool4 &qpool5 &qpool6
+						  &qpool7 &qpool8 &qpool9
+						  &qpool10 &qpool11 &qpool12
+						  &qpool13 &qpool14 &qpool15>;
+			crypto@0 {
+				dev-handle = <&crypto>;
+			};
+			pme@0 {
+				dev-handle = <&pme>;
+			};
+			fman@0 {
+				dev-handle = <&fman0>;
+			};
+			fman@1 {
+				dev-handle = <&fman1>;
+			};
+		};
+
+		qportal7: qman-portal@1c000 {
+			cell-index = <0x7>;
+			compatible = "fsl,p4080-qman-portal", "fsl,qman-portal";
+			reg = <0x1c000 0x4000 0x107000 0x1000>;
+			cpu-handle = <&cpu7>;
+			interrupts = <0x76 0x2>;
+			interrupt-parent = <&mpic>;
+			fsl,qman-channel-id = <0x7>;
+			fsl,qman-pool-channels = <&qpool1 &qpool2 &qpool3
+						  &qpool4 &qpool5 &qpool6
+						  &qpool7 &qpool8 &qpool9
+						  &qpool10 &qpool11 &qpool12
+						  &qpool13 &qpool14 &qpool15>;
+			crypto@0 {
+				dev-handle = <&crypto>;
+			};
+			pme@0 {
+				dev-handle = <&pme>;
+			};
+			fman@0 {
+				dev-handle = <&fman0>;
+			};
+			fman@1 {
+				dev-handle = <&fman1>;
+			};
+		};
+
+		qportal8: qman-portal@20000 {
+			cell-index = <0x8>;
+			compatible = "fsl,p4080-qman-portal", "fsl,qman-portal";
+			reg = <0x20000 0x4000 0x108000 0x1000>;
+			interrupts = <0x78 0x2>;
+			interrupt-parent = <&mpic>;
+			fsl,qman-channel-id = <0x8>;
+			fsl,qman-pool-channels = <&qpool1 &qpool2 &qpool3
+						  &qpool4 &qpool5 &qpool6
+						  &qpool7 &qpool8 &qpool9
+						  &qpool10 &qpool11 &qpool12
+						  &qpool13 &qpool14 &qpool15>;
+			crypto@0 {
+				dev-handle = <&crypto>;
+			};
+			pme@0 {
+				dev-handle = <&pme>;
+			};
+			fman@0 {
+				dev-handle = <&fman0>;
+			};
+			fman@1 {
+				dev-handle = <&fman1>;
+			};
+		};
+
+		qportal9: qman-portal@24000 {
+			cell-index = <0x9>;
+			compatible = "fsl,p4080-qman-portal", "fsl,qman-portal";
+			reg = <0x24000 0x4000 0x109000 0x1000>;
+			interrupts = <0x7a 0x2>;
+			interrupt-parent = <&mpic>;
+			fsl,qman-channel-id = <0x9>;
+			fsl,qman-pool-channels = <&qpool1 &qpool2 &qpool3
+						  &qpool4 &qpool5 &qpool6
+						  &qpool7 &qpool8 &qpool9
+						  &qpool10 &qpool11 &qpool12
+						  &qpool13 &qpool14 &qpool15>;
+			crypto@0 {
+				dev-handle = <&crypto>;
+			};
+			pme@0 {
+				dev-handle = <&pme>;
+			};
+			fman@0 {
+				dev-handle = <&fman0>;
+			};
+			fman@1 {
+				dev-handle = <&fman1>;
+			};
+		};
+
+		qpool1: qman-pool@1 {
+			cell-index = <1>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x21>;
+		};
+
+		qpool2: qman-pool@2 {
+			cell-index = <2>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x22>;
+		};
+
+		qpool3: qman-pool@3 {
+			cell-index = <3>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x23>;
+		};
+
+		qpool4: qman-pool@4 {
+			cell-index = <4>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x24>;
+		};
+
+		qpool5: qman-pool@5 {
+			cell-index = <5>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x25>;
+		};
+
+		qpool6: qman-pool@6 {
+			cell-index = <6>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x26>;
+		};
+
+		qpool7: qman-pool@7 {
+			cell-index = <7>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x27>;
+		};
+
+		qpool8: qman-pool@8 {
+			cell-index = <8>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x28>;
+		};
+
+		qpool9: qman-pool@9 {
+			cell-index = <9>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x29>;
+		};
+
+		qpool10: qman-pool@10 {
+			cell-index = <10>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x2a>;
+		};
+
+		qpool11: qman-pool@11 {
+			cell-index = <11>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x2b>;
+		};
+
+		qpool12: qman-pool@12 {
+			cell-index = <12>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x2c>;
+		};
+
+		qpool13: qman-pool@13 {
+			cell-index = <13>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x2d>;
+		};
+
+		qpool14: qman-pool@14 {
+			cell-index = <14>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x2e>;
+		};
+
+		qpool15: qman-pool@15 {
+			cell-index = <15>;
+			compatible = "fsl,p4080-qman-pool-channel", "fsl,qman-pool-channel";
+			fsl,qman-channel-id = <0x2f>;
+		};
+	};
+
+	soc: soc@fe000000 {
+		#address-cells = <1>;
+		#size-cells = <1>;
+		device_type = "soc";
+		compatible = "simple-bus";
+		ranges = <0x00000000 0 0xfe000000 0x1000000>;
+		reg = <0 0xfe000000 0 0x00001000>;
+
+		corenet-law {
+			compatible = "fsl,corenet-law";
+			reg = <0x0 0x1000>;
+			fsl,num-laws = <32>;
+			high-base = <0xc00>;
+			low-base = <0xc04>;
+			law-attrib = <0xc08>;
+		};
+
+		corenet-cf {
+			compatible = "fsl,corenet-cf";
+			reg = <0x18000 0x1000>;
+			fsl,ccf-num-csdids = <32>;
+			fsl,ccf-num-snoopids = <32>;
+		};
+
+		memory-controller@8000 {
+			compatible = "fsl,p4080-memory-controller";
+			reg = <0x8000 0x1000>;
+			interrupt-parent = <&mpic>;
+			interrupts = <0x12 2>;
+		};
+
+		memory-controller@9000 {
+			compatible = "fsl,p4080-memory-controller";
+			reg = <0x9000 0x1000>;
+			interrupt-parent = <&mpic>;
+			interrupts = <0x12 2>;
+		};
+
+		L3_0: l3-cache-controller@10000 {
+			compatible = "fsl,p4080-l3-cache-controller";
+			reg = <0x10000 0x1000>;
+
+		};
+
+		L3_1: l3-cache-controller@11000 {
+			compatible = "fsl,p4080-l3-cache-controller";
+			reg = <0x11000 0x1000>;
+		};
+
+		iommu@20000 {
+			compatible = "fsl,p4080-pamu";
+			reg = <0x20000 0x5000>;
+			interrupts = <24 2>;
+			interrupt-parent = <&mpic>;
+		};
+
+		msi0: msi@41600 {
+			compatible = "fsl,mpic-msi";
+			reg = <0x41600 0x200>;
+			msi-available-ranges = <0 0x100>;
+			interrupts = <
+				0xe0 0
+				0xe1 0
+				0xe2 0
+				0xe3 0
+				0xe4 0
+				0xe5 0
+				0xe6 0
+				0xe7 0>;
+			interrupt-parent = <&mpic>;
+		};
+
+		msi1: msi@41800 {
+			compatible = "fsl,mpic-msi";
+			reg = <0x41800 0x200>;
+			msi-available-ranges = <0 0x100>;
+			interrupts = <
+				0xe8 0
+				0xe9 0
+				0xea 0
+				0xeb 0
+				0xec 0
+				0xed 0
+				0xee 0
+				0xef 0>;
+			interrupt-parent = <&mpic>;
+		};
+
+		msi2: msi@41a00 {
+			compatible = "fsl,mpic-msi";
+			reg = <0x41a00 0x200>;
+			msi-available-ranges = <0 0x100>;
+			interrupts = <
+				0xf0 0
+				0xf1 0
+				0xf2 0
+				0xf3 0
+				0xf4 0
+				0xf5 0
+				0xf6 0
+				0xf7 0>;
+			interrupt-parent = <&mpic>;
+		};
+
+		dma0: dma@100300 {
+			#address-cells = <1>;
+			#size-cells = <1>;
+			compatible = "fsl,p4080-dma", "fsl,eloplus-dma";
+			reg = <0x100300 0x4>;
+			ranges = <0x0 0x100100 0x200>;
+			cell-index = <0>;
+			dma-channel@0 {
+				compatible = "fsl,p4080-dma-channel",
+						"fsl,eloplus-dma-channel";
+				reg = <0x0 0x80>;
+				cell-index = <0>;
+				interrupt-parent = <&mpic>;
+				interrupts = <28 2>;
+			};
+			dma-channel@80 {
+				compatible = "fsl,p4080-dma-channel",
+						"fsl,eloplus-dma-channel";
+				reg = <0x80 0x80>;
+				cell-index = <1>;
+				interrupt-parent = <&mpic>;
+				interrupts = <29 2>;
+			};
+			dma-channel@100 {
+				compatible = "fsl,p4080-dma-channel",
+						"fsl,eloplus-dma-channel";
+				reg = <0x100 0x80>;
+				cell-index = <2>;
+				interrupt-parent = <&mpic>;
+				interrupts = <30 2>;
+			};
+			dma-channel@180 {
+				compatible = "fsl,p4080-dma-channel",
+						"fsl,eloplus-dma-channel";
+				reg = <0x180 0x80>;
+				cell-index = <3>;
+				interrupt-parent = <&mpic>;
+				interrupts = <31 2>;
+			};
+		};
+
+		dma1: dma@101300 {
+			#address-cells = <1>;
+			#size-cells = <1>;
+			compatible = "fsl,p4080-dma", "fsl,eloplus-dma";
+			reg = <0x101300 0x4>;
+			ranges = <0x0 0x101100 0x200>;
+			cell-index = <1>;
+			dma-channel@0 {
+				compatible = "fsl,p4080-dma-channel",
+						"fsl,eloplus-dma-channel";
+				reg = <0x0 0x80>;
+				cell-index = <0>;
+				interrupt-parent = <&mpic>;
+				interrupts = <32 2>;
+			};
+			dma-channel@80 {
+				compatible = "fsl,p4080-dma-channel",
+						"fsl,eloplus-dma-channel";
+				reg = <0x80 0x80>;
+				cell-index = <1>;
+				interrupt-parent = <&mpic>;
+				interrupts = <33 2>;
+			};
+			dma-channel@100 {
+				compatible = "fsl,p4080-dma-channel",
+						"fsl,eloplus-dma-channel";
+				reg = <0x100 0x80>;
+				cell-index = <2>;
+				interrupt-parent = <&mpic>;
+				interrupts = <34 2>;
+			};
+			dma-channel@180 {
+				compatible = "fsl,p4080-dma-channel",
+						"fsl,eloplus-dma-channel";
+				reg = <0x180 0x80>;
+				cell-index = <3>;
+				interrupt-parent = <&mpic>;
+				interrupts = <35 2>;
+			};
+		};
+
+		i2c@118000 {
+			#address-cells = <1>;
+			#size-cells = <0>;
+			cell-index = <0>;
+			compatible = "fsl-i2c";
+			reg = <0x118000 0x100>;
+			interrupts = <38 2>;
+			interrupt-parent = <&mpic>;
+			dfsrr;
+		};
+
+		i2c@118100 {
+			#address-cells = <1>;
+			#size-cells = <0>;
+			cell-index = <1>;
+			compatible = "fsl-i2c";
+			reg = <0x118100 0x100>;
+			interrupts = <38 2>;
+			interrupt-parent = <&mpic>;
+			dfsrr;
+			eeprom@51 {
+				compatible = "at24,24c256";
+				reg = <0x51>;
+			};
+			eeprom@52 {
+				compatible = "at24,24c256";
+				reg = <0x52>;
+			};
+			rtc@68 {
+				compatible = "dallas,ds3232";
+				reg = <0x68>;
+				interrupts = <0 0x1>;
+				interrupt-parent = <&mpic>;
+			};
+		};
+
+		i2c@119000 {
+			#address-cells = <1>;
+			#size-cells = <0>;
+			cell-index = <2>;
+			compatible = "fsl-i2c";
+			reg = <0x119000 0x100>;
+			interrupts = <39 2>;
+			interrupt-parent = <&mpic>;
+			dfsrr;
+		};
+
+		i2c@119100 {
+			#address-cells = <1>;
+			#size-cells = <0>;
+			cell-index = <3>;
+			compatible = "fsl-i2c";
+			reg = <0x119100 0x100>;
+			interrupts = <39 2>;
+			interrupt-parent = <&mpic>;
+			dfsrr;
+		};
+
+		spi@110000 {
+			cell-index = <0>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+			compatible = "fsl,espi";
+			reg = <0x110000 0x1000>;
+			interrupts = <53 0x2>;
+			interrupt-parent = <&mpic>;
+			espi,num-ss-bits = <4>;
+			mode = "cpu";
+
+			fsl_m25p80@0 {
+				#address-cells = <1>;
+				#size-cells = <1>;
+				compatible = "fsl,espi-flash";
+				reg = <0>;
+				linux,modalias = "fsl_m25p80";
+				spi-max-frequency = <40000000>; /* input clock */
+				partition@u-boot {
+					label = "u-boot";
+					reg = <0x00000000 0x00100000>;
+					read-only;
+				};
+				partition@kernel {
+					label = "kernel";
+					reg = <0x00100000 0x00500000>;
+					read-only;
+				};
+				partition@dtb {
+					label = "dtb";
+					reg = <0x00600000 0x00100000>;
+					read-only;
+				};
+				partition@fs {
+					label = "file system";
+					reg = <0x00700000 0x00900000>;
+				};
+			};
+		};
+
+		usb0: usb@210000 {
+			compatible = "fsl,p4080-usb2-mph",
+					"fsl,mpc85xx-usb2-mph", "fsl-usb2-mph";
+			reg = <0x210000 0x1000>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+			interrupt-parent = <&mpic>;
+			interrupts = <44 0x2>;
+			phy_type = "ulpi";
+		};
+
+		usb1: usb@211000 {
+			compatible = "fsl,p4080-usb2-dr",
+					"fsl,mpc85xx-usb2-dr", "fsl-usb2-dr";
+			reg = <0x211000 0x1000>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+			interrupt-parent = <&mpic>;
+			interrupts = <45 0x2>;
+			dr_mode = "host";
+			phy_type = "ulpi";
+		};
+
+		serial0: serial@11c500 {
+			cell-index = <0>;
+			device_type = "serial";
+			compatible = "ns16550";
+			reg = <0x11c500 0x100>;
+			clock-frequency = <0>;
+			interrupts = <36 2>;
+			interrupt-parent = <&mpic>;
+		};
+
+		serial1: serial@11c600 {
+			cell-index = <1>;
+			device_type = "serial";
+			compatible = "ns16550";
+			reg = <0x11c600 0x100>;
+			clock-frequency = <0>;
+			interrupts = <36 2>;
+			interrupt-parent = <&mpic>;
+		};
+
+		serial2: serial@11d500 {
+			cell-index = <2>;
+			device_type = "serial";
+			compatible = "ns16550";
+			reg = <0x11d500 0x100>;
+			clock-frequency = <0>;
+			interrupts = <37 2>;
+			interrupt-parent = <&mpic>;
+		};
+
+		serial3: serial@11d600 {
+			cell-index = <3>;
+			device_type = "serial";
+			compatible = "ns16550";
+			reg = <0x11d600 0x100>;
+			clock-frequency = <0>;
+			interrupts = <37 2>;
+			interrupt-parent = <&mpic>;
+		};
+
+		guts: global-utilities@e0000 {
+			compatible = "fsl,qoriq-device-config-1.0";
+			reg = <0xe0000 0xe00>;
+			fsl,has-rstcr;
+			#sleep-cells = <1>;
+			fsl,liodn-bits = <12>;
+		};
+
+		pins: global-utilities@e0e00 {
+			compatible = "fsl,qoriq-pin-control-1.0";
+			reg = <0xe0e00 0x200>;
+			#sleep-cells = <2>;
+		};
+
+		clockgen: global-utilities@e1000 {
+			compatible = "fsl,p4080-clockgen";
+			reg = <0xe1000 0x1000>;
+			clock-frequency = <0>;
+		};
+
+		rcpm: global-utilities@e2000 {
+			compatible = "fsl,qoriq-rcpm-1.0";
+			reg = <0xe2000 0x1000>;
+			#sleep-cells = <1>;
+		};
+
+		mpic: pic@40000 {
+			clock-frequency = <0>;
+			interrupt-controller;
+			#address-cells = <0>;
+			#interrupt-cells = <2>;
+			reg = <0x40000 0x40000>;
+			compatible = "chrp,open-pic";
+			device_type = "open-pic";
+			big-endian;
+			message@1400 {
+				compatible = "fsl,mpic-msg";
+				interrupts = <0xb0 2 0xb1 2 0xb2 2 0xb3 2>;
+				interrupt-parent = < &mpic >;
+			};
+		};
+
+		sdhc: sdhc@114000 {
+			compatible = "fsl,p4080-esdhc", "fsl,esdhc";
+			reg = <0x114000 0x1000>;
+			interrupts = <48 2>;
+			interrupt-parent = <&mpic>;
+			fsl,sdhci-auto-cmd12;
+			clock-frequency = <0>;
+		};
+
+		gpio: gpio@130008 {
+			compatible = "fsl,qoriq-gpio";
+			reg = <0x130008 0xff8>;
+		};
+
+		crypto: crypto@300000 {
+			compatible = "fsl,p4080-sec4.0", "fsl,sec4.0";
+			#address-cells = <1>;
+			#size-cells = <1>;
+			reg		 = <0x300000 0x10000>;
+			ranges		 = <0 0x300000 0x1000>;
+			interrupts	 = <92 2>;
+			interrupt-parent = <&mpic>;
+			fsl,qi-spids	 = <5>;
+
+			sec_jq0: jq@1000 {
+				compatible = "fsl,p4080-sec4.0-job-queue", "fsl,sec4.0-job-queue";
+				reg	   = <0x1000 0x1000>;
+				interrupts	 = <88 2>;
+				interrupt-parent = <&mpic>;
+			};
+
+			sec_jq1: jq@2000 {
+				compatible = "fsl,p4080-sec4.0-job-queue", "fsl,sec4.0-job-queue";
+				reg	   = <0x2000 0x1000>;
+				interrupts	 = <89 2>;
+				interrupt-parent = <&mpic>;
+			};
+
+			sec_jq2: jq@3000 {
+				compatible = "fsl,p4080-sec4.0-job-queue", "fsl,sec4.0-job-queue";
+				reg	   = <0x3000 0x1000>;
+				interrupts	 = <90 2>;
+				interrupt-parent = <&mpic>;
+			};
+
+			sec_jq3: jq@4000 {
+				compatible = "fsl,p4080-sec4.0-job-queue", "fsl,sec4.0-job-queue";
+				reg	   = <0x4000 0x1000>;
+				interrupts	 = <91 2>;
+				interrupt-parent = <&mpic>;
+			};
+
+			rtic@6100 {
+				compatible = "fsl,p4080-sec4.0-rtic", "fsl,sec4.0-rtic";
+				#address-cells = <1>;
+				#size-cells = <1>;
+				reg		 = <0x6100 0x100>;
+				ranges		 = <0x0 0x6100 0xe00>;
+
+				rtic_a: rtic-a@100 {
+					compatible = "fsl,p4080-sec4.0-rtic-memory", "fsl,sec4.0-rtic-memory";
+					reg		 = <0x100 0x20 0x200 0x80>;
+				};
+
+				rtic_b: rtic-b@120 {
+					compatible = "fsl,p4080-sec4.0-rtic-memory", "fsl,sec4.0-rtic-memory";
+					reg		 = <0x120 0x20 0x300 0x80>;
+				};
+
+				rtic_c: rtic-c@140 {
+					compatible = "fsl,p4080-sec4.0-rtic-memory", "fsl,sec4.0-rtic-memory";
+					reg		 = <0x140 0x20 0x400 0x80>;
+				};
+
+				rtic_d: rtic-d@160 {
+					compatible = "fsl,p4080-sec4.0-rtic-memory", "fsl,sec4.0-rtic-memory";
+					reg		 = <0x160 0x20 0x500 0x80>;
+				};
+			};
+		};
+
+		snvs: snvs@314000 {
+			compatible = "fsl,p4080-sec4.0-snvs", "fsl,sec4.0-snvs";
+			reg	   = <0x314000 0x1000>;
+			interrupts	 = <93 2>;
+			interrupt-parent = <&mpic>;
+		};
+
+		pme: pme@316000 {
+			compatible = "fsl,pme";
+			reg = <0x316000 0x10000>;
+			/* fsl,pme-pdsr = <0x0 0x23000000 0x0 0x01000000>; */
+			/* fsl,pme-sre = <0x0 0x24000000 0x0 0x00a00000>; */
+			clock-frequency = <400000000>;
+			interrupts = <16 2>;
+			interrupt-parent = <&mpic>;
+		};
+
+		qman: qman@318000 {
+			compatible = "fsl,p4080-qman", "fsl,qman";
+			reg = <0x318000 0x1000>;
+			/* Commented out, use default allocation */
+			/* fsl,qman-fqd = <0x0 0x20000000 0x0 0x01000000>; */
+			/* fsl,qman-pfdr = <0x0 0x21000000 0x0 0x01000000>; */
+		};
+
+		bman: bman@31a000 {
+			compatible = "fsl,p4080-bman", "fsl,bman";
+			reg = <0x31a000 0x1000>;
+			/* Same as fsl,qman-*, use default allocation */
+			/* fsl,bman-fbpr = <0x0 0x22000000 0x0 0x01000000>; */
+		};
+
+		fman0: fman@400000 {
+			#address-cells = <1>;
+			#size-cells = <1>;
+			cell-index = <0>;
+			compatible = "fsl,p4080-fman", "fsl,fman", "simple-bus";
+			ranges = <0 0x400000 0x100000>;
+			reg = <0x400000 0x100000>;
+			clock-frequency = <0>;
+			interrupts = <96 2>;
+			interrupt-parent = <&mpic>;
+
+			cc@0 {
+				compatible = "fsl,p4080-fman-cc", "fsl,fman-cc";
+			};
+
+			parser@c7000 {
+				compatible = "fsl,p4080-fman-parser", "fsl,fman-parser";
+				reg = <0xc7000 0x1000>;
+			};
+
+			keygen@c1000 {
+				compatible = "fsl,p4080-fman-keygen", "fsl,fman-keygen";
+				reg = <0xc1000 0x1000>;
+			};
+
+			policer@c0000 {
+				compatible = "fsl,p4080-fman-policer", "fsl,fman-policer";
+				reg = <0xc0000 0x1000>;
+			};
+
+			muram@0 {
+				compatible = "fsl,p4080-fman-muram", "fsl,fman-muram";
+				reg = <0x0 0x28000>;
+			};
+
+			bmi@80000 {
+				compatible = "fsl,p4080-fman-bmi", "fsl,fman-bmi";
+				reg = <0x80000 0x400>;
+			};
+
+			qmi@80400 {
+				compatible = "fsl,p4080-fman-qmi", "fsl,fman-qmi";
+				reg = <0x80400 0x400>;
+			};
+
+			fman0_rx0: port@88000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-port-1g-rx", "fsl,fman-port-1g-rx";
+				reg = <0x88000 0x1000>;
+			};
+			fman0_rx1: port@89000 {
+				cell-index = <1>;
+				compatible = "fsl,p4080-fman-port-1g-rx", "fsl,fman-port-1g-rx";
+				reg = <0x89000 0x1000>;
+			};
+			fman0_rx2: port@8a000 {
+				cell-index = <2>;
+				compatible = "fsl,p4080-fman-port-1g-rx", "fsl,fman-port-1g-rx";
+				reg = <0x8a000 0x1000>;
+			};
+			fman0_rx3: port@8b000 {
+				cell-index = <3>;
+				compatible = "fsl,p4080-fman-port-1g-rx", "fsl,fman-port-1g-rx";
+				reg = <0x8b000 0x1000>;
+			};
+			fman0_rx4: port@90000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-port-10g-rx", "fsl,fman-port-10g-rx";
+				reg = <0x90000 0x1000>;
+			};
+
+			fman0_tx4: port@b0000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-port-10g-tx", "fsl,fman-port-10g-tx";
+				reg = <0xb0000 0x1000>;
+				fsl,qman-channel-id = <0x40>;
+			};
+			fman0_tx0: port@a8000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-port-1g-tx", "fsl,fman-port-1g-tx";
+				reg = <0xa8000 0x1000>;
+				fsl,qman-channel-id = <0x41>;
+			};
+			fman0_tx1: port@a9000 {
+				cell-index = <1>;
+				compatible = "fsl,p4080-fman-port-1g-tx", "fsl,fman-port-1g-tx";
+				reg = <0xa9000 0x1000>;
+				fsl,qman-channel-id = <0x42>;
+			};
+			fman0_tx2: port@aa000 {
+				cell-index = <2>;
+				compatible = "fsl,p4080-fman-port-1g-tx", "fsl,fman-port-1g-tx";
+				reg = <0xaa000 0x1000>;
+				fsl,qman-channel-id = <0x43>;
+			};
+			fman0_tx3: port@ab000 {
+				cell-index = <3>;
+				compatible = "fsl,p4080-fman-port-1g-tx", "fsl,fman-port-1g-tx";
+				reg = <0xab000 0x1000>;
+				fsl,qman-channel-id = <0x44>;
+			};
+
+			fman0_oh0: port@81000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x81000 0x1000>;
+				fsl,qman-channel-id = <0x45>;
+			};
+			fman0_oh1: port@82000 {
+				cell-index = <1>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x82000 0x1000>;
+				fsl,qman-channel-id = <0x46>;
+			};
+			fman0_oh2: port@83000 {
+				cell-index = <2>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x83000 0x1000>;
+				fsl,qman-channel-id = <0x47>;
+			};
+			fman0_oh3: port@84000 {
+				cell-index = <3>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x84000 0x1000>;
+				fsl,qman-channel-id = <0x48>;
+			};
+			fman0_oh4: port@85000 {
+				cell-index = <4>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x85000 0x1000>;
+				fsl,qman-channel-id = <0x49>;
+			};
+			fman0_oh5: port@86000 {
+				cell-index = <5>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x86000 0x1000>;
+				fsl,qman-channel-id = <0x4a>;
+			};
+			fman0_oh6: port@87000 {
+				cell-index = <6>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x87000 0x1000>;
+				fsl,qman-channel-id = <0x4b>;
+			};
+
+			enet0: ethernet@e0000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-1g-mac", "fsl,fman-1g-mac";
+				reg = <0xe0000 0x1000>;
+				fsl,port-handles = <&fman0_rx0 &fman0_tx0>;
+				tbi-handle = <&tbi0>;
+				phy-handle = <&phy0>;
+				phy-connection-type = "sgmii";
+			};
+
+			mdio0: mdio@e1120 {
+				#address-cells = <1>;
+				#size-cells = <0>;
+				compatible = "fsl,fman-mdio";
+				reg = <0xe1120 0xee0>;
+				interrupts = <100 1>;
+
+				tbi0: tbi-phy@8 {
+					reg = <0x8>;
+					device_type = "tbi-phy";
+				};
+
+				p4080mdio0: p4080ds-mdio0 {
+					#address-cells = <1>;
+					#size-cells = <0>;
+					compatible = "fsl,p4080ds-mdio";
+					fsl,mdio-handle = <&mdio0>;
+					fsl,muxval = <0>;
+
+					phyrgmii: ethernet-phy@0 {
+						reg = <0x0>;
+					};
+				};
+
+				p4080mdio1: p4080ds-mdio1 {
+					#address-cells = <1>;
+					#size-cells = <0>;
+					compatible = "fsl,p4080ds-mdio";
+					fsl,mdio-handle = <&mdio0>;
+					fsl,muxval = <1>;
+
+					phy5: ethernet-phy@1c {
+						reg = <0x1c>;
+					};
+					phy6: ethernet-phy@1d {
+						reg = <0x1d>;
+					};
+					phy7: ethernet-phy@1e {
+						reg = <0x1e>;
+					};
+					phy8: ethernet-phy@1f {
+						reg = <0x1f>;
+					};
+				};
+
+				p4080mdio2: p4080ds-mdio2 {
+					#address-cells = <1>;
+					#size-cells = <0>;
+					compatible = "fsl,p4080ds-mdio";
+					fsl,mdio-handle = <&mdio0>;
+					fsl,muxval = <2>;
+					status = "disabled";
+
+					phy5slot3: ethernet-phy@1c {
+						reg = <0x1c>;
+					};
+					phy6slot3: ethernet-phy@1d {
+						reg = <0x1d>;
+					};
+					phy7slot3: ethernet-phy@1e {
+						reg = <0x1e>;
+					};
+					phy8slot3: ethernet-phy@1f {
+						reg = <0x1f>;
+					};
+				};
+
+				p4080mdio3: p4080ds-mdio3 {
+					#address-cells = <1>;
+					#size-cells = <0>;
+					compatible = "fsl,p4080ds-mdio";
+					fsl,mdio-handle = <&mdio0>;
+					fsl,muxval = <3>;
+
+					phy0: ethernet-phy@1c {
+						reg = <0x1c>;
+					};
+					phy1: ethernet-phy@1d {
+						reg = <0x1d>;
+					};
+					phy2: ethernet-phy@1e {
+						reg = <0x1e>;
+					};
+					phy3: ethernet-phy@1f {
+						reg = <0x1f>;
+					};
+				};
+			};
+
+			enet1: ethernet@e2000 {
+				cell-index = <1>;
+				compatible = "fsl,p4080-fman-1g-mac", "fsl,fman-1g-mac";
+				reg = <0xe2000 0x1000>;
+				fsl,port-handles = <&fman0_rx1 &fman0_tx1>;
+				tbi-handle = <&tbi1>;
+				phy-handle = <&phy1>;
+				phy-connection-type = "sgmii";
+			};
+
+			mdio@e3120 {
+				#address-cells = <1>;
+				#size-cells = <0>;
+				compatible = "fsl,fman-tbi";
+				reg = <0xe3120 0xee0>;
+				interrupts = <100 1>;
+
+				tbi1: tbi-phy@8 {
+					reg = <8>;
+					device_type = "tbi-phy";
+				};
+			};
+
+			enet2: ethernet@e4000 {
+				cell-index = <2>;
+				compatible = "fsl,p4080-fman-1g-mac", "fsl,fman-1g-mac";
+				reg = <0xe4000 0x1000>;
+				fsl,port-handles = <&fman0_rx2 &fman0_tx2>;
+				tbi-handle = <&tbi2>;
+				phy-handle = <&phy2>;
+				phy-connection-type = "sgmii";
+			};
+
+			mdio@e5120 {
+				#address-cells = <1>;
+				#size-cells = <0>;
+				compatible = "fsl,fman-tbi";
+				reg = <0xe5120 0xee0>;
+				interrupts = <100 1>;
+
+				tbi2: tbi-phy@8 {
+					reg = <8>;
+					device_type = "tbi-phy";
+				};
+			};
+
+			enet3: ethernet@e6000 {
+				cell-index = <3>;
+				compatible = "fsl,p4080-fman-1g-mac", "fsl,fman-1g-mac";
+				reg = <0xe6000 0x1000>;
+				fsl,port-handles = <&fman0_rx3 &fman0_tx3>;
+				tbi-handle = <&tbi3>;
+				phy-handle = <&phy3>;
+				phy-connection-type = "sgmii";
+			};
+
+			mdio@e7120 {
+				#address-cells = <1>;
+				#size-cells = <0>;
+				compatible = "fsl,fman-tbi";
+				reg = <0xe7120 0xee0>;
+				interrupts = <100 1>;
+
+				tbi3: tbi-phy@8 {
+					reg = <8>;
+					device_type = "tbi-phy";
+				};
+			};
+			enet4: ethernet@f0000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-10g-mac", "fsl,fman-10g-mac";
+				reg = <0xf0000 0x1000>;
+				fsl,port-handles = <&fman0_rx4 &fman0_tx4>;
+				phy-handle = <&phy10>;
+				phy-connection-type = "xgmii";
+			};
+
+			xmdio0: mdio@f1000 {
+				#address-cells = <1>;
+				#size-cells = <0>;
+				compatible = "fsl,fman-xmdio";
+				reg = <0xf1000 0x1000>;
+				interrupts = <100 1>;
+
+				p4080xmdio1: p4080ds-xmdio1 {
+					#address-cells = <1>;
+					#size-cells = <0>;
+					compatible = "fsl,p4080ds-xmdio";
+					fsl,mdio-handle = <&xmdio0>;
+					fsl,muxval = <1>;
+
+					phy11: ethernet-phy@0 {
+						reg = <0x0>;
+					};
+				};
+
+				p4080xmdio3: p4080ds-xmdio3 {
+					#address-cells = <1>;
+					#size-cells = <0>;
+					compatible = "fsl,p4080ds-xmdio";
+					fsl,mdio-handle = <&xmdio0>;
+					fsl,muxval = <3>;
+
+					phy10: ethernet-phy@4 {
+						reg = <0x4>;
+					};
+				};
+			};
+		};
+
+		fman1: fman@500000 {
+			#address-cells = <1>;
+			#size-cells = <1>;
+			cell-index = <1>;
+			compatible = "fsl,p4080-fman", "fsl,fman", "simple-bus";
+			ranges = <0 0x500000 0x100000>;
+			reg = <0x500000 0x100000>;
+			clock-frequency = <0>;
+			interrupts = <97 2>;
+			interrupt-parent = <&mpic>;
+
+			cc@0 {
+				compatible = "fsl,p4080-fman-cc", "fsl,fman-cc";
+			};
+
+			parser@c7000 {
+				compatible = "fsl,p4080-fman-parser", "fsl,fman-parser";
+				reg = <0xc7000 0x1000>;
+			};
+
+			keygen@c1000 {
+				compatible = "fsl,p4080-fman-keygen", "fsl,fman-keygen";
+				reg = <0xc1000 0x1000>;
+			};
+
+			policer@c0000 {
+				compatible = "fsl,p4080-fman-policer", "fsl,fman-policer";
+				reg = <0xc0000 0x1000>;
+			};
+
+			muram@0 {
+				compatible = "fsl,p4080-fman-muram", "fsl,fman-muram";
+				reg = <0x0 0x28000>;
+			};
+
+			bmi@80000 {
+				compatible = "fsl,p4080-fman-bmi", "fsl,fman-bmi";
+				reg = <0x80000 0x400>;
+			};
+
+			qmi@80400 {
+				compatible = "fsl,p4080-fman-qmi", "fsl,fman-qmi";
+				reg = <0x80400 0x400>;
+			};
+
+			fman1_rx0: port@88000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-port-1g-rx", "fsl,fman-port-1g-rx";
+				reg = <0x88000 0x1000>;
+			};
+			fman1_rx1: port@89000 {
+				cell-index = <1>;
+				compatible = "fsl,p4080-fman-port-1g-rx", "fsl,fman-port-1g-rx";
+				reg = <0x89000 0x1000>;
+			};
+			fman1_rx2: port@8a000 {
+				cell-index = <2>;
+				compatible = "fsl,p4080-fman-port-1g-rx", "fsl,fman-port-1g-rx";
+				reg = <0x8a000 0x1000>;
+			};
+			fman1_rx3: port@8b000 {
+				cell-index = <3>;
+				compatible = "fsl,p4080-fman-port-1g-rx", "fsl,fman-port-1g-rx";
+				reg = <0x8b000 0x1000>;
+			};
+			fman1_rx4: port@90000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-port-10g-rx", "fsl,fman-port-10g-rx";
+				reg = <0x90000 0x1000>;
+			};
+
+			fman1_tx4: port@b0000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-port-10g-tx", "fsl,fman-port-10g-tx";
+				reg = <0xb0000 0x1000>;
+				fsl,qman-channel-id = <0x60>;
+			};
+			fman1_tx0: port@a8000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-port-1g-tx", "fsl,fman-port-1g-tx";
+				reg = <0xa8000 0x1000>;
+				fsl,qman-channel-id = <0x61>;
+			};
+			fman1_tx1: port@a9000 {
+				cell-index = <1>;
+				compatible = "fsl,p4080-fman-port-1g-tx", "fsl,fman-port-1g-tx";
+				reg = <0xa9000 0x1000>;
+				fsl,qman-channel-id = <0x62>;
+			};
+			fman1_tx2: port@aa000 {
+				cell-index = <2>;
+				compatible = "fsl,p4080-fman-port-1g-tx", "fsl,fman-port-1g-tx";
+				reg = <0xaa000 0x1000>;
+				fsl,qman-channel-id = <0x63>;
+			};
+			fman1_tx3: port@ab000 {
+				cell-index = <3>;
+				compatible = "fsl,p4080-fman-port-1g-tx", "fsl,fman-port-1g-tx";
+				reg = <0xab000 0x1000>;
+				fsl,qman-channel-id = <0x64>;
+			};
+
+			fman1_oh0: port@81000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x81000 0x1000>;
+				fsl,qman-channel-id = <0x65>;
+			};
+			fman1_oh1: port@82000 {
+				cell-index = <1>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x82000 0x1000>;
+				fsl,qman-channel-id = <0x66>;
+			};
+			fman1_oh2: port@83000 {
+				cell-index = <2>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x83000 0x1000>;
+				fsl,qman-channel-id = <0x67>;
+			};
+			fman1_oh3: port@84000 {
+				cell-index = <3>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x84000 0x1000>;
+				fsl,qman-channel-id = <0x68>;
+			};
+			fman1_oh4: port@85000 {
+				cell-index = <4>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x85000 0x1000>;
+				fsl,qman-channel-id = <0x69>;
+			};
+			fman1_oh5: port@86000 {
+				cell-index = <5>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x86000 0x1000>;
+				fsl,qman-channel-id = <0x6a>;
+			};
+			fman1_oh6: port@87000 {
+				cell-index = <6>;
+				compatible = "fsl,p4080-fman-port-oh", "fsl,fman-port-oh";
+				reg = <0x87000 0x1000>;
+				fsl,qman-channel-id = <0x6b>;
+			};
+
+			enet5: ethernet@e0000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-1g-mac", "fsl,fman-1g-mac";
+				reg = <0xe0000 0x1000>;
+				fsl,port-handles = <&fman1_rx0 &fman1_tx0>;
+				tbi-handle = <&tbi5>;
+				phy-handle = <&phy5>;
+				phy-connection-type = "sgmii";
+			};
+			mdio@e1120 {
+				#address-cells = <1>;
+				#size-cells = <0>;
+				compatible = "fsl,fman-tbi";
+				reg = <0xe1120 0xee0>;
+				interrupts = <101 1>;
+
+				tbi5: tbi-phy@8 {
+					reg = <8>;
+					device_type = "tbi-phy";
+				};
+			};
+
+			enet6: ethernet@e2000 {
+				cell-index = <1>;
+				compatible = "fsl,p4080-fman-1g-mac", "fsl,fman-1g-mac";
+				reg = <0xe2000 0x1000>;
+				fsl,port-handles = <&fman1_rx1 &fman1_tx1>;
+				tbi-handle = <&tbi6>;
+				phy-handle = <&phy6>;
+				phy-connection-type = "sgmii";
+			};
+
+			mdio@e3120 {
+				#address-cells = <1>;
+				#size-cells = <0>;
+				compatible = "fsl,fman-tbi";
+				reg = <0xe3120 0xee0>;
+				interrupts = <101 1>;
+
+				tbi6: tbi-phy@8 {
+					reg = <8>;
+					device_type = "tbi-phy";
+				};
+			};
+
+			enet7: ethernet@e4000 {
+				cell-index = <2>;
+				compatible = "fsl,p4080-fman-1g-mac", "fsl,fman-1g-mac";
+				reg = <0xe4000 0x1000>;
+				fsl,port-handles = <&fman1_rx2 &fman1_tx2>;
+				tbi-handle = <&tbi7>;
+				phy-handle = <&phy7>;
+				phy-connection-type = "sgmii";
+			};
+
+			mdio@e5120 {
+				#address-cells = <1>;
+				#size-cells = <0>;
+				compatible = "fsl,fman-tbi";
+				reg = <0xe5120 0xee0>;
+				interrupts = <101 1>;
+
+				tbi7: tbi-phy@8 {
+					reg = <8>;
+					device_type = "tbi-phy";
+				};
+			};
+
+			enet8: ethernet@e6000 {
+				cell-index = <3>;
+				compatible = "fsl,p4080-fman-1g-mac", "fsl,fman-1g-mac";
+				reg = <0xe6000 0x1000>;
+				fsl,port-handles = <&fman1_rx3 &fman1_tx3>;
+				tbi-handle = <&tbi8>;
+				phy-handle = <&phy8>;
+				phy-connection-type = "sgmii";
+			};
+
+			mdio@e7120 {
+				#address-cells = <1>;
+				#size-cells = <0>;
+				compatible = "fsl,fman-tbi";
+				reg = <0xe7120 0xee0>;
+				interrupts = <101 1>;
+
+				tbi8: tbi-phy@8 {
+					reg = <8>;
+					device_type = "tbi-phy";
+				};
+			};
+
+			enet9: ethernet@f0000 {
+				cell-index = <0>;
+				compatible = "fsl,p4080-fman-10g-mac", "fsl,fman-10g-mac";
+				reg = <0xf0000 0x1000>;
+				fsl,port-handles = <&fman1_rx4 &fman1_tx4>;
+				phy-handle = <&phy11>;
+				phy-connection-type = "xgmii";
+			};
+		};
+	};
+
+	rapidio0: rapidio@fe0c0000 {
+		#address-cells = <2>;
+		#size-cells = <2>;
+		compatible = "fsl,rapidio-delta";
+		reg = <0 0xfe0c0000 0 0x20000>;
+		ranges = <0 0 0 0xa0000000 0 0x10000000>;
+		interrupt-parent = <&mpic>;
+		/* err_irq bell_outb_irq bell_inb_irq
+			msg1_tx_irq msg1_rx_irq	msg2_tx_irq msg2_rx_irq */
+		interrupts = <16 2 56 2 57 2 60 2 61 2 62 2 63 2>;
+	};
+
+	pci0: pcie@fe200000 {
+		compatible = "fsl,p4080-pcie";
+		device_type = "pci";
+		target-id = <0>;
+		#interrupt-cells = <1>;
+		#size-cells = <2>;
+		#address-cells = <3>;
+		reg = <0 0xfe200000 0 0x1000>;
+		bus-range = <0x0 0xff>;
+		ranges = <0x02000000 0 0x80000000 0 0x80000000 0x0 0x20000000
+			  0x01000000 0 0x00000000 0 0xf8000000 0x0 0x00010000>;
+		clock-frequency = <0x1fca055>;
+		fsl,msi = <&msi0>;
+		interrupt-parent = <&mpic>;
+		interrupts = <16 2>;
+
+		interrupt-map-mask = <0xf800 0 0 7>;
+		interrupt-map = <
+			/* IDSEL 0x0 */
+			0000 0 0 1 &mpic 40 1
+			0000 0 0 2 &mpic 1 1
+			0000 0 0 3 &mpic 2 1
+			0000 0 0 4 &mpic 3 1
+			>;
+		pcie@0 {
+			reg = <0 0 0 0 0>;
+			#size-cells = <2>;
+			#address-cells = <3>;
+			device_type = "pci";
+			ranges = <0x02000000 0 0x80000000
+				  0x02000000 0 0x80000000
+				  0 0x20000000
+
+				  0x01000000 0 0x00000000
+				  0x01000000 0 0x00000000
+				  0 0x00010000>;
+		};
+	};
+
+	fsl,dpaa {
+		compatible = "fsl,p4080-dpaa", "fsl,dpaa";
+
+		ethernet@0 {
+			compatible = "fsl,p4080-dpa-ethernet", "fsl,dpa-ethernet";
+			fsl,qman-channel = <&qpool1>;
+			fsl,fman-mac = <&enet0>;
+		};
+		ethernet@1 {
+			compatible = "fsl,p4080-dpa-ethernet", "fsl,dpa-ethernet";
+			fsl,qman-channel = <&qpool1>;
+			fsl,fman-mac = <&enet1>;
+		};
+		ethernet@2 {
+			compatible = "fsl,p4080-dpa-ethernet", "fsl,dpa-ethernet";
+			fsl,qman-channel = <&qpool1>;
+			fsl,fman-mac = <&enet2>;
+		};
+		ethernet@3 {
+			compatible = "fsl,p4080-dpa-ethernet", "fsl,dpa-ethernet";
+			fsl,qman-channel = <&qpool1>;
+			fsl,fman-mac = <&enet3>;
+		};
+		ethernet@4 {
+			compatible = "fsl,p4080-dpa-ethernet", "fsl,dpa-ethernet";
+			fsl,qman-channel = <&qportal0>;
+			fsl,fman-mac = <&enet4>;
+		};
+		ethernet@5 {
+			compatible = "fsl,p4080-dpa-ethernet", "fsl,dpa-ethernet";
+			fsl,qman-channel = <&qportal7>;
+			fsl,fman-mac = <&enet5>;
+		};
+		ethernet@6 {
+			compatible = "fsl,p4080-dpa-ethernet", "fsl,dpa-ethernet";
+			fsl,qman-channel = <&qpool1>;
+			fsl,fman-mac = <&enet6>;
+		};
+		ethernet@7 {
+			compatible = "fsl,p4080-dpa-ethernet", "fsl,dpa-ethernet";
+			fsl,qman-channel = <&qpool1>;
+			fsl,fman-mac = <&enet7>;
+		};
+		ethernet@8 {
+			compatible = "fsl,p4080-dpa-ethernet", "fsl,dpa-ethernet";
+			fsl,qman-channel = <&qpool1>;
+			fsl,fman-mac = <&enet8>;
+		};
+		ethernet@9 {
+			compatible = "fsl,p4080-dpa-ethernet", "fsl,dpa-ethernet";
+			fsl,qman-channel = <&qportal0>;
+			fsl,fman-mac = <&enet9>;
+		};
+	};
+
+	localbus@fe124000 {
+		compatible = "fsl,p4080-elbc", "fsl,elbc", "simple-bus";
+		reg = <0 0xfe124000 0 0x1000>;
+		interrupts = <25 2>;
+		#address-cells = <2>;
+		#size-cells = <1>;
+
+		ranges = <0 0 0 0xe8000000 0x08000000>;
+
+		flash@0,0 {
+			compatible = "cfi-flash";
+			reg = <0 0 0x08000000>;
+			bank-width = <2>;
+			device-width = <2>;
+		};
+	};
+
+	chosen {
+		linux,stdout-path = &serial0;
+	};
+};
diff --git a/arch/powerpc/boot/main.c b/arch/powerpc/boot/main.c
index a28f021..91e43a2 100644
--- a/arch/powerpc/boot/main.c
+++ b/arch/powerpc/boot/main.c
@@ -18,6 +18,10 @@
 #include "gunzip_util.h"
 #include "reg.h"
 
+#ifdef CONFIG_WRHV
+#include "wrhv_boot.h"
+#endif
+
 static struct gunzip_state gzstate;
 
 struct addr_range {
@@ -192,6 +196,9 @@ void start(void)
 	vmlinux = prep_kernel();
 	initrd = prep_initrd(vmlinux, chosen,
 			     loader_info.initrd_addr, loader_info.initrd_size);
+#ifdef CONFIG_WRHV
+	strncpy(cmdline,(char *)(WRHV_CMDLINE_ADDR),WRHV_CMDLINE_SIZE);
+#endif
 	prep_cmdline(chosen);
 
 	printf("Finalizing device tree...");
@@ -205,9 +212,15 @@ void start(void)
 	if (console_ops.close)
 		console_ops.close();
 
-	kentry = (kernel_entry_t) vmlinux.addr;
+	/* For Hypervisor, kernel entry should be at 0xC0000000 */
+#ifdef CONFIG_WRHV
+#define ENT_OFFSET 0xC0000000
+#else
+#define ENT_OFFSET 0
+#endif
+	kentry = (kernel_entry_t) (vmlinux.addr + ENT_OFFSET);
 	if (ft_addr)
-		kentry(ft_addr, 0, NULL);
+		kentry(ft_addr, ENT_OFFSET, NULL);
 	else
 		kentry((unsigned long)initrd.addr, initrd.size,
 		       loader_info.promptr);
diff --git a/arch/powerpc/boot/ns16550.c b/arch/powerpc/boot/ns16550.c
index 8c9ead9..699e36f 100644
--- a/arch/powerpc/boot/ns16550.c
+++ b/arch/powerpc/boot/ns16550.c
@@ -52,6 +52,39 @@ static u8 ns16550_tstc(void)
 	return ((in_8(reg_base + (UART_LSR << reg_shift)) & UART_LSR_DR) != 0);
 }
 
+#if defined(CONFIG_WRHV_P4080DS)
+
+#define TLBWE_CODE          0x7C0007A4
+#define MAS0_TLBSEL1_ENTRY  0x10000000
+#define MAS1_VALID_4K_TSIZE (0x80000000|((1 << 8) & 0x00000F00))
+#define MAS2_IG             0x0000000a
+#define MAS2_SXWR           0x00000015
+
+/*
+ * Here we have to create a TLB0 entry to map uart since the
+ * Hypervisor dose not map this while pass the guest OS on E500mc.
+ */
+static void wrhv_uart_tlb0_create(void)
+{
+	/* Write MAS0/1/2/3 to create tlb0 to map uart. And note
+	 * r3 should be privileged instruction code as the HY expect. */
+	__asm__ __volatile__(
+						 "mtspr  0x270,%0\n"
+						 "mtspr  0x271,%1\n"
+						 "mtspr  0x272,%2\n"
+						 "mtspr  0x273,%3\n"
+						 "lis    3,%4@h\n"
+						 "ori    3,3,%4@l\n"
+						 "tlbwe\n"
+						 ::"r" (MAS0_TLBSEL1_ENTRY), "r" (MAS1_VALID_4K_TSIZE),
+						  "r" ((unsigned int)reg_base|MAS2_IG),
+						  "r" ((unsigned int)reg_base|MAS2_SXWR),
+						  "i" (TLBWE_CODE)
+						 );
+}
+
+#endif
+
 int ns16550_console_init(void *devp, struct serial_console_data *scdp)
 {
 	int n;
@@ -68,6 +101,10 @@ int ns16550_console_init(void *devp, struct serial_console_data *scdp)
 	if (n != sizeof(reg_shift))
 		reg_shift = 0;
 
+#if defined(CONFIG_WRHV_P4080DS)
+	wrhv_uart_tlb0_create();
+#endif
+
 	scdp->open = ns16550_open;
 	scdp->putc = ns16550_putc;
 	scdp->getc = ns16550_getc;
diff --git a/arch/powerpc/boot/serial.c b/arch/powerpc/boot/serial.c
index f2156f0..725a35d 100644
--- a/arch/powerpc/boot/serial.c
+++ b/arch/powerpc/boot/serial.c
@@ -19,6 +19,10 @@
 #include "io.h"
 #include "ops.h"
 
+#ifdef CONFIG_WRHV
+#include "wrhv_boot.h"
+#endif
+
 static int serial_open(void)
 {
 	struct serial_console_data *scdp = console_ops.data;
@@ -82,6 +86,56 @@ static void serial_close(void)
 		scdp->close();
 }
 
+#ifdef CONFIG_WRHV
+static inline const char * wrhv_serial(int port_index)
+{
+	switch(port_index) {
+		case  0:
+			return "serial0";
+		case  1:
+			return "serial1";
+		case  2:
+			return "serial2";
+		case  3:
+			return "serial3";
+		default:
+			return NULL;
+	}
+}
+
+static void * wrhv_serial_get_stdout_devp(void)
+{
+	void *devp;
+	char *cmdline_p = (char *)(WRHV_CMDLINE_ADDR);
+	char wrhv_path[256];
+	int i = 0, serial_index = -1;
+
+	do{
+		if(!strncmp(&cmdline_p[i],"wrhv_earlycon=",WRHV_EARLYCON_SIZE)){
+			serial_index = cmdline_p[i+WRHV_EARLYCON_SIZE];
+			break;
+		}
+		/* Try to find next space  */
+		while((i < 242) && (cmdline_p[i] != 0x20))
+			i++;
+		/*skip the space */
+		i++;
+	}while(i < WRHV_CMDLINE_SIZE);
+
+	devp = finddevice("/aliases");
+	if (devp == NULL)
+		goto null_out;
+
+	if (getprop(devp,wrhv_serial((serial_index - 0x30)),wrhv_path,256) > 0){
+		devp =  finddevice(wrhv_path);
+		return devp;
+	}
+
+null_out:
+	return NULL;
+}
+#endif
+
 static void *serial_get_stdout_devp(void)
 {
 	void *devp;
@@ -113,6 +167,11 @@ int serial_console_init(void)
 	void *devp;
 	int rc = -1;
 
+#ifdef CONFIG_WRHV
+	devp = wrhv_serial_get_stdout_devp();
+	if(devp == NULL)
+#endif
+
 	devp = serial_get_stdout_devp();
 	if (devp == NULL)
 		goto err_out;
@@ -142,7 +201,11 @@ int serial_console_init(void)
 		console_ops.data = &serial_cd;
 
 		if (serial_cd.getc)
+#ifdef CONFIG_WRHV
+			console_ops.edit_cmdline = NULL;
+#else	
 			console_ops.edit_cmdline = serial_edit_cmdline;
+#endif
 
 		return 0;
 	}
diff --git a/arch/powerpc/boot/wrapper b/arch/powerpc/boot/wrapper
index f4594ed..d482d32 100755
--- a/arch/powerpc/boot/wrapper
+++ b/arch/powerpc/boot/wrapper
@@ -225,6 +225,11 @@ simpleboot-*)
     platformo="$object/fixed-head.o $object/simpleboot.o"
     binary=y
     ;;
+wrhvboot-*)
+    link_address='0x6000000'
+    platformo="$object/simpleboot.o"
+    binary=y
+    ;;
 asp834x-redboot)
     platformo="$object/fixed-head.o $object/redboot-83xx.o"
     binary=y
diff --git a/arch/powerpc/boot/wrhv_boot.h b/arch/powerpc/boot/wrhv_boot.h
new file mode 100644
index 0000000..6dc2d94
--- /dev/null
+++ b/arch/powerpc/boot/wrhv_boot.h
@@ -0,0 +1,15 @@
+#ifndef _WRHV_BOOT_H
+#define _WRHV_BOOT_H
+
+/*
+ * In current situation, there is no parameters protocol negotiated
+ * between hypervisor and guest Linux, so we still define the hard
+ * address for command line buffer like ENT_OFFSET as follows. Just
+ * for notes to remove them in the future.
+ * WRHV_CMDLINE_ADDR=offsetof(struct vb_config,bootLine)+ENT_OFFSET
+ */
+#define WRHV_CMDLINE_ADDR 0xF00000DC
+#define WRHV_CMDLINE_SIZE 256
+#define WRHV_EARLYCON_SIZE  14  /* sizeof("wrhv_earlycon=") */
+
+#endif /* _WRHV_BOOT_H */
diff --git a/arch/powerpc/include/asm/fs_pd.h b/arch/powerpc/include/asm/fs_pd.h
index 9361cd5..9df3b12 100644
--- a/arch/powerpc/include/asm/fs_pd.h
+++ b/arch/powerpc/include/asm/fs_pd.h
@@ -42,9 +42,21 @@ static inline int uart_baudrate(void)
         return get_baudrate();
 }
 
+#ifdef CONFIG_PARAVIRT
+extern int paravirt_ppc_proc_freq(void);
+static inline int native_ppc_proc_freq(void)
+{
+	return ppc_proc_freq;
+}
+#endif
+
 static inline int uart_clock(void)
 {
+#ifdef CONFIG_PARAVIRT
+	return paravirt_ppc_proc_freq();
+#else
         return ppc_proc_freq;
+#endif
 }
 
 #endif
diff --git a/arch/powerpc/include/asm/hw_irq.h b/arch/powerpc/include/asm/hw_irq.h
index bd100fc..492bb1d 100644
--- a/arch/powerpc/include/asm/hw_irq.h
+++ b/arch/powerpc/include/asm/hw_irq.h
@@ -13,6 +13,7 @@
 
 extern void timer_interrupt(struct pt_regs *);
 
+#ifndef CONFIG_PARAVIRT
 #ifdef CONFIG_PPC64
 #include <asm/paca.h>
 
@@ -124,6 +125,82 @@ static inline int irqs_disabled_flags(unsigned long flags)
 
 #endif /* CONFIG_PPC64 */
 
+#else /* !CONFIG_PARAVIRT */
+
+/* native implementation taken from !CONFIG_PPC64 */
+#if defined(CONFIG_BOOKE)
+#define SET_MSR_EE(x)	mtmsr(x)
+#define native_raw_local_irq_restore(flags)	__asm__ __volatile__("wrtee %0" : : "r" (flags) : "memory")
+#else
+#define SET_MSR_EE(x)	mtmsr(x)
+#define native_raw_local_irq_restore(flags)	mtmsr(flags)
+#endif
+
+static inline void native_raw_local_irq_disable(void)
+{
+#ifdef CONFIG_BOOKE
+#ifdef CONFIG_KVM_GUEST
+	__asm__ __volatile__("wrtee %0": : "r"(0) :"memory");
+#else
+	__asm__ __volatile__("wrteei 0": : :"memory");
+#endif
+#else
+	unsigned long msr;
+	__asm__ __volatile__("": : :"memory");
+	msr = mfmsr();
+	SET_MSR_EE(msr & ~MSR_EE);
+#endif
+}
+
+static inline void native_raw_local_irq_enable(void)
+{
+#ifdef CONFIG_BOOKE
+#ifdef CONFIG_KVM_GUEST
+	__asm__ __volatile__("wrtee %0": : "r"(MSR_EE) :"memory");
+#else
+	__asm__ __volatile__("wrteei 1": : :"memory");
+#endif
+#else
+	unsigned long msr;
+	__asm__ __volatile__("": : :"memory");
+	msr = mfmsr();
+	SET_MSR_EE(msr | MSR_EE);
+#endif
+}
+
+static inline void native_raw_local_irq_save_ptr(unsigned long *flags)
+{
+	unsigned long msr;
+	msr = mfmsr();
+	*flags = msr;
+#ifdef CONFIG_BOOKE
+#ifdef CONFIG_KVM_GUEST
+	__asm__ __volatile__("wrtee %0": : "r"(0) :"memory");
+#else
+	__asm__ __volatile__("wrteei 0": : :"memory");
+#endif
+#else
+	SET_MSR_EE(msr & ~MSR_EE);
+#endif
+	__asm__ __volatile__("": : :"memory");
+}
+
+#define native_raw_local_save_flags(flags)	((flags) = mfmsr())
+#define native_raw_local_irq_save(flags)	native_raw_local_irq_save_ptr(&flags)
+#define native_raw_irqs_disabled()		((mfmsr() & MSR_EE) == 0)
+#define native_raw_irqs_disabled_flags(flags)	(((flags) & MSR_EE) == 0)
+
+#define native_hard_irq_disable()	native_raw_local_irq_disable()
+
+static inline int native_irqs_disabled_flags(unsigned long flags)
+{
+	return (flags & MSR_EE) == 0;
+}
+
+/* Hypervior specific implementation */
+#include <asm/pv_hw_irq.h>
+#endif /* CONFIG_PARAVIRT */
+
 /*
  * interrupt-retrigger: should we handle this via lost interrupts and IPIs
  * or should we not care like we do now ? --BenH.
diff --git a/arch/powerpc/include/asm/machdep.h b/arch/powerpc/include/asm/machdep.h
index de73b07..579b9fb 100644
--- a/arch/powerpc/include/asm/machdep.h
+++ b/arch/powerpc/include/asm/machdep.h
@@ -12,6 +12,7 @@
 #include <linux/seq_file.h>
 #include <linux/init.h>
 #include <linux/dma-mapping.h>
+#include <linux/phy.h>
 
 #include <asm/setup.h>
 
@@ -275,6 +276,17 @@ struct machdep_calls {
 	ssize_t (*cpu_probe)(const char *, size_t);
 	ssize_t (*cpu_release)(const char *, size_t);
 #endif
+
+#ifdef CONFIG_VIRTUALIZATION
+	int (*earlycon_setup)(void);
+	int (*enable_pci_law)(void);
+	int (*set_law_base)(int index, unsigned long long addr);
+	unsigned long long (*get_law_base)(int index);
+	int (*set_law_attr)(int index, unsigned int attr);
+	int (*get_law_attr)(int index);
+	uint32_t (*get_mdio_bus)(struct mii_bus *bus, int mii_id);
+	unsigned int (*get_direct_irq)(void);
+#endif
 };
 
 extern void e500_idle(void);
@@ -373,5 +385,7 @@ static inline void log_error(char *buf, unsigned int err_type, int fatal)
 void generic_suspend_disable_irqs(void);
 void generic_suspend_enable_irqs(void);
 
+extern unsigned int get_pvr(void);
+
 #endif /* __KERNEL__ */
 #endif /* _ASM_POWERPC_MACHDEP_H */
diff --git a/arch/powerpc/include/asm/mmu-book3e.h b/arch/powerpc/include/asm/mmu-book3e.h
index 7469581..9e1119b 100644
--- a/arch/powerpc/include/asm/mmu-book3e.h
+++ b/arch/powerpc/include/asm/mmu-book3e.h
@@ -181,6 +181,10 @@ typedef struct {
 	unsigned int	id;
 	unsigned int	active;
 	unsigned long	vdso_base;
+#ifdef CONFIG_WRHV_ASID_OPTIMIZATION
+	unsigned int	asid;
+	unsigned long	vmmu_handle;
+#endif
 } mm_context_t;
 
 /* Page size definitions, common between 32 and 64-bit
diff --git a/arch/powerpc/include/asm/page_32.h b/arch/powerpc/include/asm/page_32.h
index bd0849d..9a6bd5a 100644
--- a/arch/powerpc/include/asm/page_32.h
+++ b/arch/powerpc/include/asm/page_32.h
@@ -13,7 +13,7 @@
 #define ARCH_KMALLOC_MINALIGN	L1_CACHE_BYTES
 #endif
 
-#ifdef CONFIG_PTE_64BIT
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_PARAVIRT_PTE)
 #define PTE_FLAGS_OFFSET	4	/* offset of PTE flags, in bytes */
 #else
 #define PTE_FLAGS_OFFSET	0
@@ -30,7 +30,7 @@
  * The basic type of a PTE - 64 bits for those CPUs with > 32 bit
  * physical addressing.
  */
-#ifdef CONFIG_PTE_64BIT
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_PARAVIRT_PTE)
 typedef unsigned long long pte_basic_t;
 #else
 typedef unsigned long pte_basic_t;
diff --git a/arch/powerpc/include/asm/paravirt.h b/arch/powerpc/include/asm/paravirt.h
new file mode 100644
index 0000000..bfd9d3b
--- /dev/null
+++ b/arch/powerpc/include/asm/paravirt.h
@@ -0,0 +1,135 @@
+#ifndef __ASM_PARAVIRT_H
+#define __ASM_PARAVIRT_H
+
+#ifdef CONFIG_PARAVIRT
+/*
+ * native functions
+ */
+extern void native_do_IRQ(struct pt_regs *regs);
+extern unsigned int native_irq_of_parse_and_map(struct device_node *dev,
+						int index);
+extern unsigned int native_get_pvr(void);
+extern unsigned int native_get_svr(void);
+extern void native_timer_interrupt(struct pt_regs * regs);
+extern void __init native_time_init(void);
+extern void __init native_clocksource_init(void);
+extern void native_vmmu_restore (void);
+extern void __init native_MMU_init_hw(void);
+extern unsigned long __init native_mmu_mapin_ram(unsigned long top);
+extern void native_MMU_setup(void);
+extern void __init native_MMU_init(void);
+extern void native_flush_dcache_page(struct page *page);
+extern int native_map_page(unsigned long va, phys_addr_t pa, int flags);
+extern int native_kgdb_arch_handle_exception(int vector, int signo,
+				int err_code,
+				char *remcom_in_buffer,
+				char *remcom_out_buffer,
+				struct pt_regs *linux_regs);
+extern void __kprobes native_DebugException(struct pt_regs *regs,
+				unsigned long debug_status);
+extern void native_prime_debug_regs(struct thread_struct *thread);
+extern int __init native_early_init_dt_scan_memory_ppc(unsigned long node, 
+			const char *uname, int depth, void *data);
+extern void __init native_time_init_cont(void);
+extern void __iomem* native___ioremap(phys_addr_t addr, unsigned long size, unsigned long flags);
+extern int __attribute__((weak)) native_fsl_pq_mdio_write(struct mii_bus *bus, int mii_id,
+					int devad, int regnum, u16 value);
+extern int __attribute__((weak)) native_fsl_pq_mdio_read(struct mii_bus *bus, int mii_id,
+					int devad, int regnum);
+extern void native_udbg_init_uart(void __iomem *comport, unsigned int speed,
+		unsigned int clock);
+
+extern int native_init_new_context(struct task_struct *t, struct mm_struct *mm);
+extern void native_destroy_context(struct mm_struct *mm);
+extern void native_switch_mmu_context(struct mm_struct *prev,
+		struct mm_struct *next);
+extern void __init native_mmu_context_init(void);
+
+/*
+ * paravirtual operations structure
+ */
+struct pv_time_ops {
+	void (*time_init_cont)(void);
+	void (*timer_interrupt)(struct pt_regs *regs);
+	void (*clocksource_init)(void);
+};
+
+struct pv_cpu_ops {
+	unsigned int (*get_pvr)(void);
+	unsigned int (*get_svr)(void);
+	void (*DebugException)(struct pt_regs *regs, unsigned long debug_status);
+	void (*prime_debug_regs)(struct thread_struct *thread);
+	int (*kgdb_arch_handle_exception)(int vector, int signo, int err_code,
+                               char *remcom_in_buffer, char *remcom_out_buffer,
+                               struct pt_regs *linux_regs);
+	int (*ppc_proc_freq)(void);
+};
+
+/* general info */
+struct pv_info {
+        const char *name;
+        int paravirt_enabled;
+};
+
+struct pv_irq_ops {
+	void (*do_IRQ)(struct pt_regs *regs);
+	unsigned int (*irq_of_parse_and_map)
+		(struct device_node *dev, int index);
+};
+
+struct pv_apic_ops {
+	unsigned int (*get_irq)(void);
+	void (*do_irq)(struct pt_regs *regs);
+	int (*get_ppc_spurious_interrupts)(void);
+	void (*set_ppc_spurious_interrupts)(int value);
+	unsigned int (*irq_of_parse_and_map)
+		(struct device_node *dev, int index);
+
+};
+
+struct pv_mmu_ops {
+	void (*vmmu_restore)(void);
+	void (*MMU_init_hw)(void);
+	unsigned long (*mmu_mapin_ram)(unsigned long top);
+	void (*MMU_setup)(void);
+	void (*MMU_init)(void);
+	void (*flush_dcache_page)(struct page *page);
+	int (*map_page)(unsigned long va, phys_addr_t pa, int flags);
+	int (*early_init_dt_scan_memory_ppc)(unsigned long node,
+			const char *uname, int depth, void *data);
+	void __iomem* (*__ioremap)(phys_addr_t addr, unsigned long size, unsigned long flags);
+	void (*__set_pte_at)(struct mm_struct *mm, unsigned long addr, 
+		pte_t *ptep, pte_t pte, int percpu);
+};
+
+struct pv_mdio_ops {
+	int (*fsl_pq_mdio_write)(struct mii_bus *bus, int mii_id,
+					int devad, int regnum, u16 value);
+	int (*fsl_pq_mdio_read)(struct mii_bus *bus, int mii_id,
+					int devad, int regnum);
+};
+
+struct pv_context_ops {
+	int (*init_new_context)(struct task_struct *t, struct mm_struct *mm);
+	void (*destroy_context)(struct mm_struct *mm);
+	void (*switch_mmu_context)(struct mm_struct *prev,
+		struct mm_struct *next);
+	void (*mmu_context_init)(void);
+};
+
+struct pv_serial_ops{
+	void (*udbg_init_uart)(void __iomem *comport, unsigned int speed,
+		unsigned int clock);
+};
+
+extern struct pv_info pv_info;
+extern struct pv_time_ops pv_time_ops;
+extern struct pv_cpu_ops pv_cpu_ops;
+extern struct pv_irq_ops pv_irq_ops;
+extern struct pv_mmu_ops pv_mmu_ops;
+extern struct pv_mdio_ops pv_mdio_ops;
+extern struct pv_context_ops pv_context_ops;
+extern struct pv_serial_ops pv_serial_ops;
+
+#endif /* CONFIG_PARAVIRT */
+#endif	/* __ASM_PARAVIRT_H */
diff --git a/arch/powerpc/include/asm/pgalloc-32.h b/arch/powerpc/include/asm/pgalloc-32.h
index 580cf73..4099dff 100644
--- a/arch/powerpc/include/asm/pgalloc-32.h
+++ b/arch/powerpc/include/asm/pgalloc-32.h
@@ -20,7 +20,7 @@ extern void pgd_free(struct mm_struct *mm, pgd_t *pgd);
 #define __pmd_free_tlb(tlb,x,a)		do { } while (0)
 /* #define pgd_populate(mm, pmd, pte)      BUG() */
 
-#ifndef CONFIG_BOOKE
+#if !defined(CONFIG_BOOKE) || defined(CONFIG_PARAVIRT_PTE)
 #define pmd_populate_kernel(mm, pmd, pte)	\
 		(pmd_val(*(pmd)) = __pa(pte) | _PMD_PRESENT)
 #define pmd_populate(mm, pmd, pte)	\
diff --git a/arch/powerpc/include/asm/pgtable-ppc32.h b/arch/powerpc/include/asm/pgtable-ppc32.h
index 55646ad..faa731e 100644
--- a/arch/powerpc/include/asm/pgtable-ppc32.h
+++ b/arch/powerpc/include/asm/pgtable-ppc32.h
@@ -27,6 +27,11 @@ extern int icache_44x_need_flush;
  * are an index to the second level table.  The combined pgdir/pmd first
  * level has 2048 entries and the second level has 512 64-bit PTE entries.
  * -Matt
+ *
+ * For WRHV, the combined pgdir/pmd first level has 2 page 2048 entries
+ * and the second level has 9bit indexing into 512 elements with each element
+ * contains an 8-byte PTE
+ * -Yiming
  */
 /* PGDIR_SHIFT determines what a top-level page table entry can map */
 #define PGDIR_SHIFT	(PAGE_SHIFT + PTE_SHIFT)
@@ -107,13 +112,15 @@ extern int icache_44x_need_flush;
  * (hardware-defined) PowerPC PTE as closely as possible.
  */
 
-#if defined(CONFIG_40x)
+#if defined(CONFIG_PARAVIRT_PTE)
+#include <asm/pv_pgtable-ppc32.h>
+#elif defined(CONFIG_40x)
 #include <asm/pte-40x.h>
 #elif defined(CONFIG_44x)
 #include <asm/pte-44x.h>
 #elif defined(CONFIG_FSL_BOOKE) && defined(CONFIG_PTE_64BIT)
 #include <asm/pte-book3e.h>
-#elif defined(CONFIG_FSL_BOOKE)
+#elif defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT_PTE)
 #include <asm/pte-fsl-booke.h>
 #elif defined(CONFIG_8xx)
 #include <asm/pte-8xx.h>
@@ -164,7 +171,7 @@ extern void flush_hash_entry(struct mm_struct *mm, pte_t *ptep,
  * to properly flush the virtually tagged instruction cache of
  * those implementations.
  */
-#ifndef CONFIG_PTE_64BIT
+#if !defined(CONFIG_PTE_64BIT) && !defined(CONFIG_PARAVIRT_PTE)
 static inline unsigned long pte_update(pte_t *p,
 				       unsigned long clr,
 				       unsigned long set)
@@ -193,7 +200,7 @@ static inline unsigned long pte_update(pte_t *p,
 #endif
 	return old;
 }
-#else /* CONFIG_PTE_64BIT */
+#else /* CONFIG_PTE_64BIT && CONFIG_PARAVIRT_PTE */
 static inline unsigned long long pte_update(pte_t *p,
 					    unsigned long clr,
 					    unsigned long set)
@@ -224,13 +231,14 @@ static inline unsigned long long pte_update(pte_t *p,
 #endif
 	return old;
 }
-#endif /* CONFIG_PTE_64BIT */
+#endif /* CONFIG_PTE_64BIT && CONFIG_PARAVIRT_PTE */
 
 /*
  * 2.6 calls this without flushing the TLB entry; this is wrong
  * for our hash-based implementation, we fix that up here.
  */
 #define __HAVE_ARCH_PTEP_TEST_AND_CLEAR_YOUNG
+#ifndef CONFIG_PARAVIRT
 static inline int __ptep_test_and_clear_young(unsigned int context, unsigned long addr, pte_t *ptep)
 {
 	unsigned long old;
@@ -243,9 +251,29 @@ static inline int __ptep_test_and_clear_young(unsigned int context, unsigned lon
 #endif
 	return (old & _PAGE_ACCESSED) != 0;
 }
+#else /* CONFIG_PARAVIRT */
+static inline int __ptep_test_and_clear_young(mm_context_t * ctx,
+                                              unsigned long addr, pte_t *ptep)
+{
+	unsigned long old;
+	old = pte_update(ptep, _PAGE_ACCESSED, 0);
+#if _PAGE_HASHPTE != 0
+	if (old & _PAGE_HASHPTE) {
+		unsigned long ptephys = __pa(ptep) & PAGE_MASK;
+		flush_hash_pages(context, addr, ptephys, 1);
+	}
+#endif
+#if 0 
+        vbi_tlb_flush_vmmu (&vmmu_cfg, &addr, 1);
+#endif
+	return (old & _PAGE_ACCESSED) != 0;
+}
+#endif   /* CONFIG_PARAVIRT */
+
 #define ptep_test_and_clear_young(__vma, __addr, __ptep) \
 	__ptep_test_and_clear_young((__vma)->vm_mm->context.id, __addr, __ptep)
 
+
 #define __HAVE_ARCH_PTEP_GET_AND_CLEAR
 static inline pte_t ptep_get_and_clear(struct mm_struct *mm, unsigned long addr,
 				       pte_t *ptep)
@@ -283,7 +311,7 @@ static inline void __ptep_set_access_flags(pte_t *ptep, pte_t entry)
  * handler).  On everything else the pmd contains the physical address
  * of the pte page.  -- paulus
  */
-#ifndef CONFIG_BOOKE
+#if !defined(CONFIG_BOOKE) || defined(CONFIG_PARAVIRT_PTE)
 #define pmd_page_vaddr(pmd)	\
 	((unsigned long) __va(pmd_val(pmd) & PAGE_MASK))
 #define pmd_page(pmd)		\
@@ -315,6 +343,10 @@ static inline void __ptep_set_access_flags(pte_t *ptep, pte_t entry)
 #define pte_unmap(pte)		kunmap_atomic(pte, KM_PTE0)
 #define pte_unmap_nested(pte)	kunmap_atomic(pte, KM_PTE1)
 
+/* We will re-define that on file, arch/powerpc/include/asm/pv_pgtable-ppc32.h,
+ * since e500 guest OS should match VMMU. 
+ */
+#if !defined(CONFIG_WRHV) || defined(CONFIG_PPC85xx_VT_MODE)
 /*
  * Encode and decode a swap entry.
  * Note that the bits we use in a PTE for representing a swap entry
@@ -331,6 +363,7 @@ static inline void __ptep_set_access_flags(pte_t *ptep, pte_t entry)
 #define PTE_FILE_MAX_BITS	29
 #define pte_to_pgoff(pte)	(pte_val(pte) >> 3)
 #define pgoff_to_pte(off)	((pte_t) { ((off) << 3) | _PAGE_FILE })
+#endif
 
 /*
  * No page table caches to initialise
diff --git a/arch/powerpc/include/asm/pgtable.h b/arch/powerpc/include/asm/pgtable.h
index 89f1587..17b13ef 100644
--- a/arch/powerpc/include/asm/pgtable.h
+++ b/arch/powerpc/include/asm/pgtable.h
@@ -88,7 +88,7 @@ extern void set_pte_at(struct mm_struct *mm, unsigned long addr, pte_t *ptep,
  * an horrible mess that I'm not going to try to clean up now but
  * I'm keeping it in one place rather than spread around
  */
-static inline void __set_pte_at(struct mm_struct *mm, unsigned long addr,
+static inline void native__set_pte_at(struct mm_struct *mm, unsigned long addr,
 				pte_t *ptep, pte_t pte, int percpu)
 {
 #if defined(CONFIG_PPC_STD_MMU_32) && defined(CONFIG_SMP) && !defined(CONFIG_PTE_64BIT)
@@ -147,6 +147,18 @@ static inline void __set_pte_at(struct mm_struct *mm, unsigned long addr,
 }
 
 
+static inline void __set_pte_at(struct mm_struct *mm, unsigned long addr, 
+				pte_t *ptep, pte_t pte, int percpu)
+{
+#ifdef CONFIG_PARAVIRT
+	extern void paravirt__set_pte_at(struct mm_struct *,
+			unsigned long, pte_t *, pte_t, int);
+	paravirt__set_pte_at(mm, addr, ptep, pte, percpu);
+#else
+	native__set_pte_at(mm, addr, ptep, pte, percpu);
+#endif
+}
+
 #define __HAVE_ARCH_PTEP_SET_ACCESS_FLAGS
 extern int ptep_set_access_flags(struct vm_area_struct *vma, unsigned long address,
 				 pte_t *ptep, pte_t entry, int dirty);
diff --git a/arch/powerpc/include/asm/ppc_asm.h b/arch/powerpc/include/asm/ppc_asm.h
index 498fe09..0127eb4 100644
--- a/arch/powerpc/include/asm/ppc_asm.h
+++ b/arch/powerpc/include/asm/ppc_asm.h
@@ -339,7 +339,8 @@ END_FTR_SECTION_NESTED(CPU_FTR_CELL_TB_BUG, CPU_FTR_CELL_TB_BUG, 96)
 #define MFTB(dest)			mftb dest
 #endif
 
-#ifndef CONFIG_SMP
+#if !defined(CONFIG_SMP) || defined(CONFIG_WRHV)
+/* The hypervisor will do that. */
 #define TLBSYNC
 #else /* CONFIG_SMP */
 /* tlbsync is not implemented on 601 */
diff --git a/arch/powerpc/include/asm/processor.h b/arch/powerpc/include/asm/processor.h
index 221ba62..94e3fce 100644
--- a/arch/powerpc/include/asm/processor.h
+++ b/arch/powerpc/include/asm/processor.h
@@ -42,6 +42,12 @@
 
 #if defined(__KERNEL__) && defined(CONFIG_PPC32)
 
+#ifdef CONFIG_PARAVIRT
+extern int paravirt_enabled(void);
+#else
+#define paravirt_enabled()      0
+#endif
+
 extern int _chrp_type;
 
 #ifdef CONFIG_PPC_PREP
diff --git a/arch/powerpc/include/asm/pte-common.h b/arch/powerpc/include/asm/pte-common.h
index 76bb195..ecbb3cf 100644
--- a/arch/powerpc/include/asm/pte-common.h
+++ b/arch/powerpc/include/asm/pte-common.h
@@ -78,7 +78,7 @@ extern unsigned long bad_call_to_PMD_PAGE_SIZE(void);
 /* The mask convered by the RPN must be a ULL on 32-bit platforms with
  * 64-bit PTEs
  */
-#if defined(CONFIG_PPC32) && defined(CONFIG_PTE_64BIT)
+#if defined(CONFIG_PPC32) && defined(CONFIG_PTE_64BIT) || (defined(CONFIG_PARAVIRT) && !defined(CONFIG_PPC85xx_VT_MODE))
 #define PTE_RPN_MAX	(1ULL << (64 - PTE_RPN_SHIFT))
 #define PTE_RPN_MASK	(~((1ULL<<PTE_RPN_SHIFT)-1))
 #else
@@ -104,9 +104,14 @@ extern unsigned long bad_call_to_PMD_PAGE_SIZE(void);
  * pages. We always set _PAGE_COHERENT when SMP is enabled or
  * the processor might need it for DMA coherency.
  */
+
+#if defined(CONFIG_WRHV_E500)
+#define _PAGE_BASE_NC	(_PAGE_PRESENT | _PAGE_ACCESSED | VMMU_PROT_USER_READ)
+#else
 #define _PAGE_BASE_NC	(_PAGE_PRESENT | _PAGE_ACCESSED | _PAGE_PSIZE)
-#if defined(CONFIG_SMP) || defined(CONFIG_PPC_STD_MMU)
-#define _PAGE_BASE	(_PAGE_BASE_NC | _PAGE_COHERENT)
+#endif
+#if defined(CONFIG_SMP)
+#define _PAGE_BASE (_PAGE_BASE_NC | _PAGE_COHERENT)
 #else
 #define _PAGE_BASE	(_PAGE_BASE_NC)
 #endif
@@ -148,14 +153,20 @@ extern unsigned long bad_call_to_PMD_PAGE_SIZE(void);
 #define __S111	PAGE_SHARED_X
 
 /* Permission masks used for kernel mappings */
+#ifdef CONFIG_WRHV_E500
+#define PAGE_KERNEL	__pgprot(_PAGE_BASE | _PAGE_KERNEL_RW | _PAGE_HWEXEC)
+#define PAGE_KERNEL_X	__pgprot(_PAGE_BASE | _PAGE_KERNEL_RWX | _PAGE_HWEXEC)
+#define PAGE_KERNEL_ROX	__pgprot(_PAGE_BASE | _PAGE_KERNEL_ROX | _PAGE_HWEXEC)
+#else
 #define PAGE_KERNEL	__pgprot(_PAGE_BASE | _PAGE_KERNEL_RW)
+#define PAGE_KERNEL_X	__pgprot(_PAGE_BASE | _PAGE_KERNEL_RWX)
+#define PAGE_KERNEL_ROX	__pgprot(_PAGE_BASE | _PAGE_KERNEL_ROX)
+#endif
 #define PAGE_KERNEL_NC	__pgprot(_PAGE_BASE_NC | _PAGE_KERNEL_RW | \
 				 _PAGE_NO_CACHE)
 #define PAGE_KERNEL_NCG	__pgprot(_PAGE_BASE_NC | _PAGE_KERNEL_RW | \
 				 _PAGE_NO_CACHE | _PAGE_GUARDED)
-#define PAGE_KERNEL_X	__pgprot(_PAGE_BASE | _PAGE_KERNEL_RWX)
 #define PAGE_KERNEL_RO	__pgprot(_PAGE_BASE | _PAGE_KERNEL_RO)
-#define PAGE_KERNEL_ROX	__pgprot(_PAGE_BASE | _PAGE_KERNEL_ROX)
 
 /* Protection used for kernel text. We want the debuggers to be able to
  * set breakpoints anywhere, so don't write protect the kernel text
@@ -182,6 +193,7 @@ extern unsigned long bad_call_to_PMD_PAGE_SIZE(void);
 #define PAGE_AGP		(PAGE_KERNEL_NC)
 #define HAVE_PAGE_AGP
 
+#ifndef CONFIG_WRHV_E500
 /* Advertise support for _PAGE_SPECIAL */
 #define __HAVE_ARCH_PTE_SPECIAL
-
+#endif
diff --git a/arch/powerpc/include/asm/pv_hw_irq.h b/arch/powerpc/include/asm/pv_hw_irq.h
new file mode 100644
index 0000000..b8feb99
--- /dev/null
+++ b/arch/powerpc/include/asm/pv_hw_irq.h
@@ -0,0 +1,80 @@
+#ifndef PV_HW_IRQ_H
+#define PV_HW_IRQ_H
+
+/* set default definiation to native implemenation */
+#define raw_local_irq_restore(flags)   native_raw_local_irq_restore(flags)
+#define raw_local_irq_disable()        native_raw_local_irq_disable()
+#define raw_local_irq_enable()         native_raw_local_irq_enable()
+#define raw_local_save_flags(flags)    native_raw_local_save_flags(flags)
+#define raw_local_irq_save(flags)      native_raw_local_irq_save(flags)
+#define raw_irqs_disabled()            native_raw_irqs_disabled()
+#define raw_irqs_disabled_flags(flags) native_raw_irqs_disabled_flags(flags)
+
+#define hard_irq_disable()             native_hard_irq_disable()
+
+/* Hypervisor specific irq implementation */
+#ifdef CONFIG_WRHV
+#include <vbi/interface.h>
+extern void wrhv_int_lock(void);
+extern void wrhv_int_unlock(int lvl);
+extern int wrhv_int_lvl_get (void);
+
+#ifdef CONFIG_WRHV_E500
+#define IRQS_ENABLED 0
+#define IRQS_DISABLED -1
+#elif defined(CONFIG_WRHV_P4080DS)
+#define IRQS_ENABLED 1
+#define IRQS_DISABLED 0
+#endif
+
+/* undefine native implementation */
+#undef raw_local_irq_restore
+#undef raw_local_irq_disable
+#undef raw_local_irq_enable
+#undef raw_local_save_flags
+#undef raw_local_irq_save
+#undef raw_irqs_disabled
+#undef raw_irqs_disabled_flags
+#undef hard_irq_disable
+#undef irqs_disabled_flags
+
+/* WRHV specific static inline implementation */
+static inline void pv_local_irq_disable(void)
+{
+        wrhv_int_lock();
+}
+
+static inline void pv_local_irq_enable(void)
+{
+        wrhv_int_unlock(0);
+}
+
+static inline void pv_local_irq_save_ptr(unsigned long *flags)
+{
+        *flags = wrhv_int_lvl_get();
+        wrhv_int_lock();
+}
+
+#define raw_local_irq_disable()        pv_local_irq_disable()
+#define raw_local_irq_enable()         pv_local_irq_enable()
+
+#define raw_local_save_flags(flags)    ((flags) = wrhv_int_lvl_get())
+#define raw_local_irq_restore(flags)   (flags == IRQS_ENABLED  \
+			 ? pv_local_irq_enable() : pv_local_irq_disable ())
+#define raw_irqs_disabled_flags(flags) (flags == IRQS_DISABLED)
+#define raw_irqs_disabled()		(wrhv_int_lvl_get() == IRQS_DISABLED)
+#ifdef CONFIG_WRHV_P4080DS
+#define raw_local_irq_save(flags)      do {    \
+		flags = wrhv_int_lvl_get();     \
+		pv_local_irq_disable();         \
+	} while (IRQS_DISABLED)
+
+#elif defined(CONFIG_WRHV_E500)
+#define raw_local_irq_save(flags)      pv_local_irq_save_ptr(&flags)
+#endif
+
+#define hard_irq_disable()             raw_local_irq_disable()
+
+#endif /* CONFIG_WRHV */
+#endif /* PV_HW_IRQ_H */
+
diff --git a/arch/powerpc/include/asm/pv_pgtable-ppc32.h b/arch/powerpc/include/asm/pv_pgtable-ppc32.h
new file mode 100644
index 0000000..ba2680e
--- /dev/null
+++ b/arch/powerpc/include/asm/pv_pgtable-ppc32.h
@@ -0,0 +1,92 @@
+#ifndef _ASM_PV_DEF_PGTABLE_PPC32_H
+#define _ASM_PV_DEF_PGTABLE_PPC32_H
+
+#include <asm-generic/pgtable-nopmd.h>
+
+#ifdef CONFIG_WRHV
+#include <vbi/vmmu.h>
+#include <vbi/interface.h>
+/*
+ * refer to include/sys/vmmu.h on what format the hypervisor expects
+ * the guest OS software page table to be
+ */
+/*
+ * need extra care for _PAGE_SPECIAL -- Liang Li
+ */
+#define _PAGE_SPECIAL		0x0
+#define _PAGE_PRESENT		VMMU_PROT_SUPV_READ
+#define _PAGE_USER		(VMMU_PROT_USER_READ|VMMU_PROT_USER_EXECUTE)
+#define _PAGE_FILE      	_PAGE_USER
+#define _PAGE_ACCESSED	        VMMU_PROT_SUPV_WRITE
+#define _PAGE_HWWRITE   	VMMU_PROT_USER_WRITE
+#define	 _PAGE_RW		(VMMU_PROT_SUPV_EXECUTE|VMMU_PROT_USER_WRITE)
+#define _PAGE_HWEXEC    	VMMU_PROT_USER_EXECUTE
+
+#define _PAGE_ENDIAN		VMMU_CACHE_LE
+#define _PAGE_GUARDED		VMMU_CACHE_GUARDED
+#define _PAGE_COHERENT		VMMU_CACHE_COHERENT
+#define _PAGE_NO_CACHE		VMMU_CACHE_INHIBIT
+#define _PAGE_WRITETHRU		VMMU_CACHE_WRITETHROUGH
+
+#define _PAGE_DIRTY		VMMU_PTE_CHG_MASK
+
+#define _PAGE_EXEC		VMMU_CACHE_COHERENT
+
+/* The flag, _PAGE_FILE_, bit0, should be used to mask this pte 
+ * as nonlinear file mapping.
+ */
+#define _PTE_NONE_MASK		0xffffffff00000ffdULL
+
+/* See figure 1 located in include/vbi/vmmu.h for definition
+   of RPN (Real Page Number) and the associated shift value*/
+
+/* MAX_SWAPFILES_SHIFT is defined in include/linux/swap.h as
+   5 , but because the HV only gives us bits 0-19 of the second
+   word for each PTE, that only leaves us with 15 bits.  (32MB)
+   Given this limitation we need to reduce the number of swaptypes
+   from 5 bits to 3 therefor giving us access to 18 bits. (256MB)
+*/
+
+/* Encode and de-code a swap entry */
+/* These values need to match the native version found in
+   arch/powerpc/include/asm/pgtable-ppc32.h */
+#define __swp_type(entry)	((entry).val & 0x1f)
+
+/* When running under the HV we have a PTE therefor inorder
+   to support large amounts of swap we need to reduce the
+   maximum number of swapfile entries */
+#define __swp_offset(entry)	((entry).val >> 2)
+#define __swp_entry(type, offset) ((swp_entry_t){(type)|((offset)<<2)})
+/* Unfortunately the hypervisor's VMMU maps PTE's differently then
+   that of native */
+#define __pte_to_swp_entry(pte)	((swp_entry_t){pte_val(pte) >> VMMU_RPN_SHIFT})
+#define __swp_entry_to_pte(x)	((pte_t) { (x).val << VMMU_RPN_SHIFT })
+
+#define pte_to_pgoff(pte)	(pte_val(pte) >> VMMU_RPN_SHIFT)
+#define pgoff_to_pte(off)	((pte_t) {((off) << VMMU_RPN_SHIFT)|_PAGE_FILE})
+#define PTE_FILE_MAX_BITS	(BITS_PER_LONG - VMMU_RPN_SHIFT)
+
+/* based on hypervisor VMMU_LEVEL_1_DESC definition */
+#define _PMD_PRESENT		0x00000001   /* big endian */
+#define _PMD_PRESENT_MASK	(_PMD_PRESENT)
+#define _PMD_BAD		(~PAGE_MASK & ~0x03)
+
+#ifndef CONFIG_WRHV_E500
+#define _PAGE_BASE		(_PAGE_PRESENT | _PAGE_ACCESSED | VMMU_PROT_USER_READ)
+#endif
+
+#define PFN_SIZE		(1UL << PFN_SHIFT_OFFSET)
+#define PFN_MASK		(~(PFN_SIZE-1))
+#define pte_to_pa(x)		(pte_val(x) & PFN_MASK)
+#define pte_to_prot(x)		(pte_val(x) & (PFN_SIZE-1))
+
+/*
+ * Some bits are only used on some cpu families...
+ */
+#ifndef _PAGE_HASHPTE
+#define _PAGE_HASHPTE   0
+#endif
+#elif defined(CONFIG_FSL_BOOKE)
+#include <asm/pte-fsl-booke.h>
+#endif
+#endif /* _ASM_PV_DEF_PGTABLE_PPC32_H */
diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 8a36268..2568736 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -13,6 +13,11 @@
 #include <linux/stringify.h>
 #include <asm/cputable.h>
 
+/* Pickup paravirt specific registers */
+#if defined (CONFIG_PARAVIRT)
+#include <asm/reg_paravirt.h>
+#endif
+
 /* Pickup Book E specific registers. */
 #if defined(CONFIG_BOOKE) || defined(CONFIG_40x)
 #include <asm/reg_booke.h>
@@ -877,6 +882,36 @@
 #define PV_BE		0x0070
 #define PV_PA6T		0x0090
 
+/* machine code for accessing SPRN_DBSR and SPRN_DBCR0 */
+#define SPRN_DBSR_W 0x7c904ba6  /* mtspr SPRN_DBSR,r4 */
+#define SPRN_DBSR_R 0x7c904aa6  /* mfspr r4,SPRN_DBSR */
+#define SPRN_DBCR0_W 0x7c944ba6 /* mtspr SPRN_DBCR0,r4 */
+#define SPRN_DBCR0_R 0x7c944aa6 /* mfspr r4,SPRN_DBCR0 */
+
+/* machine code for acessing IAC1, IAC2 */
+#define SPRN_IAC1_W 0x7c984ba6 /* mtspr SPRN_IAC1,r4 */
+#define SPRN_IAC1_R 0x7c984aa6 /* mfspr r4,SPRN_IAC1 */
+#define SPRN_IAC2_W 0x7c994ba6 /* mtspr SPRN_IAC2,r4 */
+#define SPRN_IAC2_R 0x7c994aa6 /* mfspr r4,SPRN_IAC2 */
+
+/* machine code for accessing DAC1, DAC2 */
+#define SPRN_DAC1_W 0x7c9c4ba6 /* mtspr SPRN_DAC1,r4 */
+#define SPRN_DAC1_R 0x7c9c4aa6 /* mfspr r4,SPRN_DAC1 */
+#define SPRN_DAC2_W 0x7c9d4ba6 /* mtspr SPRN_DAC2,r4 */
+#define SPRN_DAC2_R 0x7c9d4aa6 /* mfspr r4,SPRN_DAC2 */
+
+/* machine code for accessing DBCR1 and DBCR2 */
+#define SPRN_DBCR1_W 0x7c954ba6 /* mtspr SPRN_DBCR1,r4 */
+#define SPRN_DBCR1_R 0x7c954aa6 /* mfspr r4,SPRN_DBCR1 */
+#define SPRN_DBCR2_W 0x7c964ba6 /* mtspr SPRN_DBCR2,r4 */
+#define SPRN_DBCR2_R 0x7c964aa6 /* mfspr r4,SPRN_DBCR2 */
+
+/* macros to encode register number into the machine code */
+#define SPRN_DBSR_W_RN(rn) (SPRN_DBSR_W & ~(0x1F<<21) | (rn<<21))
+#define SPRN_DBSR_R_RN(rn) (SPRN_DBSR_R & ~(0x1F<<21) | (rn<<21))
+#define SPRN_DBCR0_W_RN(rn) (SPRN_DBCR0_W & ~(0x1F<<21) | (rn<<21))
+#define SPRN_DBCR0_R_RN(rn) (SPRN_DBCR0_R & ~(0x1F<<21) | (rn<<21))
+
 /* Macros for setting and retrieving special purpose registers */
 #ifndef __ASSEMBLY__
 #define mfmsr()		({unsigned long rval; \
@@ -893,9 +928,9 @@
 #define mfspr(rn)	({unsigned long rval; \
 			asm volatile("mfspr %0," __stringify(rn) \
 				: "=r" (rval)); rval;})
+
 #define mtspr(rn, v)	asm volatile("mtspr " __stringify(rn) ",%0" : : "r" (v)\
 				     : "memory")
-
 #ifdef __powerpc64__
 #ifdef CONFIG_PPC_CELL
 #define mftb()		({unsigned long rval;				\
diff --git a/arch/powerpc/include/asm/reg_paravirt.h b/arch/powerpc/include/asm/reg_paravirt.h
new file mode 100644
index 0000000..b765cce
--- /dev/null
+++ b/arch/powerpc/include/asm/reg_paravirt.h
@@ -0,0 +1,22 @@
+/*
+ * Contains the definition of registers common to all PowerPC variants.
+ * If a register definition has been changed in a different PowerPC
+ * variant, we will case it in #ifndef XXX ... #endif, and have the
+ * number used in the Programming Environments Manual For 32-Bit
+ * Implementations of the PowerPC Architecture (a.k.a. Green Book) here.
+ */
+
+#ifndef _ASM_POWERPC_REG_PARAVIRT_H
+#define _ASM_POWERPC_REG_PARAVIRT_H
+#ifdef __KERNEL__
+
+/* default native macros */
+#define PARAVIRT_MFSPR_SPRG3(a) mfspr a,SPRN_SPRG3 
+
+/* pickup individual hypervisor specific regs */
+#ifdef CONFIG_WRHV
+#include <asm/reg_wrhv.h>
+#endif
+
+#endif /* __KERNEL__ */
+#endif /* _ASM_POWERPC_REG_PARAVIRT_H */
diff --git a/arch/powerpc/include/asm/reg_wrhv.h b/arch/powerpc/include/asm/reg_wrhv.h
new file mode 100644
index 0000000..33ba1e3
--- /dev/null
+++ b/arch/powerpc/include/asm/reg_wrhv.h
@@ -0,0 +1,207 @@
+/*
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2, or (at your option) any
+ *  later version.
+ *
+ *  This program is distributed in the hope that it will be useful, but
+ *  WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  General Public License for more details.
+ *
+ *  Copyright (C) 2009 Wind River Systems, Inc.
+ *
+ * Contains the definition of registers common to all PowerPC variants.
+ * If a register definition has been changed in a different PowerPC
+ * variant, we will case it in #ifndef XXX ... #endif, and have the
+ * number used in the Programming Environments Manual For 32-Bit
+ * Implementations of the PowerPC Architecture (a.k.a. Green Book) here.
+ */
+
+#ifndef _ASM_POWERPC_REG_WRHV_H
+#define _ASM_POWERPC_REG_WRHV_H
+#ifdef __KERNEL__
+
+#include <linux/stringify.h>
+#include <asm/cputable.h>
+#include <vbi/interface.h>
+#include <vbi/syscalls.h>
+
+/* macro used in on entry_32.S */
+#define PARAVIRT_ENABLE_MSR_EE      WRHV_INT_UNLOCK(r10,r11)
+#define PARAVIRT_DISABLE_MSR_EE     WRHV_INT_LOCK(r10,r3)
+
+/* macro used in misc.S */
+#undef PARAVIRT_MFSPR_SPRG3
+#define PARAVIRT_MFSPR_SPRG3(a)  WRHV_MFSPRG3(a)
+
+/* macro used in arch/powerpc/kernel/traps.c */
+#define PARAVIRT_DISABLE_INST_COMPLETION       do{ } while (0)
+#define PARAVIRT_CLEAR_INST_COMPLETION                 do{ } while (0)
+
+#ifdef __ASSEMBLY__
+#define wrhv_supervisor (0xF0002000 +VB_CONTROL_RESERVED7)
+.extern var(wrhv_sprg3)
+.extern var(wrhv_user)
+.extern var(wrhv_pir)
+
+#ifdef CONFIG_SMP
+/*temporary solution for MFSPRG3,PIR ,wrhv-reserverd:0xf0002068 */
+#define WRHY_SPRG3 (0xF0002000 + VB_CONTROL_RESERVED8)
+#define WRHV_MFSPRG3(rd)	\
+	lis	rd,WRHY_SPRG3@ha;	\
+	lwz	rd,WRHY_SPRG3@l(rd)
+
+#define WRHV_MTSPRG3(rs,tmpr)	\
+	lis	tmpr,WRHY_SPRG3@ha;             \
+	stw	rs,WRHY_SPRG3@l(tmpr)
+
+#else
+
+#if defined(CONFIG_PPC85xx_VT_MODE)
+
+#define WRHV_MFSPRG3(rd)			\
+	mfspr   rd, SPRN_SPRG3
+
+#define WRHV_MTSPRG3(rs, tmpr)			\
+	mtspr   SPRN_SPRG3, rs
+
+#ifdef CONFIG_SMP
+#define WRHV_MFPIR(rd)				\
+	mfspr   rd, SPRN_PIR
+#endif
+
+#else
+
+#define WRHV_MFSPRG3(rd)                        \
+	lis	rd,wrhv_sprg3@ha;               \
+	lwz	rd,wrhv_sprg3@l(rd)
+
+#define WRHV_MTSPRG3(rs,tmpr)                   \
+	lis	tmpr,wrhv_sprg3@ha;             \
+	stw	rs,wrhv_sprg3@l(tmpr)
+#endif
+
+#ifdef CONFIG_SMP
+#define WRHV_MFPIR(rd)				\
+	lis	rd,wrhv_pir@ha;		\
+	lwz	rd,wrhv_pir@l(rd);
+#endif
+
+#endif
+
+#ifdef CONFIG_PPC85xx_VT_MODE
+#define WRHV_INT_LOCK(tmpr1,tmpr2)			\
+	wrteei	0;
+#else
+#define WRHV_INT_LOCK(tmpr1,tmpr2)                      \
+	li	tmpr2,-1;                               \
+	lis	tmpr1,wr_control@ha;                   \
+	lwz	tmpr1,wr_control@l(tmpr1);             \
+	stw	tmpr2,VB_CONTROL_INT_DISABLE(tmpr1)
+#endif
+
+#ifdef CONFIG_PPC85xx_VT_MODE
+#define WRHV_INT_UNLOCK(tmpr1,tmpr2)			\
+	wrteei	1;					\
+	lis	tmpr1,wr_status@ha;			\
+	lwz	tmpr1,wr_status@l(tmpr1);		\
+	lwz	tmpr1,VB_STATUS_INT_PENDING(tmpr1);	\
+	cmpwi	0,tmpr1,0;				\
+	beq	1f;					\
+	mr	tmpr2,r0;				\
+	lis	r0,VBI_SYS_int_enable@h;		\
+	ori	r0,r0,VBI_SYS_int_enable@l;		\
+	sc	1;					\
+	mr	r0,tmpr2;				\
+1:
+#else
+#define WRHV_INT_UNLOCK(tmpr1,tmpr2)                    \
+	lis	tmpr1,wr_control@ha;                   \
+	lwz	tmpr1,wr_control@l(tmpr1);             \
+	li	tmpr2,0;                                \
+	stw	tmpr2,VB_CONTROL_INT_DISABLE(tmpr1);    \
+	lis	tmpr1,wr_status@ha;                    \
+	lwz	tmpr1,wr_status@l(tmpr1);              \
+	lwz	tmpr1,VB_STATUS_INT_PENDING(tmpr1);     \
+	cmpwi	0,tmpr1,0;                              \
+	beq	1f;                                     \
+	mr	tmpr1,r0;                               \
+	lis	r0,VBI_SYS_int_enable@h;                \
+	ori	r0,r0,VBI_SYS_int_enable@l;             \
+	sc;                                             \
+	mr	r0,tmpr1;                               \
+1:
+#endif
+
+#ifdef CONFIG_PPC85xx_VT_MODE
+#define WRHV_INT_LVL_GET(rd)				\
+	li	r4,1;					\
+	mfmsr	rd;					\
+	rlwinm.	rd,rd,0,16,16;      /* test EE bit */	\
+	bne	1f;					\
+	li	r4,0;					\
+1:	mr	rd,r4                                  
+#else
+#define WRHV_INT_LVL_GET(rd)                            \
+	lis	rd,wr_control@ha;                      \
+	lwz	rd,wr_control@l(rd);                   \
+	lwz	rd,VB_CONTROL_INT_DISABLE(rd)
+#endif
+
+#ifndef CONFIG_PPC85xx_VT_MODE
+#define WRHV_FIX_MSR(msr,tmpr)                                  \
+	rlwinm	msr,msr,0,18,15; /* Clear EE & PR bits */       \
+	WRHV_INT_LVL_GET(tmpr);                         \
+	cmpwi	0,tmpr,0;                                       \
+	bne	1f;                                             \
+	ori	msr,msr,MSR_EE;                                 \
+1:	lis	tmpr,wrhv_supervisor@ha;                        \
+	lwz	tmpr,wrhv_supervisor@l(tmpr);                   \
+	cmpwi	0,tmpr,0;                                       \
+	bne	2f;                                             \
+	ori	msr,msr,MSR_PR;                                 \
+2:
+
+#define WRHV_LOAD_MSR(msr,tmpr1,tmpr2)                          \
+	li	tmpr2,0;                                        \
+	rlwinm.	tmpr1,msr,0,16,16;      /* test EE bit */       \
+	bne	1f;                     /* IT unlocked? */      \
+	li	tmpr2,-1;                                       \
+1:	lis	tmpr1,wr_control@ha;                           \
+	lwz	tmpr1,wr_control@l(tmpr1);                     \
+	stw	tmpr2,VB_CONTROL_NEW_INT_DISABLE(tmpr1);        \
+	stw	msr,VB_CONTROL_SRR1(tmpr1);                     \
+	li	tmpr2,1;                                        \
+	rlwinm.	tmpr1,msr,0,17,17;      /* test PR bit */       \
+	beq	2f;                     /* priv. mode? */       \
+	li	tmpr2,0;                                        \
+2:	WRHV_SET_SUP_MODE(tmpr1,tmpr2)
+
+#define WRHV_FIX_MSR2(msr,tmpr)                         \
+	rlwinm	msr,msr,0,18,15; /* Clear EE & PR bits */       \
+	lis	tmpr,wr_status@ha;                             \
+	lwz	tmpr,wr_status@l(tmpr);                        \
+	lwz	tmpr,VB_STATUS_OLD_INT_DISABLE(tmpr);           \
+	cmpwi	0,tmpr,0;                                       \
+	bne	1f;                                             \
+	ori	msr,msr,MSR_EE;                                 \
+1:	lis	tmpr,wrhv_supervisor@ha;                        \
+	lwz	tmpr,wrhv_supervisor@l(tmpr);                   \
+	cmpwi	0,tmpr,0;                                       \
+	bne	2f;                                             \
+	ori	msr,msr,MSR_PR;                                 \
+2:
+
+#define WRHV_SET_SUP_MODE(tmpr,rs)                              \
+	lis	tmpr,wrhv_supervisor@ha;                        \
+	stw	rs,wrhv_supervisor@l(tmpr)
+
+#define WRHV_SUP_MODE_GET(rd)                                   \
+	lis	rd,wrhv_supervisor@ha;                          \
+	lwz	rd,wrhv_supervisor@l(rd)
+#endif
+#endif /* __ASSEMBLY__ */
+
+#endif /* __KERNEL__ */
+#endif /* _ASM_POWERPC_REG_WRHV_H */
diff --git a/arch/powerpc/include/asm/system.h b/arch/powerpc/include/asm/system.h
index a6297c6..216c89e 100644
--- a/arch/powerpc/include/asm/system.h
+++ b/arch/powerpc/include/asm/system.h
@@ -206,6 +206,10 @@ extern u32 booke_wdt_period;
 struct device_node;
 extern void note_scsi_host(struct device_node *, void *);
 
+#ifdef CONFIG_PARAVIRT
+#define prepare_arch_switch(next)      local_irq_disable()
+#endif
+
 extern struct task_struct *__switch_to(struct task_struct *,
 	struct task_struct *);
 #define switch_to(prev, next, last)	((last) = __switch_to((prev), (next)))
diff --git a/arch/powerpc/include/asm/time.h b/arch/powerpc/include/asm/time.h
index 27ccb76..2052e49 100644
--- a/arch/powerpc/include/asm/time.h
+++ b/arch/powerpc/include/asm/time.h
@@ -110,13 +110,16 @@ static inline u64 get_rtc(void)
 	return (u64)hi * 1000000000 + lo;
 }
 
+long long wrhv_gettb_diff(void);
+void wrhv_settb_diff(long long diff);
+
 #ifdef CONFIG_PPC64
 static inline u64 get_tb(void)
 {
 	return mftb();
 }
 #else /* CONFIG_PPC64 */
-static inline u64 get_tb(void)
+static inline u64 get_hardware_tb(void)
 {
 	unsigned int tbhi, tblo, tbhi2;
 
@@ -128,6 +131,16 @@ static inline u64 get_tb(void)
 
 	return ((u64)tbhi << 32) | tblo;
 }
+
+static inline u64 get_tb(void)
+{
+#ifndef CONFIG_WRHV
+	return get_hardware_tb();
+#else
+	return (u64)((long long)get_hardware_tb() + wrhv_gettb_diff());
+#endif
+}
+
 #endif /* !CONFIG_PPC64 */
 
 static inline u64 get_tb_or_rtc(void)
@@ -137,9 +150,14 @@ static inline u64 get_tb_or_rtc(void)
 
 static inline void set_tb(unsigned int upper, unsigned int lower)
 {
+#ifndef CONFIG_WRHV
 	mtspr(SPRN_TBWL, 0);
 	mtspr(SPRN_TBWU, upper);
 	mtspr(SPRN_TBWL, lower);
+#else
+	unsigned long long tb = ((u64)upper<<32) | lower;
+	wrhv_settb_diff((long long)tb - (long long)get_hardware_tb());
+#endif
 }
 
 /* Accessor functions for the decrementer register.
@@ -181,7 +199,9 @@ static inline void set_dec(int val)
 		return;
 	}
 #endif
+#ifndef CONFIG_WRHV
 	mtspr(SPRN_DEC, val);
+#endif
 #endif /* not 40x or 8xx_CPU6 */
 }
 
diff --git a/arch/powerpc/include/asm/udbg.h b/arch/powerpc/include/asm/udbg.h
index 11ae699..42d8a14 100644
--- a/arch/powerpc/include/asm/udbg.h
+++ b/arch/powerpc/include/asm/udbg.h
@@ -52,6 +52,7 @@ extern void __init udbg_init_44x_as1(void);
 extern void __init udbg_init_40x_realmode(void);
 extern void __init udbg_init_cpm(void);
 extern void __init udbg_init_usbgecko(void);
+extern void __init udbg_init_wrhv_duart(void);
 
 #endif /* __KERNEL__ */
 #endif /* _ASM_POWERPC_UDBG_H */
diff --git a/arch/powerpc/include/asm/wrhv.h b/arch/powerpc/include/asm/wrhv.h
new file mode 100644
index 0000000..d1baed8
--- /dev/null
+++ b/arch/powerpc/include/asm/wrhv.h
@@ -0,0 +1,73 @@
+/*
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2, or (at your option) any
+ *  later version.
+ *
+ *  This program is distributed in the hope that it will be useful, but
+ *  WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  General Public License for more details.
+ *
+ *  Copyright (C) 2008 Wind River Systems, Inc.
+ */
+
+#ifndef __ASM_WRHV_H
+#define __ASM_WRHV_H
+
+#ifdef CONFIG_WRHV
+
+/*
+ * This macro will tend to clean_dcache_range function, but
+ * we do not need to do that, so delete below macro to try
+ * native clean_dcache_range
+ */
+#define CONFIG_PARAVIRT_DCACHE_CLEAN
+
+#ifndef __ASSEMBLY__
+
+extern unsigned char *law_base;
+
+extern void wrhv_mapping(void);
+extern void wrhv_restart(char *cmd);
+extern unsigned long __init wrhv_find_end_of_memory(void);
+extern void wrhv_power_save(void);
+extern unsigned int wrhv_vioapic_get_irq(void);
+extern void wrhv_init_irq(void);
+extern void __init wrhv_calibrate_decr(void);
+extern void __init wrhv_time_init(void);
+extern int __init wrhv_earlycon_setup(void);
+extern void wrhv_setup_msr_for_ap(VBI_HREG_SET_CMPLX_QUALIFIED *);
+
+extern int __init smp_wrhv_probe(void);
+extern void smp_wrhv_message_pass(int target, int msg);
+extern void __init smp_wrhv_setup_cpu(int cpu_nr);
+extern void wrhv_umask_IPIs_for_vcore(void);
+extern void wrhv_request_ipis(void);
+extern unsigned long wrhv_cpu_freq;
+
+extern uint32_t service_handle;
+extern void get_hv_bsp_server_handle(void);
+extern int get_bsp_clock_freq(void);
+
+extern void ppc_setup_law(unsigned int target_id, unsigned long long addr, unsigned int attr);
+extern int ppc_search_free_law(int target_id);
+extern int ppc_setup_pci_law(struct device_node *dev);
+
+#ifdef CONFIG_PCI
+extern int wrhv_enable_pci_law(void);
+#endif
+
+extern unsigned int wrhv_get_direct_irq(void);
+
+/* following extern functions is implemented in wrhv.c
+ * to access hypervisor serial driver
+ */
+extern void wrhv_duart_putc(char c);
+extern int wrhv_duart_tstc(void);
+extern int wrhv_duart_getc(void);
+extern int wrhv_duart_init(void);
+
+#endif /* __ASSEMBLY__ */
+#endif /* CONFIG_WRHV */
+#endif /* __ASM_WRHV_H */
diff --git a/arch/powerpc/kernel/Makefile b/arch/powerpc/kernel/Makefile
index 9189556..5240041 100644
--- a/arch/powerpc/kernel/Makefile
+++ b/arch/powerpc/kernel/Makefile
@@ -65,6 +65,20 @@ obj-$(CONFIG_HIBERNATION)	+= swsusp_$(CONFIG_WORD_SIZE).o
 endif
 obj64-$(CONFIG_HIBERNATION)	+= swsusp_asm64.o
 obj-$(CONFIG_MODULES)		+= module.o module_$(CONFIG_WORD_SIZE).o
+
+ifeq ($(CONFIG_WRHV),y)
+entry = wrhv_entry_32.o
+endif
+ifeq ($(CONFIG_PPC85xx_VT_MODE),y)
+entry = entry_32.o
+endif
+
+obj-$(CONFIG_WRHV)		+= $(entry) wrhv_misc_32.o
+
+ifeq ($(CONFIG_PARAVIRT),y)
+obj-$(CONFIG_PARAVIRT)          += paravirt_entry_32.o paravirt_misc_32.o
+endif
+
 obj-$(CONFIG_44x)		+= cpu_setup_44x.o
 obj-$(CONFIG_FSL_BOOKE)		+= cpu_setup_fsl_booke.o dbell.o
 obj-$(USE_IMMEDIATE)		+= immediate.o
@@ -73,7 +87,17 @@ extra-y				:= head_$(CONFIG_WORD_SIZE).o
 extra-$(CONFIG_PPC_BOOK3E_32)	:= head_new_booke.o
 extra-$(CONFIG_40x)		:= head_40x.o
 extra-$(CONFIG_44x)		:= head_44x.o
-extra-$(CONFIG_FSL_BOOKE)	:= head_fsl_booke.o
+
+ifeq ($(CONFIG_WRHV),y)
+ifeq ($(CONFIG_WRHV_P4080DS),y)
+extra-$(CONFIG_WRHV)		:= head_wrhv_p4080.o
+else
+extra-$(CONFIG_WRHV)		:= head_wrhv.o
+endif
+else
+extra-$(CONFIG_FSL_BOOKE)		:= head_fsl_booke.o
+endif
+
 extra-$(CONFIG_8xx)		:= head_8xx.o
 extra-y				+= vmlinux.lds
 
@@ -115,6 +139,9 @@ obj-$(CONFIG_FSL_EMB_PERF_EVENT_E500) += e500-pmu.o
 
 obj-$(CONFIG_8XX_MINIMAL_FPEMU) += softemu8xx.o
 
+obj-$(CONFIG_WRHV)		+= vbi/
+obj-$(CONFIG_PARAVIRT)         += paravirt.o
+
 ifneq ($(CONFIG_PPC_INDIRECT_IO),y)
 obj-y				+= iomap.o
 endif
diff --git a/arch/powerpc/kernel/cpu_setup_fsl_booke.S b/arch/powerpc/kernel/cpu_setup_fsl_booke.S
index 0adb50a..e40d9b2 100644
--- a/arch/powerpc/kernel/cpu_setup_fsl_booke.S
+++ b/arch/powerpc/kernel/cpu_setup_fsl_booke.S
@@ -17,6 +17,7 @@
 #include <asm/cputable.h>
 #include <asm/ppc_asm.h>
 
+#ifndef CONFIG_WRHV
 _GLOBAL(__e500_icache_setup)
 	mfspr	r0, SPRN_L1CSR1
 	andi.	r3, r0, L1CSR1_ICE
@@ -51,6 +52,32 @@ _GLOBAL(__e500_dcache_setup)
 	isync
 	blr
 
+#else
+/* Only weak for WRHV. */
+	.globl	__e500_icache_setup
+__e500_icache_setup:
+	blr
+
+	.globl	__e500_dcache_setup
+__e500_dcache_setup:
+	blr
+
+	.weak	__setup_e200_ivors
+	.globl	__setup_e200_ivors
+__setup_e200_ivors:
+	blr
+
+	.weak	__setup_e500_ivors
+	.globl	__setup_e500_ivors
+__setup_e500_ivors:
+	blr
+
+	.weak	__setup_e500mc_ivors
+	.globl	__setup_e500mc_ivors
+__setup_e500mc_ivors:
+	blr
+#endif
+
 _GLOBAL(__setup_cpu_e200)
 	/* enable dedicated debug exception handling resources (Debug APU) */
 	mfspr	r3,SPRN_HID0
diff --git a/arch/powerpc/kernel/dma.c b/arch/powerpc/kernel/dma.c
index 6c1df57..c9e4c35 100644
--- a/arch/powerpc/kernel/dma.c
+++ b/arch/powerpc/kernel/dma.c
@@ -13,6 +13,10 @@
 #include <asm/bug.h>
 #include <asm/abs_addr.h>
 
+#ifdef CONFIG_WRHV
+#include <vbi/vbi.h>
+#endif
+
 /*
  * Generic direct DMA implementation
  *
@@ -27,6 +31,9 @@ void *dma_direct_alloc_coherent(struct device *dev, size_t size,
 				dma_addr_t *dma_handle, gfp_t flag)
 {
 	void *ret;
+#ifdef CONFIG_WRHV
+	u64 paddr;
+#endif
 #ifdef CONFIG_NOT_COHERENT_CACHE
 	ret = __dma_alloc_coherent(dev, size, dma_handle, flag);
 	if (ret == NULL)
@@ -45,7 +52,16 @@ void *dma_direct_alloc_coherent(struct device *dev, size_t size,
 		return NULL;
 	ret = page_address(page);
 	memset(ret, 0, size);
+#ifdef CONFIG_WRHV
+	if (vbi_get_guest_dma_addr((ret + get_dma_offset(dev)), &paddr) == 0) {
+		*dma_handle = (dma_addr_t)paddr;
+	} else {
+		free_pages((unsigned long)ret, get_order(size));
+		ret = NULL;
+	}
+#else
 	*dma_handle = virt_to_abs(ret) + get_dma_offset(dev);
+#endif
 
 	return ret;
 #endif
@@ -67,9 +83,19 @@ static int dma_direct_map_sg(struct device *dev, struct scatterlist *sgl,
 {
 	struct scatterlist *sg;
 	int i;
+#ifdef CONFIG_WRHV
+	u64 paddr;
+	u32 ptr;
+#endif
 
 	for_each_sg(sgl, sg, nents, i) {
+#ifdef CONFIG_WRHV
+		ptr = sg_phys(sg) + get_dma_offset(dev);
+		vbi_get_guest_dma_addr((void *)ptr, &paddr);
+		sg->dma_address = (dma_addr_t)paddr;
+#else
 		sg->dma_address = sg_phys(sg) + get_dma_offset(dev);
+#endif
 		sg->dma_length = sg->length;
 		__dma_sync_page(sg_page(sg), sg->offset, sg->length, direction);
 	}
@@ -102,9 +128,19 @@ static inline dma_addr_t dma_direct_map_page(struct device *dev,
 					     enum dma_data_direction dir,
 					     struct dma_attrs *attrs)
 {
+#ifdef CONFIG_WRHV
+	u64 paddr;
+	u32 ptr;
+#endif
 	BUG_ON(dir == DMA_NONE);
 	__dma_sync_page(page, offset, size, dir);
+#ifdef CONFIG_WRHV
+	ptr = (u32)page_to_phys(page) + offset + get_dma_offset(dev);
+	vbi_get_guest_dma_addr((void *)ptr, &paddr);
+	return (dma_addr_t)paddr;
+#else
 	return page_to_phys(page) + offset + get_dma_offset(dev);
+#endif
 }
 
 static inline void dma_direct_unmap_page(struct device *dev,
diff --git a/arch/powerpc/kernel/entry_32.S b/arch/powerpc/kernel/entry_32.S
index a04c471..4725424 100644
--- a/arch/powerpc/kernel/entry_32.S
+++ b/arch/powerpc/kernel/entry_32.S
@@ -32,8 +32,10 @@
 #include <asm/unistd.h>
 #include <asm/ftrace.h>
 
+#ifndef CONFIG_PARAVIRT
 #undef SHOW_SYSCALLS
 #undef SHOW_SYSCALLS_TASK
+#endif
 
 /*
  * MSR_KERNEL is > 0x10000 on 4xx/Book-E since it include MSR_CE.
@@ -44,6 +46,25 @@
 #define LOAD_MSR_KERNEL(r, x)	li r,(x)
 #endif
 
+/* native macros */
+#define ENABLE_MSR_EE  ori r10,r10,MSR_EE; SYNC; MTMSRD(r10);
+#define DISABLE_MSR_EE LOAD_MSR_KERNEL(r10,MSR_KERNEL); SYNC; MTMSRD(r10);
+
+/* paravirt overrides */
+#ifdef CONFIG_PARAVIRT
+#ifdef PARAVIRT_ENABLE_MSR_EE
+#undef ENABLE_MSR_EE
+#define ENABLE_MSR_EE PARAVIRT_ENABLE_MSR_EE
+#endif
+#endif
+
+#ifdef CONFIG_PARAVIRT
+#ifdef PARAVIRT_DISABLE_MSR_EE
+#undef DISABLE_MSR_EE
+#define DISABLE_MSR_EE PARAVIRT_DISABLE_MSR_EE
+#endif
+#endif
+
 #ifdef CONFIG_BOOKE
 	.globl	mcheck_transfer_to_handler
 mcheck_transfer_to_handler:
@@ -130,6 +151,13 @@ transfer_to_handler_full:
 
 	.globl	transfer_to_handler
 transfer_to_handler:
+#ifndef CONFIG_PARAVIRT
+	b       native_transfer_to_handler
+#else
+	b       paravirt_transfer_to_handler
+#endif
+	.globl  native_transfer_to_handler
+native_transfer_to_handler:
 	stw	r2,GPR2(r11)
 	stw	r12,_NIP(r11)
 	stw	r9,_MSR(r11)
@@ -144,7 +172,7 @@ transfer_to_handler:
 	beq	2f			/* if from user, fix up THREAD.regs */
 	addi	r11,r1,STACK_FRAME_OVERHEAD
 	stw	r11,PT_REGS(r12)
-#if defined(CONFIG_40x) || defined(CONFIG_BOOKE)
+#if defined(CONFIG_40x) || defined(CONFIG_BOOKE) && !defined(CONFIG_PARAVIRT)
 	/* Check to see if the dbcr0 register is set up to debug.  Use the
 	   internal debug mode bit to do this. */
 	lwz	r12,THREAD_DBCR0(r12)
@@ -337,6 +365,13 @@ syscall_dotrace_cont:
 	blrl			/* Call handler */
 	.globl	ret_from_syscall
 ret_from_syscall:
+#ifndef CONFIG_PARAVIRT
+	b       native_ret_from_syscall
+#else
+	b       paravirt_ret_from_syscall
+#endif 
+	.globl  native_ret_from_syscall
+native_ret_from_syscall:
 #ifdef SHOW_SYSCALLS
 	bl	do_show_syscall_exit
 #endif
@@ -371,7 +406,7 @@ syscall_exit_cont:
 	lwz	r3,GPR3(r1)
 1:
 #endif /* CONFIG_TRACE_IRQFLAGS */
-#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE)
+#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE) && !(CONFIG_PARAVIRT)
 	/* If the process has its own DBCR0 value, load it up.  The internal
 	   debug mode bit tells us that dbcr0 should be loaded. */
 	lwz	r0,THREAD+THREAD_DBCR0(r2)
@@ -440,7 +475,15 @@ syscall_dotrace:
 	REST_NVGPRS(r1)
 	b	syscall_dotrace_cont
 
+	.globl  syscall_exit_work
 syscall_exit_work:
+#ifndef CONFIG_PARAVIRT
+	b       native_syscall_exit_work
+#else
+	b       paravirt_syscall_exit_work
+#endif
+	.globl  native_syscall_exit_work
+native_syscall_exit_work:
 	andi.	r0,r9,_TIF_RESTOREALL
 	beq+	0f
 	REST_NVGPRS(r1)
@@ -644,6 +687,13 @@ handle_page_fault:
  * in arch/ppc/kernel/process.c
  */
 _GLOBAL(_switch)
+#ifndef CONFIG_PARAVIRT
+	b	native_switch
+#else
+	b	paravirt_switch
+#endif
+
+_GLOBAL(native_switch)
 	stwu	r1,-INT_FRAME_SIZE(r1)
 	mflr	r0
 	stw	r0,INT_FRAME_SIZE+4(r1)
@@ -790,9 +840,7 @@ ret_from_except:
 	 * can't change between when we test it and when we return
 	 * from the interrupt. */
 	/* Note: We don't bother telling lockdep about it */
-	LOAD_MSR_KERNEL(r10,MSR_KERNEL)
-	SYNC			/* Some chip revs have problems here... */
-	MTMSRD(r10)		/* disable interrupts */
+	DISABLE_MSR_EE
 
 	lwz	r3,_MSR(r1)	/* Returning to user mode? */
 	andi.	r0,r3,MSR_PR
@@ -806,7 +854,7 @@ user_exc_return:		/* r10 contains MSR_KERNEL here */
 	bne	do_work
 
 restore_user:
-#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE)
+#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE) && !defined(CONFIG_PARAVIRT)
 	/* Check whether this process has its own DBCR0 value.  The internal
 	   debug mode bit tells us that dbcr0 should be loaded. */
 	lwz	r0,THREAD+THREAD_DBCR0(r2)
@@ -853,6 +901,13 @@ resume_kernel:
 
 	/* interrupts are hard-disabled at this point */
 restore:
+#ifndef CONFIG_PARAVIRT
+	b       native_restore
+#else
+	b       paravirt_restore
+#endif
+
+_GLOBAL(native_restore)
 #ifdef CONFIG_44x
 	lis	r4,icache_44x_need_flush@ha
 	lwz	r5,icache_44x_need_flush@l(r4)
@@ -1135,7 +1190,16 @@ ret_from_prog_exc:
  * having first saved away the global DBCR0.  Note that r0
  * has the dbcr0 value to set upon entry to this.
  */
+	.globl  load_dbcr0
 load_dbcr0:
+#ifndef CONFIG_PARAVIRT
+	b	native_load_dbcr0
+#else
+	b	paravirt_load_dbcr0
+#endif
+
+	.globl native_load_dbcr0
+native_load_dbcr0:
 	mfmsr	r10		/* first disable debug exceptions */
 	rlwinm	r10,r10,0,~MSR_DE
 	mtmsr	r10
@@ -1160,6 +1224,7 @@ load_dbcr0:
 
 	.section .bss
 	.align	4
+	.globl	global_dbcr0
 global_dbcr0:
 	.space	8*NR_CPUS
 	.previous
@@ -1173,18 +1238,14 @@ do_resched:			/* r10 contains MSR_KERNEL here */
 	/* Note: We don't need to inform lockdep that we are enabling
 	 * interrupts here. As far as it knows, they are already enabled
 	 */
-	ori	r10,r10,MSR_EE
-	SYNC
-	MTMSRD(r10)		/* hard-enable interrupts */
+	ENABLE_MSR_EE
 	bl	schedule
 recheck:
 	/* Note: And we don't tell it we are disabling them again
 	 * neither. Those disable/enable cycles used to peek at
 	 * TI_FLAGS aren't advertised.
 	 */
-	LOAD_MSR_KERNEL(r10,MSR_KERNEL)
-	SYNC
-	MTMSRD(r10)		/* disable interrupts */
+	DISABLE_MSR_EE
 	rlwinm	r9,r1,0,0,(31-THREAD_SHIFT)
 	lwz	r9,TI_FLAGS(r9)
 	andi.	r0,r9,_TIF_NEED_RESCHED
@@ -1192,9 +1253,7 @@ recheck:
 	andi.	r0,r9,_TIF_USER_WORK_MASK
 	beq	restore_user
 do_user_signal:			/* r10 contains MSR_KERNEL here */
-	ori	r10,r10,MSR_EE
-	SYNC
-	MTMSRD(r10)		/* hard-enable interrupts */
+	ENABLE_MSR_EE
 	/* save r13-r31 in the exception frame, if not already done */
 	lwz	r3,_TRAP(r1)
 	andi.	r0,r3,1
diff --git a/arch/powerpc/kernel/head_booke.h b/arch/powerpc/kernel/head_booke.h
index a2a6a38..0363822 100644
--- a/arch/powerpc/kernel/head_booke.h
+++ b/arch/powerpc/kernel/head_booke.h
@@ -81,7 +81,7 @@
 
 #define EXC_LVL_FRAME_OVERHEAD	(THREAD_SIZE - INT_FRAME_SIZE - EXC_LVL_SIZE)
 
-#ifdef CONFIG_SMP
+#if defined(CONFIG_SMP) && !defined(CONFIG_PARAVIRT) 
 #define BOOKE_LOAD_EXC_LEVEL_STACK(level)		\
 	mfspr	r8,SPRN_PIR;				\
 	slwi	r8,r8,2;				\
diff --git a/arch/powerpc/kernel/head_wrhv.S b/arch/powerpc/kernel/head_wrhv.S
new file mode 100644
index 0000000..2992a79
--- /dev/null
+++ b/arch/powerpc/kernel/head_wrhv.S
@@ -0,0 +1,948 @@
+/*
+ * Kernel execution entry point code.
+ *
+ *    Copyright (c) 1995-1996 Gary Thomas <gdt@linuxppc.org>
+ *	Initial PowerPC version.
+ *    Copyright (c) 1996 Cort Dougan <cort@cs.nmt.edu>
+ *	Rewritten for PReP
+ *    Copyright (c) 1996 Paul Mackerras <paulus@cs.anu.edu.au>
+ *	Low-level exception handers, MMU support, and rewrite.
+ *    Copyright (c) 1997 Dan Malek <dmalek@jlc.net>
+ *	PowerPC 8xx modifications.
+ *    Copyright (c) 1998-1999 TiVo, Inc.
+ *	PowerPC 403GCX modifications.
+ *    Copyright (c) 1999 Grant Erickson <grant@lcse.umn.edu>
+ *	PowerPC 403GCX/405GP modifications.
+ *    Copyright 2000 MontaVista Software Inc.
+ *	PPC405 modifications
+ *	PowerPC 403GCX/405GP modifications.
+ *	Author: MontaVista Software, Inc.
+ *		frank_rowand@mvista.com or source@mvista.com
+ *		debbie_chu@mvista.com
+ *    Copyright 2002-2004 MontaVista Software, Inc.
+ *	PowerPC 44x support, Matt Porter <mporter@kernel.crashing.org>
+ *    Copyright 2004, 2008-2009 Freescale Semiconductor, Inc
+ *	PowerPC e500 modifications, Kumar Gala <galak@kernel.crashing.org>
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ */
+
+#include <linux/init.h>
+#include <linux/threads.h>
+#include <asm/processor.h>
+#include <asm/page.h>
+#include <asm/mmu.h>
+#include <asm/pgtable.h>
+#include <asm/cputable.h>
+#include <asm/thread_info.h>
+#include <asm/ppc_asm.h>
+#include <asm/asm-offsets.h>
+#include <asm/cache.h>
+#include "head_booke.h"
+#include <asm/ppc-opcode.h>
+
+#include "head_wrhv.h"
+#include <vbi/interface.h>
+#include <vbi/vmmu.h>
+#include <vbi/syscalls.h>
+
+/* As with the other PowerPC ports, it is expected that when code
+ * execution begins here, the following registers contain valid, yet
+ * optional, information:
+ *
+ *   r3 - Board info structure pointer (DRAM, frequency, MAC address, etc.)
+ *   r4 - Starting address of the init RAM disk
+ *   r5 - Ending address of the init RAM disk
+ *   r6 - Start of kernel command line string (e.g. "mem=128")
+ *   r7 - End of kernel command line string
+ *
+ */
+	__HEAD
+_ENTRY(_stext);
+_ENTRY(_start);
+	/*
+	 * Reserve a word at a fixed location to store the address
+	 * of abatron_pteptrs
+	 */
+	nop
+/*
+ * Save parameters we are passed
+ */
+	mr	r31,r3
+	mr	r30,r4
+	mr	r29,r5
+	mr	r28,r6
+	mr	r27,r7
+	li	r25,0		/* phys kernel start (low) */
+	li	r24,0		/* CPU number */
+	li	r23,0		/* phys kernel start (high) */
+
+/* We try to not make any assumptions about how the boot loader
+ * setup or used the TLBs.  We invalidate all mappings from the
+ * boot loader and load a single entry in TLB1[0] to map the
+ * first 64M of kernel memory.  Any boot info passed from the
+ * bootloader needs to live in this first 64M.
+ *
+ * Requirement on bootloader:
+ *  - The page we're executing in needs to reside in TLB1 and
+ *    have IPROT=1.  If not an invalidate broadcast could
+ *    evict the entry we're currently executing in.
+ *
+ *  r3 = Index of TLB1 were executing in
+ *  r4 = Current MSR[IS]
+ *  r5 = Index of TLB1 temp mapping
+ *
+ * Later in mapin_ram we will correctly map lowmem, and resize TLB1[0]
+ * if needed
+ */
+
+_ENTRY(__early_start)
+
+	/* Establish the interrupt vector base */
+	lis	r0,VBI_SYS_hyIoctl@h
+	ori     r0,r0,VBI_SYS_hyIoctl@l
+	lis	r3,VBI_HYIOCTL_EXCBASE@h
+	ori	r3,r3,VBI_HYIOCTL_EXCBASE@l
+	lis	r4,_start@h
+	ori	r4,r4,_start@l
+	sc
+
+#ifdef CONFIG_SMP
+	/* Check to see if we're the second processor, and jump
+	 * to the secondary_start code if so
+	 */
+	lis	r24, 0xF0000000@h
+	ori	r24, r24, 0xF0000000@l
+	lwz	r24, WRHV_COREID_OFFSET(r24)
+	cmpwi	r24,0
+	bne	__secondary_start
+#endif
+
+
+	/* ptr to current */
+	lis	r2,init_task@h
+	ori	r2,r2,init_task@l
+
+	li	r4,1
+	WRHV_SET_SUP_MODE(r1,r4)
+	/* ptr to current thread */
+	addi	r4,r2,THREAD	/* init task's THREAD */
+	WRHV_MTSPRG3(r4,r1)
+
+	/* stack */
+	lis	r1,init_thread_union@h
+	ori	r1,r1,init_thread_union@l
+	li	r0,0
+	stwu	r0,THREAD_SIZE-STACK_FRAME_OVERHEAD(r1)
+
+	/*
+	 * Move the calls to SET_IVOR(...) out of line, since they will
+	 * push us past 0x100 and hence CriticalInput will align up at
+	 * 0x200 instead, which breaks MILS.  Also, since SET_IVOR uses
+	 * blr itself, we use two b, instead of a bl + blr combo.
+	 */
+	b	set_ivors
+done_ivors:
+	bl	early_init
+
+#ifdef CONFIG_RELOCATABLE
+	lis	r3,kernstart_addr@ha
+	la	r3,kernstart_addr@l(r3)
+#ifdef CONFIG_PHYS_64BIT
+	stw	r23,0(r3)
+	stw	r25,4(r3)
+#else
+	stw	r25,0(r3)
+#endif
+#endif
+
+/*
+ * Decide what sort of machine this is and initialize the MMU.
+ */
+	mr	r3,r31
+	mr	r4,r30
+	mr	r5,r29
+	mr	r6,r28
+	mr	r7,r27
+	bl	machine_init
+	bl	MMU_init
+
+	/* Let's move on */
+	b	start_kernel	/* change context and jump to start_kernel */
+
+/* Macros to hide the PTE size differences
+ *
+ * FIND_PTE -- walks the page tables given EA & pgdir pointer
+ *   r10 -- EA of fault
+ *   r11 -- PGDIR pointer
+ *   r12 -- free
+ *   label 2: is the bailout case
+ *
+ * if we find the pte (fall through):
+ *   r11 is low pte word
+ *   r12 is pointer to the pte
+ */
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_WRHV)
+#define FIND_PTE	\
+	rlwinm	r12, r10, 13, 19, 29;	/* Compute pgdir/pmd offset */	\
+	lwzx	r11, r12, r11;		/* Get pgd/pmd entry */		\
+	rlwinm.	r12, r11, 0, 0, 20;	/* Extract pt base address */	\
+	rlwimi	r12, r10, 23, 20, 28;	/* Compute pte address */
+
+#define LOAD_PTE \
+	lwz	r11, 4(r12);
+
+#ifdef CONFIG_SMP
+#define LWARX_PTE \
+	li	r11, 4;
+	lwarx	r11, r11, r12;		/* lwarx pte */
+
+#define STWCX_PTE \
+	addi	r12, r12, 4;	\
+	stwcx.	r11, 0, r12;	\
+	addi	r12, r12, -4;
+#else
+#define LWARX_PTE \
+	lwz	r11, 4(r12)
+
+#define STWCX_PTE \
+	stw	r11, 4(r12)
+#endif
+
+#else
+#define FIND_PTE	\
+	rlwimi	r11, r10, 12, 20, 29;	/* Create L1 (pgdir/pmd) address */	\
+	lwz	r11, 0(r11);		/* Get L1 entry */			\
+	rlwinm.	r12, r11, 0, 0, 19;	/* Extract L2 (pte) base address */	\
+	beq	2f;			/* Bail if no table */			\
+	rlwimi	r12, r10, 22, 20, 29;	/* Compute PTE address */		\
+	lwz	r11, 0(r12);		/* Get Linux PTE */
+#endif
+
+/*
+ * Interrupt vector entry code
+ *
+ * The Book E MMUs are always on so we don't need to handle
+ * interrupts in real mode as with previous PPC processors. In
+ * this case we handle interrupts in the kernel virtual address
+ * space.
+ *
+ * Interrupt vectors are dynamically placed relative to the
+ * interrupt prefix as determined by the address of interrupt_base.
+ * The interrupt vectors offsets are programmed using the labels
+ * for each interrupt vector entry.
+ *
+ * Interrupt vectors must be aligned on a 16 byte boundary.
+ * We align on a 32 byte cache line boundary for good measure.
+ */
+interrupt_base:
+	/* Critical Input Interrupt */
+	CRITICAL_EXCEPTION(0x0100, CriticalInput, unknown_exception)
+
+	/* Machine Check Interrupt */
+	MCHECK_EXCEPTION(0x0200, MachineCheck, machine_check_exception)
+
+	/* Data Storage Interrupt */
+	START_EXCEPTION(DataStorage)
+
+       /*    only  r3, r4, CR are saved in vb_status */
+        lis     r4,wr_control@ha
+        lwz     r4,wr_control@l(r4)
+        stw     r10,VB_CONTROL_R10(r4)
+        stw     r11,VB_CONTROL_R11(r4)
+        stw     r12,VB_CONTROL_R12(r4)
+        stw     r13,VB_CONTROL_R13(r4)
+
+        /*
+         * Check if it was a store fault, if not then bail
+         * because a user tried to access a kernel or
+         * read-protected page.  Otherwise, get the
+         * offending address and handle it.
+         */
+        lis     r11,wr_status@ha
+        lwz     r11,wr_status@l(r11)
+        lwz     r10,VB_STATUS_ESR(r11)
+        srwi    r10,r10,16    /* get the hibit of ESR_ST */
+        andis.  r10, r10, ESR_ST@h
+        beq     2f
+
+        lwz     r10,VB_STATUS_DEAR(r11)
+
+        /* If we are faulting a kernel address, we have to use the
+         * kernel page tables.
+         */
+        lis     r11, PAGE_OFFSET@h
+        cmplw   0, r10, r11
+        bge     2f
+
+        /* Get the PGD for the current thread */
+3:
+        WRHV_MFSPRG3(r11)
+        lwz     r11,PGDIR(r11)
+4:
+	FIND_PTE
+
+	beq     2f      /* Bail if there's no entry */
+5:
+        LOAD_PTE
+
+        /* Are _PAGE_USER & _PAGE_RW set & _PAGE_HWWRITE not? */
+        andi.   r13, r11, _PAGE_RW|_PAGE_USER|_PAGE_HWWRITE
+        cmpwi   0, r13, _PAGE_RW|_PAGE_USER
+        bne     2f                      /* Bail if not */
+
+        /* update search PID in MAS6, AS = 0 */
+        mfspr   r13, SPRN_PID0
+        slwi    r13, r13, 16
+        mtspr   SPRN_MAS6, r13
+
+        /* find the TLB index that caused the fault. */
+        tlbsx   0, r10
+
+#if defined(CONFIG_SMP)
+        /*
+         * It's possible another processor kicked out the entry
+         * before we did our tlbsx, so check if we hit
+         */
+        mfspr   r13, SPRN_MAS1
+        rlwinm. r13,r13, 0, 0, 0;       /* Check the Valid bit */
+        beq     2f
+#endif /* CONFIG_SMP */
+
+        /*
+         * MAS2 not updated as the entry does exist in the tlb, this
+         * fault taken to detect state transition (eg: COW -> DIRTY)
+         */
+        andi.   r13, r11, _PAGE_HWEXEC
+        rlwimi  r13, r13, 31, 27, 27    /* SX <- _PAGE_HWEXEC */
+        ori     r13, r13, (MAS3_UW|MAS3_SW|MAS3_UR|MAS3_SR)@l /* set static perms */
+
+        /* only update the perm bits, assume the RPN is fine */
+        mfspr   r10, SPRN_MAS3
+        rlwimi  r10, r13, 0, 20, 31
+        mtspr   SPRN_MAS3,r10
+        tlbwe
+
+#if defined(CONFIG_SMP)
+        mr      r13, r11
+        LWARX_PTE
+        cmpw    r13, r11
+        bne-    7f
+#endif
+
+        /* Update 'changed'. */
+        ori     r11, r11, _PAGE_DIRTY|_PAGE_ACCESSED|_PAGE_HWWRITE
+        STWCX_PTE       /* r11 and r12 must be PTE and &PTE */
+
+#if defined(CONFIG_SMP)
+        /*
+         * If the stwcx. failed, we invalidate the entry we just wrote,
+         * and start over
+         */
+        beq+    6f
+7:      mfspr   r13, SPRN_MAS1
+        rlwinm  r13, r13, 0, 1, 31      /* Clear Valid bit */
+        mtspr   SPRN_MAS1, r13
+
+        tlbwe
+
+        b       5b              /* Try again */
+#endif  /* CONFIG_SMP */
+6:
+
+        /* Done...restore registers and get out of here.  */
+        mfspr   r11, SPRN_SPRG7R
+        mtcr    r11
+        mfspr   r13, SPRN_SPRG5R
+        mfspr   r12, SPRN_SPRG4R
+        mfspr   r11, SPRN_SPRG1
+        mfspr   r10, SPRN_SPRG0
+        rfi                     /* Force context change */
+
+2:
+#if defined(CONFIG_SMP)
+        /* Clear the reservation */
+        lis     r11, dummy_stwcx@h
+        ori     r11,r11, dummy_stwcx@l
+        stwcx.  r11, 0, r11
+#endif
+
+        /*
+         * The bailout.  Restore registers to pre-exception conditions
+         * and call the heavyweights to help us out.
+         */
+        lis     r11,wr_control@ha
+        lwz     r11,wr_control@l(r11)
+        lwz     r13,VB_CONTROL_R13(r11)
+        lwz     r12,VB_CONTROL_R12(r11)
+        lwz     r10,VB_CONTROL_R10(r11)
+        lwz     r11,VB_CONTROL_R11(r11)
+        b       data_access
+
+        /* Instruction Storage Interrupt */
+        INSTRUCTION_STORAGE_EXCEPTION
+
+	/* External Input Interrupt */
+	EXCEPTION(0x0500, ExternalInput, do_IRQ, EXC_XFER_LITE)
+
+	/* Alignment Interrupt */
+	ALIGNMENT_EXCEPTION
+
+	/* Program Interrupt */
+	PROGRAM_EXCEPTION
+
+	/* Floating Point Unavailable Interrupt */
+#ifdef CONFIG_PPC_FPU
+	EXCEPTION(0x0800, FloatingPointUnavailableErrata, program_check_exception, EXC_XFER_EE)
+#else
+	EXCEPTION(0x0800, FloatingPointUnavailable, unknown_exception, EXC_XFER_EE)
+#endif
+
+	/* System Call Interrupt */
+	START_EXCEPTION(SystemCall)
+	NORMAL_EXCEPTION_PROLOG
+	EXC_XFER_EE_LITE(0x0c00, DoSyscall)
+
+	/* Auxillary Processor Unavailable Interrupt */
+	EXCEPTION(0x2900, AuxillaryProcessorUnavailable, unknown_exception, EXC_XFER_EE)
+
+	/* Decrementer Interrupt */
+	DECREMENTER_EXCEPTION
+
+	/* Fixed Internal Timer Interrupt */
+	/* TODO: Add FIT support */
+	EXCEPTION(0x3100, FixedIntervalTimer, unknown_exception, EXC_XFER_EE)
+
+	/* Watchdog Timer Interrupt */
+#ifdef CONFIG_BOOKE_WDT
+	CRITICAL_EXCEPTION(0x3200, WatchdogTimer, WatchdogException)
+#else
+	CRITICAL_EXCEPTION(0x3200, WatchdogTimer, unknown_exception)
+#endif
+
+	/* Data TLB Error Interrupt */
+	START_EXCEPTION(DataTLBError)
+	b	data_access
+
+        /* Instruction TLB Error Interrupt */
+        /*
+         * Nearly the same as above, except we get our
+         * information from different registers and bailout
+         * to a different point.
+         */
+        START_EXCEPTION(InstructionTLBError)
+        b       InstructionStorage
+
+	/* Debug Interrupt */
+	DEBUG_DEBUG_EXCEPTION
+#ifdef CONFIG_SPE
+	/* SPE Unavailable */
+	START_EXCEPTION(SPEUnavailable)
+	NORMAL_EXCEPTION_PROLOG
+	beq	load_up_spe
+	addi	r3,r1,STACK_FRAME_OVERHEAD
+	EXC_XFER_EE_LITE(0x2010, KernelSPE)
+#else
+	EXCEPTION(0x2020, SPEUnavailable, unknown_exception, EXC_XFER_EE)
+#endif /* CONFIG_SPE */
+
+	/* SPE Floating Point Data */
+#ifdef CONFIG_SPE
+	EXCEPTION(0x2030, SPEFloatingPointData, SPEFloatingPointException, EXC_XFER_EE);
+	/* SPE Floating Point Round */
+	EXCEPTION(0x2050, SPEFloatingPointRound, SPEFloatingPointRoundException, EXC_XFER_EE)
+#else
+	EXCEPTION(0x2040, SPEFloatingPointData, unknown_exception, EXC_XFER_EE)
+	EXCEPTION(0x2050, SPEFloatingPointRound, unknown_exception, EXC_XFER_EE)
+#endif /* CONFIG_SPE */
+
+	/* Performance Monitor */
+	EXCEPTION(0x2060, PerformanceMonitor, performance_monitor_exception, EXC_XFER_STD)
+
+	EXCEPTION(0x2070, Doorbell, doorbell_exception, EXC_XFER_STD)
+
+	CRITICAL_EXCEPTION(0x2080, CriticalDoorbell, unknown_exception)
+
+	/* Debug Crit Interrupt */
+	DEBUG_CRIT_EXCEPTION
+
+/*
+ * Local functions
+ */
+
+/*
+ * Both the instruction and data TLB miss get to this
+ * point to load the TLB.
+ *	r10 - available to use
+ *	r11 - TLB (info from Linux PTE)
+ *	r12 - available to use
+ *	r13 - upper bits of PTE (if PTE_64BIT) or available to use
+ *	CR5 - results of addr >= PAGE_OFFSET
+ *	MAS0, MAS1 - loaded with proper value when we get here
+ *	MAS2, MAS3 - will need additional info from Linux PTE
+ *	Upon exit, we reload everything and RFI.
+ */
+finish_tlb_load:
+	/*
+	 * We set execute, because we don't have the granularity to
+	 * properly set this at the page level (Linux problem).
+	 * Many of these bits are software only.  Bits we don't set
+	 * here we (properly should) assume have the appropriate value.
+	 */
+
+	mfspr	r12, SPRN_MAS2
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_WRHV)
+	rlwimi	r12, r11, 32-19, 27, 31	/* extract WIMGE from pte */
+#else
+	rlwimi	r12, r11, 26, 27, 31	/* extract WIMGE from pte */
+#endif
+	mtspr	SPRN_MAS2, r12
+
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_WRHV)
+	rlwinm	r12, r11, 32-2, 26, 31	/* Move in perm bits */
+	andi.	r10, r11, _PAGE_DIRTY
+	bne	1f
+	li	r10, MAS3_SW | MAS3_UW
+	andc	r12, r12, r10
+1:	rlwimi	r12, r13, 20, 0, 11	/* grab RPN[32:43] */
+	rlwimi	r12, r11, 20, 12, 19	/* grab RPN[44:51] */
+	mtspr	SPRN_MAS3, r12
+BEGIN_MMU_FTR_SECTION
+	srwi	r10, r13, 12		/* grab RPN[12:31] */
+	mtspr	SPRN_MAS7, r10
+END_MMU_FTR_SECTION_IFSET(MMU_FTR_BIG_PHYS)
+#else
+	li	r10, (_PAGE_EXEC | _PAGE_PRESENT)
+	rlwimi	r10, r11, 31, 29, 29	/* extract _PAGE_DIRTY into SW */
+	and	r12, r11, r10
+	andi.	r10, r11, _PAGE_USER	/* Test for _PAGE_USER */
+	slwi	r10, r12, 1
+	or	r10, r10, r12
+	iseleq	r12, r12, r10
+	rlwimi	r11, r12, 0, 20, 31	/* Extract RPN from PTE and merge with perms */
+	mtspr	SPRN_MAS3, r11
+#endif
+
+	tlbwe
+
+	/* Done...restore registers and get out of here.  */
+	mfspr	r11, SPRN_SPRG7R
+	mtcr	r11
+	mfspr	r13, SPRN_SPRG5R
+	mfspr	r12, SPRN_SPRG4R
+	mfspr   r11, SPRN_SPRG1
+	mfspr   r10, SPRN_SPRG0
+	rfi					/* Force context change */
+
+
+        /*
+         * Data TLB exceptions will bail out to this point
+         * if they can't resolve the lightweight TLB fault.
+         */
+data_access:
+        NORMAL_EXCEPTION_PROLOG
+        lis     r6,wr_status@ha
+        lwz     r6,wr_status@l(r6)
+        lwz     r5, VB_STATUS_ESR(r6)
+        stw     r5,_ESR(r11)
+        lwz     r4, VB_STATUS_DEAR(r6)
+        andis.  r10,r5,(ESR_ILK|ESR_DLK)@h
+        bne     1f
+        EXC_XFER_EE_LITE(0x0300, handle_page_fault)
+1:
+        addi    r3,r1,STACK_FRAME_OVERHEAD
+        EXC_XFER_EE_LITE(0x0300, CacheLockingException)
+
+
+
+#ifdef CONFIG_SPE
+/* Note that the SPE support is closely modeled after the AltiVec
+ * support.  Changes to one are likely to be applicable to the
+ * other!  */
+load_up_spe:
+/*
+ * Disable SPE for the task which had SPE previously,
+ * and save its SPE registers in its thread_struct.
+ * Enables SPE for use in the kernel on return.
+ * On SMP we know the SPE units are free, since we give it up every
+ * switch.  -- Kumar
+ */
+	stw	r2,GPR2(r11)
+	stw	r12,_NIP(r11)
+	stw	r9,_MSR(r11)
+	mfctr	r12
+	mfspr	r2,SPRN_XER
+	stw	r12,_CTR(r11)
+	stw	r2,_XER(r11)
+
+	li r3, 1
+	li r4,(SPEFSCR_FINVE | SPEFSCR_FDBZE | SPEFSCR_FUNFE | SPEFSCR_FOVFE)
+	lis r0,VBI_SYS_spefscr_update@h
+	ori r0,r0,VBI_SYS_spefscr_update@l
+	sc
+
+/*
+ * For SMP, we don't do lazy SPE switching because it just gets too
+ * horrendously complex, especially when a task switches from one CPU
+ * to another.  Instead we call giveup_spe in switch_to.
+ */
+#ifndef CONFIG_SMP
+	lis	r3,last_task_used_spe@ha
+	lwz	r4,last_task_used_spe@l(r3)
+	cmpi	0,r4,0
+	beq	1f
+	addi	r4,r4,THREAD	/* want THREAD of last_task_used_spe */
+	SAVE_32EVRS(0,r10,r4)
+	evxor	evr10, evr10, evr10	/* clear out evr10 */
+	evmwumiaa evr10, evr10, evr10	/* evr10 <- ACC = 0 * 0 + ACC */
+	li	r5,THREAD_ACC
+	evstddx	evr10, r4, r5		/* save off accumulator */
+	lwz	r5,PT_REGS(r4)
+	lwz	r4,_MSR-STACK_FRAME_OVERHEAD(r5)
+	lis	r10,MSR_SPE@h
+	andc	r4,r4,r10	/* disable SPE for previous task */
+	stw	r4,_MSR-STACK_FRAME_OVERHEAD(r5)
+1:
+#endif /* !CONFIG_SMP */
+	WRHV_MFSPRG3(r5)		/* current task's THREAD (phys) */
+	li	r4,1
+	li	r10,THREAD_ACC
+	stw	r4,THREAD_USED_SPE(r5)
+	evlddx	evr4,r10,r5
+	evmra	evr4,evr4
+	REST_32EVRS(0,r10,r5)
+#ifndef CONFIG_SMP
+	subi	r4,r5,THREAD
+	stw	r4,last_task_used_spe@l(r3)
+#endif /* !CONFIG_SMP */
+
+	/* restore registers and return */
+	lis	r4,wr_control@ha
+	lwz	r4,wr_control@l(r4)
+	lwz	r0,GPR0(r1)
+	stw	r0,VB_CONTROL_R0(r4)
+	lwz	r2,GPR2(r1)
+	lwz	r3,GPR3(r1)
+	lwz	r6,GPR6(r1)
+	lwz	r7,GPR7(r1)
+	lwz	r8,GPR8(r1)
+	lwz	r9,GPR9(r1)
+	lwz	r10,GPR10(r1)
+	lwz	r11,GPR11(r1)
+
+	lis	r12,wr_status@ha
+	lwz	r12,wr_status@l(r12)
+	lwz	r5,VB_STATUS_OLD_INT_DISABLE(r12)
+	stw	r5,VB_CONTROL_NEW_INT_DISABLE(r4)
+
+	lwz	r0,_CCR(r1)
+	stw	r0,VB_CONTROL_CR(r4)
+	lwz	r0,_NIP(r1)
+	stw	r0,VB_CONTROL_SRR0(r4)
+	lwz	r0,_LINK(r1)
+	mtlr	r0
+	lwz	r0,_XER(r1)
+	mtspr	SPRN_XER,r0
+	lwz	r0,_CTR(r1)
+	mtctr	r0
+	lwz	r0,_MSR(r1)
+	/* enable use of SPE after return */
+	oris	r0,r0,MSR_SPE@h
+	WRHV_LOAD_MSR(r0,r12,r5)
+	lwz	r12,GPR12(r1)
+	lwz	r5,GPR5(r1)
+
+	lwz	r4,GPR4(r1)
+	lwz	r1,GPR1(r1)
+	lis	r0,VBI_SYS_ctx_load@h
+	ori	r0,r0,VBI_SYS_ctx_load@l
+	sc
+
+/*
+ * SPE unavailable trap from kernel - print a message, but let
+ * the task use SPE in the kernel until it returns to user mode.
+ */
+KernelSPE:
+	lwz	r3,_MSR(r1)
+	oris	r3,r3,MSR_SPE@h
+	stw	r3,_MSR(r1)	/* enable use of SPE after return */
+#ifdef CONFIG_PRINTK
+	lis	r3,87f@h
+	ori	r3,r3,87f@l
+	mr	r4,r2		/* current */
+	lwz	r5,_NIP(r1)
+	bl	printk
+#endif
+	b	ret_from_except
+#ifdef CONFIG_PRINTK
+87:	.string	"SPE used in kernel  (task=%p, pc=%x)  \n"
+#endif
+	.align	4,0
+
+#endif /* CONFIG_SPE */
+
+/*
+ * Set the interrupt vector offset to the exec table
+ * r3 - the interrupt vector number
+ * r4 - the vector handler label
+ */
+set_exec_table:
+	lis	r5,exec_table@h
+	ori	r5,r5,exec_table@l
+	slwi	r3,r3,2
+	subis	r4,r4,PAGE_OFFSET@h
+	stwx	r4,r3,r5
+	blr
+
+/*
+ * Establish the interrupt vector offsets.  Since SET_IVOR
+ * is itself using bl+blr into set_exec_table above, we just
+ * use absolute branches to labels to get here and back.  It
+ * is kept out-of-line so that CriticalInput can be at 0x100.
+ */
+set_ivors:
+	SET_IVOR(0,  CriticalInput);
+	SET_IVOR(1,  MachineCheck);
+	SET_IVOR(2,  DataStorage);
+	SET_IVOR(3,  InstructionStorage);
+	SET_IVOR(4,  ExternalInput);
+	SET_IVOR(5,  Alignment);
+	SET_IVOR(6,  Program);
+	SET_IVOR(7,  FloatingPointUnavailable);
+	SET_IVOR(8,  SystemCall);
+	SET_IVOR(9,  AuxillaryProcessorUnavailable);
+	SET_IVOR(10, Decrementer);
+	SET_IVOR(11, FixedIntervalTimer);
+	SET_IVOR(12, WatchdogTimer);
+	SET_IVOR(13, DataTLBError);
+	SET_IVOR(14, InstructionTLBError);
+	SET_IVOR(15, DebugDebug);
+	SET_IVOR(32, SPEUnavailable);
+	SET_IVOR(33, SPEFloatingPointData);
+	SET_IVOR(34, SPEFloatingPointRound);
+	SET_IVOR(35, PerformanceMonitor);
+	SET_IVOR(36, doorbell_exception);
+	SET_IVOR(37, CriticalDoorbell);
+	b done_ivors
+
+/*
+ * Global functions
+ */
+
+/*
+ * extern void giveup_altivec(struct task_struct *prev)
+ *
+ * The e500 core does not have an AltiVec unit.
+ */
+_GLOBAL(giveup_altivec)
+	blr
+
+#if defined(CONFIG_SPE) && defined(CONFIG_WRHV)
+/*
+ * extern void giveup_spe(struct task_struct *prev)
+ *
+ */
+_GLOBAL(giveup_spe)
+	stwu	r1,-INT_FRAME_SIZE(r1)
+	mflr	r0
+	stw	r0,INT_FRAME_SIZE+4(r1)
+	SAVE_GPR(3,r1)
+
+	li	r3, 1			/* enable SPE */
+	li	r4,(SPEFSCR_FINVE | SPEFSCR_FDBZE | SPEFSCR_FUNFE | \
+			SPEFSCR_FOVFE)
+	lis	r0,VBI_SYS_spefscr_update@h
+	ori	r0,r0,VBI_SYS_spefscr_update@l
+	sc
+
+	REST_GPR(3,r1)
+	addi	r1,r1,INT_FRAME_SIZE
+
+	cmpi	0,r3,0
+	beqlr-				/* if no previous owner, done */
+	addi	r3,r3,THREAD		/* want THREAD of task */
+	lwz	r5,PT_REGS(r3)
+	cmpi	0,r5,0
+	SAVE_32EVRS(0, r4, r3)
+	evxor	evr6, evr6, evr6	/* clear out evr6 */
+	evmwumiaa evr6, evr6, evr6	/* evr6 <- ACC = 0 * 0 + ACC */
+	li	r4,THREAD_ACC
+	evstddx	evr6, r4, r3		/* save off accumulator */
+
+	lis	r6,wr_status@ha
+	lwz     r6,wr_status@l(r6)
+	lwz	r6,VB_STATUS_SPEFSCR(r6)
+	stw	r6,THREAD_SPEFSCR(r3)	/* save spefscr register value */
+	beq	1f
+	lwz	r4,_MSR-STACK_FRAME_OVERHEAD(r5)
+	lis	r3,MSR_SPE@h
+	andc	r4,r4,r3		/* disable SPE for previous task */
+	stw	r4,_MSR-STACK_FRAME_OVERHEAD(r5)
+1:
+#ifndef CONFIG_SMP
+	li	r5,0
+	lis	r4,last_task_used_spe@ha
+	stw	r5,last_task_used_spe@l(r4)
+#endif /* !CONFIG_SMP */
+	blr
+#endif /* CONFIG_SPE */
+
+/*
+ * extern void giveup_fpu(struct task_struct *prev)
+ *
+ * Not all FSL Book-E cores have an FPU
+ */
+#ifndef CONFIG_PPC_FPU
+_GLOBAL(giveup_fpu)
+	blr
+#endif
+
+/*
+ * extern void abort(void)
+ *
+ * At present, this routine just applies a system reset.
+ */
+_GLOBAL(abort)
+	li	r13,0
+	mtspr	SPRN_DBCR0,r13		/* disable all debug events */
+	isync
+	mfmsr	r13
+	ori	r13,r13,MSR_DE@l	/* Enable Debug Events */
+	mtmsr	r13
+	isync
+	mfspr	r13,SPRN_DBCR0
+	lis	r13,(DBCR0_IDM|DBCR0_RST_CHIP)@h
+	mtspr	SPRN_DBCR0,r13
+	isync
+
+#ifndef CONFIG_WRHV_E500
+_GLOBAL(set_context)
+
+#ifdef CONFIG_BDI_SWITCH
+	/* Context switch the PTE pointer for the Abatron BDI2000.
+	 * The PGDIR is the second parameter.
+	 */
+	lis	r5, abatron_pteptrs@h
+	ori	r5, r5, abatron_pteptrs@l
+	stw	r4, 0x4(r5)
+#endif
+	mtspr	SPRN_PID,r3
+	isync			/* Force context change */
+	blr
+#endif
+
+_GLOBAL(flush_dcache_L1)
+	mfspr	r3,SPRN_L1CFG0
+
+	rlwinm	r5,r3,9,3	/* Extract cache block size */
+	twlgti	r5,1		/* Only 32 and 64 byte cache blocks
+				 * are currently defined.
+				 */
+	li	r4,32
+	subfic	r6,r5,2		/* r6 = log2(1KiB / cache block size) -
+				 *      log2(number of ways)
+				 */
+	slw	r5,r4,r5	/* r5 = cache block size */
+
+	rlwinm	r7,r3,0,0xff	/* Extract number of KiB in the cache */
+	mulli	r7,r7,13	/* An 8-way cache will require 13
+				 * loads per set.
+				 */
+	slw	r7,r7,r6
+
+	/* save off HID0 and set DCFA */
+	mfspr	r8,SPRN_HID0
+	ori	r9,r8,HID0_DCFA@l
+	mtspr	SPRN_HID0,r9
+	isync
+
+	lis	r4,KERNELBASE@h
+	mtctr	r7
+
+1:	lwz	r3,0(r4)	/* Load... */
+	add	r4,r4,r5
+	bdnz	1b
+
+	msync
+	lis	r4,KERNELBASE@h
+	mtctr	r7
+
+1:	dcbf	0,r4		/* ...and flush. */
+	add	r4,r4,r5
+	bdnz	1b
+
+	/* restore HID0 */
+	mtspr	SPRN_HID0,r8
+	isync
+
+	blr
+
+#ifdef CONFIG_SMP
+/* When we get here, r24 needs to hold the CPU # */
+	.globl __secondary_start
+__secondary_start:
+	lis	r3,__secondary_hold_acknowledge@h
+	ori	r3,r3,__secondary_hold_acknowledge@l
+	stw	r24,0(r3)
+
+	li	r3,0
+	mr	r4,r24		/* Why? */
+	bl	call_setup_cpu
+
+	/* get current_thread_info and current */
+	lis	r1,secondary_ti@ha
+	lwz	r1,secondary_ti@l(r1)
+	lwz	r2,TI_TASK(r1)
+
+	/* stack */
+	addi	r1,r1,THREAD_SIZE-STACK_FRAME_OVERHEAD
+	li	r0,0
+	stw	r0,0(r1)
+
+	li	r4,1
+	WRHV_SET_SUP_MODE(r3,r4)
+
+	/* ptr to current thread */
+	addi	r4,r2,THREAD	/* address of our thread_struct */
+	WRHV_MTSPRG3(r4,r3)
+
+	/* Jump to start_secondary */
+	b	wrhv_start_secondary
+	sync
+
+	.globl __secondary_hold_acknowledge
+__secondary_hold_acknowledge:
+	.long	-1
+#endif
+
+/*
+ * We put a few things here that have to be page-aligned. This stuff
+ * goes at the beginning of the data segment, which is page-aligned.
+ */
+	.data
+	.align	12
+	.globl	sdata
+sdata:
+	.globl	empty_zero_page
+empty_zero_page:
+	.space	4096
+	.globl	swapper_pg_dir
+swapper_pg_dir:
+	.space	8192
+/*
+ * We need a place to stwcx. to when we want to clear a reservation
+ * without knowing where the original was.
+ */
+	.globl	dummy_stwcx
+dummy_stwcx:
+	.space	4
+
+/*
+ * Room for two PTE pointers, usually the kernel and current user pointers
+ * to their respective root page table.
+ */
+abatron_pteptrs:
+	.space	8
diff --git a/arch/powerpc/kernel/head_wrhv.h b/arch/powerpc/kernel/head_wrhv.h
new file mode 100644
index 0000000..2133805
--- /dev/null
+++ b/arch/powerpc/kernel/head_wrhv.h
@@ -0,0 +1,166 @@
+/*
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2, or (at your option) any
+ *  later version.
+ *
+ *  This program is distributed in the hope that it will be useful, but
+ *  WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  General Public License for more details.
+ *
+ *  Copyright (C) 2008 Wind River Systems, Inc.
+ */
+
+#ifndef __HEAD_WRHV_H__
+#define __HEAD_WRHV_H__
+
+#include <asm/arch_vbi.h>
+
+#ifdef	CONFIG_PPC85xx_VT_MODE
+#define TLBWE_CODE	0x7C0007A4
+#define TLBSX_CODE	0x7c005724
+#endif
+
+#define WRHV_COREID_OFFSET	0x98
+
+	/* Interrupts are disabled by hypervisor at this entry point.
+	 * It puts the following registers into the status page:
+	 *   VB_STATUS_OLD_INT_DISABLE (the INT_DISABLE from Control)
+	 *   CR register
+	 *   SRR0 register - pc at time of interrupt
+	 *   SRR1 register - msr at time of interrupt
+	 *   LR register - link register at time of interrupt
+	 *   R3 register - R3 at time of interrupt
+	 *   R4 register - R4 at time of interrupt
+	 * When code in this macro has been executed, r9 contains MSR, r12 pc
+	 * r10 is trashed and r11 pointer on interrupt frame. All other
+	 * registers contain their value before the system call was executed.
+	 */
+#ifndef	CONFIG_PPC85xx_VT_MODE
+#ifdef CONFIG_WRHV_ASID_OPTIMIZATION
+#define ASID_OPT							\
+	lis     r9,wr_control@ha;					\
+	lwz     r9,wr_control@l(r9);					\
+	lwz     r12,VB_STATUS_VMMU0(r4);				\
+	stw     r12,VB_CONTROL_VMMU0(r9);				\
+	lwz     r12,VB_STATUS_VMMU_HANDLE(r4);				\
+	stw     r12,VB_CONTROL_VMMU_HANDLE(r9);				\
+	lwz     r12,VB_STATUS_ASID(r4);					\
+	stw     r12,VB_CONTROL_ASID(r9)
+#else
+#define ASID_OPT							\
+	nop
+#endif
+#undef NORMAL_EXCEPTION_PROLOG
+#define NORMAL_EXCEPTION_PROLOG						     \
+        mr      r4,r1;                                                       \
+        WRHV_SUP_MODE_GET(r3);         /* check whether user or kernel */   \
+        cmpwi   0,r3,0;                                                 \
+        bne     1f;                                                          \
+        WRHV_MFSPRG3(r1);              /* if from user, start at top of   */\
+        lwz     r1,THREAD_INFO-THREAD(r1); /* this thread's kernel stack   */\
+        addi    r1,r1,THREAD_SIZE;                                           \
+1:      subi    r1,r1,INT_FRAME_SIZE;   /* Allocate an exception frame     */\
+        mr      r3,r1;                                                       \
+        stw     r0,GPR0(r3);                                                 \
+        stw     r4,GPR1(r3);                                                 \
+        stw     r4,0(r3);                                                    \
+        SAVE_4GPRS(5, r3);                                                   \
+        SAVE_4GPRS(9, r3);                                                   \
+        mr      r11,r3;                                                      \
+        lis     r4,wr_status@ha;                                           \
+        lwz     r4,wr_status@l(r4);                                        \
+        lwz     r12,VB_STATUS_LR(r4);                                        \
+        stw     r12,_LINK(r11);                                              \
+        lwz     r12,VB_STATUS_R3(r4);                                        \
+        stw     r12,GPR3(r11);                                               \
+        lwz     r12,VB_STATUS_R4(r4);                                        \
+        stw     r12,GPR4(r11);                                               \
+        lwz     r12,VB_STATUS_CR(r4);                                        \
+        stw     r12,_CCR(r11);                                               \
+        ASID_OPT;                                                            \
+        lwz     r9,VB_STATUS_SRR1(r4);                                       \
+	rlwinm  r9,r9,0,18,15; /* Clear EE & PR bits */                      \
+	mr	r12, r4;                                                     \
+        lwz     r12,VB_STATUS_OLD_INT_DISABLE(r12);                          \
+        cmpwi   0,r12,0;                                                     \
+        bne     2f;                                                          \
+        ori     r9,r9,MSR_EE;                                                \
+2:      lis     r12,wrhv_supervisor@ha;                                     \
+        lwz     r12,wrhv_supervisor@l(r12);                                \
+        cmpwi   0,r12,0;                                                     \
+        bne     3f;                                                          \
+        ori     r9,r9,MSR_PR;                                                \
+3:      li      r12,1;                                                       \
+        WRHV_SET_SUP_MODE(r3,r12);                                          \
+        lwz     r12,VB_STATUS_SRR0(r4);                                      \
+        lwz     r3,VB_STATUS_R3(r4);                                         \
+        mr      r10,r4;                                                      \
+        lwz     r4,VB_STATUS_R4(r4)
+#endif
+
+/*
+ * Macros used for set Book-e exception table
+*/
+#undef SET_IVOR
+#define SET_IVOR(vector_number, vector_label)		\
+	li	r3,vector_number@l;			\
+	lis	r4,vector_label@h;			\
+	ori	r4,r4,vector_label@l;			\
+	bl	set_exec_table
+
+#undef DEBUG_DEBUG_EXCEPTION
+#define DEBUG_DEBUG_EXCEPTION						      \
+	START_EXCEPTION(DebugDebug);						\
+	NORMAL_EXCEPTION_PROLOG;					\
+	mr      r4,r12;                /* Pass SRR0 as arg2 */		\
+	lwz     r5,VB_STATUS_ESR(r10);					\
+	stw     r5,_ESR(r11);						\
+	addi    r3,r1,STACK_FRAME_OVERHEAD;				\
+	/* EXC_XFER_STD(0x1000, DebugException)	*/		\
+	EXC_XFER_TEMPLATE(DebugException, 0x2008, (MSR_KERNEL & ~(MSR_ME|MSR_DE|MSR_CE)), NOCOPY, transfer_to_handler_full, ret_from_except_full)
+
+#ifndef CONFIG_PPC85xx_VT_MODE
+#undef INSTRUCTION_STORAGE_EXCEPTION
+#define INSTRUCTION_STORAGE_EXCEPTION					      \
+	START_EXCEPTION(InstructionStorage)				      \
+	NORMAL_EXCEPTION_PROLOG;					      \
+	mr      r4,r12;                /* Pass SRR0 as arg2 */                \
+        lwz     r5,VB_STATUS_ESR(r10);                                        \
+        stw     r5,_ESR(r11);                                                 \
+        li      r5,0;                   /* Pass zero as arg3 */               \
+	EXC_XFER_EE_LITE(0x0400, handle_page_fault)
+
+#undef ALIGNMENT_EXCEPTION
+#define ALIGNMENT_EXCEPTION							\
+	START_EXCEPTION(Alignment)						\
+	NORMAL_EXCEPTION_PROLOG;						\
+	lwz r5,VB_STATUS_DEAR(r10);						\
+	stw r5,_DEAR(r11);							\
+	addi r3,r1,STACK_FRAME_OVERHEAD;					\
+	EXC_XFER_EE(0x0600, alignment_exception)
+
+#undef PROGRAM_EXCEPTION
+#define PROGRAM_EXCEPTION						      \
+	START_EXCEPTION(Program)					      \
+	NORMAL_EXCEPTION_PROLOG;					      \
+	mr      r4,r12;               /* Pass SRR0 as arg2 */                \
+        lwz     r5,VB_STATUS_ESR(r10);                                        \
+	stw	r5,_ESR(r11);						      \
+	addi	r3,r1,STACK_FRAME_OVERHEAD;				      \
+	EXC_XFER_STD(0x0700, program_check_exception)
+#endif
+
+#undef DECREMENTER_EXCEPTION
+#define DECREMENTER_EXCEPTION						      \
+	START_EXCEPTION(Decrementer)					      \
+	NORMAL_EXCEPTION_PROLOG;					      \
+	addi    r3,r1,STACK_FRAME_OVERHEAD;				      \
+	EXC_XFER_LITE(0x0900, timer_interrupt)
+
+
+/* ensure this structure is always sized to a multiple of the stack alignment */
+#define STACK_EXC_LVL_FRAME_SIZE	_ALIGN_UP(sizeof (struct exception_regs), 16)
+
+#endif /* __HEAD_BOOKE_H__ */
diff --git a/arch/powerpc/kernel/head_wrhv_p4080.S b/arch/powerpc/kernel/head_wrhv_p4080.S
new file mode 100644
index 0000000..7c22fc5
--- /dev/null
+++ b/arch/powerpc/kernel/head_wrhv_p4080.S
@@ -0,0 +1,908 @@
+/*
+ * Kernel execution entry point code.
+ *
+ *    Copyright (c) 1995-1996 Gary Thomas <gdt@linuxppc.org>
+ *	Initial PowerPC version.
+ *    Copyright (c) 1996 Cort Dougan <cort@cs.nmt.edu>
+ *	Rewritten for PReP
+ *    Copyright (c) 1996 Paul Mackerras <paulus@cs.anu.edu.au>
+ *	Low-level exception handers, MMU support, and rewrite.
+ *    Copyright (c) 1997 Dan Malek <dmalek@jlc.net>
+ *	PowerPC 8xx modifications.
+ *    Copyright (c) 1998-1999 TiVo, Inc.
+ *	PowerPC 403GCX modifications.
+ *    Copyright (c) 1999 Grant Erickson <grant@lcse.umn.edu>
+ *	PowerPC 403GCX/405GP modifications.
+ *    Copyright 2000 MontaVista Software Inc.
+ *	PPC405 modifications
+ *	PowerPC 403GCX/405GP modifications.
+ *	Author: MontaVista Software, Inc.
+ *		frank_rowand@mvista.com or source@mvista.com
+ *		debbie_chu@mvista.com
+ *    Copyright 2002-2004 MontaVista Software, Inc.
+ *	PowerPC 44x support, Matt Porter <mporter@kernel.crashing.org>
+ *    Copyright 2004, 2008-2009 Freescale Semiconductor, Inc
+ *	PowerPC e500 modifications, Kumar Gala <galak@kernel.crashing.org>
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ */
+
+#include <linux/init.h>
+#include <linux/threads.h>
+#include <asm/processor.h>
+#include <asm/page.h>
+#include <asm/mmu.h>
+#include <asm/pgtable.h>
+#include <asm/cputable.h>
+#include <asm/thread_info.h>
+#include <asm/ppc_asm.h>
+#include <asm/asm-offsets.h>
+#include <asm/cache.h>
+#include "head_booke.h"
+#include <asm/ppc-opcode.h>
+
+#include "head_wrhv.h"
+#include <vbi/interface.h>
+#include <vbi/vmmu.h>
+#include <vbi/syscalls.h>
+
+/* As with the other PowerPC ports, it is expected that when code
+ * execution begins here, the following registers contain valid, yet
+ * optional, information:
+ *
+ *   r3 - Board info structure pointer (DRAM, frequency, MAC address, etc.)
+ *   r4 - Starting address of the init RAM disk
+ *   r5 - Ending address of the init RAM disk
+ *   r6 - Start of kernel command line string (e.g. "mem=128")
+ *   r7 - End of kernel command line string
+ *
+ */
+	__HEAD
+_ENTRY(_stext);
+_ENTRY(_start);
+	/*
+	 * Reserve a word at a fixed location to store the address
+	 * of abatron_pteptrs
+	 */
+	nop
+/*
+ * Save parameters we are passed
+ */
+	mr	r31,r3
+	mr	r30,r4
+	mr	r29,r5
+	mr	r28,r6
+	mr	r27,r7
+	li	r25,0		/* phys kernel start (low) */
+	li	r24,0		/* CPU number */
+	li	r23,0		/* phys kernel start (high) */
+
+/* We try to not make any assumptions about how the boot loader
+ * setup or used the TLBs.  We invalidate all mappings from the
+ * boot loader and load a single entry in TLB1[0] to map the
+ * first 64M of kernel memory.  Any boot info passed from the
+ * bootloader needs to live in this first 64M.
+ *
+ * Requirement on bootloader:
+ *  - The page we're executing in needs to reside in TLB1 and
+ *    have IPROT=1.  If not an invalidate broadcast could
+ *    evict the entry we're currently executing in.
+ *
+ *  r3 = Index of TLB1 were executing in
+ *  r4 = Current MSR[IS]
+ *  r5 = Index of TLB1 temp mapping
+ *
+ * Later in mapin_ram we will correctly map lowmem, and resize TLB1[0]
+ * if needed
+ */
+
+_ENTRY(__early_start)
+	/* Jump to KERNELBASE mapping on address space 1 */
+	lis     r3,(KERNELBASE & ~0xfff)@h
+	ori     r3,r3,(KERNELBASE & ~0xfff)@l
+	mfmsr   r4
+	ori     r4, r4, MSR_IS|MSR_DS
+	bl      1f /* Find our address */
+1:	mflr    r5
+	rlwimi  r3,r5,0,20,31
+	addi    r3,r3,(2f - 1b)
+	mtspr   SPRN_SRR0,r3
+	mtspr   SPRN_SRR1,r4
+	rfi
+2:     
+	/* Invalid unnecessary TLB entries passed by the Hypervisor */
+	li      r0,0
+	PPC_TLBILX_ALL(0,0)
+	TLBSYNC
+
+	/* Establish the interrupt vector base */
+	lis	r0,VBI_SYS_hyIoctl@h
+	ori     r0,r0,VBI_SYS_hyIoctl@l
+	lis	r3,VBI_HYIOCTL_EXCBASE@h
+	ori	r3,r3,VBI_HYIOCTL_EXCBASE@l
+	lis	r4,_start@h
+	ori	r4,r4,_start@l
+	sc	1
+
+#ifdef CONFIG_SMP
+	/* Check to see if we're the second processor, and jump
+	 * to the secondary_start code if so
+	 */
+	lis	r24, 0xF0000000@h
+	ori	r24, r24, 0xF0000000@l
+	lwz	r24, WRHV_COREID_OFFSET(r24)
+	cmpwi	r24,0
+	bne	__secondary_start
+#endif
+
+	/*
+	 * This is where the main kernel code starts.
+	 */
+
+	/* ptr to current */
+	lis	r2,init_task@h
+	ori	r2,r2,init_task@l
+
+	/* ptr to current thread */
+	addi	r4,r2,THREAD	/* init task's THREAD */
+	mtspr	SPRN_SPRG_THREAD,r4
+
+	/* stack */
+	lis	r1,init_thread_union@h
+	ori	r1,r1,init_thread_union@l
+	li	r0,0
+	stwu	r0,THREAD_SIZE-STACK_FRAME_OVERHEAD(r1)
+
+	/* Establish the interrupt vector offsets */
+	SET_IVOR(0,  CriticalInput);
+	SET_IVOR(1,  MachineCheck);
+	SET_IVOR(2,  DataStorage);
+	SET_IVOR(3,  InstructionStorage);
+	SET_IVOR(4,  ExternalInput);
+	SET_IVOR(5,  Alignment);
+	SET_IVOR(6,  Program);
+	SET_IVOR(7,  FloatingPointUnavailable);
+	SET_IVOR(8,  SystemCall);
+	SET_IVOR(9,  AuxillaryProcessorUnavailable);
+	SET_IVOR(10, Decrementer);
+	SET_IVOR(11, FixedIntervalTimer);
+	SET_IVOR(12, WatchdogTimer);
+	SET_IVOR(13, DataTLBError);
+	SET_IVOR(14, InstructionTLBError);
+	SET_IVOR(15, DebugDebug);
+	SET_IVOR(20, DirectExternalInput);
+#ifdef CONFIG_SPE
+	SET_IVOR(32, SPEUnavailable);
+#endif
+	SET_IVOR(33, SPEFloatingPointData);
+	SET_IVOR(34, SPEFloatingPointRound);
+	SET_IVOR(35, PerformanceMonitor);
+	SET_IVOR(36, doorbell_exception);
+	SET_IVOR(37, CriticalDoorbell);
+
+	bl	early_init
+
+#ifdef CONFIG_RELOCATABLE
+	lis	r3,kernstart_addr@ha
+	la	r3,kernstart_addr@l(r3)
+#ifdef CONFIG_PHYS_64BIT
+	stw	r23,0(r3)
+	stw	r25,4(r3)
+#else
+	stw	r25,0(r3)
+#endif
+#endif
+
+/*
+ * Decide what sort of machine this is and initialize the MMU.
+ */
+	mr	r3,r31
+	mr	r4,r30
+	mr	r5,r29
+	mr	r6,r28
+	mr	r7,r27
+	bl	machine_init
+	bl	MMU_init
+
+	/* Let's move on */
+	b	start_kernel	/* change context and jump to start_kernel */
+
+/* Macros to hide the PTE size differences
+ *
+ * FIND_PTE -- walks the page tables given EA & pgdir pointer
+ *   r10 -- EA of fault
+ *   r11 -- PGDIR pointer
+ *   r12 -- free
+ *   label 2: is the bailout case
+ *
+ * if we find the pte (fall through):
+ *   r11 is low pte word
+ *   r12 is pointer to the pte
+ */
+#ifdef CONFIG_PTE_64BIT
+#define FIND_PTE	\
+	rlwinm	r12, r10, 13, 19, 29;	/* Compute pgdir/pmd offset */	\
+	lwzx	r11, r12, r11;		/* Get pgd/pmd entry */		\
+	rlwinm.	r12, r11, 0, 0, 20;	/* Extract pt base address */	\
+	beq	2f;			/* Bail if no table */		\
+	rlwimi	r12, r10, 23, 20, 28;	/* Compute pte address */	\
+	lwz	r11, 4(r12);		/* Get pte entry */
+#else
+#define FIND_PTE	\
+	rlwimi	r11, r10, 12, 20, 29;	/* Create L1 (pgdir/pmd) address */	\
+	lwz	r11, 0(r11);		/* Get L1 entry */			\
+	rlwinm.	r12, r11, 0, 0, 19;	/* Extract L2 (pte) base address */	\
+	beq	2f;			/* Bail if no table */			\
+	rlwimi	r12, r10, 22, 20, 29;	/* Compute PTE address */		\
+	lwz	r11, 0(r12);		/* Get Linux PTE */
+#endif
+
+/*
+ * Interrupt vector entry code
+ *
+ * The Book E MMUs are always on so we don't need to handle
+ * interrupts in real mode as with previous PPC processors. In
+ * this case we handle interrupts in the kernel virtual address
+ * space.
+ *
+ * Interrupt vectors are dynamically placed relative to the
+ * interrupt prefix as determined by the address of interrupt_base.
+ * The interrupt vectors offsets are programmed using the labels
+ * for each interrupt vector entry.
+ *
+ * Interrupt vectors must be aligned on a 16 byte boundary.
+ * We align on a 32 byte cache line boundary for good measure.
+ */
+interrupt_base:
+	/* Critical Input Interrupt */
+	CRITICAL_EXCEPTION(0x0100, CriticalInput, unknown_exception)
+
+	/* Machine Check Interrupt */
+	MCHECK_EXCEPTION(0x0200, MachineCheck, machine_check_exception)
+
+	/* Data Storage Interrupt */
+	START_EXCEPTION(DataStorage)
+	NORMAL_EXCEPTION_PROLOG
+	mfspr	r5,SPRN_ESR		/* Grab the ESR, save it, pass arg3 */
+	stw	r5,_ESR(r11)
+	mfspr	r4,SPRN_DEAR		/* Grab the DEAR, save it, pass arg2 */
+	andis.	r10,r5,(ESR_ILK|ESR_DLK)@h
+	bne	1f
+	EXC_XFER_EE_LITE(0x0300, handle_page_fault)
+1:
+	addi	r3,r1,STACK_FRAME_OVERHEAD
+	EXC_XFER_EE_LITE(0x0300, CacheLockingException)
+
+	/* Instruction Storage Interrupt */
+	INSTRUCTION_STORAGE_EXCEPTION
+
+	/* External Input Interrupt */
+	EXCEPTION(0x0500, ExternalInput, do_IRQ, EXC_XFER_LITE)
+
+	/* Alignment Interrupt */
+	ALIGNMENT_EXCEPTION
+
+	/* Program Interrupt */
+	PROGRAM_EXCEPTION
+
+	/* Floating Point Unavailable Interrupt */
+#ifdef CONFIG_PPC_FPU
+	FP_UNAVAILABLE_EXCEPTION
+#else
+	EXCEPTION(0x0800, FloatingPointUnavailable, unknown_exception, EXC_XFER_EE)
+#endif
+
+	/* System Call Interrupt */
+	START_EXCEPTION(SystemCall)
+	NORMAL_EXCEPTION_PROLOG
+	EXC_XFER_EE_LITE(0x0c00, DoSyscall)
+
+	/* Auxillary Processor Unavailable Interrupt */
+	EXCEPTION(0x2900, AuxillaryProcessorUnavailable, unknown_exception, EXC_XFER_EE)
+
+	/* Decrementer Interrupt */
+	DECREMENTER_EXCEPTION
+
+	/* Fixed Internal Timer Interrupt */
+	/* TODO: Add FIT support */
+	EXCEPTION(0x3100, FixedIntervalTimer, unknown_exception, EXC_XFER_EE)
+
+	/* Watchdog Timer Interrupt */
+#ifdef CONFIG_BOOKE_WDT
+	CRITICAL_EXCEPTION(0x3200, WatchdogTimer, WatchdogException)
+#else
+	CRITICAL_EXCEPTION(0x3200, WatchdogTimer, unknown_exception)
+#endif
+
+	/* Data TLB Error Interrupt */
+	START_EXCEPTION(DataTLBError)
+	mtspr	SPRN_SPRG_WSCRATCH0, r10 /* Save some working registers */
+	mtspr	SPRN_SPRG_WSCRATCH1, r11
+	mtspr	SPRN_SPRG_WSCRATCH2, r12
+	mtspr	SPRN_SPRG_WSCRATCH3, r13
+
+	/* Save r3 since that store an emulated privileged instruction. */
+	mtspr	SPRN_SPRG_WSCRATCH_MC, r3
+
+	mfcr	r11
+	mtspr	SPRN_SPRG_WSCRATCH4, r11
+	mfspr	r10, SPRN_DEAR		/* Get faulting address */
+
+	/* If we are faulting a kernel address, we have to use the
+	 * kernel page tables.
+	 */
+	lis	r11, PAGE_OFFSET@h
+	cmplw	5, r10, r11
+	blt	5, 3f
+	lis	r11, swapper_pg_dir@h
+	ori	r11, r11, swapper_pg_dir@l
+
+	mfspr	r12,SPRN_MAS1		/* Set TID to 0 */
+	rlwinm	r12,r12,0,16,1
+	mtspr	SPRN_MAS1,r12
+
+	b	4f
+
+	/* Get the PGD for the current thread */
+3:
+	mfspr	r11,SPRN_SPRG_THREAD
+	lwz	r11,PGDIR(r11)
+
+4:
+	/* Mask of required permission bits. Note that while we
+	 * do copy ESR:ST to _PAGE_RW position as trying to write
+	 * to an RO page is pretty common, we don't do it with
+	 * _PAGE_DIRTY. We could do it, but it's a fairly rare
+	 * event so I'd rather take the overhead when it happens
+	 * rather than adding an instruction here. We should measure
+	 * whether the whole thing is worth it in the first place
+	 * as we could avoid loading SPRN_ESR completely in the first
+	 * place...
+	 *
+	 * TODO: Is it worth doing that mfspr & rlwimi in the first
+	 *       place or can we save a couple of instructions here ?
+	 */
+	mfspr	r12,SPRN_ESR
+#ifdef CONFIG_PTE_64BIT
+	li	r13,_PAGE_PRESENT
+	oris	r13,r13,_PAGE_ACCESSED@h
+#else
+	li	r13,_PAGE_PRESENT|_PAGE_ACCESSED
+#endif
+	rlwimi	r13,r12,11,29,29
+
+	FIND_PTE
+	andc.	r13,r13,r11		/* Check permission */
+
+#ifdef CONFIG_PTE_64BIT
+#ifdef CONFIG_SMP
+	subf	r10,r11,r12		/* create false data dep */
+	lwzx	r13,r11,r10		/* Get upper pte bits */
+#else
+	lwz	r13,0(r12)		/* Get upper pte bits */
+#endif
+#endif
+
+	bne	2f			/* Bail if permission/valid mismach */
+
+	/* Jump to common tlb load */
+	b	finish_tlb_load
+2:
+	/* The bailout.  Restore registers to pre-exception conditions
+	 * and call the heavyweights to help us out.
+	 */
+
+	/* Restore r3 since that store an emulated privileged instruction. */
+	mfspr	r3, SPRN_SPRG_RSCRATCH_MC
+
+	mfspr	r11, SPRN_SPRG_RSCRATCH4
+	mtcr	r11
+	mfspr	r13, SPRN_SPRG_RSCRATCH3
+	mfspr	r12, SPRN_SPRG_RSCRATCH2
+	mfspr	r11, SPRN_SPRG_RSCRATCH1
+	mfspr	r10, SPRN_SPRG_RSCRATCH0
+	b	DataStorage
+
+	/* Instruction TLB Error Interrupt */
+	/*
+	 * Nearly the same as above, except we get our
+	 * information from different registers and bailout
+	 * to a different point.
+	 */
+	START_EXCEPTION(InstructionTLBError)
+	mtspr	SPRN_SPRG_WSCRATCH0, r10 /* Save some working registers */
+	mtspr	SPRN_SPRG_WSCRATCH1, r11
+	mtspr	SPRN_SPRG_WSCRATCH2, r12
+	mtspr	SPRN_SPRG_WSCRATCH3, r13
+
+	/* Save r3 since that store an emulated privileged instruction. */
+	mtspr	SPRN_SPRG_WSCRATCH_MC, r3
+
+	mfcr	r11
+	mtspr	SPRN_SPRG_WSCRATCH4, r11
+	mfspr	r10, SPRN_SRR0		/* Get faulting address */
+
+	/* If we are faulting a kernel address, we have to use the
+	 * kernel page tables.
+	 */
+	lis	r11, PAGE_OFFSET@h
+	cmplw	5, r10, r11
+	blt	5, 3f
+	lis	r11, swapper_pg_dir@h
+	ori	r11, r11, swapper_pg_dir@l
+
+	mfspr	r12,SPRN_MAS1		/* Set TID to 0 */
+	rlwinm	r12,r12,0,16,1
+	mtspr	SPRN_MAS1,r12
+
+	b	4f
+
+	/* Get the PGD for the current thread */
+3:
+	mfspr	r11,SPRN_SPRG_THREAD
+	lwz	r11,PGDIR(r11)
+
+4:
+	/* Make up the required permissions */
+#ifdef CONFIG_PTE_64BIT
+	li	r13,_PAGE_PRESENT | _PAGE_EXEC
+	oris	r13,r13,_PAGE_ACCESSED@h
+#else
+	li	r13,_PAGE_PRESENT | _PAGE_ACCESSED | _PAGE_EXEC
+#endif
+
+	FIND_PTE
+	andc.	r13,r13,r11		/* Check permission */
+
+#ifdef CONFIG_PTE_64BIT
+#ifdef CONFIG_SMP
+	subf	r10,r11,r12		/* create false data dep */
+	lwzx	r13,r11,r10		/* Get upper pte bits */
+#else
+	lwz	r13,0(r12)		/* Get upper pte bits */
+#endif
+#endif
+
+	bne	2f			/* Bail if permission mismach */
+
+	/* Jump to common TLB load point */
+	b	finish_tlb_load
+
+2:
+	/* The bailout.  Restore registers to pre-exception conditions
+	 * and call the heavyweights to help us out.
+	 */
+
+	/* Restore r3 since that store an emulated privileged instruction. */
+	mfspr	r3, SPRN_SPRG_RSCRATCH_MC
+
+	mfspr	r11, SPRN_SPRG_RSCRATCH4
+	mtcr	r11
+	mfspr	r13, SPRN_SPRG_RSCRATCH3
+	mfspr	r12, SPRN_SPRG_RSCRATCH2
+	mfspr	r11, SPRN_SPRG_RSCRATCH1
+	mfspr	r10, SPRN_SPRG_RSCRATCH0
+	b	InstructionStorage
+
+#ifdef CONFIG_SPE
+	/* SPE Unavailable */
+	START_EXCEPTION(SPEUnavailable)
+	NORMAL_EXCEPTION_PROLOG
+	bne	load_up_spe
+	addi	r3,r1,STACK_FRAME_OVERHEAD
+	EXC_XFER_EE_LITE(0x2010, KernelSPE)
+#else
+	EXCEPTION(0x2020, SPEUnavailable, unknown_exception, EXC_XFER_EE)
+#endif /* CONFIG_SPE */
+
+	/* SPE Floating Point Data */
+#ifdef CONFIG_SPE
+	EXCEPTION(0x2030, SPEFloatingPointData, SPEFloatingPointException, EXC_XFER_EE);
+
+	/* SPE Floating Point Round */
+	EXCEPTION(0x2050, SPEFloatingPointRound, SPEFloatingPointRoundException, EXC_XFER_EE)
+#else
+	EXCEPTION(0x2040, SPEFloatingPointData, unknown_exception, EXC_XFER_EE)
+	EXCEPTION(0x2050, SPEFloatingPointRound, unknown_exception, EXC_XFER_EE)
+#endif /* CONFIG_SPE */
+
+	/* Performance Monitor */
+	EXCEPTION(0x2060, PerformanceMonitor, performance_monitor_exception, EXC_XFER_STD)
+
+	EXCEPTION(0x2070, Doorbell, doorbell_exception, EXC_XFER_STD)
+
+	CRITICAL_EXCEPTION(0x2080, CriticalDoorbell, unknown_exception)
+
+	EXCEPTION(0x2090, DirectExternalInput, wrhv_do_direct_IRQ, EXC_XFER_LITE)
+
+	/* Debug Interrupt */
+	DEBUG_DEBUG_EXCEPTION
+
+	/* Debug CRIT Interrupt */
+	DEBUG_CRIT_EXCEPTION
+
+/*
+ * Local functions
+ */
+
+/*
+ * Both the instruction and data TLB miss get to this
+ * point to load the TLB.
+ *	r10 - available to use
+ *	r11 - TLB (info from Linux PTE)
+ *	r12 - available to use
+ *	r13 - upper bits of PTE (if PTE_64BIT) or available to use
+ *	CR5 - results of addr >= PAGE_OFFSET
+ *	MAS0, MAS1 - loaded with proper value when we get here
+ *	MAS2, MAS3 - will need additional info from Linux PTE
+ *	Upon exit, we reload everything and RFI.
+ */
+finish_tlb_load:
+	/*
+	 * We set execute, because we don't have the granularity to
+	 * properly set this at the page level (Linux problem).
+	 * Many of these bits are software only.  Bits we don't set
+	 * here we (properly should) assume have the appropriate value.
+	 */
+
+	mfspr	r12, SPRN_MAS2
+#ifdef CONFIG_PTE_64BIT
+	rlwimi	r12, r11, 32-19, 27, 31	/* extract WIMGE from pte */
+#else
+	rlwimi	r12, r11, 26, 27, 31	/* extract WIMGE from pte */
+#endif
+	mtspr	SPRN_MAS2, r12
+
+#ifdef CONFIG_PTE_64BIT
+	rlwinm	r12, r11, 32-2, 26, 31	/* Move in perm bits */
+	andi.	r10, r11, _PAGE_DIRTY
+	bne	1f
+	li	r10, MAS3_SW | MAS3_UW
+	andc	r12, r12, r10
+1:	rlwimi	r12, r13, 20, 0, 11	/* grab RPN[32:43] */
+	rlwimi	r12, r11, 20, 12, 19	/* grab RPN[44:51] */
+	mtspr	SPRN_MAS3, r12
+BEGIN_MMU_FTR_SECTION
+	srwi	r10, r13, 12		/* grab RPN[12:31] */
+	mtspr	SPRN_MAS7, r10
+END_MMU_FTR_SECTION_IFSET(MMU_FTR_BIG_PHYS)
+#else
+	li	r10, (_PAGE_EXEC | _PAGE_PRESENT)
+	rlwimi	r10, r11, 31, 29, 29	/* extract _PAGE_DIRTY into SW */
+	and	r12, r11, r10
+	andi.	r10, r11, _PAGE_USER	/* Test for _PAGE_USER */
+	slwi	r10, r12, 1
+	or	r10, r10, r12
+	iseleq	r12, r12, r10
+	rlwimi	r11, r12, 0, 20, 31	/* Extract RPN from PTE and merge with perms */
+	mtspr	SPRN_MAS3, r11
+#endif
+
+	/*  The HY will check which privileged instruction trap privileged 
+	 *  exception via r3.
+	 */
+	lis	r3,TLBWE_CODE@h
+	ori	r3,r3,TLBWE_CODE@l
+	tlbwe
+
+	/* Done...restore registers and get out of here.  */
+
+	/* Restore r3 since that store an emulated privileged instruction. */
+	mfspr	r3, SPRN_SPRG_RSCRATCH_MC
+
+	mfspr	r11, SPRN_SPRG_RSCRATCH4
+	mtcr	r11
+	mfspr	r13, SPRN_SPRG_RSCRATCH3
+	mfspr	r12, SPRN_SPRG_RSCRATCH2
+	mfspr	r11, SPRN_SPRG_RSCRATCH1
+	mfspr	r10, SPRN_SPRG_RSCRATCH0
+	rfi					/* Force context change */
+
+#ifdef CONFIG_SPE
+/* Note that the SPE support is closely modeled after the AltiVec
+ * support.  Changes to one are likely to be applicable to the
+ * other!  */
+load_up_spe:
+/*
+ * Disable SPE for the task which had SPE previously,
+ * and save its SPE registers in its thread_struct.
+ * Enables SPE for use in the kernel on return.
+ * On SMP we know the SPE units are free, since we give it up every
+ * switch.  -- Kumar
+ */
+	mfmsr	r5
+	oris	r5,r5,MSR_SPE@h
+	mtmsr	r5			/* enable use of SPE now */
+	isync
+/*
+ * For SMP, we don't do lazy SPE switching because it just gets too
+ * horrendously complex, especially when a task switches from one CPU
+ * to another.  Instead we call giveup_spe in switch_to.
+ */
+#ifndef CONFIG_SMP
+	lis	r3,last_task_used_spe@ha
+	lwz	r4,last_task_used_spe@l(r3)
+	cmpi	0,r4,0
+	beq	1f
+	addi	r4,r4,THREAD	/* want THREAD of last_task_used_spe */
+	SAVE_32EVRS(0,r10,r4)
+	evxor	evr10, evr10, evr10	/* clear out evr10 */
+	evmwumiaa evr10, evr10, evr10	/* evr10 <- ACC = 0 * 0 + ACC */
+	li	r5,THREAD_ACC
+	evstddx	evr10, r4, r5		/* save off accumulator */
+	lwz	r5,PT_REGS(r4)
+	lwz	r4,_MSR-STACK_FRAME_OVERHEAD(r5)
+	lis	r10,MSR_SPE@h
+	andc	r4,r4,r10	/* disable SPE for previous task */
+	stw	r4,_MSR-STACK_FRAME_OVERHEAD(r5)
+1:
+#endif /* !CONFIG_SMP */
+	/* enable use of SPE after return */
+	oris	r9,r9,MSR_SPE@h
+	mfspr	r5,SPRN_SPRG_THREAD	/* current task's THREAD (phys) */
+	li	r4,1
+	li	r10,THREAD_ACC
+	stw	r4,THREAD_USED_SPE(r5)
+	evlddx	evr4,r10,r5
+	evmra	evr4,evr4
+	REST_32EVRS(0,r10,r5)
+#ifndef CONFIG_SMP
+	subi	r4,r5,THREAD
+	stw	r4,last_task_used_spe@l(r3)
+#endif /* !CONFIG_SMP */
+	/* restore registers and return */
+2:	REST_4GPRS(3, r11)
+	lwz	r10,_CCR(r11)
+	REST_GPR(1, r11)
+	mtcr	r10
+	lwz	r10,_LINK(r11)
+	mtlr	r10
+	REST_GPR(10, r11)
+	mtspr	SPRN_SRR1,r9
+	mtspr	SPRN_SRR0,r12
+	REST_GPR(9, r11)
+	REST_GPR(12, r11)
+	lwz	r11,GPR11(r11)
+	rfi
+
+/*
+ * SPE unavailable trap from kernel - print a message, but let
+ * the task use SPE in the kernel until it returns to user mode.
+ */
+KernelSPE:
+	lwz	r3,_MSR(r1)
+	oris	r3,r3,MSR_SPE@h
+	stw	r3,_MSR(r1)	/* enable use of SPE after return */
+#ifdef CONFIG_PRINTK
+	lis	r3,87f@h
+	ori	r3,r3,87f@l
+	mr	r4,r2		/* current */
+	lwz	r5,_NIP(r1)
+	bl	printk
+#endif
+	b	ret_from_except
+#ifdef CONFIG_PRINTK
+87:	.string	"SPE used in kernel  (task=%p, pc=%x)  \n"
+#endif
+	.align	4,0
+
+#endif /* CONFIG_SPE */
+
+/*
+ * Set the interrupt vector offset to the exec table
+ * r3 - the interrupt vector number
+ * r4 - the vector handler label
+*/
+set_exec_table:
+	lis	r5,exec_table@h
+	ori	r5,r5,exec_table@l
+	slwi	r3,r3,2
+	subis	r4,r4,PAGE_OFFSET@h
+	stwx	r4,r3,r5
+	blr
+
+/*
+ * Global functions
+ */
+
+/*
+ * extern void giveup_altivec(struct task_struct *prev)
+ *
+ * The e500 core does not have an AltiVec unit.
+ */
+_GLOBAL(giveup_altivec)
+	blr
+
+#ifdef CONFIG_SPE
+/*
+ * extern void giveup_spe(struct task_struct *prev)
+ *
+ */
+_GLOBAL(giveup_spe)
+	mfmsr	r5
+	oris	r5,r5,MSR_SPE@h
+	mtmsr	r5			/* enable use of SPE now */
+	isync
+	cmpi	0,r3,0
+	beqlr-				/* if no previous owner, done */
+	addi	r3,r3,THREAD		/* want THREAD of task */
+	lwz	r5,PT_REGS(r3)
+	cmpi	0,r5,0
+	SAVE_32EVRS(0, r4, r3)
+	evxor	evr6, evr6, evr6	/* clear out evr6 */
+	evmwumiaa evr6, evr6, evr6	/* evr6 <- ACC = 0 * 0 + ACC */
+	li	r4,THREAD_ACC
+	evstddx	evr6, r4, r3		/* save off accumulator */
+	mfspr	r6,SPRN_SPEFSCR
+	stw	r6,THREAD_SPEFSCR(r3)	/* save spefscr register value */
+	beq	1f
+	lwz	r4,_MSR-STACK_FRAME_OVERHEAD(r5)
+	lis	r3,MSR_SPE@h
+	andc	r4,r4,r3		/* disable SPE for previous task */
+	stw	r4,_MSR-STACK_FRAME_OVERHEAD(r5)
+1:
+#ifndef CONFIG_SMP
+	li	r5,0
+	lis	r4,last_task_used_spe@ha
+	stw	r5,last_task_used_spe@l(r4)
+#endif /* !CONFIG_SMP */
+	blr
+#endif /* CONFIG_SPE */
+
+/*
+ * extern void giveup_fpu(struct task_struct *prev)
+ *
+ * Not all FSL Book-E cores have an FPU
+ */
+#ifndef CONFIG_PPC_FPU
+_GLOBAL(giveup_fpu)
+	blr
+#endif
+
+/*
+ * extern void abort(void)
+ *
+ * At present, this routine just applies a system reset.
+ */
+_GLOBAL(abort)
+	li	r13,0
+	mtspr	SPRN_DBCR0,r13		/* disable all debug events */
+	isync
+	mfmsr	r13
+	ori	r13,r13,MSR_DE@l	/* Enable Debug Events */
+	mtmsr	r13
+	isync
+	mfspr	r13,SPRN_DBCR0
+	lis	r13,(DBCR0_IDM|DBCR0_RST_CHIP)@h
+	mtspr	SPRN_DBCR0,r13
+	isync
+
+_GLOBAL(set_context)
+
+#ifdef CONFIG_BDI_SWITCH
+	/* Context switch the PTE pointer for the Abatron BDI2000.
+	 * The PGDIR is the second parameter.
+	 */
+	lis	r5, abatron_pteptrs@h
+	ori	r5, r5, abatron_pteptrs@l
+	stw	r4, 0x4(r5)
+#endif
+	mtspr	SPRN_PID,r3
+	isync			/* Force context change */
+#ifdef CONFIG_P4080_ERRATUM_CPU8
+	isync
+#endif
+	blr
+
+_GLOBAL(flush_dcache_L1)
+	mfspr	r3,SPRN_L1CFG0
+
+	rlwinm	r5,r3,9,3	/* Extract cache block size */
+	twlgti	r5,1		/* Only 32 and 64 byte cache blocks
+				 * are currently defined.
+				 */
+	li	r4,32
+	subfic	r6,r5,2		/* r6 = log2(1KiB / cache block size) -
+				 *      log2(number of ways)
+				 */
+	slw	r5,r4,r5	/* r5 = cache block size */
+
+	rlwinm	r7,r3,0,0xff	/* Extract number of KiB in the cache */
+	mulli	r7,r7,13	/* An 8-way cache will require 13
+				 * loads per set.
+				 */
+	slw	r7,r7,r6
+
+	/* save off HID0 and set DCFA */
+	mfspr	r8,SPRN_HID0
+	ori	r9,r8,HID0_DCFA@l
+	mtspr	SPRN_HID0,r9
+	isync
+
+	lis	r4,KERNELBASE@h
+	mtctr	r7
+
+1:	lwz	r3,0(r4)	/* Load... */
+	add	r4,r4,r5
+	bdnz	1b
+
+	msync
+	lis	r4,KERNELBASE@h
+	mtctr	r7
+
+1:	dcbf	0,r4		/* ...and flush. */
+	add	r4,r4,r5
+	bdnz	1b
+
+	/* restore HID0 */
+	mtspr	SPRN_HID0,r8
+	isync
+
+	blr
+
+#ifdef CONFIG_SMP
+/* When we get here, r24 needs to hold the CPU # */
+	.globl __secondary_start
+__secondary_start:
+	lis	r3,__secondary_hold_acknowledge@h
+	ori	r3,r3,__secondary_hold_acknowledge@l
+	stw	r24,0(r3)
+
+	li	r3,0
+	mr	r4,r24		/* Why? */
+	bl	call_setup_cpu
+
+	/* get current_thread_info and current */
+	lis	r1,secondary_ti@ha
+	lwz	r1,secondary_ti@l(r1)
+	lwz	r2,TI_TASK(r1)
+
+	/* stack */
+	addi	r1,r1,THREAD_SIZE-STACK_FRAME_OVERHEAD
+	li	r0,0
+	stw	r0,0(r1)
+
+	/* ptr to current thread */
+	addi	r4,r2,THREAD	/* address of our thread_struct */
+	mtspr	SPRN_SPRG_THREAD,r4
+
+	/* Jump to start_secondary */
+	lis	r4,MSR_KERNEL@h
+	ori	r4,r4,MSR_KERNEL@l
+	lis	r3,wrhv_start_secondary@h
+	ori	r3,r3,wrhv_start_secondary@l
+	mtspr	SPRN_SRR0,r3
+	mtspr	SPRN_SRR1,r4
+	sync
+	rfi
+	sync
+
+	.globl __secondary_hold_acknowledge
+__secondary_hold_acknowledge:
+	.long	-1
+#endif
+
+/*
+ * We put a few things here that have to be page-aligned. This stuff
+ * goes at the beginning of the data segment, which is page-aligned.
+ */
+	.data
+	.align	12
+	.globl	sdata
+sdata:
+	.globl	empty_zero_page
+empty_zero_page:
+	.space	4096
+	.globl	swapper_pg_dir
+swapper_pg_dir:
+	.space	PGD_TABLE_SIZE
+
+/*
+ * Room for two PTE pointers, usually the kernel and current user pointers
+ * to their respective root page table.
+ */
+abatron_pteptrs:
+	.space	8
diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c
index ffefbc5..5a68ec0 100644
--- a/arch/powerpc/kernel/irq.c
+++ b/arch/powerpc/kernel/irq.c
@@ -318,7 +318,7 @@ void fixup_irqs(cpumask_t map)
 #endif
 
 #ifdef CONFIG_IRQSTACKS
-static inline void handle_one_irq(unsigned int irq)
+inline void handle_one_irq(unsigned int irq)
 {
 	struct thread_info *curtp, *irqtp;
 	unsigned long saved_sp_limit;
@@ -359,13 +359,13 @@ static inline void handle_one_irq(unsigned int irq)
 		set_bits(irqtp->flags, &curtp->flags);
 }
 #else
-static inline void handle_one_irq(unsigned int irq)
+inline void handle_one_irq(unsigned int irq)
 {
 	generic_handle_irq(irq);
 }
 #endif
 
-static inline void check_stack_overflow(void)
+inline void check_stack_overflow(void)
 {
 #ifdef CONFIG_DEBUG_STACKOVERFLOW
 	long sp;
@@ -381,8 +381,20 @@ static inline void check_stack_overflow(void)
 #endif
 }
 
+#ifdef CONFIG_WRHV
+EXPORT_SYMBOL(handle_one_irq);
+EXPORT_SYMBOL(check_stack_overflow);
+#endif
+
+void paravirt_do_IRQ(struct pt_regs *regs) __attribute__((weak, alias("native_do_IRQ")));
+
 void do_IRQ(struct pt_regs *regs)
 {
+	paravirt_do_IRQ(regs);  
+}
+
+void native_do_IRQ(struct pt_regs *regs)
+{
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	unsigned int irq;
 
@@ -820,7 +832,10 @@ unsigned int irq_create_of_mapping(struct device_node *controller,
 }
 EXPORT_SYMBOL_GPL(irq_create_of_mapping);
 
-unsigned int irq_of_parse_and_map(struct device_node *dev, int index)
+unsigned int paravirt_irq_of_parse_and_map(struct device_node *dev, int index)
+        __attribute__((weak, alias("native_irq_of_parse_and_map")));
+
+unsigned int native_irq_of_parse_and_map(struct device_node *dev, int index)
 {
 	struct of_irq oirq;
 
@@ -830,6 +845,11 @@ unsigned int irq_of_parse_and_map(struct device_node *dev, int index)
 	return irq_create_of_mapping(oirq.controller, oirq.specifier,
 				     oirq.size);
 }
+
+unsigned int irq_of_parse_and_map(struct device_node *dev, int index)
+{
+	return paravirt_irq_of_parse_and_map(dev, index);
+}
 EXPORT_SYMBOL_GPL(irq_of_parse_and_map);
 
 void irq_dispose_mapping(unsigned int virq)
diff --git a/arch/powerpc/kernel/kgdb.c b/arch/powerpc/kernel/kgdb.c
index 6cee246..a140bb8 100644
--- a/arch/powerpc/kernel/kgdb.c
+++ b/arch/powerpc/kernel/kgdb.c
@@ -307,7 +307,12 @@ void kgdb_arch_set_pc(struct pt_regs *regs, unsigned long pc)
 /*
  * This function does PowerPC specific procesing for interfacing to gdb.
  */
-int kgdb_arch_handle_exception(int vector, int signo, int err_code,
+int paravirt_kgdb_arch_handle_exception(int vector, int signo, int err_code,
+                               char *remcom_in_buffer, char *remcom_out_buffer,
+                               struct pt_regs *linux_regs) __attribute__
+			((weak, alias("native_kgdb_arch_handle_exception")));
+
+int native_kgdb_arch_handle_exception(int vector, int signo, int err_code,
 			       char *remcom_in_buffer, char *remcom_out_buffer,
 			       struct pt_regs *linux_regs)
 {
@@ -344,6 +349,15 @@ int kgdb_arch_handle_exception(int vector, int signo, int err_code,
 	return -1;
 }
 
+int kgdb_arch_handle_exception(int vector, int signo, int err_code,
+			       char *remcom_in_buffer, char *remcom_out_buffer,
+			       struct pt_regs *linux_regs)
+{
+	return paravirt_kgdb_arch_handle_exception(vector, signo, err_code,
+					remcom_in_buffer, remcom_out_buffer,
+					linux_regs);	
+}
+
 /*
  * Global data
  */
diff --git a/arch/powerpc/kernel/legacy_serial.c b/arch/powerpc/kernel/legacy_serial.c
index 035ada5..89a15f3 100644
--- a/arch/powerpc/kernel/legacy_serial.c
+++ b/arch/powerpc/kernel/legacy_serial.c
@@ -23,6 +23,9 @@
 
 #define MAX_LEGACY_SERIAL_PORTS	8
 
+#ifdef CONFIG_WRHV
+extern int wrhv_earlycon;
+#endif
 static struct plat_serial8250_port
 legacy_serial_ports[MAX_LEGACY_SERIAL_PORTS+1];
 static struct legacy_serial_info {
@@ -379,6 +382,10 @@ void __init find_legacy_serial_ports(void)
 	}
 #endif
 
+#ifdef CONFIG_WRHV
+	if(wrhv_earlycon != -1 && wrhv_earlycon < MAX_LEGACY_SERIAL_PORTS)
+		legacy_serial_console = wrhv_earlycon;
+#endif
 	DBG("legacy_serial_console = %d\n", legacy_serial_console);
 	if (legacy_serial_console >= 0)
 		setup_legacy_serial_console(legacy_serial_console);
diff --git a/arch/powerpc/kernel/misc_32.S b/arch/powerpc/kernel/misc_32.S
index 88ebaec..6fde005 100644
--- a/arch/powerpc/kernel/misc_32.S
+++ b/arch/powerpc/kernel/misc_32.S
@@ -327,6 +327,12 @@ END_FTR_SECTION_IFSET(CPU_FTR_UNIFIED_ID_CACHE)
  * flush_icache_range(unsigned long start, unsigned long stop)
  */
 _KPROBE(__flush_icache_range)
+#ifndef CONFIG_PARAVIRT
+	b	native__flush_icache_range
+#else
+	b	paravirt__flush_icache_range
+#endif
+_KPROBE(native__flush_icache_range)
 BEGIN_FTR_SECTION
 	blr				/* for 601, do nothing */
 END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
@@ -364,6 +370,12 @@ END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
  * clean_dcache_range(unsigned long start, unsigned long stop)
  */
 _GLOBAL(clean_dcache_range)
+#ifndef CONFIG_PARAVIRT
+        b       native_clean_dcache_range
+#else
+        b       paravirt_clean_dcache_range
+#endif
+_GLOBAL(native_clean_dcache_range)
 	li	r5,L1_CACHE_BYTES-1
 	andc	r3,r3,r5
 	subf	r4,r3,r4
@@ -385,6 +397,12 @@ _GLOBAL(clean_dcache_range)
  * flush_dcache_range(unsigned long start, unsigned long stop)
  */
 _GLOBAL(flush_dcache_range)
+#ifndef CONFIG_PARAVIRT
+	b	native_flush_dcache_range
+#else
+	b	paravirt_flush_dcache_range
+#endif
+_GLOBAL(native_flush_dcache_range)
 	li	r5,L1_CACHE_BYTES-1
 	andc	r3,r3,r5
 	subf	r4,r3,r4
@@ -430,6 +448,12 @@ _GLOBAL(invalidate_dcache_range)
  *	void __flush_dcache_icache(void *page)
  */
 _GLOBAL(__flush_dcache_icache)
+#ifndef CONFIG_PARAVIRT
+	b	native__flush_dcache_icache
+#else
+	b	paravirt__flush_dcache_icache
+#endif
+_GLOBAL(native__flush_dcache_icache)
 BEGIN_FTR_SECTION
 	blr
 END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
@@ -467,6 +491,12 @@ END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
  *	void __flush_dcache_icache_phys(unsigned long physaddr)
  */
 _GLOBAL(__flush_dcache_icache_phys)
+#ifndef CONFIG_PARAVIRT
+	b	native__flush_dcache_icache_phys
+#else
+	b	paravirt__flush_dcache_icache_phys
+#endif
+_GLOBAL(native__flush_dcache_icache_phys)
 BEGIN_FTR_SECTION
 	blr					/* for 601, do nothing */
 END_FTR_SECTION_IFSET(CPU_FTR_COHERENT_ICACHE)
diff --git a/arch/powerpc/kernel/module.c b/arch/powerpc/kernel/module.c
index 477c663..987b251 100644
--- a/arch/powerpc/kernel/module.c
+++ b/arch/powerpc/kernel/module.c
@@ -26,6 +26,7 @@
 #include <asm/uaccess.h>
 #include <asm/firmware.h>
 #include <linux/sort.h>
+#include <linux/slab.h>
 
 #include "setup.h"
 
@@ -36,13 +37,21 @@ void *module_alloc(unsigned long size)
 	if (size == 0)
 		return NULL;
 
+#if defined(CONFIG_WRHV) && defined(CONFIG_PPC)
+	return kmalloc(size, GFP_KERNEL);
+#else
 	return vmalloc_exec(size);
+#endif
 }
 
 /* Free memory returned from module_alloc */
 void module_free(struct module *mod, void *module_region)
 {
+#if defined(CONFIG_WRHV) && defined(CONFIG_PPC)
+	kfree(module_region);
+#else
 	vfree(module_region);
+#endif
 }
 
 static const Elf_Shdr *find_section(const Elf_Ehdr *hdr,
diff --git a/arch/powerpc/kernel/paravirt.c b/arch/powerpc/kernel/paravirt.c
new file mode 100644
index 0000000..9e0f22a
--- /dev/null
+++ b/arch/powerpc/kernel/paravirt.c
@@ -0,0 +1,349 @@
+/*  Paravirtualization interfaces
+
+    This program is free software; you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation; either version 2 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    Adaptation for powerpc based on x86 version, Copyright (C) 2009
+    Wind River Systems, Inc.
+
+*/
+
+#include <linux/errno.h>
+#include <linux/module.h>
+#include <linux/efi.h>
+#include <linux/bcd.h>
+#include <linux/highmem.h>
+
+#include <asm/bug.h>
+#include <asm/setup.h>
+#include <asm/pgtable.h>
+#include <asm/time.h>
+#include <asm/pgalloc.h>
+#include <asm/irq.h>
+#include <asm/delay.h>
+#include <asm/fixmap.h>
+#include <asm/tlbflush.h>
+#include <asm/machdep.h>
+#include <asm/fs_pd.h>
+
+#include <linux/kernel.h>
+#include <linux/string.h>
+#include <linux/types.h>
+#include <linux/mm.h>
+#include <linux/stddef.h>
+#include <linux/init.h>
+#include <linux/bootmem.h>
+#include <linux/initrd.h>
+#include <linux/pagemap.h>
+
+#include <linux/kprobes.h>
+#include <linux/kexec.h>
+#include <linux/backlight.h> 
+#include <linux/bug.h>
+#include <linux/kdebug.h>
+#include <linux/kallsyms.h> 
+
+#include <mm/mmu_decl.h>
+#include <linux/lmb.h>
+
+#include <linux/major.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/of_platform.h>
+#include <linux/phy.h>
+#include <linux/phy_fixed.h>
+#include <linux/spi/spi.h>
+#include <linux/fsl_devices.h>
+#include <linux/fs_enet_pd.h>
+#include <linux/fs_uart_pd.h>
+
+#include <asm/system.h>
+#include <asm/atomic.h>
+#include <asm/io.h>
+#include <asm/prom.h>
+#include <sysdev/fsl_soc.h>
+#include <asm/cpm2.h>
+
+#include <linux/kgdb.h>
+#include <linux/smp.h>
+#include <linux/signal.h>
+#include <linux/ptrace.h>
+#include <asm/current.h>
+#include <asm/processor.h>
+
+#include <asm/wrhv.h>
+#include <asm/paravirt.h>
+
+#ifdef CONFIG_WRHV
+extern void wrhv_init(void);
+#endif
+
+/* XXX fixme - use an existing implementation */
+#if 1
+#define DEBUGP printk
+#else
+#define DEBUGP(fmt , ...)       do { } while (0)
+#endif
+
+/* paravirt init */
+void paravirt_init(void)
+{
+#ifdef CONFIG_WRHV
+	wrhv_init();
+#endif
+}
+
+struct pv_info pv_info = {
+        .name = "bare hardware",
+        .paravirt_enabled = 0,
+};
+
+/* default native operations */
+struct pv_time_ops pv_time_ops = {
+	.time_init_cont = native_time_init_cont,
+	.timer_interrupt = native_timer_interrupt,
+	.clocksource_init = native_clocksource_init,
+};
+
+struct pv_irq_ops pv_irq_ops = {
+	.do_IRQ = native_do_IRQ,
+	.irq_of_parse_and_map = native_irq_of_parse_and_map,
+};
+
+struct pv_cpu_ops pv_cpu_ops = {
+	.get_pvr = native_get_pvr,
+	.get_svr = native_get_svr,
+	.DebugException = native_DebugException,
+	.prime_debug_regs = native_prime_debug_regs,
+#ifdef CONFIG_KGDB
+	.kgdb_arch_handle_exception = native_kgdb_arch_handle_exception,
+#endif
+	.ppc_proc_freq = native_ppc_proc_freq,
+};
+
+struct pv_mmu_ops pv_mmu_ops = {
+	.vmmu_restore = native_vmmu_restore,
+	.MMU_init_hw = native_MMU_init_hw,
+	.mmu_mapin_ram = native_mmu_mapin_ram,
+	.MMU_setup = native_MMU_setup,
+	.MMU_init = native_MMU_init,
+	.flush_dcache_page = native_flush_dcache_page,
+	.map_page = native_map_page,
+	.early_init_dt_scan_memory_ppc =
+		native_early_init_dt_scan_memory_ppc,
+	.__ioremap = native___ioremap,
+	.__set_pte_at = native__set_pte_at,
+};
+
+struct pv_mdio_ops pv_mdio_ops = {
+	.fsl_pq_mdio_write	= native_fsl_pq_mdio_write,
+	.fsl_pq_mdio_read	= native_fsl_pq_mdio_read,
+};
+
+struct pv_context_ops pv_context_ops = {
+	.init_new_context	= native_init_new_context,
+	.destroy_context	= native_destroy_context,
+	.switch_mmu_context	= native_switch_mmu_context,
+	.mmu_context_init	= native_mmu_context_init,
+};
+
+struct pv_serial_ops pv_serial_ops = {
+	.udbg_init_uart	= native_udbg_init_uart,
+};
+
+/* pv_time_ops */
+void __init paravirt_time_init_cont(void)
+{
+	pv_time_ops.time_init_cont();
+}
+
+void paravirt_timer_interrupt(struct pt_regs * regs)
+{	
+	pv_time_ops.timer_interrupt(regs);
+}
+
+void __init paravirt_clocksource_init(void)
+{
+	pv_time_ops.clocksource_init();
+}
+
+
+/* pv_context_ops */
+int paravirt_init_new_context(struct task_struct *t, struct mm_struct *mm)
+{
+	return pv_context_ops.init_new_context(t, mm);
+}
+
+void paravirt_destroy_context(struct mm_struct *mm)
+{
+	pv_context_ops.destroy_context(mm);
+}
+
+void paravirt_switch_mmu_context(struct mm_struct *prev, struct mm_struct *next)
+{
+	pv_context_ops.switch_mmu_context(prev, next);
+}
+
+void __init paravirt_mmu_context_init(void)
+{
+	pv_context_ops.mmu_context_init();
+}
+
+/* pv_irq_ops */
+void paravirt_do_IRQ(struct pt_regs *regs)
+{
+	pv_irq_ops.do_IRQ(regs);
+}
+
+
+unsigned int paravirt_irq_of_parse_and_map(struct device_node *dev, int index)
+{
+	return pv_irq_ops.irq_of_parse_and_map(dev, index);
+}
+
+/* pv_cpu_ops */
+unsigned int paravirt_get_pvr(void)
+{
+	return pv_cpu_ops.get_pvr();
+}
+
+unsigned int paravirt_get_svr(void)
+{
+	return pv_cpu_ops.get_svr();
+}
+
+int fsl_pq_mdio_write(struct mii_bus *bus, int mii_id, int devad,
+				int regnum, u16 value)
+{
+	return pv_mdio_ops.fsl_pq_mdio_write(bus, mii_id, devad, regnum, value);
+}
+
+int fsl_pq_mdio_read(struct mii_bus *bus, int mii_id,
+				int devad, int regnum)
+{
+	return pv_mdio_ops.fsl_pq_mdio_read(bus, mii_id, devad, regnum);
+}
+
+void paravirt_udbg_init_uart(void __iomem *comport, unsigned int speed,
+		unsigned int clock)
+{
+	return pv_serial_ops.udbg_init_uart(comport, speed, clock);
+}
+
+void __kprobes paravirt_DebugException(struct pt_regs *regs, unsigned long debug_status)
+{
+	pv_cpu_ops.DebugException(regs, debug_status);
+
+}
+
+void  paravirt_prime_debug_regs(struct thread_struct *thread)
+{
+	pv_cpu_ops.prime_debug_regs(thread);
+}
+
+int paravirt_kgdb_arch_handle_exception(int vector, int signo, int err_code,
+			char *remcom_in_buffer, char *remcom_out_buffer,
+			struct pt_regs *linux_regs)
+{
+
+	return pv_cpu_ops.kgdb_arch_handle_exception(vector, signo, err_code,
+			remcom_in_buffer, remcom_out_buffer, linux_regs);
+}
+
+
+int paravirt_ppc_proc_freq(void)
+{
+	return pv_cpu_ops.ppc_proc_freq();
+}
+
+/* pv_mmu_ops */
+void paravirt_vmmu_restore (void)
+{
+	pv_mmu_ops.vmmu_restore();
+}
+
+void __init paravirt_MMU_init_hw(void)
+{
+	pv_mmu_ops.MMU_init_hw();
+}
+
+unsigned long __init paravirt_mmu_mapin_ram(unsigned long top)
+{
+	return pv_mmu_ops.mmu_mapin_ram(top);
+}
+
+void paravirt_MMU_setup(void)
+{
+	pv_mmu_ops.MMU_setup();
+}
+
+void __init paravirt_MMU_init(void)
+{
+	pv_mmu_ops.MMU_init();
+}
+
+void paravirt_flush_dcache_page(struct page *page)
+{
+	pv_mmu_ops.flush_dcache_page(page);
+}
+
+int paravirt_map_page(unsigned long va, phys_addr_t pa, int flags)
+{
+	return	pv_mmu_ops.map_page(va, pa, flags);
+}
+
+int paravirt_early_init_dt_scan_memory_ppc(unsigned long node,
+		const char *uname, int depth, void *data)
+{
+       return pv_mmu_ops.early_init_dt_scan_memory_ppc(node,
+					uname, depth, data);
+}
+
+void paravirt___ioremap(phys_addr_t addr, unsigned long size, unsigned long flags)
+{
+	pv_mmu_ops.__ioremap(addr, size, flags);
+}
+
+void paravirt__set_pte_at(struct mm_struct *mm, unsigned long addr, 
+					pte_t *ptep, pte_t pte, int percpu) 
+{
+	pv_mmu_ops.__set_pte_at(mm, addr, ptep, pte, percpu);
+}
+
+inline int paravirt_enabled(void)
+{
+        return pv_info.paravirt_enabled;
+}
+
+#ifdef CONFIG_PCI
+int paravirt_pci_read_irq_line(struct pci_dev *dev)
+{
+	return 0;
+}
+#endif
+
+extern struct pv_time_ops pv_time_ops;
+extern struct pv_cpu_ops pv_cpu_ops;
+extern struct pv_irq_ops pv_irq_ops;
+extern struct pv_mmu_ops pv_mmu_ops; 
+extern struct pv_mdio_ops pv_mdio_ops;
+extern struct pv_context_ops pv_context_ops;
+
+EXPORT_SYMBOL    (pv_info);
+EXPORT_SYMBOL    (pv_time_ops);
+EXPORT_SYMBOL    (pv_cpu_ops);
+EXPORT_SYMBOL    (pv_context_ops);
+EXPORT_SYMBOL    (pv_mmu_ops);
+EXPORT_SYMBOL    (pv_irq_ops);
+EXPORT_SYMBOL    (pv_mdio_ops);
diff --git a/arch/powerpc/kernel/paravirt_entry_32.S b/arch/powerpc/kernel/paravirt_entry_32.S
new file mode 100644
index 0000000..32077b6
--- /dev/null
+++ b/arch/powerpc/kernel/paravirt_entry_32.S
@@ -0,0 +1,44 @@
+/*
+ *  Normally this file would contain the system call entry code, context
+ *  switch code, and exception/interrupt return code for PowerPC.
+ *  In this paravirt version of entry_32.S only a few redirects remain.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version
+ *  2 of the License, or (at your option) any later version.
+ *
+ */
+
+#include <asm/reg.h>
+#include <asm/ppc_asm.h>
+#include <asm/asm-offsets.h>
+
+	.globl	paravirt_transfer_to_handler
+	.weak	paravirt_transfer_to_handler
+paravirt_transfer_to_handler:
+	b	native_transfer_to_handler
+
+	.globl	paravirt_ret_from_syscall
+	.weak	paravirt_ret_from_syscall
+paravirt_ret_from_syscall:
+	b	native_ret_from_syscall
+
+	.globl  paravirt_syscall_exit_work
+	.weak  paravirt_syscall_exit_work
+paravirt_syscall_exit_work:
+	b	native_syscall_exit_work
+
+	.globl	paravirt_restore
+	.weak	paravirt_restore
+paravirt_restore:
+	b	native_restore
+
+	.globl	paravirt_load_dbcr0
+	.weak	paravirt_load_dbcr0
+paravirt_load_dbcr0:
+	b	native_load_dbcr0
+
+_GLOBAL(paravirt_switch)
+.weak paravirt_switch
+	b	native_switch
diff --git a/arch/powerpc/kernel/paravirt_misc_32.S b/arch/powerpc/kernel/paravirt_misc_32.S
new file mode 100644
index 0000000..28cb3fb
--- /dev/null
+++ b/arch/powerpc/kernel/paravirt_misc_32.S
@@ -0,0 +1,32 @@
+/*
+ *  misc operations, for paravirt implementation.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version
+ *  2 of the License, or (at your option) any later version.
+ *
+ */
+
+#include <asm/ppc_asm.h>
+#include <asm/asm-offsets.h>
+
+_GLOBAL(paravirt_clean_dcache_range)
+.weak paravirt_clean_dcache_range
+		b	native_clean_dcache_range
+
+_GLOBAL(paravirt__flush_dcache_icache)
+.weak paravirt__flush_dcache_icache
+        b       native__flush_dcache_icache
+
+_GLOBAL(paravirt_flush_dcache_range)
+.weak paravirt_flush_dcache_range
+        b       native_flush_dcache_range
+
+_GLOBAL(paravirt__flush_icache_range)
+.weak paravirt__flush_icache_range
+        b       native__flush_icache_range
+
+_GLOBAL(paravirt__flush_dcache_icache_phys)
+.weak paravirt__flush_dcache_icache_phys
+        b       native__flush_dcache_icache_phys
diff --git a/arch/powerpc/kernel/pci-common.c b/arch/powerpc/kernel/pci-common.c
index 0c0567e..d4b8d86 100644
--- a/arch/powerpc/kernel/pci-common.c
+++ b/arch/powerpc/kernel/pci-common.c
@@ -206,12 +206,14 @@ char __devinit *pcibios_setup(char *str)
 	return str;
 }
 
+int paravirt_pci_read_irq_line(struct pci_dev *pci_dev) 
+	__attribute__((weak, alias("native_pci_read_irq_line")));
 /*
  * Reads the interrupt pin to determine if interrupt is use by card.
  * If the interrupt is used, then gets the interrupt line from the
  * openfirmware and sets it in the pci_dev and pci_config line.
  */
-int pci_read_irq_line(struct pci_dev *pci_dev)
+int native_pci_read_irq_line(struct pci_dev *pci_dev)
 {
 	struct of_irq oirq;
 	unsigned int virq;
@@ -280,6 +282,11 @@ int pci_read_irq_line(struct pci_dev *pci_dev)
 
 	return 0;
 }
+
+int pci_read_irq_line(struct pci_dev *pci_dev)
+{
+	return paravirt_pci_read_irq_line(pci_dev);
+}
 EXPORT_SYMBOL(pci_read_irq_line);
 
 /*
diff --git a/arch/powerpc/kernel/process.c b/arch/powerpc/kernel/process.c
index 55bb81e..9d8a535 100644
--- a/arch/powerpc/kernel/process.c
+++ b/arch/powerpc/kernel/process.c
@@ -192,6 +192,26 @@ void flush_vsx_to_thread(struct task_struct *tsk)
 
 #ifdef CONFIG_SPE
 
+#if defined(CONFIG_PARAVIRT) && !defined(CONFIG_WRHV)
+/* refer to native implementation in
+ * linux/arch/powerpc/kernel/head_fsl_booke.S
+ */
+void giveup_spe(struct task_struct *tsk)
+{
+	/* if no previous owner, done */
+	if (!tsk){
+                return;
+        }
+
+        /* disable SPE for previous task */
+        tsk->thread.regs->msr &= ~MSR_SPE;
+
+#ifndef CONFIG_SMP
+        last_task_used_spe = 0;
+#endif /* CONFIG_SMP */
+}
+#endif
+
 void enable_kernel_spe(void)
 {
 	WARN_ON(preemptible());
@@ -322,8 +342,10 @@ static void set_debug_reg_defaults(struct thread_struct *thread)
 	thread->dbcr1 = 0;
 #endif
 }
+void paravirt_prime_debug_regs(struct thread_struct *thread)
+	__attribute__((weak, alias("native_prime_debug_regs")));
 
-static void prime_debug_regs(struct thread_struct *thread)
+void native_prime_debug_regs(struct thread_struct *thread)
 {
 	mtspr(SPRN_IAC1, thread->iac1);
 	mtspr(SPRN_IAC2, thread->iac2);
@@ -353,6 +375,11 @@ static void prime_debug_regs(struct thread_struct *thread)
 	mtspr(SPRN_DBCR2, thread->dbcr2);
 #endif
 }
+
+static void prime_debug_regs(struct thread_struct *thread)
+{
+	paravirt_prime_debug_regs(thread);
+}
 /*
  * Unless neither the old or new thread are making use of the
  * debug registers, set the debug registers from the values
diff --git a/arch/powerpc/kernel/prom.c b/arch/powerpc/kernel/prom.c
index 05131d6..d17d45b 100644
--- a/arch/powerpc/kernel/prom.c
+++ b/arch/powerpc/kernel/prom.c
@@ -479,7 +479,11 @@ static int __init early_init_dt_scan_drconf_memory(unsigned long node)
 #define early_init_dt_scan_drconf_memory(node)	0
 #endif /* CONFIG_PPC_PSERIES */
 
-static int __init early_init_dt_scan_memory_ppc(unsigned long node,
+int paravirt_early_init_dt_scan_memory_ppc(unsigned long node,
+			const char *uname, int depth, void *data)
+	__attribute__((weak, alias("native_early_init_dt_scan_memory_ppc")));
+
+int __init native_early_init_dt_scan_memory_ppc(unsigned long node,
 						const char *uname,
 						int depth, void *data)
 {
@@ -490,6 +494,13 @@ static int __init early_init_dt_scan_memory_ppc(unsigned long node,
 	return early_init_dt_scan_memory(node, uname, depth, data);
 }
 
+static int __init early_init_dt_scan_memory_ppc(unsigned long node,
+						const char *uname,
+						int depth, void *data)
+{
+	return  paravirt_early_init_dt_scan_memory_ppc(node, uname, depth, data);
+}
+
 void __init early_init_dt_add_memory_arch(u64 base, u64 size)
 {
 #if defined(CONFIG_PPC64)
diff --git a/arch/powerpc/kernel/setup-common.c b/arch/powerpc/kernel/setup-common.c
index b028d1d..5ec32cd 100644
--- a/arch/powerpc/kernel/setup-common.c
+++ b/arch/powerpc/kernel/setup-common.c
@@ -161,6 +161,30 @@ extern u32 cpu_temp_both(unsigned long cpu);
 DEFINE_PER_CPU(unsigned int, cpu_pvr);
 #endif
 
+unsigned paravirt_get_pvr(void) __attribute__((weak, alias("native_get_pvr")));
+unsigned int native_get_pvr(void)
+{
+	return mfspr(SPRN_PVR);
+}
+
+unsigned int get_pvr(void)
+{
+	return paravirt_get_pvr();
+}
+EXPORT_SYMBOL(get_pvr);
+
+unsigned paravirt_get_svr(void) __attribute__((weak, alias("native_get_svr")));
+unsigned int native_get_svr(void)
+{
+	return mfspr(SPRN_SVR);
+}
+
+unsigned int get_svr(void)
+{
+	return paravirt_get_svr();
+}
+EXPORT_SYMBOL(get_svr);
+
 static int show_cpuinfo(struct seq_file *m, void *v)
 {
 	unsigned long cpu_id = (unsigned long)v - 1;
@@ -209,11 +233,15 @@ static int show_cpuinfo(struct seq_file *m, void *v)
 		return 0;
 	}
 
+#ifdef CONFIG_PARAVIRT
+	pvr = get_pvr();
+#else
 #ifdef CONFIG_SMP
 	pvr = per_cpu(cpu_pvr, cpu_id);
 #else
 	pvr = mfspr(SPRN_PVR);
 #endif
+#endif /* CONFIG_PARAVIRT */
 	maj = (pvr >> 8) & 0xFF;
 	min = pvr & 0xFF;
 
diff --git a/arch/powerpc/kernel/setup_32.c b/arch/powerpc/kernel/setup_32.c
index 432a4a8..ba42582 100644
--- a/arch/powerpc/kernel/setup_32.c
+++ b/arch/powerpc/kernel/setup_32.c
@@ -78,6 +78,10 @@ int ucache_bsize;
  * from the address that it was linked at, so we must use RELOC/PTRRELOC
  * to access static data (including strings).  -- paulus
  */
+#ifdef CONFIG_PARAVIRT
+extern void paravirt_init(void);
+#endif
+
 notrace unsigned long __init early_init(unsigned long dt_ptr)
 {
 	unsigned long offset = reloc_offset();
@@ -87,12 +91,19 @@ notrace unsigned long __init early_init(unsigned long dt_ptr)
 	 * caches on yet */
 	memset_io((void __iomem *)PTRRELOC(&__bss_start), 0,
 			__bss_stop - __bss_start);
+	
+	/* 
+	 * initialize paravirtual operations 
+	 */
+#ifdef CONFIG_PARAVIRT
+	paravirt_init();
+#endif
 
 	/*
 	 * Identify the CPU type and fix up code sections
 	 * that depend on which cpu we have.
 	 */
-	spec = identify_cpu(offset, mfspr(SPRN_PVR));
+	spec = identify_cpu(offset, get_pvr());
 
 	do_feature_fixups(spec->cpu_features,
 			  PTRRELOC(&__start___ftr_fixup),
@@ -136,7 +147,7 @@ notrace void __init machine_init(unsigned long dt_ptr)
 		ppc_md.power_save = ppc6xx_idle;
 #endif
 
-#ifdef CONFIG_E500
+#if defined(CONFIG_E500) && !defined(CONFIG_PARAVIRT)
 	if (cpu_has_feature(CPU_FTR_CAN_DOZE) ||
 	    cpu_has_feature(CPU_FTR_CAN_NAP))
 		ppc_md.power_save = e500_idle;
@@ -299,6 +310,18 @@ void __init setup_arch(char **cmdline_p)
 	if (ppc_md.init_early)
 		ppc_md.init_early();
 
+#ifdef CONFIG_WRHV
+	/* give an opporunity for special legacy serial or
+	   other setup to be run */
+	if (ppc_md.earlycon_setup)
+		ppc_md.earlycon_setup();
+#endif
+
+#if defined(CONFIG_PCI) && defined(CONFIG_WRHV)
+	if (ppc_md.enable_pci_law)
+		ppc_md.enable_pci_law();
+#endif
+
 	find_legacy_serial_ports();
 
 	smp_setup_cpu_maps();
diff --git a/arch/powerpc/kernel/smp.c b/arch/powerpc/kernel/smp.c
index 82e68f4..3a8c805 100644
--- a/arch/powerpc/kernel/smp.c
+++ b/arch/powerpc/kernel/smp.c
@@ -50,6 +50,8 @@
 #include <asm/paca.h>
 #endif
 
+#include <asm/wrhv.h>
+
 #ifdef DEBUG
 #include <asm/udbg.h>
 #define DBG(fmt...) udbg_printf(fmt)
@@ -235,7 +237,7 @@ struct thread_info *current_set[NR_CPUS];
 
 static void __devinit smp_store_cpu_info(int id)
 {
-	per_cpu(cpu_pvr, id) = mfspr(SPRN_PVR);
+	per_cpu(cpu_pvr, id) = get_pvr();
 }
 
 static void __init smp_create_idle(unsigned int cpu)
@@ -281,6 +283,10 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
  
 	smp_space_timers(max_cpus);
 
+#ifdef CONFIG_WRHV
+	wrhv_umask_IPIs_for_vcore();
+#endif
+
 	for_each_possible_cpu(cpu)
 		if (cpu != boot_cpuid)
 			smp_create_idle(cpu);
diff --git a/arch/powerpc/kernel/time.c b/arch/powerpc/kernel/time.c
index 14ee644..4c266fc 100644
--- a/arch/powerpc/kernel/time.c
+++ b/arch/powerpc/kernel/time.c
@@ -438,7 +438,14 @@ static inline void update_gtod(u64 new_tb_stamp, u64 new_stamp_xsec,
 	 * We expect the caller to have done the first increment of
 	 * vdso_data->tb_update_count already.
 	 */
+#ifndef CONFIG_WRHV
 	vdso_data->tb_orig_stamp = new_tb_stamp;
+#else
+	/* We substract tb orig stamp with our paravirtualized get_tb() in
+	 * advance to make vdso easy for guest OS.
+	 */
+	vdso_data->tb_orig_stamp = get_tb() - new_tb_stamp;
+#endif
 	vdso_data->stamp_xsec = new_stamp_xsec;
 	vdso_data->tb_to_xs = new_tb_to_xs;
 	vdso_data->wtom_clock_sec = wall_to_monotonic.tv_sec;
@@ -602,7 +609,15 @@ void set_perf_event_pending(void)
  * timer_interrupt - gets called when the decrementer overflows,
  * with interrupts disabled.
  */
-void timer_interrupt(struct pt_regs * regs)
+void paravirt_timer_interrupt(struct pt_regs *regs)
+	__attribute__((weak, alias("native_timer_interrupt")));
+
+void timer_interrupt(struct pt_regs *regs)
+{
+	paravirt_timer_interrupt(regs);
+}
+
+void native_timer_interrupt(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs;
 	struct decrementer_clock *decrementer =  &__get_cpu_var(decrementers);
@@ -783,7 +798,7 @@ static int __init get_freq(char *name, int cells, unsigned long *val)
 /* should become __cpuinit when secondary_cpu_time_init also is */
 void start_cpu_decrementer(void)
 {
-#if defined(CONFIG_BOOKE) || defined(CONFIG_40x)
+#if (defined(CONFIG_BOOKE) || defined(CONFIG_40x)) && !defined(CONFIG_WRHV)
 	/* Clear any pending timer interrupts */
 	mtspr(SPRN_TSR, TSR_ENW | TSR_WIS | TSR_DIS | TSR_FIS);
 
@@ -910,7 +925,15 @@ void update_vsyscall_tz(void)
 	++vdso_data->tb_update_count;
 }
 
-static void __init clocksource_init(void)
+void paravirt_clocksource_init(void)
+	__attribute__((weak, alias("native_clocksource_init")));
+
+void __init clocksource_init(void)
+{
+	paravirt_clocksource_init();
+}
+
+void __init native_clocksource_init(void)
 {
 	struct clocksource *clock;
 
@@ -1009,6 +1032,23 @@ void secondary_cpu_time_init(void)
 	register_decrementer_clockevent(smp_processor_id());
 }
 
+/* time_init() is seperate into two parts, the first part is common to
+ * native and paravirtual target. The 2nd part, time_init_cont is target
+ * specific init
+ */
+void paravirt_time_init_cont(void)
+	__attribute__((weak, alias("native_time_init_cont")));
+
+void __init time_init_cont(void)
+{
+	paravirt_time_init_cont();
+}
+
+void __init native_time_init_cont(void)
+{
+	init_decrementer_clockevent();
+}
+
 /* This function is only called on the boot processor */
 void __init time_init(void)
 {
@@ -1117,7 +1157,8 @@ void __init time_init(void)
 	if (!firmware_has_feature(FW_FEATURE_ISERIES))
 		clocksource_init();
 
-	init_decrementer_clockevent();
+	/* continue with native or paravirtual specific time_init */
+	time_init_cont();
 }
 
 
diff --git a/arch/powerpc/kernel/traps.c b/arch/powerpc/kernel/traps.c
index 398c3ba..3286e6d 100644
--- a/arch/powerpc/kernel/traps.c
+++ b/arch/powerpc/kernel/traps.c
@@ -769,7 +769,15 @@ static int emulate_instruction(struct pt_regs *regs)
 	if ((instword & PPC_INST_MFSPR_PVR_MASK) == PPC_INST_MFSPR_PVR) {
 		PPC_WARN_EMULATED(mfpvr, regs);
 		rd = (instword >> 21) & 0x1f;
+#ifndef CONFIG_WRHV
 		regs->gpr[rd] = mfspr(SPRN_PVR);
+#else
+		/* 
+		 * PVR for wrhv hypervisor should be 0x80200000,
+		 * why is it 0x80200010?
+		 */
+		regs->gpr[rd] = 0x80200010;
+#endif
 		return 0;
 	}
 
@@ -1110,7 +1118,10 @@ static void handle_debug(struct pt_regs *regs, unsigned long debug_status)
 		mtspr(SPRN_DBCR0, current->thread.dbcr0);
 }
 
-void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
+void paravirt_DebugException(struct pt_regs *regs, unsigned long debug_status)
+	 __attribute__((weak, alias("native_DebugException")));
+
+void __kprobes native_DebugException(struct pt_regs *regs, unsigned long debug_status)
 {
 	current->thread.dbsr = debug_status;
 
@@ -1173,6 +1184,11 @@ void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
 	} else
 		handle_debug(regs, debug_status);
 }
+
+void __kprobes DebugException(struct pt_regs *regs, unsigned long debug_status)
+{
+	paravirt_DebugException(regs, debug_status);
+}
 #endif /* CONFIG_PPC_ADV_DEBUG_REGS */
 
 #if !defined(CONFIG_TAU_INT)
diff --git a/arch/powerpc/kernel/udbg.c b/arch/powerpc/kernel/udbg.c
index e39cad8..32934c0 100644
--- a/arch/powerpc/kernel/udbg.c
+++ b/arch/powerpc/kernel/udbg.c
@@ -62,6 +62,8 @@ void __init udbg_early_init(void)
 	udbg_init_cpm();
 #elif defined(CONFIG_PPC_EARLY_DEBUG_USBGECKO)
 	udbg_init_usbgecko();
+#elif defined(CONFIG_PPC_EARLY_DEBUG_WRHV_DUART)
+	udbg_init_wrhv_duart();
 #endif
 
 #ifdef CONFIG_PPC_EARLY_DEBUG
diff --git a/arch/powerpc/kernel/udbg_16550.c b/arch/powerpc/kernel/udbg_16550.c
index b4b167b..868c5f2 100644
--- a/arch/powerpc/kernel/udbg_16550.c
+++ b/arch/powerpc/kernel/udbg_16550.c
@@ -12,6 +12,10 @@
 #include <asm/udbg.h>
 #include <asm/io.h>
 
+#include <asm/wrhv.h>
+#include <vbi/vbi.h>
+#include <vbi/pdc.h>
+
 extern u8 real_readb(volatile u8 __iomem  *addr);
 extern void real_writeb(u8 data, volatile u8 __iomem *addr);
 extern u8 real_205_readb(volatile u8 __iomem  *addr);
@@ -87,8 +91,12 @@ static int udbg_550_getc(void)
 	return -1;
 }
 
-void udbg_init_uart(void __iomem *comport, unsigned int speed,
-		    unsigned int clock)
+void paravirt_udbg_init_uart(void __iomem *comport, unsigned int speed,
+		unsigned int clock)
+		__attribute__((weak, alias("native_udbg_init_uart")));
+
+void native_udbg_init_uart(void __iomem *comport, unsigned int speed,
+		unsigned int clock)
 {
 	unsigned int dll, base_bauds;
 
@@ -119,6 +127,13 @@ void udbg_init_uart(void __iomem *comport, unsigned int speed,
 		udbg_getc = udbg_550_getc;
 		udbg_getc_poll = udbg_550_getc_poll;
 	}
+
+}
+
+void udbg_init_uart(void __iomem *comport, unsigned int speed,
+		unsigned int clock)
+{
+	paravirt_udbg_init_uart(comport, speed, clock);
 }
 
 unsigned int udbg_probe_uart_speed(void __iomem *comport, unsigned int clock)
@@ -298,3 +313,44 @@ void __init udbg_init_40x_realmode(void)
 	udbg_getc_poll = NULL;
 }
 #endif /* CONFIG_PPC_EARLY_DEBUG_40x */
+
+#ifdef CONFIG_PPC_EARLY_DEBUG_WRHV_DUART
+/* following extern functions is implemented in wrhv.c
+ * to access hypervisor serial driver
+ */
+extern void wrhv_duart_putc(char c);
+extern vbi_pdc_handle duart_pdc;
+extern int wrhv_duart_tstc(void);
+extern int wrhv_duart_getc(void);
+extern int wrhv_duart_init(void);
+
+static void udbg_wrhv_duart_flush(void)
+{
+}
+
+void udbg_wrhv_duart_putc(char c)
+{
+	wrhv_duart_putc(c);
+}
+
+int udbg_wrhv_duart_getc(void)
+{
+	if (!wrhv_duart_tstc()) {
+		return -1;
+	}
+	return wrhv_duart_getc();
+}
+
+void __init udbg_init_wrhv_duart(void)
+{
+	wrhv_duart_init();
+
+	/* setup function pointer for early
+	 * console output and set no input polling.
+	 */
+	udbg_putc = udbg_wrhv_duart_putc;
+	udbg_flush = udbg_wrhv_duart_flush;
+	udbg_getc = udbg_wrhv_duart_getc;
+	udbg_getc_poll = NULL;
+}
+#endif /* CONFIG_PPC_EARLY_WRHV_DUART */
diff --git a/arch/powerpc/kernel/vbi/util.c b/arch/powerpc/kernel/vbi/util.c
new file mode 100644
index 0000000..0fd41fd
--- /dev/null
+++ b/arch/powerpc/kernel/vbi/util.c
@@ -0,0 +1,164 @@
+/*
+ * util.c - utilities routines for guest OS para-virtualization
+ *
+ * Copyright (c) 2009 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See the GNU General Public License for more details.
+ *
+ */
+
+/*
+This module implements a library which is handy for para-virtualized
+guest os to use. The routines are developed based on the need while
+para-virtualize linux, therefore, may need some tweaks to be generic.
+*/
+
+#include <asm/page.h>
+#include <linux/module.h>
+#include <vbi/interface.h>
+#include <vbi/vmmu.h>
+#include <vbi/syscall.h>
+#include <vbi/vbi.h>
+
+
+/* defines */
+
+/* globals */
+
+/*
+ * wr_config is initialized as part of the guest os init, before os turns on
+ * MMU. For paravirualized linux, it is initialized in plaform_init().
+ */
+
+extern struct vb_config *wr_config;
+extern struct vb_status *wr_status;
+extern struct vb_control *wr_control;
+
+/* local */
+
+/* extern */
+extern void pteAttrSet(VMMU_PTE * pte, u_int attr);
+extern void vmmuPageTableDisplay(VMMU_LEVEL_1_DESC *l1, int vmmuon);
+
+/* forward declarations */
+
+/*
+ * vb_memsize_get should not be called before wr_config is initialized
+ */
+unsigned int vb_memsize_get(void)
+{
+	if (wr_config == (struct vb_config *)(-1)) 
+		return 0;
+	return VBI_MEM_SIZE_GET();
+}
+
+unsigned int vb_context_get(void)
+{
+	if (wr_config == (struct vb_config *)(-1))
+		return 0xdeadbee0;
+	return VBI_CONTEXT_ID_GET();
+}
+
+void vb_pte_set(void *pPte, unsigned long paddr, int protval)
+{
+
+	/* caller has guaranteed pPte != NULL */
+
+	*(uint *) pPte = (uint) VMMU_PTE_VALID_MASK;
+
+	/* linux uses more than the permission bits, in word1 of PTE */
+
+	*((uint *) ((uint *) pPte) + 1) = (((u_int) paddr & VMMU_PTE_RPN_MASK) | (protval & 0xfff));
+
+	return;
+}
+
+/*
+ * turn on mmu for the particular context
+ *
+ * note, caller must make sure, context switch inside the guest OS must
+ * not happen during this call.
+ */
+
+int vb_context_mmu_on(int pid,	/* context id */
+	void *pgtable, int pagesize, int asid, int vmmu_handle,
+	int debug)
+{
+	static VMMU_CONFIG vmmu_cfg;
+
+	if (wr_config == (struct vb_config *)(- 1) || pgtable == NULL || pagesize <= 0)
+		return -1;
+
+#ifdef CONFIG_WRHV_ASID_OPTIMIZATION
+	/* Create needs to be called when dealing with kernel only,
+	   once we create a process, in this case we don't need to
+	   copy the kernel page tables since swapper_pg_dir is being
+	   passed in. */
+	if (asid == 1) { /* special case.  Kernel ASID needs to
+		be created here.  Once the first userspace process is
+		available init, create and destroy will do all the heavy
+		lifting. */
+		vmmu_cfg.addr = (VMMU_LEVEL_1_DESC *) pgtable;
+		vmmu_cfg.flush_type = VMMU_TLB_FLUSH_ASID;
+		vmmu_cfg.asid = asid;
+		vmmu_cfg.vmmu_handle = vmmu_handle;
+
+		if ((vbi_create_vmmu(&vmmu_cfg)) != 0)
+			return -1;
+	}
+	wr_control->vb_control_regs.asid = asid;
+	wr_control->vb_control_regs.vmmu_handle = vmmu_handle;
+	vbi_load_ctx();
+#else
+	vmmu_cfg.addr = (VMMU_LEVEL_1_DESC *) pgtable;
+	vmmu_cfg.flush_type = pagesize;
+	vmmu_cfg.asid = pid;
+	vmmu_cfg.vmmu_handle = 0; /* only vmmu 0 is supported for now */
+
+	if ((vbi_config_vmmu(&vmmu_cfg)) != 0)
+		return -1;
+
+	if (debug) {
+		printk("L1 page table address %p\n", pgtable);
+		vmmuPageTableDisplay(pgtable, 0);
+		printk("End of page table display \n");
+	}
+
+	vbi_enable_vmmu(vmmu_cfg.vmmu_handle);
+#endif
+	return 0;
+}
+EXPORT_SYMBOL(vb_context_mmu_on);
+
+void vb__flush_dcache_icache(void *start)
+{
+	vbi_flush_icache(start, 4096);
+	vbi_flush_dcache(start, 4096);
+}
+
+void vb_flush_dcache_range(unsigned long start, unsigned long stop)
+{
+	vbi_flush_dcache((void *) start, (stop - start + 1));
+}
+
+void vb__flush_icache_range(unsigned long start, unsigned long stop)
+{
+	vbi_update_text_cache((void *) start, (stop - start + 1));
+}
+
+void vb__flush_dcache_icache_phys(unsigned long physaddr)
+{
+	vbi_flush_icache((void *) physaddr, 4096);
+	vbi_flush_dcache((void *) physaddr, 4096);
+}
+
+EXPORT_SYMBOL(wrhv_int_lock);
+EXPORT_SYMBOL(wrhv_int_unlock);
+EXPORT_SYMBOL(wrhv_int_lvl_get);
diff --git a/arch/powerpc/kernel/vbi/vmmu_display.c b/arch/powerpc/kernel/vbi/vmmu_display.c
new file mode 100644
index 0000000..d1fc41a
--- /dev/null
+++ b/arch/powerpc/kernel/vbi/vmmu_display.c
@@ -0,0 +1,140 @@
+/*
+ * vmmu_display.c - hypervisor VMMU operations
+ *
+ * Copyright (c) 2009 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See the GNU General Public License for more details.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <vbi/interface.h>
+#include <vbi/vmmu.h>
+
+#define __va(paddr) (((unsigned long )(paddr))+0xC0000000)
+#define __pa(vaddr) (((unsigned long )(vaddr))-0xC0000000)
+
+
+/*
+ *
+ * vmmuPageTableDisplay - display information about the specified page table
+ *
+ * This routine display all the VMMU PTE entries in the specified table
+ *
+ */
+
+void vmmuPageTableDisplay(VMMU_LEVEL_1_DESC *l1, int vmmuon)
+{
+	VMMU_LEVEL_2_DESC *l2;
+	VMMU_PTE *pte;
+	VMMU_EFFECTIVE_ADDR ea;
+	u_int l1_index;
+	u_int i,j;
+
+	l1_index = 0;
+	ea.addr = 0;
+
+	printk("Logical           Physical          R C U[01234567] WIMGE S[XWR] U[XWR]\n");
+	printk("----------------- ----------------- - -  ---------- -----  -----  -----\n");
+
+	/* run through all the entries */
+	for (i=0; i<VMMU_L1_ENTRIES; i++) {
+		if (l1->field.v) {
+			ea.field.l1index = l1_index;
+			l2 = (VMMU_LEVEL_2_DESC *)VMMU_LBA_TO_ADDR(l1->field.l2ba);
+			if (vmmuon)
+				l2 = (VMMU_LEVEL_2_DESC *)__va(l2);
+
+			pte = (VMMU_PTE *)l2;
+
+			for (j=0; j<VMMU_L2_ENTRIES; j++) {
+				if (pte->field.v) {
+					ea.field.l2index = j;
+					printk ("%08x-%08x %08x-%08x %d %d ",
+					(u_int)ea.addr, (u_int)ea.addr + 0xfff,
+					pte->field.rpn << VMMU_RPN_SHIFT,
+					(pte->field.rpn << VMMU_RPN_SHIFT) + 0xfff,
+					pte->field.r, pte->field.c);
+					printk ("  %d%d%d%d%d%d%d%d  %d%d%d%d%d   %c%c%c    %c%c%c\n",
+					pte->field.u0, pte->field.u1,
+					pte->field.u2, pte->field.u3,
+					pte->field.u4, pte->field.u5,
+					pte->field.u6, pte->field.u7,
+					pte->field.w, pte->field.i,
+					pte->field.m,
+					pte->field.g, pte->field.e,
+					pte->field.sx ? 'X' : ' ',
+					pte->field.sw ? 'W' : ' ',
+					pte->field.sr ? 'R' : ' ',
+					pte->field.ux ? 'X' : ' ',
+					pte->field.uw ? 'W' : ' ',
+					pte->field.ur ? 'R' : ' ');
+				} /* pte field.v */
+				pte++;
+			} /* j */
+		} /* l1 field.v */
+		l1++;
+		l1_index++;
+	} /* i */
+}
+
+/*
+ * vmmuPteDisplay - display a specific PTE entry
+ *
+ * This routine display the VMMU PTE entrie corresponding to the specified
+ * virtual address.
+ *
+ */
+unsigned int vmmuPteDisplay(VMMU_LEVEL_1_DESC *l1, void *vaddr)
+{
+	VMMU_LEVEL_2_DESC  *l2;
+	VMMU_PTE *pte;
+
+	/* find the level-1 page table descriptor for the virtual address */
+	l1 += VMMU_L1_INDEX(vaddr);
+
+	/* if no level-2 table exists abort and return error */
+	if (!l1->field.v)
+		return -1;
+
+	/* locate correct PTE entry in level-2 table */
+	l2  = (VMMU_LEVEL_2_DESC *)VMMU_LBA_TO_ADDR(l1->field.l2ba) +
+		VMMU_L2_INDEX(vaddr);
+
+	l2 = (VMMU_LEVEL_2_DESC *)__va(l2);
+
+	pte = &l2->pte;
+
+	if (!pte->field.v)
+		return  -1;
+
+	printk("PTE for virtual address 0x%p:\n", vaddr);
+	printk("  Page Number:  0x%08x\n", pte->field.rpn<<VMMU_RPN_SHIFT);
+	printk("  Referenced:   %d\n", pte->field.r);
+	printk("  Changed:      %d\n", pte->field.c);
+	printk("  User bits:    %d%d%d%d%d%d%d%d\n",
+		pte->field.u0, pte->field.u1,
+		pte->field.u2, pte->field.u3,
+		pte->field.u4, pte->field.u5,
+		pte->field.u6, pte->field.u7);
+	printk("  WIMGE:        %d%d%d%d%d\n",
+		pte->field.w, pte->field.i, pte->field.m,
+		pte->field.g, pte->field.e);
+	printk("  Supv Perms:   %c%c%c\n",
+		pte->field.sr ? 'R' : '-',
+		pte->field.sw ? 'W' : '-',
+		pte->field.sx ? 'X' : '-');
+	printk("  User Perms:   %c%c%c\n",
+		pte->field.ur ? 'R' : '-',
+		pte->field.uw ? 'W' : '-',
+		pte->field.ux ? 'X' : '-');
+
+	return 0;
+}
diff --git a/arch/powerpc/kernel/vbi/wrhv.c b/arch/powerpc/kernel/vbi/wrhv.c
new file mode 100644
index 0000000..7409a13
--- /dev/null
+++ b/arch/powerpc/kernel/vbi/wrhv.c
@@ -0,0 +1,2655 @@
+/*
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation; either version 2, or (at your option) any
+ *  later version.
+ *
+ *  This program is distributed in the hope that it will be useful, but
+ *  WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  General Public License for more details.
+ *
+ *  Copyright (C) 2009 Wind River Systems, Inc.
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/irq.h>
+#include <linux/profile.h>
+#include <linux/wrhv.h>
+#include <linux/interrupt.h>
+#include <linux/vmalloc.h>
+#include <vbi/interface.h>
+#include <vbi/interrupt.h>
+#include <vbi/errors.h>
+
+#include <asm/page.h>
+#include <asm/pgtable.h>
+#include <asm/time.h>
+
+#include <linux/threads.h>
+#include <linux/kernel_stat.h>
+#include <linux/signal.h>
+#include <linux/sched.h>
+#include <linux/ptrace.h>
+#include <linux/ioport.h>
+#include <linux/timex.h>
+#include <linux/slab.h>
+#include <linux/delay.h>
+
+#include <linux/seq_file.h>
+#include <linux/cpumask.h>
+#include <linux/bitops.h>
+#include <linux/list.h>
+#include <linux/radix-tree.h>
+#include <linux/mutex.h>
+#include <linux/bootmem.h>
+#include <linux/pci.h>
+#include <linux/debugfs.h>
+
+#include <asm/uaccess.h>
+#include <asm/system.h>
+#include <asm/io.h>
+#include <asm/cache.h>
+#include <asm/prom.h>
+#include <asm/machdep.h>
+#include <asm/udbg.h>
+#include <asm/firmware.h>
+
+#include <asm/pgalloc.h>
+#include <asm/mmu_context.h>
+#include <asm/mmu.h>
+#include <asm/smp.h>
+#include <asm/btext.h>
+#include <asm/tlb.h>
+#include <asm/sections.h>
+#include <asm/pgtable.h>
+
+#include <linux/sched.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/string.h>
+#include <linux/types.h>
+#include <linux/mm.h>
+#include <linux/stddef.h>
+#include <linux/highmem.h>
+#include <linux/initrd.h>
+#include <linux/pagemap.h>
+
+#include <linux/kprobes.h>
+#include <linux/kexec.h>
+#include <linux/backlight.h>
+#include <linux/bug.h>
+#include <linux/kdebug.h>
+#include <linux/kallsyms.h>
+
+#include <mm/mmu_decl.h>
+#include <linux/lmb.h>
+
+#include <linux/major.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/of_platform.h>
+#include <linux/phy.h>
+#include <linux/phy_fixed.h>
+#include <linux/spi/spi.h>
+#include <linux/fsl_devices.h>
+#include <linux/fs_enet_pd.h>
+#include <linux/fs_uart_pd.h>
+
+#include <asm/irq.h>
+#include <sysdev/fsl_soc.h>
+#include <asm/cpm2.h>
+
+#include <asm/current.h>
+#include <asm/processor.h>
+
+#include <asm/paravirt.h>
+
+#include <linux/perf_event.h>
+#include <asm/trace.h>
+#include <trace/irq.h>
+#include <asm/ptrace.h>
+
+/* powerpc clocksource/clockevent code */
+
+#include <linux/clockchips.h>
+#include <linux/clocksource.h>
+#include <linux/kgdb.h>
+
+/* Context switching code */
+#include <asm/mmu_context.h>
+#include <asm/tlbflush.h>
+
+#include <asm/cputhreads.h>
+#include <linux/irq.h>
+#include <asm/tlb.h>
+#include <asm/arch_vbi.h>
+
+#include <vbi/vbi.h>
+#include <vbi/interface.h>
+
+/*
+ * We will set the default interrupt handler address into exec_table before
+ * early_init, then adjust the interrupt handler in early_init according to
+ * the cpu type. Since the early_init will zero all the bss section, we can't
+ * put the exec_table in bss section.
+ */
+VBI_EXC_OFFSETS_TABLE  exec_table __attribute__((__section__(".data")));
+struct vb_config *wr_config;		/* TODO kernel relocation friendly ? */
+struct vb_control *wr_control;
+struct vb_status *wr_status;
+EXPORT_SYMBOL(wr_config);
+EXPORT_SYMBOL(wr_status);
+
+extern int is_wrhv_duart_inited;
+
+void wrhv_mapping(void);
+void mpc85xx_power_down(void);
+
+extern int map_page(unsigned long, phys_addr_t, int);
+
+extern int vb_context_mmu_on(int pid,  /* context id */
+			void *pgtable,    /* level 1 page table */
+			int pagesize, int asid, int vmmu_handle, int debug);
+
+/* declared in linux/arch/powerpc/kernel/time.c */
+
+#define p_mapped_by_bats(x)     (0UL)
+#define p_mapped_by_tlbcam(x)   (0UL)
+
+unsigned long wrhv_cpu_freq = 0;
+
+int wrhv_earlycon = -1;
+char wrhv_macaddr[6];
+
+char wrhv_net_name[15]; /* eth0, eth1, eth2... */
+int wrhv_nic_num = 0; /* start with eth0 as default */
+int wrhv_nic_start = 0;
+
+unsigned int first_context, last_context;
+unsigned int next_context, nr_free_contexts;
+unsigned long *context_map;
+unsigned long *stale_map[NR_CPUS];
+struct mm_struct **context_mm;
+
+EXPORT_SYMBOL(context_mm);
+EXPORT_SYMBOL(stale_map);
+
+DEFINE_RAW_SPINLOCK(wrhv_context_lock);
+
+#define CTX_MAP_SIZE	\
+	(sizeof(unsigned long) * (last_context / BITS_PER_LONG + 1))
+
+extern unsigned int steal_context_up(unsigned int id);
+static void context_check_map(void) { }
+#define NO_CONTEXT	((unsigned long) -1)
+#define ASID_LAST_CONTEXT	CONFIG_WRHV_NUM_ASID
+#define ASID_FIRST_CONTEXT	2 /* ASID of 1 is reserved in the HV
+					for kernel context, 2 and > are
+					assumed to be userspace */
+#undef CONFIG_WRHV_DEBUG
+
+#ifdef CONFIG_WRHV_ASID_OPTIMIZATION
+#define KERNEL_BASE_ASID 1
+#else
+#define KERNEL_BASE_ASID 0
+#endif
+
+#define WRHV_EARLYCON_SIZE  14  /* sizeof("wrhv_earlycon=") */
+int __init wrhv_earlycon_setup(void)
+{
+	char *p = NULL;
+
+	if ((p = strstr(cmd_line, "wrhv_earlycon=")) != NULL) {
+	/* Since the maximal number supported of serial port is 8
+	 * in legacy serial, so here we just use this convention
+	 */
+		wrhv_earlycon =  p[WRHV_EARLYCON_SIZE] - 0x30;
+		printk(KERN_INFO "WRHV: early serial output port is at %d\n",
+			wrhv_earlycon);
+		return 1;
+	}
+
+	return 0;
+}
+
+#define WRHV_IF_NAME 7 /* sizeof(ifname) */
+#define ETH_LENGTH   4 /* length of eth */
+static int __init wrhv_net_name_setup(void)
+{
+	char *p = NULL;
+
+	if ((p = strstr(cmd_line, "ifname=")) != NULL) {
+		printk(KERN_INFO "WRHV: replacing MAC address for %s\n", p);
+		/* First occurance of ifname= in the bootline. Only copy 1
+		"ethX" for now */
+		strncpy(wrhv_net_name, p + WRHV_IF_NAME, ETH_LENGTH);
+		wrhv_nic_start = p[WRHV_IF_NAME + ETH_LENGTH-1] - 0x30;
+		return 1;
+	}
+	return 0;
+}
+__setup("ifname=", wrhv_net_name_setup);
+
+/* How many nics are we setting up? */
+#define WRHV_IFNIC_SIZE 7
+static int __init wrhv_net_num_setup(void)
+{
+	char *p = NULL;
+
+	if ((p = strstr(cmd_line, "ifnics=")) != NULL) {
+		wrhv_nic_num = p[WRHV_IFNIC_SIZE] - 0x30;
+		return 1;
+	}
+	return 0;
+}
+__setup("ifnics=", wrhv_net_num_setup);
+
+
+static int __init wrhv_macaddr_setup(char *str)
+{
+	int i;
+
+	for (i = 0; i < 6; i++) {
+		int ret, oct;
+
+		ret = get_option(&str, &oct);
+		if (!ret)
+			break;
+
+		wrhv_macaddr[i] = oct;
+		if (ret != 2)
+			break;
+	}
+	return 1;
+}
+__setup("ifmacaddr=", wrhv_macaddr_setup);
+
+uint32_t service_handle;
+void get_hv_bsp_server_handle(void)
+{
+	int32_t rc;
+
+	rc = vbi_ns_lookup ("bspServer", 0, &service_handle,
+						VBI_NS_NO_TIMEOUT, VBI_NS_OPTION_NONE);
+	if (rc)
+		printk ("bspServer lookup returned error code: %d\n", rc);
+}
+
+int bsp_service_handle(VBI_BSP_MSG *ask_msg, VBI_BSP_MSG_REPLY *reply_msg)
+{
+	int32_t rc = -1;
+
+	if (!service_handle) {
+		printk(KERN_ERR "Can't get bsp service handle!\n");
+		return rc;
+	}
+
+	rc = vbi_send (service_handle, ask_msg, sizeof(VBI_BSP_MSG),
+		reply_msg, sizeof(VBI_BSP_MSG_REPLY), NULL, NULL);
+
+	if (rc)
+		printk("vbi_send to the bspServer returned error code: %d\n", rc);
+
+        return rc;
+}
+
+uint32_t get_bsp_clock_freq(void)
+{
+	VBI_BSP_MSG clk_msg;
+	VBI_BSP_MSG_REPLY clk_reply;
+	uint16_t rc = -1;
+
+	clk_msg.request = VBI_BSP_CORE_FREQ; /* request CPU freq */
+
+	rc = bsp_service_handle(&clk_msg, &clk_reply);
+	if (rc)
+		return rc;
+	return (clk_reply.dataVal);
+}
+
+int wrhv_pci_law = 0;
+int __init wrhv_enable_pci_law(void)
+{
+	const char *opt;
+	opt = strstr(cmd_line, "wrhv_pci_law=");
+	if (opt) {
+		opt += 13;
+		while (*opt && *opt == ' ')
+			opt++;
+		if (!strncmp(opt, "on", 2))
+			wrhv_pci_law = 1;
+		else
+			wrhv_pci_law = 0;
+	}
+	
+	return 0;
+}
+
+int wrhv_dir_irq = 0;
+static int __init wrhv_enable_dir_irq(void)
+{
+	const char *opt;
+	opt = strstr(cmd_line, "wrhv_dir_irq=");
+	if (opt) {
+		opt += 13;
+		while (*opt && *opt == ' ')
+			opt++;
+		if (!strncmp(opt, "on", 2))
+			wrhv_dir_irq = 1;
+		else
+			wrhv_dir_irq = 0;
+	}
+
+	return 0;
+}
+
+static void wrhv_map_pages(unsigned long addr, size_t size, int flags)
+{
+	unsigned long va, i;
+	int r;
+
+	va = addr & PAGE_MASK;
+	size = PAGE_ALIGN(addr + size) - va;
+
+	for (i = 0; i < size; i += PAGE_SIZE) {
+		r = map_page(va + i, va + i, flags);
+		WARN_ON_ONCE(r);
+	}
+}
+
+void wrhv_mapping(void)
+{
+	struct config_page_map *pConfigPageMap = &wr_config->configPageMap[0];
+	uint32_t index = wr_config->configPageNum, i = 0;
+	for (i = 0;i < index;i++) {
+#ifdef WRHV_CONFIG_DEBUG
+		printk("Region No.: %d Address 0x%p Access Privilege 0x%x"
+			" Mapping Size 0x%x\n",i,
+			pConfigPageMap[i].address,
+			pConfigPageMap[i].accessPriv,
+			pConfigPageMap[i].size);
+#endif
+		wrhv_map_pages((unsigned long)pConfigPageMap[i].address,
+			pConfigPageMap[i].size,
+#ifdef CONFIG_PPC85xx_VT_MODE
+			pConfigPageMap[i].accessPriv ? PAGE_KERNEL : PAGE_KERNEL_RO);
+#else
+			pConfigPageMap[i].accessPriv ? PAGE_KERNEL_X : PAGE_KERNEL_ROX);
+#endif
+	}
+
+	return;
+}
+
+unsigned long __init wrhv_find_end_of_memory(void)
+{
+	return wr_config->phys_mem_size;
+}
+
+int __init wrhv_early_init_dt_scan_memory_ppc(unsigned long node,
+			const char *uname, int depth, void *data)
+{
+	/* instead of using the memory size from
+	 * device tree, we use RamSize from linux.xml
+	 */
+	u64 base, size;
+	/*
+	 * add the first memory region which is
+	 * from 0x00000000 to end of virtual board memory.
+	 */
+	base = 0x00000000ul;
+	size = wrhv_find_end_of_memory();
+	lmb_add(base, size);
+	memstart_addr = min((u64)memstart_addr, base);
+
+	return 0;
+}
+
+void wrhv_power_save(void)
+{
+	local_irq_enable();
+
+	/*
+	 * wrhv_power_save() is called by cpu_idle. When running in direct irq or
+	 * duart mode, we need core 0 to handle interrupt from hypervisor. In this
+	 * case we do not allow core 0 to go into idle.
+	 */
+#ifdef CONFIG_WRHV_DUART
+	if ((wrhv_dir_irq) || (is_wrhv_duart_inited)) {
+#else
+	if (wrhv_dir_irq) {
+#endif
+		/* running in direct irq or using duart */
+		if (smp_processor_id())
+			vbi_idle(1);
+	}
+	else {
+		/* not using direct irq and not using duart */
+		vbi_idle(1);
+	}
+
+}
+
+static void wrhv_do_restart(void *data)
+{
+	int ret;
+	int cpu = smp_processor_id();
+
+	if (!cpu) {
+		printk(KERN_INFO "WRHV: rebooting \n");
+
+		ret = vbi_vb_reset(VBI_BOARD_ID_GET(), VBI_VB_CORES_ALL,
+				VBI_VBMGMT_RESET_AND_START_CORE0 |
+				VBI_VBMGMT_RESET_DOWNLOAD
+				);
+
+		if (ret)
+			printk(KERN_ERR "WRHV: reboot failed. ret = %d\n", ret);
+	}
+}
+
+void wrhv_restart(char *cmd)
+{
+	int cpu = smp_processor_id();
+
+	if (!cpu)
+		wrhv_do_restart(NULL);
+	else
+		smp_call_function(wrhv_do_restart, NULL, 1);
+
+	while (1);
+}
+
+void __devinit wrhv_calibrate_decr(void)
+{
+	ppc_tb_freq = VBI_TIMESTAMP_FREQ_GET();
+	ppc_proc_freq = wrhv_cpu_freq;
+	printk(KERN_DEBUG "WRHV-TIME: wrhv_cpu_freq=%lu  ppc_tb_freq =%lu\n",
+			wrhv_cpu_freq, ppc_tb_freq);
+
+	if (VBI_TICK_TIMER_FREQ_GET() != CONFIG_HZ) {
+		printk(KERN_ERR "Mismatch between CONFIG_HZ and TickTimerFreq detected!");
+		printk(KERN_ERR "  Your decrementer has not been setup correctly\n");
+		BUG();
+	}
+}
+
+void __init wrhv_time_init(void)
+{
+	return;
+}
+
+#define LAW_TARGET_ID (0xff << 20)
+#define LAW_EN (0x1 << 31)
+#define LAW_SIZE_MASK (0x1f)
+
+unsigned int high_base = -1;
+unsigned int low_base = -1;
+unsigned int law_attrib = -1;
+unsigned int law_offset = 0x10;
+unsigned char *law_base;
+int law_num;
+int law_prepare_done;
+int ppc_prepare_law_setup(void)
+{
+	struct device_node *dev;
+	const int *prop;
+
+	if (law_prepare_done == 0) {
+		dev = of_find_compatible_node(NULL, NULL, "fsl,corenet-law");
+		if (!dev) {
+			printk(KERN_ERR
+				"%s: No corenet law device node.\n", __func__);
+			return -1;
+		}
+
+		law_base = of_iomap(dev, 0);
+		if (!law_base) {
+			printk(KERN_ERR
+				"%s: Can't iomap corenet law.\n", __func__);
+			return -1;
+		}
+
+		/* Get law numbers property */
+		prop = of_get_property(dev, "fsl,num-laws", NULL);
+		if (prop)
+			law_num = *prop;
+		else
+			return -1;
+
+		/* Get the high base offset for setting law address */
+		prop = of_get_property(dev, "high-base", NULL);
+		if (prop)
+			high_base = *prop;
+		else
+			return -1;
+
+		/* Get the low base offset for setting the law address
+		no need to bail if this property is missing since the
+		8572 does not have this property */
+		prop = of_get_property(dev, "low-base", NULL);
+		if (prop)
+			low_base = *prop;
+
+		/* Get the law attribute used for setting law attributes */
+		prop = of_get_property(dev, "law-attrib", NULL);
+		if (prop)
+			law_attrib = *prop;
+		else
+			return -1;
+
+		/* Get the law register offset for setting law address */
+		prop = of_get_property(dev, "offset", NULL);
+		if (prop)
+			law_offset = *prop;
+
+		law_prepare_done = 1;
+	}
+
+	return 0;
+}
+
+int ppc_search_free_law(int target_id, unsigned long long addr)
+{
+	int i;
+	static int index = -1;
+
+	if ((!ppc_md.set_law_attr) || (!ppc_md.set_law_base) || (!ppc_md.get_law_attr))
+		return -1;
+
+	for (i = index + 1; i < law_num; i++) {
+		u32 base = ppc_md.get_law_base(i);
+		u32 attr = ppc_md.get_law_attr(i);
+		u32 len = 1 << ((attr & LAW_SIZE_MASK) + 1) - 1;
+
+		/*
+		 * clean LAW settings in cases:
+		 * #1. target bus has valid LAW setting
+		 * #2. target address space was mapped yet
+		 */
+		if (((attr & LAW_TARGET_ID) == (target_id << 20))
+				|| (base == addr))
+			ppc_md.set_law_attr(i, 0);
+
+		/*
+		 * we'd better to check if existing LAW setting
+		 * overlapped with us, some *strange* thing might
+		 * happen
+		 */
+		if (addr > base && addr < base + len)
+			printk(KERN_WARNING "\n\t--- Warning!!! ---\n\t"
+					"Existing LAW setting partly overlapped with "
+					"new setting:\n\t"
+					"LAW[%d] already mapped 0x%08x to 0x%08x\n",
+					i, base, base + len);
+
+		/* Skip these used LAW item */
+		if (attr & LAW_EN)
+			continue;
+
+		index = i;
+		break;
+	}
+
+	return  index;
+}
+
+void ppc_setup_law(unsigned int target_id, unsigned long long addr, unsigned int attr)
+{
+	int index;
+	ppc_prepare_law_setup();
+
+	index = ppc_search_free_law(target_id, addr);
+	if (index >= 0) {
+		printk(KERN_INFO "WRHV-setup-law: index: "
+				"%#x, addr: %#llx, attr: %#x\n",
+				index, addr, attr);
+		ppc_md.set_law_base(index, addr);
+		ppc_md.set_law_attr(index, attr);
+	} else {
+		printk(KERN_ERR "WRHV-setup-law: fail setup LAW[%d] "
+				"with addr:[%#llx], attr:[%#x]\n",
+				target_id, addr, attr);
+	}
+}
+
+int ppc_setup_pci_law( struct device_node *dev)
+{
+	unsigned long long pci_addr, cpu_addr, pci_next, cpu_next, size;
+	const u32 *ranges;
+	int rlen;
+	int pna = 0;
+	int np = 0;
+	u32 pci_space, attr;
+	int pcie_index = 0;
+	const int *prop;
+	char *space_type;
+
+	if (!dev)
+		return -ENODEV;
+
+	if (wrhv_pci_law == 1) {
+		/* Get PCIE target id property */
+		prop = of_get_property(dev, "target-id", NULL);
+		if (prop)
+			pcie_index = *prop;
+		else
+			return -1;
+
+		pna = of_n_addr_cells(dev);
+		np = pna + 5;
+		/* Get ranges property */
+		ranges = of_get_property(dev, "ranges", &rlen);
+		if (ranges == NULL)
+			return -1;
+		/* Parse it */
+		while ((rlen -= np * 4) >= 0) {
+			/* Read next ranges element */
+			pci_space = ranges[0];
+			pci_addr = of_read_number(ranges + 1, 2);
+			cpu_addr = of_translate_address(dev, ranges + 3);
+			size = of_read_number(ranges + pna + 3, 2);
+			ranges += np;
+			if (cpu_addr == OF_BAD_ADDR || size == 0)
+				continue;
+
+			/* Now consume following elements while they are contiguous */
+			for (; rlen >= np * sizeof(u32);
+				     ranges += np, rlen -= np * 4) {
+				if (ranges[0] != pci_space)
+					break;
+				pci_next = of_read_number(ranges + 1, 2);
+				cpu_next = of_translate_address(dev, ranges + 3);
+				if (pci_next != pci_addr + size ||
+						    cpu_next != cpu_addr + size)
+					break;
+				size += of_read_number(ranges + pna + 3, 2);
+			}
+
+			if (((pci_space >> 24 ) & 0x3) == 0x1)
+				space_type = "I/O";
+
+			if (((pci_space >> 24 ) & 0x3) == 0x2)
+				space_type = "MEM";
+
+			printk(KERN_INFO "WRHV: fixup LAW for PCIE[%d] %s Space "
+					"[ 0x%016llx..0x%016llx ]\n", pcie_index,
+					space_type, cpu_addr, cpu_addr + size - 1);
+
+			attr = LAW_EN | (pcie_index << 20) | (__ilog2(size) - 1) ;
+			ppc_setup_law(pcie_index, cpu_addr, attr);
+		}
+	}
+
+	return 0;
+}
+
+int wrhv_set_law_base(int index, unsigned long long addr)
+{
+	/* Set High base address */
+	/* The secret here is that the P4080 has both a high-base and low-base
+	   where as the 8572 only has a high-base attribute */
+	if (low_base == -1)
+		out_be32((unsigned int *)(law_base + high_base + index * law_offset), (unsigned int)(addr >> 12));
+	else
+	{
+		out_be32((unsigned int *)(law_base + high_base + index * law_offset), (addr >> 32) & 0xf);
+		/* Set Low base address */
+		out_be32((unsigned int *)(law_base + low_base + index * law_offset), (unsigned int)addr);
+	}
+	return 0;
+}
+
+unsigned long long wrhv_get_law_base(int index)
+{
+	unsigned long long volatile val = 0;
+	if (low_base == -1)
+		val = in_be32((unsigned int *)(law_base + high_base + index * law_offset));
+
+	return (val << 12);
+}
+
+int wrhv_set_law_attr(int index, unsigned int attr)
+{
+	/* Set Attributes */
+	out_be32((unsigned int *)(law_base + law_attrib + index * law_offset), attr);
+	return 0;
+}
+ 
+int wrhv_get_law_attr(int index)
+{
+	unsigned int volatile attr = -1;
+
+	/* Get Attributes */
+	attr = in_be32((unsigned int *)(law_base + law_attrib + index * law_offset));
+	return attr;
+}
+
+#ifdef CONFIG_SPARSE_IRQ
+#define WRHV_NR_IRQS	NR_IRQS_LEGACY
+#else
+#define WRHV_NR_IRQS	NR_IRQS
+#endif
+void __init wrhv_init_irq(void)
+{
+	int i;
+	struct irq_desc *desc;
+
+#ifdef CONFIG_SMP
+	/* Be default all the irqs will be routed to core0 */
+	cpumask_copy(irq_default_affinity, cpumask_of(0));
+#endif
+
+	wrhv_irq_chip.typename = "WRHV-PIC";
+	for (i = 0; i < WRHV_NR_IRQS; i++) {
+		desc = irq_to_desc_alloc_node(i, 0);
+		desc->status = IRQ_DISABLED | IRQ_LEVEL;
+		desc->action = NULL;
+		desc->depth = 1;
+		set_irq_chip_and_handler(i, &wrhv_irq_chip, handle_fasteoi_irq);
+	}
+}
+
+#ifdef CONFIG_DEBUG_VIRTUAL_IRQS
+static irqreturn_t wrhv_vbint(int irq, void * dev_id)
+{
+	printk("[DEBUG VIRTUAL IRQS] Handling the DEBUG IRQ %d\n", irq);
+	return IRQ_HANDLED;
+}
+
+static int __init wrhv_late_init_irq(void)
+{
+	int dev_id = 1;
+	int i;
+
+	/* IRQ 0 is unknown IRQ number for Hypervisor */
+	for (i = 1; i < 32; i++) {
+		if(request_irq(i, wrhv_vbint, IRQF_SHARED, "vbint_single", &dev_id))
+			printk("Unable request IRQ for IRQ %d\n", i);
+	}
+
+	return 0;
+}
+subsys_initcall(wrhv_late_init_irq);
+#endif
+
+unsigned int wrhv_vioapic_get_irq(void)
+{
+	unsigned int irq;
+
+	irq = wr_control->irq_pend;
+
+#ifdef CONFIG_DEBUG_VIRTUAL_IRQS
+	/* Maybe this is useless for real external interrupt */
+	wr_status->irq_pend = 0;
+#endif
+
+	if (irq == 0xffff)
+		irq = NO_IRQ_IGNORE;
+	else
+		wr_control->irq_pend = 0xffff;
+
+	return irq;
+}
+
+/* We get irw by reading EPR for handling direct interrupt. 
+ * Note the irq should be asked automatically by the hardware 
+ * once read EPR. 
+ */
+unsigned int wrhv_get_direct_irq(void)
+{
+	unsigned int irq = mfspr(SPRN_EPR);
+	/* When reboot some devices may generate spurious irq so here
+	 * eoi that and skip this unnecessary interrupt process.
+	 */
+	if (!irq_to_desc(irq)) {
+		printk(KERN_INFO "wrhv: spurious interrupt %d acknowledged.\n",
+			irq);
+		vbi_di_eoi();
+		irq = NO_IRQ;
+	}
+	return irq;
+}
+
+/* refer to native implementation in arch/powerpc/kernel/irq.c */
+extern inline void check_stack_overflow(void);
+extern inline void handle_one_irq(unsigned int irq);
+
+/* Refer to wrhv_do_IRQ */
+void wrhv_do_direct_IRQ(struct pt_regs *regs)
+{
+	struct pt_regs *old_regs = set_irq_regs(regs);
+	unsigned int irq;
+
+	trace_irq_entry(0, regs, NULL);
+
+	irq_enter();
+
+	check_stack_overflow();
+
+	irq = ppc_md.get_direct_irq();
+
+	if (irq != NO_IRQ && irq != NO_IRQ_IGNORE) {
+		handle_one_irq(irq);
+	} else if (irq != NO_IRQ_IGNORE)
+		__get_cpu_var(irq_stat).spurious_irqs++;
+
+	irq_exit();
+	set_irq_regs(old_regs);
+
+#ifdef CONFIG_PPC_ISERIES
+	if (firmware_has_feature(FW_FEATURE_ISERIES) &&
+			get_lppaca()->int_dword.fields.decr_int) {
+		get_lppaca()->int_dword.fields.decr_int = 0;
+		/* Signal a fake decrementer interrupt */
+		timer_interrupt(regs);
+	}
+#endif
+
+	trace_irq_exit(IRQ_HANDLED);
+
+}
+
+void wrhv_do_IRQ(struct pt_regs *regs)
+{
+	struct pt_regs *old_regs = set_irq_regs(regs);
+	unsigned int irq;
+
+	trace_irq_entry(0, regs, NULL);
+
+	irq_enter();
+
+	check_stack_overflow();
+
+check_again:
+	irq = ppc_md.get_irq();
+
+	if (irq != NO_IRQ && irq != NO_IRQ_IGNORE) {
+		handle_one_irq(irq);
+		goto check_again;	
+	} else if (irq != NO_IRQ_IGNORE)
+		__get_cpu_var(irq_stat).spurious_irqs++;
+
+	irq_exit();
+	set_irq_regs(old_regs);
+
+#ifdef CONFIG_PPC_ISERIES
+	if (firmware_has_feature(FW_FEATURE_ISERIES) &&
+			get_lppaca()->int_dword.fields.decr_int) {
+		get_lppaca()->int_dword.fields.decr_int = 0;
+		/* Signal a fake decrementer interrupt */
+		timer_interrupt(regs);
+	}
+#endif
+
+	trace_irq_exit(IRQ_HANDLED);
+}
+
+struct irq_desc * __ref wrhv_irq_to_desc(unsigned int irq)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+	if (desc)
+		return desc;
+
+#ifdef CONFIG_SPARSE_IRQ
+	desc = irq_to_desc_alloc_node(irq, 0);
+	if (unlikely(!desc)) {
+		pr_err("can't get irq_desc for irq%d\n", irq);
+		goto out;
+	}
+
+	desc->status = IRQ_DISABLED | IRQ_LEVEL;
+	desc->action = NULL;
+	desc->depth = 1;
+	set_irq_chip_and_handler(irq, &wrhv_irq_chip, handle_fasteoi_irq);
+out:
+#endif
+	return desc;
+}
+EXPORT_SYMBOL(wrhv_irq_to_desc);
+
+unsigned int wrhv_map_irq_of_desc(char *irq_name, int32_t irq_dir)
+{
+	int irq;
+	struct irq_desc *desc;
+
+	irq = vbi_find_irq(irq_name, irq_dir);
+	if (irq == VBI_INVALID_IRQ) {
+		printk(KERN_WARNING "WRHV: no defined INT for [ %s ].\n",
+				irq_name);
+		return NO_IRQ;
+	}
+
+	desc = wrhv_irq_to_desc(irq);
+	if (unlikely(!desc))
+		return NO_IRQ;
+
+	return irq;
+}
+
+unsigned int wrhv_irq_of_parse_and_map(struct device_node *dev, int index)
+{
+	char *p, tmp[120];
+
+	/* Currently we only support 0 ~ 9 index */
+	if (index > 9 || index < 0)
+		return NO_IRQ;
+
+	if (!index)
+		p = dev->full_name;
+	else {
+		int i;
+
+		p = tmp;
+		strncpy(p, dev->full_name, 120 - 2);
+		i = strlen(p);
+		p[i++] = '#';
+		p[i++] = index + '0';
+		p[i]   = '\0';
+	}
+
+	return wrhv_map_irq_of_desc(p, VB_INPUT_INT);
+}
+
+unsigned int wrhv_get_pvr(void)
+{
+	return wr_status->vb_status_regs.pvr;
+}
+
+unsigned int wrhv_get_svr(void)
+{
+	return wr_status->vb_status_regs.svr;
+}
+
+static void wrhv_set_mode(enum clock_event_mode mode,
+				 struct clock_event_device *dev)
+{
+	return;
+}
+
+static int wrhv_set_next_event(unsigned long evt,
+				      struct clock_event_device *dev)
+{
+	return 0;
+}
+
+/* See arch/x86/kernel/vbi/wrhv.c */
+static struct clock_event_device wrhv_clockevent = {
+	.name		= "wrhv",
+	.features	= CLOCK_EVT_FEAT_PERIODIC,
+	.set_mode	= wrhv_set_mode,
+	.set_next_event = wrhv_set_next_event,
+	.max_delta_ns	= 0xffffffff,
+	.min_delta_ns	= 10000,
+	.shift		= 32,   /* nanoseconds to cycles divisor 2^ */
+	.mult		= 1,     /* To be filled in */
+	.irq		= 0,
+	.rating		= 1,
+};
+
+/* Refer to arch/powerpc/kernel/time.c. */
+#undef	test_perf_event_pending
+#undef	clear_perf_event_pending
+
+#ifdef CONFIG_PERF_EVENTS
+extern DEFINE_PER_CPU(u8, perf_event_pending);
+#define test_perf_event_pending()	__get_cpu_var(perf_event_pending)
+#define clear_perf_event_pending()	__get_cpu_var(perf_event_pending) = 0
+#else
+#define test_perf_event_pending()	0
+#define clear_perf_event_pending()
+#endif
+
+void wrhv_hw_timer_interrupt(struct pt_regs * regs)
+{
+	struct pt_regs *old_regs;
+
+	trace_timer_interrupt_entry(regs);
+
+	__get_cpu_var(irq_stat).timer_irqs++;
+
+#ifdef CONFIG_PPC32
+	if (atomic_read(&ppc_n_lost_interrupts) != 0)
+		do_IRQ(regs);
+#endif
+
+	old_regs = set_irq_regs(regs);
+	irq_enter();
+
+	calculate_steal_time();
+
+	if (test_perf_event_pending()) {
+		clear_perf_event_pending();
+		perf_event_do_pending();
+	}
+
+	wrhv_timer_interrupt(0, NULL);
+
+	irq_exit();
+	set_irq_regs(old_regs);
+
+	trace_timer_interrupt_exit(regs);
+}
+
+void __init wrhv_time_init_cont(void)
+{
+	wrhv_clockevent.cpumask = get_cpu_mask(0);
+	clockevents_register_device(&wrhv_clockevent);
+}
+
+
+/* arch/powerpc/mm/fault.c */
+void wrhv_vmmu_restore(void)
+{
+	/*
+	 * called by the end of page fault handling to reinstall the vmmu
+	 */
+	wr_control->vmmu0 = wr_status->vmmu0;
+	wr_control->vmmu1 = wr_status->vmmu1;
+#ifdef CONFIG_WRHV_ASID_OPTIMIZATION
+	wr_control->vb_control_regs.vmmu_handle =
+		wr_status->vb_status_regs.vmmu_handle;
+	wr_control->vb_control_regs.asid =
+		wr_status->vb_status_regs.asid;
+#endif
+	return;
+}
+
+/* arch/powerpc/mm/fsl_booke_mmu.c */
+void __init wrhv_MMU_init_hw(void)
+{
+	return;
+}
+
+unsigned long __init wrhv_mmu_mapin_ram(unsigned long top)
+{
+       return 0;
+}
+
+/* arch/powerpc/mm/init_32.c */
+void wrhv_MMU_setup(void)
+{
+	__map_without_bats = 1;
+
+#ifdef CONFIG_DEBUG_PAGEALLOC
+	__map_without_bats = 1;
+	__map_without_ltlbs = 1;
+#endif
+}
+
+void __init wrhv_MMU_init(void)
+{
+#ifdef DEBUG
+	int i;
+#endif
+
+	if (ppc_md.progress)
+		ppc_md.progress("MMU:enter", 0x111);
+
+	/* parse args from command line */
+	wrhv_MMU_setup();
+
+	if (lmb.memory.cnt > 1) {
+		lmb.memory.cnt = 1;
+		lmb_analyze();
+		printk(KERN_WARNING "Only using first contiguous memory region");
+	}
+
+	total_lowmem = total_memory = lmb_end_of_DRAM() - memstart_addr;
+	lowmem_end_addr = memstart_addr + total_lowmem;
+
+	if (total_lowmem > __max_low_memory) {
+		total_lowmem = __max_low_memory;
+		lowmem_end_addr = memstart_addr + total_lowmem;
+#ifndef CONFIG_HIGHMEM
+		total_memory = total_lowmem;
+		lmb_enforce_memory_limit(lowmem_end_addr);
+		lmb_analyze();
+#endif /* CONFIG_HIGHMEM */
+	}
+
+	/* Initialize the MMU hardware */
+	if (ppc_md.progress)
+		ppc_md.progress("MMU:hw init", 0x300);
+	MMU_init_hw();
+
+	/* Map in all of RAM starting at KERNELBASE */
+	if (ppc_md.progress)
+		ppc_md.progress("MMU:mapin", 0x301);
+	mapin_ram();
+
+	/* Initialize early top-down ioremap allocator */
+	ioremap_bot = IOREMAP_TOP;
+
+	/* Map in I/O resources */
+	if (ppc_md.progress)
+		ppc_md.progress("MMU:setio", 0x302);
+
+	if (ppc_md.progress)
+		ppc_md.progress("MMU:exit", 0x211);
+
+	/* From now on, btext is no longer BAT mapped if it was at all */
+#ifdef CONFIG_BOOTX_TEXT
+	btext_unmap();
+#endif
+
+#ifndef CONFIG_PPC85xx_VT_MODE
+	/*
+	 * we enable the mmu here without having to do this from the caller
+	 * (which is in assembly world)
+	 */
+	vb_context_mmu_on(0, swapper_pg_dir, PAGE_SIZE, KERNEL_BASE_ASID,
+		KERNEL_BASE_ASID, 0);
+#endif
+
+	/* Check if enable direct interrupt mode. */
+	wrhv_enable_dir_irq();
+	
+	vbi_set_exc_offset(&exec_table);
+
+#ifdef DEBUG
+	printk("****DUMP EXEC OFFSET AFTER SET***\n");
+	vbi_get_exc_offset(&exec_table);
+	for(i=0;i<VBI_ARCH_MAX_EXC_OFFSETS;i++)
+		printk("execoffset:%d	----	0x%08x\n",i,exec_table.excOffset[i]);
+#endif
+}
+
+/* arch/powerpc/mm/mem.c */
+extern void __flush_dcache_icache_phys(unsigned long physaddr);
+void wrhv_flush_dcache_page(struct page *page)
+{
+	if (cpu_has_feature(CPU_FTR_COHERENT_ICACHE))
+		return;
+	/* avoid an atomic op if possible */
+	if (test_bit(PG_arch_1, &page->flags))
+		clear_bit(PG_arch_1, &page->flags);
+
+	vbi_flush_dcache((void *)(page_to_pfn(page) << PAGE_SHIFT),
+					 PAGE_SIZE);
+}
+
+void set_context(unsigned long contextid, pgd_t *pgd) 
+	__attribute__((weak, alias("wrhv_set_context")));
+
+/* arch/powerpc/mm/mmu_context_32.c */
+void wrhv_set_context(unsigned long contextId, pgd_t * pgd)
+{
+
+	pgd_t * kpdStart, *kpdEnd, *updStart;
+	/* we attach (copy) kernel page mapping to the user page table
+	 * Note, we only copy the L1 entrys to user L1 pageTable,
+	 * then letting L1 share the same L2 page table
+	 */
+
+	kpdStart = pgd_offset_k(KERNELBASE);
+	kpdEnd =   pgd_offset_k(0xffffffff);
+
+	updStart = pgd + pgd_index(KERNELBASE);
+
+	memcpy(updStart, kpdStart, (kpdEnd - kpdStart + 1) * sizeof (pgd_t));
+
+	/* in linux context, page table entry is not set up yet */
+#ifdef CONFIG_WRHV_ASID_OPTIMIZATION
+	vb_context_mmu_on(contextId, pgd, PAGE_SIZE,
+		wr_control->vb_control_regs.asid,
+		wr_control->vb_control_regs.vmmu_handle, 0);
+#else
+	vb_context_mmu_on(contextId, pgd, PAGE_SIZE, KERNEL_BASE_ASID,
+		KERNEL_BASE_ASID, 0);
+#endif
+}
+
+/* arch/powerpc/mm/pgtable_32.c */
+int wrhv_map_page(unsigned long va, phys_addr_t pa, int flags)
+{
+	pmd_t *pd;
+	pte_t *pg;
+	int err = -ENOMEM;
+
+	/* Use upper 10 bits of VA to index the first level map */
+	pd = pmd_offset(pud_offset(pgd_offset_k(va), va), va);
+	/* Use middle 10 bits of VA to index the second-level map */
+	pg = pte_alloc_kernel(pd, va);
+	if (pg != 0) {
+		err = 0;
+		/* The PTE should never be already set nor present in the
+		 * hash table
+		 */
+		BUG_ON(pte_val(*pg) & (_PAGE_PRESENT | _PAGE_HASHPTE));
+		set_pte_at(&init_mm, va, pg, pfn_pte(pa >> PAGE_SHIFT,
+						     __pgprot(flags)));
+#if defined(CONFIG_WRHV_E500) && !defined(CONFIG_PHYS_64BIT) \
+			      && !defined(CONFIG_PPC85xx_VT_MODE)
+		if (current->active_mm != &init_mm)
+			*pgd_offset(current->active_mm, va) =
+						*pgd_offset_k(va);
+#endif
+	}
+
+	return err;
+}
+
+void __iomem *
+wrhv___ioremap(phys_addr_t addr, unsigned long size, unsigned long flags)
+{
+	unsigned long v, i;
+	phys_addr_t p;
+	int err;
+
+	/* writeable implies dirty for kernel addresses */
+	if (flags & _PAGE_RW)
+		flags |= _PAGE_DIRTY | _PAGE_HWWRITE;
+
+	/* we don't want to let _PAGE_USER and _PAGE_EXEC leak out */
+	flags &= ~(_PAGE_USER | _PAGE_EXEC);
+
+	/* Make sure we have the base flags */
+	if ((flags & _PAGE_PRESENT) == 0)
+		flags |= PAGE_KERNEL;
+
+	/* Non-cacheable page cannot be coherent */
+	if (flags & _PAGE_NO_CACHE)
+		flags &= ~_PAGE_COHERENT;
+
+	/*
+	 * Choose an address to map it to.
+	 * Once the vmalloc system is running, we use it.
+	 * Before then, we use space going down from ioremap_base
+	 * (ioremap_bot records where we're up to).
+	 */
+	p = addr & PAGE_MASK;
+	size = PAGE_ALIGN(addr + size) - p;
+
+	/*
+	 * If the address lies within the first 16 MB, assume it's in ISA
+	 * memory space
+	 */
+	if (p < 16*1024*1024)
+		p += _ISA_MEM_BASE;
+
+#ifndef CONFIG_CRASH_DUMP
+	/*
+	 * Don't allow anybody to remap normal RAM that we're using.
+	 * mem_init() sets high_memory so only do the check after that.
+	 */
+	if (mem_init_done && (p < virt_to_phys(high_memory))) {
+		printk("__ioremap(): phys addr 0x%llx is RAM lr %p\n",
+		       (unsigned long long)p, __builtin_return_address(0));
+		return NULL;
+	}
+#endif
+
+	if (size == 0)
+		return NULL;
+
+	/*
+	 * Is it already mapped?  Perhaps overlapped by a previous
+	 * BAT mapping.  If the whole area is mapped then we're done,
+	 * otherwise remap it since we want to keep the virt addrs for
+	 * each request contiguous.
+	 *
+	 * We make the assumption here that if the bottom and top
+	 * of the range we want are mapped then it's mapped to the
+	 * same virt address (and this is contiguous).
+	 *  -- Cort
+	 */
+	if ((v = p_mapped_by_bats(p)) /*&& p_mapped_by_bats(p+size-1)*/ )
+		goto out;
+
+	if ((v = p_mapped_by_tlbcam(p)))
+		goto out;
+
+	if (mem_init_done) {
+		struct vm_struct *area;
+		area = get_vm_area(size, VM_IOREMAP);
+		if (area == 0)
+			return NULL;
+		v = (unsigned long) area->addr;
+	} else {
+		v = (ioremap_bot -= size);
+	}
+
+	/*
+	 * Should check if it is a candidate for a BAT mapping
+	 */
+
+	err = 0;
+	for (i = 0; i < size && err == 0; i += PAGE_SIZE)
+		err = map_page(v+i, p+i, flags);
+	if (err) {
+		if (mem_init_done)
+			vunmap((void *)v);
+		return NULL;
+	}
+
+/* Just E500 Guest OS need copy kernel PTEs in ioremap.
+ * And, don't support 36 bit physical address now.
+ */
+#if !defined(CONFIG_PPC85xx_VT_MODE) && !defined(CONFIG_PHYS_64BIT)
+	{
+		pgd_t *kpd_start, *kpd_end, *upd_start, *pgd;
+		if (mem_init_done && (current->mm != NULL) && (current->mm != &init_mm)) {
+			pgd = current->mm->pgd;
+
+			/* we attach (copy) kernel page mapping to the user page table
+			 * Note, we only copy the L1 entrys to user L1 pageTable,
+			 * then letting L1 share the same L2 page table.
+			 */
+			kpd_start = pgd_offset_k(KERNELBASE);
+			kpd_end =   pgd_offset_k(0xffffffff);
+
+			upd_start = pgd + pgd_index(KERNELBASE);
+			memcpy(upd_start, kpd_start, (kpd_end - kpd_start + 1) * sizeof (pgd_t));
+		}
+	}
+#endif
+out:
+	return (void __iomem *) (v + ((unsigned long)addr & ~PAGE_MASK));
+}
+
+#if defined(CONFIG_WRHV_GUEST_PROTECTION)
+/* In native Linux the kernel page table addresses are marked as supervisor
+ * RWX only.  So that the Linux guest can protect kernel memory space from
+ *  nefarious users the same range of pages need to be set. */
+#define KERNEL_MEMORY_START	(CONFIG_KERNEL_START)
+#define KERNEL_MEMORY_END	(CONFIG_KERNEL_START+0x0FFFFFFF)
+#endif
+
+/* From arch/powerpc/include/asm/pgtable.h */
+static inline void wrhv__set_pte_at(struct mm_struct *mm, unsigned long addr,
+				pte_t *ptep, pte_t pte, int percpu)
+{
+#if defined(CONFIG_PPC_STD_MMU_32) && defined(CONFIG_SMP) && !defined(CONFIG_PTE_64BIT)
+	/* First case is 32-bit Hash MMU in SMP mode with 32-bit PTEs. We use the
+	 * helper pte_update() which does an atomic update. We need to do that
+	 * because a concurrent invalidation can clear _PAGE_HASHPTE. If it's a
+	 * per-CPU PTE such as a kmap_atomic, we do a simple update preserving
+	 * the hash bits instead (ie, same as the non-SMP case)
+	 */
+	if (percpu)
+		*ptep = __pte((pte_val(*ptep) & _PAGE_HASHPTE)
+			      | (pte_val(pte) & ~_PAGE_HASHPTE));
+	else
+		pte_update(ptep, ~_PAGE_HASHPTE, pte_val(pte));
+
+#elif defined(CONFIG_PPC32) && defined(CONFIG_PTE_64BIT)
+	/* Second case is 32-bit with 64-bit PTE.  In this case, we
+	 * can just store as long as we do the two halves in the right order
+	 * with a barrier in between. This is possible because we take care,
+	 * in the hash code, to pre-invalidate if the PTE was already hashed,
+	 * which synchronizes us with any concurrent invalidation.
+	 * In the percpu case, we also fallback to the simple update preserving
+	 * the hash bits
+	 */
+	if (percpu) {
+		*ptep = __pte((pte_val(*ptep) & _PAGE_HASHPTE)
+			      | (pte_val(pte) & ~_PAGE_HASHPTE));
+		return;
+	}
+#if _PAGE_HASHPTE != 0
+	if (pte_val(*ptep) & _PAGE_HASHPTE)
+		flush_hash_entry(mm, ptep, addr);
+#endif
+	__asm__ __volatile__("\
+		stw%U0%X0 %2,%0\n\
+		eieio\n\
+		stw%U0%X0 %L2,%1"
+	: "=m" (*ptep), "=m" (*((unsigned char *)ptep+4))
+	: "r" (pte) : "memory");
+
+#elif defined(CONFIG_PPC_STD_MMU_32)
+	/* Third case is 32-bit hash table in UP mode, we need to preserve
+	 * the _PAGE_HASHPTE bit since we may not have invalidated the previous
+	 * translation in the hash yet (done in a subsequent flush_tlb_xxx())
+	 * and see we need to keep track that this PTE needs invalidating
+	 */
+	*ptep = __pte((pte_val(*ptep) & _PAGE_HASHPTE)
+		      | (pte_val(pte) & ~_PAGE_HASHPTE));
+
+#else
+	/* Anything else just stores the PTE normally. That covers all 64-bit
+	 * cases, and 32-bit non-hash with 32-bit PTEs.
+	 */
+	*ptep = pte;
+
+#if defined(CONFIG_WRHV) && !defined(CONFIG_PPC85xx_VT_MODE)
+	/* linux does not use valid bit, hypervisor does, in word0 */
+	*(u_int *)ptep |= (u_int) VMMU_PTE_VALID_MASK;
+
+#if defined(CONFIG_WRHV_GUEST_PROTECTION)
+	/* The P4080 does not suffer from lack of protection like that
+	of the 8548 and 8572. */
+	if ((addr >= KERNEL_MEMORY_START) && (addr <= KERNEL_MEMORY_END))
+		*(u_int *)ptep |= (u_int) VMMU_PTE_SUPER_MASK;
+#endif
+
+#endif /* CONFIG_WRHV */
+
+#endif
+
+}
+
+static void wrhv_handle_debug(struct pt_regs *regs, unsigned long debug_status)
+{
+	int changed = 0;
+	/*
+	 * Determine the cause of the debug event, clear the
+	 * event flags and send a trap to the handler. Torez
+	 */
+	if (debug_status & (DBSR_DAC1R | DBSR_DAC1W)) {
+		dbcr_dac(current) &= ~(DBCR_DAC1R | DBCR_DAC1W);
+#ifdef CONFIG_PPC_ADV_DEBUG_DAC_RANGE
+		current->thread.dbcr2 &= ~DBCR2_DAC12MODE;
+#endif
+		do_send_trap(regs, mfspr(SPRN_DAC1), debug_status, TRAP_HWBKPT,
+			     5);
+		changed |= 0x01;
+	}  else if (debug_status & (DBSR_DAC2R | DBSR_DAC2W)) {
+		dbcr_dac(current) &= ~(DBCR_DAC2R | DBCR_DAC2W);
+		do_send_trap(regs, mfspr(SPRN_DAC2), debug_status, TRAP_HWBKPT,
+			     6);
+		changed |= 0x01;
+	}  else if (debug_status & DBSR_IAC1) {
+		current->thread.dbcr0 &= ~DBCR0_IAC1;
+		dbcr_iac_range(current) &= ~DBCR_IAC12MODE;
+		do_send_trap(regs, mfspr(SPRN_IAC1), debug_status, TRAP_HWBKPT,
+			     1);
+		changed |= 0x01;
+	}  else if (debug_status & DBSR_IAC2) {
+		current->thread.dbcr0 &= ~DBCR0_IAC2;
+		do_send_trap(regs, mfspr(SPRN_IAC2), debug_status, TRAP_HWBKPT,
+			     2);
+		changed |= 0x01;
+	}  else if (debug_status & DBSR_IAC3) {
+		current->thread.dbcr0 &= ~DBCR0_IAC3;
+		dbcr_iac_range(current) &= ~DBCR_IAC34MODE;
+		do_send_trap(regs, mfspr(SPRN_IAC3), debug_status, TRAP_HWBKPT,
+			     3);
+		changed |= 0x01;
+	}  else if (debug_status & DBSR_IAC4) {
+		current->thread.dbcr0 &= ~DBCR0_IAC4;
+		do_send_trap(regs, mfspr(SPRN_IAC4), debug_status, TRAP_HWBKPT,
+			     4);
+		changed |= 0x01;
+	}
+	/*
+	 * At the point this routine was called, the MSR(DE) was turned off.
+	 * Check all other debug flags and see if that bit needs to be turned
+	 * back on or not.
+	 */
+	if (DBCR_ACTIVE_EVENTS(current->thread.dbcr0, current->thread.dbcr1))
+		regs->msr |= MSR_DE;
+	else
+		/* Make sure the IDM flag is off */
+		current->thread.dbcr0 &= ~DBCR0_IDM;
+
+	if (changed & 0x01)
+		mtspr(SPRN_DBCR0, current->thread.dbcr0);
+}
+
+/* arch/powerpc/include/asm/reg.h */
+#ifdef CONFIG_PPC85xx_VT_MODE
+void wrhv_mtspr(unsigned int sprn, unsigned int value)
+{
+
+	switch(sprn){
+		case SPRN_DBCR0:
+			__asm__ __volatile__(
+			"lis    3,%0@h\n"
+			"ori    3,3,%0@l\n"
+			"mr	4,%1\n"
+			"mtspr	0x134,4\n"
+			::"i" (SPRN_DBCR0_W), "r" (value)
+			);
+			break;
+
+		case SPRN_DBSR:
+			__asm__ __volatile__(
+			"lis    3,%0@h\n"
+			"ori    3,3,%0@l\n"
+			"mr	4,%1\n"
+			"mtspr	0x130,4\n"
+			::"i" (SPRN_DBSR_W), "r" (value)
+			);
+			break;
+
+		case SPRN_IAC1:
+			__asm__ __volatile__(
+			"lis    3,%0@h\n"
+			"ori    3,3,%0@l\n"
+			"mr	4,%1\n"
+			"mtspr	0x138,4\n"
+			::"i" (SPRN_IAC1_W), "r" (value)
+			);
+			break;
+
+		case SPRN_IAC2:
+			__asm__ __volatile__(
+			"lis    3,%0@h\n"
+			"ori    3,3,%0@l\n"
+			"mr	4,%1\n"
+			"mtspr	0x139,4\n"
+			::"i" (SPRN_IAC2_W), "r" (value)
+			);
+			break;
+
+		case SPRN_DAC1:
+			__asm__ __volatile__(
+			"lis    3,%0@h\n"
+			"ori    3,3,%0@l\n"
+			"mr	4,%1\n"
+			"mtspr	0x13C,4\n"
+			::"i" (SPRN_DAC1_W), "r" (value)
+			);
+			break;
+
+		case SPRN_DAC2:
+			__asm__ __volatile__(
+			"lis    3,%0@h\n"
+			"ori    3,3,%0@l\n"
+			"mr	4,%1\n"
+			"mtspr	0x13D,4\n"
+			::"i" (SPRN_DAC2_W), "r" (value)
+			);
+			break;
+
+		case SPRN_DBCR1:
+			__asm__ __volatile__(
+			"lis    3,%0@h\n"
+			"ori    3,3,%0@l\n"
+			"mr	4,%1\n"
+			"mtspr	0x135,4\n"
+			::"i" (SPRN_DBCR1_W), "r" (value)
+			);
+			break;
+
+		case SPRN_DBCR2:
+			__asm__ __volatile__(
+			"lis    3,%0@h\n"
+			"ori    3,3,%0@l\n"
+			"mr	4,%1\n"
+			"mtspr	0x136,4\n"
+			::"i" (SPRN_DBCR2_W), "r" (value)
+			);
+			break;
+	}
+}
+#else
+void wrhv_mtspr(unsigned int sprn, unsigned int value)
+{
+	switch(sprn){
+		case SPRN_DBCR0:
+			wr_control->vb_control_regs.dbcr0 = value;
+			break;
+
+		case SPRN_DBSR:
+			wr_control->vb_control_regs.dbsr = value;
+			break;
+	}
+}
+#endif
+
+/* arch/powerpc/kernel/process.c */ 
+extern void wrhv_mtspr(unsigned int, unsigned int);
+void wrhv_prime_debug_regs(struct thread_struct *thread)
+{
+	wrhv_mtspr(SPRN_IAC1, thread->iac1);
+	wrhv_mtspr(SPRN_IAC2, thread->iac2);
+#if CONFIG_PPC_ADV_DEBUG_IACS > 2
+	wrhv_mtspr(SPRN_IAC3, thread->iac3);
+	wrhv_mtspr(SPRN_IAC4, thread->iac4);
+#endif
+	wrhv_mtspr(SPRN_DAC1, thread->dac1);
+	wrhv_mtspr(SPRN_DAC2, thread->dac2);
+#if CONFIG_PPC_ADV_DEBUG_DVCS > 0
+	wrhv_mtspr(SPRN_DVC1, thread->dvc1);
+	wrhv_mtspr(SPRN_DVC2, thread->dvc2);
+#endif
+	wrhv_mtspr(SPRN_DBCR0, thread->dbcr0);
+	wrhv_mtspr(SPRN_DBCR1, thread->dbcr1);
+#ifdef CONFIG_BOOKE
+	wrhv_mtspr(SPRN_DBCR2, thread->dbcr2);
+#endif
+}
+
+#ifdef CONFIG_PPC85xx_VT_MODE
+unsigned int wrhv_mfspr(unsigned int sprn)
+{
+	unsigned int value = 0;
+	switch(sprn){
+		case SPRN_DBCR0:
+			__asm__ __volatile__(
+			"lis    3,%1@h\n"
+			"ori    3,3,%1@l\n"
+			"mfspr	4,0x134\n"
+			"mr	%0,4\n"
+			:"=r" (value)
+			:"i" (SPRN_DBCR0_R)
+			);
+			break;
+
+		case SPRN_DBSR:
+			__asm__ __volatile__(
+			"lis    3,%1@h\n"
+			"ori    3,3,%1@l\n"
+			"mfspr	4,0x130\n"
+			"mr	%0,4\n"
+			:"=r" (value)
+			:"i" (SPRN_DBSR_R)
+			);
+			break;
+
+		case SPRN_IAC1:
+			__asm__ __volatile__(
+			"lis    3,%1@h\n"
+			"ori    3,3,%1@l\n"
+			"mfspr	4,0x138\n"
+			"mr	%0,4\n"
+			:"=r" (value)
+			:"i" (SPRN_IAC1_R)
+			);
+			break;
+
+		case SPRN_IAC2:
+			__asm__ __volatile__(
+			"lis    3,%1@h\n"
+			"ori    3,3,%1@l\n"
+			"mfspr	4,0x139\n"
+			"mr	%0,4\n"
+			:"=r" (value)
+			:"i" (SPRN_IAC2_R)
+			);
+			break;
+
+		case SPRN_DAC1:
+			__asm__ __volatile__(
+			"lis    3,%1@h\n"
+			"ori    3,3,%1@l\n"
+			"mfspr	4,0x13C\n"
+			"mr	%0,4\n"
+			:"=r" (value)
+			:"i" (SPRN_DAC1_R)
+			);
+			break;
+
+		case SPRN_DAC2:
+			__asm__ __volatile__(
+			"lis    3,%1@h\n"
+			"ori    3,3,%1@l\n"
+			"mfspr	4,0x13D\n"
+			"mr	%0,4\n"
+			:"=r" (value)
+			:"i" (SPRN_DAC2_R)
+			);
+			break;
+
+		case SPRN_DBCR1:
+			__asm__ __volatile__(
+			"lis    3,%1@h\n"
+			"ori    3,3,%1@l\n"
+			"mfspr	4,0x135\n"
+			"mr	%0,4\n"
+			:"=r" (value)
+			:"i" (SPRN_DBCR1_R)
+			);
+			break;
+
+		case SPRN_DBCR2:
+			__asm__ __volatile__(
+			"lis    3,%1@h\n"
+			"ori    3,3,%1@l\n"
+			"mfspr	4,0x136\n"
+			"mr	%0,4\n"
+			:"=r" (value)
+			:"i" (SPRN_DBCR2_R)
+			);
+			break;
+	}
+
+	return value;
+}
+#else
+unsigned int wrhv_mfspr(unsigned int sprn)
+{
+	unsigned int value = 0;
+	switch(sprn){
+		case SPRN_DBCR0:
+			value = wr_control->vb_control_regs.dbcr0;
+			break;
+
+		case SPRN_DBSR:
+			value = wr_control->vb_control_regs.dbsr;
+			break;
+	}
+
+	return value;
+}
+#endif
+
+/* arch/powerpc/kernel/traps.c */
+void __kprobes wrhv_DebugException(struct pt_regs *regs, unsigned long debug_status)
+{
+	debug_status = wr_control->vb_control_regs.dbsr;
+	wr_control->vb_control_regs.emsr &= ~MSR_DE;
+
+	current->thread.dbsr = debug_status;
+
+	/* Hack alert: On BookE, Branch Taken stops on the branch itself, while
+	 * on server, it stops on the target of the branch. In order to simulate
+	 * the server behaviour, we thus restart right away with a single step
+	 * instead of stopping here when hitting a BT
+	 */
+	if (debug_status & DBSR_BT) {
+		regs->msr &= ~MSR_DE;
+
+#ifdef CONFIG_PPC85xx_VT_MODE
+		/* Disable BT */
+		wrhv_mtspr(SPRN_DBCR0, wrhv_mfspr(SPRN_DBCR0) & ~DBCR0_BT);
+		/* Clear the BT event */
+		wrhv_mtspr(SPRN_DBSR, DBSR_BT);
+#endif
+
+		/* Do the single step trick only when coming from userspace */
+		if (user_mode(regs)) {
+			current->thread.dbcr0 &= ~DBCR0_BT;
+			current->thread.dbcr0 |= DBCR0_IDM | DBCR0_IC;
+			regs->msr |= MSR_DE;
+			return;
+		}
+
+		if (notify_die(DIE_SSTEP, "block_step", regs, 5,
+			       5, SIGTRAP) == NOTIFY_STOP) {
+			return;
+		}
+		if (debugger_sstep(regs))
+			return;
+	} else if (debug_status & DBSR_IC) { 	/* Instruction complete */
+		regs->msr &= ~MSR_DE;
+
+#ifdef CONFIG_PPC85xx_VT_MODE
+		/* Disable instruction completion */
+		wrhv_mtspr(SPRN_DBCR0, wrhv_mfspr(SPRN_DBCR0) & ~DBCR0_IC);
+		/* Clear the instruction completion event */
+		wrhv_mtspr(SPRN_DBSR, DBSR_IC);
+#endif
+
+		if (notify_die(DIE_SSTEP, "single_step", regs, 5,
+			       5, SIGTRAP) == NOTIFY_STOP) {
+			return;
+		}
+
+		if (debugger_sstep(regs))
+			return;
+
+		if (user_mode(regs)) {
+			current->thread.dbcr0 &= ~DBCR0_IC;
+#ifdef CONFIG_PPC_ADV_DEBUG_REGS
+			if (DBCR_ACTIVE_EVENTS(current->thread.dbcr0,
+					       current->thread.dbcr1))
+				regs->msr |= MSR_DE;
+			else
+				/* Make sure the IDM bit is off */
+				current->thread.dbcr0 &= ~DBCR0_IDM;
+#endif
+		}
+
+		_exception(SIGTRAP, regs, TRAP_TRACE, regs->nip);
+	} else
+		wrhv_handle_debug(regs, debug_status);
+}
+
+/* arch/powerpc/kernel/kgdb.c */
+int wrhv_kgdb_arch_handle_exception(int vector, int signo, int err_code,
+			       char *remcom_in_buffer, char *remcom_out_buffer,
+			       struct pt_regs *linux_regs)
+{
+	char *ptr = &remcom_in_buffer[1];
+	unsigned long addr;
+
+	switch (remcom_in_buffer[0]) {
+		/*
+		 * sAA..AA   Step one instruction from AA..AA
+		 * This will return an error to gdb ..
+		 */
+	case 's':
+	case 'c':
+		/* handle the optional parameter */
+		if (kgdb_hex2long(&ptr, &addr))
+			linux_regs->nip = addr;
+
+		atomic_set(&kgdb_cpu_doing_single_step, -1);
+		/* set the trace bit if we're stepping */
+		if (remcom_in_buffer[0] == 's') {
+#ifdef CONFIG_PPC_ADV_DEBUG_REGS
+#ifdef CONFIG_PPC85xx_VT_MODE
+			wrhv_mtspr(SPRN_DBCR0,
+			      wrhv_mfspr(SPRN_DBCR0) | DBCR0_IC | DBCR0_IDM);
+#else
+			wr_control->vb_control_regs.dbcr0 |= (DBCR0_IC | DBCR0_IDM);
+#endif
+			wr_control->vb_control_regs.emsr |= MSR_DE;
+			linux_regs->msr |= MSR_DE;
+#else
+			linux_regs->msr |= MSR_SE;
+#endif
+			kgdb_single_step = 1;
+			atomic_set(&kgdb_cpu_doing_single_step,
+				   raw_smp_processor_id());
+		}
+		return 0;
+	}
+	return -1;
+}
+
+int wrhv_ppc_cpu_freq(void)
+{
+	return wrhv_cpu_freq;
+}
+
+/* Use bus 0 by default. On p4080 bus is encoded as famn0:dtsec0. */
+uint32_t wrhv_mdio_bus = 0;
+int wrhv_mdio_write(struct mii_bus *bus, int mii_id, int devad, int regnum,
+			u16 value)
+{
+	VBI_BSP_MSG		mdio_msg;
+	VBI_BSP_MSG_REPLY	mdio_reply;
+	int			rc = -1;
+	u32			bid = 0;
+
+	if (ppc_md.get_mdio_bus)
+		bid = ppc_md.get_mdio_bus(bus, mii_id);
+
+	mdio_msg.request = VBI_MDIO_WRITE;
+	mdio_msg.arg.mdioWrite.bus = bid;
+	mdio_msg.arg.mdioWrite.phyAddr = (uint32_t) mii_id;
+	mdio_msg.arg.mdioWrite.regNum = (uint32_t) regnum;
+	mdio_msg.arg.mdioWrite.page = 0;
+	mdio_msg.arg.mdioWrite.dataVal = value;
+
+	rc = bsp_service_handle(&mdio_msg, &mdio_reply);
+
+	if (rc || mdio_reply.status)
+		rc = -1;
+
+	return rc;
+
+}
+
+int wrhv_mdio_read(struct mii_bus *bus, int mii_id, int devad, int regnum)
+{
+	VBI_BSP_MSG		mdio_msg;
+	VBI_BSP_MSG_REPLY	mdio_reply;
+	int			rc = -1;
+	u32			bid = 0;
+
+	if (ppc_md.get_mdio_bus)
+		bid = ppc_md.get_mdio_bus(bus, mii_id);
+
+	mdio_msg.request = VBI_MDIO_READ;
+	mdio_msg.arg.mdioRead.bus = bid;
+	mdio_msg.arg.mdioRead.phyAddr = (uint32_t) mii_id;
+	mdio_msg.arg.mdioRead.regNum = (uint32_t) regnum;
+	mdio_msg.arg.mdioRead.page = 0;
+
+	rc = bsp_service_handle(&mdio_msg, &mdio_reply);
+
+	if (rc || mdio_reply.status || (mdio_reply.dataVal >> 16 != 0))
+		return -1;
+
+	return mdio_reply.dataVal;
+}
+
+#ifdef CONFIG_WRHV_ASID_OPTIMIZATION
+/* Clone of: arch/powerpc/mm/mmu_context_nohash.c */
+
+unsigned int wrhv_steal_context_up(unsigned int id)
+{
+	struct mm_struct *mm;
+	int cpu = smp_processor_id();
+
+	static VMMU_CONFIG vmmu_cfg;
+
+	/* Pick up the victim mm */
+	mm = context_mm[id];
+#ifdef CONFIG_WRHV_DEBUG
+	printk(" | steal %d from 0x%p MM->ctxID %d \n", id, mm, mm->context.id);
+#endif
+
+	/* Flush the TLB for that context */
+	local_flush_tlb_mm(mm);
+
+	/* Mark this mm has having no context anymore */
+	mm->context.id = MMU_NO_CONTEXT;
+
+	/* XXX This clear should ultimately be part of local_flush_tlb_mm */
+	__clear_bit(id, stale_map[cpu]);
+
+	return id;
+}
+
+
+
+int wrhv_init_new_context(struct task_struct *t, struct mm_struct *mm)
+{
+	unsigned long ctx = next_context;
+	static VMMU_CONFIG vmmu_cfg;
+	unsigned int ret_code;
+	pgd_t *kpdStart, *kpdEnd, *updStart;
+
+
+	pgd_t *pgd = mm->pgd;
+
+	kpdStart = pgd_offset_k(KERNELBASE);
+	kpdEnd =   pgd_offset_k(0xffffffff);
+
+	updStart = pgd + pgd_index(KERNELBASE);
+
+	memcpy(updStart, kpdStart, (kpdEnd - kpdStart + 1) * sizeof (pgd_t));
+
+	vmmu_cfg.addr = (VMMU_LEVEL_1_DESC *) pgd;
+	vmmu_cfg.flush_type = VMMU_TLB_FLUSH_ASID;
+	vmmu_cfg.asid = ctx;
+	vmmu_cfg.vmmu_handle = ctx;
+
+	ret_code = vbi_create_vmmu(&vmmu_cfg);
+	if (ret_code) {
+		printk(" Error creating VMMU handles \n");
+	}
+	mm->context.vmmu_handle = vmmu_cfg.vmmu_handle;
+
+	mm->context.id = NO_CONTEXT;
+	mm->context.active = 0;
+
+	return 0;
+}
+
+
+void wrhv_destroy_context(struct mm_struct *mm)
+{
+	unsigned long flags;
+	unsigned int id;
+	static VMMU_CONFIG vmmu_cfg;
+
+	if (mm->context.id == NO_CONTEXT)
+		return;
+
+	vmmu_cfg.addr = -1;
+	vmmu_cfg.flush_type = VMMU_TLB_FLUSH_ASID;
+	vmmu_cfg.asid = mm->context.id;
+	vmmu_cfg.vmmu_handle = mm->context.vmmu_handle;
+
+	WARN_ON(mm->context.active != 0);
+
+	raw_spin_lock_irqsave(&wrhv_context_lock, flags);
+	id = mm->context.id;
+	if (id != NO_CONTEXT) {
+		__clear_bit(id, context_map);
+		mm->context.id = NO_CONTEXT;
+#ifdef DEBUG_MAP_CONSISTENCY
+		mm->context.active = 0;
+#endif
+		context_mm[id] = NULL;
+		nr_free_contexts++;
+	}
+	vbi_delete_vmmu(&vmmu_cfg);
+	raw_spin_unlock_irqrestore(&wrhv_context_lock, flags);
+}
+
+void wrhv_switch_mmu_context(struct mm_struct *prev, struct mm_struct *next)
+{
+	unsigned int i, id, cpu = smp_processor_id();
+	unsigned long *map;
+	static VMMU_CONFIG vmmu_cfg;
+
+	/* No lockless fast path .. yet */
+	raw_spin_lock(&wrhv_context_lock);
+#ifdef DEBUG_MAP_CONSISTENCY
+	printk("[%d] activating context for mm @%p, active=%d, id=%d",
+		cpu, next, next->context.active, next->context.id);
+#endif
+#ifdef CONFIG_SMP
+	/* Mark us active and the previous one not anymore */
+	next->context.active++;
+	if (prev) {
+		printk(" (old=0x%p a=%d)", prev, prev->context.active);
+		WARN_ON(prev->context.active < 1);
+		prev->context.active--;
+	}
+
+ again:
+#endif /* CONFIG_SMP */
+
+	/* If we already have a valid assigned context, skip all that */
+	id = next->context.id;
+	if (likely(id != NO_CONTEXT)) {
+#ifdef DEBUG_MAP_CONSISTENCY
+		if (context_mm[id] != next)
+			printk("MMU: mm 0x%p has id %d but context_mm[%d] says 0x%p\n",
+				next, id, id, context_mm[id]);
+#endif
+		goto ctxt_ok;
+	}
+
+	/* We really don't have a context, let's try to acquire one */
+	id = next_context;
+	if (id > last_context)
+		id = first_context;
+	map = context_map;
+
+	/* No more free contexts, let's try to steal one */
+	if (nr_free_contexts == 0) {
+#ifdef CONFIG_SMP
+		if (num_online_cpus() > 1) {
+			id = steal_context_smp(id);
+			if (id == NO_CONTEXT)
+				goto again;
+			goto stolen;
+		}
+#endif /* CONFIG_SMP */
+		id = wrhv_steal_context_up(id);
+		goto stolen;
+	}
+	nr_free_contexts--;
+
+	/* We know there's at least one free context, try to find it */
+	while (__test_and_set_bit(id, map)) {
+		id = find_next_zero_bit(map, last_context+1, id);
+		if (id > last_context)
+			id = first_context;
+	}
+ stolen:
+	if (id <= first_context)
+		id = first_context;
+	next_context = id + 1;
+	context_mm[id] = next;
+	next->context.id = id;
+#ifdef CONFIG_WRHV_DEBUG
+	printk(" | new id=%d,nrf=%d", id, nr_free_contexts);
+#endif
+
+	context_check_map();
+ ctxt_ok:
+
+	/* If that context got marked stale on this CPU, then flush the
+	 * local TLB for it and unmark it before we use it
+	 */
+	if (test_bit(id, stale_map[cpu])) {
+#ifdef CONFIG_WRHV_DEBUG
+		printk(" | stale flush %d [%d..%d]",
+				id, cpu_first_thread_in_core(cpu),
+				cpu_last_thread_in_core(cpu));
+#endif
+
+		local_flush_tlb_mm(next);
+
+		/* XXX This clear should ultimately be part of local_flush_tlb_mm */
+		for (i = cpu_first_thread_in_core(cpu);
+			i <= cpu_last_thread_in_core(cpu); i++) {
+			__clear_bit(id, stale_map[i]);
+		}
+	}
+
+	/* Flick the MMU and release lock */
+#ifdef CONFIG_WRHV_ASID_OPTIMIZATION
+#ifdef CONFIG_WRHV_DEBUG
+	printk(" -> %d\n", id);
+#endif
+	vb_context_mmu_on(id, next->pgd, PAGE_SIZE, next->context.id,
+		next->context.vmmu_handle, 0);
+#else
+	set_context(id, next->pgd);
+#endif
+	raw_spin_unlock(&wrhv_context_lock);
+}
+
+
+/*
+ * Initialize the context management stuff.
+ */
+void __init wrhv_mmu_context_init(void)
+{
+	/* Mark init_mm as being active on all possible CPUs since
+	 * we'll get called with prev == init_mm the first time
+	 * we schedule on a given CPU
+	 */
+	init_mm.context.active = NR_CPUS;
+
+	/*
+	 *   The MPC8xx has only 16 contexts.  We rotate through them on each
+	 * task switch.  A better way would be to keep track of tasks that
+	 * own contexts, and implement an LRU usage.  That way very active
+	 * tasks don't always have to pay the TLB reload overhead.  The
+	 * kernel pages are mapped shared, so the kernel can run on behalf
+	 * of any task that makes a kernel entry.  Shared does not mean they
+	 * are not protected, just that the ASID comparison is not performed.
+	 *      -- Dan
+	 *
+	 * The IBM4xx has 256 contexts, so we can just rotate through these
+	 * as a way of "switching" contexts.  If the TID of the TLB is zero,
+	 * the PID/TID comparison is disabled, so we can use a TID of zero
+	 * to represent all kernel pages as shared among all contexts.
+	 * 	-- Dan
+	 */
+	first_context = ASID_FIRST_CONTEXT;
+	last_context = ASID_LAST_CONTEXT;
+
+	/*
+	 * Allocate the maps used by context management
+	 */
+	context_map = alloc_bootmem(CTX_MAP_SIZE);
+	context_mm = alloc_bootmem(sizeof(void *) * (last_context + 1));
+	stale_map[0] = alloc_bootmem(CTX_MAP_SIZE);
+
+#ifdef CONFIG_SMP
+	register_cpu_notifier(&mmu_context_cpu_nb);
+#endif
+
+	printk(KERN_INFO
+		"MMU: Allocated %zu bytes of context maps for %d contexts\n",
+		2 * CTX_MAP_SIZE + (sizeof(void *) * (last_context + 1)),
+		last_context - first_context + 1);
+
+	/*
+	 * Some processors have too few contexts to reserve one for
+	 * init_mm, and require using context 0 for a normal task.
+	 * Other processors reserve the use of context zero for the kernel.
+	 * This code assumes first_context < 32.
+	 */
+	context_map[0] = (1 << first_context) - 1;
+	next_context = first_context;
+	nr_free_contexts = last_context - first_context + 1;
+}
+#endif
+
+void wrhv_duart_init(void);
+void wrhv_udbg_init_uart(void __iomem *comport, unsigned int speed,
+		unsigned int clock)
+{
+#ifdef CONFIG_WRHV_DUART
+	/* initialize hypervisor duart serial device driver */
+	wrhv_duart_init();
+#endif
+}
+
+void wrhv_init(void)
+{
+	/* initialize wr_config so that we can access
+	 * vbi configuration. The vbi configuration space
+	 * is defined in Hypervisor linux.xml
+	 */
+	wr_config = (struct vb_config *)0xF0000000;
+	wr_control = wr_config->vb_control;
+	wr_status = wr_config->vb_status;
+
+	pv_info.name = "wrhv";
+	pv_info.paravirt_enabled = 1;
+
+	pv_time_ops.time_init_cont = wrhv_time_init_cont;
+	pv_time_ops.timer_interrupt = wrhv_hw_timer_interrupt;
+	pv_time_ops.clocksource_init = native_clocksource_init;
+
+	pv_irq_ops.do_IRQ = wrhv_do_IRQ;
+	pv_irq_ops.irq_of_parse_and_map =
+			wrhv_irq_of_parse_and_map;
+
+#ifndef CONFIG_PPC85xx_VT_MODE
+	pv_cpu_ops.get_pvr = wrhv_get_pvr;
+	pv_cpu_ops.get_svr = wrhv_get_svr;
+#endif
+
+	pv_cpu_ops.DebugException = wrhv_DebugException;
+	pv_cpu_ops.prime_debug_regs = wrhv_prime_debug_regs;
+	pv_cpu_ops.kgdb_arch_handle_exception =
+		wrhv_kgdb_arch_handle_exception;
+	pv_cpu_ops.ppc_proc_freq =
+		wrhv_ppc_cpu_freq;
+
+#ifndef CONFIG_PPC85xx_VT_MODE
+	pv_mmu_ops.vmmu_restore = wrhv_vmmu_restore;
+#ifdef CONFIG_WRHV_ASID_OPTIMIZATION
+	pv_context_ops.init_new_context = wrhv_init_new_context;
+	pv_context_ops.destroy_context = wrhv_destroy_context;
+	pv_context_ops.switch_mmu_context = wrhv_switch_mmu_context;
+	pv_context_ops.mmu_context_init = wrhv_mmu_context_init;
+#endif
+#endif
+	pv_mmu_ops.MMU_init_hw = wrhv_MMU_init_hw;
+	pv_mmu_ops.mmu_mapin_ram = wrhv_mmu_mapin_ram;
+	pv_mmu_ops.MMU_setup = wrhv_MMU_setup;
+	pv_mmu_ops.MMU_init = wrhv_MMU_init;
+	pv_mmu_ops.flush_dcache_page = wrhv_flush_dcache_page;
+	pv_mmu_ops.map_page = wrhv_map_page;
+	pv_mmu_ops.early_init_dt_scan_memory_ppc =
+		wrhv_early_init_dt_scan_memory_ppc;
+	pv_mmu_ops.__ioremap = wrhv___ioremap;
+	pv_mmu_ops.__set_pte_at = wrhv__set_pte_at;
+	pv_mdio_ops.fsl_pq_mdio_write = wrhv_mdio_write;
+	pv_mdio_ops.fsl_pq_mdio_read = wrhv_mdio_read;
+
+#ifdef CONFIG_PCI
+	ppc_pci_set_flags(PPC_PCI_REASSIGN_ALL_RSRC);
+#endif
+
+#ifdef CONFIG_WRHV_DUART
+	pv_serial_ops.udbg_init_uart = wrhv_udbg_init_uart;
+#endif
+}
+
+__weak void wrhv_setup_msr_for_ap(VBI_HREG_SET_CMPLX_QUALIFIED *regs)
+{
+	return;
+}
+EXPORT_SYMBOL(wrhv_setup_msr_for_ap);
+
+#ifdef CONFIG_SMP
+VBI_HREG_SET_CMPLX_QUALIFIED bootREG;
+#define IPI_IRQ_BASE_NAME "ipi0"
+int irq_base = 0xFFFF; /*init as invalid IRQ number*/
+#define WRHV_IPI_NUM      4
+
+DEFINE_PER_CPU(long long, tb_diff);
+
+long long wrhv_gettb_diff()
+{
+	return __raw_get_cpu_var(tb_diff);
+}
+
+void wrhv_settb_diff(long long diff)
+{
+	 __get_cpu_var(tb_diff) = diff;
+}
+
+static irqreturn_t wrhv_ipi_action(int irq, void *data)
+{
+	long ipi = (long)data;
+
+	smp_message_recv(ipi);
+
+	return IRQ_HANDLED;
+}
+
+void __devinit smp_wrhv_setup_cpu(int cpu_nr)
+{
+	return;
+}
+
+static void wrhv_mask_IPIs_for_vcore(void)
+{
+	int i;
+
+	for (i = 0; i < WRHV_IPI_NUM; i++)
+		vbi_mask_vioapic_irq(irq_base + i);
+}
+
+void wrhv_umask_IPIs_for_vcore(void)
+{
+	int i;
+
+	for (i = 0; i < WRHV_IPI_NUM; i++)
+		vbi_unmask_vioapic_irq(irq_base + i);
+}
+
+void wrhv_request_ipis(void)
+{
+	static char *ipi_names[] = {
+		"IPI0 (call function)",
+		"IPI1 (reschedule)",
+		"IPI2 (call function single)",
+		"IPI3 (debugger break)",
+	};
+	int i, err;
+
+	printk(KERN_INFO "WRHV requesting IPIs ... \n");
+
+	irq_base = wrhv_map_irq_of_desc(IPI_IRQ_BASE_NAME, VB_INPUT_INT);
+	if (irq_base == VBI_INVALID_IRQ)
+		panic("WRHV reslove irq for IPI failed.\n");
+
+	for (i = 0; i < WRHV_IPI_NUM; i++) {
+		err = request_irq(irq_base + i, wrhv_ipi_action,
+				IRQF_DISABLED | IRQF_PERCPU | IRQF_NOBALANCING,
+				ipi_names[i], (void *)i);
+		if (err) {
+			printk(KERN_ERR "WRHV Request of irq %d for %s failed\n",
+					irq_base + i, ipi_names[i]);
+			/*
+			 * There is no really clean work here. The best choice
+			 * here might panic() immediately
+			 */
+			panic("WRHV: request_irq for IPI faild.\n");
+		}
+
+		set_irq_chip_and_handler_name(irq_base + i,
+				&wrhv_ipi_irq_chip, handle_percpu_irq, "per_cpu");
+	}
+}
+
+int __init smp_wrhv_probe(void)
+{
+	int nr_cpus;
+
+	pr_debug("smp_mpic_probe()...\n");
+
+	nr_cpus = cpus_weight(cpu_possible_map);
+
+	pr_debug("nr_cpus: %d\n", nr_cpus);
+
+	if (nr_cpus > 1) {
+		wrhv_request_ipis();
+		wrhv_umask_IPIs_for_vcore();
+	}
+
+	return nr_cpus;
+}
+
+static inline void wrhv_send_IPI_mask(int irq, cpumask_t mask)
+{
+	unsigned long coreset = cpus_addr(mask)[0];
+	unsigned long flags;
+
+	local_irq_save(flags);
+	WARN_ON(coreset & ~cpus_addr(cpu_online_map)[0]);
+	vbi_send_vcore_vioapic_irq(irq, coreset, 0);
+	local_irq_restore(flags);
+}
+
+void smp_wrhv_message_pass(int target, int msg)
+{
+	cpumask_t mask, dst;
+	int self = smp_processor_id();
+
+	/* make sure we're sending something that translates to an IPI */
+	if (msg > 3) {
+		printk(KERN_INFO "SMP %d: smp_message_pass: unknown msg %d\n",
+				smp_processor_id(), msg);
+		return;
+	}
+
+	switch (target) {
+		case MSG_ALL:
+			cpus_setall(dst);
+			cpus_and(mask, dst, cpu_online_map);
+			wrhv_send_IPI_mask(msg + irq_base,mask);
+			break;
+		case MSG_ALL_BUT_SELF:
+			cpus_setall(dst);
+			cpu_clear(self, dst);
+			cpus_and(mask, dst, cpu_online_map);
+			wrhv_send_IPI_mask(msg + irq_base, mask);
+			break;
+		default:
+			cpus_clear(dst);
+			cpu_set(target, dst);
+			cpus_and(mask, dst, cpu_online_map);
+			wrhv_send_IPI_mask(msg + irq_base, mask);
+			break;
+	}
+}
+
+static void __devinit smp_wrhv_kick_cpu(int nr)
+{
+	unsigned long flags;
+	int32_t ret;
+	
+	int n = 0;
+	WARN_ON (nr < 0 || nr >= NR_CPUS);
+
+	local_irq_save(flags);
+
+	bootREG.vbiRegType = VBI_REG_SET_32BIT;
+
+	ret = vbi_vb_read_reg(&bootREG, VBI_BOARD_ID_GET(), nr);
+	if (ret)
+		printk(KERN_ERR "WRHV read REG failed: %d\n", ret);
+
+	bootREG.vbiRegType = VBI_REG_SET_32BIT;
+	bootREG.vbiRegSet.hreg32.pc = 0xc0000000;
+	wrhv_setup_msr_for_ap(&bootREG);
+
+	ret = vbi_vb_write_reg(&bootREG, VBI_BOARD_ID_GET(), nr);
+	if (ret)
+		printk(KERN_ERR "WRHV write REG failed: %d\n", ret);
+
+	ret = vbi_vb_resume(VBI_BOARD_ID_GET(), nr);
+	if (ret)
+		printk(KERN_ERR "WRHV resume CPU failed: %d\n", ret);
+
+	/* Wait a bit for the CPU to ack. */
+	while ((__secondary_hold_acknowledge != nr) && (++n < 1000))
+		mdelay(1);
+
+	local_irq_restore(flags);
+}
+
+unsigned long mpc85xx_smp_message[NR_CPUS]; /*fix doorbell_exception link error */
+
+#ifdef CONFIG_HOTPLUG_CPU
+DECLARE_PER_CPU(int, cpu_state);
+void cpu_die(void)
+{
+	unsigned int cpu;
+	int ret;
+
+	idle_task_exit();
+
+	local_irq_disable();
+	cpu = smp_processor_id();
+	printk(KERN_DEBUG "CPU%d offline\n", cpu);
+	__get_cpu_var(cpu_state) = CPU_DEAD;
+	smp_wmb();
+
+	preempt_enable();
+	ret = vbi_vb_suspend(VBI_BOARD_ID_GET(), cpu);
+	if (ret)
+		printk(KERN_ERR "%s: suspend result: %d\n", __func__, ret);
+
+	while (1);
+}
+
+static int wrhv_cpu_disable(void)
+{
+	int cpu = smp_processor_id();
+	printk(KERN_INFO "%s: cpu = %d\n", __func__, cpu);
+
+	if (cpu == boot_cpuid)
+		return -EBUSY;
+
+	wrhv_fixup_irqs(cpu);
+
+	wrhv_mask_IPIs_for_vcore();
+
+	set_cpu_online(cpu, false);
+
+	return 0;
+}
+
+static int wrhv_cpu_enable(unsigned int cpu)
+{
+	printk(KERN_INFO "%s: cpu = %d\n", __func__, cpu);
+
+	if (system_state != SYSTEM_RUNNING)
+		return -ENOSYS;
+
+	return 1;
+}
+
+#endif
+
+struct smp_ops_t smp_wrhv_ops = {
+	.kick_cpu = smp_wrhv_kick_cpu,
+#if defined(CONFIG_HOTPLUG_CPU) && defined(CONFIG_PPC32)
+	.cpu_enable  = wrhv_cpu_enable,
+	.cpu_disable = wrhv_cpu_disable,
+	.cpu_die = generic_cpu_die,
+#endif
+	.probe = smp_wrhv_probe,
+	.message_pass = smp_wrhv_message_pass,
+	.setup_cpu = smp_wrhv_setup_cpu,
+	.take_timebase = smp_generic_take_timebase,
+	.give_timebase = smp_generic_give_timebase,
+};
+
+void __init wrhv_smp_init(void)
+{
+	smp_ops = &smp_wrhv_ops;
+}
+
+extern struct smp_ops_t *smp_ops;
+extern volatile unsigned int cpu_callin_map[NR_CPUS];
+
+static void __devinit smp_store_cpu_info(int id)
+{
+	per_cpu(cpu_pvr, id) = get_pvr();
+}
+
+/* Must be called when no change can occur to cpu_present_map,
+ * i.e. during cpu online or offline.
+ */
+static struct device_node *cpu_to_l2cache(int cpu)
+{
+	struct device_node *np;
+	struct device_node *cache;
+
+	if (!cpu_present(cpu))
+		return NULL;
+
+	np = of_get_cpu_node(cpu, NULL);
+	if (np == NULL)
+		return NULL;
+
+	cache = of_find_next_cache_node(np);
+
+	of_node_put(np);
+
+	return cache;
+}
+
+/* Activate a secondary processor. */
+int __devinit wrhv_start_secondary(void *unused)
+{
+	unsigned int cpu = smp_processor_id();
+	struct device_node *l2_cache;
+	int i, base;
+
+	local_irq_disable();
+#ifndef CONFIG_PPC85xx_VT_MODE
+	vb_context_mmu_on(0, swapper_pg_dir, PAGE_SIZE, KERNEL_BASE_ASID,
+			KERNEL_BASE_ASID, 0);
+#endif
+
+	wrhv_umask_IPIs_for_vcore();
+	vbi_set_exc_offset(&exec_table);
+
+	atomic_inc(&init_mm.mm_count);
+	current->active_mm = &init_mm;
+
+	smp_store_cpu_info(cpu);
+	preempt_disable();
+	cpu_callin_map[cpu] = 1;
+
+	if (smp_ops->setup_cpu)
+		smp_ops->setup_cpu(cpu);
+	if (smp_ops->take_timebase)
+		smp_ops->take_timebase();
+
+	if (system_state > SYSTEM_BOOTING)
+		snapshot_timebase();
+
+	ipi_call_lock();
+	notify_cpu_starting(cpu);
+	set_cpu_online(cpu, true);
+	/* Update sibling maps */
+	base = cpu_first_thread_in_core(cpu);
+	for (i = 0; i < threads_per_core; i++) {
+		if (cpu_is_offline(base + i))
+			continue;
+		cpu_set(cpu, per_cpu(cpu_sibling_map, base + i));
+		cpu_set(base + i, per_cpu(cpu_sibling_map, cpu));
+
+		/* cpu_core_map should be a superset of
+		 * cpu_sibling_map even if we don't have cache
+		 * information, so update the former here, too.
+		 */
+		cpu_set(cpu, per_cpu(cpu_core_map, base +i));
+		cpu_set(base + i, per_cpu(cpu_core_map, cpu));
+	}
+	l2_cache = cpu_to_l2cache(cpu);
+	for_each_online_cpu(i) {
+		struct device_node *np = cpu_to_l2cache(i);
+		if (!np)
+			continue;
+		if (np == l2_cache) {
+			cpu_set(cpu, per_cpu(cpu_core_map, i));
+			cpu_set(i, per_cpu(cpu_core_map, cpu));
+		}
+		of_node_put(np);
+	}
+	of_node_put(l2_cache);
+	ipi_call_unlock();
+
+	local_irq_enable();
+
+	cpu_idle();
+	return 0;
+}
+#else
+long long wrhv_gettb_diff()
+{
+	return 0;
+}
+#endif
+
+#ifdef CONFIG_PCI
+
+/* On PPC we have to disable MSI firstly to adopt the legacy interrupt 
+ * since the BootROM with supporting PCIE always use MSI way. 
+ */
+void pci_msi_disable(struct pci_dev *dev)
+{
+	u16 control;
+	int pos = pci_find_capability(dev, PCI_CAP_ID_MSI);
+
+	if (pos) {
+		pci_read_config_word(dev, pos + PCI_MSI_FLAGS, &control);
+		if (control & PCI_MSI_FLAGS_ENABLE) {
+			control &= ~PCI_MSI_FLAGS_ENABLE;
+			pci_write_config_word(dev, pos + PCI_MSI_FLAGS, control);
+		}
+	}
+}
+DECLARE_PCI_FIXUP_FINAL(PCI_ANY_ID, PCI_ANY_ID, pci_msi_disable);
+#endif
+
+static int __init parse_memmap_opt(char *p)
+{
+	char *oldp;
+	u64 start, size, offset;
+
+	if (!p)
+		return -EINVAL;
+
+	oldp = p;
+	size = memparse(p, &p);
+	if (p == oldp)
+		return -EINVAL;
+
+	if (*p == '$')
+		start = memparse(p + 1, &p);
+	else
+		return -EINVAL;
+
+	/*
+	 * The guest physical address of a VB is start from 0. So we can get
+	 * the real RAM offset of a VB by using following method.
+	 */
+	vbi_guest_phys_to_phys(0, &offset);
+
+	start = start - offset;	/* Convert to guest physical address */
+	lmb_reserve(start, size);
+	return 0;
+}
+early_param("memmap", parse_memmap_opt);
+
diff --git a/arch/powerpc/kernel/vdso32/gettimeofday.S b/arch/powerpc/kernel/vdso32/gettimeofday.S
index ee038d4..b6d65c0 100644
--- a/arch/powerpc/kernel/vdso32/gettimeofday.S
+++ b/arch/powerpc/kernel/vdso32/gettimeofday.S
@@ -219,6 +219,7 @@ __do_get_xsec:
 	lwz	r5,CFG_TB_ORIG_STAMP(r9)
 	lwz	r6,(CFG_TB_ORIG_STAMP+4)(r9)
 
+#ifndef CONFIG_WRHV
 	/* Get a stable TB value */
 2:	mftbu	r3
 	mftbl	r4
@@ -232,6 +233,16 @@ __do_get_xsec:
 	 */
 	subfc	r7,r6,r4
 	subfe.	r0,r5,r3
+#else
+	/* Here we should use our paravirtualized get_tb() to get
+	 * proper tb, but its difficult to call C program in this
+	 * pure assemble codes section, so we substract tb orig stamp
+	 * in update_gtod() directly.
+	 */
+	mr	r7,r6
+	mr	r0,r5
+	cmpwi	0,r0,0
+#endif
 	bne-	3f
 
 	/* Load scale factor & do multiplication */
@@ -293,6 +304,7 @@ __do_get_tspec:
 	lwz	r5,CFG_TB_ORIG_STAMP(r9)
 	lwz	r6,(CFG_TB_ORIG_STAMP+4)(r9)
 
+#ifndef CONFIG_WRHV
 	/* Get a stable TB value */
 2:	mftbu	r3
 	mftbl	r4
@@ -304,6 +316,15 @@ __do_get_tspec:
 	 */
 	subfc	r7,r6,r4
 	subfe	r0,r5,r3
+#else
+	/* Here we should use our paravirtualized get_tb() to get
+	 * proper tb, but its difficult to call C program in this
+	 * pure assemble codes section, so we substract tb orig stamp
+	 * in update_gtod() directly.
+	 */
+	mr	r7,r6
+	mr	r0,r5
+#endif
 	slwi	r0,r0,12
 	rlwimi.	r0,r7,12,20,31
 	slwi	r7,r7,12
diff --git a/arch/powerpc/kernel/wrhv_entry_32.S b/arch/powerpc/kernel/wrhv_entry_32.S
new file mode 100644
index 0000000..707e6cf
--- /dev/null
+++ b/arch/powerpc/kernel/wrhv_entry_32.S
@@ -0,0 +1,551 @@
+/*
+ *  PowerPC version
+ *    Copyright (C) 1995-1996 Gary Thomas (gdt@linuxppc.org)
+ *  Rewritten by Cort Dougan (cort@fsmlabs.com) for PReP
+ *    Copyright (C) 1996 Cort Dougan <cort@fsmlabs.com>
+ *  Adapted for Power Macintosh by Paul Mackerras.
+ *  Low-level exception handlers and MMU support
+ *  rewritten by Paul Mackerras.
+ *    Copyright (C) 1996 Paul Mackerras.
+ *  MPC8xx modifications Copyright (C) 1997 Dan Malek (dmalek@jlc.net).
+ *  
+ *  Fork from entry_32.S for Hypervisor/Guest, Copyright (C) 2009
+ *  Wind River Systems, Inc.
+ *
+ *  This file contains the system call entry code, context switch
+ *  code, and exception/interrupt return code for PowerPC.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version
+ *  2 of the License, or (at your option) any later version.
+ *
+ */
+
+#include <linux/errno.h>
+#include <linux/sys.h>
+#include <linux/threads.h>
+#include <asm/reg.h>
+#include <asm/page.h>
+#include <asm/mmu.h>
+#include <asm/cputable.h>
+#include <asm/thread_info.h>
+#include <asm/ppc_asm.h>
+#include <asm/asm-offsets.h>
+#include <asm/unistd.h>
+#include <asm/ftrace.h>
+#ifdef CONFIG_WRHV
+#include <vbi/interface.h>
+#include <asm/arch_vbi.h>
+#include <vbi/syscalls.h>
+#endif /* CONFIG_WRHV */
+
+#undef SHOW_SYSCALLS
+#undef SHOW_SYSCALLS_TASK
+#ifdef	CONFIG_WRHV
+#undef VMMU  /* just for debugging */
+#endif /* CONFIG_WRHV */
+
+#ifdef CONFIG_WRHV
+       .data
+       .globl  wrhv_sprg3
+wrhv_sprg3:
+       .long   0
+#ifdef CONFIG_SMP
+       .globl wrhv_pir
+wrhv_pir:
+       .long   0
+#endif
+       .text
+#endif /* CONFIG_WRHV */
+
+/*
+ * MSR_KERNEL is > 0x10000 on 4xx/Book-E since it include MSR_CE.
+ */
+#if MSR_KERNEL >= 0x10000
+#define LOAD_MSR_KERNEL(r, x)	lis r,(x)@h; ori r,r,(x)@l
+#else
+#define LOAD_MSR_KERNEL(r, x)	li r,(x)
+#endif
+
+	.globl	paravirt_transfer_to_handler
+paravirt_transfer_to_handler:
+	stw	r2,GPR2(r11)
+	stw	r12,_NIP(r11)
+	stw	r9,_MSR(r11)
+	andi.	r2,r9,MSR_PR
+	mfctr	r12
+	mfspr	r2,SPRN_XER
+	stw	r12,_CTR(r11)
+	stw	r2,_XER(r11)
+	WRHV_MFSPRG3(r12)
+	addi	r2,r12,-THREAD
+	tovirt(r2,r2)			/* set r2 to current */
+	beq	2f			/* if from user, fix up THREAD.regs */
+	addi	r11,r1,STACK_FRAME_OVERHEAD
+	stw	r11,PT_REGS(r12)
+#if defined(CONFIG_40x) || defined(CONFIG_BOOKE)
+	/* Check to see if the dbcr0 register is set up to debug.  Use the
+	internal debug mode bit to do this. */
+	lwz	r12,THREAD_DBCR0(r12)
+	andis.	r12,r12,DBCR0_IDM@h
+	beq+	3f
+	/* From user and task is ptraced - load up global dbcr0 */
+	li	r12,-1                  /* clear all pending debug events */
+	lis	r9,wr_control@ha
+	lwz	r9,wr_control@l(r9)
+	stw	r12,VB_CONTROL_DBCR0(r9)
+	lis	r11,global_dbcr0@ha
+	tophys(r11,r11)
+	addi	r11,r11,global_dbcr0@l
+#ifdef CONFIG_SMP
+	rlwinm	r9,r1,0,0,(31-THREAD_SHIFT)
+	lwz	r9,TI_CPU(r9)
+	slwi	r9,r9,3
+	add	r11,r11,r9
+#endif
+	lwz	r12,0(r11)
+	lis	r9,wr_control@ha
+	lwz	r9,wr_control@l(r9)
+	stw	r12,VB_CONTROL_DBCR0(r9)
+	lwz	r12,4(r11)
+	addi	r12,r12,-1
+	stw	r12,4(r11)
+#endif
+	b	3f
+
+2:	/* if from kernel, check interrupted DOZE/NAP mode and
+         * check for stack overflow
+         */
+	lwz	r9,KSP_LIMIT(r12)
+	cmplw	r1,r9			/* if r1 <= ksp_limit */
+	ble-	paravirt_stack_ovf		/* then the kernel stack overflowed */
+5:
+#if defined(CONFIG_6xx) || defined(CONFIG_E500)
+	rlwinm	r9,r1,0,0,31-THREAD_SHIFT
+	tophys(r9,r9)			/* check local flags */
+	lwz	r12,TI_LOCAL_FLAGS(r9)
+	mtcrf	0x01,r12
+	bt-	31-TLF_NAPPING,4f
+	bt-	31-TLF_SLEEPING,7f
+#endif /* CONFIG_6xx || CONFIG_E500 */
+	.globl paravirt_transfer_to_handler_cont
+paravirt_transfer_to_handler_cont:
+3:
+	mflr	r9
+	lwz	r11,0(r9)		/* virtual address of handler */
+	lwz	r9,4(r9)		/* where to go when done */
+	mtlr	r9
+	lis	r9,wr_control@ha
+	lwz	r9,wr_control@l(r9)
+	stw	r11,VB_CONTROL_SRR0(r9)
+	mfcr	r11
+	stw	r11,VB_CONTROL_CR(r9)
+	stw	r0,VB_CONTROL_R0(r9)
+
+	lis	r12,wr_status@ha
+	lwz	r12,wr_status@l(r12)
+
+	lwz	r11,VB_STATUS_OLD_INT_DISABLE(r12)
+	stw	r11,VB_CONTROL_NEW_INT_DISABLE(r9)
+
+#ifdef CONFIG_WRHV_ASID_OPTIMIZATION
+	/* Push the virtual ASID into the control struct */
+	lwz	r11,VB_STATUS_ASID(r12)
+	stw	r11,VB_CONTROL_ASID(r9)
+
+	/* Update the VMMU handle */
+	lwz	r11,VB_STATUS_VMMU_HANDLE(r12)
+	stw	r11,VB_CONTROL_VMMU_HANDLE(r9)
+
+	lwz	r11,VB_STATUS_VMMU0(r12)
+	stw	r11,VB_CONTROL_VMMU0(r9)
+#endif
+/*
+	lwz	r11,VB_STATUS_CR(r12)
+	stw	r11,VB_CONTROL_CR(r9)
+*/
+
+#ifdef VMMU
+        /* restore vmmu from wr_status to wr_control */
+
+	lwz	r11,VB_STATUS_VMMU0(r12)
+	stw	r11,VB_CONTROL_VMMU0(r9)
+
+	lwz	r11,VB_STATUS_VMMU1(r12)
+	stw	r11,VB_CONTROL_VMMU1(r9)
+
+	lwz	r11,VB_STATUS_EMSR(r12)
+	stw	r11,VB_CONTROL_EMSR(r9)
+
+	stw	r1,VB_CONTROL_SP(r9)
+	stw	r2,VB_CONTROL_R2(r9)
+	stw	r3,VB_CONTROL_R3(r9)
+	stw	r4,VB_CONTROL_R4(r9)
+	stw	r5,VB_CONTROL_R5(r9)
+	stw	r6,VB_CONTROL_R6(r9)
+	stw	r7,VB_CONTROL_R7(r9)
+	stw	r8,VB_CONTROL_R8(r9)
+	stw	r10,VB_CONTROL_R10(r9)
+	mflr	r11
+#endif
+
+	WRHV_LOAD_MSR(r10,r9,r11)
+
+	lis	r0,VBI_SYS_ctx_load@h
+	ori	r0,r0,VBI_SYS_ctx_load@l
+	sc
+
+#if defined (CONFIG_6xx) || defined(CONFIG_E500)
+4:	rlwinm	r12,r12,0,~_TLF_NAPPING
+	stw	r12,TI_LOCAL_FLAGS(r9)
+	b	power_save_ppc32_restore
+
+7:	rlwinm	r12,r12,0,~_TLF_SLEEPING
+	stw	r12,TI_LOCAL_FLAGS(r9)
+	lwz	r9,_MSR(r11)		/* if sleeping, clear MSR.EE */
+	rlwinm	r9,r9,0,~MSR_EE
+	lwz	r12,_LINK(r11)		/* and return to address in LR */
+	b	fast_exception_return
+#endif
+
+/*
+ * On kernel stack overflow, load up an initial stack pointer
+ * and call StackOverflow(regs), which should not return.
+ */
+paravirt_stack_ovf:
+	/* sometimes we use a statically-allocated stack, which is OK. */
+	lis	r12,_end@h
+	ori	r12,r12,_end@l
+	cmplw	r1,r12
+	ble	5b			/* r1 <= &_end is OK */
+	SAVE_NVGPRS(r11)
+	addi	r3,r1,STACK_FRAME_OVERHEAD
+	lis	r1,init_thread_union@ha
+	addi	r1,r1,init_thread_union@l
+	addi	r1,r1,THREAD_SIZE-STACK_FRAME_OVERHEAD
+	lis	r9,StackOverflow@ha
+	addi	r9,r9,StackOverflow@l
+	LOAD_MSR_KERNEL(r10,MSR_KERNEL)
+	WRHV_FIX_MSR(r10,r11)
+	b	StackOverflow
+#if 0
+	FIX_SRR1(r10,r12)
+	mtspr	SPRN_SRR0,r9
+	mtspr	SPRN_SRR1,r10
+	SYNC
+	RFI
+#endif
+
+
+	.globl	paravirt_ret_from_syscall
+paravirt_ret_from_syscall:
+#ifdef SHOW_SYSCALLS
+	bl	do_show_syscall_exit
+#endif
+	mr	r6,r3
+	rlwinm	r12,r1,0,0,(31-THREAD_SHIFT)	/* current_thread_info() */
+	/* disable interrupts so current_thread_info()->flags can't change */
+	WRHV_INT_LOCK(r10,r9)
+	lwz	r9,TI_FLAGS(r12)
+	li	r8,-_LAST_ERRNO
+	andi.	r0,r9,(_TIF_SYSCALL_T_OR_A|_TIF_SINGLESTEP|_TIF_USER_WORK_MASK|_TIF_PERSYSCALL_MASK)
+	bne-	syscall_exit_work
+	cmplw	0,r3,r8
+	blt+	paravirt_syscall_exit_cont
+	lwz	r11,_CCR(r1)			/* Load CR */
+	neg	r3,r3
+	oris	r11,r11,0x1000	/* Set SO bit in CR */
+	stw	r11,_CCR(r1)
+paravirt_syscall_exit_cont:
+#if defined(CONFIG_4xx) || defined(CONFIG_BOOKE)
+	/* If the process has its own DBCR0 value, load it up.  The internal
+	   debug mode bit tells us that dbcr0 should be loaded. */
+	lwz	r0,THREAD+THREAD_DBCR0(r2)
+	andis.	r10,r0,DBCR0_IDM@h
+	bnel-	load_dbcr0
+#endif
+#ifdef CONFIG_44x
+	lis	r4,icache_44x_need_flush@ha
+	lwz	r5,icache_44x_need_flush@l(r4)
+	cmplwi	cr0,r5,0
+	bne-	2f
+1:
+#endif /* CONFIG_44x */
+BEGIN_FTR_SECTION
+	lwarx	r7,0,r1
+END_FTR_SECTION_IFSET(CPU_FTR_NEED_PAIRED_STWCX)
+	stwcx.	r0,0,r1			/* to clear the reservation */
+	lwz	r4,_LINK(r1)
+	lwz	r5,_CCR(r1)
+	mtlr	r4
+	lis	r4,wr_control@ha
+	lwz	r4,wr_control@l(r4)
+	stw	r5,VB_CONTROL_CR(r4)
+	lwz	r5,GPR0(r1)
+	stw	r5,VB_CONTROL_R0(r4)
+	lwz	r5,_NIP(r1)
+	stw	r5,VB_CONTROL_SRR0(r4)
+
+	lis	r5,wr_status@ha
+	lwz	r5,wr_status@l(r5)
+	lwz	r5,VB_STATUS_OLD_INT_DISABLE(r5)
+	stw	r5,VB_CONTROL_NEW_INT_DISABLE(r4)
+ 
+	lwz	r5,_MSR(r1)
+	WRHV_LOAD_MSR(r5,r7,r8)
+	lwz	r2,GPR2(r1)
+	lwz	r1,GPR1(r1)
+	lis	r0,VBI_SYS_ctx_load@h
+	ori	r0,r0,VBI_SYS_ctx_load@l
+	sc
+
+66:	li	r3,-ENOSYS
+	b	paravirt_ret_from_syscall
+
+	.globl	paravirt_syscall_exit_work
+paravirt_syscall_exit_work:
+	andi.	r0,r9,_TIF_RESTOREALL
+	beq+	0f
+	REST_NVGPRS(r1)
+	b	2f
+0:	cmplw	0,r3,r8
+	blt+	1f
+	andi.	r0,r9,_TIF_NOERROR
+	bne-	1f
+	lwz	r11,_CCR(r1)			/* Load CR */
+	neg	r3,r3
+	oris	r11,r11,0x1000	/* Set SO bit in CR */
+	stw	r11,_CCR(r1)
+
+1:	stw	r6,RESULT(r1)	/* Save result */
+	stw	r3,GPR3(r1)	/* Update return value */
+2:	andi.	r0,r9,(_TIF_PERSYSCALL_MASK)
+	beq	4f
+
+	/* Clear per-syscall TIF flags if any are set.  */
+
+	li	r11,_TIF_PERSYSCALL_MASK
+	addi	r12,r12,TI_FLAGS
+3:	lwarx	r8,0,r12
+	andc	r8,r8,r11
+#ifdef CONFIG_IBM405_ERR77
+	dcbt	0,r12
+#endif
+	stwcx.	r8,0,r12
+	bne-	3b
+	subi	r12,r12,TI_FLAGS
+	
+4:	/* Anything which requires enabling interrupts? */
+	andi.	r0,r9,(_TIF_SYSCALL_T_OR_A|_TIF_SINGLESTEP)
+	beq	ret_from_except
+
+	/* Re-enable interrupts */
+	WRHV_INT_UNLOCK(r10,r4)
+
+	/* Save NVGPRS if they're not saved already */
+	lwz	r4,_TRAP(r1)
+	andi.	r4,r4,1
+	beq	5f
+	SAVE_NVGPRS(r1)
+	li	r4,0xc00
+	stw	r4,_TRAP(r1)
+5:
+	addi	r3,r1,STACK_FRAME_OVERHEAD
+	bl	do_syscall_trace_leave
+	b	ret_from_except_full
+
+
+/*
+ * This routine switches between two different tasks.  The process
+ * state of one is saved on its kernel stack.  Then the state
+ * of the other is restored from its kernel stack.  The memory
+ * management hardware is updated to the second process's state.
+ * Finally, we can return to the second process.
+ * On entry, r3 points to the THREAD for the current task, r4
+ * points to the THREAD for the new task.
+ *
+ * This routine is always called with interrupts disabled.
+ *
+ * Note: there are two ways to get to the "going out" portion
+ * of this code; either by coming in via the entry (_switch)
+ * or via "fork" which must set up an environment equivalent
+ * to the "_switch" path.  If you change this , you'll have to
+ * change the fork code also.
+ *
+ * The code which creates the new task context is in 'copy_thread'
+ * in arch/ppc/kernel/process.c
+ */
+_GLOBAL(paravirt_switch)
+	stwu	r1,-INT_FRAME_SIZE(r1)
+	mflr	r0
+	stw	r0,INT_FRAME_SIZE+4(r1)
+	/* r3-r12 are caller saved -- Cort */
+	SAVE_NVGPRS(r1)
+	stw	r0,_NIP(r1)	/* Return to switch caller */
+	LOAD_MSR_KERNEL(r11,MSR_KERNEL)
+	WRHV_FIX_MSR(r11,r10)
+#ifdef CONFIG_SPE
+BEGIN_FTR_SECTION
+	lis	r12,wr_status@ha
+	lwz	r12,wr_status@l(r12)
+	lwz	r12,VB_STATUS_SPEFSCR(r12)  /* save spefscr register value */
+	stw	r12,THREAD+THREAD_SPEFSCR(r2)
+END_FTR_SECTION_IFSET(CPU_FTR_SPE)
+#endif /* CONFIG_SPE */
+1:	stw	r11,_MSR(r1)
+	mfcr	r10
+	stw	r10,_CCR(r1)
+	stw	r1,KSP(r3)	/* Set old stack pointer */
+
+#ifdef CONFIG_SMP
+	/* We need a sync somewhere here to make sure that if the
+	 * previous task gets rescheduled on another CPU, it sees all
+	 * stores it has performed on this one.
+	 */
+	sync
+#endif /* CONFIG_SMP */
+
+	tophys(r0,r4)
+	CLR_TOP32(r0)
+	WRHV_MTSPRG3(r0,r3)
+	lwz	r1,KSP(r4)	/* Load new stack pointer */
+
+	/* save the old current 'last' for return value */
+	mr	r3,r2
+	addi	r2,r4,-THREAD	/* Update current */
+
+#ifdef CONFIG_SPE
+BEGIN_FTR_SECTION
+	lwz	r0,THREAD+THREAD_SPEFSCR(r2)
+	lis	r12,wr_control@ha
+	lwz	r12,wr_control@l(r12)
+	stw	r0,VB_CONTROL_SPEFSCR(r12)	/* restore SPEFSCR reg */
+END_FTR_SECTION_IFSET(CPU_FTR_SPE)
+#endif /* CONFIG_SPE */
+
+	lwz	r0,_CCR(r1)
+	mtcrf	0xFF,r0
+	/* r3-r12 are destroyed -- Cort */
+	REST_NVGPRS(r1)
+
+	lwz	r4,_NIP(r1)	/* Return to _switch caller in new task */
+	mtlr	r4
+	addi	r1,r1,INT_FRAME_SIZE
+	blr
+
+
+	/* interrupts are hard-disabled at this point */
+	.globl	paravirt_restore
+paravirt_restore:
+#ifdef	CONFIG_WRHV
+	lis	r4,wr_control@ha
+	lwz	r4,wr_control@l(r4)
+	lwz	r0,GPR0(r1)
+	stw	r0,VB_CONTROL_R0(r4)
+	lwz	r2,GPR2(r1)
+	lwz	r3,GPR3(r1)
+	lwz	r6,GPR6(r1)
+	lwz	r7,GPR7(r1)
+	lwz	r8,GPR8(r1)
+	lwz	r9,GPR9(r1)
+	lwz	r10,GPR10(r1)
+	lwz	r11,GPR11(r1)
+
+	lis	r12,wr_status@ha
+	lwz	r12,wr_status@l(r12)
+	lwz	r5,VB_STATUS_OLD_INT_DISABLE(r12)
+	stw	r5,VB_CONTROL_NEW_INT_DISABLE(r4)
+
+#ifdef VMMU
+	stw	r2,VB_CONTROL_R2(r4)
+	stw	r3,VB_CONTROL_R3(r4)
+	stw	r6,VB_CONTROL_R6(r4)
+	stw	r7,VB_CONTROL_R7(r4)
+	stw	r8,VB_CONTROL_R8(r4)
+	stw	r9,VB_CONTROL_R9(r4)
+	stw	r10,VB_CONTROL_R10(r4)
+	stw	r11,VB_CONTROL_R11(r4)
+#endif /* VMMU */
+	lwz	r0,_CCR(r1)
+	stw	r0,VB_CONTROL_CR(r4)
+	lwz	r0,_NIP(r1)
+	stw	r0,VB_CONTROL_SRR0(r4)
+	lwz	r0,_LINK(r1)
+	mtlr	r0
+	lwz	r0,_XER(r1)
+	mtspr	SPRN_XER,r0
+	lwz	r0,_CTR(r1)
+	mtctr	r0
+	lwz	r0,_MSR(r1)
+	WRHV_LOAD_MSR(r0,r12,r5)
+	lwz	r12,GPR12(r1)
+	lwz	r5,GPR5(r1)
+#ifdef VMMU
+	stw	r12,VB_CONTROL_R12(r4)
+	stw	r5,VB_CONTROL_R5(r4)
+
+	lwz	r5,GPR1(r1)
+	stw	r5,VB_CONTROL_R1(r4)
+
+	lwz	r5,GPR4(r1)
+	stw	r5,VB_CONTROL_R4(r4)
+
+	lis	r12,wr_status@ha
+	lwz	r12,wr_status@l(r12)
+
+	lwz	r5,VB_STATUS_EMSR(r12)
+	stw	r5,VB_CONTROL_EMSR(r4)
+
+#if 1
+        /* resume VMMU, since we always turn VMMU back on during the
+         * exception entrance, this is really not needed, but we
+         * make them here anyway for consistency
+         */
+	lwz	r5,VB_STATUS_VMMU0(r12)
+	stw	r5,VB_CONTROL_VMMU0(r4)
+
+	lwz	r5,VB_STATUS_VMMU1(r12)
+	stw	r5,VB_CONTROL_VMMU1(r4)
+#endif
+
+	lis	r0,VBI_SYS_ctx_load_vmmu@h
+	ori	r0,r0,VBI_SYS_ctx_load_vmmu@l
+#else
+	lwz	r4,GPR4(r1)
+	lwz	r1,GPR1(r1)
+	lis	r0,VBI_SYS_ctx_load@h
+	ori	r0,r0,VBI_SYS_ctx_load@l
+	sc
+#endif  /* VMMU */
+
+	/* Never back from here */
+#endif /* CONFIG_WRHV */
+
+	.globl  paravirt_load_dbcr0
+paravirt_load_dbcr0:
+	lis	r9,wr_control@ha
+	lwz	r9,wr_control@l(r9)
+	lwz	r10,VB_CONTROL_DBCR0(r9)
+	lis	r11,global_dbcr0@ha
+	addi	r11,r11,global_dbcr0@l
+#ifdef CONFIG_SMP
+	rlwinm	r9,r1,0,0,(31-THREAD_SHIFT)
+	lwz	r9,TI_CPU(r9)
+	slwi	r9,r9,3
+	add 	r11,r11,r9
+#endif
+	stw	r10,0(r11)
+	lis	r9,wr_control@ha
+	lwz	r9,wr_control@l(r9)
+	stw	r0,VB_CONTROL_DBCR0(r9)
+	lwz	r10,4(r11)
+	addi	r10,r10,1
+	stw	r10,4(r11)
+	li	r11,-1
+	/* clear all pending debug events */
+	lis	r9,wr_control@ha
+	lwz	r9,wr_control@l(r9)
+	stw	r11,VB_CONTROL_DBSR(r9)
+	blr
+
diff --git a/arch/powerpc/kernel/wrhv_misc_32.S b/arch/powerpc/kernel/wrhv_misc_32.S
new file mode 100644
index 0000000..79a84b3
--- /dev/null
+++ b/arch/powerpc/kernel/wrhv_misc_32.S
@@ -0,0 +1,74 @@
+/*
+ * Low level asm functions for guest implementation on powerpc
+ * 
+ * Copyright (c) 2009 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ *
+ */
+
+#include <linux/sys.h>
+#include <asm/unistd.h>
+#include <asm/errno.h>
+#include <asm/reg.h>
+#include <asm/page.h>
+#include <asm/cache.h>
+#include <asm/cputable.h>
+#include <asm/mmu.h>
+#include <asm/ppc_asm.h>
+#include <asm/thread_info.h>
+#include <asm/asm-offsets.h>
+#include <asm/processor.h>
+#include <vbi/interface.h>
+#include <vbi/syscalls.h>
+#include <asm/wrhv.h>
+
+	.text
+
+	.align	5
+_GLOBAL(wrhv_int_lock)
+	WRHV_INT_LOCK(r4,r5)
+	blr
+
+_GLOBAL(wrhv_int_lvl_get)
+	WRHV_INT_LVL_GET(r3)
+	blr
+
+_GLOBAL(wrhv_int_unlock)
+	WRHV_INT_UNLOCK(r3,r4)
+	blr
+
+/*
+ * Write any modified data cache blocks out to memory.
+ * Does not invalidate the corresponding data cache lines
+ *
+ * paravirt_clean_dcache_range(unsigned long start, unsigned long stop)
+ */
+#ifdef CONFIG_PARAVIRT_DCACHE_CLEAN
+_GLOBAL(paravirt_clean_dcache_range)
+	/*
+	 * vbi_flush_dcache (void *start_addr, void *end_addr)
+	 */
+	#li	r5, 8
+	subf	r4,r3,r4
+	addi	r4, r4, 1
+	bl	vbi_flush_dcache
+	blr
+#endif
+
+_GLOBAL(paravirt__flush_dcache_icache)
+	b	vb__flush_dcache_icache
+
+_GLOBAL(paravirt_flush_dcache_range)
+	b	vb_flush_dcache_range
+
+_GLOBAL(paravirt__flush_icache_range)
+	b	vb__flush_icache_range
+
+_GLOBAL(paravirt__flush_dcache_icache_phys)
+	b	vb__flush_dcache_icache_phys
+
+
diff --git a/arch/powerpc/kvm/Kconfig b/arch/powerpc/kvm/Kconfig
index 60624cc..92c27fa 100644
--- a/arch/powerpc/kvm/Kconfig
+++ b/arch/powerpc/kvm/Kconfig
@@ -16,6 +16,34 @@ menuconfig VIRTUALIZATION
 
 if VIRTUALIZATION
 
+config PARAVIRT
+        bool "Enable paravirtualization code"
+        default y
+        help
+          This changes the kernel so it can modify itself when it is run
+          under a hypervisor, potentially improving performance significantly
+          over full virtualization.  However, when run without a hypervisor
+          the kernel is theoretically slower and slightly larger.
+
+          CONFIG_PARAVIRT assume a E500 like core.
+
+config PARAVIRT_PTE
+        bool "Enable 64 Bit PTE to support VMMU"
+        default n
+        help
+          CONFIG_PARAVIRT will use 64 bit PTE for VMMU.
+
+config PARAVIRT_CLOCK
+        bool
+        default n
+
+config PARAVIRT_DEBUG
+       bool "paravirt-ops debugging"
+       depends on PARAVIRT && DEBUG_KERNEL
+       help
+         Enable to debug paravirt_ops internals.  Specifically, BUG if
+         a paravirt_op is missing when it is called.
+
 config KVM
 	bool
 	select PREEMPT_NOTIFIERS
diff --git a/arch/powerpc/mm/Makefile b/arch/powerpc/mm/Makefile
index ce68708..d0d522f 100644
--- a/arch/powerpc/mm/Makefile
+++ b/arch/powerpc/mm/Makefile
@@ -11,8 +11,14 @@ endif
 obj-y				:= fault.o mem.o pgtable.o gup.o \
 				   init_$(CONFIG_WORD_SIZE).o \
 				   pgtable_$(CONFIG_WORD_SIZE).o
-obj-$(CONFIG_PPC_MMU_NOHASH)	+= mmu_context_nohash.o tlb_nohash.o \
-				   tlb_nohash_low.o
+obj-$(CONFIG_PPC_MMU_NOHASH)	+= mmu_context_nohash.o tlb_nohash.o 
+
+ifeq ($(CONFIG_WRHV),y)
+obj-$(CONFIG_PPC_MMU_NOHASH)	+= wrhv_tlb_nohash_low.o
+else
+obj-$(CONFIG_PPC_MMU_NOHASH)	+= tlb_nohash_low.o
+endif
+
 obj-$(CONFIG_PPC_BOOK3E)	+= tlb_low_$(CONFIG_WORD_SIZE)e.o
 obj-$(CONFIG_PPC64)		+= mmap_64.o
 hash64-$(CONFIG_PPC_NATIVE)	:= hash_native_64.o
diff --git a/arch/powerpc/mm/fault.c b/arch/powerpc/mm/fault.c
index dcc1720..abb333e 100644
--- a/arch/powerpc/mm/fault.c
+++ b/arch/powerpc/mm/fault.c
@@ -69,6 +69,24 @@ static inline int notify_page_fault(struct pt_regs *regs)
 #endif
 
 /*
+ * this function restore mmu for paravirt operations,
+ * default native operation is noop
+ */
+void paravirt_vmmu_restore(void) __attribute__((weak, alias("native_vmmu_restore")));
+
+void native_vmmu_restore(void)
+{
+	/* default is noop */
+	return;
+}
+
+void vmmu_restore (void)
+{
+	paravirt_vmmu_restore();
+	return;
+}
+
+/*
  * Check whether the instruction at regs->nip is a store using
  * an update addressing form which will update r1.
  */
@@ -348,6 +366,7 @@ bad_area_nosemaphore:
 	/* User mode accesses cause a SIGSEGV */
 	if (user_mode(regs)) {
 		_exception(SIGSEGV, regs, code, address);
+		vmmu_restore ();
 		return 0;
 	}
 
@@ -383,6 +402,7 @@ do_sigbus:
 		info.si_code = BUS_ADRERR;
 		info.si_addr = (void __user *)address;
 		force_sig_info(SIGBUS, &info, current);
+		vmmu_restore ();
 		return 0;
 	}
 	return SIGBUS;
diff --git a/arch/powerpc/mm/fsl_booke_mmu.c b/arch/powerpc/mm/fsl_booke_mmu.c
index 12a7d8e..21b549d 100644
--- a/arch/powerpc/mm/fsl_booke_mmu.c
+++ b/arch/powerpc/mm/fsl_booke_mmu.c
@@ -184,19 +184,36 @@ unsigned long map_mem_in_cams(unsigned long ram, int max_cam_idx)
 	return amount_mapped;
 }
 
-unsigned long __init mmu_mapin_ram(unsigned long top)
+unsigned long paravirt_mmu_mapin_ram(unsigned long top) 
+	__attribute__((weak, alias("native_mmu_mapin_ram")));
+
+unsigned long native_mmu_mapin_ram(unsigned long top)
 {
 	return tlbcam_addrs[tlbcam_index - 1].limit - PAGE_OFFSET + 1;
 }
 
+unsigned long __init mmu_mapin_ram(unsigned long top)
+{
+	return paravirt_mmu_mapin_ram(top);
+}
+
 /*
  * MMU_init_hw does the chip-specific initialization of the MMU hardware.
  */
-void __init MMU_init_hw(void)
+
+void paravirt_MMU_init_hw(void) 
+	__attribute__((weak, alias("native_MMU_init_hw")));
+
+void __init native_MMU_init_hw(void)
 {
 	flush_instruction_cache();
 }
 
+void __init MMU_init_hw(void)
+{
+	paravirt_MMU_init_hw();
+}
+
 void __init adjust_total_lowmem(void)
 {
 	unsigned long ram;
diff --git a/arch/powerpc/mm/init_32.c b/arch/powerpc/mm/init_32.c
index 7673330..591178d 100644
--- a/arch/powerpc/mm/init_32.c
+++ b/arch/powerpc/mm/init_32.c
@@ -100,7 +100,10 @@ phys_addr_t __initial_memory_limit_addr = (phys_addr_t)0x10000000;
 /*
  * Check for command-line options that affect what MMU_init will do.
  */
-void MMU_setup(void)
+void paravirt_MMU_setup(void) 
+	__attribute__((weak, alias("native_MMU_setup")));
+
+void native_MMU_setup(void)
 {
 	/* Check for nobats option (used in mapin_ram). */
 	if (strstr(cmd_line, "nobats")) {
@@ -116,12 +119,20 @@ void MMU_setup(void)
 #endif
 }
 
+void MMU_setup(void)
+{
+	paravirt_MMU_setup();
+}
+
 /*
  * MMU_init sets up the basic memory mappings for the kernel,
  * including both RAM and possibly some I/O regions,
  * and sets up the page tables and the MMU hardware ready to go.
  */
-void __init MMU_init(void)
+void paravirt_MMU_init(void) 
+	__attribute__((weak, alias("native_MMU_init")));
+
+void __init native_MMU_init(void)
 {
 	if (ppc_md.progress)
 		ppc_md.progress("MMU:enter", 0x111);
@@ -149,12 +160,12 @@ void __init MMU_init(void)
 	total_lowmem = total_memory = lmb_end_of_DRAM() - memstart_addr;
 	lowmem_end_addr = memstart_addr + total_lowmem;
 
-#ifdef CONFIG_FSL_BOOKE
+#if defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT)
 	/* Freescale Book-E parts expect lowmem to be mapped by fixed TLB
 	 * entries, so we need to adjust lowmem to match the amount we can map
 	 * in the fixed entries */
 	adjust_total_lowmem();
-#endif /* CONFIG_FSL_BOOKE */
+#endif /* CONFIG_FSL_BOOKE && !defined(CONFIG_PARAVIRT) */
 
 	if (total_lowmem > __max_low_memory) {
 		total_lowmem = __max_low_memory;
@@ -192,6 +203,11 @@ void __init MMU_init(void)
 #endif
 }
 
+void __init MMU_init(void)
+{
+	paravirt_MMU_init();
+}
+
 /* This is only called until mem_init is done. */
 void __init *early_get_page(void)
 {
diff --git a/arch/powerpc/mm/mem.c b/arch/powerpc/mm/mem.c
index 0f594d7..748eaa5 100644
--- a/arch/powerpc/mm/mem.c
+++ b/arch/powerpc/mm/mem.c
@@ -413,7 +413,11 @@ void __init mem_init(void)
  * It just marks the page as not i-cache clean.  We do the i-cache
  * flush later when the page is given to a user process, if necessary.
  */
-void flush_dcache_page(struct page *page)
+
+void paravirt_flush_dcache_page(struct page *page) 
+               __attribute__((weak, alias("native_flush_dcache_page")));
+
+void native_flush_dcache_page(struct page *page)
 {
 	if (cpu_has_feature(CPU_FTR_COHERENT_ICACHE))
 		return;
@@ -421,6 +425,11 @@ void flush_dcache_page(struct page *page)
 	if (test_bit(PG_arch_1, &page->flags))
 		clear_bit(PG_arch_1, &page->flags);
 }
+
+void flush_dcache_page(struct page *page)
+{
+	paravirt_flush_dcache_page(page);
+}
 EXPORT_SYMBOL(flush_dcache_page);
 
 void flush_dcache_icache_page(struct page *page)
diff --git a/arch/powerpc/mm/mmu_context_nohash.c b/arch/powerpc/mm/mmu_context_nohash.c
index 1f2d9ff..cfad922 100644
--- a/arch/powerpc/mm/mmu_context_nohash.c
+++ b/arch/powerpc/mm/mmu_context_nohash.c
@@ -62,7 +62,6 @@ static DEFINE_RAW_SPINLOCK(context_lock);
 #define CTX_MAP_SIZE	\
 	(sizeof(unsigned long) * (last_context / BITS_PER_LONG + 1))
 
-
 /* Steal a context from a task that has one at the moment.
  *
  * This is used when we are running out of available PID numbers
@@ -136,7 +135,7 @@ static unsigned int steal_context_smp(unsigned int id)
  * this to work, we somewhat assume that CPUs that are onlined
  * come up with a fully clean TLB (or are cleaned when offlined)
  */
-static unsigned int steal_context_up(unsigned int id)
+unsigned int steal_context_up(unsigned int id)
 {
 	struct mm_struct *mm;
 	int cpu = smp_processor_id();
@@ -157,6 +156,7 @@ static unsigned int steal_context_up(unsigned int id)
 
 	return id;
 }
+EXPORT_SYMBOL(steal_context_up);
 
 #ifdef DEBUG_MAP_CONSISTENCY
 static void context_check_map(void)
@@ -189,8 +189,15 @@ static void context_check_map(void)
 static void context_check_map(void) { }
 #endif
 
+void paravirt_switch_mmu_context(struct mm_struct *prev, struct mm_struct *next)
+	__attribute__((weak, alias("native_switch_mmu_context")));
 void switch_mmu_context(struct mm_struct *prev, struct mm_struct *next)
 {
+	paravirt_switch_mmu_context(prev, next);
+}
+
+void native_switch_mmu_context(struct mm_struct *prev, struct mm_struct *next)
+{
 	unsigned int i, id, cpu = smp_processor_id();
 	unsigned long *map;
 
@@ -279,14 +286,22 @@ void switch_mmu_context(struct mm_struct *prev, struct mm_struct *next)
 	/* Flick the MMU and release lock */
 	pr_hardcont(" -> %d\n", id);
 	set_context(id, next->pgd);
+
 	raw_spin_unlock(&context_lock);
 }
 
 /*
  * Set up the context for a new address space.
  */
+int paravirt_init_new_context(struct task_struct *t, struct mm_struct *mm)
+	__attribute__((weak, alias("native_init_new_context")));
 int init_new_context(struct task_struct *t, struct mm_struct *mm)
 {
+	return paravirt_init_new_context(t, mm);
+}
+
+int native_init_new_context(struct task_struct *t, struct mm_struct *mm)
+{
 	pr_hard("initing context for mm @%p\n", mm);
 
 	mm->context.id = MMU_NO_CONTEXT;
@@ -298,8 +313,15 @@ int init_new_context(struct task_struct *t, struct mm_struct *mm)
 /*
  * We're finished using the context for an address space.
  */
+void paravirt_destroy_context(struct mm_struct *mm)
+	__attribute__((weak, alias("native_destroy_context")));
 void destroy_context(struct mm_struct *mm)
 {
+	paravirt_destroy_context(mm);
+}
+
+void native_destroy_context(struct mm_struct *mm)
+{
 	unsigned long flags;
 	unsigned int id;
 
@@ -372,8 +394,15 @@ static struct notifier_block __cpuinitdata mmu_context_cpu_nb = {
 /*
  * Initialize the context management stuff.
  */
+void paravirt_mmu_context_init(void)
+	__attribute__((weak, alias("native_mmu_context_init")));
 void __init mmu_context_init(void)
 {
+	paravirt_mmu_context_init();
+}
+
+void __init native_mmu_context_init(void)
+{
 	/* Mark init_mm as being active on all possible CPUs since
 	 * we'll get called with prev == init_mm the first time
 	 * we schedule on a given CPU
diff --git a/arch/powerpc/mm/mmu_decl.h b/arch/powerpc/mm/mmu_decl.h
index 0591f25..7877b32 100644
--- a/arch/powerpc/mm/mmu_decl.h
+++ b/arch/powerpc/mm/mmu_decl.h
@@ -134,10 +134,28 @@ extern unsigned long wii_mmu_mapin_mem2(unsigned long top);
 extern void wii_memory_fixups(void);
 #endif
 
+#if defined(CONFIG_FSL_BOOKE)
+
+struct tlbcam {
+	u32	MAS0;
+	u32	MAS1;
+	unsigned long	MAS2;
+	u32	MAS3;
+	u32	MAS7;
+};
+extern void loadcam_entry(unsigned int index);
+
+#endif
+
 /* ...and now those things that may be slightly different between processor
  * architectures.  -- Dan
  */
-#if defined(CONFIG_8xx)
+#if defined(CONFIG_PARAVIRT)
+
+extern void MMU_init_hw(void);
+extern unsigned long mmu_mapin_ram(unsigned long top);
+
+#elif defined(CONFIG_8xx)
 #define MMU_init_hw()		do { } while(0)
 #define mmu_mapin_ram(top)	(0UL)
 
@@ -145,19 +163,12 @@ extern void wii_memory_fixups(void);
 extern void MMU_init_hw(void);
 extern unsigned long mmu_mapin_ram(unsigned long top);
 
-#elif defined(CONFIG_FSL_BOOKE)
+#elif defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT)
 extern void MMU_init_hw(void);
 extern unsigned long mmu_mapin_ram(unsigned long top);
 extern void adjust_total_lowmem(void);
-extern void loadcam_entry(unsigned int index);
 
-struct tlbcam {
-	u32	MAS0;
-	u32	MAS1;
-	unsigned long	MAS2;
-	u32	MAS3;
-	u32	MAS7;
-};
+
 #elif defined(CONFIG_PPC32)
 /* anything 32-bit except 4xx or 8xx */
 extern void MMU_init_hw(void);
diff --git a/arch/powerpc/mm/pgtable_32.c b/arch/powerpc/mm/pgtable_32.c
index 767b0cf..ed3838c 100644
--- a/arch/powerpc/mm/pgtable_32.c
+++ b/arch/powerpc/mm/pgtable_32.c
@@ -44,7 +44,7 @@ EXPORT_SYMBOL(ioremap_bot);	/* aka VMALLOC_END */
 #define HAVE_BATS	1
 #endif
 
-#if defined(CONFIG_FSL_BOOKE)
+#if defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT)
 #define HAVE_TLBCAM	1
 #endif
 
@@ -158,12 +158,24 @@ ioremap_flags(phys_addr_t addr, unsigned long size, unsigned long flags)
 }
 EXPORT_SYMBOL(ioremap_flags);
 
-void __iomem *
-__ioremap(phys_addr_t addr, unsigned long size, unsigned long flags)
+void __iomem * paravirt___ioremap(phys_addr_t addr, unsigned long size, unsigned long flags)
+               __attribute__((weak, alias("native___ioremap")));
+
+/* Native __ioremap implementation. For paravirt version please 
+ * refer to arch/powerpc/kernel/vbi/wrhv.c 
+ */
+void __iomem * 
+native___ioremap(phys_addr_t addr, unsigned long size, unsigned long flags)
 {
 	return __ioremap_caller(addr, size, flags, __builtin_return_address(0));
 }
 
+void __iomem * 
+__ioremap(phys_addr_t addr, unsigned long size, unsigned long flags) 
+{
+	return paravirt___ioremap(addr, size, flags);
+}
+
 void __iomem *
 __ioremap_caller(phys_addr_t addr, unsigned long size, unsigned long flags,
 		 void *caller)
@@ -270,7 +282,10 @@ void iounmap(volatile void __iomem *addr)
 }
 EXPORT_SYMBOL(iounmap);
 
-int map_page(unsigned long va, phys_addr_t pa, int flags)
+int paravirt_map_page(unsigned long, phys_addr_t, int) 
+	__attribute__((weak, alias("native_map_page")));
+
+int native_map_page(unsigned long va, phys_addr_t pa, int flags)
 {
 	pmd_t *pd;
 	pte_t *pg;
@@ -293,6 +308,15 @@ int map_page(unsigned long va, phys_addr_t pa, int flags)
 	return err;
 }
 
+int map_page(unsigned long va, phys_addr_t pa, int flags)
+{
+	return paravirt_map_page(va, pa, flags);
+}
+
+#ifdef CONFIG_PARAVIRT
+EXPORT_SYMBOL(map_page);
+#endif
+
 /*
  * Map in a chunk of physical memory starting at start.
  */
diff --git a/arch/powerpc/mm/wrhv_tlb_nohash_low.S b/arch/powerpc/mm/wrhv_tlb_nohash_low.S
new file mode 100644
index 0000000..a4213b5
--- /dev/null
+++ b/arch/powerpc/mm/wrhv_tlb_nohash_low.S
@@ -0,0 +1,210 @@
+/*
+ * This file contains low-level functions for performing various
+ * types of TLB invalidations on various processors with no hash
+ * table.
+ *
+ * This file implements the following functions for all no-hash
+ * processors. Some aren't implemented for some variants. Some
+ * are inline in tlbflush.h
+ *
+ *	- tlbil_va
+ *	- tlbil_pid
+ *	- tlbil_all
+ *	- tlbivax_bcast (not yet)
+ *
+ * Copyright (C) 2009-2010 Wind River Systems, Inc.
+ *
+ * Partially rewritten by Cort Dougan (cort@cs.nmt.edu)
+ * Paul Mackerras, Kumar Gala and Benjamin Herrenschmidt.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ *
+ */
+
+#include <asm/reg.h>
+#include <asm/page.h>
+#include <asm/cputable.h>
+#include <asm/mmu.h>
+#include <asm/ppc_asm.h>
+#include <asm/asm-offsets.h>
+#include <asm/processor.h>
+
+#if defined(CONFIG_WRHV_E500) && !defined(CONFIG_PPC85xx_VT_MODE)
+_GLOBAL(_tlbil_all)
+_GLOBAL(_tlbil_pid)
+_GLOBAL(__tlbil_va)
+	lis     r0, VBI_SYS_tlb_flush@h
+	ori     r0, r0, VBI_SYS_tlb_flush@l
+	sc
+	blr
+
+#elif defined(CONFIG_FSL_BOOKE) && defined(CONFIG_PPC85xx_VT_MODE)
+/*
+ * FSL BookE implementations on Wind River HY.
+ *
+ * Since feature sections are using _SECTION_ELSE we need
+ * to have the larger code path before the _SECTION_ELSE
+ */
+
+#define TLBWE_CODE	0x7C0007A4
+#define TLBSX_CODE	0x7c005724
+
+/*
+ * Flush MMU TLB on the local processor
+ */
+_GLOBAL(_tlbil_all)
+BEGIN_MMU_FTR_SECTION
+	li	r3,(MMUCSR0_TLBFI)@l
+	mtspr	SPRN_MMUCSR0, r3
+1:
+	mfspr	r3,SPRN_MMUCSR0
+	andi.	r3,r3,MMUCSR0_TLBFI@l
+	bne	1b
+MMU_FTR_SECTION_ELSE
+	PPC_TLBILX_ALL(0,0)
+ALT_MMU_FTR_SECTION_END_IFCLR(MMU_FTR_USE_TLBILX)
+	msync
+	isync
+	blr
+
+_GLOBAL(_tlbil_pid)
+BEGIN_MMU_FTR_SECTION
+	slwi	r3,r3,16
+	mfmsr	r10
+	wrteei	0
+	mfspr	r4,SPRN_MAS6	/* save MAS6 */
+	mtspr	SPRN_MAS6,r3
+	PPC_TLBILX_PID(0,0)
+	mtspr	SPRN_MAS6,r4	/* restore MAS6 */
+	wrtee	r10
+	/* When enable EE we check if the pending interrupt 
+	 * should be handled.
+	 */
+	rlwinm.	r10,r10,0,16,16;	/* test EE bit */
+	beq	2f
+	mr	r10,r0
+	lis	r0,VBI_SYS_int_enable@h;
+	ori	r0,r0,VBI_SYS_int_enable@l;
+	sc	1
+	mr	r0,r10
+2:
+MMU_FTR_SECTION_ELSE
+	li	r3,(MMUCSR0_TLBFI)@l
+	mtspr	SPRN_MMUCSR0, r3
+1:
+	mfspr	r3,SPRN_MMUCSR0
+	andi.	r3,r3,MMUCSR0_TLBFI@l
+	bne	1b
+ALT_MMU_FTR_SECTION_END_IFSET(MMU_FTR_USE_TLBILX)
+	msync
+	isync
+	blr
+
+/*
+ * Flush MMU TLB for a particular address, but only on the local processor
+ * (no broadcast)
+ */
+_GLOBAL(__tlbil_va)
+	mfmsr	r10
+	wrteei	0
+	
+	/* Save r3 and r4 */
+	mr	r11,r3
+	mr	r12,r4
+
+	/* Invalidate AS = 1 */
+	slwi	r4,r4,16
+	ori	r4,r4,(MAS6_ISIZE(BOOK3E_PAGESZ_4K))@l
+	ori	r4,r4,MAS6_SAS
+	mtspr	SPRN_MAS6,r4		/* assume AS=1 for now */
+
+inv:
+BEGIN_MMU_FTR_SECTION
+	/* The HY will check which privileged instruction trap privileged
+	 * exception via r3.
+	 */
+	mr	r4,r3
+	lis	r3,TLBSX_CODE@h
+	ori	r3,r3,TLBSX_CODE@l
+	tlbsx	0,r4
+	mr	r3,r4
+	mfspr	r4,SPRN_MAS1		/* check valid */
+	andis.	r3,r4,MAS1_VALID@h
+	beq	1f
+	rlwinm	r4,r4,0,1,31
+	mtspr	SPRN_MAS1,r4
+
+	/* The HY will check which privileged instruction trap privileged 
+	 * exception via r3. 
+	 */
+	mr	r4,r3
+	lis	r3,TLBWE_CODE@h
+	ori	r3,r3,TLBWE_CODE@l
+	tlbwe
+	mr	r3,r4
+MMU_FTR_SECTION_ELSE
+	PPC_TLBILX_VA(0,r3)
+ALT_MMU_FTR_SECTION_END_IFCLR(MMU_FTR_USE_TLBILX)
+	msync
+	isync
+	
+	/* Check if already invalidated AS = 0 */
+	mfspr	r5,SPRN_MAS6
+	rlwinm.	r5,r5,0,31,31
+	beq	1f
+
+	/* Invalidate AS = 0 */
+	mr	r3,r11
+	mr	r4,r12
+	slwi	r4,r4,16
+	ori	r4,r4,(MAS6_ISIZE(BOOK3E_PAGESZ_4K))@l
+	mtspr	SPRN_MAS6,r4		/* assume AS=0 for now */
+	b	inv
+
+1:	wrtee	r10
+	/* When enable EE we check if the pending interrupt 
+	 * should be handled. 
+	 */
+	rlwinm.	r10,r10,0,16,16;	/* test EE bit */       
+	beq	2f
+	mr	r10,r0
+	lis	r0,VBI_SYS_int_enable@h;
+	ori	r0,r0,VBI_SYS_int_enable@l;
+	sc	1
+	mr	r0,r10
+2:
+	blr
+#else
+#error Unsupported processor type !
+#endif
+
+#if defined(CONFIG_FSL_BOOKE)
+/*
+ * extern void loadcam_entry(unsigned int index)
+ *
+ * Load TLBCAM[index] entry in to the L2 CAM MMU
+ */
+_GLOBAL(loadcam_entry)
+	LOAD_REG_ADDR(r4, TLBCAM)
+	mulli	r5,r3,TLBCAM_SIZE
+	add	r3,r5,r4
+	lwz	r4,TLBCAM_MAS0(r3)
+	mtspr	SPRN_MAS0,r4
+	lwz	r4,TLBCAM_MAS1(r3)
+	mtspr	SPRN_MAS1,r4
+	PPC_LL	r4,TLBCAM_MAS2(r3)
+	mtspr	SPRN_MAS2,r4
+	lwz	r4,TLBCAM_MAS3(r3)
+	mtspr	SPRN_MAS3,r4
+BEGIN_MMU_FTR_SECTION
+	lwz	r4,TLBCAM_MAS7(r3)
+	mtspr	SPRN_MAS7,r4
+END_MMU_FTR_SECTION_IFSET(MMU_FTR_BIG_PHYS)
+	isync
+	tlbwe
+	isync
+	blr
+#endif
diff --git a/arch/powerpc/platforms/85xx/Kconfig b/arch/powerpc/platforms/85xx/Kconfig
index 08fab45..e2fcc40 100644
--- a/arch/powerpc/platforms/85xx/Kconfig
+++ b/arch/powerpc/platforms/85xx/Kconfig
@@ -165,10 +165,29 @@ config P4080_DS
 	help
 	  This option enables support for the P4080 DS board
 
+config WRHV_E500
+	bool
+
 config FSL_85XX_CACHE_SRAM
 	bool
 	select PPC_LIB_RHEAP
 
+config WRHV_P4080DS
+	bool "WindRiver QorIQ WRHV-P4080"
+	depends on WRHV
+	select PPC_FSL_BOOK3E
+	select PPC_E500MC
+	select SWIOTLB
+	select MPC8xxx_GPIO
+	select HAS_RAPIDIO
+	select HAS_FSL_PAMU
+	select PPC85xx_VT_MODE
+	help
+	  This option enables support for the P4080 DS board on Wind River Hypervisor.
+
+config PPC85xx_VT_MODE
+	bool
+
 endif # FSL_SOC_BOOKE
 
 config TQM85xx
diff --git a/arch/powerpc/platforms/85xx/Makefile b/arch/powerpc/platforms/85xx/Makefile
index 886c93c..efabc7d 100644
--- a/arch/powerpc/platforms/85xx/Makefile
+++ b/arch/powerpc/platforms/85xx/Makefile
@@ -20,4 +20,5 @@ obj-$(CONFIG_SBC8548)     += sbc8548.o
 obj-$(CONFIG_SOCRATES)    += socrates.o socrates_fpga_pic.o
 obj-$(CONFIG_KSI8560)	  += ksi8560.o
 obj-$(CONFIG_XES_MPC85xx) += xes_mpc85xx.o
+obj-$(CONFIG_WRHV_P4080DS)    += wrhv_p4080_ds.o corenet_ds_mdio.o
 obj-$(CONFIG_FSL_PMC)     += uli8259_suspend.o
diff --git a/arch/powerpc/platforms/85xx/wrhv_p4080_ds.c b/arch/powerpc/platforms/85xx/wrhv_p4080_ds.c
new file mode 100644
index 0000000..6391416
--- /dev/null
+++ b/arch/powerpc/platforms/85xx/wrhv_p4080_ds.c
@@ -0,0 +1,331 @@
+/*
+ * P4080 DS Setup
+ *
+ * Copyright (C) 2009-2010 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ */
+
+#include <linux/kernel.h>
+#include <linux/pci.h>
+#include <linux/kdev_t.h>
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/phy.h>
+#include <linux/lmb.h>
+
+#include <asm/system.h>
+#include <asm/time.h>
+#include <asm/machdep.h>
+#include <asm/pci-bridge.h>
+#include <mm/mmu_decl.h>
+#include <asm/prom.h>
+#include <asm/udbg.h>
+#include <asm/mpic.h>
+
+#include <linux/of_platform.h>
+#include <sysdev/fsl_soc.h>
+#include <sysdev/fsl_pci.h>
+
+#include <asm/wrhv.h>
+#include <vbi/vbi.h>
+
+extern struct vb_config *wr_config;
+extern struct vb_status *wr_status;
+extern struct vb_control *wr_control;
+extern int wrhv_set_law_base(int index, unsigned long long addr);
+extern int wrhv_set_law_attr(int index, unsigned int attr);
+extern int wrhv_get_law_attr(int index);
+
+static void __init wrhv_mpc85xx_pic_init(void)
+{
+	wrhv_init_irq();
+}
+
+#ifdef CONFIG_PCI
+static int primary_phb_addr;
+#endif
+
+/*
+ * Setup the architecture
+ */
+#ifdef CONFIG_SMP
+extern void __init wrhv_smp_init(void);
+#endif
+
+/*
+ * The hypervisor needs to know which FMAN and which DTSEC you
+ * are trying to access via the MDIO as the access functions
+ * need that information.
+ * This information should be encoded into the "bus" element
+ * of the MDIO_MSG struct.
+
+ * fman 4 bits  0-1
+ * dtsec 4 bits 0-3
+
+ * 0x000000<fman><dtsec>
+ */
+static uint32_t p4080_mdio_bus[PHY_MAX_ADDR];
+
+static int __init p4080_mdio_bus_init(void)
+{
+	struct device_node *np, *phy_np;
+	int i, j;
+	uint32_t bus = 0;
+	char *mdio_bus[] = {
+			"/soc@fe000000/fman@400000/ethernet@e0000",
+			"/soc@fe000000/fman@400000/ethernet@e2000",
+			"/soc@fe000000/fman@400000/ethernet@e4000",
+			"/soc@fe000000/fman@400000/ethernet@e6000",
+			"/soc@fe000000/fman@500000/ethernet@e0000",
+			"/soc@fe000000/fman@500000/ethernet@e2000",
+			"/soc@fe000000/fman@500000/ethernet@e4000",
+			"/soc@fe000000/fman@500000/ethernet@e6000",
+	};
+
+	for (i = 0; i < PHY_MAX_ADDR; i++) {
+		for_each_compatible_node(np, NULL, "fsl,p4080-fman-1g-mac") {
+			const u32 *phandle;
+			const u32 *reg;
+
+			phandle = of_get_property(np, "phy-handle", NULL);
+			phy_np = of_find_node_by_phandle(*phandle);
+			reg = of_get_property(phy_np, "reg", NULL);
+			if (reg && (*reg == i))
+				break;
+		}
+		if (!np) {
+			bus = 0;
+			goto get_bus;
+		}
+
+		for (j = 0; j < ARRAY_SIZE(mdio_bus); j++) {
+			if (!(strcmp(np->full_name,  mdio_bus[j]))) {
+				bus = j;
+				/*
+				 * mask fman1
+				*/
+				if (j > 3) {
+					bus -= 4;
+					bus |= 1 << 4;
+				}
+				break;
+			}
+		}
+
+get_bus:
+		p4080_mdio_bus[i] = bus;
+	}
+
+	return 0;
+}
+subsys_initcall(p4080_mdio_bus_init);
+
+uint32_t p4080_get_vb_mdio_bus(struct mii_bus *mii_bus, int addr)
+{
+	if (addr > PHY_MAX_ADDR)
+		return -1;
+
+	return p4080_mdio_bus[addr];
+}
+
+static void __init wrhv_p4080_setup_arch(void)
+{
+#ifdef CONFIG_PCI
+	struct device_node *np;
+	struct pci_controller *hose;
+#endif
+	dma_addr_t max = 0xffffffff;
+
+	if (ppc_md.progress)
+		ppc_md.progress("wrhv_p4080_setup_arch()", 0);
+
+#ifdef CONFIG_SMP
+	wrhv_smp_init();
+#endif
+
+	get_hv_bsp_server_handle();
+	wrhv_cpu_freq = get_bsp_clock_freq();
+
+#ifdef CONFIG_PCI
+	for_each_compatible_node(np, "pci", "fsl,p4080-pcie") {
+		struct resource rsrc;
+		of_address_to_resource(np, 0, &rsrc);
+		if ((rsrc.start & 0xfffff) == primary_phb_addr)
+			fsl_add_bridge(np, 1);
+		else
+			fsl_add_bridge(np, 0);
+
+		hose = pci_find_hose_for_OF_device(np);
+		max = min(max, hose->dma_window_base_cur +
+				hose->dma_window_size);
+
+		ppc_setup_pci_law(np);
+	}
+#endif
+
+#ifdef CONFIG_SWIOTLB
+	if (lmb_end_of_DRAM() > max) {
+		ppc_swiotlb_enable = 1;
+		set_pci_dma_ops(&swiotlb_dma_ops);
+		ppc_md.pci_dma_dev_setup = pci_dma_dev_setup_swiotlb;
+	}
+#endif
+	printk(KERN_INFO "P4080 DS board from Freescale Semiconductor\n");
+}
+
+extern int vsc824x_add_skew(struct phy_device *phydev);
+#define PHY_ID_VSC8244	0x000fc6c0
+static int __init board_fixups(void)
+{
+	phy_register_fixup_for_uid(PHY_ID_VSC8244, 0xfffff, vsc824x_add_skew);
+
+	return 0;
+}
+machine_device_initcall(p4080_ds, board_fixups);
+
+static const struct of_device_id of_device_ids[] __devinitconst = {
+	{
+		.compatible	= "simple-bus"
+	},
+	{
+		.compatible	= "fsl,dpaa"
+	},
+	{
+		.compatible	= "fsl,rapidio-delta",
+	},
+	{}
+};
+
+int __init declare_of_platform_devices(void)
+{
+	struct device_node *np;
+	struct of_device *dev;
+	int err;
+
+	err = of_platform_bus_probe(NULL, of_device_ids, NULL);
+	if (err)
+		return err;
+
+	/* Now probe the fake MDIO buses */
+	for_each_compatible_node(np, NULL, "fsl,p4080ds-mdio") {
+		dev = of_platform_device_create(np, NULL, NULL);
+		if (!dev) {
+			of_node_put(np);
+			return -ENOMEM;
+		}
+	}
+
+	for_each_compatible_node(np, NULL, "fsl,p4080ds-xmdio") {
+		dev = of_platform_device_create(np, NULL, NULL);
+		if (!dev) {
+			of_node_put(np);
+			return -ENOMEM;
+		}
+	}
+
+	return 0;
+}
+machine_device_initcall(p4080_ds, declare_of_platform_devices);
+
+/*
+ * Called very early, device-tree isn't unflattened
+ */
+static int __init wrhv_p4080_probe(void)
+{
+	unsigned long root = of_get_flat_dt_root();
+
+	/* wr_config should have been initialized in wrhv_init(),
+	 * continue to complete the vbi initialization here.
+	 */
+	wrhv_mapping(); /* Map vb_config structure */
+	vbi_init(wr_config);
+
+	strncpy(cmd_line, VBI_BOOTLINE_ADDR_GET(), VB_MAX_BOOTLINE_LENGTH - 1);
+	cmd_line[VB_MAX_BOOTLINE_LENGTH - 1] = 0;
+
+	/* Save command line for /proc/cmdline */
+	strlcpy(boot_command_line, cmd_line, COMMAND_LINE_SIZE);
+
+	if (of_flat_dt_is_compatible(root, "fsl,P4080DS")) {
+#ifdef CONFIG_PCI
+		/* xxx - galak */
+		primary_phb_addr = 0x8000;
+#endif
+		return 1;
+	} else {
+		return 0;
+	}
+}
+
+/* Early setup is required for large chunks of contiguous (and coarsely-aligned)
+ * memory. The following shoe-horns Qman/Bman "init_early" calls into the
+ * platform setup to let them parse their CCSR nodes early on. */
+#ifdef CONFIG_FSL_QMAN_CONFIG
+void __init qman_init_early(void);
+#endif
+#ifdef CONFIG_FSL_BMAN_CONFIG
+void __init bman_init_early(void);
+#endif
+#ifdef CONFIG_FSL_PME2_CTRL
+void __init pme2_init_early(void);
+#endif
+
+static __init void p4080_init_early(void)
+{
+	if (system_state != SYSTEM_RUNNING) {
+#ifdef CONFIG_FSL_QMAN_CONFIG
+	qman_init_early();
+#endif
+#ifdef CONFIG_FSL_BMAN_CONFIG
+	bman_init_early();
+#endif
+#ifdef CONFIG_FSL_PME2_CTRL
+	pme2_init_early();
+#endif
+	}
+}
+
+void wrhv_setup_msr_for_ap(VBI_HREG_SET_CMPLX_QUALIFIED *regs)
+{
+	/*
+	 * The MSR value depends on hypervisor's preparetion for GOS.
+	 * Hypervisor has prepared 2 TLB entry for GOS, hence here we don't
+	 * have to set IS | DS. But e500mc will use kernel space 1, aka
+	 * MSR_IS | MSR_DS, the same as E500. Refer to head_wrhv_p4080.S to
+	 * see e500mc GOS run space 1. And thanks to e500mc's vt mode, we
+	 * don't need PR bit at the entry point of GOS and the interrupts
+	 * are masked as well. MSR_GS will good enough for e500mc. And
+	 * GOS will manage (MSR_CE | MSR_ME | MSR_EE) bits with MSR_KERNEL
+	 * without hypervisor's involvement.
+	 */
+	regs->vbiRegSet.hreg32.msr = MSR_GS;
+}
+
+define_machine(p4080_ds) {
+	.name			= "Wind River Hypervisor P4080 DS",
+	.probe			= wrhv_p4080_probe,
+	.setup_arch		= wrhv_p4080_setup_arch,
+	.init_IRQ		= wrhv_mpc85xx_pic_init,
+#ifdef CONFIG_PCI
+	.pcibios_fixup_bus	= fsl_pcibios_fixup_bus,
+	.enable_pci_law 	= wrhv_enable_pci_law,
+#endif
+	.get_irq		= wrhv_vioapic_get_irq,
+	.get_direct_irq		= wrhv_get_direct_irq,
+	.restart		= wrhv_restart,
+	.calibrate_decr		= wrhv_calibrate_decr,
+	.progress		= udbg_progress,
+	.init_early		= p4080_init_early,
+	.power_save		= wrhv_power_save,
+	.set_law_base		= wrhv_set_law_base,
+	.set_law_attr		= wrhv_set_law_attr,
+	.get_law_attr		= wrhv_get_law_attr,
+	.get_mdio_bus		= p4080_get_vb_mdio_bus,
+#ifdef CONFIG_HOTPLUG_CPU
+	.cpu_die		= cpu_die,
+#endif
+};
diff --git a/arch/powerpc/sysdev/fsl_pci.c b/arch/powerpc/sysdev/fsl_pci.c
index a14760f..bd63dd7 100644
--- a/arch/powerpc/sysdev/fsl_pci.c
+++ b/arch/powerpc/sysdev/fsl_pci.c
@@ -34,6 +34,10 @@
 #include <sysdev/fsl_soc.h>
 #include <sysdev/fsl_pci.h>
 
+#ifdef CONFIG_WRHV
+#include <vbi/vbi.h>
+#endif
+
 static int fsl_pcie_bus_fixup;
 
 static void __init quirk_fsl_pcie_header(struct pci_dev *dev)
@@ -207,8 +211,20 @@ static void __init setup_pci_atmu(struct pci_controller *hose,
 		piwar |= (mem_log - 1);
 
 		/* Setup inbound memory window */
+#ifdef CONFIG_WRHV
+		{
+		u64 paddr;
+			if (vbi_get_guest_dma_addr(0, &paddr) == 0) {
+				out_be32(&pci->piw[win_idx].pitar,  paddr >> 12);
+				out_be32(&pci->piw[win_idx].piwbar, paddr >> 12);
+				printk ("Real Memory Start @%llx.\n", paddr);
+			} else
+				printk ("%s: it's failed when calling dma VBI.\n", __func__);
+		}
+#else
 		out_be32(&pci->piw[win_idx].pitar,  0x00000000);
 		out_be32(&pci->piw[win_idx].piwbar, 0x00000000);
+#endif
 		out_be32(&pci->piw[win_idx].piwar,  piwar);
 		win_idx--;
 
diff --git a/drivers/Kconfig b/drivers/Kconfig
index 0a17225..a24fb0b 100644
--- a/drivers/Kconfig
+++ b/drivers/Kconfig
@@ -114,4 +114,5 @@ source "drivers/platform/Kconfig"
 
 source "drivers/tdm/Kconfig"
 
+source "drivers/wrhv/Kconfig"
 endmenu
diff --git a/drivers/Makefile b/drivers/Makefile
index 12101ef..29ed61d 100644
--- a/drivers/Makefile
+++ b/drivers/Makefile
@@ -114,3 +114,4 @@ obj-$(CONFIG_STAGING)		+= staging/
 obj-y				+= platform/
 obj-y				+= ieee802154/
 obj-y				+= tdm/
+obj-y				+= wrhv/
diff --git a/drivers/net/gianfar.c b/drivers/net/gianfar.c
index 7b57064..10a76bd 100644
--- a/drivers/net/gianfar.c
+++ b/drivers/net/gianfar.c
@@ -115,6 +115,14 @@ EXPORT_SYMBOL(devfp_tx_hook);
 #undef BRIEF_GFAR_ERRORS
 #undef VERBOSE_GFAR_ERRORS
 
+#ifdef CONFIG_WRHV
+#define NIC_STR_LEN	15
+extern char wrhv_macaddr[MAC_ADDR_LEN];
+extern char wrhv_net_name[NIC_STR_LEN]; /* eth0, eth1, eth2... */
+extern int wrhv_nic_num;
+extern int wrhv_nic_start; /* which index should we start at */
+#endif
+
 const char gfar_driver_name[] = "Gianfar Ethernet";
 const char gfar_driver_version[] = "1.3";
 
@@ -1109,11 +1117,13 @@ out:
 	priv->ftp_rqfpr = priv->ftp_rqfcr = NULL;
 }
 
+extern unsigned int get_pvr(void);
+extern unsigned int get_svr(void);
 static void gfar_detect_errata(struct gfar_private *priv)
 {
 	struct device *dev = &priv->ofdev->dev;
-	unsigned int pvr = mfspr(SPRN_PVR);
-	unsigned int svr = mfspr(SPRN_SVR);
+	unsigned int pvr = get_pvr();
+	unsigned int svr = get_svr();
 	unsigned int mod = (svr >> 16) & 0xfff6; /* w/o E suffix */
 	unsigned int rev = svr & 0xffff;
 
@@ -1224,6 +1234,7 @@ static int gfar_probe(struct of_device *ofdev,
 	u32 rstat = 0, tstat = 0, rqueue = 0, tqueue = 0;
 	u32 isrg = 0;
 	u32 __iomem *baddr;
+	int j;
 
 	err = gfar_of_init(ofdev, &dev);
 
@@ -1444,6 +1455,50 @@ static int gfar_probe(struct of_device *ofdev,
 
 	err = register_netdev(dev);
 
+#ifdef CONFIG_WRHV
+	if (wrhv_nic_start > wrhv_nic_num) {
+		printk(KERN_ERR " WRHV: bootline NIC setup error\n");
+		return -ENODEV;
+	}
+
+	for (j = wrhv_nic_start; j <= wrhv_nic_num; j++) {
+		char nic_num[NIC_STR_LEN] = "";
+		char net_sub_name[NIC_STR_LEN]; /* eth on most platforms except
+		on cavium they call there network devices mgmtX */
+
+		if (!is_valid_ether_addr(wrhv_macaddr))
+				break;
+		else if (!wrhv_net_name[0])
+			strcpy(wrhv_net_name, "eth0");
+
+		/* eth0 --> we only want the eth part so we
+		   Simply append to the ifname the nic number */
+
+		/* Clear out the buffer for the next iteration */
+		memset(net_sub_name, '\0', NIC_STR_LEN);
+
+		/* get rid of the number on the end 'ethX' */
+		strncpy(net_sub_name, wrhv_net_name, strlen(wrhv_net_name) - 1);
+		sprintf(nic_num, "%d", j);
+		strcat(net_sub_name, nic_num);
+
+		if (strcmp(dev->name, net_sub_name) == 0) {
+			char local_mac[MAC_ADDR_LEN];
+			char last_byte = wrhv_macaddr[MAC_ADDR_LEN - 1];
+
+			memcpy(local_mac, wrhv_macaddr, MAC_ADDR_LEN);
+			/* Extract the last byte of the MAC address */
+			/* One limitation is that we do not check to see if
+			the last byte needs to wrap around.  We expect sane
+			values are being passed in.  This limitation has been
+			documented in the README.bootline */
+
+			local_mac[MAC_ADDR_LEN - 1] = (last_byte + j) & 0xff;
+			memcpy(dev->dev_addr, local_mac, MAC_ADDR_LEN);
+		}
+	}
+#endif
+
 	if (err) {
 		printk(KERN_ERR "%s: Cannot register net device, aborting.\n",
 				dev->name);
diff --git a/drivers/serial/8250.c b/drivers/serial/8250.c
index 73ab756..c1c7aaf 100644
--- a/drivers/serial/8250.c
+++ b/drivers/serial/8250.c
@@ -43,6 +43,13 @@
 #include <asm/io.h>
 #include <asm/irq.h>
 
+#ifdef CONFIG_WRHV
+#include <asm/wrhv.h>
+#include <vbi/vbi.h>
+#include <vbi/pdc.h>
+#include <vbi/duart.h>
+#endif
+
 #include "8250.h"
 
 #ifdef CONFIG_SPARC
@@ -108,6 +115,9 @@ static unsigned int skip_txen_test; /* force skip of txen test at init time */
 #define CONFIG_HUB6 1
 
 #include <asm/serial.h>
+#if defined(CONFIG_WRHV) && defined(CONFIG_X86)
+#include <asm/wrhv_serial.h>
+#endif
 /*
  * SERIAL_PORT_DFNS tells us about built-in ports that have no
  * standard enumeration mechanism.   Platforms that can find all
@@ -386,6 +396,144 @@ static inline int map_8250_out_reg(struct uart_port *p, int offset)
 
 #endif
 
+#ifdef CONFIG_WRHV_DUART
+
+/* handle to access hypervisor serial device driver */
+extern vbi_pdc_handle duart_pdc;
+
+/* stub registers */
+static unsigned int wrhv_uart_scr;
+static unsigned int wrhv_uart_ier;
+static unsigned int wrhv_uart_iir;
+static unsigned int wrhv_is_opened = 0;
+
+/* stub function to read register */
+static unsigned int wrhv_serial_in(struct uart_port *p, int offset)
+{
+	unsigned int value;
+	switch (offset) {
+
+	case UART_IER: /* interrupt enable register */
+		return wrhv_uart_ier;
+
+	case UART_LSR: /* line status register */
+		value = BOTH_EMPTY;
+		/* check receiver data ready */
+		if (wrhv_duart_tstc()) {
+			value |= UART_LSR_DR;
+		}
+		return value;
+
+	case UART_MSR: /* modem status register */
+		return UART_MSR_CTS;
+
+	case UART_SCR: /* scratch register */
+		return wrhv_uart_scr;
+
+	case UART_IIR: /* interrupt id register */
+		/* always return FIFO enabled bits */
+		return wrhv_uart_iir | 0xc0;
+
+	case UART_RX: /* receive buffer */
+		/* return received character */
+		return wrhv_duart_getc();
+
+	}
+
+	return 0;
+}
+
+/* stub function to write register */
+static void wrhv_serial_out(struct uart_port *p, int offset, int value)
+{
+	unsigned int mode;
+	switch (offset) {
+
+	case UART_IER: /* interrupt enable register */
+		wrhv_uart_ier = (unsigned int)value;
+		/* set wrhv duart to interrupt mode */
+		if (wrhv_uart_ier) {
+			if (!wrhv_is_opened) {
+				wrhv_is_opened = 1;
+				value = vbi_pdc_op(duart_pdc, PDC_REQUEST_IOCTL,
+					PDC_IOCTL_SIO_OPEN,
+					0, 0,
+				0);
+			}
+			/* set driver to interrupt mode */
+			mode = SIO_MODE_INT;
+			value = vbi_pdc_op(duart_pdc, PDC_REQUEST_IOCTL,
+				PDC_IOCTL_SIO_MODE_SET,
+				(void *)mode, SIO_HW_OPTS_CLOCAL,
+				0);
+		}
+		break;
+
+	case UART_TX: /* transmit register */
+		wrhv_duart_putc(value);
+		break;
+
+	case UART_SCR: /* scratch register */
+		wrhv_uart_scr = (unsigned int)value;
+		break;
+
+	case UART_IIR: /* interrupt id register */
+		wrhv_uart_iir = (unsigned int)value;
+		break;
+
+	}
+}
+
+/* function to set terminal options */
+static void wrhv_set_termios(struct uart_port *port, struct ktermios *termios,
+		       struct ktermios *old)
+{
+	struct uart_8250_port *up = (struct uart_8250_port *)port;
+	unsigned int cval;
+	unsigned long flags;
+
+	switch (termios->c_cflag & CSIZE) {
+	case CS5:
+		cval = SIO_HW_OPTS_CS5;
+		break;
+	case CS6:
+		cval = SIO_HW_OPTS_CS6;
+		break;
+	case CS7:
+		cval = SIO_HW_OPTS_CS7;
+		break;
+	default:
+	case CS8:
+		cval = SIO_HW_OPTS_CS8;
+		break;
+	}
+
+	if (termios->c_cflag & CSTOPB)
+		cval |= SIO_HW_OPTS_STOPB;
+	if (termios->c_cflag & PARENB)
+		cval |= SIO_HW_OPTS_PARENB;
+	if (!(termios->c_cflag & PARODD))
+		cval |= SIO_HW_OPTS_PARODD;
+
+	/*
+	 * ignore all characters if CREAD is not set
+	 */
+	if ((termios->c_cflag & CREAD) == 0)
+		up->port.ignore_status_mask |= UART_LSR_DR;
+	else
+		cval |= CREAD;
+
+	/*
+	 * Ok, we're now changing the port state.  Do it with
+	 * interrupts disabled.
+	 */
+	spin_lock_irqsave(&up->port.lock, flags);
+	vbi_pdc_op(duart_pdc, PDC_REQUEST_IOCTL, PDC_IOCTL_SIO_HW_OPTS_SET,
+			(void *)cval, 0, 0);
+	spin_unlock_irqrestore(&up->port.lock, flags);
+}
+#endif
+
 static unsigned int hub6_serial_in(struct uart_port *p, int offset)
 {
 	offset = map_8250_in_reg(p, offset) << p->regshift;
@@ -526,6 +674,13 @@ static void set_io_from_upio(struct uart_port *p)
 		p->serial_out = io_serial_out;
 		break;
 	}
+
+#ifdef CONFIG_WRHV_DUART
+	/* use stub functions to access register */
+	p->serial_in = wrhv_serial_in;
+	p->serial_out = wrhv_serial_out;
+#endif
+
 	/* Remember loaded iotype */
 	up->cur_iotype = p->iotype;
 }
@@ -1052,6 +1207,7 @@ static void autoconfig_16550a(struct uart_8250_port *up)
 	 * already a 1 and maybe locked there before we even start start.
 	 */
 	iersave = serial_in(up, UART_IER);
+#ifndef CONFIG_WRHV_DUART
 	serial_outp(up, UART_IER, iersave & ~UART_IER_UUE);
 	if (!(serial_in(up, UART_IER) & UART_IER_UUE)) {
 		/*
@@ -1076,6 +1232,7 @@ static void autoconfig_16550a(struct uart_8250_port *up)
 		 */
 		DEBUG_AUTOCONF("Couldn't force IER_UUE to 0 ");
 	}
+#endif
 	serial_outp(up, UART_IER, iersave);
 }
 
@@ -1334,6 +1491,16 @@ static void serial8250_start_tx(struct uart_port *port)
 {
 	struct uart_8250_port *up = (struct uart_8250_port *)port;
 
+#ifdef CONFIG_WRHV_DUART
+	/* wrhv duart does not support tx interrupt, so need to
+	 * check uart circ_buf and transmit all characters
+	 */
+	do {
+		transmit_chars(up);
+	} while (!uart_circ_empty(&up->port.state->xmit));
+	return;
+#endif
+
 	if (!(up->ier & UART_IER_THRI)) {
 		up->ier |= UART_IER_THRI;
 		serial_out(up, UART_IER, up->ier);
@@ -1530,12 +1697,14 @@ static void serial8250_handle_port(struct uart_8250_port *up)
 
 	spin_lock_irqsave(&up->port.lock, flags);
 
+#ifndef CONFIG_WRHV_DUART
 	if (unlikely(up->lsr_last & UART_LSR_BI && up->bugs & UART_BUG_PPC)) {
 		up->lsr_last &= ~UART_LSR_BI;
 		serial_inp(up, UART_RX);
 		spin_unlock_irqrestore(&up->port.lock, flags);
 		return;
 	}
+#endif
 
 	status = up->lsr_last = serial_inp(up, UART_LSR);
 
@@ -1543,9 +1712,15 @@ static void serial8250_handle_port(struct uart_8250_port *up)
 
 	if (status & (UART_LSR_DR | UART_LSR_BI))
 		receive_chars(up, &status);
+
+/* wrhv duart does not support tx interrupt, we always handle
+ * transmit buffer in start_tx()
+ */
+#ifndef CONFIG_WRHV_DUART
 	check_modem_status(up);
 	if (status & UART_LSR_THRE)
 		transmit_chars(up);
+#endif
 
 	spin_unlock_irqrestore(&up->port.lock, flags);
 }
@@ -1581,6 +1756,15 @@ static irqreturn_t serial8250_interrupt(int irq, void *dev_id)
 
 		up = list_entry(l, struct uart_8250_port, list);
 
+#ifdef CONFIG_WRHV_DUART
+		/* for wrhv duart, we check rx interrupt in
+		 * serial8250_handl_port()
+		 */
+		serial8250_handle_port(up);
+		handled = 1;
+		end = NULL;
+		break;
+#endif
 		iir = serial_in(up, UART_IIR);
 		if (!(iir & UART_IIR_NO_INT)) {
 			serial8250_handle_port(up);
@@ -1588,6 +1772,7 @@ static irqreturn_t serial8250_interrupt(int irq, void *dev_id)
 			handled = 1;
 
 			end = NULL;
+			break;
 		} else if (up->port.iotype == UPIO_DWAPB &&
 			  (iir & UART_IIR_BUSY) == UART_IIR_BUSY) {
 			/* The DesignWare APB UART has an Busy Detect (0x07)
@@ -2394,7 +2579,10 @@ serial8250_set_termios(struct uart_port *port, struct ktermios *termios,
 		/* Switch to bank 2 not bank 1, to avoid resetting EXCR2 */
 		serial_outp(up, UART_LCR, 0xe0);
 	} else {
+		/* skip DLAB on WRHV + PPC */
+#if !defined(CONFIG_WRHV) || !defined(CONFIG_PPC)
 		serial_outp(up, UART_LCR, cval | UART_LCR_DLAB);/* set DLAB */
+#endif
 	}
 
 	serial_dl_write(up, quot);
@@ -2657,7 +2845,11 @@ static struct uart_ops serial8250_pops = {
 	.break_ctl	= serial8250_break_ctl,
 	.startup	= serial8250_startup,
 	.shutdown	= serial8250_shutdown,
+#ifdef CONFIG_WRHV_DUART
+	.set_termios	= wrhv_set_termios,
+#else
 	.set_termios	= serial8250_set_termios,
+#endif
 	.set_ldisc	= serial8250_set_ldisc,
 	.pm		= serial8250_pm,
 	.type		= serial8250_type,
@@ -2839,6 +3031,7 @@ static int __init serial8250_console_setup(struct console *co, char *options)
 	if (co->index >= nr_uarts)
 		co->index = 0;
 	port = &serial8250_ports[co->index].port;
+
 	if (!port->iobase && !port->membase)
 		return -ENODEV;
 
@@ -2866,6 +3059,9 @@ static struct console serial8250_console = {
 
 static int __init serial8250_console_init(void)
 {
+#ifdef CONFIG_WRHV_DUART
+	wrhv_duart_init();
+#endif
 	if (nr_uarts > UART_NR)
 		nr_uarts = UART_NR;
 
@@ -3241,6 +3437,10 @@ static int __init serial8250_init(void)
 {
 	int ret;
 
+#ifdef CONFIG_WRHV_DUART
+	wrhv_duart_init();
+#endif
+
 	if (nr_uarts > UART_NR)
 		nr_uarts = UART_NR;
 
diff --git a/drivers/serial/Kconfig b/drivers/serial/Kconfig
index 158c7c1..afea0af 100644
--- a/drivers/serial/Kconfig
+++ b/drivers/serial/Kconfig
@@ -70,6 +70,13 @@ config SERIAL_8250_CONSOLE
 
 	  If unsure, say N.
 
+config WRHV_DUART
+	bool "WRHV duart serial support"
+	depends on SERIAL_8250=y && WRHV && PPC32
+	---help---
+	  This selects whether you want to include the driver for the wrhv
+	  duart driver.
+
 config SERIAL_8250_PPC_BUG
 	bool "Fix 8250/16550 to handle IRQ storm after receipt of a break"
 	depends on SERIAL_8250 && PPC
diff --git a/drivers/wrhv/Kconfig b/drivers/wrhv/Kconfig
new file mode 100644
index 0000000..5d2169c
--- /dev/null
+++ b/drivers/wrhv/Kconfig
@@ -0,0 +1,34 @@
+menuconfig WRHV_VIRTIO
+	bool "Virtual devices support for WindRiver Hypervisor Guest OS"
+	depends on WRHV
+	select VIRTIO
+	---help---
+	  This provides support for the virtio based paravirtual device on
+	  the WindRiver Hypervisor Guest OS.
+
+if WRHV_VIRTIO
+
+config WRHV_FRAME_TRANSITION_INTERRUPT_TEST
+	bool "Frame transition interrupt test"
+	depends on WRHV_CERT
+	default n
+	---help---
+	  Enable testing the start frame and end frame transition interrupt
+	  for Certifiable Hypervisor.
+
+config WRHV_VIRTIO_SERIAL
+	bool "Virtual serial device support for WindRiver Hypervisor Guest OS"
+	depends on !WRHV_DUART && !SERIAL_8250
+	select VIRTIO_CONSOLE
+	---help---
+	  This provides support for the virtual serial device support for
+	  WindRiver Hypervisor Guest OS.
+
+config WRHV_VIRTIO_SERIAL_CONSOLE
+	bool "Virtual serial console support for WindRiver Hypervisor Guest OS"
+	depends on WRHV_VIRTIO_SERIAL
+	---help---
+	  If you say Y here, it will be possible to user the virtual
+	  serial as a system console.
+
+endif  # WRHV_VIRTIO
diff --git a/drivers/wrhv/Makefile b/drivers/wrhv/Makefile
new file mode 100644
index 0000000..f6cf019
--- /dev/null
+++ b/drivers/wrhv/Makefile
@@ -0,0 +1,7 @@
+obj-$(CONFIG_WRHV_VIRTIO)	+= wrhv_devices.o
+obj-$(CONFIG_WRHV_FRAME_TRANSITION_INTERRUPT_TEST) += wrhv_frame_irq.o
+obj-$(CONFIG_WRHV_DUART)	+= wrhv_duart.o
+
+obj-$(CONFIG_WRHV_VIRTIO_SERIAL) += wrhv_serial_driver.o
+
+wrhv_serial_driver-objs	:= wrhv_serial.o wrhv_duart.o
diff --git a/drivers/wrhv/wrhv_devices.c b/drivers/wrhv/wrhv_devices.c
new file mode 100644
index 0000000..6d5571c
--- /dev/null
+++ b/drivers/wrhv/wrhv_devices.c
@@ -0,0 +1,480 @@
+/*
+ *  Copyright (C) 2011 Wind River Systems, Inc.
+ *
+ *  This file is based on drivers/lguest/lguest_device.c
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/interrupt.h>
+#include <linux/virtio.h>
+#include <linux/virtio_config.h>
+#include <linux/virtio_ids.h>
+#include <linux/virtio_console.h>
+#include <vbi/vbi.h>
+#include <vbi/pdc.h>
+#include <vbi/duart.h>
+#include <linux/scatterlist.h>
+#include <linux/circ_buf.h>
+#include "wrhv_devices.h"
+
+/*
+ * Device configurations
+ *
+ * The configuration information for a device consists of
+ * virtqueues, a feature bitmap, and some configuration bytes.
+ */
+static inline struct wrhv_vqconfig *wrhv_vq(struct wrhv_device_desc *desc)
+{
+	return desc->vqconfig;
+}
+
+static inline u8 *wrhv_features(struct wrhv_device_desc *desc)
+{
+	return desc->features;
+}
+
+static inline u8 *wrhv_config(struct wrhv_device_desc *desc)
+{
+	return desc->config;
+}
+
+/* The total size of the config page used by this device (incl. desc) */
+static inline unsigned desc_size(struct wrhv_device_desc *desc)
+{
+	return sizeof(*desc);
+}
+
+static u32 wrhv_get_features(struct virtio_device *vdev)
+{
+	unsigned int i;
+	u32 features = 0;
+	struct wrhv_device_desc *desc = to_wrhvdev(vdev)->desc;
+	u8 *in_features = wrhv_features(desc);
+
+	for (i = 0; i < min(desc->feature_len * 8, 32); i++)
+		if (in_features[i / 8] & (1 << (i % 8)))
+			features |= (1 << i);
+
+	return features;
+}
+
+/*
+ * The virtio core takes the features the Host offers, and copies the ones
+ * supported by the driver into the vdev->features array.  Once that's all
+ * sorted out, this routine is called so we can tell the Host which features we
+ * understand and accept.
+ */
+static void wrhv_finalize_features(struct virtio_device *vdev)
+{
+	unsigned int i, bits;
+	struct wrhv_device_desc *desc = to_wrhvdev(vdev)->desc;
+	u8 *out_features = wrhv_features(desc) + WRHV_DEVICE_MAX_FEATURES_LEN;
+
+	memset(out_features, 0, desc->feature_len);
+	bits = min_t(unsigned, desc->feature_len, sizeof(vdev->features)) * 8;
+	for (i = 0; i < bits; i++) {
+		if (test_bit(i, vdev->features))
+			out_features[i / 8] |= (1 << (i % 8));
+	}
+}
+
+/*
+ * Reading and writing elements in config space
+ */
+static void wrhv_get(struct virtio_device *vdev, unsigned int offset,
+			void *buf, unsigned len)
+{
+	struct wrhv_device_desc *desc = to_wrhvdev(vdev)->desc;
+
+	BUG_ON(offset + len > desc->config_len);
+	memcpy(buf, wrhv_config(desc) + offset, len);
+}
+
+static void wrhv_set(struct virtio_device *vdev, unsigned int offset,
+			const void *buf, unsigned len)
+{
+	struct wrhv_device_desc *desc = to_wrhvdev(vdev)->desc;
+
+	BUG_ON(offset + len > desc->config_len);
+	memcpy(wrhv_config(desc) + offset, buf, len);
+}
+
+/*
+ * The operations to get and set the status word just access the status field
+ * of the device descriptor.
+ */
+static u8 wrhv_get_status(struct virtio_device *vdev)
+{
+	return to_wrhvdev(vdev)->desc->status;
+}
+
+static void wrhv_set_status(struct virtio_device *vdev, u8 status)
+{
+	to_wrhvdev(vdev)->desc->status = status;
+}
+
+static void wrhv_reset(struct virtio_device *vdev)
+{
+	wrhv_set_status(vdev, 0);
+}
+
+static int wrhv_vq_buf_space(struct wrhv_virtqueue *vq)
+{
+	u32 h = *vq->ph, t = *vq->pt;
+	size_t len = vq->len;
+
+	return CIRC_SPACE(h, t, len);
+}
+
+static int wrhv_vq_buf_count(struct wrhv_virtqueue *vq)
+{
+	u32 h = *vq->ph, t = *vq->pt;
+	size_t len = vq->len;
+
+	return CIRC_CNT(h, t, len);
+}
+
+static int wrhv_add_sg(struct wrhv_virtqueue *vq,
+			struct scatterlist *sg)
+{
+	u32 len = sg->length;
+	size_t l = vq->len;
+	u32 h = *vq->ph, t = *vq->pt;
+
+	while (len) {
+		u32 free = wrhv_vq_buf_space(vq);
+		u32 s, r;
+
+		if (!free) {
+			vq->vq.vq_ops->kick(&vq->vq);
+			continue;
+		}
+
+		s = min(len, free);
+		len -= s;
+
+		r = CIRC_SPACE_TO_END(h, t, l);
+		if (s  > r) {
+			memcpy(vq->buf + h, sg_virt(sg), r);
+			memcpy(vq->buf, sg_virt(sg) + r, s - r);
+		} else
+			memcpy(vq->buf + h, sg_virt(sg), s);
+
+		*vq->ph = (h + s) % vq->len;
+	}
+	return 0;
+}
+
+static int wrhv_add_buf(struct virtqueue *_vq,
+			struct scatterlist *sg,
+			unsigned int out,
+			unsigned int in,
+			void *data)
+{
+	struct wrhv_virtqueue *vq = to_wrhvvq(_vq);
+
+	vq->data = data;
+	while (out--) {
+		wrhv_add_sg(vq, sg);
+		sg = sg_next(sg);
+	}
+
+	WARN_ONCE(in > 1, "We only support one read buffer now");
+
+	if (in) {
+		vq->read_buf = sg_virt(sg);
+		vq->read_len = sg->length;
+	}
+
+	return 0;
+}
+
+static void *wrhv_get_buf(struct virtqueue *_vq, unsigned int *len)
+{
+	struct wrhv_virtqueue *vq = to_wrhvvq(_vq);
+	u32 n, r;
+	u32 h = *vq->ph, t = *vq->pt;
+	size_t l = vq->len;
+	unsigned char *pt = vq->buf + t;
+
+	if (!(vq->mode & WRHV_DEVICE_VQ_IN))
+		return vq->data;
+
+	n = wrhv_vq_buf_count(vq);
+	if (!n) {
+		*len = 0;
+		return NULL;
+	}
+
+	n = min(n, vq->read_len);
+	r = CIRC_CNT_TO_END(h, t, l);
+	if (n > r) {
+		memcpy(vq->read_buf, pt, r);
+		memcpy(vq->read_buf + r, vq->buf, n - r);
+	} else
+		memcpy(vq->read_buf, pt, n);
+
+	*vq->pt = (t + n) % vq->len;
+
+	*len = n;
+	return vq->data;
+}
+
+static void wrhv_kick(struct virtqueue *_vq)
+{
+	struct wrhv_virtqueue *vq = to_wrhvvq(_vq);
+	struct wrhv_device *vdev = to_wrhvdev(vq->vq.vdev);
+
+	if (!(vq->mode & WRHV_DEVICE_VQ_OUT))
+		return;
+
+	vbi_pdc_op(vdev->pdc_handle, PDC_REQUEST_WRITE, 0,
+			vq->buf, vq->len, 0);
+}
+
+static struct virtqueue_ops wrhv_vq_ops = {
+	.add_buf = wrhv_add_buf,
+	.get_buf = wrhv_get_buf,
+	.kick = wrhv_kick,
+};
+
+static irqreturn_t wrhv_interrupt(int irq, void *_vq)
+{
+	struct wrhv_virtqueue *vq = _vq;
+
+	/*
+	 * Don't run the input virtual queue callback function before we
+	 * fill the read buffer.
+	 */
+	if ((vq->mode & WRHV_DEVICE_VQ_IN) &&
+		(!vq->read_buf || !vq->len))
+		return IRQ_HANDLED;
+
+	if (vq->vq.callback)
+		vq->vq.callback(&vq->vq);
+
+	return IRQ_HANDLED;
+}
+
+int wrhv_init_vq(struct wrhv_device *vdev, unsigned int index,
+			struct wrhv_virtqueue *vq)
+{
+	struct intr_device_channel_buffer *idc = vdev->idc;
+
+	/* index 0 should be rx queue, index 1 should be tx queue */
+	switch (index) {
+	case 0:
+		idc->rxBuf = vq->buf;
+		idc->rxBufLen = vq->len;
+		vq->ph = &idc->rxBufWrPtr;
+		vq->pt = &idc->rxBufRdPtr;
+		vq->mode |= WRHV_DEVICE_VQ_IN;
+		break;
+	case 1:
+		idc->txBuf = vq->buf;
+		idc->txBufLen = vq->len;
+		vq->ph = &idc->txBufWrPtr;
+		vq->pt = &idc->txBufRdPtr;
+		vq->mode |= WRHV_DEVICE_VQ_OUT;
+		break;
+	default:
+		pr_err("unsupported queue for wrhv virtual device\n");
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(wrhv_init_vq);
+
+/*
+ * This routine finds the Nth virtqueue described in the configuration of
+ * this device and sets it up.
+ */
+static struct virtqueue *wrhv_find_vq(struct virtio_device *vdev,
+					unsigned int index,
+					void (*callback)(struct virtqueue *vq),
+					const char *name)
+{
+	struct wrhv_device *wdev = to_wrhvdev(vdev);
+	struct wrhv_virtqueue *vq;
+	struct wrhv_vqconfig *vconfig = wrhv_vq(wdev->desc) + index;
+	int err;
+
+	if (index >= wdev->desc->num_vq)
+		return ERR_PTR(-ENOENT);
+
+	vq = kzalloc(sizeof(*vq), GFP_KERNEL);
+	if (!vq)
+		return ERR_PTR(-ENOMEM);
+
+	vq->vq.callback = callback;
+	vq->vq.vdev = vdev;
+	vq->vq.vq_ops = &wrhv_vq_ops;
+	vq->vq.name = name;
+	vq->vq.priv = vconfig;
+	vq->len = vconfig->num;
+
+	if (wdev->ops && wdev->ops->init_idc)
+		wdev->ops->init_idc(wdev, index, vq);
+
+	if (vconfig->irq) {
+		err = request_irq(vconfig->irq, wrhv_interrupt, IRQF_SHARED,
+					dev_name(&vdev->dev), vq);
+		if (err) {
+			kfree(vq->buf);
+			kfree(vq);
+			return ERR_PTR(err);
+		}
+
+		wdev->mode |= WRHV_DEVICE_MODE_INT;
+	}
+
+	return &vq->vq;
+}
+
+static void wrhv_del_vq(struct virtqueue *vq)
+{
+	struct wrhv_vqconfig *vconfig = vq->priv;
+	struct wrhv_virtqueue *wvq = to_wrhvvq(vq);
+
+	if (vconfig->irq)
+		free_irq(vconfig->irq, vq);
+	if (!(wvq->mode & WRHV_DEVICE_VQ_NOFREE))
+		kfree(wvq->buf);
+	kfree(wvq);
+}
+
+static void wrhv_del_vqs(struct virtio_device *vdev)
+{
+	struct virtqueue *vq, *n;
+
+	list_for_each_entry_safe(vq, n, &vdev->vqs, list)
+		wrhv_del_vq(vq);
+}
+
+int wrhv_init_device(struct wrhv_device *vdev)
+{
+	if (vbi_pdc_op(vdev->pdc_handle, PDC_REQUEST_IOCTL,
+			PDC_IOCTL_SIO_OPEN, 0, 0, 0))
+		return -1;
+
+	if (vbi_pdc_op(vdev->pdc_handle, PDC_REQUEST_IOCTL,
+			PDC_IOCTL_SIO_MODE_SET, (void *)SIO_MODE_INT,
+			SIO_HW_OPTS_CLOCAL, 0))
+		return -1;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(wrhv_init_device);
+
+static int wrhv_find_vqs(struct virtio_device *vdev, unsigned nvqs,
+			struct virtqueue *vqs[], vq_callback_t *callbacks[],
+			const char *names[])
+{
+	struct wrhv_device *wdev = to_wrhvdev(vdev);
+	int i;
+
+	if (nvqs > wdev->desc->num_vq)
+		return -ENOENT;
+
+	for (i = 0; i < nvqs; i++) {
+		vqs[i] = wrhv_find_vq(vdev, i, callbacks[i], names[i]);
+		if (IS_ERR(vqs[i]))
+			goto error;
+	}
+
+	if (wdev->ops && wdev->ops->init_dev)
+		wdev->ops->init_dev(wdev);
+
+	return 0;
+error:
+	wrhv_del_vqs(vdev);
+	return PTR_ERR(vqs[i]);
+}
+
+static struct virtio_config_ops wrhv_config_ops = {
+	.get_features		= wrhv_get_features,
+	.finalize_features	= wrhv_finalize_features,
+	.get			= wrhv_get,
+	.set			= wrhv_set,
+	.get_status		= wrhv_get_status,
+	.set_status		= wrhv_set_status,
+	.reset			= wrhv_reset,
+	.find_vqs		= wrhv_find_vqs,
+	.del_vqs		= wrhv_del_vqs,
+};
+
+/*
+ * The root device for the wrhv virtio devices. This makes them appear as
+ * /sys/devices/wrhv/0,1,2 not /sys/devices/0,1,2.
+ */
+static struct device *wrhv_root;
+
+static int wrhv_device_sanity_check(struct wrhv_device_desc *d)
+{
+	if (d->num_vq > WRHV_DEVICE_MAX_VQS ||
+		d->feature_len > WRHV_DEVICE_MAX_FEATURES_LEN ||
+		d->config_len > WRHV_DEVICE_MAX_CONFIG_LEN) {
+		pr_err("incorrect description for wrhv device type %u\n",
+			d->type);
+		return -1;
+	}
+	return 0;
+}
+
+
+int wrhv_add_device(struct wrhv_device_desc *d, struct wrhv_device_ops *ops)
+{
+	struct wrhv_device *vdev;
+
+	if (wrhv_device_sanity_check(d))
+		return -1;
+
+	vdev = kzalloc(sizeof(*vdev), GFP_KERNEL);
+	if (!vdev) {
+		pr_err("Cannot allocate wrhv dev type %u\n", d->type);
+		return -ENOMEM;
+	}
+
+	vdev->vdev.dev.parent = wrhv_root;
+	vdev->vdev.id.device = d->type;
+	vdev->vdev.config = &wrhv_config_ops;
+	vdev->desc = d;
+	vdev->ops = ops;
+
+	vdev->idc = ops->alloc_idc(vdev);
+	if (!vdev->idc)
+		return -ENOMEM;
+
+	if (register_virtio_device(&vdev->vdev)  != 0) {
+		pr_err("Failed to register wrhv dev type %u\n", d->type);
+		kfree(vdev);
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(wrhv_add_device);
+
+static int __init wrhv_devices_init(void)
+{
+	wrhv_root = root_device_register("wrhv");
+	if (IS_ERR(wrhv_root))
+		panic("Could not register wrhv root");
+
+	return 0;
+}
+postcore_initcall(wrhv_devices_init);
diff --git a/drivers/wrhv/wrhv_devices.h b/drivers/wrhv/wrhv_devices.h
new file mode 100644
index 0000000..2f9efe2
--- /dev/null
+++ b/drivers/wrhv/wrhv_devices.h
@@ -0,0 +1,105 @@
+/*
+ *  Copyright (C) 2011 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#ifndef _LINUX_WRHV_DEVICES
+#define _LINUX_WRHV_DEVICES
+
+#define WRHV_DEVICE_MAX_NAME_LEN	16
+#define WRHV_DEVICE_MAX_VQS		4
+#define WRHV_DEVICE_MAX_FEATURES_LEN	4
+#define WRHV_DEVICE_MAX_CONFIG_LEN	4
+
+/*
+ * This is how we expect the device configuration field for a virtqueue
+ * to be laid out in config space.
+ */
+struct wrhv_vqconfig {
+	/* The number of bytes for the buffer */
+	__u32 num;
+	/* The interrupt we get when something happens. */
+	__u32 irq;
+};
+
+struct wrhv_device_desc {
+	char name[WRHV_DEVICE_MAX_NAME_LEN];
+	/* The device type: console, network, disk etc. Type 0 terminates. */
+	__u8 type;
+	/* The number of virtqueus (first in config array) */
+	__u8 num_vq;
+	/*
+	 * The number of bytes of feature bits.  Multiply by 2: one for host
+	 * features and one for Guest acknowledgements.
+	 */
+	__u8 feature_len;
+	/* The number of bytes of the config array after virtqueues. */
+	__u8 config_len;
+	/* A status byte, written by the Guest. */
+	__u8 status;
+	struct wrhv_vqconfig vqconfig[WRHV_DEVICE_MAX_VQS];
+	__u8 features[WRHV_DEVICE_MAX_FEATURES_LEN * 2];
+	__u8 config[WRHV_DEVICE_MAX_CONFIG_LEN];
+};
+
+struct wrhv_device;
+struct wrhv_virtqueue;
+
+struct wrhv_device_ops {
+	int (*init_dev)(struct wrhv_device *vdev);
+	struct intr_device_channel_buffer *(*alloc_idc)(struct wrhv_device *vdev);
+	int (*init_idc)(struct wrhv_device *vdev, unsigned int index,
+			struct wrhv_virtqueue *vq);
+};
+
+#define WRHV_DEVICE_MODE_INT	1
+
+struct wrhv_device {
+	unsigned int mode;
+	struct virtio_device vdev;
+	struct wrhv_device_desc *desc;
+	struct intr_device_channel_buffer *idc;
+	vbi_pdc_handle	pdc_handle;
+	struct wrhv_device_ops *ops;
+};
+
+#define to_wrhvdev(vd) container_of(vd, struct wrhv_device, vdev)
+
+#define WRHV_DEVICE_VQ_IN	1
+#define WRHV_DEVICE_VQ_OUT	2
+#define WRHV_DEVICE_VQ_NOFREE	4
+
+struct wrhv_virtqueue {
+	struct virtqueue vq;
+	void *buf;	/* the virtqueue idc buffer */
+	size_t len;	/* the idc buffer length */
+	unsigned int mode;	/* in or out */
+	u32 *ph;	/* head pointer, must be consistent with ptr in idc */
+	u32 *pt;	/* tail pointer, must be consistent with ptr in idc */
+	void *read_buf;	/* the buffer used by guest for read */
+	u32 read_len;	/* the read buffer len */
+	void *data;	/* Token for callbacks */
+};
+
+#define to_wrhvvq(v) container_of(v, struct wrhv_virtqueue, vq)
+
+
+extern int wrhv_add_device(struct wrhv_device_desc *d,
+			struct wrhv_device_ops *ops);
+extern int wrhv_init_device(struct wrhv_device *vdev);
+extern int wrhv_init_vq(struct wrhv_device *vdev, unsigned int index,
+			struct wrhv_virtqueue *vq);
+#endif /* _LINUX_WRHV_DEVICES */
diff --git a/drivers/wrhv/wrhv_duart.c b/drivers/wrhv/wrhv_duart.c
new file mode 100644
index 0000000..b84d473
--- /dev/null
+++ b/drivers/wrhv/wrhv_duart.c
@@ -0,0 +1,163 @@
+/*
+ *  Copyright (C) 2011 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/irq.h>
+#include <linux/wrhv.h>
+#include <vbi/vbi.h>
+#include <vbi/errors.h>
+#include <vbi/pdc.h>
+
+extern struct vb_config *wr_config;
+
+/* interface to wrhv duart actual device driver */
+#define WRHV_DUART_RX_SIZE	(16)
+#define WRHV_DUART_TX_SIZE	(1024)
+static char rxBuf[WRHV_DUART_RX_SIZE];
+static char txBuf[WRHV_DUART_TX_SIZE];
+char wrhv_duart_name[256];
+vbi_pdc_handle duart_pdc;
+int is_wrhv_duart_inited;
+
+struct intr_device_channel_buffer idc = {
+	.rxBuf = (void *)rxBuf,
+	.rxBufLen = WRHV_DUART_RX_SIZE,
+	.rxBufWrPtr = (size_t)0,
+	.rxBufRdPtr = (size_t)0,
+	.txBuf = (void *)txBuf,
+	.txBufLen = WRHV_DUART_TX_SIZE,
+	.txBufWrPtr = (size_t)0,
+	.txBufRdPtr = (size_t)0
+};
+
+void __attribute__((weak)) wrhv_get_serial_devices(void)  { return; }
+__attribute__((weak)) char *wrhv_get_serial_dev_name(int index)
+{
+	return NULL;
+}
+
+void wrhv_duart_putc(char c)
+{
+	if (((idc.txBufWrPtr + 1) % WRHV_DUART_TX_SIZE) == idc.txBufRdPtr) {
+		/* tx ring buffer full */
+		return ;
+	}
+
+	if (c == '\n') {
+		wrhv_duart_putc('\r');
+	}
+
+	txBuf[idc.txBufWrPtr] = c;
+	idc.txBufWrPtr = (idc.txBufWrPtr + 1) % WRHV_DUART_TX_SIZE;
+
+	vbi_pdc_op(duart_pdc, PDC_REQUEST_WRITE,
+		0, (void *)idc.txBuf, (size_t)idc.txBufLen, 0);
+
+}
+
+void wrhv_duart_puts(char *str)
+{
+	while (*str != 0) {
+		wrhv_duart_putc(*str);
+		str++;
+	}
+}
+
+int wrhv_duart_tstc(void)
+{
+	if (idc.rxBufWrPtr == idc.rxBufRdPtr) {
+		/* rx ring buffer empty */
+		return 0;
+	}
+	return 1;
+}
+
+int wrhv_duart_getc(void)
+{
+	int value;
+
+	if (!wrhv_duart_tstc()) {
+		return 0;
+	}
+	value = rxBuf[idc.rxBufRdPtr++];
+	idc.rxBufRdPtr = idc.rxBufRdPtr % WRHV_DUART_RX_SIZE;
+	return value;
+}
+
+void wrhv_duart_init(void)
+{
+	const char *opt;
+	char *pstring;
+	unsigned char bootline[VB_MAX_BOOTLINE_LENGTH];
+
+	/* this functions can be called very early, even before
+	 * the platform code. The command line options needed
+	 * to be directly from VBI_BOOTLINE
+	 */
+	strncpy(bootline, wr_config->bootLine, VB_MAX_BOOTLINE_LENGTH - 1);
+	bootline[VB_MAX_BOOTLINE_LENGTH - 1] = 0;
+
+	/* get the duart name, the duart name is
+	 * specified in the hypervisor xml
+	 */
+	memset(wrhv_duart_name, 0, sizeof(wrhv_duart_name));
+	pstring = wrhv_duart_name;
+	opt = strstr(bootline, "duart=");
+	if (opt) {
+		opt += 6;
+		while (*opt && (*opt != ' ')) {
+			*pstring = *opt;
+			pstring++;
+			opt++;
+		}
+	} else {
+		opt = strstr(bootline, "console=hvc");
+		if (opt) {
+			char *p;
+
+			opt += 11;
+			if (*opt < '0' || *opt > '9')
+				return;
+			wrhv_get_serial_devices();
+			p = wrhv_get_serial_dev_name(*opt - '0');
+			strcpy(pstring, p);
+		} else
+			return;
+	}
+
+	/* only init the duart once */
+	if (is_wrhv_duart_inited) {
+		return;
+	}
+	is_wrhv_duart_inited = 1;
+
+
+	/* init channel */
+	if (vbi_pdc_init(wrhv_duart_name, &duart_pdc)) {
+		printk("vbi_pdc_init failed\n");
+		return;
+	}
+
+	/* init device */
+	if (vbi_pdc_op(duart_pdc, PDC_REQUEST_INIT,
+		0, (void *) &idc, 0, 0)) {
+		printk("vbi_pdc_op: PDC_REQUEST_INIT failed\n");
+		return;
+	}
+}
diff --git a/drivers/wrhv/wrhv_frame_irq.c b/drivers/wrhv/wrhv_frame_irq.c
new file mode 100644
index 0000000..71c0892
--- /dev/null
+++ b/drivers/wrhv/wrhv_frame_irq.c
@@ -0,0 +1,91 @@
+/*
+ *  Copyright (C) 2011 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/irq.h>
+#include <linux/interrupt.h>
+#include <linux/wrhv.h>
+#include <vbi/vbi.h>
+#include <vbi/errors.h>
+
+#define START_FRAME_IRQ_NAME	"start"
+#define END_FRAME_IRQ_NAME	"end"
+
+/* a simple start of frame interrupt handler */
+static irqreturn_t start_frame_interrupt(int irq, void *p)
+{
+	return IRQ_HANDLED;
+}
+
+/* a simple end of frame interrupt handler */
+static irqreturn_t end_frame_interrupt(int irq, void *p)
+{
+	return IRQ_HANDLED;
+}
+
+/* certifiable hypervisor support start and end frame transition interrupts.
+   User can make use of this interrupt to maintain house keeping related tasks.
+*/
+static int __init frame_transition_test_init(void)
+{
+	int rc;
+	int start_irq;
+	int end_irq;
+
+	printk(KERN_INFO "Initialize frame transition interrupt test");
+
+	/* scheduled transition vbi, the schedule name "init" is
+	 * defined in the scheduler section of wrhvConfig.xml
+	 */
+	rc = vbi_sched_transition("init", SCHEDULER_TRANSITION_MAJOR,
+		VBI_VCORE_ID_GET());
+
+	if (rc) {
+		printk(KERN_WARNING
+			"Failed to schedule transition %s core id=%d\n", "init",
+			 VBI_VCORE_ID_GET());
+	}
+
+	start_irq = vbi_find_irq(START_FRAME_IRQ_NAME, 1);
+	if (start_irq != VBI_INVALID_IRQ) {
+		/* request start frame interrupt handler */
+		rc = request_irq(start_irq, start_frame_interrupt,
+				IRQF_SHARED, "start_frame_interrupt",
+				start_frame_interrupt);
+		if (rc) {
+			printk(KERN_WARNING 
+				"Failed to request start frame irq at %d\n", start_irq);
+		}
+	}
+
+	end_irq = vbi_find_irq(END_FRAME_IRQ_NAME, 1);
+	if (end_irq != VBI_INVALID_IRQ) {
+		/* request end frame interrupt handler */
+		rc = request_irq(end_irq, end_frame_interrupt,
+				IRQF_SHARED, "end_frame_interrupt",
+				end_frame_interrupt);
+		if (rc) {
+			printk(KERN_WARNING 
+				"Failed to request start frame irq at %d\n", end_irq);
+		}
+	}
+
+	return rc;
+}
+module_init(frame_transition_test_init);
diff --git a/drivers/wrhv/wrhv_serial.c b/drivers/wrhv/wrhv_serial.c
new file mode 100644
index 0000000..7eef360
--- /dev/null
+++ b/drivers/wrhv/wrhv_serial.c
@@ -0,0 +1,244 @@
+/*
+ *  Copyright (C) 2011 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/interrupt.h>
+#include <linux/virtio.h>
+#include <linux/virtio_config.h>
+#include <linux/virtio_ids.h>
+#include <linux/virtio_console.h>
+#include <vbi/vbi.h>
+#include <vbi/pdc.h>
+#include <vbi/duart.h>
+#include <linux/scatterlist.h>
+#include <linux/hrtimer.h>
+#include "wrhv_devices.h"
+
+static struct hrtimer *wrhv_serial_timer;
+
+extern vbi_pdc_handle duart_pdc;
+extern struct intr_device_channel_buffer idc;
+extern char wrhv_duart_name[];
+
+#ifdef CONFIG_WRHV_VIRTIO_SERIAL_CONSOLE
+/* interface to wrhv duart actual device driver */
+#define WRHV_DUART_RX_SIZE	(16)
+#define WRHV_DUART_TX_SIZE	(1024)
+
+void wrhv_duart_putc(char c);
+void wrhv_duart_init(void);
+
+static int __init wrhv_early_put_chars(u32 vtermo, const char *buf, int count)
+{
+	int i;
+
+	for (i = 0; i < count; i++, buf++)
+		wrhv_duart_putc(*buf);
+
+	return count;
+}
+
+static int __init wrhv_virtio_console_init(void)
+{
+	wrhv_duart_init();
+
+	return virtio_cons_early_init(wrhv_early_put_chars);
+}
+console_initcall(wrhv_virtio_console_init);
+#endif
+
+#define WRHV_MAX_SERIAL_DEVICES 4
+struct wrhv_serial_dev {
+	char name[16];
+	int irq;
+};
+struct wrhv_serial_dev wrhv_serial_devs[WRHV_MAX_SERIAL_DEVICES];
+
+#define WRHV_CLASS_SERIAL	0
+#define WRHV_TYPE_ADD		1
+
+extern struct vb_config *wr_vb_config;
+void wrhv_get_serial_devices(void)
+{
+	struct vb_dev_info *pdev = wr_vb_config->deviceConfiguration;
+	struct vb_dev_int_info *pint;
+	int num = wr_vb_config->numDevices, i, j;
+	struct wrhv_serial_dev *p;
+	static int done;
+
+	if (done)
+		return;
+	else
+		done = 1;
+
+	j = 0;
+	for (i = 0; i < num; i++, pdev++) {
+		if (pdev->deviceClass != WRHV_CLASS_SERIAL ||
+			pdev->deviceType != WRHV_TYPE_ADD)
+			continue;
+
+		p = &wrhv_serial_devs[j];
+		strcpy(p->name, pdev->deviceName);
+		if (pdev->numInterrupts) {
+			pint = (struct vb_dev_int_info *)((char *)pdev +
+					pdev->intInfoOffset);
+			p->irq = pint ? pint->intNum : 0;
+		}
+		j++;
+		if (j >= WRHV_MAX_SERIAL_DEVICES)
+			break;
+	}
+}
+EXPORT_SYMBOL_GPL(wrhv_get_serial_devices);
+
+char *wrhv_get_serial_dev_name(int index)
+{
+	if (index < 0 || index >= WRHV_MAX_SERIAL_DEVICES)
+		return NULL;
+
+	return wrhv_serial_devs[index].name;
+}
+EXPORT_SYMBOL(wrhv_get_serial_dev_name);
+
+static int is_console_device(struct wrhv_device *vdev)
+{
+	return !strcmp(vdev->desc->name, wrhv_duart_name);
+}
+
+extern void hvc_kick(void);
+static enum hrtimer_restart wrhv_serial_kick(struct hrtimer *t)
+{
+	ktime_t now;
+
+	hvc_kick();
+
+	now = hrtimer_cb_get_time(t);
+	hrtimer_forward(t, now, ktime_set(0, 50000000));
+	return HRTIMER_RESTART;
+}
+
+static int wrhv_serial_init_device(struct wrhv_device *vdev)
+{
+	if (is_console_device(vdev))
+		vdev->pdc_handle = duart_pdc;
+	else {
+		/* init channel */
+		if (vbi_pdc_init(vdev->desc->name, &vdev->pdc_handle))
+			return -1;
+
+		/* init device */
+		if (vbi_pdc_op(vdev->pdc_handle, PDC_REQUEST_INIT, 0,
+			vdev->idc, 0, 0))
+			return -1;
+	}
+
+	if (!(vdev->mode & WRHV_DEVICE_MODE_INT) && !wrhv_serial_timer) {
+		struct hrtimer *t = kzalloc(sizeof(*t), GFP_KERNEL);
+
+		if (!t)
+			return -1;
+		hrtimer_init(t, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
+		t->function = wrhv_serial_kick;
+		hrtimer_start(t, ktime_set(0, 1000000000), HRTIMER_MODE_REL);
+		wrhv_serial_timer = t;
+	}
+
+	return wrhv_init_device(vdev);
+}
+
+static struct intr_device_channel_buffer *wrhv_serial_alloc_idc(struct wrhv_device *vdev)
+{
+	if (is_console_device(vdev))
+		vdev->idc = &idc;
+	else
+		vdev->idc = kzalloc(sizeof(*vdev->idc), GFP_KERNEL);
+
+	return vdev->idc;
+}
+
+static int wrhv_serial_init_idc(struct wrhv_device *vdev, unsigned int index,
+				struct wrhv_virtqueue *vq)
+{
+	if (is_console_device(vdev)) {
+		switch (index) {
+		case 0:
+			vq->buf = vdev->idc->rxBuf;
+			break;
+		case 1:
+			vq->buf = vdev->idc->txBuf;
+			break;
+		}
+		vq->mode |= WRHV_DEVICE_VQ_NOFREE;
+	} else {
+		vq->buf = kmalloc(vq->len, GFP_KERNEL);
+		if (!vq->buf)
+			return -ENOMEM;
+	}
+
+	wrhv_init_vq(vdev, index, vq);
+	return 0;
+}
+
+static struct wrhv_device_ops wrhv_serial_ops = {
+	.init_dev	= wrhv_serial_init_device,
+	.alloc_idc	= wrhv_serial_alloc_idc,
+	.init_idc	= wrhv_serial_init_idc,
+};
+
+struct wrhv_device_desc wrhv_init_serial_device = {
+	.name		= "uart0",
+	.type		= VIRTIO_ID_CONSOLE,
+	.num_vq		= 2,
+	.feature_len	= 1,
+	.config_len	= 1,
+	.vqconfig[0]	= {
+	.num		= 16,
+		.irq	= 20,
+	},
+	.vqconfig[1]	= {
+		.num	= 1024,
+	},
+};
+
+static __init int wrhv_add_serial(void)
+{
+	struct wrhv_device_desc *desc;
+	struct wrhv_serial_dev *p;
+	int i;
+
+	wrhv_get_serial_devices();
+
+	p = wrhv_serial_devs;
+	for (i = 0; i < WRHV_MAX_SERIAL_DEVICES; i++, p++) {
+		if (!p->name[0])
+			break;
+
+		desc = kzalloc(sizeof(*desc), GFP_KERNEL);
+		if (!desc)
+			return -ENOMEM;
+
+		*desc = wrhv_init_serial_device;
+		sprintf(desc->name, p->name);
+		desc->vqconfig[0].irq = p->irq;
+		wrhv_add_device(desc, &wrhv_serial_ops);
+	}
+
+	return 0;
+}
+module_init(wrhv_add_serial);
diff --git a/include/linux/interrupt.h b/include/linux/interrupt.h
index 01db7a1..16bffa8 100644
--- a/include/linux/interrupt.h
+++ b/include/linux/interrupt.h
@@ -181,7 +181,7 @@ extern void devm_free_irq(struct device *dev, unsigned int irq, void *dev_id);
  * places left. So the only effect should be slightly increased
  * irqs-off latencies.
  */
-#ifdef CONFIG_LOCKDEP
+#if defined(CONFIG_LOCKDEP) || defined(CONFIG_PARAVIRT)
 # define local_irq_enable_in_hardirq()	do { } while (0)
 #else
 # define local_irq_enable_in_hardirq()	local_irq_enable()
diff --git a/include/linux/wrhv.h b/include/linux/wrhv.h
index ed3faa5..8564d7e 100644
--- a/include/linux/wrhv.h
+++ b/include/linux/wrhv.h
@@ -77,7 +77,7 @@ typedef union {
 		uint32_t destination:8;	/* destination field */
 	} field;
 	uint32_t value;
-} VIOAPIC_REDIR_HIGH;
+} ioapic_redir_high;
 
 typedef union {
 	struct {
@@ -96,6 +96,6 @@ typedef union {
 	} field;
 
 	uint32_t value;
-} VIOAPIC_REDIR_LOW;
+} vioapic_redir_low;
 
 #endif	/* __LINUX_WRHV_H */
diff --git a/include/vbi/duart.h b/include/vbi/duart.h
new file mode 100644
index 0000000..99c6b89
--- /dev/null
+++ b/include/vbi/duart.h
@@ -0,0 +1,24 @@
+#ifndef DAURT_H
+#define DAURT_H
+
+/* taken from wrhv-1.2/include/sys/devices/drivers/serial.h */
+#define SIO_MODE_POLL   1       /* polling mode */
+#define SIO_MODE_INT    2       /* interrupt mode */
+
+/* options to SIO_HW_OPTS_SET (ala POSIX), bitwise or'ed together */
+
+#define SIO_HW_OPTS_CLOCAL 0x1 /* ignore modem status lines */
+#define SIO_HW_OPTS_CREAD  0x2 /* enable device reciever */
+
+#define SIO_HW_OPTS_CSIZE  0xc /* bits 3 and 4 encode the character size */
+#define SIO_HW_OPTS_CS5    0x0 /* 5 bits */
+#define SIO_HW_OPTS_CS6    0x4 /* 6 bits */
+#define SIO_HW_OPTS_CS7    0x8 /* 7 bits */
+#define SIO_HW_OPTS_CS8    0xc /* 8 bits */
+
+#define SIO_HW_OPTS_HUPCL  0x10 /* hang up on last close */
+#define SIO_HW_OPTS_STOPB  0x20 /* send two stop bits (else one) */
+#define SIO_HW_OPTS_PARENB 0x40 /* parity detection enabled (else disabled) */
+#define SIO_HW_OPTS_PARODD 0x80 /* odd parity  (else even) */
+
+#endif /* DUART_H */
diff --git a/init/Kconfig.wrhv b/init/Kconfig.wrhv
index 72f60bd..3b37511 100644
--- a/init/Kconfig.wrhv
+++ b/init/Kconfig.wrhv
@@ -28,3 +28,24 @@ config DEBUG_VIRTUAL_IRQS
 	bool "Debug VIOAPIC with software IRQ"
 	default n
 	depends on WRHV
+
+config WRHV_ASID_OPTIMIZATION
+	bool "ASID performance optimization"
+	default n
+	depends on WRHV && E500
+	help
+	  ASID performance optimization.  The cost of invalidating and
+	  re-filling TLB cache's on behalf of the guest is an extremely
+	  expensive operation which results in a performance degradation.
+	  ASIDs enable TLB entries to remain resident during context switches,
+	  avoiding the penalty
+
+
+config WRHV_NUM_ASID
+	int "Number of ASID handles"
+	range 1 63
+	default "62"
+	depends on WRHV_ASID_OPTIMIZATION
+	help
+	   This defines the number of ASID handles used by this specific
+	   virtual board.
diff --git a/kernel/module.c b/kernel/module.c
index 1bb0f7f..13170d5 100644
--- a/kernel/module.c
+++ b/kernel/module.c
@@ -2059,7 +2059,12 @@ static noinline struct module *load_module(void __user *umod,
 
 	/* Suck in entire file: we'll want most of it. */
 	/* vmalloc barfs on "unusual" numbers.  Check here */
+
+#if defined(CONFIG_WRHV) && defined(CONFIG_PPC)
+	if (len > 64 * 1024 * 1024 || (hdr = kmalloc(len, GFP_KERNEL)) == NULL)
+#else
 	if (len > 64 * 1024 * 1024 || (hdr = vmalloc(len)) == NULL)
+#endif
 		return ERR_PTR(-ENOMEM);
 
 	/*
@@ -2452,12 +2457,19 @@ static noinline struct module *load_module(void __user *umod,
 	 * Do it before processing of module parameters, so the module
 	 * can provide parameter accessor functions of its own.
 	 */
-	if (mod->module_init)
+	if (mod->module_init) {
 		flush_icache_range((unsigned long)mod->module_init,
 				   (unsigned long)mod->module_init
 				   + mod->init_size);
+#if defined(CONFIG_WRHV) && defined(CONFIG_PPC)
+		flush_dcache_page(virt_to_page(mod->module_init));
+#endif
+	}
 	flush_icache_range((unsigned long)mod->module_core,
 			   (unsigned long)mod->module_core + mod->core_size);
+#if defined(CONFIG_WRHV) && defined(CONFIG_PPC)
+	flush_dcache_page(virt_to_page(mod->module_core));
+#endif
 
 	set_fs(old_fs);
 
@@ -2501,7 +2513,11 @@ module_added:
 	add_notes_attrs(mod, hdr->e_shnum, secstrings, sechdrs);
 
 	/* Get rid of temporary copy */
+#if defined(CONFIG_WRHV) && defined(CONFIG_PPC)
+	kfree(hdr);
+#else
 	vfree(hdr);
+#endif
 
 	trace_module_load(mod);
 
@@ -2535,7 +2551,11 @@ module_added:
 	kfree(args);
 	kfree(strmap);
  free_hdr:
+#if defined(CONFIG_WRHV) && defined(CONFIG_PPC)
+	kfree(hdr);
+#else
 	vfree(hdr);
+#endif
 	return ERR_PTR(err);
 
  truncated:
diff --git a/kernel/vbi/wrhv.c b/kernel/vbi/wrhv.c
index aa8db0c..b1b2211 100644
--- a/kernel/vbi/wrhv.c
+++ b/kernel/vbi/wrhv.c
@@ -251,14 +251,6 @@ int wrhv_irq_set_affinity(unsigned int irq,
 	int cpu;
 	struct wrhv_irq_head *head = &wrhv_irq_head;
 
-	/* Currently we don't support set affinity in direct irq mode */
-	if (wrhv_dir_irq) {
-		printk(KERN_WARNING "Currently we don't support set affinity"
-			" in direct irq mode on e500mc.\n");
-
-		return -1;
-	}
-
 	if (cpumask_equal(desc->affinity, dest))
 		return 0;
 
@@ -367,18 +359,24 @@ unsigned long wrhv_calculate_cpu_khz(void)
 
 irqreturn_t __weak wrhv_timer_interrupt(int irq, void *dev_id)
 {
-	static long long mark_offset;
+	static DEFINE_PER_CPU(long long, mark_offset);
+	int cpu;
 	long long ticks;
 	int lost_jiffies = 0;
 	struct pt_regs *regs = get_irq_regs();
 
+	cpu = smp_processor_id();
 	ticks = wr_vb_status->tick_count;
-	ticks -= mark_offset;
+	ticks -= per_cpu(mark_offset,cpu);
 	lost_jiffies = ticks - 1;
-	mark_offset = wr_vb_status->tick_count;
+	per_cpu(mark_offset,cpu) = wr_vb_status->tick_count;
 
 	do {
-		do_timer(1);
+		if (!smp_processor_id()) {
+			write_seqlock(&xtime_lock);
+			do_timer(1);
+			write_sequnlock(&xtime_lock);
+		}
 		update_process_times(user_mode(regs));
 		profile_tick(CPU_PROFILING);
 		if (lost_jiffies > (2*HZ)) {
diff --git a/mm/vmalloc.c b/mm/vmalloc.c
index 007fa26..ae38b7c 100644
--- a/mm/vmalloc.c
+++ b/mm/vmalloc.c
@@ -170,6 +170,11 @@ static int vmap_page_range_noflush(unsigned long start, unsigned long end,
 		err = vmap_pud_range(pgd, addr, next, prot, pages, &nr);
 		if (err)
 			return err;
+#if defined(CONFIG_WRHV_E500) && !defined(CONFIG_PHYS_64BIT) \
+			      && !defined(CONFIG_PPC85xx_VT_MODE)
+		if (current->active_mm != &init_mm)
+			*pgd_offset(current->active_mm, addr) = *pgd;
+#endif
 	} while (pgd++, addr = next, addr != end);
 
 	return nr;
-- 
1.7.0.4

