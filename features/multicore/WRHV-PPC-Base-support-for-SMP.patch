From cdbe90d88a492aa993242d4a29fcc438fcb1e1e6 Mon Sep 17 00:00:00 2001
From: Tiejun Chen <tiejun.chen@windriver.com>
Date: Wed, 12 May 2010 16:39:49 +0800
Subject: [PATCH] WRHV/PPC: Base support for SMP

Provide basic e500 SMP support which will be shared by all
non e500mc hypervisor guests.

Currently the only supported SMP guest is the fsl_8572ds.

Our implementation differs from upstream in that it does
not make use of the MPIC for IPIs, rather it uses the VIOAPIC
as its IPI communication mechanism.

Signed-off-by: Jeremy McNicoll <jeremy.mcnicoll@windriver.com>
---
 arch/powerpc/include/asm/arch_vbi.h         |    2 +
 arch/powerpc/include/asm/ppc_asm.h          |    3 +-
 arch/powerpc/include/asm/pte-common.h       |   11 +-
 arch/powerpc/include/asm/pv_pgtable-ppc32.h |    5 +-
 arch/powerpc/include/asm/reg_wrhv.h         |   19 ++-
 arch/powerpc/include/asm/time.h             |   22 ++
 arch/powerpc/include/asm/wrhv.h             |    5 +
 arch/powerpc/kernel/head_wrhv.S             |   74 ++++---
 arch/powerpc/kernel/head_wrhv.h             |    8 +
 arch/powerpc/kernel/smp-tbsync.c            |    7 +
 arch/powerpc/kernel/smp.c                   |    6 +
 arch/powerpc/kernel/vbi/wrhv.c              |  344 +++++++++++++++++++++++++++
 arch/powerpc/kernel/wrhv_entry_32.S         |   44 ++--
 kernel/vbi/wrhv.c                           |   11 +-
 14 files changed, 491 insertions(+), 70 deletions(-)

diff --git a/arch/powerpc/include/asm/ppc_asm.h b/arch/powerpc/include/asm/ppc_asm.h
index 498fe09..0127eb4 100644
--- a/arch/powerpc/include/asm/ppc_asm.h
+++ b/arch/powerpc/include/asm/ppc_asm.h
@@ -339,7 +339,8 @@ END_FTR_SECTION_NESTED(CPU_FTR_CELL_TB_BUG, CPU_FTR_CELL_TB_BUG, 96)
 #define MFTB(dest)			mftb dest
 #endif
 
-#ifndef CONFIG_SMP
+#if !defined(CONFIG_SMP) || defined(CONFIG_WRHV)
+/* The hypervisor will do that. */
 #define TLBSYNC
 #else /* CONFIG_SMP */
 /* tlbsync is not implemented on 601 */
diff --git a/arch/powerpc/include/asm/pte-common.h b/arch/powerpc/include/asm/pte-common.h
index 53c0a46..75faae7 100644
--- a/arch/powerpc/include/asm/pte-common.h
+++ b/arch/powerpc/include/asm/pte-common.h
@@ -104,11 +104,14 @@ extern unsigned long bad_call_to_PMD_PAGE_SIZE(void);
  * pages. We always set _PAGE_COHERENT when SMP is enabled or
  * the processor might need it for DMA coherency.
  */
+
+#if defined(CONFIG_WRHV_E500)
+#define _PAGE_BASE_NC	(_PAGE_PRESENT | _PAGE_ACCESSED | VMMU_PROT_USER_READ)
+#else
 #define _PAGE_BASE_NC	(_PAGE_PRESENT | _PAGE_ACCESSED | _PAGE_PSIZE)
-#if defined(CONFIG_SMP) || defined(CONFIG_PPC_STD_MMU)
-#define _PAGE_BASE	(_PAGE_BASE_NC | _PAGE_COHERENT)
-#elif defined(CONFIG_WRHV_E500)
-#define _PAGE_BASE (_PAGE_PRESENT | _PAGE_ACCESSED | VMMU_PROT_USER_READ)
+#endif
+#if defined(CONFIG_SMP)
+#define _PAGE_BASE (_PAGE_BASE_NC | _PAGE_COHERENT)
 #else
 #define _PAGE_BASE	(_PAGE_BASE_NC)
 #endif
diff --git a/arch/powerpc/include/asm/pv_pgtable-ppc32.h b/arch/powerpc/include/asm/pv_pgtable-ppc32.h
index 81c44a1..8a8fc1f 100644
--- a/arch/powerpc/include/asm/pv_pgtable-ppc32.h
+++ b/arch/powerpc/include/asm/pv_pgtable-ppc32.h
@@ -12,7 +12,8 @@
  */
 /*
  * need extra care for _PAGE_SPECIAL -- Liang Li
- */ #define _PAGE_SPECIAL    0x0
+ */
+#define _PAGE_SPECIAL		0x0
 #define _PAGE_PRESENT		VMMU_PROT_SUPV_READ
 #define _PAGE_USER		(VMMU_PROT_USER_READ|VMMU_PROT_USER_EXECUTE)
 #define _PAGE_FILE      	_PAGE_USER
@@ -38,7 +39,9 @@
 #define _PMD_PRESENT_MASK	(_PMD_PRESENT)
 #define _PMD_BAD		(~PAGE_MASK & ~0x03)
 
+#ifndef CONFIG_WRHV_E500
 #define _PAGE_BASE		(_PAGE_PRESENT | _PAGE_ACCESSED | VMMU_PROT_USER_READ)
+#endif
 
 #define PFN_SIZE		(1UL << PFN_SHIFT_OFFSET)
 #define PFN_MASK		(~(PFN_SIZE-1))
diff --git a/arch/powerpc/include/asm/reg_wrhv.h b/arch/powerpc/include/asm/reg_wrhv.h
index 4d88f9e..d9d4847 100644
--- a/arch/powerpc/include/asm/reg_wrhv.h
+++ b/arch/powerpc/include/asm/reg_wrhv.h
@@ -40,10 +40,24 @@
 #define PARAVIRT_CLEAR_INST_COMPLETION                 do{ } while (0)
 
 #ifdef __ASSEMBLY__
-.extern	var(wrhv_sprg3)
-.extern	var(wrhv_user)
+#define wrhv_supervisor (0xF0002000 +VB_CONTROL_RESERVED7)
+.extern var(wrhv_sprg3)
+.extern var(wrhv_user)
 .extern var(wrhv_pir)
 
+#ifdef CONFIG_SMP
+/*temporary solution for MFSPRG3,PIR ,wrhv-reserverd:0xf0002068 */
+#define WRHY_SPRG3 (0xF0002000 + VB_CONTROL_RESERVED8)
+#define WRHV_MFSPRG3(rd)	\
+	lis	rd,WRHY_SPRG3@ha;	\
+	lwz	rd,WRHY_SPRG3@l(rd)
+
+#define WRHV_MTSPRG3(rs,tmpr)	\
+	lis	tmpr,WRHY_SPRG3@ha;             \
+	stw	rs,WRHY_SPRG3@l(tmpr)
+
+#else
+
 #define WRHV_MFSPRG3(rd)                        \
 	lis	rd,wrhv_sprg3@ha;               \
 	lwz	rd,wrhv_sprg3@l(rd)
@@ -51,6 +65,7 @@
 #define WRHV_MTSPRG3(rs,tmpr)                   \
 	lis	tmpr,wrhv_sprg3@ha;             \
 	stw	rs,wrhv_sprg3@l(tmpr)
+#endif
 
 #ifdef CONFIG_SMP
 #define WRHV_MFPIR(rd)				\
diff --git a/arch/powerpc/include/asm/time.h b/arch/powerpc/include/asm/time.h
index 27ccb76..95eba1a 100644
--- a/arch/powerpc/include/asm/time.h
+++ b/arch/powerpc/include/asm/time.h
@@ -110,6 +110,9 @@ static inline u64 get_rtc(void)
 	return (u64)hi * 1000000000 + lo;
 }
 
+long long wrhv_gettb_diff(void);
+void wrhv_settb_diff(long long diff);
+
 #ifdef CONFIG_PPC64
 static inline u64 get_tb(void)
 {
@@ -126,7 +129,17 @@ static inline u64 get_tb(void)
 		tbhi2 = get_tbu();
 	} while (tbhi != tbhi2);
 
+#ifndef CONFIG_WRHV
 	return ((u64)tbhi << 32) | tblo;
+#else
+	{
+	int cpuid = smp_processor_id();
+	if(cpuid)
+		return (((u64)tbhi << 32) | tblo) + wrhv_gettb_diff();
+	else
+		return ((u64)tbhi << 32) | tblo;
+	}
+#endif
 }
 #endif /* !CONFIG_PPC64 */
 
@@ -137,9 +150,16 @@ static inline u64 get_tb_or_rtc(void)
 
 static inline void set_tb(unsigned int upper, unsigned int lower)
 {
+#ifndef CONFIG_WRHV
 	mtspr(SPRN_TBWL, 0);
 	mtspr(SPRN_TBWU, upper);
 	mtspr(SPRN_TBWL, lower);
+#else
+	unsigned long long tb = ((u64)upper<<32) | lower;
+	int cpuid = smp_processor_id();
+	if(cpuid)
+		wrhv_settb_diff((long long)get_tb() - (long long)tb);
+#endif
 }
 
 /* Accessor functions for the decrementer register.
@@ -181,7 +201,9 @@ static inline void set_dec(int val)
 		return;
 	}
 #endif
+#ifndef CONFIG_WRHV
 	mtspr(SPRN_DEC, val);
+#endif
 #endif /* not 40x or 8xx_CPU6 */
 }
 
diff --git a/arch/powerpc/include/asm/wrhv.h b/arch/powerpc/include/asm/wrhv.h
index 334dbe7..01ea5f7 100644
--- a/arch/powerpc/include/asm/wrhv.h
+++ b/arch/powerpc/include/asm/wrhv.h
@@ -28,6 +28,11 @@ extern void __init wrhv_calibrate_decr(void);
 extern void __init wrhv_time_init(void);
 extern int __init wrhv_earlycon_setup(void);
 
+extern int __init smp_wrhv_probe(void);
+extern void smp_wrhv_message_pass(int target, int msg);
+extern void __init smp_wrhv_setup_cpu(int cpu_nr);
+extern void wrhv_umask_IPIs_for_vcore(void);
+extern void wrhv_request_ipis(void);
 extern unsigned long wrhv_cpu_freq;
 
 extern uint32_t service_handle;
diff --git a/arch/powerpc/kernel/head_wrhv.S b/arch/powerpc/kernel/head_wrhv.S
index e3928a1..caba46d 100644
--- a/arch/powerpc/kernel/head_wrhv.S
+++ b/arch/powerpc/kernel/head_wrhv.S
@@ -100,17 +100,6 @@ _ENTRY(_start);
  */
 
 _ENTRY(__early_start)
-	/*
-	 * This is where the main kernel code starts.
-	 */
-
-	/* ptr to current */
-	lis	r2,init_task@h
-	ori	r2,r2,init_task@l
-
-	/* ptr to current thread */
-	addi	r4,r2,THREAD	/* init task's THREAD */
-	WRHV_MTSPRG3(r4,r1)
 
 	/* Establish the interrupt vector base */
 	lis	r0,VBI_SYS_hyIoctl@h
@@ -132,6 +121,17 @@ _ENTRY(__early_start)
 	bne	__secondary_start
 #endif
 
+
+	/* ptr to current */
+	lis	r2,init_task@h
+	ori	r2,r2,init_task@l
+
+	li	r4,1
+	WRHV_SET_SUP_MODE(r1,r4)
+	/* ptr to current thread */
+	addi	r4,r2,THREAD	/* init task's THREAD */
+	WRHV_MTSPRG3(r4,r1)
+
 	/* stack */
 	lis	r1,init_thread_union@h
 	ori	r1,r1,init_thread_union@l
@@ -187,10 +187,22 @@ _ENTRY(__early_start)
 #define LOAD_PTE \
 	lwz	r11, 4(r12);
 
+#ifdef CONFIG_SMP
+#define LWARX_PTE \
+	li	r11, 4;
+	lwarx	r11, r11, r12;		/* lwarx pte */
+
 #define STWCX_PTE \
 	addi	r12, r12, 4;	\
 	stwcx.	r11, 0, r12;	\
 	addi	r12, r12, -4;
+#else
+#define LWARX_PTE \
+	lwz	r11, 4(r12)
+
+#define STWCX_PTE \
+	stw	r11, 4(r12)
+#endif
 
 #else
 #define FIND_PTE	\
@@ -289,7 +301,7 @@ interrupt_base:
         /* find the TLB index that caused the fault. */
         tlbsx   0, r10
 
-	#if defined(CONFIG_SMP) && !defined(CONFIG_WRHV)
+#if defined(CONFIG_SMP)
         /*
          * It's possible another processor kicked out the entry
          * before we did our tlbsx, so check if we hit
@@ -313,7 +325,7 @@ interrupt_base:
         mtspr   SPRN_MAS3,r10
         tlbwe
 
-#if defined(CONFIG_SMP) && !defined(CONFIG_WRHV)
+#if defined(CONFIG_SMP)
         mr      r13, r11
         LWARX_PTE
         cmpw    r13, r11
@@ -324,7 +336,7 @@ interrupt_base:
         ori     r11, r11, _PAGE_DIRTY|_PAGE_ACCESSED|_PAGE_HWWRITE
         STWCX_PTE       /* r11 and r12 must be PTE and &PTE */
 
-#if defined(CONFIG_SMP) && !defined(CONFIG_WRHV)
+#if defined(CONFIG_SMP)
         /*
          * If the stwcx. failed, we invalidate the entry we just wrote,
          * and start over
@@ -334,11 +346,6 @@ interrupt_base:
         rlwinm  r13, r13, 0, 1, 31      /* Clear Valid bit */
         mtspr   SPRN_MAS1, r13
 
-        /* We have to restore GPA to MAS3 when execute continuously
-         * tlb instruction.
-         */
-        mtspr   SPRN_MAS3,r10
-
         tlbwe
 
         b       5b              /* Try again */
@@ -355,7 +362,7 @@ interrupt_base:
         rfi                     /* Force context change */
 
 2:
-#if defined(CONFIG_SMP) && !defined(CONFIG_WRHV)
+#if defined(CONFIG_SMP)
         /* Clear the reservation */
         lis     r11, dummy_stwcx@h
         ori     r11,r11, dummy_stwcx@l
@@ -486,14 +493,14 @@ finish_tlb_load:
 	 */
 
 	mfspr	r12, SPRN_MAS2
-#ifdef CONFIG_PTE_64BIT
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_WRHV)
 	rlwimi	r12, r11, 32-19, 27, 31	/* extract WIMGE from pte */
 #else
 	rlwimi	r12, r11, 26, 27, 31	/* extract WIMGE from pte */
 #endif
 	mtspr	SPRN_MAS2, r12
 
-#ifdef CONFIG_PTE_64BIT
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_WRHV)
 	rlwinm	r12, r11, 32-2, 26, 31	/* Move in perm bits */
 	andi.	r10, r11, _PAGE_DIRTY
 	bne	1f
@@ -850,19 +857,15 @@ __secondary_start:
 	li	r0,0
 	stw	r0,0(r1)
 
+	li	r4,1
+	WRHV_SET_SUP_MODE(r3,r4)
+
 	/* ptr to current thread */
 	addi	r4,r2,THREAD	/* address of our thread_struct */
-	mtspr	SPRN_SPRG_THREAD,r4
+	WRHV_MTSPRG3(r4,r3)
 
 	/* Jump to start_secondary */
-	lis	r4,MSR_KERNEL@h
-	ori	r4,r4,MSR_KERNEL@l
-	lis	r3,wrhv_start_secondary@h
-	ori	r3,r3,wrhv_start_secondary@l
-	mtspr	SPRN_SRR0,r3
-	mtspr	SPRN_SRR1,r4
-	sync
-	rfi
+	b	wrhv_start_secondary
 	sync
 
 	.globl __secondary_hold_acknowledge
@@ -883,7 +886,14 @@ empty_zero_page:
 	.space	4096
 	.globl	swapper_pg_dir
 swapper_pg_dir:
-	.space	PGD_TABLE_SIZE
+	.space	8192
+/*
+ * We need a place to stwcx. to when we want to clear a reservation
+ * without knowing where the original was.
+ */
+	.globl	dummy_stwcx
+dummy_stwcx:
+	.space	4
 
 /*
  * Room for two PTE pointers, usually the kernel and current user pointers
diff --git a/arch/powerpc/kernel/head_wrhv.h b/arch/powerpc/kernel/head_wrhv.h
index 5c4aef8..9f25c5e 100644
--- a/arch/powerpc/kernel/head_wrhv.h
+++ b/arch/powerpc/kernel/head_wrhv.h
@@ -22,6 +22,8 @@
 #define TLBSX_CODE	0x7c005724
 #endif
 
+#define WRHV_COREID_OFFSET	0x98
+
 	/* Interrupts are disabled by hypervisor at this entry point.
 	 * It puts the following registers into the status page:
 	 *   VB_STATUS_OLD_INT_DISABLE (the INT_DISABLE from Control)
@@ -96,9 +98,15 @@ label:									     \
 #else
 #ifdef CONFIG_WRHV
 #undef START_EXCEPTION
+#ifdef CONFIG_SMP 	
+#define        START_EXCEPTION(label)				\
+       .align 9;						\
+label:
+#else
 #define        START_EXCEPTION(label)                                  \
        .align 8;                                               \
 label:
+#endif
 #else
 #define        START_EXCEPTION(label)                                  \
        .align 5;                                               \
diff --git a/arch/powerpc/kernel/smp-tbsync.c b/arch/powerpc/kernel/smp-tbsync.c
index 03e45c4..d3f6425 100644
--- a/arch/powerpc/kernel/smp-tbsync.c
+++ b/arch/powerpc/kernel/smp-tbsync.c
@@ -126,6 +126,10 @@ void __devinit smp_generic_give_timebase(void)
 
 	pr_debug("Got ack\n");
 
+#ifdef CONFIG_WRHV
+	goto bypass;
+#endif
+
 	/* binary search */
 	for (old = -1; old != offset ; offset = (min+max) / 2) {
 		score = start_contest(kSetAndTest, offset, NUM_ITER);
@@ -158,6 +162,9 @@ void __devinit smp_generic_give_timebase(void)
 	}
 	pr_debug("Final offset: %d (%d/%d)\n", offset, score2, NUM_ITER );
 
+#ifdef CONFIG_WRHV
+bypass:
+#endif
 	/* exiting */
 	tbsync->cmd = kExit;
 	wmb();
diff --git a/arch/powerpc/kernel/smp.c b/arch/powerpc/kernel/smp.c
index cf7d658..3a8c805 100644
--- a/arch/powerpc/kernel/smp.c
+++ b/arch/powerpc/kernel/smp.c
@@ -50,6 +50,8 @@
 #include <asm/paca.h>
 #endif
 
+#include <asm/wrhv.h>
+
 #ifdef DEBUG
 #include <asm/udbg.h>
 #define DBG(fmt...) udbg_printf(fmt)
@@ -281,6 +283,10 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
  
 	smp_space_timers(max_cpus);
 
+#ifdef CONFIG_WRHV
+	wrhv_umask_IPIs_for_vcore();
+#endif
+
 	for_each_possible_cpu(cpu)
 		if (cpu != boot_cpuid)
 			smp_create_idle(cpu);
diff --git a/arch/powerpc/kernel/vbi/wrhv.c b/arch/powerpc/kernel/vbi/wrhv.c
index 737a4ff..5304bbd 100644
--- a/arch/powerpc/kernel/vbi/wrhv.c
+++ b/arch/powerpc/kernel/vbi/wrhv.c
@@ -124,6 +124,7 @@
 #include <vbi/vbi.h>
 #include <vbi/interface.h>
 
+VBI_EXC_OFFSETS_TABLE  exec_table;
 static struct vb_config __wr_config;
 struct vb_config *wr_config;		/* TODO kernel relocation friendly ? */
 struct vb_control *wr_control;
@@ -894,6 +895,29 @@ void __init wrhv_MMU_init(void)
 	 */
 	vb_context_mmu_on(0, swapper_pg_dir, PAGE_SIZE, 0);
 #endif
+
+#ifdef CONFIG_SMP
+	{
+		int i;
+		vbi_get_exc_offset(&exec_table);
+#ifdef DEBUG
+		printk("****DUMP EXEC OFFSET***\n");
+		for(i=0;i<VBI_ARCH_MAX_EXC_OFFSETS;i++)
+			printk("execoffset:%d	----	0x%08x\n",i,exec_table.excOffset[i]);
+#endif 
+		for(i=0;i<VBI_ARCH_MAX_EXC_OFFSETS;i++)
+		if(exec_table.excOffset[i])
+			/*extend to 0x200, 9bits space*/
+			exec_table.excOffset[i] = exec_table.excOffset[i] << 1;
+		vbi_set_exc_offset(&exec_table);
+#ifdef DEBUG
+		printk("****DUMP EXEC OFFSET AFTER SET***\n");
+		vbi_get_exc_offset(&exec_table);
+		for(i=0;i<VBI_ARCH_MAX_EXC_OFFSETS;i++)
+			printk("execoffset:%d	----	0x%08x\n",i,exec_table.excOffset[i]);
+#endif
+	}
+#endif
 }
 
 /* arch/powerpc/mm/mem.c */
@@ -1347,6 +1371,326 @@ void wrhv_init(void)
 
 }
 
+#ifdef CONFIG_SMP
+VBI_HREG_SET_CMPLX_QUALIFIED bootREG;
+#define IPI_IRQ_BASE_NAME "ipi0"
+int irq_base = 0xFFFF; /*init as invalid IRQ number*/
+
+DEFINE_PER_CPU(long long, tb_diff);
+
+long long wrhv_gettb_diff()
+{
+	return __get_cpu_var(tb_diff);
+}
+
+void wrhv_settb_diff(long long diff)
+{
+	 __get_cpu_var(tb_diff) = diff;
+}
+
+static irqreturn_t wrhv_ipi_action(int irq, void *data)
+{
+	long ipi = (long)data;
+
+	smp_message_recv(ipi);
+
+	return IRQ_HANDLED;
+}
+
+void __init smp_wrhv_setup_cpu(int cpu_nr)
+{
+	return;
+}
+
+void wrhv_umask_IPIs_for_vcore(void)
+{
+	int i;
+
+	for (i = 0; i < 4; i++) {
+		 vbi_unmask_vioapic_irq(irq_base+i);
+	}
+}
+
+void wrhv_request_ipis(void)
+{
+/* Need call vbiIntVecFind to get IPI IRQ numbers
+ * from Hypervisor configuration. So comment out
+ * this temprorily.
+ * IPI0 (call function)		irq_base
+ * IPI1 (reschedule)		irq_base+1
+ * IPI2 (call function single)	irq_base+2
+ * IPI3 (debugger break)	irq_base+3
+ */
+	static char *ipi_names[] = {
+		"IPI0 (call function)",
+		"IPI1 (reschedule)",
+		"IPI2 (call function single)",
+		"IPI3 (debugger break)",
+	};
+	int i,err;
+
+	printk(KERN_INFO "WRHV requesting IPIs ... \n");
+	
+	irq_base = wrhv_map_irq_of_desc(IPI_IRQ_BASE_NAME, VB_INPUT_INT);
+	if (irq_base == VBI_INVALID_IRQ)
+		panic("WRHV reslove irq for IPI failed.\n");
+
+	for (i = 0; i < 4; i++) {
+		set_irq_chip_and_handler_name(irq_base+i,
+			&wrhv_ipi_irq_chip, handle_percpu_irq, "per_cpu");
+
+		err = request_irq(irq_base+i, wrhv_ipi_action,
+				  IRQF_DISABLED|IRQF_PERCPU,
+				  ipi_names[i], (void *)i);
+		if (err) {
+			printk(KERN_ERR "WRHV Request of irq %d for IPI(%s) failed\n", 
+				irq_base+i,ipi_names[i]);
+			if (i) {
+				while (--i)
+					free_irq(irq_base+i, wrhv_ipi_action);	
+			}
+			break;
+		}
+	}
+}
+
+int __init smp_wrhv_probe(void)
+{
+	int nr_cpus;
+
+	pr_debug("smp_mpic_probe()...\n");
+
+	nr_cpus = cpus_weight(cpu_possible_map);
+
+	pr_debug("nr_cpus: %d\n", nr_cpus);
+
+	if (nr_cpus > 1)
+		wrhv_request_ipis();
+
+	wrhv_umask_IPIs_for_vcore();
+
+	return nr_cpus;
+}
+
+static inline void wrhv_send_IPI_mask(int irq, cpumask_t mask)
+{
+	unsigned long coreset = cpus_addr(mask)[0];
+	unsigned long flags;
+
+	local_irq_save(flags);
+	WARN_ON(coreset & ~cpus_addr(cpu_online_map)[0]);
+	vbi_send_vcore_vioapic_irq(irq, coreset, 0);
+	local_irq_restore(flags);
+}
+
+void smp_wrhv_message_pass(int target, int msg)
+{
+  
+	/* make sure we're sending something that translates to an IPI */
+	if ((unsigned int)msg > 3) {
+		printk("SMP %d: smp_message_pass: unknown msg %d\n",
+		       smp_processor_id(), msg);
+		return;
+	}
+
+	switch (target) {
+	case MSG_ALL:{
+		cpumask_t mask,dst;
+		
+		cpus_setall(dst);
+		cpus_and(mask, dst, cpu_online_map);
+		wrhv_send_IPI_mask(msg+irq_base,mask);
+
+		break;
+		}
+	case MSG_ALL_BUT_SELF:{
+		cpumask_t mask,dst;
+		int self = smp_processor_id();
+		
+		cpus_setall(dst);
+		cpu_clear(self,dst);
+		cpus_and(mask, dst, cpu_online_map);
+		wrhv_send_IPI_mask(msg+irq_base,mask);
+		break;
+		}
+	default:{
+		cpumask_t mask,dst;
+		cpus_clear(dst);
+		cpu_set(target,dst);
+		cpus_and(mask, dst, cpu_online_map);
+		wrhv_send_IPI_mask(msg+irq_base,mask);
+		break;
+		}
+	}
+}
+
+static void __init  smp_wrhv_kick_cpu(int nr)
+{
+	unsigned long flags;
+	int32_t ret;
+	
+
+	int n = 0;
+	WARN_ON (nr < 0 || nr >= NR_CPUS);
+
+	local_irq_save(flags);
+
+	bootREG.vbiRegType = VBI_REG_SET_32BIT;
+
+	ret=vbi_vb_read_reg(&bootREG, VBI_BOARD_ID_GET(), nr);
+	if(ret)
+		printk("WRHV read REG failed:%d\n",ret);
+
+	bootREG.vbiRegType = VBI_REG_SET_32BIT;
+	bootREG.vbiRegSet.hreg32.pc = 0xc0000000;
+
+	ret=vbi_vb_write_reg(&bootREG, VBI_BOARD_ID_GET(), nr);
+	if(ret)
+		printk("WRHV write REG failed:%d\n",ret);
+
+	ret=vbi_vb_resume(VBI_BOARD_ID_GET(), nr);
+	if(ret)
+		printk("WRHV resume CPU failed:%d\n",ret);
+
+	/* Wait a bit for the CPU to ack. */
+	while ((__secondary_hold_acknowledge != nr) && (++n < 1000))
+		mdelay(1);
+
+	local_irq_restore(flags);
+
+}
+
+unsigned long mpc85xx_smp_message[NR_CPUS]; /*fix doorbell_exception link error */
+
+struct smp_ops_t smp_wrhv_ops = {
+	.kick_cpu = smp_wrhv_kick_cpu,
+#if defined(CONFIG_HOTPLUG_CPU) && defined(CONFIG_PPC32)
+	.cpu_enable = generic_cpu_enable,
+	.cpu_disable = generic_cpu_disable,
+	.cpu_die = generic_cpu_die,
+#endif
+	.probe = smp_wrhv_probe,
+	.message_pass = smp_wrhv_message_pass,
+	.setup_cpu = smp_wrhv_setup_cpu,
+};
+
+#if defined(CONFIG_HOTPLUG_CPU)
+void cpu_die(void)
+{
+	if (smp_ops->cpu_die)
+	smp_ops->cpu_die(smp_processor_id());
+}
+#endif
+
+void __init wrhv_smp_init(void)
+{
+	smp_ops = &smp_wrhv_ops;
+}
+
+extern struct smp_ops_t *smp_ops;
+extern volatile unsigned int cpu_callin_map[NR_CPUS];
+
+static void __devinit smp_store_cpu_info(int id)
+{
+	per_cpu(cpu_pvr, id) = get_pvr();
+}
+
+/* Must be called when no change can occur to cpu_present_map,
+ * i.e. during cpu online or offline.
+ */
+static struct device_node *cpu_to_l2cache(int cpu)
+{
+	struct device_node *np;
+	struct device_node *cache;
+
+	if (!cpu_present(cpu))
+		return NULL;
+
+	np = of_get_cpu_node(cpu, NULL);
+	if (np == NULL)
+		return NULL;
+
+	cache = of_find_next_cache_node(np);
+
+	of_node_put(np);
+
+	return cache;
+}
+
+/* Activate a secondary processor. */
+int __devinit wrhv_start_secondary(void *unused)
+{
+	unsigned int cpu = smp_processor_id();
+	struct device_node *l2_cache;
+	int i, base;
+
+	local_irq_disable();
+#ifndef CONFIG_PPC85xx_VT_MODE
+	vb_context_mmu_on(0, swapper_pg_dir, PAGE_SIZE, 0);
+#endif
+
+	wrhv_umask_IPIs_for_vcore();
+	vbi_set_exc_offset(&exec_table);
+
+	atomic_inc(&init_mm.mm_count);
+	current->active_mm = &init_mm;
+
+	smp_store_cpu_info(cpu);
+	preempt_disable();
+	cpu_callin_map[cpu] = 1;
+
+	if (smp_ops->setup_cpu)
+		smp_ops->setup_cpu(cpu);
+	if (smp_ops->take_timebase)
+		smp_ops->take_timebase();
+
+	if (system_state > SYSTEM_BOOTING)
+		snapshot_timebase();
+
+	ipi_call_lock();
+	notify_cpu_starting(cpu);
+	set_cpu_online(cpu, true);
+	/* Update sibling maps */
+	base = cpu_first_thread_in_core(cpu);
+	for (i = 0; i < threads_per_core; i++) {
+		if (cpu_is_offline(base + i))
+			continue;
+		cpu_set(cpu, per_cpu(cpu_sibling_map, base + i));
+		cpu_set(base + i, per_cpu(cpu_sibling_map, cpu));
+
+		/* cpu_core_map should be a superset of
+		 * cpu_sibling_map even if we don't have cache
+		 * information, so update the former here, too.
+		 */
+		cpu_set(cpu, per_cpu(cpu_core_map, base +i));
+		cpu_set(base + i, per_cpu(cpu_core_map, cpu));
+	}
+	l2_cache = cpu_to_l2cache(cpu);
+	for_each_online_cpu(i) {
+		struct device_node *np = cpu_to_l2cache(i);
+		if (!np)
+			continue;
+		if (np == l2_cache) {
+			cpu_set(cpu, per_cpu(cpu_core_map, i));
+			cpu_set(i, per_cpu(cpu_core_map, cpu));
+		}
+		of_node_put(np);
+	}
+	of_node_put(l2_cache);
+	ipi_call_unlock();
+
+	local_irq_enable();
+
+	cpu_idle();
+	return 0;
+}
+#else
+long long wrhv_gettb_diff()
+{
+	return 0;
+}
+#endif
+
 #ifdef CONFIG_PCI
 #define VECTOR_NAME_SIZE	8
 int ppc_get_pci_intr_wrhv(struct pci_dev *dev)
diff --git a/arch/powerpc/kernel/wrhv_entry_32.S b/arch/powerpc/kernel/wrhv_entry_32.S
index 71785ee..5e3ab79 100644
--- a/arch/powerpc/kernel/wrhv_entry_32.S
+++ b/arch/powerpc/kernel/wrhv_entry_32.S
@@ -46,21 +46,18 @@
 #undef VMMU  /* just for debugging */
 #endif /* CONFIG_WRHV */
 
-#ifdef	CONFIG_WRHV
-	.data
-	.globl	wrhv_sprg3
+#ifdef CONFIG_WRHV
+       .data
+       .globl  wrhv_sprg3
 wrhv_sprg3:
-	.long	0
-	.globl	wrhv_supervisor
-wrhv_supervisor:
-	.long	1
+       .long   0
 #ifdef CONFIG_SMP
-	.globl wrhv_pir
+       .globl wrhv_pir
 wrhv_pir:
-	.long	0
+       .long   0
 #endif
-	.text
-#endif	/* CONFIG_WRHV */
+       .text
+#endif /* CONFIG_WRHV */
 
 /*
  * MSR_KERNEL is > 0x10000 on 4xx/Book-E since it include MSR_CE.
@@ -87,30 +84,19 @@ paravirt_transfer_to_handler:
 	beq	2f			/* if from user, fix up THREAD.regs */
 	addi	r11,r1,STACK_FRAME_OVERHEAD
 	stw	r11,PT_REGS(r12)
-#if defined(CONFIG_40x) || defined(CONFIG_BOOKE) && !defined(CONFIG_WRHV)
-	/* Check to see if the dbcr0 register is set up to debug.  Use the
-	   internal debug mode bit to do this. */
-	lwz	r12,THREAD_DBCR0(r12)
-	andis.	r12,r12,DBCR0_IDM@h
-	beq+	3f
-	/* From user and task is ptraced - load up global dbcr0 */
-	li	r12,-1			/* clear all pending debug events */
-	mtspr	SPRN_DBSR,r12
-	lis	r11,global_dbcr0@ha
-	tophys(r11,r11)
-	addi	r11,r11,global_dbcr0@l
+#if 0
+#if defined(CONFIG_40x) || defined(CONFIG_BOOKE)
 #ifdef CONFIG_SMP
 	rlwinm	r9,r1,0,0,(31-THREAD_SHIFT)
 	lwz	r9,TI_CPU(r9)
 	slwi	r9,r9,3
 	add	r11,r11,r9
 #endif
-	lwz	r12,0(r11)
-	mtspr	SPRN_DBCR0,r12
 	lwz	r12,4(r11)
 	addi	r12,r12,-1
 	stw	r12,4(r11)
 #endif
+#endif
 	b	3f
 
 2:	/* if from kernel, check interrupted DOZE/NAP mode and
@@ -223,11 +209,15 @@ paravirt_stack_ovf:
 	lis	r9,StackOverflow@ha
 	addi	r9,r9,StackOverflow@l
 	LOAD_MSR_KERNEL(r10,MSR_KERNEL)
+	WRHV_FIX_MSR(r10,r11)
+	b	StackOverflow
+#if 0
 	FIX_SRR1(r10,r12)
 	mtspr	SPRN_SRR0,r9
 	mtspr	SPRN_SRR1,r10
 	SYNC
 	RFI
+#endif
 
 
 	.globl	paravirt_ret_from_syscall
@@ -289,10 +279,11 @@ END_FTR_SECTION_IFSET(CPU_FTR_NEED_PAIRED_STWCX)
 	lwz	r2,GPR2(r1)
 	lwz	r1,GPR1(r1)
 	lis	r0,VBI_SYS_ctx_load@h
+	ori	r0,r0,VBI_SYS_ctx_load@l
 	sc
 
 66:	li	r3,-ENOSYS
-	b	ret_from_syscall
+	b	paravirt_ret_from_syscall
 
 	.globl	paravirt_syscall_exit_work
 paravirt_syscall_exit_work:
@@ -509,6 +500,7 @@ paravirt_restore:
 	lwz	r4,GPR4(r1)
 	lwz	r1,GPR1(r1)
 	lis	r0,VBI_SYS_ctx_load@h
+	ori	r0,r0,VBI_SYS_ctx_load@l
 #endif  /* VMMU */
 	sc
 
diff --git a/kernel/vbi/wrhv.c b/kernel/vbi/wrhv.c
index 39b1eae..56e1a26 100644
--- a/kernel/vbi/wrhv.c
+++ b/kernel/vbi/wrhv.c
@@ -148,18 +148,21 @@ unsigned long wrhv_calculate_cpu_khz(void)
 
 irqreturn_t __weak wrhv_timer_interrupt(int irq, void *dev_id)
 {
-	static long long mark_offset;
+	static DEFINE_PER_CPU(long long, mark_offset);
+	int cpu;
 	long long ticks;
 	int lost_jiffies = 0;
 	struct pt_regs *regs = get_irq_regs();
 
+	cpu = smp_processor_id();
 	ticks = wr_vb_status->tick_count;
-	ticks -= mark_offset;
+	ticks -= per_cpu(mark_offset,cpu);
 	lost_jiffies = ticks - 1;
-	mark_offset = wr_vb_status->tick_count;
+	per_cpu(mark_offset,cpu) = wr_vb_status->tick_count;
 
 	do {
-		do_timer(1);
+		if(!smp_processor_id())
+			do_timer(1);
 		update_process_times(user_mode(regs));
 		profile_tick(CPU_PROFILING);
 		if (lost_jiffies > (2*HZ)) {
-- 
1.6.5.2

