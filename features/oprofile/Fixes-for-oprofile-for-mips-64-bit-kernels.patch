From 7a1d41060653ea38e7edc37c64cd049e879b2a76 Mon Sep 17 00:00:00 2001
From: Dave Lerner <Dave.Lerner@windriver.com>
Date: Fri, 7 Nov 2008 18:37:43 -0600
Subject: [PATCH 17/21] Fixes for oprofile for mips 64 bit kernels

Catch memory access errors for 64 bit kernels that are not caught
by probe_kernel_read() by catching both page faults and unaligned
access errors.  Enable 64 bit SB1 cpu types that have incompletely
implemented PMU interfaces by switching to timer interrupts instead
of the PMU interrupts.

Signed-off-by: Dave Lerner <dave.lerner@windriver.com>
---
 arch/mips/kernel/unaligned.c         |   14 +++++++
 arch/mips/mm/fault.c                 |   15 +++++++
 arch/mips/oprofile/backtrace.h       |   17 ++++++++
 arch/mips/oprofile/common.c          |    4 ++
 arch/mips/oprofile/mips_crawl.c      |   70 ++++++++++++++++++++++++++++++++++
 arch/mips/oprofile/op_model_mipsxx.c |    5 +-
 6 files changed, 123 insertions(+), 2 deletions(-)

diff --git a/arch/mips/kernel/unaligned.c b/arch/mips/kernel/unaligned.c
index 69b039c..7ba78a1 100644
--- a/arch/mips/kernel/unaligned.c
+++ b/arch/mips/kernel/unaligned.c
@@ -452,6 +452,12 @@ static void emulate_load_store_insn(struct pt_regs *regs,
 		 */
 		goto sigbus;
 
+#if defined(CONFIG_64BIT) \
+	&& (defined(CONFIG_OPROFILE_MODULE) || defined(CONFIG_OPROFILE))
+	if (is_oprofile_fault && (*is_oprofile_fault)(regs))
+		return;
+#endif
+
 	/*
 	 * COP2 is available to implementor for application specific use.
 	 * It's up to applications to register a notifier chain and do
@@ -508,6 +514,14 @@ sigill:
 	force_sig(SIGILL, current);
 }
 
+#if defined(CONFIG_64BIT) \
+	&& (defined(CONFIG_OPROFILE_MODULE) || defined(CONFIG_OPROFILE))
+/*
+ * For oprofile backtrace code. If oprofile is enabled, this callback is valid
+ */
+extern int (*is_oprofile_fault)(struct pt_regs *regs);
+#endif
+
 asmlinkage void do_ade(struct pt_regs *regs)
 {
 	unsigned int __user *pc;
diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index b78f7d9..26b49e5 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -26,6 +26,13 @@
 #include <asm/ptrace.h>
 #include <asm/highmem.h>		/* For VMALLOC_END */
 
+#if defined(CONFIG_64BIT) && \
+		(defined(CONFIG_OPROFILE_MODULE) || defined(CONFIG_OPROFILE))
+int (*is_oprofile_fault)(struct pt_regs *regs) = 0;
+EXPORT_SYMBOL_GPL(is_oprofile_fault);
+#endif
+
+
 /*
  * This routine handles page faults.  It determines the address,
  * and the problem, and then passes it off to one of the appropriate
@@ -41,6 +48,14 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	siginfo_t info;
 	int fault;
 
+#if defined(CONFIG_64BIT) && \
+		(defined(CONFIG_OPROFILE_MODULE) || defined(CONFIG_OPROFILE))
+	/* for stack and frame pointer validity checking */
+	if (is_oprofile_fault && (*is_oprofile_fault)(regs)) {
+		return;
+	}
+#endif
+
 #if 0
 	printk("Cpu%d[%s:%d:%0*lx:%ld:%0*lx]\n", raw_smp_processor_id(),
 	       current->comm, current->pid, field, address, write,
diff --git a/arch/mips/oprofile/backtrace.h b/arch/mips/oprofile/backtrace.h
index 0b49062..b105a58 100644
--- a/arch/mips/oprofile/backtrace.h
+++ b/arch/mips/oprofile/backtrace.h
@@ -22,4 +22,21 @@
  */
 extern void mips_backtrace(struct pt_regs *const regs, unsigned int depth);
 
+#if defined(CONFIG_64BIT)
+/*
+ * Callback from do_page_fault and do_ade to detect if
+ * page fault occured during an oprofile_backtrace.
+ * returns 1 if caller should not handle the fault
+ *   (caused by oprofile backtracing)
+ * returns 0 if the caller should handle the fault
+ */
+extern unsigned int (*is_oprofile_fault)(struct pt_regs *regs);
+
+/*
+ * Callback from do_page_fault and do_ade to set return
+ * of oprofile user space address valididator to false
+ */
+extern unsigned int op_page_fault_filter(struct pt_regs *regs);
+#endif
+
 #endif /* BACKTRACE_H */
diff --git a/arch/mips/oprofile/common.c b/arch/mips/oprofile/common.c
index 0f5d3eb..5046c81 100644
--- a/arch/mips/oprofile/common.c
+++ b/arch/mips/oprofile/common.c
@@ -112,6 +112,10 @@ int __init oprofile_arch_init(struct oprofile_operations *ops)
 	ops->start		= op_mips_start;
 	ops->stop		= op_mips_stop;
 	ops->backtrace		= mips_backtrace;
+#if defined(CONFIG_64BIT)
+	/* set do_page_fault and do_ade handler callback */
+	is_oprofile_fault	= op_page_fault_filter;
+#endif
 
 	res = lmodel->init();
 	if (res) {
diff --git a/arch/mips/oprofile/mips_crawl.c b/arch/mips/oprofile/mips_crawl.c
index 0673902..0118947 100644
--- a/arch/mips/oprofile/mips_crawl.c
+++ b/arch/mips/oprofile/mips_crawl.c
@@ -214,6 +214,73 @@ long double     64 (128 in n32)     128
  *-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-*/
 int op_context_debug_output; /* = 0 */
 
+#if defined(CONFIG_64BIT)
+
+/*
+ * Make a page fault or else prove we won't.  Tool used by PCOk and SPOk
+ * Return 0 if no page fault, 1 if page fault happened
+ *
+ * NOTE: The probe_kernel_read() routine does not catch unaligned
+ * exceptions which occur in the upper address space for MIPS64.
+ */
+noinline int will_page_fault(const void *const address)
+{
+	register long ret asm("$2") = 0;
+
+	asm(".set noreorder");
+	asm("ssnop");
+
+	/* dereference the given address.  If this causes a page fault, our
+	 * installed handlers should intercept this and set the "ret" register
+	 * to 1.
+	 * This instruction has an artificial dependency on the "ret" variable
+	 * as an input parameter, which ensures "ret" is not forcefully set to
+	 * true after our page fault handling mechanism may have set it false.
+	 */
+	asm("lw   $3, %1" ::"X" (ret), "m" (*(long *)address));
+
+	asm("ssnop");
+	asm(".set reorder");
+
+	return ret;
+}
+
+/*
+ * Delimit the end of oprofile_address_checker
+ */
+noinline int will_page_fault_end(void)
+{
+	return op_context_debug_output;
+}
+
+/*
+ * callback for do_page_fault and do_ade
+ * return 1 to abort the do_page_fault
+ * return 0 if fault not caused by our backtrace
+ */
+unsigned int op_page_fault_filter(struct pt_regs *regs)
+{
+	unsigned long pc = regs->cp0_epc;
+
+	if ((pc >= (unsigned long) will_page_fault) &&
+		(pc <= (unsigned long) will_page_fault_end)) {
+		/* page corresponding to pc isn't in memory, set return
+		 * value to true
+		 */
+		regs->regs[REG_V0] = 1;
+
+		/* change pc to right instruction (*/
+		regs->cp0_epc = pc + sizeof(tInst);
+
+		return 1;
+	}
+
+	/* return 0, since this isn't our page fault */
+	return 0;
+}
+
+#else
+
 /*
  * Make a page fault or else prove we won't.  Tool used by PCOk and SPOk
  * Return 0 if no page fault, 1 if page fault happened
@@ -226,6 +293,9 @@ int will_page_fault(const void *const address)
 	return 0;
 }
 
+#endif
+
+
 /**
  * op_frame_crawl - given a target pc value, locate the calling stack frame
  *
diff --git a/arch/mips/oprofile/op_model_mipsxx.c b/arch/mips/oprofile/op_model_mipsxx.c
index 54759f1..88511fb 100644
--- a/arch/mips/oprofile/op_model_mipsxx.c
+++ b/arch/mips/oprofile/op_model_mipsxx.c
@@ -362,8 +362,9 @@ static int __init mipsxx_init(void)
 
 	case CPU_SB1:
 	case CPU_SB1A:
-		op_model_mipsxx_ops.cpu_type = "mips/sb1";
-		break;
+		op_model_mipsxx_ops.cpu_type = "mips/sb1-timer";
+		/* since the pmr's dont fire yet, return nodev */
+		return -ENODEV;
 
 	default:
 		printk(KERN_ERR "Profiling unsupported for this CPU\n");
-- 
1.6.5.2

