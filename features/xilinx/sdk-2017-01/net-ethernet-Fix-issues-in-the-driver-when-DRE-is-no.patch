From 462240fef352f0713b28150bf1fafe3931d3af2a Mon Sep 17 00:00:00 2001
From: Kedareswara rao Appana <appana.durga.rao@xilinx.com>
Date: Tue, 24 Jan 2017 15:53:26 +0530
Subject: [PATCH 1138/1566] net: ethernet: Fix issues in the driver when DRE
 is not enabled in the h/w

commit  99d053bb0e87207e0177f8ac236477e812857aee from
https://github.com/Xilinx/linux-xlnx.git

If DRE (Data realignment engine) is not enabled in the DMA h/w,
SW has to take care of the alignment of the buffers.

Currently driver is not handling alignment of buffers properly,
Resulting weired behaviour when try to test the ethernet interface
with these kind of designs.

This patch fixes this issue by allocating a pool of tx buffers
In the driver when DRE is not enabled in the h/w.
When there is an unaligned skb comes it will use those
Allocated tx buffers when DRE is not enabled in the h/w.

Note: When DRE is not enabled in the h/w the tx
Side performance will be very less as there is
a manual copy in the hard_xmit for this case.
Tx Perf Numbers on ZynqMP:
Without DRE: 248 Mbits/sec.
With DRE:   932 Mbits/sec.

Signed-off-by: Kedareswara rao Appana <appanad@xilinx.com>
Signed-off-by: Michal Simek <michal.simek@xilinx.com>
Signed-off-by: Meng Li <Meng.Li@windriver.com>
---
 drivers/net/ethernet/xilinx/xilinx_axienet.h      |   16 ++++++++++
 drivers/net/ethernet/xilinx/xilinx_axienet_main.c |   33 +++++++++++++++++++-
 2 files changed, 47 insertions(+), 2 deletions(-)

diff --git a/drivers/net/ethernet/xilinx/xilinx_axienet.h b/drivers/net/ethernet/xilinx/xilinx_axienet.h
index 616f185..897d38e 100644
--- a/drivers/net/ethernet/xilinx/xilinx_axienet.h
+++ b/drivers/net/ethernet/xilinx/xilinx_axienet.h
@@ -392,6 +392,10 @@
 #define XAE_TX_PTP_LEN		16
 #define XXV_TX_PTP_LEN		12
 
+/* Macros used when AXI DMA h/w is configured without DRE */
+#define XAE_TX_BUFFERS		64
+#define XAE_MAX_PKT_LEN		8192
+
 /**
  * struct axidma_bd - Axi Dma buffer descriptor layout
  * @next:         MM2S/S2MM Next Descriptor Pointer
@@ -460,6 +464,12 @@ struct axidma_bd {
  * @tx_bd_p:	Physical address(start address) of the TX buffer descr. ring
  * @rx_bd_v:	Virtual address of the RX buffer descriptor ring
  * @rx_bd_p:	Physical address(start address) of the RX buffer descr. ring
+ * @tx_buf:	Virtual address of the Tx buffer pool used by the driver when
+ *		DMA h/w is configured without DRE.
+ * @tx_bufs:	Virutal address of the Tx buffer address.
+ * @tx_bufs_dma: Physical address of the Tx buffer address used by the driver
+ *		 when DMA h/w is configured without DRE.
+ * @eth_hasdre: Tells whether DMA h/w is configured with dre or not.
  * @tx_bd_ci:	Stores the index of the Tx buffer descriptor in the ring being
  *		accessed currently. Used while alloc. BDs before a TX starts
  * @tx_bd_tail:	Stores the index of the Tx buffer descriptor in the ring being
@@ -519,6 +529,12 @@ struct axienet_local {
 	dma_addr_t tx_bd_p;
 	struct axidma_bd *rx_bd_v;
 	dma_addr_t rx_bd_p;
+
+	unsigned char *tx_buf[XAE_TX_BUFFERS];
+	unsigned char *tx_bufs;
+	dma_addr_t tx_bufs_dma;
+	bool eth_hasdre;
+
 	u32 tx_bd_ci;
 	u32 tx_bd_tail;
 	u32 rx_bd_ci;
diff --git a/drivers/net/ethernet/xilinx/xilinx_axienet_main.c b/drivers/net/ethernet/xilinx/xilinx_axienet_main.c
index da89541..cef1fbe 100644
--- a/drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ b/drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -257,6 +257,18 @@ static int axienet_dma_bd_init(struct net_device *ndev)
 				      ((i + 1) % TX_BD_NUM);
 	}
 
+	if (!lp->eth_hasdre) {
+		lp->tx_bufs = dma_zalloc_coherent(ndev->dev.parent,
+						  XAE_MAX_PKT_LEN * TX_BD_NUM,
+						  &lp->tx_bufs_dma,
+						  GFP_KERNEL);
+		if (!lp->tx_bufs)
+			goto out;
+
+		for (i = 0; i < TX_BD_NUM; i++)
+			lp->tx_buf[i] = &lp->tx_bufs[i * XAE_MAX_PKT_LEN];
+	}
+
 	for (i = 0; i < RX_BD_NUM; i++) {
 		lp->rx_bd_v[i].next = lp->rx_bd_p +
 				      sizeof(*lp->rx_bd_v) *
@@ -1040,8 +1052,23 @@ static int axienet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
 	}
 
 	cur_p->cntrl = (skb_headlen(skb) | XAXIDMA_BD_CTRL_TXSOF_MASK) + pad;
-	cur_p->phys = dma_map_single(ndev->dev.parent, skb->data,
-				     skb_headlen(skb), DMA_TO_DEVICE);
+	if (!lp->eth_hasdre &&
+	    (((phys_addr_t)skb->data & 0x3) || (num_frag > 0))) {
+		skb_copy_and_csum_dev(skb, lp->tx_buf[lp->tx_bd_tail]);
+
+		cur_p->phys = lp->tx_bufs_dma +
+			      (lp->tx_buf[lp->tx_bd_tail] - lp->tx_bufs);
+
+		if (num_frag > 0) {
+			pad = skb_pagelen(skb) - skb_headlen(skb);
+			cur_p->cntrl = (skb_headlen(skb) |
+					XAXIDMA_BD_CTRL_TXSOF_MASK) + pad;
+		}
+		goto out;
+	} else {
+		cur_p->phys = dma_map_single(ndev->dev.parent, skb->data,
+					     skb_headlen(skb), DMA_TO_DEVICE);
+	}
 	cur_p->tx_desc_mapping = DESC_DMA_MAP_SINGLE;
 
 	for (ii = 0; ii < num_frag; ii++) {
@@ -1059,6 +1086,7 @@ static int axienet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
 		cur_p->tx_desc_mapping = DESC_DMA_MAP_PAGE;
 	}
 
+out:
 	cur_p->cntrl |= XAXIDMA_BD_CTRL_TXEOF_MASK;
 	cur_p->tx_skb = (phys_addr_t)skb;
 
@@ -2361,6 +2389,7 @@ static int axienet_probe(struct platform_device *pdev)
 		ret = -ENOMEM;
 		goto free_netdev;
 	}
+	lp->eth_hasdre = of_property_read_bool(np, "xlnx,include-dre");
 
 	spin_lock_init(&lp->tx_lock);
 	spin_lock_init(&lp->rx_lock);
-- 
1.7.5.4

