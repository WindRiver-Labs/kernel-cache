From f14feac3932fa2365717f8d074798cd52bd840e7 Mon Sep 17 00:00:00 2001
From: Tom Rix <trix@kernel-dev.(none)>
Date: Thu, 23 Oct 2008 17:07:22 -0500
Subject: [PATCH] Add 'early' tracer to report early boot timing analysis

CQID: WIND00122917

early
-----

early is a static tracer of early boottime functions.  It is used to profile
the early bootup of the kernel.

To configure, choose 'Early Tracing' in xconfig or manually set throudh the
config variable CONFIG_TRACE_EARLY.  Be aware that this is a static tracer
and will not function if CONFIG_DYNAMIC_FTRACE is set.

early produces its output when the system boots up.  Its output is accessed
through the normal ftrace method of reading the tracing/trace file in the
debugfs.  The tracer is started as early in the bootup as possible.  It
is started after kmem_cache_init in start_kernel.  This is an example of
output from x86.

          <idle>-0     [00]     0.001000: hpet_time_init <-start_kernel
          <idle>-0     [00]     0.001000: hpet_enable <-hpet_time_init
          <idle>-0     [00]     0.001000: setup_pit_timer <-hpet_time_init
          <idle>-0     [00]     0.001000: time_init_hook <-hpet_time_init
          <idle>-0     [00]     0.001368: pidmap_init <-start_kernel

Note that the timestamp does not start at 0.  There will be variation because
in this case, the tracing started after the system clock.  In some cases the
tracing will start before the system clock.  This is an example of the omap3430
start up.

          <idle>-0     [00]     0.000000: calibrate_delay <-start_kernel
          <idle>-0     [00]     0.000000: pidmap_init <-start_kernel
          <idle>-0     [00]     0.000000: anon_vma_init <-start_kernel
          <idle>-0     [00]     0.000000: thread_info_cache_init <-start_kernel

- removed output -

           <...>-1     [00]     0.000000: omap_register_i2c_bus <-omap_i2c_init
           <...>-1     [00]     0.000000: omap_init_clocksource_32k <-__exception_text_end
           <...>-1     [00]  1433.023041: omap_init_devices <-__exception_text_end
           <...>-1     [00]  1433.024933: omap_init_dma <-__exception_text_end

Note that the timestamp for omap_init_devices looks valid of the call to
omap_init_clocksource_32k.

The functions listed are either in the kernel's init section, which is
unloaded when the kernel boots, or one of the many initcalls that are
responsible for initizing devices and kernel subsystems.  The tracing
continues until before the kernel hands off processing to the init process.
This is an example of the last part of a x86 trace log.

           <...>-1     [00]     3.858983: initrd_load <-prepare_namespace
           <...>-1     [00]     3.859173: rd_load_image <-initrd_load
           <...>-1     [00]     3.859456: mount_root <-prepare_namespace
           <...>-1     [00]     3.859458: nfs_root_data <-mount_root
           <...>-1     [00]     3.859463: root_nfs_parse <-nfs_root_data
           <...>-1     [00]     3.859465: root_nfs_parse <-nfs_root_data
           <...>-1     [00]     3.931151: do_mount_root <-mount_root
---
 Documentation/ftrace.txt   |   66 ++++++++++++++
 init/main.c                |   14 +++
 kernel/trace/Kconfig       |   16 ++++
 kernel/trace/Makefile      |    1 +
 kernel/trace/trace.c       |   85 +++++++++++++++++-
 kernel/trace/trace.h       |    5 +
 kernel/trace/trace_early.c |  212 ++++++++++++++++++++++++++++++++++++++++++++
 7 files changed, 398 insertions(+), 1 deletions(-)
 create mode 100644 kernel/trace/trace_early.c

diff --git a/Documentation/ftrace.txt b/Documentation/ftrace.txt
index d330fe3..117062d 100644
--- a/Documentation/ftrace.txt
+++ b/Documentation/ftrace.txt
@@ -166,6 +166,8 @@ Here is the list of current tracers that may be configured.
 		the highest priority task to get scheduled after
 		it has been woken up.
 
+  early - Traces boottime functions. 
+
   none - This is not a tracer. To remove all tracers from tracing
 		simply echo "none" into current_tracer.
 
@@ -1000,6 +1002,70 @@ is the stack for the hard interrupt. This hides the fact that NEED_RESCHED
 has been set. We do not see the 'N' until we switch back to the task's
 assigned stack.
 
+early
+-----
+
+early is a static tracer of early boottime functions.  It is used to profile 
+the early bootup of the kernel.  
+
+To configure, choose 'Early Tracing' in xconfig or manually set throudh the
+config variable CONFIG_TRACE_EARLY.  Be aware that this is a static tracer
+and will not function if CONFIG_DYNAMIC_FTRACE is set.  
+
+early produces its output when the system boots up.  Its output is accessed 
+through the normal ftrace method of reading the tracing/trace file in the 
+debugfs.  The tracer is started as early in the bootup as possible.  It 
+is started after kmem_cache_init in start_kernel.  This is an example of 
+output from x86. 
+
+# tracer: early
+#
+#           TASK-PID   CPU#    TIMESTAMP  FUNCTION
+#              | |      |          |         |
+          <idle>-0     [00]     0.001000: hpet_time_init <-start_kernel
+          <idle>-0     [00]     0.001000: hpet_enable <-hpet_time_init
+          <idle>-0     [00]     0.001000: setup_pit_timer <-hpet_time_init
+          <idle>-0     [00]     0.001000: time_init_hook <-hpet_time_init
+          <idle>-0     [00]     0.001368: pidmap_init <-start_kernel
+
+Note that the timestamp does not start at 0.  There will be variation because 
+in this case, the tracing started after the system clock.  In some cases the 
+tracing will start before the system clock.  This is an example of the omap3430
+start up. 
+
+# tracer: early
+#
+#           TASK-PID   CPU#    TIMESTAMP  FUNCTION
+#              | |      |          |         |
+          <idle>-0     [00]     0.000000: calibrate_delay <-start_kernel
+          <idle>-0     [00]     0.000000: pidmap_init <-start_kernel
+          <idle>-0     [00]     0.000000: anon_vma_init <-start_kernel
+          <idle>-0     [00]     0.000000: thread_info_cache_init <-start_kernel
+
+- removed output -
+
+           <...>-1     [00]     0.000000: omap_register_i2c_bus <-omap_i2c_init
+           <...>-1     [00]     0.000000: omap_init_clocksource_32k <-__exception_text_end
+           <...>-1     [00]  1433.023041: omap_init_devices <-__exception_text_end
+           <...>-1     [00]  1433.024933: omap_init_dma <-__exception_text_end
+
+Note that the timestamp for omap_init_devices looks valid of the call to 
+omap_init_clocksource_32k. 
+
+The functions listed are either in the kernel's init section, which is 
+unloaded when the kernel boots, or one of the many initcalls that are 
+responsible for initizing devices and kernel subsystems.  The tracing 
+continues until before the kernel hands off processing to the init process.  
+This is an example of the last part of a x86 trace log. 
+
+           <...>-1     [00]     3.858983: initrd_load <-prepare_namespace
+           <...>-1     [00]     3.859173: rd_load_image <-initrd_load
+           <...>-1     [00]     3.859456: mount_root <-prepare_namespace
+           <...>-1     [00]     3.859458: nfs_root_data <-mount_root
+           <...>-1     [00]     3.859463: root_nfs_parse <-nfs_root_data
+           <...>-1     [00]     3.859465: root_nfs_parse <-nfs_root_data
+           <...>-1     [00]     3.931151: do_mount_root <-mount_root
+
 ftrace
 ------
 
diff --git a/init/main.c b/init/main.c
index 3820323..526f5d7 100644
--- a/init/main.c
+++ b/init/main.c
@@ -102,6 +102,13 @@ static inline void mark_rodata_ro(void) { }
 extern void tc_init(void);
 #endif
 
+#ifdef CONFIG_FTRACE_EARLY
+extern int tracer_alloc_buffers(void);
+extern int init_function_trace(void);
+extern int tracing_early_ctrl_write(unsigned int val);
+extern int init_early_trace(void);
+#endif
+
 enum system_states system_state;
 EXPORT_SYMBOL(system_state);
 
@@ -648,6 +655,10 @@ asmlinkage void __init start_kernel(void)
 	enable_debug_pagealloc();
 	cpu_hotplug_init();
 	kmem_cache_init();
+#ifdef CONFIG_FTRACE_EARLY
+	tracer_alloc_buffers();
+	init_early_trace();
+#endif
 	debug_objects_mem_init();
 	idr_init_cache();
 	setup_per_cpu_pageset();
@@ -876,6 +887,9 @@ static int __init kernel_init(void * unused)
 		prepare_namespace();
 	}
 
+#ifdef CONFIG_FTRACE_EARLY
+	tracing_early_ctrl_write(0);
+#endif
 	/*
 	 * Ok, we have completed the initial bootup, and
 	 * we're essentially up and running. Get rid of the
diff --git a/kernel/trace/Kconfig b/kernel/trace/Kconfig
index aa53fdd..65b0ac1 100644
--- a/kernel/trace/Kconfig
+++ b/kernel/trace/Kconfig
@@ -122,6 +122,22 @@ config DYNAMIC_FTRACE
 	 were made. If so, it runs stop_machine (stops all CPUS)
 	 and modifies the code to jump over the call to ftrace.
 
+config FTRACE_EARLY
+	bool "Early tracing (Experimental)"
+	default n
+	depends on HAVE_FTRACE
+	select TRACING
+	help
+	  This option enables static tracing of the early boot sequence.
+          This tracer is useful for finding, at a high level, how long early
+	  kernel initializations are taking to complete.  By removing or
+	  reducing the time for functions, the overall boottime can be reduced.
+
+	  The tracing starts in start_kernel after kmem_cache_init and finishes
+	  in kernel_init before init_post.
+
+	  This option depends on the early initialization of the system timer.
+
 config FTRACE_SELFTEST
 	bool
 
diff --git a/kernel/trace/Makefile b/kernel/trace/Makefile
index 71d17de..5d4072a 100644
--- a/kernel/trace/Makefile
+++ b/kernel/trace/Makefile
@@ -20,5 +20,6 @@ obj-$(CONFIG_IRQSOFF_TRACER) += trace_irqsoff.o
 obj-$(CONFIG_PREEMPT_TRACER) += trace_irqsoff.o
 obj-$(CONFIG_SCHED_TRACER) += trace_sched_wakeup.o
 obj-$(CONFIG_MMIOTRACE) += trace_mmiotrace.o
+obj-$(CONFIG_FTRACE_EARLY) += trace_early.o
 
 libftrace-y := ftrace.o
diff --git a/kernel/trace/trace.c b/kernel/trace/trace.c
index 8f3fb3d..56748f1 100644
--- a/kernel/trace/trace.c
+++ b/kernel/trace/trace.c
@@ -2327,6 +2327,32 @@ tracing_ctrl_write(struct file *filp, const char __user *ubuf,
 	return cnt;
 }
 
+#ifdef CONFIG_FTRACE_EARLY
+int __init tracing_early_ctrl_write(unsigned int val)
+{
+	struct trace_array *tr = &global_trace;
+	int ret = 0;
+
+	mutex_lock(&trace_types_lock);
+	if (tr->ctrl ^ val) {
+		if (val)
+			tracer_enabled = 1;
+		else
+			tracer_enabled = 0;
+
+		tr->ctrl = val;
+
+		if (current_trace && current_trace->ctrl_update)
+			current_trace->ctrl_update(tr);
+
+		ret = 1;
+	}
+	mutex_unlock(&trace_types_lock);
+
+	return ret;
+}
+#endif /* CONFIG_EARLY_FTRACE */
+
 static ssize_t
 tracing_set_trace_read(struct file *filp, char __user *ubuf,
 		       size_t cnt, loff_t *ppos)
@@ -2388,6 +2414,46 @@ tracing_set_trace_write(struct file *filp, const char __user *ubuf,
 	return cnt;
 }
 
+#ifdef CONFIG_FTRACE_EARLY
+ssize_t __init tracing_early_set_trace_write(const char *ubuf, size_t cnt)
+{
+	struct trace_array *tr = &global_trace;
+	struct tracer *t;
+	char buf[max_tracer_type_len+1];
+	int i;
+
+	if (cnt > max_tracer_type_len)
+		cnt = max_tracer_type_len;
+
+	memcpy(&buf, ubuf, cnt);
+	buf[cnt] = 0;
+
+	/* strip ending whitespace. */
+	for (i = cnt - 1; i > 0 && isspace(buf[i]); i--)
+		buf[i] = 0;
+
+	mutex_lock(&trace_types_lock);
+	for (t = trace_types; t; t = t->next) {
+		if (strcmp(t->name, buf) == 0)
+			break;
+	}
+	if (!t || t == current_trace)
+		goto out;
+
+	if (current_trace && current_trace->reset)
+		current_trace->reset(tr);
+
+	current_trace = t;
+	if (t->init)
+		t->init(tr);
+
+ out:
+	mutex_unlock(&trace_types_lock);
+
+	return cnt;
+}
+#endif /* CONFIG_FTRACE_EARLY */
+
 static ssize_t
 tracing_max_lat_read(struct file *filp, char __user *ubuf,
 		     size_t cnt, loff_t *ppos)
@@ -2846,7 +2912,11 @@ struct dentry *tracing_init_dentry(void)
 #include "trace_selftest.c"
 #endif
 
+#ifndef CONFIG_FTRACE_EARLY
 static __init void tracer_init_debugfs(void)
+#else
+static __init int tracer_init_debugfs(void)
+#endif
 {
 	struct dentry *d_tracer;
 	struct dentry *entry;
@@ -2928,6 +2998,9 @@ static __init void tracer_init_debugfs(void)
 #ifdef CONFIG_SYSPROF_TRACER
 	init_tracer_sysprof_debugfs(d_tracer);
 #endif
+#ifdef CONFIG_FTRACE_EARLY
+	return 0;
+#endif
 }
 
 static int trace_alloc_page(void)
@@ -3046,7 +3119,11 @@ static int trace_free_page(void)
 	return ret;
 }
 
+#ifndef CONFIG_FTRACE_EARLY
 __init static int tracer_alloc_buffers(void)
+#else
+__init int tracer_alloc_buffers(void)
+#endif
 {
 	struct trace_array_cpu *data;
 	void *array;
@@ -3115,8 +3192,9 @@ __init static int tracer_alloc_buffers(void)
 		pages, trace_nr_entries, (long)TRACE_ENTRY_SIZE);
 	pr_info("   actual entries %ld\n", global_trace.entries);
 
+#ifndef CONFIG_FTRACE_EARLY
 	tracer_init_debugfs();
-
+#endif
 	trace_init_cmdlines();
 
 	register_tracer(&no_tracer);
@@ -3154,4 +3232,9 @@ __init static int tracer_alloc_buffers(void)
 	}
 	return ret;
 }
+
+#ifndef CONFIG_FTRACE_EARLY
 fs_initcall(tracer_alloc_buffers);
+#else
+fs_initcall(tracer_init_debugfs);
+#endif
diff --git a/kernel/trace/trace.h b/kernel/trace/trace.h
index f69f867..88a810a 100644
--- a/kernel/trace/trace.h
+++ b/kernel/trace/trace.h
@@ -336,4 +336,9 @@ enum trace_iterator_flags {
 	TRACE_ITER_SCHED_TREE		= 0x200,
 };
 
+#ifdef CONFIG_FTRACE_EARLY
+ssize_t __init tracing_early_set_trace_write(const char *ubuf, size_t cnt);
+int __init tracing_early_ctrl_write(unsigned int val);
+#endif /* CONFIG_EARLY_FTRACE */
+
 #endif /* _LINUX_KERNEL_TRACE_H */
diff --git a/kernel/trace/trace_early.c b/kernel/trace/trace_early.c
new file mode 100644
index 0000000..920b47e
--- /dev/null
+++ b/kernel/trace/trace_early.c
@@ -0,0 +1,212 @@
+/*
+ * Statically trace early boot.
+ *
+ * Copyright (C) 2008 Tom Rix <Tom.Rix@windriver.com>
+ */
+#include <linux/kallsyms.h>
+#include <linux/debugfs.h>
+#include <linux/uaccess.h>
+#include <linux/module.h>
+#include <linux/ftrace.h>
+#include <linux/fs.h>
+#include <linux/sort.h>
+
+#include <linux/irq.h>
+#include <linux/stacktrace.h>
+#include <asm/sections.h>
+
+#include "trace.h"
+
+/* Uncomment for debug output */
+/* #define EARLY_TRACE_DB */
+
+extern ftrace_func_t ftrace_trace_function;
+extern int ftrace_function_enabled;
+
+static struct trace_array *early_trace;
+static unsigned long *itable;
+static unsigned long itable_size;
+
+extern initcall_t __initcall_start[], __initcall_end[], __early_initcall_end[];
+
+/* This routine determines which kernel functions are recorded and which
+   are ignored.  */
+static int skip(unsigned long ip)
+{
+	/* Functions in the kernel init section are OK */
+	if (ip >= (unsigned long)_sinittext &&
+	    ip <= (unsigned long)_einittext)
+		return 0;
+	/* Functions in the initcall tables are OK
+	   The itable holds these calls and is presorted */
+	if (itable &&
+	    ip >= itable[0] &&
+	    ip <= itable[itable_size - 1]) {
+		unsigned long s, e, m, v;
+
+		s = m = 0;
+		e = itable_size - 1;
+		for (;;) {
+			m = s + ((e - s) >> 1);
+			v = itable[m];
+			if (unlikely(ip == v))
+				return 0;
+			if (likely(e <= (s+1)))
+				break;
+			if (ip > v)
+				s = m;
+			else /* (ip < v) */
+				e = m;
+		}
+	}
+	/* Most functions we do not care to measure these are skipped */
+	return 1;
+}
+
+static void
+early_trace_func(unsigned long ip, unsigned long parent_ip)
+{
+	struct trace_array *tr = early_trace;
+	struct trace_array_cpu *data;
+	long disabled;
+	int cpu;
+
+	if (skip(ip))
+		return;
+	/*
+	 * Does not matter if we preempt. We test the flags
+	 * afterward, to see if irqs are disabled or not.
+	 * If we preempt and get a false positive, the flags
+	 * test will fail.
+	 */
+	cpu = raw_smp_processor_id();
+
+	data = tr->data[cpu];
+	disabled = atomic_inc_return(&data->disabled);
+
+	if (likely(disabled == 1))
+		trace_function(tr, data, ip, parent_ip, 0);
+
+	atomic_dec(&data->disabled);
+}
+
+static struct ftrace_ops early_trace_ops __read_mostly =
+{
+	.func = early_trace_func,
+};
+
+static int compare(const void *a, const void *b)
+{
+	unsigned long *la = (unsigned long *) a;
+	unsigned long *lb = (unsigned long *) b;
+
+	if (*la > *lb)
+		return 1;
+	else if (*lb > *la)
+		return -1;
+	else
+		return 0;
+}
+
+static void swap(void *a, void *b, int size)
+{
+	unsigned long *la = (unsigned long *)a;
+	unsigned long *lb = (unsigned long *)b;
+	unsigned long t = *la;
+	*la = *lb;
+	*lb = t;
+}
+
+static void early_trace_init(struct trace_array *tr)
+{
+#ifdef EARLY_TRACE_DB
+	pr_info("early_trace_init\n");
+#endif
+
+	ftrace_function_enabled = 0;
+
+	if (!ftrace_enabled)
+		ftrace_enabled = 1;
+
+	if (!itable) {
+		unsigned long s;
+
+		s = __initcall_end - __initcall_start;
+
+#ifdef EARLY_TRACE_DB
+		pr_info("early_trace_init init call table size %lu\n", s);
+#endif
+		if (s) {
+			itable = kzalloc(s, GFP_KERNEL);
+			if (itable) {
+				unsigned long l;
+				initcall_t *call = __initcall_start;
+				itable_size = s / sizeof(unsigned long);
+
+				BUG_ON(!itable_size);
+
+				for (l = 0; l < itable_size; l++)
+					itable[l] = (unsigned long) call[l];
+
+				sort(itable, itable_size, sizeof(unsigned long),
+				     compare, swap);
+			}
+		}
+	}
+	early_trace = tr;
+	if (tr->ctrl) {
+		int cpu;
+		for_each_online_cpu(cpu)
+			tracing_reset(tr->data[cpu]);
+
+		register_ftrace_function(&early_trace_ops);
+	}
+}
+
+static void early_trace_reset(struct trace_array *tr)
+{
+	int status = -1;
+
+	if (itable) {
+		kfree(itable);
+		itable = NULL;
+		itable_size = 0;
+	}
+	if (tr->ctrl)
+		status = unregister_ftrace_function(&early_trace_ops);
+}
+
+static void early_trace_ctrl_update(struct trace_array *tr)
+{
+	if (tr->ctrl)
+		register_ftrace_function(&early_trace_ops);
+	else
+		unregister_ftrace_function(&early_trace_ops);
+}
+
+#ifndef CONFIG_DYNAMIC_FTRACE
+static struct tracer early_tracer __read_mostly =
+{
+	.name	        = "early",
+	.init           = early_trace_init,
+	.reset          = early_trace_reset,
+	.ctrl_update	= early_trace_ctrl_update,
+};
+#endif
+
+__init int init_early_trace(void)
+{
+	int ret = -1;
+#ifndef CONFIG_DYNAMIC_FTRACE
+	ret = register_tracer(&early_tracer);
+
+	if (5 != tracing_early_set_trace_write("early", 5))
+		pr_warning("Could not enable early trace\n");
+	else
+		pr_info("Early trace enabled\n");
+
+	ftrace_function_enabled = 1;
+#endif
+	return ret;
+}
+
-- 
1.5.5.1

