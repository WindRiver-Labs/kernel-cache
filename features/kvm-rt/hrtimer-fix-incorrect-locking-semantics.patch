From abdcba4fa1474219759b414c2dcb801bbf257f5d Mon Sep 17 00:00:00 2001
From: Nam Ninh <nam.ninh@windriver.com>
Date: Thu, 15 Aug 2013 14:40:51 -0400
Subject: [PATCH] hrtimer: fix incorrect locking semantics

When lapic hrtimer is in irqsafe context, we see this lockup on host
when we run KVM guests and lapic hrtimer in irq context.

INFO: rcu_preempt detected stalls on CPUs/tasks:
	10: (1 GPs behind) idle=c1f/140000000000001/0 softirq=14267/14270
	(detected by 2, t=84007 jiffies, g=3574, c=3573, q=709)
Task dump for CPU 10:
qemu-system-x86 R  running task        0  1958   1945 0x00080880
 0000000000000046 ffff88036fd4bf78 0000000000000000 0000000000000000
 ffff88063ed7bbf8 ffffffff81075450 ffff88036fd4af00 0000000000000000
 0000005f027d46c6 0000000000000000 ffff88063ed7bc38 ffffffff8107b20d
 Call Trace:
 [<ffffffff81075450>] ? ktime_get+0x60/0xe0
 [<ffffffff8107b20d>] ? clockevents_program_event+0x3d/0x100
 [<ffffffff8107c65f>] ? tick_program_event+0x1f/0x30
 [<ffffffff810598b2>] ? hrtimer_reprogram.isra.35+0x72/0xb0
 [<ffffffff81059fda>] ? __hrtimer_start_range_ns+0x1ca/0x280
 [<ffffffffa0040cd7>] ? kvm_arch_vcpu_ioctl_run+0xeb7/0x1360 [kvm]
 [<ffffffffa0040cdf>] ? kvm_arch_vcpu_ioctl_run+0xebf/0x1360 [kvm]
 [<ffffffffa0040cd7>] ? kvm_arch_vcpu_ioctl_run+0xeb7/0x1360 [kvm]
 [<ffffffffa0040071>] ? kvm_arch_vcpu_ioctl_run+0x251/0x1360 [kvm]
 [<ffffffffa003bbc2>] ? kvm_arch_vcpu_load+0x52/0x1b0 [kvm]
 [<ffffffffa002eebd>] ? kvm_vcpu_ioctl+0x45d/0x5c0 [kvm]
 [<ffffffff811274d6>] ? do_vfs_ioctl+0x96/0x570
 [<ffffffff81116533>] ? fget_light+0xe3/0x160
 [<ffffffff8111648b>] ? fget_light+0x3b/0x160
 [<ffffffff81127a49>] ? sys_ioctl+0x99/0xa0
 [<ffffffff816bb586>] ? tracesys+0xe1/0xe6
BUG: spinlock lockup on CPU#10, qemu-system-x86/1958
 lock: ffff88036fd4bf60, .magic: dead4ead, .owner: qemu-system-x86/1958, .owner_cpu: 10
Pid: 1958, comm: qemu-system-x86 Not tainted 3.4.34-ovp-ga-rt40-WR5.0.1.0_preempt-rt #3
Call Trace:
 <IRQ>  [<ffffffff816b4372>] spin_dump+0x8a/0x8f
 [<ffffffff81321bc3>] do_raw_spin_lock+0xf3/0x140
 [<ffffffffa06a7320>] ? vmx_invpcid_supported+0x20/0x20 [kvm_intel]
 [<ffffffff816ba324>] _raw_spin_lock+0x44/0x50
 [<ffffffff8105a117>] ? hrtimer_interrupt+0x47/0x2f0
 [<ffffffff810629ab>] ? try_to_wake_up+0x6b/0x290
 [<ffffffff8105a117>] hrtimer_interrupt+0x47/0x2f0
 [<ffffffff8107d93d>] ? trace_hardirqs_off+0xd/0x10
 [<ffffffff810b48f8>] ? rcu_irq_enter+0x68/0xc0
 [<ffffffffa06a7320>] ? vmx_invpcid_supported+0x20/0x20 [kvm_intel]
 [<ffffffff81020e34>] smp_apic_timer_interrupt+0x64/0xa0
 [<ffffffff816bbfdc>] apic_timer_interrupt+0x6c/0x80
 <EOI>  [<ffffffffa0040cd7>] ? kvm_arch_vcpu_ioctl_run+0xeb7/0x1360 [kvm]
 [<ffffffffa0040cdf>] ? kvm_arch_vcpu_ioctl_run+0xebf/0x1360 [kvm]
 [<ffffffffa0040cd7>] ? kvm_arch_vcpu_ioctl_run+0xeb7/0x1360 [kvm]
 [<ffffffffa0040071>] ? kvm_arch_vcpu_ioctl_run+0x251/0x1360 [kvm]
 [<ffffffffa003bbc2>] ? kvm_arch_vcpu_load+0x52/0x1b0 [kvm]
 [<ffffffffa002eebd>] kvm_vcpu_ioctl+0x45d/0x5c0 [kvm]
 [<ffffffff811274d6>] do_vfs_ioctl+0x96/0x570
 [<ffffffff81116533>] ? fget_light+0xe3/0x160
 [<ffffffff8111648b>] ? fget_light+0x3b/0x160
 [<ffffffff81127a49>] sys_ioctl+0x99/0xa0
 [<ffffffff816bb586>] tracesys+0xe1/0xe6

In irqsafe, __hrtimer_start_range_ns owns and does not release
cpu_base->lock after reprogram and hrtimer_interrupt tries to get the
same lock.

Signed-off-by: Nam Ninh <nam.ninh@windriver.com>

diff --git a/kernel/hrtimer.c b/kernel/hrtimer.c
index 071a66a..6e12682 100644
--- a/kernel/hrtimer.c
+++ b/kernel/hrtimer.c
@@ -1038,23 +1038,33 @@ int __hrtimer_start_range_ns(struct hrtimer *timer, ktime_t tim,
 	if (leftmost && new_base->cpu_base == &__get_cpu_var(hrtimer_bases)
 		&& hrtimer_enqueue_reprogram(timer, new_base)) {
 
-		if (wakeup
+		if (wakeup) {
+
 #ifdef CONFIG_PREEMPT_RT_BASE
+			/*
+			 * In irqsafe mode, we need to drop cpu_base->lock
+			 * to avoid lockup with hrtimer_interrupt.
+			 */
+			if (timer->irqsafe)
+				raw_spin_unlock(&new_base->cpu_base->lock);
+
 		    /*
 		     * Move softirq based timers away from the rbtree in
 		     * case it expired already. Otherwise we would have a
 		     * stale base->first entry until the softirq runs.
 		     */
-		    && hrtimer_rt_defer(timer)
+			if (hrtimer_rt_defer(timer)) {
+#endif
+				/*
+				 * We need to drop cpu_base->lock to avoid a
+				 * lock ordering issue vs. rq->lock.
+				 */
+				raw_spin_unlock(&new_base->cpu_base->lock);
+				raise_softirq_irqoff(HRTIMER_SOFTIRQ);
+				local_irq_restore(flags);
+#ifdef CONFIG_PREEMPT_RT_BASE
+			}
 #endif
-			) {
-			/*
-			 * We need to drop cpu_base->lock to avoid a
-			 * lock ordering issue vs. rq->lock.
-			 */
-			raw_spin_unlock(&new_base->cpu_base->lock);
-			raise_softirq_irqoff(HRTIMER_SOFTIRQ);
-			local_irq_restore(flags);
 			return ret;
 		}
 
-- 
1.8.3.1

