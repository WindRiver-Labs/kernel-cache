From f8f9790c931cc42c476b21b233387738f9405cdf Mon Sep 17 00:00:00 2001
From: Paul Gortmaker <paul.gortmaker@windriver.com>
Date: Tue, 29 Apr 2014 15:55:40 -0400
Subject: [PATCH] kvm: convert various IRQ infrastructure locks to raw

David reports seeing the following when using the KVM
option "allow_unsafe_assigned_interrupts":

BUG: sleeping function called from invalid context at kernel/rtmutex.c:659
in_atomic(): 1, irqs_disabled(): 1, pid: 0, name: swapper/2
Preemption disabled at:[<ffffffff8180a5ef>] start_secondary+0x1ab/0x1b0

Pid: 0, comm: swapper/2 Tainted: G           O 3.4.82-ovp-ga2-rt95-WR5.0.1.13_preempt-rt #2
Call Trace:
 <IRQ>
  [<ffffffff8106ef4e>] __might_sleep+0xfe/0x170
  [<ffffffff8181b424>] rt_spin_lock+0x24/0x50
  [<ffffffffa01afe53>] kvm_assigned_dev_intx+0x33/0x70 [kvm]
  [<ffffffff810ccdf8>] handle_irq_event_percpu+0x98/0x2c0
  [<ffffffff813f9588>] ? intel_idle+0xd8/0x180
  [<ffffffff810cd07e>] handle_irq_event+0x5e/0x90
  [<ffffffff810d0401>] handle_fasteoi_irq+0xd1/0x140
  [<ffffffff81004672>] handle_irq+0x22/0x40
  [<ffffffff8182471a>] do_IRQ+0x5a/0xd0
  [<ffffffff8181bc27>] common_interrupt+0x67/0x67
 <EOI>
  [<ffffffff8181b7d8>] ? _raw_spin_unlock_irqrestore+0x18/0x50
  [<ffffffff813f9588>] ? intel_idle+0xd8/0x180
  [<ffffffff813f9567>] ? intel_idle+0xb7/0x180
  [<ffffffff8165b9f8>] cpuidle_enter+0x18/0x20
  [<ffffffff8165c064>] cpuidle_idle_call+0xd4/0x400
  [<ffffffff8100bf4a>] cpu_idle+0x7a/0x130
  [<ffffffff8180a5ef>] start_secondary+0x1ab/0x1b0

The locking order means that after the 1st conversion to silence
the above, two more locks need to be converted before no similar
warnings are produced.

Originally-by: "Mercado, David" <david.mercado@windriver.com>
Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/x86/kvm/i8259.c b/arch/x86/kvm/i8259.c
index 6d18fd082f3b..418b06118278 100644
--- a/arch/x86/kvm/i8259.c
+++ b/arch/x86/kvm/i8259.c
@@ -42,7 +42,7 @@ static void pic_irq_request(struct kvm *kvm, int level);
 static void pic_lock(struct kvm_pic *s)
 	__acquires(&s->lock)
 {
-	spin_lock(&s->lock);
+	raw_spin_lock(&s->lock);
 }
 
 static void pic_unlock(struct kvm_pic *s)
@@ -54,7 +54,7 @@ static void pic_unlock(struct kvm_pic *s)
 
 	s->wakeup_needed = false;
 
-	spin_unlock(&s->lock);
+	raw_spin_unlock(&s->lock);
 
 	if (wakeup) {
 		kvm_for_each_vcpu(i, vcpu, s->kvm) {
@@ -635,7 +635,7 @@ struct kvm_pic *kvm_create_pic(struct kvm *kvm)
 	s = kzalloc(sizeof(struct kvm_pic), GFP_KERNEL);
 	if (!s)
 		return NULL;
-	spin_lock_init(&s->lock);
+	raw_spin_lock_init(&s->lock);
 	s->kvm = kvm;
 	s->pics[0].elcr_mask = 0xf8;
 	s->pics[1].elcr_mask = 0xde;
diff --git a/arch/x86/kvm/irq.h b/arch/x86/kvm/irq.h
index 2086f2bfba33..ab3c039d652b 100644
--- a/arch/x86/kvm/irq.h
+++ b/arch/x86/kvm/irq.h
@@ -60,7 +60,7 @@ struct kvm_kpic_state {
 };
 
 struct kvm_pic {
-	spinlock_t lock;
+	raw_spinlock_t lock;
 	bool wakeup_needed;
 	unsigned pending_acks;
 	struct kvm *kvm;
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 7da4734082ba..15b3dc9bd5d4 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -3068,18 +3068,18 @@ static int kvm_vm_ioctl_set_irqchip(struct kvm *kvm, struct kvm_irqchip *chip)
 	r = 0;
 	switch (chip->chip_id) {
 	case KVM_IRQCHIP_PIC_MASTER:
-		spin_lock(&pic_irqchip(kvm)->lock);
+		raw_spin_lock(&pic_irqchip(kvm)->lock);
 		memcpy(&pic_irqchip(kvm)->pics[0],
 			&chip->chip.pic,
 			sizeof(struct kvm_pic_state));
-		spin_unlock(&pic_irqchip(kvm)->lock);
+		raw_spin_unlock(&pic_irqchip(kvm)->lock);
 		break;
 	case KVM_IRQCHIP_PIC_SLAVE:
-		spin_lock(&pic_irqchip(kvm)->lock);
+		raw_spin_lock(&pic_irqchip(kvm)->lock);
 		memcpy(&pic_irqchip(kvm)->pics[1],
 			&chip->chip.pic,
 			sizeof(struct kvm_pic_state));
-		spin_unlock(&pic_irqchip(kvm)->lock);
+		raw_spin_unlock(&pic_irqchip(kvm)->lock);
 		break;
 	case KVM_IRQCHIP_IOAPIC:
 		r = kvm_set_ioapic(kvm, &chip->chip.ioapic);
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index 4f017bb2b97a..3d21d242b132 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -612,8 +612,8 @@ struct kvm_assigned_dev_kernel {
 	int flags;
 	struct pci_dev *dev;
 	struct kvm *kvm;
-	spinlock_t intx_lock;
-	spinlock_t intx_mask_lock;
+	raw_spinlock_t intx_lock;
+	raw_spinlock_t intx_mask_lock;
 	char irq_name[32];
 	struct pci_saved_state *pci_saved_state;
 };
diff --git a/virt/kvm/assigned-dev.c b/virt/kvm/assigned-dev.c
index 118a632e02c1..58205ce15893 100644
--- a/virt/kvm/assigned-dev.c
+++ b/virt/kvm/assigned-dev.c
@@ -60,13 +60,13 @@ static irqreturn_t kvm_assigned_dev_intx(int irq, void *dev_id)
 	struct kvm_assigned_dev_kernel *assigned_dev = dev_id;
 	int ret;
 
-	spin_lock(&assigned_dev->intx_lock);
+	raw_spin_lock(&assigned_dev->intx_lock);
 	if (pci_check_and_mask_intx(assigned_dev->dev)) {
 		assigned_dev->host_irq_disabled = true;
 		ret = IRQ_WAKE_THREAD;
 	} else
 		ret = IRQ_NONE;
-	spin_unlock(&assigned_dev->intx_lock);
+	raw_spin_unlock(&assigned_dev->intx_lock);
 
 	return ret;
 }
@@ -77,12 +77,12 @@ kvm_assigned_dev_raise_guest_irq(struct kvm_assigned_dev_kernel *assigned_dev,
 {
 	if (unlikely(assigned_dev->irq_requested_type &
 		     KVM_DEV_IRQ_GUEST_INTX)) {
-		spin_lock(&assigned_dev->intx_mask_lock);
+		raw_spin_lock(&assigned_dev->intx_mask_lock);
 		if (!(assigned_dev->flags & KVM_DEV_ASSIGN_MASK_INTX))
 			kvm_set_irq(assigned_dev->kvm,
 				    assigned_dev->irq_source_id, vector, 1,
 				    false);
-		spin_unlock(&assigned_dev->intx_mask_lock);
+		raw_spin_unlock(&assigned_dev->intx_mask_lock);
 	} else
 		kvm_set_irq(assigned_dev->kvm, assigned_dev->irq_source_id,
 			    vector, 1, false);
@@ -93,10 +93,10 @@ static irqreturn_t kvm_assigned_dev_thread_intx(int irq, void *dev_id)
 	struct kvm_assigned_dev_kernel *assigned_dev = dev_id;
 
 	if (!(assigned_dev->flags & KVM_DEV_ASSIGN_PCI_2_3)) {
-		spin_lock_irq(&assigned_dev->intx_lock);
+		raw_spin_lock_irq(&assigned_dev->intx_lock);
 		disable_irq_nosync(irq);
 		assigned_dev->host_irq_disabled = true;
-		spin_unlock_irq(&assigned_dev->intx_lock);
+		raw_spin_unlock_irq(&assigned_dev->intx_lock);
 	}
 
 	kvm_assigned_dev_raise_guest_irq(assigned_dev,
@@ -142,12 +142,12 @@ static void kvm_assigned_dev_ack_irq(struct kvm_irq_ack_notifier *kian)
 
 	kvm_set_irq(dev->kvm, dev->irq_source_id, dev->guest_irq, 0, false);
 
-	spin_lock(&dev->intx_mask_lock);
+	raw_spin_lock(&dev->intx_mask_lock);
 
 	if (!(dev->flags & KVM_DEV_ASSIGN_MASK_INTX)) {
 		bool reassert = false;
 
-		spin_lock_irq(&dev->intx_lock);
+		raw_spin_lock_irq(&dev->intx_lock);
 		/*
 		 * The guest IRQ may be shared so this ack can come from an
 		 * IRQ for another guest device.
@@ -159,14 +159,14 @@ static void kvm_assigned_dev_ack_irq(struct kvm_irq_ack_notifier *kian)
 				reassert = true;
 			dev->host_irq_disabled = reassert;
 		}
-		spin_unlock_irq(&dev->intx_lock);
+		raw_spin_unlock_irq(&dev->intx_lock);
 
 		if (reassert)
 			kvm_set_irq(dev->kvm, dev->irq_source_id,
 				    dev->guest_irq, 1, false);
 	}
 
-	spin_unlock(&dev->intx_mask_lock);
+	raw_spin_unlock(&dev->intx_mask_lock);
 }
 
 static void deassign_guest_irq(struct kvm *kvm,
@@ -217,9 +217,9 @@ static void deassign_host_irq(struct kvm *kvm,
 		if ((assigned_dev->irq_requested_type &
 		     KVM_DEV_IRQ_HOST_INTX) &&
 		    (assigned_dev->flags & KVM_DEV_ASSIGN_PCI_2_3)) {
-			spin_lock_irq(&assigned_dev->intx_lock);
+			raw_spin_lock_irq(&assigned_dev->intx_lock);
 			pci_intx(assigned_dev->dev, false);
-			spin_unlock_irq(&assigned_dev->intx_lock);
+			raw_spin_unlock_irq(&assigned_dev->intx_lock);
 			synchronize_irq(assigned_dev->host_irq);
 		} else
 			disable_irq(assigned_dev->host_irq);
@@ -327,9 +327,9 @@ static int assigned_device_enable_host_intx(struct kvm *kvm,
 		return -EIO;
 
 	if (dev->flags & KVM_DEV_ASSIGN_PCI_2_3) {
-		spin_lock_irq(&dev->intx_lock);
+		raw_spin_lock_irq(&dev->intx_lock);
 		pci_intx(dev->dev, true);
-		spin_unlock_irq(&dev->intx_lock);
+		raw_spin_unlock_irq(&dev->intx_lock);
 	}
 	return 0;
 }
@@ -704,8 +704,8 @@ static int kvm_vm_ioctl_assign_device(struct kvm *kvm,
 	match->host_devfn = assigned_dev->devfn;
 	match->flags = assigned_dev->flags;
 	match->dev = dev;
-	spin_lock_init(&match->intx_lock);
-	spin_lock_init(&match->intx_mask_lock);
+	raw_spin_lock_init(&match->intx_lock);
+	raw_spin_lock_init(&match->intx_mask_lock);
 	match->irq_source_id = -1;
 	match->kvm = kvm;
 	match->ack_notifier.irq_acked = kvm_assigned_dev_ack_irq;
@@ -896,7 +896,7 @@ static int kvm_vm_ioctl_set_pci_irq_mask(struct kvm *kvm,
 		goto out;
 	}
 
-	spin_lock(&match->intx_mask_lock);
+	raw_spin_lock(&match->intx_mask_lock);
 
 	match->flags &= ~KVM_DEV_ASSIGN_MASK_INTX;
 	match->flags |= assigned_dev->flags & KVM_DEV_ASSIGN_MASK_INTX;
@@ -914,16 +914,16 @@ static int kvm_vm_ioctl_set_pci_irq_mask(struct kvm *kvm,
 			 * Unmask the IRQ line if required. Unmasking at
 			 * device level will be performed by user space.
 			 */
-			spin_lock_irq(&match->intx_lock);
+			raw_spin_lock_irq(&match->intx_lock);
 			if (match->host_irq_disabled) {
 				enable_irq(match->host_irq);
 				match->host_irq_disabled = false;
 			}
-			spin_unlock_irq(&match->intx_lock);
+			raw_spin_unlock_irq(&match->intx_lock);
 		}
 	}
 
-	spin_unlock(&match->intx_mask_lock);
+	raw_spin_unlock(&match->intx_mask_lock);
 
 out:
 	mutex_unlock(&kvm->lock);
diff --git a/virt/kvm/ioapic.c b/virt/kvm/ioapic.c
index 023b0158aba9..e092d018e74e 100644
--- a/virt/kvm/ioapic.c
+++ b/virt/kvm/ioapic.c
@@ -129,9 +129,9 @@ void kvm_rtc_eoi_tracking_restore_one(struct kvm_vcpu *vcpu)
 {
 	struct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	__rtc_irq_eoi_tracking_restore_one(vcpu);
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 }
 
 static void kvm_rtc_eoi_tracking_restore_all(struct kvm_ioapic *ioapic)
@@ -200,7 +200,7 @@ void kvm_ioapic_scan_entry(struct kvm_vcpu *vcpu, u64 *eoi_exit_bitmap,
 	union kvm_ioapic_redirect_entry *e;
 	int index;
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	for (index = 0; index < IOAPIC_NUM_PINS; index++) {
 		e = &ioapic->redirtbl[index];
 		if (!e->fields.mask &&
@@ -217,7 +217,7 @@ void kvm_ioapic_scan_entry(struct kvm_vcpu *vcpu, u64 *eoi_exit_bitmap,
 			}
 		}
 	}
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 }
 
 #ifdef CONFIG_X86
@@ -330,7 +330,7 @@ int kvm_ioapic_set_irq(struct kvm_ioapic *ioapic, int irq, int irq_source_id,
 	union kvm_ioapic_redirect_entry entry;
 	int ret = 1;
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	old_irr = ioapic->irr;
 	if (irq >= 0 && irq < IOAPIC_NUM_PINS) {
 		int irq_level = __kvm_irq_line_state(&ioapic->irq_states[irq],
@@ -357,7 +357,7 @@ int kvm_ioapic_set_irq(struct kvm_ioapic *ioapic, int irq, int irq_source_id,
 		trace_kvm_ioapic_set_irq(entry.bits, irq, ret == 0);
 	}
 out:
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 
 	return ret;
 }
@@ -366,10 +366,10 @@ void kvm_ioapic_clear_all(struct kvm_ioapic *ioapic, int irq_source_id)
 {
 	int i;
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	for (i = 0; i < KVM_IOAPIC_NUM_PINS; i++)
 		__clear_bit(irq_source_id, &ioapic->irq_states[i]);
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 }
 
 static void __kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu,
@@ -393,9 +393,9 @@ static void __kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu,
 		 * is dropped it will be put into irr and will be delivered
 		 * after ack notifier returns.
 		 */
-		spin_unlock(&ioapic->lock);
+		raw_spin_unlock(&ioapic->lock);
 		kvm_notify_acked_irq(ioapic->kvm, KVM_IRQCHIP_IOAPIC, i);
-		spin_lock(&ioapic->lock);
+		raw_spin_lock(&ioapic->lock);
 
 		if (trigger_mode != IOAPIC_LEVEL_TRIG)
 			continue;
@@ -418,9 +418,9 @@ void kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu, int vector, int trigger_mode)
 {
 	struct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	__kvm_ioapic_update_eoi(vcpu, ioapic, vector, trigger_mode);
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 }
 
 static inline struct kvm_ioapic *to_ioapic(struct kvm_io_device *dev)
@@ -446,7 +446,7 @@ static int ioapic_mmio_read(struct kvm_io_device *this, gpa_t addr, int len,
 	ASSERT(!(addr & 0xf));	/* check alignment */
 
 	addr &= 0xff;
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	switch (addr) {
 	case IOAPIC_REG_SELECT:
 		result = ioapic->ioregsel;
@@ -460,7 +460,7 @@ static int ioapic_mmio_read(struct kvm_io_device *this, gpa_t addr, int len,
 		result = 0;
 		break;
 	}
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 
 	switch (len) {
 	case 8:
@@ -506,7 +506,7 @@ static int ioapic_mmio_write(struct kvm_io_device *this, gpa_t addr, int len,
 	}
 
 	addr &= 0xff;
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	switch (addr) {
 	case IOAPIC_REG_SELECT:
 		ioapic->ioregsel = data & 0xFF; /* 8-bit register */
@@ -524,7 +524,7 @@ static int ioapic_mmio_write(struct kvm_io_device *this, gpa_t addr, int len,
 	default:
 		break;
 	}
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 	return 0;
 }
 
@@ -555,7 +555,7 @@ int kvm_ioapic_init(struct kvm *kvm)
 	ioapic = kzalloc(sizeof(struct kvm_ioapic), GFP_KERNEL);
 	if (!ioapic)
 		return -ENOMEM;
-	spin_lock_init(&ioapic->lock);
+	raw_spin_lock_init(&ioapic->lock);
 	kvm->arch.vioapic = ioapic;
 	kvm_ioapic_reset(ioapic);
 	kvm_iodevice_init(&ioapic->dev, &ioapic_mmio_ops);
@@ -589,9 +589,9 @@ int kvm_get_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state)
 	if (!ioapic)
 		return -EINVAL;
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	memcpy(state, ioapic, sizeof(struct kvm_ioapic_state));
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 	return 0;
 }
 
@@ -601,11 +601,11 @@ int kvm_set_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state)
 	if (!ioapic)
 		return -EINVAL;
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	memcpy(ioapic, state, sizeof(struct kvm_ioapic_state));
 	update_handled_vectors(ioapic);
 	kvm_vcpu_request_scan_ioapic(kvm);
 	kvm_rtc_eoi_tracking_restore_all(ioapic);
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 	return 0;
 }
diff --git a/virt/kvm/ioapic.h b/virt/kvm/ioapic.h
index 615d8c995c3c..db01b92a64de 100644
--- a/virt/kvm/ioapic.h
+++ b/virt/kvm/ioapic.h
@@ -56,7 +56,7 @@ struct kvm_ioapic {
 	struct kvm_io_device dev;
 	struct kvm *kvm;
 	void (*ack_notifier)(void *opaque, int irq);
-	spinlock_t lock;
+	raw_spinlock_t lock;
 	DECLARE_BITMAP(handled_vectors, 256);
 	struct rtc_status rtc_status;
 };
-- 
1.9.0

