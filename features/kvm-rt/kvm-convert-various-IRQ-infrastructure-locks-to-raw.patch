From 8cfaa886185c4aad8b92cad6ce659e757065f9d6 Mon Sep 17 00:00:00 2001
From: Paul Gortmaker <paul.gortmaker@windriver.com>
Date: Tue, 29 Apr 2014 15:55:40 -0400
Subject: [PATCH] kvm: convert various IRQ infrastructure locks to raw

David reports seeing the following when using the KVM
option "allow_unsafe_assigned_interrupts":

BUG: sleeping function called from invalid context at kernel/rtmutex.c:659
in_atomic(): 1, irqs_disabled(): 1, pid: 0, name: swapper/2
Preemption disabled at:[<ffffffff8180a5ef>] start_secondary+0x1ab/0x1b0

Pid: 0, comm: swapper/2 Tainted: G           O 3.4.82-ovp-ga2-rt95-WR5.0.1.13_preempt-rt #2
Call Trace:
 <IRQ>
  [<ffffffff8106ef4e>] __might_sleep+0xfe/0x170
  [<ffffffff8181b424>] rt_spin_lock+0x24/0x50
  [<ffffffffa01afe53>] kvm_assigned_dev_intx+0x33/0x70 [kvm]
  [<ffffffff810ccdf8>] handle_irq_event_percpu+0x98/0x2c0
  [<ffffffff813f9588>] ? intel_idle+0xd8/0x180
  [<ffffffff810cd07e>] handle_irq_event+0x5e/0x90
  [<ffffffff810d0401>] handle_fasteoi_irq+0xd1/0x140
  [<ffffffff81004672>] handle_irq+0x22/0x40
  [<ffffffff8182471a>] do_IRQ+0x5a/0xd0
  [<ffffffff8181bc27>] common_interrupt+0x67/0x67
 <EOI>
  [<ffffffff8181b7d8>] ? _raw_spin_unlock_irqrestore+0x18/0x50
  [<ffffffff813f9588>] ? intel_idle+0xd8/0x180
  [<ffffffff813f9567>] ? intel_idle+0xb7/0x180
  [<ffffffff8165b9f8>] cpuidle_enter+0x18/0x20
  [<ffffffff8165c064>] cpuidle_idle_call+0xd4/0x400
  [<ffffffff8100bf4a>] cpu_idle+0x7a/0x130
  [<ffffffff8180a5ef>] start_secondary+0x1ab/0x1b0

The locking order means that after the 1st conversion to silence
the above, two more locks need to be converted before no similar
warnings are produced.

Originally-by: "Mercado, David" <david.mercado@windriver.com>
Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/x86/kvm/assigned-dev.c b/arch/x86/kvm/assigned-dev.c
index 2d2d26017369..81954d4d0b93 100644
--- a/arch/x86/kvm/assigned-dev.c
+++ b/arch/x86/kvm/assigned-dev.c
@@ -41,8 +41,8 @@ struct kvm_assigned_dev_kernel {
 	int flags;
 	struct pci_dev *dev;
 	struct kvm *kvm;
-	spinlock_t intx_lock;
-	spinlock_t intx_mask_lock;
+	raw_spinlock_t intx_lock;
+	raw_spinlock_t intx_mask_lock;
 	char irq_name[32];
 	struct pci_saved_state *pci_saved_state;
 };
@@ -86,13 +86,13 @@ static irqreturn_t kvm_assigned_dev_intx(int irq, void *dev_id)
 	struct kvm_assigned_dev_kernel *assigned_dev = dev_id;
 	int ret;
 
-	spin_lock(&assigned_dev->intx_lock);
+	raw_spin_lock(&assigned_dev->intx_lock);
 	if (pci_check_and_mask_intx(assigned_dev->dev)) {
 		assigned_dev->host_irq_disabled = true;
 		ret = IRQ_WAKE_THREAD;
 	} else
 		ret = IRQ_NONE;
-	spin_unlock(&assigned_dev->intx_lock);
+	raw_spin_unlock(&assigned_dev->intx_lock);
 
 	return ret;
 }
@@ -103,12 +103,12 @@ kvm_assigned_dev_raise_guest_irq(struct kvm_assigned_dev_kernel *assigned_dev,
 {
 	if (unlikely(assigned_dev->irq_requested_type &
 		     KVM_DEV_IRQ_GUEST_INTX)) {
-		spin_lock(&assigned_dev->intx_mask_lock);
+		raw_spin_lock(&assigned_dev->intx_mask_lock);
 		if (!(assigned_dev->flags & KVM_DEV_ASSIGN_MASK_INTX))
 			kvm_set_irq(assigned_dev->kvm,
 				    assigned_dev->irq_source_id, vector, 1,
 				    false);
-		spin_unlock(&assigned_dev->intx_mask_lock);
+		raw_spin_unlock(&assigned_dev->intx_mask_lock);
 	} else
 		kvm_set_irq(assigned_dev->kvm, assigned_dev->irq_source_id,
 			    vector, 1, false);
@@ -119,10 +119,10 @@ static irqreturn_t kvm_assigned_dev_thread_intx(int irq, void *dev_id)
 	struct kvm_assigned_dev_kernel *assigned_dev = dev_id;
 
 	if (!(assigned_dev->flags & KVM_DEV_ASSIGN_PCI_2_3)) {
-		spin_lock_irq(&assigned_dev->intx_lock);
+		raw_spin_lock_irq(&assigned_dev->intx_lock);
 		disable_irq_nosync(irq);
 		assigned_dev->host_irq_disabled = true;
-		spin_unlock_irq(&assigned_dev->intx_lock);
+		raw_spin_unlock_irq(&assigned_dev->intx_lock);
 	}
 
 	kvm_assigned_dev_raise_guest_irq(assigned_dev,
@@ -194,12 +194,12 @@ static void kvm_assigned_dev_ack_irq(struct kvm_irq_ack_notifier *kian)
 
 	kvm_set_irq(dev->kvm, dev->irq_source_id, dev->guest_irq, 0, false);
 
-	spin_lock(&dev->intx_mask_lock);
+	raw_spin_lock(&dev->intx_mask_lock);
 
 	if (!(dev->flags & KVM_DEV_ASSIGN_MASK_INTX)) {
 		bool reassert = false;
 
-		spin_lock_irq(&dev->intx_lock);
+		raw_spin_lock_irq(&dev->intx_lock);
 		/*
 		 * The guest IRQ may be shared so this ack can come from an
 		 * IRQ for another guest device.
@@ -211,14 +211,14 @@ static void kvm_assigned_dev_ack_irq(struct kvm_irq_ack_notifier *kian)
 				reassert = true;
 			dev->host_irq_disabled = reassert;
 		}
-		spin_unlock_irq(&dev->intx_lock);
+		raw_spin_unlock_irq(&dev->intx_lock);
 
 		if (reassert)
 			kvm_set_irq(dev->kvm, dev->irq_source_id,
 				    dev->guest_irq, 1, false);
 	}
 
-	spin_unlock(&dev->intx_mask_lock);
+	raw_spin_unlock(&dev->intx_mask_lock);
 }
 
 static void deassign_guest_irq(struct kvm *kvm,
@@ -269,9 +269,9 @@ static void deassign_host_irq(struct kvm *kvm,
 		if ((assigned_dev->irq_requested_type &
 		     KVM_DEV_IRQ_HOST_INTX) &&
 		    (assigned_dev->flags & KVM_DEV_ASSIGN_PCI_2_3)) {
-			spin_lock_irq(&assigned_dev->intx_lock);
+			raw_spin_lock_irq(&assigned_dev->intx_lock);
 			pci_intx(assigned_dev->dev, false);
-			spin_unlock_irq(&assigned_dev->intx_lock);
+			raw_spin_unlock_irq(&assigned_dev->intx_lock);
 			synchronize_irq(assigned_dev->host_irq);
 		} else
 			disable_irq(assigned_dev->host_irq);
@@ -379,9 +379,9 @@ static int assigned_device_enable_host_intx(struct kvm *kvm,
 		return -EIO;
 
 	if (dev->flags & KVM_DEV_ASSIGN_PCI_2_3) {
-		spin_lock_irq(&dev->intx_lock);
+		raw_spin_lock_irq(&dev->intx_lock);
 		pci_intx(dev->dev, true);
-		spin_unlock_irq(&dev->intx_lock);
+		raw_spin_unlock_irq(&dev->intx_lock);
 	}
 	return 0;
 }
@@ -761,8 +761,8 @@ static int kvm_vm_ioctl_assign_device(struct kvm *kvm,
 	match->host_devfn = assigned_dev->devfn;
 	match->flags = assigned_dev->flags;
 	match->dev = dev;
-	spin_lock_init(&match->intx_lock);
-	spin_lock_init(&match->intx_mask_lock);
+	raw_spin_lock_init(&match->intx_lock);
+	raw_spin_lock_init(&match->intx_mask_lock);
 	match->irq_source_id = -1;
 	match->kvm = kvm;
 	match->ack_notifier.irq_acked = kvm_assigned_dev_ack_irq;
@@ -953,7 +953,7 @@ static int kvm_vm_ioctl_set_pci_irq_mask(struct kvm *kvm,
 		goto out;
 	}
 
-	spin_lock(&match->intx_mask_lock);
+	raw_spin_lock(&match->intx_mask_lock);
 
 	match->flags &= ~KVM_DEV_ASSIGN_MASK_INTX;
 	match->flags |= assigned_dev->flags & KVM_DEV_ASSIGN_MASK_INTX;
@@ -971,16 +971,16 @@ static int kvm_vm_ioctl_set_pci_irq_mask(struct kvm *kvm,
 			 * Unmask the IRQ line if required. Unmasking at
 			 * device level will be performed by user space.
 			 */
-			spin_lock_irq(&match->intx_lock);
+			raw_spin_lock_irq(&match->intx_lock);
 			if (match->host_irq_disabled) {
 				enable_irq(match->host_irq);
 				match->host_irq_disabled = false;
 			}
-			spin_unlock_irq(&match->intx_lock);
+			raw_spin_unlock_irq(&match->intx_lock);
 		}
 	}
 
-	spin_unlock(&match->intx_mask_lock);
+	raw_spin_unlock(&match->intx_mask_lock);
 
 out:
 	mutex_unlock(&kvm->lock);
diff --git a/arch/x86/kvm/i8259.c b/arch/x86/kvm/i8259.c
index fef922ff2635..9a0ee4c7810e 100644
--- a/arch/x86/kvm/i8259.c
+++ b/arch/x86/kvm/i8259.c
@@ -42,7 +42,7 @@ static void pic_irq_request(struct kvm *kvm, int level);
 static void pic_lock(struct kvm_pic *s)
 	__acquires(&s->lock)
 {
-	spin_lock(&s->lock);
+	raw_spin_lock(&s->lock);
 }
 
 static void pic_unlock(struct kvm_pic *s)
@@ -54,7 +54,7 @@ static void pic_unlock(struct kvm_pic *s)
 
 	s->wakeup_needed = false;
 
-	spin_unlock(&s->lock);
+	raw_spin_unlock(&s->lock);
 
 	if (wakeup) {
 		kvm_for_each_vcpu(i, vcpu, s->kvm) {
@@ -606,7 +606,7 @@ struct kvm_pic *kvm_create_pic(struct kvm *kvm)
 	s = kzalloc(sizeof(struct kvm_pic), GFP_KERNEL);
 	if (!s)
 		return NULL;
-	spin_lock_init(&s->lock);
+	raw_spin_lock_init(&s->lock);
 	s->kvm = kvm;
 	s->pics[0].elcr_mask = 0xf8;
 	s->pics[1].elcr_mask = 0xde;
diff --git a/arch/x86/kvm/ioapic.c b/arch/x86/kvm/ioapic.c
index 28146f03c514..b111b43777ad 100644
--- a/arch/x86/kvm/ioapic.c
+++ b/arch/x86/kvm/ioapic.c
@@ -136,9 +136,9 @@ void kvm_rtc_eoi_tracking_restore_one(struct kvm_vcpu *vcpu)
 {
 	struct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	__rtc_irq_eoi_tracking_restore_one(vcpu);
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 }
 
 static void kvm_rtc_eoi_tracking_restore_all(struct kvm_ioapic *ioapic)
@@ -253,7 +253,7 @@ void kvm_ioapic_scan_entry(struct kvm_vcpu *vcpu, u64 *eoi_exit_bitmap,
 	union kvm_ioapic_redirect_entry *e;
 	int index;
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	for (index = 0; index < IOAPIC_NUM_PINS; index++) {
 		e = &ioapic->redirtbl[index];
 		if (e->fields.trig_mode == IOAPIC_LEVEL_TRIG ||
@@ -269,7 +269,7 @@ void kvm_ioapic_scan_entry(struct kvm_vcpu *vcpu, u64 *eoi_exit_bitmap,
 			}
 		}
 	}
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 }
 
 void kvm_vcpu_request_scan_ioapic(struct kvm *kvm)
@@ -380,12 +380,12 @@ int kvm_ioapic_set_irq(struct kvm_ioapic *ioapic, int irq, int irq_source_id,
 
 	BUG_ON(irq < 0 || irq >= IOAPIC_NUM_PINS);
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	irq_level = __kvm_irq_line_state(&ioapic->irq_states[irq],
 					 irq_source_id, level);
 	ret = ioapic_set_irq(ioapic, irq, irq_level, line_status);
 
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 
 	return ret;
 }
@@ -394,10 +394,10 @@ void kvm_ioapic_clear_all(struct kvm_ioapic *ioapic, int irq_source_id)
 {
 	int i;
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	for (i = 0; i < KVM_IOAPIC_NUM_PINS; i++)
 		__clear_bit(irq_source_id, &ioapic->irq_states[i]);
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 }
 
 static void kvm_ioapic_eoi_inject_work(struct work_struct *work)
@@ -442,9 +442,9 @@ static void __kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu,
 		 * is dropped it will be put into irr and will be delivered
 		 * after ack notifier returns.
 		 */
-		spin_unlock(&ioapic->lock);
+		raw_spin_unlock(&ioapic->lock);
 		kvm_notify_acked_irq(ioapic->kvm, KVM_IRQCHIP_IOAPIC, i);
-		spin_lock(&ioapic->lock);
+		raw_spin_lock(&ioapic->lock);
 
 		if (trigger_mode != IOAPIC_LEVEL_TRIG ||
 		    kvm_apic_get_reg(apic, APIC_SPIV) & APIC_SPIV_DIRECTED_EOI)
@@ -479,9 +479,9 @@ void kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu, int vector, int trigger_mode)
 {
 	struct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	__kvm_ioapic_update_eoi(vcpu, ioapic, vector, trigger_mode);
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 }
 
 static inline struct kvm_ioapic *to_ioapic(struct kvm_io_device *dev)
@@ -507,7 +507,7 @@ static int ioapic_mmio_read(struct kvm_vcpu *vcpu, struct kvm_io_device *this,
 	ASSERT(!(addr & 0xf));	/* check alignment */
 
 	addr &= 0xff;
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	switch (addr) {
 	case IOAPIC_REG_SELECT:
 		result = ioapic->ioregsel;
@@ -521,7 +521,7 @@ static int ioapic_mmio_read(struct kvm_vcpu *vcpu, struct kvm_io_device *this,
 		result = 0;
 		break;
 	}
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 
 	switch (len) {
 	case 8:
@@ -567,7 +567,7 @@ static int ioapic_mmio_write(struct kvm_vcpu *vcpu, struct kvm_io_device *this,
 	}
 
 	addr &= 0xff;
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	switch (addr) {
 	case IOAPIC_REG_SELECT:
 		ioapic->ioregsel = data & 0xFF; /* 8-bit register */
@@ -580,7 +580,7 @@ static int ioapic_mmio_write(struct kvm_vcpu *vcpu, struct kvm_io_device *this,
 	default:
 		break;
 	}
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 	return 0;
 }
 
@@ -614,7 +614,7 @@ int kvm_ioapic_init(struct kvm *kvm)
 	ioapic = kzalloc(sizeof(struct kvm_ioapic), GFP_KERNEL);
 	if (!ioapic)
 		return -ENOMEM;
-	spin_lock_init(&ioapic->lock);
+	raw_spin_lock_init(&ioapic->lock);
 	INIT_DELAYED_WORK(&ioapic->eoi_inject, kvm_ioapic_eoi_inject_work);
 	kvm->arch.vioapic = ioapic;
 	kvm_ioapic_reset(ioapic);
@@ -650,10 +650,10 @@ int kvm_get_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state)
 	if (!ioapic)
 		return -EINVAL;
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	memcpy(state, ioapic, sizeof(struct kvm_ioapic_state));
 	state->irr &= ~ioapic->irr_delivered;
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 	return 0;
 }
 
@@ -663,13 +663,13 @@ int kvm_set_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state)
 	if (!ioapic)
 		return -EINVAL;
 
-	spin_lock(&ioapic->lock);
+	raw_spin_lock(&ioapic->lock);
 	memcpy(ioapic, state, sizeof(struct kvm_ioapic_state));
 	ioapic->irr = 0;
 	ioapic->irr_delivered = 0;
 	update_handled_vectors(ioapic);
 	kvm_vcpu_request_scan_ioapic(kvm);
 	kvm_ioapic_inject_all(ioapic, state->irr);
-	spin_unlock(&ioapic->lock);
+	raw_spin_unlock(&ioapic->lock);
 	return 0;
 }
diff --git a/arch/x86/kvm/ioapic.h b/arch/x86/kvm/ioapic.h
index ca0b0b4e6256..cdc7cbed6757 100644
--- a/arch/x86/kvm/ioapic.h
+++ b/arch/x86/kvm/ioapic.h
@@ -72,7 +72,7 @@ struct kvm_ioapic {
 	struct kvm_io_device dev;
 	struct kvm *kvm;
 	void (*ack_notifier)(void *opaque, int irq);
-	spinlock_t lock;
+	raw_spinlock_t lock;
 	DECLARE_BITMAP(handled_vectors, 256);
 	struct rtc_status rtc_status;
 	struct delayed_work eoi_inject;
diff --git a/arch/x86/kvm/irq.h b/arch/x86/kvm/irq.h
index ad68c73008c5..0e1d037fd318 100644
--- a/arch/x86/kvm/irq.h
+++ b/arch/x86/kvm/irq.h
@@ -60,7 +60,7 @@ struct kvm_kpic_state {
 };
 
 struct kvm_pic {
-	spinlock_t lock;
+	raw_spinlock_t lock;
 	bool wakeup_needed;
 	unsigned pending_acks;
 	struct kvm *kvm;
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 49d5b85ff74b..02aeb5b0c2a6 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -3701,18 +3701,18 @@ static int kvm_vm_ioctl_set_irqchip(struct kvm *kvm, struct kvm_irqchip *chip)
 	r = 0;
 	switch (chip->chip_id) {
 	case KVM_IRQCHIP_PIC_MASTER:
-		spin_lock(&pic_irqchip(kvm)->lock);
+		raw_spin_lock(&pic_irqchip(kvm)->lock);
 		memcpy(&pic_irqchip(kvm)->pics[0],
 			&chip->chip.pic,
 			sizeof(struct kvm_pic_state));
-		spin_unlock(&pic_irqchip(kvm)->lock);
+		raw_spin_unlock(&pic_irqchip(kvm)->lock);
 		break;
 	case KVM_IRQCHIP_PIC_SLAVE:
-		spin_lock(&pic_irqchip(kvm)->lock);
+		raw_spin_lock(&pic_irqchip(kvm)->lock);
 		memcpy(&pic_irqchip(kvm)->pics[1],
 			&chip->chip.pic,
 			sizeof(struct kvm_pic_state));
-		spin_unlock(&pic_irqchip(kvm)->lock);
+		raw_spin_unlock(&pic_irqchip(kvm)->lock);
 		break;
 	case KVM_IRQCHIP_IOAPIC:
 		r = kvm_set_ioapic(kvm, &chip->chip.ioapic);
-- 
2.5.0

