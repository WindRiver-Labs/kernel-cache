From fe921c8949166a332f0655ed6c6d078fb7972cd8 Mon Sep 17 00:00:00 2001
From: zou cao <cao.zou@windriver.com>
Date: Wed, 26 Apr 2017 14:31:32 +0800
Subject: [PATCH] imx: gpcv2: use raw_spin_lock to make it irq safe

The gpcv2_lock is used to sync between A9 and M4. it maybe used from
any context including hard-irq one, and the normal spinlock will
become sleepable in rt kernel and will trigger the following
call trace:
BUG: sleeping function called from invalid context at kernel/locking/rtmutex.c:917
in_atomic(): 1, irqs_disabled(): 128, pid: 508, name: sh
Preemption disabled at:[<  (null)>]   (null)

CPU: 0 PID: 0 Comm: swapper/0 Not tainted 4.1.21-rt13-WR8.0.0.16_preempt-rt #1
Hardware name: Freescale i.MX7 Dual (Device Tree)
[<8001a0e8>] (unwind_backtrace) from [<80013b30>] (show_stack+0x20/0x24)
[<80013b30>] (show_stack) from [<808e586c>] (dump_stack+0x84/0xa8)
[<808e586c>] (dump_stack) from [<8005b164>] (___might_sleep+0x184/0x1b8)
[<8005b164>] (___might_sleep) from [<808ece10>] (rt_spin_lock+0x28/0x78)
[<808ece10>] (rt_spin_lock) from [<80029ab0>] (imx_gpcv2_set_lpm_mode+0x28/0xcc)
[<80029ab0>] (imx_gpcv2_set_lpm_mode) from [<800276b8>] (imx7d_enter_low_power_idle+0x178/0x198)
[<800276b8>] (imx7d_enter_low_power_idle) from [<80637378>] (cpuidle_enter_state+0x124/0x394)
[<80637378>] (cpuidle_enter_state) from [<80637638>] (cpuidle_enter+0x24/0x28)
[<80637638>] (cpuidle_enter) from [<8007334c>] (cpu_startup_entry+0x388/0x4f0)
[<8007334c>] (cpu_startup_entry) from [<808e1dc4>] (rest_init+0x84/0x9c)
[<808e1dc4>] (rest_init) from [<80c4ecbc>] (start_kernel+0x36c/0x3dc)
BUG: sleeping function called from invalid context at kernel/locking/rtmutex.c:917
in_atomic(): 1, irqs_disabled(): 128, pid: 0, name: swapper/1
Preemption disabled at:[< (null)>] (null)

Signed-off-by: zou cao <cao.zou@windriver.com>
---
 arch/arm/mach-imx/gpcv2.c |   30 +++++++++++++++---------------
 1 files changed, 15 insertions(+), 15 deletions(-)

diff --git a/arch/arm/mach-imx/gpcv2.c b/arch/arm/mach-imx/gpcv2.c
index 0e25024..ea7d6e2 100644
--- a/arch/arm/mach-imx/gpcv2.c
+++ b/arch/arm/mach-imx/gpcv2.c
@@ -114,7 +114,7 @@ static u32 gpcv2_saved_imrs[IMR_NUM];
 static u32 gpcv2_saved_imrs_m4[IMR_NUM];
 static u32 gpcv2_mf_irqs[IMR_NUM];
 static u32 gpcv2_mf_request_on[IMR_NUM];
-static DEFINE_SPINLOCK(gpcv2_lock);
+static DEFINE_RAW_SPINLOCK(gpcv2_lock);
 static struct notifier_block nb_mipi, nb_pcie, nb_usb_hsic;
 
 void imx_gpcv2_add_m4_wake_up_irq(u32 hwirq, bool enable)
@@ -128,10 +128,10 @@ void imx_gpcv2_add_m4_wake_up_irq(u32 hwirq, bool enable)
 		return;
 
 	mask = 1 << hwirq % 32;
-	spin_lock_irqsave(&gpcv2_lock, flags);
+	raw_spin_lock_irqsave(&gpcv2_lock, flags);
 	gpcv2_wake_irqs[idx] = enable ? gpcv2_wake_irqs[idx] | mask :
 		gpcv2_wake_irqs[idx] & ~mask;
-	spin_unlock_irqrestore(&gpcv2_lock, flags);
+	raw_spin_unlock_irqrestore(&gpcv2_lock, flags);
 }
 
 static int imx_gpcv2_irq_set_wake(struct irq_data *d, unsigned int on)
@@ -143,10 +143,10 @@ static int imx_gpcv2_irq_set_wake(struct irq_data *d, unsigned int on)
 	BUG_ON(idx >= IMR_NUM);
 
 	mask = 1 << d->hwirq % 32;
-	spin_lock_irqsave(&gpcv2_lock, flags);
+	raw_spin_lock_irqsave(&gpcv2_lock, flags);
 	gpcv2_wake_irqs[idx] = on ? gpcv2_wake_irqs[idx] | mask :
 				  gpcv2_wake_irqs[idx] & ~mask;
-	spin_unlock_irqrestore(&gpcv2_lock, flags);
+	raw_spin_unlock_irqrestore(&gpcv2_lock, flags);
 
 	return 0;
 }
@@ -232,7 +232,7 @@ void imx_gpcv2_set_lpm_mode(enum mxc_cpu_pwr_mode mode)
 	unsigned long flags;
 	u32 val1, val2;
 
-	spin_lock_irqsave(&gpcv2_lock, flags);
+	raw_spin_lock_irqsave(&gpcv2_lock, flags);
 
 	val1 = readl_relaxed(gpc_base + GPC_LPCR_A7_BSC);
 	val2 = readl_relaxed(gpc_base + GPC_SLPCR);
@@ -289,7 +289,7 @@ void imx_gpcv2_set_lpm_mode(enum mxc_cpu_pwr_mode mode)
 	writel_relaxed(val1, gpc_base + GPC_LPCR_A7_BSC);
 	writel_relaxed(val2, gpc_base + GPC_SLPCR);
 
-	spin_unlock_irqrestore(&gpcv2_lock, flags);
+	raw_spin_unlock_irqrestore(&gpcv2_lock, flags);
 }
 
 void imx_gpcv2_set_plat_power_gate_by_lpm(bool pdn)
@@ -335,7 +335,7 @@ void imx_gpcv2_set_cpu_power_gate_by_wfi(u32 cpu, bool pdn)
 	unsigned long flags;
 	u32 val;
 
-	spin_lock_irqsave(&gpcv2_lock, flags);
+	raw_spin_lock_irqsave(&gpcv2_lock, flags);
 	val = readl_relaxed(gpc_base + GPC_LPCR_A7_AD);
 
 	if (cpu == 0) {
@@ -361,7 +361,7 @@ void imx_gpcv2_set_cpu_power_gate_by_wfi(u32 cpu, bool pdn)
 		}
 	}
 	writel_relaxed(val, gpc_base + GPC_LPCR_A7_AD);
-	spin_unlock_irqrestore(&gpcv2_lock, flags);
+	raw_spin_unlock_irqrestore(&gpcv2_lock, flags);
 }
 
 void imx_gpcv2_set_cpu_power_gate_by_lpm(u32 cpu, bool pdn)
@@ -369,7 +369,7 @@ void imx_gpcv2_set_cpu_power_gate_by_lpm(u32 cpu, bool pdn)
 	unsigned long flags;
 	u32 val;
 
-	spin_lock_irqsave(&gpcv2_lock, flags);
+	raw_spin_lock_irqsave(&gpcv2_lock, flags);
 
 	val = readl_relaxed(gpc_base + GPC_LPCR_A7_AD);
 	if (cpu == 0) {
@@ -390,7 +390,7 @@ void imx_gpcv2_set_cpu_power_gate_by_lpm(u32 cpu, bool pdn)
 	}
 
 	writel_relaxed(val, gpc_base + GPC_LPCR_A7_AD);
-	spin_unlock_irqrestore(&gpcv2_lock, flags);
+	raw_spin_unlock_irqrestore(&gpcv2_lock, flags);
 }
 
 void imx_gpcv2_set_cpu_power_gate_in_idle(bool pdn)
@@ -401,7 +401,7 @@ void imx_gpcv2_set_cpu_power_gate_in_idle(bool pdn)
 	for_each_possible_cpu(cpu)
 		imx_gpcv2_set_cpu_power_gate_by_lpm(cpu, pdn);
 
-	spin_lock_irqsave(&gpcv2_lock, flags);
+	raw_spin_lock_irqsave(&gpcv2_lock, flags);
 
 	imx_gpcv2_set_m_core_pgc(pdn, GPC_PGC_C0);
 	if (num_online_cpus() > 1)
@@ -430,7 +430,7 @@ void imx_gpcv2_set_cpu_power_gate_in_idle(bool pdn)
 			gpc_base + GPC_PGC_ACK_SEL_A7);
 		imx_gpcv2_enable_rbc(false);
 	}
-	spin_unlock_irqrestore(&gpcv2_lock, flags);
+	raw_spin_unlock_irqrestore(&gpcv2_lock, flags);
 }
 
 void imx_gpcv2_set_mix_phy_gate_by_lpm(u32 pdn_index, u32 pup_index)
@@ -474,10 +474,10 @@ int imx_gpcv2_mf_power_on(unsigned int irq, unsigned int on)
 
 	BUG_ON(idx >= IMR_NUM);
 
-	spin_lock_irqsave(&gpcv2_lock, flags);
+	raw_spin_lock_irqsave(&gpcv2_lock, flags);
 	gpcv2_mf_request_on[idx] = on ? gpcv2_mf_request_on[idx] | mask :
 				  gpcv2_mf_request_on[idx] & ~mask;
-	spin_unlock_irqrestore(&gpcv2_lock, flags);
+	raw_spin_unlock_irqrestore(&gpcv2_lock, flags);
 
 	return 0;
 }
-- 
1.7.5.4

