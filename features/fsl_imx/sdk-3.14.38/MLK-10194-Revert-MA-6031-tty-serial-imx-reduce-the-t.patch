From 9f8ef4057d7d8f11a511a5b9948e888cc3fede22 Mon Sep 17 00:00:00 2001
From: Fugang Duan <b38611@freescale.com>
Date: Mon, 2 Feb 2015 15:35:03 +0800
Subject: [PATCH 0131/1594] MLK-10194 Revert "MA-6031 tty: serial: imx: reduce
 the transmit and receive latency"

commit 739d2f5c51e00df8030a171cb6eec5e0da9b9a4a from
git://git.freescale.com/imx/linux-2.6-imx.git

The patch "MA-6031 tty: serial: imx: reduce the transmit and receive latency"
cannot pass stress test, so revert it now.

Signed-off-by: Fugang Duan <B38611@freescale.com>
---
 drivers/tty/serial/imx.c |   35 +++++++++++++++++++++++------------
 1 files changed, 23 insertions(+), 12 deletions(-)

diff --git a/drivers/tty/serial/imx.c b/drivers/tty/serial/imx.c
index ee38951..4521938 100644
--- a/drivers/tty/serial/imx.c
+++ b/drivers/tty/serial/imx.c
@@ -234,6 +234,8 @@ struct imx_port {
 	struct imx_dma_rxbuf	rx_buf;
 	unsigned int		tx_bytes;
 	unsigned int		dma_tx_nents;
+	struct delayed_work	tsk_dma_tx;
+	struct work_struct	tsk_dma_rx;
 	wait_queue_head_t	dma_wait;
 	unsigned int            saved_reg[11];
 #define DMA_TX_IS_WORKING 1
@@ -441,7 +443,6 @@ static void imx_enable_ms(struct uart_port *port)
 	mod_timer(&sport->timer, jiffies);
 }
 
-static void imx_dma_tx(struct imx_port *sport);
 static inline void imx_transmit_buffer(struct imx_port *sport)
 {
 	struct circ_buf *xmit = &sport->port.state->xmit;
@@ -472,7 +473,7 @@ static inline void imx_transmit_buffer(struct imx_port *sport)
 			writel(temp, sport->port.membase + UCR1);
 		} else {
 			writel(temp, sport->port.membase + UCR1);
-			schedule_work(&sport->tsk_dma_tx);
+			schedule_delayed_work(&sport->tsk_dma_tx, 0);
 		}
 	}
 
@@ -515,7 +516,7 @@ static void dma_tx_callback(void *data)
 	dev_dbg(sport->port.dev, "we finish the TX DMA.\n");
 
 	clear_bit(DMA_TX_IS_WORKING, &sport->flags);
-	smp_mb__after_clear_bit();
+	smp_mb__after_atomic();
 
 	sport->dma_is_txing = 0;
 
@@ -524,25 +525,26 @@ static void dma_tx_callback(void *data)
 	if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS)
 		uart_write_wakeup(&sport->port);
 
+	schedule_delayed_work(&sport->tsk_dma_tx, msecs_to_jiffies(1));
+
 	if (waitqueue_active(&sport->dma_wait)) {
 		wake_up(&sport->dma_wait);
 		dev_dbg(sport->port.dev, "exit in %s.\n", __func__);
 		return;
 	}
 
-	spin_lock_irqsave(&sport->port.lock, flags);
-	if (!uart_circ_empty(xmit) && !uart_tx_stopped(&sport->port))
-		imx_dma_tx(sport);
-	spin_unlock_irqrestore(&sport->port.lock, flags);
 }
 
-static void imx_dma_tx(struct imx_port *sport)
+static void dma_tx_work(struct work_struct *w)
 {
+	struct delayed_work *delay_work = to_delayed_work(w);
+	struct imx_port *sport = container_of(delay_work, struct imx_port, tsk_dma_tx);
 	struct circ_buf *xmit = &sport->port.state->xmit;
 	struct scatterlist *sgl = sport->tx_sgl;
 	struct dma_async_tx_descriptor *desc;
 	struct dma_chan	*chan = sport->dma_chan_tx;
 	struct device *dev = sport->port.dev;
+	unsigned long flags;
 	unsigned long temp;
 	int ret;
 
@@ -552,6 +554,7 @@ static void imx_dma_tx(struct imx_port *sport)
 	if (test_and_set_bit(DMA_TX_IS_WORKING, &sport->flags))
 		return;
 
+	spin_lock_irqsave(&sport->port.lock, flags);
 	sport->tx_bytes = uart_circ_chars_pending(xmit);
 
 	if (sport->tx_bytes > 0) {
@@ -565,6 +568,7 @@ static void imx_dma_tx(struct imx_port *sport)
 					UART_XMIT_SIZE - xmit->tail);
 			sg_set_buf(sgl + 1, xmit->buf, xmit->head);
 		}
+		spin_unlock_irqrestore(&sport->port.lock, flags);
 
 		ret = dma_map_sg(dev, sgl, sport->dma_tx_nents, DMA_TO_DEVICE);
 		if (ret == 0) {
@@ -597,9 +601,10 @@ static void imx_dma_tx(struct imx_port *sport)
 		return;
 	}
 
+	spin_unlock_irqrestore(&sport->port.lock, flags);
 err_out:
 	clear_bit(DMA_TX_IS_WORKING, &sport->flags);
-	smp_mb__after_clear_bit();
+	smp_mb__after_atomic();
 }
 
 /*
@@ -642,7 +647,7 @@ static void imx_start_tx(struct uart_port *port)
 
 		if (!uart_circ_empty(&port->state->xmit) &&
 		    !uart_tx_stopped(port))
-			imx_dma_tx(sport);
+			schedule_delayed_work(&sport->tsk_dma_tx, 0);
 		return;
 	}
 }
@@ -908,8 +913,9 @@ static void dma_rx_push_data(struct imx_port *sport, struct tty_struct *tty,
 	spin_unlock_irqrestore(&sport->port.lock, flags);
 }
 
-static void dma_rx_work(struct imx_port *sport)
+static void dma_rx_work(struct work_struct *w)
 {
+	struct imx_port *sport = container_of(w, struct imx_port, tsk_dma_rx);
 	struct tty_struct *tty = sport->port.state->port.tty;
 	unsigned int cur_idx = sport->rx_buf.cur_idx;
 
@@ -983,7 +989,7 @@ static void dma_rx_callback(void *data)
 		dev_err(sport->port.dev, "overwrite!\n");
 
 	if (count)
-		dma_rx_work(sport);
+		schedule_work(&sport->tsk_dma_rx);
 }
 
 static int start_rx_dma(struct imx_port *sport)
@@ -1186,6 +1192,11 @@ static int imx_startup(struct uart_port *port)
 		&& !sport->dma_is_inited)
 		imx_uart_dma_init(sport);
 
+	if (sport->dma_is_inited) {
+		INIT_DELAYED_WORK(&sport->tsk_dma_tx, dma_tx_work);
+		INIT_WORK(&sport->tsk_dma_rx, dma_rx_work);
+	}
+
 	spin_lock_irqsave(&sport->port.lock, flags);
 
 	/*
-- 
1.7.5.4

