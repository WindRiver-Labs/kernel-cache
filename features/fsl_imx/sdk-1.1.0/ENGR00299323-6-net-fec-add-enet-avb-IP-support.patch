From 694de4a9617e403eeb491299922f43641361cfc0 Mon Sep 17 00:00:00 2001
From: Fugang Duan <B38611@freescale.com>
Date: Mon, 13 Jan 2014 15:22:37 +0800
Subject: [PATCH 1030/1074] ENGR00299323-6 net:fec: add enet-avb IP support

i.MX6SX Enet-AVB support 3 tx queues, 3 rx queues.
For tx queues: ring 0 -> best effort
	       ring 1 -> Class A
	       ring 2 -> Class B
For rx queues:
	       ring 0 -> best effort
	       ring 1 -> receive VLAN packet with classification match
	       ring 2 -> receive VLAN packet with classification match

Add enet-avb IP multiqueue support for the driver.

Signed-off-by: Fugang Duan <B38611@freescale.com>
[Original patch taken from git://git.freescale.com/imx/linux-2.6-imx.git]
Signed-off-by: Biyao Zhai <biyao.zhai@windriver.com>
---
 drivers/net/ethernet/freescale/fec.h      |   64 +++++++++++++++--
 drivers/net/ethernet/freescale/fec_main.c |  108 +++++++++++++++++++---------
 2 files changed, 130 insertions(+), 42 deletions(-)

diff --git a/drivers/net/ethernet/freescale/fec.h b/drivers/net/ethernet/freescale/fec.h
index 47c1b98..7a80d79 100644
--- a/drivers/net/ethernet/freescale/fec.h
+++ b/drivers/net/ethernet/freescale/fec.h
@@ -30,8 +30,8 @@
  */
 #define FEC_IEVENT		0x004 /* Interrupt event reg */
 #define FEC_IMASK		0x008 /* Interrupt mask reg */
-#define FEC_R_DES_ACTIVE	0x010 /* Receive descriptor reg */
-#define FEC_X_DES_ACTIVE	0x014 /* Transmit descriptor reg */
+#define FEC_R_DES_ACTIVE_0	0x010 /* Receive descriptor reg */
+#define FEC_X_DES_ACTIVE_0	0x014 /* Transmit descriptor reg */
 #define FEC_ECNTRL		0x024 /* Ethernet control reg */
 #define FEC_MII_DATA		0x040 /* MII manage frame reg */
 #define FEC_MII_SPEED		0x044 /* MII speed control reg */
@@ -41,6 +41,12 @@
 #define FEC_ADDR_LOW		0x0e4 /* Low 32bits MAC address */
 #define FEC_ADDR_HIGH		0x0e8 /* High 16bits MAC address */
 #define FEC_OPD			0x0ec /* Opcode + Pause duration */
+#define FEC_TXIC0		0xF0  /* Transmit Interrupt Coalescing for ring 0 */
+#define FEC_TXIC1		0xF4  /* Transmit Interrupt Coalescing for ring 1 */
+#define FEC_TXIC2		0xF8  /* Transmit Interrupt Coalescing for ring 2 */
+#define FEC_RXIC0		0x100 /* Receive Interrupt Coalescing for ring 0 */
+#define FEC_RXIC1		0x104 /* Receive Interrupt Coalescing for ring 1 */
+#define FEC_RXIC2		0x108 /* Receive Interrupt Coalescing for ring 2 */
 #define FEC_HASH_TABLE_HIGH	0x118 /* High 32bits hash table */
 #define FEC_HASH_TABLE_LOW	0x11c /* Low 32bits hash table */
 #define FEC_GRP_HASH_TABLE_HIGH	0x120 /* High 32bits hash table */
@@ -48,14 +54,27 @@
 #define FEC_X_WMRK		0x144 /* FIFO transmit water mark */
 #define FEC_R_BOUND		0x14c /* FIFO receive bound reg */
 #define FEC_R_FSTART		0x150 /* FIFO receive start reg */
-#define FEC_R_DES_START		0x180 /* Receive descriptor ring */
-#define FEC_X_DES_START		0x184 /* Transmit descriptor ring */
+#define FEC_R_DES_START_1	0x160 /* Receive descriptor ring 1 */
+#define FEC_X_DES_START_1	0x164 /* Transmit descriptor ring 1 */
+#define FEC_R_DES_START_2	0x16c /* Receive descriptor ring 2 */
+#define FEC_X_DES_START_2	0x170 /* Transmit descriptor ring 2 */
+#define FEC_R_DES_START_0	0x180 /* Receive descriptor ring */
+#define FEC_X_DES_START_0	0x184 /* Transmit descriptor ring */
 #define FEC_R_BUFF_SIZE		0x188 /* Maximum receive buff size */
 #define FEC_R_FIFO_RSFL		0x190 /* Receive FIFO section full threshold */
 #define FEC_R_FIFO_RSEM		0x194 /* Receive FIFO section empty threshold */
 #define FEC_R_FIFO_RAEM		0x198 /* Receive FIFO almost empty threshold */
 #define FEC_R_FIFO_RAFL		0x19c /* Receive FIFO almost full threshold */
 #define FEC_RACC		0x1C4 /* Receive Accelerator function */
+#define FEC_RCMR_1		0x1c8 /* Receive classification match ring 1 */
+#define FEC_RCMR_2		0x1cc /* Receive classification match ring 2 */
+#define FEC_DMA_CFG_1		0x1d8 /* DMA class based configuration for ring 1 */
+#define FEC_DMA_CFG_2		0x1dc /* DMA class based Configuration for ring 2 */
+#define FEC_R_DES_ACTIVE_1	0x1e0 /* Receive descriptor active for ring 1 */
+#define FEC_X_DES_ACTIVE_1	0x1e4 /* Transmit descriptor active for ring 1 */
+#define FEC_R_DES_ACTIVE_2	0x1e8 /* Receive descriptor active for ring 2 */
+#define FEC_X_DES_ACTIVE_2	0x1ec /* Transmit descriptor active for ring 2 */
+#define FEC_QOS_SCHEME		0x1f0 /* Set multi queues Qos scheme */
 #define FEC_MIIGSK_CFGR		0x300 /* MIIGSK Configuration reg */
 #define FEC_MIIGSK_ENR		0x308 /* MIIGSK Enable reg */
 
@@ -275,18 +294,49 @@ struct bufdesc_ex {
 #define FEC_ENET_BABR   ((uint)0x40000000)      /* Babbling receiver */
 #define FEC_ENET_BABT   ((uint)0x20000000)      /* Babbling transmitter */
 #define FEC_ENET_GRA    ((uint)0x10000000)      /* Graceful stop complete */
-#define FEC_ENET_TXF    ((uint)0x08000000)      /* Full frame transmitted */
+#define FEC_ENET_TXF_0	((uint)0x08000000)	/* Full frame transmitted */
+#define FEC_ENET_TXF_1	((uint)0x00000008)	/* Full frame transmitted */
+#define FEC_ENET_TXF_2	((uint)0x00000080)	/* Full frame transmitted */
 #define FEC_ENET_TXB    ((uint)0x04000000)      /* A buffer was transmitted */
-#define FEC_ENET_RXF    ((uint)0x02000000)      /* Full frame received */
+#define FEC_ENET_RXF_0	((uint)0x02000000)	/* Full frame received */
+#define FEC_ENET_RXF_1	((uint)0x00000002)	/* Full frame received */
+#define FEC_ENET_RXF_2	((uint)0x00000020)	/* Full frame received */
 #define FEC_ENET_RXB    ((uint)0x01000000)      /* A buffer was received */
 #define FEC_ENET_MII    ((uint)0x00800000)      /* MII interrupt */
 #define FEC_ENET_EBERR  ((uint)0x00400000)      /* SDMA bus error */
+#define FEC_ENET_TXF	(FEC_ENET_TXF_0 | FEC_ENET_TXF_1 | FEC_ENET_TXF_2)
+#define FEC_ENET_RXF	(FEC_ENET_RXF_0 | FEC_ENET_RXF_1 | FEC_ENET_RXF_2)
 #define FEC_ENET_TS_AVAIL       ((uint)0x00010000)
 #define FEC_ENET_TS_TIMER       ((uint)0x00008000)
 
 #define FEC_DEFAULT_IMASK (FEC_ENET_TXF | FEC_ENET_RXF | FEC_ENET_MII | FEC_ENET_TS_TIMER)
 #define FEC_RX_DISABLED_IMASK (FEC_DEFAULT_IMASK & (~FEC_ENET_RXF))
 
+/* ENET AVB related macros define */
+#define FEC_R_DES_START(X)	((X == 1) ? FEC_R_DES_START_1 : \
+				((X == 2) ? FEC_R_DES_START_2 : FEC_R_DES_START_0))
+#define FEC_X_DES_START(X)	((X == 1) ? FEC_X_DES_START_1 : \
+				((X == 2) ? FEC_X_DES_START_2 : FEC_X_DES_START_0))
+#define FEC_R_DES_ACTIVE(X)	((X == 1) ? FEC_R_DES_ACTIVE_1 : \
+				((X == 2) ? FEC_R_DES_ACTIVE_2 : FEC_R_DES_ACTIVE_0))
+#define FEC_X_DES_ACTIVE(X)	((X == 1) ? FEC_X_DES_ACTIVE_1 : \
+				((X == 2) ? FEC_X_DES_ACTIVE_2 : FEC_X_DES_ACTIVE_0))
+#define FEC_DMA_CFG(X)		((X == 2) ? FEC_DMA_CFG_2 : FEC_DMA_CFG_1)
+#define FEC_RCMR(X)		((X == 2) ? FEC_RCMR_2 : FEC_RCMR_1)
+#define DMA_CLASS_EN		(1 << 16)
+#define IDLE_SLOPE_MASK		0xFFFF
+#define IDLE_SLOPE_1		0x200 /* BW fraction: 0.5 */
+#define IDLE_SLOPE_2		0x100 /* BW fraction: 0.33 */
+#define IDLE_SLOPE(X)		((X == 1) ? (IDLE_SLOPE_1 & IDLE_SLOPE_MASK) : \
+				(IDLE_SLOPE_2 & IDLE_SLOPE_MASK))
+#define RCMR_MATCHEN		(0x1 << 16)
+#define RCMR_CMP_CFG(v, n)	((v & 0x7) <<  (n << 2))
+#define RCMR_CMP_1		(RCMR_CMP_CFG(0, 0) | RCMR_CMP_CFG(1, 1) | \
+				RCMR_CMP_CFG(2, 2) | RCMR_CMP_CFG(3, 3))
+#define RCMR_CMP_2		(RCMR_CMP_CFG(4, 0) | RCMR_CMP_CFG(5, 1) | \
+				RCMR_CMP_CFG(6, 2) | RCMR_CMP_CFG(7, 3))
+#define RCMR_CMP(X)		((X == 1) ? RCMR_CMP_1 : RCMR_CMP_2)
+
 /* IEEE 1588 definition */
 #define FEC_T_PERIOD_ONE_SEC           0x3B9ACA00
 
@@ -381,7 +431,7 @@ struct ptp_time_correct {
 struct fec_enet_delayed_work {
 	struct delayed_work delay_work;
 	bool timeout;
-	bool trig_tx;
+	int trig_tx;
 };
 
 struct fec_enet_priv_tx_q {
diff --git a/drivers/net/ethernet/freescale/fec_main.c b/drivers/net/ethernet/freescale/fec_main.c
index 817194e..0e63db7 100644
--- a/drivers/net/ethernet/freescale/fec_main.c
+++ b/drivers/net/ethernet/freescale/fec_main.c
@@ -433,7 +433,7 @@ fec_enet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
 	bdp_pre = fec_enet_get_prevdesc(bdp, fep);
 	if ((id_entry->driver_data & FEC_QUIRK_ERR006358) &&
 	    !(bdp_pre->cbd_sc & BD_ENET_TX_READY)) {
-		fep->delay_work.trig_tx = true;
+		fep->delay_work.trig_tx = queue + 1;
 		schedule_delayed_work(&(fep->delay_work.delay_work),
 					msecs_to_jiffies(1));
 	}
@@ -449,7 +449,7 @@ fec_enet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
 		netif_tx_stop_queue(nq);
 
 	/* Trigger transmission start */
-	writel(0, fep->hwp + FEC_X_DES_ACTIVE);
+	writel(0, fep->hwp + FEC_X_DES_ACTIVE(queue));
 
 	return NETDEV_TX_OK;
 }
@@ -511,17 +511,41 @@ static void fec_enet_bd_init(struct net_device *dev)
 	}
 }
 
-static inline void fec_enet_enable_ring(struct net_device *ndev)
+static void fec_enet_active_rxring(struct net_device *ndev)
+{
+	struct fec_enet_private *fep = netdev_priv(ndev);
+	int i;
+
+	for (i = 0; i < fep->num_rx_queues; i++)
+		writel(0, fep->hwp + FEC_R_DES_ACTIVE(i));
+}
+
+static void fec_enet_enable_ring(struct net_device *ndev)
 {
 	struct fec_enet_private *fep = netdev_priv(ndev);
 	struct fec_enet_priv_tx_q *tx_queue;
 	struct fec_enet_priv_rx_q *rx_queue;
+	int i;
+
+	for (i = 0; i < fep->num_rx_queues; i++) {
+		rx_queue = fep->rx_queue[i];
+		writel(rx_queue->bd_dma, fep->hwp + FEC_R_DES_START(i));
+
+		/* enable DMA1/2 */
+		if (i)
+			writel(RCMR_MATCHEN | RCMR_CMP(i),
+				fep->hwp + FEC_RCMR(i));
+	}
 
-	rx_queue = fep->rx_queue[0];
-	writel(rx_queue->bd_dma, fep->hwp + FEC_R_DES_START);
+	for (i = 0; i < fep->num_tx_queues; i++) {
+		tx_queue = fep->tx_queue[i];
+		writel(tx_queue->bd_dma, fep->hwp + FEC_X_DES_START(i));
 
-	tx_queue = fep->tx_queue[0];
-	writel(tx_queue->bd_dma, fep->hwp + FEC_X_DES_START);
+		/* enable DMA1/2 */
+		if (i)
+			writel(DMA_CLASS_EN | IDLE_SLOPE(i),
+				fep->hwp + FEC_DMA_CFG(i));
+	}
 }
 
 static void fec_enet_reset_skb(struct net_device *ndev)
@@ -723,7 +747,7 @@ fec_restart(struct net_device *ndev, int duplex)
 
 	/* And last, enable the transmit and receive processing */
 	writel(ecntl, fep->hwp + FEC_ECNTRL);
-	writel(0, fep->hwp + FEC_R_DES_ACTIVE);
+	fec_enet_active_rxring(ndev);
 
 	if (fep->bufdesc_ex)
 		fec_ptp_start_cyclecounter(ndev);
@@ -807,8 +831,9 @@ static void fec_enet_work(struct work_struct *work)
 	}
 
 	if (fep->delay_work.trig_tx) {
-		fep->delay_work.trig_tx = false;
-		writel(0, fep->hwp + FEC_X_DES_ACTIVE);
+		writel(0, fep->hwp +
+			FEC_X_DES_ACTIVE(fep->delay_work.trig_tx - 1));
+		fep->delay_work.trig_tx = 0;
 	}
 }
 
@@ -1125,7 +1150,7 @@ rx_processing_done:
 			 * incoming frames.  On a heavily loaded network, we should be
 			 * able to keep up at the expense of system resources.
 			 */
-			writel(0, fep->hwp + FEC_R_DES_ACTIVE);
+			writel(0, fep->hwp + FEC_R_DES_ACTIVE(queue_id));
 		}
 		rxq->cur_rx = bdp;
 	}
@@ -1146,9 +1171,17 @@ static bool fec_enet_collect_events(struct fec_enet_private *fep)
 
 	if (int_events & FEC_ENET_RXF)
 		fep->work_rx |= (1 << 2);
+	if (int_events & FEC_ENET_RXF_1)
+		fep->work_rx |= (1 << 0);
+	if (int_events & FEC_ENET_RXF_2)
+		fep->work_rx |= (1 << 1);
 
 	if (int_events & FEC_ENET_TXF)
 		fep->work_tx |= (1 << 2);
+	if (int_events & FEC_ENET_TXF_1)
+		fep->work_tx |= (1 << 0);
+	if (int_events & FEC_ENET_TXF_2)
+		fep->work_tx |= (1 << 1);
 
 	if (int_events & FEC_ENET_TS_TIMER)
 		fep->work_ts = 1;
@@ -1844,10 +1877,12 @@ static void fec_enet_free_buffers(struct net_device *ndev)
 		}
 	}
 
-	tx_queue = fep->tx_queue[0];
-	bdp = tx_queue->tx_bd_base;
-	for (i = 0; i < tx_queue->tx_ring_size; i++)
-		kfree(tx_queue->tx_bounce[i]);
+	for (j = 0; j < fep->num_tx_queues; j++) {
+		tx_queue = fep->tx_queue[j];
+		bdp = tx_queue->tx_bd_base;
+		for (i = 0; i < tx_queue->tx_ring_size; i++)
+			kfree(tx_queue->tx_bounce[i]);
+	}
 }
 
 static int fec_enet_alloc_buffers(struct net_device *ndev)
@@ -1898,33 +1933,36 @@ static int fec_enet_alloc_buffers(struct net_device *ndev)
 		bdp->cbd_sc |= BD_SC_WRAP;
 	}
 
-	/* legacy for the previous enet IP verision with only
-	 * support one queue
+	/* legacy for the previous enet IP verision that enet uDMA don't
+	 * support tx data buffer byte align.
 	 */
-	tx_queue = fep->tx_queue[0];
-	bdp = tx_queue->tx_bd_base;
-	for (i = 0; i < tx_queue->tx_ring_size; i++) {
-		tx_queue->tx_bounce[i] = kmalloc(FEC_ENET_TX_FRSIZE, GFP_KERNEL);
-		if (!tx_queue->tx_bounce[i]) {
-			fec_enet_free_buffers(ndev);
-			return -ENOMEM;
-		}
+	for (j = 0; j < fep->num_tx_queues; j++) {
+		tx_queue = fep->tx_queue[j];
+		bdp = tx_queue->tx_bd_base;
 
-		bdp->cbd_sc = 0;
-		bdp->cbd_bufaddr = 0;
+		for (i = 0; i < tx_queue->tx_ring_size; i++) {
+			tx_queue->tx_bounce[i] = kmalloc(FEC_ENET_TX_FRSIZE, GFP_KERNEL);
+			if (!tx_queue->tx_bounce[i]) {
+				fec_enet_free_buffers(ndev);
+				return -ENOMEM;
+			}
 
-		if (fep->bufdesc_ex) {
-			struct bufdesc_ex *ebdp = (struct bufdesc_ex *)bdp;
-			ebdp->cbd_esc = BD_ENET_TX_INT;
+			bdp->cbd_sc = 0;
+			bdp->cbd_bufaddr = 0;
+
+			if (fep->bufdesc_ex) {
+				struct bufdesc_ex *ebdp = (struct bufdesc_ex *)bdp;
+				ebdp->cbd_esc = BD_ENET_TX_INT;
+			}
+
+			bdp = fec_enet_get_nextdesc(bdp, fep);
 		}
 
-		bdp = fec_enet_get_nextdesc(bdp, fep);
+		/* Set the last buffer to wrap. */
+		bdp = fec_enet_get_prevdesc(bdp, fep);
+		bdp->cbd_sc |= BD_SC_WRAP;
 	}
 
-	/* Set the last buffer to wrap. */
-	bdp = fec_enet_get_prevdesc(bdp, fep);
-	bdp->cbd_sc |= BD_SC_WRAP;
-
 	return 0;
 }
 
-- 
1.7.5.4

