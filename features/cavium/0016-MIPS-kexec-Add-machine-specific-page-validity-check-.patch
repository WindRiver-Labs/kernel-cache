From 9eb8fa024c005b25683fd94dd35612aaa34d81aa Mon Sep 17 00:00:00 2001
From: Bin Jiang <bin.jiang@windriver.com>
Date: Tue, 23 Apr 2013 19:33:51 +0800
Subject: [PATCH 16/22] MIPS: kexec: Add machine-specific page validity check
 in vmcore

Some systems need to verify the validity of pages referenced by
vmcore when accessing them, some do not. By default, the check
returns all pages valid. Systems that need a different implementation
can install their own.

Signed-off-by: Benjamin Walsh <benjamin.walsh@windriver.com>
Signed-off-by: Bin Jiang <bin.jiang@windriver.com>
---
 arch/mips/cavium-octeon/setup.c |   15 +++++++++++++
 arch/mips/kernel/crash_dump.c   |   47 +++++++++++++++++++++++++++++----------
 2 files changed, 50 insertions(+), 12 deletions(-)

diff --git a/arch/mips/cavium-octeon/setup.c b/arch/mips/cavium-octeon/setup.c
index 3347ccb..7723b54 100644
--- a/arch/mips/cavium-octeon/setup.c
+++ b/arch/mips/cavium-octeon/setup.c
@@ -142,6 +142,18 @@ static void octeon_kexec_setup(void)
 }
 #endif
 
+#ifdef CONFIG_CRASH_DUMP
+extern int (*_machine_check_pfn_validity)(unsigned long pfn);
+static int octeon_check_pfn_validity(unsigned long pfn)
+{
+	return (pfn_present(pfn) && pfn_valid(pfn));
+}
+static void octeon_crash_dump_setup(void)
+{
+	_machine_check_pfn_validity = octeon_check_pfn_validity;
+}
+#endif
+
 static int octeon_uart;
 
 extern asmlinkage void handle_int(void);
@@ -895,6 +907,9 @@ append_arg:
 #ifdef CONFIG_KEXEC
 	octeon_kexec_setup();
 #endif
+#ifdef CONFIG_CRASH_DUMP
+	octeon_crash_dump_setup();
+#endif
 }
 
 /* constants for memory initialization */
diff --git a/arch/mips/kernel/crash_dump.c b/arch/mips/kernel/crash_dump.c
index 35bed0d..a4c8127 100644
--- a/arch/mips/kernel/crash_dump.c
+++ b/arch/mips/kernel/crash_dump.c
@@ -15,6 +15,14 @@ __setup("savemaxmem=", parse_savemaxmem);
 
 static void *kdump_buf_page;
 
+static int default_machine_check_pfn_validity(unsigned long pfn)
+{
+	return 1;
+}
+/* Do NOT set this to NULL */
+int (*_machine_check_pfn_validity)(unsigned long pfn) =
+	default_machine_check_pfn_validity;
+
 /**
  * copy_oldmem_page - copy one page from "oldmem"
  * @pfn: page frame number to be copied
@@ -40,21 +48,36 @@ ssize_t copy_oldmem_page(unsigned long pfn, char *buf,
 	if (!csize)
 		return 0;
 
-	vaddr = kmap_atomic_pfn(pfn);
+	/* see if the PFN is valid and present */
+	if (_machine_check_pfn_validity(pfn)) {
+		vaddr = kmap_atomic_pfn(pfn);
 
-	if (!userbuf) {
-		memcpy(buf, (vaddr + offset), csize);
-		kunmap_atomic(vaddr);
+		if (!userbuf) {
+			memcpy(buf, (vaddr + offset), csize);
+			kunmap_atomic(vaddr);
+		} else {
+			if (!kdump_buf_page) {
+				printk(KERN_WARNING "Kdump: Kdump buffer " \
+					"page not allocated\n");
+				return -EFAULT;
+			}
+			copy_page(kdump_buf_page, vaddr);
+			kunmap_atomic(vaddr);
+			if (copy_to_user(buf,
+				(kdump_buf_page + offset), csize))
+				return -EFAULT;
+		}
 	} else {
-		if (!kdump_buf_page) {
-			pr_warning("Kdump: Kdump buffer page not allocated\n");
-
-			return -EFAULT;
+		/* the PFN isn't present and/or valid in the paging tables
+		 * use the __va() macro to get the virtual address from the PFN
+		 */
+		vaddr = (void *)(__va(pfn * PAGE_SIZE));
+		if (!userbuf) {
+			memcpy(buf, (vaddr + offset), csize);
+		} else {
+			if (copy_to_user(buf, (vaddr + offset), csize))
+				return -EFAULT;
 		}
-		copy_page(kdump_buf_page, vaddr);
-		kunmap_atomic(vaddr);
-		if (copy_to_user(buf, (kdump_buf_page + offset), csize))
-			return -EFAULT;
 	}
 
 	return csize;
-- 
1.7.10.4

