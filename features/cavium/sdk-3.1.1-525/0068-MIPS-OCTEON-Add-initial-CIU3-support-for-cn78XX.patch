From 8429fea6bb0a2bc296f076b16ed2390582571694 Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Thu, 22 Aug 2013 16:31:06 -0700
Subject: [PATCH 068/122] MIPS: OCTEON: Add initial CIU3 support for cn78XX.

Source: Cavium Networks, Inc.
MR: 00000
Type: Integration
Disposition: Merged from Octeon Tree
ChangeID: efdc172a9c4d928c02d9da3c82ddc438dc72a471
Description:

Add initial CIU3 support for cn78XX.

Signed-off-by: David Daney <david.daney@cavium.com>
Signed-off-by: Corey Minyard <cminyard@mvista.com>
[Original patch taken from Cavium SDK 3.1.1 525]
Signed-off-by: Bin Jiang <bin.jiang@windriver.com>
---
 arch/mips/cavium-octeon/octeon-irq.c          | 414 +++++++++++++-
 arch/mips/include/asm/octeon/cvmx-asm.h       |   8 +
 arch/mips/include/asm/octeon/cvmx-ciu3-defs.h | 793 ++++++++++++++++++++++++++
 arch/mips/include/asm/octeon/cvmx.h           |  28 +
 arch/mips/include/asm/octeon/octeon.h         |   1 +
 5 files changed, 1241 insertions(+), 3 deletions(-)
 create mode 100644 arch/mips/include/asm/octeon/cvmx-ciu3-defs.h

diff --git a/arch/mips/cavium-octeon/octeon-irq.c b/arch/mips/cavium-octeon/octeon-irq.c
index 99b63c1..ac54660 100644
--- a/arch/mips/cavium-octeon/octeon-irq.c
+++ b/arch/mips/cavium-octeon/octeon-irq.c
@@ -3,7 +3,7 @@
  * License.  See the file "COPYING" in the main directory of this archive
  * for more details.
  *
- * Copyright (C) 2004-2012 Cavium, Inc.
+ * Copyright (C) 2004-2013 Cavium, Inc.
  */
 
 #include <linux/interrupt.h>
@@ -18,11 +18,14 @@
 
 #include <asm/octeon/octeon.h>
 #include <asm/octeon/cvmx-ciu2-defs.h>
+#include <asm/octeon/cvmx-ciu3-defs.h>
 
 static DEFINE_PER_CPU(unsigned long, octeon_irq_ciu0_en_mirror);
 static DEFINE_PER_CPU(unsigned long, octeon_irq_ciu1_en_mirror);
 static DEFINE_PER_CPU(raw_spinlock_t, octeon_irq_ciu_spinlock);
 
+static struct irq_domain *octeon_irq_ciu3_domain;
+
 static __read_mostly u8 octeon_irq_ciu_to_irq[8][64];
 
 union octeon_ciu_chip_data {
@@ -606,7 +609,7 @@ static void octeon_irq_ciu_gpio_ack(struct irq_data *data)
 	cvmx_write_csr(CVMX_GPIO_INT_CLR, mask);
 }
 
-static void octeon_irq_handle_gpio(unsigned int irq, struct irq_desc *desc)
+static void octeon_irq_handle_trigger(unsigned int irq, struct irq_desc *desc)
 {
 	if (irq_get_trigger_type(irq) & IRQ_TYPE_EDGE_BOTH)
 		handle_edge_irq(irq, desc);
@@ -1063,7 +1066,7 @@ static int octeon_irq_gpio_map(struct irq_domain *d,
 		return -EINVAL;
 
 	octeon_irq_set_ciu_mapping(virq, line, bit, hw,
-				   octeon_irq_gpio_chip, octeon_irq_handle_gpio);
+				   octeon_irq_gpio_chip, octeon_irq_handle_trigger);
 	return 0;
 }
 
@@ -1773,10 +1776,415 @@ static int __init octeon_irq_init_ciu2(struct device_node *ciu_node, struct devi
 	return 0;
 }
 
+static void octeon_irq_ciu3_enable(struct irq_data *data)
+{
+	union cvmx_ciu3_iscx_ctl isc_ctl;
+	union cvmx_ciu3_iscx_w1c isc_w1c;
+	u64 isc_ctl_addr;
+
+	union octeon_ciu_chip_data cd;
+
+	cd.p = irq_data_get_irq_chip_data(data);
+
+	isc_w1c.u64 = 0;
+	isc_w1c.s.en = 1;
+
+	isc_ctl.u64 = 0;
+	isc_ctl.s.en = 1;
+	isc_ctl.s.idt = 1;
+	isc_ctl_addr = CVMX_CIU3_ISCX_CTL(cd.l);
+	cvmx_write_csr(CVMX_CIU3_ISCX_W1C(cd.l), isc_w1c.u64);
+	cvmx_write_csr(isc_ctl_addr, isc_ctl.u64);
+	cvmx_read_csr(isc_ctl_addr);
+}
+
+static void octeon_irq_ciu3_disable(struct irq_data *data)
+{
+	u64 isc_ctl_addr;
+	union cvmx_ciu3_iscx_w1c isc_w1c;
+
+	union octeon_ciu_chip_data cd;
+
+	cd.p = irq_data_get_irq_chip_data(data);
+
+	isc_w1c.u64 = 0;
+	isc_w1c.s.en = 1;
+
+	isc_ctl_addr = CVMX_CIU3_ISCX_CTL(cd.l);
+	cvmx_write_csr(CVMX_CIU3_ISCX_W1C(cd.l), isc_w1c.u64);
+	cvmx_write_csr(isc_ctl_addr, 0);
+	cvmx_read_csr(isc_ctl_addr);
+}
+
+static void octeon_irq_ciu3_ack(struct irq_data *data)
+{
+	u64 isc_w1c_addr;
+	union cvmx_ciu3_iscx_w1c isc_w1c;
+	union octeon_ciu_chip_data cd;
+	u32 trigger_type = irqd_get_trigger_type(data);
+
+	/*
+	 * We use a single irq_chip, so we have to do nothing to ack a
+	 * level interrupt.
+	 */
+	if (trigger_type & IRQ_TYPE_LEVEL_MASK)
+		return;
+
+	cd.p = irq_data_get_irq_chip_data(data);
+
+	isc_w1c.u64 = 0;
+	isc_w1c.s.raw = 1;
+
+	isc_w1c_addr = CVMX_CIU3_ISCX_W1C(cd.l);
+	cvmx_write_csr(isc_w1c_addr, isc_w1c.u64);
+	cvmx_read_csr(isc_w1c_addr);
+}
+
+static void octeon_irq_ciu3_mask(struct irq_data *data)
+{
+	union cvmx_ciu3_iscx_w1c isc_w1c;
+	u64 isc_w1c_addr;
+	union octeon_ciu_chip_data cd;
+
+	cd.p = irq_data_get_irq_chip_data(data);
+
+	isc_w1c.u64 = 0;
+	isc_w1c.s.en = 1;
+
+	isc_w1c_addr = CVMX_CIU3_ISCX_W1C(cd.l);
+	cvmx_write_csr(isc_w1c_addr, isc_w1c.u64);
+	cvmx_read_csr(isc_w1c_addr);
+}
+
+static void octeon_irq_ciu3_mask_ack(struct irq_data *data)
+{
+	union cvmx_ciu3_iscx_w1c isc_w1c;
+	u64 isc_w1c_addr;
+	union octeon_ciu_chip_data cd;
+	u32 trigger_type = irqd_get_trigger_type(data);
+
+	cd.p = irq_data_get_irq_chip_data(data);
+
+	isc_w1c.u64 = 0;
+	isc_w1c.s.en = 1;
+
+	/*
+	 * We use a single irq_chip, so only ack an edge (!level)
+	 * interrupt.
+	 */
+	if (!(trigger_type & IRQ_TYPE_LEVEL_MASK))
+		isc_w1c.s.raw = 1;
+
+	isc_w1c_addr = CVMX_CIU3_ISCX_W1C(cd.l);
+	cvmx_write_csr(isc_w1c_addr, isc_w1c.u64);
+	cvmx_read_csr(isc_w1c_addr);
+}
+
+static void octeon_irq_ciu3_unmask(struct irq_data *data)
+{
+	union cvmx_ciu3_iscx_w1s isc_w1s;
+	u64 isc_w1s_addr;
+	union octeon_ciu_chip_data cd;
+
+	cd.p = irq_data_get_irq_chip_data(data);
+
+	isc_w1s.u64 = 0;
+	isc_w1s.s.en = 1;
+
+	isc_w1s_addr = CVMX_CIU3_ISCX_W1S(cd.l);
+	cvmx_write_csr(isc_w1s_addr, isc_w1s.u64);
+	cvmx_read_csr(isc_w1s_addr);
+}
+
+static struct irq_chip octeon_irq_chip_ciu3 = {
+	.name = "CIU3",
+	.irq_enable = octeon_irq_ciu3_enable,
+	.irq_disable = octeon_irq_ciu3_disable,
+	.irq_ack = octeon_irq_ciu3_ack,
+	.irq_mask = octeon_irq_ciu3_mask,
+	.irq_mask_ack = octeon_irq_ciu3_mask_ack,
+	.irq_unmask = octeon_irq_ciu3_unmask,
+//#ifdef CONFIG_SMP
+//	.irq_set_affinity = octeon_irq_ciu3_set_affinity,
+//	.irq_cpu_offline = octeon_irq_cpu_offline_ciu,
+//#endif
+};
+
+static int octeon_irq_ciu3_xlat(struct irq_domain *d,
+				struct device_node *node,
+				const u32 *intspec,
+				unsigned int intsize,
+				unsigned long *out_hwirq,
+				unsigned int *out_type)
+{
+	unsigned int hwirq, type, intsn_major;
+	union cvmx_ciu3_iscx_ctl isc;
+	hwirq = intspec[0];
+	type = intspec[1];
+
+	if (hwirq >= (1 << 20))
+		return -EINVAL;
+
+	intsn_major = hwirq >> 12;
+	switch (intsn_major) {
+	case 0x04: /* Software handled seperatly. */
+		return -EINVAL;
+	default:
+		break;
+	}
+
+
+	isc.u64 =  cvmx_read_csr(CVMX_CIU3_ISCX_CTL(hwirq));
+	if (!isc.s.imp)
+		return -EINVAL;
+
+	switch (type) {
+	case 0: /* unofficial value, but we might as well let it work. */
+	case 4: /* official value for level triggering. */
+		*out_type = IRQ_TYPE_LEVEL_HIGH;
+		break;
+	case 1: /* official value for edge triggering. */
+		*out_type = IRQ_TYPE_EDGE_RISING;
+		break;
+	default: /* Nothing else is acceptable. */
+		return -EINVAL;
+	}
+
+	*out_hwirq = hwirq;
+
+	return 0;
+}
+
+static int octeon_irq_ciu3_map(struct irq_domain *d,
+			       unsigned int virq, irq_hw_number_t hw)
+{
+	union octeon_ciu_chip_data cd;
+	cd.l = hw;
+
+	irq_set_chip_and_handler(virq, &octeon_irq_chip_ciu3, octeon_irq_handle_trigger);
+	irq_set_chip_data(virq, cd.p);
+
+	return 0;
+}
+
+static struct irq_domain_ops octeon_irq_domain_ciu3_ops = {
+	.map = octeon_irq_ciu3_map,
+	.xlate = octeon_irq_ciu3_xlat,
+};
+
+static void octeon_irq_ciu3_ip2(void)
+{
+	union cvmx_ciu3_destx_pp_int dest_pp_int;
+
+	dest_pp_int.u64 = cvmx_read_csr(CVMX_CIU3_DESTX_PP_INT(3 * cvmx_get_core_num()));
+
+	if (likely(dest_pp_int.s.intr)) {
+		irq_hw_number_t intsn = dest_pp_int.s.intsn;
+		int irq = irq_find_mapping(octeon_irq_ciu3_domain, intsn);
+
+		if (likely(irq)) {
+			do_IRQ(irq);
+		} else {
+			u64 isc_ctl_addr = CVMX_CIU3_ISCX_CTL(intsn);
+			cvmx_write_csr(isc_ctl_addr, 0);
+			cvmx_read_csr(isc_ctl_addr);
+			spurious_interrupt();
+		}
+	} else {
+		spurious_interrupt();
+	}
+}
+
+static void octeon_irq_ciu3_mbox(void)
+{
+	union cvmx_ciu3_destx_pp_int dest_pp_int;
+
+	dest_pp_int.u64 = cvmx_read_csr(CVMX_CIU3_DESTX_PP_INT(1 + (3 * cvmx_get_core_num())));
+
+	if (likely(dest_pp_int.s.intr)) {
+		irq_hw_number_t intsn = dest_pp_int.s.intsn;
+		int irq = (intsn & 7) + OCTEON_IRQ_MBOX0;
+
+		if (likely(irq)) {
+			do_IRQ(irq);
+		} else {
+			u64 isc_ctl_addr = CVMX_CIU3_ISCX_CTL(intsn);
+			cvmx_write_csr(isc_ctl_addr, 0);
+			cvmx_read_csr(isc_ctl_addr);
+			spurious_interrupt();
+		}
+	} else {
+		spurious_interrupt();
+	}
+}
+
+static unsigned int octeon_irq_ciu3_mbox_intsn_for_core(unsigned int core, unsigned int mbox)
+{
+	return (0x04 << 12) | (core << 3) | mbox;
+}
+
+void octeon_ciu3_mbox_send(int cpu, unsigned int mbox)
+{
+	union cvmx_ciu3_iscx_w1s isc_w1s;
+	u64 isc_w1s_addr;
+	unsigned int core = octeon_coreid_for_cpu(cpu);
+
+	if (WARN_ON_ONCE(mbox >= 8))
+		return;
+
+	isc_w1s_addr = CVMX_CIU3_ISCX_W1S(octeon_irq_ciu3_mbox_intsn_for_core(core, mbox));
+
+	isc_w1s.u64 = 0;
+	isc_w1s.s.raw = 1;
+
+	cvmx_write_csr(isc_w1s_addr, isc_w1s.u64);
+	cvmx_read_csr(isc_w1s_addr);
+}
+EXPORT_SYMBOL(octeon_ciu3_mbox_send);
+
+static void octeon_irq_ciu3_mbox_set_enable(struct irq_data *data, unsigned int core, bool en)
+{
+	unsigned int intsn;
+	u64 isc_ctl_addr;
+	unsigned int mbox = data->irq - OCTEON_IRQ_MBOX0;
+
+	intsn = octeon_irq_ciu3_mbox_intsn_for_core(core, mbox);
+	isc_ctl_addr = CVMX_CIU3_ISCX_CTL(intsn);
+
+	cvmx_write_csr(isc_ctl_addr, 0);
+	if (en) {
+		union cvmx_ciu3_iscx_ctl isc_ctl;
+		isc_ctl.u64 = 0;
+		isc_ctl.s.en = 1;
+		isc_ctl.s.idt = 2 + core;
+		cvmx_write_csr(isc_ctl_addr, isc_ctl.u64);
+	}
+	cvmx_read_csr(isc_ctl_addr);
+}
+
+static void octeon_irq_ciu3_mbox_enable(struct irq_data *data)
+{
+	int cpu;
+	unsigned int mbox = data->irq - OCTEON_IRQ_MBOX0;
+
+	WARN_ON(mbox >= 8);
+
+	for_each_online_cpu(cpu) {
+		unsigned int core = octeon_coreid_for_cpu(cpu);
+		octeon_irq_ciu3_mbox_set_enable(data, core, true);
+	}
+}
+
+static void octeon_irq_ciu3_mbox_disable(struct irq_data *data)
+{
+	int cpu;
+	unsigned int mbox = data->irq - OCTEON_IRQ_MBOX0;
+
+	WARN_ON(mbox >= 8);
+
+	for_each_online_cpu(cpu) {
+		unsigned int core = octeon_coreid_for_cpu(cpu);
+		octeon_irq_ciu3_mbox_set_enable(data, core, false);
+	}
+}
+
+static void octeon_irq_ciu3_mbox_ack(struct irq_data *data)
+{
+	unsigned int intsn;
+	u64 isc_w1c_addr;
+	union cvmx_ciu3_iscx_w1c isc_w1c;
+	unsigned int core = cvmx_get_core_num();
+	unsigned int mbox = data->irq - OCTEON_IRQ_MBOX0;
+
+	intsn = octeon_irq_ciu3_mbox_intsn_for_core(core, mbox);
+
+	isc_w1c.u64 = 0;
+	isc_w1c.s.raw = 1;
+
+	isc_w1c_addr = CVMX_CIU3_ISCX_W1C(intsn);
+	cvmx_write_csr(isc_w1c_addr, isc_w1c.u64);
+	cvmx_read_csr(isc_w1c_addr);
+}
+
+static void octeon_irq_ciu3_mbox_cpu_online(struct irq_data *data)
+{
+	unsigned int core = cvmx_get_core_num();
+	octeon_irq_ciu3_mbox_set_enable(data, core, true);
+}
+
+static void octeon_irq_ciu3_mbox_cpu_offline(struct irq_data *data)
+{
+	unsigned int core = cvmx_get_core_num();
+	octeon_irq_ciu3_mbox_set_enable(data, core, false);
+}
+
+static void octeon_irq_setup_secondary_ciu3(void)
+{
+	irq_cpu_online();
+
+	/* Enable the CIU lines */
+	set_c0_status(STATUSF_IP3 | STATUSF_IP2);
+	if (octeon_irq_use_ip4)
+		set_c0_status(STATUSF_IP4);
+	else
+		clear_c0_status(STATUSF_IP4);
+}
+
+static struct irq_chip octeon_irq_chip_ciu3_mbox = {
+	.name = "CIU3-M",
+	.irq_enable = octeon_irq_ciu3_mbox_enable,
+	.irq_disable = octeon_irq_ciu3_mbox_disable,
+	.irq_ack = octeon_irq_ciu3_mbox_ack,
+
+	.irq_cpu_online = octeon_irq_ciu3_mbox_cpu_online,
+	.irq_cpu_offline = octeon_irq_ciu3_mbox_cpu_offline,
+	.flags = IRQCHIP_ONOFFLINE_ENABLED,
+};
+
+static int __init octeon_irq_init_ciu3(struct device_node *ciu_node,
+				       struct device_node *parent)
+{
+	int i;
+
+	octeon_irq_setup_secondary = octeon_irq_setup_secondary_ciu3;
+
+	octeon_irq_ip2 = octeon_irq_ciu3_ip2;
+	octeon_irq_ip3 = octeon_irq_ciu3_mbox;
+	octeon_irq_ip4 = octeon_irq_ip4_mask;
+
+	/* Mips internal */
+	octeon_irq_init_core();
+
+	for (i = 0; i < 8; i++)
+		irq_set_chip_and_handler(i + OCTEON_IRQ_MBOX0, &octeon_irq_chip_ciu3_mbox, handle_percpu_irq);
+
+	octeon_irq_ciu3_domain = irq_domain_add_tree(ciu_node, &octeon_irq_domain_ciu3_ops, NULL);
+	irq_set_default_host(octeon_irq_ciu3_domain);
+
+	/* ip2 interrupts all use IDT[1] targeting core 0 */
+	cvmx_write_csr(CVMX_CIU3_IDTX_CTL(1), 0);
+	cvmx_write_csr(CVMX_CIU3_IDTX_PPX(0, 1), 1);
+	cvmx_write_csr(CVMX_CIU3_IDTX_IO(1), 0);
+
+	for (i = 0; i < 48; i++) {
+		/* idt[2..49] target ip3, one per core */
+		cvmx_write_csr(CVMX_CIU3_IDTX_CTL(2 + i), 1);
+		cvmx_write_csr(CVMX_CIU3_IDTX_PPX(0, 2 + i), 1ull << i);
+		cvmx_write_csr(CVMX_CIU3_IDTX_IO(1), 0);
+	}
+
+	/* Enable the CIU lines */
+	set_c0_status(STATUSF_IP2 | STATUSF_IP3);
+	clear_c0_status(STATUSF_IP4);
+
+	return 0;
+}
+
 static struct of_device_id __initdata ciu_types[] = {
 	{.compatible = "cavium,octeon-3860-ciu", .data = octeon_irq_init_ciu},
 	{.compatible = "cavium,octeon-3860-gpio", .data = octeon_irq_init_gpio},
 	{.compatible = "cavium,octeon-6880-ciu2", .data = octeon_irq_init_ciu2},
+	{.compatible = "cavium,octeon-7890-ciu3", .data = octeon_irq_init_ciu3},
 	{}
 };
 
diff --git a/arch/mips/include/asm/octeon/cvmx-asm.h b/arch/mips/include/asm/octeon/cvmx-asm.h
index 31eacc2..62ebacf 100644
--- a/arch/mips/include/asm/octeon/cvmx-asm.h
+++ b/arch/mips/include/asm/octeon/cvmx-asm.h
@@ -34,6 +34,14 @@
 
 #include <asm/octeon/octeon-model.h>
 
+#define CVMX_NODE_NO_SHIFT	(7)	/* Maximum # of bits to define core in node */
+#define CVMX_NODE_BITS		(2)	/* Number of bits to define a node */
+#define CVMX_MAX_NODES		(1 << CVMX_NODE_BITS)
+#define CVMX_NODE_MASK		(CVMX_MAX_NODES - 1)
+#define CVMX_NODE_IO_SHIFT	(36)
+#define CVMX_NODE_MEM_SHIFT	(40)
+#define CVMX_NODE_IO_MASK	((uint64_t)CVMX_NODE_MASK << CVMX_NODE_IO_SHIFT)
+
 /* other useful stuff */
 #define CVMX_SYNC asm volatile ("sync" : : : "memory")
 /* String version of SYNCW macro for using in inline asm constructs */
diff --git a/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h b/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
new file mode 100644
index 0000000..de896a6c
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
@@ -0,0 +1,793 @@
+/***********************license start***************
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+
+/**
+ * cvmx-ciu3-defs.h
+ *
+ * Configuration and status register (CSR) type definitions for
+ * Octeon ciu3.
+ *
+ * This file is auto generated. Do not edit.
+ *
+ * <hr>$Revision$<hr>
+ *
+ */
+#ifndef __CVMX_CIU3_DEFS_H__
+#define __CVMX_CIU3_DEFS_H__
+
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU3_BIST CVMX_CIU3_BIST_FUNC()
+static inline uint64_t CVMX_CIU3_BIST_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_CIU3_BIST not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00010100000001C0ull);
+}
+#else
+#define CVMX_CIU3_BIST (CVMX_ADD_IO_SEG(0x00010100000001C0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU3_CONST CVMX_CIU3_CONST_FUNC()
+static inline uint64_t CVMX_CIU3_CONST_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_CIU3_CONST not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001010000000220ull);
+}
+#else
+#define CVMX_CIU3_CONST (CVMX_ADD_IO_SEG(0x0001010000000220ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU3_CTL CVMX_CIU3_CTL_FUNC()
+static inline uint64_t CVMX_CIU3_CTL_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_CIU3_CTL not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00010100000000E0ull);
+}
+#else
+#define CVMX_CIU3_CTL (CVMX_ADD_IO_SEG(0x00010100000000E0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_CIU3_DESTX_IO_INT(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 4)))))
+		cvmx_warn("CVMX_CIU3_DESTX_IO_INT(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001010000210000ull) + ((offset) & 7) * 8;
+}
+#else
+#define CVMX_CIU3_DESTX_IO_INT(offset) (CVMX_ADD_IO_SEG(0x0001010000210000ull) + ((offset) & 7) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_CIU3_DESTX_PP_INT(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 143)))))
+		cvmx_warn("CVMX_CIU3_DESTX_PP_INT(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001010000200000ull) + ((offset) & 255) * 8;
+}
+#else
+#define CVMX_CIU3_DESTX_PP_INT(offset) (CVMX_ADD_IO_SEG(0x0001010000200000ull) + ((offset) & 255) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU3_GSTOP CVMX_CIU3_GSTOP_FUNC()
+static inline uint64_t CVMX_CIU3_GSTOP_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_CIU3_GSTOP not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001010000000140ull);
+}
+#else
+#define CVMX_CIU3_GSTOP (CVMX_ADD_IO_SEG(0x0001010000000140ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_CIU3_IDTX_CTL(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 255)))))
+		cvmx_warn("CVMX_CIU3_IDTX_CTL(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001010000110000ull) + ((offset) & 255) * 8;
+}
+#else
+#define CVMX_CIU3_IDTX_CTL(offset) (CVMX_ADD_IO_SEG(0x0001010000110000ull) + ((offset) & 255) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_CIU3_IDTX_IO(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 255)))))
+		cvmx_warn("CVMX_CIU3_IDTX_IO(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001010000130000ull) + ((offset) & 255) * 8;
+}
+#else
+#define CVMX_CIU3_IDTX_IO(offset) (CVMX_ADD_IO_SEG(0x0001010000130000ull) + ((offset) & 255) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_CIU3_IDTX_PPX(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset == 0)) && ((block_id <= 255))))))
+		cvmx_warn("CVMX_CIU3_IDTX_PPX(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001010000120000ull) + ((block_id) & 255) * 0x20ull;
+}
+#else
+#define CVMX_CIU3_IDTX_PPX(offset, block_id) (CVMX_ADD_IO_SEG(0x0001010000120000ull) + ((block_id) & 255) * 0x20ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU3_INTR_RAM_ECC_CTL CVMX_CIU3_INTR_RAM_ECC_CTL_FUNC()
+static inline uint64_t CVMX_CIU3_INTR_RAM_ECC_CTL_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_CIU3_INTR_RAM_ECC_CTL not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001010000000260ull);
+}
+#else
+#define CVMX_CIU3_INTR_RAM_ECC_CTL (CVMX_ADD_IO_SEG(0x0001010000000260ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU3_INTR_RAM_ECC_ST CVMX_CIU3_INTR_RAM_ECC_ST_FUNC()
+static inline uint64_t CVMX_CIU3_INTR_RAM_ECC_ST_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_CIU3_INTR_RAM_ECC_ST not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001010000000280ull);
+}
+#else
+#define CVMX_CIU3_INTR_RAM_ECC_ST (CVMX_ADD_IO_SEG(0x0001010000000280ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU3_INTR_READY CVMX_CIU3_INTR_READY_FUNC()
+static inline uint64_t CVMX_CIU3_INTR_READY_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_CIU3_INTR_READY not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00010100000002A0ull);
+}
+#else
+#define CVMX_CIU3_INTR_READY (CVMX_ADD_IO_SEG(0x00010100000002A0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU3_INTR_SLOWDOWN CVMX_CIU3_INTR_SLOWDOWN_FUNC()
+static inline uint64_t CVMX_CIU3_INTR_SLOWDOWN_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_CIU3_INTR_SLOWDOWN not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001010000000240ull);
+}
+#else
+#define CVMX_CIU3_INTR_SLOWDOWN (CVMX_ADD_IO_SEG(0x0001010000000240ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU3_ISCMEM_BASE CVMX_CIU3_ISCMEM_BASE_FUNC()
+static inline uint64_t CVMX_CIU3_ISCMEM_BASE_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_CIU3_ISCMEM_BASE not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00010100000002C0ull);
+}
+#else
+#define CVMX_CIU3_ISCMEM_BASE (CVMX_ADD_IO_SEG(0x00010100000002C0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_CIU3_ISCX_CTL(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1048575)))))
+		cvmx_warn("CVMX_CIU3_ISCX_CTL(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001010080000000ull) + ((offset) & 1048575) * 8;
+}
+#else
+#define CVMX_CIU3_ISCX_CTL(offset) (CVMX_ADD_IO_SEG(0x0001010080000000ull) + ((offset) & 1048575) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_CIU3_ISCX_W1C(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1048575)))))
+		cvmx_warn("CVMX_CIU3_ISCX_W1C(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001010090000000ull) + ((offset) & 1048575) * 8;
+}
+#else
+#define CVMX_CIU3_ISCX_W1C(offset) (CVMX_ADD_IO_SEG(0x0001010090000000ull) + ((offset) & 1048575) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_CIU3_ISCX_W1S(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1048575)))))
+		cvmx_warn("CVMX_CIU3_ISCX_W1S(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00010100A0000000ull) + ((offset) & 1048575) * 8;
+}
+#else
+#define CVMX_CIU3_ISCX_W1S(offset) (CVMX_ADD_IO_SEG(0x00010100A0000000ull) + ((offset) & 1048575) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU3_NMI CVMX_CIU3_NMI_FUNC()
+static inline uint64_t CVMX_CIU3_NMI_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_CIU3_NMI not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001010000000160ull);
+}
+#else
+#define CVMX_CIU3_NMI (CVMX_ADD_IO_SEG(0x0001010000000160ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_CIU3_SISCX(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 191)))))
+		cvmx_warn("CVMX_CIU3_SISCX(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001010000220000ull) + ((offset) & 255) * 8;
+}
+#else
+#define CVMX_CIU3_SISCX(offset) (CVMX_ADD_IO_SEG(0x0001010000220000ull) + ((offset) & 255) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_CIU3_TIMX(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 9)))))
+		cvmx_warn("CVMX_CIU3_TIMX(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001010000010000ull) + ((offset) & 15) * 8;
+}
+#else
+#define CVMX_CIU3_TIMX(offset) (CVMX_ADD_IO_SEG(0x0001010000010000ull) + ((offset) & 15) * 8)
+#endif
+
+/**
+ * cvmx_ciu3_bist
+ */
+union cvmx_ciu3_bist {
+	uint64_t u64;
+	struct cvmx_ciu3_bist_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_11_63               : 53;
+	uint64_t bist                         : 11; /**< BIST results. Hardware sets a bit for each memory that fails BIST. INTERNAL:
+                                                         <10>= ncbo_crd_fif_mem0.
+                                                         <9> = ciu_nbt_sso_req_ram.
+                                                         <8> = ciu_nbt_rsp_ram.
+                                                         <7> = ciu_sso_output_fifo_mem.
+                                                         <6> = ciu_isc_ram2.
+                                                         <5> = ciu_isc_ram1.
+                                                         <4> = ciu_isc_ram0.
+                                                         <3> = ciu_sist_ram.
+                                                         <2> = ciu_idt_ram.
+                                                         <1> = csr req_mem.
+                                                         <0> = ciu3_wdg_ctl_mem. */
+#else
+	uint64_t bist                         : 11;
+	uint64_t reserved_11_63               : 53;
+#endif
+	} s;
+	struct cvmx_ciu3_bist_s               cn78xx;
+};
+typedef union cvmx_ciu3_bist cvmx_ciu3_bist_t;
+
+/**
+ * cvmx_ciu3_const
+ */
+union cvmx_ciu3_const {
+	uint64_t u64;
+	struct cvmx_ciu3_const_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dests_io                     : 16; /**< Number of entries in CIU3_DEST(0..4)_IO_INT. */
+	uint64_t pintsn                       : 16; /**< Physical INTSNs implemented. */
+	uint64_t dests_pp                     : 16; /**< Number of entries in CIU3_DEST(0..143)_PP_INT. */
+	uint64_t idt                          : 16; /**< Number of entries in CIU3_IDT(0..255)_CTL. */
+#else
+	uint64_t idt                          : 16;
+	uint64_t dests_pp                     : 16;
+	uint64_t pintsn                       : 16;
+	uint64_t dests_io                     : 16;
+#endif
+	} s;
+	struct cvmx_ciu3_const_s              cn78xx;
+};
+typedef union cvmx_ciu3_const cvmx_ciu3_const_t;
+
+/**
+ * cvmx_ciu3_ctl
+ */
+union cvmx_ciu3_ctl {
+	uint64_t u64;
+	struct cvmx_ciu3_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_5_63                : 59;
+	uint64_t mcd_sel                      : 2;  /**< When a MCD interrupt is requested via the IDT, which MCD number to pulse:
+                                                         0x0 = MCD0.
+                                                         0x1 = MCD1.
+                                                         0x2 = MCD2.
+                                                         0x3 = Reserved. */
+	uint64_t iscmem_le                    : 1;  /**< Reserved. */
+	uint64_t seq_dis                      : 1;  /**< Disable running sequencer only when required to reduce power, and run continuously. For
+                                                         diagnostic use only. */
+	uint64_t cclk_dis                     : 1;  /**< Disable power saving conditional clocking. */
+#else
+	uint64_t cclk_dis                     : 1;
+	uint64_t seq_dis                      : 1;
+	uint64_t iscmem_le                    : 1;
+	uint64_t mcd_sel                      : 2;
+	uint64_t reserved_5_63                : 59;
+#endif
+	} s;
+	struct cvmx_ciu3_ctl_s                cn78xx;
+};
+typedef union cvmx_ciu3_ctl cvmx_ciu3_ctl_t;
+
+/**
+ * cvmx_ciu3_dest#_io_int
+ *
+ * This register contains reduced interrupt source numbers for delivery to software, indexed by
+ * I/O bridge number. Fields are identical to CIU3_DEST()_PP_INT.
+ */
+union cvmx_ciu3_destx_io_int {
+	uint64_t u64;
+	struct cvmx_ciu3_destx_io_int_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_52_63               : 12;
+	uint64_t intsn                        : 20; /**< Interrupt source number causing the current interrupt, or most recent interrupt if INTR is
+                                                         clear. Note this field is not stored in the DEST ram itself; it is instead read from
+                                                         CIU3_IDT()_CTL[INTSN]. */
+	uint64_t reserved_10_31               : 22;
+	uint64_t intidt                       : 8;  /**< IDT entry number causing the current interrupt, or most recent interrupt if INTR is clear. */
+	uint64_t newint                       : 1;  /**< New interrupt to be delivered. Internal state, for diagnostic use only. */
+	uint64_t intr                         : 1;  /**< Interrupt pending. This bit is recalculated when CIU3_ISC()_CTL or interrupts
+                                                         change, so does not need to be cleared by software. */
+#else
+	uint64_t intr                         : 1;
+	uint64_t newint                       : 1;
+	uint64_t intidt                       : 8;
+	uint64_t reserved_10_31               : 22;
+	uint64_t intsn                        : 20;
+	uint64_t reserved_52_63               : 12;
+#endif
+	} s;
+	struct cvmx_ciu3_destx_io_int_s       cn78xx;
+};
+typedef union cvmx_ciu3_destx_io_int cvmx_ciu3_destx_io_int_t;
+
+/**
+ * cvmx_ciu3_dest#_pp_int
+ *
+ * This register contains reduced interrupt source numbers for delivery to software, indexed by
+ * CIU_DEST_E.
+ */
+union cvmx_ciu3_destx_pp_int {
+	uint64_t u64;
+	struct cvmx_ciu3_destx_pp_int_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_52_63               : 12;
+	uint64_t intsn                        : 20; /**< Interrupt source number causing the current interrupt, or most recent interrupt if INTR is
+                                                         clear. Note this field is not stored in the DEST ram itself; it is instead read from
+                                                         CIU3_IDT()_CTL[INTSN]. */
+	uint64_t reserved_10_31               : 22;
+	uint64_t intidt                       : 8;  /**< IDT entry number causing the current interrupt, or most recent interrupt if INTR is clear. */
+	uint64_t newint                       : 1;  /**< New interrupt to be delivered. Internal state, for diagnostic use only. */
+	uint64_t intr                         : 1;  /**< Interrupt pending. This bit is recalculated when CIU3_ISC()_CTL or interrupts
+                                                         change, so does not need to be cleared by software. */
+#else
+	uint64_t intr                         : 1;
+	uint64_t newint                       : 1;
+	uint64_t intidt                       : 8;
+	uint64_t reserved_10_31               : 22;
+	uint64_t intsn                        : 20;
+	uint64_t reserved_52_63               : 12;
+#endif
+	} s;
+	struct cvmx_ciu3_destx_pp_int_s       cn78xx;
+};
+typedef union cvmx_ciu3_destx_pp_int cvmx_ciu3_destx_pp_int_t;
+
+/**
+ * cvmx_ciu3_gstop
+ */
+union cvmx_ciu3_gstop {
+	uint64_t u64;
+	struct cvmx_ciu3_gstop_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_1_63                : 63;
+	uint64_t gstop                        : 1;  /**< Set global-stop mode. */
+#else
+	uint64_t gstop                        : 1;
+	uint64_t reserved_1_63                : 63;
+#endif
+	} s;
+	struct cvmx_ciu3_gstop_s              cn78xx;
+};
+typedef union cvmx_ciu3_gstop cvmx_ciu3_gstop_t;
+
+/**
+ * cvmx_ciu3_idt#_ctl
+ *
+ * Entry zero of the IDT is reserved to mean 'no interrupt' and is not writable by software.
+ *
+ */
+union cvmx_ciu3_idtx_ctl {
+	uint64_t u64;
+	struct cvmx_ciu3_idtx_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_52_63               : 12;
+	uint64_t intsn                        : 20; /**< Interrupt source number causing the current interrupt, or most recent interrupt if INTR is
+                                                         clear. INTERNAL: Hardware does not store the 20 bit INTSN here; it instead stores the
+                                                         sparse 12 bit PINTSN, and maps it to INTSN on a read. */
+	uint64_t reserved_4_31                : 28;
+	uint64_t intr                         : 1;  /**< Interrupt pending */
+	uint64_t newint                       : 1;  /**< New interrupt to be delivered. Internal state, for diagnostic use only. */
+	uint64_t ip_num                       : 2;  /**< Destination interrupt priority level to receive this interrupt. Only used for core
+                                                         interrupts; for IO interrupts this level must be zero.
+                                                         0x0 = IP2, or I/O interrupt.
+                                                         0x1 = IP3.
+                                                         0x2 = IP4.
+                                                         0x3 = Reserved. */
+#else
+	uint64_t ip_num                       : 2;
+	uint64_t newint                       : 1;
+	uint64_t intr                         : 1;
+	uint64_t reserved_4_31                : 28;
+	uint64_t intsn                        : 20;
+	uint64_t reserved_52_63               : 12;
+#endif
+	} s;
+	struct cvmx_ciu3_idtx_ctl_s           cn78xx;
+};
+typedef union cvmx_ciu3_idtx_ctl cvmx_ciu3_idtx_ctl_t;
+
+/**
+ * cvmx_ciu3_idt#_io
+ *
+ * Entry zero of the IDT is reserved to mean 'no interrupt' and is not writable by software.
+ *
+ */
+union cvmx_ciu3_idtx_io {
+	uint64_t u64;
+	struct cvmx_ciu3_idtx_io_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_5_63                : 59;
+	uint64_t io                           : 5;  /**< Bitmask of which IO bridges or MCD to receive interrupts via this IDT.
+                                                         Enumerated with CIU_DEST_IO_E. */
+#else
+	uint64_t io                           : 5;
+	uint64_t reserved_5_63                : 59;
+#endif
+	} s;
+	struct cvmx_ciu3_idtx_io_s            cn78xx;
+};
+typedef union cvmx_ciu3_idtx_io cvmx_ciu3_idtx_io_t;
+
+/**
+ * cvmx_ciu3_idt#_pp#
+ *
+ * Entry zero of the IDT is reserved to mean 'no interrupt' and is not writable by software. The
+ * second (PP) index in this register is always zero to allow expansion beyond 64 cores.
+ */
+union cvmx_ciu3_idtx_ppx {
+	uint64_t u64;
+	struct cvmx_ciu3_idtx_ppx_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_48_63               : 16;
+	uint64_t pp                           : 48; /**< Bitmask of which cores receive interrupts via this IDT. */
+#else
+	uint64_t pp                           : 48;
+	uint64_t reserved_48_63               : 16;
+#endif
+	} s;
+	struct cvmx_ciu3_idtx_ppx_s           cn78xx;
+};
+typedef union cvmx_ciu3_idtx_ppx cvmx_ciu3_idtx_ppx_t;
+
+/**
+ * cvmx_ciu3_intr_ram_ecc_ctl
+ */
+union cvmx_ciu3_intr_ram_ecc_ctl {
+	uint64_t u64;
+	struct cvmx_ciu3_intr_ram_ecc_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_3_63                : 61;
+	uint64_t flip_synd                    : 2;  /**< Testing feature. Flip syndrome to generate single-bit or double-bit errors. FLIP_SYND<0>
+                                                         generates even numbered bits errors; FLIP_SYND<1> generates odd bits errors. */
+	uint64_t ecc_ena                      : 1;  /**< ECC enable. When set, enables the 9-bit ECC check/correct logic for CIU interrupt-enable
+                                                         RAM. With ECC enabled, the ECC code is generated and written in memory, and then later on
+                                                         reads, is used to check and correct single-bit errors and detect double-bit errors. */
+#else
+	uint64_t ecc_ena                      : 1;
+	uint64_t flip_synd                    : 2;
+	uint64_t reserved_3_63                : 61;
+#endif
+	} s;
+	struct cvmx_ciu3_intr_ram_ecc_ctl_s   cn78xx;
+};
+typedef union cvmx_ciu3_intr_ram_ecc_ctl cvmx_ciu3_intr_ram_ecc_ctl_t;
+
+/**
+ * cvmx_ciu3_intr_ram_ecc_st
+ */
+union cvmx_ciu3_intr_ram_ecc_st {
+	uint64_t u64;
+	struct cvmx_ciu3_intr_ram_ecc_st_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_52_63               : 12;
+	uint64_t addr                         : 20; /**< Latch the address for latest SBE/DBE that occurred. */
+	uint64_t reserved_6_31                : 26;
+	uint64_t sisc_dbe                     : 1;  /**< SISC Double-bit error observed. Throws CIU_INTSN_E::CIU_ECC_SISC_DBE. */
+	uint64_t sisc_sbe                     : 1;  /**< SISC Single-bit error observed. Throws CIU_INTSN_E::CIU_ECC_SISC_SBE. */
+	uint64_t idt_dbe                      : 1;  /**< IDT Double-bit error observed. Throws CIU_INTSN_E::CIU_ECC_IDT_DBE. */
+	uint64_t idt_sbe                      : 1;  /**< IDT Single-bit error observed. Throws CIU_INTSN_E::CIU_ECC_IDT_SBE. */
+	uint64_t isc_dbe                      : 1;  /**< ISC Double-bit error observed. Throws CIU_INTSN_E::CIU_ECC_ISC_DBE. */
+	uint64_t isc_sbe                      : 1;  /**< ISC Single-bit error observed. Throws CIU_INTSN_E::CIU_ECC_ISC_SBE. */
+#else
+	uint64_t isc_sbe                      : 1;
+	uint64_t isc_dbe                      : 1;
+	uint64_t idt_sbe                      : 1;
+	uint64_t idt_dbe                      : 1;
+	uint64_t sisc_sbe                     : 1;
+	uint64_t sisc_dbe                     : 1;
+	uint64_t reserved_6_31                : 26;
+	uint64_t addr                         : 20;
+	uint64_t reserved_52_63               : 12;
+#endif
+	} s;
+	struct cvmx_ciu3_intr_ram_ecc_st_s    cn78xx;
+};
+typedef union cvmx_ciu3_intr_ram_ecc_st cvmx_ciu3_intr_ram_ecc_st_t;
+
+/**
+ * cvmx_ciu3_intr_ready
+ */
+union cvmx_ciu3_intr_ready {
+	uint64_t u64;
+	struct cvmx_ciu3_intr_ready_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_46_63               : 18;
+	uint64_t index                        : 14; /**< Scanner index. If [READY] set, the current index, else the index the scanner stopped at.
+                                                         For diagnostic use only. */
+	uint64_t sso_cnt                      : 16; /**< Reserved. INTERNAL: Deprecated. Number of SSO events waiting to be sent to SSO. */
+	uint64_t reserved_1_15                : 15;
+	uint64_t ready                        : 1;  /**< CIU is idle. If clear, CIU is performing a background scan searching for secondary
+                                                         interrupts. Write one to force a new scan. For diagnostic use only. */
+#else
+	uint64_t ready                        : 1;
+	uint64_t reserved_1_15                : 15;
+	uint64_t sso_cnt                      : 16;
+	uint64_t index                        : 14;
+	uint64_t reserved_46_63               : 18;
+#endif
+	} s;
+	struct cvmx_ciu3_intr_ready_s         cn78xx;
+};
+typedef union cvmx_ciu3_intr_ready cvmx_ciu3_intr_ready_t;
+
+/**
+ * cvmx_ciu3_intr_slowdown
+ */
+union cvmx_ciu3_intr_slowdown {
+	uint64_t u64;
+	struct cvmx_ciu3_intr_slowdown_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_3_63                : 61;
+	uint64_t ctl                          : 3;  /**< Slow down CIU interrupt walker processing time. IRQ2/3/4 for all cores are sent to the
+                                                         core (MRC) in a serial bus to reduce global routing. There is no backpressure mechanism
+                                                         designed for this scheme. It will only be a problem when SCLK is faster; this control will
+                                                         process 1 interrupt in 4*(2^CTL) SCLK cycles. For example:
+                                                         0x0 = sclk_freq/aclk_freq ratio is 4.
+                                                         0x1 = sclk_freq/aclk_freq ratio is 8. */
+#else
+	uint64_t ctl                          : 3;
+	uint64_t reserved_3_63                : 61;
+#endif
+	} s;
+	struct cvmx_ciu3_intr_slowdown_s      cn78xx;
+};
+typedef union cvmx_ciu3_intr_slowdown cvmx_ciu3_intr_slowdown_t;
+
+/**
+ * cvmx_ciu3_isc#_ctl
+ *
+ * Sparse table indexed by INTSN.
+ *
+ */
+union cvmx_ciu3_iscx_ctl {
+	uint64_t u64;
+	struct cvmx_ciu3_iscx_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_24_63               : 40;
+	uint64_t idt                          : 8;  /**< Interrupt Delivery Table entry number. Zero indicates IDT delivery is disabled. This field
+                                                         may only be changed when EN was previously clear, though it may be changed with the same
+                                                         write that sets EN. Thus if EN is set, to change IDT two register writes are required, the
+                                                         first to clear EN (perhaps by a store to CIU3_ISC()_W1C), and the second to make
+                                                         the change to IDT. */
+	uint64_t imp                          : 1;  /**< Entry implemented. Although the table has 1M entries, most of those do not correspond to
+                                                         any INTSN, and as such are not implemented.
+                                                         1 = The IDT and EN fields for this index are R/W, and may have a corresponding INTSN,
+                                                         although some indices may have IMP set but not have any INTSN use.
+                                                         0 = The IDT and EN fields for this index are RAZ, and do not have any corresponding
+                                                         INTSN. */
+	uint64_t sso_pend                     : 1;  /**< Reserved. INTERNAL: Deprecated. Transaction needs to be sent to SSO. CIU internal state
+                                                         for diagnostic use. [SSO_PEND] will be cleared when the entry is transmitted to SSO, or by
+                                                         a software clear of [SSO], [RAW] or [EN]. */
+	uint64_t reserved_3_13                : 11;
+	uint64_t sso                          : 1;  /**< Reserved. This field may be read-only for some indexes.
+                                                         INTERNAL: Deprecated. Use SSO delivery. */
+	uint64_t en                           : 1;  /**< Enable interrupt delivery. */
+	uint64_t raw                          : 1;  /**< Interrupt pending before masking. Note read only, must use
+                                                         CIU3_ISC()_W1C/CIU3_ISC()_W1S to toggle. */
+#else
+	uint64_t raw                          : 1;
+	uint64_t en                           : 1;
+	uint64_t sso                          : 1;
+	uint64_t reserved_3_13                : 11;
+	uint64_t sso_pend                     : 1;
+	uint64_t imp                          : 1;
+	uint64_t idt                          : 8;
+	uint64_t reserved_24_63               : 40;
+#endif
+	} s;
+	struct cvmx_ciu3_iscx_ctl_s           cn78xx;
+};
+typedef union cvmx_ciu3_iscx_ctl cvmx_ciu3_iscx_ctl_t;
+
+/**
+ * cvmx_ciu3_isc#_w1c
+ */
+union cvmx_ciu3_iscx_w1c {
+	uint64_t u64;
+	struct cvmx_ciu3_iscx_w1c_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_3_63                : 61;
+	uint64_t sso                          : 1;  /**< Reserved. INTERNAL: Deprecated. Use SSO work-queue-entry delivery. */
+	uint64_t en                           : 1;  /**< Clear enable interrupt delivery. See CIU3_ISC()_CTL[EN]. */
+	uint64_t raw                          : 1;  /**< Clear interrupt pending. See CIU3_ISC()_CTL[RAW]. */
+#else
+	uint64_t raw                          : 1;
+	uint64_t en                           : 1;
+	uint64_t sso                          : 1;
+	uint64_t reserved_3_63                : 61;
+#endif
+	} s;
+	struct cvmx_ciu3_iscx_w1c_s           cn78xx;
+};
+typedef union cvmx_ciu3_iscx_w1c cvmx_ciu3_iscx_w1c_t;
+
+/**
+ * cvmx_ciu3_isc#_w1s
+ */
+union cvmx_ciu3_iscx_w1s {
+	uint64_t u64;
+	struct cvmx_ciu3_iscx_w1s_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_3_63                : 61;
+	uint64_t sso                          : 1;  /**< Reserved. INTERNAL: Deprecated. Use SSO work-queue-entry delivery. */
+	uint64_t en                           : 1;  /**< Set enable interrupt delivery. See CIU3_ISC()_CTL[EN]. */
+	uint64_t raw                          : 1;  /**< Set interrupt pending. See CIU3_ISC()_CTL[RAW]. */
+#else
+	uint64_t raw                          : 1;
+	uint64_t en                           : 1;
+	uint64_t sso                          : 1;
+	uint64_t reserved_3_63                : 61;
+#endif
+	} s;
+	struct cvmx_ciu3_iscx_w1s_s           cn78xx;
+};
+typedef union cvmx_ciu3_iscx_w1s cvmx_ciu3_iscx_w1s_t;
+
+/**
+ * cvmx_ciu3_iscmem_base
+ *
+ * Deprecated.
+ *
+ */
+union cvmx_ciu3_iscmem_base {
+	uint64_t u64;
+	struct cvmx_ciu3_iscmem_base_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_42_63               : 22;
+	uint64_t addr                         : 38; /**< Base address of CIU_INTSN_E table. Note must be 16-byte aligned and is in root-physical
+                                                         address space. Endinaness is selected with CIU3_CTL[ISCMEM_LE]. */
+	uint64_t addrl4                       : 4;  /**< Lowest 4 bits of Base address of CIU_INTSN_E table, always zero as CIU_ISCMEM_S structure
+                                                         is 16-byte aligned. */
+#else
+	uint64_t addrl4                       : 4;
+	uint64_t addr                         : 38;
+	uint64_t reserved_42_63               : 22;
+#endif
+	} s;
+	struct cvmx_ciu3_iscmem_base_s        cn78xx;
+};
+typedef union cvmx_ciu3_iscmem_base cvmx_ciu3_iscmem_base_t;
+
+/**
+ * cvmx_ciu3_nmi
+ */
+union cvmx_ciu3_nmi {
+	uint64_t u64;
+	struct cvmx_ciu3_nmi_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_48_63               : 16;
+	uint64_t nmi                          : 48; /**< Writing a 1 to a bit sends an NMI pulse to the corresponding core vector. */
+#else
+	uint64_t nmi                          : 48;
+	uint64_t reserved_48_63               : 16;
+#endif
+	} s;
+	struct cvmx_ciu3_nmi_s                cn78xx;
+};
+typedef union cvmx_ciu3_nmi cvmx_ciu3_nmi_t;
+
+/**
+ * cvmx_ciu3_sisc#
+ */
+union cvmx_ciu3_siscx {
+	uint64_t u64;
+	struct cvmx_ciu3_siscx_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t en                           : 64; /**< Indicates each corresponding ISC entry has enabled & interrupting entry. For diagnostic use only. */
+#else
+	uint64_t en                           : 64;
+#endif
+	} s;
+	struct cvmx_ciu3_siscx_s              cn78xx;
+};
+typedef union cvmx_ciu3_siscx cvmx_ciu3_siscx_t;
+
+/**
+ * cvmx_ciu3_tim#
+ */
+union cvmx_ciu3_timx {
+	uint64_t u64;
+	struct cvmx_ciu3_timx_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_37_63               : 27;
+	uint64_t one_shot                     : 1;  /**< One-shot mode when LEN != 0x0:
+                                                         0 = Timer is in periodic mode.
+                                                         1 = Timer is in one-shot mode. */
+	uint64_t len                          : 36; /**< Time-out length in coprocessor clock cycles. The timer disabled when LEN = 0x0. Periodic
+                                                         interrupts will occur every LEN+1 coprocessor clock cycles when ONE_SHOT = 0 */
+#else
+	uint64_t len                          : 36;
+	uint64_t one_shot                     : 1;
+	uint64_t reserved_37_63               : 27;
+#endif
+	} s;
+	struct cvmx_ciu3_timx_s               cn78xx;
+};
+typedef union cvmx_ciu3_timx cvmx_ciu3_timx_t;
+
+#endif
diff --git a/arch/mips/include/asm/octeon/cvmx.h b/arch/mips/include/asm/octeon/cvmx.h
index 1125819..b5de442 100644
--- a/arch/mips/include/asm/octeon/cvmx.h
+++ b/arch/mips/include/asm/octeon/cvmx.h
@@ -275,6 +275,21 @@ static inline void cvmx_write_csr(uint64_t csr_addr, uint64_t val)
 		cvmx_read64(CVMX_MIO_BOOT_BIST_STAT);
 }
 
+static inline void cvmx_write_csr_node(uint64_t node, uint64_t csr_addr,
+                                       uint64_t val)
+{
+	uint64_t node_addr;
+	uint64_t composite_csr_addr;
+	node_addr = (node & CVMX_NODE_MASK) << CVMX_NODE_IO_SHIFT;
+
+	composite_csr_addr = (csr_addr & ~CVMX_NODE_IO_MASK) | node_addr;
+
+	cvmx_write64_uint64(composite_csr_addr, val);
+	if (((csr_addr >> 40) & 0x7ffff) == (0x118)) {
+		cvmx_read64_uint64(CVMX_MIO_BOOT_BIST_STAT | node_addr);
+	}
+}
+
 static inline void cvmx_write_io(uint64_t io_addr, uint64_t val)
 {
 	cvmx_write64(io_addr, val);
@@ -287,6 +302,13 @@ static inline uint64_t cvmx_read_csr(uint64_t csr_addr)
 	return val;
 }
 
+static inline uint64_t cvmx_read_csr_node(uint64_t node, uint64_t csr_addr)
+{
+	uint64_t node_addr;
+
+	node_addr = (csr_addr & ~CVMX_NODE_IO_MASK) | (node & CVMX_NODE_MASK) << CVMX_NODE_IO_SHIFT;
+	return cvmx_read_csr(node_addr);
+}
 
 static inline void cvmx_send_single(uint64_t data)
 {
@@ -332,6 +354,12 @@ static inline unsigned int cvmx_get_core_num(void)
 	return core_num;
 }
 
+static inline unsigned int cvmx_get_node_num(void)
+{
+	unsigned int core_num = cvmx_get_core_num();
+	return (core_num >> CVMX_NODE_NO_SHIFT) & CVMX_NODE_MASK;
+}
+
 /**
  * Returns the number of bits set in the provided value.
  * Simple wrapper for POP instruction.
diff --git a/arch/mips/include/asm/octeon/octeon.h b/arch/mips/include/asm/octeon/octeon.h
index 12827b2..9d42eac 100644
--- a/arch/mips/include/asm/octeon/octeon.h
+++ b/arch/mips/include/asm/octeon/octeon.h
@@ -260,6 +260,7 @@ typedef void (*octeon_message_fn_t)(void);
 int octeon_request_ipi_handler(octeon_message_fn_t fn);
 void octeon_send_ipi_single(int cpu, unsigned int action);
 void octeon_release_ipi_handler(int action);
+void octeon_ciu3_mbox_send(int cpu, unsigned int mbox);
 
 #if IS_ENABLED(CONFIG_CAVIUM_OCTEON_ERROR_TREE)
 int octeon_error_tree_enable(enum cvmx_error_groups group, int unit);
-- 
1.8.2.1

